{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.client.session.Session at 0x7fe5b43111d0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "# #指定使用那块GUP训练\n",
    "import os\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "config = tf.ConfigProto()\n",
    "# 设置最大占有GPU不超过显存的70%\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.7 \n",
    "# # 重点：设置动态分配GPU\n",
    "config.gpu_options.allow_growth = True\n",
    "# 创建session时\n",
    "tf.Session(config=config) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Conv2d(3, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "  (2): ReLU()\n",
      "  (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "  (5): ReLU()\n",
      "  (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (7): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (8): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "  (9): ReLU()\n",
      "  (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (11): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "  (12): ReLU()\n",
      "  (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (14): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (15): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "  (16): ReLU()\n",
      "  (17): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (18): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "  (19): ReLU()\n",
      "  (20): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (21): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (22): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "  (23): ReLU()\n",
      "  (24): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      ")\n",
      "Sequential(\n",
      "  (0): Linear(in_features=1024, out_features=10, bias=True)\n",
      ")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 16, 16, 16)        448       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 16, 16, 16)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 16, 16, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 8, 8, 32)          4640      \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 8, 8, 32)          128       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)    (None, 8, 8, 32)          0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 8, 8, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 4, 4, 64)          18496     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 4, 4, 64)          256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)    (None, 4, 4, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 4, 4, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 4, 4, 128)         73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 4, 4, 128)         512       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)    (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 2049      \n",
      "=================================================================\n",
      "Total params: 100,385\n",
      "Trainable params: 99,937\n",
      "Non-trainable params: 448\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_2 (Dense)              (None, 8192)              827392    \n",
      "_________________________________________________________________\n",
      "reshape_1 (Reshape)          (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2 (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 16, 16, 128)       262272    \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 16, 16, 128)       512       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2 (None, 32, 32, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 32, 32, 64)        131136    \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 32, 32, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 32, 32, 3)         3075      \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 32, 32, 3)         0         \n",
      "=================================================================\n",
      "Total params: 1,224,643\n",
      "Trainable params: 1,224,259\n",
      "Non-trainable params: 384\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/imi432_006/anaconda3/envs/tf/lib/python3.5/site-packages/keras/engine/training.py:490: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "  'Discrepancy between trainable weights and collected trainable'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0 step:5[D loss: 0.999906] [G loss: 1.000187]\n",
      "epoch:0 step:10[D loss: 0.999914] [G loss: 1.000194]\n",
      "epoch:0 step:15[D loss: 0.999915] [G loss: 1.000194]\n",
      "epoch:0 step:20[D loss: 0.999912] [G loss: 1.000190]\n",
      "epoch:0 step:25[D loss: 0.999912] [G loss: 1.000190]\n",
      "epoch:0 step:30[D loss: 0.999914] [G loss: 1.000188]\n",
      "epoch:0 step:35[D loss: 0.999917] [G loss: 1.000182]\n",
      "epoch:0 step:40[D loss: 0.999917] [G loss: 1.000189]\n",
      "epoch:0 step:45[D loss: 0.999918] [G loss: 1.000188]\n",
      "epoch:0 step:50[D loss: 0.999913] [G loss: 1.000187]\n",
      "epoch:0 step:55[D loss: 0.999918] [G loss: 1.000186]\n",
      "epoch:0 step:60[D loss: 0.999921] [G loss: 1.000182]\n",
      "epoch:0 step:65[D loss: 0.999922] [G loss: 1.000175]\n",
      "epoch:0 step:70[D loss: 0.999922] [G loss: 1.000172]\n",
      "epoch:0 step:75[D loss: 0.999921] [G loss: 1.000163]\n",
      "epoch:0 step:80[D loss: 0.999924] [G loss: 1.000157]\n",
      "epoch:0 step:85[D loss: 0.999930] [G loss: 1.000140]\n",
      "epoch:0 step:90[D loss: 0.999931] [G loss: 1.000141]\n",
      "epoch:0 step:95[D loss: 0.999934] [G loss: 1.000131]\n",
      "epoch:0 step:100[D loss: 0.999938] [G loss: 1.000130]\n",
      "epoch:0 step:105[D loss: 0.999940] [G loss: 1.000121]\n",
      "epoch:0 step:110[D loss: 0.999943] [G loss: 1.000120]\n",
      "epoch:0 step:115[D loss: 0.999947] [G loss: 1.000109]\n",
      "epoch:0 step:120[D loss: 0.999949] [G loss: 1.000105]\n",
      "epoch:0 step:125[D loss: 0.999951] [G loss: 1.000097]\n",
      "epoch:0 step:130[D loss: 0.999955] [G loss: 1.000094]\n",
      "epoch:0 step:135[D loss: 0.999958] [G loss: 1.000091]\n",
      "epoch:0 step:140[D loss: 0.999959] [G loss: 1.000085]\n",
      "epoch:0 step:145[D loss: 0.999960] [G loss: 1.000080]\n",
      "epoch:0 step:150[D loss: 0.999959] [G loss: 1.000076]\n",
      "epoch:0 step:155[D loss: 0.999962] [G loss: 1.000080]\n",
      "epoch:0 step:160[D loss: 0.999963] [G loss: 1.000077]\n",
      "epoch:0 step:165[D loss: 0.999964] [G loss: 1.000078]\n",
      "epoch:0 step:170[D loss: 0.999965] [G loss: 1.000074]\n",
      "epoch:0 step:175[D loss: 0.999966] [G loss: 1.000070]\n",
      "epoch:0 step:180[D loss: 0.999966] [G loss: 1.000072]\n",
      "epoch:0 step:185[D loss: 0.999967] [G loss: 1.000073]\n",
      "epoch:0 step:190[D loss: 0.999966] [G loss: 1.000070]\n",
      "epoch:0 step:195[D loss: 0.999968] [G loss: 1.000072]\n",
      "epoch:0 step:200[D loss: 0.999968] [G loss: 1.000065]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/imi432_006/anaconda3/envs/tf/lib/python3.5/site-packages/ipykernel_launcher.py:57: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "/home/imi432_006/anaconda3/envs/tf/lib/python3.5/site-packages/ipykernel_launcher.py:59: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/home/imi432_006/anaconda3/envs/tf/lib/python3.5/site-packages/ipykernel_launcher.py:86: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "/home/imi432_006/anaconda3/envs/tf/lib/python3.5/site-packages/ipykernel_launcher.py:90: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##############\n",
      "[0.87096688 0.85958426 0.85245389 0.84565436 0.82675575 0.86339356\n",
      " 0.86045328 0.86506312 0.81397523 0.87950795]\n",
      "##########\n",
      "epoch:0 step:205[D loss: 0.999971] [G loss: 1.000069]\n",
      "epoch:0 step:210[D loss: 0.999969] [G loss: 1.000069]\n",
      "epoch:0 step:215[D loss: 0.999972] [G loss: 1.000070]\n",
      "epoch:0 step:220[D loss: 0.999971] [G loss: 1.000071]\n",
      "epoch:0 step:225[D loss: 0.999969] [G loss: 1.000071]\n",
      "epoch:0 step:230[D loss: 0.999970] [G loss: 1.000074]\n",
      "epoch:0 step:235[D loss: 0.999969] [G loss: 1.000070]\n",
      "epoch:0 step:240[D loss: 0.999969] [G loss: 1.000067]\n",
      "epoch:0 step:245[D loss: 0.999970] [G loss: 1.000068]\n",
      "epoch:0 step:250[D loss: 0.999971] [G loss: 1.000063]\n",
      "epoch:0 step:255[D loss: 0.999971] [G loss: 1.000069]\n",
      "epoch:0 step:260[D loss: 0.999969] [G loss: 1.000068]\n",
      "epoch:0 step:265[D loss: 0.999971] [G loss: 1.000067]\n",
      "epoch:0 step:270[D loss: 0.999972] [G loss: 1.000067]\n",
      "epoch:0 step:275[D loss: 0.999970] [G loss: 1.000065]\n",
      "epoch:0 step:280[D loss: 0.999973] [G loss: 1.000058]\n",
      "epoch:0 step:285[D loss: 0.999974] [G loss: 1.000068]\n",
      "epoch:0 step:290[D loss: 0.999974] [G loss: 1.000067]\n",
      "epoch:0 step:295[D loss: 0.999973] [G loss: 1.000068]\n",
      "epoch:0 step:300[D loss: 0.999969] [G loss: 1.000065]\n",
      "epoch:0 step:305[D loss: 0.999973] [G loss: 1.000061]\n",
      "epoch:0 step:310[D loss: 0.999968] [G loss: 1.000063]\n",
      "epoch:0 step:315[D loss: 0.999970] [G loss: 1.000064]\n",
      "epoch:0 step:320[D loss: 0.999971] [G loss: 1.000070]\n",
      "epoch:0 step:325[D loss: 0.999972] [G loss: 1.000064]\n",
      "epoch:0 step:330[D loss: 0.999972] [G loss: 1.000061]\n",
      "epoch:0 step:335[D loss: 0.999973] [G loss: 1.000064]\n",
      "epoch:0 step:340[D loss: 0.999975] [G loss: 1.000056]\n",
      "epoch:0 step:345[D loss: 0.999970] [G loss: 1.000065]\n",
      "epoch:0 step:350[D loss: 0.999972] [G loss: 1.000064]\n",
      "epoch:0 step:355[D loss: 0.999973] [G loss: 1.000058]\n",
      "epoch:0 step:360[D loss: 0.999978] [G loss: 1.000063]\n",
      "epoch:0 step:365[D loss: 0.999972] [G loss: 1.000065]\n",
      "epoch:0 step:370[D loss: 0.999971] [G loss: 1.000064]\n",
      "epoch:0 step:375[D loss: 0.999974] [G loss: 1.000066]\n",
      "epoch:0 step:380[D loss: 0.999971] [G loss: 1.000061]\n",
      "epoch:0 step:385[D loss: 0.999973] [G loss: 1.000061]\n",
      "epoch:0 step:390[D loss: 0.999975] [G loss: 1.000064]\n",
      "epoch:0 step:395[D loss: 0.999976] [G loss: 1.000063]\n",
      "epoch:0 step:400[D loss: 0.999972] [G loss: 1.000064]\n",
      "##############\n",
      "[0.85504298 0.8601317  0.83826385 0.84706567 0.81020543 0.82254523\n",
      " 0.8359952  0.87636327 0.81198454 0.86923309]\n",
      "##########\n",
      "epoch:0 step:405[D loss: 0.999976] [G loss: 1.000064]\n",
      "epoch:0 step:410[D loss: 0.999974] [G loss: 1.000065]\n",
      "epoch:0 step:415[D loss: 0.999974] [G loss: 1.000066]\n",
      "epoch:0 step:420[D loss: 0.999977] [G loss: 1.000062]\n",
      "epoch:0 step:425[D loss: 0.999969] [G loss: 1.000068]\n",
      "epoch:0 step:430[D loss: 0.999972] [G loss: 1.000069]\n",
      "epoch:0 step:435[D loss: 0.999976] [G loss: 1.000064]\n",
      "epoch:0 step:440[D loss: 0.999971] [G loss: 1.000066]\n",
      "epoch:0 step:445[D loss: 0.999972] [G loss: 1.000064]\n",
      "epoch:0 step:450[D loss: 0.999973] [G loss: 1.000061]\n",
      "epoch:0 step:455[D loss: 0.999977] [G loss: 1.000060]\n",
      "epoch:0 step:460[D loss: 0.999979] [G loss: 1.000062]\n",
      "epoch:0 step:465[D loss: 0.999978] [G loss: 1.000058]\n",
      "epoch:0 step:470[D loss: 0.999971] [G loss: 1.000060]\n",
      "epoch:0 step:475[D loss: 0.999976] [G loss: 1.000065]\n",
      "epoch:0 step:480[D loss: 0.999977] [G loss: 1.000060]\n",
      "epoch:0 step:485[D loss: 0.999974] [G loss: 1.000055]\n",
      "epoch:0 step:490[D loss: 0.999976] [G loss: 1.000063]\n",
      "epoch:0 step:495[D loss: 0.999975] [G loss: 1.000049]\n",
      "epoch:0 step:500[D loss: 0.999984] [G loss: 1.000063]\n",
      "epoch:0 step:505[D loss: 0.999983] [G loss: 1.000058]\n",
      "epoch:0 step:510[D loss: 0.999981] [G loss: 1.000049]\n",
      "epoch:0 step:515[D loss: 0.999977] [G loss: 1.000053]\n",
      "epoch:0 step:520[D loss: 0.999978] [G loss: 1.000053]\n",
      "epoch:0 step:525[D loss: 0.999978] [G loss: 1.000055]\n",
      "epoch:0 step:530[D loss: 0.999986] [G loss: 1.000051]\n",
      "epoch:0 step:535[D loss: 0.999981] [G loss: 1.000048]\n",
      "epoch:0 step:540[D loss: 0.999978] [G loss: 1.000045]\n",
      "epoch:0 step:545[D loss: 0.999983] [G loss: 1.000052]\n",
      "epoch:0 step:550[D loss: 0.999978] [G loss: 1.000044]\n",
      "epoch:0 step:555[D loss: 0.999986] [G loss: 1.000037]\n",
      "epoch:0 step:560[D loss: 0.999977] [G loss: 1.000052]\n",
      "epoch:0 step:565[D loss: 0.999977] [G loss: 1.000052]\n",
      "epoch:0 step:570[D loss: 0.999972] [G loss: 1.000050]\n",
      "epoch:0 step:575[D loss: 0.999976] [G loss: 1.000052]\n",
      "epoch:0 step:580[D loss: 0.999973] [G loss: 1.000055]\n",
      "epoch:0 step:585[D loss: 0.999976] [G loss: 1.000049]\n",
      "epoch:0 step:590[D loss: 0.999979] [G loss: 1.000054]\n",
      "epoch:0 step:595[D loss: 0.999973] [G loss: 1.000065]\n",
      "epoch:0 step:600[D loss: 0.999977] [G loss: 1.000062]\n",
      "##############\n",
      "[0.85249033 0.85572115 0.83708465 0.84751519 0.81302078 0.8242231\n",
      " 0.87585492 0.85425151 0.81791436 0.83990251]\n",
      "##########\n",
      "epoch:0 step:605[D loss: 0.999980] [G loss: 1.000066]\n",
      "epoch:0 step:610[D loss: 0.999980] [G loss: 1.000063]\n",
      "epoch:0 step:615[D loss: 0.999974] [G loss: 1.000070]\n",
      "epoch:0 step:620[D loss: 0.999978] [G loss: 1.000063]\n",
      "epoch:0 step:625[D loss: 0.999974] [G loss: 1.000067]\n",
      "epoch:0 step:630[D loss: 0.999978] [G loss: 1.000072]\n",
      "epoch:0 step:635[D loss: 0.999970] [G loss: 1.000078]\n",
      "epoch:0 step:640[D loss: 0.999967] [G loss: 1.000072]\n",
      "epoch:0 step:645[D loss: 0.999977] [G loss: 1.000075]\n",
      "epoch:0 step:650[D loss: 0.999978] [G loss: 1.000066]\n",
      "epoch:0 step:655[D loss: 0.999981] [G loss: 1.000071]\n",
      "epoch:0 step:660[D loss: 0.999974] [G loss: 1.000077]\n",
      "epoch:0 step:665[D loss: 0.999973] [G loss: 1.000076]\n",
      "epoch:0 step:670[D loss: 0.999973] [G loss: 1.000073]\n",
      "epoch:0 step:675[D loss: 0.999977] [G loss: 1.000068]\n",
      "epoch:0 step:680[D loss: 0.999972] [G loss: 1.000078]\n",
      "epoch:0 step:685[D loss: 0.999971] [G loss: 1.000084]\n",
      "epoch:0 step:690[D loss: 0.999980] [G loss: 1.000077]\n",
      "epoch:0 step:695[D loss: 0.999975] [G loss: 1.000075]\n",
      "epoch:0 step:700[D loss: 0.999972] [G loss: 1.000083]\n",
      "epoch:0 step:705[D loss: 0.999970] [G loss: 1.000075]\n",
      "epoch:0 step:710[D loss: 0.999977] [G loss: 1.000070]\n",
      "epoch:0 step:715[D loss: 0.999970] [G loss: 1.000073]\n",
      "epoch:0 step:720[D loss: 0.999976] [G loss: 1.000069]\n",
      "epoch:0 step:725[D loss: 0.999970] [G loss: 1.000075]\n",
      "epoch:0 step:730[D loss: 0.999979] [G loss: 1.000072]\n",
      "epoch:0 step:735[D loss: 0.999971] [G loss: 1.000078]\n",
      "epoch:0 step:740[D loss: 0.999974] [G loss: 1.000073]\n",
      "epoch:0 step:745[D loss: 0.999975] [G loss: 1.000076]\n",
      "epoch:0 step:750[D loss: 0.999969] [G loss: 1.000073]\n",
      "epoch:0 step:755[D loss: 0.999970] [G loss: 1.000077]\n",
      "epoch:0 step:760[D loss: 0.999972] [G loss: 1.000073]\n",
      "epoch:0 step:765[D loss: 0.999971] [G loss: 1.000065]\n",
      "epoch:0 step:770[D loss: 0.999970] [G loss: 1.000067]\n",
      "epoch:0 step:775[D loss: 0.999972] [G loss: 1.000067]\n",
      "epoch:0 step:780[D loss: 0.999973] [G loss: 1.000074]\n",
      "epoch:0 step:785[D loss: 0.999977] [G loss: 1.000063]\n",
      "epoch:0 step:790[D loss: 0.999972] [G loss: 1.000065]\n",
      "epoch:0 step:795[D loss: 0.999975] [G loss: 1.000069]\n",
      "epoch:0 step:800[D loss: 0.999976] [G loss: 1.000061]\n",
      "##############\n",
      "[0.86561443 0.87090437 0.82375342 0.82942851 0.82792756 0.83468509\n",
      " 0.86693932 0.83929656 0.83782842 0.82565356]\n",
      "##########\n",
      "epoch:0 step:805[D loss: 0.999971] [G loss: 1.000066]\n",
      "epoch:0 step:810[D loss: 0.999975] [G loss: 1.000063]\n",
      "epoch:0 step:815[D loss: 0.999977] [G loss: 1.000067]\n",
      "epoch:0 step:820[D loss: 0.999972] [G loss: 1.000060]\n",
      "epoch:0 step:825[D loss: 0.999973] [G loss: 1.000066]\n",
      "epoch:0 step:830[D loss: 0.999971] [G loss: 1.000070]\n",
      "epoch:0 step:835[D loss: 0.999976] [G loss: 1.000060]\n",
      "epoch:0 step:840[D loss: 0.999970] [G loss: 1.000055]\n",
      "epoch:0 step:845[D loss: 0.999971] [G loss: 1.000068]\n",
      "epoch:0 step:850[D loss: 0.999977] [G loss: 1.000070]\n",
      "epoch:0 step:855[D loss: 0.999977] [G loss: 1.000064]\n",
      "epoch:0 step:860[D loss: 0.999969] [G loss: 1.000074]\n",
      "epoch:0 step:865[D loss: 0.999972] [G loss: 1.000069]\n",
      "epoch:0 step:870[D loss: 0.999974] [G loss: 1.000065]\n",
      "epoch:0 step:875[D loss: 0.999973] [G loss: 1.000058]\n",
      "epoch:0 step:880[D loss: 0.999975] [G loss: 1.000062]\n",
      "epoch:0 step:885[D loss: 0.999971] [G loss: 1.000060]\n",
      "epoch:0 step:890[D loss: 0.999972] [G loss: 1.000069]\n",
      "epoch:0 step:895[D loss: 0.999969] [G loss: 1.000056]\n",
      "epoch:0 step:900[D loss: 0.999973] [G loss: 1.000056]\n",
      "epoch:0 step:905[D loss: 0.999973] [G loss: 1.000060]\n",
      "epoch:0 step:910[D loss: 0.999972] [G loss: 1.000057]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0 step:915[D loss: 0.999976] [G loss: 1.000051]\n",
      "epoch:0 step:920[D loss: 0.999969] [G loss: 1.000059]\n",
      "epoch:0 step:925[D loss: 0.999972] [G loss: 1.000050]\n",
      "epoch:0 step:930[D loss: 0.999971] [G loss: 1.000060]\n",
      "epoch:0 step:935[D loss: 0.999972] [G loss: 1.000062]\n",
      "epoch:0 step:940[D loss: 0.999973] [G loss: 1.000053]\n",
      "epoch:0 step:945[D loss: 0.999973] [G loss: 1.000055]\n",
      "epoch:0 step:950[D loss: 0.999972] [G loss: 1.000056]\n",
      "epoch:0 step:955[D loss: 0.999972] [G loss: 1.000057]\n",
      "epoch:0 step:960[D loss: 0.999972] [G loss: 1.000059]\n",
      "epoch:0 step:965[D loss: 0.999974] [G loss: 1.000056]\n",
      "epoch:0 step:970[D loss: 0.999972] [G loss: 1.000054]\n",
      "epoch:0 step:975[D loss: 0.999972] [G loss: 1.000054]\n",
      "epoch:0 step:980[D loss: 0.999972] [G loss: 1.000053]\n",
      "epoch:0 step:985[D loss: 0.999975] [G loss: 1.000054]\n",
      "epoch:0 step:990[D loss: 0.999973] [G loss: 1.000047]\n",
      "epoch:0 step:995[D loss: 0.999971] [G loss: 1.000053]\n",
      "epoch:0 step:1000[D loss: 0.999971] [G loss: 1.000059]\n",
      "##############\n",
      "[0.8751581  0.88044875 0.81849718 0.82674367 0.80990396 0.83679607\n",
      " 0.88067966 0.83667637 0.83188216 0.85504126]\n",
      "##########\n",
      "epoch:0 step:1005[D loss: 0.999979] [G loss: 1.000053]\n",
      "epoch:0 step:1010[D loss: 0.999973] [G loss: 1.000060]\n",
      "epoch:0 step:1015[D loss: 0.999976] [G loss: 1.000057]\n",
      "epoch:0 step:1020[D loss: 0.999974] [G loss: 1.000055]\n",
      "epoch:0 step:1025[D loss: 0.999971] [G loss: 1.000057]\n",
      "epoch:0 step:1030[D loss: 0.999975] [G loss: 1.000060]\n",
      "epoch:0 step:1035[D loss: 0.999972] [G loss: 1.000062]\n",
      "epoch:0 step:1040[D loss: 0.999974] [G loss: 1.000055]\n",
      "epoch:0 step:1045[D loss: 0.999975] [G loss: 1.000046]\n",
      "epoch:0 step:1050[D loss: 0.999974] [G loss: 1.000053]\n",
      "epoch:0 step:1055[D loss: 0.999975] [G loss: 1.000053]\n",
      "epoch:0 step:1060[D loss: 0.999976] [G loss: 1.000053]\n",
      "epoch:0 step:1065[D loss: 0.999978] [G loss: 1.000042]\n",
      "epoch:0 step:1070[D loss: 0.999972] [G loss: 1.000045]\n",
      "epoch:0 step:1075[D loss: 0.999971] [G loss: 1.000062]\n",
      "epoch:0 step:1080[D loss: 0.999975] [G loss: 1.000049]\n",
      "epoch:0 step:1085[D loss: 0.999974] [G loss: 1.000050]\n",
      "epoch:0 step:1090[D loss: 0.999970] [G loss: 1.000050]\n",
      "epoch:0 step:1095[D loss: 0.999977] [G loss: 1.000045]\n",
      "epoch:0 step:1100[D loss: 0.999969] [G loss: 1.000052]\n",
      "epoch:0 step:1105[D loss: 0.999972] [G loss: 1.000050]\n",
      "epoch:0 step:1110[D loss: 0.999972] [G loss: 1.000050]\n",
      "epoch:0 step:1115[D loss: 0.999975] [G loss: 1.000047]\n",
      "epoch:0 step:1120[D loss: 0.999974] [G loss: 1.000056]\n",
      "epoch:0 step:1125[D loss: 0.999971] [G loss: 1.000057]\n",
      "epoch:0 step:1130[D loss: 0.999972] [G loss: 1.000057]\n",
      "epoch:0 step:1135[D loss: 0.999973] [G loss: 1.000054]\n",
      "epoch:0 step:1140[D loss: 0.999974] [G loss: 1.000050]\n",
      "epoch:0 step:1145[D loss: 0.999969] [G loss: 1.000051]\n",
      "epoch:0 step:1150[D loss: 0.999972] [G loss: 1.000057]\n",
      "epoch:0 step:1155[D loss: 0.999970] [G loss: 1.000060]\n",
      "epoch:0 step:1160[D loss: 0.999976] [G loss: 1.000062]\n",
      "epoch:0 step:1165[D loss: 0.999970] [G loss: 1.000064]\n",
      "epoch:0 step:1170[D loss: 0.999971] [G loss: 1.000062]\n",
      "epoch:0 step:1175[D loss: 0.999971] [G loss: 1.000061]\n",
      "epoch:0 step:1180[D loss: 0.999973] [G loss: 1.000061]\n",
      "epoch:0 step:1185[D loss: 0.999972] [G loss: 1.000058]\n",
      "epoch:0 step:1190[D loss: 0.999971] [G loss: 1.000059]\n",
      "epoch:0 step:1195[D loss: 0.999966] [G loss: 1.000060]\n",
      "epoch:0 step:1200[D loss: 0.999972] [G loss: 1.000056]\n",
      "##############\n",
      "[0.85032334 0.84948065 0.81028682 0.84393242 0.81139471 0.83736304\n",
      " 0.86208965 0.83844305 0.8411789  0.8334406 ]\n",
      "##########\n",
      "epoch:0 step:1205[D loss: 0.999966] [G loss: 1.000060]\n",
      "epoch:0 step:1210[D loss: 0.999972] [G loss: 1.000063]\n",
      "epoch:0 step:1215[D loss: 0.999980] [G loss: 1.000062]\n",
      "epoch:0 step:1220[D loss: 0.999977] [G loss: 1.000054]\n",
      "epoch:0 step:1225[D loss: 0.999976] [G loss: 1.000058]\n",
      "epoch:0 step:1230[D loss: 0.999973] [G loss: 1.000058]\n",
      "epoch:0 step:1235[D loss: 0.999973] [G loss: 1.000060]\n",
      "epoch:0 step:1240[D loss: 0.999977] [G loss: 1.000061]\n",
      "epoch:0 step:1245[D loss: 0.999975] [G loss: 1.000059]\n",
      "epoch:0 step:1250[D loss: 0.999975] [G loss: 1.000056]\n",
      "epoch:0 step:1255[D loss: 0.999972] [G loss: 1.000058]\n",
      "epoch:0 step:1260[D loss: 0.999973] [G loss: 1.000062]\n",
      "epoch:0 step:1265[D loss: 0.999974] [G loss: 1.000060]\n",
      "epoch:0 step:1270[D loss: 0.999970] [G loss: 1.000059]\n",
      "epoch:0 step:1275[D loss: 0.999973] [G loss: 1.000070]\n",
      "epoch:0 step:1280[D loss: 0.999971] [G loss: 1.000061]\n",
      "epoch:0 step:1285[D loss: 0.999971] [G loss: 1.000062]\n",
      "epoch:0 step:1290[D loss: 0.999974] [G loss: 1.000060]\n",
      "epoch:0 step:1295[D loss: 0.999971] [G loss: 1.000064]\n",
      "epoch:0 step:1300[D loss: 0.999975] [G loss: 1.000065]\n",
      "epoch:0 step:1305[D loss: 0.999972] [G loss: 1.000062]\n",
      "epoch:0 step:1310[D loss: 0.999974] [G loss: 1.000060]\n",
      "epoch:0 step:1315[D loss: 0.999974] [G loss: 1.000053]\n",
      "epoch:0 step:1320[D loss: 0.999970] [G loss: 1.000058]\n",
      "epoch:0 step:1325[D loss: 0.999974] [G loss: 1.000057]\n",
      "epoch:0 step:1330[D loss: 0.999978] [G loss: 1.000056]\n",
      "epoch:0 step:1335[D loss: 0.999972] [G loss: 1.000058]\n",
      "epoch:0 step:1340[D loss: 0.999972] [G loss: 1.000058]\n",
      "epoch:0 step:1345[D loss: 0.999975] [G loss: 1.000050]\n",
      "epoch:0 step:1350[D loss: 0.999975] [G loss: 1.000059]\n",
      "epoch:0 step:1355[D loss: 0.999970] [G loss: 1.000058]\n",
      "epoch:0 step:1360[D loss: 0.999974] [G loss: 1.000068]\n",
      "epoch:0 step:1365[D loss: 0.999972] [G loss: 1.000065]\n",
      "epoch:0 step:1370[D loss: 0.999976] [G loss: 1.000069]\n",
      "epoch:0 step:1375[D loss: 0.999973] [G loss: 1.000067]\n",
      "epoch:0 step:1380[D loss: 0.999972] [G loss: 1.000060]\n",
      "epoch:0 step:1385[D loss: 0.999975] [G loss: 1.000056]\n",
      "epoch:0 step:1390[D loss: 0.999969] [G loss: 1.000063]\n",
      "epoch:0 step:1395[D loss: 0.999970] [G loss: 1.000066]\n",
      "epoch:0 step:1400[D loss: 0.999968] [G loss: 1.000064]\n",
      "##############\n",
      "[0.88126203 0.83969279 0.81447673 0.85184656 0.8041558  0.81171341\n",
      " 0.84326605 0.86364246 0.81901951 0.84227485]\n",
      "##########\n",
      "epoch:0 step:1405[D loss: 0.999975] [G loss: 1.000067]\n",
      "epoch:0 step:1410[D loss: 0.999972] [G loss: 1.000071]\n",
      "epoch:0 step:1415[D loss: 0.999969] [G loss: 1.000063]\n",
      "epoch:0 step:1420[D loss: 0.999970] [G loss: 1.000069]\n",
      "epoch:0 step:1425[D loss: 0.999968] [G loss: 1.000061]\n",
      "epoch:0 step:1430[D loss: 0.999973] [G loss: 1.000065]\n",
      "epoch:0 step:1435[D loss: 0.999975] [G loss: 1.000065]\n",
      "epoch:0 step:1440[D loss: 0.999971] [G loss: 1.000064]\n",
      "epoch:0 step:1445[D loss: 0.999976] [G loss: 1.000066]\n",
      "epoch:0 step:1450[D loss: 0.999970] [G loss: 1.000062]\n",
      "epoch:0 step:1455[D loss: 0.999974] [G loss: 1.000059]\n",
      "epoch:0 step:1460[D loss: 0.999973] [G loss: 1.000062]\n",
      "epoch:0 step:1465[D loss: 0.999972] [G loss: 1.000068]\n",
      "epoch:0 step:1470[D loss: 0.999974] [G loss: 1.000070]\n",
      "epoch:0 step:1475[D loss: 0.999974] [G loss: 1.000067]\n",
      "epoch:0 step:1480[D loss: 0.999975] [G loss: 1.000063]\n",
      "epoch:0 step:1485[D loss: 0.999971] [G loss: 1.000073]\n",
      "epoch:0 step:1490[D loss: 0.999971] [G loss: 1.000070]\n",
      "epoch:0 step:1495[D loss: 0.999970] [G loss: 1.000068]\n",
      "epoch:0 step:1500[D loss: 0.999973] [G loss: 1.000068]\n",
      "epoch:0 step:1505[D loss: 0.999970] [G loss: 1.000069]\n",
      "epoch:0 step:1510[D loss: 0.999969] [G loss: 1.000070]\n",
      "epoch:0 step:1515[D loss: 0.999970] [G loss: 1.000070]\n",
      "epoch:0 step:1520[D loss: 0.999973] [G loss: 1.000070]\n",
      "epoch:0 step:1525[D loss: 0.999971] [G loss: 1.000065]\n",
      "epoch:0 step:1530[D loss: 0.999972] [G loss: 1.000067]\n",
      "epoch:0 step:1535[D loss: 0.999970] [G loss: 1.000065]\n",
      "epoch:0 step:1540[D loss: 0.999973] [G loss: 1.000068]\n",
      "epoch:0 step:1545[D loss: 0.999973] [G loss: 1.000067]\n",
      "epoch:0 step:1550[D loss: 0.999973] [G loss: 1.000063]\n",
      "epoch:0 step:1555[D loss: 0.999972] [G loss: 1.000069]\n",
      "epoch:0 step:1560[D loss: 0.999970] [G loss: 1.000066]\n",
      "epoch:0 step:1565[D loss: 0.999971] [G loss: 1.000065]\n",
      "epoch:0 step:1570[D loss: 0.999969] [G loss: 1.000060]\n",
      "epoch:0 step:1575[D loss: 0.999970] [G loss: 1.000059]\n",
      "epoch:0 step:1580[D loss: 0.999975] [G loss: 1.000065]\n",
      "epoch:0 step:1585[D loss: 0.999971] [G loss: 1.000065]\n",
      "epoch:0 step:1590[D loss: 0.999970] [G loss: 1.000062]\n",
      "epoch:0 step:1595[D loss: 0.999975] [G loss: 1.000064]\n",
      "epoch:0 step:1600[D loss: 0.999971] [G loss: 1.000066]\n",
      "##############\n",
      "[0.88672843 0.85607484 0.82384155 0.8458781  0.81805793 0.81993915\n",
      " 0.84823185 0.85312332 0.81851069 0.84036799]\n",
      "##########\n",
      "epoch:0 step:1605[D loss: 0.999974] [G loss: 1.000065]\n",
      "epoch:0 step:1610[D loss: 0.999972] [G loss: 1.000063]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0 step:1615[D loss: 0.999972] [G loss: 1.000063]\n",
      "epoch:0 step:1620[D loss: 0.999973] [G loss: 1.000066]\n",
      "epoch:0 step:1625[D loss: 0.999970] [G loss: 1.000067]\n",
      "epoch:0 step:1630[D loss: 0.999975] [G loss: 1.000063]\n",
      "epoch:0 step:1635[D loss: 0.999972] [G loss: 1.000066]\n",
      "epoch:0 step:1640[D loss: 0.999974] [G loss: 1.000065]\n",
      "epoch:0 step:1645[D loss: 0.999974] [G loss: 1.000065]\n",
      "epoch:0 step:1650[D loss: 0.999973] [G loss: 1.000069]\n",
      "epoch:0 step:1655[D loss: 0.999973] [G loss: 1.000066]\n",
      "epoch:0 step:1660[D loss: 0.999967] [G loss: 1.000077]\n",
      "epoch:0 step:1665[D loss: 0.999970] [G loss: 1.000071]\n",
      "epoch:0 step:1670[D loss: 0.999974] [G loss: 1.000070]\n",
      "epoch:0 step:1675[D loss: 0.999975] [G loss: 1.000071]\n",
      "epoch:0 step:1680[D loss: 0.999975] [G loss: 1.000064]\n",
      "epoch:0 step:1685[D loss: 0.999973] [G loss: 1.000060]\n",
      "epoch:0 step:1690[D loss: 0.999973] [G loss: 1.000066]\n",
      "epoch:0 step:1695[D loss: 0.999970] [G loss: 1.000061]\n",
      "epoch:0 step:1700[D loss: 0.999971] [G loss: 1.000066]\n",
      "epoch:0 step:1705[D loss: 0.999972] [G loss: 1.000062]\n",
      "epoch:0 step:1710[D loss: 0.999969] [G loss: 1.000067]\n",
      "epoch:0 step:1715[D loss: 0.999972] [G loss: 1.000063]\n",
      "epoch:0 step:1720[D loss: 0.999975] [G loss: 1.000065]\n",
      "epoch:0 step:1725[D loss: 0.999974] [G loss: 1.000064]\n",
      "epoch:0 step:1730[D loss: 0.999970] [G loss: 1.000064]\n",
      "epoch:0 step:1735[D loss: 0.999972] [G loss: 1.000064]\n",
      "epoch:0 step:1740[D loss: 0.999972] [G loss: 1.000064]\n",
      "epoch:0 step:1745[D loss: 0.999970] [G loss: 1.000066]\n",
      "epoch:0 step:1750[D loss: 0.999973] [G loss: 1.000060]\n",
      "epoch:0 step:1755[D loss: 0.999975] [G loss: 1.000055]\n",
      "epoch:0 step:1760[D loss: 0.999973] [G loss: 1.000058]\n",
      "epoch:0 step:1765[D loss: 0.999971] [G loss: 1.000059]\n",
      "epoch:0 step:1770[D loss: 0.999975] [G loss: 1.000059]\n",
      "epoch:0 step:1775[D loss: 0.999971] [G loss: 1.000063]\n",
      "epoch:0 step:1780[D loss: 0.999972] [G loss: 1.000063]\n",
      "epoch:0 step:1785[D loss: 0.999972] [G loss: 1.000052]\n",
      "epoch:0 step:1790[D loss: 0.999971] [G loss: 1.000060]\n",
      "epoch:0 step:1795[D loss: 0.999976] [G loss: 1.000051]\n",
      "epoch:0 step:1800[D loss: 0.999969] [G loss: 1.000059]\n",
      "##############\n",
      "[0.85930408 0.85520584 0.82413051 0.84570743 0.78189254 0.83563286\n",
      " 0.85515754 0.82991215 0.85578212 0.80603188]\n",
      "##########\n",
      "epoch:0 step:1805[D loss: 0.999974] [G loss: 1.000067]\n",
      "epoch:0 step:1810[D loss: 0.999971] [G loss: 1.000067]\n",
      "epoch:0 step:1815[D loss: 0.999972] [G loss: 1.000062]\n",
      "epoch:0 step:1820[D loss: 0.999976] [G loss: 1.000054]\n",
      "epoch:0 step:1825[D loss: 0.999969] [G loss: 1.000060]\n",
      "epoch:0 step:1830[D loss: 0.999973] [G loss: 1.000064]\n",
      "epoch:0 step:1835[D loss: 0.999971] [G loss: 1.000062]\n",
      "epoch:0 step:1840[D loss: 0.999971] [G loss: 1.000064]\n",
      "epoch:0 step:1845[D loss: 0.999975] [G loss: 1.000066]\n",
      "epoch:0 step:1850[D loss: 0.999972] [G loss: 1.000065]\n",
      "epoch:0 step:1855[D loss: 0.999965] [G loss: 1.000071]\n",
      "epoch:0 step:1860[D loss: 0.999972] [G loss: 1.000060]\n",
      "epoch:0 step:1865[D loss: 0.999972] [G loss: 1.000068]\n",
      "epoch:0 step:1870[D loss: 0.999973] [G loss: 1.000063]\n",
      "epoch:0 step:1875[D loss: 0.999971] [G loss: 1.000072]\n",
      "epoch:0 step:1880[D loss: 0.999977] [G loss: 1.000065]\n",
      "epoch:0 step:1885[D loss: 0.999969] [G loss: 1.000063]\n",
      "epoch:0 step:1890[D loss: 0.999971] [G loss: 1.000064]\n",
      "epoch:0 step:1895[D loss: 0.999972] [G loss: 1.000067]\n",
      "epoch:0 step:1900[D loss: 0.999969] [G loss: 1.000069]\n",
      "epoch:0 step:1905[D loss: 0.999970] [G loss: 1.000063]\n",
      "epoch:0 step:1910[D loss: 0.999971] [G loss: 1.000067]\n",
      "epoch:0 step:1915[D loss: 0.999974] [G loss: 1.000062]\n",
      "epoch:0 step:1920[D loss: 0.999977] [G loss: 1.000068]\n",
      "epoch:0 step:1925[D loss: 0.999970] [G loss: 1.000068]\n",
      "epoch:0 step:1930[D loss: 0.999973] [G loss: 1.000066]\n",
      "epoch:0 step:1935[D loss: 0.999972] [G loss: 1.000063]\n",
      "epoch:0 step:1940[D loss: 0.999972] [G loss: 1.000067]\n",
      "epoch:0 step:1945[D loss: 0.999974] [G loss: 1.000069]\n",
      "epoch:0 step:1950[D loss: 0.999975] [G loss: 1.000068]\n",
      "epoch:0 step:1955[D loss: 0.999969] [G loss: 1.000067]\n",
      "epoch:0 step:1960[D loss: 0.999970] [G loss: 1.000070]\n",
      "epoch:0 step:1965[D loss: 0.999968] [G loss: 1.000063]\n",
      "epoch:0 step:1970[D loss: 0.999973] [G loss: 1.000069]\n",
      "epoch:0 step:1975[D loss: 0.999972] [G loss: 1.000065]\n",
      "epoch:0 step:1980[D loss: 0.999970] [G loss: 1.000071]\n",
      "epoch:0 step:1985[D loss: 0.999974] [G loss: 1.000062]\n",
      "epoch:0 step:1990[D loss: 0.999975] [G loss: 1.000063]\n",
      "epoch:0 step:1995[D loss: 0.999974] [G loss: 1.000068]\n",
      "epoch:0 step:2000[D loss: 0.999975] [G loss: 1.000067]\n",
      "##############\n",
      "[0.86793622 0.83126588 0.82815497 0.82443641 0.81512896 0.81773659\n",
      " 0.84750816 0.8384434  0.82146467 0.84885794]\n",
      "##########\n",
      "epoch:0 step:2005[D loss: 0.999973] [G loss: 1.000069]\n",
      "epoch:0 step:2010[D loss: 0.999969] [G loss: 1.000056]\n",
      "epoch:0 step:2015[D loss: 0.999971] [G loss: 1.000068]\n",
      "epoch:0 step:2020[D loss: 0.999968] [G loss: 1.000060]\n",
      "epoch:0 step:2025[D loss: 0.999970] [G loss: 1.000064]\n",
      "epoch:0 step:2030[D loss: 0.999974] [G loss: 1.000065]\n",
      "epoch:0 step:2035[D loss: 0.999971] [G loss: 1.000053]\n",
      "epoch:0 step:2040[D loss: 0.999972] [G loss: 1.000058]\n",
      "epoch:0 step:2045[D loss: 0.999970] [G loss: 1.000061]\n",
      "epoch:0 step:2050[D loss: 0.999973] [G loss: 1.000064]\n",
      "epoch:0 step:2055[D loss: 0.999971] [G loss: 1.000064]\n",
      "epoch:0 step:2060[D loss: 0.999974] [G loss: 1.000058]\n",
      "epoch:0 step:2065[D loss: 0.999969] [G loss: 1.000060]\n",
      "epoch:0 step:2070[D loss: 0.999969] [G loss: 1.000064]\n",
      "epoch:0 step:2075[D loss: 0.999973] [G loss: 1.000058]\n",
      "epoch:0 step:2080[D loss: 0.999968] [G loss: 1.000065]\n",
      "epoch:0 step:2085[D loss: 0.999974] [G loss: 1.000064]\n",
      "epoch:0 step:2090[D loss: 0.999972] [G loss: 1.000061]\n",
      "epoch:0 step:2095[D loss: 0.999973] [G loss: 1.000067]\n",
      "epoch:0 step:2100[D loss: 0.999969] [G loss: 1.000070]\n",
      "epoch:0 step:2105[D loss: 0.999976] [G loss: 1.000059]\n",
      "epoch:0 step:2110[D loss: 0.999972] [G loss: 1.000063]\n",
      "epoch:0 step:2115[D loss: 0.999972] [G loss: 1.000066]\n",
      "epoch:0 step:2120[D loss: 0.999972] [G loss: 1.000065]\n",
      "epoch:0 step:2125[D loss: 0.999972] [G loss: 1.000065]\n",
      "epoch:0 step:2130[D loss: 0.999971] [G loss: 1.000068]\n",
      "epoch:0 step:2135[D loss: 0.999977] [G loss: 1.000065]\n",
      "epoch:0 step:2140[D loss: 0.999972] [G loss: 1.000059]\n",
      "epoch:0 step:2145[D loss: 0.999975] [G loss: 1.000065]\n",
      "epoch:0 step:2150[D loss: 0.999971] [G loss: 1.000060]\n",
      "epoch:0 step:2155[D loss: 0.999974] [G loss: 1.000059]\n",
      "epoch:0 step:2160[D loss: 0.999976] [G loss: 1.000067]\n",
      "epoch:0 step:2165[D loss: 0.999972] [G loss: 1.000059]\n",
      "epoch:0 step:2170[D loss: 0.999972] [G loss: 1.000053]\n",
      "epoch:0 step:2175[D loss: 0.999974] [G loss: 1.000066]\n",
      "epoch:0 step:2180[D loss: 0.999973] [G loss: 1.000059]\n",
      "epoch:0 step:2185[D loss: 0.999973] [G loss: 1.000063]\n",
      "epoch:0 step:2190[D loss: 0.999969] [G loss: 1.000064]\n",
      "epoch:0 step:2195[D loss: 0.999971] [G loss: 1.000055]\n",
      "epoch:0 step:2200[D loss: 0.999978] [G loss: 1.000050]\n",
      "##############\n",
      "[0.86663806 0.85591542 0.8459828  0.84300936 0.79856569 0.84536018\n",
      " 0.86270901 0.84920609 0.83191192 0.83064137]\n",
      "##########\n",
      "epoch:0 step:2205[D loss: 0.999978] [G loss: 1.000057]\n",
      "epoch:0 step:2210[D loss: 0.999970] [G loss: 1.000054]\n",
      "epoch:0 step:2215[D loss: 0.999973] [G loss: 1.000060]\n",
      "epoch:0 step:2220[D loss: 0.999974] [G loss: 1.000060]\n",
      "epoch:0 step:2225[D loss: 0.999972] [G loss: 1.000062]\n",
      "epoch:0 step:2230[D loss: 0.999972] [G loss: 1.000062]\n",
      "epoch:0 step:2235[D loss: 0.999972] [G loss: 1.000060]\n",
      "epoch:0 step:2240[D loss: 0.999974] [G loss: 1.000060]\n",
      "epoch:0 step:2245[D loss: 0.999974] [G loss: 1.000057]\n",
      "epoch:0 step:2250[D loss: 0.999972] [G loss: 1.000058]\n",
      "epoch:0 step:2255[D loss: 0.999974] [G loss: 1.000059]\n",
      "epoch:0 step:2260[D loss: 0.999977] [G loss: 1.000054]\n",
      "epoch:0 step:2265[D loss: 0.999974] [G loss: 1.000058]\n",
      "epoch:0 step:2270[D loss: 0.999976] [G loss: 1.000060]\n",
      "epoch:0 step:2275[D loss: 0.999975] [G loss: 1.000064]\n",
      "epoch:0 step:2280[D loss: 0.999979] [G loss: 1.000059]\n",
      "epoch:0 step:2285[D loss: 0.999975] [G loss: 1.000063]\n",
      "epoch:0 step:2290[D loss: 0.999976] [G loss: 1.000053]\n",
      "epoch:0 step:2295[D loss: 0.999976] [G loss: 1.000057]\n",
      "epoch:0 step:2300[D loss: 0.999974] [G loss: 1.000053]\n",
      "epoch:0 step:2305[D loss: 0.999973] [G loss: 1.000057]\n",
      "epoch:0 step:2310[D loss: 0.999971] [G loss: 1.000068]\n",
      "epoch:0 step:2315[D loss: 0.999975] [G loss: 1.000062]\n",
      "epoch:0 step:2320[D loss: 0.999978] [G loss: 1.000065]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0 step:2325[D loss: 0.999975] [G loss: 1.000067]\n",
      "epoch:0 step:2330[D loss: 0.999974] [G loss: 1.000059]\n",
      "epoch:0 step:2335[D loss: 0.999966] [G loss: 1.000072]\n",
      "epoch:0 step:2340[D loss: 0.999971] [G loss: 1.000068]\n",
      "epoch:0 step:2345[D loss: 0.999970] [G loss: 1.000068]\n",
      "epoch:0 step:2350[D loss: 0.999974] [G loss: 1.000068]\n",
      "epoch:0 step:2355[D loss: 0.999973] [G loss: 1.000068]\n",
      "epoch:0 step:2360[D loss: 0.999971] [G loss: 1.000066]\n",
      "epoch:0 step:2365[D loss: 0.999970] [G loss: 1.000064]\n",
      "epoch:0 step:2370[D loss: 0.999969] [G loss: 1.000068]\n",
      "epoch:0 step:2375[D loss: 0.999971] [G loss: 1.000064]\n",
      "epoch:0 step:2380[D loss: 0.999973] [G loss: 1.000060]\n",
      "epoch:0 step:2385[D loss: 0.999973] [G loss: 1.000061]\n",
      "epoch:0 step:2390[D loss: 0.999973] [G loss: 1.000059]\n",
      "epoch:0 step:2395[D loss: 0.999973] [G loss: 1.000065]\n",
      "epoch:0 step:2400[D loss: 0.999971] [G loss: 1.000063]\n",
      "##############\n",
      "[0.88370612 0.82260418 0.84176739 0.83600283 0.7877557  0.84549793\n",
      " 0.85232361 0.85997201 0.81862821 0.83714106]\n",
      "##########\n",
      "epoch:0 step:2405[D loss: 0.999972] [G loss: 1.000064]\n",
      "epoch:0 step:2410[D loss: 0.999971] [G loss: 1.000063]\n",
      "epoch:0 step:2415[D loss: 0.999973] [G loss: 1.000060]\n",
      "epoch:0 step:2420[D loss: 0.999977] [G loss: 1.000059]\n",
      "epoch:0 step:2425[D loss: 0.999974] [G loss: 1.000058]\n",
      "epoch:0 step:2430[D loss: 0.999973] [G loss: 1.000066]\n",
      "epoch:0 step:2435[D loss: 0.999971] [G loss: 1.000055]\n",
      "epoch:0 step:2440[D loss: 0.999975] [G loss: 1.000059]\n",
      "epoch:0 step:2445[D loss: 0.999972] [G loss: 1.000063]\n",
      "epoch:0 step:2450[D loss: 0.999974] [G loss: 1.000055]\n",
      "epoch:0 step:2455[D loss: 0.999977] [G loss: 1.000058]\n",
      "epoch:0 step:2460[D loss: 0.999977] [G loss: 1.000056]\n",
      "epoch:0 step:2465[D loss: 0.999976] [G loss: 1.000049]\n",
      "epoch:0 step:2470[D loss: 0.999972] [G loss: 1.000056]\n",
      "epoch:0 step:2475[D loss: 0.999977] [G loss: 1.000056]\n",
      "epoch:0 step:2480[D loss: 0.999975] [G loss: 1.000060]\n",
      "epoch:0 step:2485[D loss: 0.999975] [G loss: 1.000057]\n",
      "epoch:0 step:2490[D loss: 0.999974] [G loss: 1.000051]\n",
      "epoch:0 step:2495[D loss: 0.999976] [G loss: 1.000050]\n",
      "epoch:0 step:2500[D loss: 0.999973] [G loss: 1.000052]\n",
      "epoch:0 step:2505[D loss: 0.999974] [G loss: 1.000057]\n",
      "epoch:0 step:2510[D loss: 0.999975] [G loss: 1.000056]\n",
      "epoch:0 step:2515[D loss: 0.999974] [G loss: 1.000047]\n",
      "epoch:0 step:2520[D loss: 0.999977] [G loss: 1.000048]\n",
      "epoch:0 step:2525[D loss: 0.999974] [G loss: 1.000055]\n",
      "epoch:0 step:2530[D loss: 0.999978] [G loss: 1.000058]\n",
      "epoch:0 step:2535[D loss: 0.999974] [G loss: 1.000055]\n",
      "epoch:0 step:2540[D loss: 0.999971] [G loss: 1.000053]\n",
      "epoch:0 step:2545[D loss: 0.999979] [G loss: 1.000058]\n",
      "epoch:0 step:2550[D loss: 0.999972] [G loss: 1.000062]\n",
      "epoch:0 step:2555[D loss: 0.999978] [G loss: 1.000065]\n",
      "epoch:0 step:2560[D loss: 0.999974] [G loss: 1.000065]\n",
      "epoch:0 step:2565[D loss: 0.999976] [G loss: 1.000063]\n",
      "epoch:0 step:2570[D loss: 0.999969] [G loss: 1.000066]\n",
      "epoch:0 step:2575[D loss: 0.999967] [G loss: 1.000063]\n",
      "epoch:0 step:2580[D loss: 0.999973] [G loss: 1.000055]\n",
      "epoch:0 step:2585[D loss: 0.999969] [G loss: 1.000063]\n",
      "epoch:0 step:2590[D loss: 0.999971] [G loss: 1.000063]\n",
      "epoch:0 step:2595[D loss: 0.999976] [G loss: 1.000055]\n",
      "epoch:0 step:2600[D loss: 0.999972] [G loss: 1.000068]\n",
      "##############\n",
      "[0.87438288 0.82139992 0.83903627 0.83386645 0.79877098 0.83694366\n",
      " 0.86202945 0.85789271 0.84268535 0.83622096]\n",
      "##########\n",
      "epoch:0 step:2605[D loss: 0.999974] [G loss: 1.000059]\n",
      "epoch:0 step:2610[D loss: 0.999976] [G loss: 1.000057]\n",
      "epoch:0 step:2615[D loss: 0.999977] [G loss: 1.000056]\n",
      "epoch:0 step:2620[D loss: 0.999976] [G loss: 1.000055]\n",
      "epoch:0 step:2625[D loss: 0.999972] [G loss: 1.000048]\n",
      "epoch:0 step:2630[D loss: 0.999976] [G loss: 1.000053]\n",
      "epoch:0 step:2635[D loss: 0.999978] [G loss: 1.000058]\n",
      "epoch:0 step:2640[D loss: 0.999975] [G loss: 1.000057]\n",
      "epoch:0 step:2645[D loss: 0.999972] [G loss: 1.000052]\n",
      "epoch:0 step:2650[D loss: 0.999978] [G loss: 1.000051]\n",
      "epoch:0 step:2655[D loss: 0.999974] [G loss: 1.000055]\n",
      "epoch:0 step:2660[D loss: 0.999978] [G loss: 1.000052]\n",
      "epoch:0 step:2665[D loss: 0.999978] [G loss: 1.000057]\n",
      "epoch:0 step:2670[D loss: 0.999980] [G loss: 1.000045]\n",
      "epoch:0 step:2675[D loss: 0.999975] [G loss: 1.000054]\n",
      "epoch:0 step:2680[D loss: 0.999978] [G loss: 1.000056]\n",
      "epoch:0 step:2685[D loss: 0.999972] [G loss: 1.000061]\n",
      "epoch:0 step:2690[D loss: 0.999974] [G loss: 1.000060]\n",
      "epoch:0 step:2695[D loss: 0.999975] [G loss: 1.000058]\n",
      "epoch:0 step:2700[D loss: 0.999973] [G loss: 1.000061]\n",
      "epoch:0 step:2705[D loss: 0.999969] [G loss: 1.000060]\n",
      "epoch:0 step:2710[D loss: 0.999971] [G loss: 1.000064]\n",
      "epoch:0 step:2715[D loss: 0.999974] [G loss: 1.000061]\n",
      "epoch:0 step:2720[D loss: 0.999972] [G loss: 1.000057]\n",
      "epoch:0 step:2725[D loss: 0.999972] [G loss: 1.000061]\n",
      "epoch:0 step:2730[D loss: 0.999971] [G loss: 1.000058]\n",
      "epoch:0 step:2735[D loss: 0.999973] [G loss: 1.000061]\n",
      "epoch:0 step:2740[D loss: 0.999974] [G loss: 1.000053]\n",
      "epoch:0 step:2745[D loss: 0.999979] [G loss: 1.000058]\n",
      "epoch:0 step:2750[D loss: 0.999975] [G loss: 1.000047]\n",
      "epoch:0 step:2755[D loss: 0.999978] [G loss: 1.000046]\n",
      "epoch:0 step:2760[D loss: 0.999978] [G loss: 1.000050]\n",
      "epoch:0 step:2765[D loss: 0.999981] [G loss: 1.000047]\n",
      "epoch:0 step:2770[D loss: 0.999978] [G loss: 1.000040]\n",
      "epoch:0 step:2775[D loss: 0.999984] [G loss: 1.000041]\n",
      "epoch:0 step:2780[D loss: 0.999979] [G loss: 1.000046]\n",
      "epoch:0 step:2785[D loss: 0.999976] [G loss: 1.000046]\n",
      "epoch:0 step:2790[D loss: 0.999981] [G loss: 1.000049]\n",
      "epoch:0 step:2795[D loss: 0.999980] [G loss: 1.000054]\n",
      "epoch:0 step:2800[D loss: 0.999977] [G loss: 1.000058]\n",
      "##############\n",
      "[0.85752762 0.83884789 0.80267108 0.83131914 0.8227108  0.84351206\n",
      " 0.85452499 0.84665603 0.84874155 0.84477759]\n",
      "##########\n",
      "epoch:0 step:2805[D loss: 0.999972] [G loss: 1.000063]\n",
      "epoch:0 step:2810[D loss: 0.999976] [G loss: 1.000063]\n",
      "epoch:0 step:2815[D loss: 0.999978] [G loss: 1.000066]\n",
      "epoch:0 step:2820[D loss: 0.999971] [G loss: 1.000069]\n",
      "epoch:0 step:2825[D loss: 0.999975] [G loss: 1.000069]\n",
      "epoch:0 step:2830[D loss: 0.999973] [G loss: 1.000059]\n",
      "epoch:0 step:2835[D loss: 0.999974] [G loss: 1.000061]\n",
      "epoch:0 step:2840[D loss: 0.999973] [G loss: 1.000052]\n",
      "epoch:0 step:2845[D loss: 0.999977] [G loss: 1.000058]\n",
      "epoch:0 step:2850[D loss: 0.999982] [G loss: 1.000041]\n",
      "epoch:0 step:2855[D loss: 0.999980] [G loss: 1.000044]\n",
      "epoch:0 step:2860[D loss: 0.999983] [G loss: 1.000042]\n",
      "epoch:0 step:2865[D loss: 0.999987] [G loss: 1.000031]\n",
      "epoch:0 step:2870[D loss: 0.999984] [G loss: 1.000035]\n",
      "epoch:0 step:2875[D loss: 0.999980] [G loss: 1.000039]\n",
      "epoch:0 step:2880[D loss: 0.999985] [G loss: 1.000042]\n",
      "epoch:0 step:2885[D loss: 0.999986] [G loss: 1.000036]\n",
      "epoch:0 step:2890[D loss: 0.999988] [G loss: 1.000038]\n",
      "epoch:0 step:2895[D loss: 0.999980] [G loss: 1.000042]\n",
      "epoch:0 step:2900[D loss: 0.999984] [G loss: 1.000034]\n",
      "epoch:0 step:2905[D loss: 0.999996] [G loss: 1.000037]\n",
      "epoch:0 step:2910[D loss: 0.999990] [G loss: 1.000028]\n",
      "epoch:0 step:2915[D loss: 0.999991] [G loss: 1.000039]\n",
      "epoch:0 step:2920[D loss: 0.999982] [G loss: 1.000053]\n",
      "epoch:0 step:2925[D loss: 0.999989] [G loss: 1.000053]\n",
      "epoch:0 step:2930[D loss: 0.999986] [G loss: 1.000057]\n",
      "epoch:0 step:2935[D loss: 0.999975] [G loss: 1.000058]\n",
      "epoch:0 step:2940[D loss: 0.999981] [G loss: 1.000052]\n",
      "epoch:0 step:2945[D loss: 0.999977] [G loss: 1.000062]\n",
      "epoch:0 step:2950[D loss: 0.999978] [G loss: 1.000054]\n",
      "epoch:0 step:2955[D loss: 0.999980] [G loss: 1.000053]\n",
      "epoch:0 step:2960[D loss: 0.999979] [G loss: 1.000046]\n",
      "epoch:0 step:2965[D loss: 0.999987] [G loss: 1.000046]\n",
      "epoch:0 step:2970[D loss: 0.999986] [G loss: 1.000044]\n",
      "epoch:0 step:2975[D loss: 0.999987] [G loss: 1.000034]\n",
      "epoch:0 step:2980[D loss: 0.999994] [G loss: 1.000028]\n",
      "epoch:0 step:2985[D loss: 0.999990] [G loss: 1.000041]\n",
      "epoch:0 step:2990[D loss: 0.999997] [G loss: 1.000029]\n",
      "epoch:0 step:2995[D loss: 0.999995] [G loss: 1.000044]\n",
      "epoch:0 step:3000[D loss: 1.000003] [G loss: 1.000060]\n",
      "##############\n",
      "[0.86754431 0.83407509 0.82811365 0.83224153 0.77289703 0.81735396\n",
      " 0.86928983 0.86238519 0.81022986 0.8457191 ]\n",
      "##########\n",
      "epoch:0 step:3005[D loss: 1.000005] [G loss: 1.000064]\n",
      "epoch:0 step:3010[D loss: 1.000014] [G loss: 1.000063]\n",
      "epoch:0 step:3015[D loss: 0.999986] [G loss: 1.000069]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0 step:3020[D loss: 0.999975] [G loss: 1.000073]\n",
      "epoch:0 step:3025[D loss: 0.999971] [G loss: 1.000068]\n",
      "epoch:0 step:3030[D loss: 0.999965] [G loss: 1.000065]\n",
      "epoch:0 step:3035[D loss: 0.999973] [G loss: 1.000068]\n",
      "epoch:0 step:3040[D loss: 0.999967] [G loss: 1.000059]\n",
      "epoch:0 step:3045[D loss: 0.999972] [G loss: 1.000059]\n",
      "epoch:0 step:3050[D loss: 0.999984] [G loss: 1.000043]\n",
      "epoch:0 step:3055[D loss: 0.999986] [G loss: 1.000033]\n",
      "epoch:0 step:3060[D loss: 0.999998] [G loss: 1.000021]\n",
      "epoch:0 step:3065[D loss: 0.999995] [G loss: 1.000008]\n",
      "epoch:0 step:3070[D loss: 0.999990] [G loss: 1.000009]\n",
      "epoch:0 step:3075[D loss: 0.999996] [G loss: 1.000022]\n",
      "epoch:0 step:3080[D loss: 0.999993] [G loss: 1.000020]\n",
      "epoch:0 step:3085[D loss: 0.999997] [G loss: 1.000014]\n",
      "epoch:0 step:3090[D loss: 0.999993] [G loss: 1.000027]\n",
      "epoch:0 step:3095[D loss: 0.999996] [G loss: 1.000018]\n",
      "epoch:0 step:3100[D loss: 0.999997] [G loss: 1.000017]\n",
      "epoch:0 step:3105[D loss: 0.999996] [G loss: 1.000010]\n",
      "epoch:0 step:3110[D loss: 0.999999] [G loss: 1.000024]\n",
      "epoch:0 step:3115[D loss: 0.999988] [G loss: 1.000022]\n",
      "epoch:0 step:3120[D loss: 0.999999] [G loss: 1.000020]\n",
      "epoch:0 step:3125[D loss: 0.999990] [G loss: 1.000024]\n",
      "epoch:0 step:3130[D loss: 0.999990] [G loss: 1.000030]\n",
      "epoch:0 step:3135[D loss: 0.999991] [G loss: 1.000035]\n",
      "epoch:0 step:3140[D loss: 0.999989] [G loss: 1.000043]\n",
      "epoch:0 step:3145[D loss: 0.999989] [G loss: 1.000045]\n",
      "epoch:0 step:3150[D loss: 0.999994] [G loss: 1.000046]\n",
      "epoch:0 step:3155[D loss: 0.999982] [G loss: 1.000048]\n",
      "epoch:0 step:3160[D loss: 0.999990] [G loss: 1.000037]\n",
      "epoch:0 step:3165[D loss: 0.999985] [G loss: 1.000043]\n",
      "epoch:0 step:3170[D loss: 0.999985] [G loss: 1.000035]\n",
      "epoch:0 step:3175[D loss: 0.999989] [G loss: 1.000043]\n",
      "epoch:0 step:3180[D loss: 0.999985] [G loss: 1.000045]\n",
      "epoch:0 step:3185[D loss: 0.999984] [G loss: 1.000052]\n",
      "epoch:0 step:3190[D loss: 0.999981] [G loss: 1.000052]\n",
      "epoch:0 step:3195[D loss: 0.999983] [G loss: 1.000052]\n",
      "epoch:0 step:3200[D loss: 0.999987] [G loss: 1.000047]\n",
      "##############\n",
      "[0.87434782 0.84570882 0.83869881 0.85627738 0.82304808 0.83473566\n",
      " 0.86434531 0.83915131 0.81704973 0.83144651]\n",
      "##########\n",
      "epoch:0 step:3205[D loss: 0.999979] [G loss: 1.000054]\n",
      "epoch:0 step:3210[D loss: 0.999980] [G loss: 1.000052]\n",
      "epoch:0 step:3215[D loss: 0.999985] [G loss: 1.000054]\n",
      "epoch:0 step:3220[D loss: 0.999998] [G loss: 1.000048]\n",
      "epoch:0 step:3225[D loss: 0.999977] [G loss: 1.000057]\n",
      "epoch:0 step:3230[D loss: 0.999985] [G loss: 1.000045]\n",
      "epoch:0 step:3235[D loss: 0.999976] [G loss: 1.000056]\n",
      "epoch:0 step:3240[D loss: 0.999982] [G loss: 1.000044]\n",
      "epoch:0 step:3245[D loss: 0.999984] [G loss: 1.000040]\n",
      "epoch:0 step:3250[D loss: 0.999981] [G loss: 1.000042]\n",
      "epoch:0 step:3255[D loss: 0.999983] [G loss: 1.000027]\n",
      "epoch:0 step:3260[D loss: 0.999991] [G loss: 1.000013]\n",
      "epoch:0 step:3265[D loss: 0.999988] [G loss: 1.000017]\n",
      "epoch:0 step:3270[D loss: 0.999993] [G loss: 1.000007]\n",
      "epoch:0 step:3275[D loss: 0.999997] [G loss: 1.000006]\n",
      "epoch:0 step:3280[D loss: 0.999996] [G loss: 0.999999]\n",
      "epoch:0 step:3285[D loss: 0.999995] [G loss: 1.000011]\n",
      "epoch:0 step:3290[D loss: 1.000002] [G loss: 0.999996]\n",
      "epoch:0 step:3295[D loss: 0.999990] [G loss: 1.000009]\n",
      "epoch:0 step:3300[D loss: 0.999993] [G loss: 1.000013]\n",
      "epoch:0 step:3305[D loss: 0.999992] [G loss: 1.000009]\n",
      "epoch:0 step:3310[D loss: 0.999991] [G loss: 1.000014]\n",
      "epoch:0 step:3315[D loss: 0.999994] [G loss: 1.000020]\n",
      "epoch:0 step:3320[D loss: 0.999983] [G loss: 1.000004]\n",
      "epoch:0 step:3325[D loss: 0.999987] [G loss: 1.000006]\n",
      "epoch:0 step:3330[D loss: 0.999991] [G loss: 1.000002]\n",
      "epoch:0 step:3335[D loss: 0.999989] [G loss: 1.000012]\n",
      "epoch:0 step:3340[D loss: 0.999982] [G loss: 1.000011]\n",
      "epoch:0 step:3345[D loss: 0.999987] [G loss: 1.000014]\n",
      "epoch:0 step:3350[D loss: 0.999982] [G loss: 1.000017]\n",
      "epoch:0 step:3355[D loss: 0.999999] [G loss: 0.999998]\n",
      "epoch:0 step:3360[D loss: 0.999986] [G loss: 1.000002]\n",
      "epoch:0 step:3365[D loss: 0.999993] [G loss: 0.999993]\n",
      "epoch:0 step:3370[D loss: 0.999988] [G loss: 0.999997]\n",
      "epoch:0 step:3375[D loss: 0.999992] [G loss: 0.999986]\n",
      "epoch:0 step:3380[D loss: 1.000010] [G loss: 0.999965]\n",
      "epoch:0 step:3385[D loss: 1.000006] [G loss: 0.999959]\n",
      "epoch:0 step:3390[D loss: 0.999997] [G loss: 0.999981]\n",
      "epoch:0 step:3395[D loss: 0.999990] [G loss: 0.999989]\n",
      "epoch:0 step:3400[D loss: 0.999993] [G loss: 0.999996]\n",
      "##############\n",
      "[0.86890177 0.86792711 0.82211878 0.84576696 0.80552214 0.84942412\n",
      " 0.85358494 0.86561986 0.83701509 0.84116574]\n",
      "##########\n",
      "epoch:0 step:3405[D loss: 0.999986] [G loss: 0.999996]\n",
      "epoch:0 step:3410[D loss: 0.999995] [G loss: 0.999997]\n",
      "epoch:0 step:3415[D loss: 0.999990] [G loss: 1.000001]\n",
      "epoch:0 step:3420[D loss: 0.999986] [G loss: 1.000014]\n",
      "epoch:0 step:3425[D loss: 0.999991] [G loss: 0.999985]\n",
      "epoch:0 step:3430[D loss: 0.999997] [G loss: 0.999994]\n",
      "epoch:0 step:3435[D loss: 0.999992] [G loss: 0.999990]\n",
      "epoch:0 step:3440[D loss: 0.999999] [G loss: 0.999979]\n",
      "epoch:0 step:3445[D loss: 1.000004] [G loss: 0.999957]\n",
      "epoch:0 step:3450[D loss: 1.000019] [G loss: 0.999918]\n",
      "epoch:0 step:3455[D loss: 1.000016] [G loss: 0.999909]\n",
      "epoch:0 step:3460[D loss: 1.000038] [G loss: 0.999904]\n",
      "epoch:0 step:3465[D loss: 1.000031] [G loss: 0.999895]\n",
      "epoch:0 step:3470[D loss: 1.000037] [G loss: 0.999904]\n",
      "epoch:0 step:3475[D loss: 1.000037] [G loss: 0.999913]\n",
      "epoch:0 step:3480[D loss: 1.000022] [G loss: 0.999942]\n",
      "epoch:0 step:3485[D loss: 1.000014] [G loss: 0.999973]\n",
      "epoch:0 step:3490[D loss: 1.000002] [G loss: 0.999968]\n",
      "epoch:0 step:3495[D loss: 1.000014] [G loss: 0.999975]\n",
      "epoch:0 step:3500[D loss: 0.999999] [G loss: 0.999989]\n",
      "epoch:0 step:3505[D loss: 0.999998] [G loss: 0.999988]\n",
      "epoch:0 step:3510[D loss: 1.000005] [G loss: 0.999988]\n",
      "epoch:0 step:3515[D loss: 1.000005] [G loss: 0.999972]\n",
      "epoch:0 step:3520[D loss: 1.000000] [G loss: 0.999962]\n",
      "epoch:0 step:3525[D loss: 1.000012] [G loss: 0.999950]\n",
      "epoch:0 step:3530[D loss: 1.000013] [G loss: 0.999937]\n",
      "epoch:0 step:3535[D loss: 1.000014] [G loss: 0.999937]\n",
      "epoch:0 step:3540[D loss: 1.000000] [G loss: 0.999927]\n",
      "epoch:0 step:3545[D loss: 1.000006] [G loss: 0.999947]\n",
      "epoch:0 step:3550[D loss: 1.000018] [G loss: 0.999943]\n",
      "epoch:0 step:3555[D loss: 1.000011] [G loss: 0.999943]\n",
      "epoch:0 step:3560[D loss: 1.000029] [G loss: 0.999929]\n",
      "epoch:0 step:3565[D loss: 1.000017] [G loss: 0.999931]\n",
      "epoch:0 step:3570[D loss: 1.000034] [G loss: 0.999918]\n",
      "epoch:0 step:3575[D loss: 1.000019] [G loss: 0.999924]\n",
      "epoch:0 step:3580[D loss: 1.000024] [G loss: 0.999934]\n",
      "epoch:0 step:3585[D loss: 1.000039] [G loss: 0.999902]\n",
      "epoch:0 step:3590[D loss: 1.000034] [G loss: 0.999896]\n",
      "epoch:0 step:3595[D loss: 1.000037] [G loss: 0.999883]\n",
      "epoch:0 step:3600[D loss: 1.000046] [G loss: 0.999887]\n",
      "##############\n",
      "[0.88111711 0.84980842 0.82001474 0.85785062 0.78860475 0.84466019\n",
      " 0.85429525 0.86913539 0.83348913 0.83282476]\n",
      "##########\n",
      "epoch:0 step:3605[D loss: 1.000029] [G loss: 0.999889]\n",
      "epoch:0 step:3610[D loss: 1.000038] [G loss: 0.999887]\n",
      "epoch:0 step:3615[D loss: 1.000012] [G loss: 0.999944]\n",
      "epoch:0 step:3620[D loss: 1.000006] [G loss: 0.999973]\n",
      "epoch:0 step:3625[D loss: 1.000003] [G loss: 1.000024]\n",
      "epoch:0 step:3630[D loss: 0.999980] [G loss: 1.000057]\n",
      "epoch:0 step:3635[D loss: 0.999979] [G loss: 1.000028]\n",
      "epoch:0 step:3640[D loss: 0.999985] [G loss: 1.000036]\n",
      "epoch:0 step:3645[D loss: 0.999990] [G loss: 1.000001]\n",
      "epoch:0 step:3650[D loss: 0.999980] [G loss: 1.000003]\n",
      "epoch:0 step:3655[D loss: 1.000013] [G loss: 0.999943]\n",
      "epoch:0 step:3660[D loss: 1.000027] [G loss: 0.999911]\n",
      "epoch:0 step:3665[D loss: 1.000062] [G loss: 0.999867]\n",
      "epoch:0 step:3670[D loss: 1.000042] [G loss: 0.999874]\n",
      "epoch:0 step:3675[D loss: 1.000073] [G loss: 0.999839]\n",
      "epoch:0 step:3680[D loss: 1.000051] [G loss: 0.999872]\n",
      "epoch:0 step:3685[D loss: 1.000067] [G loss: 0.999888]\n",
      "epoch:0 step:3690[D loss: 1.000042] [G loss: 0.999914]\n",
      "epoch:0 step:3695[D loss: 1.000036] [G loss: 0.999940]\n",
      "epoch:0 step:3700[D loss: 1.000028] [G loss: 0.999949]\n",
      "epoch:0 step:3705[D loss: 1.000005] [G loss: 0.999994]\n",
      "epoch:0 step:3710[D loss: 1.000000] [G loss: 1.000024]\n",
      "epoch:0 step:3715[D loss: 0.999993] [G loss: 1.000020]\n",
      "epoch:0 step:3720[D loss: 0.999998] [G loss: 0.999982]\n",
      "epoch:0 step:3725[D loss: 1.000001] [G loss: 0.999958]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0 step:3730[D loss: 1.000023] [G loss: 0.999947]\n",
      "epoch:0 step:3735[D loss: 1.000036] [G loss: 0.999934]\n",
      "epoch:0 step:3740[D loss: 1.000034] [G loss: 0.999890]\n",
      "epoch:0 step:3745[D loss: 1.000044] [G loss: 0.999860]\n",
      "epoch:0 step:3750[D loss: 1.000062] [G loss: 0.999867]\n",
      "epoch:0 step:3755[D loss: 1.000039] [G loss: 0.999887]\n",
      "epoch:0 step:3760[D loss: 1.000054] [G loss: 0.999902]\n",
      "epoch:0 step:3765[D loss: 1.000042] [G loss: 0.999911]\n",
      "epoch:0 step:3770[D loss: 1.000046] [G loss: 0.999919]\n",
      "epoch:0 step:3775[D loss: 1.000036] [G loss: 0.999923]\n",
      "epoch:0 step:3780[D loss: 1.000019] [G loss: 0.999923]\n",
      "epoch:0 step:3785[D loss: 1.000021] [G loss: 0.999928]\n",
      "epoch:0 step:3790[D loss: 1.000038] [G loss: 0.999930]\n",
      "epoch:0 step:3795[D loss: 1.000048] [G loss: 0.999916]\n",
      "epoch:0 step:3800[D loss: 1.000032] [G loss: 0.999916]\n",
      "##############\n",
      "[0.86390519 0.84290387 0.84222959 0.85450739 0.79011187 0.82872535\n",
      " 0.86812368 0.82615109 0.84787078 0.81333787]\n",
      "##########\n",
      "epoch:0 step:3805[D loss: 1.000038] [G loss: 0.999926]\n",
      "epoch:0 step:3810[D loss: 1.000029] [G loss: 0.999924]\n",
      "epoch:0 step:3815[D loss: 1.000037] [G loss: 0.999905]\n",
      "epoch:0 step:3820[D loss: 1.000044] [G loss: 0.999905]\n",
      "epoch:0 step:3825[D loss: 1.000043] [G loss: 0.999895]\n",
      "epoch:0 step:3830[D loss: 1.000064] [G loss: 0.999888]\n",
      "epoch:0 step:3835[D loss: 1.000053] [G loss: 0.999865]\n",
      "epoch:0 step:3840[D loss: 1.000070] [G loss: 0.999870]\n",
      "epoch:0 step:3845[D loss: 1.000063] [G loss: 0.999870]\n",
      "epoch:0 step:3850[D loss: 1.000066] [G loss: 0.999919]\n",
      "epoch:0 step:3855[D loss: 1.000044] [G loss: 0.999936]\n",
      "epoch:0 step:3860[D loss: 1.000040] [G loss: 0.999918]\n",
      "epoch:0 step:3865[D loss: 1.000022] [G loss: 0.999948]\n",
      "epoch:0 step:3870[D loss: 1.000015] [G loss: 0.999944]\n",
      "epoch:0 step:3875[D loss: 1.000009] [G loss: 0.999943]\n",
      "epoch:0 step:3880[D loss: 1.000027] [G loss: 0.999917]\n",
      "epoch:0 step:3885[D loss: 1.000034] [G loss: 0.999878]\n",
      "epoch:0 step:3890[D loss: 1.000076] [G loss: 0.999844]\n",
      "epoch:0 step:3895[D loss: 1.000076] [G loss: 0.999813]\n",
      "epoch:0 step:3900[D loss: 1.000081] [G loss: 0.999801]\n",
      "epoch:0 step:3905[D loss: 1.000107] [G loss: 0.999815]\n",
      "epoch:1 step:3910[D loss: 1.000087] [G loss: 0.999826]\n",
      "epoch:1 step:3915[D loss: 1.000059] [G loss: 0.999834]\n",
      "epoch:1 step:3920[D loss: 1.000036] [G loss: 0.999878]\n",
      "epoch:1 step:3925[D loss: 1.000051] [G loss: 0.999892]\n",
      "epoch:1 step:3930[D loss: 1.000016] [G loss: 0.999919]\n",
      "epoch:1 step:3935[D loss: 1.000025] [G loss: 0.999907]\n",
      "epoch:1 step:3940[D loss: 1.000015] [G loss: 0.999915]\n",
      "epoch:1 step:3945[D loss: 1.000027] [G loss: 0.999915]\n",
      "epoch:1 step:3950[D loss: 1.000029] [G loss: 0.999912]\n",
      "epoch:1 step:3955[D loss: 1.000021] [G loss: 0.999915]\n",
      "epoch:1 step:3960[D loss: 1.000042] [G loss: 0.999916]\n",
      "epoch:1 step:3965[D loss: 1.000044] [G loss: 0.999898]\n",
      "epoch:1 step:3970[D loss: 1.000054] [G loss: 0.999892]\n",
      "epoch:1 step:3975[D loss: 1.000045] [G loss: 0.999892]\n",
      "epoch:1 step:3980[D loss: 1.000050] [G loss: 0.999901]\n",
      "epoch:1 step:3985[D loss: 1.000062] [G loss: 0.999905]\n",
      "epoch:1 step:3990[D loss: 1.000021] [G loss: 0.999905]\n",
      "epoch:1 step:3995[D loss: 1.000044] [G loss: 0.999901]\n",
      "epoch:1 step:4000[D loss: 1.000039] [G loss: 0.999921]\n",
      "##############\n",
      "[0.87223047 0.85528819 0.83078363 0.83234307 0.81611515 0.85061982\n",
      " 0.82360111 0.8356801  0.81506975 0.84578808]\n",
      "##########\n",
      "epoch:1 step:4005[D loss: 1.000051] [G loss: 0.999903]\n",
      "epoch:1 step:4010[D loss: 1.000033] [G loss: 0.999910]\n",
      "epoch:1 step:4015[D loss: 1.000042] [G loss: 0.999881]\n",
      "epoch:1 step:4020[D loss: 1.000034] [G loss: 0.999866]\n",
      "epoch:1 step:4025[D loss: 1.000069] [G loss: 0.999845]\n",
      "epoch:1 step:4030[D loss: 1.000049] [G loss: 0.999835]\n",
      "epoch:1 step:4035[D loss: 1.000061] [G loss: 0.999843]\n",
      "epoch:1 step:4040[D loss: 1.000062] [G loss: 0.999815]\n",
      "epoch:1 step:4045[D loss: 1.000070] [G loss: 0.999837]\n",
      "epoch:1 step:4050[D loss: 1.000052] [G loss: 0.999840]\n",
      "epoch:1 step:4055[D loss: 1.000047] [G loss: 0.999886]\n",
      "epoch:1 step:4060[D loss: 1.000049] [G loss: 0.999884]\n",
      "epoch:1 step:4065[D loss: 1.000054] [G loss: 0.999856]\n",
      "epoch:1 step:4070[D loss: 1.000032] [G loss: 0.999867]\n",
      "epoch:1 step:4075[D loss: 1.000031] [G loss: 0.999863]\n",
      "epoch:1 step:4080[D loss: 1.000052] [G loss: 0.999859]\n",
      "epoch:1 step:4085[D loss: 1.000039] [G loss: 0.999876]\n",
      "epoch:1 step:4090[D loss: 1.000043] [G loss: 0.999867]\n",
      "epoch:1 step:4095[D loss: 1.000048] [G loss: 0.999897]\n",
      "epoch:1 step:4100[D loss: 1.000048] [G loss: 0.999883]\n",
      "epoch:1 step:4105[D loss: 1.000042] [G loss: 0.999847]\n",
      "epoch:1 step:4110[D loss: 1.000067] [G loss: 0.999844]\n",
      "epoch:1 step:4115[D loss: 1.000048] [G loss: 0.999866]\n",
      "epoch:1 step:4120[D loss: 1.000055] [G loss: 0.999859]\n",
      "epoch:1 step:4125[D loss: 1.000067] [G loss: 0.999862]\n",
      "epoch:1 step:4130[D loss: 1.000083] [G loss: 0.999857]\n",
      "epoch:1 step:4135[D loss: 1.000065] [G loss: 0.999873]\n",
      "epoch:1 step:4140[D loss: 1.000064] [G loss: 0.999850]\n",
      "epoch:1 step:4145[D loss: 1.000060] [G loss: 0.999851]\n",
      "epoch:1 step:4150[D loss: 1.000059] [G loss: 0.999865]\n",
      "epoch:1 step:4155[D loss: 1.000081] [G loss: 0.999843]\n",
      "epoch:1 step:4160[D loss: 1.000046] [G loss: 0.999861]\n",
      "epoch:1 step:4165[D loss: 1.000060] [G loss: 0.999851]\n",
      "epoch:1 step:4170[D loss: 1.000062] [G loss: 0.999864]\n",
      "epoch:1 step:4175[D loss: 1.000055] [G loss: 0.999868]\n",
      "epoch:1 step:4180[D loss: 1.000055] [G loss: 0.999873]\n",
      "epoch:1 step:4185[D loss: 1.000055] [G loss: 0.999860]\n",
      "epoch:1 step:4190[D loss: 1.000050] [G loss: 0.999859]\n",
      "epoch:1 step:4195[D loss: 1.000035] [G loss: 0.999847]\n",
      "epoch:1 step:4200[D loss: 1.000046] [G loss: 0.999874]\n",
      "##############\n",
      "[0.86595641 0.85160713 0.82449186 0.84034083 0.80776369 0.83883004\n",
      " 0.83668108 0.84645002 0.81045953 0.83273318]\n",
      "##########\n",
      "epoch:1 step:4205[D loss: 1.000042] [G loss: 0.999899]\n",
      "epoch:1 step:4210[D loss: 1.000047] [G loss: 0.999876]\n",
      "epoch:1 step:4215[D loss: 1.000060] [G loss: 0.999859]\n",
      "epoch:1 step:4220[D loss: 1.000063] [G loss: 0.999851]\n",
      "epoch:1 step:4225[D loss: 1.000071] [G loss: 0.999860]\n",
      "epoch:1 step:4230[D loss: 1.000090] [G loss: 0.999808]\n",
      "epoch:1 step:4235[D loss: 1.000086] [G loss: 0.999799]\n",
      "epoch:1 step:4240[D loss: 1.000066] [G loss: 0.999827]\n",
      "epoch:1 step:4245[D loss: 1.000090] [G loss: 0.999810]\n",
      "epoch:1 step:4250[D loss: 1.000059] [G loss: 0.999857]\n",
      "epoch:1 step:4255[D loss: 1.000081] [G loss: 0.999859]\n",
      "epoch:1 step:4260[D loss: 1.000051] [G loss: 0.999823]\n",
      "epoch:1 step:4265[D loss: 1.000046] [G loss: 0.999892]\n",
      "epoch:1 step:4270[D loss: 1.000077] [G loss: 0.999866]\n",
      "epoch:1 step:4275[D loss: 1.000065] [G loss: 0.999847]\n",
      "epoch:1 step:4280[D loss: 1.000037] [G loss: 0.999861]\n",
      "epoch:1 step:4285[D loss: 1.000069] [G loss: 0.999832]\n",
      "epoch:1 step:4290[D loss: 1.000058] [G loss: 0.999857]\n",
      "epoch:1 step:4295[D loss: 1.000080] [G loss: 0.999859]\n",
      "epoch:1 step:4300[D loss: 1.000067] [G loss: 0.999863]\n",
      "epoch:1 step:4305[D loss: 1.000059] [G loss: 0.999849]\n",
      "epoch:1 step:4310[D loss: 1.000055] [G loss: 0.999865]\n",
      "epoch:1 step:4315[D loss: 1.000046] [G loss: 0.999874]\n",
      "epoch:1 step:4320[D loss: 1.000049] [G loss: 0.999871]\n",
      "epoch:1 step:4325[D loss: 1.000049] [G loss: 0.999868]\n",
      "epoch:1 step:4330[D loss: 1.000026] [G loss: 0.999891]\n",
      "epoch:1 step:4335[D loss: 1.000035] [G loss: 0.999889]\n",
      "epoch:1 step:4340[D loss: 1.000042] [G loss: 0.999860]\n",
      "epoch:1 step:4345[D loss: 1.000079] [G loss: 0.999844]\n",
      "epoch:1 step:4350[D loss: 1.000059] [G loss: 0.999860]\n",
      "epoch:1 step:4355[D loss: 1.000089] [G loss: 0.999863]\n",
      "epoch:1 step:4360[D loss: 1.000069] [G loss: 0.999870]\n",
      "epoch:1 step:4365[D loss: 1.000076] [G loss: 0.999870]\n",
      "epoch:1 step:4370[D loss: 1.000070] [G loss: 0.999900]\n",
      "epoch:1 step:4375[D loss: 1.000052] [G loss: 0.999886]\n",
      "epoch:1 step:4380[D loss: 1.000031] [G loss: 0.999915]\n",
      "epoch:1 step:4385[D loss: 1.000053] [G loss: 0.999892]\n",
      "epoch:1 step:4390[D loss: 1.000049] [G loss: 0.999877]\n",
      "epoch:1 step:4395[D loss: 1.000061] [G loss: 0.999860]\n",
      "epoch:1 step:4400[D loss: 1.000074] [G loss: 0.999831]\n",
      "##############\n",
      "[0.87295969 0.86345012 0.82058458 0.82293567 0.79675709 0.8495935\n",
      " 0.85091729 0.84114965 0.79544069 0.84592702]\n",
      "##########\n",
      "epoch:1 step:4405[D loss: 1.000053] [G loss: 0.999857]\n",
      "epoch:1 step:4410[D loss: 1.000077] [G loss: 0.999809]\n",
      "epoch:1 step:4415[D loss: 1.000069] [G loss: 0.999852]\n",
      "epoch:1 step:4420[D loss: 1.000074] [G loss: 0.999853]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1 step:4425[D loss: 1.000056] [G loss: 0.999854]\n",
      "epoch:1 step:4430[D loss: 1.000056] [G loss: 0.999868]\n",
      "epoch:1 step:4435[D loss: 1.000049] [G loss: 0.999896]\n",
      "epoch:1 step:4440[D loss: 1.000022] [G loss: 0.999933]\n",
      "epoch:1 step:4445[D loss: 1.000035] [G loss: 0.999936]\n",
      "epoch:1 step:4450[D loss: 1.000059] [G loss: 0.999889]\n",
      "epoch:1 step:4455[D loss: 1.000055] [G loss: 0.999878]\n",
      "epoch:1 step:4460[D loss: 1.000066] [G loss: 0.999863]\n",
      "epoch:1 step:4465[D loss: 1.000064] [G loss: 0.999839]\n",
      "epoch:1 step:4470[D loss: 1.000066] [G loss: 0.999867]\n",
      "epoch:1 step:4475[D loss: 1.000076] [G loss: 0.999886]\n",
      "epoch:1 step:4480[D loss: 1.000071] [G loss: 0.999872]\n",
      "epoch:1 step:4485[D loss: 1.000054] [G loss: 0.999879]\n",
      "epoch:1 step:4490[D loss: 1.000053] [G loss: 0.999904]\n",
      "epoch:1 step:4495[D loss: 1.000032] [G loss: 0.999938]\n",
      "epoch:1 step:4500[D loss: 1.000046] [G loss: 0.999971]\n",
      "epoch:1 step:4505[D loss: 1.000045] [G loss: 0.999950]\n",
      "epoch:1 step:4510[D loss: 1.000039] [G loss: 0.999955]\n",
      "epoch:1 step:4515[D loss: 1.000034] [G loss: 0.999936]\n",
      "epoch:1 step:4520[D loss: 1.000055] [G loss: 0.999917]\n",
      "epoch:1 step:4525[D loss: 1.000047] [G loss: 0.999891]\n",
      "epoch:1 step:4530[D loss: 1.000067] [G loss: 0.999862]\n",
      "epoch:1 step:4535[D loss: 1.000081] [G loss: 0.999827]\n",
      "epoch:1 step:4540[D loss: 1.000067] [G loss: 0.999869]\n",
      "epoch:1 step:4545[D loss: 1.000057] [G loss: 0.999890]\n",
      "epoch:1 step:4550[D loss: 1.000081] [G loss: 0.999874]\n",
      "epoch:1 step:4555[D loss: 1.000054] [G loss: 0.999904]\n",
      "epoch:1 step:4560[D loss: 1.000052] [G loss: 0.999930]\n",
      "epoch:1 step:4565[D loss: 1.000042] [G loss: 0.999934]\n",
      "epoch:1 step:4570[D loss: 1.000032] [G loss: 0.999965]\n",
      "epoch:1 step:4575[D loss: 1.000046] [G loss: 0.999919]\n",
      "epoch:1 step:4580[D loss: 1.000051] [G loss: 0.999922]\n",
      "epoch:1 step:4585[D loss: 1.000056] [G loss: 0.999897]\n",
      "epoch:1 step:4590[D loss: 1.000071] [G loss: 0.999922]\n",
      "epoch:1 step:4595[D loss: 1.000068] [G loss: 0.999907]\n",
      "epoch:1 step:4600[D loss: 1.000061] [G loss: 0.999895]\n",
      "##############\n",
      "[0.8722822  0.83833327 0.81907965 0.81587986 0.78407334 0.85195851\n",
      " 0.85216832 0.84621049 0.84035309 0.83935345]\n",
      "##########\n",
      "epoch:1 step:4605[D loss: 1.000066] [G loss: 0.999910]\n",
      "epoch:1 step:4610[D loss: 1.000080] [G loss: 0.999916]\n",
      "epoch:1 step:4615[D loss: 1.000064] [G loss: 0.999928]\n",
      "epoch:1 step:4620[D loss: 1.000064] [G loss: 0.999922]\n",
      "epoch:1 step:4625[D loss: 1.000037] [G loss: 0.999929]\n",
      "epoch:1 step:4630[D loss: 1.000025] [G loss: 0.999982]\n",
      "epoch:1 step:4635[D loss: 1.000047] [G loss: 0.999928]\n",
      "epoch:1 step:4640[D loss: 1.000044] [G loss: 0.999923]\n",
      "epoch:1 step:4645[D loss: 1.000046] [G loss: 0.999906]\n",
      "epoch:1 step:4650[D loss: 1.000031] [G loss: 0.999944]\n",
      "epoch:1 step:4655[D loss: 1.000077] [G loss: 0.999921]\n",
      "epoch:1 step:4660[D loss: 1.000057] [G loss: 0.999916]\n",
      "epoch:1 step:4665[D loss: 1.000084] [G loss: 0.999863]\n",
      "epoch:1 step:4670[D loss: 1.000052] [G loss: 0.999905]\n",
      "epoch:1 step:4675[D loss: 1.000060] [G loss: 0.999906]\n",
      "epoch:1 step:4680[D loss: 1.000063] [G loss: 0.999963]\n",
      "epoch:1 step:4685[D loss: 1.000027] [G loss: 0.999922]\n",
      "epoch:1 step:4690[D loss: 1.000035] [G loss: 0.999924]\n",
      "epoch:1 step:4695[D loss: 1.000054] [G loss: 0.999913]\n",
      "epoch:1 step:4700[D loss: 1.000053] [G loss: 0.999898]\n",
      "epoch:1 step:4705[D loss: 1.000096] [G loss: 0.999918]\n",
      "epoch:1 step:4710[D loss: 1.000037] [G loss: 0.999965]\n",
      "epoch:1 step:4715[D loss: 1.000037] [G loss: 0.999982]\n",
      "epoch:1 step:4720[D loss: 1.000039] [G loss: 0.999942]\n",
      "epoch:1 step:4725[D loss: 1.000023] [G loss: 0.999936]\n",
      "epoch:1 step:4730[D loss: 1.000039] [G loss: 0.999961]\n",
      "epoch:1 step:4735[D loss: 1.000064] [G loss: 0.999942]\n",
      "epoch:1 step:4740[D loss: 1.000033] [G loss: 0.999969]\n",
      "epoch:1 step:4745[D loss: 1.000040] [G loss: 0.999958]\n",
      "epoch:1 step:4750[D loss: 1.000059] [G loss: 0.999983]\n",
      "epoch:1 step:4755[D loss: 1.000030] [G loss: 0.999952]\n",
      "epoch:1 step:4760[D loss: 1.000057] [G loss: 0.999929]\n",
      "epoch:1 step:4765[D loss: 1.000045] [G loss: 0.999960]\n",
      "epoch:1 step:4770[D loss: 1.000055] [G loss: 0.999932]\n",
      "epoch:1 step:4775[D loss: 1.000053] [G loss: 0.999939]\n",
      "epoch:1 step:4780[D loss: 1.000050] [G loss: 0.999947]\n",
      "epoch:1 step:4785[D loss: 1.000038] [G loss: 0.999944]\n",
      "epoch:1 step:4790[D loss: 1.000050] [G loss: 0.999923]\n",
      "epoch:1 step:4795[D loss: 1.000046] [G loss: 0.999916]\n",
      "epoch:1 step:4800[D loss: 1.000052] [G loss: 0.999922]\n",
      "##############\n",
      "[0.86569326 0.84476766 0.80938296 0.82505718 0.80739781 0.8225381\n",
      " 0.83339263 0.85976607 0.83251882 0.84717267]\n",
      "##########\n",
      "epoch:1 step:4805[D loss: 1.000061] [G loss: 0.999931]\n",
      "epoch:1 step:4810[D loss: 1.000050] [G loss: 0.999918]\n",
      "epoch:1 step:4815[D loss: 1.000034] [G loss: 0.999937]\n",
      "epoch:1 step:4820[D loss: 1.000068] [G loss: 0.999877]\n",
      "epoch:1 step:4825[D loss: 1.000065] [G loss: 0.999917]\n",
      "epoch:1 step:4830[D loss: 1.000045] [G loss: 0.999952]\n",
      "epoch:1 step:4835[D loss: 1.000039] [G loss: 0.999942]\n",
      "epoch:1 step:4840[D loss: 1.000065] [G loss: 1.000013]\n",
      "epoch:1 step:4845[D loss: 1.000051] [G loss: 0.999963]\n",
      "epoch:1 step:4850[D loss: 1.000034] [G loss: 0.999972]\n",
      "epoch:1 step:4855[D loss: 1.000036] [G loss: 0.999932]\n",
      "epoch:1 step:4860[D loss: 1.000049] [G loss: 0.999937]\n",
      "epoch:1 step:4865[D loss: 1.000064] [G loss: 0.999940]\n",
      "epoch:1 step:4870[D loss: 1.000050] [G loss: 0.999947]\n",
      "epoch:1 step:4875[D loss: 1.000044] [G loss: 0.999960]\n",
      "epoch:1 step:4880[D loss: 1.000035] [G loss: 0.999957]\n",
      "epoch:1 step:4885[D loss: 1.000049] [G loss: 0.999954]\n",
      "epoch:1 step:4890[D loss: 1.000013] [G loss: 0.999985]\n",
      "epoch:1 step:4895[D loss: 1.000045] [G loss: 0.999955]\n",
      "epoch:1 step:4900[D loss: 1.000043] [G loss: 0.999946]\n",
      "epoch:1 step:4905[D loss: 1.000050] [G loss: 0.999935]\n",
      "epoch:1 step:4910[D loss: 1.000057] [G loss: 0.999916]\n",
      "epoch:1 step:4915[D loss: 1.000055] [G loss: 0.999911]\n",
      "epoch:1 step:4920[D loss: 1.000056] [G loss: 0.999884]\n",
      "epoch:1 step:4925[D loss: 1.000063] [G loss: 0.999933]\n",
      "epoch:1 step:4930[D loss: 1.000041] [G loss: 0.999925]\n",
      "epoch:1 step:4935[D loss: 1.000016] [G loss: 1.000018]\n",
      "epoch:1 step:4940[D loss: 1.000026] [G loss: 1.000019]\n",
      "epoch:1 step:4945[D loss: 1.000015] [G loss: 0.999984]\n",
      "epoch:1 step:4950[D loss: 1.000029] [G loss: 0.999958]\n",
      "epoch:1 step:4955[D loss: 1.000067] [G loss: 0.999926]\n",
      "epoch:1 step:4960[D loss: 1.000058] [G loss: 0.999908]\n",
      "epoch:1 step:4965[D loss: 1.000061] [G loss: 0.999918]\n",
      "epoch:1 step:4970[D loss: 1.000068] [G loss: 0.999881]\n",
      "epoch:1 step:4975[D loss: 1.000067] [G loss: 0.999877]\n",
      "epoch:1 step:4980[D loss: 1.000080] [G loss: 0.999873]\n",
      "epoch:1 step:4985[D loss: 1.000052] [G loss: 0.999917]\n",
      "epoch:1 step:4990[D loss: 1.000048] [G loss: 0.999987]\n",
      "epoch:1 step:4995[D loss: 1.000031] [G loss: 0.999998]\n",
      "epoch:1 step:5000[D loss: 1.000054] [G loss: 1.000019]\n",
      "##############\n",
      "[0.8671675  0.85938033 0.79111156 0.81734826 0.79257935 0.81396143\n",
      " 0.85608216 0.83960206 0.82384574 0.83970866]\n",
      "##########\n",
      "epoch:1 step:5005[D loss: 1.000040] [G loss: 1.000000]\n",
      "epoch:1 step:5010[D loss: 1.000043] [G loss: 0.999988]\n",
      "epoch:1 step:5015[D loss: 1.000044] [G loss: 0.999991]\n",
      "epoch:1 step:5020[D loss: 1.000017] [G loss: 0.999960]\n",
      "epoch:1 step:5025[D loss: 1.000030] [G loss: 0.999943]\n",
      "epoch:1 step:5030[D loss: 1.000015] [G loss: 0.999986]\n",
      "epoch:1 step:5035[D loss: 1.000026] [G loss: 0.999957]\n",
      "epoch:1 step:5040[D loss: 1.000002] [G loss: 0.999908]\n",
      "epoch:1 step:5045[D loss: 1.000022] [G loss: 0.999934]\n",
      "epoch:1 step:5050[D loss: 1.000035] [G loss: 0.999931]\n",
      "epoch:1 step:5055[D loss: 1.000040] [G loss: 0.999948]\n",
      "epoch:1 step:5060[D loss: 1.000035] [G loss: 0.999915]\n",
      "epoch:1 step:5065[D loss: 1.000043] [G loss: 0.999922]\n",
      "epoch:1 step:5070[D loss: 1.000021] [G loss: 0.999938]\n",
      "epoch:1 step:5075[D loss: 1.000020] [G loss: 0.999976]\n",
      "epoch:1 step:5080[D loss: 1.000005] [G loss: 0.999969]\n",
      "epoch:1 step:5085[D loss: 1.000009] [G loss: 0.999954]\n",
      "epoch:1 step:5090[D loss: 1.000018] [G loss: 0.999941]\n",
      "epoch:1 step:5095[D loss: 1.000019] [G loss: 0.999970]\n",
      "epoch:1 step:5100[D loss: 1.000034] [G loss: 0.999936]\n",
      "epoch:1 step:5105[D loss: 1.000044] [G loss: 0.999953]\n",
      "epoch:1 step:5110[D loss: 1.000027] [G loss: 0.999988]\n",
      "epoch:1 step:5115[D loss: 1.000019] [G loss: 0.999962]\n",
      "epoch:1 step:5120[D loss: 1.000022] [G loss: 1.000010]\n",
      "epoch:1 step:5125[D loss: 1.000018] [G loss: 1.000001]\n",
      "epoch:1 step:5130[D loss: 1.000032] [G loss: 0.999973]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1 step:5135[D loss: 1.000008] [G loss: 1.000023]\n",
      "epoch:1 step:5140[D loss: 1.000036] [G loss: 1.000021]\n",
      "epoch:1 step:5145[D loss: 1.000018] [G loss: 0.999978]\n",
      "epoch:1 step:5150[D loss: 0.999985] [G loss: 0.999953]\n",
      "epoch:1 step:5155[D loss: 1.000024] [G loss: 0.999930]\n",
      "epoch:1 step:5160[D loss: 1.000025] [G loss: 0.999933]\n",
      "epoch:1 step:5165[D loss: 1.000003] [G loss: 0.999908]\n",
      "epoch:1 step:5170[D loss: 1.000016] [G loss: 0.999918]\n",
      "epoch:1 step:5175[D loss: 1.000030] [G loss: 0.999954]\n",
      "epoch:1 step:5180[D loss: 1.000025] [G loss: 0.999966]\n",
      "epoch:1 step:5185[D loss: 1.000022] [G loss: 0.999949]\n",
      "epoch:1 step:5190[D loss: 1.000033] [G loss: 0.999948]\n",
      "epoch:1 step:5195[D loss: 1.000037] [G loss: 0.999956]\n",
      "epoch:1 step:5200[D loss: 1.000020] [G loss: 0.999959]\n",
      "##############\n",
      "[0.8600138  0.8497373  0.83065129 0.82351468 0.78295146 0.82447331\n",
      " 0.85988505 0.83560354 0.81317793 0.83269292]\n",
      "##########\n",
      "epoch:1 step:5205[D loss: 1.000023] [G loss: 0.999951]\n",
      "epoch:1 step:5210[D loss: 1.000022] [G loss: 0.999918]\n",
      "epoch:1 step:5215[D loss: 1.000033] [G loss: 0.999958]\n",
      "epoch:1 step:5220[D loss: 1.000026] [G loss: 0.999977]\n",
      "epoch:1 step:5225[D loss: 1.000032] [G loss: 0.999962]\n",
      "epoch:1 step:5230[D loss: 1.000022] [G loss: 0.999987]\n",
      "epoch:1 step:5235[D loss: 1.000037] [G loss: 1.000005]\n",
      "epoch:1 step:5240[D loss: 1.000020] [G loss: 0.999991]\n",
      "epoch:1 step:5245[D loss: 1.000020] [G loss: 0.999988]\n",
      "epoch:1 step:5250[D loss: 1.000022] [G loss: 0.999982]\n",
      "epoch:1 step:5255[D loss: 1.000026] [G loss: 0.999971]\n",
      "epoch:1 step:5260[D loss: 1.000016] [G loss: 0.999908]\n",
      "epoch:1 step:5265[D loss: 1.000027] [G loss: 0.999933]\n",
      "epoch:1 step:5270[D loss: 1.000019] [G loss: 0.999986]\n",
      "epoch:1 step:5275[D loss: 1.000041] [G loss: 0.999981]\n",
      "epoch:1 step:5280[D loss: 1.000038] [G loss: 0.999969]\n",
      "epoch:1 step:5285[D loss: 1.000035] [G loss: 1.000002]\n",
      "epoch:1 step:5290[D loss: 1.000014] [G loss: 0.999994]\n",
      "epoch:1 step:5295[D loss: 1.000009] [G loss: 0.999972]\n",
      "epoch:1 step:5300[D loss: 1.000025] [G loss: 0.999952]\n",
      "epoch:1 step:5305[D loss: 1.000012] [G loss: 1.000005]\n",
      "epoch:1 step:5310[D loss: 1.000023] [G loss: 0.999997]\n",
      "epoch:1 step:5315[D loss: 1.000008] [G loss: 1.000005]\n",
      "epoch:1 step:5320[D loss: 1.000037] [G loss: 0.999934]\n",
      "epoch:1 step:5325[D loss: 1.000010] [G loss: 0.999942]\n",
      "epoch:1 step:5330[D loss: 1.000017] [G loss: 1.000036]\n",
      "epoch:1 step:5335[D loss: 1.000025] [G loss: 0.999976]\n",
      "epoch:1 step:5340[D loss: 1.000034] [G loss: 0.999962]\n",
      "epoch:1 step:5345[D loss: 1.000000] [G loss: 0.999989]\n",
      "epoch:1 step:5350[D loss: 1.000026] [G loss: 0.999954]\n",
      "epoch:1 step:5355[D loss: 1.000007] [G loss: 0.999943]\n",
      "epoch:1 step:5360[D loss: 1.000017] [G loss: 0.999924]\n",
      "epoch:1 step:5365[D loss: 1.000023] [G loss: 0.999970]\n",
      "epoch:1 step:5370[D loss: 1.000016] [G loss: 0.999993]\n",
      "epoch:1 step:5375[D loss: 1.000004] [G loss: 0.999995]\n",
      "epoch:1 step:5380[D loss: 1.000010] [G loss: 0.999977]\n",
      "epoch:1 step:5385[D loss: 1.000024] [G loss: 1.000023]\n",
      "epoch:1 step:5390[D loss: 1.000027] [G loss: 0.999977]\n",
      "epoch:1 step:5395[D loss: 1.000017] [G loss: 0.999980]\n",
      "epoch:1 step:5400[D loss: 1.000004] [G loss: 0.999975]\n",
      "##############\n",
      "[0.86186034 0.86725684 0.79057869 0.83246294 0.76797306 0.84200498\n",
      " 0.88115576 0.83312371 0.80906068 0.82333159]\n",
      "##########\n",
      "epoch:1 step:5405[D loss: 0.999990] [G loss: 1.000002]\n",
      "epoch:1 step:5410[D loss: 1.000011] [G loss: 1.000023]\n",
      "epoch:1 step:5415[D loss: 1.000014] [G loss: 1.000008]\n",
      "epoch:1 step:5420[D loss: 1.000014] [G loss: 0.999999]\n",
      "epoch:1 step:5425[D loss: 1.000018] [G loss: 0.999977]\n",
      "epoch:1 step:5430[D loss: 0.999998] [G loss: 1.000008]\n",
      "epoch:1 step:5435[D loss: 0.999996] [G loss: 0.999991]\n",
      "epoch:1 step:5440[D loss: 1.000016] [G loss: 0.999972]\n",
      "epoch:1 step:5445[D loss: 1.000031] [G loss: 0.999933]\n",
      "epoch:1 step:5450[D loss: 1.000017] [G loss: 0.999945]\n",
      "epoch:1 step:5455[D loss: 1.000021] [G loss: 0.999949]\n",
      "epoch:1 step:5460[D loss: 1.000029] [G loss: 0.999973]\n",
      "epoch:1 step:5465[D loss: 1.000028] [G loss: 0.999979]\n",
      "epoch:1 step:5470[D loss: 1.000025] [G loss: 0.999982]\n",
      "epoch:1 step:5475[D loss: 1.000022] [G loss: 0.999966]\n",
      "epoch:1 step:5480[D loss: 1.000040] [G loss: 0.999950]\n",
      "epoch:1 step:5485[D loss: 1.000010] [G loss: 0.999941]\n",
      "epoch:1 step:5490[D loss: 1.000008] [G loss: 0.999963]\n",
      "epoch:1 step:5495[D loss: 1.000011] [G loss: 0.999955]\n",
      "epoch:1 step:5500[D loss: 1.000026] [G loss: 0.999964]\n",
      "epoch:1 step:5505[D loss: 1.000022] [G loss: 0.999983]\n",
      "epoch:1 step:5510[D loss: 1.000014] [G loss: 0.999995]\n",
      "epoch:1 step:5515[D loss: 1.000025] [G loss: 0.999908]\n",
      "epoch:1 step:5520[D loss: 1.000041] [G loss: 0.999919]\n",
      "epoch:1 step:5525[D loss: 0.999999] [G loss: 0.999980]\n",
      "epoch:1 step:5530[D loss: 1.000034] [G loss: 0.999946]\n",
      "epoch:1 step:5535[D loss: 1.000012] [G loss: 0.999990]\n",
      "epoch:1 step:5540[D loss: 1.000008] [G loss: 0.999978]\n",
      "epoch:1 step:5545[D loss: 1.000036] [G loss: 0.999949]\n",
      "epoch:1 step:5550[D loss: 1.000024] [G loss: 0.999955]\n",
      "epoch:1 step:5555[D loss: 0.999989] [G loss: 0.999982]\n",
      "epoch:1 step:5560[D loss: 0.999991] [G loss: 1.000007]\n",
      "epoch:1 step:5565[D loss: 1.000012] [G loss: 0.999969]\n",
      "epoch:1 step:5570[D loss: 0.999996] [G loss: 0.999965]\n",
      "epoch:1 step:5575[D loss: 1.000010] [G loss: 0.999972]\n",
      "epoch:1 step:5580[D loss: 1.000015] [G loss: 0.999998]\n",
      "epoch:1 step:5585[D loss: 1.000010] [G loss: 0.999992]\n",
      "epoch:1 step:5590[D loss: 1.000028] [G loss: 0.999991]\n",
      "epoch:1 step:5595[D loss: 1.000022] [G loss: 0.999959]\n",
      "epoch:1 step:5600[D loss: 0.999997] [G loss: 0.999974]\n",
      "##############\n",
      "[0.85458456 0.86086879 0.79521376 0.83191021 0.79862581 0.8296595\n",
      " 0.84692738 0.84946438 0.82534135 0.81769871]\n",
      "##########\n",
      "epoch:1 step:5605[D loss: 1.000007] [G loss: 0.999987]\n",
      "epoch:1 step:5610[D loss: 1.000017] [G loss: 0.999963]\n",
      "epoch:1 step:5615[D loss: 1.000018] [G loss: 0.999960]\n",
      "epoch:1 step:5620[D loss: 1.000022] [G loss: 1.000006]\n",
      "epoch:1 step:5625[D loss: 1.000003] [G loss: 0.999987]\n",
      "epoch:1 step:5630[D loss: 0.999991] [G loss: 0.999982]\n",
      "epoch:1 step:5635[D loss: 1.000021] [G loss: 0.999946]\n",
      "epoch:1 step:5640[D loss: 1.000019] [G loss: 0.999982]\n",
      "epoch:1 step:5645[D loss: 1.000007] [G loss: 0.999996]\n",
      "epoch:1 step:5650[D loss: 1.000004] [G loss: 0.999956]\n",
      "epoch:1 step:5655[D loss: 1.000019] [G loss: 0.999946]\n",
      "epoch:1 step:5660[D loss: 1.000017] [G loss: 0.999972]\n",
      "epoch:1 step:5665[D loss: 1.000004] [G loss: 0.999989]\n",
      "epoch:1 step:5670[D loss: 1.000012] [G loss: 0.999996]\n",
      "epoch:1 step:5675[D loss: 1.000036] [G loss: 0.999948]\n",
      "epoch:1 step:5680[D loss: 1.000024] [G loss: 0.999952]\n",
      "epoch:1 step:5685[D loss: 1.000011] [G loss: 0.999991]\n",
      "epoch:1 step:5690[D loss: 1.000014] [G loss: 1.000014]\n",
      "epoch:1 step:5695[D loss: 1.000004] [G loss: 1.000012]\n",
      "epoch:1 step:5700[D loss: 1.000002] [G loss: 0.999990]\n",
      "epoch:1 step:5705[D loss: 1.000013] [G loss: 0.999973]\n",
      "epoch:1 step:5710[D loss: 1.000024] [G loss: 0.999966]\n",
      "epoch:1 step:5715[D loss: 1.000013] [G loss: 0.999963]\n",
      "epoch:1 step:5720[D loss: 0.999998] [G loss: 1.000006]\n",
      "epoch:1 step:5725[D loss: 0.999998] [G loss: 1.000008]\n",
      "epoch:1 step:5730[D loss: 0.999989] [G loss: 0.999978]\n",
      "epoch:1 step:5735[D loss: 1.000012] [G loss: 0.999980]\n",
      "epoch:1 step:5740[D loss: 0.999998] [G loss: 1.000002]\n",
      "epoch:1 step:5745[D loss: 1.000013] [G loss: 0.999967]\n",
      "epoch:1 step:5750[D loss: 1.000012] [G loss: 0.999958]\n",
      "epoch:1 step:5755[D loss: 1.000025] [G loss: 0.999994]\n",
      "epoch:1 step:5760[D loss: 0.999992] [G loss: 0.999991]\n",
      "epoch:1 step:5765[D loss: 1.000016] [G loss: 0.999960]\n",
      "epoch:1 step:5770[D loss: 1.000015] [G loss: 0.999964]\n",
      "epoch:1 step:5775[D loss: 0.999985] [G loss: 0.999994]\n",
      "epoch:1 step:5780[D loss: 1.000013] [G loss: 1.000004]\n",
      "epoch:1 step:5785[D loss: 1.000007] [G loss: 1.000000]\n",
      "epoch:1 step:5790[D loss: 1.000010] [G loss: 0.999946]\n",
      "epoch:1 step:5795[D loss: 1.000005] [G loss: 0.999978]\n",
      "epoch:1 step:5800[D loss: 0.999993] [G loss: 0.999996]\n",
      "##############\n",
      "[0.85954848 0.8609869  0.79281909 0.8373627  0.77201588 0.80908217\n",
      " 0.85700636 0.82130219 0.80417494 0.82679799]\n",
      "##########\n",
      "epoch:1 step:5805[D loss: 1.000009] [G loss: 1.000024]\n",
      "epoch:1 step:5810[D loss: 0.999996] [G loss: 0.999994]\n",
      "epoch:1 step:5815[D loss: 1.000016] [G loss: 0.999968]\n",
      "epoch:1 step:5820[D loss: 1.000015] [G loss: 0.999976]\n",
      "epoch:1 step:5825[D loss: 1.000007] [G loss: 0.999965]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1 step:5830[D loss: 1.000004] [G loss: 0.999990]\n",
      "epoch:1 step:5835[D loss: 1.000020] [G loss: 0.999988]\n",
      "epoch:1 step:5840[D loss: 0.999983] [G loss: 1.000025]\n",
      "epoch:1 step:5845[D loss: 1.000017] [G loss: 1.000012]\n",
      "epoch:1 step:5850[D loss: 1.000013] [G loss: 0.999963]\n",
      "epoch:1 step:5855[D loss: 0.999999] [G loss: 0.999993]\n",
      "epoch:1 step:5860[D loss: 0.999999] [G loss: 0.999977]\n",
      "epoch:1 step:5865[D loss: 1.000002] [G loss: 0.999989]\n",
      "epoch:1 step:5870[D loss: 1.000009] [G loss: 0.999940]\n",
      "epoch:1 step:5875[D loss: 0.999993] [G loss: 0.999982]\n",
      "epoch:1 step:5880[D loss: 1.000018] [G loss: 0.999967]\n",
      "epoch:1 step:5885[D loss: 0.999997] [G loss: 1.000002]\n",
      "epoch:1 step:5890[D loss: 1.000004] [G loss: 0.999983]\n",
      "epoch:1 step:5895[D loss: 1.000011] [G loss: 0.999971]\n",
      "epoch:1 step:5900[D loss: 1.000023] [G loss: 0.999975]\n",
      "epoch:1 step:5905[D loss: 0.999997] [G loss: 0.999982]\n",
      "epoch:1 step:5910[D loss: 0.999991] [G loss: 0.999999]\n",
      "epoch:1 step:5915[D loss: 0.999995] [G loss: 0.999993]\n",
      "epoch:1 step:5920[D loss: 0.999996] [G loss: 0.999966]\n",
      "epoch:1 step:5925[D loss: 0.999998] [G loss: 0.999992]\n",
      "epoch:1 step:5930[D loss: 1.000032] [G loss: 0.999960]\n",
      "epoch:1 step:5935[D loss: 0.999982] [G loss: 1.000011]\n",
      "epoch:1 step:5940[D loss: 0.999991] [G loss: 1.000034]\n",
      "epoch:1 step:5945[D loss: 0.999990] [G loss: 0.999982]\n",
      "epoch:1 step:5950[D loss: 1.000011] [G loss: 0.999958]\n",
      "epoch:1 step:5955[D loss: 0.999986] [G loss: 0.999996]\n",
      "epoch:1 step:5960[D loss: 1.000026] [G loss: 0.999929]\n",
      "epoch:1 step:5965[D loss: 1.000027] [G loss: 0.999986]\n",
      "epoch:1 step:5970[D loss: 0.999999] [G loss: 1.000007]\n",
      "epoch:1 step:5975[D loss: 0.999999] [G loss: 1.000027]\n",
      "epoch:1 step:5980[D loss: 0.999993] [G loss: 0.999981]\n",
      "epoch:1 step:5985[D loss: 1.000010] [G loss: 0.999934]\n",
      "epoch:1 step:5990[D loss: 1.000009] [G loss: 0.999974]\n",
      "epoch:1 step:5995[D loss: 1.000000] [G loss: 0.999971]\n",
      "epoch:1 step:6000[D loss: 1.000023] [G loss: 0.999940]\n",
      "##############\n",
      "[0.8649285  0.87848779 0.80316094 0.81562352 0.78428269 0.82060175\n",
      " 0.8740397  0.82679884 0.81142176 0.83426165]\n",
      "##########\n",
      "epoch:1 step:6005[D loss: 1.000021] [G loss: 0.999996]\n",
      "epoch:1 step:6010[D loss: 0.999987] [G loss: 1.000017]\n",
      "epoch:1 step:6015[D loss: 1.000000] [G loss: 1.000017]\n",
      "epoch:1 step:6020[D loss: 0.999994] [G loss: 0.999970]\n",
      "epoch:1 step:6025[D loss: 0.999987] [G loss: 1.000001]\n",
      "epoch:1 step:6030[D loss: 0.999980] [G loss: 1.000001]\n",
      "epoch:1 step:6035[D loss: 0.999978] [G loss: 1.000005]\n",
      "epoch:1 step:6040[D loss: 1.000002] [G loss: 1.000021]\n",
      "epoch:1 step:6045[D loss: 1.000008] [G loss: 0.999983]\n",
      "epoch:1 step:6050[D loss: 1.000012] [G loss: 0.999990]\n",
      "epoch:1 step:6055[D loss: 1.000018] [G loss: 0.999955]\n",
      "epoch:1 step:6060[D loss: 0.999998] [G loss: 0.999970]\n",
      "epoch:1 step:6065[D loss: 0.999984] [G loss: 1.000013]\n",
      "epoch:1 step:6070[D loss: 0.999982] [G loss: 1.000029]\n",
      "epoch:1 step:6075[D loss: 1.000020] [G loss: 0.999978]\n",
      "epoch:1 step:6080[D loss: 0.999997] [G loss: 0.999984]\n",
      "epoch:1 step:6085[D loss: 1.000033] [G loss: 0.999861]\n",
      "epoch:1 step:6090[D loss: 1.000007] [G loss: 0.999957]\n",
      "epoch:1 step:6095[D loss: 0.999986] [G loss: 1.000021]\n",
      "epoch:1 step:6100[D loss: 0.999968] [G loss: 1.000053]\n",
      "epoch:1 step:6105[D loss: 0.999993] [G loss: 0.999999]\n",
      "epoch:1 step:6110[D loss: 0.999998] [G loss: 0.999972]\n",
      "epoch:1 step:6115[D loss: 1.000016] [G loss: 0.999969]\n",
      "epoch:1 step:6120[D loss: 0.999981] [G loss: 1.000023]\n",
      "epoch:1 step:6125[D loss: 0.999986] [G loss: 0.999985]\n",
      "epoch:1 step:6130[D loss: 1.000003] [G loss: 0.999999]\n",
      "epoch:1 step:6135[D loss: 0.999990] [G loss: 1.000026]\n",
      "epoch:1 step:6140[D loss: 1.000007] [G loss: 1.000002]\n",
      "epoch:1 step:6145[D loss: 0.999994] [G loss: 1.000001]\n",
      "epoch:1 step:6150[D loss: 0.999994] [G loss: 1.000001]\n",
      "epoch:1 step:6155[D loss: 1.000005] [G loss: 0.999971]\n",
      "epoch:1 step:6160[D loss: 1.000014] [G loss: 0.999968]\n",
      "epoch:1 step:6165[D loss: 0.999994] [G loss: 1.000000]\n",
      "epoch:1 step:6170[D loss: 0.999995] [G loss: 0.999986]\n",
      "epoch:1 step:6175[D loss: 0.999995] [G loss: 0.999999]\n",
      "epoch:1 step:6180[D loss: 0.999991] [G loss: 0.999992]\n",
      "epoch:1 step:6185[D loss: 0.999986] [G loss: 0.999989]\n",
      "epoch:1 step:6190[D loss: 1.000011] [G loss: 0.999938]\n",
      "epoch:1 step:6195[D loss: 0.999997] [G loss: 1.000001]\n",
      "epoch:1 step:6200[D loss: 0.999974] [G loss: 1.000046]\n",
      "##############\n",
      "[0.83947371 0.86515123 0.80507732 0.81675684 0.79170215 0.83521514\n",
      " 0.88550273 0.84804497 0.80652604 0.8504042 ]\n",
      "##########\n",
      "epoch:1 step:6205[D loss: 1.000006] [G loss: 1.000010]\n",
      "epoch:1 step:6210[D loss: 0.999994] [G loss: 0.999978]\n",
      "epoch:1 step:6215[D loss: 0.999997] [G loss: 0.999998]\n",
      "epoch:1 step:6220[D loss: 1.000001] [G loss: 0.999961]\n",
      "epoch:1 step:6225[D loss: 0.999988] [G loss: 0.999992]\n",
      "epoch:1 step:6230[D loss: 0.999983] [G loss: 1.000032]\n",
      "epoch:1 step:6235[D loss: 0.999996] [G loss: 1.000030]\n",
      "epoch:1 step:6240[D loss: 1.000002] [G loss: 1.000026]\n",
      "epoch:1 step:6245[D loss: 0.999998] [G loss: 1.000000]\n",
      "epoch:1 step:6250[D loss: 0.999997] [G loss: 0.999990]\n",
      "epoch:1 step:6255[D loss: 1.000001] [G loss: 1.000014]\n",
      "epoch:1 step:6260[D loss: 0.999993] [G loss: 1.000023]\n",
      "epoch:1 step:6265[D loss: 0.999998] [G loss: 1.000040]\n",
      "epoch:1 step:6270[D loss: 1.000007] [G loss: 1.000005]\n",
      "epoch:1 step:6275[D loss: 0.999992] [G loss: 1.000020]\n",
      "epoch:1 step:6280[D loss: 1.000003] [G loss: 0.999976]\n",
      "epoch:1 step:6285[D loss: 0.999988] [G loss: 1.000015]\n",
      "epoch:1 step:6290[D loss: 0.999987] [G loss: 1.000033]\n",
      "epoch:1 step:6295[D loss: 0.999982] [G loss: 1.000034]\n",
      "epoch:1 step:6300[D loss: 0.999983] [G loss: 1.000033]\n",
      "epoch:1 step:6305[D loss: 0.999991] [G loss: 0.999991]\n",
      "epoch:1 step:6310[D loss: 0.999979] [G loss: 1.000023]\n",
      "epoch:1 step:6315[D loss: 0.999985] [G loss: 1.000004]\n",
      "epoch:1 step:6320[D loss: 0.999989] [G loss: 1.000034]\n",
      "epoch:1 step:6325[D loss: 0.999969] [G loss: 1.000054]\n",
      "epoch:1 step:6330[D loss: 0.999992] [G loss: 1.000040]\n",
      "epoch:1 step:6335[D loss: 0.999998] [G loss: 1.000004]\n",
      "epoch:1 step:6340[D loss: 1.000005] [G loss: 1.000004]\n",
      "epoch:1 step:6345[D loss: 0.999989] [G loss: 1.000024]\n",
      "epoch:1 step:6350[D loss: 0.999981] [G loss: 1.000011]\n",
      "epoch:1 step:6355[D loss: 0.999983] [G loss: 1.000042]\n",
      "epoch:1 step:6360[D loss: 0.999981] [G loss: 1.000017]\n",
      "epoch:1 step:6365[D loss: 0.999982] [G loss: 1.000011]\n",
      "epoch:1 step:6370[D loss: 1.000014] [G loss: 0.999983]\n",
      "epoch:1 step:6375[D loss: 0.999980] [G loss: 0.999989]\n",
      "epoch:1 step:6380[D loss: 0.999989] [G loss: 1.000016]\n",
      "epoch:1 step:6385[D loss: 0.999993] [G loss: 1.000011]\n",
      "epoch:1 step:6390[D loss: 0.999994] [G loss: 1.000018]\n",
      "epoch:1 step:6395[D loss: 1.000004] [G loss: 1.000011]\n",
      "epoch:1 step:6400[D loss: 0.999987] [G loss: 0.999993]\n",
      "##############\n",
      "[0.85306006 0.87874714 0.80053498 0.81916896 0.77462209 0.83100917\n",
      " 0.86920908 0.81041236 0.81964815 0.82976083]\n",
      "##########\n",
      "epoch:1 step:6405[D loss: 0.999979] [G loss: 1.000033]\n",
      "epoch:1 step:6410[D loss: 0.999985] [G loss: 1.000034]\n",
      "epoch:1 step:6415[D loss: 0.999979] [G loss: 1.000042]\n",
      "epoch:1 step:6420[D loss: 0.999992] [G loss: 1.000021]\n",
      "epoch:1 step:6425[D loss: 0.999996] [G loss: 0.999994]\n",
      "epoch:1 step:6430[D loss: 1.000000] [G loss: 1.000040]\n",
      "epoch:1 step:6435[D loss: 0.999991] [G loss: 1.000019]\n",
      "epoch:1 step:6440[D loss: 0.999997] [G loss: 1.000019]\n",
      "epoch:1 step:6445[D loss: 0.999974] [G loss: 1.000050]\n",
      "epoch:1 step:6450[D loss: 0.999997] [G loss: 1.000024]\n",
      "epoch:1 step:6455[D loss: 1.000029] [G loss: 0.999942]\n",
      "epoch:1 step:6460[D loss: 0.999986] [G loss: 0.999997]\n",
      "epoch:1 step:6465[D loss: 0.999973] [G loss: 1.000052]\n",
      "epoch:1 step:6470[D loss: 0.999979] [G loss: 1.000038]\n",
      "epoch:1 step:6475[D loss: 0.999977] [G loss: 1.000037]\n",
      "epoch:1 step:6480[D loss: 0.999987] [G loss: 1.000034]\n",
      "epoch:1 step:6485[D loss: 0.999989] [G loss: 1.000009]\n",
      "epoch:1 step:6490[D loss: 0.999986] [G loss: 1.000013]\n",
      "epoch:1 step:6495[D loss: 0.999985] [G loss: 1.000028]\n",
      "epoch:1 step:6500[D loss: 0.999991] [G loss: 0.999991]\n",
      "epoch:1 step:6505[D loss: 0.999973] [G loss: 1.000043]\n",
      "epoch:1 step:6510[D loss: 0.999990] [G loss: 1.000017]\n",
      "epoch:1 step:6515[D loss: 0.999983] [G loss: 1.000007]\n",
      "epoch:1 step:6520[D loss: 0.999989] [G loss: 0.999991]\n",
      "epoch:1 step:6525[D loss: 0.999992] [G loss: 1.000020]\n",
      "epoch:1 step:6530[D loss: 1.000000] [G loss: 1.000018]\n",
      "epoch:1 step:6535[D loss: 0.999991] [G loss: 0.999998]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1 step:6540[D loss: 0.999978] [G loss: 1.000038]\n",
      "epoch:1 step:6545[D loss: 0.999976] [G loss: 1.000019]\n",
      "epoch:1 step:6550[D loss: 0.999991] [G loss: 1.000028]\n",
      "epoch:1 step:6555[D loss: 0.999988] [G loss: 1.000038]\n",
      "epoch:1 step:6560[D loss: 0.999993] [G loss: 1.000010]\n",
      "epoch:1 step:6565[D loss: 1.000009] [G loss: 1.000002]\n",
      "epoch:1 step:6570[D loss: 1.000017] [G loss: 1.000005]\n",
      "epoch:1 step:6575[D loss: 0.999998] [G loss: 0.999981]\n",
      "epoch:1 step:6580[D loss: 0.999975] [G loss: 0.999999]\n",
      "epoch:1 step:6585[D loss: 0.999985] [G loss: 1.000016]\n",
      "epoch:1 step:6590[D loss: 0.999978] [G loss: 1.000026]\n",
      "epoch:1 step:6595[D loss: 0.999992] [G loss: 0.999999]\n",
      "epoch:1 step:6600[D loss: 1.000004] [G loss: 1.000006]\n",
      "##############\n",
      "[0.86241227 0.86914287 0.79805163 0.82925797 0.79071164 0.81295851\n",
      " 0.86883064 0.78947399 0.84370357 0.82288781]\n",
      "##########\n",
      "epoch:1 step:6605[D loss: 0.999989] [G loss: 1.000033]\n",
      "epoch:1 step:6610[D loss: 0.999974] [G loss: 1.000067]\n",
      "epoch:1 step:6615[D loss: 0.999984] [G loss: 1.000041]\n",
      "epoch:1 step:6620[D loss: 0.999991] [G loss: 0.999971]\n",
      "epoch:1 step:6625[D loss: 1.000000] [G loss: 0.999974]\n",
      "epoch:1 step:6630[D loss: 0.999975] [G loss: 1.000060]\n",
      "epoch:1 step:6635[D loss: 0.999986] [G loss: 1.000072]\n",
      "epoch:1 step:6640[D loss: 0.999976] [G loss: 1.000035]\n",
      "epoch:1 step:6645[D loss: 0.999987] [G loss: 1.000035]\n",
      "epoch:1 step:6650[D loss: 0.999973] [G loss: 1.000053]\n",
      "epoch:1 step:6655[D loss: 0.999972] [G loss: 1.000057]\n",
      "epoch:1 step:6660[D loss: 0.999975] [G loss: 1.000040]\n",
      "epoch:1 step:6665[D loss: 0.999998] [G loss: 1.000007]\n",
      "epoch:1 step:6670[D loss: 1.000010] [G loss: 0.999996]\n",
      "epoch:1 step:6675[D loss: 0.999993] [G loss: 1.000019]\n",
      "epoch:1 step:6680[D loss: 0.999997] [G loss: 1.000024]\n",
      "epoch:1 step:6685[D loss: 0.999984] [G loss: 1.000024]\n",
      "epoch:1 step:6690[D loss: 0.999981] [G loss: 1.000056]\n",
      "epoch:1 step:6695[D loss: 0.999992] [G loss: 1.000034]\n",
      "epoch:1 step:6700[D loss: 0.999973] [G loss: 1.000039]\n",
      "epoch:1 step:6705[D loss: 0.999981] [G loss: 0.999998]\n",
      "epoch:1 step:6710[D loss: 0.999985] [G loss: 1.000002]\n",
      "epoch:1 step:6715[D loss: 0.999975] [G loss: 1.000020]\n",
      "epoch:1 step:6720[D loss: 0.999994] [G loss: 1.000006]\n",
      "epoch:1 step:6725[D loss: 1.000003] [G loss: 0.999990]\n",
      "epoch:1 step:6730[D loss: 1.000007] [G loss: 0.999987]\n",
      "epoch:1 step:6735[D loss: 0.999989] [G loss: 1.000008]\n",
      "epoch:1 step:6740[D loss: 0.999991] [G loss: 1.000029]\n",
      "epoch:1 step:6745[D loss: 0.999996] [G loss: 1.000021]\n",
      "epoch:1 step:6750[D loss: 0.999985] [G loss: 0.999989]\n",
      "epoch:1 step:6755[D loss: 0.999983] [G loss: 1.000053]\n",
      "epoch:1 step:6760[D loss: 0.999969] [G loss: 1.000058]\n",
      "epoch:1 step:6765[D loss: 0.999988] [G loss: 1.000021]\n",
      "epoch:1 step:6770[D loss: 1.000002] [G loss: 1.000004]\n",
      "epoch:1 step:6775[D loss: 0.999988] [G loss: 1.000027]\n",
      "epoch:1 step:6780[D loss: 0.999994] [G loss: 1.000011]\n",
      "epoch:1 step:6785[D loss: 1.000000] [G loss: 1.000048]\n",
      "epoch:1 step:6790[D loss: 0.999990] [G loss: 1.000010]\n",
      "epoch:1 step:6795[D loss: 0.999985] [G loss: 1.000008]\n",
      "epoch:1 step:6800[D loss: 0.999992] [G loss: 1.000037]\n",
      "##############\n",
      "[0.8508339  0.87559105 0.80862175 0.80541314 0.78355543 0.8205007\n",
      " 0.87257742 0.8191691  0.80572091 0.81032726]\n",
      "##########\n",
      "epoch:1 step:6805[D loss: 0.999971] [G loss: 1.000063]\n",
      "epoch:1 step:6810[D loss: 0.999981] [G loss: 1.000030]\n",
      "epoch:1 step:6815[D loss: 0.999989] [G loss: 1.000015]\n",
      "epoch:1 step:6820[D loss: 0.999976] [G loss: 1.000033]\n",
      "epoch:1 step:6825[D loss: 0.999987] [G loss: 1.000031]\n",
      "epoch:1 step:6830[D loss: 0.999991] [G loss: 1.000025]\n",
      "epoch:1 step:6835[D loss: 0.999984] [G loss: 1.000015]\n",
      "epoch:1 step:6840[D loss: 1.000004] [G loss: 1.000013]\n",
      "epoch:1 step:6845[D loss: 0.999994] [G loss: 0.999987]\n",
      "epoch:1 step:6850[D loss: 0.999990] [G loss: 0.999992]\n",
      "epoch:1 step:6855[D loss: 0.999975] [G loss: 1.000047]\n",
      "epoch:1 step:6860[D loss: 0.999981] [G loss: 1.000066]\n",
      "epoch:1 step:6865[D loss: 0.999974] [G loss: 1.000042]\n",
      "epoch:1 step:6870[D loss: 0.999981] [G loss: 1.000036]\n",
      "epoch:1 step:6875[D loss: 0.999969] [G loss: 1.000048]\n",
      "epoch:1 step:6880[D loss: 0.999980] [G loss: 1.000044]\n",
      "epoch:1 step:6885[D loss: 0.999996] [G loss: 1.000005]\n",
      "epoch:1 step:6890[D loss: 0.999975] [G loss: 1.000036]\n",
      "epoch:1 step:6895[D loss: 0.999986] [G loss: 1.000033]\n",
      "epoch:1 step:6900[D loss: 0.999987] [G loss: 1.000020]\n",
      "epoch:1 step:6905[D loss: 0.999973] [G loss: 1.000047]\n",
      "epoch:1 step:6910[D loss: 0.999977] [G loss: 1.000014]\n",
      "epoch:1 step:6915[D loss: 0.999999] [G loss: 0.999997]\n",
      "epoch:1 step:6920[D loss: 0.999988] [G loss: 0.999991]\n",
      "epoch:1 step:6925[D loss: 0.999980] [G loss: 1.000030]\n",
      "epoch:1 step:6930[D loss: 0.999980] [G loss: 1.000025]\n",
      "epoch:1 step:6935[D loss: 1.000005] [G loss: 0.999993]\n",
      "epoch:1 step:6940[D loss: 0.999984] [G loss: 1.000027]\n",
      "epoch:1 step:6945[D loss: 0.999984] [G loss: 1.000040]\n",
      "epoch:1 step:6950[D loss: 0.999989] [G loss: 1.000013]\n",
      "epoch:1 step:6955[D loss: 0.999998] [G loss: 0.999990]\n",
      "epoch:1 step:6960[D loss: 0.999969] [G loss: 1.000050]\n",
      "epoch:1 step:6965[D loss: 0.999961] [G loss: 1.000030]\n",
      "epoch:1 step:6970[D loss: 0.999976] [G loss: 1.000053]\n",
      "epoch:1 step:6975[D loss: 0.999996] [G loss: 1.000038]\n",
      "epoch:1 step:6980[D loss: 0.999979] [G loss: 1.000042]\n",
      "epoch:1 step:6985[D loss: 0.999992] [G loss: 1.000042]\n",
      "epoch:1 step:6990[D loss: 0.999982] [G loss: 1.000047]\n",
      "epoch:1 step:6995[D loss: 0.999991] [G loss: 1.000014]\n",
      "epoch:1 step:7000[D loss: 0.999995] [G loss: 1.000032]\n",
      "##############\n",
      "[0.85575485 0.87348791 0.78414984 0.81880455 0.79050533 0.82675187\n",
      " 0.87115775 0.82962319 0.84010674 0.84958717]\n",
      "##########\n",
      "epoch:1 step:7005[D loss: 0.999977] [G loss: 1.000042]\n",
      "epoch:1 step:7010[D loss: 0.999981] [G loss: 1.000044]\n",
      "epoch:1 step:7015[D loss: 0.999989] [G loss: 1.000041]\n",
      "epoch:1 step:7020[D loss: 0.999997] [G loss: 1.000010]\n",
      "epoch:1 step:7025[D loss: 0.999989] [G loss: 1.000004]\n",
      "epoch:1 step:7030[D loss: 0.999985] [G loss: 1.000028]\n",
      "epoch:1 step:7035[D loss: 0.999979] [G loss: 1.000036]\n",
      "epoch:1 step:7040[D loss: 0.999984] [G loss: 1.000021]\n",
      "epoch:1 step:7045[D loss: 0.999984] [G loss: 1.000028]\n",
      "epoch:1 step:7050[D loss: 0.999984] [G loss: 1.000012]\n",
      "epoch:1 step:7055[D loss: 0.999979] [G loss: 1.000039]\n",
      "epoch:1 step:7060[D loss: 0.999991] [G loss: 1.000038]\n",
      "epoch:1 step:7065[D loss: 0.999987] [G loss: 1.000052]\n",
      "epoch:1 step:7070[D loss: 0.999976] [G loss: 1.000048]\n",
      "epoch:1 step:7075[D loss: 0.999991] [G loss: 0.999974]\n",
      "epoch:1 step:7080[D loss: 0.999984] [G loss: 1.000035]\n",
      "epoch:1 step:7085[D loss: 0.999968] [G loss: 1.000041]\n",
      "epoch:1 step:7090[D loss: 0.999983] [G loss: 1.000018]\n",
      "epoch:1 step:7095[D loss: 0.999987] [G loss: 1.000021]\n",
      "epoch:1 step:7100[D loss: 0.999983] [G loss: 1.000032]\n",
      "epoch:1 step:7105[D loss: 0.999983] [G loss: 1.000030]\n",
      "epoch:1 step:7110[D loss: 0.999985] [G loss: 1.000056]\n",
      "epoch:1 step:7115[D loss: 0.999986] [G loss: 1.000036]\n",
      "epoch:1 step:7120[D loss: 0.999993] [G loss: 1.000015]\n",
      "epoch:1 step:7125[D loss: 0.999971] [G loss: 1.000024]\n",
      "epoch:1 step:7130[D loss: 0.999991] [G loss: 1.000025]\n",
      "epoch:1 step:7135[D loss: 1.000004] [G loss: 1.000000]\n",
      "epoch:1 step:7140[D loss: 0.999969] [G loss: 1.000032]\n",
      "epoch:1 step:7145[D loss: 0.999982] [G loss: 1.000011]\n",
      "epoch:1 step:7150[D loss: 0.999994] [G loss: 1.000016]\n",
      "epoch:1 step:7155[D loss: 0.999967] [G loss: 1.000011]\n",
      "epoch:1 step:7160[D loss: 0.999967] [G loss: 1.000022]\n",
      "epoch:1 step:7165[D loss: 0.999985] [G loss: 1.000017]\n",
      "epoch:1 step:7170[D loss: 0.999966] [G loss: 1.000044]\n",
      "epoch:1 step:7175[D loss: 0.999969] [G loss: 1.000034]\n",
      "epoch:1 step:7180[D loss: 0.999995] [G loss: 1.000008]\n",
      "epoch:1 step:7185[D loss: 0.999998] [G loss: 1.000028]\n",
      "epoch:1 step:7190[D loss: 0.999972] [G loss: 1.000023]\n",
      "epoch:1 step:7195[D loss: 0.999969] [G loss: 1.000037]\n",
      "epoch:1 step:7200[D loss: 0.999986] [G loss: 1.000045]\n",
      "##############\n",
      "[0.84872328 0.8729987  0.80713546 0.83936666 0.79071199 0.80468016\n",
      " 0.86369339 0.82785739 0.82341573 0.83658116]\n",
      "##########\n",
      "epoch:1 step:7205[D loss: 0.999989] [G loss: 1.000033]\n",
      "epoch:1 step:7210[D loss: 0.999970] [G loss: 1.000055]\n",
      "epoch:1 step:7215[D loss: 0.999993] [G loss: 1.000028]\n",
      "epoch:1 step:7220[D loss: 0.999982] [G loss: 1.000003]\n",
      "epoch:1 step:7225[D loss: 0.999982] [G loss: 1.000005]\n",
      "epoch:1 step:7230[D loss: 0.999978] [G loss: 1.000037]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1 step:7235[D loss: 0.999972] [G loss: 1.000011]\n",
      "epoch:1 step:7240[D loss: 0.999982] [G loss: 1.000026]\n",
      "epoch:1 step:7245[D loss: 0.999972] [G loss: 1.000030]\n",
      "epoch:1 step:7250[D loss: 0.999982] [G loss: 1.000029]\n",
      "epoch:1 step:7255[D loss: 0.999994] [G loss: 1.000036]\n",
      "epoch:1 step:7260[D loss: 0.999973] [G loss: 1.000017]\n",
      "epoch:1 step:7265[D loss: 0.999990] [G loss: 1.000003]\n",
      "epoch:1 step:7270[D loss: 0.999981] [G loss: 1.000014]\n",
      "epoch:1 step:7275[D loss: 0.999982] [G loss: 1.000045]\n",
      "epoch:1 step:7280[D loss: 0.999986] [G loss: 1.000021]\n",
      "epoch:1 step:7285[D loss: 0.999975] [G loss: 1.000029]\n",
      "epoch:1 step:7290[D loss: 0.999977] [G loss: 1.000038]\n",
      "epoch:1 step:7295[D loss: 0.999984] [G loss: 1.000019]\n",
      "epoch:1 step:7300[D loss: 0.999976] [G loss: 1.000042]\n",
      "epoch:1 step:7305[D loss: 0.999980] [G loss: 1.000050]\n",
      "epoch:1 step:7310[D loss: 0.999985] [G loss: 1.000042]\n",
      "epoch:1 step:7315[D loss: 0.999976] [G loss: 1.000037]\n",
      "epoch:1 step:7320[D loss: 0.999980] [G loss: 1.000031]\n",
      "epoch:1 step:7325[D loss: 0.999986] [G loss: 1.000046]\n",
      "epoch:1 step:7330[D loss: 0.999979] [G loss: 1.000022]\n",
      "epoch:1 step:7335[D loss: 0.999975] [G loss: 1.000031]\n",
      "epoch:1 step:7340[D loss: 0.999980] [G loss: 1.000036]\n",
      "epoch:1 step:7345[D loss: 0.999976] [G loss: 1.000019]\n",
      "epoch:1 step:7350[D loss: 0.999986] [G loss: 1.000048]\n",
      "epoch:1 step:7355[D loss: 0.999988] [G loss: 0.999999]\n",
      "epoch:1 step:7360[D loss: 0.999978] [G loss: 1.000029]\n",
      "epoch:1 step:7365[D loss: 1.000007] [G loss: 1.000003]\n",
      "epoch:1 step:7370[D loss: 0.999979] [G loss: 1.000051]\n",
      "epoch:1 step:7375[D loss: 0.999976] [G loss: 1.000036]\n",
      "epoch:1 step:7380[D loss: 0.999975] [G loss: 1.000030]\n",
      "epoch:1 step:7385[D loss: 0.999977] [G loss: 1.000051]\n",
      "epoch:1 step:7390[D loss: 0.999973] [G loss: 1.000041]\n",
      "epoch:1 step:7395[D loss: 0.999991] [G loss: 1.000018]\n",
      "epoch:1 step:7400[D loss: 0.999991] [G loss: 1.000037]\n",
      "##############\n",
      "[0.85736888 0.88156124 0.81435861 0.81391112 0.80207343 0.83576748\n",
      " 0.88699623 0.80743973 0.8155941  0.81963961]\n",
      "##########\n",
      "epoch:1 step:7405[D loss: 0.999987] [G loss: 1.000025]\n",
      "epoch:1 step:7410[D loss: 0.999981] [G loss: 1.000027]\n",
      "epoch:1 step:7415[D loss: 0.999991] [G loss: 1.000015]\n",
      "epoch:1 step:7420[D loss: 0.999982] [G loss: 1.000028]\n",
      "epoch:1 step:7425[D loss: 0.999972] [G loss: 1.000029]\n",
      "epoch:1 step:7430[D loss: 0.999981] [G loss: 1.000043]\n",
      "epoch:1 step:7435[D loss: 0.999979] [G loss: 1.000048]\n",
      "epoch:1 step:7440[D loss: 0.999979] [G loss: 1.000033]\n",
      "epoch:1 step:7445[D loss: 0.999987] [G loss: 1.000027]\n",
      "epoch:1 step:7450[D loss: 0.999992] [G loss: 1.000012]\n",
      "epoch:1 step:7455[D loss: 0.999989] [G loss: 1.000011]\n",
      "epoch:1 step:7460[D loss: 0.999986] [G loss: 1.000016]\n",
      "epoch:1 step:7465[D loss: 0.999979] [G loss: 1.000029]\n",
      "epoch:1 step:7470[D loss: 0.999986] [G loss: 1.000028]\n",
      "epoch:1 step:7475[D loss: 0.999985] [G loss: 1.000011]\n",
      "epoch:1 step:7480[D loss: 0.999977] [G loss: 1.000044]\n",
      "epoch:1 step:7485[D loss: 0.999980] [G loss: 1.000022]\n",
      "epoch:1 step:7490[D loss: 0.999974] [G loss: 1.000012]\n",
      "epoch:1 step:7495[D loss: 0.999990] [G loss: 0.999986]\n",
      "epoch:1 step:7500[D loss: 0.999977] [G loss: 1.000021]\n",
      "epoch:1 step:7505[D loss: 0.999976] [G loss: 1.000038]\n",
      "epoch:1 step:7510[D loss: 0.999981] [G loss: 1.000032]\n",
      "epoch:1 step:7515[D loss: 0.999984] [G loss: 1.000017]\n",
      "epoch:1 step:7520[D loss: 0.999980] [G loss: 1.000041]\n",
      "epoch:1 step:7525[D loss: 0.999982] [G loss: 1.000040]\n",
      "epoch:1 step:7530[D loss: 0.999969] [G loss: 1.000039]\n",
      "epoch:1 step:7535[D loss: 0.999977] [G loss: 1.000041]\n",
      "epoch:1 step:7540[D loss: 0.999974] [G loss: 1.000034]\n",
      "epoch:1 step:7545[D loss: 0.999979] [G loss: 1.000009]\n",
      "epoch:1 step:7550[D loss: 0.999988] [G loss: 1.000026]\n",
      "epoch:1 step:7555[D loss: 0.999972] [G loss: 1.000042]\n",
      "epoch:1 step:7560[D loss: 0.999991] [G loss: 1.000043]\n",
      "epoch:1 step:7565[D loss: 0.999986] [G loss: 1.000016]\n",
      "epoch:1 step:7570[D loss: 0.999988] [G loss: 1.000020]\n",
      "epoch:1 step:7575[D loss: 0.999980] [G loss: 1.000048]\n",
      "epoch:1 step:7580[D loss: 0.999975] [G loss: 1.000039]\n",
      "epoch:1 step:7585[D loss: 0.999991] [G loss: 1.000030]\n",
      "epoch:1 step:7590[D loss: 0.999988] [G loss: 1.000030]\n",
      "epoch:1 step:7595[D loss: 0.999994] [G loss: 1.000017]\n",
      "epoch:1 step:7600[D loss: 1.000007] [G loss: 1.000001]\n",
      "##############\n",
      "[0.83140447 0.88428935 0.82935331 0.82905025 0.78136338 0.81633712\n",
      " 0.86517366 0.83391146 0.81093861 0.84614581]\n",
      "##########\n",
      "epoch:1 step:7605[D loss: 0.999962] [G loss: 1.000040]\n",
      "epoch:1 step:7610[D loss: 0.999984] [G loss: 1.000033]\n",
      "epoch:1 step:7615[D loss: 0.999983] [G loss: 1.000035]\n",
      "epoch:1 step:7620[D loss: 0.999979] [G loss: 1.000016]\n",
      "epoch:1 step:7625[D loss: 0.999975] [G loss: 1.000040]\n",
      "epoch:1 step:7630[D loss: 0.999975] [G loss: 1.000051]\n",
      "epoch:1 step:7635[D loss: 0.999989] [G loss: 1.000009]\n",
      "epoch:1 step:7640[D loss: 0.999990] [G loss: 0.999991]\n",
      "epoch:1 step:7645[D loss: 0.999977] [G loss: 1.000038]\n",
      "epoch:1 step:7650[D loss: 0.999985] [G loss: 1.000018]\n",
      "epoch:1 step:7655[D loss: 0.999988] [G loss: 1.000026]\n",
      "epoch:1 step:7660[D loss: 0.999986] [G loss: 1.000028]\n",
      "epoch:1 step:7665[D loss: 0.999978] [G loss: 1.000032]\n",
      "epoch:1 step:7670[D loss: 0.999977] [G loss: 1.000034]\n",
      "epoch:1 step:7675[D loss: 0.999988] [G loss: 1.000038]\n",
      "epoch:1 step:7680[D loss: 0.999977] [G loss: 1.000037]\n",
      "epoch:1 step:7685[D loss: 0.999985] [G loss: 1.000031]\n",
      "epoch:1 step:7690[D loss: 0.999998] [G loss: 1.000032]\n",
      "epoch:1 step:7695[D loss: 0.999975] [G loss: 1.000032]\n",
      "epoch:1 step:7700[D loss: 0.999978] [G loss: 1.000039]\n",
      "epoch:1 step:7705[D loss: 0.999983] [G loss: 1.000038]\n",
      "epoch:1 step:7710[D loss: 0.999984] [G loss: 1.000035]\n",
      "epoch:1 step:7715[D loss: 0.999983] [G loss: 1.000014]\n",
      "epoch:1 step:7720[D loss: 0.999980] [G loss: 0.999983]\n",
      "epoch:1 step:7725[D loss: 0.999990] [G loss: 1.000030]\n",
      "epoch:1 step:7730[D loss: 0.999974] [G loss: 1.000034]\n",
      "epoch:1 step:7735[D loss: 0.999978] [G loss: 1.000029]\n",
      "epoch:1 step:7740[D loss: 0.999978] [G loss: 1.000032]\n",
      "epoch:1 step:7745[D loss: 0.999982] [G loss: 1.000035]\n",
      "epoch:1 step:7750[D loss: 0.999972] [G loss: 1.000036]\n",
      "epoch:1 step:7755[D loss: 0.999972] [G loss: 1.000045]\n",
      "epoch:1 step:7760[D loss: 1.000024] [G loss: 0.999969]\n",
      "epoch:1 step:7765[D loss: 0.999966] [G loss: 1.000054]\n",
      "epoch:1 step:7770[D loss: 0.999966] [G loss: 1.000044]\n",
      "epoch:1 step:7775[D loss: 0.999971] [G loss: 1.000029]\n",
      "epoch:1 step:7780[D loss: 0.999967] [G loss: 1.000055]\n",
      "epoch:1 step:7785[D loss: 0.999980] [G loss: 1.000040]\n",
      "epoch:1 step:7790[D loss: 0.999989] [G loss: 1.000019]\n",
      "epoch:1 step:7795[D loss: 0.999979] [G loss: 1.000006]\n",
      "epoch:1 step:7800[D loss: 1.000009] [G loss: 0.999975]\n",
      "##############\n",
      "[0.84432571 0.89548649 0.81385807 0.82826085 0.79344988 0.81082885\n",
      " 0.88211087 0.80813711 0.81592447 0.84924081]\n",
      "##########\n",
      "epoch:1 step:7805[D loss: 0.999985] [G loss: 1.000034]\n",
      "epoch:1 step:7810[D loss: 0.999981] [G loss: 1.000021]\n",
      "epoch:2 step:7815[D loss: 0.999985] [G loss: 1.000000]\n",
      "epoch:2 step:7820[D loss: 0.999992] [G loss: 0.999984]\n",
      "epoch:2 step:7825[D loss: 0.999970] [G loss: 1.000026]\n",
      "epoch:2 step:7830[D loss: 0.999974] [G loss: 1.000045]\n",
      "epoch:2 step:7835[D loss: 0.999976] [G loss: 1.000043]\n",
      "epoch:2 step:7840[D loss: 0.999986] [G loss: 1.000035]\n",
      "epoch:2 step:7845[D loss: 0.999983] [G loss: 1.000030]\n",
      "epoch:2 step:7850[D loss: 0.999979] [G loss: 1.000034]\n",
      "epoch:2 step:7855[D loss: 0.999971] [G loss: 1.000043]\n",
      "epoch:2 step:7860[D loss: 0.999972] [G loss: 1.000052]\n",
      "epoch:2 step:7865[D loss: 0.999989] [G loss: 1.000034]\n",
      "epoch:2 step:7870[D loss: 0.999979] [G loss: 1.000052]\n",
      "epoch:2 step:7875[D loss: 0.999973] [G loss: 1.000035]\n",
      "epoch:2 step:7880[D loss: 0.999976] [G loss: 1.000044]\n",
      "epoch:2 step:7885[D loss: 0.999971] [G loss: 1.000024]\n",
      "epoch:2 step:7890[D loss: 0.999986] [G loss: 1.000038]\n",
      "epoch:2 step:7895[D loss: 0.999983] [G loss: 1.000055]\n",
      "epoch:2 step:7900[D loss: 0.999980] [G loss: 1.000030]\n",
      "epoch:2 step:7905[D loss: 0.999981] [G loss: 1.000005]\n",
      "epoch:2 step:7910[D loss: 0.999987] [G loss: 1.000013]\n",
      "epoch:2 step:7915[D loss: 0.999984] [G loss: 1.000023]\n",
      "epoch:2 step:7920[D loss: 0.999983] [G loss: 1.000028]\n",
      "epoch:2 step:7925[D loss: 0.999984] [G loss: 1.000050]\n",
      "epoch:2 step:7930[D loss: 0.999993] [G loss: 1.000037]\n",
      "epoch:2 step:7935[D loss: 0.999981] [G loss: 1.000040]\n",
      "epoch:2 step:7940[D loss: 0.999972] [G loss: 1.000037]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:2 step:7945[D loss: 0.999983] [G loss: 1.000039]\n",
      "epoch:2 step:7950[D loss: 0.999977] [G loss: 1.000011]\n",
      "epoch:2 step:7955[D loss: 0.999988] [G loss: 0.999998]\n",
      "epoch:2 step:7960[D loss: 0.999972] [G loss: 1.000056]\n",
      "epoch:2 step:7965[D loss: 0.999985] [G loss: 1.000015]\n",
      "epoch:2 step:7970[D loss: 0.999975] [G loss: 1.000040]\n",
      "epoch:2 step:7975[D loss: 0.999975] [G loss: 1.000047]\n",
      "epoch:2 step:7980[D loss: 0.999988] [G loss: 1.000040]\n",
      "epoch:2 step:7985[D loss: 0.999987] [G loss: 1.000043]\n",
      "epoch:2 step:7990[D loss: 0.999971] [G loss: 1.000036]\n",
      "epoch:2 step:7995[D loss: 0.999983] [G loss: 1.000037]\n",
      "epoch:2 step:8000[D loss: 0.999979] [G loss: 1.000037]\n",
      "##############\n",
      "[0.83007062 0.85603666 0.79906441 0.80819634 0.80734279 0.82573698\n",
      " 0.86939426 0.82875764 0.84482743 0.83218478]\n",
      "##########\n",
      "epoch:2 step:8005[D loss: 0.999988] [G loss: 1.000030]\n",
      "epoch:2 step:8010[D loss: 0.999980] [G loss: 1.000030]\n",
      "epoch:2 step:8015[D loss: 0.999982] [G loss: 1.000025]\n",
      "epoch:2 step:8020[D loss: 1.000003] [G loss: 1.000001]\n",
      "epoch:2 step:8025[D loss: 0.999970] [G loss: 1.000045]\n",
      "epoch:2 step:8030[D loss: 0.999978] [G loss: 1.000040]\n",
      "epoch:2 step:8035[D loss: 0.999977] [G loss: 1.000036]\n",
      "epoch:2 step:8040[D loss: 0.999975] [G loss: 1.000052]\n",
      "epoch:2 step:8045[D loss: 0.999972] [G loss: 1.000030]\n",
      "epoch:2 step:8050[D loss: 0.999974] [G loss: 1.000016]\n",
      "epoch:2 step:8055[D loss: 0.999982] [G loss: 1.000038]\n",
      "epoch:2 step:8060[D loss: 1.000008] [G loss: 0.999991]\n",
      "epoch:2 step:8065[D loss: 0.999983] [G loss: 1.000010]\n",
      "epoch:2 step:8070[D loss: 0.999962] [G loss: 1.000063]\n",
      "epoch:2 step:8075[D loss: 0.999974] [G loss: 1.000039]\n",
      "epoch:2 step:8080[D loss: 0.999977] [G loss: 1.000014]\n",
      "epoch:2 step:8085[D loss: 0.999974] [G loss: 1.000038]\n",
      "epoch:2 step:8090[D loss: 0.999982] [G loss: 1.000051]\n",
      "epoch:2 step:8095[D loss: 0.999981] [G loss: 1.000038]\n",
      "epoch:2 step:8100[D loss: 0.999990] [G loss: 1.000006]\n",
      "epoch:2 step:8105[D loss: 0.999986] [G loss: 1.000038]\n",
      "epoch:2 step:8110[D loss: 0.999982] [G loss: 1.000023]\n",
      "epoch:2 step:8115[D loss: 1.000008] [G loss: 0.999962]\n",
      "epoch:2 step:8120[D loss: 0.999967] [G loss: 1.000039]\n",
      "epoch:2 step:8125[D loss: 0.999989] [G loss: 0.999993]\n",
      "epoch:2 step:8130[D loss: 0.999984] [G loss: 1.000026]\n",
      "epoch:2 step:8135[D loss: 0.999984] [G loss: 1.000021]\n",
      "epoch:2 step:8140[D loss: 0.999977] [G loss: 1.000024]\n",
      "epoch:2 step:8145[D loss: 0.999977] [G loss: 1.000035]\n",
      "epoch:2 step:8150[D loss: 0.999979] [G loss: 1.000036]\n",
      "epoch:2 step:8155[D loss: 0.999993] [G loss: 1.000042]\n",
      "epoch:2 step:8160[D loss: 0.999985] [G loss: 1.000037]\n",
      "epoch:2 step:8165[D loss: 0.999988] [G loss: 1.000014]\n",
      "epoch:2 step:8170[D loss: 0.999983] [G loss: 1.000022]\n",
      "epoch:2 step:8175[D loss: 0.999983] [G loss: 1.000034]\n",
      "epoch:2 step:8180[D loss: 0.999993] [G loss: 1.000009]\n",
      "epoch:2 step:8185[D loss: 0.999983] [G loss: 1.000039]\n",
      "epoch:2 step:8190[D loss: 0.999982] [G loss: 1.000041]\n",
      "epoch:2 step:8195[D loss: 0.999980] [G loss: 1.000050]\n",
      "epoch:2 step:8200[D loss: 0.999974] [G loss: 1.000048]\n",
      "##############\n",
      "[0.84884041 0.88407216 0.80937015 0.83254611 0.7983375  0.82126333\n",
      " 0.8932051  0.83352677 0.81478611 0.83749155]\n",
      "##########\n",
      "epoch:2 step:8205[D loss: 0.999972] [G loss: 1.000037]\n",
      "epoch:2 step:8210[D loss: 0.999992] [G loss: 1.000005]\n",
      "epoch:2 step:8215[D loss: 0.999972] [G loss: 1.000025]\n",
      "epoch:2 step:8220[D loss: 0.999975] [G loss: 1.000035]\n",
      "epoch:2 step:8225[D loss: 0.999981] [G loss: 1.000023]\n",
      "epoch:2 step:8230[D loss: 0.999986] [G loss: 1.000020]\n",
      "epoch:2 step:8235[D loss: 0.999974] [G loss: 1.000039]\n",
      "epoch:2 step:8240[D loss: 0.999974] [G loss: 1.000037]\n",
      "epoch:2 step:8245[D loss: 0.999967] [G loss: 1.000046]\n",
      "epoch:2 step:8250[D loss: 0.999984] [G loss: 1.000055]\n",
      "epoch:2 step:8255[D loss: 0.999971] [G loss: 1.000044]\n",
      "epoch:2 step:8260[D loss: 0.999984] [G loss: 1.000021]\n",
      "epoch:2 step:8265[D loss: 0.999984] [G loss: 1.000039]\n",
      "epoch:2 step:8270[D loss: 0.999991] [G loss: 1.000031]\n",
      "epoch:2 step:8275[D loss: 0.999986] [G loss: 1.000011]\n",
      "epoch:2 step:8280[D loss: 0.999982] [G loss: 1.000041]\n",
      "epoch:2 step:8285[D loss: 1.000004] [G loss: 1.000004]\n",
      "epoch:2 step:8290[D loss: 0.999983] [G loss: 1.000032]\n",
      "epoch:2 step:8295[D loss: 0.999966] [G loss: 1.000037]\n",
      "epoch:2 step:8300[D loss: 0.999987] [G loss: 1.000023]\n",
      "epoch:2 step:8305[D loss: 0.999984] [G loss: 1.000022]\n",
      "epoch:2 step:8310[D loss: 0.999979] [G loss: 1.000017]\n",
      "epoch:2 step:8315[D loss: 0.999977] [G loss: 1.000003]\n",
      "epoch:2 step:8320[D loss: 0.999991] [G loss: 1.000036]\n",
      "epoch:2 step:8325[D loss: 0.999987] [G loss: 1.000034]\n",
      "epoch:2 step:8330[D loss: 0.999965] [G loss: 1.000018]\n",
      "epoch:2 step:8335[D loss: 0.999976] [G loss: 1.000024]\n",
      "epoch:2 step:8340[D loss: 0.999970] [G loss: 1.000018]\n",
      "epoch:2 step:8345[D loss: 0.999972] [G loss: 1.000018]\n",
      "epoch:2 step:8350[D loss: 0.999976] [G loss: 1.000022]\n",
      "epoch:2 step:8355[D loss: 0.999981] [G loss: 1.000013]\n",
      "epoch:2 step:8360[D loss: 0.999993] [G loss: 1.000000]\n",
      "epoch:2 step:8365[D loss: 0.999981] [G loss: 1.000026]\n",
      "epoch:2 step:8370[D loss: 0.999980] [G loss: 1.000038]\n",
      "epoch:2 step:8375[D loss: 0.999983] [G loss: 1.000019]\n",
      "epoch:2 step:8380[D loss: 0.999980] [G loss: 1.000053]\n",
      "epoch:2 step:8385[D loss: 0.999981] [G loss: 1.000034]\n",
      "epoch:2 step:8390[D loss: 0.999982] [G loss: 1.000027]\n",
      "epoch:2 step:8395[D loss: 0.999987] [G loss: 1.000020]\n",
      "epoch:2 step:8400[D loss: 0.999992] [G loss: 1.000024]\n",
      "##############\n",
      "[0.87193597 0.84913776 0.79972957 0.82611063 0.76858145 0.82019505\n",
      " 0.85568768 0.8369412  0.82523648 0.82705506]\n",
      "##########\n",
      "epoch:2 step:8405[D loss: 0.999986] [G loss: 1.000029]\n",
      "epoch:2 step:8410[D loss: 0.999999] [G loss: 1.000037]\n",
      "epoch:2 step:8415[D loss: 0.999983] [G loss: 1.000023]\n",
      "epoch:2 step:8420[D loss: 0.999975] [G loss: 1.000014]\n",
      "epoch:2 step:8425[D loss: 0.999991] [G loss: 1.000005]\n",
      "epoch:2 step:8430[D loss: 0.999974] [G loss: 1.000044]\n",
      "epoch:2 step:8435[D loss: 0.999983] [G loss: 1.000029]\n",
      "epoch:2 step:8440[D loss: 0.999984] [G loss: 1.000048]\n",
      "epoch:2 step:8445[D loss: 0.999978] [G loss: 1.000040]\n",
      "epoch:2 step:8450[D loss: 0.999981] [G loss: 1.000040]\n",
      "epoch:2 step:8455[D loss: 0.999995] [G loss: 1.000024]\n",
      "epoch:2 step:8460[D loss: 0.999981] [G loss: 1.000044]\n",
      "epoch:2 step:8465[D loss: 0.999998] [G loss: 0.999975]\n",
      "epoch:2 step:8470[D loss: 0.999963] [G loss: 1.000014]\n",
      "epoch:2 step:8475[D loss: 0.999974] [G loss: 1.000052]\n",
      "epoch:2 step:8480[D loss: 0.999969] [G loss: 1.000049]\n",
      "epoch:2 step:8485[D loss: 0.999993] [G loss: 1.000044]\n",
      "epoch:2 step:8490[D loss: 0.999984] [G loss: 1.000015]\n",
      "epoch:2 step:8495[D loss: 0.999969] [G loss: 1.000058]\n",
      "epoch:2 step:8500[D loss: 0.999984] [G loss: 1.000039]\n",
      "epoch:2 step:8505[D loss: 0.999977] [G loss: 1.000040]\n",
      "epoch:2 step:8510[D loss: 0.999972] [G loss: 1.000042]\n",
      "epoch:2 step:8515[D loss: 0.999985] [G loss: 1.000036]\n",
      "epoch:2 step:8520[D loss: 0.999983] [G loss: 1.000049]\n",
      "epoch:2 step:8525[D loss: 0.999978] [G loss: 1.000028]\n",
      "epoch:2 step:8530[D loss: 0.999977] [G loss: 1.000031]\n",
      "epoch:2 step:8535[D loss: 0.999994] [G loss: 1.000015]\n",
      "epoch:2 step:8540[D loss: 0.999991] [G loss: 1.000041]\n",
      "epoch:2 step:8545[D loss: 0.999953] [G loss: 1.000047]\n",
      "epoch:2 step:8550[D loss: 0.999983] [G loss: 1.000014]\n",
      "epoch:2 step:8555[D loss: 1.000003] [G loss: 0.999972]\n",
      "epoch:2 step:8560[D loss: 0.999958] [G loss: 1.000042]\n",
      "epoch:2 step:8565[D loss: 0.999962] [G loss: 1.000080]\n",
      "epoch:2 step:8570[D loss: 0.999980] [G loss: 1.000048]\n",
      "epoch:2 step:8575[D loss: 0.999976] [G loss: 1.000005]\n",
      "epoch:2 step:8580[D loss: 1.000007] [G loss: 0.999982]\n",
      "epoch:2 step:8585[D loss: 0.999985] [G loss: 0.999999]\n",
      "epoch:2 step:8590[D loss: 0.999985] [G loss: 1.000031]\n",
      "epoch:2 step:8595[D loss: 0.999996] [G loss: 0.999981]\n",
      "epoch:2 step:8600[D loss: 0.999993] [G loss: 0.999978]\n",
      "##############\n",
      "[0.84203088 0.87535038 0.83043669 0.83819372 0.77603234 0.83420143\n",
      " 0.87856967 0.85900665 0.83242332 0.82347202]\n",
      "##########\n",
      "epoch:2 step:8605[D loss: 0.999978] [G loss: 1.000077]\n",
      "epoch:2 step:8610[D loss: 0.999952] [G loss: 1.000048]\n",
      "epoch:2 step:8615[D loss: 0.999979] [G loss: 1.000040]\n",
      "epoch:2 step:8620[D loss: 0.999981] [G loss: 1.000015]\n",
      "epoch:2 step:8625[D loss: 0.999983] [G loss: 0.999995]\n",
      "epoch:2 step:8630[D loss: 0.999984] [G loss: 1.000009]\n",
      "epoch:2 step:8635[D loss: 0.999969] [G loss: 1.000056]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:2 step:8640[D loss: 0.999970] [G loss: 1.000058]\n",
      "epoch:2 step:8645[D loss: 0.999984] [G loss: 1.000035]\n",
      "epoch:2 step:8650[D loss: 0.999971] [G loss: 1.000044]\n",
      "epoch:2 step:8655[D loss: 0.999981] [G loss: 1.000041]\n",
      "epoch:2 step:8660[D loss: 0.999976] [G loss: 1.000033]\n",
      "epoch:2 step:8665[D loss: 0.999978] [G loss: 1.000036]\n",
      "epoch:2 step:8670[D loss: 0.999983] [G loss: 1.000029]\n",
      "epoch:2 step:8675[D loss: 0.999994] [G loss: 1.000035]\n",
      "epoch:2 step:8680[D loss: 0.999983] [G loss: 1.000024]\n",
      "epoch:2 step:8685[D loss: 0.999976] [G loss: 1.000024]\n",
      "epoch:2 step:8690[D loss: 0.999980] [G loss: 1.000020]\n",
      "epoch:2 step:8695[D loss: 0.999979] [G loss: 1.000036]\n",
      "epoch:2 step:8700[D loss: 0.999967] [G loss: 1.000048]\n",
      "epoch:2 step:8705[D loss: 0.999985] [G loss: 1.000033]\n",
      "epoch:2 step:8710[D loss: 0.999979] [G loss: 1.000025]\n",
      "epoch:2 step:8715[D loss: 0.999978] [G loss: 1.000039]\n",
      "epoch:2 step:8720[D loss: 0.999999] [G loss: 1.000008]\n",
      "epoch:2 step:8725[D loss: 0.999987] [G loss: 1.000073]\n",
      "epoch:2 step:8730[D loss: 0.999982] [G loss: 1.000016]\n",
      "epoch:2 step:8735[D loss: 0.999975] [G loss: 1.000022]\n",
      "epoch:2 step:8740[D loss: 0.999991] [G loss: 1.000008]\n",
      "epoch:2 step:8745[D loss: 0.999973] [G loss: 1.000050]\n",
      "epoch:2 step:8750[D loss: 0.999972] [G loss: 1.000056]\n",
      "epoch:2 step:8755[D loss: 0.999984] [G loss: 1.000043]\n",
      "epoch:2 step:8760[D loss: 0.999976] [G loss: 1.000046]\n",
      "epoch:2 step:8765[D loss: 0.999974] [G loss: 1.000025]\n",
      "epoch:2 step:8770[D loss: 0.999971] [G loss: 1.000025]\n",
      "epoch:2 step:8775[D loss: 0.999984] [G loss: 1.000014]\n",
      "epoch:2 step:8780[D loss: 0.999977] [G loss: 1.000043]\n",
      "epoch:2 step:8785[D loss: 0.999988] [G loss: 1.000026]\n",
      "epoch:2 step:8790[D loss: 0.999979] [G loss: 1.000033]\n",
      "epoch:2 step:8795[D loss: 0.999976] [G loss: 1.000042]\n",
      "epoch:2 step:8800[D loss: 1.000004] [G loss: 0.999991]\n",
      "##############\n",
      "[0.87732321 0.86838511 0.8130586  0.81374185 0.78026111 0.83778736\n",
      " 0.88429717 0.82778309 0.81422966 0.8121987 ]\n",
      "##########\n",
      "epoch:2 step:8805[D loss: 1.000014] [G loss: 1.000004]\n",
      "epoch:2 step:8810[D loss: 0.999970] [G loss: 1.000069]\n",
      "epoch:2 step:8815[D loss: 0.999977] [G loss: 1.000039]\n",
      "epoch:2 step:8820[D loss: 0.999993] [G loss: 1.000021]\n",
      "epoch:2 step:8825[D loss: 0.999972] [G loss: 1.000022]\n",
      "epoch:2 step:8830[D loss: 0.999980] [G loss: 1.000035]\n",
      "epoch:2 step:8835[D loss: 1.000002] [G loss: 1.000062]\n",
      "epoch:2 step:8840[D loss: 0.999956] [G loss: 1.000071]\n",
      "epoch:2 step:8845[D loss: 0.999976] [G loss: 1.000033]\n",
      "epoch:2 step:8850[D loss: 1.000004] [G loss: 1.000014]\n",
      "epoch:2 step:8855[D loss: 0.999979] [G loss: 1.000022]\n",
      "epoch:2 step:8860[D loss: 0.999965] [G loss: 1.000060]\n",
      "epoch:2 step:8865[D loss: 0.999969] [G loss: 1.000065]\n",
      "epoch:2 step:8870[D loss: 0.999979] [G loss: 1.000061]\n",
      "epoch:2 step:8875[D loss: 1.000013] [G loss: 1.000038]\n",
      "epoch:2 step:8880[D loss: 0.999964] [G loss: 1.000066]\n",
      "epoch:2 step:8885[D loss: 0.999980] [G loss: 1.000050]\n",
      "epoch:2 step:8890[D loss: 0.999995] [G loss: 0.999970]\n",
      "epoch:2 step:8895[D loss: 0.999961] [G loss: 1.000039]\n",
      "epoch:2 step:8900[D loss: 0.999981] [G loss: 1.000034]\n",
      "epoch:2 step:8905[D loss: 0.999974] [G loss: 1.000059]\n",
      "epoch:2 step:8910[D loss: 0.999974] [G loss: 1.000053]\n",
      "epoch:2 step:8915[D loss: 0.999997] [G loss: 1.000022]\n",
      "epoch:2 step:8920[D loss: 0.999986] [G loss: 1.000054]\n",
      "epoch:2 step:8925[D loss: 0.999970] [G loss: 1.000060]\n",
      "epoch:2 step:8930[D loss: 0.999973] [G loss: 1.000043]\n",
      "epoch:2 step:8935[D loss: 0.999995] [G loss: 1.000042]\n",
      "epoch:2 step:8940[D loss: 0.999990] [G loss: 1.000032]\n",
      "epoch:2 step:8945[D loss: 0.999968] [G loss: 1.000043]\n",
      "epoch:2 step:8950[D loss: 0.999973] [G loss: 1.000053]\n",
      "epoch:2 step:8955[D loss: 0.999978] [G loss: 1.000047]\n",
      "epoch:2 step:8960[D loss: 0.999970] [G loss: 1.000044]\n",
      "epoch:2 step:8965[D loss: 0.999990] [G loss: 1.000029]\n",
      "epoch:2 step:8970[D loss: 0.999976] [G loss: 1.000050]\n",
      "epoch:2 step:8975[D loss: 0.999975] [G loss: 1.000048]\n",
      "epoch:2 step:8980[D loss: 0.999983] [G loss: 1.000043]\n",
      "epoch:2 step:8985[D loss: 0.999977] [G loss: 1.000037]\n",
      "epoch:2 step:8990[D loss: 0.999987] [G loss: 1.000037]\n",
      "epoch:2 step:8995[D loss: 0.999970] [G loss: 1.000041]\n",
      "epoch:2 step:9000[D loss: 0.999973] [G loss: 1.000041]\n",
      "##############\n",
      "[0.86068531 0.857042   0.80672008 0.83397929 0.78701846 0.84402889\n",
      " 0.85257761 0.84850694 0.81187429 0.84737034]\n",
      "##########\n",
      "epoch:2 step:9005[D loss: 0.999973] [G loss: 1.000047]\n",
      "epoch:2 step:9010[D loss: 0.999978] [G loss: 1.000058]\n",
      "epoch:2 step:9015[D loss: 0.999964] [G loss: 1.000065]\n",
      "epoch:2 step:9020[D loss: 0.999976] [G loss: 1.000039]\n",
      "epoch:2 step:9025[D loss: 0.999987] [G loss: 1.000025]\n",
      "epoch:2 step:9030[D loss: 0.999979] [G loss: 1.000030]\n",
      "epoch:2 step:9035[D loss: 0.999979] [G loss: 1.000026]\n",
      "epoch:2 step:9040[D loss: 0.999972] [G loss: 1.000036]\n",
      "epoch:2 step:9045[D loss: 0.999995] [G loss: 0.999993]\n",
      "epoch:2 step:9050[D loss: 0.999973] [G loss: 1.000032]\n",
      "epoch:2 step:9055[D loss: 0.999977] [G loss: 1.000042]\n",
      "epoch:2 step:9060[D loss: 0.999977] [G loss: 1.000041]\n",
      "epoch:2 step:9065[D loss: 0.999976] [G loss: 1.000040]\n",
      "epoch:2 step:9070[D loss: 0.999977] [G loss: 1.000036]\n",
      "epoch:2 step:9075[D loss: 0.999985] [G loss: 1.000045]\n",
      "epoch:2 step:9080[D loss: 0.999983] [G loss: 1.000025]\n",
      "epoch:2 step:9085[D loss: 1.000005] [G loss: 0.999992]\n",
      "epoch:2 step:9090[D loss: 0.999989] [G loss: 1.000030]\n",
      "epoch:2 step:9095[D loss: 0.999971] [G loss: 1.000065]\n",
      "epoch:2 step:9100[D loss: 0.999964] [G loss: 1.000071]\n",
      "epoch:2 step:9105[D loss: 0.999980] [G loss: 1.000033]\n",
      "epoch:2 step:9110[D loss: 1.000006] [G loss: 0.999993]\n",
      "epoch:2 step:9115[D loss: 0.999964] [G loss: 1.000027]\n",
      "epoch:2 step:9120[D loss: 0.999979] [G loss: 1.000019]\n",
      "epoch:2 step:9125[D loss: 0.999977] [G loss: 1.000014]\n",
      "epoch:2 step:9130[D loss: 0.999982] [G loss: 1.000053]\n",
      "epoch:2 step:9135[D loss: 0.999981] [G loss: 1.000006]\n",
      "epoch:2 step:9140[D loss: 0.999974] [G loss: 1.000041]\n",
      "epoch:2 step:9145[D loss: 0.999982] [G loss: 1.000047]\n",
      "epoch:2 step:9150[D loss: 0.999985] [G loss: 1.000023]\n",
      "epoch:2 step:9155[D loss: 0.999983] [G loss: 1.000027]\n",
      "epoch:2 step:9160[D loss: 0.999984] [G loss: 1.000045]\n",
      "epoch:2 step:9165[D loss: 0.999972] [G loss: 1.000042]\n",
      "epoch:2 step:9170[D loss: 0.999966] [G loss: 1.000047]\n",
      "epoch:2 step:9175[D loss: 0.999989] [G loss: 1.000039]\n",
      "epoch:2 step:9180[D loss: 0.999970] [G loss: 1.000048]\n",
      "epoch:2 step:9185[D loss: 0.999978] [G loss: 1.000038]\n",
      "epoch:2 step:9190[D loss: 0.999975] [G loss: 1.000050]\n",
      "epoch:2 step:9195[D loss: 0.999973] [G loss: 1.000046]\n",
      "epoch:2 step:9200[D loss: 0.999979] [G loss: 1.000046]\n",
      "##############\n",
      "[0.85238489 0.87344811 0.82722415 0.83660872 0.80488302 0.83325659\n",
      " 0.85812772 0.84123373 0.80095854 0.81349719]\n",
      "##########\n",
      "epoch:2 step:9205[D loss: 0.999982] [G loss: 1.000033]\n",
      "epoch:2 step:9210[D loss: 0.999981] [G loss: 1.000040]\n",
      "epoch:2 step:9215[D loss: 0.999970] [G loss: 1.000050]\n",
      "epoch:2 step:9220[D loss: 0.999977] [G loss: 1.000055]\n",
      "epoch:2 step:9225[D loss: 0.999980] [G loss: 1.000036]\n",
      "epoch:2 step:9230[D loss: 0.999982] [G loss: 1.000039]\n",
      "epoch:2 step:9235[D loss: 0.999975] [G loss: 1.000060]\n",
      "epoch:2 step:9240[D loss: 0.999966] [G loss: 1.000057]\n",
      "epoch:2 step:9245[D loss: 0.999982] [G loss: 1.000048]\n",
      "epoch:2 step:9250[D loss: 1.000002] [G loss: 0.999954]\n",
      "epoch:2 step:9255[D loss: 0.999988] [G loss: 1.000049]\n",
      "epoch:2 step:9260[D loss: 0.999981] [G loss: 1.000052]\n",
      "epoch:2 step:9265[D loss: 1.000001] [G loss: 1.000006]\n",
      "epoch:2 step:9270[D loss: 0.999972] [G loss: 1.000044]\n",
      "epoch:2 step:9275[D loss: 0.999975] [G loss: 1.000053]\n",
      "epoch:2 step:9280[D loss: 0.999976] [G loss: 1.000067]\n",
      "epoch:2 step:9285[D loss: 0.999970] [G loss: 1.000045]\n",
      "epoch:2 step:9290[D loss: 0.999977] [G loss: 1.000029]\n",
      "epoch:2 step:9295[D loss: 0.999967] [G loss: 1.000032]\n",
      "epoch:2 step:9300[D loss: 0.999972] [G loss: 1.000028]\n",
      "epoch:2 step:9305[D loss: 0.999970] [G loss: 1.000029]\n",
      "epoch:2 step:9310[D loss: 0.999983] [G loss: 1.000022]\n",
      "epoch:2 step:9315[D loss: 0.999983] [G loss: 1.000027]\n",
      "epoch:2 step:9320[D loss: 0.999982] [G loss: 1.000014]\n",
      "epoch:2 step:9325[D loss: 0.999978] [G loss: 1.000011]\n",
      "epoch:2 step:9330[D loss: 0.999977] [G loss: 1.000028]\n",
      "epoch:2 step:9335[D loss: 0.999979] [G loss: 1.000044]\n",
      "epoch:2 step:9340[D loss: 0.999971] [G loss: 1.000034]\n",
      "epoch:2 step:9345[D loss: 0.999986] [G loss: 1.000047]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:2 step:9350[D loss: 0.999969] [G loss: 1.000070]\n",
      "epoch:2 step:9355[D loss: 0.999977] [G loss: 1.000055]\n",
      "epoch:2 step:9360[D loss: 0.999971] [G loss: 1.000051]\n",
      "epoch:2 step:9365[D loss: 0.999980] [G loss: 1.000034]\n",
      "epoch:2 step:9370[D loss: 0.999970] [G loss: 1.000050]\n",
      "epoch:2 step:9375[D loss: 0.999973] [G loss: 1.000059]\n",
      "epoch:2 step:9380[D loss: 0.999982] [G loss: 1.000048]\n",
      "epoch:2 step:9385[D loss: 0.999976] [G loss: 1.000037]\n",
      "epoch:2 step:9390[D loss: 0.999980] [G loss: 1.000045]\n",
      "epoch:2 step:9395[D loss: 0.999981] [G loss: 1.000050]\n",
      "epoch:2 step:9400[D loss: 0.999973] [G loss: 1.000046]\n",
      "##############\n",
      "[0.85409952 0.87851358 0.81020163 0.81372327 0.78896918 0.85743653\n",
      " 0.86468302 0.8410538  0.8184036  0.8355472 ]\n",
      "##########\n",
      "epoch:2 step:9405[D loss: 0.999982] [G loss: 1.000028]\n",
      "epoch:2 step:9410[D loss: 0.999986] [G loss: 1.000022]\n",
      "epoch:2 step:9415[D loss: 0.999979] [G loss: 1.000036]\n",
      "epoch:2 step:9420[D loss: 0.999987] [G loss: 1.000043]\n",
      "epoch:2 step:9425[D loss: 0.999992] [G loss: 0.999994]\n",
      "epoch:2 step:9430[D loss: 0.999980] [G loss: 1.000037]\n",
      "epoch:2 step:9435[D loss: 1.000002] [G loss: 0.999985]\n",
      "epoch:2 step:9440[D loss: 1.000001] [G loss: 1.000042]\n",
      "epoch:2 step:9445[D loss: 0.999954] [G loss: 1.000052]\n",
      "epoch:2 step:9450[D loss: 0.999979] [G loss: 1.000054]\n",
      "epoch:2 step:9455[D loss: 0.999999] [G loss: 0.999988]\n",
      "epoch:2 step:9460[D loss: 0.999979] [G loss: 1.000000]\n",
      "epoch:2 step:9465[D loss: 0.999978] [G loss: 1.000007]\n",
      "epoch:2 step:9470[D loss: 0.999979] [G loss: 1.000028]\n",
      "epoch:2 step:9475[D loss: 0.999972] [G loss: 1.000064]\n",
      "epoch:2 step:9480[D loss: 0.999985] [G loss: 1.000023]\n",
      "epoch:2 step:9485[D loss: 0.999989] [G loss: 1.000009]\n",
      "epoch:2 step:9490[D loss: 0.999980] [G loss: 1.000037]\n",
      "epoch:2 step:9495[D loss: 0.999961] [G loss: 1.000070]\n",
      "epoch:2 step:9500[D loss: 0.999967] [G loss: 1.000067]\n",
      "epoch:2 step:9505[D loss: 0.999969] [G loss: 1.000060]\n",
      "epoch:2 step:9510[D loss: 0.999986] [G loss: 1.000038]\n",
      "epoch:2 step:9515[D loss: 0.999958] [G loss: 1.000073]\n",
      "epoch:2 step:9520[D loss: 0.999974] [G loss: 1.000045]\n",
      "epoch:2 step:9525[D loss: 0.999985] [G loss: 1.000041]\n",
      "epoch:2 step:9530[D loss: 0.999976] [G loss: 1.000011]\n",
      "epoch:2 step:9535[D loss: 0.999977] [G loss: 1.000050]\n",
      "epoch:2 step:9540[D loss: 0.999993] [G loss: 1.000017]\n",
      "epoch:2 step:9545[D loss: 0.999986] [G loss: 1.000023]\n",
      "epoch:2 step:9550[D loss: 0.999982] [G loss: 1.000043]\n",
      "epoch:2 step:9555[D loss: 0.999995] [G loss: 1.000051]\n",
      "epoch:2 step:9560[D loss: 0.999996] [G loss: 1.000007]\n",
      "epoch:2 step:9565[D loss: 0.999974] [G loss: 1.000032]\n",
      "epoch:2 step:9570[D loss: 0.999968] [G loss: 1.000037]\n",
      "epoch:2 step:9575[D loss: 1.000004] [G loss: 1.000022]\n",
      "epoch:2 step:9580[D loss: 0.999966] [G loss: 1.000048]\n",
      "epoch:2 step:9585[D loss: 0.999969] [G loss: 1.000037]\n",
      "epoch:2 step:9590[D loss: 0.999979] [G loss: 1.000024]\n",
      "epoch:2 step:9595[D loss: 0.999969] [G loss: 1.000024]\n",
      "epoch:2 step:9600[D loss: 0.999979] [G loss: 1.000024]\n",
      "##############\n",
      "[0.88347871 0.87054053 0.8202466  0.84240645 0.77262611 0.84594591\n",
      " 0.85153492 0.81761543 0.80175892 0.85047091]\n",
      "##########\n",
      "epoch:2 step:9605[D loss: 0.999988] [G loss: 1.000024]\n",
      "epoch:2 step:9610[D loss: 0.999996] [G loss: 1.000023]\n",
      "epoch:2 step:9615[D loss: 0.999970] [G loss: 1.000023]\n",
      "epoch:2 step:9620[D loss: 0.999978] [G loss: 1.000010]\n",
      "epoch:2 step:9625[D loss: 0.999988] [G loss: 1.000014]\n",
      "epoch:2 step:9630[D loss: 0.999983] [G loss: 1.000033]\n",
      "epoch:2 step:9635[D loss: 0.999970] [G loss: 1.000049]\n",
      "epoch:2 step:9640[D loss: 0.999980] [G loss: 1.000030]\n",
      "epoch:2 step:9645[D loss: 0.999978] [G loss: 1.000013]\n",
      "epoch:2 step:9650[D loss: 0.999979] [G loss: 1.000050]\n",
      "epoch:2 step:9655[D loss: 0.999975] [G loss: 1.000036]\n",
      "epoch:2 step:9660[D loss: 1.000002] [G loss: 1.000004]\n",
      "epoch:2 step:9665[D loss: 0.999996] [G loss: 0.999992]\n",
      "epoch:2 step:9670[D loss: 0.999974] [G loss: 1.000024]\n",
      "epoch:2 step:9675[D loss: 0.999974] [G loss: 1.000057]\n",
      "epoch:2 step:9680[D loss: 0.999986] [G loss: 1.000048]\n",
      "epoch:2 step:9685[D loss: 1.000012] [G loss: 0.999992]\n",
      "epoch:2 step:9690[D loss: 0.999983] [G loss: 1.000068]\n",
      "epoch:2 step:9695[D loss: 0.999969] [G loss: 1.000062]\n",
      "epoch:2 step:9700[D loss: 0.999974] [G loss: 1.000063]\n",
      "epoch:2 step:9705[D loss: 0.999984] [G loss: 1.000018]\n",
      "epoch:2 step:9710[D loss: 0.999995] [G loss: 0.999993]\n",
      "epoch:2 step:9715[D loss: 0.999978] [G loss: 1.000067]\n",
      "epoch:2 step:9720[D loss: 0.999962] [G loss: 1.000066]\n",
      "epoch:2 step:9725[D loss: 0.999962] [G loss: 1.000053]\n",
      "epoch:2 step:9730[D loss: 0.999979] [G loss: 1.000048]\n",
      "epoch:2 step:9735[D loss: 0.999998] [G loss: 1.000014]\n",
      "epoch:2 step:9740[D loss: 0.999962] [G loss: 1.000058]\n",
      "epoch:2 step:9745[D loss: 0.999961] [G loss: 1.000060]\n",
      "epoch:2 step:9750[D loss: 0.999974] [G loss: 1.000042]\n",
      "epoch:2 step:9755[D loss: 0.999969] [G loss: 1.000058]\n",
      "epoch:2 step:9760[D loss: 0.999983] [G loss: 1.000035]\n",
      "epoch:2 step:9765[D loss: 0.999984] [G loss: 1.000037]\n",
      "epoch:2 step:9770[D loss: 0.999980] [G loss: 1.000038]\n",
      "epoch:2 step:9775[D loss: 0.999991] [G loss: 1.000012]\n",
      "epoch:2 step:9780[D loss: 1.000003] [G loss: 1.000011]\n",
      "epoch:2 step:9785[D loss: 0.999968] [G loss: 1.000039]\n",
      "epoch:2 step:9790[D loss: 0.999989] [G loss: 1.000034]\n",
      "epoch:2 step:9795[D loss: 0.999980] [G loss: 1.000018]\n",
      "epoch:2 step:9800[D loss: 0.999965] [G loss: 1.000055]\n",
      "##############\n",
      "[0.87060902 0.86985457 0.81730481 0.82641213 0.78326274 0.83221932\n",
      " 0.89067716 0.838882   0.80532555 0.8314256 ]\n",
      "##########\n",
      "epoch:2 step:9805[D loss: 0.999969] [G loss: 1.000041]\n",
      "epoch:2 step:9810[D loss: 0.999979] [G loss: 1.000020]\n",
      "epoch:2 step:9815[D loss: 1.000000] [G loss: 0.999990]\n",
      "epoch:2 step:9820[D loss: 0.999965] [G loss: 1.000050]\n",
      "epoch:2 step:9825[D loss: 0.999981] [G loss: 1.000032]\n",
      "epoch:2 step:9830[D loss: 0.999982] [G loss: 1.000044]\n",
      "epoch:2 step:9835[D loss: 0.999971] [G loss: 1.000032]\n",
      "epoch:2 step:9840[D loss: 0.999977] [G loss: 1.000062]\n",
      "epoch:2 step:9845[D loss: 0.999962] [G loss: 1.000047]\n",
      "epoch:2 step:9850[D loss: 0.999985] [G loss: 1.000042]\n",
      "epoch:2 step:9855[D loss: 0.999953] [G loss: 1.000057]\n",
      "epoch:2 step:9860[D loss: 0.999970] [G loss: 1.000051]\n",
      "epoch:2 step:9865[D loss: 0.999969] [G loss: 1.000044]\n",
      "epoch:2 step:9870[D loss: 0.999974] [G loss: 1.000045]\n",
      "epoch:2 step:9875[D loss: 0.999987] [G loss: 1.000036]\n",
      "epoch:2 step:9880[D loss: 0.999990] [G loss: 1.000037]\n",
      "epoch:2 step:9885[D loss: 0.999984] [G loss: 1.000017]\n",
      "epoch:2 step:9890[D loss: 0.999977] [G loss: 1.000048]\n",
      "epoch:2 step:9895[D loss: 0.999974] [G loss: 1.000054]\n",
      "epoch:2 step:9900[D loss: 0.999965] [G loss: 1.000061]\n",
      "epoch:2 step:9905[D loss: 0.999979] [G loss: 1.000036]\n",
      "epoch:2 step:9910[D loss: 0.999970] [G loss: 1.000048]\n",
      "epoch:2 step:9915[D loss: 0.999972] [G loss: 1.000054]\n",
      "epoch:2 step:9920[D loss: 0.999966] [G loss: 1.000044]\n",
      "epoch:2 step:9925[D loss: 0.999972] [G loss: 1.000044]\n",
      "epoch:2 step:9930[D loss: 0.999989] [G loss: 1.000018]\n",
      "epoch:2 step:9935[D loss: 0.999968] [G loss: 1.000029]\n",
      "epoch:2 step:9940[D loss: 0.999982] [G loss: 1.000018]\n",
      "epoch:2 step:9945[D loss: 0.999976] [G loss: 1.000024]\n",
      "epoch:2 step:9950[D loss: 0.999970] [G loss: 1.000037]\n",
      "epoch:2 step:9955[D loss: 0.999976] [G loss: 1.000047]\n",
      "epoch:2 step:9960[D loss: 0.999990] [G loss: 1.000040]\n",
      "epoch:2 step:9965[D loss: 0.999972] [G loss: 1.000047]\n",
      "epoch:2 step:9970[D loss: 0.999972] [G loss: 1.000039]\n",
      "epoch:2 step:9975[D loss: 0.999977] [G loss: 1.000040]\n",
      "epoch:2 step:9980[D loss: 0.999979] [G loss: 1.000039]\n",
      "epoch:2 step:9985[D loss: 0.999973] [G loss: 1.000039]\n",
      "epoch:2 step:9990[D loss: 0.999975] [G loss: 1.000038]\n",
      "epoch:2 step:9995[D loss: 0.999994] [G loss: 1.000031]\n",
      "epoch:2 step:10000[D loss: 0.999978] [G loss: 1.000060]\n",
      "##############\n",
      "[0.8692387  0.86633581 0.81963328 0.82499768 0.78973678 0.83925464\n",
      " 0.8660942  0.81336476 0.82781605 0.83647212]\n",
      "##########\n",
      "epoch:2 step:10005[D loss: 0.999986] [G loss: 1.000048]\n",
      "epoch:2 step:10010[D loss: 0.999976] [G loss: 1.000047]\n",
      "epoch:2 step:10015[D loss: 0.999965] [G loss: 1.000075]\n",
      "epoch:2 step:10020[D loss: 0.999974] [G loss: 1.000057]\n",
      "epoch:2 step:10025[D loss: 0.999973] [G loss: 1.000060]\n",
      "epoch:2 step:10030[D loss: 0.999970] [G loss: 1.000038]\n",
      "epoch:2 step:10035[D loss: 0.999973] [G loss: 1.000058]\n",
      "epoch:2 step:10040[D loss: 0.999975] [G loss: 1.000048]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:2 step:10045[D loss: 0.999977] [G loss: 1.000025]\n",
      "epoch:2 step:10050[D loss: 0.999993] [G loss: 1.000016]\n",
      "epoch:2 step:10055[D loss: 0.999977] [G loss: 1.000031]\n",
      "epoch:2 step:10060[D loss: 0.999975] [G loss: 1.000018]\n",
      "epoch:2 step:10065[D loss: 0.999977] [G loss: 1.000039]\n",
      "epoch:2 step:10070[D loss: 0.999984] [G loss: 1.000037]\n",
      "epoch:2 step:10075[D loss: 0.999983] [G loss: 1.000025]\n",
      "epoch:2 step:10080[D loss: 0.999976] [G loss: 1.000043]\n",
      "epoch:2 step:10085[D loss: 0.999974] [G loss: 1.000057]\n",
      "epoch:2 step:10090[D loss: 0.999987] [G loss: 1.000037]\n",
      "epoch:2 step:10095[D loss: 0.999977] [G loss: 1.000040]\n",
      "epoch:2 step:10100[D loss: 0.999983] [G loss: 1.000028]\n",
      "epoch:2 step:10105[D loss: 0.999977] [G loss: 1.000035]\n",
      "epoch:2 step:10110[D loss: 0.999986] [G loss: 1.000023]\n",
      "epoch:2 step:10115[D loss: 0.999970] [G loss: 1.000049]\n",
      "epoch:2 step:10120[D loss: 0.999989] [G loss: 1.000018]\n",
      "epoch:2 step:10125[D loss: 1.000012] [G loss: 0.999992]\n",
      "epoch:2 step:10130[D loss: 0.999977] [G loss: 1.000028]\n",
      "epoch:2 step:10135[D loss: 0.999971] [G loss: 1.000064]\n",
      "epoch:2 step:10140[D loss: 0.999989] [G loss: 1.000024]\n",
      "epoch:2 step:10145[D loss: 0.999976] [G loss: 1.000022]\n",
      "epoch:2 step:10150[D loss: 0.999975] [G loss: 1.000066]\n",
      "epoch:2 step:10155[D loss: 0.999973] [G loss: 1.000058]\n",
      "epoch:2 step:10160[D loss: 0.999988] [G loss: 1.000054]\n",
      "epoch:2 step:10165[D loss: 0.999978] [G loss: 1.000055]\n",
      "epoch:2 step:10170[D loss: 0.999984] [G loss: 1.000043]\n",
      "epoch:2 step:10175[D loss: 1.000001] [G loss: 1.000014]\n",
      "epoch:2 step:10180[D loss: 0.999975] [G loss: 1.000067]\n",
      "epoch:2 step:10185[D loss: 0.999980] [G loss: 1.000060]\n",
      "epoch:2 step:10190[D loss: 0.999968] [G loss: 1.000049]\n",
      "epoch:2 step:10195[D loss: 0.999971] [G loss: 1.000051]\n",
      "epoch:2 step:10200[D loss: 0.999976] [G loss: 1.000050]\n",
      "##############\n",
      "[0.86383845 0.8501992  0.8170183  0.83718053 0.80767814 0.82576336\n",
      " 0.8707822  0.83964166 0.81240432 0.83930444]\n",
      "##########\n",
      "epoch:2 step:10205[D loss: 0.999972] [G loss: 1.000058]\n",
      "epoch:2 step:10210[D loss: 0.999967] [G loss: 1.000065]\n",
      "epoch:2 step:10215[D loss: 0.999972] [G loss: 1.000049]\n",
      "epoch:2 step:10220[D loss: 0.999970] [G loss: 1.000042]\n",
      "epoch:2 step:10225[D loss: 0.999976] [G loss: 1.000017]\n",
      "epoch:2 step:10230[D loss: 0.999981] [G loss: 1.000040]\n",
      "epoch:2 step:10235[D loss: 0.999973] [G loss: 1.000033]\n",
      "epoch:2 step:10240[D loss: 0.999978] [G loss: 1.000033]\n",
      "epoch:2 step:10245[D loss: 0.999970] [G loss: 1.000024]\n",
      "epoch:2 step:10250[D loss: 0.999973] [G loss: 1.000048]\n",
      "epoch:2 step:10255[D loss: 0.999977] [G loss: 1.000045]\n",
      "epoch:2 step:10260[D loss: 0.999982] [G loss: 1.000026]\n",
      "epoch:2 step:10265[D loss: 0.999970] [G loss: 1.000060]\n",
      "epoch:2 step:10270[D loss: 0.999973] [G loss: 1.000062]\n",
      "epoch:2 step:10275[D loss: 0.999979] [G loss: 1.000028]\n",
      "epoch:2 step:10280[D loss: 0.999970] [G loss: 1.000058]\n",
      "epoch:2 step:10285[D loss: 0.999977] [G loss: 1.000045]\n",
      "epoch:2 step:10290[D loss: 0.999987] [G loss: 1.000052]\n",
      "epoch:2 step:10295[D loss: 0.999980] [G loss: 1.000044]\n",
      "epoch:2 step:10300[D loss: 0.999989] [G loss: 1.000044]\n",
      "epoch:2 step:10305[D loss: 0.999977] [G loss: 1.000029]\n",
      "epoch:2 step:10310[D loss: 0.999963] [G loss: 1.000048]\n",
      "epoch:2 step:10315[D loss: 0.999973] [G loss: 1.000063]\n",
      "epoch:2 step:10320[D loss: 0.999968] [G loss: 1.000057]\n",
      "epoch:2 step:10325[D loss: 0.999973] [G loss: 1.000050]\n",
      "epoch:2 step:10330[D loss: 0.999973] [G loss: 1.000053]\n",
      "epoch:2 step:10335[D loss: 0.999973] [G loss: 1.000040]\n",
      "epoch:2 step:10340[D loss: 0.999977] [G loss: 1.000040]\n",
      "epoch:2 step:10345[D loss: 0.999981] [G loss: 1.000035]\n",
      "epoch:2 step:10350[D loss: 0.999985] [G loss: 1.000034]\n",
      "epoch:2 step:10355[D loss: 0.999983] [G loss: 1.000018]\n",
      "epoch:2 step:10360[D loss: 0.999993] [G loss: 1.000026]\n",
      "epoch:2 step:10365[D loss: 0.999974] [G loss: 1.000024]\n",
      "epoch:2 step:10370[D loss: 0.999990] [G loss: 1.000031]\n",
      "epoch:2 step:10375[D loss: 0.999968] [G loss: 1.000061]\n",
      "epoch:2 step:10380[D loss: 0.999972] [G loss: 1.000053]\n",
      "epoch:2 step:10385[D loss: 0.999982] [G loss: 1.000054]\n",
      "epoch:2 step:10390[D loss: 0.999978] [G loss: 1.000056]\n",
      "epoch:2 step:10395[D loss: 0.999978] [G loss: 1.000047]\n",
      "epoch:2 step:10400[D loss: 0.999983] [G loss: 1.000051]\n",
      "##############\n",
      "[0.87143271 0.88146778 0.83596017 0.83291668 0.7949558  0.83575434\n",
      " 0.86401992 0.84347918 0.83162285 0.84122613]\n",
      "##########\n",
      "epoch:2 step:10405[D loss: 0.999983] [G loss: 1.000049]\n",
      "epoch:2 step:10410[D loss: 0.999959] [G loss: 1.000051]\n",
      "epoch:2 step:10415[D loss: 0.999969] [G loss: 1.000059]\n",
      "epoch:2 step:10420[D loss: 0.999973] [G loss: 1.000053]\n",
      "epoch:2 step:10425[D loss: 0.999976] [G loss: 1.000047]\n",
      "epoch:2 step:10430[D loss: 0.999975] [G loss: 1.000040]\n",
      "epoch:2 step:10435[D loss: 0.999974] [G loss: 1.000052]\n",
      "epoch:2 step:10440[D loss: 0.999981] [G loss: 1.000048]\n",
      "epoch:2 step:10445[D loss: 0.999975] [G loss: 1.000052]\n",
      "epoch:2 step:10450[D loss: 0.999974] [G loss: 1.000045]\n",
      "epoch:2 step:10455[D loss: 0.999965] [G loss: 1.000064]\n",
      "epoch:2 step:10460[D loss: 0.999966] [G loss: 1.000049]\n",
      "epoch:2 step:10465[D loss: 0.999995] [G loss: 1.000031]\n",
      "epoch:2 step:10470[D loss: 0.999974] [G loss: 1.000048]\n",
      "epoch:2 step:10475[D loss: 0.999979] [G loss: 1.000056]\n",
      "epoch:2 step:10480[D loss: 0.999980] [G loss: 1.000030]\n",
      "epoch:2 step:10485[D loss: 0.999979] [G loss: 1.000030]\n",
      "epoch:2 step:10490[D loss: 0.999967] [G loss: 1.000050]\n",
      "epoch:2 step:10495[D loss: 0.999974] [G loss: 1.000037]\n",
      "epoch:2 step:10500[D loss: 0.999984] [G loss: 1.000040]\n",
      "epoch:2 step:10505[D loss: 0.999984] [G loss: 1.000043]\n",
      "epoch:2 step:10510[D loss: 0.999967] [G loss: 1.000074]\n",
      "epoch:2 step:10515[D loss: 0.999969] [G loss: 1.000059]\n",
      "epoch:2 step:10520[D loss: 0.999968] [G loss: 1.000036]\n",
      "epoch:2 step:10525[D loss: 0.999993] [G loss: 1.000019]\n",
      "epoch:2 step:10530[D loss: 0.999981] [G loss: 1.000018]\n",
      "epoch:2 step:10535[D loss: 0.999962] [G loss: 1.000058]\n",
      "epoch:2 step:10540[D loss: 0.999978] [G loss: 1.000068]\n",
      "epoch:2 step:10545[D loss: 0.999988] [G loss: 1.000057]\n",
      "epoch:2 step:10550[D loss: 0.999986] [G loss: 1.000046]\n",
      "epoch:2 step:10555[D loss: 0.999982] [G loss: 1.000060]\n",
      "epoch:2 step:10560[D loss: 0.999968] [G loss: 1.000065]\n",
      "epoch:2 step:10565[D loss: 0.999973] [G loss: 1.000044]\n",
      "epoch:2 step:10570[D loss: 0.999976] [G loss: 1.000044]\n",
      "epoch:2 step:10575[D loss: 0.999980] [G loss: 1.000047]\n",
      "epoch:2 step:10580[D loss: 0.999972] [G loss: 1.000035]\n",
      "epoch:2 step:10585[D loss: 0.999973] [G loss: 1.000041]\n",
      "epoch:2 step:10590[D loss: 0.999975] [G loss: 1.000039]\n",
      "epoch:2 step:10595[D loss: 0.999968] [G loss: 1.000055]\n",
      "epoch:2 step:10600[D loss: 0.999966] [G loss: 1.000052]\n",
      "##############\n",
      "[0.86556455 0.86547427 0.83165782 0.81330417 0.79217042 0.84723539\n",
      " 0.89347426 0.83218553 0.80592671 0.8184701 ]\n",
      "##########\n",
      "epoch:2 step:10605[D loss: 0.999979] [G loss: 1.000038]\n",
      "epoch:2 step:10610[D loss: 0.999980] [G loss: 1.000043]\n",
      "epoch:2 step:10615[D loss: 0.999990] [G loss: 1.000031]\n",
      "epoch:2 step:10620[D loss: 0.999975] [G loss: 1.000055]\n",
      "epoch:2 step:10625[D loss: 0.999981] [G loss: 1.000057]\n",
      "epoch:2 step:10630[D loss: 0.999981] [G loss: 1.000049]\n",
      "epoch:2 step:10635[D loss: 0.999982] [G loss: 1.000056]\n",
      "epoch:2 step:10640[D loss: 0.999979] [G loss: 1.000024]\n",
      "epoch:2 step:10645[D loss: 0.999982] [G loss: 1.000037]\n",
      "epoch:2 step:10650[D loss: 0.999980] [G loss: 1.000040]\n",
      "epoch:2 step:10655[D loss: 0.999979] [G loss: 1.000003]\n",
      "epoch:2 step:10660[D loss: 0.999979] [G loss: 1.000027]\n",
      "epoch:2 step:10665[D loss: 0.999989] [G loss: 1.000032]\n",
      "epoch:2 step:10670[D loss: 0.999968] [G loss: 1.000049]\n",
      "epoch:2 step:10675[D loss: 0.999978] [G loss: 1.000049]\n",
      "epoch:2 step:10680[D loss: 0.999984] [G loss: 1.000052]\n",
      "epoch:2 step:10685[D loss: 0.999962] [G loss: 1.000073]\n",
      "epoch:2 step:10690[D loss: 0.999975] [G loss: 1.000060]\n",
      "epoch:2 step:10695[D loss: 0.999970] [G loss: 1.000051]\n",
      "epoch:2 step:10700[D loss: 0.999986] [G loss: 1.000017]\n",
      "epoch:2 step:10705[D loss: 0.999974] [G loss: 1.000041]\n",
      "epoch:2 step:10710[D loss: 0.999970] [G loss: 1.000046]\n",
      "epoch:2 step:10715[D loss: 0.999975] [G loss: 1.000056]\n",
      "epoch:2 step:10720[D loss: 0.999989] [G loss: 1.000018]\n",
      "epoch:2 step:10725[D loss: 0.999967] [G loss: 1.000064]\n",
      "epoch:2 step:10730[D loss: 0.999983] [G loss: 1.000043]\n",
      "epoch:2 step:10735[D loss: 0.999988] [G loss: 1.000030]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:2 step:10740[D loss: 0.999965] [G loss: 1.000060]\n",
      "epoch:2 step:10745[D loss: 0.999967] [G loss: 1.000045]\n",
      "epoch:2 step:10750[D loss: 0.999984] [G loss: 1.000034]\n",
      "epoch:2 step:10755[D loss: 0.999967] [G loss: 1.000055]\n",
      "epoch:2 step:10760[D loss: 0.999975] [G loss: 1.000049]\n",
      "epoch:2 step:10765[D loss: 0.999973] [G loss: 1.000054]\n",
      "epoch:2 step:10770[D loss: 0.999976] [G loss: 1.000046]\n",
      "epoch:2 step:10775[D loss: 0.999983] [G loss: 1.000046]\n",
      "epoch:2 step:10780[D loss: 0.999973] [G loss: 1.000049]\n",
      "epoch:2 step:10785[D loss: 0.999984] [G loss: 1.000036]\n",
      "epoch:2 step:10790[D loss: 0.999981] [G loss: 1.000050]\n",
      "epoch:2 step:10795[D loss: 0.999978] [G loss: 1.000053]\n",
      "epoch:2 step:10800[D loss: 0.999985] [G loss: 1.000045]\n",
      "##############\n",
      "[0.86514699 0.87554435 0.82769815 0.83775011 0.7978026  0.84049386\n",
      " 0.8636889  0.83994354 0.81568908 0.83915071]\n",
      "##########\n",
      "epoch:2 step:10805[D loss: 0.999977] [G loss: 1.000054]\n",
      "epoch:2 step:10810[D loss: 0.999977] [G loss: 1.000057]\n",
      "epoch:2 step:10815[D loss: 0.999973] [G loss: 1.000038]\n",
      "epoch:2 step:10820[D loss: 0.999988] [G loss: 1.000044]\n",
      "epoch:2 step:10825[D loss: 0.999972] [G loss: 1.000049]\n",
      "epoch:2 step:10830[D loss: 0.999981] [G loss: 1.000046]\n",
      "epoch:2 step:10835[D loss: 0.999969] [G loss: 1.000041]\n",
      "epoch:2 step:10840[D loss: 0.999991] [G loss: 1.000020]\n",
      "epoch:2 step:10845[D loss: 0.999964] [G loss: 1.000040]\n",
      "epoch:2 step:10850[D loss: 0.999973] [G loss: 1.000040]\n",
      "epoch:2 step:10855[D loss: 0.999973] [G loss: 1.000061]\n",
      "epoch:2 step:10860[D loss: 0.999975] [G loss: 1.000068]\n",
      "epoch:2 step:10865[D loss: 0.999981] [G loss: 1.000052]\n",
      "epoch:2 step:10870[D loss: 0.999980] [G loss: 1.000053]\n",
      "epoch:2 step:10875[D loss: 0.999974] [G loss: 1.000049]\n",
      "epoch:2 step:10880[D loss: 0.999981] [G loss: 1.000050]\n",
      "epoch:2 step:10885[D loss: 0.999974] [G loss: 1.000041]\n",
      "epoch:2 step:10890[D loss: 0.999970] [G loss: 1.000053]\n",
      "epoch:2 step:10895[D loss: 0.999973] [G loss: 1.000065]\n",
      "epoch:2 step:10900[D loss: 0.999972] [G loss: 1.000054]\n",
      "epoch:2 step:10905[D loss: 0.999968] [G loss: 1.000066]\n",
      "epoch:2 step:10910[D loss: 0.999974] [G loss: 1.000048]\n",
      "epoch:2 step:10915[D loss: 0.999971] [G loss: 1.000058]\n",
      "epoch:2 step:10920[D loss: 0.999979] [G loss: 1.000042]\n",
      "epoch:2 step:10925[D loss: 0.999970] [G loss: 1.000053]\n",
      "epoch:2 step:10930[D loss: 0.999976] [G loss: 1.000067]\n",
      "epoch:2 step:10935[D loss: 0.999980] [G loss: 1.000041]\n",
      "epoch:2 step:10940[D loss: 0.999968] [G loss: 1.000059]\n",
      "epoch:2 step:10945[D loss: 0.999991] [G loss: 1.000054]\n",
      "epoch:2 step:10950[D loss: 0.999974] [G loss: 1.000067]\n",
      "epoch:2 step:10955[D loss: 0.999977] [G loss: 1.000055]\n",
      "epoch:2 step:10960[D loss: 0.999975] [G loss: 1.000065]\n",
      "epoch:2 step:10965[D loss: 0.999985] [G loss: 1.000048]\n",
      "epoch:2 step:10970[D loss: 0.999970] [G loss: 1.000050]\n",
      "epoch:2 step:10975[D loss: 0.999970] [G loss: 1.000073]\n",
      "epoch:2 step:10980[D loss: 0.999978] [G loss: 1.000046]\n",
      "epoch:2 step:10985[D loss: 0.999987] [G loss: 1.000051]\n",
      "epoch:2 step:10990[D loss: 0.999972] [G loss: 1.000062]\n",
      "epoch:2 step:10995[D loss: 0.999977] [G loss: 1.000034]\n",
      "epoch:2 step:11000[D loss: 0.999979] [G loss: 1.000042]\n",
      "##############\n",
      "[0.84117418 0.87249893 0.82567555 0.82957624 0.79026291 0.80977104\n",
      " 0.8479075  0.83160271 0.81869091 0.85650035]\n",
      "##########\n",
      "epoch:2 step:11005[D loss: 0.999980] [G loss: 1.000062]\n",
      "epoch:2 step:11010[D loss: 0.999972] [G loss: 1.000055]\n",
      "epoch:2 step:11015[D loss: 0.999978] [G loss: 1.000053]\n",
      "epoch:2 step:11020[D loss: 0.999969] [G loss: 1.000053]\n",
      "epoch:2 step:11025[D loss: 0.999969] [G loss: 1.000055]\n",
      "epoch:2 step:11030[D loss: 0.999980] [G loss: 1.000048]\n",
      "epoch:2 step:11035[D loss: 0.999984] [G loss: 1.000038]\n",
      "epoch:2 step:11040[D loss: 0.999971] [G loss: 1.000063]\n",
      "epoch:2 step:11045[D loss: 0.999980] [G loss: 1.000053]\n",
      "epoch:2 step:11050[D loss: 0.999974] [G loss: 1.000048]\n",
      "epoch:2 step:11055[D loss: 0.999981] [G loss: 1.000025]\n",
      "epoch:2 step:11060[D loss: 0.999971] [G loss: 1.000043]\n",
      "epoch:2 step:11065[D loss: 0.999976] [G loss: 1.000041]\n",
      "epoch:2 step:11070[D loss: 0.999973] [G loss: 1.000050]\n",
      "epoch:2 step:11075[D loss: 0.999978] [G loss: 1.000049]\n",
      "epoch:2 step:11080[D loss: 0.999978] [G loss: 1.000056]\n",
      "epoch:2 step:11085[D loss: 0.999989] [G loss: 1.000026]\n",
      "epoch:2 step:11090[D loss: 0.999973] [G loss: 1.000049]\n",
      "epoch:2 step:11095[D loss: 0.999972] [G loss: 1.000064]\n",
      "epoch:2 step:11100[D loss: 0.999972] [G loss: 1.000059]\n",
      "epoch:2 step:11105[D loss: 0.999973] [G loss: 1.000054]\n",
      "epoch:2 step:11110[D loss: 0.999973] [G loss: 1.000058]\n",
      "epoch:2 step:11115[D loss: 0.999984] [G loss: 1.000047]\n",
      "epoch:2 step:11120[D loss: 0.999977] [G loss: 1.000054]\n",
      "epoch:2 step:11125[D loss: 0.999978] [G loss: 1.000056]\n",
      "epoch:2 step:11130[D loss: 0.999978] [G loss: 1.000055]\n",
      "epoch:2 step:11135[D loss: 0.999977] [G loss: 1.000057]\n",
      "epoch:2 step:11140[D loss: 0.999966] [G loss: 1.000049]\n",
      "epoch:2 step:11145[D loss: 0.999984] [G loss: 1.000027]\n",
      "epoch:2 step:11150[D loss: 0.999965] [G loss: 1.000070]\n",
      "epoch:2 step:11155[D loss: 0.999982] [G loss: 1.000037]\n",
      "epoch:2 step:11160[D loss: 0.999971] [G loss: 1.000078]\n",
      "epoch:2 step:11165[D loss: 0.999974] [G loss: 1.000060]\n",
      "epoch:2 step:11170[D loss: 0.999968] [G loss: 1.000065]\n",
      "epoch:2 step:11175[D loss: 0.999965] [G loss: 1.000057]\n",
      "epoch:2 step:11180[D loss: 0.999982] [G loss: 1.000041]\n",
      "epoch:2 step:11185[D loss: 0.999976] [G loss: 1.000045]\n",
      "epoch:2 step:11190[D loss: 0.999972] [G loss: 1.000070]\n",
      "epoch:2 step:11195[D loss: 0.999979] [G loss: 1.000058]\n",
      "epoch:2 step:11200[D loss: 0.999976] [G loss: 1.000025]\n",
      "##############\n",
      "[0.86536967 0.87770529 0.83471286 0.82466836 0.79631028 0.82397183\n",
      " 0.85858755 0.83515143 0.83167432 0.83600708]\n",
      "##########\n",
      "epoch:2 step:11205[D loss: 0.999977] [G loss: 1.000047]\n",
      "epoch:2 step:11210[D loss: 0.999966] [G loss: 1.000062]\n",
      "epoch:2 step:11215[D loss: 0.999965] [G loss: 1.000057]\n",
      "epoch:2 step:11220[D loss: 0.999985] [G loss: 1.000057]\n",
      "epoch:2 step:11225[D loss: 0.999973] [G loss: 1.000044]\n",
      "epoch:2 step:11230[D loss: 0.999975] [G loss: 1.000061]\n",
      "epoch:2 step:11235[D loss: 0.999983] [G loss: 1.000052]\n",
      "epoch:2 step:11240[D loss: 0.999975] [G loss: 1.000057]\n",
      "epoch:2 step:11245[D loss: 0.999986] [G loss: 1.000054]\n",
      "epoch:2 step:11250[D loss: 0.999967] [G loss: 1.000051]\n",
      "epoch:2 step:11255[D loss: 0.999958] [G loss: 1.000051]\n",
      "epoch:2 step:11260[D loss: 0.999978] [G loss: 1.000036]\n",
      "epoch:2 step:11265[D loss: 0.999987] [G loss: 1.000011]\n",
      "epoch:2 step:11270[D loss: 0.999975] [G loss: 1.000031]\n",
      "epoch:2 step:11275[D loss: 0.999991] [G loss: 1.000045]\n",
      "epoch:2 step:11280[D loss: 0.999972] [G loss: 1.000056]\n",
      "epoch:2 step:11285[D loss: 0.999966] [G loss: 1.000053]\n",
      "epoch:2 step:11290[D loss: 0.999975] [G loss: 1.000053]\n",
      "epoch:2 step:11295[D loss: 0.999973] [G loss: 1.000054]\n",
      "epoch:2 step:11300[D loss: 0.999971] [G loss: 1.000058]\n",
      "epoch:2 step:11305[D loss: 0.999986] [G loss: 1.000044]\n",
      "epoch:2 step:11310[D loss: 0.999984] [G loss: 1.000042]\n",
      "epoch:2 step:11315[D loss: 0.999980] [G loss: 1.000042]\n",
      "epoch:2 step:11320[D loss: 0.999978] [G loss: 1.000049]\n",
      "epoch:2 step:11325[D loss: 0.999967] [G loss: 1.000067]\n",
      "epoch:2 step:11330[D loss: 0.999977] [G loss: 1.000053]\n",
      "epoch:2 step:11335[D loss: 0.999976] [G loss: 1.000057]\n",
      "epoch:2 step:11340[D loss: 0.999965] [G loss: 1.000065]\n",
      "epoch:2 step:11345[D loss: 0.999969] [G loss: 1.000061]\n",
      "epoch:2 step:11350[D loss: 0.999982] [G loss: 1.000049]\n",
      "epoch:2 step:11355[D loss: 0.999981] [G loss: 1.000064]\n",
      "epoch:2 step:11360[D loss: 0.999970] [G loss: 1.000057]\n",
      "epoch:2 step:11365[D loss: 0.999979] [G loss: 1.000052]\n",
      "epoch:2 step:11370[D loss: 0.999978] [G loss: 1.000045]\n",
      "epoch:2 step:11375[D loss: 0.999972] [G loss: 1.000040]\n",
      "epoch:2 step:11380[D loss: 0.999982] [G loss: 1.000040]\n",
      "epoch:2 step:11385[D loss: 0.999978] [G loss: 1.000058]\n",
      "epoch:2 step:11390[D loss: 0.999982] [G loss: 1.000036]\n",
      "epoch:2 step:11395[D loss: 0.999985] [G loss: 1.000038]\n",
      "epoch:2 step:11400[D loss: 0.999973] [G loss: 1.000049]\n",
      "##############\n",
      "[0.86146425 0.88490422 0.80754763 0.81998509 0.79065404 0.82554774\n",
      " 0.84700613 0.8457139  0.80855984 0.80876813]\n",
      "##########\n",
      "epoch:2 step:11405[D loss: 0.999965] [G loss: 1.000064]\n",
      "epoch:2 step:11410[D loss: 0.999968] [G loss: 1.000051]\n",
      "epoch:2 step:11415[D loss: 0.999968] [G loss: 1.000062]\n",
      "epoch:2 step:11420[D loss: 0.999978] [G loss: 1.000040]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:2 step:11425[D loss: 0.999972] [G loss: 1.000047]\n",
      "epoch:2 step:11430[D loss: 0.999983] [G loss: 1.000049]\n",
      "epoch:2 step:11435[D loss: 0.999986] [G loss: 1.000029]\n",
      "epoch:2 step:11440[D loss: 0.999978] [G loss: 1.000051]\n",
      "epoch:2 step:11445[D loss: 0.999969] [G loss: 1.000026]\n",
      "epoch:2 step:11450[D loss: 0.999967] [G loss: 1.000054]\n",
      "epoch:2 step:11455[D loss: 0.999982] [G loss: 1.000030]\n",
      "epoch:2 step:11460[D loss: 0.999969] [G loss: 1.000052]\n",
      "epoch:2 step:11465[D loss: 0.999990] [G loss: 1.000031]\n",
      "epoch:2 step:11470[D loss: 0.999969] [G loss: 1.000069]\n",
      "epoch:2 step:11475[D loss: 0.999981] [G loss: 1.000040]\n",
      "epoch:2 step:11480[D loss: 0.999983] [G loss: 1.000028]\n",
      "epoch:2 step:11485[D loss: 0.999973] [G loss: 1.000057]\n",
      "epoch:2 step:11490[D loss: 0.999983] [G loss: 1.000036]\n",
      "epoch:2 step:11495[D loss: 0.999993] [G loss: 1.000042]\n",
      "epoch:2 step:11500[D loss: 0.999970] [G loss: 1.000054]\n",
      "epoch:2 step:11505[D loss: 0.999975] [G loss: 1.000054]\n",
      "epoch:2 step:11510[D loss: 0.999979] [G loss: 1.000047]\n",
      "epoch:2 step:11515[D loss: 0.999971] [G loss: 1.000053]\n",
      "epoch:2 step:11520[D loss: 0.999969] [G loss: 1.000060]\n",
      "epoch:2 step:11525[D loss: 0.999978] [G loss: 1.000046]\n",
      "epoch:2 step:11530[D loss: 0.999976] [G loss: 1.000047]\n",
      "epoch:2 step:11535[D loss: 1.000003] [G loss: 1.000009]\n",
      "epoch:2 step:11540[D loss: 0.999961] [G loss: 1.000070]\n",
      "epoch:2 step:11545[D loss: 0.999984] [G loss: 1.000048]\n",
      "epoch:2 step:11550[D loss: 0.999984] [G loss: 1.000032]\n",
      "epoch:2 step:11555[D loss: 0.999965] [G loss: 1.000069]\n",
      "epoch:2 step:11560[D loss: 0.999978] [G loss: 1.000057]\n",
      "epoch:2 step:11565[D loss: 0.999973] [G loss: 1.000054]\n",
      "epoch:2 step:11570[D loss: 0.999976] [G loss: 1.000056]\n",
      "epoch:2 step:11575[D loss: 0.999974] [G loss: 1.000059]\n",
      "epoch:2 step:11580[D loss: 0.999984] [G loss: 1.000056]\n",
      "epoch:2 step:11585[D loss: 0.999977] [G loss: 1.000042]\n",
      "epoch:2 step:11590[D loss: 0.999965] [G loss: 1.000058]\n",
      "epoch:2 step:11595[D loss: 0.999983] [G loss: 1.000052]\n",
      "epoch:2 step:11600[D loss: 0.999971] [G loss: 1.000056]\n",
      "##############\n",
      "[0.88915401 0.85795532 0.8125118  0.8312949  0.81550973 0.82521216\n",
      " 0.88118481 0.82439522 0.82782517 0.83128671]\n",
      "##########\n",
      "epoch:2 step:11605[D loss: 0.999982] [G loss: 1.000054]\n",
      "epoch:2 step:11610[D loss: 0.999968] [G loss: 1.000042]\n",
      "epoch:2 step:11615[D loss: 0.999957] [G loss: 1.000058]\n",
      "epoch:2 step:11620[D loss: 0.999970] [G loss: 1.000057]\n",
      "epoch:2 step:11625[D loss: 0.999970] [G loss: 1.000046]\n",
      "epoch:2 step:11630[D loss: 0.999976] [G loss: 1.000044]\n",
      "epoch:2 step:11635[D loss: 0.999973] [G loss: 1.000038]\n",
      "epoch:2 step:11640[D loss: 0.999965] [G loss: 1.000052]\n",
      "epoch:2 step:11645[D loss: 0.999973] [G loss: 1.000060]\n",
      "epoch:2 step:11650[D loss: 0.999976] [G loss: 1.000048]\n",
      "epoch:2 step:11655[D loss: 0.999984] [G loss: 1.000047]\n",
      "epoch:2 step:11660[D loss: 0.999973] [G loss: 1.000051]\n",
      "epoch:2 step:11665[D loss: 0.999967] [G loss: 1.000056]\n",
      "epoch:2 step:11670[D loss: 0.999975] [G loss: 1.000049]\n",
      "epoch:2 step:11675[D loss: 0.999981] [G loss: 1.000042]\n",
      "epoch:2 step:11680[D loss: 0.999965] [G loss: 1.000058]\n",
      "epoch:2 step:11685[D loss: 0.999980] [G loss: 1.000067]\n",
      "epoch:2 step:11690[D loss: 0.999978] [G loss: 1.000060]\n",
      "epoch:2 step:11695[D loss: 0.999977] [G loss: 1.000065]\n",
      "epoch:2 step:11700[D loss: 1.000002] [G loss: 1.000005]\n",
      "epoch:2 step:11705[D loss: 0.999986] [G loss: 1.000090]\n",
      "epoch:2 step:11710[D loss: 0.999957] [G loss: 1.000081]\n",
      "epoch:2 step:11715[D loss: 0.999963] [G loss: 1.000064]\n",
      "epoch:3 step:11720[D loss: 0.999980] [G loss: 1.000041]\n",
      "epoch:3 step:11725[D loss: 0.999971] [G loss: 1.000053]\n",
      "epoch:3 step:11730[D loss: 0.999968] [G loss: 1.000060]\n",
      "epoch:3 step:11735[D loss: 0.999969] [G loss: 1.000077]\n",
      "epoch:3 step:11740[D loss: 0.999965] [G loss: 1.000068]\n",
      "epoch:3 step:11745[D loss: 0.999974] [G loss: 1.000058]\n",
      "epoch:3 step:11750[D loss: 0.999971] [G loss: 1.000060]\n",
      "epoch:3 step:11755[D loss: 0.999971] [G loss: 1.000057]\n",
      "epoch:3 step:11760[D loss: 0.999990] [G loss: 1.000007]\n",
      "epoch:3 step:11765[D loss: 0.999962] [G loss: 1.000067]\n",
      "epoch:3 step:11770[D loss: 0.999973] [G loss: 1.000050]\n",
      "epoch:3 step:11775[D loss: 0.999975] [G loss: 1.000052]\n",
      "epoch:3 step:11780[D loss: 0.999978] [G loss: 1.000065]\n",
      "epoch:3 step:11785[D loss: 0.999971] [G loss: 1.000052]\n",
      "epoch:3 step:11790[D loss: 0.999971] [G loss: 1.000047]\n",
      "epoch:3 step:11795[D loss: 0.999971] [G loss: 1.000043]\n",
      "epoch:3 step:11800[D loss: 0.999962] [G loss: 1.000069]\n",
      "##############\n",
      "[0.85619391 0.85636937 0.8277541  0.80902926 0.78324274 0.8187886\n",
      " 0.87118849 0.82805479 0.80314378 0.83072552]\n",
      "##########\n",
      "epoch:3 step:11805[D loss: 0.999969] [G loss: 1.000064]\n",
      "epoch:3 step:11810[D loss: 0.999973] [G loss: 1.000060]\n",
      "epoch:3 step:11815[D loss: 0.999973] [G loss: 1.000061]\n",
      "epoch:3 step:11820[D loss: 0.999978] [G loss: 1.000033]\n",
      "epoch:3 step:11825[D loss: 0.999967] [G loss: 1.000057]\n",
      "epoch:3 step:11830[D loss: 0.999976] [G loss: 1.000055]\n",
      "epoch:3 step:11835[D loss: 0.999970] [G loss: 1.000050]\n",
      "epoch:3 step:11840[D loss: 0.999972] [G loss: 1.000048]\n",
      "epoch:3 step:11845[D loss: 0.999970] [G loss: 1.000048]\n",
      "epoch:3 step:11850[D loss: 0.999974] [G loss: 1.000066]\n",
      "epoch:3 step:11855[D loss: 0.999972] [G loss: 1.000054]\n",
      "epoch:3 step:11860[D loss: 0.999974] [G loss: 1.000055]\n",
      "epoch:3 step:11865[D loss: 0.999966] [G loss: 1.000051]\n",
      "epoch:3 step:11870[D loss: 0.999970] [G loss: 1.000048]\n",
      "epoch:3 step:11875[D loss: 0.999974] [G loss: 1.000057]\n",
      "epoch:3 step:11880[D loss: 0.999973] [G loss: 1.000059]\n",
      "epoch:3 step:11885[D loss: 0.999970] [G loss: 1.000060]\n",
      "epoch:3 step:11890[D loss: 0.999972] [G loss: 1.000067]\n",
      "epoch:3 step:11895[D loss: 0.999971] [G loss: 1.000068]\n",
      "epoch:3 step:11900[D loss: 0.999976] [G loss: 1.000060]\n",
      "epoch:3 step:11905[D loss: 0.999973] [G loss: 1.000056]\n",
      "epoch:3 step:11910[D loss: 0.999977] [G loss: 1.000058]\n",
      "epoch:3 step:11915[D loss: 0.999981] [G loss: 1.000052]\n",
      "epoch:3 step:11920[D loss: 0.999973] [G loss: 1.000056]\n",
      "epoch:3 step:11925[D loss: 0.999972] [G loss: 1.000048]\n",
      "epoch:3 step:11930[D loss: 0.999972] [G loss: 1.000055]\n",
      "epoch:3 step:11935[D loss: 0.999983] [G loss: 1.000045]\n",
      "epoch:3 step:11940[D loss: 0.999974] [G loss: 1.000061]\n",
      "epoch:3 step:11945[D loss: 0.999970] [G loss: 1.000057]\n",
      "epoch:3 step:11950[D loss: 0.999970] [G loss: 1.000044]\n",
      "epoch:3 step:11955[D loss: 0.999967] [G loss: 1.000061]\n",
      "epoch:3 step:11960[D loss: 0.999968] [G loss: 1.000060]\n",
      "epoch:3 step:11965[D loss: 0.999975] [G loss: 1.000053]\n",
      "epoch:3 step:11970[D loss: 0.999971] [G loss: 1.000063]\n",
      "epoch:3 step:11975[D loss: 0.999975] [G loss: 1.000073]\n",
      "epoch:3 step:11980[D loss: 0.999974] [G loss: 1.000057]\n",
      "epoch:3 step:11985[D loss: 0.999976] [G loss: 1.000052]\n",
      "epoch:3 step:11990[D loss: 0.999976] [G loss: 1.000062]\n",
      "epoch:3 step:11995[D loss: 0.999972] [G loss: 1.000055]\n",
      "epoch:3 step:12000[D loss: 0.999976] [G loss: 1.000055]\n",
      "##############\n",
      "[0.8520651  0.86064002 0.82055116 0.84361754 0.7967039  0.84541274\n",
      " 0.87615106 0.81934891 0.82063543 0.8232628 ]\n",
      "##########\n",
      "epoch:3 step:12005[D loss: 0.999972] [G loss: 1.000066]\n",
      "epoch:3 step:12010[D loss: 0.999975] [G loss: 1.000061]\n",
      "epoch:3 step:12015[D loss: 0.999974] [G loss: 1.000061]\n",
      "epoch:3 step:12020[D loss: 0.999973] [G loss: 1.000052]\n",
      "epoch:3 step:12025[D loss: 0.999971] [G loss: 1.000059]\n",
      "epoch:3 step:12030[D loss: 0.999972] [G loss: 1.000056]\n",
      "epoch:3 step:12035[D loss: 0.999975] [G loss: 1.000059]\n",
      "epoch:3 step:12040[D loss: 0.999972] [G loss: 1.000073]\n",
      "epoch:3 step:12045[D loss: 0.999973] [G loss: 1.000064]\n",
      "epoch:3 step:12050[D loss: 0.999970] [G loss: 1.000060]\n",
      "epoch:3 step:12055[D loss: 0.999976] [G loss: 1.000051]\n",
      "epoch:3 step:12060[D loss: 0.999967] [G loss: 1.000064]\n",
      "epoch:3 step:12065[D loss: 0.999972] [G loss: 1.000058]\n",
      "epoch:3 step:12070[D loss: 0.999972] [G loss: 1.000059]\n",
      "epoch:3 step:12075[D loss: 0.999973] [G loss: 1.000054]\n",
      "epoch:3 step:12080[D loss: 0.999974] [G loss: 1.000043]\n",
      "epoch:3 step:12085[D loss: 0.999965] [G loss: 1.000063]\n",
      "epoch:3 step:12090[D loss: 0.999977] [G loss: 1.000059]\n",
      "epoch:3 step:12095[D loss: 0.999972] [G loss: 1.000066]\n",
      "epoch:3 step:12100[D loss: 0.999977] [G loss: 1.000057]\n",
      "epoch:3 step:12105[D loss: 0.999983] [G loss: 1.000046]\n",
      "epoch:3 step:12110[D loss: 0.999975] [G loss: 1.000073]\n",
      "epoch:3 step:12115[D loss: 0.999972] [G loss: 1.000059]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:3 step:12120[D loss: 0.999970] [G loss: 1.000064]\n",
      "epoch:3 step:12125[D loss: 0.999972] [G loss: 1.000055]\n",
      "epoch:3 step:12130[D loss: 0.999979] [G loss: 1.000053]\n",
      "epoch:3 step:12135[D loss: 0.999969] [G loss: 1.000060]\n",
      "epoch:3 step:12140[D loss: 0.999962] [G loss: 1.000065]\n",
      "epoch:3 step:12145[D loss: 0.999970] [G loss: 1.000062]\n",
      "epoch:3 step:12150[D loss: 0.999965] [G loss: 1.000049]\n",
      "epoch:3 step:12155[D loss: 0.999977] [G loss: 1.000053]\n",
      "epoch:3 step:12160[D loss: 0.999972] [G loss: 1.000067]\n",
      "epoch:3 step:12165[D loss: 0.999969] [G loss: 1.000068]\n",
      "epoch:3 step:12170[D loss: 0.999974] [G loss: 1.000054]\n",
      "epoch:3 step:12175[D loss: 0.999980] [G loss: 1.000038]\n",
      "epoch:3 step:12180[D loss: 0.999995] [G loss: 1.000039]\n",
      "epoch:3 step:12185[D loss: 0.999986] [G loss: 1.000059]\n",
      "epoch:3 step:12190[D loss: 0.999967] [G loss: 1.000077]\n",
      "epoch:3 step:12195[D loss: 0.999986] [G loss: 1.000055]\n",
      "epoch:3 step:12200[D loss: 0.999964] [G loss: 1.000072]\n",
      "##############\n",
      "[0.86129354 0.85411898 0.8333355  0.81065199 0.81122939 0.81879146\n",
      " 0.85621494 0.83620262 0.84509578 0.85261655]\n",
      "##########\n",
      "epoch:3 step:12205[D loss: 0.999968] [G loss: 1.000080]\n",
      "epoch:3 step:12210[D loss: 0.999962] [G loss: 1.000067]\n",
      "epoch:3 step:12215[D loss: 0.999968] [G loss: 1.000066]\n",
      "epoch:3 step:12220[D loss: 0.999970] [G loss: 1.000057]\n",
      "epoch:3 step:12225[D loss: 0.999971] [G loss: 1.000057]\n",
      "epoch:3 step:12230[D loss: 0.999971] [G loss: 1.000059]\n",
      "epoch:3 step:12235[D loss: 0.999974] [G loss: 1.000061]\n",
      "epoch:3 step:12240[D loss: 0.999973] [G loss: 1.000054]\n",
      "epoch:3 step:12245[D loss: 0.999984] [G loss: 1.000055]\n",
      "epoch:3 step:12250[D loss: 0.999973] [G loss: 1.000051]\n",
      "epoch:3 step:12255[D loss: 0.999987] [G loss: 1.000047]\n",
      "epoch:3 step:12260[D loss: 0.999983] [G loss: 1.000048]\n",
      "epoch:3 step:12265[D loss: 0.999980] [G loss: 1.000004]\n",
      "epoch:3 step:12270[D loss: 0.999971] [G loss: 0.999981]\n",
      "epoch:3 step:12275[D loss: 0.999979] [G loss: 1.000029]\n",
      "epoch:3 step:12280[D loss: 0.999968] [G loss: 1.000041]\n",
      "epoch:3 step:12285[D loss: 0.999968] [G loss: 1.000068]\n",
      "epoch:3 step:12290[D loss: 0.999981] [G loss: 1.000059]\n",
      "epoch:3 step:12295[D loss: 0.999978] [G loss: 1.000040]\n",
      "epoch:3 step:12300[D loss: 0.999971] [G loss: 1.000053]\n",
      "epoch:3 step:12305[D loss: 0.999973] [G loss: 1.000058]\n",
      "epoch:3 step:12310[D loss: 0.999968] [G loss: 1.000066]\n",
      "epoch:3 step:12315[D loss: 0.999971] [G loss: 1.000053]\n",
      "epoch:3 step:12320[D loss: 0.999976] [G loss: 1.000054]\n",
      "epoch:3 step:12325[D loss: 0.999967] [G loss: 1.000058]\n",
      "epoch:3 step:12330[D loss: 0.999969] [G loss: 1.000063]\n",
      "epoch:3 step:12335[D loss: 0.999973] [G loss: 1.000051]\n",
      "epoch:3 step:12340[D loss: 0.999970] [G loss: 1.000055]\n",
      "epoch:3 step:12345[D loss: 0.999985] [G loss: 1.000051]\n",
      "epoch:3 step:12350[D loss: 0.999987] [G loss: 1.000048]\n",
      "epoch:3 step:12355[D loss: 0.999979] [G loss: 1.000044]\n",
      "epoch:3 step:12360[D loss: 0.999999] [G loss: 1.000020]\n",
      "epoch:3 step:12365[D loss: 0.999997] [G loss: 1.000030]\n",
      "epoch:3 step:12370[D loss: 0.999970] [G loss: 1.000061]\n",
      "epoch:3 step:12375[D loss: 0.999962] [G loss: 1.000071]\n",
      "epoch:3 step:12380[D loss: 0.999967] [G loss: 1.000064]\n",
      "epoch:3 step:12385[D loss: 0.999971] [G loss: 1.000057]\n",
      "epoch:3 step:12390[D loss: 0.999976] [G loss: 1.000054]\n",
      "epoch:3 step:12395[D loss: 0.999977] [G loss: 1.000065]\n",
      "epoch:3 step:12400[D loss: 0.999974] [G loss: 1.000061]\n",
      "##############\n",
      "[0.85667859 0.87617985 0.830633   0.8354267  0.78554865 0.82394946\n",
      " 0.86141046 0.82923181 0.81394215 0.83643546]\n",
      "##########\n",
      "epoch:3 step:12405[D loss: 0.999978] [G loss: 1.000059]\n",
      "epoch:3 step:12410[D loss: 0.999971] [G loss: 1.000070]\n",
      "epoch:3 step:12415[D loss: 0.999977] [G loss: 1.000060]\n",
      "epoch:3 step:12420[D loss: 0.999982] [G loss: 1.000029]\n",
      "epoch:3 step:12425[D loss: 0.999967] [G loss: 1.000064]\n",
      "epoch:3 step:12430[D loss: 0.999975] [G loss: 1.000055]\n",
      "epoch:3 step:12435[D loss: 0.999972] [G loss: 1.000047]\n",
      "epoch:3 step:12440[D loss: 0.999984] [G loss: 1.000050]\n",
      "epoch:3 step:12445[D loss: 0.999972] [G loss: 1.000058]\n",
      "epoch:3 step:12450[D loss: 0.999975] [G loss: 1.000042]\n",
      "epoch:3 step:12455[D loss: 0.999963] [G loss: 1.000062]\n",
      "epoch:3 step:12460[D loss: 0.999978] [G loss: 1.000048]\n",
      "epoch:3 step:12465[D loss: 0.999970] [G loss: 1.000054]\n",
      "epoch:3 step:12470[D loss: 0.999964] [G loss: 1.000062]\n",
      "epoch:3 step:12475[D loss: 0.999977] [G loss: 1.000050]\n",
      "epoch:3 step:12480[D loss: 0.999968] [G loss: 1.000054]\n",
      "epoch:3 step:12485[D loss: 0.999976] [G loss: 1.000032]\n",
      "epoch:3 step:12490[D loss: 0.999973] [G loss: 1.000053]\n",
      "epoch:3 step:12495[D loss: 0.999969] [G loss: 1.000069]\n",
      "epoch:3 step:12500[D loss: 0.999979] [G loss: 1.000057]\n",
      "epoch:3 step:12505[D loss: 0.999980] [G loss: 1.000045]\n",
      "epoch:3 step:12510[D loss: 0.999973] [G loss: 1.000050]\n",
      "epoch:3 step:12515[D loss: 0.999970] [G loss: 1.000049]\n",
      "epoch:3 step:12520[D loss: 0.999974] [G loss: 1.000047]\n",
      "epoch:3 step:12525[D loss: 0.999973] [G loss: 1.000050]\n",
      "epoch:3 step:12530[D loss: 0.999970] [G loss: 1.000054]\n",
      "epoch:3 step:12535[D loss: 0.999973] [G loss: 1.000053]\n",
      "epoch:3 step:12540[D loss: 0.999982] [G loss: 1.000055]\n",
      "epoch:3 step:12545[D loss: 0.999969] [G loss: 1.000050]\n",
      "epoch:3 step:12550[D loss: 0.999972] [G loss: 1.000049]\n",
      "epoch:3 step:12555[D loss: 0.999979] [G loss: 1.000055]\n",
      "epoch:3 step:12560[D loss: 0.999978] [G loss: 1.000053]\n",
      "epoch:3 step:12565[D loss: 0.999981] [G loss: 1.000051]\n",
      "epoch:3 step:12570[D loss: 0.999973] [G loss: 1.000053]\n",
      "epoch:3 step:12575[D loss: 0.999970] [G loss: 1.000050]\n",
      "epoch:3 step:12580[D loss: 0.999977] [G loss: 1.000041]\n",
      "epoch:3 step:12585[D loss: 0.999970] [G loss: 1.000067]\n",
      "epoch:3 step:12590[D loss: 0.999968] [G loss: 1.000053]\n",
      "epoch:3 step:12595[D loss: 0.999971] [G loss: 1.000057]\n",
      "epoch:3 step:12600[D loss: 0.999976] [G loss: 1.000054]\n",
      "##############\n",
      "[0.86655141 0.8492545  0.81650327 0.84126993 0.79665069 0.81094295\n",
      " 0.85341277 0.84813291 0.79722888 0.83812771]\n",
      "##########\n",
      "epoch:3 step:12605[D loss: 0.999971] [G loss: 1.000046]\n",
      "epoch:3 step:12610[D loss: 0.999980] [G loss: 1.000060]\n",
      "epoch:3 step:12615[D loss: 0.999977] [G loss: 1.000063]\n",
      "epoch:3 step:12620[D loss: 0.999970] [G loss: 1.000061]\n",
      "epoch:3 step:12625[D loss: 0.999970] [G loss: 1.000051]\n",
      "epoch:3 step:12630[D loss: 0.999986] [G loss: 1.000038]\n",
      "epoch:3 step:12635[D loss: 0.999968] [G loss: 1.000065]\n",
      "epoch:3 step:12640[D loss: 0.999972] [G loss: 1.000063]\n",
      "epoch:3 step:12645[D loss: 0.999980] [G loss: 1.000044]\n",
      "epoch:3 step:12650[D loss: 0.999977] [G loss: 1.000045]\n",
      "epoch:3 step:12655[D loss: 1.000000] [G loss: 0.999997]\n",
      "epoch:3 step:12660[D loss: 0.999970] [G loss: 1.000067]\n",
      "epoch:3 step:12665[D loss: 0.999971] [G loss: 1.000076]\n",
      "epoch:3 step:12670[D loss: 0.999966] [G loss: 1.000054]\n",
      "epoch:3 step:12675[D loss: 0.999971] [G loss: 1.000068]\n",
      "epoch:3 step:12680[D loss: 0.999972] [G loss: 1.000061]\n",
      "epoch:3 step:12685[D loss: 0.999967] [G loss: 1.000061]\n",
      "epoch:3 step:12690[D loss: 0.999976] [G loss: 1.000046]\n",
      "epoch:3 step:12695[D loss: 0.999977] [G loss: 1.000068]\n",
      "epoch:3 step:12700[D loss: 0.999967] [G loss: 1.000074]\n",
      "epoch:3 step:12705[D loss: 0.999977] [G loss: 1.000060]\n",
      "epoch:3 step:12710[D loss: 0.999985] [G loss: 1.000043]\n",
      "epoch:3 step:12715[D loss: 0.999974] [G loss: 1.000059]\n",
      "epoch:3 step:12720[D loss: 0.999971] [G loss: 1.000059]\n",
      "epoch:3 step:12725[D loss: 0.999975] [G loss: 1.000070]\n",
      "epoch:3 step:12730[D loss: 0.999977] [G loss: 1.000064]\n",
      "epoch:3 step:12735[D loss: 0.999979] [G loss: 1.000055]\n",
      "epoch:3 step:12740[D loss: 1.000022] [G loss: 1.000035]\n",
      "epoch:3 step:12745[D loss: 0.999978] [G loss: 1.000058]\n",
      "epoch:3 step:12750[D loss: 0.999968] [G loss: 1.000073]\n",
      "epoch:3 step:12755[D loss: 0.999971] [G loss: 1.000053]\n",
      "epoch:3 step:12760[D loss: 0.999975] [G loss: 1.000050]\n",
      "epoch:3 step:12765[D loss: 0.999969] [G loss: 1.000049]\n",
      "epoch:3 step:12770[D loss: 0.999979] [G loss: 1.000048]\n",
      "epoch:3 step:12775[D loss: 0.999979] [G loss: 1.000051]\n",
      "epoch:3 step:12780[D loss: 0.999965] [G loss: 1.000063]\n",
      "epoch:3 step:12785[D loss: 0.999969] [G loss: 1.000064]\n",
      "epoch:3 step:12790[D loss: 0.999983] [G loss: 1.000057]\n",
      "epoch:3 step:12795[D loss: 0.999972] [G loss: 1.000066]\n",
      "epoch:3 step:12800[D loss: 0.999974] [G loss: 1.000068]\n",
      "##############\n",
      "[0.87844846 0.86080496 0.80803589 0.83050755 0.81815303 0.83446538\n",
      " 0.87532295 0.84480619 0.80384846 0.81557891]\n",
      "##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:3 step:12805[D loss: 0.999975] [G loss: 1.000053]\n",
      "epoch:3 step:12810[D loss: 0.999969] [G loss: 1.000057]\n",
      "epoch:3 step:12815[D loss: 0.999980] [G loss: 1.000053]\n",
      "epoch:3 step:12820[D loss: 0.999968] [G loss: 1.000063]\n",
      "epoch:3 step:12825[D loss: 0.999973] [G loss: 1.000064]\n",
      "epoch:3 step:12830[D loss: 0.999976] [G loss: 1.000054]\n",
      "epoch:3 step:12835[D loss: 0.999972] [G loss: 1.000054]\n",
      "epoch:3 step:12840[D loss: 0.999976] [G loss: 1.000053]\n",
      "epoch:3 step:12845[D loss: 0.999980] [G loss: 1.000040]\n",
      "epoch:3 step:12850[D loss: 0.999976] [G loss: 1.000054]\n",
      "epoch:3 step:12855[D loss: 0.999978] [G loss: 1.000053]\n",
      "epoch:3 step:12860[D loss: 0.999975] [G loss: 1.000061]\n",
      "epoch:3 step:12865[D loss: 0.999972] [G loss: 1.000050]\n",
      "epoch:3 step:12870[D loss: 0.999972] [G loss: 1.000055]\n",
      "epoch:3 step:12875[D loss: 0.999974] [G loss: 1.000064]\n",
      "epoch:3 step:12880[D loss: 0.999974] [G loss: 1.000047]\n",
      "epoch:3 step:12885[D loss: 0.999984] [G loss: 1.000037]\n",
      "epoch:3 step:12890[D loss: 0.999969] [G loss: 1.000054]\n",
      "epoch:3 step:12895[D loss: 0.999975] [G loss: 1.000057]\n",
      "epoch:3 step:12900[D loss: 0.999975] [G loss: 1.000058]\n",
      "epoch:3 step:12905[D loss: 0.999972] [G loss: 1.000058]\n",
      "epoch:3 step:12910[D loss: 0.999974] [G loss: 1.000058]\n",
      "epoch:3 step:12915[D loss: 0.999972] [G loss: 1.000059]\n",
      "epoch:3 step:12920[D loss: 0.999977] [G loss: 1.000060]\n",
      "epoch:3 step:12925[D loss: 0.999979] [G loss: 1.000038]\n",
      "epoch:3 step:12930[D loss: 0.999967] [G loss: 1.000051]\n",
      "epoch:3 step:12935[D loss: 0.999970] [G loss: 1.000059]\n",
      "epoch:3 step:12940[D loss: 0.999978] [G loss: 1.000051]\n",
      "epoch:3 step:12945[D loss: 0.999981] [G loss: 1.000047]\n",
      "epoch:3 step:12950[D loss: 0.999971] [G loss: 1.000053]\n",
      "epoch:3 step:12955[D loss: 0.999976] [G loss: 1.000051]\n",
      "epoch:3 step:12960[D loss: 0.999972] [G loss: 1.000046]\n",
      "epoch:3 step:12965[D loss: 0.999970] [G loss: 1.000050]\n",
      "epoch:3 step:12970[D loss: 0.999977] [G loss: 1.000052]\n",
      "epoch:3 step:12975[D loss: 0.999977] [G loss: 1.000051]\n",
      "epoch:3 step:12980[D loss: 0.999976] [G loss: 1.000061]\n",
      "epoch:3 step:12985[D loss: 0.999972] [G loss: 1.000050]\n",
      "epoch:3 step:12990[D loss: 0.999980] [G loss: 1.000048]\n",
      "epoch:3 step:12995[D loss: 0.999975] [G loss: 1.000048]\n",
      "epoch:3 step:13000[D loss: 0.999973] [G loss: 1.000055]\n",
      "##############\n",
      "[0.88216645 0.86394396 0.83516228 0.830117   0.79880157 0.82092341\n",
      " 0.84985971 0.8391578  0.81631895 0.80362536]\n",
      "##########\n",
      "epoch:3 step:13005[D loss: 0.999973] [G loss: 1.000061]\n",
      "epoch:3 step:13010[D loss: 0.999984] [G loss: 1.000041]\n",
      "epoch:3 step:13015[D loss: 0.999982] [G loss: 1.000040]\n",
      "epoch:3 step:13020[D loss: 0.999975] [G loss: 1.000047]\n",
      "epoch:3 step:13025[D loss: 0.999972] [G loss: 1.000050]\n",
      "epoch:3 step:13030[D loss: 0.999977] [G loss: 1.000047]\n",
      "epoch:3 step:13035[D loss: 0.999972] [G loss: 1.000057]\n",
      "epoch:3 step:13040[D loss: 0.999972] [G loss: 1.000058]\n",
      "epoch:3 step:13045[D loss: 0.999969] [G loss: 1.000081]\n",
      "epoch:3 step:13050[D loss: 0.999976] [G loss: 1.000059]\n",
      "epoch:3 step:13055[D loss: 0.999978] [G loss: 1.000060]\n",
      "epoch:3 step:13060[D loss: 0.999971] [G loss: 1.000048]\n",
      "epoch:3 step:13065[D loss: 0.999970] [G loss: 1.000060]\n",
      "epoch:3 step:13070[D loss: 0.999974] [G loss: 1.000060]\n",
      "epoch:3 step:13075[D loss: 0.999971] [G loss: 1.000050]\n",
      "epoch:3 step:13080[D loss: 0.999972] [G loss: 1.000058]\n",
      "epoch:3 step:13085[D loss: 0.999967] [G loss: 1.000059]\n",
      "epoch:3 step:13090[D loss: 0.999977] [G loss: 1.000064]\n",
      "epoch:3 step:13095[D loss: 0.999974] [G loss: 1.000055]\n",
      "epoch:3 step:13100[D loss: 0.999983] [G loss: 1.000040]\n",
      "epoch:3 step:13105[D loss: 0.999969] [G loss: 1.000048]\n",
      "epoch:3 step:13110[D loss: 0.999973] [G loss: 1.000043]\n",
      "epoch:3 step:13115[D loss: 0.999978] [G loss: 1.000037]\n",
      "epoch:3 step:13120[D loss: 0.999969] [G loss: 1.000056]\n",
      "epoch:3 step:13125[D loss: 0.999974] [G loss: 1.000040]\n",
      "epoch:3 step:13130[D loss: 0.999970] [G loss: 1.000048]\n",
      "epoch:3 step:13135[D loss: 0.999976] [G loss: 1.000049]\n",
      "epoch:3 step:13140[D loss: 0.999980] [G loss: 1.000035]\n",
      "epoch:3 step:13145[D loss: 0.999980] [G loss: 1.000056]\n",
      "epoch:3 step:13150[D loss: 0.999975] [G loss: 1.000045]\n",
      "epoch:3 step:13155[D loss: 0.999987] [G loss: 0.999996]\n",
      "epoch:3 step:13160[D loss: 0.999956] [G loss: 1.000050]\n",
      "epoch:3 step:13165[D loss: 0.999976] [G loss: 1.000042]\n",
      "epoch:3 step:13170[D loss: 0.999991] [G loss: 1.000004]\n",
      "epoch:3 step:13175[D loss: 0.999981] [G loss: 1.000037]\n",
      "epoch:3 step:13180[D loss: 0.999967] [G loss: 1.000051]\n",
      "epoch:3 step:13185[D loss: 0.999971] [G loss: 1.000061]\n",
      "epoch:3 step:13190[D loss: 0.999974] [G loss: 1.000056]\n",
      "epoch:3 step:13195[D loss: 0.999970] [G loss: 1.000066]\n",
      "epoch:3 step:13200[D loss: 0.999974] [G loss: 1.000055]\n",
      "##############\n",
      "[0.87198265 0.86796036 0.82939472 0.81751965 0.78337215 0.81458794\n",
      " 0.87004899 0.84075331 0.81809385 0.82364298]\n",
      "##########\n",
      "epoch:3 step:13205[D loss: 0.999979] [G loss: 1.000055]\n",
      "epoch:3 step:13210[D loss: 0.999971] [G loss: 1.000055]\n",
      "epoch:3 step:13215[D loss: 0.999975] [G loss: 1.000047]\n",
      "epoch:3 step:13220[D loss: 0.999974] [G loss: 1.000066]\n",
      "epoch:3 step:13225[D loss: 0.999969] [G loss: 1.000049]\n",
      "epoch:3 step:13230[D loss: 0.999972] [G loss: 1.000063]\n",
      "epoch:3 step:13235[D loss: 0.999978] [G loss: 1.000051]\n",
      "epoch:3 step:13240[D loss: 0.999973] [G loss: 1.000047]\n",
      "epoch:3 step:13245[D loss: 0.999974] [G loss: 1.000056]\n",
      "epoch:3 step:13250[D loss: 0.999969] [G loss: 1.000064]\n",
      "epoch:3 step:13255[D loss: 0.999976] [G loss: 1.000055]\n",
      "epoch:3 step:13260[D loss: 0.999980] [G loss: 1.000037]\n",
      "epoch:3 step:13265[D loss: 0.999971] [G loss: 1.000058]\n",
      "epoch:3 step:13270[D loss: 0.999980] [G loss: 1.000067]\n",
      "epoch:3 step:13275[D loss: 0.999972] [G loss: 1.000054]\n",
      "epoch:3 step:13280[D loss: 0.999978] [G loss: 1.000057]\n",
      "epoch:3 step:13285[D loss: 0.999973] [G loss: 1.000060]\n",
      "epoch:3 step:13290[D loss: 0.999988] [G loss: 1.000030]\n",
      "epoch:3 step:13295[D loss: 0.999975] [G loss: 1.000053]\n",
      "epoch:3 step:13300[D loss: 0.999972] [G loss: 1.000067]\n",
      "epoch:3 step:13305[D loss: 0.999974] [G loss: 1.000068]\n",
      "epoch:3 step:13310[D loss: 0.999983] [G loss: 1.000031]\n",
      "epoch:3 step:13315[D loss: 0.999971] [G loss: 1.000057]\n",
      "epoch:3 step:13320[D loss: 0.999971] [G loss: 1.000069]\n",
      "epoch:3 step:13325[D loss: 0.999983] [G loss: 1.000040]\n",
      "epoch:3 step:13330[D loss: 0.999977] [G loss: 1.000051]\n",
      "epoch:3 step:13335[D loss: 0.999972] [G loss: 1.000062]\n",
      "epoch:3 step:13340[D loss: 0.999973] [G loss: 1.000041]\n",
      "epoch:3 step:13345[D loss: 0.999982] [G loss: 1.000036]\n",
      "epoch:3 step:13350[D loss: 0.999974] [G loss: 1.000066]\n",
      "epoch:3 step:13355[D loss: 0.999972] [G loss: 1.000045]\n",
      "epoch:3 step:13360[D loss: 0.999990] [G loss: 1.000053]\n",
      "epoch:3 step:13365[D loss: 0.999971] [G loss: 1.000069]\n",
      "epoch:3 step:13370[D loss: 0.999968] [G loss: 1.000060]\n",
      "epoch:3 step:13375[D loss: 0.999969] [G loss: 1.000047]\n",
      "epoch:3 step:13380[D loss: 0.999976] [G loss: 1.000057]\n",
      "epoch:3 step:13385[D loss: 0.999988] [G loss: 1.000034]\n",
      "epoch:3 step:13390[D loss: 0.999983] [G loss: 1.000040]\n",
      "epoch:3 step:13395[D loss: 0.999975] [G loss: 1.000057]\n",
      "epoch:3 step:13400[D loss: 0.999981] [G loss: 1.000052]\n",
      "##############\n",
      "[0.85368184 0.87314251 0.81909195 0.83395582 0.79478477 0.83265958\n",
      " 0.88424247 0.83805372 0.815674   0.83560946]\n",
      "##########\n",
      "epoch:3 step:13405[D loss: 0.999982] [G loss: 1.000030]\n",
      "epoch:3 step:13410[D loss: 0.999976] [G loss: 1.000028]\n",
      "epoch:3 step:13415[D loss: 0.999970] [G loss: 1.000060]\n",
      "epoch:3 step:13420[D loss: 0.999978] [G loss: 1.000048]\n",
      "epoch:3 step:13425[D loss: 1.000001] [G loss: 1.000022]\n",
      "epoch:3 step:13430[D loss: 0.999973] [G loss: 1.000081]\n",
      "epoch:3 step:13435[D loss: 0.999968] [G loss: 1.000076]\n",
      "epoch:3 step:13440[D loss: 0.999970] [G loss: 1.000071]\n",
      "epoch:3 step:13445[D loss: 0.999983] [G loss: 1.000058]\n",
      "epoch:3 step:13450[D loss: 0.999985] [G loss: 1.000040]\n",
      "epoch:3 step:13455[D loss: 0.999964] [G loss: 1.000048]\n",
      "epoch:3 step:13460[D loss: 0.999967] [G loss: 1.000074]\n",
      "epoch:3 step:13465[D loss: 0.999962] [G loss: 1.000064]\n",
      "epoch:3 step:13470[D loss: 0.999973] [G loss: 1.000060]\n",
      "epoch:3 step:13475[D loss: 0.999980] [G loss: 1.000037]\n",
      "epoch:3 step:13480[D loss: 0.999987] [G loss: 1.000016]\n",
      "epoch:3 step:13485[D loss: 0.999970] [G loss: 1.000050]\n",
      "epoch:3 step:13490[D loss: 0.999978] [G loss: 1.000066]\n",
      "epoch:3 step:13495[D loss: 0.999974] [G loss: 1.000062]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:3 step:13500[D loss: 0.999979] [G loss: 1.000036]\n",
      "epoch:3 step:13505[D loss: 0.999987] [G loss: 1.000049]\n",
      "epoch:3 step:13510[D loss: 0.999979] [G loss: 1.000050]\n",
      "epoch:3 step:13515[D loss: 0.999978] [G loss: 1.000058]\n",
      "epoch:3 step:13520[D loss: 0.999967] [G loss: 1.000048]\n",
      "epoch:3 step:13525[D loss: 0.999978] [G loss: 1.000063]\n",
      "epoch:3 step:13530[D loss: 0.999978] [G loss: 1.000035]\n",
      "epoch:3 step:13535[D loss: 0.999973] [G loss: 1.000059]\n",
      "epoch:3 step:13540[D loss: 0.999967] [G loss: 1.000059]\n",
      "epoch:3 step:13545[D loss: 0.999978] [G loss: 1.000063]\n",
      "epoch:3 step:13550[D loss: 0.999977] [G loss: 1.000074]\n",
      "epoch:3 step:13555[D loss: 0.999976] [G loss: 1.000058]\n",
      "epoch:3 step:13560[D loss: 0.999961] [G loss: 1.000067]\n",
      "epoch:3 step:13565[D loss: 0.999976] [G loss: 1.000056]\n",
      "epoch:3 step:13570[D loss: 0.999990] [G loss: 1.000001]\n",
      "epoch:3 step:13575[D loss: 0.999973] [G loss: 1.000045]\n",
      "epoch:3 step:13580[D loss: 0.999964] [G loss: 1.000073]\n",
      "epoch:3 step:13585[D loss: 0.999969] [G loss: 1.000079]\n",
      "epoch:3 step:13590[D loss: 1.000005] [G loss: 1.000030]\n",
      "epoch:3 step:13595[D loss: 0.999985] [G loss: 1.000050]\n",
      "epoch:3 step:13600[D loss: 0.999977] [G loss: 1.000072]\n",
      "##############\n",
      "[0.84470615 0.90213248 0.82441107 0.82830004 0.78791058 0.83137781\n",
      " 0.85465569 0.82382017 0.8097825  0.8469582 ]\n",
      "##########\n",
      "epoch:3 step:13605[D loss: 0.999966] [G loss: 1.000076]\n",
      "epoch:3 step:13610[D loss: 0.999974] [G loss: 1.000059]\n",
      "epoch:3 step:13615[D loss: 0.999985] [G loss: 1.000034]\n",
      "epoch:3 step:13620[D loss: 0.999985] [G loss: 1.000024]\n",
      "epoch:3 step:13625[D loss: 0.999974] [G loss: 1.000050]\n",
      "epoch:3 step:13630[D loss: 0.999965] [G loss: 1.000069]\n",
      "epoch:3 step:13635[D loss: 0.999973] [G loss: 1.000061]\n",
      "epoch:3 step:13640[D loss: 0.999980] [G loss: 1.000051]\n",
      "epoch:3 step:13645[D loss: 0.999966] [G loss: 1.000057]\n",
      "epoch:3 step:13650[D loss: 0.999980] [G loss: 1.000062]\n",
      "epoch:3 step:13655[D loss: 0.999973] [G loss: 1.000054]\n",
      "epoch:3 step:13660[D loss: 0.999974] [G loss: 1.000042]\n",
      "epoch:3 step:13665[D loss: 0.999970] [G loss: 1.000051]\n",
      "epoch:3 step:13670[D loss: 0.999974] [G loss: 1.000051]\n",
      "epoch:3 step:13675[D loss: 0.999974] [G loss: 1.000053]\n",
      "epoch:3 step:13680[D loss: 0.999982] [G loss: 1.000037]\n",
      "epoch:3 step:13685[D loss: 0.999982] [G loss: 1.000056]\n",
      "epoch:3 step:13690[D loss: 0.999971] [G loss: 1.000056]\n",
      "epoch:3 step:13695[D loss: 0.999973] [G loss: 1.000058]\n",
      "epoch:3 step:13700[D loss: 0.999980] [G loss: 1.000038]\n",
      "epoch:3 step:13705[D loss: 0.999979] [G loss: 1.000056]\n",
      "epoch:3 step:13710[D loss: 0.999976] [G loss: 1.000044]\n",
      "epoch:3 step:13715[D loss: 0.999973] [G loss: 1.000038]\n",
      "epoch:3 step:13720[D loss: 0.999977] [G loss: 1.000058]\n",
      "epoch:3 step:13725[D loss: 0.999974] [G loss: 1.000062]\n",
      "epoch:3 step:13730[D loss: 0.999971] [G loss: 1.000032]\n",
      "epoch:3 step:13735[D loss: 0.999980] [G loss: 1.000025]\n",
      "epoch:3 step:13740[D loss: 0.999964] [G loss: 1.000067]\n",
      "epoch:3 step:13745[D loss: 0.999965] [G loss: 1.000044]\n",
      "epoch:3 step:13750[D loss: 0.999974] [G loss: 1.000040]\n",
      "epoch:3 step:13755[D loss: 0.999967] [G loss: 1.000046]\n",
      "epoch:3 step:13760[D loss: 0.999986] [G loss: 1.000044]\n",
      "epoch:3 step:13765[D loss: 0.999970] [G loss: 1.000061]\n",
      "epoch:3 step:13770[D loss: 0.999979] [G loss: 1.000047]\n",
      "epoch:3 step:13775[D loss: 0.999977] [G loss: 1.000055]\n",
      "epoch:3 step:13780[D loss: 0.999989] [G loss: 1.000036]\n",
      "epoch:3 step:13785[D loss: 0.999966] [G loss: 1.000072]\n",
      "epoch:3 step:13790[D loss: 0.999969] [G loss: 1.000061]\n",
      "epoch:3 step:13795[D loss: 0.999975] [G loss: 1.000047]\n",
      "epoch:3 step:13800[D loss: 0.999969] [G loss: 1.000052]\n",
      "##############\n",
      "[0.87360849 0.88217123 0.82584441 0.83451338 0.80638115 0.82857507\n",
      " 0.88578602 0.82921267 0.82904997 0.82845983]\n",
      "##########\n",
      "epoch:3 step:13805[D loss: 0.999974] [G loss: 1.000050]\n",
      "epoch:3 step:13810[D loss: 0.999979] [G loss: 1.000055]\n",
      "epoch:3 step:13815[D loss: 0.999976] [G loss: 1.000051]\n",
      "epoch:3 step:13820[D loss: 0.999980] [G loss: 1.000054]\n",
      "epoch:3 step:13825[D loss: 0.999973] [G loss: 1.000061]\n",
      "epoch:3 step:13830[D loss: 0.999971] [G loss: 1.000054]\n",
      "epoch:3 step:13835[D loss: 0.999971] [G loss: 1.000056]\n",
      "epoch:3 step:13840[D loss: 0.999967] [G loss: 1.000059]\n",
      "epoch:3 step:13845[D loss: 0.999968] [G loss: 1.000054]\n",
      "epoch:3 step:13850[D loss: 0.999984] [G loss: 1.000042]\n",
      "epoch:3 step:13855[D loss: 0.999963] [G loss: 1.000053]\n",
      "epoch:3 step:13860[D loss: 0.999978] [G loss: 1.000057]\n",
      "epoch:3 step:13865[D loss: 0.999975] [G loss: 1.000036]\n",
      "epoch:3 step:13870[D loss: 0.999981] [G loss: 1.000024]\n",
      "epoch:3 step:13875[D loss: 0.999968] [G loss: 1.000068]\n",
      "epoch:3 step:13880[D loss: 0.999970] [G loss: 1.000062]\n",
      "epoch:3 step:13885[D loss: 0.999973] [G loss: 1.000055]\n",
      "epoch:3 step:13890[D loss: 0.999980] [G loss: 1.000058]\n",
      "epoch:3 step:13895[D loss: 1.000014] [G loss: 0.999987]\n",
      "epoch:3 step:13900[D loss: 0.999983] [G loss: 1.000034]\n",
      "epoch:3 step:13905[D loss: 0.999964] [G loss: 1.000061]\n",
      "epoch:3 step:13910[D loss: 0.999964] [G loss: 1.000077]\n",
      "epoch:3 step:13915[D loss: 0.999976] [G loss: 1.000054]\n",
      "epoch:3 step:13920[D loss: 0.999982] [G loss: 1.000020]\n",
      "epoch:3 step:13925[D loss: 0.999989] [G loss: 1.000011]\n",
      "epoch:3 step:13930[D loss: 0.999970] [G loss: 1.000064]\n",
      "epoch:3 step:13935[D loss: 0.999973] [G loss: 1.000076]\n",
      "epoch:3 step:13940[D loss: 0.999979] [G loss: 1.000054]\n",
      "epoch:3 step:13945[D loss: 0.999975] [G loss: 1.000038]\n",
      "epoch:3 step:13950[D loss: 0.999977] [G loss: 1.000043]\n",
      "epoch:3 step:13955[D loss: 0.999970] [G loss: 1.000070]\n",
      "epoch:3 step:13960[D loss: 0.999972] [G loss: 1.000062]\n",
      "epoch:3 step:13965[D loss: 0.999972] [G loss: 1.000066]\n",
      "epoch:3 step:13970[D loss: 0.999977] [G loss: 1.000056]\n",
      "epoch:3 step:13975[D loss: 0.999975] [G loss: 1.000065]\n",
      "epoch:3 step:13980[D loss: 0.999974] [G loss: 1.000054]\n",
      "epoch:3 step:13985[D loss: 0.999977] [G loss: 1.000058]\n",
      "epoch:3 step:13990[D loss: 0.999975] [G loss: 1.000054]\n",
      "epoch:3 step:13995[D loss: 0.999979] [G loss: 1.000026]\n",
      "epoch:3 step:14000[D loss: 0.999980] [G loss: 1.000054]\n",
      "##############\n",
      "[0.87818068 0.85778385 0.83623775 0.84305833 0.79613298 0.79972386\n",
      " 0.86689498 0.85039083 0.83090583 0.83894393]\n",
      "##########\n",
      "epoch:3 step:14005[D loss: 0.999982] [G loss: 1.000035]\n",
      "epoch:3 step:14010[D loss: 0.999976] [G loss: 1.000047]\n",
      "epoch:3 step:14015[D loss: 0.999972] [G loss: 1.000049]\n",
      "epoch:3 step:14020[D loss: 0.999973] [G loss: 1.000053]\n",
      "epoch:3 step:14025[D loss: 0.999973] [G loss: 1.000063]\n",
      "epoch:3 step:14030[D loss: 0.999979] [G loss: 1.000054]\n",
      "epoch:3 step:14035[D loss: 0.999959] [G loss: 1.000077]\n",
      "epoch:3 step:14040[D loss: 0.999978] [G loss: 1.000052]\n",
      "epoch:3 step:14045[D loss: 0.999975] [G loss: 1.000053]\n",
      "epoch:3 step:14050[D loss: 0.999973] [G loss: 1.000045]\n",
      "epoch:3 step:14055[D loss: 0.999975] [G loss: 1.000053]\n",
      "epoch:3 step:14060[D loss: 0.999978] [G loss: 1.000043]\n",
      "epoch:3 step:14065[D loss: 0.999971] [G loss: 1.000058]\n",
      "epoch:3 step:14070[D loss: 0.999975] [G loss: 1.000051]\n",
      "epoch:3 step:14075[D loss: 0.999978] [G loss: 1.000059]\n",
      "epoch:3 step:14080[D loss: 0.999980] [G loss: 1.000050]\n",
      "epoch:3 step:14085[D loss: 0.999967] [G loss: 1.000061]\n",
      "epoch:3 step:14090[D loss: 0.999974] [G loss: 1.000067]\n",
      "epoch:3 step:14095[D loss: 0.999979] [G loss: 1.000057]\n",
      "epoch:3 step:14100[D loss: 0.999974] [G loss: 1.000064]\n",
      "epoch:3 step:14105[D loss: 0.999967] [G loss: 1.000068]\n",
      "epoch:3 step:14110[D loss: 0.999973] [G loss: 1.000061]\n",
      "epoch:3 step:14115[D loss: 0.999976] [G loss: 1.000055]\n",
      "epoch:3 step:14120[D loss: 0.999974] [G loss: 1.000057]\n",
      "epoch:3 step:14125[D loss: 0.999971] [G loss: 1.000062]\n",
      "epoch:3 step:14130[D loss: 0.999975] [G loss: 1.000043]\n",
      "epoch:3 step:14135[D loss: 0.999967] [G loss: 1.000057]\n",
      "epoch:3 step:14140[D loss: 0.999971] [G loss: 1.000056]\n",
      "epoch:3 step:14145[D loss: 0.999973] [G loss: 1.000061]\n",
      "epoch:3 step:14150[D loss: 0.999971] [G loss: 1.000072]\n",
      "epoch:3 step:14155[D loss: 0.999971] [G loss: 1.000056]\n",
      "epoch:3 step:14160[D loss: 0.999985] [G loss: 1.000044]\n",
      "epoch:3 step:14165[D loss: 0.999979] [G loss: 1.000048]\n",
      "epoch:3 step:14170[D loss: 0.999972] [G loss: 1.000066]\n",
      "epoch:3 step:14175[D loss: 0.999976] [G loss: 1.000054]\n",
      "epoch:3 step:14180[D loss: 0.999979] [G loss: 1.000042]\n",
      "epoch:3 step:14185[D loss: 0.999971] [G loss: 1.000040]\n",
      "epoch:3 step:14190[D loss: 0.999986] [G loss: 1.000036]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:3 step:14195[D loss: 0.999969] [G loss: 1.000058]\n",
      "epoch:3 step:14200[D loss: 0.999977] [G loss: 1.000060]\n",
      "##############\n",
      "[0.85196589 0.85439957 0.82237761 0.82664622 0.81323623 0.82754691\n",
      " 0.83915338 0.84930432 0.8192183  0.84143767]\n",
      "##########\n",
      "epoch:3 step:14205[D loss: 0.999967] [G loss: 1.000054]\n",
      "epoch:3 step:14210[D loss: 0.999967] [G loss: 1.000042]\n",
      "epoch:3 step:14215[D loss: 0.999976] [G loss: 1.000042]\n",
      "epoch:3 step:14220[D loss: 0.999981] [G loss: 1.000043]\n",
      "epoch:3 step:14225[D loss: 0.999964] [G loss: 1.000072]\n",
      "epoch:3 step:14230[D loss: 0.999977] [G loss: 1.000059]\n",
      "epoch:3 step:14235[D loss: 0.999988] [G loss: 0.999998]\n",
      "epoch:3 step:14240[D loss: 0.999998] [G loss: 1.000054]\n",
      "epoch:3 step:14245[D loss: 0.999955] [G loss: 1.000082]\n",
      "epoch:3 step:14250[D loss: 0.999974] [G loss: 1.000052]\n",
      "epoch:3 step:14255[D loss: 0.999981] [G loss: 1.000029]\n",
      "epoch:3 step:14260[D loss: 1.000007] [G loss: 0.999993]\n",
      "epoch:3 step:14265[D loss: 0.999971] [G loss: 1.000076]\n",
      "epoch:3 step:14270[D loss: 0.999970] [G loss: 1.000087]\n",
      "epoch:3 step:14275[D loss: 0.999970] [G loss: 1.000081]\n",
      "epoch:3 step:14280[D loss: 0.999965] [G loss: 1.000076]\n",
      "epoch:3 step:14285[D loss: 0.999974] [G loss: 1.000058]\n",
      "epoch:3 step:14290[D loss: 0.999990] [G loss: 1.000000]\n",
      "epoch:3 step:14295[D loss: 1.000020] [G loss: 0.999961]\n",
      "epoch:3 step:14300[D loss: 0.999955] [G loss: 1.000083]\n",
      "epoch:3 step:14305[D loss: 0.999970] [G loss: 1.000068]\n",
      "epoch:3 step:14310[D loss: 0.999973] [G loss: 1.000061]\n",
      "epoch:3 step:14315[D loss: 0.999975] [G loss: 1.000054]\n",
      "epoch:3 step:14320[D loss: 0.999970] [G loss: 1.000057]\n",
      "epoch:3 step:14325[D loss: 0.999968] [G loss: 1.000049]\n",
      "epoch:3 step:14330[D loss: 0.999991] [G loss: 1.000043]\n",
      "epoch:3 step:14335[D loss: 0.999965] [G loss: 1.000057]\n",
      "epoch:3 step:14340[D loss: 0.999967] [G loss: 1.000060]\n",
      "epoch:3 step:14345[D loss: 0.999973] [G loss: 1.000056]\n",
      "epoch:3 step:14350[D loss: 0.999975] [G loss: 1.000062]\n",
      "epoch:3 step:14355[D loss: 0.999975] [G loss: 1.000058]\n",
      "epoch:3 step:14360[D loss: 0.999978] [G loss: 1.000050]\n",
      "epoch:3 step:14365[D loss: 0.999971] [G loss: 1.000068]\n",
      "epoch:3 step:14370[D loss: 0.999977] [G loss: 1.000058]\n",
      "epoch:3 step:14375[D loss: 0.999975] [G loss: 1.000068]\n",
      "epoch:3 step:14380[D loss: 0.999973] [G loss: 1.000063]\n",
      "epoch:3 step:14385[D loss: 0.999969] [G loss: 1.000071]\n",
      "epoch:3 step:14390[D loss: 0.999985] [G loss: 1.000043]\n",
      "epoch:3 step:14395[D loss: 0.999963] [G loss: 1.000079]\n",
      "epoch:3 step:14400[D loss: 0.999973] [G loss: 1.000062]\n",
      "##############\n",
      "[0.86447823 0.85496632 0.82314994 0.82675223 0.82025711 0.84768837\n",
      " 0.88624556 0.83272634 0.81846501 0.84376863]\n",
      "##########\n",
      "epoch:3 step:14405[D loss: 0.999971] [G loss: 1.000043]\n",
      "epoch:3 step:14410[D loss: 0.999979] [G loss: 1.000043]\n",
      "epoch:3 step:14415[D loss: 0.999986] [G loss: 1.000054]\n",
      "epoch:3 step:14420[D loss: 0.999960] [G loss: 1.000081]\n",
      "epoch:3 step:14425[D loss: 0.999969] [G loss: 1.000075]\n",
      "epoch:3 step:14430[D loss: 0.999990] [G loss: 1.000044]\n",
      "epoch:3 step:14435[D loss: 0.999991] [G loss: 1.000008]\n",
      "epoch:3 step:14440[D loss: 0.999969] [G loss: 1.000065]\n",
      "epoch:3 step:14445[D loss: 0.999972] [G loss: 1.000068]\n",
      "epoch:3 step:14450[D loss: 0.999972] [G loss: 1.000064]\n",
      "epoch:3 step:14455[D loss: 0.999980] [G loss: 1.000052]\n",
      "epoch:3 step:14460[D loss: 0.999975] [G loss: 1.000050]\n",
      "epoch:3 step:14465[D loss: 0.999997] [G loss: 0.999982]\n",
      "epoch:3 step:14470[D loss: 0.999974] [G loss: 1.000044]\n",
      "epoch:3 step:14475[D loss: 0.999968] [G loss: 1.000063]\n",
      "epoch:3 step:14480[D loss: 0.999977] [G loss: 1.000046]\n",
      "epoch:3 step:14485[D loss: 0.999979] [G loss: 1.000048]\n",
      "epoch:3 step:14490[D loss: 0.999970] [G loss: 1.000055]\n",
      "epoch:3 step:14495[D loss: 0.999972] [G loss: 1.000050]\n",
      "epoch:3 step:14500[D loss: 0.999977] [G loss: 1.000052]\n",
      "epoch:3 step:14505[D loss: 0.999990] [G loss: 1.000028]\n",
      "epoch:3 step:14510[D loss: 0.999971] [G loss: 1.000053]\n",
      "epoch:3 step:14515[D loss: 0.999969] [G loss: 1.000055]\n",
      "epoch:3 step:14520[D loss: 0.999980] [G loss: 1.000046]\n",
      "epoch:3 step:14525[D loss: 0.999973] [G loss: 1.000048]\n",
      "epoch:3 step:14530[D loss: 0.999978] [G loss: 1.000051]\n",
      "epoch:3 step:14535[D loss: 0.999969] [G loss: 1.000054]\n",
      "epoch:3 step:14540[D loss: 0.999981] [G loss: 1.000032]\n",
      "epoch:3 step:14545[D loss: 0.999979] [G loss: 1.000048]\n",
      "epoch:3 step:14550[D loss: 0.999968] [G loss: 1.000033]\n",
      "epoch:3 step:14555[D loss: 0.999968] [G loss: 1.000049]\n",
      "epoch:3 step:14560[D loss: 0.999972] [G loss: 1.000066]\n",
      "epoch:3 step:14565[D loss: 0.999981] [G loss: 1.000058]\n",
      "epoch:3 step:14570[D loss: 0.999961] [G loss: 1.000061]\n",
      "epoch:3 step:14575[D loss: 0.999976] [G loss: 1.000049]\n",
      "epoch:3 step:14580[D loss: 0.999973] [G loss: 1.000061]\n",
      "epoch:3 step:14585[D loss: 0.999964] [G loss: 1.000059]\n",
      "epoch:3 step:14590[D loss: 0.999977] [G loss: 1.000058]\n",
      "epoch:3 step:14595[D loss: 0.999979] [G loss: 1.000035]\n",
      "epoch:3 step:14600[D loss: 0.999970] [G loss: 1.000050]\n",
      "##############\n",
      "[0.88473349 0.8563196  0.82252844 0.83113787 0.80579106 0.81784033\n",
      " 0.8674854  0.83537167 0.82105901 0.84702366]\n",
      "##########\n",
      "epoch:3 step:14605[D loss: 0.999972] [G loss: 1.000040]\n",
      "epoch:3 step:14610[D loss: 0.999974] [G loss: 1.000051]\n",
      "epoch:3 step:14615[D loss: 0.999979] [G loss: 1.000051]\n",
      "epoch:3 step:14620[D loss: 0.999975] [G loss: 1.000054]\n",
      "epoch:3 step:14625[D loss: 0.999994] [G loss: 1.000017]\n",
      "epoch:3 step:14630[D loss: 0.999958] [G loss: 1.000068]\n",
      "epoch:3 step:14635[D loss: 0.999969] [G loss: 1.000059]\n",
      "epoch:3 step:14640[D loss: 0.999982] [G loss: 1.000030]\n",
      "epoch:3 step:14645[D loss: 0.999970] [G loss: 1.000054]\n",
      "epoch:3 step:14650[D loss: 0.999981] [G loss: 1.000045]\n",
      "epoch:3 step:14655[D loss: 0.999974] [G loss: 1.000064]\n",
      "epoch:3 step:14660[D loss: 0.999976] [G loss: 1.000056]\n",
      "epoch:3 step:14665[D loss: 0.999972] [G loss: 1.000057]\n",
      "epoch:3 step:14670[D loss: 0.999970] [G loss: 1.000055]\n",
      "epoch:3 step:14675[D loss: 0.999971] [G loss: 1.000064]\n",
      "epoch:3 step:14680[D loss: 0.999973] [G loss: 1.000058]\n",
      "epoch:3 step:14685[D loss: 0.999974] [G loss: 1.000056]\n",
      "epoch:3 step:14690[D loss: 0.999978] [G loss: 1.000060]\n",
      "epoch:3 step:14695[D loss: 0.999987] [G loss: 1.000016]\n",
      "epoch:3 step:14700[D loss: 0.999973] [G loss: 1.000055]\n",
      "epoch:3 step:14705[D loss: 0.999976] [G loss: 1.000052]\n",
      "epoch:3 step:14710[D loss: 0.999975] [G loss: 1.000054]\n",
      "epoch:3 step:14715[D loss: 0.999965] [G loss: 1.000055]\n",
      "epoch:3 step:14720[D loss: 0.999972] [G loss: 1.000055]\n",
      "epoch:3 step:14725[D loss: 0.999973] [G loss: 1.000061]\n",
      "epoch:3 step:14730[D loss: 0.999970] [G loss: 1.000064]\n",
      "epoch:3 step:14735[D loss: 0.999975] [G loss: 1.000047]\n",
      "epoch:3 step:14740[D loss: 0.999966] [G loss: 1.000064]\n",
      "epoch:3 step:14745[D loss: 0.999987] [G loss: 1.000039]\n",
      "epoch:3 step:14750[D loss: 0.999969] [G loss: 1.000063]\n",
      "epoch:3 step:14755[D loss: 0.999969] [G loss: 1.000062]\n",
      "epoch:3 step:14760[D loss: 0.999981] [G loss: 1.000050]\n",
      "epoch:3 step:14765[D loss: 0.999979] [G loss: 1.000060]\n",
      "epoch:3 step:14770[D loss: 0.999970] [G loss: 1.000062]\n",
      "epoch:3 step:14775[D loss: 0.999976] [G loss: 1.000045]\n",
      "epoch:3 step:14780[D loss: 0.999972] [G loss: 1.000057]\n",
      "epoch:3 step:14785[D loss: 0.999991] [G loss: 1.000051]\n",
      "epoch:3 step:14790[D loss: 0.999971] [G loss: 1.000059]\n",
      "epoch:3 step:14795[D loss: 0.999976] [G loss: 1.000053]\n",
      "epoch:3 step:14800[D loss: 0.999972] [G loss: 1.000054]\n",
      "##############\n",
      "[0.84772888 0.87245979 0.80014492 0.8221651  0.79836848 0.83536033\n",
      " 0.85878547 0.825501   0.78562248 0.84605979]\n",
      "##########\n",
      "epoch:3 step:14805[D loss: 0.999970] [G loss: 1.000047]\n",
      "epoch:3 step:14810[D loss: 0.999978] [G loss: 1.000050]\n",
      "epoch:3 step:14815[D loss: 0.999978] [G loss: 1.000052]\n",
      "epoch:3 step:14820[D loss: 0.999977] [G loss: 1.000056]\n",
      "epoch:3 step:14825[D loss: 0.999976] [G loss: 1.000052]\n",
      "epoch:3 step:14830[D loss: 0.999989] [G loss: 1.000046]\n",
      "epoch:3 step:14835[D loss: 0.999980] [G loss: 1.000031]\n",
      "epoch:3 step:14840[D loss: 0.999970] [G loss: 1.000049]\n",
      "epoch:3 step:14845[D loss: 0.999977] [G loss: 1.000048]\n",
      "epoch:3 step:14850[D loss: 0.999967] [G loss: 1.000074]\n",
      "epoch:3 step:14855[D loss: 0.999973] [G loss: 1.000053]\n",
      "epoch:3 step:14860[D loss: 0.999976] [G loss: 1.000052]\n",
      "epoch:3 step:14865[D loss: 0.999970] [G loss: 1.000062]\n",
      "epoch:3 step:14870[D loss: 0.999972] [G loss: 1.000055]\n",
      "epoch:3 step:14875[D loss: 0.999973] [G loss: 1.000055]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:3 step:14880[D loss: 0.999973] [G loss: 1.000069]\n",
      "epoch:3 step:14885[D loss: 0.999979] [G loss: 1.000056]\n",
      "epoch:3 step:14890[D loss: 0.999983] [G loss: 1.000030]\n",
      "epoch:3 step:14895[D loss: 0.999976] [G loss: 1.000053]\n",
      "epoch:3 step:14900[D loss: 0.999990] [G loss: 1.000048]\n",
      "epoch:3 step:14905[D loss: 0.999966] [G loss: 1.000064]\n",
      "epoch:3 step:14910[D loss: 0.999975] [G loss: 1.000057]\n",
      "epoch:3 step:14915[D loss: 0.999964] [G loss: 1.000050]\n",
      "epoch:3 step:14920[D loss: 0.999969] [G loss: 1.000050]\n",
      "epoch:3 step:14925[D loss: 0.999969] [G loss: 1.000065]\n",
      "epoch:3 step:14930[D loss: 0.999968] [G loss: 1.000070]\n",
      "epoch:3 step:14935[D loss: 0.999980] [G loss: 1.000039]\n",
      "epoch:3 step:14940[D loss: 0.999975] [G loss: 1.000057]\n",
      "epoch:3 step:14945[D loss: 0.999967] [G loss: 1.000054]\n",
      "epoch:3 step:14950[D loss: 0.999964] [G loss: 1.000072]\n",
      "epoch:3 step:14955[D loss: 0.999975] [G loss: 1.000062]\n",
      "epoch:3 step:14960[D loss: 0.999970] [G loss: 1.000056]\n",
      "epoch:3 step:14965[D loss: 0.999974] [G loss: 1.000057]\n",
      "epoch:3 step:14970[D loss: 0.999977] [G loss: 1.000036]\n",
      "epoch:3 step:14975[D loss: 0.999969] [G loss: 1.000049]\n",
      "epoch:3 step:14980[D loss: 0.999968] [G loss: 1.000061]\n",
      "epoch:3 step:14985[D loss: 0.999970] [G loss: 1.000069]\n",
      "epoch:3 step:14990[D loss: 0.999991] [G loss: 1.000022]\n",
      "epoch:3 step:14995[D loss: 0.999969] [G loss: 1.000071]\n",
      "epoch:3 step:15000[D loss: 0.999970] [G loss: 1.000066]\n",
      "##############\n",
      "[0.86426353 0.86383765 0.82411669 0.84711511 0.83353613 0.84427724\n",
      " 0.85529392 0.83892928 0.80502071 0.81549075]\n",
      "##########\n",
      "epoch:3 step:15005[D loss: 0.999973] [G loss: 1.000056]\n",
      "epoch:3 step:15010[D loss: 0.999965] [G loss: 1.000055]\n",
      "epoch:3 step:15015[D loss: 0.999972] [G loss: 1.000068]\n",
      "epoch:3 step:15020[D loss: 0.999977] [G loss: 1.000055]\n",
      "epoch:3 step:15025[D loss: 0.999970] [G loss: 1.000055]\n",
      "epoch:3 step:15030[D loss: 0.999967] [G loss: 1.000058]\n",
      "epoch:3 step:15035[D loss: 0.999977] [G loss: 1.000060]\n",
      "epoch:3 step:15040[D loss: 0.999967] [G loss: 1.000055]\n",
      "epoch:3 step:15045[D loss: 0.999974] [G loss: 1.000048]\n",
      "epoch:3 step:15050[D loss: 0.999976] [G loss: 1.000053]\n",
      "epoch:3 step:15055[D loss: 0.999977] [G loss: 1.000055]\n",
      "epoch:3 step:15060[D loss: 0.999973] [G loss: 1.000042]\n",
      "epoch:3 step:15065[D loss: 0.999968] [G loss: 1.000064]\n",
      "epoch:3 step:15070[D loss: 0.999972] [G loss: 1.000056]\n",
      "epoch:3 step:15075[D loss: 0.999979] [G loss: 1.000047]\n",
      "epoch:3 step:15080[D loss: 0.999965] [G loss: 1.000057]\n",
      "epoch:3 step:15085[D loss: 0.999966] [G loss: 1.000060]\n",
      "epoch:3 step:15090[D loss: 0.999971] [G loss: 1.000058]\n",
      "epoch:3 step:15095[D loss: 0.999972] [G loss: 1.000061]\n",
      "epoch:3 step:15100[D loss: 0.999977] [G loss: 1.000054]\n",
      "epoch:3 step:15105[D loss: 0.999969] [G loss: 1.000064]\n",
      "epoch:3 step:15110[D loss: 0.999971] [G loss: 1.000058]\n",
      "epoch:3 step:15115[D loss: 0.999976] [G loss: 1.000058]\n",
      "epoch:3 step:15120[D loss: 0.999973] [G loss: 1.000055]\n",
      "epoch:3 step:15125[D loss: 0.999971] [G loss: 1.000057]\n",
      "epoch:3 step:15130[D loss: 0.999978] [G loss: 1.000047]\n",
      "epoch:3 step:15135[D loss: 0.999970] [G loss: 1.000057]\n",
      "epoch:3 step:15140[D loss: 0.999983] [G loss: 1.000057]\n",
      "epoch:3 step:15145[D loss: 0.999972] [G loss: 1.000052]\n",
      "epoch:3 step:15150[D loss: 0.999974] [G loss: 1.000067]\n",
      "epoch:3 step:15155[D loss: 0.999972] [G loss: 1.000054]\n",
      "epoch:3 step:15160[D loss: 0.999980] [G loss: 1.000041]\n",
      "epoch:3 step:15165[D loss: 0.999974] [G loss: 1.000053]\n",
      "epoch:3 step:15170[D loss: 0.999983] [G loss: 1.000035]\n",
      "epoch:3 step:15175[D loss: 0.999970] [G loss: 1.000058]\n",
      "epoch:3 step:15180[D loss: 0.999971] [G loss: 1.000062]\n",
      "epoch:3 step:15185[D loss: 0.999970] [G loss: 1.000056]\n",
      "epoch:3 step:15190[D loss: 0.999977] [G loss: 1.000068]\n",
      "epoch:3 step:15195[D loss: 0.999968] [G loss: 1.000064]\n",
      "epoch:3 step:15200[D loss: 0.999980] [G loss: 1.000058]\n",
      "##############\n",
      "[0.8665432  0.86970507 0.82298816 0.8368501  0.79598831 0.82528813\n",
      " 0.86260798 0.84806667 0.81656653 0.82651486]\n",
      "##########\n",
      "epoch:3 step:15205[D loss: 0.999974] [G loss: 1.000064]\n",
      "epoch:3 step:15210[D loss: 0.999994] [G loss: 1.000030]\n",
      "epoch:3 step:15215[D loss: 0.999981] [G loss: 1.000056]\n",
      "epoch:3 step:15220[D loss: 0.999981] [G loss: 1.000058]\n",
      "epoch:3 step:15225[D loss: 0.999974] [G loss: 1.000056]\n",
      "epoch:3 step:15230[D loss: 0.999980] [G loss: 1.000045]\n",
      "epoch:3 step:15235[D loss: 0.999981] [G loss: 1.000046]\n",
      "epoch:3 step:15240[D loss: 0.999979] [G loss: 1.000047]\n",
      "epoch:3 step:15245[D loss: 0.999963] [G loss: 1.000071]\n",
      "epoch:3 step:15250[D loss: 0.999962] [G loss: 1.000071]\n",
      "epoch:3 step:15255[D loss: 0.999968] [G loss: 1.000057]\n",
      "epoch:3 step:15260[D loss: 0.999970] [G loss: 1.000057]\n",
      "epoch:3 step:15265[D loss: 0.999966] [G loss: 1.000059]\n",
      "epoch:3 step:15270[D loss: 0.999973] [G loss: 1.000058]\n",
      "epoch:3 step:15275[D loss: 0.999976] [G loss: 1.000055]\n",
      "epoch:3 step:15280[D loss: 0.999970] [G loss: 1.000056]\n",
      "epoch:3 step:15285[D loss: 0.999975] [G loss: 1.000050]\n",
      "epoch:3 step:15290[D loss: 0.999972] [G loss: 1.000056]\n",
      "epoch:3 step:15295[D loss: 0.999970] [G loss: 1.000056]\n",
      "epoch:3 step:15300[D loss: 0.999973] [G loss: 1.000060]\n",
      "epoch:3 step:15305[D loss: 0.999988] [G loss: 1.000028]\n",
      "epoch:3 step:15310[D loss: 0.999961] [G loss: 1.000058]\n",
      "epoch:3 step:15315[D loss: 0.999966] [G loss: 1.000103]\n",
      "epoch:3 step:15320[D loss: 0.999966] [G loss: 1.000074]\n",
      "epoch:3 step:15325[D loss: 0.999975] [G loss: 1.000064]\n",
      "epoch:3 step:15330[D loss: 0.999976] [G loss: 1.000047]\n",
      "epoch:3 step:15335[D loss: 0.999975] [G loss: 1.000038]\n",
      "epoch:3 step:15340[D loss: 0.999990] [G loss: 1.000044]\n",
      "epoch:3 step:15345[D loss: 0.999963] [G loss: 1.000075]\n",
      "epoch:3 step:15350[D loss: 0.999966] [G loss: 1.000066]\n",
      "epoch:3 step:15355[D loss: 0.999983] [G loss: 1.000035]\n",
      "epoch:3 step:15360[D loss: 0.999976] [G loss: 1.000038]\n",
      "epoch:3 step:15365[D loss: 0.999973] [G loss: 1.000056]\n",
      "epoch:3 step:15370[D loss: 0.999974] [G loss: 1.000063]\n",
      "epoch:3 step:15375[D loss: 0.999981] [G loss: 1.000048]\n",
      "epoch:3 step:15380[D loss: 0.999979] [G loss: 1.000046]\n",
      "epoch:3 step:15385[D loss: 0.999977] [G loss: 1.000055]\n",
      "epoch:3 step:15390[D loss: 0.999984] [G loss: 1.000011]\n",
      "epoch:3 step:15395[D loss: 0.999962] [G loss: 1.000076]\n",
      "epoch:3 step:15400[D loss: 0.999969] [G loss: 1.000059]\n",
      "##############\n",
      "[0.86849083 0.86531071 0.82585941 0.81897428 0.79747254 0.83921945\n",
      " 0.86252162 0.85207212 0.81016722 0.83216872]\n",
      "##########\n",
      "epoch:3 step:15405[D loss: 0.999971] [G loss: 1.000066]\n",
      "epoch:3 step:15410[D loss: 0.999978] [G loss: 1.000056]\n",
      "epoch:3 step:15415[D loss: 0.999976] [G loss: 1.000056]\n",
      "epoch:3 step:15420[D loss: 0.999974] [G loss: 1.000054]\n",
      "epoch:3 step:15425[D loss: 0.999973] [G loss: 1.000066]\n",
      "epoch:3 step:15430[D loss: 0.999975] [G loss: 1.000063]\n",
      "epoch:3 step:15435[D loss: 0.999966] [G loss: 1.000071]\n",
      "epoch:3 step:15440[D loss: 0.999983] [G loss: 1.000043]\n",
      "epoch:3 step:15445[D loss: 0.999961] [G loss: 1.000078]\n",
      "epoch:3 step:15450[D loss: 0.999973] [G loss: 1.000060]\n",
      "epoch:3 step:15455[D loss: 0.999971] [G loss: 1.000059]\n",
      "epoch:3 step:15460[D loss: 0.999968] [G loss: 1.000054]\n",
      "epoch:3 step:15465[D loss: 0.999974] [G loss: 1.000062]\n",
      "epoch:3 step:15470[D loss: 0.999974] [G loss: 1.000061]\n",
      "epoch:3 step:15475[D loss: 0.999973] [G loss: 1.000060]\n",
      "epoch:3 step:15480[D loss: 0.999970] [G loss: 1.000061]\n",
      "epoch:3 step:15485[D loss: 0.999975] [G loss: 1.000055]\n",
      "epoch:3 step:15490[D loss: 0.999968] [G loss: 1.000055]\n",
      "epoch:3 step:15495[D loss: 0.999975] [G loss: 1.000054]\n",
      "epoch:3 step:15500[D loss: 0.999970] [G loss: 1.000062]\n",
      "epoch:3 step:15505[D loss: 0.999969] [G loss: 1.000058]\n",
      "epoch:3 step:15510[D loss: 0.999983] [G loss: 1.000044]\n",
      "epoch:3 step:15515[D loss: 0.999979] [G loss: 1.000051]\n",
      "epoch:3 step:15520[D loss: 0.999969] [G loss: 1.000065]\n",
      "epoch:3 step:15525[D loss: 0.999973] [G loss: 1.000059]\n",
      "epoch:3 step:15530[D loss: 0.999979] [G loss: 1.000061]\n",
      "epoch:3 step:15535[D loss: 0.999972] [G loss: 1.000058]\n",
      "epoch:3 step:15540[D loss: 0.999972] [G loss: 1.000044]\n",
      "epoch:3 step:15545[D loss: 0.999967] [G loss: 1.000060]\n",
      "epoch:3 step:15550[D loss: 0.999971] [G loss: 1.000055]\n",
      "epoch:3 step:15555[D loss: 0.999972] [G loss: 1.000057]\n",
      "epoch:3 step:15560[D loss: 0.999980] [G loss: 1.000043]\n",
      "epoch:3 step:15565[D loss: 0.999981] [G loss: 1.000050]\n",
      "epoch:3 step:15570[D loss: 0.999977] [G loss: 1.000050]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:3 step:15575[D loss: 0.999971] [G loss: 1.000049]\n",
      "epoch:3 step:15580[D loss: 0.999973] [G loss: 1.000061]\n",
      "epoch:3 step:15585[D loss: 0.999970] [G loss: 1.000065]\n",
      "epoch:3 step:15590[D loss: 0.999969] [G loss: 1.000055]\n",
      "epoch:3 step:15595[D loss: 0.999977] [G loss: 1.000056]\n",
      "epoch:3 step:15600[D loss: 0.999971] [G loss: 1.000066]\n",
      "##############\n",
      "[0.86051236 0.87342765 0.84283149 0.82480963 0.79458671 0.82659012\n",
      " 0.88383838 0.81886401 0.81164511 0.84341812]\n",
      "##########\n",
      "epoch:3 step:15605[D loss: 0.999976] [G loss: 1.000059]\n",
      "epoch:3 step:15610[D loss: 0.999990] [G loss: 1.000039]\n",
      "epoch:3 step:15615[D loss: 0.999980] [G loss: 1.000066]\n",
      "epoch:3 step:15620[D loss: 0.999970] [G loss: 1.000069]\n",
      "epoch:4 step:15625[D loss: 0.999974] [G loss: 1.000063]\n",
      "epoch:4 step:15630[D loss: 0.999987] [G loss: 1.000025]\n",
      "epoch:4 step:15635[D loss: 0.999979] [G loss: 1.000051]\n",
      "epoch:4 step:15640[D loss: 0.999969] [G loss: 1.000075]\n",
      "epoch:4 step:15645[D loss: 0.999974] [G loss: 1.000061]\n",
      "epoch:4 step:15650[D loss: 0.999963] [G loss: 1.000066]\n",
      "epoch:4 step:15655[D loss: 0.999972] [G loss: 1.000064]\n",
      "epoch:4 step:15660[D loss: 0.999969] [G loss: 1.000054]\n",
      "epoch:4 step:15665[D loss: 0.999973] [G loss: 1.000052]\n",
      "epoch:4 step:15670[D loss: 0.999978] [G loss: 1.000053]\n",
      "epoch:4 step:15675[D loss: 0.999974] [G loss: 1.000056]\n",
      "epoch:4 step:15680[D loss: 0.999976] [G loss: 1.000054]\n",
      "epoch:4 step:15685[D loss: 0.999972] [G loss: 1.000051]\n",
      "epoch:4 step:15690[D loss: 0.999973] [G loss: 1.000058]\n",
      "epoch:4 step:15695[D loss: 0.999981] [G loss: 1.000051]\n",
      "epoch:4 step:15700[D loss: 0.999978] [G loss: 1.000053]\n",
      "epoch:4 step:15705[D loss: 0.999962] [G loss: 1.000066]\n",
      "epoch:4 step:15710[D loss: 0.999966] [G loss: 1.000056]\n",
      "epoch:4 step:15715[D loss: 0.999970] [G loss: 1.000051]\n",
      "epoch:4 step:15720[D loss: 0.999973] [G loss: 1.000060]\n",
      "epoch:4 step:15725[D loss: 0.999974] [G loss: 1.000059]\n",
      "epoch:4 step:15730[D loss: 0.999968] [G loss: 1.000063]\n",
      "epoch:4 step:15735[D loss: 0.999976] [G loss: 1.000059]\n",
      "epoch:4 step:15740[D loss: 0.999974] [G loss: 1.000067]\n",
      "epoch:4 step:15745[D loss: 0.999972] [G loss: 1.000058]\n",
      "epoch:4 step:15750[D loss: 0.999975] [G loss: 1.000058]\n",
      "epoch:4 step:15755[D loss: 0.999965] [G loss: 1.000065]\n",
      "epoch:4 step:15760[D loss: 0.999970] [G loss: 1.000066]\n",
      "epoch:4 step:15765[D loss: 0.999968] [G loss: 1.000066]\n",
      "epoch:4 step:15770[D loss: 0.999971] [G loss: 1.000053]\n",
      "epoch:4 step:15775[D loss: 0.999976] [G loss: 1.000054]\n",
      "epoch:4 step:15780[D loss: 0.999966] [G loss: 1.000069]\n",
      "epoch:4 step:15785[D loss: 0.999975] [G loss: 1.000063]\n",
      "epoch:4 step:15790[D loss: 0.999970] [G loss: 1.000063]\n",
      "epoch:4 step:15795[D loss: 0.999983] [G loss: 1.000057]\n",
      "epoch:4 step:15800[D loss: 0.999968] [G loss: 1.000038]\n",
      "##############\n",
      "[0.87136747 0.88435892 0.83067848 0.82444287 0.80870091 0.82733354\n",
      " 0.87821342 0.8343269  0.81177658 0.82699447]\n",
      "##########\n",
      "epoch:4 step:15805[D loss: 0.999968] [G loss: 1.000053]\n",
      "epoch:4 step:15810[D loss: 0.999977] [G loss: 1.000045]\n",
      "epoch:4 step:15815[D loss: 0.999977] [G loss: 1.000031]\n",
      "epoch:4 step:15820[D loss: 0.999975] [G loss: 1.000067]\n",
      "epoch:4 step:15825[D loss: 0.999973] [G loss: 1.000078]\n",
      "epoch:4 step:15830[D loss: 0.999970] [G loss: 1.000065]\n",
      "epoch:4 step:15835[D loss: 0.999978] [G loss: 1.000047]\n",
      "epoch:4 step:15840[D loss: 0.999994] [G loss: 1.000058]\n",
      "epoch:4 step:15845[D loss: 0.999967] [G loss: 1.000077]\n",
      "epoch:4 step:15850[D loss: 0.999976] [G loss: 1.000057]\n",
      "epoch:4 step:15855[D loss: 0.999974] [G loss: 1.000056]\n",
      "epoch:4 step:15860[D loss: 0.999979] [G loss: 1.000048]\n",
      "epoch:4 step:15865[D loss: 1.000030] [G loss: 0.999969]\n",
      "epoch:4 step:15870[D loss: 0.999965] [G loss: 1.000061]\n",
      "epoch:4 step:15875[D loss: 0.999964] [G loss: 1.000079]\n",
      "epoch:4 step:15880[D loss: 0.999970] [G loss: 1.000064]\n",
      "epoch:4 step:15885[D loss: 0.999977] [G loss: 1.000060]\n",
      "epoch:4 step:15890[D loss: 1.000002] [G loss: 0.999998]\n",
      "epoch:4 step:15895[D loss: 0.999980] [G loss: 1.000060]\n",
      "epoch:4 step:15900[D loss: 0.999966] [G loss: 1.000074]\n",
      "epoch:4 step:15905[D loss: 0.999971] [G loss: 1.000070]\n",
      "epoch:4 step:15910[D loss: 0.999973] [G loss: 1.000066]\n",
      "epoch:4 step:15915[D loss: 0.999973] [G loss: 1.000044]\n",
      "epoch:4 step:15920[D loss: 0.999982] [G loss: 1.000049]\n",
      "epoch:4 step:15925[D loss: 0.999984] [G loss: 1.000045]\n",
      "epoch:4 step:15930[D loss: 0.999973] [G loss: 1.000073]\n",
      "epoch:4 step:15935[D loss: 0.999970] [G loss: 1.000064]\n",
      "epoch:4 step:15940[D loss: 0.999977] [G loss: 1.000058]\n",
      "epoch:4 step:15945[D loss: 0.999978] [G loss: 1.000036]\n",
      "epoch:4 step:15950[D loss: 0.999989] [G loss: 1.000017]\n",
      "epoch:4 step:15955[D loss: 0.999973] [G loss: 1.000052]\n",
      "epoch:4 step:15960[D loss: 0.999970] [G loss: 1.000072]\n",
      "epoch:4 step:15965[D loss: 0.999976] [G loss: 1.000058]\n",
      "epoch:4 step:15970[D loss: 0.999968] [G loss: 1.000069]\n",
      "epoch:4 step:15975[D loss: 0.999963] [G loss: 1.000081]\n",
      "epoch:4 step:15980[D loss: 0.999963] [G loss: 1.000087]\n",
      "epoch:4 step:15985[D loss: 0.999974] [G loss: 1.000063]\n",
      "epoch:4 step:15990[D loss: 0.999966] [G loss: 1.000065]\n",
      "epoch:4 step:15995[D loss: 0.999971] [G loss: 1.000049]\n",
      "epoch:4 step:16000[D loss: 0.999979] [G loss: 1.000052]\n",
      "##############\n",
      "[0.85433432 0.85491993 0.81607447 0.83856486 0.79769769 0.83546262\n",
      " 0.88899546 0.86230744 0.79549637 0.84704246]\n",
      "##########\n",
      "epoch:4 step:16005[D loss: 0.999976] [G loss: 1.000041]\n",
      "epoch:4 step:16010[D loss: 0.999992] [G loss: 1.000009]\n",
      "epoch:4 step:16015[D loss: 0.999959] [G loss: 1.000079]\n",
      "epoch:4 step:16020[D loss: 0.999972] [G loss: 1.000063]\n",
      "epoch:4 step:16025[D loss: 0.999967] [G loss: 1.000063]\n",
      "epoch:4 step:16030[D loss: 0.999980] [G loss: 1.000040]\n",
      "epoch:4 step:16035[D loss: 0.999977] [G loss: 1.000046]\n",
      "epoch:4 step:16040[D loss: 0.999964] [G loss: 1.000048]\n",
      "epoch:4 step:16045[D loss: 0.999973] [G loss: 1.000063]\n",
      "epoch:4 step:16050[D loss: 0.999975] [G loss: 1.000061]\n",
      "epoch:4 step:16055[D loss: 0.999980] [G loss: 1.000042]\n",
      "epoch:4 step:16060[D loss: 0.999982] [G loss: 1.000060]\n",
      "epoch:4 step:16065[D loss: 0.999964] [G loss: 1.000085]\n",
      "epoch:4 step:16070[D loss: 0.999975] [G loss: 1.000065]\n",
      "epoch:4 step:16075[D loss: 0.999987] [G loss: 1.000039]\n",
      "epoch:4 step:16080[D loss: 0.999995] [G loss: 1.000006]\n",
      "epoch:4 step:16085[D loss: 1.000001] [G loss: 1.000019]\n",
      "epoch:4 step:16090[D loss: 0.999960] [G loss: 1.000088]\n",
      "epoch:4 step:16095[D loss: 0.999954] [G loss: 1.000078]\n",
      "epoch:4 step:16100[D loss: 0.999971] [G loss: 1.000051]\n",
      "epoch:4 step:16105[D loss: 0.999987] [G loss: 1.000034]\n",
      "epoch:4 step:16110[D loss: 0.999971] [G loss: 1.000061]\n",
      "epoch:4 step:16115[D loss: 0.999965] [G loss: 1.000061]\n",
      "epoch:4 step:16120[D loss: 0.999965] [G loss: 1.000074]\n",
      "epoch:4 step:16125[D loss: 0.999957] [G loss: 1.000081]\n",
      "epoch:4 step:16130[D loss: 0.999976] [G loss: 1.000060]\n",
      "epoch:4 step:16135[D loss: 0.999997] [G loss: 1.000020]\n",
      "epoch:4 step:16140[D loss: 0.999980] [G loss: 1.000039]\n",
      "epoch:4 step:16145[D loss: 0.999971] [G loss: 1.000062]\n",
      "epoch:4 step:16150[D loss: 0.999972] [G loss: 1.000056]\n",
      "epoch:4 step:16155[D loss: 0.999969] [G loss: 1.000047]\n",
      "epoch:4 step:16160[D loss: 0.999983] [G loss: 1.000035]\n",
      "epoch:4 step:16165[D loss: 0.999968] [G loss: 1.000063]\n",
      "epoch:4 step:16170[D loss: 0.999970] [G loss: 1.000059]\n",
      "epoch:4 step:16175[D loss: 0.999970] [G loss: 1.000047]\n",
      "epoch:4 step:16180[D loss: 0.999983] [G loss: 1.000042]\n",
      "epoch:4 step:16185[D loss: 0.999978] [G loss: 1.000044]\n",
      "epoch:4 step:16190[D loss: 0.999964] [G loss: 1.000066]\n",
      "epoch:4 step:16195[D loss: 0.999972] [G loss: 1.000061]\n",
      "epoch:4 step:16200[D loss: 0.999965] [G loss: 1.000070]\n",
      "##############\n",
      "[0.86294257 0.87381023 0.81775981 0.83713753 0.80288351 0.83092467\n",
      " 0.87118623 0.84751947 0.83024959 0.85180307]\n",
      "##########\n",
      "epoch:4 step:16205[D loss: 0.999976] [G loss: 1.000055]\n",
      "epoch:4 step:16210[D loss: 0.999979] [G loss: 1.000034]\n",
      "epoch:4 step:16215[D loss: 0.999966] [G loss: 1.000063]\n",
      "epoch:4 step:16220[D loss: 0.999984] [G loss: 1.000041]\n",
      "epoch:4 step:16225[D loss: 0.999974] [G loss: 1.000063]\n",
      "epoch:4 step:16230[D loss: 0.999971] [G loss: 1.000072]\n",
      "epoch:4 step:16235[D loss: 0.999973] [G loss: 1.000072]\n",
      "epoch:4 step:16240[D loss: 0.999970] [G loss: 1.000053]\n",
      "epoch:4 step:16245[D loss: 0.999977] [G loss: 1.000040]\n",
      "epoch:4 step:16250[D loss: 0.999980] [G loss: 1.000036]\n",
      "epoch:4 step:16255[D loss: 0.999965] [G loss: 1.000069]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:4 step:16260[D loss: 0.999968] [G loss: 1.000072]\n",
      "epoch:4 step:16265[D loss: 0.999985] [G loss: 1.000049]\n",
      "epoch:4 step:16270[D loss: 0.999996] [G loss: 1.000017]\n",
      "epoch:4 step:16275[D loss: 0.999978] [G loss: 1.000038]\n",
      "epoch:4 step:16280[D loss: 0.999976] [G loss: 1.000056]\n",
      "epoch:4 step:16285[D loss: 0.999972] [G loss: 1.000050]\n",
      "epoch:4 step:16290[D loss: 0.999967] [G loss: 1.000075]\n",
      "epoch:4 step:16295[D loss: 0.999966] [G loss: 1.000065]\n",
      "epoch:4 step:16300[D loss: 0.999979] [G loss: 1.000041]\n",
      "epoch:4 step:16305[D loss: 0.999998] [G loss: 1.000014]\n",
      "epoch:4 step:16310[D loss: 0.999977] [G loss: 1.000051]\n",
      "epoch:4 step:16315[D loss: 0.999980] [G loss: 1.000070]\n",
      "epoch:4 step:16320[D loss: 0.999967] [G loss: 1.000060]\n",
      "epoch:4 step:16325[D loss: 0.999998] [G loss: 1.000012]\n",
      "epoch:4 step:16330[D loss: 0.999979] [G loss: 1.000032]\n",
      "epoch:4 step:16335[D loss: 0.999967] [G loss: 1.000073]\n",
      "epoch:4 step:16340[D loss: 0.999969] [G loss: 1.000060]\n",
      "epoch:4 step:16345[D loss: 0.999972] [G loss: 1.000067]\n",
      "epoch:4 step:16350[D loss: 0.999996] [G loss: 1.000026]\n",
      "epoch:4 step:16355[D loss: 0.999974] [G loss: 1.000066]\n",
      "epoch:4 step:16360[D loss: 0.999974] [G loss: 1.000052]\n",
      "epoch:4 step:16365[D loss: 0.999966] [G loss: 1.000070]\n",
      "epoch:4 step:16370[D loss: 0.999986] [G loss: 1.000037]\n",
      "epoch:4 step:16375[D loss: 0.999995] [G loss: 1.000008]\n",
      "epoch:4 step:16380[D loss: 0.999974] [G loss: 1.000070]\n",
      "epoch:4 step:16385[D loss: 0.999997] [G loss: 1.000045]\n",
      "epoch:4 step:16390[D loss: 0.999973] [G loss: 1.000053]\n",
      "epoch:4 step:16395[D loss: 0.999970] [G loss: 1.000066]\n",
      "epoch:4 step:16400[D loss: 0.999978] [G loss: 1.000029]\n",
      "##############\n",
      "[0.86667251 0.83714206 0.82549952 0.81975721 0.78166511 0.82827269\n",
      " 0.87876013 0.82580089 0.8377305  0.8313287 ]\n",
      "##########\n",
      "epoch:4 step:16405[D loss: 0.999984] [G loss: 1.000026]\n",
      "epoch:4 step:16410[D loss: 0.999966] [G loss: 1.000059]\n",
      "epoch:4 step:16415[D loss: 0.999965] [G loss: 1.000066]\n",
      "epoch:4 step:16420[D loss: 0.999971] [G loss: 1.000051]\n",
      "epoch:4 step:16425[D loss: 0.999970] [G loss: 1.000049]\n",
      "epoch:4 step:16430[D loss: 0.999989] [G loss: 1.000043]\n",
      "epoch:4 step:16435[D loss: 0.999977] [G loss: 1.000059]\n",
      "epoch:4 step:16440[D loss: 0.999965] [G loss: 1.000063]\n",
      "epoch:4 step:16445[D loss: 0.999980] [G loss: 1.000048]\n",
      "epoch:4 step:16450[D loss: 0.999978] [G loss: 1.000055]\n",
      "epoch:4 step:16455[D loss: 0.999964] [G loss: 1.000071]\n",
      "epoch:4 step:16460[D loss: 0.999979] [G loss: 1.000049]\n",
      "epoch:4 step:16465[D loss: 0.999971] [G loss: 1.000056]\n",
      "epoch:4 step:16470[D loss: 0.999987] [G loss: 1.000025]\n",
      "epoch:4 step:16475[D loss: 0.999970] [G loss: 1.000059]\n",
      "epoch:4 step:16480[D loss: 0.999977] [G loss: 1.000038]\n",
      "epoch:4 step:16485[D loss: 0.999965] [G loss: 1.000067]\n",
      "epoch:4 step:16490[D loss: 0.999972] [G loss: 1.000067]\n",
      "epoch:4 step:16495[D loss: 0.999977] [G loss: 1.000036]\n",
      "epoch:4 step:16500[D loss: 0.999962] [G loss: 1.000057]\n",
      "epoch:4 step:16505[D loss: 0.999964] [G loss: 1.000060]\n",
      "epoch:4 step:16510[D loss: 0.999975] [G loss: 1.000054]\n",
      "epoch:4 step:16515[D loss: 0.999981] [G loss: 1.000047]\n",
      "epoch:4 step:16520[D loss: 0.999970] [G loss: 1.000059]\n",
      "epoch:4 step:16525[D loss: 0.999970] [G loss: 1.000056]\n",
      "epoch:4 step:16530[D loss: 0.999960] [G loss: 1.000071]\n",
      "epoch:4 step:16535[D loss: 0.999974] [G loss: 1.000085]\n",
      "epoch:4 step:16540[D loss: 0.999969] [G loss: 1.000069]\n",
      "epoch:4 step:16545[D loss: 0.999970] [G loss: 1.000064]\n",
      "epoch:4 step:16550[D loss: 1.000013] [G loss: 0.999965]\n",
      "epoch:4 step:16555[D loss: 0.999959] [G loss: 1.000064]\n",
      "epoch:4 step:16560[D loss: 0.999985] [G loss: 1.000046]\n",
      "epoch:4 step:16565[D loss: 0.999972] [G loss: 1.000062]\n",
      "epoch:4 step:16570[D loss: 0.999975] [G loss: 1.000071]\n",
      "epoch:4 step:16575[D loss: 1.000006] [G loss: 1.000038]\n",
      "epoch:4 step:16580[D loss: 0.999960] [G loss: 1.000061]\n",
      "epoch:4 step:16585[D loss: 0.999970] [G loss: 1.000066]\n",
      "epoch:4 step:16590[D loss: 0.999977] [G loss: 1.000050]\n",
      "epoch:4 step:16595[D loss: 0.999971] [G loss: 1.000046]\n",
      "epoch:4 step:16600[D loss: 0.999982] [G loss: 1.000062]\n",
      "##############\n",
      "[0.86302869 0.84743695 0.83389648 0.83973716 0.80864627 0.83770437\n",
      " 0.86113932 0.85374601 0.81780819 0.82165682]\n",
      "##########\n",
      "epoch:4 step:16605[D loss: 0.999978] [G loss: 1.000044]\n",
      "epoch:4 step:16610[D loss: 0.999985] [G loss: 1.000085]\n",
      "epoch:4 step:16615[D loss: 0.999963] [G loss: 1.000085]\n",
      "epoch:4 step:16620[D loss: 0.999965] [G loss: 1.000067]\n",
      "epoch:4 step:16625[D loss: 0.999978] [G loss: 1.000064]\n",
      "epoch:4 step:16630[D loss: 0.999971] [G loss: 1.000046]\n",
      "epoch:4 step:16635[D loss: 0.999964] [G loss: 1.000051]\n",
      "epoch:4 step:16640[D loss: 0.999992] [G loss: 1.000036]\n",
      "epoch:4 step:16645[D loss: 1.000013] [G loss: 1.000072]\n",
      "epoch:4 step:16650[D loss: 0.999951] [G loss: 1.000084]\n",
      "epoch:4 step:16655[D loss: 0.999975] [G loss: 1.000069]\n",
      "epoch:4 step:16660[D loss: 0.999977] [G loss: 1.000044]\n",
      "epoch:4 step:16665[D loss: 0.999979] [G loss: 1.000049]\n",
      "epoch:4 step:16670[D loss: 0.999966] [G loss: 1.000054]\n",
      "epoch:4 step:16675[D loss: 0.999980] [G loss: 1.000053]\n",
      "epoch:4 step:16680[D loss: 0.999975] [G loss: 1.000044]\n",
      "epoch:4 step:16685[D loss: 0.999988] [G loss: 1.000058]\n",
      "epoch:4 step:16690[D loss: 0.999972] [G loss: 1.000063]\n",
      "epoch:4 step:16695[D loss: 0.999973] [G loss: 1.000062]\n",
      "epoch:4 step:16700[D loss: 0.999971] [G loss: 1.000068]\n",
      "epoch:4 step:16705[D loss: 0.999970] [G loss: 1.000058]\n",
      "epoch:4 step:16710[D loss: 0.999976] [G loss: 1.000064]\n",
      "epoch:4 step:16715[D loss: 0.999976] [G loss: 1.000061]\n",
      "epoch:4 step:16720[D loss: 0.999980] [G loss: 1.000060]\n",
      "epoch:4 step:16725[D loss: 0.999979] [G loss: 1.000034]\n",
      "epoch:4 step:16730[D loss: 0.999975] [G loss: 1.000044]\n",
      "epoch:4 step:16735[D loss: 0.999971] [G loss: 1.000062]\n",
      "epoch:4 step:16740[D loss: 0.999973] [G loss: 1.000060]\n",
      "epoch:4 step:16745[D loss: 0.999980] [G loss: 1.000057]\n",
      "epoch:4 step:16750[D loss: 0.999991] [G loss: 1.000040]\n",
      "epoch:4 step:16755[D loss: 0.999966] [G loss: 1.000071]\n",
      "epoch:4 step:16760[D loss: 0.999973] [G loss: 1.000061]\n",
      "epoch:4 step:16765[D loss: 0.999976] [G loss: 1.000049]\n",
      "epoch:4 step:16770[D loss: 0.999974] [G loss: 1.000058]\n",
      "epoch:4 step:16775[D loss: 0.999977] [G loss: 1.000045]\n",
      "epoch:4 step:16780[D loss: 0.999981] [G loss: 1.000049]\n",
      "epoch:4 step:16785[D loss: 0.999985] [G loss: 1.000066]\n",
      "epoch:4 step:16790[D loss: 0.999991] [G loss: 1.000041]\n",
      "epoch:4 step:16795[D loss: 0.999974] [G loss: 1.000051]\n",
      "epoch:4 step:16800[D loss: 0.999972] [G loss: 1.000066]\n",
      "##############\n",
      "[0.8593407  0.86815009 0.83747714 0.83140393 0.77441262 0.82702461\n",
      " 0.86887782 0.84004942 0.80156837 0.84796084]\n",
      "##########\n",
      "epoch:4 step:16805[D loss: 0.999980] [G loss: 1.000039]\n",
      "epoch:4 step:16810[D loss: 0.999963] [G loss: 1.000074]\n",
      "epoch:4 step:16815[D loss: 0.999968] [G loss: 1.000063]\n",
      "epoch:4 step:16820[D loss: 0.999973] [G loss: 1.000026]\n",
      "epoch:4 step:16825[D loss: 1.000018] [G loss: 0.999979]\n",
      "epoch:4 step:16830[D loss: 0.999958] [G loss: 1.000062]\n",
      "epoch:4 step:16835[D loss: 0.999965] [G loss: 1.000069]\n",
      "epoch:4 step:16840[D loss: 0.999973] [G loss: 1.000055]\n",
      "epoch:4 step:16845[D loss: 0.999973] [G loss: 1.000058]\n",
      "epoch:4 step:16850[D loss: 0.999979] [G loss: 1.000060]\n",
      "epoch:4 step:16855[D loss: 0.999981] [G loss: 1.000060]\n",
      "epoch:4 step:16860[D loss: 0.999967] [G loss: 1.000070]\n",
      "epoch:4 step:16865[D loss: 0.999975] [G loss: 1.000069]\n",
      "epoch:4 step:16870[D loss: 0.999978] [G loss: 1.000051]\n",
      "epoch:4 step:16875[D loss: 0.999983] [G loss: 1.000037]\n",
      "epoch:4 step:16880[D loss: 0.999986] [G loss: 1.000046]\n",
      "epoch:4 step:16885[D loss: 0.999984] [G loss: 1.000030]\n",
      "epoch:4 step:16890[D loss: 0.999977] [G loss: 1.000062]\n",
      "epoch:4 step:16895[D loss: 0.999973] [G loss: 1.000058]\n",
      "epoch:4 step:16900[D loss: 0.999972] [G loss: 1.000054]\n",
      "epoch:4 step:16905[D loss: 0.999999] [G loss: 0.999994]\n",
      "epoch:4 step:16910[D loss: 0.999966] [G loss: 1.000068]\n",
      "epoch:4 step:16915[D loss: 0.999963] [G loss: 1.000062]\n",
      "epoch:4 step:16920[D loss: 0.999970] [G loss: 1.000060]\n",
      "epoch:4 step:16925[D loss: 0.999978] [G loss: 1.000060]\n",
      "epoch:4 step:16930[D loss: 0.999974] [G loss: 1.000033]\n",
      "epoch:4 step:16935[D loss: 0.999985] [G loss: 1.000036]\n",
      "epoch:4 step:16940[D loss: 0.999965] [G loss: 1.000055]\n",
      "epoch:4 step:16945[D loss: 0.999973] [G loss: 1.000049]\n",
      "epoch:4 step:16950[D loss: 0.999991] [G loss: 1.000040]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:4 step:16955[D loss: 0.999976] [G loss: 1.000062]\n",
      "epoch:4 step:16960[D loss: 0.999976] [G loss: 1.000045]\n",
      "epoch:4 step:16965[D loss: 0.999984] [G loss: 1.000031]\n",
      "epoch:4 step:16970[D loss: 0.999986] [G loss: 1.000035]\n",
      "epoch:4 step:16975[D loss: 0.999980] [G loss: 1.000063]\n",
      "epoch:4 step:16980[D loss: 0.999965] [G loss: 1.000067]\n",
      "epoch:4 step:16985[D loss: 0.999979] [G loss: 1.000057]\n",
      "epoch:4 step:16990[D loss: 0.999981] [G loss: 1.000043]\n",
      "epoch:4 step:16995[D loss: 0.999978] [G loss: 1.000032]\n",
      "epoch:4 step:17000[D loss: 0.999981] [G loss: 0.999998]\n",
      "##############\n",
      "[0.87429809 0.8751146  0.83573821 0.8313386  0.80240235 0.81882995\n",
      " 0.87113051 0.8468514  0.81847301 0.8420588 ]\n",
      "##########\n",
      "epoch:4 step:17005[D loss: 0.999965] [G loss: 1.000079]\n",
      "epoch:4 step:17010[D loss: 0.999970] [G loss: 1.000079]\n",
      "epoch:4 step:17015[D loss: 0.999966] [G loss: 1.000060]\n",
      "epoch:4 step:17020[D loss: 0.999971] [G loss: 1.000057]\n",
      "epoch:4 step:17025[D loss: 0.999977] [G loss: 1.000051]\n",
      "epoch:4 step:17030[D loss: 1.000010] [G loss: 1.000034]\n",
      "epoch:4 step:17035[D loss: 0.999966] [G loss: 1.000068]\n",
      "epoch:4 step:17040[D loss: 0.999976] [G loss: 1.000060]\n",
      "epoch:4 step:17045[D loss: 0.999997] [G loss: 1.000047]\n",
      "epoch:4 step:17050[D loss: 0.999987] [G loss: 1.000028]\n",
      "epoch:4 step:17055[D loss: 0.999985] [G loss: 1.000044]\n",
      "epoch:4 step:17060[D loss: 0.999974] [G loss: 1.000063]\n",
      "epoch:4 step:17065[D loss: 0.999974] [G loss: 1.000058]\n",
      "epoch:4 step:17070[D loss: 0.999977] [G loss: 1.000051]\n",
      "epoch:4 step:17075[D loss: 0.999978] [G loss: 1.000065]\n",
      "epoch:4 step:17080[D loss: 0.999978] [G loss: 1.000050]\n",
      "epoch:4 step:17085[D loss: 0.999974] [G loss: 1.000075]\n",
      "epoch:4 step:17090[D loss: 0.999968] [G loss: 1.000068]\n",
      "epoch:4 step:17095[D loss: 0.999970] [G loss: 1.000061]\n",
      "epoch:4 step:17100[D loss: 0.999982] [G loss: 1.000068]\n",
      "epoch:4 step:17105[D loss: 0.999977] [G loss: 1.000063]\n",
      "epoch:4 step:17110[D loss: 0.999971] [G loss: 1.000057]\n",
      "epoch:4 step:17115[D loss: 0.999970] [G loss: 1.000069]\n",
      "epoch:4 step:17120[D loss: 0.999972] [G loss: 1.000058]\n",
      "epoch:4 step:17125[D loss: 0.999982] [G loss: 1.000052]\n",
      "epoch:4 step:17130[D loss: 0.999992] [G loss: 1.000002]\n",
      "epoch:4 step:17135[D loss: 0.999960] [G loss: 1.000073]\n",
      "epoch:4 step:17140[D loss: 0.999971] [G loss: 1.000054]\n",
      "epoch:4 step:17145[D loss: 0.999981] [G loss: 1.000049]\n",
      "epoch:4 step:17150[D loss: 0.999968] [G loss: 1.000061]\n",
      "epoch:4 step:17155[D loss: 0.999960] [G loss: 1.000076]\n",
      "epoch:4 step:17160[D loss: 0.999974] [G loss: 1.000074]\n",
      "epoch:4 step:17165[D loss: 0.999975] [G loss: 1.000063]\n",
      "epoch:4 step:17170[D loss: 0.999973] [G loss: 1.000057]\n",
      "epoch:4 step:17175[D loss: 0.999971] [G loss: 1.000053]\n",
      "epoch:4 step:17180[D loss: 0.999978] [G loss: 1.000062]\n",
      "epoch:4 step:17185[D loss: 0.999967] [G loss: 1.000063]\n",
      "epoch:4 step:17190[D loss: 0.999967] [G loss: 1.000063]\n",
      "epoch:4 step:17195[D loss: 0.999973] [G loss: 1.000050]\n",
      "epoch:4 step:17200[D loss: 0.999973] [G loss: 1.000048]\n",
      "##############\n",
      "[0.84460524 0.8557822  0.83801481 0.81769955 0.83303328 0.83837124\n",
      " 0.88611414 0.84126737 0.81277535 0.84240518]\n",
      "##########\n",
      "epoch:4 step:17205[D loss: 0.999971] [G loss: 1.000058]\n",
      "epoch:4 step:17210[D loss: 0.999977] [G loss: 1.000047]\n",
      "epoch:4 step:17215[D loss: 0.999970] [G loss: 1.000054]\n",
      "epoch:4 step:17220[D loss: 0.999969] [G loss: 1.000064]\n",
      "epoch:4 step:17225[D loss: 0.999980] [G loss: 1.000050]\n",
      "epoch:4 step:17230[D loss: 1.000040] [G loss: 0.999977]\n",
      "epoch:4 step:17235[D loss: 0.999987] [G loss: 1.000042]\n",
      "epoch:4 step:17240[D loss: 0.999970] [G loss: 1.000054]\n",
      "epoch:4 step:17245[D loss: 0.999973] [G loss: 1.000057]\n",
      "epoch:4 step:17250[D loss: 0.999982] [G loss: 1.000014]\n",
      "epoch:4 step:17255[D loss: 0.999966] [G loss: 1.000046]\n",
      "epoch:4 step:17260[D loss: 0.999975] [G loss: 1.000042]\n",
      "epoch:4 step:17265[D loss: 0.999972] [G loss: 1.000054]\n",
      "epoch:4 step:17270[D loss: 0.999964] [G loss: 1.000052]\n",
      "epoch:4 step:17275[D loss: 0.999977] [G loss: 1.000060]\n",
      "epoch:4 step:17280[D loss: 0.999988] [G loss: 1.000052]\n",
      "epoch:4 step:17285[D loss: 0.999972] [G loss: 1.000067]\n",
      "epoch:4 step:17290[D loss: 0.999974] [G loss: 1.000050]\n",
      "epoch:4 step:17295[D loss: 0.999980] [G loss: 1.000046]\n",
      "epoch:4 step:17300[D loss: 0.999968] [G loss: 1.000058]\n",
      "epoch:4 step:17305[D loss: 0.999976] [G loss: 1.000070]\n",
      "epoch:4 step:17310[D loss: 0.999974] [G loss: 1.000068]\n",
      "epoch:4 step:17315[D loss: 0.999985] [G loss: 1.000044]\n",
      "epoch:4 step:17320[D loss: 0.999976] [G loss: 1.000042]\n",
      "epoch:4 step:17325[D loss: 0.999975] [G loss: 1.000049]\n",
      "epoch:4 step:17330[D loss: 0.999973] [G loss: 1.000058]\n",
      "epoch:4 step:17335[D loss: 0.999985] [G loss: 1.000042]\n",
      "epoch:4 step:17340[D loss: 0.999997] [G loss: 1.000024]\n",
      "epoch:4 step:17345[D loss: 0.999956] [G loss: 1.000073]\n",
      "epoch:4 step:17350[D loss: 0.999958] [G loss: 1.000089]\n",
      "epoch:4 step:17355[D loss: 0.999971] [G loss: 1.000063]\n",
      "epoch:4 step:17360[D loss: 0.999979] [G loss: 1.000050]\n",
      "epoch:4 step:17365[D loss: 0.999993] [G loss: 1.000015]\n",
      "epoch:4 step:17370[D loss: 0.999989] [G loss: 1.000060]\n",
      "epoch:4 step:17375[D loss: 0.999969] [G loss: 1.000060]\n",
      "epoch:4 step:17380[D loss: 0.999970] [G loss: 1.000062]\n",
      "epoch:4 step:17385[D loss: 0.999976] [G loss: 1.000050]\n",
      "epoch:4 step:17390[D loss: 0.999971] [G loss: 1.000048]\n",
      "epoch:4 step:17395[D loss: 0.999984] [G loss: 1.000032]\n",
      "epoch:4 step:17400[D loss: 0.999969] [G loss: 1.000057]\n",
      "##############\n",
      "[0.87445362 0.86827994 0.82125248 0.84548788 0.80391638 0.84021464\n",
      " 0.8606559  0.83260174 0.80731245 0.81495853]\n",
      "##########\n",
      "epoch:4 step:17405[D loss: 0.999967] [G loss: 1.000058]\n",
      "epoch:4 step:17410[D loss: 0.999970] [G loss: 1.000054]\n",
      "epoch:4 step:17415[D loss: 0.999974] [G loss: 1.000050]\n",
      "epoch:4 step:17420[D loss: 0.999981] [G loss: 1.000042]\n",
      "epoch:4 step:17425[D loss: 0.999968] [G loss: 1.000053]\n",
      "epoch:4 step:17430[D loss: 0.999970] [G loss: 1.000073]\n",
      "epoch:4 step:17435[D loss: 0.999986] [G loss: 1.000039]\n",
      "epoch:4 step:17440[D loss: 0.999976] [G loss: 1.000060]\n",
      "epoch:4 step:17445[D loss: 0.999970] [G loss: 1.000058]\n",
      "epoch:4 step:17450[D loss: 0.999977] [G loss: 1.000048]\n",
      "epoch:4 step:17455[D loss: 0.999977] [G loss: 1.000066]\n",
      "epoch:4 step:17460[D loss: 0.999975] [G loss: 1.000054]\n",
      "epoch:4 step:17465[D loss: 0.999968] [G loss: 1.000065]\n",
      "epoch:4 step:17470[D loss: 0.999988] [G loss: 1.000034]\n",
      "epoch:4 step:17475[D loss: 0.999974] [G loss: 1.000044]\n",
      "epoch:4 step:17480[D loss: 0.999975] [G loss: 1.000066]\n",
      "epoch:4 step:17485[D loss: 0.999977] [G loss: 1.000064]\n",
      "epoch:4 step:17490[D loss: 0.999965] [G loss: 1.000057]\n",
      "epoch:4 step:17495[D loss: 1.000034] [G loss: 1.000002]\n",
      "epoch:4 step:17500[D loss: 0.999938] [G loss: 1.000107]\n",
      "epoch:4 step:17505[D loss: 0.999966] [G loss: 1.000080]\n",
      "epoch:4 step:17510[D loss: 0.999974] [G loss: 1.000061]\n",
      "epoch:4 step:17515[D loss: 0.999975] [G loss: 1.000051]\n",
      "epoch:4 step:17520[D loss: 0.999988] [G loss: 1.000022]\n",
      "epoch:4 step:17525[D loss: 0.999975] [G loss: 1.000054]\n",
      "epoch:4 step:17530[D loss: 0.999952] [G loss: 1.000096]\n",
      "epoch:4 step:17535[D loss: 0.999970] [G loss: 1.000065]\n",
      "epoch:4 step:17540[D loss: 0.999973] [G loss: 1.000062]\n",
      "epoch:4 step:17545[D loss: 1.000003] [G loss: 1.000011]\n",
      "epoch:4 step:17550[D loss: 0.999968] [G loss: 1.000071]\n",
      "epoch:4 step:17555[D loss: 0.999973] [G loss: 1.000072]\n",
      "epoch:4 step:17560[D loss: 0.999970] [G loss: 1.000059]\n",
      "epoch:4 step:17565[D loss: 0.999963] [G loss: 1.000055]\n",
      "epoch:4 step:17570[D loss: 0.999969] [G loss: 1.000065]\n",
      "epoch:4 step:17575[D loss: 0.999982] [G loss: 1.000052]\n",
      "epoch:4 step:17580[D loss: 0.999984] [G loss: 1.000040]\n",
      "epoch:4 step:17585[D loss: 0.999980] [G loss: 1.000051]\n",
      "epoch:4 step:17590[D loss: 0.999980] [G loss: 1.000029]\n",
      "epoch:4 step:17595[D loss: 0.999972] [G loss: 1.000055]\n",
      "epoch:4 step:17600[D loss: 0.999979] [G loss: 1.000025]\n",
      "##############\n",
      "[0.86949616 0.86895105 0.84059903 0.82571285 0.81838635 0.84029501\n",
      " 0.87964916 0.84492297 0.81503447 0.82065837]\n",
      "##########\n",
      "epoch:4 step:17605[D loss: 0.999972] [G loss: 1.000026]\n",
      "epoch:4 step:17610[D loss: 0.999964] [G loss: 1.000069]\n",
      "epoch:4 step:17615[D loss: 0.999966] [G loss: 1.000054]\n",
      "epoch:4 step:17620[D loss: 0.999972] [G loss: 1.000058]\n",
      "epoch:4 step:17625[D loss: 0.999980] [G loss: 1.000051]\n",
      "epoch:4 step:17630[D loss: 0.999992] [G loss: 1.000034]\n",
      "epoch:4 step:17635[D loss: 0.999979] [G loss: 1.000065]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:4 step:17640[D loss: 0.999968] [G loss: 1.000068]\n",
      "epoch:4 step:17645[D loss: 0.999978] [G loss: 1.000044]\n",
      "epoch:4 step:17650[D loss: 0.999982] [G loss: 1.000030]\n",
      "epoch:4 step:17655[D loss: 0.999985] [G loss: 1.000025]\n",
      "epoch:4 step:17660[D loss: 0.999976] [G loss: 1.000082]\n",
      "epoch:4 step:17665[D loss: 0.999971] [G loss: 1.000078]\n",
      "epoch:4 step:17670[D loss: 0.999983] [G loss: 1.000061]\n",
      "epoch:4 step:17675[D loss: 0.999981] [G loss: 1.000055]\n",
      "epoch:4 step:17680[D loss: 0.999968] [G loss: 1.000053]\n",
      "epoch:4 step:17685[D loss: 0.999985] [G loss: 1.000069]\n",
      "epoch:4 step:17690[D loss: 0.999977] [G loss: 1.000064]\n",
      "epoch:4 step:17695[D loss: 0.999985] [G loss: 1.000047]\n",
      "epoch:4 step:17700[D loss: 0.999962] [G loss: 1.000075]\n",
      "epoch:4 step:17705[D loss: 0.999987] [G loss: 1.000034]\n",
      "epoch:4 step:17710[D loss: 0.999991] [G loss: 1.000011]\n",
      "epoch:4 step:17715[D loss: 0.999980] [G loss: 1.000047]\n",
      "epoch:4 step:17720[D loss: 0.999978] [G loss: 1.000063]\n",
      "epoch:4 step:17725[D loss: 0.999980] [G loss: 1.000068]\n",
      "epoch:4 step:17730[D loss: 0.999975] [G loss: 1.000057]\n",
      "epoch:4 step:17735[D loss: 0.999972] [G loss: 1.000061]\n",
      "epoch:4 step:17740[D loss: 0.999972] [G loss: 1.000058]\n",
      "epoch:4 step:17745[D loss: 0.999964] [G loss: 1.000069]\n",
      "epoch:4 step:17750[D loss: 0.999972] [G loss: 1.000061]\n",
      "epoch:4 step:17755[D loss: 0.999981] [G loss: 1.000042]\n",
      "epoch:4 step:17760[D loss: 0.999979] [G loss: 1.000048]\n",
      "epoch:4 step:17765[D loss: 0.999970] [G loss: 1.000066]\n",
      "epoch:4 step:17770[D loss: 0.999973] [G loss: 1.000059]\n",
      "epoch:4 step:17775[D loss: 0.999972] [G loss: 1.000047]\n",
      "epoch:4 step:17780[D loss: 0.999976] [G loss: 1.000037]\n",
      "epoch:4 step:17785[D loss: 0.999976] [G loss: 1.000038]\n",
      "epoch:4 step:17790[D loss: 0.999980] [G loss: 1.000058]\n",
      "epoch:4 step:17795[D loss: 0.999967] [G loss: 1.000074]\n",
      "epoch:4 step:17800[D loss: 0.999990] [G loss: 1.000012]\n",
      "##############\n",
      "[0.8593279  0.85273091 0.83088572 0.80927835 0.81218381 0.85560407\n",
      " 0.87497131 0.83710947 0.80309657 0.85260671]\n",
      "##########\n",
      "epoch:4 step:17805[D loss: 0.999975] [G loss: 1.000064]\n",
      "epoch:4 step:17810[D loss: 0.999975] [G loss: 1.000068]\n",
      "epoch:4 step:17815[D loss: 0.999974] [G loss: 1.000079]\n",
      "epoch:4 step:17820[D loss: 0.999980] [G loss: 1.000069]\n",
      "epoch:4 step:17825[D loss: 0.999976] [G loss: 1.000062]\n",
      "epoch:4 step:17830[D loss: 0.999988] [G loss: 1.000017]\n",
      "epoch:4 step:17835[D loss: 1.000002] [G loss: 1.000021]\n",
      "epoch:4 step:17840[D loss: 0.999967] [G loss: 1.000085]\n",
      "epoch:4 step:17845[D loss: 0.999970] [G loss: 1.000083]\n",
      "epoch:4 step:17850[D loss: 0.999974] [G loss: 1.000073]\n",
      "epoch:4 step:17855[D loss: 0.999972] [G loss: 1.000069]\n",
      "epoch:4 step:17860[D loss: 0.999976] [G loss: 1.000070]\n",
      "epoch:4 step:17865[D loss: 0.999980] [G loss: 1.000051]\n",
      "epoch:4 step:17870[D loss: 0.999987] [G loss: 1.000031]\n",
      "epoch:4 step:17875[D loss: 0.999992] [G loss: 1.000022]\n",
      "epoch:4 step:17880[D loss: 0.999966] [G loss: 1.000064]\n",
      "epoch:4 step:17885[D loss: 0.999959] [G loss: 1.000085]\n",
      "epoch:4 step:17890[D loss: 0.999967] [G loss: 1.000071]\n",
      "epoch:4 step:17895[D loss: 0.999978] [G loss: 1.000051]\n",
      "epoch:4 step:17900[D loss: 0.999973] [G loss: 1.000077]\n",
      "epoch:4 step:17905[D loss: 0.999979] [G loss: 1.000058]\n",
      "epoch:4 step:17910[D loss: 0.999965] [G loss: 1.000064]\n",
      "epoch:4 step:17915[D loss: 0.999973] [G loss: 1.000083]\n",
      "epoch:4 step:17920[D loss: 0.999977] [G loss: 1.000062]\n",
      "epoch:4 step:17925[D loss: 0.999974] [G loss: 1.000057]\n",
      "epoch:4 step:17930[D loss: 0.999962] [G loss: 1.000075]\n",
      "epoch:4 step:17935[D loss: 0.999971] [G loss: 1.000076]\n",
      "epoch:4 step:17940[D loss: 0.999967] [G loss: 1.000072]\n",
      "epoch:4 step:17945[D loss: 0.999975] [G loss: 1.000073]\n",
      "epoch:4 step:17950[D loss: 0.999972] [G loss: 1.000070]\n",
      "epoch:4 step:17955[D loss: 0.999973] [G loss: 1.000066]\n",
      "epoch:4 step:17960[D loss: 0.999977] [G loss: 1.000033]\n",
      "epoch:4 step:17965[D loss: 0.999971] [G loss: 1.000091]\n",
      "epoch:4 step:17970[D loss: 0.999981] [G loss: 1.000050]\n",
      "epoch:4 step:17975[D loss: 0.999965] [G loss: 1.000063]\n",
      "epoch:4 step:17980[D loss: 0.999976] [G loss: 1.000061]\n",
      "epoch:4 step:17985[D loss: 0.999976] [G loss: 1.000037]\n",
      "epoch:4 step:17990[D loss: 0.999984] [G loss: 1.000063]\n",
      "epoch:4 step:17995[D loss: 0.999952] [G loss: 1.000079]\n",
      "epoch:4 step:18000[D loss: 0.999968] [G loss: 1.000065]\n",
      "##############\n",
      "[0.87210851 0.89037711 0.80586422 0.81953757 0.8279889  0.82925633\n",
      " 0.89553692 0.8436081  0.83477936 0.83535608]\n",
      "##########\n",
      "epoch:4 step:18005[D loss: 0.999970] [G loss: 1.000070]\n",
      "epoch:4 step:18010[D loss: 0.999971] [G loss: 1.000057]\n",
      "epoch:4 step:18015[D loss: 0.999969] [G loss: 1.000066]\n",
      "epoch:4 step:18020[D loss: 0.999986] [G loss: 1.000039]\n",
      "epoch:4 step:18025[D loss: 0.999983] [G loss: 1.000050]\n",
      "epoch:4 step:18030[D loss: 0.999971] [G loss: 1.000064]\n",
      "epoch:4 step:18035[D loss: 0.999968] [G loss: 1.000072]\n",
      "epoch:4 step:18040[D loss: 0.999977] [G loss: 1.000062]\n",
      "epoch:4 step:18045[D loss: 0.999974] [G loss: 1.000074]\n",
      "epoch:4 step:18050[D loss: 0.999985] [G loss: 1.000016]\n",
      "epoch:4 step:18055[D loss: 0.999967] [G loss: 1.000075]\n",
      "epoch:4 step:18060[D loss: 0.999976] [G loss: 1.000067]\n",
      "epoch:4 step:18065[D loss: 0.999975] [G loss: 1.000063]\n",
      "epoch:4 step:18070[D loss: 0.999969] [G loss: 1.000058]\n",
      "epoch:4 step:18075[D loss: 0.999984] [G loss: 1.000059]\n",
      "epoch:4 step:18080[D loss: 0.999967] [G loss: 1.000064]\n",
      "epoch:4 step:18085[D loss: 0.999978] [G loss: 1.000079]\n",
      "epoch:4 step:18090[D loss: 0.999968] [G loss: 1.000065]\n",
      "epoch:4 step:18095[D loss: 0.999972] [G loss: 1.000075]\n",
      "epoch:4 step:18100[D loss: 0.999970] [G loss: 1.000063]\n",
      "epoch:4 step:18105[D loss: 0.999988] [G loss: 1.000035]\n",
      "epoch:4 step:18110[D loss: 0.999977] [G loss: 1.000020]\n",
      "epoch:4 step:18115[D loss: 0.999974] [G loss: 1.000055]\n",
      "epoch:4 step:18120[D loss: 0.999959] [G loss: 1.000065]\n",
      "epoch:4 step:18125[D loss: 0.999975] [G loss: 1.000053]\n",
      "epoch:4 step:18130[D loss: 0.999975] [G loss: 1.000040]\n",
      "epoch:4 step:18135[D loss: 0.999964] [G loss: 1.000048]\n",
      "epoch:4 step:18140[D loss: 0.999980] [G loss: 1.000044]\n",
      "epoch:4 step:18145[D loss: 0.999973] [G loss: 1.000049]\n",
      "epoch:4 step:18150[D loss: 0.999972] [G loss: 1.000044]\n",
      "epoch:4 step:18155[D loss: 0.999974] [G loss: 1.000061]\n",
      "epoch:4 step:18160[D loss: 0.999972] [G loss: 1.000054]\n",
      "epoch:4 step:18165[D loss: 0.999980] [G loss: 1.000040]\n",
      "epoch:4 step:18170[D loss: 0.999981] [G loss: 1.000045]\n",
      "epoch:4 step:18175[D loss: 0.999967] [G loss: 1.000075]\n",
      "epoch:4 step:18180[D loss: 0.999976] [G loss: 1.000052]\n",
      "epoch:4 step:18185[D loss: 0.999971] [G loss: 1.000060]\n",
      "epoch:4 step:18190[D loss: 0.999988] [G loss: 1.000029]\n",
      "epoch:4 step:18195[D loss: 0.999972] [G loss: 1.000051]\n",
      "epoch:4 step:18200[D loss: 0.999970] [G loss: 1.000059]\n",
      "##############\n",
      "[0.85950483 0.85908137 0.82884569 0.84263112 0.79955056 0.84253153\n",
      " 0.85979025 0.83809448 0.82699035 0.81542454]\n",
      "##########\n",
      "epoch:4 step:18205[D loss: 0.999979] [G loss: 1.000053]\n",
      "epoch:4 step:18210[D loss: 0.999981] [G loss: 1.000042]\n",
      "epoch:4 step:18215[D loss: 0.999982] [G loss: 1.000055]\n",
      "epoch:4 step:18220[D loss: 0.999972] [G loss: 1.000063]\n",
      "epoch:4 step:18225[D loss: 0.999963] [G loss: 1.000051]\n",
      "epoch:4 step:18230[D loss: 0.999972] [G loss: 1.000059]\n",
      "epoch:4 step:18235[D loss: 0.999970] [G loss: 1.000057]\n",
      "epoch:4 step:18240[D loss: 0.999971] [G loss: 1.000056]\n",
      "epoch:4 step:18245[D loss: 0.999974] [G loss: 1.000055]\n",
      "epoch:4 step:18250[D loss: 0.999971] [G loss: 1.000047]\n",
      "epoch:4 step:18255[D loss: 0.999973] [G loss: 1.000059]\n",
      "epoch:4 step:18260[D loss: 0.999980] [G loss: 1.000053]\n",
      "epoch:4 step:18265[D loss: 0.999971] [G loss: 1.000023]\n",
      "epoch:4 step:18270[D loss: 0.999979] [G loss: 1.000064]\n",
      "epoch:4 step:18275[D loss: 0.999964] [G loss: 1.000078]\n",
      "epoch:4 step:18280[D loss: 0.999958] [G loss: 1.000065]\n",
      "epoch:4 step:18285[D loss: 0.999976] [G loss: 1.000059]\n",
      "epoch:4 step:18290[D loss: 0.999988] [G loss: 1.000022]\n",
      "epoch:4 step:18295[D loss: 0.999999] [G loss: 1.000026]\n",
      "epoch:4 step:18300[D loss: 0.999970] [G loss: 1.000072]\n",
      "epoch:4 step:18305[D loss: 0.999972] [G loss: 1.000072]\n",
      "epoch:4 step:18310[D loss: 0.999977] [G loss: 1.000061]\n",
      "epoch:4 step:18315[D loss: 1.000009] [G loss: 1.000018]\n",
      "epoch:4 step:18320[D loss: 0.999979] [G loss: 1.000061]\n",
      "epoch:4 step:18325[D loss: 0.999952] [G loss: 1.000124]\n",
      "epoch:4 step:18330[D loss: 0.999962] [G loss: 1.000085]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:4 step:18335[D loss: 0.999971] [G loss: 1.000071]\n",
      "epoch:4 step:18340[D loss: 0.999978] [G loss: 1.000060]\n",
      "epoch:4 step:18345[D loss: 0.999983] [G loss: 1.000028]\n",
      "epoch:4 step:18350[D loss: 1.000023] [G loss: 1.000021]\n",
      "epoch:4 step:18355[D loss: 0.999944] [G loss: 1.000076]\n",
      "epoch:4 step:18360[D loss: 0.999964] [G loss: 1.000078]\n",
      "epoch:4 step:18365[D loss: 0.999969] [G loss: 1.000071]\n",
      "epoch:4 step:18370[D loss: 0.999967] [G loss: 1.000061]\n",
      "epoch:4 step:18375[D loss: 0.999991] [G loss: 1.000044]\n",
      "epoch:4 step:18380[D loss: 0.999959] [G loss: 1.000081]\n",
      "epoch:4 step:18385[D loss: 0.999968] [G loss: 1.000077]\n",
      "epoch:4 step:18390[D loss: 0.999955] [G loss: 1.000080]\n",
      "epoch:4 step:18395[D loss: 0.999973] [G loss: 1.000067]\n",
      "epoch:4 step:18400[D loss: 0.999971] [G loss: 1.000061]\n",
      "##############\n",
      "[0.87379365 0.88596077 0.82848952 0.83584699 0.80424957 0.82311321\n",
      " 0.87248303 0.8530093  0.83320143 0.8447376 ]\n",
      "##########\n",
      "epoch:4 step:18405[D loss: 0.999974] [G loss: 1.000063]\n",
      "epoch:4 step:18410[D loss: 0.999968] [G loss: 1.000060]\n",
      "epoch:4 step:18415[D loss: 0.999992] [G loss: 1.000043]\n",
      "epoch:4 step:18420[D loss: 1.000001] [G loss: 0.999994]\n",
      "epoch:4 step:18425[D loss: 0.999968] [G loss: 1.000065]\n",
      "epoch:4 step:18430[D loss: 0.999970] [G loss: 1.000070]\n",
      "epoch:4 step:18435[D loss: 0.999974] [G loss: 1.000053]\n",
      "epoch:4 step:18440[D loss: 0.999977] [G loss: 1.000059]\n",
      "epoch:4 step:18445[D loss: 0.999985] [G loss: 1.000038]\n",
      "epoch:4 step:18450[D loss: 0.999985] [G loss: 1.000021]\n",
      "epoch:4 step:18455[D loss: 0.999977] [G loss: 1.000073]\n",
      "epoch:4 step:18460[D loss: 0.999970] [G loss: 1.000067]\n",
      "epoch:4 step:18465[D loss: 0.999967] [G loss: 1.000076]\n",
      "epoch:4 step:18470[D loss: 0.999969] [G loss: 1.000076]\n",
      "epoch:4 step:18475[D loss: 0.999972] [G loss: 1.000066]\n",
      "epoch:4 step:18480[D loss: 0.999972] [G loss: 1.000060]\n",
      "epoch:4 step:18485[D loss: 0.999973] [G loss: 1.000062]\n",
      "epoch:4 step:18490[D loss: 0.999997] [G loss: 1.000019]\n",
      "epoch:4 step:18495[D loss: 0.999969] [G loss: 1.000065]\n",
      "epoch:4 step:18500[D loss: 0.999968] [G loss: 1.000068]\n",
      "epoch:4 step:18505[D loss: 0.999973] [G loss: 1.000063]\n",
      "epoch:4 step:18510[D loss: 0.999974] [G loss: 1.000066]\n",
      "epoch:4 step:18515[D loss: 0.999975] [G loss: 1.000080]\n",
      "epoch:4 step:18520[D loss: 0.999974] [G loss: 1.000049]\n",
      "epoch:4 step:18525[D loss: 0.999976] [G loss: 1.000060]\n",
      "epoch:4 step:18530[D loss: 1.000006] [G loss: 1.000016]\n",
      "epoch:4 step:18535[D loss: 0.999988] [G loss: 1.000028]\n",
      "epoch:4 step:18540[D loss: 0.999984] [G loss: 1.000018]\n",
      "epoch:4 step:18545[D loss: 0.999969] [G loss: 1.000050]\n",
      "epoch:4 step:18550[D loss: 0.999976] [G loss: 1.000058]\n",
      "epoch:4 step:18555[D loss: 1.000004] [G loss: 1.000012]\n",
      "epoch:4 step:18560[D loss: 0.999974] [G loss: 1.000062]\n",
      "epoch:4 step:18565[D loss: 0.999978] [G loss: 1.000057]\n",
      "epoch:4 step:18570[D loss: 0.999977] [G loss: 1.000072]\n",
      "epoch:4 step:18575[D loss: 0.999983] [G loss: 1.000052]\n",
      "epoch:4 step:18580[D loss: 0.999972] [G loss: 1.000045]\n",
      "epoch:4 step:18585[D loss: 0.999985] [G loss: 1.000039]\n",
      "epoch:4 step:18590[D loss: 0.999987] [G loss: 1.000025]\n",
      "epoch:4 step:18595[D loss: 0.999967] [G loss: 1.000088]\n",
      "epoch:4 step:18600[D loss: 0.999967] [G loss: 1.000075]\n",
      "##############\n",
      "[0.85399164 0.84311701 0.82462493 0.83688981 0.80435154 0.82083231\n",
      " 0.86122373 0.85344613 0.82259537 0.83392764]\n",
      "##########\n",
      "epoch:4 step:18605[D loss: 0.999973] [G loss: 1.000061]\n",
      "epoch:4 step:18610[D loss: 0.999985] [G loss: 1.000054]\n",
      "epoch:4 step:18615[D loss: 0.999989] [G loss: 1.000064]\n",
      "epoch:4 step:18620[D loss: 0.999968] [G loss: 1.000078]\n",
      "epoch:4 step:18625[D loss: 0.999954] [G loss: 1.000085]\n",
      "epoch:4 step:18630[D loss: 0.999972] [G loss: 1.000069]\n",
      "epoch:4 step:18635[D loss: 0.999970] [G loss: 1.000070]\n",
      "epoch:4 step:18640[D loss: 0.999970] [G loss: 1.000040]\n",
      "epoch:4 step:18645[D loss: 0.999985] [G loss: 1.000044]\n",
      "epoch:4 step:18650[D loss: 0.999979] [G loss: 1.000043]\n",
      "epoch:4 step:18655[D loss: 0.999957] [G loss: 1.000098]\n",
      "epoch:4 step:18660[D loss: 0.999969] [G loss: 1.000061]\n",
      "epoch:4 step:18665[D loss: 0.999967] [G loss: 1.000080]\n",
      "epoch:4 step:18670[D loss: 0.999968] [G loss: 1.000069]\n",
      "epoch:4 step:18675[D loss: 0.999973] [G loss: 1.000067]\n",
      "epoch:4 step:18680[D loss: 0.999979] [G loss: 1.000071]\n",
      "epoch:4 step:18685[D loss: 0.999970] [G loss: 1.000066]\n",
      "epoch:4 step:18690[D loss: 0.999980] [G loss: 1.000064]\n",
      "epoch:4 step:18695[D loss: 0.999974] [G loss: 1.000055]\n",
      "epoch:4 step:18700[D loss: 0.999979] [G loss: 1.000064]\n",
      "epoch:4 step:18705[D loss: 0.999975] [G loss: 1.000044]\n",
      "epoch:4 step:18710[D loss: 0.999971] [G loss: 1.000051]\n",
      "epoch:4 step:18715[D loss: 0.999974] [G loss: 1.000058]\n",
      "epoch:4 step:18720[D loss: 0.999971] [G loss: 1.000059]\n",
      "epoch:4 step:18725[D loss: 0.999977] [G loss: 1.000054]\n",
      "epoch:4 step:18730[D loss: 0.999982] [G loss: 1.000040]\n",
      "epoch:4 step:18735[D loss: 0.999970] [G loss: 1.000071]\n",
      "epoch:4 step:18740[D loss: 0.999974] [G loss: 1.000052]\n",
      "epoch:4 step:18745[D loss: 0.999976] [G loss: 1.000052]\n",
      "epoch:4 step:18750[D loss: 0.999965] [G loss: 1.000053]\n",
      "epoch:4 step:18755[D loss: 0.999980] [G loss: 1.000038]\n",
      "epoch:4 step:18760[D loss: 0.999962] [G loss: 1.000077]\n",
      "epoch:4 step:18765[D loss: 0.999960] [G loss: 1.000057]\n",
      "epoch:4 step:18770[D loss: 0.999959] [G loss: 1.000048]\n",
      "epoch:4 step:18775[D loss: 0.999988] [G loss: 1.000045]\n",
      "epoch:4 step:18780[D loss: 0.999979] [G loss: 1.000059]\n",
      "epoch:4 step:18785[D loss: 0.999987] [G loss: 1.000035]\n",
      "epoch:4 step:18790[D loss: 0.999963] [G loss: 1.000082]\n",
      "epoch:4 step:18795[D loss: 0.999971] [G loss: 1.000071]\n",
      "epoch:4 step:18800[D loss: 0.999971] [G loss: 1.000065]\n",
      "##############\n",
      "[0.86812599 0.88694038 0.82005424 0.82235747 0.81085403 0.82432493\n",
      " 0.85750708 0.84458662 0.83734812 0.82755226]\n",
      "##########\n",
      "epoch:4 step:18805[D loss: 0.999995] [G loss: 1.000028]\n",
      "epoch:4 step:18810[D loss: 0.999962] [G loss: 1.000057]\n",
      "epoch:4 step:18815[D loss: 0.999977] [G loss: 1.000056]\n",
      "epoch:4 step:18820[D loss: 0.999972] [G loss: 1.000038]\n",
      "epoch:4 step:18825[D loss: 0.999975] [G loss: 1.000057]\n",
      "epoch:4 step:18830[D loss: 0.999977] [G loss: 1.000046]\n",
      "epoch:4 step:18835[D loss: 0.999985] [G loss: 1.000021]\n",
      "epoch:4 step:18840[D loss: 0.999964] [G loss: 1.000062]\n",
      "epoch:4 step:18845[D loss: 0.999969] [G loss: 1.000049]\n",
      "epoch:4 step:18850[D loss: 0.999970] [G loss: 1.000054]\n",
      "epoch:4 step:18855[D loss: 0.999980] [G loss: 1.000046]\n",
      "epoch:4 step:18860[D loss: 0.999964] [G loss: 1.000045]\n",
      "epoch:4 step:18865[D loss: 0.999967] [G loss: 1.000048]\n",
      "epoch:4 step:18870[D loss: 0.999971] [G loss: 1.000061]\n",
      "epoch:4 step:18875[D loss: 0.999967] [G loss: 1.000063]\n",
      "epoch:4 step:18880[D loss: 0.999978] [G loss: 1.000055]\n",
      "epoch:4 step:18885[D loss: 0.999973] [G loss: 1.000048]\n",
      "epoch:4 step:18890[D loss: 0.999974] [G loss: 1.000038]\n",
      "epoch:4 step:18895[D loss: 0.999983] [G loss: 1.000034]\n",
      "epoch:4 step:18900[D loss: 0.999977] [G loss: 1.000047]\n",
      "epoch:4 step:18905[D loss: 0.999969] [G loss: 1.000067]\n",
      "epoch:4 step:18910[D loss: 0.999974] [G loss: 1.000059]\n",
      "epoch:4 step:18915[D loss: 0.999974] [G loss: 1.000059]\n",
      "epoch:4 step:18920[D loss: 0.999975] [G loss: 1.000054]\n",
      "epoch:4 step:18925[D loss: 0.999970] [G loss: 1.000058]\n",
      "epoch:4 step:18930[D loss: 0.999971] [G loss: 1.000049]\n",
      "epoch:4 step:18935[D loss: 0.999973] [G loss: 1.000055]\n",
      "epoch:4 step:18940[D loss: 0.999974] [G loss: 1.000060]\n",
      "epoch:4 step:18945[D loss: 0.999981] [G loss: 1.000051]\n",
      "epoch:4 step:18950[D loss: 0.999981] [G loss: 1.000054]\n",
      "epoch:4 step:18955[D loss: 0.999982] [G loss: 1.000050]\n",
      "epoch:4 step:18960[D loss: 0.999968] [G loss: 1.000075]\n",
      "epoch:4 step:18965[D loss: 0.999965] [G loss: 1.000062]\n",
      "epoch:4 step:18970[D loss: 0.999972] [G loss: 1.000064]\n",
      "epoch:4 step:18975[D loss: 0.999965] [G loss: 1.000050]\n",
      "epoch:4 step:18980[D loss: 0.999976] [G loss: 1.000064]\n",
      "epoch:4 step:18985[D loss: 0.999978] [G loss: 1.000055]\n",
      "epoch:4 step:18990[D loss: 0.999972] [G loss: 1.000055]\n",
      "epoch:4 step:18995[D loss: 0.999978] [G loss: 1.000078]\n",
      "epoch:4 step:19000[D loss: 0.999972] [G loss: 1.000055]\n",
      "##############\n",
      "[0.86754851 0.8646491  0.81702735 0.80377288 0.79890783 0.823131\n",
      " 0.86591806 0.86046022 0.81367981 0.82915501]\n",
      "##########\n",
      "epoch:4 step:19005[D loss: 0.999977] [G loss: 1.000055]\n",
      "epoch:4 step:19010[D loss: 0.999973] [G loss: 1.000055]\n",
      "epoch:4 step:19015[D loss: 0.999973] [G loss: 1.000058]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:4 step:19020[D loss: 0.999976] [G loss: 1.000055]\n",
      "epoch:4 step:19025[D loss: 0.999973] [G loss: 1.000063]\n",
      "epoch:4 step:19030[D loss: 0.999974] [G loss: 1.000062]\n",
      "epoch:4 step:19035[D loss: 0.999969] [G loss: 1.000062]\n",
      "epoch:4 step:19040[D loss: 0.999972] [G loss: 1.000069]\n",
      "epoch:4 step:19045[D loss: 0.999971] [G loss: 1.000064]\n",
      "epoch:4 step:19050[D loss: 0.999970] [G loss: 1.000072]\n",
      "epoch:4 step:19055[D loss: 0.999997] [G loss: 1.000026]\n",
      "epoch:4 step:19060[D loss: 0.999972] [G loss: 1.000072]\n",
      "epoch:4 step:19065[D loss: 0.999970] [G loss: 1.000082]\n",
      "epoch:4 step:19070[D loss: 0.999963] [G loss: 1.000075]\n",
      "epoch:4 step:19075[D loss: 0.999990] [G loss: 1.000025]\n",
      "epoch:4 step:19080[D loss: 0.999967] [G loss: 1.000072]\n",
      "epoch:4 step:19085[D loss: 0.999966] [G loss: 1.000062]\n",
      "epoch:4 step:19090[D loss: 0.999970] [G loss: 1.000050]\n",
      "epoch:4 step:19095[D loss: 0.999978] [G loss: 1.000050]\n",
      "epoch:4 step:19100[D loss: 0.999972] [G loss: 1.000045]\n",
      "epoch:4 step:19105[D loss: 0.999977] [G loss: 1.000045]\n",
      "epoch:4 step:19110[D loss: 0.999970] [G loss: 1.000053]\n",
      "epoch:4 step:19115[D loss: 0.999987] [G loss: 1.000019]\n",
      "epoch:4 step:19120[D loss: 0.999976] [G loss: 1.000052]\n",
      "epoch:4 step:19125[D loss: 0.999977] [G loss: 1.000048]\n",
      "epoch:4 step:19130[D loss: 0.999974] [G loss: 1.000052]\n",
      "epoch:4 step:19135[D loss: 0.999980] [G loss: 1.000047]\n",
      "epoch:4 step:19140[D loss: 0.999983] [G loss: 1.000044]\n",
      "epoch:4 step:19145[D loss: 0.999985] [G loss: 1.000048]\n",
      "epoch:4 step:19150[D loss: 0.999981] [G loss: 1.000042]\n",
      "epoch:4 step:19155[D loss: 0.999971] [G loss: 1.000068]\n",
      "epoch:4 step:19160[D loss: 0.999983] [G loss: 1.000046]\n",
      "epoch:4 step:19165[D loss: 0.999993] [G loss: 1.000013]\n",
      "epoch:4 step:19170[D loss: 0.999975] [G loss: 1.000056]\n",
      "epoch:4 step:19175[D loss: 0.999968] [G loss: 1.000062]\n",
      "epoch:4 step:19180[D loss: 0.999982] [G loss: 1.000033]\n",
      "epoch:4 step:19185[D loss: 0.999982] [G loss: 1.000053]\n",
      "epoch:4 step:19190[D loss: 0.999971] [G loss: 1.000046]\n",
      "epoch:4 step:19195[D loss: 0.999966] [G loss: 1.000059]\n",
      "epoch:4 step:19200[D loss: 0.999979] [G loss: 1.000071]\n",
      "##############\n",
      "[0.86707922 0.85817602 0.84574206 0.82770252 0.7831227  0.8281982\n",
      " 0.86417549 0.83620169 0.81837964 0.82882552]\n",
      "##########\n",
      "epoch:4 step:19205[D loss: 0.999977] [G loss: 1.000058]\n",
      "epoch:4 step:19210[D loss: 0.999971] [G loss: 1.000058]\n",
      "epoch:4 step:19215[D loss: 0.999980] [G loss: 1.000039]\n",
      "epoch:4 step:19220[D loss: 0.999978] [G loss: 1.000032]\n",
      "epoch:4 step:19225[D loss: 0.999957] [G loss: 1.000086]\n",
      "epoch:4 step:19230[D loss: 0.999972] [G loss: 1.000057]\n",
      "epoch:4 step:19235[D loss: 0.999977] [G loss: 1.000055]\n",
      "epoch:4 step:19240[D loss: 0.999966] [G loss: 1.000061]\n",
      "epoch:4 step:19245[D loss: 0.999975] [G loss: 1.000043]\n",
      "epoch:4 step:19250[D loss: 0.999988] [G loss: 1.000046]\n",
      "epoch:4 step:19255[D loss: 0.999970] [G loss: 1.000061]\n",
      "epoch:4 step:19260[D loss: 0.999980] [G loss: 1.000042]\n",
      "epoch:4 step:19265[D loss: 0.999982] [G loss: 1.000057]\n",
      "epoch:4 step:19270[D loss: 0.999973] [G loss: 1.000050]\n",
      "epoch:4 step:19275[D loss: 0.999973] [G loss: 1.000064]\n",
      "epoch:4 step:19280[D loss: 0.999968] [G loss: 1.000045]\n",
      "epoch:4 step:19285[D loss: 0.999973] [G loss: 1.000055]\n",
      "epoch:4 step:19290[D loss: 0.999970] [G loss: 1.000060]\n",
      "epoch:4 step:19295[D loss: 0.999989] [G loss: 1.000047]\n",
      "epoch:4 step:19300[D loss: 0.999975] [G loss: 1.000085]\n",
      "epoch:4 step:19305[D loss: 0.999965] [G loss: 1.000076]\n",
      "epoch:4 step:19310[D loss: 0.999976] [G loss: 1.000053]\n",
      "epoch:4 step:19315[D loss: 0.999995] [G loss: 1.000004]\n",
      "epoch:4 step:19320[D loss: 0.999962] [G loss: 1.000058]\n",
      "epoch:4 step:19325[D loss: 0.999963] [G loss: 1.000067]\n",
      "epoch:4 step:19330[D loss: 0.999973] [G loss: 1.000069]\n",
      "epoch:4 step:19335[D loss: 0.999974] [G loss: 1.000069]\n",
      "epoch:4 step:19340[D loss: 0.999976] [G loss: 1.000027]\n",
      "epoch:4 step:19345[D loss: 0.999985] [G loss: 1.000071]\n",
      "epoch:4 step:19350[D loss: 0.999963] [G loss: 1.000068]\n",
      "epoch:4 step:19355[D loss: 0.999983] [G loss: 1.000058]\n",
      "epoch:4 step:19360[D loss: 0.999976] [G loss: 1.000047]\n",
      "epoch:4 step:19365[D loss: 0.999975] [G loss: 1.000053]\n",
      "epoch:4 step:19370[D loss: 0.999967] [G loss: 1.000066]\n",
      "epoch:4 step:19375[D loss: 0.999996] [G loss: 1.000023]\n",
      "epoch:4 step:19380[D loss: 0.999975] [G loss: 1.000070]\n",
      "epoch:4 step:19385[D loss: 0.999972] [G loss: 1.000061]\n",
      "epoch:4 step:19390[D loss: 0.999975] [G loss: 1.000043]\n",
      "epoch:4 step:19395[D loss: 0.999972] [G loss: 1.000048]\n",
      "epoch:4 step:19400[D loss: 0.999995] [G loss: 1.000033]\n",
      "##############\n",
      "[0.86046568 0.86353405 0.80899802 0.86016547 0.76672744 0.8277986\n",
      " 0.87166748 0.82707553 0.84125069 0.84076021]\n",
      "##########\n",
      "epoch:4 step:19405[D loss: 0.999981] [G loss: 1.000055]\n",
      "epoch:4 step:19410[D loss: 0.999972] [G loss: 1.000043]\n",
      "epoch:4 step:19415[D loss: 0.999971] [G loss: 1.000043]\n",
      "epoch:4 step:19420[D loss: 0.999975] [G loss: 1.000062]\n",
      "epoch:4 step:19425[D loss: 0.999975] [G loss: 1.000064]\n",
      "epoch:4 step:19430[D loss: 0.999968] [G loss: 1.000053]\n",
      "epoch:4 step:19435[D loss: 0.999976] [G loss: 1.000059]\n",
      "epoch:4 step:19440[D loss: 0.999973] [G loss: 1.000091]\n",
      "epoch:4 step:19445[D loss: 0.999969] [G loss: 1.000073]\n",
      "epoch:4 step:19450[D loss: 0.999976] [G loss: 1.000062]\n",
      "epoch:4 step:19455[D loss: 0.999982] [G loss: 1.000052]\n",
      "epoch:4 step:19460[D loss: 0.999968] [G loss: 1.000045]\n",
      "epoch:4 step:19465[D loss: 0.999986] [G loss: 1.000033]\n",
      "epoch:4 step:19470[D loss: 0.999970] [G loss: 1.000076]\n",
      "epoch:4 step:19475[D loss: 0.999971] [G loss: 1.000062]\n",
      "epoch:4 step:19480[D loss: 0.999981] [G loss: 1.000059]\n",
      "epoch:4 step:19485[D loss: 0.999980] [G loss: 1.000052]\n",
      "epoch:4 step:19490[D loss: 0.999974] [G loss: 1.000057]\n",
      "epoch:4 step:19495[D loss: 0.999983] [G loss: 1.000053]\n",
      "epoch:4 step:19500[D loss: 0.999977] [G loss: 1.000069]\n",
      "epoch:4 step:19505[D loss: 0.999973] [G loss: 1.000069]\n",
      "epoch:4 step:19510[D loss: 0.999970] [G loss: 1.000071]\n",
      "epoch:4 step:19515[D loss: 1.000008] [G loss: 1.000043]\n",
      "epoch:4 step:19520[D loss: 0.999997] [G loss: 1.000065]\n",
      "epoch:4 step:19525[D loss: 0.999960] [G loss: 1.000071]\n",
      "epoch:5 step:19530[D loss: 0.999964] [G loss: 1.000076]\n",
      "epoch:5 step:19535[D loss: 0.999971] [G loss: 1.000068]\n",
      "epoch:5 step:19540[D loss: 0.999974] [G loss: 1.000052]\n",
      "epoch:5 step:19545[D loss: 0.999980] [G loss: 1.000043]\n",
      "epoch:5 step:19550[D loss: 0.999972] [G loss: 1.000032]\n",
      "epoch:5 step:19555[D loss: 0.999989] [G loss: 1.000035]\n",
      "epoch:5 step:19560[D loss: 0.999948] [G loss: 1.000079]\n",
      "epoch:5 step:19565[D loss: 0.999966] [G loss: 1.000077]\n",
      "epoch:5 step:19570[D loss: 0.999979] [G loss: 1.000044]\n",
      "epoch:5 step:19575[D loss: 0.999999] [G loss: 0.999998]\n",
      "epoch:5 step:19580[D loss: 0.999972] [G loss: 1.000055]\n",
      "epoch:5 step:19585[D loss: 1.000009] [G loss: 0.999998]\n",
      "epoch:5 step:19590[D loss: 0.999954] [G loss: 1.000097]\n",
      "epoch:5 step:19595[D loss: 0.999973] [G loss: 1.000065]\n",
      "epoch:5 step:19600[D loss: 0.999949] [G loss: 1.000099]\n",
      "##############\n",
      "[0.85730063 0.86617167 0.826872   0.82798352 0.80127974 0.83577889\n",
      " 0.88492302 0.82857974 0.79853422 0.83760431]\n",
      "##########\n",
      "epoch:5 step:19605[D loss: 0.999971] [G loss: 1.000076]\n",
      "epoch:5 step:19610[D loss: 0.999971] [G loss: 1.000069]\n",
      "epoch:5 step:19615[D loss: 0.999965] [G loss: 1.000065]\n",
      "epoch:5 step:19620[D loss: 0.999968] [G loss: 1.000074]\n",
      "epoch:5 step:19625[D loss: 0.999973] [G loss: 1.000049]\n",
      "epoch:5 step:19630[D loss: 0.999974] [G loss: 1.000059]\n",
      "epoch:5 step:19635[D loss: 0.999967] [G loss: 1.000062]\n",
      "epoch:5 step:19640[D loss: 0.999970] [G loss: 1.000072]\n",
      "epoch:5 step:19645[D loss: 0.999976] [G loss: 1.000064]\n",
      "epoch:5 step:19650[D loss: 0.999977] [G loss: 1.000051]\n",
      "epoch:5 step:19655[D loss: 0.999977] [G loss: 1.000062]\n",
      "epoch:5 step:19660[D loss: 0.999973] [G loss: 1.000063]\n",
      "epoch:5 step:19665[D loss: 0.999971] [G loss: 1.000061]\n",
      "epoch:5 step:19670[D loss: 0.999976] [G loss: 1.000061]\n",
      "epoch:5 step:19675[D loss: 0.999959] [G loss: 1.000072]\n",
      "epoch:5 step:19680[D loss: 0.999965] [G loss: 1.000063]\n",
      "epoch:5 step:19685[D loss: 0.999967] [G loss: 1.000060]\n",
      "epoch:5 step:19690[D loss: 0.999973] [G loss: 1.000064]\n",
      "epoch:5 step:19695[D loss: 0.999974] [G loss: 1.000063]\n",
      "epoch:5 step:19700[D loss: 0.999990] [G loss: 1.000029]\n",
      "epoch:5 step:19705[D loss: 0.999971] [G loss: 1.000061]\n",
      "epoch:5 step:19710[D loss: 0.999974] [G loss: 1.000055]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:5 step:19715[D loss: 0.999975] [G loss: 1.000060]\n",
      "epoch:5 step:19720[D loss: 0.999976] [G loss: 1.000058]\n",
      "epoch:5 step:19725[D loss: 0.999968] [G loss: 1.000056]\n",
      "epoch:5 step:19730[D loss: 0.999974] [G loss: 1.000053]\n",
      "epoch:5 step:19735[D loss: 0.999967] [G loss: 1.000075]\n",
      "epoch:5 step:19740[D loss: 0.999967] [G loss: 1.000070]\n",
      "epoch:5 step:19745[D loss: 0.999993] [G loss: 1.000046]\n",
      "epoch:5 step:19750[D loss: 0.999980] [G loss: 1.000083]\n",
      "epoch:5 step:19755[D loss: 0.999967] [G loss: 1.000067]\n",
      "epoch:5 step:19760[D loss: 0.999982] [G loss: 1.000044]\n",
      "epoch:5 step:19765[D loss: 0.999971] [G loss: 1.000053]\n",
      "epoch:5 step:19770[D loss: 1.000005] [G loss: 1.000003]\n",
      "epoch:5 step:19775[D loss: 0.999961] [G loss: 1.000082]\n",
      "epoch:5 step:19780[D loss: 0.999969] [G loss: 1.000063]\n",
      "epoch:5 step:19785[D loss: 0.999992] [G loss: 1.000039]\n",
      "epoch:5 step:19790[D loss: 0.999978] [G loss: 1.000033]\n",
      "epoch:5 step:19795[D loss: 0.999992] [G loss: 1.000040]\n",
      "epoch:5 step:19800[D loss: 0.999963] [G loss: 1.000077]\n",
      "##############\n",
      "[0.87844035 0.88027331 0.79961852 0.83400009 0.79650572 0.81986993\n",
      " 0.87731197 0.82628775 0.79692126 0.8418043 ]\n",
      "##########\n",
      "epoch:5 step:19805[D loss: 0.999971] [G loss: 1.000074]\n",
      "epoch:5 step:19810[D loss: 0.999972] [G loss: 1.000072]\n",
      "epoch:5 step:19815[D loss: 0.999980] [G loss: 1.000064]\n",
      "epoch:5 step:19820[D loss: 1.000004] [G loss: 0.999986]\n",
      "epoch:5 step:19825[D loss: 0.999968] [G loss: 1.000076]\n",
      "epoch:5 step:19830[D loss: 0.999979] [G loss: 1.000070]\n",
      "epoch:5 step:19835[D loss: 0.999971] [G loss: 1.000071]\n",
      "epoch:5 step:19840[D loss: 0.999976] [G loss: 1.000061]\n",
      "epoch:5 step:19845[D loss: 0.999982] [G loss: 1.000055]\n",
      "epoch:5 step:19850[D loss: 0.999968] [G loss: 1.000055]\n",
      "epoch:5 step:19855[D loss: 0.999986] [G loss: 1.000038]\n",
      "epoch:5 step:19860[D loss: 0.999957] [G loss: 1.000098]\n",
      "epoch:5 step:19865[D loss: 0.999966] [G loss: 1.000071]\n",
      "epoch:5 step:19870[D loss: 0.999972] [G loss: 1.000062]\n",
      "epoch:5 step:19875[D loss: 0.999966] [G loss: 1.000077]\n",
      "epoch:5 step:19880[D loss: 0.999965] [G loss: 1.000077]\n",
      "epoch:5 step:19885[D loss: 0.999989] [G loss: 1.000048]\n",
      "epoch:5 step:19890[D loss: 0.999973] [G loss: 1.000073]\n",
      "epoch:5 step:19895[D loss: 0.999987] [G loss: 1.000056]\n",
      "epoch:5 step:19900[D loss: 0.999963] [G loss: 1.000080]\n",
      "epoch:5 step:19905[D loss: 0.999970] [G loss: 1.000068]\n",
      "epoch:5 step:19910[D loss: 0.999983] [G loss: 1.000044]\n",
      "epoch:5 step:19915[D loss: 0.999996] [G loss: 1.000036]\n",
      "epoch:5 step:19920[D loss: 0.999970] [G loss: 1.000052]\n",
      "epoch:5 step:19925[D loss: 0.999972] [G loss: 1.000060]\n",
      "epoch:5 step:19930[D loss: 0.999978] [G loss: 1.000060]\n",
      "epoch:5 step:19935[D loss: 0.999980] [G loss: 1.000061]\n",
      "epoch:5 step:19940[D loss: 0.999996] [G loss: 1.000051]\n",
      "epoch:5 step:19945[D loss: 0.999966] [G loss: 1.000061]\n",
      "epoch:5 step:19950[D loss: 0.999978] [G loss: 1.000059]\n",
      "epoch:5 step:19955[D loss: 0.999974] [G loss: 1.000067]\n",
      "epoch:5 step:19960[D loss: 0.999966] [G loss: 1.000073]\n",
      "epoch:5 step:19965[D loss: 0.999990] [G loss: 1.000025]\n",
      "epoch:5 step:19970[D loss: 1.000033] [G loss: 0.999997]\n",
      "epoch:5 step:19975[D loss: 0.999930] [G loss: 1.000099]\n",
      "epoch:5 step:19980[D loss: 0.999974] [G loss: 1.000071]\n",
      "epoch:5 step:19985[D loss: 0.999979] [G loss: 1.000055]\n",
      "epoch:5 step:19990[D loss: 1.000036] [G loss: 0.999951]\n",
      "epoch:5 step:19995[D loss: 1.000007] [G loss: 0.999954]\n",
      "epoch:5 step:20000[D loss: 0.999969] [G loss: 1.000061]\n",
      "##############\n",
      "[0.87398942 0.85755214 0.81989463 0.82462458 0.79198932 0.82364029\n",
      " 0.88257059 0.85696642 0.81576239 0.84615984]\n",
      "##########\n",
      "epoch:5 step:20005[D loss: 0.999952] [G loss: 1.000090]\n",
      "epoch:5 step:20010[D loss: 0.999963] [G loss: 1.000065]\n",
      "epoch:5 step:20015[D loss: 0.999969] [G loss: 1.000065]\n",
      "epoch:5 step:20020[D loss: 0.999972] [G loss: 1.000058]\n",
      "epoch:5 step:20025[D loss: 0.999976] [G loss: 1.000055]\n",
      "epoch:5 step:20030[D loss: 0.999985] [G loss: 1.000029]\n",
      "epoch:5 step:20035[D loss: 0.999986] [G loss: 1.000052]\n",
      "epoch:5 step:20040[D loss: 0.999970] [G loss: 1.000060]\n",
      "epoch:5 step:20045[D loss: 0.999971] [G loss: 1.000059]\n",
      "epoch:5 step:20050[D loss: 0.999973] [G loss: 1.000062]\n",
      "epoch:5 step:20055[D loss: 0.999971] [G loss: 1.000055]\n",
      "epoch:5 step:20060[D loss: 0.999973] [G loss: 1.000057]\n",
      "epoch:5 step:20065[D loss: 0.999972] [G loss: 1.000070]\n",
      "epoch:5 step:20070[D loss: 0.999970] [G loss: 1.000059]\n",
      "epoch:5 step:20075[D loss: 0.999984] [G loss: 1.000025]\n",
      "epoch:5 step:20080[D loss: 0.999971] [G loss: 1.000061]\n",
      "epoch:5 step:20085[D loss: 0.999962] [G loss: 1.000066]\n",
      "epoch:5 step:20090[D loss: 0.999972] [G loss: 1.000062]\n",
      "epoch:5 step:20095[D loss: 0.999961] [G loss: 1.000063]\n",
      "epoch:5 step:20100[D loss: 0.999973] [G loss: 1.000047]\n",
      "epoch:5 step:20105[D loss: 0.999970] [G loss: 1.000059]\n",
      "epoch:5 step:20110[D loss: 0.999973] [G loss: 1.000057]\n",
      "epoch:5 step:20115[D loss: 0.999966] [G loss: 1.000076]\n",
      "epoch:5 step:20120[D loss: 0.999968] [G loss: 1.000068]\n",
      "epoch:5 step:20125[D loss: 0.999979] [G loss: 1.000059]\n",
      "epoch:5 step:20130[D loss: 0.999977] [G loss: 1.000063]\n",
      "epoch:5 step:20135[D loss: 0.999970] [G loss: 1.000057]\n",
      "epoch:5 step:20140[D loss: 0.999964] [G loss: 1.000078]\n",
      "epoch:5 step:20145[D loss: 0.999965] [G loss: 1.000073]\n",
      "epoch:5 step:20150[D loss: 0.999969] [G loss: 1.000052]\n",
      "epoch:5 step:20155[D loss: 1.000008] [G loss: 1.000001]\n",
      "epoch:5 step:20160[D loss: 0.999988] [G loss: 1.000037]\n",
      "epoch:5 step:20165[D loss: 0.999961] [G loss: 1.000078]\n",
      "epoch:5 step:20170[D loss: 0.999961] [G loss: 1.000075]\n",
      "epoch:5 step:20175[D loss: 0.999967] [G loss: 1.000073]\n",
      "epoch:5 step:20180[D loss: 0.999973] [G loss: 1.000070]\n",
      "epoch:5 step:20185[D loss: 0.999984] [G loss: 1.000042]\n",
      "epoch:5 step:20190[D loss: 0.999973] [G loss: 1.000075]\n",
      "epoch:5 step:20195[D loss: 0.999977] [G loss: 1.000076]\n",
      "epoch:5 step:20200[D loss: 0.999961] [G loss: 1.000073]\n",
      "##############\n",
      "[0.87330013 0.86934178 0.82196975 0.84409391 0.80344881 0.82564332\n",
      " 0.86037654 0.836451   0.83180935 0.85153857]\n",
      "##########\n",
      "epoch:5 step:20205[D loss: 0.999970] [G loss: 1.000065]\n",
      "epoch:5 step:20210[D loss: 0.999973] [G loss: 1.000068]\n",
      "epoch:5 step:20215[D loss: 0.999971] [G loss: 1.000060]\n",
      "epoch:5 step:20220[D loss: 0.999982] [G loss: 1.000046]\n",
      "epoch:5 step:20225[D loss: 0.999980] [G loss: 1.000039]\n",
      "epoch:5 step:20230[D loss: 0.999964] [G loss: 1.000067]\n",
      "epoch:5 step:20235[D loss: 0.999977] [G loss: 1.000067]\n",
      "epoch:5 step:20240[D loss: 0.999972] [G loss: 1.000064]\n",
      "epoch:5 step:20245[D loss: 0.999970] [G loss: 1.000080]\n",
      "epoch:5 step:20250[D loss: 0.999975] [G loss: 1.000062]\n",
      "epoch:5 step:20255[D loss: 0.999969] [G loss: 1.000061]\n",
      "epoch:5 step:20260[D loss: 0.999971] [G loss: 1.000061]\n",
      "epoch:5 step:20265[D loss: 0.999975] [G loss: 1.000056]\n",
      "epoch:5 step:20270[D loss: 0.999977] [G loss: 1.000041]\n",
      "epoch:5 step:20275[D loss: 0.999973] [G loss: 1.000057]\n",
      "epoch:5 step:20280[D loss: 0.999975] [G loss: 1.000059]\n",
      "epoch:5 step:20285[D loss: 0.999971] [G loss: 1.000067]\n",
      "epoch:5 step:20290[D loss: 0.999974] [G loss: 1.000062]\n",
      "epoch:5 step:20295[D loss: 0.999982] [G loss: 1.000051]\n",
      "epoch:5 step:20300[D loss: 0.999975] [G loss: 1.000066]\n",
      "epoch:5 step:20305[D loss: 0.999972] [G loss: 1.000059]\n",
      "epoch:5 step:20310[D loss: 0.999981] [G loss: 1.000063]\n",
      "epoch:5 step:20315[D loss: 0.999989] [G loss: 1.000027]\n",
      "epoch:5 step:20320[D loss: 0.999975] [G loss: 1.000070]\n",
      "epoch:5 step:20325[D loss: 0.999972] [G loss: 1.000069]\n",
      "epoch:5 step:20330[D loss: 0.999971] [G loss: 1.000057]\n",
      "epoch:5 step:20335[D loss: 0.999963] [G loss: 1.000066]\n",
      "epoch:5 step:20340[D loss: 0.999973] [G loss: 1.000064]\n",
      "epoch:5 step:20345[D loss: 0.999971] [G loss: 1.000069]\n",
      "epoch:5 step:20350[D loss: 0.999970] [G loss: 1.000058]\n",
      "epoch:5 step:20355[D loss: 0.999977] [G loss: 1.000047]\n",
      "epoch:5 step:20360[D loss: 0.999970] [G loss: 1.000063]\n",
      "epoch:5 step:20365[D loss: 0.999972] [G loss: 1.000062]\n",
      "epoch:5 step:20370[D loss: 0.999976] [G loss: 1.000057]\n",
      "epoch:5 step:20375[D loss: 0.999975] [G loss: 1.000053]\n",
      "epoch:5 step:20380[D loss: 0.999980] [G loss: 1.000049]\n",
      "epoch:5 step:20385[D loss: 0.999980] [G loss: 1.000056]\n",
      "epoch:5 step:20390[D loss: 0.999973] [G loss: 1.000059]\n",
      "epoch:5 step:20395[D loss: 0.999973] [G loss: 1.000058]\n",
      "epoch:5 step:20400[D loss: 0.999971] [G loss: 1.000058]\n",
      "##############\n",
      "[0.88427888 0.84682526 0.81728024 0.84081375 0.78917342 0.85842899\n",
      " 0.86824581 0.85845024 0.81955398 0.83005734]\n",
      "##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:5 step:20405[D loss: 0.999972] [G loss: 1.000056]\n",
      "epoch:5 step:20410[D loss: 0.999969] [G loss: 1.000061]\n",
      "epoch:5 step:20415[D loss: 0.999969] [G loss: 1.000056]\n",
      "epoch:5 step:20420[D loss: 0.999977] [G loss: 1.000063]\n",
      "epoch:5 step:20425[D loss: 0.999978] [G loss: 1.000059]\n",
      "epoch:5 step:20430[D loss: 0.999971] [G loss: 1.000064]\n",
      "epoch:5 step:20435[D loss: 0.999975] [G loss: 1.000055]\n",
      "epoch:5 step:20440[D loss: 0.999980] [G loss: 1.000078]\n",
      "epoch:5 step:20445[D loss: 0.999971] [G loss: 1.000073]\n",
      "epoch:5 step:20450[D loss: 0.999972] [G loss: 1.000061]\n",
      "epoch:5 step:20455[D loss: 0.999992] [G loss: 1.000023]\n",
      "epoch:5 step:20460[D loss: 0.999969] [G loss: 1.000059]\n",
      "epoch:5 step:20465[D loss: 0.999972] [G loss: 1.000076]\n",
      "epoch:5 step:20470[D loss: 0.999961] [G loss: 1.000060]\n",
      "epoch:5 step:20475[D loss: 0.999963] [G loss: 1.000073]\n",
      "epoch:5 step:20480[D loss: 0.999985] [G loss: 1.000053]\n",
      "epoch:5 step:20485[D loss: 0.999972] [G loss: 1.000077]\n",
      "epoch:5 step:20490[D loss: 0.999975] [G loss: 1.000065]\n",
      "epoch:5 step:20495[D loss: 0.999975] [G loss: 1.000051]\n",
      "epoch:5 step:20500[D loss: 0.999976] [G loss: 1.000060]\n",
      "epoch:5 step:20505[D loss: 0.999970] [G loss: 1.000074]\n",
      "epoch:5 step:20510[D loss: 0.999985] [G loss: 1.000033]\n",
      "epoch:5 step:20515[D loss: 0.999986] [G loss: 1.000046]\n",
      "epoch:5 step:20520[D loss: 0.999979] [G loss: 1.000055]\n",
      "epoch:5 step:20525[D loss: 0.999961] [G loss: 1.000075]\n",
      "epoch:5 step:20530[D loss: 0.999974] [G loss: 1.000068]\n",
      "epoch:5 step:20535[D loss: 0.999974] [G loss: 1.000058]\n",
      "epoch:5 step:20540[D loss: 0.999972] [G loss: 1.000067]\n",
      "epoch:5 step:20545[D loss: 0.999983] [G loss: 1.000042]\n",
      "epoch:5 step:20550[D loss: 0.999982] [G loss: 1.000106]\n",
      "epoch:5 step:20555[D loss: 0.999957] [G loss: 1.000078]\n",
      "epoch:5 step:20560[D loss: 0.999965] [G loss: 1.000071]\n",
      "epoch:5 step:20565[D loss: 0.999982] [G loss: 1.000045]\n",
      "epoch:5 step:20570[D loss: 0.999978] [G loss: 1.000047]\n",
      "epoch:5 step:20575[D loss: 0.999970] [G loss: 1.000065]\n",
      "epoch:5 step:20580[D loss: 0.999972] [G loss: 1.000057]\n",
      "epoch:5 step:20585[D loss: 0.999971] [G loss: 1.000053]\n",
      "epoch:5 step:20590[D loss: 0.999967] [G loss: 1.000059]\n",
      "epoch:5 step:20595[D loss: 0.999971] [G loss: 1.000067]\n",
      "epoch:5 step:20600[D loss: 0.999975] [G loss: 1.000065]\n",
      "##############\n",
      "[0.86013603 0.85564156 0.8158024  0.83145851 0.7839135  0.84542565\n",
      " 0.88180873 0.83950221 0.81763494 0.84395233]\n",
      "##########\n",
      "epoch:5 step:20605[D loss: 0.999970] [G loss: 1.000055]\n",
      "epoch:5 step:20610[D loss: 0.999969] [G loss: 1.000063]\n",
      "epoch:5 step:20615[D loss: 0.999976] [G loss: 1.000060]\n",
      "epoch:5 step:20620[D loss: 0.999966] [G loss: 1.000054]\n",
      "epoch:5 step:20625[D loss: 0.999971] [G loss: 1.000051]\n",
      "epoch:5 step:20630[D loss: 0.999960] [G loss: 1.000065]\n",
      "epoch:5 step:20635[D loss: 0.999975] [G loss: 1.000050]\n",
      "epoch:5 step:20640[D loss: 0.999973] [G loss: 1.000052]\n",
      "epoch:5 step:20645[D loss: 0.999971] [G loss: 1.000053]\n",
      "epoch:5 step:20650[D loss: 0.999972] [G loss: 1.000060]\n",
      "epoch:5 step:20655[D loss: 0.999989] [G loss: 1.000027]\n",
      "epoch:5 step:20660[D loss: 0.999970] [G loss: 1.000058]\n",
      "epoch:5 step:20665[D loss: 0.999975] [G loss: 1.000049]\n",
      "epoch:5 step:20670[D loss: 0.999969] [G loss: 1.000061]\n",
      "epoch:5 step:20675[D loss: 0.999972] [G loss: 1.000065]\n",
      "epoch:5 step:20680[D loss: 0.999972] [G loss: 1.000058]\n",
      "epoch:5 step:20685[D loss: 0.999967] [G loss: 1.000073]\n",
      "epoch:5 step:20690[D loss: 0.999965] [G loss: 1.000051]\n",
      "epoch:5 step:20695[D loss: 0.999975] [G loss: 1.000037]\n",
      "epoch:5 step:20700[D loss: 0.999969] [G loss: 1.000060]\n",
      "epoch:5 step:20705[D loss: 0.999975] [G loss: 1.000061]\n",
      "epoch:5 step:20710[D loss: 0.999973] [G loss: 1.000066]\n",
      "epoch:5 step:20715[D loss: 0.999969] [G loss: 1.000060]\n",
      "epoch:5 step:20720[D loss: 0.999973] [G loss: 1.000065]\n",
      "epoch:5 step:20725[D loss: 0.999974] [G loss: 1.000058]\n",
      "epoch:5 step:20730[D loss: 0.999983] [G loss: 1.000047]\n",
      "epoch:5 step:20735[D loss: 0.999968] [G loss: 1.000055]\n",
      "epoch:5 step:20740[D loss: 0.999976] [G loss: 1.000058]\n",
      "epoch:5 step:20745[D loss: 0.999977] [G loss: 1.000048]\n",
      "epoch:5 step:20750[D loss: 0.999969] [G loss: 1.000071]\n",
      "epoch:5 step:20755[D loss: 0.999975] [G loss: 1.000059]\n",
      "epoch:5 step:20760[D loss: 0.999980] [G loss: 1.000033]\n",
      "epoch:5 step:20765[D loss: 0.999971] [G loss: 1.000068]\n",
      "epoch:5 step:20770[D loss: 0.999972] [G loss: 1.000066]\n",
      "epoch:5 step:20775[D loss: 0.999969] [G loss: 1.000063]\n",
      "epoch:5 step:20780[D loss: 0.999981] [G loss: 1.000069]\n",
      "epoch:5 step:20785[D loss: 0.999975] [G loss: 1.000041]\n",
      "epoch:5 step:20790[D loss: 0.999949] [G loss: 1.000092]\n",
      "epoch:5 step:20795[D loss: 0.999963] [G loss: 1.000085]\n",
      "epoch:5 step:20800[D loss: 0.999970] [G loss: 1.000073]\n",
      "##############\n",
      "[0.8586528  0.85575084 0.82636829 0.84658454 0.78946058 0.84820778\n",
      " 0.86957867 0.85327139 0.80355488 0.83241892]\n",
      "##########\n",
      "epoch:5 step:20805[D loss: 0.999973] [G loss: 1.000062]\n",
      "epoch:5 step:20810[D loss: 0.999971] [G loss: 1.000066]\n",
      "epoch:5 step:20815[D loss: 0.999984] [G loss: 1.000049]\n",
      "epoch:5 step:20820[D loss: 0.999971] [G loss: 1.000075]\n",
      "epoch:5 step:20825[D loss: 0.999975] [G loss: 1.000067]\n",
      "epoch:5 step:20830[D loss: 0.999964] [G loss: 1.000066]\n",
      "epoch:5 step:20835[D loss: 0.999992] [G loss: 0.999995]\n",
      "epoch:5 step:20840[D loss: 0.999963] [G loss: 1.000082]\n",
      "epoch:5 step:20845[D loss: 0.999962] [G loss: 1.000071]\n",
      "epoch:5 step:20850[D loss: 0.999973] [G loss: 1.000067]\n",
      "epoch:5 step:20855[D loss: 0.999971] [G loss: 1.000063]\n",
      "epoch:5 step:20860[D loss: 0.999974] [G loss: 1.000063]\n",
      "epoch:5 step:20865[D loss: 0.999976] [G loss: 1.000048]\n",
      "epoch:5 step:20870[D loss: 0.999984] [G loss: 1.000051]\n",
      "epoch:5 step:20875[D loss: 0.999978] [G loss: 1.000068]\n",
      "epoch:5 step:20880[D loss: 0.999974] [G loss: 1.000039]\n",
      "epoch:5 step:20885[D loss: 0.999971] [G loss: 1.000075]\n",
      "epoch:5 step:20890[D loss: 0.999976] [G loss: 1.000077]\n",
      "epoch:5 step:20895[D loss: 0.999972] [G loss: 1.000056]\n",
      "epoch:5 step:20900[D loss: 0.999975] [G loss: 1.000057]\n",
      "epoch:5 step:20905[D loss: 0.999980] [G loss: 1.000067]\n",
      "epoch:5 step:20910[D loss: 0.999973] [G loss: 1.000066]\n",
      "epoch:5 step:20915[D loss: 0.999976] [G loss: 1.000054]\n",
      "epoch:5 step:20920[D loss: 0.999970] [G loss: 1.000048]\n",
      "epoch:5 step:20925[D loss: 0.999974] [G loss: 1.000059]\n",
      "epoch:5 step:20930[D loss: 0.999974] [G loss: 1.000067]\n",
      "epoch:5 step:20935[D loss: 0.999998] [G loss: 1.000040]\n",
      "epoch:5 step:20940[D loss: 0.999973] [G loss: 1.000050]\n",
      "epoch:5 step:20945[D loss: 0.999974] [G loss: 1.000061]\n",
      "epoch:5 step:20950[D loss: 0.999976] [G loss: 1.000061]\n",
      "epoch:5 step:20955[D loss: 0.999979] [G loss: 1.000056]\n",
      "epoch:5 step:20960[D loss: 0.999963] [G loss: 1.000082]\n",
      "epoch:5 step:20965[D loss: 0.999966] [G loss: 1.000065]\n",
      "epoch:5 step:20970[D loss: 0.999979] [G loss: 1.000031]\n",
      "epoch:5 step:20975[D loss: 0.999982] [G loss: 1.000052]\n",
      "epoch:5 step:20980[D loss: 0.999978] [G loss: 1.000058]\n",
      "epoch:5 step:20985[D loss: 0.999980] [G loss: 1.000052]\n",
      "epoch:5 step:20990[D loss: 0.999965] [G loss: 1.000085]\n",
      "epoch:5 step:20995[D loss: 0.999976] [G loss: 1.000072]\n",
      "epoch:5 step:21000[D loss: 0.999968] [G loss: 1.000072]\n",
      "##############\n",
      "[0.86039427 0.86822745 0.82628949 0.79776845 0.82858849 0.84756108\n",
      " 0.88830278 0.83645438 0.80675081 0.84823583]\n",
      "##########\n",
      "epoch:5 step:21005[D loss: 0.999971] [G loss: 1.000061]\n",
      "epoch:5 step:21010[D loss: 0.999976] [G loss: 1.000057]\n",
      "epoch:5 step:21015[D loss: 0.999977] [G loss: 1.000050]\n",
      "epoch:5 step:21020[D loss: 0.999978] [G loss: 1.000046]\n",
      "epoch:5 step:21025[D loss: 0.999975] [G loss: 1.000070]\n",
      "epoch:5 step:21030[D loss: 0.999972] [G loss: 1.000072]\n",
      "epoch:5 step:21035[D loss: 0.999978] [G loss: 1.000071]\n",
      "epoch:5 step:21040[D loss: 0.999978] [G loss: 1.000069]\n",
      "epoch:5 step:21045[D loss: 0.999971] [G loss: 1.000074]\n",
      "epoch:5 step:21050[D loss: 0.999961] [G loss: 1.000065]\n",
      "epoch:5 step:21055[D loss: 0.999983] [G loss: 1.000061]\n",
      "epoch:5 step:21060[D loss: 0.999971] [G loss: 1.000063]\n",
      "epoch:5 step:21065[D loss: 0.999966] [G loss: 1.000059]\n",
      "epoch:5 step:21070[D loss: 0.999970] [G loss: 1.000064]\n",
      "epoch:5 step:21075[D loss: 0.999977] [G loss: 1.000057]\n",
      "epoch:5 step:21080[D loss: 0.999979] [G loss: 1.000075]\n",
      "epoch:5 step:21085[D loss: 0.999976] [G loss: 1.000063]\n",
      "epoch:5 step:21090[D loss: 0.999970] [G loss: 1.000061]\n",
      "epoch:5 step:21095[D loss: 0.999968] [G loss: 1.000066]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:5 step:21100[D loss: 0.999975] [G loss: 1.000059]\n",
      "epoch:5 step:21105[D loss: 0.999968] [G loss: 1.000058]\n",
      "epoch:5 step:21110[D loss: 0.999969] [G loss: 1.000059]\n",
      "epoch:5 step:21115[D loss: 0.999976] [G loss: 1.000046]\n",
      "epoch:5 step:21120[D loss: 0.999975] [G loss: 1.000052]\n",
      "epoch:5 step:21125[D loss: 0.999967] [G loss: 1.000067]\n",
      "epoch:5 step:21130[D loss: 0.999965] [G loss: 1.000077]\n",
      "epoch:5 step:21135[D loss: 1.000000] [G loss: 1.000051]\n",
      "epoch:5 step:21140[D loss: 1.000022] [G loss: 0.999995]\n",
      "epoch:5 step:21145[D loss: 0.999953] [G loss: 1.000071]\n",
      "epoch:5 step:21150[D loss: 0.999967] [G loss: 1.000063]\n",
      "epoch:5 step:21155[D loss: 0.999984] [G loss: 1.000043]\n",
      "epoch:5 step:21160[D loss: 0.999985] [G loss: 1.000022]\n",
      "epoch:5 step:21165[D loss: 0.999980] [G loss: 1.000060]\n",
      "epoch:5 step:21170[D loss: 0.999964] [G loss: 1.000065]\n",
      "epoch:5 step:21175[D loss: 0.999972] [G loss: 1.000065]\n",
      "epoch:5 step:21180[D loss: 0.999980] [G loss: 1.000059]\n",
      "epoch:5 step:21185[D loss: 0.999974] [G loss: 1.000061]\n",
      "epoch:5 step:21190[D loss: 0.999987] [G loss: 1.000059]\n",
      "epoch:5 step:21195[D loss: 0.999974] [G loss: 1.000071]\n",
      "epoch:5 step:21200[D loss: 0.999982] [G loss: 1.000035]\n",
      "##############\n",
      "[0.86749324 0.85397194 0.82652475 0.81438222 0.79984685 0.83935309\n",
      " 0.85291883 0.828661   0.83198686 0.83558735]\n",
      "##########\n",
      "epoch:5 step:21205[D loss: 1.000021] [G loss: 0.999966]\n",
      "epoch:5 step:21210[D loss: 0.999988] [G loss: 1.000088]\n",
      "epoch:5 step:21215[D loss: 0.999957] [G loss: 1.000077]\n",
      "epoch:5 step:21220[D loss: 0.999962] [G loss: 1.000073]\n",
      "epoch:5 step:21225[D loss: 0.999971] [G loss: 1.000057]\n",
      "epoch:5 step:21230[D loss: 0.999973] [G loss: 1.000054]\n",
      "epoch:5 step:21235[D loss: 0.999970] [G loss: 1.000068]\n",
      "epoch:5 step:21240[D loss: 0.999967] [G loss: 1.000064]\n",
      "epoch:5 step:21245[D loss: 0.999982] [G loss: 1.000066]\n",
      "epoch:5 step:21250[D loss: 0.999976] [G loss: 1.000055]\n",
      "epoch:5 step:21255[D loss: 0.999972] [G loss: 1.000077]\n",
      "epoch:5 step:21260[D loss: 0.999964] [G loss: 1.000059]\n",
      "epoch:5 step:21265[D loss: 0.999973] [G loss: 1.000061]\n",
      "epoch:5 step:21270[D loss: 0.999979] [G loss: 1.000057]\n",
      "epoch:5 step:21275[D loss: 0.999972] [G loss: 1.000071]\n",
      "epoch:5 step:21280[D loss: 0.999960] [G loss: 1.000070]\n",
      "epoch:5 step:21285[D loss: 0.999966] [G loss: 1.000053]\n",
      "epoch:5 step:21290[D loss: 0.999971] [G loss: 1.000073]\n",
      "epoch:5 step:21295[D loss: 0.999978] [G loss: 1.000061]\n",
      "epoch:5 step:21300[D loss: 0.999975] [G loss: 1.000058]\n",
      "epoch:5 step:21305[D loss: 0.999968] [G loss: 1.000057]\n",
      "epoch:5 step:21310[D loss: 0.999969] [G loss: 1.000051]\n",
      "epoch:5 step:21315[D loss: 0.999973] [G loss: 1.000062]\n",
      "epoch:5 step:21320[D loss: 0.999969] [G loss: 1.000046]\n",
      "epoch:5 step:21325[D loss: 0.999975] [G loss: 1.000038]\n",
      "epoch:5 step:21330[D loss: 0.999969] [G loss: 1.000055]\n",
      "epoch:5 step:21335[D loss: 0.999971] [G loss: 1.000051]\n",
      "epoch:5 step:21340[D loss: 0.999970] [G loss: 1.000052]\n",
      "epoch:5 step:21345[D loss: 0.999973] [G loss: 1.000038]\n",
      "epoch:5 step:21350[D loss: 0.999968] [G loss: 1.000049]\n",
      "epoch:5 step:21355[D loss: 0.999989] [G loss: 1.000012]\n",
      "epoch:5 step:21360[D loss: 0.999988] [G loss: 1.000061]\n",
      "epoch:5 step:21365[D loss: 0.999963] [G loss: 1.000068]\n",
      "epoch:5 step:21370[D loss: 0.999976] [G loss: 1.000049]\n",
      "epoch:5 step:21375[D loss: 1.000006] [G loss: 1.000015]\n",
      "epoch:5 step:21380[D loss: 0.999965] [G loss: 1.000062]\n",
      "epoch:5 step:21385[D loss: 0.999967] [G loss: 1.000077]\n",
      "epoch:5 step:21390[D loss: 0.999968] [G loss: 1.000096]\n",
      "epoch:5 step:21395[D loss: 0.999966] [G loss: 1.000074]\n",
      "epoch:5 step:21400[D loss: 0.999974] [G loss: 1.000058]\n",
      "##############\n",
      "[0.86259004 0.86517035 0.83383323 0.83058062 0.80855826 0.84451446\n",
      " 0.83360367 0.83489584 0.8255617  0.84026194]\n",
      "##########\n",
      "epoch:5 step:21405[D loss: 0.999989] [G loss: 1.000049]\n",
      "epoch:5 step:21410[D loss: 1.000008] [G loss: 0.999991]\n",
      "epoch:5 step:21415[D loss: 0.999954] [G loss: 1.000088]\n",
      "epoch:5 step:21420[D loss: 0.999969] [G loss: 1.000084]\n",
      "epoch:5 step:21425[D loss: 0.999968] [G loss: 1.000071]\n",
      "epoch:5 step:21430[D loss: 0.999968] [G loss: 1.000066]\n",
      "epoch:5 step:21435[D loss: 0.999969] [G loss: 1.000068]\n",
      "epoch:5 step:21440[D loss: 0.999988] [G loss: 1.000042]\n",
      "epoch:5 step:21445[D loss: 0.999973] [G loss: 1.000052]\n",
      "epoch:5 step:21450[D loss: 0.999970] [G loss: 1.000067]\n",
      "epoch:5 step:21455[D loss: 0.999968] [G loss: 1.000079]\n",
      "epoch:5 step:21460[D loss: 0.999972] [G loss: 1.000062]\n",
      "epoch:5 step:21465[D loss: 0.999968] [G loss: 1.000063]\n",
      "epoch:5 step:21470[D loss: 0.999981] [G loss: 1.000046]\n",
      "epoch:5 step:21475[D loss: 0.999961] [G loss: 1.000065]\n",
      "epoch:5 step:21480[D loss: 0.999970] [G loss: 1.000064]\n",
      "epoch:5 step:21485[D loss: 0.999982] [G loss: 1.000054]\n",
      "epoch:5 step:21490[D loss: 0.999962] [G loss: 1.000065]\n",
      "epoch:5 step:21495[D loss: 0.999996] [G loss: 1.000022]\n",
      "epoch:5 step:21500[D loss: 0.999978] [G loss: 1.000042]\n",
      "epoch:5 step:21505[D loss: 0.999975] [G loss: 1.000041]\n",
      "epoch:5 step:21510[D loss: 0.999975] [G loss: 1.000049]\n",
      "epoch:5 step:21515[D loss: 0.999965] [G loss: 1.000068]\n",
      "epoch:5 step:21520[D loss: 0.999967] [G loss: 1.000076]\n",
      "epoch:5 step:21525[D loss: 0.999965] [G loss: 1.000073]\n",
      "epoch:5 step:21530[D loss: 0.999974] [G loss: 1.000071]\n",
      "epoch:5 step:21535[D loss: 0.999971] [G loss: 1.000052]\n",
      "epoch:5 step:21540[D loss: 0.999968] [G loss: 1.000064]\n",
      "epoch:5 step:21545[D loss: 0.999976] [G loss: 1.000061]\n",
      "epoch:5 step:21550[D loss: 0.999979] [G loss: 1.000062]\n",
      "epoch:5 step:21555[D loss: 0.999971] [G loss: 1.000055]\n",
      "epoch:5 step:21560[D loss: 0.999977] [G loss: 1.000065]\n",
      "epoch:5 step:21565[D loss: 0.999972] [G loss: 1.000065]\n",
      "epoch:5 step:21570[D loss: 0.999972] [G loss: 1.000059]\n",
      "epoch:5 step:21575[D loss: 0.999969] [G loss: 1.000086]\n",
      "epoch:5 step:21580[D loss: 0.999973] [G loss: 1.000068]\n",
      "epoch:5 step:21585[D loss: 0.999966] [G loss: 1.000067]\n",
      "epoch:5 step:21590[D loss: 0.999979] [G loss: 1.000051]\n",
      "epoch:5 step:21595[D loss: 0.999992] [G loss: 1.000012]\n",
      "epoch:5 step:21600[D loss: 0.999963] [G loss: 1.000074]\n",
      "##############\n",
      "[0.86193184 0.88302956 0.8453662  0.82379122 0.78942982 0.82855998\n",
      " 0.8686021  0.82347005 0.81242549 0.84103508]\n",
      "##########\n",
      "epoch:5 step:21605[D loss: 0.999971] [G loss: 1.000073]\n",
      "epoch:5 step:21610[D loss: 0.999981] [G loss: 1.000050]\n",
      "epoch:5 step:21615[D loss: 0.999972] [G loss: 1.000076]\n",
      "epoch:5 step:21620[D loss: 0.999967] [G loss: 1.000064]\n",
      "epoch:5 step:21625[D loss: 0.999986] [G loss: 1.000070]\n",
      "epoch:5 step:21630[D loss: 0.999982] [G loss: 1.000057]\n",
      "epoch:5 step:21635[D loss: 0.999964] [G loss: 1.000070]\n",
      "epoch:5 step:21640[D loss: 0.999972] [G loss: 1.000060]\n",
      "epoch:5 step:21645[D loss: 0.999970] [G loss: 1.000066]\n",
      "epoch:5 step:21650[D loss: 0.999969] [G loss: 1.000058]\n",
      "epoch:5 step:21655[D loss: 0.999981] [G loss: 1.000051]\n",
      "epoch:5 step:21660[D loss: 0.999972] [G loss: 1.000069]\n",
      "epoch:5 step:21665[D loss: 0.999970] [G loss: 1.000067]\n",
      "epoch:5 step:21670[D loss: 0.999969] [G loss: 1.000074]\n",
      "epoch:5 step:21675[D loss: 0.999981] [G loss: 1.000052]\n",
      "epoch:5 step:21680[D loss: 0.999972] [G loss: 1.000065]\n",
      "epoch:5 step:21685[D loss: 0.999980] [G loss: 1.000061]\n",
      "epoch:5 step:21690[D loss: 0.999963] [G loss: 1.000084]\n",
      "epoch:5 step:21695[D loss: 0.999970] [G loss: 1.000073]\n",
      "epoch:5 step:21700[D loss: 0.999975] [G loss: 1.000065]\n",
      "epoch:5 step:21705[D loss: 0.999977] [G loss: 1.000053]\n",
      "epoch:5 step:21710[D loss: 0.999997] [G loss: 1.000005]\n",
      "epoch:5 step:21715[D loss: 0.999972] [G loss: 1.000088]\n",
      "epoch:5 step:21720[D loss: 0.999954] [G loss: 1.000102]\n",
      "epoch:5 step:21725[D loss: 0.999967] [G loss: 1.000077]\n",
      "epoch:5 step:21730[D loss: 0.999965] [G loss: 1.000066]\n",
      "epoch:5 step:21735[D loss: 0.999982] [G loss: 1.000053]\n",
      "epoch:5 step:21740[D loss: 0.999990] [G loss: 1.000028]\n",
      "epoch:5 step:21745[D loss: 0.999972] [G loss: 1.000054]\n",
      "epoch:5 step:21750[D loss: 0.999983] [G loss: 1.000048]\n",
      "epoch:5 step:21755[D loss: 0.999952] [G loss: 1.000075]\n",
      "epoch:5 step:21760[D loss: 0.999966] [G loss: 1.000071]\n",
      "epoch:5 step:21765[D loss: 0.999974] [G loss: 1.000057]\n",
      "epoch:5 step:21770[D loss: 0.999997] [G loss: 0.999999]\n",
      "epoch:5 step:21775[D loss: 0.999974] [G loss: 1.000052]\n",
      "epoch:5 step:21780[D loss: 0.999999] [G loss: 1.000006]\n",
      "epoch:5 step:21785[D loss: 0.999955] [G loss: 1.000088]\n",
      "epoch:5 step:21790[D loss: 0.999973] [G loss: 1.000072]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:5 step:21795[D loss: 0.999973] [G loss: 1.000063]\n",
      "epoch:5 step:21800[D loss: 0.999981] [G loss: 1.000035]\n",
      "##############\n",
      "[0.88107707 0.85195231 0.82807277 0.8330176  0.79068463 0.8272284\n",
      " 0.88579448 0.84645052 0.8059006  0.85070409]\n",
      "##########\n",
      "epoch:5 step:21805[D loss: 0.999965] [G loss: 1.000065]\n",
      "epoch:5 step:21810[D loss: 1.000005] [G loss: 1.000007]\n",
      "epoch:5 step:21815[D loss: 0.999970] [G loss: 1.000059]\n",
      "epoch:5 step:21820[D loss: 0.999976] [G loss: 1.000062]\n",
      "epoch:5 step:21825[D loss: 0.999974] [G loss: 1.000050]\n",
      "epoch:5 step:21830[D loss: 0.999983] [G loss: 1.000042]\n",
      "epoch:5 step:21835[D loss: 0.999983] [G loss: 1.000059]\n",
      "epoch:5 step:21840[D loss: 0.999966] [G loss: 1.000068]\n",
      "epoch:5 step:21845[D loss: 0.999954] [G loss: 1.000082]\n",
      "epoch:5 step:21850[D loss: 0.999974] [G loss: 1.000058]\n",
      "epoch:5 step:21855[D loss: 0.999971] [G loss: 1.000067]\n",
      "epoch:5 step:21860[D loss: 0.999968] [G loss: 1.000065]\n",
      "epoch:5 step:21865[D loss: 0.999976] [G loss: 1.000071]\n",
      "epoch:5 step:21870[D loss: 0.999994] [G loss: 1.000044]\n",
      "epoch:5 step:21875[D loss: 0.999972] [G loss: 1.000064]\n",
      "epoch:5 step:21880[D loss: 0.999971] [G loss: 1.000068]\n",
      "epoch:5 step:21885[D loss: 0.999973] [G loss: 1.000067]\n",
      "epoch:5 step:21890[D loss: 0.999976] [G loss: 1.000055]\n",
      "epoch:5 step:21895[D loss: 0.999987] [G loss: 1.000046]\n",
      "epoch:5 step:21900[D loss: 0.999957] [G loss: 1.000074]\n",
      "epoch:5 step:21905[D loss: 0.999975] [G loss: 1.000055]\n",
      "epoch:5 step:21910[D loss: 0.999969] [G loss: 1.000068]\n",
      "epoch:5 step:21915[D loss: 0.999964] [G loss: 1.000079]\n",
      "epoch:5 step:21920[D loss: 0.999975] [G loss: 1.000054]\n",
      "epoch:5 step:21925[D loss: 0.999969] [G loss: 1.000072]\n",
      "epoch:5 step:21930[D loss: 0.999972] [G loss: 1.000058]\n",
      "epoch:5 step:21935[D loss: 0.999970] [G loss: 1.000069]\n",
      "epoch:5 step:21940[D loss: 0.999970] [G loss: 1.000064]\n",
      "epoch:5 step:21945[D loss: 0.999979] [G loss: 1.000035]\n",
      "epoch:5 step:21950[D loss: 0.999979] [G loss: 1.000058]\n",
      "epoch:5 step:21955[D loss: 0.999969] [G loss: 1.000058]\n",
      "epoch:5 step:21960[D loss: 0.999976] [G loss: 1.000042]\n",
      "epoch:5 step:21965[D loss: 0.999977] [G loss: 1.000060]\n",
      "epoch:5 step:21970[D loss: 0.999970] [G loss: 1.000063]\n",
      "epoch:5 step:21975[D loss: 0.999974] [G loss: 1.000052]\n",
      "epoch:5 step:21980[D loss: 0.999969] [G loss: 1.000059]\n",
      "epoch:5 step:21985[D loss: 0.999971] [G loss: 1.000058]\n",
      "epoch:5 step:21990[D loss: 0.999970] [G loss: 1.000066]\n",
      "epoch:5 step:21995[D loss: 0.999962] [G loss: 1.000070]\n",
      "epoch:5 step:22000[D loss: 0.999973] [G loss: 1.000058]\n",
      "##############\n",
      "[0.86367319 0.88335225 0.81223034 0.83861022 0.81141817 0.8372061\n",
      " 0.8648921  0.84084455 0.81033579 0.82164486]\n",
      "##########\n",
      "epoch:5 step:22005[D loss: 0.999974] [G loss: 1.000058]\n",
      "epoch:5 step:22010[D loss: 0.999980] [G loss: 1.000041]\n",
      "epoch:5 step:22015[D loss: 0.999970] [G loss: 1.000060]\n",
      "epoch:5 step:22020[D loss: 0.999963] [G loss: 1.000063]\n",
      "epoch:5 step:22025[D loss: 0.999970] [G loss: 1.000069]\n",
      "epoch:5 step:22030[D loss: 0.999971] [G loss: 1.000068]\n",
      "epoch:5 step:22035[D loss: 0.999971] [G loss: 1.000072]\n",
      "epoch:5 step:22040[D loss: 0.999970] [G loss: 1.000067]\n",
      "epoch:5 step:22045[D loss: 0.999968] [G loss: 1.000068]\n",
      "epoch:5 step:22050[D loss: 0.999975] [G loss: 1.000056]\n",
      "epoch:5 step:22055[D loss: 0.999974] [G loss: 1.000053]\n",
      "epoch:5 step:22060[D loss: 0.999965] [G loss: 1.000067]\n",
      "epoch:5 step:22065[D loss: 0.999975] [G loss: 1.000055]\n",
      "epoch:5 step:22070[D loss: 0.999981] [G loss: 1.000038]\n",
      "epoch:5 step:22075[D loss: 0.999986] [G loss: 1.000032]\n",
      "epoch:5 step:22080[D loss: 0.999976] [G loss: 1.000078]\n",
      "epoch:5 step:22085[D loss: 0.999975] [G loss: 1.000074]\n",
      "epoch:5 step:22090[D loss: 0.999963] [G loss: 1.000079]\n",
      "epoch:5 step:22095[D loss: 0.999980] [G loss: 1.000041]\n",
      "epoch:5 step:22100[D loss: 0.999971] [G loss: 1.000054]\n",
      "epoch:5 step:22105[D loss: 0.999978] [G loss: 1.000064]\n",
      "epoch:5 step:22110[D loss: 0.999976] [G loss: 1.000048]\n",
      "epoch:5 step:22115[D loss: 0.999977] [G loss: 1.000072]\n",
      "epoch:5 step:22120[D loss: 0.999981] [G loss: 1.000061]\n",
      "epoch:5 step:22125[D loss: 0.999978] [G loss: 1.000054]\n",
      "epoch:5 step:22130[D loss: 0.999971] [G loss: 1.000067]\n",
      "epoch:5 step:22135[D loss: 0.999970] [G loss: 1.000063]\n",
      "epoch:5 step:22140[D loss: 0.999983] [G loss: 1.000057]\n",
      "epoch:5 step:22145[D loss: 0.999967] [G loss: 1.000070]\n",
      "epoch:5 step:22150[D loss: 0.999968] [G loss: 1.000077]\n",
      "epoch:5 step:22155[D loss: 0.999972] [G loss: 1.000066]\n",
      "epoch:5 step:22160[D loss: 0.999977] [G loss: 1.000058]\n",
      "epoch:5 step:22165[D loss: 0.999967] [G loss: 1.000066]\n",
      "epoch:5 step:22170[D loss: 0.999976] [G loss: 1.000067]\n",
      "epoch:5 step:22175[D loss: 0.999971] [G loss: 1.000078]\n",
      "epoch:5 step:22180[D loss: 0.999975] [G loss: 1.000070]\n",
      "epoch:5 step:22185[D loss: 0.999971] [G loss: 1.000069]\n",
      "epoch:5 step:22190[D loss: 0.999975] [G loss: 1.000076]\n",
      "epoch:5 step:22195[D loss: 0.999975] [G loss: 1.000065]\n",
      "epoch:5 step:22200[D loss: 0.999980] [G loss: 1.000042]\n",
      "##############\n",
      "[0.85720179 0.86296523 0.82323315 0.83326967 0.80347039 0.8297485\n",
      " 0.87125025 0.83760242 0.82811659 0.83771913]\n",
      "##########\n",
      "epoch:5 step:22205[D loss: 0.999970] [G loss: 1.000072]\n",
      "epoch:5 step:22210[D loss: 0.999970] [G loss: 1.000072]\n",
      "epoch:5 step:22215[D loss: 0.999972] [G loss: 1.000064]\n",
      "epoch:5 step:22220[D loss: 0.999970] [G loss: 1.000074]\n",
      "epoch:5 step:22225[D loss: 0.999990] [G loss: 1.000045]\n",
      "epoch:5 step:22230[D loss: 0.999989] [G loss: 1.000027]\n",
      "epoch:5 step:22235[D loss: 0.999959] [G loss: 1.000089]\n",
      "epoch:5 step:22240[D loss: 0.999973] [G loss: 1.000061]\n",
      "epoch:5 step:22245[D loss: 0.999982] [G loss: 1.000017]\n",
      "epoch:5 step:22250[D loss: 0.999986] [G loss: 1.000021]\n",
      "epoch:5 step:22255[D loss: 0.999997] [G loss: 1.000031]\n",
      "epoch:5 step:22260[D loss: 0.999954] [G loss: 1.000088]\n",
      "epoch:5 step:22265[D loss: 0.999963] [G loss: 1.000078]\n",
      "epoch:5 step:22270[D loss: 0.999970] [G loss: 1.000071]\n",
      "epoch:5 step:22275[D loss: 0.999977] [G loss: 1.000054]\n",
      "epoch:5 step:22280[D loss: 0.999988] [G loss: 1.000057]\n",
      "epoch:5 step:22285[D loss: 0.999956] [G loss: 1.000092]\n",
      "epoch:5 step:22290[D loss: 0.999992] [G loss: 1.000031]\n",
      "epoch:5 step:22295[D loss: 0.999963] [G loss: 1.000087]\n",
      "epoch:5 step:22300[D loss: 0.999974] [G loss: 1.000077]\n",
      "epoch:5 step:22305[D loss: 0.999973] [G loss: 1.000067]\n",
      "epoch:5 step:22310[D loss: 0.999974] [G loss: 1.000064]\n",
      "epoch:5 step:22315[D loss: 0.999965] [G loss: 1.000070]\n",
      "epoch:5 step:22320[D loss: 0.999972] [G loss: 1.000065]\n",
      "epoch:5 step:22325[D loss: 0.999986] [G loss: 1.000036]\n",
      "epoch:5 step:22330[D loss: 0.999988] [G loss: 1.000040]\n",
      "epoch:5 step:22335[D loss: 0.999958] [G loss: 1.000082]\n",
      "epoch:5 step:22340[D loss: 0.999968] [G loss: 1.000073]\n",
      "epoch:5 step:22345[D loss: 0.999969] [G loss: 1.000084]\n",
      "epoch:5 step:22350[D loss: 0.999971] [G loss: 1.000073]\n",
      "epoch:5 step:22355[D loss: 0.999971] [G loss: 1.000073]\n",
      "epoch:5 step:22360[D loss: 0.999978] [G loss: 1.000061]\n",
      "epoch:5 step:22365[D loss: 0.999979] [G loss: 1.000050]\n",
      "epoch:5 step:22370[D loss: 0.999979] [G loss: 1.000053]\n",
      "epoch:5 step:22375[D loss: 0.999975] [G loss: 1.000065]\n",
      "epoch:5 step:22380[D loss: 0.999972] [G loss: 1.000063]\n",
      "epoch:5 step:22385[D loss: 0.999972] [G loss: 1.000060]\n",
      "epoch:5 step:22390[D loss: 0.999970] [G loss: 1.000068]\n",
      "epoch:5 step:22395[D loss: 0.999972] [G loss: 1.000051]\n",
      "epoch:5 step:22400[D loss: 0.999966] [G loss: 1.000071]\n",
      "##############\n",
      "[0.89224909 0.86981276 0.82814978 0.80910752 0.8136304  0.84048581\n",
      " 0.87659462 0.84311161 0.81584606 0.84104842]\n",
      "##########\n",
      "epoch:5 step:22405[D loss: 0.999970] [G loss: 1.000070]\n",
      "epoch:5 step:22410[D loss: 0.999975] [G loss: 1.000059]\n",
      "epoch:5 step:22415[D loss: 0.999970] [G loss: 1.000063]\n",
      "epoch:5 step:22420[D loss: 0.999975] [G loss: 1.000060]\n",
      "epoch:5 step:22425[D loss: 0.999972] [G loss: 1.000071]\n",
      "epoch:5 step:22430[D loss: 0.999974] [G loss: 1.000075]\n",
      "epoch:5 step:22435[D loss: 1.000006] [G loss: 0.999991]\n",
      "epoch:5 step:22440[D loss: 0.999957] [G loss: 1.000065]\n",
      "epoch:5 step:22445[D loss: 0.999951] [G loss: 1.000106]\n",
      "epoch:5 step:22450[D loss: 0.999969] [G loss: 1.000078]\n",
      "epoch:5 step:22455[D loss: 0.999972] [G loss: 1.000072]\n",
      "epoch:5 step:22460[D loss: 0.999976] [G loss: 1.000049]\n",
      "epoch:5 step:22465[D loss: 0.999974] [G loss: 1.000051]\n",
      "epoch:5 step:22470[D loss: 0.999980] [G loss: 1.000060]\n",
      "epoch:5 step:22475[D loss: 0.999968] [G loss: 1.000076]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:5 step:22480[D loss: 0.999980] [G loss: 1.000051]\n",
      "epoch:5 step:22485[D loss: 0.999962] [G loss: 1.000079]\n",
      "epoch:5 step:22490[D loss: 0.999972] [G loss: 1.000064]\n",
      "epoch:5 step:22495[D loss: 0.999989] [G loss: 1.000031]\n",
      "epoch:5 step:22500[D loss: 0.999994] [G loss: 1.000050]\n",
      "epoch:5 step:22505[D loss: 0.999974] [G loss: 1.000053]\n",
      "epoch:5 step:22510[D loss: 0.999967] [G loss: 1.000078]\n",
      "epoch:5 step:22515[D loss: 0.999969] [G loss: 1.000048]\n",
      "epoch:5 step:22520[D loss: 1.000004] [G loss: 1.000026]\n",
      "epoch:5 step:22525[D loss: 1.000019] [G loss: 1.000024]\n",
      "epoch:5 step:22530[D loss: 1.000022] [G loss: 1.000040]\n",
      "epoch:5 step:22535[D loss: 0.999933] [G loss: 1.000101]\n",
      "epoch:5 step:22540[D loss: 0.999956] [G loss: 1.000092]\n",
      "epoch:5 step:22545[D loss: 0.999971] [G loss: 1.000074]\n",
      "epoch:5 step:22550[D loss: 0.999972] [G loss: 1.000070]\n",
      "epoch:5 step:22555[D loss: 0.999972] [G loss: 1.000067]\n",
      "epoch:5 step:22560[D loss: 0.999983] [G loss: 1.000027]\n",
      "epoch:5 step:22565[D loss: 0.999993] [G loss: 1.000003]\n",
      "epoch:5 step:22570[D loss: 1.000072] [G loss: 0.999895]\n",
      "epoch:5 step:22575[D loss: 0.999945] [G loss: 1.000117]\n",
      "epoch:5 step:22580[D loss: 0.999948] [G loss: 1.000102]\n",
      "epoch:5 step:22585[D loss: 0.999967] [G loss: 1.000079]\n",
      "epoch:5 step:22590[D loss: 0.999969] [G loss: 1.000075]\n",
      "epoch:5 step:22595[D loss: 0.999978] [G loss: 1.000050]\n",
      "epoch:5 step:22600[D loss: 0.999985] [G loss: 1.000051]\n",
      "##############\n",
      "[0.85680629 0.85964966 0.83189936 0.8133405  0.80722171 0.84323944\n",
      " 0.88150545 0.8411435  0.80715483 0.84052927]\n",
      "##########\n",
      "epoch:5 step:22605[D loss: 1.000005] [G loss: 1.000016]\n",
      "epoch:5 step:22610[D loss: 1.000002] [G loss: 1.000049]\n",
      "epoch:5 step:22615[D loss: 0.999951] [G loss: 1.000077]\n",
      "epoch:5 step:22620[D loss: 0.999968] [G loss: 1.000080]\n",
      "epoch:5 step:22625[D loss: 0.999966] [G loss: 1.000092]\n",
      "epoch:5 step:22630[D loss: 0.999964] [G loss: 1.000090]\n",
      "epoch:5 step:22635[D loss: 0.999969] [G loss: 1.000078]\n",
      "epoch:5 step:22640[D loss: 0.999981] [G loss: 1.000063]\n",
      "epoch:5 step:22645[D loss: 0.999980] [G loss: 1.000049]\n",
      "epoch:5 step:22650[D loss: 0.999977] [G loss: 1.000051]\n",
      "epoch:5 step:22655[D loss: 0.999993] [G loss: 1.000012]\n",
      "epoch:5 step:22660[D loss: 0.999967] [G loss: 1.000068]\n",
      "epoch:5 step:22665[D loss: 0.999960] [G loss: 1.000123]\n",
      "epoch:5 step:22670[D loss: 0.999952] [G loss: 1.000107]\n",
      "epoch:5 step:22675[D loss: 0.999973] [G loss: 1.000073]\n",
      "epoch:5 step:22680[D loss: 0.999981] [G loss: 1.000051]\n",
      "epoch:5 step:22685[D loss: 0.999968] [G loss: 1.000068]\n",
      "epoch:5 step:22690[D loss: 0.999999] [G loss: 1.000050]\n",
      "epoch:5 step:22695[D loss: 0.999960] [G loss: 1.000095]\n",
      "epoch:5 step:22700[D loss: 0.999956] [G loss: 1.000090]\n",
      "epoch:5 step:22705[D loss: 0.999982] [G loss: 1.000058]\n",
      "epoch:5 step:22710[D loss: 0.999969] [G loss: 1.000070]\n",
      "epoch:5 step:22715[D loss: 0.999976] [G loss: 1.000076]\n",
      "epoch:5 step:22720[D loss: 0.999971] [G loss: 1.000070]\n",
      "epoch:5 step:22725[D loss: 0.999973] [G loss: 1.000064]\n",
      "epoch:5 step:22730[D loss: 0.999980] [G loss: 1.000026]\n",
      "epoch:5 step:22735[D loss: 0.999970] [G loss: 1.000049]\n",
      "epoch:5 step:22740[D loss: 0.999970] [G loss: 1.000069]\n",
      "epoch:5 step:22745[D loss: 0.999971] [G loss: 1.000073]\n",
      "epoch:5 step:22750[D loss: 0.999973] [G loss: 1.000066]\n",
      "epoch:5 step:22755[D loss: 0.999985] [G loss: 1.000033]\n",
      "epoch:5 step:22760[D loss: 0.999972] [G loss: 1.000062]\n",
      "epoch:5 step:22765[D loss: 0.999967] [G loss: 1.000071]\n",
      "epoch:5 step:22770[D loss: 0.999972] [G loss: 1.000069]\n",
      "epoch:5 step:22775[D loss: 0.999975] [G loss: 1.000060]\n",
      "epoch:5 step:22780[D loss: 0.999976] [G loss: 1.000052]\n",
      "epoch:5 step:22785[D loss: 0.999984] [G loss: 1.000026]\n",
      "epoch:5 step:22790[D loss: 0.999967] [G loss: 1.000079]\n",
      "epoch:5 step:22795[D loss: 0.999957] [G loss: 1.000075]\n",
      "epoch:5 step:22800[D loss: 0.999983] [G loss: 1.000057]\n",
      "##############\n",
      "[0.87369287 0.86233587 0.83204306 0.83111332 0.81356975 0.82713361\n",
      " 0.87449611 0.84733133 0.82506784 0.82364627]\n",
      "##########\n",
      "epoch:5 step:22805[D loss: 0.999970] [G loss: 1.000061]\n",
      "epoch:5 step:22810[D loss: 0.999993] [G loss: 1.000030]\n",
      "epoch:5 step:22815[D loss: 0.999984] [G loss: 1.000061]\n",
      "epoch:5 step:22820[D loss: 0.999964] [G loss: 1.000091]\n",
      "epoch:5 step:22825[D loss: 0.999966] [G loss: 1.000077]\n",
      "epoch:5 step:22830[D loss: 0.999972] [G loss: 1.000070]\n",
      "epoch:5 step:22835[D loss: 0.999970] [G loss: 1.000067]\n",
      "epoch:5 step:22840[D loss: 0.999975] [G loss: 1.000064]\n",
      "epoch:5 step:22845[D loss: 0.999972] [G loss: 1.000060]\n",
      "epoch:5 step:22850[D loss: 0.999985] [G loss: 1.000046]\n",
      "epoch:5 step:22855[D loss: 0.999963] [G loss: 1.000071]\n",
      "epoch:5 step:22860[D loss: 0.999969] [G loss: 1.000070]\n",
      "epoch:5 step:22865[D loss: 0.999972] [G loss: 1.000069]\n",
      "epoch:5 step:22870[D loss: 0.999975] [G loss: 1.000075]\n",
      "epoch:5 step:22875[D loss: 0.999972] [G loss: 1.000065]\n",
      "epoch:5 step:22880[D loss: 0.999978] [G loss: 1.000087]\n",
      "epoch:5 step:22885[D loss: 0.999964] [G loss: 1.000056]\n",
      "epoch:5 step:22890[D loss: 0.999978] [G loss: 1.000050]\n",
      "epoch:5 step:22895[D loss: 0.999973] [G loss: 1.000050]\n",
      "epoch:5 step:22900[D loss: 0.999973] [G loss: 1.000070]\n",
      "epoch:5 step:22905[D loss: 0.999978] [G loss: 1.000061]\n",
      "epoch:5 step:22910[D loss: 0.999977] [G loss: 1.000073]\n",
      "epoch:5 step:22915[D loss: 0.999980] [G loss: 1.000061]\n",
      "epoch:5 step:22920[D loss: 0.999975] [G loss: 1.000059]\n",
      "epoch:5 step:22925[D loss: 0.999967] [G loss: 1.000061]\n",
      "epoch:5 step:22930[D loss: 0.999977] [G loss: 1.000062]\n",
      "epoch:5 step:22935[D loss: 0.999966] [G loss: 1.000065]\n",
      "epoch:5 step:22940[D loss: 0.999972] [G loss: 1.000066]\n",
      "epoch:5 step:22945[D loss: 0.999964] [G loss: 1.000070]\n",
      "epoch:5 step:22950[D loss: 0.999969] [G loss: 1.000060]\n",
      "epoch:5 step:22955[D loss: 0.999974] [G loss: 1.000065]\n",
      "epoch:5 step:22960[D loss: 0.999982] [G loss: 1.000052]\n",
      "epoch:5 step:22965[D loss: 0.999977] [G loss: 1.000069]\n",
      "epoch:5 step:22970[D loss: 0.999986] [G loss: 1.000042]\n",
      "epoch:5 step:22975[D loss: 0.999961] [G loss: 1.000072]\n",
      "epoch:5 step:22980[D loss: 0.999977] [G loss: 1.000048]\n",
      "epoch:5 step:22985[D loss: 0.999974] [G loss: 1.000057]\n",
      "epoch:5 step:22990[D loss: 0.999980] [G loss: 1.000038]\n",
      "epoch:5 step:22995[D loss: 0.999977] [G loss: 1.000051]\n",
      "epoch:5 step:23000[D loss: 0.999983] [G loss: 1.000064]\n",
      "##############\n",
      "[0.87174309 0.87290569 0.81315498 0.84617524 0.79876635 0.84057566\n",
      " 0.88268462 0.82944445 0.83026879 0.83339918]\n",
      "##########\n",
      "epoch:5 step:23005[D loss: 0.999973] [G loss: 1.000062]\n",
      "epoch:5 step:23010[D loss: 0.999955] [G loss: 1.000088]\n",
      "epoch:5 step:23015[D loss: 0.999977] [G loss: 1.000048]\n",
      "epoch:5 step:23020[D loss: 0.999971] [G loss: 1.000060]\n",
      "epoch:5 step:23025[D loss: 0.999998] [G loss: 1.000030]\n",
      "epoch:5 step:23030[D loss: 0.999977] [G loss: 1.000055]\n",
      "epoch:5 step:23035[D loss: 0.999968] [G loss: 1.000065]\n",
      "epoch:5 step:23040[D loss: 0.999978] [G loss: 1.000050]\n",
      "epoch:5 step:23045[D loss: 0.999962] [G loss: 1.000070]\n",
      "epoch:5 step:23050[D loss: 0.999984] [G loss: 1.000048]\n",
      "epoch:5 step:23055[D loss: 0.999970] [G loss: 1.000060]\n",
      "epoch:5 step:23060[D loss: 0.999972] [G loss: 1.000056]\n",
      "epoch:5 step:23065[D loss: 0.999974] [G loss: 1.000068]\n",
      "epoch:5 step:23070[D loss: 0.999968] [G loss: 1.000070]\n",
      "epoch:5 step:23075[D loss: 0.999970] [G loss: 1.000073]\n",
      "epoch:5 step:23080[D loss: 0.999973] [G loss: 1.000058]\n",
      "epoch:5 step:23085[D loss: 0.999972] [G loss: 1.000065]\n",
      "epoch:5 step:23090[D loss: 0.999978] [G loss: 1.000053]\n",
      "epoch:5 step:23095[D loss: 0.999970] [G loss: 1.000065]\n",
      "epoch:5 step:23100[D loss: 0.999965] [G loss: 1.000072]\n",
      "epoch:5 step:23105[D loss: 0.999975] [G loss: 1.000063]\n",
      "epoch:5 step:23110[D loss: 0.999974] [G loss: 1.000067]\n",
      "epoch:5 step:23115[D loss: 0.999979] [G loss: 1.000053]\n",
      "epoch:5 step:23120[D loss: 0.999973] [G loss: 1.000058]\n",
      "epoch:5 step:23125[D loss: 0.999990] [G loss: 1.000021]\n",
      "epoch:5 step:23130[D loss: 0.999970] [G loss: 1.000067]\n",
      "epoch:5 step:23135[D loss: 0.999966] [G loss: 1.000077]\n",
      "epoch:5 step:23140[D loss: 0.999970] [G loss: 1.000059]\n",
      "epoch:5 step:23145[D loss: 0.999972] [G loss: 1.000059]\n",
      "epoch:5 step:23150[D loss: 0.999984] [G loss: 1.000045]\n",
      "epoch:5 step:23155[D loss: 0.999959] [G loss: 1.000086]\n",
      "epoch:5 step:23160[D loss: 0.999966] [G loss: 1.000067]\n",
      "epoch:5 step:23165[D loss: 0.999971] [G loss: 1.000057]\n",
      "epoch:5 step:23170[D loss: 0.999970] [G loss: 1.000066]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:5 step:23175[D loss: 0.999970] [G loss: 1.000063]\n",
      "epoch:5 step:23180[D loss: 0.999972] [G loss: 1.000068]\n",
      "epoch:5 step:23185[D loss: 0.999971] [G loss: 1.000061]\n",
      "epoch:5 step:23190[D loss: 0.999995] [G loss: 1.000054]\n",
      "epoch:5 step:23195[D loss: 0.999974] [G loss: 1.000072]\n",
      "epoch:5 step:23200[D loss: 0.999975] [G loss: 1.000073]\n",
      "##############\n",
      "[0.87930521 0.85736546 0.81700631 0.8501193  0.80535398 0.83074274\n",
      " 0.85047212 0.84000448 0.81623667 0.84745689]\n",
      "##########\n",
      "epoch:5 step:23205[D loss: 1.000004] [G loss: 1.000035]\n",
      "epoch:5 step:23210[D loss: 0.999983] [G loss: 1.000090]\n",
      "epoch:5 step:23215[D loss: 0.999963] [G loss: 1.000076]\n",
      "epoch:5 step:23220[D loss: 0.999967] [G loss: 1.000075]\n",
      "epoch:5 step:23225[D loss: 0.999974] [G loss: 1.000071]\n",
      "epoch:5 step:23230[D loss: 0.999969] [G loss: 1.000058]\n",
      "epoch:5 step:23235[D loss: 0.999996] [G loss: 1.000021]\n",
      "epoch:5 step:23240[D loss: 0.999983] [G loss: 1.000005]\n",
      "epoch:5 step:23245[D loss: 0.999981] [G loss: 1.000046]\n",
      "epoch:5 step:23250[D loss: 0.999971] [G loss: 1.000070]\n",
      "epoch:5 step:23255[D loss: 0.999974] [G loss: 1.000064]\n",
      "epoch:5 step:23260[D loss: 0.999974] [G loss: 1.000072]\n",
      "epoch:5 step:23265[D loss: 0.999977] [G loss: 1.000065]\n",
      "epoch:5 step:23270[D loss: 0.999984] [G loss: 1.000038]\n",
      "epoch:5 step:23275[D loss: 0.999965] [G loss: 1.000089]\n",
      "epoch:5 step:23280[D loss: 0.999975] [G loss: 1.000065]\n",
      "epoch:5 step:23285[D loss: 0.999975] [G loss: 1.000061]\n",
      "epoch:5 step:23290[D loss: 0.999984] [G loss: 1.000046]\n",
      "epoch:5 step:23295[D loss: 0.999971] [G loss: 1.000035]\n",
      "epoch:5 step:23300[D loss: 0.999963] [G loss: 1.000081]\n",
      "epoch:5 step:23305[D loss: 0.999962] [G loss: 1.000072]\n",
      "epoch:5 step:23310[D loss: 0.999969] [G loss: 1.000069]\n",
      "epoch:5 step:23315[D loss: 0.999973] [G loss: 1.000064]\n",
      "epoch:5 step:23320[D loss: 0.999972] [G loss: 1.000071]\n",
      "epoch:5 step:23325[D loss: 0.999989] [G loss: 1.000043]\n",
      "epoch:5 step:23330[D loss: 0.999972] [G loss: 1.000055]\n",
      "epoch:5 step:23335[D loss: 0.999978] [G loss: 1.000067]\n",
      "epoch:5 step:23340[D loss: 0.999968] [G loss: 1.000081]\n",
      "epoch:5 step:23345[D loss: 0.999984] [G loss: 1.000031]\n",
      "epoch:5 step:23350[D loss: 0.999986] [G loss: 1.000060]\n",
      "epoch:5 step:23355[D loss: 0.999976] [G loss: 1.000054]\n",
      "epoch:5 step:23360[D loss: 0.999970] [G loss: 1.000079]\n",
      "epoch:5 step:23365[D loss: 0.999972] [G loss: 1.000071]\n",
      "epoch:5 step:23370[D loss: 0.999991] [G loss: 1.000034]\n",
      "epoch:5 step:23375[D loss: 0.999997] [G loss: 1.000044]\n",
      "epoch:5 step:23380[D loss: 0.999963] [G loss: 1.000066]\n",
      "epoch:5 step:23385[D loss: 0.999973] [G loss: 1.000078]\n",
      "epoch:5 step:23390[D loss: 0.999971] [G loss: 1.000066]\n",
      "epoch:5 step:23395[D loss: 0.999983] [G loss: 1.000074]\n",
      "epoch:5 step:23400[D loss: 0.999971] [G loss: 1.000062]\n",
      "##############\n",
      "[0.86407761 0.88671325 0.81783499 0.83252666 0.79235849 0.84666458\n",
      " 0.86283578 0.83192094 0.83031607 0.83476542]\n",
      "##########\n",
      "epoch:5 step:23405[D loss: 0.999997] [G loss: 1.000008]\n",
      "epoch:5 step:23410[D loss: 0.999988] [G loss: 1.000041]\n",
      "epoch:5 step:23415[D loss: 0.999959] [G loss: 1.000088]\n",
      "epoch:5 step:23420[D loss: 0.999974] [G loss: 1.000059]\n",
      "epoch:5 step:23425[D loss: 0.999993] [G loss: 1.000028]\n",
      "epoch:5 step:23430[D loss: 0.999978] [G loss: 1.000045]\n",
      "epoch:6 step:23435[D loss: 0.999968] [G loss: 1.000088]\n",
      "epoch:6 step:23440[D loss: 0.999968] [G loss: 1.000077]\n",
      "epoch:6 step:23445[D loss: 0.999975] [G loss: 1.000072]\n",
      "epoch:6 step:23450[D loss: 0.999967] [G loss: 1.000066]\n",
      "epoch:6 step:23455[D loss: 0.999971] [G loss: 1.000064]\n",
      "epoch:6 step:23460[D loss: 0.999988] [G loss: 1.000040]\n",
      "epoch:6 step:23465[D loss: 0.999976] [G loss: 1.000054]\n",
      "epoch:6 step:23470[D loss: 0.999968] [G loss: 1.000063]\n",
      "epoch:6 step:23475[D loss: 0.999968] [G loss: 1.000070]\n",
      "epoch:6 step:23480[D loss: 0.999977] [G loss: 1.000054]\n",
      "epoch:6 step:23485[D loss: 0.999969] [G loss: 1.000067]\n",
      "epoch:6 step:23490[D loss: 0.999974] [G loss: 1.000071]\n",
      "epoch:6 step:23495[D loss: 0.999975] [G loss: 1.000068]\n",
      "epoch:6 step:23500[D loss: 0.999978] [G loss: 1.000052]\n",
      "epoch:6 step:23505[D loss: 1.000006] [G loss: 0.999983]\n",
      "epoch:6 step:23510[D loss: 0.999964] [G loss: 1.000085]\n",
      "epoch:6 step:23515[D loss: 0.999971] [G loss: 1.000076]\n",
      "epoch:6 step:23520[D loss: 0.999971] [G loss: 1.000066]\n",
      "epoch:6 step:23525[D loss: 0.999963] [G loss: 1.000064]\n",
      "epoch:6 step:23530[D loss: 0.999962] [G loss: 1.000060]\n",
      "epoch:6 step:23535[D loss: 0.999984] [G loss: 1.000031]\n",
      "epoch:6 step:23540[D loss: 0.999973] [G loss: 1.000061]\n",
      "epoch:6 step:23545[D loss: 0.999973] [G loss: 1.000065]\n",
      "epoch:6 step:23550[D loss: 0.999978] [G loss: 1.000084]\n",
      "epoch:6 step:23555[D loss: 0.999968] [G loss: 1.000077]\n",
      "epoch:6 step:23560[D loss: 0.999969] [G loss: 1.000070]\n",
      "epoch:6 step:23565[D loss: 0.999973] [G loss: 1.000074]\n",
      "epoch:6 step:23570[D loss: 0.999981] [G loss: 1.000061]\n",
      "epoch:6 step:23575[D loss: 0.999987] [G loss: 1.000042]\n",
      "epoch:6 step:23580[D loss: 0.999961] [G loss: 1.000087]\n",
      "epoch:6 step:23585[D loss: 0.999970] [G loss: 1.000071]\n",
      "epoch:6 step:23590[D loss: 0.999967] [G loss: 1.000072]\n",
      "epoch:6 step:23595[D loss: 0.999971] [G loss: 1.000065]\n",
      "epoch:6 step:23600[D loss: 0.999971] [G loss: 1.000062]\n",
      "##############\n",
      "[0.87789493 0.86852322 0.82904863 0.82574503 0.79295226 0.84242605\n",
      " 0.8514974  0.82260989 0.79605297 0.82823441]\n",
      "##########\n",
      "epoch:6 step:23605[D loss: 0.999981] [G loss: 1.000049]\n",
      "epoch:6 step:23610[D loss: 0.999967] [G loss: 1.000064]\n",
      "epoch:6 step:23615[D loss: 0.999973] [G loss: 1.000066]\n",
      "epoch:6 step:23620[D loss: 0.999967] [G loss: 1.000069]\n",
      "epoch:6 step:23625[D loss: 0.999971] [G loss: 1.000059]\n",
      "epoch:6 step:23630[D loss: 0.999977] [G loss: 1.000063]\n",
      "epoch:6 step:23635[D loss: 0.999962] [G loss: 1.000072]\n",
      "epoch:6 step:23640[D loss: 0.999977] [G loss: 1.000067]\n",
      "epoch:6 step:23645[D loss: 0.999970] [G loss: 1.000058]\n",
      "epoch:6 step:23650[D loss: 0.999968] [G loss: 1.000108]\n",
      "epoch:6 step:23655[D loss: 0.999960] [G loss: 1.000093]\n",
      "epoch:6 step:23660[D loss: 0.999971] [G loss: 1.000078]\n",
      "epoch:6 step:23665[D loss: 0.999975] [G loss: 1.000060]\n",
      "epoch:6 step:23670[D loss: 0.999976] [G loss: 1.000053]\n",
      "epoch:6 step:23675[D loss: 1.000008] [G loss: 0.999998]\n",
      "epoch:6 step:23680[D loss: 0.999967] [G loss: 1.000042]\n",
      "epoch:6 step:23685[D loss: 0.999971] [G loss: 1.000064]\n",
      "epoch:6 step:23690[D loss: 0.999979] [G loss: 1.000047]\n",
      "epoch:6 step:23695[D loss: 0.999971] [G loss: 1.000061]\n",
      "epoch:6 step:23700[D loss: 0.999992] [G loss: 1.000035]\n",
      "epoch:6 step:23705[D loss: 0.999964] [G loss: 1.000069]\n",
      "epoch:6 step:23710[D loss: 0.999968] [G loss: 1.000062]\n",
      "epoch:6 step:23715[D loss: 0.999978] [G loss: 1.000062]\n",
      "epoch:6 step:23720[D loss: 0.999982] [G loss: 1.000017]\n",
      "epoch:6 step:23725[D loss: 0.999968] [G loss: 1.000068]\n",
      "epoch:6 step:23730[D loss: 0.999973] [G loss: 1.000046]\n",
      "epoch:6 step:23735[D loss: 0.999994] [G loss: 1.000027]\n",
      "epoch:6 step:23740[D loss: 0.999959] [G loss: 1.000077]\n",
      "epoch:6 step:23745[D loss: 0.999972] [G loss: 1.000075]\n",
      "epoch:6 step:23750[D loss: 0.999972] [G loss: 1.000061]\n",
      "epoch:6 step:23755[D loss: 0.999970] [G loss: 1.000055]\n",
      "epoch:6 step:23760[D loss: 0.999997] [G loss: 1.000008]\n",
      "epoch:6 step:23765[D loss: 0.999983] [G loss: 1.000051]\n",
      "epoch:6 step:23770[D loss: 0.999977] [G loss: 1.000052]\n",
      "epoch:6 step:23775[D loss: 0.999969] [G loss: 1.000067]\n",
      "epoch:6 step:23780[D loss: 0.999977] [G loss: 1.000064]\n",
      "epoch:6 step:23785[D loss: 0.999973] [G loss: 1.000060]\n",
      "epoch:6 step:23790[D loss: 0.999980] [G loss: 1.000058]\n",
      "epoch:6 step:23795[D loss: 0.999971] [G loss: 1.000060]\n",
      "epoch:6 step:23800[D loss: 0.999983] [G loss: 1.000040]\n",
      "##############\n",
      "[0.87159771 0.85182738 0.82403692 0.81251558 0.83533995 0.82851614\n",
      " 0.88465879 0.86157292 0.82331894 0.84866745]\n",
      "##########\n",
      "epoch:6 step:23805[D loss: 0.999971] [G loss: 1.000085]\n",
      "epoch:6 step:23810[D loss: 0.999965] [G loss: 1.000075]\n",
      "epoch:6 step:23815[D loss: 0.999974] [G loss: 1.000049]\n",
      "epoch:6 step:23820[D loss: 1.000029] [G loss: 0.999990]\n",
      "epoch:6 step:23825[D loss: 0.999973] [G loss: 1.000058]\n",
      "epoch:6 step:23830[D loss: 0.999946] [G loss: 1.000095]\n",
      "epoch:6 step:23835[D loss: 0.999959] [G loss: 1.000094]\n",
      "epoch:6 step:23840[D loss: 0.999973] [G loss: 1.000067]\n",
      "epoch:6 step:23845[D loss: 0.999974] [G loss: 1.000075]\n",
      "epoch:6 step:23850[D loss: 0.999974] [G loss: 1.000060]\n",
      "epoch:6 step:23855[D loss: 0.999971] [G loss: 1.000063]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:6 step:23860[D loss: 0.999977] [G loss: 1.000058]\n",
      "epoch:6 step:23865[D loss: 0.999968] [G loss: 1.000068]\n",
      "epoch:6 step:23870[D loss: 0.999994] [G loss: 1.000058]\n",
      "epoch:6 step:23875[D loss: 1.000016] [G loss: 1.000030]\n",
      "epoch:6 step:23880[D loss: 0.999978] [G loss: 1.000032]\n",
      "epoch:6 step:23885[D loss: 0.999964] [G loss: 1.000100]\n",
      "epoch:6 step:23890[D loss: 0.999972] [G loss: 1.000072]\n",
      "epoch:6 step:23895[D loss: 1.000004] [G loss: 1.000028]\n",
      "epoch:6 step:23900[D loss: 0.999990] [G loss: 1.000032]\n",
      "epoch:6 step:23905[D loss: 0.999942] [G loss: 1.000101]\n",
      "epoch:6 step:23910[D loss: 0.999986] [G loss: 1.000065]\n",
      "epoch:6 step:23915[D loss: 0.999955] [G loss: 1.000087]\n",
      "epoch:6 step:23920[D loss: 0.999972] [G loss: 1.000073]\n",
      "epoch:6 step:23925[D loss: 0.999974] [G loss: 1.000075]\n",
      "epoch:6 step:23930[D loss: 0.999979] [G loss: 1.000068]\n",
      "epoch:6 step:23935[D loss: 0.999976] [G loss: 1.000058]\n",
      "epoch:6 step:23940[D loss: 0.999991] [G loss: 1.000030]\n",
      "epoch:6 step:23945[D loss: 0.999987] [G loss: 1.000021]\n",
      "epoch:6 step:23950[D loss: 0.999984] [G loss: 1.000045]\n",
      "epoch:6 step:23955[D loss: 0.999967] [G loss: 1.000119]\n",
      "epoch:6 step:23960[D loss: 0.999959] [G loss: 1.000076]\n",
      "epoch:6 step:23965[D loss: 0.999970] [G loss: 1.000082]\n",
      "epoch:6 step:23970[D loss: 0.999980] [G loss: 1.000075]\n",
      "epoch:6 step:23975[D loss: 0.999976] [G loss: 1.000046]\n",
      "epoch:6 step:23980[D loss: 0.999974] [G loss: 1.000060]\n",
      "epoch:6 step:23985[D loss: 0.999972] [G loss: 1.000054]\n",
      "epoch:6 step:23990[D loss: 0.999994] [G loss: 1.000011]\n",
      "epoch:6 step:23995[D loss: 0.999991] [G loss: 1.000044]\n",
      "epoch:6 step:24000[D loss: 0.999950] [G loss: 1.000093]\n",
      "##############\n",
      "[0.8474943  0.85449579 0.82559091 0.826892   0.79407793 0.82712361\n",
      " 0.87179421 0.83391177 0.81102266 0.8511957 ]\n",
      "##########\n",
      "epoch:6 step:24005[D loss: 0.999958] [G loss: 1.000071]\n",
      "epoch:6 step:24010[D loss: 0.999971] [G loss: 1.000071]\n",
      "epoch:6 step:24015[D loss: 0.999973] [G loss: 1.000065]\n",
      "epoch:6 step:24020[D loss: 0.999966] [G loss: 1.000073]\n",
      "epoch:6 step:24025[D loss: 0.999971] [G loss: 1.000062]\n",
      "epoch:6 step:24030[D loss: 0.999976] [G loss: 1.000052]\n",
      "epoch:6 step:24035[D loss: 0.999973] [G loss: 1.000056]\n",
      "epoch:6 step:24040[D loss: 0.999981] [G loss: 1.000054]\n",
      "epoch:6 step:24045[D loss: 0.999972] [G loss: 1.000064]\n",
      "epoch:6 step:24050[D loss: 0.999972] [G loss: 1.000069]\n",
      "epoch:6 step:24055[D loss: 0.999969] [G loss: 1.000061]\n",
      "epoch:6 step:24060[D loss: 0.999982] [G loss: 1.000046]\n",
      "epoch:6 step:24065[D loss: 0.999971] [G loss: 1.000079]\n",
      "epoch:6 step:24070[D loss: 0.999959] [G loss: 1.000082]\n",
      "epoch:6 step:24075[D loss: 0.999977] [G loss: 1.000059]\n",
      "epoch:6 step:24080[D loss: 0.999970] [G loss: 1.000067]\n",
      "epoch:6 step:24085[D loss: 0.999970] [G loss: 1.000060]\n",
      "epoch:6 step:24090[D loss: 0.999986] [G loss: 1.000066]\n",
      "epoch:6 step:24095[D loss: 0.999980] [G loss: 1.000038]\n",
      "epoch:6 step:24100[D loss: 0.999986] [G loss: 1.000049]\n",
      "epoch:6 step:24105[D loss: 0.999966] [G loss: 1.000073]\n",
      "epoch:6 step:24110[D loss: 0.999971] [G loss: 1.000077]\n",
      "epoch:6 step:24115[D loss: 0.999988] [G loss: 1.000033]\n",
      "epoch:6 step:24120[D loss: 0.999972] [G loss: 1.000054]\n",
      "epoch:6 step:24125[D loss: 0.999983] [G loss: 1.000047]\n",
      "epoch:6 step:24130[D loss: 0.999983] [G loss: 1.000040]\n",
      "epoch:6 step:24135[D loss: 0.999969] [G loss: 1.000066]\n",
      "epoch:6 step:24140[D loss: 0.999973] [G loss: 1.000071]\n",
      "epoch:6 step:24145[D loss: 0.999981] [G loss: 1.000050]\n",
      "epoch:6 step:24150[D loss: 0.999980] [G loss: 1.000048]\n",
      "epoch:6 step:24155[D loss: 0.999990] [G loss: 1.000067]\n",
      "epoch:6 step:24160[D loss: 0.999970] [G loss: 1.000065]\n",
      "epoch:6 step:24165[D loss: 0.999977] [G loss: 1.000063]\n",
      "epoch:6 step:24170[D loss: 0.999978] [G loss: 1.000051]\n",
      "epoch:6 step:24175[D loss: 0.999971] [G loss: 1.000069]\n",
      "epoch:6 step:24180[D loss: 0.999970] [G loss: 1.000056]\n",
      "epoch:6 step:24185[D loss: 0.999976] [G loss: 1.000070]\n",
      "epoch:6 step:24190[D loss: 0.999981] [G loss: 1.000054]\n",
      "epoch:6 step:24195[D loss: 0.999970] [G loss: 1.000064]\n",
      "epoch:6 step:24200[D loss: 0.999976] [G loss: 1.000044]\n",
      "##############\n",
      "[0.86944404 0.88522346 0.81548003 0.81561466 0.81107656 0.82319749\n",
      " 0.87550662 0.84219996 0.84014659 0.84140561]\n",
      "##########\n",
      "epoch:6 step:24205[D loss: 0.999974] [G loss: 1.000052]\n",
      "epoch:6 step:24210[D loss: 0.999970] [G loss: 1.000062]\n",
      "epoch:6 step:24215[D loss: 0.999973] [G loss: 1.000062]\n",
      "epoch:6 step:24220[D loss: 0.999973] [G loss: 1.000054]\n",
      "epoch:6 step:24225[D loss: 0.999975] [G loss: 1.000060]\n",
      "epoch:6 step:24230[D loss: 0.999974] [G loss: 1.000067]\n",
      "epoch:6 step:24235[D loss: 0.999971] [G loss: 1.000063]\n",
      "epoch:6 step:24240[D loss: 0.999969] [G loss: 1.000073]\n",
      "epoch:6 step:24245[D loss: 0.999974] [G loss: 1.000065]\n",
      "epoch:6 step:24250[D loss: 0.999973] [G loss: 1.000055]\n",
      "epoch:6 step:24255[D loss: 0.999979] [G loss: 1.000059]\n",
      "epoch:6 step:24260[D loss: 0.999975] [G loss: 1.000054]\n",
      "epoch:6 step:24265[D loss: 0.999971] [G loss: 1.000060]\n",
      "epoch:6 step:24270[D loss: 0.999954] [G loss: 1.000073]\n",
      "epoch:6 step:24275[D loss: 0.999970] [G loss: 1.000061]\n",
      "epoch:6 step:24280[D loss: 0.999977] [G loss: 1.000056]\n",
      "epoch:6 step:24285[D loss: 0.999982] [G loss: 1.000056]\n",
      "epoch:6 step:24290[D loss: 0.999974] [G loss: 1.000099]\n",
      "epoch:6 step:24295[D loss: 0.999973] [G loss: 1.000070]\n",
      "epoch:6 step:24300[D loss: 0.999964] [G loss: 1.000071]\n",
      "epoch:6 step:24305[D loss: 0.999980] [G loss: 1.000028]\n",
      "epoch:6 step:24310[D loss: 1.000000] [G loss: 0.999982]\n",
      "epoch:6 step:24315[D loss: 0.999966] [G loss: 1.000072]\n",
      "epoch:6 step:24320[D loss: 0.999963] [G loss: 1.000076]\n",
      "epoch:6 step:24325[D loss: 0.999978] [G loss: 1.000073]\n",
      "epoch:6 step:24330[D loss: 0.999963] [G loss: 1.000090]\n",
      "epoch:6 step:24335[D loss: 0.999970] [G loss: 1.000073]\n",
      "epoch:6 step:24340[D loss: 0.999978] [G loss: 1.000061]\n",
      "epoch:6 step:24345[D loss: 1.000017] [G loss: 1.000020]\n",
      "epoch:6 step:24350[D loss: 0.999965] [G loss: 1.000066]\n",
      "epoch:6 step:24355[D loss: 0.999967] [G loss: 1.000085]\n",
      "epoch:6 step:24360[D loss: 0.999970] [G loss: 1.000053]\n",
      "epoch:6 step:24365[D loss: 0.999973] [G loss: 1.000053]\n",
      "epoch:6 step:24370[D loss: 1.000004] [G loss: 1.000044]\n",
      "epoch:6 step:24375[D loss: 0.999980] [G loss: 1.000060]\n",
      "epoch:6 step:24380[D loss: 0.999980] [G loss: 1.000093]\n",
      "epoch:6 step:24385[D loss: 0.999965] [G loss: 1.000063]\n",
      "epoch:6 step:24390[D loss: 0.999973] [G loss: 1.000071]\n",
      "epoch:6 step:24395[D loss: 0.999971] [G loss: 1.000061]\n",
      "epoch:6 step:24400[D loss: 0.999969] [G loss: 1.000063]\n",
      "##############\n",
      "[0.86482983 0.8330829  0.8269198  0.83988704 0.80720036 0.83982135\n",
      " 0.89012389 0.84889679 0.80963413 0.84591872]\n",
      "##########\n",
      "epoch:6 step:24405[D loss: 0.999985] [G loss: 1.000035]\n",
      "epoch:6 step:24410[D loss: 0.999979] [G loss: 1.000050]\n",
      "epoch:6 step:24415[D loss: 0.999955] [G loss: 1.000121]\n",
      "epoch:6 step:24420[D loss: 0.999973] [G loss: 1.000054]\n",
      "epoch:6 step:24425[D loss: 0.999990] [G loss: 1.000032]\n",
      "epoch:6 step:24430[D loss: 0.999974] [G loss: 1.000064]\n",
      "epoch:6 step:24435[D loss: 0.999968] [G loss: 1.000064]\n",
      "epoch:6 step:24440[D loss: 0.999962] [G loss: 1.000075]\n",
      "epoch:6 step:24445[D loss: 0.999972] [G loss: 1.000079]\n",
      "epoch:6 step:24450[D loss: 0.999971] [G loss: 1.000070]\n",
      "epoch:6 step:24455[D loss: 0.999992] [G loss: 1.000077]\n",
      "epoch:6 step:24460[D loss: 0.999951] [G loss: 1.000075]\n",
      "epoch:6 step:24465[D loss: 0.999980] [G loss: 1.000074]\n",
      "epoch:6 step:24470[D loss: 0.999970] [G loss: 1.000079]\n",
      "epoch:6 step:24475[D loss: 0.999967] [G loss: 1.000088]\n",
      "epoch:6 step:24480[D loss: 0.999975] [G loss: 1.000061]\n",
      "epoch:6 step:24485[D loss: 0.999983] [G loss: 1.000031]\n",
      "epoch:6 step:24490[D loss: 0.999971] [G loss: 1.000055]\n",
      "epoch:6 step:24495[D loss: 0.999976] [G loss: 1.000064]\n",
      "epoch:6 step:24500[D loss: 0.999975] [G loss: 1.000056]\n",
      "epoch:6 step:24505[D loss: 0.999973] [G loss: 1.000077]\n",
      "epoch:6 step:24510[D loss: 0.999973] [G loss: 1.000064]\n",
      "epoch:6 step:24515[D loss: 0.999969] [G loss: 1.000071]\n",
      "epoch:6 step:24520[D loss: 0.999967] [G loss: 1.000074]\n",
      "epoch:6 step:24525[D loss: 0.999974] [G loss: 1.000062]\n",
      "epoch:6 step:24530[D loss: 0.999971] [G loss: 1.000072]\n",
      "epoch:6 step:24535[D loss: 0.999975] [G loss: 1.000061]\n",
      "epoch:6 step:24540[D loss: 0.999976] [G loss: 1.000068]\n",
      "epoch:6 step:24545[D loss: 0.999965] [G loss: 1.000081]\n",
      "epoch:6 step:24550[D loss: 0.999968] [G loss: 1.000079]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:6 step:24555[D loss: 0.999969] [G loss: 1.000068]\n",
      "epoch:6 step:24560[D loss: 0.999971] [G loss: 1.000075]\n",
      "epoch:6 step:24565[D loss: 0.999973] [G loss: 1.000057]\n",
      "epoch:6 step:24570[D loss: 0.999974] [G loss: 1.000072]\n",
      "epoch:6 step:24575[D loss: 0.999977] [G loss: 1.000059]\n",
      "epoch:6 step:24580[D loss: 0.999984] [G loss: 1.000052]\n",
      "epoch:6 step:24585[D loss: 0.999965] [G loss: 1.000076]\n",
      "epoch:6 step:24590[D loss: 0.999969] [G loss: 1.000069]\n",
      "epoch:6 step:24595[D loss: 0.999974] [G loss: 1.000070]\n",
      "epoch:6 step:24600[D loss: 0.999960] [G loss: 1.000075]\n",
      "##############\n",
      "[0.85651774 0.86896258 0.82920242 0.82510563 0.79923086 0.83840686\n",
      " 0.87962394 0.85021688 0.82146643 0.82907296]\n",
      "##########\n",
      "epoch:6 step:24605[D loss: 0.999973] [G loss: 1.000073]\n",
      "epoch:6 step:24610[D loss: 0.999980] [G loss: 1.000065]\n",
      "epoch:6 step:24615[D loss: 0.999964] [G loss: 1.000071]\n",
      "epoch:6 step:24620[D loss: 0.999975] [G loss: 1.000066]\n",
      "epoch:6 step:24625[D loss: 0.999972] [G loss: 1.000071]\n",
      "epoch:6 step:24630[D loss: 0.999976] [G loss: 1.000072]\n",
      "epoch:6 step:24635[D loss: 0.999969] [G loss: 1.000067]\n",
      "epoch:6 step:24640[D loss: 0.999973] [G loss: 1.000073]\n",
      "epoch:6 step:24645[D loss: 0.999973] [G loss: 1.000069]\n",
      "epoch:6 step:24650[D loss: 0.999974] [G loss: 1.000060]\n",
      "epoch:6 step:24655[D loss: 0.999980] [G loss: 1.000059]\n",
      "epoch:6 step:24660[D loss: 0.999974] [G loss: 1.000066]\n",
      "epoch:6 step:24665[D loss: 0.999955] [G loss: 1.000082]\n",
      "epoch:6 step:24670[D loss: 0.999968] [G loss: 1.000071]\n",
      "epoch:6 step:24675[D loss: 0.999972] [G loss: 1.000057]\n",
      "epoch:6 step:24680[D loss: 0.999968] [G loss: 1.000063]\n",
      "epoch:6 step:24685[D loss: 0.999972] [G loss: 1.000050]\n",
      "epoch:6 step:24690[D loss: 0.999974] [G loss: 1.000060]\n",
      "epoch:6 step:24695[D loss: 0.999972] [G loss: 1.000074]\n",
      "epoch:6 step:24700[D loss: 0.999971] [G loss: 1.000066]\n",
      "epoch:6 step:24705[D loss: 0.999966] [G loss: 1.000071]\n",
      "epoch:6 step:24710[D loss: 0.999972] [G loss: 1.000075]\n",
      "epoch:6 step:24715[D loss: 0.999977] [G loss: 1.000064]\n",
      "epoch:6 step:24720[D loss: 0.999975] [G loss: 1.000075]\n",
      "epoch:6 step:24725[D loss: 0.999973] [G loss: 1.000072]\n",
      "epoch:6 step:24730[D loss: 0.999972] [G loss: 1.000073]\n",
      "epoch:6 step:24735[D loss: 0.999973] [G loss: 1.000061]\n",
      "epoch:6 step:24740[D loss: 0.999970] [G loss: 1.000054]\n",
      "epoch:6 step:24745[D loss: 0.999991] [G loss: 1.000047]\n",
      "epoch:6 step:24750[D loss: 0.999971] [G loss: 1.000070]\n",
      "epoch:6 step:24755[D loss: 0.999976] [G loss: 1.000058]\n",
      "epoch:6 step:24760[D loss: 0.999978] [G loss: 1.000054]\n",
      "epoch:6 step:24765[D loss: 0.999972] [G loss: 1.000063]\n",
      "epoch:6 step:24770[D loss: 0.999974] [G loss: 1.000072]\n",
      "epoch:6 step:24775[D loss: 0.999978] [G loss: 1.000057]\n",
      "epoch:6 step:24780[D loss: 0.999971] [G loss: 1.000049]\n",
      "epoch:6 step:24785[D loss: 0.999968] [G loss: 1.000065]\n",
      "epoch:6 step:24790[D loss: 0.999975] [G loss: 1.000062]\n",
      "epoch:6 step:24795[D loss: 0.999972] [G loss: 1.000068]\n",
      "epoch:6 step:24800[D loss: 0.999974] [G loss: 1.000059]\n",
      "##############\n",
      "[0.88284109 0.86193194 0.83439487 0.81930974 0.78023281 0.84453552\n",
      " 0.86309766 0.86439033 0.83306145 0.82887203]\n",
      "##########\n",
      "epoch:6 step:24805[D loss: 0.999971] [G loss: 1.000069]\n",
      "epoch:6 step:24810[D loss: 0.999978] [G loss: 1.000054]\n",
      "epoch:6 step:24815[D loss: 0.999976] [G loss: 1.000057]\n",
      "epoch:6 step:24820[D loss: 0.999977] [G loss: 1.000063]\n",
      "epoch:6 step:24825[D loss: 0.999974] [G loss: 1.000067]\n",
      "epoch:6 step:24830[D loss: 0.999975] [G loss: 1.000062]\n",
      "epoch:6 step:24835[D loss: 0.999988] [G loss: 1.000022]\n",
      "epoch:6 step:24840[D loss: 0.999970] [G loss: 1.000091]\n",
      "epoch:6 step:24845[D loss: 0.999964] [G loss: 1.000080]\n",
      "epoch:6 step:24850[D loss: 0.999967] [G loss: 1.000070]\n",
      "epoch:6 step:24855[D loss: 0.999987] [G loss: 1.000039]\n",
      "epoch:6 step:24860[D loss: 0.999983] [G loss: 1.000048]\n",
      "epoch:6 step:24865[D loss: 0.999963] [G loss: 1.000055]\n",
      "epoch:6 step:24870[D loss: 0.999972] [G loss: 1.000067]\n",
      "epoch:6 step:24875[D loss: 0.999970] [G loss: 1.000072]\n",
      "epoch:6 step:24880[D loss: 0.999977] [G loss: 1.000058]\n",
      "epoch:6 step:24885[D loss: 0.999971] [G loss: 1.000075]\n",
      "epoch:6 step:24890[D loss: 0.999973] [G loss: 1.000053]\n",
      "epoch:6 step:24895[D loss: 0.999988] [G loss: 1.000045]\n",
      "epoch:6 step:24900[D loss: 0.999973] [G loss: 1.000078]\n",
      "epoch:6 step:24905[D loss: 0.999970] [G loss: 1.000065]\n",
      "epoch:6 step:24910[D loss: 0.999974] [G loss: 1.000073]\n",
      "epoch:6 step:24915[D loss: 0.999972] [G loss: 1.000070]\n",
      "epoch:6 step:24920[D loss: 0.999967] [G loss: 1.000073]\n",
      "epoch:6 step:24925[D loss: 0.999980] [G loss: 1.000073]\n",
      "epoch:6 step:24930[D loss: 0.999965] [G loss: 1.000073]\n",
      "epoch:6 step:24935[D loss: 0.999970] [G loss: 1.000070]\n",
      "epoch:6 step:24940[D loss: 0.999972] [G loss: 1.000067]\n",
      "epoch:6 step:24945[D loss: 0.999975] [G loss: 1.000068]\n",
      "epoch:6 step:24950[D loss: 0.999976] [G loss: 1.000064]\n",
      "epoch:6 step:24955[D loss: 0.999971] [G loss: 1.000068]\n",
      "epoch:6 step:24960[D loss: 0.999971] [G loss: 1.000079]\n",
      "epoch:6 step:24965[D loss: 0.999977] [G loss: 1.000060]\n",
      "epoch:6 step:24970[D loss: 0.999973] [G loss: 1.000079]\n",
      "epoch:6 step:24975[D loss: 0.999977] [G loss: 1.000064]\n",
      "epoch:6 step:24980[D loss: 0.999978] [G loss: 1.000077]\n",
      "epoch:6 step:24985[D loss: 0.999984] [G loss: 1.000041]\n",
      "epoch:6 step:24990[D loss: 0.999965] [G loss: 1.000083]\n",
      "epoch:6 step:24995[D loss: 0.999971] [G loss: 1.000071]\n",
      "epoch:6 step:25000[D loss: 0.999969] [G loss: 1.000077]\n",
      "##############\n",
      "[0.85978185 0.86830305 0.79992766 0.81892411 0.81826942 0.84540521\n",
      " 0.84469175 0.86064858 0.81611403 0.83614801]\n",
      "##########\n",
      "epoch:6 step:25005[D loss: 0.999968] [G loss: 1.000077]\n",
      "epoch:6 step:25010[D loss: 0.999976] [G loss: 1.000054]\n",
      "epoch:6 step:25015[D loss: 0.999964] [G loss: 1.000080]\n",
      "epoch:6 step:25020[D loss: 0.999973] [G loss: 1.000070]\n",
      "epoch:6 step:25025[D loss: 0.999978] [G loss: 1.000045]\n",
      "epoch:6 step:25030[D loss: 0.999977] [G loss: 1.000054]\n",
      "epoch:6 step:25035[D loss: 0.999973] [G loss: 1.000061]\n",
      "epoch:6 step:25040[D loss: 0.999995] [G loss: 1.000018]\n",
      "epoch:6 step:25045[D loss: 0.999996] [G loss: 1.000023]\n",
      "epoch:6 step:25050[D loss: 0.999967] [G loss: 1.000055]\n",
      "epoch:6 step:25055[D loss: 0.999968] [G loss: 1.000053]\n",
      "epoch:6 step:25060[D loss: 0.999980] [G loss: 1.000047]\n",
      "epoch:6 step:25065[D loss: 0.999964] [G loss: 1.000069]\n",
      "epoch:6 step:25070[D loss: 0.999981] [G loss: 1.000052]\n",
      "epoch:6 step:25075[D loss: 0.999981] [G loss: 1.000058]\n",
      "epoch:6 step:25080[D loss: 0.999973] [G loss: 1.000043]\n",
      "epoch:6 step:25085[D loss: 0.999974] [G loss: 1.000059]\n",
      "epoch:6 step:25090[D loss: 0.999987] [G loss: 1.000015]\n",
      "epoch:6 step:25095[D loss: 0.999969] [G loss: 1.000068]\n",
      "epoch:6 step:25100[D loss: 0.999972] [G loss: 1.000066]\n",
      "epoch:6 step:25105[D loss: 0.999970] [G loss: 1.000068]\n",
      "epoch:6 step:25110[D loss: 0.999983] [G loss: 1.000045]\n",
      "epoch:6 step:25115[D loss: 0.999982] [G loss: 1.000080]\n",
      "epoch:6 step:25120[D loss: 0.999991] [G loss: 0.999990]\n",
      "epoch:6 step:25125[D loss: 0.999959] [G loss: 1.000083]\n",
      "epoch:6 step:25130[D loss: 0.999976] [G loss: 1.000059]\n",
      "epoch:6 step:25135[D loss: 0.999975] [G loss: 1.000058]\n",
      "epoch:6 step:25140[D loss: 0.999972] [G loss: 1.000068]\n",
      "epoch:6 step:25145[D loss: 0.999974] [G loss: 1.000067]\n",
      "epoch:6 step:25150[D loss: 0.999970] [G loss: 1.000068]\n",
      "epoch:6 step:25155[D loss: 0.999974] [G loss: 1.000066]\n",
      "epoch:6 step:25160[D loss: 0.999982] [G loss: 1.000038]\n",
      "epoch:6 step:25165[D loss: 0.999964] [G loss: 1.000074]\n",
      "epoch:6 step:25170[D loss: 0.999973] [G loss: 1.000067]\n",
      "epoch:6 step:25175[D loss: 0.999972] [G loss: 1.000070]\n",
      "epoch:6 step:25180[D loss: 0.999973] [G loss: 1.000074]\n",
      "epoch:6 step:25185[D loss: 0.999972] [G loss: 1.000061]\n",
      "epoch:6 step:25190[D loss: 0.999971] [G loss: 1.000066]\n",
      "epoch:6 step:25195[D loss: 0.999969] [G loss: 1.000071]\n",
      "epoch:6 step:25200[D loss: 0.999970] [G loss: 1.000070]\n",
      "##############\n",
      "[0.87354909 0.86842756 0.81657079 0.82522854 0.80650554 0.82784357\n",
      " 0.85751911 0.86018298 0.8199277  0.86163296]\n",
      "##########\n",
      "epoch:6 step:25205[D loss: 0.999967] [G loss: 1.000058]\n",
      "epoch:6 step:25210[D loss: 0.999962] [G loss: 1.000080]\n",
      "epoch:6 step:25215[D loss: 0.999975] [G loss: 1.000059]\n",
      "epoch:6 step:25220[D loss: 0.999973] [G loss: 1.000063]\n",
      "epoch:6 step:25225[D loss: 0.999976] [G loss: 1.000064]\n",
      "epoch:6 step:25230[D loss: 0.999973] [G loss: 1.000059]\n",
      "epoch:6 step:25235[D loss: 0.999965] [G loss: 1.000081]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:6 step:25240[D loss: 0.999977] [G loss: 1.000044]\n",
      "epoch:6 step:25245[D loss: 0.999973] [G loss: 1.000062]\n",
      "epoch:6 step:25250[D loss: 0.999979] [G loss: 1.000047]\n",
      "epoch:6 step:25255[D loss: 0.999962] [G loss: 1.000063]\n",
      "epoch:6 step:25260[D loss: 0.999990] [G loss: 1.000019]\n",
      "epoch:6 step:25265[D loss: 0.999982] [G loss: 1.000051]\n",
      "epoch:6 step:25270[D loss: 0.999975] [G loss: 1.000073]\n",
      "epoch:6 step:25275[D loss: 0.999980] [G loss: 1.000062]\n",
      "epoch:6 step:25280[D loss: 0.999996] [G loss: 1.000027]\n",
      "epoch:6 step:25285[D loss: 0.999969] [G loss: 1.000059]\n",
      "epoch:6 step:25290[D loss: 0.999957] [G loss: 1.000091]\n",
      "epoch:6 step:25295[D loss: 0.999976] [G loss: 1.000081]\n",
      "epoch:6 step:25300[D loss: 0.999970] [G loss: 1.000084]\n",
      "epoch:6 step:25305[D loss: 0.999991] [G loss: 1.000028]\n",
      "epoch:6 step:25310[D loss: 0.999983] [G loss: 1.000031]\n",
      "epoch:6 step:25315[D loss: 1.000000] [G loss: 1.000011]\n",
      "epoch:6 step:25320[D loss: 0.999963] [G loss: 1.000065]\n",
      "epoch:6 step:25325[D loss: 0.999973] [G loss: 1.000073]\n",
      "epoch:6 step:25330[D loss: 0.999974] [G loss: 1.000070]\n",
      "epoch:6 step:25335[D loss: 0.999977] [G loss: 1.000059]\n",
      "epoch:6 step:25340[D loss: 0.999962] [G loss: 1.000063]\n",
      "epoch:6 step:25345[D loss: 0.999976] [G loss: 1.000059]\n",
      "epoch:6 step:25350[D loss: 0.999963] [G loss: 1.000064]\n",
      "epoch:6 step:25355[D loss: 0.999972] [G loss: 1.000068]\n",
      "epoch:6 step:25360[D loss: 0.999973] [G loss: 1.000069]\n",
      "epoch:6 step:25365[D loss: 0.999966] [G loss: 1.000077]\n",
      "epoch:6 step:25370[D loss: 0.999967] [G loss: 1.000074]\n",
      "epoch:6 step:25375[D loss: 0.999975] [G loss: 1.000061]\n",
      "epoch:6 step:25380[D loss: 0.999976] [G loss: 1.000060]\n",
      "epoch:6 step:25385[D loss: 0.999976] [G loss: 1.000054]\n",
      "epoch:6 step:25390[D loss: 0.999977] [G loss: 1.000060]\n",
      "epoch:6 step:25395[D loss: 0.999975] [G loss: 1.000055]\n",
      "epoch:6 step:25400[D loss: 0.999986] [G loss: 1.000007]\n",
      "##############\n",
      "[0.87599778 0.85784232 0.81824079 0.83469321 0.76995583 0.84143991\n",
      " 0.89599984 0.83397487 0.81089702 0.84685382]\n",
      "##########\n",
      "epoch:6 step:25405[D loss: 0.999969] [G loss: 1.000064]\n",
      "epoch:6 step:25410[D loss: 0.999966] [G loss: 1.000062]\n",
      "epoch:6 step:25415[D loss: 0.999968] [G loss: 1.000072]\n",
      "epoch:6 step:25420[D loss: 0.999971] [G loss: 1.000058]\n",
      "epoch:6 step:25425[D loss: 0.999978] [G loss: 1.000063]\n",
      "epoch:6 step:25430[D loss: 0.999973] [G loss: 1.000065]\n",
      "epoch:6 step:25435[D loss: 0.999971] [G loss: 1.000080]\n",
      "epoch:6 step:25440[D loss: 0.999968] [G loss: 1.000066]\n",
      "epoch:6 step:25445[D loss: 0.999971] [G loss: 1.000070]\n",
      "epoch:6 step:25450[D loss: 0.999976] [G loss: 1.000063]\n",
      "epoch:6 step:25455[D loss: 0.999968] [G loss: 1.000070]\n",
      "epoch:6 step:25460[D loss: 0.999974] [G loss: 1.000057]\n",
      "epoch:6 step:25465[D loss: 0.999971] [G loss: 1.000062]\n",
      "epoch:6 step:25470[D loss: 0.999968] [G loss: 1.000067]\n",
      "epoch:6 step:25475[D loss: 0.999982] [G loss: 1.000049]\n",
      "epoch:6 step:25480[D loss: 0.999963] [G loss: 1.000087]\n",
      "epoch:6 step:25485[D loss: 0.999975] [G loss: 1.000071]\n",
      "epoch:6 step:25490[D loss: 0.999968] [G loss: 1.000060]\n",
      "epoch:6 step:25495[D loss: 0.999975] [G loss: 1.000064]\n",
      "epoch:6 step:25500[D loss: 0.999981] [G loss: 1.000057]\n",
      "epoch:6 step:25505[D loss: 0.999967] [G loss: 1.000071]\n",
      "epoch:6 step:25510[D loss: 0.999964] [G loss: 1.000076]\n",
      "epoch:6 step:25515[D loss: 0.999974] [G loss: 1.000066]\n",
      "epoch:6 step:25520[D loss: 0.999972] [G loss: 1.000065]\n",
      "epoch:6 step:25525[D loss: 0.999970] [G loss: 1.000070]\n",
      "epoch:6 step:25530[D loss: 0.999970] [G loss: 1.000059]\n",
      "epoch:6 step:25535[D loss: 0.999997] [G loss: 1.000028]\n",
      "epoch:6 step:25540[D loss: 0.999966] [G loss: 1.000062]\n",
      "epoch:6 step:25545[D loss: 0.999973] [G loss: 1.000065]\n",
      "epoch:6 step:25550[D loss: 0.999975] [G loss: 1.000055]\n",
      "epoch:6 step:25555[D loss: 0.999968] [G loss: 1.000068]\n",
      "epoch:6 step:25560[D loss: 0.999972] [G loss: 1.000061]\n",
      "epoch:6 step:25565[D loss: 0.999972] [G loss: 1.000070]\n",
      "epoch:6 step:25570[D loss: 0.999977] [G loss: 1.000053]\n",
      "epoch:6 step:25575[D loss: 0.999988] [G loss: 1.000050]\n",
      "epoch:6 step:25580[D loss: 0.999974] [G loss: 1.000068]\n",
      "epoch:6 step:25585[D loss: 0.999971] [G loss: 1.000064]\n",
      "epoch:6 step:25590[D loss: 0.999970] [G loss: 1.000075]\n",
      "epoch:6 step:25595[D loss: 0.999972] [G loss: 1.000066]\n",
      "epoch:6 step:25600[D loss: 0.999991] [G loss: 1.000019]\n",
      "##############\n",
      "[0.8608428  0.88358254 0.82747068 0.81709744 0.80692116 0.8327162\n",
      " 0.87044224 0.88295457 0.81743763 0.84404411]\n",
      "##########\n",
      "epoch:6 step:25605[D loss: 0.999970] [G loss: 1.000079]\n",
      "epoch:6 step:25610[D loss: 0.999972] [G loss: 1.000071]\n",
      "epoch:6 step:25615[D loss: 0.999983] [G loss: 1.000045]\n",
      "epoch:6 step:25620[D loss: 1.000027] [G loss: 0.999988]\n",
      "epoch:6 step:25625[D loss: 0.999978] [G loss: 1.000072]\n",
      "epoch:6 step:25630[D loss: 0.999972] [G loss: 1.000064]\n",
      "epoch:6 step:25635[D loss: 0.999965] [G loss: 1.000095]\n",
      "epoch:6 step:25640[D loss: 0.999972] [G loss: 1.000068]\n",
      "epoch:6 step:25645[D loss: 0.999982] [G loss: 1.000033]\n",
      "epoch:6 step:25650[D loss: 0.999968] [G loss: 1.000060]\n",
      "epoch:6 step:25655[D loss: 0.999965] [G loss: 1.000073]\n",
      "epoch:6 step:25660[D loss: 0.999969] [G loss: 1.000063]\n",
      "epoch:6 step:25665[D loss: 0.999992] [G loss: 1.000056]\n",
      "epoch:6 step:25670[D loss: 0.999967] [G loss: 1.000096]\n",
      "epoch:6 step:25675[D loss: 0.999964] [G loss: 1.000079]\n",
      "epoch:6 step:25680[D loss: 0.999973] [G loss: 1.000069]\n",
      "epoch:6 step:25685[D loss: 0.999985] [G loss: 1.000045]\n",
      "epoch:6 step:25690[D loss: 0.999978] [G loss: 1.000029]\n",
      "epoch:6 step:25695[D loss: 0.999997] [G loss: 1.000043]\n",
      "epoch:6 step:25700[D loss: 0.999960] [G loss: 1.000069]\n",
      "epoch:6 step:25705[D loss: 0.999972] [G loss: 1.000063]\n",
      "epoch:6 step:25710[D loss: 0.999972] [G loss: 1.000069]\n",
      "epoch:6 step:25715[D loss: 0.999972] [G loss: 1.000064]\n",
      "epoch:6 step:25720[D loss: 0.999976] [G loss: 1.000060]\n",
      "epoch:6 step:25725[D loss: 0.999983] [G loss: 1.000044]\n",
      "epoch:6 step:25730[D loss: 0.999971] [G loss: 1.000067]\n",
      "epoch:6 step:25735[D loss: 0.999977] [G loss: 1.000054]\n",
      "epoch:6 step:25740[D loss: 0.999972] [G loss: 1.000065]\n",
      "epoch:6 step:25745[D loss: 0.999971] [G loss: 1.000055]\n",
      "epoch:6 step:25750[D loss: 0.999969] [G loss: 1.000064]\n",
      "epoch:6 step:25755[D loss: 0.999974] [G loss: 1.000061]\n",
      "epoch:6 step:25760[D loss: 0.999968] [G loss: 1.000073]\n",
      "epoch:6 step:25765[D loss: 0.999972] [G loss: 1.000064]\n",
      "epoch:6 step:25770[D loss: 0.999973] [G loss: 1.000063]\n",
      "epoch:6 step:25775[D loss: 0.999979] [G loss: 1.000036]\n",
      "epoch:6 step:25780[D loss: 0.999958] [G loss: 1.000067]\n",
      "epoch:6 step:25785[D loss: 0.999970] [G loss: 1.000064]\n",
      "epoch:6 step:25790[D loss: 0.999973] [G loss: 1.000057]\n",
      "epoch:6 step:25795[D loss: 0.999986] [G loss: 1.000042]\n",
      "epoch:6 step:25800[D loss: 1.000013] [G loss: 1.000037]\n",
      "##############\n",
      "[0.85895992 0.87516891 0.80918157 0.81927955 0.83210178 0.82642123\n",
      " 0.85329322 0.82785342 0.80854296 0.84332551]\n",
      "##########\n",
      "epoch:6 step:25805[D loss: 0.999954] [G loss: 1.000073]\n",
      "epoch:6 step:25810[D loss: 0.999966] [G loss: 1.000063]\n",
      "epoch:6 step:25815[D loss: 0.999968] [G loss: 1.000062]\n",
      "epoch:6 step:25820[D loss: 0.999971] [G loss: 1.000052]\n",
      "epoch:6 step:25825[D loss: 0.999974] [G loss: 1.000041]\n",
      "epoch:6 step:25830[D loss: 0.999969] [G loss: 1.000061]\n",
      "epoch:6 step:25835[D loss: 0.999970] [G loss: 1.000061]\n",
      "epoch:6 step:25840[D loss: 0.999972] [G loss: 1.000073]\n",
      "epoch:6 step:25845[D loss: 0.999975] [G loss: 1.000060]\n",
      "epoch:6 step:25850[D loss: 0.999980] [G loss: 1.000044]\n",
      "epoch:6 step:25855[D loss: 0.999969] [G loss: 1.000064]\n",
      "epoch:6 step:25860[D loss: 0.999972] [G loss: 1.000061]\n",
      "epoch:6 step:25865[D loss: 0.999975] [G loss: 1.000060]\n",
      "epoch:6 step:25870[D loss: 0.999992] [G loss: 1.000005]\n",
      "epoch:6 step:25875[D loss: 0.999968] [G loss: 1.000067]\n",
      "epoch:6 step:25880[D loss: 0.999973] [G loss: 1.000067]\n",
      "epoch:6 step:25885[D loss: 0.999978] [G loss: 1.000050]\n",
      "epoch:6 step:25890[D loss: 0.999971] [G loss: 1.000110]\n",
      "epoch:6 step:25895[D loss: 0.999994] [G loss: 1.000073]\n",
      "epoch:6 step:25900[D loss: 0.999957] [G loss: 1.000095]\n",
      "epoch:6 step:25905[D loss: 0.999966] [G loss: 1.000087]\n",
      "epoch:6 step:25910[D loss: 0.999969] [G loss: 1.000077]\n",
      "epoch:6 step:25915[D loss: 0.999982] [G loss: 1.000039]\n",
      "epoch:6 step:25920[D loss: 0.999988] [G loss: 1.000002]\n",
      "epoch:6 step:25925[D loss: 0.999989] [G loss: 1.000015]\n",
      "epoch:6 step:25930[D loss: 0.999968] [G loss: 1.000074]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:6 step:25935[D loss: 0.999962] [G loss: 1.000062]\n",
      "epoch:6 step:25940[D loss: 0.999972] [G loss: 1.000063]\n",
      "epoch:6 step:25945[D loss: 0.999968] [G loss: 1.000075]\n",
      "epoch:6 step:25950[D loss: 0.999971] [G loss: 1.000057]\n",
      "epoch:6 step:25955[D loss: 0.999968] [G loss: 1.000070]\n",
      "epoch:6 step:25960[D loss: 0.999974] [G loss: 1.000061]\n",
      "epoch:6 step:25965[D loss: 0.999974] [G loss: 1.000064]\n",
      "epoch:6 step:25970[D loss: 0.999976] [G loss: 1.000055]\n",
      "epoch:6 step:25975[D loss: 0.999980] [G loss: 1.000079]\n",
      "epoch:6 step:25980[D loss: 1.000004] [G loss: 1.000043]\n",
      "epoch:6 step:25985[D loss: 0.999954] [G loss: 1.000132]\n",
      "epoch:6 step:25990[D loss: 0.999957] [G loss: 1.000105]\n",
      "epoch:6 step:25995[D loss: 0.999971] [G loss: 1.000072]\n",
      "epoch:6 step:26000[D loss: 0.999976] [G loss: 1.000053]\n",
      "##############\n",
      "[0.88257117 0.87878369 0.82077244 0.81307087 0.78957689 0.82061973\n",
      " 0.85885439 0.84307355 0.80168377 0.84657891]\n",
      "##########\n",
      "epoch:6 step:26005[D loss: 1.000002] [G loss: 0.999977]\n",
      "epoch:6 step:26010[D loss: 0.999995] [G loss: 1.000009]\n",
      "epoch:6 step:26015[D loss: 0.999973] [G loss: 1.000038]\n",
      "epoch:6 step:26020[D loss: 0.999980] [G loss: 1.000049]\n",
      "epoch:6 step:26025[D loss: 0.999966] [G loss: 1.000078]\n",
      "epoch:6 step:26030[D loss: 0.999965] [G loss: 1.000077]\n",
      "epoch:6 step:26035[D loss: 0.999967] [G loss: 1.000083]\n",
      "epoch:6 step:26040[D loss: 0.999969] [G loss: 1.000070]\n",
      "epoch:6 step:26045[D loss: 0.999979] [G loss: 1.000064]\n",
      "epoch:6 step:26050[D loss: 0.999971] [G loss: 1.000064]\n",
      "epoch:6 step:26055[D loss: 0.999983] [G loss: 1.000027]\n",
      "epoch:6 step:26060[D loss: 0.999964] [G loss: 1.000059]\n",
      "epoch:6 step:26065[D loss: 0.999965] [G loss: 1.000074]\n",
      "epoch:6 step:26070[D loss: 0.999973] [G loss: 1.000071]\n",
      "epoch:6 step:26075[D loss: 0.999969] [G loss: 1.000072]\n",
      "epoch:6 step:26080[D loss: 0.999974] [G loss: 1.000069]\n",
      "epoch:6 step:26085[D loss: 0.999970] [G loss: 1.000082]\n",
      "epoch:6 step:26090[D loss: 0.999964] [G loss: 1.000073]\n",
      "epoch:6 step:26095[D loss: 0.999976] [G loss: 1.000065]\n",
      "epoch:6 step:26100[D loss: 0.999969] [G loss: 1.000061]\n",
      "epoch:6 step:26105[D loss: 0.999998] [G loss: 1.000031]\n",
      "epoch:6 step:26110[D loss: 0.999977] [G loss: 1.000018]\n",
      "epoch:6 step:26115[D loss: 0.999964] [G loss: 1.000060]\n",
      "epoch:6 step:26120[D loss: 0.999975] [G loss: 1.000068]\n",
      "epoch:6 step:26125[D loss: 0.999972] [G loss: 1.000071]\n",
      "epoch:6 step:26130[D loss: 0.999979] [G loss: 1.000062]\n",
      "epoch:6 step:26135[D loss: 0.999985] [G loss: 1.000064]\n",
      "epoch:6 step:26140[D loss: 0.999970] [G loss: 1.000073]\n",
      "epoch:6 step:26145[D loss: 0.999970] [G loss: 1.000064]\n",
      "epoch:6 step:26150[D loss: 0.999977] [G loss: 1.000067]\n",
      "epoch:6 step:26155[D loss: 0.999955] [G loss: 1.000072]\n",
      "epoch:6 step:26160[D loss: 0.999990] [G loss: 1.000046]\n",
      "epoch:6 step:26165[D loss: 0.999969] [G loss: 1.000058]\n",
      "epoch:6 step:26170[D loss: 0.999971] [G loss: 1.000063]\n",
      "epoch:6 step:26175[D loss: 0.999974] [G loss: 1.000070]\n",
      "epoch:6 step:26180[D loss: 0.999975] [G loss: 1.000068]\n",
      "epoch:6 step:26185[D loss: 0.999976] [G loss: 1.000063]\n",
      "epoch:6 step:26190[D loss: 0.999963] [G loss: 1.000066]\n",
      "epoch:6 step:26195[D loss: 0.999972] [G loss: 1.000064]\n",
      "epoch:6 step:26200[D loss: 0.999972] [G loss: 1.000077]\n",
      "##############\n",
      "[0.87725086 0.87390425 0.80481916 0.8302186  0.80387172 0.82583121\n",
      " 0.85697389 0.82990084 0.83909949 0.85103281]\n",
      "##########\n",
      "epoch:6 step:26205[D loss: 0.999962] [G loss: 1.000091]\n",
      "epoch:6 step:26210[D loss: 0.999967] [G loss: 1.000078]\n",
      "epoch:6 step:26215[D loss: 0.999971] [G loss: 1.000075]\n",
      "epoch:6 step:26220[D loss: 0.999966] [G loss: 1.000072]\n",
      "epoch:6 step:26225[D loss: 0.999973] [G loss: 1.000057]\n",
      "epoch:6 step:26230[D loss: 0.999998] [G loss: 1.000003]\n",
      "epoch:6 step:26235[D loss: 0.999979] [G loss: 1.000067]\n",
      "epoch:6 step:26240[D loss: 0.999967] [G loss: 1.000064]\n",
      "epoch:6 step:26245[D loss: 0.999971] [G loss: 1.000081]\n",
      "epoch:6 step:26250[D loss: 0.999976] [G loss: 1.000073]\n",
      "epoch:6 step:26255[D loss: 0.999981] [G loss: 1.000063]\n",
      "epoch:6 step:26260[D loss: 0.999983] [G loss: 1.000037]\n",
      "epoch:6 step:26265[D loss: 0.999985] [G loss: 1.000042]\n",
      "epoch:6 step:26270[D loss: 0.999977] [G loss: 1.000035]\n",
      "epoch:6 step:26275[D loss: 0.999958] [G loss: 1.000085]\n",
      "epoch:6 step:26280[D loss: 0.999969] [G loss: 1.000074]\n",
      "epoch:6 step:26285[D loss: 0.999971] [G loss: 1.000066]\n",
      "epoch:6 step:26290[D loss: 0.999972] [G loss: 1.000070]\n",
      "epoch:6 step:26295[D loss: 0.999971] [G loss: 1.000065]\n",
      "epoch:6 step:26300[D loss: 0.999976] [G loss: 1.000067]\n",
      "epoch:6 step:26305[D loss: 0.999963] [G loss: 1.000060]\n",
      "epoch:6 step:26310[D loss: 0.999967] [G loss: 1.000070]\n",
      "epoch:6 step:26315[D loss: 0.999976] [G loss: 1.000064]\n",
      "epoch:6 step:26320[D loss: 0.999974] [G loss: 1.000072]\n",
      "epoch:6 step:26325[D loss: 0.999972] [G loss: 1.000063]\n",
      "epoch:6 step:26330[D loss: 0.999971] [G loss: 1.000058]\n",
      "epoch:6 step:26335[D loss: 0.999976] [G loss: 1.000053]\n",
      "epoch:6 step:26340[D loss: 0.999982] [G loss: 1.000068]\n",
      "epoch:6 step:26345[D loss: 0.999995] [G loss: 1.000017]\n",
      "epoch:6 step:26350[D loss: 1.000016] [G loss: 0.999995]\n",
      "epoch:6 step:26355[D loss: 0.999970] [G loss: 1.000084]\n",
      "epoch:6 step:26360[D loss: 0.999971] [G loss: 1.000087]\n",
      "epoch:6 step:26365[D loss: 0.999972] [G loss: 1.000063]\n",
      "epoch:6 step:26370[D loss: 0.999969] [G loss: 1.000061]\n",
      "epoch:6 step:26375[D loss: 1.000003] [G loss: 0.999987]\n",
      "epoch:6 step:26380[D loss: 0.999986] [G loss: 1.000057]\n",
      "epoch:6 step:26385[D loss: 1.000006] [G loss: 1.000043]\n",
      "epoch:6 step:26390[D loss: 0.999960] [G loss: 1.000096]\n",
      "epoch:6 step:26395[D loss: 0.999965] [G loss: 1.000075]\n",
      "epoch:6 step:26400[D loss: 0.999974] [G loss: 1.000069]\n",
      "##############\n",
      "[0.884178   0.85466165 0.82588848 0.81964002 0.79789953 0.83765823\n",
      " 0.86495494 0.84521664 0.80297649 0.83075001]\n",
      "##########\n",
      "epoch:6 step:26405[D loss: 0.999978] [G loss: 1.000075]\n",
      "epoch:6 step:26410[D loss: 0.999995] [G loss: 1.000009]\n",
      "epoch:6 step:26415[D loss: 0.999979] [G loss: 1.000083]\n",
      "epoch:6 step:26420[D loss: 0.999964] [G loss: 1.000062]\n",
      "epoch:6 step:26425[D loss: 0.999970] [G loss: 1.000068]\n",
      "epoch:6 step:26430[D loss: 0.999972] [G loss: 1.000063]\n",
      "epoch:6 step:26435[D loss: 0.999994] [G loss: 1.000035]\n",
      "epoch:6 step:26440[D loss: 0.999963] [G loss: 1.000063]\n",
      "epoch:6 step:26445[D loss: 0.999968] [G loss: 1.000070]\n",
      "epoch:6 step:26450[D loss: 0.999978] [G loss: 1.000072]\n",
      "epoch:6 step:26455[D loss: 0.999975] [G loss: 1.000070]\n",
      "epoch:6 step:26460[D loss: 0.999968] [G loss: 1.000067]\n",
      "epoch:6 step:26465[D loss: 0.999969] [G loss: 1.000058]\n",
      "epoch:6 step:26470[D loss: 0.999969] [G loss: 1.000067]\n",
      "epoch:6 step:26475[D loss: 0.999993] [G loss: 1.000048]\n",
      "epoch:6 step:26480[D loss: 0.999966] [G loss: 1.000073]\n",
      "epoch:6 step:26485[D loss: 0.999973] [G loss: 1.000051]\n",
      "epoch:6 step:26490[D loss: 0.999961] [G loss: 1.000075]\n",
      "epoch:6 step:26495[D loss: 0.999971] [G loss: 1.000071]\n",
      "epoch:6 step:26500[D loss: 0.999978] [G loss: 1.000064]\n",
      "epoch:6 step:26505[D loss: 0.999972] [G loss: 1.000060]\n",
      "epoch:6 step:26510[D loss: 0.999978] [G loss: 1.000062]\n",
      "epoch:6 step:26515[D loss: 0.999972] [G loss: 1.000061]\n",
      "epoch:6 step:26520[D loss: 0.999966] [G loss: 1.000068]\n",
      "epoch:6 step:26525[D loss: 0.999969] [G loss: 1.000067]\n",
      "epoch:6 step:26530[D loss: 0.999959] [G loss: 1.000087]\n",
      "epoch:6 step:26535[D loss: 0.999972] [G loss: 1.000073]\n",
      "epoch:6 step:26540[D loss: 0.999971] [G loss: 1.000069]\n",
      "epoch:6 step:26545[D loss: 0.999970] [G loss: 1.000070]\n",
      "epoch:6 step:26550[D loss: 0.999973] [G loss: 1.000067]\n",
      "epoch:6 step:26555[D loss: 0.999971] [G loss: 1.000074]\n",
      "epoch:6 step:26560[D loss: 0.999972] [G loss: 1.000064]\n",
      "epoch:6 step:26565[D loss: 0.999961] [G loss: 1.000072]\n",
      "epoch:6 step:26570[D loss: 0.999993] [G loss: 1.000013]\n",
      "epoch:6 step:26575[D loss: 0.999967] [G loss: 1.000059]\n",
      "epoch:6 step:26580[D loss: 0.999966] [G loss: 1.000074]\n",
      "epoch:6 step:26585[D loss: 0.999995] [G loss: 1.000037]\n",
      "epoch:6 step:26590[D loss: 0.999968] [G loss: 1.000055]\n",
      "epoch:6 step:26595[D loss: 0.999964] [G loss: 1.000097]\n",
      "epoch:6 step:26600[D loss: 0.999961] [G loss: 1.000073]\n",
      "##############\n",
      "[0.85661304 0.86311868 0.8050275  0.83904089 0.8031164  0.84223823\n",
      " 0.86926968 0.81629695 0.81117392 0.8556831 ]\n",
      "##########\n",
      "epoch:6 step:26605[D loss: 0.999968] [G loss: 1.000073]\n",
      "epoch:6 step:26610[D loss: 0.999969] [G loss: 1.000077]\n",
      "epoch:6 step:26615[D loss: 0.999975] [G loss: 1.000067]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:6 step:26620[D loss: 0.999967] [G loss: 1.000068]\n",
      "epoch:6 step:26625[D loss: 0.999974] [G loss: 1.000066]\n",
      "epoch:6 step:26630[D loss: 0.999981] [G loss: 1.000046]\n",
      "epoch:6 step:26635[D loss: 0.999980] [G loss: 1.000050]\n",
      "epoch:6 step:26640[D loss: 0.999965] [G loss: 1.000069]\n",
      "epoch:6 step:26645[D loss: 0.999973] [G loss: 1.000069]\n",
      "epoch:6 step:26650[D loss: 0.999967] [G loss: 1.000066]\n",
      "epoch:6 step:26655[D loss: 0.999969] [G loss: 1.000064]\n",
      "epoch:6 step:26660[D loss: 0.999977] [G loss: 1.000049]\n",
      "epoch:6 step:26665[D loss: 0.999963] [G loss: 1.000064]\n",
      "epoch:6 step:26670[D loss: 0.999973] [G loss: 1.000063]\n",
      "epoch:6 step:26675[D loss: 0.999974] [G loss: 1.000057]\n",
      "epoch:6 step:26680[D loss: 0.999973] [G loss: 1.000062]\n",
      "epoch:6 step:26685[D loss: 0.999970] [G loss: 1.000062]\n",
      "epoch:6 step:26690[D loss: 0.999984] [G loss: 1.000052]\n",
      "epoch:6 step:26695[D loss: 0.999971] [G loss: 1.000078]\n",
      "epoch:6 step:26700[D loss: 0.999973] [G loss: 1.000072]\n",
      "epoch:6 step:26705[D loss: 0.999965] [G loss: 1.000070]\n",
      "epoch:6 step:26710[D loss: 0.999973] [G loss: 1.000066]\n",
      "epoch:6 step:26715[D loss: 0.999972] [G loss: 1.000065]\n",
      "epoch:6 step:26720[D loss: 0.999983] [G loss: 1.000050]\n",
      "epoch:6 step:26725[D loss: 0.999955] [G loss: 1.000102]\n",
      "epoch:6 step:26730[D loss: 0.999965] [G loss: 1.000072]\n",
      "epoch:6 step:26735[D loss: 0.999978] [G loss: 1.000081]\n",
      "epoch:6 step:26740[D loss: 0.999961] [G loss: 1.000076]\n",
      "epoch:6 step:26745[D loss: 0.999971] [G loss: 1.000066]\n",
      "epoch:6 step:26750[D loss: 0.999977] [G loss: 1.000060]\n",
      "epoch:6 step:26755[D loss: 0.999991] [G loss: 1.000021]\n",
      "epoch:6 step:26760[D loss: 0.999995] [G loss: 1.000000]\n",
      "epoch:6 step:26765[D loss: 0.999974] [G loss: 1.000059]\n",
      "epoch:6 step:26770[D loss: 0.999970] [G loss: 1.000071]\n",
      "epoch:6 step:26775[D loss: 0.999976] [G loss: 1.000068]\n",
      "epoch:6 step:26780[D loss: 0.999970] [G loss: 1.000063]\n",
      "epoch:6 step:26785[D loss: 0.999978] [G loss: 1.000046]\n",
      "epoch:6 step:26790[D loss: 0.999972] [G loss: 1.000064]\n",
      "epoch:6 step:26795[D loss: 0.999972] [G loss: 1.000067]\n",
      "epoch:6 step:26800[D loss: 0.999971] [G loss: 1.000066]\n",
      "##############\n",
      "[0.88948275 0.87138962 0.81781592 0.84749777 0.79868027 0.84071976\n",
      " 0.85250533 0.84168565 0.84340965 0.82240153]\n",
      "##########\n",
      "epoch:6 step:26805[D loss: 0.999972] [G loss: 1.000070]\n",
      "epoch:6 step:26810[D loss: 0.999960] [G loss: 1.000068]\n",
      "epoch:6 step:26815[D loss: 0.999968] [G loss: 1.000061]\n",
      "epoch:6 step:26820[D loss: 0.999972] [G loss: 1.000064]\n",
      "epoch:6 step:26825[D loss: 0.999995] [G loss: 1.000020]\n",
      "epoch:6 step:26830[D loss: 0.999985] [G loss: 1.000036]\n",
      "epoch:6 step:26835[D loss: 0.999970] [G loss: 1.000069]\n",
      "epoch:6 step:26840[D loss: 0.999976] [G loss: 1.000046]\n",
      "epoch:6 step:26845[D loss: 0.999979] [G loss: 1.000068]\n",
      "epoch:6 step:26850[D loss: 0.999966] [G loss: 1.000075]\n",
      "epoch:6 step:26855[D loss: 0.999973] [G loss: 1.000067]\n",
      "epoch:6 step:26860[D loss: 0.999971] [G loss: 1.000092]\n",
      "epoch:6 step:26865[D loss: 0.999970] [G loss: 1.000061]\n",
      "epoch:6 step:26870[D loss: 0.999972] [G loss: 1.000055]\n",
      "epoch:6 step:26875[D loss: 1.000033] [G loss: 0.999995]\n",
      "epoch:6 step:26880[D loss: 0.999975] [G loss: 1.000030]\n",
      "epoch:6 step:26885[D loss: 0.999964] [G loss: 1.000067]\n",
      "epoch:6 step:26890[D loss: 0.999970] [G loss: 1.000070]\n",
      "epoch:6 step:26895[D loss: 0.999973] [G loss: 1.000061]\n",
      "epoch:6 step:26900[D loss: 0.999975] [G loss: 1.000044]\n",
      "epoch:6 step:26905[D loss: 0.999974] [G loss: 1.000072]\n",
      "epoch:6 step:26910[D loss: 0.999993] [G loss: 1.000017]\n",
      "epoch:6 step:26915[D loss: 0.999966] [G loss: 1.000067]\n",
      "epoch:6 step:26920[D loss: 0.999970] [G loss: 1.000085]\n",
      "epoch:6 step:26925[D loss: 0.999982] [G loss: 1.000079]\n",
      "epoch:6 step:26930[D loss: 0.999969] [G loss: 1.000068]\n",
      "epoch:6 step:26935[D loss: 0.999972] [G loss: 1.000063]\n",
      "epoch:6 step:26940[D loss: 0.999973] [G loss: 1.000063]\n",
      "epoch:6 step:26945[D loss: 0.999979] [G loss: 1.000052]\n",
      "epoch:6 step:26950[D loss: 0.999979] [G loss: 1.000055]\n",
      "epoch:6 step:26955[D loss: 0.999977] [G loss: 1.000059]\n",
      "epoch:6 step:26960[D loss: 0.999974] [G loss: 1.000084]\n",
      "epoch:6 step:26965[D loss: 0.999970] [G loss: 1.000054]\n",
      "epoch:6 step:26970[D loss: 0.999972] [G loss: 1.000068]\n",
      "epoch:6 step:26975[D loss: 0.999972] [G loss: 1.000070]\n",
      "epoch:6 step:26980[D loss: 0.999971] [G loss: 1.000068]\n",
      "epoch:6 step:26985[D loss: 0.999967] [G loss: 1.000065]\n",
      "epoch:6 step:26990[D loss: 0.999972] [G loss: 1.000069]\n",
      "epoch:6 step:26995[D loss: 0.999994] [G loss: 1.000034]\n",
      "epoch:6 step:27000[D loss: 0.999969] [G loss: 1.000068]\n",
      "##############\n",
      "[0.85622287 0.85896867 0.82956868 0.83014397 0.79624505 0.83983803\n",
      " 0.86334603 0.85378118 0.82346587 0.84246838]\n",
      "##########\n",
      "epoch:6 step:27005[D loss: 1.000015] [G loss: 1.000043]\n",
      "epoch:6 step:27010[D loss: 0.999938] [G loss: 1.000106]\n",
      "epoch:6 step:27015[D loss: 0.999947] [G loss: 1.000106]\n",
      "epoch:6 step:27020[D loss: 0.999957] [G loss: 1.000092]\n",
      "epoch:6 step:27025[D loss: 0.999966] [G loss: 1.000077]\n",
      "epoch:6 step:27030[D loss: 0.999978] [G loss: 1.000043]\n",
      "epoch:6 step:27035[D loss: 0.999994] [G loss: 1.000035]\n",
      "epoch:6 step:27040[D loss: 0.999984] [G loss: 1.000018]\n",
      "epoch:6 step:27045[D loss: 0.999969] [G loss: 1.000082]\n",
      "epoch:6 step:27050[D loss: 0.999976] [G loss: 1.000094]\n",
      "epoch:6 step:27055[D loss: 0.999957] [G loss: 1.000078]\n",
      "epoch:6 step:27060[D loss: 0.999972] [G loss: 1.000058]\n",
      "epoch:6 step:27065[D loss: 0.999976] [G loss: 1.000053]\n",
      "epoch:6 step:27070[D loss: 0.999978] [G loss: 1.000044]\n",
      "epoch:6 step:27075[D loss: 1.000006] [G loss: 0.999954]\n",
      "epoch:6 step:27080[D loss: 0.999974] [G loss: 1.000069]\n",
      "epoch:6 step:27085[D loss: 0.999984] [G loss: 1.000075]\n",
      "epoch:6 step:27090[D loss: 0.999948] [G loss: 1.000100]\n",
      "epoch:6 step:27095[D loss: 0.999970] [G loss: 1.000073]\n",
      "epoch:6 step:27100[D loss: 0.999967] [G loss: 1.000061]\n",
      "epoch:6 step:27105[D loss: 0.999977] [G loss: 1.000048]\n",
      "epoch:6 step:27110[D loss: 0.999978] [G loss: 1.000061]\n",
      "epoch:6 step:27115[D loss: 0.999967] [G loss: 1.000071]\n",
      "epoch:6 step:27120[D loss: 0.999968] [G loss: 1.000071]\n",
      "epoch:6 step:27125[D loss: 0.999972] [G loss: 1.000061]\n",
      "epoch:6 step:27130[D loss: 0.999975] [G loss: 1.000065]\n",
      "epoch:6 step:27135[D loss: 0.999971] [G loss: 1.000068]\n",
      "epoch:6 step:27140[D loss: 0.999969] [G loss: 1.000074]\n",
      "epoch:6 step:27145[D loss: 0.999974] [G loss: 1.000062]\n",
      "epoch:6 step:27150[D loss: 0.999980] [G loss: 1.000057]\n",
      "epoch:6 step:27155[D loss: 0.999986] [G loss: 1.000046]\n",
      "epoch:6 step:27160[D loss: 0.999966] [G loss: 1.000074]\n",
      "epoch:6 step:27165[D loss: 0.999975] [G loss: 1.000043]\n",
      "epoch:6 step:27170[D loss: 0.999967] [G loss: 1.000066]\n",
      "epoch:6 step:27175[D loss: 0.999970] [G loss: 1.000070]\n",
      "epoch:6 step:27180[D loss: 0.999971] [G loss: 1.000061]\n",
      "epoch:6 step:27185[D loss: 0.999987] [G loss: 1.000057]\n",
      "epoch:6 step:27190[D loss: 0.999964] [G loss: 1.000064]\n",
      "epoch:6 step:27195[D loss: 0.999973] [G loss: 1.000058]\n",
      "epoch:6 step:27200[D loss: 0.999974] [G loss: 1.000061]\n",
      "##############\n",
      "[0.88307056 0.85253383 0.82420689 0.82809555 0.8079857  0.84052638\n",
      " 0.87013689 0.85828896 0.8241227  0.84056514]\n",
      "##########\n",
      "epoch:6 step:27205[D loss: 0.999970] [G loss: 1.000074]\n",
      "epoch:6 step:27210[D loss: 0.999975] [G loss: 1.000078]\n",
      "epoch:6 step:27215[D loss: 0.999971] [G loss: 1.000068]\n",
      "epoch:6 step:27220[D loss: 0.999974] [G loss: 1.000066]\n",
      "epoch:6 step:27225[D loss: 0.999969] [G loss: 1.000064]\n",
      "epoch:6 step:27230[D loss: 0.999972] [G loss: 1.000065]\n",
      "epoch:6 step:27235[D loss: 0.999977] [G loss: 1.000062]\n",
      "epoch:6 step:27240[D loss: 0.999973] [G loss: 1.000073]\n",
      "epoch:6 step:27245[D loss: 0.999973] [G loss: 1.000068]\n",
      "epoch:6 step:27250[D loss: 0.999988] [G loss: 1.000018]\n",
      "epoch:6 step:27255[D loss: 0.999962] [G loss: 1.000070]\n",
      "epoch:6 step:27260[D loss: 0.999976] [G loss: 1.000054]\n",
      "epoch:6 step:27265[D loss: 0.999973] [G loss: 1.000058]\n",
      "epoch:6 step:27270[D loss: 0.999976] [G loss: 1.000066]\n",
      "epoch:6 step:27275[D loss: 0.999989] [G loss: 1.000045]\n",
      "epoch:6 step:27280[D loss: 0.999995] [G loss: 1.000035]\n",
      "epoch:6 step:27285[D loss: 0.999971] [G loss: 1.000069]\n",
      "epoch:6 step:27290[D loss: 0.999987] [G loss: 1.000067]\n",
      "epoch:6 step:27295[D loss: 0.999966] [G loss: 1.000074]\n",
      "epoch:6 step:27300[D loss: 0.999970] [G loss: 1.000093]\n",
      "epoch:6 step:27305[D loss: 0.999972] [G loss: 1.000059]\n",
      "epoch:6 step:27310[D loss: 0.999991] [G loss: 0.999994]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:6 step:27315[D loss: 1.000029] [G loss: 0.999971]\n",
      "epoch:6 step:27320[D loss: 0.999969] [G loss: 1.000066]\n",
      "epoch:6 step:27325[D loss: 0.999951] [G loss: 1.000075]\n",
      "epoch:6 step:27330[D loss: 0.999965] [G loss: 1.000071]\n",
      "epoch:6 step:27335[D loss: 0.999974] [G loss: 1.000063]\n",
      "epoch:7 step:27340[D loss: 0.999971] [G loss: 1.000068]\n",
      "epoch:7 step:27345[D loss: 0.999983] [G loss: 1.000058]\n",
      "epoch:7 step:27350[D loss: 0.999979] [G loss: 1.000094]\n",
      "epoch:7 step:27355[D loss: 0.999970] [G loss: 1.000077]\n",
      "epoch:7 step:27360[D loss: 0.999982] [G loss: 1.000064]\n",
      "epoch:7 step:27365[D loss: 0.999956] [G loss: 1.000081]\n",
      "epoch:7 step:27370[D loss: 0.999969] [G loss: 1.000073]\n",
      "epoch:7 step:27375[D loss: 0.999979] [G loss: 1.000048]\n",
      "epoch:7 step:27380[D loss: 0.999971] [G loss: 1.000066]\n",
      "epoch:7 step:27385[D loss: 0.999969] [G loss: 1.000068]\n",
      "epoch:7 step:27390[D loss: 0.999989] [G loss: 1.000077]\n",
      "epoch:7 step:27395[D loss: 0.999966] [G loss: 1.000064]\n",
      "epoch:7 step:27400[D loss: 0.999975] [G loss: 1.000073]\n",
      "##############\n",
      "[0.88733405 0.84118339 0.82437673 0.8339719  0.77225219 0.83565569\n",
      " 0.87784563 0.8485822  0.84018144 0.85051383]\n",
      "##########\n",
      "epoch:7 step:27405[D loss: 0.999971] [G loss: 1.000072]\n",
      "epoch:7 step:27410[D loss: 0.999986] [G loss: 1.000053]\n",
      "epoch:7 step:27415[D loss: 0.999979] [G loss: 1.000058]\n",
      "epoch:7 step:27420[D loss: 0.999994] [G loss: 1.000046]\n",
      "epoch:7 step:27425[D loss: 0.999978] [G loss: 1.000072]\n",
      "epoch:7 step:27430[D loss: 0.999954] [G loss: 1.000078]\n",
      "epoch:7 step:27435[D loss: 0.999965] [G loss: 1.000081]\n",
      "epoch:7 step:27440[D loss: 0.999978] [G loss: 1.000045]\n",
      "epoch:7 step:27445[D loss: 0.999983] [G loss: 1.000009]\n",
      "epoch:7 step:27450[D loss: 0.999961] [G loss: 1.000070]\n",
      "epoch:7 step:27455[D loss: 1.000045] [G loss: 1.000039]\n",
      "epoch:7 step:27460[D loss: 0.999944] [G loss: 1.000097]\n",
      "epoch:7 step:27465[D loss: 0.999980] [G loss: 1.000075]\n",
      "epoch:7 step:27470[D loss: 0.999965] [G loss: 1.000096]\n",
      "epoch:7 step:27475[D loss: 0.999973] [G loss: 1.000084]\n",
      "epoch:7 step:27480[D loss: 0.999976] [G loss: 1.000064]\n",
      "epoch:7 step:27485[D loss: 1.000016] [G loss: 0.999974]\n",
      "epoch:7 step:27490[D loss: 0.999977] [G loss: 1.000014]\n",
      "epoch:7 step:27495[D loss: 0.999998] [G loss: 1.000047]\n",
      "epoch:7 step:27500[D loss: 0.999952] [G loss: 1.000097]\n",
      "epoch:7 step:27505[D loss: 0.999960] [G loss: 1.000087]\n",
      "epoch:7 step:27510[D loss: 0.999968] [G loss: 1.000072]\n",
      "epoch:7 step:27515[D loss: 0.999969] [G loss: 1.000072]\n",
      "epoch:7 step:27520[D loss: 0.999980] [G loss: 1.000061]\n",
      "epoch:7 step:27525[D loss: 0.999970] [G loss: 1.000066]\n",
      "epoch:7 step:27530[D loss: 0.999988] [G loss: 1.000026]\n",
      "epoch:7 step:27535[D loss: 0.999999] [G loss: 1.000043]\n",
      "epoch:7 step:27540[D loss: 0.999992] [G loss: 1.000008]\n",
      "epoch:7 step:27545[D loss: 0.999943] [G loss: 1.000102]\n",
      "epoch:7 step:27550[D loss: 0.999967] [G loss: 1.000068]\n",
      "epoch:7 step:27555[D loss: 0.999972] [G loss: 1.000070]\n",
      "epoch:7 step:27560[D loss: 0.999985] [G loss: 1.000045]\n",
      "epoch:7 step:27565[D loss: 1.000005] [G loss: 0.999994]\n",
      "epoch:7 step:27570[D loss: 0.999972] [G loss: 1.000055]\n",
      "epoch:7 step:27575[D loss: 0.999969] [G loss: 1.000063]\n",
      "epoch:7 step:27580[D loss: 0.999969] [G loss: 1.000067]\n",
      "epoch:7 step:27585[D loss: 0.999976] [G loss: 1.000051]\n",
      "epoch:7 step:27590[D loss: 0.999975] [G loss: 1.000069]\n",
      "epoch:7 step:27595[D loss: 0.999967] [G loss: 1.000083]\n",
      "epoch:7 step:27600[D loss: 0.999969] [G loss: 1.000059]\n",
      "##############\n",
      "[0.87146812 0.86566262 0.82202109 0.8351752  0.79510909 0.84750335\n",
      " 0.86928984 0.83864743 0.81634805 0.83437405]\n",
      "##########\n",
      "epoch:7 step:27605[D loss: 0.999978] [G loss: 1.000064]\n",
      "epoch:7 step:27610[D loss: 0.999970] [G loss: 1.000070]\n",
      "epoch:7 step:27615[D loss: 0.999980] [G loss: 1.000062]\n",
      "epoch:7 step:27620[D loss: 0.999965] [G loss: 1.000065]\n",
      "epoch:7 step:27625[D loss: 0.999989] [G loss: 1.000047]\n",
      "epoch:7 step:27630[D loss: 0.999978] [G loss: 1.000077]\n",
      "epoch:7 step:27635[D loss: 0.999971] [G loss: 1.000079]\n",
      "epoch:7 step:27640[D loss: 0.999981] [G loss: 1.000109]\n",
      "epoch:7 step:27645[D loss: 0.999961] [G loss: 1.000089]\n",
      "epoch:7 step:27650[D loss: 0.999968] [G loss: 1.000074]\n",
      "epoch:7 step:27655[D loss: 0.999977] [G loss: 1.000066]\n",
      "epoch:7 step:27660[D loss: 0.999976] [G loss: 1.000058]\n",
      "epoch:7 step:27665[D loss: 0.999994] [G loss: 1.000031]\n",
      "epoch:7 step:27670[D loss: 0.999985] [G loss: 1.000031]\n",
      "epoch:7 step:27675[D loss: 0.999961] [G loss: 1.000085]\n",
      "epoch:7 step:27680[D loss: 0.999954] [G loss: 1.000074]\n",
      "epoch:7 step:27685[D loss: 0.999967] [G loss: 1.000075]\n",
      "epoch:7 step:27690[D loss: 0.999981] [G loss: 1.000067]\n",
      "epoch:7 step:27695[D loss: 0.999973] [G loss: 1.000071]\n",
      "epoch:7 step:27700[D loss: 0.999970] [G loss: 1.000072]\n",
      "epoch:7 step:27705[D loss: 0.999974] [G loss: 1.000064]\n",
      "epoch:7 step:27710[D loss: 0.999972] [G loss: 1.000073]\n",
      "epoch:7 step:27715[D loss: 0.999963] [G loss: 1.000085]\n",
      "epoch:7 step:27720[D loss: 0.999968] [G loss: 1.000085]\n",
      "epoch:7 step:27725[D loss: 0.999966] [G loss: 1.000074]\n",
      "epoch:7 step:27730[D loss: 0.999971] [G loss: 1.000071]\n",
      "epoch:7 step:27735[D loss: 0.999971] [G loss: 1.000066]\n",
      "epoch:7 step:27740[D loss: 0.999984] [G loss: 1.000049]\n",
      "epoch:7 step:27745[D loss: 0.999973] [G loss: 1.000074]\n",
      "epoch:7 step:27750[D loss: 0.999975] [G loss: 1.000054]\n",
      "epoch:7 step:27755[D loss: 0.999972] [G loss: 1.000046]\n",
      "epoch:7 step:27760[D loss: 0.999971] [G loss: 1.000067]\n",
      "epoch:7 step:27765[D loss: 0.999974] [G loss: 1.000067]\n",
      "epoch:7 step:27770[D loss: 0.999969] [G loss: 1.000068]\n",
      "epoch:7 step:27775[D loss: 0.999982] [G loss: 1.000052]\n",
      "epoch:7 step:27780[D loss: 0.999992] [G loss: 1.000061]\n",
      "epoch:7 step:27785[D loss: 0.999971] [G loss: 1.000070]\n",
      "epoch:7 step:27790[D loss: 0.999973] [G loss: 1.000064]\n",
      "epoch:7 step:27795[D loss: 0.999975] [G loss: 1.000053]\n",
      "epoch:7 step:27800[D loss: 0.999987] [G loss: 1.000055]\n",
      "##############\n",
      "[0.87687307 0.8584655  0.82606053 0.81880416 0.82146781 0.81539843\n",
      " 0.87478728 0.84701708 0.79995061 0.85837216]\n",
      "##########\n",
      "epoch:7 step:27805[D loss: 0.999980] [G loss: 1.000043]\n",
      "epoch:7 step:27810[D loss: 0.999975] [G loss: 1.000060]\n",
      "epoch:7 step:27815[D loss: 0.999992] [G loss: 1.000068]\n",
      "epoch:7 step:27820[D loss: 0.999965] [G loss: 1.000075]\n",
      "epoch:7 step:27825[D loss: 0.999976] [G loss: 1.000060]\n",
      "epoch:7 step:27830[D loss: 0.999973] [G loss: 1.000078]\n",
      "epoch:7 step:27835[D loss: 0.999979] [G loss: 1.000050]\n",
      "epoch:7 step:27840[D loss: 1.000012] [G loss: 0.999987]\n",
      "epoch:7 step:27845[D loss: 0.999971] [G loss: 1.000039]\n",
      "epoch:7 step:27850[D loss: 0.999952] [G loss: 1.000084]\n",
      "epoch:7 step:27855[D loss: 0.999974] [G loss: 1.000050]\n",
      "epoch:7 step:27860[D loss: 0.999987] [G loss: 1.000057]\n",
      "epoch:7 step:27865[D loss: 0.999969] [G loss: 1.000067]\n",
      "epoch:7 step:27870[D loss: 0.999979] [G loss: 1.000080]\n",
      "epoch:7 step:27875[D loss: 0.999976] [G loss: 1.000079]\n",
      "epoch:7 step:27880[D loss: 0.999967] [G loss: 1.000082]\n",
      "epoch:7 step:27885[D loss: 0.999975] [G loss: 1.000057]\n",
      "epoch:7 step:27890[D loss: 0.999982] [G loss: 1.000026]\n",
      "epoch:7 step:27895[D loss: 1.000059] [G loss: 0.999882]\n",
      "epoch:7 step:27900[D loss: 0.999980] [G loss: 1.000046]\n",
      "epoch:7 step:27905[D loss: 0.999975] [G loss: 1.000030]\n",
      "epoch:7 step:27910[D loss: 0.999980] [G loss: 1.000091]\n",
      "epoch:7 step:27915[D loss: 0.999946] [G loss: 1.000087]\n",
      "epoch:7 step:27920[D loss: 0.999957] [G loss: 1.000096]\n",
      "epoch:7 step:27925[D loss: 0.999962] [G loss: 1.000087]\n",
      "epoch:7 step:27930[D loss: 0.999975] [G loss: 1.000070]\n",
      "epoch:7 step:27935[D loss: 0.999977] [G loss: 1.000069]\n",
      "epoch:7 step:27940[D loss: 0.999985] [G loss: 1.000051]\n",
      "epoch:7 step:27945[D loss: 0.999994] [G loss: 1.000034]\n",
      "epoch:7 step:27950[D loss: 1.000013] [G loss: 0.999997]\n",
      "epoch:7 step:27955[D loss: 0.999984] [G loss: 1.000021]\n",
      "epoch:7 step:27960[D loss: 0.999968] [G loss: 1.000073]\n",
      "epoch:7 step:27965[D loss: 0.999960] [G loss: 1.000078]\n",
      "epoch:7 step:27970[D loss: 0.999970] [G loss: 1.000072]\n",
      "epoch:7 step:27975[D loss: 0.999976] [G loss: 1.000046]\n",
      "epoch:7 step:27980[D loss: 0.999973] [G loss: 1.000060]\n",
      "epoch:7 step:27985[D loss: 1.000006] [G loss: 1.000004]\n",
      "epoch:7 step:27990[D loss: 1.000058] [G loss: 0.999939]\n",
      "epoch:7 step:27995[D loss: 0.999915] [G loss: 1.000115]\n",
      "epoch:7 step:28000[D loss: 0.999967] [G loss: 1.000062]\n",
      "##############\n",
      "[0.86797119 0.83450719 0.83232982 0.82205276 0.78766457 0.85497622\n",
      " 0.86640056 0.84099899 0.80324594 0.83427044]\n",
      "##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:7 step:28005[D loss: 0.999979] [G loss: 1.000077]\n",
      "epoch:7 step:28010[D loss: 0.999973] [G loss: 1.000052]\n",
      "epoch:7 step:28015[D loss: 0.999979] [G loss: 1.000062]\n",
      "epoch:7 step:28020[D loss: 0.999970] [G loss: 1.000059]\n",
      "epoch:7 step:28025[D loss: 0.999970] [G loss: 1.000069]\n",
      "epoch:7 step:28030[D loss: 0.999967] [G loss: 1.000071]\n",
      "epoch:7 step:28035[D loss: 0.999965] [G loss: 1.000079]\n",
      "epoch:7 step:28040[D loss: 0.999986] [G loss: 1.000023]\n",
      "epoch:7 step:28045[D loss: 0.999967] [G loss: 1.000077]\n",
      "epoch:7 step:28050[D loss: 0.999971] [G loss: 1.000061]\n",
      "epoch:7 step:28055[D loss: 0.999971] [G loss: 1.000074]\n",
      "epoch:7 step:28060[D loss: 0.999982] [G loss: 1.000066]\n",
      "epoch:7 step:28065[D loss: 0.999966] [G loss: 1.000065]\n",
      "epoch:7 step:28070[D loss: 0.999979] [G loss: 1.000057]\n",
      "epoch:7 step:28075[D loss: 0.999969] [G loss: 1.000069]\n",
      "epoch:7 step:28080[D loss: 0.999969] [G loss: 1.000067]\n",
      "epoch:7 step:28085[D loss: 0.999981] [G loss: 1.000040]\n",
      "epoch:7 step:28090[D loss: 0.999958] [G loss: 1.000080]\n",
      "epoch:7 step:28095[D loss: 0.999978] [G loss: 1.000092]\n",
      "epoch:7 step:28100[D loss: 0.999969] [G loss: 1.000074]\n",
      "epoch:7 step:28105[D loss: 0.999992] [G loss: 1.000040]\n",
      "epoch:7 step:28110[D loss: 0.999984] [G loss: 1.000047]\n",
      "epoch:7 step:28115[D loss: 0.999976] [G loss: 1.000073]\n",
      "epoch:7 step:28120[D loss: 0.999966] [G loss: 1.000085]\n",
      "epoch:7 step:28125[D loss: 0.999975] [G loss: 1.000070]\n",
      "epoch:7 step:28130[D loss: 1.000013] [G loss: 1.000022]\n",
      "epoch:7 step:28135[D loss: 0.999971] [G loss: 1.000083]\n",
      "epoch:7 step:28140[D loss: 0.999955] [G loss: 1.000100]\n",
      "epoch:7 step:28145[D loss: 0.999967] [G loss: 1.000075]\n",
      "epoch:7 step:28150[D loss: 0.999969] [G loss: 1.000069]\n",
      "epoch:7 step:28155[D loss: 0.999975] [G loss: 1.000044]\n",
      "epoch:7 step:28160[D loss: 0.999976] [G loss: 1.000062]\n",
      "epoch:7 step:28165[D loss: 0.999977] [G loss: 1.000063]\n",
      "epoch:7 step:28170[D loss: 0.999969] [G loss: 1.000066]\n",
      "epoch:7 step:28175[D loss: 0.999971] [G loss: 1.000069]\n",
      "epoch:7 step:28180[D loss: 0.999972] [G loss: 1.000058]\n",
      "epoch:7 step:28185[D loss: 0.999969] [G loss: 1.000063]\n",
      "epoch:7 step:28190[D loss: 0.999975] [G loss: 1.000074]\n",
      "epoch:7 step:28195[D loss: 0.999971] [G loss: 1.000081]\n",
      "epoch:7 step:28200[D loss: 0.999996] [G loss: 1.000016]\n",
      "##############\n",
      "[0.86645899 0.84241491 0.82271742 0.81450175 0.78069216 0.84274551\n",
      " 0.85206943 0.83291115 0.80422911 0.83195143]\n",
      "##########\n",
      "epoch:7 step:28205[D loss: 0.999977] [G loss: 1.000049]\n",
      "epoch:7 step:28210[D loss: 0.999988] [G loss: 1.000006]\n",
      "epoch:7 step:28215[D loss: 0.999993] [G loss: 0.999990]\n",
      "epoch:7 step:28220[D loss: 0.999975] [G loss: 1.000037]\n",
      "epoch:7 step:28225[D loss: 0.999964] [G loss: 1.000064]\n",
      "epoch:7 step:28230[D loss: 0.999970] [G loss: 1.000088]\n",
      "epoch:7 step:28235[D loss: 0.999962] [G loss: 1.000086]\n",
      "epoch:7 step:28240[D loss: 0.999965] [G loss: 1.000078]\n",
      "epoch:7 step:28245[D loss: 0.999972] [G loss: 1.000073]\n",
      "epoch:7 step:28250[D loss: 1.000003] [G loss: 1.000051]\n",
      "epoch:7 step:28255[D loss: 0.999980] [G loss: 1.000027]\n",
      "epoch:7 step:28260[D loss: 0.999996] [G loss: 1.000075]\n",
      "epoch:7 step:28265[D loss: 0.999960] [G loss: 1.000074]\n",
      "epoch:7 step:28270[D loss: 0.999975] [G loss: 1.000071]\n",
      "epoch:7 step:28275[D loss: 0.999981] [G loss: 1.000053]\n",
      "epoch:7 step:28280[D loss: 0.999977] [G loss: 1.000031]\n",
      "epoch:7 step:28285[D loss: 0.999998] [G loss: 1.000020]\n",
      "epoch:7 step:28290[D loss: 0.999969] [G loss: 1.000066]\n",
      "epoch:7 step:28295[D loss: 0.999985] [G loss: 1.000054]\n",
      "epoch:7 step:28300[D loss: 0.999967] [G loss: 1.000069]\n",
      "epoch:7 step:28305[D loss: 0.999966] [G loss: 1.000073]\n",
      "epoch:7 step:28310[D loss: 0.999974] [G loss: 1.000063]\n",
      "epoch:7 step:28315[D loss: 0.999987] [G loss: 1.000056]\n",
      "epoch:7 step:28320[D loss: 1.000006] [G loss: 1.000029]\n",
      "epoch:7 step:28325[D loss: 0.999971] [G loss: 1.000044]\n",
      "epoch:7 step:28330[D loss: 0.999966] [G loss: 1.000062]\n",
      "epoch:7 step:28335[D loss: 0.999970] [G loss: 1.000072]\n",
      "epoch:7 step:28340[D loss: 0.999965] [G loss: 1.000078]\n",
      "epoch:7 step:28345[D loss: 0.999970] [G loss: 1.000083]\n",
      "epoch:7 step:28350[D loss: 0.999973] [G loss: 1.000065]\n",
      "epoch:7 step:28355[D loss: 0.999971] [G loss: 1.000069]\n",
      "epoch:7 step:28360[D loss: 0.999985] [G loss: 1.000079]\n",
      "epoch:7 step:28365[D loss: 0.999962] [G loss: 1.000079]\n",
      "epoch:7 step:28370[D loss: 0.999968] [G loss: 1.000083]\n",
      "epoch:7 step:28375[D loss: 0.999966] [G loss: 1.000075]\n",
      "epoch:7 step:28380[D loss: 0.999963] [G loss: 1.000068]\n",
      "epoch:7 step:28385[D loss: 0.999973] [G loss: 1.000068]\n",
      "epoch:7 step:28390[D loss: 0.999971] [G loss: 1.000058]\n",
      "epoch:7 step:28395[D loss: 0.999975] [G loss: 1.000066]\n",
      "epoch:7 step:28400[D loss: 0.999990] [G loss: 1.000041]\n",
      "##############\n",
      "[0.87252069 0.83860656 0.83112217 0.84114553 0.8070675  0.82326734\n",
      " 0.88376564 0.84728781 0.80084093 0.84461572]\n",
      "##########\n",
      "epoch:7 step:28405[D loss: 0.999961] [G loss: 1.000074]\n",
      "epoch:7 step:28410[D loss: 0.999980] [G loss: 1.000059]\n",
      "epoch:7 step:28415[D loss: 1.000014] [G loss: 0.999994]\n",
      "epoch:7 step:28420[D loss: 0.999972] [G loss: 1.000071]\n",
      "epoch:7 step:28425[D loss: 0.999984] [G loss: 1.000044]\n",
      "epoch:7 step:28430[D loss: 0.999964] [G loss: 1.000065]\n",
      "epoch:7 step:28435[D loss: 0.999967] [G loss: 1.000081]\n",
      "epoch:7 step:28440[D loss: 0.999971] [G loss: 1.000073]\n",
      "epoch:7 step:28445[D loss: 0.999984] [G loss: 1.000054]\n",
      "epoch:7 step:28450[D loss: 0.999970] [G loss: 1.000065]\n",
      "epoch:7 step:28455[D loss: 0.999994] [G loss: 1.000054]\n",
      "epoch:7 step:28460[D loss: 0.999963] [G loss: 1.000076]\n",
      "epoch:7 step:28465[D loss: 0.999942] [G loss: 1.000113]\n",
      "epoch:7 step:28470[D loss: 0.999968] [G loss: 1.000075]\n",
      "epoch:7 step:28475[D loss: 0.999967] [G loss: 1.000071]\n",
      "epoch:7 step:28480[D loss: 0.999973] [G loss: 1.000070]\n",
      "epoch:7 step:28485[D loss: 0.999996] [G loss: 1.000001]\n",
      "epoch:7 step:28490[D loss: 0.999992] [G loss: 1.000046]\n",
      "epoch:7 step:28495[D loss: 1.000007] [G loss: 0.999993]\n",
      "epoch:7 step:28500[D loss: 0.999919] [G loss: 1.000113]\n",
      "epoch:7 step:28505[D loss: 0.999962] [G loss: 1.000077]\n",
      "epoch:7 step:28510[D loss: 0.999971] [G loss: 1.000066]\n",
      "epoch:7 step:28515[D loss: 0.999979] [G loss: 1.000060]\n",
      "epoch:7 step:28520[D loss: 0.999968] [G loss: 1.000074]\n",
      "epoch:7 step:28525[D loss: 1.000000] [G loss: 0.999996]\n",
      "epoch:7 step:28530[D loss: 0.999988] [G loss: 1.000019]\n",
      "epoch:7 step:28535[D loss: 0.999979] [G loss: 1.000068]\n",
      "epoch:7 step:28540[D loss: 0.999964] [G loss: 1.000082]\n",
      "epoch:7 step:28545[D loss: 0.999972] [G loss: 1.000076]\n",
      "epoch:7 step:28550[D loss: 0.999977] [G loss: 1.000071]\n",
      "epoch:7 step:28555[D loss: 0.999969] [G loss: 1.000091]\n",
      "epoch:7 step:28560[D loss: 0.999960] [G loss: 1.000095]\n",
      "epoch:7 step:28565[D loss: 0.999973] [G loss: 1.000079]\n",
      "epoch:7 step:28570[D loss: 0.999966] [G loss: 1.000076]\n",
      "epoch:7 step:28575[D loss: 0.999974] [G loss: 1.000070]\n",
      "epoch:7 step:28580[D loss: 0.999981] [G loss: 1.000033]\n",
      "epoch:7 step:28585[D loss: 0.999964] [G loss: 1.000037]\n",
      "epoch:7 step:28590[D loss: 0.999963] [G loss: 1.000056]\n",
      "epoch:7 step:28595[D loss: 0.999972] [G loss: 1.000054]\n",
      "epoch:7 step:28600[D loss: 0.999965] [G loss: 1.000068]\n",
      "##############\n",
      "[0.87491167 0.85511713 0.821361   0.80296192 0.79829054 0.83295227\n",
      " 0.87641272 0.83606647 0.81012376 0.84375204]\n",
      "##########\n",
      "epoch:7 step:28605[D loss: 0.999982] [G loss: 1.000066]\n",
      "epoch:7 step:28610[D loss: 0.999974] [G loss: 1.000072]\n",
      "epoch:7 step:28615[D loss: 0.999963] [G loss: 1.000087]\n",
      "epoch:7 step:28620[D loss: 0.999987] [G loss: 1.000042]\n",
      "epoch:7 step:28625[D loss: 0.999996] [G loss: 1.000017]\n",
      "epoch:7 step:28630[D loss: 0.999951] [G loss: 1.000086]\n",
      "epoch:7 step:28635[D loss: 0.999970] [G loss: 1.000075]\n",
      "epoch:7 step:28640[D loss: 0.999976] [G loss: 1.000064]\n",
      "epoch:7 step:28645[D loss: 0.999968] [G loss: 1.000063]\n",
      "epoch:7 step:28650[D loss: 0.999987] [G loss: 1.000033]\n",
      "epoch:7 step:28655[D loss: 0.999985] [G loss: 1.000007]\n",
      "epoch:7 step:28660[D loss: 0.999989] [G loss: 1.000037]\n",
      "epoch:7 step:28665[D loss: 0.999966] [G loss: 1.000065]\n",
      "epoch:7 step:28670[D loss: 0.999977] [G loss: 1.000053]\n",
      "epoch:7 step:28675[D loss: 0.999973] [G loss: 1.000052]\n",
      "epoch:7 step:28680[D loss: 0.999981] [G loss: 1.000053]\n",
      "epoch:7 step:28685[D loss: 0.999978] [G loss: 1.000059]\n",
      "epoch:7 step:28690[D loss: 0.999976] [G loss: 1.000053]\n",
      "epoch:7 step:28695[D loss: 0.999973] [G loss: 1.000027]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:7 step:28700[D loss: 0.999962] [G loss: 1.000094]\n",
      "epoch:7 step:28705[D loss: 0.999973] [G loss: 1.000057]\n",
      "epoch:7 step:28710[D loss: 0.999963] [G loss: 1.000065]\n",
      "epoch:7 step:28715[D loss: 0.999970] [G loss: 1.000070]\n",
      "epoch:7 step:28720[D loss: 0.999977] [G loss: 1.000050]\n",
      "epoch:7 step:28725[D loss: 0.999999] [G loss: 1.000027]\n",
      "epoch:7 step:28730[D loss: 0.999962] [G loss: 1.000052]\n",
      "epoch:7 step:28735[D loss: 0.999963] [G loss: 1.000070]\n",
      "epoch:7 step:28740[D loss: 0.999973] [G loss: 1.000066]\n",
      "epoch:7 step:28745[D loss: 0.999975] [G loss: 1.000080]\n",
      "epoch:7 step:28750[D loss: 0.999973] [G loss: 1.000083]\n",
      "epoch:7 step:28755[D loss: 0.999984] [G loss: 1.000044]\n",
      "epoch:7 step:28760[D loss: 1.000019] [G loss: 0.999986]\n",
      "epoch:7 step:28765[D loss: 0.999996] [G loss: 1.000038]\n",
      "epoch:7 step:28770[D loss: 0.999968] [G loss: 1.000033]\n",
      "epoch:7 step:28775[D loss: 0.999958] [G loss: 1.000090]\n",
      "epoch:7 step:28780[D loss: 0.999968] [G loss: 1.000072]\n",
      "epoch:7 step:28785[D loss: 0.999970] [G loss: 1.000060]\n",
      "epoch:7 step:28790[D loss: 0.999977] [G loss: 1.000060]\n",
      "epoch:7 step:28795[D loss: 0.999977] [G loss: 1.000050]\n",
      "epoch:7 step:28800[D loss: 0.999988] [G loss: 1.000030]\n",
      "##############\n",
      "[0.8569028  0.84789506 0.83288899 0.83659259 0.80970006 0.82492094\n",
      " 0.87282358 0.83894536 0.82518719 0.82531972]\n",
      "##########\n",
      "epoch:7 step:28805[D loss: 0.999966] [G loss: 1.000066]\n",
      "epoch:7 step:28810[D loss: 0.999989] [G loss: 1.000038]\n",
      "epoch:7 step:28815[D loss: 0.999974] [G loss: 1.000073]\n",
      "epoch:7 step:28820[D loss: 0.999967] [G loss: 1.000073]\n",
      "epoch:7 step:28825[D loss: 0.999975] [G loss: 1.000077]\n",
      "epoch:7 step:28830[D loss: 0.999967] [G loss: 1.000091]\n",
      "epoch:7 step:28835[D loss: 0.999967] [G loss: 1.000078]\n",
      "epoch:7 step:28840[D loss: 0.999970] [G loss: 1.000073]\n",
      "epoch:7 step:28845[D loss: 0.999970] [G loss: 1.000078]\n",
      "epoch:7 step:28850[D loss: 0.999968] [G loss: 1.000079]\n",
      "epoch:7 step:28855[D loss: 0.999973] [G loss: 1.000065]\n",
      "epoch:7 step:28860[D loss: 0.999963] [G loss: 1.000076]\n",
      "epoch:7 step:28865[D loss: 0.999970] [G loss: 1.000079]\n",
      "epoch:7 step:28870[D loss: 0.999975] [G loss: 1.000066]\n",
      "epoch:7 step:28875[D loss: 0.999975] [G loss: 1.000062]\n",
      "epoch:7 step:28880[D loss: 0.999972] [G loss: 1.000070]\n",
      "epoch:7 step:28885[D loss: 0.999977] [G loss: 1.000069]\n",
      "epoch:7 step:28890[D loss: 0.999963] [G loss: 1.000078]\n",
      "epoch:7 step:28895[D loss: 0.999971] [G loss: 1.000059]\n",
      "epoch:7 step:28900[D loss: 0.999973] [G loss: 1.000053]\n",
      "epoch:7 step:28905[D loss: 0.999961] [G loss: 1.000077]\n",
      "epoch:7 step:28910[D loss: 0.999979] [G loss: 1.000065]\n",
      "epoch:7 step:28915[D loss: 0.999976] [G loss: 1.000059]\n",
      "epoch:7 step:28920[D loss: 0.999981] [G loss: 1.000054]\n",
      "epoch:7 step:28925[D loss: 0.999961] [G loss: 1.000077]\n",
      "epoch:7 step:28930[D loss: 0.999968] [G loss: 1.000066]\n",
      "epoch:7 step:28935[D loss: 0.999969] [G loss: 1.000064]\n",
      "epoch:7 step:28940[D loss: 0.999975] [G loss: 1.000055]\n",
      "epoch:7 step:28945[D loss: 0.999978] [G loss: 1.000071]\n",
      "epoch:7 step:28950[D loss: 0.999981] [G loss: 1.000048]\n",
      "epoch:7 step:28955[D loss: 0.999973] [G loss: 1.000048]\n",
      "epoch:7 step:28960[D loss: 1.000000] [G loss: 0.999995]\n",
      "epoch:7 step:28965[D loss: 1.000002] [G loss: 1.000003]\n",
      "epoch:7 step:28970[D loss: 0.999947] [G loss: 1.000084]\n",
      "epoch:7 step:28975[D loss: 0.999960] [G loss: 1.000074]\n",
      "epoch:7 step:28980[D loss: 1.000013] [G loss: 0.999968]\n",
      "epoch:7 step:28985[D loss: 0.999958] [G loss: 1.000073]\n",
      "epoch:7 step:28990[D loss: 0.999977] [G loss: 1.000051]\n",
      "epoch:7 step:28995[D loss: 0.999982] [G loss: 1.000067]\n",
      "epoch:7 step:29000[D loss: 0.999970] [G loss: 1.000068]\n",
      "##############\n",
      "[0.89467462 0.85264045 0.82773717 0.82493258 0.799635   0.8348488\n",
      " 0.89021585 0.83824994 0.8170628  0.83357874]\n",
      "##########\n",
      "epoch:7 step:29005[D loss: 0.999963] [G loss: 1.000067]\n",
      "epoch:7 step:29010[D loss: 0.999974] [G loss: 1.000062]\n",
      "epoch:7 step:29015[D loss: 0.999977] [G loss: 1.000042]\n",
      "epoch:7 step:29020[D loss: 1.000017] [G loss: 0.999996]\n",
      "epoch:7 step:29025[D loss: 0.999967] [G loss: 1.000074]\n",
      "epoch:7 step:29030[D loss: 0.999960] [G loss: 1.000071]\n",
      "epoch:7 step:29035[D loss: 0.999975] [G loss: 1.000062]\n",
      "epoch:7 step:29040[D loss: 0.999971] [G loss: 1.000059]\n",
      "epoch:7 step:29045[D loss: 0.999979] [G loss: 1.000056]\n",
      "epoch:7 step:29050[D loss: 0.999963] [G loss: 1.000060]\n",
      "epoch:7 step:29055[D loss: 0.999972] [G loss: 1.000065]\n",
      "epoch:7 step:29060[D loss: 0.999969] [G loss: 1.000071]\n",
      "epoch:7 step:29065[D loss: 0.999970] [G loss: 1.000069]\n",
      "epoch:7 step:29070[D loss: 0.999968] [G loss: 1.000060]\n",
      "epoch:7 step:29075[D loss: 0.999968] [G loss: 1.000060]\n",
      "epoch:7 step:29080[D loss: 0.999978] [G loss: 1.000064]\n",
      "epoch:7 step:29085[D loss: 0.999988] [G loss: 1.000021]\n",
      "epoch:7 step:29090[D loss: 0.999968] [G loss: 1.000079]\n",
      "epoch:7 step:29095[D loss: 0.999967] [G loss: 1.000070]\n",
      "epoch:7 step:29100[D loss: 0.999976] [G loss: 1.000067]\n",
      "epoch:7 step:29105[D loss: 0.999973] [G loss: 1.000064]\n",
      "epoch:7 step:29110[D loss: 0.999978] [G loss: 1.000053]\n",
      "epoch:7 step:29115[D loss: 0.999969] [G loss: 1.000067]\n",
      "epoch:7 step:29120[D loss: 0.999971] [G loss: 1.000057]\n",
      "epoch:7 step:29125[D loss: 0.999982] [G loss: 1.000041]\n",
      "epoch:7 step:29130[D loss: 0.999985] [G loss: 1.000055]\n",
      "epoch:7 step:29135[D loss: 0.999973] [G loss: 1.000056]\n",
      "epoch:7 step:29140[D loss: 0.999969] [G loss: 1.000092]\n",
      "epoch:7 step:29145[D loss: 0.999958] [G loss: 1.000075]\n",
      "epoch:7 step:29150[D loss: 0.999975] [G loss: 1.000073]\n",
      "epoch:7 step:29155[D loss: 0.999964] [G loss: 1.000078]\n",
      "epoch:7 step:29160[D loss: 0.999966] [G loss: 1.000074]\n",
      "epoch:7 step:29165[D loss: 0.999989] [G loss: 1.000036]\n",
      "epoch:7 step:29170[D loss: 1.000011] [G loss: 0.999986]\n",
      "epoch:7 step:29175[D loss: 0.999976] [G loss: 1.000023]\n",
      "epoch:7 step:29180[D loss: 0.999963] [G loss: 1.000069]\n",
      "epoch:7 step:29185[D loss: 0.999962] [G loss: 1.000071]\n",
      "epoch:7 step:29190[D loss: 0.999978] [G loss: 1.000061]\n",
      "epoch:7 step:29195[D loss: 0.999977] [G loss: 1.000062]\n",
      "epoch:7 step:29200[D loss: 0.999971] [G loss: 1.000066]\n",
      "##############\n",
      "[0.86070448 0.85299069 0.81227526 0.81878303 0.79284931 0.82924196\n",
      " 0.86229118 0.8751338  0.81246569 0.85132252]\n",
      "##########\n",
      "epoch:7 step:29205[D loss: 0.999978] [G loss: 1.000057]\n",
      "epoch:7 step:29210[D loss: 0.999973] [G loss: 1.000066]\n",
      "epoch:7 step:29215[D loss: 0.999974] [G loss: 1.000073]\n",
      "epoch:7 step:29220[D loss: 0.999966] [G loss: 1.000071]\n",
      "epoch:7 step:29225[D loss: 0.999981] [G loss: 1.000058]\n",
      "epoch:7 step:29230[D loss: 0.999983] [G loss: 1.000047]\n",
      "epoch:7 step:29235[D loss: 0.999969] [G loss: 1.000079]\n",
      "epoch:7 step:29240[D loss: 0.999990] [G loss: 1.000020]\n",
      "epoch:7 step:29245[D loss: 0.999993] [G loss: 1.000066]\n",
      "epoch:7 step:29250[D loss: 0.999976] [G loss: 1.000077]\n",
      "epoch:7 step:29255[D loss: 0.999983] [G loss: 1.000051]\n",
      "epoch:7 step:29260[D loss: 0.999972] [G loss: 1.000078]\n",
      "epoch:7 step:29265[D loss: 0.999971] [G loss: 1.000062]\n",
      "epoch:7 step:29270[D loss: 1.000009] [G loss: 0.999997]\n",
      "epoch:7 step:29275[D loss: 0.999969] [G loss: 1.000044]\n",
      "epoch:7 step:29280[D loss: 0.999970] [G loss: 1.000062]\n",
      "epoch:7 step:29285[D loss: 0.999973] [G loss: 1.000067]\n",
      "epoch:7 step:29290[D loss: 0.999974] [G loss: 1.000059]\n",
      "epoch:7 step:29295[D loss: 0.999966] [G loss: 1.000066]\n",
      "epoch:7 step:29300[D loss: 0.999973] [G loss: 1.000064]\n",
      "epoch:7 step:29305[D loss: 0.999972] [G loss: 1.000072]\n",
      "epoch:7 step:29310[D loss: 0.999974] [G loss: 1.000052]\n",
      "epoch:7 step:29315[D loss: 0.999979] [G loss: 1.000048]\n",
      "epoch:7 step:29320[D loss: 0.999967] [G loss: 1.000067]\n",
      "epoch:7 step:29325[D loss: 0.999971] [G loss: 1.000067]\n",
      "epoch:7 step:29330[D loss: 0.999969] [G loss: 1.000064]\n",
      "epoch:7 step:29335[D loss: 0.999973] [G loss: 1.000059]\n",
      "epoch:7 step:29340[D loss: 0.999976] [G loss: 1.000063]\n",
      "epoch:7 step:29345[D loss: 0.999979] [G loss: 1.000056]\n",
      "epoch:7 step:29350[D loss: 0.999973] [G loss: 1.000053]\n",
      "epoch:7 step:29355[D loss: 0.999976] [G loss: 1.000058]\n",
      "epoch:7 step:29360[D loss: 0.999970] [G loss: 1.000059]\n",
      "epoch:7 step:29365[D loss: 0.999970] [G loss: 1.000062]\n",
      "epoch:7 step:29370[D loss: 0.999971] [G loss: 1.000065]\n",
      "epoch:7 step:29375[D loss: 0.999966] [G loss: 1.000061]\n",
      "epoch:7 step:29380[D loss: 0.999964] [G loss: 1.000083]\n",
      "epoch:7 step:29385[D loss: 0.999966] [G loss: 1.000086]\n",
      "epoch:7 step:29390[D loss: 0.999963] [G loss: 1.000070]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:7 step:29395[D loss: 0.999973] [G loss: 1.000072]\n",
      "epoch:7 step:29400[D loss: 0.999975] [G loss: 1.000057]\n",
      "##############\n",
      "[0.87668141 0.88031417 0.80116962 0.82540382 0.80708393 0.803334\n",
      " 0.87037303 0.83481654 0.80718836 0.84935441]\n",
      "##########\n",
      "epoch:7 step:29405[D loss: 0.999968] [G loss: 1.000073]\n",
      "epoch:7 step:29410[D loss: 0.999963] [G loss: 1.000074]\n",
      "epoch:7 step:29415[D loss: 0.999968] [G loss: 1.000077]\n",
      "epoch:7 step:29420[D loss: 0.999973] [G loss: 1.000060]\n",
      "epoch:7 step:29425[D loss: 0.999970] [G loss: 1.000064]\n",
      "epoch:7 step:29430[D loss: 0.999974] [G loss: 1.000064]\n",
      "epoch:7 step:29435[D loss: 0.999964] [G loss: 1.000063]\n",
      "epoch:7 step:29440[D loss: 1.000030] [G loss: 0.999995]\n",
      "epoch:7 step:29445[D loss: 0.999956] [G loss: 1.000060]\n",
      "epoch:7 step:29450[D loss: 0.999967] [G loss: 1.000057]\n",
      "epoch:7 step:29455[D loss: 0.999978] [G loss: 1.000072]\n",
      "epoch:7 step:29460[D loss: 0.999972] [G loss: 1.000056]\n",
      "epoch:7 step:29465[D loss: 0.999976] [G loss: 1.000054]\n",
      "epoch:7 step:29470[D loss: 0.999976] [G loss: 1.000053]\n",
      "epoch:7 step:29475[D loss: 0.999988] [G loss: 1.000038]\n",
      "epoch:7 step:29480[D loss: 0.999992] [G loss: 1.000059]\n",
      "epoch:7 step:29485[D loss: 0.999990] [G loss: 0.999973]\n",
      "epoch:7 step:29490[D loss: 0.999997] [G loss: 1.000007]\n",
      "epoch:7 step:29495[D loss: 0.999963] [G loss: 1.000072]\n",
      "epoch:7 step:29500[D loss: 0.999966] [G loss: 1.000076]\n",
      "epoch:7 step:29505[D loss: 0.999970] [G loss: 1.000066]\n",
      "epoch:7 step:29510[D loss: 0.999980] [G loss: 1.000062]\n",
      "epoch:7 step:29515[D loss: 0.999968] [G loss: 1.000062]\n",
      "epoch:7 step:29520[D loss: 0.999972] [G loss: 1.000072]\n",
      "epoch:7 step:29525[D loss: 0.999976] [G loss: 1.000059]\n",
      "epoch:7 step:29530[D loss: 0.999970] [G loss: 1.000066]\n",
      "epoch:7 step:29535[D loss: 0.999973] [G loss: 1.000069]\n",
      "epoch:7 step:29540[D loss: 0.999970] [G loss: 1.000065]\n",
      "epoch:7 step:29545[D loss: 0.999975] [G loss: 1.000065]\n",
      "epoch:7 step:29550[D loss: 0.999971] [G loss: 1.000058]\n",
      "epoch:7 step:29555[D loss: 0.999964] [G loss: 1.000065]\n",
      "epoch:7 step:29560[D loss: 0.999976] [G loss: 1.000064]\n",
      "epoch:7 step:29565[D loss: 0.999980] [G loss: 1.000040]\n",
      "epoch:7 step:29570[D loss: 0.999985] [G loss: 1.000067]\n",
      "epoch:7 step:29575[D loss: 0.999960] [G loss: 1.000103]\n",
      "epoch:7 step:29580[D loss: 0.999970] [G loss: 1.000063]\n",
      "epoch:7 step:29585[D loss: 0.999961] [G loss: 1.000082]\n",
      "epoch:7 step:29590[D loss: 0.999976] [G loss: 1.000066]\n",
      "epoch:7 step:29595[D loss: 0.999972] [G loss: 1.000068]\n",
      "epoch:7 step:29600[D loss: 0.999980] [G loss: 1.000054]\n",
      "##############\n",
      "[0.87157489 0.86013859 0.81360292 0.84362998 0.81172763 0.83125158\n",
      " 0.87611293 0.84476952 0.8353439  0.83548799]\n",
      "##########\n",
      "epoch:7 step:29605[D loss: 0.999963] [G loss: 1.000065]\n",
      "epoch:7 step:29610[D loss: 0.999974] [G loss: 1.000057]\n",
      "epoch:7 step:29615[D loss: 0.999989] [G loss: 1.000030]\n",
      "epoch:7 step:29620[D loss: 0.999964] [G loss: 1.000072]\n",
      "epoch:7 step:29625[D loss: 0.999972] [G loss: 1.000063]\n",
      "epoch:7 step:29630[D loss: 0.999970] [G loss: 1.000065]\n",
      "epoch:7 step:29635[D loss: 0.999970] [G loss: 1.000071]\n",
      "epoch:7 step:29640[D loss: 0.999970] [G loss: 1.000074]\n",
      "epoch:7 step:29645[D loss: 0.999975] [G loss: 1.000069]\n",
      "epoch:7 step:29650[D loss: 0.999983] [G loss: 1.000073]\n",
      "epoch:7 step:29655[D loss: 1.000018] [G loss: 0.999964]\n",
      "epoch:7 step:29660[D loss: 0.999963] [G loss: 1.000065]\n",
      "epoch:7 step:29665[D loss: 0.999978] [G loss: 1.000062]\n",
      "epoch:7 step:29670[D loss: 0.999973] [G loss: 1.000068]\n",
      "epoch:7 step:29675[D loss: 0.999981] [G loss: 1.000054]\n",
      "epoch:7 step:29680[D loss: 0.999970] [G loss: 1.000079]\n",
      "epoch:7 step:29685[D loss: 0.999977] [G loss: 1.000056]\n",
      "epoch:7 step:29690[D loss: 0.999971] [G loss: 1.000070]\n",
      "epoch:7 step:29695[D loss: 0.999968] [G loss: 1.000071]\n",
      "epoch:7 step:29700[D loss: 0.999983] [G loss: 1.000051]\n",
      "epoch:7 step:29705[D loss: 1.000004] [G loss: 1.000032]\n",
      "epoch:7 step:29710[D loss: 0.999968] [G loss: 1.000072]\n",
      "epoch:7 step:29715[D loss: 0.999971] [G loss: 1.000071]\n",
      "epoch:7 step:29720[D loss: 0.999984] [G loss: 1.000045]\n",
      "epoch:7 step:29725[D loss: 0.999963] [G loss: 1.000080]\n",
      "epoch:7 step:29730[D loss: 0.999961] [G loss: 1.000071]\n",
      "epoch:7 step:29735[D loss: 0.999972] [G loss: 1.000069]\n",
      "epoch:7 step:29740[D loss: 0.999977] [G loss: 1.000073]\n",
      "epoch:7 step:29745[D loss: 0.999979] [G loss: 1.000077]\n",
      "epoch:7 step:29750[D loss: 0.999956] [G loss: 1.000076]\n",
      "epoch:7 step:29755[D loss: 0.999991] [G loss: 1.000057]\n",
      "epoch:7 step:29760[D loss: 0.999969] [G loss: 1.000080]\n",
      "epoch:7 step:29765[D loss: 0.999969] [G loss: 1.000079]\n",
      "epoch:7 step:29770[D loss: 0.999978] [G loss: 1.000055]\n",
      "epoch:7 step:29775[D loss: 0.999975] [G loss: 1.000049]\n",
      "epoch:7 step:29780[D loss: 0.999968] [G loss: 1.000068]\n",
      "epoch:7 step:29785[D loss: 0.999974] [G loss: 1.000068]\n",
      "epoch:7 step:29790[D loss: 0.999995] [G loss: 1.000033]\n",
      "epoch:7 step:29795[D loss: 0.999956] [G loss: 1.000111]\n",
      "epoch:7 step:29800[D loss: 0.999972] [G loss: 1.000115]\n",
      "##############\n",
      "[0.86688273 0.86181661 0.8203145  0.81919903 0.77298008 0.8233776\n",
      " 0.8589515  0.83757803 0.83176098 0.8410072 ]\n",
      "##########\n",
      "epoch:7 step:29805[D loss: 0.999948] [G loss: 1.000116]\n",
      "epoch:7 step:29810[D loss: 0.999973] [G loss: 1.000076]\n",
      "epoch:7 step:29815[D loss: 0.999973] [G loss: 1.000066]\n",
      "epoch:7 step:29820[D loss: 0.999991] [G loss: 1.000006]\n",
      "epoch:7 step:29825[D loss: 1.000006] [G loss: 0.999958]\n",
      "epoch:7 step:29830[D loss: 0.999988] [G loss: 1.000016]\n",
      "epoch:7 step:29835[D loss: 0.999977] [G loss: 1.000054]\n",
      "epoch:7 step:29840[D loss: 0.999943] [G loss: 1.000066]\n",
      "epoch:7 step:29845[D loss: 0.999961] [G loss: 1.000074]\n",
      "epoch:7 step:29850[D loss: 0.999975] [G loss: 1.000052]\n",
      "epoch:7 step:29855[D loss: 0.999971] [G loss: 1.000063]\n",
      "epoch:7 step:29860[D loss: 0.999972] [G loss: 1.000061]\n",
      "epoch:7 step:29865[D loss: 0.999973] [G loss: 1.000063]\n",
      "epoch:7 step:29870[D loss: 0.999972] [G loss: 1.000054]\n",
      "epoch:7 step:29875[D loss: 1.000001] [G loss: 1.000022]\n",
      "epoch:7 step:29880[D loss: 1.000005] [G loss: 1.000009]\n",
      "epoch:7 step:29885[D loss: 1.000029] [G loss: 1.000045]\n",
      "epoch:7 step:29890[D loss: 0.999995] [G loss: 1.000116]\n",
      "epoch:7 step:29895[D loss: 0.999944] [G loss: 1.000137]\n",
      "epoch:7 step:29900[D loss: 0.999956] [G loss: 1.000104]\n",
      "epoch:7 step:29905[D loss: 0.999971] [G loss: 1.000065]\n",
      "epoch:7 step:29910[D loss: 0.999998] [G loss: 0.999974]\n",
      "epoch:7 step:29915[D loss: 1.000031] [G loss: 0.999944]\n",
      "epoch:7 step:29920[D loss: 1.000045] [G loss: 0.999888]\n",
      "epoch:7 step:29925[D loss: 1.000004] [G loss: 0.999960]\n",
      "epoch:7 step:29930[D loss: 0.999964] [G loss: 1.000055]\n",
      "epoch:7 step:29935[D loss: 0.999973] [G loss: 1.000057]\n",
      "epoch:7 step:29940[D loss: 0.999952] [G loss: 1.000109]\n",
      "epoch:7 step:29945[D loss: 0.999964] [G loss: 1.000085]\n",
      "epoch:7 step:29950[D loss: 0.999983] [G loss: 1.000055]\n",
      "epoch:7 step:29955[D loss: 0.999962] [G loss: 1.000067]\n",
      "epoch:7 step:29960[D loss: 0.999977] [G loss: 1.000038]\n",
      "epoch:7 step:29965[D loss: 1.000004] [G loss: 1.000002]\n",
      "epoch:7 step:29970[D loss: 0.999986] [G loss: 1.000013]\n",
      "epoch:7 step:29975[D loss: 0.999975] [G loss: 1.000061]\n",
      "epoch:7 step:29980[D loss: 0.999965] [G loss: 1.000058]\n",
      "epoch:7 step:29985[D loss: 0.999990] [G loss: 1.000069]\n",
      "epoch:7 step:29990[D loss: 0.999952] [G loss: 1.000080]\n",
      "epoch:7 step:29995[D loss: 0.999965] [G loss: 1.000082]\n",
      "epoch:7 step:30000[D loss: 0.999979] [G loss: 1.000092]\n",
      "##############\n",
      "[0.87127969 0.85189204 0.82633097 0.83266672 0.80942909 0.83280255\n",
      " 0.86726844 0.82331267 0.83068129 0.84437315]\n",
      "##########\n",
      "epoch:7 step:30005[D loss: 0.999962] [G loss: 1.000079]\n",
      "epoch:7 step:30010[D loss: 0.999977] [G loss: 1.000067]\n",
      "epoch:7 step:30015[D loss: 0.999969] [G loss: 1.000064]\n",
      "epoch:7 step:30020[D loss: 0.999971] [G loss: 1.000053]\n",
      "epoch:7 step:30025[D loss: 1.000010] [G loss: 1.000011]\n",
      "epoch:7 step:30030[D loss: 0.999954] [G loss: 1.000057]\n",
      "epoch:7 step:30035[D loss: 0.999948] [G loss: 1.000089]\n",
      "epoch:7 step:30040[D loss: 0.999970] [G loss: 1.000061]\n",
      "epoch:7 step:30045[D loss: 0.999998] [G loss: 1.000016]\n",
      "epoch:7 step:30050[D loss: 0.999964] [G loss: 1.000057]\n",
      "epoch:7 step:30055[D loss: 0.999973] [G loss: 1.000044]\n",
      "epoch:7 step:30060[D loss: 0.999966] [G loss: 1.000059]\n",
      "epoch:7 step:30065[D loss: 0.999985] [G loss: 1.000031]\n",
      "epoch:7 step:30070[D loss: 0.999970] [G loss: 1.000068]\n",
      "epoch:7 step:30075[D loss: 0.999969] [G loss: 1.000068]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:7 step:30080[D loss: 0.999970] [G loss: 1.000065]\n",
      "epoch:7 step:30085[D loss: 0.999975] [G loss: 1.000064]\n",
      "epoch:7 step:30090[D loss: 0.999977] [G loss: 1.000061]\n",
      "epoch:7 step:30095[D loss: 0.999971] [G loss: 1.000072]\n",
      "epoch:7 step:30100[D loss: 0.999967] [G loss: 1.000080]\n",
      "epoch:7 step:30105[D loss: 0.999973] [G loss: 1.000070]\n",
      "epoch:7 step:30110[D loss: 0.999961] [G loss: 1.000089]\n",
      "epoch:7 step:30115[D loss: 0.999962] [G loss: 1.000085]\n",
      "epoch:7 step:30120[D loss: 0.999978] [G loss: 1.000062]\n",
      "epoch:7 step:30125[D loss: 0.999972] [G loss: 1.000068]\n",
      "epoch:7 step:30130[D loss: 0.999994] [G loss: 1.000011]\n",
      "epoch:7 step:30135[D loss: 1.000042] [G loss: 0.999908]\n",
      "epoch:7 step:30140[D loss: 1.000001] [G loss: 1.000044]\n",
      "epoch:7 step:30145[D loss: 0.999946] [G loss: 1.000103]\n",
      "epoch:7 step:30150[D loss: 0.999975] [G loss: 1.000073]\n",
      "epoch:7 step:30155[D loss: 0.999969] [G loss: 1.000090]\n",
      "epoch:7 step:30160[D loss: 0.999975] [G loss: 1.000068]\n",
      "epoch:7 step:30165[D loss: 0.999975] [G loss: 1.000070]\n",
      "epoch:7 step:30170[D loss: 0.999997] [G loss: 0.999996]\n",
      "epoch:7 step:30175[D loss: 0.999993] [G loss: 0.999988]\n",
      "epoch:7 step:30180[D loss: 0.999964] [G loss: 1.000074]\n",
      "epoch:7 step:30185[D loss: 0.999973] [G loss: 1.000043]\n",
      "epoch:7 step:30190[D loss: 0.999984] [G loss: 1.000055]\n",
      "epoch:7 step:30195[D loss: 0.999980] [G loss: 1.000088]\n",
      "epoch:7 step:30200[D loss: 0.999959] [G loss: 1.000085]\n",
      "##############\n",
      "[0.86524579 0.84917515 0.80468339 0.83459262 0.79203737 0.84964848\n",
      " 0.88136833 0.85277246 0.82156871 0.82987844]\n",
      "##########\n",
      "epoch:7 step:30205[D loss: 0.999968] [G loss: 1.000076]\n",
      "epoch:7 step:30210[D loss: 0.999970] [G loss: 1.000075]\n",
      "epoch:7 step:30215[D loss: 0.999981] [G loss: 1.000065]\n",
      "epoch:7 step:30220[D loss: 0.999965] [G loss: 1.000080]\n",
      "epoch:7 step:30225[D loss: 0.999975] [G loss: 1.000067]\n",
      "epoch:7 step:30230[D loss: 0.999973] [G loss: 1.000053]\n",
      "epoch:7 step:30235[D loss: 0.999985] [G loss: 1.000017]\n",
      "epoch:7 step:30240[D loss: 0.999969] [G loss: 1.000074]\n",
      "epoch:7 step:30245[D loss: 1.000007] [G loss: 1.000034]\n",
      "epoch:7 step:30250[D loss: 0.999986] [G loss: 1.000014]\n",
      "epoch:7 step:30255[D loss: 0.999975] [G loss: 1.000090]\n",
      "epoch:7 step:30260[D loss: 0.999960] [G loss: 1.000094]\n",
      "epoch:7 step:30265[D loss: 0.999967] [G loss: 1.000079]\n",
      "epoch:7 step:30270[D loss: 0.999976] [G loss: 1.000058]\n",
      "epoch:7 step:30275[D loss: 0.999973] [G loss: 1.000058]\n",
      "epoch:7 step:30280[D loss: 1.000018] [G loss: 0.999983]\n",
      "epoch:7 step:30285[D loss: 0.999988] [G loss: 1.000052]\n",
      "epoch:7 step:30290[D loss: 1.000014] [G loss: 1.000034]\n",
      "epoch:7 step:30295[D loss: 0.999957] [G loss: 1.000074]\n",
      "epoch:7 step:30300[D loss: 0.999967] [G loss: 1.000068]\n",
      "epoch:7 step:30305[D loss: 0.999967] [G loss: 1.000074]\n",
      "epoch:7 step:30310[D loss: 1.000005] [G loss: 1.000032]\n",
      "epoch:7 step:30315[D loss: 0.999983] [G loss: 1.000015]\n",
      "epoch:7 step:30320[D loss: 0.999995] [G loss: 1.000047]\n",
      "epoch:7 step:30325[D loss: 0.999945] [G loss: 1.000112]\n",
      "epoch:7 step:30330[D loss: 0.999965] [G loss: 1.000073]\n",
      "epoch:7 step:30335[D loss: 0.999963] [G loss: 1.000088]\n",
      "epoch:7 step:30340[D loss: 1.000009] [G loss: 0.999994]\n",
      "epoch:7 step:30345[D loss: 0.999969] [G loss: 1.000081]\n",
      "epoch:7 step:30350[D loss: 0.999984] [G loss: 1.000059]\n",
      "epoch:7 step:30355[D loss: 1.000026] [G loss: 1.000015]\n",
      "epoch:7 step:30360[D loss: 0.999948] [G loss: 1.000140]\n",
      "epoch:7 step:30365[D loss: 0.999973] [G loss: 1.000100]\n",
      "epoch:7 step:30370[D loss: 0.999954] [G loss: 1.000101]\n",
      "epoch:7 step:30375[D loss: 0.999969] [G loss: 1.000068]\n",
      "epoch:7 step:30380[D loss: 0.999989] [G loss: 1.000042]\n",
      "epoch:7 step:30385[D loss: 1.000011] [G loss: 0.999953]\n",
      "epoch:7 step:30390[D loss: 0.999958] [G loss: 1.000066]\n",
      "epoch:7 step:30395[D loss: 0.999970] [G loss: 1.000047]\n",
      "epoch:7 step:30400[D loss: 0.999970] [G loss: 1.000084]\n",
      "##############\n",
      "[0.8756997  0.86985135 0.80764038 0.82001113 0.81085362 0.84202843\n",
      " 0.89807996 0.82344338 0.81183046 0.82698455]\n",
      "##########\n",
      "epoch:7 step:30405[D loss: 0.999976] [G loss: 1.000066]\n",
      "epoch:7 step:30410[D loss: 0.999984] [G loss: 1.000034]\n",
      "epoch:7 step:30415[D loss: 0.999971] [G loss: 1.000068]\n",
      "epoch:7 step:30420[D loss: 0.999999] [G loss: 1.000009]\n",
      "epoch:7 step:30425[D loss: 0.999977] [G loss: 1.000036]\n",
      "epoch:7 step:30430[D loss: 0.999968] [G loss: 1.000073]\n",
      "epoch:7 step:30435[D loss: 1.000010] [G loss: 1.000055]\n",
      "epoch:7 step:30440[D loss: 0.999980] [G loss: 1.000107]\n",
      "epoch:7 step:30445[D loss: 0.999986] [G loss: 1.000075]\n",
      "epoch:7 step:30450[D loss: 0.999965] [G loss: 1.000091]\n",
      "epoch:7 step:30455[D loss: 0.999967] [G loss: 1.000078]\n",
      "epoch:7 step:30460[D loss: 0.999971] [G loss: 1.000080]\n",
      "epoch:7 step:30465[D loss: 0.999984] [G loss: 1.000045]\n",
      "epoch:7 step:30470[D loss: 1.000010] [G loss: 0.999975]\n",
      "epoch:7 step:30475[D loss: 1.000066] [G loss: 0.999939]\n",
      "epoch:7 step:30480[D loss: 1.000028] [G loss: 1.000012]\n",
      "epoch:7 step:30485[D loss: 0.999935] [G loss: 1.000154]\n",
      "epoch:7 step:30490[D loss: 0.999927] [G loss: 1.000117]\n",
      "epoch:7 step:30495[D loss: 0.999966] [G loss: 1.000087]\n",
      "epoch:7 step:30500[D loss: 0.999976] [G loss: 1.000074]\n",
      "epoch:7 step:30505[D loss: 1.000014] [G loss: 0.999983]\n",
      "epoch:7 step:30510[D loss: 0.999986] [G loss: 1.000004]\n",
      "epoch:7 step:30515[D loss: 1.000003] [G loss: 1.000012]\n",
      "epoch:7 step:30520[D loss: 0.999954] [G loss: 1.000073]\n",
      "epoch:7 step:30525[D loss: 0.999997] [G loss: 1.000079]\n",
      "epoch:7 step:30530[D loss: 0.999963] [G loss: 1.000098]\n",
      "epoch:7 step:30535[D loss: 0.999966] [G loss: 1.000086]\n",
      "epoch:7 step:30540[D loss: 0.999977] [G loss: 1.000062]\n",
      "epoch:7 step:30545[D loss: 0.999973] [G loss: 1.000068]\n",
      "epoch:7 step:30550[D loss: 0.999969] [G loss: 1.000041]\n",
      "epoch:7 step:30555[D loss: 0.999994] [G loss: 1.000030]\n",
      "epoch:7 step:30560[D loss: 0.999970] [G loss: 1.000053]\n",
      "epoch:7 step:30565[D loss: 0.999948] [G loss: 1.000082]\n",
      "epoch:7 step:30570[D loss: 0.999968] [G loss: 1.000093]\n",
      "epoch:7 step:30575[D loss: 0.999962] [G loss: 1.000085]\n",
      "epoch:7 step:30580[D loss: 0.999977] [G loss: 1.000064]\n",
      "epoch:7 step:30585[D loss: 0.999961] [G loss: 1.000078]\n",
      "epoch:7 step:30590[D loss: 0.999978] [G loss: 1.000055]\n",
      "epoch:7 step:30595[D loss: 0.999973] [G loss: 1.000071]\n",
      "epoch:7 step:30600[D loss: 0.999965] [G loss: 1.000068]\n",
      "##############\n",
      "[0.87605366 0.87055229 0.85096597 0.81117599 0.81748622 0.82346796\n",
      " 0.87530802 0.84265022 0.81124923 0.84396625]\n",
      "##########\n",
      "epoch:7 step:30605[D loss: 0.999975] [G loss: 1.000069]\n",
      "epoch:7 step:30610[D loss: 1.000012] [G loss: 1.000022]\n",
      "epoch:7 step:30615[D loss: 0.999976] [G loss: 1.000032]\n",
      "epoch:7 step:30620[D loss: 0.999977] [G loss: 1.000068]\n",
      "epoch:7 step:30625[D loss: 0.999994] [G loss: 1.000085]\n",
      "epoch:7 step:30630[D loss: 0.999959] [G loss: 1.000121]\n",
      "epoch:7 step:30635[D loss: 0.999958] [G loss: 1.000092]\n",
      "epoch:7 step:30640[D loss: 0.999962] [G loss: 1.000103]\n",
      "epoch:7 step:30645[D loss: 0.999964] [G loss: 1.000073]\n",
      "epoch:7 step:30650[D loss: 0.999979] [G loss: 1.000060]\n",
      "epoch:7 step:30655[D loss: 0.999994] [G loss: 1.000018]\n",
      "epoch:7 step:30660[D loss: 0.999980] [G loss: 1.000039]\n",
      "epoch:7 step:30665[D loss: 0.999975] [G loss: 1.000065]\n",
      "epoch:7 step:30670[D loss: 0.999972] [G loss: 1.000057]\n",
      "epoch:7 step:30675[D loss: 0.999966] [G loss: 1.000061]\n",
      "epoch:7 step:30680[D loss: 0.999965] [G loss: 1.000076]\n",
      "epoch:7 step:30685[D loss: 0.999977] [G loss: 1.000076]\n",
      "epoch:7 step:30690[D loss: 0.999969] [G loss: 1.000060]\n",
      "epoch:7 step:30695[D loss: 0.999969] [G loss: 1.000065]\n",
      "epoch:7 step:30700[D loss: 0.999977] [G loss: 1.000057]\n",
      "epoch:7 step:30705[D loss: 0.999971] [G loss: 1.000078]\n",
      "epoch:7 step:30710[D loss: 0.999987] [G loss: 1.000031]\n",
      "epoch:7 step:30715[D loss: 0.999968] [G loss: 1.000066]\n",
      "epoch:7 step:30720[D loss: 0.999976] [G loss: 1.000076]\n",
      "epoch:7 step:30725[D loss: 0.999973] [G loss: 1.000075]\n",
      "epoch:7 step:30730[D loss: 0.999970] [G loss: 1.000063]\n",
      "epoch:7 step:30735[D loss: 0.999974] [G loss: 1.000069]\n",
      "epoch:7 step:30740[D loss: 0.999972] [G loss: 1.000061]\n",
      "epoch:7 step:30745[D loss: 0.999975] [G loss: 1.000053]\n",
      "epoch:7 step:30750[D loss: 0.999972] [G loss: 1.000071]\n",
      "epoch:7 step:30755[D loss: 0.999970] [G loss: 1.000059]\n",
      "epoch:7 step:30760[D loss: 0.999976] [G loss: 1.000063]\n",
      "epoch:7 step:30765[D loss: 0.999999] [G loss: 1.000037]\n",
      "epoch:7 step:30770[D loss: 0.999949] [G loss: 1.000062]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:7 step:30775[D loss: 0.999972] [G loss: 1.000051]\n",
      "epoch:7 step:30780[D loss: 1.000012] [G loss: 1.000001]\n",
      "epoch:7 step:30785[D loss: 0.999963] [G loss: 1.000081]\n",
      "epoch:7 step:30790[D loss: 0.999967] [G loss: 1.000061]\n",
      "epoch:7 step:30795[D loss: 0.999970] [G loss: 1.000072]\n",
      "epoch:7 step:30800[D loss: 0.999977] [G loss: 1.000061]\n",
      "##############\n",
      "[0.87519178 0.84902954 0.82344066 0.83877971 0.79000413 0.83687256\n",
      " 0.88426426 0.83596148 0.81359427 0.84415512]\n",
      "##########\n",
      "epoch:7 step:30805[D loss: 0.999964] [G loss: 1.000073]\n",
      "epoch:7 step:30810[D loss: 0.999985] [G loss: 1.000075]\n",
      "epoch:7 step:30815[D loss: 0.999987] [G loss: 1.000025]\n",
      "epoch:7 step:30820[D loss: 0.999968] [G loss: 1.000073]\n",
      "epoch:7 step:30825[D loss: 0.999958] [G loss: 1.000082]\n",
      "epoch:7 step:30830[D loss: 0.999982] [G loss: 1.000084]\n",
      "epoch:7 step:30835[D loss: 0.999978] [G loss: 1.000069]\n",
      "epoch:7 step:30840[D loss: 0.999976] [G loss: 1.000049]\n",
      "epoch:7 step:30845[D loss: 0.999981] [G loss: 1.000062]\n",
      "epoch:7 step:30850[D loss: 0.999972] [G loss: 1.000065]\n",
      "epoch:7 step:30855[D loss: 0.999981] [G loss: 1.000050]\n",
      "epoch:7 step:30860[D loss: 0.999964] [G loss: 1.000070]\n",
      "epoch:7 step:30865[D loss: 0.999980] [G loss: 1.000108]\n",
      "epoch:7 step:30870[D loss: 0.999967] [G loss: 1.000081]\n",
      "epoch:7 step:30875[D loss: 0.999961] [G loss: 1.000080]\n",
      "epoch:7 step:30880[D loss: 0.999976] [G loss: 1.000071]\n",
      "epoch:7 step:30885[D loss: 0.999975] [G loss: 1.000080]\n",
      "epoch:7 step:30890[D loss: 0.999979] [G loss: 1.000056]\n",
      "epoch:7 step:30895[D loss: 0.999977] [G loss: 1.000042]\n",
      "epoch:7 step:30900[D loss: 0.999999] [G loss: 1.000068]\n",
      "epoch:7 step:30905[D loss: 0.999967] [G loss: 1.000039]\n",
      "epoch:7 step:30910[D loss: 0.999993] [G loss: 1.000087]\n",
      "epoch:7 step:30915[D loss: 0.999932] [G loss: 1.000122]\n",
      "epoch:7 step:30920[D loss: 0.999968] [G loss: 1.000088]\n",
      "epoch:7 step:30925[D loss: 0.999968] [G loss: 1.000076]\n",
      "epoch:7 step:30930[D loss: 0.999983] [G loss: 1.000020]\n",
      "epoch:7 step:30935[D loss: 1.000021] [G loss: 0.999976]\n",
      "epoch:7 step:30940[D loss: 1.000033] [G loss: 0.999969]\n",
      "epoch:7 step:30945[D loss: 0.999973] [G loss: 1.000004]\n",
      "epoch:7 step:30950[D loss: 0.999958] [G loss: 1.000071]\n",
      "epoch:7 step:30955[D loss: 0.999955] [G loss: 1.000111]\n",
      "epoch:7 step:30960[D loss: 0.999961] [G loss: 1.000068]\n",
      "epoch:7 step:30965[D loss: 1.000004] [G loss: 1.000008]\n",
      "epoch:7 step:30970[D loss: 0.999969] [G loss: 1.000053]\n",
      "epoch:7 step:30975[D loss: 0.999991] [G loss: 1.000006]\n",
      "epoch:7 step:30980[D loss: 0.999983] [G loss: 1.000052]\n",
      "epoch:7 step:30985[D loss: 0.999950] [G loss: 1.000108]\n",
      "epoch:7 step:30990[D loss: 0.999971] [G loss: 1.000080]\n",
      "epoch:7 step:30995[D loss: 0.999978] [G loss: 1.000082]\n",
      "epoch:7 step:31000[D loss: 0.999986] [G loss: 1.000038]\n",
      "##############\n",
      "[0.87873976 0.85771289 0.82770477 0.82265792 0.79660487 0.8512307\n",
      " 0.8762595  0.8410792  0.81503261 0.83381594]\n",
      "##########\n",
      "epoch:7 step:31005[D loss: 0.999983] [G loss: 1.000040]\n",
      "epoch:7 step:31010[D loss: 0.999956] [G loss: 1.000069]\n",
      "epoch:7 step:31015[D loss: 0.999972] [G loss: 1.000036]\n",
      "epoch:7 step:31020[D loss: 0.999966] [G loss: 1.000078]\n",
      "epoch:7 step:31025[D loss: 0.999975] [G loss: 1.000063]\n",
      "epoch:7 step:31030[D loss: 0.999969] [G loss: 1.000069]\n",
      "epoch:7 step:31035[D loss: 0.999968] [G loss: 1.000071]\n",
      "epoch:7 step:31040[D loss: 0.999966] [G loss: 1.000068]\n",
      "epoch:7 step:31045[D loss: 0.999975] [G loss: 1.000079]\n",
      "epoch:7 step:31050[D loss: 0.999970] [G loss: 1.000073]\n",
      "epoch:7 step:31055[D loss: 0.999962] [G loss: 1.000082]\n",
      "epoch:7 step:31060[D loss: 0.999962] [G loss: 1.000078]\n",
      "epoch:7 step:31065[D loss: 0.999978] [G loss: 1.000067]\n",
      "epoch:7 step:31070[D loss: 0.999977] [G loss: 1.000073]\n",
      "epoch:7 step:31075[D loss: 0.999971] [G loss: 1.000084]\n",
      "epoch:7 step:31080[D loss: 0.999994] [G loss: 1.000040]\n",
      "epoch:7 step:31085[D loss: 0.999963] [G loss: 1.000113]\n",
      "epoch:7 step:31090[D loss: 1.000003] [G loss: 1.000007]\n",
      "epoch:7 step:31095[D loss: 0.999967] [G loss: 1.000067]\n",
      "epoch:7 step:31100[D loss: 0.999952] [G loss: 1.000085]\n",
      "epoch:7 step:31105[D loss: 0.999967] [G loss: 1.000086]\n",
      "epoch:7 step:31110[D loss: 0.999971] [G loss: 1.000072]\n",
      "epoch:7 step:31115[D loss: 0.999990] [G loss: 1.000065]\n",
      "epoch:7 step:31120[D loss: 0.999970] [G loss: 1.000074]\n",
      "epoch:7 step:31125[D loss: 0.999976] [G loss: 1.000071]\n",
      "epoch:7 step:31130[D loss: 0.999976] [G loss: 1.000061]\n",
      "epoch:7 step:31135[D loss: 0.999987] [G loss: 1.000032]\n",
      "epoch:7 step:31140[D loss: 0.999967] [G loss: 1.000086]\n",
      "epoch:7 step:31145[D loss: 0.999974] [G loss: 1.000068]\n",
      "epoch:7 step:31150[D loss: 0.999975] [G loss: 1.000045]\n",
      "epoch:7 step:31155[D loss: 1.000016] [G loss: 1.000019]\n",
      "epoch:7 step:31160[D loss: 0.999964] [G loss: 1.000055]\n",
      "epoch:7 step:31165[D loss: 0.999947] [G loss: 1.000093]\n",
      "epoch:7 step:31170[D loss: 0.999974] [G loss: 1.000058]\n",
      "epoch:7 step:31175[D loss: 0.999975] [G loss: 1.000064]\n",
      "epoch:7 step:31180[D loss: 1.000002] [G loss: 1.000004]\n",
      "epoch:7 step:31185[D loss: 0.999971] [G loss: 1.000078]\n",
      "epoch:7 step:31190[D loss: 0.999953] [G loss: 1.000069]\n",
      "epoch:7 step:31195[D loss: 0.999981] [G loss: 1.000087]\n",
      "epoch:7 step:31200[D loss: 0.999960] [G loss: 1.000093]\n",
      "##############\n",
      "[0.87300902 0.86275238 0.81923749 0.82367545 0.78327714 0.81227631\n",
      " 0.88165238 0.8382656  0.80687006 0.84258744]\n",
      "##########\n",
      "epoch:7 step:31205[D loss: 0.999993] [G loss: 1.000080]\n",
      "epoch:7 step:31210[D loss: 0.999973] [G loss: 1.000073]\n",
      "epoch:7 step:31215[D loss: 0.999991] [G loss: 1.000034]\n",
      "epoch:7 step:31220[D loss: 1.000043] [G loss: 0.999917]\n",
      "epoch:7 step:31225[D loss: 0.999981] [G loss: 1.000017]\n",
      "epoch:7 step:31230[D loss: 0.999929] [G loss: 1.000075]\n",
      "epoch:7 step:31235[D loss: 0.999973] [G loss: 1.000057]\n",
      "epoch:7 step:31240[D loss: 0.999983] [G loss: 1.000032]\n",
      "epoch:8 step:31245[D loss: 0.999968] [G loss: 1.000062]\n",
      "epoch:8 step:31250[D loss: 0.999976] [G loss: 1.000067]\n",
      "epoch:8 step:31255[D loss: 1.000009] [G loss: 0.999998]\n",
      "epoch:8 step:31260[D loss: 1.000012] [G loss: 0.999987]\n",
      "epoch:8 step:31265[D loss: 0.999977] [G loss: 1.000100]\n",
      "epoch:8 step:31270[D loss: 0.999963] [G loss: 1.000067]\n",
      "epoch:8 step:31275[D loss: 0.999973] [G loss: 1.000061]\n",
      "epoch:8 step:31280[D loss: 0.999986] [G loss: 1.000048]\n",
      "epoch:8 step:31285[D loss: 0.999965] [G loss: 1.000060]\n",
      "epoch:8 step:31290[D loss: 0.999970] [G loss: 1.000068]\n",
      "epoch:8 step:31295[D loss: 1.000013] [G loss: 0.999998]\n",
      "epoch:8 step:31300[D loss: 0.999969] [G loss: 1.000043]\n",
      "epoch:8 step:31305[D loss: 0.999989] [G loss: 1.000051]\n",
      "epoch:8 step:31310[D loss: 0.999987] [G loss: 1.000060]\n",
      "epoch:8 step:31315[D loss: 0.999978] [G loss: 1.000083]\n",
      "epoch:8 step:31320[D loss: 1.000009] [G loss: 1.000006]\n",
      "epoch:8 step:31325[D loss: 0.999993] [G loss: 1.000073]\n",
      "epoch:8 step:31330[D loss: 0.999936] [G loss: 1.000187]\n",
      "epoch:8 step:31335[D loss: 0.999948] [G loss: 1.000091]\n",
      "epoch:8 step:31340[D loss: 0.999961] [G loss: 1.000090]\n",
      "epoch:8 step:31345[D loss: 0.999997] [G loss: 1.000032]\n",
      "epoch:8 step:31350[D loss: 0.999980] [G loss: 1.000016]\n",
      "epoch:8 step:31355[D loss: 0.999983] [G loss: 1.000018]\n",
      "epoch:8 step:31360[D loss: 1.000108] [G loss: 1.000035]\n",
      "epoch:8 step:31365[D loss: 0.999999] [G loss: 0.999962]\n",
      "epoch:8 step:31370[D loss: 1.000016] [G loss: 1.000011]\n",
      "epoch:8 step:31375[D loss: 0.999946] [G loss: 1.000122]\n",
      "epoch:8 step:31380[D loss: 0.999941] [G loss: 1.000139]\n",
      "epoch:8 step:31385[D loss: 0.999962] [G loss: 1.000065]\n",
      "epoch:8 step:31390[D loss: 0.999986] [G loss: 1.000024]\n",
      "epoch:8 step:31395[D loss: 0.999970] [G loss: 1.000066]\n",
      "epoch:8 step:31400[D loss: 1.000019] [G loss: 1.000042]\n",
      "##############\n",
      "[0.87238276 0.85300561 0.82752701 0.82918033 0.80329447 0.83754848\n",
      " 0.88667856 0.83676652 0.80659765 0.83897172]\n",
      "##########\n",
      "epoch:8 step:31405[D loss: 0.999971] [G loss: 1.000072]\n",
      "epoch:8 step:31410[D loss: 0.999915] [G loss: 1.000158]\n",
      "epoch:8 step:31415[D loss: 0.999992] [G loss: 1.000047]\n",
      "epoch:8 step:31420[D loss: 0.999987] [G loss: 1.000100]\n",
      "epoch:8 step:31425[D loss: 0.999943] [G loss: 1.000133]\n",
      "epoch:8 step:31430[D loss: 0.999971] [G loss: 1.000083]\n",
      "epoch:8 step:31435[D loss: 0.999957] [G loss: 1.000084]\n",
      "epoch:8 step:31440[D loss: 0.999987] [G loss: 1.000052]\n",
      "epoch:8 step:31445[D loss: 1.000008] [G loss: 0.999962]\n",
      "epoch:8 step:31450[D loss: 0.999976] [G loss: 1.000049]\n",
      "epoch:8 step:31455[D loss: 0.999990] [G loss: 1.000041]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:8 step:31460[D loss: 0.999965] [G loss: 1.000076]\n",
      "epoch:8 step:31465[D loss: 0.999969] [G loss: 1.000073]\n",
      "epoch:8 step:31470[D loss: 0.999971] [G loss: 1.000074]\n",
      "epoch:8 step:31475[D loss: 0.999978] [G loss: 1.000090]\n",
      "epoch:8 step:31480[D loss: 0.999959] [G loss: 1.000077]\n",
      "epoch:8 step:31485[D loss: 0.999997] [G loss: 1.000021]\n",
      "epoch:8 step:31490[D loss: 0.999965] [G loss: 1.000064]\n",
      "epoch:8 step:31495[D loss: 0.999985] [G loss: 1.000078]\n",
      "epoch:8 step:31500[D loss: 0.999977] [G loss: 1.000073]\n",
      "epoch:8 step:31505[D loss: 0.999945] [G loss: 1.000089]\n",
      "epoch:8 step:31510[D loss: 0.999982] [G loss: 1.000085]\n",
      "epoch:8 step:31515[D loss: 0.999962] [G loss: 1.000084]\n",
      "epoch:8 step:31520[D loss: 0.999967] [G loss: 1.000057]\n",
      "epoch:8 step:31525[D loss: 0.999978] [G loss: 1.000052]\n",
      "epoch:8 step:31530[D loss: 0.999972] [G loss: 1.000064]\n",
      "epoch:8 step:31535[D loss: 0.999985] [G loss: 1.000044]\n",
      "epoch:8 step:31540[D loss: 0.999983] [G loss: 1.000048]\n",
      "epoch:8 step:31545[D loss: 0.999952] [G loss: 1.000106]\n",
      "epoch:8 step:31550[D loss: 0.999922] [G loss: 1.000132]\n",
      "epoch:8 step:31555[D loss: 0.999966] [G loss: 1.000082]\n",
      "epoch:8 step:31560[D loss: 0.999961] [G loss: 1.000093]\n",
      "epoch:8 step:31565[D loss: 0.999983] [G loss: 1.000066]\n",
      "epoch:8 step:31570[D loss: 0.999987] [G loss: 1.000047]\n",
      "epoch:8 step:31575[D loss: 0.999990] [G loss: 1.000025]\n",
      "epoch:8 step:31580[D loss: 0.999988] [G loss: 1.000020]\n",
      "epoch:8 step:31585[D loss: 0.999980] [G loss: 1.000047]\n",
      "epoch:8 step:31590[D loss: 0.999974] [G loss: 1.000052]\n",
      "epoch:8 step:31595[D loss: 1.000002] [G loss: 1.000065]\n",
      "epoch:8 step:31600[D loss: 0.999958] [G loss: 1.000106]\n",
      "##############\n",
      "[0.87764741 0.86696939 0.82480601 0.83246385 0.80206977 0.82289116\n",
      " 0.86751221 0.85784568 0.81926863 0.832546  ]\n",
      "##########\n",
      "epoch:8 step:31605[D loss: 0.999991] [G loss: 1.000043]\n",
      "epoch:8 step:31610[D loss: 0.999966] [G loss: 1.000092]\n",
      "epoch:8 step:31615[D loss: 0.999983] [G loss: 1.000056]\n",
      "epoch:8 step:31620[D loss: 0.999962] [G loss: 1.000088]\n",
      "epoch:8 step:31625[D loss: 0.999994] [G loss: 1.000064]\n",
      "epoch:8 step:31630[D loss: 0.999966] [G loss: 1.000081]\n",
      "epoch:8 step:31635[D loss: 0.999973] [G loss: 1.000069]\n",
      "epoch:8 step:31640[D loss: 0.999992] [G loss: 1.000005]\n",
      "epoch:8 step:31645[D loss: 0.999977] [G loss: 1.000071]\n",
      "epoch:8 step:31650[D loss: 1.000026] [G loss: 0.999975]\n",
      "epoch:8 step:31655[D loss: 1.000001] [G loss: 0.999999]\n",
      "epoch:8 step:31660[D loss: 0.999946] [G loss: 1.000113]\n",
      "epoch:8 step:31665[D loss: 0.999952] [G loss: 1.000082]\n",
      "epoch:8 step:31670[D loss: 0.999968] [G loss: 1.000071]\n",
      "epoch:8 step:31675[D loss: 0.999985] [G loss: 1.000043]\n",
      "epoch:8 step:31680[D loss: 1.000050] [G loss: 0.999945]\n",
      "epoch:8 step:31685[D loss: 1.000092] [G loss: 1.000005]\n",
      "epoch:8 step:31690[D loss: 0.999939] [G loss: 1.000142]\n",
      "epoch:8 step:31695[D loss: 1.000009] [G loss: 1.000036]\n",
      "epoch:8 step:31700[D loss: 0.999916] [G loss: 1.000169]\n",
      "epoch:8 step:31705[D loss: 0.999963] [G loss: 1.000092]\n",
      "epoch:8 step:31710[D loss: 0.999973] [G loss: 1.000051]\n",
      "epoch:8 step:31715[D loss: 0.999989] [G loss: 1.000015]\n",
      "epoch:8 step:31720[D loss: 1.000017] [G loss: 0.999981]\n",
      "epoch:8 step:31725[D loss: 0.999969] [G loss: 0.999975]\n",
      "epoch:8 step:31730[D loss: 1.000029] [G loss: 1.000010]\n",
      "epoch:8 step:31735[D loss: 1.000058] [G loss: 0.999969]\n",
      "epoch:8 step:31740[D loss: 0.999977] [G loss: 1.000030]\n",
      "epoch:8 step:31745[D loss: 0.999919] [G loss: 1.000124]\n",
      "epoch:8 step:31750[D loss: 0.999911] [G loss: 1.000167]\n",
      "epoch:8 step:31755[D loss: 0.999948] [G loss: 1.000093]\n",
      "epoch:8 step:31760[D loss: 0.999985] [G loss: 1.000062]\n",
      "epoch:8 step:31765[D loss: 1.000031] [G loss: 1.000005]\n",
      "epoch:8 step:31770[D loss: 0.999956] [G loss: 1.000096]\n",
      "epoch:8 step:31775[D loss: 1.000009] [G loss: 1.000059]\n",
      "epoch:8 step:31780[D loss: 1.000052] [G loss: 1.000047]\n",
      "epoch:8 step:31785[D loss: 0.999930] [G loss: 1.000150]\n",
      "epoch:8 step:31790[D loss: 1.000046] [G loss: 0.999933]\n",
      "epoch:8 step:31795[D loss: 0.999912] [G loss: 1.000184]\n",
      "epoch:8 step:31800[D loss: 0.999949] [G loss: 1.000105]\n",
      "##############\n",
      "[0.89419209 0.86651197 0.82282453 0.81796221 0.81826925 0.83101339\n",
      " 0.87831557 0.83988654 0.8021927  0.82932954]\n",
      "##########\n",
      "epoch:8 step:31805[D loss: 0.999979] [G loss: 1.000055]\n",
      "epoch:8 step:31810[D loss: 0.999964] [G loss: 1.000043]\n",
      "epoch:8 step:31815[D loss: 0.999991] [G loss: 1.000032]\n",
      "epoch:8 step:31820[D loss: 1.000013] [G loss: 0.999972]\n",
      "epoch:8 step:31825[D loss: 1.000056] [G loss: 1.000008]\n",
      "epoch:8 step:31830[D loss: 0.999933] [G loss: 1.000080]\n",
      "epoch:8 step:31835[D loss: 0.999919] [G loss: 1.000133]\n",
      "epoch:8 step:31840[D loss: 0.999946] [G loss: 1.000110]\n",
      "epoch:8 step:31845[D loss: 0.999957] [G loss: 1.000092]\n",
      "epoch:8 step:31850[D loss: 0.999963] [G loss: 1.000078]\n",
      "epoch:8 step:31855[D loss: 0.999979] [G loss: 1.000082]\n",
      "epoch:8 step:31860[D loss: 0.999997] [G loss: 1.000012]\n",
      "epoch:8 step:31865[D loss: 0.999986] [G loss: 1.000069]\n",
      "epoch:8 step:31870[D loss: 0.999960] [G loss: 1.000041]\n",
      "epoch:8 step:31875[D loss: 0.999988] [G loss: 1.000004]\n",
      "epoch:8 step:31880[D loss: 0.999962] [G loss: 1.000085]\n",
      "epoch:8 step:31885[D loss: 0.999953] [G loss: 1.000100]\n",
      "epoch:8 step:31890[D loss: 0.999972] [G loss: 1.000073]\n",
      "epoch:8 step:31895[D loss: 0.999975] [G loss: 1.000071]\n",
      "epoch:8 step:31900[D loss: 0.999967] [G loss: 1.000059]\n",
      "epoch:8 step:31905[D loss: 0.999973] [G loss: 1.000060]\n",
      "epoch:8 step:31910[D loss: 0.999974] [G loss: 1.000086]\n",
      "epoch:8 step:31915[D loss: 0.999983] [G loss: 1.000064]\n",
      "epoch:8 step:31920[D loss: 0.999974] [G loss: 1.000056]\n",
      "epoch:8 step:31925[D loss: 0.999999] [G loss: 1.000038]\n",
      "epoch:8 step:31930[D loss: 0.999951] [G loss: 1.000085]\n",
      "epoch:8 step:31935[D loss: 0.999964] [G loss: 1.000078]\n",
      "epoch:8 step:31940[D loss: 0.999979] [G loss: 1.000065]\n",
      "epoch:8 step:31945[D loss: 0.999976] [G loss: 1.000082]\n",
      "epoch:8 step:31950[D loss: 0.999962] [G loss: 1.000068]\n",
      "epoch:8 step:31955[D loss: 0.999965] [G loss: 1.000073]\n",
      "epoch:8 step:31960[D loss: 0.999989] [G loss: 1.000032]\n",
      "epoch:8 step:31965[D loss: 1.000015] [G loss: 0.999980]\n",
      "epoch:8 step:31970[D loss: 0.999962] [G loss: 1.000061]\n",
      "epoch:8 step:31975[D loss: 0.999977] [G loss: 1.000055]\n",
      "epoch:8 step:31980[D loss: 0.999973] [G loss: 1.000035]\n",
      "epoch:8 step:31985[D loss: 0.999975] [G loss: 1.000059]\n",
      "epoch:8 step:31990[D loss: 0.999986] [G loss: 1.000045]\n",
      "epoch:8 step:31995[D loss: 0.999978] [G loss: 1.000064]\n",
      "epoch:8 step:32000[D loss: 0.999973] [G loss: 1.000054]\n",
      "##############\n",
      "[0.88024234 0.84818195 0.82251518 0.81808101 0.81163792 0.8440881\n",
      " 0.8636867  0.84120234 0.81848292 0.85504888]\n",
      "##########\n",
      "epoch:8 step:32005[D loss: 0.999981] [G loss: 1.000066]\n",
      "epoch:8 step:32010[D loss: 0.999981] [G loss: 1.000048]\n",
      "epoch:8 step:32015[D loss: 0.999985] [G loss: 1.000041]\n",
      "epoch:8 step:32020[D loss: 0.999975] [G loss: 1.000061]\n",
      "epoch:8 step:32025[D loss: 0.999972] [G loss: 1.000064]\n",
      "epoch:8 step:32030[D loss: 0.999982] [G loss: 1.000079]\n",
      "epoch:8 step:32035[D loss: 0.999993] [G loss: 1.000062]\n",
      "epoch:8 step:32040[D loss: 0.999972] [G loss: 1.000076]\n",
      "epoch:8 step:32045[D loss: 0.999958] [G loss: 1.000079]\n",
      "epoch:8 step:32050[D loss: 0.999965] [G loss: 1.000070]\n",
      "epoch:8 step:32055[D loss: 0.999978] [G loss: 1.000068]\n",
      "epoch:8 step:32060[D loss: 0.999998] [G loss: 1.000002]\n",
      "epoch:8 step:32065[D loss: 0.999989] [G loss: 1.000023]\n",
      "epoch:8 step:32070[D loss: 0.999989] [G loss: 1.000050]\n",
      "epoch:8 step:32075[D loss: 0.999966] [G loss: 1.000043]\n",
      "epoch:8 step:32080[D loss: 0.999982] [G loss: 1.000023]\n",
      "epoch:8 step:32085[D loss: 0.999966] [G loss: 1.000082]\n",
      "epoch:8 step:32090[D loss: 0.999992] [G loss: 1.000046]\n",
      "epoch:8 step:32095[D loss: 1.000021] [G loss: 0.999986]\n",
      "epoch:8 step:32100[D loss: 1.000066] [G loss: 0.999927]\n",
      "epoch:8 step:32105[D loss: 0.999962] [G loss: 1.000081]\n",
      "epoch:8 step:32110[D loss: 0.999912] [G loss: 1.000129]\n",
      "epoch:8 step:32115[D loss: 0.999948] [G loss: 1.000072]\n",
      "epoch:8 step:32120[D loss: 0.999972] [G loss: 1.000055]\n",
      "epoch:8 step:32125[D loss: 0.999967] [G loss: 1.000044]\n",
      "epoch:8 step:32130[D loss: 0.999961] [G loss: 1.000077]\n",
      "epoch:8 step:32135[D loss: 1.000009] [G loss: 1.000059]\n",
      "epoch:8 step:32140[D loss: 1.000016] [G loss: 0.999986]\n",
      "epoch:8 step:32145[D loss: 0.999941] [G loss: 1.000112]\n",
      "epoch:8 step:32150[D loss: 0.999975] [G loss: 1.000045]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:8 step:32155[D loss: 0.999988] [G loss: 1.000025]\n",
      "epoch:8 step:32160[D loss: 0.999987] [G loss: 1.000041]\n",
      "epoch:8 step:32165[D loss: 1.000003] [G loss: 1.000048]\n",
      "epoch:8 step:32170[D loss: 0.999946] [G loss: 1.000065]\n",
      "epoch:8 step:32175[D loss: 0.999982] [G loss: 1.000046]\n",
      "epoch:8 step:32180[D loss: 0.999982] [G loss: 1.000034]\n",
      "epoch:8 step:32185[D loss: 0.999975] [G loss: 1.000055]\n",
      "epoch:8 step:32190[D loss: 0.999975] [G loss: 1.000049]\n",
      "epoch:8 step:32195[D loss: 0.999968] [G loss: 1.000096]\n",
      "epoch:8 step:32200[D loss: 0.999969] [G loss: 1.000062]\n",
      "##############\n",
      "[0.86057491 0.86885245 0.82478153 0.82100325 0.8022477  0.85615821\n",
      " 0.87344625 0.85493619 0.80062183 0.85463462]\n",
      "##########\n",
      "epoch:8 step:32205[D loss: 0.999974] [G loss: 1.000058]\n",
      "epoch:8 step:32210[D loss: 0.999971] [G loss: 1.000054]\n",
      "epoch:8 step:32215[D loss: 0.999977] [G loss: 1.000060]\n",
      "epoch:8 step:32220[D loss: 0.999973] [G loss: 1.000066]\n",
      "epoch:8 step:32225[D loss: 0.999989] [G loss: 1.000065]\n",
      "epoch:8 step:32230[D loss: 0.999973] [G loss: 1.000063]\n",
      "epoch:8 step:32235[D loss: 1.000014] [G loss: 0.999996]\n",
      "epoch:8 step:32240[D loss: 0.999969] [G loss: 1.000068]\n",
      "epoch:8 step:32245[D loss: 0.999973] [G loss: 1.000058]\n",
      "epoch:8 step:32250[D loss: 0.999967] [G loss: 1.000066]\n",
      "epoch:8 step:32255[D loss: 0.999972] [G loss: 1.000066]\n",
      "epoch:8 step:32260[D loss: 1.000004] [G loss: 0.999989]\n",
      "epoch:8 step:32265[D loss: 1.000011] [G loss: 1.000060]\n",
      "epoch:8 step:32270[D loss: 0.999945] [G loss: 1.000083]\n",
      "epoch:8 step:32275[D loss: 0.999966] [G loss: 1.000100]\n",
      "epoch:8 step:32280[D loss: 0.999971] [G loss: 1.000058]\n",
      "epoch:8 step:32285[D loss: 0.999966] [G loss: 1.000057]\n",
      "epoch:8 step:32290[D loss: 0.999973] [G loss: 1.000051]\n",
      "epoch:8 step:32295[D loss: 0.999985] [G loss: 1.000040]\n",
      "epoch:8 step:32300[D loss: 0.999978] [G loss: 1.000079]\n",
      "epoch:8 step:32305[D loss: 0.999980] [G loss: 1.000072]\n",
      "epoch:8 step:32310[D loss: 0.999975] [G loss: 1.000071]\n",
      "epoch:8 step:32315[D loss: 0.999980] [G loss: 1.000056]\n",
      "epoch:8 step:32320[D loss: 0.999968] [G loss: 1.000105]\n",
      "epoch:8 step:32325[D loss: 0.999972] [G loss: 1.000092]\n",
      "epoch:8 step:32330[D loss: 0.999961] [G loss: 1.000103]\n",
      "epoch:8 step:32335[D loss: 1.000010] [G loss: 1.000024]\n",
      "epoch:8 step:32340[D loss: 0.999963] [G loss: 1.000061]\n",
      "epoch:8 step:32345[D loss: 0.999980] [G loss: 1.000072]\n",
      "epoch:8 step:32350[D loss: 0.999984] [G loss: 1.000063]\n",
      "epoch:8 step:32355[D loss: 0.999983] [G loss: 1.000068]\n",
      "epoch:8 step:32360[D loss: 0.999975] [G loss: 1.000076]\n",
      "epoch:8 step:32365[D loss: 0.999965] [G loss: 1.000081]\n",
      "epoch:8 step:32370[D loss: 0.999981] [G loss: 1.000071]\n",
      "epoch:8 step:32375[D loss: 0.999970] [G loss: 1.000080]\n",
      "epoch:8 step:32380[D loss: 0.999970] [G loss: 1.000077]\n",
      "epoch:8 step:32385[D loss: 0.999963] [G loss: 1.000069]\n",
      "epoch:8 step:32390[D loss: 0.999976] [G loss: 1.000074]\n",
      "epoch:8 step:32395[D loss: 1.000008] [G loss: 0.999982]\n",
      "epoch:8 step:32400[D loss: 0.999971] [G loss: 1.000059]\n",
      "##############\n",
      "[0.87520039 0.8580538  0.82646723 0.84111873 0.84486303 0.84982082\n",
      " 0.89052211 0.85602959 0.78739532 0.84407474]\n",
      "##########\n",
      "epoch:8 step:32405[D loss: 0.999972] [G loss: 1.000053]\n",
      "epoch:8 step:32410[D loss: 0.999989] [G loss: 1.000034]\n",
      "epoch:8 step:32415[D loss: 0.999980] [G loss: 1.000042]\n",
      "epoch:8 step:32420[D loss: 0.999998] [G loss: 1.000039]\n",
      "epoch:8 step:32425[D loss: 0.999977] [G loss: 1.000075]\n",
      "epoch:8 step:32430[D loss: 0.999960] [G loss: 1.000082]\n",
      "epoch:8 step:32435[D loss: 0.999986] [G loss: 1.000019]\n",
      "epoch:8 step:32440[D loss: 0.999988] [G loss: 1.000047]\n",
      "epoch:8 step:32445[D loss: 0.999965] [G loss: 1.000060]\n",
      "epoch:8 step:32450[D loss: 0.999967] [G loss: 1.000068]\n",
      "epoch:8 step:32455[D loss: 0.999974] [G loss: 1.000065]\n",
      "epoch:8 step:32460[D loss: 0.999980] [G loss: 1.000075]\n",
      "epoch:8 step:32465[D loss: 0.999973] [G loss: 1.000078]\n",
      "epoch:8 step:32470[D loss: 1.000020] [G loss: 0.999996]\n",
      "epoch:8 step:32475[D loss: 0.999956] [G loss: 1.000145]\n",
      "epoch:8 step:32480[D loss: 0.999959] [G loss: 1.000076]\n",
      "epoch:8 step:32485[D loss: 0.999976] [G loss: 1.000040]\n",
      "epoch:8 step:32490[D loss: 0.999976] [G loss: 1.000030]\n",
      "epoch:8 step:32495[D loss: 0.999974] [G loss: 1.000062]\n",
      "epoch:8 step:32500[D loss: 0.999983] [G loss: 1.000061]\n",
      "epoch:8 step:32505[D loss: 0.999980] [G loss: 1.000060]\n",
      "epoch:8 step:32510[D loss: 0.999965] [G loss: 1.000068]\n",
      "epoch:8 step:32515[D loss: 0.999984] [G loss: 1.000045]\n",
      "epoch:8 step:32520[D loss: 0.999974] [G loss: 1.000054]\n",
      "epoch:8 step:32525[D loss: 0.999980] [G loss: 1.000078]\n",
      "epoch:8 step:32530[D loss: 0.999992] [G loss: 1.000080]\n",
      "epoch:8 step:32535[D loss: 0.999974] [G loss: 1.000061]\n",
      "epoch:8 step:32540[D loss: 0.999962] [G loss: 1.000053]\n",
      "epoch:8 step:32545[D loss: 0.999971] [G loss: 1.000062]\n",
      "epoch:8 step:32550[D loss: 0.999968] [G loss: 1.000070]\n",
      "epoch:8 step:32555[D loss: 1.000018] [G loss: 0.999997]\n",
      "epoch:8 step:32560[D loss: 0.999949] [G loss: 1.000093]\n",
      "epoch:8 step:32565[D loss: 0.999969] [G loss: 1.000072]\n",
      "epoch:8 step:32570[D loss: 0.999977] [G loss: 1.000060]\n",
      "epoch:8 step:32575[D loss: 0.999982] [G loss: 1.000072]\n",
      "epoch:8 step:32580[D loss: 0.999974] [G loss: 1.000061]\n",
      "epoch:8 step:32585[D loss: 0.999978] [G loss: 1.000067]\n",
      "epoch:8 step:32590[D loss: 0.999976] [G loss: 1.000057]\n",
      "epoch:8 step:32595[D loss: 0.999970] [G loss: 1.000068]\n",
      "epoch:8 step:32600[D loss: 0.999983] [G loss: 1.000038]\n",
      "##############\n",
      "[0.87680338 0.85592463 0.80542603 0.82455017 0.81022451 0.86034577\n",
      " 0.86380949 0.8319213  0.83038021 0.834759  ]\n",
      "##########\n",
      "epoch:8 step:32605[D loss: 0.999975] [G loss: 1.000054]\n",
      "epoch:8 step:32610[D loss: 0.999979] [G loss: 1.000058]\n",
      "epoch:8 step:32615[D loss: 0.999971] [G loss: 1.000064]\n",
      "epoch:8 step:32620[D loss: 0.999977] [G loss: 1.000032]\n",
      "epoch:8 step:32625[D loss: 0.999968] [G loss: 1.000077]\n",
      "epoch:8 step:32630[D loss: 0.999980] [G loss: 1.000073]\n",
      "epoch:8 step:32635[D loss: 0.999971] [G loss: 1.000071]\n",
      "epoch:8 step:32640[D loss: 0.999989] [G loss: 1.000038]\n",
      "epoch:8 step:32645[D loss: 0.999975] [G loss: 1.000081]\n",
      "epoch:8 step:32650[D loss: 0.999996] [G loss: 1.000082]\n",
      "epoch:8 step:32655[D loss: 0.999965] [G loss: 1.000079]\n",
      "epoch:8 step:32660[D loss: 0.999961] [G loss: 1.000066]\n",
      "epoch:8 step:32665[D loss: 1.000017] [G loss: 0.999985]\n",
      "epoch:8 step:32670[D loss: 0.999993] [G loss: 1.000022]\n",
      "epoch:8 step:32675[D loss: 0.999965] [G loss: 1.000066]\n",
      "epoch:8 step:32680[D loss: 0.999969] [G loss: 1.000066]\n",
      "epoch:8 step:32685[D loss: 0.999978] [G loss: 1.000078]\n",
      "epoch:8 step:32690[D loss: 0.999970] [G loss: 1.000057]\n",
      "epoch:8 step:32695[D loss: 0.999963] [G loss: 1.000076]\n",
      "epoch:8 step:32700[D loss: 0.999977] [G loss: 1.000055]\n",
      "epoch:8 step:32705[D loss: 0.999978] [G loss: 1.000059]\n",
      "epoch:8 step:32710[D loss: 0.999975] [G loss: 1.000057]\n",
      "epoch:8 step:32715[D loss: 0.999967] [G loss: 1.000095]\n",
      "epoch:8 step:32720[D loss: 0.999961] [G loss: 1.000068]\n",
      "epoch:8 step:32725[D loss: 0.999973] [G loss: 1.000061]\n",
      "epoch:8 step:32730[D loss: 0.999973] [G loss: 1.000072]\n",
      "epoch:8 step:32735[D loss: 0.999997] [G loss: 1.000055]\n",
      "epoch:8 step:32740[D loss: 0.999973] [G loss: 1.000075]\n",
      "epoch:8 step:32745[D loss: 0.999970] [G loss: 1.000056]\n",
      "epoch:8 step:32750[D loss: 0.999971] [G loss: 1.000075]\n",
      "epoch:8 step:32755[D loss: 0.999976] [G loss: 1.000068]\n",
      "epoch:8 step:32760[D loss: 0.999973] [G loss: 1.000075]\n",
      "epoch:8 step:32765[D loss: 0.999974] [G loss: 1.000064]\n",
      "epoch:8 step:32770[D loss: 0.999974] [G loss: 1.000069]\n",
      "epoch:8 step:32775[D loss: 0.999973] [G loss: 1.000056]\n",
      "epoch:8 step:32780[D loss: 0.999977] [G loss: 1.000078]\n",
      "epoch:8 step:32785[D loss: 0.999978] [G loss: 1.000069]\n",
      "epoch:8 step:32790[D loss: 0.999989] [G loss: 1.000083]\n",
      "epoch:8 step:32795[D loss: 0.999964] [G loss: 1.000085]\n",
      "epoch:8 step:32800[D loss: 0.999964] [G loss: 1.000068]\n",
      "##############\n",
      "[0.88826889 0.8634088  0.82169981 0.82206366 0.82896491 0.82946885\n",
      " 0.87632536 0.84320091 0.79317756 0.83319702]\n",
      "##########\n",
      "epoch:8 step:32805[D loss: 0.999973] [G loss: 1.000066]\n",
      "epoch:8 step:32810[D loss: 0.999975] [G loss: 1.000057]\n",
      "epoch:8 step:32815[D loss: 0.999983] [G loss: 1.000047]\n",
      "epoch:8 step:32820[D loss: 0.999986] [G loss: 1.000035]\n",
      "epoch:8 step:32825[D loss: 0.999968] [G loss: 1.000077]\n",
      "epoch:8 step:32830[D loss: 0.999965] [G loss: 1.000063]\n",
      "epoch:8 step:32835[D loss: 0.999979] [G loss: 1.000059]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:8 step:32840[D loss: 0.999964] [G loss: 1.000094]\n",
      "epoch:8 step:32845[D loss: 0.999970] [G loss: 1.000061]\n",
      "epoch:8 step:32850[D loss: 0.999978] [G loss: 1.000028]\n",
      "epoch:8 step:32855[D loss: 0.999999] [G loss: 1.000032]\n",
      "epoch:8 step:32860[D loss: 0.999960] [G loss: 1.000032]\n",
      "epoch:8 step:32865[D loss: 0.999967] [G loss: 1.000054]\n",
      "epoch:8 step:32870[D loss: 0.999992] [G loss: 1.000018]\n",
      "epoch:8 step:32875[D loss: 0.999965] [G loss: 1.000070]\n",
      "epoch:8 step:32880[D loss: 0.999981] [G loss: 1.000049]\n",
      "epoch:8 step:32885[D loss: 0.999983] [G loss: 1.000076]\n",
      "epoch:8 step:32890[D loss: 0.999978] [G loss: 1.000070]\n",
      "epoch:8 step:32895[D loss: 0.999992] [G loss: 1.000040]\n",
      "epoch:8 step:32900[D loss: 0.999990] [G loss: 1.000044]\n",
      "epoch:8 step:32905[D loss: 0.999962] [G loss: 1.000059]\n",
      "epoch:8 step:32910[D loss: 0.999974] [G loss: 1.000067]\n",
      "epoch:8 step:32915[D loss: 0.999972] [G loss: 1.000057]\n",
      "epoch:8 step:32920[D loss: 0.999970] [G loss: 1.000084]\n",
      "epoch:8 step:32925[D loss: 0.999993] [G loss: 1.000060]\n",
      "epoch:8 step:32930[D loss: 0.999976] [G loss: 1.000067]\n",
      "epoch:8 step:32935[D loss: 0.999988] [G loss: 1.000059]\n",
      "epoch:8 step:32940[D loss: 0.999991] [G loss: 1.000071]\n",
      "epoch:8 step:32945[D loss: 0.999974] [G loss: 1.000052]\n",
      "epoch:8 step:32950[D loss: 0.999962] [G loss: 1.000077]\n",
      "epoch:8 step:32955[D loss: 0.999967] [G loss: 1.000073]\n",
      "epoch:8 step:32960[D loss: 0.999964] [G loss: 1.000081]\n",
      "epoch:8 step:32965[D loss: 0.999970] [G loss: 1.000073]\n",
      "epoch:8 step:32970[D loss: 0.999982] [G loss: 1.000071]\n",
      "epoch:8 step:32975[D loss: 0.999954] [G loss: 1.000087]\n",
      "epoch:8 step:32980[D loss: 0.999978] [G loss: 1.000073]\n",
      "epoch:8 step:32985[D loss: 0.999982] [G loss: 1.000056]\n",
      "epoch:8 step:32990[D loss: 0.999973] [G loss: 1.000067]\n",
      "epoch:8 step:32995[D loss: 0.999977] [G loss: 1.000059]\n",
      "epoch:8 step:33000[D loss: 0.999986] [G loss: 1.000020]\n",
      "##############\n",
      "[0.87028137 0.86126165 0.81620529 0.82504488 0.80765651 0.82998354\n",
      " 0.87677269 0.84518542 0.81354865 0.84517189]\n",
      "##########\n",
      "epoch:8 step:33005[D loss: 0.999969] [G loss: 1.000063]\n",
      "epoch:8 step:33010[D loss: 0.999976] [G loss: 1.000077]\n",
      "epoch:8 step:33015[D loss: 0.999981] [G loss: 1.000066]\n",
      "epoch:8 step:33020[D loss: 0.999967] [G loss: 1.000071]\n",
      "epoch:8 step:33025[D loss: 0.999991] [G loss: 1.000034]\n",
      "epoch:8 step:33030[D loss: 0.999983] [G loss: 1.000062]\n",
      "epoch:8 step:33035[D loss: 0.999970] [G loss: 1.000111]\n",
      "epoch:8 step:33040[D loss: 0.999973] [G loss: 1.000079]\n",
      "epoch:8 step:33045[D loss: 0.999971] [G loss: 1.000106]\n",
      "epoch:8 step:33050[D loss: 0.999960] [G loss: 1.000082]\n",
      "epoch:8 step:33055[D loss: 0.999973] [G loss: 1.000084]\n",
      "epoch:8 step:33060[D loss: 0.999972] [G loss: 1.000067]\n",
      "epoch:8 step:33065[D loss: 0.999970] [G loss: 1.000085]\n",
      "epoch:8 step:33070[D loss: 0.999987] [G loss: 1.000045]\n",
      "epoch:8 step:33075[D loss: 1.000004] [G loss: 1.000038]\n",
      "epoch:8 step:33080[D loss: 0.999962] [G loss: 1.000096]\n",
      "epoch:8 step:33085[D loss: 0.999972] [G loss: 1.000073]\n",
      "epoch:8 step:33090[D loss: 0.999978] [G loss: 1.000069]\n",
      "epoch:8 step:33095[D loss: 0.999971] [G loss: 1.000060]\n",
      "epoch:8 step:33100[D loss: 0.999975] [G loss: 1.000070]\n",
      "epoch:8 step:33105[D loss: 0.999998] [G loss: 1.000052]\n",
      "epoch:8 step:33110[D loss: 0.999979] [G loss: 1.000055]\n",
      "epoch:8 step:33115[D loss: 0.999969] [G loss: 1.000068]\n",
      "epoch:8 step:33120[D loss: 0.999964] [G loss: 1.000070]\n",
      "epoch:8 step:33125[D loss: 0.999991] [G loss: 1.000018]\n",
      "epoch:8 step:33130[D loss: 0.999962] [G loss: 1.000058]\n",
      "epoch:8 step:33135[D loss: 0.999970] [G loss: 1.000063]\n",
      "epoch:8 step:33140[D loss: 0.999975] [G loss: 1.000068]\n",
      "epoch:8 step:33145[D loss: 0.999999] [G loss: 1.000043]\n",
      "epoch:8 step:33150[D loss: 0.999967] [G loss: 1.000071]\n",
      "epoch:8 step:33155[D loss: 0.999985] [G loss: 1.000063]\n",
      "epoch:8 step:33160[D loss: 0.999969] [G loss: 1.000070]\n",
      "epoch:8 step:33165[D loss: 0.999972] [G loss: 1.000059]\n",
      "epoch:8 step:33170[D loss: 0.999990] [G loss: 1.000043]\n",
      "epoch:8 step:33175[D loss: 0.999992] [G loss: 1.000006]\n",
      "epoch:8 step:33180[D loss: 0.999959] [G loss: 1.000070]\n",
      "epoch:8 step:33185[D loss: 0.999977] [G loss: 1.000056]\n",
      "epoch:8 step:33190[D loss: 0.999976] [G loss: 1.000028]\n",
      "epoch:8 step:33195[D loss: 0.999981] [G loss: 1.000041]\n",
      "epoch:8 step:33200[D loss: 0.999959] [G loss: 1.000074]\n",
      "##############\n",
      "[0.86783173 0.84187692 0.82407294 0.8259661  0.79322251 0.83577985\n",
      " 0.89961854 0.85052558 0.82971115 0.83482564]\n",
      "##########\n",
      "epoch:8 step:33205[D loss: 0.999973] [G loss: 1.000057]\n",
      "epoch:8 step:33210[D loss: 0.999971] [G loss: 1.000070]\n",
      "epoch:8 step:33215[D loss: 0.999975] [G loss: 1.000057]\n",
      "epoch:8 step:33220[D loss: 0.999974] [G loss: 1.000065]\n",
      "epoch:8 step:33225[D loss: 0.999966] [G loss: 1.000068]\n",
      "epoch:8 step:33230[D loss: 0.999969] [G loss: 1.000065]\n",
      "epoch:8 step:33235[D loss: 0.999982] [G loss: 1.000057]\n",
      "epoch:8 step:33240[D loss: 0.999972] [G loss: 1.000063]\n",
      "epoch:8 step:33245[D loss: 0.999986] [G loss: 1.000055]\n",
      "epoch:8 step:33250[D loss: 0.999987] [G loss: 1.000062]\n",
      "epoch:8 step:33255[D loss: 0.999961] [G loss: 1.000088]\n",
      "epoch:8 step:33260[D loss: 0.999975] [G loss: 1.000039]\n",
      "epoch:8 step:33265[D loss: 0.999981] [G loss: 1.000036]\n",
      "epoch:8 step:33270[D loss: 0.999967] [G loss: 1.000064]\n",
      "epoch:8 step:33275[D loss: 0.999968] [G loss: 1.000069]\n",
      "epoch:8 step:33280[D loss: 1.000002] [G loss: 1.000028]\n",
      "epoch:8 step:33285[D loss: 0.999958] [G loss: 1.000127]\n",
      "epoch:8 step:33290[D loss: 0.999957] [G loss: 1.000096]\n",
      "epoch:8 step:33295[D loss: 0.999977] [G loss: 1.000074]\n",
      "epoch:8 step:33300[D loss: 0.999975] [G loss: 1.000075]\n",
      "epoch:8 step:33305[D loss: 1.000013] [G loss: 1.000009]\n",
      "epoch:8 step:33310[D loss: 1.000029] [G loss: 0.999996]\n",
      "epoch:8 step:33315[D loss: 0.999977] [G loss: 1.000034]\n",
      "epoch:8 step:33320[D loss: 0.999959] [G loss: 1.000096]\n",
      "epoch:8 step:33325[D loss: 0.999994] [G loss: 1.000053]\n",
      "epoch:8 step:33330[D loss: 0.999955] [G loss: 1.000078]\n",
      "epoch:8 step:33335[D loss: 0.999966] [G loss: 1.000064]\n",
      "epoch:8 step:33340[D loss: 0.999957] [G loss: 1.000078]\n",
      "epoch:8 step:33345[D loss: 1.000029] [G loss: 0.999991]\n",
      "epoch:8 step:33350[D loss: 0.999967] [G loss: 1.000055]\n",
      "epoch:8 step:33355[D loss: 0.999968] [G loss: 1.000076]\n",
      "epoch:8 step:33360[D loss: 0.999978] [G loss: 1.000083]\n",
      "epoch:8 step:33365[D loss: 0.999958] [G loss: 1.000090]\n",
      "epoch:8 step:33370[D loss: 0.999963] [G loss: 1.000090]\n",
      "epoch:8 step:33375[D loss: 0.999980] [G loss: 1.000066]\n",
      "epoch:8 step:33380[D loss: 0.999992] [G loss: 1.000029]\n",
      "epoch:8 step:33385[D loss: 1.000001] [G loss: 1.000040]\n",
      "epoch:8 step:33390[D loss: 0.999972] [G loss: 1.000062]\n",
      "epoch:8 step:33395[D loss: 0.999982] [G loss: 1.000054]\n",
      "epoch:8 step:33400[D loss: 0.999970] [G loss: 1.000042]\n",
      "##############\n",
      "[0.89096304 0.87352326 0.8141494  0.8048367  0.78298815 0.83076851\n",
      " 0.88578017 0.86322592 0.80490912 0.84451581]\n",
      "##########\n",
      "epoch:8 step:33405[D loss: 0.999965] [G loss: 1.000071]\n",
      "epoch:8 step:33410[D loss: 0.999996] [G loss: 1.000037]\n",
      "epoch:8 step:33415[D loss: 0.999968] [G loss: 1.000084]\n",
      "epoch:8 step:33420[D loss: 0.999971] [G loss: 1.000055]\n",
      "epoch:8 step:33425[D loss: 0.999985] [G loss: 1.000031]\n",
      "epoch:8 step:33430[D loss: 1.000001] [G loss: 1.000049]\n",
      "epoch:8 step:33435[D loss: 0.999916] [G loss: 1.000155]\n",
      "epoch:8 step:33440[D loss: 0.999963] [G loss: 1.000086]\n",
      "epoch:8 step:33445[D loss: 0.999995] [G loss: 1.000033]\n",
      "epoch:8 step:33450[D loss: 0.999957] [G loss: 1.000107]\n",
      "epoch:8 step:33455[D loss: 0.999976] [G loss: 1.000054]\n",
      "epoch:8 step:33460[D loss: 0.999974] [G loss: 1.000054]\n",
      "epoch:8 step:33465[D loss: 0.999985] [G loss: 1.000024]\n",
      "epoch:8 step:33470[D loss: 0.999997] [G loss: 1.000045]\n",
      "epoch:8 step:33475[D loss: 1.000001] [G loss: 1.000040]\n",
      "epoch:8 step:33480[D loss: 1.000024] [G loss: 1.000065]\n",
      "epoch:8 step:33485[D loss: 0.999949] [G loss: 1.000050]\n",
      "epoch:8 step:33490[D loss: 0.999958] [G loss: 1.000104]\n",
      "epoch:8 step:33495[D loss: 0.999967] [G loss: 1.000060]\n",
      "epoch:8 step:33500[D loss: 0.999971] [G loss: 1.000072]\n",
      "epoch:8 step:33505[D loss: 1.000003] [G loss: 0.999995]\n",
      "epoch:8 step:33510[D loss: 0.999975] [G loss: 1.000048]\n",
      "epoch:8 step:33515[D loss: 0.999976] [G loss: 1.000075]\n",
      "epoch:8 step:33520[D loss: 0.999996] [G loss: 1.000046]\n",
      "epoch:8 step:33525[D loss: 0.999967] [G loss: 1.000075]\n",
      "epoch:8 step:33530[D loss: 0.999964] [G loss: 1.000077]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:8 step:33535[D loss: 0.999977] [G loss: 1.000081]\n",
      "epoch:8 step:33540[D loss: 0.999963] [G loss: 1.000083]\n",
      "epoch:8 step:33545[D loss: 0.999974] [G loss: 1.000077]\n",
      "epoch:8 step:33550[D loss: 0.999972] [G loss: 1.000067]\n",
      "epoch:8 step:33555[D loss: 0.999983] [G loss: 1.000052]\n",
      "epoch:8 step:33560[D loss: 0.999982] [G loss: 1.000050]\n",
      "epoch:8 step:33565[D loss: 0.999978] [G loss: 1.000074]\n",
      "epoch:8 step:33570[D loss: 0.999967] [G loss: 1.000093]\n",
      "epoch:8 step:33575[D loss: 0.999964] [G loss: 1.000079]\n",
      "epoch:8 step:33580[D loss: 0.999966] [G loss: 1.000084]\n",
      "epoch:8 step:33585[D loss: 1.000001] [G loss: 0.999999]\n",
      "epoch:8 step:33590[D loss: 0.999978] [G loss: 1.000064]\n",
      "epoch:8 step:33595[D loss: 0.999966] [G loss: 1.000090]\n",
      "epoch:8 step:33600[D loss: 0.999969] [G loss: 1.000064]\n",
      "##############\n",
      "[0.87795624 0.85428165 0.84534586 0.8246834  0.78668731 0.84065253\n",
      " 0.86783047 0.8441879  0.80534214 0.83211732]\n",
      "##########\n",
      "epoch:8 step:33605[D loss: 0.999983] [G loss: 1.000053]\n",
      "epoch:8 step:33610[D loss: 0.999996] [G loss: 1.000060]\n",
      "epoch:8 step:33615[D loss: 0.999960] [G loss: 1.000070]\n",
      "epoch:8 step:33620[D loss: 0.999973] [G loss: 1.000067]\n",
      "epoch:8 step:33625[D loss: 0.999972] [G loss: 1.000083]\n",
      "epoch:8 step:33630[D loss: 0.999975] [G loss: 1.000068]\n",
      "epoch:8 step:33635[D loss: 0.999972] [G loss: 1.000067]\n",
      "epoch:8 step:33640[D loss: 0.999970] [G loss: 1.000084]\n",
      "epoch:8 step:33645[D loss: 0.999969] [G loss: 1.000091]\n",
      "epoch:8 step:33650[D loss: 0.999969] [G loss: 1.000066]\n",
      "epoch:8 step:33655[D loss: 0.999994] [G loss: 1.000052]\n",
      "epoch:8 step:33660[D loss: 0.999968] [G loss: 1.000075]\n",
      "epoch:8 step:33665[D loss: 0.999967] [G loss: 1.000085]\n",
      "epoch:8 step:33670[D loss: 0.999971] [G loss: 1.000068]\n",
      "epoch:8 step:33675[D loss: 0.999972] [G loss: 1.000073]\n",
      "epoch:8 step:33680[D loss: 0.999969] [G loss: 1.000077]\n",
      "epoch:8 step:33685[D loss: 0.999972] [G loss: 1.000086]\n",
      "epoch:8 step:33690[D loss: 0.999984] [G loss: 1.000077]\n",
      "epoch:8 step:33695[D loss: 1.000001] [G loss: 1.000056]\n",
      "epoch:8 step:33700[D loss: 0.999967] [G loss: 1.000111]\n",
      "epoch:8 step:33705[D loss: 0.999947] [G loss: 1.000168]\n",
      "epoch:8 step:33710[D loss: 0.999953] [G loss: 1.000127]\n",
      "epoch:8 step:33715[D loss: 0.999966] [G loss: 1.000084]\n",
      "epoch:8 step:33720[D loss: 0.999972] [G loss: 1.000053]\n",
      "epoch:8 step:33725[D loss: 1.000003] [G loss: 0.999986]\n",
      "epoch:8 step:33730[D loss: 0.999984] [G loss: 1.000018]\n",
      "epoch:8 step:33735[D loss: 0.999975] [G loss: 1.000035]\n",
      "epoch:8 step:33740[D loss: 1.000033] [G loss: 0.999957]\n",
      "epoch:8 step:33745[D loss: 0.999970] [G loss: 1.000006]\n",
      "epoch:8 step:33750[D loss: 0.999948] [G loss: 1.000103]\n",
      "epoch:8 step:33755[D loss: 0.999973] [G loss: 1.000067]\n",
      "epoch:8 step:33760[D loss: 0.999971] [G loss: 1.000064]\n",
      "epoch:8 step:33765[D loss: 0.999963] [G loss: 1.000061]\n",
      "epoch:8 step:33770[D loss: 0.999978] [G loss: 1.000059]\n",
      "epoch:8 step:33775[D loss: 0.999963] [G loss: 1.000064]\n",
      "epoch:8 step:33780[D loss: 0.999977] [G loss: 1.000053]\n",
      "epoch:8 step:33785[D loss: 1.000004] [G loss: 1.000039]\n",
      "epoch:8 step:33790[D loss: 1.000021] [G loss: 1.000026]\n",
      "epoch:8 step:33795[D loss: 0.999966] [G loss: 1.000134]\n",
      "epoch:8 step:33800[D loss: 0.999990] [G loss: 1.000074]\n",
      "##############\n",
      "[0.88809576 0.86681381 0.82743915 0.82224656 0.8282574  0.82013192\n",
      " 0.85523986 0.84264132 0.81168852 0.85643199]\n",
      "##########\n",
      "epoch:8 step:33805[D loss: 0.999972] [G loss: 1.000064]\n",
      "epoch:8 step:33810[D loss: 0.999974] [G loss: 1.000031]\n",
      "epoch:8 step:33815[D loss: 0.999970] [G loss: 1.000064]\n",
      "epoch:8 step:33820[D loss: 0.999987] [G loss: 1.000006]\n",
      "epoch:8 step:33825[D loss: 1.000027] [G loss: 0.999949]\n",
      "epoch:8 step:33830[D loss: 0.999966] [G loss: 1.000023]\n",
      "epoch:8 step:33835[D loss: 1.000014] [G loss: 0.999938]\n",
      "epoch:8 step:33840[D loss: 1.000009] [G loss: 0.999973]\n",
      "epoch:8 step:33845[D loss: 0.999931] [G loss: 1.000146]\n",
      "epoch:8 step:33850[D loss: 0.999935] [G loss: 1.000115]\n",
      "epoch:8 step:33855[D loss: 0.999979] [G loss: 1.000064]\n",
      "epoch:8 step:33860[D loss: 0.999968] [G loss: 1.000070]\n",
      "epoch:8 step:33865[D loss: 0.999967] [G loss: 1.000061]\n",
      "epoch:8 step:33870[D loss: 0.999985] [G loss: 1.000031]\n",
      "epoch:8 step:33875[D loss: 0.999980] [G loss: 1.000026]\n",
      "epoch:8 step:33880[D loss: 0.999966] [G loss: 1.000096]\n",
      "epoch:8 step:33885[D loss: 0.999977] [G loss: 1.000069]\n",
      "epoch:8 step:33890[D loss: 1.000056] [G loss: 0.999989]\n",
      "epoch:8 step:33895[D loss: 0.999944] [G loss: 1.000127]\n",
      "epoch:8 step:33900[D loss: 0.999945] [G loss: 1.000120]\n",
      "epoch:8 step:33905[D loss: 1.000003] [G loss: 1.000099]\n",
      "epoch:8 step:33910[D loss: 0.999974] [G loss: 1.000073]\n",
      "epoch:8 step:33915[D loss: 0.999977] [G loss: 1.000076]\n",
      "epoch:8 step:33920[D loss: 0.999977] [G loss: 1.000065]\n",
      "epoch:8 step:33925[D loss: 0.999969] [G loss: 1.000061]\n",
      "epoch:8 step:33930[D loss: 0.999992] [G loss: 1.000028]\n",
      "epoch:8 step:33935[D loss: 0.999964] [G loss: 1.000046]\n",
      "epoch:8 step:33940[D loss: 0.999957] [G loss: 1.000063]\n",
      "epoch:8 step:33945[D loss: 0.999974] [G loss: 1.000070]\n",
      "epoch:8 step:33950[D loss: 0.999969] [G loss: 1.000063]\n",
      "epoch:8 step:33955[D loss: 0.999989] [G loss: 1.000059]\n",
      "epoch:8 step:33960[D loss: 0.999968] [G loss: 1.000089]\n",
      "epoch:8 step:33965[D loss: 0.999952] [G loss: 1.000088]\n",
      "epoch:8 step:33970[D loss: 0.999991] [G loss: 1.000048]\n",
      "epoch:8 step:33975[D loss: 0.999965] [G loss: 1.000060]\n",
      "epoch:8 step:33980[D loss: 0.999970] [G loss: 1.000059]\n",
      "epoch:8 step:33985[D loss: 0.999969] [G loss: 1.000063]\n",
      "epoch:8 step:33990[D loss: 0.999977] [G loss: 1.000072]\n",
      "epoch:8 step:33995[D loss: 0.999975] [G loss: 1.000089]\n",
      "epoch:8 step:34000[D loss: 0.999978] [G loss: 1.000031]\n",
      "##############\n",
      "[0.88063806 0.85637337 0.83598408 0.81482939 0.79488813 0.8379538\n",
      " 0.86601975 0.84291621 0.79981771 0.83914827]\n",
      "##########\n",
      "epoch:8 step:34005[D loss: 0.999973] [G loss: 1.000096]\n",
      "epoch:8 step:34010[D loss: 0.999976] [G loss: 1.000085]\n",
      "epoch:8 step:34015[D loss: 0.999996] [G loss: 1.000042]\n",
      "epoch:8 step:34020[D loss: 0.999964] [G loss: 1.000083]\n",
      "epoch:8 step:34025[D loss: 0.999980] [G loss: 1.000083]\n",
      "epoch:8 step:34030[D loss: 0.999959] [G loss: 1.000083]\n",
      "epoch:8 step:34035[D loss: 1.000010] [G loss: 1.000012]\n",
      "epoch:8 step:34040[D loss: 0.999980] [G loss: 1.000069]\n",
      "epoch:8 step:34045[D loss: 0.999993] [G loss: 1.000037]\n",
      "epoch:8 step:34050[D loss: 0.999924] [G loss: 1.000159]\n",
      "epoch:8 step:34055[D loss: 0.999943] [G loss: 1.000126]\n",
      "epoch:8 step:34060[D loss: 0.999968] [G loss: 1.000086]\n",
      "epoch:8 step:34065[D loss: 0.999972] [G loss: 1.000067]\n",
      "epoch:8 step:34070[D loss: 0.999979] [G loss: 1.000059]\n",
      "epoch:8 step:34075[D loss: 0.999981] [G loss: 1.000043]\n",
      "epoch:8 step:34080[D loss: 0.999971] [G loss: 1.000060]\n",
      "epoch:8 step:34085[D loss: 0.999975] [G loss: 1.000051]\n",
      "epoch:8 step:34090[D loss: 0.999964] [G loss: 1.000060]\n",
      "epoch:8 step:34095[D loss: 0.999952] [G loss: 1.000072]\n",
      "epoch:8 step:34100[D loss: 0.999958] [G loss: 1.000063]\n",
      "epoch:8 step:34105[D loss: 0.999969] [G loss: 1.000064]\n",
      "epoch:8 step:34110[D loss: 0.999991] [G loss: 1.000023]\n",
      "epoch:8 step:34115[D loss: 0.999973] [G loss: 1.000064]\n",
      "epoch:8 step:34120[D loss: 0.999984] [G loss: 1.000042]\n",
      "epoch:8 step:34125[D loss: 0.999966] [G loss: 1.000106]\n",
      "epoch:8 step:34130[D loss: 0.999963] [G loss: 1.000065]\n",
      "epoch:8 step:34135[D loss: 0.999977] [G loss: 1.000068]\n",
      "epoch:8 step:34140[D loss: 0.999976] [G loss: 1.000039]\n",
      "epoch:8 step:34145[D loss: 0.999959] [G loss: 1.000038]\n",
      "epoch:8 step:34150[D loss: 1.000055] [G loss: 0.999991]\n",
      "epoch:8 step:34155[D loss: 0.999965] [G loss: 1.000079]\n",
      "epoch:8 step:34160[D loss: 1.000003] [G loss: 1.000083]\n",
      "epoch:8 step:34165[D loss: 0.999942] [G loss: 1.000118]\n",
      "epoch:8 step:34170[D loss: 0.999957] [G loss: 1.000099]\n",
      "epoch:8 step:34175[D loss: 0.999993] [G loss: 1.000022]\n",
      "epoch:8 step:34180[D loss: 0.999967] [G loss: 1.000050]\n",
      "epoch:8 step:34185[D loss: 1.000012] [G loss: 0.999970]\n",
      "epoch:8 step:34190[D loss: 1.000005] [G loss: 1.000025]\n",
      "epoch:8 step:34195[D loss: 0.999994] [G loss: 1.000057]\n",
      "epoch:8 step:34200[D loss: 0.999960] [G loss: 1.000085]\n",
      "##############\n",
      "[0.86207272 0.8584855  0.83113608 0.82268858 0.79673828 0.82595978\n",
      " 0.8925247  0.8540573  0.83993816 0.85864634]\n",
      "##########\n",
      "epoch:8 step:34205[D loss: 0.999960] [G loss: 1.000069]\n",
      "epoch:8 step:34210[D loss: 0.999970] [G loss: 1.000063]\n",
      "epoch:8 step:34215[D loss: 1.000018] [G loss: 1.000034]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:8 step:34220[D loss: 1.000003] [G loss: 0.999974]\n",
      "epoch:8 step:34225[D loss: 1.000031] [G loss: 0.999976]\n",
      "epoch:8 step:34230[D loss: 0.999939] [G loss: 1.000110]\n",
      "epoch:8 step:34235[D loss: 0.999976] [G loss: 1.000051]\n",
      "epoch:8 step:34240[D loss: 0.999989] [G loss: 1.000037]\n",
      "epoch:8 step:34245[D loss: 1.000022] [G loss: 1.000015]\n",
      "epoch:8 step:34250[D loss: 0.999977] [G loss: 1.000064]\n",
      "epoch:8 step:34255[D loss: 0.999986] [G loss: 1.000051]\n",
      "epoch:8 step:34260[D loss: 0.999954] [G loss: 1.000132]\n",
      "epoch:8 step:34265[D loss: 0.999992] [G loss: 1.000065]\n",
      "epoch:8 step:34270[D loss: 0.999971] [G loss: 1.000106]\n",
      "epoch:8 step:34275[D loss: 0.999972] [G loss: 1.000097]\n",
      "epoch:8 step:34280[D loss: 0.999982] [G loss: 1.000041]\n",
      "epoch:8 step:34285[D loss: 1.000017] [G loss: 1.000029]\n",
      "epoch:8 step:34290[D loss: 1.000020] [G loss: 0.999981]\n",
      "epoch:8 step:34295[D loss: 0.999924] [G loss: 1.000126]\n",
      "epoch:8 step:34300[D loss: 0.999990] [G loss: 1.000031]\n",
      "epoch:8 step:34305[D loss: 0.999939] [G loss: 1.000134]\n",
      "epoch:8 step:34310[D loss: 0.999970] [G loss: 1.000071]\n",
      "epoch:8 step:34315[D loss: 0.999978] [G loss: 1.000076]\n",
      "epoch:8 step:34320[D loss: 0.999972] [G loss: 1.000077]\n",
      "epoch:8 step:34325[D loss: 0.999978] [G loss: 1.000064]\n",
      "epoch:8 step:34330[D loss: 0.999974] [G loss: 1.000058]\n",
      "epoch:8 step:34335[D loss: 0.999971] [G loss: 1.000060]\n",
      "epoch:8 step:34340[D loss: 0.999961] [G loss: 1.000143]\n",
      "epoch:8 step:34345[D loss: 0.999999] [G loss: 1.000071]\n",
      "epoch:8 step:34350[D loss: 0.999956] [G loss: 1.000135]\n",
      "epoch:8 step:34355[D loss: 0.999931] [G loss: 1.000126]\n",
      "epoch:8 step:34360[D loss: 0.999969] [G loss: 1.000079]\n",
      "epoch:8 step:34365[D loss: 0.999967] [G loss: 1.000087]\n",
      "epoch:8 step:34370[D loss: 0.999976] [G loss: 1.000062]\n",
      "epoch:8 step:34375[D loss: 0.999978] [G loss: 1.000054]\n",
      "epoch:8 step:34380[D loss: 1.000001] [G loss: 1.000082]\n",
      "epoch:8 step:34385[D loss: 1.000032] [G loss: 0.999979]\n",
      "epoch:8 step:34390[D loss: 0.999919] [G loss: 1.000155]\n",
      "epoch:8 step:34395[D loss: 0.999941] [G loss: 1.000080]\n",
      "epoch:8 step:34400[D loss: 0.999965] [G loss: 1.000097]\n",
      "##############\n",
      "[0.88734089 0.8521884  0.83662767 0.81414728 0.80751742 0.85240885\n",
      " 0.88542932 0.8504221  0.81581574 0.85174685]\n",
      "##########\n",
      "epoch:8 step:34405[D loss: 0.999978] [G loss: 1.000071]\n",
      "epoch:8 step:34410[D loss: 1.000011] [G loss: 1.000000]\n",
      "epoch:8 step:34415[D loss: 0.999981] [G loss: 1.000048]\n",
      "epoch:8 step:34420[D loss: 0.999989] [G loss: 1.000036]\n",
      "epoch:8 step:34425[D loss: 0.999971] [G loss: 1.000050]\n",
      "epoch:8 step:34430[D loss: 0.999954] [G loss: 1.000165]\n",
      "epoch:8 step:34435[D loss: 0.999950] [G loss: 1.000120]\n",
      "epoch:8 step:34440[D loss: 0.999962] [G loss: 1.000088]\n",
      "epoch:8 step:34445[D loss: 0.999972] [G loss: 1.000054]\n",
      "epoch:8 step:34450[D loss: 0.999975] [G loss: 1.000059]\n",
      "epoch:8 step:34455[D loss: 0.999975] [G loss: 1.000052]\n",
      "epoch:8 step:34460[D loss: 0.999979] [G loss: 1.000073]\n",
      "epoch:8 step:34465[D loss: 0.999978] [G loss: 1.000066]\n",
      "epoch:8 step:34470[D loss: 0.999967] [G loss: 1.000073]\n",
      "epoch:8 step:34475[D loss: 0.999978] [G loss: 1.000044]\n",
      "epoch:8 step:34480[D loss: 0.999959] [G loss: 1.000076]\n",
      "epoch:8 step:34485[D loss: 0.999963] [G loss: 1.000085]\n",
      "epoch:8 step:34490[D loss: 0.999968] [G loss: 1.000044]\n",
      "epoch:8 step:34495[D loss: 0.999981] [G loss: 1.000058]\n",
      "epoch:8 step:34500[D loss: 1.000007] [G loss: 1.000018]\n",
      "epoch:8 step:34505[D loss: 0.999991] [G loss: 1.000063]\n",
      "epoch:8 step:34510[D loss: 0.999952] [G loss: 1.000094]\n",
      "epoch:8 step:34515[D loss: 1.000019] [G loss: 0.999999]\n",
      "epoch:8 step:34520[D loss: 0.999963] [G loss: 1.000060]\n",
      "epoch:8 step:34525[D loss: 0.999960] [G loss: 1.000107]\n",
      "epoch:8 step:34530[D loss: 0.999960] [G loss: 1.000126]\n",
      "epoch:8 step:34535[D loss: 0.999943] [G loss: 1.000134]\n",
      "epoch:8 step:34540[D loss: 0.999970] [G loss: 1.000073]\n",
      "epoch:8 step:34545[D loss: 0.999969] [G loss: 1.000101]\n",
      "epoch:8 step:34550[D loss: 0.999975] [G loss: 1.000046]\n",
      "epoch:8 step:34555[D loss: 0.999979] [G loss: 1.000040]\n",
      "epoch:8 step:34560[D loss: 0.999977] [G loss: 1.000048]\n",
      "epoch:8 step:34565[D loss: 1.000024] [G loss: 0.999950]\n",
      "epoch:8 step:34570[D loss: 0.999965] [G loss: 1.000077]\n",
      "epoch:8 step:34575[D loss: 0.999964] [G loss: 1.000065]\n",
      "epoch:8 step:34580[D loss: 0.999973] [G loss: 1.000055]\n",
      "epoch:8 step:34585[D loss: 0.999974] [G loss: 1.000062]\n",
      "epoch:8 step:34590[D loss: 0.999974] [G loss: 1.000057]\n",
      "epoch:8 step:34595[D loss: 1.000007] [G loss: 0.999989]\n",
      "epoch:8 step:34600[D loss: 0.999967] [G loss: 1.000056]\n",
      "##############\n",
      "[0.88930267 0.86895585 0.80249437 0.82927106 0.81065764 0.83682354\n",
      " 0.86901024 0.83451052 0.81625217 0.84356999]\n",
      "##########\n",
      "epoch:8 step:34605[D loss: 0.999992] [G loss: 1.000022]\n",
      "epoch:8 step:34610[D loss: 0.999964] [G loss: 1.000061]\n",
      "epoch:8 step:34615[D loss: 0.999967] [G loss: 1.000065]\n",
      "epoch:8 step:34620[D loss: 1.000007] [G loss: 1.000012]\n",
      "epoch:8 step:34625[D loss: 0.999961] [G loss: 1.000074]\n",
      "epoch:8 step:34630[D loss: 0.999985] [G loss: 1.000051]\n",
      "epoch:8 step:34635[D loss: 0.999990] [G loss: 1.000017]\n",
      "epoch:8 step:34640[D loss: 0.999969] [G loss: 1.000077]\n",
      "epoch:8 step:34645[D loss: 0.999978] [G loss: 1.000068]\n",
      "epoch:8 step:34650[D loss: 0.999974] [G loss: 1.000065]\n",
      "epoch:8 step:34655[D loss: 0.999989] [G loss: 1.000044]\n",
      "epoch:8 step:34660[D loss: 0.999966] [G loss: 1.000055]\n",
      "epoch:8 step:34665[D loss: 0.999979] [G loss: 1.000045]\n",
      "epoch:8 step:34670[D loss: 1.000022] [G loss: 0.999997]\n",
      "epoch:8 step:34675[D loss: 0.999984] [G loss: 1.000033]\n",
      "epoch:8 step:34680[D loss: 0.999953] [G loss: 1.000079]\n",
      "epoch:8 step:34685[D loss: 1.000085] [G loss: 0.999955]\n",
      "epoch:8 step:34690[D loss: 0.999937] [G loss: 1.000118]\n",
      "epoch:8 step:34695[D loss: 0.999961] [G loss: 1.000068]\n",
      "epoch:8 step:34700[D loss: 0.999959] [G loss: 1.000069]\n",
      "epoch:8 step:34705[D loss: 1.000001] [G loss: 1.000029]\n",
      "epoch:8 step:34710[D loss: 1.000007] [G loss: 1.000002]\n",
      "epoch:8 step:34715[D loss: 1.000026] [G loss: 1.000025]\n",
      "epoch:8 step:34720[D loss: 0.999942] [G loss: 1.000146]\n",
      "epoch:8 step:34725[D loss: 0.999965] [G loss: 1.000086]\n",
      "epoch:8 step:34730[D loss: 0.999972] [G loss: 1.000089]\n",
      "epoch:8 step:34735[D loss: 0.999962] [G loss: 1.000171]\n",
      "epoch:8 step:34740[D loss: 0.999971] [G loss: 1.000124]\n",
      "epoch:8 step:34745[D loss: 0.999951] [G loss: 1.000116]\n",
      "epoch:8 step:34750[D loss: 0.999954] [G loss: 1.000132]\n",
      "epoch:8 step:34755[D loss: 0.999968] [G loss: 1.000094]\n",
      "epoch:8 step:34760[D loss: 0.999986] [G loss: 1.000014]\n",
      "epoch:8 step:34765[D loss: 0.999995] [G loss: 1.000045]\n",
      "epoch:8 step:34770[D loss: 0.999996] [G loss: 1.000093]\n",
      "epoch:8 step:34775[D loss: 1.000004] [G loss: 1.000034]\n",
      "epoch:8 step:34780[D loss: 0.999952] [G loss: 1.000088]\n",
      "epoch:8 step:34785[D loss: 0.999977] [G loss: 1.000079]\n",
      "epoch:8 step:34790[D loss: 0.999967] [G loss: 1.000081]\n",
      "epoch:8 step:34795[D loss: 0.999976] [G loss: 1.000074]\n",
      "epoch:8 step:34800[D loss: 0.999969] [G loss: 1.000059]\n",
      "##############\n",
      "[0.884781   0.86840065 0.82526193 0.85150517 0.78201988 0.83060206\n",
      " 0.85018041 0.86018332 0.80208135 0.82404082]\n",
      "##########\n",
      "epoch:8 step:34805[D loss: 1.000016] [G loss: 0.999990]\n",
      "epoch:8 step:34810[D loss: 0.999999] [G loss: 0.999993]\n",
      "epoch:8 step:34815[D loss: 1.000012] [G loss: 1.000062]\n",
      "epoch:8 step:34820[D loss: 0.999954] [G loss: 1.000095]\n",
      "epoch:8 step:34825[D loss: 0.999964] [G loss: 1.000065]\n",
      "epoch:8 step:34830[D loss: 0.999968] [G loss: 1.000066]\n",
      "epoch:8 step:34835[D loss: 0.999977] [G loss: 1.000047]\n",
      "epoch:8 step:34840[D loss: 1.000005] [G loss: 0.999971]\n",
      "epoch:8 step:34845[D loss: 1.000084] [G loss: 0.999857]\n",
      "epoch:8 step:34850[D loss: 0.999978] [G loss: 0.999976]\n",
      "epoch:8 step:34855[D loss: 0.999983] [G loss: 1.000037]\n",
      "epoch:8 step:34860[D loss: 1.000034] [G loss: 0.999971]\n",
      "epoch:8 step:34865[D loss: 0.999960] [G loss: 1.000064]\n",
      "epoch:8 step:34870[D loss: 0.999994] [G loss: 1.000005]\n",
      "epoch:8 step:34875[D loss: 0.999980] [G loss: 1.000011]\n",
      "epoch:8 step:34880[D loss: 0.999977] [G loss: 1.000076]\n",
      "epoch:8 step:34885[D loss: 0.999982] [G loss: 1.000034]\n",
      "epoch:8 step:34890[D loss: 0.999980] [G loss: 1.000053]\n",
      "epoch:8 step:34895[D loss: 1.000002] [G loss: 1.000048]\n",
      "epoch:8 step:34900[D loss: 0.999947] [G loss: 1.000132]\n",
      "epoch:8 step:34905[D loss: 0.999956] [G loss: 1.000063]\n",
      "epoch:8 step:34910[D loss: 0.999969] [G loss: 1.000076]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:8 step:34915[D loss: 0.999968] [G loss: 1.000099]\n",
      "epoch:8 step:34920[D loss: 0.999984] [G loss: 1.000069]\n",
      "epoch:8 step:34925[D loss: 0.999968] [G loss: 1.000087]\n",
      "epoch:8 step:34930[D loss: 0.999975] [G loss: 1.000068]\n",
      "epoch:8 step:34935[D loss: 0.999965] [G loss: 1.000081]\n",
      "epoch:8 step:34940[D loss: 0.999973] [G loss: 1.000075]\n",
      "epoch:8 step:34945[D loss: 0.999987] [G loss: 1.000033]\n",
      "epoch:8 step:34950[D loss: 0.999993] [G loss: 1.000056]\n",
      "epoch:8 step:34955[D loss: 0.999990] [G loss: 0.999985]\n",
      "epoch:8 step:34960[D loss: 0.999981] [G loss: 1.000024]\n",
      "epoch:8 step:34965[D loss: 0.999958] [G loss: 1.000082]\n",
      "epoch:8 step:34970[D loss: 0.999969] [G loss: 1.000072]\n",
      "epoch:8 step:34975[D loss: 0.999976] [G loss: 1.000067]\n",
      "epoch:8 step:34980[D loss: 1.000020] [G loss: 0.999996]\n",
      "epoch:8 step:34985[D loss: 0.999986] [G loss: 1.000086]\n",
      "epoch:8 step:34990[D loss: 0.999922] [G loss: 1.000172]\n",
      "epoch:8 step:34995[D loss: 0.999962] [G loss: 1.000075]\n",
      "epoch:8 step:35000[D loss: 0.999970] [G loss: 1.000071]\n",
      "##############\n",
      "[0.86698319 0.86414481 0.81750777 0.82261249 0.79637606 0.8193568\n",
      " 0.88431407 0.85977888 0.80169145 0.84883484]\n",
      "##########\n",
      "epoch:8 step:35005[D loss: 0.999974] [G loss: 1.000077]\n",
      "epoch:8 step:35010[D loss: 0.999977] [G loss: 1.000071]\n",
      "epoch:8 step:35015[D loss: 0.999963] [G loss: 1.000074]\n",
      "epoch:8 step:35020[D loss: 0.999966] [G loss: 1.000093]\n",
      "epoch:8 step:35025[D loss: 0.999974] [G loss: 1.000065]\n",
      "epoch:8 step:35030[D loss: 0.999973] [G loss: 1.000056]\n",
      "epoch:8 step:35035[D loss: 0.999968] [G loss: 1.000075]\n",
      "epoch:8 step:35040[D loss: 0.999960] [G loss: 1.000088]\n",
      "epoch:8 step:35045[D loss: 0.999969] [G loss: 1.000064]\n",
      "epoch:8 step:35050[D loss: 0.999980] [G loss: 1.000052]\n",
      "epoch:8 step:35055[D loss: 0.999967] [G loss: 1.000071]\n",
      "epoch:8 step:35060[D loss: 0.999983] [G loss: 1.000063]\n",
      "epoch:8 step:35065[D loss: 0.999993] [G loss: 1.000034]\n",
      "epoch:8 step:35070[D loss: 0.999964] [G loss: 1.000080]\n",
      "epoch:8 step:35075[D loss: 0.999972] [G loss: 1.000055]\n",
      "epoch:8 step:35080[D loss: 0.999971] [G loss: 1.000054]\n",
      "epoch:8 step:35085[D loss: 1.000012] [G loss: 1.000039]\n",
      "epoch:8 step:35090[D loss: 0.999977] [G loss: 1.000101]\n",
      "epoch:8 step:35095[D loss: 0.999949] [G loss: 1.000071]\n",
      "epoch:8 step:35100[D loss: 0.999983] [G loss: 1.000067]\n",
      "epoch:8 step:35105[D loss: 0.999956] [G loss: 1.000091]\n",
      "epoch:8 step:35110[D loss: 1.000000] [G loss: 1.000064]\n",
      "epoch:8 step:35115[D loss: 0.999977] [G loss: 1.000065]\n",
      "epoch:8 step:35120[D loss: 0.999998] [G loss: 1.000034]\n",
      "epoch:8 step:35125[D loss: 0.999964] [G loss: 1.000095]\n",
      "epoch:8 step:35130[D loss: 1.000017] [G loss: 0.999908]\n",
      "epoch:8 step:35135[D loss: 0.999935] [G loss: 1.000038]\n",
      "epoch:8 step:35140[D loss: 0.999968] [G loss: 1.000055]\n",
      "epoch:8 step:35145[D loss: 0.999987] [G loss: 1.000068]\n",
      "epoch:9 step:35150[D loss: 0.999968] [G loss: 1.000078]\n",
      "epoch:9 step:35155[D loss: 0.999970] [G loss: 1.000061]\n",
      "epoch:9 step:35160[D loss: 0.999996] [G loss: 1.000023]\n",
      "epoch:9 step:35165[D loss: 0.999962] [G loss: 1.000076]\n",
      "epoch:9 step:35170[D loss: 1.000014] [G loss: 1.000039]\n",
      "epoch:9 step:35175[D loss: 0.999949] [G loss: 1.000070]\n",
      "epoch:9 step:35180[D loss: 0.999989] [G loss: 1.000070]\n",
      "epoch:9 step:35185[D loss: 0.999980] [G loss: 1.000075]\n",
      "epoch:9 step:35190[D loss: 0.999975] [G loss: 1.000028]\n",
      "epoch:9 step:35195[D loss: 0.999970] [G loss: 1.000074]\n",
      "epoch:9 step:35200[D loss: 1.000010] [G loss: 1.000018]\n",
      "##############\n",
      "[0.87001286 0.86863518 0.82887057 0.83903073 0.79067272 0.84835735\n",
      " 0.86592613 0.84764208 0.7894077  0.84197491]\n",
      "##########\n",
      "epoch:9 step:35205[D loss: 0.999976] [G loss: 1.000054]\n",
      "epoch:9 step:35210[D loss: 0.999971] [G loss: 1.000082]\n",
      "epoch:9 step:35215[D loss: 0.999970] [G loss: 1.000069]\n",
      "epoch:9 step:35220[D loss: 0.999999] [G loss: 1.000022]\n",
      "epoch:9 step:35225[D loss: 0.999998] [G loss: 1.000049]\n",
      "epoch:9 step:35230[D loss: 0.999989] [G loss: 1.000117]\n",
      "epoch:9 step:35235[D loss: 0.999998] [G loss: 1.000095]\n",
      "epoch:9 step:35240[D loss: 0.999942] [G loss: 1.000106]\n",
      "epoch:9 step:35245[D loss: 0.999967] [G loss: 1.000112]\n",
      "epoch:9 step:35250[D loss: 0.999979] [G loss: 1.000058]\n",
      "epoch:9 step:35255[D loss: 0.999972] [G loss: 1.000049]\n",
      "epoch:9 step:35260[D loss: 0.999981] [G loss: 1.000028]\n",
      "epoch:9 step:35265[D loss: 1.000109] [G loss: 0.999960]\n",
      "epoch:9 step:35270[D loss: 1.000038] [G loss: 0.999893]\n",
      "epoch:9 step:35275[D loss: 1.000005] [G loss: 1.000036]\n",
      "epoch:9 step:35280[D loss: 0.999927] [G loss: 1.000154]\n",
      "epoch:9 step:35285[D loss: 0.999925] [G loss: 1.000139]\n",
      "epoch:9 step:35290[D loss: 0.999956] [G loss: 1.000087]\n",
      "epoch:9 step:35295[D loss: 0.999976] [G loss: 1.000061]\n",
      "epoch:9 step:35300[D loss: 0.999980] [G loss: 1.000042]\n",
      "epoch:9 step:35305[D loss: 1.000100] [G loss: 0.999828]\n",
      "epoch:9 step:35310[D loss: 0.999934] [G loss: 1.000113]\n",
      "epoch:9 step:35315[D loss: 1.000010] [G loss: 0.999980]\n",
      "epoch:9 step:35320[D loss: 0.999977] [G loss: 1.000034]\n",
      "epoch:9 step:35325[D loss: 0.999947] [G loss: 1.000157]\n",
      "epoch:9 step:35330[D loss: 0.999943] [G loss: 1.000154]\n",
      "epoch:9 step:35335[D loss: 0.999962] [G loss: 1.000119]\n",
      "epoch:9 step:35340[D loss: 0.999960] [G loss: 1.000089]\n",
      "epoch:9 step:35345[D loss: 0.999978] [G loss: 1.000062]\n",
      "epoch:9 step:35350[D loss: 1.000001] [G loss: 0.999990]\n",
      "epoch:9 step:35355[D loss: 0.999968] [G loss: 1.000053]\n",
      "epoch:9 step:35360[D loss: 1.000008] [G loss: 1.000012]\n",
      "epoch:9 step:35365[D loss: 0.999960] [G loss: 1.000056]\n",
      "epoch:9 step:35370[D loss: 0.999976] [G loss: 1.000072]\n",
      "epoch:9 step:35375[D loss: 0.999971] [G loss: 1.000064]\n",
      "epoch:9 step:35380[D loss: 0.999970] [G loss: 1.000074]\n",
      "epoch:9 step:35385[D loss: 0.999976] [G loss: 1.000071]\n",
      "epoch:9 step:35390[D loss: 0.999997] [G loss: 1.000033]\n",
      "epoch:9 step:35395[D loss: 0.999957] [G loss: 1.000073]\n",
      "epoch:9 step:35400[D loss: 1.000003] [G loss: 0.999998]\n",
      "##############\n",
      "[0.86845606 0.86697718 0.8230835  0.82270182 0.79722838 0.81995583\n",
      " 0.87367908 0.85873695 0.81337641 0.82904464]\n",
      "##########\n",
      "epoch:9 step:35405[D loss: 1.000003] [G loss: 1.000012]\n",
      "epoch:9 step:35410[D loss: 0.999965] [G loss: 1.000091]\n",
      "epoch:9 step:35415[D loss: 0.999997] [G loss: 1.000078]\n",
      "epoch:9 step:35420[D loss: 0.999972] [G loss: 1.000075]\n",
      "epoch:9 step:35425[D loss: 0.999955] [G loss: 1.000080]\n",
      "epoch:9 step:35430[D loss: 0.999969] [G loss: 1.000076]\n",
      "epoch:9 step:35435[D loss: 1.000000] [G loss: 1.000022]\n",
      "epoch:9 step:35440[D loss: 0.999999] [G loss: 1.000001]\n",
      "epoch:9 step:35445[D loss: 0.999959] [G loss: 1.000109]\n",
      "epoch:9 step:35450[D loss: 1.000045] [G loss: 1.000031]\n",
      "epoch:9 step:35455[D loss: 0.999905] [G loss: 1.000145]\n",
      "epoch:9 step:35460[D loss: 0.999972] [G loss: 1.000091]\n",
      "epoch:9 step:35465[D loss: 0.999976] [G loss: 1.000058]\n",
      "epoch:9 step:35470[D loss: 0.999981] [G loss: 1.000062]\n",
      "epoch:9 step:35475[D loss: 0.999994] [G loss: 1.000089]\n",
      "epoch:9 step:35480[D loss: 0.999963] [G loss: 1.000103]\n",
      "epoch:9 step:35485[D loss: 0.999967] [G loss: 1.000074]\n",
      "epoch:9 step:35490[D loss: 0.999962] [G loss: 1.000071]\n",
      "epoch:9 step:35495[D loss: 0.999971] [G loss: 1.000079]\n",
      "epoch:9 step:35500[D loss: 1.000007] [G loss: 1.000011]\n",
      "epoch:9 step:35505[D loss: 0.999958] [G loss: 1.000094]\n",
      "epoch:9 step:35510[D loss: 0.999978] [G loss: 1.000073]\n",
      "epoch:9 step:35515[D loss: 0.999961] [G loss: 1.000079]\n",
      "epoch:9 step:35520[D loss: 0.999989] [G loss: 1.000050]\n",
      "epoch:9 step:35525[D loss: 0.999972] [G loss: 1.000059]\n",
      "epoch:9 step:35530[D loss: 0.999960] [G loss: 1.000094]\n",
      "epoch:9 step:35535[D loss: 0.999984] [G loss: 1.000082]\n",
      "epoch:9 step:35540[D loss: 0.999957] [G loss: 1.000092]\n",
      "epoch:9 step:35545[D loss: 0.999967] [G loss: 1.000068]\n",
      "epoch:9 step:35550[D loss: 0.999975] [G loss: 1.000066]\n",
      "epoch:9 step:35555[D loss: 1.000044] [G loss: 0.999961]\n",
      "epoch:9 step:35560[D loss: 1.000016] [G loss: 1.000001]\n",
      "epoch:9 step:35565[D loss: 0.999960] [G loss: 1.000094]\n",
      "epoch:9 step:35570[D loss: 0.999979] [G loss: 1.000046]\n",
      "epoch:9 step:35575[D loss: 0.999969] [G loss: 1.000076]\n",
      "epoch:9 step:35580[D loss: 0.999987] [G loss: 1.000028]\n",
      "epoch:9 step:35585[D loss: 1.000034] [G loss: 1.000010]\n",
      "epoch:9 step:35590[D loss: 1.000018] [G loss: 1.000083]\n",
      "epoch:9 step:35595[D loss: 0.999980] [G loss: 1.000029]\n",
      "epoch:9 step:35600[D loss: 1.000008] [G loss: 1.000056]\n",
      "##############\n",
      "[0.87620284 0.85071168 0.84124181 0.81677154 0.79639618 0.82355521\n",
      " 0.86059824 0.82050943 0.80975229 0.84711004]\n",
      "##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:9 step:35605[D loss: 0.999938] [G loss: 1.000135]\n",
      "epoch:9 step:35610[D loss: 0.999943] [G loss: 1.000089]\n",
      "epoch:9 step:35615[D loss: 0.999984] [G loss: 1.000038]\n",
      "epoch:9 step:35620[D loss: 0.999972] [G loss: 1.000051]\n",
      "epoch:9 step:35625[D loss: 1.000077] [G loss: 0.999916]\n",
      "epoch:9 step:35630[D loss: 0.999951] [G loss: 1.000032]\n",
      "epoch:9 step:35635[D loss: 0.999965] [G loss: 1.000119]\n",
      "epoch:9 step:35640[D loss: 1.000005] [G loss: 1.000093]\n",
      "epoch:9 step:35645[D loss: 0.999977] [G loss: 1.000056]\n",
      "epoch:9 step:35650[D loss: 0.999981] [G loss: 1.000052]\n",
      "epoch:9 step:35655[D loss: 0.999990] [G loss: 1.000096]\n",
      "epoch:9 step:35660[D loss: 0.999945] [G loss: 1.000075]\n",
      "epoch:9 step:35665[D loss: 0.999999] [G loss: 1.000015]\n",
      "epoch:9 step:35670[D loss: 0.999998] [G loss: 1.000085]\n",
      "epoch:9 step:35675[D loss: 0.999950] [G loss: 1.000074]\n",
      "epoch:9 step:35680[D loss: 1.000000] [G loss: 1.000114]\n",
      "epoch:9 step:35685[D loss: 0.999997] [G loss: 1.000154]\n",
      "epoch:9 step:35690[D loss: 0.999997] [G loss: 1.000023]\n",
      "epoch:9 step:35695[D loss: 0.999961] [G loss: 1.000135]\n",
      "epoch:9 step:35700[D loss: 0.999944] [G loss: 1.000103]\n",
      "epoch:9 step:35705[D loss: 0.999973] [G loss: 1.000029]\n",
      "epoch:9 step:35710[D loss: 1.000046] [G loss: 0.999895]\n",
      "epoch:9 step:35715[D loss: 0.999976] [G loss: 1.000043]\n",
      "epoch:9 step:35720[D loss: 1.000068] [G loss: 0.999901]\n",
      "epoch:9 step:35725[D loss: 0.999957] [G loss: 1.000050]\n",
      "epoch:9 step:35730[D loss: 1.000002] [G loss: 1.000118]\n",
      "epoch:9 step:35735[D loss: 0.999958] [G loss: 1.000135]\n",
      "epoch:9 step:35740[D loss: 0.999981] [G loss: 1.000051]\n",
      "epoch:9 step:35745[D loss: 0.999976] [G loss: 1.000057]\n",
      "epoch:9 step:35750[D loss: 0.999982] [G loss: 1.000076]\n",
      "epoch:9 step:35755[D loss: 1.000008] [G loss: 1.000062]\n",
      "epoch:9 step:35760[D loss: 1.000000] [G loss: 1.000047]\n",
      "epoch:9 step:35765[D loss: 0.999966] [G loss: 1.000053]\n",
      "epoch:9 step:35770[D loss: 0.999965] [G loss: 1.000101]\n",
      "epoch:9 step:35775[D loss: 0.999938] [G loss: 1.000112]\n",
      "epoch:9 step:35780[D loss: 0.999967] [G loss: 1.000079]\n",
      "epoch:9 step:35785[D loss: 0.999964] [G loss: 1.000084]\n",
      "epoch:9 step:35790[D loss: 0.999970] [G loss: 1.000076]\n",
      "epoch:9 step:35795[D loss: 0.999970] [G loss: 1.000089]\n",
      "epoch:9 step:35800[D loss: 1.000010] [G loss: 1.000075]\n",
      "##############\n",
      "[0.86264363 0.85708763 0.84662138 0.81867437 0.79978718 0.8408953\n",
      " 0.8813028  0.85063699 0.82143734 0.86611397]\n",
      "##########\n",
      "epoch:9 step:35805[D loss: 0.999949] [G loss: 1.000046]\n",
      "epoch:9 step:35810[D loss: 0.999991] [G loss: 1.000029]\n",
      "epoch:9 step:35815[D loss: 1.000003] [G loss: 1.000071]\n",
      "epoch:9 step:35820[D loss: 0.999937] [G loss: 1.000091]\n",
      "epoch:9 step:35825[D loss: 0.999974] [G loss: 1.000084]\n",
      "epoch:9 step:35830[D loss: 0.999980] [G loss: 1.000029]\n",
      "epoch:9 step:35835[D loss: 0.999972] [G loss: 1.000063]\n",
      "epoch:9 step:35840[D loss: 1.000000] [G loss: 0.999997]\n",
      "epoch:9 step:35845[D loss: 0.999999] [G loss: 1.000013]\n",
      "epoch:9 step:35850[D loss: 0.999946] [G loss: 1.000112]\n",
      "epoch:9 step:35855[D loss: 0.999960] [G loss: 1.000062]\n",
      "epoch:9 step:35860[D loss: 0.999959] [G loss: 1.000077]\n",
      "epoch:9 step:35865[D loss: 1.000009] [G loss: 0.999992]\n",
      "epoch:9 step:35870[D loss: 1.000045] [G loss: 0.999960]\n",
      "epoch:9 step:35875[D loss: 0.999966] [G loss: 1.000028]\n",
      "epoch:9 step:35880[D loss: 0.999971] [G loss: 1.000084]\n",
      "epoch:9 step:35885[D loss: 0.999964] [G loss: 1.000062]\n",
      "epoch:9 step:35890[D loss: 0.999953] [G loss: 1.000085]\n",
      "epoch:9 step:35895[D loss: 0.999974] [G loss: 1.000060]\n",
      "epoch:9 step:35900[D loss: 0.999967] [G loss: 1.000081]\n",
      "epoch:9 step:35905[D loss: 0.999970] [G loss: 1.000066]\n",
      "epoch:9 step:35910[D loss: 0.999968] [G loss: 1.000090]\n",
      "epoch:9 step:35915[D loss: 0.999996] [G loss: 1.000046]\n",
      "epoch:9 step:35920[D loss: 0.999933] [G loss: 1.000133]\n",
      "epoch:9 step:35925[D loss: 0.999950] [G loss: 1.000081]\n",
      "epoch:9 step:35930[D loss: 0.999978] [G loss: 1.000063]\n",
      "epoch:9 step:35935[D loss: 0.999946] [G loss: 1.000098]\n",
      "epoch:9 step:35940[D loss: 1.000038] [G loss: 0.999952]\n",
      "epoch:9 step:35945[D loss: 1.000019] [G loss: 0.999995]\n",
      "epoch:9 step:35950[D loss: 0.999919] [G loss: 1.000133]\n",
      "epoch:9 step:35955[D loss: 0.999967] [G loss: 1.000087]\n",
      "epoch:9 step:35960[D loss: 0.999963] [G loss: 1.000116]\n",
      "epoch:9 step:35965[D loss: 0.999964] [G loss: 1.000075]\n",
      "epoch:9 step:35970[D loss: 0.999966] [G loss: 1.000088]\n",
      "epoch:9 step:35975[D loss: 0.999969] [G loss: 1.000063]\n",
      "epoch:9 step:35980[D loss: 0.999961] [G loss: 1.000064]\n",
      "epoch:9 step:35985[D loss: 0.999971] [G loss: 1.000088]\n",
      "epoch:9 step:35990[D loss: 0.999969] [G loss: 1.000090]\n",
      "epoch:9 step:35995[D loss: 0.999973] [G loss: 1.000086]\n",
      "epoch:9 step:36000[D loss: 0.999981] [G loss: 1.000087]\n",
      "##############\n",
      "[0.87559974 0.86310838 0.81406317 0.83838536 0.79463209 0.82729208\n",
      " 0.88274414 0.85702442 0.81690499 0.83561079]\n",
      "##########\n",
      "epoch:9 step:36005[D loss: 0.999964] [G loss: 1.000074]\n",
      "epoch:9 step:36010[D loss: 0.999952] [G loss: 1.000121]\n",
      "epoch:9 step:36015[D loss: 0.999971] [G loss: 1.000064]\n",
      "epoch:9 step:36020[D loss: 0.999962] [G loss: 1.000085]\n",
      "epoch:9 step:36025[D loss: 0.999987] [G loss: 1.000035]\n",
      "epoch:9 step:36030[D loss: 0.999972] [G loss: 1.000067]\n",
      "epoch:9 step:36035[D loss: 0.999984] [G loss: 1.000024]\n",
      "epoch:9 step:36040[D loss: 0.999977] [G loss: 1.000113]\n",
      "epoch:9 step:36045[D loss: 0.999971] [G loss: 1.000089]\n",
      "epoch:9 step:36050[D loss: 0.999951] [G loss: 1.000078]\n",
      "epoch:9 step:36055[D loss: 1.000010] [G loss: 0.999949]\n",
      "epoch:9 step:36060[D loss: 1.000016] [G loss: 1.000010]\n",
      "epoch:9 step:36065[D loss: 0.999974] [G loss: 1.000006]\n",
      "epoch:9 step:36070[D loss: 1.000077] [G loss: 0.999905]\n",
      "epoch:9 step:36075[D loss: 0.999902] [G loss: 1.000094]\n",
      "epoch:9 step:36080[D loss: 0.999962] [G loss: 1.000050]\n",
      "epoch:9 step:36085[D loss: 1.000018] [G loss: 0.999949]\n",
      "epoch:9 step:36090[D loss: 0.999958] [G loss: 1.000061]\n",
      "epoch:9 step:36095[D loss: 0.999974] [G loss: 1.000079]\n",
      "epoch:9 step:36100[D loss: 0.999981] [G loss: 0.999928]\n",
      "epoch:9 step:36105[D loss: 1.000015] [G loss: 1.000020]\n",
      "epoch:9 step:36110[D loss: 0.999957] [G loss: 1.000049]\n",
      "epoch:9 step:36115[D loss: 0.999962] [G loss: 1.000062]\n",
      "epoch:9 step:36120[D loss: 0.999973] [G loss: 1.000050]\n",
      "epoch:9 step:36125[D loss: 1.000021] [G loss: 0.999964]\n",
      "epoch:9 step:36130[D loss: 1.000059] [G loss: 0.999978]\n",
      "epoch:9 step:36135[D loss: 0.999947] [G loss: 1.000080]\n",
      "epoch:9 step:36140[D loss: 0.999968] [G loss: 1.000048]\n",
      "epoch:9 step:36145[D loss: 0.999972] [G loss: 1.000035]\n",
      "epoch:9 step:36150[D loss: 0.999970] [G loss: 1.000066]\n",
      "epoch:9 step:36155[D loss: 0.999975] [G loss: 1.000063]\n",
      "epoch:9 step:36160[D loss: 0.999979] [G loss: 1.000086]\n",
      "epoch:9 step:36165[D loss: 0.999965] [G loss: 1.000060]\n",
      "epoch:9 step:36170[D loss: 0.999991] [G loss: 1.000013]\n",
      "epoch:9 step:36175[D loss: 0.999955] [G loss: 1.000058]\n",
      "epoch:9 step:36180[D loss: 0.999964] [G loss: 1.000061]\n",
      "epoch:9 step:36185[D loss: 0.999957] [G loss: 1.000071]\n",
      "epoch:9 step:36190[D loss: 0.999964] [G loss: 1.000081]\n",
      "epoch:9 step:36195[D loss: 0.999983] [G loss: 1.000074]\n",
      "epoch:9 step:36200[D loss: 0.999961] [G loss: 1.000072]\n",
      "##############\n",
      "[0.88277957 0.86082501 0.83209018 0.81449328 0.79117482 0.83727131\n",
      " 0.87699044 0.82973482 0.81117719 0.86515348]\n",
      "##########\n",
      "epoch:9 step:36205[D loss: 0.999969] [G loss: 1.000106]\n",
      "epoch:9 step:36210[D loss: 0.999977] [G loss: 1.000098]\n",
      "epoch:9 step:36215[D loss: 0.999973] [G loss: 1.000050]\n",
      "epoch:9 step:36220[D loss: 0.999988] [G loss: 1.000008]\n",
      "epoch:9 step:36225[D loss: 1.000018] [G loss: 1.000007]\n",
      "epoch:9 step:36230[D loss: 0.999997] [G loss: 1.000024]\n",
      "epoch:9 step:36235[D loss: 0.999996] [G loss: 1.000057]\n",
      "epoch:9 step:36240[D loss: 0.999961] [G loss: 1.000092]\n",
      "epoch:9 step:36245[D loss: 0.999975] [G loss: 1.000088]\n",
      "epoch:9 step:36250[D loss: 0.999996] [G loss: 1.000046]\n",
      "epoch:9 step:36255[D loss: 1.000004] [G loss: 0.999993]\n",
      "epoch:9 step:36260[D loss: 1.000007] [G loss: 0.999982]\n",
      "epoch:9 step:36265[D loss: 1.000039] [G loss: 0.999987]\n",
      "epoch:9 step:36270[D loss: 0.999978] [G loss: 1.000047]\n",
      "epoch:9 step:36275[D loss: 0.999966] [G loss: 1.000106]\n",
      "epoch:9 step:36280[D loss: 0.999951] [G loss: 1.000114]\n",
      "epoch:9 step:36285[D loss: 0.999971] [G loss: 1.000093]\n",
      "epoch:9 step:36290[D loss: 0.999987] [G loss: 1.000059]\n",
      "epoch:9 step:36295[D loss: 1.000017] [G loss: 1.000015]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:9 step:36300[D loss: 0.999946] [G loss: 1.000185]\n",
      "epoch:9 step:36305[D loss: 0.999956] [G loss: 1.000128]\n",
      "epoch:9 step:36310[D loss: 0.999951] [G loss: 1.000096]\n",
      "epoch:9 step:36315[D loss: 0.999956] [G loss: 1.000085]\n",
      "epoch:9 step:36320[D loss: 0.999983] [G loss: 1.000051]\n",
      "epoch:9 step:36325[D loss: 1.000015] [G loss: 1.000038]\n",
      "epoch:9 step:36330[D loss: 0.999981] [G loss: 1.000068]\n",
      "epoch:9 step:36335[D loss: 0.999951] [G loss: 1.000049]\n",
      "epoch:9 step:36340[D loss: 0.999956] [G loss: 1.000094]\n",
      "epoch:9 step:36345[D loss: 0.999958] [G loss: 1.000085]\n",
      "epoch:9 step:36350[D loss: 0.999975] [G loss: 1.000063]\n",
      "epoch:9 step:36355[D loss: 0.999957] [G loss: 1.000086]\n",
      "epoch:9 step:36360[D loss: 0.999992] [G loss: 1.000053]\n",
      "epoch:9 step:36365[D loss: 0.999990] [G loss: 1.000075]\n",
      "epoch:9 step:36370[D loss: 0.999996] [G loss: 1.000022]\n",
      "epoch:9 step:36375[D loss: 1.000000] [G loss: 1.000041]\n",
      "epoch:9 step:36380[D loss: 0.999993] [G loss: 1.000066]\n",
      "epoch:9 step:36385[D loss: 0.999975] [G loss: 1.000084]\n",
      "epoch:9 step:36390[D loss: 0.999988] [G loss: 0.999988]\n",
      "epoch:9 step:36395[D loss: 1.000008] [G loss: 0.999995]\n",
      "epoch:9 step:36400[D loss: 0.999930] [G loss: 1.000088]\n",
      "##############\n",
      "[0.85046609 0.85589922 0.82432203 0.82194217 0.82356597 0.82712814\n",
      " 0.88373946 0.85398199 0.81230432 0.84050427]\n",
      "##########\n",
      "epoch:9 step:36405[D loss: 0.999985] [G loss: 1.000022]\n",
      "epoch:9 step:36410[D loss: 0.999983] [G loss: 1.000038]\n",
      "epoch:9 step:36415[D loss: 0.999964] [G loss: 1.000080]\n",
      "epoch:9 step:36420[D loss: 1.000017] [G loss: 0.999966]\n",
      "epoch:9 step:36425[D loss: 0.999945] [G loss: 1.000150]\n",
      "epoch:9 step:36430[D loss: 0.999948] [G loss: 1.000082]\n",
      "epoch:9 step:36435[D loss: 1.000022] [G loss: 1.000002]\n",
      "epoch:9 step:36440[D loss: 0.999970] [G loss: 1.000056]\n",
      "epoch:9 step:36445[D loss: 0.999979] [G loss: 1.000043]\n",
      "epoch:9 step:36450[D loss: 0.999973] [G loss: 1.000066]\n",
      "epoch:9 step:36455[D loss: 0.999967] [G loss: 1.000063]\n",
      "epoch:9 step:36460[D loss: 0.999967] [G loss: 1.000089]\n",
      "epoch:9 step:36465[D loss: 0.999988] [G loss: 1.000003]\n",
      "epoch:9 step:36470[D loss: 0.999959] [G loss: 1.000071]\n",
      "epoch:9 step:36475[D loss: 1.000027] [G loss: 0.999986]\n",
      "epoch:9 step:36480[D loss: 0.999979] [G loss: 1.000046]\n",
      "epoch:9 step:36485[D loss: 0.999984] [G loss: 1.000059]\n",
      "epoch:9 step:36490[D loss: 0.999971] [G loss: 1.000067]\n",
      "epoch:9 step:36495[D loss: 0.999990] [G loss: 1.000024]\n",
      "epoch:9 step:36500[D loss: 0.999975] [G loss: 1.000049]\n",
      "epoch:9 step:36505[D loss: 1.000000] [G loss: 1.000030]\n",
      "epoch:9 step:36510[D loss: 0.999980] [G loss: 1.000042]\n",
      "epoch:9 step:36515[D loss: 0.999986] [G loss: 1.000036]\n",
      "epoch:9 step:36520[D loss: 0.999967] [G loss: 1.000071]\n",
      "epoch:9 step:36525[D loss: 0.999973] [G loss: 1.000029]\n",
      "epoch:9 step:36530[D loss: 0.999983] [G loss: 1.000042]\n",
      "epoch:9 step:36535[D loss: 0.999966] [G loss: 1.000076]\n",
      "epoch:9 step:36540[D loss: 0.999981] [G loss: 1.000065]\n",
      "epoch:9 step:36545[D loss: 0.999973] [G loss: 1.000075]\n",
      "epoch:9 step:36550[D loss: 0.999970] [G loss: 1.000091]\n",
      "epoch:9 step:36555[D loss: 0.999986] [G loss: 1.000150]\n",
      "epoch:9 step:36560[D loss: 1.000026] [G loss: 0.999998]\n",
      "epoch:9 step:36565[D loss: 0.999942] [G loss: 1.000097]\n",
      "epoch:9 step:36570[D loss: 0.999998] [G loss: 1.000033]\n",
      "epoch:9 step:36575[D loss: 1.000055] [G loss: 0.999981]\n",
      "epoch:9 step:36580[D loss: 1.000012] [G loss: 0.999979]\n",
      "epoch:9 step:36585[D loss: 0.999959] [G loss: 1.000074]\n",
      "epoch:9 step:36590[D loss: 0.999959] [G loss: 1.000070]\n",
      "epoch:9 step:36595[D loss: 0.999978] [G loss: 1.000052]\n",
      "epoch:9 step:36600[D loss: 0.999994] [G loss: 1.000051]\n",
      "##############\n",
      "[0.86746004 0.88486644 0.81453444 0.81542741 0.81507206 0.83354351\n",
      " 0.8876301  0.8243112  0.82244082 0.83342879]\n",
      "##########\n",
      "epoch:9 step:36605[D loss: 0.999989] [G loss: 1.000040]\n",
      "epoch:9 step:36610[D loss: 0.999980] [G loss: 1.000033]\n",
      "epoch:9 step:36615[D loss: 0.999999] [G loss: 1.000015]\n",
      "epoch:9 step:36620[D loss: 0.999997] [G loss: 1.000043]\n",
      "epoch:9 step:36625[D loss: 0.999966] [G loss: 1.000086]\n",
      "epoch:9 step:36630[D loss: 0.999980] [G loss: 1.000075]\n",
      "epoch:9 step:36635[D loss: 0.999981] [G loss: 1.000083]\n",
      "epoch:9 step:36640[D loss: 1.000012] [G loss: 1.000018]\n",
      "epoch:9 step:36645[D loss: 0.999952] [G loss: 1.000089]\n",
      "epoch:9 step:36650[D loss: 0.999967] [G loss: 1.000082]\n",
      "epoch:9 step:36655[D loss: 0.999959] [G loss: 1.000101]\n",
      "epoch:9 step:36660[D loss: 0.999992] [G loss: 1.000031]\n",
      "epoch:9 step:36665[D loss: 1.000010] [G loss: 0.999997]\n",
      "epoch:9 step:36670[D loss: 0.999973] [G loss: 1.000073]\n",
      "epoch:9 step:36675[D loss: 0.999974] [G loss: 1.000104]\n",
      "epoch:9 step:36680[D loss: 0.999981] [G loss: 1.000084]\n",
      "epoch:9 step:36685[D loss: 0.999949] [G loss: 1.000102]\n",
      "epoch:9 step:36690[D loss: 0.999975] [G loss: 1.000092]\n",
      "epoch:9 step:36695[D loss: 0.999975] [G loss: 1.000114]\n",
      "epoch:9 step:36700[D loss: 1.000012] [G loss: 1.000033]\n",
      "epoch:9 step:36705[D loss: 0.999971] [G loss: 1.000093]\n",
      "epoch:9 step:36710[D loss: 0.999967] [G loss: 1.000079]\n",
      "epoch:9 step:36715[D loss: 0.999963] [G loss: 1.000082]\n",
      "epoch:9 step:36720[D loss: 1.000003] [G loss: 1.000036]\n",
      "epoch:9 step:36725[D loss: 0.999976] [G loss: 1.000103]\n",
      "epoch:9 step:36730[D loss: 0.999988] [G loss: 1.000065]\n",
      "epoch:9 step:36735[D loss: 0.999955] [G loss: 1.000107]\n",
      "epoch:9 step:36740[D loss: 0.999961] [G loss: 1.000094]\n",
      "epoch:9 step:36745[D loss: 0.999968] [G loss: 1.000090]\n",
      "epoch:9 step:36750[D loss: 0.999959] [G loss: 1.000104]\n",
      "epoch:9 step:36755[D loss: 0.999973] [G loss: 1.000104]\n",
      "epoch:9 step:36760[D loss: 0.999992] [G loss: 1.000078]\n",
      "epoch:9 step:36765[D loss: 0.999982] [G loss: 1.000051]\n",
      "epoch:9 step:36770[D loss: 1.000023] [G loss: 1.000001]\n",
      "epoch:9 step:36775[D loss: 0.999977] [G loss: 1.000035]\n",
      "epoch:9 step:36780[D loss: 0.999952] [G loss: 1.000069]\n",
      "epoch:9 step:36785[D loss: 0.999960] [G loss: 1.000056]\n",
      "epoch:9 step:36790[D loss: 1.000022] [G loss: 1.000006]\n",
      "epoch:9 step:36795[D loss: 1.000008] [G loss: 0.999975]\n",
      "epoch:9 step:36800[D loss: 1.000001] [G loss: 1.000024]\n",
      "##############\n",
      "[0.87430428 0.84232952 0.82739288 0.82916189 0.78844418 0.83260291\n",
      " 0.88429784 0.8274367  0.80816656 0.85433923]\n",
      "##########\n",
      "epoch:9 step:36805[D loss: 0.999995] [G loss: 1.000072]\n",
      "epoch:9 step:36810[D loss: 0.999969] [G loss: 1.000051]\n",
      "epoch:9 step:36815[D loss: 0.999964] [G loss: 1.000052]\n",
      "epoch:9 step:36820[D loss: 0.999959] [G loss: 1.000101]\n",
      "epoch:9 step:36825[D loss: 0.999991] [G loss: 1.000030]\n",
      "epoch:9 step:36830[D loss: 1.000029] [G loss: 1.000008]\n",
      "epoch:9 step:36835[D loss: 0.999931] [G loss: 1.000129]\n",
      "epoch:9 step:36840[D loss: 0.999964] [G loss: 1.000060]\n",
      "epoch:9 step:36845[D loss: 1.000021] [G loss: 1.000033]\n",
      "epoch:9 step:36850[D loss: 0.999979] [G loss: 1.000021]\n",
      "epoch:9 step:36855[D loss: 0.999943] [G loss: 1.000078]\n",
      "epoch:9 step:36860[D loss: 0.999970] [G loss: 1.000055]\n",
      "epoch:9 step:36865[D loss: 0.999973] [G loss: 1.000064]\n",
      "epoch:9 step:36870[D loss: 0.999983] [G loss: 1.000047]\n",
      "epoch:9 step:36875[D loss: 0.999977] [G loss: 1.000065]\n",
      "epoch:9 step:36880[D loss: 0.999964] [G loss: 1.000052]\n",
      "epoch:9 step:36885[D loss: 0.999940] [G loss: 1.000087]\n",
      "epoch:9 step:36890[D loss: 0.999970] [G loss: 1.000065]\n",
      "epoch:9 step:36895[D loss: 0.999974] [G loss: 1.000052]\n",
      "epoch:9 step:36900[D loss: 0.999978] [G loss: 1.000037]\n",
      "epoch:9 step:36905[D loss: 0.999975] [G loss: 1.000017]\n",
      "epoch:9 step:36910[D loss: 0.999968] [G loss: 1.000040]\n",
      "epoch:9 step:36915[D loss: 0.999976] [G loss: 1.000053]\n",
      "epoch:9 step:36920[D loss: 0.999966] [G loss: 1.000078]\n",
      "epoch:9 step:36925[D loss: 1.000014] [G loss: 0.999974]\n",
      "epoch:9 step:36930[D loss: 0.999966] [G loss: 1.000062]\n",
      "epoch:9 step:36935[D loss: 0.999983] [G loss: 1.000043]\n",
      "epoch:9 step:36940[D loss: 0.999978] [G loss: 1.000036]\n",
      "epoch:9 step:36945[D loss: 0.999989] [G loss: 1.000023]\n",
      "epoch:9 step:36950[D loss: 1.000013] [G loss: 1.000023]\n",
      "epoch:9 step:36955[D loss: 0.999972] [G loss: 1.000055]\n",
      "epoch:9 step:36960[D loss: 1.000001] [G loss: 1.000162]\n",
      "epoch:9 step:36965[D loss: 0.999932] [G loss: 1.000113]\n",
      "epoch:9 step:36970[D loss: 0.999981] [G loss: 1.000085]\n",
      "epoch:9 step:36975[D loss: 0.999987] [G loss: 1.000057]\n",
      "epoch:9 step:36980[D loss: 1.000016] [G loss: 1.000030]\n",
      "epoch:9 step:36985[D loss: 0.999999] [G loss: 1.000033]\n",
      "epoch:9 step:36990[D loss: 0.999993] [G loss: 1.000034]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:9 step:36995[D loss: 0.999961] [G loss: 1.000081]\n",
      "epoch:9 step:37000[D loss: 0.999972] [G loss: 1.000090]\n",
      "##############\n",
      "[0.87075157 0.85429805 0.81567495 0.82960714 0.82383604 0.85886089\n",
      " 0.88092189 0.8365893  0.81483576 0.83752011]\n",
      "##########\n",
      "epoch:9 step:37005[D loss: 0.999972] [G loss: 1.000079]\n",
      "epoch:9 step:37010[D loss: 0.999985] [G loss: 1.000073]\n",
      "epoch:9 step:37015[D loss: 0.999966] [G loss: 1.000076]\n",
      "epoch:9 step:37020[D loss: 0.999961] [G loss: 1.000092]\n",
      "epoch:9 step:37025[D loss: 0.999973] [G loss: 1.000079]\n",
      "epoch:9 step:37030[D loss: 1.000004] [G loss: 0.999986]\n",
      "epoch:9 step:37035[D loss: 0.999971] [G loss: 1.000053]\n",
      "epoch:9 step:37040[D loss: 0.999975] [G loss: 1.000060]\n",
      "epoch:9 step:37045[D loss: 0.999964] [G loss: 1.000077]\n",
      "epoch:9 step:37050[D loss: 1.000056] [G loss: 1.000020]\n",
      "epoch:9 step:37055[D loss: 0.999994] [G loss: 1.000040]\n",
      "epoch:9 step:37060[D loss: 0.999986] [G loss: 1.000083]\n",
      "epoch:9 step:37065[D loss: 0.999976] [G loss: 1.000069]\n",
      "epoch:9 step:37070[D loss: 0.999962] [G loss: 1.000073]\n",
      "epoch:9 step:37075[D loss: 1.000015] [G loss: 1.000004]\n",
      "epoch:9 step:37080[D loss: 1.000037] [G loss: 0.999968]\n",
      "epoch:9 step:37085[D loss: 0.999987] [G loss: 0.999983]\n",
      "epoch:9 step:37090[D loss: 0.999996] [G loss: 0.999944]\n",
      "epoch:9 step:37095[D loss: 0.999952] [G loss: 1.000093]\n",
      "epoch:9 step:37100[D loss: 0.999970] [G loss: 1.000078]\n",
      "epoch:9 step:37105[D loss: 0.999958] [G loss: 1.000087]\n",
      "epoch:9 step:37110[D loss: 0.999970] [G loss: 1.000063]\n",
      "epoch:9 step:37115[D loss: 0.999972] [G loss: 1.000062]\n",
      "epoch:9 step:37120[D loss: 1.000021] [G loss: 0.999999]\n",
      "epoch:9 step:37125[D loss: 1.000031] [G loss: 0.999946]\n",
      "epoch:9 step:37130[D loss: 0.999977] [G loss: 1.000012]\n",
      "epoch:9 step:37135[D loss: 0.999926] [G loss: 1.000105]\n",
      "epoch:9 step:37140[D loss: 0.999987] [G loss: 1.000033]\n",
      "epoch:9 step:37145[D loss: 0.999970] [G loss: 1.000046]\n",
      "epoch:9 step:37150[D loss: 0.999971] [G loss: 1.000056]\n",
      "epoch:9 step:37155[D loss: 1.000003] [G loss: 1.000019]\n",
      "epoch:9 step:37160[D loss: 1.000019] [G loss: 0.999991]\n",
      "epoch:9 step:37165[D loss: 0.999969] [G loss: 1.000037]\n",
      "epoch:9 step:37170[D loss: 0.999976] [G loss: 1.000030]\n",
      "epoch:9 step:37175[D loss: 0.999977] [G loss: 1.000016]\n",
      "epoch:9 step:37180[D loss: 0.999967] [G loss: 1.000043]\n",
      "epoch:9 step:37185[D loss: 0.999967] [G loss: 1.000046]\n",
      "epoch:9 step:37190[D loss: 0.999955] [G loss: 1.000091]\n",
      "epoch:9 step:37195[D loss: 0.999974] [G loss: 1.000031]\n",
      "epoch:9 step:37200[D loss: 0.999937] [G loss: 1.000104]\n",
      "##############\n",
      "[0.88245291 0.85865393 0.81620189 0.83307293 0.81094973 0.85481587\n",
      " 0.88755854 0.84167043 0.81067461 0.81800687]\n",
      "##########\n",
      "epoch:9 step:37205[D loss: 0.999964] [G loss: 1.000103]\n",
      "epoch:9 step:37210[D loss: 0.999962] [G loss: 1.000057]\n",
      "epoch:9 step:37215[D loss: 1.000014] [G loss: 0.999967]\n",
      "epoch:9 step:37220[D loss: 0.999942] [G loss: 1.000073]\n",
      "epoch:9 step:37225[D loss: 0.999972] [G loss: 1.000051]\n",
      "epoch:9 step:37230[D loss: 1.000000] [G loss: 1.000002]\n",
      "epoch:9 step:37235[D loss: 0.999958] [G loss: 1.000063]\n",
      "epoch:9 step:37240[D loss: 0.999940] [G loss: 1.000110]\n",
      "epoch:9 step:37245[D loss: 0.999986] [G loss: 1.000074]\n",
      "epoch:9 step:37250[D loss: 0.999954] [G loss: 1.000047]\n",
      "epoch:9 step:37255[D loss: 0.999972] [G loss: 1.000056]\n",
      "epoch:9 step:37260[D loss: 0.999980] [G loss: 1.000016]\n",
      "epoch:9 step:37265[D loss: 1.000006] [G loss: 1.000006]\n",
      "epoch:9 step:37270[D loss: 0.999967] [G loss: 1.000086]\n",
      "epoch:9 step:37275[D loss: 0.999936] [G loss: 1.000101]\n",
      "epoch:9 step:37280[D loss: 0.999985] [G loss: 1.000070]\n",
      "epoch:9 step:37285[D loss: 0.999947] [G loss: 1.000077]\n",
      "epoch:9 step:37290[D loss: 0.999993] [G loss: 1.000012]\n",
      "epoch:9 step:37295[D loss: 0.999984] [G loss: 1.000048]\n",
      "epoch:9 step:37300[D loss: 0.999970] [G loss: 1.000063]\n",
      "epoch:9 step:37305[D loss: 0.999960] [G loss: 1.000045]\n",
      "epoch:9 step:37310[D loss: 0.999979] [G loss: 1.000055]\n",
      "epoch:9 step:37315[D loss: 0.999968] [G loss: 1.000049]\n",
      "epoch:9 step:37320[D loss: 0.999985] [G loss: 1.000047]\n",
      "epoch:9 step:37325[D loss: 1.000007] [G loss: 0.999999]\n",
      "epoch:9 step:37330[D loss: 0.999974] [G loss: 1.000069]\n",
      "epoch:9 step:37335[D loss: 1.000000] [G loss: 1.000013]\n",
      "epoch:9 step:37340[D loss: 0.999985] [G loss: 1.000050]\n",
      "epoch:9 step:37345[D loss: 0.999966] [G loss: 1.000070]\n",
      "epoch:9 step:37350[D loss: 1.000040] [G loss: 0.999939]\n",
      "epoch:9 step:37355[D loss: 0.999961] [G loss: 1.000094]\n",
      "epoch:9 step:37360[D loss: 0.999947] [G loss: 1.000093]\n",
      "epoch:9 step:37365[D loss: 0.999983] [G loss: 1.000063]\n",
      "epoch:9 step:37370[D loss: 0.999965] [G loss: 1.000059]\n",
      "epoch:9 step:37375[D loss: 0.999984] [G loss: 1.000050]\n",
      "epoch:9 step:37380[D loss: 1.000053] [G loss: 0.999927]\n",
      "epoch:9 step:37385[D loss: 1.000027] [G loss: 1.000058]\n",
      "epoch:9 step:37390[D loss: 0.999946] [G loss: 1.000030]\n",
      "epoch:9 step:37395[D loss: 0.999992] [G loss: 1.000098]\n",
      "epoch:9 step:37400[D loss: 0.999969] [G loss: 1.000087]\n",
      "##############\n",
      "[0.88146372 0.85310921 0.82520985 0.82210778 0.80179593 0.84653652\n",
      " 0.88894495 0.83223082 0.8130622  0.84658257]\n",
      "##########\n",
      "epoch:9 step:37405[D loss: 0.999957] [G loss: 1.000109]\n",
      "epoch:9 step:37410[D loss: 0.999992] [G loss: 1.000037]\n",
      "epoch:9 step:37415[D loss: 0.999965] [G loss: 1.000042]\n",
      "epoch:9 step:37420[D loss: 0.999986] [G loss: 1.000058]\n",
      "epoch:9 step:37425[D loss: 1.000036] [G loss: 1.000030]\n",
      "epoch:9 step:37430[D loss: 0.999957] [G loss: 1.000077]\n",
      "epoch:9 step:37435[D loss: 0.999992] [G loss: 1.000010]\n",
      "epoch:9 step:37440[D loss: 0.999966] [G loss: 1.000045]\n",
      "epoch:9 step:37445[D loss: 0.999941] [G loss: 1.000192]\n",
      "epoch:9 step:37450[D loss: 0.999962] [G loss: 1.000131]\n",
      "epoch:9 step:37455[D loss: 0.999968] [G loss: 1.000089]\n",
      "epoch:9 step:37460[D loss: 0.999975] [G loss: 1.000093]\n",
      "epoch:9 step:37465[D loss: 1.000066] [G loss: 0.999896]\n",
      "epoch:9 step:37470[D loss: 1.000002] [G loss: 1.000012]\n",
      "epoch:9 step:37475[D loss: 0.999931] [G loss: 1.000145]\n",
      "epoch:9 step:37480[D loss: 0.999984] [G loss: 1.000089]\n",
      "epoch:9 step:37485[D loss: 1.000018] [G loss: 0.999971]\n",
      "epoch:9 step:37490[D loss: 0.999979] [G loss: 1.000190]\n",
      "epoch:9 step:37495[D loss: 0.999879] [G loss: 1.000203]\n",
      "epoch:9 step:37500[D loss: 0.999978] [G loss: 1.000078]\n",
      "epoch:9 step:37505[D loss: 0.999971] [G loss: 1.000042]\n",
      "epoch:9 step:37510[D loss: 1.000046] [G loss: 0.999907]\n",
      "epoch:9 step:37515[D loss: 1.000030] [G loss: 0.999964]\n",
      "epoch:9 step:37520[D loss: 0.999978] [G loss: 0.999964]\n",
      "epoch:9 step:37525[D loss: 0.999955] [G loss: 1.000106]\n",
      "epoch:9 step:37530[D loss: 0.999961] [G loss: 1.000095]\n",
      "epoch:9 step:37535[D loss: 0.999930] [G loss: 1.000096]\n",
      "epoch:9 step:37540[D loss: 0.999984] [G loss: 1.000044]\n",
      "epoch:9 step:37545[D loss: 0.999974] [G loss: 1.000072]\n",
      "epoch:9 step:37550[D loss: 0.999972] [G loss: 1.000045]\n",
      "epoch:9 step:37555[D loss: 0.999967] [G loss: 1.000078]\n",
      "epoch:9 step:37560[D loss: 1.000061] [G loss: 0.999932]\n",
      "epoch:9 step:37565[D loss: 0.999973] [G loss: 1.000036]\n",
      "epoch:9 step:37570[D loss: 1.000000] [G loss: 1.000003]\n",
      "epoch:9 step:37575[D loss: 0.999969] [G loss: 1.000051]\n",
      "epoch:9 step:37580[D loss: 1.000002] [G loss: 1.000028]\n",
      "epoch:9 step:37585[D loss: 0.999978] [G loss: 1.000031]\n",
      "epoch:9 step:37590[D loss: 0.999994] [G loss: 1.000042]\n",
      "epoch:9 step:37595[D loss: 1.000009] [G loss: 0.999958]\n",
      "epoch:9 step:37600[D loss: 1.000067] [G loss: 0.999977]\n",
      "##############\n",
      "[0.87062032 0.85761124 0.81989232 0.83043296 0.80356152 0.83592361\n",
      " 0.87759096 0.85166849 0.80958452 0.84349118]\n",
      "##########\n",
      "epoch:9 step:37605[D loss: 1.000045] [G loss: 1.000061]\n",
      "epoch:9 step:37610[D loss: 0.999929] [G loss: 1.000335]\n",
      "epoch:9 step:37615[D loss: 0.999922] [G loss: 1.000221]\n",
      "epoch:9 step:37620[D loss: 0.999944] [G loss: 1.000211]\n",
      "epoch:9 step:37625[D loss: 0.999965] [G loss: 1.000115]\n",
      "epoch:9 step:37630[D loss: 0.999969] [G loss: 1.000101]\n",
      "epoch:9 step:37635[D loss: 0.999953] [G loss: 1.000089]\n",
      "epoch:9 step:37640[D loss: 0.999988] [G loss: 1.000061]\n",
      "epoch:9 step:37645[D loss: 1.000071] [G loss: 0.999901]\n",
      "epoch:9 step:37650[D loss: 0.999975] [G loss: 1.000007]\n",
      "epoch:9 step:37655[D loss: 1.000093] [G loss: 0.999784]\n",
      "epoch:9 step:37660[D loss: 1.000064] [G loss: 0.999825]\n",
      "epoch:9 step:37665[D loss: 0.999958] [G loss: 1.000045]\n",
      "epoch:9 step:37670[D loss: 0.999979] [G loss: 1.000117]\n",
      "epoch:9 step:37675[D loss: 0.999899] [G loss: 1.000219]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:9 step:37680[D loss: 0.999946] [G loss: 1.000148]\n",
      "epoch:9 step:37685[D loss: 0.999959] [G loss: 1.000088]\n",
      "epoch:9 step:37690[D loss: 0.999990] [G loss: 1.000023]\n",
      "epoch:9 step:37695[D loss: 1.000062] [G loss: 0.999998]\n",
      "epoch:9 step:37700[D loss: 1.000095] [G loss: 0.999952]\n",
      "epoch:9 step:37705[D loss: 0.999991] [G loss: 1.000081]\n",
      "epoch:9 step:37710[D loss: 0.999925] [G loss: 1.000071]\n",
      "epoch:9 step:37715[D loss: 0.999920] [G loss: 1.000138]\n",
      "epoch:9 step:37720[D loss: 0.999951] [G loss: 1.000098]\n",
      "epoch:9 step:37725[D loss: 0.999980] [G loss: 1.000067]\n",
      "epoch:9 step:37730[D loss: 0.999962] [G loss: 1.000077]\n",
      "epoch:9 step:37735[D loss: 0.999984] [G loss: 1.000044]\n",
      "epoch:9 step:37740[D loss: 1.000003] [G loss: 0.999981]\n",
      "epoch:9 step:37745[D loss: 1.000034] [G loss: 0.999986]\n",
      "epoch:9 step:37750[D loss: 0.999958] [G loss: 1.000181]\n",
      "epoch:9 step:37755[D loss: 1.000018] [G loss: 0.999908]\n",
      "epoch:9 step:37760[D loss: 0.999947] [G loss: 1.000063]\n",
      "epoch:9 step:37765[D loss: 0.999990] [G loss: 1.000034]\n",
      "epoch:9 step:37770[D loss: 0.999962] [G loss: 1.000084]\n",
      "epoch:9 step:37775[D loss: 0.999920] [G loss: 1.000119]\n",
      "epoch:9 step:37780[D loss: 0.999981] [G loss: 1.000060]\n",
      "epoch:9 step:37785[D loss: 1.000005] [G loss: 0.999988]\n",
      "epoch:9 step:37790[D loss: 1.000039] [G loss: 0.999945]\n",
      "epoch:9 step:37795[D loss: 1.000084] [G loss: 0.999970]\n",
      "epoch:9 step:37800[D loss: 0.999914] [G loss: 1.000184]\n",
      "##############\n",
      "[0.84947895 0.86263233 0.83953857 0.81908876 0.81968934 0.83097365\n",
      " 0.87355357 0.82807139 0.81167284 0.85176061]\n",
      "##########\n",
      "epoch:9 step:37805[D loss: 0.999917] [G loss: 1.000189]\n",
      "epoch:9 step:37810[D loss: 0.999991] [G loss: 1.000262]\n",
      "epoch:9 step:37815[D loss: 0.999853] [G loss: 1.000282]\n",
      "epoch:9 step:37820[D loss: 0.999950] [G loss: 1.000122]\n",
      "epoch:9 step:37825[D loss: 0.999983] [G loss: 1.000088]\n",
      "epoch:9 step:37830[D loss: 0.999990] [G loss: 1.000001]\n",
      "epoch:9 step:37835[D loss: 1.000010] [G loss: 1.000018]\n",
      "epoch:9 step:37840[D loss: 0.999971] [G loss: 0.999992]\n",
      "epoch:9 step:37845[D loss: 0.999978] [G loss: 1.000008]\n",
      "epoch:9 step:37850[D loss: 0.999954] [G loss: 1.000060]\n",
      "epoch:9 step:37855[D loss: 0.999971] [G loss: 1.000042]\n",
      "epoch:9 step:37860[D loss: 0.999989] [G loss: 1.000046]\n",
      "epoch:9 step:37865[D loss: 0.999992] [G loss: 1.000041]\n",
      "epoch:9 step:37870[D loss: 0.999977] [G loss: 0.999988]\n",
      "epoch:9 step:37875[D loss: 1.000015] [G loss: 1.000063]\n",
      "epoch:9 step:37880[D loss: 0.999940] [G loss: 1.000082]\n",
      "epoch:9 step:37885[D loss: 0.999987] [G loss: 1.000022]\n",
      "epoch:9 step:37890[D loss: 0.999971] [G loss: 1.000039]\n",
      "epoch:9 step:37895[D loss: 1.000020] [G loss: 0.999973]\n",
      "epoch:9 step:37900[D loss: 0.999980] [G loss: 1.000112]\n",
      "epoch:9 step:37905[D loss: 0.999910] [G loss: 1.000156]\n",
      "epoch:9 step:37910[D loss: 1.000005] [G loss: 1.000071]\n",
      "epoch:9 step:37915[D loss: 0.999952] [G loss: 1.000087]\n",
      "epoch:9 step:37920[D loss: 0.999966] [G loss: 1.000069]\n",
      "epoch:9 step:37925[D loss: 0.999969] [G loss: 1.000071]\n",
      "epoch:9 step:37930[D loss: 0.999961] [G loss: 1.000066]\n",
      "epoch:9 step:37935[D loss: 0.999964] [G loss: 1.000046]\n",
      "epoch:9 step:37940[D loss: 1.000040] [G loss: 0.999939]\n",
      "epoch:9 step:37945[D loss: 1.000002] [G loss: 1.000025]\n",
      "epoch:9 step:37950[D loss: 0.999898] [G loss: 1.000232]\n",
      "epoch:9 step:37955[D loss: 1.000000] [G loss: 1.000016]\n",
      "epoch:9 step:37960[D loss: 0.999956] [G loss: 1.000088]\n",
      "epoch:9 step:37965[D loss: 0.999958] [G loss: 1.000110]\n",
      "epoch:9 step:37970[D loss: 0.999977] [G loss: 1.000075]\n",
      "epoch:9 step:37975[D loss: 0.999987] [G loss: 1.000016]\n",
      "epoch:9 step:37980[D loss: 1.000025] [G loss: 0.999944]\n",
      "epoch:9 step:37985[D loss: 0.999957] [G loss: 1.000067]\n",
      "epoch:9 step:37990[D loss: 0.999971] [G loss: 1.000051]\n",
      "epoch:9 step:37995[D loss: 0.999948] [G loss: 1.000060]\n",
      "epoch:9 step:38000[D loss: 0.999984] [G loss: 1.000079]\n",
      "##############\n",
      "[0.88423514 0.86285817 0.80443791 0.82861661 0.80124141 0.84958127\n",
      " 0.85952988 0.83893965 0.822564   0.84378766]\n",
      "##########\n",
      "epoch:9 step:38005[D loss: 1.000036] [G loss: 0.999994]\n",
      "epoch:9 step:38010[D loss: 0.999980] [G loss: 1.000065]\n",
      "epoch:9 step:38015[D loss: 0.999965] [G loss: 1.000058]\n",
      "epoch:9 step:38020[D loss: 0.999987] [G loss: 1.000041]\n",
      "epoch:9 step:38025[D loss: 0.999994] [G loss: 1.000050]\n",
      "epoch:9 step:38030[D loss: 0.999964] [G loss: 1.000077]\n",
      "epoch:9 step:38035[D loss: 0.999987] [G loss: 1.000057]\n",
      "epoch:9 step:38040[D loss: 0.999975] [G loss: 1.000054]\n",
      "epoch:9 step:38045[D loss: 0.999972] [G loss: 1.000060]\n",
      "epoch:9 step:38050[D loss: 0.999968] [G loss: 1.000061]\n",
      "epoch:9 step:38055[D loss: 1.000039] [G loss: 1.000042]\n",
      "epoch:9 step:38060[D loss: 0.999935] [G loss: 1.000179]\n",
      "epoch:9 step:38065[D loss: 0.999987] [G loss: 1.000111]\n",
      "epoch:9 step:38070[D loss: 0.999923] [G loss: 1.000158]\n",
      "epoch:9 step:38075[D loss: 0.999961] [G loss: 1.000123]\n",
      "epoch:9 step:38080[D loss: 0.999982] [G loss: 1.000069]\n",
      "epoch:9 step:38085[D loss: 0.999968] [G loss: 1.000077]\n",
      "epoch:9 step:38090[D loss: 0.999987] [G loss: 1.000062]\n",
      "epoch:9 step:38095[D loss: 1.000012] [G loss: 0.999985]\n",
      "epoch:9 step:38100[D loss: 0.999995] [G loss: 1.000062]\n",
      "epoch:9 step:38105[D loss: 0.999985] [G loss: 1.000032]\n",
      "epoch:9 step:38110[D loss: 0.999939] [G loss: 1.000098]\n",
      "epoch:9 step:38115[D loss: 0.999992] [G loss: 1.000049]\n",
      "epoch:9 step:38120[D loss: 1.000044] [G loss: 0.999976]\n",
      "epoch:9 step:38125[D loss: 0.999991] [G loss: 1.000036]\n",
      "epoch:9 step:38130[D loss: 1.000037] [G loss: 0.999993]\n",
      "epoch:9 step:38135[D loss: 0.999982] [G loss: 1.000004]\n",
      "epoch:9 step:38140[D loss: 0.999996] [G loss: 1.000028]\n",
      "epoch:9 step:38145[D loss: 0.999972] [G loss: 1.000070]\n",
      "epoch:9 step:38150[D loss: 1.000125] [G loss: 0.999850]\n",
      "epoch:9 step:38155[D loss: 0.999999] [G loss: 0.999964]\n",
      "epoch:9 step:38160[D loss: 0.999965] [G loss: 1.000105]\n",
      "epoch:9 step:38165[D loss: 0.999998] [G loss: 1.000114]\n",
      "epoch:9 step:38170[D loss: 0.999941] [G loss: 1.000172]\n",
      "epoch:9 step:38175[D loss: 0.999913] [G loss: 1.000205]\n",
      "epoch:9 step:38180[D loss: 1.000009] [G loss: 1.000056]\n",
      "epoch:9 step:38185[D loss: 0.999981] [G loss: 1.000024]\n",
      "epoch:9 step:38190[D loss: 1.000057] [G loss: 0.999965]\n",
      "epoch:9 step:38195[D loss: 1.000036] [G loss: 0.999919]\n",
      "epoch:9 step:38200[D loss: 0.999970] [G loss: 0.999970]\n",
      "##############\n",
      "[0.86094249 0.85154857 0.83448191 0.83438161 0.80436708 0.82145032\n",
      " 0.88102869 0.81933586 0.82497254 0.81962055]\n",
      "##########\n",
      "epoch:9 step:38205[D loss: 0.999992] [G loss: 0.999958]\n",
      "epoch:9 step:38210[D loss: 0.999934] [G loss: 1.000112]\n",
      "epoch:9 step:38215[D loss: 0.999918] [G loss: 1.000125]\n",
      "epoch:9 step:38220[D loss: 0.999963] [G loss: 1.000099]\n",
      "epoch:9 step:38225[D loss: 0.999963] [G loss: 1.000065]\n",
      "epoch:9 step:38230[D loss: 0.999995] [G loss: 1.000034]\n",
      "epoch:9 step:38235[D loss: 0.999976] [G loss: 1.000051]\n",
      "epoch:9 step:38240[D loss: 0.999963] [G loss: 1.000083]\n",
      "epoch:9 step:38245[D loss: 1.000004] [G loss: 1.000095]\n",
      "epoch:9 step:38250[D loss: 0.999962] [G loss: 1.000138]\n",
      "epoch:9 step:38255[D loss: 0.999932] [G loss: 1.000184]\n",
      "epoch:9 step:38260[D loss: 0.999979] [G loss: 1.000052]\n",
      "epoch:9 step:38265[D loss: 0.999970] [G loss: 1.000095]\n",
      "epoch:9 step:38270[D loss: 0.999961] [G loss: 1.000082]\n",
      "epoch:9 step:38275[D loss: 0.999971] [G loss: 1.000078]\n",
      "epoch:9 step:38280[D loss: 0.999974] [G loss: 1.000076]\n",
      "epoch:9 step:38285[D loss: 0.999985] [G loss: 1.000074]\n",
      "epoch:9 step:38290[D loss: 0.999995] [G loss: 1.000094]\n",
      "epoch:9 step:38295[D loss: 0.999947] [G loss: 1.000141]\n",
      "epoch:9 step:38300[D loss: 0.999976] [G loss: 1.000052]\n",
      "epoch:9 step:38305[D loss: 0.999966] [G loss: 1.000056]\n",
      "epoch:9 step:38310[D loss: 0.999993] [G loss: 1.000036]\n",
      "epoch:9 step:38315[D loss: 0.999976] [G loss: 1.000046]\n",
      "epoch:9 step:38320[D loss: 0.999961] [G loss: 1.000084]\n",
      "epoch:9 step:38325[D loss: 1.000002] [G loss: 1.000047]\n",
      "epoch:9 step:38330[D loss: 0.999966] [G loss: 1.000061]\n",
      "epoch:9 step:38335[D loss: 0.999969] [G loss: 1.000083]\n",
      "epoch:9 step:38340[D loss: 0.999974] [G loss: 1.000077]\n",
      "epoch:9 step:38345[D loss: 0.999973] [G loss: 1.000055]\n",
      "epoch:9 step:38350[D loss: 0.999980] [G loss: 1.000074]\n",
      "epoch:9 step:38355[D loss: 0.999963] [G loss: 1.000116]\n",
      "epoch:9 step:38360[D loss: 0.999998] [G loss: 1.000012]\n",
      "epoch:9 step:38365[D loss: 0.999960] [G loss: 1.000073]\n",
      "epoch:9 step:38370[D loss: 0.999968] [G loss: 1.000086]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:9 step:38375[D loss: 0.999989] [G loss: 1.000076]\n",
      "epoch:9 step:38380[D loss: 0.999973] [G loss: 1.000086]\n",
      "epoch:9 step:38385[D loss: 0.999972] [G loss: 1.000074]\n",
      "epoch:9 step:38390[D loss: 0.999984] [G loss: 1.000058]\n",
      "epoch:9 step:38395[D loss: 1.000000] [G loss: 1.000031]\n",
      "epoch:9 step:38400[D loss: 0.999985] [G loss: 1.000055]\n",
      "##############\n",
      "[0.87587032 0.85831645 0.83813944 0.83481039 0.80095103 0.83780132\n",
      " 0.88159826 0.83847801 0.83279891 0.84982226]\n",
      "##########\n",
      "epoch:9 step:38405[D loss: 1.000006] [G loss: 1.000058]\n",
      "epoch:9 step:38410[D loss: 1.000041] [G loss: 0.999997]\n",
      "epoch:9 step:38415[D loss: 0.999994] [G loss: 1.000082]\n",
      "epoch:9 step:38420[D loss: 0.999969] [G loss: 1.000052]\n",
      "epoch:9 step:38425[D loss: 0.999959] [G loss: 1.000069]\n",
      "epoch:9 step:38430[D loss: 1.000031] [G loss: 0.999986]\n",
      "epoch:9 step:38435[D loss: 1.000059] [G loss: 0.999974]\n",
      "epoch:9 step:38440[D loss: 0.999972] [G loss: 1.000101]\n",
      "epoch:9 step:38445[D loss: 0.999963] [G loss: 1.000097]\n",
      "epoch:9 step:38450[D loss: 1.000016] [G loss: 1.000113]\n",
      "epoch:9 step:38455[D loss: 0.999897] [G loss: 1.000153]\n",
      "epoch:9 step:38460[D loss: 0.999953] [G loss: 1.000083]\n",
      "epoch:9 step:38465[D loss: 0.999962] [G loss: 1.000047]\n",
      "epoch:9 step:38470[D loss: 1.000013] [G loss: 0.999946]\n",
      "epoch:9 step:38475[D loss: 1.000013] [G loss: 0.999981]\n",
      "epoch:9 step:38480[D loss: 0.999990] [G loss: 0.999969]\n",
      "epoch:9 step:38485[D loss: 0.999939] [G loss: 1.000104]\n",
      "epoch:9 step:38490[D loss: 0.999971] [G loss: 1.000057]\n",
      "epoch:9 step:38495[D loss: 0.999956] [G loss: 1.000079]\n",
      "epoch:9 step:38500[D loss: 0.999961] [G loss: 1.000050]\n",
      "epoch:9 step:38505[D loss: 1.000006] [G loss: 1.000044]\n",
      "epoch:9 step:38510[D loss: 0.999992] [G loss: 1.000042]\n",
      "epoch:9 step:38515[D loss: 0.999968] [G loss: 1.000060]\n",
      "epoch:9 step:38520[D loss: 0.999968] [G loss: 1.000063]\n",
      "epoch:9 step:38525[D loss: 0.999973] [G loss: 1.000054]\n",
      "epoch:9 step:38530[D loss: 1.000033] [G loss: 0.999926]\n",
      "epoch:9 step:38535[D loss: 0.999976] [G loss: 1.000058]\n",
      "epoch:9 step:38540[D loss: 0.999974] [G loss: 1.000052]\n",
      "epoch:9 step:38545[D loss: 0.999974] [G loss: 1.000053]\n",
      "epoch:9 step:38550[D loss: 0.999960] [G loss: 1.000066]\n",
      "epoch:9 step:38555[D loss: 0.999963] [G loss: 1.000074]\n",
      "epoch:9 step:38560[D loss: 0.999973] [G loss: 1.000056]\n",
      "epoch:9 step:38565[D loss: 0.999982] [G loss: 1.000057]\n",
      "epoch:9 step:38570[D loss: 0.999967] [G loss: 1.000076]\n",
      "epoch:9 step:38575[D loss: 0.999978] [G loss: 1.000076]\n",
      "epoch:9 step:38580[D loss: 0.999977] [G loss: 1.000057]\n",
      "epoch:9 step:38585[D loss: 0.999976] [G loss: 1.000024]\n",
      "epoch:9 step:38590[D loss: 1.000053] [G loss: 1.000029]\n",
      "epoch:9 step:38595[D loss: 0.999984] [G loss: 1.000033]\n",
      "epoch:9 step:38600[D loss: 0.999961] [G loss: 1.000080]\n",
      "##############\n",
      "[0.8733273  0.84377408 0.82327951 0.82347603 0.79983804 0.83781172\n",
      " 0.88887417 0.83688191 0.82414598 0.83863673]\n",
      "##########\n",
      "epoch:9 step:38605[D loss: 1.000020] [G loss: 0.999929]\n",
      "epoch:9 step:38610[D loss: 1.000012] [G loss: 1.000016]\n",
      "epoch:9 step:38615[D loss: 0.999994] [G loss: 1.000045]\n",
      "epoch:9 step:38620[D loss: 0.999992] [G loss: 1.000089]\n",
      "epoch:9 step:38625[D loss: 0.999982] [G loss: 1.000055]\n",
      "epoch:9 step:38630[D loss: 0.999943] [G loss: 1.000134]\n",
      "epoch:9 step:38635[D loss: 0.999973] [G loss: 1.000116]\n",
      "epoch:9 step:38640[D loss: 0.999994] [G loss: 1.000118]\n",
      "epoch:9 step:38645[D loss: 0.999946] [G loss: 1.000135]\n",
      "epoch:9 step:38650[D loss: 0.999957] [G loss: 1.000110]\n",
      "epoch:9 step:38655[D loss: 0.999979] [G loss: 1.000086]\n",
      "epoch:9 step:38660[D loss: 0.999974] [G loss: 1.000077]\n",
      "epoch:9 step:38665[D loss: 0.999994] [G loss: 0.999997]\n",
      "epoch:9 step:38670[D loss: 0.999975] [G loss: 1.000065]\n",
      "epoch:9 step:38675[D loss: 1.000058] [G loss: 1.000018]\n",
      "epoch:9 step:38680[D loss: 1.000055] [G loss: 0.999952]\n",
      "epoch:9 step:38685[D loss: 0.999930] [G loss: 1.000110]\n",
      "epoch:9 step:38690[D loss: 0.999934] [G loss: 1.000150]\n",
      "epoch:9 step:38695[D loss: 0.999967] [G loss: 1.000111]\n",
      "epoch:9 step:38700[D loss: 0.999957] [G loss: 1.000125]\n",
      "epoch:9 step:38705[D loss: 0.999967] [G loss: 1.000111]\n",
      "epoch:9 step:38710[D loss: 0.999984] [G loss: 1.000038]\n",
      "epoch:9 step:38715[D loss: 0.999975] [G loss: 1.000058]\n",
      "epoch:9 step:38720[D loss: 1.000015] [G loss: 0.999997]\n",
      "epoch:9 step:38725[D loss: 0.999970] [G loss: 1.000047]\n",
      "epoch:9 step:38730[D loss: 0.999953] [G loss: 1.000123]\n",
      "epoch:9 step:38735[D loss: 0.999979] [G loss: 1.000054]\n",
      "epoch:9 step:38740[D loss: 0.999987] [G loss: 1.000030]\n",
      "epoch:9 step:38745[D loss: 0.999965] [G loss: 1.000035]\n",
      "epoch:9 step:38750[D loss: 0.999982] [G loss: 1.000056]\n",
      "epoch:9 step:38755[D loss: 0.999966] [G loss: 0.999996]\n",
      "epoch:9 step:38760[D loss: 0.999966] [G loss: 1.000054]\n",
      "epoch:9 step:38765[D loss: 0.999999] [G loss: 1.000095]\n",
      "epoch:9 step:38770[D loss: 0.999968] [G loss: 1.000064]\n",
      "epoch:9 step:38775[D loss: 0.999952] [G loss: 1.000086]\n",
      "epoch:9 step:38780[D loss: 0.999970] [G loss: 1.000083]\n",
      "epoch:9 step:38785[D loss: 0.999974] [G loss: 1.000047]\n",
      "epoch:9 step:38790[D loss: 0.999983] [G loss: 1.000058]\n",
      "epoch:9 step:38795[D loss: 0.999974] [G loss: 1.000085]\n",
      "epoch:9 step:38800[D loss: 1.000053] [G loss: 0.999934]\n",
      "##############\n",
      "[0.88160879 0.83465972 0.82431779 0.83617181 0.7912153  0.84305697\n",
      " 0.91432417 0.85938357 0.79863058 0.81740021]\n",
      "##########\n",
      "epoch:9 step:38805[D loss: 0.999982] [G loss: 1.000073]\n",
      "epoch:9 step:38810[D loss: 0.999914] [G loss: 1.000123]\n",
      "epoch:9 step:38815[D loss: 1.000004] [G loss: 1.000065]\n",
      "epoch:9 step:38820[D loss: 0.999991] [G loss: 1.000092]\n",
      "epoch:9 step:38825[D loss: 0.999987] [G loss: 1.000099]\n",
      "epoch:9 step:38830[D loss: 0.999934] [G loss: 1.000181]\n",
      "epoch:9 step:38835[D loss: 0.999969] [G loss: 1.000066]\n",
      "epoch:9 step:38840[D loss: 0.999994] [G loss: 1.000086]\n",
      "epoch:9 step:38845[D loss: 0.999968] [G loss: 1.000101]\n",
      "epoch:9 step:38850[D loss: 0.999979] [G loss: 1.000071]\n",
      "epoch:9 step:38855[D loss: 1.000073] [G loss: 0.999937]\n",
      "epoch:9 step:38860[D loss: 0.999941] [G loss: 1.000115]\n",
      "epoch:9 step:38865[D loss: 0.999958] [G loss: 1.000096]\n",
      "epoch:9 step:38870[D loss: 0.999970] [G loss: 1.000067]\n",
      "epoch:9 step:38875[D loss: 0.999983] [G loss: 1.000063]\n",
      "epoch:9 step:38880[D loss: 0.999977] [G loss: 1.000081]\n",
      "epoch:9 step:38885[D loss: 0.999993] [G loss: 1.000071]\n",
      "epoch:9 step:38890[D loss: 1.000038] [G loss: 0.999962]\n",
      "epoch:9 step:38895[D loss: 0.999993] [G loss: 1.000029]\n",
      "epoch:9 step:38900[D loss: 0.999987] [G loss: 1.000026]\n",
      "epoch:9 step:38905[D loss: 0.999962] [G loss: 1.000072]\n",
      "epoch:9 step:38910[D loss: 0.999968] [G loss: 1.000082]\n",
      "epoch:9 step:38915[D loss: 0.999979] [G loss: 1.000047]\n",
      "epoch:9 step:38920[D loss: 0.999944] [G loss: 1.000054]\n",
      "epoch:9 step:38925[D loss: 0.999935] [G loss: 1.000098]\n",
      "epoch:9 step:38930[D loss: 0.999969] [G loss: 1.000090]\n",
      "epoch:9 step:38935[D loss: 0.999963] [G loss: 1.000069]\n",
      "epoch:9 step:38940[D loss: 0.999985] [G loss: 1.000055]\n",
      "epoch:9 step:38945[D loss: 0.999987] [G loss: 1.000057]\n",
      "epoch:9 step:38950[D loss: 0.999994] [G loss: 1.000047]\n",
      "epoch:9 step:38955[D loss: 1.000047] [G loss: 0.999976]\n",
      "epoch:9 step:38960[D loss: 0.999975] [G loss: 1.000096]\n",
      "epoch:9 step:38965[D loss: 1.000029] [G loss: 0.999989]\n",
      "epoch:9 step:38970[D loss: 1.000009] [G loss: 1.000011]\n",
      "epoch:9 step:38975[D loss: 1.000009] [G loss: 0.999976]\n",
      "epoch:9 step:38980[D loss: 0.999986] [G loss: 1.000095]\n",
      "epoch:9 step:38985[D loss: 0.999942] [G loss: 1.000120]\n",
      "epoch:9 step:38990[D loss: 0.999983] [G loss: 1.000057]\n",
      "epoch:9 step:38995[D loss: 0.999989] [G loss: 1.000044]\n",
      "epoch:9 step:39000[D loss: 0.999970] [G loss: 1.000072]\n",
      "##############\n",
      "[0.86595937 0.85707281 0.82345219 0.83650785 0.80827464 0.82882355\n",
      " 0.88774013 0.83948254 0.80847322 0.82822084]\n",
      "##########\n",
      "epoch:9 step:39005[D loss: 1.000022] [G loss: 1.000024]\n",
      "epoch:9 step:39010[D loss: 1.000027] [G loss: 0.999972]\n",
      "epoch:9 step:39015[D loss: 1.000015] [G loss: 1.000122]\n",
      "epoch:9 step:39020[D loss: 0.999961] [G loss: 1.000132]\n",
      "epoch:9 step:39025[D loss: 0.999920] [G loss: 1.000150]\n",
      "epoch:9 step:39030[D loss: 0.999993] [G loss: 1.000006]\n",
      "epoch:9 step:39035[D loss: 1.000017] [G loss: 0.999942]\n",
      "epoch:9 step:39040[D loss: 0.999924] [G loss: 1.000081]\n",
      "epoch:9 step:39045[D loss: 0.999956] [G loss: 1.000089]\n",
      "epoch:9 step:39050[D loss: 1.000052] [G loss: 0.999956]\n",
      "epoch:10 step:39055[D loss: 1.000001] [G loss: 1.000025]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:10 step:39060[D loss: 0.999954] [G loss: 1.000035]\n",
      "epoch:10 step:39065[D loss: 0.999975] [G loss: 1.000033]\n",
      "epoch:10 step:39070[D loss: 0.999969] [G loss: 1.000074]\n",
      "epoch:10 step:39075[D loss: 1.000030] [G loss: 0.999906]\n",
      "epoch:10 step:39080[D loss: 0.999965] [G loss: 1.000031]\n",
      "epoch:10 step:39085[D loss: 0.999987] [G loss: 1.000082]\n",
      "epoch:10 step:39090[D loss: 0.999949] [G loss: 1.000084]\n",
      "epoch:10 step:39095[D loss: 1.000010] [G loss: 1.000056]\n",
      "epoch:10 step:39100[D loss: 0.999963] [G loss: 1.000100]\n",
      "epoch:10 step:39105[D loss: 0.999969] [G loss: 1.000068]\n",
      "epoch:10 step:39110[D loss: 0.999975] [G loss: 1.000054]\n",
      "epoch:10 step:39115[D loss: 0.999984] [G loss: 1.000053]\n",
      "epoch:10 step:39120[D loss: 0.999972] [G loss: 1.000062]\n",
      "epoch:10 step:39125[D loss: 0.999964] [G loss: 1.000055]\n",
      "epoch:10 step:39130[D loss: 0.999995] [G loss: 1.000021]\n",
      "epoch:10 step:39135[D loss: 0.999972] [G loss: 1.000054]\n",
      "epoch:10 step:39140[D loss: 0.999986] [G loss: 1.000056]\n",
      "epoch:10 step:39145[D loss: 0.999973] [G loss: 1.000055]\n",
      "epoch:10 step:39150[D loss: 0.999974] [G loss: 1.000054]\n",
      "epoch:10 step:39155[D loss: 0.999973] [G loss: 1.000062]\n",
      "epoch:10 step:39160[D loss: 0.999949] [G loss: 1.000087]\n",
      "epoch:10 step:39165[D loss: 0.999970] [G loss: 1.000066]\n",
      "epoch:10 step:39170[D loss: 1.000054] [G loss: 1.000039]\n",
      "epoch:10 step:39175[D loss: 0.999941] [G loss: 1.000061]\n",
      "epoch:10 step:39180[D loss: 0.999997] [G loss: 0.999975]\n",
      "epoch:10 step:39185[D loss: 0.999930] [G loss: 1.000144]\n",
      "epoch:10 step:39190[D loss: 0.999983] [G loss: 1.000063]\n",
      "epoch:10 step:39195[D loss: 0.999988] [G loss: 1.000005]\n",
      "epoch:10 step:39200[D loss: 1.000008] [G loss: 0.999977]\n",
      "##############\n",
      "[0.86903208 0.83049996 0.83583205 0.82861157 0.81690818 0.83126595\n",
      " 0.89899978 0.84112352 0.79863701 0.83834585]\n",
      "##########\n",
      "epoch:10 step:39205[D loss: 0.999944] [G loss: 1.000118]\n",
      "epoch:10 step:39210[D loss: 1.000009] [G loss: 1.000042]\n",
      "epoch:10 step:39215[D loss: 0.999978] [G loss: 1.000074]\n",
      "epoch:10 step:39220[D loss: 0.999960] [G loss: 1.000088]\n",
      "epoch:10 step:39225[D loss: 0.999972] [G loss: 1.000087]\n",
      "epoch:10 step:39230[D loss: 0.999988] [G loss: 1.000114]\n",
      "epoch:10 step:39235[D loss: 0.999940] [G loss: 1.000153]\n",
      "epoch:10 step:39240[D loss: 0.999966] [G loss: 1.000103]\n",
      "epoch:10 step:39245[D loss: 0.999977] [G loss: 1.000059]\n",
      "epoch:10 step:39250[D loss: 1.000002] [G loss: 1.000007]\n",
      "epoch:10 step:39255[D loss: 0.999985] [G loss: 1.000027]\n",
      "epoch:10 step:39260[D loss: 1.000014] [G loss: 0.999996]\n",
      "epoch:10 step:39265[D loss: 0.999902] [G loss: 1.000234]\n",
      "epoch:10 step:39270[D loss: 0.999915] [G loss: 1.000107]\n",
      "epoch:10 step:39275[D loss: 0.999973] [G loss: 1.000066]\n",
      "epoch:10 step:39280[D loss: 0.999964] [G loss: 1.000043]\n",
      "epoch:10 step:39285[D loss: 0.999967] [G loss: 1.000061]\n",
      "epoch:10 step:39290[D loss: 0.999977] [G loss: 1.000062]\n",
      "epoch:10 step:39295[D loss: 0.999980] [G loss: 1.000064]\n",
      "epoch:10 step:39300[D loss: 0.999968] [G loss: 1.000079]\n",
      "epoch:10 step:39305[D loss: 1.000050] [G loss: 0.999969]\n",
      "epoch:10 step:39310[D loss: 1.000013] [G loss: 1.000014]\n",
      "epoch:10 step:39315[D loss: 0.999970] [G loss: 1.000073]\n",
      "epoch:10 step:39320[D loss: 0.999985] [G loss: 1.000085]\n",
      "epoch:10 step:39325[D loss: 0.999964] [G loss: 1.000079]\n",
      "epoch:10 step:39330[D loss: 0.999994] [G loss: 1.000036]\n",
      "epoch:10 step:39335[D loss: 0.999961] [G loss: 1.000067]\n",
      "epoch:10 step:39340[D loss: 0.999985] [G loss: 1.000103]\n",
      "epoch:10 step:39345[D loss: 0.999972] [G loss: 1.000093]\n",
      "epoch:10 step:39350[D loss: 0.999982] [G loss: 1.000077]\n",
      "epoch:10 step:39355[D loss: 1.000032] [G loss: 1.000018]\n",
      "epoch:10 step:39360[D loss: 0.999971] [G loss: 1.000076]\n",
      "epoch:10 step:39365[D loss: 0.999947] [G loss: 1.000139]\n",
      "epoch:10 step:39370[D loss: 0.999978] [G loss: 1.000076]\n",
      "epoch:10 step:39375[D loss: 0.999970] [G loss: 1.000079]\n",
      "epoch:10 step:39380[D loss: 1.000004] [G loss: 0.999987]\n",
      "epoch:10 step:39385[D loss: 0.999992] [G loss: 1.000019]\n",
      "epoch:10 step:39390[D loss: 0.999962] [G loss: 1.000056]\n",
      "epoch:10 step:39395[D loss: 0.999969] [G loss: 1.000091]\n",
      "epoch:10 step:39400[D loss: 0.999986] [G loss: 1.000048]\n",
      "##############\n",
      "[0.86857136 0.8602917  0.804884   0.83686286 0.83308464 0.83308505\n",
      " 0.88062641 0.84046194 0.83573331 0.84352466]\n",
      "##########\n",
      "epoch:10 step:39405[D loss: 1.000040] [G loss: 0.999996]\n",
      "epoch:10 step:39410[D loss: 0.999938] [G loss: 1.000134]\n",
      "epoch:10 step:39415[D loss: 1.000010] [G loss: 1.000066]\n",
      "epoch:10 step:39420[D loss: 0.999969] [G loss: 1.000088]\n",
      "epoch:10 step:39425[D loss: 0.999968] [G loss: 1.000121]\n",
      "epoch:10 step:39430[D loss: 0.999975] [G loss: 1.000091]\n",
      "epoch:10 step:39435[D loss: 0.999991] [G loss: 1.000091]\n",
      "epoch:10 step:39440[D loss: 0.999983] [G loss: 1.000134]\n",
      "epoch:10 step:39445[D loss: 0.999964] [G loss: 1.000099]\n",
      "epoch:10 step:39450[D loss: 0.999974] [G loss: 1.000067]\n",
      "epoch:10 step:39455[D loss: 0.999975] [G loss: 1.000065]\n",
      "epoch:10 step:39460[D loss: 1.000030] [G loss: 0.999962]\n",
      "epoch:10 step:39465[D loss: 1.000004] [G loss: 0.999976]\n",
      "epoch:10 step:39470[D loss: 0.999981] [G loss: 1.000042]\n",
      "epoch:10 step:39475[D loss: 0.999989] [G loss: 1.000016]\n",
      "epoch:10 step:39480[D loss: 0.999974] [G loss: 1.000072]\n",
      "epoch:10 step:39485[D loss: 1.000028] [G loss: 0.999966]\n",
      "epoch:10 step:39490[D loss: 1.000050] [G loss: 0.999965]\n",
      "epoch:10 step:39495[D loss: 1.000137] [G loss: 0.999880]\n",
      "epoch:10 step:39500[D loss: 0.999961] [G loss: 1.000088]\n",
      "epoch:10 step:39505[D loss: 0.999975] [G loss: 1.000113]\n",
      "epoch:10 step:39510[D loss: 0.999957] [G loss: 1.000124]\n",
      "epoch:10 step:39515[D loss: 0.999953] [G loss: 1.000077]\n",
      "epoch:10 step:39520[D loss: 0.999991] [G loss: 1.000010]\n",
      "epoch:10 step:39525[D loss: 1.000006] [G loss: 0.999988]\n",
      "epoch:10 step:39530[D loss: 1.000128] [G loss: 0.999876]\n",
      "epoch:10 step:39535[D loss: 0.999936] [G loss: 1.000079]\n",
      "epoch:10 step:39540[D loss: 0.999954] [G loss: 1.000188]\n",
      "epoch:10 step:39545[D loss: 1.000023] [G loss: 1.000079]\n",
      "epoch:10 step:39550[D loss: 0.999957] [G loss: 1.000105]\n",
      "epoch:10 step:39555[D loss: 0.999955] [G loss: 1.000083]\n",
      "epoch:10 step:39560[D loss: 0.999978] [G loss: 1.000113]\n",
      "epoch:10 step:39565[D loss: 0.999968] [G loss: 1.000057]\n",
      "epoch:10 step:39570[D loss: 0.999992] [G loss: 1.000024]\n",
      "epoch:10 step:39575[D loss: 1.000081] [G loss: 0.999892]\n",
      "epoch:10 step:39580[D loss: 0.999974] [G loss: 1.000046]\n",
      "epoch:10 step:39585[D loss: 1.000018] [G loss: 1.000064]\n",
      "epoch:10 step:39590[D loss: 0.999994] [G loss: 1.000151]\n",
      "epoch:10 step:39595[D loss: 1.000009] [G loss: 1.000050]\n",
      "epoch:10 step:39600[D loss: 1.000007] [G loss: 1.000036]\n",
      "##############\n",
      "[0.86188999 0.86597604 0.83246179 0.83733543 0.8132947  0.84257148\n",
      " 0.86878647 0.85239299 0.80212014 0.8407832 ]\n",
      "##########\n",
      "epoch:10 step:39605[D loss: 0.999904] [G loss: 1.000176]\n",
      "epoch:10 step:39610[D loss: 0.999971] [G loss: 1.000075]\n",
      "epoch:10 step:39615[D loss: 1.000060] [G loss: 0.999945]\n",
      "epoch:10 step:39620[D loss: 0.999958] [G loss: 1.000061]\n",
      "epoch:10 step:39625[D loss: 1.000002] [G loss: 1.000065]\n",
      "epoch:10 step:39630[D loss: 0.999916] [G loss: 1.000122]\n",
      "epoch:10 step:39635[D loss: 1.000030] [G loss: 1.000054]\n",
      "epoch:10 step:39640[D loss: 0.999972] [G loss: 1.000086]\n",
      "epoch:10 step:39645[D loss: 0.999905] [G loss: 1.000180]\n",
      "epoch:10 step:39650[D loss: 0.999943] [G loss: 1.000130]\n",
      "epoch:10 step:39655[D loss: 0.999957] [G loss: 1.000101]\n",
      "epoch:10 step:39660[D loss: 1.000009] [G loss: 1.000002]\n",
      "epoch:10 step:39665[D loss: 1.000011] [G loss: 1.000029]\n",
      "epoch:10 step:39670[D loss: 0.999991] [G loss: 1.000032]\n",
      "epoch:10 step:39675[D loss: 1.000017] [G loss: 1.000004]\n",
      "epoch:10 step:39680[D loss: 0.999927] [G loss: 1.000082]\n",
      "epoch:10 step:39685[D loss: 0.999962] [G loss: 1.000052]\n",
      "epoch:10 step:39690[D loss: 0.999990] [G loss: 1.000064]\n",
      "epoch:10 step:39695[D loss: 0.999961] [G loss: 1.000067]\n",
      "epoch:10 step:39700[D loss: 0.999982] [G loss: 1.000079]\n",
      "epoch:10 step:39705[D loss: 1.000019] [G loss: 1.000052]\n",
      "epoch:10 step:39710[D loss: 0.999959] [G loss: 1.000040]\n",
      "epoch:10 step:39715[D loss: 0.999975] [G loss: 1.000075]\n",
      "epoch:10 step:39720[D loss: 1.000007] [G loss: 1.000065]\n",
      "epoch:10 step:39725[D loss: 0.999971] [G loss: 1.000008]\n",
      "epoch:10 step:39730[D loss: 1.000051] [G loss: 0.999985]\n",
      "epoch:10 step:39735[D loss: 0.999960] [G loss: 1.000056]\n",
      "epoch:10 step:39740[D loss: 0.999988] [G loss: 1.000085]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:10 step:39745[D loss: 0.999995] [G loss: 1.000026]\n",
      "epoch:10 step:39750[D loss: 0.999997] [G loss: 1.000058]\n",
      "epoch:10 step:39755[D loss: 0.999992] [G loss: 1.000010]\n",
      "epoch:10 step:39760[D loss: 0.999997] [G loss: 0.999988]\n",
      "epoch:10 step:39765[D loss: 0.999962] [G loss: 1.000078]\n",
      "epoch:10 step:39770[D loss: 0.999977] [G loss: 1.000058]\n",
      "epoch:10 step:39775[D loss: 1.000017] [G loss: 1.000021]\n",
      "epoch:10 step:39780[D loss: 0.999960] [G loss: 0.999983]\n",
      "epoch:10 step:39785[D loss: 0.999985] [G loss: 1.000044]\n",
      "epoch:10 step:39790[D loss: 0.999970] [G loss: 1.000071]\n",
      "epoch:10 step:39795[D loss: 0.999970] [G loss: 1.000068]\n",
      "epoch:10 step:39800[D loss: 0.999982] [G loss: 1.000055]\n",
      "##############\n",
      "[0.86691646 0.86900631 0.83270634 0.83675009 0.80529736 0.83565\n",
      " 0.86749015 0.81373593 0.84505166 0.82205068]\n",
      "##########\n",
      "epoch:10 step:39805[D loss: 0.999985] [G loss: 1.000017]\n",
      "epoch:10 step:39810[D loss: 0.999985] [G loss: 1.000068]\n",
      "epoch:10 step:39815[D loss: 0.999979] [G loss: 1.000062]\n",
      "epoch:10 step:39820[D loss: 0.999966] [G loss: 1.000092]\n",
      "epoch:10 step:39825[D loss: 0.999955] [G loss: 1.000082]\n",
      "epoch:10 step:39830[D loss: 0.999978] [G loss: 1.000052]\n",
      "epoch:10 step:39835[D loss: 0.999976] [G loss: 1.000061]\n",
      "epoch:10 step:39840[D loss: 1.000039] [G loss: 0.999978]\n",
      "epoch:10 step:39845[D loss: 1.000030] [G loss: 1.000018]\n",
      "epoch:10 step:39850[D loss: 0.999970] [G loss: 1.000076]\n",
      "epoch:10 step:39855[D loss: 0.999954] [G loss: 1.000080]\n",
      "epoch:10 step:39860[D loss: 0.999983] [G loss: 1.000047]\n",
      "epoch:10 step:39865[D loss: 0.999984] [G loss: 1.000063]\n",
      "epoch:10 step:39870[D loss: 0.999976] [G loss: 1.000058]\n",
      "epoch:10 step:39875[D loss: 0.999986] [G loss: 1.000047]\n",
      "epoch:10 step:39880[D loss: 0.999975] [G loss: 1.000067]\n",
      "epoch:10 step:39885[D loss: 0.999970] [G loss: 1.000067]\n",
      "epoch:10 step:39890[D loss: 0.999985] [G loss: 1.000062]\n",
      "epoch:10 step:39895[D loss: 0.999963] [G loss: 1.000062]\n",
      "epoch:10 step:39900[D loss: 0.999973] [G loss: 1.000091]\n",
      "epoch:10 step:39905[D loss: 1.000019] [G loss: 1.000010]\n",
      "epoch:10 step:39910[D loss: 0.999945] [G loss: 1.000155]\n",
      "epoch:10 step:39915[D loss: 0.999950] [G loss: 1.000120]\n",
      "epoch:10 step:39920[D loss: 0.999927] [G loss: 1.000107]\n",
      "epoch:10 step:39925[D loss: 0.999968] [G loss: 1.000063]\n",
      "epoch:10 step:39930[D loss: 0.999980] [G loss: 1.000042]\n",
      "epoch:10 step:39935[D loss: 0.999955] [G loss: 1.000068]\n",
      "epoch:10 step:39940[D loss: 0.999969] [G loss: 1.000065]\n",
      "epoch:10 step:39945[D loss: 0.999993] [G loss: 1.000087]\n",
      "epoch:10 step:39950[D loss: 1.000056] [G loss: 0.999930]\n",
      "epoch:10 step:39955[D loss: 0.999939] [G loss: 1.000115]\n",
      "epoch:10 step:39960[D loss: 0.999966] [G loss: 1.000031]\n",
      "epoch:10 step:39965[D loss: 1.000027] [G loss: 0.999981]\n",
      "epoch:10 step:39970[D loss: 0.999914] [G loss: 1.000073]\n",
      "epoch:10 step:39975[D loss: 1.000047] [G loss: 0.999981]\n",
      "epoch:10 step:39980[D loss: 0.999935] [G loss: 1.000089]\n",
      "epoch:10 step:39985[D loss: 0.999967] [G loss: 1.000031]\n",
      "epoch:10 step:39990[D loss: 1.000026] [G loss: 0.999952]\n",
      "epoch:10 step:39995[D loss: 0.999949] [G loss: 1.000063]\n",
      "epoch:10 step:40000[D loss: 0.999992] [G loss: 0.999992]\n",
      "##############\n",
      "[0.8917473  0.85409884 0.81010202 0.84290064 0.82030909 0.84270784\n",
      " 0.87650916 0.82369202 0.82427247 0.84275698]\n",
      "##########\n",
      "epoch:10 step:40005[D loss: 0.999962] [G loss: 1.000043]\n",
      "epoch:10 step:40010[D loss: 0.999985] [G loss: 1.000064]\n",
      "epoch:10 step:40015[D loss: 0.999957] [G loss: 1.000050]\n",
      "epoch:10 step:40020[D loss: 0.999983] [G loss: 1.000052]\n",
      "epoch:10 step:40025[D loss: 0.999980] [G loss: 1.000060]\n",
      "epoch:10 step:40030[D loss: 0.999968] [G loss: 1.000060]\n",
      "epoch:10 step:40035[D loss: 1.000035] [G loss: 1.000007]\n",
      "epoch:10 step:40040[D loss: 0.999979] [G loss: 1.000055]\n",
      "epoch:10 step:40045[D loss: 0.999963] [G loss: 1.000031]\n",
      "epoch:10 step:40050[D loss: 0.999968] [G loss: 1.000033]\n",
      "epoch:10 step:40055[D loss: 0.999974] [G loss: 1.000061]\n",
      "epoch:10 step:40060[D loss: 0.999957] [G loss: 1.000055]\n",
      "epoch:10 step:40065[D loss: 0.999985] [G loss: 1.000084]\n",
      "epoch:10 step:40070[D loss: 0.999968] [G loss: 1.000058]\n",
      "epoch:10 step:40075[D loss: 0.999988] [G loss: 1.000059]\n",
      "epoch:10 step:40080[D loss: 0.999978] [G loss: 1.000033]\n",
      "epoch:10 step:40085[D loss: 0.999967] [G loss: 1.000052]\n",
      "epoch:10 step:40090[D loss: 0.999964] [G loss: 1.000061]\n",
      "epoch:10 step:40095[D loss: 1.000005] [G loss: 1.000021]\n",
      "epoch:10 step:40100[D loss: 0.999946] [G loss: 1.000089]\n",
      "epoch:10 step:40105[D loss: 0.999989] [G loss: 1.000013]\n",
      "epoch:10 step:40110[D loss: 0.999981] [G loss: 1.000059]\n",
      "epoch:10 step:40115[D loss: 0.999982] [G loss: 1.000040]\n",
      "epoch:10 step:40120[D loss: 1.000006] [G loss: 0.999974]\n",
      "epoch:10 step:40125[D loss: 1.000001] [G loss: 0.999955]\n",
      "epoch:10 step:40130[D loss: 0.999970] [G loss: 1.000087]\n",
      "epoch:10 step:40135[D loss: 0.999983] [G loss: 1.000047]\n",
      "epoch:10 step:40140[D loss: 0.999987] [G loss: 1.000072]\n",
      "epoch:10 step:40145[D loss: 0.999957] [G loss: 1.000075]\n",
      "epoch:10 step:40150[D loss: 0.999966] [G loss: 1.000054]\n",
      "epoch:10 step:40155[D loss: 0.999992] [G loss: 1.000019]\n",
      "epoch:10 step:40160[D loss: 0.999985] [G loss: 1.000097]\n",
      "epoch:10 step:40165[D loss: 0.999997] [G loss: 1.000033]\n",
      "epoch:10 step:40170[D loss: 0.999972] [G loss: 1.000149]\n",
      "epoch:10 step:40175[D loss: 0.999938] [G loss: 1.000141]\n",
      "epoch:10 step:40180[D loss: 0.999981] [G loss: 1.000070]\n",
      "epoch:10 step:40185[D loss: 0.999971] [G loss: 1.000083]\n",
      "epoch:10 step:40190[D loss: 0.999965] [G loss: 1.000080]\n",
      "epoch:10 step:40195[D loss: 0.999987] [G loss: 1.000062]\n",
      "epoch:10 step:40200[D loss: 1.000039] [G loss: 1.000001]\n",
      "##############\n",
      "[0.87052164 0.86860362 0.82458648 0.83486634 0.815965   0.85298887\n",
      " 0.85769468 0.84970841 0.84495036 0.85025282]\n",
      "##########\n",
      "epoch:10 step:40205[D loss: 0.999969] [G loss: 1.000103]\n",
      "epoch:10 step:40210[D loss: 0.999907] [G loss: 1.000231]\n",
      "epoch:10 step:40215[D loss: 0.999893] [G loss: 1.000184]\n",
      "epoch:10 step:40220[D loss: 0.999940] [G loss: 1.000138]\n",
      "epoch:10 step:40225[D loss: 0.999991] [G loss: 1.000082]\n",
      "epoch:10 step:40230[D loss: 1.000067] [G loss: 0.999965]\n",
      "epoch:10 step:40235[D loss: 1.000021] [G loss: 0.999978]\n",
      "epoch:10 step:40240[D loss: 1.000001] [G loss: 0.999951]\n",
      "epoch:10 step:40245[D loss: 0.999972] [G loss: 1.000047]\n",
      "epoch:10 step:40250[D loss: 0.999963] [G loss: 1.000094]\n",
      "epoch:10 step:40255[D loss: 0.999973] [G loss: 1.000074]\n",
      "epoch:10 step:40260[D loss: 0.999989] [G loss: 1.000059]\n",
      "epoch:10 step:40265[D loss: 0.999953] [G loss: 1.000124]\n",
      "epoch:10 step:40270[D loss: 0.999998] [G loss: 1.000057]\n",
      "epoch:10 step:40275[D loss: 1.000001] [G loss: 1.000058]\n",
      "epoch:10 step:40280[D loss: 0.999965] [G loss: 1.000108]\n",
      "epoch:10 step:40285[D loss: 0.999994] [G loss: 1.000058]\n",
      "epoch:10 step:40290[D loss: 0.999966] [G loss: 1.000039]\n",
      "epoch:10 step:40295[D loss: 0.999983] [G loss: 1.000016]\n",
      "epoch:10 step:40300[D loss: 1.000012] [G loss: 0.999968]\n",
      "epoch:10 step:40305[D loss: 0.999945] [G loss: 1.000037]\n",
      "epoch:10 step:40310[D loss: 0.999973] [G loss: 1.000032]\n",
      "epoch:10 step:40315[D loss: 0.999956] [G loss: 1.000088]\n",
      "epoch:10 step:40320[D loss: 0.999958] [G loss: 1.000055]\n",
      "epoch:10 step:40325[D loss: 0.999944] [G loss: 1.000076]\n",
      "epoch:10 step:40330[D loss: 0.999981] [G loss: 1.000089]\n",
      "epoch:10 step:40335[D loss: 0.999948] [G loss: 1.000104]\n",
      "epoch:10 step:40340[D loss: 0.999976] [G loss: 1.000078]\n",
      "epoch:10 step:40345[D loss: 0.999951] [G loss: 1.000063]\n",
      "epoch:10 step:40350[D loss: 0.999977] [G loss: 1.000039]\n",
      "epoch:10 step:40355[D loss: 0.999982] [G loss: 1.000034]\n",
      "epoch:10 step:40360[D loss: 0.999965] [G loss: 1.000058]\n",
      "epoch:10 step:40365[D loss: 0.999974] [G loss: 1.000056]\n",
      "epoch:10 step:40370[D loss: 0.999966] [G loss: 1.000056]\n",
      "epoch:10 step:40375[D loss: 0.999983] [G loss: 1.000041]\n",
      "epoch:10 step:40380[D loss: 0.999974] [G loss: 1.000049]\n",
      "epoch:10 step:40385[D loss: 0.999956] [G loss: 1.000098]\n",
      "epoch:10 step:40390[D loss: 0.999976] [G loss: 1.000034]\n",
      "epoch:10 step:40395[D loss: 0.999978] [G loss: 1.000035]\n",
      "epoch:10 step:40400[D loss: 0.999966] [G loss: 1.000061]\n",
      "##############\n",
      "[0.86424508 0.86250072 0.83525535 0.82405232 0.81071192 0.85134683\n",
      " 0.8835876  0.82116057 0.80351065 0.83777743]\n",
      "##########\n",
      "epoch:10 step:40405[D loss: 0.999965] [G loss: 1.000069]\n",
      "epoch:10 step:40410[D loss: 0.999983] [G loss: 1.000071]\n",
      "epoch:10 step:40415[D loss: 0.999978] [G loss: 1.000098]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:10 step:40420[D loss: 0.999999] [G loss: 1.000079]\n",
      "epoch:10 step:40425[D loss: 0.999992] [G loss: 1.000000]\n",
      "epoch:10 step:40430[D loss: 0.999984] [G loss: 1.000024]\n",
      "epoch:10 step:40435[D loss: 0.999961] [G loss: 1.000065]\n",
      "epoch:10 step:40440[D loss: 0.999977] [G loss: 1.000057]\n",
      "epoch:10 step:40445[D loss: 0.999957] [G loss: 1.000054]\n",
      "epoch:10 step:40450[D loss: 0.999972] [G loss: 1.000066]\n",
      "epoch:10 step:40455[D loss: 0.999981] [G loss: 1.000051]\n",
      "epoch:10 step:40460[D loss: 0.999975] [G loss: 1.000074]\n",
      "epoch:10 step:40465[D loss: 0.999953] [G loss: 1.000099]\n",
      "epoch:10 step:40470[D loss: 0.999968] [G loss: 1.000059]\n",
      "epoch:10 step:40475[D loss: 0.999996] [G loss: 1.000062]\n",
      "epoch:10 step:40480[D loss: 0.999984] [G loss: 1.000069]\n",
      "epoch:10 step:40485[D loss: 0.999958] [G loss: 1.000079]\n",
      "epoch:10 step:40490[D loss: 0.999957] [G loss: 1.000078]\n",
      "epoch:10 step:40495[D loss: 0.999965] [G loss: 1.000070]\n",
      "epoch:10 step:40500[D loss: 0.999958] [G loss: 1.000068]\n",
      "epoch:10 step:40505[D loss: 0.999970] [G loss: 1.000084]\n",
      "epoch:10 step:40510[D loss: 0.999971] [G loss: 1.000058]\n",
      "epoch:10 step:40515[D loss: 0.999965] [G loss: 1.000065]\n",
      "epoch:10 step:40520[D loss: 0.999994] [G loss: 1.000008]\n",
      "epoch:10 step:40525[D loss: 0.999969] [G loss: 1.000086]\n",
      "epoch:10 step:40530[D loss: 0.999979] [G loss: 1.000071]\n",
      "epoch:10 step:40535[D loss: 0.999974] [G loss: 1.000076]\n",
      "epoch:10 step:40540[D loss: 0.999975] [G loss: 1.000081]\n",
      "epoch:10 step:40545[D loss: 1.000003] [G loss: 1.000079]\n",
      "epoch:10 step:40550[D loss: 0.999963] [G loss: 1.000072]\n",
      "epoch:10 step:40555[D loss: 0.999967] [G loss: 1.000079]\n",
      "epoch:10 step:40560[D loss: 0.999971] [G loss: 1.000083]\n",
      "epoch:10 step:40565[D loss: 0.999969] [G loss: 1.000083]\n",
      "epoch:10 step:40570[D loss: 0.999977] [G loss: 1.000050]\n",
      "epoch:10 step:40575[D loss: 0.999978] [G loss: 1.000062]\n",
      "epoch:10 step:40580[D loss: 0.999978] [G loss: 1.000079]\n",
      "epoch:10 step:40585[D loss: 0.999969] [G loss: 1.000090]\n",
      "epoch:10 step:40590[D loss: 0.999981] [G loss: 1.000055]\n",
      "epoch:10 step:40595[D loss: 0.999957] [G loss: 1.000096]\n",
      "epoch:10 step:40600[D loss: 0.999977] [G loss: 1.000134]\n",
      "##############\n",
      "[0.86434208 0.84889522 0.80827698 0.84843001 0.80820709 0.82521333\n",
      " 0.88811291 0.83805435 0.82608287 0.83521521]\n",
      "##########\n",
      "epoch:10 step:40605[D loss: 0.999976] [G loss: 1.000088]\n",
      "epoch:10 step:40610[D loss: 0.999962] [G loss: 1.000088]\n",
      "epoch:10 step:40615[D loss: 0.999971] [G loss: 1.000077]\n",
      "epoch:10 step:40620[D loss: 0.999986] [G loss: 1.000038]\n",
      "epoch:10 step:40625[D loss: 1.000030] [G loss: 0.999983]\n",
      "epoch:10 step:40630[D loss: 1.000039] [G loss: 0.999986]\n",
      "epoch:10 step:40635[D loss: 0.999955] [G loss: 1.000148]\n",
      "epoch:10 step:40640[D loss: 0.999951] [G loss: 1.000102]\n",
      "epoch:10 step:40645[D loss: 0.999964] [G loss: 1.000086]\n",
      "epoch:10 step:40650[D loss: 0.999982] [G loss: 1.000069]\n",
      "epoch:10 step:40655[D loss: 0.999969] [G loss: 1.000062]\n",
      "epoch:10 step:40660[D loss: 0.999986] [G loss: 1.000093]\n",
      "epoch:10 step:40665[D loss: 1.000000] [G loss: 1.000048]\n",
      "epoch:10 step:40670[D loss: 0.999983] [G loss: 1.000022]\n",
      "epoch:10 step:40675[D loss: 0.999996] [G loss: 1.000068]\n",
      "epoch:10 step:40680[D loss: 0.999968] [G loss: 1.000019]\n",
      "epoch:10 step:40685[D loss: 0.999974] [G loss: 1.000051]\n",
      "epoch:10 step:40690[D loss: 1.000003] [G loss: 1.000041]\n",
      "epoch:10 step:40695[D loss: 0.999991] [G loss: 1.000107]\n",
      "epoch:10 step:40700[D loss: 0.999979] [G loss: 1.000037]\n",
      "epoch:10 step:40705[D loss: 0.999972] [G loss: 1.000091]\n",
      "epoch:10 step:40710[D loss: 1.000004] [G loss: 1.000052]\n",
      "epoch:10 step:40715[D loss: 0.999948] [G loss: 1.000101]\n",
      "epoch:10 step:40720[D loss: 0.999978] [G loss: 1.000063]\n",
      "epoch:10 step:40725[D loss: 0.999972] [G loss: 1.000077]\n",
      "epoch:10 step:40730[D loss: 0.999981] [G loss: 1.000053]\n",
      "epoch:10 step:40735[D loss: 1.000023] [G loss: 1.000017]\n",
      "epoch:10 step:40740[D loss: 0.999965] [G loss: 1.000074]\n",
      "epoch:10 step:40745[D loss: 0.999981] [G loss: 1.000087]\n",
      "epoch:10 step:40750[D loss: 1.000001] [G loss: 1.000023]\n",
      "epoch:10 step:40755[D loss: 0.999971] [G loss: 1.000017]\n",
      "epoch:10 step:40760[D loss: 0.999957] [G loss: 1.000079]\n",
      "epoch:10 step:40765[D loss: 0.999968] [G loss: 1.000068]\n",
      "epoch:10 step:40770[D loss: 0.999973] [G loss: 1.000050]\n",
      "epoch:10 step:40775[D loss: 0.999965] [G loss: 1.000056]\n",
      "epoch:10 step:40780[D loss: 0.999960] [G loss: 1.000103]\n",
      "epoch:10 step:40785[D loss: 0.999964] [G loss: 1.000073]\n",
      "epoch:10 step:40790[D loss: 0.999977] [G loss: 1.000043]\n",
      "epoch:10 step:40795[D loss: 0.999977] [G loss: 1.000067]\n",
      "epoch:10 step:40800[D loss: 0.999989] [G loss: 1.000041]\n",
      "##############\n",
      "[0.8733699  0.85937397 0.83947386 0.82884547 0.81427336 0.84948834\n",
      " 0.85411489 0.83093914 0.81124879 0.82012262]\n",
      "##########\n",
      "epoch:10 step:40805[D loss: 0.999991] [G loss: 0.999995]\n",
      "epoch:10 step:40810[D loss: 0.999942] [G loss: 1.000087]\n",
      "epoch:10 step:40815[D loss: 0.999947] [G loss: 1.000067]\n",
      "epoch:10 step:40820[D loss: 0.999993] [G loss: 1.000045]\n",
      "epoch:10 step:40825[D loss: 0.999949] [G loss: 1.000100]\n",
      "epoch:10 step:40830[D loss: 0.999961] [G loss: 1.000104]\n",
      "epoch:10 step:40835[D loss: 0.999989] [G loss: 1.000028]\n",
      "epoch:10 step:40840[D loss: 0.999987] [G loss: 0.999987]\n",
      "epoch:10 step:40845[D loss: 0.999979] [G loss: 1.000004]\n",
      "epoch:10 step:40850[D loss: 0.999997] [G loss: 1.000010]\n",
      "epoch:10 step:40855[D loss: 1.000016] [G loss: 1.000089]\n",
      "epoch:10 step:40860[D loss: 0.999936] [G loss: 1.000110]\n",
      "epoch:10 step:40865[D loss: 1.000017] [G loss: 1.000065]\n",
      "epoch:10 step:40870[D loss: 0.999950] [G loss: 1.000068]\n",
      "epoch:10 step:40875[D loss: 0.999996] [G loss: 1.000046]\n",
      "epoch:10 step:40880[D loss: 0.999994] [G loss: 1.000024]\n",
      "epoch:10 step:40885[D loss: 1.000027] [G loss: 0.999986]\n",
      "epoch:10 step:40890[D loss: 0.999958] [G loss: 1.000053]\n",
      "epoch:10 step:40895[D loss: 0.999946] [G loss: 1.000089]\n",
      "epoch:10 step:40900[D loss: 0.999966] [G loss: 1.000059]\n",
      "epoch:10 step:40905[D loss: 0.999961] [G loss: 1.000096]\n",
      "epoch:10 step:40910[D loss: 0.999968] [G loss: 1.000084]\n",
      "epoch:10 step:40915[D loss: 1.000006] [G loss: 1.000064]\n",
      "epoch:10 step:40920[D loss: 0.999972] [G loss: 1.000096]\n",
      "epoch:10 step:40925[D loss: 0.999962] [G loss: 1.000077]\n",
      "epoch:10 step:40930[D loss: 0.999959] [G loss: 1.000091]\n",
      "epoch:10 step:40935[D loss: 0.999982] [G loss: 1.000067]\n",
      "epoch:10 step:40940[D loss: 0.999976] [G loss: 1.000052]\n",
      "epoch:10 step:40945[D loss: 0.999968] [G loss: 1.000066]\n",
      "epoch:10 step:40950[D loss: 0.999976] [G loss: 1.000069]\n",
      "epoch:10 step:40955[D loss: 1.000017] [G loss: 1.000112]\n",
      "epoch:10 step:40960[D loss: 1.000044] [G loss: 1.000026]\n",
      "epoch:10 step:40965[D loss: 0.999989] [G loss: 1.000098]\n",
      "epoch:10 step:40970[D loss: 0.999969] [G loss: 1.000103]\n",
      "epoch:10 step:40975[D loss: 0.999944] [G loss: 1.000115]\n",
      "epoch:10 step:40980[D loss: 0.999982] [G loss: 1.000061]\n",
      "epoch:10 step:40985[D loss: 1.000001] [G loss: 1.000050]\n",
      "epoch:10 step:40990[D loss: 0.999973] [G loss: 1.000051]\n",
      "epoch:10 step:40995[D loss: 0.999960] [G loss: 1.000075]\n",
      "epoch:10 step:41000[D loss: 1.000009] [G loss: 1.000016]\n",
      "##############\n",
      "[0.87696646 0.86688158 0.81541999 0.83632787 0.79200064 0.84342123\n",
      " 0.88493676 0.85219992 0.8247143  0.83525113]\n",
      "##########\n",
      "epoch:10 step:41005[D loss: 0.999957] [G loss: 1.000118]\n",
      "epoch:10 step:41010[D loss: 0.999956] [G loss: 1.000065]\n",
      "epoch:10 step:41015[D loss: 0.999979] [G loss: 1.000065]\n",
      "epoch:10 step:41020[D loss: 0.999990] [G loss: 1.000060]\n",
      "epoch:10 step:41025[D loss: 1.000001] [G loss: 1.000013]\n",
      "epoch:10 step:41030[D loss: 1.000037] [G loss: 0.999944]\n",
      "epoch:10 step:41035[D loss: 0.999985] [G loss: 1.000064]\n",
      "epoch:10 step:41040[D loss: 0.999966] [G loss: 1.000075]\n",
      "epoch:10 step:41045[D loss: 0.999985] [G loss: 1.000073]\n",
      "epoch:10 step:41050[D loss: 0.999956] [G loss: 1.000107]\n",
      "epoch:10 step:41055[D loss: 0.999947] [G loss: 1.000098]\n",
      "epoch:10 step:41060[D loss: 0.999964] [G loss: 1.000083]\n",
      "epoch:10 step:41065[D loss: 0.999979] [G loss: 1.000085]\n",
      "epoch:10 step:41070[D loss: 0.999993] [G loss: 1.000040]\n",
      "epoch:10 step:41075[D loss: 1.000037] [G loss: 0.999923]\n",
      "epoch:10 step:41080[D loss: 0.999955] [G loss: 1.000071]\n",
      "epoch:10 step:41085[D loss: 0.999986] [G loss: 1.000031]\n",
      "epoch:10 step:41090[D loss: 1.000020] [G loss: 1.000009]\n",
      "epoch:10 step:41095[D loss: 0.999969] [G loss: 1.000057]\n",
      "epoch:10 step:41100[D loss: 0.999986] [G loss: 1.000046]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:10 step:41105[D loss: 0.999958] [G loss: 1.000074]\n",
      "epoch:10 step:41110[D loss: 0.999976] [G loss: 1.000056]\n",
      "epoch:10 step:41115[D loss: 1.000001] [G loss: 0.999981]\n",
      "epoch:10 step:41120[D loss: 1.000002] [G loss: 1.000051]\n",
      "epoch:10 step:41125[D loss: 0.999996] [G loss: 1.000048]\n",
      "epoch:10 step:41130[D loss: 0.999984] [G loss: 1.000070]\n",
      "epoch:10 step:41135[D loss: 0.999947] [G loss: 1.000117]\n",
      "epoch:10 step:41140[D loss: 0.999974] [G loss: 1.000078]\n",
      "epoch:10 step:41145[D loss: 0.999976] [G loss: 1.000048]\n",
      "epoch:10 step:41150[D loss: 0.999973] [G loss: 1.000060]\n",
      "epoch:10 step:41155[D loss: 1.000002] [G loss: 1.000048]\n",
      "epoch:10 step:41160[D loss: 0.999954] [G loss: 1.000060]\n",
      "epoch:10 step:41165[D loss: 0.999976] [G loss: 1.000067]\n",
      "epoch:10 step:41170[D loss: 0.999980] [G loss: 1.000059]\n",
      "epoch:10 step:41175[D loss: 0.999965] [G loss: 1.000085]\n",
      "epoch:10 step:41180[D loss: 0.999958] [G loss: 1.000093]\n",
      "epoch:10 step:41185[D loss: 0.999987] [G loss: 1.000049]\n",
      "epoch:10 step:41190[D loss: 0.999973] [G loss: 1.000039]\n",
      "epoch:10 step:41195[D loss: 1.000015] [G loss: 1.000021]\n",
      "epoch:10 step:41200[D loss: 0.999957] [G loss: 1.000066]\n",
      "##############\n",
      "[0.89566531 0.84879891 0.83501294 0.83814008 0.81449903 0.84512723\n",
      " 0.90062625 0.81663521 0.83329665 0.83800339]\n",
      "##########\n",
      "epoch:10 step:41205[D loss: 0.999987] [G loss: 1.000025]\n",
      "epoch:10 step:41210[D loss: 0.999980] [G loss: 1.000019]\n",
      "epoch:10 step:41215[D loss: 0.999977] [G loss: 1.000044]\n",
      "epoch:10 step:41220[D loss: 1.000031] [G loss: 0.999995]\n",
      "epoch:10 step:41225[D loss: 0.999952] [G loss: 1.000109]\n",
      "epoch:10 step:41230[D loss: 0.999967] [G loss: 1.000099]\n",
      "epoch:10 step:41235[D loss: 1.000023] [G loss: 0.999879]\n",
      "epoch:10 step:41240[D loss: 1.000013] [G loss: 1.000048]\n",
      "epoch:10 step:41245[D loss: 0.999937] [G loss: 1.000129]\n",
      "epoch:10 step:41250[D loss: 0.999977] [G loss: 1.000069]\n",
      "epoch:10 step:41255[D loss: 0.999986] [G loss: 1.000068]\n",
      "epoch:10 step:41260[D loss: 0.999965] [G loss: 1.000089]\n",
      "epoch:10 step:41265[D loss: 0.999986] [G loss: 1.000033]\n",
      "epoch:10 step:41270[D loss: 0.999973] [G loss: 1.000064]\n",
      "epoch:10 step:41275[D loss: 0.999973] [G loss: 1.000043]\n",
      "epoch:10 step:41280[D loss: 1.000042] [G loss: 0.999931]\n",
      "epoch:10 step:41285[D loss: 0.999976] [G loss: 1.000079]\n",
      "epoch:10 step:41290[D loss: 1.000012] [G loss: 1.000120]\n",
      "epoch:10 step:41295[D loss: 0.999909] [G loss: 1.000106]\n",
      "epoch:10 step:41300[D loss: 0.999985] [G loss: 1.000099]\n",
      "epoch:10 step:41305[D loss: 0.999956] [G loss: 1.000112]\n",
      "epoch:10 step:41310[D loss: 0.999971] [G loss: 1.000040]\n",
      "epoch:10 step:41315[D loss: 0.999975] [G loss: 1.000083]\n",
      "epoch:10 step:41320[D loss: 0.999945] [G loss: 1.000039]\n",
      "epoch:10 step:41325[D loss: 1.000010] [G loss: 1.000002]\n",
      "epoch:10 step:41330[D loss: 0.999986] [G loss: 1.000064]\n",
      "epoch:10 step:41335[D loss: 0.999969] [G loss: 1.000102]\n",
      "epoch:10 step:41340[D loss: 0.999984] [G loss: 1.000078]\n",
      "epoch:10 step:41345[D loss: 0.999998] [G loss: 1.000033]\n",
      "epoch:10 step:41350[D loss: 0.999969] [G loss: 1.000066]\n",
      "epoch:10 step:41355[D loss: 0.999982] [G loss: 1.000081]\n",
      "epoch:10 step:41360[D loss: 0.999953] [G loss: 1.000096]\n",
      "epoch:10 step:41365[D loss: 0.999977] [G loss: 1.000083]\n",
      "epoch:10 step:41370[D loss: 0.999985] [G loss: 1.000061]\n",
      "epoch:10 step:41375[D loss: 0.999970] [G loss: 1.000083]\n",
      "epoch:10 step:41380[D loss: 1.000018] [G loss: 0.999993]\n",
      "epoch:10 step:41385[D loss: 0.999969] [G loss: 1.000071]\n",
      "epoch:10 step:41390[D loss: 0.999974] [G loss: 1.000052]\n",
      "epoch:10 step:41395[D loss: 1.000056] [G loss: 0.999937]\n",
      "epoch:10 step:41400[D loss: 0.999949] [G loss: 1.000104]\n",
      "##############\n",
      "[0.86881489 0.86354631 0.84474058 0.82686675 0.82352389 0.82953787\n",
      " 0.86447394 0.8533402  0.80658264 0.84593123]\n",
      "##########\n",
      "epoch:10 step:41405[D loss: 0.999988] [G loss: 0.999991]\n",
      "epoch:10 step:41410[D loss: 0.999960] [G loss: 1.000055]\n",
      "epoch:10 step:41415[D loss: 1.000040] [G loss: 0.999930]\n",
      "epoch:10 step:41420[D loss: 1.000025] [G loss: 0.999990]\n",
      "epoch:10 step:41425[D loss: 0.999947] [G loss: 1.000064]\n",
      "epoch:10 step:41430[D loss: 0.999983] [G loss: 1.000032]\n",
      "epoch:10 step:41435[D loss: 0.999960] [G loss: 1.000073]\n",
      "epoch:10 step:41440[D loss: 0.999977] [G loss: 1.000060]\n",
      "epoch:10 step:41445[D loss: 0.999970] [G loss: 1.000059]\n",
      "epoch:10 step:41450[D loss: 0.999975] [G loss: 1.000064]\n",
      "epoch:10 step:41455[D loss: 0.999955] [G loss: 1.000081]\n",
      "epoch:10 step:41460[D loss: 0.999981] [G loss: 1.000075]\n",
      "epoch:10 step:41465[D loss: 0.999961] [G loss: 1.000059]\n",
      "epoch:10 step:41470[D loss: 0.999993] [G loss: 1.000048]\n",
      "epoch:10 step:41475[D loss: 0.999981] [G loss: 1.000045]\n",
      "epoch:10 step:41480[D loss: 0.999985] [G loss: 1.000050]\n",
      "epoch:10 step:41485[D loss: 0.999990] [G loss: 1.000027]\n",
      "epoch:10 step:41490[D loss: 0.999990] [G loss: 1.000030]\n",
      "epoch:10 step:41495[D loss: 0.999984] [G loss: 1.000022]\n",
      "epoch:10 step:41500[D loss: 0.999974] [G loss: 1.000067]\n",
      "epoch:10 step:41505[D loss: 0.999972] [G loss: 1.000055]\n",
      "epoch:10 step:41510[D loss: 1.000020] [G loss: 0.999968]\n",
      "epoch:10 step:41515[D loss: 1.000025] [G loss: 1.000117]\n",
      "epoch:10 step:41520[D loss: 0.999950] [G loss: 1.000060]\n",
      "epoch:10 step:41525[D loss: 0.999952] [G loss: 1.000139]\n",
      "epoch:10 step:41530[D loss: 0.999943] [G loss: 1.000104]\n",
      "epoch:10 step:41535[D loss: 0.999981] [G loss: 1.000067]\n",
      "epoch:10 step:41540[D loss: 0.999974] [G loss: 1.000056]\n",
      "epoch:10 step:41545[D loss: 0.999966] [G loss: 1.000085]\n",
      "epoch:10 step:41550[D loss: 1.000040] [G loss: 0.999950]\n",
      "epoch:10 step:41555[D loss: 0.999967] [G loss: 1.000038]\n",
      "epoch:10 step:41560[D loss: 1.000049] [G loss: 0.999924]\n",
      "epoch:10 step:41565[D loss: 0.999998] [G loss: 1.000003]\n",
      "epoch:10 step:41570[D loss: 0.999974] [G loss: 1.000039]\n",
      "epoch:10 step:41575[D loss: 0.999985] [G loss: 1.000055]\n",
      "epoch:10 step:41580[D loss: 0.999962] [G loss: 1.000130]\n",
      "epoch:10 step:41585[D loss: 0.999976] [G loss: 1.000084]\n",
      "epoch:10 step:41590[D loss: 1.000003] [G loss: 1.000016]\n",
      "epoch:10 step:41595[D loss: 1.000011] [G loss: 1.000063]\n",
      "epoch:10 step:41600[D loss: 1.000004] [G loss: 1.000210]\n",
      "##############\n",
      "[0.86791276 0.83570318 0.82702065 0.83136035 0.82619083 0.83107141\n",
      " 0.88397154 0.82768141 0.81020944 0.84242557]\n",
      "##########\n",
      "epoch:10 step:41605[D loss: 1.000035] [G loss: 1.000139]\n",
      "epoch:10 step:41610[D loss: 1.000002] [G loss: 1.000074]\n",
      "epoch:10 step:41615[D loss: 0.999907] [G loss: 1.000160]\n",
      "epoch:10 step:41620[D loss: 0.999942] [G loss: 1.000072]\n",
      "epoch:10 step:41625[D loss: 1.000000] [G loss: 0.999987]\n",
      "epoch:10 step:41630[D loss: 1.000012] [G loss: 0.999889]\n",
      "epoch:10 step:41635[D loss: 1.000027] [G loss: 0.999929]\n",
      "epoch:10 step:41640[D loss: 0.999960] [G loss: 1.000027]\n",
      "epoch:10 step:41645[D loss: 1.000025] [G loss: 0.999923]\n",
      "epoch:10 step:41650[D loss: 0.999936] [G loss: 1.000115]\n",
      "epoch:10 step:41655[D loss: 1.000051] [G loss: 0.999997]\n",
      "epoch:10 step:41660[D loss: 0.999986] [G loss: 1.000001]\n",
      "epoch:10 step:41665[D loss: 0.999959] [G loss: 1.000067]\n",
      "epoch:10 step:41670[D loss: 0.999954] [G loss: 1.000038]\n",
      "epoch:10 step:41675[D loss: 0.999994] [G loss: 1.000013]\n",
      "epoch:10 step:41680[D loss: 1.000017] [G loss: 0.999935]\n",
      "epoch:10 step:41685[D loss: 1.000022] [G loss: 0.999930]\n",
      "epoch:10 step:41690[D loss: 0.999989] [G loss: 1.000103]\n",
      "epoch:10 step:41695[D loss: 0.999926] [G loss: 1.000171]\n",
      "epoch:10 step:41700[D loss: 1.000028] [G loss: 1.000142]\n",
      "epoch:10 step:41705[D loss: 0.999963] [G loss: 1.000201]\n",
      "epoch:10 step:41710[D loss: 0.999976] [G loss: 1.000175]\n",
      "epoch:10 step:41715[D loss: 1.000100] [G loss: 1.000096]\n",
      "epoch:10 step:41720[D loss: 0.999922] [G loss: 1.000164]\n",
      "epoch:10 step:41725[D loss: 0.999971] [G loss: 1.000097]\n",
      "epoch:10 step:41730[D loss: 0.999994] [G loss: 0.999998]\n",
      "epoch:10 step:41735[D loss: 0.999989] [G loss: 1.000009]\n",
      "epoch:10 step:41740[D loss: 1.000054] [G loss: 0.999949]\n",
      "epoch:10 step:41745[D loss: 0.999917] [G loss: 1.000009]\n",
      "epoch:10 step:41750[D loss: 0.999985] [G loss: 0.999968]\n",
      "epoch:10 step:41755[D loss: 0.999954] [G loss: 1.000027]\n",
      "epoch:10 step:41760[D loss: 0.999973] [G loss: 1.000025]\n",
      "epoch:10 step:41765[D loss: 1.000052] [G loss: 0.999933]\n",
      "epoch:10 step:41770[D loss: 1.000011] [G loss: 1.000005]\n",
      "epoch:10 step:41775[D loss: 0.999990] [G loss: 0.999954]\n",
      "epoch:10 step:41780[D loss: 0.999946] [G loss: 1.000212]\n",
      "epoch:10 step:41785[D loss: 0.999903] [G loss: 1.000115]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:10 step:41790[D loss: 0.999976] [G loss: 1.000066]\n",
      "epoch:10 step:41795[D loss: 0.999967] [G loss: 1.000064]\n",
      "epoch:10 step:41800[D loss: 0.999965] [G loss: 1.000104]\n",
      "##############\n",
      "[0.87416547 0.84723592 0.82404079 0.83116928 0.81155129 0.84559286\n",
      " 0.88383731 0.85002162 0.81013977 0.85501501]\n",
      "##########\n",
      "epoch:10 step:41805[D loss: 0.999948] [G loss: 1.000141]\n",
      "epoch:10 step:41810[D loss: 1.000006] [G loss: 1.000035]\n",
      "epoch:10 step:41815[D loss: 1.000013] [G loss: 1.000061]\n",
      "epoch:10 step:41820[D loss: 1.000018] [G loss: 1.000025]\n",
      "epoch:10 step:41825[D loss: 1.000035] [G loss: 1.000008]\n",
      "epoch:10 step:41830[D loss: 0.999935] [G loss: 1.000177]\n",
      "epoch:10 step:41835[D loss: 0.999961] [G loss: 1.000183]\n",
      "epoch:10 step:41840[D loss: 0.999941] [G loss: 1.000116]\n",
      "epoch:10 step:41845[D loss: 1.000079] [G loss: 0.999829]\n",
      "epoch:10 step:41850[D loss: 1.000100] [G loss: 0.999828]\n",
      "epoch:10 step:41855[D loss: 0.999973] [G loss: 1.000132]\n",
      "epoch:10 step:41860[D loss: 1.000089] [G loss: 0.999853]\n",
      "epoch:10 step:41865[D loss: 0.999977] [G loss: 0.999979]\n",
      "epoch:10 step:41870[D loss: 0.999924] [G loss: 1.000220]\n",
      "epoch:10 step:41875[D loss: 0.999946] [G loss: 1.000165]\n",
      "epoch:10 step:41880[D loss: 0.999897] [G loss: 1.000130]\n",
      "epoch:10 step:41885[D loss: 0.999970] [G loss: 1.000087]\n",
      "epoch:10 step:41890[D loss: 0.999998] [G loss: 1.000017]\n",
      "epoch:10 step:41895[D loss: 0.999974] [G loss: 1.000066]\n",
      "epoch:10 step:41900[D loss: 0.999975] [G loss: 1.000071]\n",
      "epoch:10 step:41905[D loss: 1.000019] [G loss: 1.000024]\n",
      "epoch:10 step:41910[D loss: 1.000000] [G loss: 1.000090]\n",
      "epoch:10 step:41915[D loss: 0.999925] [G loss: 1.000156]\n",
      "epoch:10 step:41920[D loss: 0.999942] [G loss: 1.000184]\n",
      "epoch:10 step:41925[D loss: 1.000016] [G loss: 1.000025]\n",
      "epoch:10 step:41930[D loss: 0.999933] [G loss: 1.000168]\n",
      "epoch:10 step:41935[D loss: 0.999983] [G loss: 1.000105]\n",
      "epoch:10 step:41940[D loss: 0.999960] [G loss: 1.000089]\n",
      "epoch:10 step:41945[D loss: 0.999976] [G loss: 1.000083]\n",
      "epoch:10 step:41950[D loss: 0.999968] [G loss: 1.000071]\n",
      "epoch:10 step:41955[D loss: 0.999987] [G loss: 1.000036]\n",
      "epoch:10 step:41960[D loss: 1.000068] [G loss: 1.000012]\n",
      "epoch:10 step:41965[D loss: 0.999998] [G loss: 1.000031]\n",
      "epoch:10 step:41970[D loss: 1.000100] [G loss: 0.999963]\n",
      "epoch:10 step:41975[D loss: 0.999962] [G loss: 1.000053]\n",
      "epoch:10 step:41980[D loss: 1.000003] [G loss: 1.000008]\n",
      "epoch:10 step:41985[D loss: 0.999897] [G loss: 1.000121]\n",
      "epoch:10 step:41990[D loss: 0.999951] [G loss: 1.000106]\n",
      "epoch:10 step:41995[D loss: 0.999982] [G loss: 1.000052]\n",
      "epoch:10 step:42000[D loss: 0.999993] [G loss: 1.000044]\n",
      "##############\n",
      "[0.87986931 0.8633526  0.82402704 0.82371541 0.7965628  0.83513266\n",
      " 0.8780429  0.84768502 0.78530128 0.8306312 ]\n",
      "##########\n",
      "epoch:10 step:42005[D loss: 1.000027] [G loss: 0.999998]\n",
      "epoch:10 step:42010[D loss: 0.999950] [G loss: 1.000075]\n",
      "epoch:10 step:42015[D loss: 0.999959] [G loss: 1.000057]\n",
      "epoch:10 step:42020[D loss: 0.999969] [G loss: 1.000072]\n",
      "epoch:10 step:42025[D loss: 1.000024] [G loss: 1.000042]\n",
      "epoch:10 step:42030[D loss: 1.000022] [G loss: 0.999963]\n",
      "epoch:10 step:42035[D loss: 1.000043] [G loss: 0.999973]\n",
      "epoch:10 step:42040[D loss: 0.999946] [G loss: 1.000055]\n",
      "epoch:10 step:42045[D loss: 0.999958] [G loss: 1.000104]\n",
      "epoch:10 step:42050[D loss: 1.000016] [G loss: 1.000024]\n",
      "epoch:10 step:42055[D loss: 1.000056] [G loss: 0.999963]\n",
      "epoch:10 step:42060[D loss: 0.999951] [G loss: 1.000087]\n",
      "epoch:10 step:42065[D loss: 0.999961] [G loss: 1.000125]\n",
      "epoch:10 step:42070[D loss: 0.999977] [G loss: 1.000157]\n",
      "epoch:10 step:42075[D loss: 0.999972] [G loss: 1.000127]\n",
      "epoch:10 step:42080[D loss: 1.000019] [G loss: 1.000022]\n",
      "epoch:10 step:42085[D loss: 0.999989] [G loss: 1.000123]\n",
      "epoch:10 step:42090[D loss: 0.999977] [G loss: 1.000045]\n",
      "epoch:10 step:42095[D loss: 1.000059] [G loss: 0.999972]\n",
      "epoch:10 step:42100[D loss: 1.000006] [G loss: 1.000082]\n",
      "epoch:10 step:42105[D loss: 1.000055] [G loss: 0.999818]\n",
      "epoch:10 step:42110[D loss: 0.999904] [G loss: 1.000139]\n",
      "epoch:10 step:42115[D loss: 0.999976] [G loss: 1.000100]\n",
      "epoch:10 step:42120[D loss: 0.999936] [G loss: 1.000102]\n",
      "epoch:10 step:42125[D loss: 0.999975] [G loss: 1.000032]\n",
      "epoch:10 step:42130[D loss: 0.999982] [G loss: 1.000019]\n",
      "epoch:10 step:42135[D loss: 1.000009] [G loss: 1.000047]\n",
      "epoch:10 step:42140[D loss: 0.999954] [G loss: 1.000059]\n",
      "epoch:10 step:42145[D loss: 0.999967] [G loss: 1.000041]\n",
      "epoch:10 step:42150[D loss: 1.000026] [G loss: 1.000055]\n",
      "epoch:10 step:42155[D loss: 1.000027] [G loss: 1.000006]\n",
      "epoch:10 step:42160[D loss: 1.000056] [G loss: 0.999983]\n",
      "epoch:10 step:42165[D loss: 0.999946] [G loss: 1.000115]\n",
      "epoch:10 step:42170[D loss: 0.999942] [G loss: 1.000134]\n",
      "epoch:10 step:42175[D loss: 0.999954] [G loss: 1.000104]\n",
      "epoch:10 step:42180[D loss: 0.999978] [G loss: 1.000006]\n",
      "epoch:10 step:42185[D loss: 1.000066] [G loss: 0.999857]\n",
      "epoch:10 step:42190[D loss: 1.000068] [G loss: 0.999915]\n",
      "epoch:10 step:42195[D loss: 1.000247] [G loss: 0.999670]\n",
      "epoch:10 step:42200[D loss: 0.999997] [G loss: 1.000059]\n",
      "##############\n",
      "[0.86880495 0.8538592  0.82039714 0.84090632 0.79898231 0.84587705\n",
      " 0.89030459 0.83735312 0.84709848 0.81955944]\n",
      "##########\n",
      "epoch:10 step:42205[D loss: 0.999843] [G loss: 1.000166]\n",
      "epoch:10 step:42210[D loss: 1.000004] [G loss: 1.000091]\n",
      "epoch:10 step:42215[D loss: 0.999985] [G loss: 1.000043]\n",
      "epoch:10 step:42220[D loss: 0.999991] [G loss: 1.000023]\n",
      "epoch:10 step:42225[D loss: 0.999952] [G loss: 1.000090]\n",
      "epoch:10 step:42230[D loss: 1.000044] [G loss: 0.999930]\n",
      "epoch:10 step:42235[D loss: 0.999981] [G loss: 1.000021]\n",
      "epoch:10 step:42240[D loss: 1.000060] [G loss: 0.999975]\n",
      "epoch:10 step:42245[D loss: 0.999980] [G loss: 1.000087]\n",
      "epoch:10 step:42250[D loss: 0.999912] [G loss: 1.000131]\n",
      "epoch:10 step:42255[D loss: 0.999960] [G loss: 1.000049]\n",
      "epoch:10 step:42260[D loss: 0.999987] [G loss: 1.000046]\n",
      "epoch:10 step:42265[D loss: 0.999971] [G loss: 1.000057]\n",
      "epoch:10 step:42270[D loss: 0.999991] [G loss: 1.000009]\n",
      "epoch:10 step:42275[D loss: 0.999982] [G loss: 1.000037]\n",
      "epoch:10 step:42280[D loss: 0.999951] [G loss: 1.000075]\n",
      "epoch:10 step:42285[D loss: 0.999986] [G loss: 1.000069]\n",
      "epoch:10 step:42290[D loss: 0.999983] [G loss: 1.000012]\n",
      "epoch:10 step:42295[D loss: 0.999986] [G loss: 1.000037]\n",
      "epoch:10 step:42300[D loss: 0.999972] [G loss: 1.000066]\n",
      "epoch:10 step:42305[D loss: 1.000002] [G loss: 1.000043]\n",
      "epoch:10 step:42310[D loss: 0.999973] [G loss: 1.000082]\n",
      "epoch:10 step:42315[D loss: 0.999967] [G loss: 1.000111]\n",
      "epoch:10 step:42320[D loss: 0.999987] [G loss: 1.000021]\n",
      "epoch:10 step:42325[D loss: 1.000039] [G loss: 1.000041]\n",
      "epoch:10 step:42330[D loss: 0.999972] [G loss: 1.000081]\n",
      "epoch:10 step:42335[D loss: 0.999960] [G loss: 1.000126]\n",
      "epoch:10 step:42340[D loss: 0.999942] [G loss: 1.000171]\n",
      "epoch:10 step:42345[D loss: 0.999961] [G loss: 1.000107]\n",
      "epoch:10 step:42350[D loss: 0.999980] [G loss: 1.000034]\n",
      "epoch:10 step:42355[D loss: 0.999970] [G loss: 1.000079]\n",
      "epoch:10 step:42360[D loss: 0.999968] [G loss: 1.000083]\n",
      "epoch:10 step:42365[D loss: 0.999984] [G loss: 1.000063]\n",
      "epoch:10 step:42370[D loss: 0.999960] [G loss: 1.000068]\n",
      "epoch:10 step:42375[D loss: 0.999994] [G loss: 1.000023]\n",
      "epoch:10 step:42380[D loss: 0.999897] [G loss: 1.000181]\n",
      "epoch:10 step:42385[D loss: 0.999971] [G loss: 1.000062]\n",
      "epoch:10 step:42390[D loss: 0.999969] [G loss: 1.000070]\n",
      "epoch:10 step:42395[D loss: 0.999974] [G loss: 1.000077]\n",
      "epoch:10 step:42400[D loss: 0.999962] [G loss: 1.000075]\n",
      "##############\n",
      "[0.86217368 0.8517097  0.83361855 0.82417787 0.8268804  0.84248712\n",
      " 0.89314476 0.84621644 0.80348741 0.81485295]\n",
      "##########\n",
      "epoch:10 step:42405[D loss: 1.000006] [G loss: 1.000006]\n",
      "epoch:10 step:42410[D loss: 0.999959] [G loss: 1.000056]\n",
      "epoch:10 step:42415[D loss: 0.999993] [G loss: 1.000015]\n",
      "epoch:10 step:42420[D loss: 0.999957] [G loss: 1.000054]\n",
      "epoch:10 step:42425[D loss: 0.999957] [G loss: 1.000087]\n",
      "epoch:10 step:42430[D loss: 0.999976] [G loss: 1.000072]\n",
      "epoch:10 step:42435[D loss: 0.999997] [G loss: 1.000035]\n",
      "epoch:10 step:42440[D loss: 0.999983] [G loss: 1.000015]\n",
      "epoch:10 step:42445[D loss: 0.999959] [G loss: 1.000057]\n",
      "epoch:10 step:42450[D loss: 0.999988] [G loss: 1.000035]\n",
      "epoch:10 step:42455[D loss: 0.999989] [G loss: 1.000046]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:10 step:42460[D loss: 0.999985] [G loss: 1.000038]\n",
      "epoch:10 step:42465[D loss: 0.999961] [G loss: 1.000060]\n",
      "epoch:10 step:42470[D loss: 0.999955] [G loss: 1.000066]\n",
      "epoch:10 step:42475[D loss: 0.999972] [G loss: 1.000040]\n",
      "epoch:10 step:42480[D loss: 0.999999] [G loss: 1.000043]\n",
      "epoch:10 step:42485[D loss: 0.999970] [G loss: 1.000077]\n",
      "epoch:10 step:42490[D loss: 1.000011] [G loss: 0.999969]\n",
      "epoch:10 step:42495[D loss: 0.999985] [G loss: 1.000116]\n",
      "epoch:10 step:42500[D loss: 0.999951] [G loss: 1.000073]\n",
      "epoch:10 step:42505[D loss: 0.999971] [G loss: 1.000067]\n",
      "epoch:10 step:42510[D loss: 1.000010] [G loss: 1.000020]\n",
      "epoch:10 step:42515[D loss: 0.999997] [G loss: 1.000056]\n",
      "epoch:10 step:42520[D loss: 0.999974] [G loss: 1.000083]\n",
      "epoch:10 step:42525[D loss: 1.000021] [G loss: 1.000050]\n",
      "epoch:10 step:42530[D loss: 0.999955] [G loss: 1.000103]\n",
      "epoch:10 step:42535[D loss: 0.999943] [G loss: 1.000107]\n",
      "epoch:10 step:42540[D loss: 0.999985] [G loss: 1.000086]\n",
      "epoch:10 step:42545[D loss: 0.999977] [G loss: 1.000169]\n",
      "epoch:10 step:42550[D loss: 0.999984] [G loss: 1.000076]\n",
      "epoch:10 step:42555[D loss: 0.999985] [G loss: 1.000052]\n",
      "epoch:10 step:42560[D loss: 0.999971] [G loss: 1.000030]\n",
      "epoch:10 step:42565[D loss: 0.999975] [G loss: 1.000087]\n",
      "epoch:10 step:42570[D loss: 0.999988] [G loss: 1.000062]\n",
      "epoch:10 step:42575[D loss: 0.999970] [G loss: 1.000111]\n",
      "epoch:10 step:42580[D loss: 0.999960] [G loss: 1.000153]\n",
      "epoch:10 step:42585[D loss: 1.000043] [G loss: 0.999969]\n",
      "epoch:10 step:42590[D loss: 0.999941] [G loss: 1.000103]\n",
      "epoch:10 step:42595[D loss: 0.999977] [G loss: 1.000072]\n",
      "epoch:10 step:42600[D loss: 0.999973] [G loss: 1.000093]\n",
      "##############\n",
      "[0.87066185 0.86679203 0.82144095 0.83825357 0.79221218 0.85581166\n",
      " 0.88838114 0.86046194 0.81088612 0.84779336]\n",
      "##########\n",
      "epoch:10 step:42605[D loss: 0.999963] [G loss: 1.000071]\n",
      "epoch:10 step:42610[D loss: 0.999971] [G loss: 1.000094]\n",
      "epoch:10 step:42615[D loss: 0.999978] [G loss: 1.000051]\n",
      "epoch:10 step:42620[D loss: 0.999963] [G loss: 1.000068]\n",
      "epoch:10 step:42625[D loss: 0.999987] [G loss: 1.000075]\n",
      "epoch:10 step:42630[D loss: 0.999972] [G loss: 1.000061]\n",
      "epoch:10 step:42635[D loss: 0.999982] [G loss: 1.000026]\n",
      "epoch:10 step:42640[D loss: 0.999984] [G loss: 1.000046]\n",
      "epoch:10 step:42645[D loss: 0.999995] [G loss: 1.000052]\n",
      "epoch:10 step:42650[D loss: 0.999985] [G loss: 1.000001]\n",
      "epoch:10 step:42655[D loss: 0.999984] [G loss: 1.000056]\n",
      "epoch:10 step:42660[D loss: 0.999973] [G loss: 1.000046]\n",
      "epoch:10 step:42665[D loss: 1.000007] [G loss: 0.999993]\n",
      "epoch:10 step:42670[D loss: 0.999973] [G loss: 1.000054]\n",
      "epoch:10 step:42675[D loss: 0.999985] [G loss: 1.000051]\n",
      "epoch:10 step:42680[D loss: 0.999949] [G loss: 1.000141]\n",
      "epoch:10 step:42685[D loss: 0.999956] [G loss: 1.000063]\n",
      "epoch:10 step:42690[D loss: 0.999971] [G loss: 1.000109]\n",
      "epoch:10 step:42695[D loss: 0.999946] [G loss: 1.000109]\n",
      "epoch:10 step:42700[D loss: 0.999991] [G loss: 1.000014]\n",
      "epoch:10 step:42705[D loss: 1.000014] [G loss: 1.000013]\n",
      "epoch:10 step:42710[D loss: 0.999994] [G loss: 1.000010]\n",
      "epoch:10 step:42715[D loss: 0.999962] [G loss: 1.000070]\n",
      "epoch:10 step:42720[D loss: 0.999979] [G loss: 1.000079]\n",
      "epoch:10 step:42725[D loss: 0.999962] [G loss: 1.000079]\n",
      "epoch:10 step:42730[D loss: 0.999982] [G loss: 1.000058]\n",
      "epoch:10 step:42735[D loss: 0.999955] [G loss: 1.000102]\n",
      "epoch:10 step:42740[D loss: 0.999984] [G loss: 1.000040]\n",
      "epoch:10 step:42745[D loss: 0.999985] [G loss: 1.000104]\n",
      "epoch:10 step:42750[D loss: 0.999978] [G loss: 1.000072]\n",
      "epoch:10 step:42755[D loss: 0.999976] [G loss: 1.000066]\n",
      "epoch:10 step:42760[D loss: 1.000026] [G loss: 1.000006]\n",
      "epoch:10 step:42765[D loss: 0.999960] [G loss: 1.000065]\n",
      "epoch:10 step:42770[D loss: 0.999965] [G loss: 1.000074]\n",
      "epoch:10 step:42775[D loss: 0.999976] [G loss: 1.000066]\n",
      "epoch:10 step:42780[D loss: 0.999980] [G loss: 1.000052]\n",
      "epoch:10 step:42785[D loss: 0.999979] [G loss: 1.000089]\n",
      "epoch:10 step:42790[D loss: 0.999971] [G loss: 1.000075]\n",
      "epoch:10 step:42795[D loss: 0.999946] [G loss: 1.000114]\n",
      "epoch:10 step:42800[D loss: 0.999985] [G loss: 1.000045]\n",
      "##############\n",
      "[0.87730753 0.85432087 0.84529219 0.82688848 0.78632606 0.85222317\n",
      " 0.88199878 0.82592721 0.81583225 0.84405859]\n",
      "##########\n",
      "epoch:10 step:42805[D loss: 1.000016] [G loss: 1.000058]\n",
      "epoch:10 step:42810[D loss: 0.999970] [G loss: 1.000067]\n",
      "epoch:10 step:42815[D loss: 0.999976] [G loss: 1.000068]\n",
      "epoch:10 step:42820[D loss: 0.999996] [G loss: 1.000033]\n",
      "epoch:10 step:42825[D loss: 0.999965] [G loss: 1.000072]\n",
      "epoch:10 step:42830[D loss: 0.999979] [G loss: 1.000058]\n",
      "epoch:10 step:42835[D loss: 0.999951] [G loss: 1.000076]\n",
      "epoch:10 step:42840[D loss: 0.999980] [G loss: 1.000061]\n",
      "epoch:10 step:42845[D loss: 0.999974] [G loss: 1.000064]\n",
      "epoch:10 step:42850[D loss: 0.999994] [G loss: 1.000025]\n",
      "epoch:10 step:42855[D loss: 0.999966] [G loss: 1.000061]\n",
      "epoch:10 step:42860[D loss: 0.999991] [G loss: 1.000054]\n",
      "epoch:10 step:42865[D loss: 0.999952] [G loss: 1.000086]\n",
      "epoch:10 step:42870[D loss: 1.000080] [G loss: 0.999869]\n",
      "epoch:10 step:42875[D loss: 0.999975] [G loss: 1.000027]\n",
      "epoch:10 step:42880[D loss: 0.999974] [G loss: 1.000024]\n",
      "epoch:10 step:42885[D loss: 0.999985] [G loss: 1.000031]\n",
      "epoch:10 step:42890[D loss: 0.999974] [G loss: 1.000046]\n",
      "epoch:10 step:42895[D loss: 1.000033] [G loss: 0.999980]\n",
      "epoch:10 step:42900[D loss: 1.000040] [G loss: 0.999975]\n",
      "epoch:10 step:42905[D loss: 0.999930] [G loss: 1.000105]\n",
      "epoch:10 step:42910[D loss: 1.000022] [G loss: 1.000088]\n",
      "epoch:10 step:42915[D loss: 1.000033] [G loss: 0.999944]\n",
      "epoch:10 step:42920[D loss: 0.999999] [G loss: 1.000159]\n",
      "epoch:10 step:42925[D loss: 0.999947] [G loss: 1.000130]\n",
      "epoch:10 step:42930[D loss: 0.999993] [G loss: 1.000044]\n",
      "epoch:10 step:42935[D loss: 1.000100] [G loss: 0.999893]\n",
      "epoch:10 step:42940[D loss: 0.999990] [G loss: 1.000026]\n",
      "epoch:10 step:42945[D loss: 0.999889] [G loss: 1.000071]\n",
      "epoch:10 step:42950[D loss: 0.999947] [G loss: 1.000120]\n",
      "epoch:10 step:42955[D loss: 0.999969] [G loss: 1.000102]\n",
      "epoch:11 step:42960[D loss: 0.999973] [G loss: 1.000078]\n",
      "epoch:11 step:42965[D loss: 0.999992] [G loss: 1.000021]\n",
      "epoch:11 step:42970[D loss: 1.000013] [G loss: 0.999999]\n",
      "epoch:11 step:42975[D loss: 0.999999] [G loss: 1.000042]\n",
      "epoch:11 step:42980[D loss: 0.999976] [G loss: 1.000103]\n",
      "epoch:11 step:42985[D loss: 0.999974] [G loss: 1.000076]\n",
      "epoch:11 step:42990[D loss: 0.999953] [G loss: 1.000095]\n",
      "epoch:11 step:42995[D loss: 0.999994] [G loss: 1.000060]\n",
      "epoch:11 step:43000[D loss: 0.999973] [G loss: 1.000063]\n",
      "##############\n",
      "[0.86442342 0.84177569 0.84678451 0.82324528 0.80417254 0.84008398\n",
      " 0.88442023 0.86707286 0.79909353 0.86904586]\n",
      "##########\n",
      "epoch:11 step:43005[D loss: 0.999963] [G loss: 1.000092]\n",
      "epoch:11 step:43010[D loss: 0.999988] [G loss: 1.000054]\n",
      "epoch:11 step:43015[D loss: 0.999967] [G loss: 1.000073]\n",
      "epoch:11 step:43020[D loss: 0.999978] [G loss: 1.000072]\n",
      "epoch:11 step:43025[D loss: 0.999967] [G loss: 1.000053]\n",
      "epoch:11 step:43030[D loss: 0.999984] [G loss: 1.000054]\n",
      "epoch:11 step:43035[D loss: 0.999984] [G loss: 1.000059]\n",
      "epoch:11 step:43040[D loss: 0.999995] [G loss: 1.000075]\n",
      "epoch:11 step:43045[D loss: 0.999934] [G loss: 1.000169]\n",
      "epoch:11 step:43050[D loss: 0.999978] [G loss: 1.000061]\n",
      "epoch:11 step:43055[D loss: 0.999973] [G loss: 1.000112]\n",
      "epoch:11 step:43060[D loss: 0.999964] [G loss: 1.000043]\n",
      "epoch:11 step:43065[D loss: 0.999972] [G loss: 1.000062]\n",
      "epoch:11 step:43070[D loss: 0.999973] [G loss: 1.000067]\n",
      "epoch:11 step:43075[D loss: 1.000124] [G loss: 1.000030]\n",
      "epoch:11 step:43080[D loss: 0.999906] [G loss: 1.000148]\n",
      "epoch:11 step:43085[D loss: 1.000079] [G loss: 0.999878]\n",
      "epoch:11 step:43090[D loss: 0.999907] [G loss: 1.000238]\n",
      "epoch:11 step:43095[D loss: 0.999913] [G loss: 1.000176]\n",
      "epoch:11 step:43100[D loss: 0.999982] [G loss: 1.000049]\n",
      "epoch:11 step:43105[D loss: 1.000029] [G loss: 0.999924]\n",
      "epoch:11 step:43110[D loss: 0.999965] [G loss: 0.999999]\n",
      "epoch:11 step:43115[D loss: 1.000043] [G loss: 0.999955]\n",
      "epoch:11 step:43120[D loss: 0.999972] [G loss: 1.000006]\n",
      "epoch:11 step:43125[D loss: 0.999981] [G loss: 1.000029]\n",
      "epoch:11 step:43130[D loss: 0.999894] [G loss: 1.000205]\n",
      "epoch:11 step:43135[D loss: 0.999971] [G loss: 1.000108]\n",
      "epoch:11 step:43140[D loss: 0.999989] [G loss: 1.000055]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:11 step:43145[D loss: 0.999937] [G loss: 1.000106]\n",
      "epoch:11 step:43150[D loss: 0.999971] [G loss: 1.000055]\n",
      "epoch:11 step:43155[D loss: 0.999976] [G loss: 1.000064]\n",
      "epoch:11 step:43160[D loss: 0.999989] [G loss: 1.000060]\n",
      "epoch:11 step:43165[D loss: 0.999986] [G loss: 1.000060]\n",
      "epoch:11 step:43170[D loss: 0.999982] [G loss: 1.000037]\n",
      "epoch:11 step:43175[D loss: 0.999988] [G loss: 1.000048]\n",
      "epoch:11 step:43180[D loss: 0.999986] [G loss: 1.000076]\n",
      "epoch:11 step:43185[D loss: 0.999973] [G loss: 1.000087]\n",
      "epoch:11 step:43190[D loss: 0.999969] [G loss: 1.000071]\n",
      "epoch:11 step:43195[D loss: 0.999983] [G loss: 1.000068]\n",
      "epoch:11 step:43200[D loss: 1.000013] [G loss: 1.000080]\n",
      "##############\n",
      "[0.86500472 0.87156265 0.8536324  0.82430691 0.79692985 0.83758644\n",
      " 0.88027026 0.85731216 0.80603221 0.84840664]\n",
      "##########\n",
      "epoch:11 step:43205[D loss: 0.999958] [G loss: 1.000113]\n",
      "epoch:11 step:43210[D loss: 0.999967] [G loss: 1.000099]\n",
      "epoch:11 step:43215[D loss: 0.999961] [G loss: 1.000071]\n",
      "epoch:11 step:43220[D loss: 0.999966] [G loss: 1.000105]\n",
      "epoch:11 step:43225[D loss: 0.999973] [G loss: 1.000084]\n",
      "epoch:11 step:43230[D loss: 0.999981] [G loss: 1.000066]\n",
      "epoch:11 step:43235[D loss: 0.999963] [G loss: 1.000091]\n",
      "epoch:11 step:43240[D loss: 0.999974] [G loss: 1.000055]\n",
      "epoch:11 step:43245[D loss: 0.999962] [G loss: 1.000060]\n",
      "epoch:11 step:43250[D loss: 0.999961] [G loss: 1.000065]\n",
      "epoch:11 step:43255[D loss: 1.000016] [G loss: 0.999991]\n",
      "epoch:11 step:43260[D loss: 1.000025] [G loss: 1.000024]\n",
      "epoch:11 step:43265[D loss: 0.999941] [G loss: 1.000110]\n",
      "epoch:11 step:43270[D loss: 0.999960] [G loss: 1.000090]\n",
      "epoch:11 step:43275[D loss: 0.999985] [G loss: 1.000032]\n",
      "epoch:11 step:43280[D loss: 0.999960] [G loss: 1.000059]\n",
      "epoch:11 step:43285[D loss: 0.999988] [G loss: 1.000059]\n",
      "epoch:11 step:43290[D loss: 0.999975] [G loss: 1.000053]\n",
      "epoch:11 step:43295[D loss: 0.999971] [G loss: 1.000066]\n",
      "epoch:11 step:43300[D loss: 1.000014] [G loss: 1.000029]\n",
      "epoch:11 step:43305[D loss: 0.999972] [G loss: 1.000042]\n",
      "epoch:11 step:43310[D loss: 0.999993] [G loss: 1.000066]\n",
      "epoch:11 step:43315[D loss: 0.999985] [G loss: 1.000056]\n",
      "epoch:11 step:43320[D loss: 0.999989] [G loss: 1.000056]\n",
      "epoch:11 step:43325[D loss: 0.999976] [G loss: 1.000079]\n",
      "epoch:11 step:43330[D loss: 0.999972] [G loss: 1.000064]\n",
      "epoch:11 step:43335[D loss: 0.999963] [G loss: 1.000061]\n",
      "epoch:11 step:43340[D loss: 0.999984] [G loss: 1.000102]\n",
      "epoch:11 step:43345[D loss: 0.999965] [G loss: 1.000124]\n",
      "epoch:11 step:43350[D loss: 0.999970] [G loss: 1.000043]\n",
      "epoch:11 step:43355[D loss: 0.999958] [G loss: 1.000079]\n",
      "epoch:11 step:43360[D loss: 0.999989] [G loss: 1.000009]\n",
      "epoch:11 step:43365[D loss: 1.000014] [G loss: 0.999998]\n",
      "epoch:11 step:43370[D loss: 0.999985] [G loss: 1.000021]\n",
      "epoch:11 step:43375[D loss: 0.999964] [G loss: 1.000062]\n",
      "epoch:11 step:43380[D loss: 0.999972] [G loss: 1.000045]\n",
      "epoch:11 step:43385[D loss: 0.999954] [G loss: 1.000078]\n",
      "epoch:11 step:43390[D loss: 0.999977] [G loss: 1.000059]\n",
      "epoch:11 step:43395[D loss: 1.000007] [G loss: 0.999992]\n",
      "epoch:11 step:43400[D loss: 1.000022] [G loss: 1.000091]\n",
      "##############\n",
      "[0.86732204 0.85822074 0.83794381 0.82484637 0.81502759 0.84156273\n",
      " 0.87231912 0.83689719 0.8080865  0.84819352]\n",
      "##########\n",
      "epoch:11 step:43405[D loss: 0.999960] [G loss: 1.000090]\n",
      "epoch:11 step:43410[D loss: 0.999940] [G loss: 1.000157]\n",
      "epoch:11 step:43415[D loss: 0.999958] [G loss: 1.000079]\n",
      "epoch:11 step:43420[D loss: 1.000013] [G loss: 1.000018]\n",
      "epoch:11 step:43425[D loss: 0.999994] [G loss: 1.000066]\n",
      "epoch:11 step:43430[D loss: 0.999966] [G loss: 1.000052]\n",
      "epoch:11 step:43435[D loss: 1.000055] [G loss: 0.999955]\n",
      "epoch:11 step:43440[D loss: 0.999952] [G loss: 1.000038]\n",
      "epoch:11 step:43445[D loss: 0.999965] [G loss: 1.000174]\n",
      "epoch:11 step:43450[D loss: 0.999960] [G loss: 1.000219]\n",
      "epoch:11 step:43455[D loss: 0.999899] [G loss: 1.000206]\n",
      "epoch:11 step:43460[D loss: 0.999974] [G loss: 1.000061]\n",
      "epoch:11 step:43465[D loss: 0.999983] [G loss: 0.999993]\n",
      "epoch:11 step:43470[D loss: 1.000024] [G loss: 0.999942]\n",
      "epoch:11 step:43475[D loss: 1.000040] [G loss: 1.000012]\n",
      "epoch:11 step:43480[D loss: 1.000066] [G loss: 0.999962]\n",
      "epoch:11 step:43485[D loss: 1.000017] [G loss: 0.999925]\n",
      "epoch:11 step:43490[D loss: 1.000096] [G loss: 0.999904]\n",
      "epoch:11 step:43495[D loss: 0.999926] [G loss: 1.000292]\n",
      "epoch:11 step:43500[D loss: 0.999864] [G loss: 1.000265]\n",
      "epoch:11 step:43505[D loss: 0.999852] [G loss: 1.000318]\n",
      "epoch:11 step:43510[D loss: 0.999977] [G loss: 1.000064]\n",
      "epoch:11 step:43515[D loss: 0.999985] [G loss: 1.000048]\n",
      "epoch:11 step:43520[D loss: 0.999990] [G loss: 1.000010]\n",
      "epoch:11 step:43525[D loss: 0.999988] [G loss: 1.000028]\n",
      "epoch:11 step:43530[D loss: 1.000039] [G loss: 0.999965]\n",
      "epoch:11 step:43535[D loss: 0.999967] [G loss: 1.000003]\n",
      "epoch:11 step:43540[D loss: 1.000087] [G loss: 0.999905]\n",
      "epoch:11 step:43545[D loss: 0.999889] [G loss: 1.000197]\n",
      "epoch:11 step:43550[D loss: 0.999959] [G loss: 1.000137]\n",
      "epoch:11 step:43555[D loss: 0.999962] [G loss: 1.000137]\n",
      "epoch:11 step:43560[D loss: 0.999953] [G loss: 1.000134]\n",
      "epoch:11 step:43565[D loss: 0.999990] [G loss: 1.000085]\n",
      "epoch:11 step:43570[D loss: 0.999972] [G loss: 1.000095]\n",
      "epoch:11 step:43575[D loss: 0.999966] [G loss: 1.000095]\n",
      "epoch:11 step:43580[D loss: 0.999968] [G loss: 1.000108]\n",
      "epoch:11 step:43585[D loss: 0.999967] [G loss: 1.000084]\n",
      "epoch:11 step:43590[D loss: 0.999977] [G loss: 1.000090]\n",
      "epoch:11 step:43595[D loss: 0.999968] [G loss: 1.000093]\n",
      "epoch:11 step:43600[D loss: 0.999985] [G loss: 1.000060]\n",
      "##############\n",
      "[0.87944992 0.88849256 0.84413448 0.8256711  0.81583305 0.83669102\n",
      " 0.8848289  0.84951976 0.78712193 0.85322789]\n",
      "##########\n",
      "epoch:11 step:43605[D loss: 1.000012] [G loss: 0.999982]\n",
      "epoch:11 step:43610[D loss: 1.000042] [G loss: 1.000050]\n",
      "epoch:11 step:43615[D loss: 0.999917] [G loss: 1.000080]\n",
      "epoch:11 step:43620[D loss: 0.999976] [G loss: 1.000076]\n",
      "epoch:11 step:43625[D loss: 1.000037] [G loss: 1.000049]\n",
      "epoch:11 step:43630[D loss: 0.999971] [G loss: 1.000033]\n",
      "epoch:11 step:43635[D loss: 1.000009] [G loss: 1.000044]\n",
      "epoch:11 step:43640[D loss: 0.999975] [G loss: 1.000046]\n",
      "epoch:11 step:43645[D loss: 0.999985] [G loss: 1.000073]\n",
      "epoch:11 step:43650[D loss: 0.999981] [G loss: 1.000041]\n",
      "epoch:11 step:43655[D loss: 1.000038] [G loss: 0.999973]\n",
      "epoch:11 step:43660[D loss: 1.000000] [G loss: 1.000040]\n",
      "epoch:11 step:43665[D loss: 0.999989] [G loss: 1.000061]\n",
      "epoch:11 step:43670[D loss: 0.999949] [G loss: 1.000090]\n",
      "epoch:11 step:43675[D loss: 0.999959] [G loss: 1.000073]\n",
      "epoch:11 step:43680[D loss: 1.000063] [G loss: 0.999852]\n",
      "epoch:11 step:43685[D loss: 0.999954] [G loss: 1.000012]\n",
      "epoch:11 step:43690[D loss: 0.999997] [G loss: 1.000047]\n",
      "epoch:11 step:43695[D loss: 0.999984] [G loss: 1.000064]\n",
      "epoch:11 step:43700[D loss: 0.999969] [G loss: 1.000084]\n",
      "epoch:11 step:43705[D loss: 0.999969] [G loss: 1.000072]\n",
      "epoch:11 step:43710[D loss: 0.999979] [G loss: 1.000049]\n",
      "epoch:11 step:43715[D loss: 1.000039] [G loss: 0.999966]\n",
      "epoch:11 step:43720[D loss: 0.999977] [G loss: 1.000048]\n",
      "epoch:11 step:43725[D loss: 0.999990] [G loss: 1.000036]\n",
      "epoch:11 step:43730[D loss: 0.999974] [G loss: 1.000038]\n",
      "epoch:11 step:43735[D loss: 0.999946] [G loss: 1.000072]\n",
      "epoch:11 step:43740[D loss: 0.999995] [G loss: 1.000039]\n",
      "epoch:11 step:43745[D loss: 0.999991] [G loss: 1.000002]\n",
      "epoch:11 step:43750[D loss: 1.000050] [G loss: 0.999975]\n",
      "epoch:11 step:43755[D loss: 0.999934] [G loss: 1.000150]\n",
      "epoch:11 step:43760[D loss: 0.999961] [G loss: 1.000045]\n",
      "epoch:11 step:43765[D loss: 0.999969] [G loss: 1.000066]\n",
      "epoch:11 step:43770[D loss: 0.999991] [G loss: 1.000044]\n",
      "epoch:11 step:43775[D loss: 0.999975] [G loss: 1.000075]\n",
      "epoch:11 step:43780[D loss: 0.999978] [G loss: 1.000040]\n",
      "epoch:11 step:43785[D loss: 0.999979] [G loss: 1.000050]\n",
      "epoch:11 step:43790[D loss: 0.999975] [G loss: 1.000068]\n",
      "epoch:11 step:43795[D loss: 0.999959] [G loss: 1.000077]\n",
      "epoch:11 step:43800[D loss: 0.999971] [G loss: 1.000058]\n",
      "##############\n",
      "[0.87146382 0.86131926 0.83864668 0.83628225 0.79766629 0.84851813\n",
      " 0.90166485 0.84418113 0.81922285 0.81789198]\n",
      "##########\n",
      "epoch:11 step:43805[D loss: 0.999983] [G loss: 1.000074]\n",
      "epoch:11 step:43810[D loss: 1.000000] [G loss: 1.000046]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:11 step:43815[D loss: 0.999966] [G loss: 1.000097]\n",
      "epoch:11 step:43820[D loss: 0.999974] [G loss: 1.000043]\n",
      "epoch:11 step:43825[D loss: 1.000020] [G loss: 0.999966]\n",
      "epoch:11 step:43830[D loss: 1.000010] [G loss: 0.999991]\n",
      "epoch:11 step:43835[D loss: 1.000108] [G loss: 0.999854]\n",
      "epoch:11 step:43840[D loss: 0.999905] [G loss: 1.000135]\n",
      "epoch:11 step:43845[D loss: 0.999960] [G loss: 1.000090]\n",
      "epoch:11 step:43850[D loss: 0.999991] [G loss: 1.000089]\n",
      "epoch:11 step:43855[D loss: 0.999980] [G loss: 1.000086]\n",
      "epoch:11 step:43860[D loss: 0.999985] [G loss: 1.000040]\n",
      "epoch:11 step:43865[D loss: 1.000002] [G loss: 1.000045]\n",
      "epoch:11 step:43870[D loss: 1.000021] [G loss: 1.000088]\n",
      "epoch:11 step:43875[D loss: 0.999944] [G loss: 1.000088]\n",
      "epoch:11 step:43880[D loss: 1.000013] [G loss: 1.000045]\n",
      "epoch:11 step:43885[D loss: 0.999972] [G loss: 1.000038]\n",
      "epoch:11 step:43890[D loss: 0.999941] [G loss: 1.000105]\n",
      "epoch:11 step:43895[D loss: 1.000088] [G loss: 0.999911]\n",
      "epoch:11 step:43900[D loss: 0.999910] [G loss: 1.000116]\n",
      "epoch:11 step:43905[D loss: 1.000057] [G loss: 0.999976]\n",
      "epoch:11 step:43910[D loss: 0.999939] [G loss: 1.000046]\n",
      "epoch:11 step:43915[D loss: 0.999957] [G loss: 1.000088]\n",
      "epoch:11 step:43920[D loss: 0.999976] [G loss: 1.000061]\n",
      "epoch:11 step:43925[D loss: 0.999985] [G loss: 1.000067]\n",
      "epoch:11 step:43930[D loss: 0.999990] [G loss: 1.000073]\n",
      "epoch:11 step:43935[D loss: 0.999987] [G loss: 1.000077]\n",
      "epoch:11 step:43940[D loss: 1.000060] [G loss: 0.999994]\n",
      "epoch:11 step:43945[D loss: 0.999925] [G loss: 1.000143]\n",
      "epoch:11 step:43950[D loss: 0.999954] [G loss: 1.000061]\n",
      "epoch:11 step:43955[D loss: 0.999968] [G loss: 1.000071]\n",
      "epoch:11 step:43960[D loss: 0.999978] [G loss: 1.000096]\n",
      "epoch:11 step:43965[D loss: 0.999970] [G loss: 1.000095]\n",
      "epoch:11 step:43970[D loss: 0.999985] [G loss: 1.000061]\n",
      "epoch:11 step:43975[D loss: 0.999988] [G loss: 1.000059]\n",
      "epoch:11 step:43980[D loss: 0.999968] [G loss: 1.000077]\n",
      "epoch:11 step:43985[D loss: 0.999976] [G loss: 1.000062]\n",
      "epoch:11 step:43990[D loss: 0.999970] [G loss: 1.000076]\n",
      "epoch:11 step:43995[D loss: 0.999975] [G loss: 1.000051]\n",
      "epoch:11 step:44000[D loss: 0.999981] [G loss: 1.000058]\n",
      "##############\n",
      "[0.86888682 0.86240507 0.80715033 0.81871054 0.81298815 0.83557175\n",
      " 0.88238105 0.82277429 0.81838851 0.8435647 ]\n",
      "##########\n",
      "epoch:11 step:44005[D loss: 0.999982] [G loss: 1.000042]\n",
      "epoch:11 step:44010[D loss: 0.999986] [G loss: 1.000012]\n",
      "epoch:11 step:44015[D loss: 0.999960] [G loss: 1.000064]\n",
      "epoch:11 step:44020[D loss: 0.999994] [G loss: 1.000021]\n",
      "epoch:11 step:44025[D loss: 0.999988] [G loss: 1.000006]\n",
      "epoch:11 step:44030[D loss: 0.999945] [G loss: 1.000075]\n",
      "epoch:11 step:44035[D loss: 0.999979] [G loss: 1.000052]\n",
      "epoch:11 step:44040[D loss: 0.999968] [G loss: 1.000068]\n",
      "epoch:11 step:44045[D loss: 1.000029] [G loss: 1.000001]\n",
      "epoch:11 step:44050[D loss: 0.999950] [G loss: 1.000124]\n",
      "epoch:11 step:44055[D loss: 0.999977] [G loss: 1.000059]\n",
      "epoch:11 step:44060[D loss: 0.999953] [G loss: 1.000115]\n",
      "epoch:11 step:44065[D loss: 0.999999] [G loss: 1.000024]\n",
      "epoch:11 step:44070[D loss: 1.000022] [G loss: 0.999962]\n",
      "epoch:11 step:44075[D loss: 1.000107] [G loss: 0.999821]\n",
      "epoch:11 step:44080[D loss: 1.000042] [G loss: 0.999914]\n",
      "epoch:11 step:44085[D loss: 1.000006] [G loss: 1.000080]\n",
      "epoch:11 step:44090[D loss: 0.999977] [G loss: 1.000093]\n",
      "epoch:11 step:44095[D loss: 0.999959] [G loss: 1.000150]\n",
      "epoch:11 step:44100[D loss: 0.999966] [G loss: 1.000086]\n",
      "epoch:11 step:44105[D loss: 0.999995] [G loss: 1.000072]\n",
      "epoch:11 step:44110[D loss: 1.000020] [G loss: 1.000019]\n",
      "epoch:11 step:44115[D loss: 1.000008] [G loss: 1.000069]\n",
      "epoch:11 step:44120[D loss: 0.999979] [G loss: 1.000074]\n",
      "epoch:11 step:44125[D loss: 0.999924] [G loss: 1.000167]\n",
      "epoch:11 step:44130[D loss: 1.000016] [G loss: 1.000054]\n",
      "epoch:11 step:44135[D loss: 0.999957] [G loss: 1.000159]\n",
      "epoch:11 step:44140[D loss: 1.000006] [G loss: 1.000075]\n",
      "epoch:11 step:44145[D loss: 0.999934] [G loss: 1.000119]\n",
      "epoch:11 step:44150[D loss: 0.999967] [G loss: 1.000094]\n",
      "epoch:11 step:44155[D loss: 0.999962] [G loss: 1.000093]\n",
      "epoch:11 step:44160[D loss: 0.999965] [G loss: 1.000086]\n",
      "epoch:11 step:44165[D loss: 0.999990] [G loss: 1.000022]\n",
      "epoch:11 step:44170[D loss: 1.000005] [G loss: 1.000080]\n",
      "epoch:11 step:44175[D loss: 0.999990] [G loss: 1.000129]\n",
      "epoch:11 step:44180[D loss: 0.999990] [G loss: 1.000102]\n",
      "epoch:11 step:44185[D loss: 0.999926] [G loss: 1.000179]\n",
      "epoch:11 step:44190[D loss: 0.999976] [G loss: 1.000104]\n",
      "epoch:11 step:44195[D loss: 0.999964] [G loss: 1.000073]\n",
      "epoch:11 step:44200[D loss: 1.000001] [G loss: 1.000006]\n",
      "##############\n",
      "[0.88341228 0.86946443 0.83835966 0.82892394 0.81528613 0.83793058\n",
      " 0.87850554 0.83562852 0.84448471 0.8442201 ]\n",
      "##########\n",
      "epoch:11 step:44205[D loss: 1.000006] [G loss: 1.000047]\n",
      "epoch:11 step:44210[D loss: 0.999935] [G loss: 1.000052]\n",
      "epoch:11 step:44215[D loss: 0.999958] [G loss: 1.000062]\n",
      "epoch:11 step:44220[D loss: 0.999978] [G loss: 1.000065]\n",
      "epoch:11 step:44225[D loss: 0.999978] [G loss: 1.000048]\n",
      "epoch:11 step:44230[D loss: 0.999941] [G loss: 1.000119]\n",
      "epoch:11 step:44235[D loss: 0.999974] [G loss: 1.000063]\n",
      "epoch:11 step:44240[D loss: 0.999963] [G loss: 1.000026]\n",
      "epoch:11 step:44245[D loss: 1.000013] [G loss: 1.000002]\n",
      "epoch:11 step:44250[D loss: 0.999968] [G loss: 1.000088]\n",
      "epoch:11 step:44255[D loss: 0.999956] [G loss: 1.000092]\n",
      "epoch:11 step:44260[D loss: 0.999990] [G loss: 1.000012]\n",
      "epoch:11 step:44265[D loss: 1.000006] [G loss: 0.999974]\n",
      "epoch:11 step:44270[D loss: 0.999988] [G loss: 0.999967]\n",
      "epoch:11 step:44275[D loss: 0.999994] [G loss: 1.000028]\n",
      "epoch:11 step:44280[D loss: 1.000015] [G loss: 0.999973]\n",
      "epoch:11 step:44285[D loss: 0.999915] [G loss: 1.000100]\n",
      "epoch:11 step:44290[D loss: 0.999965] [G loss: 1.000108]\n",
      "epoch:11 step:44295[D loss: 1.000001] [G loss: 0.999997]\n",
      "epoch:11 step:44300[D loss: 0.999993] [G loss: 1.000025]\n",
      "epoch:11 step:44305[D loss: 0.999961] [G loss: 1.000071]\n",
      "epoch:11 step:44310[D loss: 0.999990] [G loss: 1.000060]\n",
      "epoch:11 step:44315[D loss: 1.000009] [G loss: 1.000009]\n",
      "epoch:11 step:44320[D loss: 1.000065] [G loss: 0.999990]\n",
      "epoch:11 step:44325[D loss: 1.000001] [G loss: 1.000074]\n",
      "epoch:11 step:44330[D loss: 0.999933] [G loss: 1.000134]\n",
      "epoch:11 step:44335[D loss: 0.999966] [G loss: 1.000108]\n",
      "epoch:11 step:44340[D loss: 0.999975] [G loss: 1.000093]\n",
      "epoch:11 step:44345[D loss: 0.999992] [G loss: 1.000083]\n",
      "epoch:11 step:44350[D loss: 0.999974] [G loss: 1.000047]\n",
      "epoch:11 step:44355[D loss: 1.000001] [G loss: 1.000061]\n",
      "epoch:11 step:44360[D loss: 0.999952] [G loss: 1.000119]\n",
      "epoch:11 step:44365[D loss: 0.999991] [G loss: 1.000136]\n",
      "epoch:11 step:44370[D loss: 0.999977] [G loss: 1.000146]\n",
      "epoch:11 step:44375[D loss: 0.999953] [G loss: 1.000064]\n",
      "epoch:11 step:44380[D loss: 1.000023] [G loss: 1.000044]\n",
      "epoch:11 step:44385[D loss: 1.000015] [G loss: 1.000039]\n",
      "epoch:11 step:44390[D loss: 0.999964] [G loss: 1.000093]\n",
      "epoch:11 step:44395[D loss: 0.999969] [G loss: 1.000054]\n",
      "epoch:11 step:44400[D loss: 0.999950] [G loss: 1.000080]\n",
      "##############\n",
      "[0.86900389 0.85799324 0.81702794 0.85521799 0.79540501 0.84962752\n",
      " 0.87371129 0.82818859 0.82979122 0.84247441]\n",
      "##########\n",
      "epoch:11 step:44405[D loss: 0.999973] [G loss: 1.000132]\n",
      "epoch:11 step:44410[D loss: 0.999936] [G loss: 1.000107]\n",
      "epoch:11 step:44415[D loss: 0.999937] [G loss: 1.000131]\n",
      "epoch:11 step:44420[D loss: 0.999986] [G loss: 1.000059]\n",
      "epoch:11 step:44425[D loss: 0.999953] [G loss: 1.000089]\n",
      "epoch:11 step:44430[D loss: 0.999979] [G loss: 1.000077]\n",
      "epoch:11 step:44435[D loss: 0.999992] [G loss: 1.000030]\n",
      "epoch:11 step:44440[D loss: 1.000003] [G loss: 1.000018]\n",
      "epoch:11 step:44445[D loss: 0.999969] [G loss: 1.000080]\n",
      "epoch:11 step:44450[D loss: 0.999917] [G loss: 1.000222]\n",
      "epoch:11 step:44455[D loss: 0.999939] [G loss: 1.000088]\n",
      "epoch:11 step:44460[D loss: 0.999968] [G loss: 1.000067]\n",
      "epoch:11 step:44465[D loss: 0.999983] [G loss: 1.000069]\n",
      "epoch:11 step:44470[D loss: 0.999970] [G loss: 1.000060]\n",
      "epoch:11 step:44475[D loss: 0.999973] [G loss: 1.000074]\n",
      "epoch:11 step:44480[D loss: 0.999979] [G loss: 1.000072]\n",
      "epoch:11 step:44485[D loss: 0.999957] [G loss: 1.000085]\n",
      "epoch:11 step:44490[D loss: 0.999958] [G loss: 1.000105]\n",
      "epoch:11 step:44495[D loss: 0.999977] [G loss: 1.000074]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:11 step:44500[D loss: 0.999985] [G loss: 1.000063]\n",
      "epoch:11 step:44505[D loss: 1.000000] [G loss: 1.000132]\n",
      "epoch:11 step:44510[D loss: 0.999966] [G loss: 1.000111]\n",
      "epoch:11 step:44515[D loss: 0.999967] [G loss: 1.000090]\n",
      "epoch:11 step:44520[D loss: 0.999977] [G loss: 1.000052]\n",
      "epoch:11 step:44525[D loss: 0.999987] [G loss: 1.000056]\n",
      "epoch:11 step:44530[D loss: 0.999982] [G loss: 1.000125]\n",
      "epoch:11 step:44535[D loss: 0.999983] [G loss: 1.000138]\n",
      "epoch:11 step:44540[D loss: 1.000008] [G loss: 1.000012]\n",
      "epoch:11 step:44545[D loss: 0.999963] [G loss: 1.000108]\n",
      "epoch:11 step:44550[D loss: 1.000006] [G loss: 1.000033]\n",
      "epoch:11 step:44555[D loss: 0.999995] [G loss: 1.000023]\n",
      "epoch:11 step:44560[D loss: 0.999968] [G loss: 1.000090]\n",
      "epoch:11 step:44565[D loss: 0.999944] [G loss: 1.000079]\n",
      "epoch:11 step:44570[D loss: 0.999974] [G loss: 1.000064]\n",
      "epoch:11 step:44575[D loss: 1.000011] [G loss: 1.000090]\n",
      "epoch:11 step:44580[D loss: 1.000039] [G loss: 1.000035]\n",
      "epoch:11 step:44585[D loss: 0.999944] [G loss: 1.000116]\n",
      "epoch:11 step:44590[D loss: 1.000011] [G loss: 1.000078]\n",
      "epoch:11 step:44595[D loss: 1.000001] [G loss: 1.000059]\n",
      "epoch:11 step:44600[D loss: 0.999990] [G loss: 1.000115]\n",
      "##############\n",
      "[0.85579038 0.82660174 0.82098177 0.83175408 0.80998382 0.84226962\n",
      " 0.90393747 0.84510356 0.83378289 0.83793377]\n",
      "##########\n",
      "epoch:11 step:44605[D loss: 0.999953] [G loss: 1.000095]\n",
      "epoch:11 step:44610[D loss: 0.999954] [G loss: 1.000167]\n",
      "epoch:11 step:44615[D loss: 1.000006] [G loss: 1.000104]\n",
      "epoch:11 step:44620[D loss: 0.999940] [G loss: 1.000132]\n",
      "epoch:11 step:44625[D loss: 0.999961] [G loss: 1.000094]\n",
      "epoch:11 step:44630[D loss: 0.999975] [G loss: 1.000109]\n",
      "epoch:11 step:44635[D loss: 0.999956] [G loss: 1.000150]\n",
      "epoch:11 step:44640[D loss: 1.000089] [G loss: 0.999915]\n",
      "epoch:11 step:44645[D loss: 1.000007] [G loss: 1.000086]\n",
      "epoch:11 step:44650[D loss: 0.999918] [G loss: 1.000165]\n",
      "epoch:11 step:44655[D loss: 0.999962] [G loss: 1.000045]\n",
      "epoch:11 step:44660[D loss: 0.999959] [G loss: 1.000084]\n",
      "epoch:11 step:44665[D loss: 0.999983] [G loss: 1.000110]\n",
      "epoch:11 step:44670[D loss: 0.999965] [G loss: 1.000079]\n",
      "epoch:11 step:44675[D loss: 0.999976] [G loss: 1.000034]\n",
      "epoch:11 step:44680[D loss: 1.000003] [G loss: 0.999993]\n",
      "epoch:11 step:44685[D loss: 0.999968] [G loss: 1.000025]\n",
      "epoch:11 step:44690[D loss: 0.999974] [G loss: 1.000033]\n",
      "epoch:11 step:44695[D loss: 0.999945] [G loss: 1.000064]\n",
      "epoch:11 step:44700[D loss: 1.000013] [G loss: 0.999945]\n",
      "epoch:11 step:44705[D loss: 1.000079] [G loss: 0.999924]\n",
      "epoch:11 step:44710[D loss: 1.000026] [G loss: 0.999902]\n",
      "epoch:11 step:44715[D loss: 0.999946] [G loss: 1.000060]\n",
      "epoch:11 step:44720[D loss: 0.999956] [G loss: 1.000029]\n",
      "epoch:11 step:44725[D loss: 0.999955] [G loss: 1.000030]\n",
      "epoch:11 step:44730[D loss: 0.999961] [G loss: 0.999999]\n",
      "epoch:11 step:44735[D loss: 0.999968] [G loss: 1.000033]\n",
      "epoch:11 step:44740[D loss: 0.999997] [G loss: 0.999995]\n",
      "epoch:11 step:44745[D loss: 0.999986] [G loss: 1.000014]\n",
      "epoch:11 step:44750[D loss: 0.999932] [G loss: 1.000097]\n",
      "epoch:11 step:44755[D loss: 0.999978] [G loss: 1.000066]\n",
      "epoch:11 step:44760[D loss: 0.999999] [G loss: 1.000041]\n",
      "epoch:11 step:44765[D loss: 0.999964] [G loss: 1.000017]\n",
      "epoch:11 step:44770[D loss: 1.000082] [G loss: 0.999889]\n",
      "epoch:11 step:44775[D loss: 0.999944] [G loss: 1.000065]\n",
      "epoch:11 step:44780[D loss: 0.999968] [G loss: 1.000082]\n",
      "epoch:11 step:44785[D loss: 1.000013] [G loss: 0.999935]\n",
      "epoch:11 step:44790[D loss: 1.000069] [G loss: 0.999889]\n",
      "epoch:11 step:44795[D loss: 1.000072] [G loss: 0.999867]\n",
      "epoch:11 step:44800[D loss: 0.999984] [G loss: 0.999965]\n",
      "##############\n",
      "[0.88289817 0.8541326  0.82937422 0.82594755 0.82029722 0.85813386\n",
      " 0.86877522 0.84957756 0.82124911 0.87026316]\n",
      "##########\n",
      "epoch:11 step:44805[D loss: 0.999947] [G loss: 1.000079]\n",
      "epoch:11 step:44810[D loss: 0.999966] [G loss: 1.000077]\n",
      "epoch:11 step:44815[D loss: 0.999980] [G loss: 1.000050]\n",
      "epoch:11 step:44820[D loss: 1.000009] [G loss: 1.000046]\n",
      "epoch:11 step:44825[D loss: 0.999982] [G loss: 1.000060]\n",
      "epoch:11 step:44830[D loss: 0.999990] [G loss: 1.000049]\n",
      "epoch:11 step:44835[D loss: 0.999979] [G loss: 1.000053]\n",
      "epoch:11 step:44840[D loss: 1.000045] [G loss: 0.999970]\n",
      "epoch:11 step:44845[D loss: 0.999963] [G loss: 1.000084]\n",
      "epoch:11 step:44850[D loss: 0.999972] [G loss: 1.000065]\n",
      "epoch:11 step:44855[D loss: 0.999965] [G loss: 1.000083]\n",
      "epoch:11 step:44860[D loss: 0.999996] [G loss: 1.000050]\n",
      "epoch:11 step:44865[D loss: 1.000008] [G loss: 1.000041]\n",
      "epoch:11 step:44870[D loss: 0.999980] [G loss: 1.000045]\n",
      "epoch:11 step:44875[D loss: 0.999965] [G loss: 1.000117]\n",
      "epoch:11 step:44880[D loss: 0.999951] [G loss: 1.000072]\n",
      "epoch:11 step:44885[D loss: 0.999975] [G loss: 1.000119]\n",
      "epoch:11 step:44890[D loss: 1.000009] [G loss: 1.000079]\n",
      "epoch:11 step:44895[D loss: 0.999996] [G loss: 1.000026]\n",
      "epoch:11 step:44900[D loss: 0.999953] [G loss: 1.000129]\n",
      "epoch:11 step:44905[D loss: 0.999967] [G loss: 1.000099]\n",
      "epoch:11 step:44910[D loss: 0.999995] [G loss: 1.000072]\n",
      "epoch:11 step:44915[D loss: 0.999954] [G loss: 1.000093]\n",
      "epoch:11 step:44920[D loss: 1.000020] [G loss: 0.999986]\n",
      "epoch:11 step:44925[D loss: 0.999987] [G loss: 1.000053]\n",
      "epoch:11 step:44930[D loss: 1.000000] [G loss: 1.000135]\n",
      "epoch:11 step:44935[D loss: 1.000026] [G loss: 0.999995]\n",
      "epoch:11 step:44940[D loss: 0.999966] [G loss: 1.000072]\n",
      "epoch:11 step:44945[D loss: 0.999973] [G loss: 1.000056]\n",
      "epoch:11 step:44950[D loss: 1.000066] [G loss: 0.999981]\n",
      "epoch:11 step:44955[D loss: 0.999954] [G loss: 1.000086]\n",
      "epoch:11 step:44960[D loss: 0.999997] [G loss: 1.000029]\n",
      "epoch:11 step:44965[D loss: 0.999972] [G loss: 1.000089]\n",
      "epoch:11 step:44970[D loss: 0.999944] [G loss: 1.000123]\n",
      "epoch:11 step:44975[D loss: 0.999923] [G loss: 1.000089]\n",
      "epoch:11 step:44980[D loss: 1.000006] [G loss: 1.000055]\n",
      "epoch:11 step:44985[D loss: 0.999980] [G loss: 1.000060]\n",
      "epoch:11 step:44990[D loss: 0.999990] [G loss: 1.000027]\n",
      "epoch:11 step:44995[D loss: 1.000061] [G loss: 0.999869]\n",
      "epoch:11 step:45000[D loss: 0.999978] [G loss: 1.000091]\n",
      "##############\n",
      "[0.87501562 0.85755186 0.83142152 0.8312195  0.79643979 0.85170824\n",
      " 0.87918711 0.83280763 0.81277134 0.86305747]\n",
      "##########\n",
      "epoch:11 step:45005[D loss: 0.999879] [G loss: 1.000239]\n",
      "epoch:11 step:45010[D loss: 0.999912] [G loss: 1.000134]\n",
      "epoch:11 step:45015[D loss: 0.999999] [G loss: 1.000149]\n",
      "epoch:11 step:45020[D loss: 0.999933] [G loss: 1.000100]\n",
      "epoch:11 step:45025[D loss: 1.000022] [G loss: 0.999971]\n",
      "epoch:11 step:45030[D loss: 1.000049] [G loss: 0.999879]\n",
      "epoch:11 step:45035[D loss: 1.000009] [G loss: 1.000031]\n",
      "epoch:11 step:45040[D loss: 0.999940] [G loss: 1.000187]\n",
      "epoch:11 step:45045[D loss: 0.999966] [G loss: 1.000088]\n",
      "epoch:11 step:45050[D loss: 0.999951] [G loss: 1.000117]\n",
      "epoch:11 step:45055[D loss: 1.000023] [G loss: 1.000080]\n",
      "epoch:11 step:45060[D loss: 0.999970] [G loss: 1.000088]\n",
      "epoch:11 step:45065[D loss: 0.999944] [G loss: 1.000105]\n",
      "epoch:11 step:45070[D loss: 0.999988] [G loss: 1.000032]\n",
      "epoch:11 step:45075[D loss: 1.000037] [G loss: 0.999997]\n",
      "epoch:11 step:45080[D loss: 1.000041] [G loss: 0.999915]\n",
      "epoch:11 step:45085[D loss: 0.999967] [G loss: 1.000083]\n",
      "epoch:11 step:45090[D loss: 0.999908] [G loss: 1.000196]\n",
      "epoch:11 step:45095[D loss: 0.999959] [G loss: 1.000045]\n",
      "epoch:11 step:45100[D loss: 1.000000] [G loss: 1.000022]\n",
      "epoch:11 step:45105[D loss: 0.999991] [G loss: 1.000015]\n",
      "epoch:11 step:45110[D loss: 0.999955] [G loss: 1.000069]\n",
      "epoch:11 step:45115[D loss: 0.999966] [G loss: 1.000043]\n",
      "epoch:11 step:45120[D loss: 0.999969] [G loss: 1.000051]\n",
      "epoch:11 step:45125[D loss: 0.999994] [G loss: 1.000043]\n",
      "epoch:11 step:45130[D loss: 0.999950] [G loss: 1.000130]\n",
      "epoch:11 step:45135[D loss: 0.999973] [G loss: 1.000068]\n",
      "epoch:11 step:45140[D loss: 0.999973] [G loss: 1.000056]\n",
      "epoch:11 step:45145[D loss: 0.999999] [G loss: 1.000019]\n",
      "epoch:11 step:45150[D loss: 0.999982] [G loss: 1.000069]\n",
      "epoch:11 step:45155[D loss: 0.999996] [G loss: 0.999974]\n",
      "epoch:11 step:45160[D loss: 1.000018] [G loss: 1.000032]\n",
      "epoch:11 step:45165[D loss: 0.999974] [G loss: 1.000054]\n",
      "epoch:11 step:45170[D loss: 0.999980] [G loss: 1.000044]\n",
      "epoch:11 step:45175[D loss: 0.999984] [G loss: 1.000030]\n",
      "epoch:11 step:45180[D loss: 0.999982] [G loss: 1.000019]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:11 step:45185[D loss: 0.999971] [G loss: 1.000058]\n",
      "epoch:11 step:45190[D loss: 1.000026] [G loss: 1.000037]\n",
      "epoch:11 step:45195[D loss: 1.000125] [G loss: 0.999887]\n",
      "epoch:11 step:45200[D loss: 0.999897] [G loss: 1.000109]\n",
      "##############\n",
      "[0.86338467 0.84299804 0.83589429 0.81931327 0.78560928 0.85964395\n",
      " 0.89813152 0.83381618 0.8162283  0.83909896]\n",
      "##########\n",
      "epoch:11 step:45205[D loss: 0.999930] [G loss: 1.000209]\n",
      "epoch:11 step:45210[D loss: 0.999921] [G loss: 1.000115]\n",
      "epoch:11 step:45215[D loss: 0.999964] [G loss: 1.000063]\n",
      "epoch:11 step:45220[D loss: 1.000018] [G loss: 0.999980]\n",
      "epoch:11 step:45225[D loss: 0.999961] [G loss: 1.000000]\n",
      "epoch:11 step:45230[D loss: 1.000039] [G loss: 0.999959]\n",
      "epoch:11 step:45235[D loss: 0.999998] [G loss: 1.000033]\n",
      "epoch:11 step:45240[D loss: 0.999936] [G loss: 1.000085]\n",
      "epoch:11 step:45245[D loss: 0.999951] [G loss: 1.000097]\n",
      "epoch:11 step:45250[D loss: 0.999993] [G loss: 1.000047]\n",
      "epoch:11 step:45255[D loss: 0.999961] [G loss: 1.000042]\n",
      "epoch:11 step:45260[D loss: 0.999957] [G loss: 1.000095]\n",
      "epoch:11 step:45265[D loss: 0.999977] [G loss: 1.000035]\n",
      "epoch:11 step:45270[D loss: 0.999982] [G loss: 1.000057]\n",
      "epoch:11 step:45275[D loss: 1.000000] [G loss: 1.000006]\n",
      "epoch:11 step:45280[D loss: 0.999964] [G loss: 1.000052]\n",
      "epoch:11 step:45285[D loss: 0.999952] [G loss: 1.000055]\n",
      "epoch:11 step:45290[D loss: 0.999990] [G loss: 1.000070]\n",
      "epoch:11 step:45295[D loss: 0.999987] [G loss: 1.000019]\n",
      "epoch:11 step:45300[D loss: 1.000002] [G loss: 1.000033]\n",
      "epoch:11 step:45305[D loss: 0.999965] [G loss: 1.000096]\n",
      "epoch:11 step:45310[D loss: 0.999971] [G loss: 1.000036]\n",
      "epoch:11 step:45315[D loss: 0.999953] [G loss: 1.000074]\n",
      "epoch:11 step:45320[D loss: 0.999980] [G loss: 1.000062]\n",
      "epoch:11 step:45325[D loss: 0.999973] [G loss: 1.000066]\n",
      "epoch:11 step:45330[D loss: 0.999963] [G loss: 1.000048]\n",
      "epoch:11 step:45335[D loss: 0.999967] [G loss: 1.000064]\n",
      "epoch:11 step:45340[D loss: 0.999976] [G loss: 1.000062]\n",
      "epoch:11 step:45345[D loss: 0.999966] [G loss: 1.000079]\n",
      "epoch:11 step:45350[D loss: 0.999994] [G loss: 1.000060]\n",
      "epoch:11 step:45355[D loss: 0.999978] [G loss: 1.000050]\n",
      "epoch:11 step:45360[D loss: 0.999979] [G loss: 1.000062]\n",
      "epoch:11 step:45365[D loss: 0.999985] [G loss: 1.000062]\n",
      "epoch:11 step:45370[D loss: 0.999972] [G loss: 1.000052]\n",
      "epoch:11 step:45375[D loss: 1.000001] [G loss: 1.000068]\n",
      "epoch:11 step:45380[D loss: 0.999988] [G loss: 1.000059]\n",
      "epoch:11 step:45385[D loss: 0.999986] [G loss: 1.000054]\n",
      "epoch:11 step:45390[D loss: 0.999982] [G loss: 1.000017]\n",
      "epoch:11 step:45395[D loss: 0.999961] [G loss: 1.000079]\n",
      "epoch:11 step:45400[D loss: 0.999983] [G loss: 1.000075]\n",
      "##############\n",
      "[0.86831102 0.83457358 0.84141097 0.82264718 0.81304307 0.84531186\n",
      " 0.88550438 0.8348706  0.8204174  0.83993396]\n",
      "##########\n",
      "epoch:11 step:45405[D loss: 0.999953] [G loss: 1.000086]\n",
      "epoch:11 step:45410[D loss: 1.000003] [G loss: 1.000036]\n",
      "epoch:11 step:45415[D loss: 0.999964] [G loss: 1.000063]\n",
      "epoch:11 step:45420[D loss: 1.000053] [G loss: 1.000022]\n",
      "epoch:11 step:45425[D loss: 0.999946] [G loss: 1.000119]\n",
      "epoch:11 step:45430[D loss: 0.999961] [G loss: 1.000096]\n",
      "epoch:11 step:45435[D loss: 0.999965] [G loss: 1.000078]\n",
      "epoch:11 step:45440[D loss: 0.999978] [G loss: 1.000084]\n",
      "epoch:11 step:45445[D loss: 0.999998] [G loss: 1.000048]\n",
      "epoch:11 step:45450[D loss: 0.999966] [G loss: 1.000065]\n",
      "epoch:11 step:45455[D loss: 1.000069] [G loss: 0.999994]\n",
      "epoch:11 step:45460[D loss: 0.999944] [G loss: 1.000142]\n",
      "epoch:11 step:45465[D loss: 0.999984] [G loss: 1.000068]\n",
      "epoch:11 step:45470[D loss: 0.999964] [G loss: 1.000099]\n",
      "epoch:11 step:45475[D loss: 0.999974] [G loss: 1.000048]\n",
      "epoch:11 step:45480[D loss: 0.999981] [G loss: 1.000058]\n",
      "epoch:11 step:45485[D loss: 0.999962] [G loss: 1.000089]\n",
      "epoch:11 step:45490[D loss: 0.999954] [G loss: 1.000112]\n",
      "epoch:11 step:45495[D loss: 0.999986] [G loss: 1.000049]\n",
      "epoch:11 step:45500[D loss: 0.999994] [G loss: 1.000050]\n",
      "epoch:11 step:45505[D loss: 1.000055] [G loss: 0.999987]\n",
      "epoch:11 step:45510[D loss: 1.000010] [G loss: 1.000045]\n",
      "epoch:11 step:45515[D loss: 0.999995] [G loss: 1.000085]\n",
      "epoch:11 step:45520[D loss: 0.999949] [G loss: 1.000124]\n",
      "epoch:11 step:45525[D loss: 0.999983] [G loss: 1.000024]\n",
      "epoch:11 step:45530[D loss: 0.999992] [G loss: 1.000064]\n",
      "epoch:11 step:45535[D loss: 0.999994] [G loss: 1.000028]\n",
      "epoch:11 step:45540[D loss: 1.000020] [G loss: 0.999949]\n",
      "epoch:11 step:45545[D loss: 0.999948] [G loss: 1.000125]\n",
      "epoch:11 step:45550[D loss: 0.999935] [G loss: 1.000126]\n",
      "epoch:11 step:45555[D loss: 0.999954] [G loss: 1.000096]\n",
      "epoch:11 step:45560[D loss: 0.999957] [G loss: 1.000152]\n",
      "epoch:11 step:45565[D loss: 0.999981] [G loss: 1.000066]\n",
      "epoch:11 step:45570[D loss: 1.000014] [G loss: 1.000021]\n",
      "epoch:11 step:45575[D loss: 0.999968] [G loss: 1.000041]\n",
      "epoch:11 step:45580[D loss: 0.999981] [G loss: 1.000082]\n",
      "epoch:11 step:45585[D loss: 0.999958] [G loss: 1.000108]\n",
      "epoch:11 step:45590[D loss: 0.999961] [G loss: 1.000086]\n",
      "epoch:11 step:45595[D loss: 0.999963] [G loss: 1.000090]\n",
      "epoch:11 step:45600[D loss: 0.999970] [G loss: 1.000086]\n",
      "##############\n",
      "[0.8504335  0.8684324  0.83580416 0.83002333 0.79438586 0.8384966\n",
      " 0.88655489 0.85717477 0.79766635 0.84184664]\n",
      "##########\n",
      "epoch:11 step:45605[D loss: 1.000050] [G loss: 1.000008]\n",
      "epoch:11 step:45610[D loss: 0.999972] [G loss: 1.000081]\n",
      "epoch:11 step:45615[D loss: 0.999991] [G loss: 1.000110]\n",
      "epoch:11 step:45620[D loss: 1.000024] [G loss: 1.000085]\n",
      "epoch:11 step:45625[D loss: 0.999961] [G loss: 1.000079]\n",
      "epoch:11 step:45630[D loss: 0.999998] [G loss: 1.000014]\n",
      "epoch:11 step:45635[D loss: 0.999997] [G loss: 1.000030]\n",
      "epoch:11 step:45640[D loss: 1.000016] [G loss: 0.999958]\n",
      "epoch:11 step:45645[D loss: 1.000134] [G loss: 0.999782]\n",
      "epoch:11 step:45650[D loss: 0.999943] [G loss: 1.000016]\n",
      "epoch:11 step:45655[D loss: 0.999961] [G loss: 1.000043]\n",
      "epoch:11 step:45660[D loss: 0.999978] [G loss: 1.000065]\n",
      "epoch:11 step:45665[D loss: 0.999985] [G loss: 1.000024]\n",
      "epoch:11 step:45670[D loss: 0.999966] [G loss: 1.000054]\n",
      "epoch:11 step:45675[D loss: 0.999984] [G loss: 1.000050]\n",
      "epoch:11 step:45680[D loss: 0.999974] [G loss: 1.000059]\n",
      "epoch:11 step:45685[D loss: 0.999993] [G loss: 1.000045]\n",
      "epoch:11 step:45690[D loss: 0.999990] [G loss: 1.000005]\n",
      "epoch:11 step:45695[D loss: 0.999969] [G loss: 1.000066]\n",
      "epoch:11 step:45700[D loss: 0.999962] [G loss: 1.000082]\n",
      "epoch:11 step:45705[D loss: 0.999974] [G loss: 1.000053]\n",
      "epoch:11 step:45710[D loss: 0.999968] [G loss: 1.000080]\n",
      "epoch:11 step:45715[D loss: 0.999984] [G loss: 1.000056]\n",
      "epoch:11 step:45720[D loss: 1.000000] [G loss: 1.000042]\n",
      "epoch:11 step:45725[D loss: 0.999967] [G loss: 1.000073]\n",
      "epoch:11 step:45730[D loss: 0.999968] [G loss: 1.000086]\n",
      "epoch:11 step:45735[D loss: 0.999980] [G loss: 1.000081]\n",
      "epoch:11 step:45740[D loss: 1.000050] [G loss: 0.999967]\n",
      "epoch:11 step:45745[D loss: 0.999951] [G loss: 1.000096]\n",
      "epoch:11 step:45750[D loss: 1.000036] [G loss: 0.999947]\n",
      "epoch:11 step:45755[D loss: 1.000044] [G loss: 0.999925]\n",
      "epoch:11 step:45760[D loss: 1.000095] [G loss: 0.999907]\n",
      "epoch:11 step:45765[D loss: 1.000053] [G loss: 0.999981]\n",
      "epoch:11 step:45770[D loss: 0.999945] [G loss: 1.000122]\n",
      "epoch:11 step:45775[D loss: 0.999940] [G loss: 1.000141]\n",
      "epoch:11 step:45780[D loss: 0.999946] [G loss: 1.000113]\n",
      "epoch:11 step:45785[D loss: 0.999973] [G loss: 1.000047]\n",
      "epoch:11 step:45790[D loss: 0.999996] [G loss: 1.000034]\n",
      "epoch:11 step:45795[D loss: 1.000014] [G loss: 1.000008]\n",
      "epoch:11 step:45800[D loss: 1.000004] [G loss: 1.000048]\n",
      "##############\n",
      "[0.87583036 0.85459299 0.8575841  0.81742643 0.79601135 0.82600343\n",
      " 0.87377505 0.84248033 0.79574444 0.85036084]\n",
      "##########\n",
      "epoch:11 step:45805[D loss: 0.999980] [G loss: 1.000075]\n",
      "epoch:11 step:45810[D loss: 0.999937] [G loss: 1.000101]\n",
      "epoch:11 step:45815[D loss: 0.999966] [G loss: 1.000119]\n",
      "epoch:11 step:45820[D loss: 0.999979] [G loss: 1.000077]\n",
      "epoch:11 step:45825[D loss: 0.999993] [G loss: 1.000068]\n",
      "epoch:11 step:45830[D loss: 0.999959] [G loss: 1.000083]\n",
      "epoch:11 step:45835[D loss: 0.999987] [G loss: 1.000037]\n",
      "epoch:11 step:45840[D loss: 0.999968] [G loss: 1.000086]\n",
      "epoch:11 step:45845[D loss: 0.999987] [G loss: 0.999996]\n",
      "epoch:11 step:45850[D loss: 0.999972] [G loss: 1.000060]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:11 step:45855[D loss: 0.999978] [G loss: 1.000074]\n",
      "epoch:11 step:45860[D loss: 0.999962] [G loss: 1.000105]\n",
      "epoch:11 step:45865[D loss: 0.999998] [G loss: 1.000045]\n",
      "epoch:11 step:45870[D loss: 0.999996] [G loss: 1.000080]\n",
      "epoch:11 step:45875[D loss: 1.000036] [G loss: 1.000148]\n",
      "epoch:11 step:45880[D loss: 0.999903] [G loss: 1.000179]\n",
      "epoch:11 step:45885[D loss: 0.999924] [G loss: 1.000144]\n",
      "epoch:11 step:45890[D loss: 0.999976] [G loss: 1.000039]\n",
      "epoch:11 step:45895[D loss: 0.999973] [G loss: 1.000067]\n",
      "epoch:11 step:45900[D loss: 0.999999] [G loss: 1.000000]\n",
      "epoch:11 step:45905[D loss: 1.000006] [G loss: 1.000020]\n",
      "epoch:11 step:45910[D loss: 0.999967] [G loss: 1.000117]\n",
      "epoch:11 step:45915[D loss: 0.999947] [G loss: 1.000139]\n",
      "epoch:11 step:45920[D loss: 0.999969] [G loss: 1.000084]\n",
      "epoch:11 step:45925[D loss: 1.000030] [G loss: 0.999975]\n",
      "epoch:11 step:45930[D loss: 1.000084] [G loss: 0.999980]\n",
      "epoch:11 step:45935[D loss: 0.999988] [G loss: 1.000099]\n",
      "epoch:11 step:45940[D loss: 0.999998] [G loss: 1.000030]\n",
      "epoch:11 step:45945[D loss: 0.999928] [G loss: 1.000093]\n",
      "epoch:11 step:45950[D loss: 0.999982] [G loss: 1.000049]\n",
      "epoch:11 step:45955[D loss: 1.000017] [G loss: 0.999983]\n",
      "epoch:11 step:45960[D loss: 1.000073] [G loss: 0.999883]\n",
      "epoch:11 step:45965[D loss: 0.999922] [G loss: 1.000121]\n",
      "epoch:11 step:45970[D loss: 0.999923] [G loss: 1.000235]\n",
      "epoch:11 step:45975[D loss: 1.000057] [G loss: 1.000098]\n",
      "epoch:11 step:45980[D loss: 0.999914] [G loss: 1.000255]\n",
      "epoch:11 step:45985[D loss: 0.999950] [G loss: 1.000175]\n",
      "epoch:11 step:45990[D loss: 0.999969] [G loss: 1.000173]\n",
      "epoch:11 step:45995[D loss: 0.999973] [G loss: 1.000050]\n",
      "epoch:11 step:46000[D loss: 1.000054] [G loss: 0.999940]\n",
      "##############\n",
      "[0.86520188 0.86031573 0.83342133 0.82533899 0.80604857 0.82003374\n",
      " 0.88591956 0.82301167 0.80616629 0.86889288]\n",
      "##########\n",
      "epoch:11 step:46005[D loss: 1.000072] [G loss: 0.999954]\n",
      "epoch:11 step:46010[D loss: 1.000016] [G loss: 0.999880]\n",
      "epoch:11 step:46015[D loss: 0.999969] [G loss: 1.000054]\n",
      "epoch:11 step:46020[D loss: 1.000008] [G loss: 1.000071]\n",
      "epoch:11 step:46025[D loss: 0.999922] [G loss: 1.000103]\n",
      "epoch:11 step:46030[D loss: 0.999982] [G loss: 1.000099]\n",
      "epoch:11 step:46035[D loss: 0.999971] [G loss: 1.000106]\n",
      "epoch:11 step:46040[D loss: 0.999999] [G loss: 1.000100]\n",
      "epoch:11 step:46045[D loss: 0.999947] [G loss: 1.000097]\n",
      "epoch:11 step:46050[D loss: 0.999973] [G loss: 1.000043]\n",
      "epoch:11 step:46055[D loss: 1.000031] [G loss: 1.000084]\n",
      "epoch:11 step:46060[D loss: 1.000057] [G loss: 1.000078]\n",
      "epoch:11 step:46065[D loss: 0.999996] [G loss: 1.000141]\n",
      "epoch:11 step:46070[D loss: 0.999920] [G loss: 1.000154]\n",
      "epoch:11 step:46075[D loss: 0.999950] [G loss: 1.000157]\n",
      "epoch:11 step:46080[D loss: 0.999963] [G loss: 1.000112]\n",
      "epoch:11 step:46085[D loss: 0.999990] [G loss: 1.000021]\n",
      "epoch:11 step:46090[D loss: 1.000126] [G loss: 0.999782]\n",
      "epoch:11 step:46095[D loss: 1.000160] [G loss: 0.999756]\n",
      "epoch:11 step:46100[D loss: 1.000023] [G loss: 1.000139]\n",
      "epoch:11 step:46105[D loss: 0.999895] [G loss: 1.000237]\n",
      "epoch:11 step:46110[D loss: 0.999935] [G loss: 1.000059]\n",
      "epoch:11 step:46115[D loss: 0.999970] [G loss: 1.000156]\n",
      "epoch:11 step:46120[D loss: 0.999974] [G loss: 1.000045]\n",
      "epoch:11 step:46125[D loss: 0.999980] [G loss: 1.000052]\n",
      "epoch:11 step:46130[D loss: 0.999944] [G loss: 1.000086]\n",
      "epoch:11 step:46135[D loss: 0.999996] [G loss: 1.000012]\n",
      "epoch:11 step:46140[D loss: 0.999976] [G loss: 1.000050]\n",
      "epoch:11 step:46145[D loss: 1.000036] [G loss: 1.000009]\n",
      "epoch:11 step:46150[D loss: 0.999929] [G loss: 1.000142]\n",
      "epoch:11 step:46155[D loss: 0.999958] [G loss: 1.000055]\n",
      "epoch:11 step:46160[D loss: 0.999955] [G loss: 1.000083]\n",
      "epoch:11 step:46165[D loss: 1.000009] [G loss: 1.000052]\n",
      "epoch:11 step:46170[D loss: 1.000002] [G loss: 1.000023]\n",
      "epoch:11 step:46175[D loss: 0.999967] [G loss: 1.000074]\n",
      "epoch:11 step:46180[D loss: 0.999952] [G loss: 1.000065]\n",
      "epoch:11 step:46185[D loss: 0.999969] [G loss: 1.000072]\n",
      "epoch:11 step:46190[D loss: 0.999970] [G loss: 1.000062]\n",
      "epoch:11 step:46195[D loss: 0.999968] [G loss: 1.000029]\n",
      "epoch:11 step:46200[D loss: 0.999970] [G loss: 1.000066]\n",
      "##############\n",
      "[0.87430232 0.83509208 0.8243853  0.83031057 0.80949574 0.83377185\n",
      " 0.87976395 0.81787829 0.81950328 0.82737631]\n",
      "##########\n",
      "epoch:11 step:46205[D loss: 0.999978] [G loss: 1.000055]\n",
      "epoch:11 step:46210[D loss: 0.999988] [G loss: 1.000087]\n",
      "epoch:11 step:46215[D loss: 0.999990] [G loss: 1.000029]\n",
      "epoch:11 step:46220[D loss: 1.000022] [G loss: 0.999984]\n",
      "epoch:11 step:46225[D loss: 0.999991] [G loss: 1.000125]\n",
      "epoch:11 step:46230[D loss: 0.999923] [G loss: 1.000074]\n",
      "epoch:11 step:46235[D loss: 0.999985] [G loss: 1.000087]\n",
      "epoch:11 step:46240[D loss: 0.999956] [G loss: 1.000112]\n",
      "epoch:11 step:46245[D loss: 1.000050] [G loss: 0.999946]\n",
      "epoch:11 step:46250[D loss: 0.999983] [G loss: 1.000063]\n",
      "epoch:11 step:46255[D loss: 0.999969] [G loss: 1.000054]\n",
      "epoch:11 step:46260[D loss: 0.999970] [G loss: 1.000077]\n",
      "epoch:11 step:46265[D loss: 0.999970] [G loss: 1.000043]\n",
      "epoch:11 step:46270[D loss: 0.999997] [G loss: 1.000011]\n",
      "epoch:11 step:46275[D loss: 1.000001] [G loss: 0.999962]\n",
      "epoch:11 step:46280[D loss: 1.000008] [G loss: 1.000029]\n",
      "epoch:11 step:46285[D loss: 1.000002] [G loss: 0.999989]\n",
      "epoch:11 step:46290[D loss: 0.999948] [G loss: 1.000101]\n",
      "epoch:11 step:46295[D loss: 0.999955] [G loss: 1.000051]\n",
      "epoch:11 step:46300[D loss: 0.999969] [G loss: 1.000076]\n",
      "epoch:11 step:46305[D loss: 0.999954] [G loss: 1.000070]\n",
      "epoch:11 step:46310[D loss: 0.999965] [G loss: 1.000113]\n",
      "epoch:11 step:46315[D loss: 0.999976] [G loss: 1.000042]\n",
      "epoch:11 step:46320[D loss: 0.999955] [G loss: 1.000072]\n",
      "epoch:11 step:46325[D loss: 0.999981] [G loss: 1.000010]\n",
      "epoch:11 step:46330[D loss: 0.999972] [G loss: 1.000066]\n",
      "epoch:11 step:46335[D loss: 0.999996] [G loss: 1.000100]\n",
      "epoch:11 step:46340[D loss: 0.999992] [G loss: 1.000063]\n",
      "epoch:11 step:46345[D loss: 0.999986] [G loss: 0.999996]\n",
      "epoch:11 step:46350[D loss: 0.999936] [G loss: 1.000101]\n",
      "epoch:11 step:46355[D loss: 0.999980] [G loss: 1.000022]\n",
      "epoch:11 step:46360[D loss: 0.999978] [G loss: 1.000070]\n",
      "epoch:11 step:46365[D loss: 0.999980] [G loss: 1.000050]\n",
      "epoch:11 step:46370[D loss: 0.999985] [G loss: 1.000060]\n",
      "epoch:11 step:46375[D loss: 0.999980] [G loss: 1.000065]\n",
      "epoch:11 step:46380[D loss: 0.999978] [G loss: 1.000057]\n",
      "epoch:11 step:46385[D loss: 0.999988] [G loss: 0.999995]\n",
      "epoch:11 step:46390[D loss: 1.000017] [G loss: 1.000093]\n",
      "epoch:11 step:46395[D loss: 0.999977] [G loss: 0.999989]\n",
      "epoch:11 step:46400[D loss: 1.000000] [G loss: 1.000209]\n",
      "##############\n",
      "[0.88683581 0.86745326 0.83548301 0.84096366 0.8031306  0.83782173\n",
      " 0.86541947 0.83635353 0.80721141 0.82278885]\n",
      "##########\n",
      "epoch:11 step:46405[D loss: 0.999973] [G loss: 1.000053]\n",
      "epoch:11 step:46410[D loss: 0.999975] [G loss: 1.000077]\n",
      "epoch:11 step:46415[D loss: 1.000028] [G loss: 0.999987]\n",
      "epoch:11 step:46420[D loss: 0.999994] [G loss: 1.000061]\n",
      "epoch:11 step:46425[D loss: 0.999960] [G loss: 1.000062]\n",
      "epoch:11 step:46430[D loss: 0.999995] [G loss: 1.000090]\n",
      "epoch:11 step:46435[D loss: 0.999989] [G loss: 1.000046]\n",
      "epoch:11 step:46440[D loss: 0.999918] [G loss: 1.000172]\n",
      "epoch:11 step:46445[D loss: 0.999959] [G loss: 1.000138]\n",
      "epoch:11 step:46450[D loss: 0.999960] [G loss: 1.000264]\n",
      "epoch:11 step:46455[D loss: 0.999977] [G loss: 1.000096]\n",
      "epoch:11 step:46460[D loss: 0.999963] [G loss: 1.000138]\n",
      "epoch:11 step:46465[D loss: 0.999946] [G loss: 1.000117]\n",
      "epoch:11 step:46470[D loss: 0.999968] [G loss: 1.000070]\n",
      "epoch:11 step:46475[D loss: 1.000025] [G loss: 0.999973]\n",
      "epoch:11 step:46480[D loss: 0.999973] [G loss: 1.000013]\n",
      "epoch:11 step:46485[D loss: 1.000102] [G loss: 0.999994]\n",
      "epoch:11 step:46490[D loss: 1.000039] [G loss: 1.000032]\n",
      "epoch:11 step:46495[D loss: 0.999877] [G loss: 1.000203]\n",
      "epoch:11 step:46500[D loss: 0.999925] [G loss: 1.000132]\n",
      "epoch:11 step:46505[D loss: 0.999985] [G loss: 1.000047]\n",
      "epoch:11 step:46510[D loss: 0.999959] [G loss: 1.000066]\n",
      "epoch:11 step:46515[D loss: 0.999978] [G loss: 1.000103]\n",
      "epoch:11 step:46520[D loss: 0.999996] [G loss: 1.000052]\n",
      "epoch:11 step:46525[D loss: 0.999959] [G loss: 1.000029]\n",
      "epoch:11 step:46530[D loss: 1.000017] [G loss: 1.000025]\n",
      "epoch:11 step:46535[D loss: 0.999949] [G loss: 1.000056]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:11 step:46540[D loss: 0.999960] [G loss: 1.000026]\n",
      "epoch:11 step:46545[D loss: 0.999923] [G loss: 1.000084]\n",
      "epoch:11 step:46550[D loss: 0.999936] [G loss: 1.000128]\n",
      "epoch:11 step:46555[D loss: 0.999958] [G loss: 1.000039]\n",
      "epoch:11 step:46560[D loss: 1.000008] [G loss: 0.999986]\n",
      "epoch:11 step:46565[D loss: 0.999940] [G loss: 1.000060]\n",
      "epoch:11 step:46570[D loss: 0.999969] [G loss: 1.000041]\n",
      "epoch:11 step:46575[D loss: 1.000022] [G loss: 1.000056]\n",
      "epoch:11 step:46580[D loss: 0.999957] [G loss: 1.000065]\n",
      "epoch:11 step:46585[D loss: 0.999973] [G loss: 1.000063]\n",
      "epoch:11 step:46590[D loss: 0.999968] [G loss: 1.000094]\n",
      "epoch:11 step:46595[D loss: 0.999983] [G loss: 1.000053]\n",
      "epoch:11 step:46600[D loss: 1.000057] [G loss: 0.999933]\n",
      "##############\n",
      "[0.87200504 0.84449631 0.81848402 0.84419507 0.80502453 0.8324671\n",
      " 0.87513254 0.82960487 0.81701149 0.84889217]\n",
      "##########\n",
      "epoch:11 step:46605[D loss: 0.999996] [G loss: 1.000074]\n",
      "epoch:11 step:46610[D loss: 0.999995] [G loss: 1.000112]\n",
      "epoch:11 step:46615[D loss: 0.999931] [G loss: 1.000158]\n",
      "epoch:11 step:46620[D loss: 0.999983] [G loss: 1.000082]\n",
      "epoch:11 step:46625[D loss: 0.999988] [G loss: 1.000082]\n",
      "epoch:11 step:46630[D loss: 0.999975] [G loss: 1.000081]\n",
      "epoch:11 step:46635[D loss: 0.999964] [G loss: 1.000103]\n",
      "epoch:11 step:46640[D loss: 0.999975] [G loss: 1.000112]\n",
      "epoch:11 step:46645[D loss: 0.999971] [G loss: 1.000095]\n",
      "epoch:11 step:46650[D loss: 0.999966] [G loss: 1.000101]\n",
      "epoch:11 step:46655[D loss: 0.999975] [G loss: 1.000099]\n",
      "epoch:11 step:46660[D loss: 0.999972] [G loss: 1.000085]\n",
      "epoch:11 step:46665[D loss: 1.000001] [G loss: 1.000058]\n",
      "epoch:11 step:46670[D loss: 0.999981] [G loss: 1.000038]\n",
      "epoch:11 step:46675[D loss: 0.999987] [G loss: 1.000016]\n",
      "epoch:11 step:46680[D loss: 0.999991] [G loss: 1.000053]\n",
      "epoch:11 step:46685[D loss: 0.999983] [G loss: 1.000090]\n",
      "epoch:11 step:46690[D loss: 0.999980] [G loss: 1.000074]\n",
      "epoch:11 step:46695[D loss: 0.999981] [G loss: 1.000111]\n",
      "epoch:11 step:46700[D loss: 0.999996] [G loss: 1.000026]\n",
      "epoch:11 step:46705[D loss: 0.999998] [G loss: 1.000032]\n",
      "epoch:11 step:46710[D loss: 1.000042] [G loss: 0.999956]\n",
      "epoch:11 step:46715[D loss: 0.999917] [G loss: 1.000141]\n",
      "epoch:11 step:46720[D loss: 1.000026] [G loss: 0.999956]\n",
      "epoch:11 step:46725[D loss: 0.999975] [G loss: 1.000047]\n",
      "epoch:11 step:46730[D loss: 0.999950] [G loss: 1.000056]\n",
      "epoch:11 step:46735[D loss: 0.999956] [G loss: 1.000046]\n",
      "epoch:11 step:46740[D loss: 0.999955] [G loss: 1.000065]\n",
      "epoch:11 step:46745[D loss: 0.999986] [G loss: 1.000039]\n",
      "epoch:11 step:46750[D loss: 1.000023] [G loss: 1.000017]\n",
      "epoch:11 step:46755[D loss: 1.000016] [G loss: 1.000010]\n",
      "epoch:11 step:46760[D loss: 1.000013] [G loss: 1.000025]\n",
      "epoch:11 step:46765[D loss: 0.999936] [G loss: 1.000154]\n",
      "epoch:11 step:46770[D loss: 0.999986] [G loss: 1.000089]\n",
      "epoch:11 step:46775[D loss: 1.000038] [G loss: 1.000108]\n",
      "epoch:11 step:46780[D loss: 1.000031] [G loss: 0.999914]\n",
      "epoch:11 step:46785[D loss: 0.999887] [G loss: 1.000219]\n",
      "epoch:11 step:46790[D loss: 0.999943] [G loss: 1.000118]\n",
      "epoch:11 step:46795[D loss: 0.999956] [G loss: 1.000089]\n",
      "epoch:11 step:46800[D loss: 1.000014] [G loss: 1.000025]\n",
      "##############\n",
      "[0.85558745 0.84627699 0.82751834 0.81867529 0.81112787 0.83710276\n",
      " 0.87623418 0.83021979 0.8386053  0.84419428]\n",
      "##########\n",
      "epoch:11 step:46805[D loss: 0.999993] [G loss: 1.000049]\n",
      "epoch:11 step:46810[D loss: 0.999934] [G loss: 1.000095]\n",
      "epoch:11 step:46815[D loss: 1.000000] [G loss: 1.000064]\n",
      "epoch:11 step:46820[D loss: 0.999943] [G loss: 1.000141]\n",
      "epoch:11 step:46825[D loss: 1.000041] [G loss: 1.000043]\n",
      "epoch:11 step:46830[D loss: 0.999941] [G loss: 1.000150]\n",
      "epoch:11 step:46835[D loss: 0.999984] [G loss: 1.000059]\n",
      "epoch:11 step:46840[D loss: 1.000060] [G loss: 0.999901]\n",
      "epoch:11 step:46845[D loss: 1.000065] [G loss: 0.999835]\n",
      "epoch:11 step:46850[D loss: 0.999933] [G loss: 1.000013]\n",
      "epoch:11 step:46855[D loss: 0.999953] [G loss: 1.000085]\n",
      "epoch:11 step:46860[D loss: 0.999987] [G loss: 1.000028]\n",
      "epoch:12 step:46865[D loss: 0.999981] [G loss: 1.000056]\n",
      "epoch:12 step:46870[D loss: 0.999978] [G loss: 1.000040]\n",
      "epoch:12 step:46875[D loss: 0.999980] [G loss: 1.000067]\n",
      "epoch:12 step:46880[D loss: 0.999987] [G loss: 1.000026]\n",
      "epoch:12 step:46885[D loss: 0.999987] [G loss: 1.000077]\n",
      "epoch:12 step:46890[D loss: 0.999962] [G loss: 1.000063]\n",
      "epoch:12 step:46895[D loss: 0.999994] [G loss: 1.000080]\n",
      "epoch:12 step:46900[D loss: 0.999979] [G loss: 1.000057]\n",
      "epoch:12 step:46905[D loss: 0.999966] [G loss: 1.000066]\n",
      "epoch:12 step:46910[D loss: 0.999977] [G loss: 1.000070]\n",
      "epoch:12 step:46915[D loss: 0.999994] [G loss: 1.000070]\n",
      "epoch:12 step:46920[D loss: 0.999958] [G loss: 1.000077]\n",
      "epoch:12 step:46925[D loss: 0.999969] [G loss: 1.000113]\n",
      "epoch:12 step:46930[D loss: 0.999992] [G loss: 1.000022]\n",
      "epoch:12 step:46935[D loss: 0.999971] [G loss: 1.000076]\n",
      "epoch:12 step:46940[D loss: 0.999973] [G loss: 1.000055]\n",
      "epoch:12 step:46945[D loss: 0.999992] [G loss: 1.000022]\n",
      "epoch:12 step:46950[D loss: 1.000035] [G loss: 1.000020]\n",
      "epoch:12 step:46955[D loss: 0.999951] [G loss: 1.000096]\n",
      "epoch:12 step:46960[D loss: 0.999983] [G loss: 1.000095]\n",
      "epoch:12 step:46965[D loss: 0.999957] [G loss: 1.000080]\n",
      "epoch:12 step:46970[D loss: 0.999980] [G loss: 1.000018]\n",
      "epoch:12 step:46975[D loss: 1.000038] [G loss: 0.999907]\n",
      "epoch:12 step:46980[D loss: 1.000216] [G loss: 0.999845]\n",
      "epoch:12 step:46985[D loss: 0.999934] [G loss: 1.000073]\n",
      "epoch:12 step:46990[D loss: 0.999947] [G loss: 1.000125]\n",
      "epoch:12 step:46995[D loss: 0.999891] [G loss: 1.000245]\n",
      "epoch:12 step:47000[D loss: 0.999946] [G loss: 1.000134]\n",
      "##############\n",
      "[0.87178341 0.85111695 0.83155933 0.82442327 0.78440714 0.86017213\n",
      " 0.8874531  0.83274026 0.80552828 0.86054528]\n",
      "##########\n",
      "epoch:12 step:47005[D loss: 0.999965] [G loss: 1.000035]\n",
      "epoch:12 step:47010[D loss: 0.999996] [G loss: 1.000003]\n",
      "epoch:12 step:47015[D loss: 1.000024] [G loss: 0.999903]\n",
      "epoch:12 step:47020[D loss: 1.000040] [G loss: 1.000006]\n",
      "epoch:12 step:47025[D loss: 1.000027] [G loss: 0.999902]\n",
      "epoch:12 step:47030[D loss: 0.999852] [G loss: 1.000274]\n",
      "epoch:12 step:47035[D loss: 0.999973] [G loss: 1.000062]\n",
      "epoch:12 step:47040[D loss: 0.999993] [G loss: 1.000095]\n",
      "epoch:12 step:47045[D loss: 0.999977] [G loss: 1.000115]\n",
      "epoch:12 step:47050[D loss: 0.999943] [G loss: 1.000149]\n",
      "epoch:12 step:47055[D loss: 0.999960] [G loss: 1.000106]\n",
      "epoch:12 step:47060[D loss: 0.999991] [G loss: 1.000043]\n",
      "epoch:12 step:47065[D loss: 0.999991] [G loss: 1.000057]\n",
      "epoch:12 step:47070[D loss: 0.999974] [G loss: 1.000093]\n",
      "epoch:12 step:47075[D loss: 0.999976] [G loss: 1.000075]\n",
      "epoch:12 step:47080[D loss: 0.999969] [G loss: 1.000080]\n",
      "epoch:12 step:47085[D loss: 0.999972] [G loss: 1.000067]\n",
      "epoch:12 step:47090[D loss: 0.999992] [G loss: 1.000055]\n",
      "epoch:12 step:47095[D loss: 0.999993] [G loss: 1.000049]\n",
      "epoch:12 step:47100[D loss: 0.999976] [G loss: 1.000049]\n",
      "epoch:12 step:47105[D loss: 1.000015] [G loss: 1.000023]\n",
      "epoch:12 step:47110[D loss: 0.999979] [G loss: 1.000019]\n",
      "epoch:12 step:47115[D loss: 0.999962] [G loss: 1.000072]\n",
      "epoch:12 step:47120[D loss: 0.999967] [G loss: 1.000069]\n",
      "epoch:12 step:47125[D loss: 0.999979] [G loss: 1.000057]\n",
      "epoch:12 step:47130[D loss: 0.999975] [G loss: 1.000068]\n",
      "epoch:12 step:47135[D loss: 0.999988] [G loss: 1.000037]\n",
      "epoch:12 step:47140[D loss: 0.999962] [G loss: 1.000066]\n",
      "epoch:12 step:47145[D loss: 0.999998] [G loss: 0.999984]\n",
      "epoch:12 step:47150[D loss: 0.999952] [G loss: 1.000071]\n",
      "epoch:12 step:47155[D loss: 0.999942] [G loss: 1.000123]\n",
      "epoch:12 step:47160[D loss: 0.999996] [G loss: 1.000022]\n",
      "epoch:12 step:47165[D loss: 0.999982] [G loss: 1.000054]\n",
      "epoch:12 step:47170[D loss: 0.999973] [G loss: 1.000039]\n",
      "epoch:12 step:47175[D loss: 0.999975] [G loss: 1.000090]\n",
      "epoch:12 step:47180[D loss: 0.999976] [G loss: 1.000103]\n",
      "epoch:12 step:47185[D loss: 0.999990] [G loss: 1.000115]\n",
      "epoch:12 step:47190[D loss: 0.999955] [G loss: 1.000069]\n",
      "epoch:12 step:47195[D loss: 0.999994] [G loss: 1.000043]\n",
      "epoch:12 step:47200[D loss: 0.999983] [G loss: 1.000052]\n",
      "##############\n",
      "[0.86603704 0.86563852 0.81266873 0.8337656  0.80766802 0.83221262\n",
      " 0.8928105  0.82792014 0.80236316 0.83557201]\n",
      "##########\n",
      "epoch:12 step:47205[D loss: 0.999979] [G loss: 1.000062]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:12 step:47210[D loss: 0.999962] [G loss: 1.000092]\n",
      "epoch:12 step:47215[D loss: 1.000144] [G loss: 0.999814]\n",
      "epoch:12 step:47220[D loss: 1.000058] [G loss: 1.000035]\n",
      "epoch:12 step:47225[D loss: 1.000007] [G loss: 1.000117]\n",
      "epoch:12 step:47230[D loss: 0.999936] [G loss: 1.000154]\n",
      "epoch:12 step:47235[D loss: 0.999989] [G loss: 1.000110]\n",
      "epoch:12 step:47240[D loss: 0.999975] [G loss: 1.000054]\n",
      "epoch:12 step:47245[D loss: 0.999976] [G loss: 1.000124]\n",
      "epoch:12 step:47250[D loss: 0.999992] [G loss: 1.000092]\n",
      "epoch:12 step:47255[D loss: 0.999953] [G loss: 1.000098]\n",
      "epoch:12 step:47260[D loss: 0.999965] [G loss: 1.000102]\n",
      "epoch:12 step:47265[D loss: 0.999965] [G loss: 1.000100]\n",
      "epoch:12 step:47270[D loss: 0.999947] [G loss: 1.000093]\n",
      "epoch:12 step:47275[D loss: 0.999973] [G loss: 1.000052]\n",
      "epoch:12 step:47280[D loss: 0.999976] [G loss: 1.000062]\n",
      "epoch:12 step:47285[D loss: 0.999968] [G loss: 1.000053]\n",
      "epoch:12 step:47290[D loss: 0.999981] [G loss: 1.000047]\n",
      "epoch:12 step:47295[D loss: 0.999973] [G loss: 1.000080]\n",
      "epoch:12 step:47300[D loss: 0.999992] [G loss: 1.000044]\n",
      "epoch:12 step:47305[D loss: 1.000032] [G loss: 1.000052]\n",
      "epoch:12 step:47310[D loss: 0.999944] [G loss: 1.000093]\n",
      "epoch:12 step:47315[D loss: 0.999969] [G loss: 1.000064]\n",
      "epoch:12 step:47320[D loss: 0.999958] [G loss: 1.000063]\n",
      "epoch:12 step:47325[D loss: 1.000022] [G loss: 0.999991]\n",
      "epoch:12 step:47330[D loss: 0.999960] [G loss: 1.000077]\n",
      "epoch:12 step:47335[D loss: 0.999966] [G loss: 1.000082]\n",
      "epoch:12 step:47340[D loss: 1.000008] [G loss: 1.000099]\n",
      "epoch:12 step:47345[D loss: 0.999942] [G loss: 1.000098]\n",
      "epoch:12 step:47350[D loss: 0.999975] [G loss: 1.000109]\n",
      "epoch:12 step:47355[D loss: 0.999993] [G loss: 1.000144]\n",
      "epoch:12 step:47360[D loss: 0.999992] [G loss: 1.000051]\n",
      "epoch:12 step:47365[D loss: 0.999997] [G loss: 1.000039]\n",
      "epoch:12 step:47370[D loss: 0.999983] [G loss: 1.000085]\n",
      "epoch:12 step:47375[D loss: 1.000000] [G loss: 0.999990]\n",
      "epoch:12 step:47380[D loss: 1.000036] [G loss: 0.999976]\n",
      "epoch:12 step:47385[D loss: 1.000104] [G loss: 0.999845]\n",
      "epoch:12 step:47390[D loss: 0.999950] [G loss: 1.000120]\n",
      "epoch:12 step:47395[D loss: 0.999984] [G loss: 1.000110]\n",
      "epoch:12 step:47400[D loss: 0.999919] [G loss: 1.000190]\n",
      "##############\n",
      "[0.85334958 0.86328835 0.83562879 0.84872821 0.81182991 0.83282979\n",
      " 0.88123701 0.83452279 0.82359785 0.82202566]\n",
      "##########\n",
      "epoch:12 step:47405[D loss: 0.999953] [G loss: 1.000106]\n",
      "epoch:12 step:47410[D loss: 0.999979] [G loss: 1.000097]\n",
      "epoch:12 step:47415[D loss: 0.999996] [G loss: 1.000047]\n",
      "epoch:12 step:47420[D loss: 0.999990] [G loss: 1.000063]\n",
      "epoch:12 step:47425[D loss: 1.000024] [G loss: 0.999977]\n",
      "epoch:12 step:47430[D loss: 0.999982] [G loss: 1.000024]\n",
      "epoch:12 step:47435[D loss: 0.999966] [G loss: 1.000106]\n",
      "epoch:12 step:47440[D loss: 0.999956] [G loss: 1.000105]\n",
      "epoch:12 step:47445[D loss: 0.999988] [G loss: 1.000134]\n",
      "epoch:12 step:47450[D loss: 0.999982] [G loss: 1.000092]\n",
      "epoch:12 step:47455[D loss: 0.999996] [G loss: 1.000070]\n",
      "epoch:12 step:47460[D loss: 0.999961] [G loss: 1.000103]\n",
      "epoch:12 step:47465[D loss: 1.000012] [G loss: 1.000065]\n",
      "epoch:12 step:47470[D loss: 0.999977] [G loss: 1.000170]\n",
      "epoch:12 step:47475[D loss: 1.000016] [G loss: 1.000019]\n",
      "epoch:12 step:47480[D loss: 0.999941] [G loss: 1.000152]\n",
      "epoch:12 step:47485[D loss: 0.999961] [G loss: 1.000158]\n",
      "epoch:12 step:47490[D loss: 1.000006] [G loss: 1.000025]\n",
      "epoch:12 step:47495[D loss: 1.000091] [G loss: 0.999846]\n",
      "epoch:12 step:47500[D loss: 1.000033] [G loss: 1.000031]\n",
      "epoch:12 step:47505[D loss: 0.999895] [G loss: 1.000161]\n",
      "epoch:12 step:47510[D loss: 0.999939] [G loss: 1.000143]\n",
      "epoch:12 step:47515[D loss: 0.999967] [G loss: 1.000238]\n",
      "epoch:12 step:47520[D loss: 0.999937] [G loss: 1.000074]\n",
      "epoch:12 step:47525[D loss: 0.999956] [G loss: 1.000117]\n",
      "epoch:12 step:47530[D loss: 1.000054] [G loss: 1.000036]\n",
      "epoch:12 step:47535[D loss: 0.999960] [G loss: 0.999974]\n",
      "epoch:12 step:47540[D loss: 1.000060] [G loss: 0.999953]\n",
      "epoch:12 step:47545[D loss: 0.999966] [G loss: 0.999966]\n",
      "epoch:12 step:47550[D loss: 1.000001] [G loss: 1.000129]\n",
      "epoch:12 step:47555[D loss: 0.999942] [G loss: 1.000108]\n",
      "epoch:12 step:47560[D loss: 1.000003] [G loss: 1.000014]\n",
      "epoch:12 step:47565[D loss: 1.000023] [G loss: 0.999967]\n",
      "epoch:12 step:47570[D loss: 0.999970] [G loss: 1.000070]\n",
      "epoch:12 step:47575[D loss: 0.999951] [G loss: 1.000080]\n",
      "epoch:12 step:47580[D loss: 0.999984] [G loss: 1.000024]\n",
      "epoch:12 step:47585[D loss: 0.999980] [G loss: 1.000019]\n",
      "epoch:12 step:47590[D loss: 0.999973] [G loss: 1.000022]\n",
      "epoch:12 step:47595[D loss: 0.999981] [G loss: 1.000034]\n",
      "epoch:12 step:47600[D loss: 0.999963] [G loss: 1.000053]\n",
      "##############\n",
      "[0.87553208 0.86579291 0.81237877 0.83820913 0.80101399 0.84160247\n",
      " 0.88317111 0.80654007 0.80890265 0.86213465]\n",
      "##########\n",
      "epoch:12 step:47605[D loss: 0.999965] [G loss: 1.000066]\n",
      "epoch:12 step:47610[D loss: 0.999952] [G loss: 1.000090]\n",
      "epoch:12 step:47615[D loss: 1.000013] [G loss: 0.999979]\n",
      "epoch:12 step:47620[D loss: 0.999985] [G loss: 1.000115]\n",
      "epoch:12 step:47625[D loss: 0.999951] [G loss: 1.000074]\n",
      "epoch:12 step:47630[D loss: 0.999981] [G loss: 1.000044]\n",
      "epoch:12 step:47635[D loss: 0.999984] [G loss: 1.000022]\n",
      "epoch:12 step:47640[D loss: 0.999962] [G loss: 1.000021]\n",
      "epoch:12 step:47645[D loss: 0.999995] [G loss: 0.999997]\n",
      "epoch:12 step:47650[D loss: 0.999964] [G loss: 1.000065]\n",
      "epoch:12 step:47655[D loss: 0.999987] [G loss: 1.000034]\n",
      "epoch:12 step:47660[D loss: 0.999984] [G loss: 1.000013]\n",
      "epoch:12 step:47665[D loss: 0.999964] [G loss: 1.000049]\n",
      "epoch:12 step:47670[D loss: 0.999976] [G loss: 1.000036]\n",
      "epoch:12 step:47675[D loss: 0.999964] [G loss: 1.000070]\n",
      "epoch:12 step:47680[D loss: 0.999950] [G loss: 1.000091]\n",
      "epoch:12 step:47685[D loss: 0.999980] [G loss: 1.000043]\n",
      "epoch:12 step:47690[D loss: 0.999953] [G loss: 1.000068]\n",
      "epoch:12 step:47695[D loss: 0.999980] [G loss: 1.000049]\n",
      "epoch:12 step:47700[D loss: 0.999985] [G loss: 1.000020]\n",
      "epoch:12 step:47705[D loss: 0.999971] [G loss: 1.000055]\n",
      "epoch:12 step:47710[D loss: 0.999985] [G loss: 1.000069]\n",
      "epoch:12 step:47715[D loss: 1.000023] [G loss: 1.000019]\n",
      "epoch:12 step:47720[D loss: 0.999973] [G loss: 1.000075]\n",
      "epoch:12 step:47725[D loss: 0.999975] [G loss: 1.000055]\n",
      "epoch:12 step:47730[D loss: 1.000011] [G loss: 0.999995]\n",
      "epoch:12 step:47735[D loss: 1.000022] [G loss: 0.999997]\n",
      "epoch:12 step:47740[D loss: 1.000098] [G loss: 0.999907]\n",
      "epoch:12 step:47745[D loss: 0.999915] [G loss: 1.000144]\n",
      "epoch:12 step:47750[D loss: 0.999967] [G loss: 1.000064]\n",
      "epoch:12 step:47755[D loss: 1.000008] [G loss: 1.000091]\n",
      "epoch:12 step:47760[D loss: 0.999961] [G loss: 1.000113]\n",
      "epoch:12 step:47765[D loss: 0.999992] [G loss: 0.999993]\n",
      "epoch:12 step:47770[D loss: 1.000001] [G loss: 1.000063]\n",
      "epoch:12 step:47775[D loss: 1.000110] [G loss: 0.999821]\n",
      "epoch:12 step:47780[D loss: 0.999956] [G loss: 1.000029]\n",
      "epoch:12 step:47785[D loss: 1.000019] [G loss: 1.000029]\n",
      "epoch:12 step:47790[D loss: 0.999970] [G loss: 1.000028]\n",
      "epoch:12 step:47795[D loss: 0.999996] [G loss: 1.000023]\n",
      "epoch:12 step:47800[D loss: 1.000037] [G loss: 1.000009]\n",
      "##############\n",
      "[0.88114085 0.85639088 0.84182321 0.81429121 0.79577241 0.83174854\n",
      " 0.87981332 0.83826349 0.82704463 0.85939463]\n",
      "##########\n",
      "epoch:12 step:47805[D loss: 0.999982] [G loss: 0.999954]\n",
      "epoch:12 step:47810[D loss: 0.999977] [G loss: 1.000126]\n",
      "epoch:12 step:47815[D loss: 0.999901] [G loss: 1.000093]\n",
      "epoch:12 step:47820[D loss: 1.000001] [G loss: 1.000101]\n",
      "epoch:12 step:47825[D loss: 0.999982] [G loss: 1.000046]\n",
      "epoch:12 step:47830[D loss: 0.999978] [G loss: 1.000056]\n",
      "epoch:12 step:47835[D loss: 0.999997] [G loss: 0.999987]\n",
      "epoch:12 step:47840[D loss: 1.000023] [G loss: 0.999944]\n",
      "epoch:12 step:47845[D loss: 1.000137] [G loss: 0.999870]\n",
      "epoch:12 step:47850[D loss: 0.999920] [G loss: 1.000143]\n",
      "epoch:12 step:47855[D loss: 0.999960] [G loss: 1.000062]\n",
      "epoch:12 step:47860[D loss: 0.999968] [G loss: 1.000069]\n",
      "epoch:12 step:47865[D loss: 1.000005] [G loss: 1.000048]\n",
      "epoch:12 step:47870[D loss: 0.999958] [G loss: 1.000085]\n",
      "epoch:12 step:47875[D loss: 0.999983] [G loss: 1.000058]\n",
      "epoch:12 step:47880[D loss: 0.999960] [G loss: 1.000090]\n",
      "epoch:12 step:47885[D loss: 0.999972] [G loss: 1.000020]\n",
      "epoch:12 step:47890[D loss: 1.000011] [G loss: 0.999982]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:12 step:47895[D loss: 0.999955] [G loss: 1.000088]\n",
      "epoch:12 step:47900[D loss: 0.999990] [G loss: 1.000034]\n",
      "epoch:12 step:47905[D loss: 0.999975] [G loss: 1.000058]\n",
      "epoch:12 step:47910[D loss: 0.999973] [G loss: 1.000069]\n",
      "epoch:12 step:47915[D loss: 0.999990] [G loss: 1.000055]\n",
      "epoch:12 step:47920[D loss: 0.999991] [G loss: 1.000047]\n",
      "epoch:12 step:47925[D loss: 0.999975] [G loss: 1.000068]\n",
      "epoch:12 step:47930[D loss: 0.999983] [G loss: 1.000012]\n",
      "epoch:12 step:47935[D loss: 0.999958] [G loss: 1.000053]\n",
      "epoch:12 step:47940[D loss: 0.999970] [G loss: 1.000051]\n",
      "epoch:12 step:47945[D loss: 0.999972] [G loss: 1.000062]\n",
      "epoch:12 step:47950[D loss: 1.000009] [G loss: 1.000013]\n",
      "epoch:12 step:47955[D loss: 0.999987] [G loss: 1.000050]\n",
      "epoch:12 step:47960[D loss: 0.999984] [G loss: 1.000030]\n",
      "epoch:12 step:47965[D loss: 0.999955] [G loss: 1.000099]\n",
      "epoch:12 step:47970[D loss: 0.999985] [G loss: 1.000032]\n",
      "epoch:12 step:47975[D loss: 0.999978] [G loss: 1.000006]\n",
      "epoch:12 step:47980[D loss: 0.999947] [G loss: 1.000132]\n",
      "epoch:12 step:47985[D loss: 0.999954] [G loss: 1.000071]\n",
      "epoch:12 step:47990[D loss: 0.999976] [G loss: 1.000052]\n",
      "epoch:12 step:47995[D loss: 0.999979] [G loss: 1.000045]\n",
      "epoch:12 step:48000[D loss: 0.999979] [G loss: 1.000049]\n",
      "##############\n",
      "[0.86235206 0.86455968 0.82116864 0.83433179 0.82502502 0.82401048\n",
      " 0.89431781 0.84627407 0.8473234  0.84676561]\n",
      "##########\n",
      "epoch:12 step:48005[D loss: 0.999999] [G loss: 1.000057]\n",
      "epoch:12 step:48010[D loss: 0.999976] [G loss: 1.000052]\n",
      "epoch:12 step:48015[D loss: 1.000003] [G loss: 1.000058]\n",
      "epoch:12 step:48020[D loss: 0.999941] [G loss: 1.000135]\n",
      "epoch:12 step:48025[D loss: 0.999960] [G loss: 1.000083]\n",
      "epoch:12 step:48030[D loss: 0.999951] [G loss: 1.000071]\n",
      "epoch:12 step:48035[D loss: 0.999978] [G loss: 1.000057]\n",
      "epoch:12 step:48040[D loss: 1.000061] [G loss: 0.999995]\n",
      "epoch:12 step:48045[D loss: 0.999988] [G loss: 1.000067]\n",
      "epoch:12 step:48050[D loss: 0.999923] [G loss: 1.000129]\n",
      "epoch:12 step:48055[D loss: 1.000000] [G loss: 0.999991]\n",
      "epoch:12 step:48060[D loss: 0.999995] [G loss: 1.000024]\n",
      "epoch:12 step:48065[D loss: 0.999993] [G loss: 0.999962]\n",
      "epoch:12 step:48070[D loss: 0.999949] [G loss: 1.000048]\n",
      "epoch:12 step:48075[D loss: 1.000021] [G loss: 0.999960]\n",
      "epoch:12 step:48080[D loss: 1.000081] [G loss: 0.999916]\n",
      "epoch:12 step:48085[D loss: 0.999912] [G loss: 1.000166]\n",
      "epoch:12 step:48090[D loss: 0.999985] [G loss: 1.000097]\n",
      "epoch:12 step:48095[D loss: 0.999966] [G loss: 1.000117]\n",
      "epoch:12 step:48100[D loss: 0.999943] [G loss: 1.000083]\n",
      "epoch:12 step:48105[D loss: 0.999993] [G loss: 0.999982]\n",
      "epoch:12 step:48110[D loss: 1.000051] [G loss: 0.999921]\n",
      "epoch:12 step:48115[D loss: 0.999963] [G loss: 0.999983]\n",
      "epoch:12 step:48120[D loss: 0.999934] [G loss: 1.000077]\n",
      "epoch:12 step:48125[D loss: 0.999993] [G loss: 1.000058]\n",
      "epoch:12 step:48130[D loss: 0.999962] [G loss: 1.000058]\n",
      "epoch:12 step:48135[D loss: 0.999971] [G loss: 1.000046]\n",
      "epoch:12 step:48140[D loss: 0.999960] [G loss: 1.000074]\n",
      "epoch:12 step:48145[D loss: 0.999994] [G loss: 1.000039]\n",
      "epoch:12 step:48150[D loss: 1.000006] [G loss: 1.000016]\n",
      "epoch:12 step:48155[D loss: 0.999931] [G loss: 1.000097]\n",
      "epoch:12 step:48160[D loss: 0.999971] [G loss: 1.000063]\n",
      "epoch:12 step:48165[D loss: 0.999970] [G loss: 1.000099]\n",
      "epoch:12 step:48170[D loss: 0.999954] [G loss: 1.000096]\n",
      "epoch:12 step:48175[D loss: 0.999963] [G loss: 1.000027]\n",
      "epoch:12 step:48180[D loss: 0.999957] [G loss: 1.000019]\n",
      "epoch:12 step:48185[D loss: 1.000039] [G loss: 0.999921]\n",
      "epoch:12 step:48190[D loss: 0.999943] [G loss: 1.000064]\n",
      "epoch:12 step:48195[D loss: 1.000007] [G loss: 1.000018]\n",
      "epoch:12 step:48200[D loss: 1.000010] [G loss: 0.999997]\n",
      "##############\n",
      "[0.8804065  0.85976668 0.83117886 0.82813338 0.80206222 0.81977262\n",
      " 0.8664278  0.84401778 0.82941179 0.83171948]\n",
      "##########\n",
      "epoch:12 step:48205[D loss: 0.999946] [G loss: 1.000033]\n",
      "epoch:12 step:48210[D loss: 0.999963] [G loss: 1.000034]\n",
      "epoch:12 step:48215[D loss: 0.999970] [G loss: 1.000064]\n",
      "epoch:12 step:48220[D loss: 0.999974] [G loss: 1.000065]\n",
      "epoch:12 step:48225[D loss: 1.000020] [G loss: 1.000048]\n",
      "epoch:12 step:48230[D loss: 0.999959] [G loss: 1.000073]\n",
      "epoch:12 step:48235[D loss: 0.999973] [G loss: 1.000063]\n",
      "epoch:12 step:48240[D loss: 1.000019] [G loss: 1.000005]\n",
      "epoch:12 step:48245[D loss: 0.999927] [G loss: 1.000020]\n",
      "epoch:12 step:48250[D loss: 0.999936] [G loss: 1.000132]\n",
      "epoch:12 step:48255[D loss: 0.999945] [G loss: 1.000064]\n",
      "epoch:12 step:48260[D loss: 0.999947] [G loss: 1.000100]\n",
      "epoch:12 step:48265[D loss: 0.999981] [G loss: 1.000061]\n",
      "epoch:12 step:48270[D loss: 0.999995] [G loss: 1.000040]\n",
      "epoch:12 step:48275[D loss: 0.999985] [G loss: 1.000029]\n",
      "epoch:12 step:48280[D loss: 0.999955] [G loss: 1.000067]\n",
      "epoch:12 step:48285[D loss: 1.000008] [G loss: 1.000028]\n",
      "epoch:12 step:48290[D loss: 1.000009] [G loss: 1.000010]\n",
      "epoch:12 step:48295[D loss: 0.999960] [G loss: 1.000014]\n",
      "epoch:12 step:48300[D loss: 0.999975] [G loss: 1.000049]\n",
      "epoch:12 step:48305[D loss: 0.999973] [G loss: 1.000082]\n",
      "epoch:12 step:48310[D loss: 0.999995] [G loss: 1.000034]\n",
      "epoch:12 step:48315[D loss: 0.999976] [G loss: 1.000036]\n",
      "epoch:12 step:48320[D loss: 1.000000] [G loss: 1.000028]\n",
      "epoch:12 step:48325[D loss: 0.999981] [G loss: 1.000063]\n",
      "epoch:12 step:48330[D loss: 0.999946] [G loss: 1.000090]\n",
      "epoch:12 step:48335[D loss: 0.999970] [G loss: 1.000099]\n",
      "epoch:12 step:48340[D loss: 0.999977] [G loss: 1.000078]\n",
      "epoch:12 step:48345[D loss: 1.000013] [G loss: 0.999926]\n",
      "epoch:12 step:48350[D loss: 1.000004] [G loss: 1.000011]\n",
      "epoch:12 step:48355[D loss: 1.000086] [G loss: 0.999899]\n",
      "epoch:12 step:48360[D loss: 0.999930] [G loss: 1.000095]\n",
      "epoch:12 step:48365[D loss: 0.999963] [G loss: 1.000085]\n",
      "epoch:12 step:48370[D loss: 0.999987] [G loss: 1.000071]\n",
      "epoch:12 step:48375[D loss: 0.999969] [G loss: 1.000082]\n",
      "epoch:12 step:48380[D loss: 0.999972] [G loss: 1.000067]\n",
      "epoch:12 step:48385[D loss: 0.999972] [G loss: 1.000064]\n",
      "epoch:12 step:48390[D loss: 1.000001] [G loss: 1.000063]\n",
      "epoch:12 step:48395[D loss: 0.999959] [G loss: 1.000061]\n",
      "epoch:12 step:48400[D loss: 0.999980] [G loss: 1.000105]\n",
      "##############\n",
      "[0.86491838 0.84789765 0.814885   0.80956307 0.79867511 0.82907061\n",
      " 0.87715247 0.83449677 0.8407282  0.82824631]\n",
      "##########\n",
      "epoch:12 step:48405[D loss: 0.999968] [G loss: 1.000094]\n",
      "epoch:12 step:48410[D loss: 0.999962] [G loss: 1.000129]\n",
      "epoch:12 step:48415[D loss: 0.999954] [G loss: 1.000113]\n",
      "epoch:12 step:48420[D loss: 0.999972] [G loss: 1.000077]\n",
      "epoch:12 step:48425[D loss: 0.999981] [G loss: 1.000056]\n",
      "epoch:12 step:48430[D loss: 1.000017] [G loss: 1.000002]\n",
      "epoch:12 step:48435[D loss: 1.000112] [G loss: 0.999905]\n",
      "epoch:12 step:48440[D loss: 0.999950] [G loss: 1.000179]\n",
      "epoch:12 step:48445[D loss: 0.999939] [G loss: 1.000115]\n",
      "epoch:12 step:48450[D loss: 0.999993] [G loss: 1.000063]\n",
      "epoch:12 step:48455[D loss: 0.999965] [G loss: 1.000068]\n",
      "epoch:12 step:48460[D loss: 0.999964] [G loss: 1.000026]\n",
      "epoch:12 step:48465[D loss: 1.000005] [G loss: 0.999994]\n",
      "epoch:12 step:48470[D loss: 0.999898] [G loss: 1.000072]\n",
      "epoch:12 step:48475[D loss: 0.999955] [G loss: 1.000049]\n",
      "epoch:12 step:48480[D loss: 1.000011] [G loss: 1.000022]\n",
      "epoch:12 step:48485[D loss: 1.000025] [G loss: 1.000005]\n",
      "epoch:12 step:48490[D loss: 0.999932] [G loss: 1.000082]\n",
      "epoch:12 step:48495[D loss: 0.999972] [G loss: 1.000068]\n",
      "epoch:12 step:48500[D loss: 0.999976] [G loss: 1.000051]\n",
      "epoch:12 step:48505[D loss: 1.000067] [G loss: 0.999986]\n",
      "epoch:12 step:48510[D loss: 0.999895] [G loss: 1.000127]\n",
      "epoch:12 step:48515[D loss: 0.999944] [G loss: 1.000127]\n",
      "epoch:12 step:48520[D loss: 0.999995] [G loss: 1.000063]\n",
      "epoch:12 step:48525[D loss: 0.999961] [G loss: 1.000081]\n",
      "epoch:12 step:48530[D loss: 0.999963] [G loss: 1.000087]\n",
      "epoch:12 step:48535[D loss: 0.999978] [G loss: 1.000081]\n",
      "epoch:12 step:48540[D loss: 0.999980] [G loss: 1.000095]\n",
      "epoch:12 step:48545[D loss: 0.999997] [G loss: 1.000063]\n",
      "epoch:12 step:48550[D loss: 1.000071] [G loss: 0.999917]\n",
      "epoch:12 step:48555[D loss: 0.999991] [G loss: 1.000097]\n",
      "epoch:12 step:48560[D loss: 0.999944] [G loss: 1.000078]\n",
      "epoch:12 step:48565[D loss: 0.999962] [G loss: 1.000100]\n",
      "epoch:12 step:48570[D loss: 0.999971] [G loss: 1.000078]\n",
      "epoch:12 step:48575[D loss: 0.999996] [G loss: 1.000014]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:12 step:48580[D loss: 0.999976] [G loss: 1.000048]\n",
      "epoch:12 step:48585[D loss: 1.000031] [G loss: 0.999981]\n",
      "epoch:12 step:48590[D loss: 0.999976] [G loss: 1.000002]\n",
      "epoch:12 step:48595[D loss: 0.999973] [G loss: 1.000066]\n",
      "epoch:12 step:48600[D loss: 0.999957] [G loss: 1.000087]\n",
      "##############\n",
      "[0.87588377 0.84577336 0.82564449 0.84949431 0.82472206 0.83425879\n",
      " 0.88785356 0.823762   0.81339165 0.84679534]\n",
      "##########\n",
      "epoch:12 step:48605[D loss: 0.999964] [G loss: 1.000030]\n",
      "epoch:12 step:48610[D loss: 0.999990] [G loss: 1.000001]\n",
      "epoch:12 step:48615[D loss: 0.999990] [G loss: 1.000047]\n",
      "epoch:12 step:48620[D loss: 1.000002] [G loss: 1.000006]\n",
      "epoch:12 step:48625[D loss: 0.999962] [G loss: 1.000048]\n",
      "epoch:12 step:48630[D loss: 0.999974] [G loss: 1.000024]\n",
      "epoch:12 step:48635[D loss: 0.999970] [G loss: 1.000063]\n",
      "epoch:12 step:48640[D loss: 0.999981] [G loss: 1.000061]\n",
      "epoch:12 step:48645[D loss: 0.999981] [G loss: 1.000029]\n",
      "epoch:12 step:48650[D loss: 0.999970] [G loss: 1.000045]\n",
      "epoch:12 step:48655[D loss: 0.999962] [G loss: 1.000056]\n",
      "epoch:12 step:48660[D loss: 0.999966] [G loss: 1.000058]\n",
      "epoch:12 step:48665[D loss: 1.000018] [G loss: 1.000005]\n",
      "epoch:12 step:48670[D loss: 0.999967] [G loss: 1.000043]\n",
      "epoch:12 step:48675[D loss: 0.999985] [G loss: 1.000138]\n",
      "epoch:12 step:48680[D loss: 0.999933] [G loss: 1.000084]\n",
      "epoch:12 step:48685[D loss: 0.999995] [G loss: 1.000037]\n",
      "epoch:12 step:48690[D loss: 0.999978] [G loss: 1.000046]\n",
      "epoch:12 step:48695[D loss: 0.999990] [G loss: 1.000044]\n",
      "epoch:12 step:48700[D loss: 0.999910] [G loss: 1.000163]\n",
      "epoch:12 step:48705[D loss: 0.999955] [G loss: 1.000022]\n",
      "epoch:12 step:48710[D loss: 0.999986] [G loss: 1.000032]\n",
      "epoch:12 step:48715[D loss: 0.999974] [G loss: 1.000003]\n",
      "epoch:12 step:48720[D loss: 0.999980] [G loss: 0.999993]\n",
      "epoch:12 step:48725[D loss: 0.999990] [G loss: 1.000070]\n",
      "epoch:12 step:48730[D loss: 0.999974] [G loss: 1.000086]\n",
      "epoch:12 step:48735[D loss: 0.999958] [G loss: 1.000060]\n",
      "epoch:12 step:48740[D loss: 0.999988] [G loss: 1.000017]\n",
      "epoch:12 step:48745[D loss: 1.000015] [G loss: 1.000047]\n",
      "epoch:12 step:48750[D loss: 0.999972] [G loss: 0.999975]\n",
      "epoch:12 step:48755[D loss: 0.999889] [G loss: 1.000142]\n",
      "epoch:12 step:48760[D loss: 0.999986] [G loss: 1.000067]\n",
      "epoch:12 step:48765[D loss: 1.000058] [G loss: 0.999960]\n",
      "epoch:12 step:48770[D loss: 1.000015] [G loss: 1.000103]\n",
      "epoch:12 step:48775[D loss: 0.999962] [G loss: 1.000120]\n",
      "epoch:12 step:48780[D loss: 0.999973] [G loss: 1.000080]\n",
      "epoch:12 step:48785[D loss: 0.999945] [G loss: 1.000091]\n",
      "epoch:12 step:48790[D loss: 1.000031] [G loss: 0.999975]\n",
      "epoch:12 step:48795[D loss: 0.999979] [G loss: 1.000073]\n",
      "epoch:12 step:48800[D loss: 0.999973] [G loss: 1.000042]\n",
      "##############\n",
      "[0.8598577  0.85515829 0.83134028 0.8168119  0.8027866  0.84228711\n",
      " 0.87562219 0.85748257 0.82867596 0.84509995]\n",
      "##########\n",
      "epoch:12 step:48805[D loss: 0.999965] [G loss: 1.000044]\n",
      "epoch:12 step:48810[D loss: 0.999961] [G loss: 1.000074]\n",
      "epoch:12 step:48815[D loss: 1.000019] [G loss: 1.000030]\n",
      "epoch:12 step:48820[D loss: 0.999970] [G loss: 1.000051]\n",
      "epoch:12 step:48825[D loss: 0.999995] [G loss: 0.999985]\n",
      "epoch:12 step:48830[D loss: 0.999967] [G loss: 1.000065]\n",
      "epoch:12 step:48835[D loss: 1.000050] [G loss: 1.000062]\n",
      "epoch:12 step:48840[D loss: 0.999953] [G loss: 1.000168]\n",
      "epoch:12 step:48845[D loss: 0.999968] [G loss: 1.000078]\n",
      "epoch:12 step:48850[D loss: 0.999960] [G loss: 1.000103]\n",
      "epoch:12 step:48855[D loss: 1.000039] [G loss: 0.999987]\n",
      "epoch:12 step:48860[D loss: 0.999950] [G loss: 1.000074]\n",
      "epoch:12 step:48865[D loss: 0.999954] [G loss: 1.000082]\n",
      "epoch:12 step:48870[D loss: 1.000047] [G loss: 0.999939]\n",
      "epoch:12 step:48875[D loss: 0.999974] [G loss: 1.000110]\n",
      "epoch:12 step:48880[D loss: 0.999949] [G loss: 1.000076]\n",
      "epoch:12 step:48885[D loss: 0.999972] [G loss: 1.000057]\n",
      "epoch:12 step:48890[D loss: 0.999996] [G loss: 1.000010]\n",
      "epoch:12 step:48895[D loss: 1.000002] [G loss: 1.000015]\n",
      "epoch:12 step:48900[D loss: 1.000021] [G loss: 1.000024]\n",
      "epoch:12 step:48905[D loss: 1.000078] [G loss: 0.999871]\n",
      "epoch:12 step:48910[D loss: 1.000033] [G loss: 0.999945]\n",
      "epoch:12 step:48915[D loss: 0.999951] [G loss: 1.000091]\n",
      "epoch:12 step:48920[D loss: 0.999938] [G loss: 1.000173]\n",
      "epoch:12 step:48925[D loss: 0.999989] [G loss: 1.000063]\n",
      "epoch:12 step:48930[D loss: 1.000070] [G loss: 0.999891]\n",
      "epoch:12 step:48935[D loss: 1.000073] [G loss: 0.999839]\n",
      "epoch:12 step:48940[D loss: 0.999961] [G loss: 1.000138]\n",
      "epoch:12 step:48945[D loss: 1.000030] [G loss: 0.999918]\n",
      "epoch:12 step:48950[D loss: 0.999970] [G loss: 0.999999]\n",
      "epoch:12 step:48955[D loss: 0.999946] [G loss: 1.000128]\n",
      "epoch:12 step:48960[D loss: 0.999993] [G loss: 1.000090]\n",
      "epoch:12 step:48965[D loss: 0.999925] [G loss: 1.000118]\n",
      "epoch:12 step:48970[D loss: 0.999972] [G loss: 1.000076]\n",
      "epoch:12 step:48975[D loss: 0.999972] [G loss: 1.000060]\n",
      "epoch:12 step:48980[D loss: 1.000067] [G loss: 0.999886]\n",
      "epoch:12 step:48985[D loss: 1.000005] [G loss: 1.000000]\n",
      "epoch:12 step:48990[D loss: 1.000023] [G loss: 0.999943]\n",
      "epoch:12 step:48995[D loss: 1.000038] [G loss: 0.999993]\n",
      "epoch:12 step:49000[D loss: 0.999961] [G loss: 1.000056]\n",
      "##############\n",
      "[0.86454586 0.84703789 0.84624214 0.83239221 0.80849919 0.84015912\n",
      " 0.85419812 0.82676283 0.81689749 0.84366168]\n",
      "##########\n",
      "epoch:12 step:49005[D loss: 0.999983] [G loss: 1.000065]\n",
      "epoch:12 step:49010[D loss: 0.999969] [G loss: 1.000034]\n",
      "epoch:12 step:49015[D loss: 0.999957] [G loss: 1.000078]\n",
      "epoch:12 step:49020[D loss: 0.999970] [G loss: 1.000038]\n",
      "epoch:12 step:49025[D loss: 0.999997] [G loss: 1.000023]\n",
      "epoch:12 step:49030[D loss: 0.999977] [G loss: 1.000037]\n",
      "epoch:12 step:49035[D loss: 0.999992] [G loss: 1.000039]\n",
      "epoch:12 step:49040[D loss: 0.999997] [G loss: 1.000027]\n",
      "epoch:12 step:49045[D loss: 0.999979] [G loss: 1.000042]\n",
      "epoch:12 step:49050[D loss: 1.000001] [G loss: 1.000024]\n",
      "epoch:12 step:49055[D loss: 0.999980] [G loss: 1.000031]\n",
      "epoch:12 step:49060[D loss: 0.999972] [G loss: 1.000048]\n",
      "epoch:12 step:49065[D loss: 0.999962] [G loss: 1.000121]\n",
      "epoch:12 step:49070[D loss: 0.999973] [G loss: 1.000035]\n",
      "epoch:12 step:49075[D loss: 0.999966] [G loss: 1.000033]\n",
      "epoch:12 step:49080[D loss: 0.999980] [G loss: 1.000002]\n",
      "epoch:12 step:49085[D loss: 0.999974] [G loss: 1.000040]\n",
      "epoch:12 step:49090[D loss: 1.000015] [G loss: 0.999947]\n",
      "epoch:12 step:49095[D loss: 0.999992] [G loss: 1.000048]\n",
      "epoch:12 step:49100[D loss: 1.000030] [G loss: 1.000108]\n",
      "epoch:12 step:49105[D loss: 0.999964] [G loss: 1.000000]\n",
      "epoch:12 step:49110[D loss: 1.000011] [G loss: 1.000112]\n",
      "epoch:12 step:49115[D loss: 0.999938] [G loss: 1.000117]\n",
      "epoch:12 step:49120[D loss: 0.999971] [G loss: 1.000041]\n",
      "epoch:12 step:49125[D loss: 1.000037] [G loss: 0.999945]\n",
      "epoch:12 step:49130[D loss: 1.000019] [G loss: 0.999839]\n",
      "epoch:12 step:49135[D loss: 0.999983] [G loss: 1.000107]\n",
      "epoch:12 step:49140[D loss: 1.000054] [G loss: 0.999940]\n",
      "epoch:12 step:49145[D loss: 0.999925] [G loss: 1.000120]\n",
      "epoch:12 step:49150[D loss: 0.999958] [G loss: 1.000056]\n",
      "epoch:12 step:49155[D loss: 0.999972] [G loss: 1.000059]\n",
      "epoch:12 step:49160[D loss: 0.999972] [G loss: 1.000082]\n",
      "epoch:12 step:49165[D loss: 0.999954] [G loss: 1.000119]\n",
      "epoch:12 step:49170[D loss: 0.999935] [G loss: 1.000130]\n",
      "epoch:12 step:49175[D loss: 0.999977] [G loss: 1.000080]\n",
      "epoch:12 step:49180[D loss: 0.999966] [G loss: 1.000076]\n",
      "epoch:12 step:49185[D loss: 0.999975] [G loss: 1.000069]\n",
      "epoch:12 step:49190[D loss: 0.999942] [G loss: 1.000122]\n",
      "epoch:12 step:49195[D loss: 0.999957] [G loss: 1.000109]\n",
      "epoch:12 step:49200[D loss: 0.999976] [G loss: 1.000062]\n",
      "##############\n",
      "[0.86298271 0.85891773 0.80442382 0.84992141 0.79357683 0.85729081\n",
      " 0.88652021 0.83239614 0.82789478 0.83928051]\n",
      "##########\n",
      "epoch:12 step:49205[D loss: 1.000007] [G loss: 1.000093]\n",
      "epoch:12 step:49210[D loss: 0.999989] [G loss: 1.000078]\n",
      "epoch:12 step:49215[D loss: 0.999977] [G loss: 1.000048]\n",
      "epoch:12 step:49220[D loss: 0.999959] [G loss: 1.000099]\n",
      "epoch:12 step:49225[D loss: 0.999973] [G loss: 1.000091]\n",
      "epoch:12 step:49230[D loss: 1.000017] [G loss: 0.999992]\n",
      "epoch:12 step:49235[D loss: 0.999963] [G loss: 1.000038]\n",
      "epoch:12 step:49240[D loss: 0.999970] [G loss: 1.000064]\n",
      "epoch:12 step:49245[D loss: 0.999980] [G loss: 1.000068]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:12 step:49250[D loss: 0.999963] [G loss: 1.000067]\n",
      "epoch:12 step:49255[D loss: 0.999989] [G loss: 1.000059]\n",
      "epoch:12 step:49260[D loss: 0.999980] [G loss: 1.000071]\n",
      "epoch:12 step:49265[D loss: 0.999965] [G loss: 1.000075]\n",
      "epoch:12 step:49270[D loss: 0.999955] [G loss: 1.000080]\n",
      "epoch:12 step:49275[D loss: 0.999976] [G loss: 1.000121]\n",
      "epoch:12 step:49280[D loss: 0.999983] [G loss: 1.000057]\n",
      "epoch:12 step:49285[D loss: 0.999970] [G loss: 1.000083]\n",
      "epoch:12 step:49290[D loss: 0.999967] [G loss: 1.000085]\n",
      "epoch:12 step:49295[D loss: 0.999962] [G loss: 1.000090]\n",
      "epoch:12 step:49300[D loss: 0.999978] [G loss: 1.000073]\n",
      "epoch:12 step:49305[D loss: 0.999985] [G loss: 1.000064]\n",
      "epoch:12 step:49310[D loss: 0.999968] [G loss: 1.000064]\n",
      "epoch:12 step:49315[D loss: 0.999998] [G loss: 1.000041]\n",
      "epoch:12 step:49320[D loss: 0.999979] [G loss: 1.000076]\n",
      "epoch:12 step:49325[D loss: 1.000040] [G loss: 1.000051]\n",
      "epoch:12 step:49330[D loss: 0.999956] [G loss: 1.000054]\n",
      "epoch:12 step:49335[D loss: 0.999979] [G loss: 1.000068]\n",
      "epoch:12 step:49340[D loss: 0.999984] [G loss: 1.000012]\n",
      "epoch:12 step:49345[D loss: 1.000024] [G loss: 0.999950]\n",
      "epoch:12 step:49350[D loss: 0.999979] [G loss: 1.000018]\n",
      "epoch:12 step:49355[D loss: 1.000010] [G loss: 0.999968]\n",
      "epoch:12 step:49360[D loss: 1.000044] [G loss: 1.000048]\n",
      "epoch:12 step:49365[D loss: 0.999990] [G loss: 1.000001]\n",
      "epoch:12 step:49370[D loss: 0.999992] [G loss: 1.000015]\n",
      "epoch:12 step:49375[D loss: 0.999993] [G loss: 1.000029]\n",
      "epoch:12 step:49380[D loss: 0.999957] [G loss: 1.000068]\n",
      "epoch:12 step:49385[D loss: 0.999951] [G loss: 1.000077]\n",
      "epoch:12 step:49390[D loss: 0.999972] [G loss: 1.000061]\n",
      "epoch:12 step:49395[D loss: 0.999951] [G loss: 1.000100]\n",
      "epoch:12 step:49400[D loss: 1.000003] [G loss: 1.000036]\n",
      "##############\n",
      "[0.87579438 0.85628335 0.81713571 0.83921128 0.81080224 0.8465613\n",
      " 0.87629699 0.82319614 0.81460714 0.82601616]\n",
      "##########\n",
      "epoch:12 step:49405[D loss: 0.999999] [G loss: 1.000109]\n",
      "epoch:12 step:49410[D loss: 1.000131] [G loss: 0.999868]\n",
      "epoch:12 step:49415[D loss: 1.000035] [G loss: 1.000064]\n",
      "epoch:12 step:49420[D loss: 0.999953] [G loss: 1.000148]\n",
      "epoch:12 step:49425[D loss: 0.999949] [G loss: 1.000109]\n",
      "epoch:12 step:49430[D loss: 1.000018] [G loss: 0.999898]\n",
      "epoch:12 step:49435[D loss: 1.000059] [G loss: 0.999940]\n",
      "epoch:12 step:49440[D loss: 1.000016] [G loss: 0.999935]\n",
      "epoch:12 step:49445[D loss: 1.000058] [G loss: 0.999845]\n",
      "epoch:12 step:49450[D loss: 0.999842] [G loss: 1.000267]\n",
      "epoch:12 step:49455[D loss: 0.999933] [G loss: 1.000108]\n",
      "epoch:12 step:49460[D loss: 0.999916] [G loss: 1.000157]\n",
      "epoch:12 step:49465[D loss: 0.999963] [G loss: 1.000144]\n",
      "epoch:12 step:49470[D loss: 0.999954] [G loss: 1.000047]\n",
      "epoch:12 step:49475[D loss: 1.000035] [G loss: 0.999967]\n",
      "epoch:12 step:49480[D loss: 1.000021] [G loss: 0.999903]\n",
      "epoch:12 step:49485[D loss: 1.000009] [G loss: 1.000002]\n",
      "epoch:12 step:49490[D loss: 0.999942] [G loss: 1.000042]\n",
      "epoch:12 step:49495[D loss: 0.999970] [G loss: 1.000064]\n",
      "epoch:12 step:49500[D loss: 0.999960] [G loss: 1.000128]\n",
      "epoch:12 step:49505[D loss: 0.999921] [G loss: 1.000172]\n",
      "epoch:12 step:49510[D loss: 0.999959] [G loss: 1.000176]\n",
      "epoch:12 step:49515[D loss: 0.999954] [G loss: 1.000123]\n",
      "epoch:12 step:49520[D loss: 0.999957] [G loss: 1.000123]\n",
      "epoch:12 step:49525[D loss: 1.000020] [G loss: 1.000114]\n",
      "epoch:12 step:49530[D loss: 0.999952] [G loss: 1.000107]\n",
      "epoch:12 step:49535[D loss: 1.000020] [G loss: 1.000009]\n",
      "epoch:12 step:49540[D loss: 1.000001] [G loss: 0.999996]\n",
      "epoch:12 step:49545[D loss: 0.999991] [G loss: 1.000052]\n",
      "epoch:12 step:49550[D loss: 1.000079] [G loss: 0.999919]\n",
      "epoch:12 step:49555[D loss: 0.999956] [G loss: 1.000044]\n",
      "epoch:12 step:49560[D loss: 0.999973] [G loss: 1.000061]\n",
      "epoch:12 step:49565[D loss: 0.999975] [G loss: 1.000048]\n",
      "epoch:12 step:49570[D loss: 0.999995] [G loss: 1.000011]\n",
      "epoch:12 step:49575[D loss: 0.999985] [G loss: 1.000002]\n",
      "epoch:12 step:49580[D loss: 0.999988] [G loss: 1.000030]\n",
      "epoch:12 step:49585[D loss: 0.999975] [G loss: 1.000019]\n",
      "epoch:12 step:49590[D loss: 1.000012] [G loss: 1.000018]\n",
      "epoch:12 step:49595[D loss: 0.999966] [G loss: 1.000055]\n",
      "epoch:12 step:49600[D loss: 0.999988] [G loss: 1.000053]\n",
      "##############\n",
      "[0.88419638 0.85510415 0.80930665 0.84530168 0.80188777 0.83771908\n",
      " 0.86688956 0.84329292 0.82076625 0.85257168]\n",
      "##########\n",
      "epoch:12 step:49605[D loss: 0.999972] [G loss: 1.000056]\n",
      "epoch:12 step:49610[D loss: 0.999961] [G loss: 1.000110]\n",
      "epoch:12 step:49615[D loss: 0.999969] [G loss: 1.000078]\n",
      "epoch:12 step:49620[D loss: 0.999987] [G loss: 1.000012]\n",
      "epoch:12 step:49625[D loss: 1.000003] [G loss: 1.000057]\n",
      "epoch:12 step:49630[D loss: 0.999974] [G loss: 1.000085]\n",
      "epoch:12 step:49635[D loss: 0.999952] [G loss: 1.000098]\n",
      "epoch:12 step:49640[D loss: 0.999966] [G loss: 1.000092]\n",
      "epoch:12 step:49645[D loss: 0.999961] [G loss: 1.000173]\n",
      "epoch:12 step:49650[D loss: 0.999939] [G loss: 1.000107]\n",
      "epoch:12 step:49655[D loss: 1.000042] [G loss: 0.999966]\n",
      "epoch:12 step:49660[D loss: 0.999976] [G loss: 1.000044]\n",
      "epoch:12 step:49665[D loss: 1.000020] [G loss: 1.000067]\n",
      "epoch:12 step:49670[D loss: 1.000032] [G loss: 1.000026]\n",
      "epoch:12 step:49675[D loss: 0.999947] [G loss: 1.000099]\n",
      "epoch:12 step:49680[D loss: 0.999951] [G loss: 1.000088]\n",
      "epoch:12 step:49685[D loss: 0.999974] [G loss: 1.000080]\n",
      "epoch:12 step:49690[D loss: 0.999970] [G loss: 1.000067]\n",
      "epoch:12 step:49695[D loss: 1.000022] [G loss: 0.999988]\n",
      "epoch:12 step:49700[D loss: 0.999976] [G loss: 1.000106]\n",
      "epoch:12 step:49705[D loss: 0.999969] [G loss: 1.000074]\n",
      "epoch:12 step:49710[D loss: 1.000019] [G loss: 0.999968]\n",
      "epoch:12 step:49715[D loss: 1.000005] [G loss: 1.000002]\n",
      "epoch:12 step:49720[D loss: 0.999963] [G loss: 1.000088]\n",
      "epoch:12 step:49725[D loss: 0.999969] [G loss: 1.000060]\n",
      "epoch:12 step:49730[D loss: 0.999985] [G loss: 1.000061]\n",
      "epoch:12 step:49735[D loss: 1.000027] [G loss: 1.000007]\n",
      "epoch:12 step:49740[D loss: 0.999975] [G loss: 1.000105]\n",
      "epoch:12 step:49745[D loss: 1.000070] [G loss: 0.999938]\n",
      "epoch:12 step:49750[D loss: 0.999892] [G loss: 1.000151]\n",
      "epoch:12 step:49755[D loss: 0.999967] [G loss: 1.000122]\n",
      "epoch:12 step:49760[D loss: 0.999961] [G loss: 1.000042]\n",
      "epoch:12 step:49765[D loss: 0.999973] [G loss: 1.000061]\n",
      "epoch:12 step:49770[D loss: 1.000107] [G loss: 0.999956]\n",
      "epoch:12 step:49775[D loss: 1.000006] [G loss: 0.999987]\n",
      "epoch:12 step:49780[D loss: 1.000109] [G loss: 0.999983]\n",
      "epoch:12 step:49785[D loss: 1.000025] [G loss: 0.999903]\n",
      "epoch:12 step:49790[D loss: 0.999987] [G loss: 1.000035]\n",
      "epoch:12 step:49795[D loss: 0.999907] [G loss: 1.000113]\n",
      "epoch:12 step:49800[D loss: 0.999967] [G loss: 1.000082]\n",
      "##############\n",
      "[0.858784   0.84180741 0.81762527 0.82671912 0.82039542 0.86730315\n",
      " 0.88087413 0.8411014  0.82835295 0.85114869]\n",
      "##########\n",
      "epoch:12 step:49805[D loss: 0.999966] [G loss: 1.000061]\n",
      "epoch:12 step:49810[D loss: 0.999980] [G loss: 1.000057]\n",
      "epoch:12 step:49815[D loss: 0.999992] [G loss: 1.000079]\n",
      "epoch:12 step:49820[D loss: 0.999994] [G loss: 1.000019]\n",
      "epoch:12 step:49825[D loss: 0.999955] [G loss: 1.000083]\n",
      "epoch:12 step:49830[D loss: 0.999980] [G loss: 1.000049]\n",
      "epoch:12 step:49835[D loss: 1.000052] [G loss: 0.999995]\n",
      "epoch:12 step:49840[D loss: 0.999984] [G loss: 1.000042]\n",
      "epoch:12 step:49845[D loss: 0.999965] [G loss: 1.000070]\n",
      "epoch:12 step:49850[D loss: 0.999968] [G loss: 1.000066]\n",
      "epoch:12 step:49855[D loss: 0.999936] [G loss: 1.000113]\n",
      "epoch:12 step:49860[D loss: 0.999996] [G loss: 1.000071]\n",
      "epoch:12 step:49865[D loss: 0.999921] [G loss: 1.000195]\n",
      "epoch:12 step:49870[D loss: 0.999979] [G loss: 1.000051]\n",
      "epoch:12 step:49875[D loss: 1.000031] [G loss: 1.000029]\n",
      "epoch:12 step:49880[D loss: 1.000003] [G loss: 1.000132]\n",
      "epoch:12 step:49885[D loss: 0.999993] [G loss: 1.000110]\n",
      "epoch:12 step:49890[D loss: 0.999965] [G loss: 1.000112]\n",
      "epoch:12 step:49895[D loss: 0.999971] [G loss: 1.000162]\n",
      "epoch:12 step:49900[D loss: 0.999997] [G loss: 1.000032]\n",
      "epoch:12 step:49905[D loss: 1.000050] [G loss: 1.000028]\n",
      "epoch:12 step:49910[D loss: 1.000138] [G loss: 0.999839]\n",
      "epoch:12 step:49915[D loss: 0.999915] [G loss: 1.000107]\n",
      "epoch:12 step:49920[D loss: 0.999970] [G loss: 1.000075]\n",
      "epoch:12 step:49925[D loss: 0.999911] [G loss: 1.000253]\n",
      "epoch:12 step:49930[D loss: 0.999914] [G loss: 1.000182]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:12 step:49935[D loss: 0.999949] [G loss: 1.000139]\n",
      "epoch:12 step:49940[D loss: 0.999972] [G loss: 1.000090]\n",
      "epoch:12 step:49945[D loss: 1.000010] [G loss: 1.000065]\n",
      "epoch:12 step:49950[D loss: 0.999976] [G loss: 1.000058]\n",
      "epoch:12 step:49955[D loss: 0.999957] [G loss: 1.000089]\n",
      "epoch:12 step:49960[D loss: 0.999999] [G loss: 1.000100]\n",
      "epoch:12 step:49965[D loss: 1.000013] [G loss: 1.000099]\n",
      "epoch:12 step:49970[D loss: 0.999981] [G loss: 1.000146]\n",
      "epoch:12 step:49975[D loss: 0.999964] [G loss: 1.000128]\n",
      "epoch:12 step:49980[D loss: 0.999999] [G loss: 1.000093]\n",
      "epoch:12 step:49985[D loss: 0.999971] [G loss: 1.000077]\n",
      "epoch:12 step:49990[D loss: 0.999971] [G loss: 1.000106]\n",
      "epoch:12 step:49995[D loss: 0.999993] [G loss: 1.000050]\n",
      "epoch:12 step:50000[D loss: 1.000069] [G loss: 0.999910]\n",
      "##############\n",
      "[0.8827121  0.85008984 0.82409655 0.81511853 0.79327612 0.84198561\n",
      " 0.87495014 0.83788697 0.8252498  0.85249725]\n",
      "##########\n",
      "epoch:12 step:50005[D loss: 1.000162] [G loss: 0.999865]\n",
      "epoch:12 step:50010[D loss: 0.999888] [G loss: 1.000234]\n",
      "epoch:12 step:50015[D loss: 0.999918] [G loss: 1.000072]\n",
      "epoch:12 step:50020[D loss: 0.999985] [G loss: 1.000107]\n",
      "epoch:12 step:50025[D loss: 0.999981] [G loss: 1.000078]\n",
      "epoch:12 step:50030[D loss: 0.999992] [G loss: 1.000038]\n",
      "epoch:12 step:50035[D loss: 0.999955] [G loss: 1.000073]\n",
      "epoch:12 step:50040[D loss: 0.999986] [G loss: 1.000044]\n",
      "epoch:12 step:50045[D loss: 0.999988] [G loss: 1.000016]\n",
      "epoch:12 step:50050[D loss: 1.000058] [G loss: 0.999930]\n",
      "epoch:12 step:50055[D loss: 0.999952] [G loss: 1.000124]\n",
      "epoch:12 step:50060[D loss: 0.999950] [G loss: 1.000091]\n",
      "epoch:12 step:50065[D loss: 0.999969] [G loss: 1.000053]\n",
      "epoch:12 step:50070[D loss: 0.999970] [G loss: 1.000066]\n",
      "epoch:12 step:50075[D loss: 0.999971] [G loss: 1.000073]\n",
      "epoch:12 step:50080[D loss: 0.999962] [G loss: 1.000073]\n",
      "epoch:12 step:50085[D loss: 0.999967] [G loss: 1.000078]\n",
      "epoch:12 step:50090[D loss: 0.999969] [G loss: 1.000101]\n",
      "epoch:12 step:50095[D loss: 0.999973] [G loss: 1.000085]\n",
      "epoch:12 step:50100[D loss: 0.999978] [G loss: 1.000046]\n",
      "epoch:12 step:50105[D loss: 0.999991] [G loss: 1.000021]\n",
      "epoch:12 step:50110[D loss: 0.999967] [G loss: 1.000076]\n",
      "epoch:12 step:50115[D loss: 1.000007] [G loss: 1.000032]\n",
      "epoch:12 step:50120[D loss: 0.999988] [G loss: 1.000057]\n",
      "epoch:12 step:50125[D loss: 0.999975] [G loss: 1.000079]\n",
      "epoch:12 step:50130[D loss: 1.000023] [G loss: 0.999951]\n",
      "epoch:12 step:50135[D loss: 0.999982] [G loss: 1.000064]\n",
      "epoch:12 step:50140[D loss: 0.999973] [G loss: 1.000087]\n",
      "epoch:12 step:50145[D loss: 0.999986] [G loss: 1.000061]\n",
      "epoch:12 step:50150[D loss: 0.999951] [G loss: 1.000148]\n",
      "epoch:12 step:50155[D loss: 0.999967] [G loss: 1.000122]\n",
      "epoch:12 step:50160[D loss: 0.999997] [G loss: 1.000034]\n",
      "epoch:12 step:50165[D loss: 0.999960] [G loss: 1.000138]\n",
      "epoch:12 step:50170[D loss: 0.999979] [G loss: 1.000010]\n",
      "epoch:12 step:50175[D loss: 1.000054] [G loss: 0.999873]\n",
      "epoch:12 step:50180[D loss: 0.999959] [G loss: 1.000045]\n",
      "epoch:12 step:50185[D loss: 0.999987] [G loss: 1.000029]\n",
      "epoch:12 step:50190[D loss: 0.999990] [G loss: 1.000020]\n",
      "epoch:12 step:50195[D loss: 0.999981] [G loss: 1.000036]\n",
      "epoch:12 step:50200[D loss: 0.999954] [G loss: 1.000050]\n",
      "##############\n",
      "[0.85987295 0.82368549 0.83382896 0.83726635 0.81000107 0.8316918\n",
      " 0.8727611  0.83694707 0.82619777 0.86720389]\n",
      "##########\n",
      "epoch:12 step:50205[D loss: 0.999990] [G loss: 1.000042]\n",
      "epoch:12 step:50210[D loss: 0.999980] [G loss: 1.000045]\n",
      "epoch:12 step:50215[D loss: 0.999977] [G loss: 1.000063]\n",
      "epoch:12 step:50220[D loss: 0.999956] [G loss: 1.000072]\n",
      "epoch:12 step:50225[D loss: 0.999988] [G loss: 1.000031]\n",
      "epoch:12 step:50230[D loss: 0.999965] [G loss: 1.000040]\n",
      "epoch:12 step:50235[D loss: 0.999955] [G loss: 1.000057]\n",
      "epoch:12 step:50240[D loss: 0.999978] [G loss: 1.000051]\n",
      "epoch:12 step:50245[D loss: 0.999993] [G loss: 1.000022]\n",
      "epoch:12 step:50250[D loss: 1.000029] [G loss: 0.999938]\n",
      "epoch:12 step:50255[D loss: 0.999958] [G loss: 1.000046]\n",
      "epoch:12 step:50260[D loss: 0.999962] [G loss: 1.000061]\n",
      "epoch:12 step:50265[D loss: 0.999959] [G loss: 1.000092]\n",
      "epoch:12 step:50270[D loss: 0.999994] [G loss: 1.000024]\n",
      "epoch:12 step:50275[D loss: 1.000021] [G loss: 1.000035]\n",
      "epoch:12 step:50280[D loss: 0.999971] [G loss: 1.000033]\n",
      "epoch:12 step:50285[D loss: 0.999983] [G loss: 1.000026]\n",
      "epoch:12 step:50290[D loss: 0.999967] [G loss: 1.000061]\n",
      "epoch:12 step:50295[D loss: 1.000095] [G loss: 0.999873]\n",
      "epoch:12 step:50300[D loss: 0.999967] [G loss: 1.000051]\n",
      "epoch:12 step:50305[D loss: 1.000069] [G loss: 1.000022]\n",
      "epoch:12 step:50310[D loss: 0.999950] [G loss: 1.000110]\n",
      "epoch:12 step:50315[D loss: 0.999953] [G loss: 1.000111]\n",
      "epoch:12 step:50320[D loss: 0.999989] [G loss: 1.000027]\n",
      "epoch:12 step:50325[D loss: 1.000017] [G loss: 0.999950]\n",
      "epoch:12 step:50330[D loss: 1.000023] [G loss: 0.999993]\n",
      "epoch:12 step:50335[D loss: 1.000099] [G loss: 0.999884]\n",
      "epoch:12 step:50340[D loss: 0.999981] [G loss: 1.000075]\n",
      "epoch:12 step:50345[D loss: 0.999922] [G loss: 1.000227]\n",
      "epoch:12 step:50350[D loss: 0.999916] [G loss: 1.000232]\n",
      "epoch:12 step:50355[D loss: 0.999976] [G loss: 1.000232]\n",
      "epoch:12 step:50360[D loss: 0.999953] [G loss: 1.000161]\n",
      "epoch:12 step:50365[D loss: 1.000065] [G loss: 0.999946]\n",
      "epoch:12 step:50370[D loss: 0.999951] [G loss: 1.000183]\n",
      "epoch:12 step:50375[D loss: 0.999912] [G loss: 1.000223]\n",
      "epoch:12 step:50380[D loss: 1.000010] [G loss: 1.000020]\n",
      "epoch:12 step:50385[D loss: 0.999965] [G loss: 1.000051]\n",
      "epoch:12 step:50390[D loss: 1.000108] [G loss: 0.999973]\n",
      "epoch:12 step:50395[D loss: 1.000035] [G loss: 1.000072]\n",
      "epoch:12 step:50400[D loss: 1.000001] [G loss: 0.999961]\n",
      "##############\n",
      "[0.85272736 0.85209616 0.82949776 0.81420722 0.82835392 0.84499172\n",
      " 0.86489384 0.84631393 0.81140305 0.84227864]\n",
      "##########\n",
      "epoch:12 step:50405[D loss: 0.999994] [G loss: 1.000055]\n",
      "epoch:12 step:50410[D loss: 0.999890] [G loss: 1.000206]\n",
      "epoch:12 step:50415[D loss: 0.999986] [G loss: 1.000024]\n",
      "epoch:12 step:50420[D loss: 0.999993] [G loss: 1.000139]\n",
      "epoch:12 step:50425[D loss: 0.999982] [G loss: 1.000036]\n",
      "epoch:12 step:50430[D loss: 0.999956] [G loss: 1.000101]\n",
      "epoch:12 step:50435[D loss: 1.000000] [G loss: 1.000023]\n",
      "epoch:12 step:50440[D loss: 1.000012] [G loss: 0.999985]\n",
      "epoch:12 step:50445[D loss: 0.999995] [G loss: 1.000062]\n",
      "epoch:12 step:50450[D loss: 0.999977] [G loss: 1.000014]\n",
      "epoch:12 step:50455[D loss: 0.999977] [G loss: 1.000052]\n",
      "epoch:12 step:50460[D loss: 0.999949] [G loss: 1.000089]\n",
      "epoch:12 step:50465[D loss: 0.999957] [G loss: 1.000062]\n",
      "epoch:12 step:50470[D loss: 0.999987] [G loss: 1.000066]\n",
      "epoch:12 step:50475[D loss: 0.999991] [G loss: 1.000054]\n",
      "epoch:12 step:50480[D loss: 0.999965] [G loss: 1.000074]\n",
      "epoch:12 step:50485[D loss: 0.999965] [G loss: 1.000063]\n",
      "epoch:12 step:50490[D loss: 0.999970] [G loss: 1.000056]\n",
      "epoch:12 step:50495[D loss: 0.999975] [G loss: 1.000096]\n",
      "epoch:12 step:50500[D loss: 0.999980] [G loss: 1.000035]\n",
      "epoch:12 step:50505[D loss: 0.999961] [G loss: 1.000084]\n",
      "epoch:12 step:50510[D loss: 0.999975] [G loss: 1.000078]\n",
      "epoch:12 step:50515[D loss: 0.999964] [G loss: 1.000097]\n",
      "epoch:12 step:50520[D loss: 0.999977] [G loss: 1.000071]\n",
      "epoch:12 step:50525[D loss: 0.999986] [G loss: 1.000085]\n",
      "epoch:12 step:50530[D loss: 0.999980] [G loss: 1.000059]\n",
      "epoch:12 step:50535[D loss: 0.999980] [G loss: 1.000050]\n",
      "epoch:12 step:50540[D loss: 0.999976] [G loss: 1.000048]\n",
      "epoch:12 step:50545[D loss: 0.999988] [G loss: 1.000059]\n",
      "epoch:12 step:50550[D loss: 0.999967] [G loss: 1.000103]\n",
      "epoch:12 step:50555[D loss: 0.999970] [G loss: 1.000117]\n",
      "epoch:12 step:50560[D loss: 0.999975] [G loss: 1.000060]\n",
      "epoch:12 step:50565[D loss: 0.999966] [G loss: 1.000080]\n",
      "epoch:12 step:50570[D loss: 1.000010] [G loss: 1.000033]\n",
      "epoch:12 step:50575[D loss: 0.999939] [G loss: 1.000081]\n",
      "epoch:12 step:50580[D loss: 0.999972] [G loss: 1.000064]\n",
      "epoch:12 step:50585[D loss: 0.999982] [G loss: 1.000048]\n",
      "epoch:12 step:50590[D loss: 0.999993] [G loss: 1.000012]\n",
      "epoch:12 step:50595[D loss: 0.999978] [G loss: 1.000064]\n",
      "epoch:12 step:50600[D loss: 0.999994] [G loss: 1.000080]\n",
      "##############\n",
      "[0.88335915 0.83839457 0.83183788 0.84061088 0.80755223 0.84550449\n",
      " 0.85854311 0.82108537 0.82249399 0.84156234]\n",
      "##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:12 step:50605[D loss: 1.000006] [G loss: 0.999987]\n",
      "epoch:12 step:50610[D loss: 0.999988] [G loss: 1.000089]\n",
      "epoch:12 step:50615[D loss: 0.999991] [G loss: 1.000086]\n",
      "epoch:12 step:50620[D loss: 0.999982] [G loss: 1.000026]\n",
      "epoch:12 step:50625[D loss: 0.999974] [G loss: 1.000088]\n",
      "epoch:12 step:50630[D loss: 1.000024] [G loss: 0.999964]\n",
      "epoch:12 step:50635[D loss: 0.999966] [G loss: 1.000068]\n",
      "epoch:12 step:50640[D loss: 0.999964] [G loss: 1.000101]\n",
      "epoch:12 step:50645[D loss: 0.999986] [G loss: 1.000084]\n",
      "epoch:12 step:50650[D loss: 0.999989] [G loss: 1.000043]\n",
      "epoch:12 step:50655[D loss: 0.999975] [G loss: 1.000144]\n",
      "epoch:12 step:50660[D loss: 0.999953] [G loss: 1.000101]\n",
      "epoch:12 step:50665[D loss: 0.999939] [G loss: 1.000196]\n",
      "epoch:12 step:50670[D loss: 0.999929] [G loss: 1.000201]\n",
      "epoch:12 step:50675[D loss: 0.999956] [G loss: 1.000118]\n",
      "epoch:12 step:50680[D loss: 0.999958] [G loss: 1.000198]\n",
      "epoch:12 step:50685[D loss: 1.000013] [G loss: 1.000061]\n",
      "epoch:12 step:50690[D loss: 0.999996] [G loss: 1.000033]\n",
      "epoch:12 step:50695[D loss: 0.999965] [G loss: 1.000079]\n",
      "epoch:12 step:50700[D loss: 0.999959] [G loss: 1.000101]\n",
      "epoch:12 step:50705[D loss: 1.000030] [G loss: 1.000079]\n",
      "epoch:12 step:50710[D loss: 1.000046] [G loss: 0.999979]\n",
      "epoch:12 step:50715[D loss: 0.999873] [G loss: 1.000231]\n",
      "epoch:12 step:50720[D loss: 1.000036] [G loss: 1.000034]\n",
      "epoch:12 step:50725[D loss: 0.999980] [G loss: 1.000115]\n",
      "epoch:12 step:50730[D loss: 1.000042] [G loss: 1.000121]\n",
      "epoch:12 step:50735[D loss: 0.999995] [G loss: 1.000115]\n",
      "epoch:12 step:50740[D loss: 0.999969] [G loss: 1.000123]\n",
      "epoch:12 step:50745[D loss: 1.000060] [G loss: 0.999868]\n",
      "epoch:12 step:50750[D loss: 1.000037] [G loss: 0.999917]\n",
      "epoch:12 step:50755[D loss: 0.999896] [G loss: 1.000133]\n",
      "epoch:12 step:50760[D loss: 0.999943] [G loss: 1.000137]\n",
      "epoch:12 step:50765[D loss: 0.999955] [G loss: 1.000113]\n",
      "epoch:13 step:50770[D loss: 0.999994] [G loss: 1.000012]\n",
      "epoch:13 step:50775[D loss: 0.999947] [G loss: 1.000071]\n",
      "epoch:13 step:50780[D loss: 0.999980] [G loss: 1.000035]\n",
      "epoch:13 step:50785[D loss: 1.000004] [G loss: 1.000030]\n",
      "epoch:13 step:50790[D loss: 0.999995] [G loss: 1.000048]\n",
      "epoch:13 step:50795[D loss: 0.999975] [G loss: 1.000047]\n",
      "epoch:13 step:50800[D loss: 0.999985] [G loss: 1.000072]\n",
      "##############\n",
      "[0.86275769 0.85208182 0.83721749 0.82112333 0.83421186 0.84848295\n",
      " 0.87056266 0.82470319 0.84271779 0.84113671]\n",
      "##########\n",
      "epoch:13 step:50805[D loss: 0.999963] [G loss: 1.000055]\n",
      "epoch:13 step:50810[D loss: 0.999982] [G loss: 1.000066]\n",
      "epoch:13 step:50815[D loss: 0.999993] [G loss: 1.000008]\n",
      "epoch:13 step:50820[D loss: 0.999996] [G loss: 1.000004]\n",
      "epoch:13 step:50825[D loss: 0.999962] [G loss: 1.000025]\n",
      "epoch:13 step:50830[D loss: 0.999953] [G loss: 1.000115]\n",
      "epoch:13 step:50835[D loss: 0.999933] [G loss: 1.000091]\n",
      "epoch:13 step:50840[D loss: 0.999995] [G loss: 1.000027]\n",
      "epoch:13 step:50845[D loss: 0.999977] [G loss: 1.000044]\n",
      "epoch:13 step:50850[D loss: 1.000004] [G loss: 0.999998]\n",
      "epoch:13 step:50855[D loss: 1.000017] [G loss: 1.000059]\n",
      "epoch:13 step:50860[D loss: 0.999962] [G loss: 1.000031]\n",
      "epoch:13 step:50865[D loss: 0.999938] [G loss: 1.000146]\n",
      "epoch:13 step:50870[D loss: 0.999964] [G loss: 1.000077]\n",
      "epoch:13 step:50875[D loss: 0.999967] [G loss: 1.000046]\n",
      "epoch:13 step:50880[D loss: 0.999979] [G loss: 1.000016]\n",
      "epoch:13 step:50885[D loss: 1.000111] [G loss: 0.999918]\n",
      "epoch:13 step:50890[D loss: 0.999976] [G loss: 0.999958]\n",
      "epoch:13 step:50895[D loss: 1.000030] [G loss: 0.999906]\n",
      "epoch:13 step:50900[D loss: 0.999945] [G loss: 1.000111]\n",
      "epoch:13 step:50905[D loss: 0.999980] [G loss: 1.000134]\n",
      "epoch:13 step:50910[D loss: 0.999913] [G loss: 1.000120]\n",
      "epoch:13 step:50915[D loss: 0.999977] [G loss: 1.000050]\n",
      "epoch:13 step:50920[D loss: 0.999972] [G loss: 1.000027]\n",
      "epoch:13 step:50925[D loss: 1.000057] [G loss: 0.999900]\n",
      "epoch:13 step:50930[D loss: 0.999943] [G loss: 1.000072]\n",
      "epoch:13 step:50935[D loss: 0.999952] [G loss: 1.000106]\n",
      "epoch:13 step:50940[D loss: 1.000042] [G loss: 0.999960]\n",
      "epoch:13 step:50945[D loss: 1.000059] [G loss: 0.999927]\n",
      "epoch:13 step:50950[D loss: 0.999984] [G loss: 1.000126]\n",
      "epoch:13 step:50955[D loss: 0.999924] [G loss: 1.000162]\n",
      "epoch:13 step:50960[D loss: 0.999976] [G loss: 1.000095]\n",
      "epoch:13 step:50965[D loss: 0.999970] [G loss: 1.000102]\n",
      "epoch:13 step:50970[D loss: 0.999978] [G loss: 1.000065]\n",
      "epoch:13 step:50975[D loss: 0.999998] [G loss: 1.000044]\n",
      "epoch:13 step:50980[D loss: 0.999966] [G loss: 1.000091]\n",
      "epoch:13 step:50985[D loss: 0.999940] [G loss: 1.000136]\n",
      "epoch:13 step:50990[D loss: 0.999970] [G loss: 1.000076]\n",
      "epoch:13 step:50995[D loss: 0.999975] [G loss: 1.000095]\n",
      "epoch:13 step:51000[D loss: 0.999983] [G loss: 1.000103]\n",
      "##############\n",
      "[0.84703714 0.84584435 0.84340502 0.82679707 0.7997373  0.84428963\n",
      " 0.88454868 0.83049298 0.8252574  0.84205921]\n",
      "##########\n",
      "epoch:13 step:51005[D loss: 0.999981] [G loss: 1.000082]\n",
      "epoch:13 step:51010[D loss: 0.999978] [G loss: 1.000133]\n",
      "epoch:13 step:51015[D loss: 0.999983] [G loss: 1.000062]\n",
      "epoch:13 step:51020[D loss: 0.999934] [G loss: 1.000128]\n",
      "epoch:13 step:51025[D loss: 0.999953] [G loss: 1.000094]\n",
      "epoch:13 step:51030[D loss: 0.999983] [G loss: 1.000081]\n",
      "epoch:13 step:51035[D loss: 0.999980] [G loss: 1.000075]\n",
      "epoch:13 step:51040[D loss: 0.999987] [G loss: 1.000061]\n",
      "epoch:13 step:51045[D loss: 0.999963] [G loss: 1.000111]\n",
      "epoch:13 step:51050[D loss: 0.999977] [G loss: 1.000057]\n",
      "epoch:13 step:51055[D loss: 0.999991] [G loss: 1.000049]\n",
      "epoch:13 step:51060[D loss: 0.999967] [G loss: 1.000053]\n",
      "epoch:13 step:51065[D loss: 0.999987] [G loss: 1.000089]\n",
      "epoch:13 step:51070[D loss: 0.999998] [G loss: 1.000038]\n",
      "epoch:13 step:51075[D loss: 0.999958] [G loss: 1.000086]\n",
      "epoch:13 step:51080[D loss: 0.999980] [G loss: 1.000077]\n",
      "epoch:13 step:51085[D loss: 0.999975] [G loss: 1.000074]\n",
      "epoch:13 step:51090[D loss: 0.999966] [G loss: 1.000096]\n",
      "epoch:13 step:51095[D loss: 0.999973] [G loss: 1.000074]\n",
      "epoch:13 step:51100[D loss: 0.999970] [G loss: 1.000089]\n",
      "epoch:13 step:51105[D loss: 0.999964] [G loss: 1.000111]\n",
      "epoch:13 step:51110[D loss: 1.000002] [G loss: 1.000081]\n",
      "epoch:13 step:51115[D loss: 0.999939] [G loss: 1.000144]\n",
      "epoch:13 step:51120[D loss: 0.999961] [G loss: 1.000114]\n",
      "epoch:13 step:51125[D loss: 0.999984] [G loss: 1.000071]\n",
      "epoch:13 step:51130[D loss: 1.000006] [G loss: 1.000070]\n",
      "epoch:13 step:51135[D loss: 0.999958] [G loss: 1.000112]\n",
      "epoch:13 step:51140[D loss: 0.999980] [G loss: 1.000094]\n",
      "epoch:13 step:51145[D loss: 0.999977] [G loss: 1.000073]\n",
      "epoch:13 step:51150[D loss: 1.000024] [G loss: 1.000021]\n",
      "epoch:13 step:51155[D loss: 1.000000] [G loss: 1.000086]\n",
      "epoch:13 step:51160[D loss: 0.999999] [G loss: 1.000028]\n",
      "epoch:13 step:51165[D loss: 0.999947] [G loss: 1.000088]\n",
      "epoch:13 step:51170[D loss: 0.999987] [G loss: 1.000030]\n",
      "epoch:13 step:51175[D loss: 0.999964] [G loss: 1.000108]\n",
      "epoch:13 step:51180[D loss: 0.999961] [G loss: 1.000087]\n",
      "epoch:13 step:51185[D loss: 0.999976] [G loss: 1.000081]\n",
      "epoch:13 step:51190[D loss: 0.999961] [G loss: 1.000072]\n",
      "epoch:13 step:51195[D loss: 0.999980] [G loss: 1.000071]\n",
      "epoch:13 step:51200[D loss: 0.999967] [G loss: 1.000085]\n",
      "##############\n",
      "[0.87459687 0.86816643 0.8178426  0.80738593 0.80108777 0.83195637\n",
      " 0.89548588 0.83741118 0.80857799 0.84042494]\n",
      "##########\n",
      "epoch:13 step:51205[D loss: 0.999966] [G loss: 1.000111]\n",
      "epoch:13 step:51210[D loss: 1.000065] [G loss: 1.000043]\n",
      "epoch:13 step:51215[D loss: 0.999940] [G loss: 1.000089]\n",
      "epoch:13 step:51220[D loss: 0.999973] [G loss: 1.000071]\n",
      "epoch:13 step:51225[D loss: 0.999965] [G loss: 1.000081]\n",
      "epoch:13 step:51230[D loss: 1.000028] [G loss: 0.999994]\n",
      "epoch:13 step:51235[D loss: 0.999964] [G loss: 1.000113]\n",
      "epoch:13 step:51240[D loss: 0.999956] [G loss: 1.000083]\n",
      "epoch:13 step:51245[D loss: 1.000057] [G loss: 1.000053]\n",
      "epoch:13 step:51250[D loss: 0.999986] [G loss: 1.000038]\n",
      "epoch:13 step:51255[D loss: 0.999981] [G loss: 1.000164]\n",
      "epoch:13 step:51260[D loss: 0.999984] [G loss: 1.000128]\n",
      "epoch:13 step:51265[D loss: 0.999968] [G loss: 1.000117]\n",
      "epoch:13 step:51270[D loss: 0.999988] [G loss: 1.000044]\n",
      "epoch:13 step:51275[D loss: 0.999968] [G loss: 1.000098]\n",
      "epoch:13 step:51280[D loss: 0.999975] [G loss: 1.000063]\n",
      "epoch:13 step:51285[D loss: 0.999969] [G loss: 1.000120]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:13 step:51290[D loss: 0.999956] [G loss: 1.000141]\n",
      "epoch:13 step:51295[D loss: 0.999963] [G loss: 1.000104]\n",
      "epoch:13 step:51300[D loss: 0.999984] [G loss: 1.000056]\n",
      "epoch:13 step:51305[D loss: 0.999994] [G loss: 1.000089]\n",
      "epoch:13 step:51310[D loss: 0.999994] [G loss: 1.000057]\n",
      "epoch:13 step:51315[D loss: 0.999968] [G loss: 1.000134]\n",
      "epoch:13 step:51320[D loss: 0.999975] [G loss: 1.000079]\n",
      "epoch:13 step:51325[D loss: 0.999966] [G loss: 1.000075]\n",
      "epoch:13 step:51330[D loss: 0.999974] [G loss: 1.000076]\n",
      "epoch:13 step:51335[D loss: 0.999955] [G loss: 1.000104]\n",
      "epoch:13 step:51340[D loss: 0.999992] [G loss: 1.000042]\n",
      "epoch:13 step:51345[D loss: 0.999983] [G loss: 1.000041]\n",
      "epoch:13 step:51350[D loss: 1.000061] [G loss: 0.999988]\n",
      "epoch:13 step:51355[D loss: 0.999983] [G loss: 1.000030]\n",
      "epoch:13 step:51360[D loss: 0.999943] [G loss: 1.000139]\n",
      "epoch:13 step:51365[D loss: 0.999972] [G loss: 1.000101]\n",
      "epoch:13 step:51370[D loss: 0.999946] [G loss: 1.000145]\n",
      "epoch:13 step:51375[D loss: 0.999963] [G loss: 1.000108]\n",
      "epoch:13 step:51380[D loss: 0.999953] [G loss: 1.000120]\n",
      "epoch:13 step:51385[D loss: 0.999968] [G loss: 1.000097]\n",
      "epoch:13 step:51390[D loss: 0.999976] [G loss: 1.000104]\n",
      "epoch:13 step:51395[D loss: 0.999976] [G loss: 1.000094]\n",
      "epoch:13 step:51400[D loss: 0.999961] [G loss: 1.000102]\n",
      "##############\n",
      "[0.85376415 0.85081542 0.83407726 0.83279895 0.80576769 0.83958841\n",
      " 0.89917855 0.85045533 0.82839495 0.82810547]\n",
      "##########\n",
      "epoch:13 step:51405[D loss: 0.999969] [G loss: 1.000093]\n",
      "epoch:13 step:51410[D loss: 0.999976] [G loss: 1.000088]\n",
      "epoch:13 step:51415[D loss: 0.999969] [G loss: 1.000086]\n",
      "epoch:13 step:51420[D loss: 0.999972] [G loss: 1.000116]\n",
      "epoch:13 step:51425[D loss: 0.999971] [G loss: 1.000097]\n",
      "epoch:13 step:51430[D loss: 0.999966] [G loss: 1.000099]\n",
      "epoch:13 step:51435[D loss: 1.000001] [G loss: 1.000072]\n",
      "epoch:13 step:51440[D loss: 0.999982] [G loss: 1.000030]\n",
      "epoch:13 step:51445[D loss: 0.999977] [G loss: 1.000079]\n",
      "epoch:13 step:51450[D loss: 0.999961] [G loss: 1.000084]\n",
      "epoch:13 step:51455[D loss: 0.999995] [G loss: 1.000081]\n",
      "epoch:13 step:51460[D loss: 0.999972] [G loss: 1.000057]\n",
      "epoch:13 step:51465[D loss: 0.999981] [G loss: 1.000058]\n",
      "epoch:13 step:51470[D loss: 1.000035] [G loss: 0.999969]\n",
      "epoch:13 step:51475[D loss: 0.999975] [G loss: 1.000080]\n",
      "epoch:13 step:51480[D loss: 0.999947] [G loss: 1.000103]\n",
      "epoch:13 step:51485[D loss: 0.999962] [G loss: 1.000112]\n",
      "epoch:13 step:51490[D loss: 1.000020] [G loss: 0.999999]\n",
      "epoch:13 step:51495[D loss: 0.999959] [G loss: 1.000051]\n",
      "epoch:13 step:51500[D loss: 0.999953] [G loss: 1.000088]\n",
      "epoch:13 step:51505[D loss: 0.999969] [G loss: 1.000070]\n",
      "epoch:13 step:51510[D loss: 0.999970] [G loss: 1.000068]\n",
      "epoch:13 step:51515[D loss: 0.999973] [G loss: 1.000035]\n",
      "epoch:13 step:51520[D loss: 0.999971] [G loss: 1.000068]\n",
      "epoch:13 step:51525[D loss: 0.999971] [G loss: 1.000032]\n",
      "epoch:13 step:51530[D loss: 1.000005] [G loss: 1.000071]\n",
      "epoch:13 step:51535[D loss: 0.999988] [G loss: 1.000050]\n",
      "epoch:13 step:51540[D loss: 0.999914] [G loss: 1.000128]\n",
      "epoch:13 step:51545[D loss: 0.999988] [G loss: 1.000049]\n",
      "epoch:13 step:51550[D loss: 0.999980] [G loss: 1.000069]\n",
      "epoch:13 step:51555[D loss: 0.999956] [G loss: 1.000093]\n",
      "epoch:13 step:51560[D loss: 0.999993] [G loss: 1.000106]\n",
      "epoch:13 step:51565[D loss: 0.999971] [G loss: 1.000071]\n",
      "epoch:13 step:51570[D loss: 0.999967] [G loss: 1.000074]\n",
      "epoch:13 step:51575[D loss: 0.999986] [G loss: 1.000043]\n",
      "epoch:13 step:51580[D loss: 0.999960] [G loss: 1.000081]\n",
      "epoch:13 step:51585[D loss: 0.999983] [G loss: 1.000051]\n",
      "epoch:13 step:51590[D loss: 0.999987] [G loss: 1.000069]\n",
      "epoch:13 step:51595[D loss: 0.999985] [G loss: 1.000050]\n",
      "epoch:13 step:51600[D loss: 0.999966] [G loss: 1.000079]\n",
      "##############\n",
      "[0.87592346 0.84764578 0.83676509 0.84989562 0.79506026 0.87360422\n",
      " 0.8821067  0.85062983 0.8172696  0.82954194]\n",
      "##########\n",
      "epoch:13 step:51605[D loss: 0.999982] [G loss: 1.000081]\n",
      "epoch:13 step:51610[D loss: 0.999991] [G loss: 1.000037]\n",
      "epoch:13 step:51615[D loss: 1.000016] [G loss: 1.000075]\n",
      "epoch:13 step:51620[D loss: 1.000000] [G loss: 1.000139]\n",
      "epoch:13 step:51625[D loss: 0.999949] [G loss: 1.000168]\n",
      "epoch:13 step:51630[D loss: 0.999936] [G loss: 1.000132]\n",
      "epoch:13 step:51635[D loss: 0.999973] [G loss: 1.000071]\n",
      "epoch:13 step:51640[D loss: 1.000030] [G loss: 0.999958]\n",
      "epoch:13 step:51645[D loss: 1.000121] [G loss: 0.999861]\n",
      "epoch:13 step:51650[D loss: 0.999996] [G loss: 0.999943]\n",
      "epoch:13 step:51655[D loss: 0.999916] [G loss: 1.000177]\n",
      "epoch:13 step:51660[D loss: 1.000098] [G loss: 0.999916]\n",
      "epoch:13 step:51665[D loss: 1.000008] [G loss: 1.000082]\n",
      "epoch:13 step:51670[D loss: 0.999925] [G loss: 1.000114]\n",
      "epoch:13 step:51675[D loss: 0.999989] [G loss: 0.999969]\n",
      "epoch:13 step:51680[D loss: 1.000120] [G loss: 0.999915]\n",
      "epoch:13 step:51685[D loss: 0.999973] [G loss: 0.999976]\n",
      "epoch:13 step:51690[D loss: 0.999985] [G loss: 1.000064]\n",
      "epoch:13 step:51695[D loss: 0.999936] [G loss: 1.000076]\n",
      "epoch:13 step:51700[D loss: 0.999968] [G loss: 1.000057]\n",
      "epoch:13 step:51705[D loss: 1.000026] [G loss: 0.999951]\n",
      "epoch:13 step:51710[D loss: 0.999933] [G loss: 1.000086]\n",
      "epoch:13 step:51715[D loss: 0.999997] [G loss: 1.000047]\n",
      "epoch:13 step:51720[D loss: 0.999967] [G loss: 1.000025]\n",
      "epoch:13 step:51725[D loss: 0.999970] [G loss: 1.000082]\n",
      "epoch:13 step:51730[D loss: 0.999962] [G loss: 1.000086]\n",
      "epoch:13 step:51735[D loss: 1.000007] [G loss: 1.000026]\n",
      "epoch:13 step:51740[D loss: 1.000009] [G loss: 0.999983]\n",
      "epoch:13 step:51745[D loss: 0.999963] [G loss: 1.000103]\n",
      "epoch:13 step:51750[D loss: 1.000038] [G loss: 1.000059]\n",
      "epoch:13 step:51755[D loss: 0.999972] [G loss: 1.000134]\n",
      "epoch:13 step:51760[D loss: 0.999957] [G loss: 1.000059]\n",
      "epoch:13 step:51765[D loss: 0.999960] [G loss: 1.000083]\n",
      "epoch:13 step:51770[D loss: 0.999998] [G loss: 1.000062]\n",
      "epoch:13 step:51775[D loss: 0.999952] [G loss: 1.000142]\n",
      "epoch:13 step:51780[D loss: 0.999988] [G loss: 1.000075]\n",
      "epoch:13 step:51785[D loss: 0.999951] [G loss: 1.000141]\n",
      "epoch:13 step:51790[D loss: 0.999944] [G loss: 1.000134]\n",
      "epoch:13 step:51795[D loss: 0.999974] [G loss: 1.000074]\n",
      "epoch:13 step:51800[D loss: 0.999963] [G loss: 1.000088]\n",
      "##############\n",
      "[0.85821068 0.86246155 0.81940792 0.83332925 0.8174097  0.85817148\n",
      " 0.87513877 0.83392962 0.81612909 0.8457082 ]\n",
      "##########\n",
      "epoch:13 step:51805[D loss: 1.000008] [G loss: 0.999959]\n",
      "epoch:13 step:51810[D loss: 0.999959] [G loss: 1.000073]\n",
      "epoch:13 step:51815[D loss: 0.999984] [G loss: 0.999986]\n",
      "epoch:13 step:51820[D loss: 0.999972] [G loss: 1.000078]\n",
      "epoch:13 step:51825[D loss: 0.999966] [G loss: 1.000070]\n",
      "epoch:13 step:51830[D loss: 0.999982] [G loss: 1.000059]\n",
      "epoch:13 step:51835[D loss: 0.999990] [G loss: 1.000065]\n",
      "epoch:13 step:51840[D loss: 0.999976] [G loss: 1.000003]\n",
      "epoch:13 step:51845[D loss: 0.999938] [G loss: 1.000038]\n",
      "epoch:13 step:51850[D loss: 0.999974] [G loss: 1.000064]\n",
      "epoch:13 step:51855[D loss: 0.999986] [G loss: 1.000056]\n",
      "epoch:13 step:51860[D loss: 0.999977] [G loss: 1.000074]\n",
      "epoch:13 step:51865[D loss: 0.999947] [G loss: 1.000092]\n",
      "epoch:13 step:51870[D loss: 0.999966] [G loss: 1.000080]\n",
      "epoch:13 step:51875[D loss: 0.999980] [G loss: 1.000086]\n",
      "epoch:13 step:51880[D loss: 0.999968] [G loss: 1.000082]\n",
      "epoch:13 step:51885[D loss: 1.000007] [G loss: 1.000049]\n",
      "epoch:13 step:51890[D loss: 0.999956] [G loss: 1.000097]\n",
      "epoch:13 step:51895[D loss: 0.999964] [G loss: 1.000101]\n",
      "epoch:13 step:51900[D loss: 1.000000] [G loss: 1.000036]\n",
      "epoch:13 step:51905[D loss: 1.000010] [G loss: 1.000026]\n",
      "epoch:13 step:51910[D loss: 0.999980] [G loss: 1.000049]\n",
      "epoch:13 step:51915[D loss: 0.999985] [G loss: 1.000051]\n",
      "epoch:13 step:51920[D loss: 1.000120] [G loss: 0.999770]\n",
      "epoch:13 step:51925[D loss: 1.000039] [G loss: 0.999943]\n",
      "epoch:13 step:51930[D loss: 1.000018] [G loss: 1.000005]\n",
      "epoch:13 step:51935[D loss: 0.999970] [G loss: 1.000054]\n",
      "epoch:13 step:51940[D loss: 0.999973] [G loss: 1.000084]\n",
      "epoch:13 step:51945[D loss: 1.000035] [G loss: 0.999959]\n",
      "epoch:13 step:51950[D loss: 1.000069] [G loss: 0.999935]\n",
      "epoch:13 step:51955[D loss: 0.999889] [G loss: 1.000109]\n",
      "epoch:13 step:51960[D loss: 0.999963] [G loss: 1.000000]\n",
      "epoch:13 step:51965[D loss: 0.999967] [G loss: 1.000066]\n",
      "epoch:13 step:51970[D loss: 0.999976] [G loss: 1.000074]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:13 step:51975[D loss: 0.999966] [G loss: 1.000110]\n",
      "epoch:13 step:51980[D loss: 1.000013] [G loss: 1.000090]\n",
      "epoch:13 step:51985[D loss: 0.999954] [G loss: 1.000229]\n",
      "epoch:13 step:51990[D loss: 0.999941] [G loss: 1.000160]\n",
      "epoch:13 step:51995[D loss: 0.999978] [G loss: 1.000083]\n",
      "epoch:13 step:52000[D loss: 1.000007] [G loss: 1.000023]\n",
      "##############\n",
      "[0.86826625 0.88070934 0.83734923 0.8257997  0.81409801 0.84072665\n",
      " 0.86406062 0.83775745 0.81160509 0.8260374 ]\n",
      "##########\n",
      "epoch:13 step:52005[D loss: 0.999962] [G loss: 1.000029]\n",
      "epoch:13 step:52010[D loss: 0.999983] [G loss: 1.000012]\n",
      "epoch:13 step:52015[D loss: 1.000079] [G loss: 0.999896]\n",
      "epoch:13 step:52020[D loss: 0.999944] [G loss: 1.000066]\n",
      "epoch:13 step:52025[D loss: 0.999950] [G loss: 1.000082]\n",
      "epoch:13 step:52030[D loss: 0.999991] [G loss: 1.000056]\n",
      "epoch:13 step:52035[D loss: 0.999950] [G loss: 1.000085]\n",
      "epoch:13 step:52040[D loss: 0.999955] [G loss: 1.000086]\n",
      "epoch:13 step:52045[D loss: 0.999975] [G loss: 1.000047]\n",
      "epoch:13 step:52050[D loss: 0.999987] [G loss: 1.000041]\n",
      "epoch:13 step:52055[D loss: 1.000011] [G loss: 0.999984]\n",
      "epoch:13 step:52060[D loss: 0.999971] [G loss: 1.000038]\n",
      "epoch:13 step:52065[D loss: 0.999975] [G loss: 1.000069]\n",
      "epoch:13 step:52070[D loss: 0.999946] [G loss: 1.000098]\n",
      "epoch:13 step:52075[D loss: 0.999993] [G loss: 1.000053]\n",
      "epoch:13 step:52080[D loss: 1.000017] [G loss: 0.999940]\n",
      "epoch:13 step:52085[D loss: 0.999987] [G loss: 1.000016]\n",
      "epoch:13 step:52090[D loss: 0.999972] [G loss: 1.000081]\n",
      "epoch:13 step:52095[D loss: 0.999977] [G loss: 1.000060]\n",
      "epoch:13 step:52100[D loss: 0.999963] [G loss: 1.000077]\n",
      "epoch:13 step:52105[D loss: 0.999970] [G loss: 1.000051]\n",
      "epoch:13 step:52110[D loss: 0.999983] [G loss: 1.000041]\n",
      "epoch:13 step:52115[D loss: 1.000000] [G loss: 1.000015]\n",
      "epoch:13 step:52120[D loss: 1.000040] [G loss: 0.999936]\n",
      "epoch:13 step:52125[D loss: 0.999998] [G loss: 1.000064]\n",
      "epoch:13 step:52130[D loss: 0.999977] [G loss: 1.000162]\n",
      "epoch:13 step:52135[D loss: 0.999929] [G loss: 1.000167]\n",
      "epoch:13 step:52140[D loss: 1.000025] [G loss: 1.000001]\n",
      "epoch:13 step:52145[D loss: 1.000024] [G loss: 1.000092]\n",
      "epoch:13 step:52150[D loss: 0.999924] [G loss: 1.000015]\n",
      "epoch:13 step:52155[D loss: 0.999996] [G loss: 1.000029]\n",
      "epoch:13 step:52160[D loss: 0.999988] [G loss: 0.999990]\n",
      "epoch:13 step:52165[D loss: 0.999949] [G loss: 1.000121]\n",
      "epoch:13 step:52170[D loss: 0.999986] [G loss: 1.000045]\n",
      "epoch:13 step:52175[D loss: 0.999983] [G loss: 1.000103]\n",
      "epoch:13 step:52180[D loss: 0.999979] [G loss: 1.000069]\n",
      "epoch:13 step:52185[D loss: 0.999970] [G loss: 1.000067]\n",
      "epoch:13 step:52190[D loss: 1.000038] [G loss: 1.000000]\n",
      "epoch:13 step:52195[D loss: 0.999983] [G loss: 1.000059]\n",
      "epoch:13 step:52200[D loss: 0.999978] [G loss: 1.000071]\n",
      "##############\n",
      "[0.85385253 0.83225203 0.81683456 0.82587371 0.80946228 0.85801139\n",
      " 0.86141003 0.87190551 0.80647935 0.83421702]\n",
      "##########\n",
      "epoch:13 step:52205[D loss: 0.999977] [G loss: 1.000054]\n",
      "epoch:13 step:52210[D loss: 0.999997] [G loss: 1.000022]\n",
      "epoch:13 step:52215[D loss: 0.999968] [G loss: 1.000078]\n",
      "epoch:13 step:52220[D loss: 0.999961] [G loss: 1.000094]\n",
      "epoch:13 step:52225[D loss: 0.999994] [G loss: 1.000030]\n",
      "epoch:13 step:52230[D loss: 0.999968] [G loss: 1.000124]\n",
      "epoch:13 step:52235[D loss: 0.999966] [G loss: 1.000098]\n",
      "epoch:13 step:52240[D loss: 1.000026] [G loss: 1.000020]\n",
      "epoch:13 step:52245[D loss: 0.999925] [G loss: 1.000126]\n",
      "epoch:13 step:52250[D loss: 0.999953] [G loss: 1.000081]\n",
      "epoch:13 step:52255[D loss: 0.999990] [G loss: 1.000068]\n",
      "epoch:13 step:52260[D loss: 0.999960] [G loss: 1.000196]\n",
      "epoch:13 step:52265[D loss: 0.999962] [G loss: 1.000057]\n",
      "epoch:13 step:52270[D loss: 0.999973] [G loss: 1.000087]\n",
      "epoch:13 step:52275[D loss: 0.999972] [G loss: 1.000123]\n",
      "epoch:13 step:52280[D loss: 0.999971] [G loss: 1.000077]\n",
      "epoch:13 step:52285[D loss: 0.999989] [G loss: 1.000091]\n",
      "epoch:13 step:52290[D loss: 0.999994] [G loss: 1.000077]\n",
      "epoch:13 step:52295[D loss: 0.999974] [G loss: 1.000085]\n",
      "epoch:13 step:52300[D loss: 0.999993] [G loss: 1.000022]\n",
      "epoch:13 step:52305[D loss: 0.999952] [G loss: 1.000080]\n",
      "epoch:13 step:52310[D loss: 0.999963] [G loss: 1.000076]\n",
      "epoch:13 step:52315[D loss: 1.000060] [G loss: 0.999973]\n",
      "epoch:13 step:52320[D loss: 0.999941] [G loss: 1.000154]\n",
      "epoch:13 step:52325[D loss: 0.999945] [G loss: 1.000109]\n",
      "epoch:13 step:52330[D loss: 0.999972] [G loss: 1.000060]\n",
      "epoch:13 step:52335[D loss: 1.000017] [G loss: 1.000054]\n",
      "epoch:13 step:52340[D loss: 1.000084] [G loss: 0.999940]\n",
      "epoch:13 step:52345[D loss: 1.000052] [G loss: 0.999996]\n",
      "epoch:13 step:52350[D loss: 0.999929] [G loss: 1.000137]\n",
      "epoch:13 step:52355[D loss: 0.999920] [G loss: 1.000178]\n",
      "epoch:13 step:52360[D loss: 0.999914] [G loss: 1.000155]\n",
      "epoch:13 step:52365[D loss: 0.999934] [G loss: 1.000146]\n",
      "epoch:13 step:52370[D loss: 0.999969] [G loss: 1.000071]\n",
      "epoch:13 step:52375[D loss: 0.999959] [G loss: 1.000059]\n",
      "epoch:13 step:52380[D loss: 0.999958] [G loss: 1.000085]\n",
      "epoch:13 step:52385[D loss: 1.000012] [G loss: 1.000007]\n",
      "epoch:13 step:52390[D loss: 1.000091] [G loss: 0.999879]\n",
      "epoch:13 step:52395[D loss: 0.999968] [G loss: 1.000065]\n",
      "epoch:13 step:52400[D loss: 1.000008] [G loss: 1.000063]\n",
      "##############\n",
      "[0.86391167 0.85956092 0.81588948 0.82540132 0.82090055 0.84148458\n",
      " 0.87777688 0.85612006 0.82264792 0.85551672]\n",
      "##########\n",
      "epoch:13 step:52405[D loss: 0.999953] [G loss: 1.000140]\n",
      "epoch:13 step:52410[D loss: 0.999979] [G loss: 1.000103]\n",
      "epoch:13 step:52415[D loss: 0.999969] [G loss: 1.000093]\n",
      "epoch:13 step:52420[D loss: 0.999969] [G loss: 1.000133]\n",
      "epoch:13 step:52425[D loss: 1.000003] [G loss: 1.000066]\n",
      "epoch:13 step:52430[D loss: 0.999982] [G loss: 1.000083]\n",
      "epoch:13 step:52435[D loss: 0.999947] [G loss: 1.000132]\n",
      "epoch:13 step:52440[D loss: 0.999957] [G loss: 1.000130]\n",
      "epoch:13 step:52445[D loss: 0.999994] [G loss: 1.000054]\n",
      "epoch:13 step:52450[D loss: 0.999972] [G loss: 1.000086]\n",
      "epoch:13 step:52455[D loss: 0.999998] [G loss: 1.000078]\n",
      "epoch:13 step:52460[D loss: 0.999957] [G loss: 1.000110]\n",
      "epoch:13 step:52465[D loss: 0.999979] [G loss: 1.000103]\n",
      "epoch:13 step:52470[D loss: 0.999985] [G loss: 1.000026]\n",
      "epoch:13 step:52475[D loss: 0.999982] [G loss: 1.000094]\n",
      "epoch:13 step:52480[D loss: 0.999986] [G loss: 1.000051]\n",
      "epoch:13 step:52485[D loss: 0.999987] [G loss: 1.000056]\n",
      "epoch:13 step:52490[D loss: 1.000030] [G loss: 0.999979]\n",
      "epoch:13 step:52495[D loss: 0.999951] [G loss: 1.000080]\n",
      "epoch:13 step:52500[D loss: 0.999974] [G loss: 1.000050]\n",
      "epoch:13 step:52505[D loss: 0.999983] [G loss: 1.000060]\n",
      "epoch:13 step:52510[D loss: 0.999957] [G loss: 1.000088]\n",
      "epoch:13 step:52515[D loss: 0.999982] [G loss: 1.000063]\n",
      "epoch:13 step:52520[D loss: 0.999978] [G loss: 1.000077]\n",
      "epoch:13 step:52525[D loss: 0.999966] [G loss: 1.000073]\n",
      "epoch:13 step:52530[D loss: 0.999964] [G loss: 1.000034]\n",
      "epoch:13 step:52535[D loss: 0.999958] [G loss: 1.000083]\n",
      "epoch:13 step:52540[D loss: 0.999973] [G loss: 1.000064]\n",
      "epoch:13 step:52545[D loss: 0.999983] [G loss: 1.000103]\n",
      "epoch:13 step:52550[D loss: 0.999952] [G loss: 1.000103]\n",
      "epoch:13 step:52555[D loss: 0.999983] [G loss: 1.000072]\n",
      "epoch:13 step:52560[D loss: 0.999949] [G loss: 1.000116]\n",
      "epoch:13 step:52565[D loss: 0.999986] [G loss: 1.000038]\n",
      "epoch:13 step:52570[D loss: 1.000001] [G loss: 1.000013]\n",
      "epoch:13 step:52575[D loss: 0.999908] [G loss: 1.000124]\n",
      "epoch:13 step:52580[D loss: 1.000070] [G loss: 1.000002]\n",
      "epoch:13 step:52585[D loss: 0.999960] [G loss: 1.000040]\n",
      "epoch:13 step:52590[D loss: 1.000005] [G loss: 1.000101]\n",
      "epoch:13 step:52595[D loss: 0.999949] [G loss: 1.000102]\n",
      "epoch:13 step:52600[D loss: 0.999976] [G loss: 1.000068]\n",
      "##############\n",
      "[0.88770609 0.84968714 0.84136697 0.82759959 0.78698978 0.84203928\n",
      " 0.86291591 0.87069457 0.82380353 0.8473748 ]\n",
      "##########\n",
      "epoch:13 step:52605[D loss: 0.999986] [G loss: 0.999983]\n",
      "epoch:13 step:52610[D loss: 0.999983] [G loss: 1.000036]\n",
      "epoch:13 step:52615[D loss: 0.999986] [G loss: 1.000040]\n",
      "epoch:13 step:52620[D loss: 0.999976] [G loss: 1.000069]\n",
      "epoch:13 step:52625[D loss: 1.000010] [G loss: 1.000023]\n",
      "epoch:13 step:52630[D loss: 0.999983] [G loss: 1.000053]\n",
      "epoch:13 step:52635[D loss: 0.999966] [G loss: 1.000106]\n",
      "epoch:13 step:52640[D loss: 0.999995] [G loss: 1.000045]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:13 step:52645[D loss: 0.999996] [G loss: 1.000057]\n",
      "epoch:13 step:52650[D loss: 0.999989] [G loss: 1.000072]\n",
      "epoch:13 step:52655[D loss: 0.999961] [G loss: 1.000074]\n",
      "epoch:13 step:52660[D loss: 0.999987] [G loss: 1.000039]\n",
      "epoch:13 step:52665[D loss: 0.999986] [G loss: 1.000043]\n",
      "epoch:13 step:52670[D loss: 1.000009] [G loss: 1.000030]\n",
      "epoch:13 step:52675[D loss: 0.999996] [G loss: 1.000165]\n",
      "epoch:13 step:52680[D loss: 0.999987] [G loss: 1.000107]\n",
      "epoch:13 step:52685[D loss: 0.999942] [G loss: 1.000172]\n",
      "epoch:13 step:52690[D loss: 0.999950] [G loss: 1.000095]\n",
      "epoch:13 step:52695[D loss: 0.999984] [G loss: 1.000041]\n",
      "epoch:13 step:52700[D loss: 0.999994] [G loss: 1.000049]\n",
      "epoch:13 step:52705[D loss: 0.999968] [G loss: 1.000055]\n",
      "epoch:13 step:52710[D loss: 0.999984] [G loss: 1.000038]\n",
      "epoch:13 step:52715[D loss: 0.999988] [G loss: 1.000044]\n",
      "epoch:13 step:52720[D loss: 0.999992] [G loss: 1.000092]\n",
      "epoch:13 step:52725[D loss: 0.999950] [G loss: 1.000087]\n",
      "epoch:13 step:52730[D loss: 1.000001] [G loss: 1.000018]\n",
      "epoch:13 step:52735[D loss: 0.999975] [G loss: 1.000053]\n",
      "epoch:13 step:52740[D loss: 1.000138] [G loss: 0.999893]\n",
      "epoch:13 step:52745[D loss: 0.999986] [G loss: 1.000121]\n",
      "epoch:13 step:52750[D loss: 0.999953] [G loss: 1.000069]\n",
      "epoch:13 step:52755[D loss: 0.999975] [G loss: 1.000071]\n",
      "epoch:13 step:52760[D loss: 1.000030] [G loss: 0.999980]\n",
      "epoch:13 step:52765[D loss: 0.999961] [G loss: 1.000089]\n",
      "epoch:13 step:52770[D loss: 0.999983] [G loss: 1.000057]\n",
      "epoch:13 step:52775[D loss: 0.999992] [G loss: 1.000027]\n",
      "epoch:13 step:52780[D loss: 0.999986] [G loss: 1.000055]\n",
      "epoch:13 step:52785[D loss: 0.999999] [G loss: 1.000050]\n",
      "epoch:13 step:52790[D loss: 0.999943] [G loss: 1.000122]\n",
      "epoch:13 step:52795[D loss: 0.999946] [G loss: 1.000132]\n",
      "epoch:13 step:52800[D loss: 0.999976] [G loss: 1.000089]\n",
      "##############\n",
      "[0.87002942 0.85904625 0.82277404 0.83950903 0.79738585 0.82643085\n",
      " 0.87814885 0.85484437 0.84569655 0.8549798 ]\n",
      "##########\n",
      "epoch:13 step:52805[D loss: 0.999954] [G loss: 1.000114]\n",
      "epoch:13 step:52810[D loss: 0.999978] [G loss: 1.000041]\n",
      "epoch:13 step:52815[D loss: 0.999967] [G loss: 1.000091]\n",
      "epoch:13 step:52820[D loss: 0.999982] [G loss: 1.000079]\n",
      "epoch:13 step:52825[D loss: 0.999938] [G loss: 1.000135]\n",
      "epoch:13 step:52830[D loss: 0.999977] [G loss: 1.000093]\n",
      "epoch:13 step:52835[D loss: 1.000027] [G loss: 0.999983]\n",
      "epoch:13 step:52840[D loss: 0.999979] [G loss: 1.000091]\n",
      "epoch:13 step:52845[D loss: 0.999938] [G loss: 1.000170]\n",
      "epoch:13 step:52850[D loss: 0.999983] [G loss: 1.000094]\n",
      "epoch:13 step:52855[D loss: 0.999983] [G loss: 1.000043]\n",
      "epoch:13 step:52860[D loss: 0.999989] [G loss: 0.999989]\n",
      "epoch:13 step:52865[D loss: 0.999957] [G loss: 1.000093]\n",
      "epoch:13 step:52870[D loss: 1.000005] [G loss: 1.000097]\n",
      "epoch:13 step:52875[D loss: 0.999936] [G loss: 1.000101]\n",
      "epoch:13 step:52880[D loss: 0.999970] [G loss: 1.000091]\n",
      "epoch:13 step:52885[D loss: 1.000007] [G loss: 1.000048]\n",
      "epoch:13 step:52890[D loss: 0.999949] [G loss: 1.000083]\n",
      "epoch:13 step:52895[D loss: 0.999976] [G loss: 1.000084]\n",
      "epoch:13 step:52900[D loss: 0.999981] [G loss: 1.000099]\n",
      "epoch:13 step:52905[D loss: 0.999997] [G loss: 1.000011]\n",
      "epoch:13 step:52910[D loss: 1.000009] [G loss: 0.999987]\n",
      "epoch:13 step:52915[D loss: 0.999984] [G loss: 1.000034]\n",
      "epoch:13 step:52920[D loss: 0.999983] [G loss: 1.000029]\n",
      "epoch:13 step:52925[D loss: 0.999954] [G loss: 1.000069]\n",
      "epoch:13 step:52930[D loss: 0.999962] [G loss: 1.000087]\n",
      "epoch:13 step:52935[D loss: 0.999974] [G loss: 1.000065]\n",
      "epoch:13 step:52940[D loss: 0.999973] [G loss: 1.000066]\n",
      "epoch:13 step:52945[D loss: 0.999962] [G loss: 1.000138]\n",
      "epoch:13 step:52950[D loss: 0.999970] [G loss: 1.000055]\n",
      "epoch:13 step:52955[D loss: 0.999982] [G loss: 1.000074]\n",
      "epoch:13 step:52960[D loss: 0.999950] [G loss: 1.000086]\n",
      "epoch:13 step:52965[D loss: 0.999977] [G loss: 1.000062]\n",
      "epoch:13 step:52970[D loss: 0.999979] [G loss: 1.000052]\n",
      "epoch:13 step:52975[D loss: 0.999979] [G loss: 1.000057]\n",
      "epoch:13 step:52980[D loss: 0.999984] [G loss: 1.000044]\n",
      "epoch:13 step:52985[D loss: 0.999971] [G loss: 1.000063]\n",
      "epoch:13 step:52990[D loss: 0.999959] [G loss: 1.000082]\n",
      "epoch:13 step:52995[D loss: 0.999969] [G loss: 1.000092]\n",
      "epoch:13 step:53000[D loss: 0.999975] [G loss: 1.000056]\n",
      "##############\n",
      "[0.87211448 0.84622079 0.84088212 0.80420919 0.81759714 0.83443732\n",
      " 0.87914169 0.84262801 0.80995829 0.83392241]\n",
      "##########\n",
      "epoch:13 step:53005[D loss: 0.999989] [G loss: 1.000071]\n",
      "epoch:13 step:53010[D loss: 0.999972] [G loss: 1.000054]\n",
      "epoch:13 step:53015[D loss: 1.000017] [G loss: 1.000013]\n",
      "epoch:13 step:53020[D loss: 1.000001] [G loss: 1.000031]\n",
      "epoch:13 step:53025[D loss: 0.999985] [G loss: 1.000029]\n",
      "epoch:13 step:53030[D loss: 0.999967] [G loss: 1.000077]\n",
      "epoch:13 step:53035[D loss: 0.999950] [G loss: 1.000075]\n",
      "epoch:13 step:53040[D loss: 1.000027] [G loss: 0.999978]\n",
      "epoch:13 step:53045[D loss: 0.999972] [G loss: 1.000081]\n",
      "epoch:13 step:53050[D loss: 0.999962] [G loss: 1.000083]\n",
      "epoch:13 step:53055[D loss: 0.999968] [G loss: 1.000081]\n",
      "epoch:13 step:53060[D loss: 0.999991] [G loss: 1.000055]\n",
      "epoch:13 step:53065[D loss: 0.999970] [G loss: 1.000092]\n",
      "epoch:13 step:53070[D loss: 0.999992] [G loss: 1.000047]\n",
      "epoch:13 step:53075[D loss: 0.999991] [G loss: 1.000042]\n",
      "epoch:13 step:53080[D loss: 0.999975] [G loss: 1.000087]\n",
      "epoch:13 step:53085[D loss: 0.999978] [G loss: 1.000063]\n",
      "epoch:13 step:53090[D loss: 0.999970] [G loss: 1.000076]\n",
      "epoch:13 step:53095[D loss: 0.999968] [G loss: 1.000070]\n",
      "epoch:13 step:53100[D loss: 1.000005] [G loss: 1.000029]\n",
      "epoch:13 step:53105[D loss: 0.999983] [G loss: 1.000047]\n",
      "epoch:13 step:53110[D loss: 1.000046] [G loss: 1.000026]\n",
      "epoch:13 step:53115[D loss: 0.999976] [G loss: 1.000073]\n",
      "epoch:13 step:53120[D loss: 0.999984] [G loss: 1.000060]\n",
      "epoch:13 step:53125[D loss: 0.999966] [G loss: 1.000059]\n",
      "epoch:13 step:53130[D loss: 1.000002] [G loss: 1.000043]\n",
      "epoch:13 step:53135[D loss: 1.000018] [G loss: 1.000011]\n",
      "epoch:13 step:53140[D loss: 0.999925] [G loss: 1.000075]\n",
      "epoch:13 step:53145[D loss: 1.000018] [G loss: 0.999997]\n",
      "epoch:13 step:53150[D loss: 0.999969] [G loss: 1.000095]\n",
      "epoch:13 step:53155[D loss: 0.999964] [G loss: 1.000092]\n",
      "epoch:13 step:53160[D loss: 0.999976] [G loss: 1.000080]\n",
      "epoch:13 step:53165[D loss: 0.999960] [G loss: 1.000087]\n",
      "epoch:13 step:53170[D loss: 0.999973] [G loss: 1.000075]\n",
      "epoch:13 step:53175[D loss: 0.999972] [G loss: 1.000062]\n",
      "epoch:13 step:53180[D loss: 1.000111] [G loss: 0.999872]\n",
      "epoch:13 step:53185[D loss: 0.999889] [G loss: 1.000118]\n",
      "epoch:13 step:53190[D loss: 0.999999] [G loss: 1.000061]\n",
      "epoch:13 step:53195[D loss: 0.999880] [G loss: 1.000275]\n",
      "epoch:13 step:53200[D loss: 0.999923] [G loss: 1.000178]\n",
      "##############\n",
      "[0.87797579 0.8470029  0.83754424 0.82392506 0.80145961 0.84445902\n",
      " 0.88659989 0.83427314 0.82593175 0.83635736]\n",
      "##########\n",
      "epoch:13 step:53205[D loss: 0.999979] [G loss: 1.000106]\n",
      "epoch:13 step:53210[D loss: 0.999956] [G loss: 1.000093]\n",
      "epoch:13 step:53215[D loss: 1.000000] [G loss: 1.000053]\n",
      "epoch:13 step:53220[D loss: 1.000039] [G loss: 0.999944]\n",
      "epoch:13 step:53225[D loss: 1.000067] [G loss: 0.999903]\n",
      "epoch:13 step:53230[D loss: 1.000168] [G loss: 1.000009]\n",
      "epoch:13 step:53235[D loss: 0.999943] [G loss: 1.000078]\n",
      "epoch:13 step:53240[D loss: 0.999973] [G loss: 1.000211]\n",
      "epoch:13 step:53245[D loss: 0.999938] [G loss: 1.000170]\n",
      "epoch:13 step:53250[D loss: 0.999979] [G loss: 1.000082]\n",
      "epoch:13 step:53255[D loss: 0.999940] [G loss: 1.000163]\n",
      "epoch:13 step:53260[D loss: 0.999981] [G loss: 1.000096]\n",
      "epoch:13 step:53265[D loss: 0.999975] [G loss: 1.000069]\n",
      "epoch:13 step:53270[D loss: 0.999999] [G loss: 1.000014]\n",
      "epoch:13 step:53275[D loss: 1.000044] [G loss: 0.999883]\n",
      "epoch:13 step:53280[D loss: 0.999985] [G loss: 1.000019]\n",
      "epoch:13 step:53285[D loss: 0.999955] [G loss: 1.000070]\n",
      "epoch:13 step:53290[D loss: 1.000029] [G loss: 1.000053]\n",
      "epoch:13 step:53295[D loss: 0.999980] [G loss: 1.000048]\n",
      "epoch:13 step:53300[D loss: 0.999866] [G loss: 1.000293]\n",
      "epoch:13 step:53305[D loss: 0.999864] [G loss: 1.000204]\n",
      "epoch:13 step:53310[D loss: 0.999968] [G loss: 1.000039]\n",
      "epoch:13 step:53315[D loss: 1.000002] [G loss: 1.000020]\n",
      "epoch:13 step:53320[D loss: 0.999998] [G loss: 1.000078]\n",
      "epoch:13 step:53325[D loss: 0.999983] [G loss: 1.000021]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:13 step:53330[D loss: 0.999897] [G loss: 1.000131]\n",
      "epoch:13 step:53335[D loss: 0.999965] [G loss: 1.000097]\n",
      "epoch:13 step:53340[D loss: 0.999981] [G loss: 1.000059]\n",
      "epoch:13 step:53345[D loss: 0.999971] [G loss: 1.000100]\n",
      "epoch:13 step:53350[D loss: 0.999977] [G loss: 1.000054]\n",
      "epoch:13 step:53355[D loss: 0.999958] [G loss: 1.000079]\n",
      "epoch:13 step:53360[D loss: 0.999939] [G loss: 1.000109]\n",
      "epoch:13 step:53365[D loss: 0.999984] [G loss: 1.000079]\n",
      "epoch:13 step:53370[D loss: 1.000006] [G loss: 1.000050]\n",
      "epoch:13 step:53375[D loss: 0.999974] [G loss: 1.000031]\n",
      "epoch:13 step:53380[D loss: 0.999990] [G loss: 0.999995]\n",
      "epoch:13 step:53385[D loss: 0.999979] [G loss: 1.000057]\n",
      "epoch:13 step:53390[D loss: 0.999980] [G loss: 1.000041]\n",
      "epoch:13 step:53395[D loss: 0.999955] [G loss: 1.000080]\n",
      "epoch:13 step:53400[D loss: 0.999985] [G loss: 1.000055]\n",
      "##############\n",
      "[0.86404546 0.84487636 0.85551816 0.8370566  0.82404945 0.82182591\n",
      " 0.85653722 0.83816222 0.82993096 0.83289207]\n",
      "##########\n",
      "epoch:13 step:53405[D loss: 0.999951] [G loss: 1.000091]\n",
      "epoch:13 step:53410[D loss: 0.999962] [G loss: 1.000098]\n",
      "epoch:13 step:53415[D loss: 1.000073] [G loss: 0.999930]\n",
      "epoch:13 step:53420[D loss: 0.999997] [G loss: 1.000005]\n",
      "epoch:13 step:53425[D loss: 0.999971] [G loss: 1.000110]\n",
      "epoch:13 step:53430[D loss: 0.999945] [G loss: 1.000359]\n",
      "epoch:13 step:53435[D loss: 0.999886] [G loss: 1.000150]\n",
      "epoch:13 step:53440[D loss: 0.999982] [G loss: 1.000062]\n",
      "epoch:13 step:53445[D loss: 0.999977] [G loss: 1.000003]\n",
      "epoch:13 step:53450[D loss: 1.000002] [G loss: 1.000014]\n",
      "epoch:13 step:53455[D loss: 1.000123] [G loss: 0.999768]\n",
      "epoch:13 step:53460[D loss: 0.999885] [G loss: 1.000081]\n",
      "epoch:13 step:53465[D loss: 0.999958] [G loss: 1.000053]\n",
      "epoch:13 step:53470[D loss: 0.999954] [G loss: 1.000046]\n",
      "epoch:13 step:53475[D loss: 1.000023] [G loss: 0.999971]\n",
      "epoch:13 step:53480[D loss: 0.999972] [G loss: 1.000114]\n",
      "epoch:13 step:53485[D loss: 0.999935] [G loss: 1.000124]\n",
      "epoch:13 step:53490[D loss: 0.999962] [G loss: 1.000065]\n",
      "epoch:13 step:53495[D loss: 1.000013] [G loss: 1.000020]\n",
      "epoch:13 step:53500[D loss: 0.999979] [G loss: 1.000014]\n",
      "epoch:13 step:53505[D loss: 1.000012] [G loss: 0.999961]\n",
      "epoch:13 step:53510[D loss: 1.000013] [G loss: 0.999950]\n",
      "epoch:13 step:53515[D loss: 1.000013] [G loss: 1.000041]\n",
      "epoch:13 step:53520[D loss: 0.999925] [G loss: 1.000159]\n",
      "epoch:13 step:53525[D loss: 0.999974] [G loss: 1.000112]\n",
      "epoch:13 step:53530[D loss: 1.000001] [G loss: 1.000083]\n",
      "epoch:13 step:53535[D loss: 0.999949] [G loss: 1.000086]\n",
      "epoch:13 step:53540[D loss: 0.999951] [G loss: 1.000076]\n",
      "epoch:13 step:53545[D loss: 0.999996] [G loss: 1.000021]\n",
      "epoch:13 step:53550[D loss: 0.999947] [G loss: 1.000151]\n",
      "epoch:13 step:53555[D loss: 0.999973] [G loss: 1.000058]\n",
      "epoch:13 step:53560[D loss: 1.000026] [G loss: 1.000002]\n",
      "epoch:13 step:53565[D loss: 0.999995] [G loss: 1.000013]\n",
      "epoch:13 step:53570[D loss: 0.999980] [G loss: 1.000091]\n",
      "epoch:13 step:53575[D loss: 1.000001] [G loss: 1.000107]\n",
      "epoch:13 step:53580[D loss: 0.999963] [G loss: 1.000064]\n",
      "epoch:13 step:53585[D loss: 0.999953] [G loss: 1.000114]\n",
      "epoch:13 step:53590[D loss: 0.999989] [G loss: 1.000054]\n",
      "epoch:13 step:53595[D loss: 0.999962] [G loss: 1.000075]\n",
      "epoch:13 step:53600[D loss: 1.000006] [G loss: 1.000022]\n",
      "##############\n",
      "[0.89018733 0.85704222 0.83329513 0.79763688 0.82149969 0.84192102\n",
      " 0.86025185 0.83142621 0.79806214 0.83214899]\n",
      "##########\n",
      "epoch:13 step:53605[D loss: 1.000005] [G loss: 1.000033]\n",
      "epoch:13 step:53610[D loss: 1.000035] [G loss: 0.999965]\n",
      "epoch:13 step:53615[D loss: 0.999906] [G loss: 1.000111]\n",
      "epoch:13 step:53620[D loss: 1.000007] [G loss: 1.000061]\n",
      "epoch:13 step:53625[D loss: 0.999933] [G loss: 1.000186]\n",
      "epoch:13 step:53630[D loss: 0.999957] [G loss: 1.000073]\n",
      "epoch:13 step:53635[D loss: 0.999969] [G loss: 1.000082]\n",
      "epoch:13 step:53640[D loss: 0.999958] [G loss: 1.000087]\n",
      "epoch:13 step:53645[D loss: 1.000046] [G loss: 0.999923]\n",
      "epoch:13 step:53650[D loss: 0.999954] [G loss: 1.000059]\n",
      "epoch:13 step:53655[D loss: 1.000002] [G loss: 1.000003]\n",
      "epoch:13 step:53660[D loss: 0.999934] [G loss: 1.000086]\n",
      "epoch:13 step:53665[D loss: 0.999969] [G loss: 1.000081]\n",
      "epoch:13 step:53670[D loss: 0.999978] [G loss: 1.000070]\n",
      "epoch:13 step:53675[D loss: 0.999991] [G loss: 1.000081]\n",
      "epoch:13 step:53680[D loss: 0.999972] [G loss: 1.000069]\n",
      "epoch:13 step:53685[D loss: 1.000095] [G loss: 0.999960]\n",
      "epoch:13 step:53690[D loss: 0.999960] [G loss: 1.000042]\n",
      "epoch:13 step:53695[D loss: 0.999955] [G loss: 1.000080]\n",
      "epoch:13 step:53700[D loss: 0.999973] [G loss: 1.000068]\n",
      "epoch:13 step:53705[D loss: 0.999977] [G loss: 1.000067]\n",
      "epoch:13 step:53710[D loss: 0.999957] [G loss: 1.000101]\n",
      "epoch:13 step:53715[D loss: 1.000009] [G loss: 1.000020]\n",
      "epoch:13 step:53720[D loss: 0.999964] [G loss: 1.000081]\n",
      "epoch:13 step:53725[D loss: 0.999961] [G loss: 1.000069]\n",
      "epoch:13 step:53730[D loss: 0.999966] [G loss: 1.000067]\n",
      "epoch:13 step:53735[D loss: 0.999970] [G loss: 1.000056]\n",
      "epoch:13 step:53740[D loss: 1.000023] [G loss: 0.999956]\n",
      "epoch:13 step:53745[D loss: 1.000026] [G loss: 0.999977]\n",
      "epoch:13 step:53750[D loss: 0.999956] [G loss: 1.000071]\n",
      "epoch:13 step:53755[D loss: 0.999950] [G loss: 1.000064]\n",
      "epoch:13 step:53760[D loss: 0.999984] [G loss: 1.000038]\n",
      "epoch:13 step:53765[D loss: 1.000003] [G loss: 1.000052]\n",
      "epoch:13 step:53770[D loss: 1.000019] [G loss: 1.000031]\n",
      "epoch:13 step:53775[D loss: 0.999915] [G loss: 1.000133]\n",
      "epoch:13 step:53780[D loss: 1.000023] [G loss: 1.000011]\n",
      "epoch:13 step:53785[D loss: 1.000033] [G loss: 1.000043]\n",
      "epoch:13 step:53790[D loss: 0.999969] [G loss: 1.000161]\n",
      "epoch:13 step:53795[D loss: 0.999955] [G loss: 1.000141]\n",
      "epoch:13 step:53800[D loss: 0.999950] [G loss: 1.000153]\n",
      "##############\n",
      "[0.86327987 0.88116078 0.84298403 0.85118047 0.79515863 0.8466832\n",
      " 0.89963724 0.82638509 0.81328514 0.86036591]\n",
      "##########\n",
      "epoch:13 step:53805[D loss: 1.000019] [G loss: 0.999958]\n",
      "epoch:13 step:53810[D loss: 1.000108] [G loss: 0.999852]\n",
      "epoch:13 step:53815[D loss: 1.000105] [G loss: 0.999981]\n",
      "epoch:13 step:53820[D loss: 0.999959] [G loss: 0.999972]\n",
      "epoch:13 step:53825[D loss: 0.999928] [G loss: 1.000104]\n",
      "epoch:13 step:53830[D loss: 0.999970] [G loss: 1.000045]\n",
      "epoch:13 step:53835[D loss: 0.999946] [G loss: 1.000086]\n",
      "epoch:13 step:53840[D loss: 0.999985] [G loss: 1.000080]\n",
      "epoch:13 step:53845[D loss: 0.999998] [G loss: 1.000046]\n",
      "epoch:13 step:53850[D loss: 1.000011] [G loss: 1.000024]\n",
      "epoch:13 step:53855[D loss: 0.999953] [G loss: 1.000079]\n",
      "epoch:13 step:53860[D loss: 0.999952] [G loss: 1.000052]\n",
      "epoch:13 step:53865[D loss: 1.000060] [G loss: 0.999938]\n",
      "epoch:13 step:53870[D loss: 0.999964] [G loss: 1.000222]\n",
      "epoch:13 step:53875[D loss: 0.999974] [G loss: 1.000239]\n",
      "epoch:13 step:53880[D loss: 0.999916] [G loss: 1.000144]\n",
      "epoch:13 step:53885[D loss: 1.000014] [G loss: 1.000140]\n",
      "epoch:13 step:53890[D loss: 0.999873] [G loss: 1.000271]\n",
      "epoch:13 step:53895[D loss: 0.999967] [G loss: 1.000128]\n",
      "epoch:13 step:53900[D loss: 0.999970] [G loss: 1.000091]\n",
      "epoch:13 step:53905[D loss: 0.999993] [G loss: 1.000056]\n",
      "epoch:13 step:53910[D loss: 1.000105] [G loss: 0.999826]\n",
      "epoch:13 step:53915[D loss: 0.999996] [G loss: 0.999986]\n",
      "epoch:13 step:53920[D loss: 0.999961] [G loss: 1.000020]\n",
      "epoch:13 step:53925[D loss: 1.000113] [G loss: 0.999782]\n",
      "epoch:13 step:53930[D loss: 0.999955] [G loss: 0.999990]\n",
      "epoch:13 step:53935[D loss: 0.999993] [G loss: 0.999998]\n",
      "epoch:13 step:53940[D loss: 0.999957] [G loss: 1.000164]\n",
      "epoch:13 step:53945[D loss: 0.999959] [G loss: 1.000169]\n",
      "epoch:13 step:53950[D loss: 0.999973] [G loss: 1.000086]\n",
      "epoch:13 step:53955[D loss: 0.999949] [G loss: 1.000072]\n",
      "epoch:13 step:53960[D loss: 0.999967] [G loss: 1.000063]\n",
      "epoch:13 step:53965[D loss: 0.999955] [G loss: 1.000088]\n",
      "epoch:13 step:53970[D loss: 0.999970] [G loss: 1.000045]\n",
      "epoch:13 step:53975[D loss: 1.000070] [G loss: 0.999975]\n",
      "epoch:13 step:53980[D loss: 0.999902] [G loss: 1.000268]\n",
      "epoch:13 step:53985[D loss: 0.999963] [G loss: 1.000102]\n",
      "epoch:13 step:53990[D loss: 0.999904] [G loss: 1.000211]\n",
      "epoch:13 step:53995[D loss: 0.999945] [G loss: 1.000165]\n",
      "epoch:13 step:54000[D loss: 0.999964] [G loss: 1.000118]\n",
      "##############\n",
      "[0.86457856 0.8742138  0.82700576 0.82720222 0.80033508 0.83496204\n",
      " 0.85044277 0.82414195 0.81576597 0.8292916 ]\n",
      "##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:13 step:54005[D loss: 0.999978] [G loss: 1.000084]\n",
      "epoch:13 step:54010[D loss: 0.999975] [G loss: 1.000061]\n",
      "epoch:13 step:54015[D loss: 1.000002] [G loss: 1.000001]\n",
      "epoch:13 step:54020[D loss: 1.000036] [G loss: 0.999978]\n",
      "epoch:13 step:54025[D loss: 0.999970] [G loss: 1.000100]\n",
      "epoch:13 step:54030[D loss: 0.999985] [G loss: 1.000072]\n",
      "epoch:13 step:54035[D loss: 0.999981] [G loss: 1.000086]\n",
      "epoch:13 step:54040[D loss: 0.999960] [G loss: 1.000070]\n",
      "epoch:13 step:54045[D loss: 0.999963] [G loss: 1.000101]\n",
      "epoch:13 step:54050[D loss: 0.999968] [G loss: 1.000073]\n",
      "epoch:13 step:54055[D loss: 0.999979] [G loss: 1.000054]\n",
      "epoch:13 step:54060[D loss: 0.999976] [G loss: 1.000063]\n",
      "epoch:13 step:54065[D loss: 0.999998] [G loss: 1.000053]\n",
      "epoch:13 step:54070[D loss: 0.999984] [G loss: 1.000006]\n",
      "epoch:13 step:54075[D loss: 0.999987] [G loss: 1.000069]\n",
      "epoch:13 step:54080[D loss: 0.999991] [G loss: 1.000044]\n",
      "epoch:13 step:54085[D loss: 0.999944] [G loss: 1.000068]\n",
      "epoch:13 step:54090[D loss: 0.999975] [G loss: 1.000060]\n",
      "epoch:13 step:54095[D loss: 0.999967] [G loss: 1.000071]\n",
      "epoch:13 step:54100[D loss: 0.999997] [G loss: 0.999998]\n",
      "epoch:13 step:54105[D loss: 0.999968] [G loss: 1.000054]\n",
      "epoch:13 step:54110[D loss: 0.999975] [G loss: 1.000053]\n",
      "epoch:13 step:54115[D loss: 0.999983] [G loss: 1.000047]\n",
      "epoch:13 step:54120[D loss: 0.999986] [G loss: 1.000053]\n",
      "epoch:13 step:54125[D loss: 0.999987] [G loss: 1.000061]\n",
      "epoch:13 step:54130[D loss: 1.000005] [G loss: 1.000027]\n",
      "epoch:13 step:54135[D loss: 0.999958] [G loss: 1.000097]\n",
      "epoch:13 step:54140[D loss: 0.999992] [G loss: 1.000062]\n",
      "epoch:13 step:54145[D loss: 0.999978] [G loss: 1.000075]\n",
      "epoch:13 step:54150[D loss: 0.999971] [G loss: 1.000068]\n",
      "epoch:13 step:54155[D loss: 0.999979] [G loss: 1.000031]\n",
      "epoch:13 step:54160[D loss: 0.999976] [G loss: 1.000062]\n",
      "epoch:13 step:54165[D loss: 0.999977] [G loss: 1.000059]\n",
      "epoch:13 step:54170[D loss: 1.000009] [G loss: 1.000028]\n",
      "epoch:13 step:54175[D loss: 0.999981] [G loss: 1.000057]\n",
      "epoch:13 step:54180[D loss: 0.999989] [G loss: 1.000032]\n",
      "epoch:13 step:54185[D loss: 0.999977] [G loss: 1.000061]\n",
      "epoch:13 step:54190[D loss: 0.999999] [G loss: 1.000033]\n",
      "epoch:13 step:54195[D loss: 0.999964] [G loss: 1.000086]\n",
      "epoch:13 step:54200[D loss: 1.000044] [G loss: 1.000006]\n",
      "##############\n",
      "[0.8731919  0.85573079 0.82978309 0.80738004 0.82252065 0.84553666\n",
      " 0.85755665 0.80979738 0.8317174  0.8363065 ]\n",
      "##########\n",
      "epoch:13 step:54205[D loss: 0.999968] [G loss: 1.000040]\n",
      "epoch:13 step:54210[D loss: 0.999920] [G loss: 1.000189]\n",
      "epoch:13 step:54215[D loss: 0.999970] [G loss: 1.000052]\n",
      "epoch:13 step:54220[D loss: 0.999969] [G loss: 1.000087]\n",
      "epoch:13 step:54225[D loss: 1.000093] [G loss: 0.999905]\n",
      "epoch:13 step:54230[D loss: 1.000092] [G loss: 0.999945]\n",
      "epoch:13 step:54235[D loss: 1.000089] [G loss: 0.999955]\n",
      "epoch:13 step:54240[D loss: 0.999916] [G loss: 1.000389]\n",
      "epoch:13 step:54245[D loss: 0.999949] [G loss: 1.000205]\n",
      "epoch:13 step:54250[D loss: 0.999944] [G loss: 1.000174]\n",
      "epoch:13 step:54255[D loss: 0.999980] [G loss: 1.000208]\n",
      "epoch:13 step:54260[D loss: 1.000051] [G loss: 1.000064]\n",
      "epoch:13 step:54265[D loss: 0.999940] [G loss: 1.000202]\n",
      "epoch:13 step:54270[D loss: 0.999960] [G loss: 1.000134]\n",
      "epoch:13 step:54275[D loss: 0.999959] [G loss: 1.000115]\n",
      "epoch:13 step:54280[D loss: 0.999974] [G loss: 1.000118]\n",
      "epoch:13 step:54285[D loss: 1.000009] [G loss: 0.999994]\n",
      "epoch:13 step:54290[D loss: 0.999959] [G loss: 1.000066]\n",
      "epoch:13 step:54295[D loss: 1.000158] [G loss: 0.999818]\n",
      "epoch:13 step:54300[D loss: 1.000158] [G loss: 0.999749]\n",
      "epoch:13 step:54305[D loss: 0.999985] [G loss: 1.000004]\n",
      "epoch:13 step:54310[D loss: 1.000004] [G loss: 1.000008]\n",
      "epoch:13 step:54315[D loss: 0.999991] [G loss: 0.999929]\n",
      "epoch:13 step:54320[D loss: 0.999977] [G loss: 1.000018]\n",
      "epoch:13 step:54325[D loss: 0.999953] [G loss: 1.000177]\n",
      "epoch:13 step:54330[D loss: 0.999941] [G loss: 1.000104]\n",
      "epoch:13 step:54335[D loss: 0.999945] [G loss: 1.000145]\n",
      "epoch:13 step:54340[D loss: 0.999957] [G loss: 1.000078]\n",
      "epoch:13 step:54345[D loss: 0.999973] [G loss: 1.000067]\n",
      "epoch:13 step:54350[D loss: 1.000000] [G loss: 0.999992]\n",
      "epoch:13 step:54355[D loss: 0.999974] [G loss: 1.000057]\n",
      "epoch:13 step:54360[D loss: 0.999991] [G loss: 1.000055]\n",
      "epoch:13 step:54365[D loss: 0.999954] [G loss: 1.000136]\n",
      "epoch:13 step:54370[D loss: 0.999934] [G loss: 1.000108]\n",
      "epoch:13 step:54375[D loss: 1.000025] [G loss: 1.000095]\n",
      "epoch:13 step:54380[D loss: 1.000045] [G loss: 1.000004]\n",
      "epoch:13 step:54385[D loss: 0.999936] [G loss: 1.000120]\n",
      "epoch:13 step:54390[D loss: 0.999944] [G loss: 1.000111]\n",
      "epoch:13 step:54395[D loss: 0.999985] [G loss: 1.000072]\n",
      "epoch:13 step:54400[D loss: 0.999987] [G loss: 1.000037]\n",
      "##############\n",
      "[0.84235943 0.86154762 0.82560866 0.82630895 0.79677775 0.84039313\n",
      " 0.87004241 0.85033496 0.82340201 0.83035413]\n",
      "##########\n",
      "epoch:13 step:54405[D loss: 0.999971] [G loss: 1.000069]\n",
      "epoch:13 step:54410[D loss: 0.999978] [G loss: 1.000062]\n",
      "epoch:13 step:54415[D loss: 0.999979] [G loss: 1.000067]\n",
      "epoch:13 step:54420[D loss: 0.999971] [G loss: 1.000062]\n",
      "epoch:13 step:54425[D loss: 1.000002] [G loss: 1.000023]\n",
      "epoch:13 step:54430[D loss: 0.999989] [G loss: 1.000049]\n",
      "epoch:13 step:54435[D loss: 0.999969] [G loss: 1.000072]\n",
      "epoch:13 step:54440[D loss: 0.999964] [G loss: 1.000055]\n",
      "epoch:13 step:54445[D loss: 0.999975] [G loss: 1.000078]\n",
      "epoch:13 step:54450[D loss: 0.999989] [G loss: 1.000039]\n",
      "epoch:13 step:54455[D loss: 0.999962] [G loss: 1.000088]\n",
      "epoch:13 step:54460[D loss: 1.000002] [G loss: 1.000065]\n",
      "epoch:13 step:54465[D loss: 0.999974] [G loss: 1.000072]\n",
      "epoch:13 step:54470[D loss: 0.999976] [G loss: 1.000066]\n",
      "epoch:13 step:54475[D loss: 1.000003] [G loss: 1.000012]\n",
      "epoch:13 step:54480[D loss: 0.999970] [G loss: 1.000048]\n",
      "epoch:13 step:54485[D loss: 0.999984] [G loss: 1.000028]\n",
      "epoch:13 step:54490[D loss: 0.999961] [G loss: 1.000088]\n",
      "epoch:13 step:54495[D loss: 0.999982] [G loss: 1.000038]\n",
      "epoch:13 step:54500[D loss: 0.999971] [G loss: 1.000037]\n",
      "epoch:13 step:54505[D loss: 0.999986] [G loss: 1.000037]\n",
      "epoch:13 step:54510[D loss: 0.999994] [G loss: 1.000021]\n",
      "epoch:13 step:54515[D loss: 0.999970] [G loss: 1.000065]\n",
      "epoch:13 step:54520[D loss: 1.000014] [G loss: 0.999962]\n",
      "epoch:13 step:54525[D loss: 0.999963] [G loss: 1.000050]\n",
      "epoch:13 step:54530[D loss: 0.999986] [G loss: 1.000035]\n",
      "epoch:13 step:54535[D loss: 0.999980] [G loss: 1.000077]\n",
      "epoch:13 step:54540[D loss: 0.999964] [G loss: 1.000060]\n",
      "epoch:13 step:54545[D loss: 0.999989] [G loss: 1.000043]\n",
      "epoch:13 step:54550[D loss: 0.999963] [G loss: 1.000085]\n",
      "epoch:13 step:54555[D loss: 0.999978] [G loss: 1.000077]\n",
      "epoch:13 step:54560[D loss: 0.999988] [G loss: 1.000067]\n",
      "epoch:13 step:54565[D loss: 0.999982] [G loss: 1.000068]\n",
      "epoch:13 step:54570[D loss: 0.999984] [G loss: 1.000109]\n",
      "epoch:13 step:54575[D loss: 0.999996] [G loss: 1.000069]\n",
      "epoch:13 step:54580[D loss: 0.999979] [G loss: 1.000053]\n",
      "epoch:13 step:54585[D loss: 1.000088] [G loss: 0.999944]\n",
      "epoch:13 step:54590[D loss: 1.000039] [G loss: 0.999943]\n",
      "epoch:13 step:54595[D loss: 0.999922] [G loss: 1.000175]\n",
      "epoch:13 step:54600[D loss: 0.999972] [G loss: 1.000071]\n",
      "##############\n",
      "[0.86374395 0.87477076 0.82937294 0.83674024 0.82061633 0.845673\n",
      " 0.86451436 0.85102317 0.79644868 0.84560032]\n",
      "##########\n",
      "epoch:13 step:54605[D loss: 0.999952] [G loss: 1.000086]\n",
      "epoch:13 step:54610[D loss: 1.000012] [G loss: 1.000042]\n",
      "epoch:13 step:54615[D loss: 0.999960] [G loss: 1.000125]\n",
      "epoch:13 step:54620[D loss: 0.999924] [G loss: 1.000118]\n",
      "epoch:13 step:54625[D loss: 1.000074] [G loss: 0.999958]\n",
      "epoch:13 step:54630[D loss: 1.000010] [G loss: 1.000025]\n",
      "epoch:13 step:54635[D loss: 1.000126] [G loss: 1.000002]\n",
      "epoch:13 step:54640[D loss: 0.999960] [G loss: 1.000166]\n",
      "epoch:13 step:54645[D loss: 0.999956] [G loss: 1.000140]\n",
      "epoch:13 step:54650[D loss: 0.999999] [G loss: 0.999984]\n",
      "epoch:13 step:54655[D loss: 0.999991] [G loss: 1.000019]\n",
      "epoch:13 step:54660[D loss: 0.999957] [G loss: 0.999997]\n",
      "epoch:13 step:54665[D loss: 0.999976] [G loss: 1.000031]\n",
      "epoch:13 step:54670[D loss: 1.000038] [G loss: 0.999998]\n",
      "epoch:14 step:54675[D loss: 1.000038] [G loss: 0.999936]\n",
      "epoch:14 step:54680[D loss: 0.999920] [G loss: 1.000076]\n",
      "epoch:14 step:54685[D loss: 0.999962] [G loss: 1.000064]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:14 step:54690[D loss: 0.999968] [G loss: 1.000067]\n",
      "epoch:14 step:54695[D loss: 0.999988] [G loss: 1.000058]\n",
      "epoch:14 step:54700[D loss: 0.999974] [G loss: 1.000074]\n",
      "epoch:14 step:54705[D loss: 0.999975] [G loss: 1.000082]\n",
      "epoch:14 step:54710[D loss: 0.999969] [G loss: 1.000083]\n",
      "epoch:14 step:54715[D loss: 0.999981] [G loss: 1.000057]\n",
      "epoch:14 step:54720[D loss: 0.999988] [G loss: 1.000043]\n",
      "epoch:14 step:54725[D loss: 0.999987] [G loss: 1.000057]\n",
      "epoch:14 step:54730[D loss: 0.999968] [G loss: 1.000083]\n",
      "epoch:14 step:54735[D loss: 0.999969] [G loss: 1.000083]\n",
      "epoch:14 step:54740[D loss: 0.999968] [G loss: 1.000061]\n",
      "epoch:14 step:54745[D loss: 1.000000] [G loss: 1.000024]\n",
      "epoch:14 step:54750[D loss: 0.999943] [G loss: 1.000121]\n",
      "epoch:14 step:54755[D loss: 0.999990] [G loss: 1.000098]\n",
      "epoch:14 step:54760[D loss: 1.000012] [G loss: 1.000090]\n",
      "epoch:14 step:54765[D loss: 0.999948] [G loss: 1.000118]\n",
      "epoch:14 step:54770[D loss: 0.999937] [G loss: 1.000187]\n",
      "epoch:14 step:54775[D loss: 0.999978] [G loss: 1.000089]\n",
      "epoch:14 step:54780[D loss: 1.000000] [G loss: 1.000000]\n",
      "epoch:14 step:54785[D loss: 0.999977] [G loss: 1.000084]\n",
      "epoch:14 step:54790[D loss: 1.000141] [G loss: 0.999934]\n",
      "epoch:14 step:54795[D loss: 0.999937] [G loss: 1.000099]\n",
      "epoch:14 step:54800[D loss: 0.999935] [G loss: 1.000146]\n",
      "##############\n",
      "[0.86395718 0.86116562 0.83208518 0.8292996  0.81620665 0.84444774\n",
      " 0.87335024 0.84120682 0.8266554  0.83322582]\n",
      "##########\n",
      "epoch:14 step:54805[D loss: 1.000030] [G loss: 0.999911]\n",
      "epoch:14 step:54810[D loss: 0.999995] [G loss: 1.000083]\n",
      "epoch:14 step:54815[D loss: 0.999957] [G loss: 1.000111]\n",
      "epoch:14 step:54820[D loss: 0.999990] [G loss: 1.000031]\n",
      "epoch:14 step:54825[D loss: 1.000019] [G loss: 0.999982]\n",
      "epoch:14 step:54830[D loss: 1.000066] [G loss: 0.999928]\n",
      "epoch:14 step:54835[D loss: 0.999986] [G loss: 0.999989]\n",
      "epoch:14 step:54840[D loss: 1.000052] [G loss: 0.999931]\n",
      "epoch:14 step:54845[D loss: 1.000107] [G loss: 0.999905]\n",
      "epoch:14 step:54850[D loss: 0.999958] [G loss: 1.000132]\n",
      "epoch:14 step:54855[D loss: 0.999940] [G loss: 1.000237]\n",
      "epoch:14 step:54860[D loss: 0.999919] [G loss: 1.000171]\n",
      "epoch:14 step:54865[D loss: 0.999920] [G loss: 1.000134]\n",
      "epoch:14 step:54870[D loss: 0.999953] [G loss: 1.000119]\n",
      "epoch:14 step:54875[D loss: 0.999969] [G loss: 1.000095]\n",
      "epoch:14 step:54880[D loss: 0.999938] [G loss: 1.000145]\n",
      "epoch:14 step:54885[D loss: 0.999977] [G loss: 1.000098]\n",
      "epoch:14 step:54890[D loss: 0.999976] [G loss: 1.000103]\n",
      "epoch:14 step:54895[D loss: 0.999977] [G loss: 1.000058]\n",
      "epoch:14 step:54900[D loss: 0.999969] [G loss: 1.000078]\n",
      "epoch:14 step:54905[D loss: 0.999996] [G loss: 1.000035]\n",
      "epoch:14 step:54910[D loss: 1.000027] [G loss: 1.000002]\n",
      "epoch:14 step:54915[D loss: 0.999979] [G loss: 1.000017]\n",
      "epoch:14 step:54920[D loss: 1.000011] [G loss: 0.999998]\n",
      "epoch:14 step:54925[D loss: 0.999965] [G loss: 1.000034]\n",
      "epoch:14 step:54930[D loss: 0.999951] [G loss: 1.000099]\n",
      "epoch:14 step:54935[D loss: 0.999977] [G loss: 1.000069]\n",
      "epoch:14 step:54940[D loss: 0.999977] [G loss: 1.000044]\n",
      "epoch:14 step:54945[D loss: 0.999983] [G loss: 1.000079]\n",
      "epoch:14 step:54950[D loss: 0.999954] [G loss: 1.000093]\n",
      "epoch:14 step:54955[D loss: 0.999992] [G loss: 1.000071]\n",
      "epoch:14 step:54960[D loss: 1.000011] [G loss: 0.999926]\n",
      "epoch:14 step:54965[D loss: 0.999932] [G loss: 1.000091]\n",
      "epoch:14 step:54970[D loss: 0.999963] [G loss: 1.000069]\n",
      "epoch:14 step:54975[D loss: 1.000001] [G loss: 1.000033]\n",
      "epoch:14 step:54980[D loss: 0.999955] [G loss: 1.000092]\n",
      "epoch:14 step:54985[D loss: 0.999993] [G loss: 1.000023]\n",
      "epoch:14 step:54990[D loss: 0.999959] [G loss: 1.000101]\n",
      "epoch:14 step:54995[D loss: 1.000038] [G loss: 1.000017]\n",
      "epoch:14 step:55000[D loss: 0.999958] [G loss: 1.000083]\n",
      "##############\n",
      "[0.86453903 0.88531537 0.82813824 0.81855546 0.79209516 0.83101893\n",
      " 0.87953762 0.85855321 0.8040749  0.83154513]\n",
      "##########\n",
      "epoch:14 step:55005[D loss: 0.999964] [G loss: 1.000079]\n",
      "epoch:14 step:55010[D loss: 0.999969] [G loss: 1.000087]\n",
      "epoch:14 step:55015[D loss: 0.999966] [G loss: 1.000084]\n",
      "epoch:14 step:55020[D loss: 0.999986] [G loss: 1.000001]\n",
      "epoch:14 step:55025[D loss: 1.000094] [G loss: 1.000026]\n",
      "epoch:14 step:55030[D loss: 1.000019] [G loss: 1.000113]\n",
      "epoch:14 step:55035[D loss: 1.000035] [G loss: 1.000115]\n",
      "epoch:14 step:55040[D loss: 0.999961] [G loss: 1.000112]\n",
      "epoch:14 step:55045[D loss: 1.000054] [G loss: 1.000047]\n",
      "epoch:14 step:55050[D loss: 0.999953] [G loss: 1.000095]\n",
      "epoch:14 step:55055[D loss: 0.999934] [G loss: 1.000186]\n",
      "epoch:14 step:55060[D loss: 0.999957] [G loss: 1.000199]\n",
      "epoch:14 step:55065[D loss: 0.999956] [G loss: 1.000096]\n",
      "epoch:14 step:55070[D loss: 0.999964] [G loss: 1.000041]\n",
      "epoch:14 step:55075[D loss: 1.000025] [G loss: 0.999916]\n",
      "epoch:14 step:55080[D loss: 1.000000] [G loss: 0.999990]\n",
      "epoch:14 step:55085[D loss: 0.999941] [G loss: 1.000008]\n",
      "epoch:14 step:55090[D loss: 0.999928] [G loss: 0.999986]\n",
      "epoch:14 step:55095[D loss: 1.000018] [G loss: 0.999945]\n",
      "epoch:14 step:55100[D loss: 0.999958] [G loss: 1.000005]\n",
      "epoch:14 step:55105[D loss: 0.999978] [G loss: 1.000039]\n",
      "epoch:14 step:55110[D loss: 1.000015] [G loss: 0.999953]\n",
      "epoch:14 step:55115[D loss: 1.000033] [G loss: 1.000137]\n",
      "epoch:14 step:55120[D loss: 0.999915] [G loss: 1.000122]\n",
      "epoch:14 step:55125[D loss: 0.999963] [G loss: 1.000091]\n",
      "epoch:14 step:55130[D loss: 0.999951] [G loss: 1.000052]\n",
      "epoch:14 step:55135[D loss: 0.999941] [G loss: 1.000076]\n",
      "epoch:14 step:55140[D loss: 0.999987] [G loss: 1.000014]\n",
      "epoch:14 step:55145[D loss: 0.999966] [G loss: 1.000031]\n",
      "epoch:14 step:55150[D loss: 1.000039] [G loss: 0.999959]\n",
      "epoch:14 step:55155[D loss: 0.999985] [G loss: 0.999974]\n",
      "epoch:14 step:55160[D loss: 1.000061] [G loss: 0.999959]\n",
      "epoch:14 step:55165[D loss: 1.000063] [G loss: 0.999975]\n",
      "epoch:14 step:55170[D loss: 1.000055] [G loss: 0.999900]\n",
      "epoch:14 step:55175[D loss: 0.999933] [G loss: 1.000054]\n",
      "epoch:14 step:55180[D loss: 0.999999] [G loss: 1.000090]\n",
      "epoch:14 step:55185[D loss: 0.999961] [G loss: 1.000062]\n",
      "epoch:14 step:55190[D loss: 1.000047] [G loss: 0.999959]\n",
      "epoch:14 step:55195[D loss: 1.000016] [G loss: 1.000041]\n",
      "epoch:14 step:55200[D loss: 0.999994] [G loss: 1.000037]\n",
      "##############\n",
      "[0.85215025 0.84762162 0.81252424 0.82582703 0.78234095 0.83644985\n",
      " 0.88908617 0.85919335 0.81051157 0.83686229]\n",
      "##########\n",
      "epoch:14 step:55205[D loss: 0.999997] [G loss: 1.000016]\n",
      "epoch:14 step:55210[D loss: 0.999977] [G loss: 1.000112]\n",
      "epoch:14 step:55215[D loss: 0.999955] [G loss: 1.000129]\n",
      "epoch:14 step:55220[D loss: 0.999959] [G loss: 1.000169]\n",
      "epoch:14 step:55225[D loss: 0.999981] [G loss: 1.000020]\n",
      "epoch:14 step:55230[D loss: 0.999950] [G loss: 1.000084]\n",
      "epoch:14 step:55235[D loss: 0.999999] [G loss: 1.000020]\n",
      "epoch:14 step:55240[D loss: 0.999956] [G loss: 1.000055]\n",
      "epoch:14 step:55245[D loss: 0.999995] [G loss: 1.000010]\n",
      "epoch:14 step:55250[D loss: 0.999957] [G loss: 1.000057]\n",
      "epoch:14 step:55255[D loss: 1.000001] [G loss: 1.000051]\n",
      "epoch:14 step:55260[D loss: 0.999997] [G loss: 1.000034]\n",
      "epoch:14 step:55265[D loss: 0.999983] [G loss: 1.000012]\n",
      "epoch:14 step:55270[D loss: 0.999991] [G loss: 1.000074]\n",
      "epoch:14 step:55275[D loss: 0.999981] [G loss: 1.000071]\n",
      "epoch:14 step:55280[D loss: 0.999965] [G loss: 1.000089]\n",
      "epoch:14 step:55285[D loss: 0.999962] [G loss: 1.000091]\n",
      "epoch:14 step:55290[D loss: 0.999979] [G loss: 1.000067]\n",
      "epoch:14 step:55295[D loss: 0.999968] [G loss: 1.000054]\n",
      "epoch:14 step:55300[D loss: 0.999960] [G loss: 1.000076]\n",
      "epoch:14 step:55305[D loss: 0.999962] [G loss: 1.000095]\n",
      "epoch:14 step:55310[D loss: 0.999974] [G loss: 1.000059]\n",
      "epoch:14 step:55315[D loss: 0.999938] [G loss: 1.000093]\n",
      "epoch:14 step:55320[D loss: 0.999963] [G loss: 1.000102]\n",
      "epoch:14 step:55325[D loss: 1.000028] [G loss: 0.999979]\n",
      "epoch:14 step:55330[D loss: 0.999972] [G loss: 1.000063]\n",
      "epoch:14 step:55335[D loss: 0.999991] [G loss: 1.000047]\n",
      "epoch:14 step:55340[D loss: 1.000112] [G loss: 0.999840]\n",
      "epoch:14 step:55345[D loss: 0.999907] [G loss: 1.000163]\n",
      "epoch:14 step:55350[D loss: 0.999979] [G loss: 1.000125]\n",
      "epoch:14 step:55355[D loss: 0.999934] [G loss: 1.000095]\n",
      "epoch:14 step:55360[D loss: 0.999966] [G loss: 1.000102]\n",
      "epoch:14 step:55365[D loss: 1.000029] [G loss: 0.999973]\n",
      "epoch:14 step:55370[D loss: 1.000032] [G loss: 0.999989]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:14 step:55375[D loss: 1.000135] [G loss: 0.999782]\n",
      "epoch:14 step:55380[D loss: 1.000005] [G loss: 0.999957]\n",
      "epoch:14 step:55385[D loss: 0.999830] [G loss: 1.000245]\n",
      "epoch:14 step:55390[D loss: 0.999946] [G loss: 1.000149]\n",
      "epoch:14 step:55395[D loss: 0.999960] [G loss: 1.000003]\n",
      "epoch:14 step:55400[D loss: 0.999963] [G loss: 1.000076]\n",
      "##############\n",
      "[0.85806648 0.86266075 0.8242885  0.82193129 0.81253878 0.8413744\n",
      " 0.87561811 0.82270346 0.8311593  0.83821301]\n",
      "##########\n",
      "epoch:14 step:55405[D loss: 0.999968] [G loss: 1.000001]\n",
      "epoch:14 step:55410[D loss: 0.999991] [G loss: 0.999990]\n",
      "epoch:14 step:55415[D loss: 0.999991] [G loss: 0.999997]\n",
      "epoch:14 step:55420[D loss: 0.999965] [G loss: 1.000020]\n",
      "epoch:14 step:55425[D loss: 0.999968] [G loss: 1.000059]\n",
      "epoch:14 step:55430[D loss: 0.999959] [G loss: 1.000157]\n",
      "epoch:14 step:55435[D loss: 0.999957] [G loss: 1.000080]\n",
      "epoch:14 step:55440[D loss: 0.999978] [G loss: 0.999990]\n",
      "epoch:14 step:55445[D loss: 0.999980] [G loss: 1.000032]\n",
      "epoch:14 step:55450[D loss: 0.999969] [G loss: 1.000048]\n",
      "epoch:14 step:55455[D loss: 0.999973] [G loss: 1.000047]\n",
      "epoch:14 step:55460[D loss: 0.999974] [G loss: 1.000027]\n",
      "epoch:14 step:55465[D loss: 1.000022] [G loss: 0.999979]\n",
      "epoch:14 step:55470[D loss: 0.999931] [G loss: 1.000111]\n",
      "epoch:14 step:55475[D loss: 0.999984] [G loss: 1.000043]\n",
      "epoch:14 step:55480[D loss: 0.999990] [G loss: 1.000009]\n",
      "epoch:14 step:55485[D loss: 0.999960] [G loss: 1.000071]\n",
      "epoch:14 step:55490[D loss: 0.999975] [G loss: 1.000066]\n",
      "epoch:14 step:55495[D loss: 0.999939] [G loss: 1.000112]\n",
      "epoch:14 step:55500[D loss: 0.999951] [G loss: 1.000058]\n",
      "epoch:14 step:55505[D loss: 1.000009] [G loss: 0.999947]\n",
      "epoch:14 step:55510[D loss: 0.999969] [G loss: 1.000038]\n",
      "epoch:14 step:55515[D loss: 1.000020] [G loss: 0.999966]\n",
      "epoch:14 step:55520[D loss: 0.999976] [G loss: 1.000122]\n",
      "epoch:14 step:55525[D loss: 1.000065] [G loss: 1.000017]\n",
      "epoch:14 step:55530[D loss: 0.999901] [G loss: 1.000266]\n",
      "epoch:14 step:55535[D loss: 0.999983] [G loss: 1.000068]\n",
      "epoch:14 step:55540[D loss: 0.999969] [G loss: 1.000071]\n",
      "epoch:14 step:55545[D loss: 0.999997] [G loss: 1.000023]\n",
      "epoch:14 step:55550[D loss: 1.000129] [G loss: 0.999868]\n",
      "epoch:14 step:55555[D loss: 0.999974] [G loss: 0.999980]\n",
      "epoch:14 step:55560[D loss: 1.000017] [G loss: 0.999912]\n",
      "epoch:14 step:55565[D loss: 1.000034] [G loss: 1.000163]\n",
      "epoch:14 step:55570[D loss: 1.000008] [G loss: 1.000085]\n",
      "epoch:14 step:55575[D loss: 0.999852] [G loss: 1.000232]\n",
      "epoch:14 step:55580[D loss: 0.999952] [G loss: 1.000055]\n",
      "epoch:14 step:55585[D loss: 1.000075] [G loss: 0.999884]\n",
      "epoch:14 step:55590[D loss: 0.999972] [G loss: 0.999934]\n",
      "epoch:14 step:55595[D loss: 0.999986] [G loss: 1.000056]\n",
      "epoch:14 step:55600[D loss: 0.999932] [G loss: 1.000084]\n",
      "##############\n",
      "[0.87321153 0.85109727 0.82879548 0.82838162 0.80590268 0.83566776\n",
      " 0.86645527 0.83241174 0.82351449 0.83899692]\n",
      "##########\n",
      "epoch:14 step:55605[D loss: 0.999975] [G loss: 1.000023]\n",
      "epoch:14 step:55610[D loss: 0.999977] [G loss: 1.000066]\n",
      "epoch:14 step:55615[D loss: 0.999978] [G loss: 1.000035]\n",
      "epoch:14 step:55620[D loss: 1.000025] [G loss: 1.000018]\n",
      "epoch:14 step:55625[D loss: 0.999953] [G loss: 1.000057]\n",
      "epoch:14 step:55630[D loss: 0.999966] [G loss: 1.000085]\n",
      "epoch:14 step:55635[D loss: 0.999996] [G loss: 1.000009]\n",
      "epoch:14 step:55640[D loss: 0.999983] [G loss: 1.000028]\n",
      "epoch:14 step:55645[D loss: 0.999953] [G loss: 1.000078]\n",
      "epoch:14 step:55650[D loss: 0.999969] [G loss: 1.000056]\n",
      "epoch:14 step:55655[D loss: 1.000054] [G loss: 0.999992]\n",
      "epoch:14 step:55660[D loss: 0.999948] [G loss: 1.000121]\n",
      "epoch:14 step:55665[D loss: 0.999956] [G loss: 1.000080]\n",
      "epoch:14 step:55670[D loss: 0.999946] [G loss: 1.000110]\n",
      "epoch:14 step:55675[D loss: 1.000038] [G loss: 1.000021]\n",
      "epoch:14 step:55680[D loss: 0.999927] [G loss: 1.000180]\n",
      "epoch:14 step:55685[D loss: 0.999964] [G loss: 1.000114]\n",
      "epoch:14 step:55690[D loss: 0.999969] [G loss: 1.000125]\n",
      "epoch:14 step:55695[D loss: 0.999961] [G loss: 1.000065]\n",
      "epoch:14 step:55700[D loss: 0.999997] [G loss: 1.000063]\n",
      "epoch:14 step:55705[D loss: 0.999972] [G loss: 1.000022]\n",
      "epoch:14 step:55710[D loss: 0.999960] [G loss: 1.000064]\n",
      "epoch:14 step:55715[D loss: 1.000006] [G loss: 0.999958]\n",
      "epoch:14 step:55720[D loss: 0.999940] [G loss: 1.000064]\n",
      "epoch:14 step:55725[D loss: 0.999971] [G loss: 1.000066]\n",
      "epoch:14 step:55730[D loss: 0.999982] [G loss: 1.000058]\n",
      "epoch:14 step:55735[D loss: 0.999976] [G loss: 1.000087]\n",
      "epoch:14 step:55740[D loss: 1.000010] [G loss: 0.999967]\n",
      "epoch:14 step:55745[D loss: 0.999965] [G loss: 1.000048]\n",
      "epoch:14 step:55750[D loss: 0.999969] [G loss: 1.000086]\n",
      "epoch:14 step:55755[D loss: 0.999956] [G loss: 1.000076]\n",
      "epoch:14 step:55760[D loss: 0.999989] [G loss: 1.000034]\n",
      "epoch:14 step:55765[D loss: 1.000011] [G loss: 1.000022]\n",
      "epoch:14 step:55770[D loss: 0.999986] [G loss: 1.000057]\n",
      "epoch:14 step:55775[D loss: 0.999961] [G loss: 1.000088]\n",
      "epoch:14 step:55780[D loss: 0.999974] [G loss: 1.000050]\n",
      "epoch:14 step:55785[D loss: 0.999978] [G loss: 1.000043]\n",
      "epoch:14 step:55790[D loss: 1.000038] [G loss: 0.999939]\n",
      "epoch:14 step:55795[D loss: 1.000003] [G loss: 1.000024]\n",
      "epoch:14 step:55800[D loss: 0.999951] [G loss: 1.000158]\n",
      "##############\n",
      "[0.84958243 0.84865203 0.80303894 0.82030884 0.81352009 0.84440961\n",
      " 0.87221813 0.84970749 0.84158479 0.83598632]\n",
      "##########\n",
      "epoch:14 step:55805[D loss: 0.999948] [G loss: 1.000162]\n",
      "epoch:14 step:55810[D loss: 0.999981] [G loss: 1.000118]\n",
      "epoch:14 step:55815[D loss: 0.999965] [G loss: 1.000052]\n",
      "epoch:14 step:55820[D loss: 1.000000] [G loss: 1.000028]\n",
      "epoch:14 step:55825[D loss: 0.999986] [G loss: 1.000051]\n",
      "epoch:14 step:55830[D loss: 0.999972] [G loss: 1.000049]\n",
      "epoch:14 step:55835[D loss: 0.999984] [G loss: 1.000028]\n",
      "epoch:14 step:55840[D loss: 0.999967] [G loss: 1.000061]\n",
      "epoch:14 step:55845[D loss: 0.999984] [G loss: 1.000026]\n",
      "epoch:14 step:55850[D loss: 0.999981] [G loss: 1.000040]\n",
      "epoch:14 step:55855[D loss: 0.999979] [G loss: 1.000068]\n",
      "epoch:14 step:55860[D loss: 0.999969] [G loss: 1.000071]\n",
      "epoch:14 step:55865[D loss: 0.999975] [G loss: 1.000096]\n",
      "epoch:14 step:55870[D loss: 0.999977] [G loss: 1.000045]\n",
      "epoch:14 step:55875[D loss: 0.999974] [G loss: 1.000052]\n",
      "epoch:14 step:55880[D loss: 1.000001] [G loss: 1.000036]\n",
      "epoch:14 step:55885[D loss: 0.999997] [G loss: 1.000137]\n",
      "epoch:14 step:55890[D loss: 1.000066] [G loss: 0.999991]\n",
      "epoch:14 step:55895[D loss: 0.999969] [G loss: 1.000087]\n",
      "epoch:14 step:55900[D loss: 0.999948] [G loss: 1.000182]\n",
      "epoch:14 step:55905[D loss: 1.000025] [G loss: 1.000044]\n",
      "epoch:14 step:55910[D loss: 0.999923] [G loss: 1.000103]\n",
      "epoch:14 step:55915[D loss: 0.999974] [G loss: 1.000027]\n",
      "epoch:14 step:55920[D loss: 1.000071] [G loss: 0.999951]\n",
      "epoch:14 step:55925[D loss: 0.999999] [G loss: 0.999912]\n",
      "epoch:14 step:55930[D loss: 1.000033] [G loss: 0.999898]\n",
      "epoch:14 step:55935[D loss: 1.000006] [G loss: 1.000036]\n",
      "epoch:14 step:55940[D loss: 0.999956] [G loss: 1.000092]\n",
      "epoch:14 step:55945[D loss: 0.999937] [G loss: 1.000135]\n",
      "epoch:14 step:55950[D loss: 0.999995] [G loss: 1.000043]\n",
      "epoch:14 step:55955[D loss: 0.999938] [G loss: 1.000092]\n",
      "epoch:14 step:55960[D loss: 0.999967] [G loss: 1.000102]\n",
      "epoch:14 step:55965[D loss: 0.999962] [G loss: 1.000065]\n",
      "epoch:14 step:55970[D loss: 0.999974] [G loss: 1.000072]\n",
      "epoch:14 step:55975[D loss: 0.999982] [G loss: 1.000034]\n",
      "epoch:14 step:55980[D loss: 1.000008] [G loss: 1.000025]\n",
      "epoch:14 step:55985[D loss: 0.999938] [G loss: 1.000094]\n",
      "epoch:14 step:55990[D loss: 0.999974] [G loss: 1.000041]\n",
      "epoch:14 step:55995[D loss: 0.999981] [G loss: 1.000056]\n",
      "epoch:14 step:56000[D loss: 0.999988] [G loss: 1.000040]\n",
      "##############\n",
      "[0.85080627 0.84302994 0.83070087 0.82237224 0.80177578 0.85412069\n",
      " 0.86694539 0.83024305 0.82732199 0.83148067]\n",
      "##########\n",
      "epoch:14 step:56005[D loss: 0.999964] [G loss: 1.000042]\n",
      "epoch:14 step:56010[D loss: 0.999974] [G loss: 1.000071]\n",
      "epoch:14 step:56015[D loss: 0.999969] [G loss: 1.000047]\n",
      "epoch:14 step:56020[D loss: 0.999984] [G loss: 1.000038]\n",
      "epoch:14 step:56025[D loss: 0.999976] [G loss: 1.000068]\n",
      "epoch:14 step:56030[D loss: 0.999987] [G loss: 1.000036]\n",
      "epoch:14 step:56035[D loss: 0.999985] [G loss: 1.000098]\n",
      "epoch:14 step:56040[D loss: 0.999960] [G loss: 1.000071]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:14 step:56045[D loss: 1.000047] [G loss: 0.999943]\n",
      "epoch:14 step:56050[D loss: 1.000203] [G loss: 0.999829]\n",
      "epoch:14 step:56055[D loss: 0.999897] [G loss: 1.000031]\n",
      "epoch:14 step:56060[D loss: 0.999981] [G loss: 1.000055]\n",
      "epoch:14 step:56065[D loss: 0.999975] [G loss: 1.000037]\n",
      "epoch:14 step:56070[D loss: 0.999989] [G loss: 1.000067]\n",
      "epoch:14 step:56075[D loss: 0.999992] [G loss: 1.000054]\n",
      "epoch:14 step:56080[D loss: 0.999998] [G loss: 1.000065]\n",
      "epoch:14 step:56085[D loss: 0.999975] [G loss: 1.000089]\n",
      "epoch:14 step:56090[D loss: 0.999977] [G loss: 1.000030]\n",
      "epoch:14 step:56095[D loss: 1.000029] [G loss: 1.000051]\n",
      "epoch:14 step:56100[D loss: 0.999978] [G loss: 1.000071]\n",
      "epoch:14 step:56105[D loss: 0.999939] [G loss: 1.000042]\n",
      "epoch:14 step:56110[D loss: 0.999983] [G loss: 1.000074]\n",
      "epoch:14 step:56115[D loss: 0.999977] [G loss: 1.000088]\n",
      "epoch:14 step:56120[D loss: 0.999957] [G loss: 1.000087]\n",
      "epoch:14 step:56125[D loss: 0.999974] [G loss: 1.000067]\n",
      "epoch:14 step:56130[D loss: 0.999973] [G loss: 1.000066]\n",
      "epoch:14 step:56135[D loss: 0.999973] [G loss: 1.000077]\n",
      "epoch:14 step:56140[D loss: 0.999979] [G loss: 1.000062]\n",
      "epoch:14 step:56145[D loss: 1.000019] [G loss: 0.999985]\n",
      "epoch:14 step:56150[D loss: 0.999947] [G loss: 1.000096]\n",
      "epoch:14 step:56155[D loss: 0.999981] [G loss: 1.000096]\n",
      "epoch:14 step:56160[D loss: 0.999961] [G loss: 1.000090]\n",
      "epoch:14 step:56165[D loss: 0.999980] [G loss: 1.000074]\n",
      "epoch:14 step:56170[D loss: 0.999982] [G loss: 1.000060]\n",
      "epoch:14 step:56175[D loss: 0.999964] [G loss: 1.000081]\n",
      "epoch:14 step:56180[D loss: 0.999972] [G loss: 1.000107]\n",
      "epoch:14 step:56185[D loss: 0.999964] [G loss: 1.000099]\n",
      "epoch:14 step:56190[D loss: 0.999956] [G loss: 1.000114]\n",
      "epoch:14 step:56195[D loss: 0.999974] [G loss: 1.000066]\n",
      "epoch:14 step:56200[D loss: 0.999969] [G loss: 1.000111]\n",
      "##############\n",
      "[0.855276   0.86240537 0.81480418 0.83017896 0.81745732 0.8187281\n",
      " 0.87523164 0.83918094 0.81973903 0.84206659]\n",
      "##########\n",
      "epoch:14 step:56205[D loss: 0.999978] [G loss: 1.000091]\n",
      "epoch:14 step:56210[D loss: 0.999973] [G loss: 1.000097]\n",
      "epoch:14 step:56215[D loss: 0.999963] [G loss: 1.000091]\n",
      "epoch:14 step:56220[D loss: 1.000026] [G loss: 1.000001]\n",
      "epoch:14 step:56225[D loss: 0.999960] [G loss: 1.000072]\n",
      "epoch:14 step:56230[D loss: 0.999967] [G loss: 1.000076]\n",
      "epoch:14 step:56235[D loss: 0.999970] [G loss: 1.000067]\n",
      "epoch:14 step:56240[D loss: 1.000015] [G loss: 1.000009]\n",
      "epoch:14 step:56245[D loss: 1.000081] [G loss: 0.999937]\n",
      "epoch:14 step:56250[D loss: 1.000014] [G loss: 1.000027]\n",
      "epoch:14 step:56255[D loss: 0.999931] [G loss: 1.000114]\n",
      "epoch:14 step:56260[D loss: 0.999958] [G loss: 1.000104]\n",
      "epoch:14 step:56265[D loss: 0.999985] [G loss: 1.000068]\n",
      "epoch:14 step:56270[D loss: 0.999988] [G loss: 1.000067]\n",
      "epoch:14 step:56275[D loss: 0.999944] [G loss: 1.000092]\n",
      "epoch:14 step:56280[D loss: 0.999972] [G loss: 1.000078]\n",
      "epoch:14 step:56285[D loss: 0.999992] [G loss: 1.000062]\n",
      "epoch:14 step:56290[D loss: 0.999972] [G loss: 1.000070]\n",
      "epoch:14 step:56295[D loss: 1.000040] [G loss: 1.000056]\n",
      "epoch:14 step:56300[D loss: 0.999989] [G loss: 1.000016]\n",
      "epoch:14 step:56305[D loss: 1.000007] [G loss: 1.000061]\n",
      "epoch:14 step:56310[D loss: 0.999950] [G loss: 1.000132]\n",
      "epoch:14 step:56315[D loss: 1.000002] [G loss: 1.000080]\n",
      "epoch:14 step:56320[D loss: 0.999994] [G loss: 1.000060]\n",
      "epoch:14 step:56325[D loss: 0.999979] [G loss: 1.000159]\n",
      "epoch:14 step:56330[D loss: 0.999996] [G loss: 1.000093]\n",
      "epoch:14 step:56335[D loss: 1.000017] [G loss: 0.999984]\n",
      "epoch:14 step:56340[D loss: 0.999972] [G loss: 1.000082]\n",
      "epoch:14 step:56345[D loss: 0.999952] [G loss: 1.000161]\n",
      "epoch:14 step:56350[D loss: 0.999939] [G loss: 1.000112]\n",
      "epoch:14 step:56355[D loss: 0.999971] [G loss: 1.000076]\n",
      "epoch:14 step:56360[D loss: 1.000022] [G loss: 1.000069]\n",
      "epoch:14 step:56365[D loss: 1.000061] [G loss: 0.999941]\n",
      "epoch:14 step:56370[D loss: 0.999973] [G loss: 1.000088]\n",
      "epoch:14 step:56375[D loss: 0.999960] [G loss: 1.000127]\n",
      "epoch:14 step:56380[D loss: 0.999986] [G loss: 1.000129]\n",
      "epoch:14 step:56385[D loss: 0.999952] [G loss: 1.000084]\n",
      "epoch:14 step:56390[D loss: 0.999970] [G loss: 1.000089]\n",
      "epoch:14 step:56395[D loss: 1.000002] [G loss: 1.000050]\n",
      "epoch:14 step:56400[D loss: 0.999944] [G loss: 1.000088]\n",
      "##############\n",
      "[0.85847988 0.85365661 0.8287957  0.82870751 0.80396847 0.84284707\n",
      " 0.86509432 0.82165884 0.80170627 0.85126425]\n",
      "##########\n",
      "epoch:14 step:56405[D loss: 0.999958] [G loss: 1.000089]\n",
      "epoch:14 step:56410[D loss: 0.999970] [G loss: 1.000040]\n",
      "epoch:14 step:56415[D loss: 0.999971] [G loss: 1.000066]\n",
      "epoch:14 step:56420[D loss: 0.999997] [G loss: 1.000115]\n",
      "epoch:14 step:56425[D loss: 1.000048] [G loss: 0.999955]\n",
      "epoch:14 step:56430[D loss: 0.999996] [G loss: 0.999970]\n",
      "epoch:14 step:56435[D loss: 0.999973] [G loss: 1.000016]\n",
      "epoch:14 step:56440[D loss: 0.999979] [G loss: 1.000013]\n",
      "epoch:14 step:56445[D loss: 0.999986] [G loss: 1.000002]\n",
      "epoch:14 step:56450[D loss: 0.999998] [G loss: 1.000007]\n",
      "epoch:14 step:56455[D loss: 1.000000] [G loss: 0.999996]\n",
      "epoch:14 step:56460[D loss: 0.999991] [G loss: 1.000061]\n",
      "epoch:14 step:56465[D loss: 0.999958] [G loss: 1.000032]\n",
      "epoch:14 step:56470[D loss: 0.999982] [G loss: 1.000045]\n",
      "epoch:14 step:56475[D loss: 0.999996] [G loss: 1.000035]\n",
      "epoch:14 step:56480[D loss: 0.999979] [G loss: 1.000003]\n",
      "epoch:14 step:56485[D loss: 1.000105] [G loss: 0.999921]\n",
      "epoch:14 step:56490[D loss: 0.999959] [G loss: 1.000086]\n",
      "epoch:14 step:56495[D loss: 0.999969] [G loss: 1.000143]\n",
      "epoch:14 step:56500[D loss: 0.999960] [G loss: 1.000071]\n",
      "epoch:14 step:56505[D loss: 0.999988] [G loss: 1.000048]\n",
      "epoch:14 step:56510[D loss: 0.999972] [G loss: 1.000043]\n",
      "epoch:14 step:56515[D loss: 0.999950] [G loss: 0.999986]\n",
      "epoch:14 step:56520[D loss: 0.999925] [G loss: 1.000065]\n",
      "epoch:14 step:56525[D loss: 0.999977] [G loss: 1.000032]\n",
      "epoch:14 step:56530[D loss: 0.999969] [G loss: 1.000067]\n",
      "epoch:14 step:56535[D loss: 0.999991] [G loss: 1.000108]\n",
      "epoch:14 step:56540[D loss: 0.999971] [G loss: 1.000094]\n",
      "epoch:14 step:56545[D loss: 0.999960] [G loss: 1.000082]\n",
      "epoch:14 step:56550[D loss: 0.999972] [G loss: 1.000083]\n",
      "epoch:14 step:56555[D loss: 0.999993] [G loss: 1.000046]\n",
      "epoch:14 step:56560[D loss: 0.999969] [G loss: 1.000071]\n",
      "epoch:14 step:56565[D loss: 0.999998] [G loss: 1.000027]\n",
      "epoch:14 step:56570[D loss: 0.999981] [G loss: 1.000052]\n",
      "epoch:14 step:56575[D loss: 1.000019] [G loss: 1.000024]\n",
      "epoch:14 step:56580[D loss: 1.000049] [G loss: 1.000135]\n",
      "epoch:14 step:56585[D loss: 1.000017] [G loss: 1.000039]\n",
      "epoch:14 step:56590[D loss: 0.999872] [G loss: 1.000298]\n",
      "epoch:14 step:56595[D loss: 0.999910] [G loss: 1.000156]\n",
      "epoch:14 step:56600[D loss: 0.999963] [G loss: 1.000064]\n",
      "##############\n",
      "[0.86376458 0.86119644 0.81556415 0.828547   0.8214922  0.83379055\n",
      " 0.88304105 0.85206666 0.82521287 0.83404859]\n",
      "##########\n",
      "epoch:14 step:56605[D loss: 1.000032] [G loss: 0.999917]\n",
      "epoch:14 step:56610[D loss: 0.999988] [G loss: 0.999988]\n",
      "epoch:14 step:56615[D loss: 0.999980] [G loss: 1.000012]\n",
      "epoch:14 step:56620[D loss: 1.000015] [G loss: 0.999998]\n",
      "epoch:14 step:56625[D loss: 1.000040] [G loss: 1.000084]\n",
      "epoch:14 step:56630[D loss: 0.999901] [G loss: 1.000077]\n",
      "epoch:14 step:56635[D loss: 0.999973] [G loss: 1.000096]\n",
      "epoch:14 step:56640[D loss: 0.999937] [G loss: 1.000094]\n",
      "epoch:14 step:56645[D loss: 1.000032] [G loss: 1.000004]\n",
      "epoch:14 step:56650[D loss: 0.999994] [G loss: 1.000127]\n",
      "epoch:14 step:56655[D loss: 0.999962] [G loss: 1.000040]\n",
      "epoch:14 step:56660[D loss: 0.999981] [G loss: 1.000049]\n",
      "epoch:14 step:56665[D loss: 0.999994] [G loss: 1.000049]\n",
      "epoch:14 step:56670[D loss: 0.999977] [G loss: 1.000057]\n",
      "epoch:14 step:56675[D loss: 0.999956] [G loss: 1.000109]\n",
      "epoch:14 step:56680[D loss: 1.000008] [G loss: 1.000029]\n",
      "epoch:14 step:56685[D loss: 1.000014] [G loss: 1.000001]\n",
      "epoch:14 step:56690[D loss: 0.999996] [G loss: 0.999983]\n",
      "epoch:14 step:56695[D loss: 1.000019] [G loss: 0.999992]\n",
      "epoch:14 step:56700[D loss: 0.999948] [G loss: 1.000067]\n",
      "epoch:14 step:56705[D loss: 0.999962] [G loss: 1.000045]\n",
      "epoch:14 step:56710[D loss: 0.999963] [G loss: 1.000125]\n",
      "epoch:14 step:56715[D loss: 0.999996] [G loss: 1.000004]\n",
      "epoch:14 step:56720[D loss: 0.999963] [G loss: 1.000081]\n",
      "epoch:14 step:56725[D loss: 0.999986] [G loss: 1.000047]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:14 step:56730[D loss: 1.000013] [G loss: 1.000053]\n",
      "epoch:14 step:56735[D loss: 0.999994] [G loss: 1.000000]\n",
      "epoch:14 step:56740[D loss: 1.000067] [G loss: 0.999913]\n",
      "epoch:14 step:56745[D loss: 1.000004] [G loss: 1.000038]\n",
      "epoch:14 step:56750[D loss: 1.000022] [G loss: 1.000092]\n",
      "epoch:14 step:56755[D loss: 0.999863] [G loss: 1.000305]\n",
      "epoch:14 step:56760[D loss: 0.999958] [G loss: 1.000111]\n",
      "epoch:14 step:56765[D loss: 0.999973] [G loss: 1.000106]\n",
      "epoch:14 step:56770[D loss: 0.999973] [G loss: 1.000118]\n",
      "epoch:14 step:56775[D loss: 0.999943] [G loss: 1.000139]\n",
      "epoch:14 step:56780[D loss: 0.999934] [G loss: 1.000126]\n",
      "epoch:14 step:56785[D loss: 0.999987] [G loss: 1.000087]\n",
      "epoch:14 step:56790[D loss: 1.000014] [G loss: 1.000093]\n",
      "epoch:14 step:56795[D loss: 0.999997] [G loss: 1.000048]\n",
      "epoch:14 step:56800[D loss: 1.000082] [G loss: 0.999904]\n",
      "##############\n",
      "[0.86995786 0.86150004 0.82839199 0.83867948 0.80552604 0.83167601\n",
      " 0.88311149 0.8321245  0.84411082 0.86110393]\n",
      "##########\n",
      "epoch:14 step:56805[D loss: 1.000022] [G loss: 1.000133]\n",
      "epoch:14 step:56810[D loss: 0.999939] [G loss: 1.000045]\n",
      "epoch:14 step:56815[D loss: 0.999927] [G loss: 1.000123]\n",
      "epoch:14 step:56820[D loss: 0.999982] [G loss: 1.000107]\n",
      "epoch:14 step:56825[D loss: 0.999976] [G loss: 1.000071]\n",
      "epoch:14 step:56830[D loss: 0.999989] [G loss: 1.000061]\n",
      "epoch:14 step:56835[D loss: 0.999965] [G loss: 1.000081]\n",
      "epoch:14 step:56840[D loss: 0.999964] [G loss: 1.000059]\n",
      "epoch:14 step:56845[D loss: 0.999962] [G loss: 1.000049]\n",
      "epoch:14 step:56850[D loss: 0.999982] [G loss: 1.000126]\n",
      "epoch:14 step:56855[D loss: 0.999979] [G loss: 1.000076]\n",
      "epoch:14 step:56860[D loss: 1.000040] [G loss: 1.000001]\n",
      "epoch:14 step:56865[D loss: 0.999968] [G loss: 1.000119]\n",
      "epoch:14 step:56870[D loss: 0.999947] [G loss: 1.000104]\n",
      "epoch:14 step:56875[D loss: 0.999958] [G loss: 1.000132]\n",
      "epoch:14 step:56880[D loss: 0.999956] [G loss: 1.000053]\n",
      "epoch:14 step:56885[D loss: 1.000012] [G loss: 1.000004]\n",
      "epoch:14 step:56890[D loss: 0.999957] [G loss: 1.000044]\n",
      "epoch:14 step:56895[D loss: 0.999991] [G loss: 1.000013]\n",
      "epoch:14 step:56900[D loss: 1.000029] [G loss: 0.999952]\n",
      "epoch:14 step:56905[D loss: 1.000049] [G loss: 1.000030]\n",
      "epoch:14 step:56910[D loss: 1.000046] [G loss: 1.000075]\n",
      "epoch:14 step:56915[D loss: 0.999846] [G loss: 1.000209]\n",
      "epoch:14 step:56920[D loss: 0.999954] [G loss: 1.000150]\n",
      "epoch:14 step:56925[D loss: 0.999957] [G loss: 1.000071]\n",
      "epoch:14 step:56930[D loss: 1.000017] [G loss: 0.999974]\n",
      "epoch:14 step:56935[D loss: 1.000037] [G loss: 1.000006]\n",
      "epoch:14 step:56940[D loss: 0.999919] [G loss: 1.000081]\n",
      "epoch:14 step:56945[D loss: 0.999922] [G loss: 1.000145]\n",
      "epoch:14 step:56950[D loss: 1.000024] [G loss: 0.999955]\n",
      "epoch:14 step:56955[D loss: 0.999949] [G loss: 1.000047]\n",
      "epoch:14 step:56960[D loss: 0.999974] [G loss: 1.000062]\n",
      "epoch:14 step:56965[D loss: 1.000067] [G loss: 0.999911]\n",
      "epoch:14 step:56970[D loss: 0.999930] [G loss: 1.000073]\n",
      "epoch:14 step:56975[D loss: 0.999947] [G loss: 1.000055]\n",
      "epoch:14 step:56980[D loss: 0.999963] [G loss: 1.000070]\n",
      "epoch:14 step:56985[D loss: 0.999945] [G loss: 1.000103]\n",
      "epoch:14 step:56990[D loss: 0.999978] [G loss: 1.000064]\n",
      "epoch:14 step:56995[D loss: 0.999956] [G loss: 1.000056]\n",
      "epoch:14 step:57000[D loss: 0.999982] [G loss: 1.000044]\n",
      "##############\n",
      "[0.86470388 0.85461122 0.81924676 0.80995587 0.81717609 0.83287083\n",
      " 0.88538922 0.82498002 0.83265048 0.84463549]\n",
      "##########\n",
      "epoch:14 step:57005[D loss: 0.999977] [G loss: 1.000017]\n",
      "epoch:14 step:57010[D loss: 0.999993] [G loss: 1.000078]\n",
      "epoch:14 step:57015[D loss: 0.999974] [G loss: 1.000070]\n",
      "epoch:14 step:57020[D loss: 1.000007] [G loss: 0.999984]\n",
      "epoch:14 step:57025[D loss: 1.000070] [G loss: 0.999828]\n",
      "epoch:14 step:57030[D loss: 0.999983] [G loss: 1.000039]\n",
      "epoch:14 step:57035[D loss: 0.999956] [G loss: 1.000062]\n",
      "epoch:14 step:57040[D loss: 0.999964] [G loss: 1.000070]\n",
      "epoch:14 step:57045[D loss: 0.999979] [G loss: 1.000017]\n",
      "epoch:14 step:57050[D loss: 0.999965] [G loss: 1.000086]\n",
      "epoch:14 step:57055[D loss: 0.999946] [G loss: 1.000114]\n",
      "epoch:14 step:57060[D loss: 1.000017] [G loss: 0.999988]\n",
      "epoch:14 step:57065[D loss: 1.000016] [G loss: 1.000028]\n",
      "epoch:14 step:57070[D loss: 1.000017] [G loss: 0.999994]\n",
      "epoch:14 step:57075[D loss: 0.999902] [G loss: 1.000226]\n",
      "epoch:14 step:57080[D loss: 0.999983] [G loss: 1.000131]\n",
      "epoch:14 step:57085[D loss: 1.000014] [G loss: 1.000003]\n",
      "epoch:14 step:57090[D loss: 0.999968] [G loss: 1.000056]\n",
      "epoch:14 step:57095[D loss: 1.000024] [G loss: 1.000009]\n",
      "epoch:14 step:57100[D loss: 1.000045] [G loss: 0.999973]\n",
      "epoch:14 step:57105[D loss: 0.999975] [G loss: 1.000065]\n",
      "epoch:14 step:57110[D loss: 0.999974] [G loss: 1.000017]\n",
      "epoch:14 step:57115[D loss: 0.999904] [G loss: 1.000200]\n",
      "epoch:14 step:57120[D loss: 0.999968] [G loss: 1.000078]\n",
      "epoch:14 step:57125[D loss: 1.000009] [G loss: 1.000023]\n",
      "epoch:14 step:57130[D loss: 1.000055] [G loss: 0.999941]\n",
      "epoch:14 step:57135[D loss: 1.000194] [G loss: 0.999960]\n",
      "epoch:14 step:57140[D loss: 0.999907] [G loss: 1.000098]\n",
      "epoch:14 step:57145[D loss: 0.999980] [G loss: 1.000134]\n",
      "epoch:14 step:57150[D loss: 0.999984] [G loss: 1.000029]\n",
      "epoch:14 step:57155[D loss: 1.000020] [G loss: 0.999989]\n",
      "epoch:14 step:57160[D loss: 0.999918] [G loss: 1.000200]\n",
      "epoch:14 step:57165[D loss: 0.999968] [G loss: 1.000166]\n",
      "epoch:14 step:57170[D loss: 0.999998] [G loss: 0.999993]\n",
      "epoch:14 step:57175[D loss: 1.000021] [G loss: 0.999948]\n",
      "epoch:14 step:57180[D loss: 1.000012] [G loss: 0.999969]\n",
      "epoch:14 step:57185[D loss: 0.999931] [G loss: 1.000082]\n",
      "epoch:14 step:57190[D loss: 0.999962] [G loss: 1.000061]\n",
      "epoch:14 step:57195[D loss: 1.000190] [G loss: 0.999803]\n",
      "epoch:14 step:57200[D loss: 0.999972] [G loss: 1.000006]\n",
      "##############\n",
      "[0.86409994 0.87294548 0.83474403 0.8285148  0.80583933 0.83572831\n",
      " 0.88804432 0.87116036 0.80563524 0.85349365]\n",
      "##########\n",
      "epoch:14 step:57205[D loss: 1.000092] [G loss: 0.999835]\n",
      "epoch:14 step:57210[D loss: 0.999941] [G loss: 1.000098]\n",
      "epoch:14 step:57215[D loss: 0.999942] [G loss: 1.000089]\n",
      "epoch:14 step:57220[D loss: 1.000041] [G loss: 0.999949]\n",
      "epoch:14 step:57225[D loss: 1.000076] [G loss: 0.999885]\n",
      "epoch:14 step:57230[D loss: 0.999939] [G loss: 1.000151]\n",
      "epoch:14 step:57235[D loss: 0.999879] [G loss: 1.000137]\n",
      "epoch:14 step:57240[D loss: 0.999959] [G loss: 0.999977]\n",
      "epoch:14 step:57245[D loss: 0.999929] [G loss: 1.000076]\n",
      "epoch:14 step:57250[D loss: 0.999940] [G loss: 1.000141]\n",
      "epoch:14 step:57255[D loss: 0.999949] [G loss: 1.000087]\n",
      "epoch:14 step:57260[D loss: 0.999974] [G loss: 1.000078]\n",
      "epoch:14 step:57265[D loss: 0.999974] [G loss: 1.000050]\n",
      "epoch:14 step:57270[D loss: 1.000003] [G loss: 1.000019]\n",
      "epoch:14 step:57275[D loss: 0.999969] [G loss: 1.000146]\n",
      "epoch:14 step:57280[D loss: 0.999979] [G loss: 1.000058]\n",
      "epoch:14 step:57285[D loss: 0.999968] [G loss: 1.000046]\n",
      "epoch:14 step:57290[D loss: 1.000017] [G loss: 0.999946]\n",
      "epoch:14 step:57295[D loss: 0.999994] [G loss: 1.000082]\n",
      "epoch:14 step:57300[D loss: 0.999969] [G loss: 1.000111]\n",
      "epoch:14 step:57305[D loss: 0.999980] [G loss: 1.000079]\n",
      "epoch:14 step:57310[D loss: 0.999979] [G loss: 1.000105]\n",
      "epoch:14 step:57315[D loss: 1.000003] [G loss: 1.000045]\n",
      "epoch:14 step:57320[D loss: 1.000043] [G loss: 1.000012]\n",
      "epoch:14 step:57325[D loss: 1.000060] [G loss: 0.999996]\n",
      "epoch:14 step:57330[D loss: 0.999954] [G loss: 1.000163]\n",
      "epoch:14 step:57335[D loss: 1.000045] [G loss: 1.000175]\n",
      "epoch:14 step:57340[D loss: 0.999862] [G loss: 1.000204]\n",
      "epoch:14 step:57345[D loss: 0.999976] [G loss: 1.000084]\n",
      "epoch:14 step:57350[D loss: 0.999957] [G loss: 1.000125]\n",
      "epoch:14 step:57355[D loss: 1.000032] [G loss: 0.999996]\n",
      "epoch:14 step:57360[D loss: 1.000095] [G loss: 0.999909]\n",
      "epoch:14 step:57365[D loss: 0.999851] [G loss: 1.000134]\n",
      "epoch:14 step:57370[D loss: 1.000048] [G loss: 0.999822]\n",
      "epoch:14 step:57375[D loss: 0.999950] [G loss: 1.000058]\n",
      "epoch:14 step:57380[D loss: 1.000019] [G loss: 0.999983]\n",
      "epoch:14 step:57385[D loss: 0.999977] [G loss: 1.000099]\n",
      "epoch:14 step:57390[D loss: 1.000028] [G loss: 1.000015]\n",
      "epoch:14 step:57395[D loss: 1.000010] [G loss: 1.000000]\n",
      "epoch:14 step:57400[D loss: 0.999973] [G loss: 1.000112]\n",
      "##############\n",
      "[0.85533206 0.8696026  0.83188758 0.82772126 0.80652168 0.83886991\n",
      " 0.87200217 0.82348087 0.82561113 0.84168528]\n",
      "##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:14 step:57405[D loss: 0.999967] [G loss: 1.000053]\n",
      "epoch:14 step:57410[D loss: 1.000063] [G loss: 0.999951]\n",
      "epoch:14 step:57415[D loss: 0.999944] [G loss: 1.000037]\n",
      "epoch:14 step:57420[D loss: 1.000004] [G loss: 1.000097]\n",
      "epoch:14 step:57425[D loss: 0.999991] [G loss: 1.000064]\n",
      "epoch:14 step:57430[D loss: 0.999811] [G loss: 1.000345]\n",
      "epoch:14 step:57435[D loss: 1.000198] [G loss: 0.999761]\n",
      "epoch:14 step:57440[D loss: 0.999918] [G loss: 1.000170]\n",
      "epoch:14 step:57445[D loss: 0.999931] [G loss: 1.000179]\n",
      "epoch:14 step:57450[D loss: 0.999930] [G loss: 1.000200]\n",
      "epoch:14 step:57455[D loss: 1.000023] [G loss: 1.000060]\n",
      "epoch:14 step:57460[D loss: 0.999970] [G loss: 1.000090]\n",
      "epoch:14 step:57465[D loss: 1.000123] [G loss: 0.999752]\n",
      "epoch:14 step:57470[D loss: 0.999962] [G loss: 1.000117]\n",
      "epoch:14 step:57475[D loss: 1.000034] [G loss: 1.000004]\n",
      "epoch:14 step:57480[D loss: 1.000112] [G loss: 0.999948]\n",
      "epoch:14 step:57485[D loss: 0.999960] [G loss: 0.999991]\n",
      "epoch:14 step:57490[D loss: 0.999871] [G loss: 1.000272]\n",
      "epoch:14 step:57495[D loss: 0.999854] [G loss: 1.000291]\n",
      "epoch:14 step:57500[D loss: 0.999915] [G loss: 1.000187]\n",
      "epoch:14 step:57505[D loss: 0.999987] [G loss: 1.000075]\n",
      "epoch:14 step:57510[D loss: 0.999989] [G loss: 0.999970]\n",
      "epoch:14 step:57515[D loss: 1.000000] [G loss: 1.000012]\n",
      "epoch:14 step:57520[D loss: 1.000015] [G loss: 0.999920]\n",
      "epoch:14 step:57525[D loss: 1.000095] [G loss: 0.999860]\n",
      "epoch:14 step:57530[D loss: 1.000007] [G loss: 1.000159]\n",
      "epoch:14 step:57535[D loss: 0.999957] [G loss: 1.000063]\n",
      "epoch:14 step:57540[D loss: 0.999950] [G loss: 1.000139]\n",
      "epoch:14 step:57545[D loss: 0.999970] [G loss: 1.000165]\n",
      "epoch:14 step:57550[D loss: 0.999968] [G loss: 1.000119]\n",
      "epoch:14 step:57555[D loss: 0.999988] [G loss: 1.000096]\n",
      "epoch:14 step:57560[D loss: 0.999965] [G loss: 1.000086]\n",
      "epoch:14 step:57565[D loss: 0.999995] [G loss: 1.000093]\n",
      "epoch:14 step:57570[D loss: 0.999958] [G loss: 1.000114]\n",
      "epoch:14 step:57575[D loss: 0.999985] [G loss: 1.000053]\n",
      "epoch:14 step:57580[D loss: 1.000057] [G loss: 1.000029]\n",
      "epoch:14 step:57585[D loss: 1.000060] [G loss: 0.999859]\n",
      "epoch:14 step:57590[D loss: 1.000230] [G loss: 0.999821]\n",
      "epoch:14 step:57595[D loss: 0.999806] [G loss: 1.000230]\n",
      "epoch:14 step:57600[D loss: 0.999957] [G loss: 1.000103]\n",
      "##############\n",
      "[0.87566881 0.86134954 0.81824005 0.81419197 0.80343112 0.85434299\n",
      " 0.85774596 0.85035191 0.82059747 0.84283489]\n",
      "##########\n",
      "epoch:14 step:57605[D loss: 0.999915] [G loss: 1.000105]\n",
      "epoch:14 step:57610[D loss: 0.999980] [G loss: 1.000101]\n",
      "epoch:14 step:57615[D loss: 0.999953] [G loss: 1.000074]\n",
      "epoch:14 step:57620[D loss: 0.999972] [G loss: 1.000097]\n",
      "epoch:14 step:57625[D loss: 0.999963] [G loss: 1.000081]\n",
      "epoch:14 step:57630[D loss: 0.999970] [G loss: 1.000079]\n",
      "epoch:14 step:57635[D loss: 0.999964] [G loss: 1.000065]\n",
      "epoch:14 step:57640[D loss: 0.999938] [G loss: 1.000088]\n",
      "epoch:14 step:57645[D loss: 1.000007] [G loss: 1.000035]\n",
      "epoch:14 step:57650[D loss: 1.000012] [G loss: 1.000056]\n",
      "epoch:14 step:57655[D loss: 0.999970] [G loss: 1.000047]\n",
      "epoch:14 step:57660[D loss: 0.999967] [G loss: 1.000050]\n",
      "epoch:14 step:57665[D loss: 0.999965] [G loss: 1.000066]\n",
      "epoch:14 step:57670[D loss: 0.999992] [G loss: 1.000058]\n",
      "epoch:14 step:57675[D loss: 1.000000] [G loss: 1.000101]\n",
      "epoch:14 step:57680[D loss: 0.999955] [G loss: 1.000099]\n",
      "epoch:14 step:57685[D loss: 0.999987] [G loss: 1.000180]\n",
      "epoch:14 step:57690[D loss: 0.999995] [G loss: 1.000218]\n",
      "epoch:14 step:57695[D loss: 0.999930] [G loss: 1.000253]\n",
      "epoch:14 step:57700[D loss: 0.999929] [G loss: 1.000219]\n",
      "epoch:14 step:57705[D loss: 1.000024] [G loss: 1.000178]\n",
      "epoch:14 step:57710[D loss: 0.999901] [G loss: 1.000154]\n",
      "epoch:14 step:57715[D loss: 0.999997] [G loss: 1.000051]\n",
      "epoch:14 step:57720[D loss: 1.000191] [G loss: 0.999663]\n",
      "epoch:14 step:57725[D loss: 0.999983] [G loss: 0.999913]\n",
      "epoch:14 step:57730[D loss: 1.000022] [G loss: 0.999982]\n",
      "epoch:14 step:57735[D loss: 0.999958] [G loss: 1.000128]\n",
      "epoch:14 step:57740[D loss: 0.999924] [G loss: 1.000122]\n",
      "epoch:14 step:57745[D loss: 0.999955] [G loss: 1.000111]\n",
      "epoch:14 step:57750[D loss: 0.999962] [G loss: 1.000121]\n",
      "epoch:14 step:57755[D loss: 1.000018] [G loss: 0.999999]\n",
      "epoch:14 step:57760[D loss: 0.999951] [G loss: 1.000068]\n",
      "epoch:14 step:57765[D loss: 0.999950] [G loss: 1.000061]\n",
      "epoch:14 step:57770[D loss: 0.999950] [G loss: 1.000150]\n",
      "epoch:14 step:57775[D loss: 1.000049] [G loss: 1.000006]\n",
      "epoch:14 step:57780[D loss: 0.999986] [G loss: 1.000184]\n",
      "epoch:14 step:57785[D loss: 0.999900] [G loss: 1.000133]\n",
      "epoch:14 step:57790[D loss: 0.999917] [G loss: 1.000233]\n",
      "epoch:14 step:57795[D loss: 0.999916] [G loss: 1.000149]\n",
      "epoch:14 step:57800[D loss: 0.999990] [G loss: 1.000040]\n",
      "##############\n",
      "[0.87046547 0.87636034 0.81187538 0.8404428  0.7967195  0.86714661\n",
      " 0.87956491 0.83529978 0.82288253 0.83160975]\n",
      "##########\n",
      "epoch:14 step:57805[D loss: 0.999996] [G loss: 1.000044]\n",
      "epoch:14 step:57810[D loss: 1.000018] [G loss: 1.000045]\n",
      "epoch:14 step:57815[D loss: 1.000012] [G loss: 1.000064]\n",
      "epoch:14 step:57820[D loss: 0.999850] [G loss: 1.000268]\n",
      "epoch:14 step:57825[D loss: 0.999906] [G loss: 1.000135]\n",
      "epoch:14 step:57830[D loss: 1.000000] [G loss: 1.000129]\n",
      "epoch:14 step:57835[D loss: 0.999955] [G loss: 1.000049]\n",
      "epoch:14 step:57840[D loss: 0.999991] [G loss: 0.999980]\n",
      "epoch:14 step:57845[D loss: 0.999975] [G loss: 1.000089]\n",
      "epoch:14 step:57850[D loss: 0.999995] [G loss: 1.000048]\n",
      "epoch:14 step:57855[D loss: 0.999994] [G loss: 1.000011]\n",
      "epoch:14 step:57860[D loss: 1.000020] [G loss: 1.000036]\n",
      "epoch:14 step:57865[D loss: 0.999913] [G loss: 1.000186]\n",
      "epoch:14 step:57870[D loss: 0.999945] [G loss: 1.000101]\n",
      "epoch:14 step:57875[D loss: 0.999933] [G loss: 1.000118]\n",
      "epoch:14 step:57880[D loss: 1.000029] [G loss: 1.000036]\n",
      "epoch:14 step:57885[D loss: 0.999940] [G loss: 1.000146]\n",
      "epoch:14 step:57890[D loss: 0.999972] [G loss: 1.000079]\n",
      "epoch:14 step:57895[D loss: 0.999988] [G loss: 1.000053]\n",
      "epoch:14 step:57900[D loss: 0.999983] [G loss: 1.000086]\n",
      "epoch:14 step:57905[D loss: 0.999970] [G loss: 1.000111]\n",
      "epoch:14 step:57910[D loss: 0.999953] [G loss: 1.000108]\n",
      "epoch:14 step:57915[D loss: 0.999993] [G loss: 1.000048]\n",
      "epoch:14 step:57920[D loss: 0.999958] [G loss: 1.000095]\n",
      "epoch:14 step:57925[D loss: 0.999966] [G loss: 1.000070]\n",
      "epoch:14 step:57930[D loss: 1.000018] [G loss: 1.000019]\n",
      "epoch:14 step:57935[D loss: 0.999962] [G loss: 1.000140]\n",
      "epoch:14 step:57940[D loss: 1.000034] [G loss: 1.000050]\n",
      "epoch:14 step:57945[D loss: 0.999928] [G loss: 1.000072]\n",
      "epoch:14 step:57950[D loss: 0.999953] [G loss: 1.000158]\n",
      "epoch:14 step:57955[D loss: 0.999992] [G loss: 1.000044]\n",
      "epoch:14 step:57960[D loss: 1.000000] [G loss: 1.000034]\n",
      "epoch:14 step:57965[D loss: 1.000027] [G loss: 0.999966]\n",
      "epoch:14 step:57970[D loss: 0.999972] [G loss: 1.000047]\n",
      "epoch:14 step:57975[D loss: 0.999935] [G loss: 1.000185]\n",
      "epoch:14 step:57980[D loss: 0.999975] [G loss: 1.000067]\n",
      "epoch:14 step:57985[D loss: 0.999992] [G loss: 1.000052]\n",
      "epoch:14 step:57990[D loss: 0.999952] [G loss: 1.000086]\n",
      "epoch:14 step:57995[D loss: 1.000014] [G loss: 0.999974]\n",
      "epoch:14 step:58000[D loss: 1.000011] [G loss: 0.999941]\n",
      "##############\n",
      "[0.84363808 0.85453968 0.82324743 0.82441312 0.81486611 0.85852258\n",
      " 0.85782562 0.8507289  0.82003212 0.83570863]\n",
      "##########\n",
      "epoch:14 step:58005[D loss: 0.999995] [G loss: 0.999974]\n",
      "epoch:14 step:58010[D loss: 0.999949] [G loss: 1.000067]\n",
      "epoch:14 step:58015[D loss: 1.000000] [G loss: 1.000039]\n",
      "epoch:14 step:58020[D loss: 1.000054] [G loss: 0.999915]\n",
      "epoch:14 step:58025[D loss: 0.999983] [G loss: 1.000068]\n",
      "epoch:14 step:58030[D loss: 0.999996] [G loss: 1.000071]\n",
      "epoch:14 step:58035[D loss: 0.999964] [G loss: 1.000070]\n",
      "epoch:14 step:58040[D loss: 0.999968] [G loss: 1.000072]\n",
      "epoch:14 step:58045[D loss: 0.999967] [G loss: 1.000033]\n",
      "epoch:14 step:58050[D loss: 1.000022] [G loss: 1.000007]\n",
      "epoch:14 step:58055[D loss: 0.999964] [G loss: 1.000091]\n",
      "epoch:14 step:58060[D loss: 0.999978] [G loss: 1.000100]\n",
      "epoch:14 step:58065[D loss: 0.999987] [G loss: 1.000076]\n",
      "epoch:14 step:58070[D loss: 0.999967] [G loss: 1.000078]\n",
      "epoch:14 step:58075[D loss: 0.999973] [G loss: 1.000029]\n",
      "epoch:14 step:58080[D loss: 0.999972] [G loss: 1.000073]\n",
      "epoch:14 step:58085[D loss: 0.999954] [G loss: 1.000085]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:14 step:58090[D loss: 1.000002] [G loss: 1.000003]\n",
      "epoch:14 step:58095[D loss: 0.999971] [G loss: 1.000085]\n",
      "epoch:14 step:58100[D loss: 1.000012] [G loss: 1.000055]\n",
      "epoch:14 step:58105[D loss: 0.999980] [G loss: 1.000065]\n",
      "epoch:14 step:58110[D loss: 0.999971] [G loss: 1.000081]\n",
      "epoch:14 step:58115[D loss: 0.999993] [G loss: 1.000096]\n",
      "epoch:14 step:58120[D loss: 0.999995] [G loss: 0.999989]\n",
      "epoch:14 step:58125[D loss: 0.999970] [G loss: 1.000074]\n",
      "epoch:14 step:58130[D loss: 1.000003] [G loss: 1.000065]\n",
      "epoch:14 step:58135[D loss: 1.000010] [G loss: 1.000076]\n",
      "epoch:14 step:58140[D loss: 0.999987] [G loss: 1.000098]\n",
      "epoch:14 step:58145[D loss: 1.000018] [G loss: 1.000082]\n",
      "epoch:14 step:58150[D loss: 0.999960] [G loss: 1.000115]\n",
      "epoch:14 step:58155[D loss: 0.999943] [G loss: 1.000152]\n",
      "epoch:14 step:58160[D loss: 0.999994] [G loss: 1.000080]\n",
      "epoch:14 step:58165[D loss: 1.000011] [G loss: 1.000101]\n",
      "epoch:14 step:58170[D loss: 0.999995] [G loss: 1.000089]\n",
      "epoch:14 step:58175[D loss: 0.999998] [G loss: 1.000055]\n",
      "epoch:14 step:58180[D loss: 0.999929] [G loss: 1.000154]\n",
      "epoch:14 step:58185[D loss: 0.999982] [G loss: 1.000090]\n",
      "epoch:14 step:58190[D loss: 1.000007] [G loss: 1.000019]\n",
      "epoch:14 step:58195[D loss: 0.999963] [G loss: 1.000075]\n",
      "epoch:14 step:58200[D loss: 1.000081] [G loss: 0.999944]\n",
      "##############\n",
      "[0.86066714 0.85734556 0.82581306 0.83622901 0.79998008 0.86340231\n",
      " 0.87426894 0.84217947 0.81497503 0.83765248]\n",
      "##########\n",
      "epoch:14 step:58205[D loss: 1.000016] [G loss: 1.000144]\n",
      "epoch:14 step:58210[D loss: 0.999963] [G loss: 1.000030]\n",
      "epoch:14 step:58215[D loss: 0.999849] [G loss: 1.000273]\n",
      "epoch:14 step:58220[D loss: 0.999935] [G loss: 1.000117]\n",
      "epoch:14 step:58225[D loss: 0.999985] [G loss: 1.000051]\n",
      "epoch:14 step:58230[D loss: 1.000024] [G loss: 1.000018]\n",
      "epoch:14 step:58235[D loss: 0.999972] [G loss: 1.000050]\n",
      "epoch:14 step:58240[D loss: 1.000047] [G loss: 0.999901]\n",
      "epoch:14 step:58245[D loss: 0.999990] [G loss: 1.000013]\n",
      "epoch:14 step:58250[D loss: 0.999944] [G loss: 1.000063]\n",
      "epoch:14 step:58255[D loss: 0.999989] [G loss: 1.000001]\n",
      "epoch:14 step:58260[D loss: 0.999946] [G loss: 1.000131]\n",
      "epoch:14 step:58265[D loss: 0.999947] [G loss: 1.000088]\n",
      "epoch:14 step:58270[D loss: 0.999940] [G loss: 1.000054]\n",
      "epoch:14 step:58275[D loss: 0.999943] [G loss: 1.000056]\n",
      "epoch:14 step:58280[D loss: 1.000002] [G loss: 1.000039]\n",
      "epoch:14 step:58285[D loss: 1.000002] [G loss: 1.000065]\n",
      "epoch:14 step:58290[D loss: 0.999944] [G loss: 1.000089]\n",
      "epoch:14 step:58295[D loss: 0.999965] [G loss: 1.000108]\n",
      "epoch:14 step:58300[D loss: 0.999979] [G loss: 1.000074]\n",
      "epoch:14 step:58305[D loss: 0.999967] [G loss: 1.000085]\n",
      "epoch:14 step:58310[D loss: 0.999981] [G loss: 1.000088]\n",
      "epoch:14 step:58315[D loss: 0.999974] [G loss: 1.000105]\n",
      "epoch:14 step:58320[D loss: 0.999968] [G loss: 1.000090]\n",
      "epoch:14 step:58325[D loss: 0.999976] [G loss: 1.000071]\n",
      "epoch:14 step:58330[D loss: 0.999984] [G loss: 1.000068]\n",
      "epoch:14 step:58335[D loss: 1.000008] [G loss: 1.000047]\n",
      "epoch:14 step:58340[D loss: 0.999970] [G loss: 1.000082]\n",
      "epoch:14 step:58345[D loss: 0.999944] [G loss: 1.000112]\n",
      "epoch:14 step:58350[D loss: 0.999963] [G loss: 1.000087]\n",
      "epoch:14 step:58355[D loss: 0.999982] [G loss: 1.000048]\n",
      "epoch:14 step:58360[D loss: 0.999969] [G loss: 1.000083]\n",
      "epoch:14 step:58365[D loss: 0.999993] [G loss: 1.000063]\n",
      "epoch:14 step:58370[D loss: 0.999993] [G loss: 1.000043]\n",
      "epoch:14 step:58375[D loss: 0.999963] [G loss: 1.000061]\n",
      "epoch:14 step:58380[D loss: 0.999964] [G loss: 1.000103]\n",
      "epoch:14 step:58385[D loss: 0.999968] [G loss: 1.000070]\n",
      "epoch:14 step:58390[D loss: 0.999959] [G loss: 1.000092]\n",
      "epoch:14 step:58395[D loss: 0.999999] [G loss: 1.000003]\n",
      "epoch:14 step:58400[D loss: 0.999981] [G loss: 1.000070]\n",
      "##############\n",
      "[0.86710054 0.8593082  0.82169188 0.82481735 0.82918247 0.83173344\n",
      " 0.86050085 0.82188362 0.82472603 0.83616907]\n",
      "##########\n",
      "epoch:14 step:58405[D loss: 0.999971] [G loss: 1.000106]\n",
      "epoch:14 step:58410[D loss: 0.999966] [G loss: 1.000032]\n",
      "epoch:14 step:58415[D loss: 0.999985] [G loss: 1.000048]\n",
      "epoch:14 step:58420[D loss: 0.999993] [G loss: 1.000015]\n",
      "epoch:14 step:58425[D loss: 0.999987] [G loss: 1.000049]\n",
      "epoch:14 step:58430[D loss: 0.999960] [G loss: 1.000025]\n",
      "epoch:14 step:58435[D loss: 0.999973] [G loss: 1.000063]\n",
      "epoch:14 step:58440[D loss: 0.999977] [G loss: 1.000076]\n",
      "epoch:14 step:58445[D loss: 0.999978] [G loss: 1.000050]\n",
      "epoch:14 step:58450[D loss: 1.000009] [G loss: 1.000067]\n",
      "epoch:14 step:58455[D loss: 0.999981] [G loss: 1.000047]\n",
      "epoch:14 step:58460[D loss: 0.999979] [G loss: 1.000075]\n",
      "epoch:14 step:58465[D loss: 0.999975] [G loss: 1.000120]\n",
      "epoch:14 step:58470[D loss: 0.999950] [G loss: 1.000110]\n",
      "epoch:14 step:58475[D loss: 1.000001] [G loss: 1.000049]\n",
      "epoch:14 step:58480[D loss: 1.000000] [G loss: 1.000039]\n",
      "epoch:14 step:58485[D loss: 0.999985] [G loss: 1.000079]\n",
      "epoch:14 step:58490[D loss: 0.999992] [G loss: 1.000098]\n",
      "epoch:14 step:58495[D loss: 1.000001] [G loss: 1.000027]\n",
      "epoch:14 step:58500[D loss: 0.999980] [G loss: 1.000098]\n",
      "epoch:14 step:58505[D loss: 0.999992] [G loss: 1.000034]\n",
      "epoch:14 step:58510[D loss: 0.999917] [G loss: 1.000127]\n",
      "epoch:14 step:58515[D loss: 1.000019] [G loss: 1.000029]\n",
      "epoch:14 step:58520[D loss: 0.999997] [G loss: 1.000025]\n",
      "epoch:14 step:58525[D loss: 0.999984] [G loss: 1.000012]\n",
      "epoch:14 step:58530[D loss: 1.000080] [G loss: 0.999973]\n",
      "epoch:14 step:58535[D loss: 0.999914] [G loss: 1.000211]\n",
      "epoch:14 step:58540[D loss: 0.999947] [G loss: 1.000276]\n",
      "epoch:14 step:58545[D loss: 0.999916] [G loss: 1.000230]\n",
      "epoch:14 step:58550[D loss: 0.999959] [G loss: 1.000128]\n",
      "epoch:14 step:58555[D loss: 1.000001] [G loss: 0.999997]\n",
      "epoch:14 step:58560[D loss: 1.000073] [G loss: 0.999828]\n",
      "epoch:14 step:58565[D loss: 0.999944] [G loss: 0.999994]\n",
      "epoch:14 step:58570[D loss: 0.999994] [G loss: 0.999994]\n",
      "epoch:14 step:58575[D loss: 1.000069] [G loss: 0.999992]\n",
      "epoch:15 step:58580[D loss: 1.000073] [G loss: 0.999874]\n",
      "epoch:15 step:58585[D loss: 0.999904] [G loss: 1.000040]\n",
      "epoch:15 step:58590[D loss: 0.999953] [G loss: 1.000056]\n",
      "epoch:15 step:58595[D loss: 0.999973] [G loss: 1.000026]\n",
      "epoch:15 step:58600[D loss: 0.999993] [G loss: 1.000051]\n",
      "##############\n",
      "[0.85891113 0.86100684 0.82979417 0.82614383 0.78938571 0.8077492\n",
      " 0.88456995 0.85779774 0.81291966 0.82216215]\n",
      "##########\n",
      "epoch:15 step:58605[D loss: 0.999953] [G loss: 1.000065]\n",
      "epoch:15 step:58610[D loss: 0.999983] [G loss: 1.000074]\n",
      "epoch:15 step:58615[D loss: 0.999974] [G loss: 1.000067]\n",
      "epoch:15 step:58620[D loss: 0.999948] [G loss: 1.000092]\n",
      "epoch:15 step:58625[D loss: 0.999949] [G loss: 1.000069]\n",
      "epoch:15 step:58630[D loss: 0.999979] [G loss: 1.000054]\n",
      "epoch:15 step:58635[D loss: 0.999973] [G loss: 1.000040]\n",
      "epoch:15 step:58640[D loss: 0.999991] [G loss: 1.000068]\n",
      "epoch:15 step:58645[D loss: 0.999967] [G loss: 1.000087]\n",
      "epoch:15 step:58650[D loss: 1.000025] [G loss: 1.000004]\n",
      "epoch:15 step:58655[D loss: 0.999978] [G loss: 1.000036]\n",
      "epoch:15 step:58660[D loss: 0.999950] [G loss: 1.000147]\n",
      "epoch:15 step:58665[D loss: 1.000079] [G loss: 0.999912]\n",
      "epoch:15 step:58670[D loss: 0.999930] [G loss: 1.000149]\n",
      "epoch:15 step:58675[D loss: 1.000014] [G loss: 1.000087]\n",
      "epoch:15 step:58680[D loss: 0.999955] [G loss: 1.000132]\n",
      "epoch:15 step:58685[D loss: 0.999958] [G loss: 1.000124]\n",
      "epoch:15 step:58690[D loss: 0.999951] [G loss: 1.000085]\n",
      "epoch:15 step:58695[D loss: 1.000194] [G loss: 0.999756]\n",
      "epoch:15 step:58700[D loss: 1.000044] [G loss: 0.999873]\n",
      "epoch:15 step:58705[D loss: 0.999962] [G loss: 1.000162]\n",
      "epoch:15 step:58710[D loss: 0.999960] [G loss: 1.000082]\n",
      "epoch:15 step:58715[D loss: 0.999966] [G loss: 1.000123]\n",
      "epoch:15 step:58720[D loss: 0.999932] [G loss: 1.000127]\n",
      "epoch:15 step:58725[D loss: 0.999949] [G loss: 1.000077]\n",
      "epoch:15 step:58730[D loss: 0.999982] [G loss: 1.000037]\n",
      "epoch:15 step:58735[D loss: 1.000005] [G loss: 0.999972]\n",
      "epoch:15 step:58740[D loss: 0.999990] [G loss: 1.000015]\n",
      "epoch:15 step:58745[D loss: 0.999929] [G loss: 1.000145]\n",
      "epoch:15 step:58750[D loss: 0.999998] [G loss: 1.000076]\n",
      "epoch:15 step:58755[D loss: 1.000022] [G loss: 1.000024]\n",
      "epoch:15 step:58760[D loss: 1.000009] [G loss: 1.000025]\n",
      "epoch:15 step:58765[D loss: 0.999968] [G loss: 1.000085]\n",
      "epoch:15 step:58770[D loss: 0.999946] [G loss: 1.000103]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:15 step:58775[D loss: 0.999964] [G loss: 1.000060]\n",
      "epoch:15 step:58780[D loss: 0.999964] [G loss: 1.000088]\n",
      "epoch:15 step:58785[D loss: 0.999994] [G loss: 1.000113]\n",
      "epoch:15 step:58790[D loss: 0.999981] [G loss: 1.000091]\n",
      "epoch:15 step:58795[D loss: 0.999973] [G loss: 1.000055]\n",
      "epoch:15 step:58800[D loss: 0.999981] [G loss: 1.000059]\n",
      "##############\n",
      "[0.85687024 0.85214924 0.82511135 0.81592447 0.80635539 0.83706146\n",
      " 0.86670317 0.84558729 0.80800373 0.84461436]\n",
      "##########\n",
      "epoch:15 step:58805[D loss: 0.999973] [G loss: 1.000076]\n",
      "epoch:15 step:58810[D loss: 0.999958] [G loss: 1.000090]\n",
      "epoch:15 step:58815[D loss: 0.999975] [G loss: 1.000082]\n",
      "epoch:15 step:58820[D loss: 0.999979] [G loss: 1.000071]\n",
      "epoch:15 step:58825[D loss: 0.999973] [G loss: 1.000058]\n",
      "epoch:15 step:58830[D loss: 0.999971] [G loss: 1.000058]\n",
      "epoch:15 step:58835[D loss: 0.999984] [G loss: 1.000060]\n",
      "epoch:15 step:58840[D loss: 0.999975] [G loss: 1.000052]\n",
      "epoch:15 step:58845[D loss: 0.999971] [G loss: 1.000062]\n",
      "epoch:15 step:58850[D loss: 0.999973] [G loss: 1.000068]\n",
      "epoch:15 step:58855[D loss: 0.999990] [G loss: 1.000029]\n",
      "epoch:15 step:58860[D loss: 1.000004] [G loss: 1.000020]\n",
      "epoch:15 step:58865[D loss: 0.999974] [G loss: 1.000041]\n",
      "epoch:15 step:58870[D loss: 0.999962] [G loss: 1.000077]\n",
      "epoch:15 step:58875[D loss: 1.000047] [G loss: 0.999950]\n",
      "epoch:15 step:58880[D loss: 1.000000] [G loss: 1.000061]\n",
      "epoch:15 step:58885[D loss: 0.999970] [G loss: 1.000023]\n",
      "epoch:15 step:58890[D loss: 0.999979] [G loss: 1.000080]\n",
      "epoch:15 step:58895[D loss: 0.999983] [G loss: 1.000051]\n",
      "epoch:15 step:58900[D loss: 1.000000] [G loss: 1.000074]\n",
      "epoch:15 step:58905[D loss: 0.999964] [G loss: 1.000066]\n",
      "epoch:15 step:58910[D loss: 0.999977] [G loss: 1.000058]\n",
      "epoch:15 step:58915[D loss: 0.999994] [G loss: 1.000011]\n",
      "epoch:15 step:58920[D loss: 0.999986] [G loss: 1.000058]\n",
      "epoch:15 step:58925[D loss: 0.999978] [G loss: 1.000084]\n",
      "epoch:15 step:58930[D loss: 1.000122] [G loss: 0.999933]\n",
      "epoch:15 step:58935[D loss: 1.000050] [G loss: 1.000066]\n",
      "epoch:15 step:58940[D loss: 0.999994] [G loss: 1.000139]\n",
      "epoch:15 step:58945[D loss: 0.999942] [G loss: 1.000140]\n",
      "epoch:15 step:58950[D loss: 0.999991] [G loss: 1.000178]\n",
      "epoch:15 step:58955[D loss: 0.999951] [G loss: 1.000096]\n",
      "epoch:15 step:58960[D loss: 0.999967] [G loss: 1.000133]\n",
      "epoch:15 step:58965[D loss: 0.999967] [G loss: 1.000098]\n",
      "epoch:15 step:58970[D loss: 0.999973] [G loss: 1.000078]\n",
      "epoch:15 step:58975[D loss: 0.999926] [G loss: 1.000129]\n",
      "epoch:15 step:58980[D loss: 0.999946] [G loss: 1.000103]\n",
      "epoch:15 step:58985[D loss: 0.999973] [G loss: 1.000043]\n",
      "epoch:15 step:58990[D loss: 0.999942] [G loss: 1.000082]\n",
      "epoch:15 step:58995[D loss: 0.999977] [G loss: 1.000068]\n",
      "epoch:15 step:59000[D loss: 0.999985] [G loss: 1.000008]\n",
      "##############\n",
      "[0.8687506  0.85847836 0.82285296 0.83797171 0.79335593 0.84374386\n",
      " 0.86693218 0.8403186  0.80578996 0.84669104]\n",
      "##########\n",
      "epoch:15 step:59005[D loss: 0.999963] [G loss: 1.000046]\n",
      "epoch:15 step:59010[D loss: 0.999987] [G loss: 1.000015]\n",
      "epoch:15 step:59015[D loss: 0.999991] [G loss: 1.000041]\n",
      "epoch:15 step:59020[D loss: 1.000052] [G loss: 1.000043]\n",
      "epoch:15 step:59025[D loss: 0.999928] [G loss: 1.000091]\n",
      "epoch:15 step:59030[D loss: 0.999978] [G loss: 1.000074]\n",
      "epoch:15 step:59035[D loss: 0.999953] [G loss: 1.000087]\n",
      "epoch:15 step:59040[D loss: 0.999959] [G loss: 1.000022]\n",
      "epoch:15 step:59045[D loss: 0.999962] [G loss: 1.000051]\n",
      "epoch:15 step:59050[D loss: 0.999976] [G loss: 1.000006]\n",
      "epoch:15 step:59055[D loss: 1.000065] [G loss: 0.999964]\n",
      "epoch:15 step:59060[D loss: 0.999922] [G loss: 1.000105]\n",
      "epoch:15 step:59065[D loss: 1.000002] [G loss: 1.000100]\n",
      "epoch:15 step:59070[D loss: 1.000147] [G loss: 0.999837]\n",
      "epoch:15 step:59075[D loss: 1.000062] [G loss: 0.999967]\n",
      "epoch:15 step:59080[D loss: 0.999966] [G loss: 0.999921]\n",
      "epoch:15 step:59085[D loss: 0.999944] [G loss: 1.000209]\n",
      "epoch:15 step:59090[D loss: 0.999969] [G loss: 1.000029]\n",
      "epoch:15 step:59095[D loss: 0.999974] [G loss: 1.000046]\n",
      "epoch:15 step:59100[D loss: 1.000069] [G loss: 0.999901]\n",
      "epoch:15 step:59105[D loss: 1.000039] [G loss: 0.999931]\n",
      "epoch:15 step:59110[D loss: 1.000069] [G loss: 0.999906]\n",
      "epoch:15 step:59115[D loss: 1.000094] [G loss: 0.999944]\n",
      "epoch:15 step:59120[D loss: 0.999974] [G loss: 1.000040]\n",
      "epoch:15 step:59125[D loss: 1.000013] [G loss: 1.000142]\n",
      "epoch:15 step:59130[D loss: 0.999793] [G loss: 1.000369]\n",
      "epoch:15 step:59135[D loss: 0.999855] [G loss: 1.000218]\n",
      "epoch:15 step:59140[D loss: 0.999980] [G loss: 1.000061]\n",
      "epoch:15 step:59145[D loss: 1.000048] [G loss: 1.000025]\n",
      "epoch:15 step:59150[D loss: 1.000026] [G loss: 0.999981]\n",
      "epoch:15 step:59155[D loss: 0.999934] [G loss: 1.000099]\n",
      "epoch:15 step:59160[D loss: 1.000028] [G loss: 1.000023]\n",
      "epoch:15 step:59165[D loss: 1.000012] [G loss: 0.999952]\n",
      "epoch:15 step:59170[D loss: 1.000031] [G loss: 0.999984]\n",
      "epoch:15 step:59175[D loss: 0.999972] [G loss: 1.000026]\n",
      "epoch:15 step:59180[D loss: 0.999971] [G loss: 1.000141]\n",
      "epoch:15 step:59185[D loss: 1.000019] [G loss: 1.000032]\n",
      "epoch:15 step:59190[D loss: 0.999934] [G loss: 1.000121]\n",
      "epoch:15 step:59195[D loss: 0.999974] [G loss: 1.000096]\n",
      "epoch:15 step:59200[D loss: 0.999962] [G loss: 1.000081]\n",
      "##############\n",
      "[0.8701785  0.88371264 0.82209195 0.83238328 0.81163137 0.84833828\n",
      " 0.89992092 0.85212493 0.82956647 0.8236498 ]\n",
      "##########\n",
      "epoch:15 step:59205[D loss: 0.999975] [G loss: 1.000085]\n",
      "epoch:15 step:59210[D loss: 1.000021] [G loss: 0.999980]\n",
      "epoch:15 step:59215[D loss: 1.000045] [G loss: 0.999978]\n",
      "epoch:15 step:59220[D loss: 0.999948] [G loss: 1.000083]\n",
      "epoch:15 step:59225[D loss: 0.999986] [G loss: 1.000021]\n",
      "epoch:15 step:59230[D loss: 1.000000] [G loss: 1.000077]\n",
      "epoch:15 step:59235[D loss: 0.999973] [G loss: 1.000059]\n",
      "epoch:15 step:59240[D loss: 0.999999] [G loss: 1.000069]\n",
      "epoch:15 step:59245[D loss: 1.000140] [G loss: 0.999799]\n",
      "epoch:15 step:59250[D loss: 0.999964] [G loss: 1.000019]\n",
      "epoch:15 step:59255[D loss: 1.000014] [G loss: 1.000081]\n",
      "epoch:15 step:59260[D loss: 0.999935] [G loss: 1.000103]\n",
      "epoch:15 step:59265[D loss: 1.000008] [G loss: 1.000048]\n",
      "epoch:15 step:59270[D loss: 1.000007] [G loss: 1.000026]\n",
      "epoch:15 step:59275[D loss: 1.000009] [G loss: 1.000018]\n",
      "epoch:15 step:59280[D loss: 1.000046] [G loss: 0.999965]\n",
      "epoch:15 step:59285[D loss: 0.999993] [G loss: 1.000070]\n",
      "epoch:15 step:59290[D loss: 1.000087] [G loss: 0.999837]\n",
      "epoch:15 step:59295[D loss: 0.999941] [G loss: 1.000193]\n",
      "epoch:15 step:59300[D loss: 0.999934] [G loss: 1.000084]\n",
      "epoch:15 step:59305[D loss: 0.999982] [G loss: 1.000067]\n",
      "epoch:15 step:59310[D loss: 0.999971] [G loss: 1.000072]\n",
      "epoch:15 step:59315[D loss: 0.999987] [G loss: 1.000016]\n",
      "epoch:15 step:59320[D loss: 0.999983] [G loss: 1.000038]\n",
      "epoch:15 step:59325[D loss: 1.000049] [G loss: 0.999904]\n",
      "epoch:15 step:59330[D loss: 0.999965] [G loss: 1.000098]\n",
      "epoch:15 step:59335[D loss: 0.999985] [G loss: 1.000171]\n",
      "epoch:15 step:59340[D loss: 0.999962] [G loss: 1.000031]\n",
      "epoch:15 step:59345[D loss: 0.999950] [G loss: 1.000060]\n",
      "epoch:15 step:59350[D loss: 0.999969] [G loss: 1.000059]\n",
      "epoch:15 step:59355[D loss: 0.999969] [G loss: 1.000045]\n",
      "epoch:15 step:59360[D loss: 1.000018] [G loss: 1.000003]\n",
      "epoch:15 step:59365[D loss: 0.999988] [G loss: 0.999986]\n",
      "epoch:15 step:59370[D loss: 0.999963] [G loss: 1.000051]\n",
      "epoch:15 step:59375[D loss: 0.999977] [G loss: 1.000044]\n",
      "epoch:15 step:59380[D loss: 0.999981] [G loss: 1.000037]\n",
      "epoch:15 step:59385[D loss: 0.999979] [G loss: 1.000041]\n",
      "epoch:15 step:59390[D loss: 0.999967] [G loss: 1.000072]\n",
      "epoch:15 step:59395[D loss: 1.000002] [G loss: 0.999971]\n",
      "epoch:15 step:59400[D loss: 0.999979] [G loss: 1.000061]\n",
      "##############\n",
      "[0.85460721 0.85814575 0.83947445 0.81762974 0.81436652 0.81759269\n",
      " 0.87072975 0.83772634 0.82734464 0.83745745]\n",
      "##########\n",
      "epoch:15 step:59405[D loss: 0.999962] [G loss: 1.000073]\n",
      "epoch:15 step:59410[D loss: 1.000027] [G loss: 0.999991]\n",
      "epoch:15 step:59415[D loss: 0.999980] [G loss: 1.000043]\n",
      "epoch:15 step:59420[D loss: 0.999926] [G loss: 1.000191]\n",
      "epoch:15 step:59425[D loss: 1.000076] [G loss: 1.000018]\n",
      "epoch:15 step:59430[D loss: 1.000100] [G loss: 1.000031]\n",
      "epoch:15 step:59435[D loss: 0.999829] [G loss: 1.000412]\n",
      "epoch:15 step:59440[D loss: 0.999898] [G loss: 1.000180]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:15 step:59445[D loss: 0.999947] [G loss: 1.000111]\n",
      "epoch:15 step:59450[D loss: 0.999984] [G loss: 1.000004]\n",
      "epoch:15 step:59455[D loss: 1.000181] [G loss: 0.999759]\n",
      "epoch:15 step:59460[D loss: 0.999970] [G loss: 1.000003]\n",
      "epoch:15 step:59465[D loss: 0.999890] [G loss: 1.000155]\n",
      "epoch:15 step:59470[D loss: 1.000200] [G loss: 0.999874]\n",
      "epoch:15 step:59475[D loss: 1.000119] [G loss: 0.999911]\n",
      "epoch:15 step:59480[D loss: 0.999929] [G loss: 1.000161]\n",
      "epoch:15 step:59485[D loss: 0.999919] [G loss: 1.000091]\n",
      "epoch:15 step:59490[D loss: 0.999991] [G loss: 1.000015]\n",
      "epoch:15 step:59495[D loss: 0.999990] [G loss: 1.000015]\n",
      "epoch:15 step:59500[D loss: 1.000037] [G loss: 1.000001]\n",
      "epoch:15 step:59505[D loss: 0.999998] [G loss: 0.999932]\n",
      "epoch:15 step:59510[D loss: 0.999984] [G loss: 1.000079]\n",
      "epoch:15 step:59515[D loss: 0.999987] [G loss: 1.000033]\n",
      "epoch:15 step:59520[D loss: 0.999988] [G loss: 1.000048]\n",
      "epoch:15 step:59525[D loss: 0.999957] [G loss: 1.000017]\n",
      "epoch:15 step:59530[D loss: 0.999955] [G loss: 1.000100]\n",
      "epoch:15 step:59535[D loss: 0.999938] [G loss: 1.000087]\n",
      "epoch:15 step:59540[D loss: 0.999989] [G loss: 1.000024]\n",
      "epoch:15 step:59545[D loss: 0.999981] [G loss: 1.000068]\n",
      "epoch:15 step:59550[D loss: 0.999974] [G loss: 1.000081]\n",
      "epoch:15 step:59555[D loss: 0.999988] [G loss: 1.000038]\n",
      "epoch:15 step:59560[D loss: 0.999974] [G loss: 1.000063]\n",
      "epoch:15 step:59565[D loss: 1.000022] [G loss: 1.000039]\n",
      "epoch:15 step:59570[D loss: 1.000007] [G loss: 1.000039]\n",
      "epoch:15 step:59575[D loss: 0.999968] [G loss: 1.000104]\n",
      "epoch:15 step:59580[D loss: 1.000073] [G loss: 0.999991]\n",
      "epoch:15 step:59585[D loss: 1.000000] [G loss: 1.000053]\n",
      "epoch:15 step:59590[D loss: 1.000009] [G loss: 1.000088]\n",
      "epoch:15 step:59595[D loss: 0.999992] [G loss: 1.000112]\n",
      "epoch:15 step:59600[D loss: 0.999897] [G loss: 1.000219]\n",
      "##############\n",
      "[0.86365435 0.84378812 0.81970266 0.82869346 0.7868002  0.82028983\n",
      " 0.87519896 0.84000781 0.83070169 0.83638887]\n",
      "##########\n",
      "epoch:15 step:59605[D loss: 0.999950] [G loss: 1.000077]\n",
      "epoch:15 step:59610[D loss: 0.999952] [G loss: 1.000150]\n",
      "epoch:15 step:59615[D loss: 0.999971] [G loss: 1.000077]\n",
      "epoch:15 step:59620[D loss: 0.999978] [G loss: 1.000060]\n",
      "epoch:15 step:59625[D loss: 0.999972] [G loss: 1.000043]\n",
      "epoch:15 step:59630[D loss: 1.000012] [G loss: 1.000011]\n",
      "epoch:15 step:59635[D loss: 0.999992] [G loss: 1.000031]\n",
      "epoch:15 step:59640[D loss: 0.999976] [G loss: 1.000056]\n",
      "epoch:15 step:59645[D loss: 1.000045] [G loss: 1.000036]\n",
      "epoch:15 step:59650[D loss: 0.999970] [G loss: 0.999936]\n",
      "epoch:15 step:59655[D loss: 0.999995] [G loss: 0.999958]\n",
      "epoch:15 step:59660[D loss: 0.999962] [G loss: 1.000075]\n",
      "epoch:15 step:59665[D loss: 1.000011] [G loss: 1.000040]\n",
      "epoch:15 step:59670[D loss: 1.000048] [G loss: 0.999966]\n",
      "epoch:15 step:59675[D loss: 0.999976] [G loss: 1.000067]\n",
      "epoch:15 step:59680[D loss: 0.999925] [G loss: 1.000130]\n",
      "epoch:15 step:59685[D loss: 0.999988] [G loss: 1.000024]\n",
      "epoch:15 step:59690[D loss: 1.000040] [G loss: 0.999977]\n",
      "epoch:15 step:59695[D loss: 0.999974] [G loss: 1.000149]\n",
      "epoch:15 step:59700[D loss: 1.000015] [G loss: 0.999986]\n",
      "epoch:15 step:59705[D loss: 0.999941] [G loss: 1.000157]\n",
      "epoch:15 step:59710[D loss: 0.999955] [G loss: 1.000132]\n",
      "epoch:15 step:59715[D loss: 1.000007] [G loss: 1.000073]\n",
      "epoch:15 step:59720[D loss: 0.999959] [G loss: 1.000065]\n",
      "epoch:15 step:59725[D loss: 0.999986] [G loss: 1.000060]\n",
      "epoch:15 step:59730[D loss: 1.000040] [G loss: 0.999959]\n",
      "epoch:15 step:59735[D loss: 1.000003] [G loss: 1.000056]\n",
      "epoch:15 step:59740[D loss: 1.000095] [G loss: 0.999828]\n",
      "epoch:15 step:59745[D loss: 0.999999] [G loss: 0.999992]\n",
      "epoch:15 step:59750[D loss: 0.999925] [G loss: 1.000153]\n",
      "epoch:15 step:59755[D loss: 0.999988] [G loss: 1.000074]\n",
      "epoch:15 step:59760[D loss: 1.000031] [G loss: 0.999982]\n",
      "epoch:15 step:59765[D loss: 0.999936] [G loss: 1.000085]\n",
      "epoch:15 step:59770[D loss: 0.999955] [G loss: 1.000036]\n",
      "epoch:15 step:59775[D loss: 1.000011] [G loss: 0.999974]\n",
      "epoch:15 step:59780[D loss: 1.000020] [G loss: 0.999958]\n",
      "epoch:15 step:59785[D loss: 0.999977] [G loss: 1.000088]\n",
      "epoch:15 step:59790[D loss: 0.999960] [G loss: 1.000235]\n",
      "epoch:15 step:59795[D loss: 0.999955] [G loss: 1.000242]\n",
      "epoch:15 step:59800[D loss: 0.999886] [G loss: 1.000324]\n",
      "##############\n",
      "[0.86917792 0.85312164 0.86395497 0.81473432 0.79731143 0.82826034\n",
      " 0.87674504 0.82961628 0.80946735 0.84493394]\n",
      "##########\n",
      "epoch:15 step:59805[D loss: 0.999892] [G loss: 1.000267]\n",
      "epoch:15 step:59810[D loss: 0.999953] [G loss: 1.000177]\n",
      "epoch:15 step:59815[D loss: 0.999987] [G loss: 1.000071]\n",
      "epoch:15 step:59820[D loss: 0.999980] [G loss: 1.000005]\n",
      "epoch:15 step:59825[D loss: 1.000087] [G loss: 0.999901]\n",
      "epoch:15 step:59830[D loss: 0.999965] [G loss: 0.999988]\n",
      "epoch:15 step:59835[D loss: 0.999931] [G loss: 1.000075]\n",
      "epoch:15 step:59840[D loss: 1.000020] [G loss: 0.999955]\n",
      "epoch:15 step:59845[D loss: 1.000130] [G loss: 0.999812]\n",
      "epoch:15 step:59850[D loss: 1.000024] [G loss: 0.999911]\n",
      "epoch:15 step:59855[D loss: 0.999976] [G loss: 1.000119]\n",
      "epoch:15 step:59860[D loss: 0.999941] [G loss: 1.000115]\n",
      "epoch:15 step:59865[D loss: 0.999926] [G loss: 1.000131]\n",
      "epoch:15 step:59870[D loss: 0.999972] [G loss: 1.000086]\n",
      "epoch:15 step:59875[D loss: 0.999953] [G loss: 1.000062]\n",
      "epoch:15 step:59880[D loss: 0.999986] [G loss: 1.000028]\n",
      "epoch:15 step:59885[D loss: 1.000050] [G loss: 0.999884]\n",
      "epoch:15 step:59890[D loss: 0.999911] [G loss: 1.000049]\n",
      "epoch:15 step:59895[D loss: 0.999989] [G loss: 0.999964]\n",
      "epoch:15 step:59900[D loss: 0.999975] [G loss: 1.000020]\n",
      "epoch:15 step:59905[D loss: 1.000007] [G loss: 1.000137]\n",
      "epoch:15 step:59910[D loss: 0.999909] [G loss: 1.000099]\n",
      "epoch:15 step:59915[D loss: 1.000011] [G loss: 0.999982]\n",
      "epoch:15 step:59920[D loss: 0.999955] [G loss: 1.000056]\n",
      "epoch:15 step:59925[D loss: 0.999960] [G loss: 1.000042]\n",
      "epoch:15 step:59930[D loss: 0.999976] [G loss: 1.000050]\n",
      "epoch:15 step:59935[D loss: 1.000004] [G loss: 0.999981]\n",
      "epoch:15 step:59940[D loss: 1.000023] [G loss: 0.999963]\n",
      "epoch:15 step:59945[D loss: 0.999994] [G loss: 1.000014]\n",
      "epoch:15 step:59950[D loss: 1.000010] [G loss: 1.000014]\n",
      "epoch:15 step:59955[D loss: 1.000031] [G loss: 1.000009]\n",
      "epoch:15 step:59960[D loss: 0.999955] [G loss: 1.000014]\n",
      "epoch:15 step:59965[D loss: 0.999999] [G loss: 0.999993]\n",
      "epoch:15 step:59970[D loss: 0.999973] [G loss: 1.000018]\n",
      "epoch:15 step:59975[D loss: 0.999969] [G loss: 1.000038]\n",
      "epoch:15 step:59980[D loss: 0.999981] [G loss: 1.000033]\n",
      "epoch:15 step:59985[D loss: 1.000011] [G loss: 0.999950]\n",
      "epoch:15 step:59990[D loss: 0.999981] [G loss: 1.000028]\n",
      "epoch:15 step:59995[D loss: 0.999960] [G loss: 1.000064]\n",
      "epoch:15 step:60000[D loss: 0.999948] [G loss: 1.000135]\n",
      "##############\n",
      "[0.8718273  0.85166503 0.81273567 0.8364547  0.78728263 0.84755996\n",
      " 0.88708946 0.82614473 0.8222539  0.82561344]\n",
      "##########\n",
      "epoch:15 step:60005[D loss: 0.999992] [G loss: 1.000040]\n",
      "epoch:15 step:60010[D loss: 1.000046] [G loss: 0.999975]\n",
      "epoch:15 step:60015[D loss: 0.999980] [G loss: 0.999966]\n",
      "epoch:15 step:60020[D loss: 0.999965] [G loss: 1.000023]\n",
      "epoch:15 step:60025[D loss: 0.999904] [G loss: 1.000229]\n",
      "epoch:15 step:60030[D loss: 0.999931] [G loss: 1.000061]\n",
      "epoch:15 step:60035[D loss: 0.999930] [G loss: 1.000075]\n",
      "epoch:15 step:60040[D loss: 0.999979] [G loss: 1.000065]\n",
      "epoch:15 step:60045[D loss: 0.999955] [G loss: 1.000074]\n",
      "epoch:15 step:60050[D loss: 0.999964] [G loss: 1.000077]\n",
      "epoch:15 step:60055[D loss: 0.999991] [G loss: 1.000043]\n",
      "epoch:15 step:60060[D loss: 1.000017] [G loss: 0.999952]\n",
      "epoch:15 step:60065[D loss: 0.999984] [G loss: 1.000059]\n",
      "epoch:15 step:60070[D loss: 0.999932] [G loss: 1.000145]\n",
      "epoch:15 step:60075[D loss: 0.999969] [G loss: 1.000024]\n",
      "epoch:15 step:60080[D loss: 1.000002] [G loss: 0.999981]\n",
      "epoch:15 step:60085[D loss: 0.999966] [G loss: 1.000088]\n",
      "epoch:15 step:60090[D loss: 0.999986] [G loss: 1.000050]\n",
      "epoch:15 step:60095[D loss: 0.999945] [G loss: 1.000146]\n",
      "epoch:15 step:60100[D loss: 0.999968] [G loss: 1.000114]\n",
      "epoch:15 step:60105[D loss: 0.999955] [G loss: 1.000104]\n",
      "epoch:15 step:60110[D loss: 0.999963] [G loss: 1.000067]\n",
      "epoch:15 step:60115[D loss: 0.999981] [G loss: 1.000149]\n",
      "epoch:15 step:60120[D loss: 0.999976] [G loss: 1.000060]\n",
      "epoch:15 step:60125[D loss: 1.000018] [G loss: 1.000141]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:15 step:60130[D loss: 1.000042] [G loss: 0.999993]\n",
      "epoch:15 step:60135[D loss: 0.999973] [G loss: 1.000072]\n",
      "epoch:15 step:60140[D loss: 0.999964] [G loss: 1.000076]\n",
      "epoch:15 step:60145[D loss: 0.999967] [G loss: 1.000081]\n",
      "epoch:15 step:60150[D loss: 1.000223] [G loss: 0.999717]\n",
      "epoch:15 step:60155[D loss: 1.000032] [G loss: 1.000042]\n",
      "epoch:15 step:60160[D loss: 0.999889] [G loss: 1.000209]\n",
      "epoch:15 step:60165[D loss: 0.999878] [G loss: 1.000257]\n",
      "epoch:15 step:60170[D loss: 0.999947] [G loss: 1.000073]\n",
      "epoch:15 step:60175[D loss: 0.999968] [G loss: 1.000176]\n",
      "epoch:15 step:60180[D loss: 0.999955] [G loss: 1.000060]\n",
      "epoch:15 step:60185[D loss: 0.999937] [G loss: 1.000036]\n",
      "epoch:15 step:60190[D loss: 1.000007] [G loss: 1.000033]\n",
      "epoch:15 step:60195[D loss: 0.999985] [G loss: 1.000076]\n",
      "epoch:15 step:60200[D loss: 1.000116] [G loss: 0.999815]\n",
      "##############\n",
      "[0.86496538 0.84076412 0.83346222 0.81958279 0.80492537 0.82247888\n",
      " 0.88292491 0.85696571 0.8076275  0.85622479]\n",
      "##########\n",
      "epoch:15 step:60205[D loss: 0.999994] [G loss: 0.999988]\n",
      "epoch:15 step:60210[D loss: 1.000015] [G loss: 0.999960]\n",
      "epoch:15 step:60215[D loss: 0.999946] [G loss: 1.000149]\n",
      "epoch:15 step:60220[D loss: 1.000007] [G loss: 0.999993]\n",
      "epoch:15 step:60225[D loss: 0.999987] [G loss: 1.000025]\n",
      "epoch:15 step:60230[D loss: 0.999983] [G loss: 1.000073]\n",
      "epoch:15 step:60235[D loss: 1.000031] [G loss: 0.999972]\n",
      "epoch:15 step:60240[D loss: 0.999992] [G loss: 1.000038]\n",
      "epoch:15 step:60245[D loss: 0.999966] [G loss: 1.000073]\n",
      "epoch:15 step:60250[D loss: 0.999993] [G loss: 1.000049]\n",
      "epoch:15 step:60255[D loss: 0.999953] [G loss: 1.000066]\n",
      "epoch:15 step:60260[D loss: 0.999957] [G loss: 1.000126]\n",
      "epoch:15 step:60265[D loss: 1.000015] [G loss: 1.000003]\n",
      "epoch:15 step:60270[D loss: 0.999983] [G loss: 1.000100]\n",
      "epoch:15 step:60275[D loss: 0.999966] [G loss: 1.000069]\n",
      "epoch:15 step:60280[D loss: 1.000002] [G loss: 1.000050]\n",
      "epoch:15 step:60285[D loss: 0.999962] [G loss: 1.000236]\n",
      "epoch:15 step:60290[D loss: 0.999920] [G loss: 1.000117]\n",
      "epoch:15 step:60295[D loss: 0.999941] [G loss: 1.000111]\n",
      "epoch:15 step:60300[D loss: 0.999979] [G loss: 1.000039]\n",
      "epoch:15 step:60305[D loss: 0.999984] [G loss: 1.000022]\n",
      "epoch:15 step:60310[D loss: 0.999988] [G loss: 1.000034]\n",
      "epoch:15 step:60315[D loss: 0.999961] [G loss: 1.000029]\n",
      "epoch:15 step:60320[D loss: 0.999983] [G loss: 1.000072]\n",
      "epoch:15 step:60325[D loss: 0.999985] [G loss: 1.000113]\n",
      "epoch:15 step:60330[D loss: 0.999933] [G loss: 1.000120]\n",
      "epoch:15 step:60335[D loss: 0.999981] [G loss: 1.000051]\n",
      "epoch:15 step:60340[D loss: 0.999968] [G loss: 1.000055]\n",
      "epoch:15 step:60345[D loss: 0.999952] [G loss: 1.000045]\n",
      "epoch:15 step:60350[D loss: 0.999986] [G loss: 1.000014]\n",
      "epoch:15 step:60355[D loss: 1.000013] [G loss: 1.000011]\n",
      "epoch:15 step:60360[D loss: 0.999973] [G loss: 1.000084]\n",
      "epoch:15 step:60365[D loss: 1.000023] [G loss: 0.999968]\n",
      "epoch:15 step:60370[D loss: 0.999974] [G loss: 1.000068]\n",
      "epoch:15 step:60375[D loss: 1.000000] [G loss: 1.000018]\n",
      "epoch:15 step:60380[D loss: 1.000039] [G loss: 1.000034]\n",
      "epoch:15 step:60385[D loss: 0.999953] [G loss: 1.000088]\n",
      "epoch:15 step:60390[D loss: 1.000074] [G loss: 1.000016]\n",
      "epoch:15 step:60395[D loss: 0.999940] [G loss: 1.000126]\n",
      "epoch:15 step:60400[D loss: 1.000009] [G loss: 1.000100]\n",
      "##############\n",
      "[0.86736357 0.86248406 0.82006588 0.83954109 0.82985434 0.83352402\n",
      " 0.88230363 0.81944936 0.83861317 0.84897289]\n",
      "##########\n",
      "epoch:15 step:60405[D loss: 0.999948] [G loss: 1.000120]\n",
      "epoch:15 step:60410[D loss: 0.999983] [G loss: 1.000062]\n",
      "epoch:15 step:60415[D loss: 0.999997] [G loss: 1.000023]\n",
      "epoch:15 step:60420[D loss: 1.000017] [G loss: 0.999975]\n",
      "epoch:15 step:60425[D loss: 0.999974] [G loss: 1.000049]\n",
      "epoch:15 step:60430[D loss: 0.999989] [G loss: 1.000002]\n",
      "epoch:15 step:60435[D loss: 0.999965] [G loss: 1.000109]\n",
      "epoch:15 step:60440[D loss: 0.999983] [G loss: 1.000052]\n",
      "epoch:15 step:60445[D loss: 0.999972] [G loss: 1.000072]\n",
      "epoch:15 step:60450[D loss: 0.999989] [G loss: 1.000060]\n",
      "epoch:15 step:60455[D loss: 0.999917] [G loss: 1.000139]\n",
      "epoch:15 step:60460[D loss: 0.999960] [G loss: 1.000127]\n",
      "epoch:15 step:60465[D loss: 0.999964] [G loss: 1.000075]\n",
      "epoch:15 step:60470[D loss: 0.999983] [G loss: 1.000059]\n",
      "epoch:15 step:60475[D loss: 0.999976] [G loss: 1.000031]\n",
      "epoch:15 step:60480[D loss: 1.000007] [G loss: 1.000070]\n",
      "epoch:15 step:60485[D loss: 1.000060] [G loss: 1.000105]\n",
      "epoch:15 step:60490[D loss: 1.000022] [G loss: 1.000042]\n",
      "epoch:15 step:60495[D loss: 0.999980] [G loss: 1.000072]\n",
      "epoch:15 step:60500[D loss: 0.999891] [G loss: 1.000165]\n",
      "epoch:15 step:60505[D loss: 0.999993] [G loss: 1.000028]\n",
      "epoch:15 step:60510[D loss: 1.000008] [G loss: 1.000011]\n",
      "epoch:15 step:60515[D loss: 0.999992] [G loss: 0.999972]\n",
      "epoch:15 step:60520[D loss: 0.999938] [G loss: 1.000114]\n",
      "epoch:15 step:60525[D loss: 0.999957] [G loss: 1.000126]\n",
      "epoch:15 step:60530[D loss: 1.000041] [G loss: 0.999968]\n",
      "epoch:15 step:60535[D loss: 0.999989] [G loss: 0.999988]\n",
      "epoch:15 step:60540[D loss: 0.999992] [G loss: 1.000024]\n",
      "epoch:15 step:60545[D loss: 0.999943] [G loss: 1.000108]\n",
      "epoch:15 step:60550[D loss: 1.000028] [G loss: 1.000073]\n",
      "epoch:15 step:60555[D loss: 1.000044] [G loss: 1.000019]\n",
      "epoch:15 step:60560[D loss: 0.999970] [G loss: 1.000065]\n",
      "epoch:15 step:60565[D loss: 0.999983] [G loss: 1.000043]\n",
      "epoch:15 step:60570[D loss: 1.000053] [G loss: 0.999876]\n",
      "epoch:15 step:60575[D loss: 1.000022] [G loss: 0.999984]\n",
      "epoch:15 step:60580[D loss: 0.999947] [G loss: 1.000070]\n",
      "epoch:15 step:60585[D loss: 0.999953] [G loss: 1.000068]\n",
      "epoch:15 step:60590[D loss: 0.999963] [G loss: 1.000085]\n",
      "epoch:15 step:60595[D loss: 1.000017] [G loss: 0.999987]\n",
      "epoch:15 step:60600[D loss: 0.999979] [G loss: 1.000111]\n",
      "##############\n",
      "[0.85923328 0.85683311 0.83241015 0.83631208 0.80406956 0.81473183\n",
      " 0.85478031 0.83513947 0.8106307  0.8575738 ]\n",
      "##########\n",
      "epoch:15 step:60605[D loss: 1.000028] [G loss: 1.000024]\n",
      "epoch:15 step:60610[D loss: 1.000010] [G loss: 1.000026]\n",
      "epoch:15 step:60615[D loss: 0.999945] [G loss: 1.000113]\n",
      "epoch:15 step:60620[D loss: 0.999895] [G loss: 1.000128]\n",
      "epoch:15 step:60625[D loss: 0.999965] [G loss: 1.000065]\n",
      "epoch:15 step:60630[D loss: 0.999999] [G loss: 0.999931]\n",
      "epoch:15 step:60635[D loss: 1.000006] [G loss: 0.999993]\n",
      "epoch:15 step:60640[D loss: 1.000031] [G loss: 0.999935]\n",
      "epoch:15 step:60645[D loss: 1.000112] [G loss: 0.999849]\n",
      "epoch:15 step:60650[D loss: 1.000079] [G loss: 0.999848]\n",
      "epoch:15 step:60655[D loss: 1.000001] [G loss: 1.000124]\n",
      "epoch:15 step:60660[D loss: 0.999998] [G loss: 1.000031]\n",
      "epoch:15 step:60665[D loss: 0.999896] [G loss: 1.000151]\n",
      "epoch:15 step:60670[D loss: 0.999965] [G loss: 1.000103]\n",
      "epoch:15 step:60675[D loss: 1.000008] [G loss: 1.000061]\n",
      "epoch:15 step:60680[D loss: 0.999994] [G loss: 1.000098]\n",
      "epoch:15 step:60685[D loss: 0.999965] [G loss: 1.000064]\n",
      "epoch:15 step:60690[D loss: 1.000001] [G loss: 1.000040]\n",
      "epoch:15 step:60695[D loss: 1.000021] [G loss: 1.000070]\n",
      "epoch:15 step:60700[D loss: 0.999849] [G loss: 1.000265]\n",
      "epoch:15 step:60705[D loss: 0.999901] [G loss: 1.000194]\n",
      "epoch:15 step:60710[D loss: 0.999959] [G loss: 1.000168]\n",
      "epoch:15 step:60715[D loss: 0.999938] [G loss: 1.000073]\n",
      "epoch:15 step:60720[D loss: 0.999981] [G loss: 1.000050]\n",
      "epoch:15 step:60725[D loss: 0.999947] [G loss: 1.000106]\n",
      "epoch:15 step:60730[D loss: 0.999978] [G loss: 1.000076]\n",
      "epoch:15 step:60735[D loss: 0.999997] [G loss: 1.000011]\n",
      "epoch:15 step:60740[D loss: 0.999958] [G loss: 1.000030]\n",
      "epoch:15 step:60745[D loss: 0.999992] [G loss: 1.000010]\n",
      "epoch:15 step:60750[D loss: 0.999950] [G loss: 1.000072]\n",
      "epoch:15 step:60755[D loss: 1.000004] [G loss: 0.999992]\n",
      "epoch:15 step:60760[D loss: 0.999955] [G loss: 1.000094]\n",
      "epoch:15 step:60765[D loss: 1.000029] [G loss: 0.999923]\n",
      "epoch:15 step:60770[D loss: 0.999974] [G loss: 1.000086]\n",
      "epoch:15 step:60775[D loss: 0.999943] [G loss: 1.000126]\n",
      "epoch:15 step:60780[D loss: 0.999912] [G loss: 1.000172]\n",
      "epoch:15 step:60785[D loss: 0.999940] [G loss: 1.000060]\n",
      "epoch:15 step:60790[D loss: 0.999968] [G loss: 1.000041]\n",
      "epoch:15 step:60795[D loss: 0.999992] [G loss: 0.999894]\n",
      "epoch:15 step:60800[D loss: 0.999970] [G loss: 1.000035]\n",
      "##############\n",
      "[0.83422931 0.86182562 0.84043207 0.83495392 0.79450881 0.83478036\n",
      " 0.88472472 0.83558538 0.83990659 0.84724532]\n",
      "##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:15 step:60805[D loss: 1.000046] [G loss: 0.999891]\n",
      "epoch:15 step:60810[D loss: 1.000002] [G loss: 1.000047]\n",
      "epoch:15 step:60815[D loss: 0.999993] [G loss: 1.000132]\n",
      "epoch:15 step:60820[D loss: 0.999937] [G loss: 1.000067]\n",
      "epoch:15 step:60825[D loss: 0.999942] [G loss: 1.000133]\n",
      "epoch:15 step:60830[D loss: 0.999966] [G loss: 1.000030]\n",
      "epoch:15 step:60835[D loss: 1.000019] [G loss: 0.999972]\n",
      "epoch:15 step:60840[D loss: 1.000007] [G loss: 1.000015]\n",
      "epoch:15 step:60845[D loss: 0.999954] [G loss: 0.999924]\n",
      "epoch:15 step:60850[D loss: 1.000081] [G loss: 0.999915]\n",
      "epoch:15 step:60855[D loss: 0.999922] [G loss: 1.000147]\n",
      "epoch:15 step:60860[D loss: 0.999837] [G loss: 1.000274]\n",
      "epoch:15 step:60865[D loss: 0.999902] [G loss: 1.000137]\n",
      "epoch:15 step:60870[D loss: 0.999997] [G loss: 1.000009]\n",
      "epoch:15 step:60875[D loss: 0.999977] [G loss: 1.000040]\n",
      "epoch:15 step:60880[D loss: 0.999962] [G loss: 1.000073]\n",
      "epoch:15 step:60885[D loss: 0.999973] [G loss: 1.000012]\n",
      "epoch:15 step:60890[D loss: 0.999993] [G loss: 1.000033]\n",
      "epoch:15 step:60895[D loss: 0.999968] [G loss: 1.000085]\n",
      "epoch:15 step:60900[D loss: 0.999983] [G loss: 1.000063]\n",
      "epoch:15 step:60905[D loss: 0.999948] [G loss: 1.000095]\n",
      "epoch:15 step:60910[D loss: 0.999954] [G loss: 1.000081]\n",
      "epoch:15 step:60915[D loss: 1.000019] [G loss: 1.000020]\n",
      "epoch:15 step:60920[D loss: 1.000019] [G loss: 0.999999]\n",
      "epoch:15 step:60925[D loss: 0.999953] [G loss: 1.000103]\n",
      "epoch:15 step:60930[D loss: 1.000021] [G loss: 1.000021]\n",
      "epoch:15 step:60935[D loss: 0.999953] [G loss: 1.000041]\n",
      "epoch:15 step:60940[D loss: 0.999977] [G loss: 1.000037]\n",
      "epoch:15 step:60945[D loss: 1.000011] [G loss: 0.999994]\n",
      "epoch:15 step:60950[D loss: 0.999973] [G loss: 1.000028]\n",
      "epoch:15 step:60955[D loss: 0.999972] [G loss: 1.000039]\n",
      "epoch:15 step:60960[D loss: 0.999974] [G loss: 1.000092]\n",
      "epoch:15 step:60965[D loss: 0.999983] [G loss: 1.000025]\n",
      "epoch:15 step:60970[D loss: 0.999941] [G loss: 1.000113]\n",
      "epoch:15 step:60975[D loss: 0.999974] [G loss: 1.000065]\n",
      "epoch:15 step:60980[D loss: 0.999974] [G loss: 1.000057]\n",
      "epoch:15 step:60985[D loss: 0.999980] [G loss: 1.000055]\n",
      "epoch:15 step:60990[D loss: 0.999975] [G loss: 1.000069]\n",
      "epoch:15 step:60995[D loss: 0.999955] [G loss: 1.000062]\n",
      "epoch:15 step:61000[D loss: 0.999971] [G loss: 1.000055]\n",
      "##############\n",
      "[0.85565805 0.86666538 0.83143639 0.83051896 0.79684686 0.83512635\n",
      " 0.89003349 0.80072554 0.81517482 0.85241177]\n",
      "##########\n",
      "epoch:15 step:61005[D loss: 1.000015] [G loss: 0.999959]\n",
      "epoch:15 step:61010[D loss: 0.999894] [G loss: 1.000180]\n",
      "epoch:15 step:61015[D loss: 0.999967] [G loss: 1.000075]\n",
      "epoch:15 step:61020[D loss: 0.999974] [G loss: 1.000088]\n",
      "epoch:15 step:61025[D loss: 1.000002] [G loss: 1.000028]\n",
      "epoch:15 step:61030[D loss: 0.999989] [G loss: 1.000038]\n",
      "epoch:15 step:61035[D loss: 1.000017] [G loss: 0.999979]\n",
      "epoch:15 step:61040[D loss: 1.000058] [G loss: 1.000087]\n",
      "epoch:15 step:61045[D loss: 0.999950] [G loss: 1.000016]\n",
      "epoch:15 step:61050[D loss: 0.999863] [G loss: 1.000253]\n",
      "epoch:15 step:61055[D loss: 0.999943] [G loss: 1.000107]\n",
      "epoch:15 step:61060[D loss: 0.999985] [G loss: 1.000048]\n",
      "epoch:15 step:61065[D loss: 0.999961] [G loss: 1.000078]\n",
      "epoch:15 step:61070[D loss: 0.999967] [G loss: 1.000060]\n",
      "epoch:15 step:61075[D loss: 1.000049] [G loss: 0.999942]\n",
      "epoch:15 step:61080[D loss: 1.000017] [G loss: 0.999941]\n",
      "epoch:15 step:61085[D loss: 1.000001] [G loss: 1.000048]\n",
      "epoch:15 step:61090[D loss: 0.999896] [G loss: 1.000144]\n",
      "epoch:15 step:61095[D loss: 0.999929] [G loss: 1.000117]\n",
      "epoch:15 step:61100[D loss: 0.999988] [G loss: 1.000095]\n",
      "epoch:15 step:61105[D loss: 0.999906] [G loss: 1.000181]\n",
      "epoch:15 step:61110[D loss: 0.999971] [G loss: 1.000057]\n",
      "epoch:15 step:61115[D loss: 0.999964] [G loss: 1.000065]\n",
      "epoch:15 step:61120[D loss: 0.999994] [G loss: 1.000025]\n",
      "epoch:15 step:61125[D loss: 1.000077] [G loss: 0.999893]\n",
      "epoch:15 step:61130[D loss: 0.999933] [G loss: 1.000227]\n",
      "epoch:15 step:61135[D loss: 0.999988] [G loss: 1.000014]\n",
      "epoch:15 step:61140[D loss: 0.999963] [G loss: 1.000098]\n",
      "epoch:15 step:61145[D loss: 0.999941] [G loss: 1.000107]\n",
      "epoch:15 step:61150[D loss: 0.999963] [G loss: 1.000075]\n",
      "epoch:15 step:61155[D loss: 0.999967] [G loss: 1.000068]\n",
      "epoch:15 step:61160[D loss: 0.999979] [G loss: 1.000073]\n",
      "epoch:15 step:61165[D loss: 1.000002] [G loss: 1.000041]\n",
      "epoch:15 step:61170[D loss: 1.000001] [G loss: 1.000007]\n",
      "epoch:15 step:61175[D loss: 1.000035] [G loss: 1.000004]\n",
      "epoch:15 step:61180[D loss: 0.999948] [G loss: 1.000141]\n",
      "epoch:15 step:61185[D loss: 0.999920] [G loss: 1.000177]\n",
      "epoch:15 step:61190[D loss: 0.999994] [G loss: 1.000038]\n",
      "epoch:15 step:61195[D loss: 0.999994] [G loss: 1.000016]\n",
      "epoch:15 step:61200[D loss: 0.999983] [G loss: 1.000056]\n",
      "##############\n",
      "[0.85812379 0.85773165 0.82356899 0.83775549 0.80657514 0.84035699\n",
      " 0.88582219 0.85217274 0.82020691 0.832292  ]\n",
      "##########\n",
      "epoch:15 step:61205[D loss: 0.999993] [G loss: 1.000024]\n",
      "epoch:15 step:61210[D loss: 0.999951] [G loss: 1.000081]\n",
      "epoch:15 step:61215[D loss: 0.999970] [G loss: 1.000070]\n",
      "epoch:15 step:61220[D loss: 0.999975] [G loss: 1.000044]\n",
      "epoch:15 step:61225[D loss: 0.999995] [G loss: 1.000139]\n",
      "epoch:15 step:61230[D loss: 1.000007] [G loss: 1.000001]\n",
      "epoch:15 step:61235[D loss: 1.000014] [G loss: 1.000040]\n",
      "epoch:15 step:61240[D loss: 1.000025] [G loss: 1.000172]\n",
      "epoch:15 step:61245[D loss: 0.999928] [G loss: 1.000062]\n",
      "epoch:15 step:61250[D loss: 0.999993] [G loss: 1.000023]\n",
      "epoch:15 step:61255[D loss: 0.999988] [G loss: 0.999975]\n",
      "epoch:15 step:61260[D loss: 1.000000] [G loss: 1.000063]\n",
      "epoch:15 step:61265[D loss: 1.000028] [G loss: 1.000013]\n",
      "epoch:15 step:61270[D loss: 0.999909] [G loss: 1.000061]\n",
      "epoch:15 step:61275[D loss: 0.999914] [G loss: 1.000125]\n",
      "epoch:15 step:61280[D loss: 0.999981] [G loss: 0.999996]\n",
      "epoch:15 step:61285[D loss: 0.999995] [G loss: 1.000023]\n",
      "epoch:15 step:61290[D loss: 1.000022] [G loss: 0.999904]\n",
      "epoch:15 step:61295[D loss: 1.000000] [G loss: 1.000030]\n",
      "epoch:15 step:61300[D loss: 0.999989] [G loss: 1.000003]\n",
      "epoch:15 step:61305[D loss: 0.999983] [G loss: 1.000084]\n",
      "epoch:15 step:61310[D loss: 0.999978] [G loss: 1.000027]\n",
      "epoch:15 step:61315[D loss: 1.000070] [G loss: 0.999928]\n",
      "epoch:15 step:61320[D loss: 0.999971] [G loss: 1.000001]\n",
      "epoch:15 step:61325[D loss: 1.000087] [G loss: 0.999952]\n",
      "epoch:15 step:61330[D loss: 1.000074] [G loss: 0.999857]\n",
      "epoch:15 step:61335[D loss: 1.000015] [G loss: 1.000034]\n",
      "epoch:15 step:61340[D loss: 0.999975] [G loss: 1.000129]\n",
      "epoch:15 step:61345[D loss: 0.999922] [G loss: 1.000195]\n",
      "epoch:15 step:61350[D loss: 0.999962] [G loss: 1.000077]\n",
      "epoch:15 step:61355[D loss: 0.999997] [G loss: 1.000079]\n",
      "epoch:15 step:61360[D loss: 0.999915] [G loss: 1.000233]\n",
      "epoch:15 step:61365[D loss: 0.999928] [G loss: 1.000094]\n",
      "epoch:15 step:61370[D loss: 1.000003] [G loss: 1.000023]\n",
      "epoch:15 step:61375[D loss: 0.999972] [G loss: 1.000059]\n",
      "epoch:15 step:61380[D loss: 0.999968] [G loss: 1.000100]\n",
      "epoch:15 step:61385[D loss: 1.000101] [G loss: 0.999913]\n",
      "epoch:15 step:61390[D loss: 0.999980] [G loss: 0.999994]\n",
      "epoch:15 step:61395[D loss: 0.999993] [G loss: 0.999975]\n",
      "epoch:15 step:61400[D loss: 1.000003] [G loss: 1.000005]\n",
      "##############\n",
      "[0.86457397 0.83876079 0.82172913 0.83477015 0.78628559 0.83880198\n",
      " 0.85905611 0.8227513  0.82645337 0.86193292]\n",
      "##########\n",
      "epoch:15 step:61405[D loss: 0.999962] [G loss: 1.000059]\n",
      "epoch:15 step:61410[D loss: 0.999982] [G loss: 1.000042]\n",
      "epoch:15 step:61415[D loss: 1.000024] [G loss: 0.999919]\n",
      "epoch:15 step:61420[D loss: 1.000041] [G loss: 0.999881]\n",
      "epoch:15 step:61425[D loss: 0.999959] [G loss: 1.000018]\n",
      "epoch:15 step:61430[D loss: 0.999904] [G loss: 1.000224]\n",
      "epoch:15 step:61435[D loss: 0.999957] [G loss: 1.000166]\n",
      "epoch:15 step:61440[D loss: 0.999966] [G loss: 1.000077]\n",
      "epoch:15 step:61445[D loss: 0.999953] [G loss: 1.000054]\n",
      "epoch:15 step:61450[D loss: 0.999960] [G loss: 1.000083]\n",
      "epoch:15 step:61455[D loss: 0.999994] [G loss: 1.000023]\n",
      "epoch:15 step:61460[D loss: 0.999923] [G loss: 1.000082]\n",
      "epoch:15 step:61465[D loss: 0.999976] [G loss: 1.000055]\n",
      "epoch:15 step:61470[D loss: 0.999987] [G loss: 1.000059]\n",
      "epoch:15 step:61475[D loss: 0.999967] [G loss: 1.000075]\n",
      "epoch:15 step:61480[D loss: 0.999966] [G loss: 1.000097]\n",
      "epoch:15 step:61485[D loss: 0.999984] [G loss: 1.000060]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:15 step:61490[D loss: 0.999980] [G loss: 1.000032]\n",
      "epoch:15 step:61495[D loss: 1.000081] [G loss: 0.999991]\n",
      "epoch:15 step:61500[D loss: 0.999962] [G loss: 1.000043]\n",
      "epoch:15 step:61505[D loss: 0.999974] [G loss: 1.000043]\n",
      "epoch:15 step:61510[D loss: 0.999972] [G loss: 1.000065]\n",
      "epoch:15 step:61515[D loss: 0.999986] [G loss: 0.999983]\n",
      "epoch:15 step:61520[D loss: 0.999984] [G loss: 1.000025]\n",
      "epoch:15 step:61525[D loss: 0.999980] [G loss: 1.000089]\n",
      "epoch:15 step:61530[D loss: 0.999982] [G loss: 1.000058]\n",
      "epoch:15 step:61535[D loss: 0.999976] [G loss: 1.000040]\n",
      "epoch:15 step:61540[D loss: 0.999993] [G loss: 0.999988]\n",
      "epoch:15 step:61545[D loss: 0.999992] [G loss: 1.000002]\n",
      "epoch:15 step:61550[D loss: 0.999981] [G loss: 1.000223]\n",
      "epoch:15 step:61555[D loss: 0.999990] [G loss: 1.000086]\n",
      "epoch:15 step:61560[D loss: 0.999928] [G loss: 1.000121]\n",
      "epoch:15 step:61565[D loss: 0.999975] [G loss: 0.999976]\n",
      "epoch:15 step:61570[D loss: 0.999985] [G loss: 1.000049]\n",
      "epoch:15 step:61575[D loss: 1.000030] [G loss: 0.999977]\n",
      "epoch:15 step:61580[D loss: 1.000037] [G loss: 1.000018]\n",
      "epoch:15 step:61585[D loss: 0.999995] [G loss: 0.999986]\n",
      "epoch:15 step:61590[D loss: 0.999995] [G loss: 1.000111]\n",
      "epoch:15 step:61595[D loss: 1.000060] [G loss: 1.000059]\n",
      "epoch:15 step:61600[D loss: 1.000039] [G loss: 1.000076]\n",
      "##############\n",
      "[0.86226841 0.88073351 0.82116193 0.83719284 0.81198877 0.81754627\n",
      " 0.86135664 0.8243926  0.81188223 0.83716953]\n",
      "##########\n",
      "epoch:15 step:61605[D loss: 0.999848] [G loss: 1.000301]\n",
      "epoch:15 step:61610[D loss: 1.000019] [G loss: 1.000146]\n",
      "epoch:15 step:61615[D loss: 0.999894] [G loss: 1.000135]\n",
      "epoch:15 step:61620[D loss: 0.999964] [G loss: 1.000067]\n",
      "epoch:15 step:61625[D loss: 1.000040] [G loss: 0.999966]\n",
      "epoch:15 step:61630[D loss: 1.000004] [G loss: 0.999960]\n",
      "epoch:15 step:61635[D loss: 1.000094] [G loss: 0.999744]\n",
      "epoch:15 step:61640[D loss: 0.999975] [G loss: 1.000011]\n",
      "epoch:15 step:61645[D loss: 0.999941] [G loss: 1.000072]\n",
      "epoch:15 step:61650[D loss: 0.999965] [G loss: 1.000064]\n",
      "epoch:15 step:61655[D loss: 0.999985] [G loss: 1.000066]\n",
      "epoch:15 step:61660[D loss: 0.999996] [G loss: 1.000060]\n",
      "epoch:15 step:61665[D loss: 0.999973] [G loss: 1.000052]\n",
      "epoch:15 step:61670[D loss: 0.999960] [G loss: 1.000068]\n",
      "epoch:15 step:61675[D loss: 0.999966] [G loss: 1.000079]\n",
      "epoch:15 step:61680[D loss: 0.999990] [G loss: 1.000072]\n",
      "epoch:15 step:61685[D loss: 0.999933] [G loss: 1.000279]\n",
      "epoch:15 step:61690[D loss: 0.999870] [G loss: 1.000176]\n",
      "epoch:15 step:61695[D loss: 1.000007] [G loss: 1.000112]\n",
      "epoch:15 step:61700[D loss: 0.999957] [G loss: 1.000102]\n",
      "epoch:15 step:61705[D loss: 0.999968] [G loss: 1.000069]\n",
      "epoch:15 step:61710[D loss: 0.999973] [G loss: 1.000071]\n",
      "epoch:15 step:61715[D loss: 1.000055] [G loss: 0.999917]\n",
      "epoch:15 step:61720[D loss: 1.000069] [G loss: 0.999953]\n",
      "epoch:15 step:61725[D loss: 0.999962] [G loss: 1.000070]\n",
      "epoch:15 step:61730[D loss: 0.999916] [G loss: 1.000078]\n",
      "epoch:15 step:61735[D loss: 0.999938] [G loss: 1.000196]\n",
      "epoch:15 step:61740[D loss: 0.999972] [G loss: 1.000045]\n",
      "epoch:15 step:61745[D loss: 0.999996] [G loss: 0.999965]\n",
      "epoch:15 step:61750[D loss: 0.999962] [G loss: 1.000059]\n",
      "epoch:15 step:61755[D loss: 1.000016] [G loss: 0.999932]\n",
      "epoch:15 step:61760[D loss: 0.999938] [G loss: 1.000129]\n",
      "epoch:15 step:61765[D loss: 0.999989] [G loss: 1.000021]\n",
      "epoch:15 step:61770[D loss: 0.999968] [G loss: 1.000068]\n",
      "epoch:15 step:61775[D loss: 0.999972] [G loss: 1.000044]\n",
      "epoch:15 step:61780[D loss: 0.999979] [G loss: 1.000055]\n",
      "epoch:15 step:61785[D loss: 0.999977] [G loss: 1.000071]\n",
      "epoch:15 step:61790[D loss: 1.000001] [G loss: 1.000023]\n",
      "epoch:15 step:61795[D loss: 0.999995] [G loss: 1.000075]\n",
      "epoch:15 step:61800[D loss: 0.999935] [G loss: 1.000128]\n",
      "##############\n",
      "[0.86772612 0.8587586  0.83922609 0.8171114  0.8090755  0.83913706\n",
      " 0.88238999 0.84274749 0.85023181 0.84055118]\n",
      "##########\n",
      "epoch:15 step:61805[D loss: 0.999951] [G loss: 1.000093]\n",
      "epoch:15 step:61810[D loss: 1.000006] [G loss: 1.000043]\n",
      "epoch:15 step:61815[D loss: 0.999997] [G loss: 1.000002]\n",
      "epoch:15 step:61820[D loss: 0.999994] [G loss: 1.000058]\n",
      "epoch:15 step:61825[D loss: 1.000012] [G loss: 1.000000]\n",
      "epoch:15 step:61830[D loss: 0.999949] [G loss: 1.000084]\n",
      "epoch:15 step:61835[D loss: 0.999982] [G loss: 1.000109]\n",
      "epoch:15 step:61840[D loss: 0.999970] [G loss: 1.000100]\n",
      "epoch:15 step:61845[D loss: 1.000044] [G loss: 1.000017]\n",
      "epoch:15 step:61850[D loss: 0.999959] [G loss: 1.000064]\n",
      "epoch:15 step:61855[D loss: 0.999973] [G loss: 1.000049]\n",
      "epoch:15 step:61860[D loss: 1.000075] [G loss: 0.999916]\n",
      "epoch:15 step:61865[D loss: 1.000064] [G loss: 1.000000]\n",
      "epoch:15 step:61870[D loss: 0.999976] [G loss: 1.000082]\n",
      "epoch:15 step:61875[D loss: 0.999897] [G loss: 1.000143]\n",
      "epoch:15 step:61880[D loss: 0.999957] [G loss: 1.000233]\n",
      "epoch:15 step:61885[D loss: 0.999990] [G loss: 0.999997]\n",
      "epoch:15 step:61890[D loss: 0.999960] [G loss: 1.000101]\n",
      "epoch:15 step:61895[D loss: 0.999961] [G loss: 1.000078]\n",
      "epoch:15 step:61900[D loss: 1.000073] [G loss: 0.999900]\n",
      "epoch:15 step:61905[D loss: 1.000071] [G loss: 0.999830]\n",
      "epoch:15 step:61910[D loss: 0.999913] [G loss: 1.000129]\n",
      "epoch:15 step:61915[D loss: 0.999987] [G loss: 0.999990]\n",
      "epoch:15 step:61920[D loss: 0.999998] [G loss: 1.000058]\n",
      "epoch:15 step:61925[D loss: 0.999979] [G loss: 1.000108]\n",
      "epoch:15 step:61930[D loss: 0.999957] [G loss: 1.000090]\n",
      "epoch:15 step:61935[D loss: 1.000032] [G loss: 1.000054]\n",
      "epoch:15 step:61940[D loss: 1.000042] [G loss: 1.000032]\n",
      "epoch:15 step:61945[D loss: 0.999876] [G loss: 1.000196]\n",
      "epoch:15 step:61950[D loss: 0.999967] [G loss: 1.000108]\n",
      "epoch:15 step:61955[D loss: 0.999964] [G loss: 1.000071]\n",
      "epoch:15 step:61960[D loss: 0.999970] [G loss: 1.000049]\n",
      "epoch:15 step:61965[D loss: 1.000000] [G loss: 1.000030]\n",
      "epoch:15 step:61970[D loss: 0.999973] [G loss: 0.999992]\n",
      "epoch:15 step:61975[D loss: 0.999997] [G loss: 1.000036]\n",
      "epoch:15 step:61980[D loss: 0.999992] [G loss: 1.000048]\n",
      "epoch:15 step:61985[D loss: 0.999964] [G loss: 1.000084]\n",
      "epoch:15 step:61990[D loss: 0.999975] [G loss: 1.000078]\n",
      "epoch:15 step:61995[D loss: 0.999975] [G loss: 1.000085]\n",
      "epoch:15 step:62000[D loss: 0.999971] [G loss: 1.000078]\n",
      "##############\n",
      "[0.86969398 0.83956864 0.82691989 0.83271541 0.78422107 0.83285595\n",
      " 0.86685111 0.81265639 0.82355974 0.84004622]\n",
      "##########\n",
      "epoch:15 step:62005[D loss: 1.000005] [G loss: 1.000054]\n",
      "epoch:15 step:62010[D loss: 1.000021] [G loss: 0.999982]\n",
      "epoch:15 step:62015[D loss: 0.999944] [G loss: 1.000088]\n",
      "epoch:15 step:62020[D loss: 1.000050] [G loss: 1.000012]\n",
      "epoch:15 step:62025[D loss: 0.999933] [G loss: 1.000145]\n",
      "epoch:15 step:62030[D loss: 0.999965] [G loss: 1.000059]\n",
      "epoch:15 step:62035[D loss: 0.999970] [G loss: 1.000063]\n",
      "epoch:15 step:62040[D loss: 1.000012] [G loss: 0.999997]\n",
      "epoch:15 step:62045[D loss: 1.000020] [G loss: 0.999977]\n",
      "epoch:15 step:62050[D loss: 1.000133] [G loss: 0.999793]\n",
      "epoch:15 step:62055[D loss: 0.999979] [G loss: 1.000106]\n",
      "epoch:15 step:62060[D loss: 0.999964] [G loss: 1.000138]\n",
      "epoch:15 step:62065[D loss: 0.999951] [G loss: 1.000192]\n",
      "epoch:15 step:62070[D loss: 1.000050] [G loss: 1.000145]\n",
      "epoch:15 step:62075[D loss: 1.000014] [G loss: 1.000086]\n",
      "epoch:15 step:62080[D loss: 1.000046] [G loss: 1.000054]\n",
      "epoch:15 step:62085[D loss: 1.000027] [G loss: 1.000115]\n",
      "epoch:15 step:62090[D loss: 0.999922] [G loss: 1.000254]\n",
      "epoch:15 step:62095[D loss: 0.999959] [G loss: 1.000084]\n",
      "epoch:15 step:62100[D loss: 0.999961] [G loss: 1.000145]\n",
      "epoch:15 step:62105[D loss: 1.000010] [G loss: 1.000058]\n",
      "epoch:15 step:62110[D loss: 1.000153] [G loss: 0.999746]\n",
      "epoch:15 step:62115[D loss: 0.999870] [G loss: 1.000148]\n",
      "epoch:15 step:62120[D loss: 1.000011] [G loss: 0.999916]\n",
      "epoch:15 step:62125[D loss: 0.999886] [G loss: 1.000111]\n",
      "epoch:15 step:62130[D loss: 1.000013] [G loss: 0.999966]\n",
      "epoch:15 step:62135[D loss: 1.000000] [G loss: 1.000084]\n",
      "epoch:15 step:62140[D loss: 0.999875] [G loss: 1.000168]\n",
      "epoch:15 step:62145[D loss: 1.000020] [G loss: 1.000055]\n",
      "epoch:15 step:62150[D loss: 0.999997] [G loss: 1.000023]\n",
      "epoch:15 step:62155[D loss: 0.999977] [G loss: 1.000008]\n",
      "epoch:15 step:62160[D loss: 0.999990] [G loss: 1.000043]\n",
      "epoch:15 step:62165[D loss: 0.999984] [G loss: 1.000052]\n",
      "epoch:15 step:62170[D loss: 0.999973] [G loss: 1.000107]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:15 step:62175[D loss: 0.999943] [G loss: 1.000050]\n",
      "epoch:15 step:62180[D loss: 0.999968] [G loss: 1.000063]\n",
      "epoch:15 step:62185[D loss: 0.999973] [G loss: 1.000103]\n",
      "epoch:15 step:62190[D loss: 0.999973] [G loss: 1.000129]\n",
      "epoch:15 step:62195[D loss: 0.999951] [G loss: 1.000096]\n",
      "epoch:15 step:62200[D loss: 0.999969] [G loss: 1.000078]\n",
      "##############\n",
      "[0.84842526 0.84595271 0.79895268 0.84170207 0.79824057 0.82081769\n",
      " 0.8813101  0.8397274  0.83914557 0.83398106]\n",
      "##########\n",
      "epoch:15 step:62205[D loss: 0.999965] [G loss: 1.000100]\n",
      "epoch:15 step:62210[D loss: 0.999968] [G loss: 1.000072]\n",
      "epoch:15 step:62215[D loss: 0.999978] [G loss: 1.000121]\n",
      "epoch:15 step:62220[D loss: 1.000032] [G loss: 0.999981]\n",
      "epoch:15 step:62225[D loss: 0.999958] [G loss: 1.000093]\n",
      "epoch:15 step:62230[D loss: 1.000001] [G loss: 1.000018]\n",
      "epoch:15 step:62235[D loss: 0.999964] [G loss: 1.000068]\n",
      "epoch:15 step:62240[D loss: 0.999982] [G loss: 1.000065]\n",
      "epoch:15 step:62245[D loss: 0.999984] [G loss: 1.000058]\n",
      "epoch:15 step:62250[D loss: 0.999959] [G loss: 1.000071]\n",
      "epoch:15 step:62255[D loss: 0.999977] [G loss: 1.000025]\n",
      "epoch:15 step:62260[D loss: 0.999983] [G loss: 1.000065]\n",
      "epoch:15 step:62265[D loss: 0.999969] [G loss: 1.000054]\n",
      "epoch:15 step:62270[D loss: 0.999981] [G loss: 1.000060]\n",
      "epoch:15 step:62275[D loss: 0.999985] [G loss: 1.000068]\n",
      "epoch:15 step:62280[D loss: 0.999970] [G loss: 1.000059]\n",
      "epoch:15 step:62285[D loss: 1.000014] [G loss: 1.000006]\n",
      "epoch:15 step:62290[D loss: 0.999976] [G loss: 1.000072]\n",
      "epoch:15 step:62295[D loss: 0.999979] [G loss: 1.000059]\n",
      "epoch:15 step:62300[D loss: 0.999975] [G loss: 1.000062]\n",
      "epoch:15 step:62305[D loss: 0.999968] [G loss: 1.000059]\n",
      "epoch:15 step:62310[D loss: 0.999970] [G loss: 1.000062]\n",
      "epoch:15 step:62315[D loss: 0.999988] [G loss: 1.000040]\n",
      "epoch:15 step:62320[D loss: 0.999981] [G loss: 1.000064]\n",
      "epoch:15 step:62325[D loss: 1.000009] [G loss: 1.000028]\n",
      "epoch:15 step:62330[D loss: 1.000040] [G loss: 0.999994]\n",
      "epoch:15 step:62335[D loss: 0.999966] [G loss: 1.000019]\n",
      "epoch:15 step:62340[D loss: 1.000055] [G loss: 0.999892]\n",
      "epoch:15 step:62345[D loss: 1.000010] [G loss: 1.000055]\n",
      "epoch:15 step:62350[D loss: 0.999907] [G loss: 1.000116]\n",
      "epoch:15 step:62355[D loss: 0.999965] [G loss: 1.000048]\n",
      "epoch:15 step:62360[D loss: 0.999990] [G loss: 1.000056]\n",
      "epoch:15 step:62365[D loss: 0.999969] [G loss: 1.000097]\n",
      "epoch:15 step:62370[D loss: 0.999991] [G loss: 1.000061]\n",
      "epoch:15 step:62375[D loss: 0.999971] [G loss: 1.000092]\n",
      "epoch:15 step:62380[D loss: 0.999945] [G loss: 1.000139]\n",
      "epoch:15 step:62385[D loss: 0.999988] [G loss: 1.000068]\n",
      "epoch:15 step:62390[D loss: 0.999939] [G loss: 1.000104]\n",
      "epoch:15 step:62395[D loss: 0.999959] [G loss: 1.000102]\n",
      "epoch:15 step:62400[D loss: 0.999994] [G loss: 1.000039]\n",
      "##############\n",
      "[0.85067266 0.87109455 0.83023306 0.81072698 0.79621067 0.82146358\n",
      " 0.86838818 0.84536592 0.81340194 0.85335576]\n",
      "##########\n",
      "epoch:15 step:62405[D loss: 0.999977] [G loss: 1.000067]\n",
      "epoch:15 step:62410[D loss: 0.999954] [G loss: 1.000093]\n",
      "epoch:15 step:62415[D loss: 0.999974] [G loss: 1.000103]\n",
      "epoch:15 step:62420[D loss: 0.999961] [G loss: 1.000125]\n",
      "epoch:15 step:62425[D loss: 0.999984] [G loss: 1.000070]\n",
      "epoch:15 step:62430[D loss: 0.999964] [G loss: 1.000093]\n",
      "epoch:15 step:62435[D loss: 0.999996] [G loss: 1.000101]\n",
      "epoch:15 step:62440[D loss: 0.999937] [G loss: 1.000164]\n",
      "epoch:15 step:62445[D loss: 0.999965] [G loss: 1.000199]\n",
      "epoch:15 step:62450[D loss: 0.999940] [G loss: 1.000156]\n",
      "epoch:15 step:62455[D loss: 0.999982] [G loss: 1.000081]\n",
      "epoch:15 step:62460[D loss: 1.000079] [G loss: 0.999943]\n",
      "epoch:15 step:62465[D loss: 0.999954] [G loss: 1.000151]\n",
      "epoch:15 step:62470[D loss: 0.999951] [G loss: 1.000081]\n",
      "epoch:15 step:62475[D loss: 0.999968] [G loss: 1.000076]\n",
      "epoch:15 step:62480[D loss: 0.999985] [G loss: 1.000094]\n",
      "epoch:16 step:62485[D loss: 0.999962] [G loss: 1.000069]\n",
      "epoch:16 step:62490[D loss: 0.999964] [G loss: 1.000050]\n",
      "epoch:16 step:62495[D loss: 0.999980] [G loss: 1.000040]\n",
      "epoch:16 step:62500[D loss: 0.999983] [G loss: 1.000063]\n",
      "epoch:16 step:62505[D loss: 0.999984] [G loss: 1.000079]\n",
      "epoch:16 step:62510[D loss: 0.999951] [G loss: 1.000072]\n",
      "epoch:16 step:62515[D loss: 0.999971] [G loss: 1.000070]\n",
      "epoch:16 step:62520[D loss: 0.999979] [G loss: 1.000049]\n",
      "epoch:16 step:62525[D loss: 0.999982] [G loss: 1.000057]\n",
      "epoch:16 step:62530[D loss: 0.999967] [G loss: 1.000063]\n",
      "epoch:16 step:62535[D loss: 0.999993] [G loss: 1.000048]\n",
      "epoch:16 step:62540[D loss: 0.999968] [G loss: 1.000061]\n",
      "epoch:16 step:62545[D loss: 1.000006] [G loss: 1.000004]\n",
      "epoch:16 step:62550[D loss: 0.999968] [G loss: 1.000064]\n",
      "epoch:16 step:62555[D loss: 0.999991] [G loss: 1.000062]\n",
      "epoch:16 step:62560[D loss: 0.999979] [G loss: 1.000017]\n",
      "epoch:16 step:62565[D loss: 0.999985] [G loss: 1.000078]\n",
      "epoch:16 step:62570[D loss: 0.999997] [G loss: 1.000045]\n",
      "epoch:16 step:62575[D loss: 0.999962] [G loss: 1.000090]\n",
      "epoch:16 step:62580[D loss: 0.999972] [G loss: 1.000123]\n",
      "epoch:16 step:62585[D loss: 0.999979] [G loss: 1.000078]\n",
      "epoch:16 step:62590[D loss: 0.999971] [G loss: 1.000050]\n",
      "epoch:16 step:62595[D loss: 0.999979] [G loss: 1.000032]\n",
      "epoch:16 step:62600[D loss: 1.000115] [G loss: 1.000018]\n",
      "##############\n",
      "[0.84679023 0.85815512 0.83060389 0.82046978 0.79769401 0.82413385\n",
      " 0.90350236 0.83970104 0.81858847 0.83344271]\n",
      "##########\n",
      "epoch:16 step:62605[D loss: 1.000011] [G loss: 0.999975]\n",
      "epoch:16 step:62610[D loss: 1.000037] [G loss: 0.999879]\n",
      "epoch:16 step:62615[D loss: 0.999931] [G loss: 1.000144]\n",
      "epoch:16 step:62620[D loss: 1.000044] [G loss: 1.000004]\n",
      "epoch:16 step:62625[D loss: 0.999993] [G loss: 1.000042]\n",
      "epoch:16 step:62630[D loss: 0.999989] [G loss: 1.000032]\n",
      "epoch:16 step:62635[D loss: 0.999998] [G loss: 1.000008]\n",
      "epoch:16 step:62640[D loss: 1.000032] [G loss: 0.999992]\n",
      "epoch:16 step:62645[D loss: 0.999954] [G loss: 1.000065]\n",
      "epoch:16 step:62650[D loss: 0.999954] [G loss: 1.000108]\n",
      "epoch:16 step:62655[D loss: 0.999945] [G loss: 1.000132]\n",
      "epoch:16 step:62660[D loss: 0.999891] [G loss: 1.000240]\n",
      "epoch:16 step:62665[D loss: 0.999969] [G loss: 1.000130]\n",
      "epoch:16 step:62670[D loss: 0.999925] [G loss: 1.000131]\n",
      "epoch:16 step:62675[D loss: 0.999979] [G loss: 1.000063]\n",
      "epoch:16 step:62680[D loss: 0.999978] [G loss: 1.000092]\n",
      "epoch:16 step:62685[D loss: 0.999970] [G loss: 1.000087]\n",
      "epoch:16 step:62690[D loss: 0.999976] [G loss: 1.000089]\n",
      "epoch:16 step:62695[D loss: 0.999949] [G loss: 1.000107]\n",
      "epoch:16 step:62700[D loss: 0.999948] [G loss: 1.000139]\n",
      "epoch:16 step:62705[D loss: 0.999972] [G loss: 1.000067]\n",
      "epoch:16 step:62710[D loss: 0.999973] [G loss: 1.000107]\n",
      "epoch:16 step:62715[D loss: 0.999949] [G loss: 1.000088]\n",
      "epoch:16 step:62720[D loss: 1.000014] [G loss: 1.000013]\n",
      "epoch:16 step:62725[D loss: 0.999984] [G loss: 1.000033]\n",
      "epoch:16 step:62730[D loss: 0.999965] [G loss: 1.000092]\n",
      "epoch:16 step:62735[D loss: 0.999981] [G loss: 1.000044]\n",
      "epoch:16 step:62740[D loss: 1.000023] [G loss: 0.999918]\n",
      "epoch:16 step:62745[D loss: 0.999969] [G loss: 1.000074]\n",
      "epoch:16 step:62750[D loss: 0.999981] [G loss: 1.000084]\n",
      "epoch:16 step:62755[D loss: 0.999965] [G loss: 1.000075]\n",
      "epoch:16 step:62760[D loss: 0.999999] [G loss: 1.000010]\n",
      "epoch:16 step:62765[D loss: 0.999987] [G loss: 1.000049]\n",
      "epoch:16 step:62770[D loss: 0.999967] [G loss: 1.000091]\n",
      "epoch:16 step:62775[D loss: 0.999963] [G loss: 1.000084]\n",
      "epoch:16 step:62780[D loss: 1.000001] [G loss: 1.000043]\n",
      "epoch:16 step:62785[D loss: 0.999992] [G loss: 1.000037]\n",
      "epoch:16 step:62790[D loss: 0.999948] [G loss: 1.000095]\n",
      "epoch:16 step:62795[D loss: 0.999968] [G loss: 1.000097]\n",
      "epoch:16 step:62800[D loss: 0.999972] [G loss: 1.000065]\n",
      "##############\n",
      "[0.87087393 0.84589107 0.83233959 0.82876134 0.79374365 0.83887716\n",
      " 0.86893896 0.83326254 0.82612342 0.84106092]\n",
      "##########\n",
      "epoch:16 step:62805[D loss: 0.999935] [G loss: 1.000167]\n",
      "epoch:16 step:62810[D loss: 0.999965] [G loss: 1.000094]\n",
      "epoch:16 step:62815[D loss: 0.999976] [G loss: 1.000064]\n",
      "epoch:16 step:62820[D loss: 0.999957] [G loss: 1.000106]\n",
      "epoch:16 step:62825[D loss: 0.999966] [G loss: 1.000107]\n",
      "epoch:16 step:62830[D loss: 0.999969] [G loss: 1.000056]\n",
      "epoch:16 step:62835[D loss: 1.000088] [G loss: 1.000031]\n",
      "epoch:16 step:62840[D loss: 1.000021] [G loss: 1.000087]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:16 step:62845[D loss: 0.999925] [G loss: 1.000211]\n",
      "epoch:16 step:62850[D loss: 0.999995] [G loss: 1.000036]\n",
      "epoch:16 step:62855[D loss: 0.999986] [G loss: 1.000168]\n",
      "epoch:16 step:62860[D loss: 0.999958] [G loss: 1.000111]\n",
      "epoch:16 step:62865[D loss: 0.999965] [G loss: 1.000097]\n",
      "epoch:16 step:62870[D loss: 1.000017] [G loss: 1.000018]\n",
      "epoch:16 step:62875[D loss: 0.999965] [G loss: 1.000089]\n",
      "epoch:16 step:62880[D loss: 0.999956] [G loss: 1.000108]\n",
      "epoch:16 step:62885[D loss: 0.999980] [G loss: 1.000050]\n",
      "epoch:16 step:62890[D loss: 0.999981] [G loss: 1.000057]\n",
      "epoch:16 step:62895[D loss: 0.999969] [G loss: 1.000087]\n",
      "epoch:16 step:62900[D loss: 0.999979] [G loss: 1.000027]\n",
      "epoch:16 step:62905[D loss: 0.999976] [G loss: 1.000057]\n",
      "epoch:16 step:62910[D loss: 0.999959] [G loss: 1.000083]\n",
      "epoch:16 step:62915[D loss: 0.999957] [G loss: 1.000107]\n",
      "epoch:16 step:62920[D loss: 0.999989] [G loss: 1.000054]\n",
      "epoch:16 step:62925[D loss: 0.999958] [G loss: 1.000172]\n",
      "epoch:16 step:62930[D loss: 0.999978] [G loss: 1.000071]\n",
      "epoch:16 step:62935[D loss: 0.999977] [G loss: 1.000013]\n",
      "epoch:16 step:62940[D loss: 0.999970] [G loss: 1.000034]\n",
      "epoch:16 step:62945[D loss: 0.999952] [G loss: 1.000111]\n",
      "epoch:16 step:62950[D loss: 0.999974] [G loss: 1.000053]\n",
      "epoch:16 step:62955[D loss: 0.999967] [G loss: 1.000072]\n",
      "epoch:16 step:62960[D loss: 0.999988] [G loss: 1.000156]\n",
      "epoch:16 step:62965[D loss: 0.999892] [G loss: 1.000178]\n",
      "epoch:16 step:62970[D loss: 1.000001] [G loss: 1.000066]\n",
      "epoch:16 step:62975[D loss: 1.000021] [G loss: 1.000062]\n",
      "epoch:16 step:62980[D loss: 0.999956] [G loss: 1.000091]\n",
      "epoch:16 step:62985[D loss: 0.999975] [G loss: 1.000042]\n",
      "epoch:16 step:62990[D loss: 0.999979] [G loss: 1.000061]\n",
      "epoch:16 step:62995[D loss: 0.999992] [G loss: 1.000040]\n",
      "epoch:16 step:63000[D loss: 1.000100] [G loss: 0.999880]\n",
      "##############\n",
      "[0.85630331 0.86178155 0.82134171 0.83045305 0.81100034 0.82175054\n",
      " 0.8851603  0.82201318 0.79909388 0.84497956]\n",
      "##########\n",
      "epoch:16 step:63005[D loss: 0.999986] [G loss: 1.000088]\n",
      "epoch:16 step:63010[D loss: 0.999898] [G loss: 1.000202]\n",
      "epoch:16 step:63015[D loss: 0.999911] [G loss: 1.000231]\n",
      "epoch:16 step:63020[D loss: 0.999992] [G loss: 1.000076]\n",
      "epoch:16 step:63025[D loss: 0.999992] [G loss: 1.000070]\n",
      "epoch:16 step:63030[D loss: 0.999996] [G loss: 1.000123]\n",
      "epoch:16 step:63035[D loss: 0.999969] [G loss: 1.000107]\n",
      "epoch:16 step:63040[D loss: 0.999963] [G loss: 1.000092]\n",
      "epoch:16 step:63045[D loss: 0.999989] [G loss: 1.000066]\n",
      "epoch:16 step:63050[D loss: 0.999965] [G loss: 1.000082]\n",
      "epoch:16 step:63055[D loss: 0.999991] [G loss: 1.000052]\n",
      "epoch:16 step:63060[D loss: 0.999968] [G loss: 1.000046]\n",
      "epoch:16 step:63065[D loss: 1.000105] [G loss: 0.999895]\n",
      "epoch:16 step:63070[D loss: 0.999998] [G loss: 1.000042]\n",
      "epoch:16 step:63075[D loss: 0.999933] [G loss: 1.000159]\n",
      "epoch:16 step:63080[D loss: 1.000015] [G loss: 1.000098]\n",
      "epoch:16 step:63085[D loss: 0.999973] [G loss: 1.000095]\n",
      "epoch:16 step:63090[D loss: 0.999967] [G loss: 1.000106]\n",
      "epoch:16 step:63095[D loss: 0.999956] [G loss: 1.000091]\n",
      "epoch:16 step:63100[D loss: 0.999970] [G loss: 1.000095]\n",
      "epoch:16 step:63105[D loss: 0.999966] [G loss: 1.000114]\n",
      "epoch:16 step:63110[D loss: 0.999970] [G loss: 1.000087]\n",
      "epoch:16 step:63115[D loss: 0.999972] [G loss: 1.000069]\n",
      "epoch:16 step:63120[D loss: 0.999976] [G loss: 1.000060]\n",
      "epoch:16 step:63125[D loss: 1.000001] [G loss: 1.000028]\n",
      "epoch:16 step:63130[D loss: 0.999976] [G loss: 1.000046]\n",
      "epoch:16 step:63135[D loss: 0.999973] [G loss: 1.000068]\n",
      "epoch:16 step:63140[D loss: 1.000013] [G loss: 1.000023]\n",
      "epoch:16 step:63145[D loss: 1.000067] [G loss: 0.999912]\n",
      "epoch:16 step:63150[D loss: 1.000037] [G loss: 1.000049]\n",
      "epoch:16 step:63155[D loss: 0.999929] [G loss: 1.000149]\n",
      "epoch:16 step:63160[D loss: 0.999990] [G loss: 1.000038]\n",
      "epoch:16 step:63165[D loss: 1.000000] [G loss: 1.000045]\n",
      "epoch:16 step:63170[D loss: 0.999961] [G loss: 1.000040]\n",
      "epoch:16 step:63175[D loss: 1.000086] [G loss: 0.999925]\n",
      "epoch:16 step:63180[D loss: 0.999942] [G loss: 1.000179]\n",
      "epoch:16 step:63185[D loss: 1.000113] [G loss: 0.999899]\n",
      "epoch:16 step:63190[D loss: 0.999993] [G loss: 1.000019]\n",
      "epoch:16 step:63195[D loss: 0.999890] [G loss: 1.000179]\n",
      "epoch:16 step:63200[D loss: 0.999967] [G loss: 1.000137]\n",
      "##############\n",
      "[0.85290831 0.84987362 0.82904159 0.8127494  0.80321526 0.85994304\n",
      " 0.87371027 0.8391002  0.8216858  0.83594318]\n",
      "##########\n",
      "epoch:16 step:63205[D loss: 1.000038] [G loss: 0.999940]\n",
      "epoch:16 step:63210[D loss: 0.999988] [G loss: 0.999981]\n",
      "epoch:16 step:63215[D loss: 0.999948] [G loss: 1.000090]\n",
      "epoch:16 step:63220[D loss: 1.000029] [G loss: 0.999928]\n",
      "epoch:16 step:63225[D loss: 0.999918] [G loss: 1.000150]\n",
      "epoch:16 step:63230[D loss: 0.999964] [G loss: 1.000066]\n",
      "epoch:16 step:63235[D loss: 0.999945] [G loss: 1.000111]\n",
      "epoch:16 step:63240[D loss: 0.999963] [G loss: 1.000153]\n",
      "epoch:16 step:63245[D loss: 0.999962] [G loss: 1.000078]\n",
      "epoch:16 step:63250[D loss: 0.999978] [G loss: 1.000042]\n",
      "epoch:16 step:63255[D loss: 0.999986] [G loss: 1.000024]\n",
      "epoch:16 step:63260[D loss: 0.999983] [G loss: 1.000059]\n",
      "epoch:16 step:63265[D loss: 1.000014] [G loss: 0.999976]\n",
      "epoch:16 step:63270[D loss: 0.999953] [G loss: 1.000062]\n",
      "epoch:16 step:63275[D loss: 1.000041] [G loss: 1.000011]\n",
      "epoch:16 step:63280[D loss: 0.999975] [G loss: 1.000041]\n",
      "epoch:16 step:63285[D loss: 0.999973] [G loss: 1.000052]\n",
      "epoch:16 step:63290[D loss: 0.999976] [G loss: 1.000039]\n",
      "epoch:16 step:63295[D loss: 0.999963] [G loss: 1.000050]\n",
      "epoch:16 step:63300[D loss: 0.999958] [G loss: 1.000078]\n",
      "epoch:16 step:63305[D loss: 0.999981] [G loss: 1.000052]\n",
      "epoch:16 step:63310[D loss: 0.999972] [G loss: 1.000071]\n",
      "epoch:16 step:63315[D loss: 0.999961] [G loss: 1.000083]\n",
      "epoch:16 step:63320[D loss: 0.999987] [G loss: 1.000057]\n",
      "epoch:16 step:63325[D loss: 0.999975] [G loss: 1.000074]\n",
      "epoch:16 step:63330[D loss: 1.000024] [G loss: 1.000018]\n",
      "epoch:16 step:63335[D loss: 1.000011] [G loss: 1.000099]\n",
      "epoch:16 step:63340[D loss: 0.999991] [G loss: 1.000050]\n",
      "epoch:16 step:63345[D loss: 0.999968] [G loss: 1.000050]\n",
      "epoch:16 step:63350[D loss: 1.000014] [G loss: 0.999992]\n",
      "epoch:16 step:63355[D loss: 1.000035] [G loss: 0.999961]\n",
      "epoch:16 step:63360[D loss: 1.000163] [G loss: 0.999905]\n",
      "epoch:16 step:63365[D loss: 0.999944] [G loss: 0.999975]\n",
      "epoch:16 step:63370[D loss: 0.999918] [G loss: 1.000122]\n",
      "epoch:16 step:63375[D loss: 1.000000] [G loss: 1.000205]\n",
      "epoch:16 step:63380[D loss: 1.000100] [G loss: 0.999886]\n",
      "epoch:16 step:63385[D loss: 0.999946] [G loss: 1.000105]\n",
      "epoch:16 step:63390[D loss: 1.000011] [G loss: 1.000021]\n",
      "epoch:16 step:63395[D loss: 1.000159] [G loss: 0.999848]\n",
      "epoch:16 step:63400[D loss: 0.999979] [G loss: 0.999875]\n",
      "##############\n",
      "[0.85247714 0.85126757 0.82059588 0.82295228 0.78794462 0.84013351\n",
      " 0.87391259 0.8365237  0.80818864 0.84417978]\n",
      "##########\n",
      "epoch:16 step:63405[D loss: 1.000092] [G loss: 0.999985]\n",
      "epoch:16 step:63410[D loss: 0.999863] [G loss: 1.000139]\n",
      "epoch:16 step:63415[D loss: 0.999967] [G loss: 1.000054]\n",
      "epoch:16 step:63420[D loss: 0.999944] [G loss: 1.000080]\n",
      "epoch:16 step:63425[D loss: 0.999996] [G loss: 1.000015]\n",
      "epoch:16 step:63430[D loss: 0.999989] [G loss: 1.000104]\n",
      "epoch:16 step:63435[D loss: 0.999896] [G loss: 1.000136]\n",
      "epoch:16 step:63440[D loss: 0.999997] [G loss: 1.000055]\n",
      "epoch:16 step:63445[D loss: 1.000027] [G loss: 0.999988]\n",
      "epoch:16 step:63450[D loss: 0.999985] [G loss: 1.000089]\n",
      "epoch:16 step:63455[D loss: 1.000003] [G loss: 1.000023]\n",
      "epoch:16 step:63460[D loss: 0.999926] [G loss: 1.000163]\n",
      "epoch:16 step:63465[D loss: 1.000071] [G loss: 0.999979]\n",
      "epoch:16 step:63470[D loss: 0.999916] [G loss: 1.000191]\n",
      "epoch:16 step:63475[D loss: 0.999950] [G loss: 1.000100]\n",
      "epoch:16 step:63480[D loss: 1.000003] [G loss: 1.000046]\n",
      "epoch:16 step:63485[D loss: 0.999994] [G loss: 1.000088]\n",
      "epoch:16 step:63490[D loss: 0.999975] [G loss: 1.000092]\n",
      "epoch:16 step:63495[D loss: 0.999978] [G loss: 1.000111]\n",
      "epoch:16 step:63500[D loss: 0.999970] [G loss: 1.000104]\n",
      "epoch:16 step:63505[D loss: 0.999941] [G loss: 1.000131]\n",
      "epoch:16 step:63510[D loss: 0.999984] [G loss: 1.000070]\n",
      "epoch:16 step:63515[D loss: 0.999958] [G loss: 1.000073]\n",
      "epoch:16 step:63520[D loss: 0.999967] [G loss: 1.000065]\n",
      "epoch:16 step:63525[D loss: 0.999959] [G loss: 1.000085]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:16 step:63530[D loss: 0.999955] [G loss: 1.000058]\n",
      "epoch:16 step:63535[D loss: 0.999989] [G loss: 1.000059]\n",
      "epoch:16 step:63540[D loss: 0.999955] [G loss: 1.000085]\n",
      "epoch:16 step:63545[D loss: 0.999971] [G loss: 1.000070]\n",
      "epoch:16 step:63550[D loss: 1.000009] [G loss: 1.000037]\n",
      "epoch:16 step:63555[D loss: 0.999925] [G loss: 1.000078]\n",
      "epoch:16 step:63560[D loss: 0.999959] [G loss: 1.000056]\n",
      "epoch:16 step:63565[D loss: 0.999977] [G loss: 1.000055]\n",
      "epoch:16 step:63570[D loss: 1.000007] [G loss: 1.000007]\n",
      "epoch:16 step:63575[D loss: 0.999988] [G loss: 1.000071]\n",
      "epoch:16 step:63580[D loss: 1.000033] [G loss: 0.999951]\n",
      "epoch:16 step:63585[D loss: 0.999976] [G loss: 1.000060]\n",
      "epoch:16 step:63590[D loss: 0.999991] [G loss: 1.000026]\n",
      "epoch:16 step:63595[D loss: 0.999985] [G loss: 1.000025]\n",
      "epoch:16 step:63600[D loss: 1.000052] [G loss: 0.999952]\n",
      "##############\n",
      "[0.85704175 0.85440973 0.8188956  0.80650471 0.78133723 0.83419361\n",
      " 0.87357457 0.84415156 0.82827901 0.85453651]\n",
      "##########\n",
      "epoch:16 step:63605[D loss: 0.999979] [G loss: 1.000055]\n",
      "epoch:16 step:63610[D loss: 1.000004] [G loss: 1.000074]\n",
      "epoch:16 step:63615[D loss: 0.999984] [G loss: 1.000063]\n",
      "epoch:16 step:63620[D loss: 1.000004] [G loss: 1.000097]\n",
      "epoch:16 step:63625[D loss: 0.999951] [G loss: 1.000065]\n",
      "epoch:16 step:63630[D loss: 1.000013] [G loss: 1.000036]\n",
      "epoch:16 step:63635[D loss: 0.999997] [G loss: 1.000071]\n",
      "epoch:16 step:63640[D loss: 1.000006] [G loss: 1.000046]\n",
      "epoch:16 step:63645[D loss: 0.999931] [G loss: 1.000102]\n",
      "epoch:16 step:63650[D loss: 0.999959] [G loss: 1.000087]\n",
      "epoch:16 step:63655[D loss: 0.999998] [G loss: 1.000089]\n",
      "epoch:16 step:63660[D loss: 1.000004] [G loss: 1.000063]\n",
      "epoch:16 step:63665[D loss: 0.999952] [G loss: 1.000165]\n",
      "epoch:16 step:63670[D loss: 0.999974] [G loss: 1.000053]\n",
      "epoch:16 step:63675[D loss: 1.000022] [G loss: 1.000032]\n",
      "epoch:16 step:63680[D loss: 1.000030] [G loss: 0.999951]\n",
      "epoch:16 step:63685[D loss: 0.999908] [G loss: 1.000160]\n",
      "epoch:16 step:63690[D loss: 1.000001] [G loss: 1.000032]\n",
      "epoch:16 step:63695[D loss: 0.999981] [G loss: 1.000129]\n",
      "epoch:16 step:63700[D loss: 1.000031] [G loss: 1.000095]\n",
      "epoch:16 step:63705[D loss: 0.999954] [G loss: 1.000144]\n",
      "epoch:16 step:63710[D loss: 0.999934] [G loss: 1.000179]\n",
      "epoch:16 step:63715[D loss: 0.999925] [G loss: 1.000221]\n",
      "epoch:16 step:63720[D loss: 0.999975] [G loss: 1.000061]\n",
      "epoch:16 step:63725[D loss: 1.000004] [G loss: 0.999985]\n",
      "epoch:16 step:63730[D loss: 1.000052] [G loss: 1.000028]\n",
      "epoch:16 step:63735[D loss: 0.999983] [G loss: 0.999902]\n",
      "epoch:16 step:63740[D loss: 1.000013] [G loss: 0.999890]\n",
      "epoch:16 step:63745[D loss: 0.999928] [G loss: 1.000117]\n",
      "epoch:16 step:63750[D loss: 0.999945] [G loss: 1.000100]\n",
      "epoch:16 step:63755[D loss: 0.999950] [G loss: 1.000104]\n",
      "epoch:16 step:63760[D loss: 0.999956] [G loss: 1.000094]\n",
      "epoch:16 step:63765[D loss: 0.999978] [G loss: 1.000007]\n",
      "epoch:16 step:63770[D loss: 0.999958] [G loss: 1.000049]\n",
      "epoch:16 step:63775[D loss: 0.999976] [G loss: 1.000054]\n",
      "epoch:16 step:63780[D loss: 0.999981] [G loss: 1.000022]\n",
      "epoch:16 step:63785[D loss: 1.000028] [G loss: 0.999892]\n",
      "epoch:16 step:63790[D loss: 0.999958] [G loss: 1.000098]\n",
      "epoch:16 step:63795[D loss: 0.999921] [G loss: 1.000066]\n",
      "epoch:16 step:63800[D loss: 0.999969] [G loss: 1.000024]\n",
      "##############\n",
      "[0.84075743 0.86804398 0.83320468 0.8393273  0.79985959 0.83894168\n",
      " 0.88850884 0.82941306 0.79446078 0.84651076]\n",
      "##########\n",
      "epoch:16 step:63805[D loss: 0.999964] [G loss: 1.000015]\n",
      "epoch:16 step:63810[D loss: 0.999992] [G loss: 1.000019]\n",
      "epoch:16 step:63815[D loss: 0.999991] [G loss: 1.000018]\n",
      "epoch:16 step:63820[D loss: 1.000047] [G loss: 0.999902]\n",
      "epoch:16 step:63825[D loss: 0.999962] [G loss: 0.999999]\n",
      "epoch:16 step:63830[D loss: 0.999980] [G loss: 1.000009]\n",
      "epoch:16 step:63835[D loss: 0.999985] [G loss: 1.000030]\n",
      "epoch:16 step:63840[D loss: 0.999966] [G loss: 1.000051]\n",
      "epoch:16 step:63845[D loss: 0.999975] [G loss: 1.000154]\n",
      "epoch:16 step:63850[D loss: 0.999906] [G loss: 1.000189]\n",
      "epoch:16 step:63855[D loss: 0.999963] [G loss: 1.000023]\n",
      "epoch:16 step:63860[D loss: 1.000046] [G loss: 0.999937]\n",
      "epoch:16 step:63865[D loss: 0.999962] [G loss: 0.999988]\n",
      "epoch:16 step:63870[D loss: 0.999982] [G loss: 1.000016]\n",
      "epoch:16 step:63875[D loss: 1.000026] [G loss: 0.999899]\n",
      "epoch:16 step:63880[D loss: 1.000006] [G loss: 0.999967]\n",
      "epoch:16 step:63885[D loss: 1.000034] [G loss: 0.999924]\n",
      "epoch:16 step:63890[D loss: 0.999996] [G loss: 1.000032]\n",
      "epoch:16 step:63895[D loss: 0.999956] [G loss: 1.000104]\n",
      "epoch:16 step:63900[D loss: 0.999961] [G loss: 1.000057]\n",
      "epoch:16 step:63905[D loss: 1.000037] [G loss: 0.999935]\n",
      "epoch:16 step:63910[D loss: 0.999978] [G loss: 1.000036]\n",
      "epoch:16 step:63915[D loss: 0.999966] [G loss: 1.000023]\n",
      "epoch:16 step:63920[D loss: 0.999974] [G loss: 1.000033]\n",
      "epoch:16 step:63925[D loss: 0.999960] [G loss: 1.000074]\n",
      "epoch:16 step:63930[D loss: 0.999988] [G loss: 1.000041]\n",
      "epoch:16 step:63935[D loss: 0.999977] [G loss: 1.000055]\n",
      "epoch:16 step:63940[D loss: 0.999981] [G loss: 1.000019]\n",
      "epoch:16 step:63945[D loss: 0.999955] [G loss: 1.000116]\n",
      "epoch:16 step:63950[D loss: 0.999978] [G loss: 1.000072]\n",
      "epoch:16 step:63955[D loss: 0.999953] [G loss: 1.000099]\n",
      "epoch:16 step:63960[D loss: 0.999990] [G loss: 1.000032]\n",
      "epoch:16 step:63965[D loss: 0.999991] [G loss: 1.000022]\n",
      "epoch:16 step:63970[D loss: 1.000013] [G loss: 1.000048]\n",
      "epoch:16 step:63975[D loss: 0.999955] [G loss: 1.000112]\n",
      "epoch:16 step:63980[D loss: 0.999979] [G loss: 1.000064]\n",
      "epoch:16 step:63985[D loss: 0.999959] [G loss: 1.000088]\n",
      "epoch:16 step:63990[D loss: 0.999978] [G loss: 1.000071]\n",
      "epoch:16 step:63995[D loss: 0.999974] [G loss: 1.000072]\n",
      "epoch:16 step:64000[D loss: 0.999968] [G loss: 1.000082]\n",
      "##############\n",
      "[0.85738475 0.85538685 0.8201222  0.81668006 0.79442278 0.8374232\n",
      " 0.87912911 0.85674985 0.8321071  0.83070608]\n",
      "##########\n",
      "epoch:16 step:64005[D loss: 0.999973] [G loss: 1.000086]\n",
      "epoch:16 step:64010[D loss: 0.999974] [G loss: 1.000055]\n",
      "epoch:16 step:64015[D loss: 0.999981] [G loss: 1.000045]\n",
      "epoch:16 step:64020[D loss: 0.999955] [G loss: 1.000126]\n",
      "epoch:16 step:64025[D loss: 0.999982] [G loss: 1.000065]\n",
      "epoch:16 step:64030[D loss: 1.000019] [G loss: 1.000057]\n",
      "epoch:16 step:64035[D loss: 0.999964] [G loss: 1.000095]\n",
      "epoch:16 step:64040[D loss: 0.999875] [G loss: 1.000183]\n",
      "epoch:16 step:64045[D loss: 0.999982] [G loss: 1.000027]\n",
      "epoch:16 step:64050[D loss: 1.000024] [G loss: 0.999971]\n",
      "epoch:16 step:64055[D loss: 1.000084] [G loss: 1.000052]\n",
      "epoch:16 step:64060[D loss: 0.999948] [G loss: 1.000156]\n",
      "epoch:16 step:64065[D loss: 0.999974] [G loss: 1.000010]\n",
      "epoch:16 step:64070[D loss: 1.000012] [G loss: 1.000020]\n",
      "epoch:16 step:64075[D loss: 0.999992] [G loss: 1.000066]\n",
      "epoch:16 step:64080[D loss: 0.999912] [G loss: 1.000195]\n",
      "epoch:16 step:64085[D loss: 0.999966] [G loss: 1.000060]\n",
      "epoch:16 step:64090[D loss: 0.999978] [G loss: 1.000040]\n",
      "epoch:16 step:64095[D loss: 1.000016] [G loss: 1.000020]\n",
      "epoch:16 step:64100[D loss: 0.999986] [G loss: 1.000055]\n",
      "epoch:16 step:64105[D loss: 1.000047] [G loss: 0.999945]\n",
      "epoch:16 step:64110[D loss: 1.000061] [G loss: 0.999768]\n",
      "epoch:16 step:64115[D loss: 0.999938] [G loss: 1.000192]\n",
      "epoch:16 step:64120[D loss: 1.000030] [G loss: 1.000028]\n",
      "epoch:16 step:64125[D loss: 0.999929] [G loss: 1.000105]\n",
      "epoch:16 step:64130[D loss: 1.000057] [G loss: 1.000027]\n",
      "epoch:16 step:64135[D loss: 1.000015] [G loss: 1.000150]\n",
      "epoch:16 step:64140[D loss: 0.999941] [G loss: 1.000116]\n",
      "epoch:16 step:64145[D loss: 0.999942] [G loss: 1.000091]\n",
      "epoch:16 step:64150[D loss: 0.999964] [G loss: 0.999993]\n",
      "epoch:16 step:64155[D loss: 1.000007] [G loss: 1.000035]\n",
      "epoch:16 step:64160[D loss: 0.999919] [G loss: 1.000110]\n",
      "epoch:16 step:64165[D loss: 0.999943] [G loss: 1.000079]\n",
      "epoch:16 step:64170[D loss: 1.000012] [G loss: 1.000049]\n",
      "epoch:16 step:64175[D loss: 0.999976] [G loss: 1.000115]\n",
      "epoch:16 step:64180[D loss: 0.999946] [G loss: 1.000094]\n",
      "epoch:16 step:64185[D loss: 0.999966] [G loss: 1.000068]\n",
      "epoch:16 step:64190[D loss: 0.999987] [G loss: 1.000072]\n",
      "epoch:16 step:64195[D loss: 0.999989] [G loss: 1.000039]\n",
      "epoch:16 step:64200[D loss: 0.999995] [G loss: 1.000016]\n",
      "##############\n",
      "[0.86364509 0.85341344 0.81811071 0.82854235 0.8003087  0.83297655\n",
      " 0.86479119 0.85554692 0.82400713 0.8318068 ]\n",
      "##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:16 step:64205[D loss: 0.999989] [G loss: 1.000038]\n",
      "epoch:16 step:64210[D loss: 0.999957] [G loss: 1.000087]\n",
      "epoch:16 step:64215[D loss: 0.999942] [G loss: 1.000080]\n",
      "epoch:16 step:64220[D loss: 0.999969] [G loss: 1.000051]\n",
      "epoch:16 step:64225[D loss: 0.999978] [G loss: 1.000050]\n",
      "epoch:16 step:64230[D loss: 1.000005] [G loss: 1.000057]\n",
      "epoch:16 step:64235[D loss: 1.000063] [G loss: 0.999874]\n",
      "epoch:16 step:64240[D loss: 0.999961] [G loss: 1.000050]\n",
      "epoch:16 step:64245[D loss: 0.999977] [G loss: 1.000044]\n",
      "epoch:16 step:64250[D loss: 0.999975] [G loss: 1.000046]\n",
      "epoch:16 step:64255[D loss: 0.999996] [G loss: 1.000009]\n",
      "epoch:16 step:64260[D loss: 0.999966] [G loss: 1.000092]\n",
      "epoch:16 step:64265[D loss: 0.999944] [G loss: 1.000072]\n",
      "epoch:16 step:64270[D loss: 0.999994] [G loss: 1.000007]\n",
      "epoch:16 step:64275[D loss: 0.999977] [G loss: 1.000051]\n",
      "epoch:16 step:64280[D loss: 0.999994] [G loss: 1.000008]\n",
      "epoch:16 step:64285[D loss: 1.000046] [G loss: 0.999898]\n",
      "epoch:16 step:64290[D loss: 1.000015] [G loss: 0.999993]\n",
      "epoch:16 step:64295[D loss: 1.000025] [G loss: 1.000110]\n",
      "epoch:16 step:64300[D loss: 1.000007] [G loss: 0.999966]\n",
      "epoch:16 step:64305[D loss: 0.999962] [G loss: 1.000076]\n",
      "epoch:16 step:64310[D loss: 0.999981] [G loss: 0.999999]\n",
      "epoch:16 step:64315[D loss: 1.000015] [G loss: 0.999999]\n",
      "epoch:16 step:64320[D loss: 1.000007] [G loss: 0.999962]\n",
      "epoch:16 step:64325[D loss: 0.999964] [G loss: 1.000007]\n",
      "epoch:16 step:64330[D loss: 0.999981] [G loss: 1.000058]\n",
      "epoch:16 step:64335[D loss: 0.999962] [G loss: 1.000064]\n",
      "epoch:16 step:64340[D loss: 0.999984] [G loss: 1.000023]\n",
      "epoch:16 step:64345[D loss: 1.000085] [G loss: 0.999940]\n",
      "epoch:16 step:64350[D loss: 0.999953] [G loss: 1.000096]\n",
      "epoch:16 step:64355[D loss: 0.999943] [G loss: 1.000090]\n",
      "epoch:16 step:64360[D loss: 0.999987] [G loss: 1.000032]\n",
      "epoch:16 step:64365[D loss: 1.000014] [G loss: 1.000051]\n",
      "epoch:16 step:64370[D loss: 0.999955] [G loss: 1.000073]\n",
      "epoch:16 step:64375[D loss: 0.999931] [G loss: 1.000120]\n",
      "epoch:16 step:64380[D loss: 0.999998] [G loss: 1.000052]\n",
      "epoch:16 step:64385[D loss: 0.999987] [G loss: 1.000116]\n",
      "epoch:16 step:64390[D loss: 1.000149] [G loss: 0.999959]\n",
      "epoch:16 step:64395[D loss: 1.000167] [G loss: 0.999747]\n",
      "epoch:16 step:64400[D loss: 0.999935] [G loss: 1.000149]\n",
      "##############\n",
      "[0.84411816 0.87467718 0.80428036 0.84895767 0.79472715 0.83496254\n",
      " 0.89625793 0.83517668 0.82982661 0.85147249]\n",
      "##########\n",
      "epoch:16 step:64405[D loss: 0.999912] [G loss: 1.000088]\n",
      "epoch:16 step:64410[D loss: 1.000007] [G loss: 1.000003]\n",
      "epoch:16 step:64415[D loss: 1.000041] [G loss: 0.999928]\n",
      "epoch:16 step:64420[D loss: 1.000031] [G loss: 0.999854]\n",
      "epoch:16 step:64425[D loss: 1.000075] [G loss: 0.999789]\n",
      "epoch:16 step:64430[D loss: 1.000000] [G loss: 1.000030]\n",
      "epoch:16 step:64435[D loss: 1.000225] [G loss: 0.999722]\n",
      "epoch:16 step:64440[D loss: 0.999946] [G loss: 1.000003]\n",
      "epoch:16 step:64445[D loss: 0.999980] [G loss: 1.000082]\n",
      "epoch:16 step:64450[D loss: 1.000002] [G loss: 0.999999]\n",
      "epoch:16 step:64455[D loss: 0.999987] [G loss: 1.000082]\n",
      "epoch:16 step:64460[D loss: 0.999994] [G loss: 1.000042]\n",
      "epoch:16 step:64465[D loss: 1.000000] [G loss: 1.000060]\n",
      "epoch:16 step:64470[D loss: 0.999958] [G loss: 1.000101]\n",
      "epoch:16 step:64475[D loss: 0.999952] [G loss: 1.000116]\n",
      "epoch:16 step:64480[D loss: 0.999973] [G loss: 1.000075]\n",
      "epoch:16 step:64485[D loss: 0.999969] [G loss: 1.000054]\n",
      "epoch:16 step:64490[D loss: 0.999972] [G loss: 1.000070]\n",
      "epoch:16 step:64495[D loss: 0.999970] [G loss: 1.000061]\n",
      "epoch:16 step:64500[D loss: 0.999971] [G loss: 1.000057]\n",
      "epoch:16 step:64505[D loss: 0.999991] [G loss: 1.000010]\n",
      "epoch:16 step:64510[D loss: 1.000008] [G loss: 1.000038]\n",
      "epoch:16 step:64515[D loss: 0.999958] [G loss: 1.000100]\n",
      "epoch:16 step:64520[D loss: 0.999922] [G loss: 1.000135]\n",
      "epoch:16 step:64525[D loss: 0.999950] [G loss: 1.000074]\n",
      "epoch:16 step:64530[D loss: 0.999980] [G loss: 1.000045]\n",
      "epoch:16 step:64535[D loss: 0.999986] [G loss: 1.000036]\n",
      "epoch:16 step:64540[D loss: 0.999998] [G loss: 1.000032]\n",
      "epoch:16 step:64545[D loss: 0.999961] [G loss: 1.000083]\n",
      "epoch:16 step:64550[D loss: 0.999976] [G loss: 1.000059]\n",
      "epoch:16 step:64555[D loss: 0.999986] [G loss: 1.000055]\n",
      "epoch:16 step:64560[D loss: 0.999996] [G loss: 1.000082]\n",
      "epoch:16 step:64565[D loss: 0.999978] [G loss: 1.000085]\n",
      "epoch:16 step:64570[D loss: 0.999964] [G loss: 1.000087]\n",
      "epoch:16 step:64575[D loss: 0.999950] [G loss: 1.000097]\n",
      "epoch:16 step:64580[D loss: 0.999993] [G loss: 1.000076]\n",
      "epoch:16 step:64585[D loss: 0.999988] [G loss: 1.000088]\n",
      "epoch:16 step:64590[D loss: 0.999962] [G loss: 1.000076]\n",
      "epoch:16 step:64595[D loss: 0.999980] [G loss: 1.000042]\n",
      "epoch:16 step:64600[D loss: 0.999991] [G loss: 1.000047]\n",
      "##############\n",
      "[0.85098297 0.85501811 0.83742213 0.82164974 0.80832838 0.81303029\n",
      " 0.88129783 0.82587809 0.82339707 0.85312181]\n",
      "##########\n",
      "epoch:16 step:64605[D loss: 0.999973] [G loss: 1.000073]\n",
      "epoch:16 step:64610[D loss: 0.999964] [G loss: 1.000066]\n",
      "epoch:16 step:64615[D loss: 0.999959] [G loss: 1.000107]\n",
      "epoch:16 step:64620[D loss: 0.999960] [G loss: 1.000093]\n",
      "epoch:16 step:64625[D loss: 0.999978] [G loss: 1.000072]\n",
      "epoch:16 step:64630[D loss: 0.999955] [G loss: 1.000062]\n",
      "epoch:16 step:64635[D loss: 0.999981] [G loss: 1.000028]\n",
      "epoch:16 step:64640[D loss: 0.999997] [G loss: 1.000024]\n",
      "epoch:16 step:64645[D loss: 1.000014] [G loss: 0.999977]\n",
      "epoch:16 step:64650[D loss: 0.999947] [G loss: 1.000105]\n",
      "epoch:16 step:64655[D loss: 0.999997] [G loss: 1.000065]\n",
      "epoch:16 step:64660[D loss: 1.000036] [G loss: 0.999985]\n",
      "epoch:16 step:64665[D loss: 0.999925] [G loss: 1.000145]\n",
      "epoch:16 step:64670[D loss: 0.999970] [G loss: 1.000093]\n",
      "epoch:16 step:64675[D loss: 0.999977] [G loss: 1.000074]\n",
      "epoch:16 step:64680[D loss: 0.999969] [G loss: 1.000059]\n",
      "epoch:16 step:64685[D loss: 0.999959] [G loss: 1.000078]\n",
      "epoch:16 step:64690[D loss: 1.000004] [G loss: 0.999995]\n",
      "epoch:16 step:64695[D loss: 1.000048] [G loss: 0.999972]\n",
      "epoch:16 step:64700[D loss: 0.999917] [G loss: 1.000099]\n",
      "epoch:16 step:64705[D loss: 0.999926] [G loss: 1.000109]\n",
      "epoch:16 step:64710[D loss: 1.000006] [G loss: 1.000002]\n",
      "epoch:16 step:64715[D loss: 0.999989] [G loss: 1.000047]\n",
      "epoch:16 step:64720[D loss: 0.999955] [G loss: 1.000061]\n",
      "epoch:16 step:64725[D loss: 1.000011] [G loss: 1.000003]\n",
      "epoch:16 step:64730[D loss: 0.999954] [G loss: 1.000048]\n",
      "epoch:16 step:64735[D loss: 0.999954] [G loss: 1.000131]\n",
      "epoch:16 step:64740[D loss: 1.000013] [G loss: 1.000040]\n",
      "epoch:16 step:64745[D loss: 1.000060] [G loss: 0.999923]\n",
      "epoch:16 step:64750[D loss: 0.999962] [G loss: 1.000030]\n",
      "epoch:16 step:64755[D loss: 1.000000] [G loss: 1.000044]\n",
      "epoch:16 step:64760[D loss: 0.999939] [G loss: 1.000088]\n",
      "epoch:16 step:64765[D loss: 0.999972] [G loss: 1.000071]\n",
      "epoch:16 step:64770[D loss: 0.999954] [G loss: 1.000080]\n",
      "epoch:16 step:64775[D loss: 1.000064] [G loss: 0.999896]\n",
      "epoch:16 step:64780[D loss: 0.999993] [G loss: 0.999961]\n",
      "epoch:16 step:64785[D loss: 0.999959] [G loss: 1.000062]\n",
      "epoch:16 step:64790[D loss: 0.999992] [G loss: 1.000007]\n",
      "epoch:16 step:64795[D loss: 1.000003] [G loss: 0.999974]\n",
      "epoch:16 step:64800[D loss: 0.999956] [G loss: 1.000072]\n",
      "##############\n",
      "[0.8391093  0.85126364 0.8185086  0.83713326 0.79040785 0.82269366\n",
      " 0.89156373 0.85498001 0.80047226 0.83338862]\n",
      "##########\n",
      "epoch:16 step:64805[D loss: 0.999999] [G loss: 1.000047]\n",
      "epoch:16 step:64810[D loss: 0.999929] [G loss: 1.000129]\n",
      "epoch:16 step:64815[D loss: 0.999982] [G loss: 1.000069]\n",
      "epoch:16 step:64820[D loss: 0.999985] [G loss: 1.000064]\n",
      "epoch:16 step:64825[D loss: 0.999997] [G loss: 1.000039]\n",
      "epoch:16 step:64830[D loss: 0.999989] [G loss: 1.000062]\n",
      "epoch:16 step:64835[D loss: 0.999968] [G loss: 1.000070]\n",
      "epoch:16 step:64840[D loss: 0.999967] [G loss: 1.000064]\n",
      "epoch:16 step:64845[D loss: 0.999952] [G loss: 1.000081]\n",
      "epoch:16 step:64850[D loss: 0.999990] [G loss: 1.000046]\n",
      "epoch:16 step:64855[D loss: 0.999978] [G loss: 1.000047]\n",
      "epoch:16 step:64860[D loss: 0.999979] [G loss: 1.000023]\n",
      "epoch:16 step:64865[D loss: 0.999972] [G loss: 1.000052]\n",
      "epoch:16 step:64870[D loss: 0.999967] [G loss: 1.000049]\n",
      "epoch:16 step:64875[D loss: 0.999971] [G loss: 1.000076]\n",
      "epoch:16 step:64880[D loss: 0.999991] [G loss: 1.000037]\n",
      "epoch:16 step:64885[D loss: 0.999971] [G loss: 1.000035]\n",
      "epoch:16 step:64890[D loss: 1.000009] [G loss: 0.999963]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:16 step:64895[D loss: 0.999981] [G loss: 1.000052]\n",
      "epoch:16 step:64900[D loss: 0.999995] [G loss: 1.000051]\n",
      "epoch:16 step:64905[D loss: 0.999978] [G loss: 1.000027]\n",
      "epoch:16 step:64910[D loss: 0.999962] [G loss: 1.000062]\n",
      "epoch:16 step:64915[D loss: 0.999964] [G loss: 1.000060]\n",
      "epoch:16 step:64920[D loss: 0.999972] [G loss: 1.000048]\n",
      "epoch:16 step:64925[D loss: 0.999963] [G loss: 1.000061]\n",
      "epoch:16 step:64930[D loss: 0.999982] [G loss: 1.000028]\n",
      "epoch:16 step:64935[D loss: 0.999958] [G loss: 1.000068]\n",
      "epoch:16 step:64940[D loss: 0.999989] [G loss: 1.000028]\n",
      "epoch:16 step:64945[D loss: 1.000019] [G loss: 1.000110]\n",
      "epoch:16 step:64950[D loss: 0.999946] [G loss: 1.000082]\n",
      "epoch:16 step:64955[D loss: 0.999966] [G loss: 1.000071]\n",
      "epoch:16 step:64960[D loss: 0.999972] [G loss: 1.000097]\n",
      "epoch:16 step:64965[D loss: 0.999991] [G loss: 1.000048]\n",
      "epoch:16 step:64970[D loss: 0.999976] [G loss: 1.000023]\n",
      "epoch:16 step:64975[D loss: 0.999985] [G loss: 1.000041]\n",
      "epoch:16 step:64980[D loss: 0.999998] [G loss: 1.000065]\n",
      "epoch:16 step:64985[D loss: 0.999969] [G loss: 1.000086]\n",
      "epoch:16 step:64990[D loss: 0.999984] [G loss: 1.000047]\n",
      "epoch:16 step:64995[D loss: 1.000002] [G loss: 0.999998]\n",
      "epoch:16 step:65000[D loss: 0.999978] [G loss: 1.000086]\n",
      "##############\n",
      "[0.84742541 0.85349375 0.850045   0.82221463 0.77667546 0.83906815\n",
      " 0.87542741 0.82091233 0.82539009 0.83796256]\n",
      "##########\n",
      "epoch:16 step:65005[D loss: 0.999968] [G loss: 1.000066]\n",
      "epoch:16 step:65010[D loss: 0.999978] [G loss: 1.000062]\n",
      "epoch:16 step:65015[D loss: 0.999997] [G loss: 1.000027]\n",
      "epoch:16 step:65020[D loss: 0.999989] [G loss: 1.000038]\n",
      "epoch:16 step:65025[D loss: 0.999970] [G loss: 1.000056]\n",
      "epoch:16 step:65030[D loss: 1.000066] [G loss: 0.999886]\n",
      "epoch:16 step:65035[D loss: 1.000020] [G loss: 1.000049]\n",
      "epoch:16 step:65040[D loss: 0.999949] [G loss: 1.000110]\n",
      "epoch:16 step:65045[D loss: 0.999977] [G loss: 1.000052]\n",
      "epoch:16 step:65050[D loss: 0.999964] [G loss: 1.000052]\n",
      "epoch:16 step:65055[D loss: 0.999986] [G loss: 1.000038]\n",
      "epoch:16 step:65060[D loss: 0.999985] [G loss: 1.000019]\n",
      "epoch:16 step:65065[D loss: 0.999989] [G loss: 1.000028]\n",
      "epoch:16 step:65070[D loss: 0.999963] [G loss: 1.000058]\n",
      "epoch:16 step:65075[D loss: 0.999977] [G loss: 1.000051]\n",
      "epoch:16 step:65080[D loss: 1.000007] [G loss: 1.000021]\n",
      "epoch:16 step:65085[D loss: 0.999971] [G loss: 1.000070]\n",
      "epoch:16 step:65090[D loss: 0.999958] [G loss: 1.000070]\n",
      "epoch:16 step:65095[D loss: 0.999964] [G loss: 1.000101]\n",
      "epoch:16 step:65100[D loss: 0.999962] [G loss: 1.000060]\n",
      "epoch:16 step:65105[D loss: 0.999972] [G loss: 1.000069]\n",
      "epoch:16 step:65110[D loss: 0.999968] [G loss: 1.000062]\n",
      "epoch:16 step:65115[D loss: 0.999986] [G loss: 1.000012]\n",
      "epoch:16 step:65120[D loss: 0.999962] [G loss: 1.000072]\n",
      "epoch:16 step:65125[D loss: 1.000001] [G loss: 0.999996]\n",
      "epoch:16 step:65130[D loss: 0.999955] [G loss: 1.000154]\n",
      "epoch:16 step:65135[D loss: 0.999971] [G loss: 1.000056]\n",
      "epoch:16 step:65140[D loss: 0.999948] [G loss: 1.000103]\n",
      "epoch:16 step:65145[D loss: 1.000012] [G loss: 1.000077]\n",
      "epoch:16 step:65150[D loss: 0.999969] [G loss: 1.000030]\n",
      "epoch:16 step:65155[D loss: 1.000039] [G loss: 0.999928]\n",
      "epoch:16 step:65160[D loss: 0.999930] [G loss: 1.000093]\n",
      "epoch:16 step:65165[D loss: 1.000014] [G loss: 1.000016]\n",
      "epoch:16 step:65170[D loss: 1.000057] [G loss: 0.999973]\n",
      "epoch:16 step:65175[D loss: 0.999909] [G loss: 1.000060]\n",
      "epoch:16 step:65180[D loss: 0.999954] [G loss: 1.000049]\n",
      "epoch:16 step:65185[D loss: 1.000027] [G loss: 0.999970]\n",
      "epoch:16 step:65190[D loss: 1.000031] [G loss: 0.999931]\n",
      "epoch:16 step:65195[D loss: 0.999964] [G loss: 1.000039]\n",
      "epoch:16 step:65200[D loss: 0.999976] [G loss: 1.000042]\n",
      "##############\n",
      "[0.84928185 0.84229393 0.81042683 0.81282516 0.78130585 0.83732361\n",
      " 0.9049832  0.82716401 0.82788228 0.84431558]\n",
      "##########\n",
      "epoch:16 step:65205[D loss: 0.999985] [G loss: 1.000031]\n",
      "epoch:16 step:65210[D loss: 1.000050] [G loss: 0.999898]\n",
      "epoch:16 step:65215[D loss: 0.999949] [G loss: 1.000067]\n",
      "epoch:16 step:65220[D loss: 0.999991] [G loss: 1.000056]\n",
      "epoch:16 step:65225[D loss: 0.999988] [G loss: 0.999955]\n",
      "epoch:16 step:65230[D loss: 0.999985] [G loss: 1.000083]\n",
      "epoch:16 step:65235[D loss: 0.999966] [G loss: 1.000094]\n",
      "epoch:16 step:65240[D loss: 1.000015] [G loss: 1.000017]\n",
      "epoch:16 step:65245[D loss: 0.999935] [G loss: 1.000182]\n",
      "epoch:16 step:65250[D loss: 0.999956] [G loss: 1.000076]\n",
      "epoch:16 step:65255[D loss: 1.000020] [G loss: 0.999957]\n",
      "epoch:16 step:65260[D loss: 1.000035] [G loss: 0.999873]\n",
      "epoch:16 step:65265[D loss: 0.999942] [G loss: 1.000037]\n",
      "epoch:16 step:65270[D loss: 0.999972] [G loss: 1.000084]\n",
      "epoch:16 step:65275[D loss: 0.999987] [G loss: 1.000049]\n",
      "epoch:16 step:65280[D loss: 0.999954] [G loss: 1.000037]\n",
      "epoch:16 step:65285[D loss: 0.999991] [G loss: 1.000041]\n",
      "epoch:16 step:65290[D loss: 1.000090] [G loss: 0.999977]\n",
      "epoch:16 step:65295[D loss: 0.999948] [G loss: 1.000054]\n",
      "epoch:16 step:65300[D loss: 0.999959] [G loss: 1.000085]\n",
      "epoch:16 step:65305[D loss: 0.999976] [G loss: 1.000069]\n",
      "epoch:16 step:65310[D loss: 1.000022] [G loss: 0.999994]\n",
      "epoch:16 step:65315[D loss: 1.000046] [G loss: 0.999940]\n",
      "epoch:16 step:65320[D loss: 1.000079] [G loss: 0.999956]\n",
      "epoch:16 step:65325[D loss: 0.999986] [G loss: 1.000078]\n",
      "epoch:16 step:65330[D loss: 1.000006] [G loss: 1.000049]\n",
      "epoch:16 step:65335[D loss: 0.999989] [G loss: 1.000116]\n",
      "epoch:16 step:65340[D loss: 0.999981] [G loss: 1.000066]\n",
      "epoch:16 step:65345[D loss: 0.999941] [G loss: 1.000087]\n",
      "epoch:16 step:65350[D loss: 0.999942] [G loss: 1.000124]\n",
      "epoch:16 step:65355[D loss: 0.999959] [G loss: 1.000077]\n",
      "epoch:16 step:65360[D loss: 1.000027] [G loss: 0.999940]\n",
      "epoch:16 step:65365[D loss: 0.999964] [G loss: 1.000043]\n",
      "epoch:16 step:65370[D loss: 0.999959] [G loss: 1.000107]\n",
      "epoch:16 step:65375[D loss: 0.999996] [G loss: 0.999960]\n",
      "epoch:16 step:65380[D loss: 0.999969] [G loss: 1.000057]\n",
      "epoch:16 step:65385[D loss: 0.999972] [G loss: 1.000056]\n",
      "epoch:16 step:65390[D loss: 0.999975] [G loss: 1.000077]\n",
      "epoch:16 step:65395[D loss: 0.999974] [G loss: 1.000067]\n",
      "epoch:16 step:65400[D loss: 1.000027] [G loss: 1.000079]\n",
      "##############\n",
      "[0.86056226 0.87651432 0.80966595 0.83031178 0.80967738 0.83638318\n",
      " 0.87204613 0.86456109 0.8383119  0.81925819]\n",
      "##########\n",
      "epoch:16 step:65405[D loss: 0.999966] [G loss: 1.000058]\n",
      "epoch:16 step:65410[D loss: 0.999975] [G loss: 1.000051]\n",
      "epoch:16 step:65415[D loss: 1.000022] [G loss: 1.000026]\n",
      "epoch:16 step:65420[D loss: 0.999976] [G loss: 1.000035]\n",
      "epoch:16 step:65425[D loss: 0.999966] [G loss: 1.000075]\n",
      "epoch:16 step:65430[D loss: 0.999978] [G loss: 1.000102]\n",
      "epoch:16 step:65435[D loss: 0.999974] [G loss: 1.000061]\n",
      "epoch:16 step:65440[D loss: 1.000006] [G loss: 1.000015]\n",
      "epoch:16 step:65445[D loss: 0.999974] [G loss: 1.000051]\n",
      "epoch:16 step:65450[D loss: 0.999906] [G loss: 1.000130]\n",
      "epoch:16 step:65455[D loss: 1.000041] [G loss: 1.000016]\n",
      "epoch:16 step:65460[D loss: 0.999999] [G loss: 1.000077]\n",
      "epoch:16 step:65465[D loss: 0.999939] [G loss: 1.000091]\n",
      "epoch:16 step:65470[D loss: 0.999977] [G loss: 1.000052]\n",
      "epoch:16 step:65475[D loss: 0.999993] [G loss: 1.000013]\n",
      "epoch:16 step:65480[D loss: 0.999996] [G loss: 1.000054]\n",
      "epoch:16 step:65485[D loss: 1.000055] [G loss: 1.000009]\n",
      "epoch:16 step:65490[D loss: 0.999937] [G loss: 1.000155]\n",
      "epoch:16 step:65495[D loss: 1.000052] [G loss: 1.000051]\n",
      "epoch:16 step:65500[D loss: 1.000030] [G loss: 1.000142]\n",
      "epoch:16 step:65505[D loss: 1.000032] [G loss: 1.000105]\n",
      "epoch:16 step:65510[D loss: 0.999965] [G loss: 1.000131]\n",
      "epoch:16 step:65515[D loss: 1.000043] [G loss: 1.000073]\n",
      "epoch:16 step:65520[D loss: 0.999950] [G loss: 1.000090]\n",
      "epoch:16 step:65525[D loss: 1.000018] [G loss: 0.999977]\n",
      "epoch:16 step:65530[D loss: 1.000036] [G loss: 0.999993]\n",
      "epoch:16 step:65535[D loss: 1.000036] [G loss: 0.999797]\n",
      "epoch:16 step:65540[D loss: 0.999985] [G loss: 1.000020]\n",
      "epoch:16 step:65545[D loss: 1.000061] [G loss: 0.999836]\n",
      "epoch:16 step:65550[D loss: 0.999950] [G loss: 0.999967]\n",
      "epoch:16 step:65555[D loss: 0.999970] [G loss: 1.000047]\n",
      "epoch:16 step:65560[D loss: 0.999967] [G loss: 1.000071]\n",
      "epoch:16 step:65565[D loss: 0.999975] [G loss: 1.000092]\n",
      "epoch:16 step:65570[D loss: 0.999966] [G loss: 1.000080]\n",
      "epoch:16 step:65575[D loss: 1.000002] [G loss: 1.000031]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:16 step:65580[D loss: 0.999974] [G loss: 1.000048]\n",
      "epoch:16 step:65585[D loss: 0.999984] [G loss: 1.000047]\n",
      "epoch:16 step:65590[D loss: 0.999931] [G loss: 1.000158]\n",
      "epoch:16 step:65595[D loss: 0.999993] [G loss: 1.000035]\n",
      "epoch:16 step:65600[D loss: 1.000006] [G loss: 0.999998]\n",
      "##############\n",
      "[0.85591543 0.87293747 0.83182838 0.81196918 0.82467186 0.83943116\n",
      " 0.87886018 0.83985371 0.83499242 0.84182803]\n",
      "##########\n",
      "epoch:16 step:65605[D loss: 0.999948] [G loss: 1.000068]\n",
      "epoch:16 step:65610[D loss: 0.999997] [G loss: 1.000023]\n",
      "epoch:16 step:65615[D loss: 0.999995] [G loss: 0.999993]\n",
      "epoch:16 step:65620[D loss: 0.999988] [G loss: 1.000092]\n",
      "epoch:16 step:65625[D loss: 1.000093] [G loss: 0.999926]\n",
      "epoch:16 step:65630[D loss: 0.999953] [G loss: 1.000038]\n",
      "epoch:16 step:65635[D loss: 0.999954] [G loss: 1.000046]\n",
      "epoch:16 step:65640[D loss: 0.999971] [G loss: 1.000054]\n",
      "epoch:16 step:65645[D loss: 1.000006] [G loss: 1.000004]\n",
      "epoch:16 step:65650[D loss: 0.999962] [G loss: 1.000105]\n",
      "epoch:16 step:65655[D loss: 0.999943] [G loss: 1.000075]\n",
      "epoch:16 step:65660[D loss: 0.999958] [G loss: 1.000105]\n",
      "epoch:16 step:65665[D loss: 0.999986] [G loss: 1.000033]\n",
      "epoch:16 step:65670[D loss: 0.999982] [G loss: 1.000039]\n",
      "epoch:16 step:65675[D loss: 1.000001] [G loss: 1.000035]\n",
      "epoch:16 step:65680[D loss: 0.999951] [G loss: 1.000076]\n",
      "epoch:16 step:65685[D loss: 0.999959] [G loss: 1.000088]\n",
      "epoch:16 step:65690[D loss: 0.999997] [G loss: 1.000063]\n",
      "epoch:16 step:65695[D loss: 0.999966] [G loss: 1.000101]\n",
      "epoch:16 step:65700[D loss: 0.999964] [G loss: 1.000094]\n",
      "epoch:16 step:65705[D loss: 0.999980] [G loss: 1.000041]\n",
      "epoch:16 step:65710[D loss: 0.999970] [G loss: 1.000055]\n",
      "epoch:16 step:65715[D loss: 0.999981] [G loss: 1.000032]\n",
      "epoch:16 step:65720[D loss: 0.999976] [G loss: 1.000055]\n",
      "epoch:16 step:65725[D loss: 0.999962] [G loss: 1.000100]\n",
      "epoch:16 step:65730[D loss: 0.999991] [G loss: 1.000031]\n",
      "epoch:16 step:65735[D loss: 1.000015] [G loss: 1.000062]\n",
      "epoch:16 step:65740[D loss: 0.999963] [G loss: 1.000092]\n",
      "epoch:16 step:65745[D loss: 0.999992] [G loss: 1.000048]\n",
      "epoch:16 step:65750[D loss: 1.000016] [G loss: 1.000006]\n",
      "epoch:16 step:65755[D loss: 0.999942] [G loss: 1.000097]\n",
      "epoch:16 step:65760[D loss: 0.999973] [G loss: 1.000093]\n",
      "epoch:16 step:65765[D loss: 0.999966] [G loss: 1.000089]\n",
      "epoch:16 step:65770[D loss: 0.999989] [G loss: 0.999998]\n",
      "epoch:16 step:65775[D loss: 0.999996] [G loss: 1.000000]\n",
      "epoch:16 step:65780[D loss: 1.000032] [G loss: 0.999987]\n",
      "epoch:16 step:65785[D loss: 1.000020] [G loss: 1.000008]\n",
      "epoch:16 step:65790[D loss: 0.999960] [G loss: 1.000073]\n",
      "epoch:16 step:65795[D loss: 1.000016] [G loss: 0.999986]\n",
      "epoch:16 step:65800[D loss: 0.999958] [G loss: 1.000068]\n",
      "##############\n",
      "[0.84743932 0.86986331 0.83562309 0.81841123 0.80147259 0.83659787\n",
      " 0.84738979 0.83324856 0.83123544 0.84602284]\n",
      "##########\n",
      "epoch:16 step:65805[D loss: 0.999973] [G loss: 1.000067]\n",
      "epoch:16 step:65810[D loss: 0.999966] [G loss: 1.000060]\n",
      "epoch:16 step:65815[D loss: 0.999978] [G loss: 1.000064]\n",
      "epoch:16 step:65820[D loss: 0.999969] [G loss: 1.000065]\n",
      "epoch:16 step:65825[D loss: 0.999991] [G loss: 0.999987]\n",
      "epoch:16 step:65830[D loss: 0.999953] [G loss: 1.000095]\n",
      "epoch:16 step:65835[D loss: 0.999976] [G loss: 1.000044]\n",
      "epoch:16 step:65840[D loss: 1.000005] [G loss: 1.000046]\n",
      "epoch:16 step:65845[D loss: 0.999968] [G loss: 1.000079]\n",
      "epoch:16 step:65850[D loss: 0.999971] [G loss: 1.000063]\n",
      "epoch:16 step:65855[D loss: 0.999991] [G loss: 1.000036]\n",
      "epoch:16 step:65860[D loss: 0.999994] [G loss: 1.000047]\n",
      "epoch:16 step:65865[D loss: 0.999993] [G loss: 1.000068]\n",
      "epoch:16 step:65870[D loss: 0.999970] [G loss: 1.000082]\n",
      "epoch:16 step:65875[D loss: 0.999999] [G loss: 1.000043]\n",
      "epoch:16 step:65880[D loss: 0.999981] [G loss: 1.000059]\n",
      "epoch:16 step:65885[D loss: 0.999966] [G loss: 1.000101]\n",
      "epoch:16 step:65890[D loss: 0.999933] [G loss: 1.000132]\n",
      "epoch:16 step:65895[D loss: 0.999957] [G loss: 1.000084]\n",
      "epoch:16 step:65900[D loss: 0.999956] [G loss: 1.000097]\n",
      "epoch:16 step:65905[D loss: 0.999976] [G loss: 1.000079]\n",
      "epoch:16 step:65910[D loss: 1.000022] [G loss: 1.000078]\n",
      "epoch:16 step:65915[D loss: 0.999969] [G loss: 1.000074]\n",
      "epoch:16 step:65920[D loss: 0.999991] [G loss: 1.000038]\n",
      "epoch:16 step:65925[D loss: 0.999984] [G loss: 1.000075]\n",
      "epoch:16 step:65930[D loss: 0.999966] [G loss: 1.000072]\n",
      "epoch:16 step:65935[D loss: 0.999993] [G loss: 1.000050]\n",
      "epoch:16 step:65940[D loss: 0.999997] [G loss: 1.000086]\n",
      "epoch:16 step:65945[D loss: 0.999915] [G loss: 1.000204]\n",
      "epoch:16 step:65950[D loss: 0.999980] [G loss: 1.000116]\n",
      "epoch:16 step:65955[D loss: 1.000000] [G loss: 1.000113]\n",
      "epoch:16 step:65960[D loss: 0.999926] [G loss: 1.000173]\n",
      "epoch:16 step:65965[D loss: 0.999968] [G loss: 1.000103]\n",
      "epoch:16 step:65970[D loss: 0.999950] [G loss: 1.000126]\n",
      "epoch:16 step:65975[D loss: 0.999984] [G loss: 1.000097]\n",
      "epoch:16 step:65980[D loss: 0.999963] [G loss: 1.000102]\n",
      "epoch:16 step:65985[D loss: 0.999960] [G loss: 1.000105]\n",
      "epoch:16 step:65990[D loss: 0.999965] [G loss: 1.000105]\n",
      "epoch:16 step:65995[D loss: 0.999949] [G loss: 1.000138]\n",
      "epoch:16 step:66000[D loss: 0.999978] [G loss: 1.000062]\n",
      "##############\n",
      "[0.83705    0.86314886 0.83093701 0.83722064 0.79744291 0.83885642\n",
      " 0.87197328 0.85303181 0.8297847  0.86295105]\n",
      "##########\n",
      "epoch:16 step:66005[D loss: 0.999971] [G loss: 1.000077]\n",
      "epoch:16 step:66010[D loss: 1.000022] [G loss: 1.000019]\n",
      "epoch:16 step:66015[D loss: 1.000074] [G loss: 0.999942]\n",
      "epoch:16 step:66020[D loss: 0.999949] [G loss: 1.000069]\n",
      "epoch:16 step:66025[D loss: 1.000003] [G loss: 0.999995]\n",
      "epoch:16 step:66030[D loss: 0.999984] [G loss: 1.000022]\n",
      "epoch:16 step:66035[D loss: 0.999947] [G loss: 1.000092]\n",
      "epoch:16 step:66040[D loss: 1.000040] [G loss: 1.000014]\n",
      "epoch:16 step:66045[D loss: 0.999998] [G loss: 1.000042]\n",
      "epoch:16 step:66050[D loss: 0.999990] [G loss: 1.000060]\n",
      "epoch:16 step:66055[D loss: 0.999970] [G loss: 1.000049]\n",
      "epoch:16 step:66060[D loss: 0.999987] [G loss: 1.000021]\n",
      "epoch:16 step:66065[D loss: 0.999954] [G loss: 1.000084]\n",
      "epoch:16 step:66070[D loss: 1.000026] [G loss: 0.999976]\n",
      "epoch:16 step:66075[D loss: 0.999957] [G loss: 1.000103]\n",
      "epoch:16 step:66080[D loss: 0.999954] [G loss: 1.000036]\n",
      "epoch:16 step:66085[D loss: 0.999971] [G loss: 1.000058]\n",
      "epoch:16 step:66090[D loss: 0.999990] [G loss: 0.999991]\n",
      "epoch:16 step:66095[D loss: 1.000061] [G loss: 0.999924]\n",
      "epoch:16 step:66100[D loss: 0.999963] [G loss: 1.000030]\n",
      "epoch:16 step:66105[D loss: 1.000020] [G loss: 0.999927]\n",
      "epoch:16 step:66110[D loss: 0.999950] [G loss: 1.000110]\n",
      "epoch:16 step:66115[D loss: 0.999908] [G loss: 1.000088]\n",
      "epoch:16 step:66120[D loss: 1.000051] [G loss: 0.999979]\n",
      "epoch:16 step:66125[D loss: 1.000010] [G loss: 1.000095]\n",
      "epoch:16 step:66130[D loss: 1.000010] [G loss: 0.999990]\n",
      "epoch:16 step:66135[D loss: 0.999873] [G loss: 1.000222]\n",
      "epoch:16 step:66140[D loss: 0.999962] [G loss: 1.000095]\n",
      "epoch:16 step:66145[D loss: 0.999986] [G loss: 1.000089]\n",
      "epoch:16 step:66150[D loss: 0.999980] [G loss: 1.000047]\n",
      "epoch:16 step:66155[D loss: 0.999971] [G loss: 1.000033]\n",
      "epoch:16 step:66160[D loss: 0.999965] [G loss: 1.000099]\n",
      "epoch:16 step:66165[D loss: 0.999977] [G loss: 1.000053]\n",
      "epoch:16 step:66170[D loss: 0.999976] [G loss: 1.000070]\n",
      "epoch:16 step:66175[D loss: 0.999989] [G loss: 1.000057]\n",
      "epoch:16 step:66180[D loss: 0.999978] [G loss: 1.000046]\n",
      "epoch:16 step:66185[D loss: 0.999965] [G loss: 1.000065]\n",
      "epoch:16 step:66190[D loss: 0.999965] [G loss: 1.000093]\n",
      "epoch:16 step:66195[D loss: 0.999941] [G loss: 1.000091]\n",
      "epoch:16 step:66200[D loss: 1.000008] [G loss: 1.000012]\n",
      "##############\n",
      "[0.83679566 0.86666289 0.83529009 0.81306949 0.79833311 0.83767448\n",
      " 0.88509655 0.83378103 0.80356319 0.84101438]\n",
      "##########\n",
      "epoch:16 step:66205[D loss: 0.999982] [G loss: 1.000051]\n",
      "epoch:16 step:66210[D loss: 0.999982] [G loss: 1.000046]\n",
      "epoch:16 step:66215[D loss: 1.000002] [G loss: 1.000025]\n",
      "epoch:16 step:66220[D loss: 0.999987] [G loss: 1.000058]\n",
      "epoch:16 step:66225[D loss: 0.999942] [G loss: 1.000116]\n",
      "epoch:16 step:66230[D loss: 0.999995] [G loss: 1.000018]\n",
      "epoch:16 step:66235[D loss: 1.000082] [G loss: 0.999858]\n",
      "epoch:16 step:66240[D loss: 0.999955] [G loss: 1.000065]\n",
      "epoch:16 step:66245[D loss: 1.000039] [G loss: 0.999933]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:16 step:66250[D loss: 1.000021] [G loss: 1.000041]\n",
      "epoch:16 step:66255[D loss: 0.999878] [G loss: 1.000149]\n",
      "epoch:16 step:66260[D loss: 0.999919] [G loss: 1.000097]\n",
      "epoch:16 step:66265[D loss: 0.999982] [G loss: 1.000075]\n",
      "epoch:16 step:66270[D loss: 0.999977] [G loss: 1.000101]\n",
      "epoch:16 step:66275[D loss: 1.000031] [G loss: 1.000011]\n",
      "epoch:16 step:66280[D loss: 1.000024] [G loss: 1.000021]\n",
      "epoch:16 step:66285[D loss: 1.000022] [G loss: 0.999991]\n",
      "epoch:16 step:66290[D loss: 1.000004] [G loss: 1.000129]\n",
      "epoch:16 step:66295[D loss: 0.999940] [G loss: 1.000115]\n",
      "epoch:16 step:66300[D loss: 0.999939] [G loss: 1.000118]\n",
      "epoch:16 step:66305[D loss: 0.999971] [G loss: 1.000080]\n",
      "epoch:16 step:66310[D loss: 0.999979] [G loss: 1.000046]\n",
      "epoch:16 step:66315[D loss: 0.999981] [G loss: 1.000065]\n",
      "epoch:16 step:66320[D loss: 0.999967] [G loss: 1.000052]\n",
      "epoch:16 step:66325[D loss: 0.999979] [G loss: 1.000082]\n",
      "epoch:16 step:66330[D loss: 0.999996] [G loss: 1.000042]\n",
      "epoch:16 step:66335[D loss: 0.999957] [G loss: 1.000058]\n",
      "epoch:16 step:66340[D loss: 0.999989] [G loss: 1.000055]\n",
      "epoch:16 step:66345[D loss: 0.999978] [G loss: 1.000062]\n",
      "epoch:16 step:66350[D loss: 0.999928] [G loss: 1.000248]\n",
      "epoch:16 step:66355[D loss: 0.999908] [G loss: 1.000203]\n",
      "epoch:16 step:66360[D loss: 0.999955] [G loss: 1.000141]\n",
      "epoch:16 step:66365[D loss: 1.000087] [G loss: 0.999862]\n",
      "epoch:16 step:66370[D loss: 1.000019] [G loss: 0.999937]\n",
      "epoch:16 step:66375[D loss: 0.999912] [G loss: 1.000081]\n",
      "epoch:16 step:66380[D loss: 1.000007] [G loss: 0.999987]\n",
      "epoch:16 step:66385[D loss: 0.999994] [G loss: 1.000076]\n",
      "epoch:17 step:66390[D loss: 0.999996] [G loss: 1.000005]\n",
      "epoch:17 step:66395[D loss: 0.999974] [G loss: 1.000047]\n",
      "epoch:17 step:66400[D loss: 0.999966] [G loss: 1.000038]\n",
      "##############\n",
      "[0.85312915 0.86426315 0.80455991 0.82456706 0.79757388 0.84067146\n",
      " 0.86175988 0.83280847 0.82087788 0.82920648]\n",
      "##########\n",
      "epoch:17 step:66405[D loss: 0.999968] [G loss: 1.000026]\n",
      "epoch:17 step:66410[D loss: 1.000004] [G loss: 1.000054]\n",
      "epoch:17 step:66415[D loss: 0.999954] [G loss: 1.000059]\n",
      "epoch:17 step:66420[D loss: 0.999924] [G loss: 1.000143]\n",
      "epoch:17 step:66425[D loss: 0.999999] [G loss: 0.999982]\n",
      "epoch:17 step:66430[D loss: 0.999977] [G loss: 0.999991]\n",
      "epoch:17 step:66435[D loss: 0.999997] [G loss: 1.000024]\n",
      "epoch:17 step:66440[D loss: 0.999977] [G loss: 1.000113]\n",
      "epoch:17 step:66445[D loss: 0.999922] [G loss: 1.000103]\n",
      "epoch:17 step:66450[D loss: 0.999972] [G loss: 1.000053]\n",
      "epoch:17 step:66455[D loss: 0.999950] [G loss: 1.000095]\n",
      "epoch:17 step:66460[D loss: 1.000070] [G loss: 0.999870]\n",
      "epoch:17 step:66465[D loss: 1.000008] [G loss: 0.999991]\n",
      "epoch:17 step:66470[D loss: 1.000012] [G loss: 1.000098]\n",
      "epoch:17 step:66475[D loss: 1.000115] [G loss: 1.000009]\n",
      "epoch:17 step:66480[D loss: 1.000034] [G loss: 0.999969]\n",
      "epoch:17 step:66485[D loss: 0.999958] [G loss: 1.000299]\n",
      "epoch:17 step:66490[D loss: 0.999958] [G loss: 1.000140]\n",
      "epoch:17 step:66495[D loss: 0.999966] [G loss: 1.000107]\n",
      "epoch:17 step:66500[D loss: 0.999990] [G loss: 1.000077]\n",
      "epoch:17 step:66505[D loss: 1.000086] [G loss: 0.999978]\n",
      "epoch:17 step:66510[D loss: 1.000080] [G loss: 0.999780]\n",
      "epoch:17 step:66515[D loss: 1.000235] [G loss: 0.999457]\n",
      "epoch:17 step:66520[D loss: 0.999967] [G loss: 0.999993]\n",
      "epoch:17 step:66525[D loss: 0.999983] [G loss: 1.000151]\n",
      "epoch:17 step:66530[D loss: 1.000016] [G loss: 0.999959]\n",
      "epoch:17 step:66535[D loss: 1.000004] [G loss: 1.000036]\n",
      "epoch:17 step:66540[D loss: 0.999966] [G loss: 1.000063]\n",
      "epoch:17 step:66545[D loss: 0.999956] [G loss: 1.000047]\n",
      "epoch:17 step:66550[D loss: 0.999980] [G loss: 1.000014]\n",
      "epoch:17 step:66555[D loss: 0.999981] [G loss: 1.000038]\n",
      "epoch:17 step:66560[D loss: 1.000057] [G loss: 0.999898]\n",
      "epoch:17 step:66565[D loss: 1.000041] [G loss: 0.999945]\n",
      "epoch:17 step:66570[D loss: 1.000011] [G loss: 1.000014]\n",
      "epoch:17 step:66575[D loss: 0.999949] [G loss: 1.000065]\n",
      "epoch:17 step:66580[D loss: 0.999909] [G loss: 1.000225]\n",
      "epoch:17 step:66585[D loss: 0.999940] [G loss: 1.000120]\n",
      "epoch:17 step:66590[D loss: 0.999964] [G loss: 1.000106]\n",
      "epoch:17 step:66595[D loss: 1.000063] [G loss: 1.000074]\n",
      "epoch:17 step:66600[D loss: 0.999962] [G loss: 1.000010]\n",
      "##############\n",
      "[0.86478477 0.85342089 0.84525151 0.84727016 0.80679416 0.83226685\n",
      " 0.88357563 0.85473875 0.82415644 0.83757084]\n",
      "##########\n",
      "epoch:17 step:66605[D loss: 0.999982] [G loss: 1.000198]\n",
      "epoch:17 step:66610[D loss: 0.999928] [G loss: 1.000132]\n",
      "epoch:17 step:66615[D loss: 0.999944] [G loss: 1.000173]\n",
      "epoch:17 step:66620[D loss: 0.999934] [G loss: 1.000151]\n",
      "epoch:17 step:66625[D loss: 1.000006] [G loss: 1.000014]\n",
      "epoch:17 step:66630[D loss: 1.000030] [G loss: 0.999945]\n",
      "epoch:17 step:66635[D loss: 1.000009] [G loss: 0.999925]\n",
      "epoch:17 step:66640[D loss: 0.999969] [G loss: 1.000048]\n",
      "epoch:17 step:66645[D loss: 0.999934] [G loss: 1.000121]\n",
      "epoch:17 step:66650[D loss: 1.000019] [G loss: 1.000094]\n",
      "epoch:17 step:66655[D loss: 0.999993] [G loss: 1.000016]\n",
      "epoch:17 step:66660[D loss: 1.000005] [G loss: 1.000066]\n",
      "epoch:17 step:66665[D loss: 1.000013] [G loss: 0.999984]\n",
      "epoch:17 step:66670[D loss: 0.999916] [G loss: 1.000048]\n",
      "epoch:17 step:66675[D loss: 0.999953] [G loss: 1.000110]\n",
      "epoch:17 step:66680[D loss: 0.999978] [G loss: 1.000056]\n",
      "epoch:17 step:66685[D loss: 0.999951] [G loss: 1.000127]\n",
      "epoch:17 step:66690[D loss: 1.000053] [G loss: 0.999925]\n",
      "epoch:17 step:66695[D loss: 0.999951] [G loss: 1.000097]\n",
      "epoch:17 step:66700[D loss: 0.999981] [G loss: 1.000068]\n",
      "epoch:17 step:66705[D loss: 0.999977] [G loss: 1.000068]\n",
      "epoch:17 step:66710[D loss: 0.999959] [G loss: 1.000075]\n",
      "epoch:17 step:66715[D loss: 1.000016] [G loss: 0.999984]\n",
      "epoch:17 step:66720[D loss: 0.999970] [G loss: 1.000070]\n",
      "epoch:17 step:66725[D loss: 0.999985] [G loss: 1.000037]\n",
      "epoch:17 step:66730[D loss: 1.000006] [G loss: 1.000044]\n",
      "epoch:17 step:66735[D loss: 0.999962] [G loss: 1.000105]\n",
      "epoch:17 step:66740[D loss: 1.000126] [G loss: 1.000009]\n",
      "epoch:17 step:66745[D loss: 1.000025] [G loss: 1.000103]\n",
      "epoch:17 step:66750[D loss: 0.999967] [G loss: 1.000193]\n",
      "epoch:17 step:66755[D loss: 0.999926] [G loss: 1.000128]\n",
      "epoch:17 step:66760[D loss: 1.000066] [G loss: 1.000066]\n",
      "epoch:17 step:66765[D loss: 0.999895] [G loss: 1.000192]\n",
      "epoch:17 step:66770[D loss: 0.999951] [G loss: 1.000162]\n",
      "epoch:17 step:66775[D loss: 0.999937] [G loss: 1.000150]\n",
      "epoch:17 step:66780[D loss: 1.000011] [G loss: 1.000029]\n",
      "epoch:17 step:66785[D loss: 0.999997] [G loss: 0.999959]\n",
      "epoch:17 step:66790[D loss: 0.999984] [G loss: 1.000019]\n",
      "epoch:17 step:66795[D loss: 1.000060] [G loss: 0.999929]\n",
      "epoch:17 step:66800[D loss: 0.999898] [G loss: 1.000218]\n",
      "##############\n",
      "[0.87434912 0.83965642 0.84981918 0.82587638 0.80304958 0.81538552\n",
      " 0.85645785 0.85111294 0.81618785 0.84029978]\n",
      "##########\n",
      "epoch:17 step:66805[D loss: 0.999933] [G loss: 1.000104]\n",
      "epoch:17 step:66810[D loss: 0.999960] [G loss: 1.000079]\n",
      "epoch:17 step:66815[D loss: 0.999950] [G loss: 1.000102]\n",
      "epoch:17 step:66820[D loss: 0.999953] [G loss: 1.000083]\n",
      "epoch:17 step:66825[D loss: 0.999987] [G loss: 1.000045]\n",
      "epoch:17 step:66830[D loss: 1.000014] [G loss: 1.000085]\n",
      "epoch:17 step:66835[D loss: 0.999961] [G loss: 1.000044]\n",
      "epoch:17 step:66840[D loss: 0.999984] [G loss: 1.000013]\n",
      "epoch:17 step:66845[D loss: 0.999951] [G loss: 1.000101]\n",
      "epoch:17 step:66850[D loss: 0.999935] [G loss: 1.000125]\n",
      "epoch:17 step:66855[D loss: 0.999970] [G loss: 1.000056]\n",
      "epoch:17 step:66860[D loss: 0.999966] [G loss: 1.000082]\n",
      "epoch:17 step:66865[D loss: 0.999980] [G loss: 1.000142]\n",
      "epoch:17 step:66870[D loss: 1.000001] [G loss: 0.999952]\n",
      "epoch:17 step:66875[D loss: 1.000106] [G loss: 0.999922]\n",
      "epoch:17 step:66880[D loss: 0.999964] [G loss: 1.000183]\n",
      "epoch:17 step:66885[D loss: 0.999941] [G loss: 1.000186]\n",
      "epoch:17 step:66890[D loss: 0.999967] [G loss: 0.999992]\n",
      "epoch:17 step:66895[D loss: 0.999967] [G loss: 1.000218]\n",
      "epoch:17 step:66900[D loss: 0.999884] [G loss: 1.000128]\n",
      "epoch:17 step:66905[D loss: 0.999948] [G loss: 1.000050]\n",
      "epoch:17 step:66910[D loss: 1.000026] [G loss: 0.999969]\n",
      "epoch:17 step:66915[D loss: 0.999971] [G loss: 1.000072]\n",
      "epoch:17 step:66920[D loss: 0.999966] [G loss: 1.000083]\n",
      "epoch:17 step:66925[D loss: 0.999995] [G loss: 1.000080]\n",
      "epoch:17 step:66930[D loss: 0.999947] [G loss: 1.000082]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:17 step:66935[D loss: 1.000064] [G loss: 0.999978]\n",
      "epoch:17 step:66940[D loss: 0.999983] [G loss: 1.000013]\n",
      "epoch:17 step:66945[D loss: 0.999943] [G loss: 1.000119]\n",
      "epoch:17 step:66950[D loss: 0.999969] [G loss: 1.000048]\n",
      "epoch:17 step:66955[D loss: 1.000006] [G loss: 1.000055]\n",
      "epoch:17 step:66960[D loss: 0.999965] [G loss: 1.000041]\n",
      "epoch:17 step:66965[D loss: 0.999968] [G loss: 1.000059]\n",
      "epoch:17 step:66970[D loss: 1.000007] [G loss: 1.000058]\n",
      "epoch:17 step:66975[D loss: 1.000010] [G loss: 1.000008]\n",
      "epoch:17 step:66980[D loss: 0.999999] [G loss: 1.000073]\n",
      "epoch:17 step:66985[D loss: 0.999971] [G loss: 1.000074]\n",
      "epoch:17 step:66990[D loss: 0.999994] [G loss: 1.000083]\n",
      "epoch:17 step:66995[D loss: 1.000004] [G loss: 1.000086]\n",
      "epoch:17 step:67000[D loss: 0.999955] [G loss: 1.000070]\n",
      "##############\n",
      "[0.86530159 0.85292137 0.8337436  0.81320849 0.8142018  0.83441597\n",
      " 0.87047562 0.83000931 0.80746431 0.83623683]\n",
      "##########\n",
      "epoch:17 step:67005[D loss: 0.999962] [G loss: 1.000094]\n",
      "epoch:17 step:67010[D loss: 0.999951] [G loss: 1.000084]\n",
      "epoch:17 step:67015[D loss: 0.999973] [G loss: 1.000082]\n",
      "epoch:17 step:67020[D loss: 0.999978] [G loss: 1.000072]\n",
      "epoch:17 step:67025[D loss: 1.000007] [G loss: 1.000037]\n",
      "epoch:17 step:67030[D loss: 0.999998] [G loss: 1.000001]\n",
      "epoch:17 step:67035[D loss: 0.999977] [G loss: 1.000046]\n",
      "epoch:17 step:67040[D loss: 1.000026] [G loss: 0.999994]\n",
      "epoch:17 step:67045[D loss: 0.999968] [G loss: 1.000037]\n",
      "epoch:17 step:67050[D loss: 0.999985] [G loss: 1.000017]\n",
      "epoch:17 step:67055[D loss: 0.999976] [G loss: 1.000078]\n",
      "epoch:17 step:67060[D loss: 0.999970] [G loss: 1.000023]\n",
      "epoch:17 step:67065[D loss: 1.000032] [G loss: 1.000002]\n",
      "epoch:17 step:67070[D loss: 0.999963] [G loss: 1.000059]\n",
      "epoch:17 step:67075[D loss: 1.000050] [G loss: 0.999993]\n",
      "epoch:17 step:67080[D loss: 0.999932] [G loss: 1.000064]\n",
      "epoch:17 step:67085[D loss: 0.999997] [G loss: 1.000028]\n",
      "epoch:17 step:67090[D loss: 0.999979] [G loss: 1.000103]\n",
      "epoch:17 step:67095[D loss: 0.999982] [G loss: 1.000042]\n",
      "epoch:17 step:67100[D loss: 0.999971] [G loss: 1.000045]\n",
      "epoch:17 step:67105[D loss: 0.999977] [G loss: 1.000186]\n",
      "epoch:17 step:67110[D loss: 0.999929] [G loss: 1.000049]\n",
      "epoch:17 step:67115[D loss: 0.999955] [G loss: 1.000062]\n",
      "epoch:17 step:67120[D loss: 0.999958] [G loss: 1.000092]\n",
      "epoch:17 step:67125[D loss: 0.999973] [G loss: 1.000041]\n",
      "epoch:17 step:67130[D loss: 0.999968] [G loss: 1.000031]\n",
      "epoch:17 step:67135[D loss: 0.999966] [G loss: 1.000067]\n",
      "epoch:17 step:67140[D loss: 1.000006] [G loss: 0.999931]\n",
      "epoch:17 step:67145[D loss: 1.000098] [G loss: 0.999961]\n",
      "epoch:17 step:67150[D loss: 0.999967] [G loss: 1.000063]\n",
      "epoch:17 step:67155[D loss: 0.999955] [G loss: 1.000057]\n",
      "epoch:17 step:67160[D loss: 0.999972] [G loss: 1.000050]\n",
      "epoch:17 step:67165[D loss: 0.999954] [G loss: 1.000090]\n",
      "epoch:17 step:67170[D loss: 0.999970] [G loss: 1.000044]\n",
      "epoch:17 step:67175[D loss: 0.999965] [G loss: 1.000052]\n",
      "epoch:17 step:67180[D loss: 0.999989] [G loss: 1.000039]\n",
      "epoch:17 step:67185[D loss: 0.999987] [G loss: 1.000020]\n",
      "epoch:17 step:67190[D loss: 1.000016] [G loss: 0.999958]\n",
      "epoch:17 step:67195[D loss: 0.999982] [G loss: 1.000044]\n",
      "epoch:17 step:67200[D loss: 0.999992] [G loss: 0.999999]\n",
      "##############\n",
      "[0.8517376  0.85131326 0.82148153 0.84854791 0.77983225 0.86540659\n",
      " 0.8682172  0.84954782 0.80806294 0.82216182]\n",
      "##########\n",
      "epoch:17 step:67205[D loss: 0.999980] [G loss: 1.000064]\n",
      "epoch:17 step:67210[D loss: 0.999913] [G loss: 1.000156]\n",
      "epoch:17 step:67215[D loss: 0.999976] [G loss: 1.000065]\n",
      "epoch:17 step:67220[D loss: 0.999956] [G loss: 1.000125]\n",
      "epoch:17 step:67225[D loss: 0.999959] [G loss: 1.000074]\n",
      "epoch:17 step:67230[D loss: 1.000007] [G loss: 1.000038]\n",
      "epoch:17 step:67235[D loss: 1.000066] [G loss: 0.999965]\n",
      "epoch:17 step:67240[D loss: 1.000072] [G loss: 1.000017]\n",
      "epoch:17 step:67245[D loss: 0.999955] [G loss: 1.000147]\n",
      "epoch:17 step:67250[D loss: 0.999975] [G loss: 1.000053]\n",
      "epoch:17 step:67255[D loss: 0.999984] [G loss: 1.000069]\n",
      "epoch:17 step:67260[D loss: 0.999981] [G loss: 1.000025]\n",
      "epoch:17 step:67265[D loss: 1.000175] [G loss: 0.999946]\n",
      "epoch:17 step:67270[D loss: 0.999999] [G loss: 0.999916]\n",
      "epoch:17 step:67275[D loss: 0.999973] [G loss: 1.000009]\n",
      "epoch:17 step:67280[D loss: 0.999951] [G loss: 1.000253]\n",
      "epoch:17 step:67285[D loss: 1.000058] [G loss: 1.000030]\n",
      "epoch:17 step:67290[D loss: 0.999870] [G loss: 1.000180]\n",
      "epoch:17 step:67295[D loss: 1.000000] [G loss: 1.000061]\n",
      "epoch:17 step:67300[D loss: 1.000191] [G loss: 0.999770]\n",
      "epoch:17 step:67305[D loss: 0.999957] [G loss: 1.000029]\n",
      "epoch:17 step:67310[D loss: 1.000043] [G loss: 0.999966]\n",
      "epoch:17 step:67315[D loss: 0.999888] [G loss: 1.000031]\n",
      "epoch:17 step:67320[D loss: 0.999919] [G loss: 1.000121]\n",
      "epoch:17 step:67325[D loss: 0.999939] [G loss: 1.000074]\n",
      "epoch:17 step:67330[D loss: 0.999970] [G loss: 1.000083]\n",
      "epoch:17 step:67335[D loss: 1.000011] [G loss: 1.000006]\n",
      "epoch:17 step:67340[D loss: 0.999972] [G loss: 1.000045]\n",
      "epoch:17 step:67345[D loss: 1.000030] [G loss: 0.999943]\n",
      "epoch:17 step:67350[D loss: 0.999988] [G loss: 1.000011]\n",
      "epoch:17 step:67355[D loss: 0.999988] [G loss: 1.000040]\n",
      "epoch:17 step:67360[D loss: 1.000033] [G loss: 0.999958]\n",
      "epoch:17 step:67365[D loss: 0.999980] [G loss: 1.000106]\n",
      "epoch:17 step:67370[D loss: 0.999963] [G loss: 1.000066]\n",
      "epoch:17 step:67375[D loss: 0.999988] [G loss: 1.000104]\n",
      "epoch:17 step:67380[D loss: 0.999963] [G loss: 1.000135]\n",
      "epoch:17 step:67385[D loss: 0.999914] [G loss: 1.000157]\n",
      "epoch:17 step:67390[D loss: 1.000019] [G loss: 1.000066]\n",
      "epoch:17 step:67395[D loss: 0.999996] [G loss: 1.000086]\n",
      "epoch:17 step:67400[D loss: 1.000023] [G loss: 1.000054]\n",
      "##############\n",
      "[0.85820536 0.84732144 0.8229535  0.82165911 0.79911039 0.84945775\n",
      " 0.87143084 0.83236068 0.83417999 0.84184294]\n",
      "##########\n",
      "epoch:17 step:67405[D loss: 0.999984] [G loss: 1.000062]\n",
      "epoch:17 step:67410[D loss: 0.999929] [G loss: 1.000106]\n",
      "epoch:17 step:67415[D loss: 0.999912] [G loss: 1.000115]\n",
      "epoch:17 step:67420[D loss: 0.999993] [G loss: 1.000081]\n",
      "epoch:17 step:67425[D loss: 0.999990] [G loss: 1.000061]\n",
      "epoch:17 step:67430[D loss: 0.999957] [G loss: 1.000069]\n",
      "epoch:17 step:67435[D loss: 0.999974] [G loss: 1.000073]\n",
      "epoch:17 step:67440[D loss: 1.000005] [G loss: 1.000003]\n",
      "epoch:17 step:67445[D loss: 0.999976] [G loss: 1.000080]\n",
      "epoch:17 step:67450[D loss: 0.999980] [G loss: 1.000061]\n",
      "epoch:17 step:67455[D loss: 1.000067] [G loss: 0.999965]\n",
      "epoch:17 step:67460[D loss: 0.999948] [G loss: 1.000014]\n",
      "epoch:17 step:67465[D loss: 0.999942] [G loss: 1.000045]\n",
      "epoch:17 step:67470[D loss: 0.999948] [G loss: 1.000080]\n",
      "epoch:17 step:67475[D loss: 1.000000] [G loss: 1.000109]\n",
      "epoch:17 step:67480[D loss: 1.000031] [G loss: 0.999973]\n",
      "epoch:17 step:67485[D loss: 0.999974] [G loss: 1.000048]\n",
      "epoch:17 step:67490[D loss: 0.999965] [G loss: 1.000112]\n",
      "epoch:17 step:67495[D loss: 0.999982] [G loss: 1.000054]\n",
      "epoch:17 step:67500[D loss: 1.000026] [G loss: 0.999914]\n",
      "epoch:17 step:67505[D loss: 1.000051] [G loss: 1.000056]\n",
      "epoch:17 step:67510[D loss: 0.999911] [G loss: 1.000270]\n",
      "epoch:17 step:67515[D loss: 0.999955] [G loss: 1.000175]\n",
      "epoch:17 step:67520[D loss: 0.999977] [G loss: 1.000131]\n",
      "epoch:17 step:67525[D loss: 0.999991] [G loss: 1.000115]\n",
      "epoch:17 step:67530[D loss: 0.999935] [G loss: 1.000117]\n",
      "epoch:17 step:67535[D loss: 1.000002] [G loss: 1.000040]\n",
      "epoch:17 step:67540[D loss: 1.000070] [G loss: 0.999877]\n",
      "epoch:17 step:67545[D loss: 1.000104] [G loss: 0.999827]\n",
      "epoch:17 step:67550[D loss: 1.000030] [G loss: 1.000018]\n",
      "epoch:17 step:67555[D loss: 1.000034] [G loss: 0.999920]\n",
      "epoch:17 step:67560[D loss: 0.999969] [G loss: 1.000077]\n",
      "epoch:17 step:67565[D loss: 0.999966] [G loss: 1.000120]\n",
      "epoch:17 step:67570[D loss: 0.999981] [G loss: 1.000121]\n",
      "epoch:17 step:67575[D loss: 0.999947] [G loss: 1.000139]\n",
      "epoch:17 step:67580[D loss: 0.999968] [G loss: 1.000111]\n",
      "epoch:17 step:67585[D loss: 0.999960] [G loss: 1.000091]\n",
      "epoch:17 step:67590[D loss: 0.999980] [G loss: 1.000059]\n",
      "epoch:17 step:67595[D loss: 0.999966] [G loss: 1.000064]\n",
      "epoch:17 step:67600[D loss: 1.000141] [G loss: 0.999775]\n",
      "##############\n",
      "[0.85726864 0.86895144 0.82582924 0.82396831 0.79995656 0.85431837\n",
      " 0.89965889 0.84336524 0.80363579 0.82829795]\n",
      "##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:17 step:67605[D loss: 0.999985] [G loss: 1.000151]\n",
      "epoch:17 step:67610[D loss: 0.999939] [G loss: 1.000146]\n",
      "epoch:17 step:67615[D loss: 0.999934] [G loss: 1.000227]\n",
      "epoch:17 step:67620[D loss: 1.000039] [G loss: 1.000024]\n",
      "epoch:17 step:67625[D loss: 0.999995] [G loss: 0.999986]\n",
      "epoch:17 step:67630[D loss: 0.999941] [G loss: 1.000126]\n",
      "epoch:17 step:67635[D loss: 1.000103] [G loss: 0.999954]\n",
      "epoch:17 step:67640[D loss: 0.999996] [G loss: 0.999989]\n",
      "epoch:17 step:67645[D loss: 0.999940] [G loss: 1.000059]\n",
      "epoch:17 step:67650[D loss: 1.000012] [G loss: 1.000011]\n",
      "epoch:17 step:67655[D loss: 1.000010] [G loss: 1.000001]\n",
      "epoch:17 step:67660[D loss: 0.999953] [G loss: 1.000074]\n",
      "epoch:17 step:67665[D loss: 0.999921] [G loss: 1.000135]\n",
      "epoch:17 step:67670[D loss: 0.999967] [G loss: 1.000083]\n",
      "epoch:17 step:67675[D loss: 0.999982] [G loss: 1.000039]\n",
      "epoch:17 step:67680[D loss: 1.000004] [G loss: 1.000029]\n",
      "epoch:17 step:67685[D loss: 0.999994] [G loss: 1.000030]\n",
      "epoch:17 step:67690[D loss: 0.999966] [G loss: 1.000046]\n",
      "epoch:17 step:67695[D loss: 1.000011] [G loss: 1.000022]\n",
      "epoch:17 step:67700[D loss: 0.999974] [G loss: 1.000079]\n",
      "epoch:17 step:67705[D loss: 0.999981] [G loss: 1.000025]\n",
      "epoch:17 step:67710[D loss: 0.999980] [G loss: 1.000073]\n",
      "epoch:17 step:67715[D loss: 0.999962] [G loss: 1.000089]\n",
      "epoch:17 step:67720[D loss: 1.000000] [G loss: 1.000059]\n",
      "epoch:17 step:67725[D loss: 0.999987] [G loss: 1.000096]\n",
      "epoch:17 step:67730[D loss: 0.999970] [G loss: 1.000071]\n",
      "epoch:17 step:67735[D loss: 0.999981] [G loss: 1.000036]\n",
      "epoch:17 step:67740[D loss: 0.999962] [G loss: 1.000108]\n",
      "epoch:17 step:67745[D loss: 1.000014] [G loss: 1.000046]\n",
      "epoch:17 step:67750[D loss: 1.000062] [G loss: 1.000053]\n",
      "epoch:17 step:67755[D loss: 1.000008] [G loss: 1.000074]\n",
      "epoch:17 step:67760[D loss: 0.999949] [G loss: 1.000088]\n",
      "epoch:17 step:67765[D loss: 1.000019] [G loss: 1.000083]\n",
      "epoch:17 step:67770[D loss: 0.999968] [G loss: 0.999986]\n",
      "epoch:17 step:67775[D loss: 0.999945] [G loss: 1.000117]\n",
      "epoch:17 step:67780[D loss: 0.999978] [G loss: 1.000073]\n",
      "epoch:17 step:67785[D loss: 0.999941] [G loss: 1.000170]\n",
      "epoch:17 step:67790[D loss: 0.999960] [G loss: 1.000085]\n",
      "epoch:17 step:67795[D loss: 0.999985] [G loss: 1.000076]\n",
      "epoch:17 step:67800[D loss: 0.999972] [G loss: 1.000046]\n",
      "##############\n",
      "[0.86001614 0.84730298 0.79933118 0.82545685 0.79769349 0.83054031\n",
      " 0.87438129 0.82411899 0.82509032 0.8451408 ]\n",
      "##########\n",
      "epoch:17 step:67805[D loss: 0.999981] [G loss: 1.000030]\n",
      "epoch:17 step:67810[D loss: 1.000098] [G loss: 0.999858]\n",
      "epoch:17 step:67815[D loss: 0.999984] [G loss: 1.000074]\n",
      "epoch:17 step:67820[D loss: 1.000003] [G loss: 1.000037]\n",
      "epoch:17 step:67825[D loss: 1.000003] [G loss: 1.000042]\n",
      "epoch:17 step:67830[D loss: 0.999976] [G loss: 1.000074]\n",
      "epoch:17 step:67835[D loss: 0.999964] [G loss: 1.000084]\n",
      "epoch:17 step:67840[D loss: 0.999983] [G loss: 1.000057]\n",
      "epoch:17 step:67845[D loss: 0.999963] [G loss: 1.000073]\n",
      "epoch:17 step:67850[D loss: 0.999991] [G loss: 0.999962]\n",
      "epoch:17 step:67855[D loss: 0.999960] [G loss: 1.000070]\n",
      "epoch:17 step:67860[D loss: 0.999965] [G loss: 1.000122]\n",
      "epoch:17 step:67865[D loss: 0.999984] [G loss: 0.999949]\n",
      "epoch:17 step:67870[D loss: 1.000000] [G loss: 1.000041]\n",
      "epoch:17 step:67875[D loss: 0.999973] [G loss: 1.000039]\n",
      "epoch:17 step:67880[D loss: 0.999972] [G loss: 1.000073]\n",
      "epoch:17 step:67885[D loss: 0.999981] [G loss: 1.000051]\n",
      "epoch:17 step:67890[D loss: 0.999979] [G loss: 1.000044]\n",
      "epoch:17 step:67895[D loss: 1.000002] [G loss: 1.000088]\n",
      "epoch:17 step:67900[D loss: 0.999969] [G loss: 1.000107]\n",
      "epoch:17 step:67905[D loss: 1.000034] [G loss: 1.000028]\n",
      "epoch:17 step:67910[D loss: 0.999966] [G loss: 1.000146]\n",
      "epoch:17 step:67915[D loss: 0.999967] [G loss: 1.000169]\n",
      "epoch:17 step:67920[D loss: 0.999971] [G loss: 1.000105]\n",
      "epoch:17 step:67925[D loss: 1.000091] [G loss: 1.000056]\n",
      "epoch:17 step:67930[D loss: 0.999978] [G loss: 1.000063]\n",
      "epoch:17 step:67935[D loss: 0.999944] [G loss: 1.000382]\n",
      "epoch:17 step:67940[D loss: 0.999975] [G loss: 1.000216]\n",
      "epoch:17 step:67945[D loss: 0.999889] [G loss: 1.000202]\n",
      "epoch:17 step:67950[D loss: 0.999969] [G loss: 1.000096]\n",
      "epoch:17 step:67955[D loss: 1.000007] [G loss: 0.999958]\n",
      "epoch:17 step:67960[D loss: 1.000162] [G loss: 0.999810]\n",
      "epoch:17 step:67965[D loss: 1.000116] [G loss: 0.999723]\n",
      "epoch:17 step:67970[D loss: 1.000020] [G loss: 0.999907]\n",
      "epoch:17 step:67975[D loss: 0.999908] [G loss: 1.000125]\n",
      "epoch:17 step:67980[D loss: 1.000011] [G loss: 1.000014]\n",
      "epoch:17 step:67985[D loss: 1.000088] [G loss: 1.000047]\n",
      "epoch:17 step:67990[D loss: 1.000003] [G loss: 0.999969]\n",
      "epoch:17 step:67995[D loss: 1.000010] [G loss: 0.999960]\n",
      "epoch:17 step:68000[D loss: 0.999923] [G loss: 1.000227]\n",
      "##############\n",
      "[0.84742779 0.83406648 0.85053078 0.8056184  0.80530385 0.8452814\n",
      " 0.869291   0.79992487 0.82754778 0.86652888]\n",
      "##########\n",
      "epoch:17 step:68005[D loss: 1.000029] [G loss: 0.999942]\n",
      "epoch:17 step:68010[D loss: 1.000122] [G loss: 0.999784]\n",
      "epoch:17 step:68015[D loss: 0.999984] [G loss: 1.000051]\n",
      "epoch:17 step:68020[D loss: 1.000095] [G loss: 0.999840]\n",
      "epoch:17 step:68025[D loss: 1.000043] [G loss: 0.999886]\n",
      "epoch:17 step:68030[D loss: 0.999852] [G loss: 1.000125]\n",
      "epoch:17 step:68035[D loss: 1.000028] [G loss: 1.000188]\n",
      "epoch:17 step:68040[D loss: 1.000075] [G loss: 1.000060]\n",
      "epoch:17 step:68045[D loss: 0.999899] [G loss: 1.000200]\n",
      "epoch:17 step:68050[D loss: 0.999989] [G loss: 1.000040]\n",
      "epoch:17 step:68055[D loss: 0.999963] [G loss: 1.000083]\n",
      "epoch:17 step:68060[D loss: 1.000013] [G loss: 1.000014]\n",
      "epoch:17 step:68065[D loss: 0.999943] [G loss: 1.000094]\n",
      "epoch:17 step:68070[D loss: 0.999999] [G loss: 1.000035]\n",
      "epoch:17 step:68075[D loss: 0.999998] [G loss: 1.000109]\n",
      "epoch:17 step:68080[D loss: 1.000060] [G loss: 0.999994]\n",
      "epoch:17 step:68085[D loss: 1.000028] [G loss: 0.999952]\n",
      "epoch:17 step:68090[D loss: 0.999979] [G loss: 1.000045]\n",
      "epoch:17 step:68095[D loss: 0.999981] [G loss: 1.000128]\n",
      "epoch:17 step:68100[D loss: 0.999961] [G loss: 1.000082]\n",
      "epoch:17 step:68105[D loss: 0.999966] [G loss: 1.000113]\n",
      "epoch:17 step:68110[D loss: 0.999966] [G loss: 1.000086]\n",
      "epoch:17 step:68115[D loss: 0.999992] [G loss: 1.000073]\n",
      "epoch:17 step:68120[D loss: 0.999958] [G loss: 1.000079]\n",
      "epoch:17 step:68125[D loss: 0.999982] [G loss: 1.000016]\n",
      "epoch:17 step:68130[D loss: 0.999973] [G loss: 1.000084]\n",
      "epoch:17 step:68135[D loss: 1.000017] [G loss: 1.000019]\n",
      "epoch:17 step:68140[D loss: 1.000088] [G loss: 0.999834]\n",
      "epoch:17 step:68145[D loss: 0.999944] [G loss: 1.000045]\n",
      "epoch:17 step:68150[D loss: 0.999991] [G loss: 0.999986]\n",
      "epoch:17 step:68155[D loss: 0.999920] [G loss: 1.000066]\n",
      "epoch:17 step:68160[D loss: 1.000015] [G loss: 0.999975]\n",
      "epoch:17 step:68165[D loss: 1.000138] [G loss: 0.999859]\n",
      "epoch:17 step:68170[D loss: 0.999926] [G loss: 1.000196]\n",
      "epoch:17 step:68175[D loss: 1.000052] [G loss: 0.999972]\n",
      "epoch:17 step:68180[D loss: 1.000089] [G loss: 0.999846]\n",
      "epoch:17 step:68185[D loss: 0.999961] [G loss: 1.000086]\n",
      "epoch:17 step:68190[D loss: 1.000008] [G loss: 1.000083]\n",
      "epoch:17 step:68195[D loss: 0.999934] [G loss: 1.000135]\n",
      "epoch:17 step:68200[D loss: 1.000131] [G loss: 0.999957]\n",
      "##############\n",
      "[0.84638528 0.85081552 0.81406854 0.84206483 0.81258186 0.84266737\n",
      " 0.86695305 0.82800239 0.81390554 0.84337084]\n",
      "##########\n",
      "epoch:17 step:68205[D loss: 0.999819] [G loss: 1.000308]\n",
      "epoch:17 step:68210[D loss: 0.999943] [G loss: 1.000216]\n",
      "epoch:17 step:68215[D loss: 0.999875] [G loss: 1.000205]\n",
      "epoch:17 step:68220[D loss: 0.999904] [G loss: 1.000137]\n",
      "epoch:17 step:68225[D loss: 0.999994] [G loss: 0.999998]\n",
      "epoch:17 step:68230[D loss: 0.999994] [G loss: 0.999999]\n",
      "epoch:17 step:68235[D loss: 0.999988] [G loss: 1.000068]\n",
      "epoch:17 step:68240[D loss: 0.999996] [G loss: 1.000036]\n",
      "epoch:17 step:68245[D loss: 0.999986] [G loss: 1.000022]\n",
      "epoch:17 step:68250[D loss: 0.999992] [G loss: 1.000019]\n",
      "epoch:17 step:68255[D loss: 1.000050] [G loss: 0.999916]\n",
      "epoch:17 step:68260[D loss: 0.999975] [G loss: 1.000059]\n",
      "epoch:17 step:68265[D loss: 0.999990] [G loss: 1.000087]\n",
      "epoch:17 step:68270[D loss: 0.999974] [G loss: 1.000149]\n",
      "epoch:17 step:68275[D loss: 0.999913] [G loss: 1.000133]\n",
      "epoch:17 step:68280[D loss: 0.999975] [G loss: 1.000100]\n",
      "epoch:17 step:68285[D loss: 0.999997] [G loss: 1.000049]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:17 step:68290[D loss: 1.000039] [G loss: 1.000110]\n",
      "epoch:17 step:68295[D loss: 1.000036] [G loss: 1.000312]\n",
      "epoch:17 step:68300[D loss: 1.000028] [G loss: 1.000070]\n",
      "epoch:17 step:68305[D loss: 0.999834] [G loss: 1.000400]\n",
      "epoch:17 step:68310[D loss: 0.999907] [G loss: 1.000181]\n",
      "epoch:17 step:68315[D loss: 1.000002] [G loss: 1.000048]\n",
      "epoch:17 step:68320[D loss: 1.000029] [G loss: 0.999963]\n",
      "epoch:17 step:68325[D loss: 0.999995] [G loss: 0.999943]\n",
      "epoch:17 step:68330[D loss: 0.999977] [G loss: 1.000039]\n",
      "epoch:17 step:68335[D loss: 1.000011] [G loss: 0.999961]\n",
      "epoch:17 step:68340[D loss: 1.000118] [G loss: 0.999869]\n",
      "epoch:17 step:68345[D loss: 0.999977] [G loss: 0.999894]\n",
      "epoch:17 step:68350[D loss: 0.999969] [G loss: 1.000028]\n",
      "epoch:17 step:68355[D loss: 0.999929] [G loss: 1.000109]\n",
      "epoch:17 step:68360[D loss: 0.999994] [G loss: 1.000037]\n",
      "epoch:17 step:68365[D loss: 1.000035] [G loss: 0.999993]\n",
      "epoch:17 step:68370[D loss: 0.999985] [G loss: 1.000010]\n",
      "epoch:17 step:68375[D loss: 0.999965] [G loss: 1.000062]\n",
      "epoch:17 step:68380[D loss: 0.999971] [G loss: 1.000085]\n",
      "epoch:17 step:68385[D loss: 0.999948] [G loss: 1.000102]\n",
      "epoch:17 step:68390[D loss: 0.999959] [G loss: 1.000073]\n",
      "epoch:17 step:68395[D loss: 0.999977] [G loss: 1.000052]\n",
      "epoch:17 step:68400[D loss: 1.000007] [G loss: 0.999999]\n",
      "##############\n",
      "[0.84857215 0.84850941 0.83145667 0.83950656 0.78572119 0.82816399\n",
      " 0.8847592  0.8301575  0.82030436 0.84810073]\n",
      "##########\n",
      "epoch:17 step:68405[D loss: 0.999981] [G loss: 1.000115]\n",
      "epoch:17 step:68410[D loss: 0.999971] [G loss: 1.000136]\n",
      "epoch:17 step:68415[D loss: 0.999992] [G loss: 1.000097]\n",
      "epoch:17 step:68420[D loss: 1.000080] [G loss: 0.999935]\n",
      "epoch:17 step:68425[D loss: 0.999986] [G loss: 1.000053]\n",
      "epoch:17 step:68430[D loss: 0.999952] [G loss: 1.000072]\n",
      "epoch:17 step:68435[D loss: 0.999968] [G loss: 1.000067]\n",
      "epoch:17 step:68440[D loss: 0.999971] [G loss: 1.000083]\n",
      "epoch:17 step:68445[D loss: 0.999982] [G loss: 1.000052]\n",
      "epoch:17 step:68450[D loss: 0.999987] [G loss: 1.000039]\n",
      "epoch:17 step:68455[D loss: 0.999997] [G loss: 1.000097]\n",
      "epoch:17 step:68460[D loss: 0.999973] [G loss: 1.000103]\n",
      "epoch:17 step:68465[D loss: 1.000085] [G loss: 0.999972]\n",
      "epoch:17 step:68470[D loss: 0.999898] [G loss: 1.000215]\n",
      "epoch:17 step:68475[D loss: 1.000012] [G loss: 0.999929]\n",
      "epoch:17 step:68480[D loss: 0.999941] [G loss: 1.000112]\n",
      "epoch:17 step:68485[D loss: 0.999971] [G loss: 1.000092]\n",
      "epoch:17 step:68490[D loss: 1.000045] [G loss: 1.000012]\n",
      "epoch:17 step:68495[D loss: 0.999951] [G loss: 1.000089]\n",
      "epoch:17 step:68500[D loss: 0.999983] [G loss: 1.000068]\n",
      "epoch:17 step:68505[D loss: 0.999990] [G loss: 1.000115]\n",
      "epoch:17 step:68510[D loss: 0.999939] [G loss: 1.000138]\n",
      "epoch:17 step:68515[D loss: 0.999994] [G loss: 1.000060]\n",
      "epoch:17 step:68520[D loss: 0.999948] [G loss: 1.000132]\n",
      "epoch:17 step:68525[D loss: 0.999985] [G loss: 1.000039]\n",
      "epoch:17 step:68530[D loss: 1.000055] [G loss: 0.999949]\n",
      "epoch:17 step:68535[D loss: 0.999982] [G loss: 1.000029]\n",
      "epoch:17 step:68540[D loss: 0.999986] [G loss: 1.000090]\n",
      "epoch:17 step:68545[D loss: 0.999986] [G loss: 1.000068]\n",
      "epoch:17 step:68550[D loss: 0.999973] [G loss: 1.000045]\n",
      "epoch:17 step:68555[D loss: 0.999918] [G loss: 1.000093]\n",
      "epoch:17 step:68560[D loss: 0.999999] [G loss: 1.000024]\n",
      "epoch:17 step:68565[D loss: 0.999984] [G loss: 1.000059]\n",
      "epoch:17 step:68570[D loss: 0.999983] [G loss: 0.999993]\n",
      "epoch:17 step:68575[D loss: 0.999948] [G loss: 1.000085]\n",
      "epoch:17 step:68580[D loss: 0.999983] [G loss: 1.000023]\n",
      "epoch:17 step:68585[D loss: 0.999965] [G loss: 1.000062]\n",
      "epoch:17 step:68590[D loss: 0.999970] [G loss: 1.000064]\n",
      "epoch:17 step:68595[D loss: 1.000014] [G loss: 1.000004]\n",
      "epoch:17 step:68600[D loss: 0.999946] [G loss: 1.000120]\n",
      "##############\n",
      "[0.86702978 0.85928043 0.829978   0.82225265 0.78047903 0.85341792\n",
      " 0.87815247 0.83916262 0.83049734 0.83079967]\n",
      "##########\n",
      "epoch:17 step:68605[D loss: 0.999971] [G loss: 0.999997]\n",
      "epoch:17 step:68610[D loss: 0.999953] [G loss: 1.000091]\n",
      "epoch:17 step:68615[D loss: 0.999995] [G loss: 1.000042]\n",
      "epoch:17 step:68620[D loss: 0.999968] [G loss: 1.000064]\n",
      "epoch:17 step:68625[D loss: 0.999967] [G loss: 1.000034]\n",
      "epoch:17 step:68630[D loss: 0.999980] [G loss: 1.000057]\n",
      "epoch:17 step:68635[D loss: 1.000042] [G loss: 0.999958]\n",
      "epoch:17 step:68640[D loss: 0.999979] [G loss: 1.000057]\n",
      "epoch:17 step:68645[D loss: 0.999983] [G loss: 1.000036]\n",
      "epoch:17 step:68650[D loss: 0.999988] [G loss: 1.000019]\n",
      "epoch:17 step:68655[D loss: 0.999947] [G loss: 1.000067]\n",
      "epoch:17 step:68660[D loss: 1.000004] [G loss: 1.000050]\n",
      "epoch:17 step:68665[D loss: 0.999981] [G loss: 1.000044]\n",
      "epoch:17 step:68670[D loss: 0.999977] [G loss: 1.000079]\n",
      "epoch:17 step:68675[D loss: 0.999973] [G loss: 1.000078]\n",
      "epoch:17 step:68680[D loss: 0.999975] [G loss: 1.000048]\n",
      "epoch:17 step:68685[D loss: 0.999973] [G loss: 1.000009]\n",
      "epoch:17 step:68690[D loss: 0.999948] [G loss: 1.000038]\n",
      "epoch:17 step:68695[D loss: 0.999961] [G loss: 1.000047]\n",
      "epoch:17 step:68700[D loss: 0.999978] [G loss: 1.000045]\n",
      "epoch:17 step:68705[D loss: 0.999983] [G loss: 1.000058]\n",
      "epoch:17 step:68710[D loss: 0.999966] [G loss: 1.000094]\n",
      "epoch:17 step:68715[D loss: 0.999979] [G loss: 1.000053]\n",
      "epoch:17 step:68720[D loss: 0.999980] [G loss: 1.000056]\n",
      "epoch:17 step:68725[D loss: 0.999969] [G loss: 1.000069]\n",
      "epoch:17 step:68730[D loss: 1.000000] [G loss: 1.000074]\n",
      "epoch:17 step:68735[D loss: 1.000031] [G loss: 0.999965]\n",
      "epoch:17 step:68740[D loss: 1.000008] [G loss: 1.000023]\n",
      "epoch:17 step:68745[D loss: 0.999967] [G loss: 1.000055]\n",
      "epoch:17 step:68750[D loss: 0.999991] [G loss: 1.000030]\n",
      "epoch:17 step:68755[D loss: 0.999955] [G loss: 1.000083]\n",
      "epoch:17 step:68760[D loss: 0.999941] [G loss: 1.000069]\n",
      "epoch:17 step:68765[D loss: 0.999970] [G loss: 1.000073]\n",
      "epoch:17 step:68770[D loss: 0.999956] [G loss: 1.000076]\n",
      "epoch:17 step:68775[D loss: 0.999976] [G loss: 1.000069]\n",
      "epoch:17 step:68780[D loss: 0.999985] [G loss: 1.000046]\n",
      "epoch:17 step:68785[D loss: 0.999974] [G loss: 1.000060]\n",
      "epoch:17 step:68790[D loss: 0.999969] [G loss: 1.000097]\n",
      "epoch:17 step:68795[D loss: 0.999999] [G loss: 1.000008]\n",
      "epoch:17 step:68800[D loss: 0.999977] [G loss: 1.000091]\n",
      "##############\n",
      "[0.84084575 0.8466422  0.83345598 0.8247636  0.81673385 0.83882334\n",
      " 0.86646945 0.84078235 0.81884904 0.82263437]\n",
      "##########\n",
      "epoch:17 step:68805[D loss: 0.999996] [G loss: 1.000031]\n",
      "epoch:17 step:68810[D loss: 0.999988] [G loss: 1.000047]\n",
      "epoch:17 step:68815[D loss: 0.999987] [G loss: 1.000026]\n",
      "epoch:17 step:68820[D loss: 0.999970] [G loss: 1.000051]\n",
      "epoch:17 step:68825[D loss: 0.999968] [G loss: 1.000059]\n",
      "epoch:17 step:68830[D loss: 0.999979] [G loss: 1.000063]\n",
      "epoch:17 step:68835[D loss: 0.999985] [G loss: 1.000026]\n",
      "epoch:17 step:68840[D loss: 0.999974] [G loss: 1.000059]\n",
      "epoch:17 step:68845[D loss: 1.000011] [G loss: 0.999993]\n",
      "epoch:17 step:68850[D loss: 1.000042] [G loss: 1.000056]\n",
      "epoch:17 step:68855[D loss: 0.999946] [G loss: 1.000047]\n",
      "epoch:17 step:68860[D loss: 0.999983] [G loss: 1.000046]\n",
      "epoch:17 step:68865[D loss: 0.999988] [G loss: 1.000049]\n",
      "epoch:17 step:68870[D loss: 0.999977] [G loss: 1.000040]\n",
      "epoch:17 step:68875[D loss: 0.999971] [G loss: 1.000044]\n",
      "epoch:17 step:68880[D loss: 0.999964] [G loss: 1.000069]\n",
      "epoch:17 step:68885[D loss: 1.000037] [G loss: 0.999969]\n",
      "epoch:17 step:68890[D loss: 0.999998] [G loss: 0.999976]\n",
      "epoch:17 step:68895[D loss: 1.000023] [G loss: 0.999914]\n",
      "epoch:17 step:68900[D loss: 0.999867] [G loss: 1.000140]\n",
      "epoch:17 step:68905[D loss: 0.999972] [G loss: 1.000069]\n",
      "epoch:17 step:68910[D loss: 0.999985] [G loss: 1.000040]\n",
      "epoch:17 step:68915[D loss: 0.999946] [G loss: 1.000072]\n",
      "epoch:17 step:68920[D loss: 0.999963] [G loss: 1.000067]\n",
      "epoch:17 step:68925[D loss: 0.999997] [G loss: 1.000050]\n",
      "epoch:17 step:68930[D loss: 1.000007] [G loss: 1.000023]\n",
      "epoch:17 step:68935[D loss: 1.000014] [G loss: 1.000065]\n",
      "epoch:17 step:68940[D loss: 0.999972] [G loss: 1.000102]\n",
      "epoch:17 step:68945[D loss: 0.999944] [G loss: 1.000108]\n",
      "epoch:17 step:68950[D loss: 0.999971] [G loss: 1.000066]\n",
      "epoch:17 step:68955[D loss: 0.999952] [G loss: 1.000050]\n",
      "epoch:17 step:68960[D loss: 0.999953] [G loss: 1.000099]\n",
      "epoch:17 step:68965[D loss: 0.999986] [G loss: 1.000017]\n",
      "epoch:17 step:68970[D loss: 0.999972] [G loss: 0.999988]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:17 step:68975[D loss: 0.999973] [G loss: 1.000037]\n",
      "epoch:17 step:68980[D loss: 1.000000] [G loss: 1.000006]\n",
      "epoch:17 step:68985[D loss: 1.000056] [G loss: 0.999910]\n",
      "epoch:17 step:68990[D loss: 0.999931] [G loss: 1.000147]\n",
      "epoch:17 step:68995[D loss: 0.999957] [G loss: 1.000078]\n",
      "epoch:17 step:69000[D loss: 0.999966] [G loss: 1.000020]\n",
      "##############\n",
      "[0.84718721 0.84867044 0.84635769 0.82948521 0.79659774 0.82431625\n",
      " 0.86946384 0.84904349 0.82121451 0.83486184]\n",
      "##########\n",
      "epoch:17 step:69005[D loss: 0.999983] [G loss: 1.000002]\n",
      "epoch:17 step:69010[D loss: 0.999971] [G loss: 1.000059]\n",
      "epoch:17 step:69015[D loss: 0.999950] [G loss: 1.000069]\n",
      "epoch:17 step:69020[D loss: 0.999961] [G loss: 1.000077]\n",
      "epoch:17 step:69025[D loss: 0.999973] [G loss: 1.000035]\n",
      "epoch:17 step:69030[D loss: 0.999952] [G loss: 1.000095]\n",
      "epoch:17 step:69035[D loss: 0.999987] [G loss: 1.000085]\n",
      "epoch:17 step:69040[D loss: 0.999971] [G loss: 1.000019]\n",
      "epoch:17 step:69045[D loss: 1.000003] [G loss: 1.000059]\n",
      "epoch:17 step:69050[D loss: 1.000056] [G loss: 1.000047]\n",
      "epoch:17 step:69055[D loss: 0.999955] [G loss: 0.999984]\n",
      "epoch:17 step:69060[D loss: 0.999946] [G loss: 1.000090]\n",
      "epoch:17 step:69065[D loss: 0.999985] [G loss: 1.000013]\n",
      "epoch:17 step:69070[D loss: 0.999989] [G loss: 1.000034]\n",
      "epoch:17 step:69075[D loss: 0.999984] [G loss: 1.000068]\n",
      "epoch:17 step:69080[D loss: 0.999936] [G loss: 1.000040]\n",
      "epoch:17 step:69085[D loss: 0.999982] [G loss: 1.000021]\n",
      "epoch:17 step:69090[D loss: 1.000012] [G loss: 0.999977]\n",
      "epoch:17 step:69095[D loss: 1.000001] [G loss: 1.000001]\n",
      "epoch:17 step:69100[D loss: 0.999971] [G loss: 1.000081]\n",
      "epoch:17 step:69105[D loss: 1.000003] [G loss: 1.000019]\n",
      "epoch:17 step:69110[D loss: 0.999948] [G loss: 1.000056]\n",
      "epoch:17 step:69115[D loss: 0.999996] [G loss: 1.000087]\n",
      "epoch:17 step:69120[D loss: 0.999944] [G loss: 1.000042]\n",
      "epoch:17 step:69125[D loss: 1.000029] [G loss: 0.999969]\n",
      "epoch:17 step:69130[D loss: 0.999950] [G loss: 1.000081]\n",
      "epoch:17 step:69135[D loss: 1.000008] [G loss: 1.000105]\n",
      "epoch:17 step:69140[D loss: 1.000006] [G loss: 1.000061]\n",
      "epoch:17 step:69145[D loss: 1.000074] [G loss: 0.999889]\n",
      "epoch:17 step:69150[D loss: 0.999937] [G loss: 1.000231]\n",
      "epoch:17 step:69155[D loss: 0.999887] [G loss: 1.000213]\n",
      "epoch:17 step:69160[D loss: 0.999960] [G loss: 1.000038]\n",
      "epoch:17 step:69165[D loss: 0.999956] [G loss: 1.000114]\n",
      "epoch:17 step:69170[D loss: 0.999971] [G loss: 1.000113]\n",
      "epoch:17 step:69175[D loss: 0.999926] [G loss: 1.000122]\n",
      "epoch:17 step:69180[D loss: 1.000021] [G loss: 0.999998]\n",
      "epoch:17 step:69185[D loss: 0.999988] [G loss: 0.999981]\n",
      "epoch:17 step:69190[D loss: 0.999983] [G loss: 1.000067]\n",
      "epoch:17 step:69195[D loss: 1.000118] [G loss: 0.999906]\n",
      "epoch:17 step:69200[D loss: 0.999943] [G loss: 0.999999]\n",
      "##############\n",
      "[0.8546968  0.85839157 0.84466732 0.83289299 0.79243145 0.85646241\n",
      " 0.87157308 0.84639085 0.80828916 0.83059203]\n",
      "##########\n",
      "epoch:17 step:69205[D loss: 0.999928] [G loss: 1.000103]\n",
      "epoch:17 step:69210[D loss: 1.000014] [G loss: 0.999984]\n",
      "epoch:17 step:69215[D loss: 0.999957] [G loss: 1.000082]\n",
      "epoch:17 step:69220[D loss: 0.999989] [G loss: 1.000047]\n",
      "epoch:17 step:69225[D loss: 1.000009] [G loss: 1.000037]\n",
      "epoch:17 step:69230[D loss: 1.000040] [G loss: 0.999982]\n",
      "epoch:17 step:69235[D loss: 0.999968] [G loss: 1.000126]\n",
      "epoch:17 step:69240[D loss: 0.999975] [G loss: 1.000121]\n",
      "epoch:17 step:69245[D loss: 0.999979] [G loss: 1.000101]\n",
      "epoch:17 step:69250[D loss: 0.999974] [G loss: 1.000066]\n",
      "epoch:17 step:69255[D loss: 0.999930] [G loss: 1.000125]\n",
      "epoch:17 step:69260[D loss: 0.999966] [G loss: 1.000116]\n",
      "epoch:17 step:69265[D loss: 1.000003] [G loss: 1.000020]\n",
      "epoch:17 step:69270[D loss: 0.999980] [G loss: 1.000033]\n",
      "epoch:17 step:69275[D loss: 0.999988] [G loss: 0.999993]\n",
      "epoch:17 step:69280[D loss: 0.999939] [G loss: 1.000065]\n",
      "epoch:17 step:69285[D loss: 0.999962] [G loss: 1.000090]\n",
      "epoch:17 step:69290[D loss: 0.999968] [G loss: 1.000059]\n",
      "epoch:17 step:69295[D loss: 1.000032] [G loss: 0.999997]\n",
      "epoch:17 step:69300[D loss: 0.999981] [G loss: 1.000044]\n",
      "epoch:17 step:69305[D loss: 1.000038] [G loss: 1.000066]\n",
      "epoch:17 step:69310[D loss: 0.999949] [G loss: 1.000057]\n",
      "epoch:17 step:69315[D loss: 0.999977] [G loss: 1.000048]\n",
      "epoch:17 step:69320[D loss: 1.000007] [G loss: 1.000060]\n",
      "epoch:17 step:69325[D loss: 1.000008] [G loss: 1.000002]\n",
      "epoch:17 step:69330[D loss: 0.999990] [G loss: 1.000021]\n",
      "epoch:17 step:69335[D loss: 1.000002] [G loss: 1.000140]\n",
      "epoch:17 step:69340[D loss: 0.999849] [G loss: 1.000245]\n",
      "epoch:17 step:69345[D loss: 1.000013] [G loss: 0.999979]\n",
      "epoch:17 step:69350[D loss: 0.999926] [G loss: 1.000112]\n",
      "epoch:17 step:69355[D loss: 0.999964] [G loss: 1.000031]\n",
      "epoch:17 step:69360[D loss: 1.000147] [G loss: 0.999803]\n",
      "epoch:17 step:69365[D loss: 1.000011] [G loss: 1.000045]\n",
      "epoch:17 step:69370[D loss: 0.999976] [G loss: 1.000059]\n",
      "epoch:17 step:69375[D loss: 0.999875] [G loss: 1.000224]\n",
      "epoch:17 step:69380[D loss: 1.000028] [G loss: 0.999926]\n",
      "epoch:17 step:69385[D loss: 1.000071] [G loss: 0.999972]\n",
      "epoch:17 step:69390[D loss: 1.000046] [G loss: 1.000035]\n",
      "epoch:17 step:69395[D loss: 0.999966] [G loss: 0.999981]\n",
      "epoch:17 step:69400[D loss: 0.999984] [G loss: 1.000037]\n",
      "##############\n",
      "[0.85241589 0.85707    0.83173771 0.83007226 0.80959854 0.83981311\n",
      " 0.87477134 0.83328682 0.82528202 0.82102876]\n",
      "##########\n",
      "epoch:17 step:69405[D loss: 1.000033] [G loss: 1.000019]\n",
      "epoch:17 step:69410[D loss: 0.999989] [G loss: 1.000137]\n",
      "epoch:17 step:69415[D loss: 0.999953] [G loss: 1.000218]\n",
      "epoch:17 step:69420[D loss: 0.999985] [G loss: 1.000144]\n",
      "epoch:17 step:69425[D loss: 0.999923] [G loss: 1.000135]\n",
      "epoch:17 step:69430[D loss: 0.999958] [G loss: 1.000045]\n",
      "epoch:17 step:69435[D loss: 1.000047] [G loss: 0.999890]\n",
      "epoch:17 step:69440[D loss: 0.999966] [G loss: 0.999981]\n",
      "epoch:17 step:69445[D loss: 0.999949] [G loss: 1.000067]\n",
      "epoch:17 step:69450[D loss: 0.999969] [G loss: 1.000019]\n",
      "epoch:17 step:69455[D loss: 0.999956] [G loss: 1.000013]\n",
      "epoch:17 step:69460[D loss: 0.999965] [G loss: 1.000064]\n",
      "epoch:17 step:69465[D loss: 1.000004] [G loss: 1.000004]\n",
      "epoch:17 step:69470[D loss: 1.000021] [G loss: 0.999970]\n",
      "epoch:17 step:69475[D loss: 0.999969] [G loss: 1.000006]\n",
      "epoch:17 step:69480[D loss: 0.999949] [G loss: 1.000079]\n",
      "epoch:17 step:69485[D loss: 0.999962] [G loss: 1.000027]\n",
      "epoch:17 step:69490[D loss: 1.000035] [G loss: 0.999993]\n",
      "epoch:17 step:69495[D loss: 0.999982] [G loss: 1.000176]\n",
      "epoch:17 step:69500[D loss: 0.999947] [G loss: 1.000049]\n",
      "epoch:17 step:69505[D loss: 0.999949] [G loss: 1.000216]\n",
      "epoch:17 step:69510[D loss: 0.999969] [G loss: 1.000086]\n",
      "epoch:17 step:69515[D loss: 0.999951] [G loss: 1.000116]\n",
      "epoch:17 step:69520[D loss: 1.000011] [G loss: 1.000015]\n",
      "epoch:17 step:69525[D loss: 1.000086] [G loss: 0.999896]\n",
      "epoch:17 step:69530[D loss: 1.000064] [G loss: 1.000024]\n",
      "epoch:17 step:69535[D loss: 1.000185] [G loss: 0.999530]\n",
      "epoch:17 step:69540[D loss: 0.999823] [G loss: 1.000160]\n",
      "epoch:17 step:69545[D loss: 1.000057] [G loss: 0.999993]\n",
      "epoch:17 step:69550[D loss: 0.999892] [G loss: 1.000118]\n",
      "epoch:17 step:69555[D loss: 0.999971] [G loss: 1.000066]\n",
      "epoch:17 step:69560[D loss: 0.999957] [G loss: 1.000084]\n",
      "epoch:17 step:69565[D loss: 0.999993] [G loss: 1.000065]\n",
      "epoch:17 step:69570[D loss: 1.000014] [G loss: 1.000038]\n",
      "epoch:17 step:69575[D loss: 0.999986] [G loss: 1.000075]\n",
      "epoch:17 step:69580[D loss: 1.000012] [G loss: 0.999999]\n",
      "epoch:17 step:69585[D loss: 0.999958] [G loss: 1.000081]\n",
      "epoch:17 step:69590[D loss: 0.999976] [G loss: 1.000035]\n",
      "epoch:17 step:69595[D loss: 0.999989] [G loss: 1.000092]\n",
      "epoch:17 step:69600[D loss: 1.000018] [G loss: 1.000043]\n",
      "##############\n",
      "[0.86343109 0.84885083 0.81816425 0.81561152 0.80488043 0.84277474\n",
      " 0.8962943  0.84827789 0.83256973 0.84494422]\n",
      "##########\n",
      "epoch:17 step:69605[D loss: 0.999953] [G loss: 1.000133]\n",
      "epoch:17 step:69610[D loss: 0.999958] [G loss: 1.000109]\n",
      "epoch:17 step:69615[D loss: 0.999970] [G loss: 1.000098]\n",
      "epoch:17 step:69620[D loss: 0.999991] [G loss: 1.000061]\n",
      "epoch:17 step:69625[D loss: 0.999975] [G loss: 1.000073]\n",
      "epoch:17 step:69630[D loss: 0.999993] [G loss: 1.000026]\n",
      "epoch:17 step:69635[D loss: 0.999968] [G loss: 1.000071]\n",
      "epoch:17 step:69640[D loss: 0.999962] [G loss: 1.000082]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:17 step:69645[D loss: 0.999979] [G loss: 1.000094]\n",
      "epoch:17 step:69650[D loss: 0.999999] [G loss: 1.000048]\n",
      "epoch:17 step:69655[D loss: 0.999953] [G loss: 1.000134]\n",
      "epoch:17 step:69660[D loss: 0.999988] [G loss: 1.000112]\n",
      "epoch:17 step:69665[D loss: 0.999948] [G loss: 1.000133]\n",
      "epoch:17 step:69670[D loss: 1.000024] [G loss: 1.000024]\n",
      "epoch:17 step:69675[D loss: 0.999964] [G loss: 1.000100]\n",
      "epoch:17 step:69680[D loss: 0.999967] [G loss: 1.000081]\n",
      "epoch:17 step:69685[D loss: 0.999992] [G loss: 1.000033]\n",
      "epoch:17 step:69690[D loss: 1.000006] [G loss: 1.000053]\n",
      "epoch:17 step:69695[D loss: 1.000026] [G loss: 0.999906]\n",
      "epoch:17 step:69700[D loss: 1.000005] [G loss: 1.000020]\n",
      "epoch:17 step:69705[D loss: 0.999933] [G loss: 1.000085]\n",
      "epoch:17 step:69710[D loss: 0.999971] [G loss: 1.000120]\n",
      "epoch:17 step:69715[D loss: 0.999937] [G loss: 1.000076]\n",
      "epoch:17 step:69720[D loss: 0.999969] [G loss: 1.000040]\n",
      "epoch:17 step:69725[D loss: 0.999961] [G loss: 1.000089]\n",
      "epoch:17 step:69730[D loss: 1.000002] [G loss: 1.000041]\n",
      "epoch:17 step:69735[D loss: 0.999927] [G loss: 1.000155]\n",
      "epoch:17 step:69740[D loss: 0.999979] [G loss: 1.000063]\n",
      "epoch:17 step:69745[D loss: 0.999987] [G loss: 1.000056]\n",
      "epoch:17 step:69750[D loss: 1.000003] [G loss: 1.000014]\n",
      "epoch:17 step:69755[D loss: 0.999963] [G loss: 1.000015]\n",
      "epoch:17 step:69760[D loss: 0.999929] [G loss: 1.000148]\n",
      "epoch:17 step:69765[D loss: 1.000003] [G loss: 1.000047]\n",
      "epoch:17 step:69770[D loss: 0.999978] [G loss: 1.000029]\n",
      "epoch:17 step:69775[D loss: 1.000025] [G loss: 0.999913]\n",
      "epoch:17 step:69780[D loss: 0.999949] [G loss: 1.000042]\n",
      "epoch:17 step:69785[D loss: 0.999966] [G loss: 1.000035]\n",
      "epoch:17 step:69790[D loss: 0.999989] [G loss: 1.000066]\n",
      "epoch:17 step:69795[D loss: 0.999979] [G loss: 1.000060]\n",
      "epoch:17 step:69800[D loss: 0.999967] [G loss: 1.000080]\n",
      "##############\n",
      "[0.86821978 0.8545696  0.80023924 0.82756999 0.80120206 0.84525585\n",
      " 0.90435532 0.8312505  0.81260921 0.84338644]\n",
      "##########\n",
      "epoch:17 step:69805[D loss: 0.999970] [G loss: 1.000051]\n",
      "epoch:17 step:69810[D loss: 1.000016] [G loss: 0.999940]\n",
      "epoch:17 step:69815[D loss: 0.999979] [G loss: 1.000029]\n",
      "epoch:17 step:69820[D loss: 1.000053] [G loss: 1.000056]\n",
      "epoch:17 step:69825[D loss: 0.999965] [G loss: 1.000068]\n",
      "epoch:17 step:69830[D loss: 0.999992] [G loss: 1.000119]\n",
      "epoch:17 step:69835[D loss: 0.999931] [G loss: 1.000160]\n",
      "epoch:17 step:69840[D loss: 0.999977] [G loss: 1.000049]\n",
      "epoch:17 step:69845[D loss: 1.000139] [G loss: 0.999867]\n",
      "epoch:17 step:69850[D loss: 1.000081] [G loss: 0.999922]\n",
      "epoch:17 step:69855[D loss: 1.000093] [G loss: 0.999960]\n",
      "epoch:17 step:69860[D loss: 1.000134] [G loss: 0.999921]\n",
      "epoch:17 step:69865[D loss: 0.999948] [G loss: 1.000114]\n",
      "epoch:17 step:69870[D loss: 0.999889] [G loss: 1.000295]\n",
      "epoch:17 step:69875[D loss: 1.000033] [G loss: 1.000139]\n",
      "epoch:17 step:69880[D loss: 0.999953] [G loss: 1.000346]\n",
      "epoch:17 step:69885[D loss: 0.999898] [G loss: 1.000359]\n",
      "epoch:17 step:69890[D loss: 0.999911] [G loss: 1.000270]\n",
      "epoch:17 step:69895[D loss: 0.999946] [G loss: 1.000278]\n",
      "epoch:17 step:69900[D loss: 0.999907] [G loss: 1.000308]\n",
      "epoch:17 step:69905[D loss: 0.999923] [G loss: 1.000107]\n",
      "epoch:17 step:69910[D loss: 1.000005] [G loss: 1.000151]\n",
      "epoch:17 step:69915[D loss: 1.000026] [G loss: 0.999997]\n",
      "epoch:17 step:69920[D loss: 1.000061] [G loss: 0.999921]\n",
      "epoch:17 step:69925[D loss: 0.999924] [G loss: 1.000122]\n",
      "epoch:17 step:69930[D loss: 1.000069] [G loss: 0.999779]\n",
      "epoch:17 step:69935[D loss: 0.999988] [G loss: 0.999932]\n",
      "epoch:17 step:69940[D loss: 0.999963] [G loss: 1.000048]\n",
      "epoch:17 step:69945[D loss: 1.000057] [G loss: 1.000002]\n",
      "epoch:17 step:69950[D loss: 0.999960] [G loss: 0.999992]\n",
      "epoch:17 step:69955[D loss: 1.000067] [G loss: 0.999938]\n",
      "epoch:17 step:69960[D loss: 0.999945] [G loss: 1.000123]\n",
      "epoch:17 step:69965[D loss: 0.999982] [G loss: 1.000009]\n",
      "epoch:17 step:69970[D loss: 1.000005] [G loss: 1.000010]\n",
      "epoch:17 step:69975[D loss: 1.000007] [G loss: 1.000031]\n",
      "epoch:17 step:69980[D loss: 0.999961] [G loss: 1.000187]\n",
      "epoch:17 step:69985[D loss: 0.999943] [G loss: 1.000007]\n",
      "epoch:17 step:69990[D loss: 0.999947] [G loss: 1.000064]\n",
      "epoch:17 step:69995[D loss: 1.000038] [G loss: 0.999949]\n",
      "epoch:17 step:70000[D loss: 0.999987] [G loss: 1.000087]\n",
      "##############\n",
      "[0.85690472 0.86077292 0.83212072 0.81881836 0.78969965 0.85927834\n",
      " 0.88360807 0.824925   0.82667642 0.81970526]\n",
      "##########\n",
      "epoch:17 step:70005[D loss: 0.999910] [G loss: 1.000100]\n",
      "epoch:17 step:70010[D loss: 0.999956] [G loss: 1.000098]\n",
      "epoch:17 step:70015[D loss: 0.999984] [G loss: 1.000090]\n",
      "epoch:17 step:70020[D loss: 0.999972] [G loss: 1.000074]\n",
      "epoch:17 step:70025[D loss: 0.999964] [G loss: 1.000052]\n",
      "epoch:17 step:70030[D loss: 0.999991] [G loss: 1.000049]\n",
      "epoch:17 step:70035[D loss: 0.999977] [G loss: 1.000037]\n",
      "epoch:17 step:70040[D loss: 0.999996] [G loss: 0.999990]\n",
      "epoch:17 step:70045[D loss: 0.999980] [G loss: 1.000003]\n",
      "epoch:17 step:70050[D loss: 0.999993] [G loss: 1.000023]\n",
      "epoch:17 step:70055[D loss: 0.999962] [G loss: 1.000108]\n",
      "epoch:17 step:70060[D loss: 0.999939] [G loss: 1.000100]\n",
      "epoch:17 step:70065[D loss: 0.999972] [G loss: 1.000038]\n",
      "epoch:17 step:70070[D loss: 0.999973] [G loss: 1.000055]\n",
      "epoch:17 step:70075[D loss: 1.000000] [G loss: 1.000028]\n",
      "epoch:17 step:70080[D loss: 0.999948] [G loss: 1.000128]\n",
      "epoch:17 step:70085[D loss: 0.999954] [G loss: 1.000144]\n",
      "epoch:17 step:70090[D loss: 0.999959] [G loss: 1.000093]\n",
      "epoch:17 step:70095[D loss: 0.999941] [G loss: 1.000064]\n",
      "epoch:17 step:70100[D loss: 0.999968] [G loss: 1.000082]\n",
      "epoch:17 step:70105[D loss: 0.999965] [G loss: 1.000070]\n",
      "epoch:17 step:70110[D loss: 0.999937] [G loss: 1.000107]\n",
      "epoch:17 step:70115[D loss: 0.999973] [G loss: 1.000051]\n",
      "epoch:17 step:70120[D loss: 0.999998] [G loss: 1.000022]\n",
      "epoch:17 step:70125[D loss: 0.999938] [G loss: 1.000091]\n",
      "epoch:17 step:70130[D loss: 1.000014] [G loss: 1.000029]\n",
      "epoch:17 step:70135[D loss: 0.999991] [G loss: 1.000030]\n",
      "epoch:17 step:70140[D loss: 1.000003] [G loss: 1.000055]\n",
      "epoch:17 step:70145[D loss: 0.999916] [G loss: 1.000116]\n",
      "epoch:17 step:70150[D loss: 1.000003] [G loss: 1.000062]\n",
      "epoch:17 step:70155[D loss: 1.000081] [G loss: 1.000023]\n",
      "epoch:17 step:70160[D loss: 0.999908] [G loss: 1.000096]\n",
      "epoch:17 step:70165[D loss: 1.000046] [G loss: 1.000013]\n",
      "epoch:17 step:70170[D loss: 0.999927] [G loss: 1.000091]\n",
      "epoch:17 step:70175[D loss: 0.999957] [G loss: 1.000085]\n",
      "epoch:17 step:70180[D loss: 0.999994] [G loss: 1.000066]\n",
      "epoch:17 step:70185[D loss: 1.000044] [G loss: 0.999954]\n",
      "epoch:17 step:70190[D loss: 1.000051] [G loss: 0.999977]\n",
      "epoch:17 step:70195[D loss: 1.000088] [G loss: 0.999934]\n",
      "epoch:17 step:70200[D loss: 0.999861] [G loss: 1.000201]\n",
      "##############\n",
      "[0.84095145 0.87207499 0.82855227 0.83019285 0.79374312 0.83559733\n",
      " 0.88007628 0.83057237 0.81724262 0.84203978]\n",
      "##########\n",
      "epoch:17 step:70205[D loss: 0.999989] [G loss: 0.999997]\n",
      "epoch:17 step:70210[D loss: 0.999946] [G loss: 1.000103]\n",
      "epoch:17 step:70215[D loss: 1.000026] [G loss: 0.999914]\n",
      "epoch:17 step:70220[D loss: 0.999990] [G loss: 1.000026]\n",
      "epoch:17 step:70225[D loss: 0.999970] [G loss: 1.000035]\n",
      "epoch:17 step:70230[D loss: 0.999951] [G loss: 1.000068]\n",
      "epoch:17 step:70235[D loss: 0.999974] [G loss: 1.000051]\n",
      "epoch:17 step:70240[D loss: 0.999963] [G loss: 1.000096]\n",
      "epoch:17 step:70245[D loss: 0.999962] [G loss: 1.000074]\n",
      "epoch:17 step:70250[D loss: 0.999957] [G loss: 1.000115]\n",
      "epoch:17 step:70255[D loss: 0.999938] [G loss: 1.000151]\n",
      "epoch:17 step:70260[D loss: 0.999992] [G loss: 1.000042]\n",
      "epoch:17 step:70265[D loss: 0.999960] [G loss: 1.000087]\n",
      "epoch:17 step:70270[D loss: 0.999979] [G loss: 1.000103]\n",
      "epoch:17 step:70275[D loss: 1.000022] [G loss: 1.000047]\n",
      "epoch:17 step:70280[D loss: 0.999967] [G loss: 1.000051]\n",
      "epoch:17 step:70285[D loss: 0.999984] [G loss: 1.000053]\n",
      "epoch:17 step:70290[D loss: 0.999967] [G loss: 1.000095]\n",
      "epoch:18 step:70295[D loss: 0.999964] [G loss: 1.000056]\n",
      "epoch:18 step:70300[D loss: 0.999943] [G loss: 1.000080]\n",
      "epoch:18 step:70305[D loss: 0.999989] [G loss: 1.000044]\n",
      "epoch:18 step:70310[D loss: 0.999995] [G loss: 1.000006]\n",
      "epoch:18 step:70315[D loss: 0.999997] [G loss: 1.000063]\n",
      "epoch:18 step:70320[D loss: 0.999977] [G loss: 1.000054]\n",
      "epoch:18 step:70325[D loss: 0.999948] [G loss: 1.000085]\n",
      "epoch:18 step:70330[D loss: 0.999993] [G loss: 1.000032]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:18 step:70335[D loss: 0.999997] [G loss: 1.000025]\n",
      "epoch:18 step:70340[D loss: 0.999986] [G loss: 1.000081]\n",
      "epoch:18 step:70345[D loss: 1.000016] [G loss: 1.000048]\n",
      "epoch:18 step:70350[D loss: 0.999965] [G loss: 1.000071]\n",
      "epoch:18 step:70355[D loss: 0.999973] [G loss: 1.000102]\n",
      "epoch:18 step:70360[D loss: 0.999962] [G loss: 1.000076]\n",
      "epoch:18 step:70365[D loss: 1.000042] [G loss: 0.999973]\n",
      "epoch:18 step:70370[D loss: 0.999946] [G loss: 1.000114]\n",
      "epoch:18 step:70375[D loss: 1.000025] [G loss: 0.999974]\n",
      "epoch:18 step:70380[D loss: 1.000012] [G loss: 1.000085]\n",
      "epoch:18 step:70385[D loss: 0.999965] [G loss: 1.000116]\n",
      "epoch:18 step:70390[D loss: 0.999969] [G loss: 1.000148]\n",
      "epoch:18 step:70395[D loss: 0.999953] [G loss: 1.000128]\n",
      "epoch:18 step:70400[D loss: 0.999984] [G loss: 1.000059]\n",
      "##############\n",
      "[0.86622958 0.85589536 0.81216985 0.82682345 0.79972785 0.84502936\n",
      " 0.89085232 0.82992574 0.82623972 0.82374394]\n",
      "##########\n",
      "epoch:18 step:70405[D loss: 0.999995] [G loss: 0.999995]\n",
      "epoch:18 step:70410[D loss: 1.000013] [G loss: 1.000191]\n",
      "epoch:18 step:70415[D loss: 1.000007] [G loss: 0.999984]\n",
      "epoch:18 step:70420[D loss: 0.999948] [G loss: 1.000122]\n",
      "epoch:18 step:70425[D loss: 0.999964] [G loss: 1.000122]\n",
      "epoch:18 step:70430[D loss: 1.000052] [G loss: 0.999993]\n",
      "epoch:18 step:70435[D loss: 0.999942] [G loss: 1.000104]\n",
      "epoch:18 step:70440[D loss: 0.999931] [G loss: 1.000163]\n",
      "epoch:18 step:70445[D loss: 0.999941] [G loss: 1.000081]\n",
      "epoch:18 step:70450[D loss: 1.000033] [G loss: 0.999949]\n",
      "epoch:18 step:70455[D loss: 1.000037] [G loss: 0.999928]\n",
      "epoch:18 step:70460[D loss: 0.999983] [G loss: 1.000056]\n",
      "epoch:18 step:70465[D loss: 1.000035] [G loss: 0.999902]\n",
      "epoch:18 step:70470[D loss: 0.999945] [G loss: 1.000096]\n",
      "epoch:18 step:70475[D loss: 1.000018] [G loss: 1.000057]\n",
      "epoch:18 step:70480[D loss: 0.999929] [G loss: 1.000090]\n",
      "epoch:18 step:70485[D loss: 0.999980] [G loss: 1.000047]\n",
      "epoch:18 step:70490[D loss: 1.000040] [G loss: 0.999948]\n",
      "epoch:18 step:70495[D loss: 1.000018] [G loss: 1.000007]\n",
      "epoch:18 step:70500[D loss: 0.999983] [G loss: 1.000140]\n",
      "epoch:18 step:70505[D loss: 0.999940] [G loss: 1.000080]\n",
      "epoch:18 step:70510[D loss: 1.000009] [G loss: 1.000047]\n",
      "epoch:18 step:70515[D loss: 0.999981] [G loss: 1.000061]\n",
      "epoch:18 step:70520[D loss: 0.999970] [G loss: 1.000073]\n",
      "epoch:18 step:70525[D loss: 0.999968] [G loss: 1.000095]\n",
      "epoch:18 step:70530[D loss: 1.000053] [G loss: 1.000017]\n",
      "epoch:18 step:70535[D loss: 1.000003] [G loss: 1.000007]\n",
      "epoch:18 step:70540[D loss: 0.999998] [G loss: 1.000021]\n",
      "epoch:18 step:70545[D loss: 0.999931] [G loss: 1.000089]\n",
      "epoch:18 step:70550[D loss: 0.999973] [G loss: 1.000059]\n",
      "epoch:18 step:70555[D loss: 0.999999] [G loss: 1.000052]\n",
      "epoch:18 step:70560[D loss: 1.000003] [G loss: 1.000008]\n",
      "epoch:18 step:70565[D loss: 1.000008] [G loss: 1.000062]\n",
      "epoch:18 step:70570[D loss: 0.999968] [G loss: 1.000071]\n",
      "epoch:18 step:70575[D loss: 1.000037] [G loss: 0.999963]\n",
      "epoch:18 step:70580[D loss: 1.000001] [G loss: 0.999931]\n",
      "epoch:18 step:70585[D loss: 0.999971] [G loss: 1.000040]\n",
      "epoch:18 step:70590[D loss: 0.999985] [G loss: 1.000032]\n",
      "epoch:18 step:70595[D loss: 0.999969] [G loss: 1.000087]\n",
      "epoch:18 step:70600[D loss: 0.999960] [G loss: 1.000067]\n",
      "##############\n",
      "[0.86587629 0.87144747 0.82189219 0.8316524  0.80341849 0.83069724\n",
      " 0.85268227 0.84759223 0.84652496 0.84968714]\n",
      "##########\n",
      "epoch:18 step:70605[D loss: 0.999981] [G loss: 1.000053]\n",
      "epoch:18 step:70610[D loss: 0.999990] [G loss: 1.000036]\n",
      "epoch:18 step:70615[D loss: 1.000039] [G loss: 1.000011]\n",
      "epoch:18 step:70620[D loss: 0.999949] [G loss: 1.000120]\n",
      "epoch:18 step:70625[D loss: 0.999947] [G loss: 1.000149]\n",
      "epoch:18 step:70630[D loss: 0.999971] [G loss: 1.000079]\n",
      "epoch:18 step:70635[D loss: 0.999976] [G loss: 1.000072]\n",
      "epoch:18 step:70640[D loss: 0.999977] [G loss: 1.000055]\n",
      "epoch:18 step:70645[D loss: 1.000056] [G loss: 1.000046]\n",
      "epoch:18 step:70650[D loss: 1.000093] [G loss: 0.999979]\n",
      "epoch:18 step:70655[D loss: 1.000032] [G loss: 1.000043]\n",
      "epoch:18 step:70660[D loss: 0.999901] [G loss: 1.000212]\n",
      "epoch:18 step:70665[D loss: 0.999991] [G loss: 1.000197]\n",
      "epoch:18 step:70670[D loss: 0.999953] [G loss: 1.000077]\n",
      "epoch:18 step:70675[D loss: 0.999968] [G loss: 1.000097]\n",
      "epoch:18 step:70680[D loss: 0.999977] [G loss: 1.000051]\n",
      "epoch:18 step:70685[D loss: 0.999989] [G loss: 1.000058]\n",
      "epoch:18 step:70690[D loss: 0.999956] [G loss: 1.000084]\n",
      "epoch:18 step:70695[D loss: 0.999972] [G loss: 1.000060]\n",
      "epoch:18 step:70700[D loss: 0.999993] [G loss: 1.000025]\n",
      "epoch:18 step:70705[D loss: 0.999964] [G loss: 1.000068]\n",
      "epoch:18 step:70710[D loss: 0.999966] [G loss: 1.000093]\n",
      "epoch:18 step:70715[D loss: 0.999968] [G loss: 1.000045]\n",
      "epoch:18 step:70720[D loss: 0.999970] [G loss: 1.000062]\n",
      "epoch:18 step:70725[D loss: 0.999974] [G loss: 1.000065]\n",
      "epoch:18 step:70730[D loss: 0.999995] [G loss: 1.000042]\n",
      "epoch:18 step:70735[D loss: 0.999979] [G loss: 1.000111]\n",
      "epoch:18 step:70740[D loss: 0.999992] [G loss: 0.999979]\n",
      "epoch:18 step:70745[D loss: 0.999972] [G loss: 1.000054]\n",
      "epoch:18 step:70750[D loss: 0.999948] [G loss: 1.000044]\n",
      "epoch:18 step:70755[D loss: 0.999952] [G loss: 1.000067]\n",
      "epoch:18 step:70760[D loss: 0.999975] [G loss: 1.000048]\n",
      "epoch:18 step:70765[D loss: 0.999977] [G loss: 1.000040]\n",
      "epoch:18 step:70770[D loss: 0.999944] [G loss: 1.000104]\n",
      "epoch:18 step:70775[D loss: 0.999949] [G loss: 1.000110]\n",
      "epoch:18 step:70780[D loss: 1.000033] [G loss: 0.999965]\n",
      "epoch:18 step:70785[D loss: 0.999955] [G loss: 1.000126]\n",
      "epoch:18 step:70790[D loss: 1.000004] [G loss: 1.000078]\n",
      "epoch:18 step:70795[D loss: 0.999972] [G loss: 1.000064]\n",
      "epoch:18 step:70800[D loss: 0.999975] [G loss: 1.000073]\n",
      "##############\n",
      "[0.84946484 0.86313615 0.82530488 0.82967248 0.7967125  0.85322411\n",
      " 0.85153156 0.84807471 0.80894425 0.84025169]\n",
      "##########\n",
      "epoch:18 step:70805[D loss: 0.999972] [G loss: 1.000076]\n",
      "epoch:18 step:70810[D loss: 1.000060] [G loss: 0.999982]\n",
      "epoch:18 step:70815[D loss: 1.000069] [G loss: 0.999903]\n",
      "epoch:18 step:70820[D loss: 1.000020] [G loss: 0.999951]\n",
      "epoch:18 step:70825[D loss: 1.000001] [G loss: 1.000028]\n",
      "epoch:18 step:70830[D loss: 0.999957] [G loss: 1.000141]\n",
      "epoch:18 step:70835[D loss: 0.999984] [G loss: 1.000082]\n",
      "epoch:18 step:70840[D loss: 0.999998] [G loss: 1.000069]\n",
      "epoch:18 step:70845[D loss: 0.999964] [G loss: 1.000087]\n",
      "epoch:18 step:70850[D loss: 0.999978] [G loss: 1.000059]\n",
      "epoch:18 step:70855[D loss: 1.000044] [G loss: 0.999983]\n",
      "epoch:18 step:70860[D loss: 0.999929] [G loss: 1.000105]\n",
      "epoch:18 step:70865[D loss: 0.999973] [G loss: 1.000058]\n",
      "epoch:18 step:70870[D loss: 0.999944] [G loss: 1.000097]\n",
      "epoch:18 step:70875[D loss: 1.000060] [G loss: 0.999957]\n",
      "epoch:18 step:70880[D loss: 0.999951] [G loss: 1.000088]\n",
      "epoch:18 step:70885[D loss: 0.999990] [G loss: 1.000074]\n",
      "epoch:18 step:70890[D loss: 0.999987] [G loss: 1.000095]\n",
      "epoch:18 step:70895[D loss: 0.999982] [G loss: 1.000110]\n",
      "epoch:18 step:70900[D loss: 1.000007] [G loss: 1.000092]\n",
      "epoch:18 step:70905[D loss: 0.999980] [G loss: 1.000015]\n",
      "epoch:18 step:70910[D loss: 0.999977] [G loss: 1.000056]\n",
      "epoch:18 step:70915[D loss: 1.000014] [G loss: 0.999958]\n",
      "epoch:18 step:70920[D loss: 0.999965] [G loss: 1.000081]\n",
      "epoch:18 step:70925[D loss: 0.999976] [G loss: 1.000078]\n",
      "epoch:18 step:70930[D loss: 0.999976] [G loss: 1.000081]\n",
      "epoch:18 step:70935[D loss: 0.999960] [G loss: 1.000092]\n",
      "epoch:18 step:70940[D loss: 0.999966] [G loss: 1.000060]\n",
      "epoch:18 step:70945[D loss: 1.000012] [G loss: 0.999981]\n",
      "epoch:18 step:70950[D loss: 0.999968] [G loss: 1.000033]\n",
      "epoch:18 step:70955[D loss: 0.999965] [G loss: 1.000091]\n",
      "epoch:18 step:70960[D loss: 0.999991] [G loss: 1.000048]\n",
      "epoch:18 step:70965[D loss: 0.999979] [G loss: 1.000052]\n",
      "epoch:18 step:70970[D loss: 0.999977] [G loss: 1.000020]\n",
      "epoch:18 step:70975[D loss: 0.999974] [G loss: 1.000076]\n",
      "epoch:18 step:70980[D loss: 1.000007] [G loss: 1.000036]\n",
      "epoch:18 step:70985[D loss: 0.999978] [G loss: 1.000042]\n",
      "epoch:18 step:70990[D loss: 0.999979] [G loss: 1.000059]\n",
      "epoch:18 step:70995[D loss: 1.000003] [G loss: 1.000073]\n",
      "epoch:18 step:71000[D loss: 0.999942] [G loss: 1.000167]\n",
      "##############\n",
      "[0.85386748 0.85512355 0.80840214 0.81841845 0.80860073 0.84436694\n",
      " 0.85026647 0.81117849 0.80616361 0.84999971]\n",
      "##########\n",
      "epoch:18 step:71005[D loss: 0.999942] [G loss: 1.000104]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:18 step:71010[D loss: 0.999975] [G loss: 1.000087]\n",
      "epoch:18 step:71015[D loss: 1.000035] [G loss: 0.999973]\n",
      "epoch:18 step:71020[D loss: 0.999969] [G loss: 1.000033]\n",
      "epoch:18 step:71025[D loss: 0.999946] [G loss: 1.000064]\n",
      "epoch:18 step:71030[D loss: 1.000002] [G loss: 1.000060]\n",
      "epoch:18 step:71035[D loss: 0.999961] [G loss: 1.000033]\n",
      "epoch:18 step:71040[D loss: 0.999960] [G loss: 1.000068]\n",
      "epoch:18 step:71045[D loss: 0.999976] [G loss: 1.000049]\n",
      "epoch:18 step:71050[D loss: 0.999975] [G loss: 1.000041]\n",
      "epoch:18 step:71055[D loss: 1.000068] [G loss: 0.999948]\n",
      "epoch:18 step:71060[D loss: 0.999983] [G loss: 1.000005]\n",
      "epoch:18 step:71065[D loss: 0.999944] [G loss: 1.000135]\n",
      "epoch:18 step:71070[D loss: 0.999962] [G loss: 1.000055]\n",
      "epoch:18 step:71075[D loss: 0.999985] [G loss: 1.000074]\n",
      "epoch:18 step:71080[D loss: 0.999967] [G loss: 1.000074]\n",
      "epoch:18 step:71085[D loss: 1.000073] [G loss: 0.999994]\n",
      "epoch:18 step:71090[D loss: 0.999933] [G loss: 1.000116]\n",
      "epoch:18 step:71095[D loss: 0.999957] [G loss: 1.000076]\n",
      "epoch:18 step:71100[D loss: 0.999975] [G loss: 1.000074]\n",
      "epoch:18 step:71105[D loss: 0.999982] [G loss: 1.000056]\n",
      "epoch:18 step:71110[D loss: 0.999976] [G loss: 1.000080]\n",
      "epoch:18 step:71115[D loss: 1.000004] [G loss: 1.000040]\n",
      "epoch:18 step:71120[D loss: 0.999958] [G loss: 1.000074]\n",
      "epoch:18 step:71125[D loss: 0.999968] [G loss: 1.000062]\n",
      "epoch:18 step:71130[D loss: 0.999979] [G loss: 1.000083]\n",
      "epoch:18 step:71135[D loss: 0.999987] [G loss: 1.000074]\n",
      "epoch:18 step:71140[D loss: 0.999933] [G loss: 1.000273]\n",
      "epoch:18 step:71145[D loss: 1.000031] [G loss: 1.000087]\n",
      "epoch:18 step:71150[D loss: 0.999960] [G loss: 1.000114]\n",
      "epoch:18 step:71155[D loss: 0.999952] [G loss: 1.000048]\n",
      "epoch:18 step:71160[D loss: 0.999964] [G loss: 1.000069]\n",
      "epoch:18 step:71165[D loss: 1.000005] [G loss: 1.000028]\n",
      "epoch:18 step:71170[D loss: 1.000282] [G loss: 0.999739]\n",
      "epoch:18 step:71175[D loss: 0.999976] [G loss: 0.999945]\n",
      "epoch:18 step:71180[D loss: 0.999971] [G loss: 1.000008]\n",
      "epoch:18 step:71185[D loss: 1.000083] [G loss: 0.999992]\n",
      "epoch:18 step:71190[D loss: 1.000087] [G loss: 0.999932]\n",
      "epoch:18 step:71195[D loss: 0.999940] [G loss: 1.000078]\n",
      "epoch:18 step:71200[D loss: 1.000002] [G loss: 1.000026]\n",
      "##############\n",
      "[0.86840301 0.86074952 0.81886814 0.82236496 0.79243012 0.84120683\n",
      " 0.86529281 0.848301   0.83230096 0.84315745]\n",
      "##########\n",
      "epoch:18 step:71205[D loss: 1.000104] [G loss: 0.999833]\n",
      "epoch:18 step:71210[D loss: 1.000033] [G loss: 0.999861]\n",
      "epoch:18 step:71215[D loss: 1.000090] [G loss: 0.999912]\n",
      "epoch:18 step:71220[D loss: 0.999813] [G loss: 1.000166]\n",
      "epoch:18 step:71225[D loss: 0.999951] [G loss: 1.000103]\n",
      "epoch:18 step:71230[D loss: 0.999985] [G loss: 1.000001]\n",
      "epoch:18 step:71235[D loss: 0.999991] [G loss: 0.999999]\n",
      "epoch:18 step:71240[D loss: 1.000032] [G loss: 0.999976]\n",
      "epoch:18 step:71245[D loss: 0.999958] [G loss: 1.000013]\n",
      "epoch:18 step:71250[D loss: 0.999996] [G loss: 0.999953]\n",
      "epoch:18 step:71255[D loss: 0.999920] [G loss: 1.000132]\n",
      "epoch:18 step:71260[D loss: 0.999963] [G loss: 1.000107]\n",
      "epoch:18 step:71265[D loss: 0.999980] [G loss: 1.000065]\n",
      "epoch:18 step:71270[D loss: 0.999921] [G loss: 1.000140]\n",
      "epoch:18 step:71275[D loss: 0.999978] [G loss: 0.999998]\n",
      "epoch:18 step:71280[D loss: 1.000017] [G loss: 0.999988]\n",
      "epoch:18 step:71285[D loss: 0.999974] [G loss: 1.000037]\n",
      "epoch:18 step:71290[D loss: 0.999984] [G loss: 1.000033]\n",
      "epoch:18 step:71295[D loss: 0.999978] [G loss: 1.000070]\n",
      "epoch:18 step:71300[D loss: 0.999954] [G loss: 1.000120]\n",
      "epoch:18 step:71305[D loss: 0.999967] [G loss: 1.000145]\n",
      "epoch:18 step:71310[D loss: 0.999917] [G loss: 1.000185]\n",
      "epoch:18 step:71315[D loss: 0.999951] [G loss: 1.000117]\n",
      "epoch:18 step:71320[D loss: 0.999981] [G loss: 1.000069]\n",
      "epoch:18 step:71325[D loss: 0.999947] [G loss: 1.000083]\n",
      "epoch:18 step:71330[D loss: 0.999985] [G loss: 1.000036]\n",
      "epoch:18 step:71335[D loss: 0.999974] [G loss: 1.000057]\n",
      "epoch:18 step:71340[D loss: 1.000025] [G loss: 0.999992]\n",
      "epoch:18 step:71345[D loss: 0.999981] [G loss: 1.000019]\n",
      "epoch:18 step:71350[D loss: 0.999988] [G loss: 1.000050]\n",
      "epoch:18 step:71355[D loss: 0.999975] [G loss: 1.000084]\n",
      "epoch:18 step:71360[D loss: 1.000079] [G loss: 0.999965]\n",
      "epoch:18 step:71365[D loss: 0.999904] [G loss: 1.000099]\n",
      "epoch:18 step:71370[D loss: 0.999975] [G loss: 1.000005]\n",
      "epoch:18 step:71375[D loss: 0.999992] [G loss: 1.000000]\n",
      "epoch:18 step:71380[D loss: 0.999990] [G loss: 1.000046]\n",
      "epoch:18 step:71385[D loss: 1.000014] [G loss: 0.999995]\n",
      "epoch:18 step:71390[D loss: 0.999997] [G loss: 1.000050]\n",
      "epoch:18 step:71395[D loss: 0.999974] [G loss: 1.000055]\n",
      "epoch:18 step:71400[D loss: 0.999985] [G loss: 1.000036]\n",
      "##############\n",
      "[0.86058713 0.84581101 0.82667963 0.8191494  0.80169546 0.84048658\n",
      " 0.86991345 0.83453783 0.8357446  0.84530448]\n",
      "##########\n",
      "epoch:18 step:71405[D loss: 0.999971] [G loss: 1.000044]\n",
      "epoch:18 step:71410[D loss: 1.000008] [G loss: 1.000064]\n",
      "epoch:18 step:71415[D loss: 1.000027] [G loss: 1.000013]\n",
      "epoch:18 step:71420[D loss: 1.000012] [G loss: 0.999985]\n",
      "epoch:18 step:71425[D loss: 0.999906] [G loss: 1.000252]\n",
      "epoch:18 step:71430[D loss: 0.999967] [G loss: 1.000155]\n",
      "epoch:18 step:71435[D loss: 1.000012] [G loss: 1.000014]\n",
      "epoch:18 step:71440[D loss: 1.000034] [G loss: 0.999976]\n",
      "epoch:18 step:71445[D loss: 1.000095] [G loss: 0.999939]\n",
      "epoch:18 step:71450[D loss: 0.999912] [G loss: 1.000157]\n",
      "epoch:18 step:71455[D loss: 0.999923] [G loss: 1.000171]\n",
      "epoch:18 step:71460[D loss: 0.999982] [G loss: 1.000031]\n",
      "epoch:18 step:71465[D loss: 0.999956] [G loss: 1.000114]\n",
      "epoch:18 step:71470[D loss: 1.000012] [G loss: 1.000068]\n",
      "epoch:18 step:71475[D loss: 0.999960] [G loss: 1.000140]\n",
      "epoch:18 step:71480[D loss: 0.999959] [G loss: 1.000049]\n",
      "epoch:18 step:71485[D loss: 0.999987] [G loss: 1.000022]\n",
      "epoch:18 step:71490[D loss: 0.999993] [G loss: 1.000053]\n",
      "epoch:18 step:71495[D loss: 1.000030] [G loss: 0.999951]\n",
      "epoch:18 step:71500[D loss: 1.000011] [G loss: 1.000127]\n",
      "epoch:18 step:71505[D loss: 1.000062] [G loss: 1.000022]\n",
      "epoch:18 step:71510[D loss: 0.999964] [G loss: 1.000263]\n",
      "epoch:18 step:71515[D loss: 0.999927] [G loss: 1.000235]\n",
      "epoch:18 step:71520[D loss: 0.999902] [G loss: 1.000257]\n",
      "epoch:18 step:71525[D loss: 0.999934] [G loss: 1.000159]\n",
      "epoch:18 step:71530[D loss: 0.999959] [G loss: 1.000099]\n",
      "epoch:18 step:71535[D loss: 0.999995] [G loss: 0.999970]\n",
      "epoch:18 step:71540[D loss: 1.000114] [G loss: 0.999834]\n",
      "epoch:18 step:71545[D loss: 1.000010] [G loss: 0.999888]\n",
      "epoch:18 step:71550[D loss: 1.000118] [G loss: 0.999752]\n",
      "epoch:18 step:71555[D loss: 1.000021] [G loss: 1.000089]\n",
      "epoch:18 step:71560[D loss: 0.999898] [G loss: 1.000211]\n",
      "epoch:18 step:71565[D loss: 0.999947] [G loss: 1.000097]\n",
      "epoch:18 step:71570[D loss: 0.999932] [G loss: 1.000155]\n",
      "epoch:18 step:71575[D loss: 0.999984] [G loss: 1.000058]\n",
      "epoch:18 step:71580[D loss: 0.999977] [G loss: 1.000067]\n",
      "epoch:18 step:71585[D loss: 0.999979] [G loss: 1.000093]\n",
      "epoch:18 step:71590[D loss: 0.999973] [G loss: 1.000065]\n",
      "epoch:18 step:71595[D loss: 0.999952] [G loss: 1.000080]\n",
      "epoch:18 step:71600[D loss: 1.000092] [G loss: 0.999915]\n",
      "##############\n",
      "[0.84845514 0.87713697 0.82554445 0.83444011 0.79892413 0.84236749\n",
      " 0.83662836 0.81300943 0.8260866  0.83688245]\n",
      "##########\n",
      "epoch:18 step:71605[D loss: 0.999961] [G loss: 1.000049]\n",
      "epoch:18 step:71610[D loss: 0.999968] [G loss: 1.000062]\n",
      "epoch:18 step:71615[D loss: 0.999952] [G loss: 1.000084]\n",
      "epoch:18 step:71620[D loss: 0.999981] [G loss: 1.000043]\n",
      "epoch:18 step:71625[D loss: 0.999968] [G loss: 1.000082]\n",
      "epoch:18 step:71630[D loss: 0.999992] [G loss: 1.000056]\n",
      "epoch:18 step:71635[D loss: 0.999992] [G loss: 1.000064]\n",
      "epoch:18 step:71640[D loss: 0.999994] [G loss: 1.000061]\n",
      "epoch:18 step:71645[D loss: 0.999982] [G loss: 1.000071]\n",
      "epoch:18 step:71650[D loss: 0.999953] [G loss: 1.000123]\n",
      "epoch:18 step:71655[D loss: 1.000050] [G loss: 1.000063]\n",
      "epoch:18 step:71660[D loss: 0.999921] [G loss: 1.000184]\n",
      "epoch:18 step:71665[D loss: 1.000006] [G loss: 1.000060]\n",
      "epoch:18 step:71670[D loss: 1.000288] [G loss: 0.999646]\n",
      "epoch:18 step:71675[D loss: 0.999978] [G loss: 0.999924]\n",
      "epoch:18 step:71680[D loss: 0.999938] [G loss: 1.000100]\n",
      "epoch:18 step:71685[D loss: 0.999957] [G loss: 1.000087]\n",
      "epoch:18 step:71690[D loss: 0.999975] [G loss: 1.000062]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:18 step:71695[D loss: 1.000016] [G loss: 1.000084]\n",
      "epoch:18 step:71700[D loss: 1.000000] [G loss: 1.000077]\n",
      "epoch:18 step:71705[D loss: 0.999961] [G loss: 1.000076]\n",
      "epoch:18 step:71710[D loss: 0.999966] [G loss: 1.000065]\n",
      "epoch:18 step:71715[D loss: 0.999997] [G loss: 1.000061]\n",
      "epoch:18 step:71720[D loss: 1.000001] [G loss: 1.000037]\n",
      "epoch:18 step:71725[D loss: 1.000011] [G loss: 1.000122]\n",
      "epoch:18 step:71730[D loss: 0.999936] [G loss: 1.000054]\n",
      "epoch:18 step:71735[D loss: 1.000010] [G loss: 0.999877]\n",
      "epoch:18 step:71740[D loss: 0.999948] [G loss: 1.000155]\n",
      "epoch:18 step:71745[D loss: 1.000030] [G loss: 0.999962]\n",
      "epoch:18 step:71750[D loss: 1.000006] [G loss: 1.000015]\n",
      "epoch:18 step:71755[D loss: 0.999941] [G loss: 1.000107]\n",
      "epoch:18 step:71760[D loss: 0.999947] [G loss: 1.000136]\n",
      "epoch:18 step:71765[D loss: 0.999988] [G loss: 1.000036]\n",
      "epoch:18 step:71770[D loss: 1.000002] [G loss: 1.000024]\n",
      "epoch:18 step:71775[D loss: 1.000020] [G loss: 0.999984]\n",
      "epoch:18 step:71780[D loss: 1.000016] [G loss: 1.000035]\n",
      "epoch:18 step:71785[D loss: 1.000066] [G loss: 0.999928]\n",
      "epoch:18 step:71790[D loss: 0.999944] [G loss: 1.000138]\n",
      "epoch:18 step:71795[D loss: 0.999972] [G loss: 1.000084]\n",
      "epoch:18 step:71800[D loss: 1.000025] [G loss: 1.000014]\n",
      "##############\n",
      "[0.85926842 0.85627965 0.81627174 0.83535818 0.80106123 0.83973343\n",
      " 0.88082162 0.81560077 0.82361635 0.84189115]\n",
      "##########\n",
      "epoch:18 step:71805[D loss: 0.999962] [G loss: 1.000092]\n",
      "epoch:18 step:71810[D loss: 0.999964] [G loss: 1.000071]\n",
      "epoch:18 step:71815[D loss: 0.999967] [G loss: 1.000079]\n",
      "epoch:18 step:71820[D loss: 0.999949] [G loss: 1.000116]\n",
      "epoch:18 step:71825[D loss: 0.999985] [G loss: 1.000076]\n",
      "epoch:18 step:71830[D loss: 0.999962] [G loss: 1.000156]\n",
      "epoch:18 step:71835[D loss: 0.999934] [G loss: 1.000117]\n",
      "epoch:18 step:71840[D loss: 1.000128] [G loss: 0.999956]\n",
      "epoch:18 step:71845[D loss: 0.999966] [G loss: 1.000208]\n",
      "epoch:18 step:71850[D loss: 0.999962] [G loss: 1.000047]\n",
      "epoch:18 step:71855[D loss: 0.999920] [G loss: 1.000152]\n",
      "epoch:18 step:71860[D loss: 0.999974] [G loss: 1.000055]\n",
      "epoch:18 step:71865[D loss: 1.000067] [G loss: 0.999912]\n",
      "epoch:18 step:71870[D loss: 1.000064] [G loss: 0.999923]\n",
      "epoch:18 step:71875[D loss: 1.000033] [G loss: 0.999888]\n",
      "epoch:18 step:71880[D loss: 1.000062] [G loss: 0.999957]\n",
      "epoch:18 step:71885[D loss: 0.999944] [G loss: 1.000165]\n",
      "epoch:18 step:71890[D loss: 1.000164] [G loss: 0.999899]\n",
      "epoch:18 step:71895[D loss: 0.999753] [G loss: 1.000436]\n",
      "epoch:18 step:71900[D loss: 0.999958] [G loss: 1.000085]\n",
      "epoch:18 step:71905[D loss: 0.999996] [G loss: 1.000128]\n",
      "epoch:18 step:71910[D loss: 0.999935] [G loss: 1.000053]\n",
      "epoch:18 step:71915[D loss: 1.000127] [G loss: 0.999821]\n",
      "epoch:18 step:71920[D loss: 0.999899] [G loss: 1.000192]\n",
      "epoch:18 step:71925[D loss: 1.000060] [G loss: 0.999977]\n",
      "epoch:18 step:71930[D loss: 1.000019] [G loss: 1.000034]\n",
      "epoch:18 step:71935[D loss: 0.999943] [G loss: 1.000040]\n",
      "epoch:18 step:71940[D loss: 0.999997] [G loss: 1.000169]\n",
      "epoch:18 step:71945[D loss: 1.000097] [G loss: 0.999963]\n",
      "epoch:18 step:71950[D loss: 1.000078] [G loss: 0.999939]\n",
      "epoch:18 step:71955[D loss: 1.000028] [G loss: 0.999973]\n",
      "epoch:18 step:71960[D loss: 0.999974] [G loss: 1.000108]\n",
      "epoch:18 step:71965[D loss: 0.999990] [G loss: 1.000088]\n",
      "epoch:18 step:71970[D loss: 0.999947] [G loss: 1.000106]\n",
      "epoch:18 step:71975[D loss: 0.999932] [G loss: 1.000132]\n",
      "epoch:18 step:71980[D loss: 1.000020] [G loss: 1.000125]\n",
      "epoch:18 step:71985[D loss: 1.000021] [G loss: 1.000151]\n",
      "epoch:18 step:71990[D loss: 0.999869] [G loss: 1.000291]\n",
      "epoch:18 step:71995[D loss: 0.999910] [G loss: 1.000168]\n",
      "epoch:18 step:72000[D loss: 0.999958] [G loss: 1.000175]\n",
      "##############\n",
      "[0.85255848 0.86602864 0.85538549 0.83268996 0.81115994 0.84254192\n",
      " 0.87882473 0.8219155  0.80484164 0.86092971]\n",
      "##########\n",
      "epoch:18 step:72005[D loss: 0.999948] [G loss: 1.000101]\n",
      "epoch:18 step:72010[D loss: 0.999984] [G loss: 1.000038]\n",
      "epoch:18 step:72015[D loss: 1.000012] [G loss: 0.999984]\n",
      "epoch:18 step:72020[D loss: 0.999974] [G loss: 1.000007]\n",
      "epoch:18 step:72025[D loss: 0.999979] [G loss: 1.000030]\n",
      "epoch:18 step:72030[D loss: 0.999966] [G loss: 1.000059]\n",
      "epoch:18 step:72035[D loss: 0.999954] [G loss: 1.000080]\n",
      "epoch:18 step:72040[D loss: 1.000020] [G loss: 1.000027]\n",
      "epoch:18 step:72045[D loss: 1.000010] [G loss: 1.000019]\n",
      "epoch:18 step:72050[D loss: 1.000018] [G loss: 0.999903]\n",
      "epoch:18 step:72055[D loss: 1.000040] [G loss: 0.999973]\n",
      "epoch:18 step:72060[D loss: 0.999943] [G loss: 1.000013]\n",
      "epoch:18 step:72065[D loss: 0.999936] [G loss: 1.000160]\n",
      "epoch:18 step:72070[D loss: 0.999988] [G loss: 1.000160]\n",
      "epoch:18 step:72075[D loss: 0.999986] [G loss: 1.000096]\n",
      "epoch:18 step:72080[D loss: 0.999959] [G loss: 1.000173]\n",
      "epoch:18 step:72085[D loss: 1.000002] [G loss: 1.000065]\n",
      "epoch:18 step:72090[D loss: 0.999929] [G loss: 1.000173]\n",
      "epoch:18 step:72095[D loss: 0.999939] [G loss: 1.000226]\n",
      "epoch:18 step:72100[D loss: 1.000024] [G loss: 0.999956]\n",
      "epoch:18 step:72105[D loss: 1.000126] [G loss: 0.999931]\n",
      "epoch:18 step:72110[D loss: 0.999902] [G loss: 1.000188]\n",
      "epoch:18 step:72115[D loss: 0.999961] [G loss: 1.000215]\n",
      "epoch:18 step:72120[D loss: 0.999938] [G loss: 1.000145]\n",
      "epoch:18 step:72125[D loss: 1.000012] [G loss: 1.000004]\n",
      "epoch:18 step:72130[D loss: 0.999980] [G loss: 1.000060]\n",
      "epoch:18 step:72135[D loss: 1.000030] [G loss: 0.999992]\n",
      "epoch:18 step:72140[D loss: 1.000043] [G loss: 0.999971]\n",
      "epoch:18 step:72145[D loss: 0.999991] [G loss: 1.000042]\n",
      "epoch:18 step:72150[D loss: 1.000020] [G loss: 1.000015]\n",
      "epoch:18 step:72155[D loss: 0.999965] [G loss: 1.000175]\n",
      "epoch:18 step:72160[D loss: 0.999954] [G loss: 1.000173]\n",
      "epoch:18 step:72165[D loss: 0.999981] [G loss: 1.000089]\n",
      "epoch:18 step:72170[D loss: 0.999986] [G loss: 1.000100]\n",
      "epoch:18 step:72175[D loss: 0.999975] [G loss: 1.000123]\n",
      "epoch:18 step:72180[D loss: 0.999961] [G loss: 1.000093]\n",
      "epoch:18 step:72185[D loss: 0.999975] [G loss: 1.000055]\n",
      "epoch:18 step:72190[D loss: 1.000013] [G loss: 0.999989]\n",
      "epoch:18 step:72195[D loss: 1.000025] [G loss: 1.000077]\n",
      "epoch:18 step:72200[D loss: 1.000314] [G loss: 0.999767]\n",
      "##############\n",
      "[0.86678209 0.84885206 0.83052893 0.83065113 0.79614862 0.8397426\n",
      " 0.85989836 0.83288253 0.82136455 0.8348058 ]\n",
      "##########\n",
      "epoch:18 step:72205[D loss: 0.999941] [G loss: 1.000232]\n",
      "epoch:18 step:72210[D loss: 0.999965] [G loss: 1.000195]\n",
      "epoch:18 step:72215[D loss: 0.999957] [G loss: 1.000036]\n",
      "epoch:18 step:72220[D loss: 1.000074] [G loss: 0.999989]\n",
      "epoch:18 step:72225[D loss: 0.999992] [G loss: 1.000084]\n",
      "epoch:18 step:72230[D loss: 0.999944] [G loss: 1.000113]\n",
      "epoch:18 step:72235[D loss: 0.999938] [G loss: 1.000103]\n",
      "epoch:18 step:72240[D loss: 0.999986] [G loss: 1.000068]\n",
      "epoch:18 step:72245[D loss: 1.000081] [G loss: 0.999898]\n",
      "epoch:18 step:72250[D loss: 0.999958] [G loss: 1.000004]\n",
      "epoch:18 step:72255[D loss: 1.000008] [G loss: 0.999992]\n",
      "epoch:18 step:72260[D loss: 0.999936] [G loss: 1.000058]\n",
      "epoch:18 step:72265[D loss: 0.999984] [G loss: 1.000043]\n",
      "epoch:18 step:72270[D loss: 0.999987] [G loss: 1.000075]\n",
      "epoch:18 step:72275[D loss: 1.000025] [G loss: 1.000017]\n",
      "epoch:18 step:72280[D loss: 0.999999] [G loss: 1.000052]\n",
      "epoch:18 step:72285[D loss: 0.999957] [G loss: 1.000122]\n",
      "epoch:18 step:72290[D loss: 0.999975] [G loss: 1.000046]\n",
      "epoch:18 step:72295[D loss: 0.999956] [G loss: 1.000060]\n",
      "epoch:18 step:72300[D loss: 0.999964] [G loss: 1.000079]\n",
      "epoch:18 step:72305[D loss: 0.999972] [G loss: 1.000073]\n",
      "epoch:18 step:72310[D loss: 0.999988] [G loss: 1.000059]\n",
      "epoch:18 step:72315[D loss: 1.000017] [G loss: 0.999981]\n",
      "epoch:18 step:72320[D loss: 0.999966] [G loss: 1.000150]\n",
      "epoch:18 step:72325[D loss: 0.999957] [G loss: 1.000119]\n",
      "epoch:18 step:72330[D loss: 0.999973] [G loss: 1.000084]\n",
      "epoch:18 step:72335[D loss: 0.999939] [G loss: 1.000049]\n",
      "epoch:18 step:72340[D loss: 0.999983] [G loss: 1.000043]\n",
      "epoch:18 step:72345[D loss: 0.999972] [G loss: 1.000033]\n",
      "epoch:18 step:72350[D loss: 0.999992] [G loss: 1.000036]\n",
      "epoch:18 step:72355[D loss: 0.999940] [G loss: 1.000121]\n",
      "epoch:18 step:72360[D loss: 1.000027] [G loss: 0.999998]\n",
      "epoch:18 step:72365[D loss: 0.999987] [G loss: 1.000067]\n",
      "epoch:18 step:72370[D loss: 1.000041] [G loss: 1.000040]\n",
      "epoch:18 step:72375[D loss: 1.000023] [G loss: 0.999940]\n",
      "epoch:18 step:72380[D loss: 0.999983] [G loss: 1.000055]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:18 step:72385[D loss: 0.999931] [G loss: 1.000168]\n",
      "epoch:18 step:72390[D loss: 0.999979] [G loss: 1.000085]\n",
      "epoch:18 step:72395[D loss: 1.000042] [G loss: 1.000046]\n",
      "epoch:18 step:72400[D loss: 0.999930] [G loss: 1.000130]\n",
      "##############\n",
      "[0.8516858  0.85373976 0.83902437 0.82453945 0.80044826 0.86142576\n",
      " 0.86996611 0.84083397 0.83133437 0.86301885]\n",
      "##########\n",
      "epoch:18 step:72405[D loss: 0.999978] [G loss: 1.000088]\n",
      "epoch:18 step:72410[D loss: 1.000015] [G loss: 1.000056]\n",
      "epoch:18 step:72415[D loss: 0.999995] [G loss: 0.999998]\n",
      "epoch:18 step:72420[D loss: 0.999963] [G loss: 1.000116]\n",
      "epoch:18 step:72425[D loss: 1.000012] [G loss: 1.000047]\n",
      "epoch:18 step:72430[D loss: 0.999980] [G loss: 1.000022]\n",
      "epoch:18 step:72435[D loss: 1.000029] [G loss: 0.999981]\n",
      "epoch:18 step:72440[D loss: 0.999980] [G loss: 1.000022]\n",
      "epoch:18 step:72445[D loss: 1.000024] [G loss: 1.000020]\n",
      "epoch:18 step:72450[D loss: 0.999952] [G loss: 1.000081]\n",
      "epoch:18 step:72455[D loss: 0.999965] [G loss: 1.000004]\n",
      "epoch:18 step:72460[D loss: 0.999966] [G loss: 1.000010]\n",
      "epoch:18 step:72465[D loss: 0.999930] [G loss: 1.000126]\n",
      "epoch:18 step:72470[D loss: 0.999952] [G loss: 1.000099]\n",
      "epoch:18 step:72475[D loss: 0.999974] [G loss: 1.000046]\n",
      "epoch:18 step:72480[D loss: 0.999947] [G loss: 1.000113]\n",
      "epoch:18 step:72485[D loss: 1.000006] [G loss: 1.000025]\n",
      "epoch:18 step:72490[D loss: 0.999973] [G loss: 1.000036]\n",
      "epoch:18 step:72495[D loss: 0.999960] [G loss: 1.000061]\n",
      "epoch:18 step:72500[D loss: 0.999971] [G loss: 1.000041]\n",
      "epoch:18 step:72505[D loss: 0.999978] [G loss: 1.000030]\n",
      "epoch:18 step:72510[D loss: 0.999966] [G loss: 1.000049]\n",
      "epoch:18 step:72515[D loss: 0.999982] [G loss: 1.000032]\n",
      "epoch:18 step:72520[D loss: 0.999974] [G loss: 1.000086]\n",
      "epoch:18 step:72525[D loss: 0.999974] [G loss: 1.000107]\n",
      "epoch:18 step:72530[D loss: 0.999949] [G loss: 1.000130]\n",
      "epoch:18 step:72535[D loss: 0.999972] [G loss: 1.000078]\n",
      "epoch:18 step:72540[D loss: 1.000007] [G loss: 1.000061]\n",
      "epoch:18 step:72545[D loss: 1.000016] [G loss: 0.999984]\n",
      "epoch:18 step:72550[D loss: 1.000002] [G loss: 1.000010]\n",
      "epoch:18 step:72555[D loss: 1.000024] [G loss: 0.999972]\n",
      "epoch:18 step:72560[D loss: 0.999944] [G loss: 1.000058]\n",
      "epoch:18 step:72565[D loss: 0.999983] [G loss: 1.000080]\n",
      "epoch:18 step:72570[D loss: 0.999974] [G loss: 1.000031]\n",
      "epoch:18 step:72575[D loss: 0.999947] [G loss: 1.000123]\n",
      "epoch:18 step:72580[D loss: 0.999987] [G loss: 1.000055]\n",
      "epoch:18 step:72585[D loss: 1.000041] [G loss: 0.999958]\n",
      "epoch:18 step:72590[D loss: 0.999983] [G loss: 1.000031]\n",
      "epoch:18 step:72595[D loss: 0.999937] [G loss: 1.000079]\n",
      "epoch:18 step:72600[D loss: 0.999976] [G loss: 1.000049]\n",
      "##############\n",
      "[0.85819438 0.87868065 0.83269365 0.83659551 0.81300937 0.86699453\n",
      " 0.89295927 0.83073806 0.81954042 0.83798998]\n",
      "##########\n",
      "epoch:18 step:72605[D loss: 0.999963] [G loss: 1.000065]\n",
      "epoch:18 step:72610[D loss: 0.999971] [G loss: 1.000070]\n",
      "epoch:18 step:72615[D loss: 0.999984] [G loss: 1.000059]\n",
      "epoch:18 step:72620[D loss: 0.999956] [G loss: 1.000100]\n",
      "epoch:18 step:72625[D loss: 1.000004] [G loss: 1.000054]\n",
      "epoch:18 step:72630[D loss: 1.000007] [G loss: 1.000014]\n",
      "epoch:18 step:72635[D loss: 0.999992] [G loss: 1.000068]\n",
      "epoch:18 step:72640[D loss: 1.000007] [G loss: 1.000017]\n",
      "epoch:18 step:72645[D loss: 0.999979] [G loss: 1.000045]\n",
      "epoch:18 step:72650[D loss: 0.999977] [G loss: 1.000031]\n",
      "epoch:18 step:72655[D loss: 0.999976] [G loss: 1.000065]\n",
      "epoch:18 step:72660[D loss: 1.000007] [G loss: 1.000003]\n",
      "epoch:18 step:72665[D loss: 0.999957] [G loss: 1.000091]\n",
      "epoch:18 step:72670[D loss: 0.999935] [G loss: 1.000108]\n",
      "epoch:18 step:72675[D loss: 0.999990] [G loss: 1.000037]\n",
      "epoch:18 step:72680[D loss: 0.999973] [G loss: 1.000068]\n",
      "epoch:18 step:72685[D loss: 0.999977] [G loss: 1.000066]\n",
      "epoch:18 step:72690[D loss: 0.999971] [G loss: 1.000061]\n",
      "epoch:18 step:72695[D loss: 0.999972] [G loss: 1.000088]\n",
      "epoch:18 step:72700[D loss: 0.999969] [G loss: 1.000087]\n",
      "epoch:18 step:72705[D loss: 1.000034] [G loss: 0.999964]\n",
      "epoch:18 step:72710[D loss: 0.999962] [G loss: 1.000074]\n",
      "epoch:18 step:72715[D loss: 1.000004] [G loss: 1.000028]\n",
      "epoch:18 step:72720[D loss: 0.999962] [G loss: 1.000096]\n",
      "epoch:18 step:72725[D loss: 0.999961] [G loss: 1.000072]\n",
      "epoch:18 step:72730[D loss: 0.999961] [G loss: 1.000092]\n",
      "epoch:18 step:72735[D loss: 0.999992] [G loss: 1.000065]\n",
      "epoch:18 step:72740[D loss: 0.999985] [G loss: 1.000067]\n",
      "epoch:18 step:72745[D loss: 0.999987] [G loss: 1.000073]\n",
      "epoch:18 step:72750[D loss: 0.999976] [G loss: 1.000096]\n",
      "epoch:18 step:72755[D loss: 1.000062] [G loss: 1.000036]\n",
      "epoch:18 step:72760[D loss: 0.999970] [G loss: 1.000031]\n",
      "epoch:18 step:72765[D loss: 0.999969] [G loss: 1.000051]\n",
      "epoch:18 step:72770[D loss: 0.999994] [G loss: 1.000002]\n",
      "epoch:18 step:72775[D loss: 1.000000] [G loss: 0.999991]\n",
      "epoch:18 step:72780[D loss: 0.999916] [G loss: 1.000115]\n",
      "epoch:18 step:72785[D loss: 0.999971] [G loss: 1.000054]\n",
      "epoch:18 step:72790[D loss: 1.000048] [G loss: 0.999953]\n",
      "epoch:18 step:72795[D loss: 0.999960] [G loss: 1.000073]\n",
      "epoch:18 step:72800[D loss: 1.000013] [G loss: 0.999987]\n",
      "##############\n",
      "[0.86088479 0.87645163 0.81642491 0.83002099 0.79319096 0.81707477\n",
      " 0.87763946 0.82973055 0.82986917 0.83250625]\n",
      "##########\n",
      "epoch:18 step:72805[D loss: 0.999979] [G loss: 1.000046]\n",
      "epoch:18 step:72810[D loss: 0.999996] [G loss: 0.999948]\n",
      "epoch:18 step:72815[D loss: 0.999962] [G loss: 1.000076]\n",
      "epoch:18 step:72820[D loss: 0.999957] [G loss: 1.000057]\n",
      "epoch:18 step:72825[D loss: 0.999969] [G loss: 1.000049]\n",
      "epoch:18 step:72830[D loss: 0.999977] [G loss: 1.000055]\n",
      "epoch:18 step:72835[D loss: 0.999981] [G loss: 1.000042]\n",
      "epoch:18 step:72840[D loss: 0.999978] [G loss: 1.000092]\n",
      "epoch:18 step:72845[D loss: 0.999981] [G loss: 1.000101]\n",
      "epoch:18 step:72850[D loss: 0.999947] [G loss: 1.000085]\n",
      "epoch:18 step:72855[D loss: 1.000065] [G loss: 0.999849]\n",
      "epoch:18 step:72860[D loss: 0.999963] [G loss: 1.000015]\n",
      "epoch:18 step:72865[D loss: 1.000118] [G loss: 0.999756]\n",
      "epoch:18 step:72870[D loss: 0.999985] [G loss: 0.999991]\n",
      "epoch:18 step:72875[D loss: 0.999986] [G loss: 0.999979]\n",
      "epoch:18 step:72880[D loss: 0.999979] [G loss: 1.000047]\n",
      "epoch:18 step:72885[D loss: 0.999977] [G loss: 1.000091]\n",
      "epoch:18 step:72890[D loss: 0.999955] [G loss: 1.000126]\n",
      "epoch:18 step:72895[D loss: 0.999968] [G loss: 1.000080]\n",
      "epoch:18 step:72900[D loss: 0.999990] [G loss: 1.000025]\n",
      "epoch:18 step:72905[D loss: 1.000098] [G loss: 0.999924]\n",
      "epoch:18 step:72910[D loss: 0.999954] [G loss: 1.000112]\n",
      "epoch:18 step:72915[D loss: 0.999955] [G loss: 1.000116]\n",
      "epoch:18 step:72920[D loss: 0.999960] [G loss: 1.000056]\n",
      "epoch:18 step:72925[D loss: 0.999979] [G loss: 1.000049]\n",
      "epoch:18 step:72930[D loss: 0.999960] [G loss: 1.000045]\n",
      "epoch:18 step:72935[D loss: 0.999974] [G loss: 1.000032]\n",
      "epoch:18 step:72940[D loss: 0.999965] [G loss: 1.000068]\n",
      "epoch:18 step:72945[D loss: 0.999959] [G loss: 1.000029]\n",
      "epoch:18 step:72950[D loss: 1.000003] [G loss: 1.000003]\n",
      "epoch:18 step:72955[D loss: 0.999975] [G loss: 1.000056]\n",
      "epoch:18 step:72960[D loss: 1.000018] [G loss: 0.999985]\n",
      "epoch:18 step:72965[D loss: 0.999977] [G loss: 0.999969]\n",
      "epoch:18 step:72970[D loss: 0.999975] [G loss: 0.999987]\n",
      "epoch:18 step:72975[D loss: 0.999994] [G loss: 1.000078]\n",
      "epoch:18 step:72980[D loss: 1.000004] [G loss: 1.000082]\n",
      "epoch:18 step:72985[D loss: 0.999957] [G loss: 1.000032]\n",
      "epoch:18 step:72990[D loss: 0.999958] [G loss: 1.000040]\n",
      "epoch:18 step:72995[D loss: 0.999984] [G loss: 1.000036]\n",
      "epoch:18 step:73000[D loss: 0.999970] [G loss: 1.000061]\n",
      "##############\n",
      "[0.84027536 0.85552806 0.82323752 0.83045264 0.8055844  0.8506678\n",
      " 0.87893437 0.84316431 0.82060872 0.8516865 ]\n",
      "##########\n",
      "epoch:18 step:73005[D loss: 0.999979] [G loss: 1.000036]\n",
      "epoch:18 step:73010[D loss: 0.999992] [G loss: 1.000012]\n",
      "epoch:18 step:73015[D loss: 0.999988] [G loss: 1.000038]\n",
      "epoch:18 step:73020[D loss: 1.000045] [G loss: 0.999995]\n",
      "epoch:18 step:73025[D loss: 0.999961] [G loss: 1.000101]\n",
      "epoch:18 step:73030[D loss: 0.999988] [G loss: 1.000094]\n",
      "epoch:18 step:73035[D loss: 0.999998] [G loss: 1.000010]\n",
      "epoch:18 step:73040[D loss: 1.000016] [G loss: 1.000070]\n",
      "epoch:18 step:73045[D loss: 1.000061] [G loss: 0.999933]\n",
      "epoch:18 step:73050[D loss: 1.000025] [G loss: 1.000084]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:18 step:73055[D loss: 0.999934] [G loss: 1.000268]\n",
      "epoch:18 step:73060[D loss: 0.999970] [G loss: 1.000124]\n",
      "epoch:18 step:73065[D loss: 0.999962] [G loss: 1.000068]\n",
      "epoch:18 step:73070[D loss: 0.999972] [G loss: 1.000058]\n",
      "epoch:18 step:73075[D loss: 0.999978] [G loss: 1.000036]\n",
      "epoch:18 step:73080[D loss: 1.000018] [G loss: 0.999992]\n",
      "epoch:18 step:73085[D loss: 1.000070] [G loss: 0.999924]\n",
      "epoch:18 step:73090[D loss: 0.999918] [G loss: 1.000047]\n",
      "epoch:18 step:73095[D loss: 1.000061] [G loss: 0.999916]\n",
      "epoch:18 step:73100[D loss: 1.000105] [G loss: 0.999948]\n",
      "epoch:18 step:73105[D loss: 0.999880] [G loss: 1.000139]\n",
      "epoch:18 step:73110[D loss: 0.999948] [G loss: 1.000060]\n",
      "epoch:18 step:73115[D loss: 0.999959] [G loss: 1.000071]\n",
      "epoch:18 step:73120[D loss: 0.999957] [G loss: 1.000079]\n",
      "epoch:18 step:73125[D loss: 0.999988] [G loss: 1.000047]\n",
      "epoch:18 step:73130[D loss: 0.999896] [G loss: 1.000161]\n",
      "epoch:18 step:73135[D loss: 0.999957] [G loss: 1.000103]\n",
      "epoch:18 step:73140[D loss: 0.999978] [G loss: 1.000058]\n",
      "epoch:18 step:73145[D loss: 0.999991] [G loss: 1.000034]\n",
      "epoch:18 step:73150[D loss: 0.999948] [G loss: 1.000095]\n",
      "epoch:18 step:73155[D loss: 0.999968] [G loss: 1.000062]\n",
      "epoch:18 step:73160[D loss: 0.999964] [G loss: 1.000082]\n",
      "epoch:18 step:73165[D loss: 0.999970] [G loss: 1.000069]\n",
      "epoch:18 step:73170[D loss: 0.999983] [G loss: 1.000058]\n",
      "epoch:18 step:73175[D loss: 0.999971] [G loss: 1.000069]\n",
      "epoch:18 step:73180[D loss: 0.999980] [G loss: 1.000069]\n",
      "epoch:18 step:73185[D loss: 0.999966] [G loss: 1.000051]\n",
      "epoch:18 step:73190[D loss: 0.999969] [G loss: 1.000064]\n",
      "epoch:18 step:73195[D loss: 1.000059] [G loss: 0.999912]\n",
      "epoch:18 step:73200[D loss: 1.000005] [G loss: 1.000008]\n",
      "##############\n",
      "[0.84697898 0.84413868 0.82290615 0.83058837 0.793812   0.84358068\n",
      " 0.8959619  0.84511132 0.82617291 0.84395082]\n",
      "##########\n",
      "epoch:18 step:73205[D loss: 0.999971] [G loss: 1.000038]\n",
      "epoch:18 step:73210[D loss: 1.000011] [G loss: 1.000096]\n",
      "epoch:18 step:73215[D loss: 0.999983] [G loss: 0.999997]\n",
      "epoch:18 step:73220[D loss: 0.999933] [G loss: 1.000113]\n",
      "epoch:18 step:73225[D loss: 0.999978] [G loss: 1.000036]\n",
      "epoch:18 step:73230[D loss: 0.999991] [G loss: 1.000018]\n",
      "epoch:18 step:73235[D loss: 0.999944] [G loss: 1.000108]\n",
      "epoch:18 step:73240[D loss: 0.999987] [G loss: 1.000069]\n",
      "epoch:18 step:73245[D loss: 0.999966] [G loss: 1.000056]\n",
      "epoch:18 step:73250[D loss: 0.999998] [G loss: 0.999967]\n",
      "epoch:18 step:73255[D loss: 0.999985] [G loss: 1.000027]\n",
      "epoch:18 step:73260[D loss: 0.999956] [G loss: 1.000032]\n",
      "epoch:18 step:73265[D loss: 1.000032] [G loss: 1.000043]\n",
      "epoch:18 step:73270[D loss: 1.000109] [G loss: 0.999854]\n",
      "epoch:18 step:73275[D loss: 0.999949] [G loss: 1.000092]\n",
      "epoch:18 step:73280[D loss: 0.999974] [G loss: 1.000000]\n",
      "epoch:18 step:73285[D loss: 1.000004] [G loss: 1.000050]\n",
      "epoch:18 step:73290[D loss: 1.000045] [G loss: 0.999985]\n",
      "epoch:18 step:73295[D loss: 0.999998] [G loss: 1.000093]\n",
      "epoch:18 step:73300[D loss: 0.999902] [G loss: 1.000227]\n",
      "epoch:18 step:73305[D loss: 1.000050] [G loss: 1.000064]\n",
      "epoch:18 step:73310[D loss: 1.000116] [G loss: 0.999947]\n",
      "epoch:18 step:73315[D loss: 1.000131] [G loss: 0.999905]\n",
      "epoch:18 step:73320[D loss: 0.999909] [G loss: 1.000141]\n",
      "epoch:18 step:73325[D loss: 1.000013] [G loss: 1.000179]\n",
      "epoch:18 step:73330[D loss: 0.999883] [G loss: 1.000176]\n",
      "epoch:18 step:73335[D loss: 1.000025] [G loss: 0.999988]\n",
      "epoch:18 step:73340[D loss: 1.000054] [G loss: 0.999970]\n",
      "epoch:18 step:73345[D loss: 0.999969] [G loss: 0.999951]\n",
      "epoch:18 step:73350[D loss: 1.000029] [G loss: 0.999963]\n",
      "epoch:18 step:73355[D loss: 0.999957] [G loss: 0.999991]\n",
      "epoch:18 step:73360[D loss: 0.999917] [G loss: 1.000069]\n",
      "epoch:18 step:73365[D loss: 0.999949] [G loss: 1.000098]\n",
      "epoch:18 step:73370[D loss: 1.000013] [G loss: 1.000036]\n",
      "epoch:18 step:73375[D loss: 1.000004] [G loss: 1.000028]\n",
      "epoch:18 step:73380[D loss: 0.999952] [G loss: 1.000098]\n",
      "epoch:18 step:73385[D loss: 0.999977] [G loss: 1.000069]\n",
      "epoch:18 step:73390[D loss: 0.999962] [G loss: 1.000053]\n",
      "epoch:18 step:73395[D loss: 0.999995] [G loss: 1.000061]\n",
      "epoch:18 step:73400[D loss: 1.000115] [G loss: 0.999827]\n",
      "##############\n",
      "[0.85381044 0.85420904 0.83954668 0.82762501 0.78529052 0.82456712\n",
      " 0.90424073 0.83237762 0.83378918 0.84233865]\n",
      "##########\n",
      "epoch:18 step:73405[D loss: 0.999968] [G loss: 1.000060]\n",
      "epoch:18 step:73410[D loss: 1.000076] [G loss: 0.999964]\n",
      "epoch:18 step:73415[D loss: 0.999895] [G loss: 1.000216]\n",
      "epoch:18 step:73420[D loss: 0.999956] [G loss: 1.000107]\n",
      "epoch:18 step:73425[D loss: 0.999965] [G loss: 1.000072]\n",
      "epoch:18 step:73430[D loss: 0.999998] [G loss: 1.000036]\n",
      "epoch:18 step:73435[D loss: 1.000020] [G loss: 1.000014]\n",
      "epoch:18 step:73440[D loss: 1.000007] [G loss: 0.999969]\n",
      "epoch:18 step:73445[D loss: 0.999937] [G loss: 1.000106]\n",
      "epoch:18 step:73450[D loss: 0.999946] [G loss: 1.000096]\n",
      "epoch:18 step:73455[D loss: 0.999955] [G loss: 1.000108]\n",
      "epoch:18 step:73460[D loss: 0.999892] [G loss: 1.000141]\n",
      "epoch:18 step:73465[D loss: 0.999988] [G loss: 1.000040]\n",
      "epoch:18 step:73470[D loss: 0.999995] [G loss: 1.000064]\n",
      "epoch:18 step:73475[D loss: 1.000053] [G loss: 0.999969]\n",
      "epoch:18 step:73480[D loss: 0.999988] [G loss: 1.000014]\n",
      "epoch:18 step:73485[D loss: 0.999992] [G loss: 1.000024]\n",
      "epoch:18 step:73490[D loss: 1.000005] [G loss: 1.000051]\n",
      "epoch:18 step:73495[D loss: 1.000002] [G loss: 1.000000]\n",
      "epoch:18 step:73500[D loss: 0.999961] [G loss: 1.000121]\n",
      "epoch:18 step:73505[D loss: 1.000020] [G loss: 1.000038]\n",
      "epoch:18 step:73510[D loss: 1.000052] [G loss: 0.999874]\n",
      "epoch:18 step:73515[D loss: 0.999956] [G loss: 1.000023]\n",
      "epoch:18 step:73520[D loss: 1.000024] [G loss: 0.999923]\n",
      "epoch:18 step:73525[D loss: 1.000001] [G loss: 1.000061]\n",
      "epoch:18 step:73530[D loss: 1.000007] [G loss: 1.000039]\n",
      "epoch:18 step:73535[D loss: 1.000018] [G loss: 1.000021]\n",
      "epoch:18 step:73540[D loss: 0.999996] [G loss: 1.000090]\n",
      "epoch:18 step:73545[D loss: 1.000036] [G loss: 1.000157]\n",
      "epoch:18 step:73550[D loss: 0.999988] [G loss: 1.000091]\n",
      "epoch:18 step:73555[D loss: 0.999955] [G loss: 1.000188]\n",
      "epoch:18 step:73560[D loss: 0.999990] [G loss: 1.000107]\n",
      "epoch:18 step:73565[D loss: 0.999953] [G loss: 1.000070]\n",
      "epoch:18 step:73570[D loss: 0.999987] [G loss: 1.000093]\n",
      "epoch:18 step:73575[D loss: 0.999951] [G loss: 1.000109]\n",
      "epoch:18 step:73580[D loss: 0.999960] [G loss: 1.000107]\n",
      "epoch:18 step:73585[D loss: 1.000019] [G loss: 0.999980]\n",
      "epoch:18 step:73590[D loss: 1.000067] [G loss: 0.999956]\n",
      "epoch:18 step:73595[D loss: 1.000082] [G loss: 0.999932]\n",
      "epoch:18 step:73600[D loss: 0.999954] [G loss: 1.000060]\n",
      "##############\n",
      "[0.86420466 0.85097788 0.82098971 0.8420801  0.77916879 0.84887373\n",
      " 0.88961872 0.84428442 0.8388969  0.83276082]\n",
      "##########\n",
      "epoch:18 step:73605[D loss: 0.999972] [G loss: 1.000152]\n",
      "epoch:18 step:73610[D loss: 0.999932] [G loss: 1.000068]\n",
      "epoch:18 step:73615[D loss: 0.999981] [G loss: 1.000073]\n",
      "epoch:18 step:73620[D loss: 0.999932] [G loss: 1.000126]\n",
      "epoch:18 step:73625[D loss: 0.999994] [G loss: 1.000075]\n",
      "epoch:18 step:73630[D loss: 0.999959] [G loss: 1.000090]\n",
      "epoch:18 step:73635[D loss: 0.999988] [G loss: 1.000028]\n",
      "epoch:18 step:73640[D loss: 1.000081] [G loss: 0.999840]\n",
      "epoch:18 step:73645[D loss: 0.999974] [G loss: 0.999989]\n",
      "epoch:18 step:73650[D loss: 1.000016] [G loss: 1.000031]\n",
      "epoch:18 step:73655[D loss: 1.000003] [G loss: 1.000084]\n",
      "epoch:18 step:73660[D loss: 0.999998] [G loss: 0.999973]\n",
      "epoch:18 step:73665[D loss: 1.000004] [G loss: 1.000055]\n",
      "epoch:18 step:73670[D loss: 1.000007] [G loss: 1.000047]\n",
      "epoch:18 step:73675[D loss: 0.999976] [G loss: 1.000069]\n",
      "epoch:18 step:73680[D loss: 0.999980] [G loss: 1.000036]\n",
      "epoch:18 step:73685[D loss: 0.999967] [G loss: 1.000074]\n",
      "epoch:18 step:73690[D loss: 0.999994] [G loss: 1.000019]\n",
      "epoch:18 step:73695[D loss: 0.999989] [G loss: 1.000096]\n",
      "epoch:18 step:73700[D loss: 0.999984] [G loss: 1.000036]\n",
      "epoch:18 step:73705[D loss: 0.999989] [G loss: 1.000071]\n",
      "epoch:18 step:73710[D loss: 0.999962] [G loss: 1.000068]\n",
      "epoch:18 step:73715[D loss: 0.999947] [G loss: 1.000098]\n",
      "epoch:18 step:73720[D loss: 0.999983] [G loss: 1.000108]\n",
      "epoch:18 step:73725[D loss: 0.999987] [G loss: 1.000083]\n",
      "epoch:18 step:73730[D loss: 0.999994] [G loss: 1.000039]\n",
      "epoch:18 step:73735[D loss: 1.000000] [G loss: 1.000100]\n",
      "epoch:18 step:73740[D loss: 0.999941] [G loss: 1.000137]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:18 step:73745[D loss: 0.999963] [G loss: 1.000069]\n",
      "epoch:18 step:73750[D loss: 1.000064] [G loss: 0.999959]\n",
      "epoch:18 step:73755[D loss: 1.000061] [G loss: 0.999930]\n",
      "epoch:18 step:73760[D loss: 0.999958] [G loss: 1.000196]\n",
      "epoch:18 step:73765[D loss: 1.000012] [G loss: 1.000099]\n",
      "epoch:18 step:73770[D loss: 0.999885] [G loss: 1.000225]\n",
      "epoch:18 step:73775[D loss: 0.999955] [G loss: 1.000120]\n",
      "epoch:18 step:73780[D loss: 0.999970] [G loss: 1.000093]\n",
      "epoch:18 step:73785[D loss: 0.999984] [G loss: 1.000120]\n",
      "epoch:18 step:73790[D loss: 0.999961] [G loss: 1.000134]\n",
      "epoch:18 step:73795[D loss: 0.999983] [G loss: 1.000086]\n",
      "epoch:18 step:73800[D loss: 0.999963] [G loss: 1.000092]\n",
      "##############\n",
      "[0.85595893 0.86143036 0.81703476 0.81103028 0.81507661 0.84823247\n",
      " 0.878656   0.8440297  0.83339535 0.84523386]\n",
      "##########\n",
      "epoch:18 step:73805[D loss: 0.999987] [G loss: 1.000001]\n",
      "epoch:18 step:73810[D loss: 1.000053] [G loss: 0.999965]\n",
      "epoch:18 step:73815[D loss: 0.999959] [G loss: 1.000074]\n",
      "epoch:18 step:73820[D loss: 1.000030] [G loss: 1.000023]\n",
      "epoch:18 step:73825[D loss: 1.000045] [G loss: 0.999963]\n",
      "epoch:18 step:73830[D loss: 0.999965] [G loss: 0.999994]\n",
      "epoch:18 step:73835[D loss: 0.999962] [G loss: 1.000101]\n",
      "epoch:18 step:73840[D loss: 1.000001] [G loss: 0.999987]\n",
      "epoch:18 step:73845[D loss: 0.999955] [G loss: 1.000092]\n",
      "epoch:18 step:73850[D loss: 1.000010] [G loss: 0.999998]\n",
      "epoch:18 step:73855[D loss: 0.999986] [G loss: 1.000052]\n",
      "epoch:18 step:73860[D loss: 0.999963] [G loss: 1.000084]\n",
      "epoch:18 step:73865[D loss: 0.999982] [G loss: 1.000085]\n",
      "epoch:18 step:73870[D loss: 0.999996] [G loss: 1.000038]\n",
      "epoch:18 step:73875[D loss: 0.999950] [G loss: 1.000124]\n",
      "epoch:18 step:73880[D loss: 1.000037] [G loss: 1.000009]\n",
      "epoch:18 step:73885[D loss: 1.000082] [G loss: 0.999882]\n",
      "epoch:18 step:73890[D loss: 0.999914] [G loss: 1.000104]\n",
      "epoch:18 step:73895[D loss: 0.999982] [G loss: 1.000050]\n",
      "epoch:18 step:73900[D loss: 1.000054] [G loss: 0.999953]\n",
      "epoch:18 step:73905[D loss: 1.000152] [G loss: 0.999890]\n",
      "epoch:18 step:73910[D loss: 0.999987] [G loss: 1.000035]\n",
      "epoch:18 step:73915[D loss: 0.999979] [G loss: 0.999985]\n",
      "epoch:18 step:73920[D loss: 0.999954] [G loss: 1.000037]\n",
      "epoch:18 step:73925[D loss: 0.999956] [G loss: 1.000066]\n",
      "epoch:18 step:73930[D loss: 0.999987] [G loss: 1.000103]\n",
      "epoch:18 step:73935[D loss: 1.000009] [G loss: 1.000089]\n",
      "epoch:18 step:73940[D loss: 0.999927] [G loss: 1.000147]\n",
      "epoch:18 step:73945[D loss: 0.999999] [G loss: 1.000066]\n",
      "epoch:18 step:73950[D loss: 0.999952] [G loss: 1.000095]\n",
      "epoch:18 step:73955[D loss: 0.999978] [G loss: 1.000068]\n",
      "epoch:18 step:73960[D loss: 0.999925] [G loss: 1.000140]\n",
      "epoch:18 step:73965[D loss: 0.999982] [G loss: 1.000034]\n",
      "epoch:18 step:73970[D loss: 0.999956] [G loss: 1.000094]\n",
      "epoch:18 step:73975[D loss: 0.999974] [G loss: 1.000037]\n",
      "epoch:18 step:73980[D loss: 0.999976] [G loss: 1.000020]\n",
      "epoch:18 step:73985[D loss: 1.000005] [G loss: 1.000021]\n",
      "epoch:18 step:73990[D loss: 0.999965] [G loss: 1.000107]\n",
      "epoch:18 step:73995[D loss: 0.999954] [G loss: 1.000127]\n",
      "epoch:18 step:74000[D loss: 0.999984] [G loss: 1.000067]\n",
      "##############\n",
      "[0.85816259 0.86725108 0.82700292 0.82876208 0.76572467 0.85101178\n",
      " 0.88402004 0.84015174 0.81997103 0.83788039]\n",
      "##########\n",
      "epoch:18 step:74005[D loss: 0.999973] [G loss: 1.000083]\n",
      "epoch:18 step:74010[D loss: 0.999964] [G loss: 1.000076]\n",
      "epoch:18 step:74015[D loss: 0.999998] [G loss: 1.000029]\n",
      "epoch:18 step:74020[D loss: 0.999989] [G loss: 1.000052]\n",
      "epoch:18 step:74025[D loss: 0.999977] [G loss: 1.000059]\n",
      "epoch:18 step:74030[D loss: 0.999972] [G loss: 1.000075]\n",
      "epoch:18 step:74035[D loss: 0.999972] [G loss: 1.000079]\n",
      "epoch:18 step:74040[D loss: 0.999968] [G loss: 1.000096]\n",
      "epoch:18 step:74045[D loss: 0.999989] [G loss: 1.000079]\n",
      "epoch:18 step:74050[D loss: 0.999988] [G loss: 1.000057]\n",
      "epoch:18 step:74055[D loss: 0.999998] [G loss: 1.000061]\n",
      "epoch:18 step:74060[D loss: 1.000011] [G loss: 1.000042]\n",
      "epoch:18 step:74065[D loss: 0.999969] [G loss: 1.000012]\n",
      "epoch:18 step:74070[D loss: 0.999977] [G loss: 1.000064]\n",
      "epoch:18 step:74075[D loss: 0.999970] [G loss: 1.000056]\n",
      "epoch:18 step:74080[D loss: 0.999965] [G loss: 1.000087]\n",
      "epoch:18 step:74085[D loss: 1.000037] [G loss: 1.000061]\n",
      "epoch:18 step:74090[D loss: 1.000009] [G loss: 1.000100]\n",
      "epoch:18 step:74095[D loss: 1.000029] [G loss: 1.000040]\n",
      "epoch:18 step:74100[D loss: 1.000027] [G loss: 1.000033]\n",
      "epoch:18 step:74105[D loss: 0.999927] [G loss: 1.000116]\n",
      "epoch:18 step:74110[D loss: 1.000029] [G loss: 1.000007]\n",
      "epoch:18 step:74115[D loss: 0.999958] [G loss: 1.000061]\n",
      "epoch:18 step:74120[D loss: 0.999998] [G loss: 1.000007]\n",
      "epoch:18 step:74125[D loss: 0.999994] [G loss: 1.000047]\n",
      "epoch:18 step:74130[D loss: 0.999973] [G loss: 1.000092]\n",
      "epoch:18 step:74135[D loss: 0.999924] [G loss: 1.000108]\n",
      "epoch:18 step:74140[D loss: 0.999966] [G loss: 1.000016]\n",
      "epoch:18 step:74145[D loss: 0.999963] [G loss: 1.000106]\n",
      "epoch:18 step:74150[D loss: 0.999961] [G loss: 1.000119]\n",
      "epoch:18 step:74155[D loss: 0.999984] [G loss: 0.999988]\n",
      "epoch:18 step:74160[D loss: 0.999995] [G loss: 1.000115]\n",
      "epoch:18 step:74165[D loss: 0.999883] [G loss: 1.000236]\n",
      "epoch:18 step:74170[D loss: 0.999988] [G loss: 1.000088]\n",
      "epoch:18 step:74175[D loss: 0.999978] [G loss: 1.000051]\n",
      "epoch:18 step:74180[D loss: 0.999941] [G loss: 1.000076]\n",
      "epoch:18 step:74185[D loss: 1.000045] [G loss: 0.999972]\n",
      "epoch:18 step:74190[D loss: 0.999945] [G loss: 1.000105]\n",
      "epoch:18 step:74195[D loss: 0.999991] [G loss: 1.000050]\n",
      "epoch:19 step:74200[D loss: 0.999958] [G loss: 1.000055]\n",
      "##############\n",
      "[0.84800213 0.85065735 0.82243317 0.82845667 0.77863447 0.84584116\n",
      " 0.87494091 0.82548542 0.82866534 0.85146927]\n",
      "##########\n",
      "epoch:19 step:74205[D loss: 0.999929] [G loss: 1.000069]\n",
      "epoch:19 step:74210[D loss: 1.000028] [G loss: 0.999871]\n",
      "epoch:19 step:74215[D loss: 0.999983] [G loss: 0.999974]\n",
      "epoch:19 step:74220[D loss: 0.999970] [G loss: 1.000057]\n",
      "epoch:19 step:74225[D loss: 0.999980] [G loss: 1.000077]\n",
      "epoch:19 step:74230[D loss: 0.999979] [G loss: 0.999984]\n",
      "epoch:19 step:74235[D loss: 0.999946] [G loss: 1.000062]\n",
      "epoch:19 step:74240[D loss: 0.999998] [G loss: 1.000017]\n",
      "epoch:19 step:74245[D loss: 0.999980] [G loss: 1.000021]\n",
      "epoch:19 step:74250[D loss: 0.999996] [G loss: 1.000020]\n",
      "epoch:19 step:74255[D loss: 1.000006] [G loss: 1.000015]\n",
      "epoch:19 step:74260[D loss: 0.999972] [G loss: 1.000043]\n",
      "epoch:19 step:74265[D loss: 0.999974] [G loss: 1.000015]\n",
      "epoch:19 step:74270[D loss: 1.000035] [G loss: 1.000020]\n",
      "epoch:19 step:74275[D loss: 0.999948] [G loss: 1.000067]\n",
      "epoch:19 step:74280[D loss: 0.999915] [G loss: 1.000178]\n",
      "epoch:19 step:74285[D loss: 0.999906] [G loss: 1.000218]\n",
      "epoch:19 step:74290[D loss: 0.999963] [G loss: 1.000094]\n",
      "epoch:19 step:74295[D loss: 0.999984] [G loss: 1.000104]\n",
      "epoch:19 step:74300[D loss: 0.999936] [G loss: 1.000082]\n",
      "epoch:19 step:74305[D loss: 1.000069] [G loss: 0.999837]\n",
      "epoch:19 step:74310[D loss: 0.999993] [G loss: 0.999991]\n",
      "epoch:19 step:74315[D loss: 1.000195] [G loss: 0.999800]\n",
      "epoch:19 step:74320[D loss: 1.000001] [G loss: 0.999968]\n",
      "epoch:19 step:74325[D loss: 0.999930] [G loss: 1.000135]\n",
      "epoch:19 step:74330[D loss: 0.999979] [G loss: 0.999997]\n",
      "epoch:19 step:74335[D loss: 0.999952] [G loss: 1.000211]\n",
      "epoch:19 step:74340[D loss: 0.999933] [G loss: 1.000105]\n",
      "epoch:19 step:74345[D loss: 1.000051] [G loss: 0.999874]\n",
      "epoch:19 step:74350[D loss: 0.999921] [G loss: 1.000008]\n",
      "epoch:19 step:74355[D loss: 1.000038] [G loss: 0.999895]\n",
      "epoch:19 step:74360[D loss: 0.999976] [G loss: 0.999983]\n",
      "epoch:19 step:74365[D loss: 0.999978] [G loss: 1.000020]\n",
      "epoch:19 step:74370[D loss: 1.000097] [G loss: 0.999880]\n",
      "epoch:19 step:74375[D loss: 0.999961] [G loss: 1.000132]\n",
      "epoch:19 step:74380[D loss: 0.999952] [G loss: 1.000091]\n",
      "epoch:19 step:74385[D loss: 0.999952] [G loss: 1.000104]\n",
      "epoch:19 step:74390[D loss: 0.999965] [G loss: 1.000144]\n",
      "epoch:19 step:74395[D loss: 0.999977] [G loss: 1.000158]\n",
      "epoch:19 step:74400[D loss: 0.999996] [G loss: 1.000036]\n",
      "##############\n",
      "[0.85442781 0.8759043  0.82779505 0.84301501 0.79914501 0.83826851\n",
      " 0.86248171 0.8541466  0.85044094 0.84137095]\n",
      "##########\n",
      "epoch:19 step:74405[D loss: 0.999990] [G loss: 1.000070]\n",
      "epoch:19 step:74410[D loss: 0.999933] [G loss: 1.000080]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:19 step:74415[D loss: 0.999958] [G loss: 1.000133]\n",
      "epoch:19 step:74420[D loss: 0.999992] [G loss: 1.000103]\n",
      "epoch:19 step:74425[D loss: 0.999978] [G loss: 1.000067]\n",
      "epoch:19 step:74430[D loss: 0.999998] [G loss: 1.000084]\n",
      "epoch:19 step:74435[D loss: 0.999979] [G loss: 1.000074]\n",
      "epoch:19 step:74440[D loss: 1.000007] [G loss: 1.000040]\n",
      "epoch:19 step:74445[D loss: 0.999993] [G loss: 1.000018]\n",
      "epoch:19 step:74450[D loss: 0.999957] [G loss: 1.000048]\n",
      "epoch:19 step:74455[D loss: 0.999972] [G loss: 1.000061]\n",
      "epoch:19 step:74460[D loss: 0.999972] [G loss: 1.000075]\n",
      "epoch:19 step:74465[D loss: 0.999948] [G loss: 1.000090]\n",
      "epoch:19 step:74470[D loss: 0.999989] [G loss: 1.000061]\n",
      "epoch:19 step:74475[D loss: 0.999983] [G loss: 1.000070]\n",
      "epoch:19 step:74480[D loss: 0.999924] [G loss: 1.000101]\n",
      "epoch:19 step:74485[D loss: 0.999970] [G loss: 1.000044]\n",
      "epoch:19 step:74490[D loss: 0.999968] [G loss: 1.000083]\n",
      "epoch:19 step:74495[D loss: 0.999969] [G loss: 1.000103]\n",
      "epoch:19 step:74500[D loss: 0.999894] [G loss: 1.000191]\n",
      "epoch:19 step:74505[D loss: 0.999962] [G loss: 1.000058]\n",
      "epoch:19 step:74510[D loss: 0.999960] [G loss: 1.000085]\n",
      "epoch:19 step:74515[D loss: 0.999947] [G loss: 1.000115]\n",
      "epoch:19 step:74520[D loss: 0.999946] [G loss: 1.000099]\n",
      "epoch:19 step:74525[D loss: 0.999963] [G loss: 1.000080]\n",
      "epoch:19 step:74530[D loss: 0.999970] [G loss: 1.000053]\n",
      "epoch:19 step:74535[D loss: 0.999989] [G loss: 1.000052]\n",
      "epoch:19 step:74540[D loss: 0.999959] [G loss: 1.000074]\n",
      "epoch:19 step:74545[D loss: 0.999977] [G loss: 1.000068]\n",
      "epoch:19 step:74550[D loss: 1.000095] [G loss: 0.999953]\n",
      "epoch:19 step:74555[D loss: 1.000043] [G loss: 1.000050]\n",
      "epoch:19 step:74560[D loss: 0.999959] [G loss: 1.000093]\n",
      "epoch:19 step:74565[D loss: 0.999979] [G loss: 1.000015]\n",
      "epoch:19 step:74570[D loss: 1.000004] [G loss: 1.000087]\n",
      "epoch:19 step:74575[D loss: 0.999975] [G loss: 1.000044]\n",
      "epoch:19 step:74580[D loss: 0.999971] [G loss: 1.000081]\n",
      "epoch:19 step:74585[D loss: 0.999970] [G loss: 1.000066]\n",
      "epoch:19 step:74590[D loss: 0.999962] [G loss: 1.000088]\n",
      "epoch:19 step:74595[D loss: 0.999948] [G loss: 1.000072]\n",
      "epoch:19 step:74600[D loss: 0.999993] [G loss: 0.999994]\n",
      "##############\n",
      "[0.88270265 0.87977654 0.81560544 0.82301866 0.80400604 0.8406257\n",
      " 0.89123601 0.85102316 0.84304017 0.83555695]\n",
      "##########\n",
      "epoch:19 step:74605[D loss: 1.000027] [G loss: 0.999948]\n",
      "epoch:19 step:74610[D loss: 0.999956] [G loss: 1.000077]\n",
      "epoch:19 step:74615[D loss: 1.000057] [G loss: 0.999946]\n",
      "epoch:19 step:74620[D loss: 0.999945] [G loss: 1.000069]\n",
      "epoch:19 step:74625[D loss: 0.999999] [G loss: 1.000072]\n",
      "epoch:19 step:74630[D loss: 0.999989] [G loss: 1.000090]\n",
      "epoch:19 step:74635[D loss: 0.999969] [G loss: 1.000082]\n",
      "epoch:19 step:74640[D loss: 0.999955] [G loss: 1.000202]\n",
      "epoch:19 step:74645[D loss: 0.999977] [G loss: 1.000052]\n",
      "epoch:19 step:74650[D loss: 1.000011] [G loss: 0.999965]\n",
      "epoch:19 step:74655[D loss: 0.999974] [G loss: 0.999996]\n",
      "epoch:19 step:74660[D loss: 0.999960] [G loss: 1.000085]\n",
      "epoch:19 step:74665[D loss: 0.999951] [G loss: 1.000097]\n",
      "epoch:19 step:74670[D loss: 0.999983] [G loss: 1.000048]\n",
      "epoch:19 step:74675[D loss: 1.000054] [G loss: 1.000018]\n",
      "epoch:19 step:74680[D loss: 0.999923] [G loss: 1.000100]\n",
      "epoch:19 step:74685[D loss: 0.999957] [G loss: 1.000207]\n",
      "epoch:19 step:74690[D loss: 1.000031] [G loss: 0.999989]\n",
      "epoch:19 step:74695[D loss: 0.999905] [G loss: 1.000250]\n",
      "epoch:19 step:74700[D loss: 0.999949] [G loss: 1.000076]\n",
      "epoch:19 step:74705[D loss: 0.999990] [G loss: 1.000106]\n",
      "epoch:19 step:74710[D loss: 0.999950] [G loss: 1.000075]\n",
      "epoch:19 step:74715[D loss: 1.000041] [G loss: 0.999975]\n",
      "epoch:19 step:74720[D loss: 1.000063] [G loss: 0.999903]\n",
      "epoch:19 step:74725[D loss: 1.000058] [G loss: 0.999969]\n",
      "epoch:19 step:74730[D loss: 0.999930] [G loss: 1.000211]\n",
      "epoch:19 step:74735[D loss: 1.000067] [G loss: 1.000009]\n",
      "epoch:19 step:74740[D loss: 0.999901] [G loss: 1.000216]\n",
      "epoch:19 step:74745[D loss: 1.000005] [G loss: 1.000168]\n",
      "epoch:19 step:74750[D loss: 0.999867] [G loss: 1.000251]\n",
      "epoch:19 step:74755[D loss: 0.999951] [G loss: 1.000114]\n",
      "epoch:19 step:74760[D loss: 0.999963] [G loss: 1.000065]\n",
      "epoch:19 step:74765[D loss: 0.999997] [G loss: 1.000045]\n",
      "epoch:19 step:74770[D loss: 0.999990] [G loss: 1.000045]\n",
      "epoch:19 step:74775[D loss: 0.999985] [G loss: 1.000024]\n",
      "epoch:19 step:74780[D loss: 1.000011] [G loss: 1.000110]\n",
      "epoch:19 step:74785[D loss: 0.999959] [G loss: 1.000082]\n",
      "epoch:19 step:74790[D loss: 0.999971] [G loss: 1.000071]\n",
      "epoch:19 step:74795[D loss: 0.999988] [G loss: 1.000110]\n",
      "epoch:19 step:74800[D loss: 0.999981] [G loss: 1.000114]\n",
      "##############\n",
      "[0.84428912 0.85824367 0.82714792 0.8320953  0.78666732 0.82917917\n",
      " 0.90028831 0.84311695 0.83242584 0.82227251]\n",
      "##########\n",
      "epoch:19 step:74805[D loss: 0.999964] [G loss: 1.000125]\n",
      "epoch:19 step:74810[D loss: 0.999951] [G loss: 1.000110]\n",
      "epoch:19 step:74815[D loss: 0.999971] [G loss: 1.000104]\n",
      "epoch:19 step:74820[D loss: 0.999989] [G loss: 1.000074]\n",
      "epoch:19 step:74825[D loss: 0.999974] [G loss: 1.000097]\n",
      "epoch:19 step:74830[D loss: 0.999960] [G loss: 1.000092]\n",
      "epoch:19 step:74835[D loss: 0.999979] [G loss: 1.000092]\n",
      "epoch:19 step:74840[D loss: 1.000013] [G loss: 0.999994]\n",
      "epoch:19 step:74845[D loss: 0.999966] [G loss: 1.000047]\n",
      "epoch:19 step:74850[D loss: 1.000014] [G loss: 1.000043]\n",
      "epoch:19 step:74855[D loss: 0.999980] [G loss: 1.000069]\n",
      "epoch:19 step:74860[D loss: 1.000055] [G loss: 0.999937]\n",
      "epoch:19 step:74865[D loss: 1.000138] [G loss: 0.999913]\n",
      "epoch:19 step:74870[D loss: 1.000023] [G loss: 0.999999]\n",
      "epoch:19 step:74875[D loss: 1.000006] [G loss: 1.000138]\n",
      "epoch:19 step:74880[D loss: 0.999953] [G loss: 1.000003]\n",
      "epoch:19 step:74885[D loss: 1.000022] [G loss: 1.000061]\n",
      "epoch:19 step:74890[D loss: 0.999952] [G loss: 1.000076]\n",
      "epoch:19 step:74895[D loss: 0.999976] [G loss: 1.000110]\n",
      "epoch:19 step:74900[D loss: 1.000119] [G loss: 0.999848]\n",
      "epoch:19 step:74905[D loss: 0.999947] [G loss: 1.000040]\n",
      "epoch:19 step:74910[D loss: 1.000013] [G loss: 0.999965]\n",
      "epoch:19 step:74915[D loss: 1.000034] [G loss: 1.000091]\n",
      "epoch:19 step:74920[D loss: 0.999874] [G loss: 1.000095]\n",
      "epoch:19 step:74925[D loss: 1.000009] [G loss: 1.000009]\n",
      "epoch:19 step:74930[D loss: 0.999925] [G loss: 1.000126]\n",
      "epoch:19 step:74935[D loss: 0.999972] [G loss: 1.000055]\n",
      "epoch:19 step:74940[D loss: 0.999991] [G loss: 1.000034]\n",
      "epoch:19 step:74945[D loss: 1.000001] [G loss: 1.000023]\n",
      "epoch:19 step:74950[D loss: 0.999969] [G loss: 1.000103]\n",
      "epoch:19 step:74955[D loss: 1.000049] [G loss: 0.999951]\n",
      "epoch:19 step:74960[D loss: 0.999968] [G loss: 1.000030]\n",
      "epoch:19 step:74965[D loss: 0.999962] [G loss: 1.000039]\n",
      "epoch:19 step:74970[D loss: 0.999947] [G loss: 1.000063]\n",
      "epoch:19 step:74975[D loss: 0.999984] [G loss: 1.000063]\n",
      "epoch:19 step:74980[D loss: 0.999961] [G loss: 1.000079]\n",
      "epoch:19 step:74985[D loss: 0.999962] [G loss: 1.000056]\n",
      "epoch:19 step:74990[D loss: 1.000019] [G loss: 1.000022]\n",
      "epoch:19 step:74995[D loss: 0.999976] [G loss: 0.999993]\n",
      "epoch:19 step:75000[D loss: 0.999966] [G loss: 1.000058]\n",
      "##############\n",
      "[0.85679254 0.85050688 0.82881347 0.82834086 0.82434963 0.85414576\n",
      " 0.85471848 0.83803762 0.80582805 0.82991255]\n",
      "##########\n",
      "epoch:19 step:75005[D loss: 0.999956] [G loss: 1.000064]\n",
      "epoch:19 step:75010[D loss: 0.999969] [G loss: 1.000062]\n",
      "epoch:19 step:75015[D loss: 0.999981] [G loss: 1.000049]\n",
      "epoch:19 step:75020[D loss: 0.999953] [G loss: 1.000101]\n",
      "epoch:19 step:75025[D loss: 0.999988] [G loss: 1.000044]\n",
      "epoch:19 step:75030[D loss: 0.999976] [G loss: 1.000057]\n",
      "epoch:19 step:75035[D loss: 0.999987] [G loss: 1.000049]\n",
      "epoch:19 step:75040[D loss: 0.999982] [G loss: 1.000056]\n",
      "epoch:19 step:75045[D loss: 0.999985] [G loss: 1.000093]\n",
      "epoch:19 step:75050[D loss: 0.999993] [G loss: 1.000104]\n",
      "epoch:19 step:75055[D loss: 0.999935] [G loss: 1.000142]\n",
      "epoch:19 step:75060[D loss: 0.999961] [G loss: 1.000075]\n",
      "epoch:19 step:75065[D loss: 0.999994] [G loss: 1.000034]\n",
      "epoch:19 step:75070[D loss: 1.000030] [G loss: 0.999976]\n",
      "epoch:19 step:75075[D loss: 0.999994] [G loss: 1.000266]\n",
      "epoch:19 step:75080[D loss: 0.999941] [G loss: 0.999967]\n",
      "epoch:19 step:75085[D loss: 0.999918] [G loss: 1.000133]\n",
      "epoch:19 step:75090[D loss: 0.999895] [G loss: 1.000248]\n",
      "epoch:19 step:75095[D loss: 1.000007] [G loss: 1.000069]\n",
      "epoch:19 step:75100[D loss: 0.999959] [G loss: 1.000058]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:19 step:75105[D loss: 0.999992] [G loss: 1.000030]\n",
      "epoch:19 step:75110[D loss: 1.000075] [G loss: 0.999968]\n",
      "epoch:19 step:75115[D loss: 0.999947] [G loss: 1.000044]\n",
      "epoch:19 step:75120[D loss: 1.000052] [G loss: 0.999992]\n",
      "epoch:19 step:75125[D loss: 0.999906] [G loss: 1.000060]\n",
      "epoch:19 step:75130[D loss: 0.999967] [G loss: 1.000051]\n",
      "epoch:19 step:75135[D loss: 0.999972] [G loss: 1.000041]\n",
      "epoch:19 step:75140[D loss: 0.999997] [G loss: 1.000028]\n",
      "epoch:19 step:75145[D loss: 1.000020] [G loss: 0.999987]\n",
      "epoch:19 step:75150[D loss: 0.999951] [G loss: 1.000010]\n",
      "epoch:19 step:75155[D loss: 0.999974] [G loss: 1.000090]\n",
      "epoch:19 step:75160[D loss: 0.999970] [G loss: 1.000070]\n",
      "epoch:19 step:75165[D loss: 0.999982] [G loss: 1.000033]\n",
      "epoch:19 step:75170[D loss: 0.999957] [G loss: 1.000085]\n",
      "epoch:19 step:75175[D loss: 0.999975] [G loss: 1.000068]\n",
      "epoch:19 step:75180[D loss: 0.999990] [G loss: 1.000041]\n",
      "epoch:19 step:75185[D loss: 1.000038] [G loss: 1.000030]\n",
      "epoch:19 step:75190[D loss: 0.999957] [G loss: 1.000045]\n",
      "epoch:19 step:75195[D loss: 0.999964] [G loss: 1.000071]\n",
      "epoch:19 step:75200[D loss: 0.999989] [G loss: 1.000087]\n",
      "##############\n",
      "[0.85369716 0.87207996 0.81765905 0.83535374 0.79793986 0.84040108\n",
      " 0.88303038 0.84240626 0.83258465 0.83552092]\n",
      "##########\n",
      "epoch:19 step:75205[D loss: 0.999999] [G loss: 0.999982]\n",
      "epoch:19 step:75210[D loss: 0.999980] [G loss: 1.000100]\n",
      "epoch:19 step:75215[D loss: 0.999976] [G loss: 1.000091]\n",
      "epoch:19 step:75220[D loss: 0.999945] [G loss: 1.000084]\n",
      "epoch:19 step:75225[D loss: 1.000033] [G loss: 0.999970]\n",
      "epoch:19 step:75230[D loss: 0.999930] [G loss: 1.000101]\n",
      "epoch:19 step:75235[D loss: 0.999986] [G loss: 1.000038]\n",
      "epoch:19 step:75240[D loss: 0.999938] [G loss: 1.000093]\n",
      "epoch:19 step:75245[D loss: 0.999974] [G loss: 0.999993]\n",
      "epoch:19 step:75250[D loss: 0.999990] [G loss: 1.000000]\n",
      "epoch:19 step:75255[D loss: 1.000039] [G loss: 0.999979]\n",
      "epoch:19 step:75260[D loss: 1.000014] [G loss: 1.000023]\n",
      "epoch:19 step:75265[D loss: 1.000099] [G loss: 0.999889]\n",
      "epoch:19 step:75270[D loss: 0.999956] [G loss: 0.999961]\n",
      "epoch:19 step:75275[D loss: 0.999968] [G loss: 1.000037]\n",
      "epoch:19 step:75280[D loss: 0.999981] [G loss: 1.000047]\n",
      "epoch:19 step:75285[D loss: 1.000003] [G loss: 0.999995]\n",
      "epoch:19 step:75290[D loss: 1.000030] [G loss: 0.999975]\n",
      "epoch:19 step:75295[D loss: 1.000051] [G loss: 0.999891]\n",
      "epoch:19 step:75300[D loss: 0.999954] [G loss: 1.000151]\n",
      "epoch:19 step:75305[D loss: 0.999966] [G loss: 1.000076]\n",
      "epoch:19 step:75310[D loss: 0.999983] [G loss: 1.000034]\n",
      "epoch:19 step:75315[D loss: 0.999971] [G loss: 1.000112]\n",
      "epoch:19 step:75320[D loss: 1.000101] [G loss: 0.999812]\n",
      "epoch:19 step:75325[D loss: 1.000054] [G loss: 1.000049]\n",
      "epoch:19 step:75330[D loss: 1.000023] [G loss: 1.000021]\n",
      "epoch:19 step:75335[D loss: 1.000053] [G loss: 1.000087]\n",
      "epoch:19 step:75340[D loss: 0.999930] [G loss: 1.000058]\n",
      "epoch:19 step:75345[D loss: 1.000033] [G loss: 1.000050]\n",
      "epoch:19 step:75350[D loss: 0.999951] [G loss: 1.000130]\n",
      "epoch:19 step:75355[D loss: 0.999981] [G loss: 1.000151]\n",
      "epoch:19 step:75360[D loss: 0.999954] [G loss: 1.000166]\n",
      "epoch:19 step:75365[D loss: 0.999980] [G loss: 1.000055]\n",
      "epoch:19 step:75370[D loss: 0.999981] [G loss: 1.000074]\n",
      "epoch:19 step:75375[D loss: 0.999981] [G loss: 1.000088]\n",
      "epoch:19 step:75380[D loss: 0.999973] [G loss: 1.000085]\n",
      "epoch:19 step:75385[D loss: 0.999958] [G loss: 1.000103]\n",
      "epoch:19 step:75390[D loss: 0.999991] [G loss: 1.000071]\n",
      "epoch:19 step:75395[D loss: 0.999901] [G loss: 1.000170]\n",
      "epoch:19 step:75400[D loss: 1.000000] [G loss: 1.000046]\n",
      "##############\n",
      "[0.88230954 0.85275796 0.82227199 0.81917297 0.80414641 0.85830581\n",
      " 0.87295522 0.83400375 0.82290258 0.84492088]\n",
      "##########\n",
      "epoch:19 step:75405[D loss: 1.000023] [G loss: 0.999978]\n",
      "epoch:19 step:75410[D loss: 1.000145] [G loss: 0.999890]\n",
      "epoch:19 step:75415[D loss: 1.000148] [G loss: 0.999934]\n",
      "epoch:19 step:75420[D loss: 1.000025] [G loss: 1.000129]\n",
      "epoch:19 step:75425[D loss: 1.000088] [G loss: 1.000038]\n",
      "epoch:19 step:75430[D loss: 0.999932] [G loss: 1.000227]\n",
      "epoch:19 step:75435[D loss: 0.999910] [G loss: 1.000261]\n",
      "epoch:19 step:75440[D loss: 0.999984] [G loss: 1.000073]\n",
      "epoch:19 step:75445[D loss: 1.000154] [G loss: 0.999900]\n",
      "epoch:19 step:75450[D loss: 0.999958] [G loss: 1.000078]\n",
      "epoch:19 step:75455[D loss: 0.999919] [G loss: 1.000106]\n",
      "epoch:19 step:75460[D loss: 0.999970] [G loss: 1.000111]\n",
      "epoch:19 step:75465[D loss: 1.000106] [G loss: 0.999821]\n",
      "epoch:19 step:75470[D loss: 0.999958] [G loss: 1.000055]\n",
      "epoch:19 step:75475[D loss: 1.000107] [G loss: 0.999876]\n",
      "epoch:19 step:75480[D loss: 0.999822] [G loss: 1.000278]\n",
      "epoch:19 step:75485[D loss: 1.000015] [G loss: 1.000088]\n",
      "epoch:19 step:75490[D loss: 1.000004] [G loss: 1.000108]\n",
      "epoch:19 step:75495[D loss: 0.999986] [G loss: 1.000124]\n",
      "epoch:19 step:75500[D loss: 0.999991] [G loss: 1.000088]\n",
      "epoch:19 step:75505[D loss: 1.000040] [G loss: 0.999888]\n",
      "epoch:19 step:75510[D loss: 0.999979] [G loss: 1.000008]\n",
      "epoch:19 step:75515[D loss: 1.000028] [G loss: 1.000014]\n",
      "epoch:19 step:75520[D loss: 0.999891] [G loss: 1.000126]\n",
      "epoch:19 step:75525[D loss: 1.000084] [G loss: 1.000073]\n",
      "epoch:19 step:75530[D loss: 0.999909] [G loss: 1.000120]\n",
      "epoch:19 step:75535[D loss: 0.999913] [G loss: 1.000065]\n",
      "epoch:19 step:75540[D loss: 1.000012] [G loss: 1.000128]\n",
      "epoch:19 step:75545[D loss: 0.999983] [G loss: 1.000162]\n",
      "epoch:19 step:75550[D loss: 0.999955] [G loss: 1.000127]\n",
      "epoch:19 step:75555[D loss: 0.999955] [G loss: 1.000191]\n",
      "epoch:19 step:75560[D loss: 1.000043] [G loss: 1.000043]\n",
      "epoch:19 step:75565[D loss: 0.999958] [G loss: 1.000142]\n",
      "epoch:19 step:75570[D loss: 0.999882] [G loss: 1.000128]\n",
      "epoch:19 step:75575[D loss: 1.000072] [G loss: 1.000013]\n",
      "epoch:19 step:75580[D loss: 0.999851] [G loss: 1.000136]\n",
      "epoch:19 step:75585[D loss: 0.999884] [G loss: 1.000174]\n",
      "epoch:19 step:75590[D loss: 0.999967] [G loss: 1.000095]\n",
      "epoch:19 step:75595[D loss: 0.999976] [G loss: 1.000091]\n",
      "epoch:19 step:75600[D loss: 0.999925] [G loss: 1.000109]\n",
      "##############\n",
      "[0.8768996  0.85910053 0.8204598  0.81216481 0.7931026  0.82810543\n",
      " 0.88913013 0.8544811  0.84307988 0.83160771]\n",
      "##########\n",
      "epoch:19 step:75605[D loss: 0.999940] [G loss: 1.000117]\n",
      "epoch:19 step:75610[D loss: 0.999991] [G loss: 1.000047]\n",
      "epoch:19 step:75615[D loss: 1.000060] [G loss: 0.999954]\n",
      "epoch:19 step:75620[D loss: 0.999969] [G loss: 1.000083]\n",
      "epoch:19 step:75625[D loss: 1.000021] [G loss: 0.999995]\n",
      "epoch:19 step:75630[D loss: 1.000097] [G loss: 1.000015]\n",
      "epoch:19 step:75635[D loss: 0.999872] [G loss: 1.000199]\n",
      "epoch:19 step:75640[D loss: 0.999985] [G loss: 1.000057]\n",
      "epoch:19 step:75645[D loss: 0.999979] [G loss: 1.000093]\n",
      "epoch:19 step:75650[D loss: 0.999951] [G loss: 1.000226]\n",
      "epoch:19 step:75655[D loss: 0.999947] [G loss: 1.000126]\n",
      "epoch:19 step:75660[D loss: 0.999948] [G loss: 1.000108]\n",
      "epoch:19 step:75665[D loss: 0.999941] [G loss: 1.000121]\n",
      "epoch:19 step:75670[D loss: 0.999982] [G loss: 1.000040]\n",
      "epoch:19 step:75675[D loss: 0.999993] [G loss: 1.000110]\n",
      "epoch:19 step:75680[D loss: 0.999990] [G loss: 1.000033]\n",
      "epoch:19 step:75685[D loss: 1.000011] [G loss: 1.000065]\n",
      "epoch:19 step:75690[D loss: 1.000010] [G loss: 1.000007]\n",
      "epoch:19 step:75695[D loss: 0.999960] [G loss: 1.000087]\n",
      "epoch:19 step:75700[D loss: 0.999995] [G loss: 0.999994]\n",
      "epoch:19 step:75705[D loss: 1.000000] [G loss: 1.000106]\n",
      "epoch:19 step:75710[D loss: 1.000002] [G loss: 1.000045]\n",
      "epoch:19 step:75715[D loss: 0.999994] [G loss: 1.000060]\n",
      "epoch:19 step:75720[D loss: 1.000010] [G loss: 1.000086]\n",
      "epoch:19 step:75725[D loss: 0.999931] [G loss: 1.000170]\n",
      "epoch:19 step:75730[D loss: 1.000027] [G loss: 1.000082]\n",
      "epoch:19 step:75735[D loss: 0.999969] [G loss: 1.000223]\n",
      "epoch:19 step:75740[D loss: 0.999994] [G loss: 1.000109]\n",
      "epoch:19 step:75745[D loss: 0.999867] [G loss: 1.000387]\n",
      "epoch:19 step:75750[D loss: 1.000014] [G loss: 1.000120]\n",
      "epoch:19 step:75755[D loss: 0.999930] [G loss: 1.000153]\n",
      "epoch:19 step:75760[D loss: 1.000033] [G loss: 0.999982]\n",
      "epoch:19 step:75765[D loss: 1.000115] [G loss: 0.999928]\n",
      "epoch:19 step:75770[D loss: 1.000325] [G loss: 0.999839]\n",
      "epoch:19 step:75775[D loss: 1.000114] [G loss: 0.999899]\n",
      "epoch:19 step:75780[D loss: 0.999982] [G loss: 0.999952]\n",
      "epoch:19 step:75785[D loss: 1.000255] [G loss: 0.999546]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:19 step:75790[D loss: 1.000024] [G loss: 0.999882]\n",
      "epoch:19 step:75795[D loss: 0.999980] [G loss: 1.000391]\n",
      "epoch:19 step:75800[D loss: 0.999943] [G loss: 1.000173]\n",
      "##############\n",
      "[0.86549237 0.86472786 0.8317422  0.81786713 0.79239183 0.85694764\n",
      " 0.87103404 0.81951732 0.83220937 0.82141114]\n",
      "##########\n",
      "epoch:19 step:75805[D loss: 1.000014] [G loss: 0.999875]\n",
      "epoch:19 step:75810[D loss: 0.999726] [G loss: 1.000543]\n",
      "epoch:19 step:75815[D loss: 0.999923] [G loss: 1.000073]\n",
      "epoch:19 step:75820[D loss: 0.999995] [G loss: 1.000007]\n",
      "epoch:19 step:75825[D loss: 1.000028] [G loss: 0.999949]\n",
      "epoch:19 step:75830[D loss: 0.999936] [G loss: 1.000059]\n",
      "epoch:19 step:75835[D loss: 1.000079] [G loss: 0.999916]\n",
      "epoch:19 step:75840[D loss: 0.999802] [G loss: 1.000185]\n",
      "epoch:19 step:75845[D loss: 1.000183] [G loss: 0.999865]\n",
      "epoch:19 step:75850[D loss: 1.000082] [G loss: 1.000023]\n",
      "epoch:19 step:75855[D loss: 1.000074] [G loss: 0.999905]\n",
      "epoch:19 step:75860[D loss: 0.999964] [G loss: 1.000141]\n",
      "epoch:19 step:75865[D loss: 0.999954] [G loss: 1.000051]\n",
      "epoch:19 step:75870[D loss: 0.999997] [G loss: 1.000025]\n",
      "epoch:19 step:75875[D loss: 0.999831] [G loss: 1.000340]\n",
      "epoch:19 step:75880[D loss: 0.999938] [G loss: 1.000206]\n",
      "epoch:19 step:75885[D loss: 1.000084] [G loss: 1.000066]\n",
      "epoch:19 step:75890[D loss: 1.000185] [G loss: 0.999945]\n",
      "epoch:19 step:75895[D loss: 0.999884] [G loss: 1.000317]\n",
      "epoch:19 step:75900[D loss: 0.999915] [G loss: 1.000179]\n",
      "epoch:19 step:75905[D loss: 0.999969] [G loss: 1.000096]\n",
      "epoch:19 step:75910[D loss: 0.999917] [G loss: 1.000117]\n",
      "epoch:19 step:75915[D loss: 1.000004] [G loss: 1.000016]\n",
      "epoch:19 step:75920[D loss: 1.000028] [G loss: 0.999933]\n",
      "epoch:19 step:75925[D loss: 1.000000] [G loss: 0.999848]\n",
      "epoch:19 step:75930[D loss: 0.999998] [G loss: 0.999963]\n",
      "epoch:19 step:75935[D loss: 0.999972] [G loss: 0.999939]\n",
      "epoch:19 step:75940[D loss: 0.999992] [G loss: 0.999994]\n",
      "epoch:19 step:75945[D loss: 0.999915] [G loss: 1.000278]\n",
      "epoch:19 step:75950[D loss: 0.999948] [G loss: 1.000122]\n",
      "epoch:19 step:75955[D loss: 0.999952] [G loss: 1.000052]\n",
      "epoch:19 step:75960[D loss: 1.000005] [G loss: 0.999964]\n",
      "epoch:19 step:75965[D loss: 0.999965] [G loss: 0.999982]\n",
      "epoch:19 step:75970[D loss: 0.999984] [G loss: 0.999994]\n",
      "epoch:19 step:75975[D loss: 0.999967] [G loss: 1.000093]\n",
      "epoch:19 step:75980[D loss: 1.000009] [G loss: 1.000054]\n",
      "epoch:19 step:75985[D loss: 0.999988] [G loss: 1.000073]\n",
      "epoch:19 step:75990[D loss: 0.999977] [G loss: 1.000081]\n",
      "epoch:19 step:75995[D loss: 0.999987] [G loss: 1.000076]\n",
      "epoch:19 step:76000[D loss: 0.999987] [G loss: 1.000061]\n",
      "##############\n",
      "[0.85733366 0.85397816 0.84040293 0.84822259 0.7955514  0.84240869\n",
      " 0.85184309 0.832359   0.83041978 0.82958318]\n",
      "##########\n",
      "epoch:19 step:76005[D loss: 1.000020] [G loss: 1.000008]\n",
      "epoch:19 step:76010[D loss: 1.000024] [G loss: 1.000061]\n",
      "epoch:19 step:76015[D loss: 0.999989] [G loss: 1.000094]\n",
      "epoch:19 step:76020[D loss: 1.000051] [G loss: 1.000032]\n",
      "epoch:19 step:76025[D loss: 0.999927] [G loss: 1.000118]\n",
      "epoch:19 step:76030[D loss: 1.000021] [G loss: 1.000005]\n",
      "epoch:19 step:76035[D loss: 0.999936] [G loss: 1.000071]\n",
      "epoch:19 step:76040[D loss: 1.000007] [G loss: 1.000115]\n",
      "epoch:19 step:76045[D loss: 1.000039] [G loss: 1.000035]\n",
      "epoch:19 step:76050[D loss: 1.000015] [G loss: 0.999999]\n",
      "epoch:19 step:76055[D loss: 0.999975] [G loss: 1.000081]\n",
      "epoch:19 step:76060[D loss: 0.999968] [G loss: 1.000068]\n",
      "epoch:19 step:76065[D loss: 0.999985] [G loss: 1.000100]\n",
      "epoch:19 step:76070[D loss: 1.000014] [G loss: 0.999979]\n",
      "epoch:19 step:76075[D loss: 1.000003] [G loss: 1.000040]\n",
      "epoch:19 step:76080[D loss: 1.000213] [G loss: 0.999614]\n",
      "epoch:19 step:76085[D loss: 0.999881] [G loss: 1.000238]\n",
      "epoch:19 step:76090[D loss: 0.999986] [G loss: 0.999999]\n",
      "epoch:19 step:76095[D loss: 0.999967] [G loss: 1.000053]\n",
      "epoch:19 step:76100[D loss: 0.999945] [G loss: 1.000176]\n",
      "epoch:19 step:76105[D loss: 1.000130] [G loss: 1.000046]\n",
      "epoch:19 step:76110[D loss: 0.999885] [G loss: 1.000300]\n",
      "epoch:19 step:76115[D loss: 0.999914] [G loss: 1.000156]\n",
      "epoch:19 step:76120[D loss: 0.999922] [G loss: 1.000140]\n",
      "epoch:19 step:76125[D loss: 1.000007] [G loss: 1.000067]\n",
      "epoch:19 step:76130[D loss: 0.999966] [G loss: 1.000157]\n",
      "epoch:19 step:76135[D loss: 0.999951] [G loss: 1.000067]\n",
      "epoch:19 step:76140[D loss: 0.999955] [G loss: 1.000054]\n",
      "epoch:19 step:76145[D loss: 1.000015] [G loss: 1.000021]\n",
      "epoch:19 step:76150[D loss: 1.000041] [G loss: 1.000059]\n",
      "epoch:19 step:76155[D loss: 0.999993] [G loss: 0.999939]\n",
      "epoch:19 step:76160[D loss: 0.999979] [G loss: 1.000045]\n",
      "epoch:19 step:76165[D loss: 0.999934] [G loss: 1.000041]\n",
      "epoch:19 step:76170[D loss: 1.000024] [G loss: 0.999966]\n",
      "epoch:19 step:76175[D loss: 1.000025] [G loss: 1.000017]\n",
      "epoch:19 step:76180[D loss: 1.000009] [G loss: 1.000006]\n",
      "epoch:19 step:76185[D loss: 1.000012] [G loss: 1.000030]\n",
      "epoch:19 step:76190[D loss: 1.000034] [G loss: 1.000011]\n",
      "epoch:19 step:76195[D loss: 0.999847] [G loss: 1.000311]\n",
      "epoch:19 step:76200[D loss: 0.999965] [G loss: 1.000092]\n",
      "##############\n",
      "[0.87597745 0.86505777 0.82313445 0.84401439 0.801861   0.8200366\n",
      " 0.86549259 0.84022119 0.82098009 0.84794419]\n",
      "##########\n",
      "epoch:19 step:76205[D loss: 0.999978] [G loss: 1.000059]\n",
      "epoch:19 step:76210[D loss: 0.999964] [G loss: 1.000103]\n",
      "epoch:19 step:76215[D loss: 0.999987] [G loss: 1.000038]\n",
      "epoch:19 step:76220[D loss: 1.000025] [G loss: 1.000083]\n",
      "epoch:19 step:76225[D loss: 1.000110] [G loss: 0.999908]\n",
      "epoch:19 step:76230[D loss: 0.999984] [G loss: 1.000120]\n",
      "epoch:19 step:76235[D loss: 0.999924] [G loss: 1.000118]\n",
      "epoch:19 step:76240[D loss: 0.999959] [G loss: 1.000046]\n",
      "epoch:19 step:76245[D loss: 0.999963] [G loss: 1.000083]\n",
      "epoch:19 step:76250[D loss: 0.999990] [G loss: 1.000056]\n",
      "epoch:19 step:76255[D loss: 0.999997] [G loss: 1.000066]\n",
      "epoch:19 step:76260[D loss: 0.999964] [G loss: 1.000021]\n",
      "epoch:19 step:76265[D loss: 1.000037] [G loss: 0.999997]\n",
      "epoch:19 step:76270[D loss: 1.000043] [G loss: 1.000029]\n",
      "epoch:19 step:76275[D loss: 1.000006] [G loss: 1.000208]\n",
      "epoch:19 step:76280[D loss: 0.999936] [G loss: 1.000259]\n",
      "epoch:19 step:76285[D loss: 0.999939] [G loss: 1.000129]\n",
      "epoch:19 step:76290[D loss: 0.999931] [G loss: 1.000147]\n",
      "epoch:19 step:76295[D loss: 0.999938] [G loss: 1.000169]\n",
      "epoch:19 step:76300[D loss: 1.000048] [G loss: 1.000064]\n",
      "epoch:19 step:76305[D loss: 0.999931] [G loss: 1.000115]\n",
      "epoch:19 step:76310[D loss: 0.999973] [G loss: 1.000061]\n",
      "epoch:19 step:76315[D loss: 1.000095] [G loss: 0.999918]\n",
      "epoch:19 step:76320[D loss: 0.999939] [G loss: 1.000100]\n",
      "epoch:19 step:76325[D loss: 0.999959] [G loss: 1.000054]\n",
      "epoch:19 step:76330[D loss: 1.000042] [G loss: 1.000033]\n",
      "epoch:19 step:76335[D loss: 1.000022] [G loss: 1.000008]\n",
      "epoch:19 step:76340[D loss: 1.000080] [G loss: 0.999907]\n",
      "epoch:19 step:76345[D loss: 0.999971] [G loss: 1.000017]\n",
      "epoch:19 step:76350[D loss: 0.999986] [G loss: 1.000120]\n",
      "epoch:19 step:76355[D loss: 0.999966] [G loss: 1.000094]\n",
      "epoch:19 step:76360[D loss: 0.999982] [G loss: 1.000021]\n",
      "epoch:19 step:76365[D loss: 0.999963] [G loss: 1.000018]\n",
      "epoch:19 step:76370[D loss: 0.999946] [G loss: 1.000123]\n",
      "epoch:19 step:76375[D loss: 0.999992] [G loss: 1.000081]\n",
      "epoch:19 step:76380[D loss: 1.000008] [G loss: 1.000001]\n",
      "epoch:19 step:76385[D loss: 1.000012] [G loss: 1.000011]\n",
      "epoch:19 step:76390[D loss: 0.999967] [G loss: 1.000046]\n",
      "epoch:19 step:76395[D loss: 0.999984] [G loss: 1.000014]\n",
      "epoch:19 step:76400[D loss: 0.999988] [G loss: 1.000050]\n",
      "##############\n",
      "[0.8544458  0.84269737 0.81943825 0.83772642 0.79531787 0.83465182\n",
      " 0.89784461 0.86103611 0.83144409 0.84825045]\n",
      "##########\n",
      "epoch:19 step:76405[D loss: 0.999956] [G loss: 1.000075]\n",
      "epoch:19 step:76410[D loss: 0.999984] [G loss: 1.000020]\n",
      "epoch:19 step:76415[D loss: 0.999978] [G loss: 0.999997]\n",
      "epoch:19 step:76420[D loss: 1.000019] [G loss: 0.999949]\n",
      "epoch:19 step:76425[D loss: 0.999961] [G loss: 1.000048]\n",
      "epoch:19 step:76430[D loss: 0.999963] [G loss: 1.000046]\n",
      "epoch:19 step:76435[D loss: 1.000009] [G loss: 1.000042]\n",
      "epoch:19 step:76440[D loss: 0.999940] [G loss: 1.000058]\n",
      "epoch:19 step:76445[D loss: 0.999999] [G loss: 1.000056]\n",
      "epoch:19 step:76450[D loss: 0.999932] [G loss: 1.000173]\n",
      "epoch:19 step:76455[D loss: 1.000001] [G loss: 1.000005]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:19 step:76460[D loss: 1.000071] [G loss: 0.999885]\n",
      "epoch:19 step:76465[D loss: 0.999999] [G loss: 0.999952]\n",
      "epoch:19 step:76470[D loss: 1.000095] [G loss: 0.999883]\n",
      "epoch:19 step:76475[D loss: 0.999962] [G loss: 1.000104]\n",
      "epoch:19 step:76480[D loss: 0.999989] [G loss: 1.000080]\n",
      "epoch:19 step:76485[D loss: 0.999947] [G loss: 1.000200]\n",
      "epoch:19 step:76490[D loss: 0.999948] [G loss: 1.000100]\n",
      "epoch:19 step:76495[D loss: 0.999973] [G loss: 1.000034]\n",
      "epoch:19 step:76500[D loss: 0.999949] [G loss: 1.000055]\n",
      "epoch:19 step:76505[D loss: 0.999966] [G loss: 1.000070]\n",
      "epoch:19 step:76510[D loss: 0.999985] [G loss: 1.000051]\n",
      "epoch:19 step:76515[D loss: 0.999989] [G loss: 0.999999]\n",
      "epoch:19 step:76520[D loss: 0.999933] [G loss: 1.000104]\n",
      "epoch:19 step:76525[D loss: 0.999993] [G loss: 1.000056]\n",
      "epoch:19 step:76530[D loss: 1.000103] [G loss: 0.999819]\n",
      "epoch:19 step:76535[D loss: 0.999937] [G loss: 1.000074]\n",
      "epoch:19 step:76540[D loss: 0.999978] [G loss: 1.000102]\n",
      "epoch:19 step:76545[D loss: 0.999968] [G loss: 1.000105]\n",
      "epoch:19 step:76550[D loss: 0.999998] [G loss: 1.000038]\n",
      "epoch:19 step:76555[D loss: 1.000022] [G loss: 0.999963]\n",
      "epoch:19 step:76560[D loss: 1.000045] [G loss: 0.999959]\n",
      "epoch:19 step:76565[D loss: 0.999992] [G loss: 0.999969]\n",
      "epoch:19 step:76570[D loss: 0.999950] [G loss: 1.000046]\n",
      "epoch:19 step:76575[D loss: 0.999980] [G loss: 1.000095]\n",
      "epoch:19 step:76580[D loss: 1.000024] [G loss: 0.999938]\n",
      "epoch:19 step:76585[D loss: 0.999934] [G loss: 1.000144]\n",
      "epoch:19 step:76590[D loss: 0.999956] [G loss: 1.000122]\n",
      "epoch:19 step:76595[D loss: 0.999997] [G loss: 1.000018]\n",
      "epoch:19 step:76600[D loss: 0.999966] [G loss: 1.000066]\n",
      "##############\n",
      "[0.85010175 0.85758647 0.81664213 0.83146261 0.79213468 0.8463309\n",
      " 0.89632292 0.8215928  0.81330051 0.84987641]\n",
      "##########\n",
      "epoch:19 step:76605[D loss: 0.999954] [G loss: 1.000029]\n",
      "epoch:19 step:76610[D loss: 1.000093] [G loss: 0.999901]\n",
      "epoch:19 step:76615[D loss: 0.999862] [G loss: 1.000193]\n",
      "epoch:19 step:76620[D loss: 0.999979] [G loss: 1.000043]\n",
      "epoch:19 step:76625[D loss: 0.999981] [G loss: 1.000091]\n",
      "epoch:19 step:76630[D loss: 0.999920] [G loss: 1.000141]\n",
      "epoch:19 step:76635[D loss: 0.999977] [G loss: 1.000042]\n",
      "epoch:19 step:76640[D loss: 0.999973] [G loss: 1.000042]\n",
      "epoch:19 step:76645[D loss: 0.999999] [G loss: 1.000027]\n",
      "epoch:19 step:76650[D loss: 0.999988] [G loss: 1.000081]\n",
      "epoch:19 step:76655[D loss: 0.999991] [G loss: 1.000091]\n",
      "epoch:19 step:76660[D loss: 1.000020] [G loss: 1.000232]\n",
      "epoch:19 step:76665[D loss: 0.999946] [G loss: 1.000029]\n",
      "epoch:19 step:76670[D loss: 0.999933] [G loss: 1.000201]\n",
      "epoch:19 step:76675[D loss: 0.999989] [G loss: 1.000064]\n",
      "epoch:19 step:76680[D loss: 0.999970] [G loss: 1.000024]\n",
      "epoch:19 step:76685[D loss: 0.999987] [G loss: 1.000052]\n",
      "epoch:19 step:76690[D loss: 0.999971] [G loss: 1.000053]\n",
      "epoch:19 step:76695[D loss: 1.000039] [G loss: 0.999977]\n",
      "epoch:19 step:76700[D loss: 1.000000] [G loss: 1.000001]\n",
      "epoch:19 step:76705[D loss: 1.000032] [G loss: 1.000016]\n",
      "epoch:19 step:76710[D loss: 0.999960] [G loss: 1.000008]\n",
      "epoch:19 step:76715[D loss: 0.999933] [G loss: 1.000096]\n",
      "epoch:19 step:76720[D loss: 0.999981] [G loss: 1.000127]\n",
      "epoch:19 step:76725[D loss: 0.999922] [G loss: 1.000152]\n",
      "epoch:19 step:76730[D loss: 0.999990] [G loss: 1.000074]\n",
      "epoch:19 step:76735[D loss: 0.999980] [G loss: 1.000057]\n",
      "epoch:19 step:76740[D loss: 1.000036] [G loss: 0.999971]\n",
      "epoch:19 step:76745[D loss: 1.000110] [G loss: 1.000017]\n",
      "epoch:19 step:76750[D loss: 0.999970] [G loss: 1.000137]\n",
      "epoch:19 step:76755[D loss: 0.999989] [G loss: 1.000068]\n",
      "epoch:19 step:76760[D loss: 0.999950] [G loss: 1.000053]\n",
      "epoch:19 step:76765[D loss: 0.999936] [G loss: 1.000084]\n",
      "epoch:19 step:76770[D loss: 0.999985] [G loss: 0.999995]\n",
      "epoch:19 step:76775[D loss: 0.999977] [G loss: 1.000031]\n",
      "epoch:19 step:76780[D loss: 0.999995] [G loss: 1.000016]\n",
      "epoch:19 step:76785[D loss: 0.999994] [G loss: 1.000037]\n",
      "epoch:19 step:76790[D loss: 0.999980] [G loss: 1.000066]\n",
      "epoch:19 step:76795[D loss: 1.000046] [G loss: 0.999981]\n",
      "epoch:19 step:76800[D loss: 0.999976] [G loss: 1.000131]\n",
      "##############\n",
      "[0.85976937 0.85221313 0.82100581 0.83786943 0.79633677 0.84917946\n",
      " 0.86265759 0.82639344 0.82434266 0.83530738]\n",
      "##########\n",
      "epoch:19 step:76805[D loss: 0.999945] [G loss: 1.000130]\n",
      "epoch:19 step:76810[D loss: 0.999965] [G loss: 1.000086]\n",
      "epoch:19 step:76815[D loss: 0.999998] [G loss: 0.999995]\n",
      "epoch:19 step:76820[D loss: 0.999978] [G loss: 1.000083]\n",
      "epoch:19 step:76825[D loss: 0.999939] [G loss: 1.000134]\n",
      "epoch:19 step:76830[D loss: 0.999964] [G loss: 1.000103]\n",
      "epoch:19 step:76835[D loss: 0.999944] [G loss: 1.000169]\n",
      "epoch:19 step:76840[D loss: 0.999995] [G loss: 1.000045]\n",
      "epoch:19 step:76845[D loss: 1.000063] [G loss: 1.000031]\n",
      "epoch:19 step:76850[D loss: 0.999988] [G loss: 1.000079]\n",
      "epoch:19 step:76855[D loss: 0.999989] [G loss: 1.000118]\n",
      "epoch:19 step:76860[D loss: 1.000053] [G loss: 1.000158]\n",
      "epoch:19 step:76865[D loss: 0.999934] [G loss: 1.000136]\n",
      "epoch:19 step:76870[D loss: 1.000022] [G loss: 0.999918]\n",
      "epoch:19 step:76875[D loss: 0.999955] [G loss: 1.000080]\n",
      "epoch:19 step:76880[D loss: 1.000046] [G loss: 0.999940]\n",
      "epoch:19 step:76885[D loss: 1.000009] [G loss: 1.000009]\n",
      "epoch:19 step:76890[D loss: 0.999953] [G loss: 0.999994]\n",
      "epoch:19 step:76895[D loss: 0.999954] [G loss: 1.000007]\n",
      "epoch:19 step:76900[D loss: 0.999997] [G loss: 0.999974]\n",
      "epoch:19 step:76905[D loss: 0.999965] [G loss: 1.000128]\n",
      "epoch:19 step:76910[D loss: 1.000049] [G loss: 1.000020]\n",
      "epoch:19 step:76915[D loss: 0.999947] [G loss: 1.000175]\n",
      "epoch:19 step:76920[D loss: 0.999977] [G loss: 1.000045]\n",
      "epoch:19 step:76925[D loss: 1.000013] [G loss: 1.000061]\n",
      "epoch:19 step:76930[D loss: 1.000011] [G loss: 1.000003]\n",
      "epoch:19 step:76935[D loss: 1.000090] [G loss: 0.999917]\n",
      "epoch:19 step:76940[D loss: 1.000018] [G loss: 0.999931]\n",
      "epoch:19 step:76945[D loss: 1.000034] [G loss: 1.000005]\n",
      "epoch:19 step:76950[D loss: 1.000042] [G loss: 0.999946]\n",
      "epoch:19 step:76955[D loss: 1.000103] [G loss: 0.999982]\n",
      "epoch:19 step:76960[D loss: 1.000088] [G loss: 1.000038]\n",
      "epoch:19 step:76965[D loss: 0.999898] [G loss: 1.000161]\n",
      "epoch:19 step:76970[D loss: 0.999909] [G loss: 1.000144]\n",
      "epoch:19 step:76975[D loss: 0.999953] [G loss: 1.000182]\n",
      "epoch:19 step:76980[D loss: 0.999932] [G loss: 1.000190]\n",
      "epoch:19 step:76985[D loss: 0.999973] [G loss: 1.000084]\n",
      "epoch:19 step:76990[D loss: 1.000032] [G loss: 0.999933]\n",
      "epoch:19 step:76995[D loss: 1.000010] [G loss: 0.999965]\n",
      "epoch:19 step:77000[D loss: 1.000019] [G loss: 1.000030]\n",
      "##############\n",
      "[0.83246069 0.86996331 0.82389793 0.83906761 0.81947872 0.82908496\n",
      " 0.85094097 0.81274003 0.81441138 0.84496822]\n",
      "##########\n",
      "epoch:19 step:77005[D loss: 1.000072] [G loss: 0.999952]\n",
      "epoch:19 step:77010[D loss: 0.999943] [G loss: 0.999995]\n",
      "epoch:19 step:77015[D loss: 0.999837] [G loss: 1.000250]\n",
      "epoch:19 step:77020[D loss: 0.999963] [G loss: 1.000147]\n",
      "epoch:19 step:77025[D loss: 0.999900] [G loss: 1.000100]\n",
      "epoch:19 step:77030[D loss: 0.999977] [G loss: 1.000009]\n",
      "epoch:19 step:77035[D loss: 1.000008] [G loss: 0.999933]\n",
      "epoch:19 step:77040[D loss: 1.000005] [G loss: 1.000046]\n",
      "epoch:19 step:77045[D loss: 0.999984] [G loss: 1.000008]\n",
      "epoch:19 step:77050[D loss: 1.000109] [G loss: 0.999831]\n",
      "epoch:19 step:77055[D loss: 0.999942] [G loss: 1.000203]\n",
      "epoch:19 step:77060[D loss: 0.999972] [G loss: 1.000054]\n",
      "epoch:19 step:77065[D loss: 0.999916] [G loss: 1.000248]\n",
      "epoch:19 step:77070[D loss: 0.999996] [G loss: 1.000062]\n",
      "epoch:19 step:77075[D loss: 0.999943] [G loss: 1.000160]\n",
      "epoch:19 step:77080[D loss: 0.999968] [G loss: 1.000117]\n",
      "epoch:19 step:77085[D loss: 0.999980] [G loss: 1.000056]\n",
      "epoch:19 step:77090[D loss: 0.999959] [G loss: 1.000033]\n",
      "epoch:19 step:77095[D loss: 1.000035] [G loss: 0.999937]\n",
      "epoch:19 step:77100[D loss: 0.999960] [G loss: 0.999984]\n",
      "epoch:19 step:77105[D loss: 1.000064] [G loss: 0.999942]\n",
      "epoch:19 step:77110[D loss: 0.999957] [G loss: 1.000066]\n",
      "epoch:19 step:77115[D loss: 1.000046] [G loss: 1.000213]\n",
      "epoch:19 step:77120[D loss: 0.999912] [G loss: 1.000085]\n",
      "epoch:19 step:77125[D loss: 0.999866] [G loss: 1.000216]\n",
      "epoch:19 step:77130[D loss: 0.999969] [G loss: 1.000067]\n",
      "epoch:19 step:77135[D loss: 1.000034] [G loss: 1.000082]\n",
      "epoch:19 step:77140[D loss: 1.000069] [G loss: 0.999945]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:19 step:77145[D loss: 1.000129] [G loss: 0.999904]\n",
      "epoch:19 step:77150[D loss: 0.999886] [G loss: 1.000136]\n",
      "epoch:19 step:77155[D loss: 0.999926] [G loss: 1.000107]\n",
      "epoch:19 step:77160[D loss: 0.999948] [G loss: 1.000080]\n",
      "epoch:19 step:77165[D loss: 0.999981] [G loss: 1.000055]\n",
      "epoch:19 step:77170[D loss: 1.000146] [G loss: 0.999824]\n",
      "epoch:19 step:77175[D loss: 1.000032] [G loss: 0.999926]\n",
      "epoch:19 step:77180[D loss: 0.999927] [G loss: 1.000063]\n",
      "epoch:19 step:77185[D loss: 0.999863] [G loss: 1.000154]\n",
      "epoch:19 step:77190[D loss: 1.000024] [G loss: 1.000009]\n",
      "epoch:19 step:77195[D loss: 0.999996] [G loss: 1.000080]\n",
      "epoch:19 step:77200[D loss: 1.000001] [G loss: 1.000091]\n",
      "##############\n",
      "[0.84303256 0.85287707 0.82976861 0.82821012 0.79252345 0.83114519\n",
      " 0.8842254  0.8261698  0.82927184 0.84746013]\n",
      "##########\n",
      "epoch:19 step:77205[D loss: 1.000000] [G loss: 1.000007]\n",
      "epoch:19 step:77210[D loss: 1.000046] [G loss: 1.000057]\n",
      "epoch:19 step:77215[D loss: 1.000214] [G loss: 0.999752]\n",
      "epoch:19 step:77220[D loss: 0.999887] [G loss: 1.000329]\n",
      "epoch:19 step:77225[D loss: 0.999943] [G loss: 1.000212]\n",
      "epoch:19 step:77230[D loss: 0.999953] [G loss: 1.000195]\n",
      "epoch:19 step:77235[D loss: 0.999865] [G loss: 1.000222]\n",
      "epoch:19 step:77240[D loss: 0.999951] [G loss: 1.000119]\n",
      "epoch:19 step:77245[D loss: 0.999974] [G loss: 1.000088]\n",
      "epoch:19 step:77250[D loss: 0.999974] [G loss: 1.000023]\n",
      "epoch:19 step:77255[D loss: 0.999957] [G loss: 1.000066]\n",
      "epoch:19 step:77260[D loss: 1.000000] [G loss: 0.999974]\n",
      "epoch:19 step:77265[D loss: 0.999918] [G loss: 1.000109]\n",
      "epoch:19 step:77270[D loss: 0.999979] [G loss: 1.000057]\n",
      "epoch:19 step:77275[D loss: 0.999991] [G loss: 1.000063]\n",
      "epoch:19 step:77280[D loss: 0.999971] [G loss: 1.000052]\n",
      "epoch:19 step:77285[D loss: 0.999984] [G loss: 1.000074]\n",
      "epoch:19 step:77290[D loss: 1.000060] [G loss: 0.999980]\n",
      "epoch:19 step:77295[D loss: 0.999961] [G loss: 1.000036]\n",
      "epoch:19 step:77300[D loss: 1.000007] [G loss: 1.000001]\n",
      "epoch:19 step:77305[D loss: 1.000043] [G loss: 1.000032]\n",
      "epoch:19 step:77310[D loss: 1.000020] [G loss: 0.999900]\n",
      "epoch:19 step:77315[D loss: 0.999985] [G loss: 1.000185]\n",
      "epoch:19 step:77320[D loss: 0.999968] [G loss: 1.000039]\n",
      "epoch:19 step:77325[D loss: 0.999989] [G loss: 1.000044]\n",
      "epoch:19 step:77330[D loss: 0.999963] [G loss: 1.000082]\n",
      "epoch:19 step:77335[D loss: 0.999998] [G loss: 0.999999]\n",
      "epoch:19 step:77340[D loss: 1.000002] [G loss: 1.000058]\n",
      "epoch:19 step:77345[D loss: 1.000003] [G loss: 0.999931]\n",
      "epoch:19 step:77350[D loss: 0.999948] [G loss: 1.000054]\n",
      "epoch:19 step:77355[D loss: 1.000024] [G loss: 1.000041]\n",
      "epoch:19 step:77360[D loss: 0.999990] [G loss: 1.000040]\n",
      "epoch:19 step:77365[D loss: 0.999967] [G loss: 1.000052]\n",
      "epoch:19 step:77370[D loss: 0.999970] [G loss: 1.000106]\n",
      "epoch:19 step:77375[D loss: 1.000052] [G loss: 0.999970]\n",
      "epoch:19 step:77380[D loss: 1.000017] [G loss: 1.000075]\n",
      "epoch:19 step:77385[D loss: 0.999983] [G loss: 1.000018]\n",
      "epoch:19 step:77390[D loss: 0.999980] [G loss: 1.000049]\n",
      "epoch:19 step:77395[D loss: 0.999990] [G loss: 1.000024]\n",
      "epoch:19 step:77400[D loss: 0.999951] [G loss: 1.000072]\n",
      "##############\n",
      "[0.86259557 0.87236705 0.85276336 0.84011931 0.77202358 0.82465088\n",
      " 0.89289803 0.82110162 0.84054792 0.83628912]\n",
      "##########\n",
      "epoch:19 step:77405[D loss: 1.000029] [G loss: 0.999988]\n",
      "epoch:19 step:77410[D loss: 1.000029] [G loss: 1.000052]\n",
      "epoch:19 step:77415[D loss: 0.999964] [G loss: 1.000161]\n",
      "epoch:19 step:77420[D loss: 0.999948] [G loss: 1.000146]\n",
      "epoch:19 step:77425[D loss: 0.999919] [G loss: 1.000204]\n",
      "epoch:19 step:77430[D loss: 1.000066] [G loss: 0.999967]\n",
      "epoch:19 step:77435[D loss: 0.999914] [G loss: 1.000173]\n",
      "epoch:19 step:77440[D loss: 1.000020] [G loss: 1.000146]\n",
      "epoch:19 step:77445[D loss: 0.999932] [G loss: 1.000198]\n",
      "epoch:19 step:77450[D loss: 1.000073] [G loss: 1.000047]\n",
      "epoch:19 step:77455[D loss: 0.999955] [G loss: 1.000179]\n",
      "epoch:19 step:77460[D loss: 1.000011] [G loss: 1.000033]\n",
      "epoch:19 step:77465[D loss: 1.000012] [G loss: 1.000027]\n",
      "epoch:19 step:77470[D loss: 0.999934] [G loss: 1.000086]\n",
      "epoch:19 step:77475[D loss: 0.999991] [G loss: 0.999972]\n",
      "epoch:19 step:77480[D loss: 0.999934] [G loss: 1.000105]\n",
      "epoch:19 step:77485[D loss: 0.999985] [G loss: 1.000056]\n",
      "epoch:19 step:77490[D loss: 0.999985] [G loss: 1.000066]\n",
      "epoch:19 step:77495[D loss: 1.000046] [G loss: 1.000040]\n",
      "epoch:19 step:77500[D loss: 1.000000] [G loss: 1.000152]\n",
      "epoch:19 step:77505[D loss: 1.000018] [G loss: 0.999966]\n",
      "epoch:19 step:77510[D loss: 0.999950] [G loss: 1.000093]\n",
      "epoch:19 step:77515[D loss: 0.999926] [G loss: 1.000085]\n",
      "epoch:19 step:77520[D loss: 0.999954] [G loss: 1.000157]\n",
      "epoch:19 step:77525[D loss: 0.999980] [G loss: 1.000047]\n",
      "epoch:19 step:77530[D loss: 0.999989] [G loss: 1.000136]\n",
      "epoch:19 step:77535[D loss: 1.000031] [G loss: 0.999915]\n",
      "epoch:19 step:77540[D loss: 0.999992] [G loss: 1.000019]\n",
      "epoch:19 step:77545[D loss: 0.999918] [G loss: 1.000126]\n",
      "epoch:19 step:77550[D loss: 0.999981] [G loss: 1.000122]\n",
      "epoch:19 step:77555[D loss: 0.999935] [G loss: 1.000111]\n",
      "epoch:19 step:77560[D loss: 0.999999] [G loss: 1.000033]\n",
      "epoch:19 step:77565[D loss: 1.000039] [G loss: 0.999914]\n",
      "epoch:19 step:77570[D loss: 1.000026] [G loss: 0.999989]\n",
      "epoch:19 step:77575[D loss: 1.000004] [G loss: 1.000037]\n",
      "epoch:19 step:77580[D loss: 0.999943] [G loss: 1.000116]\n",
      "epoch:19 step:77585[D loss: 1.000027] [G loss: 0.999931]\n",
      "epoch:19 step:77590[D loss: 1.000023] [G loss: 1.000066]\n",
      "epoch:19 step:77595[D loss: 0.999921] [G loss: 1.000203]\n",
      "epoch:19 step:77600[D loss: 0.999991] [G loss: 1.000026]\n",
      "##############\n",
      "[0.85222378 0.85571638 0.83026943 0.8401772  0.78461326 0.82812091\n",
      " 0.86299795 0.84222146 0.82544707 0.82463179]\n",
      "##########\n",
      "epoch:19 step:77605[D loss: 0.999944] [G loss: 1.000171]\n",
      "epoch:19 step:77610[D loss: 0.999958] [G loss: 1.000055]\n",
      "epoch:19 step:77615[D loss: 0.999980] [G loss: 1.000089]\n",
      "epoch:19 step:77620[D loss: 0.999951] [G loss: 1.000058]\n",
      "epoch:19 step:77625[D loss: 1.000030] [G loss: 1.000042]\n",
      "epoch:19 step:77630[D loss: 0.999905] [G loss: 1.000099]\n",
      "epoch:19 step:77635[D loss: 0.999991] [G loss: 1.000047]\n",
      "epoch:19 step:77640[D loss: 1.000048] [G loss: 0.999999]\n",
      "epoch:19 step:77645[D loss: 0.999958] [G loss: 1.000048]\n",
      "epoch:19 step:77650[D loss: 1.000028] [G loss: 0.999892]\n",
      "epoch:19 step:77655[D loss: 1.000054] [G loss: 1.000040]\n",
      "epoch:19 step:77660[D loss: 0.999968] [G loss: 1.000153]\n",
      "epoch:19 step:77665[D loss: 1.000111] [G loss: 0.999932]\n",
      "epoch:19 step:77670[D loss: 0.999878] [G loss: 1.000314]\n",
      "epoch:19 step:77675[D loss: 0.999914] [G loss: 1.000149]\n",
      "epoch:19 step:77680[D loss: 0.999958] [G loss: 1.000057]\n",
      "epoch:19 step:77685[D loss: 0.999942] [G loss: 1.000108]\n",
      "epoch:19 step:77690[D loss: 0.999955] [G loss: 1.000124]\n",
      "epoch:19 step:77695[D loss: 0.999957] [G loss: 1.000108]\n",
      "epoch:19 step:77700[D loss: 0.999978] [G loss: 1.000082]\n",
      "epoch:19 step:77705[D loss: 0.999966] [G loss: 1.000072]\n",
      "epoch:19 step:77710[D loss: 0.999994] [G loss: 1.000009]\n",
      "epoch:19 step:77715[D loss: 0.999994] [G loss: 1.000112]\n",
      "epoch:19 step:77720[D loss: 0.999951] [G loss: 1.000079]\n",
      "epoch:19 step:77725[D loss: 1.000012] [G loss: 1.000019]\n",
      "epoch:19 step:77730[D loss: 1.000010] [G loss: 1.000091]\n",
      "epoch:19 step:77735[D loss: 0.999896] [G loss: 1.000122]\n",
      "epoch:19 step:77740[D loss: 0.999994] [G loss: 1.000011]\n",
      "epoch:19 step:77745[D loss: 0.999989] [G loss: 0.999965]\n",
      "epoch:19 step:77750[D loss: 1.000014] [G loss: 1.000005]\n",
      "epoch:19 step:77755[D loss: 0.999931] [G loss: 1.000148]\n",
      "epoch:19 step:77760[D loss: 0.999964] [G loss: 1.000100]\n",
      "epoch:19 step:77765[D loss: 0.999958] [G loss: 1.000082]\n",
      "epoch:19 step:77770[D loss: 0.999958] [G loss: 1.000079]\n",
      "epoch:19 step:77775[D loss: 1.000030] [G loss: 0.999980]\n",
      "epoch:19 step:77780[D loss: 0.999958] [G loss: 1.000071]\n",
      "epoch:19 step:77785[D loss: 0.999970] [G loss: 1.000055]\n",
      "epoch:19 step:77790[D loss: 1.000006] [G loss: 0.999996]\n",
      "epoch:19 step:77795[D loss: 1.000005] [G loss: 1.000018]\n",
      "epoch:19 step:77800[D loss: 0.999988] [G loss: 1.000006]\n",
      "##############\n",
      "[0.85064439 0.85809043 0.81895578 0.84122561 0.78790639 0.821036\n",
      " 0.87503881 0.84626066 0.82281721 0.85326776]\n",
      "##########\n",
      "epoch:19 step:77805[D loss: 1.000101] [G loss: 0.999942]\n",
      "epoch:19 step:77810[D loss: 1.000097] [G loss: 0.999915]\n",
      "epoch:19 step:77815[D loss: 0.999952] [G loss: 1.000068]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:19 step:77820[D loss: 0.999948] [G loss: 1.000033]\n",
      "epoch:19 step:77825[D loss: 0.999960] [G loss: 1.000027]\n",
      "epoch:19 step:77830[D loss: 0.999999] [G loss: 1.000108]\n",
      "epoch:19 step:77835[D loss: 0.999972] [G loss: 1.000024]\n",
      "epoch:19 step:77840[D loss: 0.999969] [G loss: 1.000080]\n",
      "epoch:19 step:77845[D loss: 0.999985] [G loss: 1.000034]\n",
      "epoch:19 step:77850[D loss: 0.999973] [G loss: 1.000104]\n",
      "epoch:19 step:77855[D loss: 0.999994] [G loss: 1.000052]\n",
      "epoch:19 step:77860[D loss: 1.000014] [G loss: 0.999940]\n",
      "epoch:19 step:77865[D loss: 0.999952] [G loss: 1.000109]\n",
      "epoch:19 step:77870[D loss: 0.999990] [G loss: 1.000061]\n",
      "epoch:19 step:77875[D loss: 0.999902] [G loss: 1.000156]\n",
      "epoch:19 step:77880[D loss: 1.000002] [G loss: 1.000079]\n",
      "epoch:19 step:77885[D loss: 0.999955] [G loss: 1.000114]\n",
      "epoch:19 step:77890[D loss: 0.999959] [G loss: 1.000148]\n",
      "epoch:19 step:77895[D loss: 0.999983] [G loss: 1.000068]\n",
      "epoch:19 step:77900[D loss: 0.999990] [G loss: 1.000029]\n",
      "epoch:19 step:77905[D loss: 1.000006] [G loss: 0.999955]\n",
      "epoch:19 step:77910[D loss: 0.999965] [G loss: 1.000075]\n",
      "epoch:19 step:77915[D loss: 0.999963] [G loss: 1.000037]\n",
      "epoch:19 step:77920[D loss: 0.999990] [G loss: 1.000075]\n",
      "epoch:19 step:77925[D loss: 0.999979] [G loss: 1.000091]\n",
      "epoch:19 step:77930[D loss: 0.999948] [G loss: 1.000090]\n",
      "epoch:19 step:77935[D loss: 0.999974] [G loss: 1.000071]\n",
      "epoch:19 step:77940[D loss: 1.000009] [G loss: 0.999980]\n",
      "epoch:19 step:77945[D loss: 0.999989] [G loss: 1.000014]\n",
      "epoch:19 step:77950[D loss: 1.000003] [G loss: 1.000016]\n",
      "epoch:19 step:77955[D loss: 0.999976] [G loss: 1.000043]\n",
      "epoch:19 step:77960[D loss: 1.000023] [G loss: 0.999977]\n",
      "epoch:19 step:77965[D loss: 0.999985] [G loss: 1.000099]\n",
      "epoch:19 step:77970[D loss: 0.999978] [G loss: 1.000014]\n",
      "epoch:19 step:77975[D loss: 1.000029] [G loss: 0.999968]\n",
      "epoch:19 step:77980[D loss: 0.999993] [G loss: 1.000028]\n",
      "epoch:19 step:77985[D loss: 1.000017] [G loss: 1.000015]\n",
      "epoch:19 step:77990[D loss: 1.000070] [G loss: 0.999989]\n",
      "epoch:19 step:77995[D loss: 1.000064] [G loss: 0.999991]\n",
      "epoch:19 step:78000[D loss: 1.000028] [G loss: 1.000088]\n",
      "##############\n",
      "[0.86926553 0.84883958 0.83582975 0.83460532 0.81045039 0.82130434\n",
      " 0.88894643 0.82859429 0.80014027 0.82431285]\n",
      "##########\n",
      "epoch:19 step:78005[D loss: 0.999955] [G loss: 1.000259]\n",
      "epoch:19 step:78010[D loss: 0.999889] [G loss: 1.000166]\n",
      "epoch:19 step:78015[D loss: 0.999971] [G loss: 1.000087]\n",
      "epoch:19 step:78020[D loss: 0.999984] [G loss: 1.000067]\n",
      "epoch:19 step:78025[D loss: 0.999950] [G loss: 1.000127]\n",
      "epoch:19 step:78030[D loss: 0.999992] [G loss: 0.999998]\n",
      "epoch:19 step:78035[D loss: 0.999989] [G loss: 1.000016]\n",
      "epoch:19 step:78040[D loss: 0.999947] [G loss: 1.000028]\n",
      "epoch:19 step:78045[D loss: 0.999992] [G loss: 1.000023]\n",
      "epoch:19 step:78050[D loss: 0.999994] [G loss: 1.000006]\n",
      "epoch:19 step:78055[D loss: 0.999998] [G loss: 1.000051]\n",
      "epoch:19 step:78060[D loss: 0.999959] [G loss: 1.000063]\n",
      "epoch:19 step:78065[D loss: 1.000003] [G loss: 1.000080]\n",
      "epoch:19 step:78070[D loss: 0.999961] [G loss: 1.000065]\n",
      "epoch:19 step:78075[D loss: 0.999987] [G loss: 1.000042]\n",
      "epoch:19 step:78080[D loss: 0.999992] [G loss: 1.000034]\n",
      "epoch:19 step:78085[D loss: 0.999970] [G loss: 1.000068]\n",
      "epoch:19 step:78090[D loss: 1.000050] [G loss: 0.999940]\n",
      "epoch:19 step:78095[D loss: 0.999919] [G loss: 1.000160]\n",
      "epoch:19 step:78100[D loss: 0.999955] [G loss: 1.000049]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.datasets import cifar10\n",
    "from torch.utils.data import Dataset\n",
    "import torch.utils.data as Data\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, imgs, transform=None):\n",
    "        # super().__init__()\n",
    "        self.imgs = imgs\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.imgs)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img = self.imgs[index]\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "        else:\n",
    "            img = torch.from_numpy(img)\n",
    "        img=img.reshape([3,32,32])\n",
    "        return img\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import model\n",
    "import torch.nn.functional as F\n",
    "model = model.cifar10(128)\n",
    "model.load_state_dict(torch.load('./log/default/best-85.pth'))\n",
    "model.cuda()\n",
    "def EuclideanDistances(A, B):\n",
    "    BT = B.transpose()\n",
    "    # vecProd = A * BT\n",
    "    vecProd = np.dot(A, BT)\n",
    "    # print(vecProd)\n",
    "    SqA = A ** 2\n",
    "    # print(SqA)\n",
    "    sumSqA = np.matrix(np.sum(SqA, axis=1))\n",
    "    sumSqAEx = np.tile(sumSqA.transpose(), (1, vecProd.shape[1]))\n",
    "    # print(sumSqAEx)\n",
    "\n",
    "    SqB = B ** 2\n",
    "    sumSqB = np.sum(SqB, axis=1)\n",
    "    sumSqBEx = np.tile(sumSqB, (vecProd.shape[0], 1))\n",
    "    SqED = sumSqBEx + sumSqAEx - 2 * vecProd\n",
    "    SqED[SqED < 0] = 0.0\n",
    "    ED = np.sqrt(SqED)\n",
    "    return np.divide(ED.sum(), ED.shape[0] * ED.shape[1])\n",
    "\n",
    "\n",
    "def cal_distance_image_real(images, labels):\n",
    "    x_dataset = MyDataset(images)\n",
    "    # print(x_dataset[0].shape)\n",
    "    x_real_loader = Data.DataLoader(dataset=x_dataset, batch_size=200, shuffle=True)\n",
    "    y_logits = []\n",
    "    for i, data in enumerate(x_real_loader):\n",
    "        # indx_target = target.clone()\n",
    "        data = data.cuda()\n",
    "        data = Variable(data, volatile=True)\n",
    "        output = model(data)\n",
    "        pred = F.softmax(output).cpu().detach().numpy()\n",
    "        y_logits += [i for i in pred]\n",
    "    dict = {}\n",
    "    all_dis = []\n",
    "    for i in range(10):\n",
    "        dict[i] = []\n",
    "    for i in range(len(labels)):\n",
    "        dict[labels[i]].append(y_logits[i])\n",
    "    for i in range(10):\n",
    "        dict[i] = np.array(dict[i])\n",
    "        if len(dict[i]):\n",
    "            dis = EuclideanDistances(dict[i], dict[i])  # 生成图片的紧度\n",
    "        else:\n",
    "            dis = -1\n",
    "        all_dis.append(dis)\n",
    "    return np.array(all_dis)\n",
    "\n",
    "\n",
    "def cal_distance_image_fake(images):\n",
    "    x_dataset = MyDataset(images)\n",
    "    # print(x_dataset[0].shape)\n",
    "    x_real_loader = Data.DataLoader(dataset=x_dataset, batch_size=200, shuffle=True)\n",
    "    y_logits = []\n",
    "    labels=[]\n",
    "    for i, data in enumerate(x_real_loader):\n",
    "        # indx_target = target.clone()\n",
    "        data = data.cuda()\n",
    "        data = Variable(data, volatile=True)\n",
    "        output = model(data)\n",
    "        pred = output.data.max(1)[1]\n",
    "        labels += [i for i in pred.cpu().numpy()]\n",
    "        pred = F.softmax(output).cpu().detach().numpy()\n",
    "        y_logits += [i for i in pred]\n",
    "\n",
    "    dict = {}\n",
    "    all_dis = []\n",
    "    for i in range(10):\n",
    "        dict[i] = []\n",
    "    for i in range(len(labels)):\n",
    "        dict[labels[i]].append(y_logits[i])\n",
    "    for i in range(10):\n",
    "        dict[i] = np.array(dict[i])\n",
    "        if len(dict[i]):\n",
    "            dis = EuclideanDistances(dict[i], dict[i])  # 生成图片的紧度\n",
    "        else:\n",
    "            dis = -1\n",
    "        all_dis.append(dis)\n",
    "    return np.array(all_dis)\n",
    "\n",
    "import os\n",
    "if not os.path.isdir('saved_models_{}'.format('wgan')):\n",
    "    os.mkdir('saved_models_{}'.format('wgan'))\n",
    "f = open('saved_models_{}/log_collapse1.txt'.format('wgan'), mode='w')\n",
    "import torch.utils.data as Data\n",
    "import cv2\n",
    "\n",
    "\n",
    "from keras.datasets import cifar10\n",
    "from keras.layers import Input, Dense, Reshape, Flatten, Dropout\n",
    "from keras.layers import BatchNormalization, Activation, ZeroPadding2D\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.layers.convolutional import UpSampling2D, Conv2D\n",
    "from keras.models import Sequential, Model\n",
    "from keras.optimizers import RMSprop\n",
    "\n",
    "import keras.backend as K\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class WGAN():\n",
    "    def __init__(self):\n",
    "        self.img_rows = 32\n",
    "        self.img_cols = 32\n",
    "        self.channels = 3\n",
    "        self.img_shape = (self.img_rows, self.img_cols, self.channels)\n",
    "        self.latent_dim = 100\n",
    "        self.x = []\n",
    "        self.y = np.zeros((31, 1), dtype=np.int)\n",
    "        self.y = list(self.y)\n",
    "        for i in range(31):\n",
    "            self.y[i] = []\n",
    "\n",
    "        # Following parameter and optimizer set as recommended in paper\n",
    "        self.n_critic = 5\n",
    "        self.clip_value = 0.01\n",
    "        optimizer = RMSprop(lr=0.00005)\n",
    "\n",
    "        # Build and compile the critic\n",
    "        self.critic = self.build_critic()\n",
    "        self.critic.compile(loss=self.wasserstein_loss,\n",
    "                            optimizer=optimizer,\n",
    "                            metrics=['accuracy'])\n",
    "\n",
    "        # Build the generator\n",
    "        self.generator = self.build_generator()\n",
    "\n",
    "        # The generator takes noise as input and generated imgs\n",
    "        z = Input(shape=(self.latent_dim,))\n",
    "        img = self.generator(z)\n",
    "\n",
    "        # For the combined model we will only train the generator\n",
    "        self.critic.trainable = False\n",
    "\n",
    "        # The critic takes generated images as input and determines validity\n",
    "        valid = self.critic(img)\n",
    "\n",
    "        # The combined model  (stacked generator and critic)\n",
    "        self.combined = Model(z, valid)\n",
    "        self.combined.compile(loss=self.wasserstein_loss,\n",
    "                              optimizer=optimizer,\n",
    "                              metrics=['accuracy'])\n",
    "\n",
    "    def wasserstein_loss(self, y_true, y_pred):\n",
    "        return K.mean(y_true * y_pred)\n",
    "\n",
    "    def build_generator(self):\n",
    "\n",
    "        model = Sequential()\n",
    "\n",
    "        model.add(Dense(128 * 8 * 8, activation=\"relu\", input_dim=self.latent_dim))\n",
    "        model.add(Reshape((8, 8, 128)))\n",
    "        model.add(UpSampling2D())\n",
    "        model.add(Conv2D(128, kernel_size=4, padding=\"same\"))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(UpSampling2D())\n",
    "        model.add(Conv2D(64, kernel_size=4, padding=\"same\"))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(Conv2D(self.channels, kernel_size=4, padding=\"same\"))\n",
    "        model.add(Activation(\"tanh\"))\n",
    "\n",
    "        model.summary()\n",
    "\n",
    "        noise = Input(shape=(self.latent_dim,))\n",
    "        img = model(noise)\n",
    "\n",
    "        return Model(noise, img)\n",
    "\n",
    "    def build_critic(self):\n",
    "\n",
    "        model = Sequential()\n",
    "\n",
    "        model.add(Conv2D(16, kernel_size=3, strides=2, input_shape=self.img_shape, padding=\"same\"))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dropout(0.25))\n",
    "        model.add(Conv2D(32, kernel_size=3, strides=2, padding=\"same\"))\n",
    "        # model.add(ZeroPadding2D(padding=((0, 1), (0, 1))))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dropout(0.25))\n",
    "        model.add(Conv2D(64, kernel_size=3, strides=2, padding=\"same\"))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dropout(0.25))\n",
    "        model.add(Conv2D(128, kernel_size=3, strides=1, padding=\"same\"))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dropout(0.25))\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(1))\n",
    "\n",
    "        model.summary()\n",
    "\n",
    "        img = Input(shape=self.img_shape)\n",
    "        validity = model(img)\n",
    "\n",
    "        return Model(img, validity)\n",
    "\n",
    "    def train(self, epochs, batch_size=128, sample_interval=50):\n",
    "\n",
    "        # Load the dataset\n",
    "        (X_train, _), (X_test, y_test) = cifar10.load_data()\n",
    "\n",
    "        # Rescale -1 to 1\n",
    "        X_train = (X_train.astype(np.float32) - 127.5) / 127.5\n",
    "        X_test = (X_test.astype(np.float32) - 127.5) / 127.5\n",
    "        # X_train = np.expand_dims(X_train, axis=3)\n",
    "\n",
    "        # Adversarial ground truths\n",
    "        valid = -np.ones((batch_size, 1))\n",
    "        fake = np.ones((batch_size, 1))\n",
    "\n",
    "        nb_batches = int(X_train.shape[0] / batch_size)\n",
    "        global_step = 0\n",
    "        steps = []\n",
    "        values = []\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "\n",
    "            for index in range(nb_batches):\n",
    "                for _ in range(self.n_critic):\n",
    "                    global_step += 1\n",
    "                    imgs = X_train[index * batch_size:(index + 1) * batch_size]\n",
    "                    # ---------------------\n",
    "                    #  Train Discriminator\n",
    "                    # ---------------------\n",
    "\n",
    "                    # Select a random batch of images\n",
    "                    # idx = np.random.randint(0, X_train.shape[0], batch_size)\n",
    "                    # imgs = X_train[idx]\n",
    "\n",
    "                    # Sample noise as generator input\n",
    "                    noise = np.random.normal(0, 1, (batch_size, self.latent_dim))\n",
    "\n",
    "                    # Generate a batch of new images\n",
    "                    gen_imgs = self.generator.predict(noise)\n",
    "\n",
    "                    # Train the critic\n",
    "                    d_loss_real = self.critic.train_on_batch(imgs, valid)\n",
    "                    d_loss_fake = self.critic.train_on_batch(gen_imgs, fake)\n",
    "                    d_loss = 0.5 * np.add(d_loss_fake, d_loss_real)\n",
    "\n",
    "                    # Clip critic weights\n",
    "                    for l in self.critic.layers:\n",
    "                        weights = l.get_weights()\n",
    "                        weights = [np.clip(w, -self.clip_value, self.clip_value) for w in weights]\n",
    "                        l.set_weights(weights)\n",
    "\n",
    "                    # ---------------------\n",
    "                    #  Train Generator\n",
    "                    # ---------------------\n",
    "\n",
    "                g_loss = self.combined.train_on_batch(noise, valid)\n",
    "\n",
    "                # Plot the progress\n",
    "                print(\"epoch:%d step:%d[D loss: %f] [G loss: %f]\" % (epoch, global_step, 1 - d_loss[0], 1 - g_loss[0]))\n",
    "                sample_num=5000\n",
    "\n",
    "                if global_step % sample_interval == 0:\n",
    "                    self.mode_drop(X_test,y_test,sample_num, global_step)\n",
    "\n",
    "\n",
    "    def mode_drop(self, x_test,y_test,sample_num, global_step):\n",
    "        r, c = 10, 1000\n",
    "        noise = np.random.normal(0, 1, (r * c, 100))\n",
    "        # sampled_labels = np.array([num for _ in range(r) for num in range(c)])\n",
    "        gen_imgs = self.generator.predict([noise])\n",
    "        # Rescale images 0 - 1\n",
    "        gen_imgs = 0.5 * gen_imgs + 0.5\n",
    "        labels = np.squeeze(y_test[:sample_num])\n",
    "        labels = np.squeeze(labels)\n",
    "        dis_real = cal_distance_image_real(x_test[:sample_num], labels)\n",
    "        dis_fake = cal_distance_image_fake(gen_imgs)\n",
    "        dis_cha = dis_real - dis_fake\n",
    "        print('##############')\n",
    "        # print(dis_real)\n",
    "        # print(dis_fake)\n",
    "        print(dis_cha)\n",
    "        print('##########')\n",
    "        f.writelines('\\n')\n",
    "        f.writelines('step:' + str(global_step))\n",
    "        f.writelines('\\n')\n",
    "        f.writelines('紧度')\n",
    "        f.writelines('\\n')\n",
    "        f.writelines(' %.8f ' % (i) for i in dis_cha)\n",
    "        f.writelines('\\n')\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    wgan = WGAN()\n",
    "    wgan.train(epochs=20, batch_size=64, sample_interval=200)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pppppppp [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
