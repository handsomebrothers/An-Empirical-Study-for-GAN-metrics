{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.client.session.Session at 0x7fd3b0514160>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "# #指定使用那块GUP训练\n",
    "import os\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "config = tf.ConfigProto()\n",
    "# 设置最大占有GPU不超过显存的70%\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.7 \n",
    "# # 重点：设置动态分配GPU\n",
    "config.gpu_options.allow_growth = True\n",
    "# 创建session时\n",
    "tf.Session(config=config) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "Sequential(\n",
      "  (0): Conv2d(3, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "  (2): ReLU()\n",
      "  (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "  (5): ReLU()\n",
      "  (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (7): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (8): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "  (9): ReLU()\n",
      "  (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (11): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "  (12): ReLU()\n",
      "  (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (14): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (15): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "  (16): ReLU()\n",
      "  (17): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (18): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "  (19): ReLU()\n",
      "  (20): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (21): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (22): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "  (23): ReLU()\n",
      "  (24): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      ")\n",
      "Sequential(\n",
      "  (0): Linear(in_features=1024, out_features=10, bias=True)\n",
      ")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_3 (Dense)              (None, 8192)              827392    \n",
      "_________________________________________________________________\n",
      "reshape_2 (Reshape)          (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2 (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 16, 16, 128)       147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 16, 16, 128)       512       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2 (None, 32, 32, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 32, 32, 64)        73792     \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 32, 32, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 32, 32, 3)         1731      \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 32, 32, 3)         0         \n",
      "=================================================================\n",
      "Total params: 1,051,267\n",
      "Trainable params: 1,050,883\n",
      "Non-trainable params: 384\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_8 (Conv2D)            (None, 16, 16, 32)        896       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_5 (LeakyReLU)    (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 8, 8, 64)          18496     \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 8, 8, 64)          256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_6 (LeakyReLU)    (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 4, 4, 128)         73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 4, 4, 128)         512       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_7 (LeakyReLU)    (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 4, 4, 256)         295168    \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 4, 4, 256)         1024      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_8 (LeakyReLU)    (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 100)               409700    \n",
      "=================================================================\n",
      "Total params: 799,908\n",
      "Trainable params: 799,012\n",
      "Non-trainable params: 896\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/imi432_006/anaconda3/envs/tf/lib/python3.5/site-packages/keras/engine/training.py:490: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "  'Discrepancy between trainable weights and collected trainable'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0 step:1 [D loss: 1.071894, acc: 42.19%] [G loss: 8.116537]\n",
      "epoch:0 step:2 [D loss: 0.284235, acc: 86.72%] [G loss: 9.533644]\n",
      "epoch:0 step:3 [D loss: 0.083295, acc: 98.44%] [G loss: 9.846010]\n",
      "epoch:0 step:4 [D loss: 0.214717, acc: 94.53%] [G loss: 9.532492]\n",
      "epoch:0 step:5 [D loss: 0.139198, acc: 96.88%] [G loss: 9.261973]\n",
      "epoch:0 step:6 [D loss: 0.617191, acc: 71.09%] [G loss: 7.559661]\n",
      "epoch:0 step:7 [D loss: 0.602661, acc: 78.91%] [G loss: 5.743185]\n",
      "epoch:0 step:8 [D loss: 2.052404, acc: 35.94%] [G loss: 3.717464]\n",
      "epoch:0 step:9 [D loss: 0.232312, acc: 89.06%] [G loss: 3.810910]\n",
      "epoch:0 step:10 [D loss: 1.423892, acc: 46.09%] [G loss: 6.249705]\n",
      "epoch:0 step:11 [D loss: 0.547789, acc: 78.12%] [G loss: 6.263858]\n",
      "epoch:0 step:12 [D loss: 0.477442, acc: 81.25%] [G loss: 5.751565]\n",
      "epoch:0 step:13 [D loss: 0.163575, acc: 89.84%] [G loss: 5.365552]\n",
      "epoch:0 step:14 [D loss: 0.521411, acc: 74.22%] [G loss: 8.290746]\n",
      "epoch:0 step:15 [D loss: 0.401482, acc: 85.94%] [G loss: 9.667978]\n",
      "epoch:0 step:16 [D loss: 0.520714, acc: 82.81%] [G loss: 5.860289]\n",
      "epoch:0 step:17 [D loss: 0.352784, acc: 87.50%] [G loss: 5.846602]\n",
      "epoch:0 step:18 [D loss: 0.060289, acc: 99.22%] [G loss: 6.308526]\n",
      "epoch:0 step:19 [D loss: 0.132507, acc: 97.66%] [G loss: 4.523320]\n",
      "epoch:0 step:20 [D loss: 1.850438, acc: 48.44%] [G loss: 10.290670]\n",
      "epoch:0 step:21 [D loss: 0.320080, acc: 86.72%] [G loss: 14.650810]\n",
      "epoch:0 step:22 [D loss: 0.420605, acc: 82.81%] [G loss: 14.190940]\n",
      "epoch:0 step:23 [D loss: 0.253253, acc: 91.41%] [G loss: 13.235325]\n",
      "epoch:0 step:24 [D loss: 0.110963, acc: 96.09%] [G loss: 11.402447]\n",
      "epoch:0 step:25 [D loss: 0.073552, acc: 98.44%] [G loss: 9.488727]\n",
      "epoch:0 step:26 [D loss: 0.089403, acc: 97.66%] [G loss: 7.451984]\n",
      "epoch:0 step:27 [D loss: 0.068743, acc: 98.44%] [G loss: 6.262884]\n",
      "epoch:0 step:28 [D loss: 0.062049, acc: 100.00%] [G loss: 5.349332]\n",
      "epoch:0 step:29 [D loss: 0.111691, acc: 98.44%] [G loss: 4.446642]\n",
      "epoch:0 step:30 [D loss: 0.116403, acc: 95.31%] [G loss: 5.424427]\n",
      "epoch:0 step:31 [D loss: 0.078478, acc: 99.22%] [G loss: 4.853460]\n",
      "epoch:0 step:32 [D loss: 0.052583, acc: 99.22%] [G loss: 4.210369]\n",
      "epoch:0 step:33 [D loss: 0.094340, acc: 96.88%] [G loss: 4.590140]\n",
      "epoch:0 step:34 [D loss: 0.090662, acc: 96.88%] [G loss: 4.391327]\n",
      "epoch:0 step:35 [D loss: 0.086126, acc: 99.22%] [G loss: 4.660314]\n",
      "epoch:0 step:36 [D loss: 0.094767, acc: 96.88%] [G loss: 4.993199]\n",
      "epoch:0 step:37 [D loss: 0.093887, acc: 98.44%] [G loss: 5.382637]\n",
      "epoch:0 step:38 [D loss: 0.161938, acc: 94.53%] [G loss: 7.531525]\n",
      "epoch:0 step:39 [D loss: 0.219916, acc: 94.53%] [G loss: 8.568277]\n",
      "epoch:0 step:40 [D loss: 0.078999, acc: 96.88%] [G loss: 9.555547]\n",
      "epoch:0 step:41 [D loss: 0.132355, acc: 94.53%] [G loss: 8.832428]\n",
      "epoch:0 step:42 [D loss: 0.057494, acc: 99.22%] [G loss: 8.400054]\n",
      "epoch:0 step:43 [D loss: 0.077511, acc: 98.44%] [G loss: 9.599905]\n",
      "epoch:0 step:44 [D loss: 0.042276, acc: 100.00%] [G loss: 8.783249]\n",
      "epoch:0 step:45 [D loss: 0.050178, acc: 100.00%] [G loss: 8.369575]\n",
      "epoch:0 step:46 [D loss: 0.090595, acc: 99.22%] [G loss: 6.974558]\n",
      "epoch:0 step:47 [D loss: 0.049997, acc: 100.00%] [G loss: 6.051229]\n",
      "epoch:0 step:48 [D loss: 0.049244, acc: 99.22%] [G loss: 6.110130]\n",
      "epoch:0 step:49 [D loss: 0.102210, acc: 99.22%] [G loss: 3.794911]\n",
      "epoch:0 step:50 [D loss: 0.039266, acc: 100.00%] [G loss: 4.698504]\n",
      "epoch:0 step:51 [D loss: 0.163650, acc: 96.88%] [G loss: 6.414954]\n",
      "epoch:0 step:52 [D loss: 0.061829, acc: 98.44%] [G loss: 6.640229]\n",
      "epoch:0 step:53 [D loss: 0.082450, acc: 99.22%] [G loss: 6.770630]\n",
      "epoch:0 step:54 [D loss: 0.072507, acc: 98.44%] [G loss: 8.009042]\n",
      "epoch:0 step:55 [D loss: 0.099116, acc: 96.88%] [G loss: 7.977557]\n",
      "epoch:0 step:56 [D loss: 0.024920, acc: 100.00%] [G loss: 8.282997]\n",
      "epoch:0 step:57 [D loss: 0.114114, acc: 96.88%] [G loss: 6.010632]\n",
      "epoch:0 step:58 [D loss: 0.079262, acc: 98.44%] [G loss: 4.850621]\n",
      "epoch:0 step:59 [D loss: 0.150173, acc: 95.31%] [G loss: 3.849432]\n",
      "epoch:0 step:60 [D loss: 0.079263, acc: 97.66%] [G loss: 5.302719]\n",
      "epoch:0 step:61 [D loss: 0.251477, acc: 89.84%] [G loss: 6.348565]\n",
      "epoch:0 step:62 [D loss: 0.112543, acc: 97.66%] [G loss: 5.641594]\n",
      "epoch:0 step:63 [D loss: 0.091087, acc: 99.22%] [G loss: 4.055451]\n",
      "epoch:0 step:64 [D loss: 0.382045, acc: 78.91%] [G loss: 6.110061]\n",
      "epoch:0 step:65 [D loss: 0.164701, acc: 90.62%] [G loss: 5.829129]\n",
      "epoch:0 step:66 [D loss: 0.129810, acc: 98.44%] [G loss: 4.100964]\n",
      "epoch:0 step:67 [D loss: 0.334334, acc: 89.84%] [G loss: 6.304476]\n",
      "epoch:0 step:68 [D loss: 0.193698, acc: 93.75%] [G loss: 6.662580]\n",
      "epoch:0 step:69 [D loss: 0.127852, acc: 96.88%] [G loss: 8.112728]\n",
      "epoch:0 step:70 [D loss: 0.127472, acc: 97.66%] [G loss: 8.523997]\n",
      "epoch:0 step:71 [D loss: 0.200981, acc: 93.75%] [G loss: 6.374787]\n",
      "epoch:0 step:72 [D loss: 0.091022, acc: 100.00%] [G loss: 6.823710]\n",
      "epoch:0 step:73 [D loss: 0.087033, acc: 98.44%] [G loss: 4.592740]\n",
      "epoch:0 step:74 [D loss: 0.234993, acc: 91.41%] [G loss: 5.091707]\n",
      "epoch:0 step:75 [D loss: 0.246676, acc: 92.97%] [G loss: 6.834146]\n",
      "epoch:0 step:76 [D loss: 0.406007, acc: 88.28%] [G loss: 6.611903]\n",
      "epoch:0 step:77 [D loss: 0.039066, acc: 100.00%] [G loss: 5.001999]\n",
      "epoch:0 step:78 [D loss: 0.175936, acc: 94.53%] [G loss: 7.808967]\n",
      "epoch:0 step:79 [D loss: 0.021523, acc: 100.00%] [G loss: 9.654984]\n",
      "epoch:0 step:80 [D loss: 0.084824, acc: 99.22%] [G loss: 7.182005]\n",
      "epoch:0 step:81 [D loss: 0.136183, acc: 94.53%] [G loss: 4.474535]\n",
      "epoch:0 step:82 [D loss: 0.092110, acc: 97.66%] [G loss: 5.056329]\n",
      "epoch:0 step:83 [D loss: 0.045033, acc: 99.22%] [G loss: 5.879450]\n",
      "epoch:0 step:84 [D loss: 0.102595, acc: 96.88%] [G loss: 6.439069]\n",
      "epoch:0 step:85 [D loss: 0.043290, acc: 99.22%] [G loss: 5.610312]\n",
      "epoch:0 step:86 [D loss: 0.094632, acc: 97.66%] [G loss: 5.846498]\n",
      "epoch:0 step:87 [D loss: 0.133447, acc: 93.75%] [G loss: 7.598444]\n",
      "epoch:0 step:88 [D loss: 0.250262, acc: 90.62%] [G loss: 7.980755]\n",
      "epoch:0 step:89 [D loss: 0.029365, acc: 100.00%] [G loss: 7.972615]\n",
      "epoch:0 step:90 [D loss: 0.018376, acc: 100.00%] [G loss: 8.142776]\n",
      "epoch:0 step:91 [D loss: 0.024628, acc: 100.00%] [G loss: 6.077251]\n",
      "epoch:0 step:92 [D loss: 0.040771, acc: 99.22%] [G loss: 5.565041]\n",
      "epoch:0 step:93 [D loss: 0.105846, acc: 96.88%] [G loss: 5.249347]\n",
      "epoch:0 step:94 [D loss: 0.064052, acc: 99.22%] [G loss: 5.093952]\n",
      "epoch:0 step:95 [D loss: 0.036506, acc: 100.00%] [G loss: 5.693214]\n",
      "epoch:0 step:96 [D loss: 0.086426, acc: 97.66%] [G loss: 5.717993]\n",
      "epoch:0 step:97 [D loss: 0.061598, acc: 100.00%] [G loss: 9.301559]\n",
      "epoch:0 step:98 [D loss: 0.019887, acc: 100.00%] [G loss: 10.651588]\n",
      "epoch:0 step:99 [D loss: 0.066258, acc: 97.66%] [G loss: 8.825679]\n",
      "epoch:0 step:100 [D loss: 0.069726, acc: 99.22%] [G loss: 8.215501]\n",
      "epoch:0 step:101 [D loss: 0.049519, acc: 100.00%] [G loss: 8.585338]\n",
      "epoch:0 step:102 [D loss: 0.101642, acc: 96.09%] [G loss: 10.258308]\n",
      "epoch:0 step:103 [D loss: 0.027925, acc: 100.00%] [G loss: 11.032917]\n",
      "epoch:0 step:104 [D loss: 0.042866, acc: 99.22%] [G loss: 8.988838]\n",
      "epoch:0 step:105 [D loss: 0.091185, acc: 98.44%] [G loss: 8.429583]\n",
      "epoch:0 step:106 [D loss: 0.080157, acc: 99.22%] [G loss: 8.052131]\n",
      "epoch:0 step:107 [D loss: 0.038271, acc: 100.00%] [G loss: 8.675385]\n",
      "epoch:0 step:108 [D loss: 0.170540, acc: 92.97%] [G loss: 12.760889]\n",
      "epoch:0 step:109 [D loss: 0.054666, acc: 97.66%] [G loss: 13.423957]\n",
      "epoch:0 step:110 [D loss: 0.049999, acc: 99.22%] [G loss: 12.010540]\n",
      "epoch:0 step:111 [D loss: 0.037276, acc: 99.22%] [G loss: 10.530612]\n",
      "epoch:0 step:112 [D loss: 0.037852, acc: 99.22%] [G loss: 9.930183]\n",
      "epoch:0 step:113 [D loss: 0.069948, acc: 98.44%] [G loss: 8.383458]\n",
      "epoch:0 step:114 [D loss: 0.034224, acc: 100.00%] [G loss: 7.252568]\n",
      "epoch:0 step:115 [D loss: 0.052000, acc: 100.00%] [G loss: 5.040771]\n",
      "epoch:0 step:116 [D loss: 0.040044, acc: 100.00%] [G loss: 4.493577]\n",
      "epoch:0 step:117 [D loss: 0.074803, acc: 100.00%] [G loss: 3.730185]\n",
      "epoch:0 step:118 [D loss: 0.081638, acc: 100.00%] [G loss: 2.760186]\n",
      "epoch:0 step:119 [D loss: 0.074323, acc: 97.66%] [G loss: 5.006743]\n",
      "epoch:0 step:120 [D loss: 0.086858, acc: 100.00%] [G loss: 4.435870]\n",
      "epoch:0 step:121 [D loss: 0.076277, acc: 98.44%] [G loss: 5.098484]\n",
      "epoch:0 step:122 [D loss: 0.117077, acc: 94.53%] [G loss: 6.197310]\n",
      "epoch:0 step:123 [D loss: 0.029630, acc: 100.00%] [G loss: 5.694839]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0 step:124 [D loss: 0.028586, acc: 100.00%] [G loss: 5.222867]\n",
      "epoch:0 step:125 [D loss: 0.052866, acc: 99.22%] [G loss: 5.745964]\n",
      "epoch:0 step:126 [D loss: 0.083064, acc: 99.22%] [G loss: 6.625940]\n",
      "epoch:0 step:127 [D loss: 0.069275, acc: 100.00%] [G loss: 5.842546]\n",
      "epoch:0 step:128 [D loss: 0.053383, acc: 100.00%] [G loss: 4.819181]\n",
      "epoch:0 step:129 [D loss: 0.035443, acc: 99.22%] [G loss: 5.266744]\n",
      "epoch:0 step:130 [D loss: 0.035688, acc: 100.00%] [G loss: 4.152209]\n",
      "epoch:0 step:131 [D loss: 0.388503, acc: 82.03%] [G loss: 7.510274]\n",
      "epoch:0 step:132 [D loss: 0.047700, acc: 99.22%] [G loss: 7.422567]\n",
      "epoch:0 step:133 [D loss: 0.156401, acc: 92.97%] [G loss: 6.356783]\n",
      "epoch:0 step:134 [D loss: 0.022332, acc: 100.00%] [G loss: 5.880509]\n",
      "epoch:0 step:135 [D loss: 0.089378, acc: 97.66%] [G loss: 5.943245]\n",
      "epoch:0 step:136 [D loss: 0.037286, acc: 99.22%] [G loss: 6.202609]\n",
      "epoch:0 step:137 [D loss: 0.561871, acc: 75.78%] [G loss: 9.337641]\n",
      "epoch:0 step:138 [D loss: 0.254672, acc: 89.84%] [G loss: 10.355740]\n",
      "epoch:0 step:139 [D loss: 0.141675, acc: 94.53%] [G loss: 9.647409]\n",
      "epoch:0 step:140 [D loss: 0.596458, acc: 81.25%] [G loss: 8.643621]\n",
      "epoch:0 step:141 [D loss: 0.171289, acc: 95.31%] [G loss: 8.874504]\n",
      "epoch:0 step:142 [D loss: 0.166268, acc: 93.75%] [G loss: 9.517425]\n",
      "epoch:0 step:143 [D loss: 0.082888, acc: 97.66%] [G loss: 11.527685]\n",
      "epoch:0 step:144 [D loss: 0.039526, acc: 100.00%] [G loss: 9.713228]\n",
      "epoch:0 step:145 [D loss: 0.298240, acc: 88.28%] [G loss: 10.491468]\n",
      "epoch:0 step:146 [D loss: 0.015680, acc: 100.00%] [G loss: 7.521917]\n",
      "epoch:0 step:147 [D loss: 0.017586, acc: 100.00%] [G loss: 5.688654]\n",
      "epoch:0 step:148 [D loss: 0.148067, acc: 96.88%] [G loss: 5.266477]\n",
      "epoch:0 step:149 [D loss: 0.052810, acc: 99.22%] [G loss: 4.954762]\n",
      "epoch:0 step:150 [D loss: 0.024332, acc: 100.00%] [G loss: 4.245184]\n",
      "epoch:0 step:151 [D loss: 0.015547, acc: 100.00%] [G loss: 5.705115]\n",
      "epoch:0 step:152 [D loss: 0.546277, acc: 79.69%] [G loss: 7.383696]\n",
      "epoch:0 step:153 [D loss: 0.073930, acc: 96.88%] [G loss: 9.456999]\n",
      "epoch:0 step:154 [D loss: 0.068431, acc: 98.44%] [G loss: 7.823400]\n",
      "epoch:0 step:155 [D loss: 0.132340, acc: 98.44%] [G loss: 4.317551]\n",
      "epoch:0 step:156 [D loss: 0.089829, acc: 99.22%] [G loss: 3.234418]\n",
      "epoch:0 step:157 [D loss: 0.453852, acc: 91.41%] [G loss: 6.602981]\n",
      "epoch:0 step:158 [D loss: 0.030369, acc: 100.00%] [G loss: 7.216072]\n",
      "epoch:0 step:159 [D loss: 0.308250, acc: 86.72%] [G loss: 5.086276]\n",
      "epoch:0 step:160 [D loss: 0.213691, acc: 91.41%] [G loss: 8.175221]\n",
      "epoch:0 step:161 [D loss: 0.118222, acc: 96.88%] [G loss: 10.961876]\n",
      "epoch:0 step:162 [D loss: 0.357566, acc: 89.84%] [G loss: 10.198972]\n",
      "epoch:0 step:163 [D loss: 0.075076, acc: 98.44%] [G loss: 8.482408]\n",
      "epoch:0 step:164 [D loss: 0.096240, acc: 97.66%] [G loss: 8.288527]\n",
      "epoch:0 step:165 [D loss: 0.097949, acc: 99.22%] [G loss: 9.476361]\n",
      "epoch:0 step:166 [D loss: 0.028990, acc: 100.00%] [G loss: 10.406557]\n",
      "epoch:0 step:167 [D loss: 0.039712, acc: 100.00%] [G loss: 10.119545]\n",
      "epoch:0 step:168 [D loss: 0.036340, acc: 100.00%] [G loss: 8.972244]\n",
      "epoch:0 step:169 [D loss: 0.066543, acc: 100.00%] [G loss: 6.061871]\n",
      "epoch:0 step:170 [D loss: 0.046101, acc: 100.00%] [G loss: 6.990760]\n",
      "epoch:0 step:171 [D loss: 0.026824, acc: 99.22%] [G loss: 7.801295]\n",
      "epoch:0 step:172 [D loss: 1.798097, acc: 52.34%] [G loss: 12.393364]\n",
      "epoch:0 step:173 [D loss: 0.058562, acc: 98.44%] [G loss: 12.260886]\n",
      "epoch:0 step:174 [D loss: 0.153559, acc: 97.66%] [G loss: 11.309839]\n",
      "epoch:0 step:175 [D loss: 0.024678, acc: 100.00%] [G loss: 10.200230]\n",
      "epoch:0 step:176 [D loss: 0.106869, acc: 96.09%] [G loss: 10.391679]\n",
      "epoch:0 step:177 [D loss: 0.073666, acc: 98.44%] [G loss: 8.504590]\n",
      "epoch:0 step:178 [D loss: 0.041219, acc: 100.00%] [G loss: 7.804287]\n",
      "epoch:0 step:179 [D loss: 0.077255, acc: 98.44%] [G loss: 6.239804]\n",
      "epoch:0 step:180 [D loss: 0.145449, acc: 95.31%] [G loss: 5.040894]\n",
      "epoch:0 step:181 [D loss: 0.150283, acc: 94.53%] [G loss: 5.338306]\n",
      "epoch:0 step:182 [D loss: 0.091782, acc: 97.66%] [G loss: 4.978610]\n",
      "epoch:0 step:183 [D loss: 0.044629, acc: 100.00%] [G loss: 5.162788]\n",
      "epoch:0 step:184 [D loss: 0.050221, acc: 99.22%] [G loss: 5.200533]\n",
      "epoch:0 step:185 [D loss: 0.213884, acc: 95.31%] [G loss: 4.055657]\n",
      "epoch:0 step:186 [D loss: 0.312573, acc: 85.16%] [G loss: 6.377431]\n",
      "epoch:0 step:187 [D loss: 0.224268, acc: 96.09%] [G loss: 8.411150]\n",
      "epoch:0 step:188 [D loss: 1.839227, acc: 53.12%] [G loss: 14.169149]\n",
      "epoch:0 step:189 [D loss: 0.059631, acc: 100.00%] [G loss: 14.064840]\n",
      "epoch:0 step:190 [D loss: 0.039231, acc: 100.00%] [G loss: 13.256614]\n",
      "epoch:0 step:191 [D loss: 0.023087, acc: 100.00%] [G loss: 11.368990]\n",
      "epoch:0 step:192 [D loss: 0.066757, acc: 100.00%] [G loss: 8.941079]\n",
      "epoch:0 step:193 [D loss: 0.080429, acc: 97.66%] [G loss: 8.096354]\n",
      "epoch:0 step:194 [D loss: 0.056683, acc: 99.22%] [G loss: 6.785764]\n",
      "epoch:0 step:195 [D loss: 0.308183, acc: 89.84%] [G loss: 9.089806]\n",
      "epoch:0 step:196 [D loss: 0.265468, acc: 90.62%] [G loss: 11.168268]\n",
      "epoch:0 step:197 [D loss: 0.054112, acc: 100.00%] [G loss: 12.430931]\n",
      "epoch:0 step:198 [D loss: 0.038039, acc: 99.22%] [G loss: 11.177227]\n",
      "epoch:0 step:199 [D loss: 0.500439, acc: 84.38%] [G loss: 8.894313]\n",
      "epoch:0 step:200 [D loss: 0.045256, acc: 100.00%] [G loss: 8.819939]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/imi432_006/anaconda3/envs/tf/lib/python3.5/site-packages/ipykernel_launcher.py:57: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "/home/imi432_006/anaconda3/envs/tf/lib/python3.5/site-packages/ipykernel_launcher.py:59: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/home/imi432_006/anaconda3/envs/tf/lib/python3.5/site-packages/ipykernel_launcher.py:86: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "/home/imi432_006/anaconda3/envs/tf/lib/python3.5/site-packages/ipykernel_launcher.py:90: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##############\n",
      "[0.85250496 0.88283168 0.83496887 0.82940726 0.78648759 0.82138205\n",
      " 0.85997395 0.84619399 0.83678321 0.83821925]\n",
      "##########\n",
      "epoch:0 step:201 [D loss: 0.090179, acc: 98.44%] [G loss: 7.503876]\n",
      "epoch:0 step:202 [D loss: 0.045306, acc: 100.00%] [G loss: 7.136096]\n",
      "epoch:0 step:203 [D loss: 0.120794, acc: 96.88%] [G loss: 6.996913]\n",
      "epoch:0 step:204 [D loss: 0.132509, acc: 98.44%] [G loss: 6.647105]\n",
      "epoch:0 step:205 [D loss: 0.154781, acc: 98.44%] [G loss: 6.719089]\n",
      "epoch:0 step:206 [D loss: 0.076687, acc: 98.44%] [G loss: 7.472288]\n",
      "epoch:0 step:207 [D loss: 0.159628, acc: 92.97%] [G loss: 7.162655]\n",
      "epoch:0 step:208 [D loss: 0.071163, acc: 99.22%] [G loss: 6.944160]\n",
      "epoch:0 step:209 [D loss: 0.033166, acc: 100.00%] [G loss: 8.147186]\n",
      "epoch:0 step:210 [D loss: 0.062185, acc: 100.00%] [G loss: 7.263508]\n",
      "epoch:0 step:211 [D loss: 0.062334, acc: 100.00%] [G loss: 7.673042]\n",
      "epoch:0 step:212 [D loss: 0.027782, acc: 100.00%] [G loss: 7.904108]\n",
      "epoch:0 step:213 [D loss: 0.052580, acc: 99.22%] [G loss: 7.390604]\n",
      "epoch:0 step:214 [D loss: 0.032690, acc: 100.00%] [G loss: 8.700760]\n",
      "epoch:0 step:215 [D loss: 0.038086, acc: 100.00%] [G loss: 8.588396]\n",
      "epoch:0 step:216 [D loss: 0.115423, acc: 97.66%] [G loss: 9.817245]\n",
      "epoch:0 step:217 [D loss: 2.545272, acc: 37.50%] [G loss: 15.091449]\n",
      "epoch:0 step:218 [D loss: 0.020533, acc: 99.22%] [G loss: 16.863037]\n",
      "epoch:0 step:219 [D loss: 0.016902, acc: 100.00%] [G loss: 15.802366]\n",
      "epoch:0 step:220 [D loss: 0.063081, acc: 99.22%] [G loss: 14.514153]\n",
      "epoch:0 step:221 [D loss: 0.047328, acc: 99.22%] [G loss: 14.378418]\n",
      "epoch:0 step:222 [D loss: 0.030736, acc: 99.22%] [G loss: 14.049589]\n",
      "epoch:0 step:223 [D loss: 0.064797, acc: 97.66%] [G loss: 13.056021]\n",
      "epoch:0 step:224 [D loss: 0.075763, acc: 98.44%] [G loss: 11.165296]\n",
      "epoch:0 step:225 [D loss: 0.038449, acc: 99.22%] [G loss: 10.450588]\n",
      "epoch:0 step:226 [D loss: 0.281611, acc: 90.62%] [G loss: 11.189735]\n",
      "epoch:0 step:227 [D loss: 0.131978, acc: 95.31%] [G loss: 13.286219]\n",
      "epoch:0 step:228 [D loss: 0.534033, acc: 83.59%] [G loss: 9.696348]\n",
      "epoch:0 step:229 [D loss: 0.133837, acc: 96.09%] [G loss: 10.131914]\n",
      "epoch:0 step:230 [D loss: 0.021646, acc: 100.00%] [G loss: 11.912035]\n",
      "epoch:0 step:231 [D loss: 0.070854, acc: 100.00%] [G loss: 8.658909]\n",
      "epoch:0 step:232 [D loss: 0.082805, acc: 100.00%] [G loss: 7.591727]\n",
      "epoch:0 step:233 [D loss: 0.157879, acc: 93.75%] [G loss: 7.120743]\n",
      "epoch:0 step:234 [D loss: 0.063645, acc: 100.00%] [G loss: 7.031926]\n",
      "epoch:0 step:235 [D loss: 0.206065, acc: 91.41%] [G loss: 5.893265]\n",
      "epoch:0 step:236 [D loss: 5.614775, acc: 18.75%] [G loss: 6.848973]\n",
      "epoch:0 step:237 [D loss: 1.839009, acc: 57.81%] [G loss: 8.628697]\n",
      "epoch:0 step:238 [D loss: 0.641831, acc: 72.66%] [G loss: 9.109072]\n",
      "epoch:0 step:239 [D loss: 0.857160, acc: 69.53%] [G loss: 6.771821]\n",
      "epoch:0 step:240 [D loss: 0.436802, acc: 76.56%] [G loss: 7.484355]\n",
      "epoch:0 step:241 [D loss: 0.145925, acc: 93.75%] [G loss: 8.343440]\n",
      "epoch:0 step:242 [D loss: 0.162532, acc: 99.22%] [G loss: 6.807863]\n",
      "epoch:0 step:243 [D loss: 1.203138, acc: 70.31%] [G loss: 5.529861]\n",
      "epoch:0 step:244 [D loss: 0.559957, acc: 73.44%] [G loss: 6.828509]\n",
      "epoch:0 step:245 [D loss: 0.132970, acc: 96.09%] [G loss: 8.865778]\n",
      "epoch:0 step:246 [D loss: 0.116612, acc: 99.22%] [G loss: 7.610769]\n",
      "epoch:0 step:247 [D loss: 0.170013, acc: 96.88%] [G loss: 7.501374]\n",
      "epoch:0 step:248 [D loss: 0.096666, acc: 99.22%] [G loss: 6.205077]\n",
      "epoch:0 step:249 [D loss: 1.463104, acc: 48.44%] [G loss: 5.335535]\n",
      "epoch:0 step:250 [D loss: 0.284926, acc: 91.41%] [G loss: 5.833242]\n",
      "epoch:0 step:251 [D loss: 0.130725, acc: 99.22%] [G loss: 7.470711]\n",
      "epoch:0 step:252 [D loss: 0.081551, acc: 100.00%] [G loss: 6.935406]\n",
      "epoch:0 step:253 [D loss: 0.163377, acc: 99.22%] [G loss: 7.009377]\n",
      "epoch:0 step:254 [D loss: 0.083134, acc: 100.00%] [G loss: 6.824161]\n",
      "epoch:0 step:255 [D loss: 2.673263, acc: 12.50%] [G loss: 5.224191]\n",
      "epoch:0 step:256 [D loss: 0.201142, acc: 94.53%] [G loss: 6.062553]\n",
      "epoch:0 step:257 [D loss: 0.392636, acc: 85.94%] [G loss: 7.210292]\n",
      "epoch:0 step:258 [D loss: 0.249910, acc: 93.75%] [G loss: 6.400097]\n",
      "epoch:0 step:259 [D loss: 0.302730, acc: 89.84%] [G loss: 6.322279]\n",
      "epoch:0 step:260 [D loss: 0.287111, acc: 89.06%] [G loss: 7.300066]\n",
      "epoch:0 step:261 [D loss: 0.371825, acc: 83.59%] [G loss: 6.786965]\n",
      "epoch:0 step:262 [D loss: 0.452978, acc: 81.25%] [G loss: 6.436322]\n",
      "epoch:0 step:263 [D loss: 0.775462, acc: 68.75%] [G loss: 6.267446]\n",
      "epoch:0 step:264 [D loss: 0.159923, acc: 95.31%] [G loss: 7.448854]\n",
      "epoch:0 step:265 [D loss: 0.316236, acc: 83.59%] [G loss: 6.191112]\n",
      "epoch:0 step:266 [D loss: 1.151711, acc: 42.19%] [G loss: 4.611267]\n",
      "epoch:0 step:267 [D loss: 0.447261, acc: 79.69%] [G loss: 5.496934]\n",
      "epoch:0 step:268 [D loss: 0.582233, acc: 73.44%] [G loss: 6.328586]\n",
      "epoch:0 step:269 [D loss: 0.414265, acc: 76.56%] [G loss: 5.915167]\n",
      "epoch:0 step:270 [D loss: 0.370035, acc: 84.38%] [G loss: 7.238351]\n",
      "epoch:0 step:271 [D loss: 0.213653, acc: 95.31%] [G loss: 7.433442]\n",
      "epoch:0 step:272 [D loss: 0.321938, acc: 85.94%] [G loss: 6.823817]\n",
      "epoch:0 step:273 [D loss: 0.360990, acc: 82.03%] [G loss: 5.534617]\n",
      "epoch:0 step:274 [D loss: 0.431994, acc: 78.12%] [G loss: 4.751283]\n",
      "epoch:0 step:275 [D loss: 1.082099, acc: 55.47%] [G loss: 4.985989]\n",
      "epoch:0 step:276 [D loss: 0.672584, acc: 69.53%] [G loss: 4.846514]\n",
      "epoch:0 step:277 [D loss: 0.844814, acc: 57.03%] [G loss: 4.200845]\n",
      "epoch:0 step:278 [D loss: 0.883649, acc: 58.59%] [G loss: 5.365162]\n",
      "epoch:0 step:279 [D loss: 1.072349, acc: 64.84%] [G loss: 6.681479]\n",
      "epoch:0 step:280 [D loss: 0.259563, acc: 89.84%] [G loss: 6.177537]\n",
      "epoch:0 step:281 [D loss: 0.765392, acc: 70.31%] [G loss: 5.426761]\n",
      "epoch:0 step:282 [D loss: 0.194301, acc: 93.75%] [G loss: 6.564980]\n",
      "epoch:0 step:283 [D loss: 0.767238, acc: 69.53%] [G loss: 5.486220]\n",
      "epoch:0 step:284 [D loss: 0.121572, acc: 97.66%] [G loss: 5.760947]\n",
      "epoch:0 step:285 [D loss: 0.150654, acc: 96.09%] [G loss: 5.660796]\n",
      "epoch:0 step:286 [D loss: 0.207933, acc: 93.75%] [G loss: 5.991292]\n",
      "epoch:0 step:287 [D loss: 0.104256, acc: 98.44%] [G loss: 5.889830]\n",
      "epoch:0 step:288 [D loss: 0.210508, acc: 92.97%] [G loss: 5.566813]\n",
      "epoch:0 step:289 [D loss: 0.356974, acc: 82.03%] [G loss: 5.872775]\n",
      "epoch:0 step:290 [D loss: 0.306426, acc: 91.41%] [G loss: 4.557567]\n",
      "epoch:0 step:291 [D loss: 0.351921, acc: 84.38%] [G loss: 5.299624]\n",
      "epoch:0 step:292 [D loss: 0.431211, acc: 80.47%] [G loss: 6.392057]\n",
      "epoch:0 step:293 [D loss: 0.293378, acc: 89.84%] [G loss: 5.286425]\n",
      "epoch:0 step:294 [D loss: 0.698600, acc: 74.22%] [G loss: 5.270928]\n",
      "epoch:0 step:295 [D loss: 0.140640, acc: 97.66%] [G loss: 5.587801]\n",
      "epoch:0 step:296 [D loss: 0.858100, acc: 57.03%] [G loss: 5.273453]\n",
      "epoch:0 step:297 [D loss: 1.709894, acc: 50.00%] [G loss: 6.915607]\n",
      "epoch:0 step:298 [D loss: 1.158802, acc: 65.62%] [G loss: 6.834565]\n",
      "epoch:0 step:299 [D loss: 0.515015, acc: 82.03%] [G loss: 7.414264]\n",
      "epoch:0 step:300 [D loss: 0.424522, acc: 81.25%] [G loss: 6.502041]\n",
      "epoch:0 step:301 [D loss: 0.456340, acc: 83.59%] [G loss: 6.066942]\n",
      "epoch:0 step:302 [D loss: 0.265816, acc: 88.28%] [G loss: 5.797383]\n",
      "epoch:0 step:303 [D loss: 0.793340, acc: 63.28%] [G loss: 4.030927]\n",
      "epoch:0 step:304 [D loss: 0.610355, acc: 71.88%] [G loss: 4.528021]\n",
      "epoch:0 step:305 [D loss: 0.624237, acc: 71.09%] [G loss: 3.097961]\n",
      "epoch:0 step:306 [D loss: 0.150984, acc: 96.88%] [G loss: 4.373342]\n",
      "epoch:0 step:307 [D loss: 0.724674, acc: 75.78%] [G loss: 4.379734]\n",
      "epoch:0 step:308 [D loss: 0.432106, acc: 75.78%] [G loss: 3.622302]\n",
      "epoch:0 step:309 [D loss: 0.543160, acc: 79.69%] [G loss: 3.935909]\n",
      "epoch:0 step:310 [D loss: 0.214953, acc: 95.31%] [G loss: 3.608088]\n",
      "epoch:0 step:311 [D loss: 1.273723, acc: 32.03%] [G loss: 2.706423]\n",
      "epoch:0 step:312 [D loss: 0.757611, acc: 59.38%] [G loss: 3.474161]\n",
      "epoch:0 step:313 [D loss: 1.638886, acc: 21.88%] [G loss: 3.878567]\n",
      "epoch:0 step:314 [D loss: 0.537625, acc: 79.69%] [G loss: 3.262104]\n",
      "epoch:0 step:315 [D loss: 2.726847, acc: 21.88%] [G loss: 3.852201]\n",
      "epoch:0 step:316 [D loss: 1.057164, acc: 54.69%] [G loss: 3.135832]\n",
      "epoch:0 step:317 [D loss: 1.368812, acc: 36.72%] [G loss: 2.471334]\n",
      "epoch:0 step:318 [D loss: 0.954596, acc: 52.34%] [G loss: 3.000026]\n",
      "epoch:0 step:319 [D loss: 1.135379, acc: 50.78%] [G loss: 3.319979]\n",
      "epoch:0 step:320 [D loss: 0.826667, acc: 64.06%] [G loss: 4.141262]\n",
      "epoch:0 step:321 [D loss: 0.615562, acc: 71.88%] [G loss: 4.459796]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0 step:322 [D loss: 0.366598, acc: 88.28%] [G loss: 3.845159]\n",
      "epoch:0 step:323 [D loss: 0.246236, acc: 92.97%] [G loss: 3.835750]\n",
      "epoch:0 step:324 [D loss: 0.288440, acc: 92.19%] [G loss: 3.639450]\n",
      "epoch:0 step:325 [D loss: 0.313843, acc: 88.28%] [G loss: 4.183655]\n",
      "epoch:0 step:326 [D loss: 0.337000, acc: 89.84%] [G loss: 3.970679]\n",
      "epoch:0 step:327 [D loss: 0.316163, acc: 82.81%] [G loss: 3.616381]\n",
      "epoch:0 step:328 [D loss: 0.457661, acc: 82.03%] [G loss: 3.279543]\n",
      "epoch:0 step:329 [D loss: 0.505524, acc: 80.47%] [G loss: 2.810371]\n",
      "epoch:0 step:330 [D loss: 0.540498, acc: 77.34%] [G loss: 3.227306]\n",
      "epoch:0 step:331 [D loss: 0.325613, acc: 83.59%] [G loss: 3.399476]\n",
      "epoch:0 step:332 [D loss: 0.411821, acc: 85.16%] [G loss: 3.674945]\n",
      "epoch:0 step:333 [D loss: 0.464549, acc: 80.47%] [G loss: 2.947493]\n",
      "epoch:0 step:334 [D loss: 0.460954, acc: 78.12%] [G loss: 3.862185]\n",
      "epoch:0 step:335 [D loss: 0.416727, acc: 78.91%] [G loss: 3.425246]\n",
      "epoch:0 step:336 [D loss: 0.729353, acc: 65.62%] [G loss: 3.180495]\n",
      "epoch:0 step:337 [D loss: 0.544503, acc: 79.69%] [G loss: 3.060163]\n",
      "epoch:0 step:338 [D loss: 0.338731, acc: 84.38%] [G loss: 4.162910]\n",
      "epoch:0 step:339 [D loss: 1.042178, acc: 61.72%] [G loss: 2.881514]\n",
      "epoch:0 step:340 [D loss: 0.469846, acc: 78.12%] [G loss: 3.689930]\n",
      "epoch:0 step:341 [D loss: 0.763730, acc: 69.53%] [G loss: 3.963523]\n",
      "epoch:0 step:342 [D loss: 0.576493, acc: 71.09%] [G loss: 3.747616]\n",
      "epoch:0 step:343 [D loss: 0.776210, acc: 71.09%] [G loss: 4.980704]\n",
      "epoch:0 step:344 [D loss: 0.761135, acc: 72.66%] [G loss: 3.484480]\n",
      "epoch:0 step:345 [D loss: 0.658101, acc: 70.31%] [G loss: 3.384735]\n",
      "epoch:0 step:346 [D loss: 0.740617, acc: 69.53%] [G loss: 3.053153]\n",
      "epoch:0 step:347 [D loss: 0.679233, acc: 64.06%] [G loss: 2.883838]\n",
      "epoch:0 step:348 [D loss: 0.347397, acc: 84.38%] [G loss: 2.450596]\n",
      "epoch:0 step:349 [D loss: 0.429792, acc: 80.47%] [G loss: 2.816212]\n",
      "epoch:0 step:350 [D loss: 0.407166, acc: 81.25%] [G loss: 2.615396]\n",
      "epoch:0 step:351 [D loss: 0.320547, acc: 91.41%] [G loss: 2.429522]\n",
      "epoch:0 step:352 [D loss: 0.642027, acc: 71.09%] [G loss: 2.805260]\n",
      "epoch:0 step:353 [D loss: 0.475806, acc: 84.38%] [G loss: 2.425387]\n",
      "epoch:0 step:354 [D loss: 0.435164, acc: 82.03%] [G loss: 2.805546]\n",
      "epoch:0 step:355 [D loss: 0.446870, acc: 84.38%] [G loss: 2.832822]\n",
      "epoch:0 step:356 [D loss: 0.271693, acc: 89.84%] [G loss: 2.833275]\n",
      "epoch:0 step:357 [D loss: 0.487586, acc: 80.47%] [G loss: 2.968934]\n",
      "epoch:0 step:358 [D loss: 0.646867, acc: 71.09%] [G loss: 3.270677]\n",
      "epoch:0 step:359 [D loss: 0.482119, acc: 82.03%] [G loss: 3.387804]\n",
      "epoch:0 step:360 [D loss: 1.257431, acc: 50.00%] [G loss: 2.488902]\n",
      "epoch:0 step:361 [D loss: 1.004214, acc: 50.00%] [G loss: 2.864314]\n",
      "epoch:0 step:362 [D loss: 1.200964, acc: 41.41%] [G loss: 3.270306]\n",
      "epoch:0 step:363 [D loss: 1.156029, acc: 57.81%] [G loss: 3.082736]\n",
      "epoch:0 step:364 [D loss: 0.809583, acc: 62.50%] [G loss: 3.301662]\n",
      "epoch:0 step:365 [D loss: 0.812822, acc: 55.47%] [G loss: 3.420129]\n",
      "epoch:0 step:366 [D loss: 0.473855, acc: 82.81%] [G loss: 3.209229]\n",
      "epoch:0 step:367 [D loss: 0.855348, acc: 56.25%] [G loss: 3.810221]\n",
      "epoch:0 step:368 [D loss: 0.905125, acc: 56.25%] [G loss: 3.189855]\n",
      "epoch:0 step:369 [D loss: 0.692033, acc: 56.25%] [G loss: 3.678444]\n",
      "epoch:0 step:370 [D loss: 0.570633, acc: 73.44%] [G loss: 3.774183]\n",
      "epoch:0 step:371 [D loss: 0.567274, acc: 69.53%] [G loss: 3.463347]\n",
      "epoch:0 step:372 [D loss: 0.485750, acc: 75.00%] [G loss: 4.400774]\n",
      "epoch:0 step:373 [D loss: 1.850872, acc: 13.28%] [G loss: 2.348145]\n",
      "epoch:0 step:374 [D loss: 0.655743, acc: 64.06%] [G loss: 3.709133]\n",
      "epoch:0 step:375 [D loss: 0.956024, acc: 48.44%] [G loss: 2.907699]\n",
      "epoch:0 step:376 [D loss: 0.402690, acc: 85.16%] [G loss: 3.732168]\n",
      "epoch:0 step:377 [D loss: 0.338031, acc: 89.06%] [G loss: 3.570263]\n",
      "epoch:0 step:378 [D loss: 0.936839, acc: 50.00%] [G loss: 2.959164]\n",
      "epoch:0 step:379 [D loss: 1.006987, acc: 48.44%] [G loss: 2.562569]\n",
      "epoch:0 step:380 [D loss: 0.912769, acc: 57.03%] [G loss: 3.098162]\n",
      "epoch:0 step:381 [D loss: 0.626130, acc: 62.50%] [G loss: 3.642274]\n",
      "epoch:0 step:382 [D loss: 0.784661, acc: 66.41%] [G loss: 3.167490]\n",
      "epoch:0 step:383 [D loss: 0.772682, acc: 60.94%] [G loss: 2.808910]\n",
      "epoch:0 step:384 [D loss: 0.487824, acc: 78.12%] [G loss: 2.909460]\n",
      "epoch:0 step:385 [D loss: 0.510440, acc: 78.91%] [G loss: 3.553118]\n",
      "epoch:0 step:386 [D loss: 0.485632, acc: 82.03%] [G loss: 3.332359]\n",
      "epoch:0 step:387 [D loss: 1.280972, acc: 38.28%] [G loss: 2.827815]\n",
      "epoch:0 step:388 [D loss: 0.579075, acc: 73.44%] [G loss: 3.724729]\n",
      "epoch:0 step:389 [D loss: 0.632651, acc: 75.00%] [G loss: 3.075882]\n",
      "epoch:0 step:390 [D loss: 0.772896, acc: 57.81%] [G loss: 2.781711]\n",
      "epoch:0 step:391 [D loss: 0.813503, acc: 50.78%] [G loss: 2.419798]\n",
      "epoch:0 step:392 [D loss: 0.782429, acc: 58.59%] [G loss: 2.377334]\n",
      "epoch:0 step:393 [D loss: 0.851606, acc: 46.09%] [G loss: 1.985708]\n",
      "epoch:0 step:394 [D loss: 0.575212, acc: 66.41%] [G loss: 2.589828]\n",
      "epoch:0 step:395 [D loss: 0.785150, acc: 56.25%] [G loss: 3.163429]\n",
      "epoch:0 step:396 [D loss: 0.714178, acc: 62.50%] [G loss: 2.783336]\n",
      "epoch:0 step:397 [D loss: 0.795979, acc: 46.09%] [G loss: 2.706274]\n",
      "epoch:0 step:398 [D loss: 0.790586, acc: 57.03%] [G loss: 2.693015]\n",
      "epoch:0 step:399 [D loss: 1.349066, acc: 32.03%] [G loss: 2.634395]\n",
      "epoch:0 step:400 [D loss: 1.130997, acc: 37.50%] [G loss: 2.353601]\n",
      "##############\n",
      "[0.84518344 0.87894012 0.82613691 0.81567436 0.77379797 0.8454868\n",
      " 0.89058398 0.81166519 0.84682144 0.81774887]\n",
      "##########\n",
      "epoch:0 step:401 [D loss: 0.455642, acc: 81.25%] [G loss: 3.554437]\n",
      "epoch:0 step:402 [D loss: 0.702838, acc: 64.84%] [G loss: 2.336928]\n",
      "epoch:0 step:403 [D loss: 0.487831, acc: 76.56%] [G loss: 3.344620]\n",
      "epoch:0 step:404 [D loss: 0.387975, acc: 83.59%] [G loss: 3.099728]\n",
      "epoch:0 step:405 [D loss: 0.578832, acc: 65.62%] [G loss: 2.976752]\n",
      "epoch:0 step:406 [D loss: 0.858688, acc: 50.00%] [G loss: 2.414257]\n",
      "epoch:0 step:407 [D loss: 0.799245, acc: 52.34%] [G loss: 2.197889]\n",
      "epoch:0 step:408 [D loss: 0.898778, acc: 39.84%] [G loss: 2.619496]\n",
      "epoch:0 step:409 [D loss: 0.832656, acc: 53.12%] [G loss: 2.526893]\n",
      "epoch:0 step:410 [D loss: 0.732660, acc: 60.94%] [G loss: 3.092401]\n",
      "epoch:0 step:411 [D loss: 0.855854, acc: 53.91%] [G loss: 3.184524]\n",
      "epoch:0 step:412 [D loss: 0.628836, acc: 71.88%] [G loss: 2.887327]\n",
      "epoch:0 step:413 [D loss: 0.459494, acc: 83.59%] [G loss: 2.764201]\n",
      "epoch:0 step:414 [D loss: 0.325662, acc: 86.72%] [G loss: 2.959611]\n",
      "epoch:0 step:415 [D loss: 0.313687, acc: 88.28%] [G loss: 2.889320]\n",
      "epoch:0 step:416 [D loss: 0.817887, acc: 62.50%] [G loss: 2.431243]\n",
      "epoch:0 step:417 [D loss: 0.377517, acc: 82.03%] [G loss: 2.537150]\n",
      "epoch:0 step:418 [D loss: 0.290249, acc: 90.62%] [G loss: 2.472111]\n",
      "epoch:0 step:419 [D loss: 0.335714, acc: 85.94%] [G loss: 2.192506]\n",
      "epoch:0 step:420 [D loss: 0.807783, acc: 64.84%] [G loss: 1.770627]\n",
      "epoch:0 step:421 [D loss: 0.382750, acc: 85.16%] [G loss: 2.125474]\n",
      "epoch:0 step:422 [D loss: 0.960607, acc: 57.03%] [G loss: 2.262511]\n",
      "epoch:0 step:423 [D loss: 0.650758, acc: 69.53%] [G loss: 2.394609]\n",
      "epoch:0 step:424 [D loss: 1.063531, acc: 48.44%] [G loss: 2.152547]\n",
      "epoch:0 step:425 [D loss: 1.022287, acc: 44.53%] [G loss: 2.220561]\n",
      "epoch:0 step:426 [D loss: 0.461667, acc: 81.25%] [G loss: 2.538432]\n",
      "epoch:0 step:427 [D loss: 0.449907, acc: 78.91%] [G loss: 2.834829]\n",
      "epoch:0 step:428 [D loss: 0.876827, acc: 59.38%] [G loss: 3.442780]\n",
      "epoch:0 step:429 [D loss: 0.712121, acc: 64.84%] [G loss: 3.390386]\n",
      "epoch:0 step:430 [D loss: 0.762958, acc: 55.47%] [G loss: 2.843047]\n",
      "epoch:0 step:431 [D loss: 0.708178, acc: 60.94%] [G loss: 3.151185]\n",
      "epoch:0 step:432 [D loss: 0.646783, acc: 64.06%] [G loss: 3.706039]\n",
      "epoch:0 step:433 [D loss: 0.611168, acc: 68.75%] [G loss: 3.582269]\n",
      "epoch:0 step:434 [D loss: 0.533472, acc: 74.22%] [G loss: 4.422215]\n",
      "epoch:0 step:435 [D loss: 0.669859, acc: 73.44%] [G loss: 4.168704]\n",
      "epoch:0 step:436 [D loss: 0.692783, acc: 71.09%] [G loss: 4.098684]\n",
      "epoch:0 step:437 [D loss: 0.677492, acc: 70.31%] [G loss: 3.019487]\n",
      "epoch:0 step:438 [D loss: 0.463838, acc: 80.47%] [G loss: 4.261801]\n",
      "epoch:0 step:439 [D loss: 0.547725, acc: 74.22%] [G loss: 3.421806]\n",
      "epoch:0 step:440 [D loss: 0.691661, acc: 74.22%] [G loss: 3.388820]\n",
      "epoch:0 step:441 [D loss: 0.663621, acc: 73.44%] [G loss: 3.243569]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0 step:442 [D loss: 0.773853, acc: 60.16%] [G loss: 2.391538]\n",
      "epoch:0 step:443 [D loss: 0.628655, acc: 70.31%] [G loss: 2.279697]\n",
      "epoch:0 step:444 [D loss: 0.445460, acc: 80.47%] [G loss: 2.837210]\n",
      "epoch:0 step:445 [D loss: 0.692334, acc: 69.53%] [G loss: 2.140851]\n",
      "epoch:0 step:446 [D loss: 0.696742, acc: 67.97%] [G loss: 2.942457]\n",
      "epoch:0 step:447 [D loss: 0.572203, acc: 70.31%] [G loss: 2.567725]\n",
      "epoch:0 step:448 [D loss: 0.732692, acc: 61.72%] [G loss: 2.286849]\n",
      "epoch:0 step:449 [D loss: 0.846205, acc: 63.28%] [G loss: 2.381037]\n",
      "epoch:0 step:450 [D loss: 0.858130, acc: 48.44%] [G loss: 2.300842]\n",
      "epoch:0 step:451 [D loss: 1.087857, acc: 46.09%] [G loss: 1.809436]\n",
      "epoch:0 step:452 [D loss: 0.646401, acc: 67.19%] [G loss: 2.140031]\n",
      "epoch:0 step:453 [D loss: 0.559234, acc: 75.00%] [G loss: 2.163149]\n",
      "epoch:0 step:454 [D loss: 0.904740, acc: 49.22%] [G loss: 1.613559]\n",
      "epoch:0 step:455 [D loss: 0.728593, acc: 52.34%] [G loss: 2.073866]\n",
      "epoch:0 step:456 [D loss: 0.604197, acc: 75.00%] [G loss: 2.490135]\n",
      "epoch:0 step:457 [D loss: 0.657052, acc: 64.84%] [G loss: 1.921467]\n",
      "epoch:0 step:458 [D loss: 0.407532, acc: 80.47%] [G loss: 1.806711]\n",
      "epoch:0 step:459 [D loss: 0.616453, acc: 71.09%] [G loss: 1.736858]\n",
      "epoch:0 step:460 [D loss: 0.793416, acc: 59.38%] [G loss: 1.501448]\n",
      "epoch:0 step:461 [D loss: 0.465007, acc: 78.91%] [G loss: 1.753610]\n",
      "epoch:0 step:462 [D loss: 0.590893, acc: 70.31%] [G loss: 1.821947]\n",
      "epoch:0 step:463 [D loss: 0.774724, acc: 62.50%] [G loss: 1.611148]\n",
      "epoch:0 step:464 [D loss: 0.671111, acc: 58.59%] [G loss: 1.506770]\n",
      "epoch:0 step:465 [D loss: 0.878198, acc: 49.22%] [G loss: 1.919839]\n",
      "epoch:0 step:466 [D loss: 0.617923, acc: 67.19%] [G loss: 2.166051]\n",
      "epoch:0 step:467 [D loss: 0.710665, acc: 62.50%] [G loss: 2.049784]\n",
      "epoch:0 step:468 [D loss: 0.384460, acc: 85.16%] [G loss: 2.731960]\n",
      "epoch:0 step:469 [D loss: 0.408576, acc: 85.94%] [G loss: 2.370838]\n",
      "epoch:0 step:470 [D loss: 0.594735, acc: 73.44%] [G loss: 2.704965]\n",
      "epoch:0 step:471 [D loss: 0.595964, acc: 71.09%] [G loss: 2.564607]\n",
      "epoch:0 step:472 [D loss: 0.906953, acc: 49.22%] [G loss: 2.048972]\n",
      "epoch:0 step:473 [D loss: 0.512052, acc: 77.34%] [G loss: 1.849463]\n",
      "epoch:0 step:474 [D loss: 0.563465, acc: 71.09%] [G loss: 2.391901]\n",
      "epoch:0 step:475 [D loss: 0.848530, acc: 47.66%] [G loss: 2.046876]\n",
      "epoch:0 step:476 [D loss: 0.648237, acc: 67.19%] [G loss: 2.313819]\n",
      "epoch:0 step:477 [D loss: 0.667282, acc: 61.72%] [G loss: 2.806059]\n",
      "epoch:0 step:478 [D loss: 0.698463, acc: 65.62%] [G loss: 2.538633]\n",
      "epoch:0 step:479 [D loss: 0.567575, acc: 74.22%] [G loss: 2.669298]\n",
      "epoch:0 step:480 [D loss: 0.693975, acc: 67.19%] [G loss: 2.126601]\n",
      "epoch:0 step:481 [D loss: 1.199753, acc: 39.84%] [G loss: 2.475257]\n",
      "epoch:0 step:482 [D loss: 0.933225, acc: 50.78%] [G loss: 2.241565]\n",
      "epoch:0 step:483 [D loss: 0.745963, acc: 61.72%] [G loss: 2.355618]\n",
      "epoch:0 step:484 [D loss: 0.952043, acc: 43.75%] [G loss: 1.912466]\n",
      "epoch:0 step:485 [D loss: 0.696527, acc: 67.19%] [G loss: 2.336590]\n",
      "epoch:0 step:486 [D loss: 0.588337, acc: 67.19%] [G loss: 2.677413]\n",
      "epoch:0 step:487 [D loss: 0.890341, acc: 54.69%] [G loss: 1.940612]\n",
      "epoch:0 step:488 [D loss: 0.515557, acc: 78.12%] [G loss: 2.130374]\n",
      "epoch:0 step:489 [D loss: 0.355470, acc: 89.84%] [G loss: 2.562579]\n",
      "epoch:0 step:490 [D loss: 0.860322, acc: 53.91%] [G loss: 2.075779]\n",
      "epoch:0 step:491 [D loss: 0.270594, acc: 92.97%] [G loss: 2.535902]\n",
      "epoch:0 step:492 [D loss: 0.753215, acc: 57.81%] [G loss: 1.942321]\n",
      "epoch:0 step:493 [D loss: 0.521990, acc: 74.22%] [G loss: 2.325628]\n",
      "epoch:0 step:494 [D loss: 0.368452, acc: 91.41%] [G loss: 1.924642]\n",
      "epoch:0 step:495 [D loss: 0.461738, acc: 81.25%] [G loss: 2.124701]\n",
      "epoch:0 step:496 [D loss: 0.394371, acc: 83.59%] [G loss: 2.218810]\n",
      "epoch:0 step:497 [D loss: 0.522970, acc: 76.56%] [G loss: 2.214747]\n",
      "epoch:0 step:498 [D loss: 0.380263, acc: 84.38%] [G loss: 2.952682]\n",
      "epoch:0 step:499 [D loss: 0.224925, acc: 96.09%] [G loss: 2.843380]\n",
      "epoch:0 step:500 [D loss: 0.630743, acc: 64.84%] [G loss: 1.896345]\n",
      "epoch:0 step:501 [D loss: 0.847114, acc: 52.34%] [G loss: 2.482981]\n",
      "epoch:0 step:502 [D loss: 0.451127, acc: 82.81%] [G loss: 2.144748]\n",
      "epoch:0 step:503 [D loss: 0.572239, acc: 73.44%] [G loss: 1.939496]\n",
      "epoch:0 step:504 [D loss: 0.643430, acc: 65.62%] [G loss: 2.457914]\n",
      "epoch:0 step:505 [D loss: 0.309321, acc: 91.41%] [G loss: 2.692899]\n",
      "epoch:0 step:506 [D loss: 0.552558, acc: 75.00%] [G loss: 2.593096]\n",
      "epoch:0 step:507 [D loss: 0.397385, acc: 85.16%] [G loss: 2.610137]\n",
      "epoch:0 step:508 [D loss: 0.841857, acc: 48.44%] [G loss: 2.046921]\n",
      "epoch:0 step:509 [D loss: 0.218710, acc: 92.97%] [G loss: 3.199851]\n",
      "epoch:0 step:510 [D loss: 0.379652, acc: 85.94%] [G loss: 2.442069]\n",
      "epoch:0 step:511 [D loss: 0.789115, acc: 52.34%] [G loss: 2.510148]\n",
      "epoch:0 step:512 [D loss: 0.783913, acc: 60.16%] [G loss: 2.034608]\n",
      "epoch:0 step:513 [D loss: 1.060657, acc: 41.41%] [G loss: 2.323100]\n",
      "epoch:0 step:514 [D loss: 0.845166, acc: 57.03%] [G loss: 2.450570]\n",
      "epoch:0 step:515 [D loss: 0.547154, acc: 72.66%] [G loss: 3.128559]\n",
      "epoch:0 step:516 [D loss: 0.641117, acc: 67.19%] [G loss: 2.715949]\n",
      "epoch:0 step:517 [D loss: 0.722606, acc: 58.59%] [G loss: 3.277966]\n",
      "epoch:0 step:518 [D loss: 0.749747, acc: 59.38%] [G loss: 2.726672]\n",
      "epoch:0 step:519 [D loss: 1.140226, acc: 45.31%] [G loss: 3.426907]\n",
      "epoch:0 step:520 [D loss: 0.485880, acc: 78.12%] [G loss: 3.144400]\n",
      "epoch:0 step:521 [D loss: 0.599608, acc: 70.31%] [G loss: 2.967684]\n",
      "epoch:0 step:522 [D loss: 0.525566, acc: 71.09%] [G loss: 2.375284]\n",
      "epoch:0 step:523 [D loss: 0.444718, acc: 82.03%] [G loss: 2.772157]\n",
      "epoch:0 step:524 [D loss: 0.354400, acc: 85.94%] [G loss: 3.029656]\n",
      "epoch:0 step:525 [D loss: 0.760077, acc: 64.84%] [G loss: 1.849192]\n",
      "epoch:0 step:526 [D loss: 0.437929, acc: 82.03%] [G loss: 2.181624]\n",
      "epoch:0 step:527 [D loss: 0.409935, acc: 81.25%] [G loss: 2.503788]\n",
      "epoch:0 step:528 [D loss: 0.788118, acc: 56.25%] [G loss: 1.812378]\n",
      "epoch:0 step:529 [D loss: 0.593880, acc: 64.84%] [G loss: 1.762640]\n",
      "epoch:0 step:530 [D loss: 0.417949, acc: 85.94%] [G loss: 2.015052]\n",
      "epoch:0 step:531 [D loss: 0.806598, acc: 53.91%] [G loss: 1.389114]\n",
      "epoch:0 step:532 [D loss: 0.734168, acc: 55.47%] [G loss: 1.812096]\n",
      "epoch:0 step:533 [D loss: 0.718488, acc: 64.06%] [G loss: 1.613709]\n",
      "epoch:0 step:534 [D loss: 0.967011, acc: 41.41%] [G loss: 1.459951]\n",
      "epoch:0 step:535 [D loss: 0.897322, acc: 45.31%] [G loss: 1.350641]\n",
      "epoch:0 step:536 [D loss: 0.497915, acc: 82.03%] [G loss: 1.970594]\n",
      "epoch:0 step:537 [D loss: 0.810144, acc: 57.81%] [G loss: 1.353462]\n",
      "epoch:0 step:538 [D loss: 0.729876, acc: 59.38%] [G loss: 1.622640]\n",
      "epoch:0 step:539 [D loss: 0.818934, acc: 52.34%] [G loss: 2.038481]\n",
      "epoch:0 step:540 [D loss: 0.949722, acc: 46.09%] [G loss: 1.580935]\n",
      "epoch:0 step:541 [D loss: 0.927210, acc: 34.38%] [G loss: 1.497362]\n",
      "epoch:0 step:542 [D loss: 1.295594, acc: 29.69%] [G loss: 1.356945]\n",
      "epoch:0 step:543 [D loss: 1.344263, acc: 21.88%] [G loss: 1.214272]\n",
      "epoch:0 step:544 [D loss: 1.116362, acc: 32.03%] [G loss: 1.497443]\n",
      "epoch:0 step:545 [D loss: 1.032418, acc: 38.28%] [G loss: 1.587791]\n",
      "epoch:0 step:546 [D loss: 0.876237, acc: 50.78%] [G loss: 1.988148]\n",
      "epoch:0 step:547 [D loss: 0.990802, acc: 48.44%] [G loss: 1.923016]\n",
      "epoch:0 step:548 [D loss: 0.818838, acc: 54.69%] [G loss: 2.251408]\n",
      "epoch:0 step:549 [D loss: 0.876063, acc: 53.91%] [G loss: 2.177615]\n",
      "epoch:0 step:550 [D loss: 0.979098, acc: 51.56%] [G loss: 2.435988]\n",
      "epoch:0 step:551 [D loss: 0.607745, acc: 73.44%] [G loss: 2.735167]\n",
      "epoch:0 step:552 [D loss: 0.576131, acc: 73.44%] [G loss: 2.684662]\n",
      "epoch:0 step:553 [D loss: 0.474099, acc: 79.69%] [G loss: 2.811228]\n",
      "epoch:0 step:554 [D loss: 0.440429, acc: 81.25%] [G loss: 2.710572]\n",
      "epoch:0 step:555 [D loss: 0.395075, acc: 85.16%] [G loss: 2.271700]\n",
      "epoch:0 step:556 [D loss: 0.447744, acc: 75.00%] [G loss: 2.462753]\n",
      "epoch:0 step:557 [D loss: 0.246169, acc: 92.97%] [G loss: 2.354067]\n",
      "epoch:0 step:558 [D loss: 0.302475, acc: 90.62%] [G loss: 2.662812]\n",
      "epoch:0 step:559 [D loss: 0.447723, acc: 79.69%] [G loss: 2.360074]\n",
      "epoch:0 step:560 [D loss: 0.425076, acc: 89.06%] [G loss: 2.385242]\n",
      "epoch:0 step:561 [D loss: 0.424344, acc: 78.91%] [G loss: 2.198333]\n",
      "epoch:0 step:562 [D loss: 0.283363, acc: 89.06%] [G loss: 2.398749]\n",
      "epoch:0 step:563 [D loss: 0.952734, acc: 57.81%] [G loss: 1.733048]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0 step:564 [D loss: 0.213707, acc: 96.09%] [G loss: 2.579030]\n",
      "epoch:0 step:565 [D loss: 0.311840, acc: 92.19%] [G loss: 2.531255]\n",
      "epoch:0 step:566 [D loss: 0.423680, acc: 81.25%] [G loss: 2.999021]\n",
      "epoch:0 step:567 [D loss: 0.328555, acc: 85.94%] [G loss: 2.348956]\n",
      "epoch:0 step:568 [D loss: 0.652602, acc: 60.94%] [G loss: 2.200895]\n",
      "epoch:0 step:569 [D loss: 0.456545, acc: 78.91%] [G loss: 2.104193]\n",
      "epoch:0 step:570 [D loss: 0.531767, acc: 70.31%] [G loss: 2.119678]\n",
      "epoch:0 step:571 [D loss: 0.418559, acc: 82.81%] [G loss: 2.256849]\n",
      "epoch:0 step:572 [D loss: 0.977333, acc: 44.53%] [G loss: 1.972917]\n",
      "epoch:0 step:573 [D loss: 0.828092, acc: 50.78%] [G loss: 2.128296]\n",
      "epoch:0 step:574 [D loss: 1.229744, acc: 38.28%] [G loss: 1.604788]\n",
      "epoch:0 step:575 [D loss: 0.525623, acc: 73.44%] [G loss: 2.430726]\n",
      "epoch:0 step:576 [D loss: 0.605178, acc: 71.88%] [G loss: 2.188744]\n",
      "epoch:0 step:577 [D loss: 1.152402, acc: 28.91%] [G loss: 1.780085]\n",
      "epoch:0 step:578 [D loss: 1.007692, acc: 44.53%] [G loss: 1.897486]\n",
      "epoch:0 step:579 [D loss: 1.287845, acc: 21.88%] [G loss: 1.417007]\n",
      "epoch:0 step:580 [D loss: 0.951547, acc: 35.94%] [G loss: 1.572041]\n",
      "epoch:0 step:581 [D loss: 0.778152, acc: 51.56%] [G loss: 1.998596]\n",
      "epoch:0 step:582 [D loss: 0.927770, acc: 40.62%] [G loss: 1.802502]\n",
      "epoch:0 step:583 [D loss: 0.679378, acc: 60.16%] [G loss: 1.960496]\n",
      "epoch:0 step:584 [D loss: 0.577620, acc: 75.00%] [G loss: 2.138095]\n",
      "epoch:0 step:585 [D loss: 0.560229, acc: 65.62%] [G loss: 2.261692]\n",
      "epoch:0 step:586 [D loss: 0.574660, acc: 74.22%] [G loss: 2.074015]\n",
      "epoch:0 step:587 [D loss: 0.549941, acc: 73.44%] [G loss: 2.566164]\n",
      "epoch:0 step:588 [D loss: 0.425377, acc: 79.69%] [G loss: 2.756102]\n",
      "epoch:0 step:589 [D loss: 0.379897, acc: 87.50%] [G loss: 2.619377]\n",
      "epoch:0 step:590 [D loss: 0.470239, acc: 83.59%] [G loss: 2.624867]\n",
      "epoch:0 step:591 [D loss: 0.498902, acc: 78.12%] [G loss: 2.136942]\n",
      "epoch:0 step:592 [D loss: 0.366870, acc: 83.59%] [G loss: 2.312521]\n",
      "epoch:0 step:593 [D loss: 0.550512, acc: 69.53%] [G loss: 2.363488]\n",
      "epoch:0 step:594 [D loss: 0.273385, acc: 92.97%] [G loss: 2.650137]\n",
      "epoch:0 step:595 [D loss: 0.608182, acc: 68.75%] [G loss: 2.447101]\n",
      "epoch:0 step:596 [D loss: 0.445653, acc: 78.12%] [G loss: 2.526250]\n",
      "epoch:0 step:597 [D loss: 0.359660, acc: 87.50%] [G loss: 2.570489]\n",
      "epoch:0 step:598 [D loss: 0.554959, acc: 71.88%] [G loss: 1.913173]\n",
      "epoch:0 step:599 [D loss: 0.473979, acc: 82.03%] [G loss: 2.344088]\n",
      "epoch:0 step:600 [D loss: 0.308977, acc: 92.19%] [G loss: 2.203059]\n",
      "##############\n",
      "[0.85416741 0.88382631 0.82533491 0.83404895 0.78640585 0.82499335\n",
      " 0.87912615 0.8104603  0.80156264 0.82473854]\n",
      "##########\n",
      "epoch:0 step:601 [D loss: 0.864162, acc: 49.22%] [G loss: 1.687844]\n",
      "epoch:0 step:602 [D loss: 0.431033, acc: 80.47%] [G loss: 1.979955]\n",
      "epoch:0 step:603 [D loss: 0.499405, acc: 73.44%] [G loss: 2.086733]\n",
      "epoch:0 step:604 [D loss: 0.738917, acc: 54.69%] [G loss: 1.981259]\n",
      "epoch:0 step:605 [D loss: 0.695686, acc: 60.94%] [G loss: 1.921128]\n",
      "epoch:0 step:606 [D loss: 0.747245, acc: 50.00%] [G loss: 1.890230]\n",
      "epoch:0 step:607 [D loss: 1.168500, acc: 34.38%] [G loss: 1.607769]\n",
      "epoch:0 step:608 [D loss: 0.855240, acc: 48.44%] [G loss: 1.686093]\n",
      "epoch:0 step:609 [D loss: 0.737627, acc: 53.91%] [G loss: 1.929284]\n",
      "epoch:0 step:610 [D loss: 0.819910, acc: 47.66%] [G loss: 1.868663]\n",
      "epoch:0 step:611 [D loss: 0.940240, acc: 41.41%] [G loss: 1.941804]\n",
      "epoch:0 step:612 [D loss: 0.859825, acc: 50.00%] [G loss: 1.672308]\n",
      "epoch:0 step:613 [D loss: 0.942970, acc: 46.09%] [G loss: 1.730521]\n",
      "epoch:0 step:614 [D loss: 0.694426, acc: 65.62%] [G loss: 2.037169]\n",
      "epoch:0 step:615 [D loss: 0.660871, acc: 63.28%] [G loss: 2.041492]\n",
      "epoch:0 step:616 [D loss: 0.843006, acc: 49.22%] [G loss: 2.035567]\n",
      "epoch:0 step:617 [D loss: 0.757527, acc: 54.69%] [G loss: 1.987925]\n",
      "epoch:0 step:618 [D loss: 0.563718, acc: 71.09%] [G loss: 2.163116]\n",
      "epoch:0 step:619 [D loss: 0.818004, acc: 51.56%] [G loss: 1.854777]\n",
      "epoch:0 step:620 [D loss: 0.788901, acc: 55.47%] [G loss: 1.986142]\n",
      "epoch:0 step:621 [D loss: 0.533693, acc: 73.44%] [G loss: 2.652367]\n",
      "epoch:0 step:622 [D loss: 0.851766, acc: 53.91%] [G loss: 2.086263]\n",
      "epoch:0 step:623 [D loss: 0.845233, acc: 50.78%] [G loss: 2.089851]\n",
      "epoch:0 step:624 [D loss: 0.704174, acc: 62.50%] [G loss: 2.060257]\n",
      "epoch:0 step:625 [D loss: 0.836628, acc: 52.34%] [G loss: 2.217156]\n",
      "epoch:0 step:626 [D loss: 0.632761, acc: 64.06%] [G loss: 1.991830]\n",
      "epoch:0 step:627 [D loss: 0.747089, acc: 59.38%] [G loss: 2.128722]\n",
      "epoch:0 step:628 [D loss: 0.848381, acc: 46.09%] [G loss: 1.880708]\n",
      "epoch:0 step:629 [D loss: 0.866989, acc: 44.53%] [G loss: 1.760470]\n",
      "epoch:0 step:630 [D loss: 0.808322, acc: 59.38%] [G loss: 2.097270]\n",
      "epoch:0 step:631 [D loss: 0.831561, acc: 50.00%] [G loss: 1.886430]\n",
      "epoch:0 step:632 [D loss: 0.858134, acc: 54.69%] [G loss: 1.932905]\n",
      "epoch:0 step:633 [D loss: 0.825123, acc: 47.66%] [G loss: 2.033634]\n",
      "epoch:0 step:634 [D loss: 0.798547, acc: 56.25%] [G loss: 1.738091]\n",
      "epoch:0 step:635 [D loss: 0.786727, acc: 56.25%] [G loss: 2.003920]\n",
      "epoch:0 step:636 [D loss: 0.716085, acc: 57.81%] [G loss: 2.113101]\n",
      "epoch:0 step:637 [D loss: 0.700010, acc: 65.62%] [G loss: 2.147547]\n",
      "epoch:0 step:638 [D loss: 0.656459, acc: 67.19%] [G loss: 2.359608]\n",
      "epoch:0 step:639 [D loss: 0.564160, acc: 72.66%] [G loss: 2.276052]\n",
      "epoch:0 step:640 [D loss: 0.598128, acc: 71.88%] [G loss: 2.415097]\n",
      "epoch:0 step:641 [D loss: 0.603824, acc: 70.31%] [G loss: 2.591213]\n",
      "epoch:0 step:642 [D loss: 0.586467, acc: 77.34%] [G loss: 2.238153]\n",
      "epoch:0 step:643 [D loss: 0.590037, acc: 69.53%] [G loss: 2.566836]\n",
      "epoch:0 step:644 [D loss: 0.508989, acc: 77.34%] [G loss: 2.438689]\n",
      "epoch:0 step:645 [D loss: 0.549205, acc: 75.00%] [G loss: 2.262978]\n",
      "epoch:0 step:646 [D loss: 0.533971, acc: 79.69%] [G loss: 2.579364]\n",
      "epoch:0 step:647 [D loss: 0.562823, acc: 75.00%] [G loss: 2.489316]\n",
      "epoch:0 step:648 [D loss: 0.515374, acc: 79.69%] [G loss: 2.250372]\n",
      "epoch:0 step:649 [D loss: 0.440329, acc: 82.81%] [G loss: 2.383115]\n",
      "epoch:0 step:650 [D loss: 0.592073, acc: 67.97%] [G loss: 2.092591]\n",
      "epoch:0 step:651 [D loss: 0.364687, acc: 85.94%] [G loss: 2.494408]\n",
      "epoch:0 step:652 [D loss: 0.689220, acc: 60.94%] [G loss: 1.882925]\n",
      "epoch:0 step:653 [D loss: 0.349276, acc: 89.06%] [G loss: 1.980207]\n",
      "epoch:0 step:654 [D loss: 0.674104, acc: 64.06%] [G loss: 1.992813]\n",
      "epoch:0 step:655 [D loss: 0.491268, acc: 78.91%] [G loss: 1.898960]\n",
      "epoch:0 step:656 [D loss: 0.609228, acc: 70.31%] [G loss: 1.804276]\n",
      "epoch:0 step:657 [D loss: 0.491358, acc: 82.81%] [G loss: 1.904397]\n",
      "epoch:0 step:658 [D loss: 0.743620, acc: 61.72%] [G loss: 1.594498]\n",
      "epoch:0 step:659 [D loss: 0.453464, acc: 81.25%] [G loss: 1.890914]\n",
      "epoch:0 step:660 [D loss: 0.536770, acc: 78.91%] [G loss: 1.910879]\n",
      "epoch:0 step:661 [D loss: 0.376436, acc: 92.97%] [G loss: 2.370228]\n",
      "epoch:0 step:662 [D loss: 0.439575, acc: 83.59%] [G loss: 2.028121]\n",
      "epoch:0 step:663 [D loss: 0.467501, acc: 84.38%] [G loss: 2.028141]\n",
      "epoch:0 step:664 [D loss: 0.525945, acc: 77.34%] [G loss: 1.952785]\n",
      "epoch:0 step:665 [D loss: 0.647932, acc: 67.97%] [G loss: 2.051263]\n",
      "epoch:0 step:666 [D loss: 0.509856, acc: 82.03%] [G loss: 2.152932]\n",
      "epoch:0 step:667 [D loss: 0.490460, acc: 80.47%] [G loss: 1.857199]\n",
      "epoch:0 step:668 [D loss: 0.473521, acc: 77.34%] [G loss: 1.857765]\n",
      "epoch:0 step:669 [D loss: 0.458469, acc: 80.47%] [G loss: 1.944400]\n",
      "epoch:0 step:670 [D loss: 0.352365, acc: 89.84%] [G loss: 2.162460]\n",
      "epoch:0 step:671 [D loss: 0.844923, acc: 55.47%] [G loss: 1.691828]\n",
      "epoch:0 step:672 [D loss: 0.501854, acc: 74.22%] [G loss: 1.966453]\n",
      "epoch:0 step:673 [D loss: 0.543193, acc: 75.78%] [G loss: 1.850946]\n",
      "epoch:0 step:674 [D loss: 0.480394, acc: 85.16%] [G loss: 2.097571]\n",
      "epoch:0 step:675 [D loss: 0.721906, acc: 61.72%] [G loss: 2.179899]\n",
      "epoch:0 step:676 [D loss: 0.551005, acc: 75.00%] [G loss: 2.319834]\n",
      "epoch:0 step:677 [D loss: 0.520723, acc: 82.03%] [G loss: 2.327769]\n",
      "epoch:0 step:678 [D loss: 0.496353, acc: 82.03%] [G loss: 2.154132]\n",
      "epoch:0 step:679 [D loss: 0.643624, acc: 69.53%] [G loss: 1.977721]\n",
      "epoch:0 step:680 [D loss: 0.439283, acc: 85.94%] [G loss: 2.509546]\n",
      "epoch:0 step:681 [D loss: 0.941435, acc: 59.38%] [G loss: 2.131012]\n",
      "epoch:0 step:682 [D loss: 0.343698, acc: 86.72%] [G loss: 2.493740]\n",
      "epoch:0 step:683 [D loss: 0.436719, acc: 83.59%] [G loss: 2.428042]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0 step:684 [D loss: 0.917194, acc: 57.03%] [G loss: 2.022141]\n",
      "epoch:0 step:685 [D loss: 0.567395, acc: 71.09%] [G loss: 2.410673]\n",
      "epoch:0 step:686 [D loss: 0.664588, acc: 63.28%] [G loss: 2.280009]\n",
      "epoch:0 step:687 [D loss: 0.523572, acc: 75.78%] [G loss: 2.428713]\n",
      "epoch:0 step:688 [D loss: 0.606490, acc: 73.44%] [G loss: 1.745061]\n",
      "epoch:0 step:689 [D loss: 0.562353, acc: 75.78%] [G loss: 2.426066]\n",
      "epoch:0 step:690 [D loss: 0.629987, acc: 68.75%] [G loss: 1.775791]\n",
      "epoch:0 step:691 [D loss: 1.072058, acc: 43.75%] [G loss: 2.037869]\n",
      "epoch:0 step:692 [D loss: 0.749511, acc: 60.94%] [G loss: 2.299685]\n",
      "epoch:0 step:693 [D loss: 0.917056, acc: 47.66%] [G loss: 1.784740]\n",
      "epoch:0 step:694 [D loss: 0.877695, acc: 49.22%] [G loss: 2.274545]\n",
      "epoch:0 step:695 [D loss: 0.823824, acc: 52.34%] [G loss: 1.959556]\n",
      "epoch:0 step:696 [D loss: 0.846278, acc: 46.88%] [G loss: 1.581033]\n",
      "epoch:0 step:697 [D loss: 0.646593, acc: 64.06%] [G loss: 2.125059]\n",
      "epoch:0 step:698 [D loss: 0.521845, acc: 75.78%] [G loss: 2.332831]\n",
      "epoch:0 step:699 [D loss: 0.683161, acc: 54.69%] [G loss: 2.208580]\n",
      "epoch:0 step:700 [D loss: 0.463904, acc: 77.34%] [G loss: 2.253863]\n",
      "epoch:0 step:701 [D loss: 0.431336, acc: 80.47%] [G loss: 2.274374]\n",
      "epoch:0 step:702 [D loss: 0.627893, acc: 64.84%] [G loss: 2.293281]\n",
      "epoch:0 step:703 [D loss: 0.573990, acc: 63.28%] [G loss: 2.503676]\n",
      "epoch:0 step:704 [D loss: 0.545423, acc: 67.97%] [G loss: 2.278966]\n",
      "epoch:0 step:705 [D loss: 0.290355, acc: 94.53%] [G loss: 2.731685]\n",
      "epoch:0 step:706 [D loss: 0.350553, acc: 87.50%] [G loss: 2.516711]\n",
      "epoch:0 step:707 [D loss: 0.635432, acc: 71.09%] [G loss: 2.274293]\n",
      "epoch:0 step:708 [D loss: 0.346113, acc: 88.28%] [G loss: 2.530084]\n",
      "epoch:0 step:709 [D loss: 0.349097, acc: 86.72%] [G loss: 2.651977]\n",
      "epoch:0 step:710 [D loss: 0.324455, acc: 94.53%] [G loss: 2.320781]\n",
      "epoch:0 step:711 [D loss: 0.261336, acc: 94.53%] [G loss: 2.902619]\n",
      "epoch:0 step:712 [D loss: 0.298647, acc: 96.09%] [G loss: 2.458613]\n",
      "epoch:0 step:713 [D loss: 0.658339, acc: 69.53%] [G loss: 1.889239]\n",
      "epoch:0 step:714 [D loss: 0.441237, acc: 84.38%] [G loss: 2.268958]\n",
      "epoch:0 step:715 [D loss: 0.606326, acc: 68.75%] [G loss: 1.903731]\n",
      "epoch:0 step:716 [D loss: 0.514288, acc: 79.69%] [G loss: 2.099115]\n",
      "epoch:0 step:717 [D loss: 0.370292, acc: 87.50%] [G loss: 2.262736]\n",
      "epoch:0 step:718 [D loss: 0.574130, acc: 67.19%] [G loss: 2.202448]\n",
      "epoch:0 step:719 [D loss: 0.587247, acc: 71.09%] [G loss: 1.829736]\n",
      "epoch:0 step:720 [D loss: 0.430319, acc: 82.81%] [G loss: 2.271705]\n",
      "epoch:0 step:721 [D loss: 0.734370, acc: 59.38%] [G loss: 1.956727]\n",
      "epoch:0 step:722 [D loss: 0.450238, acc: 82.81%] [G loss: 1.938620]\n",
      "epoch:0 step:723 [D loss: 0.633868, acc: 66.41%] [G loss: 2.138592]\n",
      "epoch:0 step:724 [D loss: 0.824301, acc: 60.16%] [G loss: 1.709967]\n",
      "epoch:0 step:725 [D loss: 0.556790, acc: 74.22%] [G loss: 1.962238]\n",
      "epoch:0 step:726 [D loss: 0.778357, acc: 52.34%] [G loss: 1.799271]\n",
      "epoch:0 step:727 [D loss: 0.858616, acc: 60.94%] [G loss: 1.886053]\n",
      "epoch:0 step:728 [D loss: 0.592993, acc: 70.31%] [G loss: 2.121114]\n",
      "epoch:0 step:729 [D loss: 0.736353, acc: 57.03%] [G loss: 1.890162]\n",
      "epoch:0 step:730 [D loss: 0.901216, acc: 57.03%] [G loss: 1.892048]\n",
      "epoch:0 step:731 [D loss: 0.741631, acc: 67.19%] [G loss: 2.088260]\n",
      "epoch:0 step:732 [D loss: 0.801664, acc: 62.50%] [G loss: 2.348286]\n",
      "epoch:0 step:733 [D loss: 0.770670, acc: 63.28%] [G loss: 2.323447]\n",
      "epoch:0 step:734 [D loss: 0.724187, acc: 63.28%] [G loss: 2.117960]\n",
      "epoch:0 step:735 [D loss: 0.859808, acc: 51.56%] [G loss: 2.151550]\n",
      "epoch:0 step:736 [D loss: 0.760046, acc: 60.94%] [G loss: 2.366425]\n",
      "epoch:0 step:737 [D loss: 0.987098, acc: 47.66%] [G loss: 2.192188]\n",
      "epoch:0 step:738 [D loss: 0.739855, acc: 53.91%] [G loss: 2.373205]\n",
      "epoch:0 step:739 [D loss: 0.801214, acc: 58.59%] [G loss: 2.540572]\n",
      "epoch:0 step:740 [D loss: 0.841624, acc: 56.25%] [G loss: 2.057199]\n",
      "epoch:0 step:741 [D loss: 0.561645, acc: 70.31%] [G loss: 2.564291]\n",
      "epoch:0 step:742 [D loss: 0.528706, acc: 73.44%] [G loss: 2.611518]\n",
      "epoch:0 step:743 [D loss: 0.685340, acc: 57.03%] [G loss: 2.634261]\n",
      "epoch:0 step:744 [D loss: 0.594023, acc: 70.31%] [G loss: 2.718152]\n",
      "epoch:0 step:745 [D loss: 0.699200, acc: 57.03%] [G loss: 2.790614]\n",
      "epoch:0 step:746 [D loss: 0.415133, acc: 84.38%] [G loss: 3.188189]\n",
      "epoch:0 step:747 [D loss: 0.437603, acc: 83.59%] [G loss: 2.831924]\n",
      "epoch:0 step:748 [D loss: 0.447518, acc: 82.03%] [G loss: 2.834507]\n",
      "epoch:0 step:749 [D loss: 0.338431, acc: 91.41%] [G loss: 3.114192]\n",
      "epoch:0 step:750 [D loss: 0.429232, acc: 85.16%] [G loss: 3.320117]\n",
      "epoch:0 step:751 [D loss: 0.363900, acc: 89.84%] [G loss: 3.233676]\n",
      "epoch:0 step:752 [D loss: 0.238725, acc: 96.88%] [G loss: 3.484275]\n",
      "epoch:0 step:753 [D loss: 0.364855, acc: 86.72%] [G loss: 3.092699]\n",
      "epoch:0 step:754 [D loss: 0.255178, acc: 94.53%] [G loss: 3.299926]\n",
      "epoch:0 step:755 [D loss: 0.373931, acc: 89.06%] [G loss: 2.963524]\n",
      "epoch:0 step:756 [D loss: 0.375213, acc: 88.28%] [G loss: 3.676658]\n",
      "epoch:0 step:757 [D loss: 0.266227, acc: 92.19%] [G loss: 3.400437]\n",
      "epoch:0 step:758 [D loss: 0.179777, acc: 97.66%] [G loss: 3.678378]\n",
      "epoch:0 step:759 [D loss: 0.214174, acc: 97.66%] [G loss: 3.307424]\n",
      "epoch:0 step:760 [D loss: 0.194268, acc: 95.31%] [G loss: 3.502797]\n",
      "epoch:0 step:761 [D loss: 0.204696, acc: 97.66%] [G loss: 3.019125]\n",
      "epoch:0 step:762 [D loss: 0.284364, acc: 90.62%] [G loss: 2.839498]\n",
      "epoch:0 step:763 [D loss: 0.213853, acc: 94.53%] [G loss: 3.293406]\n",
      "epoch:0 step:764 [D loss: 0.422155, acc: 82.81%] [G loss: 2.092882]\n",
      "epoch:0 step:765 [D loss: 0.140771, acc: 97.66%] [G loss: 2.840922]\n",
      "epoch:0 step:766 [D loss: 0.279327, acc: 92.19%] [G loss: 2.731809]\n",
      "epoch:0 step:767 [D loss: 0.616446, acc: 70.31%] [G loss: 1.995136]\n",
      "epoch:0 step:768 [D loss: 0.345985, acc: 89.06%] [G loss: 2.601594]\n",
      "epoch:0 step:769 [D loss: 0.341925, acc: 90.62%] [G loss: 2.455631]\n",
      "epoch:0 step:770 [D loss: 0.200801, acc: 96.88%] [G loss: 2.503203]\n",
      "epoch:0 step:771 [D loss: 0.759548, acc: 64.06%] [G loss: 2.025725]\n",
      "epoch:0 step:772 [D loss: 0.469401, acc: 82.81%] [G loss: 2.379464]\n",
      "epoch:0 step:773 [D loss: 0.380885, acc: 85.94%] [G loss: 2.644672]\n",
      "epoch:0 step:774 [D loss: 0.508738, acc: 76.56%] [G loss: 1.962574]\n",
      "epoch:0 step:775 [D loss: 0.382918, acc: 86.72%] [G loss: 2.696815]\n",
      "epoch:0 step:776 [D loss: 0.604654, acc: 67.19%] [G loss: 1.812839]\n",
      "epoch:0 step:777 [D loss: 0.287482, acc: 91.41%] [G loss: 2.433787]\n",
      "epoch:0 step:778 [D loss: 0.462023, acc: 81.25%] [G loss: 1.608790]\n",
      "epoch:0 step:779 [D loss: 0.929494, acc: 44.53%] [G loss: 1.940566]\n",
      "epoch:0 step:780 [D loss: 0.586972, acc: 71.09%] [G loss: 1.502690]\n",
      "epoch:0 step:781 [D loss: 0.784553, acc: 53.12%] [G loss: 1.536549]\n",
      "epoch:1 step:782 [D loss: 0.866096, acc: 49.22%] [G loss: 1.622547]\n",
      "epoch:1 step:783 [D loss: 0.487043, acc: 81.25%] [G loss: 2.048658]\n",
      "epoch:1 step:784 [D loss: 1.218944, acc: 42.97%] [G loss: 1.376761]\n",
      "epoch:1 step:785 [D loss: 1.023710, acc: 37.50%] [G loss: 1.501819]\n",
      "epoch:1 step:786 [D loss: 0.881658, acc: 47.66%] [G loss: 1.558208]\n",
      "epoch:1 step:787 [D loss: 0.867277, acc: 43.75%] [G loss: 1.756657]\n",
      "epoch:1 step:788 [D loss: 0.778646, acc: 43.75%] [G loss: 1.797585]\n",
      "epoch:1 step:789 [D loss: 0.739618, acc: 59.38%] [G loss: 1.753954]\n",
      "epoch:1 step:790 [D loss: 0.978881, acc: 34.38%] [G loss: 2.027848]\n",
      "epoch:1 step:791 [D loss: 0.598633, acc: 72.66%] [G loss: 2.381636]\n",
      "epoch:1 step:792 [D loss: 0.758518, acc: 51.56%] [G loss: 2.216956]\n",
      "epoch:1 step:793 [D loss: 0.676067, acc: 57.81%] [G loss: 2.205767]\n",
      "epoch:1 step:794 [D loss: 0.594209, acc: 67.19%] [G loss: 2.418547]\n",
      "epoch:1 step:795 [D loss: 0.668439, acc: 60.16%] [G loss: 2.618654]\n",
      "epoch:1 step:796 [D loss: 0.456283, acc: 78.12%] [G loss: 2.588460]\n",
      "epoch:1 step:797 [D loss: 0.358130, acc: 82.81%] [G loss: 2.673296]\n",
      "epoch:1 step:798 [D loss: 0.387530, acc: 79.69%] [G loss: 3.351484]\n",
      "epoch:1 step:799 [D loss: 0.429166, acc: 82.03%] [G loss: 2.654433]\n",
      "epoch:1 step:800 [D loss: 0.409866, acc: 87.50%] [G loss: 2.542484]\n",
      "##############\n",
      "[0.85074991 0.89906895 0.81688345 0.83709222 0.77751468 0.85071193\n",
      " 0.91836348 0.82423322 0.82092098 0.85390681]\n",
      "##########\n",
      "epoch:1 step:801 [D loss: 0.353904, acc: 86.72%] [G loss: 2.446056]\n",
      "epoch:1 step:802 [D loss: 0.485829, acc: 75.00%] [G loss: 2.442884]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1 step:803 [D loss: 0.507308, acc: 73.44%] [G loss: 2.353035]\n",
      "epoch:1 step:804 [D loss: 0.345971, acc: 86.72%] [G loss: 2.551595]\n",
      "epoch:1 step:805 [D loss: 0.333962, acc: 89.06%] [G loss: 2.507545]\n",
      "epoch:1 step:806 [D loss: 0.239428, acc: 93.75%] [G loss: 2.916927]\n",
      "epoch:1 step:807 [D loss: 0.348614, acc: 89.06%] [G loss: 2.555016]\n",
      "epoch:1 step:808 [D loss: 0.424087, acc: 79.69%] [G loss: 2.157255]\n",
      "epoch:1 step:809 [D loss: 0.614149, acc: 67.19%] [G loss: 2.104987]\n",
      "epoch:1 step:810 [D loss: 0.463649, acc: 80.47%] [G loss: 2.096901]\n",
      "epoch:1 step:811 [D loss: 0.320529, acc: 89.84%] [G loss: 2.447391]\n",
      "epoch:1 step:812 [D loss: 0.517708, acc: 77.34%] [G loss: 2.096357]\n",
      "epoch:1 step:813 [D loss: 0.573757, acc: 71.88%] [G loss: 1.608603]\n",
      "epoch:1 step:814 [D loss: 0.385406, acc: 85.16%] [G loss: 2.023362]\n",
      "epoch:1 step:815 [D loss: 0.691823, acc: 60.94%] [G loss: 1.757057]\n",
      "epoch:1 step:816 [D loss: 1.119730, acc: 33.59%] [G loss: 1.540407]\n",
      "epoch:1 step:817 [D loss: 1.076636, acc: 35.94%] [G loss: 1.364403]\n",
      "epoch:1 step:818 [D loss: 1.165564, acc: 39.06%] [G loss: 1.292116]\n",
      "epoch:1 step:819 [D loss: 0.981592, acc: 44.53%] [G loss: 1.527640]\n",
      "epoch:1 step:820 [D loss: 1.176956, acc: 35.94%] [G loss: 1.915297]\n",
      "epoch:1 step:821 [D loss: 0.588689, acc: 71.09%] [G loss: 2.080730]\n",
      "epoch:1 step:822 [D loss: 1.025661, acc: 37.50%] [G loss: 1.730038]\n",
      "epoch:1 step:823 [D loss: 0.785829, acc: 51.56%] [G loss: 1.985716]\n",
      "epoch:1 step:824 [D loss: 0.757797, acc: 59.38%] [G loss: 2.254365]\n",
      "epoch:1 step:825 [D loss: 1.127524, acc: 39.84%] [G loss: 1.827924]\n",
      "epoch:1 step:826 [D loss: 0.759429, acc: 53.91%] [G loss: 2.114999]\n",
      "epoch:1 step:827 [D loss: 0.853219, acc: 54.69%] [G loss: 1.965855]\n",
      "epoch:1 step:828 [D loss: 0.889363, acc: 52.34%] [G loss: 2.156675]\n",
      "epoch:1 step:829 [D loss: 0.682460, acc: 66.41%] [G loss: 2.311118]\n",
      "epoch:1 step:830 [D loss: 0.478119, acc: 82.03%] [G loss: 2.774589]\n",
      "epoch:1 step:831 [D loss: 0.553732, acc: 72.66%] [G loss: 2.323656]\n",
      "epoch:1 step:832 [D loss: 0.528225, acc: 75.00%] [G loss: 2.409496]\n",
      "epoch:1 step:833 [D loss: 0.640943, acc: 68.75%] [G loss: 2.049687]\n",
      "epoch:1 step:834 [D loss: 0.604811, acc: 69.53%] [G loss: 2.475403]\n",
      "epoch:1 step:835 [D loss: 0.708336, acc: 61.72%] [G loss: 2.362722]\n",
      "epoch:1 step:836 [D loss: 0.524041, acc: 72.66%] [G loss: 2.414797]\n",
      "epoch:1 step:837 [D loss: 0.688276, acc: 62.50%] [G loss: 2.015846]\n",
      "epoch:1 step:838 [D loss: 0.716399, acc: 61.72%] [G loss: 2.123865]\n",
      "epoch:1 step:839 [D loss: 0.475620, acc: 78.12%] [G loss: 2.316854]\n",
      "epoch:1 step:840 [D loss: 0.468171, acc: 77.34%] [G loss: 2.013121]\n",
      "epoch:1 step:841 [D loss: 0.668087, acc: 66.41%] [G loss: 2.041264]\n",
      "epoch:1 step:842 [D loss: 0.549962, acc: 71.09%] [G loss: 2.395271]\n",
      "epoch:1 step:843 [D loss: 0.487670, acc: 82.03%] [G loss: 2.356153]\n",
      "epoch:1 step:844 [D loss: 0.544261, acc: 73.44%] [G loss: 2.260621]\n",
      "epoch:1 step:845 [D loss: 0.547289, acc: 72.66%] [G loss: 2.001739]\n",
      "epoch:1 step:846 [D loss: 0.407208, acc: 84.38%] [G loss: 2.063030]\n",
      "epoch:1 step:847 [D loss: 0.476008, acc: 80.47%] [G loss: 1.926177]\n",
      "epoch:1 step:848 [D loss: 0.447147, acc: 82.03%] [G loss: 2.177385]\n",
      "epoch:1 step:849 [D loss: 0.531703, acc: 69.53%] [G loss: 2.135540]\n",
      "epoch:1 step:850 [D loss: 0.390247, acc: 85.94%] [G loss: 1.934356]\n",
      "epoch:1 step:851 [D loss: 0.545827, acc: 77.34%] [G loss: 1.861326]\n",
      "epoch:1 step:852 [D loss: 0.360813, acc: 86.72%] [G loss: 2.245158]\n",
      "epoch:1 step:853 [D loss: 0.480146, acc: 78.12%] [G loss: 1.676967]\n",
      "epoch:1 step:854 [D loss: 0.453067, acc: 78.12%] [G loss: 1.810697]\n",
      "epoch:1 step:855 [D loss: 0.552844, acc: 75.00%] [G loss: 1.703354]\n",
      "epoch:1 step:856 [D loss: 0.717774, acc: 57.03%] [G loss: 1.447533]\n",
      "epoch:1 step:857 [D loss: 0.849222, acc: 49.22%] [G loss: 1.725767]\n",
      "epoch:1 step:858 [D loss: 0.414061, acc: 82.81%] [G loss: 1.871525]\n",
      "epoch:1 step:859 [D loss: 0.488813, acc: 79.69%] [G loss: 1.694457]\n",
      "epoch:1 step:860 [D loss: 0.431169, acc: 82.03%] [G loss: 1.712437]\n",
      "epoch:1 step:861 [D loss: 0.437692, acc: 82.81%] [G loss: 2.380242]\n",
      "epoch:1 step:862 [D loss: 0.977417, acc: 41.41%] [G loss: 1.472086]\n",
      "epoch:1 step:863 [D loss: 0.644896, acc: 64.84%] [G loss: 1.859069]\n",
      "epoch:1 step:864 [D loss: 0.932683, acc: 40.62%] [G loss: 1.713915]\n",
      "epoch:1 step:865 [D loss: 1.156438, acc: 32.81%] [G loss: 1.772685]\n",
      "epoch:1 step:866 [D loss: 0.324617, acc: 91.41%] [G loss: 2.383205]\n",
      "epoch:1 step:867 [D loss: 0.701608, acc: 57.81%] [G loss: 1.906510]\n",
      "epoch:1 step:868 [D loss: 0.572087, acc: 70.31%] [G loss: 2.071967]\n",
      "epoch:1 step:869 [D loss: 0.837762, acc: 47.66%] [G loss: 2.040308]\n",
      "epoch:1 step:870 [D loss: 0.822740, acc: 44.53%] [G loss: 1.872966]\n",
      "epoch:1 step:871 [D loss: 0.445304, acc: 80.47%] [G loss: 2.178801]\n",
      "epoch:1 step:872 [D loss: 0.990950, acc: 39.84%] [G loss: 2.013510]\n",
      "epoch:1 step:873 [D loss: 0.697492, acc: 61.72%] [G loss: 2.250325]\n",
      "epoch:1 step:874 [D loss: 0.754628, acc: 55.47%] [G loss: 1.954495]\n",
      "epoch:1 step:875 [D loss: 0.698091, acc: 63.28%] [G loss: 2.690070]\n",
      "epoch:1 step:876 [D loss: 0.613593, acc: 67.19%] [G loss: 2.263204]\n",
      "epoch:1 step:877 [D loss: 0.701023, acc: 64.06%] [G loss: 2.375669]\n",
      "epoch:1 step:878 [D loss: 0.402435, acc: 82.81%] [G loss: 2.945531]\n",
      "epoch:1 step:879 [D loss: 0.484401, acc: 75.78%] [G loss: 2.386609]\n",
      "epoch:1 step:880 [D loss: 0.649998, acc: 63.28%] [G loss: 2.458286]\n",
      "epoch:1 step:881 [D loss: 0.631137, acc: 61.72%] [G loss: 2.115626]\n",
      "epoch:1 step:882 [D loss: 0.766554, acc: 55.47%] [G loss: 2.216708]\n",
      "epoch:1 step:883 [D loss: 0.501454, acc: 77.34%] [G loss: 2.172598]\n",
      "epoch:1 step:884 [D loss: 0.488725, acc: 76.56%] [G loss: 2.495197]\n",
      "epoch:1 step:885 [D loss: 0.661998, acc: 64.06%] [G loss: 2.061456]\n",
      "epoch:1 step:886 [D loss: 0.528142, acc: 70.31%] [G loss: 1.972957]\n",
      "epoch:1 step:887 [D loss: 0.467558, acc: 81.25%] [G loss: 2.266980]\n",
      "epoch:1 step:888 [D loss: 0.540598, acc: 74.22%] [G loss: 1.958357]\n",
      "epoch:1 step:889 [D loss: 0.521066, acc: 78.91%] [G loss: 2.351026]\n",
      "epoch:1 step:890 [D loss: 0.848105, acc: 53.91%] [G loss: 1.611605]\n",
      "epoch:1 step:891 [D loss: 0.494400, acc: 73.44%] [G loss: 2.030285]\n",
      "epoch:1 step:892 [D loss: 0.928832, acc: 53.91%] [G loss: 1.933065]\n",
      "epoch:1 step:893 [D loss: 0.547540, acc: 69.53%] [G loss: 2.092350]\n",
      "epoch:1 step:894 [D loss: 0.632027, acc: 66.41%] [G loss: 2.526071]\n",
      "epoch:1 step:895 [D loss: 0.616866, acc: 71.88%] [G loss: 2.550533]\n",
      "epoch:1 step:896 [D loss: 0.664706, acc: 61.72%] [G loss: 2.368217]\n",
      "epoch:1 step:897 [D loss: 0.552803, acc: 75.00%] [G loss: 2.861429]\n",
      "epoch:1 step:898 [D loss: 0.459798, acc: 82.81%] [G loss: 3.236738]\n",
      "epoch:1 step:899 [D loss: 0.300342, acc: 89.84%] [G loss: 2.483142]\n",
      "epoch:1 step:900 [D loss: 0.449669, acc: 82.03%] [G loss: 2.714121]\n",
      "epoch:1 step:901 [D loss: 0.403145, acc: 80.47%] [G loss: 2.689127]\n",
      "epoch:1 step:902 [D loss: 0.521850, acc: 78.12%] [G loss: 2.352237]\n",
      "epoch:1 step:903 [D loss: 0.536223, acc: 70.31%] [G loss: 2.444725]\n",
      "epoch:1 step:904 [D loss: 0.618419, acc: 66.41%] [G loss: 2.102161]\n",
      "epoch:1 step:905 [D loss: 0.396350, acc: 83.59%] [G loss: 2.396564]\n",
      "epoch:1 step:906 [D loss: 0.497077, acc: 79.69%] [G loss: 2.090492]\n",
      "epoch:1 step:907 [D loss: 0.858087, acc: 52.34%] [G loss: 1.725966]\n",
      "epoch:1 step:908 [D loss: 0.577983, acc: 75.00%] [G loss: 2.500549]\n",
      "epoch:1 step:909 [D loss: 0.343861, acc: 89.84%] [G loss: 2.259341]\n",
      "epoch:1 step:910 [D loss: 1.181679, acc: 34.38%] [G loss: 1.942248]\n",
      "epoch:1 step:911 [D loss: 0.825127, acc: 64.84%] [G loss: 2.095773]\n",
      "epoch:1 step:912 [D loss: 0.631068, acc: 63.28%] [G loss: 2.298239]\n",
      "epoch:1 step:913 [D loss: 0.622680, acc: 70.31%] [G loss: 2.485594]\n",
      "epoch:1 step:914 [D loss: 0.764117, acc: 57.03%] [G loss: 2.851105]\n",
      "epoch:1 step:915 [D loss: 0.523687, acc: 75.78%] [G loss: 4.097446]\n",
      "epoch:1 step:916 [D loss: 0.245004, acc: 90.62%] [G loss: 4.993330]\n",
      "epoch:1 step:917 [D loss: 0.197041, acc: 93.75%] [G loss: 4.679071]\n",
      "epoch:1 step:918 [D loss: 0.243204, acc: 96.09%] [G loss: 3.713782]\n",
      "epoch:1 step:919 [D loss: 0.212322, acc: 94.53%] [G loss: 4.325548]\n",
      "epoch:1 step:920 [D loss: 0.226729, acc: 94.53%] [G loss: 3.835954]\n",
      "epoch:1 step:921 [D loss: 0.252353, acc: 90.62%] [G loss: 3.833930]\n",
      "epoch:1 step:922 [D loss: 0.210314, acc: 93.75%] [G loss: 3.217792]\n",
      "epoch:1 step:923 [D loss: 0.393181, acc: 84.38%] [G loss: 2.563765]\n",
      "epoch:1 step:924 [D loss: 0.211333, acc: 94.53%] [G loss: 3.223580]\n",
      "epoch:1 step:925 [D loss: 0.168880, acc: 94.53%] [G loss: 3.952816]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1 step:926 [D loss: 0.220294, acc: 96.88%] [G loss: 3.383039]\n",
      "epoch:1 step:927 [D loss: 0.140743, acc: 98.44%] [G loss: 4.003362]\n",
      "epoch:1 step:928 [D loss: 0.176370, acc: 98.44%] [G loss: 4.137681]\n",
      "epoch:1 step:929 [D loss: 0.250018, acc: 92.19%] [G loss: 4.446145]\n",
      "epoch:1 step:930 [D loss: 0.100948, acc: 100.00%] [G loss: 5.121805]\n",
      "epoch:1 step:931 [D loss: 0.138272, acc: 100.00%] [G loss: 4.811318]\n",
      "epoch:1 step:932 [D loss: 0.151392, acc: 97.66%] [G loss: 4.285640]\n",
      "epoch:1 step:933 [D loss: 0.234128, acc: 91.41%] [G loss: 4.123917]\n",
      "epoch:1 step:934 [D loss: 0.226574, acc: 94.53%] [G loss: 5.103286]\n",
      "epoch:1 step:935 [D loss: 0.153360, acc: 97.66%] [G loss: 3.893890]\n",
      "epoch:1 step:936 [D loss: 0.266180, acc: 89.84%] [G loss: 3.210854]\n",
      "epoch:1 step:937 [D loss: 0.116986, acc: 98.44%] [G loss: 3.828201]\n",
      "epoch:1 step:938 [D loss: 0.138986, acc: 96.88%] [G loss: 3.366621]\n",
      "epoch:1 step:939 [D loss: 0.142579, acc: 97.66%] [G loss: 3.447484]\n",
      "epoch:1 step:940 [D loss: 0.253791, acc: 91.41%] [G loss: 3.051014]\n",
      "epoch:1 step:941 [D loss: 0.293466, acc: 91.41%] [G loss: 3.106882]\n",
      "epoch:1 step:942 [D loss: 0.325864, acc: 84.38%] [G loss: 2.667243]\n",
      "epoch:1 step:943 [D loss: 0.455395, acc: 80.47%] [G loss: 2.290945]\n",
      "epoch:1 step:944 [D loss: 0.402502, acc: 82.81%] [G loss: 1.994900]\n",
      "epoch:1 step:945 [D loss: 0.390861, acc: 87.50%] [G loss: 2.375618]\n",
      "epoch:1 step:946 [D loss: 0.357504, acc: 86.72%] [G loss: 1.869703]\n",
      "epoch:1 step:947 [D loss: 0.232707, acc: 92.19%] [G loss: 2.132702]\n",
      "epoch:1 step:948 [D loss: 0.656266, acc: 67.97%] [G loss: 1.574676]\n",
      "epoch:1 step:949 [D loss: 0.689037, acc: 61.72%] [G loss: 1.497062]\n",
      "epoch:1 step:950 [D loss: 0.398097, acc: 82.03%] [G loss: 1.531887]\n",
      "epoch:1 step:951 [D loss: 0.458914, acc: 78.91%] [G loss: 1.966479]\n",
      "epoch:1 step:952 [D loss: 0.358456, acc: 88.28%] [G loss: 2.285689]\n",
      "epoch:1 step:953 [D loss: 0.981040, acc: 36.72%] [G loss: 1.774973]\n",
      "epoch:1 step:954 [D loss: 0.863771, acc: 55.47%] [G loss: 1.924592]\n",
      "epoch:1 step:955 [D loss: 0.368666, acc: 83.59%] [G loss: 2.104590]\n",
      "epoch:1 step:956 [D loss: 0.525614, acc: 73.44%] [G loss: 2.571798]\n",
      "epoch:1 step:957 [D loss: 0.354036, acc: 89.84%] [G loss: 2.440813]\n",
      "epoch:1 step:958 [D loss: 0.520477, acc: 74.22%] [G loss: 1.993190]\n",
      "epoch:1 step:959 [D loss: 0.317973, acc: 92.19%] [G loss: 3.338873]\n",
      "epoch:1 step:960 [D loss: 0.224284, acc: 96.88%] [G loss: 3.294120]\n",
      "epoch:1 step:961 [D loss: 0.188596, acc: 97.66%] [G loss: 3.002207]\n",
      "epoch:1 step:962 [D loss: 0.380879, acc: 82.81%] [G loss: 2.473317]\n",
      "epoch:1 step:963 [D loss: 0.300193, acc: 92.97%] [G loss: 2.364172]\n",
      "epoch:1 step:964 [D loss: 0.160779, acc: 97.66%] [G loss: 2.585607]\n",
      "epoch:1 step:965 [D loss: 0.277326, acc: 89.06%] [G loss: 2.680436]\n",
      "epoch:1 step:966 [D loss: 0.436631, acc: 75.00%] [G loss: 2.171048]\n",
      "epoch:1 step:967 [D loss: 0.355675, acc: 89.06%] [G loss: 2.891125]\n",
      "epoch:1 step:968 [D loss: 0.079396, acc: 98.44%] [G loss: 3.450607]\n",
      "epoch:1 step:969 [D loss: 0.164573, acc: 97.66%] [G loss: 2.939040]\n",
      "epoch:1 step:970 [D loss: 0.159776, acc: 96.88%] [G loss: 2.234339]\n",
      "epoch:1 step:971 [D loss: 0.133060, acc: 98.44%] [G loss: 2.701969]\n",
      "epoch:1 step:972 [D loss: 0.189429, acc: 95.31%] [G loss: 2.852448]\n",
      "epoch:1 step:973 [D loss: 0.177479, acc: 95.31%] [G loss: 2.790184]\n",
      "epoch:1 step:974 [D loss: 0.328771, acc: 85.16%] [G loss: 2.492942]\n",
      "epoch:1 step:975 [D loss: 0.296287, acc: 91.41%] [G loss: 1.950087]\n",
      "epoch:1 step:976 [D loss: 0.385900, acc: 82.81%] [G loss: 2.129095]\n",
      "epoch:1 step:977 [D loss: 0.566317, acc: 72.66%] [G loss: 1.980178]\n",
      "epoch:1 step:978 [D loss: 0.508399, acc: 67.19%] [G loss: 2.594763]\n",
      "epoch:1 step:979 [D loss: 0.400925, acc: 85.16%] [G loss: 2.139991]\n",
      "epoch:1 step:980 [D loss: 0.913231, acc: 49.22%] [G loss: 1.788547]\n",
      "epoch:1 step:981 [D loss: 0.649554, acc: 69.53%] [G loss: 1.639633]\n",
      "epoch:1 step:982 [D loss: 0.407220, acc: 86.72%] [G loss: 1.871015]\n",
      "epoch:1 step:983 [D loss: 0.577713, acc: 81.25%] [G loss: 2.306603]\n",
      "epoch:1 step:984 [D loss: 0.297777, acc: 93.75%] [G loss: 2.226911]\n",
      "epoch:1 step:985 [D loss: 0.246862, acc: 92.97%] [G loss: 2.699264]\n",
      "epoch:1 step:986 [D loss: 0.790983, acc: 60.94%] [G loss: 2.308405]\n",
      "epoch:1 step:987 [D loss: 0.657634, acc: 70.31%] [G loss: 1.970483]\n",
      "epoch:1 step:988 [D loss: 0.348951, acc: 92.97%] [G loss: 2.797306]\n",
      "epoch:1 step:989 [D loss: 0.604926, acc: 69.53%] [G loss: 1.925545]\n",
      "epoch:1 step:990 [D loss: 0.543821, acc: 66.41%] [G loss: 1.973629]\n",
      "epoch:1 step:991 [D loss: 0.284480, acc: 94.53%] [G loss: 2.112391]\n",
      "epoch:1 step:992 [D loss: 0.187500, acc: 95.31%] [G loss: 2.668226]\n",
      "epoch:1 step:993 [D loss: 0.315492, acc: 88.28%] [G loss: 3.019835]\n",
      "epoch:1 step:994 [D loss: 0.098765, acc: 98.44%] [G loss: 3.407685]\n",
      "epoch:1 step:995 [D loss: 0.995770, acc: 39.06%] [G loss: 1.600194]\n",
      "epoch:1 step:996 [D loss: 0.181224, acc: 96.09%] [G loss: 2.499780]\n",
      "epoch:1 step:997 [D loss: 0.370661, acc: 87.50%] [G loss: 1.915446]\n",
      "epoch:1 step:998 [D loss: 0.411465, acc: 78.12%] [G loss: 2.859491]\n",
      "epoch:1 step:999 [D loss: 0.780087, acc: 59.38%] [G loss: 1.735070]\n",
      "epoch:1 step:1000 [D loss: 0.267570, acc: 92.19%] [G loss: 2.518365]\n",
      "##############\n",
      "[0.85728823 0.91080629 0.79773901 0.81233884 0.77092664 0.82293058\n",
      " 0.87650548 0.83732427 0.81751788 0.81476549]\n",
      "##########\n",
      "epoch:1 step:1001 [D loss: 0.421314, acc: 83.59%] [G loss: 1.934004]\n",
      "epoch:1 step:1002 [D loss: 0.231266, acc: 94.53%] [G loss: 2.112082]\n",
      "epoch:1 step:1003 [D loss: 0.518940, acc: 72.66%] [G loss: 1.872963]\n",
      "epoch:1 step:1004 [D loss: 0.230890, acc: 95.31%] [G loss: 2.853482]\n",
      "epoch:1 step:1005 [D loss: 0.344764, acc: 85.94%] [G loss: 3.043233]\n",
      "epoch:1 step:1006 [D loss: 0.560949, acc: 71.09%] [G loss: 1.646111]\n",
      "epoch:1 step:1007 [D loss: 0.641453, acc: 64.06%] [G loss: 2.003339]\n",
      "epoch:1 step:1008 [D loss: 0.694038, acc: 58.59%] [G loss: 3.415900]\n",
      "epoch:1 step:1009 [D loss: 0.367884, acc: 90.62%] [G loss: 2.089300]\n",
      "epoch:1 step:1010 [D loss: 0.643722, acc: 67.97%] [G loss: 2.131263]\n",
      "epoch:1 step:1011 [D loss: 0.515678, acc: 75.00%] [G loss: 2.364610]\n",
      "epoch:1 step:1012 [D loss: 0.442841, acc: 74.22%] [G loss: 2.170506]\n",
      "epoch:1 step:1013 [D loss: 0.050289, acc: 100.00%] [G loss: 3.678258]\n",
      "epoch:1 step:1014 [D loss: 1.198768, acc: 37.50%] [G loss: 2.001709]\n",
      "epoch:1 step:1015 [D loss: 0.302331, acc: 92.97%] [G loss: 2.170140]\n",
      "epoch:1 step:1016 [D loss: 0.433539, acc: 82.81%] [G loss: 2.453228]\n",
      "epoch:1 step:1017 [D loss: 2.049898, acc: 7.03%] [G loss: 1.966402]\n",
      "epoch:1 step:1018 [D loss: 0.297979, acc: 92.19%] [G loss: 2.481616]\n",
      "epoch:1 step:1019 [D loss: 0.544840, acc: 73.44%] [G loss: 2.351474]\n",
      "epoch:1 step:1020 [D loss: 0.489356, acc: 78.12%] [G loss: 3.053733]\n",
      "epoch:1 step:1021 [D loss: 1.388773, acc: 22.66%] [G loss: 2.480433]\n",
      "epoch:1 step:1022 [D loss: 0.297957, acc: 91.41%] [G loss: 3.088149]\n",
      "epoch:1 step:1023 [D loss: 0.490081, acc: 75.00%] [G loss: 2.282691]\n",
      "epoch:1 step:1024 [D loss: 0.345595, acc: 92.97%] [G loss: 2.646213]\n",
      "epoch:1 step:1025 [D loss: 0.169831, acc: 94.53%] [G loss: 3.640034]\n",
      "epoch:1 step:1026 [D loss: 0.269986, acc: 94.53%] [G loss: 2.711221]\n",
      "epoch:1 step:1027 [D loss: 0.377267, acc: 85.94%] [G loss: 3.107409]\n",
      "epoch:1 step:1028 [D loss: 0.305171, acc: 92.19%] [G loss: 2.730803]\n",
      "epoch:1 step:1029 [D loss: 0.203238, acc: 94.53%] [G loss: 3.055327]\n",
      "epoch:1 step:1030 [D loss: 0.263924, acc: 92.19%] [G loss: 2.951396]\n",
      "epoch:1 step:1031 [D loss: 0.138673, acc: 97.66%] [G loss: 3.018485]\n",
      "epoch:1 step:1032 [D loss: 0.096068, acc: 99.22%] [G loss: 3.338613]\n",
      "epoch:1 step:1033 [D loss: 0.545165, acc: 70.31%] [G loss: 2.452952]\n",
      "epoch:1 step:1034 [D loss: 0.264454, acc: 92.19%] [G loss: 2.483283]\n",
      "epoch:1 step:1035 [D loss: 0.835358, acc: 49.22%] [G loss: 2.057528]\n",
      "epoch:1 step:1036 [D loss: 0.300661, acc: 88.28%] [G loss: 2.955450]\n",
      "epoch:1 step:1037 [D loss: 0.218947, acc: 92.97%] [G loss: 2.866063]\n",
      "epoch:1 step:1038 [D loss: 0.338837, acc: 88.28%] [G loss: 2.233987]\n",
      "epoch:1 step:1039 [D loss: 0.116364, acc: 98.44%] [G loss: 3.163511]\n",
      "epoch:1 step:1040 [D loss: 0.514422, acc: 75.00%] [G loss: 1.867891]\n",
      "epoch:1 step:1041 [D loss: 0.064301, acc: 99.22%] [G loss: 3.668986]\n",
      "epoch:1 step:1042 [D loss: 0.199432, acc: 96.09%] [G loss: 3.024399]\n",
      "epoch:1 step:1043 [D loss: 0.129760, acc: 95.31%] [G loss: 2.781596]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1 step:1044 [D loss: 1.862085, acc: 19.53%] [G loss: 2.017682]\n",
      "epoch:1 step:1045 [D loss: 0.376035, acc: 84.38%] [G loss: 2.610878]\n",
      "epoch:1 step:1046 [D loss: 0.281689, acc: 90.62%] [G loss: 3.915416]\n",
      "epoch:1 step:1047 [D loss: 0.741893, acc: 63.28%] [G loss: 2.930105]\n",
      "epoch:1 step:1048 [D loss: 1.693130, acc: 35.94%] [G loss: 1.704856]\n",
      "epoch:1 step:1049 [D loss: 0.529548, acc: 72.66%] [G loss: 3.391961]\n",
      "epoch:1 step:1050 [D loss: 0.477422, acc: 80.47%] [G loss: 3.453168]\n",
      "epoch:1 step:1051 [D loss: 0.310337, acc: 85.16%] [G loss: 3.894759]\n",
      "epoch:1 step:1052 [D loss: 0.431625, acc: 79.69%] [G loss: 3.380616]\n",
      "epoch:1 step:1053 [D loss: 0.646427, acc: 63.28%] [G loss: 3.048694]\n",
      "epoch:1 step:1054 [D loss: 0.715479, acc: 64.06%] [G loss: 2.423117]\n",
      "epoch:1 step:1055 [D loss: 1.050704, acc: 42.97%] [G loss: 3.524144]\n",
      "epoch:1 step:1056 [D loss: 0.744126, acc: 57.81%] [G loss: 2.587151]\n",
      "epoch:1 step:1057 [D loss: 1.287340, acc: 32.03%] [G loss: 2.243842]\n",
      "epoch:1 step:1058 [D loss: 2.144036, acc: 10.94%] [G loss: 1.265676]\n",
      "epoch:1 step:1059 [D loss: 0.552123, acc: 73.44%] [G loss: 2.821478]\n",
      "epoch:1 step:1060 [D loss: 0.376910, acc: 89.06%] [G loss: 2.632973]\n",
      "epoch:1 step:1061 [D loss: 0.224846, acc: 93.75%] [G loss: 3.065516]\n",
      "epoch:1 step:1062 [D loss: 0.314397, acc: 92.97%] [G loss: 2.603128]\n",
      "epoch:1 step:1063 [D loss: 0.709089, acc: 62.50%] [G loss: 1.499788]\n",
      "epoch:1 step:1064 [D loss: 0.878352, acc: 55.47%] [G loss: 2.479972]\n",
      "epoch:1 step:1065 [D loss: 0.367864, acc: 81.25%] [G loss: 2.010865]\n",
      "epoch:1 step:1066 [D loss: 0.192438, acc: 96.09%] [G loss: 2.954623]\n",
      "epoch:1 step:1067 [D loss: 0.993831, acc: 40.62%] [G loss: 1.394189]\n",
      "epoch:1 step:1068 [D loss: 0.397867, acc: 84.38%] [G loss: 1.588507]\n",
      "epoch:1 step:1069 [D loss: 0.628824, acc: 64.84%] [G loss: 1.766266]\n",
      "epoch:1 step:1070 [D loss: 0.512627, acc: 75.00%] [G loss: 1.777264]\n",
      "epoch:1 step:1071 [D loss: 0.624398, acc: 64.84%] [G loss: 2.364168]\n",
      "epoch:1 step:1072 [D loss: 0.382830, acc: 89.06%] [G loss: 2.260144]\n",
      "epoch:1 step:1073 [D loss: 0.990078, acc: 52.34%] [G loss: 1.562404]\n",
      "epoch:1 step:1074 [D loss: 0.201335, acc: 95.31%] [G loss: 2.683291]\n",
      "epoch:1 step:1075 [D loss: 0.486574, acc: 77.34%] [G loss: 2.394083]\n",
      "epoch:1 step:1076 [D loss: 0.832463, acc: 55.47%] [G loss: 1.474624]\n",
      "epoch:1 step:1077 [D loss: 0.718900, acc: 60.16%] [G loss: 2.636904]\n",
      "epoch:1 step:1078 [D loss: 0.461614, acc: 78.91%] [G loss: 2.494427]\n",
      "epoch:1 step:1079 [D loss: 0.285088, acc: 90.62%] [G loss: 3.043932]\n",
      "epoch:1 step:1080 [D loss: 0.478219, acc: 78.91%] [G loss: 2.303917]\n",
      "epoch:1 step:1081 [D loss: 1.176555, acc: 27.34%] [G loss: 1.907736]\n",
      "epoch:1 step:1082 [D loss: 0.566733, acc: 67.97%] [G loss: 2.140981]\n",
      "epoch:1 step:1083 [D loss: 0.262046, acc: 94.53%] [G loss: 2.136936]\n",
      "epoch:1 step:1084 [D loss: 0.733494, acc: 62.50%] [G loss: 2.318098]\n",
      "epoch:1 step:1085 [D loss: 0.782656, acc: 57.81%] [G loss: 2.356567]\n",
      "epoch:1 step:1086 [D loss: 0.659518, acc: 61.72%] [G loss: 2.352427]\n",
      "epoch:1 step:1087 [D loss: 0.434844, acc: 82.03%] [G loss: 2.540200]\n",
      "epoch:1 step:1088 [D loss: 0.532523, acc: 73.44%] [G loss: 2.577758]\n",
      "epoch:1 step:1089 [D loss: 0.497645, acc: 71.09%] [G loss: 2.203469]\n",
      "epoch:1 step:1090 [D loss: 0.713422, acc: 65.62%] [G loss: 2.521286]\n",
      "epoch:1 step:1091 [D loss: 0.464415, acc: 80.47%] [G loss: 2.249559]\n",
      "epoch:1 step:1092 [D loss: 0.496913, acc: 77.34%] [G loss: 2.195151]\n",
      "epoch:1 step:1093 [D loss: 0.867641, acc: 50.00%] [G loss: 2.500332]\n",
      "epoch:1 step:1094 [D loss: 0.515785, acc: 73.44%] [G loss: 2.103209]\n",
      "epoch:1 step:1095 [D loss: 0.319361, acc: 85.94%] [G loss: 2.098966]\n",
      "epoch:1 step:1096 [D loss: 0.210149, acc: 96.09%] [G loss: 3.163085]\n",
      "epoch:1 step:1097 [D loss: 0.550126, acc: 69.53%] [G loss: 2.294404]\n",
      "epoch:1 step:1098 [D loss: 0.446395, acc: 89.06%] [G loss: 1.622793]\n",
      "epoch:1 step:1099 [D loss: 0.121778, acc: 98.44%] [G loss: 3.083408]\n",
      "epoch:1 step:1100 [D loss: 0.492903, acc: 68.75%] [G loss: 2.291765]\n",
      "epoch:1 step:1101 [D loss: 0.239271, acc: 91.41%] [G loss: 3.906150]\n",
      "epoch:1 step:1102 [D loss: 0.663058, acc: 61.72%] [G loss: 3.073163]\n",
      "epoch:1 step:1103 [D loss: 0.376854, acc: 87.50%] [G loss: 2.599916]\n",
      "epoch:1 step:1104 [D loss: 0.305227, acc: 89.06%] [G loss: 2.698853]\n",
      "epoch:1 step:1105 [D loss: 0.433347, acc: 85.16%] [G loss: 2.212699]\n",
      "epoch:1 step:1106 [D loss: 0.107122, acc: 99.22%] [G loss: 3.017611]\n",
      "epoch:1 step:1107 [D loss: 0.165215, acc: 97.66%] [G loss: 2.918886]\n",
      "epoch:1 step:1108 [D loss: 0.493093, acc: 75.00%] [G loss: 2.273209]\n",
      "epoch:1 step:1109 [D loss: 0.637258, acc: 67.97%] [G loss: 2.693277]\n",
      "epoch:1 step:1110 [D loss: 0.745073, acc: 57.03%] [G loss: 2.177185]\n",
      "epoch:1 step:1111 [D loss: 0.677301, acc: 62.50%] [G loss: 2.327781]\n",
      "epoch:1 step:1112 [D loss: 0.112982, acc: 98.44%] [G loss: 3.130794]\n",
      "epoch:1 step:1113 [D loss: 0.935015, acc: 54.69%] [G loss: 2.304032]\n",
      "epoch:1 step:1114 [D loss: 0.883532, acc: 47.66%] [G loss: 2.494226]\n",
      "epoch:1 step:1115 [D loss: 1.268105, acc: 24.22%] [G loss: 2.005680]\n",
      "epoch:1 step:1116 [D loss: 0.549432, acc: 79.69%] [G loss: 2.525768]\n",
      "epoch:1 step:1117 [D loss: 1.309737, acc: 25.00%] [G loss: 2.096204]\n",
      "epoch:1 step:1118 [D loss: 0.957515, acc: 42.97%] [G loss: 2.207002]\n",
      "epoch:1 step:1119 [D loss: 1.043345, acc: 38.28%] [G loss: 1.731959]\n",
      "epoch:1 step:1120 [D loss: 0.550092, acc: 78.91%] [G loss: 2.489482]\n",
      "epoch:1 step:1121 [D loss: 0.755311, acc: 57.81%] [G loss: 1.744494]\n",
      "epoch:1 step:1122 [D loss: 0.431286, acc: 87.50%] [G loss: 2.692436]\n",
      "epoch:1 step:1123 [D loss: 0.419741, acc: 86.72%] [G loss: 2.354003]\n",
      "epoch:1 step:1124 [D loss: 0.581691, acc: 64.84%] [G loss: 2.535286]\n",
      "epoch:1 step:1125 [D loss: 0.416872, acc: 85.16%] [G loss: 2.693041]\n",
      "epoch:1 step:1126 [D loss: 0.253137, acc: 95.31%] [G loss: 2.807717]\n",
      "epoch:1 step:1127 [D loss: 0.420612, acc: 82.81%] [G loss: 2.352219]\n",
      "epoch:1 step:1128 [D loss: 0.247445, acc: 95.31%] [G loss: 2.596380]\n",
      "epoch:1 step:1129 [D loss: 0.655075, acc: 59.38%] [G loss: 2.320526]\n",
      "epoch:1 step:1130 [D loss: 0.692028, acc: 64.84%] [G loss: 2.275516]\n",
      "epoch:1 step:1131 [D loss: 0.834981, acc: 54.69%] [G loss: 2.025120]\n",
      "epoch:1 step:1132 [D loss: 0.594854, acc: 63.28%] [G loss: 2.999171]\n",
      "epoch:1 step:1133 [D loss: 0.506567, acc: 75.78%] [G loss: 2.409733]\n",
      "epoch:1 step:1134 [D loss: 0.577038, acc: 71.09%] [G loss: 2.134456]\n",
      "epoch:1 step:1135 [D loss: 0.636539, acc: 60.94%] [G loss: 2.381552]\n",
      "epoch:1 step:1136 [D loss: 0.420733, acc: 77.34%] [G loss: 1.803167]\n",
      "epoch:1 step:1137 [D loss: 0.923450, acc: 49.22%] [G loss: 1.824706]\n",
      "epoch:1 step:1138 [D loss: 0.846102, acc: 47.66%] [G loss: 1.440297]\n",
      "epoch:1 step:1139 [D loss: 0.870836, acc: 49.22%] [G loss: 1.213179]\n",
      "epoch:1 step:1140 [D loss: 0.932532, acc: 40.62%] [G loss: 1.227016]\n",
      "epoch:1 step:1141 [D loss: 1.143380, acc: 29.69%] [G loss: 1.230237]\n",
      "epoch:1 step:1142 [D loss: 1.621415, acc: 10.16%] [G loss: 0.972929]\n",
      "epoch:1 step:1143 [D loss: 1.374346, acc: 25.00%] [G loss: 1.104208]\n",
      "epoch:1 step:1144 [D loss: 0.920193, acc: 35.16%] [G loss: 1.501465]\n",
      "epoch:1 step:1145 [D loss: 1.002379, acc: 28.91%] [G loss: 1.561175]\n",
      "epoch:1 step:1146 [D loss: 1.028240, acc: 25.78%] [G loss: 1.689431]\n",
      "epoch:1 step:1147 [D loss: 1.005600, acc: 28.91%] [G loss: 1.709021]\n",
      "epoch:1 step:1148 [D loss: 0.731057, acc: 53.12%] [G loss: 1.941558]\n",
      "epoch:1 step:1149 [D loss: 0.722875, acc: 63.28%] [G loss: 1.930195]\n",
      "epoch:1 step:1150 [D loss: 0.829345, acc: 43.75%] [G loss: 1.974459]\n",
      "epoch:1 step:1151 [D loss: 0.570519, acc: 71.88%] [G loss: 2.807567]\n",
      "epoch:1 step:1152 [D loss: 0.577734, acc: 67.19%] [G loss: 2.467588]\n",
      "epoch:1 step:1153 [D loss: 0.536811, acc: 70.31%] [G loss: 2.528293]\n",
      "epoch:1 step:1154 [D loss: 0.742899, acc: 58.59%] [G loss: 2.178560]\n",
      "epoch:1 step:1155 [D loss: 0.356668, acc: 89.06%] [G loss: 2.455261]\n",
      "epoch:1 step:1156 [D loss: 0.721998, acc: 63.28%] [G loss: 1.852142]\n",
      "epoch:1 step:1157 [D loss: 0.462668, acc: 83.59%] [G loss: 2.358327]\n",
      "epoch:1 step:1158 [D loss: 0.449594, acc: 82.81%] [G loss: 2.099344]\n",
      "epoch:1 step:1159 [D loss: 0.540972, acc: 74.22%] [G loss: 1.711566]\n",
      "epoch:1 step:1160 [D loss: 0.734736, acc: 51.56%] [G loss: 1.475918]\n",
      "epoch:1 step:1161 [D loss: 0.655060, acc: 58.59%] [G loss: 1.406570]\n",
      "epoch:1 step:1162 [D loss: 0.851502, acc: 46.88%] [G loss: 1.460903]\n",
      "epoch:1 step:1163 [D loss: 0.857649, acc: 48.44%] [G loss: 1.466658]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1 step:1164 [D loss: 0.735451, acc: 55.47%] [G loss: 1.410200]\n",
      "epoch:1 step:1165 [D loss: 1.130476, acc: 22.66%] [G loss: 1.377780]\n",
      "epoch:1 step:1166 [D loss: 0.948849, acc: 35.94%] [G loss: 1.377432]\n",
      "epoch:1 step:1167 [D loss: 1.198999, acc: 21.88%] [G loss: 1.360606]\n",
      "epoch:1 step:1168 [D loss: 0.851489, acc: 42.97%] [G loss: 1.606752]\n",
      "epoch:1 step:1169 [D loss: 0.885706, acc: 34.38%] [G loss: 1.844876]\n",
      "epoch:1 step:1170 [D loss: 0.796907, acc: 53.91%] [G loss: 1.861532]\n",
      "epoch:1 step:1171 [D loss: 0.543803, acc: 75.00%] [G loss: 2.100554]\n",
      "epoch:1 step:1172 [D loss: 0.535931, acc: 77.34%] [G loss: 2.522529]\n",
      "epoch:1 step:1173 [D loss: 0.431782, acc: 78.91%] [G loss: 3.017413]\n",
      "epoch:1 step:1174 [D loss: 0.429540, acc: 83.59%] [G loss: 2.363212]\n",
      "epoch:1 step:1175 [D loss: 0.193026, acc: 96.09%] [G loss: 2.887539]\n",
      "epoch:1 step:1176 [D loss: 0.290414, acc: 92.97%] [G loss: 2.706328]\n",
      "epoch:1 step:1177 [D loss: 0.249989, acc: 96.09%] [G loss: 3.225955]\n",
      "epoch:1 step:1178 [D loss: 0.229301, acc: 96.09%] [G loss: 2.435390]\n",
      "epoch:1 step:1179 [D loss: 0.190571, acc: 95.31%] [G loss: 2.454791]\n",
      "epoch:1 step:1180 [D loss: 0.273714, acc: 92.19%] [G loss: 2.344341]\n",
      "epoch:1 step:1181 [D loss: 0.660615, acc: 61.72%] [G loss: 1.721329]\n",
      "epoch:1 step:1182 [D loss: 0.313098, acc: 90.62%] [G loss: 1.613654]\n",
      "epoch:1 step:1183 [D loss: 0.620295, acc: 64.06%] [G loss: 1.895712]\n",
      "epoch:1 step:1184 [D loss: 0.826540, acc: 49.22%] [G loss: 1.566937]\n",
      "epoch:1 step:1185 [D loss: 0.555214, acc: 75.00%] [G loss: 1.920492]\n",
      "epoch:1 step:1186 [D loss: 0.380062, acc: 84.38%] [G loss: 1.680154]\n",
      "epoch:1 step:1187 [D loss: 0.758580, acc: 56.25%] [G loss: 1.388379]\n",
      "epoch:1 step:1188 [D loss: 1.511853, acc: 18.75%] [G loss: 0.980451]\n",
      "epoch:1 step:1189 [D loss: 1.101869, acc: 22.66%] [G loss: 1.221955]\n",
      "epoch:1 step:1190 [D loss: 0.869900, acc: 44.53%] [G loss: 1.357060]\n",
      "epoch:1 step:1191 [D loss: 1.064971, acc: 31.25%] [G loss: 1.389634]\n",
      "epoch:1 step:1192 [D loss: 0.595138, acc: 67.97%] [G loss: 1.827581]\n",
      "epoch:1 step:1193 [D loss: 0.634943, acc: 67.19%] [G loss: 1.882562]\n",
      "epoch:1 step:1194 [D loss: 0.975826, acc: 37.50%] [G loss: 1.708155]\n",
      "epoch:1 step:1195 [D loss: 0.792974, acc: 52.34%] [G loss: 1.829711]\n",
      "epoch:1 step:1196 [D loss: 0.937642, acc: 40.62%] [G loss: 1.800517]\n",
      "epoch:1 step:1197 [D loss: 0.814453, acc: 50.00%] [G loss: 2.140335]\n",
      "epoch:1 step:1198 [D loss: 0.680840, acc: 55.47%] [G loss: 2.210220]\n",
      "epoch:1 step:1199 [D loss: 0.511882, acc: 78.91%] [G loss: 2.811849]\n",
      "epoch:1 step:1200 [D loss: 0.476053, acc: 82.03%] [G loss: 2.770918]\n",
      "##############\n",
      "[0.85704399 0.89397218 0.80728829 0.81650346 0.80506313 0.82809606\n",
      " 0.88145016 0.84496474 0.84649176 0.84685483]\n",
      "##########\n",
      "epoch:1 step:1201 [D loss: 0.443294, acc: 82.81%] [G loss: 2.364446]\n",
      "epoch:1 step:1202 [D loss: 0.429923, acc: 85.16%] [G loss: 2.403782]\n",
      "epoch:1 step:1203 [D loss: 0.388480, acc: 89.84%] [G loss: 2.755047]\n",
      "epoch:1 step:1204 [D loss: 0.558889, acc: 72.66%] [G loss: 2.301438]\n",
      "epoch:1 step:1205 [D loss: 0.562972, acc: 74.22%] [G loss: 2.140975]\n",
      "epoch:1 step:1206 [D loss: 0.739815, acc: 57.03%] [G loss: 1.724297]\n",
      "epoch:1 step:1207 [D loss: 0.504703, acc: 75.00%] [G loss: 1.944418]\n",
      "epoch:1 step:1208 [D loss: 0.405787, acc: 83.59%] [G loss: 2.267066]\n",
      "epoch:1 step:1209 [D loss: 0.794088, acc: 48.44%] [G loss: 1.857976]\n",
      "epoch:1 step:1210 [D loss: 0.587331, acc: 66.41%] [G loss: 2.012930]\n",
      "epoch:1 step:1211 [D loss: 0.672979, acc: 64.84%] [G loss: 1.842340]\n",
      "epoch:1 step:1212 [D loss: 0.598184, acc: 67.19%] [G loss: 2.285213]\n",
      "epoch:1 step:1213 [D loss: 0.597194, acc: 67.97%] [G loss: 1.784677]\n",
      "epoch:1 step:1214 [D loss: 0.651677, acc: 60.16%] [G loss: 2.089644]\n",
      "epoch:1 step:1215 [D loss: 0.585127, acc: 75.00%] [G loss: 2.320724]\n",
      "epoch:1 step:1216 [D loss: 0.585854, acc: 67.19%] [G loss: 2.241939]\n",
      "epoch:1 step:1217 [D loss: 0.508532, acc: 76.56%] [G loss: 2.205006]\n",
      "epoch:1 step:1218 [D loss: 0.368012, acc: 89.06%] [G loss: 2.304282]\n",
      "epoch:1 step:1219 [D loss: 0.435520, acc: 79.69%] [G loss: 2.037847]\n",
      "epoch:1 step:1220 [D loss: 0.522063, acc: 75.78%] [G loss: 2.084495]\n",
      "epoch:1 step:1221 [D loss: 0.283034, acc: 92.19%] [G loss: 2.352670]\n",
      "epoch:1 step:1222 [D loss: 0.629339, acc: 64.84%] [G loss: 1.831760]\n",
      "epoch:1 step:1223 [D loss: 0.437097, acc: 85.16%] [G loss: 1.740233]\n",
      "epoch:1 step:1224 [D loss: 0.536858, acc: 72.66%] [G loss: 2.032240]\n",
      "epoch:1 step:1225 [D loss: 0.479092, acc: 75.78%] [G loss: 1.652441]\n",
      "epoch:1 step:1226 [D loss: 0.747874, acc: 50.78%] [G loss: 1.616892]\n",
      "epoch:1 step:1227 [D loss: 0.673802, acc: 60.16%] [G loss: 1.357993]\n",
      "epoch:1 step:1228 [D loss: 0.331112, acc: 90.62%] [G loss: 2.219911]\n",
      "epoch:1 step:1229 [D loss: 1.035646, acc: 29.69%] [G loss: 1.506679]\n",
      "epoch:1 step:1230 [D loss: 0.313798, acc: 93.75%] [G loss: 1.892346]\n",
      "epoch:1 step:1231 [D loss: 0.508659, acc: 78.12%] [G loss: 1.730892]\n",
      "epoch:1 step:1232 [D loss: 0.770184, acc: 47.66%] [G loss: 1.708635]\n",
      "epoch:1 step:1233 [D loss: 0.423208, acc: 83.59%] [G loss: 1.965105]\n",
      "epoch:1 step:1234 [D loss: 0.676422, acc: 53.91%] [G loss: 1.454101]\n",
      "epoch:1 step:1235 [D loss: 0.612949, acc: 71.09%] [G loss: 1.570888]\n",
      "epoch:1 step:1236 [D loss: 0.354534, acc: 89.06%] [G loss: 1.928214]\n",
      "epoch:1 step:1237 [D loss: 0.640815, acc: 62.50%] [G loss: 1.760850]\n",
      "epoch:1 step:1238 [D loss: 0.479013, acc: 80.47%] [G loss: 1.666462]\n",
      "epoch:1 step:1239 [D loss: 0.512682, acc: 78.12%] [G loss: 1.815698]\n",
      "epoch:1 step:1240 [D loss: 0.638532, acc: 63.28%] [G loss: 1.952633]\n",
      "epoch:1 step:1241 [D loss: 0.991030, acc: 35.16%] [G loss: 1.788595]\n",
      "epoch:1 step:1242 [D loss: 0.646021, acc: 60.94%] [G loss: 2.137218]\n",
      "epoch:1 step:1243 [D loss: 0.719240, acc: 53.91%] [G loss: 1.791145]\n",
      "epoch:1 step:1244 [D loss: 1.028575, acc: 39.84%] [G loss: 1.999568]\n",
      "epoch:1 step:1245 [D loss: 0.426693, acc: 82.03%] [G loss: 2.258518]\n",
      "epoch:1 step:1246 [D loss: 0.664375, acc: 64.06%] [G loss: 2.083902]\n",
      "epoch:1 step:1247 [D loss: 0.631646, acc: 67.97%] [G loss: 2.137638]\n",
      "epoch:1 step:1248 [D loss: 0.570550, acc: 75.00%] [G loss: 2.235016]\n",
      "epoch:1 step:1249 [D loss: 0.758875, acc: 55.47%] [G loss: 2.162673]\n",
      "epoch:1 step:1250 [D loss: 0.376309, acc: 87.50%] [G loss: 2.445738]\n",
      "epoch:1 step:1251 [D loss: 0.820246, acc: 55.47%] [G loss: 2.068640]\n",
      "epoch:1 step:1252 [D loss: 0.467849, acc: 78.91%] [G loss: 2.257071]\n",
      "epoch:1 step:1253 [D loss: 0.507023, acc: 81.25%] [G loss: 2.601939]\n",
      "epoch:1 step:1254 [D loss: 0.364087, acc: 90.62%] [G loss: 2.529381]\n",
      "epoch:1 step:1255 [D loss: 0.689426, acc: 65.62%] [G loss: 2.078190]\n",
      "epoch:1 step:1256 [D loss: 0.252051, acc: 93.75%] [G loss: 2.953101]\n",
      "epoch:1 step:1257 [D loss: 0.266881, acc: 92.19%] [G loss: 2.680670]\n",
      "epoch:1 step:1258 [D loss: 0.186190, acc: 96.88%] [G loss: 2.023233]\n",
      "epoch:1 step:1259 [D loss: 0.341162, acc: 87.50%] [G loss: 2.360298]\n",
      "epoch:1 step:1260 [D loss: 0.289231, acc: 91.41%] [G loss: 2.146202]\n",
      "epoch:1 step:1261 [D loss: 0.763593, acc: 56.25%] [G loss: 2.230470]\n",
      "epoch:1 step:1262 [D loss: 0.484931, acc: 75.00%] [G loss: 2.223267]\n",
      "epoch:1 step:1263 [D loss: 0.286528, acc: 86.72%] [G loss: 2.583094]\n",
      "epoch:1 step:1264 [D loss: 0.391994, acc: 78.12%] [G loss: 2.399195]\n",
      "epoch:1 step:1265 [D loss: 1.101172, acc: 48.44%] [G loss: 2.137967]\n",
      "epoch:1 step:1266 [D loss: 0.328818, acc: 92.19%] [G loss: 1.915030]\n",
      "epoch:1 step:1267 [D loss: 0.241401, acc: 96.09%] [G loss: 2.686243]\n",
      "epoch:1 step:1268 [D loss: 0.152765, acc: 98.44%] [G loss: 2.435412]\n",
      "epoch:1 step:1269 [D loss: 0.860979, acc: 45.31%] [G loss: 1.451365]\n",
      "epoch:1 step:1270 [D loss: 0.610841, acc: 59.38%] [G loss: 1.843943]\n",
      "epoch:1 step:1271 [D loss: 0.254152, acc: 91.41%] [G loss: 1.970049]\n",
      "epoch:1 step:1272 [D loss: 0.497756, acc: 74.22%] [G loss: 2.238777]\n",
      "epoch:1 step:1273 [D loss: 0.710777, acc: 63.28%] [G loss: 1.943457]\n",
      "epoch:1 step:1274 [D loss: 1.063802, acc: 46.88%] [G loss: 1.997367]\n",
      "epoch:1 step:1275 [D loss: 1.059581, acc: 34.38%] [G loss: 1.622326]\n",
      "epoch:1 step:1276 [D loss: 0.788126, acc: 53.12%] [G loss: 1.652084]\n",
      "epoch:1 step:1277 [D loss: 0.818257, acc: 52.34%] [G loss: 1.846975]\n",
      "epoch:1 step:1278 [D loss: 0.578644, acc: 72.66%] [G loss: 2.141043]\n",
      "epoch:1 step:1279 [D loss: 0.627674, acc: 63.28%] [G loss: 2.254260]\n",
      "epoch:1 step:1280 [D loss: 0.671331, acc: 61.72%] [G loss: 2.202622]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1 step:1281 [D loss: 1.246710, acc: 33.59%] [G loss: 1.745727]\n",
      "epoch:1 step:1282 [D loss: 0.754550, acc: 54.69%] [G loss: 2.183429]\n",
      "epoch:1 step:1283 [D loss: 0.760037, acc: 60.94%] [G loss: 1.990625]\n",
      "epoch:1 step:1284 [D loss: 0.812829, acc: 47.66%] [G loss: 2.439691]\n",
      "epoch:1 step:1285 [D loss: 0.650089, acc: 69.53%] [G loss: 1.997031]\n",
      "epoch:1 step:1286 [D loss: 0.571016, acc: 73.44%] [G loss: 1.956915]\n",
      "epoch:1 step:1287 [D loss: 0.515539, acc: 73.44%] [G loss: 2.363000]\n",
      "epoch:1 step:1288 [D loss: 0.683661, acc: 67.97%] [G loss: 2.016470]\n",
      "epoch:1 step:1289 [D loss: 0.399659, acc: 83.59%] [G loss: 2.842053]\n",
      "epoch:1 step:1290 [D loss: 0.507914, acc: 71.88%] [G loss: 2.329451]\n",
      "epoch:1 step:1291 [D loss: 0.459974, acc: 82.81%] [G loss: 2.363359]\n",
      "epoch:1 step:1292 [D loss: 0.520153, acc: 72.66%] [G loss: 2.314927]\n",
      "epoch:1 step:1293 [D loss: 0.448686, acc: 83.59%] [G loss: 2.656768]\n",
      "epoch:1 step:1294 [D loss: 0.528405, acc: 71.88%] [G loss: 1.906129]\n",
      "epoch:1 step:1295 [D loss: 0.472765, acc: 82.81%] [G loss: 1.976346]\n",
      "epoch:1 step:1296 [D loss: 0.527057, acc: 75.78%] [G loss: 1.828304]\n",
      "epoch:1 step:1297 [D loss: 0.385198, acc: 82.81%] [G loss: 1.631528]\n",
      "epoch:1 step:1298 [D loss: 0.705431, acc: 62.50%] [G loss: 1.816932]\n",
      "epoch:1 step:1299 [D loss: 0.366584, acc: 88.28%] [G loss: 2.362208]\n",
      "epoch:1 step:1300 [D loss: 0.275477, acc: 91.41%] [G loss: 2.558255]\n",
      "epoch:1 step:1301 [D loss: 0.717607, acc: 57.81%] [G loss: 1.647698]\n",
      "epoch:1 step:1302 [D loss: 0.393794, acc: 84.38%] [G loss: 2.030795]\n",
      "epoch:1 step:1303 [D loss: 0.619145, acc: 66.41%] [G loss: 1.490137]\n",
      "epoch:1 step:1304 [D loss: 0.245038, acc: 96.09%] [G loss: 1.932566]\n",
      "epoch:1 step:1305 [D loss: 1.345960, acc: 32.81%] [G loss: 1.199512]\n",
      "epoch:1 step:1306 [D loss: 0.673508, acc: 61.72%] [G loss: 2.261799]\n",
      "epoch:1 step:1307 [D loss: 0.806214, acc: 56.25%] [G loss: 1.119268]\n",
      "epoch:1 step:1308 [D loss: 0.974839, acc: 53.91%] [G loss: 2.092315]\n",
      "epoch:1 step:1309 [D loss: 0.540809, acc: 75.78%] [G loss: 2.042365]\n",
      "epoch:1 step:1310 [D loss: 0.595143, acc: 70.31%] [G loss: 2.095937]\n",
      "epoch:1 step:1311 [D loss: 0.526280, acc: 71.09%] [G loss: 2.248971]\n",
      "epoch:1 step:1312 [D loss: 0.341552, acc: 89.84%] [G loss: 2.255131]\n",
      "epoch:1 step:1313 [D loss: 0.578266, acc: 67.19%] [G loss: 2.052038]\n",
      "epoch:1 step:1314 [D loss: 0.566174, acc: 65.62%] [G loss: 2.413840]\n",
      "epoch:1 step:1315 [D loss: 0.423410, acc: 85.94%] [G loss: 1.812665]\n",
      "epoch:1 step:1316 [D loss: 0.541304, acc: 75.00%] [G loss: 2.301565]\n",
      "epoch:1 step:1317 [D loss: 0.529959, acc: 75.78%] [G loss: 2.161574]\n",
      "epoch:1 step:1318 [D loss: 0.879216, acc: 42.97%] [G loss: 1.852877]\n",
      "epoch:1 step:1319 [D loss: 0.244782, acc: 93.75%] [G loss: 2.324312]\n",
      "epoch:1 step:1320 [D loss: 0.363412, acc: 89.84%] [G loss: 2.404505]\n",
      "epoch:1 step:1321 [D loss: 0.595514, acc: 68.75%] [G loss: 2.344135]\n",
      "epoch:1 step:1322 [D loss: 0.438455, acc: 81.25%] [G loss: 2.569766]\n",
      "epoch:1 step:1323 [D loss: 0.457638, acc: 78.91%] [G loss: 2.791882]\n",
      "epoch:1 step:1324 [D loss: 0.301484, acc: 95.31%] [G loss: 2.812048]\n",
      "epoch:1 step:1325 [D loss: 0.344145, acc: 85.16%] [G loss: 2.558086]\n",
      "epoch:1 step:1326 [D loss: 0.182488, acc: 93.75%] [G loss: 2.669208]\n",
      "epoch:1 step:1327 [D loss: 0.596498, acc: 67.97%] [G loss: 2.414528]\n",
      "epoch:1 step:1328 [D loss: 0.572333, acc: 66.41%] [G loss: 2.831022]\n",
      "epoch:1 step:1329 [D loss: 0.711437, acc: 56.25%] [G loss: 2.179763]\n",
      "epoch:1 step:1330 [D loss: 0.876925, acc: 46.88%] [G loss: 2.272403]\n",
      "epoch:1 step:1331 [D loss: 0.504955, acc: 77.34%] [G loss: 2.848933]\n",
      "epoch:1 step:1332 [D loss: 0.530840, acc: 74.22%] [G loss: 2.414397]\n",
      "epoch:1 step:1333 [D loss: 1.035952, acc: 35.16%] [G loss: 2.078701]\n",
      "epoch:1 step:1334 [D loss: 0.949724, acc: 47.66%] [G loss: 1.583739]\n",
      "epoch:1 step:1335 [D loss: 0.706264, acc: 61.72%] [G loss: 2.390823]\n",
      "epoch:1 step:1336 [D loss: 0.941811, acc: 53.12%] [G loss: 2.361998]\n",
      "epoch:1 step:1337 [D loss: 0.717367, acc: 59.38%] [G loss: 2.260648]\n",
      "epoch:1 step:1338 [D loss: 0.679410, acc: 61.72%] [G loss: 1.875954]\n",
      "epoch:1 step:1339 [D loss: 0.332871, acc: 89.06%] [G loss: 2.131070]\n",
      "epoch:1 step:1340 [D loss: 0.567671, acc: 70.31%] [G loss: 2.257106]\n",
      "epoch:1 step:1341 [D loss: 0.256562, acc: 96.88%] [G loss: 2.370069]\n",
      "epoch:1 step:1342 [D loss: 0.558930, acc: 71.88%] [G loss: 2.686890]\n",
      "epoch:1 step:1343 [D loss: 0.382300, acc: 83.59%] [G loss: 2.633578]\n",
      "epoch:1 step:1344 [D loss: 0.868854, acc: 50.78%] [G loss: 1.870163]\n",
      "epoch:1 step:1345 [D loss: 0.225362, acc: 96.88%] [G loss: 2.787096]\n",
      "epoch:1 step:1346 [D loss: 0.372358, acc: 86.72%] [G loss: 2.320139]\n",
      "epoch:1 step:1347 [D loss: 0.202626, acc: 96.09%] [G loss: 2.445783]\n",
      "epoch:1 step:1348 [D loss: 0.237406, acc: 91.41%] [G loss: 3.172484]\n",
      "epoch:1 step:1349 [D loss: 0.263256, acc: 92.19%] [G loss: 2.213265]\n",
      "epoch:1 step:1350 [D loss: 0.612688, acc: 65.62%] [G loss: 2.030409]\n",
      "epoch:1 step:1351 [D loss: 1.067718, acc: 51.56%] [G loss: 1.879210]\n",
      "epoch:1 step:1352 [D loss: 0.447046, acc: 76.56%] [G loss: 2.368778]\n",
      "epoch:1 step:1353 [D loss: 0.333504, acc: 85.16%] [G loss: 2.871145]\n",
      "epoch:1 step:1354 [D loss: 0.288656, acc: 88.28%] [G loss: 2.679692]\n",
      "epoch:1 step:1355 [D loss: 0.469163, acc: 75.78%] [G loss: 1.980774]\n",
      "epoch:1 step:1356 [D loss: 1.131214, acc: 31.25%] [G loss: 1.869534]\n",
      "epoch:1 step:1357 [D loss: 0.397166, acc: 86.72%] [G loss: 1.997506]\n",
      "epoch:1 step:1358 [D loss: 1.021296, acc: 40.62%] [G loss: 1.723145]\n",
      "epoch:1 step:1359 [D loss: 0.436561, acc: 78.12%] [G loss: 2.149692]\n",
      "epoch:1 step:1360 [D loss: 0.583489, acc: 71.09%] [G loss: 2.113666]\n",
      "epoch:1 step:1361 [D loss: 0.644494, acc: 62.50%] [G loss: 1.997784]\n",
      "epoch:1 step:1362 [D loss: 1.436549, acc: 19.53%] [G loss: 2.486822]\n",
      "epoch:1 step:1363 [D loss: 0.691646, acc: 62.50%] [G loss: 2.384684]\n",
      "epoch:1 step:1364 [D loss: 0.516224, acc: 72.66%] [G loss: 2.445013]\n",
      "epoch:1 step:1365 [D loss: 0.212487, acc: 94.53%] [G loss: 3.261053]\n",
      "epoch:1 step:1366 [D loss: 0.545912, acc: 77.34%] [G loss: 2.138723]\n",
      "epoch:1 step:1367 [D loss: 0.450036, acc: 83.59%] [G loss: 2.052480]\n",
      "epoch:1 step:1368 [D loss: 0.408907, acc: 86.72%] [G loss: 2.166425]\n",
      "epoch:1 step:1369 [D loss: 0.474137, acc: 84.38%] [G loss: 2.252708]\n",
      "epoch:1 step:1370 [D loss: 0.347651, acc: 91.41%] [G loss: 2.097407]\n",
      "epoch:1 step:1371 [D loss: 0.221185, acc: 97.66%] [G loss: 2.797531]\n",
      "epoch:1 step:1372 [D loss: 0.687382, acc: 57.03%] [G loss: 1.888373]\n",
      "epoch:1 step:1373 [D loss: 0.345937, acc: 88.28%] [G loss: 2.203153]\n",
      "epoch:1 step:1374 [D loss: 0.512899, acc: 74.22%] [G loss: 1.640529]\n",
      "epoch:1 step:1375 [D loss: 0.359479, acc: 86.72%] [G loss: 2.381434]\n",
      "epoch:1 step:1376 [D loss: 0.221752, acc: 95.31%] [G loss: 2.578205]\n",
      "epoch:1 step:1377 [D loss: 0.414924, acc: 78.91%] [G loss: 3.230017]\n",
      "epoch:1 step:1378 [D loss: 0.624281, acc: 61.72%] [G loss: 1.918489]\n",
      "epoch:1 step:1379 [D loss: 0.220325, acc: 96.09%] [G loss: 3.001693]\n",
      "epoch:1 step:1380 [D loss: 0.245206, acc: 95.31%] [G loss: 2.192621]\n",
      "epoch:1 step:1381 [D loss: 0.198358, acc: 96.88%] [G loss: 2.559873]\n",
      "epoch:1 step:1382 [D loss: 0.363686, acc: 82.03%] [G loss: 1.895689]\n",
      "epoch:1 step:1383 [D loss: 0.480547, acc: 84.38%] [G loss: 1.845575]\n",
      "epoch:1 step:1384 [D loss: 0.250321, acc: 92.19%] [G loss: 2.450940]\n",
      "epoch:1 step:1385 [D loss: 0.493750, acc: 77.34%] [G loss: 2.075867]\n",
      "epoch:1 step:1386 [D loss: 0.599029, acc: 71.09%] [G loss: 1.689435]\n",
      "epoch:1 step:1387 [D loss: 0.662629, acc: 57.81%] [G loss: 1.995229]\n",
      "epoch:1 step:1388 [D loss: 0.440864, acc: 76.56%] [G loss: 1.798388]\n",
      "epoch:1 step:1389 [D loss: 0.215458, acc: 98.44%] [G loss: 2.458354]\n",
      "epoch:1 step:1390 [D loss: 0.768376, acc: 51.56%] [G loss: 2.220212]\n",
      "epoch:1 step:1391 [D loss: 0.516628, acc: 70.31%] [G loss: 2.412716]\n",
      "epoch:1 step:1392 [D loss: 0.522114, acc: 70.31%] [G loss: 2.091342]\n",
      "epoch:1 step:1393 [D loss: 0.852997, acc: 43.75%] [G loss: 2.149626]\n",
      "epoch:1 step:1394 [D loss: 0.851447, acc: 56.25%] [G loss: 1.887482]\n",
      "epoch:1 step:1395 [D loss: 0.610436, acc: 64.06%] [G loss: 2.840222]\n",
      "epoch:1 step:1396 [D loss: 0.279969, acc: 93.75%] [G loss: 2.938428]\n",
      "epoch:1 step:1397 [D loss: 0.197428, acc: 97.66%] [G loss: 3.392885]\n",
      "epoch:1 step:1398 [D loss: 0.393040, acc: 81.25%] [G loss: 2.825811]\n",
      "epoch:1 step:1399 [D loss: 0.462555, acc: 81.25%] [G loss: 2.373622]\n",
      "epoch:1 step:1400 [D loss: 0.205659, acc: 96.09%] [G loss: 2.715640]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##############\n",
      "[0.85747663 0.8995241  0.79474288 0.8099075  0.81312539 0.82862996\n",
      " 0.88963129 0.83884004 0.8309361  0.80344967]\n",
      "##########\n",
      "epoch:1 step:1401 [D loss: 0.238602, acc: 93.75%] [G loss: 2.546255]\n",
      "epoch:1 step:1402 [D loss: 0.258116, acc: 95.31%] [G loss: 3.174316]\n",
      "epoch:1 step:1403 [D loss: 0.762646, acc: 60.16%] [G loss: 2.657952]\n",
      "epoch:1 step:1404 [D loss: 0.556938, acc: 71.88%] [G loss: 2.076318]\n",
      "epoch:1 step:1405 [D loss: 0.116331, acc: 98.44%] [G loss: 2.998078]\n",
      "epoch:1 step:1406 [D loss: 0.305866, acc: 87.50%] [G loss: 2.394745]\n",
      "epoch:1 step:1407 [D loss: 0.232232, acc: 90.62%] [G loss: 2.831873]\n",
      "epoch:1 step:1408 [D loss: 0.392763, acc: 80.47%] [G loss: 2.253925]\n",
      "epoch:1 step:1409 [D loss: 0.262985, acc: 90.62%] [G loss: 2.376355]\n",
      "epoch:1 step:1410 [D loss: 0.193358, acc: 96.09%] [G loss: 2.924474]\n",
      "epoch:1 step:1411 [D loss: 1.103061, acc: 55.47%] [G loss: 2.288801]\n",
      "epoch:1 step:1412 [D loss: 0.229287, acc: 92.19%] [G loss: 2.301945]\n",
      "epoch:1 step:1413 [D loss: 0.520867, acc: 70.31%] [G loss: 2.654876]\n",
      "epoch:1 step:1414 [D loss: 1.125721, acc: 51.56%] [G loss: 3.158072]\n",
      "epoch:1 step:1415 [D loss: 0.168019, acc: 97.66%] [G loss: 2.108085]\n",
      "epoch:1 step:1416 [D loss: 0.524508, acc: 69.53%] [G loss: 2.541560]\n",
      "epoch:1 step:1417 [D loss: 0.901751, acc: 56.25%] [G loss: 1.957207]\n",
      "epoch:1 step:1418 [D loss: 0.577095, acc: 67.97%] [G loss: 2.731288]\n",
      "epoch:1 step:1419 [D loss: 0.484834, acc: 70.31%] [G loss: 1.953876]\n",
      "epoch:1 step:1420 [D loss: 0.295336, acc: 87.50%] [G loss: 2.365966]\n",
      "epoch:1 step:1421 [D loss: 0.821331, acc: 54.69%] [G loss: 2.057430]\n",
      "epoch:1 step:1422 [D loss: 0.167465, acc: 96.09%] [G loss: 2.405885]\n",
      "epoch:1 step:1423 [D loss: 0.335269, acc: 91.41%] [G loss: 2.137384]\n",
      "epoch:1 step:1424 [D loss: 0.531451, acc: 75.78%] [G loss: 2.432640]\n",
      "epoch:1 step:1425 [D loss: 0.389036, acc: 84.38%] [G loss: 2.761987]\n",
      "epoch:1 step:1426 [D loss: 1.266512, acc: 48.44%] [G loss: 1.797852]\n",
      "epoch:1 step:1427 [D loss: 0.197924, acc: 97.66%] [G loss: 2.645341]\n",
      "epoch:1 step:1428 [D loss: 0.394298, acc: 81.25%] [G loss: 2.340384]\n",
      "epoch:1 step:1429 [D loss: 0.499061, acc: 81.25%] [G loss: 2.975081]\n",
      "epoch:1 step:1430 [D loss: 0.218230, acc: 92.19%] [G loss: 2.467302]\n",
      "epoch:1 step:1431 [D loss: 0.630187, acc: 63.28%] [G loss: 2.438966]\n",
      "epoch:1 step:1432 [D loss: 0.225066, acc: 93.75%] [G loss: 2.652344]\n",
      "epoch:1 step:1433 [D loss: 0.371694, acc: 89.06%] [G loss: 2.008235]\n",
      "epoch:1 step:1434 [D loss: 0.502980, acc: 78.91%] [G loss: 2.127871]\n",
      "epoch:1 step:1435 [D loss: 0.302397, acc: 89.06%] [G loss: 2.288440]\n",
      "epoch:1 step:1436 [D loss: 0.700082, acc: 57.03%] [G loss: 2.284511]\n",
      "epoch:1 step:1437 [D loss: 0.841178, acc: 53.91%] [G loss: 1.929026]\n",
      "epoch:1 step:1438 [D loss: 0.205609, acc: 95.31%] [G loss: 2.913492]\n",
      "epoch:1 step:1439 [D loss: 0.486299, acc: 75.00%] [G loss: 2.237387]\n",
      "epoch:1 step:1440 [D loss: 0.318001, acc: 91.41%] [G loss: 2.212985]\n",
      "epoch:1 step:1441 [D loss: 0.158337, acc: 97.66%] [G loss: 2.807157]\n",
      "epoch:1 step:1442 [D loss: 0.307185, acc: 92.97%] [G loss: 2.374706]\n",
      "epoch:1 step:1443 [D loss: 0.721105, acc: 59.38%] [G loss: 1.756461]\n",
      "epoch:1 step:1444 [D loss: 0.324460, acc: 91.41%] [G loss: 2.242688]\n",
      "epoch:1 step:1445 [D loss: 0.596005, acc: 69.53%] [G loss: 1.961230]\n",
      "epoch:1 step:1446 [D loss: 1.210178, acc: 40.62%] [G loss: 1.074384]\n",
      "epoch:1 step:1447 [D loss: 0.223214, acc: 93.75%] [G loss: 1.886845]\n",
      "epoch:1 step:1448 [D loss: 0.468446, acc: 83.59%] [G loss: 2.342039]\n",
      "epoch:1 step:1449 [D loss: 0.885067, acc: 42.19%] [G loss: 1.429799]\n",
      "epoch:1 step:1450 [D loss: 0.384177, acc: 88.28%] [G loss: 1.556023]\n",
      "epoch:1 step:1451 [D loss: 1.217477, acc: 43.75%] [G loss: 1.572983]\n",
      "epoch:1 step:1452 [D loss: 0.596269, acc: 66.41%] [G loss: 2.297971]\n",
      "epoch:1 step:1453 [D loss: 0.947057, acc: 53.91%] [G loss: 2.831493]\n",
      "epoch:1 step:1454 [D loss: 0.824359, acc: 53.12%] [G loss: 2.334511]\n",
      "epoch:1 step:1455 [D loss: 0.923720, acc: 49.22%] [G loss: 1.574461]\n",
      "epoch:1 step:1456 [D loss: 0.883149, acc: 41.41%] [G loss: 1.567419]\n",
      "epoch:1 step:1457 [D loss: 1.612955, acc: 10.16%] [G loss: 1.744356]\n",
      "epoch:1 step:1458 [D loss: 0.496259, acc: 73.44%] [G loss: 1.897027]\n",
      "epoch:1 step:1459 [D loss: 0.533737, acc: 68.75%] [G loss: 2.156887]\n",
      "epoch:1 step:1460 [D loss: 0.328614, acc: 90.62%] [G loss: 2.647554]\n",
      "epoch:1 step:1461 [D loss: 0.757035, acc: 56.25%] [G loss: 2.175889]\n",
      "epoch:1 step:1462 [D loss: 0.310354, acc: 92.19%] [G loss: 2.551639]\n",
      "epoch:1 step:1463 [D loss: 0.780010, acc: 48.44%] [G loss: 2.410834]\n",
      "epoch:1 step:1464 [D loss: 0.644430, acc: 66.41%] [G loss: 2.319964]\n",
      "epoch:1 step:1465 [D loss: 0.530240, acc: 73.44%] [G loss: 2.436103]\n",
      "epoch:1 step:1466 [D loss: 0.594268, acc: 72.66%] [G loss: 2.670482]\n",
      "epoch:1 step:1467 [D loss: 0.457970, acc: 80.47%] [G loss: 2.875773]\n",
      "epoch:1 step:1468 [D loss: 0.467671, acc: 81.25%] [G loss: 2.690073]\n",
      "epoch:1 step:1469 [D loss: 0.578363, acc: 73.44%] [G loss: 2.665367]\n",
      "epoch:1 step:1470 [D loss: 0.346462, acc: 85.16%] [G loss: 2.995118]\n",
      "epoch:1 step:1471 [D loss: 0.351328, acc: 87.50%] [G loss: 2.966977]\n",
      "epoch:1 step:1472 [D loss: 0.418933, acc: 83.59%] [G loss: 2.485857]\n",
      "epoch:1 step:1473 [D loss: 0.540069, acc: 67.19%] [G loss: 3.291500]\n",
      "epoch:1 step:1474 [D loss: 0.512976, acc: 73.44%] [G loss: 2.567803]\n",
      "epoch:1 step:1475 [D loss: 0.226411, acc: 95.31%] [G loss: 3.058144]\n",
      "epoch:1 step:1476 [D loss: 0.413414, acc: 82.81%] [G loss: 2.558486]\n",
      "epoch:1 step:1477 [D loss: 0.500648, acc: 77.34%] [G loss: 2.546907]\n",
      "epoch:1 step:1478 [D loss: 0.495454, acc: 77.34%] [G loss: 2.779171]\n",
      "epoch:1 step:1479 [D loss: 0.461466, acc: 78.91%] [G loss: 3.066035]\n",
      "epoch:1 step:1480 [D loss: 0.866347, acc: 49.22%] [G loss: 2.660382]\n",
      "epoch:1 step:1481 [D loss: 0.203799, acc: 92.97%] [G loss: 3.568922]\n",
      "epoch:1 step:1482 [D loss: 0.519705, acc: 75.00%] [G loss: 2.604143]\n",
      "epoch:1 step:1483 [D loss: 0.218681, acc: 93.75%] [G loss: 3.468160]\n",
      "epoch:1 step:1484 [D loss: 0.417493, acc: 78.12%] [G loss: 3.324621]\n",
      "epoch:1 step:1485 [D loss: 0.343246, acc: 89.06%] [G loss: 3.368568]\n",
      "epoch:1 step:1486 [D loss: 0.405189, acc: 80.47%] [G loss: 3.379809]\n",
      "epoch:1 step:1487 [D loss: 0.974072, acc: 39.06%] [G loss: 2.425909]\n",
      "epoch:1 step:1488 [D loss: 0.585793, acc: 66.41%] [G loss: 2.783262]\n",
      "epoch:1 step:1489 [D loss: 0.307814, acc: 88.28%] [G loss: 3.471026]\n",
      "epoch:1 step:1490 [D loss: 0.789956, acc: 51.56%] [G loss: 2.352379]\n",
      "epoch:1 step:1491 [D loss: 0.463673, acc: 78.12%] [G loss: 3.080364]\n",
      "epoch:1 step:1492 [D loss: 0.555845, acc: 66.41%] [G loss: 2.717498]\n",
      "epoch:1 step:1493 [D loss: 0.255234, acc: 91.41%] [G loss: 2.699334]\n",
      "epoch:1 step:1494 [D loss: 0.670536, acc: 63.28%] [G loss: 1.799670]\n",
      "epoch:1 step:1495 [D loss: 0.239382, acc: 95.31%] [G loss: 2.467720]\n",
      "epoch:1 step:1496 [D loss: 1.655931, acc: 25.00%] [G loss: 1.444693]\n",
      "epoch:1 step:1497 [D loss: 0.644261, acc: 61.72%] [G loss: 1.924436]\n",
      "epoch:1 step:1498 [D loss: 0.629191, acc: 64.06%] [G loss: 1.974936]\n",
      "epoch:1 step:1499 [D loss: 0.646970, acc: 65.62%] [G loss: 2.168276]\n",
      "epoch:1 step:1500 [D loss: 0.338779, acc: 88.28%] [G loss: 2.359323]\n",
      "epoch:1 step:1501 [D loss: 0.382208, acc: 89.84%] [G loss: 1.876380]\n",
      "epoch:1 step:1502 [D loss: 0.382754, acc: 81.25%] [G loss: 2.006772]\n",
      "epoch:1 step:1503 [D loss: 1.215233, acc: 18.75%] [G loss: 1.515442]\n",
      "epoch:1 step:1504 [D loss: 0.843476, acc: 48.44%] [G loss: 1.807369]\n",
      "epoch:1 step:1505 [D loss: 0.779928, acc: 53.91%] [G loss: 2.229741]\n",
      "epoch:1 step:1506 [D loss: 0.825303, acc: 54.69%] [G loss: 2.050488]\n",
      "epoch:1 step:1507 [D loss: 0.998106, acc: 35.16%] [G loss: 1.972563]\n",
      "epoch:1 step:1508 [D loss: 0.500563, acc: 75.00%] [G loss: 2.390030]\n",
      "epoch:1 step:1509 [D loss: 0.535250, acc: 73.44%] [G loss: 2.482197]\n",
      "epoch:1 step:1510 [D loss: 0.737598, acc: 53.12%] [G loss: 1.998087]\n",
      "epoch:1 step:1511 [D loss: 0.786922, acc: 53.12%] [G loss: 2.120913]\n",
      "epoch:1 step:1512 [D loss: 0.218999, acc: 97.66%] [G loss: 2.607622]\n",
      "epoch:1 step:1513 [D loss: 0.560193, acc: 70.31%] [G loss: 2.156224]\n",
      "epoch:1 step:1514 [D loss: 0.544165, acc: 68.75%] [G loss: 2.486745]\n",
      "epoch:1 step:1515 [D loss: 0.361801, acc: 83.59%] [G loss: 2.380895]\n",
      "epoch:1 step:1516 [D loss: 0.423450, acc: 83.59%] [G loss: 2.940873]\n",
      "epoch:1 step:1517 [D loss: 0.439600, acc: 83.59%] [G loss: 2.508119]\n",
      "epoch:1 step:1518 [D loss: 0.376689, acc: 78.91%] [G loss: 2.474669]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1 step:1519 [D loss: 0.713882, acc: 60.94%] [G loss: 2.753314]\n",
      "epoch:1 step:1520 [D loss: 0.476927, acc: 82.03%] [G loss: 3.074230]\n",
      "epoch:1 step:1521 [D loss: 0.883316, acc: 48.44%] [G loss: 2.451227]\n",
      "epoch:1 step:1522 [D loss: 0.342405, acc: 89.06%] [G loss: 3.354820]\n",
      "epoch:1 step:1523 [D loss: 0.748660, acc: 57.81%] [G loss: 2.850020]\n",
      "epoch:1 step:1524 [D loss: 0.457203, acc: 78.91%] [G loss: 2.603611]\n",
      "epoch:1 step:1525 [D loss: 0.451112, acc: 85.94%] [G loss: 2.780134]\n",
      "epoch:1 step:1526 [D loss: 0.426684, acc: 83.59%] [G loss: 2.378867]\n",
      "epoch:1 step:1527 [D loss: 0.363748, acc: 84.38%] [G loss: 2.936194]\n",
      "epoch:1 step:1528 [D loss: 0.438906, acc: 81.25%] [G loss: 2.304500]\n",
      "epoch:1 step:1529 [D loss: 0.372858, acc: 82.03%] [G loss: 2.703033]\n",
      "epoch:1 step:1530 [D loss: 0.641457, acc: 66.41%] [G loss: 2.114856]\n",
      "epoch:1 step:1531 [D loss: 0.458305, acc: 75.00%] [G loss: 2.197732]\n",
      "epoch:1 step:1532 [D loss: 0.688096, acc: 58.59%] [G loss: 2.260401]\n",
      "epoch:1 step:1533 [D loss: 0.526393, acc: 67.97%] [G loss: 2.440895]\n",
      "epoch:1 step:1534 [D loss: 0.148347, acc: 100.00%] [G loss: 2.658452]\n",
      "epoch:1 step:1535 [D loss: 0.144696, acc: 98.44%] [G loss: 2.813658]\n",
      "epoch:1 step:1536 [D loss: 0.195943, acc: 97.66%] [G loss: 2.548913]\n",
      "epoch:1 step:1537 [D loss: 0.441629, acc: 85.94%] [G loss: 1.804222]\n",
      "epoch:1 step:1538 [D loss: 0.444550, acc: 79.69%] [G loss: 1.626345]\n",
      "epoch:1 step:1539 [D loss: 0.649814, acc: 63.28%] [G loss: 2.277670]\n",
      "epoch:1 step:1540 [D loss: 0.691675, acc: 66.41%] [G loss: 1.977560]\n",
      "epoch:1 step:1541 [D loss: 1.229512, acc: 40.62%] [G loss: 2.198005]\n",
      "epoch:1 step:1542 [D loss: 0.313707, acc: 92.19%] [G loss: 2.454580]\n",
      "epoch:1 step:1543 [D loss: 0.495157, acc: 69.53%] [G loss: 2.225446]\n",
      "epoch:1 step:1544 [D loss: 0.249223, acc: 92.97%] [G loss: 2.540664]\n",
      "epoch:1 step:1545 [D loss: 0.796905, acc: 59.38%] [G loss: 2.445264]\n",
      "epoch:1 step:1546 [D loss: 0.302497, acc: 89.06%] [G loss: 2.497035]\n",
      "epoch:1 step:1547 [D loss: 0.446747, acc: 81.25%] [G loss: 2.056557]\n",
      "epoch:1 step:1548 [D loss: 1.390931, acc: 16.41%] [G loss: 2.073277]\n",
      "epoch:1 step:1549 [D loss: 0.473834, acc: 78.91%] [G loss: 2.581335]\n",
      "epoch:1 step:1550 [D loss: 1.711627, acc: 21.09%] [G loss: 2.713939]\n",
      "epoch:1 step:1551 [D loss: 0.584242, acc: 67.97%] [G loss: 3.470597]\n",
      "epoch:1 step:1552 [D loss: 0.883320, acc: 38.28%] [G loss: 3.153629]\n",
      "epoch:1 step:1553 [D loss: 0.558651, acc: 71.88%] [G loss: 2.898448]\n",
      "epoch:1 step:1554 [D loss: 0.428806, acc: 82.81%] [G loss: 3.309884]\n",
      "epoch:1 step:1555 [D loss: 0.677175, acc: 60.94%] [G loss: 3.376977]\n",
      "epoch:1 step:1556 [D loss: 0.402026, acc: 82.81%] [G loss: 2.999826]\n",
      "epoch:1 step:1557 [D loss: 0.396871, acc: 84.38%] [G loss: 3.081534]\n",
      "epoch:1 step:1558 [D loss: 0.419370, acc: 81.25%] [G loss: 3.226953]\n",
      "epoch:1 step:1559 [D loss: 0.254215, acc: 92.19%] [G loss: 2.557776]\n",
      "epoch:1 step:1560 [D loss: 0.234810, acc: 95.31%] [G loss: 3.014740]\n",
      "epoch:1 step:1561 [D loss: 0.429837, acc: 80.47%] [G loss: 3.020563]\n",
      "epoch:1 step:1562 [D loss: 0.222726, acc: 96.09%] [G loss: 2.670431]\n",
      "epoch:2 step:1563 [D loss: 0.633196, acc: 61.72%] [G loss: 1.838844]\n",
      "epoch:2 step:1564 [D loss: 0.377378, acc: 83.59%] [G loss: 2.864596]\n",
      "epoch:2 step:1565 [D loss: 0.250153, acc: 86.72%] [G loss: 2.610456]\n",
      "epoch:2 step:1566 [D loss: 0.199827, acc: 96.88%] [G loss: 2.946674]\n",
      "epoch:2 step:1567 [D loss: 0.244759, acc: 94.53%] [G loss: 3.082808]\n",
      "epoch:2 step:1568 [D loss: 0.459078, acc: 77.34%] [G loss: 2.732990]\n",
      "epoch:2 step:1569 [D loss: 0.391218, acc: 81.25%] [G loss: 2.349378]\n",
      "epoch:2 step:1570 [D loss: 0.623339, acc: 66.41%] [G loss: 2.098529]\n",
      "epoch:2 step:1571 [D loss: 0.231665, acc: 94.53%] [G loss: 2.869921]\n",
      "epoch:2 step:1572 [D loss: 0.634994, acc: 69.53%] [G loss: 2.072695]\n",
      "epoch:2 step:1573 [D loss: 0.428994, acc: 80.47%] [G loss: 2.311928]\n",
      "epoch:2 step:1574 [D loss: 0.215599, acc: 97.66%] [G loss: 3.195498]\n",
      "epoch:2 step:1575 [D loss: 0.746062, acc: 57.03%] [G loss: 1.880907]\n",
      "epoch:2 step:1576 [D loss: 0.410992, acc: 81.25%] [G loss: 2.146316]\n",
      "epoch:2 step:1577 [D loss: 1.679393, acc: 8.59%] [G loss: 2.017290]\n",
      "epoch:2 step:1578 [D loss: 0.189206, acc: 97.66%] [G loss: 3.167388]\n",
      "epoch:2 step:1579 [D loss: 0.339509, acc: 88.28%] [G loss: 3.252320]\n",
      "epoch:2 step:1580 [D loss: 0.629359, acc: 65.62%] [G loss: 2.621702]\n",
      "epoch:2 step:1581 [D loss: 0.470217, acc: 77.34%] [G loss: 2.561368]\n",
      "epoch:2 step:1582 [D loss: 0.451310, acc: 78.91%] [G loss: 2.665603]\n",
      "epoch:2 step:1583 [D loss: 0.474374, acc: 79.69%] [G loss: 2.422643]\n",
      "epoch:2 step:1584 [D loss: 0.494172, acc: 67.97%] [G loss: 2.398057]\n",
      "epoch:2 step:1585 [D loss: 0.667722, acc: 62.50%] [G loss: 2.399076]\n",
      "epoch:2 step:1586 [D loss: 0.389310, acc: 86.72%] [G loss: 2.344430]\n",
      "epoch:2 step:1587 [D loss: 0.384851, acc: 82.81%] [G loss: 2.479847]\n",
      "epoch:2 step:1588 [D loss: 0.334451, acc: 89.06%] [G loss: 2.246239]\n",
      "epoch:2 step:1589 [D loss: 0.596560, acc: 64.06%] [G loss: 1.930215]\n",
      "epoch:2 step:1590 [D loss: 0.614883, acc: 61.72%] [G loss: 2.335860]\n",
      "epoch:2 step:1591 [D loss: 0.544642, acc: 73.44%] [G loss: 2.593915]\n",
      "epoch:2 step:1592 [D loss: 0.475642, acc: 78.12%] [G loss: 2.400796]\n",
      "epoch:2 step:1593 [D loss: 0.450004, acc: 82.03%] [G loss: 2.326056]\n",
      "epoch:2 step:1594 [D loss: 0.219374, acc: 93.75%] [G loss: 3.123675]\n",
      "epoch:2 step:1595 [D loss: 0.681061, acc: 59.38%] [G loss: 2.298643]\n",
      "epoch:2 step:1596 [D loss: 0.255069, acc: 91.41%] [G loss: 2.295508]\n",
      "epoch:2 step:1597 [D loss: 0.130806, acc: 97.66%] [G loss: 3.064784]\n",
      "epoch:2 step:1598 [D loss: 0.611138, acc: 65.62%] [G loss: 2.625219]\n",
      "epoch:2 step:1599 [D loss: 0.370123, acc: 89.06%] [G loss: 1.941270]\n",
      "epoch:2 step:1600 [D loss: 0.776235, acc: 56.25%] [G loss: 1.797259]\n",
      "##############\n",
      "[0.85726015 0.88444887 0.82418972 0.78090648 0.79886757 0.83787004\n",
      " 0.87834504 0.83478025 0.80715631 0.8323544 ]\n",
      "##########\n",
      "epoch:2 step:1601 [D loss: 0.578145, acc: 64.84%] [G loss: 1.997666]\n",
      "epoch:2 step:1602 [D loss: 0.394670, acc: 86.72%] [G loss: 1.808680]\n",
      "epoch:2 step:1603 [D loss: 0.740328, acc: 51.56%] [G loss: 1.464566]\n",
      "epoch:2 step:1604 [D loss: 0.957467, acc: 37.50%] [G loss: 1.372682]\n",
      "epoch:2 step:1605 [D loss: 0.905175, acc: 43.75%] [G loss: 1.509918]\n",
      "epoch:2 step:1606 [D loss: 0.437709, acc: 79.69%] [G loss: 2.314107]\n",
      "epoch:2 step:1607 [D loss: 0.964890, acc: 50.78%] [G loss: 2.468761]\n",
      "epoch:2 step:1608 [D loss: 1.339016, acc: 12.50%] [G loss: 1.863122]\n",
      "epoch:2 step:1609 [D loss: 0.669200, acc: 57.03%] [G loss: 2.496451]\n",
      "epoch:2 step:1610 [D loss: 0.497636, acc: 81.25%] [G loss: 2.537034]\n",
      "epoch:2 step:1611 [D loss: 1.382531, acc: 23.44%] [G loss: 2.325172]\n",
      "epoch:2 step:1612 [D loss: 0.587135, acc: 71.09%] [G loss: 2.329968]\n",
      "epoch:2 step:1613 [D loss: 0.548366, acc: 67.97%] [G loss: 2.987757]\n",
      "epoch:2 step:1614 [D loss: 0.380280, acc: 87.50%] [G loss: 3.044322]\n",
      "epoch:2 step:1615 [D loss: 0.537451, acc: 75.00%] [G loss: 2.910891]\n",
      "epoch:2 step:1616 [D loss: 0.500450, acc: 78.12%] [G loss: 2.492513]\n",
      "epoch:2 step:1617 [D loss: 0.403892, acc: 83.59%] [G loss: 2.545905]\n",
      "epoch:2 step:1618 [D loss: 0.812261, acc: 51.56%] [G loss: 1.786650]\n",
      "epoch:2 step:1619 [D loss: 0.736332, acc: 59.38%] [G loss: 2.350943]\n",
      "epoch:2 step:1620 [D loss: 0.295119, acc: 89.84%] [G loss: 2.157794]\n",
      "epoch:2 step:1621 [D loss: 0.908483, acc: 49.22%] [G loss: 2.424419]\n",
      "epoch:2 step:1622 [D loss: 0.685819, acc: 58.59%] [G loss: 2.626053]\n",
      "epoch:2 step:1623 [D loss: 0.528672, acc: 77.34%] [G loss: 2.250960]\n",
      "epoch:2 step:1624 [D loss: 0.507404, acc: 77.34%] [G loss: 2.151462]\n",
      "epoch:2 step:1625 [D loss: 0.745527, acc: 56.25%] [G loss: 2.160255]\n",
      "epoch:2 step:1626 [D loss: 1.277383, acc: 27.34%] [G loss: 1.935431]\n",
      "epoch:2 step:1627 [D loss: 1.139701, acc: 28.12%] [G loss: 1.499552]\n",
      "epoch:2 step:1628 [D loss: 0.447318, acc: 85.94%] [G loss: 2.030978]\n",
      "epoch:2 step:1629 [D loss: 0.959023, acc: 29.69%] [G loss: 1.757000]\n",
      "epoch:2 step:1630 [D loss: 0.666190, acc: 64.06%] [G loss: 1.948949]\n",
      "epoch:2 step:1631 [D loss: 0.518952, acc: 76.56%] [G loss: 2.147463]\n",
      "epoch:2 step:1632 [D loss: 0.534824, acc: 71.09%] [G loss: 1.952152]\n",
      "epoch:2 step:1633 [D loss: 1.320509, acc: 21.88%] [G loss: 2.126406]\n",
      "epoch:2 step:1634 [D loss: 0.615471, acc: 68.75%] [G loss: 1.959219]\n",
      "epoch:2 step:1635 [D loss: 0.582564, acc: 62.50%] [G loss: 2.305201]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:2 step:1636 [D loss: 0.398933, acc: 87.50%] [G loss: 2.254148]\n",
      "epoch:2 step:1637 [D loss: 0.434814, acc: 80.47%] [G loss: 2.274929]\n",
      "epoch:2 step:1638 [D loss: 0.222946, acc: 94.53%] [G loss: 2.580235]\n",
      "epoch:2 step:1639 [D loss: 0.577487, acc: 66.41%] [G loss: 2.834834]\n",
      "epoch:2 step:1640 [D loss: 0.517460, acc: 77.34%] [G loss: 2.649693]\n",
      "epoch:2 step:1641 [D loss: 0.282720, acc: 89.06%] [G loss: 3.101592]\n",
      "epoch:2 step:1642 [D loss: 0.311718, acc: 92.97%] [G loss: 2.904126]\n",
      "epoch:2 step:1643 [D loss: 0.604249, acc: 70.31%] [G loss: 2.252941]\n",
      "epoch:2 step:1644 [D loss: 0.213837, acc: 94.53%] [G loss: 2.507355]\n",
      "epoch:2 step:1645 [D loss: 0.646457, acc: 65.62%] [G loss: 2.219676]\n",
      "epoch:2 step:1646 [D loss: 1.212667, acc: 18.75%] [G loss: 1.948135]\n",
      "epoch:2 step:1647 [D loss: 0.464039, acc: 78.91%] [G loss: 2.256140]\n",
      "epoch:2 step:1648 [D loss: 0.637192, acc: 62.50%] [G loss: 2.188445]\n",
      "epoch:2 step:1649 [D loss: 0.508563, acc: 71.09%] [G loss: 2.431458]\n",
      "epoch:2 step:1650 [D loss: 0.727419, acc: 55.47%] [G loss: 1.884536]\n",
      "epoch:2 step:1651 [D loss: 0.528025, acc: 76.56%] [G loss: 2.325043]\n",
      "epoch:2 step:1652 [D loss: 0.537994, acc: 71.88%] [G loss: 1.795302]\n",
      "epoch:2 step:1653 [D loss: 0.885449, acc: 39.06%] [G loss: 1.972695]\n",
      "epoch:2 step:1654 [D loss: 0.802988, acc: 46.09%] [G loss: 1.587047]\n",
      "epoch:2 step:1655 [D loss: 0.711473, acc: 53.12%] [G loss: 1.829464]\n",
      "epoch:2 step:1656 [D loss: 0.589341, acc: 67.19%] [G loss: 2.189709]\n",
      "epoch:2 step:1657 [D loss: 0.754018, acc: 50.78%] [G loss: 2.205009]\n",
      "epoch:2 step:1658 [D loss: 0.837056, acc: 49.22%] [G loss: 1.791809]\n",
      "epoch:2 step:1659 [D loss: 0.782779, acc: 50.78%] [G loss: 1.901237]\n",
      "epoch:2 step:1660 [D loss: 0.955027, acc: 46.88%] [G loss: 1.828028]\n",
      "epoch:2 step:1661 [D loss: 0.894902, acc: 38.28%] [G loss: 2.083610]\n",
      "epoch:2 step:1662 [D loss: 0.638063, acc: 60.94%] [G loss: 2.231074]\n",
      "epoch:2 step:1663 [D loss: 0.732740, acc: 54.69%] [G loss: 1.696523]\n",
      "epoch:2 step:1664 [D loss: 0.479673, acc: 80.47%] [G loss: 2.223273]\n",
      "epoch:2 step:1665 [D loss: 0.663122, acc: 61.72%] [G loss: 2.087635]\n",
      "epoch:2 step:1666 [D loss: 0.526204, acc: 73.44%] [G loss: 2.444336]\n",
      "epoch:2 step:1667 [D loss: 0.597743, acc: 67.19%] [G loss: 2.339838]\n",
      "epoch:2 step:1668 [D loss: 0.523126, acc: 74.22%] [G loss: 2.319150]\n",
      "epoch:2 step:1669 [D loss: 0.698135, acc: 58.59%] [G loss: 1.713920]\n",
      "epoch:2 step:1670 [D loss: 0.506164, acc: 73.44%] [G loss: 2.130735]\n",
      "epoch:2 step:1671 [D loss: 0.855585, acc: 49.22%] [G loss: 1.635380]\n",
      "epoch:2 step:1672 [D loss: 0.275885, acc: 96.09%] [G loss: 2.741668]\n",
      "epoch:2 step:1673 [D loss: 0.978391, acc: 35.16%] [G loss: 1.731560]\n",
      "epoch:2 step:1674 [D loss: 0.506237, acc: 75.78%] [G loss: 2.023692]\n",
      "epoch:2 step:1675 [D loss: 0.502497, acc: 80.47%] [G loss: 1.856512]\n",
      "epoch:2 step:1676 [D loss: 0.922475, acc: 37.50%] [G loss: 1.692910]\n",
      "epoch:2 step:1677 [D loss: 0.434066, acc: 81.25%] [G loss: 2.427211]\n",
      "epoch:2 step:1678 [D loss: 0.880858, acc: 45.31%] [G loss: 2.065049]\n",
      "epoch:2 step:1679 [D loss: 0.643401, acc: 61.72%] [G loss: 2.320583]\n",
      "epoch:2 step:1680 [D loss: 0.470559, acc: 78.12%] [G loss: 2.178128]\n",
      "epoch:2 step:1681 [D loss: 0.584810, acc: 66.41%] [G loss: 2.397851]\n",
      "epoch:2 step:1682 [D loss: 0.589060, acc: 71.09%] [G loss: 2.492675]\n",
      "epoch:2 step:1683 [D loss: 0.704832, acc: 59.38%] [G loss: 2.226898]\n",
      "epoch:2 step:1684 [D loss: 0.579449, acc: 69.53%] [G loss: 2.261423]\n",
      "epoch:2 step:1685 [D loss: 0.840405, acc: 46.88%] [G loss: 2.220320]\n",
      "epoch:2 step:1686 [D loss: 0.755019, acc: 50.00%] [G loss: 2.131225]\n",
      "epoch:2 step:1687 [D loss: 0.695598, acc: 54.69%] [G loss: 2.151270]\n",
      "epoch:2 step:1688 [D loss: 0.608791, acc: 67.97%] [G loss: 2.408903]\n",
      "epoch:2 step:1689 [D loss: 0.756390, acc: 54.69%] [G loss: 2.177174]\n",
      "epoch:2 step:1690 [D loss: 0.537124, acc: 75.00%] [G loss: 2.407136]\n",
      "epoch:2 step:1691 [D loss: 0.539783, acc: 63.28%] [G loss: 2.069593]\n",
      "epoch:2 step:1692 [D loss: 0.961926, acc: 38.28%] [G loss: 1.861967]\n",
      "epoch:2 step:1693 [D loss: 0.611096, acc: 65.62%] [G loss: 1.783677]\n",
      "epoch:2 step:1694 [D loss: 0.605554, acc: 67.97%] [G loss: 1.974923]\n",
      "epoch:2 step:1695 [D loss: 0.775986, acc: 47.66%] [G loss: 1.926575]\n",
      "epoch:2 step:1696 [D loss: 0.488278, acc: 77.34%] [G loss: 2.219000]\n",
      "epoch:2 step:1697 [D loss: 1.066980, acc: 27.34%] [G loss: 1.897331]\n",
      "epoch:2 step:1698 [D loss: 0.851128, acc: 40.62%] [G loss: 2.323528]\n",
      "epoch:2 step:1699 [D loss: 0.897115, acc: 47.66%] [G loss: 2.109032]\n",
      "epoch:2 step:1700 [D loss: 0.657713, acc: 61.72%] [G loss: 2.382225]\n",
      "epoch:2 step:1701 [D loss: 0.818875, acc: 53.91%] [G loss: 2.247422]\n",
      "epoch:2 step:1702 [D loss: 0.612487, acc: 68.75%] [G loss: 2.643734]\n",
      "epoch:2 step:1703 [D loss: 0.675180, acc: 59.38%] [G loss: 2.574486]\n",
      "epoch:2 step:1704 [D loss: 0.669867, acc: 60.16%] [G loss: 2.789896]\n",
      "epoch:2 step:1705 [D loss: 0.427879, acc: 81.25%] [G loss: 3.102389]\n",
      "epoch:2 step:1706 [D loss: 0.373121, acc: 83.59%] [G loss: 2.616554]\n",
      "epoch:2 step:1707 [D loss: 0.689613, acc: 61.72%] [G loss: 2.506306]\n",
      "epoch:2 step:1708 [D loss: 0.696890, acc: 62.50%] [G loss: 2.390495]\n",
      "epoch:2 step:1709 [D loss: 0.202156, acc: 96.88%] [G loss: 3.029772]\n",
      "epoch:2 step:1710 [D loss: 0.520543, acc: 74.22%] [G loss: 2.091066]\n",
      "epoch:2 step:1711 [D loss: 1.073324, acc: 41.41%] [G loss: 1.570153]\n",
      "epoch:2 step:1712 [D loss: 0.424325, acc: 82.81%] [G loss: 1.830545]\n",
      "epoch:2 step:1713 [D loss: 0.395069, acc: 81.25%] [G loss: 2.365469]\n",
      "epoch:2 step:1714 [D loss: 1.031160, acc: 36.72%] [G loss: 1.766209]\n",
      "epoch:2 step:1715 [D loss: 0.210470, acc: 95.31%] [G loss: 2.516217]\n",
      "epoch:2 step:1716 [D loss: 0.645157, acc: 66.41%] [G loss: 1.895217]\n",
      "epoch:2 step:1717 [D loss: 1.230311, acc: 25.78%] [G loss: 1.637331]\n",
      "epoch:2 step:1718 [D loss: 0.587036, acc: 71.09%] [G loss: 2.011415]\n",
      "epoch:2 step:1719 [D loss: 0.611602, acc: 68.75%] [G loss: 2.254681]\n",
      "epoch:2 step:1720 [D loss: 0.736227, acc: 57.81%] [G loss: 2.160332]\n",
      "epoch:2 step:1721 [D loss: 0.902487, acc: 42.97%] [G loss: 2.079798]\n",
      "epoch:2 step:1722 [D loss: 0.764034, acc: 48.44%] [G loss: 2.249895]\n",
      "epoch:2 step:1723 [D loss: 0.788463, acc: 53.12%] [G loss: 2.656625]\n",
      "epoch:2 step:1724 [D loss: 0.592575, acc: 68.75%] [G loss: 2.604913]\n",
      "epoch:2 step:1725 [D loss: 0.747917, acc: 57.03%] [G loss: 2.243613]\n",
      "epoch:2 step:1726 [D loss: 0.536191, acc: 72.66%] [G loss: 2.461016]\n",
      "epoch:2 step:1727 [D loss: 0.547011, acc: 71.88%] [G loss: 2.240177]\n",
      "epoch:2 step:1728 [D loss: 0.892672, acc: 39.06%] [G loss: 1.760488]\n",
      "epoch:2 step:1729 [D loss: 0.355542, acc: 89.84%] [G loss: 2.301311]\n",
      "epoch:2 step:1730 [D loss: 0.306834, acc: 91.41%] [G loss: 2.336579]\n",
      "epoch:2 step:1731 [D loss: 0.462409, acc: 83.59%] [G loss: 1.685648]\n",
      "epoch:2 step:1732 [D loss: 0.650736, acc: 58.59%] [G loss: 1.855261]\n",
      "epoch:2 step:1733 [D loss: 0.541548, acc: 71.09%] [G loss: 1.931276]\n",
      "epoch:2 step:1734 [D loss: 0.309182, acc: 93.75%] [G loss: 1.840879]\n",
      "epoch:2 step:1735 [D loss: 0.361584, acc: 88.28%] [G loss: 1.988745]\n",
      "epoch:2 step:1736 [D loss: 0.593086, acc: 69.53%] [G loss: 1.595783]\n",
      "epoch:2 step:1737 [D loss: 0.728737, acc: 57.03%] [G loss: 1.856123]\n",
      "epoch:2 step:1738 [D loss: 0.891284, acc: 35.94%] [G loss: 1.726608]\n",
      "epoch:2 step:1739 [D loss: 0.644615, acc: 63.28%] [G loss: 1.892390]\n",
      "epoch:2 step:1740 [D loss: 1.335724, acc: 31.25%] [G loss: 1.371460]\n",
      "epoch:2 step:1741 [D loss: 1.025841, acc: 34.38%] [G loss: 2.079759]\n",
      "epoch:2 step:1742 [D loss: 0.629438, acc: 61.72%] [G loss: 1.710278]\n",
      "epoch:2 step:1743 [D loss: 0.558680, acc: 68.75%] [G loss: 1.956350]\n",
      "epoch:2 step:1744 [D loss: 0.972306, acc: 28.12%] [G loss: 1.832886]\n",
      "epoch:2 step:1745 [D loss: 0.640999, acc: 64.06%] [G loss: 2.351850]\n",
      "epoch:2 step:1746 [D loss: 0.922631, acc: 41.41%] [G loss: 2.124115]\n",
      "epoch:2 step:1747 [D loss: 0.688584, acc: 60.16%] [G loss: 2.172785]\n",
      "epoch:2 step:1748 [D loss: 0.449392, acc: 82.81%] [G loss: 2.222172]\n",
      "epoch:2 step:1749 [D loss: 0.660030, acc: 59.38%] [G loss: 2.179808]\n",
      "epoch:2 step:1750 [D loss: 0.499311, acc: 79.69%] [G loss: 2.083967]\n",
      "epoch:2 step:1751 [D loss: 0.416933, acc: 85.16%] [G loss: 2.331829]\n",
      "epoch:2 step:1752 [D loss: 0.457051, acc: 72.66%] [G loss: 1.935408]\n",
      "epoch:2 step:1753 [D loss: 0.305942, acc: 96.09%] [G loss: 2.427037]\n",
      "epoch:2 step:1754 [D loss: 0.844251, acc: 54.69%] [G loss: 1.777603]\n",
      "epoch:2 step:1755 [D loss: 0.587330, acc: 69.53%] [G loss: 1.643433]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:2 step:1756 [D loss: 0.400085, acc: 85.16%] [G loss: 1.843410]\n",
      "epoch:2 step:1757 [D loss: 0.582741, acc: 65.62%] [G loss: 1.874176]\n",
      "epoch:2 step:1758 [D loss: 0.939234, acc: 43.75%] [G loss: 1.620191]\n",
      "epoch:2 step:1759 [D loss: 0.752920, acc: 54.69%] [G loss: 1.759342]\n",
      "epoch:2 step:1760 [D loss: 0.584559, acc: 71.09%] [G loss: 2.015706]\n",
      "epoch:2 step:1761 [D loss: 0.700723, acc: 54.69%] [G loss: 1.993323]\n",
      "epoch:2 step:1762 [D loss: 0.550859, acc: 72.66%] [G loss: 2.228230]\n",
      "epoch:2 step:1763 [D loss: 0.704525, acc: 61.72%] [G loss: 2.248227]\n",
      "epoch:2 step:1764 [D loss: 0.974993, acc: 34.38%] [G loss: 2.445248]\n",
      "epoch:2 step:1765 [D loss: 0.369620, acc: 84.38%] [G loss: 2.907923]\n",
      "epoch:2 step:1766 [D loss: 0.485630, acc: 78.12%] [G loss: 2.427953]\n",
      "epoch:2 step:1767 [D loss: 0.868483, acc: 42.19%] [G loss: 1.883233]\n",
      "epoch:2 step:1768 [D loss: 0.416223, acc: 85.16%] [G loss: 2.030035]\n",
      "epoch:2 step:1769 [D loss: 0.428174, acc: 79.69%] [G loss: 2.510679]\n",
      "epoch:2 step:1770 [D loss: 0.649461, acc: 62.50%] [G loss: 2.370441]\n",
      "epoch:2 step:1771 [D loss: 0.869811, acc: 44.53%] [G loss: 1.932426]\n",
      "epoch:2 step:1772 [D loss: 1.019457, acc: 39.06%] [G loss: 1.928358]\n",
      "epoch:2 step:1773 [D loss: 0.902741, acc: 42.19%] [G loss: 2.111602]\n",
      "epoch:2 step:1774 [D loss: 0.739345, acc: 57.81%] [G loss: 1.763805]\n",
      "epoch:2 step:1775 [D loss: 1.279669, acc: 18.75%] [G loss: 1.641462]\n",
      "epoch:2 step:1776 [D loss: 0.614255, acc: 64.06%] [G loss: 2.265121]\n",
      "epoch:2 step:1777 [D loss: 0.580578, acc: 72.66%] [G loss: 2.612362]\n",
      "epoch:2 step:1778 [D loss: 0.702286, acc: 53.12%] [G loss: 2.211780]\n",
      "epoch:2 step:1779 [D loss: 0.647139, acc: 60.94%] [G loss: 1.998321]\n",
      "epoch:2 step:1780 [D loss: 0.604541, acc: 64.84%] [G loss: 2.225939]\n",
      "epoch:2 step:1781 [D loss: 0.481282, acc: 79.69%] [G loss: 2.183395]\n",
      "epoch:2 step:1782 [D loss: 0.683367, acc: 60.94%] [G loss: 2.147781]\n",
      "epoch:2 step:1783 [D loss: 0.626200, acc: 68.75%] [G loss: 2.174577]\n",
      "epoch:2 step:1784 [D loss: 0.709412, acc: 62.50%] [G loss: 2.226864]\n",
      "epoch:2 step:1785 [D loss: 0.660905, acc: 62.50%] [G loss: 2.217996]\n",
      "epoch:2 step:1786 [D loss: 0.630833, acc: 67.19%] [G loss: 2.110588]\n",
      "epoch:2 step:1787 [D loss: 0.708238, acc: 55.47%] [G loss: 2.384921]\n",
      "epoch:2 step:1788 [D loss: 0.834023, acc: 43.75%] [G loss: 1.512020]\n",
      "epoch:2 step:1789 [D loss: 0.683935, acc: 58.59%] [G loss: 2.278015]\n",
      "epoch:2 step:1790 [D loss: 0.708834, acc: 58.59%] [G loss: 1.837517]\n",
      "epoch:2 step:1791 [D loss: 0.900449, acc: 40.62%] [G loss: 1.742351]\n",
      "epoch:2 step:1792 [D loss: 1.109195, acc: 21.88%] [G loss: 1.899105]\n",
      "epoch:2 step:1793 [D loss: 0.591395, acc: 67.97%] [G loss: 2.615318]\n",
      "epoch:2 step:1794 [D loss: 0.770659, acc: 53.12%] [G loss: 1.975225]\n",
      "epoch:2 step:1795 [D loss: 0.605126, acc: 64.06%] [G loss: 2.210549]\n",
      "epoch:2 step:1796 [D loss: 0.553298, acc: 75.00%] [G loss: 2.567894]\n",
      "epoch:2 step:1797 [D loss: 0.789515, acc: 55.47%] [G loss: 2.118335]\n",
      "epoch:2 step:1798 [D loss: 1.100519, acc: 26.56%] [G loss: 1.743790]\n",
      "epoch:2 step:1799 [D loss: 0.451904, acc: 80.47%] [G loss: 2.139531]\n",
      "epoch:2 step:1800 [D loss: 0.430396, acc: 85.94%] [G loss: 2.244202]\n",
      "##############\n",
      "[0.83432658 0.86220641 0.80467913 0.83431037 0.79682359 0.82534127\n",
      " 0.86089074 0.82042074 0.81966279 0.83320497]\n",
      "##########\n",
      "epoch:2 step:1801 [D loss: 0.517935, acc: 77.34%] [G loss: 2.195614]\n",
      "epoch:2 step:1802 [D loss: 0.490625, acc: 77.34%] [G loss: 2.018543]\n",
      "epoch:2 step:1803 [D loss: 0.641823, acc: 59.38%] [G loss: 2.093034]\n",
      "epoch:2 step:1804 [D loss: 0.378236, acc: 86.72%] [G loss: 2.682579]\n",
      "epoch:2 step:1805 [D loss: 0.729275, acc: 57.81%] [G loss: 1.914087]\n",
      "epoch:2 step:1806 [D loss: 0.788602, acc: 49.22%] [G loss: 1.934235]\n",
      "epoch:2 step:1807 [D loss: 0.396544, acc: 89.84%] [G loss: 2.562916]\n",
      "epoch:2 step:1808 [D loss: 0.558637, acc: 68.75%] [G loss: 2.029804]\n",
      "epoch:2 step:1809 [D loss: 0.658326, acc: 60.16%] [G loss: 2.177791]\n",
      "epoch:2 step:1810 [D loss: 0.313992, acc: 92.97%] [G loss: 1.803307]\n",
      "epoch:2 step:1811 [D loss: 0.747715, acc: 51.56%] [G loss: 2.041314]\n",
      "epoch:2 step:1812 [D loss: 0.456679, acc: 80.47%] [G loss: 1.931356]\n",
      "epoch:2 step:1813 [D loss: 0.418190, acc: 87.50%] [G loss: 2.191486]\n",
      "epoch:2 step:1814 [D loss: 0.950364, acc: 46.09%] [G loss: 2.418479]\n",
      "epoch:2 step:1815 [D loss: 0.301547, acc: 85.94%] [G loss: 2.238642]\n",
      "epoch:2 step:1816 [D loss: 0.631547, acc: 67.19%] [G loss: 2.138570]\n",
      "epoch:2 step:1817 [D loss: 0.674156, acc: 60.94%] [G loss: 2.010302]\n",
      "epoch:2 step:1818 [D loss: 0.397149, acc: 88.28%] [G loss: 1.786532]\n",
      "epoch:2 step:1819 [D loss: 1.162221, acc: 19.53%] [G loss: 1.381665]\n",
      "epoch:2 step:1820 [D loss: 0.447358, acc: 79.69%] [G loss: 1.807311]\n",
      "epoch:2 step:1821 [D loss: 0.759623, acc: 52.34%] [G loss: 2.255083]\n",
      "epoch:2 step:1822 [D loss: 1.003872, acc: 35.94%] [G loss: 1.924855]\n",
      "epoch:2 step:1823 [D loss: 0.422497, acc: 86.72%] [G loss: 1.883570]\n",
      "epoch:2 step:1824 [D loss: 0.673507, acc: 61.72%] [G loss: 1.870580]\n",
      "epoch:2 step:1825 [D loss: 0.764281, acc: 53.12%] [G loss: 1.793749]\n",
      "epoch:2 step:1826 [D loss: 1.204588, acc: 22.66%] [G loss: 1.893494]\n",
      "epoch:2 step:1827 [D loss: 0.675851, acc: 54.69%] [G loss: 2.252223]\n",
      "epoch:2 step:1828 [D loss: 0.639016, acc: 62.50%] [G loss: 2.398498]\n",
      "epoch:2 step:1829 [D loss: 1.505262, acc: 17.19%] [G loss: 1.196972]\n",
      "epoch:2 step:1830 [D loss: 0.617085, acc: 67.19%] [G loss: 2.313777]\n",
      "epoch:2 step:1831 [D loss: 0.746056, acc: 56.25%] [G loss: 1.879653]\n",
      "epoch:2 step:1832 [D loss: 0.732502, acc: 58.59%] [G loss: 1.874141]\n",
      "epoch:2 step:1833 [D loss: 0.757898, acc: 53.91%] [G loss: 2.003718]\n",
      "epoch:2 step:1834 [D loss: 0.604233, acc: 64.84%] [G loss: 1.758934]\n",
      "epoch:2 step:1835 [D loss: 0.460739, acc: 78.12%] [G loss: 1.860121]\n",
      "epoch:2 step:1836 [D loss: 0.764348, acc: 53.91%] [G loss: 1.545283]\n",
      "epoch:2 step:1837 [D loss: 0.902752, acc: 40.62%] [G loss: 1.412120]\n",
      "epoch:2 step:1838 [D loss: 0.432259, acc: 83.59%] [G loss: 2.000442]\n",
      "epoch:2 step:1839 [D loss: 0.716066, acc: 59.38%] [G loss: 1.871376]\n",
      "epoch:2 step:1840 [D loss: 0.650364, acc: 63.28%] [G loss: 1.767533]\n",
      "epoch:2 step:1841 [D loss: 0.424868, acc: 78.91%] [G loss: 1.882393]\n",
      "epoch:2 step:1842 [D loss: 0.449522, acc: 82.03%] [G loss: 1.819961]\n",
      "epoch:2 step:1843 [D loss: 0.713638, acc: 58.59%] [G loss: 1.908448]\n",
      "epoch:2 step:1844 [D loss: 0.951357, acc: 34.38%] [G loss: 1.741593]\n",
      "epoch:2 step:1845 [D loss: 0.412913, acc: 79.69%] [G loss: 2.045590]\n",
      "epoch:2 step:1846 [D loss: 0.535964, acc: 77.34%] [G loss: 2.128279]\n",
      "epoch:2 step:1847 [D loss: 0.420067, acc: 85.94%] [G loss: 2.341568]\n",
      "epoch:2 step:1848 [D loss: 0.973809, acc: 36.72%] [G loss: 1.895636]\n",
      "epoch:2 step:1849 [D loss: 0.829271, acc: 46.09%] [G loss: 2.160408]\n",
      "epoch:2 step:1850 [D loss: 0.915701, acc: 43.75%] [G loss: 1.768633]\n",
      "epoch:2 step:1851 [D loss: 0.706157, acc: 60.16%] [G loss: 1.581853]\n",
      "epoch:2 step:1852 [D loss: 0.343981, acc: 95.31%] [G loss: 2.154271]\n",
      "epoch:2 step:1853 [D loss: 0.860945, acc: 46.88%] [G loss: 1.981704]\n",
      "epoch:2 step:1854 [D loss: 0.816086, acc: 50.78%] [G loss: 1.908212]\n",
      "epoch:2 step:1855 [D loss: 0.768180, acc: 52.34%] [G loss: 1.914372]\n",
      "epoch:2 step:1856 [D loss: 0.829088, acc: 47.66%] [G loss: 1.714058]\n",
      "epoch:2 step:1857 [D loss: 1.167880, acc: 18.75%] [G loss: 1.597321]\n",
      "epoch:2 step:1858 [D loss: 0.690560, acc: 59.38%] [G loss: 1.978837]\n",
      "epoch:2 step:1859 [D loss: 0.667646, acc: 57.81%] [G loss: 1.802801]\n",
      "epoch:2 step:1860 [D loss: 0.823525, acc: 44.53%] [G loss: 1.892076]\n",
      "epoch:2 step:1861 [D loss: 0.816798, acc: 44.53%] [G loss: 1.985523]\n",
      "epoch:2 step:1862 [D loss: 1.020439, acc: 34.38%] [G loss: 1.708558]\n",
      "epoch:2 step:1863 [D loss: 0.949212, acc: 39.84%] [G loss: 1.950679]\n",
      "epoch:2 step:1864 [D loss: 0.790744, acc: 52.34%] [G loss: 1.829118]\n",
      "epoch:2 step:1865 [D loss: 0.717501, acc: 54.69%] [G loss: 1.592696]\n",
      "epoch:2 step:1866 [D loss: 0.712734, acc: 54.69%] [G loss: 2.118725]\n",
      "epoch:2 step:1867 [D loss: 0.808804, acc: 46.88%] [G loss: 2.165371]\n",
      "epoch:2 step:1868 [D loss: 0.786955, acc: 50.78%] [G loss: 1.947693]\n",
      "epoch:2 step:1869 [D loss: 0.789923, acc: 46.88%] [G loss: 1.999496]\n",
      "epoch:2 step:1870 [D loss: 0.784298, acc: 48.44%] [G loss: 2.113048]\n",
      "epoch:2 step:1871 [D loss: 0.486727, acc: 79.69%] [G loss: 2.121898]\n",
      "epoch:2 step:1872 [D loss: 0.660521, acc: 64.84%] [G loss: 2.222878]\n",
      "epoch:2 step:1873 [D loss: 0.678769, acc: 61.72%] [G loss: 2.271208]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:2 step:1874 [D loss: 0.774518, acc: 55.47%] [G loss: 2.059534]\n",
      "epoch:2 step:1875 [D loss: 0.712640, acc: 54.69%] [G loss: 2.008670]\n",
      "epoch:2 step:1876 [D loss: 0.768381, acc: 51.56%] [G loss: 2.189900]\n",
      "epoch:2 step:1877 [D loss: 0.886428, acc: 45.31%] [G loss: 2.150837]\n",
      "epoch:2 step:1878 [D loss: 0.676550, acc: 65.62%] [G loss: 2.045912]\n",
      "epoch:2 step:1879 [D loss: 0.527276, acc: 76.56%] [G loss: 2.142196]\n",
      "epoch:2 step:1880 [D loss: 0.659391, acc: 61.72%] [G loss: 1.964392]\n",
      "epoch:2 step:1881 [D loss: 0.922035, acc: 40.62%] [G loss: 1.619605]\n",
      "epoch:2 step:1882 [D loss: 0.661008, acc: 67.19%] [G loss: 2.063314]\n",
      "epoch:2 step:1883 [D loss: 0.681963, acc: 55.47%] [G loss: 2.008628]\n",
      "epoch:2 step:1884 [D loss: 0.646586, acc: 61.72%] [G loss: 1.612839]\n",
      "epoch:2 step:1885 [D loss: 0.772282, acc: 51.56%] [G loss: 1.924098]\n",
      "epoch:2 step:1886 [D loss: 0.371831, acc: 85.16%] [G loss: 2.044785]\n",
      "epoch:2 step:1887 [D loss: 0.420028, acc: 85.16%] [G loss: 1.893063]\n",
      "epoch:2 step:1888 [D loss: 0.774112, acc: 52.34%] [G loss: 1.588032]\n",
      "epoch:2 step:1889 [D loss: 0.471627, acc: 79.69%] [G loss: 1.810772]\n",
      "epoch:2 step:1890 [D loss: 0.556231, acc: 78.12%] [G loss: 1.735229]\n",
      "epoch:2 step:1891 [D loss: 0.661492, acc: 64.06%] [G loss: 1.684996]\n",
      "epoch:2 step:1892 [D loss: 0.667718, acc: 60.16%] [G loss: 1.759230]\n",
      "epoch:2 step:1893 [D loss: 0.924214, acc: 30.47%] [G loss: 1.793693]\n",
      "epoch:2 step:1894 [D loss: 0.443685, acc: 82.03%] [G loss: 2.172589]\n",
      "epoch:2 step:1895 [D loss: 0.591385, acc: 67.19%] [G loss: 2.249555]\n",
      "epoch:2 step:1896 [D loss: 0.882631, acc: 39.84%] [G loss: 1.689496]\n",
      "epoch:2 step:1897 [D loss: 0.504868, acc: 75.00%] [G loss: 1.854418]\n",
      "epoch:2 step:1898 [D loss: 0.682109, acc: 61.72%] [G loss: 1.823071]\n",
      "epoch:2 step:1899 [D loss: 0.836509, acc: 44.53%] [G loss: 1.301966]\n",
      "epoch:2 step:1900 [D loss: 1.091087, acc: 27.34%] [G loss: 1.448873]\n",
      "epoch:2 step:1901 [D loss: 0.440349, acc: 85.16%] [G loss: 2.215518]\n",
      "epoch:2 step:1902 [D loss: 0.753558, acc: 51.56%] [G loss: 1.604278]\n",
      "epoch:2 step:1903 [D loss: 0.416153, acc: 89.06%] [G loss: 2.136273]\n",
      "epoch:2 step:1904 [D loss: 0.738362, acc: 53.91%] [G loss: 1.480108]\n",
      "epoch:2 step:1905 [D loss: 0.720364, acc: 56.25%] [G loss: 1.607170]\n",
      "epoch:2 step:1906 [D loss: 1.221014, acc: 19.53%] [G loss: 1.365773]\n",
      "epoch:2 step:1907 [D loss: 0.612646, acc: 64.84%] [G loss: 1.934156]\n",
      "epoch:2 step:1908 [D loss: 0.856872, acc: 52.34%] [G loss: 1.547189]\n",
      "epoch:2 step:1909 [D loss: 0.589201, acc: 74.22%] [G loss: 2.089777]\n",
      "epoch:2 step:1910 [D loss: 0.689334, acc: 57.03%] [G loss: 2.153707]\n",
      "epoch:2 step:1911 [D loss: 0.691234, acc: 56.25%] [G loss: 2.106906]\n",
      "epoch:2 step:1912 [D loss: 1.076610, acc: 29.69%] [G loss: 2.145257]\n",
      "epoch:2 step:1913 [D loss: 0.846916, acc: 46.88%] [G loss: 2.007468]\n",
      "epoch:2 step:1914 [D loss: 0.875581, acc: 42.19%] [G loss: 1.914553]\n",
      "epoch:2 step:1915 [D loss: 0.699688, acc: 57.03%] [G loss: 1.979508]\n",
      "epoch:2 step:1916 [D loss: 0.744664, acc: 53.12%] [G loss: 1.847705]\n",
      "epoch:2 step:1917 [D loss: 0.906541, acc: 39.84%] [G loss: 1.682935]\n",
      "epoch:2 step:1918 [D loss: 0.652867, acc: 57.03%] [G loss: 1.764102]\n",
      "epoch:2 step:1919 [D loss: 0.761129, acc: 49.22%] [G loss: 1.776164]\n",
      "epoch:2 step:1920 [D loss: 0.874675, acc: 36.72%] [G loss: 1.674551]\n",
      "epoch:2 step:1921 [D loss: 0.784381, acc: 48.44%] [G loss: 1.910149]\n",
      "epoch:2 step:1922 [D loss: 0.390470, acc: 87.50%] [G loss: 2.192353]\n",
      "epoch:2 step:1923 [D loss: 0.731412, acc: 58.59%] [G loss: 2.151436]\n",
      "epoch:2 step:1924 [D loss: 0.440055, acc: 82.81%] [G loss: 1.906551]\n",
      "epoch:2 step:1925 [D loss: 0.556261, acc: 74.22%] [G loss: 2.159969]\n",
      "epoch:2 step:1926 [D loss: 0.438768, acc: 84.38%] [G loss: 1.995735]\n",
      "epoch:2 step:1927 [D loss: 0.418516, acc: 82.81%] [G loss: 1.838562]\n",
      "epoch:2 step:1928 [D loss: 0.879621, acc: 46.09%] [G loss: 1.462068]\n",
      "epoch:2 step:1929 [D loss: 0.780508, acc: 51.56%] [G loss: 1.853525]\n",
      "epoch:2 step:1930 [D loss: 0.385491, acc: 93.75%] [G loss: 1.976261]\n",
      "epoch:2 step:1931 [D loss: 0.553949, acc: 74.22%] [G loss: 1.593815]\n",
      "epoch:2 step:1932 [D loss: 0.697466, acc: 53.91%] [G loss: 1.764821]\n",
      "epoch:2 step:1933 [D loss: 0.769591, acc: 52.34%] [G loss: 1.493667]\n",
      "epoch:2 step:1934 [D loss: 0.420630, acc: 89.84%] [G loss: 1.620957]\n",
      "epoch:2 step:1935 [D loss: 1.538026, acc: 8.59%] [G loss: 1.127564]\n",
      "epoch:2 step:1936 [D loss: 0.627048, acc: 60.94%] [G loss: 1.613041]\n",
      "epoch:2 step:1937 [D loss: 0.462285, acc: 85.16%] [G loss: 1.824259]\n",
      "epoch:2 step:1938 [D loss: 0.681827, acc: 61.72%] [G loss: 2.000521]\n",
      "epoch:2 step:1939 [D loss: 0.480444, acc: 82.81%] [G loss: 2.144651]\n",
      "epoch:2 step:1940 [D loss: 0.881482, acc: 33.59%] [G loss: 1.754059]\n",
      "epoch:2 step:1941 [D loss: 0.767396, acc: 50.00%] [G loss: 1.741009]\n",
      "epoch:2 step:1942 [D loss: 0.814439, acc: 42.19%] [G loss: 1.700494]\n",
      "epoch:2 step:1943 [D loss: 0.667277, acc: 64.06%] [G loss: 1.612346]\n",
      "epoch:2 step:1944 [D loss: 0.766442, acc: 52.34%] [G loss: 1.731398]\n",
      "epoch:2 step:1945 [D loss: 0.862212, acc: 36.72%] [G loss: 1.730389]\n",
      "epoch:2 step:1946 [D loss: 0.879949, acc: 41.41%] [G loss: 1.665749]\n",
      "epoch:2 step:1947 [D loss: 0.768715, acc: 50.00%] [G loss: 1.968198]\n",
      "epoch:2 step:1948 [D loss: 0.921816, acc: 27.34%] [G loss: 1.656720]\n",
      "epoch:2 step:1949 [D loss: 0.681949, acc: 59.38%] [G loss: 1.569043]\n",
      "epoch:2 step:1950 [D loss: 0.810200, acc: 45.31%] [G loss: 1.543782]\n",
      "epoch:2 step:1951 [D loss: 0.666695, acc: 63.28%] [G loss: 1.677059]\n",
      "epoch:2 step:1952 [D loss: 0.966408, acc: 32.81%] [G loss: 1.568644]\n",
      "epoch:2 step:1953 [D loss: 1.220018, acc: 8.59%] [G loss: 1.497048]\n",
      "epoch:2 step:1954 [D loss: 0.775103, acc: 50.00%] [G loss: 1.615675]\n",
      "epoch:2 step:1955 [D loss: 0.628079, acc: 70.31%] [G loss: 1.368006]\n",
      "epoch:2 step:1956 [D loss: 1.040874, acc: 18.75%] [G loss: 1.356519]\n",
      "epoch:2 step:1957 [D loss: 0.849855, acc: 37.50%] [G loss: 1.540586]\n",
      "epoch:2 step:1958 [D loss: 0.714425, acc: 59.38%] [G loss: 1.718357]\n",
      "epoch:2 step:1959 [D loss: 0.872036, acc: 33.59%] [G loss: 1.683727]\n",
      "epoch:2 step:1960 [D loss: 0.682438, acc: 60.16%] [G loss: 1.687326]\n",
      "epoch:2 step:1961 [D loss: 0.852102, acc: 34.38%] [G loss: 1.721582]\n",
      "epoch:2 step:1962 [D loss: 0.663157, acc: 60.16%] [G loss: 1.763708]\n",
      "epoch:2 step:1963 [D loss: 0.665218, acc: 65.62%] [G loss: 1.539248]\n",
      "epoch:2 step:1964 [D loss: 0.607108, acc: 69.53%] [G loss: 1.992901]\n",
      "epoch:2 step:1965 [D loss: 0.614368, acc: 69.53%] [G loss: 1.785020]\n",
      "epoch:2 step:1966 [D loss: 0.829967, acc: 39.84%] [G loss: 1.602669]\n",
      "epoch:2 step:1967 [D loss: 0.646118, acc: 65.62%] [G loss: 1.735211]\n",
      "epoch:2 step:1968 [D loss: 0.546087, acc: 72.66%] [G loss: 1.711570]\n",
      "epoch:2 step:1969 [D loss: 0.604600, acc: 72.66%] [G loss: 1.702355]\n",
      "epoch:2 step:1970 [D loss: 0.538061, acc: 75.78%] [G loss: 1.591100]\n",
      "epoch:2 step:1971 [D loss: 0.477438, acc: 82.03%] [G loss: 1.703955]\n",
      "epoch:2 step:1972 [D loss: 0.403108, acc: 81.25%] [G loss: 1.768168]\n",
      "epoch:2 step:1973 [D loss: 1.276073, acc: 14.84%] [G loss: 1.741634]\n",
      "epoch:2 step:1974 [D loss: 0.883967, acc: 45.31%] [G loss: 1.705597]\n",
      "epoch:2 step:1975 [D loss: 0.601317, acc: 70.31%] [G loss: 1.698316]\n",
      "epoch:2 step:1976 [D loss: 0.636583, acc: 63.28%] [G loss: 1.617825]\n",
      "epoch:2 step:1977 [D loss: 0.756022, acc: 54.69%] [G loss: 1.937025]\n",
      "epoch:2 step:1978 [D loss: 0.527717, acc: 76.56%] [G loss: 1.784761]\n",
      "epoch:2 step:1979 [D loss: 0.677930, acc: 60.94%] [G loss: 2.032861]\n",
      "epoch:2 step:1980 [D loss: 0.729798, acc: 53.12%] [G loss: 1.871533]\n",
      "epoch:2 step:1981 [D loss: 0.713670, acc: 51.56%] [G loss: 1.977570]\n",
      "epoch:2 step:1982 [D loss: 0.773400, acc: 50.78%] [G loss: 1.640124]\n",
      "epoch:2 step:1983 [D loss: 0.607168, acc: 67.97%] [G loss: 2.040827]\n",
      "epoch:2 step:1984 [D loss: 0.619611, acc: 72.66%] [G loss: 2.065047]\n",
      "epoch:2 step:1985 [D loss: 0.605770, acc: 62.50%] [G loss: 2.090306]\n",
      "epoch:2 step:1986 [D loss: 0.703782, acc: 55.47%] [G loss: 1.808018]\n",
      "epoch:2 step:1987 [D loss: 0.635630, acc: 64.06%] [G loss: 1.913845]\n",
      "epoch:2 step:1988 [D loss: 0.625673, acc: 68.75%] [G loss: 1.857388]\n",
      "epoch:2 step:1989 [D loss: 0.564840, acc: 72.66%] [G loss: 1.823990]\n",
      "epoch:2 step:1990 [D loss: 0.647165, acc: 58.59%] [G loss: 2.047904]\n",
      "epoch:2 step:1991 [D loss: 0.608089, acc: 67.19%] [G loss: 1.877542]\n",
      "epoch:2 step:1992 [D loss: 0.746808, acc: 53.12%] [G loss: 1.627227]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:2 step:1993 [D loss: 0.690783, acc: 61.72%] [G loss: 1.841855]\n",
      "epoch:2 step:1994 [D loss: 0.535523, acc: 77.34%] [G loss: 1.963763]\n",
      "epoch:2 step:1995 [D loss: 0.843235, acc: 42.97%] [G loss: 1.582607]\n",
      "epoch:2 step:1996 [D loss: 0.901446, acc: 42.19%] [G loss: 1.572028]\n",
      "epoch:2 step:1997 [D loss: 0.616750, acc: 68.75%] [G loss: 1.903607]\n",
      "epoch:2 step:1998 [D loss: 0.564375, acc: 71.09%] [G loss: 2.032594]\n",
      "epoch:2 step:1999 [D loss: 0.744857, acc: 54.69%] [G loss: 1.858165]\n",
      "epoch:2 step:2000 [D loss: 0.556643, acc: 81.25%] [G loss: 2.458036]\n",
      "##############\n",
      "[0.83839919 0.82834144 0.81842322 0.82422005 0.81277755 0.80035174\n",
      " 0.89251732 0.81819145 0.81934246 0.855724  ]\n",
      "##########\n",
      "epoch:2 step:2001 [D loss: 0.504582, acc: 76.56%] [G loss: 2.074320]\n",
      "epoch:2 step:2002 [D loss: 0.789406, acc: 52.34%] [G loss: 1.907565]\n",
      "epoch:2 step:2003 [D loss: 0.677831, acc: 58.59%] [G loss: 2.291093]\n",
      "epoch:2 step:2004 [D loss: 0.826987, acc: 43.75%] [G loss: 1.980509]\n",
      "epoch:2 step:2005 [D loss: 0.873046, acc: 36.72%] [G loss: 1.609258]\n",
      "epoch:2 step:2006 [D loss: 0.708287, acc: 60.16%] [G loss: 1.852048]\n",
      "epoch:2 step:2007 [D loss: 0.612132, acc: 65.62%] [G loss: 1.824668]\n",
      "epoch:2 step:2008 [D loss: 0.911321, acc: 33.59%] [G loss: 1.640335]\n",
      "epoch:2 step:2009 [D loss: 0.514734, acc: 77.34%] [G loss: 1.940926]\n",
      "epoch:2 step:2010 [D loss: 0.631723, acc: 63.28%] [G loss: 1.771628]\n",
      "epoch:2 step:2011 [D loss: 0.698671, acc: 56.25%] [G loss: 1.519696]\n",
      "epoch:2 step:2012 [D loss: 0.564898, acc: 67.19%] [G loss: 1.537862]\n",
      "epoch:2 step:2013 [D loss: 0.485899, acc: 83.59%] [G loss: 1.698914]\n",
      "epoch:2 step:2014 [D loss: 0.569343, acc: 66.41%] [G loss: 2.030031]\n",
      "epoch:2 step:2015 [D loss: 0.697306, acc: 58.59%] [G loss: 1.431140]\n",
      "epoch:2 step:2016 [D loss: 0.944832, acc: 33.59%] [G loss: 1.363148]\n",
      "epoch:2 step:2017 [D loss: 0.519203, acc: 81.25%] [G loss: 1.679123]\n",
      "epoch:2 step:2018 [D loss: 0.721084, acc: 50.78%] [G loss: 1.442809]\n",
      "epoch:2 step:2019 [D loss: 0.643768, acc: 64.06%] [G loss: 1.415139]\n",
      "epoch:2 step:2020 [D loss: 0.731455, acc: 51.56%] [G loss: 1.486047]\n",
      "epoch:2 step:2021 [D loss: 0.673626, acc: 58.59%] [G loss: 1.442180]\n",
      "epoch:2 step:2022 [D loss: 0.547835, acc: 64.84%] [G loss: 1.416004]\n",
      "epoch:2 step:2023 [D loss: 0.920699, acc: 42.97%] [G loss: 1.624985]\n",
      "epoch:2 step:2024 [D loss: 0.620337, acc: 62.50%] [G loss: 1.671107]\n",
      "epoch:2 step:2025 [D loss: 1.125963, acc: 18.75%] [G loss: 1.254128]\n",
      "epoch:2 step:2026 [D loss: 0.898667, acc: 34.38%] [G loss: 1.507906]\n",
      "epoch:2 step:2027 [D loss: 0.853734, acc: 39.84%] [G loss: 1.540926]\n",
      "epoch:2 step:2028 [D loss: 0.695606, acc: 57.81%] [G loss: 1.866026]\n",
      "epoch:2 step:2029 [D loss: 0.674973, acc: 59.38%] [G loss: 1.858340]\n",
      "epoch:2 step:2030 [D loss: 0.678060, acc: 60.94%] [G loss: 1.803258]\n",
      "epoch:2 step:2031 [D loss: 0.694611, acc: 50.78%] [G loss: 1.910083]\n",
      "epoch:2 step:2032 [D loss: 0.702350, acc: 62.50%] [G loss: 2.110401]\n",
      "epoch:2 step:2033 [D loss: 0.606969, acc: 66.41%] [G loss: 1.775775]\n",
      "epoch:2 step:2034 [D loss: 0.694668, acc: 60.16%] [G loss: 1.973072]\n",
      "epoch:2 step:2035 [D loss: 0.610634, acc: 69.53%] [G loss: 1.743614]\n",
      "epoch:2 step:2036 [D loss: 0.635746, acc: 67.97%] [G loss: 1.697559]\n",
      "epoch:2 step:2037 [D loss: 0.737131, acc: 53.12%] [G loss: 1.807779]\n",
      "epoch:2 step:2038 [D loss: 0.758068, acc: 48.44%] [G loss: 1.781295]\n",
      "epoch:2 step:2039 [D loss: 0.495889, acc: 75.78%] [G loss: 2.047187]\n",
      "epoch:2 step:2040 [D loss: 0.830618, acc: 43.75%] [G loss: 1.611423]\n",
      "epoch:2 step:2041 [D loss: 0.782739, acc: 52.34%] [G loss: 1.351087]\n",
      "epoch:2 step:2042 [D loss: 0.738359, acc: 50.00%] [G loss: 1.668079]\n",
      "epoch:2 step:2043 [D loss: 0.602964, acc: 67.97%] [G loss: 1.592240]\n",
      "epoch:2 step:2044 [D loss: 0.854228, acc: 39.06%] [G loss: 1.617434]\n",
      "epoch:2 step:2045 [D loss: 0.686601, acc: 56.25%] [G loss: 1.511281]\n",
      "epoch:2 step:2046 [D loss: 0.818504, acc: 48.44%] [G loss: 1.704708]\n",
      "epoch:2 step:2047 [D loss: 0.946504, acc: 25.78%] [G loss: 1.576257]\n",
      "epoch:2 step:2048 [D loss: 0.762554, acc: 56.25%] [G loss: 1.378289]\n",
      "epoch:2 step:2049 [D loss: 0.919748, acc: 30.47%] [G loss: 1.421438]\n",
      "epoch:2 step:2050 [D loss: 0.895459, acc: 28.12%] [G loss: 1.471867]\n",
      "epoch:2 step:2051 [D loss: 0.916157, acc: 30.47%] [G loss: 1.451126]\n",
      "epoch:2 step:2052 [D loss: 0.954693, acc: 27.34%] [G loss: 1.203242]\n",
      "epoch:2 step:2053 [D loss: 0.712207, acc: 56.25%] [G loss: 1.579477]\n",
      "epoch:2 step:2054 [D loss: 0.878721, acc: 25.78%] [G loss: 1.547848]\n",
      "epoch:2 step:2055 [D loss: 1.019071, acc: 19.53%] [G loss: 1.364496]\n",
      "epoch:2 step:2056 [D loss: 0.912240, acc: 25.00%] [G loss: 1.465824]\n",
      "epoch:2 step:2057 [D loss: 0.847315, acc: 42.19%] [G loss: 1.546882]\n",
      "epoch:2 step:2058 [D loss: 0.801955, acc: 39.84%] [G loss: 1.581401]\n",
      "epoch:2 step:2059 [D loss: 0.744488, acc: 42.97%] [G loss: 1.632425]\n",
      "epoch:2 step:2060 [D loss: 0.754867, acc: 49.22%] [G loss: 1.498268]\n",
      "epoch:2 step:2061 [D loss: 0.846462, acc: 32.03%] [G loss: 1.463572]\n",
      "epoch:2 step:2062 [D loss: 0.851448, acc: 33.59%] [G loss: 1.405113]\n",
      "epoch:2 step:2063 [D loss: 0.858294, acc: 31.25%] [G loss: 1.467737]\n",
      "epoch:2 step:2064 [D loss: 0.708686, acc: 50.78%] [G loss: 1.498448]\n",
      "epoch:2 step:2065 [D loss: 0.859028, acc: 32.03%] [G loss: 1.454410]\n",
      "epoch:2 step:2066 [D loss: 0.782654, acc: 45.31%] [G loss: 1.689833]\n",
      "epoch:2 step:2067 [D loss: 0.778653, acc: 37.50%] [G loss: 1.605287]\n",
      "epoch:2 step:2068 [D loss: 0.728010, acc: 53.12%] [G loss: 1.723387]\n",
      "epoch:2 step:2069 [D loss: 0.693823, acc: 50.78%] [G loss: 1.867109]\n",
      "epoch:2 step:2070 [D loss: 0.811243, acc: 45.31%] [G loss: 1.673333]\n",
      "epoch:2 step:2071 [D loss: 0.624859, acc: 67.19%] [G loss: 1.871946]\n",
      "epoch:2 step:2072 [D loss: 0.681457, acc: 62.50%] [G loss: 1.699235]\n",
      "epoch:2 step:2073 [D loss: 0.764819, acc: 41.41%] [G loss: 1.627389]\n",
      "epoch:2 step:2074 [D loss: 0.682959, acc: 49.22%] [G loss: 1.700257]\n",
      "epoch:2 step:2075 [D loss: 0.733586, acc: 53.91%] [G loss: 1.714756]\n",
      "epoch:2 step:2076 [D loss: 0.788548, acc: 52.34%] [G loss: 1.696239]\n",
      "epoch:2 step:2077 [D loss: 0.828834, acc: 39.06%] [G loss: 1.512755]\n",
      "epoch:2 step:2078 [D loss: 0.739503, acc: 50.78%] [G loss: 1.593245]\n",
      "epoch:2 step:2079 [D loss: 0.535085, acc: 72.66%] [G loss: 1.810080]\n",
      "epoch:2 step:2080 [D loss: 0.903692, acc: 28.91%] [G loss: 1.389656]\n",
      "epoch:2 step:2081 [D loss: 0.988811, acc: 21.88%] [G loss: 1.314559]\n",
      "epoch:2 step:2082 [D loss: 0.726831, acc: 54.69%] [G loss: 1.612700]\n",
      "epoch:2 step:2083 [D loss: 0.717052, acc: 49.22%] [G loss: 1.696985]\n",
      "epoch:2 step:2084 [D loss: 0.731490, acc: 51.56%] [G loss: 1.493722]\n",
      "epoch:2 step:2085 [D loss: 0.686896, acc: 54.69%] [G loss: 1.648418]\n",
      "epoch:2 step:2086 [D loss: 0.682860, acc: 55.47%] [G loss: 1.733685]\n",
      "epoch:2 step:2087 [D loss: 0.787094, acc: 46.88%] [G loss: 1.639376]\n",
      "epoch:2 step:2088 [D loss: 0.735171, acc: 46.88%] [G loss: 1.743960]\n",
      "epoch:2 step:2089 [D loss: 0.764483, acc: 51.56%] [G loss: 1.742595]\n",
      "epoch:2 step:2090 [D loss: 0.670671, acc: 56.25%] [G loss: 1.688864]\n",
      "epoch:2 step:2091 [D loss: 0.809192, acc: 46.09%] [G loss: 1.568019]\n",
      "epoch:2 step:2092 [D loss: 0.695526, acc: 56.25%] [G loss: 1.576146]\n",
      "epoch:2 step:2093 [D loss: 0.952980, acc: 21.88%] [G loss: 1.448039]\n",
      "epoch:2 step:2094 [D loss: 0.764741, acc: 46.88%] [G loss: 1.634109]\n",
      "epoch:2 step:2095 [D loss: 0.689349, acc: 55.47%] [G loss: 1.762363]\n",
      "epoch:2 step:2096 [D loss: 0.710194, acc: 49.22%] [G loss: 1.614512]\n",
      "epoch:2 step:2097 [D loss: 0.902297, acc: 31.25%] [G loss: 1.335906]\n",
      "epoch:2 step:2098 [D loss: 0.740072, acc: 48.44%] [G loss: 1.565511]\n",
      "epoch:2 step:2099 [D loss: 0.751310, acc: 47.66%] [G loss: 1.548210]\n",
      "epoch:2 step:2100 [D loss: 0.789574, acc: 42.19%] [G loss: 1.560305]\n",
      "epoch:2 step:2101 [D loss: 0.678782, acc: 53.91%] [G loss: 1.629403]\n",
      "epoch:2 step:2102 [D loss: 0.754979, acc: 50.00%] [G loss: 1.648606]\n",
      "epoch:2 step:2103 [D loss: 0.754646, acc: 46.09%] [G loss: 1.508011]\n",
      "epoch:2 step:2104 [D loss: 0.825025, acc: 36.72%] [G loss: 1.460139]\n",
      "epoch:2 step:2105 [D loss: 0.789374, acc: 41.41%] [G loss: 1.474594]\n",
      "epoch:2 step:2106 [D loss: 0.818676, acc: 45.31%] [G loss: 1.481948]\n",
      "epoch:2 step:2107 [D loss: 0.846268, acc: 35.16%] [G loss: 1.491236]\n",
      "epoch:2 step:2108 [D loss: 0.792655, acc: 44.53%] [G loss: 1.635571]\n",
      "epoch:2 step:2109 [D loss: 0.779634, acc: 43.75%] [G loss: 1.621475]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:2 step:2110 [D loss: 0.836981, acc: 37.50%] [G loss: 1.586587]\n",
      "epoch:2 step:2111 [D loss: 0.803902, acc: 46.88%] [G loss: 1.567678]\n",
      "epoch:2 step:2112 [D loss: 0.755988, acc: 52.34%] [G loss: 1.535053]\n",
      "epoch:2 step:2113 [D loss: 0.641992, acc: 64.06%] [G loss: 1.618742]\n",
      "epoch:2 step:2114 [D loss: 0.848580, acc: 31.25%] [G loss: 1.378900]\n",
      "epoch:2 step:2115 [D loss: 0.811807, acc: 41.41%] [G loss: 1.590745]\n",
      "epoch:2 step:2116 [D loss: 0.736066, acc: 49.22%] [G loss: 1.673496]\n",
      "epoch:2 step:2117 [D loss: 0.660358, acc: 64.06%] [G loss: 1.666369]\n",
      "epoch:2 step:2118 [D loss: 0.754585, acc: 48.44%] [G loss: 1.527426]\n",
      "epoch:2 step:2119 [D loss: 0.734034, acc: 54.69%] [G loss: 1.608195]\n",
      "epoch:2 step:2120 [D loss: 0.732740, acc: 55.47%] [G loss: 1.602142]\n",
      "epoch:2 step:2121 [D loss: 0.769909, acc: 47.66%] [G loss: 1.507835]\n",
      "epoch:2 step:2122 [D loss: 0.810745, acc: 40.62%] [G loss: 1.518652]\n",
      "epoch:2 step:2123 [D loss: 0.744316, acc: 53.12%] [G loss: 1.555261]\n",
      "epoch:2 step:2124 [D loss: 0.704993, acc: 60.94%] [G loss: 1.679646]\n",
      "epoch:2 step:2125 [D loss: 0.804778, acc: 39.84%] [G loss: 1.544770]\n",
      "epoch:2 step:2126 [D loss: 0.701100, acc: 55.47%] [G loss: 1.724361]\n",
      "epoch:2 step:2127 [D loss: 0.674848, acc: 56.25%] [G loss: 1.605082]\n",
      "epoch:2 step:2128 [D loss: 0.689549, acc: 65.62%] [G loss: 1.687613]\n",
      "epoch:2 step:2129 [D loss: 0.714199, acc: 52.34%] [G loss: 1.734123]\n",
      "epoch:2 step:2130 [D loss: 0.724354, acc: 53.91%] [G loss: 1.553678]\n",
      "epoch:2 step:2131 [D loss: 0.703090, acc: 57.03%] [G loss: 1.396685]\n",
      "epoch:2 step:2132 [D loss: 0.712852, acc: 53.91%] [G loss: 1.609088]\n",
      "epoch:2 step:2133 [D loss: 0.687324, acc: 56.25%] [G loss: 1.766834]\n",
      "epoch:2 step:2134 [D loss: 0.659919, acc: 56.25%] [G loss: 1.657492]\n",
      "epoch:2 step:2135 [D loss: 0.589403, acc: 70.31%] [G loss: 1.799506]\n",
      "epoch:2 step:2136 [D loss: 0.746354, acc: 55.47%] [G loss: 1.197000]\n",
      "epoch:2 step:2137 [D loss: 0.657713, acc: 64.84%] [G loss: 1.519331]\n",
      "epoch:2 step:2138 [D loss: 0.595260, acc: 64.06%] [G loss: 1.636113]\n",
      "epoch:2 step:2139 [D loss: 0.725889, acc: 56.25%] [G loss: 1.669348]\n",
      "epoch:2 step:2140 [D loss: 0.815013, acc: 38.28%] [G loss: 1.509082]\n",
      "epoch:2 step:2141 [D loss: 0.642189, acc: 60.16%] [G loss: 1.558924]\n",
      "epoch:2 step:2142 [D loss: 0.810433, acc: 39.06%] [G loss: 1.464868]\n",
      "epoch:2 step:2143 [D loss: 0.828758, acc: 39.06%] [G loss: 1.561327]\n",
      "epoch:2 step:2144 [D loss: 0.690815, acc: 54.69%] [G loss: 1.680472]\n",
      "epoch:2 step:2145 [D loss: 0.611079, acc: 68.75%] [G loss: 1.711533]\n",
      "epoch:2 step:2146 [D loss: 0.728927, acc: 53.12%] [G loss: 1.585720]\n",
      "epoch:2 step:2147 [D loss: 0.844750, acc: 32.81%] [G loss: 1.455676]\n",
      "epoch:2 step:2148 [D loss: 0.786673, acc: 41.41%] [G loss: 1.582824]\n",
      "epoch:2 step:2149 [D loss: 0.791789, acc: 36.72%] [G loss: 1.452528]\n",
      "epoch:2 step:2150 [D loss: 0.832108, acc: 41.41%] [G loss: 1.585950]\n",
      "epoch:2 step:2151 [D loss: 0.675909, acc: 54.69%] [G loss: 1.589108]\n",
      "epoch:2 step:2152 [D loss: 0.760692, acc: 35.16%] [G loss: 1.614174]\n",
      "epoch:2 step:2153 [D loss: 0.743724, acc: 47.66%] [G loss: 1.566748]\n",
      "epoch:2 step:2154 [D loss: 0.667181, acc: 64.06%] [G loss: 1.765920]\n",
      "epoch:2 step:2155 [D loss: 0.769258, acc: 42.19%] [G loss: 1.583934]\n",
      "epoch:2 step:2156 [D loss: 0.657041, acc: 65.62%] [G loss: 1.775290]\n",
      "epoch:2 step:2157 [D loss: 0.789974, acc: 42.19%] [G loss: 1.528317]\n",
      "epoch:2 step:2158 [D loss: 0.675177, acc: 59.38%] [G loss: 1.532626]\n",
      "epoch:2 step:2159 [D loss: 0.702156, acc: 50.00%] [G loss: 1.702168]\n",
      "epoch:2 step:2160 [D loss: 0.690402, acc: 61.72%] [G loss: 1.568523]\n",
      "epoch:2 step:2161 [D loss: 0.668499, acc: 56.25%] [G loss: 1.577506]\n",
      "epoch:2 step:2162 [D loss: 0.618918, acc: 66.41%] [G loss: 1.722159]\n",
      "epoch:2 step:2163 [D loss: 0.726820, acc: 53.12%] [G loss: 1.544244]\n",
      "epoch:2 step:2164 [D loss: 0.702632, acc: 57.03%] [G loss: 1.523387]\n",
      "epoch:2 step:2165 [D loss: 0.447807, acc: 75.78%] [G loss: 1.801428]\n",
      "epoch:2 step:2166 [D loss: 0.871770, acc: 35.16%] [G loss: 1.594460]\n",
      "epoch:2 step:2167 [D loss: 0.710970, acc: 56.25%] [G loss: 1.565569]\n",
      "epoch:2 step:2168 [D loss: 0.613945, acc: 64.84%] [G loss: 1.833073]\n",
      "epoch:2 step:2169 [D loss: 0.679994, acc: 56.25%] [G loss: 1.722377]\n",
      "epoch:2 step:2170 [D loss: 0.568071, acc: 75.78%] [G loss: 1.621583]\n",
      "epoch:2 step:2171 [D loss: 0.652357, acc: 60.94%] [G loss: 1.636986]\n",
      "epoch:2 step:2172 [D loss: 0.759526, acc: 45.31%] [G loss: 1.487172]\n",
      "epoch:2 step:2173 [D loss: 0.674705, acc: 65.62%] [G loss: 1.580071]\n",
      "epoch:2 step:2174 [D loss: 0.723872, acc: 50.78%] [G loss: 1.638207]\n",
      "epoch:2 step:2175 [D loss: 0.826375, acc: 47.66%] [G loss: 1.402346]\n",
      "epoch:2 step:2176 [D loss: 0.538667, acc: 78.91%] [G loss: 1.654852]\n",
      "epoch:2 step:2177 [D loss: 0.545648, acc: 82.81%] [G loss: 1.612179]\n",
      "epoch:2 step:2178 [D loss: 0.382987, acc: 91.41%] [G loss: 1.707597]\n",
      "epoch:2 step:2179 [D loss: 1.029861, acc: 28.12%] [G loss: 1.288981]\n",
      "epoch:2 step:2180 [D loss: 0.752655, acc: 50.78%] [G loss: 1.672517]\n",
      "epoch:2 step:2181 [D loss: 0.610965, acc: 71.88%] [G loss: 1.507519]\n",
      "epoch:2 step:2182 [D loss: 0.883679, acc: 29.69%] [G loss: 1.373584]\n",
      "epoch:2 step:2183 [D loss: 0.586528, acc: 69.53%] [G loss: 1.635917]\n",
      "epoch:2 step:2184 [D loss: 0.782195, acc: 39.84%] [G loss: 1.439360]\n",
      "epoch:2 step:2185 [D loss: 0.840089, acc: 46.88%] [G loss: 1.264092]\n",
      "epoch:2 step:2186 [D loss: 0.799144, acc: 50.00%] [G loss: 1.654707]\n",
      "epoch:2 step:2187 [D loss: 0.724722, acc: 52.34%] [G loss: 1.617584]\n",
      "epoch:2 step:2188 [D loss: 0.906402, acc: 28.91%] [G loss: 1.383039]\n",
      "epoch:2 step:2189 [D loss: 0.851750, acc: 29.69%] [G loss: 1.457004]\n",
      "epoch:2 step:2190 [D loss: 0.916702, acc: 26.56%] [G loss: 1.524173]\n",
      "epoch:2 step:2191 [D loss: 0.756771, acc: 43.75%] [G loss: 1.490727]\n",
      "epoch:2 step:2192 [D loss: 0.690472, acc: 59.38%] [G loss: 1.650811]\n",
      "epoch:2 step:2193 [D loss: 0.696380, acc: 53.91%] [G loss: 1.594620]\n",
      "epoch:2 step:2194 [D loss: 0.807467, acc: 42.97%] [G loss: 1.671037]\n",
      "epoch:2 step:2195 [D loss: 0.788871, acc: 42.97%] [G loss: 1.519273]\n",
      "epoch:2 step:2196 [D loss: 0.701595, acc: 50.78%] [G loss: 1.568083]\n",
      "epoch:2 step:2197 [D loss: 0.638202, acc: 69.53%] [G loss: 1.756744]\n",
      "epoch:2 step:2198 [D loss: 0.768170, acc: 44.53%] [G loss: 1.613317]\n",
      "epoch:2 step:2199 [D loss: 0.802972, acc: 40.62%] [G loss: 1.555266]\n",
      "epoch:2 step:2200 [D loss: 0.698175, acc: 62.50%] [G loss: 1.750220]\n",
      "##############\n",
      "[0.85111521 0.85526108 0.83125218 0.80388843 0.78189687 0.81392529\n",
      " 0.88437909 0.8294086  0.80388948 0.83000021]\n",
      "##########\n",
      "epoch:2 step:2201 [D loss: 0.750718, acc: 48.44%] [G loss: 1.492771]\n",
      "epoch:2 step:2202 [D loss: 0.871795, acc: 32.81%] [G loss: 1.440968]\n",
      "epoch:2 step:2203 [D loss: 0.802105, acc: 39.84%] [G loss: 1.564780]\n",
      "epoch:2 step:2204 [D loss: 0.696846, acc: 56.25%] [G loss: 1.450836]\n",
      "epoch:2 step:2205 [D loss: 0.718143, acc: 50.00%] [G loss: 1.536766]\n",
      "epoch:2 step:2206 [D loss: 0.678469, acc: 51.56%] [G loss: 1.619983]\n",
      "epoch:2 step:2207 [D loss: 0.742731, acc: 52.34%] [G loss: 1.620878]\n",
      "epoch:2 step:2208 [D loss: 0.780349, acc: 45.31%] [G loss: 1.674431]\n",
      "epoch:2 step:2209 [D loss: 0.760984, acc: 49.22%] [G loss: 1.695587]\n",
      "epoch:2 step:2210 [D loss: 0.596049, acc: 70.31%] [G loss: 1.504861]\n",
      "epoch:2 step:2211 [D loss: 0.790013, acc: 45.31%] [G loss: 1.654362]\n",
      "epoch:2 step:2212 [D loss: 0.727729, acc: 54.69%] [G loss: 1.553965]\n",
      "epoch:2 step:2213 [D loss: 0.799032, acc: 41.41%] [G loss: 1.470013]\n",
      "epoch:2 step:2214 [D loss: 0.808592, acc: 35.94%] [G loss: 1.497425]\n",
      "epoch:2 step:2215 [D loss: 0.721205, acc: 46.09%] [G loss: 1.638667]\n",
      "epoch:2 step:2216 [D loss: 0.620423, acc: 68.75%] [G loss: 1.666188]\n",
      "epoch:2 step:2217 [D loss: 0.786350, acc: 44.53%] [G loss: 1.407877]\n",
      "epoch:2 step:2218 [D loss: 0.933159, acc: 28.12%] [G loss: 1.427277]\n",
      "epoch:2 step:2219 [D loss: 0.804359, acc: 39.06%] [G loss: 1.562634]\n",
      "epoch:2 step:2220 [D loss: 0.707124, acc: 53.91%] [G loss: 1.671127]\n",
      "epoch:2 step:2221 [D loss: 0.691111, acc: 57.03%] [G loss: 1.526349]\n",
      "epoch:2 step:2222 [D loss: 0.691573, acc: 53.91%] [G loss: 1.518117]\n",
      "epoch:2 step:2223 [D loss: 0.608357, acc: 70.31%] [G loss: 1.850938]\n",
      "epoch:2 step:2224 [D loss: 0.681855, acc: 62.50%] [G loss: 1.874286]\n",
      "epoch:2 step:2225 [D loss: 0.699055, acc: 53.91%] [G loss: 1.748245]\n",
      "epoch:2 step:2226 [D loss: 0.618389, acc: 68.75%] [G loss: 1.698758]\n",
      "epoch:2 step:2227 [D loss: 0.715867, acc: 57.81%] [G loss: 1.574988]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:2 step:2228 [D loss: 0.744886, acc: 49.22%] [G loss: 1.659932]\n",
      "epoch:2 step:2229 [D loss: 0.594895, acc: 67.97%] [G loss: 1.772380]\n",
      "epoch:2 step:2230 [D loss: 0.678218, acc: 55.47%] [G loss: 1.593375]\n",
      "epoch:2 step:2231 [D loss: 0.906880, acc: 34.38%] [G loss: 1.334103]\n",
      "epoch:2 step:2232 [D loss: 0.686183, acc: 60.16%] [G loss: 1.562875]\n",
      "epoch:2 step:2233 [D loss: 0.673225, acc: 55.47%] [G loss: 1.523071]\n",
      "epoch:2 step:2234 [D loss: 0.767415, acc: 49.22%] [G loss: 1.526258]\n",
      "epoch:2 step:2235 [D loss: 0.760810, acc: 50.00%] [G loss: 1.562738]\n",
      "epoch:2 step:2236 [D loss: 0.695405, acc: 56.25%] [G loss: 1.669038]\n",
      "epoch:2 step:2237 [D loss: 0.698775, acc: 56.25%] [G loss: 1.504458]\n",
      "epoch:2 step:2238 [D loss: 0.715601, acc: 56.25%] [G loss: 1.614285]\n",
      "epoch:2 step:2239 [D loss: 0.739292, acc: 50.00%] [G loss: 1.585264]\n",
      "epoch:2 step:2240 [D loss: 0.765657, acc: 42.97%] [G loss: 1.659375]\n",
      "epoch:2 step:2241 [D loss: 0.748084, acc: 49.22%] [G loss: 1.570547]\n",
      "epoch:2 step:2242 [D loss: 0.632213, acc: 61.72%] [G loss: 1.830375]\n",
      "epoch:2 step:2243 [D loss: 0.706630, acc: 59.38%] [G loss: 1.454552]\n",
      "epoch:2 step:2244 [D loss: 0.736171, acc: 47.66%] [G loss: 1.609844]\n",
      "epoch:2 step:2245 [D loss: 0.687639, acc: 55.47%] [G loss: 1.603464]\n",
      "epoch:2 step:2246 [D loss: 0.619068, acc: 69.53%] [G loss: 1.804796]\n",
      "epoch:2 step:2247 [D loss: 0.712833, acc: 60.94%] [G loss: 1.698220]\n",
      "epoch:2 step:2248 [D loss: 0.705740, acc: 56.25%] [G loss: 1.573652]\n",
      "epoch:2 step:2249 [D loss: 0.686450, acc: 57.81%] [G loss: 1.706653]\n",
      "epoch:2 step:2250 [D loss: 0.745067, acc: 46.09%] [G loss: 1.555987]\n",
      "epoch:2 step:2251 [D loss: 0.751450, acc: 49.22%] [G loss: 1.755524]\n",
      "epoch:2 step:2252 [D loss: 0.588727, acc: 72.66%] [G loss: 1.911977]\n",
      "epoch:2 step:2253 [D loss: 0.762328, acc: 46.88%] [G loss: 1.537086]\n",
      "epoch:2 step:2254 [D loss: 0.833486, acc: 33.59%] [G loss: 1.585182]\n",
      "epoch:2 step:2255 [D loss: 0.689650, acc: 50.78%] [G loss: 1.655176]\n",
      "epoch:2 step:2256 [D loss: 0.713085, acc: 54.69%] [G loss: 1.710952]\n",
      "epoch:2 step:2257 [D loss: 0.551684, acc: 70.31%] [G loss: 1.624845]\n",
      "epoch:2 step:2258 [D loss: 0.745970, acc: 44.53%] [G loss: 1.698073]\n",
      "epoch:2 step:2259 [D loss: 0.718206, acc: 51.56%] [G loss: 1.494085]\n",
      "epoch:2 step:2260 [D loss: 0.695173, acc: 53.91%] [G loss: 1.737560]\n",
      "epoch:2 step:2261 [D loss: 0.481876, acc: 82.03%] [G loss: 1.735780]\n",
      "epoch:2 step:2262 [D loss: 0.532690, acc: 83.59%] [G loss: 1.666427]\n",
      "epoch:2 step:2263 [D loss: 0.602690, acc: 71.88%] [G loss: 1.681521]\n",
      "epoch:2 step:2264 [D loss: 0.741946, acc: 49.22%] [G loss: 1.681635]\n",
      "epoch:2 step:2265 [D loss: 0.701065, acc: 57.81%] [G loss: 1.621909]\n",
      "epoch:2 step:2266 [D loss: 0.883564, acc: 43.75%] [G loss: 1.222625]\n",
      "epoch:2 step:2267 [D loss: 0.604592, acc: 63.28%] [G loss: 1.815767]\n",
      "epoch:2 step:2268 [D loss: 0.648937, acc: 65.62%] [G loss: 1.607655]\n",
      "epoch:2 step:2269 [D loss: 0.636357, acc: 62.50%] [G loss: 1.368604]\n",
      "epoch:2 step:2270 [D loss: 0.848265, acc: 43.75%] [G loss: 1.422944]\n",
      "epoch:2 step:2271 [D loss: 0.566484, acc: 74.22%] [G loss: 1.434227]\n",
      "epoch:2 step:2272 [D loss: 0.714802, acc: 56.25%] [G loss: 1.561667]\n",
      "epoch:2 step:2273 [D loss: 0.789664, acc: 41.41%] [G loss: 1.577281]\n",
      "epoch:2 step:2274 [D loss: 0.606448, acc: 71.09%] [G loss: 1.556924]\n",
      "epoch:2 step:2275 [D loss: 0.854016, acc: 42.97%] [G loss: 1.454692]\n",
      "epoch:2 step:2276 [D loss: 0.634886, acc: 68.75%] [G loss: 1.766132]\n",
      "epoch:2 step:2277 [D loss: 0.969688, acc: 22.66%] [G loss: 1.436580]\n",
      "epoch:2 step:2278 [D loss: 0.718430, acc: 54.69%] [G loss: 1.596557]\n",
      "epoch:2 step:2279 [D loss: 0.602872, acc: 65.62%] [G loss: 1.700014]\n",
      "epoch:2 step:2280 [D loss: 0.793641, acc: 44.53%] [G loss: 1.580882]\n",
      "epoch:2 step:2281 [D loss: 0.791960, acc: 41.41%] [G loss: 1.683900]\n",
      "epoch:2 step:2282 [D loss: 0.738402, acc: 49.22%] [G loss: 1.667874]\n",
      "epoch:2 step:2283 [D loss: 0.667707, acc: 59.38%] [G loss: 1.622140]\n",
      "epoch:2 step:2284 [D loss: 0.750963, acc: 52.34%] [G loss: 1.750777]\n",
      "epoch:2 step:2285 [D loss: 0.700475, acc: 50.78%] [G loss: 1.573136]\n",
      "epoch:2 step:2286 [D loss: 0.782813, acc: 47.66%] [G loss: 1.449141]\n",
      "epoch:2 step:2287 [D loss: 0.766375, acc: 46.09%] [G loss: 1.624096]\n",
      "epoch:2 step:2288 [D loss: 0.865013, acc: 33.59%] [G loss: 1.381964]\n",
      "epoch:2 step:2289 [D loss: 0.883242, acc: 28.91%] [G loss: 1.400873]\n",
      "epoch:2 step:2290 [D loss: 0.833658, acc: 34.38%] [G loss: 1.395985]\n",
      "epoch:2 step:2291 [D loss: 0.761942, acc: 44.53%] [G loss: 1.592297]\n",
      "epoch:2 step:2292 [D loss: 0.706126, acc: 53.91%] [G loss: 1.535330]\n",
      "epoch:2 step:2293 [D loss: 0.686331, acc: 57.03%] [G loss: 1.655766]\n",
      "epoch:2 step:2294 [D loss: 0.751704, acc: 48.44%] [G loss: 1.611277]\n",
      "epoch:2 step:2295 [D loss: 0.668832, acc: 61.72%] [G loss: 1.467486]\n",
      "epoch:2 step:2296 [D loss: 0.827885, acc: 43.75%] [G loss: 1.533883]\n",
      "epoch:2 step:2297 [D loss: 0.736984, acc: 50.00%] [G loss: 1.539220]\n",
      "epoch:2 step:2298 [D loss: 0.708200, acc: 51.56%] [G loss: 1.554039]\n",
      "epoch:2 step:2299 [D loss: 0.585471, acc: 67.97%] [G loss: 1.588535]\n",
      "epoch:2 step:2300 [D loss: 0.656821, acc: 60.94%] [G loss: 1.758665]\n",
      "epoch:2 step:2301 [D loss: 0.738666, acc: 50.78%] [G loss: 1.713188]\n",
      "epoch:2 step:2302 [D loss: 0.863731, acc: 31.25%] [G loss: 1.496774]\n",
      "epoch:2 step:2303 [D loss: 0.642525, acc: 63.28%] [G loss: 1.805768]\n",
      "epoch:2 step:2304 [D loss: 0.741579, acc: 46.09%] [G loss: 1.570209]\n",
      "epoch:2 step:2305 [D loss: 0.720245, acc: 59.38%] [G loss: 1.742748]\n",
      "epoch:2 step:2306 [D loss: 0.770528, acc: 39.06%] [G loss: 1.588617]\n",
      "epoch:2 step:2307 [D loss: 0.737200, acc: 48.44%] [G loss: 1.600953]\n",
      "epoch:2 step:2308 [D loss: 0.691691, acc: 57.03%] [G loss: 1.744370]\n",
      "epoch:2 step:2309 [D loss: 0.835901, acc: 38.28%] [G loss: 1.544051]\n",
      "epoch:2 step:2310 [D loss: 0.619052, acc: 64.06%] [G loss: 1.757841]\n",
      "epoch:2 step:2311 [D loss: 0.675297, acc: 56.25%] [G loss: 1.723541]\n",
      "epoch:2 step:2312 [D loss: 0.649632, acc: 64.06%] [G loss: 1.629552]\n",
      "epoch:2 step:2313 [D loss: 0.817005, acc: 42.19%] [G loss: 1.550560]\n",
      "epoch:2 step:2314 [D loss: 0.743635, acc: 48.44%] [G loss: 1.501724]\n",
      "epoch:2 step:2315 [D loss: 0.748360, acc: 45.31%] [G loss: 1.625191]\n",
      "epoch:2 step:2316 [D loss: 0.796962, acc: 39.06%] [G loss: 1.437002]\n",
      "epoch:2 step:2317 [D loss: 0.721603, acc: 58.59%] [G loss: 1.712250]\n",
      "epoch:2 step:2318 [D loss: 0.663581, acc: 57.03%] [G loss: 1.747405]\n",
      "epoch:2 step:2319 [D loss: 0.609763, acc: 70.31%] [G loss: 1.660906]\n",
      "epoch:2 step:2320 [D loss: 0.783857, acc: 45.31%] [G loss: 1.441233]\n",
      "epoch:2 step:2321 [D loss: 0.804652, acc: 39.06%] [G loss: 1.525215]\n",
      "epoch:2 step:2322 [D loss: 0.701704, acc: 53.91%] [G loss: 1.751893]\n",
      "epoch:2 step:2323 [D loss: 0.647883, acc: 68.75%] [G loss: 1.643126]\n",
      "epoch:2 step:2324 [D loss: 0.796349, acc: 35.94%] [G loss: 1.549247]\n",
      "epoch:2 step:2325 [D loss: 0.848664, acc: 38.28%] [G loss: 1.552054]\n",
      "epoch:2 step:2326 [D loss: 0.669118, acc: 60.16%] [G loss: 1.605883]\n",
      "epoch:2 step:2327 [D loss: 0.753738, acc: 46.88%] [G loss: 1.580963]\n",
      "epoch:2 step:2328 [D loss: 0.685113, acc: 51.56%] [G loss: 1.790106]\n",
      "epoch:2 step:2329 [D loss: 0.618684, acc: 68.75%] [G loss: 1.736152]\n",
      "epoch:2 step:2330 [D loss: 0.687453, acc: 55.47%] [G loss: 1.746821]\n",
      "epoch:2 step:2331 [D loss: 0.737102, acc: 51.56%] [G loss: 1.692015]\n",
      "epoch:2 step:2332 [D loss: 0.713149, acc: 59.38%] [G loss: 1.609869]\n",
      "epoch:2 step:2333 [D loss: 0.640696, acc: 64.06%] [G loss: 1.851236]\n",
      "epoch:2 step:2334 [D loss: 0.695929, acc: 59.38%] [G loss: 1.891204]\n",
      "epoch:2 step:2335 [D loss: 0.641465, acc: 62.50%] [G loss: 1.767001]\n",
      "epoch:2 step:2336 [D loss: 0.687833, acc: 57.03%] [G loss: 1.812885]\n",
      "epoch:2 step:2337 [D loss: 0.641748, acc: 68.75%] [G loss: 2.030372]\n",
      "epoch:2 step:2338 [D loss: 0.750959, acc: 49.22%] [G loss: 1.712972]\n",
      "epoch:2 step:2339 [D loss: 0.551758, acc: 71.88%] [G loss: 1.958591]\n",
      "epoch:2 step:2340 [D loss: 0.555529, acc: 71.88%] [G loss: 1.954436]\n",
      "epoch:2 step:2341 [D loss: 0.946063, acc: 29.69%] [G loss: 1.548586]\n",
      "epoch:2 step:2342 [D loss: 0.875242, acc: 32.81%] [G loss: 1.425357]\n",
      "epoch:2 step:2343 [D loss: 0.434630, acc: 88.28%] [G loss: 1.836693]\n",
      "epoch:3 step:2344 [D loss: 0.613966, acc: 67.97%] [G loss: 1.883926]\n",
      "epoch:3 step:2345 [D loss: 0.494304, acc: 77.34%] [G loss: 1.745245]\n",
      "epoch:3 step:2346 [D loss: 0.677744, acc: 57.03%] [G loss: 1.797880]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:3 step:2347 [D loss: 0.730826, acc: 53.12%] [G loss: 1.667848]\n",
      "epoch:3 step:2348 [D loss: 0.797103, acc: 39.84%] [G loss: 1.492692]\n",
      "epoch:3 step:2349 [D loss: 0.698760, acc: 57.81%] [G loss: 1.630250]\n",
      "epoch:3 step:2350 [D loss: 0.670362, acc: 60.94%] [G loss: 1.755260]\n",
      "epoch:3 step:2351 [D loss: 0.513601, acc: 75.00%] [G loss: 1.621064]\n",
      "epoch:3 step:2352 [D loss: 0.898185, acc: 33.59%] [G loss: 1.476630]\n",
      "epoch:3 step:2353 [D loss: 0.768634, acc: 50.78%] [G loss: 1.533442]\n",
      "epoch:3 step:2354 [D loss: 0.779807, acc: 43.75%] [G loss: 1.661176]\n",
      "epoch:3 step:2355 [D loss: 0.747780, acc: 57.03%] [G loss: 1.502502]\n",
      "epoch:3 step:2356 [D loss: 0.726009, acc: 53.91%] [G loss: 1.731629]\n",
      "epoch:3 step:2357 [D loss: 0.662054, acc: 61.72%] [G loss: 1.741555]\n",
      "epoch:3 step:2358 [D loss: 0.845903, acc: 39.84%] [G loss: 1.664958]\n",
      "epoch:3 step:2359 [D loss: 0.919146, acc: 28.91%] [G loss: 1.625262]\n",
      "epoch:3 step:2360 [D loss: 0.607538, acc: 66.41%] [G loss: 1.813256]\n",
      "epoch:3 step:2361 [D loss: 0.686378, acc: 60.16%] [G loss: 1.747840]\n",
      "epoch:3 step:2362 [D loss: 0.770340, acc: 49.22%] [G loss: 1.641649]\n",
      "epoch:3 step:2363 [D loss: 0.678578, acc: 61.72%] [G loss: 1.924355]\n",
      "epoch:3 step:2364 [D loss: 0.730131, acc: 56.25%] [G loss: 1.798656]\n",
      "epoch:3 step:2365 [D loss: 0.669335, acc: 67.19%] [G loss: 1.887893]\n",
      "epoch:3 step:2366 [D loss: 0.734777, acc: 53.12%] [G loss: 1.740861]\n",
      "epoch:3 step:2367 [D loss: 0.771276, acc: 47.66%] [G loss: 1.591369]\n",
      "epoch:3 step:2368 [D loss: 0.663847, acc: 65.62%] [G loss: 1.720127]\n",
      "epoch:3 step:2369 [D loss: 0.854198, acc: 33.59%] [G loss: 1.615391]\n",
      "epoch:3 step:2370 [D loss: 0.700101, acc: 55.47%] [G loss: 1.713551]\n",
      "epoch:3 step:2371 [D loss: 0.764734, acc: 45.31%] [G loss: 1.717379]\n",
      "epoch:3 step:2372 [D loss: 0.783690, acc: 38.28%] [G loss: 1.596150]\n",
      "epoch:3 step:2373 [D loss: 0.677637, acc: 54.69%] [G loss: 1.787143]\n",
      "epoch:3 step:2374 [D loss: 0.477265, acc: 80.47%] [G loss: 1.493896]\n",
      "epoch:3 step:2375 [D loss: 0.693530, acc: 57.03%] [G loss: 1.622269]\n",
      "epoch:3 step:2376 [D loss: 0.794620, acc: 45.31%] [G loss: 1.603587]\n",
      "epoch:3 step:2377 [D loss: 0.533996, acc: 78.91%] [G loss: 1.677999]\n",
      "epoch:3 step:2378 [D loss: 0.715151, acc: 51.56%] [G loss: 1.557848]\n",
      "epoch:3 step:2379 [D loss: 0.687742, acc: 62.50%] [G loss: 1.473648]\n",
      "epoch:3 step:2380 [D loss: 0.833315, acc: 35.16%] [G loss: 1.328057]\n",
      "epoch:3 step:2381 [D loss: 0.759479, acc: 45.31%] [G loss: 1.610842]\n",
      "epoch:3 step:2382 [D loss: 0.685186, acc: 57.03%] [G loss: 1.713338]\n",
      "epoch:3 step:2383 [D loss: 0.469660, acc: 82.81%] [G loss: 1.721700]\n",
      "epoch:3 step:2384 [D loss: 0.775282, acc: 44.53%] [G loss: 1.564201]\n",
      "epoch:3 step:2385 [D loss: 0.517688, acc: 76.56%] [G loss: 1.770332]\n",
      "epoch:3 step:2386 [D loss: 0.697256, acc: 54.69%] [G loss: 1.603492]\n",
      "epoch:3 step:2387 [D loss: 0.929722, acc: 24.22%] [G loss: 1.374049]\n",
      "epoch:3 step:2388 [D loss: 0.762202, acc: 44.53%] [G loss: 1.478720]\n",
      "epoch:3 step:2389 [D loss: 0.668577, acc: 59.38%] [G loss: 1.652842]\n",
      "epoch:3 step:2390 [D loss: 0.875344, acc: 29.69%] [G loss: 1.643622]\n",
      "epoch:3 step:2391 [D loss: 0.677227, acc: 64.06%] [G loss: 1.582017]\n",
      "epoch:3 step:2392 [D loss: 0.702733, acc: 53.91%] [G loss: 1.730469]\n",
      "epoch:3 step:2393 [D loss: 0.702260, acc: 54.69%] [G loss: 1.630279]\n",
      "epoch:3 step:2394 [D loss: 0.709064, acc: 57.81%] [G loss: 1.819093]\n",
      "epoch:3 step:2395 [D loss: 0.797342, acc: 43.75%] [G loss: 1.562523]\n",
      "epoch:3 step:2396 [D loss: 0.741260, acc: 53.91%] [G loss: 1.735521]\n",
      "epoch:3 step:2397 [D loss: 0.692452, acc: 60.94%] [G loss: 1.812398]\n",
      "epoch:3 step:2398 [D loss: 0.734056, acc: 50.78%] [G loss: 1.739350]\n",
      "epoch:3 step:2399 [D loss: 0.862802, acc: 38.28%] [G loss: 1.696306]\n",
      "epoch:3 step:2400 [D loss: 0.717349, acc: 48.44%] [G loss: 1.840826]\n",
      "##############\n",
      "[0.86454277 0.86763443 0.83868433 0.82180575 0.79036419 0.82187783\n",
      " 0.88247139 0.81688018 0.80822234 0.84398977]\n",
      "##########\n",
      "epoch:3 step:2401 [D loss: 0.618592, acc: 63.28%] [G loss: 1.672299]\n",
      "epoch:3 step:2402 [D loss: 0.678225, acc: 55.47%] [G loss: 1.675870]\n",
      "epoch:3 step:2403 [D loss: 0.555090, acc: 72.66%] [G loss: 1.732297]\n",
      "epoch:3 step:2404 [D loss: 0.582962, acc: 67.97%] [G loss: 1.671797]\n",
      "epoch:3 step:2405 [D loss: 0.746602, acc: 53.91%] [G loss: 1.727416]\n",
      "epoch:3 step:2406 [D loss: 0.579543, acc: 70.31%] [G loss: 1.504374]\n",
      "epoch:3 step:2407 [D loss: 0.439454, acc: 82.03%] [G loss: 1.737516]\n",
      "epoch:3 step:2408 [D loss: 0.260616, acc: 96.09%] [G loss: 1.901334]\n",
      "epoch:3 step:2409 [D loss: 0.496372, acc: 87.50%] [G loss: 1.514618]\n",
      "epoch:3 step:2410 [D loss: 0.902301, acc: 30.47%] [G loss: 1.057974]\n",
      "epoch:3 step:2411 [D loss: 0.431501, acc: 87.50%] [G loss: 1.557547]\n",
      "epoch:3 step:2412 [D loss: 0.276078, acc: 92.97%] [G loss: 1.754571]\n",
      "epoch:3 step:2413 [D loss: 0.681006, acc: 59.38%] [G loss: 1.315686]\n",
      "epoch:3 step:2414 [D loss: 0.721090, acc: 55.47%] [G loss: 1.479433]\n",
      "epoch:3 step:2415 [D loss: 1.082096, acc: 12.50%] [G loss: 1.185567]\n",
      "epoch:3 step:2416 [D loss: 0.655022, acc: 62.50%] [G loss: 1.377383]\n",
      "epoch:3 step:2417 [D loss: 0.712806, acc: 49.22%] [G loss: 1.308279]\n",
      "epoch:3 step:2418 [D loss: 0.555393, acc: 63.28%] [G loss: 1.365179]\n",
      "epoch:3 step:2419 [D loss: 0.565317, acc: 73.44%] [G loss: 1.615194]\n",
      "epoch:3 step:2420 [D loss: 0.708581, acc: 53.91%] [G loss: 1.528819]\n",
      "epoch:3 step:2421 [D loss: 0.525115, acc: 82.03%] [G loss: 1.656965]\n",
      "epoch:3 step:2422 [D loss: 0.588093, acc: 69.53%] [G loss: 1.681641]\n",
      "epoch:3 step:2423 [D loss: 0.835259, acc: 37.50%] [G loss: 1.843838]\n",
      "epoch:3 step:2424 [D loss: 1.084344, acc: 25.78%] [G loss: 1.277651]\n",
      "epoch:3 step:2425 [D loss: 0.603873, acc: 64.06%] [G loss: 1.594715]\n",
      "epoch:3 step:2426 [D loss: 0.910408, acc: 32.03%] [G loss: 1.572777]\n",
      "epoch:3 step:2427 [D loss: 1.200507, acc: 23.44%] [G loss: 1.323933]\n",
      "epoch:3 step:2428 [D loss: 0.655291, acc: 61.72%] [G loss: 1.956252]\n",
      "epoch:3 step:2429 [D loss: 0.695243, acc: 59.38%] [G loss: 1.915746]\n",
      "epoch:3 step:2430 [D loss: 0.654759, acc: 60.16%] [G loss: 1.944577]\n",
      "epoch:3 step:2431 [D loss: 0.866817, acc: 39.06%] [G loss: 1.581400]\n",
      "epoch:3 step:2432 [D loss: 0.728135, acc: 60.16%] [G loss: 1.886437]\n",
      "epoch:3 step:2433 [D loss: 0.793867, acc: 46.88%] [G loss: 1.524446]\n",
      "epoch:3 step:2434 [D loss: 0.585282, acc: 68.75%] [G loss: 1.880289]\n",
      "epoch:3 step:2435 [D loss: 0.569448, acc: 74.22%] [G loss: 1.758395]\n",
      "epoch:3 step:2436 [D loss: 0.527177, acc: 77.34%] [G loss: 1.885933]\n",
      "epoch:3 step:2437 [D loss: 0.529115, acc: 74.22%] [G loss: 1.975106]\n",
      "epoch:3 step:2438 [D loss: 0.600875, acc: 69.53%] [G loss: 1.773385]\n",
      "epoch:3 step:2439 [D loss: 0.448527, acc: 79.69%] [G loss: 1.688353]\n",
      "epoch:3 step:2440 [D loss: 0.701846, acc: 55.47%] [G loss: 1.590840]\n",
      "epoch:3 step:2441 [D loss: 0.824337, acc: 39.06%] [G loss: 1.472682]\n",
      "epoch:3 step:2442 [D loss: 0.755042, acc: 42.19%] [G loss: 1.333023]\n",
      "epoch:3 step:2443 [D loss: 0.625931, acc: 62.50%] [G loss: 1.524331]\n",
      "epoch:3 step:2444 [D loss: 0.776152, acc: 46.88%] [G loss: 1.223505]\n",
      "epoch:3 step:2445 [D loss: 0.577247, acc: 76.56%] [G loss: 1.533270]\n",
      "epoch:3 step:2446 [D loss: 0.825632, acc: 40.62%] [G loss: 1.258987]\n",
      "epoch:3 step:2447 [D loss: 0.573139, acc: 73.44%] [G loss: 1.642187]\n",
      "epoch:3 step:2448 [D loss: 0.854360, acc: 45.31%] [G loss: 1.509642]\n",
      "epoch:3 step:2449 [D loss: 0.616943, acc: 68.75%] [G loss: 1.626430]\n",
      "epoch:3 step:2450 [D loss: 0.785949, acc: 44.53%] [G loss: 1.478846]\n",
      "epoch:3 step:2451 [D loss: 0.544408, acc: 75.00%] [G loss: 2.005709]\n",
      "epoch:3 step:2452 [D loss: 1.018321, acc: 21.88%] [G loss: 1.425189]\n",
      "epoch:3 step:2453 [D loss: 0.662110, acc: 67.97%] [G loss: 1.819570]\n",
      "epoch:3 step:2454 [D loss: 1.113515, acc: 21.88%] [G loss: 1.380212]\n",
      "epoch:3 step:2455 [D loss: 0.438919, acc: 88.28%] [G loss: 1.853463]\n",
      "epoch:3 step:2456 [D loss: 0.717375, acc: 56.25%] [G loss: 1.696504]\n",
      "epoch:3 step:2457 [D loss: 0.693736, acc: 57.81%] [G loss: 1.866847]\n",
      "epoch:3 step:2458 [D loss: 0.770765, acc: 50.78%] [G loss: 1.813144]\n",
      "epoch:3 step:2459 [D loss: 0.736611, acc: 51.56%] [G loss: 1.938124]\n",
      "epoch:3 step:2460 [D loss: 0.542655, acc: 77.34%] [G loss: 2.016071]\n",
      "epoch:3 step:2461 [D loss: 0.614437, acc: 66.41%] [G loss: 1.814729]\n",
      "epoch:3 step:2462 [D loss: 0.615577, acc: 69.53%] [G loss: 1.797634]\n",
      "epoch:3 step:2463 [D loss: 0.707579, acc: 57.03%] [G loss: 1.835041]\n",
      "epoch:3 step:2464 [D loss: 0.754701, acc: 51.56%] [G loss: 1.787210]\n",
      "epoch:3 step:2465 [D loss: 0.626464, acc: 69.53%] [G loss: 2.050509]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:3 step:2466 [D loss: 0.666833, acc: 59.38%] [G loss: 1.838012]\n",
      "epoch:3 step:2467 [D loss: 0.540271, acc: 70.31%] [G loss: 1.966866]\n",
      "epoch:3 step:2468 [D loss: 0.676385, acc: 59.38%] [G loss: 1.868114]\n",
      "epoch:3 step:2469 [D loss: 0.765204, acc: 50.78%] [G loss: 1.329669]\n",
      "epoch:3 step:2470 [D loss: 0.870866, acc: 35.94%] [G loss: 1.681825]\n",
      "epoch:3 step:2471 [D loss: 0.580627, acc: 70.31%] [G loss: 1.737669]\n",
      "epoch:3 step:2472 [D loss: 0.472722, acc: 82.81%] [G loss: 2.095270]\n",
      "epoch:3 step:2473 [D loss: 0.806656, acc: 46.88%] [G loss: 1.394874]\n",
      "epoch:3 step:2474 [D loss: 0.784958, acc: 50.78%] [G loss: 1.782669]\n",
      "epoch:3 step:2475 [D loss: 0.602738, acc: 69.53%] [G loss: 1.764001]\n",
      "epoch:3 step:2476 [D loss: 0.621376, acc: 64.84%] [G loss: 1.895934]\n",
      "epoch:3 step:2477 [D loss: 0.629557, acc: 67.97%] [G loss: 1.731742]\n",
      "epoch:3 step:2478 [D loss: 0.650409, acc: 64.06%] [G loss: 1.671444]\n",
      "epoch:3 step:2479 [D loss: 0.892682, acc: 28.12%] [G loss: 1.620096]\n",
      "epoch:3 step:2480 [D loss: 0.793808, acc: 46.09%] [G loss: 1.492478]\n",
      "epoch:3 step:2481 [D loss: 0.794645, acc: 43.75%] [G loss: 1.687507]\n",
      "epoch:3 step:2482 [D loss: 0.795809, acc: 37.50%] [G loss: 1.607409]\n",
      "epoch:3 step:2483 [D loss: 0.715758, acc: 50.00%] [G loss: 1.853174]\n",
      "epoch:3 step:2484 [D loss: 0.825188, acc: 41.41%] [G loss: 1.654035]\n",
      "epoch:3 step:2485 [D loss: 0.702011, acc: 57.03%] [G loss: 1.767993]\n",
      "epoch:3 step:2486 [D loss: 0.840549, acc: 35.16%] [G loss: 1.638929]\n",
      "epoch:3 step:2487 [D loss: 0.657364, acc: 60.16%] [G loss: 1.640105]\n",
      "epoch:3 step:2488 [D loss: 0.667125, acc: 56.25%] [G loss: 1.654146]\n",
      "epoch:3 step:2489 [D loss: 0.583025, acc: 69.53%] [G loss: 1.919058]\n",
      "epoch:3 step:2490 [D loss: 0.696770, acc: 57.81%] [G loss: 1.956869]\n",
      "epoch:3 step:2491 [D loss: 0.669089, acc: 59.38%] [G loss: 1.662621]\n",
      "epoch:3 step:2492 [D loss: 0.441587, acc: 74.22%] [G loss: 1.902388]\n",
      "epoch:3 step:2493 [D loss: 0.811421, acc: 42.19%] [G loss: 1.674902]\n",
      "epoch:3 step:2494 [D loss: 0.729675, acc: 56.25%] [G loss: 1.839969]\n",
      "epoch:3 step:2495 [D loss: 0.681754, acc: 57.81%] [G loss: 1.787178]\n",
      "epoch:3 step:2496 [D loss: 0.627316, acc: 65.62%] [G loss: 1.701999]\n",
      "epoch:3 step:2497 [D loss: 0.708502, acc: 54.69%] [G loss: 1.609758]\n",
      "epoch:3 step:2498 [D loss: 0.523761, acc: 77.34%] [G loss: 1.646457]\n",
      "epoch:3 step:2499 [D loss: 0.684927, acc: 63.28%] [G loss: 1.690619]\n",
      "epoch:3 step:2500 [D loss: 0.545038, acc: 72.66%] [G loss: 1.698986]\n",
      "epoch:3 step:2501 [D loss: 0.832556, acc: 38.28%] [G loss: 1.519565]\n",
      "epoch:3 step:2502 [D loss: 0.514370, acc: 85.16%] [G loss: 1.720022]\n",
      "epoch:3 step:2503 [D loss: 0.907240, acc: 29.69%] [G loss: 1.400637]\n",
      "epoch:3 step:2504 [D loss: 0.505020, acc: 80.47%] [G loss: 1.661763]\n",
      "epoch:3 step:2505 [D loss: 0.733306, acc: 52.34%] [G loss: 1.793671]\n",
      "epoch:3 step:2506 [D loss: 0.738418, acc: 53.91%] [G loss: 1.615023]\n",
      "epoch:3 step:2507 [D loss: 0.786039, acc: 50.78%] [G loss: 1.588162]\n",
      "epoch:3 step:2508 [D loss: 0.476394, acc: 83.59%] [G loss: 1.903326]\n",
      "epoch:3 step:2509 [D loss: 1.001072, acc: 35.16%] [G loss: 1.369868]\n",
      "epoch:3 step:2510 [D loss: 0.719476, acc: 57.81%] [G loss: 1.644099]\n",
      "epoch:3 step:2511 [D loss: 0.508723, acc: 81.25%] [G loss: 1.926292]\n",
      "epoch:3 step:2512 [D loss: 0.635129, acc: 64.06%] [G loss: 1.537976]\n",
      "epoch:3 step:2513 [D loss: 0.775759, acc: 46.09%] [G loss: 1.640169]\n",
      "epoch:3 step:2514 [D loss: 0.845666, acc: 39.84%] [G loss: 1.371870]\n",
      "epoch:3 step:2515 [D loss: 0.803065, acc: 43.75%] [G loss: 1.567066]\n",
      "epoch:3 step:2516 [D loss: 0.682637, acc: 58.59%] [G loss: 1.974016]\n",
      "epoch:3 step:2517 [D loss: 0.632483, acc: 65.62%] [G loss: 1.541140]\n",
      "epoch:3 step:2518 [D loss: 0.786509, acc: 42.97%] [G loss: 1.596936]\n",
      "epoch:3 step:2519 [D loss: 0.840198, acc: 42.19%] [G loss: 1.507056]\n",
      "epoch:3 step:2520 [D loss: 0.730406, acc: 53.12%] [G loss: 1.545208]\n",
      "epoch:3 step:2521 [D loss: 0.872244, acc: 30.47%] [G loss: 1.530603]\n",
      "epoch:3 step:2522 [D loss: 0.940963, acc: 31.25%] [G loss: 1.424762]\n",
      "epoch:3 step:2523 [D loss: 0.822661, acc: 38.28%] [G loss: 1.550730]\n",
      "epoch:3 step:2524 [D loss: 0.676909, acc: 57.81%] [G loss: 1.601617]\n",
      "epoch:3 step:2525 [D loss: 0.711919, acc: 53.91%] [G loss: 1.649420]\n",
      "epoch:3 step:2526 [D loss: 0.602998, acc: 67.97%] [G loss: 1.947325]\n",
      "epoch:3 step:2527 [D loss: 0.678089, acc: 62.50%] [G loss: 1.772577]\n",
      "epoch:3 step:2528 [D loss: 0.882959, acc: 36.72%] [G loss: 1.531217]\n",
      "epoch:3 step:2529 [D loss: 0.649663, acc: 59.38%] [G loss: 1.725098]\n",
      "epoch:3 step:2530 [D loss: 0.799102, acc: 46.88%] [G loss: 1.818156]\n",
      "epoch:3 step:2531 [D loss: 0.456659, acc: 84.38%] [G loss: 1.791009]\n",
      "epoch:3 step:2532 [D loss: 0.646331, acc: 57.81%] [G loss: 1.733050]\n",
      "epoch:3 step:2533 [D loss: 0.627692, acc: 65.62%] [G loss: 1.721676]\n",
      "epoch:3 step:2534 [D loss: 0.680150, acc: 57.03%] [G loss: 1.807479]\n",
      "epoch:3 step:2535 [D loss: 0.483447, acc: 82.03%] [G loss: 1.690917]\n",
      "epoch:3 step:2536 [D loss: 0.661002, acc: 57.03%] [G loss: 1.850076]\n",
      "epoch:3 step:2537 [D loss: 0.550064, acc: 79.69%] [G loss: 1.501523]\n",
      "epoch:3 step:2538 [D loss: 0.800759, acc: 44.53%] [G loss: 1.653409]\n",
      "epoch:3 step:2539 [D loss: 0.930943, acc: 24.22%] [G loss: 1.353568]\n",
      "epoch:3 step:2540 [D loss: 0.626461, acc: 67.97%] [G loss: 1.608317]\n",
      "epoch:3 step:2541 [D loss: 0.448244, acc: 84.38%] [G loss: 1.861565]\n",
      "epoch:3 step:2542 [D loss: 0.771138, acc: 43.75%] [G loss: 1.500374]\n",
      "epoch:3 step:2543 [D loss: 0.738678, acc: 51.56%] [G loss: 1.751112]\n",
      "epoch:3 step:2544 [D loss: 0.686506, acc: 60.94%] [G loss: 1.580478]\n",
      "epoch:3 step:2545 [D loss: 0.934207, acc: 25.00%] [G loss: 1.423239]\n",
      "epoch:3 step:2546 [D loss: 0.650591, acc: 55.47%] [G loss: 1.864872]\n",
      "epoch:3 step:2547 [D loss: 0.702951, acc: 56.25%] [G loss: 1.862526]\n",
      "epoch:3 step:2548 [D loss: 1.189811, acc: 20.31%] [G loss: 1.271987]\n",
      "epoch:3 step:2549 [D loss: 0.657490, acc: 61.72%] [G loss: 1.720900]\n",
      "epoch:3 step:2550 [D loss: 0.866649, acc: 43.75%] [G loss: 1.579777]\n",
      "epoch:3 step:2551 [D loss: 0.678658, acc: 59.38%] [G loss: 1.848511]\n",
      "epoch:3 step:2552 [D loss: 0.774547, acc: 42.19%] [G loss: 1.718801]\n",
      "epoch:3 step:2553 [D loss: 0.546251, acc: 78.12%] [G loss: 1.807252]\n",
      "epoch:3 step:2554 [D loss: 0.727352, acc: 51.56%] [G loss: 1.690619]\n",
      "epoch:3 step:2555 [D loss: 0.800629, acc: 42.19%] [G loss: 1.683031]\n",
      "epoch:3 step:2556 [D loss: 0.850104, acc: 39.84%] [G loss: 1.505967]\n",
      "epoch:3 step:2557 [D loss: 0.705163, acc: 55.47%] [G loss: 1.709724]\n",
      "epoch:3 step:2558 [D loss: 0.690156, acc: 56.25%] [G loss: 1.703141]\n",
      "epoch:3 step:2559 [D loss: 0.733239, acc: 47.66%] [G loss: 1.724181]\n",
      "epoch:3 step:2560 [D loss: 0.710929, acc: 49.22%] [G loss: 1.511963]\n",
      "epoch:3 step:2561 [D loss: 0.719856, acc: 52.34%] [G loss: 1.614764]\n",
      "epoch:3 step:2562 [D loss: 0.684119, acc: 57.81%] [G loss: 1.768334]\n",
      "epoch:3 step:2563 [D loss: 0.702311, acc: 53.91%] [G loss: 1.782230]\n",
      "epoch:3 step:2564 [D loss: 0.647672, acc: 62.50%] [G loss: 1.721438]\n",
      "epoch:3 step:2565 [D loss: 0.722052, acc: 55.47%] [G loss: 1.874974]\n",
      "epoch:3 step:2566 [D loss: 0.702844, acc: 53.12%] [G loss: 1.809528]\n",
      "epoch:3 step:2567 [D loss: 0.834274, acc: 31.25%] [G loss: 1.423988]\n",
      "epoch:3 step:2568 [D loss: 0.745688, acc: 45.31%] [G loss: 1.717124]\n",
      "epoch:3 step:2569 [D loss: 0.703505, acc: 61.72%] [G loss: 1.754626]\n",
      "epoch:3 step:2570 [D loss: 0.761707, acc: 46.09%] [G loss: 1.691566]\n",
      "epoch:3 step:2571 [D loss: 0.496679, acc: 82.03%] [G loss: 2.185899]\n",
      "epoch:3 step:2572 [D loss: 0.585744, acc: 71.09%] [G loss: 1.910558]\n",
      "epoch:3 step:2573 [D loss: 0.809256, acc: 41.41%] [G loss: 1.818558]\n",
      "epoch:3 step:2574 [D loss: 0.581400, acc: 73.44%] [G loss: 2.157980]\n",
      "epoch:3 step:2575 [D loss: 0.691826, acc: 61.72%] [G loss: 1.825366]\n",
      "epoch:3 step:2576 [D loss: 0.549949, acc: 78.12%] [G loss: 2.078771]\n",
      "epoch:3 step:2577 [D loss: 0.528886, acc: 73.44%] [G loss: 2.021069]\n",
      "epoch:3 step:2578 [D loss: 0.658552, acc: 59.38%] [G loss: 1.894090]\n",
      "epoch:3 step:2579 [D loss: 0.871498, acc: 32.03%] [G loss: 1.601060]\n",
      "epoch:3 step:2580 [D loss: 0.525845, acc: 79.69%] [G loss: 1.891571]\n",
      "epoch:3 step:2581 [D loss: 0.470956, acc: 83.59%] [G loss: 1.421535]\n",
      "epoch:3 step:2582 [D loss: 0.613009, acc: 68.75%] [G loss: 1.903643]\n",
      "epoch:3 step:2583 [D loss: 0.823755, acc: 39.84%] [G loss: 1.610509]\n",
      "epoch:3 step:2584 [D loss: 0.345374, acc: 96.09%] [G loss: 2.040623]\n",
      "epoch:3 step:2585 [D loss: 0.583392, acc: 72.66%] [G loss: 1.712828]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:3 step:2586 [D loss: 0.499564, acc: 85.16%] [G loss: 1.755122]\n",
      "epoch:3 step:2587 [D loss: 0.438284, acc: 85.16%] [G loss: 1.756689]\n",
      "epoch:3 step:2588 [D loss: 0.511850, acc: 79.69%] [G loss: 1.718220]\n",
      "epoch:3 step:2589 [D loss: 0.685955, acc: 66.41%] [G loss: 1.330928]\n",
      "epoch:3 step:2590 [D loss: 0.582224, acc: 64.06%] [G loss: 1.413549]\n",
      "epoch:3 step:2591 [D loss: 0.576776, acc: 63.28%] [G loss: 1.947224]\n",
      "epoch:3 step:2592 [D loss: 0.825940, acc: 53.12%] [G loss: 1.317244]\n",
      "epoch:3 step:2593 [D loss: 0.689903, acc: 60.16%] [G loss: 1.994466]\n",
      "epoch:3 step:2594 [D loss: 0.607267, acc: 69.53%] [G loss: 1.645344]\n",
      "epoch:3 step:2595 [D loss: 0.716626, acc: 56.25%] [G loss: 2.048547]\n",
      "epoch:3 step:2596 [D loss: 0.849639, acc: 39.84%] [G loss: 1.653493]\n",
      "epoch:3 step:2597 [D loss: 0.612000, acc: 66.41%] [G loss: 2.128398]\n",
      "epoch:3 step:2598 [D loss: 0.698897, acc: 58.59%] [G loss: 1.913519]\n",
      "epoch:3 step:2599 [D loss: 0.907943, acc: 34.38%] [G loss: 1.651029]\n",
      "epoch:3 step:2600 [D loss: 0.630066, acc: 64.06%] [G loss: 1.655013]\n",
      "##############\n",
      "[0.8647271  0.85745531 0.83104122 0.81411103 0.79786199 0.79799909\n",
      " 0.88326558 0.84495219 0.80289918 0.82730313]\n",
      "##########\n",
      "epoch:3 step:2601 [D loss: 0.609701, acc: 71.88%] [G loss: 1.910288]\n",
      "epoch:3 step:2602 [D loss: 0.654253, acc: 67.19%] [G loss: 1.761510]\n",
      "epoch:3 step:2603 [D loss: 0.681570, acc: 56.25%] [G loss: 1.864962]\n",
      "epoch:3 step:2604 [D loss: 0.584904, acc: 72.66%] [G loss: 1.809963]\n",
      "epoch:3 step:2605 [D loss: 0.698220, acc: 53.12%] [G loss: 2.109419]\n",
      "epoch:3 step:2606 [D loss: 0.661810, acc: 57.81%] [G loss: 2.035692]\n",
      "epoch:3 step:2607 [D loss: 0.732556, acc: 50.78%] [G loss: 1.461225]\n",
      "epoch:3 step:2608 [D loss: 0.523096, acc: 76.56%] [G loss: 2.288941]\n",
      "epoch:3 step:2609 [D loss: 0.495780, acc: 82.81%] [G loss: 2.266913]\n",
      "epoch:3 step:2610 [D loss: 0.918426, acc: 43.75%] [G loss: 1.641146]\n",
      "epoch:3 step:2611 [D loss: 0.541039, acc: 75.00%] [G loss: 2.194437]\n",
      "epoch:3 step:2612 [D loss: 0.648331, acc: 60.16%] [G loss: 2.334748]\n",
      "epoch:3 step:2613 [D loss: 0.574621, acc: 71.09%] [G loss: 1.828713]\n",
      "epoch:3 step:2614 [D loss: 0.756497, acc: 50.78%] [G loss: 1.783365]\n",
      "epoch:3 step:2615 [D loss: 0.652675, acc: 57.81%] [G loss: 1.950822]\n",
      "epoch:3 step:2616 [D loss: 0.772944, acc: 49.22%] [G loss: 1.578453]\n",
      "epoch:3 step:2617 [D loss: 0.857321, acc: 39.06%] [G loss: 1.737374]\n",
      "epoch:3 step:2618 [D loss: 0.678760, acc: 55.47%] [G loss: 1.578440]\n",
      "epoch:3 step:2619 [D loss: 0.741126, acc: 50.00%] [G loss: 1.770139]\n",
      "epoch:3 step:2620 [D loss: 0.628270, acc: 64.06%] [G loss: 1.993093]\n",
      "epoch:3 step:2621 [D loss: 0.834147, acc: 37.50%] [G loss: 1.518678]\n",
      "epoch:3 step:2622 [D loss: 0.426561, acc: 90.62%] [G loss: 1.980517]\n",
      "epoch:3 step:2623 [D loss: 0.693971, acc: 59.38%] [G loss: 1.592710]\n",
      "epoch:3 step:2624 [D loss: 0.653642, acc: 62.50%] [G loss: 1.921595]\n",
      "epoch:3 step:2625 [D loss: 0.810106, acc: 37.50%] [G loss: 1.687299]\n",
      "epoch:3 step:2626 [D loss: 0.662926, acc: 59.38%] [G loss: 1.604915]\n",
      "epoch:3 step:2627 [D loss: 0.698414, acc: 54.69%] [G loss: 2.014648]\n",
      "epoch:3 step:2628 [D loss: 0.753828, acc: 49.22%] [G loss: 1.574654]\n",
      "epoch:3 step:2629 [D loss: 0.795934, acc: 46.09%] [G loss: 1.587963]\n",
      "epoch:3 step:2630 [D loss: 0.668217, acc: 60.16%] [G loss: 1.836395]\n",
      "epoch:3 step:2631 [D loss: 0.947267, acc: 28.91%] [G loss: 1.693574]\n",
      "epoch:3 step:2632 [D loss: 0.836995, acc: 36.72%] [G loss: 1.523843]\n",
      "epoch:3 step:2633 [D loss: 0.565505, acc: 71.88%] [G loss: 1.663337]\n",
      "epoch:3 step:2634 [D loss: 1.173210, acc: 23.44%] [G loss: 1.332899]\n",
      "epoch:3 step:2635 [D loss: 0.654611, acc: 60.16%] [G loss: 1.628859]\n",
      "epoch:3 step:2636 [D loss: 0.857350, acc: 38.28%] [G loss: 1.409664]\n",
      "epoch:3 step:2637 [D loss: 0.737560, acc: 55.47%] [G loss: 1.691912]\n",
      "epoch:3 step:2638 [D loss: 0.674886, acc: 59.38%] [G loss: 1.678762]\n",
      "epoch:3 step:2639 [D loss: 1.092741, acc: 19.53%] [G loss: 1.471224]\n",
      "epoch:3 step:2640 [D loss: 0.806918, acc: 42.97%] [G loss: 1.583352]\n",
      "epoch:3 step:2641 [D loss: 0.863964, acc: 31.25%] [G loss: 1.423994]\n",
      "epoch:3 step:2642 [D loss: 0.833559, acc: 38.28%] [G loss: 1.680496]\n",
      "epoch:3 step:2643 [D loss: 0.668817, acc: 62.50%] [G loss: 1.514446]\n",
      "epoch:3 step:2644 [D loss: 0.791838, acc: 37.50%] [G loss: 1.543975]\n",
      "epoch:3 step:2645 [D loss: 0.820482, acc: 35.16%] [G loss: 1.493299]\n",
      "epoch:3 step:2646 [D loss: 0.715201, acc: 50.00%] [G loss: 1.553912]\n",
      "epoch:3 step:2647 [D loss: 0.637507, acc: 68.75%] [G loss: 1.730862]\n",
      "epoch:3 step:2648 [D loss: 0.789124, acc: 39.84%] [G loss: 1.677695]\n",
      "epoch:3 step:2649 [D loss: 0.734694, acc: 53.91%] [G loss: 1.590341]\n",
      "epoch:3 step:2650 [D loss: 0.963932, acc: 23.44%] [G loss: 1.585333]\n",
      "epoch:3 step:2651 [D loss: 0.817619, acc: 42.97%] [G loss: 1.626655]\n",
      "epoch:3 step:2652 [D loss: 0.713174, acc: 56.25%] [G loss: 1.559509]\n",
      "epoch:3 step:2653 [D loss: 0.743256, acc: 52.34%] [G loss: 1.835658]\n",
      "epoch:3 step:2654 [D loss: 0.784122, acc: 48.44%] [G loss: 1.804006]\n",
      "epoch:3 step:2655 [D loss: 0.797640, acc: 36.72%] [G loss: 1.604725]\n",
      "epoch:3 step:2656 [D loss: 0.761944, acc: 51.56%] [G loss: 1.632552]\n",
      "epoch:3 step:2657 [D loss: 0.613917, acc: 67.19%] [G loss: 2.037979]\n",
      "epoch:3 step:2658 [D loss: 0.858943, acc: 36.72%] [G loss: 1.589427]\n",
      "epoch:3 step:2659 [D loss: 0.653242, acc: 64.06%] [G loss: 1.787843]\n",
      "epoch:3 step:2660 [D loss: 0.726312, acc: 49.22%] [G loss: 1.672264]\n",
      "epoch:3 step:2661 [D loss: 0.666252, acc: 58.59%] [G loss: 1.824682]\n",
      "epoch:3 step:2662 [D loss: 0.607644, acc: 67.97%] [G loss: 1.801785]\n",
      "epoch:3 step:2663 [D loss: 0.832712, acc: 43.75%] [G loss: 1.719859]\n",
      "epoch:3 step:2664 [D loss: 0.732152, acc: 53.12%] [G loss: 1.684336]\n",
      "epoch:3 step:2665 [D loss: 0.597086, acc: 74.22%] [G loss: 1.785233]\n",
      "epoch:3 step:2666 [D loss: 0.660052, acc: 60.16%] [G loss: 1.785744]\n",
      "epoch:3 step:2667 [D loss: 0.779624, acc: 46.09%] [G loss: 1.627332]\n",
      "epoch:3 step:2668 [D loss: 0.648207, acc: 64.06%] [G loss: 1.657121]\n",
      "epoch:3 step:2669 [D loss: 0.703312, acc: 52.34%] [G loss: 1.535605]\n",
      "epoch:3 step:2670 [D loss: 0.683524, acc: 57.81%] [G loss: 1.542878]\n",
      "epoch:3 step:2671 [D loss: 0.657696, acc: 55.47%] [G loss: 1.527573]\n",
      "epoch:3 step:2672 [D loss: 0.704423, acc: 49.22%] [G loss: 1.624175]\n",
      "epoch:3 step:2673 [D loss: 0.580278, acc: 71.88%] [G loss: 1.576079]\n",
      "epoch:3 step:2674 [D loss: 0.826121, acc: 34.38%] [G loss: 1.308522]\n",
      "epoch:3 step:2675 [D loss: 0.561592, acc: 75.00%] [G loss: 1.563273]\n",
      "epoch:3 step:2676 [D loss: 0.780924, acc: 39.84%] [G loss: 1.635143]\n",
      "epoch:3 step:2677 [D loss: 0.774524, acc: 49.22%] [G loss: 1.491322]\n",
      "epoch:3 step:2678 [D loss: 0.653411, acc: 58.59%] [G loss: 1.577465]\n",
      "epoch:3 step:2679 [D loss: 0.658329, acc: 57.81%] [G loss: 1.733722]\n",
      "epoch:3 step:2680 [D loss: 0.910009, acc: 32.03%] [G loss: 1.213012]\n",
      "epoch:3 step:2681 [D loss: 0.826173, acc: 37.50%] [G loss: 1.515344]\n",
      "epoch:3 step:2682 [D loss: 0.547673, acc: 71.88%] [G loss: 1.759925]\n",
      "epoch:3 step:2683 [D loss: 0.894147, acc: 34.38%] [G loss: 1.536901]\n",
      "epoch:3 step:2684 [D loss: 0.892212, acc: 35.94%] [G loss: 1.499609]\n",
      "epoch:3 step:2685 [D loss: 0.890838, acc: 31.25%] [G loss: 1.364415]\n",
      "epoch:3 step:2686 [D loss: 0.687290, acc: 55.47%] [G loss: 1.688847]\n",
      "epoch:3 step:2687 [D loss: 0.838399, acc: 32.81%] [G loss: 1.424133]\n",
      "epoch:3 step:2688 [D loss: 0.741193, acc: 59.38%] [G loss: 1.651636]\n",
      "epoch:3 step:2689 [D loss: 0.694796, acc: 51.56%] [G loss: 1.715974]\n",
      "epoch:3 step:2690 [D loss: 0.772522, acc: 40.62%] [G loss: 1.791333]\n",
      "epoch:3 step:2691 [D loss: 0.699132, acc: 50.78%] [G loss: 1.668791]\n",
      "epoch:3 step:2692 [D loss: 0.713282, acc: 54.69%] [G loss: 1.730541]\n",
      "epoch:3 step:2693 [D loss: 0.741615, acc: 50.78%] [G loss: 1.684373]\n",
      "epoch:3 step:2694 [D loss: 0.794119, acc: 46.88%] [G loss: 1.532054]\n",
      "epoch:3 step:2695 [D loss: 0.690839, acc: 60.16%] [G loss: 1.612567]\n",
      "epoch:3 step:2696 [D loss: 0.635862, acc: 66.41%] [G loss: 1.710574]\n",
      "epoch:3 step:2697 [D loss: 0.770590, acc: 48.44%] [G loss: 1.604854]\n",
      "epoch:3 step:2698 [D loss: 0.706179, acc: 57.03%] [G loss: 1.702732]\n",
      "epoch:3 step:2699 [D loss: 0.758430, acc: 48.44%] [G loss: 1.563495]\n",
      "epoch:3 step:2700 [D loss: 0.741477, acc: 51.56%] [G loss: 1.660954]\n",
      "epoch:3 step:2701 [D loss: 0.635720, acc: 60.16%] [G loss: 1.693865]\n",
      "epoch:3 step:2702 [D loss: 0.789456, acc: 44.53%] [G loss: 1.510848]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:3 step:2703 [D loss: 0.737750, acc: 46.88%] [G loss: 1.513742]\n",
      "epoch:3 step:2704 [D loss: 0.640782, acc: 64.06%] [G loss: 1.791842]\n",
      "epoch:3 step:2705 [D loss: 0.720239, acc: 54.69%] [G loss: 1.577214]\n",
      "epoch:3 step:2706 [D loss: 0.699946, acc: 57.03%] [G loss: 1.679166]\n",
      "epoch:3 step:2707 [D loss: 0.720119, acc: 57.03%] [G loss: 1.650408]\n",
      "epoch:3 step:2708 [D loss: 0.585617, acc: 72.66%] [G loss: 2.185859]\n",
      "epoch:3 step:2709 [D loss: 0.774737, acc: 44.53%] [G loss: 1.536501]\n",
      "epoch:3 step:2710 [D loss: 0.714669, acc: 60.16%] [G loss: 1.881079]\n",
      "epoch:3 step:2711 [D loss: 0.725898, acc: 50.00%] [G loss: 1.737691]\n",
      "epoch:3 step:2712 [D loss: 0.586528, acc: 70.31%] [G loss: 1.786786]\n",
      "epoch:3 step:2713 [D loss: 0.705201, acc: 53.12%] [G loss: 1.710350]\n",
      "epoch:3 step:2714 [D loss: 0.603924, acc: 69.53%] [G loss: 1.948283]\n",
      "epoch:3 step:2715 [D loss: 0.704688, acc: 57.03%] [G loss: 1.563104]\n",
      "epoch:3 step:2716 [D loss: 0.819409, acc: 43.75%] [G loss: 1.560823]\n",
      "epoch:3 step:2717 [D loss: 0.861086, acc: 34.38%] [G loss: 1.461587]\n",
      "epoch:3 step:2718 [D loss: 0.782900, acc: 41.41%] [G loss: 1.656573]\n",
      "epoch:3 step:2719 [D loss: 0.619578, acc: 67.19%] [G loss: 1.741078]\n",
      "epoch:3 step:2720 [D loss: 0.599468, acc: 73.44%] [G loss: 1.685029]\n",
      "epoch:3 step:2721 [D loss: 0.627122, acc: 63.28%] [G loss: 1.843821]\n",
      "epoch:3 step:2722 [D loss: 0.760194, acc: 46.88%] [G loss: 1.642952]\n",
      "epoch:3 step:2723 [D loss: 0.778575, acc: 50.78%] [G loss: 1.783341]\n",
      "epoch:3 step:2724 [D loss: 0.662483, acc: 57.03%] [G loss: 1.800884]\n",
      "epoch:3 step:2725 [D loss: 0.715405, acc: 52.34%] [G loss: 1.587088]\n",
      "epoch:3 step:2726 [D loss: 0.633624, acc: 63.28%] [G loss: 1.741702]\n",
      "epoch:3 step:2727 [D loss: 0.664962, acc: 58.59%] [G loss: 1.750272]\n",
      "epoch:3 step:2728 [D loss: 0.722035, acc: 46.88%] [G loss: 1.556123]\n",
      "epoch:3 step:2729 [D loss: 0.704306, acc: 52.34%] [G loss: 1.716735]\n",
      "epoch:3 step:2730 [D loss: 0.728200, acc: 57.03%] [G loss: 1.853534]\n",
      "epoch:3 step:2731 [D loss: 0.786356, acc: 35.16%] [G loss: 1.457424]\n",
      "epoch:3 step:2732 [D loss: 0.802140, acc: 35.94%] [G loss: 1.661008]\n",
      "epoch:3 step:2733 [D loss: 0.680241, acc: 64.06%] [G loss: 1.601565]\n",
      "epoch:3 step:2734 [D loss: 0.765745, acc: 44.53%] [G loss: 1.586705]\n",
      "epoch:3 step:2735 [D loss: 0.719138, acc: 53.12%] [G loss: 1.605190]\n",
      "epoch:3 step:2736 [D loss: 0.812485, acc: 36.72%] [G loss: 1.570679]\n",
      "epoch:3 step:2737 [D loss: 0.763506, acc: 45.31%] [G loss: 1.489862]\n",
      "epoch:3 step:2738 [D loss: 0.792705, acc: 42.19%] [G loss: 1.415612]\n",
      "epoch:3 step:2739 [D loss: 0.748357, acc: 42.19%] [G loss: 1.475280]\n",
      "epoch:3 step:2740 [D loss: 0.761563, acc: 46.88%] [G loss: 1.645627]\n",
      "epoch:3 step:2741 [D loss: 0.753167, acc: 45.31%] [G loss: 1.463253]\n",
      "epoch:3 step:2742 [D loss: 0.834146, acc: 28.91%] [G loss: 1.533507]\n",
      "epoch:3 step:2743 [D loss: 0.692139, acc: 56.25%] [G loss: 1.726309]\n",
      "epoch:3 step:2744 [D loss: 0.754738, acc: 48.44%] [G loss: 1.540218]\n",
      "epoch:3 step:2745 [D loss: 0.690794, acc: 56.25%] [G loss: 1.543998]\n",
      "epoch:3 step:2746 [D loss: 0.787991, acc: 39.06%] [G loss: 1.477205]\n",
      "epoch:3 step:2747 [D loss: 0.634374, acc: 64.84%] [G loss: 1.767514]\n",
      "epoch:3 step:2748 [D loss: 0.804545, acc: 38.28%] [G loss: 1.467617]\n",
      "epoch:3 step:2749 [D loss: 0.755872, acc: 42.19%] [G loss: 1.561794]\n",
      "epoch:3 step:2750 [D loss: 0.775777, acc: 45.31%] [G loss: 1.490486]\n",
      "epoch:3 step:2751 [D loss: 0.862148, acc: 28.12%] [G loss: 1.456587]\n",
      "epoch:3 step:2752 [D loss: 0.668053, acc: 57.81%] [G loss: 1.612999]\n",
      "epoch:3 step:2753 [D loss: 0.692235, acc: 59.38%] [G loss: 1.451303]\n",
      "epoch:3 step:2754 [D loss: 0.796115, acc: 39.84%] [G loss: 1.475984]\n",
      "epoch:3 step:2755 [D loss: 0.815019, acc: 36.72%] [G loss: 1.441475]\n",
      "epoch:3 step:2756 [D loss: 0.653514, acc: 63.28%] [G loss: 1.525961]\n",
      "epoch:3 step:2757 [D loss: 0.769286, acc: 39.84%] [G loss: 1.517066]\n",
      "epoch:3 step:2758 [D loss: 0.748294, acc: 45.31%] [G loss: 1.537975]\n",
      "epoch:3 step:2759 [D loss: 0.694788, acc: 53.91%] [G loss: 1.565235]\n",
      "epoch:3 step:2760 [D loss: 0.744950, acc: 52.34%] [G loss: 1.583552]\n",
      "epoch:3 step:2761 [D loss: 0.726875, acc: 46.09%] [G loss: 1.664350]\n",
      "epoch:3 step:2762 [D loss: 0.679993, acc: 59.38%] [G loss: 1.551586]\n",
      "epoch:3 step:2763 [D loss: 0.757578, acc: 42.19%] [G loss: 1.608830]\n",
      "epoch:3 step:2764 [D loss: 0.676935, acc: 60.16%] [G loss: 1.770609]\n",
      "epoch:3 step:2765 [D loss: 0.757731, acc: 43.75%] [G loss: 1.526302]\n",
      "epoch:3 step:2766 [D loss: 0.654079, acc: 60.94%] [G loss: 1.700758]\n",
      "epoch:3 step:2767 [D loss: 0.647352, acc: 64.84%] [G loss: 1.667359]\n",
      "epoch:3 step:2768 [D loss: 0.709598, acc: 53.12%] [G loss: 1.550406]\n",
      "epoch:3 step:2769 [D loss: 0.629641, acc: 65.62%] [G loss: 1.765369]\n",
      "epoch:3 step:2770 [D loss: 0.622683, acc: 68.75%] [G loss: 1.651265]\n",
      "epoch:3 step:2771 [D loss: 0.687574, acc: 53.12%] [G loss: 1.690525]\n",
      "epoch:3 step:2772 [D loss: 0.742031, acc: 47.66%] [G loss: 1.619453]\n",
      "epoch:3 step:2773 [D loss: 0.726818, acc: 49.22%] [G loss: 1.766105]\n",
      "epoch:3 step:2774 [D loss: 0.655131, acc: 64.06%] [G loss: 1.797198]\n",
      "epoch:3 step:2775 [D loss: 0.675212, acc: 52.34%] [G loss: 1.914963]\n",
      "epoch:3 step:2776 [D loss: 0.579691, acc: 74.22%] [G loss: 1.791582]\n",
      "epoch:3 step:2777 [D loss: 0.760494, acc: 45.31%] [G loss: 1.646596]\n",
      "epoch:3 step:2778 [D loss: 0.545427, acc: 78.91%] [G loss: 1.787329]\n",
      "epoch:3 step:2779 [D loss: 0.815816, acc: 34.38%] [G loss: 1.653947]\n",
      "epoch:3 step:2780 [D loss: 0.779216, acc: 50.00%] [G loss: 1.512446]\n",
      "epoch:3 step:2781 [D loss: 0.612381, acc: 68.75%] [G loss: 1.638907]\n",
      "epoch:3 step:2782 [D loss: 0.689398, acc: 57.81%] [G loss: 1.731707]\n",
      "epoch:3 step:2783 [D loss: 0.592279, acc: 67.19%] [G loss: 1.386253]\n",
      "epoch:3 step:2784 [D loss: 0.790630, acc: 49.22%] [G loss: 1.743655]\n",
      "epoch:3 step:2785 [D loss: 0.781643, acc: 43.75%] [G loss: 1.688235]\n",
      "epoch:3 step:2786 [D loss: 0.681568, acc: 61.72%] [G loss: 1.589025]\n",
      "epoch:3 step:2787 [D loss: 0.605084, acc: 71.09%] [G loss: 1.699079]\n",
      "epoch:3 step:2788 [D loss: 0.608890, acc: 70.31%] [G loss: 1.737974]\n",
      "epoch:3 step:2789 [D loss: 0.851920, acc: 39.06%] [G loss: 1.621327]\n",
      "epoch:3 step:2790 [D loss: 0.697471, acc: 57.81%] [G loss: 1.642108]\n",
      "epoch:3 step:2791 [D loss: 0.744804, acc: 42.97%] [G loss: 1.726248]\n",
      "epoch:3 step:2792 [D loss: 0.907470, acc: 33.59%] [G loss: 1.428469]\n",
      "epoch:3 step:2793 [D loss: 0.719719, acc: 50.00%] [G loss: 1.744580]\n",
      "epoch:3 step:2794 [D loss: 0.737763, acc: 46.88%] [G loss: 1.527633]\n",
      "epoch:3 step:2795 [D loss: 0.718288, acc: 53.91%] [G loss: 1.655588]\n",
      "epoch:3 step:2796 [D loss: 0.659384, acc: 58.59%] [G loss: 1.736268]\n",
      "epoch:3 step:2797 [D loss: 0.753586, acc: 48.44%] [G loss: 1.534576]\n",
      "epoch:3 step:2798 [D loss: 0.766830, acc: 46.88%] [G loss: 1.633561]\n",
      "epoch:3 step:2799 [D loss: 0.758355, acc: 48.44%] [G loss: 1.680885]\n",
      "epoch:3 step:2800 [D loss: 0.653942, acc: 63.28%] [G loss: 1.778083]\n",
      "##############\n",
      "[0.84546592 0.859262   0.82458239 0.81074719 0.79162114 0.84375075\n",
      " 0.88919903 0.84661567 0.80974918 0.80715891]\n",
      "##########\n",
      "epoch:3 step:2801 [D loss: 0.687429, acc: 56.25%] [G loss: 1.671541]\n",
      "epoch:3 step:2802 [D loss: 0.638855, acc: 64.84%] [G loss: 1.786587]\n",
      "epoch:3 step:2803 [D loss: 0.674036, acc: 60.94%] [G loss: 1.666513]\n",
      "epoch:3 step:2804 [D loss: 0.572355, acc: 72.66%] [G loss: 1.962367]\n",
      "epoch:3 step:2805 [D loss: 0.617716, acc: 70.31%] [G loss: 1.874800]\n",
      "epoch:3 step:2806 [D loss: 0.704231, acc: 57.81%] [G loss: 1.667054]\n",
      "epoch:3 step:2807 [D loss: 0.591313, acc: 67.97%] [G loss: 1.699985]\n",
      "epoch:3 step:2808 [D loss: 0.698229, acc: 54.69%] [G loss: 1.612324]\n",
      "epoch:3 step:2809 [D loss: 0.732899, acc: 47.66%] [G loss: 1.762319]\n",
      "epoch:3 step:2810 [D loss: 0.572175, acc: 71.88%] [G loss: 1.468428]\n",
      "epoch:3 step:2811 [D loss: 0.527753, acc: 76.56%] [G loss: 1.692761]\n",
      "epoch:3 step:2812 [D loss: 0.613804, acc: 75.78%] [G loss: 1.679987]\n",
      "epoch:3 step:2813 [D loss: 0.658608, acc: 60.16%] [G loss: 1.807246]\n",
      "epoch:3 step:2814 [D loss: 0.517737, acc: 78.91%] [G loss: 1.629057]\n",
      "epoch:3 step:2815 [D loss: 0.884948, acc: 36.72%] [G loss: 1.279786]\n",
      "epoch:3 step:2816 [D loss: 0.973723, acc: 18.75%] [G loss: 1.188407]\n",
      "epoch:3 step:2817 [D loss: 0.737720, acc: 46.88%] [G loss: 1.424384]\n",
      "epoch:3 step:2818 [D loss: 0.782608, acc: 42.97%] [G loss: 1.342016]\n",
      "epoch:3 step:2819 [D loss: 0.721901, acc: 50.00%] [G loss: 1.332374]\n",
      "epoch:3 step:2820 [D loss: 0.593515, acc: 72.66%] [G loss: 1.542289]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:3 step:2821 [D loss: 0.608522, acc: 69.53%] [G loss: 1.482768]\n",
      "epoch:3 step:2822 [D loss: 0.647776, acc: 64.84%] [G loss: 1.476324]\n",
      "epoch:3 step:2823 [D loss: 0.843056, acc: 32.81%] [G loss: 1.386338]\n",
      "epoch:3 step:2824 [D loss: 1.064218, acc: 21.88%] [G loss: 1.338753]\n",
      "epoch:3 step:2825 [D loss: 0.991060, acc: 21.09%] [G loss: 1.194920]\n",
      "epoch:3 step:2826 [D loss: 0.697329, acc: 50.78%] [G loss: 1.706095]\n",
      "epoch:3 step:2827 [D loss: 0.661404, acc: 64.06%] [G loss: 1.591745]\n",
      "epoch:3 step:2828 [D loss: 0.754779, acc: 47.66%] [G loss: 1.586256]\n",
      "epoch:3 step:2829 [D loss: 0.794176, acc: 42.97%] [G loss: 1.499873]\n",
      "epoch:3 step:2830 [D loss: 0.741633, acc: 51.56%] [G loss: 1.645197]\n",
      "epoch:3 step:2831 [D loss: 0.689955, acc: 63.28%] [G loss: 1.641905]\n",
      "epoch:3 step:2832 [D loss: 0.703350, acc: 56.25%] [G loss: 1.687448]\n",
      "epoch:3 step:2833 [D loss: 0.661879, acc: 66.41%] [G loss: 1.864515]\n",
      "epoch:3 step:2834 [D loss: 0.706973, acc: 52.34%] [G loss: 1.585715]\n",
      "epoch:3 step:2835 [D loss: 0.690009, acc: 57.03%] [G loss: 1.598691]\n",
      "epoch:3 step:2836 [D loss: 0.718733, acc: 55.47%] [G loss: 1.708825]\n",
      "epoch:3 step:2837 [D loss: 0.619257, acc: 67.19%] [G loss: 1.647833]\n",
      "epoch:3 step:2838 [D loss: 0.635250, acc: 65.62%] [G loss: 1.681435]\n",
      "epoch:3 step:2839 [D loss: 0.647756, acc: 64.06%] [G loss: 1.740960]\n",
      "epoch:3 step:2840 [D loss: 0.517192, acc: 70.31%] [G loss: 1.660680]\n",
      "epoch:3 step:2841 [D loss: 0.628764, acc: 67.19%] [G loss: 1.771525]\n",
      "epoch:3 step:2842 [D loss: 0.632151, acc: 64.84%] [G loss: 1.782965]\n",
      "epoch:3 step:2843 [D loss: 0.736089, acc: 53.91%] [G loss: 1.513693]\n",
      "epoch:3 step:2844 [D loss: 0.552109, acc: 72.66%] [G loss: 1.641363]\n",
      "epoch:3 step:2845 [D loss: 0.653990, acc: 58.59%] [G loss: 1.629892]\n",
      "epoch:3 step:2846 [D loss: 0.591998, acc: 67.97%] [G loss: 1.588280]\n",
      "epoch:3 step:2847 [D loss: 0.816862, acc: 38.28%] [G loss: 1.522667]\n",
      "epoch:3 step:2848 [D loss: 0.646234, acc: 60.94%] [G loss: 1.638880]\n",
      "epoch:3 step:2849 [D loss: 0.537767, acc: 77.34%] [G loss: 1.554791]\n",
      "epoch:3 step:2850 [D loss: 0.416749, acc: 82.03%] [G loss: 1.724007]\n",
      "epoch:3 step:2851 [D loss: 0.888049, acc: 25.78%] [G loss: 1.231915]\n",
      "epoch:3 step:2852 [D loss: 0.773990, acc: 53.91%] [G loss: 1.609795]\n",
      "epoch:3 step:2853 [D loss: 0.640864, acc: 60.94%] [G loss: 1.612139]\n",
      "epoch:3 step:2854 [D loss: 0.786902, acc: 45.31%] [G loss: 1.564545]\n",
      "epoch:3 step:2855 [D loss: 0.788321, acc: 50.78%] [G loss: 1.484511]\n",
      "epoch:3 step:2856 [D loss: 0.680168, acc: 53.12%] [G loss: 1.713401]\n",
      "epoch:3 step:2857 [D loss: 0.853885, acc: 34.38%] [G loss: 1.373555]\n",
      "epoch:3 step:2858 [D loss: 0.802493, acc: 49.22%] [G loss: 1.574008]\n",
      "epoch:3 step:2859 [D loss: 0.704505, acc: 57.81%] [G loss: 1.536191]\n",
      "epoch:3 step:2860 [D loss: 0.502653, acc: 85.94%] [G loss: 1.696277]\n",
      "epoch:3 step:2861 [D loss: 0.805171, acc: 44.53%] [G loss: 1.209534]\n",
      "epoch:3 step:2862 [D loss: 1.032234, acc: 23.44%] [G loss: 1.221515]\n",
      "epoch:3 step:2863 [D loss: 0.733725, acc: 49.22%] [G loss: 1.498172]\n",
      "epoch:3 step:2864 [D loss: 0.720472, acc: 52.34%] [G loss: 1.579215]\n",
      "epoch:3 step:2865 [D loss: 0.695900, acc: 55.47%] [G loss: 1.550383]\n",
      "epoch:3 step:2866 [D loss: 0.693454, acc: 57.81%] [G loss: 1.642073]\n",
      "epoch:3 step:2867 [D loss: 0.694074, acc: 56.25%] [G loss: 1.705639]\n",
      "epoch:3 step:2868 [D loss: 0.750447, acc: 44.53%] [G loss: 1.577624]\n",
      "epoch:3 step:2869 [D loss: 0.644362, acc: 62.50%] [G loss: 1.466303]\n",
      "epoch:3 step:2870 [D loss: 0.698209, acc: 57.03%] [G loss: 1.628928]\n",
      "epoch:3 step:2871 [D loss: 0.730341, acc: 50.78%] [G loss: 1.601812]\n",
      "epoch:3 step:2872 [D loss: 0.750991, acc: 42.97%] [G loss: 1.598787]\n",
      "epoch:3 step:2873 [D loss: 0.823932, acc: 37.50%] [G loss: 1.390663]\n",
      "epoch:3 step:2874 [D loss: 0.747483, acc: 49.22%] [G loss: 1.529523]\n",
      "epoch:3 step:2875 [D loss: 0.651849, acc: 60.94%] [G loss: 1.689351]\n",
      "epoch:3 step:2876 [D loss: 0.696078, acc: 53.91%] [G loss: 1.613034]\n",
      "epoch:3 step:2877 [D loss: 0.690270, acc: 50.78%] [G loss: 1.658697]\n",
      "epoch:3 step:2878 [D loss: 0.713354, acc: 53.12%] [G loss: 1.645905]\n",
      "epoch:3 step:2879 [D loss: 0.688371, acc: 53.91%] [G loss: 1.748632]\n",
      "epoch:3 step:2880 [D loss: 0.713123, acc: 53.91%] [G loss: 1.775011]\n",
      "epoch:3 step:2881 [D loss: 0.736979, acc: 49.22%] [G loss: 1.623301]\n",
      "epoch:3 step:2882 [D loss: 0.669229, acc: 58.59%] [G loss: 1.611328]\n",
      "epoch:3 step:2883 [D loss: 0.725983, acc: 51.56%] [G loss: 1.638648]\n",
      "epoch:3 step:2884 [D loss: 0.681796, acc: 60.94%] [G loss: 1.592909]\n",
      "epoch:3 step:2885 [D loss: 0.747440, acc: 47.66%] [G loss: 1.605369]\n",
      "epoch:3 step:2886 [D loss: 0.727145, acc: 52.34%] [G loss: 1.623556]\n",
      "epoch:3 step:2887 [D loss: 0.608026, acc: 66.41%] [G loss: 1.595693]\n",
      "epoch:3 step:2888 [D loss: 0.761781, acc: 38.28%] [G loss: 1.601536]\n",
      "epoch:3 step:2889 [D loss: 0.751609, acc: 49.22%] [G loss: 1.540181]\n",
      "epoch:3 step:2890 [D loss: 0.666856, acc: 61.72%] [G loss: 1.661599]\n",
      "epoch:3 step:2891 [D loss: 0.746054, acc: 46.09%] [G loss: 1.560704]\n",
      "epoch:3 step:2892 [D loss: 0.529320, acc: 75.00%] [G loss: 1.575388]\n",
      "epoch:3 step:2893 [D loss: 0.702861, acc: 59.38%] [G loss: 1.445029]\n",
      "epoch:3 step:2894 [D loss: 0.618918, acc: 66.41%] [G loss: 1.404742]\n",
      "epoch:3 step:2895 [D loss: 0.567805, acc: 70.31%] [G loss: 1.547380]\n",
      "epoch:3 step:2896 [D loss: 0.675434, acc: 60.16%] [G loss: 1.630917]\n",
      "epoch:3 step:2897 [D loss: 0.657043, acc: 63.28%] [G loss: 1.604443]\n",
      "epoch:3 step:2898 [D loss: 0.605759, acc: 64.84%] [G loss: 1.494283]\n",
      "epoch:3 step:2899 [D loss: 0.538583, acc: 79.69%] [G loss: 1.633049]\n",
      "epoch:3 step:2900 [D loss: 0.650904, acc: 63.28%] [G loss: 1.571084]\n",
      "epoch:3 step:2901 [D loss: 0.686392, acc: 55.47%] [G loss: 1.582195]\n",
      "epoch:3 step:2902 [D loss: 0.670895, acc: 53.12%] [G loss: 1.474470]\n",
      "epoch:3 step:2903 [D loss: 0.686650, acc: 55.47%] [G loss: 1.542585]\n",
      "epoch:3 step:2904 [D loss: 0.981820, acc: 16.41%] [G loss: 1.270468]\n",
      "epoch:3 step:2905 [D loss: 0.786463, acc: 44.53%] [G loss: 1.614458]\n",
      "epoch:3 step:2906 [D loss: 0.771604, acc: 45.31%] [G loss: 1.454863]\n",
      "epoch:3 step:2907 [D loss: 0.875963, acc: 33.59%] [G loss: 1.490671]\n",
      "epoch:3 step:2908 [D loss: 0.810360, acc: 37.50%] [G loss: 1.632538]\n",
      "epoch:3 step:2909 [D loss: 0.745627, acc: 50.00%] [G loss: 1.630966]\n",
      "epoch:3 step:2910 [D loss: 0.828825, acc: 38.28%] [G loss: 1.647695]\n",
      "epoch:3 step:2911 [D loss: 0.698518, acc: 51.56%] [G loss: 1.654439]\n",
      "epoch:3 step:2912 [D loss: 0.744173, acc: 51.56%] [G loss: 1.717864]\n",
      "epoch:3 step:2913 [D loss: 0.642208, acc: 64.06%] [G loss: 1.662461]\n",
      "epoch:3 step:2914 [D loss: 0.643070, acc: 67.19%] [G loss: 1.823250]\n",
      "epoch:3 step:2915 [D loss: 0.781515, acc: 42.97%] [G loss: 1.735504]\n",
      "epoch:3 step:2916 [D loss: 0.698932, acc: 57.03%] [G loss: 1.727275]\n",
      "epoch:3 step:2917 [D loss: 0.693348, acc: 59.38%] [G loss: 1.595305]\n",
      "epoch:3 step:2918 [D loss: 0.776721, acc: 44.53%] [G loss: 1.640984]\n",
      "epoch:3 step:2919 [D loss: 0.643789, acc: 63.28%] [G loss: 1.550907]\n",
      "epoch:3 step:2920 [D loss: 0.788539, acc: 46.09%] [G loss: 1.712392]\n",
      "epoch:3 step:2921 [D loss: 0.631482, acc: 58.59%] [G loss: 1.809175]\n",
      "epoch:3 step:2922 [D loss: 0.726646, acc: 52.34%] [G loss: 1.657510]\n",
      "epoch:3 step:2923 [D loss: 0.694564, acc: 50.78%] [G loss: 1.624939]\n",
      "epoch:3 step:2924 [D loss: 0.735903, acc: 44.53%] [G loss: 1.761603]\n",
      "epoch:3 step:2925 [D loss: 0.567831, acc: 72.66%] [G loss: 1.634377]\n",
      "epoch:3 step:2926 [D loss: 0.698460, acc: 59.38%] [G loss: 1.870224]\n",
      "epoch:3 step:2927 [D loss: 0.779585, acc: 40.62%] [G loss: 1.505932]\n",
      "epoch:3 step:2928 [D loss: 0.687288, acc: 55.47%] [G loss: 1.526716]\n",
      "epoch:3 step:2929 [D loss: 0.545561, acc: 71.88%] [G loss: 1.570616]\n",
      "epoch:3 step:2930 [D loss: 0.683670, acc: 58.59%] [G loss: 1.451039]\n",
      "epoch:3 step:2931 [D loss: 0.818719, acc: 41.41%] [G loss: 1.565943]\n",
      "epoch:3 step:2932 [D loss: 0.837429, acc: 35.94%] [G loss: 1.695278]\n",
      "epoch:3 step:2933 [D loss: 0.751837, acc: 52.34%] [G loss: 1.548245]\n",
      "epoch:3 step:2934 [D loss: 0.690026, acc: 55.47%] [G loss: 1.586307]\n",
      "epoch:3 step:2935 [D loss: 0.608514, acc: 67.19%] [G loss: 1.686262]\n",
      "epoch:3 step:2936 [D loss: 0.683237, acc: 58.59%] [G loss: 1.741589]\n",
      "epoch:3 step:2937 [D loss: 0.766169, acc: 45.31%] [G loss: 1.520220]\n",
      "epoch:3 step:2938 [D loss: 0.756106, acc: 41.41%] [G loss: 1.642980]\n",
      "epoch:3 step:2939 [D loss: 0.675641, acc: 59.38%] [G loss: 1.501693]\n",
      "epoch:3 step:2940 [D loss: 0.626774, acc: 67.19%] [G loss: 1.580510]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:3 step:2941 [D loss: 0.601738, acc: 71.88%] [G loss: 1.587919]\n",
      "epoch:3 step:2942 [D loss: 0.754658, acc: 42.19%] [G loss: 1.528554]\n",
      "epoch:3 step:2943 [D loss: 0.789573, acc: 43.75%] [G loss: 1.574846]\n",
      "epoch:3 step:2944 [D loss: 0.684160, acc: 56.25%] [G loss: 1.589714]\n",
      "epoch:3 step:2945 [D loss: 0.654764, acc: 65.62%] [G loss: 1.537987]\n",
      "epoch:3 step:2946 [D loss: 0.759240, acc: 53.12%] [G loss: 1.493121]\n",
      "epoch:3 step:2947 [D loss: 0.800136, acc: 38.28%] [G loss: 1.577805]\n",
      "epoch:3 step:2948 [D loss: 0.699356, acc: 57.81%] [G loss: 1.444892]\n",
      "epoch:3 step:2949 [D loss: 0.726974, acc: 48.44%] [G loss: 1.587761]\n",
      "epoch:3 step:2950 [D loss: 0.689541, acc: 54.69%] [G loss: 1.606577]\n",
      "epoch:3 step:2951 [D loss: 0.616536, acc: 69.53%] [G loss: 1.568004]\n",
      "epoch:3 step:2952 [D loss: 0.736483, acc: 47.66%] [G loss: 1.516418]\n",
      "epoch:3 step:2953 [D loss: 0.705114, acc: 51.56%] [G loss: 1.382892]\n",
      "epoch:3 step:2954 [D loss: 0.576163, acc: 75.00%] [G loss: 1.682142]\n",
      "epoch:3 step:2955 [D loss: 0.702317, acc: 53.12%] [G loss: 1.663739]\n",
      "epoch:3 step:2956 [D loss: 0.998424, acc: 22.66%] [G loss: 1.394407]\n",
      "epoch:3 step:2957 [D loss: 0.679858, acc: 56.25%] [G loss: 1.785841]\n",
      "epoch:3 step:2958 [D loss: 0.613681, acc: 66.41%] [G loss: 1.685581]\n",
      "epoch:3 step:2959 [D loss: 0.621324, acc: 61.72%] [G loss: 1.735425]\n",
      "epoch:3 step:2960 [D loss: 0.740027, acc: 46.88%] [G loss: 1.812319]\n",
      "epoch:3 step:2961 [D loss: 0.671585, acc: 61.72%] [G loss: 1.657766]\n",
      "epoch:3 step:2962 [D loss: 0.616537, acc: 69.53%] [G loss: 1.542346]\n",
      "epoch:3 step:2963 [D loss: 0.607830, acc: 61.72%] [G loss: 1.500052]\n",
      "epoch:3 step:2964 [D loss: 0.703840, acc: 51.56%] [G loss: 1.549120]\n",
      "epoch:3 step:2965 [D loss: 0.673866, acc: 60.94%] [G loss: 1.751094]\n",
      "epoch:3 step:2966 [D loss: 0.842800, acc: 37.50%] [G loss: 1.339207]\n",
      "epoch:3 step:2967 [D loss: 0.603337, acc: 68.75%] [G loss: 1.703652]\n",
      "epoch:3 step:2968 [D loss: 0.591750, acc: 72.66%] [G loss: 1.556841]\n",
      "epoch:3 step:2969 [D loss: 0.948244, acc: 30.47%] [G loss: 1.396797]\n",
      "epoch:3 step:2970 [D loss: 0.714888, acc: 50.78%] [G loss: 1.474032]\n",
      "epoch:3 step:2971 [D loss: 0.830630, acc: 41.41%] [G loss: 1.475990]\n",
      "epoch:3 step:2972 [D loss: 0.659697, acc: 64.06%] [G loss: 1.648550]\n",
      "epoch:3 step:2973 [D loss: 0.777506, acc: 38.28%] [G loss: 1.396425]\n",
      "epoch:3 step:2974 [D loss: 0.766746, acc: 44.53%] [G loss: 1.577254]\n",
      "epoch:3 step:2975 [D loss: 0.634571, acc: 67.97%] [G loss: 1.545978]\n",
      "epoch:3 step:2976 [D loss: 0.747684, acc: 43.75%] [G loss: 1.565077]\n",
      "epoch:3 step:2977 [D loss: 0.847394, acc: 33.59%] [G loss: 1.766034]\n",
      "epoch:3 step:2978 [D loss: 0.753444, acc: 48.44%] [G loss: 1.463327]\n",
      "epoch:3 step:2979 [D loss: 0.778487, acc: 42.19%] [G loss: 1.528657]\n",
      "epoch:3 step:2980 [D loss: 0.947221, acc: 32.03%] [G loss: 1.389814]\n",
      "epoch:3 step:2981 [D loss: 0.749773, acc: 46.88%] [G loss: 1.547417]\n",
      "epoch:3 step:2982 [D loss: 0.619932, acc: 64.06%] [G loss: 1.583139]\n",
      "epoch:3 step:2983 [D loss: 0.663222, acc: 61.72%] [G loss: 1.702457]\n",
      "epoch:3 step:2984 [D loss: 0.739701, acc: 42.97%] [G loss: 1.536166]\n",
      "epoch:3 step:2985 [D loss: 0.647706, acc: 63.28%] [G loss: 1.519213]\n",
      "epoch:3 step:2986 [D loss: 0.612888, acc: 70.31%] [G loss: 1.598136]\n",
      "epoch:3 step:2987 [D loss: 0.717759, acc: 50.78%] [G loss: 1.581239]\n",
      "epoch:3 step:2988 [D loss: 0.698256, acc: 56.25%] [G loss: 1.350910]\n",
      "epoch:3 step:2989 [D loss: 0.739790, acc: 50.78%] [G loss: 1.673424]\n",
      "epoch:3 step:2990 [D loss: 0.612098, acc: 68.75%] [G loss: 1.720186]\n",
      "epoch:3 step:2991 [D loss: 0.738731, acc: 42.97%] [G loss: 1.518963]\n",
      "epoch:3 step:2992 [D loss: 0.723625, acc: 44.53%] [G loss: 1.738097]\n",
      "epoch:3 step:2993 [D loss: 0.719530, acc: 52.34%] [G loss: 1.677154]\n",
      "epoch:3 step:2994 [D loss: 0.632870, acc: 65.62%] [G loss: 1.576673]\n",
      "epoch:3 step:2995 [D loss: 0.744581, acc: 53.91%] [G loss: 1.633804]\n",
      "epoch:3 step:2996 [D loss: 0.705770, acc: 53.12%] [G loss: 1.558517]\n",
      "epoch:3 step:2997 [D loss: 0.632768, acc: 64.84%] [G loss: 1.564705]\n",
      "epoch:3 step:2998 [D loss: 0.707718, acc: 54.69%] [G loss: 1.719777]\n",
      "epoch:3 step:2999 [D loss: 0.753470, acc: 49.22%] [G loss: 1.307412]\n",
      "epoch:3 step:3000 [D loss: 0.749580, acc: 53.12%] [G loss: 1.565103]\n",
      "##############\n",
      "[0.86715195 0.870847   0.81082416 0.84179725 0.80715165 0.8075482\n",
      " 0.91374942 0.82562154 0.8290383  0.8406163 ]\n",
      "##########\n",
      "epoch:3 step:3001 [D loss: 0.705370, acc: 55.47%] [G loss: 1.548181]\n",
      "epoch:3 step:3002 [D loss: 0.676998, acc: 56.25%] [G loss: 1.540689]\n",
      "epoch:3 step:3003 [D loss: 0.842557, acc: 32.03%] [G loss: 1.403931]\n",
      "epoch:3 step:3004 [D loss: 0.742505, acc: 50.78%] [G loss: 1.537519]\n",
      "epoch:3 step:3005 [D loss: 0.807427, acc: 36.72%] [G loss: 1.530564]\n",
      "epoch:3 step:3006 [D loss: 0.685406, acc: 57.03%] [G loss: 1.603149]\n",
      "epoch:3 step:3007 [D loss: 0.713003, acc: 48.44%] [G loss: 1.659282]\n",
      "epoch:3 step:3008 [D loss: 0.693817, acc: 54.69%] [G loss: 1.730146]\n",
      "epoch:3 step:3009 [D loss: 0.920798, acc: 24.22%] [G loss: 1.546789]\n",
      "epoch:3 step:3010 [D loss: 0.717716, acc: 48.44%] [G loss: 1.541160]\n",
      "epoch:3 step:3011 [D loss: 0.676915, acc: 62.50%] [G loss: 1.595860]\n",
      "epoch:3 step:3012 [D loss: 0.700688, acc: 55.47%] [G loss: 1.461947]\n",
      "epoch:3 step:3013 [D loss: 0.725241, acc: 54.69%] [G loss: 1.654470]\n",
      "epoch:3 step:3014 [D loss: 0.727532, acc: 49.22%] [G loss: 1.529398]\n",
      "epoch:3 step:3015 [D loss: 0.810711, acc: 44.53%] [G loss: 1.396950]\n",
      "epoch:3 step:3016 [D loss: 0.789514, acc: 39.84%] [G loss: 1.497651]\n",
      "epoch:3 step:3017 [D loss: 0.690511, acc: 58.59%] [G loss: 1.689122]\n",
      "epoch:3 step:3018 [D loss: 0.651572, acc: 64.84%] [G loss: 1.651849]\n",
      "epoch:3 step:3019 [D loss: 0.719022, acc: 46.88%] [G loss: 1.757165]\n",
      "epoch:3 step:3020 [D loss: 0.626090, acc: 63.28%] [G loss: 1.720389]\n",
      "epoch:3 step:3021 [D loss: 0.587439, acc: 71.09%] [G loss: 1.723602]\n",
      "epoch:3 step:3022 [D loss: 0.798547, acc: 34.38%] [G loss: 1.517980]\n",
      "epoch:3 step:3023 [D loss: 0.678646, acc: 57.81%] [G loss: 1.651755]\n",
      "epoch:3 step:3024 [D loss: 0.596140, acc: 67.97%] [G loss: 1.569241]\n",
      "epoch:3 step:3025 [D loss: 0.931982, acc: 21.09%] [G loss: 1.406932]\n",
      "epoch:3 step:3026 [D loss: 0.612844, acc: 67.19%] [G loss: 1.510596]\n",
      "epoch:3 step:3027 [D loss: 0.717986, acc: 52.34%] [G loss: 1.594658]\n",
      "epoch:3 step:3028 [D loss: 0.645659, acc: 66.41%] [G loss: 1.527432]\n",
      "epoch:3 step:3029 [D loss: 0.813537, acc: 32.03%] [G loss: 1.302652]\n",
      "epoch:3 step:3030 [D loss: 0.619646, acc: 66.41%] [G loss: 1.338680]\n",
      "epoch:3 step:3031 [D loss: 0.637553, acc: 66.41%] [G loss: 1.558560]\n",
      "epoch:3 step:3032 [D loss: 0.670340, acc: 60.94%] [G loss: 1.537880]\n",
      "epoch:3 step:3033 [D loss: 0.734296, acc: 46.88%] [G loss: 1.519734]\n",
      "epoch:3 step:3034 [D loss: 0.652951, acc: 65.62%] [G loss: 1.542913]\n",
      "epoch:3 step:3035 [D loss: 1.074843, acc: 14.84%] [G loss: 1.219405]\n",
      "epoch:3 step:3036 [D loss: 0.712317, acc: 51.56%] [G loss: 1.676233]\n",
      "epoch:3 step:3037 [D loss: 0.646996, acc: 62.50%] [G loss: 1.737223]\n",
      "epoch:3 step:3038 [D loss: 0.771915, acc: 45.31%] [G loss: 1.577600]\n",
      "epoch:3 step:3039 [D loss: 0.751124, acc: 46.88%] [G loss: 1.571919]\n",
      "epoch:3 step:3040 [D loss: 0.692903, acc: 53.91%] [G loss: 1.498671]\n",
      "epoch:3 step:3041 [D loss: 0.748056, acc: 51.56%] [G loss: 1.608198]\n",
      "epoch:3 step:3042 [D loss: 0.739513, acc: 46.88%] [G loss: 1.627186]\n",
      "epoch:3 step:3043 [D loss: 0.714350, acc: 53.12%] [G loss: 1.622255]\n",
      "epoch:3 step:3044 [D loss: 0.695193, acc: 59.38%] [G loss: 1.489161]\n",
      "epoch:3 step:3045 [D loss: 0.824643, acc: 39.06%] [G loss: 1.602681]\n",
      "epoch:3 step:3046 [D loss: 0.719671, acc: 48.44%] [G loss: 1.631660]\n",
      "epoch:3 step:3047 [D loss: 0.834355, acc: 33.59%] [G loss: 1.582138]\n",
      "epoch:3 step:3048 [D loss: 0.694175, acc: 55.47%] [G loss: 1.606151]\n",
      "epoch:3 step:3049 [D loss: 0.759443, acc: 45.31%] [G loss: 1.543330]\n",
      "epoch:3 step:3050 [D loss: 0.642398, acc: 63.28%] [G loss: 1.696633]\n",
      "epoch:3 step:3051 [D loss: 0.660246, acc: 67.97%] [G loss: 1.663074]\n",
      "epoch:3 step:3052 [D loss: 0.618659, acc: 69.53%] [G loss: 1.578975]\n",
      "epoch:3 step:3053 [D loss: 0.681855, acc: 58.59%] [G loss: 1.676121]\n",
      "epoch:3 step:3054 [D loss: 0.733520, acc: 46.88%] [G loss: 1.641188]\n",
      "epoch:3 step:3055 [D loss: 0.705409, acc: 56.25%] [G loss: 1.445737]\n",
      "epoch:3 step:3056 [D loss: 0.672059, acc: 55.47%] [G loss: 1.863090]\n",
      "epoch:3 step:3057 [D loss: 0.703611, acc: 55.47%] [G loss: 1.485703]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:3 step:3058 [D loss: 0.698706, acc: 55.47%] [G loss: 1.796570]\n",
      "epoch:3 step:3059 [D loss: 0.626116, acc: 64.84%] [G loss: 1.630990]\n",
      "epoch:3 step:3060 [D loss: 0.644743, acc: 60.16%] [G loss: 1.844083]\n",
      "epoch:3 step:3061 [D loss: 0.638022, acc: 64.06%] [G loss: 1.676678]\n",
      "epoch:3 step:3062 [D loss: 0.694569, acc: 53.91%] [G loss: 1.805152]\n",
      "epoch:3 step:3063 [D loss: 0.741421, acc: 46.88%] [G loss: 1.592762]\n",
      "epoch:3 step:3064 [D loss: 0.901395, acc: 25.78%] [G loss: 1.403986]\n",
      "epoch:3 step:3065 [D loss: 0.616171, acc: 71.88%] [G loss: 1.747314]\n",
      "epoch:3 step:3066 [D loss: 0.775935, acc: 39.84%] [G loss: 1.406186]\n",
      "epoch:3 step:3067 [D loss: 0.733802, acc: 41.41%] [G loss: 1.586699]\n",
      "epoch:3 step:3068 [D loss: 0.709509, acc: 54.69%] [G loss: 1.684932]\n",
      "epoch:3 step:3069 [D loss: 0.814782, acc: 34.38%] [G loss: 1.540930]\n",
      "epoch:3 step:3070 [D loss: 0.694926, acc: 55.47%] [G loss: 1.674557]\n",
      "epoch:3 step:3071 [D loss: 0.654084, acc: 61.72%] [G loss: 1.731118]\n",
      "epoch:3 step:3072 [D loss: 0.683739, acc: 55.47%] [G loss: 1.664008]\n",
      "epoch:3 step:3073 [D loss: 0.833578, acc: 33.59%] [G loss: 1.515652]\n",
      "epoch:3 step:3074 [D loss: 0.701832, acc: 57.81%] [G loss: 1.632310]\n",
      "epoch:3 step:3075 [D loss: 0.603679, acc: 67.97%] [G loss: 1.576655]\n",
      "epoch:3 step:3076 [D loss: 0.732259, acc: 46.88%] [G loss: 1.643591]\n",
      "epoch:3 step:3077 [D loss: 0.681822, acc: 58.59%] [G loss: 1.569266]\n",
      "epoch:3 step:3078 [D loss: 0.733470, acc: 46.88%] [G loss: 1.575313]\n",
      "epoch:3 step:3079 [D loss: 0.632214, acc: 60.94%] [G loss: 1.779705]\n",
      "epoch:3 step:3080 [D loss: 0.691478, acc: 53.12%] [G loss: 1.443754]\n",
      "epoch:3 step:3081 [D loss: 0.673727, acc: 57.81%] [G loss: 1.515706]\n",
      "epoch:3 step:3082 [D loss: 0.710909, acc: 52.34%] [G loss: 1.541356]\n",
      "epoch:3 step:3083 [D loss: 0.569755, acc: 74.22%] [G loss: 1.678551]\n",
      "epoch:3 step:3084 [D loss: 0.743255, acc: 53.12%] [G loss: 1.587265]\n",
      "epoch:3 step:3085 [D loss: 0.779776, acc: 40.62%] [G loss: 1.318616]\n",
      "epoch:3 step:3086 [D loss: 0.717926, acc: 50.78%] [G loss: 1.569078]\n",
      "epoch:3 step:3087 [D loss: 0.662662, acc: 61.72%] [G loss: 1.552333]\n",
      "epoch:3 step:3088 [D loss: 0.692603, acc: 55.47%] [G loss: 1.483012]\n",
      "epoch:3 step:3089 [D loss: 0.655122, acc: 59.38%] [G loss: 1.450729]\n",
      "epoch:3 step:3090 [D loss: 0.570622, acc: 71.09%] [G loss: 1.612592]\n",
      "epoch:3 step:3091 [D loss: 0.748811, acc: 47.66%] [G loss: 1.529104]\n",
      "epoch:3 step:3092 [D loss: 0.710951, acc: 52.34%] [G loss: 1.501538]\n",
      "epoch:3 step:3093 [D loss: 0.603037, acc: 68.75%] [G loss: 1.487434]\n",
      "epoch:3 step:3094 [D loss: 0.502088, acc: 77.34%] [G loss: 1.520363]\n",
      "epoch:3 step:3095 [D loss: 0.528796, acc: 84.38%] [G loss: 1.666774]\n",
      "epoch:3 step:3096 [D loss: 0.859582, acc: 30.47%] [G loss: 1.258388]\n",
      "epoch:3 step:3097 [D loss: 0.826461, acc: 39.06%] [G loss: 1.391566]\n",
      "epoch:3 step:3098 [D loss: 0.788423, acc: 50.00%] [G loss: 1.447060]\n",
      "epoch:3 step:3099 [D loss: 0.568062, acc: 76.56%] [G loss: 1.550608]\n",
      "epoch:3 step:3100 [D loss: 0.703728, acc: 54.69%] [G loss: 1.574846]\n",
      "epoch:3 step:3101 [D loss: 0.760001, acc: 50.00%] [G loss: 1.286398]\n",
      "epoch:3 step:3102 [D loss: 0.842664, acc: 35.94%] [G loss: 1.424682]\n",
      "epoch:3 step:3103 [D loss: 0.701559, acc: 53.91%] [G loss: 1.659584]\n",
      "epoch:3 step:3104 [D loss: 0.731590, acc: 50.78%] [G loss: 1.647155]\n",
      "epoch:3 step:3105 [D loss: 0.727148, acc: 47.66%] [G loss: 1.626978]\n",
      "epoch:3 step:3106 [D loss: 0.736459, acc: 46.88%] [G loss: 1.567505]\n",
      "epoch:3 step:3107 [D loss: 0.778908, acc: 43.75%] [G loss: 1.753435]\n",
      "epoch:3 step:3108 [D loss: 0.552472, acc: 71.09%] [G loss: 1.662945]\n",
      "epoch:3 step:3109 [D loss: 0.700191, acc: 52.34%] [G loss: 1.879236]\n",
      "epoch:3 step:3110 [D loss: 0.563248, acc: 80.47%] [G loss: 1.806143]\n",
      "epoch:3 step:3111 [D loss: 0.522915, acc: 75.00%] [G loss: 1.887913]\n",
      "epoch:3 step:3112 [D loss: 0.742189, acc: 46.09%] [G loss: 1.682595]\n",
      "epoch:3 step:3113 [D loss: 0.659003, acc: 60.94%] [G loss: 1.678647]\n",
      "epoch:3 step:3114 [D loss: 0.671901, acc: 60.94%] [G loss: 1.873288]\n",
      "epoch:3 step:3115 [D loss: 0.669293, acc: 60.94%] [G loss: 1.724301]\n",
      "epoch:3 step:3116 [D loss: 0.700865, acc: 56.25%] [G loss: 1.683579]\n",
      "epoch:3 step:3117 [D loss: 0.669505, acc: 58.59%] [G loss: 1.652913]\n",
      "epoch:3 step:3118 [D loss: 0.563092, acc: 68.75%] [G loss: 1.522101]\n",
      "epoch:3 step:3119 [D loss: 0.517129, acc: 78.12%] [G loss: 1.702555]\n",
      "epoch:3 step:3120 [D loss: 0.948178, acc: 27.34%] [G loss: 1.371220]\n",
      "epoch:3 step:3121 [D loss: 0.679597, acc: 59.38%] [G loss: 1.621374]\n",
      "epoch:3 step:3122 [D loss: 0.895847, acc: 36.72%] [G loss: 1.521661]\n",
      "epoch:3 step:3123 [D loss: 0.940990, acc: 27.34%] [G loss: 1.189092]\n",
      "epoch:3 step:3124 [D loss: 0.492123, acc: 84.38%] [G loss: 1.850626]\n",
      "epoch:4 step:3125 [D loss: 0.670832, acc: 55.47%] [G loss: 1.721542]\n",
      "epoch:4 step:3126 [D loss: 0.735924, acc: 50.00%] [G loss: 1.602926]\n",
      "epoch:4 step:3127 [D loss: 0.628255, acc: 64.84%] [G loss: 1.825990]\n",
      "epoch:4 step:3128 [D loss: 0.624245, acc: 65.62%] [G loss: 1.807077]\n",
      "epoch:4 step:3129 [D loss: 0.783883, acc: 48.44%] [G loss: 1.603786]\n",
      "epoch:4 step:3130 [D loss: 0.555376, acc: 76.56%] [G loss: 1.881863]\n",
      "epoch:4 step:3131 [D loss: 0.710337, acc: 60.94%] [G loss: 1.825067]\n",
      "epoch:4 step:3132 [D loss: 0.562119, acc: 65.62%] [G loss: 1.674504]\n",
      "epoch:4 step:3133 [D loss: 0.841497, acc: 30.47%] [G loss: 1.464524]\n",
      "epoch:4 step:3134 [D loss: 0.726991, acc: 50.78%] [G loss: 1.733578]\n",
      "epoch:4 step:3135 [D loss: 0.657183, acc: 60.94%] [G loss: 1.545897]\n",
      "epoch:4 step:3136 [D loss: 0.739350, acc: 48.44%] [G loss: 1.660049]\n",
      "epoch:4 step:3137 [D loss: 0.617921, acc: 68.75%] [G loss: 1.648884]\n",
      "epoch:4 step:3138 [D loss: 0.750778, acc: 47.66%] [G loss: 1.774865]\n",
      "epoch:4 step:3139 [D loss: 0.681549, acc: 57.03%] [G loss: 1.784452]\n",
      "epoch:4 step:3140 [D loss: 0.690840, acc: 52.34%] [G loss: 1.682457]\n",
      "epoch:4 step:3141 [D loss: 0.751390, acc: 46.09%] [G loss: 1.617749]\n",
      "epoch:4 step:3142 [D loss: 0.721430, acc: 46.88%] [G loss: 1.584333]\n",
      "epoch:4 step:3143 [D loss: 0.691218, acc: 55.47%] [G loss: 1.831710]\n",
      "epoch:4 step:3144 [D loss: 0.734939, acc: 49.22%] [G loss: 1.752073]\n",
      "epoch:4 step:3145 [D loss: 0.676070, acc: 52.34%] [G loss: 1.696359]\n",
      "epoch:4 step:3146 [D loss: 0.738095, acc: 50.78%] [G loss: 1.604244]\n",
      "epoch:4 step:3147 [D loss: 0.761693, acc: 46.09%] [G loss: 1.602848]\n",
      "epoch:4 step:3148 [D loss: 0.743059, acc: 50.78%] [G loss: 1.532755]\n",
      "epoch:4 step:3149 [D loss: 0.710528, acc: 47.66%] [G loss: 1.523736]\n",
      "epoch:4 step:3150 [D loss: 0.703005, acc: 50.00%] [G loss: 1.564820]\n",
      "epoch:4 step:3151 [D loss: 0.647672, acc: 60.94%] [G loss: 1.698010]\n",
      "epoch:4 step:3152 [D loss: 0.726081, acc: 47.66%] [G loss: 1.504193]\n",
      "epoch:4 step:3153 [D loss: 0.783913, acc: 38.28%] [G loss: 1.567000]\n",
      "epoch:4 step:3154 [D loss: 0.625172, acc: 69.53%] [G loss: 1.641432]\n",
      "epoch:4 step:3155 [D loss: 0.687613, acc: 58.59%] [G loss: 1.476312]\n",
      "epoch:4 step:3156 [D loss: 0.805549, acc: 44.53%] [G loss: 1.670901]\n",
      "epoch:4 step:3157 [D loss: 0.654168, acc: 60.94%] [G loss: 1.695125]\n",
      "epoch:4 step:3158 [D loss: 0.730303, acc: 47.66%] [G loss: 1.677260]\n",
      "epoch:4 step:3159 [D loss: 0.741429, acc: 46.09%] [G loss: 1.515511]\n",
      "epoch:4 step:3160 [D loss: 0.790965, acc: 36.72%] [G loss: 1.596082]\n",
      "epoch:4 step:3161 [D loss: 0.740855, acc: 50.00%] [G loss: 1.671627]\n",
      "epoch:4 step:3162 [D loss: 0.646097, acc: 69.53%] [G loss: 1.700950]\n",
      "epoch:4 step:3163 [D loss: 0.787021, acc: 42.19%] [G loss: 1.729459]\n",
      "epoch:4 step:3164 [D loss: 0.535170, acc: 74.22%] [G loss: 1.751646]\n",
      "epoch:4 step:3165 [D loss: 0.781432, acc: 46.09%] [G loss: 1.553860]\n",
      "epoch:4 step:3166 [D loss: 0.568797, acc: 73.44%] [G loss: 1.821212]\n",
      "epoch:4 step:3167 [D loss: 0.657519, acc: 57.81%] [G loss: 1.717176]\n",
      "epoch:4 step:3168 [D loss: 0.796373, acc: 45.31%] [G loss: 1.646056]\n",
      "epoch:4 step:3169 [D loss: 0.751160, acc: 44.53%] [G loss: 1.950828]\n",
      "epoch:4 step:3170 [D loss: 0.689572, acc: 55.47%] [G loss: 1.773355]\n",
      "epoch:4 step:3171 [D loss: 0.761221, acc: 52.34%] [G loss: 1.853006]\n",
      "epoch:4 step:3172 [D loss: 0.652942, acc: 64.06%] [G loss: 1.807901]\n",
      "epoch:4 step:3173 [D loss: 0.761717, acc: 51.56%] [G loss: 1.601995]\n",
      "epoch:4 step:3174 [D loss: 0.670442, acc: 63.28%] [G loss: 1.819035]\n",
      "epoch:4 step:3175 [D loss: 0.573411, acc: 71.88%] [G loss: 1.601150]\n",
      "epoch:4 step:3176 [D loss: 0.622174, acc: 69.53%] [G loss: 1.799942]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:4 step:3177 [D loss: 0.678813, acc: 58.59%] [G loss: 1.493318]\n",
      "epoch:4 step:3178 [D loss: 0.663880, acc: 62.50%] [G loss: 1.832608]\n",
      "epoch:4 step:3179 [D loss: 0.715891, acc: 53.12%] [G loss: 1.703551]\n",
      "epoch:4 step:3180 [D loss: 0.908660, acc: 29.69%] [G loss: 1.523498]\n",
      "epoch:4 step:3181 [D loss: 0.800637, acc: 49.22%] [G loss: 1.604227]\n",
      "epoch:4 step:3182 [D loss: 0.798592, acc: 40.62%] [G loss: 1.482220]\n",
      "epoch:4 step:3183 [D loss: 0.633195, acc: 64.06%] [G loss: 1.814376]\n",
      "epoch:4 step:3184 [D loss: 0.756281, acc: 45.31%] [G loss: 1.553299]\n",
      "epoch:4 step:3185 [D loss: 0.678314, acc: 57.81%] [G loss: 1.744050]\n",
      "epoch:4 step:3186 [D loss: 0.634752, acc: 71.09%] [G loss: 1.719211]\n",
      "epoch:4 step:3187 [D loss: 0.734052, acc: 46.88%] [G loss: 1.625096]\n",
      "epoch:4 step:3188 [D loss: 0.677411, acc: 57.81%] [G loss: 1.551897]\n",
      "epoch:4 step:3189 [D loss: 0.875868, acc: 31.25%] [G loss: 1.472749]\n",
      "epoch:4 step:3190 [D loss: 0.652824, acc: 64.06%] [G loss: 1.721643]\n",
      "epoch:4 step:3191 [D loss: 0.855007, acc: 35.16%] [G loss: 1.327879]\n",
      "epoch:4 step:3192 [D loss: 0.624879, acc: 64.06%] [G loss: 1.447365]\n",
      "epoch:4 step:3193 [D loss: 0.816924, acc: 32.81%] [G loss: 1.437126]\n",
      "epoch:4 step:3194 [D loss: 0.699502, acc: 55.47%] [G loss: 1.762275]\n",
      "epoch:4 step:3195 [D loss: 0.951142, acc: 26.56%] [G loss: 1.630867]\n",
      "epoch:4 step:3196 [D loss: 0.743334, acc: 49.22%] [G loss: 1.612644]\n",
      "epoch:4 step:3197 [D loss: 0.658467, acc: 59.38%] [G loss: 1.716464]\n",
      "epoch:4 step:3198 [D loss: 0.693535, acc: 62.50%] [G loss: 1.658122]\n",
      "epoch:4 step:3199 [D loss: 0.675051, acc: 56.25%] [G loss: 1.647298]\n",
      "epoch:4 step:3200 [D loss: 0.627393, acc: 67.19%] [G loss: 1.705469]\n",
      "##############\n",
      "[0.84339211 0.8814683  0.82938384 0.81034619 0.82440372 0.81817347\n",
      " 0.91879995 0.83171903 0.82223105 0.83272754]\n",
      "##########\n",
      "epoch:4 step:3201 [D loss: 0.758952, acc: 43.75%] [G loss: 1.713324]\n",
      "epoch:4 step:3202 [D loss: 0.743909, acc: 47.66%] [G loss: 1.691669]\n",
      "epoch:4 step:3203 [D loss: 0.657871, acc: 64.84%] [G loss: 1.808513]\n",
      "epoch:4 step:3204 [D loss: 0.787197, acc: 42.19%] [G loss: 1.572338]\n",
      "epoch:4 step:3205 [D loss: 0.726774, acc: 50.78%] [G loss: 1.452690]\n",
      "epoch:4 step:3206 [D loss: 0.625228, acc: 67.19%] [G loss: 1.639489]\n",
      "epoch:4 step:3207 [D loss: 0.796954, acc: 42.97%] [G loss: 1.704331]\n",
      "epoch:4 step:3208 [D loss: 0.914089, acc: 20.31%] [G loss: 1.311322]\n",
      "epoch:4 step:3209 [D loss: 0.670257, acc: 57.03%] [G loss: 1.631535]\n",
      "epoch:4 step:3210 [D loss: 0.690260, acc: 53.12%] [G loss: 1.644589]\n",
      "epoch:4 step:3211 [D loss: 0.560939, acc: 75.00%] [G loss: 1.656125]\n",
      "epoch:4 step:3212 [D loss: 0.840363, acc: 28.91%] [G loss: 1.552331]\n",
      "epoch:4 step:3213 [D loss: 0.629591, acc: 68.75%] [G loss: 1.615424]\n",
      "epoch:4 step:3214 [D loss: 0.790098, acc: 39.06%] [G loss: 1.467563]\n",
      "epoch:4 step:3215 [D loss: 0.753480, acc: 50.00%] [G loss: 1.478586]\n",
      "epoch:4 step:3216 [D loss: 0.675838, acc: 59.38%] [G loss: 1.586235]\n",
      "epoch:4 step:3217 [D loss: 0.701388, acc: 55.47%] [G loss: 1.601793]\n",
      "epoch:4 step:3218 [D loss: 0.758844, acc: 39.84%] [G loss: 1.409477]\n",
      "epoch:4 step:3219 [D loss: 0.721051, acc: 51.56%] [G loss: 1.571925]\n",
      "epoch:4 step:3220 [D loss: 0.709163, acc: 53.12%] [G loss: 1.565054]\n",
      "epoch:4 step:3221 [D loss: 0.768866, acc: 38.28%] [G loss: 1.576553]\n",
      "epoch:4 step:3222 [D loss: 0.686644, acc: 55.47%] [G loss: 1.565240]\n",
      "epoch:4 step:3223 [D loss: 0.756145, acc: 50.00%] [G loss: 1.585615]\n",
      "epoch:4 step:3224 [D loss: 0.686426, acc: 61.72%] [G loss: 1.690938]\n",
      "epoch:4 step:3225 [D loss: 0.824849, acc: 34.38%] [G loss: 1.405345]\n",
      "epoch:4 step:3226 [D loss: 0.835755, acc: 36.72%] [G loss: 1.518188]\n",
      "epoch:4 step:3227 [D loss: 0.704716, acc: 52.34%] [G loss: 1.605762]\n",
      "epoch:4 step:3228 [D loss: 0.759921, acc: 46.09%] [G loss: 1.473181]\n",
      "epoch:4 step:3229 [D loss: 0.726231, acc: 45.31%] [G loss: 1.556585]\n",
      "epoch:4 step:3230 [D loss: 0.643913, acc: 64.06%] [G loss: 1.669472]\n",
      "epoch:4 step:3231 [D loss: 0.814246, acc: 41.41%] [G loss: 1.554998]\n",
      "epoch:4 step:3232 [D loss: 0.726509, acc: 48.44%] [G loss: 1.637388]\n",
      "epoch:4 step:3233 [D loss: 0.781968, acc: 41.41%] [G loss: 1.458769]\n",
      "epoch:4 step:3234 [D loss: 0.714185, acc: 53.12%] [G loss: 1.481816]\n",
      "epoch:4 step:3235 [D loss: 0.845221, acc: 45.31%] [G loss: 1.295735]\n",
      "epoch:4 step:3236 [D loss: 0.684250, acc: 57.03%] [G loss: 1.596105]\n",
      "epoch:4 step:3237 [D loss: 0.699781, acc: 52.34%] [G loss: 1.655577]\n",
      "epoch:4 step:3238 [D loss: 0.695638, acc: 53.12%] [G loss: 1.567266]\n",
      "epoch:4 step:3239 [D loss: 0.895428, acc: 25.78%] [G loss: 1.313040]\n",
      "epoch:4 step:3240 [D loss: 0.766631, acc: 39.06%] [G loss: 1.464576]\n",
      "epoch:4 step:3241 [D loss: 0.717330, acc: 50.78%] [G loss: 1.520749]\n",
      "epoch:4 step:3242 [D loss: 0.547629, acc: 75.78%] [G loss: 1.533819]\n",
      "epoch:4 step:3243 [D loss: 0.722309, acc: 49.22%] [G loss: 1.551530]\n",
      "epoch:4 step:3244 [D loss: 0.753003, acc: 43.75%] [G loss: 1.536495]\n",
      "epoch:4 step:3245 [D loss: 0.583616, acc: 71.88%] [G loss: 1.502218]\n",
      "epoch:4 step:3246 [D loss: 0.692400, acc: 53.12%] [G loss: 1.507958]\n",
      "epoch:4 step:3247 [D loss: 0.718180, acc: 46.09%] [G loss: 1.509466]\n",
      "epoch:4 step:3248 [D loss: 0.737727, acc: 42.19%] [G loss: 1.461789]\n",
      "epoch:4 step:3249 [D loss: 0.637344, acc: 69.53%] [G loss: 1.646521]\n",
      "epoch:4 step:3250 [D loss: 0.732896, acc: 51.56%] [G loss: 1.531868]\n",
      "epoch:4 step:3251 [D loss: 0.732417, acc: 46.09%] [G loss: 1.463969]\n",
      "epoch:4 step:3252 [D loss: 0.638997, acc: 64.06%] [G loss: 1.657037]\n",
      "epoch:4 step:3253 [D loss: 0.741562, acc: 45.31%] [G loss: 1.481866]\n",
      "epoch:4 step:3254 [D loss: 0.799850, acc: 38.28%] [G loss: 1.466244]\n",
      "epoch:4 step:3255 [D loss: 0.683932, acc: 58.59%] [G loss: 1.589147]\n",
      "epoch:4 step:3256 [D loss: 0.755894, acc: 43.75%] [G loss: 1.583373]\n",
      "epoch:4 step:3257 [D loss: 0.640799, acc: 67.19%] [G loss: 1.566755]\n",
      "epoch:4 step:3258 [D loss: 0.756400, acc: 44.53%] [G loss: 1.554971]\n",
      "epoch:4 step:3259 [D loss: 0.718353, acc: 51.56%] [G loss: 1.679909]\n",
      "epoch:4 step:3260 [D loss: 0.740401, acc: 43.75%] [G loss: 1.498853]\n",
      "epoch:4 step:3261 [D loss: 0.790318, acc: 35.94%] [G loss: 1.437646]\n",
      "epoch:4 step:3262 [D loss: 0.657755, acc: 64.06%] [G loss: 1.544050]\n",
      "epoch:4 step:3263 [D loss: 0.649919, acc: 64.06%] [G loss: 1.738197]\n",
      "epoch:4 step:3264 [D loss: 0.606548, acc: 72.66%] [G loss: 1.573308]\n",
      "epoch:4 step:3265 [D loss: 0.728155, acc: 50.78%] [G loss: 1.605203]\n",
      "epoch:4 step:3266 [D loss: 0.698109, acc: 56.25%] [G loss: 1.532337]\n",
      "epoch:4 step:3267 [D loss: 0.602889, acc: 71.88%] [G loss: 1.660135]\n",
      "epoch:4 step:3268 [D loss: 0.636863, acc: 65.62%] [G loss: 1.564179]\n",
      "epoch:4 step:3269 [D loss: 0.607495, acc: 75.00%] [G loss: 1.636061]\n",
      "epoch:4 step:3270 [D loss: 0.732220, acc: 46.88%] [G loss: 1.554300]\n",
      "epoch:4 step:3271 [D loss: 0.668592, acc: 62.50%] [G loss: 1.601067]\n",
      "epoch:4 step:3272 [D loss: 0.754380, acc: 46.09%] [G loss: 1.580806]\n",
      "epoch:4 step:3273 [D loss: 0.727633, acc: 45.31%] [G loss: 1.628323]\n",
      "epoch:4 step:3274 [D loss: 0.726358, acc: 54.69%] [G loss: 1.390448]\n",
      "epoch:4 step:3275 [D loss: 0.741914, acc: 44.53%] [G loss: 1.506997]\n",
      "epoch:4 step:3276 [D loss: 0.638633, acc: 60.16%] [G loss: 1.577294]\n",
      "epoch:4 step:3277 [D loss: 0.653840, acc: 60.94%] [G loss: 1.723993]\n",
      "epoch:4 step:3278 [D loss: 0.685067, acc: 57.81%] [G loss: 1.610303]\n",
      "epoch:4 step:3279 [D loss: 0.808524, acc: 39.06%] [G loss: 1.585154]\n",
      "epoch:4 step:3280 [D loss: 0.687838, acc: 57.03%] [G loss: 1.544880]\n",
      "epoch:4 step:3281 [D loss: 0.828909, acc: 31.25%] [G loss: 1.465921]\n",
      "epoch:4 step:3282 [D loss: 0.746675, acc: 42.97%] [G loss: 1.602439]\n",
      "epoch:4 step:3283 [D loss: 0.662379, acc: 63.28%] [G loss: 1.553849]\n",
      "epoch:4 step:3284 [D loss: 0.823960, acc: 30.47%] [G loss: 1.401878]\n",
      "epoch:4 step:3285 [D loss: 0.683890, acc: 56.25%] [G loss: 1.559068]\n",
      "epoch:4 step:3286 [D loss: 0.674156, acc: 60.94%] [G loss: 1.557488]\n",
      "epoch:4 step:3287 [D loss: 0.740923, acc: 46.88%] [G loss: 1.418309]\n",
      "epoch:4 step:3288 [D loss: 0.703776, acc: 53.12%] [G loss: 1.578040]\n",
      "epoch:4 step:3289 [D loss: 0.746013, acc: 47.66%] [G loss: 1.609482]\n",
      "epoch:4 step:3290 [D loss: 0.792622, acc: 44.53%] [G loss: 1.471481]\n",
      "epoch:4 step:3291 [D loss: 0.745454, acc: 44.53%] [G loss: 1.480581]\n",
      "epoch:4 step:3292 [D loss: 0.663790, acc: 63.28%] [G loss: 1.741729]\n",
      "epoch:4 step:3293 [D loss: 0.703425, acc: 53.12%] [G loss: 1.607580]\n",
      "epoch:4 step:3294 [D loss: 0.723715, acc: 46.09%] [G loss: 1.746688]\n",
      "epoch:4 step:3295 [D loss: 0.677969, acc: 60.94%] [G loss: 1.665902]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:4 step:3296 [D loss: 0.621407, acc: 66.41%] [G loss: 1.650764]\n",
      "epoch:4 step:3297 [D loss: 0.750331, acc: 44.53%] [G loss: 1.430266]\n",
      "epoch:4 step:3298 [D loss: 0.731796, acc: 48.44%] [G loss: 1.618616]\n",
      "epoch:4 step:3299 [D loss: 0.688947, acc: 56.25%] [G loss: 1.689981]\n",
      "epoch:4 step:3300 [D loss: 0.734921, acc: 47.66%] [G loss: 1.554628]\n",
      "epoch:4 step:3301 [D loss: 0.701455, acc: 55.47%] [G loss: 1.567705]\n",
      "epoch:4 step:3302 [D loss: 0.816700, acc: 35.16%] [G loss: 1.501343]\n",
      "epoch:4 step:3303 [D loss: 0.742765, acc: 46.88%] [G loss: 1.636259]\n",
      "epoch:4 step:3304 [D loss: 0.721069, acc: 47.66%] [G loss: 1.434652]\n",
      "epoch:4 step:3305 [D loss: 0.684986, acc: 57.03%] [G loss: 1.681598]\n",
      "epoch:4 step:3306 [D loss: 0.729237, acc: 42.19%] [G loss: 1.543606]\n",
      "epoch:4 step:3307 [D loss: 0.654953, acc: 59.38%] [G loss: 1.494888]\n",
      "epoch:4 step:3308 [D loss: 0.764639, acc: 39.06%] [G loss: 1.598107]\n",
      "epoch:4 step:3309 [D loss: 0.736240, acc: 43.75%] [G loss: 1.456738]\n",
      "epoch:4 step:3310 [D loss: 0.674130, acc: 59.38%] [G loss: 1.718913]\n",
      "epoch:4 step:3311 [D loss: 0.691991, acc: 51.56%] [G loss: 1.704557]\n",
      "epoch:4 step:3312 [D loss: 0.686932, acc: 54.69%] [G loss: 1.587400]\n",
      "epoch:4 step:3313 [D loss: 0.679019, acc: 55.47%] [G loss: 1.474665]\n",
      "epoch:4 step:3314 [D loss: 0.643723, acc: 64.84%] [G loss: 1.562438]\n",
      "epoch:4 step:3315 [D loss: 0.789804, acc: 37.50%] [G loss: 1.475536]\n",
      "epoch:4 step:3316 [D loss: 0.642299, acc: 67.19%] [G loss: 1.540076]\n",
      "epoch:4 step:3317 [D loss: 0.662528, acc: 63.28%] [G loss: 1.575046]\n",
      "epoch:4 step:3318 [D loss: 0.769169, acc: 39.06%] [G loss: 1.373028]\n",
      "epoch:4 step:3319 [D loss: 0.803675, acc: 36.72%] [G loss: 1.402017]\n",
      "epoch:4 step:3320 [D loss: 0.842579, acc: 34.38%] [G loss: 1.332600]\n",
      "epoch:4 step:3321 [D loss: 0.639100, acc: 65.62%] [G loss: 1.701001]\n",
      "epoch:4 step:3322 [D loss: 0.669178, acc: 60.94%] [G loss: 1.699778]\n",
      "epoch:4 step:3323 [D loss: 0.740820, acc: 44.53%] [G loss: 1.611497]\n",
      "epoch:4 step:3324 [D loss: 0.546049, acc: 81.25%] [G loss: 1.735323]\n",
      "epoch:4 step:3325 [D loss: 0.673720, acc: 62.50%] [G loss: 1.575883]\n",
      "epoch:4 step:3326 [D loss: 0.798131, acc: 36.72%] [G loss: 1.468860]\n",
      "epoch:4 step:3327 [D loss: 0.704762, acc: 58.59%] [G loss: 1.662009]\n",
      "epoch:4 step:3328 [D loss: 0.635721, acc: 67.19%] [G loss: 1.637228]\n",
      "epoch:4 step:3329 [D loss: 0.798877, acc: 43.75%] [G loss: 1.431104]\n",
      "epoch:4 step:3330 [D loss: 0.763244, acc: 38.28%] [G loss: 1.544233]\n",
      "epoch:4 step:3331 [D loss: 0.706066, acc: 53.12%] [G loss: 1.545115]\n",
      "epoch:4 step:3332 [D loss: 0.470170, acc: 83.59%] [G loss: 1.602834]\n",
      "epoch:4 step:3333 [D loss: 0.880265, acc: 27.34%] [G loss: 1.374661]\n",
      "epoch:4 step:3334 [D loss: 0.745892, acc: 42.97%] [G loss: 1.712126]\n",
      "epoch:4 step:3335 [D loss: 0.654290, acc: 60.94%] [G loss: 1.564122]\n",
      "epoch:4 step:3336 [D loss: 0.693179, acc: 58.59%] [G loss: 1.606455]\n",
      "epoch:4 step:3337 [D loss: 0.696029, acc: 57.03%] [G loss: 1.684753]\n",
      "epoch:4 step:3338 [D loss: 0.790283, acc: 42.97%] [G loss: 1.416154]\n",
      "epoch:4 step:3339 [D loss: 0.761395, acc: 41.41%] [G loss: 1.493845]\n",
      "epoch:4 step:3340 [D loss: 0.825215, acc: 39.84%] [G loss: 1.302831]\n",
      "epoch:4 step:3341 [D loss: 0.699925, acc: 51.56%] [G loss: 1.513978]\n",
      "epoch:4 step:3342 [D loss: 0.595811, acc: 67.19%] [G loss: 1.394844]\n",
      "epoch:4 step:3343 [D loss: 0.699639, acc: 53.12%] [G loss: 1.533283]\n",
      "epoch:4 step:3344 [D loss: 0.663429, acc: 66.41%] [G loss: 1.528296]\n",
      "epoch:4 step:3345 [D loss: 0.652261, acc: 63.28%] [G loss: 1.512535]\n",
      "epoch:4 step:3346 [D loss: 0.849242, acc: 32.81%] [G loss: 1.410517]\n",
      "epoch:4 step:3347 [D loss: 0.699251, acc: 51.56%] [G loss: 1.611132]\n",
      "epoch:4 step:3348 [D loss: 0.716203, acc: 50.78%] [G loss: 1.590426]\n",
      "epoch:4 step:3349 [D loss: 0.791801, acc: 41.41%] [G loss: 1.412453]\n",
      "epoch:4 step:3350 [D loss: 0.802195, acc: 33.59%] [G loss: 1.594126]\n",
      "epoch:4 step:3351 [D loss: 0.632851, acc: 67.19%] [G loss: 1.524210]\n",
      "epoch:4 step:3352 [D loss: 0.688785, acc: 53.91%] [G loss: 1.625887]\n",
      "epoch:4 step:3353 [D loss: 0.695286, acc: 53.12%] [G loss: 1.683603]\n",
      "epoch:4 step:3354 [D loss: 0.857464, acc: 28.12%] [G loss: 1.423541]\n",
      "epoch:4 step:3355 [D loss: 0.614613, acc: 71.88%] [G loss: 1.610084]\n",
      "epoch:4 step:3356 [D loss: 0.753748, acc: 44.53%] [G loss: 1.468812]\n",
      "epoch:4 step:3357 [D loss: 0.643584, acc: 67.97%] [G loss: 1.687958]\n",
      "epoch:4 step:3358 [D loss: 0.703511, acc: 52.34%] [G loss: 1.681423]\n",
      "epoch:4 step:3359 [D loss: 0.689180, acc: 57.03%] [G loss: 1.648362]\n",
      "epoch:4 step:3360 [D loss: 0.765935, acc: 53.12%] [G loss: 1.639092]\n",
      "epoch:4 step:3361 [D loss: 0.682967, acc: 58.59%] [G loss: 1.498948]\n",
      "epoch:4 step:3362 [D loss: 0.675452, acc: 60.16%] [G loss: 1.673415]\n",
      "epoch:4 step:3363 [D loss: 0.626382, acc: 67.19%] [G loss: 1.552354]\n",
      "epoch:4 step:3364 [D loss: 0.683113, acc: 55.47%] [G loss: 1.722394]\n",
      "epoch:4 step:3365 [D loss: 0.722133, acc: 54.69%] [G loss: 1.441604]\n",
      "epoch:4 step:3366 [D loss: 0.829044, acc: 29.69%] [G loss: 1.446191]\n",
      "epoch:4 step:3367 [D loss: 0.771954, acc: 46.09%] [G loss: 1.454435]\n",
      "epoch:4 step:3368 [D loss: 0.703805, acc: 54.69%] [G loss: 1.528034]\n",
      "epoch:4 step:3369 [D loss: 0.842328, acc: 26.56%] [G loss: 1.281070]\n",
      "epoch:4 step:3370 [D loss: 0.690380, acc: 53.91%] [G loss: 1.528061]\n",
      "epoch:4 step:3371 [D loss: 0.641553, acc: 65.62%] [G loss: 1.510199]\n",
      "epoch:4 step:3372 [D loss: 0.755581, acc: 44.53%] [G loss: 1.471632]\n",
      "epoch:4 step:3373 [D loss: 0.722071, acc: 47.66%] [G loss: 1.510481]\n",
      "epoch:4 step:3374 [D loss: 0.839480, acc: 32.03%] [G loss: 1.434914]\n",
      "epoch:4 step:3375 [D loss: 0.748019, acc: 47.66%] [G loss: 1.543476]\n",
      "epoch:4 step:3376 [D loss: 0.648940, acc: 61.72%] [G loss: 1.529079]\n",
      "epoch:4 step:3377 [D loss: 0.789748, acc: 39.06%] [G loss: 1.545896]\n",
      "epoch:4 step:3378 [D loss: 0.757462, acc: 46.88%] [G loss: 1.391374]\n",
      "epoch:4 step:3379 [D loss: 0.816396, acc: 33.59%] [G loss: 1.362777]\n",
      "epoch:4 step:3380 [D loss: 0.558761, acc: 80.47%] [G loss: 1.436249]\n",
      "epoch:4 step:3381 [D loss: 0.753003, acc: 43.75%] [G loss: 1.481913]\n",
      "epoch:4 step:3382 [D loss: 0.706443, acc: 53.12%] [G loss: 1.558570]\n",
      "epoch:4 step:3383 [D loss: 0.727152, acc: 53.91%] [G loss: 1.534457]\n",
      "epoch:4 step:3384 [D loss: 0.651571, acc: 60.94%] [G loss: 1.583420]\n",
      "epoch:4 step:3385 [D loss: 0.535646, acc: 82.03%] [G loss: 1.770159]\n",
      "epoch:4 step:3386 [D loss: 0.719924, acc: 50.00%] [G loss: 1.509364]\n",
      "epoch:4 step:3387 [D loss: 0.811872, acc: 39.84%] [G loss: 1.574229]\n",
      "epoch:4 step:3388 [D loss: 0.678566, acc: 57.81%] [G loss: 1.665783]\n",
      "epoch:4 step:3389 [D loss: 0.675069, acc: 56.25%] [G loss: 1.628964]\n",
      "epoch:4 step:3390 [D loss: 0.681715, acc: 55.47%] [G loss: 1.619345]\n",
      "epoch:4 step:3391 [D loss: 0.942375, acc: 30.47%] [G loss: 1.374436]\n",
      "epoch:4 step:3392 [D loss: 0.698399, acc: 57.81%] [G loss: 1.718879]\n",
      "epoch:4 step:3393 [D loss: 0.588135, acc: 74.22%] [G loss: 1.719415]\n",
      "epoch:4 step:3394 [D loss: 0.690018, acc: 52.34%] [G loss: 1.672621]\n",
      "epoch:4 step:3395 [D loss: 0.672689, acc: 58.59%] [G loss: 1.597642]\n",
      "epoch:4 step:3396 [D loss: 0.667129, acc: 64.06%] [G loss: 1.667581]\n",
      "epoch:4 step:3397 [D loss: 0.640396, acc: 67.19%] [G loss: 1.593987]\n",
      "epoch:4 step:3398 [D loss: 0.596643, acc: 72.66%] [G loss: 1.602106]\n",
      "epoch:4 step:3399 [D loss: 0.596688, acc: 75.00%] [G loss: 1.515066]\n",
      "epoch:4 step:3400 [D loss: 0.679630, acc: 53.91%] [G loss: 1.709180]\n",
      "##############\n",
      "[0.8449869  0.88704501 0.82175193 0.82650064 0.78407768 0.82897143\n",
      " 0.87968693 0.82894004 0.79916038 0.82889866]\n",
      "##########\n",
      "epoch:4 step:3401 [D loss: 0.975340, acc: 16.41%] [G loss: 1.190434]\n",
      "epoch:4 step:3402 [D loss: 0.699492, acc: 52.34%] [G loss: 1.492100]\n",
      "epoch:4 step:3403 [D loss: 0.560341, acc: 82.03%] [G loss: 1.578299]\n",
      "epoch:4 step:3404 [D loss: 0.614309, acc: 69.53%] [G loss: 1.661323]\n",
      "epoch:4 step:3405 [D loss: 0.719814, acc: 47.66%] [G loss: 1.581496]\n",
      "epoch:4 step:3406 [D loss: 0.845411, acc: 31.25%] [G loss: 1.412704]\n",
      "epoch:4 step:3407 [D loss: 0.674112, acc: 54.69%] [G loss: 1.503493]\n",
      "epoch:4 step:3408 [D loss: 0.792584, acc: 32.03%] [G loss: 1.468000]\n",
      "epoch:4 step:3409 [D loss: 0.690367, acc: 57.03%] [G loss: 1.508993]\n",
      "epoch:4 step:3410 [D loss: 0.670642, acc: 64.84%] [G loss: 1.463229]\n",
      "epoch:4 step:3411 [D loss: 0.822711, acc: 31.25%] [G loss: 1.543453]\n",
      "epoch:4 step:3412 [D loss: 0.733412, acc: 46.09%] [G loss: 1.586252]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:4 step:3413 [D loss: 0.673003, acc: 60.94%] [G loss: 1.515374]\n",
      "epoch:4 step:3414 [D loss: 0.465479, acc: 89.06%] [G loss: 1.687945]\n",
      "epoch:4 step:3415 [D loss: 0.714329, acc: 48.44%] [G loss: 1.498186]\n",
      "epoch:4 step:3416 [D loss: 0.724842, acc: 46.09%] [G loss: 1.463722]\n",
      "epoch:4 step:3417 [D loss: 0.705488, acc: 53.12%] [G loss: 1.520967]\n",
      "epoch:4 step:3418 [D loss: 0.618776, acc: 66.41%] [G loss: 1.571576]\n",
      "epoch:4 step:3419 [D loss: 0.836926, acc: 32.03%] [G loss: 1.628535]\n",
      "epoch:4 step:3420 [D loss: 0.706885, acc: 53.12%] [G loss: 1.575068]\n",
      "epoch:4 step:3421 [D loss: 0.813203, acc: 33.59%] [G loss: 1.450560]\n",
      "epoch:4 step:3422 [D loss: 0.659750, acc: 60.16%] [G loss: 1.589346]\n",
      "epoch:4 step:3423 [D loss: 0.624580, acc: 67.97%] [G loss: 1.664480]\n",
      "epoch:4 step:3424 [D loss: 0.805802, acc: 31.25%] [G loss: 1.543424]\n",
      "epoch:4 step:3425 [D loss: 0.673599, acc: 55.47%] [G loss: 1.684433]\n",
      "epoch:4 step:3426 [D loss: 0.638218, acc: 66.41%] [G loss: 1.694704]\n",
      "epoch:4 step:3427 [D loss: 0.688678, acc: 55.47%] [G loss: 1.597278]\n",
      "epoch:4 step:3428 [D loss: 0.628910, acc: 62.50%] [G loss: 1.557202]\n",
      "epoch:4 step:3429 [D loss: 0.720900, acc: 50.78%] [G loss: 1.626337]\n",
      "epoch:4 step:3430 [D loss: 0.741316, acc: 48.44%] [G loss: 1.509748]\n",
      "epoch:4 step:3431 [D loss: 0.721055, acc: 52.34%] [G loss: 1.632146]\n",
      "epoch:4 step:3432 [D loss: 0.692458, acc: 54.69%] [G loss: 1.635955]\n",
      "epoch:4 step:3433 [D loss: 0.664521, acc: 54.69%] [G loss: 1.558012]\n",
      "epoch:4 step:3434 [D loss: 0.692790, acc: 56.25%] [G loss: 1.819544]\n",
      "epoch:4 step:3435 [D loss: 0.708355, acc: 51.56%] [G loss: 1.686090]\n",
      "epoch:4 step:3436 [D loss: 0.649046, acc: 64.84%] [G loss: 1.725527]\n",
      "epoch:4 step:3437 [D loss: 0.758615, acc: 43.75%] [G loss: 1.517097]\n",
      "epoch:4 step:3438 [D loss: 0.743269, acc: 50.78%] [G loss: 1.662598]\n",
      "epoch:4 step:3439 [D loss: 0.591705, acc: 75.78%] [G loss: 1.766864]\n",
      "epoch:4 step:3440 [D loss: 0.691646, acc: 60.94%] [G loss: 1.576005]\n",
      "epoch:4 step:3441 [D loss: 0.682375, acc: 54.69%] [G loss: 1.475282]\n",
      "epoch:4 step:3442 [D loss: 0.734784, acc: 48.44%] [G loss: 1.711776]\n",
      "epoch:4 step:3443 [D loss: 0.802477, acc: 41.41%] [G loss: 1.431841]\n",
      "epoch:4 step:3444 [D loss: 0.622394, acc: 65.62%] [G loss: 1.586187]\n",
      "epoch:4 step:3445 [D loss: 0.813934, acc: 43.75%] [G loss: 1.629594]\n",
      "epoch:4 step:3446 [D loss: 0.749499, acc: 48.44%] [G loss: 1.358601]\n",
      "epoch:4 step:3447 [D loss: 0.758013, acc: 42.19%] [G loss: 1.526170]\n",
      "epoch:4 step:3448 [D loss: 0.792657, acc: 37.50%] [G loss: 1.531712]\n",
      "epoch:4 step:3449 [D loss: 0.490108, acc: 82.81%] [G loss: 1.832387]\n",
      "epoch:4 step:3450 [D loss: 0.714249, acc: 50.78%] [G loss: 1.528597]\n",
      "epoch:4 step:3451 [D loss: 0.609589, acc: 64.06%] [G loss: 1.660643]\n",
      "epoch:4 step:3452 [D loss: 0.780406, acc: 42.19%] [G loss: 1.622375]\n",
      "epoch:4 step:3453 [D loss: 0.705298, acc: 50.78%] [G loss: 1.490555]\n",
      "epoch:4 step:3454 [D loss: 0.792772, acc: 41.41%] [G loss: 1.650798]\n",
      "epoch:4 step:3455 [D loss: 0.575559, acc: 77.34%] [G loss: 1.697965]\n",
      "epoch:4 step:3456 [D loss: 0.643624, acc: 67.19%] [G loss: 1.718003]\n",
      "epoch:4 step:3457 [D loss: 0.710820, acc: 52.34%] [G loss: 1.624441]\n",
      "epoch:4 step:3458 [D loss: 0.792135, acc: 36.72%] [G loss: 1.704447]\n",
      "epoch:4 step:3459 [D loss: 0.651442, acc: 63.28%] [G loss: 1.806871]\n",
      "epoch:4 step:3460 [D loss: 0.649779, acc: 60.16%] [G loss: 1.812644]\n",
      "epoch:4 step:3461 [D loss: 0.703211, acc: 46.09%] [G loss: 1.635718]\n",
      "epoch:4 step:3462 [D loss: 0.790622, acc: 38.28%] [G loss: 1.589484]\n",
      "epoch:4 step:3463 [D loss: 0.692506, acc: 57.81%] [G loss: 1.718732]\n",
      "epoch:4 step:3464 [D loss: 0.681881, acc: 60.94%] [G loss: 1.558020]\n",
      "epoch:4 step:3465 [D loss: 0.647153, acc: 60.94%] [G loss: 1.688827]\n",
      "epoch:4 step:3466 [D loss: 0.658367, acc: 63.28%] [G loss: 1.580626]\n",
      "epoch:4 step:3467 [D loss: 0.683394, acc: 57.81%] [G loss: 1.628524]\n",
      "epoch:4 step:3468 [D loss: 0.772664, acc: 50.00%] [G loss: 1.660275]\n",
      "epoch:4 step:3469 [D loss: 0.595566, acc: 74.22%] [G loss: 1.631444]\n",
      "epoch:4 step:3470 [D loss: 0.768311, acc: 42.97%] [G loss: 1.574275]\n",
      "epoch:4 step:3471 [D loss: 0.629467, acc: 61.72%] [G loss: 1.512906]\n",
      "epoch:4 step:3472 [D loss: 0.737511, acc: 50.00%] [G loss: 1.649916]\n",
      "epoch:4 step:3473 [D loss: 0.706703, acc: 54.69%] [G loss: 1.690009]\n",
      "epoch:4 step:3474 [D loss: 0.855940, acc: 36.72%] [G loss: 1.467531]\n",
      "epoch:4 step:3475 [D loss: 0.718603, acc: 52.34%] [G loss: 1.560450]\n",
      "epoch:4 step:3476 [D loss: 0.860641, acc: 36.72%] [G loss: 1.483250]\n",
      "epoch:4 step:3477 [D loss: 0.596108, acc: 76.56%] [G loss: 1.542370]\n",
      "epoch:4 step:3478 [D loss: 0.690845, acc: 54.69%] [G loss: 1.672119]\n",
      "epoch:4 step:3479 [D loss: 0.726079, acc: 48.44%] [G loss: 1.625616]\n",
      "epoch:4 step:3480 [D loss: 0.704933, acc: 56.25%] [G loss: 1.627573]\n",
      "epoch:4 step:3481 [D loss: 0.684293, acc: 60.94%] [G loss: 1.651307]\n",
      "epoch:4 step:3482 [D loss: 0.708288, acc: 50.78%] [G loss: 1.750649]\n",
      "epoch:4 step:3483 [D loss: 0.723226, acc: 53.91%] [G loss: 1.635527]\n",
      "epoch:4 step:3484 [D loss: 0.705499, acc: 51.56%] [G loss: 1.716769]\n",
      "epoch:4 step:3485 [D loss: 0.839424, acc: 33.59%] [G loss: 1.696533]\n",
      "epoch:4 step:3486 [D loss: 0.688849, acc: 53.91%] [G loss: 1.703714]\n",
      "epoch:4 step:3487 [D loss: 0.724241, acc: 48.44%] [G loss: 1.784863]\n",
      "epoch:4 step:3488 [D loss: 0.684400, acc: 55.47%] [G loss: 1.616852]\n",
      "epoch:4 step:3489 [D loss: 0.609661, acc: 68.75%] [G loss: 1.973342]\n",
      "epoch:4 step:3490 [D loss: 0.799050, acc: 39.84%] [G loss: 1.500665]\n",
      "epoch:4 step:3491 [D loss: 0.630566, acc: 70.31%] [G loss: 1.707764]\n",
      "epoch:4 step:3492 [D loss: 0.659801, acc: 63.28%] [G loss: 1.721827]\n",
      "epoch:4 step:3493 [D loss: 0.625030, acc: 67.19%] [G loss: 1.836057]\n",
      "epoch:4 step:3494 [D loss: 0.600910, acc: 75.78%] [G loss: 1.646429]\n",
      "epoch:4 step:3495 [D loss: 0.687030, acc: 56.25%] [G loss: 1.788428]\n",
      "epoch:4 step:3496 [D loss: 0.650269, acc: 62.50%] [G loss: 1.770215]\n",
      "epoch:4 step:3497 [D loss: 0.985942, acc: 14.84%] [G loss: 1.251719]\n",
      "epoch:4 step:3498 [D loss: 0.698839, acc: 53.12%] [G loss: 1.739361]\n",
      "epoch:4 step:3499 [D loss: 0.624397, acc: 67.97%] [G loss: 1.588831]\n",
      "epoch:4 step:3500 [D loss: 0.644424, acc: 65.62%] [G loss: 1.626992]\n",
      "epoch:4 step:3501 [D loss: 0.714665, acc: 51.56%] [G loss: 1.548237]\n",
      "epoch:4 step:3502 [D loss: 0.800020, acc: 39.06%] [G loss: 1.494870]\n",
      "epoch:4 step:3503 [D loss: 0.795726, acc: 39.06%] [G loss: 1.526328]\n",
      "epoch:4 step:3504 [D loss: 0.760464, acc: 47.66%] [G loss: 1.479858]\n",
      "epoch:4 step:3505 [D loss: 0.674405, acc: 61.72%] [G loss: 1.477944]\n",
      "epoch:4 step:3506 [D loss: 0.798915, acc: 41.41%] [G loss: 1.423024]\n",
      "epoch:4 step:3507 [D loss: 0.705455, acc: 49.22%] [G loss: 1.338786]\n",
      "epoch:4 step:3508 [D loss: 0.794670, acc: 42.97%] [G loss: 1.371890]\n",
      "epoch:4 step:3509 [D loss: 0.810929, acc: 32.81%] [G loss: 1.536978]\n",
      "epoch:4 step:3510 [D loss: 0.660316, acc: 55.47%] [G loss: 1.670088]\n",
      "epoch:4 step:3511 [D loss: 0.749689, acc: 42.97%] [G loss: 1.421501]\n",
      "epoch:4 step:3512 [D loss: 0.764312, acc: 39.84%] [G loss: 1.580984]\n",
      "epoch:4 step:3513 [D loss: 0.747952, acc: 46.88%] [G loss: 1.570857]\n",
      "epoch:4 step:3514 [D loss: 0.821063, acc: 34.38%] [G loss: 1.491063]\n",
      "epoch:4 step:3515 [D loss: 0.750093, acc: 47.66%] [G loss: 1.669787]\n",
      "epoch:4 step:3516 [D loss: 0.706617, acc: 49.22%] [G loss: 1.638698]\n",
      "epoch:4 step:3517 [D loss: 0.797258, acc: 35.16%] [G loss: 1.533330]\n",
      "epoch:4 step:3518 [D loss: 0.612991, acc: 70.31%] [G loss: 1.842518]\n",
      "epoch:4 step:3519 [D loss: 0.689975, acc: 54.69%] [G loss: 1.546241]\n",
      "epoch:4 step:3520 [D loss: 0.716223, acc: 50.78%] [G loss: 1.643343]\n",
      "epoch:4 step:3521 [D loss: 0.674616, acc: 57.81%] [G loss: 1.641229]\n",
      "epoch:4 step:3522 [D loss: 0.662407, acc: 58.59%] [G loss: 1.497638]\n",
      "epoch:4 step:3523 [D loss: 0.751683, acc: 47.66%] [G loss: 1.649689]\n",
      "epoch:4 step:3524 [D loss: 0.654726, acc: 67.97%] [G loss: 1.642195]\n",
      "epoch:4 step:3525 [D loss: 0.618127, acc: 73.44%] [G loss: 1.677228]\n",
      "epoch:4 step:3526 [D loss: 0.541656, acc: 79.69%] [G loss: 1.773172]\n",
      "epoch:4 step:3527 [D loss: 0.667387, acc: 54.69%] [G loss: 1.780044]\n",
      "epoch:4 step:3528 [D loss: 0.613155, acc: 67.97%] [G loss: 1.739352]\n",
      "epoch:4 step:3529 [D loss: 0.707672, acc: 58.59%] [G loss: 1.529454]\n",
      "epoch:4 step:3530 [D loss: 0.563185, acc: 76.56%] [G loss: 1.671789]\n",
      "epoch:4 step:3531 [D loss: 0.660706, acc: 59.38%] [G loss: 1.707744]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:4 step:3532 [D loss: 0.711863, acc: 50.78%] [G loss: 1.661861]\n",
      "epoch:4 step:3533 [D loss: 0.518798, acc: 82.03%] [G loss: 1.748325]\n",
      "epoch:4 step:3534 [D loss: 0.690316, acc: 51.56%] [G loss: 1.576006]\n",
      "epoch:4 step:3535 [D loss: 0.773653, acc: 50.78%] [G loss: 1.352758]\n",
      "epoch:4 step:3536 [D loss: 0.673112, acc: 61.72%] [G loss: 1.486427]\n",
      "epoch:4 step:3537 [D loss: 0.731032, acc: 51.56%] [G loss: 1.409114]\n",
      "epoch:4 step:3538 [D loss: 0.875172, acc: 31.25%] [G loss: 1.492310]\n",
      "epoch:4 step:3539 [D loss: 0.679036, acc: 59.38%] [G loss: 1.628867]\n",
      "epoch:4 step:3540 [D loss: 0.615615, acc: 68.75%] [G loss: 1.450718]\n",
      "epoch:4 step:3541 [D loss: 0.716543, acc: 50.78%] [G loss: 1.391860]\n",
      "epoch:4 step:3542 [D loss: 0.827990, acc: 40.62%] [G loss: 1.381555]\n",
      "epoch:4 step:3543 [D loss: 0.810153, acc: 32.81%] [G loss: 1.327691]\n",
      "epoch:4 step:3544 [D loss: 0.921943, acc: 25.00%] [G loss: 1.423919]\n",
      "epoch:4 step:3545 [D loss: 0.662952, acc: 60.94%] [G loss: 1.647007]\n",
      "epoch:4 step:3546 [D loss: 0.621624, acc: 61.72%] [G loss: 1.608745]\n",
      "epoch:4 step:3547 [D loss: 0.684328, acc: 57.81%] [G loss: 1.635927]\n",
      "epoch:4 step:3548 [D loss: 0.756561, acc: 42.97%] [G loss: 1.625727]\n",
      "epoch:4 step:3549 [D loss: 0.764380, acc: 40.62%] [G loss: 1.599956]\n",
      "epoch:4 step:3550 [D loss: 0.750691, acc: 49.22%] [G loss: 1.590868]\n",
      "epoch:4 step:3551 [D loss: 0.662005, acc: 56.25%] [G loss: 1.633649]\n",
      "epoch:4 step:3552 [D loss: 0.661904, acc: 60.16%] [G loss: 1.685985]\n",
      "epoch:4 step:3553 [D loss: 0.710243, acc: 57.81%] [G loss: 1.743833]\n",
      "epoch:4 step:3554 [D loss: 0.704517, acc: 56.25%] [G loss: 1.619634]\n",
      "epoch:4 step:3555 [D loss: 0.637779, acc: 67.97%] [G loss: 1.855449]\n",
      "epoch:4 step:3556 [D loss: 0.740637, acc: 48.44%] [G loss: 1.800374]\n",
      "epoch:4 step:3557 [D loss: 0.708690, acc: 55.47%] [G loss: 1.591851]\n",
      "epoch:4 step:3558 [D loss: 0.819621, acc: 33.59%] [G loss: 1.552859]\n",
      "epoch:4 step:3559 [D loss: 0.826499, acc: 35.94%] [G loss: 1.432159]\n",
      "epoch:4 step:3560 [D loss: 0.769526, acc: 46.88%] [G loss: 1.433686]\n",
      "epoch:4 step:3561 [D loss: 0.718519, acc: 53.12%] [G loss: 1.445867]\n",
      "epoch:4 step:3562 [D loss: 0.717842, acc: 51.56%] [G loss: 1.613593]\n",
      "epoch:4 step:3563 [D loss: 0.637397, acc: 70.31%] [G loss: 1.660317]\n",
      "epoch:4 step:3564 [D loss: 0.734704, acc: 51.56%] [G loss: 1.597778]\n",
      "epoch:4 step:3565 [D loss: 0.700438, acc: 57.81%] [G loss: 1.681266]\n",
      "epoch:4 step:3566 [D loss: 0.722374, acc: 47.66%] [G loss: 1.621812]\n",
      "epoch:4 step:3567 [D loss: 0.728910, acc: 46.09%] [G loss: 1.477479]\n",
      "epoch:4 step:3568 [D loss: 0.650983, acc: 63.28%] [G loss: 1.757777]\n",
      "epoch:4 step:3569 [D loss: 0.686560, acc: 53.12%] [G loss: 1.645563]\n",
      "epoch:4 step:3570 [D loss: 0.674224, acc: 60.94%] [G loss: 1.750120]\n",
      "epoch:4 step:3571 [D loss: 0.755272, acc: 43.75%] [G loss: 1.579015]\n",
      "epoch:4 step:3572 [D loss: 0.795553, acc: 39.84%] [G loss: 1.623694]\n",
      "epoch:4 step:3573 [D loss: 0.708923, acc: 55.47%] [G loss: 1.586035]\n",
      "epoch:4 step:3574 [D loss: 0.686153, acc: 54.69%] [G loss: 1.590420]\n",
      "epoch:4 step:3575 [D loss: 0.688583, acc: 53.12%] [G loss: 1.554268]\n",
      "epoch:4 step:3576 [D loss: 0.671182, acc: 58.59%] [G loss: 1.602613]\n",
      "epoch:4 step:3577 [D loss: 0.738492, acc: 40.62%] [G loss: 1.717551]\n",
      "epoch:4 step:3578 [D loss: 0.705316, acc: 55.47%] [G loss: 1.530208]\n",
      "epoch:4 step:3579 [D loss: 0.777141, acc: 42.19%] [G loss: 1.561826]\n",
      "epoch:4 step:3580 [D loss: 0.799058, acc: 35.94%] [G loss: 1.523869]\n",
      "epoch:4 step:3581 [D loss: 0.732111, acc: 44.53%] [G loss: 1.483133]\n",
      "epoch:4 step:3582 [D loss: 0.626958, acc: 71.88%] [G loss: 1.651389]\n",
      "epoch:4 step:3583 [D loss: 0.671836, acc: 53.91%] [G loss: 1.633104]\n",
      "epoch:4 step:3584 [D loss: 0.710513, acc: 51.56%] [G loss: 1.548136]\n",
      "epoch:4 step:3585 [D loss: 0.721455, acc: 49.22%] [G loss: 1.605217]\n",
      "epoch:4 step:3586 [D loss: 0.644205, acc: 70.31%] [G loss: 1.740150]\n",
      "epoch:4 step:3587 [D loss: 0.570653, acc: 73.44%] [G loss: 1.761884]\n",
      "epoch:4 step:3588 [D loss: 0.695215, acc: 54.69%] [G loss: 1.750109]\n",
      "epoch:4 step:3589 [D loss: 0.764665, acc: 35.94%] [G loss: 1.571397]\n",
      "epoch:4 step:3590 [D loss: 0.630389, acc: 64.84%] [G loss: 1.763272]\n",
      "epoch:4 step:3591 [D loss: 0.697417, acc: 55.47%] [G loss: 1.591589]\n",
      "epoch:4 step:3592 [D loss: 0.680287, acc: 53.12%] [G loss: 1.664284]\n",
      "epoch:4 step:3593 [D loss: 0.655169, acc: 60.16%] [G loss: 1.669536]\n",
      "epoch:4 step:3594 [D loss: 0.750478, acc: 42.97%] [G loss: 1.444527]\n",
      "epoch:4 step:3595 [D loss: 0.779580, acc: 40.62%] [G loss: 1.385792]\n",
      "epoch:4 step:3596 [D loss: 0.760362, acc: 44.53%] [G loss: 1.450644]\n",
      "epoch:4 step:3597 [D loss: 0.847133, acc: 28.12%] [G loss: 1.373947]\n",
      "epoch:4 step:3598 [D loss: 0.761035, acc: 43.75%] [G loss: 1.383175]\n",
      "epoch:4 step:3599 [D loss: 0.804010, acc: 42.97%] [G loss: 1.529801]\n",
      "epoch:4 step:3600 [D loss: 0.747870, acc: 53.12%] [G loss: 1.392241]\n",
      "##############\n",
      "[0.83567181 0.8695818  0.81181126 0.81439434 0.77828871 0.82323888\n",
      " 0.8924984  0.81973157 0.82270738 0.83955441]\n",
      "##########\n",
      "epoch:4 step:3601 [D loss: 0.671575, acc: 58.59%] [G loss: 1.528520]\n",
      "epoch:4 step:3602 [D loss: 0.725375, acc: 53.12%] [G loss: 1.506240]\n",
      "epoch:4 step:3603 [D loss: 0.816636, acc: 36.72%] [G loss: 1.465597]\n",
      "epoch:4 step:3604 [D loss: 0.791608, acc: 31.25%] [G loss: 1.492114]\n",
      "epoch:4 step:3605 [D loss: 0.763300, acc: 40.62%] [G loss: 1.478878]\n",
      "epoch:4 step:3606 [D loss: 0.876320, acc: 24.22%] [G loss: 1.406760]\n",
      "epoch:4 step:3607 [D loss: 0.726611, acc: 46.88%] [G loss: 1.568923]\n",
      "epoch:4 step:3608 [D loss: 0.673731, acc: 60.94%] [G loss: 1.514635]\n",
      "epoch:4 step:3609 [D loss: 0.723189, acc: 46.88%] [G loss: 1.555509]\n",
      "epoch:4 step:3610 [D loss: 0.749169, acc: 45.31%] [G loss: 1.526665]\n",
      "epoch:4 step:3611 [D loss: 0.713705, acc: 48.44%] [G loss: 1.453909]\n",
      "epoch:4 step:3612 [D loss: 0.695271, acc: 56.25%] [G loss: 1.593164]\n",
      "epoch:4 step:3613 [D loss: 0.758854, acc: 42.97%] [G loss: 1.489331]\n",
      "epoch:4 step:3614 [D loss: 0.736499, acc: 50.78%] [G loss: 1.462481]\n",
      "epoch:4 step:3615 [D loss: 0.659605, acc: 57.81%] [G loss: 1.569865]\n",
      "epoch:4 step:3616 [D loss: 0.721053, acc: 50.00%] [G loss: 1.584077]\n",
      "epoch:4 step:3617 [D loss: 0.629047, acc: 66.41%] [G loss: 1.622837]\n",
      "epoch:4 step:3618 [D loss: 0.709518, acc: 47.66%] [G loss: 1.588454]\n",
      "epoch:4 step:3619 [D loss: 0.554865, acc: 75.78%] [G loss: 1.660600]\n",
      "epoch:4 step:3620 [D loss: 0.694125, acc: 53.91%] [G loss: 1.588189]\n",
      "epoch:4 step:3621 [D loss: 0.772548, acc: 44.53%] [G loss: 1.375375]\n",
      "epoch:4 step:3622 [D loss: 0.751131, acc: 43.75%] [G loss: 1.550562]\n",
      "epoch:4 step:3623 [D loss: 0.852834, acc: 25.00%] [G loss: 1.326538]\n",
      "epoch:4 step:3624 [D loss: 0.715226, acc: 46.09%] [G loss: 1.466168]\n",
      "epoch:4 step:3625 [D loss: 0.578099, acc: 76.56%] [G loss: 1.738957]\n",
      "epoch:4 step:3626 [D loss: 0.632401, acc: 71.88%] [G loss: 1.491537]\n",
      "epoch:4 step:3627 [D loss: 0.627147, acc: 66.41%] [G loss: 1.474233]\n",
      "epoch:4 step:3628 [D loss: 0.782304, acc: 40.62%] [G loss: 1.372779]\n",
      "epoch:4 step:3629 [D loss: 0.787444, acc: 38.28%] [G loss: 1.475265]\n",
      "epoch:4 step:3630 [D loss: 0.746320, acc: 46.88%] [G loss: 1.414124]\n",
      "epoch:4 step:3631 [D loss: 0.624077, acc: 67.19%] [G loss: 1.747024]\n",
      "epoch:4 step:3632 [D loss: 0.738137, acc: 41.41%] [G loss: 1.557062]\n",
      "epoch:4 step:3633 [D loss: 0.674598, acc: 59.38%] [G loss: 1.709921]\n",
      "epoch:4 step:3634 [D loss: 0.724468, acc: 57.81%] [G loss: 1.514951]\n",
      "epoch:4 step:3635 [D loss: 0.641553, acc: 64.84%] [G loss: 1.618804]\n",
      "epoch:4 step:3636 [D loss: 0.736075, acc: 42.97%] [G loss: 1.518324]\n",
      "epoch:4 step:3637 [D loss: 0.736145, acc: 42.97%] [G loss: 1.641104]\n",
      "epoch:4 step:3638 [D loss: 0.746718, acc: 43.75%] [G loss: 1.631005]\n",
      "epoch:4 step:3639 [D loss: 0.706974, acc: 54.69%] [G loss: 1.477824]\n",
      "epoch:4 step:3640 [D loss: 0.679913, acc: 59.38%] [G loss: 1.585128]\n",
      "epoch:4 step:3641 [D loss: 0.644469, acc: 62.50%] [G loss: 1.694362]\n",
      "epoch:4 step:3642 [D loss: 0.832640, acc: 28.91%] [G loss: 1.532024]\n",
      "epoch:4 step:3643 [D loss: 0.817337, acc: 30.47%] [G loss: 1.406329]\n",
      "epoch:4 step:3644 [D loss: 0.711598, acc: 53.12%] [G loss: 1.549673]\n",
      "epoch:4 step:3645 [D loss: 0.571138, acc: 71.09%] [G loss: 1.653139]\n",
      "epoch:4 step:3646 [D loss: 0.660543, acc: 57.81%] [G loss: 1.573922]\n",
      "epoch:4 step:3647 [D loss: 0.772410, acc: 44.53%] [G loss: 1.637634]\n",
      "epoch:4 step:3648 [D loss: 0.688451, acc: 53.91%] [G loss: 1.545581]\n",
      "epoch:4 step:3649 [D loss: 0.601985, acc: 70.31%] [G loss: 1.636665]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:4 step:3650 [D loss: 0.815743, acc: 35.16%] [G loss: 1.689076]\n",
      "epoch:4 step:3651 [D loss: 0.629431, acc: 66.41%] [G loss: 1.570647]\n",
      "epoch:4 step:3652 [D loss: 0.718570, acc: 53.12%] [G loss: 1.505872]\n",
      "epoch:4 step:3653 [D loss: 0.751079, acc: 45.31%] [G loss: 1.547182]\n",
      "epoch:4 step:3654 [D loss: 0.748692, acc: 48.44%] [G loss: 1.519365]\n",
      "epoch:4 step:3655 [D loss: 0.689125, acc: 53.12%] [G loss: 1.530954]\n",
      "epoch:4 step:3656 [D loss: 0.597038, acc: 73.44%] [G loss: 1.590357]\n",
      "epoch:4 step:3657 [D loss: 0.783057, acc: 49.22%] [G loss: 1.514450]\n",
      "epoch:4 step:3658 [D loss: 0.696261, acc: 54.69%] [G loss: 1.518305]\n",
      "epoch:4 step:3659 [D loss: 0.643814, acc: 66.41%] [G loss: 1.618326]\n",
      "epoch:4 step:3660 [D loss: 0.566543, acc: 67.97%] [G loss: 1.589193]\n",
      "epoch:4 step:3661 [D loss: 0.665074, acc: 54.69%] [G loss: 1.824281]\n",
      "epoch:4 step:3662 [D loss: 0.789622, acc: 42.19%] [G loss: 1.499930]\n",
      "epoch:4 step:3663 [D loss: 0.714133, acc: 52.34%] [G loss: 1.566241]\n",
      "epoch:4 step:3664 [D loss: 0.736247, acc: 46.09%] [G loss: 1.560750]\n",
      "epoch:4 step:3665 [D loss: 0.728818, acc: 53.12%] [G loss: 1.645529]\n",
      "epoch:4 step:3666 [D loss: 0.716438, acc: 52.34%] [G loss: 1.681008]\n",
      "epoch:4 step:3667 [D loss: 0.665806, acc: 60.94%] [G loss: 1.692142]\n",
      "epoch:4 step:3668 [D loss: 0.689786, acc: 53.91%] [G loss: 1.524466]\n",
      "epoch:4 step:3669 [D loss: 0.697652, acc: 52.34%] [G loss: 1.679559]\n",
      "epoch:4 step:3670 [D loss: 0.756242, acc: 45.31%] [G loss: 1.521546]\n",
      "epoch:4 step:3671 [D loss: 0.655969, acc: 53.91%] [G loss: 1.609569]\n",
      "epoch:4 step:3672 [D loss: 0.764748, acc: 40.62%] [G loss: 1.493547]\n",
      "epoch:4 step:3673 [D loss: 0.677427, acc: 54.69%] [G loss: 1.673689]\n",
      "epoch:4 step:3674 [D loss: 0.678120, acc: 57.03%] [G loss: 1.549666]\n",
      "epoch:4 step:3675 [D loss: 0.729633, acc: 51.56%] [G loss: 1.577284]\n",
      "epoch:4 step:3676 [D loss: 0.717144, acc: 52.34%] [G loss: 1.575058]\n",
      "epoch:4 step:3677 [D loss: 0.716354, acc: 52.34%] [G loss: 1.585150]\n",
      "epoch:4 step:3678 [D loss: 0.453164, acc: 85.16%] [G loss: 1.736936]\n",
      "epoch:4 step:3679 [D loss: 0.747029, acc: 46.09%] [G loss: 1.485031]\n",
      "epoch:4 step:3680 [D loss: 0.588727, acc: 71.09%] [G loss: 1.546858]\n",
      "epoch:4 step:3681 [D loss: 0.591748, acc: 75.78%] [G loss: 1.506645]\n",
      "epoch:4 step:3682 [D loss: 0.721982, acc: 42.19%] [G loss: 1.390386]\n",
      "epoch:4 step:3683 [D loss: 0.594524, acc: 75.00%] [G loss: 1.467815]\n",
      "epoch:4 step:3684 [D loss: 0.739770, acc: 50.00%] [G loss: 1.626962]\n",
      "epoch:4 step:3685 [D loss: 0.834030, acc: 26.56%] [G loss: 1.457623]\n",
      "epoch:4 step:3686 [D loss: 0.722759, acc: 50.78%] [G loss: 1.518263]\n",
      "epoch:4 step:3687 [D loss: 0.721638, acc: 46.88%] [G loss: 1.513967]\n",
      "epoch:4 step:3688 [D loss: 0.754135, acc: 42.19%] [G loss: 1.341323]\n",
      "epoch:4 step:3689 [D loss: 0.845431, acc: 20.31%] [G loss: 1.395730]\n",
      "epoch:4 step:3690 [D loss: 0.800637, acc: 36.72%] [G loss: 1.451286]\n",
      "epoch:4 step:3691 [D loss: 0.718468, acc: 42.97%] [G loss: 1.498952]\n",
      "epoch:4 step:3692 [D loss: 0.713204, acc: 50.78%] [G loss: 1.611581]\n",
      "epoch:4 step:3693 [D loss: 0.565222, acc: 75.78%] [G loss: 1.673347]\n",
      "epoch:4 step:3694 [D loss: 0.695054, acc: 53.91%] [G loss: 1.503793]\n",
      "epoch:4 step:3695 [D loss: 0.720151, acc: 48.44%] [G loss: 1.582232]\n",
      "epoch:4 step:3696 [D loss: 0.633755, acc: 65.62%] [G loss: 1.621318]\n",
      "epoch:4 step:3697 [D loss: 0.690305, acc: 59.38%] [G loss: 1.708935]\n",
      "epoch:4 step:3698 [D loss: 0.628015, acc: 65.62%] [G loss: 1.558100]\n",
      "epoch:4 step:3699 [D loss: 0.638929, acc: 60.94%] [G loss: 1.607293]\n",
      "epoch:4 step:3700 [D loss: 0.759537, acc: 40.62%] [G loss: 1.535248]\n",
      "epoch:4 step:3701 [D loss: 0.744687, acc: 44.53%] [G loss: 1.623521]\n",
      "epoch:4 step:3702 [D loss: 0.797744, acc: 38.28%] [G loss: 1.558022]\n",
      "epoch:4 step:3703 [D loss: 0.705465, acc: 46.88%] [G loss: 1.678059]\n",
      "epoch:4 step:3704 [D loss: 0.754710, acc: 46.09%] [G loss: 1.617305]\n",
      "epoch:4 step:3705 [D loss: 0.769562, acc: 47.66%] [G loss: 1.723707]\n",
      "epoch:4 step:3706 [D loss: 0.687512, acc: 57.03%] [G loss: 1.680281]\n",
      "epoch:4 step:3707 [D loss: 0.653710, acc: 57.81%] [G loss: 1.646671]\n",
      "epoch:4 step:3708 [D loss: 0.684557, acc: 60.16%] [G loss: 1.633985]\n",
      "epoch:4 step:3709 [D loss: 0.730022, acc: 47.66%] [G loss: 1.555743]\n",
      "epoch:4 step:3710 [D loss: 0.698936, acc: 53.12%] [G loss: 1.639724]\n",
      "epoch:4 step:3711 [D loss: 0.688542, acc: 58.59%] [G loss: 1.618255]\n",
      "epoch:4 step:3712 [D loss: 0.829482, acc: 28.12%] [G loss: 1.526902]\n",
      "epoch:4 step:3713 [D loss: 0.755761, acc: 47.66%] [G loss: 1.418900]\n",
      "epoch:4 step:3714 [D loss: 0.565627, acc: 78.12%] [G loss: 1.522515]\n",
      "epoch:4 step:3715 [D loss: 0.609575, acc: 67.97%] [G loss: 1.580740]\n",
      "epoch:4 step:3716 [D loss: 0.739937, acc: 52.34%] [G loss: 1.694752]\n",
      "epoch:4 step:3717 [D loss: 0.655375, acc: 59.38%] [G loss: 1.591410]\n",
      "epoch:4 step:3718 [D loss: 0.575721, acc: 70.31%] [G loss: 1.715608]\n",
      "epoch:4 step:3719 [D loss: 0.676071, acc: 60.94%] [G loss: 1.439510]\n",
      "epoch:4 step:3720 [D loss: 0.816986, acc: 35.16%] [G loss: 1.435794]\n",
      "epoch:4 step:3721 [D loss: 0.728742, acc: 51.56%] [G loss: 1.555175]\n",
      "epoch:4 step:3722 [D loss: 0.650423, acc: 60.94%] [G loss: 1.493098]\n",
      "epoch:4 step:3723 [D loss: 0.760462, acc: 43.75%] [G loss: 1.539736]\n",
      "epoch:4 step:3724 [D loss: 0.771197, acc: 49.22%] [G loss: 1.453151]\n",
      "epoch:4 step:3725 [D loss: 0.689241, acc: 58.59%] [G loss: 1.473523]\n",
      "epoch:4 step:3726 [D loss: 0.565660, acc: 73.44%] [G loss: 1.616890]\n",
      "epoch:4 step:3727 [D loss: 0.908637, acc: 20.31%] [G loss: 1.376843]\n",
      "epoch:4 step:3728 [D loss: 0.717096, acc: 49.22%] [G loss: 1.656915]\n",
      "epoch:4 step:3729 [D loss: 0.730400, acc: 44.53%] [G loss: 1.526002]\n",
      "epoch:4 step:3730 [D loss: 0.547393, acc: 77.34%] [G loss: 1.528688]\n",
      "epoch:4 step:3731 [D loss: 0.784052, acc: 36.72%] [G loss: 1.460429]\n",
      "epoch:4 step:3732 [D loss: 0.632972, acc: 66.41%] [G loss: 1.376885]\n",
      "epoch:4 step:3733 [D loss: 0.841813, acc: 32.03%] [G loss: 1.449605]\n",
      "epoch:4 step:3734 [D loss: 0.808480, acc: 35.94%] [G loss: 1.407389]\n",
      "epoch:4 step:3735 [D loss: 0.687726, acc: 55.47%] [G loss: 1.691773]\n",
      "epoch:4 step:3736 [D loss: 0.722066, acc: 46.09%] [G loss: 1.630949]\n",
      "epoch:4 step:3737 [D loss: 0.751602, acc: 50.00%] [G loss: 1.589429]\n",
      "epoch:4 step:3738 [D loss: 0.768070, acc: 40.62%] [G loss: 1.514606]\n",
      "epoch:4 step:3739 [D loss: 0.605486, acc: 67.19%] [G loss: 1.723432]\n",
      "epoch:4 step:3740 [D loss: 0.712915, acc: 51.56%] [G loss: 1.622209]\n",
      "epoch:4 step:3741 [D loss: 0.690384, acc: 54.69%] [G loss: 1.908961]\n",
      "epoch:4 step:3742 [D loss: 0.614638, acc: 70.31%] [G loss: 1.584036]\n",
      "epoch:4 step:3743 [D loss: 0.550379, acc: 73.44%] [G loss: 1.623163]\n",
      "epoch:4 step:3744 [D loss: 0.887387, acc: 28.12%] [G loss: 1.427881]\n",
      "epoch:4 step:3745 [D loss: 0.624904, acc: 67.97%] [G loss: 1.656696]\n",
      "epoch:4 step:3746 [D loss: 0.717916, acc: 53.12%] [G loss: 1.716989]\n",
      "epoch:4 step:3747 [D loss: 0.921963, acc: 20.31%] [G loss: 1.407534]\n",
      "epoch:4 step:3748 [D loss: 0.626788, acc: 70.31%] [G loss: 1.597029]\n",
      "epoch:4 step:3749 [D loss: 0.711274, acc: 51.56%] [G loss: 1.401351]\n",
      "epoch:4 step:3750 [D loss: 0.769895, acc: 43.75%] [G loss: 1.352846]\n",
      "epoch:4 step:3751 [D loss: 0.735069, acc: 46.09%] [G loss: 1.473313]\n",
      "epoch:4 step:3752 [D loss: 0.783674, acc: 38.28%] [G loss: 1.463595]\n",
      "epoch:4 step:3753 [D loss: 0.667864, acc: 60.94%] [G loss: 1.542301]\n",
      "epoch:4 step:3754 [D loss: 0.735759, acc: 49.22%] [G loss: 1.445929]\n",
      "epoch:4 step:3755 [D loss: 0.732780, acc: 46.88%] [G loss: 1.476523]\n",
      "epoch:4 step:3756 [D loss: 0.709282, acc: 52.34%] [G loss: 1.539106]\n",
      "epoch:4 step:3757 [D loss: 0.764013, acc: 46.88%] [G loss: 1.423318]\n",
      "epoch:4 step:3758 [D loss: 0.691318, acc: 50.78%] [G loss: 1.482509]\n",
      "epoch:4 step:3759 [D loss: 0.692771, acc: 57.03%] [G loss: 1.489230]\n",
      "epoch:4 step:3760 [D loss: 0.577248, acc: 75.78%] [G loss: 1.581161]\n",
      "epoch:4 step:3761 [D loss: 0.985884, acc: 15.62%] [G loss: 1.252652]\n",
      "epoch:4 step:3762 [D loss: 0.752819, acc: 46.09%] [G loss: 1.457365]\n",
      "epoch:4 step:3763 [D loss: 0.686409, acc: 53.91%] [G loss: 1.418607]\n",
      "epoch:4 step:3764 [D loss: 0.750365, acc: 46.09%] [G loss: 1.488783]\n",
      "epoch:4 step:3765 [D loss: 0.727950, acc: 48.44%] [G loss: 1.560798]\n",
      "epoch:4 step:3766 [D loss: 0.726975, acc: 51.56%] [G loss: 1.557636]\n",
      "epoch:4 step:3767 [D loss: 0.756226, acc: 44.53%] [G loss: 1.529585]\n",
      "epoch:4 step:3768 [D loss: 0.755539, acc: 45.31%] [G loss: 1.575877]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:4 step:3769 [D loss: 0.709481, acc: 48.44%] [G loss: 1.516239]\n",
      "epoch:4 step:3770 [D loss: 0.791612, acc: 42.19%] [G loss: 1.446766]\n",
      "epoch:4 step:3771 [D loss: 0.722651, acc: 51.56%] [G loss: 1.475652]\n",
      "epoch:4 step:3772 [D loss: 0.730861, acc: 50.00%] [G loss: 1.499294]\n",
      "epoch:4 step:3773 [D loss: 0.835397, acc: 26.56%] [G loss: 1.568191]\n",
      "epoch:4 step:3774 [D loss: 0.628587, acc: 61.72%] [G loss: 1.663057]\n",
      "epoch:4 step:3775 [D loss: 0.677097, acc: 57.81%] [G loss: 1.677169]\n",
      "epoch:4 step:3776 [D loss: 0.732674, acc: 43.75%] [G loss: 1.465800]\n",
      "epoch:4 step:3777 [D loss: 0.674977, acc: 56.25%] [G loss: 1.663781]\n",
      "epoch:4 step:3778 [D loss: 0.661267, acc: 61.72%] [G loss: 1.580680]\n",
      "epoch:4 step:3779 [D loss: 0.702792, acc: 57.81%] [G loss: 1.648309]\n",
      "epoch:4 step:3780 [D loss: 0.824425, acc: 30.47%] [G loss: 1.554256]\n",
      "epoch:4 step:3781 [D loss: 0.701202, acc: 55.47%] [G loss: 1.641487]\n",
      "epoch:4 step:3782 [D loss: 0.645916, acc: 65.62%] [G loss: 1.569028]\n",
      "epoch:4 step:3783 [D loss: 0.645944, acc: 60.16%] [G loss: 1.722924]\n",
      "epoch:4 step:3784 [D loss: 0.659384, acc: 56.25%] [G loss: 1.468217]\n",
      "epoch:4 step:3785 [D loss: 0.734683, acc: 46.88%] [G loss: 1.483509]\n",
      "epoch:4 step:3786 [D loss: 0.559579, acc: 78.12%] [G loss: 1.825543]\n",
      "epoch:4 step:3787 [D loss: 0.584392, acc: 80.47%] [G loss: 1.696095]\n",
      "epoch:4 step:3788 [D loss: 0.635202, acc: 60.94%] [G loss: 1.803154]\n",
      "epoch:4 step:3789 [D loss: 0.610982, acc: 67.19%] [G loss: 1.937424]\n",
      "epoch:4 step:3790 [D loss: 0.675944, acc: 57.03%] [G loss: 1.527263]\n",
      "epoch:4 step:3791 [D loss: 0.711446, acc: 47.66%] [G loss: 1.246668]\n",
      "epoch:4 step:3792 [D loss: 0.761799, acc: 44.53%] [G loss: 1.743294]\n",
      "epoch:4 step:3793 [D loss: 0.807790, acc: 34.38%] [G loss: 1.405137]\n",
      "epoch:4 step:3794 [D loss: 0.693842, acc: 53.12%] [G loss: 1.659059]\n",
      "epoch:4 step:3795 [D loss: 0.701804, acc: 56.25%] [G loss: 1.500999]\n",
      "epoch:4 step:3796 [D loss: 0.845567, acc: 26.56%] [G loss: 1.367053]\n",
      "epoch:4 step:3797 [D loss: 0.656603, acc: 62.50%] [G loss: 1.479857]\n",
      "epoch:4 step:3798 [D loss: 0.765773, acc: 44.53%] [G loss: 1.476351]\n",
      "epoch:4 step:3799 [D loss: 0.727876, acc: 42.19%] [G loss: 1.442991]\n",
      "epoch:4 step:3800 [D loss: 0.687856, acc: 50.00%] [G loss: 1.579350]\n",
      "##############\n",
      "[0.84495088 0.86453173 0.81038779 0.81594031 0.76857225 0.81685833\n",
      " 0.89020396 0.84386493 0.79720783 0.84225723]\n",
      "##########\n",
      "epoch:4 step:3801 [D loss: 0.755727, acc: 41.41%] [G loss: 1.573072]\n",
      "epoch:4 step:3802 [D loss: 0.749851, acc: 44.53%] [G loss: 1.490993]\n",
      "epoch:4 step:3803 [D loss: 0.713386, acc: 53.12%] [G loss: 1.403300]\n",
      "epoch:4 step:3804 [D loss: 0.673807, acc: 56.25%] [G loss: 1.570980]\n",
      "epoch:4 step:3805 [D loss: 0.722510, acc: 45.31%] [G loss: 1.474194]\n",
      "epoch:4 step:3806 [D loss: 0.715235, acc: 52.34%] [G loss: 1.507957]\n",
      "epoch:4 step:3807 [D loss: 0.741852, acc: 48.44%] [G loss: 1.620258]\n",
      "epoch:4 step:3808 [D loss: 0.659617, acc: 60.16%] [G loss: 1.621426]\n",
      "epoch:4 step:3809 [D loss: 0.686145, acc: 58.59%] [G loss: 1.654067]\n",
      "epoch:4 step:3810 [D loss: 0.654881, acc: 60.94%] [G loss: 1.608289]\n",
      "epoch:4 step:3811 [D loss: 0.698479, acc: 56.25%] [G loss: 1.604433]\n",
      "epoch:4 step:3812 [D loss: 0.783629, acc: 35.16%] [G loss: 1.481989]\n",
      "epoch:4 step:3813 [D loss: 0.690242, acc: 56.25%] [G loss: 1.690568]\n",
      "epoch:4 step:3814 [D loss: 0.683913, acc: 57.03%] [G loss: 1.726702]\n",
      "epoch:4 step:3815 [D loss: 0.788207, acc: 43.75%] [G loss: 1.655843]\n",
      "epoch:4 step:3816 [D loss: 0.762090, acc: 42.19%] [G loss: 1.561553]\n",
      "epoch:4 step:3817 [D loss: 0.658947, acc: 65.62%] [G loss: 1.677656]\n",
      "epoch:4 step:3818 [D loss: 0.714671, acc: 54.69%] [G loss: 1.702357]\n",
      "epoch:4 step:3819 [D loss: 0.703749, acc: 53.12%] [G loss: 1.661600]\n",
      "epoch:4 step:3820 [D loss: 0.674300, acc: 57.03%] [G loss: 1.531782]\n",
      "epoch:4 step:3821 [D loss: 0.719195, acc: 44.53%] [G loss: 1.572497]\n",
      "epoch:4 step:3822 [D loss: 0.591927, acc: 73.44%] [G loss: 1.663462]\n",
      "epoch:4 step:3823 [D loss: 0.769159, acc: 38.28%] [G loss: 1.484014]\n",
      "epoch:4 step:3824 [D loss: 0.712545, acc: 50.00%] [G loss: 1.612786]\n",
      "epoch:4 step:3825 [D loss: 0.656264, acc: 57.81%] [G loss: 1.525416]\n",
      "epoch:4 step:3826 [D loss: 0.703174, acc: 50.00%] [G loss: 1.541414]\n",
      "epoch:4 step:3827 [D loss: 0.561340, acc: 71.88%] [G loss: 1.619287]\n",
      "epoch:4 step:3828 [D loss: 0.923861, acc: 21.09%] [G loss: 1.353528]\n",
      "epoch:4 step:3829 [D loss: 0.595416, acc: 67.97%] [G loss: 1.692871]\n",
      "epoch:4 step:3830 [D loss: 0.741667, acc: 43.75%] [G loss: 1.538749]\n",
      "epoch:4 step:3831 [D loss: 0.781305, acc: 42.97%] [G loss: 1.391667]\n",
      "epoch:4 step:3832 [D loss: 0.570882, acc: 67.19%] [G loss: 1.475261]\n",
      "epoch:4 step:3833 [D loss: 0.773901, acc: 40.62%] [G loss: 1.498791]\n",
      "epoch:4 step:3834 [D loss: 0.687450, acc: 56.25%] [G loss: 1.489212]\n",
      "epoch:4 step:3835 [D loss: 0.694084, acc: 55.47%] [G loss: 1.567620]\n",
      "epoch:4 step:3836 [D loss: 0.734504, acc: 46.88%] [G loss: 1.484787]\n",
      "epoch:4 step:3837 [D loss: 0.855949, acc: 28.91%] [G loss: 1.367093]\n",
      "epoch:4 step:3838 [D loss: 0.676182, acc: 57.03%] [G loss: 1.628013]\n",
      "epoch:4 step:3839 [D loss: 0.888816, acc: 26.56%] [G loss: 1.494733]\n",
      "epoch:4 step:3840 [D loss: 0.674289, acc: 60.16%] [G loss: 1.612344]\n",
      "epoch:4 step:3841 [D loss: 0.659822, acc: 63.28%] [G loss: 1.625361]\n",
      "epoch:4 step:3842 [D loss: 0.819444, acc: 30.47%] [G loss: 1.390139]\n",
      "epoch:4 step:3843 [D loss: 0.737583, acc: 42.19%] [G loss: 1.613248]\n",
      "epoch:4 step:3844 [D loss: 0.693969, acc: 53.12%] [G loss: 1.663789]\n",
      "epoch:4 step:3845 [D loss: 0.773929, acc: 39.06%] [G loss: 1.446009]\n",
      "epoch:4 step:3846 [D loss: 0.745261, acc: 42.97%] [G loss: 1.526516]\n",
      "epoch:4 step:3847 [D loss: 0.762033, acc: 40.62%] [G loss: 1.539455]\n",
      "epoch:4 step:3848 [D loss: 0.684779, acc: 52.34%] [G loss: 1.593812]\n",
      "epoch:4 step:3849 [D loss: 0.720484, acc: 45.31%] [G loss: 1.637680]\n",
      "epoch:4 step:3850 [D loss: 0.649423, acc: 60.94%] [G loss: 1.623594]\n",
      "epoch:4 step:3851 [D loss: 0.738714, acc: 48.44%] [G loss: 1.507325]\n",
      "epoch:4 step:3852 [D loss: 0.585518, acc: 71.88%] [G loss: 1.686298]\n",
      "epoch:4 step:3853 [D loss: 0.656691, acc: 64.84%] [G loss: 1.527327]\n",
      "epoch:4 step:3854 [D loss: 0.639054, acc: 62.50%] [G loss: 1.600643]\n",
      "epoch:4 step:3855 [D loss: 0.677174, acc: 55.47%] [G loss: 1.490361]\n",
      "epoch:4 step:3856 [D loss: 0.618804, acc: 74.22%] [G loss: 1.605887]\n",
      "epoch:4 step:3857 [D loss: 0.649156, acc: 64.84%] [G loss: 1.523168]\n",
      "epoch:4 step:3858 [D loss: 0.667948, acc: 64.84%] [G loss: 1.388735]\n",
      "epoch:4 step:3859 [D loss: 0.738687, acc: 44.53%] [G loss: 1.461587]\n",
      "epoch:4 step:3860 [D loss: 0.812409, acc: 32.03%] [G loss: 1.529903]\n",
      "epoch:4 step:3861 [D loss: 0.634657, acc: 67.97%] [G loss: 1.504853]\n",
      "epoch:4 step:3862 [D loss: 0.698598, acc: 57.03%] [G loss: 1.534597]\n",
      "epoch:4 step:3863 [D loss: 0.853809, acc: 33.59%] [G loss: 1.467074]\n",
      "epoch:4 step:3864 [D loss: 0.815986, acc: 29.69%] [G loss: 1.450081]\n",
      "epoch:4 step:3865 [D loss: 0.785114, acc: 41.41%] [G loss: 1.547615]\n",
      "epoch:4 step:3866 [D loss: 0.685028, acc: 53.91%] [G loss: 1.469319]\n",
      "epoch:4 step:3867 [D loss: 0.575192, acc: 76.56%] [G loss: 1.651686]\n",
      "epoch:4 step:3868 [D loss: 0.804779, acc: 31.25%] [G loss: 1.455496]\n",
      "epoch:4 step:3869 [D loss: 0.733052, acc: 44.53%] [G loss: 1.637928]\n",
      "epoch:4 step:3870 [D loss: 0.733210, acc: 51.56%] [G loss: 1.486452]\n",
      "epoch:4 step:3871 [D loss: 0.638600, acc: 65.62%] [G loss: 1.543138]\n",
      "epoch:4 step:3872 [D loss: 0.738050, acc: 50.78%] [G loss: 1.732171]\n",
      "epoch:4 step:3873 [D loss: 0.714442, acc: 46.09%] [G loss: 1.616786]\n",
      "epoch:4 step:3874 [D loss: 0.668423, acc: 63.28%] [G loss: 1.485024]\n",
      "epoch:4 step:3875 [D loss: 0.785816, acc: 39.06%] [G loss: 1.404533]\n",
      "epoch:4 step:3876 [D loss: 0.698708, acc: 53.91%] [G loss: 1.599728]\n",
      "epoch:4 step:3877 [D loss: 0.629039, acc: 67.19%] [G loss: 1.665465]\n",
      "epoch:4 step:3878 [D loss: 0.673341, acc: 60.94%] [G loss: 1.596702]\n",
      "epoch:4 step:3879 [D loss: 0.692352, acc: 56.25%] [G loss: 1.610932]\n",
      "epoch:4 step:3880 [D loss: 0.725089, acc: 53.91%] [G loss: 1.509793]\n",
      "epoch:4 step:3881 [D loss: 0.682858, acc: 51.56%] [G loss: 1.685910]\n",
      "epoch:4 step:3882 [D loss: 0.695160, acc: 53.12%] [G loss: 1.529356]\n",
      "epoch:4 step:3883 [D loss: 0.665207, acc: 61.72%] [G loss: 1.652035]\n",
      "epoch:4 step:3884 [D loss: 0.602942, acc: 68.75%] [G loss: 1.553271]\n",
      "epoch:4 step:3885 [D loss: 0.696708, acc: 59.38%] [G loss: 1.614822]\n",
      "epoch:4 step:3886 [D loss: 0.717749, acc: 50.78%] [G loss: 1.670973]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:4 step:3887 [D loss: 0.734391, acc: 43.75%] [G loss: 1.607516]\n",
      "epoch:4 step:3888 [D loss: 0.632146, acc: 65.62%] [G loss: 1.544018]\n",
      "epoch:4 step:3889 [D loss: 0.749297, acc: 47.66%] [G loss: 1.452649]\n",
      "epoch:4 step:3890 [D loss: 0.686854, acc: 56.25%] [G loss: 1.643715]\n",
      "epoch:4 step:3891 [D loss: 0.614362, acc: 70.31%] [G loss: 1.734437]\n",
      "epoch:4 step:3892 [D loss: 0.678035, acc: 60.94%] [G loss: 1.533049]\n",
      "epoch:4 step:3893 [D loss: 0.737821, acc: 51.56%] [G loss: 1.568922]\n",
      "epoch:4 step:3894 [D loss: 0.655782, acc: 58.59%] [G loss: 1.522338]\n",
      "epoch:4 step:3895 [D loss: 0.863582, acc: 31.25%] [G loss: 1.577256]\n",
      "epoch:4 step:3896 [D loss: 0.808583, acc: 39.06%] [G loss: 1.495109]\n",
      "epoch:4 step:3897 [D loss: 0.736450, acc: 46.88%] [G loss: 1.446092]\n",
      "epoch:4 step:3898 [D loss: 0.747855, acc: 46.09%] [G loss: 1.612350]\n",
      "epoch:4 step:3899 [D loss: 0.760792, acc: 45.31%] [G loss: 1.408771]\n",
      "epoch:4 step:3900 [D loss: 0.716240, acc: 50.78%] [G loss: 1.475855]\n",
      "epoch:4 step:3901 [D loss: 0.799685, acc: 35.16%] [G loss: 1.446861]\n",
      "epoch:4 step:3902 [D loss: 0.737730, acc: 44.53%] [G loss: 1.440299]\n",
      "epoch:4 step:3903 [D loss: 0.795636, acc: 35.94%] [G loss: 1.466784]\n",
      "epoch:4 step:3904 [D loss: 0.747037, acc: 47.66%] [G loss: 1.462102]\n",
      "epoch:4 step:3905 [D loss: 0.717740, acc: 46.88%] [G loss: 1.597376]\n",
      "epoch:5 step:3906 [D loss: 0.742164, acc: 42.97%] [G loss: 1.528967]\n",
      "epoch:5 step:3907 [D loss: 0.691051, acc: 58.59%] [G loss: 1.621958]\n",
      "epoch:5 step:3908 [D loss: 0.776596, acc: 38.28%] [G loss: 1.561345]\n",
      "epoch:5 step:3909 [D loss: 0.694402, acc: 55.47%] [G loss: 1.592962]\n",
      "epoch:5 step:3910 [D loss: 0.682134, acc: 56.25%] [G loss: 1.621332]\n",
      "epoch:5 step:3911 [D loss: 0.689742, acc: 53.12%] [G loss: 1.673956]\n",
      "epoch:5 step:3912 [D loss: 0.667850, acc: 59.38%] [G loss: 1.621874]\n",
      "epoch:5 step:3913 [D loss: 0.640733, acc: 64.06%] [G loss: 1.640177]\n",
      "epoch:5 step:3914 [D loss: 0.724337, acc: 53.12%] [G loss: 1.527330]\n",
      "epoch:5 step:3915 [D loss: 0.723350, acc: 52.34%] [G loss: 1.579487]\n",
      "epoch:5 step:3916 [D loss: 0.685056, acc: 56.25%] [G loss: 1.653499]\n",
      "epoch:5 step:3917 [D loss: 0.819198, acc: 28.91%] [G loss: 1.384830]\n",
      "epoch:5 step:3918 [D loss: 0.704396, acc: 55.47%] [G loss: 1.619238]\n",
      "epoch:5 step:3919 [D loss: 0.771367, acc: 41.41%] [G loss: 1.492388]\n",
      "epoch:5 step:3920 [D loss: 0.693003, acc: 57.03%] [G loss: 1.556242]\n",
      "epoch:5 step:3921 [D loss: 0.735578, acc: 46.09%] [G loss: 1.603363]\n",
      "epoch:5 step:3922 [D loss: 0.684467, acc: 54.69%] [G loss: 1.664292]\n",
      "epoch:5 step:3923 [D loss: 0.709533, acc: 51.56%] [G loss: 1.549563]\n",
      "epoch:5 step:3924 [D loss: 0.749009, acc: 40.62%] [G loss: 1.614770]\n",
      "epoch:5 step:3925 [D loss: 0.665549, acc: 64.06%] [G loss: 1.559043]\n",
      "epoch:5 step:3926 [D loss: 0.697802, acc: 56.25%] [G loss: 1.610165]\n",
      "epoch:5 step:3927 [D loss: 0.678795, acc: 57.81%] [G loss: 1.519098]\n",
      "epoch:5 step:3928 [D loss: 0.669498, acc: 59.38%] [G loss: 1.799219]\n",
      "epoch:5 step:3929 [D loss: 0.724527, acc: 50.78%] [G loss: 1.505788]\n",
      "epoch:5 step:3930 [D loss: 0.751959, acc: 49.22%] [G loss: 1.616983]\n",
      "epoch:5 step:3931 [D loss: 0.795048, acc: 34.38%] [G loss: 1.515916]\n",
      "epoch:5 step:3932 [D loss: 0.705429, acc: 50.78%] [G loss: 1.623157]\n",
      "epoch:5 step:3933 [D loss: 0.707935, acc: 52.34%] [G loss: 1.613286]\n",
      "epoch:5 step:3934 [D loss: 0.670866, acc: 59.38%] [G loss: 1.652136]\n",
      "epoch:5 step:3935 [D loss: 0.701605, acc: 53.12%] [G loss: 1.653047]\n",
      "epoch:5 step:3936 [D loss: 0.696145, acc: 53.91%] [G loss: 1.580709]\n",
      "epoch:5 step:3937 [D loss: 0.695843, acc: 51.56%] [G loss: 1.635345]\n",
      "epoch:5 step:3938 [D loss: 0.707539, acc: 47.66%] [G loss: 1.528013]\n",
      "epoch:5 step:3939 [D loss: 0.701722, acc: 54.69%] [G loss: 1.606174]\n",
      "epoch:5 step:3940 [D loss: 0.743418, acc: 41.41%] [G loss: 1.494752]\n",
      "epoch:5 step:3941 [D loss: 0.722092, acc: 43.75%] [G loss: 1.613472]\n",
      "epoch:5 step:3942 [D loss: 0.622532, acc: 71.88%] [G loss: 1.618147]\n",
      "epoch:5 step:3943 [D loss: 0.726364, acc: 48.44%] [G loss: 1.516708]\n",
      "epoch:5 step:3944 [D loss: 0.764261, acc: 39.06%] [G loss: 1.536576]\n",
      "epoch:5 step:3945 [D loss: 0.584945, acc: 75.00%] [G loss: 1.673000]\n",
      "epoch:5 step:3946 [D loss: 0.717538, acc: 48.44%] [G loss: 1.455550]\n",
      "epoch:5 step:3947 [D loss: 0.692272, acc: 50.00%] [G loss: 1.528702]\n",
      "epoch:5 step:3948 [D loss: 0.714082, acc: 49.22%] [G loss: 1.508657]\n",
      "epoch:5 step:3949 [D loss: 0.642459, acc: 67.19%] [G loss: 1.527494]\n",
      "epoch:5 step:3950 [D loss: 0.828987, acc: 33.59%] [G loss: 1.547761]\n",
      "epoch:5 step:3951 [D loss: 0.760057, acc: 54.69%] [G loss: 1.493629]\n",
      "epoch:5 step:3952 [D loss: 0.761243, acc: 38.28%] [G loss: 1.602387]\n",
      "epoch:5 step:3953 [D loss: 0.718392, acc: 50.78%] [G loss: 1.632606]\n",
      "epoch:5 step:3954 [D loss: 0.735686, acc: 51.56%] [G loss: 1.477906]\n",
      "epoch:5 step:3955 [D loss: 0.704647, acc: 52.34%] [G loss: 1.536559]\n",
      "epoch:5 step:3956 [D loss: 0.728980, acc: 50.00%] [G loss: 1.495904]\n",
      "epoch:5 step:3957 [D loss: 0.746906, acc: 44.53%] [G loss: 1.512995]\n",
      "epoch:5 step:3958 [D loss: 0.694078, acc: 49.22%] [G loss: 1.535789]\n",
      "epoch:5 step:3959 [D loss: 0.689811, acc: 60.16%] [G loss: 1.717542]\n",
      "epoch:5 step:3960 [D loss: 0.601182, acc: 67.97%] [G loss: 1.693843]\n",
      "epoch:5 step:3961 [D loss: 0.963584, acc: 26.56%] [G loss: 1.438886]\n",
      "epoch:5 step:3962 [D loss: 0.705079, acc: 54.69%] [G loss: 1.553482]\n",
      "epoch:5 step:3963 [D loss: 0.694715, acc: 54.69%] [G loss: 1.485409]\n",
      "epoch:5 step:3964 [D loss: 0.730257, acc: 50.78%] [G loss: 1.630606]\n",
      "epoch:5 step:3965 [D loss: 0.699626, acc: 57.03%] [G loss: 1.571883]\n",
      "epoch:5 step:3966 [D loss: 0.688887, acc: 54.69%] [G loss: 1.548049]\n",
      "epoch:5 step:3967 [D loss: 0.669050, acc: 60.16%] [G loss: 1.424340]\n",
      "epoch:5 step:3968 [D loss: 0.624396, acc: 66.41%] [G loss: 1.603203]\n",
      "epoch:5 step:3969 [D loss: 0.574541, acc: 74.22%] [G loss: 1.606683]\n",
      "epoch:5 step:3970 [D loss: 0.730223, acc: 49.22%] [G loss: 1.678841]\n",
      "epoch:5 step:3971 [D loss: 0.800520, acc: 36.72%] [G loss: 1.475113]\n",
      "epoch:5 step:3972 [D loss: 0.958381, acc: 16.41%] [G loss: 1.334748]\n",
      "epoch:5 step:3973 [D loss: 0.602308, acc: 64.84%] [G loss: 1.651623]\n",
      "epoch:5 step:3974 [D loss: 0.582399, acc: 71.88%] [G loss: 1.605845]\n",
      "epoch:5 step:3975 [D loss: 0.852702, acc: 35.94%] [G loss: 1.511463]\n",
      "epoch:5 step:3976 [D loss: 0.831731, acc: 32.03%] [G loss: 1.488920]\n",
      "epoch:5 step:3977 [D loss: 0.781885, acc: 37.50%] [G loss: 1.471197]\n",
      "epoch:5 step:3978 [D loss: 0.606712, acc: 75.78%] [G loss: 1.516846]\n",
      "epoch:5 step:3979 [D loss: 0.779918, acc: 35.16%] [G loss: 1.455922]\n",
      "epoch:5 step:3980 [D loss: 0.780605, acc: 35.16%] [G loss: 1.494864]\n",
      "epoch:5 step:3981 [D loss: 0.740708, acc: 39.84%] [G loss: 1.640111]\n",
      "epoch:5 step:3982 [D loss: 0.732436, acc: 51.56%] [G loss: 1.596464]\n",
      "epoch:5 step:3983 [D loss: 0.579343, acc: 75.00%] [G loss: 1.604803]\n",
      "epoch:5 step:3984 [D loss: 0.558279, acc: 78.12%] [G loss: 1.691220]\n",
      "epoch:5 step:3985 [D loss: 0.654127, acc: 64.06%] [G loss: 1.664823]\n",
      "epoch:5 step:3986 [D loss: 0.720959, acc: 49.22%] [G loss: 1.540004]\n",
      "epoch:5 step:3987 [D loss: 0.608476, acc: 65.62%] [G loss: 1.612309]\n",
      "epoch:5 step:3988 [D loss: 0.668909, acc: 57.81%] [G loss: 1.549534]\n",
      "epoch:5 step:3989 [D loss: 0.830469, acc: 25.00%] [G loss: 1.351967]\n",
      "epoch:5 step:3990 [D loss: 0.672406, acc: 56.25%] [G loss: 1.639242]\n",
      "epoch:5 step:3991 [D loss: 0.626251, acc: 70.31%] [G loss: 1.593333]\n",
      "epoch:5 step:3992 [D loss: 0.649329, acc: 64.06%] [G loss: 1.534329]\n",
      "epoch:5 step:3993 [D loss: 0.739395, acc: 43.75%] [G loss: 1.688598]\n",
      "epoch:5 step:3994 [D loss: 0.739206, acc: 50.78%] [G loss: 1.595358]\n",
      "epoch:5 step:3995 [D loss: 0.838940, acc: 30.47%] [G loss: 1.385140]\n",
      "epoch:5 step:3996 [D loss: 0.773384, acc: 42.97%] [G loss: 1.563371]\n",
      "epoch:5 step:3997 [D loss: 0.579931, acc: 78.91%] [G loss: 1.631369]\n",
      "epoch:5 step:3998 [D loss: 0.709525, acc: 55.47%] [G loss: 1.528357]\n",
      "epoch:5 step:3999 [D loss: 0.612042, acc: 71.09%] [G loss: 1.557626]\n",
      "epoch:5 step:4000 [D loss: 0.823758, acc: 28.91%] [G loss: 1.351845]\n",
      "##############\n",
      "[0.8483856  0.88805062 0.80952529 0.82440286 0.77004671 0.81926212\n",
      " 0.87122965 0.81791058 0.82294781 0.82590512]\n",
      "##########\n",
      "epoch:5 step:4001 [D loss: 0.718036, acc: 50.78%] [G loss: 1.547661]\n",
      "epoch:5 step:4002 [D loss: 0.589233, acc: 73.44%] [G loss: 1.647759]\n",
      "epoch:5 step:4003 [D loss: 0.787412, acc: 36.72%] [G loss: 1.470097]\n",
      "epoch:5 step:4004 [D loss: 0.744760, acc: 39.06%] [G loss: 1.742408]\n",
      "epoch:5 step:4005 [D loss: 0.718749, acc: 50.78%] [G loss: 1.532357]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:5 step:4006 [D loss: 0.741697, acc: 41.41%] [G loss: 1.513212]\n",
      "epoch:5 step:4007 [D loss: 0.721228, acc: 49.22%] [G loss: 1.512411]\n",
      "epoch:5 step:4008 [D loss: 0.768116, acc: 49.22%] [G loss: 1.472707]\n",
      "epoch:5 step:4009 [D loss: 0.697693, acc: 54.69%] [G loss: 1.622426]\n",
      "epoch:5 step:4010 [D loss: 0.700551, acc: 54.69%] [G loss: 1.609549]\n",
      "epoch:5 step:4011 [D loss: 0.692796, acc: 56.25%] [G loss: 1.728164]\n",
      "epoch:5 step:4012 [D loss: 0.747563, acc: 41.41%] [G loss: 1.660422]\n",
      "epoch:5 step:4013 [D loss: 0.684470, acc: 56.25%] [G loss: 1.678496]\n",
      "epoch:5 step:4014 [D loss: 0.718029, acc: 46.09%] [G loss: 1.611188]\n",
      "epoch:5 step:4015 [D loss: 0.639275, acc: 65.62%] [G loss: 1.637974]\n",
      "epoch:5 step:4016 [D loss: 0.835685, acc: 25.78%] [G loss: 1.737193]\n",
      "epoch:5 step:4017 [D loss: 0.724452, acc: 49.22%] [G loss: 1.561742]\n",
      "epoch:5 step:4018 [D loss: 0.654453, acc: 62.50%] [G loss: 1.573590]\n",
      "epoch:5 step:4019 [D loss: 0.626868, acc: 67.19%] [G loss: 1.672534]\n",
      "epoch:5 step:4020 [D loss: 0.701811, acc: 53.12%] [G loss: 1.507154]\n",
      "epoch:5 step:4021 [D loss: 0.732357, acc: 46.88%] [G loss: 1.461758]\n",
      "epoch:5 step:4022 [D loss: 0.686323, acc: 60.94%] [G loss: 1.587149]\n",
      "epoch:5 step:4023 [D loss: 0.684676, acc: 54.69%] [G loss: 1.729854]\n",
      "epoch:5 step:4024 [D loss: 0.725212, acc: 52.34%] [G loss: 1.650998]\n",
      "epoch:5 step:4025 [D loss: 0.703685, acc: 52.34%] [G loss: 1.568576]\n",
      "epoch:5 step:4026 [D loss: 0.743034, acc: 47.66%] [G loss: 1.590168]\n",
      "epoch:5 step:4027 [D loss: 0.657847, acc: 61.72%] [G loss: 1.752241]\n",
      "epoch:5 step:4028 [D loss: 0.701992, acc: 52.34%] [G loss: 1.592376]\n",
      "epoch:5 step:4029 [D loss: 0.709743, acc: 50.00%] [G loss: 1.645414]\n",
      "epoch:5 step:4030 [D loss: 0.656178, acc: 68.75%] [G loss: 1.575678]\n",
      "epoch:5 step:4031 [D loss: 0.679556, acc: 55.47%] [G loss: 1.559690]\n",
      "epoch:5 step:4032 [D loss: 0.802548, acc: 35.16%] [G loss: 1.612530]\n",
      "epoch:5 step:4033 [D loss: 0.677671, acc: 55.47%] [G loss: 1.583889]\n",
      "epoch:5 step:4034 [D loss: 0.524058, acc: 81.25%] [G loss: 1.711953]\n",
      "epoch:5 step:4035 [D loss: 0.774725, acc: 39.84%] [G loss: 1.339832]\n",
      "epoch:5 step:4036 [D loss: 0.755199, acc: 42.19%] [G loss: 1.604259]\n",
      "epoch:5 step:4037 [D loss: 0.448730, acc: 85.16%] [G loss: 1.638665]\n",
      "epoch:5 step:4038 [D loss: 0.807844, acc: 39.06%] [G loss: 1.505212]\n",
      "epoch:5 step:4039 [D loss: 0.746118, acc: 49.22%] [G loss: 1.527962]\n",
      "epoch:5 step:4040 [D loss: 0.709303, acc: 61.72%] [G loss: 1.472000]\n",
      "epoch:5 step:4041 [D loss: 0.711825, acc: 46.88%] [G loss: 1.638030]\n",
      "epoch:5 step:4042 [D loss: 0.744735, acc: 37.50%] [G loss: 1.393838]\n",
      "epoch:5 step:4043 [D loss: 0.691205, acc: 60.94%] [G loss: 1.610220]\n",
      "epoch:5 step:4044 [D loss: 0.772798, acc: 37.50%] [G loss: 1.450797]\n",
      "epoch:5 step:4045 [D loss: 0.664751, acc: 62.50%] [G loss: 1.561916]\n",
      "epoch:5 step:4046 [D loss: 0.714240, acc: 57.03%] [G loss: 1.498117]\n",
      "epoch:5 step:4047 [D loss: 0.661077, acc: 63.28%] [G loss: 1.622507]\n",
      "epoch:5 step:4048 [D loss: 0.722618, acc: 43.75%] [G loss: 1.574669]\n",
      "epoch:5 step:4049 [D loss: 0.761106, acc: 50.00%] [G loss: 1.658576]\n",
      "epoch:5 step:4050 [D loss: 0.636667, acc: 64.84%] [G loss: 1.586791]\n",
      "epoch:5 step:4051 [D loss: 0.641755, acc: 63.28%] [G loss: 1.679697]\n",
      "epoch:5 step:4052 [D loss: 0.681473, acc: 56.25%] [G loss: 1.687093]\n",
      "epoch:5 step:4053 [D loss: 0.613231, acc: 66.41%] [G loss: 1.711636]\n",
      "epoch:5 step:4054 [D loss: 0.818475, acc: 36.72%] [G loss: 1.518564]\n",
      "epoch:5 step:4055 [D loss: 0.678271, acc: 53.91%] [G loss: 1.449002]\n",
      "epoch:5 step:4056 [D loss: 0.726043, acc: 50.78%] [G loss: 1.497572]\n",
      "epoch:5 step:4057 [D loss: 0.751499, acc: 42.97%] [G loss: 1.497966]\n",
      "epoch:5 step:4058 [D loss: 0.719148, acc: 50.78%] [G loss: 1.680513]\n",
      "epoch:5 step:4059 [D loss: 0.639300, acc: 63.28%] [G loss: 1.585059]\n",
      "epoch:5 step:4060 [D loss: 0.695217, acc: 53.91%] [G loss: 1.585234]\n",
      "epoch:5 step:4061 [D loss: 0.752859, acc: 47.66%] [G loss: 1.554608]\n",
      "epoch:5 step:4062 [D loss: 0.720592, acc: 53.91%] [G loss: 1.775630]\n",
      "epoch:5 step:4063 [D loss: 0.804273, acc: 37.50%] [G loss: 1.406991]\n",
      "epoch:5 step:4064 [D loss: 0.634724, acc: 68.75%] [G loss: 1.662316]\n",
      "epoch:5 step:4065 [D loss: 0.756974, acc: 41.41%] [G loss: 1.437705]\n",
      "epoch:5 step:4066 [D loss: 0.666249, acc: 60.94%] [G loss: 1.686001]\n",
      "epoch:5 step:4067 [D loss: 0.682150, acc: 56.25%] [G loss: 1.587912]\n",
      "epoch:5 step:4068 [D loss: 0.662022, acc: 63.28%] [G loss: 1.528030]\n",
      "epoch:5 step:4069 [D loss: 0.717481, acc: 46.88%] [G loss: 1.518220]\n",
      "epoch:5 step:4070 [D loss: 0.596582, acc: 78.12%] [G loss: 1.551692]\n",
      "epoch:5 step:4071 [D loss: 0.902093, acc: 27.34%] [G loss: 1.355552]\n",
      "epoch:5 step:4072 [D loss: 0.720327, acc: 46.88%] [G loss: 1.739615]\n",
      "epoch:5 step:4073 [D loss: 0.564253, acc: 77.34%] [G loss: 1.749158]\n",
      "epoch:5 step:4074 [D loss: 0.720304, acc: 52.34%] [G loss: 1.455485]\n",
      "epoch:5 step:4075 [D loss: 0.657539, acc: 60.16%] [G loss: 1.669654]\n",
      "epoch:5 step:4076 [D loss: 0.724163, acc: 45.31%] [G loss: 1.647109]\n",
      "epoch:5 step:4077 [D loss: 0.703256, acc: 53.12%] [G loss: 1.551814]\n",
      "epoch:5 step:4078 [D loss: 0.681249, acc: 55.47%] [G loss: 1.478497]\n",
      "epoch:5 step:4079 [D loss: 0.663474, acc: 60.94%] [G loss: 1.453828]\n",
      "epoch:5 step:4080 [D loss: 0.791928, acc: 39.84%] [G loss: 1.567995]\n",
      "epoch:5 step:4081 [D loss: 0.845948, acc: 32.03%] [G loss: 1.539831]\n",
      "epoch:5 step:4082 [D loss: 0.629778, acc: 64.84%] [G loss: 1.525882]\n",
      "epoch:5 step:4083 [D loss: 0.708352, acc: 50.00%] [G loss: 1.326585]\n",
      "epoch:5 step:4084 [D loss: 0.579090, acc: 71.09%] [G loss: 1.541546]\n",
      "epoch:5 step:4085 [D loss: 0.713001, acc: 46.88%] [G loss: 1.475872]\n",
      "epoch:5 step:4086 [D loss: 0.716406, acc: 44.53%] [G loss: 1.654970]\n",
      "epoch:5 step:4087 [D loss: 0.873384, acc: 23.44%] [G loss: 1.369483]\n",
      "epoch:5 step:4088 [D loss: 0.597486, acc: 71.88%] [G loss: 1.697449]\n",
      "epoch:5 step:4089 [D loss: 0.762671, acc: 40.62%] [G loss: 1.587253]\n",
      "epoch:5 step:4090 [D loss: 0.646882, acc: 66.41%] [G loss: 1.545255]\n",
      "epoch:5 step:4091 [D loss: 0.687545, acc: 54.69%] [G loss: 1.722476]\n",
      "epoch:5 step:4092 [D loss: 0.612398, acc: 73.44%] [G loss: 1.923543]\n",
      "epoch:5 step:4093 [D loss: 0.755870, acc: 43.75%] [G loss: 1.458316]\n",
      "epoch:5 step:4094 [D loss: 0.631021, acc: 66.41%] [G loss: 1.713742]\n",
      "epoch:5 step:4095 [D loss: 0.689815, acc: 56.25%] [G loss: 1.733960]\n",
      "epoch:5 step:4096 [D loss: 0.592858, acc: 67.97%] [G loss: 1.723593]\n",
      "epoch:5 step:4097 [D loss: 0.518447, acc: 78.91%] [G loss: 1.664117]\n",
      "epoch:5 step:4098 [D loss: 0.689925, acc: 51.56%] [G loss: 1.713941]\n",
      "epoch:5 step:4099 [D loss: 0.525645, acc: 78.12%] [G loss: 1.600240]\n",
      "epoch:5 step:4100 [D loss: 0.778068, acc: 38.28%] [G loss: 1.492390]\n",
      "epoch:5 step:4101 [D loss: 0.871934, acc: 32.81%] [G loss: 1.455848]\n",
      "epoch:5 step:4102 [D loss: 0.674051, acc: 57.03%] [G loss: 1.717098]\n",
      "epoch:5 step:4103 [D loss: 0.720978, acc: 52.34%] [G loss: 1.651862]\n",
      "epoch:5 step:4104 [D loss: 0.719185, acc: 53.12%] [G loss: 1.647370]\n",
      "epoch:5 step:4105 [D loss: 0.635641, acc: 63.28%] [G loss: 1.534718]\n",
      "epoch:5 step:4106 [D loss: 0.605469, acc: 67.19%] [G loss: 1.710360]\n",
      "epoch:5 step:4107 [D loss: 0.833863, acc: 27.34%] [G loss: 1.351382]\n",
      "epoch:5 step:4108 [D loss: 0.583425, acc: 73.44%] [G loss: 1.677709]\n",
      "epoch:5 step:4109 [D loss: 0.705567, acc: 54.69%] [G loss: 1.736189]\n",
      "epoch:5 step:4110 [D loss: 0.785747, acc: 48.44%] [G loss: 1.598762]\n",
      "epoch:5 step:4111 [D loss: 0.758978, acc: 46.09%] [G loss: 1.477957]\n",
      "epoch:5 step:4112 [D loss: 0.661238, acc: 55.47%] [G loss: 1.613146]\n",
      "epoch:5 step:4113 [D loss: 0.806929, acc: 37.50%] [G loss: 1.446167]\n",
      "epoch:5 step:4114 [D loss: 0.659434, acc: 54.69%] [G loss: 1.454817]\n",
      "epoch:5 step:4115 [D loss: 0.828062, acc: 32.03%] [G loss: 1.311314]\n",
      "epoch:5 step:4116 [D loss: 0.670214, acc: 60.94%] [G loss: 1.621511]\n",
      "epoch:5 step:4117 [D loss: 0.571574, acc: 73.44%] [G loss: 1.704506]\n",
      "epoch:5 step:4118 [D loss: 0.739505, acc: 52.34%] [G loss: 1.607766]\n",
      "epoch:5 step:4119 [D loss: 0.821938, acc: 34.38%] [G loss: 1.448673]\n",
      "epoch:5 step:4120 [D loss: 0.750666, acc: 44.53%] [G loss: 1.667441]\n",
      "epoch:5 step:4121 [D loss: 0.651406, acc: 64.84%] [G loss: 1.724417]\n",
      "epoch:5 step:4122 [D loss: 0.870534, acc: 30.47%] [G loss: 1.575334]\n",
      "epoch:5 step:4123 [D loss: 0.648107, acc: 61.72%] [G loss: 1.647839]\n",
      "epoch:5 step:4124 [D loss: 0.656559, acc: 60.94%] [G loss: 1.787489]\n",
      "epoch:5 step:4125 [D loss: 0.783685, acc: 42.19%] [G loss: 1.544383]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:5 step:4126 [D loss: 0.779047, acc: 37.50%] [G loss: 1.682597]\n",
      "epoch:5 step:4127 [D loss: 0.645262, acc: 64.06%] [G loss: 1.816869]\n",
      "epoch:5 step:4128 [D loss: 0.610051, acc: 71.09%] [G loss: 1.851597]\n",
      "epoch:5 step:4129 [D loss: 0.705026, acc: 57.03%] [G loss: 1.727978]\n",
      "epoch:5 step:4130 [D loss: 0.762560, acc: 47.66%] [G loss: 1.593845]\n",
      "epoch:5 step:4131 [D loss: 0.718147, acc: 50.78%] [G loss: 1.636888]\n",
      "epoch:5 step:4132 [D loss: 0.769753, acc: 48.44%] [G loss: 1.488881]\n",
      "epoch:5 step:4133 [D loss: 0.707469, acc: 55.47%] [G loss: 1.677309]\n",
      "epoch:5 step:4134 [D loss: 0.645982, acc: 63.28%] [G loss: 1.591644]\n",
      "epoch:5 step:4135 [D loss: 0.795643, acc: 36.72%] [G loss: 1.475512]\n",
      "epoch:5 step:4136 [D loss: 0.704928, acc: 51.56%] [G loss: 1.597018]\n",
      "epoch:5 step:4137 [D loss: 0.768295, acc: 42.97%] [G loss: 1.452180]\n",
      "epoch:5 step:4138 [D loss: 0.729294, acc: 46.88%] [G loss: 1.679783]\n",
      "epoch:5 step:4139 [D loss: 0.648584, acc: 64.06%] [G loss: 1.716294]\n",
      "epoch:5 step:4140 [D loss: 0.716863, acc: 51.56%] [G loss: 1.656006]\n",
      "epoch:5 step:4141 [D loss: 0.825906, acc: 36.72%] [G loss: 1.624982]\n",
      "epoch:5 step:4142 [D loss: 0.681672, acc: 55.47%] [G loss: 1.589517]\n",
      "epoch:5 step:4143 [D loss: 0.803495, acc: 39.06%] [G loss: 1.530298]\n",
      "epoch:5 step:4144 [D loss: 0.602525, acc: 75.78%] [G loss: 1.770314]\n",
      "epoch:5 step:4145 [D loss: 0.683828, acc: 55.47%] [G loss: 1.766511]\n",
      "epoch:5 step:4146 [D loss: 0.726467, acc: 46.88%] [G loss: 1.644011]\n",
      "epoch:5 step:4147 [D loss: 0.806932, acc: 41.41%] [G loss: 1.414965]\n",
      "epoch:5 step:4148 [D loss: 0.674192, acc: 61.72%] [G loss: 1.627453]\n",
      "epoch:5 step:4149 [D loss: 0.606075, acc: 68.75%] [G loss: 1.610159]\n",
      "epoch:5 step:4150 [D loss: 0.842974, acc: 26.56%] [G loss: 1.445718]\n",
      "epoch:5 step:4151 [D loss: 0.569346, acc: 75.78%] [G loss: 1.597831]\n",
      "epoch:5 step:4152 [D loss: 0.554311, acc: 81.25%] [G loss: 1.588352]\n",
      "epoch:5 step:4153 [D loss: 0.771305, acc: 42.19%] [G loss: 1.438062]\n",
      "epoch:5 step:4154 [D loss: 0.747045, acc: 45.31%] [G loss: 1.478083]\n",
      "epoch:5 step:4155 [D loss: 0.791996, acc: 45.31%] [G loss: 1.438257]\n",
      "epoch:5 step:4156 [D loss: 0.709720, acc: 50.78%] [G loss: 1.471340]\n",
      "epoch:5 step:4157 [D loss: 0.613076, acc: 65.62%] [G loss: 1.494969]\n",
      "epoch:5 step:4158 [D loss: 0.819139, acc: 34.38%] [G loss: 1.302565]\n",
      "epoch:5 step:4159 [D loss: 0.786766, acc: 35.16%] [G loss: 1.401336]\n",
      "epoch:5 step:4160 [D loss: 0.867993, acc: 26.56%] [G loss: 1.371624]\n",
      "epoch:5 step:4161 [D loss: 0.761187, acc: 49.22%] [G loss: 1.424258]\n",
      "epoch:5 step:4162 [D loss: 0.813546, acc: 27.34%] [G loss: 1.372604]\n",
      "epoch:5 step:4163 [D loss: 0.703079, acc: 50.00%] [G loss: 1.333792]\n",
      "epoch:5 step:4164 [D loss: 0.748608, acc: 43.75%] [G loss: 1.418762]\n",
      "epoch:5 step:4165 [D loss: 0.714555, acc: 50.78%] [G loss: 1.538122]\n",
      "epoch:5 step:4166 [D loss: 0.722633, acc: 55.47%] [G loss: 1.454688]\n",
      "epoch:5 step:4167 [D loss: 0.637449, acc: 66.41%] [G loss: 1.655650]\n",
      "epoch:5 step:4168 [D loss: 0.758951, acc: 46.88%] [G loss: 1.484319]\n",
      "epoch:5 step:4169 [D loss: 0.809596, acc: 35.16%] [G loss: 1.448781]\n",
      "epoch:5 step:4170 [D loss: 0.683317, acc: 52.34%] [G loss: 1.598473]\n",
      "epoch:5 step:4171 [D loss: 0.670988, acc: 60.16%] [G loss: 1.659686]\n",
      "epoch:5 step:4172 [D loss: 0.846520, acc: 32.81%] [G loss: 1.593569]\n",
      "epoch:5 step:4173 [D loss: 0.697733, acc: 56.25%] [G loss: 1.470250]\n",
      "epoch:5 step:4174 [D loss: 0.711048, acc: 54.69%] [G loss: 1.508336]\n",
      "epoch:5 step:4175 [D loss: 0.603817, acc: 69.53%] [G loss: 1.590226]\n",
      "epoch:5 step:4176 [D loss: 0.664787, acc: 64.06%] [G loss: 1.588778]\n",
      "epoch:5 step:4177 [D loss: 0.731367, acc: 47.66%] [G loss: 1.469499]\n",
      "epoch:5 step:4178 [D loss: 0.785687, acc: 42.19%] [G loss: 1.482643]\n",
      "epoch:5 step:4179 [D loss: 0.721768, acc: 46.09%] [G loss: 1.511060]\n",
      "epoch:5 step:4180 [D loss: 0.720037, acc: 46.09%] [G loss: 1.508077]\n",
      "epoch:5 step:4181 [D loss: 0.631114, acc: 70.31%] [G loss: 1.608501]\n",
      "epoch:5 step:4182 [D loss: 0.877147, acc: 17.19%] [G loss: 1.279820]\n",
      "epoch:5 step:4183 [D loss: 0.693230, acc: 53.91%] [G loss: 1.531753]\n",
      "epoch:5 step:4184 [D loss: 0.701518, acc: 52.34%] [G loss: 1.496207]\n",
      "epoch:5 step:4185 [D loss: 0.656420, acc: 63.28%] [G loss: 1.597556]\n",
      "epoch:5 step:4186 [D loss: 0.749165, acc: 39.84%] [G loss: 1.445575]\n",
      "epoch:5 step:4187 [D loss: 0.738122, acc: 50.00%] [G loss: 1.535657]\n",
      "epoch:5 step:4188 [D loss: 0.673918, acc: 57.81%] [G loss: 1.511511]\n",
      "epoch:5 step:4189 [D loss: 0.710138, acc: 49.22%] [G loss: 1.477055]\n",
      "epoch:5 step:4190 [D loss: 0.774197, acc: 39.06%] [G loss: 1.518096]\n",
      "epoch:5 step:4191 [D loss: 0.659149, acc: 61.72%] [G loss: 1.547669]\n",
      "epoch:5 step:4192 [D loss: 0.695101, acc: 62.50%] [G loss: 1.626882]\n",
      "epoch:5 step:4193 [D loss: 0.719461, acc: 51.56%] [G loss: 1.551877]\n",
      "epoch:5 step:4194 [D loss: 0.752118, acc: 41.41%] [G loss: 1.594575]\n",
      "epoch:5 step:4195 [D loss: 0.746461, acc: 39.84%] [G loss: 1.491884]\n",
      "epoch:5 step:4196 [D loss: 0.715081, acc: 57.81%] [G loss: 1.444679]\n",
      "epoch:5 step:4197 [D loss: 0.776426, acc: 34.38%] [G loss: 1.505683]\n",
      "epoch:5 step:4198 [D loss: 0.667326, acc: 55.47%] [G loss: 1.422924]\n",
      "epoch:5 step:4199 [D loss: 0.702072, acc: 53.12%] [G loss: 1.490326]\n",
      "epoch:5 step:4200 [D loss: 0.737254, acc: 44.53%] [G loss: 1.621289]\n",
      "##############\n",
      "[0.85878899 0.85929719 0.80002462 0.83705423 0.80404516 0.82585206\n",
      " 0.87153255 0.84023476 0.8190545  0.83664038]\n",
      "##########\n",
      "epoch:5 step:4201 [D loss: 0.704028, acc: 60.16%] [G loss: 1.454364]\n",
      "epoch:5 step:4202 [D loss: 0.797951, acc: 35.94%] [G loss: 1.442281]\n",
      "epoch:5 step:4203 [D loss: 0.723637, acc: 50.00%] [G loss: 1.453309]\n",
      "epoch:5 step:4204 [D loss: 0.749711, acc: 46.09%] [G loss: 1.559497]\n",
      "epoch:5 step:4205 [D loss: 0.738602, acc: 45.31%] [G loss: 1.557740]\n",
      "epoch:5 step:4206 [D loss: 0.704646, acc: 51.56%] [G loss: 1.442351]\n",
      "epoch:5 step:4207 [D loss: 0.707043, acc: 51.56%] [G loss: 1.629889]\n",
      "epoch:5 step:4208 [D loss: 0.664513, acc: 61.72%] [G loss: 1.548046]\n",
      "epoch:5 step:4209 [D loss: 0.816463, acc: 35.16%] [G loss: 1.546019]\n",
      "epoch:5 step:4210 [D loss: 0.727580, acc: 45.31%] [G loss: 1.591894]\n",
      "epoch:5 step:4211 [D loss: 0.731769, acc: 50.00%] [G loss: 1.361902]\n",
      "epoch:5 step:4212 [D loss: 0.714021, acc: 48.44%] [G loss: 1.546027]\n",
      "epoch:5 step:4213 [D loss: 0.722682, acc: 56.25%] [G loss: 1.552876]\n",
      "epoch:5 step:4214 [D loss: 0.644370, acc: 60.94%] [G loss: 1.587458]\n",
      "epoch:5 step:4215 [D loss: 0.660573, acc: 67.19%] [G loss: 1.682227]\n",
      "epoch:5 step:4216 [D loss: 0.729615, acc: 53.12%] [G loss: 1.681974]\n",
      "epoch:5 step:4217 [D loss: 0.701871, acc: 50.00%] [G loss: 1.582036]\n",
      "epoch:5 step:4218 [D loss: 0.701355, acc: 55.47%] [G loss: 1.684235]\n",
      "epoch:5 step:4219 [D loss: 0.822024, acc: 32.03%] [G loss: 1.512408]\n",
      "epoch:5 step:4220 [D loss: 0.833461, acc: 34.38%] [G loss: 1.526939]\n",
      "epoch:5 step:4221 [D loss: 0.706879, acc: 54.69%] [G loss: 1.608548]\n",
      "epoch:5 step:4222 [D loss: 0.765814, acc: 45.31%] [G loss: 1.537082]\n",
      "epoch:5 step:4223 [D loss: 0.701675, acc: 51.56%] [G loss: 1.627964]\n",
      "epoch:5 step:4224 [D loss: 0.676414, acc: 63.28%] [G loss: 1.513465]\n",
      "epoch:5 step:4225 [D loss: 0.692335, acc: 55.47%] [G loss: 1.549558]\n",
      "epoch:5 step:4226 [D loss: 0.677984, acc: 53.91%] [G loss: 1.601022]\n",
      "epoch:5 step:4227 [D loss: 0.713928, acc: 50.00%] [G loss: 1.589045]\n",
      "epoch:5 step:4228 [D loss: 0.697469, acc: 52.34%] [G loss: 1.515944]\n",
      "epoch:5 step:4229 [D loss: 0.714958, acc: 50.78%] [G loss: 1.464278]\n",
      "epoch:5 step:4230 [D loss: 0.671498, acc: 56.25%] [G loss: 1.581514]\n",
      "epoch:5 step:4231 [D loss: 0.708086, acc: 51.56%] [G loss: 1.600344]\n",
      "epoch:5 step:4232 [D loss: 0.646202, acc: 64.84%] [G loss: 1.637473]\n",
      "epoch:5 step:4233 [D loss: 0.717428, acc: 54.69%] [G loss: 1.581983]\n",
      "epoch:5 step:4234 [D loss: 0.755620, acc: 33.59%] [G loss: 1.355557]\n",
      "epoch:5 step:4235 [D loss: 0.730031, acc: 45.31%] [G loss: 1.436568]\n",
      "epoch:5 step:4236 [D loss: 0.683996, acc: 54.69%] [G loss: 1.544469]\n",
      "epoch:5 step:4237 [D loss: 0.629142, acc: 71.09%] [G loss: 1.604790]\n",
      "epoch:5 step:4238 [D loss: 0.721706, acc: 45.31%] [G loss: 1.478804]\n",
      "epoch:5 step:4239 [D loss: 0.750941, acc: 39.84%] [G loss: 1.518356]\n",
      "epoch:5 step:4240 [D loss: 0.693183, acc: 57.03%] [G loss: 1.570475]\n",
      "epoch:5 step:4241 [D loss: 0.735259, acc: 49.22%] [G loss: 1.563054]\n",
      "epoch:5 step:4242 [D loss: 0.694563, acc: 53.12%] [G loss: 1.589389]\n",
      "epoch:5 step:4243 [D loss: 0.768722, acc: 41.41%] [G loss: 1.503529]\n",
      "epoch:5 step:4244 [D loss: 0.693484, acc: 58.59%] [G loss: 1.564745]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:5 step:4245 [D loss: 0.699722, acc: 53.91%] [G loss: 1.523148]\n",
      "epoch:5 step:4246 [D loss: 0.671389, acc: 60.94%] [G loss: 1.650217]\n",
      "epoch:5 step:4247 [D loss: 0.695272, acc: 53.12%] [G loss: 1.607027]\n",
      "epoch:5 step:4248 [D loss: 0.674683, acc: 55.47%] [G loss: 1.531610]\n",
      "epoch:5 step:4249 [D loss: 0.775956, acc: 42.97%] [G loss: 1.579876]\n",
      "epoch:5 step:4250 [D loss: 0.684810, acc: 50.00%] [G loss: 1.479045]\n",
      "epoch:5 step:4251 [D loss: 0.671110, acc: 62.50%] [G loss: 1.564726]\n",
      "epoch:5 step:4252 [D loss: 0.784000, acc: 35.16%] [G loss: 1.567711]\n",
      "epoch:5 step:4253 [D loss: 0.734279, acc: 42.19%] [G loss: 1.588694]\n",
      "epoch:5 step:4254 [D loss: 0.669767, acc: 55.47%] [G loss: 1.649207]\n",
      "epoch:5 step:4255 [D loss: 0.813326, acc: 33.59%] [G loss: 1.551578]\n",
      "epoch:5 step:4256 [D loss: 0.689418, acc: 57.03%] [G loss: 1.572204]\n",
      "epoch:5 step:4257 [D loss: 0.769857, acc: 33.59%] [G loss: 1.574937]\n",
      "epoch:5 step:4258 [D loss: 0.657806, acc: 63.28%] [G loss: 1.591879]\n",
      "epoch:5 step:4259 [D loss: 0.723973, acc: 47.66%] [G loss: 1.500046]\n",
      "epoch:5 step:4260 [D loss: 0.646661, acc: 64.84%] [G loss: 1.396056]\n",
      "epoch:5 step:4261 [D loss: 0.777074, acc: 46.09%] [G loss: 1.543765]\n",
      "epoch:5 step:4262 [D loss: 0.678299, acc: 57.03%] [G loss: 1.539803]\n",
      "epoch:5 step:4263 [D loss: 0.687816, acc: 51.56%] [G loss: 1.575573]\n",
      "epoch:5 step:4264 [D loss: 0.770741, acc: 39.84%] [G loss: 1.362410]\n",
      "epoch:5 step:4265 [D loss: 0.626134, acc: 64.84%] [G loss: 1.484888]\n",
      "epoch:5 step:4266 [D loss: 0.719325, acc: 51.56%] [G loss: 1.621624]\n",
      "epoch:5 step:4267 [D loss: 0.737350, acc: 47.66%] [G loss: 1.497859]\n",
      "epoch:5 step:4268 [D loss: 0.700716, acc: 49.22%] [G loss: 1.711759]\n",
      "epoch:5 step:4269 [D loss: 0.643903, acc: 66.41%] [G loss: 1.563365]\n",
      "epoch:5 step:4270 [D loss: 0.715951, acc: 49.22%] [G loss: 1.652410]\n",
      "epoch:5 step:4271 [D loss: 0.787189, acc: 35.94%] [G loss: 1.577108]\n",
      "epoch:5 step:4272 [D loss: 0.737566, acc: 50.00%] [G loss: 1.516865]\n",
      "epoch:5 step:4273 [D loss: 0.651675, acc: 66.41%] [G loss: 1.688317]\n",
      "epoch:5 step:4274 [D loss: 0.649389, acc: 63.28%] [G loss: 1.608397]\n",
      "epoch:5 step:4275 [D loss: 0.701662, acc: 53.91%] [G loss: 1.480011]\n",
      "epoch:5 step:4276 [D loss: 0.736962, acc: 46.88%] [G loss: 1.669374]\n",
      "epoch:5 step:4277 [D loss: 0.696003, acc: 50.00%] [G loss: 1.567329]\n",
      "epoch:5 step:4278 [D loss: 0.759482, acc: 42.19%] [G loss: 1.526144]\n",
      "epoch:5 step:4279 [D loss: 0.740352, acc: 40.62%] [G loss: 1.455565]\n",
      "epoch:5 step:4280 [D loss: 0.749985, acc: 42.97%] [G loss: 1.531712]\n",
      "epoch:5 step:4281 [D loss: 0.724904, acc: 46.88%] [G loss: 1.523273]\n",
      "epoch:5 step:4282 [D loss: 0.693737, acc: 57.03%] [G loss: 1.507371]\n",
      "epoch:5 step:4283 [D loss: 0.680945, acc: 57.81%] [G loss: 1.596819]\n",
      "epoch:5 step:4284 [D loss: 0.690313, acc: 55.47%] [G loss: 1.609553]\n",
      "epoch:5 step:4285 [D loss: 0.787930, acc: 35.16%] [G loss: 1.492327]\n",
      "epoch:5 step:4286 [D loss: 0.683781, acc: 57.03%] [G loss: 1.610115]\n",
      "epoch:5 step:4287 [D loss: 0.700251, acc: 50.00%] [G loss: 1.532497]\n",
      "epoch:5 step:4288 [D loss: 0.692908, acc: 56.25%] [G loss: 1.652079]\n",
      "epoch:5 step:4289 [D loss: 0.661005, acc: 65.62%] [G loss: 1.497674]\n",
      "epoch:5 step:4290 [D loss: 0.755474, acc: 42.19%] [G loss: 1.613126]\n",
      "epoch:5 step:4291 [D loss: 0.656590, acc: 60.94%] [G loss: 1.685804]\n",
      "epoch:5 step:4292 [D loss: 0.782452, acc: 39.06%] [G loss: 1.484461]\n",
      "epoch:5 step:4293 [D loss: 0.688048, acc: 56.25%] [G loss: 1.580662]\n",
      "epoch:5 step:4294 [D loss: 0.655191, acc: 59.38%] [G loss: 1.581663]\n",
      "epoch:5 step:4295 [D loss: 0.749888, acc: 39.84%] [G loss: 1.441636]\n",
      "epoch:5 step:4296 [D loss: 0.808562, acc: 41.41%] [G loss: 1.448851]\n",
      "epoch:5 step:4297 [D loss: 0.704552, acc: 53.91%] [G loss: 1.507341]\n",
      "epoch:5 step:4298 [D loss: 0.742750, acc: 45.31%] [G loss: 1.455134]\n",
      "epoch:5 step:4299 [D loss: 0.768091, acc: 45.31%] [G loss: 1.478105]\n",
      "epoch:5 step:4300 [D loss: 0.740366, acc: 40.62%] [G loss: 1.495700]\n",
      "epoch:5 step:4301 [D loss: 0.745968, acc: 41.41%] [G loss: 1.575303]\n",
      "epoch:5 step:4302 [D loss: 0.704149, acc: 53.91%] [G loss: 1.475624]\n",
      "epoch:5 step:4303 [D loss: 0.759893, acc: 40.62%] [G loss: 1.439440]\n",
      "epoch:5 step:4304 [D loss: 0.683653, acc: 54.69%] [G loss: 1.497092]\n",
      "epoch:5 step:4305 [D loss: 0.800359, acc: 32.03%] [G loss: 1.357735]\n",
      "epoch:5 step:4306 [D loss: 0.752357, acc: 41.41%] [G loss: 1.485866]\n",
      "epoch:5 step:4307 [D loss: 0.709211, acc: 53.91%] [G loss: 1.529501]\n",
      "epoch:5 step:4308 [D loss: 0.700250, acc: 53.12%] [G loss: 1.628105]\n",
      "epoch:5 step:4309 [D loss: 0.583785, acc: 78.91%] [G loss: 1.566717]\n",
      "epoch:5 step:4310 [D loss: 0.667111, acc: 65.62%] [G loss: 1.507161]\n",
      "epoch:5 step:4311 [D loss: 0.731199, acc: 47.66%] [G loss: 1.575265]\n",
      "epoch:5 step:4312 [D loss: 0.529539, acc: 82.81%] [G loss: 1.498100]\n",
      "epoch:5 step:4313 [D loss: 0.712000, acc: 50.78%] [G loss: 1.522458]\n",
      "epoch:5 step:4314 [D loss: 0.621190, acc: 69.53%] [G loss: 1.608805]\n",
      "epoch:5 step:4315 [D loss: 0.503487, acc: 87.50%] [G loss: 1.595376]\n",
      "epoch:5 step:4316 [D loss: 0.823496, acc: 24.22%] [G loss: 1.392862]\n",
      "epoch:5 step:4317 [D loss: 0.772313, acc: 36.72%] [G loss: 1.549451]\n",
      "epoch:5 step:4318 [D loss: 0.691215, acc: 59.38%] [G loss: 1.512011]\n",
      "epoch:5 step:4319 [D loss: 0.769876, acc: 37.50%] [G loss: 1.366870]\n",
      "epoch:5 step:4320 [D loss: 0.656582, acc: 61.72%] [G loss: 1.597016]\n",
      "epoch:5 step:4321 [D loss: 0.697371, acc: 50.78%] [G loss: 1.596070]\n",
      "epoch:5 step:4322 [D loss: 0.628783, acc: 65.62%] [G loss: 1.601437]\n",
      "epoch:5 step:4323 [D loss: 0.624293, acc: 65.62%] [G loss: 1.518737]\n",
      "epoch:5 step:4324 [D loss: 0.731312, acc: 46.09%] [G loss: 1.529227]\n",
      "epoch:5 step:4325 [D loss: 0.770270, acc: 35.94%] [G loss: 1.621228]\n",
      "epoch:5 step:4326 [D loss: 0.723960, acc: 43.75%] [G loss: 1.490697]\n",
      "epoch:5 step:4327 [D loss: 0.671087, acc: 57.81%] [G loss: 1.739526]\n",
      "epoch:5 step:4328 [D loss: 0.643879, acc: 64.84%] [G loss: 1.648108]\n",
      "epoch:5 step:4329 [D loss: 0.823325, acc: 32.03%] [G loss: 1.540610]\n",
      "epoch:5 step:4330 [D loss: 0.678798, acc: 57.81%] [G loss: 1.664202]\n",
      "epoch:5 step:4331 [D loss: 0.759851, acc: 40.62%] [G loss: 1.503240]\n",
      "epoch:5 step:4332 [D loss: 0.744162, acc: 40.62%] [G loss: 1.624319]\n",
      "epoch:5 step:4333 [D loss: 0.654738, acc: 63.28%] [G loss: 1.719202]\n",
      "epoch:5 step:4334 [D loss: 0.648801, acc: 61.72%] [G loss: 1.642287]\n",
      "epoch:5 step:4335 [D loss: 0.640233, acc: 61.72%] [G loss: 1.714985]\n",
      "epoch:5 step:4336 [D loss: 0.651876, acc: 57.03%] [G loss: 1.706813]\n",
      "epoch:5 step:4337 [D loss: 0.522398, acc: 81.25%] [G loss: 1.865809]\n",
      "epoch:5 step:4338 [D loss: 0.719287, acc: 47.66%] [G loss: 1.485893]\n",
      "epoch:5 step:4339 [D loss: 0.883418, acc: 22.66%] [G loss: 1.301263]\n",
      "epoch:5 step:4340 [D loss: 0.720184, acc: 53.91%] [G loss: 1.416902]\n",
      "epoch:5 step:4341 [D loss: 0.773876, acc: 36.72%] [G loss: 1.515401]\n",
      "epoch:5 step:4342 [D loss: 0.744289, acc: 40.62%] [G loss: 1.446460]\n",
      "epoch:5 step:4343 [D loss: 0.708250, acc: 50.78%] [G loss: 1.637126]\n",
      "epoch:5 step:4344 [D loss: 0.663093, acc: 60.94%] [G loss: 1.442462]\n",
      "epoch:5 step:4345 [D loss: 0.794190, acc: 29.69%] [G loss: 1.412197]\n",
      "epoch:5 step:4346 [D loss: 0.755440, acc: 39.06%] [G loss: 1.439329]\n",
      "epoch:5 step:4347 [D loss: 0.749054, acc: 49.22%] [G loss: 1.457122]\n",
      "epoch:5 step:4348 [D loss: 0.778778, acc: 37.50%] [G loss: 1.469198]\n",
      "epoch:5 step:4349 [D loss: 0.742716, acc: 42.19%] [G loss: 1.593003]\n",
      "epoch:5 step:4350 [D loss: 0.673437, acc: 57.03%] [G loss: 1.613442]\n",
      "epoch:5 step:4351 [D loss: 0.716952, acc: 47.66%] [G loss: 1.542316]\n",
      "epoch:5 step:4352 [D loss: 0.651899, acc: 66.41%] [G loss: 1.630746]\n",
      "epoch:5 step:4353 [D loss: 0.701714, acc: 60.16%] [G loss: 1.565990]\n",
      "epoch:5 step:4354 [D loss: 0.705841, acc: 47.66%] [G loss: 1.470562]\n",
      "epoch:5 step:4355 [D loss: 0.678120, acc: 60.16%] [G loss: 1.596420]\n",
      "epoch:5 step:4356 [D loss: 0.687778, acc: 52.34%] [G loss: 1.585771]\n",
      "epoch:5 step:4357 [D loss: 0.687769, acc: 56.25%] [G loss: 1.645894]\n",
      "epoch:5 step:4358 [D loss: 0.655322, acc: 63.28%] [G loss: 1.748916]\n",
      "epoch:5 step:4359 [D loss: 0.713765, acc: 48.44%] [G loss: 1.587592]\n",
      "epoch:5 step:4360 [D loss: 0.641983, acc: 64.84%] [G loss: 1.587975]\n",
      "epoch:5 step:4361 [D loss: 0.737506, acc: 42.97%] [G loss: 1.659103]\n",
      "epoch:5 step:4362 [D loss: 0.666284, acc: 61.72%] [G loss: 1.681632]\n",
      "epoch:5 step:4363 [D loss: 0.650848, acc: 65.62%] [G loss: 1.690710]\n",
      "epoch:5 step:4364 [D loss: 0.585385, acc: 75.78%] [G loss: 1.483513]\n",
      "epoch:5 step:4365 [D loss: 0.621258, acc: 72.66%] [G loss: 1.565112]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:5 step:4366 [D loss: 0.702072, acc: 63.28%] [G loss: 1.565852]\n",
      "epoch:5 step:4367 [D loss: 0.632625, acc: 64.06%] [G loss: 1.570112]\n",
      "epoch:5 step:4368 [D loss: 0.815326, acc: 32.03%] [G loss: 1.561372]\n",
      "epoch:5 step:4369 [D loss: 0.707851, acc: 46.88%] [G loss: 1.557719]\n",
      "epoch:5 step:4370 [D loss: 0.712910, acc: 55.47%] [G loss: 1.574167]\n",
      "epoch:5 step:4371 [D loss: 0.655974, acc: 60.94%] [G loss: 1.532415]\n",
      "epoch:5 step:4372 [D loss: 0.655908, acc: 60.94%] [G loss: 1.625446]\n",
      "epoch:5 step:4373 [D loss: 0.672306, acc: 57.03%] [G loss: 1.513546]\n",
      "epoch:5 step:4374 [D loss: 0.628277, acc: 65.62%] [G loss: 1.641287]\n",
      "epoch:5 step:4375 [D loss: 0.696556, acc: 55.47%] [G loss: 1.577370]\n",
      "epoch:5 step:4376 [D loss: 0.689622, acc: 61.72%] [G loss: 1.687697]\n",
      "epoch:5 step:4377 [D loss: 0.756133, acc: 44.53%] [G loss: 1.583455]\n",
      "epoch:5 step:4378 [D loss: 0.769056, acc: 39.84%] [G loss: 1.559938]\n",
      "epoch:5 step:4379 [D loss: 0.778894, acc: 39.84%] [G loss: 1.548879]\n",
      "epoch:5 step:4380 [D loss: 0.775822, acc: 39.06%] [G loss: 1.698113]\n",
      "epoch:5 step:4381 [D loss: 0.684672, acc: 59.38%] [G loss: 1.598738]\n",
      "epoch:5 step:4382 [D loss: 0.705824, acc: 54.69%] [G loss: 1.568719]\n",
      "epoch:5 step:4383 [D loss: 0.687432, acc: 53.91%] [G loss: 1.499541]\n",
      "epoch:5 step:4384 [D loss: 0.763313, acc: 37.50%] [G loss: 1.474163]\n",
      "epoch:5 step:4385 [D loss: 0.726453, acc: 46.09%] [G loss: 1.379319]\n",
      "epoch:5 step:4386 [D loss: 0.825898, acc: 32.03%] [G loss: 1.432227]\n",
      "epoch:5 step:4387 [D loss: 0.820108, acc: 41.41%] [G loss: 1.552560]\n",
      "epoch:5 step:4388 [D loss: 0.778957, acc: 42.19%] [G loss: 1.581710]\n",
      "epoch:5 step:4389 [D loss: 0.753642, acc: 48.44%] [G loss: 1.442231]\n",
      "epoch:5 step:4390 [D loss: 0.677306, acc: 53.12%] [G loss: 1.661675]\n",
      "epoch:5 step:4391 [D loss: 0.709007, acc: 48.44%] [G loss: 1.695142]\n",
      "epoch:5 step:4392 [D loss: 0.676959, acc: 62.50%] [G loss: 1.679386]\n",
      "epoch:5 step:4393 [D loss: 0.695491, acc: 54.69%] [G loss: 1.531002]\n",
      "epoch:5 step:4394 [D loss: 0.802204, acc: 39.84%] [G loss: 1.604256]\n",
      "epoch:5 step:4395 [D loss: 0.702552, acc: 56.25%] [G loss: 1.610864]\n",
      "epoch:5 step:4396 [D loss: 0.636397, acc: 67.97%] [G loss: 1.677231]\n",
      "epoch:5 step:4397 [D loss: 0.798655, acc: 37.50%] [G loss: 1.570401]\n",
      "epoch:5 step:4398 [D loss: 0.607174, acc: 69.53%] [G loss: 1.755925]\n",
      "epoch:5 step:4399 [D loss: 0.602832, acc: 75.00%] [G loss: 1.716811]\n",
      "epoch:5 step:4400 [D loss: 0.625677, acc: 61.72%] [G loss: 1.729312]\n",
      "##############\n",
      "[0.85377007 0.86838851 0.81569404 0.79948655 0.77922598 0.82534543\n",
      " 0.8478569  0.81201179 0.82091566 0.84751477]\n",
      "##########\n",
      "epoch:5 step:4401 [D loss: 0.566999, acc: 77.34%] [G loss: 1.733115]\n",
      "epoch:5 step:4402 [D loss: 0.656938, acc: 64.06%] [G loss: 1.694848]\n",
      "epoch:5 step:4403 [D loss: 0.540507, acc: 78.12%] [G loss: 1.894747]\n",
      "epoch:5 step:4404 [D loss: 0.477061, acc: 85.16%] [G loss: 1.764951]\n",
      "epoch:5 step:4405 [D loss: 0.743482, acc: 44.53%] [G loss: 1.397542]\n",
      "epoch:5 step:4406 [D loss: 0.602183, acc: 74.22%] [G loss: 1.542653]\n",
      "epoch:5 step:4407 [D loss: 0.717943, acc: 56.25%] [G loss: 1.605743]\n",
      "epoch:5 step:4408 [D loss: 0.795991, acc: 36.72%] [G loss: 1.267652]\n",
      "epoch:5 step:4409 [D loss: 0.573464, acc: 72.66%] [G loss: 1.386254]\n",
      "epoch:5 step:4410 [D loss: 0.736477, acc: 50.00%] [G loss: 1.558140]\n",
      "epoch:5 step:4411 [D loss: 0.708859, acc: 53.91%] [G loss: 1.394221]\n",
      "epoch:5 step:4412 [D loss: 0.740851, acc: 46.09%] [G loss: 1.460585]\n",
      "epoch:5 step:4413 [D loss: 0.819286, acc: 42.19%] [G loss: 1.331206]\n",
      "epoch:5 step:4414 [D loss: 0.682172, acc: 60.16%] [G loss: 1.693854]\n",
      "epoch:5 step:4415 [D loss: 0.823760, acc: 31.25%] [G loss: 1.509417]\n",
      "epoch:5 step:4416 [D loss: 0.761138, acc: 45.31%] [G loss: 1.569158]\n",
      "epoch:5 step:4417 [D loss: 0.648338, acc: 61.72%] [G loss: 1.689114]\n",
      "epoch:5 step:4418 [D loss: 0.756865, acc: 44.53%] [G loss: 1.647415]\n",
      "epoch:5 step:4419 [D loss: 0.715739, acc: 47.66%] [G loss: 1.625753]\n",
      "epoch:5 step:4420 [D loss: 0.687645, acc: 54.69%] [G loss: 1.604183]\n",
      "epoch:5 step:4421 [D loss: 0.690680, acc: 50.78%] [G loss: 1.518627]\n",
      "epoch:5 step:4422 [D loss: 0.691504, acc: 57.81%] [G loss: 1.618516]\n",
      "epoch:5 step:4423 [D loss: 0.589890, acc: 67.97%] [G loss: 1.692120]\n",
      "epoch:5 step:4424 [D loss: 0.813374, acc: 31.25%] [G loss: 1.470989]\n",
      "epoch:5 step:4425 [D loss: 0.595830, acc: 71.09%] [G loss: 1.707444]\n",
      "epoch:5 step:4426 [D loss: 0.633913, acc: 68.75%] [G loss: 1.745169]\n",
      "epoch:5 step:4427 [D loss: 0.684778, acc: 60.94%] [G loss: 1.529448]\n",
      "epoch:5 step:4428 [D loss: 0.658711, acc: 67.19%] [G loss: 1.673340]\n",
      "epoch:5 step:4429 [D loss: 0.774365, acc: 40.62%] [G loss: 1.455559]\n",
      "epoch:5 step:4430 [D loss: 0.619257, acc: 76.56%] [G loss: 1.557356]\n",
      "epoch:5 step:4431 [D loss: 0.805727, acc: 39.84%] [G loss: 1.561723]\n",
      "epoch:5 step:4432 [D loss: 0.713643, acc: 52.34%] [G loss: 1.515538]\n",
      "epoch:5 step:4433 [D loss: 0.677737, acc: 57.03%] [G loss: 1.641180]\n",
      "epoch:5 step:4434 [D loss: 0.601381, acc: 75.00%] [G loss: 1.586552]\n",
      "epoch:5 step:4435 [D loss: 0.752879, acc: 47.66%] [G loss: 1.498386]\n",
      "epoch:5 step:4436 [D loss: 0.664908, acc: 64.84%] [G loss: 1.618498]\n",
      "epoch:5 step:4437 [D loss: 0.729439, acc: 51.56%] [G loss: 1.678710]\n",
      "epoch:5 step:4438 [D loss: 0.710428, acc: 47.66%] [G loss: 1.574407]\n",
      "epoch:5 step:4439 [D loss: 0.680921, acc: 57.03%] [G loss: 1.581533]\n",
      "epoch:5 step:4440 [D loss: 0.708268, acc: 51.56%] [G loss: 1.543995]\n",
      "epoch:5 step:4441 [D loss: 0.699968, acc: 49.22%] [G loss: 1.675338]\n",
      "epoch:5 step:4442 [D loss: 0.743823, acc: 43.75%] [G loss: 1.671302]\n",
      "epoch:5 step:4443 [D loss: 0.757973, acc: 36.72%] [G loss: 1.508583]\n",
      "epoch:5 step:4444 [D loss: 0.691027, acc: 53.12%] [G loss: 1.584776]\n",
      "epoch:5 step:4445 [D loss: 0.690556, acc: 54.69%] [G loss: 1.555974]\n",
      "epoch:5 step:4446 [D loss: 0.710283, acc: 46.88%] [G loss: 1.528787]\n",
      "epoch:5 step:4447 [D loss: 0.761222, acc: 39.84%] [G loss: 1.402013]\n",
      "epoch:5 step:4448 [D loss: 0.632012, acc: 69.53%] [G loss: 1.488053]\n",
      "epoch:5 step:4449 [D loss: 0.772861, acc: 42.97%] [G loss: 1.523189]\n",
      "epoch:5 step:4450 [D loss: 0.781139, acc: 39.06%] [G loss: 1.419139]\n",
      "epoch:5 step:4451 [D loss: 0.725215, acc: 50.78%] [G loss: 1.536673]\n",
      "epoch:5 step:4452 [D loss: 0.752972, acc: 42.97%] [G loss: 1.532727]\n",
      "epoch:5 step:4453 [D loss: 0.706739, acc: 51.56%] [G loss: 1.523634]\n",
      "epoch:5 step:4454 [D loss: 0.625496, acc: 63.28%] [G loss: 1.560952]\n",
      "epoch:5 step:4455 [D loss: 0.802398, acc: 32.03%] [G loss: 1.592619]\n",
      "epoch:5 step:4456 [D loss: 0.598666, acc: 71.09%] [G loss: 1.624778]\n",
      "epoch:5 step:4457 [D loss: 0.805936, acc: 37.50%] [G loss: 1.454839]\n",
      "epoch:5 step:4458 [D loss: 0.730385, acc: 50.00%] [G loss: 1.477312]\n",
      "epoch:5 step:4459 [D loss: 0.711544, acc: 51.56%] [G loss: 1.544049]\n",
      "epoch:5 step:4460 [D loss: 0.638069, acc: 67.97%] [G loss: 1.555529]\n",
      "epoch:5 step:4461 [D loss: 0.586532, acc: 71.88%] [G loss: 1.539217]\n",
      "epoch:5 step:4462 [D loss: 0.696111, acc: 56.25%] [G loss: 1.636537]\n",
      "epoch:5 step:4463 [D loss: 0.685243, acc: 55.47%] [G loss: 1.550736]\n",
      "epoch:5 step:4464 [D loss: 0.587388, acc: 75.78%] [G loss: 1.561466]\n",
      "epoch:5 step:4465 [D loss: 0.611772, acc: 68.75%] [G loss: 1.638591]\n",
      "epoch:5 step:4466 [D loss: 0.675602, acc: 53.91%] [G loss: 1.483747]\n",
      "epoch:5 step:4467 [D loss: 0.734690, acc: 46.88%] [G loss: 1.493461]\n",
      "epoch:5 step:4468 [D loss: 0.563161, acc: 75.00%] [G loss: 1.519278]\n",
      "epoch:5 step:4469 [D loss: 0.877930, acc: 28.12%] [G loss: 1.395937]\n",
      "epoch:5 step:4470 [D loss: 0.828972, acc: 33.59%] [G loss: 1.398067]\n",
      "epoch:5 step:4471 [D loss: 0.762848, acc: 45.31%] [G loss: 1.477703]\n",
      "epoch:5 step:4472 [D loss: 0.836249, acc: 25.00%] [G loss: 1.468869]\n",
      "epoch:5 step:4473 [D loss: 0.708262, acc: 55.47%] [G loss: 1.589739]\n",
      "epoch:5 step:4474 [D loss: 0.760089, acc: 40.62%] [G loss: 1.504934]\n",
      "epoch:5 step:4475 [D loss: 0.689215, acc: 52.34%] [G loss: 1.543256]\n",
      "epoch:5 step:4476 [D loss: 0.861755, acc: 28.12%] [G loss: 1.561510]\n",
      "epoch:5 step:4477 [D loss: 0.700667, acc: 55.47%] [G loss: 1.537396]\n",
      "epoch:5 step:4478 [D loss: 0.694455, acc: 53.91%] [G loss: 1.565766]\n",
      "epoch:5 step:4479 [D loss: 0.759900, acc: 39.84%] [G loss: 1.360681]\n",
      "epoch:5 step:4480 [D loss: 0.733586, acc: 43.75%] [G loss: 1.441919]\n",
      "epoch:5 step:4481 [D loss: 0.693599, acc: 53.91%] [G loss: 1.560533]\n",
      "epoch:5 step:4482 [D loss: 0.538423, acc: 82.03%] [G loss: 1.513864]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:5 step:4483 [D loss: 0.680438, acc: 57.03%] [G loss: 1.559220]\n",
      "epoch:5 step:4484 [D loss: 0.627118, acc: 67.97%] [G loss: 1.559796]\n",
      "epoch:5 step:4485 [D loss: 0.750474, acc: 42.19%] [G loss: 1.574664]\n",
      "epoch:5 step:4486 [D loss: 0.531917, acc: 79.69%] [G loss: 1.638572]\n",
      "epoch:5 step:4487 [D loss: 0.740895, acc: 49.22%] [G loss: 1.612203]\n",
      "epoch:5 step:4488 [D loss: 0.505361, acc: 80.47%] [G loss: 1.495139]\n",
      "epoch:5 step:4489 [D loss: 0.788553, acc: 29.69%] [G loss: 1.416183]\n",
      "epoch:5 step:4490 [D loss: 0.637711, acc: 65.62%] [G loss: 1.442618]\n",
      "epoch:5 step:4491 [D loss: 0.709720, acc: 46.88%] [G loss: 1.685483]\n",
      "epoch:5 step:4492 [D loss: 0.685423, acc: 52.34%] [G loss: 1.555969]\n",
      "epoch:5 step:4493 [D loss: 0.792722, acc: 35.94%] [G loss: 1.383554]\n",
      "epoch:5 step:4494 [D loss: 0.705954, acc: 53.12%] [G loss: 1.421372]\n",
      "epoch:5 step:4495 [D loss: 0.581472, acc: 78.12%] [G loss: 1.527337]\n",
      "epoch:5 step:4496 [D loss: 0.521412, acc: 85.16%] [G loss: 1.584692]\n",
      "epoch:5 step:4497 [D loss: 0.704800, acc: 57.81%] [G loss: 1.551641]\n",
      "epoch:5 step:4498 [D loss: 0.698129, acc: 58.59%] [G loss: 1.627456]\n",
      "epoch:5 step:4499 [D loss: 0.746420, acc: 49.22%] [G loss: 1.494146]\n",
      "epoch:5 step:4500 [D loss: 0.716550, acc: 45.31%] [G loss: 1.540735]\n",
      "epoch:5 step:4501 [D loss: 0.819467, acc: 27.34%] [G loss: 1.509691]\n",
      "epoch:5 step:4502 [D loss: 0.740894, acc: 40.62%] [G loss: 1.496084]\n",
      "epoch:5 step:4503 [D loss: 0.672339, acc: 57.03%] [G loss: 1.723993]\n",
      "epoch:5 step:4504 [D loss: 0.664676, acc: 62.50%] [G loss: 1.514688]\n",
      "epoch:5 step:4505 [D loss: 0.754251, acc: 42.19%] [G loss: 1.438185]\n",
      "epoch:5 step:4506 [D loss: 0.716547, acc: 49.22%] [G loss: 1.545674]\n",
      "epoch:5 step:4507 [D loss: 0.693223, acc: 58.59%] [G loss: 1.555475]\n",
      "epoch:5 step:4508 [D loss: 0.882719, acc: 22.66%] [G loss: 1.293223]\n",
      "epoch:5 step:4509 [D loss: 0.773923, acc: 33.59%] [G loss: 1.538185]\n",
      "epoch:5 step:4510 [D loss: 0.721809, acc: 50.78%] [G loss: 1.505516]\n",
      "epoch:5 step:4511 [D loss: 0.677583, acc: 58.59%] [G loss: 1.536481]\n",
      "epoch:5 step:4512 [D loss: 0.678410, acc: 54.69%] [G loss: 1.568830]\n",
      "epoch:5 step:4513 [D loss: 0.751261, acc: 43.75%] [G loss: 1.448465]\n",
      "epoch:5 step:4514 [D loss: 0.745821, acc: 35.16%] [G loss: 1.521068]\n",
      "epoch:5 step:4515 [D loss: 0.784344, acc: 33.59%] [G loss: 1.394294]\n",
      "epoch:5 step:4516 [D loss: 0.690523, acc: 60.94%] [G loss: 1.571771]\n",
      "epoch:5 step:4517 [D loss: 0.697588, acc: 55.47%] [G loss: 1.504174]\n",
      "epoch:5 step:4518 [D loss: 0.689876, acc: 53.91%] [G loss: 1.557689]\n",
      "epoch:5 step:4519 [D loss: 0.724621, acc: 43.75%] [G loss: 1.391577]\n",
      "epoch:5 step:4520 [D loss: 0.691697, acc: 60.16%] [G loss: 1.607815]\n",
      "epoch:5 step:4521 [D loss: 0.687725, acc: 55.47%] [G loss: 1.555415]\n",
      "epoch:5 step:4522 [D loss: 0.696308, acc: 46.88%] [G loss: 1.628146]\n",
      "epoch:5 step:4523 [D loss: 0.620910, acc: 74.22%] [G loss: 1.542616]\n",
      "epoch:5 step:4524 [D loss: 0.675027, acc: 55.47%] [G loss: 1.599084]\n",
      "epoch:5 step:4525 [D loss: 0.699813, acc: 55.47%] [G loss: 1.562737]\n",
      "epoch:5 step:4526 [D loss: 0.659831, acc: 60.94%] [G loss: 1.619132]\n",
      "epoch:5 step:4527 [D loss: 0.746652, acc: 49.22%] [G loss: 1.452672]\n",
      "epoch:5 step:4528 [D loss: 0.910681, acc: 18.75%] [G loss: 1.341286]\n",
      "epoch:5 step:4529 [D loss: 0.706286, acc: 52.34%] [G loss: 1.529400]\n",
      "epoch:5 step:4530 [D loss: 0.754076, acc: 44.53%] [G loss: 1.492873]\n",
      "epoch:5 step:4531 [D loss: 0.766952, acc: 41.41%] [G loss: 1.429090]\n",
      "epoch:5 step:4532 [D loss: 0.707595, acc: 53.91%] [G loss: 1.663541]\n",
      "epoch:5 step:4533 [D loss: 0.656123, acc: 65.62%] [G loss: 1.449594]\n",
      "epoch:5 step:4534 [D loss: 0.758036, acc: 38.28%] [G loss: 1.507514]\n",
      "epoch:5 step:4535 [D loss: 0.618179, acc: 71.09%] [G loss: 1.494673]\n",
      "epoch:5 step:4536 [D loss: 0.666010, acc: 60.94%] [G loss: 1.535370]\n",
      "epoch:5 step:4537 [D loss: 0.769970, acc: 39.06%] [G loss: 1.429858]\n",
      "epoch:5 step:4538 [D loss: 0.657695, acc: 57.81%] [G loss: 1.583065]\n",
      "epoch:5 step:4539 [D loss: 0.831146, acc: 24.22%] [G loss: 1.413858]\n",
      "epoch:5 step:4540 [D loss: 0.682517, acc: 51.56%] [G loss: 1.535450]\n",
      "epoch:5 step:4541 [D loss: 0.630474, acc: 69.53%] [G loss: 1.684541]\n",
      "epoch:5 step:4542 [D loss: 0.910645, acc: 21.09%] [G loss: 1.215057]\n",
      "epoch:5 step:4543 [D loss: 0.696433, acc: 54.69%] [G loss: 1.587554]\n",
      "epoch:5 step:4544 [D loss: 0.721287, acc: 55.47%] [G loss: 1.676185]\n",
      "epoch:5 step:4545 [D loss: 0.624375, acc: 71.88%] [G loss: 1.648599]\n",
      "epoch:5 step:4546 [D loss: 0.687337, acc: 57.03%] [G loss: 1.581214]\n",
      "epoch:5 step:4547 [D loss: 0.674222, acc: 61.72%] [G loss: 1.676629]\n",
      "epoch:5 step:4548 [D loss: 0.724230, acc: 50.78%] [G loss: 1.799882]\n",
      "epoch:5 step:4549 [D loss: 0.668018, acc: 62.50%] [G loss: 1.642942]\n",
      "epoch:5 step:4550 [D loss: 0.648489, acc: 60.16%] [G loss: 1.632878]\n",
      "epoch:5 step:4551 [D loss: 0.735070, acc: 44.53%] [G loss: 1.543773]\n",
      "epoch:5 step:4552 [D loss: 0.742242, acc: 46.09%] [G loss: 1.556014]\n",
      "epoch:5 step:4553 [D loss: 0.745970, acc: 48.44%] [G loss: 1.577958]\n",
      "epoch:5 step:4554 [D loss: 0.722954, acc: 47.66%] [G loss: 1.783249]\n",
      "epoch:5 step:4555 [D loss: 0.696930, acc: 60.16%] [G loss: 1.533036]\n",
      "epoch:5 step:4556 [D loss: 0.723828, acc: 57.81%] [G loss: 1.622335]\n",
      "epoch:5 step:4557 [D loss: 0.795878, acc: 33.59%] [G loss: 1.479994]\n",
      "epoch:5 step:4558 [D loss: 0.772123, acc: 41.41%] [G loss: 1.608115]\n",
      "epoch:5 step:4559 [D loss: 0.684490, acc: 62.50%] [G loss: 1.554143]\n",
      "epoch:5 step:4560 [D loss: 0.768097, acc: 38.28%] [G loss: 1.665730]\n",
      "epoch:5 step:4561 [D loss: 0.777333, acc: 43.75%] [G loss: 1.501882]\n",
      "epoch:5 step:4562 [D loss: 0.797666, acc: 34.38%] [G loss: 1.426492]\n",
      "epoch:5 step:4563 [D loss: 0.738514, acc: 44.53%] [G loss: 1.648958]\n",
      "epoch:5 step:4564 [D loss: 0.710547, acc: 53.12%] [G loss: 1.679736]\n",
      "epoch:5 step:4565 [D loss: 0.703849, acc: 46.88%] [G loss: 1.573978]\n",
      "epoch:5 step:4566 [D loss: 0.658763, acc: 64.84%] [G loss: 1.614753]\n",
      "epoch:5 step:4567 [D loss: 0.688278, acc: 50.00%] [G loss: 1.710175]\n",
      "epoch:5 step:4568 [D loss: 0.646311, acc: 64.06%] [G loss: 1.604694]\n",
      "epoch:5 step:4569 [D loss: 0.729753, acc: 47.66%] [G loss: 1.595789]\n",
      "epoch:5 step:4570 [D loss: 0.604046, acc: 67.97%] [G loss: 1.656721]\n",
      "epoch:5 step:4571 [D loss: 0.665111, acc: 56.25%] [G loss: 1.476655]\n",
      "epoch:5 step:4572 [D loss: 0.694707, acc: 55.47%] [G loss: 1.418631]\n",
      "epoch:5 step:4573 [D loss: 0.641142, acc: 63.28%] [G loss: 1.623154]\n",
      "epoch:5 step:4574 [D loss: 0.736178, acc: 48.44%] [G loss: 1.496489]\n",
      "epoch:5 step:4575 [D loss: 0.576472, acc: 73.44%] [G loss: 1.764979]\n",
      "epoch:5 step:4576 [D loss: 0.748472, acc: 46.09%] [G loss: 1.519278]\n",
      "epoch:5 step:4577 [D loss: 0.775054, acc: 33.59%] [G loss: 1.325866]\n",
      "epoch:5 step:4578 [D loss: 0.747591, acc: 45.31%] [G loss: 1.418830]\n",
      "epoch:5 step:4579 [D loss: 0.662188, acc: 57.03%] [G loss: 1.477209]\n",
      "epoch:5 step:4580 [D loss: 0.698457, acc: 56.25%] [G loss: 1.528001]\n",
      "epoch:5 step:4581 [D loss: 0.680727, acc: 56.25%] [G loss: 1.529715]\n",
      "epoch:5 step:4582 [D loss: 0.611973, acc: 73.44%] [G loss: 1.598191]\n",
      "epoch:5 step:4583 [D loss: 0.640529, acc: 66.41%] [G loss: 1.509235]\n",
      "epoch:5 step:4584 [D loss: 0.849493, acc: 21.88%] [G loss: 1.400229]\n",
      "epoch:5 step:4585 [D loss: 0.727720, acc: 50.78%] [G loss: 1.531114]\n",
      "epoch:5 step:4586 [D loss: 0.668957, acc: 58.59%] [G loss: 1.565104]\n",
      "epoch:5 step:4587 [D loss: 0.673233, acc: 54.69%] [G loss: 1.579576]\n",
      "epoch:5 step:4588 [D loss: 0.607714, acc: 67.97%] [G loss: 1.711701]\n",
      "epoch:5 step:4589 [D loss: 0.680775, acc: 62.50%] [G loss: 1.658502]\n",
      "epoch:5 step:4590 [D loss: 0.665892, acc: 62.50%] [G loss: 1.661361]\n",
      "epoch:5 step:4591 [D loss: 0.810254, acc: 30.47%] [G loss: 1.560415]\n",
      "epoch:5 step:4592 [D loss: 0.682141, acc: 59.38%] [G loss: 1.661099]\n",
      "epoch:5 step:4593 [D loss: 0.757148, acc: 44.53%] [G loss: 1.419092]\n",
      "epoch:5 step:4594 [D loss: 0.760504, acc: 40.62%] [G loss: 1.517949]\n",
      "epoch:5 step:4595 [D loss: 0.728257, acc: 53.91%] [G loss: 1.509612]\n",
      "epoch:5 step:4596 [D loss: 0.603025, acc: 73.44%] [G loss: 1.457013]\n",
      "epoch:5 step:4597 [D loss: 0.853660, acc: 27.34%] [G loss: 1.458781]\n",
      "epoch:5 step:4598 [D loss: 0.657612, acc: 60.94%] [G loss: 1.582338]\n",
      "epoch:5 step:4599 [D loss: 0.741551, acc: 46.88%] [G loss: 1.573364]\n",
      "epoch:5 step:4600 [D loss: 0.714010, acc: 48.44%] [G loss: 1.534909]\n",
      "##############\n",
      "[0.85892757 0.86967242 0.81337268 0.81099963 0.79476001 0.83235121\n",
      " 0.86944698 0.83115597 0.80618059 0.83423966]\n",
      "##########\n",
      "epoch:5 step:4601 [D loss: 0.716808, acc: 49.22%] [G loss: 1.533227]\n",
      "epoch:5 step:4602 [D loss: 0.773014, acc: 34.38%] [G loss: 1.493805]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:5 step:4603 [D loss: 0.658246, acc: 61.72%] [G loss: 1.527259]\n",
      "epoch:5 step:4604 [D loss: 0.722405, acc: 50.00%] [G loss: 1.525401]\n",
      "epoch:5 step:4605 [D loss: 0.667200, acc: 59.38%] [G loss: 1.619793]\n",
      "epoch:5 step:4606 [D loss: 0.714011, acc: 53.91%] [G loss: 1.539028]\n",
      "epoch:5 step:4607 [D loss: 0.663609, acc: 65.62%] [G loss: 1.607837]\n",
      "epoch:5 step:4608 [D loss: 0.663656, acc: 62.50%] [G loss: 1.627516]\n",
      "epoch:5 step:4609 [D loss: 0.772381, acc: 31.25%] [G loss: 1.523940]\n",
      "epoch:5 step:4610 [D loss: 0.664653, acc: 56.25%] [G loss: 1.596628]\n",
      "epoch:5 step:4611 [D loss: 0.717793, acc: 47.66%] [G loss: 1.610862]\n",
      "epoch:5 step:4612 [D loss: 0.658039, acc: 60.94%] [G loss: 1.551818]\n",
      "epoch:5 step:4613 [D loss: 0.668340, acc: 57.03%] [G loss: 1.723987]\n",
      "epoch:5 step:4614 [D loss: 0.651688, acc: 60.94%] [G loss: 1.514616]\n",
      "epoch:5 step:4615 [D loss: 0.727190, acc: 42.97%] [G loss: 1.547578]\n",
      "epoch:5 step:4616 [D loss: 0.713210, acc: 50.00%] [G loss: 1.729644]\n",
      "epoch:5 step:4617 [D loss: 0.677769, acc: 57.81%] [G loss: 1.522706]\n",
      "epoch:5 step:4618 [D loss: 0.752004, acc: 45.31%] [G loss: 1.612063]\n",
      "epoch:5 step:4619 [D loss: 0.530550, acc: 82.81%] [G loss: 1.609223]\n",
      "epoch:5 step:4620 [D loss: 0.809575, acc: 35.16%] [G loss: 1.487146]\n",
      "epoch:5 step:4621 [D loss: 0.716177, acc: 53.12%] [G loss: 1.666722]\n",
      "epoch:5 step:4622 [D loss: 0.720256, acc: 47.66%] [G loss: 1.606295]\n",
      "epoch:5 step:4623 [D loss: 0.689883, acc: 50.00%] [G loss: 1.610770]\n",
      "epoch:5 step:4624 [D loss: 0.711078, acc: 47.66%] [G loss: 1.592629]\n",
      "epoch:5 step:4625 [D loss: 0.741953, acc: 43.75%] [G loss: 1.504275]\n",
      "epoch:5 step:4626 [D loss: 0.721364, acc: 47.66%] [G loss: 1.459170]\n",
      "epoch:5 step:4627 [D loss: 0.672478, acc: 62.50%] [G loss: 1.817815]\n",
      "epoch:5 step:4628 [D loss: 0.772872, acc: 35.94%] [G loss: 1.503864]\n",
      "epoch:5 step:4629 [D loss: 0.710115, acc: 50.78%] [G loss: 1.527330]\n",
      "epoch:5 step:4630 [D loss: 0.664450, acc: 60.94%] [G loss: 1.723806]\n",
      "epoch:5 step:4631 [D loss: 0.690406, acc: 57.81%] [G loss: 1.519696]\n",
      "epoch:5 step:4632 [D loss: 0.673486, acc: 63.28%] [G loss: 1.613912]\n",
      "epoch:5 step:4633 [D loss: 0.730448, acc: 50.78%] [G loss: 1.517078]\n",
      "epoch:5 step:4634 [D loss: 0.679576, acc: 53.12%] [G loss: 1.740982]\n",
      "epoch:5 step:4635 [D loss: 0.763348, acc: 41.41%] [G loss: 1.599051]\n",
      "epoch:5 step:4636 [D loss: 0.680584, acc: 59.38%] [G loss: 1.622939]\n",
      "epoch:5 step:4637 [D loss: 0.663237, acc: 53.91%] [G loss: 1.612082]\n",
      "epoch:5 step:4638 [D loss: 0.554673, acc: 78.12%] [G loss: 1.735817]\n",
      "epoch:5 step:4639 [D loss: 0.651698, acc: 62.50%] [G loss: 1.552953]\n",
      "epoch:5 step:4640 [D loss: 0.694476, acc: 52.34%] [G loss: 1.508468]\n",
      "epoch:5 step:4641 [D loss: 0.631501, acc: 67.97%] [G loss: 1.714636]\n",
      "epoch:5 step:4642 [D loss: 0.709507, acc: 50.78%] [G loss: 1.501399]\n",
      "epoch:5 step:4643 [D loss: 0.779778, acc: 35.94%] [G loss: 1.553066]\n",
      "epoch:5 step:4644 [D loss: 0.826410, acc: 30.47%] [G loss: 1.683341]\n",
      "epoch:5 step:4645 [D loss: 0.751504, acc: 36.72%] [G loss: 1.611743]\n",
      "epoch:5 step:4646 [D loss: 0.585858, acc: 72.66%] [G loss: 1.570609]\n",
      "epoch:5 step:4647 [D loss: 0.652450, acc: 58.59%] [G loss: 1.779642]\n",
      "epoch:5 step:4648 [D loss: 0.646010, acc: 62.50%] [G loss: 1.701711]\n",
      "epoch:5 step:4649 [D loss: 0.797178, acc: 38.28%] [G loss: 1.490904]\n",
      "epoch:5 step:4650 [D loss: 0.654634, acc: 64.84%] [G loss: 1.655686]\n",
      "epoch:5 step:4651 [D loss: 0.708530, acc: 50.00%] [G loss: 1.470104]\n",
      "epoch:5 step:4652 [D loss: 0.644334, acc: 59.38%] [G loss: 1.544381]\n",
      "epoch:5 step:4653 [D loss: 0.703159, acc: 51.56%] [G loss: 1.584258]\n",
      "epoch:5 step:4654 [D loss: 0.700586, acc: 51.56%] [G loss: 1.492174]\n",
      "epoch:5 step:4655 [D loss: 0.700463, acc: 56.25%] [G loss: 1.561084]\n",
      "epoch:5 step:4656 [D loss: 0.882080, acc: 25.78%] [G loss: 1.267375]\n",
      "epoch:5 step:4657 [D loss: 0.712183, acc: 53.91%] [G loss: 1.572599]\n",
      "epoch:5 step:4658 [D loss: 0.600210, acc: 76.56%] [G loss: 1.630484]\n",
      "epoch:5 step:4659 [D loss: 0.639693, acc: 66.41%] [G loss: 1.546792]\n",
      "epoch:5 step:4660 [D loss: 0.734566, acc: 49.22%] [G loss: 1.518652]\n",
      "epoch:5 step:4661 [D loss: 0.653417, acc: 60.94%] [G loss: 1.701404]\n",
      "epoch:5 step:4662 [D loss: 0.667772, acc: 60.16%] [G loss: 1.629632]\n",
      "epoch:5 step:4663 [D loss: 0.731197, acc: 42.97%] [G loss: 1.593480]\n",
      "epoch:5 step:4664 [D loss: 0.726359, acc: 46.09%] [G loss: 1.517696]\n",
      "epoch:5 step:4665 [D loss: 0.612533, acc: 75.78%] [G loss: 1.611296]\n",
      "epoch:5 step:4666 [D loss: 0.652105, acc: 64.84%] [G loss: 1.581484]\n",
      "epoch:5 step:4667 [D loss: 0.630019, acc: 67.97%] [G loss: 1.492812]\n",
      "epoch:5 step:4668 [D loss: 0.635833, acc: 66.41%] [G loss: 1.573216]\n",
      "epoch:5 step:4669 [D loss: 0.737829, acc: 40.62%] [G loss: 1.467481]\n",
      "epoch:5 step:4670 [D loss: 0.748305, acc: 43.75%] [G loss: 1.523898]\n",
      "epoch:5 step:4671 [D loss: 0.666409, acc: 59.38%] [G loss: 1.569830]\n",
      "epoch:5 step:4672 [D loss: 0.620257, acc: 70.31%] [G loss: 1.617444]\n",
      "epoch:5 step:4673 [D loss: 0.701757, acc: 46.09%] [G loss: 1.516492]\n",
      "epoch:5 step:4674 [D loss: 0.686345, acc: 55.47%] [G loss: 1.530942]\n",
      "epoch:5 step:4675 [D loss: 0.672196, acc: 60.16%] [G loss: 1.542947]\n",
      "epoch:5 step:4676 [D loss: 0.905480, acc: 30.47%] [G loss: 1.480797]\n",
      "epoch:5 step:4677 [D loss: 0.724877, acc: 53.91%] [G loss: 1.630666]\n",
      "epoch:5 step:4678 [D loss: 0.627156, acc: 60.94%] [G loss: 1.531090]\n",
      "epoch:5 step:4679 [D loss: 0.720570, acc: 49.22%] [G loss: 1.585976]\n",
      "epoch:5 step:4680 [D loss: 0.665108, acc: 62.50%] [G loss: 1.445486]\n",
      "epoch:5 step:4681 [D loss: 0.510259, acc: 71.09%] [G loss: 1.598556]\n",
      "epoch:5 step:4682 [D loss: 0.754112, acc: 44.53%] [G loss: 1.533615]\n",
      "epoch:5 step:4683 [D loss: 0.779862, acc: 40.62%] [G loss: 1.481337]\n",
      "epoch:5 step:4684 [D loss: 0.670393, acc: 56.25%] [G loss: 1.530888]\n",
      "epoch:5 step:4685 [D loss: 0.577607, acc: 78.91%] [G loss: 1.504431]\n",
      "epoch:5 step:4686 [D loss: 0.658035, acc: 63.28%] [G loss: 1.464522]\n",
      "epoch:6 step:4687 [D loss: 0.616019, acc: 66.41%] [G loss: 1.269074]\n",
      "epoch:6 step:4688 [D loss: 0.617490, acc: 71.09%] [G loss: 1.433312]\n",
      "epoch:6 step:4689 [D loss: 0.878271, acc: 28.12%] [G loss: 1.378564]\n",
      "epoch:6 step:4690 [D loss: 0.706937, acc: 51.56%] [G loss: 1.486098]\n",
      "epoch:6 step:4691 [D loss: 0.717260, acc: 45.31%] [G loss: 1.629735]\n",
      "epoch:6 step:4692 [D loss: 0.688804, acc: 56.25%] [G loss: 1.644351]\n",
      "epoch:6 step:4693 [D loss: 0.724533, acc: 47.66%] [G loss: 1.668049]\n",
      "epoch:6 step:4694 [D loss: 0.729988, acc: 50.00%] [G loss: 1.580459]\n",
      "epoch:6 step:4695 [D loss: 0.691611, acc: 56.25%] [G loss: 1.510866]\n",
      "epoch:6 step:4696 [D loss: 0.569870, acc: 66.41%] [G loss: 1.551721]\n",
      "epoch:6 step:4697 [D loss: 0.745832, acc: 49.22%] [G loss: 1.585194]\n",
      "epoch:6 step:4698 [D loss: 0.704686, acc: 56.25%] [G loss: 1.464208]\n",
      "epoch:6 step:4699 [D loss: 0.650614, acc: 62.50%] [G loss: 1.625193]\n",
      "epoch:6 step:4700 [D loss: 0.793548, acc: 35.16%] [G loss: 1.482750]\n",
      "epoch:6 step:4701 [D loss: 0.670121, acc: 57.81%] [G loss: 1.571816]\n",
      "epoch:6 step:4702 [D loss: 0.746242, acc: 44.53%] [G loss: 1.585410]\n",
      "epoch:6 step:4703 [D loss: 0.658183, acc: 57.03%] [G loss: 1.599354]\n",
      "epoch:6 step:4704 [D loss: 0.718442, acc: 47.66%] [G loss: 1.685445]\n",
      "epoch:6 step:4705 [D loss: 0.533007, acc: 84.38%] [G loss: 1.563771]\n",
      "epoch:6 step:4706 [D loss: 0.645482, acc: 64.84%] [G loss: 1.643795]\n",
      "epoch:6 step:4707 [D loss: 0.784117, acc: 37.50%] [G loss: 1.579564]\n",
      "epoch:6 step:4708 [D loss: 0.646217, acc: 67.97%] [G loss: 1.655042]\n",
      "epoch:6 step:4709 [D loss: 0.559139, acc: 71.88%] [G loss: 1.680086]\n",
      "epoch:6 step:4710 [D loss: 0.656764, acc: 60.16%] [G loss: 1.564803]\n",
      "epoch:6 step:4711 [D loss: 0.555130, acc: 75.00%] [G loss: 1.659431]\n",
      "epoch:6 step:4712 [D loss: 0.887577, acc: 14.84%] [G loss: 1.264329]\n",
      "epoch:6 step:4713 [D loss: 0.746942, acc: 38.28%] [G loss: 1.434145]\n",
      "epoch:6 step:4714 [D loss: 0.648618, acc: 62.50%] [G loss: 1.545364]\n",
      "epoch:6 step:4715 [D loss: 0.630607, acc: 66.41%] [G loss: 1.815770]\n",
      "epoch:6 step:4716 [D loss: 0.605365, acc: 68.75%] [G loss: 1.594759]\n",
      "epoch:6 step:4717 [D loss: 0.462711, acc: 86.72%] [G loss: 1.688877]\n",
      "epoch:6 step:4718 [D loss: 0.622536, acc: 68.75%] [G loss: 1.790445]\n",
      "epoch:6 step:4719 [D loss: 0.791708, acc: 32.81%] [G loss: 1.654384]\n",
      "epoch:6 step:4720 [D loss: 0.740694, acc: 50.78%] [G loss: 1.652853]\n",
      "epoch:6 step:4721 [D loss: 0.570143, acc: 71.88%] [G loss: 1.593154]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:6 step:4722 [D loss: 0.559616, acc: 75.00%] [G loss: 1.913963]\n",
      "epoch:6 step:4723 [D loss: 0.520887, acc: 88.28%] [G loss: 1.668877]\n",
      "epoch:6 step:4724 [D loss: 0.780861, acc: 49.22%] [G loss: 1.603911]\n",
      "epoch:6 step:4725 [D loss: 0.869764, acc: 29.69%] [G loss: 1.508879]\n",
      "epoch:6 step:4726 [D loss: 0.612555, acc: 67.97%] [G loss: 1.593451]\n",
      "epoch:6 step:4727 [D loss: 0.621552, acc: 72.66%] [G loss: 1.545125]\n",
      "epoch:6 step:4728 [D loss: 0.793903, acc: 37.50%] [G loss: 1.536238]\n",
      "epoch:6 step:4729 [D loss: 0.726595, acc: 58.59%] [G loss: 1.465623]\n",
      "epoch:6 step:4730 [D loss: 0.674030, acc: 57.81%] [G loss: 1.559880]\n",
      "epoch:6 step:4731 [D loss: 0.744836, acc: 45.31%] [G loss: 1.835431]\n",
      "epoch:6 step:4732 [D loss: 0.574109, acc: 73.44%] [G loss: 1.522455]\n",
      "epoch:6 step:4733 [D loss: 0.578825, acc: 80.47%] [G loss: 1.721622]\n",
      "epoch:6 step:4734 [D loss: 0.650706, acc: 60.16%] [G loss: 1.621283]\n",
      "epoch:6 step:4735 [D loss: 0.952920, acc: 21.88%] [G loss: 1.382149]\n",
      "epoch:6 step:4736 [D loss: 0.603573, acc: 71.88%] [G loss: 1.713116]\n",
      "epoch:6 step:4737 [D loss: 0.776424, acc: 40.62%] [G loss: 1.488871]\n",
      "epoch:6 step:4738 [D loss: 0.469389, acc: 87.50%] [G loss: 2.179963]\n",
      "epoch:6 step:4739 [D loss: 0.657861, acc: 63.28%] [G loss: 1.600547]\n",
      "epoch:6 step:4740 [D loss: 0.857506, acc: 25.78%] [G loss: 1.536885]\n",
      "epoch:6 step:4741 [D loss: 0.700075, acc: 50.78%] [G loss: 1.551724]\n",
      "epoch:6 step:4742 [D loss: 0.755922, acc: 40.62%] [G loss: 1.543508]\n",
      "epoch:6 step:4743 [D loss: 0.724097, acc: 49.22%] [G loss: 1.694335]\n",
      "epoch:6 step:4744 [D loss: 0.587483, acc: 70.31%] [G loss: 1.653495]\n",
      "epoch:6 step:4745 [D loss: 0.628781, acc: 69.53%] [G loss: 1.820666]\n",
      "epoch:6 step:4746 [D loss: 0.648078, acc: 60.16%] [G loss: 1.691544]\n",
      "epoch:6 step:4747 [D loss: 0.641816, acc: 60.16%] [G loss: 1.526021]\n",
      "epoch:6 step:4748 [D loss: 0.547693, acc: 77.34%] [G loss: 1.690681]\n",
      "epoch:6 step:4749 [D loss: 0.431447, acc: 85.94%] [G loss: 1.786564]\n",
      "epoch:6 step:4750 [D loss: 0.863678, acc: 21.88%] [G loss: 1.325178]\n",
      "epoch:6 step:4751 [D loss: 0.925328, acc: 21.88%] [G loss: 1.416499]\n",
      "epoch:6 step:4752 [D loss: 0.699733, acc: 50.78%] [G loss: 1.616642]\n",
      "epoch:6 step:4753 [D loss: 0.549983, acc: 71.09%] [G loss: 1.600275]\n",
      "epoch:6 step:4754 [D loss: 0.717036, acc: 50.00%] [G loss: 1.376230]\n",
      "epoch:6 step:4755 [D loss: 0.653739, acc: 57.03%] [G loss: 1.310933]\n",
      "epoch:6 step:4756 [D loss: 0.599565, acc: 71.88%] [G loss: 1.698023]\n",
      "epoch:6 step:4757 [D loss: 0.835700, acc: 47.66%] [G loss: 1.284928]\n",
      "epoch:6 step:4758 [D loss: 0.371399, acc: 95.31%] [G loss: 1.722521]\n",
      "epoch:6 step:4759 [D loss: 0.722949, acc: 50.78%] [G loss: 1.487665]\n",
      "epoch:6 step:4760 [D loss: 0.717274, acc: 51.56%] [G loss: 1.508840]\n",
      "epoch:6 step:4761 [D loss: 0.663965, acc: 63.28%] [G loss: 1.580135]\n",
      "epoch:6 step:4762 [D loss: 0.941676, acc: 21.88%] [G loss: 1.510321]\n",
      "epoch:6 step:4763 [D loss: 0.796296, acc: 46.88%] [G loss: 1.263094]\n",
      "epoch:6 step:4764 [D loss: 0.848918, acc: 32.81%] [G loss: 1.617695]\n",
      "epoch:6 step:4765 [D loss: 0.714212, acc: 49.22%] [G loss: 1.573914]\n",
      "epoch:6 step:4766 [D loss: 0.754936, acc: 48.44%] [G loss: 1.642017]\n",
      "epoch:6 step:4767 [D loss: 0.645591, acc: 68.75%] [G loss: 1.691514]\n",
      "epoch:6 step:4768 [D loss: 0.663496, acc: 60.94%] [G loss: 1.583984]\n",
      "epoch:6 step:4769 [D loss: 0.619170, acc: 69.53%] [G loss: 1.638093]\n",
      "epoch:6 step:4770 [D loss: 0.701276, acc: 50.78%] [G loss: 1.443521]\n",
      "epoch:6 step:4771 [D loss: 0.662206, acc: 60.16%] [G loss: 1.709656]\n",
      "epoch:6 step:4772 [D loss: 0.694884, acc: 56.25%] [G loss: 1.707046]\n",
      "epoch:6 step:4773 [D loss: 0.606377, acc: 73.44%] [G loss: 1.787153]\n",
      "epoch:6 step:4774 [D loss: 0.719164, acc: 46.09%] [G loss: 1.552785]\n",
      "epoch:6 step:4775 [D loss: 0.743537, acc: 48.44%] [G loss: 1.592083]\n",
      "epoch:6 step:4776 [D loss: 0.573255, acc: 77.34%] [G loss: 1.577643]\n",
      "epoch:6 step:4777 [D loss: 0.661103, acc: 61.72%] [G loss: 1.465845]\n",
      "epoch:6 step:4778 [D loss: 0.791299, acc: 38.28%] [G loss: 1.507182]\n",
      "epoch:6 step:4779 [D loss: 0.678048, acc: 64.06%] [G loss: 1.491808]\n",
      "epoch:6 step:4780 [D loss: 0.868904, acc: 21.88%] [G loss: 1.272754]\n",
      "epoch:6 step:4781 [D loss: 0.624980, acc: 70.31%] [G loss: 1.506157]\n",
      "epoch:6 step:4782 [D loss: 0.716618, acc: 50.78%] [G loss: 1.313543]\n",
      "epoch:6 step:4783 [D loss: 0.742803, acc: 39.84%] [G loss: 1.442157]\n",
      "epoch:6 step:4784 [D loss: 0.589339, acc: 76.56%] [G loss: 1.551059]\n",
      "epoch:6 step:4785 [D loss: 0.657710, acc: 62.50%] [G loss: 1.534547]\n",
      "epoch:6 step:4786 [D loss: 0.620246, acc: 74.22%] [G loss: 1.443391]\n",
      "epoch:6 step:4787 [D loss: 0.714376, acc: 52.34%] [G loss: 1.635743]\n",
      "epoch:6 step:4788 [D loss: 0.871260, acc: 22.66%] [G loss: 1.357944]\n",
      "epoch:6 step:4789 [D loss: 0.664105, acc: 57.81%] [G loss: 1.558954]\n",
      "epoch:6 step:4790 [D loss: 0.786495, acc: 37.50%] [G loss: 1.355588]\n",
      "epoch:6 step:4791 [D loss: 0.591074, acc: 68.75%] [G loss: 1.530934]\n",
      "epoch:6 step:4792 [D loss: 0.718756, acc: 46.88%] [G loss: 1.504262]\n",
      "epoch:6 step:4793 [D loss: 0.669943, acc: 57.03%] [G loss: 1.680106]\n",
      "epoch:6 step:4794 [D loss: 0.665201, acc: 59.38%] [G loss: 1.662390]\n",
      "epoch:6 step:4795 [D loss: 0.593221, acc: 67.97%] [G loss: 1.578974]\n",
      "epoch:6 step:4796 [D loss: 0.664216, acc: 60.94%] [G loss: 1.684391]\n",
      "epoch:6 step:4797 [D loss: 0.908382, acc: 28.91%] [G loss: 1.485131]\n",
      "epoch:6 step:4798 [D loss: 0.613835, acc: 71.09%] [G loss: 1.665332]\n",
      "epoch:6 step:4799 [D loss: 0.636220, acc: 66.41%] [G loss: 1.596401]\n",
      "epoch:6 step:4800 [D loss: 0.630006, acc: 68.75%] [G loss: 1.538307]\n",
      "##############\n",
      "[0.8519963  0.88591483 0.81776266 0.84389273 0.79146291 0.83815777\n",
      " 0.87675153 0.83058233 0.81879804 0.81702768]\n",
      "##########\n",
      "epoch:6 step:4801 [D loss: 0.741916, acc: 46.88%] [G loss: 1.377765]\n",
      "epoch:6 step:4802 [D loss: 0.586473, acc: 68.75%] [G loss: 1.458701]\n",
      "epoch:6 step:4803 [D loss: 0.748834, acc: 48.44%] [G loss: 1.616715]\n",
      "epoch:6 step:4804 [D loss: 0.584844, acc: 77.34%] [G loss: 1.394646]\n",
      "epoch:6 step:4805 [D loss: 0.646684, acc: 63.28%] [G loss: 1.573356]\n",
      "epoch:6 step:4806 [D loss: 0.526271, acc: 78.91%] [G loss: 1.587992]\n",
      "epoch:6 step:4807 [D loss: 0.838454, acc: 28.12%] [G loss: 1.386310]\n",
      "epoch:6 step:4808 [D loss: 0.470412, acc: 91.41%] [G loss: 1.637821]\n",
      "epoch:6 step:4809 [D loss: 0.966609, acc: 28.12%] [G loss: 1.478842]\n",
      "epoch:6 step:4810 [D loss: 0.928425, acc: 21.88%] [G loss: 1.397014]\n",
      "epoch:6 step:4811 [D loss: 0.544149, acc: 72.66%] [G loss: 1.666001]\n",
      "epoch:6 step:4812 [D loss: 0.759564, acc: 49.22%] [G loss: 1.566907]\n",
      "epoch:6 step:4813 [D loss: 0.656240, acc: 57.81%] [G loss: 1.622459]\n",
      "epoch:6 step:4814 [D loss: 0.547685, acc: 77.34%] [G loss: 1.751850]\n",
      "epoch:6 step:4815 [D loss: 0.666545, acc: 61.72%] [G loss: 1.762532]\n",
      "epoch:6 step:4816 [D loss: 0.749538, acc: 36.72%] [G loss: 1.657959]\n",
      "epoch:6 step:4817 [D loss: 0.652789, acc: 66.41%] [G loss: 1.501823]\n",
      "epoch:6 step:4818 [D loss: 0.686095, acc: 57.03%] [G loss: 1.650460]\n",
      "epoch:6 step:4819 [D loss: 0.732969, acc: 54.69%] [G loss: 1.559310]\n",
      "epoch:6 step:4820 [D loss: 0.619120, acc: 70.31%] [G loss: 1.731071]\n",
      "epoch:6 step:4821 [D loss: 0.738466, acc: 47.66%] [G loss: 1.542470]\n",
      "epoch:6 step:4822 [D loss: 0.525956, acc: 77.34%] [G loss: 1.562428]\n",
      "epoch:6 step:4823 [D loss: 0.559170, acc: 76.56%] [G loss: 1.566677]\n",
      "epoch:6 step:4824 [D loss: 0.654687, acc: 60.16%] [G loss: 1.684037]\n",
      "epoch:6 step:4825 [D loss: 0.713189, acc: 50.78%] [G loss: 1.831535]\n",
      "epoch:6 step:4826 [D loss: 0.689120, acc: 55.47%] [G loss: 1.947600]\n",
      "epoch:6 step:4827 [D loss: 0.762153, acc: 43.75%] [G loss: 1.491658]\n",
      "epoch:6 step:4828 [D loss: 0.450194, acc: 79.69%] [G loss: 1.582744]\n",
      "epoch:6 step:4829 [D loss: 0.740883, acc: 49.22%] [G loss: 1.687157]\n",
      "epoch:6 step:4830 [D loss: 0.765435, acc: 44.53%] [G loss: 1.743521]\n",
      "epoch:6 step:4831 [D loss: 0.637114, acc: 57.03%] [G loss: 1.562589]\n",
      "epoch:6 step:4832 [D loss: 0.789424, acc: 36.72%] [G loss: 1.606862]\n",
      "epoch:6 step:4833 [D loss: 0.475279, acc: 90.62%] [G loss: 1.796327]\n",
      "epoch:6 step:4834 [D loss: 0.710004, acc: 49.22%] [G loss: 1.562382]\n",
      "epoch:6 step:4835 [D loss: 0.852368, acc: 26.56%] [G loss: 1.403685]\n",
      "epoch:6 step:4836 [D loss: 0.830455, acc: 28.91%] [G loss: 1.378884]\n",
      "epoch:6 step:4837 [D loss: 0.540219, acc: 85.94%] [G loss: 1.613632]\n",
      "epoch:6 step:4838 [D loss: 0.668987, acc: 59.38%] [G loss: 1.630553]\n",
      "epoch:6 step:4839 [D loss: 0.589345, acc: 74.22%] [G loss: 1.757566]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:6 step:4840 [D loss: 0.738944, acc: 47.66%] [G loss: 1.643209]\n",
      "epoch:6 step:4841 [D loss: 0.754366, acc: 39.84%] [G loss: 1.496828]\n",
      "epoch:6 step:4842 [D loss: 0.633443, acc: 70.31%] [G loss: 1.722017]\n",
      "epoch:6 step:4843 [D loss: 0.498111, acc: 71.88%] [G loss: 1.572567]\n",
      "epoch:6 step:4844 [D loss: 0.807408, acc: 39.06%] [G loss: 1.444167]\n",
      "epoch:6 step:4845 [D loss: 0.647396, acc: 63.28%] [G loss: 1.794684]\n",
      "epoch:6 step:4846 [D loss: 0.822572, acc: 33.59%] [G loss: 1.587307]\n",
      "epoch:6 step:4847 [D loss: 0.741081, acc: 42.97%] [G loss: 1.506922]\n",
      "epoch:6 step:4848 [D loss: 0.573483, acc: 77.34%] [G loss: 1.628131]\n",
      "epoch:6 step:4849 [D loss: 0.634867, acc: 66.41%] [G loss: 1.620206]\n",
      "epoch:6 step:4850 [D loss: 0.664969, acc: 60.16%] [G loss: 1.689890]\n",
      "epoch:6 step:4851 [D loss: 0.709546, acc: 49.22%] [G loss: 1.746859]\n",
      "epoch:6 step:4852 [D loss: 0.811849, acc: 49.22%] [G loss: 1.444659]\n",
      "epoch:6 step:4853 [D loss: 0.690181, acc: 57.03%] [G loss: 1.780548]\n",
      "epoch:6 step:4854 [D loss: 0.711095, acc: 52.34%] [G loss: 1.730047]\n",
      "epoch:6 step:4855 [D loss: 0.662488, acc: 57.81%] [G loss: 1.562135]\n",
      "epoch:6 step:4856 [D loss: 0.709147, acc: 50.00%] [G loss: 1.634284]\n",
      "epoch:6 step:4857 [D loss: 0.697875, acc: 56.25%] [G loss: 1.772505]\n",
      "epoch:6 step:4858 [D loss: 0.689632, acc: 53.91%] [G loss: 1.918527]\n",
      "epoch:6 step:4859 [D loss: 0.658966, acc: 58.59%] [G loss: 1.826090]\n",
      "epoch:6 step:4860 [D loss: 0.770469, acc: 46.88%] [G loss: 1.729437]\n",
      "epoch:6 step:4861 [D loss: 0.806247, acc: 43.75%] [G loss: 1.610854]\n",
      "epoch:6 step:4862 [D loss: 0.767368, acc: 35.94%] [G loss: 1.471824]\n",
      "epoch:6 step:4863 [D loss: 0.555662, acc: 80.47%] [G loss: 1.845579]\n",
      "epoch:6 step:4864 [D loss: 0.864783, acc: 23.44%] [G loss: 1.363553]\n",
      "epoch:6 step:4865 [D loss: 0.784150, acc: 37.50%] [G loss: 1.445191]\n",
      "epoch:6 step:4866 [D loss: 0.722864, acc: 46.88%] [G loss: 1.565710]\n",
      "epoch:6 step:4867 [D loss: 0.661851, acc: 60.94%] [G loss: 1.474770]\n",
      "epoch:6 step:4868 [D loss: 0.560942, acc: 74.22%] [G loss: 1.712628]\n",
      "epoch:6 step:4869 [D loss: 0.583362, acc: 75.78%] [G loss: 1.820622]\n",
      "epoch:6 step:4870 [D loss: 0.757213, acc: 37.50%] [G loss: 1.492984]\n",
      "epoch:6 step:4871 [D loss: 0.657451, acc: 48.44%] [G loss: 1.590211]\n",
      "epoch:6 step:4872 [D loss: 0.628862, acc: 64.84%] [G loss: 1.717208]\n",
      "epoch:6 step:4873 [D loss: 0.639684, acc: 63.28%] [G loss: 1.723009]\n",
      "epoch:6 step:4874 [D loss: 0.690731, acc: 57.03%] [G loss: 1.638749]\n",
      "epoch:6 step:4875 [D loss: 0.660310, acc: 57.81%] [G loss: 1.665697]\n",
      "epoch:6 step:4876 [D loss: 0.609359, acc: 72.66%] [G loss: 1.633681]\n",
      "epoch:6 step:4877 [D loss: 0.589366, acc: 76.56%] [G loss: 1.616502]\n",
      "epoch:6 step:4878 [D loss: 0.667965, acc: 57.03%] [G loss: 1.725131]\n",
      "epoch:6 step:4879 [D loss: 0.540370, acc: 75.00%] [G loss: 1.681777]\n",
      "epoch:6 step:4880 [D loss: 0.641337, acc: 65.62%] [G loss: 1.699609]\n",
      "epoch:6 step:4881 [D loss: 0.665520, acc: 60.16%] [G loss: 1.631954]\n",
      "epoch:6 step:4882 [D loss: 1.040695, acc: 10.94%] [G loss: 1.371740]\n",
      "epoch:6 step:4883 [D loss: 0.670481, acc: 57.81%] [G loss: 1.695033]\n",
      "epoch:6 step:4884 [D loss: 0.821248, acc: 23.44%] [G loss: 1.482692]\n",
      "epoch:6 step:4885 [D loss: 0.552566, acc: 78.12%] [G loss: 1.796227]\n",
      "epoch:6 step:4886 [D loss: 0.654518, acc: 56.25%] [G loss: 1.669875]\n",
      "epoch:6 step:4887 [D loss: 0.612695, acc: 74.22%] [G loss: 1.640598]\n",
      "epoch:6 step:4888 [D loss: 0.936393, acc: 17.19%] [G loss: 1.287744]\n",
      "epoch:6 step:4889 [D loss: 0.666465, acc: 57.03%] [G loss: 1.648939]\n",
      "epoch:6 step:4890 [D loss: 0.735660, acc: 39.84%] [G loss: 1.681926]\n",
      "epoch:6 step:4891 [D loss: 1.000563, acc: 39.06%] [G loss: 1.262926]\n",
      "epoch:6 step:4892 [D loss: 0.716112, acc: 45.31%] [G loss: 1.513521]\n",
      "epoch:6 step:4893 [D loss: 0.801684, acc: 40.62%] [G loss: 1.485716]\n",
      "epoch:6 step:4894 [D loss: 0.585618, acc: 71.88%] [G loss: 1.697527]\n",
      "epoch:6 step:4895 [D loss: 0.805078, acc: 30.47%] [G loss: 1.458331]\n",
      "epoch:6 step:4896 [D loss: 0.679495, acc: 59.38%] [G loss: 1.640111]\n",
      "epoch:6 step:4897 [D loss: 0.699049, acc: 53.12%] [G loss: 1.700399]\n",
      "epoch:6 step:4898 [D loss: 0.682617, acc: 58.59%] [G loss: 1.665178]\n",
      "epoch:6 step:4899 [D loss: 0.685036, acc: 53.91%] [G loss: 1.553672]\n",
      "epoch:6 step:4900 [D loss: 0.746379, acc: 46.09%] [G loss: 1.577112]\n",
      "epoch:6 step:4901 [D loss: 0.681228, acc: 56.25%] [G loss: 1.574013]\n",
      "epoch:6 step:4902 [D loss: 0.630331, acc: 64.84%] [G loss: 1.745598]\n",
      "epoch:6 step:4903 [D loss: 0.861313, acc: 32.81%] [G loss: 1.486787]\n",
      "epoch:6 step:4904 [D loss: 0.653648, acc: 66.41%] [G loss: 1.814826]\n",
      "epoch:6 step:4905 [D loss: 0.676792, acc: 58.59%] [G loss: 1.767053]\n",
      "epoch:6 step:4906 [D loss: 0.677949, acc: 57.81%] [G loss: 1.742153]\n",
      "epoch:6 step:4907 [D loss: 0.880469, acc: 23.44%] [G loss: 1.496926]\n",
      "epoch:6 step:4908 [D loss: 0.715097, acc: 55.47%] [G loss: 1.672041]\n",
      "epoch:6 step:4909 [D loss: 0.725545, acc: 53.12%] [G loss: 1.567933]\n",
      "epoch:6 step:4910 [D loss: 0.595979, acc: 64.84%] [G loss: 1.489774]\n",
      "epoch:6 step:4911 [D loss: 0.784858, acc: 35.94%] [G loss: 1.496019]\n",
      "epoch:6 step:4912 [D loss: 0.818417, acc: 36.72%] [G loss: 1.420319]\n",
      "epoch:6 step:4913 [D loss: 0.729906, acc: 51.56%] [G loss: 1.532763]\n",
      "epoch:6 step:4914 [D loss: 0.711564, acc: 53.91%] [G loss: 1.611485]\n",
      "epoch:6 step:4915 [D loss: 0.645312, acc: 60.94%] [G loss: 1.682902]\n",
      "epoch:6 step:4916 [D loss: 0.939661, acc: 16.41%] [G loss: 1.346838]\n",
      "epoch:6 step:4917 [D loss: 0.617958, acc: 70.31%] [G loss: 1.748773]\n",
      "epoch:6 step:4918 [D loss: 0.779835, acc: 43.75%] [G loss: 1.361107]\n",
      "epoch:6 step:4919 [D loss: 0.730046, acc: 48.44%] [G loss: 1.521548]\n",
      "epoch:6 step:4920 [D loss: 0.778657, acc: 39.06%] [G loss: 1.417653]\n",
      "epoch:6 step:4921 [D loss: 0.659356, acc: 60.94%] [G loss: 1.512640]\n",
      "epoch:6 step:4922 [D loss: 0.677606, acc: 58.59%] [G loss: 1.482098]\n",
      "epoch:6 step:4923 [D loss: 0.701841, acc: 52.34%] [G loss: 1.678281]\n",
      "epoch:6 step:4924 [D loss: 0.589804, acc: 71.88%] [G loss: 1.423546]\n",
      "epoch:6 step:4925 [D loss: 0.630176, acc: 70.31%] [G loss: 1.499981]\n",
      "epoch:6 step:4926 [D loss: 0.966479, acc: 19.53%] [G loss: 1.370884]\n",
      "epoch:6 step:4927 [D loss: 0.738726, acc: 46.09%] [G loss: 1.588471]\n",
      "epoch:6 step:4928 [D loss: 0.671240, acc: 57.03%] [G loss: 1.730391]\n",
      "epoch:6 step:4929 [D loss: 0.634256, acc: 67.97%] [G loss: 1.599177]\n",
      "epoch:6 step:4930 [D loss: 0.713223, acc: 50.78%] [G loss: 1.483265]\n",
      "epoch:6 step:4931 [D loss: 0.704190, acc: 57.03%] [G loss: 1.617479]\n",
      "epoch:6 step:4932 [D loss: 0.791668, acc: 41.41%] [G loss: 1.546455]\n",
      "epoch:6 step:4933 [D loss: 0.723156, acc: 44.53%] [G loss: 1.770456]\n",
      "epoch:6 step:4934 [D loss: 0.528738, acc: 81.25%] [G loss: 1.767738]\n",
      "epoch:6 step:4935 [D loss: 0.519869, acc: 85.94%] [G loss: 1.574654]\n",
      "epoch:6 step:4936 [D loss: 0.504225, acc: 90.62%] [G loss: 1.582630]\n",
      "epoch:6 step:4937 [D loss: 0.514519, acc: 85.94%] [G loss: 1.721832]\n",
      "epoch:6 step:4938 [D loss: 0.473363, acc: 89.84%] [G loss: 1.679334]\n",
      "epoch:6 step:4939 [D loss: 0.760960, acc: 43.75%] [G loss: 1.457520]\n",
      "epoch:6 step:4940 [D loss: 0.649173, acc: 57.03%] [G loss: 1.384930]\n",
      "epoch:6 step:4941 [D loss: 0.839203, acc: 30.47%] [G loss: 1.366392]\n",
      "epoch:6 step:4942 [D loss: 0.593791, acc: 77.34%] [G loss: 1.514362]\n",
      "epoch:6 step:4943 [D loss: 0.728904, acc: 44.53%] [G loss: 1.420015]\n",
      "epoch:6 step:4944 [D loss: 0.700706, acc: 46.88%] [G loss: 1.474775]\n",
      "epoch:6 step:4945 [D loss: 0.669094, acc: 59.38%] [G loss: 1.394409]\n",
      "epoch:6 step:4946 [D loss: 0.692003, acc: 54.69%] [G loss: 1.635845]\n",
      "epoch:6 step:4947 [D loss: 0.747280, acc: 42.19%] [G loss: 1.531856]\n",
      "epoch:6 step:4948 [D loss: 0.657522, acc: 66.41%] [G loss: 1.517070]\n",
      "epoch:6 step:4949 [D loss: 0.941357, acc: 31.25%] [G loss: 1.144675]\n",
      "epoch:6 step:4950 [D loss: 0.769086, acc: 32.81%] [G loss: 1.412381]\n",
      "epoch:6 step:4951 [D loss: 0.591026, acc: 75.78%] [G loss: 1.654522]\n",
      "epoch:6 step:4952 [D loss: 0.611317, acc: 64.06%] [G loss: 1.426081]\n",
      "epoch:6 step:4953 [D loss: 1.055083, acc: 14.06%] [G loss: 1.190677]\n",
      "epoch:6 step:4954 [D loss: 0.709413, acc: 53.91%] [G loss: 1.590644]\n",
      "epoch:6 step:4955 [D loss: 0.683404, acc: 55.47%] [G loss: 1.496756]\n",
      "epoch:6 step:4956 [D loss: 0.623845, acc: 64.84%] [G loss: 1.654435]\n",
      "epoch:6 step:4957 [D loss: 0.758030, acc: 36.72%] [G loss: 1.499292]\n",
      "epoch:6 step:4958 [D loss: 0.702727, acc: 52.34%] [G loss: 1.431468]\n",
      "epoch:6 step:4959 [D loss: 0.728380, acc: 48.44%] [G loss: 1.536973]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:6 step:4960 [D loss: 0.655351, acc: 53.12%] [G loss: 1.384654]\n",
      "epoch:6 step:4961 [D loss: 0.663085, acc: 59.38%] [G loss: 1.621112]\n",
      "epoch:6 step:4962 [D loss: 0.768369, acc: 36.72%] [G loss: 1.545730]\n",
      "epoch:6 step:4963 [D loss: 0.649320, acc: 60.94%] [G loss: 1.663749]\n",
      "epoch:6 step:4964 [D loss: 0.759844, acc: 41.41%] [G loss: 1.448556]\n",
      "epoch:6 step:4965 [D loss: 0.677157, acc: 54.69%] [G loss: 1.644675]\n",
      "epoch:6 step:4966 [D loss: 0.678247, acc: 60.16%] [G loss: 1.578893]\n",
      "epoch:6 step:4967 [D loss: 0.679245, acc: 56.25%] [G loss: 1.642012]\n",
      "epoch:6 step:4968 [D loss: 0.756362, acc: 39.06%] [G loss: 1.550948]\n",
      "epoch:6 step:4969 [D loss: 0.710371, acc: 52.34%] [G loss: 1.546001]\n",
      "epoch:6 step:4970 [D loss: 0.732615, acc: 47.66%] [G loss: 1.580065]\n",
      "epoch:6 step:4971 [D loss: 0.641211, acc: 62.50%] [G loss: 1.651062]\n",
      "epoch:6 step:4972 [D loss: 0.699590, acc: 53.91%] [G loss: 1.551317]\n",
      "epoch:6 step:4973 [D loss: 0.674970, acc: 60.16%] [G loss: 1.640942]\n",
      "epoch:6 step:4974 [D loss: 0.499403, acc: 72.66%] [G loss: 1.543189]\n",
      "epoch:6 step:4975 [D loss: 0.660217, acc: 60.94%] [G loss: 1.605527]\n",
      "epoch:6 step:4976 [D loss: 0.610191, acc: 72.66%] [G loss: 1.651194]\n",
      "epoch:6 step:4977 [D loss: 0.609877, acc: 59.38%] [G loss: 1.517442]\n",
      "epoch:6 step:4978 [D loss: 0.964767, acc: 14.06%] [G loss: 1.426729]\n",
      "epoch:6 step:4979 [D loss: 0.609791, acc: 66.41%] [G loss: 1.568131]\n",
      "epoch:6 step:4980 [D loss: 0.590003, acc: 73.44%] [G loss: 1.616475]\n",
      "epoch:6 step:4981 [D loss: 0.722355, acc: 53.91%] [G loss: 1.399191]\n",
      "epoch:6 step:4982 [D loss: 0.716738, acc: 50.00%] [G loss: 1.585468]\n",
      "epoch:6 step:4983 [D loss: 0.542842, acc: 71.88%] [G loss: 1.404566]\n",
      "epoch:6 step:4984 [D loss: 0.631788, acc: 61.72%] [G loss: 1.564968]\n",
      "epoch:6 step:4985 [D loss: 0.655403, acc: 64.06%] [G loss: 1.634804]\n",
      "epoch:6 step:4986 [D loss: 1.089669, acc: 8.59%] [G loss: 1.342319]\n",
      "epoch:6 step:4987 [D loss: 0.667541, acc: 60.16%] [G loss: 1.546505]\n",
      "epoch:6 step:4988 [D loss: 0.524120, acc: 85.94%] [G loss: 1.547500]\n",
      "epoch:6 step:4989 [D loss: 0.747848, acc: 49.22%] [G loss: 1.550773]\n",
      "epoch:6 step:4990 [D loss: 0.859910, acc: 32.81%] [G loss: 1.452925]\n",
      "epoch:6 step:4991 [D loss: 0.624293, acc: 66.41%] [G loss: 1.682463]\n",
      "epoch:6 step:4992 [D loss: 0.806243, acc: 44.53%] [G loss: 1.487239]\n",
      "epoch:6 step:4993 [D loss: 0.636846, acc: 67.19%] [G loss: 1.785074]\n",
      "epoch:6 step:4994 [D loss: 0.573061, acc: 71.88%] [G loss: 1.631578]\n",
      "epoch:6 step:4995 [D loss: 0.780198, acc: 36.72%] [G loss: 1.438455]\n",
      "epoch:6 step:4996 [D loss: 0.612497, acc: 64.84%] [G loss: 1.777504]\n",
      "epoch:6 step:4997 [D loss: 0.768861, acc: 42.97%] [G loss: 1.480724]\n",
      "epoch:6 step:4998 [D loss: 0.634945, acc: 60.94%] [G loss: 1.689818]\n",
      "epoch:6 step:4999 [D loss: 0.792266, acc: 40.62%] [G loss: 1.507143]\n",
      "epoch:6 step:5000 [D loss: 0.671443, acc: 60.94%] [G loss: 1.648495]\n",
      "##############\n",
      "[0.84388339 0.84538474 0.81544986 0.83662221 0.78868135 0.83539362\n",
      " 0.8868843  0.81289249 0.82530982 0.84469429]\n",
      "##########\n",
      "epoch:6 step:5001 [D loss: 1.023850, acc: 16.41%] [G loss: 1.539967]\n",
      "epoch:6 step:5002 [D loss: 0.511425, acc: 84.38%] [G loss: 1.890441]\n",
      "epoch:6 step:5003 [D loss: 0.720151, acc: 52.34%] [G loss: 1.611212]\n",
      "epoch:6 step:5004 [D loss: 0.607698, acc: 67.97%] [G loss: 1.568992]\n",
      "epoch:6 step:5005 [D loss: 0.699634, acc: 55.47%] [G loss: 1.529048]\n",
      "epoch:6 step:5006 [D loss: 0.761105, acc: 39.06%] [G loss: 1.576097]\n",
      "epoch:6 step:5007 [D loss: 0.549186, acc: 82.03%] [G loss: 1.676544]\n",
      "epoch:6 step:5008 [D loss: 0.662728, acc: 57.03%] [G loss: 1.467656]\n",
      "epoch:6 step:5009 [D loss: 0.735051, acc: 48.44%] [G loss: 1.564586]\n",
      "epoch:6 step:5010 [D loss: 0.603408, acc: 70.31%] [G loss: 1.697172]\n",
      "epoch:6 step:5011 [D loss: 0.577175, acc: 82.81%] [G loss: 1.769021]\n",
      "epoch:6 step:5012 [D loss: 0.659035, acc: 66.41%] [G loss: 1.595784]\n",
      "epoch:6 step:5013 [D loss: 0.705257, acc: 51.56%] [G loss: 1.803812]\n",
      "epoch:6 step:5014 [D loss: 0.767803, acc: 47.66%] [G loss: 1.490039]\n",
      "epoch:6 step:5015 [D loss: 0.808613, acc: 35.94%] [G loss: 1.391978]\n",
      "epoch:6 step:5016 [D loss: 0.845720, acc: 22.66%] [G loss: 1.415912]\n",
      "epoch:6 step:5017 [D loss: 0.770466, acc: 33.59%] [G loss: 1.500174]\n",
      "epoch:6 step:5018 [D loss: 0.592650, acc: 80.47%] [G loss: 1.554383]\n",
      "epoch:6 step:5019 [D loss: 0.688594, acc: 55.47%] [G loss: 1.474074]\n",
      "epoch:6 step:5020 [D loss: 0.641462, acc: 61.72%] [G loss: 1.639064]\n",
      "epoch:6 step:5021 [D loss: 0.766771, acc: 45.31%] [G loss: 1.589869]\n",
      "epoch:6 step:5022 [D loss: 0.650292, acc: 60.94%] [G loss: 1.717190]\n",
      "epoch:6 step:5023 [D loss: 0.819723, acc: 32.81%] [G loss: 1.456021]\n",
      "epoch:6 step:5024 [D loss: 0.973962, acc: 13.28%] [G loss: 1.517156]\n",
      "epoch:6 step:5025 [D loss: 0.741890, acc: 46.09%] [G loss: 1.493281]\n",
      "epoch:6 step:5026 [D loss: 0.727691, acc: 48.44%] [G loss: 1.660567]\n",
      "epoch:6 step:5027 [D loss: 0.671779, acc: 60.16%] [G loss: 1.535463]\n",
      "epoch:6 step:5028 [D loss: 0.652055, acc: 60.94%] [G loss: 1.662977]\n",
      "epoch:6 step:5029 [D loss: 0.641529, acc: 64.06%] [G loss: 1.459294]\n",
      "epoch:6 step:5030 [D loss: 0.646796, acc: 60.16%] [G loss: 1.921407]\n",
      "epoch:6 step:5031 [D loss: 0.698472, acc: 50.78%] [G loss: 1.706428]\n",
      "epoch:6 step:5032 [D loss: 0.708396, acc: 52.34%] [G loss: 1.669368]\n",
      "epoch:6 step:5033 [D loss: 0.674760, acc: 57.81%] [G loss: 1.547446]\n",
      "epoch:6 step:5034 [D loss: 0.788992, acc: 35.94%] [G loss: 1.438898]\n",
      "epoch:6 step:5035 [D loss: 0.514079, acc: 86.72%] [G loss: 1.714820]\n",
      "epoch:6 step:5036 [D loss: 0.785291, acc: 39.06%] [G loss: 1.650898]\n",
      "epoch:6 step:5037 [D loss: 0.738350, acc: 46.88%] [G loss: 1.493656]\n",
      "epoch:6 step:5038 [D loss: 0.706510, acc: 57.03%] [G loss: 1.582053]\n",
      "epoch:6 step:5039 [D loss: 0.769543, acc: 39.84%] [G loss: 1.457990]\n",
      "epoch:6 step:5040 [D loss: 0.652549, acc: 62.50%] [G loss: 1.523123]\n",
      "epoch:6 step:5041 [D loss: 0.820251, acc: 23.44%] [G loss: 1.480816]\n",
      "epoch:6 step:5042 [D loss: 0.659376, acc: 61.72%] [G loss: 1.551574]\n",
      "epoch:6 step:5043 [D loss: 0.687243, acc: 51.56%] [G loss: 1.470778]\n",
      "epoch:6 step:5044 [D loss: 0.752530, acc: 38.28%] [G loss: 1.464583]\n",
      "epoch:6 step:5045 [D loss: 0.807730, acc: 28.91%] [G loss: 1.473582]\n",
      "epoch:6 step:5046 [D loss: 0.760949, acc: 39.84%] [G loss: 1.511353]\n",
      "epoch:6 step:5047 [D loss: 0.773106, acc: 35.16%] [G loss: 1.553063]\n",
      "epoch:6 step:5048 [D loss: 0.568944, acc: 82.03%] [G loss: 1.572401]\n",
      "epoch:6 step:5049 [D loss: 0.604096, acc: 75.78%] [G loss: 1.692706]\n",
      "epoch:6 step:5050 [D loss: 0.713168, acc: 49.22%] [G loss: 1.642890]\n",
      "epoch:6 step:5051 [D loss: 0.747348, acc: 39.84%] [G loss: 1.611203]\n",
      "epoch:6 step:5052 [D loss: 0.816143, acc: 29.69%] [G loss: 1.498005]\n",
      "epoch:6 step:5053 [D loss: 0.655730, acc: 57.81%] [G loss: 1.557137]\n",
      "epoch:6 step:5054 [D loss: 0.781552, acc: 37.50%] [G loss: 1.455132]\n",
      "epoch:6 step:5055 [D loss: 0.696362, acc: 51.56%] [G loss: 1.472234]\n",
      "epoch:6 step:5056 [D loss: 0.521317, acc: 85.94%] [G loss: 1.683326]\n",
      "epoch:6 step:5057 [D loss: 0.684196, acc: 57.81%] [G loss: 1.519375]\n",
      "epoch:6 step:5058 [D loss: 0.628569, acc: 69.53%] [G loss: 1.551629]\n",
      "epoch:6 step:5059 [D loss: 0.831286, acc: 20.31%] [G loss: 1.419615]\n",
      "epoch:6 step:5060 [D loss: 0.781566, acc: 32.81%] [G loss: 1.537671]\n",
      "epoch:6 step:5061 [D loss: 0.846788, acc: 28.12%] [G loss: 1.472575]\n",
      "epoch:6 step:5062 [D loss: 0.729786, acc: 46.88%] [G loss: 1.566362]\n",
      "epoch:6 step:5063 [D loss: 0.650925, acc: 65.62%] [G loss: 1.578786]\n",
      "epoch:6 step:5064 [D loss: 0.700052, acc: 56.25%] [G loss: 1.529717]\n",
      "epoch:6 step:5065 [D loss: 0.695525, acc: 52.34%] [G loss: 1.604281]\n",
      "epoch:6 step:5066 [D loss: 0.705128, acc: 50.00%] [G loss: 1.610378]\n",
      "epoch:6 step:5067 [D loss: 0.689371, acc: 50.78%] [G loss: 1.570054]\n",
      "epoch:6 step:5068 [D loss: 0.605330, acc: 74.22%] [G loss: 1.503723]\n",
      "epoch:6 step:5069 [D loss: 0.675571, acc: 53.91%] [G loss: 1.507807]\n",
      "epoch:6 step:5070 [D loss: 0.704605, acc: 48.44%] [G loss: 1.625838]\n",
      "epoch:6 step:5071 [D loss: 0.761233, acc: 35.16%] [G loss: 1.482214]\n",
      "epoch:6 step:5072 [D loss: 0.671760, acc: 53.91%] [G loss: 1.628360]\n",
      "epoch:6 step:5073 [D loss: 0.758422, acc: 38.28%] [G loss: 1.414952]\n",
      "epoch:6 step:5074 [D loss: 0.674413, acc: 54.69%] [G loss: 1.455511]\n",
      "epoch:6 step:5075 [D loss: 0.687651, acc: 56.25%] [G loss: 1.460255]\n",
      "epoch:6 step:5076 [D loss: 0.771844, acc: 42.19%] [G loss: 1.436885]\n",
      "epoch:6 step:5077 [D loss: 0.778624, acc: 42.19%] [G loss: 1.360224]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:6 step:5078 [D loss: 0.665270, acc: 57.81%] [G loss: 1.516946]\n",
      "epoch:6 step:5079 [D loss: 0.689792, acc: 56.25%] [G loss: 1.413235]\n",
      "epoch:6 step:5080 [D loss: 0.701060, acc: 53.12%] [G loss: 1.533285]\n",
      "epoch:6 step:5081 [D loss: 0.592829, acc: 76.56%] [G loss: 1.616646]\n",
      "epoch:6 step:5082 [D loss: 0.666286, acc: 58.59%] [G loss: 1.731590]\n",
      "epoch:6 step:5083 [D loss: 0.750710, acc: 38.28%] [G loss: 1.431363]\n",
      "epoch:6 step:5084 [D loss: 0.684857, acc: 55.47%] [G loss: 1.546862]\n",
      "epoch:6 step:5085 [D loss: 0.623741, acc: 64.06%] [G loss: 1.483739]\n",
      "epoch:6 step:5086 [D loss: 0.579861, acc: 75.78%] [G loss: 1.529948]\n",
      "epoch:6 step:5087 [D loss: 0.722801, acc: 56.25%] [G loss: 1.525834]\n",
      "epoch:6 step:5088 [D loss: 0.665392, acc: 63.28%] [G loss: 1.596732]\n",
      "epoch:6 step:5089 [D loss: 0.585409, acc: 74.22%] [G loss: 1.550652]\n",
      "epoch:6 step:5090 [D loss: 0.747683, acc: 45.31%] [G loss: 1.505779]\n",
      "epoch:6 step:5091 [D loss: 0.668888, acc: 56.25%] [G loss: 1.755282]\n",
      "epoch:6 step:5092 [D loss: 0.674258, acc: 54.69%] [G loss: 1.689375]\n",
      "epoch:6 step:5093 [D loss: 0.773744, acc: 40.62%] [G loss: 1.526181]\n",
      "epoch:6 step:5094 [D loss: 0.720751, acc: 42.97%] [G loss: 1.488536]\n",
      "epoch:6 step:5095 [D loss: 0.563308, acc: 81.25%] [G loss: 1.697068]\n",
      "epoch:6 step:5096 [D loss: 0.630716, acc: 70.31%] [G loss: 1.709295]\n",
      "epoch:6 step:5097 [D loss: 0.817318, acc: 31.25%] [G loss: 1.601834]\n",
      "epoch:6 step:5098 [D loss: 0.576746, acc: 71.88%] [G loss: 1.694735]\n",
      "epoch:6 step:5099 [D loss: 0.716998, acc: 49.22%] [G loss: 1.616243]\n",
      "epoch:6 step:5100 [D loss: 0.860386, acc: 25.78%] [G loss: 1.364036]\n",
      "epoch:6 step:5101 [D loss: 0.693415, acc: 55.47%] [G loss: 1.656563]\n",
      "epoch:6 step:5102 [D loss: 0.700266, acc: 53.12%] [G loss: 1.635357]\n",
      "epoch:6 step:5103 [D loss: 0.668453, acc: 58.59%] [G loss: 1.595881]\n",
      "epoch:6 step:5104 [D loss: 0.671434, acc: 57.03%] [G loss: 1.538921]\n",
      "epoch:6 step:5105 [D loss: 0.694694, acc: 55.47%] [G loss: 1.549225]\n",
      "epoch:6 step:5106 [D loss: 0.781600, acc: 38.28%] [G loss: 1.570763]\n",
      "epoch:6 step:5107 [D loss: 0.786728, acc: 37.50%] [G loss: 1.449434]\n",
      "epoch:6 step:5108 [D loss: 0.693772, acc: 53.12%] [G loss: 1.623880]\n",
      "epoch:6 step:5109 [D loss: 0.694430, acc: 55.47%] [G loss: 1.636266]\n",
      "epoch:6 step:5110 [D loss: 0.579382, acc: 77.34%] [G loss: 1.608224]\n",
      "epoch:6 step:5111 [D loss: 0.589216, acc: 77.34%] [G loss: 1.639809]\n",
      "epoch:6 step:5112 [D loss: 0.613310, acc: 70.31%] [G loss: 1.649412]\n",
      "epoch:6 step:5113 [D loss: 0.539359, acc: 71.09%] [G loss: 1.524022]\n",
      "epoch:6 step:5114 [D loss: 0.820155, acc: 27.34%] [G loss: 1.583076]\n",
      "epoch:6 step:5115 [D loss: 0.615395, acc: 68.75%] [G loss: 1.507435]\n",
      "epoch:6 step:5116 [D loss: 0.845208, acc: 30.47%] [G loss: 1.290162]\n",
      "epoch:6 step:5117 [D loss: 0.772937, acc: 32.81%] [G loss: 1.316592]\n",
      "epoch:6 step:5118 [D loss: 0.859114, acc: 28.91%] [G loss: 1.358731]\n",
      "epoch:6 step:5119 [D loss: 0.715269, acc: 48.44%] [G loss: 1.630745]\n",
      "epoch:6 step:5120 [D loss: 0.622994, acc: 68.75%] [G loss: 1.517177]\n",
      "epoch:6 step:5121 [D loss: 0.719364, acc: 45.31%] [G loss: 1.571238]\n",
      "epoch:6 step:5122 [D loss: 0.750308, acc: 37.50%] [G loss: 1.479549]\n",
      "epoch:6 step:5123 [D loss: 0.675227, acc: 63.28%] [G loss: 1.573144]\n",
      "epoch:6 step:5124 [D loss: 0.611817, acc: 53.91%] [G loss: 1.460026]\n",
      "epoch:6 step:5125 [D loss: 0.735657, acc: 46.09%] [G loss: 1.516956]\n",
      "epoch:6 step:5126 [D loss: 0.622776, acc: 69.53%] [G loss: 1.489203]\n",
      "epoch:6 step:5127 [D loss: 0.703456, acc: 54.69%] [G loss: 1.613867]\n",
      "epoch:6 step:5128 [D loss: 0.766300, acc: 42.97%] [G loss: 1.574130]\n",
      "epoch:6 step:5129 [D loss: 0.627785, acc: 67.97%] [G loss: 1.581276]\n",
      "epoch:6 step:5130 [D loss: 0.722646, acc: 47.66%] [G loss: 1.628622]\n",
      "epoch:6 step:5131 [D loss: 0.732792, acc: 48.44%] [G loss: 1.471478]\n",
      "epoch:6 step:5132 [D loss: 0.676598, acc: 52.34%] [G loss: 1.648418]\n",
      "epoch:6 step:5133 [D loss: 0.679267, acc: 53.12%] [G loss: 1.679034]\n",
      "epoch:6 step:5134 [D loss: 0.678423, acc: 55.47%] [G loss: 1.820120]\n",
      "epoch:6 step:5135 [D loss: 0.650004, acc: 62.50%] [G loss: 1.589157]\n",
      "epoch:6 step:5136 [D loss: 0.698287, acc: 53.91%] [G loss: 1.750696]\n",
      "epoch:6 step:5137 [D loss: 0.707756, acc: 53.12%] [G loss: 1.778359]\n",
      "epoch:6 step:5138 [D loss: 0.716534, acc: 43.75%] [G loss: 1.563016]\n",
      "epoch:6 step:5139 [D loss: 0.619668, acc: 64.06%] [G loss: 1.772115]\n",
      "epoch:6 step:5140 [D loss: 0.738270, acc: 49.22%] [G loss: 1.602502]\n",
      "epoch:6 step:5141 [D loss: 0.729334, acc: 48.44%] [G loss: 1.550847]\n",
      "epoch:6 step:5142 [D loss: 0.759931, acc: 46.09%] [G loss: 1.494359]\n",
      "epoch:6 step:5143 [D loss: 0.777593, acc: 33.59%] [G loss: 1.435783]\n",
      "epoch:6 step:5144 [D loss: 0.663391, acc: 62.50%] [G loss: 1.549999]\n",
      "epoch:6 step:5145 [D loss: 0.556251, acc: 78.12%] [G loss: 1.889199]\n",
      "epoch:6 step:5146 [D loss: 0.732515, acc: 50.78%] [G loss: 1.631140]\n",
      "epoch:6 step:5147 [D loss: 0.649909, acc: 58.59%] [G loss: 1.461940]\n",
      "epoch:6 step:5148 [D loss: 0.640937, acc: 68.75%] [G loss: 1.439668]\n",
      "epoch:6 step:5149 [D loss: 0.759368, acc: 35.94%] [G loss: 1.535804]\n",
      "epoch:6 step:5150 [D loss: 0.589397, acc: 77.34%] [G loss: 1.668385]\n",
      "epoch:6 step:5151 [D loss: 0.753951, acc: 42.19%] [G loss: 1.372337]\n",
      "epoch:6 step:5152 [D loss: 0.706867, acc: 52.34%] [G loss: 1.779186]\n",
      "epoch:6 step:5153 [D loss: 0.750563, acc: 46.09%] [G loss: 1.521685]\n",
      "epoch:6 step:5154 [D loss: 0.776846, acc: 30.47%] [G loss: 1.432025]\n",
      "epoch:6 step:5155 [D loss: 0.607544, acc: 76.56%] [G loss: 1.543427]\n",
      "epoch:6 step:5156 [D loss: 0.725770, acc: 49.22%] [G loss: 1.459251]\n",
      "epoch:6 step:5157 [D loss: 0.831939, acc: 24.22%] [G loss: 1.459256]\n",
      "epoch:6 step:5158 [D loss: 0.759574, acc: 45.31%] [G loss: 1.478593]\n",
      "epoch:6 step:5159 [D loss: 0.783350, acc: 34.38%] [G loss: 1.476334]\n",
      "epoch:6 step:5160 [D loss: 0.599271, acc: 66.41%] [G loss: 1.447649]\n",
      "epoch:6 step:5161 [D loss: 0.665481, acc: 65.62%] [G loss: 1.638295]\n",
      "epoch:6 step:5162 [D loss: 0.717487, acc: 51.56%] [G loss: 1.630897]\n",
      "epoch:6 step:5163 [D loss: 0.668784, acc: 61.72%] [G loss: 1.519897]\n",
      "epoch:6 step:5164 [D loss: 0.606321, acc: 67.19%] [G loss: 1.713234]\n",
      "epoch:6 step:5165 [D loss: 0.783128, acc: 35.16%] [G loss: 1.528508]\n",
      "epoch:6 step:5166 [D loss: 0.807629, acc: 28.12%] [G loss: 1.409711]\n",
      "epoch:6 step:5167 [D loss: 0.916973, acc: 26.56%] [G loss: 1.451032]\n",
      "epoch:6 step:5168 [D loss: 0.778892, acc: 35.16%] [G loss: 1.601149]\n",
      "epoch:6 step:5169 [D loss: 0.675935, acc: 63.28%] [G loss: 1.534646]\n",
      "epoch:6 step:5170 [D loss: 0.652376, acc: 62.50%] [G loss: 1.625873]\n",
      "epoch:6 step:5171 [D loss: 0.761635, acc: 39.84%] [G loss: 1.583916]\n",
      "epoch:6 step:5172 [D loss: 0.716970, acc: 56.25%] [G loss: 1.633232]\n",
      "epoch:6 step:5173 [D loss: 0.644100, acc: 62.50%] [G loss: 1.581215]\n",
      "epoch:6 step:5174 [D loss: 0.604468, acc: 62.50%] [G loss: 1.727764]\n",
      "epoch:6 step:5175 [D loss: 0.564947, acc: 75.00%] [G loss: 1.657660]\n",
      "epoch:6 step:5176 [D loss: 0.735291, acc: 50.00%] [G loss: 1.491958]\n",
      "epoch:6 step:5177 [D loss: 0.809261, acc: 32.81%] [G loss: 1.486213]\n",
      "epoch:6 step:5178 [D loss: 0.782011, acc: 32.03%] [G loss: 1.397845]\n",
      "epoch:6 step:5179 [D loss: 0.739625, acc: 44.53%] [G loss: 1.528255]\n",
      "epoch:6 step:5180 [D loss: 0.741975, acc: 41.41%] [G loss: 1.447081]\n",
      "epoch:6 step:5181 [D loss: 0.614807, acc: 73.44%] [G loss: 1.626499]\n",
      "epoch:6 step:5182 [D loss: 0.696533, acc: 46.88%] [G loss: 1.548159]\n",
      "epoch:6 step:5183 [D loss: 0.671892, acc: 56.25%] [G loss: 1.583666]\n",
      "epoch:6 step:5184 [D loss: 0.674334, acc: 62.50%] [G loss: 1.670279]\n",
      "epoch:6 step:5185 [D loss: 0.853313, acc: 31.25%] [G loss: 1.505790]\n",
      "epoch:6 step:5186 [D loss: 0.783633, acc: 38.28%] [G loss: 1.538923]\n",
      "epoch:6 step:5187 [D loss: 0.672607, acc: 63.28%] [G loss: 1.698387]\n",
      "epoch:6 step:5188 [D loss: 0.665225, acc: 55.47%] [G loss: 1.567706]\n",
      "epoch:6 step:5189 [D loss: 0.653312, acc: 63.28%] [G loss: 1.641658]\n",
      "epoch:6 step:5190 [D loss: 0.590812, acc: 70.31%] [G loss: 1.524085]\n",
      "epoch:6 step:5191 [D loss: 0.826151, acc: 26.56%] [G loss: 1.529830]\n",
      "epoch:6 step:5192 [D loss: 0.425361, acc: 90.62%] [G loss: 1.654090]\n",
      "epoch:6 step:5193 [D loss: 0.733722, acc: 47.66%] [G loss: 1.617248]\n",
      "epoch:6 step:5194 [D loss: 0.674301, acc: 59.38%] [G loss: 1.683755]\n",
      "epoch:6 step:5195 [D loss: 0.755791, acc: 42.97%] [G loss: 1.556787]\n",
      "epoch:6 step:5196 [D loss: 0.771216, acc: 39.84%] [G loss: 1.490963]\n",
      "epoch:6 step:5197 [D loss: 0.706759, acc: 50.00%] [G loss: 1.489959]\n",
      "epoch:6 step:5198 [D loss: 0.644592, acc: 57.03%] [G loss: 1.630016]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:6 step:5199 [D loss: 0.694014, acc: 58.59%] [G loss: 1.572760]\n",
      "epoch:6 step:5200 [D loss: 0.744589, acc: 40.62%] [G loss: 1.559916]\n",
      "##############\n",
      "[0.86510255 0.86582203 0.80224384 0.83259266 0.78286452 0.80812773\n",
      " 0.86696254 0.84088058 0.82785497 0.84074379]\n",
      "##########\n",
      "epoch:6 step:5201 [D loss: 0.768778, acc: 36.72%] [G loss: 1.466667]\n",
      "epoch:6 step:5202 [D loss: 0.682475, acc: 61.72%] [G loss: 1.644797]\n",
      "epoch:6 step:5203 [D loss: 0.758510, acc: 39.06%] [G loss: 1.528027]\n",
      "epoch:6 step:5204 [D loss: 0.669393, acc: 57.03%] [G loss: 1.497017]\n",
      "epoch:6 step:5205 [D loss: 0.833360, acc: 30.47%] [G loss: 1.331749]\n",
      "epoch:6 step:5206 [D loss: 0.687189, acc: 52.34%] [G loss: 1.517349]\n",
      "epoch:6 step:5207 [D loss: 0.711310, acc: 55.47%] [G loss: 1.554916]\n",
      "epoch:6 step:5208 [D loss: 0.672520, acc: 59.38%] [G loss: 1.561929]\n",
      "epoch:6 step:5209 [D loss: 0.686906, acc: 53.12%] [G loss: 1.605051]\n",
      "epoch:6 step:5210 [D loss: 0.696110, acc: 54.69%] [G loss: 1.614412]\n",
      "epoch:6 step:5211 [D loss: 0.594265, acc: 68.75%] [G loss: 1.573853]\n",
      "epoch:6 step:5212 [D loss: 0.675222, acc: 57.03%] [G loss: 1.600376]\n",
      "epoch:6 step:5213 [D loss: 0.680225, acc: 58.59%] [G loss: 1.511396]\n",
      "epoch:6 step:5214 [D loss: 0.645208, acc: 62.50%] [G loss: 1.537558]\n",
      "epoch:6 step:5215 [D loss: 0.641170, acc: 64.84%] [G loss: 1.492216]\n",
      "epoch:6 step:5216 [D loss: 0.655106, acc: 60.94%] [G loss: 1.392648]\n",
      "epoch:6 step:5217 [D loss: 0.570755, acc: 80.47%] [G loss: 1.398291]\n",
      "epoch:6 step:5218 [D loss: 0.704822, acc: 51.56%] [G loss: 1.612800]\n",
      "epoch:6 step:5219 [D loss: 0.604638, acc: 71.09%] [G loss: 1.440085]\n",
      "epoch:6 step:5220 [D loss: 0.715753, acc: 53.12%] [G loss: 1.381425]\n",
      "epoch:6 step:5221 [D loss: 0.776356, acc: 41.41%] [G loss: 1.480693]\n",
      "epoch:6 step:5222 [D loss: 0.858520, acc: 23.44%] [G loss: 1.208925]\n",
      "epoch:6 step:5223 [D loss: 0.529772, acc: 78.91%] [G loss: 1.621620]\n",
      "epoch:6 step:5224 [D loss: 0.905285, acc: 17.19%] [G loss: 1.352128]\n",
      "epoch:6 step:5225 [D loss: 0.732719, acc: 43.75%] [G loss: 1.310885]\n",
      "epoch:6 step:5226 [D loss: 0.866185, acc: 23.44%] [G loss: 1.464164]\n",
      "epoch:6 step:5227 [D loss: 0.681171, acc: 48.44%] [G loss: 1.650858]\n",
      "epoch:6 step:5228 [D loss: 0.593604, acc: 71.88%] [G loss: 1.664721]\n",
      "epoch:6 step:5229 [D loss: 0.594591, acc: 71.09%] [G loss: 1.743837]\n",
      "epoch:6 step:5230 [D loss: 0.727645, acc: 46.09%] [G loss: 1.661443]\n",
      "epoch:6 step:5231 [D loss: 0.694815, acc: 50.78%] [G loss: 1.717651]\n",
      "epoch:6 step:5232 [D loss: 0.766772, acc: 37.50%] [G loss: 1.714117]\n",
      "epoch:6 step:5233 [D loss: 0.713617, acc: 52.34%] [G loss: 1.600819]\n",
      "epoch:6 step:5234 [D loss: 0.677057, acc: 56.25%] [G loss: 1.697659]\n",
      "epoch:6 step:5235 [D loss: 0.704067, acc: 54.69%] [G loss: 1.620455]\n",
      "epoch:6 step:5236 [D loss: 0.591016, acc: 73.44%] [G loss: 1.916957]\n",
      "epoch:6 step:5237 [D loss: 0.579335, acc: 73.44%] [G loss: 1.809925]\n",
      "epoch:6 step:5238 [D loss: 0.803793, acc: 35.16%] [G loss: 1.321487]\n",
      "epoch:6 step:5239 [D loss: 0.822292, acc: 25.78%] [G loss: 1.353917]\n",
      "epoch:6 step:5240 [D loss: 0.651004, acc: 62.50%] [G loss: 1.502468]\n",
      "epoch:6 step:5241 [D loss: 0.731396, acc: 46.88%] [G loss: 1.446004]\n",
      "epoch:6 step:5242 [D loss: 0.738392, acc: 45.31%] [G loss: 1.455024]\n",
      "epoch:6 step:5243 [D loss: 0.671993, acc: 56.25%] [G loss: 1.726317]\n",
      "epoch:6 step:5244 [D loss: 0.804208, acc: 23.44%] [G loss: 1.511285]\n",
      "epoch:6 step:5245 [D loss: 0.646044, acc: 67.97%] [G loss: 1.431644]\n",
      "epoch:6 step:5246 [D loss: 0.753683, acc: 45.31%] [G loss: 1.536760]\n",
      "epoch:6 step:5247 [D loss: 0.651896, acc: 60.16%] [G loss: 1.510719]\n",
      "epoch:6 step:5248 [D loss: 0.668994, acc: 60.94%] [G loss: 1.515924]\n",
      "epoch:6 step:5249 [D loss: 0.777412, acc: 30.47%] [G loss: 1.466262]\n",
      "epoch:6 step:5250 [D loss: 0.662057, acc: 53.91%] [G loss: 1.502527]\n",
      "epoch:6 step:5251 [D loss: 0.727155, acc: 48.44%] [G loss: 1.452829]\n",
      "epoch:6 step:5252 [D loss: 0.755239, acc: 40.62%] [G loss: 1.467858]\n",
      "epoch:6 step:5253 [D loss: 0.829359, acc: 34.38%] [G loss: 1.599041]\n",
      "epoch:6 step:5254 [D loss: 0.766235, acc: 51.56%] [G loss: 1.635246]\n",
      "epoch:6 step:5255 [D loss: 0.765361, acc: 42.97%] [G loss: 1.487172]\n",
      "epoch:6 step:5256 [D loss: 0.672732, acc: 57.03%] [G loss: 1.624396]\n",
      "epoch:6 step:5257 [D loss: 0.691334, acc: 56.25%] [G loss: 1.542747]\n",
      "epoch:6 step:5258 [D loss: 0.716542, acc: 47.66%] [G loss: 1.697873]\n",
      "epoch:6 step:5259 [D loss: 0.709833, acc: 53.91%] [G loss: 1.556210]\n",
      "epoch:6 step:5260 [D loss: 0.769703, acc: 34.38%] [G loss: 1.458688]\n",
      "epoch:6 step:5261 [D loss: 0.768635, acc: 36.72%] [G loss: 1.555081]\n",
      "epoch:6 step:5262 [D loss: 0.686412, acc: 54.69%] [G loss: 1.778605]\n",
      "epoch:6 step:5263 [D loss: 0.529171, acc: 80.47%] [G loss: 1.934844]\n",
      "epoch:6 step:5264 [D loss: 0.644621, acc: 61.72%] [G loss: 1.739291]\n",
      "epoch:6 step:5265 [D loss: 0.719265, acc: 47.66%] [G loss: 1.681954]\n",
      "epoch:6 step:5266 [D loss: 0.686216, acc: 57.03%] [G loss: 1.635083]\n",
      "epoch:6 step:5267 [D loss: 0.625703, acc: 67.19%] [G loss: 1.918068]\n",
      "epoch:6 step:5268 [D loss: 0.706542, acc: 47.66%] [G loss: 1.538745]\n",
      "epoch:6 step:5269 [D loss: 0.547143, acc: 80.47%] [G loss: 1.588374]\n",
      "epoch:6 step:5270 [D loss: 0.753277, acc: 38.28%] [G loss: 1.498771]\n",
      "epoch:6 step:5271 [D loss: 0.714274, acc: 45.31%] [G loss: 1.610114]\n",
      "epoch:6 step:5272 [D loss: 0.622667, acc: 67.19%] [G loss: 1.522889]\n",
      "epoch:6 step:5273 [D loss: 0.635392, acc: 64.06%] [G loss: 1.648325]\n",
      "epoch:6 step:5274 [D loss: 0.758258, acc: 42.97%] [G loss: 1.451413]\n",
      "epoch:6 step:5275 [D loss: 0.822991, acc: 30.47%] [G loss: 1.567544]\n",
      "epoch:6 step:5276 [D loss: 0.687112, acc: 54.69%] [G loss: 1.490177]\n",
      "epoch:6 step:5277 [D loss: 0.654807, acc: 59.38%] [G loss: 1.560544]\n",
      "epoch:6 step:5278 [D loss: 0.644083, acc: 64.06%] [G loss: 1.678194]\n",
      "epoch:6 step:5279 [D loss: 0.783702, acc: 33.59%] [G loss: 1.458094]\n",
      "epoch:6 step:5280 [D loss: 0.697958, acc: 49.22%] [G loss: 1.557093]\n",
      "epoch:6 step:5281 [D loss: 0.654579, acc: 60.94%] [G loss: 1.633913]\n",
      "epoch:6 step:5282 [D loss: 0.678516, acc: 57.81%] [G loss: 1.616019]\n",
      "epoch:6 step:5283 [D loss: 0.830940, acc: 26.56%] [G loss: 1.416229]\n",
      "epoch:6 step:5284 [D loss: 0.663700, acc: 59.38%] [G loss: 1.432608]\n",
      "epoch:6 step:5285 [D loss: 0.684315, acc: 53.91%] [G loss: 1.615241]\n",
      "epoch:6 step:5286 [D loss: 0.786519, acc: 35.16%] [G loss: 1.607757]\n",
      "epoch:6 step:5287 [D loss: 0.641028, acc: 64.84%] [G loss: 1.515776]\n",
      "epoch:6 step:5288 [D loss: 0.591019, acc: 74.22%] [G loss: 1.741068]\n",
      "epoch:6 step:5289 [D loss: 0.754086, acc: 39.06%] [G loss: 1.451050]\n",
      "epoch:6 step:5290 [D loss: 0.762014, acc: 40.62%] [G loss: 1.627951]\n",
      "epoch:6 step:5291 [D loss: 0.785638, acc: 33.59%] [G loss: 1.544444]\n",
      "epoch:6 step:5292 [D loss: 0.691906, acc: 57.81%] [G loss: 1.689332]\n",
      "epoch:6 step:5293 [D loss: 0.702369, acc: 56.25%] [G loss: 1.620844]\n",
      "epoch:6 step:5294 [D loss: 0.684346, acc: 60.94%] [G loss: 1.533795]\n",
      "epoch:6 step:5295 [D loss: 0.674832, acc: 58.59%] [G loss: 1.618498]\n",
      "epoch:6 step:5296 [D loss: 0.660217, acc: 61.72%] [G loss: 1.676155]\n",
      "epoch:6 step:5297 [D loss: 0.655901, acc: 59.38%] [G loss: 1.562027]\n",
      "epoch:6 step:5298 [D loss: 0.715769, acc: 53.91%] [G loss: 1.443926]\n",
      "epoch:6 step:5299 [D loss: 0.687394, acc: 57.03%] [G loss: 1.537994]\n",
      "epoch:6 step:5300 [D loss: 0.730533, acc: 44.53%] [G loss: 1.456208]\n",
      "epoch:6 step:5301 [D loss: 0.719145, acc: 49.22%] [G loss: 1.491369]\n",
      "epoch:6 step:5302 [D loss: 0.743835, acc: 39.06%] [G loss: 1.464107]\n",
      "epoch:6 step:5303 [D loss: 0.800248, acc: 32.03%] [G loss: 1.493737]\n",
      "epoch:6 step:5304 [D loss: 0.724802, acc: 46.09%] [G loss: 1.435898]\n",
      "epoch:6 step:5305 [D loss: 0.670056, acc: 59.38%] [G loss: 1.578061]\n",
      "epoch:6 step:5306 [D loss: 0.692573, acc: 57.03%] [G loss: 1.518832]\n",
      "epoch:6 step:5307 [D loss: 0.719815, acc: 46.09%] [G loss: 1.463342]\n",
      "epoch:6 step:5308 [D loss: 0.725640, acc: 45.31%] [G loss: 1.590207]\n",
      "epoch:6 step:5309 [D loss: 0.508739, acc: 80.47%] [G loss: 1.725635]\n",
      "epoch:6 step:5310 [D loss: 0.654296, acc: 62.50%] [G loss: 1.543913]\n",
      "epoch:6 step:5311 [D loss: 0.742569, acc: 50.78%] [G loss: 1.469596]\n",
      "epoch:6 step:5312 [D loss: 0.705893, acc: 56.25%] [G loss: 1.593548]\n",
      "epoch:6 step:5313 [D loss: 0.711843, acc: 50.78%] [G loss: 1.560011]\n",
      "epoch:6 step:5314 [D loss: 0.779181, acc: 34.38%] [G loss: 1.479612]\n",
      "epoch:6 step:5315 [D loss: 0.577985, acc: 78.12%] [G loss: 1.558598]\n",
      "epoch:6 step:5316 [D loss: 0.769393, acc: 38.28%] [G loss: 1.396095]\n",
      "epoch:6 step:5317 [D loss: 0.580733, acc: 75.78%] [G loss: 1.569897]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:6 step:5318 [D loss: 0.682055, acc: 57.81%] [G loss: 1.659323]\n",
      "epoch:6 step:5319 [D loss: 0.725132, acc: 47.66%] [G loss: 1.488875]\n",
      "epoch:6 step:5320 [D loss: 0.588557, acc: 69.53%] [G loss: 1.498357]\n",
      "epoch:6 step:5321 [D loss: 0.753107, acc: 40.62%] [G loss: 1.615091]\n",
      "epoch:6 step:5322 [D loss: 0.577418, acc: 72.66%] [G loss: 1.885643]\n",
      "epoch:6 step:5323 [D loss: 0.895367, acc: 20.31%] [G loss: 1.394762]\n",
      "epoch:6 step:5324 [D loss: 0.534615, acc: 76.56%] [G loss: 1.717891]\n",
      "epoch:6 step:5325 [D loss: 0.628212, acc: 63.28%] [G loss: 1.641706]\n",
      "epoch:6 step:5326 [D loss: 0.747481, acc: 46.88%] [G loss: 1.570572]\n",
      "epoch:6 step:5327 [D loss: 0.710552, acc: 46.09%] [G loss: 1.501697]\n",
      "epoch:6 step:5328 [D loss: 0.601222, acc: 72.66%] [G loss: 1.532568]\n",
      "epoch:6 step:5329 [D loss: 0.601559, acc: 75.78%] [G loss: 1.746579]\n",
      "epoch:6 step:5330 [D loss: 0.673321, acc: 56.25%] [G loss: 1.547296]\n",
      "epoch:6 step:5331 [D loss: 0.800096, acc: 39.06%] [G loss: 1.514051]\n",
      "epoch:6 step:5332 [D loss: 0.691509, acc: 50.78%] [G loss: 1.665565]\n",
      "epoch:6 step:5333 [D loss: 0.719964, acc: 50.78%] [G loss: 1.531247]\n",
      "epoch:6 step:5334 [D loss: 0.763625, acc: 42.97%] [G loss: 1.643387]\n",
      "epoch:6 step:5335 [D loss: 0.693965, acc: 57.81%] [G loss: 1.893818]\n",
      "epoch:6 step:5336 [D loss: 0.693145, acc: 60.16%] [G loss: 1.724559]\n",
      "epoch:6 step:5337 [D loss: 0.586227, acc: 74.22%] [G loss: 1.750077]\n",
      "epoch:6 step:5338 [D loss: 0.743268, acc: 39.84%] [G loss: 1.438893]\n",
      "epoch:6 step:5339 [D loss: 0.660873, acc: 64.06%] [G loss: 1.774636]\n",
      "epoch:6 step:5340 [D loss: 0.643445, acc: 63.28%] [G loss: 1.861077]\n",
      "epoch:6 step:5341 [D loss: 0.657144, acc: 60.16%] [G loss: 1.781701]\n",
      "epoch:6 step:5342 [D loss: 0.809254, acc: 33.59%] [G loss: 1.409042]\n",
      "epoch:6 step:5343 [D loss: 0.774307, acc: 39.84%] [G loss: 1.945457]\n",
      "epoch:6 step:5344 [D loss: 0.688724, acc: 61.72%] [G loss: 1.745543]\n",
      "epoch:6 step:5345 [D loss: 0.615575, acc: 74.22%] [G loss: 1.867246]\n",
      "epoch:6 step:5346 [D loss: 0.800507, acc: 35.94%] [G loss: 1.580085]\n",
      "epoch:6 step:5347 [D loss: 0.719480, acc: 48.44%] [G loss: 1.563511]\n",
      "epoch:6 step:5348 [D loss: 0.523464, acc: 78.91%] [G loss: 1.874337]\n",
      "epoch:6 step:5349 [D loss: 0.660731, acc: 58.59%] [G loss: 1.718732]\n",
      "epoch:6 step:5350 [D loss: 0.437023, acc: 88.28%] [G loss: 1.830626]\n",
      "epoch:6 step:5351 [D loss: 0.712006, acc: 48.44%] [G loss: 1.690124]\n",
      "epoch:6 step:5352 [D loss: 0.434505, acc: 86.72%] [G loss: 1.554533]\n",
      "epoch:6 step:5353 [D loss: 0.596358, acc: 71.09%] [G loss: 1.470756]\n",
      "epoch:6 step:5354 [D loss: 0.765779, acc: 46.88%] [G loss: 1.719377]\n",
      "epoch:6 step:5355 [D loss: 0.891941, acc: 27.34%] [G loss: 1.311507]\n",
      "epoch:6 step:5356 [D loss: 0.640939, acc: 57.81%] [G loss: 1.676510]\n",
      "epoch:6 step:5357 [D loss: 0.605741, acc: 71.09%] [G loss: 1.503558]\n",
      "epoch:6 step:5358 [D loss: 0.716366, acc: 51.56%] [G loss: 1.507987]\n",
      "epoch:6 step:5359 [D loss: 0.754091, acc: 44.53%] [G loss: 1.502787]\n",
      "epoch:6 step:5360 [D loss: 0.794806, acc: 51.56%] [G loss: 1.721967]\n",
      "epoch:6 step:5361 [D loss: 0.461801, acc: 90.62%] [G loss: 2.098186]\n",
      "epoch:6 step:5362 [D loss: 0.684150, acc: 55.47%] [G loss: 1.488951]\n",
      "epoch:6 step:5363 [D loss: 0.716434, acc: 46.88%] [G loss: 1.938193]\n",
      "epoch:6 step:5364 [D loss: 0.451501, acc: 91.41%] [G loss: 1.562617]\n",
      "epoch:6 step:5365 [D loss: 0.743049, acc: 42.97%] [G loss: 1.507244]\n",
      "epoch:6 step:5366 [D loss: 0.579050, acc: 73.44%] [G loss: 1.855858]\n",
      "epoch:6 step:5367 [D loss: 0.668906, acc: 63.28%] [G loss: 1.717050]\n",
      "epoch:6 step:5368 [D loss: 0.811356, acc: 39.06%] [G loss: 1.746004]\n",
      "epoch:6 step:5369 [D loss: 0.718286, acc: 50.78%] [G loss: 1.562688]\n",
      "epoch:6 step:5370 [D loss: 0.758695, acc: 50.00%] [G loss: 2.015546]\n",
      "epoch:6 step:5371 [D loss: 0.618723, acc: 71.09%] [G loss: 1.643461]\n",
      "epoch:6 step:5372 [D loss: 0.792483, acc: 42.97%] [G loss: 1.560266]\n",
      "epoch:6 step:5373 [D loss: 0.684787, acc: 57.81%] [G loss: 1.574463]\n",
      "epoch:6 step:5374 [D loss: 0.713364, acc: 50.00%] [G loss: 1.468868]\n",
      "epoch:6 step:5375 [D loss: 0.622220, acc: 67.97%] [G loss: 1.727963]\n",
      "epoch:6 step:5376 [D loss: 0.520470, acc: 92.97%] [G loss: 1.893583]\n",
      "epoch:6 step:5377 [D loss: 0.472219, acc: 75.00%] [G loss: 1.821810]\n",
      "epoch:6 step:5378 [D loss: 1.155428, acc: 22.66%] [G loss: 1.303466]\n",
      "epoch:6 step:5379 [D loss: 0.606888, acc: 65.62%] [G loss: 1.813436]\n",
      "epoch:6 step:5380 [D loss: 0.412032, acc: 95.31%] [G loss: 1.772510]\n",
      "epoch:6 step:5381 [D loss: 0.751275, acc: 50.00%] [G loss: 1.644046]\n",
      "epoch:6 step:5382 [D loss: 0.660793, acc: 58.59%] [G loss: 1.426687]\n",
      "epoch:6 step:5383 [D loss: 0.857744, acc: 25.78%] [G loss: 1.568240]\n",
      "epoch:6 step:5384 [D loss: 0.336897, acc: 93.75%] [G loss: 1.695385]\n",
      "epoch:6 step:5385 [D loss: 0.678613, acc: 64.84%] [G loss: 1.656891]\n",
      "epoch:6 step:5386 [D loss: 0.755253, acc: 44.53%] [G loss: 1.335780]\n",
      "epoch:6 step:5387 [D loss: 0.433626, acc: 91.41%] [G loss: 1.558871]\n",
      "epoch:6 step:5388 [D loss: 0.925407, acc: 16.41%] [G loss: 1.452783]\n",
      "epoch:6 step:5389 [D loss: 0.740267, acc: 48.44%] [G loss: 1.457547]\n",
      "epoch:6 step:5390 [D loss: 1.008340, acc: 14.06%] [G loss: 1.252614]\n",
      "epoch:6 step:5391 [D loss: 0.665313, acc: 54.69%] [G loss: 1.671702]\n",
      "epoch:6 step:5392 [D loss: 0.566467, acc: 75.00%] [G loss: 1.670599]\n",
      "epoch:6 step:5393 [D loss: 0.857891, acc: 31.25%] [G loss: 1.497222]\n",
      "epoch:6 step:5394 [D loss: 0.649734, acc: 61.72%] [G loss: 1.596018]\n",
      "epoch:6 step:5395 [D loss: 0.710554, acc: 53.12%] [G loss: 1.593434]\n",
      "epoch:6 step:5396 [D loss: 0.724034, acc: 46.88%] [G loss: 1.504187]\n",
      "epoch:6 step:5397 [D loss: 0.504165, acc: 85.94%] [G loss: 2.195498]\n",
      "epoch:6 step:5398 [D loss: 0.636911, acc: 67.97%] [G loss: 1.625101]\n",
      "epoch:6 step:5399 [D loss: 0.910682, acc: 25.78%] [G loss: 1.583186]\n",
      "epoch:6 step:5400 [D loss: 0.656452, acc: 60.94%] [G loss: 1.780075]\n",
      "##############\n",
      "[0.87380971 0.87966946 0.82020044 0.80660238 0.80353751 0.82126731\n",
      " 0.89311234 0.83281496 0.79012274 0.82758766]\n",
      "##########\n",
      "epoch:6 step:5401 [D loss: 0.732013, acc: 50.00%] [G loss: 1.636375]\n",
      "epoch:6 step:5402 [D loss: 0.595498, acc: 72.66%] [G loss: 2.134563]\n",
      "epoch:6 step:5403 [D loss: 0.687140, acc: 58.59%] [G loss: 1.896764]\n",
      "epoch:6 step:5404 [D loss: 0.635482, acc: 64.84%] [G loss: 1.648836]\n",
      "epoch:6 step:5405 [D loss: 0.535168, acc: 75.78%] [G loss: 1.803778]\n",
      "epoch:6 step:5406 [D loss: 0.542890, acc: 75.78%] [G loss: 1.664150]\n",
      "epoch:6 step:5407 [D loss: 0.675590, acc: 57.03%] [G loss: 1.320796]\n",
      "epoch:6 step:5408 [D loss: 0.742788, acc: 48.44%] [G loss: 1.891279]\n",
      "epoch:6 step:5409 [D loss: 0.614214, acc: 58.59%] [G loss: 1.451457]\n",
      "epoch:6 step:5410 [D loss: 0.662599, acc: 58.59%] [G loss: 1.563050]\n",
      "epoch:6 step:5411 [D loss: 0.570345, acc: 78.91%] [G loss: 1.686761]\n",
      "epoch:6 step:5412 [D loss: 0.595874, acc: 71.09%] [G loss: 1.534307]\n",
      "epoch:6 step:5413 [D loss: 0.636499, acc: 66.41%] [G loss: 1.775589]\n",
      "epoch:6 step:5414 [D loss: 0.624588, acc: 61.72%] [G loss: 1.396050]\n",
      "epoch:6 step:5415 [D loss: 0.721304, acc: 53.91%] [G loss: 1.546979]\n",
      "epoch:6 step:5416 [D loss: 0.784916, acc: 46.88%] [G loss: 1.742618]\n",
      "epoch:6 step:5417 [D loss: 0.497708, acc: 77.34%] [G loss: 1.458336]\n",
      "epoch:6 step:5418 [D loss: 0.607700, acc: 72.66%] [G loss: 1.524598]\n",
      "epoch:6 step:5419 [D loss: 0.729511, acc: 50.00%] [G loss: 1.581271]\n",
      "epoch:6 step:5420 [D loss: 0.764081, acc: 42.97%] [G loss: 1.567478]\n",
      "epoch:6 step:5421 [D loss: 0.520182, acc: 79.69%] [G loss: 1.865388]\n",
      "epoch:6 step:5422 [D loss: 0.750159, acc: 44.53%] [G loss: 1.846071]\n",
      "epoch:6 step:5423 [D loss: 0.635899, acc: 60.16%] [G loss: 1.601261]\n",
      "epoch:6 step:5424 [D loss: 0.402253, acc: 93.75%] [G loss: 1.589357]\n",
      "epoch:6 step:5425 [D loss: 0.697446, acc: 56.25%] [G loss: 1.633804]\n",
      "epoch:6 step:5426 [D loss: 0.641221, acc: 64.84%] [G loss: 1.603830]\n",
      "epoch:6 step:5427 [D loss: 0.717301, acc: 53.91%] [G loss: 1.711202]\n",
      "epoch:6 step:5428 [D loss: 0.494025, acc: 88.28%] [G loss: 1.748093]\n",
      "epoch:6 step:5429 [D loss: 0.756541, acc: 42.97%] [G loss: 1.630855]\n",
      "epoch:6 step:5430 [D loss: 0.758605, acc: 46.09%] [G loss: 1.717459]\n",
      "epoch:6 step:5431 [D loss: 0.744243, acc: 46.88%] [G loss: 1.498104]\n",
      "epoch:6 step:5432 [D loss: 0.765862, acc: 37.50%] [G loss: 1.606354]\n",
      "epoch:6 step:5433 [D loss: 0.691175, acc: 53.12%] [G loss: 1.675794]\n",
      "epoch:6 step:5434 [D loss: 0.619917, acc: 70.31%] [G loss: 1.566127]\n",
      "epoch:6 step:5435 [D loss: 0.676606, acc: 55.47%] [G loss: 1.652014]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:6 step:5436 [D loss: 0.652382, acc: 60.16%] [G loss: 1.488926]\n",
      "epoch:6 step:5437 [D loss: 0.790324, acc: 50.78%] [G loss: 1.694992]\n",
      "epoch:6 step:5438 [D loss: 0.627819, acc: 60.94%] [G loss: 1.666017]\n",
      "epoch:6 step:5439 [D loss: 0.763126, acc: 39.84%] [G loss: 1.747162]\n",
      "epoch:6 step:5440 [D loss: 0.788208, acc: 41.41%] [G loss: 1.606817]\n",
      "epoch:6 step:5441 [D loss: 0.680313, acc: 51.56%] [G loss: 1.515684]\n",
      "epoch:6 step:5442 [D loss: 0.796138, acc: 30.47%] [G loss: 1.989920]\n",
      "epoch:6 step:5443 [D loss: 0.526813, acc: 79.69%] [G loss: 2.115206]\n",
      "epoch:6 step:5444 [D loss: 0.687108, acc: 53.91%] [G loss: 1.817765]\n",
      "epoch:6 step:5445 [D loss: 0.635708, acc: 63.28%] [G loss: 1.556084]\n",
      "epoch:6 step:5446 [D loss: 0.713811, acc: 51.56%] [G loss: 1.790145]\n",
      "epoch:6 step:5447 [D loss: 0.455885, acc: 86.72%] [G loss: 1.660366]\n",
      "epoch:6 step:5448 [D loss: 0.687645, acc: 57.03%] [G loss: 1.679338]\n",
      "epoch:6 step:5449 [D loss: 0.722916, acc: 51.56%] [G loss: 1.759125]\n",
      "epoch:6 step:5450 [D loss: 0.906068, acc: 20.31%] [G loss: 1.408289]\n",
      "epoch:6 step:5451 [D loss: 0.672943, acc: 64.06%] [G loss: 1.707654]\n",
      "epoch:6 step:5452 [D loss: 0.638877, acc: 63.28%] [G loss: 1.742480]\n",
      "epoch:6 step:5453 [D loss: 0.633652, acc: 64.84%] [G loss: 1.623364]\n",
      "epoch:6 step:5454 [D loss: 0.729456, acc: 49.22%] [G loss: 1.882282]\n",
      "epoch:6 step:5455 [D loss: 0.521231, acc: 75.78%] [G loss: 1.853054]\n",
      "epoch:6 step:5456 [D loss: 0.631353, acc: 67.97%] [G loss: 1.570704]\n",
      "epoch:6 step:5457 [D loss: 0.670705, acc: 55.47%] [G loss: 1.782754]\n",
      "epoch:6 step:5458 [D loss: 0.699692, acc: 51.56%] [G loss: 1.738544]\n",
      "epoch:6 step:5459 [D loss: 0.537186, acc: 76.56%] [G loss: 1.996771]\n",
      "epoch:6 step:5460 [D loss: 0.650391, acc: 59.38%] [G loss: 1.744432]\n",
      "epoch:6 step:5461 [D loss: 0.913360, acc: 21.09%] [G loss: 1.432059]\n",
      "epoch:6 step:5462 [D loss: 0.709726, acc: 53.91%] [G loss: 1.622483]\n",
      "epoch:6 step:5463 [D loss: 0.606278, acc: 67.19%] [G loss: 1.655876]\n",
      "epoch:6 step:5464 [D loss: 0.639096, acc: 65.62%] [G loss: 1.860641]\n",
      "epoch:6 step:5465 [D loss: 0.990096, acc: 18.75%] [G loss: 1.471087]\n",
      "epoch:6 step:5466 [D loss: 0.674671, acc: 54.69%] [G loss: 1.793884]\n",
      "epoch:6 step:5467 [D loss: 0.694540, acc: 53.12%] [G loss: 1.891732]\n",
      "epoch:7 step:5468 [D loss: 0.642095, acc: 61.72%] [G loss: 1.662289]\n",
      "epoch:7 step:5469 [D loss: 0.562864, acc: 78.91%] [G loss: 1.900235]\n",
      "epoch:7 step:5470 [D loss: 0.806575, acc: 35.16%] [G loss: 1.734146]\n",
      "epoch:7 step:5471 [D loss: 0.572704, acc: 75.78%] [G loss: 1.925535]\n",
      "epoch:7 step:5472 [D loss: 0.718331, acc: 51.56%] [G loss: 1.611802]\n",
      "epoch:7 step:5473 [D loss: 0.521838, acc: 82.81%] [G loss: 1.779816]\n",
      "epoch:7 step:5474 [D loss: 0.763951, acc: 41.41%] [G loss: 1.698616]\n",
      "epoch:7 step:5475 [D loss: 0.541467, acc: 79.69%] [G loss: 1.777991]\n",
      "epoch:7 step:5476 [D loss: 0.956009, acc: 19.53%] [G loss: 1.523282]\n",
      "epoch:7 step:5477 [D loss: 0.567953, acc: 76.56%] [G loss: 1.828067]\n",
      "epoch:7 step:5478 [D loss: 0.574092, acc: 76.56%] [G loss: 1.878787]\n",
      "epoch:7 step:5479 [D loss: 0.726012, acc: 49.22%] [G loss: 1.780512]\n",
      "epoch:7 step:5480 [D loss: 0.720828, acc: 53.12%] [G loss: 1.739797]\n",
      "epoch:7 step:5481 [D loss: 0.707392, acc: 57.03%] [G loss: 1.529462]\n",
      "epoch:7 step:5482 [D loss: 0.749649, acc: 40.62%] [G loss: 1.540072]\n",
      "epoch:7 step:5483 [D loss: 0.834470, acc: 35.94%] [G loss: 1.707997]\n",
      "epoch:7 step:5484 [D loss: 0.604585, acc: 75.00%] [G loss: 1.857943]\n",
      "epoch:7 step:5485 [D loss: 0.652978, acc: 64.84%] [G loss: 1.671210]\n",
      "epoch:7 step:5486 [D loss: 0.471480, acc: 82.81%] [G loss: 1.867940]\n",
      "epoch:7 step:5487 [D loss: 0.560539, acc: 75.78%] [G loss: 1.799164]\n",
      "epoch:7 step:5488 [D loss: 0.698542, acc: 55.47%] [G loss: 1.587468]\n",
      "epoch:7 step:5489 [D loss: 0.611297, acc: 66.41%] [G loss: 1.463091]\n",
      "epoch:7 step:5490 [D loss: 0.910188, acc: 21.09%] [G loss: 1.305642]\n",
      "epoch:7 step:5491 [D loss: 0.659881, acc: 59.38%] [G loss: 1.548444]\n",
      "epoch:7 step:5492 [D loss: 0.705883, acc: 49.22%] [G loss: 1.642138]\n",
      "epoch:7 step:5493 [D loss: 0.482702, acc: 88.28%] [G loss: 1.590702]\n",
      "epoch:7 step:5494 [D loss: 0.633771, acc: 71.09%] [G loss: 1.559985]\n",
      "epoch:7 step:5495 [D loss: 0.808915, acc: 32.81%] [G loss: 1.572339]\n",
      "epoch:7 step:5496 [D loss: 0.848840, acc: 29.69%] [G loss: 1.501092]\n",
      "epoch:7 step:5497 [D loss: 0.513713, acc: 83.59%] [G loss: 1.616178]\n",
      "epoch:7 step:5498 [D loss: 0.713436, acc: 42.19%] [G loss: 1.590836]\n",
      "epoch:7 step:5499 [D loss: 0.648192, acc: 59.38%] [G loss: 2.084366]\n",
      "epoch:7 step:5500 [D loss: 0.590433, acc: 70.31%] [G loss: 1.831145]\n",
      "epoch:7 step:5501 [D loss: 0.566693, acc: 81.25%] [G loss: 1.858024]\n",
      "epoch:7 step:5502 [D loss: 0.751620, acc: 42.19%] [G loss: 1.595140]\n",
      "epoch:7 step:5503 [D loss: 0.920468, acc: 24.22%] [G loss: 2.060561]\n",
      "epoch:7 step:5504 [D loss: 0.620044, acc: 71.09%] [G loss: 1.803050]\n",
      "epoch:7 step:5505 [D loss: 0.663447, acc: 57.81%] [G loss: 1.781243]\n",
      "epoch:7 step:5506 [D loss: 0.867240, acc: 39.06%] [G loss: 1.576312]\n",
      "epoch:7 step:5507 [D loss: 0.614146, acc: 67.19%] [G loss: 1.779005]\n",
      "epoch:7 step:5508 [D loss: 0.677376, acc: 60.16%] [G loss: 1.518676]\n",
      "epoch:7 step:5509 [D loss: 0.663665, acc: 60.16%] [G loss: 1.540788]\n",
      "epoch:7 step:5510 [D loss: 0.563866, acc: 78.91%] [G loss: 1.984699]\n",
      "epoch:7 step:5511 [D loss: 0.564302, acc: 77.34%] [G loss: 1.621903]\n",
      "epoch:7 step:5512 [D loss: 0.413214, acc: 92.97%] [G loss: 1.973995]\n",
      "epoch:7 step:5513 [D loss: 0.615197, acc: 71.09%] [G loss: 1.694072]\n",
      "epoch:7 step:5514 [D loss: 0.771284, acc: 42.19%] [G loss: 1.783495]\n",
      "epoch:7 step:5515 [D loss: 0.618280, acc: 64.06%] [G loss: 1.790304]\n",
      "epoch:7 step:5516 [D loss: 0.941227, acc: 50.00%] [G loss: 1.346965]\n",
      "epoch:7 step:5517 [D loss: 0.613719, acc: 71.88%] [G loss: 1.706696]\n",
      "epoch:7 step:5518 [D loss: 0.882549, acc: 44.53%] [G loss: 1.393316]\n",
      "epoch:7 step:5519 [D loss: 0.563621, acc: 74.22%] [G loss: 1.775918]\n",
      "epoch:7 step:5520 [D loss: 0.621668, acc: 67.97%] [G loss: 1.569519]\n",
      "epoch:7 step:5521 [D loss: 0.683354, acc: 56.25%] [G loss: 1.669223]\n",
      "epoch:7 step:5522 [D loss: 0.846243, acc: 28.12%] [G loss: 1.533583]\n",
      "epoch:7 step:5523 [D loss: 0.764897, acc: 42.97%] [G loss: 1.581064]\n",
      "epoch:7 step:5524 [D loss: 0.669074, acc: 63.28%] [G loss: 1.929063]\n",
      "epoch:7 step:5525 [D loss: 0.572902, acc: 73.44%] [G loss: 1.775692]\n",
      "epoch:7 step:5526 [D loss: 0.589320, acc: 66.41%] [G loss: 1.886755]\n",
      "epoch:7 step:5527 [D loss: 0.689136, acc: 58.59%] [G loss: 1.595683]\n",
      "epoch:7 step:5528 [D loss: 0.704422, acc: 47.66%] [G loss: 1.512609]\n",
      "epoch:7 step:5529 [D loss: 0.705745, acc: 53.12%] [G loss: 1.832339]\n",
      "epoch:7 step:5530 [D loss: 0.741639, acc: 47.66%] [G loss: 1.521305]\n",
      "epoch:7 step:5531 [D loss: 0.733797, acc: 51.56%] [G loss: 1.928717]\n",
      "epoch:7 step:5532 [D loss: 0.664467, acc: 62.50%] [G loss: 1.734206]\n",
      "epoch:7 step:5533 [D loss: 0.684168, acc: 57.81%] [G loss: 1.790628]\n",
      "epoch:7 step:5534 [D loss: 0.729988, acc: 48.44%] [G loss: 1.609763]\n",
      "epoch:7 step:5535 [D loss: 0.664743, acc: 67.19%] [G loss: 1.672383]\n",
      "epoch:7 step:5536 [D loss: 0.569510, acc: 74.22%] [G loss: 1.771476]\n",
      "epoch:7 step:5537 [D loss: 0.585437, acc: 78.91%] [G loss: 1.776149]\n",
      "epoch:7 step:5538 [D loss: 0.671906, acc: 64.84%] [G loss: 1.657155]\n",
      "epoch:7 step:5539 [D loss: 0.684587, acc: 52.34%] [G loss: 1.595386]\n",
      "epoch:7 step:5540 [D loss: 0.601810, acc: 73.44%] [G loss: 1.728931]\n",
      "epoch:7 step:5541 [D loss: 0.697923, acc: 55.47%] [G loss: 1.828075]\n",
      "epoch:7 step:5542 [D loss: 0.561000, acc: 78.91%] [G loss: 1.846803]\n",
      "epoch:7 step:5543 [D loss: 0.605928, acc: 64.84%] [G loss: 1.838972]\n",
      "epoch:7 step:5544 [D loss: 0.996043, acc: 34.38%] [G loss: 1.448029]\n",
      "epoch:7 step:5545 [D loss: 0.676600, acc: 60.94%] [G loss: 1.895820]\n",
      "epoch:7 step:5546 [D loss: 0.512071, acc: 85.94%] [G loss: 1.711277]\n",
      "epoch:7 step:5547 [D loss: 0.563906, acc: 76.56%] [G loss: 1.794320]\n",
      "epoch:7 step:5548 [D loss: 0.703643, acc: 55.47%] [G loss: 1.904613]\n",
      "epoch:7 step:5549 [D loss: 0.656728, acc: 60.94%] [G loss: 1.530463]\n",
      "epoch:7 step:5550 [D loss: 0.580124, acc: 74.22%] [G loss: 1.721589]\n",
      "epoch:7 step:5551 [D loss: 0.615028, acc: 66.41%] [G loss: 1.574325]\n",
      "epoch:7 step:5552 [D loss: 0.603279, acc: 67.97%] [G loss: 1.623782]\n",
      "epoch:7 step:5553 [D loss: 1.032035, acc: 17.97%] [G loss: 1.857427]\n",
      "epoch:7 step:5554 [D loss: 0.472354, acc: 88.28%] [G loss: 1.787149]\n",
      "epoch:7 step:5555 [D loss: 0.749529, acc: 46.88%] [G loss: 1.702241]\n",
      "epoch:7 step:5556 [D loss: 0.568268, acc: 78.91%] [G loss: 1.909908]\n",
      "epoch:7 step:5557 [D loss: 1.046309, acc: 18.75%] [G loss: 1.312830]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:7 step:5558 [D loss: 0.316659, acc: 99.22%] [G loss: 2.047585]\n",
      "epoch:7 step:5559 [D loss: 0.695659, acc: 56.25%] [G loss: 1.786455]\n",
      "epoch:7 step:5560 [D loss: 0.604055, acc: 73.44%] [G loss: 1.636688]\n",
      "epoch:7 step:5561 [D loss: 0.454821, acc: 86.72%] [G loss: 1.645250]\n",
      "epoch:7 step:5562 [D loss: 0.650317, acc: 59.38%] [G loss: 1.571458]\n",
      "epoch:7 step:5563 [D loss: 0.723467, acc: 52.34%] [G loss: 1.705253]\n",
      "epoch:7 step:5564 [D loss: 0.683843, acc: 53.12%] [G loss: 1.585949]\n",
      "epoch:7 step:5565 [D loss: 0.961181, acc: 15.62%] [G loss: 1.558285]\n",
      "epoch:7 step:5566 [D loss: 0.539215, acc: 61.72%] [G loss: 1.926433]\n",
      "epoch:7 step:5567 [D loss: 0.684493, acc: 61.72%] [G loss: 2.212101]\n",
      "epoch:7 step:5568 [D loss: 0.588026, acc: 57.81%] [G loss: 2.363640]\n",
      "epoch:7 step:5569 [D loss: 0.489102, acc: 86.72%] [G loss: 1.864151]\n",
      "epoch:7 step:5570 [D loss: 0.770561, acc: 45.31%] [G loss: 1.789155]\n",
      "epoch:7 step:5571 [D loss: 0.817370, acc: 32.03%] [G loss: 2.182959]\n",
      "epoch:7 step:5572 [D loss: 0.748198, acc: 50.78%] [G loss: 1.769891]\n",
      "epoch:7 step:5573 [D loss: 0.430755, acc: 92.19%] [G loss: 2.266777]\n",
      "epoch:7 step:5574 [D loss: 0.592390, acc: 73.44%] [G loss: 2.074087]\n",
      "epoch:7 step:5575 [D loss: 0.798339, acc: 37.50%] [G loss: 1.571690]\n",
      "epoch:7 step:5576 [D loss: 0.564793, acc: 78.91%] [G loss: 1.680881]\n",
      "epoch:7 step:5577 [D loss: 0.625545, acc: 60.16%] [G loss: 1.792607]\n",
      "epoch:7 step:5578 [D loss: 0.780653, acc: 42.97%] [G loss: 2.051729]\n",
      "epoch:7 step:5579 [D loss: 0.658820, acc: 61.72%] [G loss: 1.941175]\n",
      "epoch:7 step:5580 [D loss: 0.748006, acc: 42.97%] [G loss: 1.720754]\n",
      "epoch:7 step:5581 [D loss: 0.612454, acc: 67.19%] [G loss: 1.843641]\n",
      "epoch:7 step:5582 [D loss: 0.708999, acc: 52.34%] [G loss: 1.691536]\n",
      "epoch:7 step:5583 [D loss: 0.591517, acc: 74.22%] [G loss: 1.993849]\n",
      "epoch:7 step:5584 [D loss: 0.723482, acc: 48.44%] [G loss: 1.562287]\n",
      "epoch:7 step:5585 [D loss: 0.736644, acc: 46.88%] [G loss: 1.482101]\n",
      "epoch:7 step:5586 [D loss: 0.677290, acc: 60.16%] [G loss: 1.638283]\n",
      "epoch:7 step:5587 [D loss: 0.558488, acc: 78.12%] [G loss: 1.731699]\n",
      "epoch:7 step:5588 [D loss: 0.748160, acc: 45.31%] [G loss: 2.008327]\n",
      "epoch:7 step:5589 [D loss: 0.600108, acc: 71.09%] [G loss: 1.770406]\n",
      "epoch:7 step:5590 [D loss: 0.634381, acc: 63.28%] [G loss: 1.743208]\n",
      "epoch:7 step:5591 [D loss: 0.697852, acc: 57.03%] [G loss: 1.617512]\n",
      "epoch:7 step:5592 [D loss: 0.645215, acc: 66.41%] [G loss: 2.220594]\n",
      "epoch:7 step:5593 [D loss: 0.682641, acc: 53.91%] [G loss: 1.808324]\n",
      "epoch:7 step:5594 [D loss: 0.406237, acc: 82.03%] [G loss: 3.080617]\n",
      "epoch:7 step:5595 [D loss: 0.437367, acc: 92.19%] [G loss: 2.286955]\n",
      "epoch:7 step:5596 [D loss: 0.721056, acc: 51.56%] [G loss: 1.656778]\n",
      "epoch:7 step:5597 [D loss: 0.781976, acc: 46.88%] [G loss: 1.913209]\n",
      "epoch:7 step:5598 [D loss: 0.567329, acc: 75.78%] [G loss: 1.892514]\n",
      "epoch:7 step:5599 [D loss: 0.668571, acc: 60.16%] [G loss: 2.042786]\n",
      "epoch:7 step:5600 [D loss: 0.667927, acc: 55.47%] [G loss: 1.820877]\n",
      "##############\n",
      "[0.87933659 0.88073345 0.8212953  0.81220471 0.79310047 0.81684677\n",
      " 0.90944428 0.83165682 0.79601502 0.8267678 ]\n",
      "##########\n",
      "epoch:7 step:5601 [D loss: 0.552003, acc: 76.56%] [G loss: 1.821568]\n",
      "epoch:7 step:5602 [D loss: 0.649841, acc: 65.62%] [G loss: 1.728170]\n",
      "epoch:7 step:5603 [D loss: 0.488784, acc: 85.94%] [G loss: 1.830891]\n",
      "epoch:7 step:5604 [D loss: 0.752801, acc: 45.31%] [G loss: 1.716321]\n",
      "epoch:7 step:5605 [D loss: 0.733711, acc: 48.44%] [G loss: 1.898110]\n",
      "epoch:7 step:5606 [D loss: 0.450894, acc: 74.22%] [G loss: 1.899946]\n",
      "epoch:7 step:5607 [D loss: 0.624067, acc: 65.62%] [G loss: 1.920175]\n",
      "epoch:7 step:5608 [D loss: 0.761675, acc: 45.31%] [G loss: 1.991053]\n",
      "epoch:7 step:5609 [D loss: 0.659223, acc: 61.72%] [G loss: 1.856548]\n",
      "epoch:7 step:5610 [D loss: 0.597880, acc: 73.44%] [G loss: 1.910195]\n",
      "epoch:7 step:5611 [D loss: 0.544371, acc: 79.69%] [G loss: 1.810180]\n",
      "epoch:7 step:5612 [D loss: 0.685275, acc: 60.94%] [G loss: 1.912510]\n",
      "epoch:7 step:5613 [D loss: 0.687894, acc: 55.47%] [G loss: 1.885574]\n",
      "epoch:7 step:5614 [D loss: 0.550093, acc: 78.12%] [G loss: 2.099669]\n",
      "epoch:7 step:5615 [D loss: 0.698266, acc: 53.12%] [G loss: 2.255146]\n",
      "epoch:7 step:5616 [D loss: 0.642869, acc: 57.81%] [G loss: 2.522604]\n",
      "epoch:7 step:5617 [D loss: 0.775222, acc: 51.56%] [G loss: 1.820443]\n",
      "epoch:7 step:5618 [D loss: 0.367472, acc: 93.75%] [G loss: 1.838464]\n",
      "epoch:7 step:5619 [D loss: 0.498425, acc: 82.81%] [G loss: 1.918023]\n",
      "epoch:7 step:5620 [D loss: 0.570940, acc: 77.34%] [G loss: 1.944739]\n",
      "epoch:7 step:5621 [D loss: 0.470790, acc: 82.81%] [G loss: 2.071997]\n",
      "epoch:7 step:5622 [D loss: 0.733517, acc: 53.91%] [G loss: 1.714193]\n",
      "epoch:7 step:5623 [D loss: 0.531657, acc: 72.66%] [G loss: 2.045618]\n",
      "epoch:7 step:5624 [D loss: 0.666403, acc: 60.16%] [G loss: 1.716363]\n",
      "epoch:7 step:5625 [D loss: 0.691472, acc: 56.25%] [G loss: 1.781978]\n",
      "epoch:7 step:5626 [D loss: 0.680060, acc: 57.81%] [G loss: 1.713886]\n",
      "epoch:7 step:5627 [D loss: 0.583290, acc: 65.62%] [G loss: 1.987457]\n",
      "epoch:7 step:5628 [D loss: 0.872096, acc: 33.59%] [G loss: 1.819932]\n",
      "epoch:7 step:5629 [D loss: 0.783719, acc: 49.22%] [G loss: 1.950720]\n",
      "epoch:7 step:5630 [D loss: 0.640304, acc: 64.06%] [G loss: 1.509863]\n",
      "epoch:7 step:5631 [D loss: 0.799223, acc: 46.09%] [G loss: 1.646927]\n",
      "epoch:7 step:5632 [D loss: 0.726452, acc: 53.12%] [G loss: 1.641376]\n",
      "epoch:7 step:5633 [D loss: 1.063733, acc: 32.81%] [G loss: 1.355013]\n",
      "epoch:7 step:5634 [D loss: 0.624310, acc: 69.53%] [G loss: 1.618724]\n",
      "epoch:7 step:5635 [D loss: 0.726875, acc: 52.34%] [G loss: 1.605512]\n",
      "epoch:7 step:5636 [D loss: 0.372243, acc: 96.09%] [G loss: 2.013260]\n",
      "epoch:7 step:5637 [D loss: 0.662698, acc: 61.72%] [G loss: 2.045444]\n",
      "epoch:7 step:5638 [D loss: 0.704074, acc: 53.91%] [G loss: 1.699203]\n",
      "epoch:7 step:5639 [D loss: 0.780018, acc: 50.78%] [G loss: 1.667353]\n",
      "epoch:7 step:5640 [D loss: 0.800761, acc: 40.62%] [G loss: 1.654924]\n",
      "epoch:7 step:5641 [D loss: 0.767157, acc: 48.44%] [G loss: 1.779526]\n",
      "epoch:7 step:5642 [D loss: 0.472634, acc: 83.59%] [G loss: 1.734545]\n",
      "epoch:7 step:5643 [D loss: 0.681878, acc: 55.47%] [G loss: 1.842108]\n",
      "epoch:7 step:5644 [D loss: 0.668902, acc: 59.38%] [G loss: 1.768113]\n",
      "epoch:7 step:5645 [D loss: 0.692649, acc: 61.72%] [G loss: 1.708605]\n",
      "epoch:7 step:5646 [D loss: 0.715077, acc: 50.78%] [G loss: 1.680866]\n",
      "epoch:7 step:5647 [D loss: 0.721838, acc: 50.00%] [G loss: 1.875018]\n",
      "epoch:7 step:5648 [D loss: 0.464818, acc: 82.03%] [G loss: 2.667533]\n",
      "epoch:7 step:5649 [D loss: 0.664252, acc: 60.94%] [G loss: 1.513044]\n",
      "epoch:7 step:5650 [D loss: 0.671570, acc: 58.59%] [G loss: 1.889637]\n",
      "epoch:7 step:5651 [D loss: 0.472801, acc: 67.19%] [G loss: 2.010743]\n",
      "epoch:7 step:5652 [D loss: 0.779811, acc: 37.50%] [G loss: 1.889715]\n",
      "epoch:7 step:5653 [D loss: 0.590033, acc: 67.97%] [G loss: 2.017507]\n",
      "epoch:7 step:5654 [D loss: 0.752811, acc: 46.88%] [G loss: 1.883933]\n",
      "epoch:7 step:5655 [D loss: 0.602776, acc: 66.41%] [G loss: 1.871996]\n",
      "epoch:7 step:5656 [D loss: 0.711393, acc: 50.78%] [G loss: 1.971866]\n",
      "epoch:7 step:5657 [D loss: 0.506408, acc: 69.53%] [G loss: 1.821985]\n",
      "epoch:7 step:5658 [D loss: 0.506455, acc: 82.03%] [G loss: 2.086692]\n",
      "epoch:7 step:5659 [D loss: 0.864924, acc: 44.53%] [G loss: 1.840825]\n",
      "epoch:7 step:5660 [D loss: 0.844631, acc: 44.53%] [G loss: 1.614530]\n",
      "epoch:7 step:5661 [D loss: 0.523433, acc: 84.38%] [G loss: 1.995498]\n",
      "epoch:7 step:5662 [D loss: 0.638081, acc: 56.25%] [G loss: 1.656459]\n",
      "epoch:7 step:5663 [D loss: 1.041774, acc: 14.84%] [G loss: 1.524556]\n",
      "epoch:7 step:5664 [D loss: 0.673619, acc: 56.25%] [G loss: 1.818434]\n",
      "epoch:7 step:5665 [D loss: 0.872073, acc: 29.69%] [G loss: 1.783164]\n",
      "epoch:7 step:5666 [D loss: 0.664468, acc: 63.28%] [G loss: 1.776690]\n",
      "epoch:7 step:5667 [D loss: 0.636225, acc: 64.84%] [G loss: 1.688589]\n",
      "epoch:7 step:5668 [D loss: 0.479302, acc: 86.72%] [G loss: 1.690457]\n",
      "epoch:7 step:5669 [D loss: 0.702914, acc: 53.91%] [G loss: 1.755087]\n",
      "epoch:7 step:5670 [D loss: 0.522164, acc: 82.81%] [G loss: 1.642572]\n",
      "epoch:7 step:5671 [D loss: 0.562340, acc: 79.69%] [G loss: 2.333879]\n",
      "epoch:7 step:5672 [D loss: 1.058198, acc: 38.28%] [G loss: 1.753526]\n",
      "epoch:7 step:5673 [D loss: 0.387083, acc: 95.31%] [G loss: 1.909006]\n",
      "epoch:7 step:5674 [D loss: 0.597646, acc: 75.00%] [G loss: 1.694936]\n",
      "epoch:7 step:5675 [D loss: 0.622331, acc: 62.50%] [G loss: 1.744595]\n",
      "epoch:7 step:5676 [D loss: 0.635185, acc: 61.72%] [G loss: 1.418382]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:7 step:5677 [D loss: 0.478382, acc: 89.84%] [G loss: 1.701226]\n",
      "epoch:7 step:5678 [D loss: 0.737950, acc: 50.78%] [G loss: 1.569562]\n",
      "epoch:7 step:5679 [D loss: 0.528901, acc: 60.94%] [G loss: 1.860847]\n",
      "epoch:7 step:5680 [D loss: 0.931849, acc: 22.66%] [G loss: 1.543720]\n",
      "epoch:7 step:5681 [D loss: 0.859689, acc: 36.72%] [G loss: 2.038810]\n",
      "epoch:7 step:5682 [D loss: 0.799520, acc: 42.19%] [G loss: 1.770378]\n",
      "epoch:7 step:5683 [D loss: 0.478499, acc: 78.91%] [G loss: 1.647280]\n",
      "epoch:7 step:5684 [D loss: 0.582426, acc: 68.75%] [G loss: 2.365848]\n",
      "epoch:7 step:5685 [D loss: 0.711434, acc: 58.59%] [G loss: 1.781252]\n",
      "epoch:7 step:5686 [D loss: 0.504422, acc: 82.81%] [G loss: 2.076021]\n",
      "epoch:7 step:5687 [D loss: 0.706314, acc: 52.34%] [G loss: 1.820343]\n",
      "epoch:7 step:5688 [D loss: 0.861729, acc: 48.44%] [G loss: 1.386547]\n",
      "epoch:7 step:5689 [D loss: 0.776352, acc: 40.62%] [G loss: 1.531824]\n",
      "epoch:7 step:5690 [D loss: 0.704777, acc: 50.00%] [G loss: 1.824652]\n",
      "epoch:7 step:5691 [D loss: 0.697175, acc: 51.56%] [G loss: 1.769234]\n",
      "epoch:7 step:5692 [D loss: 1.058231, acc: 31.25%] [G loss: 1.891623]\n",
      "epoch:7 step:5693 [D loss: 0.793760, acc: 39.06%] [G loss: 1.288446]\n",
      "epoch:7 step:5694 [D loss: 0.639308, acc: 57.81%] [G loss: 1.849216]\n",
      "epoch:7 step:5695 [D loss: 0.744544, acc: 53.12%] [G loss: 1.593838]\n",
      "epoch:7 step:5696 [D loss: 0.635093, acc: 61.72%] [G loss: 1.592507]\n",
      "epoch:7 step:5697 [D loss: 1.030478, acc: 14.84%] [G loss: 1.423857]\n",
      "epoch:7 step:5698 [D loss: 0.673430, acc: 59.38%] [G loss: 1.812091]\n",
      "epoch:7 step:5699 [D loss: 0.739064, acc: 46.09%] [G loss: 1.415069]\n",
      "epoch:7 step:5700 [D loss: 0.676566, acc: 53.12%] [G loss: 1.643935]\n",
      "epoch:7 step:5701 [D loss: 0.588556, acc: 72.66%] [G loss: 1.773270]\n",
      "epoch:7 step:5702 [D loss: 0.784416, acc: 40.62%] [G loss: 1.711046]\n",
      "epoch:7 step:5703 [D loss: 0.765563, acc: 41.41%] [G loss: 1.682451]\n",
      "epoch:7 step:5704 [D loss: 0.735322, acc: 41.41%] [G loss: 1.642986]\n",
      "epoch:7 step:5705 [D loss: 0.749381, acc: 49.22%] [G loss: 1.512045]\n",
      "epoch:7 step:5706 [D loss: 0.646247, acc: 64.06%] [G loss: 1.685587]\n",
      "epoch:7 step:5707 [D loss: 0.677816, acc: 58.59%] [G loss: 1.733575]\n",
      "epoch:7 step:5708 [D loss: 0.722467, acc: 50.78%] [G loss: 1.741009]\n",
      "epoch:7 step:5709 [D loss: 0.773430, acc: 42.19%] [G loss: 1.536383]\n",
      "epoch:7 step:5710 [D loss: 0.709632, acc: 50.78%] [G loss: 1.674482]\n",
      "epoch:7 step:5711 [D loss: 0.675830, acc: 56.25%] [G loss: 1.781699]\n",
      "epoch:7 step:5712 [D loss: 0.687773, acc: 53.91%] [G loss: 1.628038]\n",
      "epoch:7 step:5713 [D loss: 0.686219, acc: 55.47%] [G loss: 1.670768]\n",
      "epoch:7 step:5714 [D loss: 0.543359, acc: 81.25%] [G loss: 1.756733]\n",
      "epoch:7 step:5715 [D loss: 0.668139, acc: 59.38%] [G loss: 1.814916]\n",
      "epoch:7 step:5716 [D loss: 0.572181, acc: 71.88%] [G loss: 2.095989]\n",
      "epoch:7 step:5717 [D loss: 0.624391, acc: 65.62%] [G loss: 1.926833]\n",
      "epoch:7 step:5718 [D loss: 0.642825, acc: 64.84%] [G loss: 1.683398]\n",
      "epoch:7 step:5719 [D loss: 0.597547, acc: 70.31%] [G loss: 1.758729]\n",
      "epoch:7 step:5720 [D loss: 0.587441, acc: 73.44%] [G loss: 1.790270]\n",
      "epoch:7 step:5721 [D loss: 0.564017, acc: 74.22%] [G loss: 1.679177]\n",
      "epoch:7 step:5722 [D loss: 0.750988, acc: 46.09%] [G loss: 1.445484]\n",
      "epoch:7 step:5723 [D loss: 0.851445, acc: 27.34%] [G loss: 1.361952]\n",
      "epoch:7 step:5724 [D loss: 0.883397, acc: 24.22%] [G loss: 1.472677]\n",
      "epoch:7 step:5725 [D loss: 0.754960, acc: 50.00%] [G loss: 1.716587]\n",
      "epoch:7 step:5726 [D loss: 0.689909, acc: 55.47%] [G loss: 1.854995]\n",
      "epoch:7 step:5727 [D loss: 0.734160, acc: 51.56%] [G loss: 1.857389]\n",
      "epoch:7 step:5728 [D loss: 0.481751, acc: 78.12%] [G loss: 1.834312]\n",
      "epoch:7 step:5729 [D loss: 0.530132, acc: 82.03%] [G loss: 1.918575]\n",
      "epoch:7 step:5730 [D loss: 0.791819, acc: 38.28%] [G loss: 1.407183]\n",
      "epoch:7 step:5731 [D loss: 0.689224, acc: 52.34%] [G loss: 1.687392]\n",
      "epoch:7 step:5732 [D loss: 0.667221, acc: 62.50%] [G loss: 1.624954]\n",
      "epoch:7 step:5733 [D loss: 0.809920, acc: 35.94%] [G loss: 1.525289]\n",
      "epoch:7 step:5734 [D loss: 0.877179, acc: 42.97%] [G loss: 1.522177]\n",
      "epoch:7 step:5735 [D loss: 0.635759, acc: 64.84%] [G loss: 1.630080]\n",
      "epoch:7 step:5736 [D loss: 0.631237, acc: 66.41%] [G loss: 1.480186]\n",
      "epoch:7 step:5737 [D loss: 0.687296, acc: 54.69%] [G loss: 1.537070]\n",
      "epoch:7 step:5738 [D loss: 0.700610, acc: 51.56%] [G loss: 1.745877]\n",
      "epoch:7 step:5739 [D loss: 0.690021, acc: 52.34%] [G loss: 1.723134]\n",
      "epoch:7 step:5740 [D loss: 0.607651, acc: 69.53%] [G loss: 1.898485]\n",
      "epoch:7 step:5741 [D loss: 0.750443, acc: 42.19%] [G loss: 1.600369]\n",
      "epoch:7 step:5742 [D loss: 0.756487, acc: 44.53%] [G loss: 1.678020]\n",
      "epoch:7 step:5743 [D loss: 0.720690, acc: 49.22%] [G loss: 1.517287]\n",
      "epoch:7 step:5744 [D loss: 1.007700, acc: 15.62%] [G loss: 1.372963]\n",
      "epoch:7 step:5745 [D loss: 0.662759, acc: 57.81%] [G loss: 1.667321]\n",
      "epoch:7 step:5746 [D loss: 0.630283, acc: 65.62%] [G loss: 1.673134]\n",
      "epoch:7 step:5747 [D loss: 0.546473, acc: 82.03%] [G loss: 1.934684]\n",
      "epoch:7 step:5748 [D loss: 0.618420, acc: 73.44%] [G loss: 1.606626]\n",
      "epoch:7 step:5749 [D loss: 0.730065, acc: 45.31%] [G loss: 1.556666]\n",
      "epoch:7 step:5750 [D loss: 0.672753, acc: 59.38%] [G loss: 1.608221]\n",
      "epoch:7 step:5751 [D loss: 0.591476, acc: 71.88%] [G loss: 1.774380]\n",
      "epoch:7 step:5752 [D loss: 0.752045, acc: 46.88%] [G loss: 1.544117]\n",
      "epoch:7 step:5753 [D loss: 0.669777, acc: 61.72%] [G loss: 1.733660]\n",
      "epoch:7 step:5754 [D loss: 0.746380, acc: 48.44%] [G loss: 1.625937]\n",
      "epoch:7 step:5755 [D loss: 0.718370, acc: 47.66%] [G loss: 1.527314]\n",
      "epoch:7 step:5756 [D loss: 0.666327, acc: 57.03%] [G loss: 1.734645]\n",
      "epoch:7 step:5757 [D loss: 0.666096, acc: 57.81%] [G loss: 1.476432]\n",
      "epoch:7 step:5758 [D loss: 1.087766, acc: 15.62%] [G loss: 1.238382]\n",
      "epoch:7 step:5759 [D loss: 0.661151, acc: 57.03%] [G loss: 1.667924]\n",
      "epoch:7 step:5760 [D loss: 0.695247, acc: 57.03%] [G loss: 1.653329]\n",
      "epoch:7 step:5761 [D loss: 0.690075, acc: 57.03%] [G loss: 1.476442]\n",
      "epoch:7 step:5762 [D loss: 0.661740, acc: 55.47%] [G loss: 1.756050]\n",
      "epoch:7 step:5763 [D loss: 0.657665, acc: 58.59%] [G loss: 1.890135]\n",
      "epoch:7 step:5764 [D loss: 0.719391, acc: 50.78%] [G loss: 1.651080]\n",
      "epoch:7 step:5765 [D loss: 0.772965, acc: 39.06%] [G loss: 1.503199]\n",
      "epoch:7 step:5766 [D loss: 0.580747, acc: 75.78%] [G loss: 1.881997]\n",
      "epoch:7 step:5767 [D loss: 0.728134, acc: 50.00%] [G loss: 1.598175]\n",
      "epoch:7 step:5768 [D loss: 0.650860, acc: 60.94%] [G loss: 1.624905]\n",
      "epoch:7 step:5769 [D loss: 0.741162, acc: 46.09%] [G loss: 1.531112]\n",
      "epoch:7 step:5770 [D loss: 0.690189, acc: 53.12%] [G loss: 1.605605]\n",
      "epoch:7 step:5771 [D loss: 0.655564, acc: 64.06%] [G loss: 1.620950]\n",
      "epoch:7 step:5772 [D loss: 0.535682, acc: 82.03%] [G loss: 1.735720]\n",
      "epoch:7 step:5773 [D loss: 0.610649, acc: 71.09%] [G loss: 1.710343]\n",
      "epoch:7 step:5774 [D loss: 0.706788, acc: 49.22%] [G loss: 1.770528]\n",
      "epoch:7 step:5775 [D loss: 0.587627, acc: 72.66%] [G loss: 1.711082]\n",
      "epoch:7 step:5776 [D loss: 0.740987, acc: 46.09%] [G loss: 1.720356]\n",
      "epoch:7 step:5777 [D loss: 0.719511, acc: 54.69%] [G loss: 1.645906]\n",
      "epoch:7 step:5778 [D loss: 0.810973, acc: 35.94%] [G loss: 1.578786]\n",
      "epoch:7 step:5779 [D loss: 0.600589, acc: 72.66%] [G loss: 1.742058]\n",
      "epoch:7 step:5780 [D loss: 0.718967, acc: 44.53%] [G loss: 1.754013]\n",
      "epoch:7 step:5781 [D loss: 0.664871, acc: 61.72%] [G loss: 1.709183]\n",
      "epoch:7 step:5782 [D loss: 0.758878, acc: 44.53%] [G loss: 1.582714]\n",
      "epoch:7 step:5783 [D loss: 0.703794, acc: 47.66%] [G loss: 1.708713]\n",
      "epoch:7 step:5784 [D loss: 0.641630, acc: 64.84%] [G loss: 1.784088]\n",
      "epoch:7 step:5785 [D loss: 0.687924, acc: 54.69%] [G loss: 1.758095]\n",
      "epoch:7 step:5786 [D loss: 0.705329, acc: 47.66%] [G loss: 1.619410]\n",
      "epoch:7 step:5787 [D loss: 0.810527, acc: 41.41%] [G loss: 1.536372]\n",
      "epoch:7 step:5788 [D loss: 0.731584, acc: 47.66%] [G loss: 1.704863]\n",
      "epoch:7 step:5789 [D loss: 0.688915, acc: 58.59%] [G loss: 1.615635]\n",
      "epoch:7 step:5790 [D loss: 0.678513, acc: 56.25%] [G loss: 1.688068]\n",
      "epoch:7 step:5791 [D loss: 0.641036, acc: 64.06%] [G loss: 1.626605]\n",
      "epoch:7 step:5792 [D loss: 0.704731, acc: 48.44%] [G loss: 1.642502]\n",
      "epoch:7 step:5793 [D loss: 0.705049, acc: 56.25%] [G loss: 1.469774]\n",
      "epoch:7 step:5794 [D loss: 0.699863, acc: 52.34%] [G loss: 1.631067]\n",
      "epoch:7 step:5795 [D loss: 0.686487, acc: 52.34%] [G loss: 1.631978]\n",
      "epoch:7 step:5796 [D loss: 0.811701, acc: 40.62%] [G loss: 1.469304]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:7 step:5797 [D loss: 0.614820, acc: 66.41%] [G loss: 1.562946]\n",
      "epoch:7 step:5798 [D loss: 0.657668, acc: 64.84%] [G loss: 1.637240]\n",
      "epoch:7 step:5799 [D loss: 0.663233, acc: 61.72%] [G loss: 1.740996]\n",
      "epoch:7 step:5800 [D loss: 0.626495, acc: 71.88%] [G loss: 1.634623]\n",
      "##############\n",
      "[0.84547732 0.87989253 0.81631841 0.83343149 0.78083862 0.82290534\n",
      " 0.85775089 0.82706973 0.80126696 0.86486035]\n",
      "##########\n",
      "epoch:7 step:5801 [D loss: 0.825145, acc: 35.16%] [G loss: 1.440306]\n",
      "epoch:7 step:5802 [D loss: 0.634629, acc: 66.41%] [G loss: 1.805410]\n",
      "epoch:7 step:5803 [D loss: 0.748496, acc: 46.88%] [G loss: 1.529160]\n",
      "epoch:7 step:5804 [D loss: 0.631733, acc: 67.19%] [G loss: 1.626927]\n",
      "epoch:7 step:5805 [D loss: 0.692325, acc: 56.25%] [G loss: 1.958352]\n",
      "epoch:7 step:5806 [D loss: 0.702928, acc: 53.12%] [G loss: 1.775285]\n",
      "epoch:7 step:5807 [D loss: 0.629982, acc: 66.41%] [G loss: 1.694298]\n",
      "epoch:7 step:5808 [D loss: 0.646630, acc: 62.50%] [G loss: 1.660035]\n",
      "epoch:7 step:5809 [D loss: 0.833112, acc: 35.16%] [G loss: 1.554255]\n",
      "epoch:7 step:5810 [D loss: 0.861756, acc: 30.47%] [G loss: 1.546316]\n",
      "epoch:7 step:5811 [D loss: 0.723475, acc: 49.22%] [G loss: 1.557707]\n",
      "epoch:7 step:5812 [D loss: 0.560856, acc: 74.22%] [G loss: 1.886320]\n",
      "epoch:7 step:5813 [D loss: 0.724197, acc: 50.00%] [G loss: 1.712040]\n",
      "epoch:7 step:5814 [D loss: 0.611876, acc: 75.78%] [G loss: 1.640359]\n",
      "epoch:7 step:5815 [D loss: 0.702750, acc: 51.56%] [G loss: 1.552284]\n",
      "epoch:7 step:5816 [D loss: 0.607817, acc: 61.72%] [G loss: 1.744846]\n",
      "epoch:7 step:5817 [D loss: 0.699952, acc: 52.34%] [G loss: 1.872675]\n",
      "epoch:7 step:5818 [D loss: 0.728505, acc: 47.66%] [G loss: 1.572987]\n",
      "epoch:7 step:5819 [D loss: 0.706140, acc: 53.12%] [G loss: 1.663212]\n",
      "epoch:7 step:5820 [D loss: 0.750839, acc: 39.84%] [G loss: 1.700885]\n",
      "epoch:7 step:5821 [D loss: 0.656103, acc: 62.50%] [G loss: 1.620346]\n",
      "epoch:7 step:5822 [D loss: 0.682121, acc: 61.72%] [G loss: 1.635642]\n",
      "epoch:7 step:5823 [D loss: 0.675149, acc: 57.81%] [G loss: 1.640365]\n",
      "epoch:7 step:5824 [D loss: 0.671908, acc: 61.72%] [G loss: 1.753008]\n",
      "epoch:7 step:5825 [D loss: 0.714628, acc: 51.56%] [G loss: 1.643678]\n",
      "epoch:7 step:5826 [D loss: 0.794712, acc: 37.50%] [G loss: 1.481352]\n",
      "epoch:7 step:5827 [D loss: 0.795879, acc: 39.06%] [G loss: 1.480550]\n",
      "epoch:7 step:5828 [D loss: 0.711092, acc: 52.34%] [G loss: 1.615638]\n",
      "epoch:7 step:5829 [D loss: 0.780764, acc: 38.28%] [G loss: 1.620021]\n",
      "epoch:7 step:5830 [D loss: 0.648860, acc: 67.19%] [G loss: 1.867751]\n",
      "epoch:7 step:5831 [D loss: 0.669905, acc: 56.25%] [G loss: 1.634762]\n",
      "epoch:7 step:5832 [D loss: 0.678621, acc: 57.81%] [G loss: 1.554500]\n",
      "epoch:7 step:5833 [D loss: 0.820774, acc: 34.38%] [G loss: 1.376776]\n",
      "epoch:7 step:5834 [D loss: 0.645498, acc: 64.06%] [G loss: 1.670663]\n",
      "epoch:7 step:5835 [D loss: 0.829944, acc: 31.25%] [G loss: 1.451158]\n",
      "epoch:7 step:5836 [D loss: 0.646736, acc: 63.28%] [G loss: 1.542477]\n",
      "epoch:7 step:5837 [D loss: 0.638609, acc: 71.09%] [G loss: 1.807068]\n",
      "epoch:7 step:5838 [D loss: 0.611711, acc: 71.88%] [G loss: 1.676529]\n",
      "epoch:7 step:5839 [D loss: 0.702810, acc: 50.78%] [G loss: 1.576649]\n",
      "epoch:7 step:5840 [D loss: 0.887487, acc: 24.22%] [G loss: 1.516257]\n",
      "epoch:7 step:5841 [D loss: 0.685634, acc: 50.78%] [G loss: 1.602846]\n",
      "epoch:7 step:5842 [D loss: 0.776676, acc: 44.53%] [G loss: 1.658912]\n",
      "epoch:7 step:5843 [D loss: 0.723010, acc: 52.34%] [G loss: 1.869811]\n",
      "epoch:7 step:5844 [D loss: 0.609214, acc: 72.66%] [G loss: 1.765360]\n",
      "epoch:7 step:5845 [D loss: 0.751163, acc: 46.88%] [G loss: 1.573772]\n",
      "epoch:7 step:5846 [D loss: 0.704124, acc: 54.69%] [G loss: 1.722591]\n",
      "epoch:7 step:5847 [D loss: 0.621744, acc: 68.75%] [G loss: 1.727109]\n",
      "epoch:7 step:5848 [D loss: 0.644276, acc: 59.38%] [G loss: 1.808406]\n",
      "epoch:7 step:5849 [D loss: 0.765083, acc: 37.50%] [G loss: 1.528974]\n",
      "epoch:7 step:5850 [D loss: 0.675144, acc: 53.91%] [G loss: 1.601890]\n",
      "epoch:7 step:5851 [D loss: 0.741004, acc: 48.44%] [G loss: 1.628464]\n",
      "epoch:7 step:5852 [D loss: 0.771139, acc: 41.41%] [G loss: 1.851745]\n",
      "epoch:7 step:5853 [D loss: 0.665485, acc: 59.38%] [G loss: 1.693258]\n",
      "epoch:7 step:5854 [D loss: 0.691420, acc: 58.59%] [G loss: 1.562742]\n",
      "epoch:7 step:5855 [D loss: 0.643764, acc: 60.94%] [G loss: 1.733472]\n",
      "epoch:7 step:5856 [D loss: 0.623875, acc: 65.62%] [G loss: 1.747122]\n",
      "epoch:7 step:5857 [D loss: 0.722714, acc: 45.31%] [G loss: 1.668258]\n",
      "epoch:7 step:5858 [D loss: 0.631383, acc: 70.31%] [G loss: 1.688169]\n",
      "epoch:7 step:5859 [D loss: 0.715162, acc: 46.88%] [G loss: 1.587454]\n",
      "epoch:7 step:5860 [D loss: 0.770936, acc: 39.84%] [G loss: 1.432891]\n",
      "epoch:7 step:5861 [D loss: 0.660195, acc: 61.72%] [G loss: 1.850247]\n",
      "epoch:7 step:5862 [D loss: 0.725777, acc: 45.31%] [G loss: 1.616906]\n",
      "epoch:7 step:5863 [D loss: 0.737709, acc: 44.53%] [G loss: 1.596653]\n",
      "epoch:7 step:5864 [D loss: 0.733153, acc: 49.22%] [G loss: 1.746001]\n",
      "epoch:7 step:5865 [D loss: 0.719697, acc: 51.56%] [G loss: 1.625346]\n",
      "epoch:7 step:5866 [D loss: 0.693649, acc: 59.38%] [G loss: 1.557638]\n",
      "epoch:7 step:5867 [D loss: 0.739603, acc: 48.44%] [G loss: 1.593074]\n",
      "epoch:7 step:5868 [D loss: 0.722240, acc: 46.88%] [G loss: 1.755659]\n",
      "epoch:7 step:5869 [D loss: 0.553385, acc: 78.91%] [G loss: 1.719010]\n",
      "epoch:7 step:5870 [D loss: 0.657628, acc: 64.06%] [G loss: 1.789126]\n",
      "epoch:7 step:5871 [D loss: 0.658775, acc: 60.16%] [G loss: 1.524517]\n",
      "epoch:7 step:5872 [D loss: 0.653162, acc: 61.72%] [G loss: 1.796754]\n",
      "epoch:7 step:5873 [D loss: 0.638661, acc: 64.84%] [G loss: 1.600260]\n",
      "epoch:7 step:5874 [D loss: 0.671147, acc: 57.81%] [G loss: 1.582832]\n",
      "epoch:7 step:5875 [D loss: 0.680724, acc: 58.59%] [G loss: 1.561644]\n",
      "epoch:7 step:5876 [D loss: 0.690491, acc: 53.91%] [G loss: 1.691601]\n",
      "epoch:7 step:5877 [D loss: 0.607795, acc: 72.66%] [G loss: 1.740585]\n",
      "epoch:7 step:5878 [D loss: 0.895654, acc: 28.12%] [G loss: 1.430878]\n",
      "epoch:7 step:5879 [D loss: 0.558246, acc: 79.69%] [G loss: 1.749031]\n",
      "epoch:7 step:5880 [D loss: 0.508813, acc: 80.47%] [G loss: 1.862696]\n",
      "epoch:7 step:5881 [D loss: 0.841621, acc: 30.47%] [G loss: 1.364044]\n",
      "epoch:7 step:5882 [D loss: 0.508426, acc: 85.94%] [G loss: 1.930125]\n",
      "epoch:7 step:5883 [D loss: 0.601229, acc: 71.88%] [G loss: 1.661087]\n",
      "epoch:7 step:5884 [D loss: 0.655439, acc: 60.16%] [G loss: 1.742556]\n",
      "epoch:7 step:5885 [D loss: 0.617017, acc: 67.97%] [G loss: 1.612098]\n",
      "epoch:7 step:5886 [D loss: 0.736879, acc: 51.56%] [G loss: 1.633565]\n",
      "epoch:7 step:5887 [D loss: 0.502716, acc: 72.66%] [G loss: 1.765104]\n",
      "epoch:7 step:5888 [D loss: 0.739522, acc: 44.53%] [G loss: 1.754547]\n",
      "epoch:7 step:5889 [D loss: 0.653294, acc: 60.94%] [G loss: 1.796403]\n",
      "epoch:7 step:5890 [D loss: 0.551054, acc: 77.34%] [G loss: 1.696937]\n",
      "epoch:7 step:5891 [D loss: 0.666882, acc: 61.72%] [G loss: 1.627954]\n",
      "epoch:7 step:5892 [D loss: 0.729242, acc: 48.44%] [G loss: 1.704466]\n",
      "epoch:7 step:5893 [D loss: 0.736096, acc: 51.56%] [G loss: 1.732460]\n",
      "epoch:7 step:5894 [D loss: 0.667241, acc: 55.47%] [G loss: 1.630270]\n",
      "epoch:7 step:5895 [D loss: 0.839446, acc: 34.38%] [G loss: 1.681743]\n",
      "epoch:7 step:5896 [D loss: 0.662002, acc: 62.50%] [G loss: 1.620651]\n",
      "epoch:7 step:5897 [D loss: 0.716974, acc: 52.34%] [G loss: 1.761871]\n",
      "epoch:7 step:5898 [D loss: 0.634832, acc: 61.72%] [G loss: 1.765684]\n",
      "epoch:7 step:5899 [D loss: 0.674766, acc: 60.16%] [G loss: 2.138893]\n",
      "epoch:7 step:5900 [D loss: 0.746668, acc: 46.09%] [G loss: 1.640113]\n",
      "epoch:7 step:5901 [D loss: 0.993995, acc: 21.09%] [G loss: 1.351116]\n",
      "epoch:7 step:5902 [D loss: 0.732517, acc: 45.31%] [G loss: 1.678299]\n",
      "epoch:7 step:5903 [D loss: 0.805601, acc: 33.59%] [G loss: 1.576604]\n",
      "epoch:7 step:5904 [D loss: 0.728348, acc: 46.09%] [G loss: 1.485129]\n",
      "epoch:7 step:5905 [D loss: 0.558368, acc: 74.22%] [G loss: 1.765108]\n",
      "epoch:7 step:5906 [D loss: 0.735196, acc: 51.56%] [G loss: 1.641841]\n",
      "epoch:7 step:5907 [D loss: 0.659636, acc: 64.84%] [G loss: 1.613262]\n",
      "epoch:7 step:5908 [D loss: 0.665360, acc: 65.62%] [G loss: 1.738333]\n",
      "epoch:7 step:5909 [D loss: 0.685287, acc: 54.69%] [G loss: 1.662492]\n",
      "epoch:7 step:5910 [D loss: 0.676010, acc: 60.16%] [G loss: 1.695933]\n",
      "epoch:7 step:5911 [D loss: 0.702521, acc: 53.12%] [G loss: 1.890427]\n",
      "epoch:7 step:5912 [D loss: 0.768921, acc: 36.72%] [G loss: 1.695275]\n",
      "epoch:7 step:5913 [D loss: 0.590426, acc: 74.22%] [G loss: 1.841156]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:7 step:5914 [D loss: 0.591513, acc: 71.09%] [G loss: 1.765215]\n",
      "epoch:7 step:5915 [D loss: 0.669221, acc: 57.03%] [G loss: 1.793742]\n",
      "epoch:7 step:5916 [D loss: 0.690886, acc: 53.91%] [G loss: 1.644701]\n",
      "epoch:7 step:5917 [D loss: 0.649064, acc: 64.84%] [G loss: 1.743347]\n",
      "epoch:7 step:5918 [D loss: 0.626626, acc: 65.62%] [G loss: 2.123114]\n",
      "epoch:7 step:5919 [D loss: 0.587576, acc: 68.75%] [G loss: 1.626065]\n",
      "epoch:7 step:5920 [D loss: 0.570572, acc: 74.22%] [G loss: 1.765115]\n",
      "epoch:7 step:5921 [D loss: 0.710611, acc: 46.88%] [G loss: 1.792796]\n",
      "epoch:7 step:5922 [D loss: 0.631616, acc: 67.97%] [G loss: 1.619635]\n",
      "epoch:7 step:5923 [D loss: 0.716297, acc: 47.66%] [G loss: 1.561628]\n",
      "epoch:7 step:5924 [D loss: 0.713630, acc: 49.22%] [G loss: 1.715040]\n",
      "epoch:7 step:5925 [D loss: 0.542816, acc: 79.69%] [G loss: 1.821998]\n",
      "epoch:7 step:5926 [D loss: 0.417394, acc: 92.97%] [G loss: 1.978747]\n",
      "epoch:7 step:5927 [D loss: 0.608288, acc: 71.09%] [G loss: 1.743688]\n",
      "epoch:7 step:5928 [D loss: 0.712269, acc: 52.34%] [G loss: 1.660738]\n",
      "epoch:7 step:5929 [D loss: 0.564330, acc: 75.78%] [G loss: 1.664764]\n",
      "epoch:7 step:5930 [D loss: 0.889389, acc: 32.81%] [G loss: 1.626346]\n",
      "epoch:7 step:5931 [D loss: 0.556891, acc: 75.00%] [G loss: 1.931973]\n",
      "epoch:7 step:5932 [D loss: 0.662136, acc: 54.69%] [G loss: 1.935823]\n",
      "epoch:7 step:5933 [D loss: 0.627560, acc: 64.06%] [G loss: 1.847451]\n",
      "epoch:7 step:5934 [D loss: 0.843364, acc: 30.47%] [G loss: 1.727661]\n",
      "epoch:7 step:5935 [D loss: 0.614885, acc: 65.62%] [G loss: 1.567350]\n",
      "epoch:7 step:5936 [D loss: 0.635515, acc: 67.97%] [G loss: 1.823954]\n",
      "epoch:7 step:5937 [D loss: 0.776909, acc: 39.84%] [G loss: 1.525711]\n",
      "epoch:7 step:5938 [D loss: 0.637914, acc: 67.19%] [G loss: 1.733573]\n",
      "epoch:7 step:5939 [D loss: 0.878180, acc: 33.59%] [G loss: 1.515663]\n",
      "epoch:7 step:5940 [D loss: 0.827225, acc: 28.91%] [G loss: 1.703603]\n",
      "epoch:7 step:5941 [D loss: 0.523670, acc: 80.47%] [G loss: 1.682781]\n",
      "epoch:7 step:5942 [D loss: 0.557770, acc: 77.34%] [G loss: 1.889356]\n",
      "epoch:7 step:5943 [D loss: 0.762766, acc: 52.34%] [G loss: 1.649352]\n",
      "epoch:7 step:5944 [D loss: 0.724701, acc: 53.91%] [G loss: 1.608900]\n",
      "epoch:7 step:5945 [D loss: 0.614912, acc: 66.41%] [G loss: 1.560404]\n",
      "epoch:7 step:5946 [D loss: 0.666203, acc: 61.72%] [G loss: 1.630969]\n",
      "epoch:7 step:5947 [D loss: 0.855074, acc: 32.03%] [G loss: 1.761780]\n",
      "epoch:7 step:5948 [D loss: 0.994807, acc: 17.97%] [G loss: 1.697258]\n",
      "epoch:7 step:5949 [D loss: 0.823635, acc: 36.72%] [G loss: 1.571908]\n",
      "epoch:7 step:5950 [D loss: 0.453928, acc: 89.84%] [G loss: 1.738434]\n",
      "epoch:7 step:5951 [D loss: 0.703794, acc: 53.12%] [G loss: 1.584493]\n",
      "epoch:7 step:5952 [D loss: 0.561228, acc: 77.34%] [G loss: 1.677364]\n",
      "epoch:7 step:5953 [D loss: 0.682144, acc: 50.78%] [G loss: 1.749514]\n",
      "epoch:7 step:5954 [D loss: 0.736700, acc: 49.22%] [G loss: 1.707638]\n",
      "epoch:7 step:5955 [D loss: 0.689495, acc: 53.91%] [G loss: 1.562503]\n",
      "epoch:7 step:5956 [D loss: 0.637268, acc: 64.84%] [G loss: 1.942960]\n",
      "epoch:7 step:5957 [D loss: 0.734437, acc: 49.22%] [G loss: 1.702464]\n",
      "epoch:7 step:5958 [D loss: 0.656547, acc: 60.16%] [G loss: 1.944805]\n",
      "epoch:7 step:5959 [D loss: 0.748804, acc: 47.66%] [G loss: 1.736982]\n",
      "epoch:7 step:5960 [D loss: 0.740016, acc: 48.44%] [G loss: 1.883186]\n",
      "epoch:7 step:5961 [D loss: 0.568806, acc: 77.34%] [G loss: 1.624274]\n",
      "epoch:7 step:5962 [D loss: 0.531645, acc: 81.25%] [G loss: 1.934004]\n",
      "epoch:7 step:5963 [D loss: 0.661599, acc: 57.03%] [G loss: 1.752085]\n",
      "epoch:7 step:5964 [D loss: 0.637032, acc: 64.84%] [G loss: 2.064045]\n",
      "epoch:7 step:5965 [D loss: 0.776214, acc: 42.97%] [G loss: 1.839872]\n",
      "epoch:7 step:5966 [D loss: 0.759322, acc: 48.44%] [G loss: 1.674756]\n",
      "epoch:7 step:5967 [D loss: 0.686633, acc: 56.25%] [G loss: 1.571576]\n",
      "epoch:7 step:5968 [D loss: 0.620524, acc: 65.62%] [G loss: 1.729575]\n",
      "epoch:7 step:5969 [D loss: 0.621311, acc: 64.84%] [G loss: 1.826759]\n",
      "epoch:7 step:5970 [D loss: 0.726173, acc: 46.88%] [G loss: 1.434918]\n",
      "epoch:7 step:5971 [D loss: 0.851310, acc: 32.03%] [G loss: 1.539463]\n",
      "epoch:7 step:5972 [D loss: 0.841023, acc: 35.16%] [G loss: 1.514033]\n",
      "epoch:7 step:5973 [D loss: 0.586514, acc: 72.66%] [G loss: 1.550970]\n",
      "epoch:7 step:5974 [D loss: 0.715804, acc: 45.31%] [G loss: 1.635604]\n",
      "epoch:7 step:5975 [D loss: 0.801900, acc: 36.72%] [G loss: 1.522761]\n",
      "epoch:7 step:5976 [D loss: 0.672354, acc: 57.03%] [G loss: 1.933867]\n",
      "epoch:7 step:5977 [D loss: 0.567336, acc: 76.56%] [G loss: 1.762578]\n",
      "epoch:7 step:5978 [D loss: 0.917761, acc: 22.66%] [G loss: 1.658136]\n",
      "epoch:7 step:5979 [D loss: 0.770001, acc: 42.97%] [G loss: 1.356765]\n",
      "epoch:7 step:5980 [D loss: 0.559762, acc: 78.12%] [G loss: 1.435503]\n",
      "epoch:7 step:5981 [D loss: 0.673854, acc: 52.34%] [G loss: 1.645983]\n",
      "epoch:7 step:5982 [D loss: 0.638168, acc: 64.06%] [G loss: 1.694342]\n",
      "epoch:7 step:5983 [D loss: 0.733393, acc: 48.44%] [G loss: 1.722257]\n",
      "epoch:7 step:5984 [D loss: 0.621742, acc: 66.41%] [G loss: 1.726254]\n",
      "epoch:7 step:5985 [D loss: 0.686563, acc: 57.03%] [G loss: 1.643277]\n",
      "epoch:7 step:5986 [D loss: 0.973453, acc: 18.75%] [G loss: 1.357710]\n",
      "epoch:7 step:5987 [D loss: 0.613984, acc: 69.53%] [G loss: 1.705480]\n",
      "epoch:7 step:5988 [D loss: 0.621901, acc: 74.22%] [G loss: 1.921832]\n",
      "epoch:7 step:5989 [D loss: 0.628941, acc: 66.41%] [G loss: 1.703165]\n",
      "epoch:7 step:5990 [D loss: 0.522106, acc: 85.94%] [G loss: 1.741194]\n",
      "epoch:7 step:5991 [D loss: 0.669274, acc: 59.38%] [G loss: 1.657300]\n",
      "epoch:7 step:5992 [D loss: 0.637519, acc: 65.62%] [G loss: 1.673811]\n",
      "epoch:7 step:5993 [D loss: 0.809297, acc: 42.19%] [G loss: 1.680143]\n",
      "epoch:7 step:5994 [D loss: 0.630855, acc: 64.84%] [G loss: 2.182065]\n",
      "epoch:7 step:5995 [D loss: 0.671036, acc: 58.59%] [G loss: 1.794312]\n",
      "epoch:7 step:5996 [D loss: 0.570134, acc: 74.22%] [G loss: 2.153305]\n",
      "epoch:7 step:5997 [D loss: 0.690922, acc: 50.78%] [G loss: 1.897010]\n",
      "epoch:7 step:5998 [D loss: 0.620233, acc: 61.72%] [G loss: 1.771664]\n",
      "epoch:7 step:5999 [D loss: 0.644794, acc: 60.16%] [G loss: 2.172531]\n",
      "epoch:7 step:6000 [D loss: 0.640193, acc: 65.62%] [G loss: 1.800092]\n",
      "##############\n",
      "[0.8544421  0.88976916 0.81495318 0.83010751 0.79613826 0.84002984\n",
      " 0.88747181 0.83637733 0.7925507  0.8476474 ]\n",
      "##########\n",
      "epoch:7 step:6001 [D loss: 0.690471, acc: 58.59%] [G loss: 1.809248]\n",
      "epoch:7 step:6002 [D loss: 0.580302, acc: 71.88%] [G loss: 1.605933]\n",
      "epoch:7 step:6003 [D loss: 0.682500, acc: 58.59%] [G loss: 1.557654]\n",
      "epoch:7 step:6004 [D loss: 0.613259, acc: 62.50%] [G loss: 1.671624]\n",
      "epoch:7 step:6005 [D loss: 0.741629, acc: 50.78%] [G loss: 1.602182]\n",
      "epoch:7 step:6006 [D loss: 0.611551, acc: 70.31%] [G loss: 1.513438]\n",
      "epoch:7 step:6007 [D loss: 0.642860, acc: 58.59%] [G loss: 1.461695]\n",
      "epoch:7 step:6008 [D loss: 0.651324, acc: 65.62%] [G loss: 1.536155]\n",
      "epoch:7 step:6009 [D loss: 0.692413, acc: 54.69%] [G loss: 1.603571]\n",
      "epoch:7 step:6010 [D loss: 0.729793, acc: 51.56%] [G loss: 1.411584]\n",
      "epoch:7 step:6011 [D loss: 0.773772, acc: 41.41%] [G loss: 1.558531]\n",
      "epoch:7 step:6012 [D loss: 0.821125, acc: 32.81%] [G loss: 1.419054]\n",
      "epoch:7 step:6013 [D loss: 0.763988, acc: 50.00%] [G loss: 1.394875]\n",
      "epoch:7 step:6014 [D loss: 0.537597, acc: 79.69%] [G loss: 1.749927]\n",
      "epoch:7 step:6015 [D loss: 0.630427, acc: 62.50%] [G loss: 2.106085]\n",
      "epoch:7 step:6016 [D loss: 0.639739, acc: 60.94%] [G loss: 1.698568]\n",
      "epoch:7 step:6017 [D loss: 0.630054, acc: 65.62%] [G loss: 2.107983]\n",
      "epoch:7 step:6018 [D loss: 0.551435, acc: 75.00%] [G loss: 1.721257]\n",
      "epoch:7 step:6019 [D loss: 0.726858, acc: 50.78%] [G loss: 1.657436]\n",
      "epoch:7 step:6020 [D loss: 0.803046, acc: 45.31%] [G loss: 2.024682]\n",
      "epoch:7 step:6021 [D loss: 0.381296, acc: 89.84%] [G loss: 1.899643]\n",
      "epoch:7 step:6022 [D loss: 0.742926, acc: 47.66%] [G loss: 1.526150]\n",
      "epoch:7 step:6023 [D loss: 0.663532, acc: 66.41%] [G loss: 1.680813]\n",
      "epoch:7 step:6024 [D loss: 0.667814, acc: 64.06%] [G loss: 1.719593]\n",
      "epoch:7 step:6025 [D loss: 0.638826, acc: 62.50%] [G loss: 1.631156]\n",
      "epoch:7 step:6026 [D loss: 0.543179, acc: 78.91%] [G loss: 2.357620]\n",
      "epoch:7 step:6027 [D loss: 0.495419, acc: 71.09%] [G loss: 1.633209]\n",
      "epoch:7 step:6028 [D loss: 0.687941, acc: 57.81%] [G loss: 1.988956]\n",
      "epoch:7 step:6029 [D loss: 0.726661, acc: 46.88%] [G loss: 1.690217]\n",
      "epoch:7 step:6030 [D loss: 0.662773, acc: 57.81%] [G loss: 1.686582]\n",
      "epoch:7 step:6031 [D loss: 0.702760, acc: 50.78%] [G loss: 1.599748]\n",
      "epoch:7 step:6032 [D loss: 0.659718, acc: 57.81%] [G loss: 1.397570]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:7 step:6033 [D loss: 0.802817, acc: 36.72%] [G loss: 1.623341]\n",
      "epoch:7 step:6034 [D loss: 0.687146, acc: 57.03%] [G loss: 1.749365]\n",
      "epoch:7 step:6035 [D loss: 0.535696, acc: 78.91%] [G loss: 1.767732]\n",
      "epoch:7 step:6036 [D loss: 0.708076, acc: 53.12%] [G loss: 1.698040]\n",
      "epoch:7 step:6037 [D loss: 0.598084, acc: 69.53%] [G loss: 1.817063]\n",
      "epoch:7 step:6038 [D loss: 0.670756, acc: 54.69%] [G loss: 1.726124]\n",
      "epoch:7 step:6039 [D loss: 0.624109, acc: 64.84%] [G loss: 1.826111]\n",
      "epoch:7 step:6040 [D loss: 0.598436, acc: 71.88%] [G loss: 1.754531]\n",
      "epoch:7 step:6041 [D loss: 0.881057, acc: 25.00%] [G loss: 1.452535]\n",
      "epoch:7 step:6042 [D loss: 0.738441, acc: 48.44%] [G loss: 1.629241]\n",
      "epoch:7 step:6043 [D loss: 0.718913, acc: 50.00%] [G loss: 1.715390]\n",
      "epoch:7 step:6044 [D loss: 0.656458, acc: 59.38%] [G loss: 2.085012]\n",
      "epoch:7 step:6045 [D loss: 0.412034, acc: 74.22%] [G loss: 2.484322]\n",
      "epoch:7 step:6046 [D loss: 0.643817, acc: 67.19%] [G loss: 1.797488]\n",
      "epoch:7 step:6047 [D loss: 0.583441, acc: 75.00%] [G loss: 2.172653]\n",
      "epoch:7 step:6048 [D loss: 0.665581, acc: 59.38%] [G loss: 1.947608]\n",
      "epoch:7 step:6049 [D loss: 0.465862, acc: 89.06%] [G loss: 2.044137]\n",
      "epoch:7 step:6050 [D loss: 0.733100, acc: 53.12%] [G loss: 1.654418]\n",
      "epoch:7 step:6051 [D loss: 0.751022, acc: 49.22%] [G loss: 1.671530]\n",
      "epoch:7 step:6052 [D loss: 0.694307, acc: 52.34%] [G loss: 1.630224]\n",
      "epoch:7 step:6053 [D loss: 0.570071, acc: 77.34%] [G loss: 1.672274]\n",
      "epoch:7 step:6054 [D loss: 0.769823, acc: 43.75%] [G loss: 1.547868]\n",
      "epoch:7 step:6055 [D loss: 0.828014, acc: 33.59%] [G loss: 1.849511]\n",
      "epoch:7 step:6056 [D loss: 0.778774, acc: 32.03%] [G loss: 1.397342]\n",
      "epoch:7 step:6057 [D loss: 0.606837, acc: 68.75%] [G loss: 1.664361]\n",
      "epoch:7 step:6058 [D loss: 0.601578, acc: 71.09%] [G loss: 1.834350]\n",
      "epoch:7 step:6059 [D loss: 0.599676, acc: 74.22%] [G loss: 1.813604]\n",
      "epoch:7 step:6060 [D loss: 0.703098, acc: 50.00%] [G loss: 1.755234]\n",
      "epoch:7 step:6061 [D loss: 0.870577, acc: 26.56%] [G loss: 1.584207]\n",
      "epoch:7 step:6062 [D loss: 0.639739, acc: 67.97%] [G loss: 1.661794]\n",
      "epoch:7 step:6063 [D loss: 0.573800, acc: 65.62%] [G loss: 2.190719]\n",
      "epoch:7 step:6064 [D loss: 0.882851, acc: 24.22%] [G loss: 1.498577]\n",
      "epoch:7 step:6065 [D loss: 0.628423, acc: 67.97%] [G loss: 1.887855]\n",
      "epoch:7 step:6066 [D loss: 0.647513, acc: 58.59%] [G loss: 1.965499]\n",
      "epoch:7 step:6067 [D loss: 0.564012, acc: 70.31%] [G loss: 1.596481]\n",
      "epoch:7 step:6068 [D loss: 0.624841, acc: 69.53%] [G loss: 1.609188]\n",
      "epoch:7 step:6069 [D loss: 0.632002, acc: 63.28%] [G loss: 1.799976]\n",
      "epoch:7 step:6070 [D loss: 0.966767, acc: 15.62%] [G loss: 1.349255]\n",
      "epoch:7 step:6071 [D loss: 0.694149, acc: 56.25%] [G loss: 1.944798]\n",
      "epoch:7 step:6072 [D loss: 0.678717, acc: 61.72%] [G loss: 1.767167]\n",
      "epoch:7 step:6073 [D loss: 0.740712, acc: 45.31%] [G loss: 1.741404]\n",
      "epoch:7 step:6074 [D loss: 0.699740, acc: 57.81%] [G loss: 1.638540]\n",
      "epoch:7 step:6075 [D loss: 0.707711, acc: 48.44%] [G loss: 1.725008]\n",
      "epoch:7 step:6076 [D loss: 0.714550, acc: 57.81%] [G loss: 1.651020]\n",
      "epoch:7 step:6077 [D loss: 0.840969, acc: 33.59%] [G loss: 1.368714]\n",
      "epoch:7 step:6078 [D loss: 0.673279, acc: 60.16%] [G loss: 1.768735]\n",
      "epoch:7 step:6079 [D loss: 0.603780, acc: 66.41%] [G loss: 1.574526]\n",
      "epoch:7 step:6080 [D loss: 0.856699, acc: 28.12%] [G loss: 1.570123]\n",
      "epoch:7 step:6081 [D loss: 0.618288, acc: 67.19%] [G loss: 1.581446]\n",
      "epoch:7 step:6082 [D loss: 0.590644, acc: 71.88%] [G loss: 1.960351]\n",
      "epoch:7 step:6083 [D loss: 0.844219, acc: 22.66%] [G loss: 1.510933]\n",
      "epoch:7 step:6084 [D loss: 0.656344, acc: 58.59%] [G loss: 1.656878]\n",
      "epoch:7 step:6085 [D loss: 0.570830, acc: 66.41%] [G loss: 1.731665]\n",
      "epoch:7 step:6086 [D loss: 0.751293, acc: 40.62%] [G loss: 1.494964]\n",
      "epoch:7 step:6087 [D loss: 0.822259, acc: 39.84%] [G loss: 1.702980]\n",
      "epoch:7 step:6088 [D loss: 0.643360, acc: 67.97%] [G loss: 1.614564]\n",
      "epoch:7 step:6089 [D loss: 0.630398, acc: 75.00%] [G loss: 1.600852]\n",
      "epoch:7 step:6090 [D loss: 0.780896, acc: 46.88%] [G loss: 1.558864]\n",
      "epoch:7 step:6091 [D loss: 0.758531, acc: 44.53%] [G loss: 1.490893]\n",
      "epoch:7 step:6092 [D loss: 0.698190, acc: 57.03%] [G loss: 1.552901]\n",
      "epoch:7 step:6093 [D loss: 0.641392, acc: 73.44%] [G loss: 1.535895]\n",
      "epoch:7 step:6094 [D loss: 0.650205, acc: 60.94%] [G loss: 1.606369]\n",
      "epoch:7 step:6095 [D loss: 0.581342, acc: 73.44%] [G loss: 1.769609]\n",
      "epoch:7 step:6096 [D loss: 0.792885, acc: 34.38%] [G loss: 1.427620]\n",
      "epoch:7 step:6097 [D loss: 0.678926, acc: 56.25%] [G loss: 1.668716]\n",
      "epoch:7 step:6098 [D loss: 0.640383, acc: 60.94%] [G loss: 1.738445]\n",
      "epoch:7 step:6099 [D loss: 0.871515, acc: 23.44%] [G loss: 1.342590]\n",
      "epoch:7 step:6100 [D loss: 0.808283, acc: 32.81%] [G loss: 1.541356]\n",
      "epoch:7 step:6101 [D loss: 0.609223, acc: 70.31%] [G loss: 1.703331]\n",
      "epoch:7 step:6102 [D loss: 0.612448, acc: 71.88%] [G loss: 1.554002]\n",
      "epoch:7 step:6103 [D loss: 0.670260, acc: 59.38%] [G loss: 1.963327]\n",
      "epoch:7 step:6104 [D loss: 0.540167, acc: 73.44%] [G loss: 1.743157]\n",
      "epoch:7 step:6105 [D loss: 0.717537, acc: 53.12%] [G loss: 1.576957]\n",
      "epoch:7 step:6106 [D loss: 0.634798, acc: 64.06%] [G loss: 1.774805]\n",
      "epoch:7 step:6107 [D loss: 0.549825, acc: 79.69%] [G loss: 1.775531]\n",
      "epoch:7 step:6108 [D loss: 0.741967, acc: 43.75%] [G loss: 1.674484]\n",
      "epoch:7 step:6109 [D loss: 0.614310, acc: 64.84%] [G loss: 1.837618]\n",
      "epoch:7 step:6110 [D loss: 0.683888, acc: 53.12%] [G loss: 1.724426]\n",
      "epoch:7 step:6111 [D loss: 0.609590, acc: 70.31%] [G loss: 1.826568]\n",
      "epoch:7 step:6112 [D loss: 0.626873, acc: 65.62%] [G loss: 1.675484]\n",
      "epoch:7 step:6113 [D loss: 0.626999, acc: 69.53%] [G loss: 1.828073]\n",
      "epoch:7 step:6114 [D loss: 0.680679, acc: 56.25%] [G loss: 1.731361]\n",
      "epoch:7 step:6115 [D loss: 0.563920, acc: 79.69%] [G loss: 1.838278]\n",
      "epoch:7 step:6116 [D loss: 0.832947, acc: 31.25%] [G loss: 1.682057]\n",
      "epoch:7 step:6117 [D loss: 0.460872, acc: 89.06%] [G loss: 2.121738]\n",
      "epoch:7 step:6118 [D loss: 0.571789, acc: 74.22%] [G loss: 1.814779]\n",
      "epoch:7 step:6119 [D loss: 0.574222, acc: 76.56%] [G loss: 1.913348]\n",
      "epoch:7 step:6120 [D loss: 0.696798, acc: 54.69%] [G loss: 1.754211]\n",
      "epoch:7 step:6121 [D loss: 0.744391, acc: 52.34%] [G loss: 1.587903]\n",
      "epoch:7 step:6122 [D loss: 0.425384, acc: 90.62%] [G loss: 2.258571]\n",
      "epoch:7 step:6123 [D loss: 0.671956, acc: 57.81%] [G loss: 1.731982]\n",
      "epoch:7 step:6124 [D loss: 0.704819, acc: 52.34%] [G loss: 1.913975]\n",
      "epoch:7 step:6125 [D loss: 0.671511, acc: 56.25%] [G loss: 1.712259]\n",
      "epoch:7 step:6126 [D loss: 0.676879, acc: 57.81%] [G loss: 1.875483]\n",
      "epoch:7 step:6127 [D loss: 0.722913, acc: 49.22%] [G loss: 1.780758]\n",
      "epoch:7 step:6128 [D loss: 0.656475, acc: 55.47%] [G loss: 1.578308]\n",
      "epoch:7 step:6129 [D loss: 0.603392, acc: 70.31%] [G loss: 2.145475]\n",
      "epoch:7 step:6130 [D loss: 0.770105, acc: 45.31%] [G loss: 1.664072]\n",
      "epoch:7 step:6131 [D loss: 0.511538, acc: 86.72%] [G loss: 2.190281]\n",
      "epoch:7 step:6132 [D loss: 0.719917, acc: 47.66%] [G loss: 1.909438]\n",
      "epoch:7 step:6133 [D loss: 0.376232, acc: 92.19%] [G loss: 1.938383]\n",
      "epoch:7 step:6134 [D loss: 0.692699, acc: 57.03%] [G loss: 1.851825]\n",
      "epoch:7 step:6135 [D loss: 0.374628, acc: 92.97%] [G loss: 1.926652]\n",
      "epoch:7 step:6136 [D loss: 0.948018, acc: 15.62%] [G loss: 1.635713]\n",
      "epoch:7 step:6137 [D loss: 0.951568, acc: 13.28%] [G loss: 1.602609]\n",
      "epoch:7 step:6138 [D loss: 0.797897, acc: 35.94%] [G loss: 1.661323]\n",
      "epoch:7 step:6139 [D loss: 0.676607, acc: 60.16%] [G loss: 1.667202]\n",
      "epoch:7 step:6140 [D loss: 0.667614, acc: 62.50%] [G loss: 1.958602]\n",
      "epoch:7 step:6141 [D loss: 0.638152, acc: 63.28%] [G loss: 2.051124]\n",
      "epoch:7 step:6142 [D loss: 0.702230, acc: 51.56%] [G loss: 1.945640]\n",
      "epoch:7 step:6143 [D loss: 0.958151, acc: 19.53%] [G loss: 1.694699]\n",
      "epoch:7 step:6144 [D loss: 0.717256, acc: 53.91%] [G loss: 2.190149]\n",
      "epoch:7 step:6145 [D loss: 0.669109, acc: 64.84%] [G loss: 1.706064]\n",
      "epoch:7 step:6146 [D loss: 0.766677, acc: 36.72%] [G loss: 1.514591]\n",
      "epoch:7 step:6147 [D loss: 0.669490, acc: 62.50%] [G loss: 1.689118]\n",
      "epoch:7 step:6148 [D loss: 0.742791, acc: 44.53%] [G loss: 1.967910]\n",
      "epoch:7 step:6149 [D loss: 0.631799, acc: 62.50%] [G loss: 1.798129]\n",
      "epoch:7 step:6150 [D loss: 0.599400, acc: 69.53%] [G loss: 1.877393]\n",
      "epoch:7 step:6151 [D loss: 0.942258, acc: 21.09%] [G loss: 1.576327]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:7 step:6152 [D loss: 0.587597, acc: 72.66%] [G loss: 1.804540]\n",
      "epoch:7 step:6153 [D loss: 0.552045, acc: 75.78%] [G loss: 1.855921]\n",
      "epoch:7 step:6154 [D loss: 0.756040, acc: 48.44%] [G loss: 1.881374]\n",
      "epoch:7 step:6155 [D loss: 0.894801, acc: 41.41%] [G loss: 1.426887]\n",
      "epoch:7 step:6156 [D loss: 0.592455, acc: 75.00%] [G loss: 1.560193]\n",
      "epoch:7 step:6157 [D loss: 0.563028, acc: 82.81%] [G loss: 1.602711]\n",
      "epoch:7 step:6158 [D loss: 0.930343, acc: 21.88%] [G loss: 1.446338]\n",
      "epoch:7 step:6159 [D loss: 0.588149, acc: 78.12%] [G loss: 1.794986]\n",
      "epoch:7 step:6160 [D loss: 0.749754, acc: 47.66%] [G loss: 1.535663]\n",
      "epoch:7 step:6161 [D loss: 0.831146, acc: 28.12%] [G loss: 1.658671]\n",
      "epoch:7 step:6162 [D loss: 0.608701, acc: 73.44%] [G loss: 1.596813]\n",
      "epoch:7 step:6163 [D loss: 0.767290, acc: 39.84%] [G loss: 1.499048]\n",
      "epoch:7 step:6164 [D loss: 0.688095, acc: 57.81%] [G loss: 1.679555]\n",
      "epoch:7 step:6165 [D loss: 0.616273, acc: 67.19%] [G loss: 1.677526]\n",
      "epoch:7 step:6166 [D loss: 0.927627, acc: 20.31%] [G loss: 1.578923]\n",
      "epoch:7 step:6167 [D loss: 0.585583, acc: 76.56%] [G loss: 1.549590]\n",
      "epoch:7 step:6168 [D loss: 0.666543, acc: 57.03%] [G loss: 1.592310]\n",
      "epoch:7 step:6169 [D loss: 0.668870, acc: 57.81%] [G loss: 1.690453]\n",
      "epoch:7 step:6170 [D loss: 0.697942, acc: 57.81%] [G loss: 1.736149]\n",
      "epoch:7 step:6171 [D loss: 0.718468, acc: 50.00%] [G loss: 1.712519]\n",
      "epoch:7 step:6172 [D loss: 0.648902, acc: 67.19%] [G loss: 1.701043]\n",
      "epoch:7 step:6173 [D loss: 0.702104, acc: 55.47%] [G loss: 1.730142]\n",
      "epoch:7 step:6174 [D loss: 0.569582, acc: 76.56%] [G loss: 1.664073]\n",
      "epoch:7 step:6175 [D loss: 0.618134, acc: 68.75%] [G loss: 1.697390]\n",
      "epoch:7 step:6176 [D loss: 0.642631, acc: 67.19%] [G loss: 1.571118]\n",
      "epoch:7 step:6177 [D loss: 0.608390, acc: 72.66%] [G loss: 1.567440]\n",
      "epoch:7 step:6178 [D loss: 0.573186, acc: 72.66%] [G loss: 2.094465]\n",
      "epoch:7 step:6179 [D loss: 0.468042, acc: 85.16%] [G loss: 2.273846]\n",
      "epoch:7 step:6180 [D loss: 0.881660, acc: 32.81%] [G loss: 1.800879]\n",
      "epoch:7 step:6181 [D loss: 0.639017, acc: 67.97%] [G loss: 1.645116]\n",
      "epoch:7 step:6182 [D loss: 0.827624, acc: 44.53%] [G loss: 1.823371]\n",
      "epoch:7 step:6183 [D loss: 0.572737, acc: 75.00%] [G loss: 1.776163]\n",
      "epoch:7 step:6184 [D loss: 0.606917, acc: 67.97%] [G loss: 1.807090]\n",
      "epoch:7 step:6185 [D loss: 0.708197, acc: 56.25%] [G loss: 1.787697]\n",
      "epoch:7 step:6186 [D loss: 0.729275, acc: 45.31%] [G loss: 1.799395]\n",
      "epoch:7 step:6187 [D loss: 0.711501, acc: 50.78%] [G loss: 1.611887]\n",
      "epoch:7 step:6188 [D loss: 0.645485, acc: 63.28%] [G loss: 1.850402]\n",
      "epoch:7 step:6189 [D loss: 0.625986, acc: 67.97%] [G loss: 1.879793]\n",
      "epoch:7 step:6190 [D loss: 0.691773, acc: 56.25%] [G loss: 1.993525]\n",
      "epoch:7 step:6191 [D loss: 0.478109, acc: 84.38%] [G loss: 1.866739]\n",
      "epoch:7 step:6192 [D loss: 0.623884, acc: 68.75%] [G loss: 1.921365]\n",
      "epoch:7 step:6193 [D loss: 0.716033, acc: 47.66%] [G loss: 1.781165]\n",
      "epoch:7 step:6194 [D loss: 0.814557, acc: 34.38%] [G loss: 1.774482]\n",
      "epoch:7 step:6195 [D loss: 0.636329, acc: 64.84%] [G loss: 1.859973]\n",
      "epoch:7 step:6196 [D loss: 0.489416, acc: 78.91%] [G loss: 1.747282]\n",
      "epoch:7 step:6197 [D loss: 0.732344, acc: 52.34%] [G loss: 1.774928]\n",
      "epoch:7 step:6198 [D loss: 0.578840, acc: 71.09%] [G loss: 1.912579]\n",
      "epoch:7 step:6199 [D loss: 0.702768, acc: 50.78%] [G loss: 1.629018]\n",
      "epoch:7 step:6200 [D loss: 0.611329, acc: 69.53%] [G loss: 1.649387]\n",
      "##############\n",
      "[0.85719099 0.87996826 0.81988441 0.81955526 0.79300727 0.82625047\n",
      " 0.88023314 0.82776232 0.80887104 0.84752942]\n",
      "##########\n",
      "epoch:7 step:6201 [D loss: 0.753489, acc: 40.62%] [G loss: 1.593243]\n",
      "epoch:7 step:6202 [D loss: 0.462331, acc: 92.19%] [G loss: 1.910267]\n",
      "epoch:7 step:6203 [D loss: 0.580264, acc: 72.66%] [G loss: 2.334705]\n",
      "epoch:7 step:6204 [D loss: 0.600712, acc: 67.19%] [G loss: 2.042482]\n",
      "epoch:7 step:6205 [D loss: 0.728241, acc: 54.69%] [G loss: 1.673139]\n",
      "epoch:7 step:6206 [D loss: 0.750762, acc: 46.88%] [G loss: 1.828620]\n",
      "epoch:7 step:6207 [D loss: 0.716779, acc: 51.56%] [G loss: 1.522733]\n",
      "epoch:7 step:6208 [D loss: 0.503872, acc: 84.38%] [G loss: 1.855534]\n",
      "epoch:7 step:6209 [D loss: 0.717520, acc: 50.00%] [G loss: 1.994895]\n",
      "epoch:7 step:6210 [D loss: 0.713823, acc: 55.47%] [G loss: 1.888419]\n",
      "epoch:7 step:6211 [D loss: 0.550220, acc: 71.09%] [G loss: 2.092139]\n",
      "epoch:7 step:6212 [D loss: 0.517801, acc: 80.47%] [G loss: 1.633400]\n",
      "epoch:7 step:6213 [D loss: 0.596053, acc: 65.62%] [G loss: 2.223813]\n",
      "epoch:7 step:6214 [D loss: 0.606858, acc: 67.19%] [G loss: 1.863184]\n",
      "epoch:7 step:6215 [D loss: 0.431309, acc: 82.81%] [G loss: 2.148042]\n",
      "epoch:7 step:6216 [D loss: 0.512499, acc: 82.03%] [G loss: 2.094657]\n",
      "epoch:7 step:6217 [D loss: 0.803812, acc: 38.28%] [G loss: 1.567568]\n",
      "epoch:7 step:6218 [D loss: 1.057526, acc: 9.38%] [G loss: 1.309762]\n",
      "epoch:7 step:6219 [D loss: 0.441047, acc: 89.06%] [G loss: 1.440615]\n",
      "epoch:7 step:6220 [D loss: 0.631348, acc: 65.62%] [G loss: 1.935353]\n",
      "epoch:7 step:6221 [D loss: 0.543665, acc: 75.78%] [G loss: 1.959608]\n",
      "epoch:7 step:6222 [D loss: 0.478623, acc: 68.75%] [G loss: 1.530955]\n",
      "epoch:7 step:6223 [D loss: 0.587465, acc: 70.31%] [G loss: 1.889660]\n",
      "epoch:7 step:6224 [D loss: 0.818378, acc: 54.69%] [G loss: 2.126032]\n",
      "epoch:7 step:6225 [D loss: 0.800080, acc: 38.28%] [G loss: 2.457351]\n",
      "epoch:7 step:6226 [D loss: 0.424487, acc: 90.62%] [G loss: 1.781064]\n",
      "epoch:7 step:6227 [D loss: 0.507031, acc: 78.12%] [G loss: 2.451231]\n",
      "epoch:7 step:6228 [D loss: 0.507265, acc: 82.03%] [G loss: 2.716204]\n",
      "epoch:7 step:6229 [D loss: 0.671158, acc: 57.81%] [G loss: 2.374562]\n",
      "epoch:7 step:6230 [D loss: 0.555277, acc: 75.00%] [G loss: 1.954254]\n",
      "epoch:7 step:6231 [D loss: 0.799049, acc: 46.88%] [G loss: 2.235292]\n",
      "epoch:7 step:6232 [D loss: 0.667831, acc: 53.12%] [G loss: 2.901332]\n",
      "epoch:7 step:6233 [D loss: 0.756555, acc: 51.56%] [G loss: 2.114575]\n",
      "epoch:7 step:6234 [D loss: 0.509287, acc: 84.38%] [G loss: 2.145449]\n",
      "epoch:7 step:6235 [D loss: 0.532676, acc: 79.69%] [G loss: 2.159629]\n",
      "epoch:7 step:6236 [D loss: 0.771249, acc: 43.75%] [G loss: 2.562517]\n",
      "epoch:7 step:6237 [D loss: 0.705521, acc: 54.69%] [G loss: 2.675914]\n",
      "epoch:7 step:6238 [D loss: 0.533954, acc: 65.62%] [G loss: 1.870901]\n",
      "epoch:7 step:6239 [D loss: 0.651352, acc: 57.03%] [G loss: 1.802474]\n",
      "epoch:7 step:6240 [D loss: 0.562289, acc: 78.12%] [G loss: 1.503224]\n",
      "epoch:7 step:6241 [D loss: 0.603663, acc: 67.19%] [G loss: 1.776935]\n",
      "epoch:7 step:6242 [D loss: 0.466103, acc: 84.38%] [G loss: 1.757317]\n",
      "epoch:7 step:6243 [D loss: 0.663919, acc: 53.91%] [G loss: 1.683483]\n",
      "epoch:7 step:6244 [D loss: 0.987812, acc: 23.44%] [G loss: 1.355582]\n",
      "epoch:7 step:6245 [D loss: 0.936707, acc: 20.31%] [G loss: 1.690572]\n",
      "epoch:7 step:6246 [D loss: 0.638007, acc: 58.59%] [G loss: 1.942863]\n",
      "epoch:7 step:6247 [D loss: 0.657777, acc: 60.94%] [G loss: 1.751987]\n",
      "epoch:7 step:6248 [D loss: 0.644128, acc: 58.59%] [G loss: 2.477011]\n",
      "epoch:8 step:6249 [D loss: 0.466940, acc: 84.38%] [G loss: 2.545159]\n",
      "epoch:8 step:6250 [D loss: 0.482928, acc: 84.38%] [G loss: 2.734660]\n",
      "epoch:8 step:6251 [D loss: 0.437420, acc: 90.62%] [G loss: 2.702775]\n",
      "epoch:8 step:6252 [D loss: 0.609194, acc: 65.62%] [G loss: 2.108852]\n",
      "epoch:8 step:6253 [D loss: 0.426120, acc: 81.25%] [G loss: 2.610540]\n",
      "epoch:8 step:6254 [D loss: 0.439088, acc: 87.50%] [G loss: 2.141762]\n",
      "epoch:8 step:6255 [D loss: 0.448519, acc: 89.84%] [G loss: 2.426667]\n",
      "epoch:8 step:6256 [D loss: 0.352771, acc: 96.09%] [G loss: 2.042313]\n",
      "epoch:8 step:6257 [D loss: 0.719183, acc: 50.00%] [G loss: 1.623842]\n",
      "epoch:8 step:6258 [D loss: 0.507105, acc: 80.47%] [G loss: 1.809202]\n",
      "epoch:8 step:6259 [D loss: 0.415579, acc: 86.72%] [G loss: 1.851552]\n",
      "epoch:8 step:6260 [D loss: 0.608265, acc: 57.81%] [G loss: 1.777574]\n",
      "epoch:8 step:6261 [D loss: 0.565702, acc: 72.66%] [G loss: 1.535927]\n",
      "epoch:8 step:6262 [D loss: 0.418326, acc: 90.62%] [G loss: 1.733690]\n",
      "epoch:8 step:6263 [D loss: 0.873640, acc: 31.25%] [G loss: 1.316586]\n",
      "epoch:8 step:6264 [D loss: 1.138914, acc: 18.75%] [G loss: 1.289594]\n",
      "epoch:8 step:6265 [D loss: 0.698111, acc: 50.78%] [G loss: 1.640843]\n",
      "epoch:8 step:6266 [D loss: 0.850603, acc: 38.28%] [G loss: 1.755965]\n",
      "epoch:8 step:6267 [D loss: 0.610328, acc: 61.72%] [G loss: 2.336435]\n",
      "epoch:8 step:6268 [D loss: 0.662519, acc: 60.94%] [G loss: 2.010872]\n",
      "epoch:8 step:6269 [D loss: 0.429817, acc: 75.78%] [G loss: 2.942358]\n",
      "epoch:8 step:6270 [D loss: 0.638764, acc: 62.50%] [G loss: 1.998560]\n",
      "epoch:8 step:6271 [D loss: 0.689031, acc: 55.47%] [G loss: 2.368268]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:8 step:6272 [D loss: 0.676115, acc: 58.59%] [G loss: 1.711349]\n",
      "epoch:8 step:6273 [D loss: 0.581382, acc: 65.62%] [G loss: 2.400752]\n",
      "epoch:8 step:6274 [D loss: 0.759901, acc: 43.75%] [G loss: 1.716703]\n",
      "epoch:8 step:6275 [D loss: 0.473225, acc: 86.72%] [G loss: 1.760697]\n",
      "epoch:8 step:6276 [D loss: 0.697671, acc: 52.34%] [G loss: 1.761399]\n",
      "epoch:8 step:6277 [D loss: 0.607939, acc: 68.75%] [G loss: 1.900020]\n",
      "epoch:8 step:6278 [D loss: 0.596606, acc: 71.88%] [G loss: 1.905372]\n",
      "epoch:8 step:6279 [D loss: 0.659420, acc: 60.94%] [G loss: 2.888106]\n",
      "epoch:8 step:6280 [D loss: 0.484594, acc: 82.81%] [G loss: 2.499351]\n",
      "epoch:8 step:6281 [D loss: 0.713343, acc: 51.56%] [G loss: 2.098159]\n",
      "epoch:8 step:6282 [D loss: 0.485208, acc: 82.03%] [G loss: 2.136653]\n",
      "epoch:8 step:6283 [D loss: 0.906479, acc: 28.91%] [G loss: 2.332610]\n",
      "epoch:8 step:6284 [D loss: 0.805568, acc: 35.94%] [G loss: 2.324359]\n",
      "epoch:8 step:6285 [D loss: 0.864869, acc: 34.38%] [G loss: 1.761696]\n",
      "epoch:8 step:6286 [D loss: 0.596108, acc: 70.31%] [G loss: 2.056002]\n",
      "epoch:8 step:6287 [D loss: 0.461322, acc: 87.50%] [G loss: 1.720679]\n",
      "epoch:8 step:6288 [D loss: 0.492534, acc: 84.38%] [G loss: 1.885721]\n",
      "epoch:8 step:6289 [D loss: 0.729970, acc: 53.12%] [G loss: 1.862291]\n",
      "epoch:8 step:6290 [D loss: 0.549624, acc: 69.53%] [G loss: 1.966202]\n",
      "epoch:8 step:6291 [D loss: 0.969424, acc: 39.06%] [G loss: 1.686036]\n",
      "epoch:8 step:6292 [D loss: 0.653361, acc: 60.94%] [G loss: 1.609967]\n",
      "epoch:8 step:6293 [D loss: 0.749930, acc: 50.78%] [G loss: 1.975799]\n",
      "epoch:8 step:6294 [D loss: 0.401199, acc: 91.41%] [G loss: 1.819713]\n",
      "epoch:8 step:6295 [D loss: 0.777623, acc: 42.97%] [G loss: 1.871579]\n",
      "epoch:8 step:6296 [D loss: 0.691243, acc: 57.03%] [G loss: 1.885215]\n",
      "epoch:8 step:6297 [D loss: 0.636191, acc: 53.12%] [G loss: 2.341149]\n",
      "epoch:8 step:6298 [D loss: 0.764404, acc: 54.69%] [G loss: 1.854832]\n",
      "epoch:8 step:6299 [D loss: 0.616084, acc: 63.28%] [G loss: 2.462852]\n",
      "epoch:8 step:6300 [D loss: 0.384806, acc: 80.47%] [G loss: 2.778102]\n",
      "epoch:8 step:6301 [D loss: 0.341108, acc: 94.53%] [G loss: 1.799858]\n",
      "epoch:8 step:6302 [D loss: 0.874150, acc: 39.06%] [G loss: 1.990415]\n",
      "epoch:8 step:6303 [D loss: 0.823305, acc: 36.72%] [G loss: 1.895742]\n",
      "epoch:8 step:6304 [D loss: 0.430475, acc: 82.03%] [G loss: 1.866004]\n",
      "epoch:8 step:6305 [D loss: 0.515972, acc: 84.38%] [G loss: 1.823440]\n",
      "epoch:8 step:6306 [D loss: 1.015868, acc: 26.56%] [G loss: 1.352556]\n",
      "epoch:8 step:6307 [D loss: 0.734416, acc: 53.91%] [G loss: 1.675632]\n",
      "epoch:8 step:6308 [D loss: 0.590892, acc: 73.44%] [G loss: 1.722584]\n",
      "epoch:8 step:6309 [D loss: 0.723034, acc: 51.56%] [G loss: 1.682038]\n",
      "epoch:8 step:6310 [D loss: 0.766109, acc: 44.53%] [G loss: 1.973081]\n",
      "epoch:8 step:6311 [D loss: 0.835849, acc: 41.41%] [G loss: 1.981772]\n",
      "epoch:8 step:6312 [D loss: 0.636761, acc: 60.94%] [G loss: 2.572115]\n",
      "epoch:8 step:6313 [D loss: 0.505623, acc: 85.16%] [G loss: 1.983941]\n",
      "epoch:8 step:6314 [D loss: 0.539682, acc: 75.78%] [G loss: 1.982067]\n",
      "epoch:8 step:6315 [D loss: 0.543665, acc: 77.34%] [G loss: 2.052075]\n",
      "epoch:8 step:6316 [D loss: 0.557657, acc: 75.78%] [G loss: 2.162917]\n",
      "epoch:8 step:6317 [D loss: 0.364224, acc: 87.50%] [G loss: 3.569722]\n",
      "epoch:8 step:6318 [D loss: 0.713360, acc: 54.69%] [G loss: 1.666609]\n",
      "epoch:8 step:6319 [D loss: 0.508777, acc: 80.47%] [G loss: 2.068625]\n",
      "epoch:8 step:6320 [D loss: 0.759995, acc: 52.34%] [G loss: 1.758698]\n",
      "epoch:8 step:6321 [D loss: 0.321955, acc: 97.66%] [G loss: 1.897350]\n",
      "epoch:8 step:6322 [D loss: 0.369809, acc: 89.06%] [G loss: 2.175829]\n",
      "epoch:8 step:6323 [D loss: 0.518550, acc: 78.12%] [G loss: 2.224379]\n",
      "epoch:8 step:6324 [D loss: 0.635030, acc: 63.28%] [G loss: 2.283822]\n",
      "epoch:8 step:6325 [D loss: 0.455777, acc: 86.72%] [G loss: 1.944435]\n",
      "epoch:8 step:6326 [D loss: 0.421372, acc: 88.28%] [G loss: 1.802321]\n",
      "epoch:8 step:6327 [D loss: 0.394092, acc: 89.84%] [G loss: 1.791602]\n",
      "epoch:8 step:6328 [D loss: 0.225402, acc: 98.44%] [G loss: 2.757118]\n",
      "epoch:8 step:6329 [D loss: 0.803144, acc: 57.03%] [G loss: 2.492349]\n",
      "epoch:8 step:6330 [D loss: 0.516605, acc: 75.00%] [G loss: 2.221732]\n",
      "epoch:8 step:6331 [D loss: 0.531402, acc: 74.22%] [G loss: 2.357837]\n",
      "epoch:8 step:6332 [D loss: 1.046339, acc: 25.00%] [G loss: 1.551449]\n",
      "epoch:8 step:6333 [D loss: 0.674132, acc: 62.50%] [G loss: 1.909823]\n",
      "epoch:8 step:6334 [D loss: 0.903195, acc: 31.25%] [G loss: 1.614960]\n",
      "epoch:8 step:6335 [D loss: 0.322345, acc: 96.88%] [G loss: 1.738688]\n",
      "epoch:8 step:6336 [D loss: 0.843221, acc: 33.59%] [G loss: 1.579465]\n",
      "epoch:8 step:6337 [D loss: 0.251552, acc: 96.88%] [G loss: 2.389153]\n",
      "epoch:8 step:6338 [D loss: 0.928661, acc: 23.44%] [G loss: 2.079230]\n",
      "epoch:8 step:6339 [D loss: 0.629265, acc: 61.72%] [G loss: 2.221616]\n",
      "epoch:8 step:6340 [D loss: 0.683156, acc: 53.12%] [G loss: 1.666236]\n",
      "epoch:8 step:6341 [D loss: 0.512022, acc: 81.25%] [G loss: 1.717928]\n",
      "epoch:8 step:6342 [D loss: 0.562154, acc: 78.12%] [G loss: 1.981907]\n",
      "epoch:8 step:6343 [D loss: 0.616789, acc: 67.97%] [G loss: 2.062945]\n",
      "epoch:8 step:6344 [D loss: 0.711982, acc: 53.12%] [G loss: 1.865853]\n",
      "epoch:8 step:6345 [D loss: 0.492028, acc: 68.75%] [G loss: 3.278099]\n",
      "epoch:8 step:6346 [D loss: 0.724105, acc: 53.12%] [G loss: 2.122768]\n",
      "epoch:8 step:6347 [D loss: 0.558504, acc: 73.44%] [G loss: 1.956695]\n",
      "epoch:8 step:6348 [D loss: 0.578775, acc: 64.84%] [G loss: 1.704723]\n",
      "epoch:8 step:6349 [D loss: 0.769550, acc: 50.00%] [G loss: 1.670900]\n",
      "epoch:8 step:6350 [D loss: 0.411299, acc: 90.62%] [G loss: 1.905414]\n",
      "epoch:8 step:6351 [D loss: 0.507837, acc: 78.91%] [G loss: 1.828480]\n",
      "epoch:8 step:6352 [D loss: 0.587389, acc: 71.09%] [G loss: 2.168633]\n",
      "epoch:8 step:6353 [D loss: 0.649694, acc: 64.06%] [G loss: 2.788104]\n",
      "epoch:8 step:6354 [D loss: 0.477593, acc: 85.16%] [G loss: 2.448367]\n",
      "epoch:8 step:6355 [D loss: 0.791811, acc: 52.34%] [G loss: 2.405849]\n",
      "epoch:8 step:6356 [D loss: 0.782855, acc: 46.09%] [G loss: 2.116616]\n",
      "epoch:8 step:6357 [D loss: 0.660079, acc: 61.72%] [G loss: 2.653954]\n",
      "epoch:8 step:6358 [D loss: 0.486421, acc: 82.81%] [G loss: 2.033016]\n",
      "epoch:8 step:6359 [D loss: 0.708514, acc: 51.56%] [G loss: 1.868072]\n",
      "epoch:8 step:6360 [D loss: 0.474424, acc: 91.41%] [G loss: 2.165921]\n",
      "epoch:8 step:6361 [D loss: 0.537855, acc: 77.34%] [G loss: 2.323970]\n",
      "epoch:8 step:6362 [D loss: 0.579987, acc: 67.19%] [G loss: 2.367707]\n",
      "epoch:8 step:6363 [D loss: 0.431771, acc: 71.09%] [G loss: 3.841037]\n",
      "epoch:8 step:6364 [D loss: 0.394884, acc: 87.50%] [G loss: 3.177323]\n",
      "epoch:8 step:6365 [D loss: 0.324228, acc: 92.97%] [G loss: 2.329504]\n",
      "epoch:8 step:6366 [D loss: 0.362814, acc: 91.41%] [G loss: 3.616148]\n",
      "epoch:8 step:6367 [D loss: 0.653094, acc: 55.47%] [G loss: 2.864765]\n",
      "epoch:8 step:6368 [D loss: 0.424450, acc: 72.66%] [G loss: 2.472737]\n",
      "epoch:8 step:6369 [D loss: 0.454289, acc: 81.25%] [G loss: 2.141047]\n",
      "epoch:8 step:6370 [D loss: 0.419871, acc: 91.41%] [G loss: 2.165099]\n",
      "epoch:8 step:6371 [D loss: 0.868994, acc: 50.00%] [G loss: 2.083264]\n",
      "epoch:8 step:6372 [D loss: 0.612105, acc: 66.41%] [G loss: 2.382812]\n",
      "epoch:8 step:6373 [D loss: 0.816905, acc: 56.25%] [G loss: 2.662335]\n",
      "epoch:8 step:6374 [D loss: 0.835983, acc: 36.72%] [G loss: 1.744089]\n",
      "epoch:8 step:6375 [D loss: 0.518403, acc: 79.69%] [G loss: 2.004637]\n",
      "epoch:8 step:6376 [D loss: 0.685474, acc: 54.69%] [G loss: 2.092508]\n",
      "epoch:8 step:6377 [D loss: 0.605236, acc: 65.62%] [G loss: 2.582943]\n",
      "epoch:8 step:6378 [D loss: 0.734863, acc: 52.34%] [G loss: 2.655435]\n",
      "epoch:8 step:6379 [D loss: 0.549117, acc: 75.78%] [G loss: 2.290151]\n",
      "epoch:8 step:6380 [D loss: 0.536844, acc: 78.12%] [G loss: 3.213367]\n",
      "epoch:8 step:6381 [D loss: 0.725461, acc: 50.00%] [G loss: 2.083208]\n",
      "epoch:8 step:6382 [D loss: 0.345701, acc: 89.06%] [G loss: 3.155515]\n",
      "epoch:8 step:6383 [D loss: 0.704561, acc: 55.47%] [G loss: 2.703450]\n",
      "epoch:8 step:6384 [D loss: 0.422990, acc: 87.50%] [G loss: 2.970887]\n",
      "epoch:8 step:6385 [D loss: 0.623683, acc: 63.28%] [G loss: 2.360347]\n",
      "epoch:8 step:6386 [D loss: 0.529147, acc: 80.47%] [G loss: 2.812073]\n",
      "epoch:8 step:6387 [D loss: 0.737218, acc: 51.56%] [G loss: 2.084311]\n",
      "epoch:8 step:6388 [D loss: 0.662753, acc: 57.81%] [G loss: 2.432028]\n",
      "epoch:8 step:6389 [D loss: 0.311417, acc: 86.72%] [G loss: 3.139487]\n",
      "epoch:8 step:6390 [D loss: 0.663046, acc: 63.28%] [G loss: 2.140670]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:8 step:6391 [D loss: 0.589314, acc: 71.09%] [G loss: 2.263458]\n",
      "epoch:8 step:6392 [D loss: 0.615971, acc: 62.50%] [G loss: 2.687463]\n",
      "epoch:8 step:6393 [D loss: 0.600040, acc: 67.19%] [G loss: 2.175071]\n",
      "epoch:8 step:6394 [D loss: 0.725105, acc: 52.34%] [G loss: 2.167299]\n",
      "epoch:8 step:6395 [D loss: 0.295391, acc: 93.75%] [G loss: 3.252736]\n",
      "epoch:8 step:6396 [D loss: 0.998304, acc: 27.34%] [G loss: 2.257788]\n",
      "epoch:8 step:6397 [D loss: 0.406401, acc: 89.84%] [G loss: 4.120632]\n",
      "epoch:8 step:6398 [D loss: 0.423066, acc: 87.50%] [G loss: 2.412863]\n",
      "epoch:8 step:6399 [D loss: 0.754466, acc: 54.69%] [G loss: 3.087715]\n",
      "epoch:8 step:6400 [D loss: 0.314217, acc: 95.31%] [G loss: 2.528057]\n",
      "##############\n",
      "[0.87178404 0.89127259 0.80971956 0.8141156  0.79945694 0.82012376\n",
      " 0.87386182 0.82499859 0.82818675 0.8344902 ]\n",
      "##########\n",
      "epoch:8 step:6401 [D loss: 0.622326, acc: 67.19%] [G loss: 2.122463]\n",
      "epoch:8 step:6402 [D loss: 0.457376, acc: 84.38%] [G loss: 2.717385]\n",
      "epoch:8 step:6403 [D loss: 0.991587, acc: 24.22%] [G loss: 2.424901]\n",
      "epoch:8 step:6404 [D loss: 0.614705, acc: 64.84%] [G loss: 2.331503]\n",
      "epoch:8 step:6405 [D loss: 0.513274, acc: 82.03%] [G loss: 2.141993]\n",
      "epoch:8 step:6406 [D loss: 0.566480, acc: 75.78%] [G loss: 3.966481]\n",
      "epoch:8 step:6407 [D loss: 0.575945, acc: 67.97%] [G loss: 2.250761]\n",
      "epoch:8 step:6408 [D loss: 0.688495, acc: 59.38%] [G loss: 2.702620]\n",
      "epoch:8 step:6409 [D loss: 0.549531, acc: 64.06%] [G loss: 3.883250]\n",
      "epoch:8 step:6410 [D loss: 0.445648, acc: 75.78%] [G loss: 2.524594]\n",
      "epoch:8 step:6411 [D loss: 0.856180, acc: 42.19%] [G loss: 1.888608]\n",
      "epoch:8 step:6412 [D loss: 0.599442, acc: 71.09%] [G loss: 1.880817]\n",
      "epoch:8 step:6413 [D loss: 0.829291, acc: 39.84%] [G loss: 2.039045]\n",
      "epoch:8 step:6414 [D loss: 0.933590, acc: 51.56%] [G loss: 3.069555]\n",
      "epoch:8 step:6415 [D loss: 0.489883, acc: 74.22%] [G loss: 2.574980]\n",
      "epoch:8 step:6416 [D loss: 0.606675, acc: 63.28%] [G loss: 2.258939]\n",
      "epoch:8 step:6417 [D loss: 0.337726, acc: 97.66%] [G loss: 1.766088]\n",
      "epoch:8 step:6418 [D loss: 0.660327, acc: 57.03%] [G loss: 2.322290]\n",
      "epoch:8 step:6419 [D loss: 0.623589, acc: 60.94%] [G loss: 1.979693]\n",
      "epoch:8 step:6420 [D loss: 0.695140, acc: 53.91%] [G loss: 2.090821]\n",
      "epoch:8 step:6421 [D loss: 1.088716, acc: 20.31%] [G loss: 1.635550]\n",
      "epoch:8 step:6422 [D loss: 0.526524, acc: 75.78%] [G loss: 2.533668]\n",
      "epoch:8 step:6423 [D loss: 0.611429, acc: 67.97%] [G loss: 1.996981]\n",
      "epoch:8 step:6424 [D loss: 0.731594, acc: 46.88%] [G loss: 2.909808]\n",
      "epoch:8 step:6425 [D loss: 0.794057, acc: 50.78%] [G loss: 2.029792]\n",
      "epoch:8 step:6426 [D loss: 0.446812, acc: 87.50%] [G loss: 2.669454]\n",
      "epoch:8 step:6427 [D loss: 0.683702, acc: 60.16%] [G loss: 2.010710]\n",
      "epoch:8 step:6428 [D loss: 0.602427, acc: 71.09%] [G loss: 1.917951]\n",
      "epoch:8 step:6429 [D loss: 0.560501, acc: 78.91%] [G loss: 1.823889]\n",
      "epoch:8 step:6430 [D loss: 0.512538, acc: 72.66%] [G loss: 2.398270]\n",
      "epoch:8 step:6431 [D loss: 0.625004, acc: 62.50%] [G loss: 2.337997]\n",
      "epoch:8 step:6432 [D loss: 1.034777, acc: 13.28%] [G loss: 1.541301]\n",
      "epoch:8 step:6433 [D loss: 0.457906, acc: 88.28%] [G loss: 2.176821]\n",
      "epoch:8 step:6434 [D loss: 0.481989, acc: 79.69%] [G loss: 2.306333]\n",
      "epoch:8 step:6435 [D loss: 0.792800, acc: 45.31%] [G loss: 1.990427]\n",
      "epoch:8 step:6436 [D loss: 0.676501, acc: 58.59%] [G loss: 2.159442]\n",
      "epoch:8 step:6437 [D loss: 0.380159, acc: 93.75%] [G loss: 2.255927]\n",
      "epoch:8 step:6438 [D loss: 0.446767, acc: 68.75%] [G loss: 2.054342]\n",
      "epoch:8 step:6439 [D loss: 0.873164, acc: 36.72%] [G loss: 2.174067]\n",
      "epoch:8 step:6440 [D loss: 0.682391, acc: 57.03%] [G loss: 1.947449]\n",
      "epoch:8 step:6441 [D loss: 0.445150, acc: 86.72%] [G loss: 2.088798]\n",
      "epoch:8 step:6442 [D loss: 0.590088, acc: 71.88%] [G loss: 1.768908]\n",
      "epoch:8 step:6443 [D loss: 0.610825, acc: 67.19%] [G loss: 1.689394]\n",
      "epoch:8 step:6444 [D loss: 0.461734, acc: 81.25%] [G loss: 1.831944]\n",
      "epoch:8 step:6445 [D loss: 0.810838, acc: 46.88%] [G loss: 1.489270]\n",
      "epoch:8 step:6446 [D loss: 0.565075, acc: 72.66%] [G loss: 2.053922]\n",
      "epoch:8 step:6447 [D loss: 0.507843, acc: 71.09%] [G loss: 1.948837]\n",
      "epoch:8 step:6448 [D loss: 0.579370, acc: 71.09%] [G loss: 1.963258]\n",
      "epoch:8 step:6449 [D loss: 0.673588, acc: 57.81%] [G loss: 1.682801]\n",
      "epoch:8 step:6450 [D loss: 0.944733, acc: 33.59%] [G loss: 1.561043]\n",
      "epoch:8 step:6451 [D loss: 0.502751, acc: 75.00%] [G loss: 2.359667]\n",
      "epoch:8 step:6452 [D loss: 0.537756, acc: 72.66%] [G loss: 1.817079]\n",
      "epoch:8 step:6453 [D loss: 1.247187, acc: 17.19%] [G loss: 1.976686]\n",
      "epoch:8 step:6454 [D loss: 0.623495, acc: 65.62%] [G loss: 1.913730]\n",
      "epoch:8 step:6455 [D loss: 0.785344, acc: 44.53%] [G loss: 1.652791]\n",
      "epoch:8 step:6456 [D loss: 0.682696, acc: 57.81%] [G loss: 1.838817]\n",
      "epoch:8 step:6457 [D loss: 0.567652, acc: 71.09%] [G loss: 2.197635]\n",
      "epoch:8 step:6458 [D loss: 0.740669, acc: 50.78%] [G loss: 1.878187]\n",
      "epoch:8 step:6459 [D loss: 0.568426, acc: 74.22%] [G loss: 2.218007]\n",
      "epoch:8 step:6460 [D loss: 0.662656, acc: 59.38%] [G loss: 2.094257]\n",
      "epoch:8 step:6461 [D loss: 0.621932, acc: 73.44%] [G loss: 1.956258]\n",
      "epoch:8 step:6462 [D loss: 0.524821, acc: 76.56%] [G loss: 2.388880]\n",
      "epoch:8 step:6463 [D loss: 0.561932, acc: 72.66%] [G loss: 2.198100]\n",
      "epoch:8 step:6464 [D loss: 0.893159, acc: 29.69%] [G loss: 1.735127]\n",
      "epoch:8 step:6465 [D loss: 0.737841, acc: 50.00%] [G loss: 2.254902]\n",
      "epoch:8 step:6466 [D loss: 0.591483, acc: 66.41%] [G loss: 2.294868]\n",
      "epoch:8 step:6467 [D loss: 0.541943, acc: 77.34%] [G loss: 2.294110]\n",
      "epoch:8 step:6468 [D loss: 0.559475, acc: 72.66%] [G loss: 2.430220]\n",
      "epoch:8 step:6469 [D loss: 0.804960, acc: 45.31%] [G loss: 1.904635]\n",
      "epoch:8 step:6470 [D loss: 0.659791, acc: 63.28%] [G loss: 1.983181]\n",
      "epoch:8 step:6471 [D loss: 0.589721, acc: 67.19%] [G loss: 2.189607]\n",
      "epoch:8 step:6472 [D loss: 0.561839, acc: 78.91%] [G loss: 2.149676]\n",
      "epoch:8 step:6473 [D loss: 0.929394, acc: 41.41%] [G loss: 1.584913]\n",
      "epoch:8 step:6474 [D loss: 0.653526, acc: 63.28%] [G loss: 2.113824]\n",
      "epoch:8 step:6475 [D loss: 0.562921, acc: 74.22%] [G loss: 1.924387]\n",
      "epoch:8 step:6476 [D loss: 0.679184, acc: 56.25%] [G loss: 1.971389]\n",
      "epoch:8 step:6477 [D loss: 0.641923, acc: 64.06%] [G loss: 2.173758]\n",
      "epoch:8 step:6478 [D loss: 1.118967, acc: 39.84%] [G loss: 1.653443]\n",
      "epoch:8 step:6479 [D loss: 0.618041, acc: 67.19%] [G loss: 2.091744]\n",
      "epoch:8 step:6480 [D loss: 0.673305, acc: 62.50%] [G loss: 1.835891]\n",
      "epoch:8 step:6481 [D loss: 0.510830, acc: 82.81%] [G loss: 2.218884]\n",
      "epoch:8 step:6482 [D loss: 0.836607, acc: 35.94%] [G loss: 1.931079]\n",
      "epoch:8 step:6483 [D loss: 0.466291, acc: 78.91%] [G loss: 2.597431]\n",
      "epoch:8 step:6484 [D loss: 1.083522, acc: 35.16%] [G loss: 1.959291]\n",
      "epoch:8 step:6485 [D loss: 0.455689, acc: 84.38%] [G loss: 2.454703]\n",
      "epoch:8 step:6486 [D loss: 0.946209, acc: 28.91%] [G loss: 1.543691]\n",
      "epoch:8 step:6487 [D loss: 0.461791, acc: 87.50%] [G loss: 1.801565]\n",
      "epoch:8 step:6488 [D loss: 0.413806, acc: 82.81%] [G loss: 2.326048]\n",
      "epoch:8 step:6489 [D loss: 0.545442, acc: 76.56%] [G loss: 2.000030]\n",
      "epoch:8 step:6490 [D loss: 0.750920, acc: 52.34%] [G loss: 2.035009]\n",
      "epoch:8 step:6491 [D loss: 0.585656, acc: 67.97%] [G loss: 1.626437]\n",
      "epoch:8 step:6492 [D loss: 0.477378, acc: 83.59%] [G loss: 2.059545]\n",
      "epoch:8 step:6493 [D loss: 0.929905, acc: 36.72%] [G loss: 2.000715]\n",
      "epoch:8 step:6494 [D loss: 0.730933, acc: 50.78%] [G loss: 1.692243]\n",
      "epoch:8 step:6495 [D loss: 0.606612, acc: 66.41%] [G loss: 2.147571]\n",
      "epoch:8 step:6496 [D loss: 0.559483, acc: 77.34%] [G loss: 1.966127]\n",
      "epoch:8 step:6497 [D loss: 0.753037, acc: 42.97%] [G loss: 1.586691]\n",
      "epoch:8 step:6498 [D loss: 0.627016, acc: 67.19%] [G loss: 1.637992]\n",
      "epoch:8 step:6499 [D loss: 0.676847, acc: 58.59%] [G loss: 1.712568]\n",
      "epoch:8 step:6500 [D loss: 0.804750, acc: 38.28%] [G loss: 1.820452]\n",
      "epoch:8 step:6501 [D loss: 0.563102, acc: 67.97%] [G loss: 1.585873]\n",
      "epoch:8 step:6502 [D loss: 1.064659, acc: 14.06%] [G loss: 1.432903]\n",
      "epoch:8 step:6503 [D loss: 0.852042, acc: 35.94%] [G loss: 1.709884]\n",
      "epoch:8 step:6504 [D loss: 0.934996, acc: 34.38%] [G loss: 1.867991]\n",
      "epoch:8 step:6505 [D loss: 1.102624, acc: 26.56%] [G loss: 1.525765]\n",
      "epoch:8 step:6506 [D loss: 0.665066, acc: 58.59%] [G loss: 1.871573]\n",
      "epoch:8 step:6507 [D loss: 0.688318, acc: 55.47%] [G loss: 1.844783]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:8 step:6508 [D loss: 0.627031, acc: 61.72%] [G loss: 1.989702]\n",
      "epoch:8 step:6509 [D loss: 0.417698, acc: 92.19%] [G loss: 2.234377]\n",
      "epoch:8 step:6510 [D loss: 0.616599, acc: 66.41%] [G loss: 2.039882]\n",
      "epoch:8 step:6511 [D loss: 0.679606, acc: 60.16%] [G loss: 1.752081]\n",
      "epoch:8 step:6512 [D loss: 0.718965, acc: 50.78%] [G loss: 1.855864]\n",
      "epoch:8 step:6513 [D loss: 0.404269, acc: 89.06%] [G loss: 2.167740]\n",
      "epoch:8 step:6514 [D loss: 0.528787, acc: 79.69%] [G loss: 2.526871]\n",
      "epoch:8 step:6515 [D loss: 0.665719, acc: 61.72%] [G loss: 2.016046]\n",
      "epoch:8 step:6516 [D loss: 0.661870, acc: 56.25%] [G loss: 2.098429]\n",
      "epoch:8 step:6517 [D loss: 0.728279, acc: 50.78%] [G loss: 1.704152]\n",
      "epoch:8 step:6518 [D loss: 0.829319, acc: 33.59%] [G loss: 1.668751]\n",
      "epoch:8 step:6519 [D loss: 0.613912, acc: 68.75%] [G loss: 2.352569]\n",
      "epoch:8 step:6520 [D loss: 0.577110, acc: 71.88%] [G loss: 2.168991]\n",
      "epoch:8 step:6521 [D loss: 0.544717, acc: 76.56%] [G loss: 2.292481]\n",
      "epoch:8 step:6522 [D loss: 0.550414, acc: 80.47%] [G loss: 1.925761]\n",
      "epoch:8 step:6523 [D loss: 0.669458, acc: 58.59%] [G loss: 2.032076]\n",
      "epoch:8 step:6524 [D loss: 0.621882, acc: 64.06%] [G loss: 1.685816]\n",
      "epoch:8 step:6525 [D loss: 0.833289, acc: 35.94%] [G loss: 2.034586]\n",
      "epoch:8 step:6526 [D loss: 0.599519, acc: 67.19%] [G loss: 2.296880]\n",
      "epoch:8 step:6527 [D loss: 0.728028, acc: 47.66%] [G loss: 1.617001]\n",
      "epoch:8 step:6528 [D loss: 0.557323, acc: 75.00%] [G loss: 1.925023]\n",
      "epoch:8 step:6529 [D loss: 0.705851, acc: 54.69%] [G loss: 1.978324]\n",
      "epoch:8 step:6530 [D loss: 0.752727, acc: 45.31%] [G loss: 1.754434]\n",
      "epoch:8 step:6531 [D loss: 0.577288, acc: 72.66%] [G loss: 2.141541]\n",
      "epoch:8 step:6532 [D loss: 0.596191, acc: 68.75%] [G loss: 1.941652]\n",
      "epoch:8 step:6533 [D loss: 0.676990, acc: 60.94%] [G loss: 2.146121]\n",
      "epoch:8 step:6534 [D loss: 0.607221, acc: 66.41%] [G loss: 2.054307]\n",
      "epoch:8 step:6535 [D loss: 0.611836, acc: 69.53%] [G loss: 2.092298]\n",
      "epoch:8 step:6536 [D loss: 0.833581, acc: 36.72%] [G loss: 1.643481]\n",
      "epoch:8 step:6537 [D loss: 0.430242, acc: 88.28%] [G loss: 2.022240]\n",
      "epoch:8 step:6538 [D loss: 0.513556, acc: 64.06%] [G loss: 2.120417]\n",
      "epoch:8 step:6539 [D loss: 1.235151, acc: 14.06%] [G loss: 1.682276]\n",
      "epoch:8 step:6540 [D loss: 0.351966, acc: 90.62%] [G loss: 2.294717]\n",
      "epoch:8 step:6541 [D loss: 0.654805, acc: 57.81%] [G loss: 1.974937]\n",
      "epoch:8 step:6542 [D loss: 0.417771, acc: 94.53%] [G loss: 2.116921]\n",
      "epoch:8 step:6543 [D loss: 1.019396, acc: 18.75%] [G loss: 1.786461]\n",
      "epoch:8 step:6544 [D loss: 0.837063, acc: 40.62%] [G loss: 1.705113]\n",
      "epoch:8 step:6545 [D loss: 0.727462, acc: 50.00%] [G loss: 2.031621]\n",
      "epoch:8 step:6546 [D loss: 0.479837, acc: 83.59%] [G loss: 1.998562]\n",
      "epoch:8 step:6547 [D loss: 0.646770, acc: 63.28%] [G loss: 1.968792]\n",
      "epoch:8 step:6548 [D loss: 0.564541, acc: 69.53%] [G loss: 1.754269]\n",
      "epoch:8 step:6549 [D loss: 0.672364, acc: 57.03%] [G loss: 1.918273]\n",
      "epoch:8 step:6550 [D loss: 0.600292, acc: 67.97%] [G loss: 1.962321]\n",
      "epoch:8 step:6551 [D loss: 1.055492, acc: 17.97%] [G loss: 1.671049]\n",
      "epoch:8 step:6552 [D loss: 0.655252, acc: 60.16%] [G loss: 1.946042]\n",
      "epoch:8 step:6553 [D loss: 0.753751, acc: 49.22%] [G loss: 1.800462]\n",
      "epoch:8 step:6554 [D loss: 0.659373, acc: 60.94%] [G loss: 1.852234]\n",
      "epoch:8 step:6555 [D loss: 0.612903, acc: 69.53%] [G loss: 1.900030]\n",
      "epoch:8 step:6556 [D loss: 0.734233, acc: 50.78%] [G loss: 1.844649]\n",
      "epoch:8 step:6557 [D loss: 0.631838, acc: 67.97%] [G loss: 2.137028]\n",
      "epoch:8 step:6558 [D loss: 0.537319, acc: 82.03%] [G loss: 1.955356]\n",
      "epoch:8 step:6559 [D loss: 0.464726, acc: 78.12%] [G loss: 2.781358]\n",
      "epoch:8 step:6560 [D loss: 0.820767, acc: 38.28%] [G loss: 2.023097]\n",
      "epoch:8 step:6561 [D loss: 0.407449, acc: 90.62%] [G loss: 2.256975]\n",
      "epoch:8 step:6562 [D loss: 0.932956, acc: 41.41%] [G loss: 1.776397]\n",
      "epoch:8 step:6563 [D loss: 0.539943, acc: 76.56%] [G loss: 1.880645]\n",
      "epoch:8 step:6564 [D loss: 0.752196, acc: 48.44%] [G loss: 1.869897]\n",
      "epoch:8 step:6565 [D loss: 0.595661, acc: 71.09%] [G loss: 2.163265]\n",
      "epoch:8 step:6566 [D loss: 0.635754, acc: 62.50%] [G loss: 1.943469]\n",
      "epoch:8 step:6567 [D loss: 0.664658, acc: 64.84%] [G loss: 1.965073]\n",
      "epoch:8 step:6568 [D loss: 0.849059, acc: 33.59%] [G loss: 1.502673]\n",
      "epoch:8 step:6569 [D loss: 0.792536, acc: 46.09%] [G loss: 1.822646]\n",
      "epoch:8 step:6570 [D loss: 0.766863, acc: 43.75%] [G loss: 1.684025]\n",
      "epoch:8 step:6571 [D loss: 0.597363, acc: 72.66%] [G loss: 1.859118]\n",
      "epoch:8 step:6572 [D loss: 0.529900, acc: 75.78%] [G loss: 2.031264]\n",
      "epoch:8 step:6573 [D loss: 0.575995, acc: 73.44%] [G loss: 2.138567]\n",
      "epoch:8 step:6574 [D loss: 0.741665, acc: 46.88%] [G loss: 1.688500]\n",
      "epoch:8 step:6575 [D loss: 0.411727, acc: 86.72%] [G loss: 2.055521]\n",
      "epoch:8 step:6576 [D loss: 0.550692, acc: 81.25%] [G loss: 1.821270]\n",
      "epoch:8 step:6577 [D loss: 0.770485, acc: 48.44%] [G loss: 1.902559]\n",
      "epoch:8 step:6578 [D loss: 0.726903, acc: 50.00%] [G loss: 1.788884]\n",
      "epoch:8 step:6579 [D loss: 0.588660, acc: 68.75%] [G loss: 2.006266]\n",
      "epoch:8 step:6580 [D loss: 0.583830, acc: 72.66%] [G loss: 1.929242]\n",
      "epoch:8 step:6581 [D loss: 0.562415, acc: 74.22%] [G loss: 1.974910]\n",
      "epoch:8 step:6582 [D loss: 0.695129, acc: 52.34%] [G loss: 2.365188]\n",
      "epoch:8 step:6583 [D loss: 0.619301, acc: 63.28%] [G loss: 1.944184]\n",
      "epoch:8 step:6584 [D loss: 0.632945, acc: 64.06%] [G loss: 2.460078]\n",
      "epoch:8 step:6585 [D loss: 0.841149, acc: 32.03%] [G loss: 1.782946]\n",
      "epoch:8 step:6586 [D loss: 0.541736, acc: 73.44%] [G loss: 1.861571]\n",
      "epoch:8 step:6587 [D loss: 0.678128, acc: 62.50%] [G loss: 1.752275]\n",
      "epoch:8 step:6588 [D loss: 0.750399, acc: 51.56%] [G loss: 1.847958]\n",
      "epoch:8 step:6589 [D loss: 0.525500, acc: 85.16%] [G loss: 2.004084]\n",
      "epoch:8 step:6590 [D loss: 0.646836, acc: 61.72%] [G loss: 1.878233]\n",
      "epoch:8 step:6591 [D loss: 0.657213, acc: 55.47%] [G loss: 1.857519]\n",
      "epoch:8 step:6592 [D loss: 0.607377, acc: 64.84%] [G loss: 2.086186]\n",
      "epoch:8 step:6593 [D loss: 0.679924, acc: 57.81%] [G loss: 1.813321]\n",
      "epoch:8 step:6594 [D loss: 0.601380, acc: 67.97%] [G loss: 1.802567]\n",
      "epoch:8 step:6595 [D loss: 0.789564, acc: 46.88%] [G loss: 1.810917]\n",
      "epoch:8 step:6596 [D loss: 0.908953, acc: 30.47%] [G loss: 1.581308]\n",
      "epoch:8 step:6597 [D loss: 0.718576, acc: 48.44%] [G loss: 2.041714]\n",
      "epoch:8 step:6598 [D loss: 0.615739, acc: 66.41%] [G loss: 2.122663]\n",
      "epoch:8 step:6599 [D loss: 0.609377, acc: 65.62%] [G loss: 1.831063]\n",
      "epoch:8 step:6600 [D loss: 0.636601, acc: 61.72%] [G loss: 2.272282]\n",
      "##############\n",
      "[0.878917   0.8460865  0.82722614 0.82180042 0.79532895 0.81764243\n",
      " 0.89229061 0.83178443 0.82567449 0.83529555]\n",
      "##########\n",
      "epoch:8 step:6601 [D loss: 0.577604, acc: 76.56%] [G loss: 2.311740]\n",
      "epoch:8 step:6602 [D loss: 0.698726, acc: 56.25%] [G loss: 1.906074]\n",
      "epoch:8 step:6603 [D loss: 0.852876, acc: 35.16%] [G loss: 1.589825]\n",
      "epoch:8 step:6604 [D loss: 0.503809, acc: 82.81%] [G loss: 2.295896]\n",
      "epoch:8 step:6605 [D loss: 0.675128, acc: 53.91%] [G loss: 1.764621]\n",
      "epoch:8 step:6606 [D loss: 0.517991, acc: 79.69%] [G loss: 1.877539]\n",
      "epoch:8 step:6607 [D loss: 0.597137, acc: 65.62%] [G loss: 1.695084]\n",
      "epoch:8 step:6608 [D loss: 0.686147, acc: 57.03%] [G loss: 1.833957]\n",
      "epoch:8 step:6609 [D loss: 0.602801, acc: 68.75%] [G loss: 2.148680]\n",
      "epoch:8 step:6610 [D loss: 0.730862, acc: 46.88%] [G loss: 1.737206]\n",
      "epoch:8 step:6611 [D loss: 0.721539, acc: 50.00%] [G loss: 1.813649]\n",
      "epoch:8 step:6612 [D loss: 0.610301, acc: 64.84%] [G loss: 1.916114]\n",
      "epoch:8 step:6613 [D loss: 0.735950, acc: 44.53%] [G loss: 1.911115]\n",
      "epoch:8 step:6614 [D loss: 0.698246, acc: 53.91%] [G loss: 1.632654]\n",
      "epoch:8 step:6615 [D loss: 0.663295, acc: 61.72%] [G loss: 2.111395]\n",
      "epoch:8 step:6616 [D loss: 0.811802, acc: 42.97%] [G loss: 1.781308]\n",
      "epoch:8 step:6617 [D loss: 0.721194, acc: 54.69%] [G loss: 1.588899]\n",
      "epoch:8 step:6618 [D loss: 0.620183, acc: 64.84%] [G loss: 1.971779]\n",
      "epoch:8 step:6619 [D loss: 0.532198, acc: 77.34%] [G loss: 1.964576]\n",
      "epoch:8 step:6620 [D loss: 0.880558, acc: 35.94%] [G loss: 2.397882]\n",
      "epoch:8 step:6621 [D loss: 0.909303, acc: 26.56%] [G loss: 1.436728]\n",
      "epoch:8 step:6622 [D loss: 0.645985, acc: 60.94%] [G loss: 1.839481]\n",
      "epoch:8 step:6623 [D loss: 0.516891, acc: 73.44%] [G loss: 1.784736]\n",
      "epoch:8 step:6624 [D loss: 0.612425, acc: 64.84%] [G loss: 2.012922]\n",
      "epoch:8 step:6625 [D loss: 0.652068, acc: 61.72%] [G loss: 1.718629]\n",
      "epoch:8 step:6626 [D loss: 0.655396, acc: 59.38%] [G loss: 1.628190]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:8 step:6627 [D loss: 0.438226, acc: 90.62%] [G loss: 1.880936]\n",
      "epoch:8 step:6628 [D loss: 0.722800, acc: 53.91%] [G loss: 1.700853]\n",
      "epoch:8 step:6629 [D loss: 0.603190, acc: 67.97%] [G loss: 1.860596]\n",
      "epoch:8 step:6630 [D loss: 0.317123, acc: 92.97%] [G loss: 2.218017]\n",
      "epoch:8 step:6631 [D loss: 0.716702, acc: 53.12%] [G loss: 2.163496]\n",
      "epoch:8 step:6632 [D loss: 0.736992, acc: 50.78%] [G loss: 1.808250]\n",
      "epoch:8 step:6633 [D loss: 0.863772, acc: 34.38%] [G loss: 1.598712]\n",
      "epoch:8 step:6634 [D loss: 0.534753, acc: 75.00%] [G loss: 1.775539]\n",
      "epoch:8 step:6635 [D loss: 0.518089, acc: 76.56%] [G loss: 1.776690]\n",
      "epoch:8 step:6636 [D loss: 0.687856, acc: 57.81%] [G loss: 1.804980]\n",
      "epoch:8 step:6637 [D loss: 0.575264, acc: 73.44%] [G loss: 1.865679]\n",
      "epoch:8 step:6638 [D loss: 0.566672, acc: 74.22%] [G loss: 1.880830]\n",
      "epoch:8 step:6639 [D loss: 1.046544, acc: 16.41%] [G loss: 1.693930]\n",
      "epoch:8 step:6640 [D loss: 0.801640, acc: 38.28%] [G loss: 1.687726]\n",
      "epoch:8 step:6641 [D loss: 0.831232, acc: 36.72%] [G loss: 1.734621]\n",
      "epoch:8 step:6642 [D loss: 0.639492, acc: 65.62%] [G loss: 1.694894]\n",
      "epoch:8 step:6643 [D loss: 0.719967, acc: 50.78%] [G loss: 1.818751]\n",
      "epoch:8 step:6644 [D loss: 0.658586, acc: 60.94%] [G loss: 2.184779]\n",
      "epoch:8 step:6645 [D loss: 0.750631, acc: 48.44%] [G loss: 1.857953]\n",
      "epoch:8 step:6646 [D loss: 0.664158, acc: 58.59%] [G loss: 1.809993]\n",
      "epoch:8 step:6647 [D loss: 0.567686, acc: 75.78%] [G loss: 2.137172]\n",
      "epoch:8 step:6648 [D loss: 0.726452, acc: 52.34%] [G loss: 1.834793]\n",
      "epoch:8 step:6649 [D loss: 0.476082, acc: 82.81%] [G loss: 1.651915]\n",
      "epoch:8 step:6650 [D loss: 0.701820, acc: 57.81%] [G loss: 1.776008]\n",
      "epoch:8 step:6651 [D loss: 0.537960, acc: 76.56%] [G loss: 2.325959]\n",
      "epoch:8 step:6652 [D loss: 0.605016, acc: 68.75%] [G loss: 1.756348]\n",
      "epoch:8 step:6653 [D loss: 0.519229, acc: 75.78%] [G loss: 2.277146]\n",
      "epoch:8 step:6654 [D loss: 0.757631, acc: 46.09%] [G loss: 1.726022]\n",
      "epoch:8 step:6655 [D loss: 0.464231, acc: 74.22%] [G loss: 2.374100]\n",
      "epoch:8 step:6656 [D loss: 0.552284, acc: 78.12%] [G loss: 1.851959]\n",
      "epoch:8 step:6657 [D loss: 0.544322, acc: 69.53%] [G loss: 2.054753]\n",
      "epoch:8 step:6658 [D loss: 0.467663, acc: 84.38%] [G loss: 2.368282]\n",
      "epoch:8 step:6659 [D loss: 0.665662, acc: 60.94%] [G loss: 2.029446]\n",
      "epoch:8 step:6660 [D loss: 0.891881, acc: 42.19%] [G loss: 1.767547]\n",
      "epoch:8 step:6661 [D loss: 0.658850, acc: 59.38%] [G loss: 2.342126]\n",
      "epoch:8 step:6662 [D loss: 0.756546, acc: 42.97%] [G loss: 2.076014]\n",
      "epoch:8 step:6663 [D loss: 0.839329, acc: 33.59%] [G loss: 1.861562]\n",
      "epoch:8 step:6664 [D loss: 0.635621, acc: 63.28%] [G loss: 1.758161]\n",
      "epoch:8 step:6665 [D loss: 0.533421, acc: 75.78%] [G loss: 2.171857]\n",
      "epoch:8 step:6666 [D loss: 0.491092, acc: 76.56%] [G loss: 2.503692]\n",
      "epoch:8 step:6667 [D loss: 0.638651, acc: 62.50%] [G loss: 2.010582]\n",
      "epoch:8 step:6668 [D loss: 0.572815, acc: 71.09%] [G loss: 1.946026]\n",
      "epoch:8 step:6669 [D loss: 0.566815, acc: 66.41%] [G loss: 1.759486]\n",
      "epoch:8 step:6670 [D loss: 0.576739, acc: 73.44%] [G loss: 1.857252]\n",
      "epoch:8 step:6671 [D loss: 0.878596, acc: 30.47%] [G loss: 1.911411]\n",
      "epoch:8 step:6672 [D loss: 0.855582, acc: 37.50%] [G loss: 1.985679]\n",
      "epoch:8 step:6673 [D loss: 0.483340, acc: 78.91%] [G loss: 2.034296]\n",
      "epoch:8 step:6674 [D loss: 0.680650, acc: 58.59%] [G loss: 1.924813]\n",
      "epoch:8 step:6675 [D loss: 0.663311, acc: 64.06%] [G loss: 1.694458]\n",
      "epoch:8 step:6676 [D loss: 0.773461, acc: 51.56%] [G loss: 2.563575]\n",
      "epoch:8 step:6677 [D loss: 0.722236, acc: 56.25%] [G loss: 1.819391]\n",
      "epoch:8 step:6678 [D loss: 0.505609, acc: 79.69%] [G loss: 2.394357]\n",
      "epoch:8 step:6679 [D loss: 0.602959, acc: 66.41%] [G loss: 1.926035]\n",
      "epoch:8 step:6680 [D loss: 0.622713, acc: 64.06%] [G loss: 1.867178]\n",
      "epoch:8 step:6681 [D loss: 0.604904, acc: 68.75%] [G loss: 1.771847]\n",
      "epoch:8 step:6682 [D loss: 0.694866, acc: 56.25%] [G loss: 2.020456]\n",
      "epoch:8 step:6683 [D loss: 0.608035, acc: 63.28%] [G loss: 2.169346]\n",
      "epoch:8 step:6684 [D loss: 0.863375, acc: 34.38%] [G loss: 1.798092]\n",
      "epoch:8 step:6685 [D loss: 0.683633, acc: 61.72%] [G loss: 1.758956]\n",
      "epoch:8 step:6686 [D loss: 0.490175, acc: 82.03%] [G loss: 1.965065]\n",
      "epoch:8 step:6687 [D loss: 0.895231, acc: 33.59%] [G loss: 1.613383]\n",
      "epoch:8 step:6688 [D loss: 0.725323, acc: 50.78%] [G loss: 1.710181]\n",
      "epoch:8 step:6689 [D loss: 0.745537, acc: 53.12%] [G loss: 1.826698]\n",
      "epoch:8 step:6690 [D loss: 0.669623, acc: 61.72%] [G loss: 1.982435]\n",
      "epoch:8 step:6691 [D loss: 0.687420, acc: 58.59%] [G loss: 1.748841]\n",
      "epoch:8 step:6692 [D loss: 0.541294, acc: 73.44%] [G loss: 2.155135]\n",
      "epoch:8 step:6693 [D loss: 0.600334, acc: 71.09%] [G loss: 2.044676]\n",
      "epoch:8 step:6694 [D loss: 0.663983, acc: 60.94%] [G loss: 1.957537]\n",
      "epoch:8 step:6695 [D loss: 0.653182, acc: 64.06%] [G loss: 1.829274]\n",
      "epoch:8 step:6696 [D loss: 0.734686, acc: 45.31%] [G loss: 1.667961]\n",
      "epoch:8 step:6697 [D loss: 0.711942, acc: 50.78%] [G loss: 1.658937]\n",
      "epoch:8 step:6698 [D loss: 0.612102, acc: 64.06%] [G loss: 1.889586]\n",
      "epoch:8 step:6699 [D loss: 0.480755, acc: 83.59%] [G loss: 1.989551]\n",
      "epoch:8 step:6700 [D loss: 0.679231, acc: 57.03%] [G loss: 1.719248]\n",
      "epoch:8 step:6701 [D loss: 0.450054, acc: 74.22%] [G loss: 2.324520]\n",
      "epoch:8 step:6702 [D loss: 0.521409, acc: 75.78%] [G loss: 1.872932]\n",
      "epoch:8 step:6703 [D loss: 0.607994, acc: 68.75%] [G loss: 1.923083]\n",
      "epoch:8 step:6704 [D loss: 0.828039, acc: 41.41%] [G loss: 1.927843]\n",
      "epoch:8 step:6705 [D loss: 0.484350, acc: 76.56%] [G loss: 1.690338]\n",
      "epoch:8 step:6706 [D loss: 0.609131, acc: 66.41%] [G loss: 2.191852]\n",
      "epoch:8 step:6707 [D loss: 0.714224, acc: 52.34%] [G loss: 1.773549]\n",
      "epoch:8 step:6708 [D loss: 0.564574, acc: 69.53%] [G loss: 2.075752]\n",
      "epoch:8 step:6709 [D loss: 0.581400, acc: 68.75%] [G loss: 1.959519]\n",
      "epoch:8 step:6710 [D loss: 0.785981, acc: 48.44%] [G loss: 1.583056]\n",
      "epoch:8 step:6711 [D loss: 0.747238, acc: 44.53%] [G loss: 1.896255]\n",
      "epoch:8 step:6712 [D loss: 0.667744, acc: 59.38%] [G loss: 1.830360]\n",
      "epoch:8 step:6713 [D loss: 0.656897, acc: 61.72%] [G loss: 2.083131]\n",
      "epoch:8 step:6714 [D loss: 0.399545, acc: 96.88%] [G loss: 2.164926]\n",
      "epoch:8 step:6715 [D loss: 0.726147, acc: 49.22%] [G loss: 2.022755]\n",
      "epoch:8 step:6716 [D loss: 0.739855, acc: 46.88%] [G loss: 1.985923]\n",
      "epoch:8 step:6717 [D loss: 0.520791, acc: 78.91%] [G loss: 1.934165]\n",
      "epoch:8 step:6718 [D loss: 0.800511, acc: 44.53%] [G loss: 1.838521]\n",
      "epoch:8 step:6719 [D loss: 1.033593, acc: 17.19%] [G loss: 1.776666]\n",
      "epoch:8 step:6720 [D loss: 0.699355, acc: 58.59%] [G loss: 1.835197]\n",
      "epoch:8 step:6721 [D loss: 0.730820, acc: 55.47%] [G loss: 2.122513]\n",
      "epoch:8 step:6722 [D loss: 0.745611, acc: 50.00%] [G loss: 1.754053]\n",
      "epoch:8 step:6723 [D loss: 0.747112, acc: 52.34%] [G loss: 1.752320]\n",
      "epoch:8 step:6724 [D loss: 0.574747, acc: 75.00%] [G loss: 2.137448]\n",
      "epoch:8 step:6725 [D loss: 0.539693, acc: 81.25%] [G loss: 2.216257]\n",
      "epoch:8 step:6726 [D loss: 0.565318, acc: 74.22%] [G loss: 1.939340]\n",
      "epoch:8 step:6727 [D loss: 0.602433, acc: 57.81%] [G loss: 1.948394]\n",
      "epoch:8 step:6728 [D loss: 0.982953, acc: 28.12%] [G loss: 1.636841]\n",
      "epoch:8 step:6729 [D loss: 0.746532, acc: 46.09%] [G loss: 1.607694]\n",
      "epoch:8 step:6730 [D loss: 0.601041, acc: 64.84%] [G loss: 1.663322]\n",
      "epoch:8 step:6731 [D loss: 0.882838, acc: 47.66%] [G loss: 1.879016]\n",
      "epoch:8 step:6732 [D loss: 0.718269, acc: 53.91%] [G loss: 2.152522]\n",
      "epoch:8 step:6733 [D loss: 0.572657, acc: 74.22%] [G loss: 1.774152]\n",
      "epoch:8 step:6734 [D loss: 0.706231, acc: 60.16%] [G loss: 1.806684]\n",
      "epoch:8 step:6735 [D loss: 0.755952, acc: 50.00%] [G loss: 1.780572]\n",
      "epoch:8 step:6736 [D loss: 0.682652, acc: 54.69%] [G loss: 1.632376]\n",
      "epoch:8 step:6737 [D loss: 0.997181, acc: 17.97%] [G loss: 1.330075]\n",
      "epoch:8 step:6738 [D loss: 0.628249, acc: 64.06%] [G loss: 1.705847]\n",
      "epoch:8 step:6739 [D loss: 0.692025, acc: 53.91%] [G loss: 1.709877]\n",
      "epoch:8 step:6740 [D loss: 0.687055, acc: 60.16%] [G loss: 1.824655]\n",
      "epoch:8 step:6741 [D loss: 0.717310, acc: 53.91%] [G loss: 1.858051]\n",
      "epoch:8 step:6742 [D loss: 0.472109, acc: 74.22%] [G loss: 1.706288]\n",
      "epoch:8 step:6743 [D loss: 0.644982, acc: 59.38%] [G loss: 2.508040]\n",
      "epoch:8 step:6744 [D loss: 0.713478, acc: 54.69%] [G loss: 2.069954]\n",
      "epoch:8 step:6745 [D loss: 0.506022, acc: 75.78%] [G loss: 2.052689]\n",
      "epoch:8 step:6746 [D loss: 0.594861, acc: 65.62%] [G loss: 2.257605]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:8 step:6747 [D loss: 0.718669, acc: 57.81%] [G loss: 1.624692]\n",
      "epoch:8 step:6748 [D loss: 0.671328, acc: 57.81%] [G loss: 1.673518]\n",
      "epoch:8 step:6749 [D loss: 0.434707, acc: 91.41%] [G loss: 1.958646]\n",
      "epoch:8 step:6750 [D loss: 0.624097, acc: 65.62%] [G loss: 1.948710]\n",
      "epoch:8 step:6751 [D loss: 0.939523, acc: 25.00%] [G loss: 2.271878]\n",
      "epoch:8 step:6752 [D loss: 0.430546, acc: 85.16%] [G loss: 1.867299]\n",
      "epoch:8 step:6753 [D loss: 1.016207, acc: 11.72%] [G loss: 1.456402]\n",
      "epoch:8 step:6754 [D loss: 0.559672, acc: 72.66%] [G loss: 1.929956]\n",
      "epoch:8 step:6755 [D loss: 0.943523, acc: 25.00%] [G loss: 1.912406]\n",
      "epoch:8 step:6756 [D loss: 0.590227, acc: 68.75%] [G loss: 2.065434]\n",
      "epoch:8 step:6757 [D loss: 0.538147, acc: 72.66%] [G loss: 1.959046]\n",
      "epoch:8 step:6758 [D loss: 0.568822, acc: 72.66%] [G loss: 2.022127]\n",
      "epoch:8 step:6759 [D loss: 0.805982, acc: 50.00%] [G loss: 2.103937]\n",
      "epoch:8 step:6760 [D loss: 1.052759, acc: 17.19%] [G loss: 1.692005]\n",
      "epoch:8 step:6761 [D loss: 0.575557, acc: 69.53%] [G loss: 1.788186]\n",
      "epoch:8 step:6762 [D loss: 0.745392, acc: 49.22%] [G loss: 1.703381]\n",
      "epoch:8 step:6763 [D loss: 0.756142, acc: 50.78%] [G loss: 1.852559]\n",
      "epoch:8 step:6764 [D loss: 0.488242, acc: 83.59%] [G loss: 2.155196]\n",
      "epoch:8 step:6765 [D loss: 0.837184, acc: 35.94%] [G loss: 1.925235]\n",
      "epoch:8 step:6766 [D loss: 0.574893, acc: 72.66%] [G loss: 1.977930]\n",
      "epoch:8 step:6767 [D loss: 0.909161, acc: 32.03%] [G loss: 1.591800]\n",
      "epoch:8 step:6768 [D loss: 0.562606, acc: 78.12%] [G loss: 2.218405]\n",
      "epoch:8 step:6769 [D loss: 0.780042, acc: 46.88%] [G loss: 1.916868]\n",
      "epoch:8 step:6770 [D loss: 0.521277, acc: 62.50%] [G loss: 2.355618]\n",
      "epoch:8 step:6771 [D loss: 0.318036, acc: 94.53%] [G loss: 2.660488]\n",
      "epoch:8 step:6772 [D loss: 0.870952, acc: 32.03%] [G loss: 1.753080]\n",
      "epoch:8 step:6773 [D loss: 0.873107, acc: 38.28%] [G loss: 1.557584]\n",
      "epoch:8 step:6774 [D loss: 0.781415, acc: 50.00%] [G loss: 2.016898]\n",
      "epoch:8 step:6775 [D loss: 0.775478, acc: 42.19%] [G loss: 1.698838]\n",
      "epoch:8 step:6776 [D loss: 0.575914, acc: 67.19%] [G loss: 1.924162]\n",
      "epoch:8 step:6777 [D loss: 0.684983, acc: 54.69%] [G loss: 2.164204]\n",
      "epoch:8 step:6778 [D loss: 0.908614, acc: 31.25%] [G loss: 1.743491]\n",
      "epoch:8 step:6779 [D loss: 0.710817, acc: 49.22%] [G loss: 1.724477]\n",
      "epoch:8 step:6780 [D loss: 0.702866, acc: 53.91%] [G loss: 1.752866]\n",
      "epoch:8 step:6781 [D loss: 0.633746, acc: 64.84%] [G loss: 1.903132]\n",
      "epoch:8 step:6782 [D loss: 0.545179, acc: 75.78%] [G loss: 1.890373]\n",
      "epoch:8 step:6783 [D loss: 0.689257, acc: 59.38%] [G loss: 1.823178]\n",
      "epoch:8 step:6784 [D loss: 0.551828, acc: 67.97%] [G loss: 1.637882]\n",
      "epoch:8 step:6785 [D loss: 0.627883, acc: 64.06%] [G loss: 2.100708]\n",
      "epoch:8 step:6786 [D loss: 0.470851, acc: 84.38%] [G loss: 2.331315]\n",
      "epoch:8 step:6787 [D loss: 0.653193, acc: 62.50%] [G loss: 1.884330]\n",
      "epoch:8 step:6788 [D loss: 0.635481, acc: 60.94%] [G loss: 1.795676]\n",
      "epoch:8 step:6789 [D loss: 0.664245, acc: 63.28%] [G loss: 1.830551]\n",
      "epoch:8 step:6790 [D loss: 0.717514, acc: 53.12%] [G loss: 1.819936]\n",
      "epoch:8 step:6791 [D loss: 0.795355, acc: 39.06%] [G loss: 1.740617]\n",
      "epoch:8 step:6792 [D loss: 0.537172, acc: 66.41%] [G loss: 1.606631]\n",
      "epoch:8 step:6793 [D loss: 0.699283, acc: 56.25%] [G loss: 1.865386]\n",
      "epoch:8 step:6794 [D loss: 0.976330, acc: 23.44%] [G loss: 1.682416]\n",
      "epoch:8 step:6795 [D loss: 0.651187, acc: 61.72%] [G loss: 1.993814]\n",
      "epoch:8 step:6796 [D loss: 0.678557, acc: 56.25%] [G loss: 1.613767]\n",
      "epoch:8 step:6797 [D loss: 0.529534, acc: 75.78%] [G loss: 2.023391]\n",
      "epoch:8 step:6798 [D loss: 0.674048, acc: 59.38%] [G loss: 2.122119]\n",
      "epoch:8 step:6799 [D loss: 0.808438, acc: 46.88%] [G loss: 1.749379]\n",
      "epoch:8 step:6800 [D loss: 0.821179, acc: 45.31%] [G loss: 1.809940]\n",
      "##############\n",
      "[0.87033327 0.90470732 0.82344993 0.8212024  0.81144772 0.82390067\n",
      " 0.86389476 0.82167039 0.83444874 0.83104675]\n",
      "##########\n",
      "epoch:8 step:6801 [D loss: 0.757613, acc: 46.88%] [G loss: 1.495780]\n",
      "epoch:8 step:6802 [D loss: 0.632432, acc: 64.84%] [G loss: 1.747818]\n",
      "epoch:8 step:6803 [D loss: 0.745127, acc: 50.00%] [G loss: 1.679832]\n",
      "epoch:8 step:6804 [D loss: 0.492326, acc: 81.25%] [G loss: 1.745752]\n",
      "epoch:8 step:6805 [D loss: 0.701940, acc: 55.47%] [G loss: 1.695946]\n",
      "epoch:8 step:6806 [D loss: 0.649650, acc: 64.84%] [G loss: 1.767210]\n",
      "epoch:8 step:6807 [D loss: 0.696012, acc: 56.25%] [G loss: 1.602682]\n",
      "epoch:8 step:6808 [D loss: 0.628808, acc: 61.72%] [G loss: 1.871882]\n",
      "epoch:8 step:6809 [D loss: 0.489079, acc: 76.56%] [G loss: 1.945330]\n",
      "epoch:8 step:6810 [D loss: 0.617827, acc: 66.41%] [G loss: 1.892177]\n",
      "epoch:8 step:6811 [D loss: 0.570901, acc: 70.31%] [G loss: 1.736497]\n",
      "epoch:8 step:6812 [D loss: 0.793669, acc: 45.31%] [G loss: 1.902046]\n",
      "epoch:8 step:6813 [D loss: 0.638496, acc: 60.94%] [G loss: 2.049863]\n",
      "epoch:8 step:6814 [D loss: 0.814812, acc: 39.84%] [G loss: 1.724235]\n",
      "epoch:8 step:6815 [D loss: 0.713649, acc: 54.69%] [G loss: 1.823866]\n",
      "epoch:8 step:6816 [D loss: 0.605126, acc: 68.75%] [G loss: 1.869489]\n",
      "epoch:8 step:6817 [D loss: 0.734163, acc: 52.34%] [G loss: 1.857115]\n",
      "epoch:8 step:6818 [D loss: 0.590382, acc: 67.19%] [G loss: 1.741954]\n",
      "epoch:8 step:6819 [D loss: 0.654034, acc: 63.28%] [G loss: 2.033422]\n",
      "epoch:8 step:6820 [D loss: 0.520712, acc: 83.59%] [G loss: 2.071859]\n",
      "epoch:8 step:6821 [D loss: 0.489990, acc: 83.59%] [G loss: 1.882626]\n",
      "epoch:8 step:6822 [D loss: 0.734384, acc: 50.00%] [G loss: 1.702677]\n",
      "epoch:8 step:6823 [D loss: 0.564713, acc: 70.31%] [G loss: 1.762203]\n",
      "epoch:8 step:6824 [D loss: 0.977760, acc: 34.38%] [G loss: 1.575966]\n",
      "epoch:8 step:6825 [D loss: 0.371936, acc: 84.38%] [G loss: 2.326197]\n",
      "epoch:8 step:6826 [D loss: 0.854448, acc: 45.31%] [G loss: 1.807983]\n",
      "epoch:8 step:6827 [D loss: 0.739528, acc: 48.44%] [G loss: 1.917685]\n",
      "epoch:8 step:6828 [D loss: 0.445674, acc: 79.69%] [G loss: 1.847250]\n",
      "epoch:8 step:6829 [D loss: 0.600436, acc: 66.41%] [G loss: 2.314357]\n",
      "epoch:8 step:6830 [D loss: 0.681147, acc: 59.38%] [G loss: 1.704733]\n",
      "epoch:8 step:6831 [D loss: 0.509872, acc: 81.25%] [G loss: 2.896817]\n",
      "epoch:8 step:6832 [D loss: 0.553764, acc: 67.97%] [G loss: 1.623252]\n",
      "epoch:8 step:6833 [D loss: 0.609295, acc: 67.19%] [G loss: 1.974861]\n",
      "epoch:8 step:6834 [D loss: 0.745982, acc: 50.78%] [G loss: 1.784964]\n",
      "epoch:8 step:6835 [D loss: 0.731408, acc: 43.75%] [G loss: 1.553645]\n",
      "epoch:8 step:6836 [D loss: 0.400346, acc: 85.94%] [G loss: 2.144708]\n",
      "epoch:8 step:6837 [D loss: 0.705245, acc: 59.38%] [G loss: 1.968365]\n",
      "epoch:8 step:6838 [D loss: 0.725523, acc: 44.53%] [G loss: 1.975088]\n",
      "epoch:8 step:6839 [D loss: 0.637486, acc: 62.50%] [G loss: 1.780334]\n",
      "epoch:8 step:6840 [D loss: 0.695763, acc: 50.00%] [G loss: 2.070810]\n",
      "epoch:8 step:6841 [D loss: 0.938553, acc: 28.91%] [G loss: 1.989098]\n",
      "epoch:8 step:6842 [D loss: 0.738077, acc: 43.75%] [G loss: 1.636456]\n",
      "epoch:8 step:6843 [D loss: 0.717096, acc: 56.25%] [G loss: 1.779354]\n",
      "epoch:8 step:6844 [D loss: 0.663296, acc: 61.72%] [G loss: 1.692962]\n",
      "epoch:8 step:6845 [D loss: 0.791827, acc: 41.41%] [G loss: 1.692066]\n",
      "epoch:8 step:6846 [D loss: 0.426079, acc: 88.28%] [G loss: 2.492549]\n",
      "epoch:8 step:6847 [D loss: 0.679083, acc: 57.81%] [G loss: 1.805682]\n",
      "epoch:8 step:6848 [D loss: 0.766711, acc: 42.19%] [G loss: 1.807612]\n",
      "epoch:8 step:6849 [D loss: 0.604835, acc: 68.75%] [G loss: 1.772655]\n",
      "epoch:8 step:6850 [D loss: 0.597975, acc: 70.31%] [G loss: 2.071411]\n",
      "epoch:8 step:6851 [D loss: 0.923380, acc: 25.78%] [G loss: 1.396235]\n",
      "epoch:8 step:6852 [D loss: 0.780686, acc: 42.97%] [G loss: 1.710148]\n",
      "epoch:8 step:6853 [D loss: 0.592114, acc: 74.22%] [G loss: 1.614691]\n",
      "epoch:8 step:6854 [D loss: 0.732450, acc: 44.53%] [G loss: 1.982348]\n",
      "epoch:8 step:6855 [D loss: 0.769225, acc: 42.97%] [G loss: 1.804170]\n",
      "epoch:8 step:6856 [D loss: 0.622102, acc: 64.84%] [G loss: 2.019246]\n",
      "epoch:8 step:6857 [D loss: 0.811658, acc: 41.41%] [G loss: 1.568131]\n",
      "epoch:8 step:6858 [D loss: 0.679674, acc: 56.25%] [G loss: 1.701872]\n",
      "epoch:8 step:6859 [D loss: 0.703588, acc: 51.56%] [G loss: 1.817220]\n",
      "epoch:8 step:6860 [D loss: 0.648499, acc: 60.94%] [G loss: 1.773145]\n",
      "epoch:8 step:6861 [D loss: 0.726076, acc: 53.12%] [G loss: 1.858083]\n",
      "epoch:8 step:6862 [D loss: 0.561355, acc: 68.75%] [G loss: 1.853828]\n",
      "epoch:8 step:6863 [D loss: 0.635770, acc: 65.62%] [G loss: 1.867287]\n",
      "epoch:8 step:6864 [D loss: 0.813430, acc: 38.28%] [G loss: 1.711198]\n",
      "epoch:8 step:6865 [D loss: 0.650952, acc: 64.84%] [G loss: 2.027814]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:8 step:6866 [D loss: 0.734556, acc: 48.44%] [G loss: 1.742910]\n",
      "epoch:8 step:6867 [D loss: 0.788072, acc: 42.97%] [G loss: 1.598285]\n",
      "epoch:8 step:6868 [D loss: 0.711324, acc: 51.56%] [G loss: 1.721875]\n",
      "epoch:8 step:6869 [D loss: 0.674824, acc: 58.59%] [G loss: 1.847332]\n",
      "epoch:8 step:6870 [D loss: 0.717100, acc: 50.00%] [G loss: 1.654337]\n",
      "epoch:8 step:6871 [D loss: 0.751266, acc: 42.19%] [G loss: 1.639369]\n",
      "epoch:8 step:6872 [D loss: 0.631944, acc: 68.75%] [G loss: 1.776612]\n",
      "epoch:8 step:6873 [D loss: 0.490325, acc: 76.56%] [G loss: 1.937173]\n",
      "epoch:8 step:6874 [D loss: 0.662744, acc: 58.59%] [G loss: 1.602912]\n",
      "epoch:8 step:6875 [D loss: 0.792032, acc: 33.59%] [G loss: 1.774870]\n",
      "epoch:8 step:6876 [D loss: 0.627799, acc: 67.19%] [G loss: 1.619848]\n",
      "epoch:8 step:6877 [D loss: 0.776539, acc: 44.53%] [G loss: 1.739892]\n",
      "epoch:8 step:6878 [D loss: 0.653455, acc: 57.03%] [G loss: 1.765174]\n",
      "epoch:8 step:6879 [D loss: 0.471534, acc: 86.72%] [G loss: 1.765542]\n",
      "epoch:8 step:6880 [D loss: 0.673934, acc: 57.81%] [G loss: 1.835592]\n",
      "epoch:8 step:6881 [D loss: 0.638645, acc: 62.50%] [G loss: 1.666206]\n",
      "epoch:8 step:6882 [D loss: 0.812690, acc: 42.97%] [G loss: 1.615899]\n",
      "epoch:8 step:6883 [D loss: 0.497808, acc: 78.91%] [G loss: 1.815894]\n",
      "epoch:8 step:6884 [D loss: 0.599974, acc: 72.66%] [G loss: 1.907456]\n",
      "epoch:8 step:6885 [D loss: 0.705143, acc: 54.69%] [G loss: 2.026341]\n",
      "epoch:8 step:6886 [D loss: 0.698913, acc: 54.69%] [G loss: 1.800806]\n",
      "epoch:8 step:6887 [D loss: 0.676520, acc: 55.47%] [G loss: 1.884323]\n",
      "epoch:8 step:6888 [D loss: 0.601174, acc: 67.19%] [G loss: 1.857800]\n",
      "epoch:8 step:6889 [D loss: 0.605474, acc: 69.53%] [G loss: 1.838866]\n",
      "epoch:8 step:6890 [D loss: 0.678290, acc: 57.81%] [G loss: 1.987490]\n",
      "epoch:8 step:6891 [D loss: 0.756756, acc: 40.62%] [G loss: 1.813195]\n",
      "epoch:8 step:6892 [D loss: 0.622537, acc: 64.84%] [G loss: 1.735449]\n",
      "epoch:8 step:6893 [D loss: 0.731735, acc: 51.56%] [G loss: 1.810954]\n",
      "epoch:8 step:6894 [D loss: 0.590905, acc: 72.66%] [G loss: 1.916102]\n",
      "epoch:8 step:6895 [D loss: 0.791421, acc: 43.75%] [G loss: 1.794718]\n",
      "epoch:8 step:6896 [D loss: 0.590605, acc: 67.19%] [G loss: 1.783852]\n",
      "epoch:8 step:6897 [D loss: 0.767197, acc: 46.88%] [G loss: 1.552406]\n",
      "epoch:8 step:6898 [D loss: 0.580415, acc: 74.22%] [G loss: 1.915061]\n",
      "epoch:8 step:6899 [D loss: 0.684767, acc: 55.47%] [G loss: 1.784842]\n",
      "epoch:8 step:6900 [D loss: 0.588757, acc: 66.41%] [G loss: 1.552077]\n",
      "epoch:8 step:6901 [D loss: 0.714581, acc: 52.34%] [G loss: 1.720913]\n",
      "epoch:8 step:6902 [D loss: 0.684821, acc: 56.25%] [G loss: 1.903333]\n",
      "epoch:8 step:6903 [D loss: 0.466382, acc: 87.50%] [G loss: 1.950055]\n",
      "epoch:8 step:6904 [D loss: 0.479863, acc: 82.03%] [G loss: 1.934673]\n",
      "epoch:8 step:6905 [D loss: 0.674091, acc: 60.94%] [G loss: 1.912351]\n",
      "epoch:8 step:6906 [D loss: 0.794485, acc: 50.78%] [G loss: 2.087339]\n",
      "epoch:8 step:6907 [D loss: 0.421517, acc: 81.25%] [G loss: 1.991915]\n",
      "epoch:8 step:6908 [D loss: 0.723666, acc: 52.34%] [G loss: 1.954478]\n",
      "epoch:8 step:6909 [D loss: 0.613312, acc: 64.06%] [G loss: 1.759208]\n",
      "epoch:8 step:6910 [D loss: 0.750369, acc: 46.88%] [G loss: 1.629113]\n",
      "epoch:8 step:6911 [D loss: 0.451683, acc: 75.00%] [G loss: 1.989880]\n",
      "epoch:8 step:6912 [D loss: 0.816142, acc: 39.84%] [G loss: 2.045295]\n",
      "epoch:8 step:6913 [D loss: 0.608963, acc: 70.31%] [G loss: 1.764219]\n",
      "epoch:8 step:6914 [D loss: 0.599065, acc: 68.75%] [G loss: 2.066185]\n",
      "epoch:8 step:6915 [D loss: 0.508815, acc: 79.69%] [G loss: 2.112305]\n",
      "epoch:8 step:6916 [D loss: 0.525002, acc: 78.91%] [G loss: 2.271294]\n",
      "epoch:8 step:6917 [D loss: 0.818798, acc: 36.72%] [G loss: 1.723076]\n",
      "epoch:8 step:6918 [D loss: 0.647184, acc: 64.84%] [G loss: 1.889783]\n",
      "epoch:8 step:6919 [D loss: 0.893808, acc: 42.97%] [G loss: 1.748628]\n",
      "epoch:8 step:6920 [D loss: 0.711364, acc: 53.91%] [G loss: 1.730885]\n",
      "epoch:8 step:6921 [D loss: 0.380490, acc: 92.19%] [G loss: 2.523911]\n",
      "epoch:8 step:6922 [D loss: 0.663098, acc: 60.16%] [G loss: 1.908274]\n",
      "epoch:8 step:6923 [D loss: 0.290135, acc: 94.53%] [G loss: 3.071698]\n",
      "epoch:8 step:6924 [D loss: 0.831863, acc: 39.84%] [G loss: 2.266944]\n",
      "epoch:8 step:6925 [D loss: 0.277101, acc: 94.53%] [G loss: 2.374620]\n",
      "epoch:8 step:6926 [D loss: 0.758836, acc: 54.69%] [G loss: 1.944712]\n",
      "epoch:8 step:6927 [D loss: 0.482466, acc: 76.56%] [G loss: 1.692486]\n",
      "epoch:8 step:6928 [D loss: 0.586090, acc: 68.75%] [G loss: 1.896771]\n",
      "epoch:8 step:6929 [D loss: 0.537143, acc: 76.56%] [G loss: 1.954482]\n",
      "epoch:8 step:6930 [D loss: 0.872657, acc: 43.75%] [G loss: 1.694506]\n",
      "epoch:8 step:6931 [D loss: 0.789424, acc: 47.66%] [G loss: 1.745130]\n",
      "epoch:8 step:6932 [D loss: 0.551364, acc: 75.00%] [G loss: 1.921011]\n",
      "epoch:8 step:6933 [D loss: 0.620741, acc: 66.41%] [G loss: 1.948164]\n",
      "epoch:8 step:6934 [D loss: 0.906050, acc: 38.28%] [G loss: 2.130448]\n",
      "epoch:8 step:6935 [D loss: 0.659102, acc: 58.59%] [G loss: 1.916431]\n",
      "epoch:8 step:6936 [D loss: 0.689308, acc: 55.47%] [G loss: 1.676316]\n",
      "epoch:8 step:6937 [D loss: 0.721150, acc: 48.44%] [G loss: 1.484776]\n",
      "epoch:8 step:6938 [D loss: 0.824663, acc: 42.97%] [G loss: 2.001161]\n",
      "epoch:8 step:6939 [D loss: 0.827740, acc: 39.06%] [G loss: 1.594800]\n",
      "epoch:8 step:6940 [D loss: 0.759434, acc: 46.09%] [G loss: 1.981929]\n",
      "epoch:8 step:6941 [D loss: 0.549392, acc: 81.25%] [G loss: 1.764557]\n",
      "epoch:8 step:6942 [D loss: 0.658573, acc: 58.59%] [G loss: 2.044750]\n",
      "epoch:8 step:6943 [D loss: 0.493338, acc: 77.34%] [G loss: 2.322790]\n",
      "epoch:8 step:6944 [D loss: 0.742480, acc: 47.66%] [G loss: 1.804543]\n",
      "epoch:8 step:6945 [D loss: 0.624580, acc: 66.41%] [G loss: 2.362274]\n",
      "epoch:8 step:6946 [D loss: 0.579007, acc: 70.31%] [G loss: 2.025331]\n",
      "epoch:8 step:6947 [D loss: 0.723901, acc: 47.66%] [G loss: 1.913596]\n",
      "epoch:8 step:6948 [D loss: 0.825131, acc: 43.75%] [G loss: 1.822034]\n",
      "epoch:8 step:6949 [D loss: 0.783536, acc: 48.44%] [G loss: 1.904303]\n",
      "epoch:8 step:6950 [D loss: 0.604310, acc: 69.53%] [G loss: 1.801871]\n",
      "epoch:8 step:6951 [D loss: 0.550371, acc: 74.22%] [G loss: 2.113202]\n",
      "epoch:8 step:6952 [D loss: 0.742419, acc: 51.56%] [G loss: 1.964007]\n",
      "epoch:8 step:6953 [D loss: 0.607617, acc: 66.41%] [G loss: 2.030985]\n",
      "epoch:8 step:6954 [D loss: 0.669374, acc: 62.50%] [G loss: 2.023866]\n",
      "epoch:8 step:6955 [D loss: 0.595884, acc: 70.31%] [G loss: 1.963406]\n",
      "epoch:8 step:6956 [D loss: 0.677908, acc: 54.69%] [G loss: 2.242417]\n",
      "epoch:8 step:6957 [D loss: 0.513444, acc: 78.12%] [G loss: 1.855699]\n",
      "epoch:8 step:6958 [D loss: 0.617453, acc: 68.75%] [G loss: 2.702967]\n",
      "epoch:8 step:6959 [D loss: 0.675960, acc: 54.69%] [G loss: 2.226078]\n",
      "epoch:8 step:6960 [D loss: 0.592507, acc: 58.59%] [G loss: 2.343108]\n",
      "epoch:8 step:6961 [D loss: 0.645555, acc: 63.28%] [G loss: 2.117059]\n",
      "epoch:8 step:6962 [D loss: 0.661248, acc: 60.94%] [G loss: 1.910949]\n",
      "epoch:8 step:6963 [D loss: 0.488288, acc: 81.25%] [G loss: 2.134823]\n",
      "epoch:8 step:6964 [D loss: 0.532028, acc: 77.34%] [G loss: 2.039950]\n",
      "epoch:8 step:6965 [D loss: 0.690140, acc: 53.12%] [G loss: 2.099449]\n",
      "epoch:8 step:6966 [D loss: 0.552536, acc: 75.78%] [G loss: 2.047875]\n",
      "epoch:8 step:6967 [D loss: 0.752442, acc: 48.44%] [G loss: 2.270080]\n",
      "epoch:8 step:6968 [D loss: 0.521959, acc: 75.78%] [G loss: 1.783875]\n",
      "epoch:8 step:6969 [D loss: 0.671577, acc: 61.72%] [G loss: 2.573542]\n",
      "epoch:8 step:6970 [D loss: 0.536158, acc: 79.69%] [G loss: 1.922898]\n",
      "epoch:8 step:6971 [D loss: 0.801762, acc: 50.78%] [G loss: 1.528725]\n",
      "epoch:8 step:6972 [D loss: 0.532147, acc: 77.34%] [G loss: 1.864696]\n",
      "epoch:8 step:6973 [D loss: 0.397783, acc: 92.19%] [G loss: 2.265383]\n",
      "epoch:8 step:6974 [D loss: 0.809852, acc: 48.44%] [G loss: 1.761711]\n",
      "epoch:8 step:6975 [D loss: 0.576540, acc: 72.66%] [G loss: 2.085178]\n",
      "epoch:8 step:6976 [D loss: 0.663675, acc: 58.59%] [G loss: 1.606809]\n",
      "epoch:8 step:6977 [D loss: 0.638566, acc: 66.41%] [G loss: 1.819170]\n",
      "epoch:8 step:6978 [D loss: 0.567281, acc: 71.88%] [G loss: 1.799896]\n",
      "epoch:8 step:6979 [D loss: 0.479357, acc: 84.38%] [G loss: 1.994157]\n",
      "epoch:8 step:6980 [D loss: 0.754809, acc: 43.75%] [G loss: 1.860246]\n",
      "epoch:8 step:6981 [D loss: 0.467953, acc: 77.34%] [G loss: 1.668659]\n",
      "epoch:8 step:6982 [D loss: 1.098607, acc: 23.44%] [G loss: 1.785891]\n",
      "epoch:8 step:6983 [D loss: 0.372288, acc: 93.75%] [G loss: 2.541576]\n",
      "epoch:8 step:6984 [D loss: 0.776613, acc: 46.09%] [G loss: 1.888443]\n",
      "epoch:8 step:6985 [D loss: 0.616445, acc: 67.19%] [G loss: 2.028872]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:8 step:6986 [D loss: 0.676890, acc: 57.03%] [G loss: 1.889060]\n",
      "epoch:8 step:6987 [D loss: 0.604170, acc: 68.75%] [G loss: 1.977381]\n",
      "epoch:8 step:6988 [D loss: 0.513287, acc: 78.91%] [G loss: 2.614717]\n",
      "epoch:8 step:6989 [D loss: 0.376971, acc: 92.19%] [G loss: 2.094300]\n",
      "epoch:8 step:6990 [D loss: 0.693782, acc: 58.59%] [G loss: 1.962410]\n",
      "epoch:8 step:6991 [D loss: 0.682436, acc: 57.03%] [G loss: 1.964467]\n",
      "epoch:8 step:6992 [D loss: 0.873419, acc: 32.03%] [G loss: 1.740047]\n",
      "epoch:8 step:6993 [D loss: 0.638453, acc: 64.84%] [G loss: 1.975827]\n",
      "epoch:8 step:6994 [D loss: 0.744932, acc: 53.91%] [G loss: 1.980077]\n",
      "epoch:8 step:6995 [D loss: 0.655920, acc: 60.94%] [G loss: 2.442917]\n",
      "epoch:8 step:6996 [D loss: 0.671787, acc: 58.59%] [G loss: 2.312198]\n",
      "epoch:8 step:6997 [D loss: 0.798717, acc: 43.75%] [G loss: 1.701225]\n",
      "epoch:8 step:6998 [D loss: 0.745324, acc: 48.44%] [G loss: 1.825621]\n",
      "epoch:8 step:6999 [D loss: 0.966610, acc: 42.19%] [G loss: 2.094815]\n",
      "epoch:8 step:7000 [D loss: 0.523512, acc: 79.69%] [G loss: 1.790817]\n",
      "##############\n",
      "[0.86253756 0.87455798 0.81779485 0.81735888 0.80401609 0.8138984\n",
      " 0.89782668 0.82818616 0.80099657 0.83583539]\n",
      "##########\n",
      "epoch:8 step:7001 [D loss: 0.520700, acc: 72.66%] [G loss: 1.990083]\n",
      "epoch:8 step:7002 [D loss: 0.543904, acc: 75.78%] [G loss: 1.978667]\n",
      "epoch:8 step:7003 [D loss: 0.574950, acc: 68.75%] [G loss: 2.101659]\n",
      "epoch:8 step:7004 [D loss: 0.685169, acc: 61.72%] [G loss: 2.054051]\n",
      "epoch:8 step:7005 [D loss: 0.482882, acc: 82.03%] [G loss: 2.264889]\n",
      "epoch:8 step:7006 [D loss: 0.545069, acc: 66.41%] [G loss: 1.849052]\n",
      "epoch:8 step:7007 [D loss: 0.551466, acc: 77.34%] [G loss: 2.685942]\n",
      "epoch:8 step:7008 [D loss: 0.806640, acc: 43.75%] [G loss: 1.855566]\n",
      "epoch:8 step:7009 [D loss: 0.489443, acc: 80.47%] [G loss: 1.917186]\n",
      "epoch:8 step:7010 [D loss: 0.574064, acc: 76.56%] [G loss: 2.067756]\n",
      "epoch:8 step:7011 [D loss: 0.657820, acc: 65.62%] [G loss: 2.093236]\n",
      "epoch:8 step:7012 [D loss: 0.562816, acc: 74.22%] [G loss: 1.688445]\n",
      "epoch:8 step:7013 [D loss: 0.723323, acc: 56.25%] [G loss: 1.744570]\n",
      "epoch:8 step:7014 [D loss: 0.366303, acc: 90.62%] [G loss: 2.094089]\n",
      "epoch:8 step:7015 [D loss: 0.451253, acc: 87.50%] [G loss: 2.125012]\n",
      "epoch:8 step:7016 [D loss: 0.466070, acc: 82.03%] [G loss: 2.573522]\n",
      "epoch:8 step:7017 [D loss: 0.711815, acc: 50.78%] [G loss: 2.115535]\n",
      "epoch:8 step:7018 [D loss: 0.309704, acc: 96.09%] [G loss: 1.943807]\n",
      "epoch:8 step:7019 [D loss: 0.367809, acc: 82.03%] [G loss: 2.292534]\n",
      "epoch:8 step:7020 [D loss: 0.277386, acc: 96.88%] [G loss: 2.329823]\n",
      "epoch:8 step:7021 [D loss: 0.730229, acc: 51.56%] [G loss: 2.207087]\n",
      "epoch:8 step:7022 [D loss: 0.349321, acc: 92.19%] [G loss: 2.095206]\n",
      "epoch:8 step:7023 [D loss: 0.780902, acc: 48.44%] [G loss: 1.780983]\n",
      "epoch:8 step:7024 [D loss: 0.788793, acc: 44.53%] [G loss: 2.077926]\n",
      "epoch:8 step:7025 [D loss: 0.943407, acc: 24.22%] [G loss: 1.569730]\n",
      "epoch:8 step:7026 [D loss: 0.570754, acc: 71.88%] [G loss: 2.248635]\n",
      "epoch:8 step:7027 [D loss: 0.526182, acc: 68.75%] [G loss: 2.351582]\n",
      "epoch:8 step:7028 [D loss: 0.754531, acc: 50.00%] [G loss: 1.888649]\n",
      "epoch:8 step:7029 [D loss: 0.357426, acc: 89.84%] [G loss: 3.146692]\n",
      "epoch:9 step:7030 [D loss: 0.282555, acc: 97.66%] [G loss: 3.109193]\n",
      "epoch:9 step:7031 [D loss: 0.272258, acc: 96.88%] [G loss: 2.978710]\n",
      "epoch:9 step:7032 [D loss: 0.612022, acc: 66.41%] [G loss: 1.901587]\n",
      "epoch:9 step:7033 [D loss: 0.292072, acc: 96.09%] [G loss: 2.007765]\n",
      "epoch:9 step:7034 [D loss: 0.467061, acc: 82.03%] [G loss: 2.431779]\n",
      "epoch:9 step:7035 [D loss: 0.469362, acc: 85.94%] [G loss: 2.223246]\n",
      "epoch:9 step:7036 [D loss: 0.353873, acc: 96.88%] [G loss: 2.573862]\n",
      "epoch:9 step:7037 [D loss: 0.438673, acc: 88.28%] [G loss: 2.184285]\n",
      "epoch:9 step:7038 [D loss: 0.635140, acc: 64.84%] [G loss: 2.364424]\n",
      "epoch:9 step:7039 [D loss: 0.429947, acc: 86.72%] [G loss: 2.809161]\n",
      "epoch:9 step:7040 [D loss: 0.302638, acc: 95.31%] [G loss: 2.359683]\n",
      "epoch:9 step:7041 [D loss: 0.717100, acc: 57.81%] [G loss: 2.359866]\n",
      "epoch:9 step:7042 [D loss: 0.401785, acc: 85.94%] [G loss: 2.089138]\n",
      "epoch:9 step:7043 [D loss: 0.269802, acc: 90.62%] [G loss: 2.279363]\n",
      "epoch:9 step:7044 [D loss: 0.698597, acc: 57.03%] [G loss: 1.547413]\n",
      "epoch:9 step:7045 [D loss: 1.022063, acc: 35.94%] [G loss: 1.387608]\n",
      "epoch:9 step:7046 [D loss: 0.791121, acc: 44.53%] [G loss: 1.463290]\n",
      "epoch:9 step:7047 [D loss: 0.435022, acc: 81.25%] [G loss: 1.826556]\n",
      "epoch:9 step:7048 [D loss: 0.948855, acc: 44.53%] [G loss: 1.660666]\n",
      "epoch:9 step:7049 [D loss: 0.573254, acc: 72.66%] [G loss: 2.937968]\n",
      "epoch:9 step:7050 [D loss: 0.532534, acc: 75.78%] [G loss: 2.349032]\n",
      "epoch:9 step:7051 [D loss: 0.508543, acc: 75.00%] [G loss: 1.729409]\n",
      "epoch:9 step:7052 [D loss: 0.660752, acc: 58.59%] [G loss: 2.078802]\n",
      "epoch:9 step:7053 [D loss: 0.447368, acc: 71.09%] [G loss: 2.146183]\n",
      "epoch:9 step:7054 [D loss: 0.637010, acc: 64.06%] [G loss: 2.212947]\n",
      "epoch:9 step:7055 [D loss: 0.871975, acc: 35.16%] [G loss: 2.676185]\n",
      "epoch:9 step:7056 [D loss: 0.666940, acc: 60.94%] [G loss: 2.727130]\n",
      "epoch:9 step:7057 [D loss: 0.260591, acc: 91.41%] [G loss: 2.764809]\n",
      "epoch:9 step:7058 [D loss: 0.278757, acc: 91.41%] [G loss: 3.180380]\n",
      "epoch:9 step:7059 [D loss: 0.788470, acc: 52.34%] [G loss: 2.598680]\n",
      "epoch:9 step:7060 [D loss: 0.409775, acc: 92.97%] [G loss: 1.822789]\n",
      "epoch:9 step:7061 [D loss: 0.638841, acc: 58.59%] [G loss: 2.073044]\n",
      "epoch:9 step:7062 [D loss: 0.590718, acc: 67.19%] [G loss: 2.380035]\n",
      "epoch:9 step:7063 [D loss: 0.409815, acc: 89.84%] [G loss: 2.552402]\n",
      "epoch:9 step:7064 [D loss: 0.684590, acc: 53.91%] [G loss: 2.318609]\n",
      "epoch:9 step:7065 [D loss: 0.409420, acc: 74.22%] [G loss: 3.043388]\n",
      "epoch:9 step:7066 [D loss: 0.772673, acc: 52.34%] [G loss: 2.381775]\n",
      "epoch:9 step:7067 [D loss: 0.319141, acc: 95.31%] [G loss: 2.724170]\n",
      "epoch:9 step:7068 [D loss: 0.525581, acc: 67.19%] [G loss: 3.463424]\n",
      "epoch:9 step:7069 [D loss: 0.538810, acc: 64.84%] [G loss: 3.142708]\n",
      "epoch:9 step:7070 [D loss: 0.331645, acc: 89.06%] [G loss: 2.748253]\n",
      "epoch:9 step:7071 [D loss: 0.449959, acc: 84.38%] [G loss: 2.514606]\n",
      "epoch:9 step:7072 [D loss: 0.742291, acc: 55.47%] [G loss: 2.389004]\n",
      "epoch:9 step:7073 [D loss: 1.243080, acc: 24.22%] [G loss: 2.454001]\n",
      "epoch:9 step:7074 [D loss: 0.604036, acc: 68.75%] [G loss: 2.421628]\n",
      "epoch:9 step:7075 [D loss: 0.645578, acc: 62.50%] [G loss: 2.303931]\n",
      "epoch:9 step:7076 [D loss: 0.860594, acc: 43.75%] [G loss: 1.708530]\n",
      "epoch:9 step:7077 [D loss: 0.435614, acc: 91.41%] [G loss: 1.846125]\n",
      "epoch:9 step:7078 [D loss: 0.718462, acc: 56.25%] [G loss: 2.177969]\n",
      "epoch:9 step:7079 [D loss: 0.552780, acc: 74.22%] [G loss: 2.126966]\n",
      "epoch:9 step:7080 [D loss: 0.713876, acc: 51.56%] [G loss: 1.908141]\n",
      "epoch:9 step:7081 [D loss: 0.658106, acc: 63.28%] [G loss: 1.724769]\n",
      "epoch:9 step:7082 [D loss: 0.464934, acc: 80.47%] [G loss: 1.854749]\n",
      "epoch:9 step:7083 [D loss: 0.648839, acc: 61.72%] [G loss: 2.531479]\n",
      "epoch:9 step:7084 [D loss: 0.903696, acc: 43.75%] [G loss: 2.089327]\n",
      "epoch:9 step:7085 [D loss: 1.007241, acc: 22.66%] [G loss: 1.821900]\n",
      "epoch:9 step:7086 [D loss: 0.547930, acc: 75.78%] [G loss: 1.934898]\n",
      "epoch:9 step:7087 [D loss: 0.721120, acc: 52.34%] [G loss: 1.913653]\n",
      "epoch:9 step:7088 [D loss: 0.788622, acc: 48.44%] [G loss: 1.878746]\n",
      "epoch:9 step:7089 [D loss: 0.547302, acc: 77.34%] [G loss: 1.593324]\n",
      "epoch:9 step:7090 [D loss: 0.674745, acc: 57.81%] [G loss: 1.773842]\n",
      "epoch:9 step:7091 [D loss: 0.587197, acc: 77.34%] [G loss: 2.284732]\n",
      "epoch:9 step:7092 [D loss: 0.517777, acc: 81.25%] [G loss: 1.966396]\n",
      "epoch:9 step:7093 [D loss: 0.851923, acc: 36.72%] [G loss: 1.921140]\n",
      "epoch:9 step:7094 [D loss: 0.625927, acc: 67.19%] [G loss: 2.038213]\n",
      "epoch:9 step:7095 [D loss: 0.573281, acc: 67.97%] [G loss: 1.906659]\n",
      "epoch:9 step:7096 [D loss: 0.702862, acc: 49.22%] [G loss: 1.954700]\n",
      "epoch:9 step:7097 [D loss: 0.763533, acc: 44.53%] [G loss: 1.797697]\n",
      "epoch:9 step:7098 [D loss: 0.485313, acc: 71.88%] [G loss: 1.912173]\n",
      "epoch:9 step:7099 [D loss: 0.621307, acc: 67.97%] [G loss: 1.804017]\n",
      "epoch:9 step:7100 [D loss: 0.828151, acc: 41.41%] [G loss: 1.813316]\n",
      "epoch:9 step:7101 [D loss: 0.690472, acc: 60.94%] [G loss: 1.768602]\n",
      "epoch:9 step:7102 [D loss: 0.456723, acc: 85.94%] [G loss: 2.022386]\n",
      "epoch:9 step:7103 [D loss: 0.669706, acc: 59.38%] [G loss: 1.898098]\n",
      "epoch:9 step:7104 [D loss: 0.330218, acc: 89.84%] [G loss: 2.140050]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:9 step:7105 [D loss: 0.492913, acc: 81.25%] [G loss: 2.114680]\n",
      "epoch:9 step:7106 [D loss: 0.867317, acc: 32.81%] [G loss: 2.008221]\n",
      "epoch:9 step:7107 [D loss: 0.567885, acc: 74.22%] [G loss: 2.137213]\n",
      "epoch:9 step:7108 [D loss: 0.822145, acc: 39.06%] [G loss: 1.618191]\n",
      "epoch:9 step:7109 [D loss: 0.496856, acc: 85.16%] [G loss: 1.869625]\n",
      "epoch:9 step:7110 [D loss: 0.590394, acc: 70.31%] [G loss: 1.824840]\n",
      "epoch:9 step:7111 [D loss: 0.768561, acc: 42.97%] [G loss: 1.825225]\n",
      "epoch:9 step:7112 [D loss: 0.570806, acc: 64.84%] [G loss: 2.682199]\n",
      "epoch:9 step:7113 [D loss: 0.756044, acc: 49.22%] [G loss: 1.631713]\n",
      "epoch:9 step:7114 [D loss: 0.979774, acc: 39.84%] [G loss: 1.653139]\n",
      "epoch:9 step:7115 [D loss: 1.260538, acc: 10.94%] [G loss: 1.719408]\n",
      "epoch:9 step:7116 [D loss: 0.709195, acc: 57.03%] [G loss: 1.761565]\n",
      "epoch:9 step:7117 [D loss: 0.678640, acc: 57.03%] [G loss: 1.598613]\n",
      "epoch:9 step:7118 [D loss: 0.574680, acc: 67.19%] [G loss: 2.141981]\n",
      "epoch:9 step:7119 [D loss: 0.559859, acc: 71.88%] [G loss: 1.659818]\n",
      "epoch:9 step:7120 [D loss: 0.690519, acc: 53.91%] [G loss: 1.763367]\n",
      "epoch:9 step:7121 [D loss: 0.704756, acc: 54.69%] [G loss: 1.870120]\n",
      "epoch:9 step:7122 [D loss: 0.595842, acc: 74.22%] [G loss: 1.657580]\n",
      "epoch:9 step:7123 [D loss: 0.434506, acc: 81.25%] [G loss: 1.980629]\n",
      "epoch:9 step:7124 [D loss: 0.766098, acc: 47.66%] [G loss: 1.635381]\n",
      "epoch:9 step:7125 [D loss: 0.443842, acc: 90.62%] [G loss: 2.036139]\n",
      "epoch:9 step:7126 [D loss: 0.598479, acc: 69.53%] [G loss: 2.248562]\n",
      "epoch:9 step:7127 [D loss: 0.527745, acc: 78.12%] [G loss: 1.867026]\n",
      "epoch:9 step:7128 [D loss: 0.434291, acc: 92.97%] [G loss: 1.983889]\n",
      "epoch:9 step:7129 [D loss: 0.732905, acc: 56.25%] [G loss: 1.541683]\n",
      "epoch:9 step:7130 [D loss: 0.610381, acc: 61.72%] [G loss: 2.227034]\n",
      "epoch:9 step:7131 [D loss: 0.587200, acc: 73.44%] [G loss: 2.127077]\n",
      "epoch:9 step:7132 [D loss: 0.705074, acc: 52.34%] [G loss: 2.045635]\n",
      "epoch:9 step:7133 [D loss: 0.552148, acc: 64.84%] [G loss: 2.415102]\n",
      "epoch:9 step:7134 [D loss: 0.519323, acc: 78.12%] [G loss: 1.890187]\n",
      "epoch:9 step:7135 [D loss: 0.476394, acc: 85.94%] [G loss: 2.271019]\n",
      "epoch:9 step:7136 [D loss: 0.502989, acc: 70.31%] [G loss: 2.668330]\n",
      "epoch:9 step:7137 [D loss: 0.747203, acc: 45.31%] [G loss: 1.664511]\n",
      "epoch:9 step:7138 [D loss: 0.527726, acc: 67.19%] [G loss: 2.264202]\n",
      "epoch:9 step:7139 [D loss: 0.527920, acc: 75.00%] [G loss: 1.884626]\n",
      "epoch:9 step:7140 [D loss: 0.348238, acc: 89.84%] [G loss: 2.783203]\n",
      "epoch:9 step:7141 [D loss: 0.688837, acc: 58.59%] [G loss: 2.257006]\n",
      "epoch:9 step:7142 [D loss: 0.830541, acc: 46.09%] [G loss: 2.572512]\n",
      "epoch:9 step:7143 [D loss: 0.527532, acc: 67.19%] [G loss: 3.204706]\n",
      "epoch:9 step:7144 [D loss: 0.394642, acc: 75.78%] [G loss: 3.004698]\n",
      "epoch:9 step:7145 [D loss: 0.860275, acc: 46.09%] [G loss: 1.986833]\n",
      "epoch:9 step:7146 [D loss: 0.591142, acc: 67.19%] [G loss: 2.058619]\n",
      "epoch:9 step:7147 [D loss: 0.535721, acc: 77.34%] [G loss: 1.890381]\n",
      "epoch:9 step:7148 [D loss: 0.833065, acc: 35.94%] [G loss: 2.123779]\n",
      "epoch:9 step:7149 [D loss: 0.675249, acc: 55.47%] [G loss: 2.091706]\n",
      "epoch:9 step:7150 [D loss: 0.507704, acc: 78.12%] [G loss: 2.200081]\n",
      "epoch:9 step:7151 [D loss: 0.766084, acc: 48.44%] [G loss: 2.183428]\n",
      "epoch:9 step:7152 [D loss: 0.550272, acc: 73.44%] [G loss: 2.013503]\n",
      "epoch:9 step:7153 [D loss: 0.545792, acc: 70.31%] [G loss: 1.989135]\n",
      "epoch:9 step:7154 [D loss: 0.888685, acc: 24.22%] [G loss: 1.860843]\n",
      "epoch:9 step:7155 [D loss: 0.633999, acc: 65.62%] [G loss: 2.588940]\n",
      "epoch:9 step:7156 [D loss: 0.830599, acc: 34.38%] [G loss: 1.913630]\n",
      "epoch:9 step:7157 [D loss: 0.391666, acc: 94.53%] [G loss: 2.849484]\n",
      "epoch:9 step:7158 [D loss: 0.489526, acc: 85.16%] [G loss: 2.645041]\n",
      "epoch:9 step:7159 [D loss: 0.834749, acc: 41.41%] [G loss: 1.992470]\n",
      "epoch:9 step:7160 [D loss: 0.368497, acc: 83.59%] [G loss: 2.762471]\n",
      "epoch:9 step:7161 [D loss: 0.463478, acc: 85.94%] [G loss: 2.792328]\n",
      "epoch:9 step:7162 [D loss: 0.600306, acc: 73.44%] [G loss: 2.249173]\n",
      "epoch:9 step:7163 [D loss: 0.433907, acc: 85.16%] [G loss: 2.288020]\n",
      "epoch:9 step:7164 [D loss: 0.635824, acc: 61.72%] [G loss: 1.721286]\n",
      "epoch:9 step:7165 [D loss: 0.410666, acc: 91.41%] [G loss: 2.771875]\n",
      "epoch:9 step:7166 [D loss: 0.891169, acc: 39.06%] [G loss: 1.693280]\n",
      "epoch:9 step:7167 [D loss: 0.633980, acc: 64.06%] [G loss: 1.912234]\n",
      "epoch:9 step:7168 [D loss: 0.506570, acc: 81.25%] [G loss: 2.012987]\n",
      "epoch:9 step:7169 [D loss: 0.431049, acc: 75.00%] [G loss: 2.333959]\n",
      "epoch:9 step:7170 [D loss: 0.466363, acc: 82.03%] [G loss: 2.263697]\n",
      "epoch:9 step:7171 [D loss: 0.273194, acc: 97.66%] [G loss: 2.438360]\n",
      "epoch:9 step:7172 [D loss: 0.623822, acc: 61.72%] [G loss: 2.228580]\n",
      "epoch:9 step:7173 [D loss: 0.627048, acc: 61.72%] [G loss: 1.808519]\n",
      "epoch:9 step:7174 [D loss: 0.815114, acc: 40.62%] [G loss: 1.591453]\n",
      "epoch:9 step:7175 [D loss: 0.521954, acc: 76.56%] [G loss: 1.948647]\n",
      "epoch:9 step:7176 [D loss: 0.731540, acc: 47.66%] [G loss: 2.130878]\n",
      "epoch:9 step:7177 [D loss: 0.740863, acc: 51.56%] [G loss: 2.215851]\n",
      "epoch:9 step:7178 [D loss: 0.812564, acc: 45.31%] [G loss: 2.161763]\n",
      "epoch:9 step:7179 [D loss: 0.591847, acc: 71.09%] [G loss: 3.312573]\n",
      "epoch:9 step:7180 [D loss: 0.563554, acc: 78.12%] [G loss: 2.016168]\n",
      "epoch:9 step:7181 [D loss: 0.670220, acc: 59.38%] [G loss: 2.576726]\n",
      "epoch:9 step:7182 [D loss: 0.570104, acc: 64.06%] [G loss: 2.949915]\n",
      "epoch:9 step:7183 [D loss: 0.627108, acc: 67.19%] [G loss: 2.284460]\n",
      "epoch:9 step:7184 [D loss: 0.801140, acc: 40.62%] [G loss: 1.850567]\n",
      "epoch:9 step:7185 [D loss: 0.370285, acc: 90.62%] [G loss: 2.080986]\n",
      "epoch:9 step:7186 [D loss: 0.387213, acc: 85.94%] [G loss: 2.018123]\n",
      "epoch:9 step:7187 [D loss: 0.341167, acc: 94.53%] [G loss: 2.272693]\n",
      "epoch:9 step:7188 [D loss: 0.828072, acc: 42.97%] [G loss: 1.908595]\n",
      "epoch:9 step:7189 [D loss: 0.869874, acc: 45.31%] [G loss: 2.060622]\n",
      "epoch:9 step:7190 [D loss: 0.710696, acc: 57.81%] [G loss: 1.942439]\n",
      "epoch:9 step:7191 [D loss: 0.258771, acc: 97.66%] [G loss: 1.893961]\n",
      "epoch:9 step:7192 [D loss: 0.617980, acc: 61.72%] [G loss: 1.808707]\n",
      "epoch:9 step:7193 [D loss: 0.402273, acc: 87.50%] [G loss: 2.890095]\n",
      "epoch:9 step:7194 [D loss: 0.871705, acc: 35.16%] [G loss: 1.681641]\n",
      "epoch:9 step:7195 [D loss: 0.618897, acc: 60.94%] [G loss: 2.128246]\n",
      "epoch:9 step:7196 [D loss: 0.570184, acc: 67.19%] [G loss: 2.070912]\n",
      "epoch:9 step:7197 [D loss: 0.580147, acc: 66.41%] [G loss: 2.096815]\n",
      "epoch:9 step:7198 [D loss: 0.408241, acc: 92.97%] [G loss: 1.979159]\n",
      "epoch:9 step:7199 [D loss: 0.615153, acc: 68.75%] [G loss: 2.101516]\n",
      "epoch:9 step:7200 [D loss: 0.657941, acc: 60.16%] [G loss: 2.095777]\n",
      "##############\n",
      "[0.84645981 0.8791895  0.82492353 0.80827498 0.79020833 0.83132467\n",
      " 0.88684154 0.84162036 0.82563783 0.8364085 ]\n",
      "##########\n",
      "epoch:9 step:7201 [D loss: 0.790902, acc: 42.97%] [G loss: 1.897406]\n",
      "epoch:9 step:7202 [D loss: 0.723187, acc: 53.12%] [G loss: 1.731446]\n",
      "epoch:9 step:7203 [D loss: 0.807641, acc: 50.78%] [G loss: 1.892972]\n",
      "epoch:9 step:7204 [D loss: 1.001756, acc: 28.91%] [G loss: 1.664714]\n",
      "epoch:9 step:7205 [D loss: 0.885834, acc: 22.66%] [G loss: 2.326758]\n",
      "epoch:9 step:7206 [D loss: 0.592100, acc: 63.28%] [G loss: 1.972362]\n",
      "epoch:9 step:7207 [D loss: 0.394468, acc: 84.38%] [G loss: 3.132173]\n",
      "epoch:9 step:7208 [D loss: 0.702539, acc: 52.34%] [G loss: 2.052566]\n",
      "epoch:9 step:7209 [D loss: 0.760984, acc: 43.75%] [G loss: 1.871325]\n",
      "epoch:9 step:7210 [D loss: 0.759333, acc: 46.09%] [G loss: 1.862298]\n",
      "epoch:9 step:7211 [D loss: 0.779884, acc: 42.97%] [G loss: 1.912879]\n",
      "epoch:9 step:7212 [D loss: 0.542616, acc: 75.78%] [G loss: 2.122183]\n",
      "epoch:9 step:7213 [D loss: 0.877501, acc: 23.44%] [G loss: 1.997692]\n",
      "epoch:9 step:7214 [D loss: 0.795201, acc: 49.22%] [G loss: 1.836855]\n",
      "epoch:9 step:7215 [D loss: 0.350300, acc: 87.50%] [G loss: 2.232600]\n",
      "epoch:9 step:7216 [D loss: 0.616411, acc: 61.72%] [G loss: 2.175019]\n",
      "epoch:9 step:7217 [D loss: 0.614150, acc: 61.72%] [G loss: 1.952067]\n",
      "epoch:9 step:7218 [D loss: 0.413030, acc: 91.41%] [G loss: 2.102981]\n",
      "epoch:9 step:7219 [D loss: 0.719678, acc: 52.34%] [G loss: 1.964635]\n",
      "epoch:9 step:7220 [D loss: 0.749499, acc: 53.12%] [G loss: 2.582892]\n",
      "epoch:9 step:7221 [D loss: 0.629467, acc: 66.41%] [G loss: 1.823613]\n",
      "epoch:9 step:7222 [D loss: 0.484839, acc: 82.03%] [G loss: 2.375963]\n",
      "epoch:9 step:7223 [D loss: 0.565413, acc: 78.12%] [G loss: 2.244328]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:9 step:7224 [D loss: 0.633065, acc: 64.84%] [G loss: 1.933632]\n",
      "epoch:9 step:7225 [D loss: 0.918307, acc: 28.12%] [G loss: 1.911907]\n",
      "epoch:9 step:7226 [D loss: 0.580718, acc: 72.66%] [G loss: 2.328566]\n",
      "epoch:9 step:7227 [D loss: 0.425067, acc: 92.19%] [G loss: 3.509707]\n",
      "epoch:9 step:7228 [D loss: 0.810896, acc: 44.53%] [G loss: 1.817418]\n",
      "epoch:9 step:7229 [D loss: 0.313007, acc: 92.19%] [G loss: 2.508898]\n",
      "epoch:9 step:7230 [D loss: 0.373070, acc: 91.41%] [G loss: 2.354755]\n",
      "epoch:9 step:7231 [D loss: 0.751767, acc: 44.53%] [G loss: 1.815721]\n",
      "epoch:9 step:7232 [D loss: 0.545241, acc: 75.00%] [G loss: 2.067091]\n",
      "epoch:9 step:7233 [D loss: 0.703053, acc: 57.81%] [G loss: 1.737269]\n",
      "epoch:9 step:7234 [D loss: 1.114947, acc: 32.81%] [G loss: 2.207157]\n",
      "epoch:9 step:7235 [D loss: 1.037705, acc: 25.78%] [G loss: 1.373019]\n",
      "epoch:9 step:7236 [D loss: 0.603086, acc: 66.41%] [G loss: 1.755764]\n",
      "epoch:9 step:7237 [D loss: 0.585765, acc: 74.22%] [G loss: 1.975718]\n",
      "epoch:9 step:7238 [D loss: 0.882776, acc: 45.31%] [G loss: 1.408195]\n",
      "epoch:9 step:7239 [D loss: 0.680543, acc: 57.03%] [G loss: 1.588295]\n",
      "epoch:9 step:7240 [D loss: 0.445022, acc: 90.62%] [G loss: 1.691876]\n",
      "epoch:9 step:7241 [D loss: 0.432540, acc: 88.28%] [G loss: 1.982375]\n",
      "epoch:9 step:7242 [D loss: 0.423487, acc: 78.91%] [G loss: 2.044942]\n",
      "epoch:9 step:7243 [D loss: 0.831249, acc: 43.75%] [G loss: 1.824301]\n",
      "epoch:9 step:7244 [D loss: 0.653438, acc: 65.62%] [G loss: 1.681897]\n",
      "epoch:9 step:7245 [D loss: 0.906656, acc: 27.34%] [G loss: 1.531708]\n",
      "epoch:9 step:7246 [D loss: 0.603096, acc: 67.97%] [G loss: 1.727939]\n",
      "epoch:9 step:7247 [D loss: 0.758730, acc: 45.31%] [G loss: 1.783889]\n",
      "epoch:9 step:7248 [D loss: 0.457214, acc: 84.38%] [G loss: 1.808695]\n",
      "epoch:9 step:7249 [D loss: 0.838819, acc: 40.62%] [G loss: 1.548330]\n",
      "epoch:9 step:7250 [D loss: 0.952905, acc: 24.22%] [G loss: 1.692850]\n",
      "epoch:9 step:7251 [D loss: 0.842373, acc: 45.31%] [G loss: 1.654564]\n",
      "epoch:9 step:7252 [D loss: 0.698039, acc: 56.25%] [G loss: 1.853116]\n",
      "epoch:9 step:7253 [D loss: 0.572112, acc: 71.09%] [G loss: 1.928380]\n",
      "epoch:9 step:7254 [D loss: 0.806148, acc: 46.88%] [G loss: 1.546425]\n",
      "epoch:9 step:7255 [D loss: 0.909470, acc: 30.47%] [G loss: 1.764392]\n",
      "epoch:9 step:7256 [D loss: 0.603368, acc: 67.97%] [G loss: 1.880250]\n",
      "epoch:9 step:7257 [D loss: 0.606511, acc: 67.97%] [G loss: 2.028029]\n",
      "epoch:9 step:7258 [D loss: 0.753339, acc: 53.91%] [G loss: 1.654340]\n",
      "epoch:9 step:7259 [D loss: 1.011937, acc: 21.88%] [G loss: 1.619573]\n",
      "epoch:9 step:7260 [D loss: 0.671424, acc: 55.47%] [G loss: 1.783112]\n",
      "epoch:9 step:7261 [D loss: 0.771328, acc: 46.09%] [G loss: 1.504411]\n",
      "epoch:9 step:7262 [D loss: 0.660901, acc: 61.72%] [G loss: 1.662837]\n",
      "epoch:9 step:7263 [D loss: 0.762522, acc: 46.88%] [G loss: 1.895015]\n",
      "epoch:9 step:7264 [D loss: 0.725111, acc: 53.12%] [G loss: 1.874290]\n",
      "epoch:9 step:7265 [D loss: 0.815542, acc: 41.41%] [G loss: 1.854440]\n",
      "epoch:9 step:7266 [D loss: 0.633891, acc: 63.28%] [G loss: 2.416476]\n",
      "epoch:9 step:7267 [D loss: 0.546889, acc: 71.88%] [G loss: 1.983257]\n",
      "epoch:9 step:7268 [D loss: 0.551057, acc: 76.56%] [G loss: 2.031003]\n",
      "epoch:9 step:7269 [D loss: 0.606078, acc: 68.75%] [G loss: 2.055010]\n",
      "epoch:9 step:7270 [D loss: 0.482640, acc: 80.47%] [G loss: 1.992280]\n",
      "epoch:9 step:7271 [D loss: 0.687754, acc: 54.69%] [G loss: 1.917799]\n",
      "epoch:9 step:7272 [D loss: 0.673772, acc: 58.59%] [G loss: 1.914502]\n",
      "epoch:9 step:7273 [D loss: 0.669828, acc: 55.47%] [G loss: 2.078051]\n",
      "epoch:9 step:7274 [D loss: 0.802138, acc: 47.66%] [G loss: 1.511050]\n",
      "epoch:9 step:7275 [D loss: 0.762146, acc: 42.97%] [G loss: 2.000298]\n",
      "epoch:9 step:7276 [D loss: 0.613180, acc: 67.19%] [G loss: 1.825536]\n",
      "epoch:9 step:7277 [D loss: 0.457468, acc: 85.16%] [G loss: 2.069268]\n",
      "epoch:9 step:7278 [D loss: 0.516179, acc: 78.91%] [G loss: 1.993286]\n",
      "epoch:9 step:7279 [D loss: 0.665148, acc: 56.25%] [G loss: 2.071200]\n",
      "epoch:9 step:7280 [D loss: 0.430577, acc: 88.28%] [G loss: 1.989892]\n",
      "epoch:9 step:7281 [D loss: 0.585981, acc: 67.19%] [G loss: 2.107490]\n",
      "epoch:9 step:7282 [D loss: 0.777878, acc: 50.78%] [G loss: 1.527552]\n",
      "epoch:9 step:7283 [D loss: 0.570132, acc: 75.00%] [G loss: 1.584066]\n",
      "epoch:9 step:7284 [D loss: 0.564459, acc: 67.19%] [G loss: 1.738752]\n",
      "epoch:9 step:7285 [D loss: 0.548809, acc: 75.78%] [G loss: 2.100213]\n",
      "epoch:9 step:7286 [D loss: 0.766976, acc: 56.25%] [G loss: 1.350186]\n",
      "epoch:9 step:7287 [D loss: 0.580647, acc: 68.75%] [G loss: 2.125529]\n",
      "epoch:9 step:7288 [D loss: 0.747572, acc: 49.22%] [G loss: 1.680958]\n",
      "epoch:9 step:7289 [D loss: 0.381435, acc: 92.19%] [G loss: 2.172146]\n",
      "epoch:9 step:7290 [D loss: 0.487277, acc: 81.25%] [G loss: 2.365078]\n",
      "epoch:9 step:7291 [D loss: 0.472602, acc: 82.81%] [G loss: 2.146865]\n",
      "epoch:9 step:7292 [D loss: 0.772900, acc: 52.34%] [G loss: 1.715829]\n",
      "epoch:9 step:7293 [D loss: 0.938231, acc: 33.59%] [G loss: 1.906405]\n",
      "epoch:9 step:7294 [D loss: 0.318473, acc: 95.31%] [G loss: 2.360814]\n",
      "epoch:9 step:7295 [D loss: 0.743061, acc: 50.00%] [G loss: 1.704051]\n",
      "epoch:9 step:7296 [D loss: 1.255727, acc: 11.72%] [G loss: 1.581580]\n",
      "epoch:9 step:7297 [D loss: 0.537910, acc: 75.00%] [G loss: 2.261951]\n",
      "epoch:9 step:7298 [D loss: 0.783755, acc: 42.97%] [G loss: 1.945196]\n",
      "epoch:9 step:7299 [D loss: 0.417061, acc: 89.84%] [G loss: 2.405838]\n",
      "epoch:9 step:7300 [D loss: 0.727914, acc: 50.00%] [G loss: 1.788956]\n",
      "epoch:9 step:7301 [D loss: 0.455264, acc: 75.78%] [G loss: 2.059831]\n",
      "epoch:9 step:7302 [D loss: 0.720144, acc: 53.91%] [G loss: 1.991418]\n",
      "epoch:9 step:7303 [D loss: 0.647066, acc: 65.62%] [G loss: 1.947970]\n",
      "epoch:9 step:7304 [D loss: 0.543696, acc: 76.56%] [G loss: 2.629512]\n",
      "epoch:9 step:7305 [D loss: 0.580114, acc: 73.44%] [G loss: 1.900275]\n",
      "epoch:9 step:7306 [D loss: 0.720528, acc: 50.78%] [G loss: 2.130900]\n",
      "epoch:9 step:7307 [D loss: 0.667311, acc: 62.50%] [G loss: 1.948220]\n",
      "epoch:9 step:7308 [D loss: 0.564022, acc: 76.56%] [G loss: 1.925268]\n",
      "epoch:9 step:7309 [D loss: 0.507259, acc: 80.47%] [G loss: 1.892221]\n",
      "epoch:9 step:7310 [D loss: 0.545769, acc: 75.00%] [G loss: 1.983702]\n",
      "epoch:9 step:7311 [D loss: 0.661775, acc: 60.94%] [G loss: 1.976106]\n",
      "epoch:9 step:7312 [D loss: 0.565530, acc: 72.66%] [G loss: 1.727474]\n",
      "epoch:9 step:7313 [D loss: 0.603208, acc: 66.41%] [G loss: 1.680281]\n",
      "epoch:9 step:7314 [D loss: 0.359939, acc: 93.75%] [G loss: 2.062387]\n",
      "epoch:9 step:7315 [D loss: 0.644610, acc: 62.50%] [G loss: 1.482603]\n",
      "epoch:9 step:7316 [D loss: 0.413692, acc: 92.19%] [G loss: 1.772384]\n",
      "epoch:9 step:7317 [D loss: 0.887176, acc: 37.50%] [G loss: 1.628673]\n",
      "epoch:9 step:7318 [D loss: 0.527712, acc: 75.78%] [G loss: 2.188003]\n",
      "epoch:9 step:7319 [D loss: 0.820015, acc: 50.00%] [G loss: 1.966774]\n",
      "epoch:9 step:7320 [D loss: 1.069357, acc: 25.00%] [G loss: 1.552351]\n",
      "epoch:9 step:7321 [D loss: 0.812735, acc: 49.22%] [G loss: 1.930596]\n",
      "epoch:9 step:7322 [D loss: 0.574817, acc: 69.53%] [G loss: 1.941046]\n",
      "epoch:9 step:7323 [D loss: 0.720630, acc: 53.91%] [G loss: 1.799467]\n",
      "epoch:9 step:7324 [D loss: 0.849459, acc: 34.38%] [G loss: 1.768612]\n",
      "epoch:9 step:7325 [D loss: 0.566439, acc: 77.34%] [G loss: 2.252506]\n",
      "epoch:9 step:7326 [D loss: 0.769660, acc: 39.06%] [G loss: 1.793747]\n",
      "epoch:9 step:7327 [D loss: 0.689619, acc: 53.91%] [G loss: 1.914664]\n",
      "epoch:9 step:7328 [D loss: 0.494087, acc: 84.38%] [G loss: 1.965327]\n",
      "epoch:9 step:7329 [D loss: 0.791891, acc: 42.19%] [G loss: 1.910338]\n",
      "epoch:9 step:7330 [D loss: 0.654218, acc: 58.59%] [G loss: 1.824772]\n",
      "epoch:9 step:7331 [D loss: 0.575434, acc: 73.44%] [G loss: 1.968803]\n",
      "epoch:9 step:7332 [D loss: 0.798166, acc: 46.09%] [G loss: 1.741901]\n",
      "epoch:9 step:7333 [D loss: 0.506207, acc: 82.81%] [G loss: 2.451917]\n",
      "epoch:9 step:7334 [D loss: 0.412784, acc: 89.06%] [G loss: 3.099748]\n",
      "epoch:9 step:7335 [D loss: 0.791774, acc: 49.22%] [G loss: 1.701834]\n",
      "epoch:9 step:7336 [D loss: 0.809648, acc: 46.09%] [G loss: 1.906172]\n",
      "epoch:9 step:7337 [D loss: 0.671179, acc: 60.16%] [G loss: 2.165360]\n",
      "epoch:9 step:7338 [D loss: 0.466806, acc: 88.28%] [G loss: 2.221583]\n",
      "epoch:9 step:7339 [D loss: 0.571701, acc: 79.69%] [G loss: 2.016110]\n",
      "epoch:9 step:7340 [D loss: 0.333372, acc: 93.75%] [G loss: 2.162145]\n",
      "epoch:9 step:7341 [D loss: 0.736431, acc: 51.56%] [G loss: 1.888392]\n",
      "epoch:9 step:7342 [D loss: 0.438137, acc: 85.94%] [G loss: 2.030128]\n",
      "epoch:9 step:7343 [D loss: 0.702040, acc: 49.22%] [G loss: 1.977133]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:9 step:7344 [D loss: 0.627218, acc: 65.62%] [G loss: 1.900426]\n",
      "epoch:9 step:7345 [D loss: 0.779959, acc: 51.56%] [G loss: 1.639054]\n",
      "epoch:9 step:7346 [D loss: 0.709179, acc: 50.00%] [G loss: 1.700061]\n",
      "epoch:9 step:7347 [D loss: 0.505237, acc: 82.81%] [G loss: 1.771329]\n",
      "epoch:9 step:7348 [D loss: 0.657124, acc: 61.72%] [G loss: 1.986202]\n",
      "epoch:9 step:7349 [D loss: 1.066783, acc: 29.69%] [G loss: 1.607483]\n",
      "epoch:9 step:7350 [D loss: 0.579322, acc: 74.22%] [G loss: 1.958250]\n",
      "epoch:9 step:7351 [D loss: 0.657932, acc: 63.28%] [G loss: 1.821710]\n",
      "epoch:9 step:7352 [D loss: 0.423219, acc: 88.28%] [G loss: 1.805388]\n",
      "epoch:9 step:7353 [D loss: 0.482670, acc: 83.59%] [G loss: 2.206192]\n",
      "epoch:9 step:7354 [D loss: 0.750952, acc: 51.56%] [G loss: 1.859906]\n",
      "epoch:9 step:7355 [D loss: 0.769963, acc: 44.53%] [G loss: 1.824418]\n",
      "epoch:9 step:7356 [D loss: 0.622198, acc: 67.19%] [G loss: 1.844912]\n",
      "epoch:9 step:7357 [D loss: 0.338019, acc: 91.41%] [G loss: 2.182488]\n",
      "epoch:9 step:7358 [D loss: 0.547869, acc: 77.34%] [G loss: 1.769693]\n",
      "epoch:9 step:7359 [D loss: 0.827734, acc: 41.41%] [G loss: 2.079410]\n",
      "epoch:9 step:7360 [D loss: 0.727743, acc: 53.12%] [G loss: 1.753377]\n",
      "epoch:9 step:7361 [D loss: 0.460141, acc: 88.28%] [G loss: 2.106714]\n",
      "epoch:9 step:7362 [D loss: 0.503505, acc: 77.34%] [G loss: 1.975012]\n",
      "epoch:9 step:7363 [D loss: 0.798120, acc: 39.06%] [G loss: 1.700501]\n",
      "epoch:9 step:7364 [D loss: 0.643464, acc: 61.72%] [G loss: 2.444253]\n",
      "epoch:9 step:7365 [D loss: 0.631118, acc: 64.84%] [G loss: 2.464911]\n",
      "epoch:9 step:7366 [D loss: 0.929288, acc: 34.38%] [G loss: 2.062579]\n",
      "epoch:9 step:7367 [D loss: 0.875733, acc: 34.38%] [G loss: 2.316100]\n",
      "epoch:9 step:7368 [D loss: 0.582452, acc: 70.31%] [G loss: 2.191035]\n",
      "epoch:9 step:7369 [D loss: 0.850684, acc: 39.06%] [G loss: 1.806027]\n",
      "epoch:9 step:7370 [D loss: 0.590353, acc: 67.97%] [G loss: 2.372323]\n",
      "epoch:9 step:7371 [D loss: 0.485147, acc: 86.72%] [G loss: 2.177650]\n",
      "epoch:9 step:7372 [D loss: 0.711574, acc: 57.81%] [G loss: 1.703908]\n",
      "epoch:9 step:7373 [D loss: 0.616084, acc: 67.19%] [G loss: 1.859200]\n",
      "epoch:9 step:7374 [D loss: 0.665797, acc: 57.81%] [G loss: 1.812922]\n",
      "epoch:9 step:7375 [D loss: 0.603967, acc: 68.75%] [G loss: 2.027674]\n",
      "epoch:9 step:7376 [D loss: 0.743933, acc: 52.34%] [G loss: 1.773598]\n",
      "epoch:9 step:7377 [D loss: 0.998314, acc: 27.34%] [G loss: 1.762780]\n",
      "epoch:9 step:7378 [D loss: 0.790973, acc: 44.53%] [G loss: 2.174237]\n",
      "epoch:9 step:7379 [D loss: 0.566385, acc: 67.97%] [G loss: 2.089223]\n",
      "epoch:9 step:7380 [D loss: 0.539668, acc: 66.41%] [G loss: 1.936673]\n",
      "epoch:9 step:7381 [D loss: 0.734594, acc: 54.69%] [G loss: 2.040499]\n",
      "epoch:9 step:7382 [D loss: 0.639023, acc: 64.06%] [G loss: 2.147755]\n",
      "epoch:9 step:7383 [D loss: 0.826657, acc: 39.84%] [G loss: 1.362955]\n",
      "epoch:9 step:7384 [D loss: 0.797712, acc: 37.50%] [G loss: 1.681854]\n",
      "epoch:9 step:7385 [D loss: 0.730131, acc: 53.91%] [G loss: 1.890933]\n",
      "epoch:9 step:7386 [D loss: 0.671741, acc: 59.38%] [G loss: 1.859210]\n",
      "epoch:9 step:7387 [D loss: 0.828736, acc: 42.97%] [G loss: 1.339801]\n",
      "epoch:9 step:7388 [D loss: 0.825354, acc: 38.28%] [G loss: 1.551500]\n",
      "epoch:9 step:7389 [D loss: 0.659113, acc: 59.38%] [G loss: 1.875043]\n",
      "epoch:9 step:7390 [D loss: 0.629569, acc: 65.62%] [G loss: 2.021021]\n",
      "epoch:9 step:7391 [D loss: 0.751825, acc: 42.97%] [G loss: 1.660736]\n",
      "epoch:9 step:7392 [D loss: 0.710696, acc: 52.34%] [G loss: 2.040833]\n",
      "epoch:9 step:7393 [D loss: 0.536556, acc: 72.66%] [G loss: 2.091611]\n",
      "epoch:9 step:7394 [D loss: 0.522316, acc: 66.41%] [G loss: 2.350849]\n",
      "epoch:9 step:7395 [D loss: 0.889224, acc: 43.75%] [G loss: 1.596002]\n",
      "epoch:9 step:7396 [D loss: 0.707742, acc: 50.00%] [G loss: 2.175389]\n",
      "epoch:9 step:7397 [D loss: 0.382875, acc: 93.75%] [G loss: 2.319397]\n",
      "epoch:9 step:7398 [D loss: 0.463764, acc: 82.03%] [G loss: 1.858394]\n",
      "epoch:9 step:7399 [D loss: 0.715487, acc: 54.69%] [G loss: 1.497631]\n",
      "epoch:9 step:7400 [D loss: 0.570037, acc: 72.66%] [G loss: 1.969803]\n",
      "##############\n",
      "[0.84750373 0.89260881 0.81941876 0.81294493 0.77698542 0.82714414\n",
      " 0.90722209 0.82130027 0.83848835 0.81980703]\n",
      "##########\n",
      "epoch:9 step:7401 [D loss: 0.651118, acc: 63.28%] [G loss: 2.373642]\n",
      "epoch:9 step:7402 [D loss: 0.912838, acc: 44.53%] [G loss: 1.675828]\n",
      "epoch:9 step:7403 [D loss: 0.656563, acc: 64.84%] [G loss: 2.035723]\n",
      "epoch:9 step:7404 [D loss: 0.566779, acc: 73.44%] [G loss: 1.865281]\n",
      "epoch:9 step:7405 [D loss: 0.640523, acc: 63.28%] [G loss: 2.034479]\n",
      "epoch:9 step:7406 [D loss: 0.452370, acc: 82.81%] [G loss: 2.452141]\n",
      "epoch:9 step:7407 [D loss: 0.643172, acc: 61.72%] [G loss: 1.761510]\n",
      "epoch:9 step:7408 [D loss: 0.623488, acc: 65.62%] [G loss: 2.118867]\n",
      "epoch:9 step:7409 [D loss: 0.781448, acc: 47.66%] [G loss: 1.627196]\n",
      "epoch:9 step:7410 [D loss: 0.648080, acc: 60.16%] [G loss: 1.877189]\n",
      "epoch:9 step:7411 [D loss: 0.571895, acc: 67.19%] [G loss: 2.012895]\n",
      "epoch:9 step:7412 [D loss: 0.461623, acc: 75.00%] [G loss: 1.756058]\n",
      "epoch:9 step:7413 [D loss: 0.735189, acc: 58.59%] [G loss: 2.089068]\n",
      "epoch:9 step:7414 [D loss: 0.512012, acc: 78.12%] [G loss: 2.055083]\n",
      "epoch:9 step:7415 [D loss: 0.710325, acc: 52.34%] [G loss: 1.666468]\n",
      "epoch:9 step:7416 [D loss: 0.625675, acc: 67.97%] [G loss: 1.804052]\n",
      "epoch:9 step:7417 [D loss: 0.945239, acc: 26.56%] [G loss: 1.824901]\n",
      "epoch:9 step:7418 [D loss: 0.600933, acc: 70.31%] [G loss: 1.928192]\n",
      "epoch:9 step:7419 [D loss: 0.627065, acc: 67.97%] [G loss: 1.752205]\n",
      "epoch:9 step:7420 [D loss: 1.411171, acc: 29.69%] [G loss: 1.233899]\n",
      "epoch:9 step:7421 [D loss: 0.739749, acc: 53.12%] [G loss: 2.003106]\n",
      "epoch:9 step:7422 [D loss: 0.690478, acc: 57.81%] [G loss: 1.859336]\n",
      "epoch:9 step:7423 [D loss: 0.673255, acc: 60.16%] [G loss: 1.977490]\n",
      "epoch:9 step:7424 [D loss: 0.485909, acc: 80.47%] [G loss: 2.244930]\n",
      "epoch:9 step:7425 [D loss: 0.487247, acc: 79.69%] [G loss: 1.881872]\n",
      "epoch:9 step:7426 [D loss: 0.651021, acc: 63.28%] [G loss: 1.908642]\n",
      "epoch:9 step:7427 [D loss: 0.610567, acc: 66.41%] [G loss: 1.899643]\n",
      "epoch:9 step:7428 [D loss: 0.406731, acc: 90.62%] [G loss: 2.214095]\n",
      "epoch:9 step:7429 [D loss: 0.466054, acc: 81.25%] [G loss: 1.895081]\n",
      "epoch:9 step:7430 [D loss: 0.566424, acc: 75.00%] [G loss: 1.934921]\n",
      "epoch:9 step:7431 [D loss: 0.708256, acc: 53.12%] [G loss: 1.816438]\n",
      "epoch:9 step:7432 [D loss: 0.470026, acc: 84.38%] [G loss: 2.237161]\n",
      "epoch:9 step:7433 [D loss: 0.333869, acc: 96.09%] [G loss: 2.366475]\n",
      "epoch:9 step:7434 [D loss: 0.624328, acc: 60.94%] [G loss: 2.186340]\n",
      "epoch:9 step:7435 [D loss: 0.661473, acc: 61.72%] [G loss: 1.951121]\n",
      "epoch:9 step:7436 [D loss: 0.586600, acc: 67.19%] [G loss: 1.867970]\n",
      "epoch:9 step:7437 [D loss: 0.628313, acc: 60.94%] [G loss: 1.720442]\n",
      "epoch:9 step:7438 [D loss: 0.633368, acc: 62.50%] [G loss: 1.796231]\n",
      "epoch:9 step:7439 [D loss: 0.838184, acc: 41.41%] [G loss: 1.709492]\n",
      "epoch:9 step:7440 [D loss: 0.653348, acc: 64.06%] [G loss: 2.354666]\n",
      "epoch:9 step:7441 [D loss: 0.695764, acc: 56.25%] [G loss: 1.856490]\n",
      "epoch:9 step:7442 [D loss: 0.672761, acc: 58.59%] [G loss: 1.790316]\n",
      "epoch:9 step:7443 [D loss: 0.342810, acc: 92.97%] [G loss: 2.011998]\n",
      "epoch:9 step:7444 [D loss: 0.516152, acc: 80.47%] [G loss: 2.412013]\n",
      "epoch:9 step:7445 [D loss: 0.652277, acc: 67.97%] [G loss: 1.983920]\n",
      "epoch:9 step:7446 [D loss: 0.611799, acc: 66.41%] [G loss: 2.085255]\n",
      "epoch:9 step:7447 [D loss: 0.558793, acc: 75.78%] [G loss: 1.892643]\n",
      "epoch:9 step:7448 [D loss: 0.694499, acc: 53.91%] [G loss: 1.633150]\n",
      "epoch:9 step:7449 [D loss: 0.579898, acc: 71.88%] [G loss: 1.911038]\n",
      "epoch:9 step:7450 [D loss: 0.765166, acc: 42.19%] [G loss: 1.574347]\n",
      "epoch:9 step:7451 [D loss: 0.623658, acc: 61.72%] [G loss: 1.875391]\n",
      "epoch:9 step:7452 [D loss: 0.773489, acc: 46.88%] [G loss: 1.943821]\n",
      "epoch:9 step:7453 [D loss: 0.695979, acc: 60.16%] [G loss: 2.012693]\n",
      "epoch:9 step:7454 [D loss: 0.614559, acc: 63.28%] [G loss: 1.966138]\n",
      "epoch:9 step:7455 [D loss: 0.741072, acc: 46.88%] [G loss: 2.009576]\n",
      "epoch:9 step:7456 [D loss: 0.522340, acc: 73.44%] [G loss: 2.028607]\n",
      "epoch:9 step:7457 [D loss: 0.822859, acc: 39.06%] [G loss: 2.136240]\n",
      "epoch:9 step:7458 [D loss: 0.540722, acc: 78.12%] [G loss: 1.937191]\n",
      "epoch:9 step:7459 [D loss: 0.646200, acc: 65.62%] [G loss: 2.160449]\n",
      "epoch:9 step:7460 [D loss: 0.523939, acc: 75.00%] [G loss: 1.949888]\n",
      "epoch:9 step:7461 [D loss: 0.429042, acc: 89.84%] [G loss: 2.273476]\n",
      "epoch:9 step:7462 [D loss: 0.530342, acc: 73.44%] [G loss: 1.769236]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:9 step:7463 [D loss: 1.074136, acc: 23.44%] [G loss: 1.614079]\n",
      "epoch:9 step:7464 [D loss: 0.795006, acc: 44.53%] [G loss: 1.699611]\n",
      "epoch:9 step:7465 [D loss: 0.894266, acc: 28.12%] [G loss: 2.078796]\n",
      "epoch:9 step:7466 [D loss: 0.465522, acc: 68.75%] [G loss: 2.480620]\n",
      "epoch:9 step:7467 [D loss: 0.720719, acc: 53.91%] [G loss: 2.030047]\n",
      "epoch:9 step:7468 [D loss: 0.635664, acc: 61.72%] [G loss: 1.721176]\n",
      "epoch:9 step:7469 [D loss: 0.774923, acc: 48.44%] [G loss: 1.768380]\n",
      "epoch:9 step:7470 [D loss: 0.594189, acc: 72.66%] [G loss: 2.147515]\n",
      "epoch:9 step:7471 [D loss: 0.684061, acc: 56.25%] [G loss: 1.913460]\n",
      "epoch:9 step:7472 [D loss: 0.688074, acc: 53.91%] [G loss: 1.925748]\n",
      "epoch:9 step:7473 [D loss: 0.748753, acc: 49.22%] [G loss: 1.821897]\n",
      "epoch:9 step:7474 [D loss: 0.752440, acc: 50.00%] [G loss: 1.672017]\n",
      "epoch:9 step:7475 [D loss: 0.716083, acc: 47.66%] [G loss: 1.865264]\n",
      "epoch:9 step:7476 [D loss: 0.686822, acc: 50.00%] [G loss: 1.741386]\n",
      "epoch:9 step:7477 [D loss: 0.579573, acc: 75.78%] [G loss: 1.862475]\n",
      "epoch:9 step:7478 [D loss: 0.499250, acc: 77.34%] [G loss: 1.926871]\n",
      "epoch:9 step:7479 [D loss: 0.546281, acc: 75.78%] [G loss: 2.121134]\n",
      "epoch:9 step:7480 [D loss: 0.824457, acc: 31.25%] [G loss: 1.765291]\n",
      "epoch:9 step:7481 [D loss: 0.708104, acc: 52.34%] [G loss: 1.746912]\n",
      "epoch:9 step:7482 [D loss: 0.667740, acc: 57.81%] [G loss: 1.909132]\n",
      "epoch:9 step:7483 [D loss: 0.577043, acc: 69.53%] [G loss: 1.755383]\n",
      "epoch:9 step:7484 [D loss: 0.508321, acc: 73.44%] [G loss: 2.179335]\n",
      "epoch:9 step:7485 [D loss: 0.683809, acc: 57.81%] [G loss: 2.015184]\n",
      "epoch:9 step:7486 [D loss: 0.861301, acc: 42.97%] [G loss: 1.665756]\n",
      "epoch:9 step:7487 [D loss: 0.582110, acc: 71.09%] [G loss: 2.132297]\n",
      "epoch:9 step:7488 [D loss: 0.694735, acc: 57.81%] [G loss: 1.820624]\n",
      "epoch:9 step:7489 [D loss: 0.675722, acc: 56.25%] [G loss: 1.849619]\n",
      "epoch:9 step:7490 [D loss: 0.513269, acc: 77.34%] [G loss: 2.267051]\n",
      "epoch:9 step:7491 [D loss: 0.562886, acc: 76.56%] [G loss: 2.137209]\n",
      "epoch:9 step:7492 [D loss: 0.627882, acc: 65.62%] [G loss: 1.939254]\n",
      "epoch:9 step:7493 [D loss: 0.564594, acc: 81.25%] [G loss: 1.690343]\n",
      "epoch:9 step:7494 [D loss: 0.739684, acc: 50.78%] [G loss: 1.784094]\n",
      "epoch:9 step:7495 [D loss: 0.591397, acc: 65.62%] [G loss: 1.998587]\n",
      "epoch:9 step:7496 [D loss: 0.572845, acc: 63.28%] [G loss: 1.776940]\n",
      "epoch:9 step:7497 [D loss: 0.697509, acc: 57.81%] [G loss: 1.824907]\n",
      "epoch:9 step:7498 [D loss: 0.754176, acc: 53.12%] [G loss: 2.031015]\n",
      "epoch:9 step:7499 [D loss: 0.700884, acc: 50.78%] [G loss: 1.547878]\n",
      "epoch:9 step:7500 [D loss: 0.718425, acc: 53.91%] [G loss: 1.929609]\n",
      "epoch:9 step:7501 [D loss: 0.878166, acc: 32.03%] [G loss: 1.550486]\n",
      "epoch:9 step:7502 [D loss: 0.886741, acc: 35.16%] [G loss: 1.982006]\n",
      "epoch:9 step:7503 [D loss: 0.688994, acc: 53.12%] [G loss: 1.766000]\n",
      "epoch:9 step:7504 [D loss: 0.593150, acc: 67.97%] [G loss: 1.905607]\n",
      "epoch:9 step:7505 [D loss: 0.602012, acc: 63.28%] [G loss: 2.009733]\n",
      "epoch:9 step:7506 [D loss: 0.456652, acc: 83.59%] [G loss: 1.868142]\n",
      "epoch:9 step:7507 [D loss: 0.487464, acc: 80.47%] [G loss: 1.811252]\n",
      "epoch:9 step:7508 [D loss: 0.715132, acc: 50.78%] [G loss: 1.765724]\n",
      "epoch:9 step:7509 [D loss: 0.630884, acc: 65.62%] [G loss: 1.500179]\n",
      "epoch:9 step:7510 [D loss: 0.817678, acc: 39.06%] [G loss: 1.728963]\n",
      "epoch:9 step:7511 [D loss: 0.590666, acc: 69.53%] [G loss: 1.957876]\n",
      "epoch:9 step:7512 [D loss: 0.630194, acc: 63.28%] [G loss: 1.779628]\n",
      "epoch:9 step:7513 [D loss: 0.625257, acc: 62.50%] [G loss: 1.788321]\n",
      "epoch:9 step:7514 [D loss: 0.483092, acc: 81.25%] [G loss: 2.010977]\n",
      "epoch:9 step:7515 [D loss: 0.730237, acc: 48.44%] [G loss: 1.982487]\n",
      "epoch:9 step:7516 [D loss: 0.667890, acc: 60.16%] [G loss: 1.993771]\n",
      "epoch:9 step:7517 [D loss: 0.786358, acc: 46.09%] [G loss: 1.478698]\n",
      "epoch:9 step:7518 [D loss: 0.577519, acc: 71.88%] [G loss: 2.071697]\n",
      "epoch:9 step:7519 [D loss: 0.756076, acc: 51.56%] [G loss: 1.582884]\n",
      "epoch:9 step:7520 [D loss: 0.851516, acc: 36.72%] [G loss: 1.728042]\n",
      "epoch:9 step:7521 [D loss: 1.051632, acc: 15.62%] [G loss: 1.840662]\n",
      "epoch:9 step:7522 [D loss: 0.675203, acc: 55.47%] [G loss: 2.002362]\n",
      "epoch:9 step:7523 [D loss: 0.703026, acc: 58.59%] [G loss: 2.075124]\n",
      "epoch:9 step:7524 [D loss: 0.568805, acc: 72.66%] [G loss: 1.711186]\n",
      "epoch:9 step:7525 [D loss: 0.713130, acc: 53.12%] [G loss: 1.832690]\n",
      "epoch:9 step:7526 [D loss: 0.572862, acc: 67.97%] [G loss: 1.916895]\n",
      "epoch:9 step:7527 [D loss: 0.642649, acc: 63.28%] [G loss: 1.871720]\n",
      "epoch:9 step:7528 [D loss: 0.838058, acc: 42.19%] [G loss: 1.808101]\n",
      "epoch:9 step:7529 [D loss: 0.658651, acc: 57.81%] [G loss: 1.579323]\n",
      "epoch:9 step:7530 [D loss: 0.619128, acc: 64.06%] [G loss: 1.915196]\n",
      "epoch:9 step:7531 [D loss: 0.673073, acc: 55.47%] [G loss: 1.726855]\n",
      "epoch:9 step:7532 [D loss: 0.596309, acc: 64.84%] [G loss: 2.259171]\n",
      "epoch:9 step:7533 [D loss: 0.835365, acc: 34.38%] [G loss: 1.579578]\n",
      "epoch:9 step:7534 [D loss: 0.772807, acc: 41.41%] [G loss: 1.780763]\n",
      "epoch:9 step:7535 [D loss: 0.646483, acc: 61.72%] [G loss: 1.735860]\n",
      "epoch:9 step:7536 [D loss: 0.700109, acc: 54.69%] [G loss: 1.880863]\n",
      "epoch:9 step:7537 [D loss: 0.803040, acc: 40.62%] [G loss: 1.991536]\n",
      "epoch:9 step:7538 [D loss: 0.636139, acc: 60.16%] [G loss: 2.132299]\n",
      "epoch:9 step:7539 [D loss: 0.703277, acc: 56.25%] [G loss: 1.905023]\n",
      "epoch:9 step:7540 [D loss: 0.666721, acc: 57.03%] [G loss: 2.033800]\n",
      "epoch:9 step:7541 [D loss: 0.647615, acc: 67.19%] [G loss: 1.554597]\n",
      "epoch:9 step:7542 [D loss: 0.676245, acc: 57.81%] [G loss: 2.053433]\n",
      "epoch:9 step:7543 [D loss: 0.607986, acc: 64.06%] [G loss: 1.919031]\n",
      "epoch:9 step:7544 [D loss: 0.716235, acc: 50.78%] [G loss: 1.578202]\n",
      "epoch:9 step:7545 [D loss: 0.596587, acc: 66.41%] [G loss: 1.660597]\n",
      "epoch:9 step:7546 [D loss: 0.442459, acc: 84.38%] [G loss: 1.796563]\n",
      "epoch:9 step:7547 [D loss: 0.531171, acc: 79.69%] [G loss: 1.670045]\n",
      "epoch:9 step:7548 [D loss: 0.636421, acc: 68.75%] [G loss: 1.950615]\n",
      "epoch:9 step:7549 [D loss: 0.497433, acc: 78.91%] [G loss: 1.650689]\n",
      "epoch:9 step:7550 [D loss: 0.625568, acc: 65.62%] [G loss: 1.933783]\n",
      "epoch:9 step:7551 [D loss: 0.650102, acc: 64.06%] [G loss: 1.569829]\n",
      "epoch:9 step:7552 [D loss: 0.535918, acc: 76.56%] [G loss: 1.816474]\n",
      "epoch:9 step:7553 [D loss: 0.488068, acc: 82.03%] [G loss: 1.661965]\n",
      "epoch:9 step:7554 [D loss: 0.738126, acc: 50.78%] [G loss: 1.541322]\n",
      "epoch:9 step:7555 [D loss: 1.336156, acc: 10.94%] [G loss: 1.800564]\n",
      "epoch:9 step:7556 [D loss: 0.642949, acc: 60.94%] [G loss: 1.824223]\n",
      "epoch:9 step:7557 [D loss: 0.960187, acc: 27.34%] [G loss: 1.666167]\n",
      "epoch:9 step:7558 [D loss: 0.611657, acc: 61.72%] [G loss: 2.078962]\n",
      "epoch:9 step:7559 [D loss: 0.587513, acc: 69.53%] [G loss: 1.736375]\n",
      "epoch:9 step:7560 [D loss: 0.644431, acc: 67.19%] [G loss: 1.675923]\n",
      "epoch:9 step:7561 [D loss: 0.727431, acc: 54.69%] [G loss: 1.647534]\n",
      "epoch:9 step:7562 [D loss: 0.612398, acc: 68.75%] [G loss: 1.856400]\n",
      "epoch:9 step:7563 [D loss: 0.566427, acc: 75.78%] [G loss: 2.210466]\n",
      "epoch:9 step:7564 [D loss: 0.650213, acc: 65.62%] [G loss: 1.843755]\n",
      "epoch:9 step:7565 [D loss: 0.683651, acc: 57.81%] [G loss: 2.407623]\n",
      "epoch:9 step:7566 [D loss: 0.589350, acc: 74.22%] [G loss: 1.988800]\n",
      "epoch:9 step:7567 [D loss: 0.493161, acc: 80.47%] [G loss: 2.180588]\n",
      "epoch:9 step:7568 [D loss: 0.505506, acc: 73.44%] [G loss: 2.103382]\n",
      "epoch:9 step:7569 [D loss: 0.535949, acc: 76.56%] [G loss: 2.038470]\n",
      "epoch:9 step:7570 [D loss: 0.464741, acc: 88.28%] [G loss: 1.925994]\n",
      "epoch:9 step:7571 [D loss: 0.568425, acc: 71.88%] [G loss: 1.803552]\n",
      "epoch:9 step:7572 [D loss: 0.536372, acc: 72.66%] [G loss: 1.950252]\n",
      "epoch:9 step:7573 [D loss: 0.648571, acc: 63.28%] [G loss: 1.684408]\n",
      "epoch:9 step:7574 [D loss: 0.636623, acc: 62.50%] [G loss: 1.902537]\n",
      "epoch:9 step:7575 [D loss: 0.925848, acc: 32.03%] [G loss: 1.835294]\n",
      "epoch:9 step:7576 [D loss: 0.543650, acc: 75.00%] [G loss: 1.794489]\n",
      "epoch:9 step:7577 [D loss: 0.820885, acc: 46.88%] [G loss: 1.639973]\n",
      "epoch:9 step:7578 [D loss: 0.589289, acc: 66.41%] [G loss: 1.762547]\n",
      "epoch:9 step:7579 [D loss: 0.803558, acc: 48.44%] [G loss: 1.694438]\n",
      "epoch:9 step:7580 [D loss: 0.482513, acc: 85.94%] [G loss: 1.838456]\n",
      "epoch:9 step:7581 [D loss: 0.952615, acc: 21.09%] [G loss: 1.347104]\n",
      "epoch:9 step:7582 [D loss: 0.870229, acc: 36.72%] [G loss: 1.610321]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:9 step:7583 [D loss: 0.665671, acc: 59.38%] [G loss: 2.426994]\n",
      "epoch:9 step:7584 [D loss: 0.623042, acc: 62.50%] [G loss: 1.855499]\n",
      "epoch:9 step:7585 [D loss: 0.501702, acc: 84.38%] [G loss: 2.138618]\n",
      "epoch:9 step:7586 [D loss: 0.855837, acc: 27.34%] [G loss: 1.938751]\n",
      "epoch:9 step:7587 [D loss: 0.834620, acc: 39.84%] [G loss: 1.830421]\n",
      "epoch:9 step:7588 [D loss: 0.409231, acc: 80.47%] [G loss: 1.936532]\n",
      "epoch:9 step:7589 [D loss: 0.941257, acc: 23.44%] [G loss: 1.784517]\n",
      "epoch:9 step:7590 [D loss: 0.592669, acc: 74.22%] [G loss: 2.024253]\n",
      "epoch:9 step:7591 [D loss: 0.741609, acc: 55.47%] [G loss: 1.778088]\n",
      "epoch:9 step:7592 [D loss: 1.100484, acc: 20.31%] [G loss: 1.536113]\n",
      "epoch:9 step:7593 [D loss: 0.633704, acc: 60.16%] [G loss: 1.724795]\n",
      "epoch:9 step:7594 [D loss: 0.476170, acc: 87.50%] [G loss: 2.150527]\n",
      "epoch:9 step:7595 [D loss: 0.617105, acc: 60.94%] [G loss: 2.122628]\n",
      "epoch:9 step:7596 [D loss: 0.534771, acc: 72.66%] [G loss: 2.398725]\n",
      "epoch:9 step:7597 [D loss: 0.498434, acc: 81.25%] [G loss: 1.920996]\n",
      "epoch:9 step:7598 [D loss: 0.647435, acc: 64.06%] [G loss: 1.878662]\n",
      "epoch:9 step:7599 [D loss: 0.544574, acc: 74.22%] [G loss: 2.159893]\n",
      "epoch:9 step:7600 [D loss: 0.627779, acc: 67.19%] [G loss: 2.062136]\n",
      "##############\n",
      "[0.8558859  0.85746985 0.82284386 0.80317674 0.81079313 0.83563815\n",
      " 0.90193628 0.85555382 0.79767809 0.85500278]\n",
      "##########\n",
      "epoch:9 step:7601 [D loss: 0.618901, acc: 67.97%] [G loss: 1.656464]\n",
      "epoch:9 step:7602 [D loss: 0.501840, acc: 83.59%] [G loss: 2.070008]\n",
      "epoch:9 step:7603 [D loss: 0.698151, acc: 55.47%] [G loss: 1.893297]\n",
      "epoch:9 step:7604 [D loss: 0.589424, acc: 71.88%] [G loss: 1.963051]\n",
      "epoch:9 step:7605 [D loss: 0.437132, acc: 89.06%] [G loss: 2.040138]\n",
      "epoch:9 step:7606 [D loss: 0.563249, acc: 71.88%] [G loss: 1.802431]\n",
      "epoch:9 step:7607 [D loss: 0.527570, acc: 76.56%] [G loss: 2.174232]\n",
      "epoch:9 step:7608 [D loss: 0.664250, acc: 56.25%] [G loss: 1.645496]\n",
      "epoch:9 step:7609 [D loss: 0.520279, acc: 78.91%] [G loss: 1.957745]\n",
      "epoch:9 step:7610 [D loss: 0.399900, acc: 92.19%] [G loss: 2.142730]\n",
      "epoch:9 step:7611 [D loss: 0.460954, acc: 89.84%] [G loss: 2.436615]\n",
      "epoch:9 step:7612 [D loss: 0.689107, acc: 62.50%] [G loss: 1.752670]\n",
      "epoch:9 step:7613 [D loss: 0.862163, acc: 28.12%] [G loss: 1.490514]\n",
      "epoch:9 step:7614 [D loss: 0.672587, acc: 58.59%] [G loss: 2.044139]\n",
      "epoch:9 step:7615 [D loss: 0.884966, acc: 33.59%] [G loss: 1.760529]\n",
      "epoch:9 step:7616 [D loss: 0.451977, acc: 83.59%] [G loss: 2.049641]\n",
      "epoch:9 step:7617 [D loss: 0.787320, acc: 45.31%] [G loss: 2.121260]\n",
      "epoch:9 step:7618 [D loss: 0.481857, acc: 78.12%] [G loss: 2.815242]\n",
      "epoch:9 step:7619 [D loss: 0.493034, acc: 81.25%] [G loss: 1.984354]\n",
      "epoch:9 step:7620 [D loss: 0.241269, acc: 96.09%] [G loss: 3.367196]\n",
      "epoch:9 step:7621 [D loss: 1.025155, acc: 28.12%] [G loss: 1.785266]\n",
      "epoch:9 step:7622 [D loss: 0.822718, acc: 38.28%] [G loss: 1.645722]\n",
      "epoch:9 step:7623 [D loss: 0.712066, acc: 57.03%] [G loss: 1.822932]\n",
      "epoch:9 step:7624 [D loss: 0.555674, acc: 72.66%] [G loss: 2.029977]\n",
      "epoch:9 step:7625 [D loss: 0.631268, acc: 61.72%] [G loss: 1.699051]\n",
      "epoch:9 step:7626 [D loss: 0.667438, acc: 60.94%] [G loss: 2.101270]\n",
      "epoch:9 step:7627 [D loss: 0.684561, acc: 54.69%] [G loss: 1.691738]\n",
      "epoch:9 step:7628 [D loss: 0.567144, acc: 75.00%] [G loss: 1.866063]\n",
      "epoch:9 step:7629 [D loss: 0.395873, acc: 91.41%] [G loss: 2.714842]\n",
      "epoch:9 step:7630 [D loss: 0.737590, acc: 55.47%] [G loss: 1.997653]\n",
      "epoch:9 step:7631 [D loss: 0.579344, acc: 73.44%] [G loss: 2.650643]\n",
      "epoch:9 step:7632 [D loss: 0.848781, acc: 35.16%] [G loss: 2.213219]\n",
      "epoch:9 step:7633 [D loss: 0.507227, acc: 79.69%] [G loss: 1.983074]\n",
      "epoch:9 step:7634 [D loss: 0.790071, acc: 45.31%] [G loss: 2.275419]\n",
      "epoch:9 step:7635 [D loss: 0.798570, acc: 50.00%] [G loss: 2.198654]\n",
      "epoch:9 step:7636 [D loss: 0.520222, acc: 67.97%] [G loss: 1.996226]\n",
      "epoch:9 step:7637 [D loss: 0.384042, acc: 93.75%] [G loss: 2.260757]\n",
      "epoch:9 step:7638 [D loss: 0.758157, acc: 48.44%] [G loss: 2.645466]\n",
      "epoch:9 step:7639 [D loss: 0.723041, acc: 47.66%] [G loss: 1.951907]\n",
      "epoch:9 step:7640 [D loss: 0.538345, acc: 79.69%] [G loss: 1.790347]\n",
      "epoch:9 step:7641 [D loss: 0.649071, acc: 60.94%] [G loss: 1.823966]\n",
      "epoch:9 step:7642 [D loss: 0.720779, acc: 52.34%] [G loss: 1.749370]\n",
      "epoch:9 step:7643 [D loss: 0.415021, acc: 83.59%] [G loss: 2.198593]\n",
      "epoch:9 step:7644 [D loss: 0.497626, acc: 79.69%] [G loss: 1.694196]\n",
      "epoch:9 step:7645 [D loss: 0.829488, acc: 35.94%] [G loss: 2.220341]\n",
      "epoch:9 step:7646 [D loss: 0.619651, acc: 71.09%] [G loss: 2.273419]\n",
      "epoch:9 step:7647 [D loss: 0.737477, acc: 52.34%] [G loss: 1.599969]\n",
      "epoch:9 step:7648 [D loss: 1.042739, acc: 21.88%] [G loss: 1.416402]\n",
      "epoch:9 step:7649 [D loss: 0.646277, acc: 57.03%] [G loss: 2.451949]\n",
      "epoch:9 step:7650 [D loss: 0.753155, acc: 46.09%] [G loss: 1.782666]\n",
      "epoch:9 step:7651 [D loss: 0.692313, acc: 54.69%] [G loss: 2.019807]\n",
      "epoch:9 step:7652 [D loss: 0.387566, acc: 93.75%] [G loss: 2.209018]\n",
      "epoch:9 step:7653 [D loss: 0.756773, acc: 47.66%] [G loss: 1.903519]\n",
      "epoch:9 step:7654 [D loss: 0.693759, acc: 54.69%] [G loss: 1.845071]\n",
      "epoch:9 step:7655 [D loss: 0.393159, acc: 82.81%] [G loss: 1.986424]\n",
      "epoch:9 step:7656 [D loss: 0.791359, acc: 33.59%] [G loss: 1.938580]\n",
      "epoch:9 step:7657 [D loss: 0.608626, acc: 70.31%] [G loss: 1.763115]\n",
      "epoch:9 step:7658 [D loss: 0.730010, acc: 49.22%] [G loss: 1.855277]\n",
      "epoch:9 step:7659 [D loss: 0.579961, acc: 70.31%] [G loss: 1.875998]\n",
      "epoch:9 step:7660 [D loss: 0.737829, acc: 52.34%] [G loss: 2.196790]\n",
      "epoch:9 step:7661 [D loss: 0.584464, acc: 69.53%] [G loss: 1.853668]\n",
      "epoch:9 step:7662 [D loss: 0.785687, acc: 47.66%] [G loss: 1.818828]\n",
      "epoch:9 step:7663 [D loss: 0.664702, acc: 58.59%] [G loss: 1.626597]\n",
      "epoch:9 step:7664 [D loss: 0.510335, acc: 79.69%] [G loss: 1.770093]\n",
      "epoch:9 step:7665 [D loss: 0.239149, acc: 95.31%] [G loss: 2.023579]\n",
      "epoch:9 step:7666 [D loss: 0.551321, acc: 78.91%] [G loss: 1.826086]\n",
      "epoch:9 step:7667 [D loss: 0.615059, acc: 63.28%] [G loss: 1.823174]\n",
      "epoch:9 step:7668 [D loss: 0.770531, acc: 46.09%] [G loss: 1.803847]\n",
      "epoch:9 step:7669 [D loss: 0.661981, acc: 57.03%] [G loss: 1.496230]\n",
      "epoch:9 step:7670 [D loss: 0.712243, acc: 51.56%] [G loss: 1.993004]\n",
      "epoch:9 step:7671 [D loss: 0.407855, acc: 85.16%] [G loss: 2.715644]\n",
      "epoch:9 step:7672 [D loss: 0.701969, acc: 56.25%] [G loss: 2.286134]\n",
      "epoch:9 step:7673 [D loss: 0.398021, acc: 81.25%] [G loss: 2.545340]\n",
      "epoch:9 step:7674 [D loss: 0.656323, acc: 56.25%] [G loss: 2.055016]\n",
      "epoch:9 step:7675 [D loss: 0.510998, acc: 81.25%] [G loss: 2.078271]\n",
      "epoch:9 step:7676 [D loss: 0.708217, acc: 50.78%] [G loss: 2.040483]\n",
      "epoch:9 step:7677 [D loss: 0.443772, acc: 86.72%] [G loss: 2.312706]\n",
      "epoch:9 step:7678 [D loss: 1.045271, acc: 15.62%] [G loss: 2.091013]\n",
      "epoch:9 step:7679 [D loss: 0.415878, acc: 85.94%] [G loss: 2.357649]\n",
      "epoch:9 step:7680 [D loss: 0.494735, acc: 81.25%] [G loss: 1.931682]\n",
      "epoch:9 step:7681 [D loss: 0.750535, acc: 46.88%] [G loss: 2.888283]\n",
      "epoch:9 step:7682 [D loss: 0.838971, acc: 36.72%] [G loss: 1.899966]\n",
      "epoch:9 step:7683 [D loss: 0.564811, acc: 74.22%] [G loss: 2.423389]\n",
      "epoch:9 step:7684 [D loss: 0.423619, acc: 91.41%] [G loss: 2.155532]\n",
      "epoch:9 step:7685 [D loss: 0.535208, acc: 72.66%] [G loss: 1.868824]\n",
      "epoch:9 step:7686 [D loss: 0.814833, acc: 50.78%] [G loss: 2.112066]\n",
      "epoch:9 step:7687 [D loss: 0.531168, acc: 78.12%] [G loss: 2.086418]\n",
      "epoch:9 step:7688 [D loss: 0.453572, acc: 76.56%] [G loss: 2.345529]\n",
      "epoch:9 step:7689 [D loss: 0.566567, acc: 67.97%] [G loss: 2.241729]\n",
      "epoch:9 step:7690 [D loss: 0.385860, acc: 89.84%] [G loss: 2.162663]\n",
      "epoch:9 step:7691 [D loss: 0.693912, acc: 52.34%] [G loss: 1.978480]\n",
      "epoch:9 step:7692 [D loss: 0.418352, acc: 84.38%] [G loss: 2.165466]\n",
      "epoch:9 step:7693 [D loss: 0.488247, acc: 85.16%] [G loss: 2.548210]\n",
      "epoch:9 step:7694 [D loss: 0.772815, acc: 42.19%] [G loss: 1.614323]\n",
      "epoch:9 step:7695 [D loss: 0.575999, acc: 66.41%] [G loss: 2.209327]\n",
      "epoch:9 step:7696 [D loss: 0.587305, acc: 70.31%] [G loss: 1.902516]\n",
      "epoch:9 step:7697 [D loss: 0.342390, acc: 87.50%] [G loss: 2.341865]\n",
      "epoch:9 step:7698 [D loss: 1.002105, acc: 27.34%] [G loss: 2.244851]\n",
      "epoch:9 step:7699 [D loss: 0.664558, acc: 62.50%] [G loss: 1.873655]\n",
      "epoch:9 step:7700 [D loss: 1.118485, acc: 26.56%] [G loss: 1.865793]\n",
      "epoch:9 step:7701 [D loss: 0.633721, acc: 66.41%] [G loss: 2.105912]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:9 step:7702 [D loss: 0.388205, acc: 91.41%] [G loss: 2.040512]\n",
      "epoch:9 step:7703 [D loss: 0.724044, acc: 54.69%] [G loss: 2.397424]\n",
      "epoch:9 step:7704 [D loss: 0.391695, acc: 89.06%] [G loss: 2.161747]\n",
      "epoch:9 step:7705 [D loss: 0.695019, acc: 56.25%] [G loss: 1.734027]\n",
      "epoch:9 step:7706 [D loss: 0.578963, acc: 70.31%] [G loss: 2.083797]\n",
      "epoch:9 step:7707 [D loss: 0.435822, acc: 84.38%] [G loss: 2.090497]\n",
      "epoch:9 step:7708 [D loss: 0.605941, acc: 71.88%] [G loss: 2.450874]\n",
      "epoch:9 step:7709 [D loss: 0.532100, acc: 75.00%] [G loss: 2.952441]\n",
      "epoch:9 step:7710 [D loss: 0.618638, acc: 67.19%] [G loss: 1.951167]\n",
      "epoch:9 step:7711 [D loss: 0.705187, acc: 53.91%] [G loss: 1.805833]\n",
      "epoch:9 step:7712 [D loss: 0.800758, acc: 46.09%] [G loss: 1.979078]\n",
      "epoch:9 step:7713 [D loss: 0.789349, acc: 49.22%] [G loss: 2.355570]\n",
      "epoch:9 step:7714 [D loss: 0.548411, acc: 72.66%] [G loss: 2.061617]\n",
      "epoch:9 step:7715 [D loss: 0.816166, acc: 40.62%] [G loss: 1.853905]\n",
      "epoch:9 step:7716 [D loss: 0.632810, acc: 64.06%] [G loss: 1.663063]\n",
      "epoch:9 step:7717 [D loss: 0.941540, acc: 26.56%] [G loss: 1.634007]\n",
      "epoch:9 step:7718 [D loss: 0.344587, acc: 91.41%] [G loss: 2.591479]\n",
      "epoch:9 step:7719 [D loss: 0.866975, acc: 42.97%] [G loss: 1.586643]\n",
      "epoch:9 step:7720 [D loss: 0.550281, acc: 69.53%] [G loss: 1.835293]\n",
      "epoch:9 step:7721 [D loss: 1.062302, acc: 17.19%] [G loss: 1.657416]\n",
      "epoch:9 step:7722 [D loss: 0.608373, acc: 67.97%] [G loss: 1.949586]\n",
      "epoch:9 step:7723 [D loss: 0.497248, acc: 69.53%] [G loss: 3.242123]\n",
      "epoch:9 step:7724 [D loss: 0.742393, acc: 53.12%] [G loss: 1.656241]\n",
      "epoch:9 step:7725 [D loss: 0.866975, acc: 30.47%] [G loss: 1.507630]\n",
      "epoch:9 step:7726 [D loss: 0.871029, acc: 28.12%] [G loss: 1.860301]\n",
      "epoch:9 step:7727 [D loss: 0.689447, acc: 56.25%] [G loss: 1.604023]\n",
      "epoch:9 step:7728 [D loss: 0.653378, acc: 60.16%] [G loss: 1.616166]\n",
      "epoch:9 step:7729 [D loss: 0.777586, acc: 51.56%] [G loss: 1.711456]\n",
      "epoch:9 step:7730 [D loss: 0.724819, acc: 50.00%] [G loss: 1.991150]\n",
      "epoch:9 step:7731 [D loss: 0.379277, acc: 95.31%] [G loss: 1.990757]\n",
      "epoch:9 step:7732 [D loss: 0.798520, acc: 43.75%] [G loss: 1.727347]\n",
      "epoch:9 step:7733 [D loss: 0.538220, acc: 71.09%] [G loss: 1.811697]\n",
      "epoch:9 step:7734 [D loss: 0.623091, acc: 58.59%] [G loss: 2.099148]\n",
      "epoch:9 step:7735 [D loss: 0.659429, acc: 64.06%] [G loss: 1.826153]\n",
      "epoch:9 step:7736 [D loss: 0.484626, acc: 83.59%] [G loss: 2.612777]\n",
      "epoch:9 step:7737 [D loss: 0.548793, acc: 72.66%] [G loss: 2.492078]\n",
      "epoch:9 step:7738 [D loss: 0.711914, acc: 53.12%] [G loss: 2.105079]\n",
      "epoch:9 step:7739 [D loss: 0.653386, acc: 63.28%] [G loss: 2.218022]\n",
      "epoch:9 step:7740 [D loss: 0.586871, acc: 68.75%] [G loss: 1.988399]\n",
      "epoch:9 step:7741 [D loss: 0.636172, acc: 65.62%] [G loss: 2.589405]\n",
      "epoch:9 step:7742 [D loss: 0.383574, acc: 95.31%] [G loss: 2.681691]\n",
      "epoch:9 step:7743 [D loss: 0.757698, acc: 42.19%] [G loss: 1.790751]\n",
      "epoch:9 step:7744 [D loss: 0.710318, acc: 56.25%] [G loss: 2.139983]\n",
      "epoch:9 step:7745 [D loss: 0.389369, acc: 90.62%] [G loss: 2.508130]\n",
      "epoch:9 step:7746 [D loss: 0.684373, acc: 61.72%] [G loss: 1.999602]\n",
      "epoch:9 step:7747 [D loss: 0.738234, acc: 47.66%] [G loss: 1.848611]\n",
      "epoch:9 step:7748 [D loss: 0.584910, acc: 69.53%] [G loss: 2.209333]\n",
      "epoch:9 step:7749 [D loss: 0.721206, acc: 50.78%] [G loss: 1.987483]\n",
      "epoch:9 step:7750 [D loss: 0.825604, acc: 37.50%] [G loss: 1.666429]\n",
      "epoch:9 step:7751 [D loss: 0.623391, acc: 71.88%] [G loss: 2.187803]\n",
      "epoch:9 step:7752 [D loss: 0.617306, acc: 65.62%] [G loss: 1.761566]\n",
      "epoch:9 step:7753 [D loss: 0.511187, acc: 78.12%] [G loss: 2.046957]\n",
      "epoch:9 step:7754 [D loss: 0.565538, acc: 71.88%] [G loss: 2.156052]\n",
      "epoch:9 step:7755 [D loss: 0.533318, acc: 76.56%] [G loss: 1.678509]\n",
      "epoch:9 step:7756 [D loss: 0.902302, acc: 34.38%] [G loss: 1.696068]\n",
      "epoch:9 step:7757 [D loss: 0.459807, acc: 87.50%] [G loss: 1.939034]\n",
      "epoch:9 step:7758 [D loss: 0.749633, acc: 47.66%] [G loss: 1.839484]\n",
      "epoch:9 step:7759 [D loss: 0.702195, acc: 52.34%] [G loss: 2.167665]\n",
      "epoch:9 step:7760 [D loss: 0.597133, acc: 69.53%] [G loss: 1.994682]\n",
      "epoch:9 step:7761 [D loss: 0.491149, acc: 78.12%] [G loss: 2.112990]\n",
      "epoch:9 step:7762 [D loss: 0.555554, acc: 77.34%] [G loss: 2.171220]\n",
      "epoch:9 step:7763 [D loss: 0.768789, acc: 42.19%] [G loss: 2.682978]\n",
      "epoch:9 step:7764 [D loss: 0.494131, acc: 88.28%] [G loss: 2.136322]\n",
      "epoch:9 step:7765 [D loss: 0.506227, acc: 79.69%] [G loss: 2.266394]\n",
      "epoch:9 step:7766 [D loss: 0.843091, acc: 35.16%] [G loss: 1.542394]\n",
      "epoch:9 step:7767 [D loss: 0.637508, acc: 63.28%] [G loss: 1.916647]\n",
      "epoch:9 step:7768 [D loss: 0.568652, acc: 69.53%] [G loss: 2.300428]\n",
      "epoch:9 step:7769 [D loss: 0.610851, acc: 66.41%] [G loss: 2.118869]\n",
      "epoch:9 step:7770 [D loss: 0.526313, acc: 87.50%] [G loss: 2.404524]\n",
      "epoch:9 step:7771 [D loss: 0.732118, acc: 50.78%] [G loss: 1.693666]\n",
      "epoch:9 step:7772 [D loss: 0.483552, acc: 81.25%] [G loss: 2.153552]\n",
      "epoch:9 step:7773 [D loss: 0.796128, acc: 42.19%] [G loss: 1.758618]\n",
      "epoch:9 step:7774 [D loss: 0.474926, acc: 85.16%] [G loss: 2.295722]\n",
      "epoch:9 step:7775 [D loss: 0.969156, acc: 32.81%] [G loss: 2.199213]\n",
      "epoch:9 step:7776 [D loss: 0.696823, acc: 56.25%] [G loss: 2.412774]\n",
      "epoch:9 step:7777 [D loss: 0.457457, acc: 78.12%] [G loss: 2.110784]\n",
      "epoch:9 step:7778 [D loss: 0.630141, acc: 65.62%] [G loss: 2.194993]\n",
      "epoch:9 step:7779 [D loss: 0.530076, acc: 79.69%] [G loss: 1.917544]\n",
      "epoch:9 step:7780 [D loss: 0.839602, acc: 39.84%] [G loss: 2.040409]\n",
      "epoch:9 step:7781 [D loss: 0.655739, acc: 63.28%] [G loss: 1.831806]\n",
      "epoch:9 step:7782 [D loss: 0.580194, acc: 69.53%] [G loss: 1.869583]\n",
      "epoch:9 step:7783 [D loss: 0.486892, acc: 78.12%] [G loss: 2.076947]\n",
      "epoch:9 step:7784 [D loss: 0.887538, acc: 30.47%] [G loss: 2.048604]\n",
      "epoch:9 step:7785 [D loss: 0.854539, acc: 35.94%] [G loss: 1.926196]\n",
      "epoch:9 step:7786 [D loss: 0.732500, acc: 53.91%] [G loss: 1.935641]\n",
      "epoch:9 step:7787 [D loss: 0.883522, acc: 46.88%] [G loss: 1.931055]\n",
      "epoch:9 step:7788 [D loss: 0.747225, acc: 49.22%] [G loss: 1.900380]\n",
      "epoch:9 step:7789 [D loss: 0.536446, acc: 78.12%] [G loss: 1.999524]\n",
      "epoch:9 step:7790 [D loss: 0.757692, acc: 44.53%] [G loss: 1.992959]\n",
      "epoch:9 step:7791 [D loss: 0.784657, acc: 46.09%] [G loss: 1.985416]\n",
      "epoch:9 step:7792 [D loss: 0.514111, acc: 75.78%] [G loss: 2.606640]\n",
      "epoch:9 step:7793 [D loss: 0.637366, acc: 61.72%] [G loss: 1.690539]\n",
      "epoch:9 step:7794 [D loss: 0.542556, acc: 76.56%] [G loss: 1.622361]\n",
      "epoch:9 step:7795 [D loss: 0.349862, acc: 93.75%] [G loss: 2.025832]\n",
      "epoch:9 step:7796 [D loss: 0.531807, acc: 81.25%] [G loss: 2.056655]\n",
      "epoch:9 step:7797 [D loss: 0.874146, acc: 40.62%] [G loss: 1.676116]\n",
      "epoch:9 step:7798 [D loss: 0.589442, acc: 70.31%] [G loss: 1.725169]\n",
      "epoch:9 step:7799 [D loss: 0.721539, acc: 52.34%] [G loss: 1.832773]\n",
      "epoch:9 step:7800 [D loss: 0.399742, acc: 77.34%] [G loss: 2.165537]\n",
      "##############\n",
      "[0.85153232 0.8773024  0.80419925 0.81713232 0.78292483 0.82330643\n",
      " 0.92014943 0.81682049 0.82526183 0.83401002]\n",
      "##########\n",
      "epoch:9 step:7801 [D loss: 0.537482, acc: 71.88%] [G loss: 1.812224]\n",
      "epoch:9 step:7802 [D loss: 0.550170, acc: 73.44%] [G loss: 2.163776]\n",
      "epoch:9 step:7803 [D loss: 0.803701, acc: 42.19%] [G loss: 2.136227]\n",
      "epoch:9 step:7804 [D loss: 0.931661, acc: 28.91%] [G loss: 1.708446]\n",
      "epoch:9 step:7805 [D loss: 0.783443, acc: 44.53%] [G loss: 1.976752]\n",
      "epoch:9 step:7806 [D loss: 0.583625, acc: 68.75%] [G loss: 1.685755]\n",
      "epoch:9 step:7807 [D loss: 0.492159, acc: 85.94%] [G loss: 1.822545]\n",
      "epoch:9 step:7808 [D loss: 0.850367, acc: 35.16%] [G loss: 1.568662]\n",
      "epoch:9 step:7809 [D loss: 0.869073, acc: 32.03%] [G loss: 1.423446]\n",
      "epoch:9 step:7810 [D loss: 0.634378, acc: 64.84%] [G loss: 2.251013]\n",
      "epoch:10 step:7811 [D loss: 0.479626, acc: 82.81%] [G loss: 2.395851]\n",
      "epoch:10 step:7812 [D loss: 0.518509, acc: 70.31%] [G loss: 2.019292]\n",
      "epoch:10 step:7813 [D loss: 0.589547, acc: 70.31%] [G loss: 1.984030]\n",
      "epoch:10 step:7814 [D loss: 0.636146, acc: 66.41%] [G loss: 1.880455]\n",
      "epoch:10 step:7815 [D loss: 0.723306, acc: 49.22%] [G loss: 1.600037]\n",
      "epoch:10 step:7816 [D loss: 0.625610, acc: 71.09%] [G loss: 1.991166]\n",
      "epoch:10 step:7817 [D loss: 0.590142, acc: 67.19%] [G loss: 1.782183]\n",
      "epoch:10 step:7818 [D loss: 0.545866, acc: 73.44%] [G loss: 1.748586]\n",
      "epoch:10 step:7819 [D loss: 1.176241, acc: 12.50%] [G loss: 1.407029]\n",
      "epoch:10 step:7820 [D loss: 0.694366, acc: 57.81%] [G loss: 1.945021]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:10 step:7821 [D loss: 0.637754, acc: 60.94%] [G loss: 2.171102]\n",
      "epoch:10 step:7822 [D loss: 0.541214, acc: 71.88%] [G loss: 1.837322]\n",
      "epoch:10 step:7823 [D loss: 0.637927, acc: 59.38%] [G loss: 1.989694]\n",
      "epoch:10 step:7824 [D loss: 0.624223, acc: 66.41%] [G loss: 1.798115]\n",
      "epoch:10 step:7825 [D loss: 0.542193, acc: 81.25%] [G loss: 2.389050]\n",
      "epoch:10 step:7826 [D loss: 0.884269, acc: 32.03%] [G loss: 1.606196]\n",
      "epoch:10 step:7827 [D loss: 0.623406, acc: 66.41%] [G loss: 2.179840]\n",
      "epoch:10 step:7828 [D loss: 0.683100, acc: 62.50%] [G loss: 1.721993]\n",
      "epoch:10 step:7829 [D loss: 0.611426, acc: 68.75%] [G loss: 1.962180]\n",
      "epoch:10 step:7830 [D loss: 0.534466, acc: 80.47%] [G loss: 2.223697]\n",
      "epoch:10 step:7831 [D loss: 0.631244, acc: 63.28%] [G loss: 2.021047]\n",
      "epoch:10 step:7832 [D loss: 0.426443, acc: 90.62%] [G loss: 2.287274]\n",
      "epoch:10 step:7833 [D loss: 0.426498, acc: 76.56%] [G loss: 2.263193]\n",
      "epoch:10 step:7834 [D loss: 0.701621, acc: 54.69%] [G loss: 1.752555]\n",
      "epoch:10 step:7835 [D loss: 0.585477, acc: 67.19%] [G loss: 1.972876]\n",
      "epoch:10 step:7836 [D loss: 0.589345, acc: 67.97%] [G loss: 2.214145]\n",
      "epoch:10 step:7837 [D loss: 0.651741, acc: 60.16%] [G loss: 1.830654]\n",
      "epoch:10 step:7838 [D loss: 0.578412, acc: 67.19%] [G loss: 1.920355]\n",
      "epoch:10 step:7839 [D loss: 0.567957, acc: 72.66%] [G loss: 1.829376]\n",
      "epoch:10 step:7840 [D loss: 0.897638, acc: 35.16%] [G loss: 1.677863]\n",
      "epoch:10 step:7841 [D loss: 0.621340, acc: 67.19%] [G loss: 1.531015]\n",
      "epoch:10 step:7842 [D loss: 0.725766, acc: 46.88%] [G loss: 1.947906]\n",
      "epoch:10 step:7843 [D loss: 0.499837, acc: 81.25%] [G loss: 1.979709]\n",
      "epoch:10 step:7844 [D loss: 0.549893, acc: 76.56%] [G loss: 1.835934]\n",
      "epoch:10 step:7845 [D loss: 0.860773, acc: 38.28%] [G loss: 1.638738]\n",
      "epoch:10 step:7846 [D loss: 0.753071, acc: 48.44%] [G loss: 2.135853]\n",
      "epoch:10 step:7847 [D loss: 0.796290, acc: 34.38%] [G loss: 2.279850]\n",
      "epoch:10 step:7848 [D loss: 0.631386, acc: 66.41%] [G loss: 1.874469]\n",
      "epoch:10 step:7849 [D loss: 0.327158, acc: 97.66%] [G loss: 2.402796]\n",
      "epoch:10 step:7850 [D loss: 0.530708, acc: 69.53%] [G loss: 2.233898]\n",
      "epoch:10 step:7851 [D loss: 0.534270, acc: 71.09%] [G loss: 2.160224]\n",
      "epoch:10 step:7852 [D loss: 0.473156, acc: 87.50%] [G loss: 2.578673]\n",
      "epoch:10 step:7853 [D loss: 0.689044, acc: 54.69%] [G loss: 2.764802]\n",
      "epoch:10 step:7854 [D loss: 0.696705, acc: 54.69%] [G loss: 1.877587]\n",
      "epoch:10 step:7855 [D loss: 0.302987, acc: 96.09%] [G loss: 2.534949]\n",
      "epoch:10 step:7856 [D loss: 0.548677, acc: 74.22%] [G loss: 2.186159]\n",
      "epoch:10 step:7857 [D loss: 0.569458, acc: 68.75%] [G loss: 2.307356]\n",
      "epoch:10 step:7858 [D loss: 0.449840, acc: 88.28%] [G loss: 2.108261]\n",
      "epoch:10 step:7859 [D loss: 0.739612, acc: 54.69%] [G loss: 2.016323]\n",
      "epoch:10 step:7860 [D loss: 0.509239, acc: 78.91%] [G loss: 1.622724]\n",
      "epoch:10 step:7861 [D loss: 0.673295, acc: 60.94%] [G loss: 1.630572]\n",
      "epoch:10 step:7862 [D loss: 0.492984, acc: 80.47%] [G loss: 2.165967]\n",
      "epoch:10 step:7863 [D loss: 0.699199, acc: 48.44%] [G loss: 1.869421]\n",
      "epoch:10 step:7864 [D loss: 1.174988, acc: 18.75%] [G loss: 2.187878]\n",
      "epoch:10 step:7865 [D loss: 0.884792, acc: 33.59%] [G loss: 1.654991]\n",
      "epoch:10 step:7866 [D loss: 0.460138, acc: 87.50%] [G loss: 2.072777]\n",
      "epoch:10 step:7867 [D loss: 0.795612, acc: 50.00%] [G loss: 1.761253]\n",
      "epoch:10 step:7868 [D loss: 0.870264, acc: 35.16%] [G loss: 1.740593]\n",
      "epoch:10 step:7869 [D loss: 0.479780, acc: 85.94%] [G loss: 2.124282]\n",
      "epoch:10 step:7870 [D loss: 0.582880, acc: 73.44%] [G loss: 2.131562]\n",
      "epoch:10 step:7871 [D loss: 0.667974, acc: 64.84%] [G loss: 1.702064]\n",
      "epoch:10 step:7872 [D loss: 0.754873, acc: 47.66%] [G loss: 1.555315]\n",
      "epoch:10 step:7873 [D loss: 0.831587, acc: 34.38%] [G loss: 1.943562]\n",
      "epoch:10 step:7874 [D loss: 0.371379, acc: 92.19%] [G loss: 2.099165]\n",
      "epoch:10 step:7875 [D loss: 0.538453, acc: 75.78%] [G loss: 1.938430]\n",
      "epoch:10 step:7876 [D loss: 0.968592, acc: 24.22%] [G loss: 1.583925]\n",
      "epoch:10 step:7877 [D loss: 0.599995, acc: 69.53%] [G loss: 2.391532]\n",
      "epoch:10 step:7878 [D loss: 0.733194, acc: 53.91%] [G loss: 2.029554]\n",
      "epoch:10 step:7879 [D loss: 0.752947, acc: 52.34%] [G loss: 1.800571]\n",
      "epoch:10 step:7880 [D loss: 0.759576, acc: 53.91%] [G loss: 1.889229]\n",
      "epoch:10 step:7881 [D loss: 0.749794, acc: 50.78%] [G loss: 1.590707]\n",
      "epoch:10 step:7882 [D loss: 0.667408, acc: 61.72%] [G loss: 1.977605]\n",
      "epoch:10 step:7883 [D loss: 0.605308, acc: 70.31%] [G loss: 1.883496]\n",
      "epoch:10 step:7884 [D loss: 0.597202, acc: 68.75%] [G loss: 2.231602]\n",
      "epoch:10 step:7885 [D loss: 0.776864, acc: 42.97%] [G loss: 1.737962]\n",
      "epoch:10 step:7886 [D loss: 0.625620, acc: 65.62%] [G loss: 2.148726]\n",
      "epoch:10 step:7887 [D loss: 0.691979, acc: 52.34%] [G loss: 2.187545]\n",
      "epoch:10 step:7888 [D loss: 0.491366, acc: 81.25%] [G loss: 1.990334]\n",
      "epoch:10 step:7889 [D loss: 0.455534, acc: 85.94%] [G loss: 2.423187]\n",
      "epoch:10 step:7890 [D loss: 0.683361, acc: 58.59%] [G loss: 1.928859]\n",
      "epoch:10 step:7891 [D loss: 0.551658, acc: 75.00%] [G loss: 2.741746]\n",
      "epoch:10 step:7892 [D loss: 0.415981, acc: 78.91%] [G loss: 2.730019]\n",
      "epoch:10 step:7893 [D loss: 0.365352, acc: 91.41%] [G loss: 2.376488]\n",
      "epoch:10 step:7894 [D loss: 0.702210, acc: 51.56%] [G loss: 1.728186]\n",
      "epoch:10 step:7895 [D loss: 0.545425, acc: 75.78%] [G loss: 2.184795]\n",
      "epoch:10 step:7896 [D loss: 0.631461, acc: 59.38%] [G loss: 2.094326]\n",
      "epoch:10 step:7897 [D loss: 0.452941, acc: 87.50%] [G loss: 1.948722]\n",
      "epoch:10 step:7898 [D loss: 0.591669, acc: 70.31%] [G loss: 2.301299]\n",
      "epoch:10 step:7899 [D loss: 0.593029, acc: 72.66%] [G loss: 2.026494]\n",
      "epoch:10 step:7900 [D loss: 0.756514, acc: 50.00%] [G loss: 1.669428]\n",
      "epoch:10 step:7901 [D loss: 0.518952, acc: 77.34%] [G loss: 1.980249]\n",
      "epoch:10 step:7902 [D loss: 0.596743, acc: 67.19%] [G loss: 2.031411]\n",
      "epoch:10 step:7903 [D loss: 0.613154, acc: 63.28%] [G loss: 1.703430]\n",
      "epoch:10 step:7904 [D loss: 0.567423, acc: 69.53%] [G loss: 2.114303]\n",
      "epoch:10 step:7905 [D loss: 0.900159, acc: 29.69%] [G loss: 1.446635]\n",
      "epoch:10 step:7906 [D loss: 0.756771, acc: 46.09%] [G loss: 1.882173]\n",
      "epoch:10 step:7907 [D loss: 0.696860, acc: 58.59%] [G loss: 2.111108]\n",
      "epoch:10 step:7908 [D loss: 0.633991, acc: 62.50%] [G loss: 2.072453]\n",
      "epoch:10 step:7909 [D loss: 0.639542, acc: 62.50%] [G loss: 1.813351]\n",
      "epoch:10 step:7910 [D loss: 0.660321, acc: 62.50%] [G loss: 1.819160]\n",
      "epoch:10 step:7911 [D loss: 0.769633, acc: 45.31%] [G loss: 1.827891]\n",
      "epoch:10 step:7912 [D loss: 0.511995, acc: 83.59%] [G loss: 2.757848]\n",
      "epoch:10 step:7913 [D loss: 0.894486, acc: 32.81%] [G loss: 1.682142]\n",
      "epoch:10 step:7914 [D loss: 0.462738, acc: 87.50%] [G loss: 2.285185]\n",
      "epoch:10 step:7915 [D loss: 0.526103, acc: 75.78%] [G loss: 2.197261]\n",
      "epoch:10 step:7916 [D loss: 0.761668, acc: 51.56%] [G loss: 1.809623]\n",
      "epoch:10 step:7917 [D loss: 0.669721, acc: 62.50%] [G loss: 1.957431]\n",
      "epoch:10 step:7918 [D loss: 0.920545, acc: 28.91%] [G loss: 1.701527]\n",
      "epoch:10 step:7919 [D loss: 0.625745, acc: 68.75%] [G loss: 1.789338]\n",
      "epoch:10 step:7920 [D loss: 0.580355, acc: 75.78%] [G loss: 2.274046]\n",
      "epoch:10 step:7921 [D loss: 0.747867, acc: 52.34%] [G loss: 1.774463]\n",
      "epoch:10 step:7922 [D loss: 0.569587, acc: 75.78%] [G loss: 1.856493]\n",
      "epoch:10 step:7923 [D loss: 0.653337, acc: 58.59%] [G loss: 2.216980]\n",
      "epoch:10 step:7924 [D loss: 0.643608, acc: 67.19%] [G loss: 1.826890]\n",
      "epoch:10 step:7925 [D loss: 0.686203, acc: 59.38%] [G loss: 1.969105]\n",
      "epoch:10 step:7926 [D loss: 0.715399, acc: 57.81%] [G loss: 1.817474]\n",
      "epoch:10 step:7927 [D loss: 0.525607, acc: 80.47%] [G loss: 2.250185]\n",
      "epoch:10 step:7928 [D loss: 0.498216, acc: 77.34%] [G loss: 2.064728]\n",
      "epoch:10 step:7929 [D loss: 0.299491, acc: 91.41%] [G loss: 2.766076]\n",
      "epoch:10 step:7930 [D loss: 0.709880, acc: 59.38%] [G loss: 1.754976]\n",
      "epoch:10 step:7931 [D loss: 0.688528, acc: 57.81%] [G loss: 1.734135]\n",
      "epoch:10 step:7932 [D loss: 0.503339, acc: 76.56%] [G loss: 2.031312]\n",
      "epoch:10 step:7933 [D loss: 0.340950, acc: 89.84%] [G loss: 2.217220]\n",
      "epoch:10 step:7934 [D loss: 0.319503, acc: 95.31%] [G loss: 2.398894]\n",
      "epoch:10 step:7935 [D loss: 0.641872, acc: 61.72%] [G loss: 2.076314]\n",
      "epoch:10 step:7936 [D loss: 0.625594, acc: 64.84%] [G loss: 1.641759]\n",
      "epoch:10 step:7937 [D loss: 0.672904, acc: 57.03%] [G loss: 1.900960]\n",
      "epoch:10 step:7938 [D loss: 0.403823, acc: 90.62%] [G loss: 2.283432]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:10 step:7939 [D loss: 0.728490, acc: 53.91%] [G loss: 1.900797]\n",
      "epoch:10 step:7940 [D loss: 0.815924, acc: 55.47%] [G loss: 1.797591]\n",
      "epoch:10 step:7941 [D loss: 0.668694, acc: 59.38%] [G loss: 1.809280]\n",
      "epoch:10 step:7942 [D loss: 0.505429, acc: 82.03%] [G loss: 2.130966]\n",
      "epoch:10 step:7943 [D loss: 0.455140, acc: 79.69%] [G loss: 1.891331]\n",
      "epoch:10 step:7944 [D loss: 0.577931, acc: 68.75%] [G loss: 2.005381]\n",
      "epoch:10 step:7945 [D loss: 0.576385, acc: 69.53%] [G loss: 2.361303]\n",
      "epoch:10 step:7946 [D loss: 0.538867, acc: 76.56%] [G loss: 1.870651]\n",
      "epoch:10 step:7947 [D loss: 0.778322, acc: 47.66%] [G loss: 1.940900]\n",
      "epoch:10 step:7948 [D loss: 0.558408, acc: 75.00%] [G loss: 1.662568]\n",
      "epoch:10 step:7949 [D loss: 0.407003, acc: 90.62%] [G loss: 2.027452]\n",
      "epoch:10 step:7950 [D loss: 0.639688, acc: 63.28%] [G loss: 2.273154]\n",
      "epoch:10 step:7951 [D loss: 1.028996, acc: 22.66%] [G loss: 1.521639]\n",
      "epoch:10 step:7952 [D loss: 0.631358, acc: 60.94%] [G loss: 2.109537]\n",
      "epoch:10 step:7953 [D loss: 0.602872, acc: 73.44%] [G loss: 2.417739]\n",
      "epoch:10 step:7954 [D loss: 0.765987, acc: 46.88%] [G loss: 1.978505]\n",
      "epoch:10 step:7955 [D loss: 0.744742, acc: 51.56%] [G loss: 1.862357]\n",
      "epoch:10 step:7956 [D loss: 0.483864, acc: 82.03%] [G loss: 2.004924]\n",
      "epoch:10 step:7957 [D loss: 0.480543, acc: 87.50%] [G loss: 2.513439]\n",
      "epoch:10 step:7958 [D loss: 0.540567, acc: 71.88%] [G loss: 1.723761]\n",
      "epoch:10 step:7959 [D loss: 0.894751, acc: 25.78%] [G loss: 1.976310]\n",
      "epoch:10 step:7960 [D loss: 0.772106, acc: 47.66%] [G loss: 1.870915]\n",
      "epoch:10 step:7961 [D loss: 0.345925, acc: 92.97%] [G loss: 2.711730]\n",
      "epoch:10 step:7962 [D loss: 0.730934, acc: 53.91%] [G loss: 2.229578]\n",
      "epoch:10 step:7963 [D loss: 0.537842, acc: 74.22%] [G loss: 2.163696]\n",
      "epoch:10 step:7964 [D loss: 0.507936, acc: 75.78%] [G loss: 2.452987]\n",
      "epoch:10 step:7965 [D loss: 0.547855, acc: 75.00%] [G loss: 2.149039]\n",
      "epoch:10 step:7966 [D loss: 0.753016, acc: 44.53%] [G loss: 4.216287]\n",
      "epoch:10 step:7967 [D loss: 0.579077, acc: 74.22%] [G loss: 2.700890]\n",
      "epoch:10 step:7968 [D loss: 0.384724, acc: 89.84%] [G loss: 2.964099]\n",
      "epoch:10 step:7969 [D loss: 0.772117, acc: 50.78%] [G loss: 2.125747]\n",
      "epoch:10 step:7970 [D loss: 0.600863, acc: 68.75%] [G loss: 2.028991]\n",
      "epoch:10 step:7971 [D loss: 0.429813, acc: 85.94%] [G loss: 2.716062]\n",
      "epoch:10 step:7972 [D loss: 0.634180, acc: 64.06%] [G loss: 2.089446]\n",
      "epoch:10 step:7973 [D loss: 0.514626, acc: 80.47%] [G loss: 2.618186]\n",
      "epoch:10 step:7974 [D loss: 0.518892, acc: 81.25%] [G loss: 2.123972]\n",
      "epoch:10 step:7975 [D loss: 0.561249, acc: 75.78%] [G loss: 2.224731]\n",
      "epoch:10 step:7976 [D loss: 0.848957, acc: 42.97%] [G loss: 1.881801]\n",
      "epoch:10 step:7977 [D loss: 0.395035, acc: 94.53%] [G loss: 2.535132]\n",
      "epoch:10 step:7978 [D loss: 0.336441, acc: 96.09%] [G loss: 2.458992]\n",
      "epoch:10 step:7979 [D loss: 0.375403, acc: 95.31%] [G loss: 1.871076]\n",
      "epoch:10 step:7980 [D loss: 0.482545, acc: 84.38%] [G loss: 2.300694]\n",
      "epoch:10 step:7981 [D loss: 0.540322, acc: 72.66%] [G loss: 2.005033]\n",
      "epoch:10 step:7982 [D loss: 0.745065, acc: 49.22%] [G loss: 2.202902]\n",
      "epoch:10 step:7983 [D loss: 0.669225, acc: 60.16%] [G loss: 2.086643]\n",
      "epoch:10 step:7984 [D loss: 0.369130, acc: 95.31%] [G loss: 2.861819]\n",
      "epoch:10 step:7985 [D loss: 0.621612, acc: 67.19%] [G loss: 2.028944]\n",
      "epoch:10 step:7986 [D loss: 0.806706, acc: 39.84%] [G loss: 2.405639]\n",
      "epoch:10 step:7987 [D loss: 0.411482, acc: 89.84%] [G loss: 1.870900]\n",
      "epoch:10 step:7988 [D loss: 0.994728, acc: 33.59%] [G loss: 1.508588]\n",
      "epoch:10 step:7989 [D loss: 0.793862, acc: 48.44%] [G loss: 2.026260]\n",
      "epoch:10 step:7990 [D loss: 1.032950, acc: 21.09%] [G loss: 1.770402]\n",
      "epoch:10 step:7991 [D loss: 0.854315, acc: 37.50%] [G loss: 1.870083]\n",
      "epoch:10 step:7992 [D loss: 0.552210, acc: 71.09%] [G loss: 1.950135]\n",
      "epoch:10 step:7993 [D loss: 0.531849, acc: 79.69%] [G loss: 2.090576]\n",
      "epoch:10 step:7994 [D loss: 0.626159, acc: 64.84%] [G loss: 2.217205]\n",
      "epoch:10 step:7995 [D loss: 0.876175, acc: 46.09%] [G loss: 1.602697]\n",
      "epoch:10 step:7996 [D loss: 0.433055, acc: 87.50%] [G loss: 2.285633]\n",
      "epoch:10 step:7997 [D loss: 0.821977, acc: 45.31%] [G loss: 1.739234]\n",
      "epoch:10 step:7998 [D loss: 0.428705, acc: 89.06%] [G loss: 2.460226]\n",
      "epoch:10 step:7999 [D loss: 0.629730, acc: 65.62%] [G loss: 2.209864]\n",
      "epoch:10 step:8000 [D loss: 0.587621, acc: 71.88%] [G loss: 1.860463]\n",
      "##############\n",
      "[0.86337684 0.8585649  0.83832421 0.82306006 0.79714098 0.8367922\n",
      " 0.89398783 0.8143083  0.82764855 0.82316438]\n",
      "##########\n",
      "epoch:10 step:8001 [D loss: 0.807014, acc: 48.44%] [G loss: 2.265627]\n",
      "epoch:10 step:8002 [D loss: 0.629669, acc: 67.19%] [G loss: 1.848554]\n",
      "epoch:10 step:8003 [D loss: 0.568401, acc: 68.75%] [G loss: 2.508193]\n",
      "epoch:10 step:8004 [D loss: 0.397188, acc: 77.34%] [G loss: 2.023373]\n",
      "epoch:10 step:8005 [D loss: 0.811244, acc: 37.50%] [G loss: 1.643054]\n",
      "epoch:10 step:8006 [D loss: 0.723558, acc: 57.03%] [G loss: 2.214190]\n",
      "epoch:10 step:8007 [D loss: 0.573898, acc: 72.66%] [G loss: 2.047256]\n",
      "epoch:10 step:8008 [D loss: 0.459169, acc: 81.25%] [G loss: 2.453288]\n",
      "epoch:10 step:8009 [D loss: 0.634229, acc: 58.59%] [G loss: 2.106654]\n",
      "epoch:10 step:8010 [D loss: 0.711066, acc: 52.34%] [G loss: 2.413495]\n",
      "epoch:10 step:8011 [D loss: 0.494870, acc: 84.38%] [G loss: 2.245133]\n",
      "epoch:10 step:8012 [D loss: 0.755275, acc: 55.47%] [G loss: 1.629994]\n",
      "epoch:10 step:8013 [D loss: 0.523112, acc: 78.12%] [G loss: 2.053046]\n",
      "epoch:10 step:8014 [D loss: 0.582473, acc: 68.75%] [G loss: 2.388258]\n",
      "epoch:10 step:8015 [D loss: 1.125252, acc: 17.19%] [G loss: 1.987295]\n",
      "epoch:10 step:8016 [D loss: 0.929614, acc: 28.12%] [G loss: 1.530054]\n",
      "epoch:10 step:8017 [D loss: 0.607607, acc: 67.19%] [G loss: 2.080760]\n",
      "epoch:10 step:8018 [D loss: 0.576271, acc: 72.66%] [G loss: 1.994853]\n",
      "epoch:10 step:8019 [D loss: 0.624647, acc: 62.50%] [G loss: 2.148868]\n",
      "epoch:10 step:8020 [D loss: 0.559109, acc: 72.66%] [G loss: 1.953702]\n",
      "epoch:10 step:8021 [D loss: 0.493968, acc: 80.47%] [G loss: 2.041145]\n",
      "epoch:10 step:8022 [D loss: 0.706079, acc: 52.34%] [G loss: 1.884603]\n",
      "epoch:10 step:8023 [D loss: 1.009990, acc: 27.34%] [G loss: 1.757396]\n",
      "epoch:10 step:8024 [D loss: 0.363067, acc: 93.75%] [G loss: 2.391466]\n",
      "epoch:10 step:8025 [D loss: 0.496339, acc: 76.56%] [G loss: 2.054940]\n",
      "epoch:10 step:8026 [D loss: 0.698115, acc: 50.00%] [G loss: 1.914059]\n",
      "epoch:10 step:8027 [D loss: 0.654389, acc: 62.50%] [G loss: 1.595223]\n",
      "epoch:10 step:8028 [D loss: 0.503616, acc: 75.78%] [G loss: 2.033237]\n",
      "epoch:10 step:8029 [D loss: 0.378752, acc: 92.97%] [G loss: 2.676855]\n",
      "epoch:10 step:8030 [D loss: 0.744038, acc: 44.53%] [G loss: 1.958931]\n",
      "epoch:10 step:8031 [D loss: 1.219339, acc: 11.72%] [G loss: 1.535476]\n",
      "epoch:10 step:8032 [D loss: 0.295876, acc: 94.53%] [G loss: 2.329612]\n",
      "epoch:10 step:8033 [D loss: 0.746149, acc: 49.22%] [G loss: 2.250302]\n",
      "epoch:10 step:8034 [D loss: 0.613106, acc: 67.19%] [G loss: 1.785135]\n",
      "epoch:10 step:8035 [D loss: 0.673445, acc: 56.25%] [G loss: 1.766626]\n",
      "epoch:10 step:8036 [D loss: 0.848071, acc: 36.72%] [G loss: 2.170210]\n",
      "epoch:10 step:8037 [D loss: 0.793738, acc: 45.31%] [G loss: 1.945451]\n",
      "epoch:10 step:8038 [D loss: 0.495008, acc: 78.91%] [G loss: 2.387722]\n",
      "epoch:10 step:8039 [D loss: 0.358918, acc: 92.97%] [G loss: 2.423131]\n",
      "epoch:10 step:8040 [D loss: 0.887020, acc: 43.75%] [G loss: 1.649137]\n",
      "epoch:10 step:8041 [D loss: 0.331389, acc: 91.41%] [G loss: 2.183021]\n",
      "epoch:10 step:8042 [D loss: 0.993875, acc: 25.00%] [G loss: 1.830634]\n",
      "epoch:10 step:8043 [D loss: 0.337575, acc: 92.97%] [G loss: 2.246249]\n",
      "epoch:10 step:8044 [D loss: 0.790890, acc: 50.00%] [G loss: 1.804641]\n",
      "epoch:10 step:8045 [D loss: 0.428924, acc: 89.06%] [G loss: 2.202421]\n",
      "epoch:10 step:8046 [D loss: 0.593993, acc: 69.53%] [G loss: 2.049187]\n",
      "epoch:10 step:8047 [D loss: 0.894425, acc: 48.44%] [G loss: 2.399483]\n",
      "epoch:10 step:8048 [D loss: 0.513069, acc: 62.50%] [G loss: 1.790642]\n",
      "epoch:10 step:8049 [D loss: 0.586876, acc: 66.41%] [G loss: 1.932053]\n",
      "epoch:10 step:8050 [D loss: 0.824011, acc: 42.97%] [G loss: 2.403896]\n",
      "epoch:10 step:8051 [D loss: 0.488821, acc: 84.38%] [G loss: 1.817988]\n",
      "epoch:10 step:8052 [D loss: 0.744164, acc: 52.34%] [G loss: 2.106944]\n",
      "epoch:10 step:8053 [D loss: 0.576291, acc: 73.44%] [G loss: 2.587362]\n",
      "epoch:10 step:8054 [D loss: 0.697939, acc: 49.22%] [G loss: 1.661214]\n",
      "epoch:10 step:8055 [D loss: 0.877332, acc: 50.78%] [G loss: 1.601990]\n",
      "epoch:10 step:8056 [D loss: 1.038720, acc: 21.88%] [G loss: 1.505796]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:10 step:8057 [D loss: 0.687065, acc: 54.69%] [G loss: 1.790342]\n",
      "epoch:10 step:8058 [D loss: 0.666831, acc: 64.06%] [G loss: 1.522239]\n",
      "epoch:10 step:8059 [D loss: 0.402121, acc: 91.41%] [G loss: 1.819417]\n",
      "epoch:10 step:8060 [D loss: 0.551017, acc: 75.78%] [G loss: 1.985390]\n",
      "epoch:10 step:8061 [D loss: 0.708076, acc: 47.66%] [G loss: 2.204472]\n",
      "epoch:10 step:8062 [D loss: 0.631427, acc: 64.84%] [G loss: 1.798567]\n",
      "epoch:10 step:8063 [D loss: 0.647460, acc: 59.38%] [G loss: 1.690720]\n",
      "epoch:10 step:8064 [D loss: 0.849233, acc: 39.84%] [G loss: 1.925566]\n",
      "epoch:10 step:8065 [D loss: 0.459227, acc: 84.38%] [G loss: 2.162203]\n",
      "epoch:10 step:8066 [D loss: 0.562147, acc: 75.78%] [G loss: 2.152446]\n",
      "epoch:10 step:8067 [D loss: 0.834753, acc: 35.16%] [G loss: 1.625716]\n",
      "epoch:10 step:8068 [D loss: 0.540849, acc: 71.09%] [G loss: 1.871298]\n",
      "epoch:10 step:8069 [D loss: 0.562067, acc: 75.00%] [G loss: 1.897358]\n",
      "epoch:10 step:8070 [D loss: 0.486454, acc: 85.16%] [G loss: 2.201859]\n",
      "epoch:10 step:8071 [D loss: 0.756557, acc: 48.44%] [G loss: 1.944573]\n",
      "epoch:10 step:8072 [D loss: 0.613678, acc: 68.75%] [G loss: 2.022201]\n",
      "epoch:10 step:8073 [D loss: 0.726427, acc: 57.03%] [G loss: 1.696504]\n",
      "epoch:10 step:8074 [D loss: 0.851474, acc: 35.94%] [G loss: 1.779937]\n",
      "epoch:10 step:8075 [D loss: 0.465370, acc: 85.94%] [G loss: 2.365386]\n",
      "epoch:10 step:8076 [D loss: 0.503635, acc: 79.69%] [G loss: 2.113400]\n",
      "epoch:10 step:8077 [D loss: 0.978190, acc: 36.72%] [G loss: 1.573910]\n",
      "epoch:10 step:8078 [D loss: 0.545545, acc: 72.66%] [G loss: 2.369639]\n",
      "epoch:10 step:8079 [D loss: 0.993122, acc: 33.59%] [G loss: 1.524507]\n",
      "epoch:10 step:8080 [D loss: 0.616574, acc: 66.41%] [G loss: 1.822165]\n",
      "epoch:10 step:8081 [D loss: 0.532449, acc: 73.44%] [G loss: 2.394331]\n",
      "epoch:10 step:8082 [D loss: 0.460821, acc: 85.94%] [G loss: 2.095167]\n",
      "epoch:10 step:8083 [D loss: 0.645923, acc: 63.28%] [G loss: 1.828364]\n",
      "epoch:10 step:8084 [D loss: 0.438525, acc: 89.84%] [G loss: 2.559476]\n",
      "epoch:10 step:8085 [D loss: 0.562472, acc: 71.88%] [G loss: 2.217212]\n",
      "epoch:10 step:8086 [D loss: 0.601506, acc: 66.41%] [G loss: 2.027671]\n",
      "epoch:10 step:8087 [D loss: 0.761647, acc: 53.12%] [G loss: 2.172760]\n",
      "epoch:10 step:8088 [D loss: 0.543165, acc: 75.78%] [G loss: 2.217231]\n",
      "epoch:10 step:8089 [D loss: 0.723222, acc: 55.47%] [G loss: 2.025557]\n",
      "epoch:10 step:8090 [D loss: 0.566012, acc: 75.00%] [G loss: 2.275306]\n",
      "epoch:10 step:8091 [D loss: 0.525770, acc: 79.69%] [G loss: 2.110767]\n",
      "epoch:10 step:8092 [D loss: 0.860889, acc: 40.62%] [G loss: 2.260192]\n",
      "epoch:10 step:8093 [D loss: 0.373915, acc: 95.31%] [G loss: 1.816074]\n",
      "epoch:10 step:8094 [D loss: 0.614613, acc: 67.19%] [G loss: 1.527337]\n",
      "epoch:10 step:8095 [D loss: 0.565935, acc: 67.19%] [G loss: 1.982469]\n",
      "epoch:10 step:8096 [D loss: 0.959653, acc: 30.47%] [G loss: 1.718771]\n",
      "epoch:10 step:8097 [D loss: 0.684154, acc: 58.59%] [G loss: 2.109818]\n",
      "epoch:10 step:8098 [D loss: 0.690481, acc: 56.25%] [G loss: 1.736075]\n",
      "epoch:10 step:8099 [D loss: 0.548619, acc: 70.31%] [G loss: 1.932793]\n",
      "epoch:10 step:8100 [D loss: 0.684598, acc: 57.03%] [G loss: 1.534672]\n",
      "epoch:10 step:8101 [D loss: 1.043965, acc: 25.00%] [G loss: 1.269048]\n",
      "epoch:10 step:8102 [D loss: 0.724288, acc: 49.22%] [G loss: 1.804711]\n",
      "epoch:10 step:8103 [D loss: 0.493639, acc: 77.34%] [G loss: 2.194141]\n",
      "epoch:10 step:8104 [D loss: 0.684590, acc: 54.69%] [G loss: 1.643070]\n",
      "epoch:10 step:8105 [D loss: 0.505942, acc: 82.81%] [G loss: 2.071572]\n",
      "epoch:10 step:8106 [D loss: 0.698677, acc: 54.69%] [G loss: 1.915458]\n",
      "epoch:10 step:8107 [D loss: 0.782553, acc: 42.19%] [G loss: 1.741561]\n",
      "epoch:10 step:8108 [D loss: 0.530731, acc: 80.47%] [G loss: 2.005620]\n",
      "epoch:10 step:8109 [D loss: 0.488399, acc: 84.38%] [G loss: 2.180301]\n",
      "epoch:10 step:8110 [D loss: 0.609138, acc: 72.66%] [G loss: 2.003510]\n",
      "epoch:10 step:8111 [D loss: 0.789316, acc: 46.09%] [G loss: 1.801306]\n",
      "epoch:10 step:8112 [D loss: 0.587910, acc: 68.75%] [G loss: 1.881437]\n",
      "epoch:10 step:8113 [D loss: 0.545014, acc: 71.09%] [G loss: 1.640849]\n",
      "epoch:10 step:8114 [D loss: 0.506865, acc: 80.47%] [G loss: 2.371905]\n",
      "epoch:10 step:8115 [D loss: 0.696351, acc: 57.81%] [G loss: 1.734130]\n",
      "epoch:10 step:8116 [D loss: 0.597475, acc: 68.75%] [G loss: 2.165971]\n",
      "epoch:10 step:8117 [D loss: 0.790368, acc: 47.66%] [G loss: 1.701886]\n",
      "epoch:10 step:8118 [D loss: 0.391206, acc: 89.06%] [G loss: 2.019546]\n",
      "epoch:10 step:8119 [D loss: 0.560849, acc: 72.66%] [G loss: 2.443446]\n",
      "epoch:10 step:8120 [D loss: 0.423831, acc: 88.28%] [G loss: 3.110312]\n",
      "epoch:10 step:8121 [D loss: 0.528532, acc: 74.22%] [G loss: 2.282887]\n",
      "epoch:10 step:8122 [D loss: 1.078449, acc: 17.19%] [G loss: 1.331479]\n",
      "epoch:10 step:8123 [D loss: 0.624161, acc: 63.28%] [G loss: 2.293888]\n",
      "epoch:10 step:8124 [D loss: 0.668465, acc: 62.50%] [G loss: 2.290067]\n",
      "epoch:10 step:8125 [D loss: 0.638330, acc: 64.06%] [G loss: 2.150248]\n",
      "epoch:10 step:8126 [D loss: 0.548683, acc: 68.75%] [G loss: 2.101428]\n",
      "epoch:10 step:8127 [D loss: 0.623346, acc: 64.84%] [G loss: 2.317791]\n",
      "epoch:10 step:8128 [D loss: 0.431511, acc: 87.50%] [G loss: 2.103251]\n",
      "epoch:10 step:8129 [D loss: 0.361494, acc: 88.28%] [G loss: 2.397100]\n",
      "epoch:10 step:8130 [D loss: 0.682959, acc: 60.16%] [G loss: 2.265564]\n",
      "epoch:10 step:8131 [D loss: 0.575945, acc: 70.31%] [G loss: 2.174195]\n",
      "epoch:10 step:8132 [D loss: 0.363624, acc: 82.03%] [G loss: 2.965494]\n",
      "epoch:10 step:8133 [D loss: 0.761999, acc: 50.00%] [G loss: 2.005827]\n",
      "epoch:10 step:8134 [D loss: 0.552510, acc: 75.00%] [G loss: 2.191850]\n",
      "epoch:10 step:8135 [D loss: 0.377409, acc: 92.19%] [G loss: 1.991070]\n",
      "epoch:10 step:8136 [D loss: 0.661884, acc: 57.03%] [G loss: 1.914208]\n",
      "epoch:10 step:8137 [D loss: 0.339002, acc: 87.50%] [G loss: 2.184538]\n",
      "epoch:10 step:8138 [D loss: 0.462366, acc: 85.94%] [G loss: 2.380949]\n",
      "epoch:10 step:8139 [D loss: 0.476256, acc: 77.34%] [G loss: 2.386177]\n",
      "epoch:10 step:8140 [D loss: 0.711865, acc: 53.12%] [G loss: 2.196902]\n",
      "epoch:10 step:8141 [D loss: 0.681897, acc: 60.16%] [G loss: 2.087096]\n",
      "epoch:10 step:8142 [D loss: 0.717679, acc: 52.34%] [G loss: 2.639788]\n",
      "epoch:10 step:8143 [D loss: 0.382579, acc: 91.41%] [G loss: 2.998828]\n",
      "epoch:10 step:8144 [D loss: 0.732513, acc: 56.25%] [G loss: 2.075601]\n",
      "epoch:10 step:8145 [D loss: 0.716453, acc: 53.91%] [G loss: 1.791415]\n",
      "epoch:10 step:8146 [D loss: 0.766368, acc: 51.56%] [G loss: 2.008456]\n",
      "epoch:10 step:8147 [D loss: 0.778309, acc: 54.69%] [G loss: 2.765108]\n",
      "epoch:10 step:8148 [D loss: 0.473848, acc: 78.91%] [G loss: 2.059422]\n",
      "epoch:10 step:8149 [D loss: 0.591196, acc: 67.19%] [G loss: 1.943378]\n",
      "epoch:10 step:8150 [D loss: 0.540993, acc: 78.12%] [G loss: 1.581046]\n",
      "epoch:10 step:8151 [D loss: 0.607588, acc: 67.19%] [G loss: 2.166382]\n",
      "epoch:10 step:8152 [D loss: 0.461624, acc: 85.16%] [G loss: 2.819583]\n",
      "epoch:10 step:8153 [D loss: 0.979629, acc: 30.47%] [G loss: 1.923513]\n",
      "epoch:10 step:8154 [D loss: 0.837948, acc: 43.75%] [G loss: 1.991012]\n",
      "epoch:10 step:8155 [D loss: 0.633238, acc: 63.28%] [G loss: 2.458892]\n",
      "epoch:10 step:8156 [D loss: 0.640159, acc: 64.84%] [G loss: 2.464887]\n",
      "epoch:10 step:8157 [D loss: 0.730943, acc: 51.56%] [G loss: 1.894481]\n",
      "epoch:10 step:8158 [D loss: 0.530985, acc: 78.12%] [G loss: 2.240693]\n",
      "epoch:10 step:8159 [D loss: 0.564444, acc: 72.66%] [G loss: 2.118599]\n",
      "epoch:10 step:8160 [D loss: 0.645584, acc: 65.62%] [G loss: 2.200125]\n",
      "epoch:10 step:8161 [D loss: 0.660867, acc: 60.94%] [G loss: 1.946469]\n",
      "epoch:10 step:8162 [D loss: 0.357179, acc: 87.50%] [G loss: 2.135748]\n",
      "epoch:10 step:8163 [D loss: 0.755270, acc: 46.09%] [G loss: 2.385413]\n",
      "epoch:10 step:8164 [D loss: 0.532411, acc: 76.56%] [G loss: 1.859911]\n",
      "epoch:10 step:8165 [D loss: 0.746882, acc: 52.34%] [G loss: 2.286301]\n",
      "epoch:10 step:8166 [D loss: 0.557614, acc: 66.41%] [G loss: 2.241714]\n",
      "epoch:10 step:8167 [D loss: 0.453561, acc: 84.38%] [G loss: 1.963876]\n",
      "epoch:10 step:8168 [D loss: 0.329909, acc: 91.41%] [G loss: 2.209471]\n",
      "epoch:10 step:8169 [D loss: 0.517049, acc: 75.78%] [G loss: 2.823988]\n",
      "epoch:10 step:8170 [D loss: 0.393319, acc: 83.59%] [G loss: 1.720088]\n",
      "epoch:10 step:8171 [D loss: 0.347649, acc: 94.53%] [G loss: 2.520903]\n",
      "epoch:10 step:8172 [D loss: 0.991176, acc: 35.16%] [G loss: 1.420640]\n",
      "epoch:10 step:8173 [D loss: 0.460658, acc: 85.94%] [G loss: 2.140046]\n",
      "epoch:10 step:8174 [D loss: 0.490130, acc: 76.56%] [G loss: 2.738857]\n",
      "epoch:10 step:8175 [D loss: 0.774203, acc: 49.22%] [G loss: 1.956548]\n",
      "epoch:10 step:8176 [D loss: 0.640981, acc: 60.16%] [G loss: 2.325032]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:10 step:8177 [D loss: 0.782475, acc: 45.31%] [G loss: 1.652206]\n",
      "epoch:10 step:8178 [D loss: 0.504796, acc: 80.47%] [G loss: 1.918517]\n",
      "epoch:10 step:8179 [D loss: 0.364880, acc: 90.62%] [G loss: 2.366209]\n",
      "epoch:10 step:8180 [D loss: 0.252095, acc: 96.09%] [G loss: 2.153538]\n",
      "epoch:10 step:8181 [D loss: 0.637175, acc: 64.84%] [G loss: 1.927760]\n",
      "epoch:10 step:8182 [D loss: 0.844043, acc: 44.53%] [G loss: 2.138152]\n",
      "epoch:10 step:8183 [D loss: 1.405139, acc: 46.09%] [G loss: 1.592620]\n",
      "epoch:10 step:8184 [D loss: 0.231226, acc: 100.00%] [G loss: 2.378683]\n",
      "epoch:10 step:8185 [D loss: 0.901093, acc: 47.66%] [G loss: 1.864377]\n",
      "epoch:10 step:8186 [D loss: 0.342571, acc: 90.62%] [G loss: 3.464464]\n",
      "epoch:10 step:8187 [D loss: 0.909307, acc: 32.03%] [G loss: 2.054714]\n",
      "epoch:10 step:8188 [D loss: 0.325885, acc: 90.62%] [G loss: 2.531878]\n",
      "epoch:10 step:8189 [D loss: 0.607182, acc: 67.97%] [G loss: 1.843938]\n",
      "epoch:10 step:8190 [D loss: 0.766901, acc: 51.56%] [G loss: 1.805913]\n",
      "epoch:10 step:8191 [D loss: 0.313545, acc: 92.97%] [G loss: 2.831517]\n",
      "epoch:10 step:8192 [D loss: 0.532566, acc: 73.44%] [G loss: 2.413780]\n",
      "epoch:10 step:8193 [D loss: 0.539152, acc: 79.69%] [G loss: 1.978382]\n",
      "epoch:10 step:8194 [D loss: 0.267766, acc: 94.53%] [G loss: 2.410635]\n",
      "epoch:10 step:8195 [D loss: 0.604200, acc: 70.31%] [G loss: 2.272398]\n",
      "epoch:10 step:8196 [D loss: 0.471197, acc: 82.81%] [G loss: 2.667176]\n",
      "epoch:10 step:8197 [D loss: 0.469128, acc: 82.03%] [G loss: 1.969591]\n",
      "epoch:10 step:8198 [D loss: 0.522544, acc: 74.22%] [G loss: 2.047655]\n",
      "epoch:10 step:8199 [D loss: 0.539306, acc: 77.34%] [G loss: 1.708669]\n",
      "epoch:10 step:8200 [D loss: 0.460483, acc: 83.59%] [G loss: 2.017066]\n",
      "##############\n",
      "[0.85212857 0.86584907 0.83316802 0.81403284 0.7981112  0.81709043\n",
      " 0.90091242 0.8136439  0.86178189 0.82053601]\n",
      "##########\n",
      "epoch:10 step:8201 [D loss: 0.899126, acc: 50.78%] [G loss: 2.295585]\n",
      "epoch:10 step:8202 [D loss: 0.725731, acc: 53.91%] [G loss: 1.829351]\n",
      "epoch:10 step:8203 [D loss: 0.450935, acc: 85.94%] [G loss: 2.367149]\n",
      "epoch:10 step:8204 [D loss: 0.546169, acc: 71.88%] [G loss: 2.674842]\n",
      "epoch:10 step:8205 [D loss: 0.520397, acc: 81.25%] [G loss: 2.415529]\n",
      "epoch:10 step:8206 [D loss: 0.833001, acc: 37.50%] [G loss: 1.820823]\n",
      "epoch:10 step:8207 [D loss: 0.633880, acc: 57.03%] [G loss: 2.106638]\n",
      "epoch:10 step:8208 [D loss: 0.495444, acc: 82.81%] [G loss: 2.894199]\n",
      "epoch:10 step:8209 [D loss: 0.485411, acc: 81.25%] [G loss: 3.126472]\n",
      "epoch:10 step:8210 [D loss: 0.277548, acc: 95.31%] [G loss: 2.843140]\n",
      "epoch:10 step:8211 [D loss: 0.361297, acc: 85.16%] [G loss: 2.881971]\n",
      "epoch:10 step:8212 [D loss: 0.320356, acc: 96.09%] [G loss: 2.486139]\n",
      "epoch:10 step:8213 [D loss: 0.616536, acc: 59.38%] [G loss: 2.434138]\n",
      "epoch:10 step:8214 [D loss: 0.435774, acc: 84.38%] [G loss: 2.439836]\n",
      "epoch:10 step:8215 [D loss: 0.349638, acc: 91.41%] [G loss: 2.223814]\n",
      "epoch:10 step:8216 [D loss: 0.620468, acc: 64.84%] [G loss: 2.497713]\n",
      "epoch:10 step:8217 [D loss: 0.572263, acc: 68.75%] [G loss: 2.830873]\n",
      "epoch:10 step:8218 [D loss: 0.666574, acc: 60.16%] [G loss: 2.072604]\n",
      "epoch:10 step:8219 [D loss: 0.579260, acc: 75.78%] [G loss: 2.219134]\n",
      "epoch:10 step:8220 [D loss: 0.628726, acc: 63.28%] [G loss: 1.898967]\n",
      "epoch:10 step:8221 [D loss: 0.517902, acc: 78.91%] [G loss: 2.346452]\n",
      "epoch:10 step:8222 [D loss: 0.569078, acc: 67.19%] [G loss: 2.069714]\n",
      "epoch:10 step:8223 [D loss: 0.408730, acc: 78.12%] [G loss: 2.434198]\n",
      "epoch:10 step:8224 [D loss: 0.453154, acc: 83.59%] [G loss: 1.678203]\n",
      "epoch:10 step:8225 [D loss: 0.578745, acc: 75.00%] [G loss: 2.269062]\n",
      "epoch:10 step:8226 [D loss: 0.417310, acc: 86.72%] [G loss: 1.882574]\n",
      "epoch:10 step:8227 [D loss: 0.192036, acc: 100.00%] [G loss: 2.630644]\n",
      "epoch:10 step:8228 [D loss: 0.725958, acc: 58.59%] [G loss: 2.045074]\n",
      "epoch:10 step:8229 [D loss: 0.545482, acc: 69.53%] [G loss: 1.549268]\n",
      "epoch:10 step:8230 [D loss: 0.427246, acc: 85.94%] [G loss: 2.004827]\n",
      "epoch:10 step:8231 [D loss: 0.445248, acc: 84.38%] [G loss: 2.931835]\n",
      "epoch:10 step:8232 [D loss: 0.494284, acc: 79.69%] [G loss: 2.312011]\n",
      "epoch:10 step:8233 [D loss: 0.582000, acc: 67.19%] [G loss: 2.333230]\n",
      "epoch:10 step:8234 [D loss: 0.754532, acc: 52.34%] [G loss: 1.912987]\n",
      "epoch:10 step:8235 [D loss: 0.546029, acc: 71.88%] [G loss: 2.283289]\n",
      "epoch:10 step:8236 [D loss: 0.882358, acc: 35.94%] [G loss: 2.027753]\n",
      "epoch:10 step:8237 [D loss: 0.339550, acc: 91.41%] [G loss: 2.328198]\n",
      "epoch:10 step:8238 [D loss: 0.793324, acc: 48.44%] [G loss: 2.143898]\n",
      "epoch:10 step:8239 [D loss: 0.405055, acc: 85.16%] [G loss: 2.360450]\n",
      "epoch:10 step:8240 [D loss: 0.380124, acc: 95.31%] [G loss: 2.379951]\n",
      "epoch:10 step:8241 [D loss: 0.374450, acc: 86.72%] [G loss: 2.201571]\n",
      "epoch:10 step:8242 [D loss: 0.805473, acc: 42.97%] [G loss: 2.329079]\n",
      "epoch:10 step:8243 [D loss: 0.660035, acc: 62.50%] [G loss: 2.231955]\n",
      "epoch:10 step:8244 [D loss: 1.287007, acc: 14.84%] [G loss: 1.984672]\n",
      "epoch:10 step:8245 [D loss: 0.380304, acc: 86.72%] [G loss: 2.544183]\n",
      "epoch:10 step:8246 [D loss: 0.567873, acc: 77.34%] [G loss: 2.581912]\n",
      "epoch:10 step:8247 [D loss: 1.017287, acc: 47.66%] [G loss: 1.829859]\n",
      "epoch:10 step:8248 [D loss: 0.440806, acc: 78.12%] [G loss: 1.947155]\n",
      "epoch:10 step:8249 [D loss: 0.779007, acc: 50.00%] [G loss: 2.190869]\n",
      "epoch:10 step:8250 [D loss: 0.422464, acc: 89.06%] [G loss: 2.268277]\n",
      "epoch:10 step:8251 [D loss: 0.449089, acc: 82.81%] [G loss: 2.669729]\n",
      "epoch:10 step:8252 [D loss: 0.642845, acc: 60.94%] [G loss: 1.869121]\n",
      "epoch:10 step:8253 [D loss: 0.534852, acc: 73.44%] [G loss: 1.879537]\n",
      "epoch:10 step:8254 [D loss: 0.775661, acc: 49.22%] [G loss: 1.973794]\n",
      "epoch:10 step:8255 [D loss: 0.804923, acc: 40.62%] [G loss: 2.075919]\n",
      "epoch:10 step:8256 [D loss: 0.856707, acc: 40.62%] [G loss: 2.144921]\n",
      "epoch:10 step:8257 [D loss: 0.571246, acc: 71.09%] [G loss: 2.211147]\n",
      "epoch:10 step:8258 [D loss: 0.482519, acc: 82.81%] [G loss: 2.028767]\n",
      "epoch:10 step:8259 [D loss: 0.517381, acc: 76.56%] [G loss: 1.792417]\n",
      "epoch:10 step:8260 [D loss: 0.398261, acc: 90.62%] [G loss: 2.677477]\n",
      "epoch:10 step:8261 [D loss: 0.451950, acc: 88.28%] [G loss: 1.955070]\n",
      "epoch:10 step:8262 [D loss: 0.574748, acc: 64.06%] [G loss: 2.405904]\n",
      "epoch:10 step:8263 [D loss: 0.671080, acc: 56.25%] [G loss: 1.718735]\n",
      "epoch:10 step:8264 [D loss: 0.601912, acc: 68.75%] [G loss: 2.167858]\n",
      "epoch:10 step:8265 [D loss: 0.464292, acc: 83.59%] [G loss: 1.880387]\n",
      "epoch:10 step:8266 [D loss: 1.004944, acc: 23.44%] [G loss: 1.824944]\n",
      "epoch:10 step:8267 [D loss: 0.796068, acc: 53.91%] [G loss: 1.375712]\n",
      "epoch:10 step:8268 [D loss: 0.404656, acc: 89.06%] [G loss: 2.097161]\n",
      "epoch:10 step:8269 [D loss: 0.588064, acc: 60.16%] [G loss: 2.515957]\n",
      "epoch:10 step:8270 [D loss: 0.609745, acc: 60.16%] [G loss: 2.050051]\n",
      "epoch:10 step:8271 [D loss: 0.999590, acc: 27.34%] [G loss: 1.694451]\n",
      "epoch:10 step:8272 [D loss: 0.441773, acc: 84.38%] [G loss: 2.196674]\n",
      "epoch:10 step:8273 [D loss: 0.911316, acc: 42.19%] [G loss: 1.479914]\n",
      "epoch:10 step:8274 [D loss: 0.656151, acc: 64.84%] [G loss: 2.115262]\n",
      "epoch:10 step:8275 [D loss: 0.523357, acc: 73.44%] [G loss: 1.768193]\n",
      "epoch:10 step:8276 [D loss: 0.464228, acc: 87.50%] [G loss: 1.843350]\n",
      "epoch:10 step:8277 [D loss: 0.652496, acc: 60.94%] [G loss: 2.256441]\n",
      "epoch:10 step:8278 [D loss: 0.819504, acc: 42.97%] [G loss: 1.982569]\n",
      "epoch:10 step:8279 [D loss: 0.644802, acc: 60.16%] [G loss: 2.802953]\n",
      "epoch:10 step:8280 [D loss: 1.089598, acc: 23.44%] [G loss: 1.479120]\n",
      "epoch:10 step:8281 [D loss: 0.789406, acc: 47.66%] [G loss: 1.776931]\n",
      "epoch:10 step:8282 [D loss: 0.732405, acc: 53.12%] [G loss: 2.733274]\n",
      "epoch:10 step:8283 [D loss: 0.568919, acc: 70.31%] [G loss: 2.208543]\n",
      "epoch:10 step:8284 [D loss: 0.517984, acc: 77.34%] [G loss: 1.674233]\n",
      "epoch:10 step:8285 [D loss: 0.542182, acc: 71.09%] [G loss: 2.247034]\n",
      "epoch:10 step:8286 [D loss: 0.569531, acc: 70.31%] [G loss: 2.414693]\n",
      "epoch:10 step:8287 [D loss: 0.553538, acc: 73.44%] [G loss: 1.947284]\n",
      "epoch:10 step:8288 [D loss: 0.570840, acc: 74.22%] [G loss: 2.149639]\n",
      "epoch:10 step:8289 [D loss: 1.090796, acc: 17.97%] [G loss: 1.502466]\n",
      "epoch:10 step:8290 [D loss: 0.741360, acc: 45.31%] [G loss: 1.789288]\n",
      "epoch:10 step:8291 [D loss: 0.798507, acc: 42.19%] [G loss: 1.657644]\n",
      "epoch:10 step:8292 [D loss: 0.917740, acc: 27.34%] [G loss: 1.653381]\n",
      "epoch:10 step:8293 [D loss: 0.671570, acc: 56.25%] [G loss: 2.034590]\n",
      "epoch:10 step:8294 [D loss: 0.790648, acc: 43.75%] [G loss: 1.694773]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:10 step:8295 [D loss: 0.599227, acc: 67.97%] [G loss: 1.954098]\n",
      "epoch:10 step:8296 [D loss: 0.634479, acc: 57.03%] [G loss: 2.182995]\n",
      "epoch:10 step:8297 [D loss: 0.802552, acc: 40.62%] [G loss: 2.116178]\n",
      "epoch:10 step:8298 [D loss: 0.837540, acc: 42.19%] [G loss: 1.862394]\n",
      "epoch:10 step:8299 [D loss: 0.621219, acc: 63.28%] [G loss: 1.773506]\n",
      "epoch:10 step:8300 [D loss: 0.607144, acc: 62.50%] [G loss: 1.934785]\n",
      "epoch:10 step:8301 [D loss: 0.858455, acc: 34.38%] [G loss: 1.722003]\n",
      "epoch:10 step:8302 [D loss: 1.055515, acc: 25.00%] [G loss: 1.971519]\n",
      "epoch:10 step:8303 [D loss: 0.487278, acc: 81.25%] [G loss: 2.153345]\n",
      "epoch:10 step:8304 [D loss: 0.650349, acc: 60.94%] [G loss: 2.068271]\n",
      "epoch:10 step:8305 [D loss: 0.442203, acc: 82.81%] [G loss: 2.148526]\n",
      "epoch:10 step:8306 [D loss: 0.645062, acc: 61.72%] [G loss: 1.893655]\n",
      "epoch:10 step:8307 [D loss: 0.912378, acc: 30.47%] [G loss: 1.463225]\n",
      "epoch:10 step:8308 [D loss: 0.700775, acc: 46.88%] [G loss: 2.498408]\n",
      "epoch:10 step:8309 [D loss: 1.061410, acc: 29.69%] [G loss: 1.788848]\n",
      "epoch:10 step:8310 [D loss: 0.536428, acc: 76.56%] [G loss: 1.915598]\n",
      "epoch:10 step:8311 [D loss: 0.622888, acc: 66.41%] [G loss: 2.202132]\n",
      "epoch:10 step:8312 [D loss: 0.510513, acc: 78.12%] [G loss: 2.211284]\n",
      "epoch:10 step:8313 [D loss: 0.439400, acc: 86.72%] [G loss: 2.383349]\n",
      "epoch:10 step:8314 [D loss: 0.515843, acc: 80.47%] [G loss: 2.232111]\n",
      "epoch:10 step:8315 [D loss: 0.642237, acc: 53.12%] [G loss: 1.653383]\n",
      "epoch:10 step:8316 [D loss: 0.564862, acc: 71.88%] [G loss: 2.059341]\n",
      "epoch:10 step:8317 [D loss: 0.714399, acc: 53.91%] [G loss: 2.204112]\n",
      "epoch:10 step:8318 [D loss: 0.624032, acc: 62.50%] [G loss: 2.043416]\n",
      "epoch:10 step:8319 [D loss: 0.608150, acc: 64.84%] [G loss: 2.400888]\n",
      "epoch:10 step:8320 [D loss: 0.346069, acc: 91.41%] [G loss: 2.392327]\n",
      "epoch:10 step:8321 [D loss: 0.662010, acc: 59.38%] [G loss: 1.796809]\n",
      "epoch:10 step:8322 [D loss: 0.705181, acc: 54.69%] [G loss: 2.513416]\n",
      "epoch:10 step:8323 [D loss: 0.415480, acc: 90.62%] [G loss: 1.893346]\n",
      "epoch:10 step:8324 [D loss: 0.787247, acc: 52.34%] [G loss: 2.006203]\n",
      "epoch:10 step:8325 [D loss: 0.677798, acc: 62.50%] [G loss: 1.827741]\n",
      "epoch:10 step:8326 [D loss: 0.628642, acc: 65.62%] [G loss: 2.095820]\n",
      "epoch:10 step:8327 [D loss: 0.701842, acc: 53.91%] [G loss: 1.599122]\n",
      "epoch:10 step:8328 [D loss: 0.717924, acc: 53.91%] [G loss: 1.881604]\n",
      "epoch:10 step:8329 [D loss: 1.125288, acc: 16.41%] [G loss: 1.499302]\n",
      "epoch:10 step:8330 [D loss: 0.551182, acc: 74.22%] [G loss: 2.160431]\n",
      "epoch:10 step:8331 [D loss: 0.501270, acc: 84.38%] [G loss: 1.973577]\n",
      "epoch:10 step:8332 [D loss: 0.443718, acc: 80.47%] [G loss: 1.767424]\n",
      "epoch:10 step:8333 [D loss: 0.650114, acc: 58.59%] [G loss: 2.044210]\n",
      "epoch:10 step:8334 [D loss: 0.464126, acc: 85.16%] [G loss: 2.194220]\n",
      "epoch:10 step:8335 [D loss: 0.456332, acc: 79.69%] [G loss: 1.872461]\n",
      "epoch:10 step:8336 [D loss: 1.103001, acc: 14.06%] [G loss: 1.764612]\n",
      "epoch:10 step:8337 [D loss: 0.861441, acc: 36.72%] [G loss: 2.074154]\n",
      "epoch:10 step:8338 [D loss: 0.893461, acc: 35.16%] [G loss: 1.705270]\n",
      "epoch:10 step:8339 [D loss: 0.551772, acc: 75.00%] [G loss: 2.051260]\n",
      "epoch:10 step:8340 [D loss: 0.660745, acc: 60.16%] [G loss: 1.801013]\n",
      "epoch:10 step:8341 [D loss: 0.736921, acc: 48.44%] [G loss: 1.618212]\n",
      "epoch:10 step:8342 [D loss: 0.571773, acc: 69.53%] [G loss: 2.037361]\n",
      "epoch:10 step:8343 [D loss: 0.536791, acc: 78.12%] [G loss: 1.760627]\n",
      "epoch:10 step:8344 [D loss: 0.581862, acc: 67.19%] [G loss: 2.205396]\n",
      "epoch:10 step:8345 [D loss: 0.575856, acc: 68.75%] [G loss: 1.826853]\n",
      "epoch:10 step:8346 [D loss: 0.551617, acc: 79.69%] [G loss: 1.979593]\n",
      "epoch:10 step:8347 [D loss: 0.581024, acc: 76.56%] [G loss: 2.539393]\n",
      "epoch:10 step:8348 [D loss: 0.352101, acc: 93.75%] [G loss: 2.708064]\n",
      "epoch:10 step:8349 [D loss: 0.620970, acc: 67.97%] [G loss: 1.946285]\n",
      "epoch:10 step:8350 [D loss: 0.630775, acc: 65.62%] [G loss: 2.168741]\n",
      "epoch:10 step:8351 [D loss: 0.468905, acc: 83.59%] [G loss: 2.019762]\n",
      "epoch:10 step:8352 [D loss: 0.547608, acc: 78.12%] [G loss: 1.988019]\n",
      "epoch:10 step:8353 [D loss: 0.904955, acc: 31.25%] [G loss: 1.615377]\n",
      "epoch:10 step:8354 [D loss: 0.528973, acc: 73.44%] [G loss: 1.844333]\n",
      "epoch:10 step:8355 [D loss: 0.868081, acc: 36.72%] [G loss: 1.726114]\n",
      "epoch:10 step:8356 [D loss: 0.811394, acc: 42.19%] [G loss: 1.643554]\n",
      "epoch:10 step:8357 [D loss: 0.480474, acc: 83.59%] [G loss: 2.069294]\n",
      "epoch:10 step:8358 [D loss: 1.061577, acc: 19.53%] [G loss: 1.627574]\n",
      "epoch:10 step:8359 [D loss: 0.661678, acc: 63.28%] [G loss: 1.887528]\n",
      "epoch:10 step:8360 [D loss: 0.526642, acc: 76.56%] [G loss: 2.580932]\n",
      "epoch:10 step:8361 [D loss: 0.538617, acc: 78.12%] [G loss: 1.980279]\n",
      "epoch:10 step:8362 [D loss: 1.165956, acc: 15.62%] [G loss: 1.291689]\n",
      "epoch:10 step:8363 [D loss: 0.619152, acc: 64.06%] [G loss: 1.694778]\n",
      "epoch:10 step:8364 [D loss: 0.563301, acc: 75.00%] [G loss: 2.166149]\n",
      "epoch:10 step:8365 [D loss: 0.780938, acc: 42.19%] [G loss: 1.734843]\n",
      "epoch:10 step:8366 [D loss: 0.582670, acc: 73.44%] [G loss: 2.048699]\n",
      "epoch:10 step:8367 [D loss: 0.354279, acc: 89.84%] [G loss: 1.874994]\n",
      "epoch:10 step:8368 [D loss: 0.447972, acc: 69.53%] [G loss: 1.831545]\n",
      "epoch:10 step:8369 [D loss: 0.766956, acc: 50.78%] [G loss: 2.140221]\n",
      "epoch:10 step:8370 [D loss: 0.494341, acc: 81.25%] [G loss: 2.387711]\n",
      "epoch:10 step:8371 [D loss: 0.355042, acc: 94.53%] [G loss: 2.539113]\n",
      "epoch:10 step:8372 [D loss: 0.562822, acc: 72.66%] [G loss: 2.337828]\n",
      "epoch:10 step:8373 [D loss: 0.727439, acc: 57.03%] [G loss: 1.770570]\n",
      "epoch:10 step:8374 [D loss: 0.369531, acc: 90.62%] [G loss: 2.177609]\n",
      "epoch:10 step:8375 [D loss: 0.660290, acc: 62.50%] [G loss: 1.985695]\n",
      "epoch:10 step:8376 [D loss: 0.704548, acc: 55.47%] [G loss: 2.161014]\n",
      "epoch:10 step:8377 [D loss: 0.580191, acc: 70.31%] [G loss: 1.740406]\n",
      "epoch:10 step:8378 [D loss: 0.309263, acc: 97.66%] [G loss: 2.631870]\n",
      "epoch:10 step:8379 [D loss: 0.492907, acc: 82.81%] [G loss: 2.466720]\n",
      "epoch:10 step:8380 [D loss: 0.599192, acc: 62.50%] [G loss: 1.823431]\n",
      "epoch:10 step:8381 [D loss: 0.519277, acc: 80.47%] [G loss: 2.243299]\n",
      "epoch:10 step:8382 [D loss: 0.806064, acc: 51.56%] [G loss: 2.307434]\n",
      "epoch:10 step:8383 [D loss: 0.671728, acc: 58.59%] [G loss: 1.784066]\n",
      "epoch:10 step:8384 [D loss: 0.474042, acc: 84.38%] [G loss: 2.161104]\n",
      "epoch:10 step:8385 [D loss: 0.531496, acc: 75.78%] [G loss: 1.957361]\n",
      "epoch:10 step:8386 [D loss: 0.552231, acc: 74.22%] [G loss: 1.765666]\n",
      "epoch:10 step:8387 [D loss: 0.483777, acc: 83.59%] [G loss: 2.063268]\n",
      "epoch:10 step:8388 [D loss: 0.587617, acc: 78.91%] [G loss: 1.869135]\n",
      "epoch:10 step:8389 [D loss: 0.698744, acc: 52.34%] [G loss: 2.123860]\n",
      "epoch:10 step:8390 [D loss: 0.839389, acc: 42.97%] [G loss: 1.817266]\n",
      "epoch:10 step:8391 [D loss: 0.649762, acc: 57.03%] [G loss: 1.919964]\n",
      "epoch:10 step:8392 [D loss: 0.745647, acc: 50.78%] [G loss: 2.095793]\n",
      "epoch:10 step:8393 [D loss: 0.397379, acc: 83.59%] [G loss: 1.999615]\n",
      "epoch:10 step:8394 [D loss: 0.776686, acc: 45.31%] [G loss: 1.545787]\n",
      "epoch:10 step:8395 [D loss: 0.460908, acc: 78.12%] [G loss: 2.117451]\n",
      "epoch:10 step:8396 [D loss: 0.712380, acc: 57.03%] [G loss: 1.872636]\n",
      "epoch:10 step:8397 [D loss: 0.551391, acc: 77.34%] [G loss: 2.706719]\n",
      "epoch:10 step:8398 [D loss: 0.351107, acc: 94.53%] [G loss: 2.417687]\n",
      "epoch:10 step:8399 [D loss: 0.594248, acc: 71.88%] [G loss: 2.033178]\n",
      "epoch:10 step:8400 [D loss: 0.652583, acc: 63.28%] [G loss: 1.863073]\n",
      "##############\n",
      "[0.86286876 0.88709007 0.7979394  0.79734127 0.77877036 0.83211571\n",
      " 0.88951107 0.8438407  0.82713501 0.80805065]\n",
      "##########\n",
      "epoch:10 step:8401 [D loss: 0.581850, acc: 73.44%] [G loss: 1.978244]\n",
      "epoch:10 step:8402 [D loss: 0.767741, acc: 49.22%] [G loss: 1.847270]\n",
      "epoch:10 step:8403 [D loss: 1.180605, acc: 14.06%] [G loss: 1.643214]\n",
      "epoch:10 step:8404 [D loss: 0.538758, acc: 74.22%] [G loss: 1.866480]\n",
      "epoch:10 step:8405 [D loss: 0.582872, acc: 73.44%] [G loss: 2.286375]\n",
      "epoch:10 step:8406 [D loss: 0.717359, acc: 52.34%] [G loss: 1.683679]\n",
      "epoch:10 step:8407 [D loss: 0.857944, acc: 38.28%] [G loss: 1.497150]\n",
      "epoch:10 step:8408 [D loss: 0.694614, acc: 54.69%] [G loss: 2.082236]\n",
      "epoch:10 step:8409 [D loss: 0.594267, acc: 67.97%] [G loss: 2.444738]\n",
      "epoch:10 step:8410 [D loss: 0.714578, acc: 57.03%] [G loss: 2.120422]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:10 step:8411 [D loss: 0.773044, acc: 48.44%] [G loss: 1.941823]\n",
      "epoch:10 step:8412 [D loss: 0.575485, acc: 74.22%] [G loss: 2.116656]\n",
      "epoch:10 step:8413 [D loss: 0.693817, acc: 55.47%] [G loss: 1.644361]\n",
      "epoch:10 step:8414 [D loss: 0.706472, acc: 50.00%] [G loss: 2.107971]\n",
      "epoch:10 step:8415 [D loss: 0.774828, acc: 48.44%] [G loss: 1.622290]\n",
      "epoch:10 step:8416 [D loss: 0.609443, acc: 68.75%] [G loss: 2.406912]\n",
      "epoch:10 step:8417 [D loss: 0.880162, acc: 30.47%] [G loss: 2.018594]\n",
      "epoch:10 step:8418 [D loss: 0.673989, acc: 60.16%] [G loss: 1.944577]\n",
      "epoch:10 step:8419 [D loss: 0.541706, acc: 65.62%] [G loss: 2.181003]\n",
      "epoch:10 step:8420 [D loss: 1.012712, acc: 27.34%] [G loss: 1.940694]\n",
      "epoch:10 step:8421 [D loss: 0.498448, acc: 79.69%] [G loss: 2.278012]\n",
      "epoch:10 step:8422 [D loss: 0.654657, acc: 64.84%] [G loss: 1.615378]\n",
      "epoch:10 step:8423 [D loss: 0.630466, acc: 64.84%] [G loss: 1.842203]\n",
      "epoch:10 step:8424 [D loss: 0.609563, acc: 62.50%] [G loss: 2.127074]\n",
      "epoch:10 step:8425 [D loss: 0.628875, acc: 66.41%] [G loss: 1.990375]\n",
      "epoch:10 step:8426 [D loss: 0.689273, acc: 61.72%] [G loss: 1.710569]\n",
      "epoch:10 step:8427 [D loss: 0.463306, acc: 82.81%] [G loss: 2.227412]\n",
      "epoch:10 step:8428 [D loss: 0.708472, acc: 53.91%] [G loss: 1.721339]\n",
      "epoch:10 step:8429 [D loss: 0.914869, acc: 34.38%] [G loss: 1.589602]\n",
      "epoch:10 step:8430 [D loss: 0.642933, acc: 64.84%] [G loss: 2.425719]\n",
      "epoch:10 step:8431 [D loss: 0.605645, acc: 68.75%] [G loss: 1.741653]\n",
      "epoch:10 step:8432 [D loss: 0.472726, acc: 83.59%] [G loss: 2.462361]\n",
      "epoch:10 step:8433 [D loss: 0.752728, acc: 52.34%] [G loss: 2.173729]\n",
      "epoch:10 step:8434 [D loss: 0.449203, acc: 85.16%] [G loss: 2.007438]\n",
      "epoch:10 step:8435 [D loss: 0.642353, acc: 59.38%] [G loss: 1.896851]\n",
      "epoch:10 step:8436 [D loss: 0.563445, acc: 67.97%] [G loss: 1.999719]\n",
      "epoch:10 step:8437 [D loss: 0.874836, acc: 31.25%] [G loss: 1.700023]\n",
      "epoch:10 step:8438 [D loss: 0.587929, acc: 66.41%] [G loss: 1.775721]\n",
      "epoch:10 step:8439 [D loss: 0.611073, acc: 70.31%] [G loss: 1.880576]\n",
      "epoch:10 step:8440 [D loss: 0.662866, acc: 59.38%] [G loss: 1.868766]\n",
      "epoch:10 step:8441 [D loss: 0.504212, acc: 81.25%] [G loss: 2.024618]\n",
      "epoch:10 step:8442 [D loss: 0.734166, acc: 52.34%] [G loss: 1.587463]\n",
      "epoch:10 step:8443 [D loss: 0.700808, acc: 60.16%] [G loss: 1.927971]\n",
      "epoch:10 step:8444 [D loss: 0.802786, acc: 46.09%] [G loss: 1.866945]\n",
      "epoch:10 step:8445 [D loss: 0.710711, acc: 59.38%] [G loss: 1.776433]\n",
      "epoch:10 step:8446 [D loss: 0.576085, acc: 71.09%] [G loss: 1.730380]\n",
      "epoch:10 step:8447 [D loss: 0.715611, acc: 54.69%] [G loss: 1.717415]\n",
      "epoch:10 step:8448 [D loss: 0.802793, acc: 47.66%] [G loss: 1.716877]\n",
      "epoch:10 step:8449 [D loss: 0.696208, acc: 52.34%] [G loss: 1.858994]\n",
      "epoch:10 step:8450 [D loss: 0.505904, acc: 81.25%] [G loss: 2.050366]\n",
      "epoch:10 step:8451 [D loss: 0.715108, acc: 54.69%] [G loss: 1.729609]\n",
      "epoch:10 step:8452 [D loss: 0.492248, acc: 75.00%] [G loss: 2.396474]\n",
      "epoch:10 step:8453 [D loss: 0.484073, acc: 83.59%] [G loss: 2.253521]\n",
      "epoch:10 step:8454 [D loss: 0.577849, acc: 70.31%] [G loss: 2.415268]\n",
      "epoch:10 step:8455 [D loss: 0.707095, acc: 50.78%] [G loss: 2.120286]\n",
      "epoch:10 step:8456 [D loss: 0.835669, acc: 35.94%] [G loss: 1.609200]\n",
      "epoch:10 step:8457 [D loss: 0.891476, acc: 32.03%] [G loss: 2.065990]\n",
      "epoch:10 step:8458 [D loss: 0.609494, acc: 65.62%] [G loss: 2.061303]\n",
      "epoch:10 step:8459 [D loss: 0.686963, acc: 61.72%] [G loss: 2.079845]\n",
      "epoch:10 step:8460 [D loss: 0.534565, acc: 77.34%] [G loss: 2.147443]\n",
      "epoch:10 step:8461 [D loss: 0.524162, acc: 73.44%] [G loss: 2.291416]\n",
      "epoch:10 step:8462 [D loss: 0.681007, acc: 53.12%] [G loss: 1.833067]\n",
      "epoch:10 step:8463 [D loss: 0.757050, acc: 46.09%] [G loss: 1.767479]\n",
      "epoch:10 step:8464 [D loss: 0.373043, acc: 93.75%] [G loss: 2.242521]\n",
      "epoch:10 step:8465 [D loss: 0.486722, acc: 85.16%] [G loss: 2.210232]\n",
      "epoch:10 step:8466 [D loss: 0.709498, acc: 54.69%] [G loss: 2.081917]\n",
      "epoch:10 step:8467 [D loss: 0.461321, acc: 84.38%] [G loss: 2.407838]\n",
      "epoch:10 step:8468 [D loss: 0.721311, acc: 53.12%] [G loss: 1.905824]\n",
      "epoch:10 step:8469 [D loss: 0.385549, acc: 86.72%] [G loss: 2.925861]\n",
      "epoch:10 step:8470 [D loss: 0.657445, acc: 59.38%] [G loss: 2.097466]\n",
      "epoch:10 step:8471 [D loss: 0.514799, acc: 75.78%] [G loss: 2.403968]\n",
      "epoch:10 step:8472 [D loss: 0.363543, acc: 89.06%] [G loss: 2.090566]\n",
      "epoch:10 step:8473 [D loss: 0.622580, acc: 63.28%] [G loss: 2.349422]\n",
      "epoch:10 step:8474 [D loss: 0.658301, acc: 64.84%] [G loss: 2.003353]\n",
      "epoch:10 step:8475 [D loss: 0.495143, acc: 84.38%] [G loss: 2.513196]\n",
      "epoch:10 step:8476 [D loss: 0.439224, acc: 89.06%] [G loss: 2.054172]\n",
      "epoch:10 step:8477 [D loss: 0.692732, acc: 53.91%] [G loss: 1.948889]\n",
      "epoch:10 step:8478 [D loss: 0.524433, acc: 75.78%] [G loss: 1.878116]\n",
      "epoch:10 step:8479 [D loss: 0.786447, acc: 44.53%] [G loss: 1.517492]\n",
      "epoch:10 step:8480 [D loss: 0.360491, acc: 92.19%] [G loss: 3.245935]\n",
      "epoch:10 step:8481 [D loss: 0.912300, acc: 38.28%] [G loss: 1.960248]\n",
      "epoch:10 step:8482 [D loss: 0.509145, acc: 76.56%] [G loss: 2.468403]\n",
      "epoch:10 step:8483 [D loss: 0.384582, acc: 95.31%] [G loss: 2.440056]\n",
      "epoch:10 step:8484 [D loss: 0.763116, acc: 43.75%] [G loss: 2.339346]\n",
      "epoch:10 step:8485 [D loss: 0.749185, acc: 54.69%] [G loss: 1.997706]\n",
      "epoch:10 step:8486 [D loss: 0.639664, acc: 60.94%] [G loss: 2.038866]\n",
      "epoch:10 step:8487 [D loss: 0.636292, acc: 62.50%] [G loss: 1.982572]\n",
      "epoch:10 step:8488 [D loss: 0.622970, acc: 67.97%] [G loss: 2.045801]\n",
      "epoch:10 step:8489 [D loss: 0.616058, acc: 64.06%] [G loss: 2.064071]\n",
      "epoch:10 step:8490 [D loss: 0.797027, acc: 44.53%] [G loss: 1.602501]\n",
      "epoch:10 step:8491 [D loss: 0.480088, acc: 87.50%] [G loss: 1.878041]\n",
      "epoch:10 step:8492 [D loss: 0.577916, acc: 66.41%] [G loss: 2.005815]\n",
      "epoch:10 step:8493 [D loss: 0.649214, acc: 56.25%] [G loss: 2.233479]\n",
      "epoch:10 step:8494 [D loss: 0.731022, acc: 50.00%] [G loss: 1.571182]\n",
      "epoch:10 step:8495 [D loss: 0.555346, acc: 74.22%] [G loss: 1.968935]\n",
      "epoch:10 step:8496 [D loss: 0.784898, acc: 51.56%] [G loss: 2.141197]\n",
      "epoch:10 step:8497 [D loss: 0.651329, acc: 63.28%] [G loss: 2.063646]\n",
      "epoch:10 step:8498 [D loss: 0.785179, acc: 50.78%] [G loss: 2.553657]\n",
      "epoch:10 step:8499 [D loss: 0.441427, acc: 90.62%] [G loss: 2.270110]\n",
      "epoch:10 step:8500 [D loss: 0.308737, acc: 93.75%] [G loss: 2.174349]\n",
      "epoch:10 step:8501 [D loss: 0.534982, acc: 80.47%] [G loss: 2.107712]\n",
      "epoch:10 step:8502 [D loss: 0.849184, acc: 41.41%] [G loss: 1.959673]\n",
      "epoch:10 step:8503 [D loss: 0.515771, acc: 77.34%] [G loss: 2.420106]\n",
      "epoch:10 step:8504 [D loss: 0.288412, acc: 97.66%] [G loss: 2.240407]\n",
      "epoch:10 step:8505 [D loss: 0.743074, acc: 52.34%] [G loss: 1.656675]\n",
      "epoch:10 step:8506 [D loss: 0.938294, acc: 31.25%] [G loss: 1.617971]\n",
      "epoch:10 step:8507 [D loss: 0.716789, acc: 54.69%] [G loss: 1.853904]\n",
      "epoch:10 step:8508 [D loss: 0.460864, acc: 85.94%] [G loss: 2.140901]\n",
      "epoch:10 step:8509 [D loss: 0.374899, acc: 93.75%] [G loss: 1.963861]\n",
      "epoch:10 step:8510 [D loss: 0.560592, acc: 75.00%] [G loss: 1.751231]\n",
      "epoch:10 step:8511 [D loss: 0.750197, acc: 50.00%] [G loss: 1.688790]\n",
      "epoch:10 step:8512 [D loss: 0.554994, acc: 72.66%] [G loss: 1.929157]\n",
      "epoch:10 step:8513 [D loss: 0.629825, acc: 59.38%] [G loss: 1.942524]\n",
      "epoch:10 step:8514 [D loss: 0.667440, acc: 54.69%] [G loss: 1.589039]\n",
      "epoch:10 step:8515 [D loss: 0.867930, acc: 50.00%] [G loss: 2.277328]\n",
      "epoch:10 step:8516 [D loss: 0.381428, acc: 89.84%] [G loss: 1.808299]\n",
      "epoch:10 step:8517 [D loss: 0.495993, acc: 77.34%] [G loss: 1.890553]\n",
      "epoch:10 step:8518 [D loss: 0.708598, acc: 49.22%] [G loss: 1.758709]\n",
      "epoch:10 step:8519 [D loss: 0.735042, acc: 54.69%] [G loss: 2.232084]\n",
      "epoch:10 step:8520 [D loss: 0.506167, acc: 78.91%] [G loss: 2.115174]\n",
      "epoch:10 step:8521 [D loss: 0.506523, acc: 75.00%] [G loss: 2.207881]\n",
      "epoch:10 step:8522 [D loss: 0.687203, acc: 54.69%] [G loss: 2.825978]\n",
      "epoch:10 step:8523 [D loss: 0.627051, acc: 68.75%] [G loss: 2.017872]\n",
      "epoch:10 step:8524 [D loss: 0.695598, acc: 55.47%] [G loss: 1.974281]\n",
      "epoch:10 step:8525 [D loss: 0.558066, acc: 73.44%] [G loss: 2.276322]\n",
      "epoch:10 step:8526 [D loss: 0.656444, acc: 60.94%] [G loss: 1.890743]\n",
      "epoch:10 step:8527 [D loss: 0.587117, acc: 65.62%] [G loss: 2.641340]\n",
      "epoch:10 step:8528 [D loss: 0.499381, acc: 76.56%] [G loss: 2.207365]\n",
      "epoch:10 step:8529 [D loss: 0.727338, acc: 46.88%] [G loss: 2.138590]\n",
      "epoch:10 step:8530 [D loss: 0.642248, acc: 60.16%] [G loss: 1.835511]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:10 step:8531 [D loss: 0.716898, acc: 54.69%] [G loss: 1.859341]\n",
      "epoch:10 step:8532 [D loss: 0.485245, acc: 82.03%] [G loss: 2.241238]\n",
      "epoch:10 step:8533 [D loss: 0.728648, acc: 50.00%] [G loss: 2.040206]\n",
      "epoch:10 step:8534 [D loss: 0.361575, acc: 84.38%] [G loss: 2.504887]\n",
      "epoch:10 step:8535 [D loss: 0.688812, acc: 54.69%] [G loss: 2.102128]\n",
      "epoch:10 step:8536 [D loss: 0.628225, acc: 68.75%] [G loss: 2.129838]\n",
      "epoch:10 step:8537 [D loss: 0.598719, acc: 60.94%] [G loss: 2.452641]\n",
      "epoch:10 step:8538 [D loss: 0.716279, acc: 50.78%] [G loss: 2.156259]\n",
      "epoch:10 step:8539 [D loss: 0.473087, acc: 81.25%] [G loss: 2.109898]\n",
      "epoch:10 step:8540 [D loss: 0.643360, acc: 62.50%] [G loss: 2.115961]\n",
      "epoch:10 step:8541 [D loss: 0.599581, acc: 68.75%] [G loss: 2.057525]\n",
      "epoch:10 step:8542 [D loss: 0.535208, acc: 75.78%] [G loss: 2.225099]\n",
      "epoch:10 step:8543 [D loss: 0.442554, acc: 84.38%] [G loss: 2.016950]\n",
      "epoch:10 step:8544 [D loss: 0.780746, acc: 50.78%] [G loss: 1.669935]\n",
      "epoch:10 step:8545 [D loss: 0.412302, acc: 89.84%] [G loss: 2.042186]\n",
      "epoch:10 step:8546 [D loss: 0.774260, acc: 43.75%] [G loss: 1.763340]\n",
      "epoch:10 step:8547 [D loss: 0.715356, acc: 55.47%] [G loss: 1.786148]\n",
      "epoch:10 step:8548 [D loss: 0.805154, acc: 39.06%] [G loss: 1.608315]\n",
      "epoch:10 step:8549 [D loss: 0.740956, acc: 56.25%] [G loss: 1.966384]\n",
      "epoch:10 step:8550 [D loss: 0.696101, acc: 57.03%] [G loss: 2.001873]\n",
      "epoch:10 step:8551 [D loss: 0.699002, acc: 58.59%] [G loss: 2.120468]\n",
      "epoch:10 step:8552 [D loss: 0.816455, acc: 43.75%] [G loss: 2.062686]\n",
      "epoch:10 step:8553 [D loss: 0.495523, acc: 82.03%] [G loss: 2.134588]\n",
      "epoch:10 step:8554 [D loss: 0.576782, acc: 70.31%] [G loss: 2.180164]\n",
      "epoch:10 step:8555 [D loss: 0.422983, acc: 86.72%] [G loss: 2.772546]\n",
      "epoch:10 step:8556 [D loss: 0.537277, acc: 77.34%] [G loss: 2.299620]\n",
      "epoch:10 step:8557 [D loss: 0.306741, acc: 91.41%] [G loss: 2.723265]\n",
      "epoch:10 step:8558 [D loss: 0.455666, acc: 82.03%] [G loss: 2.836256]\n",
      "epoch:10 step:8559 [D loss: 0.769164, acc: 45.31%] [G loss: 2.221388]\n",
      "epoch:10 step:8560 [D loss: 0.647090, acc: 63.28%] [G loss: 1.998605]\n",
      "epoch:10 step:8561 [D loss: 0.837996, acc: 44.53%] [G loss: 1.962909]\n",
      "epoch:10 step:8562 [D loss: 0.502614, acc: 84.38%] [G loss: 2.982468]\n",
      "epoch:10 step:8563 [D loss: 0.568112, acc: 75.00%] [G loss: 2.282026]\n",
      "epoch:10 step:8564 [D loss: 0.392735, acc: 89.06%] [G loss: 3.247731]\n",
      "epoch:10 step:8565 [D loss: 0.720496, acc: 52.34%] [G loss: 1.926513]\n",
      "epoch:10 step:8566 [D loss: 0.715550, acc: 54.69%] [G loss: 1.626634]\n",
      "epoch:10 step:8567 [D loss: 0.645302, acc: 59.38%] [G loss: 2.149412]\n",
      "epoch:10 step:8568 [D loss: 0.693439, acc: 57.81%] [G loss: 1.980429]\n",
      "epoch:10 step:8569 [D loss: 0.641553, acc: 64.06%] [G loss: 2.106392]\n",
      "epoch:10 step:8570 [D loss: 0.839769, acc: 46.09%] [G loss: 1.722166]\n",
      "epoch:10 step:8571 [D loss: 0.445583, acc: 85.16%] [G loss: 2.017351]\n",
      "epoch:10 step:8572 [D loss: 0.566931, acc: 68.75%] [G loss: 1.725811]\n",
      "epoch:10 step:8573 [D loss: 0.525813, acc: 74.22%] [G loss: 1.947953]\n",
      "epoch:10 step:8574 [D loss: 0.739222, acc: 51.56%] [G loss: 1.588343]\n",
      "epoch:10 step:8575 [D loss: 0.789313, acc: 46.09%] [G loss: 1.623722]\n",
      "epoch:10 step:8576 [D loss: 0.368462, acc: 87.50%] [G loss: 1.784777]\n",
      "epoch:10 step:8577 [D loss: 0.510125, acc: 82.03%] [G loss: 1.859059]\n",
      "epoch:10 step:8578 [D loss: 0.561082, acc: 75.78%] [G loss: 2.556941]\n",
      "epoch:10 step:8579 [D loss: 1.002354, acc: 45.31%] [G loss: 1.536475]\n",
      "epoch:10 step:8580 [D loss: 0.379148, acc: 84.38%] [G loss: 2.007971]\n",
      "epoch:10 step:8581 [D loss: 0.365203, acc: 92.97%] [G loss: 2.053406]\n",
      "epoch:10 step:8582 [D loss: 0.807527, acc: 48.44%] [G loss: 1.792371]\n",
      "epoch:10 step:8583 [D loss: 0.554423, acc: 75.78%] [G loss: 2.662608]\n",
      "epoch:10 step:8584 [D loss: 0.660634, acc: 64.84%] [G loss: 1.998962]\n",
      "epoch:10 step:8585 [D loss: 0.701640, acc: 64.84%] [G loss: 1.786117]\n",
      "epoch:10 step:8586 [D loss: 0.545637, acc: 74.22%] [G loss: 1.806524]\n",
      "epoch:10 step:8587 [D loss: 0.375077, acc: 90.62%] [G loss: 1.947165]\n",
      "epoch:10 step:8588 [D loss: 0.517936, acc: 78.91%] [G loss: 1.911951]\n",
      "epoch:10 step:8589 [D loss: 0.641491, acc: 59.38%] [G loss: 1.668841]\n",
      "epoch:10 step:8590 [D loss: 1.114516, acc: 41.41%] [G loss: 1.785288]\n",
      "epoch:10 step:8591 [D loss: 0.703514, acc: 47.66%] [G loss: 1.781708]\n",
      "epoch:11 step:8592 [D loss: 0.466466, acc: 82.81%] [G loss: 2.104571]\n",
      "epoch:11 step:8593 [D loss: 0.877185, acc: 43.75%] [G loss: 1.524644]\n",
      "epoch:11 step:8594 [D loss: 0.611780, acc: 63.28%] [G loss: 2.171053]\n",
      "epoch:11 step:8595 [D loss: 0.684692, acc: 55.47%] [G loss: 2.571741]\n",
      "epoch:11 step:8596 [D loss: 0.579557, acc: 70.31%] [G loss: 2.102836]\n",
      "epoch:11 step:8597 [D loss: 0.356060, acc: 78.12%] [G loss: 3.115171]\n",
      "epoch:11 step:8598 [D loss: 0.381072, acc: 89.84%] [G loss: 2.261611]\n",
      "epoch:11 step:8599 [D loss: 0.613792, acc: 67.97%] [G loss: 2.073085]\n",
      "epoch:11 step:8600 [D loss: 0.329897, acc: 92.19%] [G loss: 1.968892]\n",
      "##############\n",
      "[0.85488554 0.88549127 0.81627713 0.81301485 0.79058784 0.83890967\n",
      " 0.89026607 0.85028445 0.81865071 0.82747964]\n",
      "##########\n",
      "epoch:11 step:8601 [D loss: 0.511958, acc: 78.12%] [G loss: 2.033596]\n",
      "epoch:11 step:8602 [D loss: 0.858054, acc: 50.78%] [G loss: 2.343842]\n",
      "epoch:11 step:8603 [D loss: 0.377954, acc: 92.97%] [G loss: 2.025965]\n",
      "epoch:11 step:8604 [D loss: 0.380079, acc: 86.72%] [G loss: 1.914043]\n",
      "epoch:11 step:8605 [D loss: 0.456528, acc: 71.09%] [G loss: 1.983093]\n",
      "epoch:11 step:8606 [D loss: 0.677996, acc: 58.59%] [G loss: 1.935269]\n",
      "epoch:11 step:8607 [D loss: 0.812524, acc: 46.88%] [G loss: 1.675047]\n",
      "epoch:11 step:8608 [D loss: 0.426643, acc: 83.59%] [G loss: 2.487121]\n",
      "epoch:11 step:8609 [D loss: 0.392571, acc: 75.78%] [G loss: 1.972050]\n",
      "epoch:11 step:8610 [D loss: 0.863901, acc: 49.22%] [G loss: 1.905318]\n",
      "epoch:11 step:8611 [D loss: 0.742147, acc: 51.56%] [G loss: 2.221478]\n",
      "epoch:11 step:8612 [D loss: 0.595550, acc: 71.09%] [G loss: 2.434943]\n",
      "epoch:11 step:8613 [D loss: 0.284487, acc: 97.66%] [G loss: 2.712902]\n",
      "epoch:11 step:8614 [D loss: 0.980833, acc: 24.22%] [G loss: 1.992643]\n",
      "epoch:11 step:8615 [D loss: 0.605288, acc: 72.66%] [G loss: 2.082140]\n",
      "epoch:11 step:8616 [D loss: 0.390165, acc: 91.41%] [G loss: 2.490637]\n",
      "epoch:11 step:8617 [D loss: 0.677475, acc: 55.47%] [G loss: 1.875394]\n",
      "epoch:11 step:8618 [D loss: 0.521674, acc: 80.47%] [G loss: 1.960171]\n",
      "epoch:11 step:8619 [D loss: 0.718122, acc: 52.34%] [G loss: 2.363661]\n",
      "epoch:11 step:8620 [D loss: 0.378777, acc: 91.41%] [G loss: 2.089272]\n",
      "epoch:11 step:8621 [D loss: 0.568802, acc: 67.97%] [G loss: 1.924375]\n",
      "epoch:11 step:8622 [D loss: 0.486451, acc: 71.09%] [G loss: 2.410465]\n",
      "epoch:11 step:8623 [D loss: 0.638156, acc: 66.41%] [G loss: 2.159803]\n",
      "epoch:11 step:8624 [D loss: 0.430934, acc: 78.91%] [G loss: 1.899154]\n",
      "epoch:11 step:8625 [D loss: 0.476655, acc: 78.91%] [G loss: 2.514688]\n",
      "epoch:11 step:8626 [D loss: 0.687970, acc: 50.00%] [G loss: 3.176641]\n",
      "epoch:11 step:8627 [D loss: 0.242310, acc: 100.00%] [G loss: 2.441606]\n",
      "epoch:11 step:8628 [D loss: 0.344073, acc: 92.19%] [G loss: 2.774773]\n",
      "epoch:11 step:8629 [D loss: 0.448190, acc: 86.72%] [G loss: 2.524956]\n",
      "epoch:11 step:8630 [D loss: 0.628529, acc: 64.84%] [G loss: 2.038550]\n",
      "epoch:11 step:8631 [D loss: 0.578852, acc: 69.53%] [G loss: 1.907086]\n",
      "epoch:11 step:8632 [D loss: 0.199406, acc: 96.09%] [G loss: 2.459266]\n",
      "epoch:11 step:8633 [D loss: 0.509111, acc: 85.94%] [G loss: 2.221206]\n",
      "epoch:11 step:8634 [D loss: 0.275162, acc: 97.66%] [G loss: 2.131119]\n",
      "epoch:11 step:8635 [D loss: 0.414631, acc: 87.50%] [G loss: 1.788572]\n",
      "epoch:11 step:8636 [D loss: 0.286221, acc: 92.97%] [G loss: 2.871275]\n",
      "epoch:11 step:8637 [D loss: 0.989260, acc: 50.00%] [G loss: 1.728179]\n",
      "epoch:11 step:8638 [D loss: 0.463004, acc: 75.00%] [G loss: 2.219465]\n",
      "epoch:11 step:8639 [D loss: 0.636319, acc: 65.62%] [G loss: 2.430744]\n",
      "epoch:11 step:8640 [D loss: 0.833979, acc: 54.69%] [G loss: 1.368730]\n",
      "epoch:11 step:8641 [D loss: 0.367221, acc: 94.53%] [G loss: 2.230268]\n",
      "epoch:11 step:8642 [D loss: 1.112009, acc: 47.66%] [G loss: 1.856950]\n",
      "epoch:11 step:8643 [D loss: 0.429082, acc: 84.38%] [G loss: 2.842119]\n",
      "epoch:11 step:8644 [D loss: 0.532341, acc: 71.09%] [G loss: 3.565032]\n",
      "epoch:11 step:8645 [D loss: 0.717682, acc: 57.81%] [G loss: 2.783538]\n",
      "epoch:11 step:8646 [D loss: 0.876956, acc: 41.41%] [G loss: 1.880707]\n",
      "epoch:11 step:8647 [D loss: 0.231931, acc: 95.31%] [G loss: 2.693737]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:11 step:8648 [D loss: 0.464109, acc: 78.12%] [G loss: 2.542341]\n",
      "epoch:11 step:8649 [D loss: 0.921116, acc: 38.28%] [G loss: 2.390822]\n",
      "epoch:11 step:8650 [D loss: 0.557037, acc: 77.34%] [G loss: 2.582153]\n",
      "epoch:11 step:8651 [D loss: 0.443980, acc: 79.69%] [G loss: 2.478337]\n",
      "epoch:11 step:8652 [D loss: 0.602784, acc: 67.97%] [G loss: 1.727665]\n",
      "epoch:11 step:8653 [D loss: 0.669580, acc: 65.62%] [G loss: 2.447555]\n",
      "epoch:11 step:8654 [D loss: 0.698795, acc: 60.94%] [G loss: 1.572892]\n",
      "epoch:11 step:8655 [D loss: 0.530017, acc: 78.12%] [G loss: 2.016981]\n",
      "epoch:11 step:8656 [D loss: 0.287930, acc: 94.53%] [G loss: 3.178112]\n",
      "epoch:11 step:8657 [D loss: 0.717632, acc: 50.00%] [G loss: 1.510280]\n",
      "epoch:11 step:8658 [D loss: 0.649214, acc: 62.50%] [G loss: 2.411828]\n",
      "epoch:11 step:8659 [D loss: 0.516288, acc: 77.34%] [G loss: 1.801438]\n",
      "epoch:11 step:8660 [D loss: 0.295641, acc: 91.41%] [G loss: 2.609882]\n",
      "epoch:11 step:8661 [D loss: 0.466530, acc: 88.28%] [G loss: 1.712470]\n",
      "epoch:11 step:8662 [D loss: 1.222620, acc: 16.41%] [G loss: 1.841280]\n",
      "epoch:11 step:8663 [D loss: 0.281613, acc: 96.88%] [G loss: 2.161611]\n",
      "epoch:11 step:8664 [D loss: 0.689979, acc: 57.81%] [G loss: 1.585858]\n",
      "epoch:11 step:8665 [D loss: 0.364646, acc: 88.28%] [G loss: 1.924176]\n",
      "epoch:11 step:8666 [D loss: 0.384251, acc: 92.97%] [G loss: 1.651432]\n",
      "epoch:11 step:8667 [D loss: 0.600249, acc: 63.28%] [G loss: 1.931866]\n",
      "epoch:11 step:8668 [D loss: 0.426217, acc: 88.28%] [G loss: 1.973163]\n",
      "epoch:11 step:8669 [D loss: 0.499939, acc: 82.03%] [G loss: 1.587315]\n",
      "epoch:11 step:8670 [D loss: 0.337548, acc: 91.41%] [G loss: 1.651148]\n",
      "epoch:11 step:8671 [D loss: 1.384269, acc: 16.41%] [G loss: 1.593287]\n",
      "epoch:11 step:8672 [D loss: 0.728189, acc: 49.22%] [G loss: 1.558971]\n",
      "epoch:11 step:8673 [D loss: 0.580101, acc: 71.09%] [G loss: 2.073219]\n",
      "epoch:11 step:8674 [D loss: 0.343873, acc: 95.31%] [G loss: 2.124997]\n",
      "epoch:11 step:8675 [D loss: 1.158889, acc: 8.59%] [G loss: 1.602098]\n",
      "epoch:11 step:8676 [D loss: 0.382942, acc: 90.62%] [G loss: 2.384439]\n",
      "epoch:11 step:8677 [D loss: 0.726200, acc: 53.91%] [G loss: 2.089707]\n",
      "epoch:11 step:8678 [D loss: 0.547114, acc: 74.22%] [G loss: 1.927958]\n",
      "epoch:11 step:8679 [D loss: 0.417702, acc: 87.50%] [G loss: 2.160766]\n",
      "epoch:11 step:8680 [D loss: 0.352426, acc: 82.03%] [G loss: 2.430062]\n",
      "epoch:11 step:8681 [D loss: 1.183943, acc: 14.06%] [G loss: 1.657274]\n",
      "epoch:11 step:8682 [D loss: 0.543469, acc: 65.62%] [G loss: 2.606956]\n",
      "epoch:11 step:8683 [D loss: 0.478961, acc: 83.59%] [G loss: 2.087259]\n",
      "epoch:11 step:8684 [D loss: 0.478983, acc: 78.12%] [G loss: 2.214389]\n",
      "epoch:11 step:8685 [D loss: 0.814867, acc: 52.34%] [G loss: 2.083145]\n",
      "epoch:11 step:8686 [D loss: 0.545507, acc: 77.34%] [G loss: 2.255935]\n",
      "epoch:11 step:8687 [D loss: 0.696425, acc: 53.91%] [G loss: 2.564233]\n",
      "epoch:11 step:8688 [D loss: 0.524283, acc: 82.81%] [G loss: 2.234596]\n",
      "epoch:11 step:8689 [D loss: 0.465893, acc: 85.94%] [G loss: 1.897336]\n",
      "epoch:11 step:8690 [D loss: 0.384045, acc: 93.75%] [G loss: 2.594117]\n",
      "epoch:11 step:8691 [D loss: 0.450540, acc: 84.38%] [G loss: 2.521071]\n",
      "epoch:11 step:8692 [D loss: 0.877863, acc: 46.09%] [G loss: 1.321279]\n",
      "epoch:11 step:8693 [D loss: 0.743314, acc: 54.69%] [G loss: 2.086588]\n",
      "epoch:11 step:8694 [D loss: 0.389188, acc: 83.59%] [G loss: 1.910980]\n",
      "epoch:11 step:8695 [D loss: 0.543272, acc: 75.00%] [G loss: 1.742696]\n",
      "epoch:11 step:8696 [D loss: 0.378850, acc: 89.06%] [G loss: 1.924736]\n",
      "epoch:11 step:8697 [D loss: 0.726259, acc: 50.78%] [G loss: 2.370002]\n",
      "epoch:11 step:8698 [D loss: 0.741496, acc: 55.47%] [G loss: 2.081688]\n",
      "epoch:11 step:8699 [D loss: 0.440658, acc: 78.12%] [G loss: 2.108882]\n",
      "epoch:11 step:8700 [D loss: 1.238419, acc: 21.88%] [G loss: 1.675367]\n",
      "epoch:11 step:8701 [D loss: 0.431749, acc: 87.50%] [G loss: 1.539010]\n",
      "epoch:11 step:8702 [D loss: 0.424721, acc: 90.62%] [G loss: 1.989035]\n",
      "epoch:11 step:8703 [D loss: 0.677021, acc: 56.25%] [G loss: 1.895690]\n",
      "epoch:11 step:8704 [D loss: 0.678558, acc: 55.47%] [G loss: 1.691074]\n",
      "epoch:11 step:8705 [D loss: 0.756872, acc: 43.75%] [G loss: 1.887845]\n",
      "epoch:11 step:8706 [D loss: 0.678905, acc: 58.59%] [G loss: 1.795276]\n",
      "epoch:11 step:8707 [D loss: 0.689466, acc: 57.81%] [G loss: 1.442735]\n",
      "epoch:11 step:8708 [D loss: 0.948308, acc: 33.59%] [G loss: 1.510496]\n",
      "epoch:11 step:8709 [D loss: 0.903581, acc: 33.59%] [G loss: 1.755980]\n",
      "epoch:11 step:8710 [D loss: 0.574155, acc: 70.31%] [G loss: 2.252732]\n",
      "epoch:11 step:8711 [D loss: 0.323640, acc: 93.75%] [G loss: 1.894280]\n",
      "epoch:11 step:8712 [D loss: 0.709935, acc: 50.00%] [G loss: 1.644522]\n",
      "epoch:11 step:8713 [D loss: 0.634847, acc: 64.84%] [G loss: 1.765636]\n",
      "epoch:11 step:8714 [D loss: 0.572457, acc: 76.56%] [G loss: 2.038267]\n",
      "epoch:11 step:8715 [D loss: 0.454213, acc: 85.94%] [G loss: 2.320670]\n",
      "epoch:11 step:8716 [D loss: 0.518402, acc: 78.12%] [G loss: 2.518868]\n",
      "epoch:11 step:8717 [D loss: 0.694881, acc: 60.16%] [G loss: 1.621286]\n",
      "epoch:11 step:8718 [D loss: 0.727607, acc: 46.88%] [G loss: 2.316901]\n",
      "epoch:11 step:8719 [D loss: 0.450494, acc: 84.38%] [G loss: 2.121664]\n",
      "epoch:11 step:8720 [D loss: 0.590300, acc: 70.31%] [G loss: 1.707809]\n",
      "epoch:11 step:8721 [D loss: 0.983348, acc: 28.91%] [G loss: 1.713017]\n",
      "epoch:11 step:8722 [D loss: 0.838782, acc: 49.22%] [G loss: 1.739732]\n",
      "epoch:11 step:8723 [D loss: 0.615514, acc: 66.41%] [G loss: 1.827082]\n",
      "epoch:11 step:8724 [D loss: 0.443304, acc: 86.72%] [G loss: 2.009262]\n",
      "epoch:11 step:8725 [D loss: 0.403752, acc: 92.19%] [G loss: 2.267400]\n",
      "epoch:11 step:8726 [D loss: 0.710742, acc: 52.34%] [G loss: 1.865964]\n",
      "epoch:11 step:8727 [D loss: 0.704291, acc: 57.03%] [G loss: 1.750002]\n",
      "epoch:11 step:8728 [D loss: 0.500771, acc: 83.59%] [G loss: 1.654937]\n",
      "epoch:11 step:8729 [D loss: 0.499156, acc: 78.91%] [G loss: 1.574800]\n",
      "epoch:11 step:8730 [D loss: 0.459221, acc: 89.06%] [G loss: 2.138650]\n",
      "epoch:11 step:8731 [D loss: 0.681541, acc: 57.81%] [G loss: 2.001247]\n",
      "epoch:11 step:8732 [D loss: 0.525728, acc: 67.97%] [G loss: 2.031099]\n",
      "epoch:11 step:8733 [D loss: 0.504254, acc: 85.16%] [G loss: 3.210605]\n",
      "epoch:11 step:8734 [D loss: 0.554417, acc: 75.00%] [G loss: 2.078124]\n",
      "epoch:11 step:8735 [D loss: 0.791904, acc: 49.22%] [G loss: 2.160015]\n",
      "epoch:11 step:8736 [D loss: 0.700806, acc: 57.03%] [G loss: 2.540536]\n",
      "epoch:11 step:8737 [D loss: 0.497342, acc: 81.25%] [G loss: 1.791415]\n",
      "epoch:11 step:8738 [D loss: 0.369138, acc: 81.25%] [G loss: 2.363061]\n",
      "epoch:11 step:8739 [D loss: 0.462184, acc: 87.50%] [G loss: 2.315108]\n",
      "epoch:11 step:8740 [D loss: 0.448958, acc: 84.38%] [G loss: 2.179767]\n",
      "epoch:11 step:8741 [D loss: 0.542558, acc: 73.44%] [G loss: 1.837946]\n",
      "epoch:11 step:8742 [D loss: 0.654921, acc: 65.62%] [G loss: 1.990864]\n",
      "epoch:11 step:8743 [D loss: 0.608291, acc: 64.84%] [G loss: 2.164546]\n",
      "epoch:11 step:8744 [D loss: 0.245334, acc: 94.53%] [G loss: 3.167233]\n",
      "epoch:11 step:8745 [D loss: 0.810237, acc: 46.88%] [G loss: 1.996608]\n",
      "epoch:11 step:8746 [D loss: 0.448817, acc: 86.72%] [G loss: 1.921144]\n",
      "epoch:11 step:8747 [D loss: 0.225851, acc: 97.66%] [G loss: 2.441135]\n",
      "epoch:11 step:8748 [D loss: 0.405044, acc: 89.84%] [G loss: 2.970222]\n",
      "epoch:11 step:8749 [D loss: 0.383881, acc: 81.25%] [G loss: 3.485241]\n",
      "epoch:11 step:8750 [D loss: 0.814492, acc: 51.56%] [G loss: 2.450400]\n",
      "epoch:11 step:8751 [D loss: 0.836155, acc: 42.97%] [G loss: 1.633676]\n",
      "epoch:11 step:8752 [D loss: 0.606256, acc: 67.97%] [G loss: 2.603560]\n",
      "epoch:11 step:8753 [D loss: 0.394218, acc: 88.28%] [G loss: 2.472980]\n",
      "epoch:11 step:8754 [D loss: 0.274686, acc: 86.72%] [G loss: 3.045702]\n",
      "epoch:11 step:8755 [D loss: 0.246651, acc: 98.44%] [G loss: 2.079861]\n",
      "epoch:11 step:8756 [D loss: 0.493115, acc: 85.16%] [G loss: 3.142645]\n",
      "epoch:11 step:8757 [D loss: 0.667281, acc: 57.03%] [G loss: 2.072186]\n",
      "epoch:11 step:8758 [D loss: 0.432022, acc: 87.50%] [G loss: 2.351147]\n",
      "epoch:11 step:8759 [D loss: 0.367583, acc: 92.19%] [G loss: 2.465890]\n",
      "epoch:11 step:8760 [D loss: 0.508699, acc: 80.47%] [G loss: 2.160154]\n",
      "epoch:11 step:8761 [D loss: 0.691798, acc: 57.03%] [G loss: 2.228136]\n",
      "epoch:11 step:8762 [D loss: 0.908560, acc: 48.44%] [G loss: 2.338051]\n",
      "epoch:11 step:8763 [D loss: 0.755906, acc: 52.34%] [G loss: 2.363767]\n",
      "epoch:11 step:8764 [D loss: 0.527166, acc: 71.88%] [G loss: 2.902452]\n",
      "epoch:11 step:8765 [D loss: 0.498126, acc: 85.16%] [G loss: 2.209003]\n",
      "epoch:11 step:8766 [D loss: 0.900225, acc: 25.78%] [G loss: 2.233538]\n",
      "epoch:11 step:8767 [D loss: 0.680449, acc: 60.94%] [G loss: 1.917324]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:11 step:8768 [D loss: 0.538767, acc: 67.97%] [G loss: 2.672844]\n",
      "epoch:11 step:8769 [D loss: 0.833923, acc: 40.62%] [G loss: 1.718382]\n",
      "epoch:11 step:8770 [D loss: 0.431796, acc: 88.28%] [G loss: 2.687324]\n",
      "epoch:11 step:8771 [D loss: 0.554907, acc: 73.44%] [G loss: 1.918455]\n",
      "epoch:11 step:8772 [D loss: 0.325788, acc: 86.72%] [G loss: 3.905952]\n",
      "epoch:11 step:8773 [D loss: 0.641017, acc: 61.72%] [G loss: 2.129741]\n",
      "epoch:11 step:8774 [D loss: 0.515290, acc: 75.78%] [G loss: 2.431297]\n",
      "epoch:11 step:8775 [D loss: 0.433588, acc: 83.59%] [G loss: 2.017290]\n",
      "epoch:11 step:8776 [D loss: 1.177673, acc: 31.25%] [G loss: 2.088895]\n",
      "epoch:11 step:8777 [D loss: 0.778289, acc: 53.12%] [G loss: 1.722938]\n",
      "epoch:11 step:8778 [D loss: 0.744986, acc: 43.75%] [G loss: 2.161196]\n",
      "epoch:11 step:8779 [D loss: 0.411526, acc: 91.41%] [G loss: 2.213341]\n",
      "epoch:11 step:8780 [D loss: 0.591765, acc: 64.84%] [G loss: 2.168003]\n",
      "epoch:11 step:8781 [D loss: 0.477499, acc: 69.53%] [G loss: 2.051599]\n",
      "epoch:11 step:8782 [D loss: 0.523172, acc: 65.62%] [G loss: 2.210347]\n",
      "epoch:11 step:8783 [D loss: 0.311647, acc: 94.53%] [G loss: 2.252259]\n",
      "epoch:11 step:8784 [D loss: 0.433426, acc: 79.69%] [G loss: 2.250842]\n",
      "epoch:11 step:8785 [D loss: 0.335161, acc: 91.41%] [G loss: 2.117054]\n",
      "epoch:11 step:8786 [D loss: 0.568125, acc: 69.53%] [G loss: 1.656872]\n",
      "epoch:11 step:8787 [D loss: 0.975374, acc: 27.34%] [G loss: 1.386906]\n",
      "epoch:11 step:8788 [D loss: 0.352918, acc: 95.31%] [G loss: 1.981364]\n",
      "epoch:11 step:8789 [D loss: 0.486085, acc: 76.56%] [G loss: 1.744817]\n",
      "epoch:11 step:8790 [D loss: 0.482763, acc: 69.53%] [G loss: 2.159636]\n",
      "epoch:11 step:8791 [D loss: 0.500280, acc: 78.91%] [G loss: 2.188021]\n",
      "epoch:11 step:8792 [D loss: 0.660792, acc: 58.59%] [G loss: 1.990854]\n",
      "epoch:11 step:8793 [D loss: 0.860305, acc: 50.00%] [G loss: 1.871439]\n",
      "epoch:11 step:8794 [D loss: 0.428647, acc: 90.62%] [G loss: 2.663176]\n",
      "epoch:11 step:8795 [D loss: 0.476422, acc: 82.03%] [G loss: 2.044520]\n",
      "epoch:11 step:8796 [D loss: 1.063244, acc: 25.78%] [G loss: 1.928432]\n",
      "epoch:11 step:8797 [D loss: 0.688503, acc: 56.25%] [G loss: 2.117241]\n",
      "epoch:11 step:8798 [D loss: 1.106775, acc: 18.75%] [G loss: 1.544779]\n",
      "epoch:11 step:8799 [D loss: 0.254905, acc: 97.66%] [G loss: 2.802712]\n",
      "epoch:11 step:8800 [D loss: 0.663939, acc: 60.16%] [G loss: 2.245280]\n",
      "##############\n",
      "[0.85031938 0.86150465 0.82186769 0.81518715 0.78879293 0.79751923\n",
      " 0.87354982 0.82652764 0.83021392 0.83084084]\n",
      "##########\n",
      "epoch:11 step:8801 [D loss: 0.696361, acc: 60.16%] [G loss: 1.697502]\n",
      "epoch:11 step:8802 [D loss: 0.473327, acc: 72.66%] [G loss: 2.549189]\n",
      "epoch:11 step:8803 [D loss: 0.614744, acc: 67.19%] [G loss: 2.419099]\n",
      "epoch:11 step:8804 [D loss: 0.827078, acc: 44.53%] [G loss: 1.765278]\n",
      "epoch:11 step:8805 [D loss: 0.425540, acc: 87.50%] [G loss: 2.545336]\n",
      "epoch:11 step:8806 [D loss: 0.446389, acc: 82.03%] [G loss: 1.913806]\n",
      "epoch:11 step:8807 [D loss: 0.511957, acc: 72.66%] [G loss: 1.941950]\n",
      "epoch:11 step:8808 [D loss: 0.435016, acc: 91.41%] [G loss: 1.571892]\n",
      "epoch:11 step:8809 [D loss: 0.606874, acc: 55.47%] [G loss: 2.646382]\n",
      "epoch:11 step:8810 [D loss: 0.541816, acc: 75.00%] [G loss: 1.947330]\n",
      "epoch:11 step:8811 [D loss: 0.530154, acc: 75.00%] [G loss: 2.889711]\n",
      "epoch:11 step:8812 [D loss: 1.364228, acc: 21.09%] [G loss: 1.613608]\n",
      "epoch:11 step:8813 [D loss: 0.478966, acc: 82.03%] [G loss: 2.702098]\n",
      "epoch:11 step:8814 [D loss: 0.952212, acc: 18.75%] [G loss: 2.268930]\n",
      "epoch:11 step:8815 [D loss: 0.599339, acc: 74.22%] [G loss: 1.890253]\n",
      "epoch:11 step:8816 [D loss: 0.554175, acc: 74.22%] [G loss: 2.133154]\n",
      "epoch:11 step:8817 [D loss: 0.457085, acc: 89.84%] [G loss: 2.492856]\n",
      "epoch:11 step:8818 [D loss: 0.611187, acc: 63.28%] [G loss: 2.286193]\n",
      "epoch:11 step:8819 [D loss: 0.597703, acc: 63.28%] [G loss: 2.587575]\n",
      "epoch:11 step:8820 [D loss: 0.594674, acc: 73.44%] [G loss: 2.119526]\n",
      "epoch:11 step:8821 [D loss: 0.878306, acc: 53.12%] [G loss: 2.157415]\n",
      "epoch:11 step:8822 [D loss: 0.368368, acc: 92.19%] [G loss: 2.257430]\n",
      "epoch:11 step:8823 [D loss: 0.532001, acc: 80.47%] [G loss: 2.680886]\n",
      "epoch:11 step:8824 [D loss: 0.305805, acc: 97.66%] [G loss: 2.718775]\n",
      "epoch:11 step:8825 [D loss: 0.538038, acc: 72.66%] [G loss: 2.121392]\n",
      "epoch:11 step:8826 [D loss: 0.398021, acc: 92.97%] [G loss: 2.734696]\n",
      "epoch:11 step:8827 [D loss: 0.604048, acc: 67.19%] [G loss: 2.379689]\n",
      "epoch:11 step:8828 [D loss: 0.313738, acc: 91.41%] [G loss: 1.996123]\n",
      "epoch:11 step:8829 [D loss: 0.470961, acc: 81.25%] [G loss: 1.846642]\n",
      "epoch:11 step:8830 [D loss: 0.557917, acc: 64.06%] [G loss: 2.915158]\n",
      "epoch:11 step:8831 [D loss: 0.332171, acc: 92.97%] [G loss: 2.277104]\n",
      "epoch:11 step:8832 [D loss: 0.626561, acc: 61.72%] [G loss: 1.796993]\n",
      "epoch:11 step:8833 [D loss: 0.704208, acc: 52.34%] [G loss: 1.794029]\n",
      "epoch:11 step:8834 [D loss: 0.696811, acc: 54.69%] [G loss: 2.350722]\n",
      "epoch:11 step:8835 [D loss: 0.645883, acc: 67.19%] [G loss: 2.311162]\n",
      "epoch:11 step:8836 [D loss: 1.123258, acc: 40.62%] [G loss: 1.124393]\n",
      "epoch:11 step:8837 [D loss: 0.328053, acc: 82.81%] [G loss: 1.824673]\n",
      "epoch:11 step:8838 [D loss: 0.960852, acc: 50.00%] [G loss: 2.350873]\n",
      "epoch:11 step:8839 [D loss: 0.553179, acc: 73.44%] [G loss: 1.853336]\n",
      "epoch:11 step:8840 [D loss: 0.633275, acc: 59.38%] [G loss: 1.652742]\n",
      "epoch:11 step:8841 [D loss: 0.611085, acc: 71.09%] [G loss: 1.662013]\n",
      "epoch:11 step:8842 [D loss: 0.705127, acc: 50.00%] [G loss: 1.961193]\n",
      "epoch:11 step:8843 [D loss: 0.440994, acc: 84.38%] [G loss: 1.910784]\n",
      "epoch:11 step:8844 [D loss: 0.527876, acc: 67.97%] [G loss: 1.868100]\n",
      "epoch:11 step:8845 [D loss: 0.549840, acc: 74.22%] [G loss: 2.200755]\n",
      "epoch:11 step:8846 [D loss: 0.626632, acc: 67.19%] [G loss: 2.320869]\n",
      "epoch:11 step:8847 [D loss: 0.658673, acc: 60.94%] [G loss: 2.154519]\n",
      "epoch:11 step:8848 [D loss: 1.290261, acc: 48.44%] [G loss: 1.421779]\n",
      "epoch:11 step:8849 [D loss: 0.538164, acc: 72.66%] [G loss: 2.483564]\n",
      "epoch:11 step:8850 [D loss: 0.671248, acc: 57.81%] [G loss: 1.633640]\n",
      "epoch:11 step:8851 [D loss: 0.590557, acc: 72.66%] [G loss: 2.147349]\n",
      "epoch:11 step:8852 [D loss: 0.535431, acc: 75.78%] [G loss: 2.614749]\n",
      "epoch:11 step:8853 [D loss: 1.049995, acc: 29.69%] [G loss: 2.322923]\n",
      "epoch:11 step:8854 [D loss: 0.694848, acc: 57.81%] [G loss: 2.078482]\n",
      "epoch:11 step:8855 [D loss: 0.821931, acc: 37.50%] [G loss: 1.816461]\n",
      "epoch:11 step:8856 [D loss: 0.579941, acc: 75.00%] [G loss: 1.903595]\n",
      "epoch:11 step:8857 [D loss: 0.578205, acc: 66.41%] [G loss: 2.323762]\n",
      "epoch:11 step:8858 [D loss: 1.021590, acc: 45.31%] [G loss: 1.603103]\n",
      "epoch:11 step:8859 [D loss: 0.424688, acc: 82.81%] [G loss: 2.536152]\n",
      "epoch:11 step:8860 [D loss: 1.151802, acc: 29.69%] [G loss: 1.698872]\n",
      "epoch:11 step:8861 [D loss: 0.671775, acc: 60.94%] [G loss: 2.206555]\n",
      "epoch:11 step:8862 [D loss: 0.363441, acc: 92.19%] [G loss: 2.231251]\n",
      "epoch:11 step:8863 [D loss: 0.385296, acc: 91.41%] [G loss: 2.910452]\n",
      "epoch:11 step:8864 [D loss: 0.466513, acc: 82.81%] [G loss: 1.957021]\n",
      "epoch:11 step:8865 [D loss: 0.292341, acc: 95.31%] [G loss: 2.803333]\n",
      "epoch:11 step:8866 [D loss: 0.469755, acc: 79.69%] [G loss: 2.256069]\n",
      "epoch:11 step:8867 [D loss: 0.239295, acc: 98.44%] [G loss: 2.572782]\n",
      "epoch:11 step:8868 [D loss: 0.736899, acc: 54.69%] [G loss: 1.716599]\n",
      "epoch:11 step:8869 [D loss: 0.676877, acc: 61.72%] [G loss: 1.987351]\n",
      "epoch:11 step:8870 [D loss: 0.626160, acc: 62.50%] [G loss: 1.787915]\n",
      "epoch:11 step:8871 [D loss: 0.490466, acc: 81.25%] [G loss: 1.957860]\n",
      "epoch:11 step:8872 [D loss: 0.418118, acc: 91.41%] [G loss: 2.706145]\n",
      "epoch:11 step:8873 [D loss: 0.891859, acc: 38.28%] [G loss: 1.777536]\n",
      "epoch:11 step:8874 [D loss: 0.451163, acc: 86.72%] [G loss: 2.881043]\n",
      "epoch:11 step:8875 [D loss: 0.294654, acc: 89.84%] [G loss: 2.723876]\n",
      "epoch:11 step:8876 [D loss: 0.383584, acc: 91.41%] [G loss: 2.515983]\n",
      "epoch:11 step:8877 [D loss: 0.713622, acc: 52.34%] [G loss: 2.599049]\n",
      "epoch:11 step:8878 [D loss: 0.700469, acc: 53.91%] [G loss: 1.974140]\n",
      "epoch:11 step:8879 [D loss: 0.699176, acc: 54.69%] [G loss: 1.940217]\n",
      "epoch:11 step:8880 [D loss: 0.876839, acc: 44.53%] [G loss: 1.878948]\n",
      "epoch:11 step:8881 [D loss: 0.568469, acc: 68.75%] [G loss: 2.355086]\n",
      "epoch:11 step:8882 [D loss: 1.262792, acc: 47.66%] [G loss: 1.402777]\n",
      "epoch:11 step:8883 [D loss: 0.761389, acc: 48.44%] [G loss: 2.161938]\n",
      "epoch:11 step:8884 [D loss: 0.426394, acc: 92.19%] [G loss: 2.170346]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:11 step:8885 [D loss: 0.710585, acc: 53.91%] [G loss: 1.970363]\n",
      "epoch:11 step:8886 [D loss: 0.760305, acc: 49.22%] [G loss: 1.897583]\n",
      "epoch:11 step:8887 [D loss: 0.582635, acc: 72.66%] [G loss: 2.163790]\n",
      "epoch:11 step:8888 [D loss: 0.710885, acc: 55.47%] [G loss: 1.908465]\n",
      "epoch:11 step:8889 [D loss: 0.722405, acc: 50.00%] [G loss: 2.206630]\n",
      "epoch:11 step:8890 [D loss: 0.649358, acc: 60.94%] [G loss: 1.963208]\n",
      "epoch:11 step:8891 [D loss: 0.589668, acc: 76.56%] [G loss: 1.951297]\n",
      "epoch:11 step:8892 [D loss: 0.626113, acc: 64.84%] [G loss: 1.880808]\n",
      "epoch:11 step:8893 [D loss: 0.600973, acc: 67.97%] [G loss: 2.308196]\n",
      "epoch:11 step:8894 [D loss: 0.667678, acc: 57.81%] [G loss: 2.011994]\n",
      "epoch:11 step:8895 [D loss: 0.484889, acc: 80.47%] [G loss: 2.112442]\n",
      "epoch:11 step:8896 [D loss: 0.522646, acc: 80.47%] [G loss: 2.252484]\n",
      "epoch:11 step:8897 [D loss: 0.408226, acc: 93.75%] [G loss: 2.297743]\n",
      "epoch:11 step:8898 [D loss: 0.508246, acc: 77.34%] [G loss: 2.024318]\n",
      "epoch:11 step:8899 [D loss: 0.220975, acc: 99.22%] [G loss: 2.276728]\n",
      "epoch:11 step:8900 [D loss: 0.568585, acc: 64.06%] [G loss: 2.410813]\n",
      "epoch:11 step:8901 [D loss: 0.308447, acc: 92.19%] [G loss: 1.855277]\n",
      "epoch:11 step:8902 [D loss: 0.301982, acc: 94.53%] [G loss: 2.222666]\n",
      "epoch:11 step:8903 [D loss: 0.579015, acc: 62.50%] [G loss: 2.278161]\n",
      "epoch:11 step:8904 [D loss: 0.636754, acc: 57.81%] [G loss: 2.061317]\n",
      "epoch:11 step:8905 [D loss: 0.802672, acc: 49.22%] [G loss: 2.087337]\n",
      "epoch:11 step:8906 [D loss: 0.693693, acc: 51.56%] [G loss: 2.218871]\n",
      "epoch:11 step:8907 [D loss: 0.475043, acc: 80.47%] [G loss: 2.263947]\n",
      "epoch:11 step:8908 [D loss: 0.245225, acc: 96.09%] [G loss: 2.555536]\n",
      "epoch:11 step:8909 [D loss: 0.710580, acc: 55.47%] [G loss: 1.925696]\n",
      "epoch:11 step:8910 [D loss: 0.638852, acc: 64.84%] [G loss: 1.915138]\n",
      "epoch:11 step:8911 [D loss: 0.826071, acc: 34.38%] [G loss: 2.249338]\n",
      "epoch:11 step:8912 [D loss: 0.381417, acc: 86.72%] [G loss: 2.566424]\n",
      "epoch:11 step:8913 [D loss: 0.403922, acc: 91.41%] [G loss: 2.517466]\n",
      "epoch:11 step:8914 [D loss: 0.769790, acc: 55.47%] [G loss: 2.568132]\n",
      "epoch:11 step:8915 [D loss: 0.416453, acc: 85.94%] [G loss: 1.889115]\n",
      "epoch:11 step:8916 [D loss: 0.501028, acc: 82.03%] [G loss: 1.962351]\n",
      "epoch:11 step:8917 [D loss: 0.636259, acc: 61.72%] [G loss: 1.971059]\n",
      "epoch:11 step:8918 [D loss: 0.590759, acc: 73.44%] [G loss: 1.765686]\n",
      "epoch:11 step:8919 [D loss: 0.541970, acc: 75.00%] [G loss: 2.181221]\n",
      "epoch:11 step:8920 [D loss: 0.870349, acc: 34.38%] [G loss: 1.937384]\n",
      "epoch:11 step:8921 [D loss: 0.777732, acc: 53.12%] [G loss: 1.977381]\n",
      "epoch:11 step:8922 [D loss: 0.465679, acc: 85.94%] [G loss: 2.431885]\n",
      "epoch:11 step:8923 [D loss: 0.647609, acc: 62.50%] [G loss: 2.118057]\n",
      "epoch:11 step:8924 [D loss: 0.682162, acc: 52.34%] [G loss: 2.045642]\n",
      "epoch:11 step:8925 [D loss: 0.589887, acc: 62.50%] [G loss: 2.487112]\n",
      "epoch:11 step:8926 [D loss: 0.571538, acc: 71.88%] [G loss: 2.123598]\n",
      "epoch:11 step:8927 [D loss: 0.393044, acc: 89.06%] [G loss: 1.949287]\n",
      "epoch:11 step:8928 [D loss: 0.964963, acc: 24.22%] [G loss: 1.618038]\n",
      "epoch:11 step:8929 [D loss: 0.765314, acc: 45.31%] [G loss: 2.081769]\n",
      "epoch:11 step:8930 [D loss: 0.487243, acc: 79.69%] [G loss: 1.993945]\n",
      "epoch:11 step:8931 [D loss: 0.753605, acc: 52.34%] [G loss: 1.813790]\n",
      "epoch:11 step:8932 [D loss: 0.633949, acc: 64.06%] [G loss: 1.884645]\n",
      "epoch:11 step:8933 [D loss: 0.483731, acc: 78.12%] [G loss: 2.323450]\n",
      "epoch:11 step:8934 [D loss: 0.793401, acc: 54.69%] [G loss: 1.494366]\n",
      "epoch:11 step:8935 [D loss: 0.998722, acc: 42.97%] [G loss: 1.962857]\n",
      "epoch:11 step:8936 [D loss: 0.772502, acc: 43.75%] [G loss: 1.726452]\n",
      "epoch:11 step:8937 [D loss: 0.636972, acc: 60.94%] [G loss: 2.013939]\n",
      "epoch:11 step:8938 [D loss: 0.470445, acc: 84.38%] [G loss: 1.874699]\n",
      "epoch:11 step:8939 [D loss: 0.463904, acc: 85.94%] [G loss: 1.887936]\n",
      "epoch:11 step:8940 [D loss: 0.594519, acc: 74.22%] [G loss: 2.070415]\n",
      "epoch:11 step:8941 [D loss: 0.671046, acc: 58.59%] [G loss: 2.344447]\n",
      "epoch:11 step:8942 [D loss: 0.714904, acc: 58.59%] [G loss: 1.875184]\n",
      "epoch:11 step:8943 [D loss: 0.396560, acc: 89.06%] [G loss: 2.608525]\n",
      "epoch:11 step:8944 [D loss: 0.318608, acc: 96.09%] [G loss: 2.374844]\n",
      "epoch:11 step:8945 [D loss: 0.746892, acc: 50.00%] [G loss: 2.026724]\n",
      "epoch:11 step:8946 [D loss: 0.744785, acc: 42.97%] [G loss: 1.959357]\n",
      "epoch:11 step:8947 [D loss: 0.544664, acc: 78.91%] [G loss: 1.726730]\n",
      "epoch:11 step:8948 [D loss: 0.674426, acc: 57.81%] [G loss: 2.136673]\n",
      "epoch:11 step:8949 [D loss: 0.806018, acc: 42.19%] [G loss: 1.707737]\n",
      "epoch:11 step:8950 [D loss: 0.455130, acc: 76.56%] [G loss: 2.531794]\n",
      "epoch:11 step:8951 [D loss: 0.539828, acc: 78.12%] [G loss: 2.296196]\n",
      "epoch:11 step:8952 [D loss: 0.513434, acc: 80.47%] [G loss: 2.144061]\n",
      "epoch:11 step:8953 [D loss: 0.808067, acc: 46.09%] [G loss: 2.318795]\n",
      "epoch:11 step:8954 [D loss: 0.318443, acc: 93.75%] [G loss: 2.174861]\n",
      "epoch:11 step:8955 [D loss: 0.743533, acc: 53.91%] [G loss: 2.294971]\n",
      "epoch:11 step:8956 [D loss: 0.560567, acc: 73.44%] [G loss: 2.162294]\n",
      "epoch:11 step:8957 [D loss: 1.217717, acc: 17.97%] [G loss: 1.824831]\n",
      "epoch:11 step:8958 [D loss: 0.671306, acc: 59.38%] [G loss: 2.113237]\n",
      "epoch:11 step:8959 [D loss: 0.629933, acc: 64.06%] [G loss: 2.128208]\n",
      "epoch:11 step:8960 [D loss: 0.645135, acc: 63.28%] [G loss: 2.308949]\n",
      "epoch:11 step:8961 [D loss: 0.760938, acc: 52.34%] [G loss: 1.994585]\n",
      "epoch:11 step:8962 [D loss: 0.269674, acc: 96.09%] [G loss: 2.554456]\n",
      "epoch:11 step:8963 [D loss: 0.520245, acc: 74.22%] [G loss: 2.009527]\n",
      "epoch:11 step:8964 [D loss: 1.193251, acc: 14.84%] [G loss: 1.532094]\n",
      "epoch:11 step:8965 [D loss: 0.153882, acc: 100.00%] [G loss: 2.650356]\n",
      "epoch:11 step:8966 [D loss: 0.624055, acc: 64.06%] [G loss: 2.111509]\n",
      "epoch:11 step:8967 [D loss: 0.537479, acc: 68.75%] [G loss: 2.092170]\n",
      "epoch:11 step:8968 [D loss: 0.616054, acc: 68.75%] [G loss: 2.163525]\n",
      "epoch:11 step:8969 [D loss: 0.654882, acc: 58.59%] [G loss: 1.760195]\n",
      "epoch:11 step:8970 [D loss: 0.982157, acc: 35.16%] [G loss: 1.932041]\n",
      "epoch:11 step:8971 [D loss: 0.611018, acc: 69.53%] [G loss: 2.179762]\n",
      "epoch:11 step:8972 [D loss: 0.454001, acc: 84.38%] [G loss: 1.898511]\n",
      "epoch:11 step:8973 [D loss: 0.440260, acc: 87.50%] [G loss: 2.388267]\n",
      "epoch:11 step:8974 [D loss: 0.363642, acc: 82.81%] [G loss: 3.468055]\n",
      "epoch:11 step:8975 [D loss: 0.470020, acc: 82.81%] [G loss: 2.303916]\n",
      "epoch:11 step:8976 [D loss: 0.488450, acc: 83.59%] [G loss: 2.781501]\n",
      "epoch:11 step:8977 [D loss: 0.831492, acc: 36.72%] [G loss: 2.143868]\n",
      "epoch:11 step:8978 [D loss: 0.870626, acc: 46.09%] [G loss: 1.630428]\n",
      "epoch:11 step:8979 [D loss: 0.645932, acc: 61.72%] [G loss: 2.019647]\n",
      "epoch:11 step:8980 [D loss: 0.511160, acc: 81.25%] [G loss: 1.878460]\n",
      "epoch:11 step:8981 [D loss: 0.388872, acc: 86.72%] [G loss: 2.439199]\n",
      "epoch:11 step:8982 [D loss: 0.883217, acc: 42.19%] [G loss: 1.816497]\n",
      "epoch:11 step:8983 [D loss: 0.576170, acc: 70.31%] [G loss: 2.050158]\n",
      "epoch:11 step:8984 [D loss: 0.530686, acc: 73.44%] [G loss: 2.689854]\n",
      "epoch:11 step:8985 [D loss: 0.394327, acc: 90.62%] [G loss: 2.755569]\n",
      "epoch:11 step:8986 [D loss: 0.285178, acc: 93.75%] [G loss: 2.913032]\n",
      "epoch:11 step:8987 [D loss: 0.319346, acc: 95.31%] [G loss: 2.568606]\n",
      "epoch:11 step:8988 [D loss: 0.718945, acc: 55.47%] [G loss: 2.128984]\n",
      "epoch:11 step:8989 [D loss: 0.414378, acc: 89.06%] [G loss: 3.198806]\n",
      "epoch:11 step:8990 [D loss: 0.731563, acc: 51.56%] [G loss: 2.136368]\n",
      "epoch:11 step:8991 [D loss: 0.358714, acc: 92.19%] [G loss: 2.430275]\n",
      "epoch:11 step:8992 [D loss: 0.851180, acc: 36.72%] [G loss: 2.180956]\n",
      "epoch:11 step:8993 [D loss: 0.547318, acc: 79.69%] [G loss: 2.458213]\n",
      "epoch:11 step:8994 [D loss: 0.450447, acc: 82.03%] [G loss: 2.433037]\n",
      "epoch:11 step:8995 [D loss: 0.492835, acc: 85.94%] [G loss: 2.396357]\n",
      "epoch:11 step:8996 [D loss: 0.576022, acc: 66.41%] [G loss: 2.853024]\n",
      "epoch:11 step:8997 [D loss: 0.548556, acc: 71.88%] [G loss: 2.425156]\n",
      "epoch:11 step:8998 [D loss: 0.406568, acc: 91.41%] [G loss: 1.996305]\n",
      "epoch:11 step:8999 [D loss: 0.392833, acc: 91.41%] [G loss: 2.893576]\n",
      "epoch:11 step:9000 [D loss: 0.363450, acc: 90.62%] [G loss: 2.785047]\n",
      "##############\n",
      "[0.85729281 0.87539857 0.82280744 0.8298175  0.81294791 0.8367647\n",
      " 0.87185691 0.81944197 0.79874485 0.84806072]\n",
      "##########\n",
      "epoch:11 step:9001 [D loss: 0.375477, acc: 92.97%] [G loss: 3.057302]\n",
      "epoch:11 step:9002 [D loss: 0.510911, acc: 78.91%] [G loss: 2.487519]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:11 step:9003 [D loss: 0.658861, acc: 60.16%] [G loss: 1.960627]\n",
      "epoch:11 step:9004 [D loss: 0.754702, acc: 50.00%] [G loss: 2.009346]\n",
      "epoch:11 step:9005 [D loss: 0.350173, acc: 83.59%] [G loss: 2.506187]\n",
      "epoch:11 step:9006 [D loss: 0.349764, acc: 90.62%] [G loss: 2.117164]\n",
      "epoch:11 step:9007 [D loss: 0.776722, acc: 53.91%] [G loss: 2.264102]\n",
      "epoch:11 step:9008 [D loss: 0.491765, acc: 79.69%] [G loss: 2.633524]\n",
      "epoch:11 step:9009 [D loss: 0.462131, acc: 67.97%] [G loss: 2.734662]\n",
      "epoch:11 step:9010 [D loss: 0.331742, acc: 92.97%] [G loss: 2.343065]\n",
      "epoch:11 step:9011 [D loss: 0.697587, acc: 53.91%] [G loss: 2.575371]\n",
      "epoch:11 step:9012 [D loss: 0.630825, acc: 60.94%] [G loss: 2.654927]\n",
      "epoch:11 step:9013 [D loss: 0.482192, acc: 85.16%] [G loss: 2.242911]\n",
      "epoch:11 step:9014 [D loss: 0.708507, acc: 53.91%] [G loss: 3.436360]\n",
      "epoch:11 step:9015 [D loss: 0.431973, acc: 85.16%] [G loss: 4.048608]\n",
      "epoch:11 step:9016 [D loss: 0.887631, acc: 52.34%] [G loss: 2.517383]\n",
      "epoch:11 step:9017 [D loss: 0.530559, acc: 77.34%] [G loss: 2.334551]\n",
      "epoch:11 step:9018 [D loss: 0.488342, acc: 76.56%] [G loss: 2.075803]\n",
      "epoch:11 step:9019 [D loss: 1.021388, acc: 23.44%] [G loss: 2.499320]\n",
      "epoch:11 step:9020 [D loss: 0.665624, acc: 58.59%] [G loss: 2.331036]\n",
      "epoch:11 step:9021 [D loss: 0.505075, acc: 81.25%] [G loss: 2.182068]\n",
      "epoch:11 step:9022 [D loss: 0.529646, acc: 75.78%] [G loss: 2.125281]\n",
      "epoch:11 step:9023 [D loss: 0.589278, acc: 60.16%] [G loss: 2.488647]\n",
      "epoch:11 step:9024 [D loss: 0.800877, acc: 42.19%] [G loss: 2.599322]\n",
      "epoch:11 step:9025 [D loss: 0.688236, acc: 60.16%] [G loss: 2.501766]\n",
      "epoch:11 step:9026 [D loss: 0.800491, acc: 36.72%] [G loss: 1.929167]\n",
      "epoch:11 step:9027 [D loss: 0.830726, acc: 41.41%] [G loss: 1.893519]\n",
      "epoch:11 step:9028 [D loss: 0.558070, acc: 71.88%] [G loss: 2.093962]\n",
      "epoch:11 step:9029 [D loss: 0.605177, acc: 68.75%] [G loss: 2.497715]\n",
      "epoch:11 step:9030 [D loss: 0.299692, acc: 95.31%] [G loss: 2.263339]\n",
      "epoch:11 step:9031 [D loss: 0.765411, acc: 53.12%] [G loss: 1.897823]\n",
      "epoch:11 step:9032 [D loss: 0.405194, acc: 87.50%] [G loss: 2.334192]\n",
      "epoch:11 step:9033 [D loss: 0.562350, acc: 77.34%] [G loss: 2.725478]\n",
      "epoch:11 step:9034 [D loss: 0.632898, acc: 63.28%] [G loss: 2.251776]\n",
      "epoch:11 step:9035 [D loss: 0.713193, acc: 53.12%] [G loss: 1.877696]\n",
      "epoch:11 step:9036 [D loss: 0.678066, acc: 46.09%] [G loss: 2.166755]\n",
      "epoch:11 step:9037 [D loss: 0.419862, acc: 88.28%] [G loss: 2.022368]\n",
      "epoch:11 step:9038 [D loss: 0.634284, acc: 67.19%] [G loss: 2.360141]\n",
      "epoch:11 step:9039 [D loss: 0.316699, acc: 94.53%] [G loss: 3.062928]\n",
      "epoch:11 step:9040 [D loss: 0.646143, acc: 64.84%] [G loss: 2.590661]\n",
      "epoch:11 step:9041 [D loss: 0.401208, acc: 92.19%] [G loss: 2.118464]\n",
      "epoch:11 step:9042 [D loss: 0.389699, acc: 89.84%] [G loss: 2.778410]\n",
      "epoch:11 step:9043 [D loss: 0.505858, acc: 86.72%] [G loss: 2.076347]\n",
      "epoch:11 step:9044 [D loss: 0.530866, acc: 69.53%] [G loss: 1.859181]\n",
      "epoch:11 step:9045 [D loss: 0.615939, acc: 66.41%] [G loss: 2.268825]\n",
      "epoch:11 step:9046 [D loss: 0.388634, acc: 87.50%] [G loss: 2.330959]\n",
      "epoch:11 step:9047 [D loss: 0.835170, acc: 46.88%] [G loss: 1.939718]\n",
      "epoch:11 step:9048 [D loss: 0.693113, acc: 57.03%] [G loss: 1.602361]\n",
      "epoch:11 step:9049 [D loss: 0.693385, acc: 60.94%] [G loss: 1.969231]\n",
      "epoch:11 step:9050 [D loss: 0.687570, acc: 58.59%] [G loss: 2.127332]\n",
      "epoch:11 step:9051 [D loss: 0.469326, acc: 85.94%] [G loss: 2.724595]\n",
      "epoch:11 step:9052 [D loss: 0.760922, acc: 50.00%] [G loss: 1.904679]\n",
      "epoch:11 step:9053 [D loss: 0.686117, acc: 55.47%] [G loss: 2.223736]\n",
      "epoch:11 step:9054 [D loss: 0.882222, acc: 30.47%] [G loss: 1.823432]\n",
      "epoch:11 step:9055 [D loss: 0.519466, acc: 77.34%] [G loss: 1.964789]\n",
      "epoch:11 step:9056 [D loss: 0.441636, acc: 87.50%] [G loss: 2.139635]\n",
      "epoch:11 step:9057 [D loss: 0.507834, acc: 82.03%] [G loss: 2.454591]\n",
      "epoch:11 step:9058 [D loss: 0.626054, acc: 58.59%] [G loss: 2.242961]\n",
      "epoch:11 step:9059 [D loss: 0.575252, acc: 71.88%] [G loss: 2.174499]\n",
      "epoch:11 step:9060 [D loss: 0.513186, acc: 77.34%] [G loss: 1.571821]\n",
      "epoch:11 step:9061 [D loss: 0.828533, acc: 48.44%] [G loss: 1.848690]\n",
      "epoch:11 step:9062 [D loss: 0.437612, acc: 85.94%] [G loss: 3.049850]\n",
      "epoch:11 step:9063 [D loss: 0.357860, acc: 94.53%] [G loss: 2.551796]\n",
      "epoch:11 step:9064 [D loss: 1.023238, acc: 24.22%] [G loss: 1.738831]\n",
      "epoch:11 step:9065 [D loss: 0.660261, acc: 59.38%] [G loss: 2.149733]\n",
      "epoch:11 step:9066 [D loss: 0.317993, acc: 93.75%] [G loss: 2.347741]\n",
      "epoch:11 step:9067 [D loss: 0.412439, acc: 86.72%] [G loss: 2.550485]\n",
      "epoch:11 step:9068 [D loss: 0.305588, acc: 94.53%] [G loss: 2.154264]\n",
      "epoch:11 step:9069 [D loss: 0.667160, acc: 59.38%] [G loss: 2.237560]\n",
      "epoch:11 step:9070 [D loss: 0.766710, acc: 46.88%] [G loss: 2.007945]\n",
      "epoch:11 step:9071 [D loss: 0.904663, acc: 33.59%] [G loss: 1.676582]\n",
      "epoch:11 step:9072 [D loss: 0.838704, acc: 35.94%] [G loss: 1.938909]\n",
      "epoch:11 step:9073 [D loss: 1.516923, acc: 7.03%] [G loss: 1.519852]\n",
      "epoch:11 step:9074 [D loss: 0.505301, acc: 78.91%] [G loss: 1.951096]\n",
      "epoch:11 step:9075 [D loss: 0.644398, acc: 61.72%] [G loss: 2.792029]\n",
      "epoch:11 step:9076 [D loss: 0.549138, acc: 67.19%] [G loss: 1.911653]\n",
      "epoch:11 step:9077 [D loss: 0.613545, acc: 68.75%] [G loss: 2.246632]\n",
      "epoch:11 step:9078 [D loss: 0.652643, acc: 57.81%] [G loss: 2.724171]\n",
      "epoch:11 step:9079 [D loss: 0.375941, acc: 95.31%] [G loss: 2.482418]\n",
      "epoch:11 step:9080 [D loss: 0.444866, acc: 87.50%] [G loss: 2.435613]\n",
      "epoch:11 step:9081 [D loss: 0.857394, acc: 50.78%] [G loss: 1.788295]\n",
      "epoch:11 step:9082 [D loss: 0.469006, acc: 81.25%] [G loss: 2.314641]\n",
      "epoch:11 step:9083 [D loss: 0.759663, acc: 47.66%] [G loss: 2.257170]\n",
      "epoch:11 step:9084 [D loss: 0.597200, acc: 68.75%] [G loss: 2.344267]\n",
      "epoch:11 step:9085 [D loss: 0.491011, acc: 80.47%] [G loss: 2.748342]\n",
      "epoch:11 step:9086 [D loss: 0.524355, acc: 78.91%] [G loss: 2.130027]\n",
      "epoch:11 step:9087 [D loss: 0.680365, acc: 62.50%] [G loss: 1.774645]\n",
      "epoch:11 step:9088 [D loss: 0.659695, acc: 60.94%] [G loss: 2.211729]\n",
      "epoch:11 step:9089 [D loss: 0.752506, acc: 50.78%] [G loss: 2.444005]\n",
      "epoch:11 step:9090 [D loss: 0.793251, acc: 38.28%] [G loss: 2.272100]\n",
      "epoch:11 step:9091 [D loss: 0.589189, acc: 69.53%] [G loss: 2.083666]\n",
      "epoch:11 step:9092 [D loss: 0.646897, acc: 62.50%] [G loss: 2.221074]\n",
      "epoch:11 step:9093 [D loss: 0.803317, acc: 42.19%] [G loss: 1.755614]\n",
      "epoch:11 step:9094 [D loss: 0.685928, acc: 63.28%] [G loss: 2.521939]\n",
      "epoch:11 step:9095 [D loss: 0.597108, acc: 67.97%] [G loss: 2.282832]\n",
      "epoch:11 step:9096 [D loss: 0.655651, acc: 57.03%] [G loss: 1.559945]\n",
      "epoch:11 step:9097 [D loss: 0.607661, acc: 74.22%] [G loss: 2.095039]\n",
      "epoch:11 step:9098 [D loss: 0.563675, acc: 64.84%] [G loss: 1.987675]\n",
      "epoch:11 step:9099 [D loss: 0.930499, acc: 31.25%] [G loss: 1.937656]\n",
      "epoch:11 step:9100 [D loss: 0.535576, acc: 75.78%] [G loss: 2.447095]\n",
      "epoch:11 step:9101 [D loss: 0.314710, acc: 92.97%] [G loss: 2.334464]\n",
      "epoch:11 step:9102 [D loss: 0.902543, acc: 42.97%] [G loss: 2.106062]\n",
      "epoch:11 step:9103 [D loss: 0.843012, acc: 45.31%] [G loss: 1.518437]\n",
      "epoch:11 step:9104 [D loss: 0.394946, acc: 92.97%] [G loss: 2.543075]\n",
      "epoch:11 step:9105 [D loss: 0.832552, acc: 50.00%] [G loss: 1.887742]\n",
      "epoch:11 step:9106 [D loss: 0.668926, acc: 59.38%] [G loss: 1.954906]\n",
      "epoch:11 step:9107 [D loss: 0.871689, acc: 28.91%] [G loss: 2.174707]\n",
      "epoch:11 step:9108 [D loss: 0.657135, acc: 60.94%] [G loss: 2.257326]\n",
      "epoch:11 step:9109 [D loss: 0.497921, acc: 66.41%] [G loss: 2.186652]\n",
      "epoch:11 step:9110 [D loss: 0.818949, acc: 40.62%] [G loss: 1.869652]\n",
      "epoch:11 step:9111 [D loss: 0.504136, acc: 74.22%] [G loss: 2.906889]\n",
      "epoch:11 step:9112 [D loss: 0.398660, acc: 87.50%] [G loss: 1.990132]\n",
      "epoch:11 step:9113 [D loss: 0.820602, acc: 34.38%] [G loss: 1.670027]\n",
      "epoch:11 step:9114 [D loss: 0.620531, acc: 61.72%] [G loss: 2.227107]\n",
      "epoch:11 step:9115 [D loss: 0.613295, acc: 67.97%] [G loss: 2.362444]\n",
      "epoch:11 step:9116 [D loss: 0.698790, acc: 57.81%] [G loss: 2.112628]\n",
      "epoch:11 step:9117 [D loss: 0.943141, acc: 44.53%] [G loss: 1.653255]\n",
      "epoch:11 step:9118 [D loss: 0.665579, acc: 60.16%] [G loss: 2.362079]\n",
      "epoch:11 step:9119 [D loss: 0.588248, acc: 70.31%] [G loss: 2.139135]\n",
      "epoch:11 step:9120 [D loss: 0.797462, acc: 51.56%] [G loss: 1.845386]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:11 step:9121 [D loss: 0.619741, acc: 68.75%] [G loss: 2.294449]\n",
      "epoch:11 step:9122 [D loss: 0.671223, acc: 54.69%] [G loss: 2.146377]\n",
      "epoch:11 step:9123 [D loss: 0.667348, acc: 60.16%] [G loss: 2.335224]\n",
      "epoch:11 step:9124 [D loss: 0.451369, acc: 75.78%] [G loss: 2.841887]\n",
      "epoch:11 step:9125 [D loss: 0.704253, acc: 53.91%] [G loss: 1.958395]\n",
      "epoch:11 step:9126 [D loss: 0.484361, acc: 85.16%] [G loss: 1.805859]\n",
      "epoch:11 step:9127 [D loss: 0.417441, acc: 92.97%] [G loss: 2.641160]\n",
      "epoch:11 step:9128 [D loss: 0.395085, acc: 92.19%] [G loss: 2.782567]\n",
      "epoch:11 step:9129 [D loss: 0.417568, acc: 89.06%] [G loss: 2.368861]\n",
      "epoch:11 step:9130 [D loss: 0.572422, acc: 71.09%] [G loss: 2.142328]\n",
      "epoch:11 step:9131 [D loss: 0.828317, acc: 47.66%] [G loss: 2.058150]\n",
      "epoch:11 step:9132 [D loss: 0.338965, acc: 96.88%] [G loss: 2.636256]\n",
      "epoch:11 step:9133 [D loss: 0.425603, acc: 84.38%] [G loss: 2.540687]\n",
      "epoch:11 step:9134 [D loss: 0.452098, acc: 84.38%] [G loss: 1.958667]\n",
      "epoch:11 step:9135 [D loss: 0.750932, acc: 49.22%] [G loss: 1.701825]\n",
      "epoch:11 step:9136 [D loss: 0.765911, acc: 53.91%] [G loss: 2.589872]\n",
      "epoch:11 step:9137 [D loss: 0.947935, acc: 26.56%] [G loss: 1.749570]\n",
      "epoch:11 step:9138 [D loss: 0.358079, acc: 90.62%] [G loss: 2.339783]\n",
      "epoch:11 step:9139 [D loss: 0.578083, acc: 68.75%] [G loss: 2.150939]\n",
      "epoch:11 step:9140 [D loss: 0.562351, acc: 67.97%] [G loss: 1.965156]\n",
      "epoch:11 step:9141 [D loss: 0.328157, acc: 97.66%] [G loss: 2.725181]\n",
      "epoch:11 step:9142 [D loss: 0.690699, acc: 54.69%] [G loss: 1.877109]\n",
      "epoch:11 step:9143 [D loss: 1.010324, acc: 43.75%] [G loss: 1.864495]\n",
      "epoch:11 step:9144 [D loss: 0.566834, acc: 69.53%] [G loss: 1.533268]\n",
      "epoch:11 step:9145 [D loss: 0.309237, acc: 97.66%] [G loss: 2.261486]\n",
      "epoch:11 step:9146 [D loss: 0.646378, acc: 61.72%] [G loss: 1.747311]\n",
      "epoch:11 step:9147 [D loss: 0.492376, acc: 82.81%] [G loss: 1.947559]\n",
      "epoch:11 step:9148 [D loss: 0.484055, acc: 77.34%] [G loss: 2.147366]\n",
      "epoch:11 step:9149 [D loss: 0.432204, acc: 88.28%] [G loss: 2.417344]\n",
      "epoch:11 step:9150 [D loss: 0.509665, acc: 78.12%] [G loss: 2.698144]\n",
      "epoch:11 step:9151 [D loss: 0.481561, acc: 84.38%] [G loss: 2.275709]\n",
      "epoch:11 step:9152 [D loss: 0.640674, acc: 57.81%] [G loss: 2.234595]\n",
      "epoch:11 step:9153 [D loss: 0.302897, acc: 85.16%] [G loss: 2.988601]\n",
      "epoch:11 step:9154 [D loss: 0.414643, acc: 78.12%] [G loss: 2.410173]\n",
      "epoch:11 step:9155 [D loss: 0.825471, acc: 53.12%] [G loss: 1.890184]\n",
      "epoch:11 step:9156 [D loss: 0.508578, acc: 84.38%] [G loss: 1.931777]\n",
      "epoch:11 step:9157 [D loss: 0.492585, acc: 78.91%] [G loss: 1.995768]\n",
      "epoch:11 step:9158 [D loss: 0.661321, acc: 57.81%] [G loss: 1.830096]\n",
      "epoch:11 step:9159 [D loss: 0.325280, acc: 96.88%] [G loss: 3.854715]\n",
      "epoch:11 step:9160 [D loss: 0.573607, acc: 70.31%] [G loss: 2.083466]\n",
      "epoch:11 step:9161 [D loss: 0.232742, acc: 96.09%] [G loss: 3.308858]\n",
      "epoch:11 step:9162 [D loss: 0.776978, acc: 46.09%] [G loss: 1.762233]\n",
      "epoch:11 step:9163 [D loss: 0.289812, acc: 96.88%] [G loss: 2.601115]\n",
      "epoch:11 step:9164 [D loss: 0.636016, acc: 60.94%] [G loss: 1.651357]\n",
      "epoch:11 step:9165 [D loss: 0.517038, acc: 78.12%] [G loss: 2.183027]\n",
      "epoch:11 step:9166 [D loss: 0.261185, acc: 97.66%] [G loss: 2.712782]\n",
      "epoch:11 step:9167 [D loss: 0.382555, acc: 78.91%] [G loss: 2.659065]\n",
      "epoch:11 step:9168 [D loss: 0.648831, acc: 58.59%] [G loss: 2.392631]\n",
      "epoch:11 step:9169 [D loss: 0.696208, acc: 59.38%] [G loss: 2.270819]\n",
      "epoch:11 step:9170 [D loss: 0.436094, acc: 85.16%] [G loss: 2.090295]\n",
      "epoch:11 step:9171 [D loss: 0.845162, acc: 35.16%] [G loss: 1.764385]\n",
      "epoch:11 step:9172 [D loss: 0.544607, acc: 75.78%] [G loss: 3.002588]\n",
      "epoch:11 step:9173 [D loss: 0.636575, acc: 61.72%] [G loss: 2.413286]\n",
      "epoch:11 step:9174 [D loss: 0.858804, acc: 47.66%] [G loss: 2.075857]\n",
      "epoch:11 step:9175 [D loss: 0.748077, acc: 55.47%] [G loss: 1.846776]\n",
      "epoch:11 step:9176 [D loss: 0.632152, acc: 57.81%] [G loss: 2.627422]\n",
      "epoch:11 step:9177 [D loss: 0.663916, acc: 62.50%] [G loss: 2.028354]\n",
      "epoch:11 step:9178 [D loss: 0.504624, acc: 81.25%] [G loss: 3.048147]\n",
      "epoch:11 step:9179 [D loss: 0.568819, acc: 67.19%] [G loss: 2.598680]\n",
      "epoch:11 step:9180 [D loss: 0.479819, acc: 75.00%] [G loss: 2.674918]\n",
      "epoch:11 step:9181 [D loss: 0.581691, acc: 66.41%] [G loss: 1.871442]\n",
      "epoch:11 step:9182 [D loss: 0.579826, acc: 66.41%] [G loss: 2.325198]\n",
      "epoch:11 step:9183 [D loss: 1.070710, acc: 19.53%] [G loss: 2.105773]\n",
      "epoch:11 step:9184 [D loss: 1.211247, acc: 14.06%] [G loss: 1.998504]\n",
      "epoch:11 step:9185 [D loss: 0.807566, acc: 42.19%] [G loss: 1.858174]\n",
      "epoch:11 step:9186 [D loss: 0.423613, acc: 86.72%] [G loss: 2.346168]\n",
      "epoch:11 step:9187 [D loss: 0.746846, acc: 49.22%] [G loss: 2.060925]\n",
      "epoch:11 step:9188 [D loss: 0.574809, acc: 67.19%] [G loss: 2.121251]\n",
      "epoch:11 step:9189 [D loss: 0.682040, acc: 55.47%] [G loss: 1.884464]\n",
      "epoch:11 step:9190 [D loss: 0.699309, acc: 57.81%] [G loss: 1.966181]\n",
      "epoch:11 step:9191 [D loss: 0.611134, acc: 65.62%] [G loss: 2.116940]\n",
      "epoch:11 step:9192 [D loss: 0.689239, acc: 57.81%] [G loss: 1.690664]\n",
      "epoch:11 step:9193 [D loss: 0.596792, acc: 71.88%] [G loss: 2.296019]\n",
      "epoch:11 step:9194 [D loss: 0.815970, acc: 51.56%] [G loss: 1.817904]\n",
      "epoch:11 step:9195 [D loss: 0.605263, acc: 67.97%] [G loss: 1.861729]\n",
      "epoch:11 step:9196 [D loss: 0.488036, acc: 82.03%] [G loss: 2.265636]\n",
      "epoch:11 step:9197 [D loss: 0.981104, acc: 19.53%] [G loss: 2.258668]\n",
      "epoch:11 step:9198 [D loss: 0.499527, acc: 71.09%] [G loss: 2.256578]\n",
      "epoch:11 step:9199 [D loss: 0.415603, acc: 92.19%] [G loss: 1.999586]\n",
      "epoch:11 step:9200 [D loss: 0.624325, acc: 67.19%] [G loss: 1.981345]\n",
      "##############\n",
      "[0.87054645 0.88914082 0.83293986 0.82436945 0.79020729 0.81670418\n",
      " 0.88704428 0.86026008 0.82508629 0.82000343]\n",
      "##########\n",
      "epoch:11 step:9201 [D loss: 0.773797, acc: 54.69%] [G loss: 1.602653]\n",
      "epoch:11 step:9202 [D loss: 0.912951, acc: 29.69%] [G loss: 1.470156]\n",
      "epoch:11 step:9203 [D loss: 0.753862, acc: 52.34%] [G loss: 1.857616]\n",
      "epoch:11 step:9204 [D loss: 0.745413, acc: 48.44%] [G loss: 1.964823]\n",
      "epoch:11 step:9205 [D loss: 1.125452, acc: 12.50%] [G loss: 1.197394]\n",
      "epoch:11 step:9206 [D loss: 0.671818, acc: 58.59%] [G loss: 2.396595]\n",
      "epoch:11 step:9207 [D loss: 0.561146, acc: 71.09%] [G loss: 1.980617]\n",
      "epoch:11 step:9208 [D loss: 0.816043, acc: 45.31%] [G loss: 1.934759]\n",
      "epoch:11 step:9209 [D loss: 0.562692, acc: 73.44%] [G loss: 1.737742]\n",
      "epoch:11 step:9210 [D loss: 0.768923, acc: 53.91%] [G loss: 2.808704]\n",
      "epoch:11 step:9211 [D loss: 0.442435, acc: 83.59%] [G loss: 2.108171]\n",
      "epoch:11 step:9212 [D loss: 0.529074, acc: 75.78%] [G loss: 2.278508]\n",
      "epoch:11 step:9213 [D loss: 0.642002, acc: 57.81%] [G loss: 2.154732]\n",
      "epoch:11 step:9214 [D loss: 0.651809, acc: 65.62%] [G loss: 2.198089]\n",
      "epoch:11 step:9215 [D loss: 0.556094, acc: 69.53%] [G loss: 2.399940]\n",
      "epoch:11 step:9216 [D loss: 0.802173, acc: 43.75%] [G loss: 2.133109]\n",
      "epoch:11 step:9217 [D loss: 0.543513, acc: 75.00%] [G loss: 1.902834]\n",
      "epoch:11 step:9218 [D loss: 0.602455, acc: 68.75%] [G loss: 2.531696]\n",
      "epoch:11 step:9219 [D loss: 0.481202, acc: 85.16%] [G loss: 1.935589]\n",
      "epoch:11 step:9220 [D loss: 0.453059, acc: 82.81%] [G loss: 2.640485]\n",
      "epoch:11 step:9221 [D loss: 0.738137, acc: 53.91%] [G loss: 1.606118]\n",
      "epoch:11 step:9222 [D loss: 0.339810, acc: 94.53%] [G loss: 3.337596]\n",
      "epoch:11 step:9223 [D loss: 0.594432, acc: 71.09%] [G loss: 1.920541]\n",
      "epoch:11 step:9224 [D loss: 0.861000, acc: 32.81%] [G loss: 2.356317]\n",
      "epoch:11 step:9225 [D loss: 0.689928, acc: 58.59%] [G loss: 1.914987]\n",
      "epoch:11 step:9226 [D loss: 0.483776, acc: 82.81%] [G loss: 2.115943]\n",
      "epoch:11 step:9227 [D loss: 0.617272, acc: 70.31%] [G loss: 2.471117]\n",
      "epoch:11 step:9228 [D loss: 0.552068, acc: 71.88%] [G loss: 2.201485]\n",
      "epoch:11 step:9229 [D loss: 0.498617, acc: 82.03%] [G loss: 2.525446]\n",
      "epoch:11 step:9230 [D loss: 0.974691, acc: 22.66%] [G loss: 1.882402]\n",
      "epoch:11 step:9231 [D loss: 0.664411, acc: 58.59%] [G loss: 2.089486]\n",
      "epoch:11 step:9232 [D loss: 0.616219, acc: 64.06%] [G loss: 2.073070]\n",
      "epoch:11 step:9233 [D loss: 0.737664, acc: 47.66%] [G loss: 1.766732]\n",
      "epoch:11 step:9234 [D loss: 0.548320, acc: 71.88%] [G loss: 2.015833]\n",
      "epoch:11 step:9235 [D loss: 0.335165, acc: 91.41%] [G loss: 2.852053]\n",
      "epoch:11 step:9236 [D loss: 0.525598, acc: 66.41%] [G loss: 2.367699]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:11 step:9237 [D loss: 1.433502, acc: 6.25%] [G loss: 1.717307]\n",
      "epoch:11 step:9238 [D loss: 0.771667, acc: 55.47%] [G loss: 1.780900]\n",
      "epoch:11 step:9239 [D loss: 0.779127, acc: 51.56%] [G loss: 2.311722]\n",
      "epoch:11 step:9240 [D loss: 0.649607, acc: 63.28%] [G loss: 1.940823]\n",
      "epoch:11 step:9241 [D loss: 0.457132, acc: 86.72%] [G loss: 2.600657]\n",
      "epoch:11 step:9242 [D loss: 0.804050, acc: 41.41%] [G loss: 2.016316]\n",
      "epoch:11 step:9243 [D loss: 0.551443, acc: 75.78%] [G loss: 2.636569]\n",
      "epoch:11 step:9244 [D loss: 0.348874, acc: 93.75%] [G loss: 2.219368]\n",
      "epoch:11 step:9245 [D loss: 0.536565, acc: 81.25%] [G loss: 3.415807]\n",
      "epoch:11 step:9246 [D loss: 0.430829, acc: 82.81%] [G loss: 2.358138]\n",
      "epoch:11 step:9247 [D loss: 0.505381, acc: 78.12%] [G loss: 1.851124]\n",
      "epoch:11 step:9248 [D loss: 0.530777, acc: 78.12%] [G loss: 2.375775]\n",
      "epoch:11 step:9249 [D loss: 0.312056, acc: 93.75%] [G loss: 2.426350]\n",
      "epoch:11 step:9250 [D loss: 0.902754, acc: 41.41%] [G loss: 1.612264]\n",
      "epoch:11 step:9251 [D loss: 0.491432, acc: 79.69%] [G loss: 1.774858]\n",
      "epoch:11 step:9252 [D loss: 0.978846, acc: 24.22%] [G loss: 1.287555]\n",
      "epoch:11 step:9253 [D loss: 0.516604, acc: 82.03%] [G loss: 2.762463]\n",
      "epoch:11 step:9254 [D loss: 0.401059, acc: 78.91%] [G loss: 2.447881]\n",
      "epoch:11 step:9255 [D loss: 0.480673, acc: 83.59%] [G loss: 2.177545]\n",
      "epoch:11 step:9256 [D loss: 0.797862, acc: 42.19%] [G loss: 1.944046]\n",
      "epoch:11 step:9257 [D loss: 0.481941, acc: 77.34%] [G loss: 2.775209]\n",
      "epoch:11 step:9258 [D loss: 0.347513, acc: 84.38%] [G loss: 3.305203]\n",
      "epoch:11 step:9259 [D loss: 0.560711, acc: 71.09%] [G loss: 2.131599]\n",
      "epoch:11 step:9260 [D loss: 0.787706, acc: 50.00%] [G loss: 2.857155]\n",
      "epoch:11 step:9261 [D loss: 0.507834, acc: 74.22%] [G loss: 2.282284]\n",
      "epoch:11 step:9262 [D loss: 0.592727, acc: 70.31%] [G loss: 1.670621]\n",
      "epoch:11 step:9263 [D loss: 0.933466, acc: 32.81%] [G loss: 1.782571]\n",
      "epoch:11 step:9264 [D loss: 0.438016, acc: 82.81%] [G loss: 1.877710]\n",
      "epoch:11 step:9265 [D loss: 0.492973, acc: 79.69%] [G loss: 1.762841]\n",
      "epoch:11 step:9266 [D loss: 0.557423, acc: 71.09%] [G loss: 2.351775]\n",
      "epoch:11 step:9267 [D loss: 0.894047, acc: 43.75%] [G loss: 1.901890]\n",
      "epoch:11 step:9268 [D loss: 0.467199, acc: 85.94%] [G loss: 2.919950]\n",
      "epoch:11 step:9269 [D loss: 0.468484, acc: 85.94%] [G loss: 2.026993]\n",
      "epoch:11 step:9270 [D loss: 0.500683, acc: 84.38%] [G loss: 2.430273]\n",
      "epoch:11 step:9271 [D loss: 0.506245, acc: 77.34%] [G loss: 2.231863]\n",
      "epoch:11 step:9272 [D loss: 0.530159, acc: 74.22%] [G loss: 2.185776]\n",
      "epoch:11 step:9273 [D loss: 0.544230, acc: 71.09%] [G loss: 2.666901]\n",
      "epoch:11 step:9274 [D loss: 0.498260, acc: 81.25%] [G loss: 2.344934]\n",
      "epoch:11 step:9275 [D loss: 0.416855, acc: 85.94%] [G loss: 2.306169]\n",
      "epoch:11 step:9276 [D loss: 0.419778, acc: 86.72%] [G loss: 2.801842]\n",
      "epoch:11 step:9277 [D loss: 0.735074, acc: 52.34%] [G loss: 2.797492]\n",
      "epoch:11 step:9278 [D loss: 0.752626, acc: 49.22%] [G loss: 2.444884]\n",
      "epoch:11 step:9279 [D loss: 0.622089, acc: 66.41%] [G loss: 2.472884]\n",
      "epoch:11 step:9280 [D loss: 0.682938, acc: 57.03%] [G loss: 1.993290]\n",
      "epoch:11 step:9281 [D loss: 0.507902, acc: 78.91%] [G loss: 2.543202]\n",
      "epoch:11 step:9282 [D loss: 0.438382, acc: 69.53%] [G loss: 2.609370]\n",
      "epoch:11 step:9283 [D loss: 1.077028, acc: 36.72%] [G loss: 1.971991]\n",
      "epoch:11 step:9284 [D loss: 0.374502, acc: 90.62%] [G loss: 2.274931]\n",
      "epoch:11 step:9285 [D loss: 0.622422, acc: 60.16%] [G loss: 1.995943]\n",
      "epoch:11 step:9286 [D loss: 0.375179, acc: 94.53%] [G loss: 2.142519]\n",
      "epoch:11 step:9287 [D loss: 0.429301, acc: 85.94%] [G loss: 2.250769]\n",
      "epoch:11 step:9288 [D loss: 0.809142, acc: 53.12%] [G loss: 1.543324]\n",
      "epoch:11 step:9289 [D loss: 0.825094, acc: 53.91%] [G loss: 1.987076]\n",
      "epoch:11 step:9290 [D loss: 0.619127, acc: 65.62%] [G loss: 2.667635]\n",
      "epoch:11 step:9291 [D loss: 0.664437, acc: 60.94%] [G loss: 2.403663]\n",
      "epoch:11 step:9292 [D loss: 0.518272, acc: 82.81%] [G loss: 2.825714]\n",
      "epoch:11 step:9293 [D loss: 0.641670, acc: 63.28%] [G loss: 2.131005]\n",
      "epoch:11 step:9294 [D loss: 0.317225, acc: 85.94%] [G loss: 2.307634]\n",
      "epoch:11 step:9295 [D loss: 0.711886, acc: 48.44%] [G loss: 1.930222]\n",
      "epoch:11 step:9296 [D loss: 0.611626, acc: 64.06%] [G loss: 2.623285]\n",
      "epoch:11 step:9297 [D loss: 0.337036, acc: 91.41%] [G loss: 2.203085]\n",
      "epoch:11 step:9298 [D loss: 0.478820, acc: 76.56%] [G loss: 2.820669]\n",
      "epoch:11 step:9299 [D loss: 0.697019, acc: 57.81%] [G loss: 2.139997]\n",
      "epoch:11 step:9300 [D loss: 0.358332, acc: 93.75%] [G loss: 2.293538]\n",
      "epoch:11 step:9301 [D loss: 0.522322, acc: 70.31%] [G loss: 2.721925]\n",
      "epoch:11 step:9302 [D loss: 0.698425, acc: 54.69%] [G loss: 2.524958]\n",
      "epoch:11 step:9303 [D loss: 0.603175, acc: 67.19%] [G loss: 2.561446]\n",
      "epoch:11 step:9304 [D loss: 0.776278, acc: 52.34%] [G loss: 1.727921]\n",
      "epoch:11 step:9305 [D loss: 0.655073, acc: 61.72%] [G loss: 2.073210]\n",
      "epoch:11 step:9306 [D loss: 0.750677, acc: 50.78%] [G loss: 1.788655]\n",
      "epoch:11 step:9307 [D loss: 0.451246, acc: 83.59%] [G loss: 2.234713]\n",
      "epoch:11 step:9308 [D loss: 0.322266, acc: 96.88%] [G loss: 3.571045]\n",
      "epoch:11 step:9309 [D loss: 0.780623, acc: 44.53%] [G loss: 2.460979]\n",
      "epoch:11 step:9310 [D loss: 0.974180, acc: 22.66%] [G loss: 1.949497]\n",
      "epoch:11 step:9311 [D loss: 0.529503, acc: 82.81%] [G loss: 2.352695]\n",
      "epoch:11 step:9312 [D loss: 0.456830, acc: 89.06%] [G loss: 2.671443]\n",
      "epoch:11 step:9313 [D loss: 0.352992, acc: 89.06%] [G loss: 2.245737]\n",
      "epoch:11 step:9314 [D loss: 0.571573, acc: 71.09%] [G loss: 2.089903]\n",
      "epoch:11 step:9315 [D loss: 0.556808, acc: 66.41%] [G loss: 2.686609]\n",
      "epoch:11 step:9316 [D loss: 0.475264, acc: 85.94%] [G loss: 2.462426]\n",
      "epoch:11 step:9317 [D loss: 0.517080, acc: 73.44%] [G loss: 2.949643]\n",
      "epoch:11 step:9318 [D loss: 0.687005, acc: 54.69%] [G loss: 1.984045]\n",
      "epoch:11 step:9319 [D loss: 0.461938, acc: 85.94%] [G loss: 2.553710]\n",
      "epoch:11 step:9320 [D loss: 0.508331, acc: 81.25%] [G loss: 2.498734]\n",
      "epoch:11 step:9321 [D loss: 0.425216, acc: 70.31%] [G loss: 3.302361]\n",
      "epoch:11 step:9322 [D loss: 0.166659, acc: 100.00%] [G loss: 2.898065]\n",
      "epoch:11 step:9323 [D loss: 0.833480, acc: 50.78%] [G loss: 2.566398]\n",
      "epoch:11 step:9324 [D loss: 0.353431, acc: 89.84%] [G loss: 2.426800]\n",
      "epoch:11 step:9325 [D loss: 0.923514, acc: 26.56%] [G loss: 2.304873]\n",
      "epoch:11 step:9326 [D loss: 0.548810, acc: 74.22%] [G loss: 2.367970]\n",
      "epoch:11 step:9327 [D loss: 0.492531, acc: 87.50%] [G loss: 2.107018]\n",
      "epoch:11 step:9328 [D loss: 0.641548, acc: 66.41%] [G loss: 2.390436]\n",
      "epoch:11 step:9329 [D loss: 0.313875, acc: 96.88%] [G loss: 2.190459]\n",
      "epoch:11 step:9330 [D loss: 0.823442, acc: 37.50%] [G loss: 1.593345]\n",
      "epoch:11 step:9331 [D loss: 0.612017, acc: 64.84%] [G loss: 2.292446]\n",
      "epoch:11 step:9332 [D loss: 0.427712, acc: 89.84%] [G loss: 3.072680]\n",
      "epoch:11 step:9333 [D loss: 0.930388, acc: 28.91%] [G loss: 2.297902]\n",
      "epoch:11 step:9334 [D loss: 0.739348, acc: 46.09%] [G loss: 2.395650]\n",
      "epoch:11 step:9335 [D loss: 0.616094, acc: 57.03%] [G loss: 2.312169]\n",
      "epoch:11 step:9336 [D loss: 0.343698, acc: 93.75%] [G loss: 2.537843]\n",
      "epoch:11 step:9337 [D loss: 0.449016, acc: 83.59%] [G loss: 2.423764]\n",
      "epoch:11 step:9338 [D loss: 0.730940, acc: 53.91%] [G loss: 1.957536]\n",
      "epoch:11 step:9339 [D loss: 0.435819, acc: 84.38%] [G loss: 2.168344]\n",
      "epoch:11 step:9340 [D loss: 0.794699, acc: 42.19%] [G loss: 2.087060]\n",
      "epoch:11 step:9341 [D loss: 0.496711, acc: 71.88%] [G loss: 2.205712]\n",
      "epoch:11 step:9342 [D loss: 0.761157, acc: 51.56%] [G loss: 1.634123]\n",
      "epoch:11 step:9343 [D loss: 0.433568, acc: 82.81%] [G loss: 2.374833]\n",
      "epoch:11 step:9344 [D loss: 0.343939, acc: 93.75%] [G loss: 2.421397]\n",
      "epoch:11 step:9345 [D loss: 0.479308, acc: 78.12%] [G loss: 2.171976]\n",
      "epoch:11 step:9346 [D loss: 0.811539, acc: 41.41%] [G loss: 2.157243]\n",
      "epoch:11 step:9347 [D loss: 0.964063, acc: 27.34%] [G loss: 1.756624]\n",
      "epoch:11 step:9348 [D loss: 0.739985, acc: 50.00%] [G loss: 2.102805]\n",
      "epoch:11 step:9349 [D loss: 0.585591, acc: 67.97%] [G loss: 1.884998]\n",
      "epoch:11 step:9350 [D loss: 0.617202, acc: 69.53%] [G loss: 2.637354]\n",
      "epoch:11 step:9351 [D loss: 0.612114, acc: 65.62%] [G loss: 2.281407]\n",
      "epoch:11 step:9352 [D loss: 0.309178, acc: 92.19%] [G loss: 2.849763]\n",
      "epoch:11 step:9353 [D loss: 0.334465, acc: 96.09%] [G loss: 2.788084]\n",
      "epoch:11 step:9354 [D loss: 0.683890, acc: 60.94%] [G loss: 2.183707]\n",
      "epoch:11 step:9355 [D loss: 0.590242, acc: 60.16%] [G loss: 2.073509]\n",
      "epoch:11 step:9356 [D loss: 0.385192, acc: 92.19%] [G loss: 2.579557]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:11 step:9357 [D loss: 0.527017, acc: 67.97%] [G loss: 1.969365]\n",
      "epoch:11 step:9358 [D loss: 0.411141, acc: 89.84%] [G loss: 2.447587]\n",
      "epoch:11 step:9359 [D loss: 0.638825, acc: 61.72%] [G loss: 2.337895]\n",
      "epoch:11 step:9360 [D loss: 0.697087, acc: 53.91%] [G loss: 2.153176]\n",
      "epoch:11 step:9361 [D loss: 0.455324, acc: 85.94%] [G loss: 2.528977]\n",
      "epoch:11 step:9362 [D loss: 0.497112, acc: 78.91%] [G loss: 2.850034]\n",
      "epoch:11 step:9363 [D loss: 0.991550, acc: 27.34%] [G loss: 2.378826]\n",
      "epoch:11 step:9364 [D loss: 0.271297, acc: 92.97%] [G loss: 2.920634]\n",
      "epoch:11 step:9365 [D loss: 0.704853, acc: 54.69%] [G loss: 2.407755]\n",
      "epoch:11 step:9366 [D loss: 0.676937, acc: 59.38%] [G loss: 2.641751]\n",
      "epoch:11 step:9367 [D loss: 1.193017, acc: 7.81%] [G loss: 1.341713]\n",
      "epoch:11 step:9368 [D loss: 0.978980, acc: 32.81%] [G loss: 1.854994]\n",
      "epoch:11 step:9369 [D loss: 0.400949, acc: 82.03%] [G loss: 2.100144]\n",
      "epoch:11 step:9370 [D loss: 0.707381, acc: 57.81%] [G loss: 2.104291]\n",
      "epoch:11 step:9371 [D loss: 0.567205, acc: 72.66%] [G loss: 2.394310]\n",
      "epoch:11 step:9372 [D loss: 0.445831, acc: 92.19%] [G loss: 2.727937]\n",
      "epoch:12 step:9373 [D loss: 0.806317, acc: 48.44%] [G loss: 1.754770]\n",
      "epoch:12 step:9374 [D loss: 0.868575, acc: 30.47%] [G loss: 1.675894]\n",
      "epoch:12 step:9375 [D loss: 0.440443, acc: 87.50%] [G loss: 2.828058]\n",
      "epoch:12 step:9376 [D loss: 0.899122, acc: 31.25%] [G loss: 2.220460]\n",
      "epoch:12 step:9377 [D loss: 0.260408, acc: 98.44%] [G loss: 3.169420]\n",
      "epoch:12 step:9378 [D loss: 0.417470, acc: 78.12%] [G loss: 3.312799]\n",
      "epoch:12 step:9379 [D loss: 0.361885, acc: 94.53%] [G loss: 2.291248]\n",
      "epoch:12 step:9380 [D loss: 0.609482, acc: 63.28%] [G loss: 1.839133]\n",
      "epoch:12 step:9381 [D loss: 0.391863, acc: 85.16%] [G loss: 3.185191]\n",
      "epoch:12 step:9382 [D loss: 0.481855, acc: 87.50%] [G loss: 2.659463]\n",
      "epoch:12 step:9383 [D loss: 0.344343, acc: 97.66%] [G loss: 2.503903]\n",
      "epoch:12 step:9384 [D loss: 0.535847, acc: 74.22%] [G loss: 1.872951]\n",
      "epoch:12 step:9385 [D loss: 0.244125, acc: 100.00%] [G loss: 2.531197]\n",
      "epoch:12 step:9386 [D loss: 0.671301, acc: 59.38%] [G loss: 1.847054]\n",
      "epoch:12 step:9387 [D loss: 1.115054, acc: 23.44%] [G loss: 1.749425]\n",
      "epoch:12 step:9388 [D loss: 0.833503, acc: 38.28%] [G loss: 1.717513]\n",
      "epoch:12 step:9389 [D loss: 0.606929, acc: 66.41%] [G loss: 2.941998]\n",
      "epoch:12 step:9390 [D loss: 0.657189, acc: 60.94%] [G loss: 2.017803]\n",
      "epoch:12 step:9391 [D loss: 0.555855, acc: 66.41%] [G loss: 2.926100]\n",
      "epoch:12 step:9392 [D loss: 0.625334, acc: 66.41%] [G loss: 2.305948]\n",
      "epoch:12 step:9393 [D loss: 0.738482, acc: 53.91%] [G loss: 1.866611]\n",
      "epoch:12 step:9394 [D loss: 0.261970, acc: 92.19%] [G loss: 3.287639]\n",
      "epoch:12 step:9395 [D loss: 0.550472, acc: 76.56%] [G loss: 1.951983]\n",
      "epoch:12 step:9396 [D loss: 0.742218, acc: 48.44%] [G loss: 2.599927]\n",
      "epoch:12 step:9397 [D loss: 0.575930, acc: 71.09%] [G loss: 2.177154]\n",
      "epoch:12 step:9398 [D loss: 0.542122, acc: 76.56%] [G loss: 2.159151]\n",
      "epoch:12 step:9399 [D loss: 0.428003, acc: 89.06%] [G loss: 2.470676]\n",
      "epoch:12 step:9400 [D loss: 0.587906, acc: 71.88%] [G loss: 1.964861]\n",
      "##############\n",
      "[0.86372776 0.890496   0.82849565 0.81712856 0.81621662 0.81600985\n",
      " 0.87359138 0.81789421 0.80859916 0.85166021]\n",
      "##########\n",
      "epoch:12 step:9401 [D loss: 0.290914, acc: 91.41%] [G loss: 2.707834]\n",
      "epoch:12 step:9402 [D loss: 0.554648, acc: 63.28%] [G loss: 1.710213]\n",
      "epoch:12 step:9403 [D loss: 0.378330, acc: 90.62%] [G loss: 1.834551]\n",
      "epoch:12 step:9404 [D loss: 0.292638, acc: 96.88%] [G loss: 2.095568]\n",
      "epoch:12 step:9405 [D loss: 0.811746, acc: 50.00%] [G loss: 2.162624]\n",
      "epoch:12 step:9406 [D loss: 0.693588, acc: 57.03%] [G loss: 2.006515]\n",
      "epoch:12 step:9407 [D loss: 0.585638, acc: 64.84%] [G loss: 1.808853]\n",
      "epoch:12 step:9408 [D loss: 0.569185, acc: 71.09%] [G loss: 2.946000]\n",
      "epoch:12 step:9409 [D loss: 0.877108, acc: 39.06%] [G loss: 1.562431]\n",
      "epoch:12 step:9410 [D loss: 1.035018, acc: 31.25%] [G loss: 2.007895]\n",
      "epoch:12 step:9411 [D loss: 0.479363, acc: 69.53%] [G loss: 2.627510]\n",
      "epoch:12 step:9412 [D loss: 0.453092, acc: 88.28%] [G loss: 2.690188]\n",
      "epoch:12 step:9413 [D loss: 0.843820, acc: 41.41%] [G loss: 1.948694]\n",
      "epoch:12 step:9414 [D loss: 0.515900, acc: 79.69%] [G loss: 2.587272]\n",
      "epoch:12 step:9415 [D loss: 0.557836, acc: 76.56%] [G loss: 1.968596]\n",
      "epoch:12 step:9416 [D loss: 1.138269, acc: 15.62%] [G loss: 1.817176]\n",
      "epoch:12 step:9417 [D loss: 0.682174, acc: 55.47%] [G loss: 2.118147]\n",
      "epoch:12 step:9418 [D loss: 0.435073, acc: 85.94%] [G loss: 2.158901]\n",
      "epoch:12 step:9419 [D loss: 1.439421, acc: 12.50%] [G loss: 1.694301]\n",
      "epoch:12 step:9420 [D loss: 0.513060, acc: 75.78%] [G loss: 2.004879]\n",
      "epoch:12 step:9421 [D loss: 0.790528, acc: 49.22%] [G loss: 2.302085]\n",
      "epoch:12 step:9422 [D loss: 0.341179, acc: 91.41%] [G loss: 2.633111]\n",
      "epoch:12 step:9423 [D loss: 0.548436, acc: 73.44%] [G loss: 2.393312]\n",
      "epoch:12 step:9424 [D loss: 0.283076, acc: 94.53%] [G loss: 2.135625]\n",
      "epoch:12 step:9425 [D loss: 0.901333, acc: 42.97%] [G loss: 2.196587]\n",
      "epoch:12 step:9426 [D loss: 0.358549, acc: 92.19%] [G loss: 2.195319]\n",
      "epoch:12 step:9427 [D loss: 0.819158, acc: 39.84%] [G loss: 1.798675]\n",
      "epoch:12 step:9428 [D loss: 0.433342, acc: 85.94%] [G loss: 2.097459]\n",
      "epoch:12 step:9429 [D loss: 0.562983, acc: 72.66%] [G loss: 2.019320]\n",
      "epoch:12 step:9430 [D loss: 0.586210, acc: 63.28%] [G loss: 2.526793]\n",
      "epoch:12 step:9431 [D loss: 0.638221, acc: 65.62%] [G loss: 2.526163]\n",
      "epoch:12 step:9432 [D loss: 0.792660, acc: 43.75%] [G loss: 2.015690]\n",
      "epoch:12 step:9433 [D loss: 0.330582, acc: 90.62%] [G loss: 2.231002]\n",
      "epoch:12 step:9434 [D loss: 0.924548, acc: 34.38%] [G loss: 2.996863]\n",
      "epoch:12 step:9435 [D loss: 0.557420, acc: 66.41%] [G loss: 2.559692]\n",
      "epoch:12 step:9436 [D loss: 1.062057, acc: 27.34%] [G loss: 1.870226]\n",
      "epoch:12 step:9437 [D loss: 0.599284, acc: 68.75%] [G loss: 2.145499]\n",
      "epoch:12 step:9438 [D loss: 0.485380, acc: 77.34%] [G loss: 2.390322]\n",
      "epoch:12 step:9439 [D loss: 0.802211, acc: 35.94%] [G loss: 1.652094]\n",
      "epoch:12 step:9440 [D loss: 0.768280, acc: 45.31%] [G loss: 1.885367]\n",
      "epoch:12 step:9441 [D loss: 0.514004, acc: 82.03%] [G loss: 1.950816]\n",
      "epoch:12 step:9442 [D loss: 0.558524, acc: 75.00%] [G loss: 1.638007]\n",
      "epoch:12 step:9443 [D loss: 0.778184, acc: 44.53%] [G loss: 1.912947]\n",
      "epoch:12 step:9444 [D loss: 0.581924, acc: 79.69%] [G loss: 1.876004]\n",
      "epoch:12 step:9445 [D loss: 0.434124, acc: 90.62%] [G loss: 2.126551]\n",
      "epoch:12 step:9446 [D loss: 0.613420, acc: 60.94%] [G loss: 2.177042]\n",
      "epoch:12 step:9447 [D loss: 0.498472, acc: 84.38%] [G loss: 2.301582]\n",
      "epoch:12 step:9448 [D loss: 0.576562, acc: 70.31%] [G loss: 2.336143]\n",
      "epoch:12 step:9449 [D loss: 0.760100, acc: 50.78%] [G loss: 2.004779]\n",
      "epoch:12 step:9450 [D loss: 0.329670, acc: 92.97%] [G loss: 2.168152]\n",
      "epoch:12 step:9451 [D loss: 0.677316, acc: 54.69%] [G loss: 1.856218]\n",
      "epoch:12 step:9452 [D loss: 0.233862, acc: 98.44%] [G loss: 2.560326]\n",
      "epoch:12 step:9453 [D loss: 0.638572, acc: 67.19%] [G loss: 1.811265]\n",
      "epoch:12 step:9454 [D loss: 0.411828, acc: 84.38%] [G loss: 2.480201]\n",
      "epoch:12 step:9455 [D loss: 0.912390, acc: 36.72%] [G loss: 1.812730]\n",
      "epoch:12 step:9456 [D loss: 0.877694, acc: 44.53%] [G loss: 1.615491]\n",
      "epoch:12 step:9457 [D loss: 0.614241, acc: 67.19%] [G loss: 2.578318]\n",
      "epoch:12 step:9458 [D loss: 0.622609, acc: 59.38%] [G loss: 2.222663]\n",
      "epoch:12 step:9459 [D loss: 0.611742, acc: 62.50%] [G loss: 2.158147]\n",
      "epoch:12 step:9460 [D loss: 0.762172, acc: 50.78%] [G loss: 1.504315]\n",
      "epoch:12 step:9461 [D loss: 0.421735, acc: 88.28%] [G loss: 1.931606]\n",
      "epoch:12 step:9462 [D loss: 0.871350, acc: 32.03%] [G loss: 1.505948]\n",
      "epoch:12 step:9463 [D loss: 0.547392, acc: 75.78%] [G loss: 2.172922]\n",
      "epoch:12 step:9464 [D loss: 0.550228, acc: 64.84%] [G loss: 1.769282]\n",
      "epoch:12 step:9465 [D loss: 0.422234, acc: 77.34%] [G loss: 2.012282]\n",
      "epoch:12 step:9466 [D loss: 0.678922, acc: 59.38%] [G loss: 2.075691]\n",
      "epoch:12 step:9467 [D loss: 0.490272, acc: 82.81%] [G loss: 2.040576]\n",
      "epoch:12 step:9468 [D loss: 0.659202, acc: 58.59%] [G loss: 2.282032]\n",
      "epoch:12 step:9469 [D loss: 0.741606, acc: 48.44%] [G loss: 2.181832]\n",
      "epoch:12 step:9470 [D loss: 0.534916, acc: 74.22%] [G loss: 2.403664]\n",
      "epoch:12 step:9471 [D loss: 0.474838, acc: 86.72%] [G loss: 2.097475]\n",
      "epoch:12 step:9472 [D loss: 0.454172, acc: 89.06%] [G loss: 2.122652]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:12 step:9473 [D loss: 0.998124, acc: 36.72%] [G loss: 1.459400]\n",
      "epoch:12 step:9474 [D loss: 0.282901, acc: 96.09%] [G loss: 2.399465]\n",
      "epoch:12 step:9475 [D loss: 0.667177, acc: 64.84%] [G loss: 2.427995]\n",
      "epoch:12 step:9476 [D loss: 0.597643, acc: 66.41%] [G loss: 2.174178]\n",
      "epoch:12 step:9477 [D loss: 0.262139, acc: 98.44%] [G loss: 2.619814]\n",
      "epoch:12 step:9478 [D loss: 0.720530, acc: 56.25%] [G loss: 2.972597]\n",
      "epoch:12 step:9479 [D loss: 0.722775, acc: 53.12%] [G loss: 1.881751]\n",
      "epoch:12 step:9480 [D loss: 0.745674, acc: 44.53%] [G loss: 2.204121]\n",
      "epoch:12 step:9481 [D loss: 0.597141, acc: 67.97%] [G loss: 2.095060]\n",
      "epoch:12 step:9482 [D loss: 0.762751, acc: 42.19%] [G loss: 1.902814]\n",
      "epoch:12 step:9483 [D loss: 0.749380, acc: 50.00%] [G loss: 1.791620]\n",
      "epoch:12 step:9484 [D loss: 0.457362, acc: 86.72%] [G loss: 2.330171]\n",
      "epoch:12 step:9485 [D loss: 0.762729, acc: 53.12%] [G loss: 1.927543]\n",
      "epoch:12 step:9486 [D loss: 0.662928, acc: 61.72%] [G loss: 1.814269]\n",
      "epoch:12 step:9487 [D loss: 0.452748, acc: 82.81%] [G loss: 2.161839]\n",
      "epoch:12 step:9488 [D loss: 0.474604, acc: 85.94%] [G loss: 2.241730]\n",
      "epoch:12 step:9489 [D loss: 0.622984, acc: 65.62%] [G loss: 2.080294]\n",
      "epoch:12 step:9490 [D loss: 0.473914, acc: 85.16%] [G loss: 2.321514]\n",
      "epoch:12 step:9491 [D loss: 0.730055, acc: 53.12%] [G loss: 2.472535]\n",
      "epoch:12 step:9492 [D loss: 0.642348, acc: 64.84%] [G loss: 2.843388]\n",
      "epoch:12 step:9493 [D loss: 0.322987, acc: 89.06%] [G loss: 2.117032]\n",
      "epoch:12 step:9494 [D loss: 0.841044, acc: 39.84%] [G loss: 2.274886]\n",
      "epoch:12 step:9495 [D loss: 0.457760, acc: 85.16%] [G loss: 2.066914]\n",
      "epoch:12 step:9496 [D loss: 0.322414, acc: 95.31%] [G loss: 2.848039]\n",
      "epoch:12 step:9497 [D loss: 0.549890, acc: 75.00%] [G loss: 3.111775]\n",
      "epoch:12 step:9498 [D loss: 0.796492, acc: 46.09%] [G loss: 1.935593]\n",
      "epoch:12 step:9499 [D loss: 0.614439, acc: 67.19%] [G loss: 1.743429]\n",
      "epoch:12 step:9500 [D loss: 0.601337, acc: 57.03%] [G loss: 2.313048]\n",
      "epoch:12 step:9501 [D loss: 0.435178, acc: 85.16%] [G loss: 2.335698]\n",
      "epoch:12 step:9502 [D loss: 0.702082, acc: 58.59%] [G loss: 1.903588]\n",
      "epoch:12 step:9503 [D loss: 0.970221, acc: 42.97%] [G loss: 2.064346]\n",
      "epoch:12 step:9504 [D loss: 0.616854, acc: 65.62%] [G loss: 2.558656]\n",
      "epoch:12 step:9505 [D loss: 0.683594, acc: 63.28%] [G loss: 1.775532]\n",
      "epoch:12 step:9506 [D loss: 0.677259, acc: 54.69%] [G loss: 2.209841]\n",
      "epoch:12 step:9507 [D loss: 0.640715, acc: 60.94%] [G loss: 2.456134]\n",
      "epoch:12 step:9508 [D loss: 0.504975, acc: 75.00%] [G loss: 1.946018]\n",
      "epoch:12 step:9509 [D loss: 0.908826, acc: 35.94%] [G loss: 2.168496]\n",
      "epoch:12 step:9510 [D loss: 0.401699, acc: 89.84%] [G loss: 2.429030]\n",
      "epoch:12 step:9511 [D loss: 0.402294, acc: 82.03%] [G loss: 1.961953]\n",
      "epoch:12 step:9512 [D loss: 0.625850, acc: 64.84%] [G loss: 2.510101]\n",
      "epoch:12 step:9513 [D loss: 0.524410, acc: 83.59%] [G loss: 2.472292]\n",
      "epoch:12 step:9514 [D loss: 0.611480, acc: 67.97%] [G loss: 2.172983]\n",
      "epoch:12 step:9515 [D loss: 0.650817, acc: 60.16%] [G loss: 2.052242]\n",
      "epoch:12 step:9516 [D loss: 0.594277, acc: 71.09%] [G loss: 2.028443]\n",
      "epoch:12 step:9517 [D loss: 0.733141, acc: 51.56%] [G loss: 2.134798]\n",
      "epoch:12 step:9518 [D loss: 0.208583, acc: 99.22%] [G loss: 2.223908]\n",
      "epoch:12 step:9519 [D loss: 0.506199, acc: 76.56%] [G loss: 1.876328]\n",
      "epoch:12 step:9520 [D loss: 0.908362, acc: 28.91%] [G loss: 1.879921]\n",
      "epoch:12 step:9521 [D loss: 0.577564, acc: 67.97%] [G loss: 2.015260]\n",
      "epoch:12 step:9522 [D loss: 0.623153, acc: 64.06%] [G loss: 2.006029]\n",
      "epoch:12 step:9523 [D loss: 0.430322, acc: 91.41%] [G loss: 2.290245]\n",
      "epoch:12 step:9524 [D loss: 0.681394, acc: 54.69%] [G loss: 2.388679]\n",
      "epoch:12 step:9525 [D loss: 0.361645, acc: 90.62%] [G loss: 2.510081]\n",
      "epoch:12 step:9526 [D loss: 0.556262, acc: 70.31%] [G loss: 2.888673]\n",
      "epoch:12 step:9527 [D loss: 0.701374, acc: 53.12%] [G loss: 2.002247]\n",
      "epoch:12 step:9528 [D loss: 0.618487, acc: 61.72%] [G loss: 2.096965]\n",
      "epoch:12 step:9529 [D loss: 0.485495, acc: 83.59%] [G loss: 2.583982]\n",
      "epoch:12 step:9530 [D loss: 0.509518, acc: 75.00%] [G loss: 2.442595]\n",
      "epoch:12 step:9531 [D loss: 0.309431, acc: 98.44%] [G loss: 2.394240]\n",
      "epoch:12 step:9532 [D loss: 0.527658, acc: 75.00%] [G loss: 2.931744]\n",
      "epoch:12 step:9533 [D loss: 0.426537, acc: 75.78%] [G loss: 2.654449]\n",
      "epoch:12 step:9534 [D loss: 0.874513, acc: 50.78%] [G loss: 2.509939]\n",
      "epoch:12 step:9535 [D loss: 0.500871, acc: 77.34%] [G loss: 2.704202]\n",
      "epoch:12 step:9536 [D loss: 0.412571, acc: 78.91%] [G loss: 2.491890]\n",
      "epoch:12 step:9537 [D loss: 0.513990, acc: 82.03%] [G loss: 2.526155]\n",
      "epoch:12 step:9538 [D loss: 0.644262, acc: 66.41%] [G loss: 1.828660]\n",
      "epoch:12 step:9539 [D loss: 0.453402, acc: 81.25%] [G loss: 2.163930]\n",
      "epoch:12 step:9540 [D loss: 0.189820, acc: 99.22%] [G loss: 3.430345]\n",
      "epoch:12 step:9541 [D loss: 0.603056, acc: 64.84%] [G loss: 2.198844]\n",
      "epoch:12 step:9542 [D loss: 0.587928, acc: 71.09%] [G loss: 2.189656]\n",
      "epoch:12 step:9543 [D loss: 0.830714, acc: 42.97%] [G loss: 1.950884]\n",
      "epoch:12 step:9544 [D loss: 0.658917, acc: 63.28%] [G loss: 2.070044]\n",
      "epoch:12 step:9545 [D loss: 0.507435, acc: 72.66%] [G loss: 2.885740]\n",
      "epoch:12 step:9546 [D loss: 0.707014, acc: 52.34%] [G loss: 1.980413]\n",
      "epoch:12 step:9547 [D loss: 0.904301, acc: 32.03%] [G loss: 1.787832]\n",
      "epoch:12 step:9548 [D loss: 0.633387, acc: 59.38%] [G loss: 1.899161]\n",
      "epoch:12 step:9549 [D loss: 0.341556, acc: 93.75%] [G loss: 2.241704]\n",
      "epoch:12 step:9550 [D loss: 0.376890, acc: 91.41%] [G loss: 2.598421]\n",
      "epoch:12 step:9551 [D loss: 0.454689, acc: 88.28%] [G loss: 1.971451]\n",
      "epoch:12 step:9552 [D loss: 0.781895, acc: 46.09%] [G loss: 1.861262]\n",
      "epoch:12 step:9553 [D loss: 0.287221, acc: 89.84%] [G loss: 2.967915]\n",
      "epoch:12 step:9554 [D loss: 0.915361, acc: 36.72%] [G loss: 1.915284]\n",
      "epoch:12 step:9555 [D loss: 0.645574, acc: 67.19%] [G loss: 2.696206]\n",
      "epoch:12 step:9556 [D loss: 1.173401, acc: 13.28%] [G loss: 1.804549]\n",
      "epoch:12 step:9557 [D loss: 0.880076, acc: 33.59%] [G loss: 1.968785]\n",
      "epoch:12 step:9558 [D loss: 0.536474, acc: 76.56%] [G loss: 2.418017]\n",
      "epoch:12 step:9559 [D loss: 0.555096, acc: 75.78%] [G loss: 2.271024]\n",
      "epoch:12 step:9560 [D loss: 0.430513, acc: 88.28%] [G loss: 2.020242]\n",
      "epoch:12 step:9561 [D loss: 0.538802, acc: 74.22%] [G loss: 2.740378]\n",
      "epoch:12 step:9562 [D loss: 0.382522, acc: 84.38%] [G loss: 3.016180]\n",
      "epoch:12 step:9563 [D loss: 0.522192, acc: 73.44%] [G loss: 2.660124]\n",
      "epoch:12 step:9564 [D loss: 0.716851, acc: 51.56%] [G loss: 4.141388]\n",
      "epoch:12 step:9565 [D loss: 0.622966, acc: 64.06%] [G loss: 2.825237]\n",
      "epoch:12 step:9566 [D loss: 0.273976, acc: 92.19%] [G loss: 3.115356]\n",
      "epoch:12 step:9567 [D loss: 0.416605, acc: 84.38%] [G loss: 2.843292]\n",
      "epoch:12 step:9568 [D loss: 0.782283, acc: 43.75%] [G loss: 2.451709]\n",
      "epoch:12 step:9569 [D loss: 0.658537, acc: 59.38%] [G loss: 2.466437]\n",
      "epoch:12 step:9570 [D loss: 0.670329, acc: 60.16%] [G loss: 1.947308]\n",
      "epoch:12 step:9571 [D loss: 0.592220, acc: 67.97%] [G loss: 2.519629]\n",
      "epoch:12 step:9572 [D loss: 0.579718, acc: 71.09%] [G loss: 2.427417]\n",
      "epoch:12 step:9573 [D loss: 0.389503, acc: 92.97%] [G loss: 3.186045]\n",
      "epoch:12 step:9574 [D loss: 0.903918, acc: 48.44%] [G loss: 2.246562]\n",
      "epoch:12 step:9575 [D loss: 0.530573, acc: 77.34%] [G loss: 1.693353]\n",
      "epoch:12 step:9576 [D loss: 0.365429, acc: 95.31%] [G loss: 2.144313]\n",
      "epoch:12 step:9577 [D loss: 0.614006, acc: 65.62%] [G loss: 1.968048]\n",
      "epoch:12 step:9578 [D loss: 0.889319, acc: 34.38%] [G loss: 1.641463]\n",
      "epoch:12 step:9579 [D loss: 0.989335, acc: 23.44%] [G loss: 1.787458]\n",
      "epoch:12 step:9580 [D loss: 0.731674, acc: 50.78%] [G loss: 2.472357]\n",
      "epoch:12 step:9581 [D loss: 0.401757, acc: 79.69%] [G loss: 1.684984]\n",
      "epoch:12 step:9582 [D loss: 0.828629, acc: 42.19%] [G loss: 1.457681]\n",
      "epoch:12 step:9583 [D loss: 0.552121, acc: 71.09%] [G loss: 2.062441]\n",
      "epoch:12 step:9584 [D loss: 0.236415, acc: 96.09%] [G loss: 2.400239]\n",
      "epoch:12 step:9585 [D loss: 0.869965, acc: 41.41%] [G loss: 1.515698]\n",
      "epoch:12 step:9586 [D loss: 0.541864, acc: 69.53%] [G loss: 2.096967]\n",
      "epoch:12 step:9587 [D loss: 0.624617, acc: 66.41%] [G loss: 2.035693]\n",
      "epoch:12 step:9588 [D loss: 0.585356, acc: 72.66%] [G loss: 1.848670]\n",
      "epoch:12 step:9589 [D loss: 0.518256, acc: 60.94%] [G loss: 1.743672]\n",
      "epoch:12 step:9590 [D loss: 0.654973, acc: 58.59%] [G loss: 3.512673]\n",
      "epoch:12 step:9591 [D loss: 0.686102, acc: 57.03%] [G loss: 2.116995]\n",
      "epoch:12 step:9592 [D loss: 0.430414, acc: 84.38%] [G loss: 3.136617]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:12 step:9593 [D loss: 1.172188, acc: 35.16%] [G loss: 1.660504]\n",
      "epoch:12 step:9594 [D loss: 0.764293, acc: 56.25%] [G loss: 2.463856]\n",
      "epoch:12 step:9595 [D loss: 0.818565, acc: 46.09%] [G loss: 2.015538]\n",
      "epoch:12 step:9596 [D loss: 0.748934, acc: 50.78%] [G loss: 1.946478]\n",
      "epoch:12 step:9597 [D loss: 0.523276, acc: 77.34%] [G loss: 2.325587]\n",
      "epoch:12 step:9598 [D loss: 0.567619, acc: 76.56%] [G loss: 2.167115]\n",
      "epoch:12 step:9599 [D loss: 0.521139, acc: 77.34%] [G loss: 2.022441]\n",
      "epoch:12 step:9600 [D loss: 0.214058, acc: 100.00%] [G loss: 3.662182]\n",
      "##############\n",
      "[0.83323927 0.8702169  0.82600877 0.81014554 0.78191419 0.80858765\n",
      " 0.88991922 0.83884129 0.81093043 0.82939911]\n",
      "##########\n",
      "epoch:12 step:9601 [D loss: 0.321945, acc: 94.53%] [G loss: 2.425259]\n",
      "epoch:12 step:9602 [D loss: 0.983724, acc: 17.97%] [G loss: 2.201185]\n",
      "epoch:12 step:9603 [D loss: 0.461299, acc: 85.94%] [G loss: 2.237820]\n",
      "epoch:12 step:9604 [D loss: 0.648781, acc: 62.50%] [G loss: 2.110075]\n",
      "epoch:12 step:9605 [D loss: 0.723267, acc: 60.16%] [G loss: 1.842222]\n",
      "epoch:12 step:9606 [D loss: 0.481327, acc: 69.53%] [G loss: 1.904794]\n",
      "epoch:12 step:9607 [D loss: 0.626009, acc: 68.75%] [G loss: 1.943761]\n",
      "epoch:12 step:9608 [D loss: 0.531306, acc: 75.78%] [G loss: 2.185583]\n",
      "epoch:12 step:9609 [D loss: 0.338374, acc: 95.31%] [G loss: 2.526086]\n",
      "epoch:12 step:9610 [D loss: 0.798857, acc: 45.31%] [G loss: 2.102246]\n",
      "epoch:12 step:9611 [D loss: 0.346700, acc: 94.53%] [G loss: 3.485906]\n",
      "epoch:12 step:9612 [D loss: 0.574046, acc: 72.66%] [G loss: 2.236972]\n",
      "epoch:12 step:9613 [D loss: 0.415135, acc: 92.19%] [G loss: 2.496545]\n",
      "epoch:12 step:9614 [D loss: 0.563833, acc: 67.97%] [G loss: 1.920969]\n",
      "epoch:12 step:9615 [D loss: 0.529981, acc: 71.09%] [G loss: 1.977166]\n",
      "epoch:12 step:9616 [D loss: 0.654922, acc: 57.03%] [G loss: 2.280015]\n",
      "epoch:12 step:9617 [D loss: 0.717901, acc: 53.91%] [G loss: 1.509606]\n",
      "epoch:12 step:9618 [D loss: 1.038893, acc: 38.28%] [G loss: 1.735042]\n",
      "epoch:12 step:9619 [D loss: 0.505292, acc: 74.22%] [G loss: 1.804444]\n",
      "epoch:12 step:9620 [D loss: 0.500433, acc: 78.12%] [G loss: 1.778572]\n",
      "epoch:12 step:9621 [D loss: 0.485226, acc: 85.94%] [G loss: 2.069179]\n",
      "epoch:12 step:9622 [D loss: 0.479701, acc: 81.25%] [G loss: 2.604742]\n",
      "epoch:12 step:9623 [D loss: 0.544829, acc: 78.12%] [G loss: 1.897437]\n",
      "epoch:12 step:9624 [D loss: 0.691151, acc: 54.69%] [G loss: 1.916988]\n",
      "epoch:12 step:9625 [D loss: 0.496597, acc: 67.97%] [G loss: 1.626301]\n",
      "epoch:12 step:9626 [D loss: 0.917996, acc: 35.16%] [G loss: 1.693123]\n",
      "epoch:12 step:9627 [D loss: 0.575714, acc: 64.06%] [G loss: 2.120452]\n",
      "epoch:12 step:9628 [D loss: 0.816109, acc: 46.09%] [G loss: 1.997886]\n",
      "epoch:12 step:9629 [D loss: 0.890681, acc: 45.31%] [G loss: 1.605113]\n",
      "epoch:12 step:9630 [D loss: 0.741575, acc: 55.47%] [G loss: 2.463042]\n",
      "epoch:12 step:9631 [D loss: 0.801393, acc: 46.09%] [G loss: 1.909724]\n",
      "epoch:12 step:9632 [D loss: 0.628508, acc: 67.19%] [G loss: 1.937545]\n",
      "epoch:12 step:9633 [D loss: 0.525383, acc: 69.53%] [G loss: 2.430769]\n",
      "epoch:12 step:9634 [D loss: 0.917251, acc: 28.12%] [G loss: 2.615636]\n",
      "epoch:12 step:9635 [D loss: 0.702103, acc: 59.38%] [G loss: 2.187773]\n",
      "epoch:12 step:9636 [D loss: 0.902075, acc: 24.22%] [G loss: 1.863973]\n",
      "epoch:12 step:9637 [D loss: 0.539076, acc: 71.09%] [G loss: 1.952482]\n",
      "epoch:12 step:9638 [D loss: 0.359088, acc: 92.19%] [G loss: 2.273722]\n",
      "epoch:12 step:9639 [D loss: 0.581202, acc: 57.03%] [G loss: 2.251816]\n",
      "epoch:12 step:9640 [D loss: 0.608123, acc: 62.50%] [G loss: 2.289158]\n",
      "epoch:12 step:9641 [D loss: 0.699060, acc: 51.56%] [G loss: 1.950773]\n",
      "epoch:12 step:9642 [D loss: 1.071249, acc: 37.50%] [G loss: 1.764134]\n",
      "epoch:12 step:9643 [D loss: 0.583846, acc: 72.66%] [G loss: 1.954022]\n",
      "epoch:12 step:9644 [D loss: 0.448766, acc: 72.66%] [G loss: 2.824356]\n",
      "epoch:12 step:9645 [D loss: 0.455519, acc: 78.12%] [G loss: 1.742417]\n",
      "epoch:12 step:9646 [D loss: 0.687815, acc: 54.69%] [G loss: 2.919008]\n",
      "epoch:12 step:9647 [D loss: 0.428055, acc: 91.41%] [G loss: 2.222051]\n",
      "epoch:12 step:9648 [D loss: 0.339173, acc: 86.72%] [G loss: 2.152204]\n",
      "epoch:12 step:9649 [D loss: 1.284968, acc: 6.25%] [G loss: 1.856463]\n",
      "epoch:12 step:9650 [D loss: 0.271455, acc: 98.44%] [G loss: 2.047291]\n",
      "epoch:12 step:9651 [D loss: 0.748515, acc: 53.91%] [G loss: 1.720413]\n",
      "epoch:12 step:9652 [D loss: 0.393693, acc: 91.41%] [G loss: 1.914143]\n",
      "epoch:12 step:9653 [D loss: 0.636834, acc: 60.16%] [G loss: 2.117143]\n",
      "epoch:12 step:9654 [D loss: 0.990939, acc: 25.00%] [G loss: 1.574143]\n",
      "epoch:12 step:9655 [D loss: 0.296314, acc: 92.19%] [G loss: 1.912368]\n",
      "epoch:12 step:9656 [D loss: 0.624875, acc: 66.41%] [G loss: 1.769323]\n",
      "epoch:12 step:9657 [D loss: 0.313059, acc: 94.53%] [G loss: 1.791363]\n",
      "epoch:12 step:9658 [D loss: 0.667608, acc: 61.72%] [G loss: 1.976628]\n",
      "epoch:12 step:9659 [D loss: 0.483915, acc: 85.16%] [G loss: 2.220546]\n",
      "epoch:12 step:9660 [D loss: 1.157039, acc: 12.50%] [G loss: 1.783995]\n",
      "epoch:12 step:9661 [D loss: 0.409827, acc: 93.75%] [G loss: 1.720687]\n",
      "epoch:12 step:9662 [D loss: 0.326209, acc: 89.06%] [G loss: 3.116262]\n",
      "epoch:12 step:9663 [D loss: 0.823055, acc: 32.03%] [G loss: 1.992965]\n",
      "epoch:12 step:9664 [D loss: 0.859418, acc: 49.22%] [G loss: 1.897054]\n",
      "epoch:12 step:9665 [D loss: 0.577012, acc: 64.84%] [G loss: 2.297726]\n",
      "epoch:12 step:9666 [D loss: 0.759320, acc: 39.84%] [G loss: 1.801899]\n",
      "epoch:12 step:9667 [D loss: 0.580894, acc: 67.19%] [G loss: 1.807608]\n",
      "epoch:12 step:9668 [D loss: 0.603196, acc: 67.97%] [G loss: 1.940046]\n",
      "epoch:12 step:9669 [D loss: 0.734966, acc: 48.44%] [G loss: 2.004606]\n",
      "epoch:12 step:9670 [D loss: 0.462452, acc: 87.50%] [G loss: 2.112922]\n",
      "epoch:12 step:9671 [D loss: 0.468367, acc: 86.72%] [G loss: 2.138756]\n",
      "epoch:12 step:9672 [D loss: 0.500268, acc: 82.03%] [G loss: 1.735988]\n",
      "epoch:12 step:9673 [D loss: 0.540814, acc: 75.00%] [G loss: 2.224383]\n",
      "epoch:12 step:9674 [D loss: 0.345425, acc: 96.09%] [G loss: 2.134795]\n",
      "epoch:12 step:9675 [D loss: 0.847620, acc: 42.97%] [G loss: 2.097962]\n",
      "epoch:12 step:9676 [D loss: 0.485502, acc: 73.44%] [G loss: 2.013784]\n",
      "epoch:12 step:9677 [D loss: 0.628110, acc: 65.62%] [G loss: 2.216539]\n",
      "epoch:12 step:9678 [D loss: 0.771695, acc: 46.09%] [G loss: 1.711306]\n",
      "epoch:12 step:9679 [D loss: 0.493427, acc: 83.59%] [G loss: 2.057399]\n",
      "epoch:12 step:9680 [D loss: 0.384127, acc: 82.81%] [G loss: 2.250543]\n",
      "epoch:12 step:9681 [D loss: 0.294424, acc: 96.88%] [G loss: 2.378461]\n",
      "epoch:12 step:9682 [D loss: 0.601166, acc: 64.84%] [G loss: 2.409132]\n",
      "epoch:12 step:9683 [D loss: 0.655595, acc: 59.38%] [G loss: 2.026228]\n",
      "epoch:12 step:9684 [D loss: 0.769201, acc: 47.66%] [G loss: 2.205013]\n",
      "epoch:12 step:9685 [D loss: 0.576318, acc: 71.09%] [G loss: 1.878649]\n",
      "epoch:12 step:9686 [D loss: 0.725238, acc: 53.12%] [G loss: 1.484177]\n",
      "epoch:12 step:9687 [D loss: 1.057068, acc: 22.66%] [G loss: 2.055854]\n",
      "epoch:12 step:9688 [D loss: 0.783568, acc: 41.41%] [G loss: 2.220129]\n",
      "epoch:12 step:9689 [D loss: 0.689347, acc: 57.03%] [G loss: 2.038604]\n",
      "epoch:12 step:9690 [D loss: 0.726120, acc: 53.91%] [G loss: 1.890769]\n",
      "epoch:12 step:9691 [D loss: 0.735613, acc: 50.78%] [G loss: 1.877226]\n",
      "epoch:12 step:9692 [D loss: 0.606210, acc: 60.94%] [G loss: 1.764300]\n",
      "epoch:12 step:9693 [D loss: 0.592652, acc: 66.41%] [G loss: 2.074774]\n",
      "epoch:12 step:9694 [D loss: 0.462677, acc: 88.28%] [G loss: 2.551229]\n",
      "epoch:12 step:9695 [D loss: 0.402939, acc: 90.62%] [G loss: 2.149333]\n",
      "epoch:12 step:9696 [D loss: 0.439667, acc: 78.91%] [G loss: 2.190066]\n",
      "epoch:12 step:9697 [D loss: 0.496953, acc: 82.81%] [G loss: 2.023928]\n",
      "epoch:12 step:9698 [D loss: 0.466223, acc: 82.81%] [G loss: 1.996084]\n",
      "epoch:12 step:9699 [D loss: 0.355876, acc: 87.50%] [G loss: 1.701162]\n",
      "epoch:12 step:9700 [D loss: 0.728568, acc: 53.12%] [G loss: 2.858748]\n",
      "epoch:12 step:9701 [D loss: 0.727078, acc: 52.34%] [G loss: 1.629044]\n",
      "epoch:12 step:9702 [D loss: 0.259282, acc: 97.66%] [G loss: 2.337241]\n",
      "epoch:12 step:9703 [D loss: 0.829207, acc: 51.56%] [G loss: 2.187487]\n",
      "epoch:12 step:9704 [D loss: 0.713787, acc: 51.56%] [G loss: 3.677531]\n",
      "epoch:12 step:9705 [D loss: 0.686127, acc: 53.91%] [G loss: 1.580199]\n",
      "epoch:12 step:9706 [D loss: 0.646194, acc: 51.56%] [G loss: 2.806509]\n",
      "epoch:12 step:9707 [D loss: 0.458443, acc: 87.50%] [G loss: 2.078756]\n",
      "epoch:12 step:9708 [D loss: 0.592647, acc: 65.62%] [G loss: 2.979401]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:12 step:9709 [D loss: 0.581794, acc: 65.62%] [G loss: 1.465545]\n",
      "epoch:12 step:9710 [D loss: 0.889417, acc: 30.47%] [G loss: 2.911761]\n",
      "epoch:12 step:9711 [D loss: 0.586383, acc: 75.78%] [G loss: 2.360678]\n",
      "epoch:12 step:9712 [D loss: 0.428313, acc: 85.94%] [G loss: 3.492427]\n",
      "epoch:12 step:9713 [D loss: 0.449342, acc: 86.72%] [G loss: 2.800005]\n",
      "epoch:12 step:9714 [D loss: 0.286337, acc: 92.97%] [G loss: 2.217629]\n",
      "epoch:12 step:9715 [D loss: 0.983634, acc: 25.78%] [G loss: 1.703408]\n",
      "epoch:12 step:9716 [D loss: 0.500462, acc: 72.66%] [G loss: 3.318316]\n",
      "epoch:12 step:9717 [D loss: 0.473096, acc: 88.28%] [G loss: 2.144122]\n",
      "epoch:12 step:9718 [D loss: 0.204208, acc: 99.22%] [G loss: 3.510902]\n",
      "epoch:12 step:9719 [D loss: 0.574275, acc: 69.53%] [G loss: 2.539462]\n",
      "epoch:12 step:9720 [D loss: 0.645786, acc: 61.72%] [G loss: 2.175888]\n",
      "epoch:12 step:9721 [D loss: 0.427169, acc: 91.41%] [G loss: 1.846889]\n",
      "epoch:12 step:9722 [D loss: 0.633630, acc: 62.50%] [G loss: 1.811319]\n",
      "epoch:12 step:9723 [D loss: 0.750516, acc: 53.12%] [G loss: 1.543231]\n",
      "epoch:12 step:9724 [D loss: 0.648188, acc: 58.59%] [G loss: 2.067552]\n",
      "epoch:12 step:9725 [D loss: 0.429995, acc: 82.03%] [G loss: 2.430311]\n",
      "epoch:12 step:9726 [D loss: 1.192467, acc: 49.22%] [G loss: 1.469173]\n",
      "epoch:12 step:9727 [D loss: 0.433363, acc: 80.47%] [G loss: 2.635464]\n",
      "epoch:12 step:9728 [D loss: 0.565045, acc: 69.53%] [G loss: 1.866279]\n",
      "epoch:12 step:9729 [D loss: 0.564597, acc: 76.56%] [G loss: 2.208076]\n",
      "epoch:12 step:9730 [D loss: 0.707899, acc: 51.56%] [G loss: 1.780550]\n",
      "epoch:12 step:9731 [D loss: 0.715429, acc: 57.81%] [G loss: 2.120860]\n",
      "epoch:12 step:9732 [D loss: 0.949645, acc: 26.56%] [G loss: 1.933826]\n",
      "epoch:12 step:9733 [D loss: 0.577778, acc: 67.19%] [G loss: 2.436093]\n",
      "epoch:12 step:9734 [D loss: 0.441785, acc: 90.62%] [G loss: 1.908044]\n",
      "epoch:12 step:9735 [D loss: 0.471213, acc: 78.91%] [G loss: 2.299462]\n",
      "epoch:12 step:9736 [D loss: 0.492935, acc: 78.12%] [G loss: 3.367412]\n",
      "epoch:12 step:9737 [D loss: 0.583586, acc: 75.00%] [G loss: 2.327128]\n",
      "epoch:12 step:9738 [D loss: 1.053957, acc: 30.47%] [G loss: 2.033840]\n",
      "epoch:12 step:9739 [D loss: 0.527406, acc: 77.34%] [G loss: 3.135334]\n",
      "epoch:12 step:9740 [D loss: 0.434564, acc: 85.94%] [G loss: 2.101728]\n",
      "epoch:12 step:9741 [D loss: 0.289688, acc: 96.09%] [G loss: 2.351092]\n",
      "epoch:12 step:9742 [D loss: 0.638899, acc: 64.84%] [G loss: 2.286799]\n",
      "epoch:12 step:9743 [D loss: 0.453158, acc: 86.72%] [G loss: 2.388555]\n",
      "epoch:12 step:9744 [D loss: 0.453953, acc: 81.25%] [G loss: 2.597181]\n",
      "epoch:12 step:9745 [D loss: 0.765549, acc: 53.12%] [G loss: 1.811272]\n",
      "epoch:12 step:9746 [D loss: 0.144541, acc: 100.00%] [G loss: 3.337759]\n",
      "epoch:12 step:9747 [D loss: 0.883543, acc: 46.88%] [G loss: 1.911628]\n",
      "epoch:12 step:9748 [D loss: 0.489700, acc: 75.00%] [G loss: 1.958714]\n",
      "epoch:12 step:9749 [D loss: 0.353390, acc: 92.19%] [G loss: 2.586976]\n",
      "epoch:12 step:9750 [D loss: 0.742641, acc: 46.09%] [G loss: 2.174650]\n",
      "epoch:12 step:9751 [D loss: 0.482413, acc: 83.59%] [G loss: 3.098595]\n",
      "epoch:12 step:9752 [D loss: 0.638737, acc: 63.28%] [G loss: 1.639973]\n",
      "epoch:12 step:9753 [D loss: 0.502590, acc: 82.03%] [G loss: 3.546467]\n",
      "epoch:12 step:9754 [D loss: 0.675758, acc: 53.12%] [G loss: 1.891514]\n",
      "epoch:12 step:9755 [D loss: 0.410150, acc: 92.97%] [G loss: 3.135739]\n",
      "epoch:12 step:9756 [D loss: 0.566597, acc: 68.75%] [G loss: 2.289552]\n",
      "epoch:12 step:9757 [D loss: 0.503517, acc: 82.03%] [G loss: 2.384241]\n",
      "epoch:12 step:9758 [D loss: 1.042203, acc: 17.19%] [G loss: 1.708870]\n",
      "epoch:12 step:9759 [D loss: 0.377804, acc: 87.50%] [G loss: 2.281374]\n",
      "epoch:12 step:9760 [D loss: 0.951434, acc: 32.81%] [G loss: 1.954006]\n",
      "epoch:12 step:9761 [D loss: 0.525383, acc: 74.22%] [G loss: 2.437238]\n",
      "epoch:12 step:9762 [D loss: 0.506478, acc: 81.25%] [G loss: 2.678444]\n",
      "epoch:12 step:9763 [D loss: 1.433887, acc: 8.59%] [G loss: 1.754319]\n",
      "epoch:12 step:9764 [D loss: 0.598576, acc: 63.28%] [G loss: 2.072075]\n",
      "epoch:12 step:9765 [D loss: 0.878154, acc: 35.94%] [G loss: 1.972442]\n",
      "epoch:12 step:9766 [D loss: 0.649188, acc: 59.38%] [G loss: 2.297117]\n",
      "epoch:12 step:9767 [D loss: 0.547695, acc: 78.12%] [G loss: 2.277309]\n",
      "epoch:12 step:9768 [D loss: 0.318478, acc: 89.84%] [G loss: 2.824029]\n",
      "epoch:12 step:9769 [D loss: 0.495238, acc: 68.75%] [G loss: 2.403263]\n",
      "epoch:12 step:9770 [D loss: 0.530943, acc: 80.47%] [G loss: 2.081805]\n",
      "epoch:12 step:9771 [D loss: 0.818630, acc: 51.56%] [G loss: 1.992212]\n",
      "epoch:12 step:9772 [D loss: 0.509794, acc: 73.44%] [G loss: 2.697909]\n",
      "epoch:12 step:9773 [D loss: 0.599827, acc: 67.19%] [G loss: 2.862558]\n",
      "epoch:12 step:9774 [D loss: 0.639702, acc: 64.06%] [G loss: 1.894071]\n",
      "epoch:12 step:9775 [D loss: 0.493995, acc: 75.78%] [G loss: 2.808013]\n",
      "epoch:12 step:9776 [D loss: 0.299983, acc: 96.88%] [G loss: 2.152873]\n",
      "epoch:12 step:9777 [D loss: 0.396283, acc: 89.84%] [G loss: 2.808592]\n",
      "epoch:12 step:9778 [D loss: 0.475346, acc: 86.72%] [G loss: 3.565048]\n",
      "epoch:12 step:9779 [D loss: 0.619639, acc: 69.53%] [G loss: 2.438987]\n",
      "epoch:12 step:9780 [D loss: 0.158760, acc: 97.66%] [G loss: 2.877483]\n",
      "epoch:12 step:9781 [D loss: 0.283668, acc: 96.88%] [G loss: 1.973394]\n",
      "epoch:12 step:9782 [D loss: 0.443911, acc: 85.94%] [G loss: 2.434148]\n",
      "epoch:12 step:9783 [D loss: 0.759515, acc: 44.53%] [G loss: 1.787924]\n",
      "epoch:12 step:9784 [D loss: 0.612977, acc: 65.62%] [G loss: 2.033789]\n",
      "epoch:12 step:9785 [D loss: 0.436317, acc: 90.62%] [G loss: 2.030474]\n",
      "epoch:12 step:9786 [D loss: 1.325283, acc: 8.59%] [G loss: 1.490061]\n",
      "epoch:12 step:9787 [D loss: 0.491887, acc: 78.12%] [G loss: 2.301339]\n",
      "epoch:12 step:9788 [D loss: 0.791803, acc: 53.12%] [G loss: 1.987657]\n",
      "epoch:12 step:9789 [D loss: 0.846200, acc: 39.06%] [G loss: 2.316168]\n",
      "epoch:12 step:9790 [D loss: 1.090375, acc: 14.84%] [G loss: 1.353364]\n",
      "epoch:12 step:9791 [D loss: 0.363330, acc: 89.84%] [G loss: 2.269468]\n",
      "epoch:12 step:9792 [D loss: 0.654705, acc: 61.72%] [G loss: 2.573577]\n",
      "epoch:12 step:9793 [D loss: 0.517513, acc: 80.47%] [G loss: 2.635501]\n",
      "epoch:12 step:9794 [D loss: 0.310008, acc: 98.44%] [G loss: 2.447304]\n",
      "epoch:12 step:9795 [D loss: 0.816645, acc: 42.19%] [G loss: 2.047911]\n",
      "epoch:12 step:9796 [D loss: 0.602314, acc: 65.62%] [G loss: 2.076568]\n",
      "epoch:12 step:9797 [D loss: 0.569014, acc: 71.09%] [G loss: 2.026780]\n",
      "epoch:12 step:9798 [D loss: 0.487840, acc: 75.00%] [G loss: 2.140422]\n",
      "epoch:12 step:9799 [D loss: 0.727214, acc: 48.44%] [G loss: 1.819007]\n",
      "epoch:12 step:9800 [D loss: 0.723611, acc: 56.25%] [G loss: 2.463025]\n",
      "##############\n",
      "[0.85151796 0.8764186  0.80523686 0.82508139 0.77272101 0.82732391\n",
      " 0.86620893 0.79585589 0.79996571 0.81882447]\n",
      "##########\n",
      "epoch:12 step:9801 [D loss: 0.632141, acc: 58.59%] [G loss: 2.587551]\n",
      "epoch:12 step:9802 [D loss: 0.722879, acc: 52.34%] [G loss: 1.932925]\n",
      "epoch:12 step:9803 [D loss: 0.671237, acc: 63.28%] [G loss: 1.917884]\n",
      "epoch:12 step:9804 [D loss: 0.539291, acc: 79.69%] [G loss: 1.871909]\n",
      "epoch:12 step:9805 [D loss: 0.267627, acc: 94.53%] [G loss: 3.256800]\n",
      "epoch:12 step:9806 [D loss: 0.493285, acc: 85.94%] [G loss: 2.684743]\n",
      "epoch:12 step:9807 [D loss: 0.547829, acc: 75.00%] [G loss: 2.015182]\n",
      "epoch:12 step:9808 [D loss: 0.976644, acc: 25.78%] [G loss: 1.952127]\n",
      "epoch:12 step:9809 [D loss: 0.543953, acc: 73.44%] [G loss: 2.338090]\n",
      "epoch:12 step:9810 [D loss: 0.571719, acc: 69.53%] [G loss: 2.098928]\n",
      "epoch:12 step:9811 [D loss: 0.474748, acc: 85.94%] [G loss: 2.421595]\n",
      "epoch:12 step:9812 [D loss: 0.268985, acc: 98.44%] [G loss: 2.330844]\n",
      "epoch:12 step:9813 [D loss: 0.462733, acc: 88.28%] [G loss: 2.516414]\n",
      "epoch:12 step:9814 [D loss: 0.727566, acc: 50.78%] [G loss: 2.093796]\n",
      "epoch:12 step:9815 [D loss: 0.582136, acc: 64.06%] [G loss: 2.387802]\n",
      "epoch:12 step:9816 [D loss: 0.441915, acc: 84.38%] [G loss: 2.668803]\n",
      "epoch:12 step:9817 [D loss: 0.446287, acc: 82.03%] [G loss: 1.989593]\n",
      "epoch:12 step:9818 [D loss: 0.456374, acc: 85.94%] [G loss: 2.412802]\n",
      "epoch:12 step:9819 [D loss: 0.668747, acc: 61.72%] [G loss: 1.796555]\n",
      "epoch:12 step:9820 [D loss: 0.319297, acc: 96.09%] [G loss: 2.380710]\n",
      "epoch:12 step:9821 [D loss: 0.955042, acc: 38.28%] [G loss: 2.287366]\n",
      "epoch:12 step:9822 [D loss: 0.483056, acc: 84.38%] [G loss: 2.269798]\n",
      "epoch:12 step:9823 [D loss: 0.465371, acc: 82.81%] [G loss: 3.069549]\n",
      "epoch:12 step:9824 [D loss: 0.844806, acc: 44.53%] [G loss: 2.191375]\n",
      "epoch:12 step:9825 [D loss: 0.687373, acc: 59.38%] [G loss: 1.750896]\n",
      "epoch:12 step:9826 [D loss: 0.419398, acc: 78.12%] [G loss: 1.671059]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:12 step:9827 [D loss: 0.833457, acc: 41.41%] [G loss: 1.968612]\n",
      "epoch:12 step:9828 [D loss: 0.998760, acc: 40.62%] [G loss: 1.696185]\n",
      "epoch:12 step:9829 [D loss: 0.641208, acc: 65.62%] [G loss: 2.021911]\n",
      "epoch:12 step:9830 [D loss: 0.594599, acc: 71.88%] [G loss: 1.793020]\n",
      "epoch:12 step:9831 [D loss: 0.788353, acc: 48.44%] [G loss: 2.127120]\n",
      "epoch:12 step:9832 [D loss: 0.718972, acc: 55.47%] [G loss: 1.886305]\n",
      "epoch:12 step:9833 [D loss: 0.952291, acc: 27.34%] [G loss: 2.082507]\n",
      "epoch:12 step:9834 [D loss: 0.874136, acc: 36.72%] [G loss: 2.082997]\n",
      "epoch:12 step:9835 [D loss: 0.353128, acc: 85.94%] [G loss: 2.054116]\n",
      "epoch:12 step:9836 [D loss: 0.893510, acc: 46.09%] [G loss: 2.166183]\n",
      "epoch:12 step:9837 [D loss: 0.508090, acc: 79.69%] [G loss: 2.375729]\n",
      "epoch:12 step:9838 [D loss: 0.640255, acc: 61.72%] [G loss: 1.827003]\n",
      "epoch:12 step:9839 [D loss: 0.612865, acc: 64.06%] [G loss: 2.187332]\n",
      "epoch:12 step:9840 [D loss: 0.878214, acc: 35.16%] [G loss: 2.019569]\n",
      "epoch:12 step:9841 [D loss: 0.468692, acc: 80.47%] [G loss: 2.355436]\n",
      "epoch:12 step:9842 [D loss: 1.029995, acc: 49.22%] [G loss: 2.401505]\n",
      "epoch:12 step:9843 [D loss: 0.683050, acc: 60.94%] [G loss: 2.420687]\n",
      "epoch:12 step:9844 [D loss: 0.680253, acc: 57.03%] [G loss: 2.373922]\n",
      "epoch:12 step:9845 [D loss: 0.625134, acc: 63.28%] [G loss: 2.051095]\n",
      "epoch:12 step:9846 [D loss: 0.484253, acc: 85.94%] [G loss: 2.444817]\n",
      "epoch:12 step:9847 [D loss: 0.643505, acc: 59.38%] [G loss: 2.176824]\n",
      "epoch:12 step:9848 [D loss: 0.570145, acc: 74.22%] [G loss: 2.635738]\n",
      "epoch:12 step:9849 [D loss: 0.303856, acc: 92.97%] [G loss: 3.022140]\n",
      "epoch:12 step:9850 [D loss: 0.314069, acc: 89.84%] [G loss: 3.200117]\n",
      "epoch:12 step:9851 [D loss: 0.493708, acc: 82.03%] [G loss: 2.185064]\n",
      "epoch:12 step:9852 [D loss: 0.538773, acc: 64.84%] [G loss: 2.238827]\n",
      "epoch:12 step:9853 [D loss: 0.581666, acc: 70.31%] [G loss: 2.177275]\n",
      "epoch:12 step:9854 [D loss: 0.919573, acc: 26.56%] [G loss: 1.809627]\n",
      "epoch:12 step:9855 [D loss: 0.295325, acc: 98.44%] [G loss: 2.023573]\n",
      "epoch:12 step:9856 [D loss: 0.692097, acc: 59.38%] [G loss: 1.902741]\n",
      "epoch:12 step:9857 [D loss: 0.289344, acc: 97.66%] [G loss: 2.156296]\n",
      "epoch:12 step:9858 [D loss: 0.720796, acc: 56.25%] [G loss: 1.740106]\n",
      "epoch:12 step:9859 [D loss: 0.712779, acc: 50.78%] [G loss: 1.743032]\n",
      "epoch:12 step:9860 [D loss: 0.624373, acc: 69.53%] [G loss: 1.828287]\n",
      "epoch:12 step:9861 [D loss: 0.813217, acc: 42.19%] [G loss: 1.511354]\n",
      "epoch:12 step:9862 [D loss: 0.900450, acc: 34.38%] [G loss: 1.866068]\n",
      "epoch:12 step:9863 [D loss: 0.734229, acc: 50.00%] [G loss: 1.752011]\n",
      "epoch:12 step:9864 [D loss: 0.840628, acc: 43.75%] [G loss: 1.826453]\n",
      "epoch:12 step:9865 [D loss: 0.712271, acc: 54.69%] [G loss: 2.182708]\n",
      "epoch:12 step:9866 [D loss: 0.635276, acc: 67.97%] [G loss: 1.752466]\n",
      "epoch:12 step:9867 [D loss: 0.622995, acc: 68.75%] [G loss: 1.560035]\n",
      "epoch:12 step:9868 [D loss: 0.739672, acc: 53.12%] [G loss: 1.913373]\n",
      "epoch:12 step:9869 [D loss: 0.690307, acc: 57.03%] [G loss: 2.189224]\n",
      "epoch:12 step:9870 [D loss: 0.694142, acc: 57.81%] [G loss: 1.828295]\n",
      "epoch:12 step:9871 [D loss: 0.769062, acc: 43.75%] [G loss: 2.427556]\n",
      "epoch:12 step:9872 [D loss: 0.326683, acc: 94.53%] [G loss: 3.627954]\n",
      "epoch:12 step:9873 [D loss: 0.644260, acc: 57.03%] [G loss: 2.409383]\n",
      "epoch:12 step:9874 [D loss: 0.550316, acc: 75.78%] [G loss: 2.449765]\n",
      "epoch:12 step:9875 [D loss: 0.389643, acc: 89.06%] [G loss: 2.298960]\n",
      "epoch:12 step:9876 [D loss: 0.647916, acc: 59.38%] [G loss: 2.016594]\n",
      "epoch:12 step:9877 [D loss: 0.605196, acc: 71.09%] [G loss: 2.014547]\n",
      "epoch:12 step:9878 [D loss: 0.429984, acc: 87.50%] [G loss: 2.456300]\n",
      "epoch:12 step:9879 [D loss: 0.760757, acc: 44.53%] [G loss: 2.060386]\n",
      "epoch:12 step:9880 [D loss: 0.606089, acc: 64.84%] [G loss: 2.283914]\n",
      "epoch:12 step:9881 [D loss: 0.422518, acc: 85.94%] [G loss: 2.696397]\n",
      "epoch:12 step:9882 [D loss: 0.406304, acc: 82.81%] [G loss: 2.053602]\n",
      "epoch:12 step:9883 [D loss: 0.559510, acc: 68.75%] [G loss: 2.447910]\n",
      "epoch:12 step:9884 [D loss: 0.624920, acc: 64.84%] [G loss: 2.408455]\n",
      "epoch:12 step:9885 [D loss: 0.705897, acc: 56.25%] [G loss: 2.119030]\n",
      "epoch:12 step:9886 [D loss: 0.718692, acc: 56.25%] [G loss: 1.819800]\n",
      "epoch:12 step:9887 [D loss: 0.446488, acc: 90.62%] [G loss: 2.303588]\n",
      "epoch:12 step:9888 [D loss: 0.350571, acc: 92.19%] [G loss: 2.187886]\n",
      "epoch:12 step:9889 [D loss: 0.970735, acc: 21.09%] [G loss: 1.572785]\n",
      "epoch:12 step:9890 [D loss: 0.532790, acc: 78.12%] [G loss: 2.423276]\n",
      "epoch:12 step:9891 [D loss: 0.831096, acc: 48.44%] [G loss: 1.805053]\n",
      "epoch:12 step:9892 [D loss: 0.439249, acc: 82.81%] [G loss: 2.266274]\n",
      "epoch:12 step:9893 [D loss: 0.405860, acc: 89.84%] [G loss: 2.173990]\n",
      "epoch:12 step:9894 [D loss: 0.656821, acc: 65.62%] [G loss: 1.825752]\n",
      "epoch:12 step:9895 [D loss: 1.048162, acc: 13.28%] [G loss: 1.693919]\n",
      "epoch:12 step:9896 [D loss: 0.298044, acc: 94.53%] [G loss: 2.046293]\n",
      "epoch:12 step:9897 [D loss: 0.714086, acc: 50.00%] [G loss: 1.841696]\n",
      "epoch:12 step:9898 [D loss: 1.240349, acc: 8.59%] [G loss: 1.724247]\n",
      "epoch:12 step:9899 [D loss: 0.973117, acc: 25.78%] [G loss: 1.824846]\n",
      "epoch:12 step:9900 [D loss: 0.677680, acc: 60.94%] [G loss: 1.857560]\n",
      "epoch:12 step:9901 [D loss: 0.667631, acc: 57.03%] [G loss: 1.827477]\n",
      "epoch:12 step:9902 [D loss: 0.610800, acc: 64.84%] [G loss: 2.252593]\n",
      "epoch:12 step:9903 [D loss: 0.818493, acc: 49.22%] [G loss: 1.484978]\n",
      "epoch:12 step:9904 [D loss: 0.652792, acc: 55.47%] [G loss: 2.156965]\n",
      "epoch:12 step:9905 [D loss: 0.776186, acc: 46.09%] [G loss: 2.043265]\n",
      "epoch:12 step:9906 [D loss: 0.749922, acc: 48.44%] [G loss: 2.190652]\n",
      "epoch:12 step:9907 [D loss: 0.686183, acc: 55.47%] [G loss: 2.156778]\n",
      "epoch:12 step:9908 [D loss: 0.431149, acc: 89.84%] [G loss: 2.133514]\n",
      "epoch:12 step:9909 [D loss: 0.483737, acc: 79.69%] [G loss: 2.366446]\n",
      "epoch:12 step:9910 [D loss: 0.390441, acc: 92.97%] [G loss: 2.293957]\n",
      "epoch:12 step:9911 [D loss: 0.651498, acc: 60.94%] [G loss: 1.582076]\n",
      "epoch:12 step:9912 [D loss: 0.710654, acc: 51.56%] [G loss: 2.208694]\n",
      "epoch:12 step:9913 [D loss: 0.248217, acc: 96.88%] [G loss: 2.165241]\n",
      "epoch:12 step:9914 [D loss: 0.698646, acc: 54.69%] [G loss: 2.481768]\n",
      "epoch:12 step:9915 [D loss: 0.685572, acc: 60.94%] [G loss: 2.052752]\n",
      "epoch:12 step:9916 [D loss: 0.633108, acc: 59.38%] [G loss: 2.606663]\n",
      "epoch:12 step:9917 [D loss: 0.889376, acc: 39.84%] [G loss: 2.126422]\n",
      "epoch:12 step:9918 [D loss: 0.432413, acc: 78.12%] [G loss: 2.953346]\n",
      "epoch:12 step:9919 [D loss: 0.584491, acc: 64.06%] [G loss: 2.104991]\n",
      "epoch:12 step:9920 [D loss: 0.720023, acc: 55.47%] [G loss: 1.864770]\n",
      "epoch:12 step:9921 [D loss: 0.421237, acc: 91.41%] [G loss: 2.314207]\n",
      "epoch:12 step:9922 [D loss: 0.532144, acc: 71.88%] [G loss: 2.427041]\n",
      "epoch:12 step:9923 [D loss: 0.551845, acc: 75.00%] [G loss: 2.356026]\n",
      "epoch:12 step:9924 [D loss: 1.016395, acc: 22.66%] [G loss: 1.682947]\n",
      "epoch:12 step:9925 [D loss: 0.561047, acc: 66.41%] [G loss: 2.129441]\n",
      "epoch:12 step:9926 [D loss: 0.576170, acc: 66.41%] [G loss: 2.566602]\n",
      "epoch:12 step:9927 [D loss: 0.604012, acc: 67.19%] [G loss: 1.935629]\n",
      "epoch:12 step:9928 [D loss: 0.483844, acc: 85.94%] [G loss: 2.562459]\n",
      "epoch:12 step:9929 [D loss: 0.599169, acc: 70.31%] [G loss: 2.057383]\n",
      "epoch:12 step:9930 [D loss: 0.363540, acc: 92.97%] [G loss: 2.178979]\n",
      "epoch:12 step:9931 [D loss: 0.490358, acc: 82.03%] [G loss: 2.446064]\n",
      "epoch:12 step:9932 [D loss: 0.479803, acc: 67.97%] [G loss: 2.304561]\n",
      "epoch:12 step:9933 [D loss: 0.470654, acc: 85.16%] [G loss: 2.439252]\n",
      "epoch:12 step:9934 [D loss: 0.828288, acc: 50.00%] [G loss: 1.676159]\n",
      "epoch:12 step:9935 [D loss: 0.347005, acc: 92.19%] [G loss: 3.120498]\n",
      "epoch:12 step:9936 [D loss: 0.590202, acc: 73.44%] [G loss: 1.891151]\n",
      "epoch:12 step:9937 [D loss: 0.718063, acc: 46.88%] [G loss: 1.878040]\n",
      "epoch:12 step:9938 [D loss: 0.478216, acc: 72.66%] [G loss: 1.913297]\n",
      "epoch:12 step:9939 [D loss: 1.159570, acc: 12.50%] [G loss: 1.498399]\n",
      "epoch:12 step:9940 [D loss: 0.422182, acc: 81.25%] [G loss: 2.754870]\n",
      "epoch:12 step:9941 [D loss: 0.411601, acc: 82.03%] [G loss: 2.254072]\n",
      "epoch:12 step:9942 [D loss: 0.762560, acc: 50.00%] [G loss: 1.697397]\n",
      "epoch:12 step:9943 [D loss: 0.857857, acc: 48.44%] [G loss: 2.023266]\n",
      "epoch:12 step:9944 [D loss: 0.550015, acc: 75.78%] [G loss: 2.182317]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:12 step:9945 [D loss: 0.642942, acc: 67.19%] [G loss: 2.072595]\n",
      "epoch:12 step:9946 [D loss: 0.565218, acc: 71.09%] [G loss: 1.805640]\n",
      "epoch:12 step:9947 [D loss: 0.936738, acc: 46.09%] [G loss: 1.570665]\n",
      "epoch:12 step:9948 [D loss: 0.540927, acc: 78.12%] [G loss: 1.980638]\n",
      "epoch:12 step:9949 [D loss: 0.610507, acc: 66.41%] [G loss: 2.011084]\n",
      "epoch:12 step:9950 [D loss: 0.535308, acc: 78.91%] [G loss: 1.875937]\n",
      "epoch:12 step:9951 [D loss: 0.706005, acc: 51.56%] [G loss: 2.174682]\n",
      "epoch:12 step:9952 [D loss: 0.602208, acc: 65.62%] [G loss: 2.293968]\n",
      "epoch:12 step:9953 [D loss: 0.386272, acc: 93.75%] [G loss: 2.566133]\n",
      "epoch:12 step:9954 [D loss: 0.944439, acc: 42.97%] [G loss: 1.823305]\n",
      "epoch:12 step:9955 [D loss: 0.418493, acc: 86.72%] [G loss: 1.681540]\n",
      "epoch:12 step:9956 [D loss: 0.855572, acc: 40.62%] [G loss: 1.866443]\n",
      "epoch:12 step:9957 [D loss: 0.519899, acc: 78.12%] [G loss: 2.416464]\n",
      "epoch:12 step:9958 [D loss: 0.833568, acc: 37.50%] [G loss: 1.641781]\n",
      "epoch:12 step:9959 [D loss: 0.588803, acc: 74.22%] [G loss: 2.083166]\n",
      "epoch:12 step:9960 [D loss: 0.801965, acc: 41.41%] [G loss: 2.489091]\n",
      "epoch:12 step:9961 [D loss: 0.533677, acc: 68.75%] [G loss: 2.170234]\n",
      "epoch:12 step:9962 [D loss: 0.458280, acc: 85.16%] [G loss: 2.774830]\n",
      "epoch:12 step:9963 [D loss: 0.329764, acc: 96.09%] [G loss: 2.195570]\n",
      "epoch:12 step:9964 [D loss: 0.587531, acc: 64.84%] [G loss: 1.756558]\n",
      "epoch:12 step:9965 [D loss: 0.872469, acc: 50.00%] [G loss: 1.904604]\n",
      "epoch:12 step:9966 [D loss: 1.012118, acc: 34.38%] [G loss: 1.518095]\n",
      "epoch:12 step:9967 [D loss: 0.724505, acc: 53.12%] [G loss: 2.606024]\n",
      "epoch:12 step:9968 [D loss: 0.847459, acc: 41.41%] [G loss: 2.150510]\n",
      "epoch:12 step:9969 [D loss: 0.722744, acc: 50.00%] [G loss: 1.861651]\n",
      "epoch:12 step:9970 [D loss: 0.753375, acc: 49.22%] [G loss: 2.284074]\n",
      "epoch:12 step:9971 [D loss: 0.359429, acc: 85.94%] [G loss: 2.586243]\n",
      "epoch:12 step:9972 [D loss: 0.714141, acc: 55.47%] [G loss: 1.776072]\n",
      "epoch:12 step:9973 [D loss: 0.531712, acc: 68.75%] [G loss: 2.441667]\n",
      "epoch:12 step:9974 [D loss: 0.762140, acc: 50.00%] [G loss: 2.232796]\n",
      "epoch:12 step:9975 [D loss: 0.723822, acc: 53.91%] [G loss: 1.608363]\n",
      "epoch:12 step:9976 [D loss: 0.659164, acc: 60.94%] [G loss: 1.746962]\n",
      "epoch:12 step:9977 [D loss: 0.757052, acc: 44.53%] [G loss: 2.014611]\n",
      "epoch:12 step:9978 [D loss: 0.778982, acc: 47.66%] [G loss: 2.379970]\n",
      "epoch:12 step:9979 [D loss: 0.746784, acc: 45.31%] [G loss: 1.633792]\n",
      "epoch:12 step:9980 [D loss: 0.559416, acc: 70.31%] [G loss: 2.362145]\n",
      "epoch:12 step:9981 [D loss: 0.529656, acc: 73.44%] [G loss: 1.821039]\n",
      "epoch:12 step:9982 [D loss: 0.451535, acc: 82.81%] [G loss: 2.824223]\n",
      "epoch:12 step:9983 [D loss: 0.750855, acc: 48.44%] [G loss: 1.959437]\n",
      "epoch:12 step:9984 [D loss: 0.417169, acc: 89.06%] [G loss: 1.910574]\n",
      "epoch:12 step:9985 [D loss: 0.463054, acc: 79.69%] [G loss: 3.289988]\n",
      "epoch:12 step:9986 [D loss: 0.541713, acc: 78.12%] [G loss: 1.637688]\n",
      "epoch:12 step:9987 [D loss: 0.616041, acc: 68.75%] [G loss: 1.945814]\n",
      "epoch:12 step:9988 [D loss: 0.901689, acc: 35.94%] [G loss: 1.925776]\n",
      "epoch:12 step:9989 [D loss: 0.771928, acc: 40.62%] [G loss: 1.942077]\n",
      "epoch:12 step:9990 [D loss: 0.361246, acc: 95.31%] [G loss: 2.201943]\n",
      "epoch:12 step:9991 [D loss: 0.980101, acc: 25.00%] [G loss: 1.995293]\n",
      "epoch:12 step:9992 [D loss: 0.566572, acc: 68.75%] [G loss: 2.898301]\n",
      "epoch:12 step:9993 [D loss: 0.992998, acc: 25.78%] [G loss: 1.829884]\n",
      "epoch:12 step:9994 [D loss: 0.480546, acc: 78.12%] [G loss: 3.649652]\n",
      "epoch:12 step:9995 [D loss: 0.477267, acc: 86.72%] [G loss: 2.731799]\n",
      "epoch:12 step:9996 [D loss: 0.415816, acc: 93.75%] [G loss: 2.919199]\n",
      "epoch:12 step:9997 [D loss: 0.636751, acc: 67.19%] [G loss: 2.059448]\n",
      "epoch:12 step:9998 [D loss: 0.723355, acc: 49.22%] [G loss: 2.346216]\n",
      "epoch:12 step:9999 [D loss: 0.667408, acc: 56.25%] [G loss: 2.482924]\n",
      "epoch:12 step:10000 [D loss: 0.674169, acc: 56.25%] [G loss: 1.713442]\n",
      "##############\n",
      "[0.87130198 0.86320542 0.82063479 0.80739942 0.79341503 0.8207594\n",
      " 0.89715217 0.810188   0.82964153 0.84804562]\n",
      "##########\n",
      "epoch:12 step:10001 [D loss: 0.922294, acc: 30.47%] [G loss: 2.243657]\n",
      "epoch:12 step:10002 [D loss: 0.560504, acc: 76.56%] [G loss: 1.767426]\n",
      "epoch:12 step:10003 [D loss: 0.513389, acc: 81.25%] [G loss: 2.161711]\n",
      "epoch:12 step:10004 [D loss: 0.914066, acc: 23.44%] [G loss: 1.577308]\n",
      "epoch:12 step:10005 [D loss: 0.681717, acc: 57.81%] [G loss: 2.010391]\n",
      "epoch:12 step:10006 [D loss: 0.423133, acc: 85.16%] [G loss: 2.062623]\n",
      "epoch:12 step:10007 [D loss: 0.553339, acc: 77.34%] [G loss: 1.810141]\n",
      "epoch:12 step:10008 [D loss: 0.650024, acc: 60.94%] [G loss: 2.137506]\n",
      "epoch:12 step:10009 [D loss: 0.482383, acc: 83.59%] [G loss: 2.091919]\n",
      "epoch:12 step:10010 [D loss: 0.420444, acc: 91.41%] [G loss: 2.540570]\n",
      "epoch:12 step:10011 [D loss: 0.752948, acc: 53.91%] [G loss: 1.951889]\n",
      "epoch:12 step:10012 [D loss: 0.377293, acc: 92.97%] [G loss: 2.381355]\n",
      "epoch:12 step:10013 [D loss: 0.342174, acc: 95.31%] [G loss: 2.526364]\n",
      "epoch:12 step:10014 [D loss: 0.915338, acc: 42.19%] [G loss: 1.456842]\n",
      "epoch:12 step:10015 [D loss: 0.297210, acc: 96.88%] [G loss: 2.299302]\n",
      "epoch:12 step:10016 [D loss: 0.396998, acc: 94.53%] [G loss: 2.158113]\n",
      "epoch:12 step:10017 [D loss: 0.384563, acc: 85.94%] [G loss: 2.084435]\n",
      "epoch:12 step:10018 [D loss: 0.921122, acc: 28.12%] [G loss: 1.686360]\n",
      "epoch:12 step:10019 [D loss: 0.531935, acc: 63.28%] [G loss: 1.601216]\n",
      "epoch:12 step:10020 [D loss: 0.646313, acc: 54.69%] [G loss: 1.887045]\n",
      "epoch:12 step:10021 [D loss: 0.696925, acc: 53.12%] [G loss: 1.636317]\n",
      "epoch:12 step:10022 [D loss: 0.324672, acc: 96.88%] [G loss: 2.870269]\n",
      "epoch:12 step:10023 [D loss: 0.863153, acc: 35.94%] [G loss: 2.550314]\n",
      "epoch:12 step:10024 [D loss: 0.591219, acc: 67.97%] [G loss: 1.835652]\n",
      "epoch:12 step:10025 [D loss: 0.542290, acc: 78.12%] [G loss: 2.431904]\n",
      "epoch:12 step:10026 [D loss: 0.593930, acc: 68.75%] [G loss: 2.033937]\n",
      "epoch:12 step:10027 [D loss: 0.393286, acc: 90.62%] [G loss: 2.216637]\n",
      "epoch:12 step:10028 [D loss: 0.857286, acc: 51.56%] [G loss: 2.137364]\n",
      "epoch:12 step:10029 [D loss: 0.579119, acc: 64.84%] [G loss: 2.403587]\n",
      "epoch:12 step:10030 [D loss: 0.617281, acc: 68.75%] [G loss: 1.853661]\n",
      "epoch:12 step:10031 [D loss: 0.777445, acc: 50.00%] [G loss: 2.110346]\n",
      "epoch:12 step:10032 [D loss: 0.867256, acc: 35.16%] [G loss: 2.023581]\n",
      "epoch:12 step:10033 [D loss: 0.579074, acc: 64.84%] [G loss: 2.190870]\n",
      "epoch:12 step:10034 [D loss: 0.501777, acc: 74.22%] [G loss: 2.271442]\n",
      "epoch:12 step:10035 [D loss: 0.715037, acc: 54.69%] [G loss: 1.920210]\n",
      "epoch:12 step:10036 [D loss: 0.472638, acc: 82.03%] [G loss: 3.369383]\n",
      "epoch:12 step:10037 [D loss: 0.836086, acc: 50.78%] [G loss: 1.542692]\n",
      "epoch:12 step:10038 [D loss: 0.261557, acc: 99.22%] [G loss: 2.282214]\n",
      "epoch:12 step:10039 [D loss: 0.561893, acc: 67.97%] [G loss: 2.082250]\n",
      "epoch:12 step:10040 [D loss: 0.467662, acc: 82.81%] [G loss: 1.771714]\n",
      "epoch:12 step:10041 [D loss: 1.503724, acc: 4.69%] [G loss: 1.236358]\n",
      "epoch:12 step:10042 [D loss: 0.526368, acc: 78.12%] [G loss: 2.421528]\n",
      "epoch:12 step:10043 [D loss: 0.666151, acc: 57.81%] [G loss: 2.042556]\n",
      "epoch:12 step:10044 [D loss: 0.832332, acc: 37.50%] [G loss: 2.085764]\n",
      "epoch:12 step:10045 [D loss: 0.460672, acc: 82.03%] [G loss: 1.940998]\n",
      "epoch:12 step:10046 [D loss: 0.315277, acc: 96.09%] [G loss: 2.948591]\n",
      "epoch:12 step:10047 [D loss: 0.700714, acc: 55.47%] [G loss: 2.277492]\n",
      "epoch:12 step:10048 [D loss: 0.683874, acc: 56.25%] [G loss: 1.602168]\n",
      "epoch:12 step:10049 [D loss: 0.676095, acc: 60.16%] [G loss: 1.760829]\n",
      "epoch:12 step:10050 [D loss: 0.639557, acc: 61.72%] [G loss: 2.400667]\n",
      "epoch:12 step:10051 [D loss: 0.881884, acc: 31.25%] [G loss: 2.079799]\n",
      "epoch:12 step:10052 [D loss: 0.548581, acc: 73.44%] [G loss: 2.620100]\n",
      "epoch:12 step:10053 [D loss: 0.314680, acc: 93.75%] [G loss: 2.678905]\n",
      "epoch:12 step:10054 [D loss: 0.803601, acc: 46.09%] [G loss: 2.519907]\n",
      "epoch:12 step:10055 [D loss: 0.575026, acc: 69.53%] [G loss: 2.302289]\n",
      "epoch:12 step:10056 [D loss: 0.697317, acc: 56.25%] [G loss: 2.847571]\n",
      "epoch:12 step:10057 [D loss: 0.300597, acc: 89.06%] [G loss: 2.479221]\n",
      "epoch:12 step:10058 [D loss: 1.306555, acc: 14.06%] [G loss: 2.396938]\n",
      "epoch:12 step:10059 [D loss: 0.497104, acc: 78.91%] [G loss: 1.933916]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:12 step:10060 [D loss: 0.300092, acc: 95.31%] [G loss: 2.705194]\n",
      "epoch:12 step:10061 [D loss: 0.979770, acc: 35.94%] [G loss: 2.003892]\n",
      "epoch:12 step:10062 [D loss: 0.401978, acc: 91.41%] [G loss: 2.533676]\n",
      "epoch:12 step:10063 [D loss: 0.612735, acc: 65.62%] [G loss: 1.964068]\n",
      "epoch:12 step:10064 [D loss: 1.338332, acc: 13.28%] [G loss: 1.695291]\n",
      "epoch:12 step:10065 [D loss: 0.669150, acc: 60.94%] [G loss: 1.938759]\n",
      "epoch:12 step:10066 [D loss: 0.287394, acc: 98.44%] [G loss: 2.379998]\n",
      "epoch:12 step:10067 [D loss: 0.836345, acc: 41.41%] [G loss: 2.038690]\n",
      "epoch:12 step:10068 [D loss: 0.738902, acc: 50.78%] [G loss: 3.116314]\n",
      "epoch:12 step:10069 [D loss: 1.146918, acc: 14.84%] [G loss: 1.374215]\n",
      "epoch:12 step:10070 [D loss: 0.376877, acc: 75.78%] [G loss: 2.040602]\n",
      "epoch:12 step:10071 [D loss: 0.416470, acc: 88.28%] [G loss: 2.362391]\n",
      "epoch:12 step:10072 [D loss: 0.636796, acc: 61.72%] [G loss: 1.691572]\n",
      "epoch:12 step:10073 [D loss: 0.619017, acc: 64.06%] [G loss: 2.161328]\n",
      "epoch:12 step:10074 [D loss: 0.704880, acc: 53.12%] [G loss: 1.670121]\n",
      "epoch:12 step:10075 [D loss: 0.293485, acc: 96.88%] [G loss: 1.754486]\n",
      "epoch:12 step:10076 [D loss: 0.434212, acc: 87.50%] [G loss: 2.063257]\n",
      "epoch:12 step:10077 [D loss: 1.110149, acc: 13.28%] [G loss: 1.899341]\n",
      "epoch:12 step:10078 [D loss: 0.526965, acc: 82.03%] [G loss: 1.999360]\n",
      "epoch:12 step:10079 [D loss: 0.544173, acc: 74.22%] [G loss: 2.038075]\n",
      "epoch:12 step:10080 [D loss: 0.946523, acc: 25.78%] [G loss: 1.730676]\n",
      "epoch:12 step:10081 [D loss: 0.583903, acc: 68.75%] [G loss: 2.009669]\n",
      "epoch:12 step:10082 [D loss: 0.462671, acc: 81.25%] [G loss: 2.179354]\n",
      "epoch:12 step:10083 [D loss: 0.588003, acc: 64.84%] [G loss: 1.981551]\n",
      "epoch:12 step:10084 [D loss: 0.801138, acc: 43.75%] [G loss: 1.843504]\n",
      "epoch:12 step:10085 [D loss: 0.429722, acc: 94.53%] [G loss: 2.961251]\n",
      "epoch:12 step:10086 [D loss: 0.476614, acc: 71.88%] [G loss: 2.320768]\n",
      "epoch:12 step:10087 [D loss: 0.427647, acc: 92.97%] [G loss: 2.071492]\n",
      "epoch:12 step:10088 [D loss: 0.201921, acc: 98.44%] [G loss: 2.388392]\n",
      "epoch:12 step:10089 [D loss: 0.529566, acc: 69.53%] [G loss: 2.346090]\n",
      "epoch:12 step:10090 [D loss: 0.657448, acc: 64.06%] [G loss: 1.805123]\n",
      "epoch:12 step:10091 [D loss: 0.596744, acc: 64.06%] [G loss: 1.814545]\n",
      "epoch:12 step:10092 [D loss: 0.213387, acc: 97.66%] [G loss: 2.182281]\n",
      "epoch:12 step:10093 [D loss: 0.886501, acc: 31.25%] [G loss: 1.424634]\n",
      "epoch:12 step:10094 [D loss: 0.753384, acc: 52.34%] [G loss: 2.157976]\n",
      "epoch:12 step:10095 [D loss: 0.532982, acc: 78.12%] [G loss: 1.878707]\n",
      "epoch:12 step:10096 [D loss: 0.631844, acc: 63.28%] [G loss: 2.289234]\n",
      "epoch:12 step:10097 [D loss: 0.357704, acc: 92.97%] [G loss: 2.299886]\n",
      "epoch:12 step:10098 [D loss: 0.665269, acc: 55.47%] [G loss: 1.668030]\n",
      "epoch:12 step:10099 [D loss: 0.582642, acc: 74.22%] [G loss: 2.274434]\n",
      "epoch:12 step:10100 [D loss: 0.597265, acc: 70.31%] [G loss: 1.985139]\n",
      "epoch:12 step:10101 [D loss: 0.700481, acc: 54.69%] [G loss: 1.555552]\n",
      "epoch:12 step:10102 [D loss: 0.626898, acc: 57.03%] [G loss: 2.141477]\n",
      "epoch:12 step:10103 [D loss: 0.490090, acc: 76.56%] [G loss: 2.267086]\n",
      "epoch:12 step:10104 [D loss: 0.655700, acc: 62.50%] [G loss: 1.906723]\n",
      "epoch:12 step:10105 [D loss: 0.725185, acc: 52.34%] [G loss: 1.677429]\n",
      "epoch:12 step:10106 [D loss: 0.818905, acc: 35.16%] [G loss: 1.818082]\n",
      "epoch:12 step:10107 [D loss: 0.464674, acc: 90.62%] [G loss: 2.552258]\n",
      "epoch:12 step:10108 [D loss: 0.668983, acc: 61.72%] [G loss: 2.485508]\n",
      "epoch:12 step:10109 [D loss: 0.597323, acc: 66.41%] [G loss: 3.101990]\n",
      "epoch:12 step:10110 [D loss: 0.367294, acc: 85.94%] [G loss: 2.167586]\n",
      "epoch:12 step:10111 [D loss: 0.600569, acc: 62.50%] [G loss: 1.791525]\n",
      "epoch:12 step:10112 [D loss: 0.770431, acc: 50.78%] [G loss: 2.010633]\n",
      "epoch:12 step:10113 [D loss: 0.536999, acc: 63.28%] [G loss: 2.651948]\n",
      "epoch:12 step:10114 [D loss: 0.657045, acc: 62.50%] [G loss: 1.543148]\n",
      "epoch:12 step:10115 [D loss: 0.517716, acc: 76.56%] [G loss: 2.340285]\n",
      "epoch:12 step:10116 [D loss: 0.614155, acc: 58.59%] [G loss: 1.531436]\n",
      "epoch:12 step:10117 [D loss: 0.582273, acc: 63.28%] [G loss: 2.244602]\n",
      "epoch:12 step:10118 [D loss: 0.274653, acc: 96.09%] [G loss: 2.429847]\n",
      "epoch:12 step:10119 [D loss: 0.352468, acc: 93.75%] [G loss: 2.778081]\n",
      "epoch:12 step:10120 [D loss: 0.234919, acc: 100.00%] [G loss: 2.091933]\n",
      "epoch:12 step:10121 [D loss: 0.420302, acc: 91.41%] [G loss: 2.447038]\n",
      "epoch:12 step:10122 [D loss: 0.449445, acc: 89.84%] [G loss: 2.303346]\n",
      "epoch:12 step:10123 [D loss: 0.466385, acc: 85.94%] [G loss: 3.142660]\n",
      "epoch:12 step:10124 [D loss: 0.490629, acc: 75.78%] [G loss: 2.845035]\n",
      "epoch:12 step:10125 [D loss: 0.235481, acc: 97.66%] [G loss: 2.891361]\n",
      "epoch:12 step:10126 [D loss: 0.437710, acc: 85.16%] [G loss: 2.281270]\n",
      "epoch:12 step:10127 [D loss: 1.057411, acc: 19.53%] [G loss: 1.908574]\n",
      "epoch:12 step:10128 [D loss: 0.534344, acc: 78.91%] [G loss: 2.365669]\n",
      "epoch:12 step:10129 [D loss: 0.650497, acc: 64.84%] [G loss: 2.641026]\n",
      "epoch:12 step:10130 [D loss: 0.479273, acc: 79.69%] [G loss: 2.436508]\n",
      "epoch:12 step:10131 [D loss: 0.612907, acc: 66.41%] [G loss: 1.704499]\n",
      "epoch:12 step:10132 [D loss: 0.773433, acc: 46.88%] [G loss: 1.815790]\n",
      "epoch:12 step:10133 [D loss: 0.344659, acc: 91.41%] [G loss: 2.597904]\n",
      "epoch:12 step:10134 [D loss: 0.541240, acc: 79.69%] [G loss: 2.744292]\n",
      "epoch:12 step:10135 [D loss: 0.874287, acc: 31.25%] [G loss: 1.826936]\n",
      "epoch:12 step:10136 [D loss: 0.743937, acc: 59.38%] [G loss: 1.807341]\n",
      "epoch:12 step:10137 [D loss: 0.414497, acc: 79.69%] [G loss: 1.797988]\n",
      "epoch:12 step:10138 [D loss: 0.470529, acc: 82.81%] [G loss: 1.857057]\n",
      "epoch:12 step:10139 [D loss: 0.275716, acc: 94.53%] [G loss: 3.127931]\n",
      "epoch:12 step:10140 [D loss: 0.351709, acc: 89.06%] [G loss: 1.859919]\n",
      "epoch:12 step:10141 [D loss: 0.600405, acc: 70.31%] [G loss: 1.921386]\n",
      "epoch:12 step:10142 [D loss: 0.396236, acc: 92.19%] [G loss: 3.765702]\n",
      "epoch:12 step:10143 [D loss: 0.739719, acc: 55.47%] [G loss: 1.438798]\n",
      "epoch:12 step:10144 [D loss: 0.127492, acc: 100.00%] [G loss: 3.272424]\n",
      "epoch:12 step:10145 [D loss: 0.603786, acc: 65.62%] [G loss: 2.071445]\n",
      "epoch:12 step:10146 [D loss: 0.737035, acc: 57.03%] [G loss: 2.140053]\n",
      "epoch:12 step:10147 [D loss: 0.288716, acc: 88.28%] [G loss: 2.080086]\n",
      "epoch:12 step:10148 [D loss: 0.623388, acc: 65.62%] [G loss: 1.568604]\n",
      "epoch:12 step:10149 [D loss: 1.171153, acc: 26.56%] [G loss: 1.885944]\n",
      "epoch:12 step:10150 [D loss: 0.669980, acc: 57.03%] [G loss: 1.981189]\n",
      "epoch:12 step:10151 [D loss: 0.413566, acc: 75.00%] [G loss: 1.954440]\n",
      "epoch:12 step:10152 [D loss: 0.927610, acc: 32.03%] [G loss: 1.662063]\n",
      "epoch:12 step:10153 [D loss: 0.795172, acc: 40.62%] [G loss: 2.076791]\n",
      "epoch:13 step:10154 [D loss: 0.638376, acc: 63.28%] [G loss: 2.152068]\n",
      "epoch:13 step:10155 [D loss: 0.367508, acc: 85.94%] [G loss: 1.848843]\n",
      "epoch:13 step:10156 [D loss: 0.614690, acc: 66.41%] [G loss: 2.025565]\n",
      "epoch:13 step:10157 [D loss: 0.676724, acc: 59.38%] [G loss: 2.010875]\n",
      "epoch:13 step:10158 [D loss: 0.597997, acc: 67.97%] [G loss: 1.656504]\n",
      "epoch:13 step:10159 [D loss: 0.712218, acc: 51.56%] [G loss: 2.087320]\n",
      "epoch:13 step:10160 [D loss: 0.658352, acc: 59.38%] [G loss: 1.842320]\n",
      "epoch:13 step:10161 [D loss: 0.591424, acc: 73.44%] [G loss: 2.151976]\n",
      "epoch:13 step:10162 [D loss: 0.397262, acc: 95.31%] [G loss: 1.689856]\n",
      "epoch:13 step:10163 [D loss: 0.868330, acc: 46.88%] [G loss: 1.734819]\n",
      "epoch:13 step:10164 [D loss: 0.524409, acc: 75.78%] [G loss: 2.787709]\n",
      "epoch:13 step:10165 [D loss: 0.551337, acc: 60.94%] [G loss: 2.095978]\n",
      "epoch:13 step:10166 [D loss: 0.692714, acc: 58.59%] [G loss: 1.931836]\n",
      "epoch:13 step:10167 [D loss: 1.217933, acc: 9.38%] [G loss: 2.070088]\n",
      "epoch:13 step:10168 [D loss: 0.511836, acc: 75.00%] [G loss: 1.565556]\n",
      "epoch:13 step:10169 [D loss: 0.600841, acc: 69.53%] [G loss: 2.208310]\n",
      "epoch:13 step:10170 [D loss: 0.624624, acc: 60.94%] [G loss: 2.104016]\n",
      "epoch:13 step:10171 [D loss: 0.537804, acc: 78.91%] [G loss: 2.341954]\n",
      "epoch:13 step:10172 [D loss: 0.758877, acc: 46.09%] [G loss: 1.699647]\n",
      "epoch:13 step:10173 [D loss: 0.601109, acc: 64.06%] [G loss: 2.359478]\n",
      "epoch:13 step:10174 [D loss: 0.384610, acc: 95.31%] [G loss: 2.253854]\n",
      "epoch:13 step:10175 [D loss: 0.650684, acc: 54.69%] [G loss: 2.165619]\n",
      "epoch:13 step:10176 [D loss: 0.478919, acc: 82.03%] [G loss: 2.387426]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:13 step:10177 [D loss: 1.023559, acc: 45.31%] [G loss: 2.008449]\n",
      "epoch:13 step:10178 [D loss: 0.662596, acc: 57.03%] [G loss: 2.431611]\n",
      "epoch:13 step:10179 [D loss: 0.556802, acc: 75.78%] [G loss: 2.292665]\n",
      "epoch:13 step:10180 [D loss: 0.400415, acc: 89.06%] [G loss: 2.472241]\n",
      "epoch:13 step:10181 [D loss: 0.724555, acc: 56.25%] [G loss: 2.229330]\n",
      "epoch:13 step:10182 [D loss: 0.253346, acc: 97.66%] [G loss: 3.402612]\n",
      "epoch:13 step:10183 [D loss: 0.733644, acc: 59.38%] [G loss: 1.662833]\n",
      "epoch:13 step:10184 [D loss: 0.627596, acc: 66.41%] [G loss: 2.677077]\n",
      "epoch:13 step:10185 [D loss: 0.353064, acc: 86.72%] [G loss: 2.537828]\n",
      "epoch:13 step:10186 [D loss: 0.517627, acc: 76.56%] [G loss: 1.887379]\n",
      "epoch:13 step:10187 [D loss: 0.355406, acc: 94.53%] [G loss: 2.371773]\n",
      "epoch:13 step:10188 [D loss: 0.970003, acc: 46.88%] [G loss: 1.947999]\n",
      "epoch:13 step:10189 [D loss: 0.299392, acc: 90.62%] [G loss: 3.369335]\n",
      "epoch:13 step:10190 [D loss: 0.277523, acc: 96.09%] [G loss: 3.186019]\n",
      "epoch:13 step:10191 [D loss: 0.580837, acc: 71.88%] [G loss: 2.198383]\n",
      "epoch:13 step:10192 [D loss: 0.953068, acc: 46.09%] [G loss: 1.866803]\n",
      "epoch:13 step:10193 [D loss: 0.900480, acc: 42.19%] [G loss: 2.416571]\n",
      "epoch:13 step:10194 [D loss: 0.359350, acc: 93.75%] [G loss: 2.104537]\n",
      "epoch:13 step:10195 [D loss: 0.310149, acc: 91.41%] [G loss: 2.603154]\n",
      "epoch:13 step:10196 [D loss: 0.475880, acc: 82.03%] [G loss: 2.409233]\n",
      "epoch:13 step:10197 [D loss: 0.714769, acc: 53.12%] [G loss: 2.021430]\n",
      "epoch:13 step:10198 [D loss: 0.456629, acc: 78.12%] [G loss: 1.951962]\n",
      "epoch:13 step:10199 [D loss: 0.450651, acc: 85.94%] [G loss: 2.143749]\n",
      "epoch:13 step:10200 [D loss: 0.231136, acc: 95.31%] [G loss: 2.402974]\n",
      "##############\n",
      "[0.86000625 0.8837925  0.84278518 0.82692313 0.78884544 0.80808841\n",
      " 0.8662623  0.82700453 0.82960466 0.84367603]\n",
      "##########\n",
      "epoch:13 step:10201 [D loss: 0.225117, acc: 96.09%] [G loss: 2.185435]\n",
      "epoch:13 step:10202 [D loss: 1.037796, acc: 28.91%] [G loss: 1.784726]\n",
      "epoch:13 step:10203 [D loss: 0.953740, acc: 32.03%] [G loss: 2.116537]\n",
      "epoch:13 step:10204 [D loss: 0.348959, acc: 89.06%] [G loss: 1.746822]\n",
      "epoch:13 step:10205 [D loss: 0.670816, acc: 59.38%] [G loss: 3.217437]\n",
      "epoch:13 step:10206 [D loss: 0.362340, acc: 83.59%] [G loss: 2.056589]\n",
      "epoch:13 step:10207 [D loss: 0.732348, acc: 51.56%] [G loss: 2.080071]\n",
      "epoch:13 step:10208 [D loss: 0.513038, acc: 75.78%] [G loss: 1.911596]\n",
      "epoch:13 step:10209 [D loss: 0.656779, acc: 64.06%] [G loss: 2.937550]\n",
      "epoch:13 step:10210 [D loss: 0.657213, acc: 61.72%] [G loss: 2.077459]\n",
      "epoch:13 step:10211 [D loss: 0.341952, acc: 99.22%] [G loss: 1.959548]\n",
      "epoch:13 step:10212 [D loss: 0.545347, acc: 69.53%] [G loss: 2.867007]\n",
      "epoch:13 step:10213 [D loss: 0.343014, acc: 93.75%] [G loss: 2.273321]\n",
      "epoch:13 step:10214 [D loss: 0.734132, acc: 50.78%] [G loss: 1.938293]\n",
      "epoch:13 step:10215 [D loss: 0.888756, acc: 36.72%] [G loss: 2.485558]\n",
      "epoch:13 step:10216 [D loss: 0.951941, acc: 26.56%] [G loss: 1.712140]\n",
      "epoch:13 step:10217 [D loss: 0.643060, acc: 64.84%] [G loss: 2.475688]\n",
      "epoch:13 step:10218 [D loss: 0.528501, acc: 76.56%] [G loss: 2.589868]\n",
      "epoch:13 step:10219 [D loss: 0.500479, acc: 67.97%] [G loss: 2.174767]\n",
      "epoch:13 step:10220 [D loss: 0.366914, acc: 93.75%] [G loss: 2.054162]\n",
      "epoch:13 step:10221 [D loss: 0.703963, acc: 54.69%] [G loss: 1.759037]\n",
      "epoch:13 step:10222 [D loss: 0.445193, acc: 89.84%] [G loss: 2.085376]\n",
      "epoch:13 step:10223 [D loss: 0.486041, acc: 82.81%] [G loss: 2.327588]\n",
      "epoch:13 step:10224 [D loss: 0.786182, acc: 51.56%] [G loss: 1.805694]\n",
      "epoch:13 step:10225 [D loss: 0.639441, acc: 58.59%] [G loss: 2.890683]\n",
      "epoch:13 step:10226 [D loss: 0.504056, acc: 77.34%] [G loss: 2.341184]\n",
      "epoch:13 step:10227 [D loss: 0.332060, acc: 91.41%] [G loss: 2.153919]\n",
      "epoch:13 step:10228 [D loss: 0.539546, acc: 78.12%] [G loss: 2.878511]\n",
      "epoch:13 step:10229 [D loss: 0.494240, acc: 75.00%] [G loss: 2.414690]\n",
      "epoch:13 step:10230 [D loss: 1.153543, acc: 32.03%] [G loss: 2.075204]\n",
      "epoch:13 step:10231 [D loss: 0.608785, acc: 66.41%] [G loss: 2.115489]\n",
      "epoch:13 step:10232 [D loss: 0.432911, acc: 92.19%] [G loss: 2.339454]\n",
      "epoch:13 step:10233 [D loss: 0.444735, acc: 72.66%] [G loss: 2.467641]\n",
      "epoch:13 step:10234 [D loss: 0.439671, acc: 87.50%] [G loss: 1.978736]\n",
      "epoch:13 step:10235 [D loss: 0.739842, acc: 53.91%] [G loss: 1.619466]\n",
      "epoch:13 step:10236 [D loss: 0.334192, acc: 96.09%] [G loss: 1.749356]\n",
      "epoch:13 step:10237 [D loss: 0.377354, acc: 81.25%] [G loss: 2.210629]\n",
      "epoch:13 step:10238 [D loss: 0.465592, acc: 82.81%] [G loss: 2.384923]\n",
      "epoch:13 step:10239 [D loss: 0.701293, acc: 55.47%] [G loss: 2.987443]\n",
      "epoch:13 step:10240 [D loss: 0.489350, acc: 76.56%] [G loss: 2.708447]\n",
      "epoch:13 step:10241 [D loss: 0.492554, acc: 73.44%] [G loss: 2.152744]\n",
      "epoch:13 step:10242 [D loss: 0.281003, acc: 96.09%] [G loss: 1.709040]\n",
      "epoch:13 step:10243 [D loss: 1.017603, acc: 20.31%] [G loss: 2.038583]\n",
      "epoch:13 step:10244 [D loss: 0.281438, acc: 97.66%] [G loss: 2.434649]\n",
      "epoch:13 step:10245 [D loss: 0.652068, acc: 57.03%] [G loss: 2.251347]\n",
      "epoch:13 step:10246 [D loss: 0.331691, acc: 97.66%] [G loss: 2.372195]\n",
      "epoch:13 step:10247 [D loss: 0.531496, acc: 67.97%] [G loss: 2.687902]\n",
      "epoch:13 step:10248 [D loss: 0.664479, acc: 56.25%] [G loss: 2.234909]\n",
      "epoch:13 step:10249 [D loss: 0.341765, acc: 83.59%] [G loss: 2.452748]\n",
      "epoch:13 step:10250 [D loss: 0.893315, acc: 51.56%] [G loss: 2.106017]\n",
      "epoch:13 step:10251 [D loss: 0.663756, acc: 54.69%] [G loss: 1.918174]\n",
      "epoch:13 step:10252 [D loss: 0.196594, acc: 98.44%] [G loss: 3.862990]\n",
      "epoch:13 step:10253 [D loss: 0.774408, acc: 53.12%] [G loss: 1.908319]\n",
      "epoch:13 step:10254 [D loss: 0.991178, acc: 26.56%] [G loss: 1.825072]\n",
      "epoch:13 step:10255 [D loss: 0.649266, acc: 60.94%] [G loss: 2.333680]\n",
      "epoch:13 step:10256 [D loss: 1.202043, acc: 25.00%] [G loss: 2.246075]\n",
      "epoch:13 step:10257 [D loss: 0.421440, acc: 89.06%] [G loss: 2.032851]\n",
      "epoch:13 step:10258 [D loss: 0.471493, acc: 81.25%] [G loss: 2.247214]\n",
      "epoch:13 step:10259 [D loss: 0.458196, acc: 88.28%] [G loss: 2.171909]\n",
      "epoch:13 step:10260 [D loss: 0.824453, acc: 50.00%] [G loss: 1.782795]\n",
      "epoch:13 step:10261 [D loss: 0.686786, acc: 57.03%] [G loss: 2.230752]\n",
      "epoch:13 step:10262 [D loss: 0.424646, acc: 91.41%] [G loss: 1.824570]\n",
      "epoch:13 step:10263 [D loss: 0.510729, acc: 72.66%] [G loss: 1.766887]\n",
      "epoch:13 step:10264 [D loss: 0.501391, acc: 78.12%] [G loss: 2.077836]\n",
      "epoch:13 step:10265 [D loss: 0.616984, acc: 65.62%] [G loss: 2.081749]\n",
      "epoch:13 step:10266 [D loss: 1.019285, acc: 39.84%] [G loss: 1.479592]\n",
      "epoch:13 step:10267 [D loss: 0.634376, acc: 60.94%] [G loss: 1.631293]\n",
      "epoch:13 step:10268 [D loss: 0.420228, acc: 85.94%] [G loss: 2.282584]\n",
      "epoch:13 step:10269 [D loss: 0.336228, acc: 90.62%] [G loss: 2.478052]\n",
      "epoch:13 step:10270 [D loss: 0.727304, acc: 56.25%] [G loss: 1.545946]\n",
      "epoch:13 step:10271 [D loss: 0.517646, acc: 81.25%] [G loss: 1.842808]\n",
      "epoch:13 step:10272 [D loss: 0.282482, acc: 93.75%] [G loss: 2.593207]\n",
      "epoch:13 step:10273 [D loss: 0.877573, acc: 50.00%] [G loss: 1.747644]\n",
      "epoch:13 step:10274 [D loss: 0.283116, acc: 92.19%] [G loss: 2.227670]\n",
      "epoch:13 step:10275 [D loss: 0.474976, acc: 86.72%] [G loss: 2.154597]\n",
      "epoch:13 step:10276 [D loss: 0.535872, acc: 69.53%] [G loss: 2.193324]\n",
      "epoch:13 step:10277 [D loss: 0.325431, acc: 95.31%] [G loss: 2.157088]\n",
      "epoch:13 step:10278 [D loss: 0.505550, acc: 60.94%] [G loss: 2.611727]\n",
      "epoch:13 step:10279 [D loss: 0.723445, acc: 52.34%] [G loss: 1.715167]\n",
      "epoch:13 step:10280 [D loss: 0.867367, acc: 49.22%] [G loss: 2.455084]\n",
      "epoch:13 step:10281 [D loss: 0.524128, acc: 71.88%] [G loss: 2.096101]\n",
      "epoch:13 step:10282 [D loss: 0.385807, acc: 82.03%] [G loss: 2.372418]\n",
      "epoch:13 step:10283 [D loss: 1.700156, acc: 1.56%] [G loss: 1.838377]\n",
      "epoch:13 step:10284 [D loss: 0.521944, acc: 70.31%] [G loss: 1.986674]\n",
      "epoch:13 step:10285 [D loss: 0.421908, acc: 80.47%] [G loss: 2.192056]\n",
      "epoch:13 step:10286 [D loss: 1.091979, acc: 17.19%] [G loss: 1.483253]\n",
      "epoch:13 step:10287 [D loss: 0.256319, acc: 96.09%] [G loss: 2.973210]\n",
      "epoch:13 step:10288 [D loss: 0.565256, acc: 71.88%] [G loss: 2.144224]\n",
      "epoch:13 step:10289 [D loss: 0.602141, acc: 68.75%] [G loss: 3.129150]\n",
      "epoch:13 step:10290 [D loss: 0.376479, acc: 92.19%] [G loss: 1.977542]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:13 step:10291 [D loss: 0.255087, acc: 99.22%] [G loss: 3.202250]\n",
      "epoch:13 step:10292 [D loss: 0.770312, acc: 50.78%] [G loss: 2.077457]\n",
      "epoch:13 step:10293 [D loss: 0.753166, acc: 54.69%] [G loss: 2.054855]\n",
      "epoch:13 step:10294 [D loss: 0.499262, acc: 80.47%] [G loss: 1.781726]\n",
      "epoch:13 step:10295 [D loss: 0.815388, acc: 42.19%] [G loss: 2.277637]\n",
      "epoch:13 step:10296 [D loss: 0.709362, acc: 57.03%] [G loss: 2.302613]\n",
      "epoch:13 step:10297 [D loss: 0.652573, acc: 60.94%] [G loss: 1.704461]\n",
      "epoch:13 step:10298 [D loss: 0.765836, acc: 50.78%] [G loss: 2.447310]\n",
      "epoch:13 step:10299 [D loss: 0.431887, acc: 83.59%] [G loss: 2.523377]\n",
      "epoch:13 step:10300 [D loss: 0.454474, acc: 87.50%] [G loss: 1.937505]\n",
      "epoch:13 step:10301 [D loss: 0.224618, acc: 95.31%] [G loss: 3.874142]\n",
      "epoch:13 step:10302 [D loss: 0.994015, acc: 25.00%] [G loss: 2.034272]\n",
      "epoch:13 step:10303 [D loss: 1.285487, acc: 10.16%] [G loss: 1.819717]\n",
      "epoch:13 step:10304 [D loss: 0.766833, acc: 48.44%] [G loss: 2.114833]\n",
      "epoch:13 step:10305 [D loss: 0.422311, acc: 83.59%] [G loss: 2.484847]\n",
      "epoch:13 step:10306 [D loss: 0.373308, acc: 93.75%] [G loss: 2.422009]\n",
      "epoch:13 step:10307 [D loss: 0.487385, acc: 71.09%] [G loss: 2.253609]\n",
      "epoch:13 step:10308 [D loss: 0.420512, acc: 84.38%] [G loss: 2.372866]\n",
      "epoch:13 step:10309 [D loss: 0.471531, acc: 80.47%] [G loss: 2.419177]\n",
      "epoch:13 step:10310 [D loss: 0.640491, acc: 67.19%] [G loss: 2.279952]\n",
      "epoch:13 step:10311 [D loss: 0.523115, acc: 60.94%] [G loss: 2.186710]\n",
      "epoch:13 step:10312 [D loss: 0.983679, acc: 37.50%] [G loss: 2.285095]\n",
      "epoch:13 step:10313 [D loss: 0.379870, acc: 85.94%] [G loss: 2.135268]\n",
      "epoch:13 step:10314 [D loss: 0.408398, acc: 87.50%] [G loss: 2.576322]\n",
      "epoch:13 step:10315 [D loss: 0.486142, acc: 78.12%] [G loss: 2.055187]\n",
      "epoch:13 step:10316 [D loss: 0.629961, acc: 67.19%] [G loss: 2.162629]\n",
      "epoch:13 step:10317 [D loss: 0.577852, acc: 71.09%] [G loss: 1.933801]\n",
      "epoch:13 step:10318 [D loss: 0.643187, acc: 65.62%] [G loss: 2.102645]\n",
      "epoch:13 step:10319 [D loss: 0.503103, acc: 69.53%] [G loss: 2.439886]\n",
      "epoch:13 step:10320 [D loss: 0.901267, acc: 45.31%] [G loss: 1.987192]\n",
      "epoch:13 step:10321 [D loss: 0.338922, acc: 92.19%] [G loss: 2.819173]\n",
      "epoch:13 step:10322 [D loss: 0.592693, acc: 67.19%] [G loss: 1.951753]\n",
      "epoch:13 step:10323 [D loss: 0.613156, acc: 63.28%] [G loss: 2.355412]\n",
      "epoch:13 step:10324 [D loss: 0.758185, acc: 55.47%] [G loss: 1.543891]\n",
      "epoch:13 step:10325 [D loss: 0.652546, acc: 62.50%] [G loss: 2.047126]\n",
      "epoch:13 step:10326 [D loss: 0.620430, acc: 68.75%] [G loss: 2.333950]\n",
      "epoch:13 step:10327 [D loss: 1.059890, acc: 48.44%] [G loss: 2.137608]\n",
      "epoch:13 step:10328 [D loss: 0.405105, acc: 80.47%] [G loss: 2.305741]\n",
      "epoch:13 step:10329 [D loss: 1.049948, acc: 24.22%] [G loss: 1.950556]\n",
      "epoch:13 step:10330 [D loss: 0.483658, acc: 74.22%] [G loss: 2.120703]\n",
      "epoch:13 step:10331 [D loss: 0.622151, acc: 64.06%] [G loss: 2.911447]\n",
      "epoch:13 step:10332 [D loss: 0.252824, acc: 96.88%] [G loss: 2.586850]\n",
      "epoch:13 step:10333 [D loss: 0.657616, acc: 60.94%] [G loss: 2.155320]\n",
      "epoch:13 step:10334 [D loss: 0.780389, acc: 42.97%] [G loss: 2.154814]\n",
      "epoch:13 step:10335 [D loss: 0.643803, acc: 67.19%] [G loss: 2.101754]\n",
      "epoch:13 step:10336 [D loss: 0.406412, acc: 69.53%] [G loss: 3.004854]\n",
      "epoch:13 step:10337 [D loss: 0.870510, acc: 35.94%] [G loss: 1.603911]\n",
      "epoch:13 step:10338 [D loss: 0.516773, acc: 70.31%] [G loss: 2.071229]\n",
      "epoch:13 step:10339 [D loss: 0.830015, acc: 48.44%] [G loss: 2.055868]\n",
      "epoch:13 step:10340 [D loss: 0.708445, acc: 52.34%] [G loss: 1.775238]\n",
      "epoch:13 step:10341 [D loss: 0.344899, acc: 96.09%] [G loss: 2.833270]\n",
      "epoch:13 step:10342 [D loss: 0.372273, acc: 93.75%] [G loss: 2.439486]\n",
      "epoch:13 step:10343 [D loss: 0.620807, acc: 64.84%] [G loss: 2.288116]\n",
      "epoch:13 step:10344 [D loss: 0.673108, acc: 60.16%] [G loss: 2.504985]\n",
      "epoch:13 step:10345 [D loss: 0.627396, acc: 57.81%] [G loss: 2.136689]\n",
      "epoch:13 step:10346 [D loss: 0.352792, acc: 90.62%] [G loss: 2.230743]\n",
      "epoch:13 step:10347 [D loss: 0.688751, acc: 55.47%] [G loss: 2.001319]\n",
      "epoch:13 step:10348 [D loss: 0.634940, acc: 64.84%] [G loss: 1.934836]\n",
      "epoch:13 step:10349 [D loss: 0.678419, acc: 59.38%] [G loss: 1.963794]\n",
      "epoch:13 step:10350 [D loss: 0.905607, acc: 32.81%] [G loss: 1.665184]\n",
      "epoch:13 step:10351 [D loss: 0.613405, acc: 64.84%] [G loss: 2.188837]\n",
      "epoch:13 step:10352 [D loss: 0.588384, acc: 70.31%] [G loss: 2.334750]\n",
      "epoch:13 step:10353 [D loss: 0.710069, acc: 53.12%] [G loss: 2.338479]\n",
      "epoch:13 step:10354 [D loss: 0.251778, acc: 99.22%] [G loss: 2.630176]\n",
      "epoch:13 step:10355 [D loss: 0.988981, acc: 28.91%] [G loss: 1.869723]\n",
      "epoch:13 step:10356 [D loss: 0.356988, acc: 90.62%] [G loss: 2.393625]\n",
      "epoch:13 step:10357 [D loss: 0.507951, acc: 77.34%] [G loss: 1.993365]\n",
      "epoch:13 step:10358 [D loss: 0.947898, acc: 34.38%] [G loss: 1.906387]\n",
      "epoch:13 step:10359 [D loss: 0.837036, acc: 36.72%] [G loss: 1.784698]\n",
      "epoch:13 step:10360 [D loss: 0.538858, acc: 68.75%] [G loss: 1.844428]\n",
      "epoch:13 step:10361 [D loss: 0.803221, acc: 52.34%] [G loss: 1.945142]\n",
      "epoch:13 step:10362 [D loss: 0.643365, acc: 60.16%] [G loss: 2.022366]\n",
      "epoch:13 step:10363 [D loss: 0.924022, acc: 24.22%] [G loss: 1.431348]\n",
      "epoch:13 step:10364 [D loss: 0.480096, acc: 73.44%] [G loss: 2.559747]\n",
      "epoch:13 step:10365 [D loss: 0.295089, acc: 96.88%] [G loss: 3.733750]\n",
      "epoch:13 step:10366 [D loss: 0.453488, acc: 62.50%] [G loss: 1.989791]\n",
      "epoch:13 step:10367 [D loss: 0.779291, acc: 53.91%] [G loss: 2.355928]\n",
      "epoch:13 step:10368 [D loss: 0.579183, acc: 72.66%] [G loss: 2.408575]\n",
      "epoch:13 step:10369 [D loss: 0.838418, acc: 41.41%] [G loss: 1.427820]\n",
      "epoch:13 step:10370 [D loss: 0.315413, acc: 96.88%] [G loss: 1.741611]\n",
      "epoch:13 step:10371 [D loss: 0.686223, acc: 57.81%] [G loss: 2.014589]\n",
      "epoch:13 step:10372 [D loss: 0.336712, acc: 94.53%] [G loss: 2.675829]\n",
      "epoch:13 step:10373 [D loss: 0.505732, acc: 71.09%] [G loss: 1.950958]\n",
      "epoch:13 step:10374 [D loss: 0.592104, acc: 63.28%] [G loss: 2.229491]\n",
      "epoch:13 step:10375 [D loss: 1.060032, acc: 44.53%] [G loss: 1.384209]\n",
      "epoch:13 step:10376 [D loss: 0.448985, acc: 87.50%] [G loss: 1.924339]\n",
      "epoch:13 step:10377 [D loss: 0.779209, acc: 39.84%] [G loss: 1.781794]\n",
      "epoch:13 step:10378 [D loss: 0.734336, acc: 51.56%] [G loss: 1.447894]\n",
      "epoch:13 step:10379 [D loss: 1.136020, acc: 37.50%] [G loss: 1.455665]\n",
      "epoch:13 step:10380 [D loss: 0.895722, acc: 51.56%] [G loss: 1.679039]\n",
      "epoch:13 step:10381 [D loss: 0.446991, acc: 85.16%] [G loss: 1.885503]\n",
      "epoch:13 step:10382 [D loss: 0.674290, acc: 63.28%] [G loss: 1.204632]\n",
      "epoch:13 step:10383 [D loss: 1.467683, acc: 8.59%] [G loss: 1.450575]\n",
      "epoch:13 step:10384 [D loss: 0.627187, acc: 68.75%] [G loss: 2.038504]\n",
      "epoch:13 step:10385 [D loss: 0.292623, acc: 96.88%] [G loss: 2.343491]\n",
      "epoch:13 step:10386 [D loss: 0.777197, acc: 50.78%] [G loss: 1.923251]\n",
      "epoch:13 step:10387 [D loss: 0.804487, acc: 44.53%] [G loss: 1.705202]\n",
      "epoch:13 step:10388 [D loss: 0.635026, acc: 67.19%] [G loss: 2.188966]\n",
      "epoch:13 step:10389 [D loss: 0.867109, acc: 42.97%] [G loss: 1.823449]\n",
      "epoch:13 step:10390 [D loss: 0.482175, acc: 72.66%] [G loss: 2.310128]\n",
      "epoch:13 step:10391 [D loss: 0.778309, acc: 43.75%] [G loss: 1.584132]\n",
      "epoch:13 step:10392 [D loss: 0.566153, acc: 71.88%] [G loss: 2.551157]\n",
      "epoch:13 step:10393 [D loss: 0.648063, acc: 59.38%] [G loss: 2.323646]\n",
      "epoch:13 step:10394 [D loss: 0.276328, acc: 95.31%] [G loss: 2.727521]\n",
      "epoch:13 step:10395 [D loss: 0.909942, acc: 47.66%] [G loss: 1.944614]\n",
      "epoch:13 step:10396 [D loss: 0.668763, acc: 56.25%] [G loss: 2.264141]\n",
      "epoch:13 step:10397 [D loss: 0.267272, acc: 94.53%] [G loss: 2.518775]\n",
      "epoch:13 step:10398 [D loss: 1.553266, acc: 12.50%] [G loss: 1.408038]\n",
      "epoch:13 step:10399 [D loss: 0.768420, acc: 53.12%] [G loss: 2.207062]\n",
      "epoch:13 step:10400 [D loss: 0.576420, acc: 75.00%] [G loss: 1.613433]\n",
      "##############\n",
      "[0.86035972 0.8409692  0.81616135 0.8263379  0.77570685 0.8257328\n",
      " 0.89111957 0.83277804 0.82048472 0.82016056]\n",
      "##########\n",
      "epoch:13 step:10401 [D loss: 0.542843, acc: 80.47%] [G loss: 1.917623]\n",
      "epoch:13 step:10402 [D loss: 0.636643, acc: 57.03%] [G loss: 2.119487]\n",
      "epoch:13 step:10403 [D loss: 0.443766, acc: 82.03%] [G loss: 1.917178]\n",
      "epoch:13 step:10404 [D loss: 0.667640, acc: 60.94%] [G loss: 1.960409]\n",
      "epoch:13 step:10405 [D loss: 0.369757, acc: 89.06%] [G loss: 2.845339]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:13 step:10406 [D loss: 0.507943, acc: 78.91%] [G loss: 1.609793]\n",
      "epoch:13 step:10407 [D loss: 0.533588, acc: 76.56%] [G loss: 1.636233]\n",
      "epoch:13 step:10408 [D loss: 0.628080, acc: 61.72%] [G loss: 1.869923]\n",
      "epoch:13 step:10409 [D loss: 0.528006, acc: 73.44%] [G loss: 2.181078]\n",
      "epoch:13 step:10410 [D loss: 0.652141, acc: 53.91%] [G loss: 1.675829]\n",
      "epoch:13 step:10411 [D loss: 0.593476, acc: 66.41%] [G loss: 1.698853]\n",
      "epoch:13 step:10412 [D loss: 0.878095, acc: 32.03%] [G loss: 1.218484]\n",
      "epoch:13 step:10413 [D loss: 0.608487, acc: 64.06%] [G loss: 1.910696]\n",
      "epoch:13 step:10414 [D loss: 0.495783, acc: 85.16%] [G loss: 2.473557]\n",
      "epoch:13 step:10415 [D loss: 0.525045, acc: 78.12%] [G loss: 2.252925]\n",
      "epoch:13 step:10416 [D loss: 0.978474, acc: 35.94%] [G loss: 2.303978]\n",
      "epoch:13 step:10417 [D loss: 0.531105, acc: 61.72%] [G loss: 2.833119]\n",
      "epoch:13 step:10418 [D loss: 0.443165, acc: 85.16%] [G loss: 2.357443]\n",
      "epoch:13 step:10419 [D loss: 0.537571, acc: 69.53%] [G loss: 1.951999]\n",
      "epoch:13 step:10420 [D loss: 0.934408, acc: 38.28%] [G loss: 1.783134]\n",
      "epoch:13 step:10421 [D loss: 0.500117, acc: 75.00%] [G loss: 2.548718]\n",
      "epoch:13 step:10422 [D loss: 0.975697, acc: 19.53%] [G loss: 2.121965]\n",
      "epoch:13 step:10423 [D loss: 0.661086, acc: 64.06%] [G loss: 2.110122]\n",
      "epoch:13 step:10424 [D loss: 0.517986, acc: 68.75%] [G loss: 2.042013]\n",
      "epoch:13 step:10425 [D loss: 0.754967, acc: 46.09%] [G loss: 2.080856]\n",
      "epoch:13 step:10426 [D loss: 0.878726, acc: 48.44%] [G loss: 1.841816]\n",
      "epoch:13 step:10427 [D loss: 0.624426, acc: 67.19%] [G loss: 1.807526]\n",
      "epoch:13 step:10428 [D loss: 0.686990, acc: 60.94%] [G loss: 1.895406]\n",
      "epoch:13 step:10429 [D loss: 0.512909, acc: 83.59%] [G loss: 2.069282]\n",
      "epoch:13 step:10430 [D loss: 0.493731, acc: 75.00%] [G loss: 2.286566]\n",
      "epoch:13 step:10431 [D loss: 0.607026, acc: 71.88%] [G loss: 2.243373]\n",
      "epoch:13 step:10432 [D loss: 0.543579, acc: 73.44%] [G loss: 1.866939]\n",
      "epoch:13 step:10433 [D loss: 0.580697, acc: 72.66%] [G loss: 2.223440]\n",
      "epoch:13 step:10434 [D loss: 0.742180, acc: 47.66%] [G loss: 1.773999]\n",
      "epoch:13 step:10435 [D loss: 0.526222, acc: 79.69%] [G loss: 2.215839]\n",
      "epoch:13 step:10436 [D loss: 0.528335, acc: 76.56%] [G loss: 2.315382]\n",
      "epoch:13 step:10437 [D loss: 0.662919, acc: 60.16%] [G loss: 2.468871]\n",
      "epoch:13 step:10438 [D loss: 0.636060, acc: 66.41%] [G loss: 2.148478]\n",
      "epoch:13 step:10439 [D loss: 0.518740, acc: 78.12%] [G loss: 1.928297]\n",
      "epoch:13 step:10440 [D loss: 0.601923, acc: 69.53%] [G loss: 2.237572]\n",
      "epoch:13 step:10441 [D loss: 0.874741, acc: 40.62%] [G loss: 1.995503]\n",
      "epoch:13 step:10442 [D loss: 0.691633, acc: 57.81%] [G loss: 1.894996]\n",
      "epoch:13 step:10443 [D loss: 0.568138, acc: 70.31%] [G loss: 2.122952]\n",
      "epoch:13 step:10444 [D loss: 1.030015, acc: 20.31%] [G loss: 1.786488]\n",
      "epoch:13 step:10445 [D loss: 0.870170, acc: 34.38%] [G loss: 1.814382]\n",
      "epoch:13 step:10446 [D loss: 0.601853, acc: 64.84%] [G loss: 1.913212]\n",
      "epoch:13 step:10447 [D loss: 0.406056, acc: 88.28%] [G loss: 2.313216]\n",
      "epoch:13 step:10448 [D loss: 0.811263, acc: 42.97%] [G loss: 1.799449]\n",
      "epoch:13 step:10449 [D loss: 0.574475, acc: 71.09%] [G loss: 2.159184]\n",
      "epoch:13 step:10450 [D loss: 0.739073, acc: 50.78%] [G loss: 1.939484]\n",
      "epoch:13 step:10451 [D loss: 0.416913, acc: 88.28%] [G loss: 2.227524]\n",
      "epoch:13 step:10452 [D loss: 0.531278, acc: 75.00%] [G loss: 2.127129]\n",
      "epoch:13 step:10453 [D loss: 0.925098, acc: 24.22%] [G loss: 1.719246]\n",
      "epoch:13 step:10454 [D loss: 0.686380, acc: 57.03%] [G loss: 2.146101]\n",
      "epoch:13 step:10455 [D loss: 0.301473, acc: 96.88%] [G loss: 2.560891]\n",
      "epoch:13 step:10456 [D loss: 0.621971, acc: 67.19%] [G loss: 2.148282]\n",
      "epoch:13 step:10457 [D loss: 0.429988, acc: 89.84%] [G loss: 2.087506]\n",
      "epoch:13 step:10458 [D loss: 0.598261, acc: 67.97%] [G loss: 1.740735]\n",
      "epoch:13 step:10459 [D loss: 0.581962, acc: 75.00%] [G loss: 1.720983]\n",
      "epoch:13 step:10460 [D loss: 0.237881, acc: 100.00%] [G loss: 3.200884]\n",
      "epoch:13 step:10461 [D loss: 0.444964, acc: 89.06%] [G loss: 2.533950]\n",
      "epoch:13 step:10462 [D loss: 0.501418, acc: 80.47%] [G loss: 1.715640]\n",
      "epoch:13 step:10463 [D loss: 0.455194, acc: 88.28%] [G loss: 1.421657]\n",
      "epoch:13 step:10464 [D loss: 0.742601, acc: 48.44%] [G loss: 1.918086]\n",
      "epoch:13 step:10465 [D loss: 0.886321, acc: 42.97%] [G loss: 1.589959]\n",
      "epoch:13 step:10466 [D loss: 0.516914, acc: 79.69%] [G loss: 1.748064]\n",
      "epoch:13 step:10467 [D loss: 0.608488, acc: 64.84%] [G loss: 1.806986]\n",
      "epoch:13 step:10468 [D loss: 1.176223, acc: 17.19%] [G loss: 1.420623]\n",
      "epoch:13 step:10469 [D loss: 0.908418, acc: 32.81%] [G loss: 2.164942]\n",
      "epoch:13 step:10470 [D loss: 0.779670, acc: 50.78%] [G loss: 2.060330]\n",
      "epoch:13 step:10471 [D loss: 0.420146, acc: 89.06%] [G loss: 1.976268]\n",
      "epoch:13 step:10472 [D loss: 0.622166, acc: 62.50%] [G loss: 2.572408]\n",
      "epoch:13 step:10473 [D loss: 0.967611, acc: 33.59%] [G loss: 2.077662]\n",
      "epoch:13 step:10474 [D loss: 0.573932, acc: 71.09%] [G loss: 2.609429]\n",
      "epoch:13 step:10475 [D loss: 0.656709, acc: 60.16%] [G loss: 1.965636]\n",
      "epoch:13 step:10476 [D loss: 0.584394, acc: 71.09%] [G loss: 2.515417]\n",
      "epoch:13 step:10477 [D loss: 0.462593, acc: 89.84%] [G loss: 2.156465]\n",
      "epoch:13 step:10478 [D loss: 0.651715, acc: 64.06%] [G loss: 2.287745]\n",
      "epoch:13 step:10479 [D loss: 0.658679, acc: 61.72%] [G loss: 1.940047]\n",
      "epoch:13 step:10480 [D loss: 0.341255, acc: 90.62%] [G loss: 2.362481]\n",
      "epoch:13 step:10481 [D loss: 0.425631, acc: 86.72%] [G loss: 2.045958]\n",
      "epoch:13 step:10482 [D loss: 0.740011, acc: 49.22%] [G loss: 2.324266]\n",
      "epoch:13 step:10483 [D loss: 0.382187, acc: 91.41%] [G loss: 2.283150]\n",
      "epoch:13 step:10484 [D loss: 0.653219, acc: 67.19%] [G loss: 1.674131]\n",
      "epoch:13 step:10485 [D loss: 0.791501, acc: 50.00%] [G loss: 2.198331]\n",
      "epoch:13 step:10486 [D loss: 0.512175, acc: 79.69%] [G loss: 2.561146]\n",
      "epoch:13 step:10487 [D loss: 0.784347, acc: 43.75%] [G loss: 2.017456]\n",
      "epoch:13 step:10488 [D loss: 0.307806, acc: 89.84%] [G loss: 3.887267]\n",
      "epoch:13 step:10489 [D loss: 0.712842, acc: 57.81%] [G loss: 1.879250]\n",
      "epoch:13 step:10490 [D loss: 0.846058, acc: 47.66%] [G loss: 1.594450]\n",
      "epoch:13 step:10491 [D loss: 0.615857, acc: 57.03%] [G loss: 1.583035]\n",
      "epoch:13 step:10492 [D loss: 0.628847, acc: 53.91%] [G loss: 1.747109]\n",
      "epoch:13 step:10493 [D loss: 0.556233, acc: 73.44%] [G loss: 1.706068]\n",
      "epoch:13 step:10494 [D loss: 0.618761, acc: 65.62%] [G loss: 2.164099]\n",
      "epoch:13 step:10495 [D loss: 0.693656, acc: 53.91%] [G loss: 2.181539]\n",
      "epoch:13 step:10496 [D loss: 0.557546, acc: 71.09%] [G loss: 2.208005]\n",
      "epoch:13 step:10497 [D loss: 0.369980, acc: 87.50%] [G loss: 2.851735]\n",
      "epoch:13 step:10498 [D loss: 0.795783, acc: 43.75%] [G loss: 1.391721]\n",
      "epoch:13 step:10499 [D loss: 0.748583, acc: 52.34%] [G loss: 1.992401]\n",
      "epoch:13 step:10500 [D loss: 0.565466, acc: 60.94%] [G loss: 1.827199]\n",
      "epoch:13 step:10501 [D loss: 1.148505, acc: 19.53%] [G loss: 2.342082]\n",
      "epoch:13 step:10502 [D loss: 0.559312, acc: 74.22%] [G loss: 1.917900]\n",
      "epoch:13 step:10503 [D loss: 0.494834, acc: 83.59%] [G loss: 2.370651]\n",
      "epoch:13 step:10504 [D loss: 0.807455, acc: 42.19%] [G loss: 1.727330]\n",
      "epoch:13 step:10505 [D loss: 0.497026, acc: 77.34%] [G loss: 2.034401]\n",
      "epoch:13 step:10506 [D loss: 0.616665, acc: 67.19%] [G loss: 1.987682]\n",
      "epoch:13 step:10507 [D loss: 0.581870, acc: 58.59%] [G loss: 1.491057]\n",
      "epoch:13 step:10508 [D loss: 0.458883, acc: 76.56%] [G loss: 1.887026]\n",
      "epoch:13 step:10509 [D loss: 0.725142, acc: 52.34%] [G loss: 1.776706]\n",
      "epoch:13 step:10510 [D loss: 0.537574, acc: 82.81%] [G loss: 1.525387]\n",
      "epoch:13 step:10511 [D loss: 0.516968, acc: 80.47%] [G loss: 2.009314]\n",
      "epoch:13 step:10512 [D loss: 0.804762, acc: 42.97%] [G loss: 1.484477]\n",
      "epoch:13 step:10513 [D loss: 0.512257, acc: 71.88%] [G loss: 1.622354]\n",
      "epoch:13 step:10514 [D loss: 0.482772, acc: 78.12%] [G loss: 2.539953]\n",
      "epoch:13 step:10515 [D loss: 0.838524, acc: 50.78%] [G loss: 1.712847]\n",
      "epoch:13 step:10516 [D loss: 0.588748, acc: 70.31%] [G loss: 1.625567]\n",
      "epoch:13 step:10517 [D loss: 0.443415, acc: 89.06%] [G loss: 2.003671]\n",
      "epoch:13 step:10518 [D loss: 0.353303, acc: 92.97%] [G loss: 2.108432]\n",
      "epoch:13 step:10519 [D loss: 1.167894, acc: 39.06%] [G loss: 1.494245]\n",
      "epoch:13 step:10520 [D loss: 0.975456, acc: 42.97%] [G loss: 1.613591]\n",
      "epoch:13 step:10521 [D loss: 0.674002, acc: 61.72%] [G loss: 1.720142]\n",
      "epoch:13 step:10522 [D loss: 0.483953, acc: 88.28%] [G loss: 2.055498]\n",
      "epoch:13 step:10523 [D loss: 0.734801, acc: 55.47%] [G loss: 1.655093]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:13 step:10524 [D loss: 0.473734, acc: 89.06%] [G loss: 1.993399]\n",
      "epoch:13 step:10525 [D loss: 0.599765, acc: 64.06%] [G loss: 2.209145]\n",
      "epoch:13 step:10526 [D loss: 1.201740, acc: 28.12%] [G loss: 1.290901]\n",
      "epoch:13 step:10527 [D loss: 0.494870, acc: 72.66%] [G loss: 2.089623]\n",
      "epoch:13 step:10528 [D loss: 0.416520, acc: 91.41%] [G loss: 1.704248]\n",
      "epoch:13 step:10529 [D loss: 0.371592, acc: 91.41%] [G loss: 2.259791]\n",
      "epoch:13 step:10530 [D loss: 0.313570, acc: 96.09%] [G loss: 2.471558]\n",
      "epoch:13 step:10531 [D loss: 0.480957, acc: 85.94%] [G loss: 1.795464]\n",
      "epoch:13 step:10532 [D loss: 0.664210, acc: 61.72%] [G loss: 2.671023]\n",
      "epoch:13 step:10533 [D loss: 0.849587, acc: 40.62%] [G loss: 1.917831]\n",
      "epoch:13 step:10534 [D loss: 0.609268, acc: 70.31%] [G loss: 2.153113]\n",
      "epoch:13 step:10535 [D loss: 0.451208, acc: 86.72%] [G loss: 2.275826]\n",
      "epoch:13 step:10536 [D loss: 0.765695, acc: 48.44%] [G loss: 2.025874]\n",
      "epoch:13 step:10537 [D loss: 0.380743, acc: 89.06%] [G loss: 2.632955]\n",
      "epoch:13 step:10538 [D loss: 0.493340, acc: 84.38%] [G loss: 2.333268]\n",
      "epoch:13 step:10539 [D loss: 0.401698, acc: 96.09%] [G loss: 2.290534]\n",
      "epoch:13 step:10540 [D loss: 0.304582, acc: 94.53%] [G loss: 2.291729]\n",
      "epoch:13 step:10541 [D loss: 0.407740, acc: 85.94%] [G loss: 2.515274]\n",
      "epoch:13 step:10542 [D loss: 0.290170, acc: 98.44%] [G loss: 2.069935]\n",
      "epoch:13 step:10543 [D loss: 0.912519, acc: 50.78%] [G loss: 2.015075]\n",
      "epoch:13 step:10544 [D loss: 1.481345, acc: 5.47%] [G loss: 1.657359]\n",
      "epoch:13 step:10545 [D loss: 0.650872, acc: 65.62%] [G loss: 1.821130]\n",
      "epoch:13 step:10546 [D loss: 0.531288, acc: 79.69%] [G loss: 1.745836]\n",
      "epoch:13 step:10547 [D loss: 0.756706, acc: 48.44%] [G loss: 2.607375]\n",
      "epoch:13 step:10548 [D loss: 0.493893, acc: 82.81%] [G loss: 2.372392]\n",
      "epoch:13 step:10549 [D loss: 0.962743, acc: 19.53%] [G loss: 1.899033]\n",
      "epoch:13 step:10550 [D loss: 0.620758, acc: 67.19%] [G loss: 2.050217]\n",
      "epoch:13 step:10551 [D loss: 0.609985, acc: 65.62%] [G loss: 1.887698]\n",
      "epoch:13 step:10552 [D loss: 0.453963, acc: 75.00%] [G loss: 2.208201]\n",
      "epoch:13 step:10553 [D loss: 0.394344, acc: 87.50%] [G loss: 2.238007]\n",
      "epoch:13 step:10554 [D loss: 0.610720, acc: 64.84%] [G loss: 1.824739]\n",
      "epoch:13 step:10555 [D loss: 0.539331, acc: 77.34%] [G loss: 2.198425]\n",
      "epoch:13 step:10556 [D loss: 0.591728, acc: 62.50%] [G loss: 2.014354]\n",
      "epoch:13 step:10557 [D loss: 0.441504, acc: 85.16%] [G loss: 2.123259]\n",
      "epoch:13 step:10558 [D loss: 0.378980, acc: 79.69%] [G loss: 2.109673]\n",
      "epoch:13 step:10559 [D loss: 0.572702, acc: 64.84%] [G loss: 2.235981]\n",
      "epoch:13 step:10560 [D loss: 0.234991, acc: 99.22%] [G loss: 2.723262]\n",
      "epoch:13 step:10561 [D loss: 0.545704, acc: 69.53%] [G loss: 2.382046]\n",
      "epoch:13 step:10562 [D loss: 0.427916, acc: 88.28%] [G loss: 2.213974]\n",
      "epoch:13 step:10563 [D loss: 0.496619, acc: 78.91%] [G loss: 1.576808]\n",
      "epoch:13 step:10564 [D loss: 0.823706, acc: 53.12%] [G loss: 1.633625]\n",
      "epoch:13 step:10565 [D loss: 0.841579, acc: 49.22%] [G loss: 2.000914]\n",
      "epoch:13 step:10566 [D loss: 1.016290, acc: 35.94%] [G loss: 1.445428]\n",
      "epoch:13 step:10567 [D loss: 1.506737, acc: 1.56%] [G loss: 1.506119]\n",
      "epoch:13 step:10568 [D loss: 0.591078, acc: 71.88%] [G loss: 1.669745]\n",
      "epoch:13 step:10569 [D loss: 0.569202, acc: 74.22%] [G loss: 1.763024]\n",
      "epoch:13 step:10570 [D loss: 0.748851, acc: 53.12%] [G loss: 1.934446]\n",
      "epoch:13 step:10571 [D loss: 0.649295, acc: 59.38%] [G loss: 1.611418]\n",
      "epoch:13 step:10572 [D loss: 0.646285, acc: 63.28%] [G loss: 1.882030]\n",
      "epoch:13 step:10573 [D loss: 0.388447, acc: 88.28%] [G loss: 2.424436]\n",
      "epoch:13 step:10574 [D loss: 0.384222, acc: 92.19%] [G loss: 2.292763]\n",
      "epoch:13 step:10575 [D loss: 0.406354, acc: 92.19%] [G loss: 2.585172]\n",
      "epoch:13 step:10576 [D loss: 0.851786, acc: 28.12%] [G loss: 2.166085]\n",
      "epoch:13 step:10577 [D loss: 0.810799, acc: 40.62%] [G loss: 2.075372]\n",
      "epoch:13 step:10578 [D loss: 0.702661, acc: 60.16%] [G loss: 2.393804]\n",
      "epoch:13 step:10579 [D loss: 0.407093, acc: 88.28%] [G loss: 1.750629]\n",
      "epoch:13 step:10580 [D loss: 0.612448, acc: 66.41%] [G loss: 2.353245]\n",
      "epoch:13 step:10581 [D loss: 0.819062, acc: 37.50%] [G loss: 2.041418]\n",
      "epoch:13 step:10582 [D loss: 0.652883, acc: 59.38%] [G loss: 2.438310]\n",
      "epoch:13 step:10583 [D loss: 0.903456, acc: 42.97%] [G loss: 2.053270]\n",
      "epoch:13 step:10584 [D loss: 0.372960, acc: 73.44%] [G loss: 2.735262]\n",
      "epoch:13 step:10585 [D loss: 0.546695, acc: 71.09%] [G loss: 1.749477]\n",
      "epoch:13 step:10586 [D loss: 0.705496, acc: 50.78%] [G loss: 1.865355]\n",
      "epoch:13 step:10587 [D loss: 0.836073, acc: 47.66%] [G loss: 1.965626]\n",
      "epoch:13 step:10588 [D loss: 0.854121, acc: 35.94%] [G loss: 2.002232]\n",
      "epoch:13 step:10589 [D loss: 0.757762, acc: 53.12%] [G loss: 1.594155]\n",
      "epoch:13 step:10590 [D loss: 0.436122, acc: 89.84%] [G loss: 2.503352]\n",
      "epoch:13 step:10591 [D loss: 0.471356, acc: 80.47%] [G loss: 2.481019]\n",
      "epoch:13 step:10592 [D loss: 0.661185, acc: 64.06%] [G loss: 2.476949]\n",
      "epoch:13 step:10593 [D loss: 0.685727, acc: 54.69%] [G loss: 1.757169]\n",
      "epoch:13 step:10594 [D loss: 0.453181, acc: 84.38%] [G loss: 2.789301]\n",
      "epoch:13 step:10595 [D loss: 0.432301, acc: 77.34%] [G loss: 2.313723]\n",
      "epoch:13 step:10596 [D loss: 0.278606, acc: 96.88%] [G loss: 2.507524]\n",
      "epoch:13 step:10597 [D loss: 0.706362, acc: 54.69%] [G loss: 2.102042]\n",
      "epoch:13 step:10598 [D loss: 0.503649, acc: 79.69%] [G loss: 2.176295]\n",
      "epoch:13 step:10599 [D loss: 0.340640, acc: 96.88%] [G loss: 1.764008]\n",
      "epoch:13 step:10600 [D loss: 0.449851, acc: 85.16%] [G loss: 2.370123]\n",
      "##############\n",
      "[0.86933844 0.86704279 0.80934992 0.8125361  0.78115467 0.84144202\n",
      " 0.89888123 0.83286176 0.80914726 0.82854916]\n",
      "##########\n",
      "epoch:13 step:10601 [D loss: 0.488002, acc: 83.59%] [G loss: 2.754242]\n",
      "epoch:13 step:10602 [D loss: 0.633028, acc: 61.72%] [G loss: 3.053380]\n",
      "epoch:13 step:10603 [D loss: 0.405883, acc: 85.16%] [G loss: 2.563484]\n",
      "epoch:13 step:10604 [D loss: 0.915052, acc: 28.12%] [G loss: 1.780491]\n",
      "epoch:13 step:10605 [D loss: 0.340375, acc: 93.75%] [G loss: 2.393339]\n",
      "epoch:13 step:10606 [D loss: 0.657270, acc: 65.62%] [G loss: 1.928371]\n",
      "epoch:13 step:10607 [D loss: 0.597555, acc: 68.75%] [G loss: 2.010163]\n",
      "epoch:13 step:10608 [D loss: 0.718570, acc: 55.47%] [G loss: 2.016214]\n",
      "epoch:13 step:10609 [D loss: 0.560420, acc: 73.44%] [G loss: 2.284093]\n",
      "epoch:13 step:10610 [D loss: 0.533467, acc: 78.91%] [G loss: 2.404881]\n",
      "epoch:13 step:10611 [D loss: 0.330938, acc: 87.50%] [G loss: 3.322109]\n",
      "epoch:13 step:10612 [D loss: 0.576190, acc: 67.97%] [G loss: 2.345963]\n",
      "epoch:13 step:10613 [D loss: 0.671333, acc: 55.47%] [G loss: 1.646504]\n",
      "epoch:13 step:10614 [D loss: 1.014385, acc: 50.78%] [G loss: 1.889623]\n",
      "epoch:13 step:10615 [D loss: 0.804799, acc: 42.19%] [G loss: 1.726501]\n",
      "epoch:13 step:10616 [D loss: 0.668268, acc: 56.25%] [G loss: 2.296361]\n",
      "epoch:13 step:10617 [D loss: 0.494230, acc: 76.56%] [G loss: 2.279108]\n",
      "epoch:13 step:10618 [D loss: 0.594765, acc: 75.00%] [G loss: 2.014810]\n",
      "epoch:13 step:10619 [D loss: 0.608122, acc: 64.06%] [G loss: 2.288925]\n",
      "epoch:13 step:10620 [D loss: 0.516628, acc: 75.78%] [G loss: 2.696775]\n",
      "epoch:13 step:10621 [D loss: 0.475350, acc: 85.94%] [G loss: 2.172410]\n",
      "epoch:13 step:10622 [D loss: 0.593044, acc: 67.97%] [G loss: 2.552949]\n",
      "epoch:13 step:10623 [D loss: 1.062070, acc: 15.62%] [G loss: 2.178613]\n",
      "epoch:13 step:10624 [D loss: 0.733283, acc: 44.53%] [G loss: 1.807621]\n",
      "epoch:13 step:10625 [D loss: 0.748645, acc: 57.03%] [G loss: 2.305479]\n",
      "epoch:13 step:10626 [D loss: 0.480758, acc: 79.69%] [G loss: 2.216932]\n",
      "epoch:13 step:10627 [D loss: 0.713687, acc: 55.47%] [G loss: 2.301684]\n",
      "epoch:13 step:10628 [D loss: 0.654708, acc: 58.59%] [G loss: 1.921398]\n",
      "epoch:13 step:10629 [D loss: 0.252031, acc: 99.22%] [G loss: 2.695418]\n",
      "epoch:13 step:10630 [D loss: 0.454171, acc: 89.06%] [G loss: 2.606575]\n",
      "epoch:13 step:10631 [D loss: 0.515472, acc: 75.00%] [G loss: 2.308287]\n",
      "epoch:13 step:10632 [D loss: 0.453058, acc: 75.78%] [G loss: 1.881245]\n",
      "epoch:13 step:10633 [D loss: 0.819967, acc: 42.19%] [G loss: 2.085340]\n",
      "epoch:13 step:10634 [D loss: 0.597525, acc: 67.19%] [G loss: 1.857528]\n",
      "epoch:13 step:10635 [D loss: 0.675907, acc: 62.50%] [G loss: 2.447209]\n",
      "epoch:13 step:10636 [D loss: 0.546399, acc: 74.22%] [G loss: 2.281901]\n",
      "epoch:13 step:10637 [D loss: 0.470691, acc: 85.16%] [G loss: 2.889425]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:13 step:10638 [D loss: 0.666729, acc: 60.16%] [G loss: 2.567196]\n",
      "epoch:13 step:10639 [D loss: 0.473707, acc: 82.03%] [G loss: 2.263347]\n",
      "epoch:13 step:10640 [D loss: 0.698466, acc: 57.03%] [G loss: 1.955007]\n",
      "epoch:13 step:10641 [D loss: 0.594271, acc: 73.44%] [G loss: 2.403397]\n",
      "epoch:13 step:10642 [D loss: 0.377568, acc: 96.09%] [G loss: 2.082475]\n",
      "epoch:13 step:10643 [D loss: 0.302631, acc: 95.31%] [G loss: 2.338732]\n",
      "epoch:13 step:10644 [D loss: 0.641252, acc: 57.81%] [G loss: 2.122241]\n",
      "epoch:13 step:10645 [D loss: 0.710759, acc: 54.69%] [G loss: 2.360889]\n",
      "epoch:13 step:10646 [D loss: 0.158591, acc: 99.22%] [G loss: 2.956612]\n",
      "epoch:13 step:10647 [D loss: 0.680678, acc: 60.16%] [G loss: 2.357847]\n",
      "epoch:13 step:10648 [D loss: 0.418732, acc: 90.62%] [G loss: 2.273218]\n",
      "epoch:13 step:10649 [D loss: 0.728935, acc: 47.66%] [G loss: 1.451918]\n",
      "epoch:13 step:10650 [D loss: 0.352940, acc: 87.50%] [G loss: 2.412468]\n",
      "epoch:13 step:10651 [D loss: 0.609744, acc: 67.97%] [G loss: 1.913462]\n",
      "epoch:13 step:10652 [D loss: 0.487707, acc: 81.25%] [G loss: 2.047494]\n",
      "epoch:13 step:10653 [D loss: 0.808665, acc: 49.22%] [G loss: 1.766101]\n",
      "epoch:13 step:10654 [D loss: 0.616677, acc: 60.94%] [G loss: 1.519486]\n",
      "epoch:13 step:10655 [D loss: 0.863143, acc: 36.72%] [G loss: 1.373831]\n",
      "epoch:13 step:10656 [D loss: 0.507217, acc: 75.78%] [G loss: 3.281924]\n",
      "epoch:13 step:10657 [D loss: 0.775952, acc: 46.88%] [G loss: 2.146741]\n",
      "epoch:13 step:10658 [D loss: 0.799700, acc: 42.19%] [G loss: 1.724813]\n",
      "epoch:13 step:10659 [D loss: 0.983799, acc: 39.06%] [G loss: 1.885590]\n",
      "epoch:13 step:10660 [D loss: 0.859648, acc: 52.34%] [G loss: 1.648492]\n",
      "epoch:13 step:10661 [D loss: 0.587903, acc: 57.81%] [G loss: 2.102825]\n",
      "epoch:13 step:10662 [D loss: 0.662631, acc: 60.16%] [G loss: 1.833807]\n",
      "epoch:13 step:10663 [D loss: 0.844735, acc: 36.72%] [G loss: 1.960505]\n",
      "epoch:13 step:10664 [D loss: 0.873837, acc: 32.03%] [G loss: 2.021380]\n",
      "epoch:13 step:10665 [D loss: 0.741932, acc: 48.44%] [G loss: 1.709767]\n",
      "epoch:13 step:10666 [D loss: 0.616003, acc: 72.66%] [G loss: 2.396690]\n",
      "epoch:13 step:10667 [D loss: 0.705707, acc: 45.31%] [G loss: 2.414069]\n",
      "epoch:13 step:10668 [D loss: 0.912151, acc: 30.47%] [G loss: 1.656787]\n",
      "epoch:13 step:10669 [D loss: 0.658817, acc: 63.28%] [G loss: 2.446851]\n",
      "epoch:13 step:10670 [D loss: 0.661590, acc: 59.38%] [G loss: 2.086571]\n",
      "epoch:13 step:10671 [D loss: 0.550603, acc: 74.22%] [G loss: 2.312625]\n",
      "epoch:13 step:10672 [D loss: 0.625554, acc: 63.28%] [G loss: 1.813870]\n",
      "epoch:13 step:10673 [D loss: 0.573640, acc: 73.44%] [G loss: 2.106318]\n",
      "epoch:13 step:10674 [D loss: 0.593784, acc: 71.88%] [G loss: 2.214036]\n",
      "epoch:13 step:10675 [D loss: 0.953727, acc: 50.00%] [G loss: 1.529725]\n",
      "epoch:13 step:10676 [D loss: 0.663655, acc: 64.84%] [G loss: 1.884281]\n",
      "epoch:13 step:10677 [D loss: 0.890108, acc: 27.34%] [G loss: 1.622697]\n",
      "epoch:13 step:10678 [D loss: 0.661012, acc: 60.16%] [G loss: 2.257772]\n",
      "epoch:13 step:10679 [D loss: 1.301594, acc: 15.62%] [G loss: 1.722062]\n",
      "epoch:13 step:10680 [D loss: 0.524756, acc: 78.91%] [G loss: 1.595751]\n",
      "epoch:13 step:10681 [D loss: 0.830113, acc: 39.06%] [G loss: 1.714238]\n",
      "epoch:13 step:10682 [D loss: 0.568784, acc: 66.41%] [G loss: 1.838289]\n",
      "epoch:13 step:10683 [D loss: 0.495820, acc: 82.81%] [G loss: 2.079259]\n",
      "epoch:13 step:10684 [D loss: 1.070343, acc: 14.84%] [G loss: 1.455516]\n",
      "epoch:13 step:10685 [D loss: 0.592930, acc: 67.19%] [G loss: 1.947568]\n",
      "epoch:13 step:10686 [D loss: 0.700517, acc: 57.03%] [G loss: 1.743690]\n",
      "epoch:13 step:10687 [D loss: 0.522797, acc: 82.81%] [G loss: 2.738995]\n",
      "epoch:13 step:10688 [D loss: 0.249624, acc: 96.88%] [G loss: 2.040354]\n",
      "epoch:13 step:10689 [D loss: 0.227745, acc: 98.44%] [G loss: 2.856979]\n",
      "epoch:13 step:10690 [D loss: 0.401324, acc: 92.97%] [G loss: 2.565273]\n",
      "epoch:13 step:10691 [D loss: 0.450702, acc: 75.78%] [G loss: 2.049655]\n",
      "epoch:13 step:10692 [D loss: 0.698554, acc: 53.12%] [G loss: 1.846664]\n",
      "epoch:13 step:10693 [D loss: 0.671635, acc: 60.16%] [G loss: 1.754794]\n",
      "epoch:13 step:10694 [D loss: 0.365525, acc: 96.88%] [G loss: 1.851207]\n",
      "epoch:13 step:10695 [D loss: 0.601972, acc: 68.75%] [G loss: 1.958379]\n",
      "epoch:13 step:10696 [D loss: 0.714728, acc: 50.78%] [G loss: 1.955302]\n",
      "epoch:13 step:10697 [D loss: 0.668833, acc: 61.72%] [G loss: 1.604142]\n",
      "epoch:13 step:10698 [D loss: 0.648225, acc: 60.16%] [G loss: 1.829601]\n",
      "epoch:13 step:10699 [D loss: 1.321922, acc: 6.25%] [G loss: 1.112438]\n",
      "epoch:13 step:10700 [D loss: 0.548153, acc: 75.78%] [G loss: 1.879335]\n",
      "epoch:13 step:10701 [D loss: 0.979985, acc: 32.81%] [G loss: 2.216055]\n",
      "epoch:13 step:10702 [D loss: 0.813474, acc: 38.28%] [G loss: 1.682133]\n",
      "epoch:13 step:10703 [D loss: 0.831079, acc: 41.41%] [G loss: 2.599704]\n",
      "epoch:13 step:10704 [D loss: 0.849858, acc: 48.44%] [G loss: 2.004473]\n",
      "epoch:13 step:10705 [D loss: 0.671586, acc: 57.03%] [G loss: 1.683379]\n",
      "epoch:13 step:10706 [D loss: 0.660350, acc: 51.56%] [G loss: 1.991710]\n",
      "epoch:13 step:10707 [D loss: 0.778996, acc: 49.22%] [G loss: 1.901612]\n",
      "epoch:13 step:10708 [D loss: 0.475334, acc: 87.50%] [G loss: 2.294150]\n",
      "epoch:13 step:10709 [D loss: 0.569353, acc: 74.22%] [G loss: 2.064014]\n",
      "epoch:13 step:10710 [D loss: 0.721831, acc: 50.78%] [G loss: 2.101476]\n",
      "epoch:13 step:10711 [D loss: 0.508324, acc: 78.12%] [G loss: 1.514842]\n",
      "epoch:13 step:10712 [D loss: 0.501584, acc: 85.94%] [G loss: 2.666387]\n",
      "epoch:13 step:10713 [D loss: 0.649744, acc: 59.38%] [G loss: 1.903072]\n",
      "epoch:13 step:10714 [D loss: 0.578046, acc: 75.00%] [G loss: 1.939977]\n",
      "epoch:13 step:10715 [D loss: 0.928244, acc: 21.09%] [G loss: 1.670394]\n",
      "epoch:13 step:10716 [D loss: 0.941261, acc: 25.00%] [G loss: 1.429390]\n",
      "epoch:13 step:10717 [D loss: 0.644928, acc: 60.94%] [G loss: 1.833400]\n",
      "epoch:13 step:10718 [D loss: 0.629685, acc: 64.06%] [G loss: 1.837577]\n",
      "epoch:13 step:10719 [D loss: 0.663651, acc: 56.25%] [G loss: 1.936997]\n",
      "epoch:13 step:10720 [D loss: 0.726366, acc: 56.25%] [G loss: 1.933925]\n",
      "epoch:13 step:10721 [D loss: 0.658117, acc: 60.94%] [G loss: 2.027720]\n",
      "epoch:13 step:10722 [D loss: 0.531236, acc: 78.12%] [G loss: 1.899708]\n",
      "epoch:13 step:10723 [D loss: 0.722122, acc: 56.25%] [G loss: 1.570537]\n",
      "epoch:13 step:10724 [D loss: 0.482704, acc: 78.91%] [G loss: 2.266611]\n",
      "epoch:13 step:10725 [D loss: 0.541794, acc: 73.44%] [G loss: 2.359952]\n",
      "epoch:13 step:10726 [D loss: 0.557778, acc: 75.78%] [G loss: 1.934617]\n",
      "epoch:13 step:10727 [D loss: 0.551443, acc: 64.84%] [G loss: 1.773702]\n",
      "epoch:13 step:10728 [D loss: 0.901641, acc: 32.81%] [G loss: 1.723431]\n",
      "epoch:13 step:10729 [D loss: 0.495350, acc: 79.69%] [G loss: 2.450727]\n",
      "epoch:13 step:10730 [D loss: 0.516946, acc: 70.31%] [G loss: 2.380962]\n",
      "epoch:13 step:10731 [D loss: 0.549190, acc: 70.31%] [G loss: 2.319156]\n",
      "epoch:13 step:10732 [D loss: 0.562905, acc: 71.09%] [G loss: 2.211861]\n",
      "epoch:13 step:10733 [D loss: 0.516809, acc: 75.00%] [G loss: 1.836419]\n",
      "epoch:13 step:10734 [D loss: 0.343004, acc: 98.44%] [G loss: 2.419696]\n",
      "epoch:13 step:10735 [D loss: 0.747025, acc: 44.53%] [G loss: 2.071681]\n",
      "epoch:13 step:10736 [D loss: 0.675098, acc: 53.91%] [G loss: 2.603428]\n",
      "epoch:13 step:10737 [D loss: 0.777649, acc: 46.09%] [G loss: 2.013240]\n",
      "epoch:13 step:10738 [D loss: 0.284945, acc: 97.66%] [G loss: 3.005006]\n",
      "epoch:13 step:10739 [D loss: 0.578729, acc: 73.44%] [G loss: 1.815699]\n",
      "epoch:13 step:10740 [D loss: 0.746633, acc: 42.97%] [G loss: 1.909733]\n",
      "epoch:13 step:10741 [D loss: 0.640957, acc: 64.84%] [G loss: 1.887448]\n",
      "epoch:13 step:10742 [D loss: 0.663970, acc: 63.28%] [G loss: 2.026817]\n",
      "epoch:13 step:10743 [D loss: 0.567632, acc: 75.00%] [G loss: 2.138721]\n",
      "epoch:13 step:10744 [D loss: 0.339095, acc: 96.09%] [G loss: 2.045899]\n",
      "epoch:13 step:10745 [D loss: 0.742447, acc: 57.03%] [G loss: 2.036623]\n",
      "epoch:13 step:10746 [D loss: 0.857442, acc: 31.25%] [G loss: 1.424835]\n",
      "epoch:13 step:10747 [D loss: 0.312034, acc: 97.66%] [G loss: 2.646905]\n",
      "epoch:13 step:10748 [D loss: 0.592479, acc: 64.84%] [G loss: 2.016187]\n",
      "epoch:13 step:10749 [D loss: 0.577120, acc: 68.75%] [G loss: 1.841632]\n",
      "epoch:13 step:10750 [D loss: 0.479008, acc: 89.84%] [G loss: 1.737252]\n",
      "epoch:13 step:10751 [D loss: 0.451918, acc: 89.06%] [G loss: 2.237128]\n",
      "epoch:13 step:10752 [D loss: 0.746943, acc: 49.22%] [G loss: 2.134276]\n",
      "epoch:13 step:10753 [D loss: 0.445589, acc: 91.41%] [G loss: 1.984366]\n",
      "epoch:13 step:10754 [D loss: 0.647007, acc: 61.72%] [G loss: 2.403167]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:13 step:10755 [D loss: 0.678320, acc: 54.69%] [G loss: 2.375079]\n",
      "epoch:13 step:10756 [D loss: 0.881352, acc: 34.38%] [G loss: 1.684160]\n",
      "epoch:13 step:10757 [D loss: 0.782489, acc: 45.31%] [G loss: 2.095711]\n",
      "epoch:13 step:10758 [D loss: 0.803273, acc: 43.75%] [G loss: 1.746077]\n",
      "epoch:13 step:10759 [D loss: 0.812931, acc: 40.62%] [G loss: 2.045351]\n",
      "epoch:13 step:10760 [D loss: 0.659010, acc: 57.81%] [G loss: 1.778131]\n",
      "epoch:13 step:10761 [D loss: 0.430852, acc: 88.28%] [G loss: 2.187456]\n",
      "epoch:13 step:10762 [D loss: 0.489454, acc: 84.38%] [G loss: 2.005289]\n",
      "epoch:13 step:10763 [D loss: 0.932196, acc: 21.88%] [G loss: 1.418806]\n",
      "epoch:13 step:10764 [D loss: 0.574121, acc: 74.22%] [G loss: 1.818844]\n",
      "epoch:13 step:10765 [D loss: 0.746851, acc: 46.88%] [G loss: 2.068524]\n",
      "epoch:13 step:10766 [D loss: 0.807126, acc: 36.72%] [G loss: 1.919769]\n",
      "epoch:13 step:10767 [D loss: 0.586404, acc: 70.31%] [G loss: 1.900438]\n",
      "epoch:13 step:10768 [D loss: 0.941756, acc: 34.38%] [G loss: 1.688901]\n",
      "epoch:13 step:10769 [D loss: 0.550932, acc: 76.56%] [G loss: 2.578528]\n",
      "epoch:13 step:10770 [D loss: 0.701744, acc: 51.56%] [G loss: 2.133691]\n",
      "epoch:13 step:10771 [D loss: 0.488465, acc: 66.41%] [G loss: 2.833057]\n",
      "epoch:13 step:10772 [D loss: 1.018172, acc: 27.34%] [G loss: 1.619492]\n",
      "epoch:13 step:10773 [D loss: 0.693592, acc: 53.91%] [G loss: 1.926063]\n",
      "epoch:13 step:10774 [D loss: 0.528526, acc: 77.34%] [G loss: 1.718130]\n",
      "epoch:13 step:10775 [D loss: 0.777128, acc: 47.66%] [G loss: 1.614742]\n",
      "epoch:13 step:10776 [D loss: 0.649416, acc: 64.84%] [G loss: 1.676572]\n",
      "epoch:13 step:10777 [D loss: 0.762214, acc: 44.53%] [G loss: 1.982284]\n",
      "epoch:13 step:10778 [D loss: 0.427308, acc: 93.75%] [G loss: 2.229572]\n",
      "epoch:13 step:10779 [D loss: 0.459067, acc: 87.50%] [G loss: 2.052748]\n",
      "epoch:13 step:10780 [D loss: 0.562776, acc: 71.88%] [G loss: 2.525252]\n",
      "epoch:13 step:10781 [D loss: 0.777055, acc: 46.09%] [G loss: 1.924767]\n",
      "epoch:13 step:10782 [D loss: 0.945078, acc: 31.25%] [G loss: 1.626861]\n",
      "epoch:13 step:10783 [D loss: 0.587518, acc: 73.44%] [G loss: 2.304766]\n",
      "epoch:13 step:10784 [D loss: 0.370662, acc: 94.53%] [G loss: 2.222060]\n",
      "epoch:13 step:10785 [D loss: 0.688734, acc: 57.03%] [G loss: 2.105415]\n",
      "epoch:13 step:10786 [D loss: 0.642615, acc: 63.28%] [G loss: 2.000022]\n",
      "epoch:13 step:10787 [D loss: 0.660092, acc: 63.28%] [G loss: 2.599625]\n",
      "epoch:13 step:10788 [D loss: 0.393231, acc: 89.84%] [G loss: 1.993328]\n",
      "epoch:13 step:10789 [D loss: 0.768095, acc: 52.34%] [G loss: 1.625551]\n",
      "epoch:13 step:10790 [D loss: 0.737964, acc: 50.00%] [G loss: 2.167409]\n",
      "epoch:13 step:10791 [D loss: 0.419594, acc: 88.28%] [G loss: 2.537189]\n",
      "epoch:13 step:10792 [D loss: 0.610764, acc: 62.50%] [G loss: 1.974447]\n",
      "epoch:13 step:10793 [D loss: 0.498405, acc: 80.47%] [G loss: 2.070099]\n",
      "epoch:13 step:10794 [D loss: 0.817555, acc: 39.06%] [G loss: 1.949645]\n",
      "epoch:13 step:10795 [D loss: 0.465329, acc: 89.84%] [G loss: 2.210287]\n",
      "epoch:13 step:10796 [D loss: 0.584626, acc: 70.31%] [G loss: 2.333568]\n",
      "epoch:13 step:10797 [D loss: 0.311752, acc: 95.31%] [G loss: 1.982394]\n",
      "epoch:13 step:10798 [D loss: 0.639678, acc: 59.38%] [G loss: 2.170520]\n",
      "epoch:13 step:10799 [D loss: 0.988395, acc: 28.12%] [G loss: 1.446090]\n",
      "epoch:13 step:10800 [D loss: 0.832681, acc: 40.62%] [G loss: 2.190573]\n",
      "##############\n",
      "[0.87408858 0.86817575 0.82496108 0.79710177 0.79689836 0.82774537\n",
      " 0.89445709 0.81695076 0.81534797 0.83358699]\n",
      "##########\n",
      "epoch:13 step:10801 [D loss: 0.592505, acc: 71.88%] [G loss: 1.898930]\n",
      "epoch:13 step:10802 [D loss: 0.626469, acc: 65.62%] [G loss: 2.233983]\n",
      "epoch:13 step:10803 [D loss: 0.624429, acc: 64.06%] [G loss: 1.966673]\n",
      "epoch:13 step:10804 [D loss: 0.514304, acc: 75.78%] [G loss: 1.659135]\n",
      "epoch:13 step:10805 [D loss: 0.688531, acc: 51.56%] [G loss: 2.162128]\n",
      "epoch:13 step:10806 [D loss: 0.591498, acc: 70.31%] [G loss: 2.186663]\n",
      "epoch:13 step:10807 [D loss: 0.613190, acc: 66.41%] [G loss: 2.163009]\n",
      "epoch:13 step:10808 [D loss: 0.323347, acc: 94.53%] [G loss: 2.905040]\n",
      "epoch:13 step:10809 [D loss: 0.889675, acc: 32.03%] [G loss: 2.070792]\n",
      "epoch:13 step:10810 [D loss: 0.374094, acc: 86.72%] [G loss: 2.776768]\n",
      "epoch:13 step:10811 [D loss: 0.476118, acc: 76.56%] [G loss: 2.451342]\n",
      "epoch:13 step:10812 [D loss: 0.416156, acc: 89.06%] [G loss: 2.243444]\n",
      "epoch:13 step:10813 [D loss: 0.526779, acc: 78.12%] [G loss: 2.292600]\n",
      "epoch:13 step:10814 [D loss: 0.604466, acc: 64.84%] [G loss: 2.185041]\n",
      "epoch:13 step:10815 [D loss: 0.560823, acc: 75.00%] [G loss: 2.796475]\n",
      "epoch:13 step:10816 [D loss: 0.585907, acc: 67.19%] [G loss: 2.276261]\n",
      "epoch:13 step:10817 [D loss: 0.560202, acc: 71.88%] [G loss: 2.680609]\n",
      "epoch:13 step:10818 [D loss: 0.516466, acc: 79.69%] [G loss: 2.215737]\n",
      "epoch:13 step:10819 [D loss: 0.264752, acc: 98.44%] [G loss: 2.618239]\n",
      "epoch:13 step:10820 [D loss: 0.702774, acc: 54.69%] [G loss: 2.350462]\n",
      "epoch:13 step:10821 [D loss: 0.611580, acc: 68.75%] [G loss: 2.076717]\n",
      "epoch:13 step:10822 [D loss: 0.850137, acc: 49.22%] [G loss: 1.390870]\n",
      "epoch:13 step:10823 [D loss: 0.402280, acc: 92.97%] [G loss: 1.789548]\n",
      "epoch:13 step:10824 [D loss: 1.037000, acc: 22.66%] [G loss: 1.535322]\n",
      "epoch:13 step:10825 [D loss: 0.504690, acc: 83.59%] [G loss: 1.723103]\n",
      "epoch:13 step:10826 [D loss: 0.376631, acc: 92.97%] [G loss: 2.149572]\n",
      "epoch:13 step:10827 [D loss: 0.643829, acc: 63.28%] [G loss: 2.332157]\n",
      "epoch:13 step:10828 [D loss: 0.660156, acc: 66.41%] [G loss: 1.790260]\n",
      "epoch:13 step:10829 [D loss: 1.096962, acc: 27.34%] [G loss: 1.709823]\n",
      "epoch:13 step:10830 [D loss: 0.846380, acc: 45.31%] [G loss: 2.027144]\n",
      "epoch:13 step:10831 [D loss: 0.393781, acc: 92.97%] [G loss: 2.222607]\n",
      "epoch:13 step:10832 [D loss: 0.530262, acc: 76.56%] [G loss: 1.976539]\n",
      "epoch:13 step:10833 [D loss: 0.558638, acc: 75.78%] [G loss: 2.287325]\n",
      "epoch:13 step:10834 [D loss: 0.287512, acc: 88.28%] [G loss: 2.903771]\n",
      "epoch:13 step:10835 [D loss: 0.941412, acc: 43.75%] [G loss: 2.173492]\n",
      "epoch:13 step:10836 [D loss: 0.744169, acc: 54.69%] [G loss: 2.479691]\n",
      "epoch:13 step:10837 [D loss: 0.681519, acc: 60.94%] [G loss: 1.584679]\n",
      "epoch:13 step:10838 [D loss: 0.309888, acc: 89.06%] [G loss: 2.543191]\n",
      "epoch:13 step:10839 [D loss: 1.183326, acc: 17.97%] [G loss: 1.880555]\n",
      "epoch:13 step:10840 [D loss: 0.219128, acc: 98.44%] [G loss: 2.494607]\n",
      "epoch:13 step:10841 [D loss: 0.703013, acc: 54.69%] [G loss: 2.134121]\n",
      "epoch:13 step:10842 [D loss: 0.679375, acc: 56.25%] [G loss: 1.739640]\n",
      "epoch:13 step:10843 [D loss: 0.670468, acc: 57.03%] [G loss: 2.575811]\n",
      "epoch:13 step:10844 [D loss: 0.696266, acc: 56.25%] [G loss: 2.024520]\n",
      "epoch:13 step:10845 [D loss: 0.799168, acc: 42.97%] [G loss: 2.212429]\n",
      "epoch:13 step:10846 [D loss: 0.888989, acc: 43.75%] [G loss: 1.904033]\n",
      "epoch:13 step:10847 [D loss: 0.380455, acc: 94.53%] [G loss: 2.748817]\n",
      "epoch:13 step:10848 [D loss: 0.326319, acc: 94.53%] [G loss: 2.658326]\n",
      "epoch:13 step:10849 [D loss: 0.411588, acc: 85.16%] [G loss: 2.356418]\n",
      "epoch:13 step:10850 [D loss: 0.746396, acc: 43.75%] [G loss: 1.640728]\n",
      "epoch:13 step:10851 [D loss: 0.623894, acc: 62.50%] [G loss: 2.436572]\n",
      "epoch:13 step:10852 [D loss: 0.505006, acc: 83.59%] [G loss: 2.488903]\n",
      "epoch:13 step:10853 [D loss: 0.532573, acc: 77.34%] [G loss: 2.596593]\n",
      "epoch:13 step:10854 [D loss: 0.727820, acc: 49.22%] [G loss: 1.952695]\n",
      "epoch:13 step:10855 [D loss: 0.698739, acc: 57.03%] [G loss: 1.937380]\n",
      "epoch:13 step:10856 [D loss: 0.367947, acc: 86.72%] [G loss: 2.582130]\n",
      "epoch:13 step:10857 [D loss: 0.409740, acc: 83.59%] [G loss: 2.137126]\n",
      "epoch:13 step:10858 [D loss: 0.583586, acc: 59.38%] [G loss: 2.163045]\n",
      "epoch:13 step:10859 [D loss: 0.717676, acc: 47.66%] [G loss: 2.944282]\n",
      "epoch:13 step:10860 [D loss: 0.629066, acc: 61.72%] [G loss: 1.830386]\n",
      "epoch:13 step:10861 [D loss: 0.523840, acc: 73.44%] [G loss: 2.678760]\n",
      "epoch:13 step:10862 [D loss: 0.466612, acc: 92.97%] [G loss: 2.563844]\n",
      "epoch:13 step:10863 [D loss: 0.419400, acc: 90.62%] [G loss: 2.820235]\n",
      "epoch:13 step:10864 [D loss: 0.422989, acc: 84.38%] [G loss: 2.118434]\n",
      "epoch:13 step:10865 [D loss: 0.537450, acc: 62.50%] [G loss: 1.570362]\n",
      "epoch:13 step:10866 [D loss: 0.473904, acc: 85.16%] [G loss: 2.062507]\n",
      "epoch:13 step:10867 [D loss: 0.533385, acc: 75.00%] [G loss: 2.160140]\n",
      "epoch:13 step:10868 [D loss: 0.651074, acc: 58.59%] [G loss: 2.867778]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:13 step:10869 [D loss: 0.406365, acc: 89.06%] [G loss: 2.333522]\n",
      "epoch:13 step:10870 [D loss: 0.636356, acc: 62.50%] [G loss: 2.745448]\n",
      "epoch:13 step:10871 [D loss: 0.373531, acc: 89.06%] [G loss: 1.796625]\n",
      "epoch:13 step:10872 [D loss: 0.549933, acc: 75.00%] [G loss: 2.832729]\n",
      "epoch:13 step:10873 [D loss: 0.420732, acc: 74.22%] [G loss: 1.972702]\n",
      "epoch:13 step:10874 [D loss: 1.049212, acc: 14.84%] [G loss: 1.700719]\n",
      "epoch:13 step:10875 [D loss: 0.624567, acc: 59.38%] [G loss: 2.605470]\n",
      "epoch:13 step:10876 [D loss: 0.668355, acc: 58.59%] [G loss: 2.180787]\n",
      "epoch:13 step:10877 [D loss: 0.565703, acc: 73.44%] [G loss: 2.601883]\n",
      "epoch:13 step:10878 [D loss: 0.711837, acc: 53.91%] [G loss: 2.087282]\n",
      "epoch:13 step:10879 [D loss: 0.876409, acc: 38.28%] [G loss: 2.607536]\n",
      "epoch:13 step:10880 [D loss: 0.537960, acc: 70.31%] [G loss: 1.959523]\n",
      "epoch:13 step:10881 [D loss: 0.779788, acc: 50.00%] [G loss: 2.064672]\n",
      "epoch:13 step:10882 [D loss: 0.418341, acc: 72.66%] [G loss: 2.596378]\n",
      "epoch:13 step:10883 [D loss: 0.758132, acc: 47.66%] [G loss: 2.773225]\n",
      "epoch:13 step:10884 [D loss: 0.749992, acc: 50.78%] [G loss: 2.195133]\n",
      "epoch:13 step:10885 [D loss: 0.392541, acc: 85.16%] [G loss: 2.513906]\n",
      "epoch:13 step:10886 [D loss: 0.434958, acc: 87.50%] [G loss: 2.197651]\n",
      "epoch:13 step:10887 [D loss: 0.837934, acc: 44.53%] [G loss: 2.306582]\n",
      "epoch:13 step:10888 [D loss: 0.308227, acc: 96.09%] [G loss: 2.303683]\n",
      "epoch:13 step:10889 [D loss: 0.414183, acc: 87.50%] [G loss: 2.164248]\n",
      "epoch:13 step:10890 [D loss: 0.523186, acc: 64.06%] [G loss: 1.651411]\n",
      "epoch:13 step:10891 [D loss: 0.335412, acc: 92.19%] [G loss: 2.088328]\n",
      "epoch:13 step:10892 [D loss: 0.230524, acc: 99.22%] [G loss: 2.391103]\n",
      "epoch:13 step:10893 [D loss: 0.487514, acc: 69.53%] [G loss: 2.509979]\n",
      "epoch:13 step:10894 [D loss: 0.448331, acc: 80.47%] [G loss: 2.151145]\n",
      "epoch:13 step:10895 [D loss: 0.618220, acc: 60.94%] [G loss: 1.742080]\n",
      "epoch:13 step:10896 [D loss: 0.557997, acc: 71.09%] [G loss: 1.870022]\n",
      "epoch:13 step:10897 [D loss: 0.930075, acc: 47.66%] [G loss: 1.539216]\n",
      "epoch:13 step:10898 [D loss: 0.640698, acc: 62.50%] [G loss: 1.935814]\n",
      "epoch:13 step:10899 [D loss: 0.724909, acc: 54.69%] [G loss: 1.784882]\n",
      "epoch:13 step:10900 [D loss: 0.436076, acc: 89.84%] [G loss: 2.433957]\n",
      "epoch:13 step:10901 [D loss: 0.582947, acc: 73.44%] [G loss: 1.399714]\n",
      "epoch:13 step:10902 [D loss: 0.569800, acc: 68.75%] [G loss: 2.506754]\n",
      "epoch:13 step:10903 [D loss: 0.411569, acc: 87.50%] [G loss: 1.999555]\n",
      "epoch:13 step:10904 [D loss: 0.619763, acc: 64.06%] [G loss: 1.902555]\n",
      "epoch:13 step:10905 [D loss: 0.371759, acc: 92.97%] [G loss: 2.494966]\n",
      "epoch:13 step:10906 [D loss: 0.676342, acc: 57.03%] [G loss: 2.523754]\n",
      "epoch:13 step:10907 [D loss: 0.531328, acc: 78.12%] [G loss: 2.875534]\n",
      "epoch:13 step:10908 [D loss: 0.620155, acc: 61.72%] [G loss: 1.997394]\n",
      "epoch:13 step:10909 [D loss: 0.764566, acc: 53.12%] [G loss: 1.918418]\n",
      "epoch:13 step:10910 [D loss: 0.610089, acc: 61.72%] [G loss: 2.493959]\n",
      "epoch:13 step:10911 [D loss: 0.860588, acc: 50.00%] [G loss: 2.941041]\n",
      "epoch:13 step:10912 [D loss: 0.495898, acc: 75.00%] [G loss: 2.063111]\n",
      "epoch:13 step:10913 [D loss: 0.773520, acc: 54.69%] [G loss: 3.302129]\n",
      "epoch:13 step:10914 [D loss: 0.321547, acc: 95.31%] [G loss: 2.811178]\n",
      "epoch:13 step:10915 [D loss: 0.443782, acc: 86.72%] [G loss: 2.501382]\n",
      "epoch:13 step:10916 [D loss: 0.446602, acc: 88.28%] [G loss: 2.465443]\n",
      "epoch:13 step:10917 [D loss: 0.756725, acc: 53.12%] [G loss: 1.653653]\n",
      "epoch:13 step:10918 [D loss: 0.253215, acc: 100.00%] [G loss: 3.032283]\n",
      "epoch:13 step:10919 [D loss: 0.594133, acc: 58.59%] [G loss: 2.996542]\n",
      "epoch:13 step:10920 [D loss: 0.521091, acc: 75.78%] [G loss: 2.134630]\n",
      "epoch:13 step:10921 [D loss: 0.492203, acc: 85.16%] [G loss: 2.468346]\n",
      "epoch:13 step:10922 [D loss: 0.741134, acc: 52.34%] [G loss: 2.389584]\n",
      "epoch:13 step:10923 [D loss: 0.510300, acc: 80.47%] [G loss: 2.677494]\n",
      "epoch:13 step:10924 [D loss: 0.652861, acc: 63.28%] [G loss: 2.063414]\n",
      "epoch:13 step:10925 [D loss: 0.730344, acc: 54.69%] [G loss: 2.150872]\n",
      "epoch:13 step:10926 [D loss: 0.794071, acc: 52.34%] [G loss: 2.364039]\n",
      "epoch:13 step:10927 [D loss: 0.690621, acc: 52.34%] [G loss: 1.861388]\n",
      "epoch:13 step:10928 [D loss: 1.495454, acc: 3.91%] [G loss: 1.554629]\n",
      "epoch:13 step:10929 [D loss: 0.847106, acc: 42.97%] [G loss: 1.746939]\n",
      "epoch:13 step:10930 [D loss: 0.806016, acc: 48.44%] [G loss: 2.551914]\n",
      "epoch:13 step:10931 [D loss: 0.684410, acc: 63.28%] [G loss: 1.849607]\n",
      "epoch:13 step:10932 [D loss: 0.754868, acc: 43.75%] [G loss: 1.678664]\n",
      "epoch:13 step:10933 [D loss: 0.622879, acc: 58.59%] [G loss: 3.242200]\n",
      "epoch:13 step:10934 [D loss: 0.500347, acc: 77.34%] [G loss: 2.194256]\n",
      "epoch:14 step:10935 [D loss: 0.500333, acc: 76.56%] [G loss: 2.264616]\n",
      "epoch:14 step:10936 [D loss: 0.551543, acc: 67.97%] [G loss: 2.889803]\n",
      "epoch:14 step:10937 [D loss: 0.616337, acc: 64.84%] [G loss: 2.260119]\n",
      "epoch:14 step:10938 [D loss: 0.527069, acc: 77.34%] [G loss: 2.173613]\n",
      "epoch:14 step:10939 [D loss: 0.564692, acc: 78.12%] [G loss: 2.297788]\n",
      "epoch:14 step:10940 [D loss: 0.456918, acc: 84.38%] [G loss: 2.643500]\n",
      "epoch:14 step:10941 [D loss: 0.790688, acc: 46.09%] [G loss: 1.799067]\n",
      "epoch:14 step:10942 [D loss: 0.625145, acc: 62.50%] [G loss: 2.161089]\n",
      "epoch:14 step:10943 [D loss: 0.567062, acc: 73.44%] [G loss: 2.000340]\n",
      "epoch:14 step:10944 [D loss: 0.685779, acc: 57.81%] [G loss: 2.204210]\n",
      "epoch:14 step:10945 [D loss: 0.457414, acc: 89.84%] [G loss: 2.316249]\n",
      "epoch:14 step:10946 [D loss: 0.716753, acc: 51.56%] [G loss: 2.003140]\n",
      "epoch:14 step:10947 [D loss: 0.684720, acc: 57.81%] [G loss: 2.199262]\n",
      "epoch:14 step:10948 [D loss: 0.789940, acc: 53.91%] [G loss: 1.702756]\n",
      "epoch:14 step:10949 [D loss: 0.623840, acc: 65.62%] [G loss: 1.936299]\n",
      "epoch:14 step:10950 [D loss: 0.704245, acc: 56.25%] [G loss: 2.113863]\n",
      "epoch:14 step:10951 [D loss: 0.774028, acc: 53.91%] [G loss: 2.493461]\n",
      "epoch:14 step:10952 [D loss: 0.672842, acc: 58.59%] [G loss: 1.953472]\n",
      "epoch:14 step:10953 [D loss: 0.221338, acc: 98.44%] [G loss: 2.961997]\n",
      "epoch:14 step:10954 [D loss: 0.601251, acc: 64.84%] [G loss: 2.213918]\n",
      "epoch:14 step:10955 [D loss: 0.639636, acc: 64.84%] [G loss: 1.751525]\n",
      "epoch:14 step:10956 [D loss: 0.681219, acc: 56.25%] [G loss: 1.958932]\n",
      "epoch:14 step:10957 [D loss: 0.395987, acc: 89.84%] [G loss: 2.470199]\n",
      "epoch:14 step:10958 [D loss: 0.615638, acc: 65.62%] [G loss: 1.987417]\n",
      "epoch:14 step:10959 [D loss: 0.842119, acc: 42.19%] [G loss: 2.247637]\n",
      "epoch:14 step:10960 [D loss: 0.631129, acc: 62.50%] [G loss: 1.771952]\n",
      "epoch:14 step:10961 [D loss: 0.474369, acc: 88.28%] [G loss: 1.931607]\n",
      "epoch:14 step:10962 [D loss: 0.413417, acc: 84.38%] [G loss: 2.442250]\n",
      "epoch:14 step:10963 [D loss: 0.393833, acc: 92.97%] [G loss: 1.951548]\n",
      "epoch:14 step:10964 [D loss: 0.508712, acc: 82.03%] [G loss: 2.764778]\n",
      "epoch:14 step:10965 [D loss: 0.265745, acc: 96.09%] [G loss: 2.385771]\n",
      "epoch:14 step:10966 [D loss: 0.566903, acc: 70.31%] [G loss: 2.061269]\n",
      "epoch:14 step:10967 [D loss: 0.560332, acc: 57.81%] [G loss: 2.320433]\n",
      "epoch:14 step:10968 [D loss: 0.415713, acc: 92.19%] [G loss: 2.437415]\n",
      "epoch:14 step:10969 [D loss: 0.883457, acc: 39.84%] [G loss: 2.497096]\n",
      "epoch:14 step:10970 [D loss: 0.659477, acc: 57.81%] [G loss: 2.367005]\n",
      "epoch:14 step:10971 [D loss: 0.785352, acc: 46.09%] [G loss: 1.789930]\n",
      "epoch:14 step:10972 [D loss: 0.609550, acc: 74.22%] [G loss: 1.857143]\n",
      "epoch:14 step:10973 [D loss: 0.741550, acc: 51.56%] [G loss: 2.204082]\n",
      "epoch:14 step:10974 [D loss: 0.451033, acc: 86.72%] [G loss: 2.326420]\n",
      "epoch:14 step:10975 [D loss: 0.604373, acc: 61.72%] [G loss: 2.658423]\n",
      "epoch:14 step:10976 [D loss: 0.393750, acc: 89.84%] [G loss: 2.295598]\n",
      "epoch:14 step:10977 [D loss: 0.552188, acc: 71.88%] [G loss: 2.240864]\n",
      "epoch:14 step:10978 [D loss: 0.657744, acc: 59.38%] [G loss: 1.843997]\n",
      "epoch:14 step:10979 [D loss: 0.679143, acc: 58.59%] [G loss: 2.403129]\n",
      "epoch:14 step:10980 [D loss: 0.454936, acc: 91.41%] [G loss: 2.726573]\n",
      "epoch:14 step:10981 [D loss: 0.809725, acc: 28.91%] [G loss: 2.011128]\n",
      "epoch:14 step:10982 [D loss: 0.868993, acc: 46.88%] [G loss: 2.098500]\n",
      "epoch:14 step:10983 [D loss: 0.447008, acc: 88.28%] [G loss: 2.069969]\n",
      "epoch:14 step:10984 [D loss: 0.472532, acc: 75.00%] [G loss: 2.250593]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:14 step:10985 [D loss: 0.287637, acc: 93.75%] [G loss: 2.563146]\n",
      "epoch:14 step:10986 [D loss: 0.575309, acc: 67.19%] [G loss: 2.251155]\n",
      "epoch:14 step:10987 [D loss: 0.351373, acc: 95.31%] [G loss: 2.248672]\n",
      "epoch:14 step:10988 [D loss: 0.562366, acc: 74.22%] [G loss: 1.613861]\n",
      "epoch:14 step:10989 [D loss: 1.089118, acc: 21.88%] [G loss: 1.669035]\n",
      "epoch:14 step:10990 [D loss: 0.494838, acc: 80.47%] [G loss: 1.722457]\n",
      "epoch:14 step:10991 [D loss: 0.488882, acc: 84.38%] [G loss: 1.801871]\n",
      "epoch:14 step:10992 [D loss: 0.377982, acc: 92.19%] [G loss: 1.867430]\n",
      "epoch:14 step:10993 [D loss: 0.405247, acc: 90.62%] [G loss: 2.331074]\n",
      "epoch:14 step:10994 [D loss: 0.816594, acc: 47.66%] [G loss: 1.859803]\n",
      "epoch:14 step:10995 [D loss: 0.377137, acc: 82.03%] [G loss: 3.330506]\n",
      "epoch:14 step:10996 [D loss: 0.721397, acc: 55.47%] [G loss: 2.928716]\n",
      "epoch:14 step:10997 [D loss: 0.656128, acc: 57.03%] [G loss: 1.625462]\n",
      "epoch:14 step:10998 [D loss: 0.516871, acc: 74.22%] [G loss: 2.012011]\n",
      "epoch:14 step:10999 [D loss: 0.604016, acc: 67.19%] [G loss: 2.598960]\n",
      "epoch:14 step:11000 [D loss: 0.627344, acc: 64.06%] [G loss: 2.406196]\n",
      "##############\n",
      "[0.8582125  0.86975308 0.81239539 0.82410521 0.81611002 0.84286429\n",
      " 0.89221163 0.85306799 0.80519564 0.82384469]\n",
      "##########\n",
      "epoch:14 step:11001 [D loss: 0.566030, acc: 75.00%] [G loss: 2.123060]\n",
      "epoch:14 step:11002 [D loss: 0.854442, acc: 53.12%] [G loss: 1.978843]\n",
      "epoch:14 step:11003 [D loss: 0.334306, acc: 81.25%] [G loss: 2.678701]\n",
      "epoch:14 step:11004 [D loss: 0.880454, acc: 40.62%] [G loss: 3.097872]\n",
      "epoch:14 step:11005 [D loss: 1.035623, acc: 50.00%] [G loss: 2.808942]\n",
      "epoch:14 step:11006 [D loss: 0.642842, acc: 64.06%] [G loss: 2.596326]\n",
      "epoch:14 step:11007 [D loss: 0.641699, acc: 58.59%] [G loss: 2.499041]\n",
      "epoch:14 step:11008 [D loss: 0.631841, acc: 64.84%] [G loss: 2.839050]\n",
      "epoch:14 step:11009 [D loss: 0.484426, acc: 84.38%] [G loss: 2.613770]\n",
      "epoch:14 step:11010 [D loss: 0.375461, acc: 91.41%] [G loss: 2.891459]\n",
      "epoch:14 step:11011 [D loss: 0.265878, acc: 93.75%] [G loss: 2.188614]\n",
      "epoch:14 step:11012 [D loss: 0.684734, acc: 54.69%] [G loss: 3.738549]\n",
      "epoch:14 step:11013 [D loss: 0.632510, acc: 66.41%] [G loss: 2.064090]\n",
      "epoch:14 step:11014 [D loss: 0.381108, acc: 94.53%] [G loss: 2.263765]\n",
      "epoch:14 step:11015 [D loss: 0.432823, acc: 86.72%] [G loss: 2.659710]\n",
      "epoch:14 step:11016 [D loss: 0.316436, acc: 86.72%] [G loss: 4.507821]\n",
      "epoch:14 step:11017 [D loss: 0.330318, acc: 96.09%] [G loss: 2.433291]\n",
      "epoch:14 step:11018 [D loss: 1.005075, acc: 39.06%] [G loss: 1.119450]\n",
      "epoch:14 step:11019 [D loss: 0.588534, acc: 65.62%] [G loss: 2.506728]\n",
      "epoch:14 step:11020 [D loss: 0.808673, acc: 42.97%] [G loss: 2.208405]\n",
      "epoch:14 step:11021 [D loss: 0.350565, acc: 93.75%] [G loss: 2.340276]\n",
      "epoch:14 step:11022 [D loss: 0.891979, acc: 28.91%] [G loss: 1.633431]\n",
      "epoch:14 step:11023 [D loss: 0.465505, acc: 83.59%] [G loss: 2.106924]\n",
      "epoch:14 step:11024 [D loss: 0.541215, acc: 75.00%] [G loss: 2.647253]\n",
      "epoch:14 step:11025 [D loss: 1.035545, acc: 23.44%] [G loss: 1.783928]\n",
      "epoch:14 step:11026 [D loss: 0.826617, acc: 41.41%] [G loss: 1.956062]\n",
      "epoch:14 step:11027 [D loss: 0.644903, acc: 64.84%] [G loss: 2.189250]\n",
      "epoch:14 step:11028 [D loss: 0.424588, acc: 81.25%] [G loss: 2.191395]\n",
      "epoch:14 step:11029 [D loss: 0.388526, acc: 89.84%] [G loss: 3.335435]\n",
      "epoch:14 step:11030 [D loss: 0.693242, acc: 60.94%] [G loss: 2.008186]\n",
      "epoch:14 step:11031 [D loss: 0.640791, acc: 57.81%] [G loss: 1.968605]\n",
      "epoch:14 step:11032 [D loss: 0.307349, acc: 95.31%] [G loss: 2.935548]\n",
      "epoch:14 step:11033 [D loss: 0.540233, acc: 78.12%] [G loss: 2.639996]\n",
      "epoch:14 step:11034 [D loss: 0.648670, acc: 60.94%] [G loss: 2.459643]\n",
      "epoch:14 step:11035 [D loss: 1.357424, acc: 15.62%] [G loss: 3.610124]\n",
      "epoch:14 step:11036 [D loss: 0.438777, acc: 85.94%] [G loss: 3.255262]\n",
      "epoch:14 step:11037 [D loss: 0.780443, acc: 50.78%] [G loss: 3.564519]\n",
      "epoch:14 step:11038 [D loss: 0.212079, acc: 98.44%] [G loss: 4.002947]\n",
      "epoch:14 step:11039 [D loss: 0.841983, acc: 50.00%] [G loss: 2.811759]\n",
      "epoch:14 step:11040 [D loss: 0.397565, acc: 94.53%] [G loss: 2.607687]\n",
      "epoch:14 step:11041 [D loss: 0.622099, acc: 67.19%] [G loss: 3.376543]\n",
      "epoch:14 step:11042 [D loss: 1.042941, acc: 25.00%] [G loss: 1.776380]\n",
      "epoch:14 step:11043 [D loss: 0.403002, acc: 90.62%] [G loss: 2.064998]\n",
      "epoch:14 step:11044 [D loss: 0.657834, acc: 58.59%] [G loss: 1.815675]\n",
      "epoch:14 step:11045 [D loss: 0.322075, acc: 92.97%] [G loss: 2.293268]\n",
      "epoch:14 step:11046 [D loss: 0.838848, acc: 50.00%] [G loss: 2.611065]\n",
      "epoch:14 step:11047 [D loss: 0.307159, acc: 96.88%] [G loss: 3.020759]\n",
      "epoch:14 step:11048 [D loss: 0.494362, acc: 78.91%] [G loss: 1.728118]\n",
      "epoch:14 step:11049 [D loss: 0.541144, acc: 70.31%] [G loss: 2.089248]\n",
      "epoch:14 step:11050 [D loss: 0.618940, acc: 65.62%] [G loss: 2.405103]\n",
      "epoch:14 step:11051 [D loss: 0.767124, acc: 46.88%] [G loss: 2.374297]\n",
      "epoch:14 step:11052 [D loss: 0.200363, acc: 100.00%] [G loss: 3.103109]\n",
      "epoch:14 step:11053 [D loss: 0.606651, acc: 63.28%] [G loss: 2.423775]\n",
      "epoch:14 step:11054 [D loss: 0.710740, acc: 56.25%] [G loss: 1.883059]\n",
      "epoch:14 step:11055 [D loss: 0.518486, acc: 80.47%] [G loss: 2.095356]\n",
      "epoch:14 step:11056 [D loss: 0.989416, acc: 21.88%] [G loss: 1.901518]\n",
      "epoch:14 step:11057 [D loss: 0.536778, acc: 75.00%] [G loss: 2.295415]\n",
      "epoch:14 step:11058 [D loss: 0.876948, acc: 37.50%] [G loss: 1.670009]\n",
      "epoch:14 step:11059 [D loss: 0.556719, acc: 71.09%] [G loss: 1.867645]\n",
      "epoch:14 step:11060 [D loss: 0.496670, acc: 70.31%] [G loss: 2.565364]\n",
      "epoch:14 step:11061 [D loss: 0.858578, acc: 48.44%] [G loss: 2.390766]\n",
      "epoch:14 step:11062 [D loss: 0.395164, acc: 92.19%] [G loss: 2.414873]\n",
      "epoch:14 step:11063 [D loss: 0.235804, acc: 94.53%] [G loss: 2.571855]\n",
      "epoch:14 step:11064 [D loss: 0.679708, acc: 57.03%] [G loss: 2.347284]\n",
      "epoch:14 step:11065 [D loss: 0.540732, acc: 61.72%] [G loss: 2.564347]\n",
      "epoch:14 step:11066 [D loss: 0.601020, acc: 66.41%] [G loss: 1.849266]\n",
      "epoch:14 step:11067 [D loss: 0.735063, acc: 50.00%] [G loss: 1.753067]\n",
      "epoch:14 step:11068 [D loss: 0.405676, acc: 91.41%] [G loss: 2.661309]\n",
      "epoch:14 step:11069 [D loss: 0.751238, acc: 46.88%] [G loss: 1.736406]\n",
      "epoch:14 step:11070 [D loss: 0.560278, acc: 66.41%] [G loss: 2.929627]\n",
      "epoch:14 step:11071 [D loss: 0.474828, acc: 92.19%] [G loss: 2.633039]\n",
      "epoch:14 step:11072 [D loss: 0.623523, acc: 60.94%] [G loss: 2.191289]\n",
      "epoch:14 step:11073 [D loss: 0.355330, acc: 95.31%] [G loss: 3.470208]\n",
      "epoch:14 step:11074 [D loss: 0.513424, acc: 79.69%] [G loss: 2.011008]\n",
      "epoch:14 step:11075 [D loss: 0.541301, acc: 60.16%] [G loss: 1.916021]\n",
      "epoch:14 step:11076 [D loss: 0.610309, acc: 60.94%] [G loss: 1.860718]\n",
      "epoch:14 step:11077 [D loss: 0.530020, acc: 78.91%] [G loss: 1.696620]\n",
      "epoch:14 step:11078 [D loss: 0.966951, acc: 39.06%] [G loss: 1.896455]\n",
      "epoch:14 step:11079 [D loss: 0.745499, acc: 51.56%] [G loss: 2.203341]\n",
      "epoch:14 step:11080 [D loss: 0.611676, acc: 71.09%] [G loss: 2.157543]\n",
      "epoch:14 step:11081 [D loss: 0.398304, acc: 78.91%] [G loss: 2.233631]\n",
      "epoch:14 step:11082 [D loss: 0.643905, acc: 63.28%] [G loss: 2.892382]\n",
      "epoch:14 step:11083 [D loss: 0.761650, acc: 47.66%] [G loss: 1.955966]\n",
      "epoch:14 step:11084 [D loss: 0.377098, acc: 92.19%] [G loss: 1.990804]\n",
      "epoch:14 step:11085 [D loss: 0.494456, acc: 84.38%] [G loss: 2.764024]\n",
      "epoch:14 step:11086 [D loss: 0.568244, acc: 67.97%] [G loss: 2.862395]\n",
      "epoch:14 step:11087 [D loss: 0.495672, acc: 78.12%] [G loss: 3.532765]\n",
      "epoch:14 step:11088 [D loss: 0.360333, acc: 92.19%] [G loss: 3.735824]\n",
      "epoch:14 step:11089 [D loss: 0.351559, acc: 95.31%] [G loss: 2.549082]\n",
      "epoch:14 step:11090 [D loss: 0.240725, acc: 92.19%] [G loss: 3.543185]\n",
      "epoch:14 step:11091 [D loss: 0.546472, acc: 67.97%] [G loss: 2.996327]\n",
      "epoch:14 step:11092 [D loss: 0.610526, acc: 64.06%] [G loss: 2.646597]\n",
      "epoch:14 step:11093 [D loss: 0.530733, acc: 78.91%] [G loss: 2.085477]\n",
      "epoch:14 step:11094 [D loss: 0.630396, acc: 61.72%] [G loss: 1.766067]\n",
      "epoch:14 step:11095 [D loss: 0.444735, acc: 76.56%] [G loss: 2.285912]\n",
      "epoch:14 step:11096 [D loss: 0.397645, acc: 78.91%] [G loss: 2.856281]\n",
      "epoch:14 step:11097 [D loss: 0.872544, acc: 34.38%] [G loss: 2.366008]\n",
      "epoch:14 step:11098 [D loss: 0.415480, acc: 81.25%] [G loss: 2.347847]\n",
      "epoch:14 step:11099 [D loss: 0.624269, acc: 66.41%] [G loss: 1.908138]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:14 step:11100 [D loss: 0.883781, acc: 36.72%] [G loss: 1.938524]\n",
      "epoch:14 step:11101 [D loss: 0.832916, acc: 36.72%] [G loss: 1.810930]\n",
      "epoch:14 step:11102 [D loss: 0.602786, acc: 65.62%] [G loss: 2.151744]\n",
      "epoch:14 step:11103 [D loss: 0.445920, acc: 71.88%] [G loss: 2.003646]\n",
      "epoch:14 step:11104 [D loss: 0.919260, acc: 39.06%] [G loss: 2.042698]\n",
      "epoch:14 step:11105 [D loss: 0.664693, acc: 64.06%] [G loss: 1.921296]\n",
      "epoch:14 step:11106 [D loss: 0.428581, acc: 74.22%] [G loss: 2.536472]\n",
      "epoch:14 step:11107 [D loss: 0.501650, acc: 78.91%] [G loss: 2.296216]\n",
      "epoch:14 step:11108 [D loss: 0.754706, acc: 55.47%] [G loss: 2.273287]\n",
      "epoch:14 step:11109 [D loss: 0.691083, acc: 55.47%] [G loss: 1.842945]\n",
      "epoch:14 step:11110 [D loss: 0.879844, acc: 40.62%] [G loss: 1.792884]\n",
      "epoch:14 step:11111 [D loss: 0.788870, acc: 46.09%] [G loss: 2.031256]\n",
      "epoch:14 step:11112 [D loss: 0.532201, acc: 79.69%] [G loss: 2.000192]\n",
      "epoch:14 step:11113 [D loss: 0.619159, acc: 64.06%] [G loss: 1.938355]\n",
      "epoch:14 step:11114 [D loss: 1.032602, acc: 40.62%] [G loss: 2.160625]\n",
      "epoch:14 step:11115 [D loss: 1.179862, acc: 13.28%] [G loss: 1.749554]\n",
      "epoch:14 step:11116 [D loss: 0.648737, acc: 57.81%] [G loss: 2.270081]\n",
      "epoch:14 step:11117 [D loss: 0.242688, acc: 97.66%] [G loss: 2.620736]\n",
      "epoch:14 step:11118 [D loss: 0.668442, acc: 61.72%] [G loss: 2.047020]\n",
      "epoch:14 step:11119 [D loss: 0.668711, acc: 59.38%] [G loss: 1.807879]\n",
      "epoch:14 step:11120 [D loss: 0.620491, acc: 63.28%] [G loss: 2.199275]\n",
      "epoch:14 step:11121 [D loss: 0.656291, acc: 56.25%] [G loss: 2.806921]\n",
      "epoch:14 step:11122 [D loss: 0.670287, acc: 53.12%] [G loss: 2.323657]\n",
      "epoch:14 step:11123 [D loss: 0.364666, acc: 93.75%] [G loss: 2.347517]\n",
      "epoch:14 step:11124 [D loss: 0.434825, acc: 75.00%] [G loss: 1.829443]\n",
      "epoch:14 step:11125 [D loss: 0.584362, acc: 65.62%] [G loss: 2.178246]\n",
      "epoch:14 step:11126 [D loss: 0.785732, acc: 46.88%] [G loss: 2.386661]\n",
      "epoch:14 step:11127 [D loss: 0.574456, acc: 58.59%] [G loss: 2.233850]\n",
      "epoch:14 step:11128 [D loss: 0.295443, acc: 95.31%] [G loss: 2.637628]\n",
      "epoch:14 step:11129 [D loss: 0.727587, acc: 46.88%] [G loss: 1.754931]\n",
      "epoch:14 step:11130 [D loss: 0.731540, acc: 46.09%] [G loss: 2.209961]\n",
      "epoch:14 step:11131 [D loss: 0.518942, acc: 72.66%] [G loss: 2.368374]\n",
      "epoch:14 step:11132 [D loss: 0.369669, acc: 92.19%] [G loss: 2.024918]\n",
      "epoch:14 step:11133 [D loss: 0.816023, acc: 50.78%] [G loss: 2.467176]\n",
      "epoch:14 step:11134 [D loss: 0.425196, acc: 85.94%] [G loss: 2.326249]\n",
      "epoch:14 step:11135 [D loss: 0.374472, acc: 94.53%] [G loss: 2.303438]\n",
      "epoch:14 step:11136 [D loss: 0.911641, acc: 51.56%] [G loss: 1.847427]\n",
      "epoch:14 step:11137 [D loss: 0.280277, acc: 98.44%] [G loss: 2.500821]\n",
      "epoch:14 step:11138 [D loss: 0.549277, acc: 66.41%] [G loss: 1.861732]\n",
      "epoch:14 step:11139 [D loss: 0.734371, acc: 53.12%] [G loss: 2.394156]\n",
      "epoch:14 step:11140 [D loss: 0.744567, acc: 53.91%] [G loss: 2.272249]\n",
      "epoch:14 step:11141 [D loss: 0.804410, acc: 45.31%] [G loss: 2.097503]\n",
      "epoch:14 step:11142 [D loss: 0.269739, acc: 97.66%] [G loss: 3.023918]\n",
      "epoch:14 step:11143 [D loss: 1.222459, acc: 14.06%] [G loss: 1.649997]\n",
      "epoch:14 step:11144 [D loss: 0.688217, acc: 60.94%] [G loss: 2.619450]\n",
      "epoch:14 step:11145 [D loss: 0.452209, acc: 82.03%] [G loss: 3.131162]\n",
      "epoch:14 step:11146 [D loss: 0.544775, acc: 78.12%] [G loss: 1.760207]\n",
      "epoch:14 step:11147 [D loss: 0.694888, acc: 55.47%] [G loss: 2.046616]\n",
      "epoch:14 step:11148 [D loss: 0.462334, acc: 85.16%] [G loss: 2.141444]\n",
      "epoch:14 step:11149 [D loss: 0.494082, acc: 82.03%] [G loss: 2.271933]\n",
      "epoch:14 step:11150 [D loss: 0.979867, acc: 35.16%] [G loss: 1.920263]\n",
      "epoch:14 step:11151 [D loss: 0.636573, acc: 58.59%] [G loss: 1.876843]\n",
      "epoch:14 step:11152 [D loss: 0.673612, acc: 57.03%] [G loss: 2.261754]\n",
      "epoch:14 step:11153 [D loss: 0.560906, acc: 73.44%] [G loss: 2.129492]\n",
      "epoch:14 step:11154 [D loss: 0.521984, acc: 85.16%] [G loss: 2.352890]\n",
      "epoch:14 step:11155 [D loss: 0.777134, acc: 48.44%] [G loss: 1.637213]\n",
      "epoch:14 step:11156 [D loss: 0.525105, acc: 73.44%] [G loss: 1.966619]\n",
      "epoch:14 step:11157 [D loss: 0.959230, acc: 26.56%] [G loss: 2.308088]\n",
      "epoch:14 step:11158 [D loss: 0.672554, acc: 54.69%] [G loss: 2.078729]\n",
      "epoch:14 step:11159 [D loss: 0.700582, acc: 54.69%] [G loss: 1.827162]\n",
      "epoch:14 step:11160 [D loss: 0.468412, acc: 82.03%] [G loss: 1.656093]\n",
      "epoch:14 step:11161 [D loss: 0.557750, acc: 77.34%] [G loss: 1.938396]\n",
      "epoch:14 step:11162 [D loss: 1.070478, acc: 36.72%] [G loss: 1.859966]\n",
      "epoch:14 step:11163 [D loss: 0.279610, acc: 95.31%] [G loss: 2.057529]\n",
      "epoch:14 step:11164 [D loss: 0.862150, acc: 31.25%] [G loss: 2.269055]\n",
      "epoch:14 step:11165 [D loss: 0.369656, acc: 92.19%] [G loss: 2.882372]\n",
      "epoch:14 step:11166 [D loss: 0.802256, acc: 47.66%] [G loss: 1.567799]\n",
      "epoch:14 step:11167 [D loss: 0.588222, acc: 66.41%] [G loss: 1.728538]\n",
      "epoch:14 step:11168 [D loss: 0.907615, acc: 31.25%] [G loss: 2.120498]\n",
      "epoch:14 step:11169 [D loss: 0.697231, acc: 51.56%] [G loss: 1.428787]\n",
      "epoch:14 step:11170 [D loss: 0.929173, acc: 23.44%] [G loss: 1.744600]\n",
      "epoch:14 step:11171 [D loss: 0.646733, acc: 64.06%] [G loss: 1.966146]\n",
      "epoch:14 step:11172 [D loss: 0.966510, acc: 25.78%] [G loss: 1.168247]\n",
      "epoch:14 step:11173 [D loss: 0.653377, acc: 62.50%] [G loss: 1.867557]\n",
      "epoch:14 step:11174 [D loss: 0.588749, acc: 74.22%] [G loss: 1.895484]\n",
      "epoch:14 step:11175 [D loss: 0.711646, acc: 53.12%] [G loss: 2.193884]\n",
      "epoch:14 step:11176 [D loss: 0.803613, acc: 47.66%] [G loss: 1.665802]\n",
      "epoch:14 step:11177 [D loss: 0.516537, acc: 74.22%] [G loss: 1.693862]\n",
      "epoch:14 step:11178 [D loss: 0.648493, acc: 59.38%] [G loss: 1.815435]\n",
      "epoch:14 step:11179 [D loss: 0.755776, acc: 47.66%] [G loss: 1.751602]\n",
      "epoch:14 step:11180 [D loss: 0.635723, acc: 61.72%] [G loss: 2.347688]\n",
      "epoch:14 step:11181 [D loss: 0.829376, acc: 50.00%] [G loss: 1.956584]\n",
      "epoch:14 step:11182 [D loss: 0.578561, acc: 70.31%] [G loss: 1.558956]\n",
      "epoch:14 step:11183 [D loss: 0.599794, acc: 71.09%] [G loss: 2.078769]\n",
      "epoch:14 step:11184 [D loss: 0.441494, acc: 88.28%] [G loss: 2.670582]\n",
      "epoch:14 step:11185 [D loss: 0.906913, acc: 23.44%] [G loss: 1.752582]\n",
      "epoch:14 step:11186 [D loss: 0.435427, acc: 89.06%] [G loss: 2.089263]\n",
      "epoch:14 step:11187 [D loss: 0.708583, acc: 55.47%] [G loss: 1.836153]\n",
      "epoch:14 step:11188 [D loss: 0.730613, acc: 50.78%] [G loss: 1.862793]\n",
      "epoch:14 step:11189 [D loss: 0.778975, acc: 40.62%] [G loss: 1.821595]\n",
      "epoch:14 step:11190 [D loss: 0.514077, acc: 80.47%] [G loss: 2.038367]\n",
      "epoch:14 step:11191 [D loss: 1.018420, acc: 18.75%] [G loss: 1.702806]\n",
      "epoch:14 step:11192 [D loss: 0.537986, acc: 78.12%] [G loss: 2.264252]\n",
      "epoch:14 step:11193 [D loss: 0.625581, acc: 67.97%] [G loss: 1.800206]\n",
      "epoch:14 step:11194 [D loss: 0.638545, acc: 63.28%] [G loss: 2.256857]\n",
      "epoch:14 step:11195 [D loss: 0.569126, acc: 73.44%] [G loss: 2.011678]\n",
      "epoch:14 step:11196 [D loss: 0.518928, acc: 78.12%] [G loss: 2.535086]\n",
      "epoch:14 step:11197 [D loss: 0.692273, acc: 56.25%] [G loss: 2.464113]\n",
      "epoch:14 step:11198 [D loss: 0.750353, acc: 44.53%] [G loss: 1.509009]\n",
      "epoch:14 step:11199 [D loss: 0.520522, acc: 84.38%] [G loss: 2.177722]\n",
      "epoch:14 step:11200 [D loss: 0.530559, acc: 82.81%] [G loss: 2.786138]\n",
      "##############\n",
      "[0.85959942 0.86710854 0.79998872 0.82920667 0.78048526 0.82986135\n",
      " 0.9074511  0.84571458 0.81305268 0.83907728]\n",
      "##########\n",
      "epoch:14 step:11201 [D loss: 1.050531, acc: 27.34%] [G loss: 1.594777]\n",
      "epoch:14 step:11202 [D loss: 0.549729, acc: 65.62%] [G loss: 1.867833]\n",
      "epoch:14 step:11203 [D loss: 0.824612, acc: 37.50%] [G loss: 1.784647]\n",
      "epoch:14 step:11204 [D loss: 0.450634, acc: 78.12%] [G loss: 2.167915]\n",
      "epoch:14 step:11205 [D loss: 0.515776, acc: 84.38%] [G loss: 2.037005]\n",
      "epoch:14 step:11206 [D loss: 0.882081, acc: 41.41%] [G loss: 1.677756]\n",
      "epoch:14 step:11207 [D loss: 0.813083, acc: 38.28%] [G loss: 1.762767]\n",
      "epoch:14 step:11208 [D loss: 0.420618, acc: 80.47%] [G loss: 2.139413]\n",
      "epoch:14 step:11209 [D loss: 0.301428, acc: 95.31%] [G loss: 2.331928]\n",
      "epoch:14 step:11210 [D loss: 0.514551, acc: 81.25%] [G loss: 3.158936]\n",
      "epoch:14 step:11211 [D loss: 0.712641, acc: 54.69%] [G loss: 2.397314]\n",
      "epoch:14 step:11212 [D loss: 0.613321, acc: 69.53%] [G loss: 2.186745]\n",
      "epoch:14 step:11213 [D loss: 0.542372, acc: 75.78%] [G loss: 2.276867]\n",
      "epoch:14 step:11214 [D loss: 0.530363, acc: 73.44%] [G loss: 2.019810]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:14 step:11215 [D loss: 0.480176, acc: 79.69%] [G loss: 1.923362]\n",
      "epoch:14 step:11216 [D loss: 0.595864, acc: 61.72%] [G loss: 2.138118]\n",
      "epoch:14 step:11217 [D loss: 0.617797, acc: 60.16%] [G loss: 1.677078]\n",
      "epoch:14 step:11218 [D loss: 0.570392, acc: 73.44%] [G loss: 1.962076]\n",
      "epoch:14 step:11219 [D loss: 0.534557, acc: 77.34%] [G loss: 2.072950]\n",
      "epoch:14 step:11220 [D loss: 0.347906, acc: 92.97%] [G loss: 2.060127]\n",
      "epoch:14 step:11221 [D loss: 0.562239, acc: 69.53%] [G loss: 2.065830]\n",
      "epoch:14 step:11222 [D loss: 0.377396, acc: 91.41%] [G loss: 2.415788]\n",
      "epoch:14 step:11223 [D loss: 0.577252, acc: 75.78%] [G loss: 2.078985]\n",
      "epoch:14 step:11224 [D loss: 0.357860, acc: 93.75%] [G loss: 2.195224]\n",
      "epoch:14 step:11225 [D loss: 1.218026, acc: 14.84%] [G loss: 1.400306]\n",
      "epoch:14 step:11226 [D loss: 0.504379, acc: 70.31%] [G loss: 2.170820]\n",
      "epoch:14 step:11227 [D loss: 0.662982, acc: 55.47%] [G loss: 2.191747]\n",
      "epoch:14 step:11228 [D loss: 0.529120, acc: 81.25%] [G loss: 1.990923]\n",
      "epoch:14 step:11229 [D loss: 0.513357, acc: 75.78%] [G loss: 2.207098]\n",
      "epoch:14 step:11230 [D loss: 0.618822, acc: 60.16%] [G loss: 2.164218]\n",
      "epoch:14 step:11231 [D loss: 0.510781, acc: 85.16%] [G loss: 2.756901]\n",
      "epoch:14 step:11232 [D loss: 0.563352, acc: 78.12%] [G loss: 1.761598]\n",
      "epoch:14 step:11233 [D loss: 0.355955, acc: 91.41%] [G loss: 2.134290]\n",
      "epoch:14 step:11234 [D loss: 0.815867, acc: 50.78%] [G loss: 1.629957]\n",
      "epoch:14 step:11235 [D loss: 0.679619, acc: 60.16%] [G loss: 1.771539]\n",
      "epoch:14 step:11236 [D loss: 0.653969, acc: 61.72%] [G loss: 2.116302]\n",
      "epoch:14 step:11237 [D loss: 0.780288, acc: 48.44%] [G loss: 1.966892]\n",
      "epoch:14 step:11238 [D loss: 0.557181, acc: 78.12%] [G loss: 2.433126]\n",
      "epoch:14 step:11239 [D loss: 0.609272, acc: 67.97%] [G loss: 2.290829]\n",
      "epoch:14 step:11240 [D loss: 0.700188, acc: 55.47%] [G loss: 2.280548]\n",
      "epoch:14 step:11241 [D loss: 0.369452, acc: 82.81%] [G loss: 1.918408]\n",
      "epoch:14 step:11242 [D loss: 0.503088, acc: 81.25%] [G loss: 1.931728]\n",
      "epoch:14 step:11243 [D loss: 0.322922, acc: 94.53%] [G loss: 2.042794]\n",
      "epoch:14 step:11244 [D loss: 0.384464, acc: 94.53%] [G loss: 2.052077]\n",
      "epoch:14 step:11245 [D loss: 0.587321, acc: 61.72%] [G loss: 2.257754]\n",
      "epoch:14 step:11246 [D loss: 0.588153, acc: 71.88%] [G loss: 2.079065]\n",
      "epoch:14 step:11247 [D loss: 0.608115, acc: 69.53%] [G loss: 1.952258]\n",
      "epoch:14 step:11248 [D loss: 0.680760, acc: 56.25%] [G loss: 2.544374]\n",
      "epoch:14 step:11249 [D loss: 0.934878, acc: 46.88%] [G loss: 2.319993]\n",
      "epoch:14 step:11250 [D loss: 0.926865, acc: 35.94%] [G loss: 2.410933]\n",
      "epoch:14 step:11251 [D loss: 0.813413, acc: 51.56%] [G loss: 1.453949]\n",
      "epoch:14 step:11252 [D loss: 0.223959, acc: 99.22%] [G loss: 4.163443]\n",
      "epoch:14 step:11253 [D loss: 0.407752, acc: 84.38%] [G loss: 2.808927]\n",
      "epoch:14 step:11254 [D loss: 1.063690, acc: 47.66%] [G loss: 1.887787]\n",
      "epoch:14 step:11255 [D loss: 0.702864, acc: 53.91%] [G loss: 2.281811]\n",
      "epoch:14 step:11256 [D loss: 0.906835, acc: 33.59%] [G loss: 1.946649]\n",
      "epoch:14 step:11257 [D loss: 0.552782, acc: 71.09%] [G loss: 2.370858]\n",
      "epoch:14 step:11258 [D loss: 0.566054, acc: 70.31%] [G loss: 3.460763]\n",
      "epoch:14 step:11259 [D loss: 0.452538, acc: 89.84%] [G loss: 1.880004]\n",
      "epoch:14 step:11260 [D loss: 0.367554, acc: 88.28%] [G loss: 2.477692]\n",
      "epoch:14 step:11261 [D loss: 0.599216, acc: 67.19%] [G loss: 2.196668]\n",
      "epoch:14 step:11262 [D loss: 0.686314, acc: 54.69%] [G loss: 3.597007]\n",
      "epoch:14 step:11263 [D loss: 0.559770, acc: 74.22%] [G loss: 2.220093]\n",
      "epoch:14 step:11264 [D loss: 0.619404, acc: 57.81%] [G loss: 4.074255]\n",
      "epoch:14 step:11265 [D loss: 0.780479, acc: 48.44%] [G loss: 2.030495]\n",
      "epoch:14 step:11266 [D loss: 0.585104, acc: 70.31%] [G loss: 2.259155]\n",
      "epoch:14 step:11267 [D loss: 0.468557, acc: 88.28%] [G loss: 2.953109]\n",
      "epoch:14 step:11268 [D loss: 0.527618, acc: 78.91%] [G loss: 2.169004]\n",
      "epoch:14 step:11269 [D loss: 0.464898, acc: 69.53%] [G loss: 2.391768]\n",
      "epoch:14 step:11270 [D loss: 0.684340, acc: 53.91%] [G loss: 2.005522]\n",
      "epoch:14 step:11271 [D loss: 0.982473, acc: 21.09%] [G loss: 1.796354]\n",
      "epoch:14 step:11272 [D loss: 0.724066, acc: 42.19%] [G loss: 2.192345]\n",
      "epoch:14 step:11273 [D loss: 0.883718, acc: 32.81%] [G loss: 1.919115]\n",
      "epoch:14 step:11274 [D loss: 0.460181, acc: 71.88%] [G loss: 2.127313]\n",
      "epoch:14 step:11275 [D loss: 0.339620, acc: 94.53%] [G loss: 2.516685]\n",
      "epoch:14 step:11276 [D loss: 0.684995, acc: 54.69%] [G loss: 2.276530]\n",
      "epoch:14 step:11277 [D loss: 0.732089, acc: 50.00%] [G loss: 2.013878]\n",
      "epoch:14 step:11278 [D loss: 0.377517, acc: 95.31%] [G loss: 1.911987]\n",
      "epoch:14 step:11279 [D loss: 0.585745, acc: 66.41%] [G loss: 2.084240]\n",
      "epoch:14 step:11280 [D loss: 0.358538, acc: 94.53%] [G loss: 1.947044]\n",
      "epoch:14 step:11281 [D loss: 0.573794, acc: 76.56%] [G loss: 2.443542]\n",
      "epoch:14 step:11282 [D loss: 0.571093, acc: 67.97%] [G loss: 2.663686]\n",
      "epoch:14 step:11283 [D loss: 0.568237, acc: 77.34%] [G loss: 1.926924]\n",
      "epoch:14 step:11284 [D loss: 0.511339, acc: 82.03%] [G loss: 1.906089]\n",
      "epoch:14 step:11285 [D loss: 0.533697, acc: 73.44%] [G loss: 1.936150]\n",
      "epoch:14 step:11286 [D loss: 0.252192, acc: 98.44%] [G loss: 2.891524]\n",
      "epoch:14 step:11287 [D loss: 0.764455, acc: 44.53%] [G loss: 2.981631]\n",
      "epoch:14 step:11288 [D loss: 0.477722, acc: 84.38%] [G loss: 2.666905]\n",
      "epoch:14 step:11289 [D loss: 0.819839, acc: 44.53%] [G loss: 2.431513]\n",
      "epoch:14 step:11290 [D loss: 0.229523, acc: 94.53%] [G loss: 2.766541]\n",
      "epoch:14 step:11291 [D loss: 0.761947, acc: 54.69%] [G loss: 2.215151]\n",
      "epoch:14 step:11292 [D loss: 0.601237, acc: 56.25%] [G loss: 1.935195]\n",
      "epoch:14 step:11293 [D loss: 0.526453, acc: 72.66%] [G loss: 1.892291]\n",
      "epoch:14 step:11294 [D loss: 0.508972, acc: 78.91%] [G loss: 1.598853]\n",
      "epoch:14 step:11295 [D loss: 0.542743, acc: 73.44%] [G loss: 2.418602]\n",
      "epoch:14 step:11296 [D loss: 0.584579, acc: 57.03%] [G loss: 2.537115]\n",
      "epoch:14 step:11297 [D loss: 0.540477, acc: 71.88%] [G loss: 1.810433]\n",
      "epoch:14 step:11298 [D loss: 0.226221, acc: 97.66%] [G loss: 2.506052]\n",
      "epoch:14 step:11299 [D loss: 0.764445, acc: 40.62%] [G loss: 1.970448]\n",
      "epoch:14 step:11300 [D loss: 0.842126, acc: 42.19%] [G loss: 1.611235]\n",
      "epoch:14 step:11301 [D loss: 0.969522, acc: 44.53%] [G loss: 2.005807]\n",
      "epoch:14 step:11302 [D loss: 0.529605, acc: 65.62%] [G loss: 2.768507]\n",
      "epoch:14 step:11303 [D loss: 0.370735, acc: 93.75%] [G loss: 2.712609]\n",
      "epoch:14 step:11304 [D loss: 0.718042, acc: 52.34%] [G loss: 1.944765]\n",
      "epoch:14 step:11305 [D loss: 0.561962, acc: 70.31%] [G loss: 2.287972]\n",
      "epoch:14 step:11306 [D loss: 0.458678, acc: 74.22%] [G loss: 2.211235]\n",
      "epoch:14 step:11307 [D loss: 0.656742, acc: 60.16%] [G loss: 2.040657]\n",
      "epoch:14 step:11308 [D loss: 0.519179, acc: 75.78%] [G loss: 2.407737]\n",
      "epoch:14 step:11309 [D loss: 0.721359, acc: 50.78%] [G loss: 2.092023]\n",
      "epoch:14 step:11310 [D loss: 0.247001, acc: 97.66%] [G loss: 2.574065]\n",
      "epoch:14 step:11311 [D loss: 0.971998, acc: 30.47%] [G loss: 1.426925]\n",
      "epoch:14 step:11312 [D loss: 0.347775, acc: 95.31%] [G loss: 2.166156]\n",
      "epoch:14 step:11313 [D loss: 0.646381, acc: 63.28%] [G loss: 2.506976]\n",
      "epoch:14 step:11314 [D loss: 0.500240, acc: 71.09%] [G loss: 2.482029]\n",
      "epoch:14 step:11315 [D loss: 0.632846, acc: 58.59%] [G loss: 2.117949]\n",
      "epoch:14 step:11316 [D loss: 0.726123, acc: 51.56%] [G loss: 2.471763]\n",
      "epoch:14 step:11317 [D loss: 0.287154, acc: 94.53%] [G loss: 2.236914]\n",
      "epoch:14 step:11318 [D loss: 0.423498, acc: 88.28%] [G loss: 2.427078]\n",
      "epoch:14 step:11319 [D loss: 0.283253, acc: 99.22%] [G loss: 1.993806]\n",
      "epoch:14 step:11320 [D loss: 0.598347, acc: 71.09%] [G loss: 2.911791]\n",
      "epoch:14 step:11321 [D loss: 0.510422, acc: 76.56%] [G loss: 2.279244]\n",
      "epoch:14 step:11322 [D loss: 0.921336, acc: 27.34%] [G loss: 1.952659]\n",
      "epoch:14 step:11323 [D loss: 0.342589, acc: 95.31%] [G loss: 2.165223]\n",
      "epoch:14 step:11324 [D loss: 0.433694, acc: 83.59%] [G loss: 2.244541]\n",
      "epoch:14 step:11325 [D loss: 1.140201, acc: 6.25%] [G loss: 1.835261]\n",
      "epoch:14 step:11326 [D loss: 0.404586, acc: 87.50%] [G loss: 2.178546]\n",
      "epoch:14 step:11327 [D loss: 0.578928, acc: 71.88%] [G loss: 2.492210]\n",
      "epoch:14 step:11328 [D loss: 0.492792, acc: 76.56%] [G loss: 2.199408]\n",
      "epoch:14 step:11329 [D loss: 0.697102, acc: 55.47%] [G loss: 2.613420]\n",
      "epoch:14 step:11330 [D loss: 0.342261, acc: 93.75%] [G loss: 1.935727]\n",
      "epoch:14 step:11331 [D loss: 0.613175, acc: 57.03%] [G loss: 2.269617]\n",
      "epoch:14 step:11332 [D loss: 0.656947, acc: 57.81%] [G loss: 2.066721]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:14 step:11333 [D loss: 1.069356, acc: 49.22%] [G loss: 2.751963]\n",
      "epoch:14 step:11334 [D loss: 0.344808, acc: 95.31%] [G loss: 2.675181]\n",
      "epoch:14 step:11335 [D loss: 0.344265, acc: 82.81%] [G loss: 2.981994]\n",
      "epoch:14 step:11336 [D loss: 0.938036, acc: 34.38%] [G loss: 2.122265]\n",
      "epoch:14 step:11337 [D loss: 0.670793, acc: 57.81%] [G loss: 3.035678]\n",
      "epoch:14 step:11338 [D loss: 0.820506, acc: 43.75%] [G loss: 2.160616]\n",
      "epoch:14 step:11339 [D loss: 0.667136, acc: 53.91%] [G loss: 2.110949]\n",
      "epoch:14 step:11340 [D loss: 0.596755, acc: 67.19%] [G loss: 1.999017]\n",
      "epoch:14 step:11341 [D loss: 0.487856, acc: 78.12%] [G loss: 1.908139]\n",
      "epoch:14 step:11342 [D loss: 0.374551, acc: 94.53%] [G loss: 2.461281]\n",
      "epoch:14 step:11343 [D loss: 0.545573, acc: 78.91%] [G loss: 2.408568]\n",
      "epoch:14 step:11344 [D loss: 0.542722, acc: 68.75%] [G loss: 2.419737]\n",
      "epoch:14 step:11345 [D loss: 0.871917, acc: 46.09%] [G loss: 1.714174]\n",
      "epoch:14 step:11346 [D loss: 0.438449, acc: 83.59%] [G loss: 1.961816]\n",
      "epoch:14 step:11347 [D loss: 0.382763, acc: 84.38%] [G loss: 2.644600]\n",
      "epoch:14 step:11348 [D loss: 0.530826, acc: 78.91%] [G loss: 2.684146]\n",
      "epoch:14 step:11349 [D loss: 0.717135, acc: 53.12%] [G loss: 1.933916]\n",
      "epoch:14 step:11350 [D loss: 0.742240, acc: 52.34%] [G loss: 2.353494]\n",
      "epoch:14 step:11351 [D loss: 0.411383, acc: 78.91%] [G loss: 2.181901]\n",
      "epoch:14 step:11352 [D loss: 0.825886, acc: 39.84%] [G loss: 2.053636]\n",
      "epoch:14 step:11353 [D loss: 0.399138, acc: 89.06%] [G loss: 1.720029]\n",
      "epoch:14 step:11354 [D loss: 0.331411, acc: 96.09%] [G loss: 2.383490]\n",
      "epoch:14 step:11355 [D loss: 0.473734, acc: 75.78%] [G loss: 2.823445]\n",
      "epoch:14 step:11356 [D loss: 0.658399, acc: 57.03%] [G loss: 2.540552]\n",
      "epoch:14 step:11357 [D loss: 0.605716, acc: 70.31%] [G loss: 1.996591]\n",
      "epoch:14 step:11358 [D loss: 0.414617, acc: 85.94%] [G loss: 2.043380]\n",
      "epoch:14 step:11359 [D loss: 0.248680, acc: 99.22%] [G loss: 2.909723]\n",
      "epoch:14 step:11360 [D loss: 0.945440, acc: 42.19%] [G loss: 1.998695]\n",
      "epoch:14 step:11361 [D loss: 0.600476, acc: 63.28%] [G loss: 1.785773]\n",
      "epoch:14 step:11362 [D loss: 0.680068, acc: 53.91%] [G loss: 2.318383]\n",
      "epoch:14 step:11363 [D loss: 0.489622, acc: 86.72%] [G loss: 2.600928]\n",
      "epoch:14 step:11364 [D loss: 0.965117, acc: 46.09%] [G loss: 2.099807]\n",
      "epoch:14 step:11365 [D loss: 0.598303, acc: 71.09%] [G loss: 1.888391]\n",
      "epoch:14 step:11366 [D loss: 0.339441, acc: 93.75%] [G loss: 2.768064]\n",
      "epoch:14 step:11367 [D loss: 0.531984, acc: 82.03%] [G loss: 2.569509]\n",
      "epoch:14 step:11368 [D loss: 0.627348, acc: 60.94%] [G loss: 2.040430]\n",
      "epoch:14 step:11369 [D loss: 0.593499, acc: 67.97%] [G loss: 2.633552]\n",
      "epoch:14 step:11370 [D loss: 0.812521, acc: 42.97%] [G loss: 2.171251]\n",
      "epoch:14 step:11371 [D loss: 0.401325, acc: 93.75%] [G loss: 2.623651]\n",
      "epoch:14 step:11372 [D loss: 0.532806, acc: 73.44%] [G loss: 2.423573]\n",
      "epoch:14 step:11373 [D loss: 0.458179, acc: 88.28%] [G loss: 2.060052]\n",
      "epoch:14 step:11374 [D loss: 0.326381, acc: 90.62%] [G loss: 2.311078]\n",
      "epoch:14 step:11375 [D loss: 0.532581, acc: 78.12%] [G loss: 2.496789]\n",
      "epoch:14 step:11376 [D loss: 0.402824, acc: 92.97%] [G loss: 2.298611]\n",
      "epoch:14 step:11377 [D loss: 0.320367, acc: 96.09%] [G loss: 2.065069]\n",
      "epoch:14 step:11378 [D loss: 0.262263, acc: 98.44%] [G loss: 2.490730]\n",
      "epoch:14 step:11379 [D loss: 0.796174, acc: 50.00%] [G loss: 2.361980]\n",
      "epoch:14 step:11380 [D loss: 0.592018, acc: 64.84%] [G loss: 1.973007]\n",
      "epoch:14 step:11381 [D loss: 0.461181, acc: 81.25%] [G loss: 2.174677]\n",
      "epoch:14 step:11382 [D loss: 0.885905, acc: 48.44%] [G loss: 2.534698]\n",
      "epoch:14 step:11383 [D loss: 0.208641, acc: 99.22%] [G loss: 2.867054]\n",
      "epoch:14 step:11384 [D loss: 0.639884, acc: 54.69%] [G loss: 3.255229]\n",
      "epoch:14 step:11385 [D loss: 0.508904, acc: 68.75%] [G loss: 2.454657]\n",
      "epoch:14 step:11386 [D loss: 0.262460, acc: 96.88%] [G loss: 3.242887]\n",
      "epoch:14 step:11387 [D loss: 0.884487, acc: 45.31%] [G loss: 2.037156]\n",
      "epoch:14 step:11388 [D loss: 0.566268, acc: 71.09%] [G loss: 2.240581]\n",
      "epoch:14 step:11389 [D loss: 0.367980, acc: 91.41%] [G loss: 2.525024]\n",
      "epoch:14 step:11390 [D loss: 0.593940, acc: 67.97%] [G loss: 2.317953]\n",
      "epoch:14 step:11391 [D loss: 0.534814, acc: 78.12%] [G loss: 2.014543]\n",
      "epoch:14 step:11392 [D loss: 0.257552, acc: 99.22%] [G loss: 3.157583]\n",
      "epoch:14 step:11393 [D loss: 1.009148, acc: 44.53%] [G loss: 2.931346]\n",
      "epoch:14 step:11394 [D loss: 0.322076, acc: 96.09%] [G loss: 2.496581]\n",
      "epoch:14 step:11395 [D loss: 0.694566, acc: 57.03%] [G loss: 2.712913]\n",
      "epoch:14 step:11396 [D loss: 0.826617, acc: 39.84%] [G loss: 2.158760]\n",
      "epoch:14 step:11397 [D loss: 0.600148, acc: 67.19%] [G loss: 2.399204]\n",
      "epoch:14 step:11398 [D loss: 0.367783, acc: 96.88%] [G loss: 2.438684]\n",
      "epoch:14 step:11399 [D loss: 0.223347, acc: 100.00%] [G loss: 2.424617]\n",
      "epoch:14 step:11400 [D loss: 0.327493, acc: 93.75%] [G loss: 2.534183]\n",
      "##############\n",
      "[0.86555113 0.87009099 0.81126219 0.81091563 0.79557702 0.84246285\n",
      " 0.90192333 0.8135035  0.82608833 0.83974987]\n",
      "##########\n",
      "epoch:14 step:11401 [D loss: 0.524529, acc: 67.19%] [G loss: 3.532027]\n",
      "epoch:14 step:11402 [D loss: 0.651883, acc: 61.72%] [G loss: 1.747845]\n",
      "epoch:14 step:11403 [D loss: 0.283365, acc: 97.66%] [G loss: 1.956905]\n",
      "epoch:14 step:11404 [D loss: 0.517641, acc: 60.16%] [G loss: 3.106167]\n",
      "epoch:14 step:11405 [D loss: 0.574640, acc: 65.62%] [G loss: 1.954913]\n",
      "epoch:14 step:11406 [D loss: 0.416112, acc: 83.59%] [G loss: 2.418480]\n",
      "epoch:14 step:11407 [D loss: 0.668458, acc: 55.47%] [G loss: 1.479933]\n",
      "epoch:14 step:11408 [D loss: 0.597017, acc: 71.09%] [G loss: 2.064001]\n",
      "epoch:14 step:11409 [D loss: 0.689535, acc: 53.12%] [G loss: 2.362220]\n",
      "epoch:14 step:11410 [D loss: 0.330854, acc: 94.53%] [G loss: 1.978059]\n",
      "epoch:14 step:11411 [D loss: 0.660016, acc: 53.12%] [G loss: 2.188525]\n",
      "epoch:14 step:11412 [D loss: 0.480720, acc: 61.72%] [G loss: 2.114903]\n",
      "epoch:14 step:11413 [D loss: 0.476830, acc: 62.50%] [G loss: 2.715057]\n",
      "epoch:14 step:11414 [D loss: 0.899949, acc: 27.34%] [G loss: 2.837989]\n",
      "epoch:14 step:11415 [D loss: 1.239542, acc: 25.00%] [G loss: 1.261958]\n",
      "epoch:14 step:11416 [D loss: 1.210626, acc: 15.62%] [G loss: 1.225373]\n",
      "epoch:14 step:11417 [D loss: 0.587311, acc: 59.38%] [G loss: 2.006416]\n",
      "epoch:14 step:11418 [D loss: 0.831858, acc: 33.59%] [G loss: 1.515864]\n",
      "epoch:14 step:11419 [D loss: 0.351849, acc: 96.09%] [G loss: 2.803900]\n",
      "epoch:14 step:11420 [D loss: 0.965140, acc: 35.94%] [G loss: 1.667434]\n",
      "epoch:14 step:11421 [D loss: 0.685195, acc: 60.94%] [G loss: 1.681523]\n",
      "epoch:14 step:11422 [D loss: 0.635205, acc: 57.03%] [G loss: 1.787838]\n",
      "epoch:14 step:11423 [D loss: 0.749237, acc: 47.66%] [G loss: 2.331792]\n",
      "epoch:14 step:11424 [D loss: 0.484559, acc: 67.97%] [G loss: 1.750902]\n",
      "epoch:14 step:11425 [D loss: 0.905705, acc: 41.41%] [G loss: 1.900875]\n",
      "epoch:14 step:11426 [D loss: 0.835315, acc: 46.09%] [G loss: 2.268406]\n",
      "epoch:14 step:11427 [D loss: 0.250882, acc: 95.31%] [G loss: 2.348938]\n",
      "epoch:14 step:11428 [D loss: 0.899863, acc: 31.25%] [G loss: 2.065409]\n",
      "epoch:14 step:11429 [D loss: 0.295142, acc: 97.66%] [G loss: 2.936716]\n",
      "epoch:14 step:11430 [D loss: 0.826564, acc: 38.28%] [G loss: 1.888047]\n",
      "epoch:14 step:11431 [D loss: 0.797654, acc: 48.44%] [G loss: 2.277061]\n",
      "epoch:14 step:11432 [D loss: 0.322143, acc: 96.88%] [G loss: 2.216985]\n",
      "epoch:14 step:11433 [D loss: 0.860946, acc: 42.97%] [G loss: 1.800358]\n",
      "epoch:14 step:11434 [D loss: 0.630349, acc: 65.62%] [G loss: 1.961815]\n",
      "epoch:14 step:11435 [D loss: 0.400384, acc: 87.50%] [G loss: 2.321694]\n",
      "epoch:14 step:11436 [D loss: 0.698329, acc: 58.59%] [G loss: 2.198639]\n",
      "epoch:14 step:11437 [D loss: 0.456794, acc: 84.38%] [G loss: 2.655731]\n",
      "epoch:14 step:11438 [D loss: 0.669621, acc: 60.16%] [G loss: 2.209192]\n",
      "epoch:14 step:11439 [D loss: 0.689266, acc: 57.81%] [G loss: 1.729323]\n",
      "epoch:14 step:11440 [D loss: 1.061345, acc: 25.00%] [G loss: 2.093423]\n",
      "epoch:14 step:11441 [D loss: 0.505197, acc: 80.47%] [G loss: 1.518272]\n",
      "epoch:14 step:11442 [D loss: 0.751799, acc: 44.53%] [G loss: 2.191386]\n",
      "epoch:14 step:11443 [D loss: 0.457770, acc: 81.25%] [G loss: 2.352295]\n",
      "epoch:14 step:11444 [D loss: 0.475216, acc: 80.47%] [G loss: 2.260869]\n",
      "epoch:14 step:11445 [D loss: 0.457774, acc: 76.56%] [G loss: 2.394712]\n",
      "epoch:14 step:11446 [D loss: 0.778605, acc: 47.66%] [G loss: 2.073012]\n",
      "epoch:14 step:11447 [D loss: 0.424289, acc: 69.53%] [G loss: 2.583391]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:14 step:11448 [D loss: 0.789527, acc: 44.53%] [G loss: 1.636926]\n",
      "epoch:14 step:11449 [D loss: 1.096952, acc: 43.75%] [G loss: 2.004688]\n",
      "epoch:14 step:11450 [D loss: 0.605402, acc: 68.75%] [G loss: 1.830758]\n",
      "epoch:14 step:11451 [D loss: 0.839918, acc: 36.72%] [G loss: 1.865183]\n",
      "epoch:14 step:11452 [D loss: 0.675567, acc: 52.34%] [G loss: 2.036153]\n",
      "epoch:14 step:11453 [D loss: 1.289821, acc: 19.53%] [G loss: 1.612120]\n",
      "epoch:14 step:11454 [D loss: 0.495443, acc: 82.81%] [G loss: 2.482183]\n",
      "epoch:14 step:11455 [D loss: 0.619065, acc: 63.28%] [G loss: 2.754465]\n",
      "epoch:14 step:11456 [D loss: 0.858081, acc: 39.06%] [G loss: 2.277169]\n",
      "epoch:14 step:11457 [D loss: 0.841422, acc: 39.84%] [G loss: 2.153000]\n",
      "epoch:14 step:11458 [D loss: 0.454686, acc: 85.94%] [G loss: 2.723421]\n",
      "epoch:14 step:11459 [D loss: 0.535983, acc: 73.44%] [G loss: 2.232143]\n",
      "epoch:14 step:11460 [D loss: 0.693945, acc: 58.59%] [G loss: 2.124893]\n",
      "epoch:14 step:11461 [D loss: 0.484835, acc: 81.25%] [G loss: 2.721852]\n",
      "epoch:14 step:11462 [D loss: 0.750626, acc: 51.56%] [G loss: 1.856001]\n",
      "epoch:14 step:11463 [D loss: 0.357606, acc: 89.84%] [G loss: 2.254666]\n",
      "epoch:14 step:11464 [D loss: 0.608555, acc: 64.84%] [G loss: 1.959646]\n",
      "epoch:14 step:11465 [D loss: 0.602770, acc: 69.53%] [G loss: 2.063569]\n",
      "epoch:14 step:11466 [D loss: 0.588907, acc: 66.41%] [G loss: 2.381384]\n",
      "epoch:14 step:11467 [D loss: 0.555739, acc: 66.41%] [G loss: 1.582290]\n",
      "epoch:14 step:11468 [D loss: 0.515900, acc: 71.88%] [G loss: 1.924066]\n",
      "epoch:14 step:11469 [D loss: 0.648089, acc: 62.50%] [G loss: 2.374117]\n",
      "epoch:14 step:11470 [D loss: 0.620676, acc: 64.84%] [G loss: 3.197611]\n",
      "epoch:14 step:11471 [D loss: 0.446594, acc: 78.91%] [G loss: 2.108311]\n",
      "epoch:14 step:11472 [D loss: 0.429707, acc: 84.38%] [G loss: 2.657017]\n",
      "epoch:14 step:11473 [D loss: 0.627416, acc: 68.75%] [G loss: 1.460448]\n",
      "epoch:14 step:11474 [D loss: 0.848609, acc: 39.06%] [G loss: 2.180466]\n",
      "epoch:14 step:11475 [D loss: 0.335887, acc: 94.53%] [G loss: 2.840409]\n",
      "epoch:14 step:11476 [D loss: 0.487385, acc: 85.94%] [G loss: 2.092453]\n",
      "epoch:14 step:11477 [D loss: 0.722224, acc: 53.91%] [G loss: 2.012960]\n",
      "epoch:14 step:11478 [D loss: 0.742846, acc: 53.12%] [G loss: 2.091200]\n",
      "epoch:14 step:11479 [D loss: 0.993635, acc: 34.38%] [G loss: 1.997675]\n",
      "epoch:14 step:11480 [D loss: 0.468990, acc: 82.03%] [G loss: 2.752249]\n",
      "epoch:14 step:11481 [D loss: 0.434792, acc: 91.41%] [G loss: 2.489639]\n",
      "epoch:14 step:11482 [D loss: 1.042985, acc: 17.19%] [G loss: 1.565395]\n",
      "epoch:14 step:11483 [D loss: 0.866401, acc: 35.16%] [G loss: 2.089140]\n",
      "epoch:14 step:11484 [D loss: 0.631694, acc: 61.72%] [G loss: 1.890855]\n",
      "epoch:14 step:11485 [D loss: 0.649954, acc: 59.38%] [G loss: 1.870744]\n",
      "epoch:14 step:11486 [D loss: 0.807757, acc: 50.78%] [G loss: 2.663729]\n",
      "epoch:14 step:11487 [D loss: 0.846772, acc: 30.47%] [G loss: 1.800098]\n",
      "epoch:14 step:11488 [D loss: 0.469405, acc: 85.16%] [G loss: 2.417629]\n",
      "epoch:14 step:11489 [D loss: 0.490892, acc: 85.16%] [G loss: 2.504745]\n",
      "epoch:14 step:11490 [D loss: 0.492616, acc: 86.72%] [G loss: 2.303043]\n",
      "epoch:14 step:11491 [D loss: 0.689707, acc: 51.56%] [G loss: 2.303420]\n",
      "epoch:14 step:11492 [D loss: 0.540347, acc: 79.69%] [G loss: 1.989894]\n",
      "epoch:14 step:11493 [D loss: 0.553625, acc: 78.12%] [G loss: 2.750137]\n",
      "epoch:14 step:11494 [D loss: 0.533192, acc: 79.69%] [G loss: 2.262586]\n",
      "epoch:14 step:11495 [D loss: 0.498587, acc: 85.94%] [G loss: 2.737403]\n",
      "epoch:14 step:11496 [D loss: 0.754962, acc: 46.88%] [G loss: 1.682642]\n",
      "epoch:14 step:11497 [D loss: 0.599750, acc: 67.19%] [G loss: 2.635103]\n",
      "epoch:14 step:11498 [D loss: 0.432184, acc: 88.28%] [G loss: 2.422819]\n",
      "epoch:14 step:11499 [D loss: 0.870006, acc: 31.25%] [G loss: 2.325487]\n",
      "epoch:14 step:11500 [D loss: 0.644771, acc: 63.28%] [G loss: 1.886814]\n",
      "epoch:14 step:11501 [D loss: 0.622248, acc: 64.06%] [G loss: 2.334472]\n",
      "epoch:14 step:11502 [D loss: 0.588842, acc: 68.75%] [G loss: 1.851256]\n",
      "epoch:14 step:11503 [D loss: 0.668964, acc: 59.38%] [G loss: 2.414317]\n",
      "epoch:14 step:11504 [D loss: 0.856664, acc: 41.41%] [G loss: 2.133464]\n",
      "epoch:14 step:11505 [D loss: 0.628725, acc: 68.75%] [G loss: 2.341943]\n",
      "epoch:14 step:11506 [D loss: 0.432648, acc: 92.19%] [G loss: 2.500049]\n",
      "epoch:14 step:11507 [D loss: 0.468738, acc: 82.81%] [G loss: 2.450610]\n",
      "epoch:14 step:11508 [D loss: 0.360801, acc: 92.97%] [G loss: 1.994030]\n",
      "epoch:14 step:11509 [D loss: 0.784866, acc: 42.97%] [G loss: 2.097921]\n",
      "epoch:14 step:11510 [D loss: 0.363149, acc: 94.53%] [G loss: 2.065513]\n",
      "epoch:14 step:11511 [D loss: 0.551954, acc: 75.78%] [G loss: 2.510523]\n",
      "epoch:14 step:11512 [D loss: 0.434965, acc: 91.41%] [G loss: 1.885557]\n",
      "epoch:14 step:11513 [D loss: 0.770350, acc: 42.97%] [G loss: 2.023283]\n",
      "epoch:14 step:11514 [D loss: 0.345868, acc: 90.62%] [G loss: 1.860262]\n",
      "epoch:14 step:11515 [D loss: 0.729962, acc: 53.12%] [G loss: 2.429129]\n",
      "epoch:14 step:11516 [D loss: 0.741461, acc: 53.12%] [G loss: 2.183836]\n",
      "epoch:14 step:11517 [D loss: 0.370699, acc: 90.62%] [G loss: 2.996456]\n",
      "epoch:14 step:11518 [D loss: 0.956475, acc: 51.56%] [G loss: 2.292057]\n",
      "epoch:14 step:11519 [D loss: 0.763122, acc: 38.28%] [G loss: 2.390087]\n",
      "epoch:14 step:11520 [D loss: 0.657732, acc: 61.72%] [G loss: 2.252910]\n",
      "epoch:14 step:11521 [D loss: 0.488706, acc: 83.59%] [G loss: 2.150313]\n",
      "epoch:14 step:11522 [D loss: 0.658676, acc: 62.50%] [G loss: 2.246087]\n",
      "epoch:14 step:11523 [D loss: 0.698724, acc: 58.59%] [G loss: 2.656206]\n",
      "epoch:14 step:11524 [D loss: 0.540986, acc: 81.25%] [G loss: 2.552789]\n",
      "epoch:14 step:11525 [D loss: 0.702731, acc: 56.25%] [G loss: 2.204401]\n",
      "epoch:14 step:11526 [D loss: 0.550685, acc: 77.34%] [G loss: 2.286632]\n",
      "epoch:14 step:11527 [D loss: 0.615392, acc: 64.84%] [G loss: 2.137727]\n",
      "epoch:14 step:11528 [D loss: 0.430602, acc: 88.28%] [G loss: 2.302006]\n",
      "epoch:14 step:11529 [D loss: 0.520817, acc: 74.22%] [G loss: 2.235630]\n",
      "epoch:14 step:11530 [D loss: 0.403424, acc: 83.59%] [G loss: 1.654522]\n",
      "epoch:14 step:11531 [D loss: 0.237321, acc: 98.44%] [G loss: 2.272371]\n",
      "epoch:14 step:11532 [D loss: 0.439241, acc: 84.38%] [G loss: 2.318704]\n",
      "epoch:14 step:11533 [D loss: 0.653888, acc: 62.50%] [G loss: 2.343326]\n",
      "epoch:14 step:11534 [D loss: 0.407781, acc: 80.47%] [G loss: 2.710387]\n",
      "epoch:14 step:11535 [D loss: 0.733209, acc: 46.88%] [G loss: 1.882189]\n",
      "epoch:14 step:11536 [D loss: 0.595461, acc: 68.75%] [G loss: 2.450031]\n",
      "epoch:14 step:11537 [D loss: 0.776366, acc: 46.09%] [G loss: 1.792970]\n",
      "epoch:14 step:11538 [D loss: 0.927095, acc: 39.84%] [G loss: 2.099346]\n",
      "epoch:14 step:11539 [D loss: 0.429935, acc: 91.41%] [G loss: 2.962011]\n",
      "epoch:14 step:11540 [D loss: 0.497747, acc: 83.59%] [G loss: 2.318420]\n",
      "epoch:14 step:11541 [D loss: 0.584551, acc: 75.00%] [G loss: 1.930441]\n",
      "epoch:14 step:11542 [D loss: 0.453807, acc: 82.81%] [G loss: 2.239394]\n",
      "epoch:14 step:11543 [D loss: 0.546040, acc: 67.97%] [G loss: 1.937750]\n",
      "epoch:14 step:11544 [D loss: 0.519018, acc: 61.72%] [G loss: 2.308638]\n",
      "epoch:14 step:11545 [D loss: 1.009175, acc: 21.09%] [G loss: 1.922705]\n",
      "epoch:14 step:11546 [D loss: 0.769437, acc: 47.66%] [G loss: 2.236129]\n",
      "epoch:14 step:11547 [D loss: 0.561366, acc: 70.31%] [G loss: 2.160607]\n",
      "epoch:14 step:11548 [D loss: 0.605857, acc: 64.06%] [G loss: 2.425043]\n",
      "epoch:14 step:11549 [D loss: 0.431340, acc: 89.84%] [G loss: 3.257221]\n",
      "epoch:14 step:11550 [D loss: 0.461338, acc: 89.06%] [G loss: 2.486356]\n",
      "epoch:14 step:11551 [D loss: 0.542894, acc: 78.12%] [G loss: 2.041065]\n",
      "epoch:14 step:11552 [D loss: 0.813163, acc: 33.59%] [G loss: 2.777703]\n",
      "epoch:14 step:11553 [D loss: 0.741056, acc: 49.22%] [G loss: 2.753000]\n",
      "epoch:14 step:11554 [D loss: 0.339481, acc: 96.88%] [G loss: 2.826018]\n",
      "epoch:14 step:11555 [D loss: 0.504011, acc: 82.81%] [G loss: 2.941454]\n",
      "epoch:14 step:11556 [D loss: 0.685838, acc: 57.81%] [G loss: 1.763752]\n",
      "epoch:14 step:11557 [D loss: 0.583897, acc: 71.88%] [G loss: 1.787341]\n",
      "epoch:14 step:11558 [D loss: 0.684800, acc: 57.81%] [G loss: 3.061804]\n",
      "epoch:14 step:11559 [D loss: 0.440979, acc: 85.16%] [G loss: 2.272228]\n",
      "epoch:14 step:11560 [D loss: 0.529720, acc: 75.78%] [G loss: 2.097628]\n",
      "epoch:14 step:11561 [D loss: 0.587531, acc: 63.28%] [G loss: 2.120283]\n",
      "epoch:14 step:11562 [D loss: 0.536942, acc: 76.56%] [G loss: 2.679966]\n",
      "epoch:14 step:11563 [D loss: 0.470393, acc: 82.81%] [G loss: 2.471929]\n",
      "epoch:14 step:11564 [D loss: 0.299289, acc: 96.09%] [G loss: 2.571318]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:14 step:11565 [D loss: 0.409824, acc: 87.50%] [G loss: 2.268723]\n",
      "epoch:14 step:11566 [D loss: 1.181096, acc: 15.62%] [G loss: 1.392937]\n",
      "epoch:14 step:11567 [D loss: 0.607533, acc: 67.19%] [G loss: 2.746581]\n",
      "epoch:14 step:11568 [D loss: 0.479909, acc: 82.81%] [G loss: 1.922578]\n",
      "epoch:14 step:11569 [D loss: 0.456610, acc: 67.19%] [G loss: 2.107323]\n",
      "epoch:14 step:11570 [D loss: 1.070251, acc: 47.66%] [G loss: 2.105805]\n",
      "epoch:14 step:11571 [D loss: 0.628255, acc: 64.06%] [G loss: 2.717396]\n",
      "epoch:14 step:11572 [D loss: 0.510471, acc: 80.47%] [G loss: 2.371715]\n",
      "epoch:14 step:11573 [D loss: 0.991132, acc: 27.34%] [G loss: 2.481042]\n",
      "epoch:14 step:11574 [D loss: 0.360086, acc: 95.31%] [G loss: 2.503821]\n",
      "epoch:14 step:11575 [D loss: 0.748550, acc: 48.44%] [G loss: 1.555685]\n",
      "epoch:14 step:11576 [D loss: 0.415970, acc: 92.19%] [G loss: 1.859733]\n",
      "epoch:14 step:11577 [D loss: 0.299835, acc: 99.22%] [G loss: 2.952157]\n",
      "epoch:14 step:11578 [D loss: 0.351368, acc: 95.31%] [G loss: 2.807598]\n",
      "epoch:14 step:11579 [D loss: 0.463078, acc: 67.97%] [G loss: 3.609835]\n",
      "epoch:14 step:11580 [D loss: 0.646412, acc: 59.38%] [G loss: 2.118197]\n",
      "epoch:14 step:11581 [D loss: 0.550551, acc: 74.22%] [G loss: 2.273561]\n",
      "epoch:14 step:11582 [D loss: 0.387843, acc: 92.19%] [G loss: 2.089025]\n",
      "epoch:14 step:11583 [D loss: 0.556186, acc: 75.00%] [G loss: 1.923295]\n",
      "epoch:14 step:11584 [D loss: 0.396638, acc: 82.03%] [G loss: 2.498207]\n",
      "epoch:14 step:11585 [D loss: 0.445599, acc: 73.44%] [G loss: 2.758669]\n",
      "epoch:14 step:11586 [D loss: 0.572544, acc: 75.00%] [G loss: 2.283977]\n",
      "epoch:14 step:11587 [D loss: 0.266176, acc: 98.44%] [G loss: 2.313088]\n",
      "epoch:14 step:11588 [D loss: 0.715594, acc: 57.03%] [G loss: 2.221286]\n",
      "epoch:14 step:11589 [D loss: 0.629003, acc: 67.19%] [G loss: 2.644490]\n",
      "epoch:14 step:11590 [D loss: 0.956037, acc: 36.72%] [G loss: 2.240297]\n",
      "epoch:14 step:11591 [D loss: 0.551323, acc: 75.78%] [G loss: 2.380097]\n",
      "epoch:14 step:11592 [D loss: 0.485550, acc: 82.03%] [G loss: 2.250298]\n",
      "epoch:14 step:11593 [D loss: 0.374349, acc: 90.62%] [G loss: 2.665052]\n",
      "epoch:14 step:11594 [D loss: 0.892093, acc: 38.28%] [G loss: 2.455330]\n",
      "epoch:14 step:11595 [D loss: 0.354832, acc: 80.47%] [G loss: 3.590054]\n",
      "epoch:14 step:11596 [D loss: 0.354475, acc: 95.31%] [G loss: 2.458171]\n",
      "epoch:14 step:11597 [D loss: 0.381959, acc: 91.41%] [G loss: 2.200552]\n",
      "epoch:14 step:11598 [D loss: 0.657348, acc: 53.12%] [G loss: 2.841568]\n",
      "epoch:14 step:11599 [D loss: 0.745144, acc: 51.56%] [G loss: 2.245826]\n",
      "epoch:14 step:11600 [D loss: 0.256830, acc: 96.09%] [G loss: 3.149173]\n",
      "##############\n",
      "[0.85099557 0.8558919  0.82405104 0.79745125 0.79990036 0.82355788\n",
      " 0.89699291 0.83772819 0.83416012 0.81824721]\n",
      "##########\n",
      "epoch:14 step:11601 [D loss: 0.437910, acc: 88.28%] [G loss: 2.620162]\n",
      "epoch:14 step:11602 [D loss: 0.366458, acc: 95.31%] [G loss: 3.547474]\n",
      "epoch:14 step:11603 [D loss: 0.764469, acc: 45.31%] [G loss: 2.283344]\n",
      "epoch:14 step:11604 [D loss: 0.454516, acc: 71.09%] [G loss: 2.623535]\n",
      "epoch:14 step:11605 [D loss: 0.780976, acc: 50.00%] [G loss: 2.213263]\n",
      "epoch:14 step:11606 [D loss: 0.697521, acc: 53.91%] [G loss: 2.178168]\n",
      "epoch:14 step:11607 [D loss: 0.351347, acc: 92.19%] [G loss: 2.504053]\n",
      "epoch:14 step:11608 [D loss: 0.296651, acc: 88.28%] [G loss: 2.298162]\n",
      "epoch:14 step:11609 [D loss: 0.687220, acc: 53.12%] [G loss: 2.009503]\n",
      "epoch:14 step:11610 [D loss: 0.597346, acc: 63.28%] [G loss: 2.013809]\n",
      "epoch:14 step:11611 [D loss: 0.202710, acc: 98.44%] [G loss: 2.380534]\n",
      "epoch:14 step:11612 [D loss: 0.986432, acc: 48.44%] [G loss: 1.978902]\n",
      "epoch:14 step:11613 [D loss: 0.403058, acc: 87.50%] [G loss: 2.866171]\n",
      "epoch:14 step:11614 [D loss: 0.560065, acc: 67.97%] [G loss: 2.421683]\n",
      "epoch:14 step:11615 [D loss: 0.355456, acc: 98.44%] [G loss: 2.872813]\n",
      "epoch:14 step:11616 [D loss: 0.928536, acc: 40.62%] [G loss: 2.158350]\n",
      "epoch:14 step:11617 [D loss: 0.699163, acc: 55.47%] [G loss: 2.827894]\n",
      "epoch:14 step:11618 [D loss: 1.020185, acc: 15.62%] [G loss: 2.000818]\n",
      "epoch:14 step:11619 [D loss: 0.337167, acc: 92.19%] [G loss: 2.640100]\n",
      "epoch:14 step:11620 [D loss: 1.219527, acc: 23.44%] [G loss: 2.374826]\n",
      "epoch:14 step:11621 [D loss: 0.571377, acc: 66.41%] [G loss: 3.603842]\n",
      "epoch:14 step:11622 [D loss: 0.580312, acc: 58.59%] [G loss: 1.840410]\n",
      "epoch:14 step:11623 [D loss: 0.478592, acc: 89.06%] [G loss: 1.747693]\n",
      "epoch:14 step:11624 [D loss: 0.750367, acc: 50.00%] [G loss: 2.392685]\n",
      "epoch:14 step:11625 [D loss: 0.669558, acc: 56.25%] [G loss: 2.599343]\n",
      "epoch:14 step:11626 [D loss: 1.226854, acc: 50.78%] [G loss: 2.334981]\n",
      "epoch:14 step:11627 [D loss: 1.020555, acc: 38.28%] [G loss: 1.697637]\n",
      "epoch:14 step:11628 [D loss: 0.326500, acc: 97.66%] [G loss: 2.738460]\n",
      "epoch:14 step:11629 [D loss: 0.686257, acc: 57.03%] [G loss: 1.900919]\n",
      "epoch:14 step:11630 [D loss: 0.823419, acc: 45.31%] [G loss: 1.582570]\n",
      "epoch:14 step:11631 [D loss: 1.146168, acc: 25.78%] [G loss: 1.884580]\n",
      "epoch:14 step:11632 [D loss: 0.683043, acc: 54.69%] [G loss: 2.392462]\n",
      "epoch:14 step:11633 [D loss: 0.567787, acc: 63.28%] [G loss: 2.827585]\n",
      "epoch:14 step:11634 [D loss: 0.389108, acc: 93.75%] [G loss: 2.864983]\n",
      "epoch:14 step:11635 [D loss: 0.671446, acc: 60.94%] [G loss: 1.665511]\n",
      "epoch:14 step:11636 [D loss: 0.604480, acc: 67.19%] [G loss: 2.950392]\n",
      "epoch:14 step:11637 [D loss: 0.582406, acc: 71.09%] [G loss: 2.116252]\n",
      "epoch:14 step:11638 [D loss: 0.590302, acc: 67.97%] [G loss: 2.871444]\n",
      "epoch:14 step:11639 [D loss: 0.777361, acc: 48.44%] [G loss: 1.749857]\n",
      "epoch:14 step:11640 [D loss: 0.900445, acc: 26.56%] [G loss: 1.972023]\n",
      "epoch:14 step:11641 [D loss: 0.653968, acc: 60.94%] [G loss: 1.895336]\n",
      "epoch:14 step:11642 [D loss: 0.731625, acc: 57.03%] [G loss: 2.183123]\n",
      "epoch:14 step:11643 [D loss: 0.649378, acc: 57.03%] [G loss: 2.851497]\n",
      "epoch:14 step:11644 [D loss: 0.395128, acc: 93.75%] [G loss: 1.839137]\n",
      "epoch:14 step:11645 [D loss: 0.477856, acc: 83.59%] [G loss: 2.018739]\n",
      "epoch:14 step:11646 [D loss: 0.731203, acc: 49.22%] [G loss: 2.349084]\n",
      "epoch:14 step:11647 [D loss: 0.694147, acc: 54.69%] [G loss: 2.270410]\n",
      "epoch:14 step:11648 [D loss: 0.726202, acc: 51.56%] [G loss: 3.071667]\n",
      "epoch:14 step:11649 [D loss: 0.616776, acc: 70.31%] [G loss: 2.604337]\n",
      "epoch:14 step:11650 [D loss: 0.535060, acc: 79.69%] [G loss: 2.040916]\n",
      "epoch:14 step:11651 [D loss: 0.584912, acc: 72.66%] [G loss: 2.412225]\n",
      "epoch:14 step:11652 [D loss: 0.701708, acc: 60.16%] [G loss: 2.206107]\n",
      "epoch:14 step:11653 [D loss: 0.599548, acc: 75.00%] [G loss: 2.658913]\n",
      "epoch:14 step:11654 [D loss: 0.688694, acc: 57.81%] [G loss: 2.802371]\n",
      "epoch:14 step:11655 [D loss: 0.327829, acc: 84.38%] [G loss: 2.573438]\n",
      "epoch:14 step:11656 [D loss: 0.862957, acc: 44.53%] [G loss: 1.989726]\n",
      "epoch:14 step:11657 [D loss: 0.759329, acc: 50.78%] [G loss: 2.067943]\n",
      "epoch:14 step:11658 [D loss: 0.504412, acc: 80.47%] [G loss: 3.006567]\n",
      "epoch:14 step:11659 [D loss: 0.859589, acc: 48.44%] [G loss: 1.954774]\n",
      "epoch:14 step:11660 [D loss: 0.575753, acc: 75.00%] [G loss: 2.130570]\n",
      "epoch:14 step:11661 [D loss: 0.764657, acc: 51.56%] [G loss: 2.000502]\n",
      "epoch:14 step:11662 [D loss: 0.419916, acc: 88.28%] [G loss: 2.910431]\n",
      "epoch:14 step:11663 [D loss: 0.447849, acc: 85.16%] [G loss: 2.680898]\n",
      "epoch:14 step:11664 [D loss: 0.354556, acc: 92.97%] [G loss: 2.474351]\n",
      "epoch:14 step:11665 [D loss: 0.969570, acc: 47.66%] [G loss: 1.864018]\n",
      "epoch:14 step:11666 [D loss: 0.520583, acc: 78.91%] [G loss: 1.998706]\n",
      "epoch:14 step:11667 [D loss: 0.591542, acc: 67.19%] [G loss: 1.861206]\n",
      "epoch:14 step:11668 [D loss: 0.683242, acc: 57.03%] [G loss: 2.875904]\n",
      "epoch:14 step:11669 [D loss: 0.457499, acc: 82.81%] [G loss: 2.633819]\n",
      "epoch:14 step:11670 [D loss: 0.456248, acc: 80.47%] [G loss: 2.625482]\n",
      "epoch:14 step:11671 [D loss: 0.729347, acc: 53.91%] [G loss: 2.104017]\n",
      "epoch:14 step:11672 [D loss: 0.458718, acc: 90.62%] [G loss: 2.361625]\n",
      "epoch:14 step:11673 [D loss: 0.742950, acc: 46.88%] [G loss: 1.994528]\n",
      "epoch:14 step:11674 [D loss: 0.617133, acc: 70.31%] [G loss: 1.974032]\n",
      "epoch:14 step:11675 [D loss: 0.229791, acc: 95.31%] [G loss: 3.154989]\n",
      "epoch:14 step:11676 [D loss: 0.866572, acc: 47.66%] [G loss: 3.131188]\n",
      "epoch:14 step:11677 [D loss: 0.546648, acc: 66.41%] [G loss: 2.138217]\n",
      "epoch:14 step:11678 [D loss: 0.493330, acc: 87.50%] [G loss: 2.633872]\n",
      "epoch:14 step:11679 [D loss: 0.536972, acc: 75.78%] [G loss: 2.262414]\n",
      "epoch:14 step:11680 [D loss: 1.005420, acc: 19.53%] [G loss: 2.539532]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:14 step:11681 [D loss: 0.379397, acc: 83.59%] [G loss: 3.014161]\n",
      "epoch:14 step:11682 [D loss: 0.392891, acc: 92.97%] [G loss: 2.604227]\n",
      "epoch:14 step:11683 [D loss: 0.633701, acc: 60.16%] [G loss: 2.195638]\n",
      "epoch:14 step:11684 [D loss: 0.628980, acc: 65.62%] [G loss: 2.208921]\n",
      "epoch:14 step:11685 [D loss: 0.710220, acc: 57.81%] [G loss: 2.347677]\n",
      "epoch:14 step:11686 [D loss: 0.563247, acc: 74.22%] [G loss: 2.504040]\n",
      "epoch:14 step:11687 [D loss: 0.556164, acc: 78.91%] [G loss: 2.817433]\n",
      "epoch:14 step:11688 [D loss: 0.600884, acc: 68.75%] [G loss: 2.554547]\n",
      "epoch:14 step:11689 [D loss: 0.514354, acc: 64.06%] [G loss: 2.408513]\n",
      "epoch:14 step:11690 [D loss: 0.593625, acc: 72.66%] [G loss: 2.281263]\n",
      "epoch:14 step:11691 [D loss: 0.347554, acc: 92.19%] [G loss: 2.171132]\n",
      "epoch:14 step:11692 [D loss: 0.845759, acc: 41.41%] [G loss: 2.436640]\n",
      "epoch:14 step:11693 [D loss: 0.664503, acc: 61.72%] [G loss: 2.215651]\n",
      "epoch:14 step:11694 [D loss: 0.686047, acc: 61.72%] [G loss: 2.333189]\n",
      "epoch:14 step:11695 [D loss: 0.474318, acc: 82.81%] [G loss: 1.741583]\n",
      "epoch:14 step:11696 [D loss: 0.361379, acc: 93.75%] [G loss: 2.465621]\n",
      "epoch:14 step:11697 [D loss: 0.479210, acc: 82.03%] [G loss: 2.232997]\n",
      "epoch:14 step:11698 [D loss: 0.632519, acc: 54.69%] [G loss: 2.823539]\n",
      "epoch:14 step:11699 [D loss: 0.391750, acc: 91.41%] [G loss: 3.469053]\n",
      "epoch:14 step:11700 [D loss: 0.644499, acc: 53.91%] [G loss: 2.557318]\n",
      "epoch:14 step:11701 [D loss: 0.314828, acc: 98.44%] [G loss: 1.799882]\n",
      "epoch:14 step:11702 [D loss: 0.571665, acc: 67.97%] [G loss: 2.385818]\n",
      "epoch:14 step:11703 [D loss: 0.711165, acc: 53.91%] [G loss: 2.468761]\n",
      "epoch:14 step:11704 [D loss: 0.440572, acc: 92.19%] [G loss: 2.444024]\n",
      "epoch:14 step:11705 [D loss: 0.489696, acc: 81.25%] [G loss: 2.675925]\n",
      "epoch:14 step:11706 [D loss: 0.914346, acc: 31.25%] [G loss: 2.434073]\n",
      "epoch:14 step:11707 [D loss: 0.807701, acc: 48.44%] [G loss: 2.110916]\n",
      "epoch:14 step:11708 [D loss: 0.535366, acc: 67.19%] [G loss: 2.244249]\n",
      "epoch:14 step:11709 [D loss: 0.896359, acc: 48.44%] [G loss: 2.698465]\n",
      "epoch:14 step:11710 [D loss: 0.459090, acc: 90.62%] [G loss: 2.127551]\n",
      "epoch:14 step:11711 [D loss: 0.857389, acc: 44.53%] [G loss: 1.964073]\n",
      "epoch:14 step:11712 [D loss: 0.562742, acc: 67.97%] [G loss: 1.982977]\n",
      "epoch:14 step:11713 [D loss: 0.566689, acc: 69.53%] [G loss: 2.608646]\n",
      "epoch:14 step:11714 [D loss: 0.670547, acc: 57.03%] [G loss: 1.961647]\n",
      "epoch:14 step:11715 [D loss: 0.554606, acc: 72.66%] [G loss: 2.484425]\n",
      "epoch:15 step:11716 [D loss: 0.519218, acc: 78.91%] [G loss: 2.785732]\n",
      "epoch:15 step:11717 [D loss: 0.777973, acc: 46.09%] [G loss: 2.039169]\n",
      "epoch:15 step:11718 [D loss: 0.748482, acc: 49.22%] [G loss: 2.507566]\n",
      "epoch:15 step:11719 [D loss: 0.536052, acc: 71.09%] [G loss: 2.187945]\n",
      "epoch:15 step:11720 [D loss: 0.283289, acc: 87.50%] [G loss: 4.653315]\n",
      "epoch:15 step:11721 [D loss: 0.553985, acc: 70.31%] [G loss: 2.273285]\n",
      "epoch:15 step:11722 [D loss: 0.410417, acc: 89.84%] [G loss: 2.806960]\n",
      "epoch:15 step:11723 [D loss: 0.692764, acc: 57.03%] [G loss: 1.753991]\n",
      "epoch:15 step:11724 [D loss: 0.395075, acc: 76.56%] [G loss: 3.777635]\n",
      "epoch:15 step:11725 [D loss: 1.027449, acc: 35.16%] [G loss: 2.195820]\n",
      "epoch:15 step:11726 [D loss: 0.422747, acc: 87.50%] [G loss: 1.980934]\n",
      "epoch:15 step:11727 [D loss: 0.464267, acc: 88.28%] [G loss: 2.593163]\n",
      "epoch:15 step:11728 [D loss: 0.311898, acc: 86.72%] [G loss: 2.846619]\n",
      "epoch:15 step:11729 [D loss: 0.465362, acc: 87.50%] [G loss: 2.361862]\n",
      "epoch:15 step:11730 [D loss: 0.850264, acc: 33.59%] [G loss: 1.555667]\n",
      "epoch:15 step:11731 [D loss: 0.581020, acc: 69.53%] [G loss: 1.941389]\n",
      "epoch:15 step:11732 [D loss: 0.580423, acc: 62.50%] [G loss: 2.192061]\n",
      "epoch:15 step:11733 [D loss: 0.226169, acc: 93.75%] [G loss: 2.581122]\n",
      "epoch:15 step:11734 [D loss: 0.453350, acc: 86.72%] [G loss: 2.132469]\n",
      "epoch:15 step:11735 [D loss: 0.315653, acc: 96.88%] [G loss: 2.327979]\n",
      "epoch:15 step:11736 [D loss: 0.386355, acc: 92.19%] [G loss: 2.211314]\n",
      "epoch:15 step:11737 [D loss: 0.287142, acc: 96.88%] [G loss: 2.660853]\n",
      "epoch:15 step:11738 [D loss: 0.394144, acc: 91.41%] [G loss: 2.145100]\n",
      "epoch:15 step:11739 [D loss: 0.823454, acc: 39.84%] [G loss: 2.789730]\n",
      "epoch:15 step:11740 [D loss: 0.476059, acc: 82.81%] [G loss: 2.385904]\n",
      "epoch:15 step:11741 [D loss: 0.933409, acc: 28.12%] [G loss: 2.044965]\n",
      "epoch:15 step:11742 [D loss: 0.338857, acc: 90.62%] [G loss: 2.458589]\n",
      "epoch:15 step:11743 [D loss: 0.472889, acc: 68.75%] [G loss: 2.189155]\n",
      "epoch:15 step:11744 [D loss: 0.357973, acc: 93.75%] [G loss: 2.321853]\n",
      "epoch:15 step:11745 [D loss: 0.167843, acc: 99.22%] [G loss: 2.942543]\n",
      "epoch:15 step:11746 [D loss: 0.627589, acc: 66.41%] [G loss: 2.046501]\n",
      "epoch:15 step:11747 [D loss: 0.382353, acc: 82.81%] [G loss: 3.029056]\n",
      "epoch:15 step:11748 [D loss: 0.916478, acc: 37.50%] [G loss: 1.978587]\n",
      "epoch:15 step:11749 [D loss: 0.408643, acc: 88.28%] [G loss: 2.372934]\n",
      "epoch:15 step:11750 [D loss: 0.721970, acc: 53.12%] [G loss: 2.101007]\n",
      "epoch:15 step:11751 [D loss: 0.665037, acc: 57.03%] [G loss: 2.410507]\n",
      "epoch:15 step:11752 [D loss: 0.666725, acc: 57.81%] [G loss: 1.680362]\n",
      "epoch:15 step:11753 [D loss: 1.007711, acc: 19.53%] [G loss: 1.919875]\n",
      "epoch:15 step:11754 [D loss: 0.440545, acc: 91.41%] [G loss: 2.332814]\n",
      "epoch:15 step:11755 [D loss: 0.380934, acc: 85.16%] [G loss: 2.815589]\n",
      "epoch:15 step:11756 [D loss: 0.729687, acc: 50.00%] [G loss: 2.396407]\n",
      "epoch:15 step:11757 [D loss: 0.668647, acc: 60.94%] [G loss: 2.026579]\n",
      "epoch:15 step:11758 [D loss: 0.327084, acc: 92.19%] [G loss: 2.204585]\n",
      "epoch:15 step:11759 [D loss: 0.992576, acc: 37.50%] [G loss: 2.201673]\n",
      "epoch:15 step:11760 [D loss: 0.787320, acc: 50.78%] [G loss: 1.952316]\n",
      "epoch:15 step:11761 [D loss: 0.329377, acc: 96.88%] [G loss: 2.548210]\n",
      "epoch:15 step:11762 [D loss: 1.079974, acc: 28.91%] [G loss: 1.631523]\n",
      "epoch:15 step:11763 [D loss: 0.570158, acc: 69.53%] [G loss: 2.431143]\n",
      "epoch:15 step:11764 [D loss: 0.778650, acc: 44.53%] [G loss: 2.118042]\n",
      "epoch:15 step:11765 [D loss: 0.767030, acc: 48.44%] [G loss: 2.815626]\n",
      "epoch:15 step:11766 [D loss: 0.351332, acc: 92.19%] [G loss: 2.544744]\n",
      "epoch:15 step:11767 [D loss: 0.543589, acc: 71.88%] [G loss: 2.444840]\n",
      "epoch:15 step:11768 [D loss: 0.614612, acc: 69.53%] [G loss: 2.355281]\n",
      "epoch:15 step:11769 [D loss: 0.935527, acc: 18.75%] [G loss: 1.630139]\n",
      "epoch:15 step:11770 [D loss: 0.393019, acc: 83.59%] [G loss: 1.833843]\n",
      "epoch:15 step:11771 [D loss: 0.494929, acc: 78.12%] [G loss: 1.781554]\n",
      "epoch:15 step:11772 [D loss: 0.493620, acc: 80.47%] [G loss: 2.433818]\n",
      "epoch:15 step:11773 [D loss: 0.507921, acc: 82.03%] [G loss: 2.630165]\n",
      "epoch:15 step:11774 [D loss: 0.224233, acc: 98.44%] [G loss: 2.891163]\n",
      "epoch:15 step:11775 [D loss: 0.725737, acc: 53.91%] [G loss: 2.430825]\n",
      "epoch:15 step:11776 [D loss: 0.572215, acc: 71.09%] [G loss: 2.513552]\n",
      "epoch:15 step:11777 [D loss: 0.718848, acc: 49.22%] [G loss: 2.059880]\n",
      "epoch:15 step:11778 [D loss: 0.350083, acc: 97.66%] [G loss: 2.493358]\n",
      "epoch:15 step:11779 [D loss: 0.442704, acc: 83.59%] [G loss: 2.593725]\n",
      "epoch:15 step:11780 [D loss: 0.207788, acc: 99.22%] [G loss: 2.752284]\n",
      "epoch:15 step:11781 [D loss: 0.369797, acc: 92.97%] [G loss: 3.198845]\n",
      "epoch:15 step:11782 [D loss: 1.045023, acc: 32.81%] [G loss: 2.109816]\n",
      "epoch:15 step:11783 [D loss: 0.421070, acc: 90.62%] [G loss: 2.571612]\n",
      "epoch:15 step:11784 [D loss: 0.339328, acc: 95.31%] [G loss: 2.622386]\n",
      "epoch:15 step:11785 [D loss: 0.555655, acc: 75.78%] [G loss: 1.952862]\n",
      "epoch:15 step:11786 [D loss: 0.593185, acc: 67.19%] [G loss: 2.300567]\n",
      "epoch:15 step:11787 [D loss: 0.895914, acc: 29.69%] [G loss: 1.324275]\n",
      "epoch:15 step:11788 [D loss: 0.720828, acc: 57.03%] [G loss: 1.721615]\n",
      "epoch:15 step:11789 [D loss: 0.969359, acc: 25.00%] [G loss: 1.554252]\n",
      "epoch:15 step:11790 [D loss: 0.552064, acc: 68.75%] [G loss: 1.824050]\n",
      "epoch:15 step:11791 [D loss: 0.641235, acc: 65.62%] [G loss: 2.503488]\n",
      "epoch:15 step:11792 [D loss: 0.358775, acc: 96.88%] [G loss: 2.445533]\n",
      "epoch:15 step:11793 [D loss: 0.393917, acc: 95.31%] [G loss: 2.235569]\n",
      "epoch:15 step:11794 [D loss: 0.375891, acc: 91.41%] [G loss: 2.796417]\n",
      "epoch:15 step:11795 [D loss: 0.445561, acc: 81.25%] [G loss: 3.002207]\n",
      "epoch:15 step:11796 [D loss: 0.648238, acc: 60.94%] [G loss: 2.674614]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:15 step:11797 [D loss: 0.360120, acc: 85.94%] [G loss: 2.897876]\n",
      "epoch:15 step:11798 [D loss: 0.700027, acc: 52.34%] [G loss: 2.358160]\n",
      "epoch:15 step:11799 [D loss: 1.066721, acc: 14.84%] [G loss: 1.664166]\n",
      "epoch:15 step:11800 [D loss: 0.899355, acc: 38.28%] [G loss: 2.250438]\n",
      "##############\n",
      "[0.83403978 0.86723584 0.81765064 0.81883853 0.79769468 0.83037904\n",
      " 0.89711728 0.80479109 0.80474785 0.82914667]\n",
      "##########\n",
      "epoch:15 step:11801 [D loss: 1.008433, acc: 27.34%] [G loss: 2.328612]\n",
      "epoch:15 step:11802 [D loss: 0.634974, acc: 67.97%] [G loss: 2.300944]\n",
      "epoch:15 step:11803 [D loss: 0.726403, acc: 46.88%] [G loss: 2.503090]\n",
      "epoch:15 step:11804 [D loss: 0.539172, acc: 79.69%] [G loss: 2.119824]\n",
      "epoch:15 step:11805 [D loss: 0.505967, acc: 82.03%] [G loss: 2.226953]\n",
      "epoch:15 step:11806 [D loss: 0.440001, acc: 75.00%] [G loss: 1.920035]\n",
      "epoch:15 step:11807 [D loss: 0.772401, acc: 52.34%] [G loss: 1.944762]\n",
      "epoch:15 step:11808 [D loss: 0.840391, acc: 39.06%] [G loss: 2.256896]\n",
      "epoch:15 step:11809 [D loss: 0.371375, acc: 89.84%] [G loss: 2.911306]\n",
      "epoch:15 step:11810 [D loss: 0.423375, acc: 92.19%] [G loss: 2.323354]\n",
      "epoch:15 step:11811 [D loss: 0.766051, acc: 44.53%] [G loss: 2.717567]\n",
      "epoch:15 step:11812 [D loss: 0.666993, acc: 58.59%] [G loss: 2.683624]\n",
      "epoch:15 step:11813 [D loss: 0.363973, acc: 79.69%] [G loss: 2.563625]\n",
      "epoch:15 step:11814 [D loss: 0.845729, acc: 37.50%] [G loss: 2.387949]\n",
      "epoch:15 step:11815 [D loss: 0.607621, acc: 64.06%] [G loss: 2.256547]\n",
      "epoch:15 step:11816 [D loss: 0.650700, acc: 55.47%] [G loss: 2.348972]\n",
      "epoch:15 step:11817 [D loss: 0.598915, acc: 64.06%] [G loss: 1.978075]\n",
      "epoch:15 step:11818 [D loss: 0.663178, acc: 57.81%] [G loss: 2.201488]\n",
      "epoch:15 step:11819 [D loss: 0.488792, acc: 82.03%] [G loss: 1.656215]\n",
      "epoch:15 step:11820 [D loss: 0.642468, acc: 66.41%] [G loss: 2.149245]\n",
      "epoch:15 step:11821 [D loss: 0.634048, acc: 57.03%] [G loss: 2.207170]\n",
      "epoch:15 step:11822 [D loss: 0.931440, acc: 32.81%] [G loss: 1.594880]\n",
      "epoch:15 step:11823 [D loss: 0.757781, acc: 51.56%] [G loss: 1.800277]\n",
      "epoch:15 step:11824 [D loss: 0.679039, acc: 60.94%] [G loss: 1.703633]\n",
      "epoch:15 step:11825 [D loss: 0.242353, acc: 99.22%] [G loss: 2.821005]\n",
      "epoch:15 step:11826 [D loss: 0.739923, acc: 47.66%] [G loss: 1.753639]\n",
      "epoch:15 step:11827 [D loss: 0.427406, acc: 85.16%] [G loss: 2.595052]\n",
      "epoch:15 step:11828 [D loss: 0.428796, acc: 85.16%] [G loss: 2.883715]\n",
      "epoch:15 step:11829 [D loss: 0.288947, acc: 94.53%] [G loss: 2.961801]\n",
      "epoch:15 step:11830 [D loss: 0.576647, acc: 77.34%] [G loss: 2.046805]\n",
      "epoch:15 step:11831 [D loss: 1.132354, acc: 32.81%] [G loss: 1.767395]\n",
      "epoch:15 step:11832 [D loss: 0.604349, acc: 62.50%] [G loss: 2.041714]\n",
      "epoch:15 step:11833 [D loss: 0.418646, acc: 82.03%] [G loss: 2.987140]\n",
      "epoch:15 step:11834 [D loss: 0.303840, acc: 98.44%] [G loss: 3.285730]\n",
      "epoch:15 step:11835 [D loss: 0.581636, acc: 75.78%] [G loss: 2.521505]\n",
      "epoch:15 step:11836 [D loss: 0.577504, acc: 70.31%] [G loss: 2.271286]\n",
      "epoch:15 step:11837 [D loss: 0.701463, acc: 50.78%] [G loss: 2.159169]\n",
      "epoch:15 step:11838 [D loss: 0.562051, acc: 66.41%] [G loss: 2.089222]\n",
      "epoch:15 step:11839 [D loss: 0.733388, acc: 54.69%] [G loss: 2.711578]\n",
      "epoch:15 step:11840 [D loss: 0.747584, acc: 50.78%] [G loss: 2.274448]\n",
      "epoch:15 step:11841 [D loss: 1.028886, acc: 28.12%] [G loss: 1.909662]\n",
      "epoch:15 step:11842 [D loss: 0.550803, acc: 68.75%] [G loss: 2.358643]\n",
      "epoch:15 step:11843 [D loss: 0.711116, acc: 54.69%] [G loss: 2.084263]\n",
      "epoch:15 step:11844 [D loss: 0.567298, acc: 76.56%] [G loss: 2.361601]\n",
      "epoch:15 step:11845 [D loss: 1.090234, acc: 40.62%] [G loss: 2.039668]\n",
      "epoch:15 step:11846 [D loss: 0.430122, acc: 85.16%] [G loss: 2.842162]\n",
      "epoch:15 step:11847 [D loss: 0.462294, acc: 86.72%] [G loss: 1.948810]\n",
      "epoch:15 step:11848 [D loss: 0.462044, acc: 77.34%] [G loss: 2.135113]\n",
      "epoch:15 step:11849 [D loss: 0.751609, acc: 50.78%] [G loss: 1.992471]\n",
      "epoch:15 step:11850 [D loss: 0.655062, acc: 59.38%] [G loss: 2.169685]\n",
      "epoch:15 step:11851 [D loss: 0.306628, acc: 93.75%] [G loss: 2.760237]\n",
      "epoch:15 step:11852 [D loss: 0.895259, acc: 34.38%] [G loss: 2.162376]\n",
      "epoch:15 step:11853 [D loss: 0.688579, acc: 55.47%] [G loss: 1.964408]\n",
      "epoch:15 step:11854 [D loss: 0.370178, acc: 95.31%] [G loss: 2.301952]\n",
      "epoch:15 step:11855 [D loss: 0.510066, acc: 83.59%] [G loss: 2.080988]\n",
      "epoch:15 step:11856 [D loss: 0.526874, acc: 68.75%] [G loss: 2.517401]\n",
      "epoch:15 step:11857 [D loss: 0.333959, acc: 96.88%] [G loss: 2.228487]\n",
      "epoch:15 step:11858 [D loss: 0.824042, acc: 46.09%] [G loss: 1.831095]\n",
      "epoch:15 step:11859 [D loss: 0.527032, acc: 77.34%] [G loss: 2.376731]\n",
      "epoch:15 step:11860 [D loss: 0.429098, acc: 86.72%] [G loss: 1.947103]\n",
      "epoch:15 step:11861 [D loss: 0.218792, acc: 97.66%] [G loss: 2.312005]\n",
      "epoch:15 step:11862 [D loss: 0.702496, acc: 56.25%] [G loss: 2.622060]\n",
      "epoch:15 step:11863 [D loss: 0.585166, acc: 71.09%] [G loss: 3.618782]\n",
      "epoch:15 step:11864 [D loss: 0.503036, acc: 64.06%] [G loss: 2.853529]\n",
      "epoch:15 step:11865 [D loss: 0.550545, acc: 70.31%] [G loss: 2.266104]\n",
      "epoch:15 step:11866 [D loss: 0.756647, acc: 52.34%] [G loss: 2.035732]\n",
      "epoch:15 step:11867 [D loss: 0.196837, acc: 100.00%] [G loss: 1.540844]\n",
      "epoch:15 step:11868 [D loss: 0.689073, acc: 56.25%] [G loss: 2.276021]\n",
      "epoch:15 step:11869 [D loss: 0.519385, acc: 77.34%] [G loss: 2.121142]\n",
      "epoch:15 step:11870 [D loss: 0.437843, acc: 72.66%] [G loss: 1.864068]\n",
      "epoch:15 step:11871 [D loss: 0.395638, acc: 87.50%] [G loss: 2.492084]\n",
      "epoch:15 step:11872 [D loss: 0.433938, acc: 88.28%] [G loss: 2.707256]\n",
      "epoch:15 step:11873 [D loss: 0.479055, acc: 75.00%] [G loss: 3.509165]\n",
      "epoch:15 step:11874 [D loss: 0.554833, acc: 69.53%] [G loss: 2.500049]\n",
      "epoch:15 step:11875 [D loss: 0.202752, acc: 98.44%] [G loss: 3.116094]\n",
      "epoch:15 step:11876 [D loss: 0.572319, acc: 70.31%] [G loss: 2.242435]\n",
      "epoch:15 step:11877 [D loss: 0.367599, acc: 84.38%] [G loss: 3.134938]\n",
      "epoch:15 step:11878 [D loss: 0.445121, acc: 84.38%] [G loss: 1.955431]\n",
      "epoch:15 step:11879 [D loss: 0.614543, acc: 63.28%] [G loss: 2.245131]\n",
      "epoch:15 step:11880 [D loss: 0.571113, acc: 78.12%] [G loss: 1.907622]\n",
      "epoch:15 step:11881 [D loss: 0.820590, acc: 50.78%] [G loss: 2.961730]\n",
      "epoch:15 step:11882 [D loss: 1.045033, acc: 50.78%] [G loss: 2.939302]\n",
      "epoch:15 step:11883 [D loss: 0.156912, acc: 98.44%] [G loss: 3.484100]\n",
      "epoch:15 step:11884 [D loss: 0.925251, acc: 50.78%] [G loss: 1.911280]\n",
      "epoch:15 step:11885 [D loss: 0.490404, acc: 82.03%] [G loss: 2.544118]\n",
      "epoch:15 step:11886 [D loss: 0.345492, acc: 88.28%] [G loss: 3.458693]\n",
      "epoch:15 step:11887 [D loss: 1.095460, acc: 28.91%] [G loss: 1.885905]\n",
      "epoch:15 step:11888 [D loss: 0.899525, acc: 28.12%] [G loss: 1.416049]\n",
      "epoch:15 step:11889 [D loss: 0.472789, acc: 81.25%] [G loss: 2.409112]\n",
      "epoch:15 step:11890 [D loss: 0.621916, acc: 65.62%] [G loss: 2.294930]\n",
      "epoch:15 step:11891 [D loss: 0.798370, acc: 39.84%] [G loss: 1.681957]\n",
      "epoch:15 step:11892 [D loss: 0.422148, acc: 88.28%] [G loss: 2.775766]\n",
      "epoch:15 step:11893 [D loss: 0.332388, acc: 87.50%] [G loss: 2.086499]\n",
      "epoch:15 step:11894 [D loss: 0.352321, acc: 92.19%] [G loss: 2.542079]\n",
      "epoch:15 step:11895 [D loss: 0.702246, acc: 56.25%] [G loss: 2.353435]\n",
      "epoch:15 step:11896 [D loss: 0.445093, acc: 90.62%] [G loss: 1.809035]\n",
      "epoch:15 step:11897 [D loss: 0.626009, acc: 61.72%] [G loss: 1.816841]\n",
      "epoch:15 step:11898 [D loss: 0.373103, acc: 89.06%] [G loss: 3.494814]\n",
      "epoch:15 step:11899 [D loss: 1.200641, acc: 14.84%] [G loss: 1.442848]\n",
      "epoch:15 step:11900 [D loss: 0.977416, acc: 21.09%] [G loss: 2.060443]\n",
      "epoch:15 step:11901 [D loss: 0.279976, acc: 98.44%] [G loss: 2.409727]\n",
      "epoch:15 step:11902 [D loss: 0.507861, acc: 75.00%] [G loss: 1.560491]\n",
      "epoch:15 step:11903 [D loss: 0.323828, acc: 91.41%] [G loss: 2.827351]\n",
      "epoch:15 step:11904 [D loss: 0.725719, acc: 54.69%] [G loss: 2.406458]\n",
      "epoch:15 step:11905 [D loss: 0.640448, acc: 60.94%] [G loss: 2.623210]\n",
      "epoch:15 step:11906 [D loss: 0.447650, acc: 89.06%] [G loss: 2.369590]\n",
      "epoch:15 step:11907 [D loss: 0.303478, acc: 90.62%] [G loss: 2.646061]\n",
      "epoch:15 step:11908 [D loss: 0.413263, acc: 92.19%] [G loss: 2.697644]\n",
      "epoch:15 step:11909 [D loss: 0.232747, acc: 99.22%] [G loss: 2.720705]\n",
      "epoch:15 step:11910 [D loss: 0.645463, acc: 61.72%] [G loss: 1.876672]\n",
      "epoch:15 step:11911 [D loss: 0.565467, acc: 60.16%] [G loss: 2.295126]\n",
      "epoch:15 step:11912 [D loss: 0.627651, acc: 61.72%] [G loss: 2.321065]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:15 step:11913 [D loss: 0.758550, acc: 44.53%] [G loss: 2.353927]\n",
      "epoch:15 step:11914 [D loss: 0.526349, acc: 74.22%] [G loss: 2.139160]\n",
      "epoch:15 step:11915 [D loss: 0.719798, acc: 53.12%] [G loss: 2.434680]\n",
      "epoch:15 step:11916 [D loss: 0.388318, acc: 94.53%] [G loss: 2.195507]\n",
      "epoch:15 step:11917 [D loss: 0.933979, acc: 19.53%] [G loss: 2.057657]\n",
      "epoch:15 step:11918 [D loss: 0.545802, acc: 78.12%] [G loss: 2.162410]\n",
      "epoch:15 step:11919 [D loss: 0.602510, acc: 68.75%] [G loss: 1.929819]\n",
      "epoch:15 step:11920 [D loss: 0.368604, acc: 80.47%] [G loss: 2.216586]\n",
      "epoch:15 step:11921 [D loss: 0.707406, acc: 49.22%] [G loss: 1.838622]\n",
      "epoch:15 step:11922 [D loss: 0.699233, acc: 53.12%] [G loss: 1.249043]\n",
      "epoch:15 step:11923 [D loss: 0.415215, acc: 91.41%] [G loss: 2.354329]\n",
      "epoch:15 step:11924 [D loss: 0.653955, acc: 60.16%] [G loss: 2.003784]\n",
      "epoch:15 step:11925 [D loss: 0.870089, acc: 39.84%] [G loss: 2.309537]\n",
      "epoch:15 step:11926 [D loss: 0.401299, acc: 94.53%] [G loss: 2.317896]\n",
      "epoch:15 step:11927 [D loss: 0.400430, acc: 84.38%] [G loss: 2.584639]\n",
      "epoch:15 step:11928 [D loss: 0.749792, acc: 53.91%] [G loss: 1.741789]\n",
      "epoch:15 step:11929 [D loss: 0.505409, acc: 74.22%] [G loss: 2.655489]\n",
      "epoch:15 step:11930 [D loss: 0.265329, acc: 96.88%] [G loss: 2.120129]\n",
      "epoch:15 step:11931 [D loss: 0.456160, acc: 86.72%] [G loss: 1.834508]\n",
      "epoch:15 step:11932 [D loss: 0.888008, acc: 32.81%] [G loss: 2.100147]\n",
      "epoch:15 step:11933 [D loss: 0.553440, acc: 70.31%] [G loss: 2.459956]\n",
      "epoch:15 step:11934 [D loss: 0.252209, acc: 99.22%] [G loss: 2.880334]\n",
      "epoch:15 step:11935 [D loss: 0.614753, acc: 65.62%] [G loss: 2.212131]\n",
      "epoch:15 step:11936 [D loss: 0.369368, acc: 75.78%] [G loss: 2.429742]\n",
      "epoch:15 step:11937 [D loss: 0.798671, acc: 50.00%] [G loss: 2.213387]\n",
      "epoch:15 step:11938 [D loss: 0.521389, acc: 76.56%] [G loss: 1.972009]\n",
      "epoch:15 step:11939 [D loss: 0.500984, acc: 79.69%] [G loss: 2.087116]\n",
      "epoch:15 step:11940 [D loss: 0.857116, acc: 46.09%] [G loss: 1.772588]\n",
      "epoch:15 step:11941 [D loss: 0.690883, acc: 59.38%] [G loss: 2.302173]\n",
      "epoch:15 step:11942 [D loss: 0.426142, acc: 90.62%] [G loss: 2.419633]\n",
      "epoch:15 step:11943 [D loss: 0.456354, acc: 87.50%] [G loss: 2.416259]\n",
      "epoch:15 step:11944 [D loss: 0.617817, acc: 67.19%] [G loss: 2.327524]\n",
      "epoch:15 step:11945 [D loss: 0.725322, acc: 49.22%] [G loss: 2.409611]\n",
      "epoch:15 step:11946 [D loss: 0.608913, acc: 70.31%] [G loss: 2.586797]\n",
      "epoch:15 step:11947 [D loss: 0.630994, acc: 67.19%] [G loss: 2.034021]\n",
      "epoch:15 step:11948 [D loss: 0.350001, acc: 89.06%] [G loss: 2.944166]\n",
      "epoch:15 step:11949 [D loss: 0.606404, acc: 69.53%] [G loss: 2.480198]\n",
      "epoch:15 step:11950 [D loss: 0.321121, acc: 89.84%] [G loss: 2.328022]\n",
      "epoch:15 step:11951 [D loss: 1.089824, acc: 32.03%] [G loss: 1.880100]\n",
      "epoch:15 step:11952 [D loss: 0.724220, acc: 54.69%] [G loss: 2.471318]\n",
      "epoch:15 step:11953 [D loss: 0.806700, acc: 45.31%] [G loss: 1.438226]\n",
      "epoch:15 step:11954 [D loss: 0.747234, acc: 50.00%] [G loss: 2.447548]\n",
      "epoch:15 step:11955 [D loss: 0.560987, acc: 77.34%] [G loss: 1.821694]\n",
      "epoch:15 step:11956 [D loss: 0.683938, acc: 53.91%] [G loss: 2.274058]\n",
      "epoch:15 step:11957 [D loss: 0.601976, acc: 67.97%] [G loss: 2.707598]\n",
      "epoch:15 step:11958 [D loss: 0.760526, acc: 46.88%] [G loss: 2.015244]\n",
      "epoch:15 step:11959 [D loss: 0.562413, acc: 70.31%] [G loss: 2.233566]\n",
      "epoch:15 step:11960 [D loss: 1.189569, acc: 25.00%] [G loss: 1.194255]\n",
      "epoch:15 step:11961 [D loss: 0.432935, acc: 89.84%] [G loss: 1.932887]\n",
      "epoch:15 step:11962 [D loss: 0.805833, acc: 50.78%] [G loss: 2.086717]\n",
      "epoch:15 step:11963 [D loss: 0.923719, acc: 27.34%] [G loss: 2.060955]\n",
      "epoch:15 step:11964 [D loss: 0.672738, acc: 56.25%] [G loss: 2.532142]\n",
      "epoch:15 step:11965 [D loss: 0.499149, acc: 83.59%] [G loss: 2.300622]\n",
      "epoch:15 step:11966 [D loss: 0.679156, acc: 56.25%] [G loss: 2.320370]\n",
      "epoch:15 step:11967 [D loss: 0.537229, acc: 78.91%] [G loss: 2.795037]\n",
      "epoch:15 step:11968 [D loss: 0.844847, acc: 42.97%] [G loss: 2.037744]\n",
      "epoch:15 step:11969 [D loss: 0.692802, acc: 58.59%] [G loss: 1.879156]\n",
      "epoch:15 step:11970 [D loss: 0.477168, acc: 84.38%] [G loss: 2.213923]\n",
      "epoch:15 step:11971 [D loss: 0.435107, acc: 86.72%] [G loss: 3.000021]\n",
      "epoch:15 step:11972 [D loss: 0.857047, acc: 34.38%] [G loss: 2.498802]\n",
      "epoch:15 step:11973 [D loss: 0.529524, acc: 83.59%] [G loss: 1.719547]\n",
      "epoch:15 step:11974 [D loss: 0.462708, acc: 80.47%] [G loss: 2.554794]\n",
      "epoch:15 step:11975 [D loss: 0.519079, acc: 73.44%] [G loss: 2.539399]\n",
      "epoch:15 step:11976 [D loss: 0.532047, acc: 86.72%] [G loss: 2.787756]\n",
      "epoch:15 step:11977 [D loss: 0.429953, acc: 91.41%] [G loss: 3.021548]\n",
      "epoch:15 step:11978 [D loss: 0.531946, acc: 70.31%] [G loss: 2.977617]\n",
      "epoch:15 step:11979 [D loss: 0.648556, acc: 53.91%] [G loss: 2.812097]\n",
      "epoch:15 step:11980 [D loss: 0.357844, acc: 96.09%] [G loss: 2.921090]\n",
      "epoch:15 step:11981 [D loss: 0.625416, acc: 59.38%] [G loss: 2.706550]\n",
      "epoch:15 step:11982 [D loss: 1.229249, acc: 11.72%] [G loss: 1.870089]\n",
      "epoch:15 step:11983 [D loss: 0.485367, acc: 82.81%] [G loss: 2.706556]\n",
      "epoch:15 step:11984 [D loss: 0.554160, acc: 57.03%] [G loss: 2.864872]\n",
      "epoch:15 step:11985 [D loss: 0.888027, acc: 42.19%] [G loss: 2.040865]\n",
      "epoch:15 step:11986 [D loss: 0.516010, acc: 72.66%] [G loss: 2.173522]\n",
      "epoch:15 step:11987 [D loss: 0.497719, acc: 71.88%] [G loss: 2.086693]\n",
      "epoch:15 step:11988 [D loss: 0.635405, acc: 63.28%] [G loss: 2.326584]\n",
      "epoch:15 step:11989 [D loss: 0.636501, acc: 61.72%] [G loss: 2.197017]\n",
      "epoch:15 step:11990 [D loss: 0.486344, acc: 81.25%] [G loss: 2.440625]\n",
      "epoch:15 step:11991 [D loss: 0.362246, acc: 91.41%] [G loss: 1.731507]\n",
      "epoch:15 step:11992 [D loss: 0.599346, acc: 71.88%] [G loss: 2.416181]\n",
      "epoch:15 step:11993 [D loss: 0.579456, acc: 69.53%] [G loss: 2.460061]\n",
      "epoch:15 step:11994 [D loss: 0.873451, acc: 46.88%] [G loss: 1.680886]\n",
      "epoch:15 step:11995 [D loss: 0.456627, acc: 79.69%] [G loss: 1.908847]\n",
      "epoch:15 step:11996 [D loss: 0.583025, acc: 68.75%] [G loss: 2.086495]\n",
      "epoch:15 step:11997 [D loss: 0.575485, acc: 71.09%] [G loss: 2.243577]\n",
      "epoch:15 step:11998 [D loss: 0.315523, acc: 90.62%] [G loss: 2.641753]\n",
      "epoch:15 step:11999 [D loss: 0.419197, acc: 93.75%] [G loss: 1.956208]\n",
      "epoch:15 step:12000 [D loss: 0.551452, acc: 75.78%] [G loss: 2.361099]\n",
      "##############\n",
      "[0.85877313 0.86946504 0.81507792 0.81662259 0.81789072 0.81722376\n",
      " 0.87863167 0.83339443 0.81433224 0.82334893]\n",
      "##########\n",
      "epoch:15 step:12001 [D loss: 0.626199, acc: 71.09%] [G loss: 2.447893]\n",
      "epoch:15 step:12002 [D loss: 0.692273, acc: 57.03%] [G loss: 2.187325]\n",
      "epoch:15 step:12003 [D loss: 0.597954, acc: 71.09%] [G loss: 3.065978]\n",
      "epoch:15 step:12004 [D loss: 1.030707, acc: 17.19%] [G loss: 1.795308]\n",
      "epoch:15 step:12005 [D loss: 0.532339, acc: 78.12%] [G loss: 2.721446]\n",
      "epoch:15 step:12006 [D loss: 0.850944, acc: 48.44%] [G loss: 1.553572]\n",
      "epoch:15 step:12007 [D loss: 0.511649, acc: 71.88%] [G loss: 3.034334]\n",
      "epoch:15 step:12008 [D loss: 0.468151, acc: 86.72%] [G loss: 2.171279]\n",
      "epoch:15 step:12009 [D loss: 0.715898, acc: 56.25%] [G loss: 2.542529]\n",
      "epoch:15 step:12010 [D loss: 0.511153, acc: 82.03%] [G loss: 2.091679]\n",
      "epoch:15 step:12011 [D loss: 0.739733, acc: 53.91%] [G loss: 3.353941]\n",
      "epoch:15 step:12012 [D loss: 1.166281, acc: 13.28%] [G loss: 1.571388]\n",
      "epoch:15 step:12013 [D loss: 0.733432, acc: 50.78%] [G loss: 2.039447]\n",
      "epoch:15 step:12014 [D loss: 0.471560, acc: 80.47%] [G loss: 2.406098]\n",
      "epoch:15 step:12015 [D loss: 0.581092, acc: 67.19%] [G loss: 2.371996]\n",
      "epoch:15 step:12016 [D loss: 0.781455, acc: 46.88%] [G loss: 2.062581]\n",
      "epoch:15 step:12017 [D loss: 0.678193, acc: 57.03%] [G loss: 2.459387]\n",
      "epoch:15 step:12018 [D loss: 0.525396, acc: 79.69%] [G loss: 2.178471]\n",
      "epoch:15 step:12019 [D loss: 0.328897, acc: 96.88%] [G loss: 2.487030]\n",
      "epoch:15 step:12020 [D loss: 0.549362, acc: 80.47%] [G loss: 2.607693]\n",
      "epoch:15 step:12021 [D loss: 0.541222, acc: 81.25%] [G loss: 2.327010]\n",
      "epoch:15 step:12022 [D loss: 0.570023, acc: 73.44%] [G loss: 2.019996]\n",
      "epoch:15 step:12023 [D loss: 0.577601, acc: 71.09%] [G loss: 2.637791]\n",
      "epoch:15 step:12024 [D loss: 0.598146, acc: 67.19%] [G loss: 2.404966]\n",
      "epoch:15 step:12025 [D loss: 0.525803, acc: 74.22%] [G loss: 2.431813]\n",
      "epoch:15 step:12026 [D loss: 0.658058, acc: 59.38%] [G loss: 3.085802]\n",
      "epoch:15 step:12027 [D loss: 0.538579, acc: 75.78%] [G loss: 2.426043]\n",
      "epoch:15 step:12028 [D loss: 0.338547, acc: 95.31%] [G loss: 2.497920]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:15 step:12029 [D loss: 0.568599, acc: 72.66%] [G loss: 2.457421]\n",
      "epoch:15 step:12030 [D loss: 0.673203, acc: 64.84%] [G loss: 2.325179]\n",
      "epoch:15 step:12031 [D loss: 0.538842, acc: 76.56%] [G loss: 2.221915]\n",
      "epoch:15 step:12032 [D loss: 0.498722, acc: 83.59%] [G loss: 2.719100]\n",
      "epoch:15 step:12033 [D loss: 0.402017, acc: 93.75%] [G loss: 2.592695]\n",
      "epoch:15 step:12034 [D loss: 0.644818, acc: 64.84%] [G loss: 2.370718]\n",
      "epoch:15 step:12035 [D loss: 0.763623, acc: 46.88%] [G loss: 1.745424]\n",
      "epoch:15 step:12036 [D loss: 0.463473, acc: 85.94%] [G loss: 2.260610]\n",
      "epoch:15 step:12037 [D loss: 0.684192, acc: 54.69%] [G loss: 2.191964]\n",
      "epoch:15 step:12038 [D loss: 0.756435, acc: 53.91%] [G loss: 1.885724]\n",
      "epoch:15 step:12039 [D loss: 0.648781, acc: 57.81%] [G loss: 2.984686]\n",
      "epoch:15 step:12040 [D loss: 0.553058, acc: 75.00%] [G loss: 2.986681]\n",
      "epoch:15 step:12041 [D loss: 0.686195, acc: 56.25%] [G loss: 2.137286]\n",
      "epoch:15 step:12042 [D loss: 0.293787, acc: 91.41%] [G loss: 2.539718]\n",
      "epoch:15 step:12043 [D loss: 0.654861, acc: 62.50%] [G loss: 2.348406]\n",
      "epoch:15 step:12044 [D loss: 0.592176, acc: 59.38%] [G loss: 2.434091]\n",
      "epoch:15 step:12045 [D loss: 0.747772, acc: 50.00%] [G loss: 2.081484]\n",
      "epoch:15 step:12046 [D loss: 0.503774, acc: 79.69%] [G loss: 3.268832]\n",
      "epoch:15 step:12047 [D loss: 0.765323, acc: 53.12%] [G loss: 2.320801]\n",
      "epoch:15 step:12048 [D loss: 0.502994, acc: 80.47%] [G loss: 3.251341]\n",
      "epoch:15 step:12049 [D loss: 0.488905, acc: 74.22%] [G loss: 2.518774]\n",
      "epoch:15 step:12050 [D loss: 0.797081, acc: 53.12%] [G loss: 3.599431]\n",
      "epoch:15 step:12051 [D loss: 0.708150, acc: 57.81%] [G loss: 2.137216]\n",
      "epoch:15 step:12052 [D loss: 0.639875, acc: 57.81%] [G loss: 2.651415]\n",
      "epoch:15 step:12053 [D loss: 0.518245, acc: 71.09%] [G loss: 2.714376]\n",
      "epoch:15 step:12054 [D loss: 0.692342, acc: 56.25%] [G loss: 2.487788]\n",
      "epoch:15 step:12055 [D loss: 0.761829, acc: 56.25%] [G loss: 1.842716]\n",
      "epoch:15 step:12056 [D loss: 0.376303, acc: 85.94%] [G loss: 2.654489]\n",
      "epoch:15 step:12057 [D loss: 0.328595, acc: 91.41%] [G loss: 2.461945]\n",
      "epoch:15 step:12058 [D loss: 0.686972, acc: 57.03%] [G loss: 2.316770]\n",
      "epoch:15 step:12059 [D loss: 0.592752, acc: 70.31%] [G loss: 2.303525]\n",
      "epoch:15 step:12060 [D loss: 0.562634, acc: 77.34%] [G loss: 1.676680]\n",
      "epoch:15 step:12061 [D loss: 0.353032, acc: 93.75%] [G loss: 2.138945]\n",
      "epoch:15 step:12062 [D loss: 0.572710, acc: 71.09%] [G loss: 2.572669]\n",
      "epoch:15 step:12063 [D loss: 0.836944, acc: 42.19%] [G loss: 2.055665]\n",
      "epoch:15 step:12064 [D loss: 0.727925, acc: 51.56%] [G loss: 2.138845]\n",
      "epoch:15 step:12065 [D loss: 1.076248, acc: 46.09%] [G loss: 2.930642]\n",
      "epoch:15 step:12066 [D loss: 0.615591, acc: 65.62%] [G loss: 1.757484]\n",
      "epoch:15 step:12067 [D loss: 0.510887, acc: 81.25%] [G loss: 3.095989]\n",
      "epoch:15 step:12068 [D loss: 0.930640, acc: 43.75%] [G loss: 2.464938]\n",
      "epoch:15 step:12069 [D loss: 0.992365, acc: 46.09%] [G loss: 1.730401]\n",
      "epoch:15 step:12070 [D loss: 0.737165, acc: 54.69%] [G loss: 2.223809]\n",
      "epoch:15 step:12071 [D loss: 0.325900, acc: 96.09%] [G loss: 2.727675]\n",
      "epoch:15 step:12072 [D loss: 0.420892, acc: 85.94%] [G loss: 2.772200]\n",
      "epoch:15 step:12073 [D loss: 0.333454, acc: 83.59%] [G loss: 2.568033]\n",
      "epoch:15 step:12074 [D loss: 0.513357, acc: 79.69%] [G loss: 2.569739]\n",
      "epoch:15 step:12075 [D loss: 0.611832, acc: 65.62%] [G loss: 2.904577]\n",
      "epoch:15 step:12076 [D loss: 0.445464, acc: 87.50%] [G loss: 1.949661]\n",
      "epoch:15 step:12077 [D loss: 0.545864, acc: 78.91%] [G loss: 1.972252]\n",
      "epoch:15 step:12078 [D loss: 0.513836, acc: 85.16%] [G loss: 2.164209]\n",
      "epoch:15 step:12079 [D loss: 0.532249, acc: 72.66%] [G loss: 2.350388]\n",
      "epoch:15 step:12080 [D loss: 0.241336, acc: 93.75%] [G loss: 2.951601]\n",
      "epoch:15 step:12081 [D loss: 1.142797, acc: 45.31%] [G loss: 2.102279]\n",
      "epoch:15 step:12082 [D loss: 0.413166, acc: 92.97%] [G loss: 2.631985]\n",
      "epoch:15 step:12083 [D loss: 0.405227, acc: 79.69%] [G loss: 2.585981]\n",
      "epoch:15 step:12084 [D loss: 0.854722, acc: 50.00%] [G loss: 2.694279]\n",
      "epoch:15 step:12085 [D loss: 0.525583, acc: 64.84%] [G loss: 2.290402]\n",
      "epoch:15 step:12086 [D loss: 0.580300, acc: 67.97%] [G loss: 2.318391]\n",
      "epoch:15 step:12087 [D loss: 0.651397, acc: 61.72%] [G loss: 2.251938]\n",
      "epoch:15 step:12088 [D loss: 1.497130, acc: 3.12%] [G loss: 1.820890]\n",
      "epoch:15 step:12089 [D loss: 0.550710, acc: 62.50%] [G loss: 2.723880]\n",
      "epoch:15 step:12090 [D loss: 0.591777, acc: 72.66%] [G loss: 2.765793]\n",
      "epoch:15 step:12091 [D loss: 0.628388, acc: 67.97%] [G loss: 2.867932]\n",
      "epoch:15 step:12092 [D loss: 0.579332, acc: 72.66%] [G loss: 2.371834]\n",
      "epoch:15 step:12093 [D loss: 0.398164, acc: 89.84%] [G loss: 2.538943]\n",
      "epoch:15 step:12094 [D loss: 0.500949, acc: 75.78%] [G loss: 2.369844]\n",
      "epoch:15 step:12095 [D loss: 0.588804, acc: 71.88%] [G loss: 2.757635]\n",
      "epoch:15 step:12096 [D loss: 0.355192, acc: 85.16%] [G loss: 1.716210]\n",
      "epoch:15 step:12097 [D loss: 0.323550, acc: 96.88%] [G loss: 2.299396]\n",
      "epoch:15 step:12098 [D loss: 0.352184, acc: 92.97%] [G loss: 2.114918]\n",
      "epoch:15 step:12099 [D loss: 0.614613, acc: 59.38%] [G loss: 2.152626]\n",
      "epoch:15 step:12100 [D loss: 0.215040, acc: 99.22%] [G loss: 3.003573]\n",
      "epoch:15 step:12101 [D loss: 0.430215, acc: 88.28%] [G loss: 2.271022]\n",
      "epoch:15 step:12102 [D loss: 0.463357, acc: 85.16%] [G loss: 2.413729]\n",
      "epoch:15 step:12103 [D loss: 0.488265, acc: 78.91%] [G loss: 3.139767]\n",
      "epoch:15 step:12104 [D loss: 0.679985, acc: 57.81%] [G loss: 1.719546]\n",
      "epoch:15 step:12105 [D loss: 0.454030, acc: 78.12%] [G loss: 2.319808]\n",
      "epoch:15 step:12106 [D loss: 1.439009, acc: 50.00%] [G loss: 1.363854]\n",
      "epoch:15 step:12107 [D loss: 0.442894, acc: 88.28%] [G loss: 2.473268]\n",
      "epoch:15 step:12108 [D loss: 0.290336, acc: 98.44%] [G loss: 3.155176]\n",
      "epoch:15 step:12109 [D loss: 0.528396, acc: 61.72%] [G loss: 1.833211]\n",
      "epoch:15 step:12110 [D loss: 0.674726, acc: 59.38%] [G loss: 1.634047]\n",
      "epoch:15 step:12111 [D loss: 0.685607, acc: 60.16%] [G loss: 2.273310]\n",
      "epoch:15 step:12112 [D loss: 0.642076, acc: 63.28%] [G loss: 1.798737]\n",
      "epoch:15 step:12113 [D loss: 0.610749, acc: 60.16%] [G loss: 2.305317]\n",
      "epoch:15 step:12114 [D loss: 0.610665, acc: 64.06%] [G loss: 2.195894]\n",
      "epoch:15 step:12115 [D loss: 0.288454, acc: 96.09%] [G loss: 2.813187]\n",
      "epoch:15 step:12116 [D loss: 0.224230, acc: 99.22%] [G loss: 2.473915]\n",
      "epoch:15 step:12117 [D loss: 0.392498, acc: 89.06%] [G loss: 2.610961]\n",
      "epoch:15 step:12118 [D loss: 0.569725, acc: 66.41%] [G loss: 2.383148]\n",
      "epoch:15 step:12119 [D loss: 0.223433, acc: 100.00%] [G loss: 2.658307]\n",
      "epoch:15 step:12120 [D loss: 0.324183, acc: 97.66%] [G loss: 2.338418]\n",
      "epoch:15 step:12121 [D loss: 0.678331, acc: 57.03%] [G loss: 1.716971]\n",
      "epoch:15 step:12122 [D loss: 0.525640, acc: 78.91%] [G loss: 2.062459]\n",
      "epoch:15 step:12123 [D loss: 0.314827, acc: 92.97%] [G loss: 2.396186]\n",
      "epoch:15 step:12124 [D loss: 0.600199, acc: 60.16%] [G loss: 2.958782]\n",
      "epoch:15 step:12125 [D loss: 0.714253, acc: 53.12%] [G loss: 2.426895]\n",
      "epoch:15 step:12126 [D loss: 0.945570, acc: 45.31%] [G loss: 1.911255]\n",
      "epoch:15 step:12127 [D loss: 0.457296, acc: 85.16%] [G loss: 3.564904]\n",
      "epoch:15 step:12128 [D loss: 0.751475, acc: 52.34%] [G loss: 3.567613]\n",
      "epoch:15 step:12129 [D loss: 0.468192, acc: 85.16%] [G loss: 2.282413]\n",
      "epoch:15 step:12130 [D loss: 0.427732, acc: 89.06%] [G loss: 2.334431]\n",
      "epoch:15 step:12131 [D loss: 0.729724, acc: 50.78%] [G loss: 2.824728]\n",
      "epoch:15 step:12132 [D loss: 0.387754, acc: 92.19%] [G loss: 3.153414]\n",
      "epoch:15 step:12133 [D loss: 0.363836, acc: 95.31%] [G loss: 2.138805]\n",
      "epoch:15 step:12134 [D loss: 0.555193, acc: 74.22%] [G loss: 1.846478]\n",
      "epoch:15 step:12135 [D loss: 0.536044, acc: 76.56%] [G loss: 2.770724]\n",
      "epoch:15 step:12136 [D loss: 0.536080, acc: 79.69%] [G loss: 2.523933]\n",
      "epoch:15 step:12137 [D loss: 0.365079, acc: 85.16%] [G loss: 3.027801]\n",
      "epoch:15 step:12138 [D loss: 0.405532, acc: 75.00%] [G loss: 2.605419]\n",
      "epoch:15 step:12139 [D loss: 0.817453, acc: 40.62%] [G loss: 2.598115]\n",
      "epoch:15 step:12140 [D loss: 0.223232, acc: 99.22%] [G loss: 3.610846]\n",
      "epoch:15 step:12141 [D loss: 0.624974, acc: 62.50%] [G loss: 2.293397]\n",
      "epoch:15 step:12142 [D loss: 0.460725, acc: 85.94%] [G loss: 2.158278]\n",
      "epoch:15 step:12143 [D loss: 0.732899, acc: 47.66%] [G loss: 2.371295]\n",
      "epoch:15 step:12144 [D loss: 0.404288, acc: 94.53%] [G loss: 2.840156]\n",
      "epoch:15 step:12145 [D loss: 0.553860, acc: 77.34%] [G loss: 2.654105]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:15 step:12146 [D loss: 0.432834, acc: 89.84%] [G loss: 2.480562]\n",
      "epoch:15 step:12147 [D loss: 0.313783, acc: 97.66%] [G loss: 2.623876]\n",
      "epoch:15 step:12148 [D loss: 0.394959, acc: 79.69%] [G loss: 1.612908]\n",
      "epoch:15 step:12149 [D loss: 0.446202, acc: 88.28%] [G loss: 2.250289]\n",
      "epoch:15 step:12150 [D loss: 0.515883, acc: 73.44%] [G loss: 2.306178]\n",
      "epoch:15 step:12151 [D loss: 0.337994, acc: 84.38%] [G loss: 3.179559]\n",
      "epoch:15 step:12152 [D loss: 1.093144, acc: 28.91%] [G loss: 2.146648]\n",
      "epoch:15 step:12153 [D loss: 0.332462, acc: 94.53%] [G loss: 2.955018]\n",
      "epoch:15 step:12154 [D loss: 0.403930, acc: 85.16%] [G loss: 2.550866]\n",
      "epoch:15 step:12155 [D loss: 0.341536, acc: 96.09%] [G loss: 1.725284]\n",
      "epoch:15 step:12156 [D loss: 0.372867, acc: 95.31%] [G loss: 2.606781]\n",
      "epoch:15 step:12157 [D loss: 0.533655, acc: 77.34%] [G loss: 1.562833]\n",
      "epoch:15 step:12158 [D loss: 0.397914, acc: 92.19%] [G loss: 2.878741]\n",
      "epoch:15 step:12159 [D loss: 0.356696, acc: 96.88%] [G loss: 1.868591]\n",
      "epoch:15 step:12160 [D loss: 0.310088, acc: 94.53%] [G loss: 2.153403]\n",
      "epoch:15 step:12161 [D loss: 0.567023, acc: 64.06%] [G loss: 1.518730]\n",
      "epoch:15 step:12162 [D loss: 0.158432, acc: 100.00%] [G loss: 2.241646]\n",
      "epoch:15 step:12163 [D loss: 0.577942, acc: 61.72%] [G loss: 3.816819]\n",
      "epoch:15 step:12164 [D loss: 0.337277, acc: 95.31%] [G loss: 3.151588]\n",
      "epoch:15 step:12165 [D loss: 0.558951, acc: 68.75%] [G loss: 2.766920]\n",
      "epoch:15 step:12166 [D loss: 0.502282, acc: 83.59%] [G loss: 2.871125]\n",
      "epoch:15 step:12167 [D loss: 0.480933, acc: 61.72%] [G loss: 4.204438]\n",
      "epoch:15 step:12168 [D loss: 0.656264, acc: 60.94%] [G loss: 2.625874]\n",
      "epoch:15 step:12169 [D loss: 1.038630, acc: 50.00%] [G loss: 1.969952]\n",
      "epoch:15 step:12170 [D loss: 0.530663, acc: 80.47%] [G loss: 2.654727]\n",
      "epoch:15 step:12171 [D loss: 0.473525, acc: 64.84%] [G loss: 2.453904]\n",
      "epoch:15 step:12172 [D loss: 0.318905, acc: 91.41%] [G loss: 3.182619]\n",
      "epoch:15 step:12173 [D loss: 0.526316, acc: 60.94%] [G loss: 3.359024]\n",
      "epoch:15 step:12174 [D loss: 0.389159, acc: 82.03%] [G loss: 2.465619]\n",
      "epoch:15 step:12175 [D loss: 0.254236, acc: 95.31%] [G loss: 2.244197]\n",
      "epoch:15 step:12176 [D loss: 0.803152, acc: 36.72%] [G loss: 1.804807]\n",
      "epoch:15 step:12177 [D loss: 0.801908, acc: 40.62%] [G loss: 2.089127]\n",
      "epoch:15 step:12178 [D loss: 0.961197, acc: 32.03%] [G loss: 2.718944]\n",
      "epoch:15 step:12179 [D loss: 0.805080, acc: 47.66%] [G loss: 2.595574]\n",
      "epoch:15 step:12180 [D loss: 0.395784, acc: 75.00%] [G loss: 2.185305]\n",
      "epoch:15 step:12181 [D loss: 0.359030, acc: 92.97%] [G loss: 3.722394]\n",
      "epoch:15 step:12182 [D loss: 1.227082, acc: 12.50%] [G loss: 1.715367]\n",
      "epoch:15 step:12183 [D loss: 0.310656, acc: 95.31%] [G loss: 2.554953]\n",
      "epoch:15 step:12184 [D loss: 0.739988, acc: 51.56%] [G loss: 2.224871]\n",
      "epoch:15 step:12185 [D loss: 0.893143, acc: 49.22%] [G loss: 2.891024]\n",
      "epoch:15 step:12186 [D loss: 0.618492, acc: 68.75%] [G loss: 2.299344]\n",
      "epoch:15 step:12187 [D loss: 0.577718, acc: 73.44%] [G loss: 1.928072]\n",
      "epoch:15 step:12188 [D loss: 0.457996, acc: 64.84%] [G loss: 2.993693]\n",
      "epoch:15 step:12189 [D loss: 0.457899, acc: 69.53%] [G loss: 2.214998]\n",
      "epoch:15 step:12190 [D loss: 0.548004, acc: 64.84%] [G loss: 2.016489]\n",
      "epoch:15 step:12191 [D loss: 0.193836, acc: 100.00%] [G loss: 3.116217]\n",
      "epoch:15 step:12192 [D loss: 0.276309, acc: 97.66%] [G loss: 2.799433]\n",
      "epoch:15 step:12193 [D loss: 0.409875, acc: 87.50%] [G loss: 2.917657]\n",
      "epoch:15 step:12194 [D loss: 1.150014, acc: 15.62%] [G loss: 2.511534]\n",
      "epoch:15 step:12195 [D loss: 0.858321, acc: 47.66%] [G loss: 1.363591]\n",
      "epoch:15 step:12196 [D loss: 0.734430, acc: 53.91%] [G loss: 2.514225]\n",
      "epoch:15 step:12197 [D loss: 1.332429, acc: 50.00%] [G loss: 2.225990]\n",
      "epoch:15 step:12198 [D loss: 0.576950, acc: 66.41%] [G loss: 2.216859]\n",
      "epoch:15 step:12199 [D loss: 0.468695, acc: 80.47%] [G loss: 2.720421]\n",
      "epoch:15 step:12200 [D loss: 0.763534, acc: 51.56%] [G loss: 2.168089]\n",
      "##############\n",
      "[0.85209174 0.86553082 0.83283844 0.81660303 0.82628572 0.84134248\n",
      " 0.8842086  0.83438596 0.84190594 0.82737684]\n",
      "##########\n",
      "epoch:15 step:12201 [D loss: 0.614159, acc: 67.19%] [G loss: 2.078234]\n",
      "epoch:15 step:12202 [D loss: 0.617608, acc: 59.38%] [G loss: 2.628471]\n",
      "epoch:15 step:12203 [D loss: 0.340926, acc: 91.41%] [G loss: 3.002532]\n",
      "epoch:15 step:12204 [D loss: 0.759270, acc: 46.88%] [G loss: 2.594576]\n",
      "epoch:15 step:12205 [D loss: 0.553286, acc: 76.56%] [G loss: 1.876377]\n",
      "epoch:15 step:12206 [D loss: 1.368249, acc: 15.62%] [G loss: 1.835650]\n",
      "epoch:15 step:12207 [D loss: 0.590807, acc: 71.88%] [G loss: 3.981356]\n",
      "epoch:15 step:12208 [D loss: 0.181976, acc: 100.00%] [G loss: 3.461181]\n",
      "epoch:15 step:12209 [D loss: 0.468364, acc: 82.81%] [G loss: 2.084666]\n",
      "epoch:15 step:12210 [D loss: 0.507515, acc: 79.69%] [G loss: 2.961654]\n",
      "epoch:15 step:12211 [D loss: 0.527921, acc: 82.03%] [G loss: 2.445882]\n",
      "epoch:15 step:12212 [D loss: 0.500727, acc: 81.25%] [G loss: 2.611722]\n",
      "epoch:15 step:12213 [D loss: 0.397685, acc: 90.62%] [G loss: 2.363123]\n",
      "epoch:15 step:12214 [D loss: 0.808697, acc: 45.31%] [G loss: 1.858842]\n",
      "epoch:15 step:12215 [D loss: 0.507906, acc: 75.00%] [G loss: 2.864835]\n",
      "epoch:15 step:12216 [D loss: 0.786959, acc: 49.22%] [G loss: 2.668823]\n",
      "epoch:15 step:12217 [D loss: 0.484968, acc: 83.59%] [G loss: 2.079790]\n",
      "epoch:15 step:12218 [D loss: 0.820860, acc: 37.50%] [G loss: 2.020480]\n",
      "epoch:15 step:12219 [D loss: 0.516711, acc: 77.34%] [G loss: 2.641001]\n",
      "epoch:15 step:12220 [D loss: 0.887091, acc: 32.03%] [G loss: 1.879084]\n",
      "epoch:15 step:12221 [D loss: 0.522081, acc: 75.78%] [G loss: 2.007625]\n",
      "epoch:15 step:12222 [D loss: 0.653551, acc: 55.47%] [G loss: 2.700244]\n",
      "epoch:15 step:12223 [D loss: 0.982106, acc: 23.44%] [G loss: 1.372038]\n",
      "epoch:15 step:12224 [D loss: 0.265578, acc: 97.66%] [G loss: 3.595683]\n",
      "epoch:15 step:12225 [D loss: 0.308220, acc: 95.31%] [G loss: 2.446605]\n",
      "epoch:15 step:12226 [D loss: 0.333272, acc: 95.31%] [G loss: 2.626656]\n",
      "epoch:15 step:12227 [D loss: 0.677093, acc: 58.59%] [G loss: 2.383600]\n",
      "epoch:15 step:12228 [D loss: 0.789795, acc: 48.44%] [G loss: 2.712730]\n",
      "epoch:15 step:12229 [D loss: 0.848842, acc: 36.72%] [G loss: 1.528199]\n",
      "epoch:15 step:12230 [D loss: 0.957850, acc: 43.75%] [G loss: 1.890123]\n",
      "epoch:15 step:12231 [D loss: 0.725486, acc: 57.03%] [G loss: 1.847824]\n",
      "epoch:15 step:12232 [D loss: 0.460843, acc: 82.81%] [G loss: 2.355575]\n",
      "epoch:15 step:12233 [D loss: 0.486486, acc: 83.59%] [G loss: 1.780607]\n",
      "epoch:15 step:12234 [D loss: 0.818386, acc: 37.50%] [G loss: 1.579825]\n",
      "epoch:15 step:12235 [D loss: 0.812817, acc: 46.88%] [G loss: 2.634225]\n",
      "epoch:15 step:12236 [D loss: 0.639994, acc: 60.16%] [G loss: 2.563683]\n",
      "epoch:15 step:12237 [D loss: 0.981827, acc: 29.69%] [G loss: 1.824883]\n",
      "epoch:15 step:12238 [D loss: 0.881699, acc: 30.47%] [G loss: 2.107714]\n",
      "epoch:15 step:12239 [D loss: 0.689099, acc: 55.47%] [G loss: 2.661496]\n",
      "epoch:15 step:12240 [D loss: 0.865965, acc: 39.06%] [G loss: 2.449538]\n",
      "epoch:15 step:12241 [D loss: 0.687291, acc: 59.38%] [G loss: 2.190483]\n",
      "epoch:15 step:12242 [D loss: 0.646019, acc: 60.16%] [G loss: 2.456486]\n",
      "epoch:15 step:12243 [D loss: 0.468888, acc: 83.59%] [G loss: 2.079972]\n",
      "epoch:15 step:12244 [D loss: 0.384870, acc: 91.41%] [G loss: 2.345477]\n",
      "epoch:15 step:12245 [D loss: 0.484338, acc: 86.72%] [G loss: 2.007420]\n",
      "epoch:15 step:12246 [D loss: 0.868016, acc: 34.38%] [G loss: 1.799466]\n",
      "epoch:15 step:12247 [D loss: 0.879525, acc: 38.28%] [G loss: 1.982209]\n",
      "epoch:15 step:12248 [D loss: 0.599884, acc: 62.50%] [G loss: 2.130507]\n",
      "epoch:15 step:12249 [D loss: 0.548879, acc: 71.88%] [G loss: 2.420676]\n",
      "epoch:15 step:12250 [D loss: 0.595387, acc: 75.00%] [G loss: 1.736627]\n",
      "epoch:15 step:12251 [D loss: 0.304308, acc: 95.31%] [G loss: 2.062356]\n",
      "epoch:15 step:12252 [D loss: 0.350417, acc: 94.53%] [G loss: 3.385752]\n",
      "epoch:15 step:12253 [D loss: 0.411172, acc: 81.25%] [G loss: 1.973058]\n",
      "epoch:15 step:12254 [D loss: 0.825995, acc: 44.53%] [G loss: 1.991782]\n",
      "epoch:15 step:12255 [D loss: 0.546056, acc: 75.00%] [G loss: 2.796022]\n",
      "epoch:15 step:12256 [D loss: 0.417312, acc: 91.41%] [G loss: 2.317456]\n",
      "epoch:15 step:12257 [D loss: 0.591447, acc: 68.75%] [G loss: 2.266471]\n",
      "epoch:15 step:12258 [D loss: 0.514536, acc: 67.19%] [G loss: 2.254394]\n",
      "epoch:15 step:12259 [D loss: 1.055936, acc: 21.88%] [G loss: 1.916393]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:15 step:12260 [D loss: 0.327394, acc: 96.09%] [G loss: 1.867684]\n",
      "epoch:15 step:12261 [D loss: 0.572461, acc: 67.97%] [G loss: 1.906080]\n",
      "epoch:15 step:12262 [D loss: 0.771436, acc: 53.91%] [G loss: 2.671403]\n",
      "epoch:15 step:12263 [D loss: 1.020597, acc: 12.50%] [G loss: 1.688280]\n",
      "epoch:15 step:12264 [D loss: 0.579075, acc: 74.22%] [G loss: 2.338254]\n",
      "epoch:15 step:12265 [D loss: 0.540692, acc: 72.66%] [G loss: 2.238919]\n",
      "epoch:15 step:12266 [D loss: 0.409497, acc: 87.50%] [G loss: 2.621515]\n",
      "epoch:15 step:12267 [D loss: 0.792260, acc: 42.19%] [G loss: 2.104871]\n",
      "epoch:15 step:12268 [D loss: 0.550902, acc: 74.22%] [G loss: 2.482861]\n",
      "epoch:15 step:12269 [D loss: 0.840782, acc: 48.44%] [G loss: 2.353621]\n",
      "epoch:15 step:12270 [D loss: 0.737686, acc: 54.69%] [G loss: 2.417211]\n",
      "epoch:15 step:12271 [D loss: 0.517197, acc: 63.28%] [G loss: 2.489515]\n",
      "epoch:15 step:12272 [D loss: 0.692072, acc: 58.59%] [G loss: 1.814725]\n",
      "epoch:15 step:12273 [D loss: 0.598225, acc: 64.06%] [G loss: 2.075782]\n",
      "epoch:15 step:12274 [D loss: 0.729995, acc: 53.12%] [G loss: 1.941696]\n",
      "epoch:15 step:12275 [D loss: 0.771594, acc: 49.22%] [G loss: 2.048945]\n",
      "epoch:15 step:12276 [D loss: 0.414685, acc: 92.97%] [G loss: 2.541570]\n",
      "epoch:15 step:12277 [D loss: 0.603455, acc: 65.62%] [G loss: 2.228698]\n",
      "epoch:15 step:12278 [D loss: 1.045594, acc: 28.91%] [G loss: 1.824675]\n",
      "epoch:15 step:12279 [D loss: 0.454271, acc: 89.06%] [G loss: 1.984380]\n",
      "epoch:15 step:12280 [D loss: 0.519599, acc: 80.47%] [G loss: 2.533201]\n",
      "epoch:15 step:12281 [D loss: 0.566121, acc: 69.53%] [G loss: 2.369241]\n",
      "epoch:15 step:12282 [D loss: 0.623270, acc: 67.19%] [G loss: 2.459208]\n",
      "epoch:15 step:12283 [D loss: 0.421073, acc: 92.19%] [G loss: 2.269365]\n",
      "epoch:15 step:12284 [D loss: 0.555809, acc: 74.22%] [G loss: 2.622119]\n",
      "epoch:15 step:12285 [D loss: 0.467947, acc: 84.38%] [G loss: 2.218423]\n",
      "epoch:15 step:12286 [D loss: 0.918488, acc: 27.34%] [G loss: 1.910258]\n",
      "epoch:15 step:12287 [D loss: 0.353927, acc: 94.53%] [G loss: 2.684327]\n",
      "epoch:15 step:12288 [D loss: 0.621634, acc: 60.16%] [G loss: 2.299959]\n",
      "epoch:15 step:12289 [D loss: 0.402467, acc: 85.16%] [G loss: 2.711482]\n",
      "epoch:15 step:12290 [D loss: 0.738624, acc: 53.12%] [G loss: 1.738134]\n",
      "epoch:15 step:12291 [D loss: 0.454955, acc: 82.81%] [G loss: 2.317449]\n",
      "epoch:15 step:12292 [D loss: 0.608921, acc: 65.62%] [G loss: 1.996434]\n",
      "epoch:15 step:12293 [D loss: 0.707102, acc: 53.91%] [G loss: 2.178312]\n",
      "epoch:15 step:12294 [D loss: 0.429495, acc: 91.41%] [G loss: 1.983354]\n",
      "epoch:15 step:12295 [D loss: 0.512014, acc: 82.81%] [G loss: 1.859317]\n",
      "epoch:15 step:12296 [D loss: 0.478500, acc: 83.59%] [G loss: 2.603338]\n",
      "epoch:15 step:12297 [D loss: 0.908500, acc: 30.47%] [G loss: 1.927538]\n",
      "epoch:15 step:12298 [D loss: 0.724093, acc: 51.56%] [G loss: 2.060803]\n",
      "epoch:15 step:12299 [D loss: 0.622348, acc: 66.41%] [G loss: 2.302812]\n",
      "epoch:15 step:12300 [D loss: 0.306611, acc: 97.66%] [G loss: 3.116435]\n",
      "epoch:15 step:12301 [D loss: 0.555161, acc: 71.88%] [G loss: 2.822501]\n",
      "epoch:15 step:12302 [D loss: 0.434897, acc: 85.94%] [G loss: 2.533282]\n",
      "epoch:15 step:12303 [D loss: 0.285295, acc: 95.31%] [G loss: 2.103180]\n",
      "epoch:15 step:12304 [D loss: 0.726641, acc: 54.69%] [G loss: 2.136938]\n",
      "epoch:15 step:12305 [D loss: 0.328831, acc: 95.31%] [G loss: 2.489756]\n",
      "epoch:15 step:12306 [D loss: 0.774322, acc: 45.31%] [G loss: 2.458138]\n",
      "epoch:15 step:12307 [D loss: 0.649185, acc: 59.38%] [G loss: 3.358155]\n",
      "epoch:15 step:12308 [D loss: 0.800801, acc: 42.97%] [G loss: 1.762248]\n",
      "epoch:15 step:12309 [D loss: 0.863573, acc: 49.22%] [G loss: 2.521000]\n",
      "epoch:15 step:12310 [D loss: 0.262680, acc: 96.88%] [G loss: 2.408824]\n",
      "epoch:15 step:12311 [D loss: 0.848845, acc: 48.44%] [G loss: 2.230180]\n",
      "epoch:15 step:12312 [D loss: 0.816146, acc: 48.44%] [G loss: 2.580401]\n",
      "epoch:15 step:12313 [D loss: 0.573589, acc: 63.28%] [G loss: 1.845236]\n",
      "epoch:15 step:12314 [D loss: 0.640703, acc: 62.50%] [G loss: 1.869192]\n",
      "epoch:15 step:12315 [D loss: 0.677053, acc: 57.81%] [G loss: 2.092855]\n",
      "epoch:15 step:12316 [D loss: 0.917947, acc: 39.06%] [G loss: 1.773625]\n",
      "epoch:15 step:12317 [D loss: 0.398878, acc: 85.16%] [G loss: 2.618237]\n",
      "epoch:15 step:12318 [D loss: 0.801909, acc: 42.97%] [G loss: 2.661705]\n",
      "epoch:15 step:12319 [D loss: 0.998959, acc: 32.81%] [G loss: 1.477781]\n",
      "epoch:15 step:12320 [D loss: 0.383553, acc: 96.09%] [G loss: 2.349655]\n",
      "epoch:15 step:12321 [D loss: 0.509804, acc: 73.44%] [G loss: 2.552718]\n",
      "epoch:15 step:12322 [D loss: 0.873937, acc: 36.72%] [G loss: 2.140136]\n",
      "epoch:15 step:12323 [D loss: 0.622477, acc: 61.72%] [G loss: 2.155967]\n",
      "epoch:15 step:12324 [D loss: 0.425062, acc: 92.19%] [G loss: 2.084258]\n",
      "epoch:15 step:12325 [D loss: 0.720584, acc: 53.12%] [G loss: 1.812509]\n",
      "epoch:15 step:12326 [D loss: 0.726200, acc: 49.22%] [G loss: 2.010169]\n",
      "epoch:15 step:12327 [D loss: 0.516845, acc: 82.81%] [G loss: 2.514377]\n",
      "epoch:15 step:12328 [D loss: 0.621870, acc: 64.06%] [G loss: 2.140379]\n",
      "epoch:15 step:12329 [D loss: 0.667224, acc: 59.38%] [G loss: 2.318272]\n",
      "epoch:15 step:12330 [D loss: 0.450210, acc: 78.12%] [G loss: 2.829354]\n",
      "epoch:15 step:12331 [D loss: 0.538760, acc: 78.12%] [G loss: 2.255157]\n",
      "epoch:15 step:12332 [D loss: 0.707301, acc: 52.34%] [G loss: 3.540914]\n",
      "epoch:15 step:12333 [D loss: 0.925501, acc: 49.22%] [G loss: 2.343542]\n",
      "epoch:15 step:12334 [D loss: 0.681654, acc: 60.94%] [G loss: 1.578538]\n",
      "epoch:15 step:12335 [D loss: 0.517601, acc: 77.34%] [G loss: 2.631338]\n",
      "epoch:15 step:12336 [D loss: 0.530711, acc: 78.12%] [G loss: 2.447365]\n",
      "epoch:15 step:12337 [D loss: 0.418805, acc: 90.62%] [G loss: 1.969039]\n",
      "epoch:15 step:12338 [D loss: 0.557732, acc: 69.53%] [G loss: 2.062284]\n",
      "epoch:15 step:12339 [D loss: 0.657655, acc: 64.84%] [G loss: 2.144527]\n",
      "epoch:15 step:12340 [D loss: 0.593089, acc: 71.09%] [G loss: 2.385302]\n",
      "epoch:15 step:12341 [D loss: 0.787007, acc: 45.31%] [G loss: 2.066689]\n",
      "epoch:15 step:12342 [D loss: 0.741412, acc: 53.12%] [G loss: 1.634043]\n",
      "epoch:15 step:12343 [D loss: 0.452064, acc: 85.16%] [G loss: 3.657200]\n",
      "epoch:15 step:12344 [D loss: 0.637446, acc: 61.72%] [G loss: 2.202825]\n",
      "epoch:15 step:12345 [D loss: 0.408058, acc: 91.41%] [G loss: 2.409374]\n",
      "epoch:15 step:12346 [D loss: 0.519862, acc: 73.44%] [G loss: 2.236403]\n",
      "epoch:15 step:12347 [D loss: 0.717803, acc: 57.81%] [G loss: 1.976341]\n",
      "epoch:15 step:12348 [D loss: 0.433264, acc: 89.06%] [G loss: 2.447744]\n",
      "epoch:15 step:12349 [D loss: 0.443914, acc: 73.44%] [G loss: 1.922730]\n",
      "epoch:15 step:12350 [D loss: 0.354187, acc: 96.09%] [G loss: 2.247641]\n",
      "epoch:15 step:12351 [D loss: 0.558973, acc: 67.97%] [G loss: 2.339516]\n",
      "epoch:15 step:12352 [D loss: 0.859448, acc: 50.78%] [G loss: 2.400089]\n",
      "epoch:15 step:12353 [D loss: 0.488642, acc: 82.81%] [G loss: 3.055921]\n",
      "epoch:15 step:12354 [D loss: 0.470131, acc: 67.97%] [G loss: 3.224348]\n",
      "epoch:15 step:12355 [D loss: 0.734526, acc: 50.00%] [G loss: 2.090546]\n",
      "epoch:15 step:12356 [D loss: 0.644840, acc: 65.62%] [G loss: 2.837949]\n",
      "epoch:15 step:12357 [D loss: 0.513671, acc: 82.03%] [G loss: 1.831854]\n",
      "epoch:15 step:12358 [D loss: 0.472508, acc: 81.25%] [G loss: 2.026672]\n",
      "epoch:15 step:12359 [D loss: 0.460184, acc: 85.94%] [G loss: 2.474207]\n",
      "epoch:15 step:12360 [D loss: 0.656185, acc: 53.12%] [G loss: 2.394123]\n",
      "epoch:15 step:12361 [D loss: 0.883889, acc: 39.06%] [G loss: 2.202293]\n",
      "epoch:15 step:12362 [D loss: 0.647610, acc: 60.94%] [G loss: 2.313523]\n",
      "epoch:15 step:12363 [D loss: 0.550328, acc: 67.97%] [G loss: 2.829309]\n",
      "epoch:15 step:12364 [D loss: 0.663170, acc: 56.25%] [G loss: 1.705298]\n",
      "epoch:15 step:12365 [D loss: 0.471743, acc: 87.50%] [G loss: 2.301774]\n",
      "epoch:15 step:12366 [D loss: 0.618182, acc: 57.03%] [G loss: 2.009287]\n",
      "epoch:15 step:12367 [D loss: 0.523538, acc: 73.44%] [G loss: 2.755512]\n",
      "epoch:15 step:12368 [D loss: 0.287150, acc: 96.88%] [G loss: 2.412350]\n",
      "epoch:15 step:12369 [D loss: 0.417503, acc: 83.59%] [G loss: 2.179694]\n",
      "epoch:15 step:12370 [D loss: 0.373006, acc: 89.84%] [G loss: 2.950753]\n",
      "epoch:15 step:12371 [D loss: 1.148631, acc: 14.06%] [G loss: 1.669345]\n",
      "epoch:15 step:12372 [D loss: 0.602877, acc: 62.50%] [G loss: 2.487362]\n",
      "epoch:15 step:12373 [D loss: 0.780099, acc: 44.53%] [G loss: 2.223119]\n",
      "epoch:15 step:12374 [D loss: 0.361009, acc: 92.97%] [G loss: 2.376522]\n",
      "epoch:15 step:12375 [D loss: 0.628276, acc: 62.50%] [G loss: 2.807773]\n",
      "epoch:15 step:12376 [D loss: 0.492310, acc: 82.03%] [G loss: 2.810197]\n",
      "epoch:15 step:12377 [D loss: 0.424592, acc: 88.28%] [G loss: 2.456019]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:15 step:12378 [D loss: 0.575719, acc: 74.22%] [G loss: 2.837203]\n",
      "epoch:15 step:12379 [D loss: 0.345990, acc: 95.31%] [G loss: 2.277926]\n",
      "epoch:15 step:12380 [D loss: 0.767597, acc: 54.69%] [G loss: 1.985557]\n",
      "epoch:15 step:12381 [D loss: 0.227986, acc: 100.00%] [G loss: 2.281472]\n",
      "epoch:15 step:12382 [D loss: 0.529556, acc: 78.12%] [G loss: 2.030721]\n",
      "epoch:15 step:12383 [D loss: 0.480214, acc: 66.41%] [G loss: 2.837969]\n",
      "epoch:15 step:12384 [D loss: 0.665479, acc: 58.59%] [G loss: 2.441208]\n",
      "epoch:15 step:12385 [D loss: 0.268175, acc: 97.66%] [G loss: 2.546917]\n",
      "epoch:15 step:12386 [D loss: 0.512464, acc: 80.47%] [G loss: 1.921070]\n",
      "epoch:15 step:12387 [D loss: 0.912074, acc: 44.53%] [G loss: 2.209305]\n",
      "epoch:15 step:12388 [D loss: 0.448432, acc: 85.16%] [G loss: 3.113157]\n",
      "epoch:15 step:12389 [D loss: 0.360844, acc: 90.62%] [G loss: 2.496024]\n",
      "epoch:15 step:12390 [D loss: 0.488318, acc: 78.12%] [G loss: 1.743211]\n",
      "epoch:15 step:12391 [D loss: 0.892223, acc: 32.81%] [G loss: 2.590872]\n",
      "epoch:15 step:12392 [D loss: 0.156967, acc: 99.22%] [G loss: 3.509501]\n",
      "epoch:15 step:12393 [D loss: 0.456762, acc: 86.72%] [G loss: 2.442448]\n",
      "epoch:15 step:12394 [D loss: 0.593231, acc: 67.19%] [G loss: 2.412726]\n",
      "epoch:15 step:12395 [D loss: 0.456181, acc: 83.59%] [G loss: 2.400793]\n",
      "epoch:15 step:12396 [D loss: 0.488610, acc: 85.16%] [G loss: 2.061411]\n",
      "epoch:15 step:12397 [D loss: 0.574963, acc: 66.41%] [G loss: 2.874833]\n",
      "epoch:15 step:12398 [D loss: 1.138120, acc: 12.50%] [G loss: 2.254477]\n",
      "epoch:15 step:12399 [D loss: 0.896245, acc: 47.66%] [G loss: 1.831780]\n",
      "epoch:15 step:12400 [D loss: 0.918624, acc: 36.72%] [G loss: 1.950202]\n",
      "##############\n",
      "[0.87157173 0.8731174  0.80700556 0.80361193 0.80248568 0.83536284\n",
      " 0.91426687 0.81730066 0.81635786 0.81096858]\n",
      "##########\n",
      "epoch:15 step:12401 [D loss: 0.532452, acc: 63.28%] [G loss: 2.289591]\n",
      "epoch:15 step:12402 [D loss: 1.140099, acc: 22.66%] [G loss: 1.742916]\n",
      "epoch:15 step:12403 [D loss: 0.381912, acc: 88.28%] [G loss: 1.838637]\n",
      "epoch:15 step:12404 [D loss: 0.382861, acc: 91.41%] [G loss: 2.959146]\n",
      "epoch:15 step:12405 [D loss: 0.604627, acc: 63.28%] [G loss: 3.643345]\n",
      "epoch:15 step:12406 [D loss: 0.513353, acc: 70.31%] [G loss: 1.978954]\n",
      "epoch:15 step:12407 [D loss: 1.056511, acc: 20.31%] [G loss: 2.516769]\n",
      "epoch:15 step:12408 [D loss: 0.868228, acc: 52.34%] [G loss: 2.244033]\n",
      "epoch:15 step:12409 [D loss: 0.393060, acc: 91.41%] [G loss: 2.587731]\n",
      "epoch:15 step:12410 [D loss: 0.638094, acc: 60.94%] [G loss: 3.127638]\n",
      "epoch:15 step:12411 [D loss: 0.563856, acc: 82.03%] [G loss: 2.359922]\n",
      "epoch:15 step:12412 [D loss: 0.605688, acc: 59.38%] [G loss: 2.670272]\n",
      "epoch:15 step:12413 [D loss: 0.783443, acc: 57.03%] [G loss: 1.928797]\n",
      "epoch:15 step:12414 [D loss: 0.723927, acc: 59.38%] [G loss: 1.900919]\n",
      "epoch:15 step:12415 [D loss: 0.622561, acc: 66.41%] [G loss: 2.040960]\n",
      "epoch:15 step:12416 [D loss: 0.627255, acc: 68.75%] [G loss: 1.672897]\n",
      "epoch:15 step:12417 [D loss: 0.357670, acc: 89.84%] [G loss: 2.183776]\n",
      "epoch:15 step:12418 [D loss: 1.171288, acc: 29.69%] [G loss: 1.933780]\n",
      "epoch:15 step:12419 [D loss: 0.602970, acc: 67.97%] [G loss: 2.184191]\n",
      "epoch:15 step:12420 [D loss: 0.605299, acc: 64.06%] [G loss: 2.305218]\n",
      "epoch:15 step:12421 [D loss: 0.580040, acc: 69.53%] [G loss: 2.045299]\n",
      "epoch:15 step:12422 [D loss: 0.672425, acc: 57.81%] [G loss: 2.010890]\n",
      "epoch:15 step:12423 [D loss: 0.590254, acc: 73.44%] [G loss: 2.116044]\n",
      "epoch:15 step:12424 [D loss: 0.733729, acc: 50.00%] [G loss: 2.200005]\n",
      "epoch:15 step:12425 [D loss: 0.446238, acc: 79.69%] [G loss: 2.812407]\n",
      "epoch:15 step:12426 [D loss: 0.640659, acc: 56.25%] [G loss: 2.706419]\n",
      "epoch:15 step:12427 [D loss: 0.734117, acc: 53.12%] [G loss: 1.578088]\n",
      "epoch:15 step:12428 [D loss: 0.638595, acc: 64.06%] [G loss: 2.348692]\n",
      "epoch:15 step:12429 [D loss: 0.668780, acc: 60.16%] [G loss: 2.115225]\n",
      "epoch:15 step:12430 [D loss: 0.399501, acc: 92.97%] [G loss: 2.149951]\n",
      "epoch:15 step:12431 [D loss: 0.648274, acc: 61.72%] [G loss: 2.216398]\n",
      "epoch:15 step:12432 [D loss: 0.299974, acc: 87.50%] [G loss: 4.093532]\n",
      "epoch:15 step:12433 [D loss: 0.596226, acc: 62.50%] [G loss: 3.052779]\n",
      "epoch:15 step:12434 [D loss: 0.510847, acc: 79.69%] [G loss: 2.938437]\n",
      "epoch:15 step:12435 [D loss: 1.051048, acc: 46.88%] [G loss: 1.618742]\n",
      "epoch:15 step:12436 [D loss: 0.631413, acc: 57.81%] [G loss: 2.240760]\n",
      "epoch:15 step:12437 [D loss: 0.586896, acc: 63.28%] [G loss: 2.380491]\n",
      "epoch:15 step:12438 [D loss: 0.803240, acc: 42.97%] [G loss: 2.094503]\n",
      "epoch:15 step:12439 [D loss: 0.621867, acc: 60.16%] [G loss: 2.061320]\n",
      "epoch:15 step:12440 [D loss: 0.223469, acc: 99.22%] [G loss: 2.499155]\n",
      "epoch:15 step:12441 [D loss: 0.542265, acc: 75.78%] [G loss: 2.341655]\n",
      "epoch:15 step:12442 [D loss: 0.359991, acc: 94.53%] [G loss: 2.351989]\n",
      "epoch:15 step:12443 [D loss: 0.565926, acc: 64.84%] [G loss: 3.002369]\n",
      "epoch:15 step:12444 [D loss: 0.682123, acc: 59.38%] [G loss: 2.604128]\n",
      "epoch:15 step:12445 [D loss: 0.638279, acc: 60.16%] [G loss: 2.134951]\n",
      "epoch:15 step:12446 [D loss: 0.420747, acc: 80.47%] [G loss: 2.142946]\n",
      "epoch:15 step:12447 [D loss: 0.626284, acc: 60.16%] [G loss: 1.924405]\n",
      "epoch:15 step:12448 [D loss: 0.505787, acc: 82.03%] [G loss: 1.782198]\n",
      "epoch:15 step:12449 [D loss: 0.661424, acc: 64.84%] [G loss: 2.335525]\n",
      "epoch:15 step:12450 [D loss: 0.265375, acc: 99.22%] [G loss: 2.292227]\n",
      "epoch:15 step:12451 [D loss: 0.507646, acc: 84.38%] [G loss: 2.589133]\n",
      "epoch:15 step:12452 [D loss: 0.679547, acc: 57.03%] [G loss: 2.700886]\n",
      "epoch:15 step:12453 [D loss: 0.463997, acc: 85.94%] [G loss: 2.731484]\n",
      "epoch:15 step:12454 [D loss: 0.418757, acc: 90.62%] [G loss: 2.004554]\n",
      "epoch:15 step:12455 [D loss: 0.273540, acc: 99.22%] [G loss: 2.063311]\n",
      "epoch:15 step:12456 [D loss: 0.148577, acc: 100.00%] [G loss: 3.256863]\n",
      "epoch:15 step:12457 [D loss: 0.651680, acc: 59.38%] [G loss: 2.372949]\n",
      "epoch:15 step:12458 [D loss: 0.295567, acc: 98.44%] [G loss: 2.540843]\n",
      "epoch:15 step:12459 [D loss: 0.396083, acc: 89.06%] [G loss: 2.399395]\n",
      "epoch:15 step:12460 [D loss: 0.454479, acc: 80.47%] [G loss: 2.443267]\n",
      "epoch:15 step:12461 [D loss: 0.904680, acc: 32.81%] [G loss: 1.550461]\n",
      "epoch:15 step:12462 [D loss: 0.650679, acc: 63.28%] [G loss: 2.652821]\n",
      "epoch:15 step:12463 [D loss: 0.690502, acc: 53.12%] [G loss: 2.451559]\n",
      "epoch:15 step:12464 [D loss: 0.449556, acc: 90.62%] [G loss: 2.495301]\n",
      "epoch:15 step:12465 [D loss: 0.610429, acc: 64.84%] [G loss: 2.557262]\n",
      "epoch:15 step:12466 [D loss: 0.788139, acc: 48.44%] [G loss: 2.383701]\n",
      "epoch:15 step:12467 [D loss: 0.537564, acc: 74.22%] [G loss: 2.237179]\n",
      "epoch:15 step:12468 [D loss: 0.581729, acc: 72.66%] [G loss: 2.149092]\n",
      "epoch:15 step:12469 [D loss: 0.643316, acc: 58.59%] [G loss: 2.326742]\n",
      "epoch:15 step:12470 [D loss: 0.514174, acc: 82.81%] [G loss: 2.099277]\n",
      "epoch:15 step:12471 [D loss: 0.503202, acc: 80.47%] [G loss: 2.200986]\n",
      "epoch:15 step:12472 [D loss: 0.613369, acc: 66.41%] [G loss: 2.442439]\n",
      "epoch:15 step:12473 [D loss: 0.695112, acc: 54.69%] [G loss: 1.968628]\n",
      "epoch:15 step:12474 [D loss: 0.689492, acc: 57.03%] [G loss: 2.420548]\n",
      "epoch:15 step:12475 [D loss: 0.735695, acc: 52.34%] [G loss: 1.995599]\n",
      "epoch:15 step:12476 [D loss: 0.763752, acc: 52.34%] [G loss: 2.782210]\n",
      "epoch:15 step:12477 [D loss: 0.579591, acc: 68.75%] [G loss: 2.501169]\n",
      "epoch:15 step:12478 [D loss: 0.510799, acc: 82.81%] [G loss: 2.503273]\n",
      "epoch:15 step:12479 [D loss: 0.887892, acc: 35.16%] [G loss: 1.629821]\n",
      "epoch:15 step:12480 [D loss: 0.591293, acc: 62.50%] [G loss: 3.008423]\n",
      "epoch:15 step:12481 [D loss: 0.255049, acc: 97.66%] [G loss: 3.126555]\n",
      "epoch:15 step:12482 [D loss: 0.286896, acc: 94.53%] [G loss: 3.509466]\n",
      "epoch:15 step:12483 [D loss: 0.427167, acc: 79.69%] [G loss: 2.659894]\n",
      "epoch:15 step:12484 [D loss: 0.621576, acc: 66.41%] [G loss: 2.314955]\n",
      "epoch:15 step:12485 [D loss: 0.550325, acc: 71.09%] [G loss: 2.636568]\n",
      "epoch:15 step:12486 [D loss: 0.906566, acc: 29.69%] [G loss: 1.970072]\n",
      "epoch:15 step:12487 [D loss: 0.368172, acc: 85.94%] [G loss: 2.523365]\n",
      "epoch:15 step:12488 [D loss: 0.367562, acc: 94.53%] [G loss: 3.117147]\n",
      "epoch:15 step:12489 [D loss: 0.561258, acc: 60.94%] [G loss: 2.270764]\n",
      "epoch:15 step:12490 [D loss: 0.807408, acc: 41.41%] [G loss: 1.867042]\n",
      "epoch:15 step:12491 [D loss: 0.693579, acc: 59.38%] [G loss: 1.996323]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:15 step:12492 [D loss: 0.944307, acc: 34.38%] [G loss: 2.268866]\n",
      "epoch:15 step:12493 [D loss: 0.809591, acc: 50.00%] [G loss: 2.109118]\n",
      "epoch:15 step:12494 [D loss: 0.460127, acc: 85.94%] [G loss: 3.545697]\n",
      "epoch:15 step:12495 [D loss: 0.622203, acc: 67.19%] [G loss: 2.291549]\n",
      "epoch:15 step:12496 [D loss: 0.560514, acc: 69.53%] [G loss: 2.271601]\n",
      "epoch:16 step:12497 [D loss: 0.543365, acc: 68.75%] [G loss: 2.824201]\n",
      "epoch:16 step:12498 [D loss: 0.359967, acc: 87.50%] [G loss: 2.455504]\n",
      "epoch:16 step:12499 [D loss: 0.616494, acc: 68.75%] [G loss: 2.972951]\n",
      "epoch:16 step:12500 [D loss: 0.671528, acc: 55.47%] [G loss: 2.265296]\n",
      "epoch:16 step:12501 [D loss: 0.578064, acc: 76.56%] [G loss: 3.402352]\n",
      "epoch:16 step:12502 [D loss: 0.537503, acc: 79.69%] [G loss: 2.770651]\n",
      "epoch:16 step:12503 [D loss: 0.305943, acc: 92.19%] [G loss: 4.321615]\n",
      "epoch:16 step:12504 [D loss: 0.406206, acc: 88.28%] [G loss: 1.698220]\n",
      "epoch:16 step:12505 [D loss: 0.553456, acc: 68.75%] [G loss: 3.294743]\n",
      "epoch:16 step:12506 [D loss: 1.102653, acc: 30.47%] [G loss: 1.998548]\n",
      "epoch:16 step:12507 [D loss: 0.387899, acc: 92.97%] [G loss: 2.095080]\n",
      "epoch:16 step:12508 [D loss: 0.309714, acc: 98.44%] [G loss: 3.111809]\n",
      "epoch:16 step:12509 [D loss: 0.381311, acc: 87.50%] [G loss: 2.657499]\n",
      "epoch:16 step:12510 [D loss: 0.492573, acc: 81.25%] [G loss: 2.207016]\n",
      "epoch:16 step:12511 [D loss: 1.084468, acc: 27.34%] [G loss: 1.850084]\n",
      "epoch:16 step:12512 [D loss: 0.692122, acc: 53.91%] [G loss: 2.512154]\n",
      "epoch:16 step:12513 [D loss: 0.490063, acc: 78.12%] [G loss: 2.564109]\n",
      "epoch:16 step:12514 [D loss: 0.475484, acc: 83.59%] [G loss: 2.309458]\n",
      "epoch:16 step:12515 [D loss: 0.913348, acc: 30.47%] [G loss: 2.435010]\n",
      "epoch:16 step:12516 [D loss: 0.344657, acc: 92.19%] [G loss: 2.769685]\n",
      "epoch:16 step:12517 [D loss: 0.236241, acc: 96.88%] [G loss: 2.874851]\n",
      "epoch:16 step:12518 [D loss: 0.940627, acc: 48.44%] [G loss: 1.786023]\n",
      "epoch:16 step:12519 [D loss: 0.471893, acc: 82.81%] [G loss: 2.464603]\n",
      "epoch:16 step:12520 [D loss: 0.514699, acc: 78.91%] [G loss: 2.383920]\n",
      "epoch:16 step:12521 [D loss: 0.398598, acc: 94.53%] [G loss: 2.878843]\n",
      "epoch:16 step:12522 [D loss: 0.734589, acc: 56.25%] [G loss: 2.379138]\n",
      "epoch:16 step:12523 [D loss: 0.559735, acc: 73.44%] [G loss: 3.929020]\n",
      "epoch:16 step:12524 [D loss: 0.635792, acc: 61.72%] [G loss: 2.058656]\n",
      "epoch:16 step:12525 [D loss: 0.388766, acc: 92.97%] [G loss: 2.879421]\n",
      "epoch:16 step:12526 [D loss: 0.649867, acc: 64.84%] [G loss: 1.894614]\n",
      "epoch:16 step:12527 [D loss: 0.549270, acc: 75.78%] [G loss: 2.567187]\n",
      "epoch:16 step:12528 [D loss: 0.345795, acc: 96.09%] [G loss: 2.659970]\n",
      "epoch:16 step:12529 [D loss: 0.387643, acc: 89.84%] [G loss: 2.899412]\n",
      "epoch:16 step:12530 [D loss: 0.365383, acc: 89.84%] [G loss: 3.493390]\n",
      "epoch:16 step:12531 [D loss: 0.397379, acc: 89.84%] [G loss: 2.697577]\n",
      "epoch:16 step:12532 [D loss: 0.281621, acc: 96.88%] [G loss: 3.130932]\n",
      "epoch:16 step:12533 [D loss: 0.619298, acc: 60.94%] [G loss: 2.327531]\n",
      "epoch:16 step:12534 [D loss: 0.467443, acc: 86.72%] [G loss: 2.052479]\n",
      "epoch:16 step:12535 [D loss: 0.150340, acc: 98.44%] [G loss: 3.047190]\n",
      "epoch:16 step:12536 [D loss: 0.958937, acc: 47.66%] [G loss: 2.175966]\n",
      "epoch:16 step:12537 [D loss: 0.392991, acc: 90.62%] [G loss: 2.263709]\n",
      "epoch:16 step:12538 [D loss: 0.970322, acc: 33.59%] [G loss: 2.505211]\n",
      "epoch:16 step:12539 [D loss: 0.727691, acc: 52.34%] [G loss: 2.364511]\n",
      "epoch:16 step:12540 [D loss: 0.835293, acc: 50.78%] [G loss: 2.170230]\n",
      "epoch:16 step:12541 [D loss: 0.393660, acc: 92.19%] [G loss: 2.130742]\n",
      "epoch:16 step:12542 [D loss: 0.475955, acc: 71.88%] [G loss: 2.880261]\n",
      "epoch:16 step:12543 [D loss: 0.376355, acc: 85.16%] [G loss: 2.481891]\n",
      "epoch:16 step:12544 [D loss: 0.596086, acc: 69.53%] [G loss: 1.703946]\n",
      "epoch:16 step:12545 [D loss: 0.472472, acc: 83.59%] [G loss: 2.286081]\n",
      "epoch:16 step:12546 [D loss: 0.352052, acc: 92.97%] [G loss: 1.836221]\n",
      "epoch:16 step:12547 [D loss: 0.764671, acc: 49.22%] [G loss: 2.786324]\n",
      "epoch:16 step:12548 [D loss: 0.412178, acc: 88.28%] [G loss: 2.092523]\n",
      "epoch:16 step:12549 [D loss: 0.656673, acc: 59.38%] [G loss: 2.553018]\n",
      "epoch:16 step:12550 [D loss: 0.956755, acc: 25.78%] [G loss: 1.911521]\n",
      "epoch:16 step:12551 [D loss: 0.675138, acc: 53.12%] [G loss: 2.275881]\n",
      "epoch:16 step:12552 [D loss: 0.586174, acc: 63.28%] [G loss: 2.382535]\n",
      "epoch:16 step:12553 [D loss: 0.503206, acc: 79.69%] [G loss: 2.923470]\n",
      "epoch:16 step:12554 [D loss: 0.786010, acc: 39.84%] [G loss: 1.943475]\n",
      "epoch:16 step:12555 [D loss: 0.552067, acc: 70.31%] [G loss: 2.856064]\n",
      "epoch:16 step:12556 [D loss: 0.228911, acc: 96.09%] [G loss: 3.992273]\n",
      "epoch:16 step:12557 [D loss: 0.334003, acc: 89.06%] [G loss: 1.909695]\n",
      "epoch:16 step:12558 [D loss: 1.106811, acc: 47.66%] [G loss: 2.142715]\n",
      "epoch:16 step:12559 [D loss: 0.994926, acc: 19.53%] [G loss: 1.691086]\n",
      "epoch:16 step:12560 [D loss: 0.220981, acc: 97.66%] [G loss: 3.841905]\n",
      "epoch:16 step:12561 [D loss: 0.308336, acc: 83.59%] [G loss: 3.540933]\n",
      "epoch:16 step:12562 [D loss: 0.579202, acc: 71.88%] [G loss: 2.246264]\n",
      "epoch:16 step:12563 [D loss: 0.468493, acc: 85.16%] [G loss: 2.284207]\n",
      "epoch:16 step:12564 [D loss: 0.920244, acc: 50.78%] [G loss: 2.069843]\n",
      "epoch:16 step:12565 [D loss: 0.554595, acc: 69.53%] [G loss: 3.084412]\n",
      "epoch:16 step:12566 [D loss: 0.592764, acc: 53.12%] [G loss: 1.804929]\n",
      "epoch:16 step:12567 [D loss: 1.179369, acc: 11.72%] [G loss: 1.994989]\n",
      "epoch:16 step:12568 [D loss: 0.813198, acc: 45.31%] [G loss: 2.460797]\n",
      "epoch:16 step:12569 [D loss: 0.536458, acc: 79.69%] [G loss: 2.940975]\n",
      "epoch:16 step:12570 [D loss: 0.479096, acc: 72.66%] [G loss: 2.040871]\n",
      "epoch:16 step:12571 [D loss: 0.599103, acc: 67.97%] [G loss: 3.403144]\n",
      "epoch:16 step:12572 [D loss: 1.080700, acc: 17.97%] [G loss: 2.073488]\n",
      "epoch:16 step:12573 [D loss: 0.499386, acc: 77.34%] [G loss: 3.387776]\n",
      "epoch:16 step:12574 [D loss: 1.006609, acc: 26.56%] [G loss: 2.061169]\n",
      "epoch:16 step:12575 [D loss: 0.642750, acc: 60.94%] [G loss: 2.894452]\n",
      "epoch:16 step:12576 [D loss: 0.534552, acc: 77.34%] [G loss: 2.355227]\n",
      "epoch:16 step:12577 [D loss: 0.578944, acc: 74.22%] [G loss: 2.136631]\n",
      "epoch:16 step:12578 [D loss: 0.494207, acc: 87.50%] [G loss: 1.844317]\n",
      "epoch:16 step:12579 [D loss: 0.488322, acc: 85.94%] [G loss: 2.439285]\n",
      "epoch:16 step:12580 [D loss: 0.664367, acc: 60.94%] [G loss: 1.946923]\n",
      "epoch:16 step:12581 [D loss: 0.489092, acc: 87.50%] [G loss: 2.894351]\n",
      "epoch:16 step:12582 [D loss: 0.998276, acc: 23.44%] [G loss: 2.340501]\n",
      "epoch:16 step:12583 [D loss: 0.332843, acc: 92.97%] [G loss: 2.776143]\n",
      "epoch:16 step:12584 [D loss: 0.783192, acc: 45.31%] [G loss: 2.211846]\n",
      "epoch:16 step:12585 [D loss: 0.279352, acc: 97.66%] [G loss: 2.373720]\n",
      "epoch:16 step:12586 [D loss: 0.738584, acc: 50.78%] [G loss: 1.455826]\n",
      "epoch:16 step:12587 [D loss: 0.163922, acc: 99.22%] [G loss: 3.129675]\n",
      "epoch:16 step:12588 [D loss: 0.623748, acc: 59.38%] [G loss: 2.359064]\n",
      "epoch:16 step:12589 [D loss: 0.590115, acc: 68.75%] [G loss: 2.201289]\n",
      "epoch:16 step:12590 [D loss: 0.334189, acc: 87.50%] [G loss: 2.629218]\n",
      "epoch:16 step:12591 [D loss: 0.321994, acc: 85.16%] [G loss: 2.309656]\n",
      "epoch:16 step:12592 [D loss: 0.940129, acc: 42.19%] [G loss: 1.802397]\n",
      "epoch:16 step:12593 [D loss: 0.581830, acc: 71.88%] [G loss: 2.536385]\n",
      "epoch:16 step:12594 [D loss: 0.659295, acc: 51.56%] [G loss: 1.797828]\n",
      "epoch:16 step:12595 [D loss: 0.271761, acc: 98.44%] [G loss: 3.255441]\n",
      "epoch:16 step:12596 [D loss: 0.900754, acc: 46.09%] [G loss: 1.913512]\n",
      "epoch:16 step:12597 [D loss: 0.410592, acc: 87.50%] [G loss: 2.747023]\n",
      "epoch:16 step:12598 [D loss: 0.867232, acc: 47.66%] [G loss: 2.367031]\n",
      "epoch:16 step:12599 [D loss: 0.471688, acc: 81.25%] [G loss: 1.721037]\n",
      "epoch:16 step:12600 [D loss: 0.640810, acc: 67.19%] [G loss: 2.032444]\n",
      "##############\n",
      "[0.8674084  0.87535401 0.80503052 0.80203452 0.75730459 0.80915595\n",
      " 0.89462748 0.83666145 0.83413666 0.82219754]\n",
      "##########\n",
      "epoch:16 step:12601 [D loss: 0.265712, acc: 95.31%] [G loss: 2.966032]\n",
      "epoch:16 step:12602 [D loss: 0.349750, acc: 87.50%] [G loss: 2.938095]\n",
      "epoch:16 step:12603 [D loss: 0.962263, acc: 46.09%] [G loss: 2.039505]\n",
      "epoch:16 step:12604 [D loss: 1.298772, acc: 42.97%] [G loss: 1.979296]\n",
      "epoch:16 step:12605 [D loss: 0.314247, acc: 89.06%] [G loss: 3.010361]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:16 step:12606 [D loss: 0.573825, acc: 60.16%] [G loss: 3.141748]\n",
      "epoch:16 step:12607 [D loss: 0.689777, acc: 56.25%] [G loss: 3.134744]\n",
      "epoch:16 step:12608 [D loss: 0.414098, acc: 91.41%] [G loss: 3.265852]\n",
      "epoch:16 step:12609 [D loss: 0.407057, acc: 79.69%] [G loss: 4.143811]\n",
      "epoch:16 step:12610 [D loss: 0.447949, acc: 79.69%] [G loss: 2.557694]\n",
      "epoch:16 step:12611 [D loss: 0.580247, acc: 63.28%] [G loss: 2.572312]\n",
      "epoch:16 step:12612 [D loss: 0.604460, acc: 66.41%] [G loss: 2.602234]\n",
      "epoch:16 step:12613 [D loss: 0.631095, acc: 60.16%] [G loss: 1.974944]\n",
      "epoch:16 step:12614 [D loss: 0.346038, acc: 95.31%] [G loss: 2.384821]\n",
      "epoch:16 step:12615 [D loss: 0.472428, acc: 81.25%] [G loss: 2.238601]\n",
      "epoch:16 step:12616 [D loss: 0.652942, acc: 63.28%] [G loss: 2.383308]\n",
      "epoch:16 step:12617 [D loss: 0.481851, acc: 82.81%] [G loss: 2.151742]\n",
      "epoch:16 step:12618 [D loss: 0.519738, acc: 79.69%] [G loss: 1.900360]\n",
      "epoch:16 step:12619 [D loss: 0.411875, acc: 78.91%] [G loss: 2.797441]\n",
      "epoch:16 step:12620 [D loss: 0.471599, acc: 85.16%] [G loss: 2.768473]\n",
      "epoch:16 step:12621 [D loss: 0.402012, acc: 85.94%] [G loss: 2.316255]\n",
      "epoch:16 step:12622 [D loss: 1.244990, acc: 10.16%] [G loss: 1.904921]\n",
      "epoch:16 step:12623 [D loss: 0.371449, acc: 85.94%] [G loss: 3.148893]\n",
      "epoch:16 step:12624 [D loss: 0.426171, acc: 83.59%] [G loss: 2.424454]\n",
      "epoch:16 step:12625 [D loss: 0.323070, acc: 93.75%] [G loss: 2.310127]\n",
      "epoch:16 step:12626 [D loss: 1.591515, acc: 1.56%] [G loss: 1.691337]\n",
      "epoch:16 step:12627 [D loss: 0.799585, acc: 46.88%] [G loss: 2.386914]\n",
      "epoch:16 step:12628 [D loss: 0.588900, acc: 62.50%] [G loss: 2.209907]\n",
      "epoch:16 step:12629 [D loss: 0.500669, acc: 82.03%] [G loss: 2.348026]\n",
      "epoch:16 step:12630 [D loss: 0.516303, acc: 78.91%] [G loss: 3.045376]\n",
      "epoch:16 step:12631 [D loss: 0.652835, acc: 61.72%] [G loss: 2.776047]\n",
      "epoch:16 step:12632 [D loss: 0.725274, acc: 53.91%] [G loss: 2.431058]\n",
      "epoch:16 step:12633 [D loss: 0.832428, acc: 47.66%] [G loss: 2.392702]\n",
      "epoch:16 step:12634 [D loss: 0.702000, acc: 50.78%] [G loss: 2.692263]\n",
      "epoch:16 step:12635 [D loss: 0.677056, acc: 54.69%] [G loss: 1.963963]\n",
      "epoch:16 step:12636 [D loss: 0.589254, acc: 69.53%] [G loss: 2.644977]\n",
      "epoch:16 step:12637 [D loss: 1.187831, acc: 22.66%] [G loss: 2.571341]\n",
      "epoch:16 step:12638 [D loss: 0.776246, acc: 44.53%] [G loss: 1.696336]\n",
      "epoch:16 step:12639 [D loss: 0.456882, acc: 86.72%] [G loss: 2.572164]\n",
      "epoch:16 step:12640 [D loss: 0.693382, acc: 58.59%] [G loss: 1.979401]\n",
      "epoch:16 step:12641 [D loss: 0.274116, acc: 91.41%] [G loss: 2.379707]\n",
      "epoch:16 step:12642 [D loss: 0.405897, acc: 89.84%] [G loss: 2.761422]\n",
      "epoch:16 step:12643 [D loss: 0.449577, acc: 87.50%] [G loss: 1.911926]\n",
      "epoch:16 step:12644 [D loss: 0.582905, acc: 71.88%] [G loss: 2.687603]\n",
      "epoch:16 step:12645 [D loss: 0.366643, acc: 93.75%] [G loss: 2.549580]\n",
      "epoch:16 step:12646 [D loss: 0.622486, acc: 64.84%] [G loss: 1.951758]\n",
      "epoch:16 step:12647 [D loss: 0.512116, acc: 82.03%] [G loss: 2.178773]\n",
      "epoch:16 step:12648 [D loss: 0.423248, acc: 84.38%] [G loss: 2.441916]\n",
      "epoch:16 step:12649 [D loss: 0.581092, acc: 60.94%] [G loss: 3.024269]\n",
      "epoch:16 step:12650 [D loss: 0.459783, acc: 87.50%] [G loss: 2.920587]\n",
      "epoch:16 step:12651 [D loss: 0.601759, acc: 67.19%] [G loss: 2.103242]\n",
      "epoch:16 step:12652 [D loss: 0.280711, acc: 92.19%] [G loss: 3.458622]\n",
      "epoch:16 step:12653 [D loss: 0.591458, acc: 65.62%] [G loss: 1.974171]\n",
      "epoch:16 step:12654 [D loss: 0.309533, acc: 91.41%] [G loss: 2.347911]\n",
      "epoch:16 step:12655 [D loss: 0.431791, acc: 91.41%] [G loss: 3.641810]\n",
      "epoch:16 step:12656 [D loss: 0.756024, acc: 48.44%] [G loss: 2.016023]\n",
      "epoch:16 step:12657 [D loss: 0.316623, acc: 96.09%] [G loss: 1.948827]\n",
      "epoch:16 step:12658 [D loss: 0.576184, acc: 58.59%] [G loss: 2.173727]\n",
      "epoch:16 step:12659 [D loss: 0.627369, acc: 66.41%] [G loss: 2.834742]\n",
      "epoch:16 step:12660 [D loss: 0.511541, acc: 80.47%] [G loss: 2.163163]\n",
      "epoch:16 step:12661 [D loss: 0.700868, acc: 52.34%] [G loss: 1.913726]\n",
      "epoch:16 step:12662 [D loss: 0.659004, acc: 59.38%] [G loss: 2.131860]\n",
      "epoch:16 step:12663 [D loss: 0.647990, acc: 67.19%] [G loss: 2.410638]\n",
      "epoch:16 step:12664 [D loss: 0.491828, acc: 68.75%] [G loss: 2.427798]\n",
      "epoch:16 step:12665 [D loss: 0.505510, acc: 75.78%] [G loss: 2.326381]\n",
      "epoch:16 step:12666 [D loss: 0.591414, acc: 67.19%] [G loss: 1.929014]\n",
      "epoch:16 step:12667 [D loss: 0.532571, acc: 80.47%] [G loss: 1.915442]\n",
      "epoch:16 step:12668 [D loss: 0.764676, acc: 47.66%] [G loss: 2.405993]\n",
      "epoch:16 step:12669 [D loss: 0.548803, acc: 68.75%] [G loss: 2.216403]\n",
      "epoch:16 step:12670 [D loss: 0.199102, acc: 99.22%] [G loss: 2.927402]\n",
      "epoch:16 step:12671 [D loss: 1.095255, acc: 30.47%] [G loss: 2.843364]\n",
      "epoch:16 step:12672 [D loss: 0.450843, acc: 78.12%] [G loss: 2.383133]\n",
      "epoch:16 step:12673 [D loss: 0.274536, acc: 96.09%] [G loss: 2.626606]\n",
      "epoch:16 step:12674 [D loss: 0.542545, acc: 74.22%] [G loss: 2.085481]\n",
      "epoch:16 step:12675 [D loss: 0.317387, acc: 94.53%] [G loss: 2.778734]\n",
      "epoch:16 step:12676 [D loss: 0.646961, acc: 60.94%] [G loss: 2.590873]\n",
      "epoch:16 step:12677 [D loss: 0.571610, acc: 69.53%] [G loss: 2.535772]\n",
      "epoch:16 step:12678 [D loss: 0.825007, acc: 35.94%] [G loss: 1.884384]\n",
      "epoch:16 step:12679 [D loss: 0.454019, acc: 79.69%] [G loss: 2.875137]\n",
      "epoch:16 step:12680 [D loss: 0.495006, acc: 74.22%] [G loss: 1.777888]\n",
      "epoch:16 step:12681 [D loss: 0.786517, acc: 44.53%] [G loss: 2.886864]\n",
      "epoch:16 step:12682 [D loss: 0.364645, acc: 92.97%] [G loss: 2.705535]\n",
      "epoch:16 step:12683 [D loss: 0.428177, acc: 78.12%] [G loss: 2.381855]\n",
      "epoch:16 step:12684 [D loss: 0.593217, acc: 75.00%] [G loss: 2.171369]\n",
      "epoch:16 step:12685 [D loss: 0.431206, acc: 91.41%] [G loss: 2.317651]\n",
      "epoch:16 step:12686 [D loss: 0.629909, acc: 66.41%] [G loss: 1.901040]\n",
      "epoch:16 step:12687 [D loss: 0.440357, acc: 87.50%] [G loss: 3.054165]\n",
      "epoch:16 step:12688 [D loss: 0.596238, acc: 60.94%] [G loss: 2.261716]\n",
      "epoch:16 step:12689 [D loss: 0.381550, acc: 92.19%] [G loss: 2.553576]\n",
      "epoch:16 step:12690 [D loss: 0.265614, acc: 96.88%] [G loss: 3.152161]\n",
      "epoch:16 step:12691 [D loss: 0.871890, acc: 35.94%] [G loss: 2.630057]\n",
      "epoch:16 step:12692 [D loss: 0.833265, acc: 44.53%] [G loss: 1.338763]\n",
      "epoch:16 step:12693 [D loss: 0.411498, acc: 89.84%] [G loss: 2.243223]\n",
      "epoch:16 step:12694 [D loss: 0.609978, acc: 67.19%] [G loss: 2.328684]\n",
      "epoch:16 step:12695 [D loss: 0.401692, acc: 92.97%] [G loss: 2.553289]\n",
      "epoch:16 step:12696 [D loss: 0.681005, acc: 58.59%] [G loss: 2.117837]\n",
      "epoch:16 step:12697 [D loss: 0.389984, acc: 90.62%] [G loss: 3.050742]\n",
      "epoch:16 step:12698 [D loss: 0.389879, acc: 75.00%] [G loss: 3.065051]\n",
      "epoch:16 step:12699 [D loss: 0.346731, acc: 95.31%] [G loss: 2.547096]\n",
      "epoch:16 step:12700 [D loss: 0.553217, acc: 67.97%] [G loss: 1.929148]\n",
      "epoch:16 step:12701 [D loss: 0.816668, acc: 40.62%] [G loss: 2.096592]\n",
      "epoch:16 step:12702 [D loss: 0.526469, acc: 78.91%] [G loss: 1.869111]\n",
      "epoch:16 step:12703 [D loss: 1.099882, acc: 11.72%] [G loss: 1.837911]\n",
      "epoch:16 step:12704 [D loss: 0.355460, acc: 92.97%] [G loss: 2.180428]\n",
      "epoch:16 step:12705 [D loss: 0.597565, acc: 66.41%] [G loss: 1.972678]\n",
      "epoch:16 step:12706 [D loss: 0.500816, acc: 57.81%] [G loss: 2.693073]\n",
      "epoch:16 step:12707 [D loss: 0.556222, acc: 78.91%] [G loss: 1.887638]\n",
      "epoch:16 step:12708 [D loss: 0.777559, acc: 53.91%] [G loss: 2.016404]\n",
      "epoch:16 step:12709 [D loss: 0.901824, acc: 25.78%] [G loss: 1.395583]\n",
      "epoch:16 step:12710 [D loss: 0.627126, acc: 67.97%] [G loss: 2.796421]\n",
      "epoch:16 step:12711 [D loss: 0.566809, acc: 70.31%] [G loss: 2.392673]\n",
      "epoch:16 step:12712 [D loss: 0.363735, acc: 91.41%] [G loss: 2.120479]\n",
      "epoch:16 step:12713 [D loss: 0.564529, acc: 67.97%] [G loss: 1.992589]\n",
      "epoch:16 step:12714 [D loss: 0.442353, acc: 89.06%] [G loss: 2.613427]\n",
      "epoch:16 step:12715 [D loss: 0.283482, acc: 97.66%] [G loss: 2.272717]\n",
      "epoch:16 step:12716 [D loss: 0.669948, acc: 60.16%] [G loss: 2.300355]\n",
      "epoch:16 step:12717 [D loss: 0.924248, acc: 43.75%] [G loss: 1.772133]\n",
      "epoch:16 step:12718 [D loss: 0.583274, acc: 74.22%] [G loss: 1.657251]\n",
      "epoch:16 step:12719 [D loss: 0.597982, acc: 64.06%] [G loss: 1.761940]\n",
      "epoch:16 step:12720 [D loss: 0.568172, acc: 71.09%] [G loss: 1.994856]\n",
      "epoch:16 step:12721 [D loss: 0.675944, acc: 51.56%] [G loss: 2.822905]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:16 step:12722 [D loss: 0.489253, acc: 82.81%] [G loss: 1.952478]\n",
      "epoch:16 step:12723 [D loss: 0.488451, acc: 84.38%] [G loss: 1.941714]\n",
      "epoch:16 step:12724 [D loss: 0.520835, acc: 73.44%] [G loss: 2.449924]\n",
      "epoch:16 step:12725 [D loss: 0.601581, acc: 64.06%] [G loss: 2.164243]\n",
      "epoch:16 step:12726 [D loss: 0.664223, acc: 58.59%] [G loss: 1.972729]\n",
      "epoch:16 step:12727 [D loss: 0.339283, acc: 94.53%] [G loss: 4.007982]\n",
      "epoch:16 step:12728 [D loss: 0.669918, acc: 55.47%] [G loss: 2.142591]\n",
      "epoch:16 step:12729 [D loss: 0.592430, acc: 70.31%] [G loss: 2.425097]\n",
      "epoch:16 step:12730 [D loss: 0.521320, acc: 81.25%] [G loss: 2.274317]\n",
      "epoch:16 step:12731 [D loss: 0.568894, acc: 71.88%] [G loss: 2.089003]\n",
      "epoch:16 step:12732 [D loss: 1.155102, acc: 10.94%] [G loss: 1.880235]\n",
      "epoch:16 step:12733 [D loss: 0.705444, acc: 55.47%] [G loss: 2.397740]\n",
      "epoch:16 step:12734 [D loss: 0.872308, acc: 30.47%] [G loss: 1.988880]\n",
      "epoch:16 step:12735 [D loss: 0.706929, acc: 53.12%] [G loss: 1.966759]\n",
      "epoch:16 step:12736 [D loss: 0.813707, acc: 40.62%] [G loss: 1.649563]\n",
      "epoch:16 step:12737 [D loss: 0.464733, acc: 87.50%] [G loss: 2.647040]\n",
      "epoch:16 step:12738 [D loss: 0.428177, acc: 86.72%] [G loss: 2.236445]\n",
      "epoch:16 step:12739 [D loss: 0.774007, acc: 46.88%] [G loss: 2.804595]\n",
      "epoch:16 step:12740 [D loss: 0.289302, acc: 92.97%] [G loss: 2.031809]\n",
      "epoch:16 step:12741 [D loss: 0.888622, acc: 32.81%] [G loss: 1.310165]\n",
      "epoch:16 step:12742 [D loss: 0.711137, acc: 54.69%] [G loss: 2.199466]\n",
      "epoch:16 step:12743 [D loss: 0.487012, acc: 81.25%] [G loss: 1.946061]\n",
      "epoch:16 step:12744 [D loss: 0.252778, acc: 96.09%] [G loss: 2.191266]\n",
      "epoch:16 step:12745 [D loss: 0.358492, acc: 96.88%] [G loss: 3.616184]\n",
      "epoch:16 step:12746 [D loss: 0.515592, acc: 72.66%] [G loss: 2.712717]\n",
      "epoch:16 step:12747 [D loss: 0.517987, acc: 79.69%] [G loss: 2.971124]\n",
      "epoch:16 step:12748 [D loss: 0.303959, acc: 97.66%] [G loss: 1.818301]\n",
      "epoch:16 step:12749 [D loss: 0.816306, acc: 50.00%] [G loss: 2.055037]\n",
      "epoch:16 step:12750 [D loss: 0.894715, acc: 35.16%] [G loss: 1.947706]\n",
      "epoch:16 step:12751 [D loss: 0.634399, acc: 60.16%] [G loss: 1.980986]\n",
      "epoch:16 step:12752 [D loss: 0.178520, acc: 100.00%] [G loss: 2.903379]\n",
      "epoch:16 step:12753 [D loss: 1.102340, acc: 20.31%] [G loss: 2.353081]\n",
      "epoch:16 step:12754 [D loss: 0.444379, acc: 85.94%] [G loss: 3.104582]\n",
      "epoch:16 step:12755 [D loss: 0.410176, acc: 74.22%] [G loss: 3.287211]\n",
      "epoch:16 step:12756 [D loss: 0.557473, acc: 73.44%] [G loss: 2.619944]\n",
      "epoch:16 step:12757 [D loss: 0.295936, acc: 96.09%] [G loss: 2.577819]\n",
      "epoch:16 step:12758 [D loss: 0.304613, acc: 91.41%] [G loss: 2.475744]\n",
      "epoch:16 step:12759 [D loss: 0.851423, acc: 45.31%] [G loss: 2.226109]\n",
      "epoch:16 step:12760 [D loss: 0.514786, acc: 76.56%] [G loss: 3.428849]\n",
      "epoch:16 step:12761 [D loss: 0.175985, acc: 99.22%] [G loss: 2.766970]\n",
      "epoch:16 step:12762 [D loss: 0.354553, acc: 92.97%] [G loss: 2.495958]\n",
      "epoch:16 step:12763 [D loss: 1.038756, acc: 48.44%] [G loss: 2.100256]\n",
      "epoch:16 step:12764 [D loss: 0.328131, acc: 92.19%] [G loss: 2.712626]\n",
      "epoch:16 step:12765 [D loss: 0.902475, acc: 47.66%] [G loss: 1.942546]\n",
      "epoch:16 step:12766 [D loss: 0.607628, acc: 67.97%] [G loss: 2.066557]\n",
      "epoch:16 step:12767 [D loss: 0.254947, acc: 100.00%] [G loss: 3.618532]\n",
      "epoch:16 step:12768 [D loss: 0.359679, acc: 81.25%] [G loss: 2.788337]\n",
      "epoch:16 step:12769 [D loss: 0.177264, acc: 98.44%] [G loss: 2.884984]\n",
      "epoch:16 step:12770 [D loss: 0.734570, acc: 51.56%] [G loss: 2.864501]\n",
      "epoch:16 step:12771 [D loss: 0.349976, acc: 96.88%] [G loss: 2.918989]\n",
      "epoch:16 step:12772 [D loss: 0.604222, acc: 54.69%] [G loss: 1.749850]\n",
      "epoch:16 step:12773 [D loss: 0.468145, acc: 79.69%] [G loss: 2.757900]\n",
      "epoch:16 step:12774 [D loss: 0.757206, acc: 44.53%] [G loss: 2.188098]\n",
      "epoch:16 step:12775 [D loss: 0.622416, acc: 68.75%] [G loss: 2.453630]\n",
      "epoch:16 step:12776 [D loss: 0.625641, acc: 56.25%] [G loss: 2.157292]\n",
      "epoch:16 step:12777 [D loss: 0.694583, acc: 56.25%] [G loss: 2.499893]\n",
      "epoch:16 step:12778 [D loss: 0.864470, acc: 29.69%] [G loss: 2.611898]\n",
      "epoch:16 step:12779 [D loss: 0.445063, acc: 91.41%] [G loss: 2.684012]\n",
      "epoch:16 step:12780 [D loss: 0.815972, acc: 51.56%] [G loss: 2.439071]\n",
      "epoch:16 step:12781 [D loss: 0.648443, acc: 61.72%] [G loss: 2.176747]\n",
      "epoch:16 step:12782 [D loss: 0.560472, acc: 76.56%] [G loss: 1.727930]\n",
      "epoch:16 step:12783 [D loss: 0.617588, acc: 65.62%] [G loss: 2.316512]\n",
      "epoch:16 step:12784 [D loss: 0.941322, acc: 37.50%] [G loss: 1.915662]\n",
      "epoch:16 step:12785 [D loss: 0.536093, acc: 79.69%] [G loss: 1.380082]\n",
      "epoch:16 step:12786 [D loss: 0.649362, acc: 57.81%] [G loss: 2.624083]\n",
      "epoch:16 step:12787 [D loss: 0.943271, acc: 50.78%] [G loss: 2.074911]\n",
      "epoch:16 step:12788 [D loss: 0.552771, acc: 64.06%] [G loss: 3.651242]\n",
      "epoch:16 step:12789 [D loss: 0.218950, acc: 99.22%] [G loss: 3.314644]\n",
      "epoch:16 step:12790 [D loss: 0.620931, acc: 57.81%] [G loss: 2.210103]\n",
      "epoch:16 step:12791 [D loss: 0.309078, acc: 96.88%] [G loss: 2.554654]\n",
      "epoch:16 step:12792 [D loss: 0.464191, acc: 87.50%] [G loss: 2.782622]\n",
      "epoch:16 step:12793 [D loss: 0.832338, acc: 35.94%] [G loss: 1.633001]\n",
      "epoch:16 step:12794 [D loss: 0.677735, acc: 62.50%] [G loss: 2.148379]\n",
      "epoch:16 step:12795 [D loss: 0.481705, acc: 69.53%] [G loss: 2.562132]\n",
      "epoch:16 step:12796 [D loss: 0.638309, acc: 60.16%] [G loss: 1.727629]\n",
      "epoch:16 step:12797 [D loss: 0.665956, acc: 61.72%] [G loss: 1.914361]\n",
      "epoch:16 step:12798 [D loss: 0.594090, acc: 68.75%] [G loss: 2.328600]\n",
      "epoch:16 step:12799 [D loss: 0.752760, acc: 54.69%] [G loss: 2.103197]\n",
      "epoch:16 step:12800 [D loss: 0.242061, acc: 100.00%] [G loss: 2.777461]\n",
      "##############\n",
      "[0.84060129 0.87956766 0.81064514 0.81266146 0.80162806 0.81072221\n",
      " 0.88595812 0.8307844  0.81238035 0.84763831]\n",
      "##########\n",
      "epoch:16 step:12801 [D loss: 0.651904, acc: 65.62%] [G loss: 2.722538]\n",
      "epoch:16 step:12802 [D loss: 0.234494, acc: 98.44%] [G loss: 3.046304]\n",
      "epoch:16 step:12803 [D loss: 0.751409, acc: 49.22%] [G loss: 1.897243]\n",
      "epoch:16 step:12804 [D loss: 0.436768, acc: 89.84%] [G loss: 2.694924]\n",
      "epoch:16 step:12805 [D loss: 0.390573, acc: 90.62%] [G loss: 2.695702]\n",
      "epoch:16 step:12806 [D loss: 0.819166, acc: 35.16%] [G loss: 2.250548]\n",
      "epoch:16 step:12807 [D loss: 0.622370, acc: 62.50%] [G loss: 1.904933]\n",
      "epoch:16 step:12808 [D loss: 0.504517, acc: 83.59%] [G loss: 3.332457]\n",
      "epoch:16 step:12809 [D loss: 0.221311, acc: 99.22%] [G loss: 2.626874]\n",
      "epoch:16 step:12810 [D loss: 0.475463, acc: 85.16%] [G loss: 2.523310]\n",
      "epoch:16 step:12811 [D loss: 0.331654, acc: 97.66%] [G loss: 2.425082]\n",
      "epoch:16 step:12812 [D loss: 0.383624, acc: 87.50%] [G loss: 2.057159]\n",
      "epoch:16 step:12813 [D loss: 0.527609, acc: 75.78%] [G loss: 2.502621]\n",
      "epoch:16 step:12814 [D loss: 0.463201, acc: 75.00%] [G loss: 2.642656]\n",
      "epoch:16 step:12815 [D loss: 0.261246, acc: 95.31%] [G loss: 2.009333]\n",
      "epoch:16 step:12816 [D loss: 0.597035, acc: 67.97%] [G loss: 1.778888]\n",
      "epoch:16 step:12817 [D loss: 0.899690, acc: 49.22%] [G loss: 1.994320]\n",
      "epoch:16 step:12818 [D loss: 0.540425, acc: 71.09%] [G loss: 1.985705]\n",
      "epoch:16 step:12819 [D loss: 0.353872, acc: 92.97%] [G loss: 2.243197]\n",
      "epoch:16 step:12820 [D loss: 0.902478, acc: 47.66%] [G loss: 1.930281]\n",
      "epoch:16 step:12821 [D loss: 0.326400, acc: 96.88%] [G loss: 2.059348]\n",
      "epoch:16 step:12822 [D loss: 0.625581, acc: 62.50%] [G loss: 2.568149]\n",
      "epoch:16 step:12823 [D loss: 0.327672, acc: 93.75%] [G loss: 2.478467]\n",
      "epoch:16 step:12824 [D loss: 0.322070, acc: 93.75%] [G loss: 2.431121]\n",
      "epoch:16 step:12825 [D loss: 0.427616, acc: 84.38%] [G loss: 2.811923]\n",
      "epoch:16 step:12826 [D loss: 0.573959, acc: 75.78%] [G loss: 2.064198]\n",
      "epoch:16 step:12827 [D loss: 0.289416, acc: 95.31%] [G loss: 2.758370]\n",
      "epoch:16 step:12828 [D loss: 0.487847, acc: 76.56%] [G loss: 2.490004]\n",
      "epoch:16 step:12829 [D loss: 0.239778, acc: 99.22%] [G loss: 3.085749]\n",
      "epoch:16 step:12830 [D loss: 1.050110, acc: 28.91%] [G loss: 1.596131]\n",
      "epoch:16 step:12831 [D loss: 0.730962, acc: 54.69%] [G loss: 2.986437]\n",
      "epoch:16 step:12832 [D loss: 0.419824, acc: 78.12%] [G loss: 3.671948]\n",
      "epoch:16 step:12833 [D loss: 0.815938, acc: 38.28%] [G loss: 2.361777]\n",
      "epoch:16 step:12834 [D loss: 0.192383, acc: 98.44%] [G loss: 2.308590]\n",
      "epoch:16 step:12835 [D loss: 0.506830, acc: 65.62%] [G loss: 2.743737]\n",
      "epoch:16 step:12836 [D loss: 0.868430, acc: 32.03%] [G loss: 1.452225]\n",
      "epoch:16 step:12837 [D loss: 0.275736, acc: 99.22%] [G loss: 2.590442]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:16 step:12838 [D loss: 0.736187, acc: 50.00%] [G loss: 2.630154]\n",
      "epoch:16 step:12839 [D loss: 0.691057, acc: 53.12%] [G loss: 2.132740]\n",
      "epoch:16 step:12840 [D loss: 0.581615, acc: 60.94%] [G loss: 2.702915]\n",
      "epoch:16 step:12841 [D loss: 0.563893, acc: 72.66%] [G loss: 2.013929]\n",
      "epoch:16 step:12842 [D loss: 0.463735, acc: 81.25%] [G loss: 2.015695]\n",
      "epoch:16 step:12843 [D loss: 0.451090, acc: 91.41%] [G loss: 1.823569]\n",
      "epoch:16 step:12844 [D loss: 0.635386, acc: 64.06%] [G loss: 2.154019]\n",
      "epoch:16 step:12845 [D loss: 0.945421, acc: 50.00%] [G loss: 2.006101]\n",
      "epoch:16 step:12846 [D loss: 0.854712, acc: 47.66%] [G loss: 2.269748]\n",
      "epoch:16 step:12847 [D loss: 0.528527, acc: 71.88%] [G loss: 2.277315]\n",
      "epoch:16 step:12848 [D loss: 0.281968, acc: 96.09%] [G loss: 2.422783]\n",
      "epoch:16 step:12849 [D loss: 0.913940, acc: 50.00%] [G loss: 1.896168]\n",
      "epoch:16 step:12850 [D loss: 0.901033, acc: 48.44%] [G loss: 3.570500]\n",
      "epoch:16 step:12851 [D loss: 0.391868, acc: 87.50%] [G loss: 2.944350]\n",
      "epoch:16 step:12852 [D loss: 0.234006, acc: 98.44%] [G loss: 2.427361]\n",
      "epoch:16 step:12853 [D loss: 0.556400, acc: 73.44%] [G loss: 3.139230]\n",
      "epoch:16 step:12854 [D loss: 0.631273, acc: 64.84%] [G loss: 2.244720]\n",
      "epoch:16 step:12855 [D loss: 0.242954, acc: 98.44%] [G loss: 3.549146]\n",
      "epoch:16 step:12856 [D loss: 0.541191, acc: 79.69%] [G loss: 2.180037]\n",
      "epoch:16 step:12857 [D loss: 0.495238, acc: 74.22%] [G loss: 4.003715]\n",
      "epoch:16 step:12858 [D loss: 0.432773, acc: 92.19%] [G loss: 2.758001]\n",
      "epoch:16 step:12859 [D loss: 0.853766, acc: 33.59%] [G loss: 2.887783]\n",
      "epoch:16 step:12860 [D loss: 0.335418, acc: 95.31%] [G loss: 2.307405]\n",
      "epoch:16 step:12861 [D loss: 0.331892, acc: 96.09%] [G loss: 2.610700]\n",
      "epoch:16 step:12862 [D loss: 1.130373, acc: 49.22%] [G loss: 2.329162]\n",
      "epoch:16 step:12863 [D loss: 0.216673, acc: 100.00%] [G loss: 2.946360]\n",
      "epoch:16 step:12864 [D loss: 0.958126, acc: 50.00%] [G loss: 1.922275]\n",
      "epoch:16 step:12865 [D loss: 0.306555, acc: 96.88%] [G loss: 2.383581]\n",
      "epoch:16 step:12866 [D loss: 0.612901, acc: 66.41%] [G loss: 1.782954]\n",
      "epoch:16 step:12867 [D loss: 0.456602, acc: 79.69%] [G loss: 3.039654]\n",
      "epoch:16 step:12868 [D loss: 0.470171, acc: 71.88%] [G loss: 2.691108]\n",
      "epoch:16 step:12869 [D loss: 1.144637, acc: 17.97%] [G loss: 2.440192]\n",
      "epoch:16 step:12870 [D loss: 0.470723, acc: 75.00%] [G loss: 2.973402]\n",
      "epoch:16 step:12871 [D loss: 0.377336, acc: 81.25%] [G loss: 2.457982]\n",
      "epoch:16 step:12872 [D loss: 0.538576, acc: 65.62%] [G loss: 2.426237]\n",
      "epoch:16 step:12873 [D loss: 0.316653, acc: 93.75%] [G loss: 2.686099]\n",
      "epoch:16 step:12874 [D loss: 0.932399, acc: 39.06%] [G loss: 2.404787]\n",
      "epoch:16 step:12875 [D loss: 0.224397, acc: 96.88%] [G loss: 2.410330]\n",
      "epoch:16 step:12876 [D loss: 0.704916, acc: 55.47%] [G loss: 2.350176]\n",
      "epoch:16 step:12877 [D loss: 0.317765, acc: 90.62%] [G loss: 2.779528]\n",
      "epoch:16 step:12878 [D loss: 0.216330, acc: 96.09%] [G loss: 2.674037]\n",
      "epoch:16 step:12879 [D loss: 0.386594, acc: 91.41%] [G loss: 3.321731]\n",
      "epoch:16 step:12880 [D loss: 0.978628, acc: 50.00%] [G loss: 2.538954]\n",
      "epoch:16 step:12881 [D loss: 0.336470, acc: 97.66%] [G loss: 2.206816]\n",
      "epoch:16 step:12882 [D loss: 0.657991, acc: 57.81%] [G loss: 2.311817]\n",
      "epoch:16 step:12883 [D loss: 0.641073, acc: 63.28%] [G loss: 1.621606]\n",
      "epoch:16 step:12884 [D loss: 0.307513, acc: 91.41%] [G loss: 1.985391]\n",
      "epoch:16 step:12885 [D loss: 0.364604, acc: 89.84%] [G loss: 1.983392]\n",
      "epoch:16 step:12886 [D loss: 0.303098, acc: 96.88%] [G loss: 2.256118]\n",
      "epoch:16 step:12887 [D loss: 1.091014, acc: 17.97%] [G loss: 1.499087]\n",
      "epoch:16 step:12888 [D loss: 0.779489, acc: 50.78%] [G loss: 2.025382]\n",
      "epoch:16 step:12889 [D loss: 0.897051, acc: 31.25%] [G loss: 1.580834]\n",
      "epoch:16 step:12890 [D loss: 0.559012, acc: 66.41%] [G loss: 2.366281]\n",
      "epoch:16 step:12891 [D loss: 0.503233, acc: 82.03%] [G loss: 2.528194]\n",
      "epoch:16 step:12892 [D loss: 0.390372, acc: 89.06%] [G loss: 2.346951]\n",
      "epoch:16 step:12893 [D loss: 0.624864, acc: 57.81%] [G loss: 2.081511]\n",
      "epoch:16 step:12894 [D loss: 0.602445, acc: 61.72%] [G loss: 2.446457]\n",
      "epoch:16 step:12895 [D loss: 0.809486, acc: 41.41%] [G loss: 2.513418]\n",
      "epoch:16 step:12896 [D loss: 0.310728, acc: 96.88%] [G loss: 2.487404]\n",
      "epoch:16 step:12897 [D loss: 0.503438, acc: 80.47%] [G loss: 3.032183]\n",
      "epoch:16 step:12898 [D loss: 0.582431, acc: 58.59%] [G loss: 2.262240]\n",
      "epoch:16 step:12899 [D loss: 0.372890, acc: 86.72%] [G loss: 2.113567]\n",
      "epoch:16 step:12900 [D loss: 0.525025, acc: 77.34%] [G loss: 3.571695]\n",
      "epoch:16 step:12901 [D loss: 0.783127, acc: 50.00%] [G loss: 2.564778]\n",
      "epoch:16 step:12902 [D loss: 0.646773, acc: 65.62%] [G loss: 2.844352]\n",
      "epoch:16 step:12903 [D loss: 0.491711, acc: 85.94%] [G loss: 3.094227]\n",
      "epoch:16 step:12904 [D loss: 0.271581, acc: 100.00%] [G loss: 2.255376]\n",
      "epoch:16 step:12905 [D loss: 0.481275, acc: 82.03%] [G loss: 2.113093]\n",
      "epoch:16 step:12906 [D loss: 0.869512, acc: 31.25%] [G loss: 2.047053]\n",
      "epoch:16 step:12907 [D loss: 0.948777, acc: 40.62%] [G loss: 2.390325]\n",
      "epoch:16 step:12908 [D loss: 0.499770, acc: 80.47%] [G loss: 2.482856]\n",
      "epoch:16 step:12909 [D loss: 0.528259, acc: 71.88%] [G loss: 4.036184]\n",
      "epoch:16 step:12910 [D loss: 0.307250, acc: 95.31%] [G loss: 2.761741]\n",
      "epoch:16 step:12911 [D loss: 0.612755, acc: 61.72%] [G loss: 2.118978]\n",
      "epoch:16 step:12912 [D loss: 0.951941, acc: 50.00%] [G loss: 3.060923]\n",
      "epoch:16 step:12913 [D loss: 0.228050, acc: 100.00%] [G loss: 3.971697]\n",
      "epoch:16 step:12914 [D loss: 0.410395, acc: 74.22%] [G loss: 2.955963]\n",
      "epoch:16 step:12915 [D loss: 0.496135, acc: 69.53%] [G loss: 2.976311]\n",
      "epoch:16 step:12916 [D loss: 0.336223, acc: 96.09%] [G loss: 2.961469]\n",
      "epoch:16 step:12917 [D loss: 1.071590, acc: 50.78%] [G loss: 2.962287]\n",
      "epoch:16 step:12918 [D loss: 0.086854, acc: 100.00%] [G loss: 4.915330]\n",
      "epoch:16 step:12919 [D loss: 0.707952, acc: 61.72%] [G loss: 2.782279]\n",
      "epoch:16 step:12920 [D loss: 0.626010, acc: 62.50%] [G loss: 2.835862]\n",
      "epoch:16 step:12921 [D loss: 0.203110, acc: 96.09%] [G loss: 2.299953]\n",
      "epoch:16 step:12922 [D loss: 0.216361, acc: 99.22%] [G loss: 2.549118]\n",
      "epoch:16 step:12923 [D loss: 0.431746, acc: 75.78%] [G loss: 2.857705]\n",
      "epoch:16 step:12924 [D loss: 0.407955, acc: 68.75%] [G loss: 4.281219]\n",
      "epoch:16 step:12925 [D loss: 0.500712, acc: 68.75%] [G loss: 2.592654]\n",
      "epoch:16 step:12926 [D loss: 0.447552, acc: 84.38%] [G loss: 1.903265]\n",
      "epoch:16 step:12927 [D loss: 0.798697, acc: 50.00%] [G loss: 1.875665]\n",
      "epoch:16 step:12928 [D loss: 0.703510, acc: 49.22%] [G loss: 2.345279]\n",
      "epoch:16 step:12929 [D loss: 0.526807, acc: 57.03%] [G loss: 3.291980]\n",
      "epoch:16 step:12930 [D loss: 0.387987, acc: 84.38%] [G loss: 3.298469]\n",
      "epoch:16 step:12931 [D loss: 0.767746, acc: 52.34%] [G loss: 2.601000]\n",
      "epoch:16 step:12932 [D loss: 0.759647, acc: 53.12%] [G loss: 3.151906]\n",
      "epoch:16 step:12933 [D loss: 0.567847, acc: 74.22%] [G loss: 2.245651]\n",
      "epoch:16 step:12934 [D loss: 0.281470, acc: 94.53%] [G loss: 2.426169]\n",
      "epoch:16 step:12935 [D loss: 0.524494, acc: 78.91%] [G loss: 2.640628]\n",
      "epoch:16 step:12936 [D loss: 0.909669, acc: 43.75%] [G loss: 2.616733]\n",
      "epoch:16 step:12937 [D loss: 0.440080, acc: 86.72%] [G loss: 2.609278]\n",
      "epoch:16 step:12938 [D loss: 0.614072, acc: 61.72%] [G loss: 3.211174]\n",
      "epoch:16 step:12939 [D loss: 0.666549, acc: 57.03%] [G loss: 2.426796]\n",
      "epoch:16 step:12940 [D loss: 0.350144, acc: 92.19%] [G loss: 2.962296]\n",
      "epoch:16 step:12941 [D loss: 1.230850, acc: 14.84%] [G loss: 2.411272]\n",
      "epoch:16 step:12942 [D loss: 0.614028, acc: 67.19%] [G loss: 3.053175]\n",
      "epoch:16 step:12943 [D loss: 0.497308, acc: 82.81%] [G loss: 2.069198]\n",
      "epoch:16 step:12944 [D loss: 0.580875, acc: 74.22%] [G loss: 2.430019]\n",
      "epoch:16 step:12945 [D loss: 0.335107, acc: 81.25%] [G loss: 2.581780]\n",
      "epoch:16 step:12946 [D loss: 0.606323, acc: 58.59%] [G loss: 3.045350]\n",
      "epoch:16 step:12947 [D loss: 0.333060, acc: 93.75%] [G loss: 2.835208]\n",
      "epoch:16 step:12948 [D loss: 0.471355, acc: 80.47%] [G loss: 2.565157]\n",
      "epoch:16 step:12949 [D loss: 0.830367, acc: 51.56%] [G loss: 2.417068]\n",
      "epoch:16 step:12950 [D loss: 0.464772, acc: 82.81%] [G loss: 2.407173]\n",
      "epoch:16 step:12951 [D loss: 0.514381, acc: 77.34%] [G loss: 2.508473]\n",
      "epoch:16 step:12952 [D loss: 0.295826, acc: 97.66%] [G loss: 2.228499]\n",
      "epoch:16 step:12953 [D loss: 0.697951, acc: 57.03%] [G loss: 2.079401]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:16 step:12954 [D loss: 0.344786, acc: 94.53%] [G loss: 2.562566]\n",
      "epoch:16 step:12955 [D loss: 0.506650, acc: 68.75%] [G loss: 3.363671]\n",
      "epoch:16 step:12956 [D loss: 0.443508, acc: 78.12%] [G loss: 2.569093]\n",
      "epoch:16 step:12957 [D loss: 0.581528, acc: 67.97%] [G loss: 2.315829]\n",
      "epoch:16 step:12958 [D loss: 0.682430, acc: 56.25%] [G loss: 2.186723]\n",
      "epoch:16 step:12959 [D loss: 0.192825, acc: 97.66%] [G loss: 3.216638]\n",
      "epoch:16 step:12960 [D loss: 0.645052, acc: 60.16%] [G loss: 2.183727]\n",
      "epoch:16 step:12961 [D loss: 0.352922, acc: 82.81%] [G loss: 2.786061]\n",
      "epoch:16 step:12962 [D loss: 0.365461, acc: 85.16%] [G loss: 3.582629]\n",
      "epoch:16 step:12963 [D loss: 1.055965, acc: 23.44%] [G loss: 2.203226]\n",
      "epoch:16 step:12964 [D loss: 0.282705, acc: 94.53%] [G loss: 3.351933]\n",
      "epoch:16 step:12965 [D loss: 0.356043, acc: 92.97%] [G loss: 2.957743]\n",
      "epoch:16 step:12966 [D loss: 0.806247, acc: 46.09%] [G loss: 2.625319]\n",
      "epoch:16 step:12967 [D loss: 0.610053, acc: 68.75%] [G loss: 1.813714]\n",
      "epoch:16 step:12968 [D loss: 0.487652, acc: 82.81%] [G loss: 2.780999]\n",
      "epoch:16 step:12969 [D loss: 0.473630, acc: 72.66%] [G loss: 2.138191]\n",
      "epoch:16 step:12970 [D loss: 0.490078, acc: 78.91%] [G loss: 2.796104]\n",
      "epoch:16 step:12971 [D loss: 0.433245, acc: 81.25%] [G loss: 2.313721]\n",
      "epoch:16 step:12972 [D loss: 0.322257, acc: 95.31%] [G loss: 3.063835]\n",
      "epoch:16 step:12973 [D loss: 0.402735, acc: 90.62%] [G loss: 2.581491]\n",
      "epoch:16 step:12974 [D loss: 0.490824, acc: 85.94%] [G loss: 2.349247]\n",
      "epoch:16 step:12975 [D loss: 1.013702, acc: 31.25%] [G loss: 2.444599]\n",
      "epoch:16 step:12976 [D loss: 1.062457, acc: 37.50%] [G loss: 1.575219]\n",
      "epoch:16 step:12977 [D loss: 0.591769, acc: 65.62%] [G loss: 1.806079]\n",
      "epoch:16 step:12978 [D loss: 1.031720, acc: 51.56%] [G loss: 2.474041]\n",
      "epoch:16 step:12979 [D loss: 0.383346, acc: 91.41%] [G loss: 2.332355]\n",
      "epoch:16 step:12980 [D loss: 0.548972, acc: 71.88%] [G loss: 2.671063]\n",
      "epoch:16 step:12981 [D loss: 0.343317, acc: 92.97%] [G loss: 3.328965]\n",
      "epoch:16 step:12982 [D loss: 0.462395, acc: 85.16%] [G loss: 2.740231]\n",
      "epoch:16 step:12983 [D loss: 0.463318, acc: 85.94%] [G loss: 1.928377]\n",
      "epoch:16 step:12984 [D loss: 0.459494, acc: 69.53%] [G loss: 2.565935]\n",
      "epoch:16 step:12985 [D loss: 0.496754, acc: 71.88%] [G loss: 1.918237]\n",
      "epoch:16 step:12986 [D loss: 0.966602, acc: 14.06%] [G loss: 2.100337]\n",
      "epoch:16 step:12987 [D loss: 0.687258, acc: 60.94%] [G loss: 2.599173]\n",
      "epoch:16 step:12988 [D loss: 0.731638, acc: 49.22%] [G loss: 1.715243]\n",
      "epoch:16 step:12989 [D loss: 0.619410, acc: 67.19%] [G loss: 2.790373]\n",
      "epoch:16 step:12990 [D loss: 0.527657, acc: 76.56%] [G loss: 2.929914]\n",
      "epoch:16 step:12991 [D loss: 0.675294, acc: 57.81%] [G loss: 3.325599]\n",
      "epoch:16 step:12992 [D loss: 0.711474, acc: 54.69%] [G loss: 2.384795]\n",
      "epoch:16 step:12993 [D loss: 0.536584, acc: 63.28%] [G loss: 2.729216]\n",
      "epoch:16 step:12994 [D loss: 0.482377, acc: 73.44%] [G loss: 2.545286]\n",
      "epoch:16 step:12995 [D loss: 0.543190, acc: 57.03%] [G loss: 2.943652]\n",
      "epoch:16 step:12996 [D loss: 0.461798, acc: 76.56%] [G loss: 2.433464]\n",
      "epoch:16 step:12997 [D loss: 0.718433, acc: 54.69%] [G loss: 1.845360]\n",
      "epoch:16 step:12998 [D loss: 0.538941, acc: 67.97%] [G loss: 3.161048]\n",
      "epoch:16 step:12999 [D loss: 0.671180, acc: 58.59%] [G loss: 2.404557]\n",
      "epoch:16 step:13000 [D loss: 0.896758, acc: 30.47%] [G loss: 1.576509]\n",
      "##############\n",
      "[0.86046381 0.85573714 0.80563733 0.80824187 0.80042574 0.8056382\n",
      " 0.90220349 0.85766539 0.79129098 0.83484822]\n",
      "##########\n",
      "epoch:16 step:13001 [D loss: 0.620977, acc: 62.50%] [G loss: 1.569769]\n",
      "epoch:16 step:13002 [D loss: 0.905071, acc: 42.19%] [G loss: 1.521162]\n",
      "epoch:16 step:13003 [D loss: 0.464799, acc: 88.28%] [G loss: 2.657818]\n",
      "epoch:16 step:13004 [D loss: 0.637309, acc: 63.28%] [G loss: 2.891695]\n",
      "epoch:16 step:13005 [D loss: 0.224208, acc: 98.44%] [G loss: 3.744445]\n",
      "epoch:16 step:13006 [D loss: 0.492923, acc: 79.69%] [G loss: 2.710137]\n",
      "epoch:16 step:13007 [D loss: 0.329211, acc: 92.97%] [G loss: 2.912055]\n",
      "epoch:16 step:13008 [D loss: 0.747605, acc: 53.12%] [G loss: 2.060076]\n",
      "epoch:16 step:13009 [D loss: 0.370238, acc: 87.50%] [G loss: 2.662456]\n",
      "epoch:16 step:13010 [D loss: 0.388642, acc: 76.56%] [G loss: 3.528438]\n",
      "epoch:16 step:13011 [D loss: 1.307774, acc: 14.06%] [G loss: 1.788153]\n",
      "epoch:16 step:13012 [D loss: 0.663097, acc: 57.81%] [G loss: 1.939943]\n",
      "epoch:16 step:13013 [D loss: 0.334054, acc: 95.31%] [G loss: 3.552722]\n",
      "epoch:16 step:13014 [D loss: 0.500838, acc: 81.25%] [G loss: 2.260489]\n",
      "epoch:16 step:13015 [D loss: 0.755473, acc: 45.31%] [G loss: 1.951972]\n",
      "epoch:16 step:13016 [D loss: 0.412052, acc: 89.84%] [G loss: 3.372892]\n",
      "epoch:16 step:13017 [D loss: 0.843862, acc: 43.75%] [G loss: 2.575205]\n",
      "epoch:16 step:13018 [D loss: 0.547062, acc: 62.50%] [G loss: 1.864016]\n",
      "epoch:16 step:13019 [D loss: 0.479897, acc: 85.94%] [G loss: 3.187057]\n",
      "epoch:16 step:13020 [D loss: 0.406083, acc: 92.97%] [G loss: 3.204380]\n",
      "epoch:16 step:13021 [D loss: 0.754118, acc: 53.12%] [G loss: 2.317100]\n",
      "epoch:16 step:13022 [D loss: 0.416024, acc: 86.72%] [G loss: 2.203653]\n",
      "epoch:16 step:13023 [D loss: 0.390189, acc: 91.41%] [G loss: 2.999979]\n",
      "epoch:16 step:13024 [D loss: 0.523657, acc: 78.12%] [G loss: 2.386396]\n",
      "epoch:16 step:13025 [D loss: 0.342987, acc: 94.53%] [G loss: 2.609589]\n",
      "epoch:16 step:13026 [D loss: 0.370038, acc: 84.38%] [G loss: 2.564588]\n",
      "epoch:16 step:13027 [D loss: 0.487020, acc: 70.31%] [G loss: 2.108228]\n",
      "epoch:16 step:13028 [D loss: 0.689928, acc: 59.38%] [G loss: 2.472528]\n",
      "epoch:16 step:13029 [D loss: 0.353751, acc: 94.53%] [G loss: 4.225994]\n",
      "epoch:16 step:13030 [D loss: 0.503344, acc: 83.59%] [G loss: 2.581225]\n",
      "epoch:16 step:13031 [D loss: 0.343594, acc: 95.31%] [G loss: 2.818092]\n",
      "epoch:16 step:13032 [D loss: 0.328351, acc: 92.97%] [G loss: 2.113707]\n",
      "epoch:16 step:13033 [D loss: 0.931038, acc: 31.25%] [G loss: 2.076382]\n",
      "epoch:16 step:13034 [D loss: 0.501850, acc: 79.69%] [G loss: 2.802573]\n",
      "epoch:16 step:13035 [D loss: 0.373821, acc: 88.28%] [G loss: 2.064459]\n",
      "epoch:16 step:13036 [D loss: 0.185016, acc: 99.22%] [G loss: 2.606677]\n",
      "epoch:16 step:13037 [D loss: 0.342244, acc: 93.75%] [G loss: 3.184419]\n",
      "epoch:16 step:13038 [D loss: 0.689911, acc: 56.25%] [G loss: 2.076476]\n",
      "epoch:16 step:13039 [D loss: 0.761172, acc: 49.22%] [G loss: 2.024652]\n",
      "epoch:16 step:13040 [D loss: 1.016935, acc: 16.41%] [G loss: 2.359940]\n",
      "epoch:16 step:13041 [D loss: 0.601537, acc: 64.06%] [G loss: 2.303662]\n",
      "epoch:16 step:13042 [D loss: 0.590265, acc: 64.06%] [G loss: 3.030880]\n",
      "epoch:16 step:13043 [D loss: 0.564020, acc: 69.53%] [G loss: 2.803906]\n",
      "epoch:16 step:13044 [D loss: 0.653301, acc: 62.50%] [G loss: 1.964084]\n",
      "epoch:16 step:13045 [D loss: 0.712540, acc: 57.03%] [G loss: 2.063528]\n",
      "epoch:16 step:13046 [D loss: 0.268783, acc: 97.66%] [G loss: 2.556008]\n",
      "epoch:16 step:13047 [D loss: 0.555799, acc: 66.41%] [G loss: 2.727152]\n",
      "epoch:16 step:13048 [D loss: 0.327276, acc: 96.88%] [G loss: 2.662729]\n",
      "epoch:16 step:13049 [D loss: 0.688310, acc: 64.06%] [G loss: 2.269867]\n",
      "epoch:16 step:13050 [D loss: 0.728580, acc: 50.78%] [G loss: 1.916719]\n",
      "epoch:16 step:13051 [D loss: 0.609076, acc: 64.84%] [G loss: 2.367041]\n",
      "epoch:16 step:13052 [D loss: 0.819189, acc: 43.75%] [G loss: 1.564592]\n",
      "epoch:16 step:13053 [D loss: 0.459607, acc: 79.69%] [G loss: 2.554244]\n",
      "epoch:16 step:13054 [D loss: 0.559191, acc: 67.97%] [G loss: 2.434626]\n",
      "epoch:16 step:13055 [D loss: 0.515895, acc: 77.34%] [G loss: 2.715335]\n",
      "epoch:16 step:13056 [D loss: 0.377769, acc: 90.62%] [G loss: 2.813960]\n",
      "epoch:16 step:13057 [D loss: 0.309525, acc: 95.31%] [G loss: 3.301386]\n",
      "epoch:16 step:13058 [D loss: 0.625547, acc: 65.62%] [G loss: 2.209372]\n",
      "epoch:16 step:13059 [D loss: 0.487933, acc: 83.59%] [G loss: 2.878263]\n",
      "epoch:16 step:13060 [D loss: 0.333657, acc: 96.09%] [G loss: 2.054090]\n",
      "epoch:16 step:13061 [D loss: 0.608767, acc: 67.19%] [G loss: 2.519618]\n",
      "epoch:16 step:13062 [D loss: 0.470670, acc: 85.16%] [G loss: 3.360740]\n",
      "epoch:16 step:13063 [D loss: 0.374492, acc: 90.62%] [G loss: 2.801101]\n",
      "epoch:16 step:13064 [D loss: 0.496939, acc: 74.22%] [G loss: 2.604167]\n",
      "epoch:16 step:13065 [D loss: 0.268685, acc: 99.22%] [G loss: 3.619345]\n",
      "epoch:16 step:13066 [D loss: 0.946073, acc: 43.75%] [G loss: 1.863928]\n",
      "epoch:16 step:13067 [D loss: 0.370757, acc: 89.84%] [G loss: 1.889183]\n",
      "epoch:16 step:13068 [D loss: 0.414089, acc: 79.69%] [G loss: 3.024670]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:16 step:13069 [D loss: 0.552519, acc: 61.72%] [G loss: 2.920739]\n",
      "epoch:16 step:13070 [D loss: 0.637942, acc: 62.50%] [G loss: 2.656660]\n",
      "epoch:16 step:13071 [D loss: 0.537876, acc: 72.66%] [G loss: 2.628653]\n",
      "epoch:16 step:13072 [D loss: 0.278174, acc: 96.88%] [G loss: 3.007545]\n",
      "epoch:16 step:13073 [D loss: 0.657314, acc: 57.03%] [G loss: 1.970121]\n",
      "epoch:16 step:13074 [D loss: 0.446356, acc: 87.50%] [G loss: 2.667010]\n",
      "epoch:16 step:13075 [D loss: 0.570590, acc: 75.78%] [G loss: 3.056983]\n",
      "epoch:16 step:13076 [D loss: 0.617908, acc: 69.53%] [G loss: 2.406825]\n",
      "epoch:16 step:13077 [D loss: 0.451050, acc: 89.06%] [G loss: 2.738252]\n",
      "epoch:16 step:13078 [D loss: 0.515790, acc: 78.12%] [G loss: 2.106873]\n",
      "epoch:16 step:13079 [D loss: 0.458424, acc: 86.72%] [G loss: 2.474000]\n",
      "epoch:16 step:13080 [D loss: 0.722517, acc: 56.25%] [G loss: 2.398533]\n",
      "epoch:16 step:13081 [D loss: 0.510549, acc: 80.47%] [G loss: 2.431483]\n",
      "epoch:16 step:13082 [D loss: 0.397566, acc: 92.19%] [G loss: 2.806011]\n",
      "epoch:16 step:13083 [D loss: 0.496201, acc: 82.81%] [G loss: 2.856856]\n",
      "epoch:16 step:13084 [D loss: 0.253713, acc: 93.75%] [G loss: 2.893725]\n",
      "epoch:16 step:13085 [D loss: 0.482238, acc: 74.22%] [G loss: 2.739491]\n",
      "epoch:16 step:13086 [D loss: 0.583371, acc: 65.62%] [G loss: 2.441490]\n",
      "epoch:16 step:13087 [D loss: 0.394630, acc: 93.75%] [G loss: 3.942510]\n",
      "epoch:16 step:13088 [D loss: 0.799116, acc: 42.97%] [G loss: 2.106144]\n",
      "epoch:16 step:13089 [D loss: 0.982315, acc: 27.34%] [G loss: 1.994459]\n",
      "epoch:16 step:13090 [D loss: 0.578411, acc: 72.66%] [G loss: 3.344736]\n",
      "epoch:16 step:13091 [D loss: 0.465523, acc: 85.16%] [G loss: 2.430259]\n",
      "epoch:16 step:13092 [D loss: 0.454682, acc: 77.34%] [G loss: 3.127914]\n",
      "epoch:16 step:13093 [D loss: 1.111227, acc: 14.84%] [G loss: 2.419765]\n",
      "epoch:16 step:13094 [D loss: 0.313671, acc: 94.53%] [G loss: 3.752867]\n",
      "epoch:16 step:13095 [D loss: 0.589623, acc: 72.66%] [G loss: 2.135015]\n",
      "epoch:16 step:13096 [D loss: 0.638942, acc: 64.84%] [G loss: 2.270753]\n",
      "epoch:16 step:13097 [D loss: 0.294503, acc: 95.31%] [G loss: 3.108552]\n",
      "epoch:16 step:13098 [D loss: 0.454255, acc: 85.16%] [G loss: 3.370179]\n",
      "epoch:16 step:13099 [D loss: 1.186726, acc: 12.50%] [G loss: 2.061105]\n",
      "epoch:16 step:13100 [D loss: 0.571082, acc: 75.00%] [G loss: 1.871566]\n",
      "epoch:16 step:13101 [D loss: 0.280396, acc: 96.88%] [G loss: 2.917735]\n",
      "epoch:16 step:13102 [D loss: 0.462553, acc: 73.44%] [G loss: 2.835915]\n",
      "epoch:16 step:13103 [D loss: 0.716089, acc: 55.47%] [G loss: 2.126139]\n",
      "epoch:16 step:13104 [D loss: 0.548025, acc: 66.41%] [G loss: 2.235853]\n",
      "epoch:16 step:13105 [D loss: 0.511640, acc: 80.47%] [G loss: 3.665213]\n",
      "epoch:16 step:13106 [D loss: 1.069275, acc: 50.00%] [G loss: 2.181271]\n",
      "epoch:16 step:13107 [D loss: 0.668182, acc: 60.16%] [G loss: 2.110911]\n",
      "epoch:16 step:13108 [D loss: 0.750345, acc: 50.78%] [G loss: 2.504801]\n",
      "epoch:16 step:13109 [D loss: 0.778237, acc: 46.88%] [G loss: 1.796294]\n",
      "epoch:16 step:13110 [D loss: 0.722031, acc: 56.25%] [G loss: 2.566193]\n",
      "epoch:16 step:13111 [D loss: 0.292344, acc: 97.66%] [G loss: 2.773667]\n",
      "epoch:16 step:13112 [D loss: 0.551333, acc: 77.34%] [G loss: 2.686834]\n",
      "epoch:16 step:13113 [D loss: 0.628754, acc: 62.50%] [G loss: 2.206320]\n",
      "epoch:16 step:13114 [D loss: 0.340182, acc: 89.84%] [G loss: 2.543022]\n",
      "epoch:16 step:13115 [D loss: 0.677940, acc: 54.69%] [G loss: 2.410481]\n",
      "epoch:16 step:13116 [D loss: 0.473207, acc: 74.22%] [G loss: 3.005824]\n",
      "epoch:16 step:13117 [D loss: 0.388193, acc: 82.03%] [G loss: 1.974997]\n",
      "epoch:16 step:13118 [D loss: 0.326239, acc: 89.06%] [G loss: 3.434261]\n",
      "epoch:16 step:13119 [D loss: 1.199499, acc: 14.06%] [G loss: 2.251703]\n",
      "epoch:16 step:13120 [D loss: 0.146458, acc: 100.00%] [G loss: 2.588371]\n",
      "epoch:16 step:13121 [D loss: 0.805837, acc: 52.34%] [G loss: 2.889658]\n",
      "epoch:16 step:13122 [D loss: 1.080920, acc: 13.28%] [G loss: 1.914307]\n",
      "epoch:16 step:13123 [D loss: 0.401097, acc: 75.78%] [G loss: 2.022761]\n",
      "epoch:16 step:13124 [D loss: 0.388814, acc: 83.59%] [G loss: 2.979840]\n",
      "epoch:16 step:13125 [D loss: 0.849283, acc: 46.09%] [G loss: 2.885900]\n",
      "epoch:16 step:13126 [D loss: 0.627151, acc: 61.72%] [G loss: 2.234790]\n",
      "epoch:16 step:13127 [D loss: 0.469949, acc: 92.19%] [G loss: 2.834066]\n",
      "epoch:16 step:13128 [D loss: 0.551787, acc: 75.00%] [G loss: 2.164595]\n",
      "epoch:16 step:13129 [D loss: 0.608793, acc: 60.16%] [G loss: 2.720865]\n",
      "epoch:16 step:13130 [D loss: 1.252127, acc: 47.66%] [G loss: 2.145410]\n",
      "epoch:16 step:13131 [D loss: 0.602112, acc: 66.41%] [G loss: 2.439378]\n",
      "epoch:16 step:13132 [D loss: 0.357711, acc: 90.62%] [G loss: 2.628164]\n",
      "epoch:16 step:13133 [D loss: 0.900580, acc: 52.34%] [G loss: 1.965961]\n",
      "epoch:16 step:13134 [D loss: 0.374148, acc: 93.75%] [G loss: 3.701667]\n",
      "epoch:16 step:13135 [D loss: 0.457084, acc: 86.72%] [G loss: 2.100502]\n",
      "epoch:16 step:13136 [D loss: 0.202098, acc: 96.88%] [G loss: 3.587710]\n",
      "epoch:16 step:13137 [D loss: 0.616569, acc: 64.84%] [G loss: 2.498346]\n",
      "epoch:16 step:13138 [D loss: 0.326600, acc: 86.72%] [G loss: 2.674017]\n",
      "epoch:16 step:13139 [D loss: 0.500306, acc: 71.88%] [G loss: 2.379188]\n",
      "epoch:16 step:13140 [D loss: 0.468582, acc: 72.66%] [G loss: 2.964477]\n",
      "epoch:16 step:13141 [D loss: 0.805298, acc: 50.78%] [G loss: 2.695441]\n",
      "epoch:16 step:13142 [D loss: 0.745248, acc: 53.12%] [G loss: 2.462488]\n",
      "epoch:16 step:13143 [D loss: 0.711459, acc: 57.81%] [G loss: 2.283251]\n",
      "epoch:16 step:13144 [D loss: 0.385873, acc: 90.62%] [G loss: 2.264437]\n",
      "epoch:16 step:13145 [D loss: 0.459306, acc: 87.50%] [G loss: 2.845488]\n",
      "epoch:16 step:13146 [D loss: 0.417447, acc: 92.19%] [G loss: 3.086671]\n",
      "epoch:16 step:13147 [D loss: 0.194506, acc: 96.09%] [G loss: 4.320060]\n",
      "epoch:16 step:13148 [D loss: 0.494281, acc: 79.69%] [G loss: 2.377696]\n",
      "epoch:16 step:13149 [D loss: 0.304541, acc: 95.31%] [G loss: 2.932295]\n",
      "epoch:16 step:13150 [D loss: 0.302427, acc: 95.31%] [G loss: 2.394761]\n",
      "epoch:16 step:13151 [D loss: 0.568446, acc: 75.78%] [G loss: 1.856375]\n",
      "epoch:16 step:13152 [D loss: 1.018884, acc: 27.34%] [G loss: 2.085507]\n",
      "epoch:16 step:13153 [D loss: 0.560449, acc: 72.66%] [G loss: 2.406507]\n",
      "epoch:16 step:13154 [D loss: 0.313361, acc: 96.09%] [G loss: 2.708880]\n",
      "epoch:16 step:13155 [D loss: 0.441729, acc: 84.38%] [G loss: 2.208248]\n",
      "epoch:16 step:13156 [D loss: 0.866536, acc: 31.25%] [G loss: 1.886930]\n",
      "epoch:16 step:13157 [D loss: 0.519866, acc: 82.03%] [G loss: 3.049792]\n",
      "epoch:16 step:13158 [D loss: 0.427536, acc: 88.28%] [G loss: 2.170511]\n",
      "epoch:16 step:13159 [D loss: 0.414468, acc: 85.94%] [G loss: 2.913266]\n",
      "epoch:16 step:13160 [D loss: 0.563526, acc: 71.88%] [G loss: 2.047205]\n",
      "epoch:16 step:13161 [D loss: 0.729631, acc: 52.34%] [G loss: 1.994939]\n",
      "epoch:16 step:13162 [D loss: 0.518103, acc: 78.91%] [G loss: 2.633690]\n",
      "epoch:16 step:13163 [D loss: 0.647398, acc: 64.06%] [G loss: 2.902549]\n",
      "epoch:16 step:13164 [D loss: 0.264545, acc: 93.75%] [G loss: 2.662055]\n",
      "epoch:16 step:13165 [D loss: 0.630183, acc: 61.72%] [G loss: 2.677118]\n",
      "epoch:16 step:13166 [D loss: 0.418840, acc: 82.03%] [G loss: 2.590898]\n",
      "epoch:16 step:13167 [D loss: 0.616436, acc: 65.62%] [G loss: 2.962523]\n",
      "epoch:16 step:13168 [D loss: 1.119844, acc: 27.34%] [G loss: 2.123591]\n",
      "epoch:16 step:13169 [D loss: 0.449863, acc: 80.47%] [G loss: 2.320215]\n",
      "epoch:16 step:13170 [D loss: 0.715392, acc: 57.03%] [G loss: 2.299392]\n",
      "epoch:16 step:13171 [D loss: 0.407995, acc: 83.59%] [G loss: 2.612785]\n",
      "epoch:16 step:13172 [D loss: 0.707026, acc: 52.34%] [G loss: 3.883023]\n",
      "epoch:16 step:13173 [D loss: 0.418831, acc: 92.97%] [G loss: 3.089068]\n",
      "epoch:16 step:13174 [D loss: 0.871438, acc: 40.62%] [G loss: 2.179271]\n",
      "epoch:16 step:13175 [D loss: 0.665718, acc: 60.94%] [G loss: 2.341329]\n",
      "epoch:16 step:13176 [D loss: 0.568605, acc: 62.50%] [G loss: 2.915134]\n",
      "epoch:16 step:13177 [D loss: 0.302327, acc: 98.44%] [G loss: 4.030905]\n",
      "epoch:16 step:13178 [D loss: 0.423709, acc: 84.38%] [G loss: 2.758092]\n",
      "epoch:16 step:13179 [D loss: 0.606967, acc: 67.19%] [G loss: 2.721720]\n",
      "epoch:16 step:13180 [D loss: 0.529253, acc: 82.03%] [G loss: 2.322526]\n",
      "epoch:16 step:13181 [D loss: 0.883263, acc: 50.00%] [G loss: 2.849816]\n",
      "epoch:16 step:13182 [D loss: 0.886674, acc: 42.97%] [G loss: 3.197259]\n",
      "epoch:16 step:13183 [D loss: 0.677533, acc: 59.38%] [G loss: 2.810251]\n",
      "epoch:16 step:13184 [D loss: 0.235811, acc: 96.88%] [G loss: 3.381370]\n",
      "epoch:16 step:13185 [D loss: 0.896105, acc: 51.56%] [G loss: 2.293459]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:16 step:13186 [D loss: 0.171272, acc: 100.00%] [G loss: 3.036637]\n",
      "epoch:16 step:13187 [D loss: 1.041711, acc: 14.84%] [G loss: 2.439571]\n",
      "epoch:16 step:13188 [D loss: 0.718067, acc: 57.03%] [G loss: 1.896442]\n",
      "epoch:16 step:13189 [D loss: 0.788433, acc: 50.78%] [G loss: 2.206656]\n",
      "epoch:16 step:13190 [D loss: 0.445549, acc: 86.72%] [G loss: 1.664794]\n",
      "epoch:16 step:13191 [D loss: 0.606726, acc: 64.06%] [G loss: 2.495482]\n",
      "epoch:16 step:13192 [D loss: 0.659091, acc: 60.94%] [G loss: 3.040750]\n",
      "epoch:16 step:13193 [D loss: 0.515065, acc: 80.47%] [G loss: 2.582089]\n",
      "epoch:16 step:13194 [D loss: 0.455991, acc: 84.38%] [G loss: 2.808918]\n",
      "epoch:16 step:13195 [D loss: 0.488899, acc: 85.94%] [G loss: 2.417277]\n",
      "epoch:16 step:13196 [D loss: 0.388955, acc: 91.41%] [G loss: 2.170777]\n",
      "epoch:16 step:13197 [D loss: 0.862947, acc: 37.50%] [G loss: 2.065282]\n",
      "epoch:16 step:13198 [D loss: 0.439966, acc: 88.28%] [G loss: 2.664963]\n",
      "epoch:16 step:13199 [D loss: 0.739368, acc: 54.69%] [G loss: 2.142652]\n",
      "epoch:16 step:13200 [D loss: 0.801761, acc: 50.00%] [G loss: 1.798863]\n",
      "##############\n",
      "[0.84567918 0.86715189 0.81648126 0.80838252 0.78520232 0.82709779\n",
      " 0.9039883  0.81401181 0.82274313 0.8198229 ]\n",
      "##########\n",
      "epoch:16 step:13201 [D loss: 0.409958, acc: 92.97%] [G loss: 2.109065]\n",
      "epoch:16 step:13202 [D loss: 0.674479, acc: 62.50%] [G loss: 2.883074]\n",
      "epoch:16 step:13203 [D loss: 0.811134, acc: 42.97%] [G loss: 2.146963]\n",
      "epoch:16 step:13204 [D loss: 0.660447, acc: 54.69%] [G loss: 1.802718]\n",
      "epoch:16 step:13205 [D loss: 1.159962, acc: 7.03%] [G loss: 1.702379]\n",
      "epoch:16 step:13206 [D loss: 0.782611, acc: 47.66%] [G loss: 2.793275]\n",
      "epoch:16 step:13207 [D loss: 0.298402, acc: 95.31%] [G loss: 2.958051]\n",
      "epoch:16 step:13208 [D loss: 0.976650, acc: 47.66%] [G loss: 1.877406]\n",
      "epoch:16 step:13209 [D loss: 0.344353, acc: 94.53%] [G loss: 2.771071]\n",
      "epoch:16 step:13210 [D loss: 0.521518, acc: 80.47%] [G loss: 2.457356]\n",
      "epoch:16 step:13211 [D loss: 1.110330, acc: 28.12%] [G loss: 1.804715]\n",
      "epoch:16 step:13212 [D loss: 0.322142, acc: 97.66%] [G loss: 2.647205]\n",
      "epoch:16 step:13213 [D loss: 0.545885, acc: 79.69%] [G loss: 2.868949]\n",
      "epoch:16 step:13214 [D loss: 0.977603, acc: 19.53%] [G loss: 1.730503]\n",
      "epoch:16 step:13215 [D loss: 0.476765, acc: 84.38%] [G loss: 2.936639]\n",
      "epoch:16 step:13216 [D loss: 0.564743, acc: 75.00%] [G loss: 2.532302]\n",
      "epoch:16 step:13217 [D loss: 0.638405, acc: 58.59%] [G loss: 2.492292]\n",
      "epoch:16 step:13218 [D loss: 0.283823, acc: 91.41%] [G loss: 2.245054]\n",
      "epoch:16 step:13219 [D loss: 0.562942, acc: 72.66%] [G loss: 2.050324]\n",
      "epoch:16 step:13220 [D loss: 0.531678, acc: 72.66%] [G loss: 2.425640]\n",
      "epoch:16 step:13221 [D loss: 0.379937, acc: 85.16%] [G loss: 3.415017]\n",
      "epoch:16 step:13222 [D loss: 0.531625, acc: 72.66%] [G loss: 2.698906]\n",
      "epoch:16 step:13223 [D loss: 0.499986, acc: 78.91%] [G loss: 2.151728]\n",
      "epoch:16 step:13224 [D loss: 0.622073, acc: 69.53%] [G loss: 3.588877]\n",
      "epoch:16 step:13225 [D loss: 0.331324, acc: 95.31%] [G loss: 2.312743]\n",
      "epoch:16 step:13226 [D loss: 0.621818, acc: 69.53%] [G loss: 2.432865]\n",
      "epoch:16 step:13227 [D loss: 0.323558, acc: 94.53%] [G loss: 2.346850]\n",
      "epoch:16 step:13228 [D loss: 0.534668, acc: 75.00%] [G loss: 1.993681]\n",
      "epoch:16 step:13229 [D loss: 0.577184, acc: 74.22%] [G loss: 2.280056]\n",
      "epoch:16 step:13230 [D loss: 0.638059, acc: 69.53%] [G loss: 1.934339]\n",
      "epoch:16 step:13231 [D loss: 0.546844, acc: 67.19%] [G loss: 2.545909]\n",
      "epoch:16 step:13232 [D loss: 0.275971, acc: 96.09%] [G loss: 3.057636]\n",
      "epoch:16 step:13233 [D loss: 1.152143, acc: 14.06%] [G loss: 2.787539]\n",
      "epoch:16 step:13234 [D loss: 0.325529, acc: 92.19%] [G loss: 2.779182]\n",
      "epoch:16 step:13235 [D loss: 0.645842, acc: 62.50%] [G loss: 2.943228]\n",
      "epoch:16 step:13236 [D loss: 1.066508, acc: 41.41%] [G loss: 2.543299]\n",
      "epoch:16 step:13237 [D loss: 0.184394, acc: 99.22%] [G loss: 2.507738]\n",
      "epoch:16 step:13238 [D loss: 0.573026, acc: 67.19%] [G loss: 2.692218]\n",
      "epoch:16 step:13239 [D loss: 0.769156, acc: 51.56%] [G loss: 2.708097]\n",
      "epoch:16 step:13240 [D loss: 0.722396, acc: 48.44%] [G loss: 2.333642]\n",
      "epoch:16 step:13241 [D loss: 0.317270, acc: 92.19%] [G loss: 3.382985]\n",
      "epoch:16 step:13242 [D loss: 0.344523, acc: 95.31%] [G loss: 2.084701]\n",
      "epoch:16 step:13243 [D loss: 0.845828, acc: 43.75%] [G loss: 2.151487]\n",
      "epoch:16 step:13244 [D loss: 0.176871, acc: 100.00%] [G loss: 2.536538]\n",
      "epoch:16 step:13245 [D loss: 0.515581, acc: 84.38%] [G loss: 2.729511]\n",
      "epoch:16 step:13246 [D loss: 0.518287, acc: 77.34%] [G loss: 2.773231]\n",
      "epoch:16 step:13247 [D loss: 0.551503, acc: 64.84%] [G loss: 3.829242]\n",
      "epoch:16 step:13248 [D loss: 0.314581, acc: 94.53%] [G loss: 2.768157]\n",
      "epoch:16 step:13249 [D loss: 0.256737, acc: 95.31%] [G loss: 4.498714]\n",
      "epoch:16 step:13250 [D loss: 0.682172, acc: 55.47%] [G loss: 2.662437]\n",
      "epoch:16 step:13251 [D loss: 0.738667, acc: 50.78%] [G loss: 2.855067]\n",
      "epoch:16 step:13252 [D loss: 0.698958, acc: 60.16%] [G loss: 3.104119]\n",
      "epoch:16 step:13253 [D loss: 0.311564, acc: 85.94%] [G loss: 3.418560]\n",
      "epoch:16 step:13254 [D loss: 0.365995, acc: 89.06%] [G loss: 3.837943]\n",
      "epoch:16 step:13255 [D loss: 1.213291, acc: 33.59%] [G loss: 2.193872]\n",
      "epoch:16 step:13256 [D loss: 0.985659, acc: 42.19%] [G loss: 2.104759]\n",
      "epoch:16 step:13257 [D loss: 0.597587, acc: 69.53%] [G loss: 2.671417]\n",
      "epoch:16 step:13258 [D loss: 0.844633, acc: 49.22%] [G loss: 2.113207]\n",
      "epoch:16 step:13259 [D loss: 0.320856, acc: 89.06%] [G loss: 2.358476]\n",
      "epoch:16 step:13260 [D loss: 0.430450, acc: 82.03%] [G loss: 2.460491]\n",
      "epoch:16 step:13261 [D loss: 0.709227, acc: 57.03%] [G loss: 2.055485]\n",
      "epoch:16 step:13262 [D loss: 0.347828, acc: 91.41%] [G loss: 2.589567]\n",
      "epoch:16 step:13263 [D loss: 0.549020, acc: 76.56%] [G loss: 2.536937]\n",
      "epoch:16 step:13264 [D loss: 0.368986, acc: 88.28%] [G loss: 2.626901]\n",
      "epoch:16 step:13265 [D loss: 0.919638, acc: 44.53%] [G loss: 1.991723]\n",
      "epoch:16 step:13266 [D loss: 0.608650, acc: 65.62%] [G loss: 2.970416]\n",
      "epoch:16 step:13267 [D loss: 0.591760, acc: 72.66%] [G loss: 2.973222]\n",
      "epoch:16 step:13268 [D loss: 0.498179, acc: 80.47%] [G loss: 2.517262]\n",
      "epoch:16 step:13269 [D loss: 0.406263, acc: 85.94%] [G loss: 2.729450]\n",
      "epoch:16 step:13270 [D loss: 0.385047, acc: 82.03%] [G loss: 2.259914]\n",
      "epoch:16 step:13271 [D loss: 0.480036, acc: 85.94%] [G loss: 2.251553]\n",
      "epoch:16 step:13272 [D loss: 0.400385, acc: 94.53%] [G loss: 2.349830]\n",
      "epoch:16 step:13273 [D loss: 0.887919, acc: 46.09%] [G loss: 2.087294]\n",
      "epoch:16 step:13274 [D loss: 0.717065, acc: 59.38%] [G loss: 2.116732]\n",
      "epoch:16 step:13275 [D loss: 0.439233, acc: 90.62%] [G loss: 2.474686]\n",
      "epoch:16 step:13276 [D loss: 0.658953, acc: 64.84%] [G loss: 2.461435]\n",
      "epoch:16 step:13277 [D loss: 0.560077, acc: 74.22%] [G loss: 3.969367]\n",
      "epoch:17 step:13278 [D loss: 0.353806, acc: 92.19%] [G loss: 3.148629]\n",
      "epoch:17 step:13279 [D loss: 0.488665, acc: 81.25%] [G loss: 2.420477]\n",
      "epoch:17 step:13280 [D loss: 0.706105, acc: 54.69%] [G loss: 2.183263]\n",
      "epoch:17 step:13281 [D loss: 0.476745, acc: 70.31%] [G loss: 2.452663]\n",
      "epoch:17 step:13282 [D loss: 0.269775, acc: 97.66%] [G loss: 3.024916]\n",
      "epoch:17 step:13283 [D loss: 0.903146, acc: 28.12%] [G loss: 2.233858]\n",
      "epoch:17 step:13284 [D loss: 0.702923, acc: 53.91%] [G loss: 2.644249]\n",
      "epoch:17 step:13285 [D loss: 0.877237, acc: 30.47%] [G loss: 2.086106]\n",
      "epoch:17 step:13286 [D loss: 0.280523, acc: 99.22%] [G loss: 2.792505]\n",
      "epoch:17 step:13287 [D loss: 0.476377, acc: 79.69%] [G loss: 3.129811]\n",
      "epoch:17 step:13288 [D loss: 0.454610, acc: 89.06%] [G loss: 3.449213]\n",
      "epoch:17 step:13289 [D loss: 0.499671, acc: 75.00%] [G loss: 2.109694]\n",
      "epoch:17 step:13290 [D loss: 0.435945, acc: 81.25%] [G loss: 2.917283]\n",
      "epoch:17 step:13291 [D loss: 0.485251, acc: 82.81%] [G loss: 2.944025]\n",
      "epoch:17 step:13292 [D loss: 0.975492, acc: 41.41%] [G loss: 2.362362]\n",
      "epoch:17 step:13293 [D loss: 0.815496, acc: 46.88%] [G loss: 2.030207]\n",
      "epoch:17 step:13294 [D loss: 0.254614, acc: 99.22%] [G loss: 2.616326]\n",
      "epoch:17 step:13295 [D loss: 0.634558, acc: 61.72%] [G loss: 2.977888]\n",
      "epoch:17 step:13296 [D loss: 1.096343, acc: 17.19%] [G loss: 2.325006]\n",
      "epoch:17 step:13297 [D loss: 0.797337, acc: 46.09%] [G loss: 1.684224]\n",
      "epoch:17 step:13298 [D loss: 0.723323, acc: 51.56%] [G loss: 2.686639]\n",
      "epoch:17 step:13299 [D loss: 0.483083, acc: 79.69%] [G loss: 2.537927]\n",
      "epoch:17 step:13300 [D loss: 0.607159, acc: 68.75%] [G loss: 1.991273]\n",
      "epoch:17 step:13301 [D loss: 0.694719, acc: 59.38%] [G loss: 2.051690]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:17 step:13302 [D loss: 1.153513, acc: 14.84%] [G loss: 2.064674]\n",
      "epoch:17 step:13303 [D loss: 0.335051, acc: 93.75%] [G loss: 2.306514]\n",
      "epoch:17 step:13304 [D loss: 0.628687, acc: 67.19%] [G loss: 1.822874]\n",
      "epoch:17 step:13305 [D loss: 0.541743, acc: 69.53%] [G loss: 2.469706]\n",
      "epoch:17 step:13306 [D loss: 0.666924, acc: 62.50%] [G loss: 2.643060]\n",
      "epoch:17 step:13307 [D loss: 0.363147, acc: 97.66%] [G loss: 2.219976]\n",
      "epoch:17 step:13308 [D loss: 0.362584, acc: 76.56%] [G loss: 2.243853]\n",
      "epoch:17 step:13309 [D loss: 0.633677, acc: 55.47%] [G loss: 2.395402]\n",
      "epoch:17 step:13310 [D loss: 0.768251, acc: 46.09%] [G loss: 1.988000]\n",
      "epoch:17 step:13311 [D loss: 0.360349, acc: 89.06%] [G loss: 2.719474]\n",
      "epoch:17 step:13312 [D loss: 0.443328, acc: 83.59%] [G loss: 2.372862]\n",
      "epoch:17 step:13313 [D loss: 0.348005, acc: 91.41%] [G loss: 2.796963]\n",
      "epoch:17 step:13314 [D loss: 0.556394, acc: 73.44%] [G loss: 2.365518]\n",
      "epoch:17 step:13315 [D loss: 0.788370, acc: 51.56%] [G loss: 2.658745]\n",
      "epoch:17 step:13316 [D loss: 0.507843, acc: 70.31%] [G loss: 2.696113]\n",
      "epoch:17 step:13317 [D loss: 0.662242, acc: 57.03%] [G loss: 2.084351]\n",
      "epoch:17 step:13318 [D loss: 0.214877, acc: 96.88%] [G loss: 2.960027]\n",
      "epoch:17 step:13319 [D loss: 0.482167, acc: 86.72%] [G loss: 2.726369]\n",
      "epoch:17 step:13320 [D loss: 0.227280, acc: 94.53%] [G loss: 2.246974]\n",
      "epoch:17 step:13321 [D loss: 0.267150, acc: 99.22%] [G loss: 2.802630]\n",
      "epoch:17 step:13322 [D loss: 0.250283, acc: 96.09%] [G loss: 3.108431]\n",
      "epoch:17 step:13323 [D loss: 0.654383, acc: 64.06%] [G loss: 3.334193]\n",
      "epoch:17 step:13324 [D loss: 0.730497, acc: 48.44%] [G loss: 1.939775]\n",
      "epoch:17 step:13325 [D loss: 0.220948, acc: 100.00%] [G loss: 3.454910]\n",
      "epoch:17 step:13326 [D loss: 0.793128, acc: 39.06%] [G loss: 2.352931]\n",
      "epoch:17 step:13327 [D loss: 0.759967, acc: 50.78%] [G loss: 2.434417]\n",
      "epoch:17 step:13328 [D loss: 0.380354, acc: 82.81%] [G loss: 2.330683]\n",
      "epoch:17 step:13329 [D loss: 0.563423, acc: 68.75%] [G loss: 2.178821]\n",
      "epoch:17 step:13330 [D loss: 0.312426, acc: 93.75%] [G loss: 1.820101]\n",
      "epoch:17 step:13331 [D loss: 0.898295, acc: 32.03%] [G loss: 2.190606]\n",
      "epoch:17 step:13332 [D loss: 0.690103, acc: 60.16%] [G loss: 2.556348]\n",
      "epoch:17 step:13333 [D loss: 0.240812, acc: 99.22%] [G loss: 2.686882]\n",
      "epoch:17 step:13334 [D loss: 0.558253, acc: 64.06%] [G loss: 2.529679]\n",
      "epoch:17 step:13335 [D loss: 0.390714, acc: 95.31%] [G loss: 1.839127]\n",
      "epoch:17 step:13336 [D loss: 0.621323, acc: 58.59%] [G loss: 2.996051]\n",
      "epoch:17 step:13337 [D loss: 0.576586, acc: 66.41%] [G loss: 2.573460]\n",
      "epoch:17 step:13338 [D loss: 0.341634, acc: 94.53%] [G loss: 2.541050]\n",
      "epoch:17 step:13339 [D loss: 1.024651, acc: 17.19%] [G loss: 2.419312]\n",
      "epoch:17 step:13340 [D loss: 0.858092, acc: 32.03%] [G loss: 2.698751]\n",
      "epoch:17 step:13341 [D loss: 0.371907, acc: 89.06%] [G loss: 2.635056]\n",
      "epoch:17 step:13342 [D loss: 0.659237, acc: 60.16%] [G loss: 3.991581]\n",
      "epoch:17 step:13343 [D loss: 0.896027, acc: 35.16%] [G loss: 2.242325]\n",
      "epoch:17 step:13344 [D loss: 0.576130, acc: 57.81%] [G loss: 3.749953]\n",
      "epoch:17 step:13345 [D loss: 0.425825, acc: 89.06%] [G loss: 2.853268]\n",
      "epoch:17 step:13346 [D loss: 0.430601, acc: 88.28%] [G loss: 2.534809]\n",
      "epoch:17 step:13347 [D loss: 0.512252, acc: 83.59%] [G loss: 3.011125]\n",
      "epoch:17 step:13348 [D loss: 0.621721, acc: 60.94%] [G loss: 2.292726]\n",
      "epoch:17 step:13349 [D loss: 0.413364, acc: 89.84%] [G loss: 2.247048]\n",
      "epoch:17 step:13350 [D loss: 0.723463, acc: 53.91%] [G loss: 2.571128]\n",
      "epoch:17 step:13351 [D loss: 0.449971, acc: 88.28%] [G loss: 2.750998]\n",
      "epoch:17 step:13352 [D loss: 0.364289, acc: 78.12%] [G loss: 4.964706]\n",
      "epoch:17 step:13353 [D loss: 1.260556, acc: 32.03%] [G loss: 2.072331]\n",
      "epoch:17 step:13354 [D loss: 0.850720, acc: 39.06%] [G loss: 2.253998]\n",
      "epoch:17 step:13355 [D loss: 0.648340, acc: 61.72%] [G loss: 2.260406]\n",
      "epoch:17 step:13356 [D loss: 0.293888, acc: 97.66%] [G loss: 2.740954]\n",
      "epoch:17 step:13357 [D loss: 0.378136, acc: 75.78%] [G loss: 2.910830]\n",
      "epoch:17 step:13358 [D loss: 0.603920, acc: 67.19%] [G loss: 2.662469]\n",
      "epoch:17 step:13359 [D loss: 0.344834, acc: 96.88%] [G loss: 1.816456]\n",
      "epoch:17 step:13360 [D loss: 0.400604, acc: 90.62%] [G loss: 2.373645]\n",
      "epoch:17 step:13361 [D loss: 0.678673, acc: 53.12%] [G loss: 2.312361]\n",
      "epoch:17 step:13362 [D loss: 0.512275, acc: 78.12%] [G loss: 3.299148]\n",
      "epoch:17 step:13363 [D loss: 0.476987, acc: 86.72%] [G loss: 2.220254]\n",
      "epoch:17 step:13364 [D loss: 0.661727, acc: 57.03%] [G loss: 2.094035]\n",
      "epoch:17 step:13365 [D loss: 0.716504, acc: 53.12%] [G loss: 2.412034]\n",
      "epoch:17 step:13366 [D loss: 0.309094, acc: 97.66%] [G loss: 2.790725]\n",
      "epoch:17 step:13367 [D loss: 0.784339, acc: 39.06%] [G loss: 2.479364]\n",
      "epoch:17 step:13368 [D loss: 0.648082, acc: 64.06%] [G loss: 2.647134]\n",
      "epoch:17 step:13369 [D loss: 0.345882, acc: 88.28%] [G loss: 2.367001]\n",
      "epoch:17 step:13370 [D loss: 0.808629, acc: 42.97%] [G loss: 2.710283]\n",
      "epoch:17 step:13371 [D loss: 0.738962, acc: 53.91%] [G loss: 1.442985]\n",
      "epoch:17 step:13372 [D loss: 0.264291, acc: 98.44%] [G loss: 2.304140]\n",
      "epoch:17 step:13373 [D loss: 0.886744, acc: 41.41%] [G loss: 2.086037]\n",
      "epoch:17 step:13374 [D loss: 0.493445, acc: 76.56%] [G loss: 2.692400]\n",
      "epoch:17 step:13375 [D loss: 0.331999, acc: 90.62%] [G loss: 2.800431]\n",
      "epoch:17 step:13376 [D loss: 0.302796, acc: 91.41%] [G loss: 3.909727]\n",
      "epoch:17 step:13377 [D loss: 0.262587, acc: 96.88%] [G loss: 2.794981]\n",
      "epoch:17 step:13378 [D loss: 0.898396, acc: 32.03%] [G loss: 2.017250]\n",
      "epoch:17 step:13379 [D loss: 0.590448, acc: 60.94%] [G loss: 2.579218]\n",
      "epoch:17 step:13380 [D loss: 0.648747, acc: 63.28%] [G loss: 2.955959]\n",
      "epoch:17 step:13381 [D loss: 0.575952, acc: 64.84%] [G loss: 2.489885]\n",
      "epoch:17 step:13382 [D loss: 0.643715, acc: 63.28%] [G loss: 2.811667]\n",
      "epoch:17 step:13383 [D loss: 0.609377, acc: 62.50%] [G loss: 2.583761]\n",
      "epoch:17 step:13384 [D loss: 0.840011, acc: 38.28%] [G loss: 3.118149]\n",
      "epoch:17 step:13385 [D loss: 0.460514, acc: 85.94%] [G loss: 2.812517]\n",
      "epoch:17 step:13386 [D loss: 0.351467, acc: 97.66%] [G loss: 2.351084]\n",
      "epoch:17 step:13387 [D loss: 0.612698, acc: 64.06%] [G loss: 2.866407]\n",
      "epoch:17 step:13388 [D loss: 0.511790, acc: 80.47%] [G loss: 2.620102]\n",
      "epoch:17 step:13389 [D loss: 0.356335, acc: 92.19%] [G loss: 3.073291]\n",
      "epoch:17 step:13390 [D loss: 0.735344, acc: 54.69%] [G loss: 2.359496]\n",
      "epoch:17 step:13391 [D loss: 0.805824, acc: 43.75%] [G loss: 2.848541]\n",
      "epoch:17 step:13392 [D loss: 0.762931, acc: 47.66%] [G loss: 1.794377]\n",
      "epoch:17 step:13393 [D loss: 0.834944, acc: 45.31%] [G loss: 2.002223]\n",
      "epoch:17 step:13394 [D loss: 0.452263, acc: 78.12%] [G loss: 2.018567]\n",
      "epoch:17 step:13395 [D loss: 0.737430, acc: 50.00%] [G loss: 2.798098]\n",
      "epoch:17 step:13396 [D loss: 0.643375, acc: 64.84%] [G loss: 2.943622]\n",
      "epoch:17 step:13397 [D loss: 0.399012, acc: 92.97%] [G loss: 2.893227]\n",
      "epoch:17 step:13398 [D loss: 0.585547, acc: 71.09%] [G loss: 2.072203]\n",
      "epoch:17 step:13399 [D loss: 0.269630, acc: 89.84%] [G loss: 3.615971]\n",
      "epoch:17 step:13400 [D loss: 0.347346, acc: 95.31%] [G loss: 3.102851]\n",
      "##############\n",
      "[0.86124982 0.87550969 0.81347695 0.79634331 0.78873551 0.83509483\n",
      " 0.88628527 0.81670896 0.80430692 0.84448131]\n",
      "##########\n",
      "epoch:17 step:13401 [D loss: 0.413764, acc: 86.72%] [G loss: 3.449166]\n",
      "epoch:17 step:13402 [D loss: 0.971006, acc: 21.88%] [G loss: 2.149224]\n",
      "epoch:17 step:13403 [D loss: 0.546229, acc: 78.12%] [G loss: 2.816098]\n",
      "epoch:17 step:13404 [D loss: 0.366825, acc: 89.84%] [G loss: 2.645331]\n",
      "epoch:17 step:13405 [D loss: 0.231716, acc: 100.00%] [G loss: 2.253585]\n",
      "epoch:17 step:13406 [D loss: 0.255076, acc: 97.66%] [G loss: 3.042272]\n",
      "epoch:17 step:13407 [D loss: 0.834395, acc: 39.84%] [G loss: 2.752735]\n",
      "epoch:17 step:13408 [D loss: 0.733720, acc: 49.22%] [G loss: 2.224598]\n",
      "epoch:17 step:13409 [D loss: 0.481884, acc: 81.25%] [G loss: 3.401799]\n",
      "epoch:17 step:13410 [D loss: 0.609899, acc: 55.47%] [G loss: 3.882739]\n",
      "epoch:17 step:13411 [D loss: 0.997913, acc: 50.00%] [G loss: 2.554923]\n",
      "epoch:17 step:13412 [D loss: 0.356760, acc: 92.19%] [G loss: 2.727411]\n",
      "epoch:17 step:13413 [D loss: 0.512645, acc: 80.47%] [G loss: 2.120966]\n",
      "epoch:17 step:13414 [D loss: 0.418903, acc: 84.38%] [G loss: 2.469009]\n",
      "epoch:17 step:13415 [D loss: 0.874613, acc: 36.72%] [G loss: 2.212775]\n",
      "epoch:17 step:13416 [D loss: 0.693774, acc: 56.25%] [G loss: 2.215311]\n",
      "epoch:17 step:13417 [D loss: 0.648252, acc: 63.28%] [G loss: 2.438630]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:17 step:13418 [D loss: 1.219570, acc: 12.50%] [G loss: 2.235400]\n",
      "epoch:17 step:13419 [D loss: 0.280028, acc: 97.66%] [G loss: 1.892374]\n",
      "epoch:17 step:13420 [D loss: 0.766697, acc: 46.09%] [G loss: 2.524546]\n",
      "epoch:17 step:13421 [D loss: 0.707206, acc: 54.69%] [G loss: 1.826116]\n",
      "epoch:17 step:13422 [D loss: 0.468671, acc: 83.59%] [G loss: 2.946048]\n",
      "epoch:17 step:13423 [D loss: 0.551676, acc: 78.91%] [G loss: 3.020704]\n",
      "epoch:17 step:13424 [D loss: 0.778106, acc: 42.97%] [G loss: 2.473584]\n",
      "epoch:17 step:13425 [D loss: 0.198570, acc: 99.22%] [G loss: 2.194978]\n",
      "epoch:17 step:13426 [D loss: 0.904553, acc: 31.25%] [G loss: 2.443756]\n",
      "epoch:17 step:13427 [D loss: 0.471920, acc: 81.25%] [G loss: 2.747732]\n",
      "epoch:17 step:13428 [D loss: 0.720641, acc: 52.34%] [G loss: 3.328578]\n",
      "epoch:17 step:13429 [D loss: 0.980615, acc: 19.53%] [G loss: 1.866583]\n",
      "epoch:17 step:13430 [D loss: 0.683966, acc: 58.59%] [G loss: 2.876528]\n",
      "epoch:17 step:13431 [D loss: 0.430930, acc: 88.28%] [G loss: 2.889485]\n",
      "epoch:17 step:13432 [D loss: 0.550859, acc: 80.47%] [G loss: 3.004658]\n",
      "epoch:17 step:13433 [D loss: 0.448405, acc: 75.78%] [G loss: 2.714779]\n",
      "epoch:17 step:13434 [D loss: 0.199424, acc: 98.44%] [G loss: 2.877619]\n",
      "epoch:17 step:13435 [D loss: 0.336915, acc: 95.31%] [G loss: 3.411529]\n",
      "epoch:17 step:13436 [D loss: 0.459380, acc: 75.00%] [G loss: 3.131254]\n",
      "epoch:17 step:13437 [D loss: 0.676371, acc: 63.28%] [G loss: 1.812722]\n",
      "epoch:17 step:13438 [D loss: 0.849567, acc: 43.75%] [G loss: 2.497896]\n",
      "epoch:17 step:13439 [D loss: 0.339620, acc: 87.50%] [G loss: 2.555996]\n",
      "epoch:17 step:13440 [D loss: 0.478716, acc: 82.81%] [G loss: 2.261931]\n",
      "epoch:17 step:13441 [D loss: 0.265834, acc: 99.22%] [G loss: 2.260736]\n",
      "epoch:17 step:13442 [D loss: 0.549595, acc: 73.44%] [G loss: 2.518335]\n",
      "epoch:17 step:13443 [D loss: 1.096190, acc: 18.75%] [G loss: 2.187188]\n",
      "epoch:17 step:13444 [D loss: 0.375973, acc: 92.97%] [G loss: 1.787133]\n",
      "epoch:17 step:13445 [D loss: 0.372248, acc: 92.97%] [G loss: 2.251883]\n",
      "epoch:17 step:13446 [D loss: 0.419614, acc: 90.62%] [G loss: 2.737238]\n",
      "epoch:17 step:13447 [D loss: 0.740461, acc: 53.12%] [G loss: 2.536199]\n",
      "epoch:17 step:13448 [D loss: 0.423900, acc: 70.31%] [G loss: 2.568791]\n",
      "epoch:17 step:13449 [D loss: 0.555322, acc: 69.53%] [G loss: 2.740247]\n",
      "epoch:17 step:13450 [D loss: 0.774537, acc: 48.44%] [G loss: 2.254158]\n",
      "epoch:17 step:13451 [D loss: 0.390758, acc: 90.62%] [G loss: 2.966643]\n",
      "epoch:17 step:13452 [D loss: 0.476548, acc: 78.12%] [G loss: 2.148767]\n",
      "epoch:17 step:13453 [D loss: 0.713857, acc: 46.09%] [G loss: 2.321578]\n",
      "epoch:17 step:13454 [D loss: 0.316057, acc: 95.31%] [G loss: 2.780195]\n",
      "epoch:17 step:13455 [D loss: 0.366687, acc: 85.94%] [G loss: 2.596082]\n",
      "epoch:17 step:13456 [D loss: 0.289012, acc: 91.41%] [G loss: 3.482183]\n",
      "epoch:17 step:13457 [D loss: 0.340360, acc: 85.16%] [G loss: 2.395996]\n",
      "epoch:17 step:13458 [D loss: 0.476283, acc: 75.00%] [G loss: 2.644130]\n",
      "epoch:17 step:13459 [D loss: 0.610940, acc: 62.50%] [G loss: 1.449067]\n",
      "epoch:17 step:13460 [D loss: 0.811839, acc: 53.91%] [G loss: 3.121192]\n",
      "epoch:17 step:13461 [D loss: 0.693084, acc: 55.47%] [G loss: 2.925851]\n",
      "epoch:17 step:13462 [D loss: 0.528967, acc: 64.84%] [G loss: 2.275391]\n",
      "epoch:17 step:13463 [D loss: 0.688109, acc: 56.25%] [G loss: 2.853890]\n",
      "epoch:17 step:13464 [D loss: 0.408689, acc: 85.94%] [G loss: 3.273772]\n",
      "epoch:17 step:13465 [D loss: 0.924334, acc: 30.47%] [G loss: 2.480797]\n",
      "epoch:17 step:13466 [D loss: 0.384838, acc: 92.97%] [G loss: 2.831725]\n",
      "epoch:17 step:13467 [D loss: 0.885891, acc: 50.00%] [G loss: 2.284948]\n",
      "epoch:17 step:13468 [D loss: 0.763626, acc: 52.34%] [G loss: 3.469417]\n",
      "epoch:17 step:13469 [D loss: 0.279411, acc: 89.06%] [G loss: 3.014212]\n",
      "epoch:17 step:13470 [D loss: 0.474233, acc: 80.47%] [G loss: 4.006381]\n",
      "epoch:17 step:13471 [D loss: 0.243685, acc: 100.00%] [G loss: 3.245897]\n",
      "epoch:17 step:13472 [D loss: 0.506976, acc: 75.00%] [G loss: 2.196622]\n",
      "epoch:17 step:13473 [D loss: 0.331172, acc: 89.84%] [G loss: 2.937000]\n",
      "epoch:17 step:13474 [D loss: 0.451066, acc: 84.38%] [G loss: 2.902818]\n",
      "epoch:17 step:13475 [D loss: 0.569964, acc: 70.31%] [G loss: 2.045522]\n",
      "epoch:17 step:13476 [D loss: 0.401674, acc: 89.06%] [G loss: 3.069031]\n",
      "epoch:17 step:13477 [D loss: 0.211261, acc: 96.88%] [G loss: 2.902677]\n",
      "epoch:17 step:13478 [D loss: 0.310959, acc: 91.41%] [G loss: 2.762965]\n",
      "epoch:17 step:13479 [D loss: 1.225575, acc: 16.41%] [G loss: 2.128928]\n",
      "epoch:17 step:13480 [D loss: 0.142705, acc: 100.00%] [G loss: 4.189739]\n",
      "epoch:17 step:13481 [D loss: 0.662373, acc: 57.81%] [G loss: 3.011397]\n",
      "epoch:17 step:13482 [D loss: 0.765716, acc: 48.44%] [G loss: 2.122025]\n",
      "epoch:17 step:13483 [D loss: 0.942379, acc: 41.41%] [G loss: 2.085626]\n",
      "epoch:17 step:13484 [D loss: 0.671943, acc: 55.47%] [G loss: 1.725189]\n",
      "epoch:17 step:13485 [D loss: 0.183512, acc: 99.22%] [G loss: 2.898030]\n",
      "epoch:17 step:13486 [D loss: 0.458856, acc: 87.50%] [G loss: 2.882934]\n",
      "epoch:17 step:13487 [D loss: 0.854854, acc: 36.72%] [G loss: 1.696758]\n",
      "epoch:17 step:13488 [D loss: 0.536940, acc: 76.56%] [G loss: 2.294200]\n",
      "epoch:17 step:13489 [D loss: 0.409021, acc: 91.41%] [G loss: 2.731329]\n",
      "epoch:17 step:13490 [D loss: 0.694057, acc: 55.47%] [G loss: 2.337283]\n",
      "epoch:17 step:13491 [D loss: 0.191202, acc: 99.22%] [G loss: 2.737633]\n",
      "epoch:17 step:13492 [D loss: 0.298722, acc: 98.44%] [G loss: 3.824311]\n",
      "epoch:17 step:13493 [D loss: 0.359086, acc: 89.84%] [G loss: 2.704607]\n",
      "epoch:17 step:13494 [D loss: 0.884260, acc: 33.59%] [G loss: 2.774265]\n",
      "epoch:17 step:13495 [D loss: 0.431985, acc: 85.16%] [G loss: 2.589173]\n",
      "epoch:17 step:13496 [D loss: 0.401628, acc: 82.03%] [G loss: 3.574207]\n",
      "epoch:17 step:13497 [D loss: 0.821820, acc: 50.00%] [G loss: 3.112126]\n",
      "epoch:17 step:13498 [D loss: 0.986163, acc: 23.44%] [G loss: 2.608772]\n",
      "epoch:17 step:13499 [D loss: 0.647951, acc: 62.50%] [G loss: 2.634458]\n",
      "epoch:17 step:13500 [D loss: 0.776414, acc: 46.09%] [G loss: 2.156399]\n",
      "epoch:17 step:13501 [D loss: 0.325715, acc: 90.62%] [G loss: 2.715005]\n",
      "epoch:17 step:13502 [D loss: 0.594022, acc: 63.28%] [G loss: 2.498055]\n",
      "epoch:17 step:13503 [D loss: 0.388206, acc: 96.09%] [G loss: 2.038545]\n",
      "epoch:17 step:13504 [D loss: 0.360870, acc: 92.97%] [G loss: 2.505382]\n",
      "epoch:17 step:13505 [D loss: 0.396331, acc: 90.62%] [G loss: 1.653327]\n",
      "epoch:17 step:13506 [D loss: 0.777223, acc: 43.75%] [G loss: 4.099738]\n",
      "epoch:17 step:13507 [D loss: 0.723097, acc: 45.31%] [G loss: 2.241916]\n",
      "epoch:17 step:13508 [D loss: 0.445771, acc: 77.34%] [G loss: 4.578089]\n",
      "epoch:17 step:13509 [D loss: 0.690724, acc: 56.25%] [G loss: 2.495353]\n",
      "epoch:17 step:13510 [D loss: 0.332862, acc: 94.53%] [G loss: 2.884507]\n",
      "epoch:17 step:13511 [D loss: 1.133548, acc: 14.06%] [G loss: 2.426751]\n",
      "epoch:17 step:13512 [D loss: 0.343100, acc: 82.03%] [G loss: 3.146921]\n",
      "epoch:17 step:13513 [D loss: 0.548284, acc: 72.66%] [G loss: 2.495725]\n",
      "epoch:17 step:13514 [D loss: 0.757979, acc: 53.12%] [G loss: 2.745553]\n",
      "epoch:17 step:13515 [D loss: 0.633044, acc: 59.38%] [G loss: 1.837791]\n",
      "epoch:17 step:13516 [D loss: 0.614107, acc: 69.53%] [G loss: 2.278456]\n",
      "epoch:17 step:13517 [D loss: 0.517111, acc: 78.12%] [G loss: 2.142020]\n",
      "epoch:17 step:13518 [D loss: 0.629575, acc: 58.59%] [G loss: 1.984004]\n",
      "epoch:17 step:13519 [D loss: 0.375673, acc: 94.53%] [G loss: 1.987103]\n",
      "epoch:17 step:13520 [D loss: 0.174203, acc: 99.22%] [G loss: 2.998627]\n",
      "epoch:17 step:13521 [D loss: 0.779057, acc: 46.09%] [G loss: 2.352679]\n",
      "epoch:17 step:13522 [D loss: 0.697634, acc: 52.34%] [G loss: 2.048487]\n",
      "epoch:17 step:13523 [D loss: 0.478658, acc: 84.38%] [G loss: 2.527488]\n",
      "epoch:17 step:13524 [D loss: 0.472919, acc: 78.91%] [G loss: 2.479923]\n",
      "epoch:17 step:13525 [D loss: 0.456650, acc: 82.81%] [G loss: 3.727190]\n",
      "epoch:17 step:13526 [D loss: 0.297079, acc: 95.31%] [G loss: 2.410149]\n",
      "epoch:17 step:13527 [D loss: 0.464723, acc: 79.69%] [G loss: 2.508771]\n",
      "epoch:17 step:13528 [D loss: 0.425571, acc: 73.44%] [G loss: 2.116993]\n",
      "epoch:17 step:13529 [D loss: 0.721709, acc: 53.91%] [G loss: 2.362447]\n",
      "epoch:17 step:13530 [D loss: 1.115602, acc: 18.75%] [G loss: 2.628111]\n",
      "epoch:17 step:13531 [D loss: 0.488237, acc: 73.44%] [G loss: 2.096405]\n",
      "epoch:17 step:13532 [D loss: 0.236667, acc: 99.22%] [G loss: 3.888913]\n",
      "epoch:17 step:13533 [D loss: 0.593693, acc: 67.97%] [G loss: 2.688658]\n",
      "epoch:17 step:13534 [D loss: 1.648869, acc: 2.34%] [G loss: 1.744554]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:17 step:13535 [D loss: 0.239788, acc: 95.31%] [G loss: 2.246135]\n",
      "epoch:17 step:13536 [D loss: 0.471086, acc: 73.44%] [G loss: 2.812288]\n",
      "epoch:17 step:13537 [D loss: 0.919558, acc: 49.22%] [G loss: 2.066504]\n",
      "epoch:17 step:13538 [D loss: 0.216306, acc: 94.53%] [G loss: 4.804772]\n",
      "epoch:17 step:13539 [D loss: 0.197826, acc: 99.22%] [G loss: 3.643369]\n",
      "epoch:17 step:13540 [D loss: 0.635105, acc: 64.06%] [G loss: 3.411206]\n",
      "epoch:17 step:13541 [D loss: 0.724212, acc: 46.88%] [G loss: 2.211519]\n",
      "epoch:17 step:13542 [D loss: 0.581020, acc: 75.78%] [G loss: 2.742999]\n",
      "epoch:17 step:13543 [D loss: 0.163491, acc: 99.22%] [G loss: 3.383843]\n",
      "epoch:17 step:13544 [D loss: 0.967528, acc: 28.91%] [G loss: 2.183961]\n",
      "epoch:17 step:13545 [D loss: 0.696055, acc: 55.47%] [G loss: 3.034720]\n",
      "epoch:17 step:13546 [D loss: 0.586681, acc: 57.81%] [G loss: 2.439089]\n",
      "epoch:17 step:13547 [D loss: 0.317686, acc: 95.31%] [G loss: 3.657645]\n",
      "epoch:17 step:13548 [D loss: 0.528355, acc: 67.19%] [G loss: 2.783304]\n",
      "epoch:17 step:13549 [D loss: 0.715711, acc: 53.12%] [G loss: 2.898785]\n",
      "epoch:17 step:13550 [D loss: 0.524323, acc: 76.56%] [G loss: 2.052430]\n",
      "epoch:17 step:13551 [D loss: 0.854308, acc: 35.94%] [G loss: 2.508756]\n",
      "epoch:17 step:13552 [D loss: 0.582792, acc: 63.28%] [G loss: 2.361680]\n",
      "epoch:17 step:13553 [D loss: 0.463260, acc: 83.59%] [G loss: 3.103234]\n",
      "epoch:17 step:13554 [D loss: 0.777586, acc: 39.84%] [G loss: 1.606103]\n",
      "epoch:17 step:13555 [D loss: 0.508800, acc: 79.69%] [G loss: 2.697785]\n",
      "epoch:17 step:13556 [D loss: 0.774122, acc: 53.12%] [G loss: 2.736535]\n",
      "epoch:17 step:13557 [D loss: 0.243980, acc: 97.66%] [G loss: 2.319103]\n",
      "epoch:17 step:13558 [D loss: 0.608764, acc: 67.19%] [G loss: 2.115550]\n",
      "epoch:17 step:13559 [D loss: 0.179709, acc: 100.00%] [G loss: 3.114492]\n",
      "epoch:17 step:13560 [D loss: 0.492574, acc: 66.41%] [G loss: 2.525762]\n",
      "epoch:17 step:13561 [D loss: 0.498319, acc: 69.53%] [G loss: 3.097412]\n",
      "epoch:17 step:13562 [D loss: 0.320081, acc: 87.50%] [G loss: 2.774668]\n",
      "epoch:17 step:13563 [D loss: 0.447222, acc: 85.94%] [G loss: 2.683094]\n",
      "epoch:17 step:13564 [D loss: 0.427464, acc: 89.06%] [G loss: 3.170984]\n",
      "epoch:17 step:13565 [D loss: 0.409285, acc: 88.28%] [G loss: 2.725790]\n",
      "epoch:17 step:13566 [D loss: 0.807705, acc: 48.44%] [G loss: 1.727018]\n",
      "epoch:17 step:13567 [D loss: 0.747543, acc: 43.75%] [G loss: 1.570859]\n",
      "epoch:17 step:13568 [D loss: 0.988766, acc: 52.34%] [G loss: 2.270201]\n",
      "epoch:17 step:13569 [D loss: 0.872686, acc: 49.22%] [G loss: 2.478294]\n",
      "epoch:17 step:13570 [D loss: 0.316023, acc: 93.75%] [G loss: 2.588581]\n",
      "epoch:17 step:13571 [D loss: 0.765253, acc: 51.56%] [G loss: 1.955720]\n",
      "epoch:17 step:13572 [D loss: 0.362361, acc: 93.75%] [G loss: 3.108185]\n",
      "epoch:17 step:13573 [D loss: 0.345491, acc: 94.53%] [G loss: 2.692300]\n",
      "epoch:17 step:13574 [D loss: 0.520118, acc: 73.44%] [G loss: 3.226916]\n",
      "epoch:17 step:13575 [D loss: 1.115713, acc: 18.75%] [G loss: 2.129862]\n",
      "epoch:17 step:13576 [D loss: 0.390846, acc: 86.72%] [G loss: 1.912730]\n",
      "epoch:17 step:13577 [D loss: 0.700057, acc: 58.59%] [G loss: 2.700052]\n",
      "epoch:17 step:13578 [D loss: 0.420327, acc: 83.59%] [G loss: 2.834243]\n",
      "epoch:17 step:13579 [D loss: 0.576917, acc: 71.88%] [G loss: 2.144718]\n",
      "epoch:17 step:13580 [D loss: 0.544306, acc: 81.25%] [G loss: 2.705743]\n",
      "epoch:17 step:13581 [D loss: 0.178630, acc: 98.44%] [G loss: 4.158313]\n",
      "epoch:17 step:13582 [D loss: 0.226179, acc: 100.00%] [G loss: 3.262018]\n",
      "epoch:17 step:13583 [D loss: 0.272665, acc: 99.22%] [G loss: 2.928665]\n",
      "epoch:17 step:13584 [D loss: 0.578344, acc: 71.88%] [G loss: 2.588159]\n",
      "epoch:17 step:13585 [D loss: 0.738474, acc: 51.56%] [G loss: 3.047384]\n",
      "epoch:17 step:13586 [D loss: 0.326137, acc: 92.97%] [G loss: 2.979579]\n",
      "epoch:17 step:13587 [D loss: 0.135267, acc: 100.00%] [G loss: 2.361448]\n",
      "epoch:17 step:13588 [D loss: 0.422921, acc: 85.94%] [G loss: 2.810131]\n",
      "epoch:17 step:13589 [D loss: 0.377936, acc: 90.62%] [G loss: 2.945062]\n",
      "epoch:17 step:13590 [D loss: 0.208659, acc: 99.22%] [G loss: 3.579051]\n",
      "epoch:17 step:13591 [D loss: 0.364083, acc: 93.75%] [G loss: 2.582069]\n",
      "epoch:17 step:13592 [D loss: 1.511624, acc: 6.25%] [G loss: 1.981045]\n",
      "epoch:17 step:13593 [D loss: 0.632623, acc: 60.94%] [G loss: 2.053185]\n",
      "epoch:17 step:13594 [D loss: 0.461013, acc: 78.12%] [G loss: 2.675151]\n",
      "epoch:17 step:13595 [D loss: 0.459020, acc: 83.59%] [G loss: 2.295003]\n",
      "epoch:17 step:13596 [D loss: 0.481496, acc: 78.91%] [G loss: 3.323298]\n",
      "epoch:17 step:13597 [D loss: 0.779653, acc: 51.56%] [G loss: 2.524852]\n",
      "epoch:17 step:13598 [D loss: 0.858683, acc: 48.44%] [G loss: 2.051353]\n",
      "epoch:17 step:13599 [D loss: 0.528508, acc: 76.56%] [G loss: 2.267477]\n",
      "epoch:17 step:13600 [D loss: 0.680806, acc: 55.47%] [G loss: 1.863472]\n",
      "##############\n",
      "[0.87228107 0.86223838 0.8173044  0.81226642 0.82066873 0.79658132\n",
      " 0.89713827 0.82660781 0.81219071 0.84085352]\n",
      "##########\n",
      "epoch:17 step:13601 [D loss: 0.596764, acc: 59.38%] [G loss: 2.677289]\n",
      "epoch:17 step:13602 [D loss: 0.469487, acc: 87.50%] [G loss: 2.319453]\n",
      "epoch:17 step:13603 [D loss: 0.473345, acc: 85.16%] [G loss: 2.478463]\n",
      "epoch:17 step:13604 [D loss: 0.306240, acc: 88.28%] [G loss: 2.116120]\n",
      "epoch:17 step:13605 [D loss: 0.227980, acc: 98.44%] [G loss: 2.307781]\n",
      "epoch:17 step:13606 [D loss: 0.851078, acc: 50.00%] [G loss: 2.873299]\n",
      "epoch:17 step:13607 [D loss: 0.528895, acc: 73.44%] [G loss: 2.214169]\n",
      "epoch:17 step:13608 [D loss: 0.466982, acc: 66.41%] [G loss: 1.608759]\n",
      "epoch:17 step:13609 [D loss: 0.746592, acc: 46.88%] [G loss: 1.575707]\n",
      "epoch:17 step:13610 [D loss: 0.196186, acc: 97.66%] [G loss: 2.427711]\n",
      "epoch:17 step:13611 [D loss: 0.898356, acc: 45.31%] [G loss: 3.231479]\n",
      "epoch:17 step:13612 [D loss: 0.124464, acc: 100.00%] [G loss: 2.876821]\n",
      "epoch:17 step:13613 [D loss: 0.292357, acc: 96.88%] [G loss: 3.321205]\n",
      "epoch:17 step:13614 [D loss: 1.147587, acc: 23.44%] [G loss: 1.557900]\n",
      "epoch:17 step:13615 [D loss: 1.016944, acc: 43.75%] [G loss: 2.763292]\n",
      "epoch:17 step:13616 [D loss: 0.424429, acc: 90.62%] [G loss: 2.902668]\n",
      "epoch:17 step:13617 [D loss: 1.039427, acc: 28.12%] [G loss: 2.052541]\n",
      "epoch:17 step:13618 [D loss: 0.450110, acc: 84.38%] [G loss: 3.037536]\n",
      "epoch:17 step:13619 [D loss: 0.560271, acc: 68.75%] [G loss: 2.568291]\n",
      "epoch:17 step:13620 [D loss: 0.316165, acc: 95.31%] [G loss: 2.550297]\n",
      "epoch:17 step:13621 [D loss: 0.724800, acc: 55.47%] [G loss: 2.572278]\n",
      "epoch:17 step:13622 [D loss: 0.432644, acc: 85.16%] [G loss: 2.784595]\n",
      "epoch:17 step:13623 [D loss: 0.664134, acc: 58.59%] [G loss: 2.715861]\n",
      "epoch:17 step:13624 [D loss: 0.482528, acc: 78.91%] [G loss: 3.011549]\n",
      "epoch:17 step:13625 [D loss: 0.655805, acc: 59.38%] [G loss: 2.184903]\n",
      "epoch:17 step:13626 [D loss: 1.234316, acc: 13.28%] [G loss: 2.351198]\n",
      "epoch:17 step:13627 [D loss: 0.404708, acc: 88.28%] [G loss: 2.981052]\n",
      "epoch:17 step:13628 [D loss: 0.784012, acc: 45.31%] [G loss: 3.410141]\n",
      "epoch:17 step:13629 [D loss: 0.548380, acc: 78.91%] [G loss: 2.589908]\n",
      "epoch:17 step:13630 [D loss: 0.709390, acc: 54.69%] [G loss: 2.123770]\n",
      "epoch:17 step:13631 [D loss: 0.640037, acc: 57.81%] [G loss: 2.013931]\n",
      "epoch:17 step:13632 [D loss: 0.470120, acc: 81.25%] [G loss: 3.209913]\n",
      "epoch:17 step:13633 [D loss: 0.841240, acc: 50.78%] [G loss: 2.667001]\n",
      "epoch:17 step:13634 [D loss: 0.543872, acc: 71.09%] [G loss: 2.588218]\n",
      "epoch:17 step:13635 [D loss: 0.557778, acc: 75.00%] [G loss: 3.080598]\n",
      "epoch:17 step:13636 [D loss: 0.455153, acc: 83.59%] [G loss: 1.819233]\n",
      "epoch:17 step:13637 [D loss: 0.517307, acc: 77.34%] [G loss: 2.242754]\n",
      "epoch:17 step:13638 [D loss: 0.391735, acc: 86.72%] [G loss: 3.400935]\n",
      "epoch:17 step:13639 [D loss: 0.206121, acc: 100.00%] [G loss: 2.842497]\n",
      "epoch:17 step:13640 [D loss: 0.754658, acc: 44.53%] [G loss: 1.869550]\n",
      "epoch:17 step:13641 [D loss: 0.506721, acc: 79.69%] [G loss: 2.112278]\n",
      "epoch:17 step:13642 [D loss: 0.897465, acc: 47.66%] [G loss: 2.910637]\n",
      "epoch:17 step:13643 [D loss: 0.967967, acc: 35.16%] [G loss: 3.273918]\n",
      "epoch:17 step:13644 [D loss: 0.492596, acc: 84.38%] [G loss: 2.654028]\n",
      "epoch:17 step:13645 [D loss: 0.169488, acc: 100.00%] [G loss: 4.132458]\n",
      "epoch:17 step:13646 [D loss: 0.296491, acc: 96.88%] [G loss: 3.037177]\n",
      "epoch:17 step:13647 [D loss: 0.385473, acc: 84.38%] [G loss: 2.651707]\n",
      "epoch:17 step:13648 [D loss: 0.467158, acc: 86.72%] [G loss: 2.365937]\n",
      "epoch:17 step:13649 [D loss: 0.326502, acc: 95.31%] [G loss: 2.634619]\n",
      "epoch:17 step:13650 [D loss: 1.002735, acc: 28.91%] [G loss: 3.467983]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:17 step:13651 [D loss: 0.491431, acc: 82.03%] [G loss: 2.638344]\n",
      "epoch:17 step:13652 [D loss: 0.308022, acc: 97.66%] [G loss: 3.033995]\n",
      "epoch:17 step:13653 [D loss: 0.366833, acc: 84.38%] [G loss: 4.286927]\n",
      "epoch:17 step:13654 [D loss: 0.531463, acc: 82.03%] [G loss: 2.127688]\n",
      "epoch:17 step:13655 [D loss: 0.580823, acc: 69.53%] [G loss: 2.789627]\n",
      "epoch:17 step:13656 [D loss: 0.314203, acc: 95.31%] [G loss: 2.780265]\n",
      "epoch:17 step:13657 [D loss: 0.274466, acc: 92.97%] [G loss: 3.295357]\n",
      "epoch:17 step:13658 [D loss: 0.300820, acc: 87.50%] [G loss: 3.645946]\n",
      "epoch:17 step:13659 [D loss: 0.271204, acc: 96.88%] [G loss: 2.880008]\n",
      "epoch:17 step:13660 [D loss: 0.466104, acc: 71.09%] [G loss: 3.155531]\n",
      "epoch:17 step:13661 [D loss: 0.470073, acc: 84.38%] [G loss: 1.932664]\n",
      "epoch:17 step:13662 [D loss: 0.667156, acc: 57.03%] [G loss: 2.760103]\n",
      "epoch:17 step:13663 [D loss: 0.355156, acc: 81.25%] [G loss: 3.332554]\n",
      "epoch:17 step:13664 [D loss: 0.430341, acc: 81.25%] [G loss: 2.501806]\n",
      "epoch:17 step:13665 [D loss: 1.026417, acc: 45.31%] [G loss: 2.343650]\n",
      "epoch:17 step:13666 [D loss: 0.518032, acc: 68.75%] [G loss: 2.469581]\n",
      "epoch:17 step:13667 [D loss: 0.760588, acc: 51.56%] [G loss: 2.180958]\n",
      "epoch:17 step:13668 [D loss: 1.432313, acc: 29.69%] [G loss: 1.521595]\n",
      "epoch:17 step:13669 [D loss: 0.368353, acc: 92.97%] [G loss: 2.086331]\n",
      "epoch:17 step:13670 [D loss: 0.938409, acc: 50.00%] [G loss: 2.174440]\n",
      "epoch:17 step:13671 [D loss: 0.337576, acc: 93.75%] [G loss: 3.394664]\n",
      "epoch:17 step:13672 [D loss: 0.528534, acc: 65.62%] [G loss: 2.616937]\n",
      "epoch:17 step:13673 [D loss: 0.579749, acc: 57.03%] [G loss: 2.980001]\n",
      "epoch:17 step:13674 [D loss: 0.676266, acc: 55.47%] [G loss: 2.137922]\n",
      "epoch:17 step:13675 [D loss: 0.621877, acc: 62.50%] [G loss: 2.062103]\n",
      "epoch:17 step:13676 [D loss: 0.858590, acc: 45.31%] [G loss: 2.354100]\n",
      "epoch:17 step:13677 [D loss: 0.165505, acc: 99.22%] [G loss: 4.340194]\n",
      "epoch:17 step:13678 [D loss: 0.278548, acc: 96.88%] [G loss: 3.365837]\n",
      "epoch:17 step:13679 [D loss: 0.523956, acc: 80.47%] [G loss: 2.798652]\n",
      "epoch:17 step:13680 [D loss: 0.418076, acc: 86.72%] [G loss: 2.613181]\n",
      "epoch:17 step:13681 [D loss: 0.510358, acc: 72.66%] [G loss: 2.631099]\n",
      "epoch:17 step:13682 [D loss: 0.403960, acc: 87.50%] [G loss: 1.869617]\n",
      "epoch:17 step:13683 [D loss: 0.309258, acc: 96.88%] [G loss: 2.791335]\n",
      "epoch:17 step:13684 [D loss: 0.735190, acc: 51.56%] [G loss: 2.832587]\n",
      "epoch:17 step:13685 [D loss: 0.272114, acc: 96.88%] [G loss: 2.856834]\n",
      "epoch:17 step:13686 [D loss: 0.877929, acc: 37.50%] [G loss: 2.302511]\n",
      "epoch:17 step:13687 [D loss: 0.345870, acc: 92.19%] [G loss: 3.206558]\n",
      "epoch:17 step:13688 [D loss: 1.029540, acc: 44.53%] [G loss: 3.380455]\n",
      "epoch:17 step:13689 [D loss: 0.404924, acc: 78.91%] [G loss: 3.500262]\n",
      "epoch:17 step:13690 [D loss: 0.431870, acc: 84.38%] [G loss: 2.425756]\n",
      "epoch:17 step:13691 [D loss: 0.334743, acc: 95.31%] [G loss: 3.422504]\n",
      "epoch:17 step:13692 [D loss: 0.921836, acc: 24.22%] [G loss: 2.548230]\n",
      "epoch:17 step:13693 [D loss: 0.386232, acc: 96.09%] [G loss: 2.846612]\n",
      "epoch:17 step:13694 [D loss: 0.997807, acc: 50.78%] [G loss: 1.998892]\n",
      "epoch:17 step:13695 [D loss: 0.486001, acc: 67.19%] [G loss: 3.424671]\n",
      "epoch:17 step:13696 [D loss: 0.194550, acc: 99.22%] [G loss: 3.742780]\n",
      "epoch:17 step:13697 [D loss: 0.550574, acc: 79.69%] [G loss: 2.004253]\n",
      "epoch:17 step:13698 [D loss: 0.447996, acc: 76.56%] [G loss: 3.550098]\n",
      "epoch:17 step:13699 [D loss: 0.539699, acc: 78.91%] [G loss: 3.440815]\n",
      "epoch:17 step:13700 [D loss: 1.014408, acc: 26.56%] [G loss: 2.706170]\n",
      "epoch:17 step:13701 [D loss: 0.339924, acc: 90.62%] [G loss: 2.501650]\n",
      "epoch:17 step:13702 [D loss: 0.611296, acc: 58.59%] [G loss: 3.002747]\n",
      "epoch:17 step:13703 [D loss: 0.585540, acc: 60.16%] [G loss: 2.165817]\n",
      "epoch:17 step:13704 [D loss: 0.412201, acc: 86.72%] [G loss: 2.652261]\n",
      "epoch:17 step:13705 [D loss: 0.314368, acc: 80.47%] [G loss: 2.661298]\n",
      "epoch:17 step:13706 [D loss: 0.295153, acc: 94.53%] [G loss: 3.522421]\n",
      "epoch:17 step:13707 [D loss: 0.601096, acc: 61.72%] [G loss: 1.738339]\n",
      "epoch:17 step:13708 [D loss: 0.531214, acc: 68.75%] [G loss: 2.016135]\n",
      "epoch:17 step:13709 [D loss: 0.502704, acc: 78.91%] [G loss: 2.740895]\n",
      "epoch:17 step:13710 [D loss: 0.166599, acc: 98.44%] [G loss: 4.069246]\n",
      "epoch:17 step:13711 [D loss: 0.353326, acc: 89.84%] [G loss: 2.831913]\n",
      "epoch:17 step:13712 [D loss: 0.929629, acc: 50.00%] [G loss: 2.667906]\n",
      "epoch:17 step:13713 [D loss: 0.914375, acc: 38.28%] [G loss: 2.377046]\n",
      "epoch:17 step:13714 [D loss: 1.611799, acc: 3.12%] [G loss: 2.140545]\n",
      "epoch:17 step:13715 [D loss: 0.526883, acc: 78.91%] [G loss: 2.298493]\n",
      "epoch:17 step:13716 [D loss: 0.602918, acc: 64.06%] [G loss: 2.259985]\n",
      "epoch:17 step:13717 [D loss: 0.366426, acc: 93.75%] [G loss: 2.809228]\n",
      "epoch:17 step:13718 [D loss: 0.384789, acc: 92.19%] [G loss: 3.098221]\n",
      "epoch:17 step:13719 [D loss: 0.482501, acc: 80.47%] [G loss: 2.759748]\n",
      "epoch:17 step:13720 [D loss: 0.600603, acc: 71.88%] [G loss: 2.984049]\n",
      "epoch:17 step:13721 [D loss: 0.389824, acc: 92.19%] [G loss: 2.359629]\n",
      "epoch:17 step:13722 [D loss: 0.630746, acc: 64.06%] [G loss: 1.452648]\n",
      "epoch:17 step:13723 [D loss: 0.525674, acc: 77.34%] [G loss: 2.499049]\n",
      "epoch:17 step:13724 [D loss: 0.713561, acc: 50.78%] [G loss: 1.975777]\n",
      "epoch:17 step:13725 [D loss: 0.515068, acc: 80.47%] [G loss: 3.155951]\n",
      "epoch:17 step:13726 [D loss: 0.643900, acc: 66.41%] [G loss: 2.676870]\n",
      "epoch:17 step:13727 [D loss: 0.470475, acc: 67.97%] [G loss: 2.467596]\n",
      "epoch:17 step:13728 [D loss: 0.209298, acc: 100.00%] [G loss: 4.093314]\n",
      "epoch:17 step:13729 [D loss: 0.477527, acc: 84.38%] [G loss: 2.570793]\n",
      "epoch:17 step:13730 [D loss: 0.632188, acc: 61.72%] [G loss: 1.929694]\n",
      "epoch:17 step:13731 [D loss: 0.460979, acc: 76.56%] [G loss: 2.340328]\n",
      "epoch:17 step:13732 [D loss: 0.313285, acc: 93.75%] [G loss: 3.872363]\n",
      "epoch:17 step:13733 [D loss: 1.050108, acc: 15.62%] [G loss: 1.981891]\n",
      "epoch:17 step:13734 [D loss: 0.467668, acc: 85.16%] [G loss: 2.106034]\n",
      "epoch:17 step:13735 [D loss: 0.831360, acc: 50.00%] [G loss: 2.042517]\n",
      "epoch:17 step:13736 [D loss: 0.419220, acc: 89.84%] [G loss: 2.049423]\n",
      "epoch:17 step:13737 [D loss: 0.454685, acc: 84.38%] [G loss: 3.327523]\n",
      "epoch:17 step:13738 [D loss: 0.453284, acc: 89.06%] [G loss: 2.302430]\n",
      "epoch:17 step:13739 [D loss: 0.499449, acc: 60.94%] [G loss: 5.426198]\n",
      "epoch:17 step:13740 [D loss: 0.265412, acc: 97.66%] [G loss: 3.159372]\n",
      "epoch:17 step:13741 [D loss: 0.382145, acc: 81.25%] [G loss: 2.939310]\n",
      "epoch:17 step:13742 [D loss: 0.350742, acc: 92.97%] [G loss: 2.761952]\n",
      "epoch:17 step:13743 [D loss: 0.345680, acc: 87.50%] [G loss: 3.332269]\n",
      "epoch:17 step:13744 [D loss: 1.207623, acc: 39.06%] [G loss: 2.656054]\n",
      "epoch:17 step:13745 [D loss: 0.593393, acc: 72.66%] [G loss: 2.503427]\n",
      "epoch:17 step:13746 [D loss: 1.002590, acc: 49.22%] [G loss: 2.072834]\n",
      "epoch:17 step:13747 [D loss: 0.418858, acc: 79.69%] [G loss: 3.523426]\n",
      "epoch:17 step:13748 [D loss: 1.216065, acc: 13.28%] [G loss: 2.181431]\n",
      "epoch:17 step:13749 [D loss: 0.666877, acc: 57.81%] [G loss: 2.615498]\n",
      "epoch:17 step:13750 [D loss: 0.901222, acc: 44.53%] [G loss: 3.039481]\n",
      "epoch:17 step:13751 [D loss: 0.471210, acc: 74.22%] [G loss: 2.273404]\n",
      "epoch:17 step:13752 [D loss: 0.264821, acc: 98.44%] [G loss: 2.818274]\n",
      "epoch:17 step:13753 [D loss: 0.247043, acc: 96.88%] [G loss: 3.409513]\n",
      "epoch:17 step:13754 [D loss: 0.294528, acc: 95.31%] [G loss: 3.343955]\n",
      "epoch:17 step:13755 [D loss: 0.332858, acc: 96.09%] [G loss: 3.274312]\n",
      "epoch:17 step:13756 [D loss: 0.697806, acc: 51.56%] [G loss: 3.036496]\n",
      "epoch:17 step:13757 [D loss: 0.307674, acc: 96.09%] [G loss: 3.051597]\n",
      "epoch:17 step:13758 [D loss: 0.551338, acc: 78.12%] [G loss: 2.745431]\n",
      "epoch:17 step:13759 [D loss: 0.722700, acc: 54.69%] [G loss: 1.872137]\n",
      "epoch:17 step:13760 [D loss: 0.377661, acc: 82.03%] [G loss: 3.012808]\n",
      "epoch:17 step:13761 [D loss: 0.752948, acc: 52.34%] [G loss: 2.339594]\n",
      "epoch:17 step:13762 [D loss: 0.383685, acc: 92.19%] [G loss: 2.028142]\n",
      "epoch:17 step:13763 [D loss: 0.409272, acc: 85.94%] [G loss: 3.522594]\n",
      "epoch:17 step:13764 [D loss: 0.449490, acc: 74.22%] [G loss: 2.106300]\n",
      "epoch:17 step:13765 [D loss: 0.384600, acc: 90.62%] [G loss: 2.714161]\n",
      "epoch:17 step:13766 [D loss: 0.295534, acc: 85.94%] [G loss: 3.349089]\n",
      "epoch:17 step:13767 [D loss: 0.421455, acc: 84.38%] [G loss: 2.386083]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:17 step:13768 [D loss: 0.603819, acc: 70.31%] [G loss: 2.433749]\n",
      "epoch:17 step:13769 [D loss: 0.597459, acc: 66.41%] [G loss: 3.060279]\n",
      "epoch:17 step:13770 [D loss: 0.134599, acc: 99.22%] [G loss: 3.386495]\n",
      "epoch:17 step:13771 [D loss: 0.552271, acc: 74.22%] [G loss: 2.445752]\n",
      "epoch:17 step:13772 [D loss: 0.469756, acc: 87.50%] [G loss: 3.164364]\n",
      "epoch:17 step:13773 [D loss: 0.348685, acc: 95.31%] [G loss: 2.686409]\n",
      "epoch:17 step:13774 [D loss: 0.608302, acc: 67.97%] [G loss: 2.868777]\n",
      "epoch:17 step:13775 [D loss: 0.491338, acc: 83.59%] [G loss: 2.608270]\n",
      "epoch:17 step:13776 [D loss: 0.645302, acc: 65.62%] [G loss: 2.707306]\n",
      "epoch:17 step:13777 [D loss: 0.412159, acc: 89.06%] [G loss: 2.629885]\n",
      "epoch:17 step:13778 [D loss: 0.673221, acc: 54.69%] [G loss: 4.041599]\n",
      "epoch:17 step:13779 [D loss: 0.412015, acc: 89.84%] [G loss: 3.356641]\n",
      "epoch:17 step:13780 [D loss: 0.667021, acc: 58.59%] [G loss: 3.290925]\n",
      "epoch:17 step:13781 [D loss: 0.315807, acc: 91.41%] [G loss: 2.697220]\n",
      "epoch:17 step:13782 [D loss: 1.201574, acc: 31.25%] [G loss: 1.345746]\n",
      "epoch:17 step:13783 [D loss: 0.369671, acc: 92.19%] [G loss: 1.985101]\n",
      "epoch:17 step:13784 [D loss: 0.824136, acc: 49.22%] [G loss: 2.512834]\n",
      "epoch:17 step:13785 [D loss: 0.903433, acc: 30.47%] [G loss: 2.264257]\n",
      "epoch:17 step:13786 [D loss: 0.211980, acc: 96.09%] [G loss: 2.852454]\n",
      "epoch:17 step:13787 [D loss: 0.655245, acc: 60.94%] [G loss: 2.200011]\n",
      "epoch:17 step:13788 [D loss: 0.442404, acc: 78.91%] [G loss: 2.726943]\n",
      "epoch:17 step:13789 [D loss: 0.622151, acc: 65.62%] [G loss: 3.157876]\n",
      "epoch:17 step:13790 [D loss: 0.707475, acc: 57.03%] [G loss: 3.351989]\n",
      "epoch:17 step:13791 [D loss: 0.536338, acc: 61.72%] [G loss: 2.937193]\n",
      "epoch:17 step:13792 [D loss: 0.751192, acc: 50.78%] [G loss: 2.003762]\n",
      "epoch:17 step:13793 [D loss: 0.781784, acc: 47.66%] [G loss: 2.383497]\n",
      "epoch:17 step:13794 [D loss: 0.251921, acc: 96.88%] [G loss: 2.892902]\n",
      "epoch:17 step:13795 [D loss: 0.415903, acc: 88.28%] [G loss: 2.319773]\n",
      "epoch:17 step:13796 [D loss: 0.601740, acc: 60.94%] [G loss: 3.219055]\n",
      "epoch:17 step:13797 [D loss: 0.789717, acc: 50.78%] [G loss: 2.627186]\n",
      "epoch:17 step:13798 [D loss: 0.291620, acc: 91.41%] [G loss: 2.574339]\n",
      "epoch:17 step:13799 [D loss: 0.646225, acc: 59.38%] [G loss: 3.235480]\n",
      "epoch:17 step:13800 [D loss: 0.284503, acc: 92.97%] [G loss: 3.437534]\n",
      "##############\n",
      "[0.84976792 0.86983033 0.79487209 0.81418077 0.79608223 0.80645612\n",
      " 0.88178561 0.8352829  0.81707382 0.8321684 ]\n",
      "##########\n",
      "epoch:17 step:13801 [D loss: 0.516138, acc: 78.91%] [G loss: 2.819304]\n",
      "epoch:17 step:13802 [D loss: 0.979530, acc: 18.75%] [G loss: 2.762564]\n",
      "epoch:17 step:13803 [D loss: 0.910353, acc: 38.28%] [G loss: 2.463082]\n",
      "epoch:17 step:13804 [D loss: 0.336526, acc: 90.62%] [G loss: 3.585620]\n",
      "epoch:17 step:13805 [D loss: 0.773841, acc: 50.00%] [G loss: 3.015410]\n",
      "epoch:17 step:13806 [D loss: 0.352952, acc: 94.53%] [G loss: 2.553053]\n",
      "epoch:17 step:13807 [D loss: 0.577808, acc: 62.50%] [G loss: 2.799587]\n",
      "epoch:17 step:13808 [D loss: 0.409694, acc: 88.28%] [G loss: 3.326388]\n",
      "epoch:17 step:13809 [D loss: 0.685709, acc: 56.25%] [G loss: 2.645517]\n",
      "epoch:17 step:13810 [D loss: 0.796963, acc: 55.47%] [G loss: 2.538113]\n",
      "epoch:17 step:13811 [D loss: 0.268107, acc: 98.44%] [G loss: 2.503538]\n",
      "epoch:17 step:13812 [D loss: 0.447968, acc: 72.66%] [G loss: 4.440170]\n",
      "epoch:17 step:13813 [D loss: 0.313657, acc: 84.38%] [G loss: 3.412883]\n",
      "epoch:17 step:13814 [D loss: 0.511075, acc: 73.44%] [G loss: 2.202672]\n",
      "epoch:17 step:13815 [D loss: 0.572713, acc: 65.62%] [G loss: 3.325378]\n",
      "epoch:17 step:13816 [D loss: 0.720217, acc: 57.81%] [G loss: 2.621999]\n",
      "epoch:17 step:13817 [D loss: 0.343846, acc: 77.34%] [G loss: 3.274850]\n",
      "epoch:17 step:13818 [D loss: 0.378836, acc: 86.72%] [G loss: 3.412361]\n",
      "epoch:17 step:13819 [D loss: 0.392323, acc: 78.12%] [G loss: 3.995604]\n",
      "epoch:17 step:13820 [D loss: 0.628445, acc: 57.03%] [G loss: 2.828193]\n",
      "epoch:17 step:13821 [D loss: 1.114078, acc: 50.00%] [G loss: 2.167482]\n",
      "epoch:17 step:13822 [D loss: 0.395890, acc: 83.59%] [G loss: 1.955061]\n",
      "epoch:17 step:13823 [D loss: 0.228311, acc: 96.09%] [G loss: 2.099965]\n",
      "epoch:17 step:13824 [D loss: 0.809499, acc: 38.28%] [G loss: 1.841401]\n",
      "epoch:17 step:13825 [D loss: 0.623257, acc: 65.62%] [G loss: 3.188342]\n",
      "epoch:17 step:13826 [D loss: 0.410693, acc: 78.91%] [G loss: 2.695143]\n",
      "epoch:17 step:13827 [D loss: 0.405268, acc: 85.16%] [G loss: 3.614466]\n",
      "epoch:17 step:13828 [D loss: 0.385268, acc: 94.53%] [G loss: 2.686873]\n",
      "epoch:17 step:13829 [D loss: 0.618745, acc: 66.41%] [G loss: 2.033579]\n",
      "epoch:17 step:13830 [D loss: 0.677903, acc: 55.47%] [G loss: 2.190274]\n",
      "epoch:17 step:13831 [D loss: 0.610335, acc: 71.88%] [G loss: 2.552076]\n",
      "epoch:17 step:13832 [D loss: 0.346313, acc: 85.94%] [G loss: 2.449033]\n",
      "epoch:17 step:13833 [D loss: 0.326462, acc: 89.84%] [G loss: 3.272937]\n",
      "epoch:17 step:13834 [D loss: 0.674105, acc: 63.28%] [G loss: 2.825552]\n",
      "epoch:17 step:13835 [D loss: 0.679436, acc: 54.69%] [G loss: 3.119260]\n",
      "epoch:17 step:13836 [D loss: 0.369538, acc: 76.56%] [G loss: 3.026826]\n",
      "epoch:17 step:13837 [D loss: 0.829443, acc: 35.16%] [G loss: 2.222255]\n",
      "epoch:17 step:13838 [D loss: 0.686596, acc: 54.69%] [G loss: 2.500546]\n",
      "epoch:17 step:13839 [D loss: 0.504544, acc: 71.09%] [G loss: 2.671230]\n",
      "epoch:17 step:13840 [D loss: 0.575052, acc: 67.97%] [G loss: 1.979072]\n",
      "epoch:17 step:13841 [D loss: 0.334697, acc: 92.97%] [G loss: 2.448357]\n",
      "epoch:17 step:13842 [D loss: 0.581965, acc: 70.31%] [G loss: 1.840689]\n",
      "epoch:17 step:13843 [D loss: 0.311810, acc: 96.09%] [G loss: 3.539394]\n",
      "epoch:17 step:13844 [D loss: 0.640576, acc: 61.72%] [G loss: 2.973330]\n",
      "epoch:17 step:13845 [D loss: 0.550256, acc: 61.72%] [G loss: 2.131667]\n",
      "epoch:17 step:13846 [D loss: 0.587651, acc: 74.22%] [G loss: 2.087809]\n",
      "epoch:17 step:13847 [D loss: 0.522238, acc: 57.03%] [G loss: 2.345849]\n",
      "epoch:17 step:13848 [D loss: 0.632977, acc: 62.50%] [G loss: 2.439263]\n",
      "epoch:17 step:13849 [D loss: 0.300598, acc: 93.75%] [G loss: 2.732985]\n",
      "epoch:17 step:13850 [D loss: 0.455495, acc: 89.84%] [G loss: 2.572298]\n",
      "epoch:17 step:13851 [D loss: 0.634790, acc: 59.38%] [G loss: 1.976588]\n",
      "epoch:17 step:13852 [D loss: 0.255622, acc: 98.44%] [G loss: 3.627295]\n",
      "epoch:17 step:13853 [D loss: 0.534922, acc: 75.00%] [G loss: 3.548921]\n",
      "epoch:17 step:13854 [D loss: 0.550919, acc: 70.31%] [G loss: 2.470466]\n",
      "epoch:17 step:13855 [D loss: 0.951021, acc: 29.69%] [G loss: 1.709670]\n",
      "epoch:17 step:13856 [D loss: 0.483848, acc: 77.34%] [G loss: 1.842301]\n",
      "epoch:17 step:13857 [D loss: 0.570971, acc: 67.19%] [G loss: 2.678319]\n",
      "epoch:17 step:13858 [D loss: 0.194044, acc: 99.22%] [G loss: 3.985136]\n",
      "epoch:17 step:13859 [D loss: 0.226902, acc: 96.09%] [G loss: 3.311228]\n",
      "epoch:17 step:13860 [D loss: 0.562423, acc: 65.62%] [G loss: 2.997049]\n",
      "epoch:17 step:13861 [D loss: 0.291133, acc: 95.31%] [G loss: 2.503062]\n",
      "epoch:17 step:13862 [D loss: 0.479990, acc: 89.84%] [G loss: 2.128652]\n",
      "epoch:17 step:13863 [D loss: 0.505280, acc: 82.03%] [G loss: 2.434022]\n",
      "epoch:17 step:13864 [D loss: 0.686033, acc: 55.47%] [G loss: 2.418513]\n",
      "epoch:17 step:13865 [D loss: 0.664132, acc: 60.16%] [G loss: 2.664339]\n",
      "epoch:17 step:13866 [D loss: 0.886533, acc: 41.41%] [G loss: 2.867408]\n",
      "epoch:17 step:13867 [D loss: 0.466853, acc: 86.72%] [G loss: 2.174466]\n",
      "epoch:17 step:13868 [D loss: 0.906647, acc: 24.22%] [G loss: 2.316019]\n",
      "epoch:17 step:13869 [D loss: 0.608382, acc: 66.41%] [G loss: 2.452377]\n",
      "epoch:17 step:13870 [D loss: 0.678011, acc: 58.59%] [G loss: 2.492340]\n",
      "epoch:17 step:13871 [D loss: 0.869188, acc: 28.12%] [G loss: 2.346202]\n",
      "epoch:17 step:13872 [D loss: 0.449334, acc: 84.38%] [G loss: 2.573657]\n",
      "epoch:17 step:13873 [D loss: 0.399793, acc: 92.97%] [G loss: 2.377663]\n",
      "epoch:17 step:13874 [D loss: 0.836164, acc: 51.56%] [G loss: 2.731772]\n",
      "epoch:17 step:13875 [D loss: 0.355360, acc: 89.84%] [G loss: 2.042300]\n",
      "epoch:17 step:13876 [D loss: 0.631954, acc: 62.50%] [G loss: 2.276761]\n",
      "epoch:17 step:13877 [D loss: 0.265809, acc: 97.66%] [G loss: 3.314022]\n",
      "epoch:17 step:13878 [D loss: 0.585380, acc: 67.97%] [G loss: 2.104996]\n",
      "epoch:17 step:13879 [D loss: 0.452098, acc: 86.72%] [G loss: 2.678064]\n",
      "epoch:17 step:13880 [D loss: 0.563490, acc: 72.66%] [G loss: 1.736761]\n",
      "epoch:17 step:13881 [D loss: 1.057595, acc: 27.34%] [G loss: 1.482170]\n",
      "epoch:17 step:13882 [D loss: 0.338013, acc: 94.53%] [G loss: 2.101695]\n",
      "epoch:17 step:13883 [D loss: 0.361087, acc: 94.53%] [G loss: 2.332222]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:17 step:13884 [D loss: 0.524407, acc: 71.09%] [G loss: 1.700217]\n",
      "epoch:17 step:13885 [D loss: 0.202981, acc: 99.22%] [G loss: 3.161145]\n",
      "epoch:17 step:13886 [D loss: 0.608298, acc: 64.84%] [G loss: 2.159179]\n",
      "epoch:17 step:13887 [D loss: 0.442606, acc: 87.50%] [G loss: 1.601084]\n",
      "epoch:17 step:13888 [D loss: 0.444838, acc: 89.06%] [G loss: 2.131137]\n",
      "epoch:17 step:13889 [D loss: 0.505429, acc: 81.25%] [G loss: 2.239179]\n",
      "epoch:17 step:13890 [D loss: 1.687108, acc: 32.03%] [G loss: 2.541291]\n",
      "epoch:17 step:13891 [D loss: 0.646157, acc: 57.03%] [G loss: 2.085122]\n",
      "epoch:17 step:13892 [D loss: 0.665773, acc: 60.94%] [G loss: 2.138229]\n",
      "epoch:17 step:13893 [D loss: 0.529422, acc: 59.38%] [G loss: 4.054223]\n",
      "epoch:17 step:13894 [D loss: 0.574799, acc: 76.56%] [G loss: 2.674010]\n",
      "epoch:17 step:13895 [D loss: 0.600549, acc: 67.97%] [G loss: 2.223975]\n",
      "epoch:17 step:13896 [D loss: 0.485735, acc: 81.25%] [G loss: 2.022124]\n",
      "epoch:17 step:13897 [D loss: 0.664605, acc: 59.38%] [G loss: 2.733935]\n",
      "epoch:17 step:13898 [D loss: 0.588900, acc: 72.66%] [G loss: 2.544392]\n",
      "epoch:17 step:13899 [D loss: 0.458586, acc: 75.78%] [G loss: 2.288892]\n",
      "epoch:17 step:13900 [D loss: 1.083289, acc: 17.19%] [G loss: 2.062660]\n",
      "epoch:17 step:13901 [D loss: 0.702797, acc: 54.69%] [G loss: 2.270624]\n",
      "epoch:17 step:13902 [D loss: 0.605713, acc: 68.75%] [G loss: 3.026752]\n",
      "epoch:17 step:13903 [D loss: 0.388683, acc: 88.28%] [G loss: 2.796406]\n",
      "epoch:17 step:13904 [D loss: 0.750450, acc: 46.88%] [G loss: 1.977628]\n",
      "epoch:17 step:13905 [D loss: 0.542664, acc: 60.94%] [G loss: 2.524697]\n",
      "epoch:17 step:13906 [D loss: 0.750007, acc: 49.22%] [G loss: 2.758851]\n",
      "epoch:17 step:13907 [D loss: 0.425247, acc: 75.78%] [G loss: 3.319246]\n",
      "epoch:17 step:13908 [D loss: 0.169563, acc: 100.00%] [G loss: 3.326630]\n",
      "epoch:17 step:13909 [D loss: 0.493745, acc: 77.34%] [G loss: 3.043467]\n",
      "epoch:17 step:13910 [D loss: 0.616600, acc: 56.25%] [G loss: 2.351959]\n",
      "epoch:17 step:13911 [D loss: 0.753202, acc: 50.78%] [G loss: 1.879739]\n",
      "epoch:17 step:13912 [D loss: 0.654211, acc: 55.47%] [G loss: 2.774058]\n",
      "epoch:17 step:13913 [D loss: 0.555060, acc: 69.53%] [G loss: 2.456767]\n",
      "epoch:17 step:13914 [D loss: 0.360100, acc: 95.31%] [G loss: 3.590984]\n",
      "epoch:17 step:13915 [D loss: 0.429856, acc: 82.03%] [G loss: 3.567461]\n",
      "epoch:17 step:13916 [D loss: 0.650495, acc: 57.03%] [G loss: 2.473385]\n",
      "epoch:17 step:13917 [D loss: 0.420445, acc: 87.50%] [G loss: 3.033074]\n",
      "epoch:17 step:13918 [D loss: 0.767302, acc: 45.31%] [G loss: 2.715970]\n",
      "epoch:17 step:13919 [D loss: 0.619332, acc: 56.25%] [G loss: 3.134759]\n",
      "epoch:17 step:13920 [D loss: 0.370823, acc: 90.62%] [G loss: 2.806587]\n",
      "epoch:17 step:13921 [D loss: 0.205833, acc: 96.88%] [G loss: 3.257342]\n",
      "epoch:17 step:13922 [D loss: 0.484151, acc: 82.81%] [G loss: 2.092452]\n",
      "epoch:17 step:13923 [D loss: 1.252449, acc: 8.59%] [G loss: 2.425900]\n",
      "epoch:17 step:13924 [D loss: 0.666205, acc: 65.62%] [G loss: 2.676086]\n",
      "epoch:17 step:13925 [D loss: 0.388835, acc: 93.75%] [G loss: 1.836152]\n",
      "epoch:17 step:13926 [D loss: 0.185647, acc: 99.22%] [G loss: 2.995272]\n",
      "epoch:17 step:13927 [D loss: 0.505362, acc: 75.00%] [G loss: 2.413099]\n",
      "epoch:17 step:13928 [D loss: 0.607793, acc: 61.72%] [G loss: 2.628957]\n",
      "epoch:17 step:13929 [D loss: 0.643831, acc: 61.72%] [G loss: 1.936349]\n",
      "epoch:17 step:13930 [D loss: 0.654331, acc: 60.94%] [G loss: 2.337645]\n",
      "epoch:17 step:13931 [D loss: 0.372587, acc: 94.53%] [G loss: 2.609560]\n",
      "epoch:17 step:13932 [D loss: 0.360493, acc: 96.09%] [G loss: 4.075113]\n",
      "epoch:17 step:13933 [D loss: 1.442471, acc: 39.84%] [G loss: 2.556391]\n",
      "epoch:17 step:13934 [D loss: 0.409811, acc: 91.41%] [G loss: 2.373974]\n",
      "epoch:17 step:13935 [D loss: 0.412711, acc: 93.75%] [G loss: 2.596335]\n",
      "epoch:17 step:13936 [D loss: 0.582657, acc: 60.94%] [G loss: 2.446461]\n",
      "epoch:17 step:13937 [D loss: 0.542693, acc: 68.75%] [G loss: 2.096192]\n",
      "epoch:17 step:13938 [D loss: 0.593361, acc: 58.59%] [G loss: 2.923195]\n",
      "epoch:17 step:13939 [D loss: 0.239607, acc: 99.22%] [G loss: 3.205721]\n",
      "epoch:17 step:13940 [D loss: 0.579350, acc: 71.88%] [G loss: 3.101793]\n",
      "epoch:17 step:13941 [D loss: 0.598084, acc: 61.72%] [G loss: 2.515522]\n",
      "epoch:17 step:13942 [D loss: 0.420603, acc: 87.50%] [G loss: 2.173052]\n",
      "epoch:17 step:13943 [D loss: 0.353567, acc: 96.09%] [G loss: 3.024069]\n",
      "epoch:17 step:13944 [D loss: 0.844778, acc: 37.50%] [G loss: 2.941253]\n",
      "epoch:17 step:13945 [D loss: 0.649237, acc: 57.81%] [G loss: 2.488587]\n",
      "epoch:17 step:13946 [D loss: 0.998016, acc: 47.66%] [G loss: 2.985667]\n",
      "epoch:17 step:13947 [D loss: 0.499268, acc: 86.72%] [G loss: 2.652365]\n",
      "epoch:17 step:13948 [D loss: 0.824390, acc: 50.00%] [G loss: 2.147746]\n",
      "epoch:17 step:13949 [D loss: 0.661695, acc: 58.59%] [G loss: 1.775669]\n",
      "epoch:17 step:13950 [D loss: 0.269210, acc: 98.44%] [G loss: 3.061487]\n",
      "epoch:17 step:13951 [D loss: 0.237924, acc: 99.22%] [G loss: 2.571667]\n",
      "epoch:17 step:13952 [D loss: 0.227645, acc: 100.00%] [G loss: 3.068512]\n",
      "epoch:17 step:13953 [D loss: 1.176271, acc: 4.69%] [G loss: 2.782904]\n",
      "epoch:17 step:13954 [D loss: 0.617127, acc: 62.50%] [G loss: 2.801341]\n",
      "epoch:17 step:13955 [D loss: 0.528524, acc: 70.31%] [G loss: 1.847675]\n",
      "epoch:17 step:13956 [D loss: 0.346064, acc: 88.28%] [G loss: 3.084146]\n",
      "epoch:17 step:13957 [D loss: 0.508432, acc: 68.75%] [G loss: 2.499352]\n",
      "epoch:17 step:13958 [D loss: 0.269320, acc: 98.44%] [G loss: 2.725842]\n",
      "epoch:17 step:13959 [D loss: 0.342540, acc: 94.53%] [G loss: 2.748277]\n",
      "epoch:17 step:13960 [D loss: 0.801611, acc: 39.84%] [G loss: 2.493047]\n",
      "epoch:17 step:13961 [D loss: 0.244635, acc: 99.22%] [G loss: 2.609461]\n",
      "epoch:17 step:13962 [D loss: 0.474331, acc: 74.22%] [G loss: 2.489055]\n",
      "epoch:17 step:13963 [D loss: 0.861191, acc: 37.50%] [G loss: 3.002552]\n",
      "epoch:17 step:13964 [D loss: 0.720008, acc: 48.44%] [G loss: 2.565310]\n",
      "epoch:17 step:13965 [D loss: 0.465726, acc: 83.59%] [G loss: 2.193759]\n",
      "epoch:17 step:13966 [D loss: 0.313780, acc: 94.53%] [G loss: 2.978969]\n",
      "epoch:17 step:13967 [D loss: 0.362410, acc: 93.75%] [G loss: 2.856509]\n",
      "epoch:17 step:13968 [D loss: 0.352810, acc: 96.09%] [G loss: 2.312850]\n",
      "epoch:17 step:13969 [D loss: 1.013066, acc: 21.09%] [G loss: 2.258233]\n",
      "epoch:17 step:13970 [D loss: 0.550635, acc: 59.38%] [G loss: 2.189706]\n",
      "epoch:17 step:13971 [D loss: 0.460856, acc: 88.28%] [G loss: 2.510700]\n",
      "epoch:17 step:13972 [D loss: 0.293809, acc: 96.88%] [G loss: 2.467515]\n",
      "epoch:17 step:13973 [D loss: 0.557585, acc: 77.34%] [G loss: 2.302634]\n",
      "epoch:17 step:13974 [D loss: 0.577757, acc: 71.88%] [G loss: 2.652851]\n",
      "epoch:17 step:13975 [D loss: 0.697659, acc: 60.16%] [G loss: 1.961674]\n",
      "epoch:17 step:13976 [D loss: 0.335298, acc: 92.97%] [G loss: 2.665617]\n",
      "epoch:17 step:13977 [D loss: 0.425642, acc: 89.84%] [G loss: 2.951269]\n",
      "epoch:17 step:13978 [D loss: 0.585150, acc: 73.44%] [G loss: 2.736474]\n",
      "epoch:17 step:13979 [D loss: 0.293632, acc: 95.31%] [G loss: 2.763312]\n",
      "epoch:17 step:13980 [D loss: 0.509233, acc: 74.22%] [G loss: 2.291892]\n",
      "epoch:17 step:13981 [D loss: 0.527560, acc: 74.22%] [G loss: 4.017727]\n",
      "epoch:17 step:13982 [D loss: 0.655342, acc: 57.03%] [G loss: 3.473525]\n",
      "epoch:17 step:13983 [D loss: 0.222483, acc: 97.66%] [G loss: 2.749643]\n",
      "epoch:17 step:13984 [D loss: 0.400497, acc: 91.41%] [G loss: 2.337109]\n",
      "epoch:17 step:13985 [D loss: 0.387414, acc: 90.62%] [G loss: 3.542002]\n",
      "epoch:17 step:13986 [D loss: 0.294660, acc: 92.97%] [G loss: 2.868639]\n",
      "epoch:17 step:13987 [D loss: 0.523728, acc: 66.41%] [G loss: 3.723502]\n",
      "epoch:17 step:13988 [D loss: 0.121874, acc: 100.00%] [G loss: 2.998330]\n",
      "epoch:17 step:13989 [D loss: 0.546573, acc: 73.44%] [G loss: 1.791148]\n",
      "epoch:17 step:13990 [D loss: 0.718524, acc: 53.91%] [G loss: 2.075958]\n",
      "epoch:17 step:13991 [D loss: 0.476189, acc: 87.50%] [G loss: 2.589926]\n",
      "epoch:17 step:13992 [D loss: 0.409048, acc: 92.97%] [G loss: 2.298704]\n",
      "epoch:17 step:13993 [D loss: 0.720271, acc: 56.25%] [G loss: 2.251276]\n",
      "epoch:17 step:13994 [D loss: 0.199666, acc: 97.66%] [G loss: 2.382312]\n",
      "epoch:17 step:13995 [D loss: 0.573448, acc: 71.09%] [G loss: 2.159080]\n",
      "epoch:17 step:13996 [D loss: 0.587335, acc: 75.78%] [G loss: 3.409470]\n",
      "epoch:17 step:13997 [D loss: 0.337249, acc: 93.75%] [G loss: 2.358682]\n",
      "epoch:17 step:13998 [D loss: 0.424822, acc: 89.06%] [G loss: 2.467082]\n",
      "epoch:17 step:13999 [D loss: 0.904119, acc: 33.59%] [G loss: 3.149015]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:17 step:14000 [D loss: 0.166126, acc: 99.22%] [G loss: 2.781440]\n",
      "##############\n",
      "[0.86760114 0.87488833 0.80855745 0.8087426  0.79002184 0.8197402\n",
      " 0.87621603 0.83519339 0.79750741 0.84295362]\n",
      "##########\n",
      "epoch:17 step:14001 [D loss: 0.774669, acc: 44.53%] [G loss: 2.521265]\n",
      "epoch:17 step:14002 [D loss: 0.227524, acc: 99.22%] [G loss: 3.096611]\n",
      "epoch:17 step:14003 [D loss: 0.287289, acc: 89.84%] [G loss: 4.256814]\n",
      "epoch:17 step:14004 [D loss: 0.513961, acc: 82.03%] [G loss: 2.380629]\n",
      "epoch:17 step:14005 [D loss: 0.441171, acc: 71.09%] [G loss: 4.171862]\n",
      "epoch:17 step:14006 [D loss: 0.421720, acc: 89.06%] [G loss: 1.986736]\n",
      "epoch:17 step:14007 [D loss: 0.340171, acc: 92.97%] [G loss: 1.571493]\n",
      "epoch:17 step:14008 [D loss: 0.619885, acc: 67.97%] [G loss: 2.670561]\n",
      "epoch:17 step:14009 [D loss: 0.906310, acc: 24.22%] [G loss: 2.352604]\n",
      "epoch:17 step:14010 [D loss: 0.820736, acc: 50.00%] [G loss: 2.802678]\n",
      "epoch:17 step:14011 [D loss: 0.738844, acc: 49.22%] [G loss: 2.246205]\n",
      "epoch:17 step:14012 [D loss: 0.790886, acc: 51.56%] [G loss: 1.952738]\n",
      "epoch:17 step:14013 [D loss: 0.341092, acc: 92.97%] [G loss: 3.620095]\n",
      "epoch:17 step:14014 [D loss: 0.772308, acc: 45.31%] [G loss: 2.611415]\n",
      "epoch:17 step:14015 [D loss: 0.528183, acc: 71.88%] [G loss: 2.123580]\n",
      "epoch:17 step:14016 [D loss: 0.134296, acc: 99.22%] [G loss: 2.773018]\n",
      "epoch:17 step:14017 [D loss: 0.699277, acc: 51.56%] [G loss: 2.829490]\n",
      "epoch:17 step:14018 [D loss: 0.695404, acc: 50.00%] [G loss: 2.733653]\n",
      "epoch:17 step:14019 [D loss: 0.425127, acc: 78.91%] [G loss: 2.498930]\n",
      "epoch:17 step:14020 [D loss: 0.549492, acc: 77.34%] [G loss: 3.662571]\n",
      "epoch:17 step:14021 [D loss: 0.959124, acc: 47.66%] [G loss: 1.742665]\n",
      "epoch:17 step:14022 [D loss: 0.488184, acc: 79.69%] [G loss: 2.937499]\n",
      "epoch:17 step:14023 [D loss: 0.707991, acc: 60.16%] [G loss: 2.652130]\n",
      "epoch:17 step:14024 [D loss: 0.511083, acc: 78.91%] [G loss: 2.660789]\n",
      "epoch:17 step:14025 [D loss: 0.436868, acc: 76.56%] [G loss: 3.862700]\n",
      "epoch:17 step:14026 [D loss: 0.412708, acc: 91.41%] [G loss: 2.741461]\n",
      "epoch:17 step:14027 [D loss: 1.080815, acc: 14.06%] [G loss: 1.879688]\n",
      "epoch:17 step:14028 [D loss: 0.490492, acc: 82.03%] [G loss: 2.685807]\n",
      "epoch:17 step:14029 [D loss: 0.637755, acc: 65.62%] [G loss: 2.018650]\n",
      "epoch:17 step:14030 [D loss: 0.276133, acc: 96.09%] [G loss: 3.122069]\n",
      "epoch:17 step:14031 [D loss: 0.560652, acc: 65.62%] [G loss: 3.309989]\n",
      "epoch:17 step:14032 [D loss: 0.489815, acc: 77.34%] [G loss: 2.131897]\n",
      "epoch:17 step:14033 [D loss: 0.139081, acc: 100.00%] [G loss: 2.882425]\n",
      "epoch:17 step:14034 [D loss: 0.492887, acc: 82.81%] [G loss: 2.440009]\n",
      "epoch:17 step:14035 [D loss: 0.514714, acc: 67.19%] [G loss: 2.451432]\n",
      "epoch:17 step:14036 [D loss: 0.560230, acc: 75.00%] [G loss: 2.441396]\n",
      "epoch:17 step:14037 [D loss: 0.321315, acc: 95.31%] [G loss: 4.371801]\n",
      "epoch:17 step:14038 [D loss: 0.659085, acc: 59.38%] [G loss: 2.019241]\n",
      "epoch:17 step:14039 [D loss: 0.327303, acc: 88.28%] [G loss: 2.586983]\n",
      "epoch:17 step:14040 [D loss: 0.528449, acc: 78.91%] [G loss: 2.548590]\n",
      "epoch:17 step:14041 [D loss: 1.214486, acc: 10.16%] [G loss: 2.378889]\n",
      "epoch:17 step:14042 [D loss: 0.535333, acc: 61.72%] [G loss: 3.093960]\n",
      "epoch:17 step:14043 [D loss: 0.372552, acc: 93.75%] [G loss: 3.459028]\n",
      "epoch:17 step:14044 [D loss: 0.193589, acc: 99.22%] [G loss: 3.424357]\n",
      "epoch:17 step:14045 [D loss: 0.279068, acc: 99.22%] [G loss: 2.625420]\n",
      "epoch:17 step:14046 [D loss: 0.657461, acc: 60.94%] [G loss: 2.747560]\n",
      "epoch:17 step:14047 [D loss: 0.252964, acc: 95.31%] [G loss: 2.938494]\n",
      "epoch:17 step:14048 [D loss: 1.219215, acc: 20.31%] [G loss: 1.690766]\n",
      "epoch:17 step:14049 [D loss: 0.308959, acc: 96.88%] [G loss: 3.407951]\n",
      "epoch:17 step:14050 [D loss: 0.371374, acc: 87.50%] [G loss: 3.083073]\n",
      "epoch:17 step:14051 [D loss: 0.786068, acc: 49.22%] [G loss: 2.956015]\n",
      "epoch:17 step:14052 [D loss: 0.599492, acc: 61.72%] [G loss: 2.276842]\n",
      "epoch:17 step:14053 [D loss: 0.279146, acc: 96.88%] [G loss: 2.373854]\n",
      "epoch:17 step:14054 [D loss: 0.772672, acc: 46.88%] [G loss: 1.601188]\n",
      "epoch:17 step:14055 [D loss: 0.339692, acc: 97.66%] [G loss: 2.560680]\n",
      "epoch:17 step:14056 [D loss: 1.146449, acc: 30.47%] [G loss: 1.645159]\n",
      "epoch:17 step:14057 [D loss: 0.670065, acc: 61.72%] [G loss: 2.383401]\n",
      "epoch:17 step:14058 [D loss: 0.722247, acc: 51.56%] [G loss: 3.966951]\n",
      "epoch:18 step:14059 [D loss: 0.213689, acc: 99.22%] [G loss: 3.204296]\n",
      "epoch:18 step:14060 [D loss: 1.223330, acc: 33.59%] [G loss: 2.333683]\n",
      "epoch:18 step:14061 [D loss: 0.573330, acc: 74.22%] [G loss: 2.765077]\n",
      "epoch:18 step:14062 [D loss: 0.571810, acc: 72.66%] [G loss: 2.996778]\n",
      "epoch:18 step:14063 [D loss: 0.367037, acc: 82.03%] [G loss: 3.405269]\n",
      "epoch:18 step:14064 [D loss: 0.554969, acc: 75.00%] [G loss: 2.467488]\n",
      "epoch:18 step:14065 [D loss: 0.442695, acc: 88.28%] [G loss: 3.190072]\n",
      "epoch:18 step:14066 [D loss: 0.463304, acc: 88.28%] [G loss: 3.295753]\n",
      "epoch:18 step:14067 [D loss: 0.472946, acc: 88.28%] [G loss: 3.113670]\n",
      "epoch:18 step:14068 [D loss: 0.878449, acc: 35.16%] [G loss: 2.049158]\n",
      "epoch:18 step:14069 [D loss: 0.586197, acc: 70.31%] [G loss: 1.547966]\n",
      "epoch:18 step:14070 [D loss: 0.515914, acc: 73.44%] [G loss: 2.823282]\n",
      "epoch:18 step:14071 [D loss: 0.704468, acc: 57.03%] [G loss: 1.882009]\n",
      "epoch:18 step:14072 [D loss: 0.602457, acc: 67.97%] [G loss: 2.508642]\n",
      "epoch:18 step:14073 [D loss: 1.065420, acc: 39.84%] [G loss: 2.283175]\n",
      "epoch:18 step:14074 [D loss: 0.460410, acc: 74.22%] [G loss: 3.069361]\n",
      "epoch:18 step:14075 [D loss: 0.321819, acc: 89.84%] [G loss: 4.129078]\n",
      "epoch:18 step:14076 [D loss: 0.646358, acc: 54.69%] [G loss: 2.582377]\n",
      "epoch:18 step:14077 [D loss: 0.399717, acc: 81.25%] [G loss: 2.673368]\n",
      "epoch:18 step:14078 [D loss: 0.586552, acc: 67.97%] [G loss: 3.242948]\n",
      "epoch:18 step:14079 [D loss: 0.245831, acc: 96.09%] [G loss: 3.457729]\n",
      "epoch:18 step:14080 [D loss: 0.555772, acc: 75.00%] [G loss: 2.651473]\n",
      "epoch:18 step:14081 [D loss: 0.403055, acc: 91.41%] [G loss: 3.104243]\n",
      "epoch:18 step:14082 [D loss: 0.794915, acc: 48.44%] [G loss: 3.113420]\n",
      "epoch:18 step:14083 [D loss: 0.604705, acc: 66.41%] [G loss: 2.441923]\n",
      "epoch:18 step:14084 [D loss: 0.604362, acc: 64.84%] [G loss: 2.315081]\n",
      "epoch:18 step:14085 [D loss: 0.408323, acc: 82.81%] [G loss: 4.481271]\n",
      "epoch:18 step:14086 [D loss: 0.497714, acc: 71.88%] [G loss: 2.503264]\n",
      "epoch:18 step:14087 [D loss: 0.122501, acc: 100.00%] [G loss: 2.604094]\n",
      "epoch:18 step:14088 [D loss: 0.621121, acc: 67.97%] [G loss: 3.178174]\n",
      "epoch:18 step:14089 [D loss: 0.548703, acc: 71.88%] [G loss: 2.211378]\n",
      "epoch:18 step:14090 [D loss: 0.640887, acc: 61.72%] [G loss: 3.253133]\n",
      "epoch:18 step:14091 [D loss: 1.055820, acc: 50.78%] [G loss: 2.414347]\n",
      "epoch:18 step:14092 [D loss: 0.753722, acc: 55.47%] [G loss: 2.687222]\n",
      "epoch:18 step:14093 [D loss: 0.336911, acc: 89.84%] [G loss: 1.697598]\n",
      "epoch:18 step:14094 [D loss: 0.621182, acc: 64.84%] [G loss: 2.204171]\n",
      "epoch:18 step:14095 [D loss: 0.752025, acc: 48.44%] [G loss: 1.749610]\n",
      "epoch:18 step:14096 [D loss: 0.622717, acc: 62.50%] [G loss: 3.167858]\n",
      "epoch:18 step:14097 [D loss: 0.420411, acc: 84.38%] [G loss: 3.366175]\n",
      "epoch:18 step:14098 [D loss: 0.607717, acc: 64.84%] [G loss: 2.507862]\n",
      "epoch:18 step:14099 [D loss: 0.186032, acc: 99.22%] [G loss: 1.925166]\n",
      "epoch:18 step:14100 [D loss: 0.493739, acc: 87.50%] [G loss: 2.651941]\n",
      "epoch:18 step:14101 [D loss: 0.313150, acc: 94.53%] [G loss: 2.408180]\n",
      "epoch:18 step:14102 [D loss: 0.655435, acc: 60.94%] [G loss: 2.608305]\n",
      "epoch:18 step:14103 [D loss: 0.587071, acc: 60.94%] [G loss: 2.846065]\n",
      "epoch:18 step:14104 [D loss: 0.172091, acc: 100.00%] [G loss: 2.293178]\n",
      "epoch:18 step:14105 [D loss: 0.472421, acc: 71.88%] [G loss: 2.838290]\n",
      "epoch:18 step:14106 [D loss: 0.623244, acc: 57.81%] [G loss: 2.672373]\n",
      "epoch:18 step:14107 [D loss: 0.785598, acc: 47.66%] [G loss: 1.255035]\n",
      "epoch:18 step:14108 [D loss: 0.831263, acc: 41.41%] [G loss: 3.503666]\n",
      "epoch:18 step:14109 [D loss: 0.557746, acc: 57.81%] [G loss: 2.849508]\n",
      "epoch:18 step:14110 [D loss: 0.281607, acc: 92.97%] [G loss: 3.768615]\n",
      "epoch:18 step:14111 [D loss: 0.499512, acc: 82.03%] [G loss: 4.056512]\n",
      "epoch:18 step:14112 [D loss: 0.636981, acc: 64.06%] [G loss: 2.761133]\n",
      "epoch:18 step:14113 [D loss: 0.833568, acc: 44.53%] [G loss: 2.605939]\n",
      "epoch:18 step:14114 [D loss: 0.312094, acc: 89.84%] [G loss: 1.844868]\n",
      "epoch:18 step:14115 [D loss: 0.454671, acc: 85.16%] [G loss: 2.624476]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:18 step:14116 [D loss: 0.986015, acc: 25.00%] [G loss: 2.445573]\n",
      "epoch:18 step:14117 [D loss: 0.762763, acc: 49.22%] [G loss: 2.487860]\n",
      "epoch:18 step:14118 [D loss: 0.373189, acc: 94.53%] [G loss: 3.962498]\n",
      "epoch:18 step:14119 [D loss: 0.789420, acc: 53.12%] [G loss: 3.134963]\n",
      "epoch:18 step:14120 [D loss: 1.085177, acc: 32.81%] [G loss: 2.484670]\n",
      "epoch:18 step:14121 [D loss: 0.354679, acc: 94.53%] [G loss: 3.297472]\n",
      "epoch:18 step:14122 [D loss: 0.349825, acc: 90.62%] [G loss: 2.591662]\n",
      "epoch:18 step:14123 [D loss: 0.635711, acc: 63.28%] [G loss: 3.832003]\n",
      "epoch:18 step:14124 [D loss: 0.828482, acc: 39.06%] [G loss: 2.284162]\n",
      "epoch:18 step:14125 [D loss: 0.622193, acc: 67.97%] [G loss: 2.209304]\n",
      "epoch:18 step:14126 [D loss: 0.518344, acc: 77.34%] [G loss: 2.872392]\n",
      "epoch:18 step:14127 [D loss: 0.361801, acc: 92.97%] [G loss: 2.784657]\n",
      "epoch:18 step:14128 [D loss: 0.589793, acc: 68.75%] [G loss: 3.121063]\n",
      "epoch:18 step:14129 [D loss: 0.515999, acc: 81.25%] [G loss: 2.174640]\n",
      "epoch:18 step:14130 [D loss: 0.694996, acc: 57.81%] [G loss: 2.974480]\n",
      "epoch:18 step:14131 [D loss: 0.264419, acc: 99.22%] [G loss: 4.280213]\n",
      "epoch:18 step:14132 [D loss: 0.282479, acc: 91.41%] [G loss: 1.975028]\n",
      "epoch:18 step:14133 [D loss: 0.263488, acc: 95.31%] [G loss: 4.329514]\n",
      "epoch:18 step:14134 [D loss: 0.476212, acc: 75.00%] [G loss: 3.938165]\n",
      "epoch:18 step:14135 [D loss: 0.250814, acc: 96.88%] [G loss: 4.422328]\n",
      "epoch:18 step:14136 [D loss: 0.283769, acc: 95.31%] [G loss: 3.215364]\n",
      "epoch:18 step:14137 [D loss: 0.773768, acc: 50.00%] [G loss: 2.584471]\n",
      "epoch:18 step:14138 [D loss: 0.417761, acc: 78.12%] [G loss: 2.961871]\n",
      "epoch:18 step:14139 [D loss: 0.313246, acc: 97.66%] [G loss: 2.161587]\n",
      "epoch:18 step:14140 [D loss: 0.389001, acc: 92.19%] [G loss: 2.157412]\n",
      "epoch:18 step:14141 [D loss: 0.312754, acc: 89.84%] [G loss: 2.670743]\n",
      "epoch:18 step:14142 [D loss: 0.184166, acc: 97.66%] [G loss: 4.759787]\n",
      "epoch:18 step:14143 [D loss: 0.294855, acc: 95.31%] [G loss: 2.074371]\n",
      "epoch:18 step:14144 [D loss: 0.295460, acc: 96.88%] [G loss: 3.118320]\n",
      "epoch:18 step:14145 [D loss: 0.628735, acc: 60.16%] [G loss: 2.516917]\n",
      "epoch:18 step:14146 [D loss: 0.244200, acc: 92.19%] [G loss: 2.451285]\n",
      "epoch:18 step:14147 [D loss: 0.323952, acc: 89.84%] [G loss: 2.378479]\n",
      "epoch:18 step:14148 [D loss: 1.009879, acc: 29.69%] [G loss: 2.633496]\n",
      "epoch:18 step:14149 [D loss: 0.108075, acc: 99.22%] [G loss: 4.545542]\n",
      "epoch:18 step:14150 [D loss: 0.510322, acc: 82.81%] [G loss: 1.782599]\n",
      "epoch:18 step:14151 [D loss: 0.245813, acc: 93.75%] [G loss: 3.085721]\n",
      "epoch:18 step:14152 [D loss: 0.251070, acc: 97.66%] [G loss: 2.308707]\n",
      "epoch:18 step:14153 [D loss: 0.715819, acc: 52.34%] [G loss: 2.740213]\n",
      "epoch:18 step:14154 [D loss: 0.212933, acc: 95.31%] [G loss: 3.774747]\n",
      "epoch:18 step:14155 [D loss: 0.558562, acc: 74.22%] [G loss: 2.817844]\n",
      "epoch:18 step:14156 [D loss: 0.933570, acc: 41.41%] [G loss: 3.905482]\n",
      "epoch:18 step:14157 [D loss: 0.564000, acc: 73.44%] [G loss: 2.378725]\n",
      "epoch:18 step:14158 [D loss: 0.746574, acc: 51.56%] [G loss: 2.494403]\n",
      "epoch:18 step:14159 [D loss: 0.726149, acc: 50.78%] [G loss: 1.521180]\n",
      "epoch:18 step:14160 [D loss: 0.095666, acc: 100.00%] [G loss: 3.021810]\n",
      "epoch:18 step:14161 [D loss: 0.777132, acc: 46.88%] [G loss: 2.006920]\n",
      "epoch:18 step:14162 [D loss: 0.696981, acc: 53.12%] [G loss: 2.706692]\n",
      "epoch:18 step:14163 [D loss: 0.719715, acc: 55.47%] [G loss: 2.330944]\n",
      "epoch:18 step:14164 [D loss: 0.508968, acc: 65.62%] [G loss: 2.805174]\n",
      "epoch:18 step:14165 [D loss: 1.268037, acc: 42.97%] [G loss: 1.780960]\n",
      "epoch:18 step:14166 [D loss: 0.507627, acc: 73.44%] [G loss: 2.819819]\n",
      "epoch:18 step:14167 [D loss: 0.807005, acc: 46.88%] [G loss: 2.280366]\n",
      "epoch:18 step:14168 [D loss: 0.449156, acc: 88.28%] [G loss: 2.844418]\n",
      "epoch:18 step:14169 [D loss: 0.823221, acc: 43.75%] [G loss: 3.625031]\n",
      "epoch:18 step:14170 [D loss: 0.171678, acc: 98.44%] [G loss: 3.424901]\n",
      "epoch:18 step:14171 [D loss: 0.321253, acc: 97.66%] [G loss: 2.401510]\n",
      "epoch:18 step:14172 [D loss: 0.367347, acc: 88.28%] [G loss: 2.928205]\n",
      "epoch:18 step:14173 [D loss: 0.794338, acc: 54.69%] [G loss: 2.057385]\n",
      "epoch:18 step:14174 [D loss: 0.325086, acc: 92.97%] [G loss: 2.729769]\n",
      "epoch:18 step:14175 [D loss: 0.792968, acc: 39.84%] [G loss: 2.524309]\n",
      "epoch:18 step:14176 [D loss: 0.874823, acc: 34.38%] [G loss: 2.172500]\n",
      "epoch:18 step:14177 [D loss: 0.194467, acc: 100.00%] [G loss: 3.418980]\n",
      "epoch:18 step:14178 [D loss: 0.672279, acc: 57.03%] [G loss: 3.971866]\n",
      "epoch:18 step:14179 [D loss: 0.776536, acc: 50.00%] [G loss: 2.526685]\n",
      "epoch:18 step:14180 [D loss: 0.233294, acc: 99.22%] [G loss: 1.520646]\n",
      "epoch:18 step:14181 [D loss: 0.286620, acc: 96.88%] [G loss: 3.665776]\n",
      "epoch:18 step:14182 [D loss: 0.380001, acc: 94.53%] [G loss: 3.427238]\n",
      "epoch:18 step:14183 [D loss: 0.328474, acc: 96.09%] [G loss: 2.212583]\n",
      "epoch:18 step:14184 [D loss: 1.196818, acc: 10.16%] [G loss: 1.961625]\n",
      "epoch:18 step:14185 [D loss: 0.787906, acc: 50.78%] [G loss: 3.514956]\n",
      "epoch:18 step:14186 [D loss: 0.403666, acc: 88.28%] [G loss: 3.113543]\n",
      "epoch:18 step:14187 [D loss: 0.346531, acc: 95.31%] [G loss: 2.674818]\n",
      "epoch:18 step:14188 [D loss: 0.497545, acc: 82.03%] [G loss: 3.163763]\n",
      "epoch:18 step:14189 [D loss: 0.602907, acc: 67.19%] [G loss: 2.629767]\n",
      "epoch:18 step:14190 [D loss: 0.743385, acc: 50.00%] [G loss: 3.595275]\n",
      "epoch:18 step:14191 [D loss: 1.027304, acc: 18.75%] [G loss: 3.617055]\n",
      "epoch:18 step:14192 [D loss: 0.368642, acc: 94.53%] [G loss: 3.346627]\n",
      "epoch:18 step:14193 [D loss: 0.282078, acc: 90.62%] [G loss: 4.906446]\n",
      "epoch:18 step:14194 [D loss: 0.814355, acc: 53.91%] [G loss: 2.485562]\n",
      "epoch:18 step:14195 [D loss: 0.350765, acc: 92.19%] [G loss: 3.529857]\n",
      "epoch:18 step:14196 [D loss: 0.623943, acc: 57.81%] [G loss: 3.443278]\n",
      "epoch:18 step:14197 [D loss: 0.496212, acc: 75.00%] [G loss: 2.752047]\n",
      "epoch:18 step:14198 [D loss: 0.215895, acc: 99.22%] [G loss: 3.515450]\n",
      "epoch:18 step:14199 [D loss: 0.203084, acc: 97.66%] [G loss: 5.330312]\n",
      "epoch:18 step:14200 [D loss: 0.880491, acc: 50.78%] [G loss: 2.840545]\n",
      "##############\n",
      "[0.85599872 0.87353215 0.81588827 0.79769181 0.78209098 0.83394498\n",
      " 0.88739099 0.80902874 0.78086967 0.83818283]\n",
      "##########\n",
      "epoch:18 step:14201 [D loss: 0.843596, acc: 32.81%] [G loss: 2.160855]\n",
      "epoch:18 step:14202 [D loss: 0.553900, acc: 61.72%] [G loss: 3.221826]\n",
      "epoch:18 step:14203 [D loss: 1.164218, acc: 32.81%] [G loss: 2.454860]\n",
      "epoch:18 step:14204 [D loss: 0.123664, acc: 100.00%] [G loss: 3.999537]\n",
      "epoch:18 step:14205 [D loss: 0.467872, acc: 75.78%] [G loss: 2.731814]\n",
      "epoch:18 step:14206 [D loss: 0.252561, acc: 97.66%] [G loss: 4.482999]\n",
      "epoch:18 step:14207 [D loss: 0.365012, acc: 95.31%] [G loss: 2.211614]\n",
      "epoch:18 step:14208 [D loss: 0.943599, acc: 42.97%] [G loss: 1.627187]\n",
      "epoch:18 step:14209 [D loss: 0.757150, acc: 51.56%] [G loss: 2.542706]\n",
      "epoch:18 step:14210 [D loss: 0.526198, acc: 74.22%] [G loss: 2.241538]\n",
      "epoch:18 step:14211 [D loss: 0.511540, acc: 67.97%] [G loss: 2.366006]\n",
      "epoch:18 step:14212 [D loss: 0.264699, acc: 96.88%] [G loss: 3.791976]\n",
      "epoch:18 step:14213 [D loss: 0.458041, acc: 67.97%] [G loss: 2.709475]\n",
      "epoch:18 step:14214 [D loss: 0.231112, acc: 99.22%] [G loss: 2.931159]\n",
      "epoch:18 step:14215 [D loss: 0.208898, acc: 99.22%] [G loss: 2.549842]\n",
      "epoch:18 step:14216 [D loss: 0.180873, acc: 99.22%] [G loss: 3.890811]\n",
      "epoch:18 step:14217 [D loss: 0.668973, acc: 61.72%] [G loss: 2.542809]\n",
      "epoch:18 step:14218 [D loss: 0.698739, acc: 57.03%] [G loss: 2.180068]\n",
      "epoch:18 step:14219 [D loss: 0.295122, acc: 97.66%] [G loss: 3.021786]\n",
      "epoch:18 step:14220 [D loss: 0.534225, acc: 57.81%] [G loss: 2.676057]\n",
      "epoch:18 step:14221 [D loss: 0.514612, acc: 80.47%] [G loss: 2.961830]\n",
      "epoch:18 step:14222 [D loss: 0.354331, acc: 93.75%] [G loss: 4.063787]\n",
      "epoch:18 step:14223 [D loss: 0.481429, acc: 78.91%] [G loss: 3.228561]\n",
      "epoch:18 step:14224 [D loss: 0.893921, acc: 51.56%] [G loss: 3.615841]\n",
      "epoch:18 step:14225 [D loss: 0.783750, acc: 53.91%] [G loss: 2.227047]\n",
      "epoch:18 step:14226 [D loss: 0.563912, acc: 74.22%] [G loss: 2.770612]\n",
      "epoch:18 step:14227 [D loss: 0.481215, acc: 83.59%] [G loss: 2.737919]\n",
      "epoch:18 step:14228 [D loss: 0.332698, acc: 84.38%] [G loss: 2.299858]\n",
      "epoch:18 step:14229 [D loss: 0.436728, acc: 90.62%] [G loss: 2.037086]\n",
      "epoch:18 step:14230 [D loss: 0.369653, acc: 89.84%] [G loss: 2.459266]\n",
      "epoch:18 step:14231 [D loss: 0.243084, acc: 96.88%] [G loss: 1.906225]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:18 step:14232 [D loss: 0.404275, acc: 75.78%] [G loss: 3.369028]\n",
      "epoch:18 step:14233 [D loss: 0.168021, acc: 99.22%] [G loss: 3.730619]\n",
      "epoch:18 step:14234 [D loss: 1.015794, acc: 23.44%] [G loss: 3.158720]\n",
      "epoch:18 step:14235 [D loss: 0.451174, acc: 80.47%] [G loss: 2.755080]\n",
      "epoch:18 step:14236 [D loss: 0.665963, acc: 59.38%] [G loss: 2.623554]\n",
      "epoch:18 step:14237 [D loss: 0.775113, acc: 48.44%] [G loss: 2.838315]\n",
      "epoch:18 step:14238 [D loss: 0.459750, acc: 75.00%] [G loss: 2.609820]\n",
      "epoch:18 step:14239 [D loss: 0.473607, acc: 82.81%] [G loss: 2.414900]\n",
      "epoch:18 step:14240 [D loss: 1.011629, acc: 26.56%] [G loss: 1.978460]\n",
      "epoch:18 step:14241 [D loss: 0.195853, acc: 99.22%] [G loss: 1.894833]\n",
      "epoch:18 step:14242 [D loss: 0.823558, acc: 42.97%] [G loss: 3.162658]\n",
      "epoch:18 step:14243 [D loss: 0.575883, acc: 62.50%] [G loss: 1.738620]\n",
      "epoch:18 step:14244 [D loss: 0.293975, acc: 96.09%] [G loss: 2.611443]\n",
      "epoch:18 step:14245 [D loss: 0.241001, acc: 93.75%] [G loss: 2.850553]\n",
      "epoch:18 step:14246 [D loss: 0.247084, acc: 95.31%] [G loss: 1.454195]\n",
      "epoch:18 step:14247 [D loss: 0.060106, acc: 100.00%] [G loss: 3.381620]\n",
      "epoch:18 step:14248 [D loss: 0.214377, acc: 96.09%] [G loss: 2.811175]\n",
      "epoch:18 step:14249 [D loss: 0.187525, acc: 99.22%] [G loss: 3.520679]\n",
      "epoch:18 step:14250 [D loss: 0.241911, acc: 95.31%] [G loss: 2.441722]\n",
      "epoch:18 step:14251 [D loss: 0.094627, acc: 100.00%] [G loss: 3.714791]\n",
      "epoch:18 step:14252 [D loss: 0.339931, acc: 92.97%] [G loss: 3.026478]\n",
      "epoch:18 step:14253 [D loss: 0.650639, acc: 55.47%] [G loss: 2.356548]\n",
      "epoch:18 step:14254 [D loss: 0.512141, acc: 70.31%] [G loss: 2.088688]\n",
      "epoch:18 step:14255 [D loss: 1.064116, acc: 50.00%] [G loss: 3.466759]\n",
      "epoch:18 step:14256 [D loss: 0.511866, acc: 69.53%] [G loss: 2.252100]\n",
      "epoch:18 step:14257 [D loss: 0.299714, acc: 89.84%] [G loss: 2.239867]\n",
      "epoch:18 step:14258 [D loss: 0.439184, acc: 83.59%] [G loss: 2.379787]\n",
      "epoch:18 step:14259 [D loss: 0.213783, acc: 96.88%] [G loss: 2.704136]\n",
      "epoch:18 step:14260 [D loss: 1.169213, acc: 17.19%] [G loss: 2.205794]\n",
      "epoch:18 step:14261 [D loss: 0.716291, acc: 53.12%] [G loss: 2.176391]\n",
      "epoch:18 step:14262 [D loss: 0.452200, acc: 83.59%] [G loss: 2.458035]\n",
      "epoch:18 step:14263 [D loss: 0.684721, acc: 55.47%] [G loss: 2.070183]\n",
      "epoch:18 step:14264 [D loss: 0.889202, acc: 33.59%] [G loss: 1.929600]\n",
      "epoch:18 step:14265 [D loss: 0.743033, acc: 54.69%] [G loss: 2.112273]\n",
      "epoch:18 step:14266 [D loss: 0.329848, acc: 87.50%] [G loss: 3.152545]\n",
      "epoch:18 step:14267 [D loss: 0.822846, acc: 46.88%] [G loss: 2.677182]\n",
      "epoch:18 step:14268 [D loss: 0.605957, acc: 64.06%] [G loss: 1.518781]\n",
      "epoch:18 step:14269 [D loss: 1.136759, acc: 7.81%] [G loss: 2.000272]\n",
      "epoch:18 step:14270 [D loss: 0.280045, acc: 97.66%] [G loss: 3.442519]\n",
      "epoch:18 step:14271 [D loss: 0.989342, acc: 44.53%] [G loss: 2.270120]\n",
      "epoch:18 step:14272 [D loss: 0.272609, acc: 93.75%] [G loss: 4.174090]\n",
      "epoch:18 step:14273 [D loss: 0.731050, acc: 49.22%] [G loss: 1.834926]\n",
      "epoch:18 step:14274 [D loss: 0.804796, acc: 45.31%] [G loss: 2.266169]\n",
      "epoch:18 step:14275 [D loss: 0.587753, acc: 74.22%] [G loss: 2.619166]\n",
      "epoch:18 step:14276 [D loss: 0.236421, acc: 98.44%] [G loss: 2.618620]\n",
      "epoch:18 step:14277 [D loss: 0.671733, acc: 60.16%] [G loss: 3.012362]\n",
      "epoch:18 step:14278 [D loss: 0.590531, acc: 65.62%] [G loss: 2.074826]\n",
      "epoch:18 step:14279 [D loss: 0.457311, acc: 78.91%] [G loss: 2.673829]\n",
      "epoch:18 step:14280 [D loss: 0.280597, acc: 92.97%] [G loss: 2.183886]\n",
      "epoch:18 step:14281 [D loss: 0.333554, acc: 93.75%] [G loss: 2.316504]\n",
      "epoch:18 step:14282 [D loss: 0.534853, acc: 67.97%] [G loss: 2.189804]\n",
      "epoch:18 step:14283 [D loss: 0.448203, acc: 85.94%] [G loss: 3.011627]\n",
      "epoch:18 step:14284 [D loss: 0.491890, acc: 67.97%] [G loss: 2.724755]\n",
      "epoch:18 step:14285 [D loss: 0.426724, acc: 74.22%] [G loss: 3.442067]\n",
      "epoch:18 step:14286 [D loss: 0.348744, acc: 85.94%] [G loss: 2.432477]\n",
      "epoch:18 step:14287 [D loss: 0.239232, acc: 94.53%] [G loss: 4.123981]\n",
      "epoch:18 step:14288 [D loss: 0.661038, acc: 52.34%] [G loss: 3.493938]\n",
      "epoch:18 step:14289 [D loss: 0.068003, acc: 100.00%] [G loss: 3.722834]\n",
      "epoch:18 step:14290 [D loss: 0.355604, acc: 94.53%] [G loss: 2.633900]\n",
      "epoch:18 step:14291 [D loss: 0.501570, acc: 63.28%] [G loss: 3.044785]\n",
      "epoch:18 step:14292 [D loss: 0.770529, acc: 43.75%] [G loss: 2.518534]\n",
      "epoch:18 step:14293 [D loss: 0.517335, acc: 75.00%] [G loss: 3.602937]\n",
      "epoch:18 step:14294 [D loss: 0.258109, acc: 93.75%] [G loss: 3.025309]\n",
      "epoch:18 step:14295 [D loss: 0.201081, acc: 99.22%] [G loss: 3.097224]\n",
      "epoch:18 step:14296 [D loss: 0.496247, acc: 75.78%] [G loss: 2.443616]\n",
      "epoch:18 step:14297 [D loss: 0.400428, acc: 91.41%] [G loss: 1.645938]\n",
      "epoch:18 step:14298 [D loss: 1.104551, acc: 28.91%] [G loss: 1.462918]\n",
      "epoch:18 step:14299 [D loss: 0.745678, acc: 52.34%] [G loss: 2.006244]\n",
      "epoch:18 step:14300 [D loss: 0.235544, acc: 100.00%] [G loss: 3.569569]\n",
      "epoch:18 step:14301 [D loss: 0.399353, acc: 90.62%] [G loss: 3.380114]\n",
      "epoch:18 step:14302 [D loss: 0.490904, acc: 62.50%] [G loss: 3.958336]\n",
      "epoch:18 step:14303 [D loss: 1.561763, acc: 3.12%] [G loss: 2.088974]\n",
      "epoch:18 step:14304 [D loss: 1.204516, acc: 20.31%] [G loss: 2.111182]\n",
      "epoch:18 step:14305 [D loss: 0.678647, acc: 56.25%] [G loss: 2.796590]\n",
      "epoch:18 step:14306 [D loss: 0.444899, acc: 86.72%] [G loss: 2.767386]\n",
      "epoch:18 step:14307 [D loss: 0.432644, acc: 85.16%] [G loss: 3.238200]\n",
      "epoch:18 step:14308 [D loss: 0.454896, acc: 85.94%] [G loss: 4.226584]\n",
      "epoch:18 step:14309 [D loss: 0.459744, acc: 80.47%] [G loss: 2.536289]\n",
      "epoch:18 step:14310 [D loss: 0.470146, acc: 70.31%] [G loss: 3.011484]\n",
      "epoch:18 step:14311 [D loss: 0.943810, acc: 46.09%] [G loss: 2.326232]\n",
      "epoch:18 step:14312 [D loss: 0.882067, acc: 49.22%] [G loss: 2.464640]\n",
      "epoch:18 step:14313 [D loss: 0.151125, acc: 98.44%] [G loss: 3.697114]\n",
      "epoch:18 step:14314 [D loss: 0.625032, acc: 57.81%] [G loss: 2.784880]\n",
      "epoch:18 step:14315 [D loss: 0.755915, acc: 53.91%] [G loss: 2.204608]\n",
      "epoch:18 step:14316 [D loss: 0.491877, acc: 76.56%] [G loss: 3.158043]\n",
      "epoch:18 step:14317 [D loss: 0.212798, acc: 98.44%] [G loss: 2.432621]\n",
      "epoch:18 step:14318 [D loss: 0.261395, acc: 98.44%] [G loss: 2.867959]\n",
      "epoch:18 step:14319 [D loss: 1.289250, acc: 42.19%] [G loss: 1.715633]\n",
      "epoch:18 step:14320 [D loss: 0.502138, acc: 71.09%] [G loss: 2.764369]\n",
      "epoch:18 step:14321 [D loss: 0.511778, acc: 71.09%] [G loss: 2.548453]\n",
      "epoch:18 step:14322 [D loss: 0.425246, acc: 72.66%] [G loss: 2.360611]\n",
      "epoch:18 step:14323 [D loss: 0.573633, acc: 78.12%] [G loss: 2.933534]\n",
      "epoch:18 step:14324 [D loss: 0.468741, acc: 86.72%] [G loss: 2.753389]\n",
      "epoch:18 step:14325 [D loss: 0.887769, acc: 45.31%] [G loss: 1.781274]\n",
      "epoch:18 step:14326 [D loss: 0.563141, acc: 65.62%] [G loss: 2.918957]\n",
      "epoch:18 step:14327 [D loss: 0.435392, acc: 84.38%] [G loss: 2.296597]\n",
      "epoch:18 step:14328 [D loss: 0.771411, acc: 43.75%] [G loss: 2.211771]\n",
      "epoch:18 step:14329 [D loss: 0.999271, acc: 50.00%] [G loss: 1.816243]\n",
      "epoch:18 step:14330 [D loss: 0.429326, acc: 81.25%] [G loss: 2.263504]\n",
      "epoch:18 step:14331 [D loss: 0.357909, acc: 93.75%] [G loss: 3.396412]\n",
      "epoch:18 step:14332 [D loss: 0.872719, acc: 33.59%] [G loss: 2.117737]\n",
      "epoch:18 step:14333 [D loss: 0.252219, acc: 99.22%] [G loss: 4.274585]\n",
      "epoch:18 step:14334 [D loss: 0.556602, acc: 63.28%] [G loss: 3.695807]\n",
      "epoch:18 step:14335 [D loss: 0.338539, acc: 94.53%] [G loss: 2.243375]\n",
      "epoch:18 step:14336 [D loss: 0.332107, acc: 94.53%] [G loss: 1.948844]\n",
      "epoch:18 step:14337 [D loss: 0.444958, acc: 71.09%] [G loss: 2.984147]\n",
      "epoch:18 step:14338 [D loss: 0.224112, acc: 97.66%] [G loss: 2.015481]\n",
      "epoch:18 step:14339 [D loss: 0.896188, acc: 32.03%] [G loss: 3.942989]\n",
      "epoch:18 step:14340 [D loss: 0.320749, acc: 93.75%] [G loss: 3.517661]\n",
      "epoch:18 step:14341 [D loss: 0.764966, acc: 53.12%] [G loss: 2.946845]\n",
      "epoch:18 step:14342 [D loss: 0.322007, acc: 90.62%] [G loss: 2.179446]\n",
      "epoch:18 step:14343 [D loss: 0.662810, acc: 62.50%] [G loss: 2.443243]\n",
      "epoch:18 step:14344 [D loss: 0.332573, acc: 93.75%] [G loss: 2.516473]\n",
      "epoch:18 step:14345 [D loss: 0.526946, acc: 80.47%] [G loss: 2.458704]\n",
      "epoch:18 step:14346 [D loss: 0.600816, acc: 71.09%] [G loss: 3.537095]\n",
      "epoch:18 step:14347 [D loss: 0.855094, acc: 43.75%] [G loss: 3.005337]\n",
      "epoch:18 step:14348 [D loss: 0.912186, acc: 38.28%] [G loss: 2.676962]\n",
      "epoch:18 step:14349 [D loss: 0.877253, acc: 47.66%] [G loss: 2.733995]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:18 step:14350 [D loss: 0.506801, acc: 80.47%] [G loss: 2.524472]\n",
      "epoch:18 step:14351 [D loss: 0.558709, acc: 76.56%] [G loss: 3.144088]\n",
      "epoch:18 step:14352 [D loss: 0.728116, acc: 54.69%] [G loss: 2.261422]\n",
      "epoch:18 step:14353 [D loss: 0.312929, acc: 94.53%] [G loss: 3.113356]\n",
      "epoch:18 step:14354 [D loss: 0.299073, acc: 93.75%] [G loss: 3.174927]\n",
      "epoch:18 step:14355 [D loss: 0.585748, acc: 61.72%] [G loss: 2.029815]\n",
      "epoch:18 step:14356 [D loss: 0.271461, acc: 96.09%] [G loss: 1.621939]\n",
      "epoch:18 step:14357 [D loss: 0.549884, acc: 69.53%] [G loss: 3.196881]\n",
      "epoch:18 step:14358 [D loss: 0.844281, acc: 50.00%] [G loss: 2.158568]\n",
      "epoch:18 step:14359 [D loss: 0.973397, acc: 31.25%] [G loss: 2.390364]\n",
      "epoch:18 step:14360 [D loss: 0.616409, acc: 67.19%] [G loss: 2.160134]\n",
      "epoch:18 step:14361 [D loss: 0.613924, acc: 67.19%] [G loss: 3.014261]\n",
      "epoch:18 step:14362 [D loss: 0.585015, acc: 70.31%] [G loss: 2.029856]\n",
      "epoch:18 step:14363 [D loss: 0.233530, acc: 99.22%] [G loss: 3.361464]\n",
      "epoch:18 step:14364 [D loss: 0.468113, acc: 85.94%] [G loss: 2.745056]\n",
      "epoch:18 step:14365 [D loss: 0.988703, acc: 24.22%] [G loss: 2.778784]\n",
      "epoch:18 step:14366 [D loss: 0.213075, acc: 98.44%] [G loss: 3.954298]\n",
      "epoch:18 step:14367 [D loss: 0.540592, acc: 64.84%] [G loss: 2.372847]\n",
      "epoch:18 step:14368 [D loss: 0.601148, acc: 64.84%] [G loss: 2.437435]\n",
      "epoch:18 step:14369 [D loss: 0.770748, acc: 50.78%] [G loss: 2.858059]\n",
      "epoch:18 step:14370 [D loss: 0.412243, acc: 89.06%] [G loss: 2.133082]\n",
      "epoch:18 step:14371 [D loss: 0.524159, acc: 81.25%] [G loss: 3.582572]\n",
      "epoch:18 step:14372 [D loss: 0.367805, acc: 90.62%] [G loss: 2.940073]\n",
      "epoch:18 step:14373 [D loss: 1.659174, acc: 2.34%] [G loss: 2.173445]\n",
      "epoch:18 step:14374 [D loss: 0.594859, acc: 60.16%] [G loss: 2.666643]\n",
      "epoch:18 step:14375 [D loss: 0.304023, acc: 92.97%] [G loss: 2.290369]\n",
      "epoch:18 step:14376 [D loss: 0.929357, acc: 38.28%] [G loss: 2.125874]\n",
      "epoch:18 step:14377 [D loss: 0.273053, acc: 96.88%] [G loss: 2.911037]\n",
      "epoch:18 step:14378 [D loss: 0.511608, acc: 79.69%] [G loss: 2.218648]\n",
      "epoch:18 step:14379 [D loss: 0.589887, acc: 67.19%] [G loss: 3.388073]\n",
      "epoch:18 step:14380 [D loss: 0.283366, acc: 94.53%] [G loss: 3.657894]\n",
      "epoch:18 step:14381 [D loss: 0.268107, acc: 97.66%] [G loss: 4.700461]\n",
      "epoch:18 step:14382 [D loss: 0.559141, acc: 74.22%] [G loss: 3.025285]\n",
      "epoch:18 step:14383 [D loss: 0.308753, acc: 94.53%] [G loss: 2.591557]\n",
      "epoch:18 step:14384 [D loss: 0.221143, acc: 94.53%] [G loss: 1.858233]\n",
      "epoch:18 step:14385 [D loss: 0.243978, acc: 96.09%] [G loss: 2.618142]\n",
      "epoch:18 step:14386 [D loss: 0.267011, acc: 96.88%] [G loss: 3.445609]\n",
      "epoch:18 step:14387 [D loss: 0.565129, acc: 62.50%] [G loss: 3.119299]\n",
      "epoch:18 step:14388 [D loss: 0.289453, acc: 94.53%] [G loss: 2.833540]\n",
      "epoch:18 step:14389 [D loss: 0.573433, acc: 75.00%] [G loss: 3.785691]\n",
      "epoch:18 step:14390 [D loss: 0.563358, acc: 64.06%] [G loss: 3.463472]\n",
      "epoch:18 step:14391 [D loss: 0.224181, acc: 99.22%] [G loss: 2.958303]\n",
      "epoch:18 step:14392 [D loss: 1.052165, acc: 32.03%] [G loss: 2.907611]\n",
      "epoch:18 step:14393 [D loss: 0.406516, acc: 89.06%] [G loss: 3.411601]\n",
      "epoch:18 step:14394 [D loss: 0.776171, acc: 50.78%] [G loss: 3.291025]\n",
      "epoch:18 step:14395 [D loss: 0.581178, acc: 68.75%] [G loss: 2.017575]\n",
      "epoch:18 step:14396 [D loss: 0.322425, acc: 98.44%] [G loss: 3.371892]\n",
      "epoch:18 step:14397 [D loss: 0.624610, acc: 61.72%] [G loss: 2.502481]\n",
      "epoch:18 step:14398 [D loss: 0.912208, acc: 29.69%] [G loss: 3.355679]\n",
      "epoch:18 step:14399 [D loss: 0.157528, acc: 100.00%] [G loss: 3.112828]\n",
      "epoch:18 step:14400 [D loss: 0.714702, acc: 49.22%] [G loss: 2.740568]\n",
      "##############\n",
      "[0.84179313 0.88896908 0.80334707 0.82025127 0.77805053 0.82831717\n",
      " 0.89309545 0.8287153  0.80725686 0.83673767]\n",
      "##########\n",
      "epoch:18 step:14401 [D loss: 0.507596, acc: 65.62%] [G loss: 3.820773]\n",
      "epoch:18 step:14402 [D loss: 0.353425, acc: 96.09%] [G loss: 2.768151]\n",
      "epoch:18 step:14403 [D loss: 0.629356, acc: 56.25%] [G loss: 3.452165]\n",
      "epoch:18 step:14404 [D loss: 0.318547, acc: 95.31%] [G loss: 1.904671]\n",
      "epoch:18 step:14405 [D loss: 0.173994, acc: 100.00%] [G loss: 2.856956]\n",
      "epoch:18 step:14406 [D loss: 0.947120, acc: 39.84%] [G loss: 3.917742]\n",
      "epoch:18 step:14407 [D loss: 0.817555, acc: 39.06%] [G loss: 3.180973]\n",
      "epoch:18 step:14408 [D loss: 0.276124, acc: 95.31%] [G loss: 3.176441]\n",
      "epoch:18 step:14409 [D loss: 0.777400, acc: 50.00%] [G loss: 2.281212]\n",
      "epoch:18 step:14410 [D loss: 0.127861, acc: 100.00%] [G loss: 3.941362]\n",
      "epoch:18 step:14411 [D loss: 0.472641, acc: 82.03%] [G loss: 1.975880]\n",
      "epoch:18 step:14412 [D loss: 0.428452, acc: 86.72%] [G loss: 1.883391]\n",
      "epoch:18 step:14413 [D loss: 0.573945, acc: 67.19%] [G loss: 3.392967]\n",
      "epoch:18 step:14414 [D loss: 0.653693, acc: 58.59%] [G loss: 2.867186]\n",
      "epoch:18 step:14415 [D loss: 0.772580, acc: 52.34%] [G loss: 2.884501]\n",
      "epoch:18 step:14416 [D loss: 0.396679, acc: 75.78%] [G loss: 2.514111]\n",
      "epoch:18 step:14417 [D loss: 0.517810, acc: 80.47%] [G loss: 3.295209]\n",
      "epoch:18 step:14418 [D loss: 0.374328, acc: 89.06%] [G loss: 2.955719]\n",
      "epoch:18 step:14419 [D loss: 0.292868, acc: 95.31%] [G loss: 3.231916]\n",
      "epoch:18 step:14420 [D loss: 0.234730, acc: 97.66%] [G loss: 3.519566]\n",
      "epoch:18 step:14421 [D loss: 0.884260, acc: 38.28%] [G loss: 3.352197]\n",
      "epoch:18 step:14422 [D loss: 0.278379, acc: 95.31%] [G loss: 2.062947]\n",
      "epoch:18 step:14423 [D loss: 0.510418, acc: 75.78%] [G loss: 2.428407]\n",
      "epoch:18 step:14424 [D loss: 0.707671, acc: 51.56%] [G loss: 3.350850]\n",
      "epoch:18 step:14425 [D loss: 0.633843, acc: 63.28%] [G loss: 2.336534]\n",
      "epoch:18 step:14426 [D loss: 0.077967, acc: 100.00%] [G loss: 5.628585]\n",
      "epoch:18 step:14427 [D loss: 0.508602, acc: 82.81%] [G loss: 2.228851]\n",
      "epoch:18 step:14428 [D loss: 0.499930, acc: 70.31%] [G loss: 2.360102]\n",
      "epoch:18 step:14429 [D loss: 0.322942, acc: 95.31%] [G loss: 2.974840]\n",
      "epoch:18 step:14430 [D loss: 0.190150, acc: 99.22%] [G loss: 2.523403]\n",
      "epoch:18 step:14431 [D loss: 0.886272, acc: 31.25%] [G loss: 3.100392]\n",
      "epoch:18 step:14432 [D loss: 0.595050, acc: 64.84%] [G loss: 2.540337]\n",
      "epoch:18 step:14433 [D loss: 0.777836, acc: 41.41%] [G loss: 2.369442]\n",
      "epoch:18 step:14434 [D loss: 0.657189, acc: 56.25%] [G loss: 3.744223]\n",
      "epoch:18 step:14435 [D loss: 0.449896, acc: 72.66%] [G loss: 2.955243]\n",
      "epoch:18 step:14436 [D loss: 0.628970, acc: 66.41%] [G loss: 4.175125]\n",
      "epoch:18 step:14437 [D loss: 0.378276, acc: 85.16%] [G loss: 3.265888]\n",
      "epoch:18 step:14438 [D loss: 0.868093, acc: 35.16%] [G loss: 1.956845]\n",
      "epoch:18 step:14439 [D loss: 0.296696, acc: 90.62%] [G loss: 4.099141]\n",
      "epoch:18 step:14440 [D loss: 0.371271, acc: 90.62%] [G loss: 2.195067]\n",
      "epoch:18 step:14441 [D loss: 0.370750, acc: 92.19%] [G loss: 3.045481]\n",
      "epoch:18 step:14442 [D loss: 0.390950, acc: 91.41%] [G loss: 3.613487]\n",
      "epoch:18 step:14443 [D loss: 0.291406, acc: 96.88%] [G loss: 2.690264]\n",
      "epoch:18 step:14444 [D loss: 0.252138, acc: 97.66%] [G loss: 3.281816]\n",
      "epoch:18 step:14445 [D loss: 0.772795, acc: 48.44%] [G loss: 3.617712]\n",
      "epoch:18 step:14446 [D loss: 0.952068, acc: 28.91%] [G loss: 2.776317]\n",
      "epoch:18 step:14447 [D loss: 0.802873, acc: 44.53%] [G loss: 3.342949]\n",
      "epoch:18 step:14448 [D loss: 0.933831, acc: 31.25%] [G loss: 2.294517]\n",
      "epoch:18 step:14449 [D loss: 1.530706, acc: 2.34%] [G loss: 1.814644]\n",
      "epoch:18 step:14450 [D loss: 0.365765, acc: 91.41%] [G loss: 2.619229]\n",
      "epoch:18 step:14451 [D loss: 0.733889, acc: 50.78%] [G loss: 2.598828]\n",
      "epoch:18 step:14452 [D loss: 0.365170, acc: 89.06%] [G loss: 3.958014]\n",
      "epoch:18 step:14453 [D loss: 0.681372, acc: 54.69%] [G loss: 1.814936]\n",
      "epoch:18 step:14454 [D loss: 0.797893, acc: 46.09%] [G loss: 1.929156]\n",
      "epoch:18 step:14455 [D loss: 0.794705, acc: 50.78%] [G loss: 1.651809]\n",
      "epoch:18 step:14456 [D loss: 0.704124, acc: 58.59%] [G loss: 2.644050]\n",
      "epoch:18 step:14457 [D loss: 0.203394, acc: 99.22%] [G loss: 2.458114]\n",
      "epoch:18 step:14458 [D loss: 0.208932, acc: 99.22%] [G loss: 4.173580]\n",
      "epoch:18 step:14459 [D loss: 0.528725, acc: 67.19%] [G loss: 3.765341]\n",
      "epoch:18 step:14460 [D loss: 0.460858, acc: 78.91%] [G loss: 3.243370]\n",
      "epoch:18 step:14461 [D loss: 0.241543, acc: 93.75%] [G loss: 2.350884]\n",
      "epoch:18 step:14462 [D loss: 0.497514, acc: 74.22%] [G loss: 2.921382]\n",
      "epoch:18 step:14463 [D loss: 0.432724, acc: 90.62%] [G loss: 4.057535]\n",
      "epoch:18 step:14464 [D loss: 0.468511, acc: 85.16%] [G loss: 3.333344]\n",
      "epoch:18 step:14465 [D loss: 0.295114, acc: 97.66%] [G loss: 5.392066]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:18 step:14466 [D loss: 0.308834, acc: 95.31%] [G loss: 3.135710]\n",
      "epoch:18 step:14467 [D loss: 0.640832, acc: 60.94%] [G loss: 3.060040]\n",
      "epoch:18 step:14468 [D loss: 0.240548, acc: 97.66%] [G loss: 2.180081]\n",
      "epoch:18 step:14469 [D loss: 0.589086, acc: 71.88%] [G loss: 2.740003]\n",
      "epoch:18 step:14470 [D loss: 0.705473, acc: 53.91%] [G loss: 2.397809]\n",
      "epoch:18 step:14471 [D loss: 0.841660, acc: 39.06%] [G loss: 1.836470]\n",
      "epoch:18 step:14472 [D loss: 0.203365, acc: 97.66%] [G loss: 3.395925]\n",
      "epoch:18 step:14473 [D loss: 0.702456, acc: 52.34%] [G loss: 2.287683]\n",
      "epoch:18 step:14474 [D loss: 0.432433, acc: 83.59%] [G loss: 2.623602]\n",
      "epoch:18 step:14475 [D loss: 0.062372, acc: 100.00%] [G loss: 3.567301]\n",
      "epoch:18 step:14476 [D loss: 0.676499, acc: 53.91%] [G loss: 2.453999]\n",
      "epoch:18 step:14477 [D loss: 0.293771, acc: 94.53%] [G loss: 2.674897]\n",
      "epoch:18 step:14478 [D loss: 0.588614, acc: 71.88%] [G loss: 2.135346]\n",
      "epoch:18 step:14479 [D loss: 0.235204, acc: 100.00%] [G loss: 4.166811]\n",
      "epoch:18 step:14480 [D loss: 0.336103, acc: 91.41%] [G loss: 3.455343]\n",
      "epoch:18 step:14481 [D loss: 0.724172, acc: 54.69%] [G loss: 2.756380]\n",
      "epoch:18 step:14482 [D loss: 0.547670, acc: 70.31%] [G loss: 2.483916]\n",
      "epoch:18 step:14483 [D loss: 0.315060, acc: 95.31%] [G loss: 2.800309]\n",
      "epoch:18 step:14484 [D loss: 0.422497, acc: 89.84%] [G loss: 2.577724]\n",
      "epoch:18 step:14485 [D loss: 0.328278, acc: 90.62%] [G loss: 2.486722]\n",
      "epoch:18 step:14486 [D loss: 0.550173, acc: 75.78%] [G loss: 2.673717]\n",
      "epoch:18 step:14487 [D loss: 0.467353, acc: 85.94%] [G loss: 1.886440]\n",
      "epoch:18 step:14488 [D loss: 0.366773, acc: 74.22%] [G loss: 2.832699]\n",
      "epoch:18 step:14489 [D loss: 1.054609, acc: 35.16%] [G loss: 2.498556]\n",
      "epoch:18 step:14490 [D loss: 0.407710, acc: 86.72%] [G loss: 3.346731]\n",
      "epoch:18 step:14491 [D loss: 0.342536, acc: 86.72%] [G loss: 2.596148]\n",
      "epoch:18 step:14492 [D loss: 0.561864, acc: 58.59%] [G loss: 4.313894]\n",
      "epoch:18 step:14493 [D loss: 0.476225, acc: 81.25%] [G loss: 3.392542]\n",
      "epoch:18 step:14494 [D loss: 0.934385, acc: 52.34%] [G loss: 3.956043]\n",
      "epoch:18 step:14495 [D loss: 0.225354, acc: 98.44%] [G loss: 2.372212]\n",
      "epoch:18 step:14496 [D loss: 0.895280, acc: 50.00%] [G loss: 2.870556]\n",
      "epoch:18 step:14497 [D loss: 0.374681, acc: 96.88%] [G loss: 2.605608]\n",
      "epoch:18 step:14498 [D loss: 0.284263, acc: 96.09%] [G loss: 2.816000]\n",
      "epoch:18 step:14499 [D loss: 0.323514, acc: 84.38%] [G loss: 4.395665]\n",
      "epoch:18 step:14500 [D loss: 0.230101, acc: 99.22%] [G loss: 2.706216]\n",
      "epoch:18 step:14501 [D loss: 0.795706, acc: 52.34%] [G loss: 2.407215]\n",
      "epoch:18 step:14502 [D loss: 0.526271, acc: 65.62%] [G loss: 3.707860]\n",
      "epoch:18 step:14503 [D loss: 0.697131, acc: 57.03%] [G loss: 2.839351]\n",
      "epoch:18 step:14504 [D loss: 0.310129, acc: 96.09%] [G loss: 2.829673]\n",
      "epoch:18 step:14505 [D loss: 0.542769, acc: 75.78%] [G loss: 3.433426]\n",
      "epoch:18 step:14506 [D loss: 0.878518, acc: 45.31%] [G loss: 3.359606]\n",
      "epoch:18 step:14507 [D loss: 0.687992, acc: 61.72%] [G loss: 2.591245]\n",
      "epoch:18 step:14508 [D loss: 0.484570, acc: 79.69%] [G loss: 2.693832]\n",
      "epoch:18 step:14509 [D loss: 0.233683, acc: 99.22%] [G loss: 2.991386]\n",
      "epoch:18 step:14510 [D loss: 0.541034, acc: 79.69%] [G loss: 3.311813]\n",
      "epoch:18 step:14511 [D loss: 1.109069, acc: 35.94%] [G loss: 3.811525]\n",
      "epoch:18 step:14512 [D loss: 0.336190, acc: 95.31%] [G loss: 4.187763]\n",
      "epoch:18 step:14513 [D loss: 0.945316, acc: 33.59%] [G loss: 2.002559]\n",
      "epoch:18 step:14514 [D loss: 1.056529, acc: 26.56%] [G loss: 1.776017]\n",
      "epoch:18 step:14515 [D loss: 0.740349, acc: 49.22%] [G loss: 2.651983]\n",
      "epoch:18 step:14516 [D loss: 0.645065, acc: 64.06%] [G loss: 2.640938]\n",
      "epoch:18 step:14517 [D loss: 0.479399, acc: 73.44%] [G loss: 3.232182]\n",
      "epoch:18 step:14518 [D loss: 0.255354, acc: 92.19%] [G loss: 3.924925]\n",
      "epoch:18 step:14519 [D loss: 0.577165, acc: 78.12%] [G loss: 3.610104]\n",
      "epoch:18 step:14520 [D loss: 0.277663, acc: 89.06%] [G loss: 3.563861]\n",
      "epoch:18 step:14521 [D loss: 0.754205, acc: 51.56%] [G loss: 2.621352]\n",
      "epoch:18 step:14522 [D loss: 0.285618, acc: 92.97%] [G loss: 4.263444]\n",
      "epoch:18 step:14523 [D loss: 0.343308, acc: 95.31%] [G loss: 3.044501]\n",
      "epoch:18 step:14524 [D loss: 0.159925, acc: 100.00%] [G loss: 3.158612]\n",
      "epoch:18 step:14525 [D loss: 0.745978, acc: 52.34%] [G loss: 2.356224]\n",
      "epoch:18 step:14526 [D loss: 0.540170, acc: 77.34%] [G loss: 2.437888]\n",
      "epoch:18 step:14527 [D loss: 0.133937, acc: 100.00%] [G loss: 3.216514]\n",
      "epoch:18 step:14528 [D loss: 0.405093, acc: 87.50%] [G loss: 2.363739]\n",
      "epoch:18 step:14529 [D loss: 0.368372, acc: 93.75%] [G loss: 3.095353]\n",
      "epoch:18 step:14530 [D loss: 0.724491, acc: 53.12%] [G loss: 2.876434]\n",
      "epoch:18 step:14531 [D loss: 1.072618, acc: 23.44%] [G loss: 2.085381]\n",
      "epoch:18 step:14532 [D loss: 0.706042, acc: 54.69%] [G loss: 2.384293]\n",
      "epoch:18 step:14533 [D loss: 0.449876, acc: 84.38%] [G loss: 2.157940]\n",
      "epoch:18 step:14534 [D loss: 0.135179, acc: 99.22%] [G loss: 2.677141]\n",
      "epoch:18 step:14535 [D loss: 0.762871, acc: 53.91%] [G loss: 2.851799]\n",
      "epoch:18 step:14536 [D loss: 0.358633, acc: 82.03%] [G loss: 4.391304]\n",
      "epoch:18 step:14537 [D loss: 0.945838, acc: 50.00%] [G loss: 2.756863]\n",
      "epoch:18 step:14538 [D loss: 0.664039, acc: 56.25%] [G loss: 2.436978]\n",
      "epoch:18 step:14539 [D loss: 0.558139, acc: 73.44%] [G loss: 3.658053]\n",
      "epoch:18 step:14540 [D loss: 1.098424, acc: 16.41%] [G loss: 2.027326]\n",
      "epoch:18 step:14541 [D loss: 0.445280, acc: 73.44%] [G loss: 1.898991]\n",
      "epoch:18 step:14542 [D loss: 0.657975, acc: 57.81%] [G loss: 2.589445]\n",
      "epoch:18 step:14543 [D loss: 0.436304, acc: 85.16%] [G loss: 2.146244]\n",
      "epoch:18 step:14544 [D loss: 0.597644, acc: 59.38%] [G loss: 2.249783]\n",
      "epoch:18 step:14545 [D loss: 0.485715, acc: 79.69%] [G loss: 2.942028]\n",
      "epoch:18 step:14546 [D loss: 0.284350, acc: 96.09%] [G loss: 3.154933]\n",
      "epoch:18 step:14547 [D loss: 0.897554, acc: 36.72%] [G loss: 2.134527]\n",
      "epoch:18 step:14548 [D loss: 0.357752, acc: 94.53%] [G loss: 2.873320]\n",
      "epoch:18 step:14549 [D loss: 0.888827, acc: 34.38%] [G loss: 1.636129]\n",
      "epoch:18 step:14550 [D loss: 0.406594, acc: 89.06%] [G loss: 2.338316]\n",
      "epoch:18 step:14551 [D loss: 0.328738, acc: 87.50%] [G loss: 2.706726]\n",
      "epoch:18 step:14552 [D loss: 0.642680, acc: 58.59%] [G loss: 2.337216]\n",
      "epoch:18 step:14553 [D loss: 0.396591, acc: 82.03%] [G loss: 2.932786]\n",
      "epoch:18 step:14554 [D loss: 0.206753, acc: 100.00%] [G loss: 2.852212]\n",
      "epoch:18 step:14555 [D loss: 0.490413, acc: 83.59%] [G loss: 2.457673]\n",
      "epoch:18 step:14556 [D loss: 0.804882, acc: 49.22%] [G loss: 2.740162]\n",
      "epoch:18 step:14557 [D loss: 0.550432, acc: 67.19%] [G loss: 2.866504]\n",
      "epoch:18 step:14558 [D loss: 0.660976, acc: 59.38%] [G loss: 2.655394]\n",
      "epoch:18 step:14559 [D loss: 0.401132, acc: 85.94%] [G loss: 2.325902]\n",
      "epoch:18 step:14560 [D loss: 0.464170, acc: 82.81%] [G loss: 2.855562]\n",
      "epoch:18 step:14561 [D loss: 0.327242, acc: 94.53%] [G loss: 3.432909]\n",
      "epoch:18 step:14562 [D loss: 0.401519, acc: 85.16%] [G loss: 2.843090]\n",
      "epoch:18 step:14563 [D loss: 0.772831, acc: 46.09%] [G loss: 2.077596]\n",
      "epoch:18 step:14564 [D loss: 0.414362, acc: 88.28%] [G loss: 3.352407]\n",
      "epoch:18 step:14565 [D loss: 0.501152, acc: 82.81%] [G loss: 3.551813]\n",
      "epoch:18 step:14566 [D loss: 0.817690, acc: 47.66%] [G loss: 2.437907]\n",
      "epoch:18 step:14567 [D loss: 0.287059, acc: 97.66%] [G loss: 4.151241]\n",
      "epoch:18 step:14568 [D loss: 0.408878, acc: 90.62%] [G loss: 3.848118]\n",
      "epoch:18 step:14569 [D loss: 0.100658, acc: 100.00%] [G loss: 5.697555]\n",
      "epoch:18 step:14570 [D loss: 0.779110, acc: 50.78%] [G loss: 3.001908]\n",
      "epoch:18 step:14571 [D loss: 0.448473, acc: 87.50%] [G loss: 3.318827]\n",
      "epoch:18 step:14572 [D loss: 0.440881, acc: 85.16%] [G loss: 2.954300]\n",
      "epoch:18 step:14573 [D loss: 0.515817, acc: 78.12%] [G loss: 2.670792]\n",
      "epoch:18 step:14574 [D loss: 0.484257, acc: 81.25%] [G loss: 3.189531]\n",
      "epoch:18 step:14575 [D loss: 0.356993, acc: 92.97%] [G loss: 4.262632]\n",
      "epoch:18 step:14576 [D loss: 0.391868, acc: 83.59%] [G loss: 2.476374]\n",
      "epoch:18 step:14577 [D loss: 1.482040, acc: 2.34%] [G loss: 2.501614]\n",
      "epoch:18 step:14578 [D loss: 0.218572, acc: 99.22%] [G loss: 3.883638]\n",
      "epoch:18 step:14579 [D loss: 0.404725, acc: 91.41%] [G loss: 3.320529]\n",
      "epoch:18 step:14580 [D loss: 0.457922, acc: 82.03%] [G loss: 1.712936]\n",
      "epoch:18 step:14581 [D loss: 0.176135, acc: 100.00%] [G loss: 2.922013]\n",
      "epoch:18 step:14582 [D loss: 0.308054, acc: 96.88%] [G loss: 1.874095]\n",
      "epoch:18 step:14583 [D loss: 0.822236, acc: 46.09%] [G loss: 2.113994]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:18 step:14584 [D loss: 0.937038, acc: 45.31%] [G loss: 4.266162]\n",
      "epoch:18 step:14585 [D loss: 0.503705, acc: 71.88%] [G loss: 2.605219]\n",
      "epoch:18 step:14586 [D loss: 0.430939, acc: 91.41%] [G loss: 2.634326]\n",
      "epoch:18 step:14587 [D loss: 0.372139, acc: 88.28%] [G loss: 3.267243]\n",
      "epoch:18 step:14588 [D loss: 0.686937, acc: 59.38%] [G loss: 3.269036]\n",
      "epoch:18 step:14589 [D loss: 0.403580, acc: 93.75%] [G loss: 2.267738]\n",
      "epoch:18 step:14590 [D loss: 0.763951, acc: 51.56%] [G loss: 3.112348]\n",
      "epoch:18 step:14591 [D loss: 0.934191, acc: 44.53%] [G loss: 1.774732]\n",
      "epoch:18 step:14592 [D loss: 0.252208, acc: 97.66%] [G loss: 2.985527]\n",
      "epoch:18 step:14593 [D loss: 0.861449, acc: 36.72%] [G loss: 1.463542]\n",
      "epoch:18 step:14594 [D loss: 0.485438, acc: 77.34%] [G loss: 2.907732]\n",
      "epoch:18 step:14595 [D loss: 0.342754, acc: 94.53%] [G loss: 2.602609]\n",
      "epoch:18 step:14596 [D loss: 0.175978, acc: 100.00%] [G loss: 3.256486]\n",
      "epoch:18 step:14597 [D loss: 0.761253, acc: 53.12%] [G loss: 1.972398]\n",
      "epoch:18 step:14598 [D loss: 0.464314, acc: 87.50%] [G loss: 2.630677]\n",
      "epoch:18 step:14599 [D loss: 0.094691, acc: 100.00%] [G loss: 3.849412]\n",
      "epoch:18 step:14600 [D loss: 0.448400, acc: 88.28%] [G loss: 2.550854]\n",
      "##############\n",
      "[0.85990552 0.87677656 0.82511346 0.8172438  0.78600003 0.84233814\n",
      " 0.90924022 0.82437192 0.80807537 0.81948948]\n",
      "##########\n",
      "epoch:18 step:14601 [D loss: 1.142079, acc: 46.09%] [G loss: 1.862453]\n",
      "epoch:18 step:14602 [D loss: 0.406892, acc: 85.94%] [G loss: 2.928879]\n",
      "epoch:18 step:14603 [D loss: 0.441286, acc: 85.16%] [G loss: 2.373011]\n",
      "epoch:18 step:14604 [D loss: 0.877042, acc: 46.09%] [G loss: 2.010977]\n",
      "epoch:18 step:14605 [D loss: 0.516998, acc: 73.44%] [G loss: 2.533653]\n",
      "epoch:18 step:14606 [D loss: 0.551124, acc: 61.72%] [G loss: 2.352871]\n",
      "epoch:18 step:14607 [D loss: 1.070826, acc: 44.53%] [G loss: 2.045603]\n",
      "epoch:18 step:14608 [D loss: 0.471688, acc: 76.56%] [G loss: 2.552933]\n",
      "epoch:18 step:14609 [D loss: 0.216671, acc: 96.09%] [G loss: 2.670039]\n",
      "epoch:18 step:14610 [D loss: 1.281390, acc: 6.25%] [G loss: 2.289546]\n",
      "epoch:18 step:14611 [D loss: 0.803155, acc: 43.75%] [G loss: 2.535391]\n",
      "epoch:18 step:14612 [D loss: 0.684642, acc: 62.50%] [G loss: 2.314075]\n",
      "epoch:18 step:14613 [D loss: 0.218800, acc: 99.22%] [G loss: 3.466915]\n",
      "epoch:18 step:14614 [D loss: 0.728730, acc: 53.91%] [G loss: 2.300587]\n",
      "epoch:18 step:14615 [D loss: 0.626967, acc: 67.19%] [G loss: 3.138095]\n",
      "epoch:18 step:14616 [D loss: 0.368213, acc: 88.28%] [G loss: 2.922889]\n",
      "epoch:18 step:14617 [D loss: 0.519909, acc: 79.69%] [G loss: 2.027177]\n",
      "epoch:18 step:14618 [D loss: 0.499106, acc: 76.56%] [G loss: 3.409480]\n",
      "epoch:18 step:14619 [D loss: 0.567124, acc: 74.22%] [G loss: 2.989419]\n",
      "epoch:18 step:14620 [D loss: 0.795641, acc: 46.09%] [G loss: 2.629022]\n",
      "epoch:18 step:14621 [D loss: 0.321869, acc: 95.31%] [G loss: 2.833365]\n",
      "epoch:18 step:14622 [D loss: 0.631629, acc: 59.38%] [G loss: 2.516300]\n",
      "epoch:18 step:14623 [D loss: 0.386746, acc: 85.16%] [G loss: 3.721644]\n",
      "epoch:18 step:14624 [D loss: 0.753282, acc: 47.66%] [G loss: 2.649902]\n",
      "epoch:18 step:14625 [D loss: 0.431865, acc: 71.09%] [G loss: 2.273453]\n",
      "epoch:18 step:14626 [D loss: 0.541598, acc: 73.44%] [G loss: 2.695812]\n",
      "epoch:18 step:14627 [D loss: 0.198857, acc: 98.44%] [G loss: 2.563477]\n",
      "epoch:18 step:14628 [D loss: 0.261458, acc: 96.09%] [G loss: 1.467925]\n",
      "epoch:18 step:14629 [D loss: 0.840894, acc: 37.50%] [G loss: 2.509322]\n",
      "epoch:18 step:14630 [D loss: 0.642127, acc: 62.50%] [G loss: 2.288389]\n",
      "epoch:18 step:14631 [D loss: 0.742211, acc: 51.56%] [G loss: 2.167457]\n",
      "epoch:18 step:14632 [D loss: 0.253074, acc: 91.41%] [G loss: 2.394315]\n",
      "epoch:18 step:14633 [D loss: 0.661659, acc: 61.72%] [G loss: 2.329340]\n",
      "epoch:18 step:14634 [D loss: 0.370047, acc: 93.75%] [G loss: 2.097040]\n",
      "epoch:18 step:14635 [D loss: 0.647354, acc: 61.72%] [G loss: 3.425792]\n",
      "epoch:18 step:14636 [D loss: 0.327944, acc: 95.31%] [G loss: 2.994459]\n",
      "epoch:18 step:14637 [D loss: 0.544737, acc: 66.41%] [G loss: 2.706602]\n",
      "epoch:18 step:14638 [D loss: 0.523259, acc: 80.47%] [G loss: 2.959745]\n",
      "epoch:18 step:14639 [D loss: 0.373618, acc: 88.28%] [G loss: 3.068406]\n",
      "epoch:18 step:14640 [D loss: 0.258994, acc: 96.09%] [G loss: 3.366418]\n",
      "epoch:18 step:14641 [D loss: 0.425676, acc: 72.66%] [G loss: 3.947829]\n",
      "epoch:18 step:14642 [D loss: 0.249366, acc: 96.09%] [G loss: 2.339748]\n",
      "epoch:18 step:14643 [D loss: 1.178933, acc: 47.66%] [G loss: 2.279419]\n",
      "epoch:18 step:14644 [D loss: 0.231311, acc: 97.66%] [G loss: 4.002287]\n",
      "epoch:18 step:14645 [D loss: 0.386267, acc: 82.03%] [G loss: 3.445050]\n",
      "epoch:18 step:14646 [D loss: 0.522106, acc: 67.97%] [G loss: 2.460107]\n",
      "epoch:18 step:14647 [D loss: 0.730937, acc: 53.12%] [G loss: 2.662160]\n",
      "epoch:18 step:14648 [D loss: 0.804208, acc: 52.34%] [G loss: 2.814730]\n",
      "epoch:18 step:14649 [D loss: 0.477671, acc: 82.81%] [G loss: 2.558630]\n",
      "epoch:18 step:14650 [D loss: 0.499212, acc: 66.41%] [G loss: 3.059581]\n",
      "epoch:18 step:14651 [D loss: 0.837191, acc: 45.31%] [G loss: 2.660026]\n",
      "epoch:18 step:14652 [D loss: 0.356972, acc: 90.62%] [G loss: 2.956758]\n",
      "epoch:18 step:14653 [D loss: 0.131814, acc: 100.00%] [G loss: 3.377098]\n",
      "epoch:18 step:14654 [D loss: 0.407250, acc: 88.28%] [G loss: 2.768431]\n",
      "epoch:18 step:14655 [D loss: 0.281767, acc: 95.31%] [G loss: 2.558675]\n",
      "epoch:18 step:14656 [D loss: 0.565623, acc: 61.72%] [G loss: 1.884212]\n",
      "epoch:18 step:14657 [D loss: 0.534388, acc: 60.94%] [G loss: 2.728685]\n",
      "epoch:18 step:14658 [D loss: 0.257964, acc: 99.22%] [G loss: 3.410684]\n",
      "epoch:18 step:14659 [D loss: 0.274890, acc: 100.00%] [G loss: 2.829982]\n",
      "epoch:18 step:14660 [D loss: 0.332274, acc: 92.97%] [G loss: 2.740098]\n",
      "epoch:18 step:14661 [D loss: 0.515656, acc: 74.22%] [G loss: 2.087030]\n",
      "epoch:18 step:14662 [D loss: 0.301256, acc: 96.09%] [G loss: 1.803246]\n",
      "epoch:18 step:14663 [D loss: 0.515198, acc: 78.91%] [G loss: 3.245246]\n",
      "epoch:18 step:14664 [D loss: 0.458229, acc: 85.16%] [G loss: 2.109568]\n",
      "epoch:18 step:14665 [D loss: 0.609192, acc: 65.62%] [G loss: 3.083402]\n",
      "epoch:18 step:14666 [D loss: 0.430698, acc: 73.44%] [G loss: 2.421203]\n",
      "epoch:18 step:14667 [D loss: 0.368595, acc: 93.75%] [G loss: 2.400681]\n",
      "epoch:18 step:14668 [D loss: 0.446533, acc: 85.16%] [G loss: 2.423939]\n",
      "epoch:18 step:14669 [D loss: 0.707385, acc: 55.47%] [G loss: 3.412971]\n",
      "epoch:18 step:14670 [D loss: 0.579678, acc: 67.19%] [G loss: 2.592444]\n",
      "epoch:18 step:14671 [D loss: 0.657483, acc: 66.41%] [G loss: 2.589233]\n",
      "epoch:18 step:14672 [D loss: 0.321319, acc: 91.41%] [G loss: 2.581409]\n",
      "epoch:18 step:14673 [D loss: 0.275397, acc: 96.88%] [G loss: 2.503129]\n",
      "epoch:18 step:14674 [D loss: 0.411406, acc: 86.72%] [G loss: 4.225520]\n",
      "epoch:18 step:14675 [D loss: 0.277351, acc: 95.31%] [G loss: 1.624594]\n",
      "epoch:18 step:14676 [D loss: 0.150904, acc: 99.22%] [G loss: 3.781455]\n",
      "epoch:18 step:14677 [D loss: 0.311579, acc: 92.97%] [G loss: 2.038566]\n",
      "epoch:18 step:14678 [D loss: 1.184526, acc: 50.00%] [G loss: 2.039895]\n",
      "epoch:18 step:14679 [D loss: 0.569897, acc: 71.88%] [G loss: 3.525901]\n",
      "epoch:18 step:14680 [D loss: 0.359339, acc: 84.38%] [G loss: 2.555776]\n",
      "epoch:18 step:14681 [D loss: 0.616052, acc: 64.06%] [G loss: 2.079887]\n",
      "epoch:18 step:14682 [D loss: 0.288258, acc: 97.66%] [G loss: 2.628835]\n",
      "epoch:18 step:14683 [D loss: 0.567153, acc: 64.06%] [G loss: 2.247952]\n",
      "epoch:18 step:14684 [D loss: 1.009481, acc: 27.34%] [G loss: 2.422680]\n",
      "epoch:18 step:14685 [D loss: 0.431275, acc: 87.50%] [G loss: 2.477609]\n",
      "epoch:18 step:14686 [D loss: 0.672119, acc: 60.94%] [G loss: 2.748834]\n",
      "epoch:18 step:14687 [D loss: 0.326401, acc: 88.28%] [G loss: 1.847924]\n",
      "epoch:18 step:14688 [D loss: 0.221301, acc: 98.44%] [G loss: 3.728473]\n",
      "epoch:18 step:14689 [D loss: 0.309197, acc: 92.19%] [G loss: 3.749524]\n",
      "epoch:18 step:14690 [D loss: 0.624600, acc: 69.53%] [G loss: 2.882025]\n",
      "epoch:18 step:14691 [D loss: 0.465812, acc: 83.59%] [G loss: 2.771227]\n",
      "epoch:18 step:14692 [D loss: 1.237309, acc: 32.03%] [G loss: 2.026793]\n",
      "epoch:18 step:14693 [D loss: 0.156286, acc: 99.22%] [G loss: 2.100727]\n",
      "epoch:18 step:14694 [D loss: 0.661556, acc: 57.81%] [G loss: 2.259609]\n",
      "epoch:18 step:14695 [D loss: 0.378585, acc: 84.38%] [G loss: 2.288804]\n",
      "epoch:18 step:14696 [D loss: 0.809843, acc: 40.62%] [G loss: 2.825628]\n",
      "epoch:18 step:14697 [D loss: 0.978943, acc: 22.66%] [G loss: 2.834648]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:18 step:14698 [D loss: 0.257585, acc: 98.44%] [G loss: 4.910227]\n",
      "epoch:18 step:14699 [D loss: 0.674042, acc: 52.34%] [G loss: 1.983087]\n",
      "epoch:18 step:14700 [D loss: 0.790722, acc: 53.91%] [G loss: 1.837933]\n",
      "epoch:18 step:14701 [D loss: 0.541088, acc: 72.66%] [G loss: 2.668369]\n",
      "epoch:18 step:14702 [D loss: 0.276515, acc: 92.97%] [G loss: 2.462147]\n",
      "epoch:18 step:14703 [D loss: 0.779873, acc: 48.44%] [G loss: 1.960044]\n",
      "epoch:18 step:14704 [D loss: 1.086555, acc: 46.09%] [G loss: 2.153537]\n",
      "epoch:18 step:14705 [D loss: 0.775688, acc: 54.69%] [G loss: 2.831328]\n",
      "epoch:18 step:14706 [D loss: 0.684350, acc: 58.59%] [G loss: 2.845288]\n",
      "epoch:18 step:14707 [D loss: 0.780753, acc: 47.66%] [G loss: 2.399043]\n",
      "epoch:18 step:14708 [D loss: 0.328544, acc: 95.31%] [G loss: 2.501712]\n",
      "epoch:18 step:14709 [D loss: 0.251716, acc: 96.88%] [G loss: 3.192502]\n",
      "epoch:18 step:14710 [D loss: 0.303672, acc: 89.84%] [G loss: 4.093969]\n",
      "epoch:18 step:14711 [D loss: 0.193057, acc: 98.44%] [G loss: 3.113998]\n",
      "epoch:18 step:14712 [D loss: 0.420016, acc: 85.94%] [G loss: 2.774089]\n",
      "epoch:18 step:14713 [D loss: 0.185592, acc: 100.00%] [G loss: 2.429031]\n",
      "epoch:18 step:14714 [D loss: 0.863681, acc: 35.16%] [G loss: 2.644583]\n",
      "epoch:18 step:14715 [D loss: 0.244133, acc: 97.66%] [G loss: 4.151446]\n",
      "epoch:18 step:14716 [D loss: 0.486072, acc: 85.16%] [G loss: 3.014218]\n",
      "epoch:18 step:14717 [D loss: 0.145100, acc: 100.00%] [G loss: 3.535356]\n",
      "epoch:18 step:14718 [D loss: 0.752990, acc: 56.25%] [G loss: 3.638903]\n",
      "epoch:18 step:14719 [D loss: 0.224622, acc: 98.44%] [G loss: 3.757480]\n",
      "epoch:18 step:14720 [D loss: 0.313170, acc: 96.09%] [G loss: 1.995924]\n",
      "epoch:18 step:14721 [D loss: 0.477885, acc: 77.34%] [G loss: 3.993485]\n",
      "epoch:18 step:14722 [D loss: 0.237921, acc: 96.88%] [G loss: 3.441422]\n",
      "epoch:18 step:14723 [D loss: 0.797419, acc: 50.78%] [G loss: 2.095375]\n",
      "epoch:18 step:14724 [D loss: 0.882475, acc: 49.22%] [G loss: 2.229591]\n",
      "epoch:18 step:14725 [D loss: 0.343498, acc: 90.62%] [G loss: 3.920795]\n",
      "epoch:18 step:14726 [D loss: 0.432016, acc: 73.44%] [G loss: 2.982961]\n",
      "epoch:18 step:14727 [D loss: 1.539249, acc: 30.47%] [G loss: 1.688600]\n",
      "epoch:18 step:14728 [D loss: 0.788808, acc: 46.88%] [G loss: 2.533096]\n",
      "epoch:18 step:14729 [D loss: 0.169196, acc: 100.00%] [G loss: 2.014395]\n",
      "epoch:18 step:14730 [D loss: 0.649698, acc: 64.06%] [G loss: 2.431622]\n",
      "epoch:18 step:14731 [D loss: 0.359981, acc: 92.97%] [G loss: 5.153736]\n",
      "epoch:18 step:14732 [D loss: 0.320166, acc: 93.75%] [G loss: 2.918976]\n",
      "epoch:18 step:14733 [D loss: 0.381049, acc: 92.19%] [G loss: 3.213665]\n",
      "epoch:18 step:14734 [D loss: 0.973592, acc: 49.22%] [G loss: 3.026544]\n",
      "epoch:18 step:14735 [D loss: 0.173786, acc: 100.00%] [G loss: 3.003909]\n",
      "epoch:18 step:14736 [D loss: 0.892641, acc: 49.22%] [G loss: 2.951793]\n",
      "epoch:18 step:14737 [D loss: 0.543244, acc: 72.66%] [G loss: 3.645369]\n",
      "epoch:18 step:14738 [D loss: 0.186405, acc: 99.22%] [G loss: 3.674806]\n",
      "epoch:18 step:14739 [D loss: 0.207264, acc: 96.88%] [G loss: 5.020967]\n",
      "epoch:18 step:14740 [D loss: 0.319023, acc: 95.31%] [G loss: 4.293118]\n",
      "epoch:18 step:14741 [D loss: 0.356638, acc: 90.62%] [G loss: 3.056980]\n",
      "epoch:18 step:14742 [D loss: 0.275748, acc: 96.88%] [G loss: 2.208784]\n",
      "epoch:18 step:14743 [D loss: 0.588231, acc: 60.16%] [G loss: 3.161624]\n",
      "epoch:18 step:14744 [D loss: 0.538299, acc: 67.19%] [G loss: 2.962316]\n",
      "epoch:18 step:14745 [D loss: 0.322137, acc: 82.03%] [G loss: 4.271987]\n",
      "epoch:18 step:14746 [D loss: 0.170788, acc: 98.44%] [G loss: 4.147704]\n",
      "epoch:18 step:14747 [D loss: 0.921011, acc: 50.78%] [G loss: 3.697504]\n",
      "epoch:18 step:14748 [D loss: 0.340789, acc: 83.59%] [G loss: 2.984500]\n",
      "epoch:18 step:14749 [D loss: 0.296173, acc: 86.72%] [G loss: 4.078607]\n",
      "epoch:18 step:14750 [D loss: 2.367799, acc: 0.00%] [G loss: 2.926636]\n",
      "epoch:18 step:14751 [D loss: 0.490534, acc: 77.34%] [G loss: 2.510599]\n",
      "epoch:18 step:14752 [D loss: 0.833276, acc: 46.88%] [G loss: 2.068881]\n",
      "epoch:18 step:14753 [D loss: 0.385439, acc: 90.62%] [G loss: 4.074078]\n",
      "epoch:18 step:14754 [D loss: 0.641921, acc: 63.28%] [G loss: 2.218600]\n",
      "epoch:18 step:14755 [D loss: 0.696014, acc: 53.91%] [G loss: 2.570220]\n",
      "epoch:18 step:14756 [D loss: 0.369766, acc: 87.50%] [G loss: 2.291290]\n",
      "epoch:18 step:14757 [D loss: 0.704800, acc: 54.69%] [G loss: 1.893295]\n",
      "epoch:18 step:14758 [D loss: 0.476064, acc: 74.22%] [G loss: 2.869459]\n",
      "epoch:18 step:14759 [D loss: 0.560839, acc: 71.88%] [G loss: 2.139376]\n",
      "epoch:18 step:14760 [D loss: 0.392520, acc: 84.38%] [G loss: 2.662429]\n",
      "epoch:18 step:14761 [D loss: 0.818578, acc: 47.66%] [G loss: 2.197893]\n",
      "epoch:18 step:14762 [D loss: 0.197535, acc: 99.22%] [G loss: 2.574690]\n",
      "epoch:18 step:14763 [D loss: 1.065788, acc: 17.19%] [G loss: 2.063711]\n",
      "epoch:18 step:14764 [D loss: 0.850494, acc: 41.41%] [G loss: 2.014752]\n",
      "epoch:18 step:14765 [D loss: 1.007655, acc: 36.72%] [G loss: 2.973822]\n",
      "epoch:18 step:14766 [D loss: 0.171902, acc: 97.66%] [G loss: 3.501560]\n",
      "epoch:18 step:14767 [D loss: 0.651628, acc: 64.06%] [G loss: 2.364475]\n",
      "epoch:18 step:14768 [D loss: 0.427434, acc: 80.47%] [G loss: 2.796898]\n",
      "epoch:18 step:14769 [D loss: 0.428445, acc: 72.66%] [G loss: 4.661305]\n",
      "epoch:18 step:14770 [D loss: 0.869361, acc: 51.56%] [G loss: 3.578601]\n",
      "epoch:18 step:14771 [D loss: 0.243350, acc: 96.88%] [G loss: 3.352323]\n",
      "epoch:18 step:14772 [D loss: 0.257003, acc: 95.31%] [G loss: 2.655120]\n",
      "epoch:18 step:14773 [D loss: 0.594991, acc: 65.62%] [G loss: 2.650897]\n",
      "epoch:18 step:14774 [D loss: 0.652978, acc: 57.81%] [G loss: 2.024538]\n",
      "epoch:18 step:14775 [D loss: 0.222740, acc: 99.22%] [G loss: 3.951048]\n",
      "epoch:18 step:14776 [D loss: 0.662222, acc: 62.50%] [G loss: 3.566881]\n",
      "epoch:18 step:14777 [D loss: 0.949965, acc: 28.12%] [G loss: 1.878221]\n",
      "epoch:18 step:14778 [D loss: 0.650236, acc: 60.16%] [G loss: 2.074718]\n",
      "epoch:18 step:14779 [D loss: 0.678055, acc: 59.38%] [G loss: 2.710521]\n",
      "epoch:18 step:14780 [D loss: 0.432661, acc: 75.00%] [G loss: 3.530405]\n",
      "epoch:18 step:14781 [D loss: 0.185711, acc: 100.00%] [G loss: 3.757777]\n",
      "epoch:18 step:14782 [D loss: 1.052266, acc: 44.53%] [G loss: 2.730000]\n",
      "epoch:18 step:14783 [D loss: 0.377729, acc: 89.06%] [G loss: 2.613575]\n",
      "epoch:18 step:14784 [D loss: 0.200987, acc: 98.44%] [G loss: 3.806056]\n",
      "epoch:18 step:14785 [D loss: 0.623689, acc: 62.50%] [G loss: 3.703086]\n",
      "epoch:18 step:14786 [D loss: 0.515908, acc: 79.69%] [G loss: 2.266148]\n",
      "epoch:18 step:14787 [D loss: 0.681543, acc: 59.38%] [G loss: 2.178694]\n",
      "epoch:18 step:14788 [D loss: 0.379690, acc: 89.06%] [G loss: 1.890579]\n",
      "epoch:18 step:14789 [D loss: 0.625678, acc: 63.28%] [G loss: 3.037444]\n",
      "epoch:18 step:14790 [D loss: 0.192030, acc: 98.44%] [G loss: 3.246696]\n",
      "epoch:18 step:14791 [D loss: 0.231745, acc: 98.44%] [G loss: 2.742975]\n",
      "epoch:18 step:14792 [D loss: 0.712544, acc: 54.69%] [G loss: 2.793000]\n",
      "epoch:18 step:14793 [D loss: 0.278604, acc: 96.88%] [G loss: 2.533374]\n",
      "epoch:18 step:14794 [D loss: 0.304794, acc: 87.50%] [G loss: 3.315915]\n",
      "epoch:18 step:14795 [D loss: 0.485604, acc: 85.94%] [G loss: 2.248614]\n",
      "epoch:18 step:14796 [D loss: 0.281339, acc: 95.31%] [G loss: 2.959481]\n",
      "epoch:18 step:14797 [D loss: 0.784165, acc: 52.34%] [G loss: 3.463472]\n",
      "epoch:18 step:14798 [D loss: 0.163253, acc: 99.22%] [G loss: 3.364958]\n",
      "epoch:18 step:14799 [D loss: 0.234948, acc: 96.88%] [G loss: 3.437807]\n",
      "epoch:18 step:14800 [D loss: 0.270894, acc: 92.97%] [G loss: 3.089846]\n",
      "##############\n",
      "[0.87067818 0.8650542  0.82911149 0.82458619 0.80039629 0.81141823\n",
      " 0.88433167 0.83021188 0.83086575 0.853111  ]\n",
      "##########\n",
      "epoch:18 step:14801 [D loss: 0.498358, acc: 73.44%] [G loss: 2.605884]\n",
      "epoch:18 step:14802 [D loss: 0.900066, acc: 28.91%] [G loss: 2.368691]\n",
      "epoch:18 step:14803 [D loss: 0.288316, acc: 98.44%] [G loss: 1.921083]\n",
      "epoch:18 step:14804 [D loss: 0.995615, acc: 29.69%] [G loss: 2.410513]\n",
      "epoch:18 step:14805 [D loss: 0.589983, acc: 62.50%] [G loss: 2.705520]\n",
      "epoch:18 step:14806 [D loss: 0.315042, acc: 92.97%] [G loss: 2.550726]\n",
      "epoch:18 step:14807 [D loss: 0.502284, acc: 84.38%] [G loss: 2.983542]\n",
      "epoch:18 step:14808 [D loss: 0.680607, acc: 59.38%] [G loss: 3.676157]\n",
      "epoch:18 step:14809 [D loss: 0.454568, acc: 87.50%] [G loss: 3.930643]\n",
      "epoch:18 step:14810 [D loss: 0.133329, acc: 100.00%] [G loss: 2.356635]\n",
      "epoch:18 step:14811 [D loss: 0.498406, acc: 71.88%] [G loss: 3.854491]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:18 step:14812 [D loss: 0.281021, acc: 97.66%] [G loss: 3.204947]\n",
      "epoch:18 step:14813 [D loss: 0.941731, acc: 21.88%] [G loss: 2.639332]\n",
      "epoch:18 step:14814 [D loss: 0.136912, acc: 99.22%] [G loss: 4.043454]\n",
      "epoch:18 step:14815 [D loss: 0.995213, acc: 28.91%] [G loss: 2.144779]\n",
      "epoch:18 step:14816 [D loss: 0.510939, acc: 68.75%] [G loss: 3.272637]\n",
      "epoch:18 step:14817 [D loss: 1.431895, acc: 16.41%] [G loss: 2.485585]\n",
      "epoch:18 step:14818 [D loss: 0.230577, acc: 97.66%] [G loss: 3.785669]\n",
      "epoch:18 step:14819 [D loss: 0.588853, acc: 69.53%] [G loss: 2.374026]\n",
      "epoch:18 step:14820 [D loss: 0.366639, acc: 89.06%] [G loss: 3.946267]\n",
      "epoch:18 step:14821 [D loss: 0.281509, acc: 94.53%] [G loss: 3.371763]\n",
      "epoch:18 step:14822 [D loss: 0.151062, acc: 99.22%] [G loss: 3.318539]\n",
      "epoch:18 step:14823 [D loss: 0.493919, acc: 82.81%] [G loss: 2.250417]\n",
      "epoch:18 step:14824 [D loss: 0.839559, acc: 42.19%] [G loss: 2.202355]\n",
      "epoch:18 step:14825 [D loss: 0.233429, acc: 99.22%] [G loss: 3.879071]\n",
      "epoch:18 step:14826 [D loss: 0.222033, acc: 97.66%] [G loss: 2.260714]\n",
      "epoch:18 step:14827 [D loss: 1.259084, acc: 16.41%] [G loss: 2.381958]\n",
      "epoch:18 step:14828 [D loss: 0.833160, acc: 39.06%] [G loss: 1.680389]\n",
      "epoch:18 step:14829 [D loss: 0.466218, acc: 82.03%] [G loss: 1.890646]\n",
      "epoch:18 step:14830 [D loss: 0.237560, acc: 98.44%] [G loss: 2.688286]\n",
      "epoch:18 step:14831 [D loss: 0.186309, acc: 100.00%] [G loss: 4.529824]\n",
      "epoch:18 step:14832 [D loss: 0.725084, acc: 50.00%] [G loss: 2.814470]\n",
      "epoch:18 step:14833 [D loss: 0.274264, acc: 94.53%] [G loss: 2.405467]\n",
      "epoch:18 step:14834 [D loss: 0.608372, acc: 70.31%] [G loss: 2.885413]\n",
      "epoch:18 step:14835 [D loss: 0.576658, acc: 67.19%] [G loss: 2.898135]\n",
      "epoch:18 step:14836 [D loss: 0.579674, acc: 68.75%] [G loss: 2.823254]\n",
      "epoch:18 step:14837 [D loss: 0.415900, acc: 88.28%] [G loss: 2.856436]\n",
      "epoch:18 step:14838 [D loss: 0.777953, acc: 50.78%] [G loss: 2.841739]\n",
      "epoch:18 step:14839 [D loss: 0.353961, acc: 81.25%] [G loss: 2.497755]\n",
      "epoch:19 step:14840 [D loss: 0.163150, acc: 99.22%] [G loss: 5.309217]\n",
      "epoch:19 step:14841 [D loss: 0.208348, acc: 99.22%] [G loss: 3.976845]\n",
      "epoch:19 step:14842 [D loss: 0.683982, acc: 55.47%] [G loss: 1.889203]\n",
      "epoch:19 step:14843 [D loss: 0.596872, acc: 69.53%] [G loss: 3.284709]\n",
      "epoch:19 step:14844 [D loss: 0.318050, acc: 95.31%] [G loss: 3.303877]\n",
      "epoch:19 step:14845 [D loss: 0.665054, acc: 57.81%] [G loss: 2.330561]\n",
      "epoch:19 step:14846 [D loss: 0.191200, acc: 99.22%] [G loss: 2.736765]\n",
      "epoch:19 step:14847 [D loss: 0.416908, acc: 85.94%] [G loss: 2.968613]\n",
      "epoch:19 step:14848 [D loss: 0.203003, acc: 97.66%] [G loss: 3.545439]\n",
      "epoch:19 step:14849 [D loss: 0.451074, acc: 67.19%] [G loss: 3.218027]\n",
      "epoch:19 step:14850 [D loss: 0.441613, acc: 84.38%] [G loss: 2.695971]\n",
      "epoch:19 step:14851 [D loss: 0.451449, acc: 76.56%] [G loss: 2.202055]\n",
      "epoch:19 step:14852 [D loss: 0.473376, acc: 80.47%] [G loss: 2.888086]\n",
      "epoch:19 step:14853 [D loss: 0.853201, acc: 35.94%] [G loss: 2.638027]\n",
      "epoch:19 step:14854 [D loss: 0.777549, acc: 42.19%] [G loss: 1.721082]\n",
      "epoch:19 step:14855 [D loss: 0.662251, acc: 61.72%] [G loss: 1.989404]\n",
      "epoch:19 step:14856 [D loss: 0.170371, acc: 99.22%] [G loss: 2.816329]\n",
      "epoch:19 step:14857 [D loss: 0.475575, acc: 69.53%] [G loss: 4.085492]\n",
      "epoch:19 step:14858 [D loss: 0.604023, acc: 62.50%] [G loss: 2.912826]\n",
      "epoch:19 step:14859 [D loss: 0.955498, acc: 50.78%] [G loss: 2.524535]\n",
      "epoch:19 step:14860 [D loss: 0.193702, acc: 99.22%] [G loss: 2.944268]\n",
      "epoch:19 step:14861 [D loss: 0.310776, acc: 93.75%] [G loss: 3.478959]\n",
      "epoch:19 step:14862 [D loss: 0.556421, acc: 72.66%] [G loss: 2.447793]\n",
      "epoch:19 step:14863 [D loss: 0.870428, acc: 51.56%] [G loss: 2.314654]\n",
      "epoch:19 step:14864 [D loss: 1.156241, acc: 39.06%] [G loss: 3.288146]\n",
      "epoch:19 step:14865 [D loss: 0.236159, acc: 93.75%] [G loss: 3.399708]\n",
      "epoch:19 step:14866 [D loss: 0.319750, acc: 92.97%] [G loss: 2.655621]\n",
      "epoch:19 step:14867 [D loss: 0.449499, acc: 85.94%] [G loss: 3.520904]\n",
      "epoch:19 step:14868 [D loss: 0.317271, acc: 92.97%] [G loss: 3.442237]\n",
      "epoch:19 step:14869 [D loss: 0.556788, acc: 73.44%] [G loss: 1.895600]\n",
      "epoch:19 step:14870 [D loss: 0.474905, acc: 84.38%] [G loss: 2.416722]\n",
      "epoch:19 step:14871 [D loss: 0.423550, acc: 86.72%] [G loss: 3.578860]\n",
      "epoch:19 step:14872 [D loss: 0.500788, acc: 81.25%] [G loss: 2.717725]\n",
      "epoch:19 step:14873 [D loss: 0.553454, acc: 75.78%] [G loss: 2.821975]\n",
      "epoch:19 step:14874 [D loss: 0.290788, acc: 96.88%] [G loss: 2.456015]\n",
      "epoch:19 step:14875 [D loss: 0.141159, acc: 99.22%] [G loss: 3.212059]\n",
      "epoch:19 step:14876 [D loss: 0.739837, acc: 53.91%] [G loss: 2.339891]\n",
      "epoch:19 step:14877 [D loss: 0.268627, acc: 94.53%] [G loss: 2.836825]\n",
      "epoch:19 step:14878 [D loss: 0.584363, acc: 66.41%] [G loss: 2.897239]\n",
      "epoch:19 step:14879 [D loss: 0.759140, acc: 50.78%] [G loss: 2.909935]\n",
      "epoch:19 step:14880 [D loss: 0.351761, acc: 85.94%] [G loss: 3.994964]\n",
      "epoch:19 step:14881 [D loss: 0.711429, acc: 58.59%] [G loss: 3.448013]\n",
      "epoch:19 step:14882 [D loss: 0.556583, acc: 75.00%] [G loss: 2.250407]\n",
      "epoch:19 step:14883 [D loss: 0.618992, acc: 60.94%] [G loss: 1.655766]\n",
      "epoch:19 step:14884 [D loss: 0.395710, acc: 89.84%] [G loss: 2.630394]\n",
      "epoch:19 step:14885 [D loss: 0.239641, acc: 92.19%] [G loss: 2.140494]\n",
      "epoch:19 step:14886 [D loss: 0.697119, acc: 56.25%] [G loss: 1.881524]\n",
      "epoch:19 step:14887 [D loss: 0.111001, acc: 99.22%] [G loss: 2.724745]\n",
      "epoch:19 step:14888 [D loss: 0.662417, acc: 53.91%] [G loss: 3.143224]\n",
      "epoch:19 step:14889 [D loss: 0.567052, acc: 61.72%] [G loss: 2.344404]\n",
      "epoch:19 step:14890 [D loss: 0.631374, acc: 59.38%] [G loss: 2.447445]\n",
      "epoch:19 step:14891 [D loss: 0.407403, acc: 82.81%] [G loss: 2.662997]\n",
      "epoch:19 step:14892 [D loss: 0.544316, acc: 64.84%] [G loss: 2.509071]\n",
      "epoch:19 step:14893 [D loss: 0.524501, acc: 63.28%] [G loss: 3.629555]\n",
      "epoch:19 step:14894 [D loss: 0.299527, acc: 92.97%] [G loss: 2.940845]\n",
      "epoch:19 step:14895 [D loss: 0.842939, acc: 46.09%] [G loss: 1.425019]\n",
      "epoch:19 step:14896 [D loss: 0.284903, acc: 94.53%] [G loss: 2.706348]\n",
      "epoch:19 step:14897 [D loss: 0.361252, acc: 88.28%] [G loss: 1.775809]\n",
      "epoch:19 step:14898 [D loss: 0.199894, acc: 100.00%] [G loss: 2.738406]\n",
      "epoch:19 step:14899 [D loss: 0.418078, acc: 89.84%] [G loss: 2.478638]\n",
      "epoch:19 step:14900 [D loss: 1.346784, acc: 7.03%] [G loss: 2.796434]\n",
      "epoch:19 step:14901 [D loss: 0.844387, acc: 46.88%] [G loss: 2.613539]\n",
      "epoch:19 step:14902 [D loss: 0.659134, acc: 53.12%] [G loss: 3.406601]\n",
      "epoch:19 step:14903 [D loss: 0.485367, acc: 71.09%] [G loss: 3.460591]\n",
      "epoch:19 step:14904 [D loss: 0.511862, acc: 68.75%] [G loss: 6.017476]\n",
      "epoch:19 step:14905 [D loss: 0.737428, acc: 53.12%] [G loss: 3.065819]\n",
      "epoch:19 step:14906 [D loss: 0.249262, acc: 92.97%] [G loss: 2.377652]\n",
      "epoch:19 step:14907 [D loss: 0.438745, acc: 87.50%] [G loss: 2.301512]\n",
      "epoch:19 step:14908 [D loss: 0.328859, acc: 95.31%] [G loss: 2.912982]\n",
      "epoch:19 step:14909 [D loss: 0.737780, acc: 53.91%] [G loss: 2.615609]\n",
      "epoch:19 step:14910 [D loss: 0.477001, acc: 72.66%] [G loss: 2.798783]\n",
      "epoch:19 step:14911 [D loss: 0.563687, acc: 68.75%] [G loss: 2.790089]\n",
      "epoch:19 step:14912 [D loss: 0.300716, acc: 92.19%] [G loss: 3.312486]\n",
      "epoch:19 step:14913 [D loss: 0.539716, acc: 78.12%] [G loss: 2.695971]\n",
      "epoch:19 step:14914 [D loss: 0.318974, acc: 96.09%] [G loss: 2.357734]\n",
      "epoch:19 step:14915 [D loss: 0.624263, acc: 61.72%] [G loss: 4.313531]\n",
      "epoch:19 step:14916 [D loss: 0.443150, acc: 77.34%] [G loss: 2.977540]\n",
      "epoch:19 step:14917 [D loss: 0.374475, acc: 88.28%] [G loss: 2.804888]\n",
      "epoch:19 step:14918 [D loss: 0.718570, acc: 53.91%] [G loss: 2.386709]\n",
      "epoch:19 step:14919 [D loss: 0.444580, acc: 69.53%] [G loss: 3.256692]\n",
      "epoch:19 step:14920 [D loss: 0.152839, acc: 99.22%] [G loss: 2.657618]\n",
      "epoch:19 step:14921 [D loss: 0.294866, acc: 94.53%] [G loss: 2.990234]\n",
      "epoch:19 step:14922 [D loss: 0.480220, acc: 72.66%] [G loss: 2.869956]\n",
      "epoch:19 step:14923 [D loss: 0.430015, acc: 69.53%] [G loss: 2.354397]\n",
      "epoch:19 step:14924 [D loss: 0.344638, acc: 85.16%] [G loss: 3.717482]\n",
      "epoch:19 step:14925 [D loss: 0.473181, acc: 74.22%] [G loss: 3.173783]\n",
      "epoch:19 step:14926 [D loss: 0.305745, acc: 91.41%] [G loss: 3.182648]\n",
      "epoch:19 step:14927 [D loss: 0.519538, acc: 80.47%] [G loss: 2.655347]\n",
      "epoch:19 step:14928 [D loss: 0.241356, acc: 92.19%] [G loss: 3.825145]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:19 step:14929 [D loss: 0.264731, acc: 93.75%] [G loss: 3.343529]\n",
      "epoch:19 step:14930 [D loss: 0.280884, acc: 96.09%] [G loss: 3.635906]\n",
      "epoch:19 step:14931 [D loss: 0.530632, acc: 76.56%] [G loss: 2.851836]\n",
      "epoch:19 step:14932 [D loss: 0.567027, acc: 57.03%] [G loss: 2.840720]\n",
      "epoch:19 step:14933 [D loss: 0.169967, acc: 99.22%] [G loss: 3.215209]\n",
      "epoch:19 step:14934 [D loss: 0.360439, acc: 90.62%] [G loss: 2.828997]\n",
      "epoch:19 step:14935 [D loss: 0.606245, acc: 60.16%] [G loss: 2.011282]\n",
      "epoch:19 step:14936 [D loss: 0.345572, acc: 95.31%] [G loss: 3.007724]\n",
      "epoch:19 step:14937 [D loss: 0.295849, acc: 89.84%] [G loss: 2.505480]\n",
      "epoch:19 step:14938 [D loss: 0.846605, acc: 33.59%] [G loss: 3.554446]\n",
      "epoch:19 step:14939 [D loss: 0.154426, acc: 100.00%] [G loss: 3.537322]\n",
      "epoch:19 step:14940 [D loss: 0.447508, acc: 67.19%] [G loss: 2.026139]\n",
      "epoch:19 step:14941 [D loss: 0.143949, acc: 99.22%] [G loss: 2.647370]\n",
      "epoch:19 step:14942 [D loss: 1.341480, acc: 41.41%] [G loss: 3.013867]\n",
      "epoch:19 step:14943 [D loss: 0.648860, acc: 60.94%] [G loss: 2.745962]\n",
      "epoch:19 step:14944 [D loss: 0.299064, acc: 89.06%] [G loss: 4.538211]\n",
      "epoch:19 step:14945 [D loss: 0.664761, acc: 66.41%] [G loss: 2.227861]\n",
      "epoch:19 step:14946 [D loss: 1.157935, acc: 18.75%] [G loss: 2.680637]\n",
      "epoch:19 step:14947 [D loss: 0.956254, acc: 36.72%] [G loss: 3.825815]\n",
      "epoch:19 step:14948 [D loss: 0.993345, acc: 25.00%] [G loss: 2.054538]\n",
      "epoch:19 step:14949 [D loss: 0.590454, acc: 70.31%] [G loss: 2.975814]\n",
      "epoch:19 step:14950 [D loss: 0.541214, acc: 80.47%] [G loss: 3.102248]\n",
      "epoch:19 step:14951 [D loss: 0.221864, acc: 96.88%] [G loss: 3.245903]\n",
      "epoch:19 step:14952 [D loss: 0.720379, acc: 52.34%] [G loss: 3.510039]\n",
      "epoch:19 step:14953 [D loss: 0.931704, acc: 40.62%] [G loss: 2.279688]\n",
      "epoch:19 step:14954 [D loss: 0.543571, acc: 60.16%] [G loss: 2.595046]\n",
      "epoch:19 step:14955 [D loss: 0.504774, acc: 67.97%] [G loss: 3.220217]\n",
      "epoch:19 step:14956 [D loss: 0.790009, acc: 44.53%] [G loss: 2.500047]\n",
      "epoch:19 step:14957 [D loss: 0.511880, acc: 86.72%] [G loss: 3.936229]\n",
      "epoch:19 step:14958 [D loss: 0.504953, acc: 82.03%] [G loss: 2.560940]\n",
      "epoch:19 step:14959 [D loss: 0.440194, acc: 76.56%] [G loss: 4.935869]\n",
      "epoch:19 step:14960 [D loss: 1.068974, acc: 21.88%] [G loss: 2.723431]\n",
      "epoch:19 step:14961 [D loss: 0.589599, acc: 60.16%] [G loss: 2.975890]\n",
      "epoch:19 step:14962 [D loss: 0.222373, acc: 96.09%] [G loss: 3.483732]\n",
      "epoch:19 step:14963 [D loss: 0.245488, acc: 99.22%] [G loss: 3.962773]\n",
      "epoch:19 step:14964 [D loss: 0.620237, acc: 60.94%] [G loss: 2.941753]\n",
      "epoch:19 step:14965 [D loss: 0.680932, acc: 58.59%] [G loss: 2.691647]\n",
      "epoch:19 step:14966 [D loss: 0.551258, acc: 68.75%] [G loss: 2.291807]\n",
      "epoch:19 step:14967 [D loss: 0.509056, acc: 85.16%] [G loss: 1.970417]\n",
      "epoch:19 step:14968 [D loss: 0.858582, acc: 44.53%] [G loss: 2.678559]\n",
      "epoch:19 step:14969 [D loss: 1.385543, acc: 10.16%] [G loss: 2.100205]\n",
      "epoch:19 step:14970 [D loss: 0.650068, acc: 58.59%] [G loss: 2.796296]\n",
      "epoch:19 step:14971 [D loss: 0.335295, acc: 95.31%] [G loss: 1.884354]\n",
      "epoch:19 step:14972 [D loss: 0.594281, acc: 67.97%] [G loss: 2.114764]\n",
      "epoch:19 step:14973 [D loss: 0.356684, acc: 85.94%] [G loss: 2.865306]\n",
      "epoch:19 step:14974 [D loss: 0.673561, acc: 60.16%] [G loss: 3.094183]\n",
      "epoch:19 step:14975 [D loss: 0.429984, acc: 88.28%] [G loss: 1.326047]\n",
      "epoch:19 step:14976 [D loss: 0.247637, acc: 94.53%] [G loss: 3.767889]\n",
      "epoch:19 step:14977 [D loss: 0.591240, acc: 69.53%] [G loss: 4.426354]\n",
      "epoch:19 step:14978 [D loss: 0.606925, acc: 59.38%] [G loss: 2.282087]\n",
      "epoch:19 step:14979 [D loss: 0.768821, acc: 53.91%] [G loss: 1.907695]\n",
      "epoch:19 step:14980 [D loss: 0.949599, acc: 35.94%] [G loss: 2.509030]\n",
      "epoch:19 step:14981 [D loss: 0.649878, acc: 60.94%] [G loss: 2.749368]\n",
      "epoch:19 step:14982 [D loss: 0.444958, acc: 88.28%] [G loss: 3.677867]\n",
      "epoch:19 step:14983 [D loss: 0.290825, acc: 90.62%] [G loss: 2.918596]\n",
      "epoch:19 step:14984 [D loss: 0.641006, acc: 63.28%] [G loss: 2.226373]\n",
      "epoch:19 step:14985 [D loss: 0.651396, acc: 53.91%] [G loss: 2.143760]\n",
      "epoch:19 step:14986 [D loss: 0.725538, acc: 46.88%] [G loss: 2.523630]\n",
      "epoch:19 step:14987 [D loss: 0.437777, acc: 83.59%] [G loss: 3.381292]\n",
      "epoch:19 step:14988 [D loss: 0.810281, acc: 49.22%] [G loss: 3.227131]\n",
      "epoch:19 step:14989 [D loss: 0.617970, acc: 60.94%] [G loss: 3.156783]\n",
      "epoch:19 step:14990 [D loss: 0.747426, acc: 51.56%] [G loss: 1.936190]\n",
      "epoch:19 step:14991 [D loss: 0.187854, acc: 99.22%] [G loss: 2.859840]\n",
      "epoch:19 step:14992 [D loss: 0.360814, acc: 92.19%] [G loss: 3.179208]\n",
      "epoch:19 step:14993 [D loss: 0.225137, acc: 99.22%] [G loss: 3.303195]\n",
      "epoch:19 step:14994 [D loss: 0.673004, acc: 60.16%] [G loss: 2.646024]\n",
      "epoch:19 step:14995 [D loss: 0.173230, acc: 99.22%] [G loss: 1.891352]\n",
      "epoch:19 step:14996 [D loss: 0.505769, acc: 62.50%] [G loss: 3.104433]\n",
      "epoch:19 step:14997 [D loss: 0.604638, acc: 66.41%] [G loss: 2.467944]\n",
      "epoch:19 step:14998 [D loss: 0.428166, acc: 86.72%] [G loss: 3.029823]\n",
      "epoch:19 step:14999 [D loss: 0.492574, acc: 67.97%] [G loss: 2.818339]\n",
      "epoch:19 step:15000 [D loss: 0.678764, acc: 54.69%] [G loss: 3.360107]\n",
      "##############\n",
      "[0.84552261 0.87808393 0.82260163 0.82529214 0.77656993 0.82006573\n",
      " 0.89840891 0.82291277 0.80337069 0.81556381]\n",
      "##########\n",
      "epoch:19 step:15001 [D loss: 0.622545, acc: 57.03%] [G loss: 2.217208]\n",
      "epoch:19 step:15002 [D loss: 0.757533, acc: 50.78%] [G loss: 2.511686]\n",
      "epoch:19 step:15003 [D loss: 0.080807, acc: 100.00%] [G loss: 5.590791]\n",
      "epoch:19 step:15004 [D loss: 0.559283, acc: 75.78%] [G loss: 2.477024]\n",
      "epoch:19 step:15005 [D loss: 0.381810, acc: 75.78%] [G loss: 5.800882]\n",
      "epoch:19 step:15006 [D loss: 0.193749, acc: 98.44%] [G loss: 4.286611]\n",
      "epoch:19 step:15007 [D loss: 0.529087, acc: 61.72%] [G loss: 1.959442]\n",
      "epoch:19 step:15008 [D loss: 0.698847, acc: 55.47%] [G loss: 2.810223]\n",
      "epoch:19 step:15009 [D loss: 0.308449, acc: 92.19%] [G loss: 2.766621]\n",
      "epoch:19 step:15010 [D loss: 0.255587, acc: 91.41%] [G loss: 2.908593]\n",
      "epoch:19 step:15011 [D loss: 1.068870, acc: 33.59%] [G loss: 2.325824]\n",
      "epoch:19 step:15012 [D loss: 0.398109, acc: 87.50%] [G loss: 2.213832]\n",
      "epoch:19 step:15013 [D loss: 0.390947, acc: 83.59%] [G loss: 3.060406]\n",
      "epoch:19 step:15014 [D loss: 0.605673, acc: 68.75%] [G loss: 2.655981]\n",
      "epoch:19 step:15015 [D loss: 0.903775, acc: 50.78%] [G loss: 3.252803]\n",
      "epoch:19 step:15016 [D loss: 0.433240, acc: 78.12%] [G loss: 2.284386]\n",
      "epoch:19 step:15017 [D loss: 0.999238, acc: 46.88%] [G loss: 2.327340]\n",
      "epoch:19 step:15018 [D loss: 0.657563, acc: 66.41%] [G loss: 2.312206]\n",
      "epoch:19 step:15019 [D loss: 1.163306, acc: 50.78%] [G loss: 2.813266]\n",
      "epoch:19 step:15020 [D loss: 0.831167, acc: 46.09%] [G loss: 2.557978]\n",
      "epoch:19 step:15021 [D loss: 0.715506, acc: 53.12%] [G loss: 2.747649]\n",
      "epoch:19 step:15022 [D loss: 0.363608, acc: 94.53%] [G loss: 2.945435]\n",
      "epoch:19 step:15023 [D loss: 0.784579, acc: 39.84%] [G loss: 2.878184]\n",
      "epoch:19 step:15024 [D loss: 0.370026, acc: 78.12%] [G loss: 2.204651]\n",
      "epoch:19 step:15025 [D loss: 0.382694, acc: 82.03%] [G loss: 2.739074]\n",
      "epoch:19 step:15026 [D loss: 1.008794, acc: 42.97%] [G loss: 3.163571]\n",
      "epoch:19 step:15027 [D loss: 0.772460, acc: 40.62%] [G loss: 2.172757]\n",
      "epoch:19 step:15028 [D loss: 0.216787, acc: 100.00%] [G loss: 4.740008]\n",
      "epoch:19 step:15029 [D loss: 0.875432, acc: 50.00%] [G loss: 2.311594]\n",
      "epoch:19 step:15030 [D loss: 0.885805, acc: 37.50%] [G loss: 2.790789]\n",
      "epoch:19 step:15031 [D loss: 0.537967, acc: 75.00%] [G loss: 2.796992]\n",
      "epoch:19 step:15032 [D loss: 0.139118, acc: 100.00%] [G loss: 3.155452]\n",
      "epoch:19 step:15033 [D loss: 0.515907, acc: 79.69%] [G loss: 2.187952]\n",
      "epoch:19 step:15034 [D loss: 0.411723, acc: 89.06%] [G loss: 3.332165]\n",
      "epoch:19 step:15035 [D loss: 0.687028, acc: 66.41%] [G loss: 2.857845]\n",
      "epoch:19 step:15036 [D loss: 0.297977, acc: 89.84%] [G loss: 4.647792]\n",
      "epoch:19 step:15037 [D loss: 0.476725, acc: 75.78%] [G loss: 3.136634]\n",
      "epoch:19 step:15038 [D loss: 0.628006, acc: 60.16%] [G loss: 3.040028]\n",
      "epoch:19 step:15039 [D loss: 0.253949, acc: 96.09%] [G loss: 3.454358]\n",
      "epoch:19 step:15040 [D loss: 0.158432, acc: 100.00%] [G loss: 3.049098]\n",
      "epoch:19 step:15041 [D loss: 0.667704, acc: 55.47%] [G loss: 2.594765]\n",
      "epoch:19 step:15042 [D loss: 0.746103, acc: 53.91%] [G loss: 3.045278]\n",
      "epoch:19 step:15043 [D loss: 0.436424, acc: 81.25%] [G loss: 1.964703]\n",
      "epoch:19 step:15044 [D loss: 1.149636, acc: 15.62%] [G loss: 1.780535]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:19 step:15045 [D loss: 0.340232, acc: 82.81%] [G loss: 3.419180]\n",
      "epoch:19 step:15046 [D loss: 0.917486, acc: 28.91%] [G loss: 4.063420]\n",
      "epoch:19 step:15047 [D loss: 0.631645, acc: 57.81%] [G loss: 2.561275]\n",
      "epoch:19 step:15048 [D loss: 0.491578, acc: 66.41%] [G loss: 4.191669]\n",
      "epoch:19 step:15049 [D loss: 0.746959, acc: 49.22%] [G loss: 1.712350]\n",
      "epoch:19 step:15050 [D loss: 0.420071, acc: 75.78%] [G loss: 1.892816]\n",
      "epoch:19 step:15051 [D loss: 0.269883, acc: 96.88%] [G loss: 2.642422]\n",
      "epoch:19 step:15052 [D loss: 0.708825, acc: 50.78%] [G loss: 2.219796]\n",
      "epoch:19 step:15053 [D loss: 0.243943, acc: 96.09%] [G loss: 2.403327]\n",
      "epoch:19 step:15054 [D loss: 0.435196, acc: 87.50%] [G loss: 2.680022]\n",
      "epoch:19 step:15055 [D loss: 0.910581, acc: 35.16%] [G loss: 2.606093]\n",
      "epoch:19 step:15056 [D loss: 0.639776, acc: 64.06%] [G loss: 2.815751]\n",
      "epoch:19 step:15057 [D loss: 0.269744, acc: 97.66%] [G loss: 2.603605]\n",
      "epoch:19 step:15058 [D loss: 0.350416, acc: 91.41%] [G loss: 3.990767]\n",
      "epoch:19 step:15059 [D loss: 0.666586, acc: 61.72%] [G loss: 2.728207]\n",
      "epoch:19 step:15060 [D loss: 0.879673, acc: 51.56%] [G loss: 3.797690]\n",
      "epoch:19 step:15061 [D loss: 0.397866, acc: 85.94%] [G loss: 2.157199]\n",
      "epoch:19 step:15062 [D loss: 1.000085, acc: 33.59%] [G loss: 1.467689]\n",
      "epoch:19 step:15063 [D loss: 0.747679, acc: 51.56%] [G loss: 1.446409]\n",
      "epoch:19 step:15064 [D loss: 0.116909, acc: 100.00%] [G loss: 2.164543]\n",
      "epoch:19 step:15065 [D loss: 0.611320, acc: 64.06%] [G loss: 2.724731]\n",
      "epoch:19 step:15066 [D loss: 0.298321, acc: 94.53%] [G loss: 2.237852]\n",
      "epoch:19 step:15067 [D loss: 0.915334, acc: 25.78%] [G loss: 2.408938]\n",
      "epoch:19 step:15068 [D loss: 0.372503, acc: 92.97%] [G loss: 3.029466]\n",
      "epoch:19 step:15069 [D loss: 0.650176, acc: 56.25%] [G loss: 2.251052]\n",
      "epoch:19 step:15070 [D loss: 0.827374, acc: 41.41%] [G loss: 2.710757]\n",
      "epoch:19 step:15071 [D loss: 0.539595, acc: 76.56%] [G loss: 2.843403]\n",
      "epoch:19 step:15072 [D loss: 0.413025, acc: 93.75%] [G loss: 2.515203]\n",
      "epoch:19 step:15073 [D loss: 1.419860, acc: 5.47%] [G loss: 2.795602]\n",
      "epoch:19 step:15074 [D loss: 0.575542, acc: 74.22%] [G loss: 3.456917]\n",
      "epoch:19 step:15075 [D loss: 0.732885, acc: 54.69%] [G loss: 2.565121]\n",
      "epoch:19 step:15076 [D loss: 0.306100, acc: 92.97%] [G loss: 3.808493]\n",
      "epoch:19 step:15077 [D loss: 0.777029, acc: 46.09%] [G loss: 0.942173]\n",
      "epoch:19 step:15078 [D loss: 0.869501, acc: 46.88%] [G loss: 2.493119]\n",
      "epoch:19 step:15079 [D loss: 0.660704, acc: 61.72%] [G loss: 2.491516]\n",
      "epoch:19 step:15080 [D loss: 0.497259, acc: 81.25%] [G loss: 3.146136]\n",
      "epoch:19 step:15081 [D loss: 0.479255, acc: 85.94%] [G loss: 4.307146]\n",
      "epoch:19 step:15082 [D loss: 0.187112, acc: 98.44%] [G loss: 3.395571]\n",
      "epoch:19 step:15083 [D loss: 0.539599, acc: 76.56%] [G loss: 4.005935]\n",
      "epoch:19 step:15084 [D loss: 1.053689, acc: 25.00%] [G loss: 2.410451]\n",
      "epoch:19 step:15085 [D loss: 0.863346, acc: 33.59%] [G loss: 2.490963]\n",
      "epoch:19 step:15086 [D loss: 0.863109, acc: 28.91%] [G loss: 1.914662]\n",
      "epoch:19 step:15087 [D loss: 0.575499, acc: 66.41%] [G loss: 3.088319]\n",
      "epoch:19 step:15088 [D loss: 0.274388, acc: 96.09%] [G loss: 3.767952]\n",
      "epoch:19 step:15089 [D loss: 0.628207, acc: 59.38%] [G loss: 3.005073]\n",
      "epoch:19 step:15090 [D loss: 0.511692, acc: 71.88%] [G loss: 3.126908]\n",
      "epoch:19 step:15091 [D loss: 0.699696, acc: 54.69%] [G loss: 3.395047]\n",
      "epoch:19 step:15092 [D loss: 0.862656, acc: 50.00%] [G loss: 2.028195]\n",
      "epoch:19 step:15093 [D loss: 0.681628, acc: 48.44%] [G loss: 2.113387]\n",
      "epoch:19 step:15094 [D loss: 0.263700, acc: 94.53%] [G loss: 2.620873]\n",
      "epoch:19 step:15095 [D loss: 0.397762, acc: 77.34%] [G loss: 2.615336]\n",
      "epoch:19 step:15096 [D loss: 0.292399, acc: 93.75%] [G loss: 2.506764]\n",
      "epoch:19 step:15097 [D loss: 0.370788, acc: 87.50%] [G loss: 2.438489]\n",
      "epoch:19 step:15098 [D loss: 0.510769, acc: 74.22%] [G loss: 2.496513]\n",
      "epoch:19 step:15099 [D loss: 0.529047, acc: 81.25%] [G loss: 3.247490]\n",
      "epoch:19 step:15100 [D loss: 0.519225, acc: 67.97%] [G loss: 3.356798]\n",
      "epoch:19 step:15101 [D loss: 0.118842, acc: 100.00%] [G loss: 3.399342]\n",
      "epoch:19 step:15102 [D loss: 0.484223, acc: 64.84%] [G loss: 1.998196]\n",
      "epoch:19 step:15103 [D loss: 0.566828, acc: 78.91%] [G loss: 3.251207]\n",
      "epoch:19 step:15104 [D loss: 0.422993, acc: 80.47%] [G loss: 1.926550]\n",
      "epoch:19 step:15105 [D loss: 0.271675, acc: 100.00%] [G loss: 3.193529]\n",
      "epoch:19 step:15106 [D loss: 1.455900, acc: 12.50%] [G loss: 1.579959]\n",
      "epoch:19 step:15107 [D loss: 0.581382, acc: 61.72%] [G loss: 2.205768]\n",
      "epoch:19 step:15108 [D loss: 0.480716, acc: 84.38%] [G loss: 2.343704]\n",
      "epoch:19 step:15109 [D loss: 0.804661, acc: 50.78%] [G loss: 3.707356]\n",
      "epoch:19 step:15110 [D loss: 0.724130, acc: 53.12%] [G loss: 2.787369]\n",
      "epoch:19 step:15111 [D loss: 0.344225, acc: 95.31%] [G loss: 4.180550]\n",
      "epoch:19 step:15112 [D loss: 0.180002, acc: 95.31%] [G loss: 4.581470]\n",
      "epoch:19 step:15113 [D loss: 0.317915, acc: 96.09%] [G loss: 2.060471]\n",
      "epoch:19 step:15114 [D loss: 0.500229, acc: 58.59%] [G loss: 2.794518]\n",
      "epoch:19 step:15115 [D loss: 0.381817, acc: 91.41%] [G loss: 3.010780]\n",
      "epoch:19 step:15116 [D loss: 1.107180, acc: 17.97%] [G loss: 2.213207]\n",
      "epoch:19 step:15117 [D loss: 0.348356, acc: 93.75%] [G loss: 2.289437]\n",
      "epoch:19 step:15118 [D loss: 0.530755, acc: 79.69%] [G loss: 2.964635]\n",
      "epoch:19 step:15119 [D loss: 0.547943, acc: 68.75%] [G loss: 2.591702]\n",
      "epoch:19 step:15120 [D loss: 0.942474, acc: 42.19%] [G loss: 2.281050]\n",
      "epoch:19 step:15121 [D loss: 0.778089, acc: 48.44%] [G loss: 2.501837]\n",
      "epoch:19 step:15122 [D loss: 0.312819, acc: 96.88%] [G loss: 2.265568]\n",
      "epoch:19 step:15123 [D loss: 0.521922, acc: 77.34%] [G loss: 3.291498]\n",
      "epoch:19 step:15124 [D loss: 0.546369, acc: 75.78%] [G loss: 1.728571]\n",
      "epoch:19 step:15125 [D loss: 0.665713, acc: 59.38%] [G loss: 1.845332]\n",
      "epoch:19 step:15126 [D loss: 0.296317, acc: 98.44%] [G loss: 2.473425]\n",
      "epoch:19 step:15127 [D loss: 0.845044, acc: 46.09%] [G loss: 2.662025]\n",
      "epoch:19 step:15128 [D loss: 0.280055, acc: 97.66%] [G loss: 2.389949]\n",
      "epoch:19 step:15129 [D loss: 0.376671, acc: 82.81%] [G loss: 2.152428]\n",
      "epoch:19 step:15130 [D loss: 0.648891, acc: 59.38%] [G loss: 1.688014]\n",
      "epoch:19 step:15131 [D loss: 0.621021, acc: 55.47%] [G loss: 3.129725]\n",
      "epoch:19 step:15132 [D loss: 0.603846, acc: 64.84%] [G loss: 1.640185]\n",
      "epoch:19 step:15133 [D loss: 0.182278, acc: 100.00%] [G loss: 3.664164]\n",
      "epoch:19 step:15134 [D loss: 0.305555, acc: 99.22%] [G loss: 3.547746]\n",
      "epoch:19 step:15135 [D loss: 0.369701, acc: 95.31%] [G loss: 2.885656]\n",
      "epoch:19 step:15136 [D loss: 0.586633, acc: 71.88%] [G loss: 2.515646]\n",
      "epoch:19 step:15137 [D loss: 1.125880, acc: 13.28%] [G loss: 2.466201]\n",
      "epoch:19 step:15138 [D loss: 0.377347, acc: 89.06%] [G loss: 2.689767]\n",
      "epoch:19 step:15139 [D loss: 0.994267, acc: 23.44%] [G loss: 2.861941]\n",
      "epoch:19 step:15140 [D loss: 0.496305, acc: 79.69%] [G loss: 2.355294]\n",
      "epoch:19 step:15141 [D loss: 0.974760, acc: 21.88%] [G loss: 2.999098]\n",
      "epoch:19 step:15142 [D loss: 0.748219, acc: 47.66%] [G loss: 1.989988]\n",
      "epoch:19 step:15143 [D loss: 0.389705, acc: 85.16%] [G loss: 2.771533]\n",
      "epoch:19 step:15144 [D loss: 0.228783, acc: 96.88%] [G loss: 3.191002]\n",
      "epoch:19 step:15145 [D loss: 0.409196, acc: 83.59%] [G loss: 3.382121]\n",
      "epoch:19 step:15146 [D loss: 0.379307, acc: 90.62%] [G loss: 3.500545]\n",
      "epoch:19 step:15147 [D loss: 0.494322, acc: 70.31%] [G loss: 2.909804]\n",
      "epoch:19 step:15148 [D loss: 0.676099, acc: 63.28%] [G loss: 1.893635]\n",
      "epoch:19 step:15149 [D loss: 0.578006, acc: 63.28%] [G loss: 2.829298]\n",
      "epoch:19 step:15150 [D loss: 0.277059, acc: 98.44%] [G loss: 2.545088]\n",
      "epoch:19 step:15151 [D loss: 0.936685, acc: 47.66%] [G loss: 2.315879]\n",
      "epoch:19 step:15152 [D loss: 0.248948, acc: 97.66%] [G loss: 3.138508]\n",
      "epoch:19 step:15153 [D loss: 0.361180, acc: 85.94%] [G loss: 2.758242]\n",
      "epoch:19 step:15154 [D loss: 0.962366, acc: 22.66%] [G loss: 3.409715]\n",
      "epoch:19 step:15155 [D loss: 0.244061, acc: 96.09%] [G loss: 4.114915]\n",
      "epoch:19 step:15156 [D loss: 0.137313, acc: 100.00%] [G loss: 4.607327]\n",
      "epoch:19 step:15157 [D loss: 0.716252, acc: 53.12%] [G loss: 2.806224]\n",
      "epoch:19 step:15158 [D loss: 0.369338, acc: 92.97%] [G loss: 2.241492]\n",
      "epoch:19 step:15159 [D loss: 0.756553, acc: 46.88%] [G loss: 2.365571]\n",
      "epoch:19 step:15160 [D loss: 0.697433, acc: 53.91%] [G loss: 2.033867]\n",
      "epoch:19 step:15161 [D loss: 0.454566, acc: 82.81%] [G loss: 3.640015]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:19 step:15162 [D loss: 0.401046, acc: 92.97%] [G loss: 3.464886]\n",
      "epoch:19 step:15163 [D loss: 0.432559, acc: 83.59%] [G loss: 3.519320]\n",
      "epoch:19 step:15164 [D loss: 0.539959, acc: 78.91%] [G loss: 2.917747]\n",
      "epoch:19 step:15165 [D loss: 0.915812, acc: 47.66%] [G loss: 1.962763]\n",
      "epoch:19 step:15166 [D loss: 0.386789, acc: 82.81%] [G loss: 3.596822]\n",
      "epoch:19 step:15167 [D loss: 0.360682, acc: 96.88%] [G loss: 2.593153]\n",
      "epoch:19 step:15168 [D loss: 0.284826, acc: 99.22%] [G loss: 3.771532]\n",
      "epoch:19 step:15169 [D loss: 0.240491, acc: 99.22%] [G loss: 3.483597]\n",
      "epoch:19 step:15170 [D loss: 0.609232, acc: 65.62%] [G loss: 3.189519]\n",
      "epoch:19 step:15171 [D loss: 0.587611, acc: 60.16%] [G loss: 4.033698]\n",
      "epoch:19 step:15172 [D loss: 0.317184, acc: 83.59%] [G loss: 3.598798]\n",
      "epoch:19 step:15173 [D loss: 0.386946, acc: 80.47%] [G loss: 3.571360]\n",
      "epoch:19 step:15174 [D loss: 0.225196, acc: 97.66%] [G loss: 3.136815]\n",
      "epoch:19 step:15175 [D loss: 0.500278, acc: 78.12%] [G loss: 2.302439]\n",
      "epoch:19 step:15176 [D loss: 0.436737, acc: 82.81%] [G loss: 1.822770]\n",
      "epoch:19 step:15177 [D loss: 0.342523, acc: 96.09%] [G loss: 3.504797]\n",
      "epoch:19 step:15178 [D loss: 0.278548, acc: 96.09%] [G loss: 2.915872]\n",
      "epoch:19 step:15179 [D loss: 0.890541, acc: 33.59%] [G loss: 3.227093]\n",
      "epoch:19 step:15180 [D loss: 0.188382, acc: 97.66%] [G loss: 3.889996]\n",
      "epoch:19 step:15181 [D loss: 0.357469, acc: 89.06%] [G loss: 2.856643]\n",
      "epoch:19 step:15182 [D loss: 0.646201, acc: 60.16%] [G loss: 2.371599]\n",
      "epoch:19 step:15183 [D loss: 0.529655, acc: 66.41%] [G loss: 3.697212]\n",
      "epoch:19 step:15184 [D loss: 0.253003, acc: 93.75%] [G loss: 2.496816]\n",
      "epoch:19 step:15185 [D loss: 0.779755, acc: 51.56%] [G loss: 3.321390]\n",
      "epoch:19 step:15186 [D loss: 0.386248, acc: 87.50%] [G loss: 2.674187]\n",
      "epoch:19 step:15187 [D loss: 0.693757, acc: 57.81%] [G loss: 2.451981]\n",
      "epoch:19 step:15188 [D loss: 0.415126, acc: 80.47%] [G loss: 2.063981]\n",
      "epoch:19 step:15189 [D loss: 0.253642, acc: 96.09%] [G loss: 3.150926]\n",
      "epoch:19 step:15190 [D loss: 1.000783, acc: 24.22%] [G loss: 2.090757]\n",
      "epoch:19 step:15191 [D loss: 0.396804, acc: 85.94%] [G loss: 3.008071]\n",
      "epoch:19 step:15192 [D loss: 0.714495, acc: 58.59%] [G loss: 2.573305]\n",
      "epoch:19 step:15193 [D loss: 0.595208, acc: 65.62%] [G loss: 2.152322]\n",
      "epoch:19 step:15194 [D loss: 0.662983, acc: 60.94%] [G loss: 2.519229]\n",
      "epoch:19 step:15195 [D loss: 1.017084, acc: 48.44%] [G loss: 2.484904]\n",
      "epoch:19 step:15196 [D loss: 0.369959, acc: 95.31%] [G loss: 2.860502]\n",
      "epoch:19 step:15197 [D loss: 0.572078, acc: 64.84%] [G loss: 2.756125]\n",
      "epoch:19 step:15198 [D loss: 0.466275, acc: 78.91%] [G loss: 3.637478]\n",
      "epoch:19 step:15199 [D loss: 0.356895, acc: 93.75%] [G loss: 2.531354]\n",
      "epoch:19 step:15200 [D loss: 0.460855, acc: 85.16%] [G loss: 2.789274]\n",
      "##############\n",
      "[0.85560057 0.86499055 0.81133085 0.82267978 0.81004816 0.85452482\n",
      " 0.88636991 0.82156217 0.81068539 0.83322409]\n",
      "##########\n",
      "epoch:19 step:15201 [D loss: 0.305460, acc: 95.31%] [G loss: 4.528469]\n",
      "epoch:19 step:15202 [D loss: 1.113176, acc: 13.28%] [G loss: 3.232440]\n",
      "epoch:19 step:15203 [D loss: 0.591709, acc: 71.88%] [G loss: 3.089777]\n",
      "epoch:19 step:15204 [D loss: 0.345796, acc: 96.09%] [G loss: 3.303118]\n",
      "epoch:19 step:15205 [D loss: 0.901663, acc: 42.19%] [G loss: 2.621706]\n",
      "epoch:19 step:15206 [D loss: 1.054283, acc: 41.41%] [G loss: 3.167170]\n",
      "epoch:19 step:15207 [D loss: 0.377564, acc: 89.84%] [G loss: 3.689376]\n",
      "epoch:19 step:15208 [D loss: 0.650901, acc: 52.34%] [G loss: 3.332064]\n",
      "epoch:19 step:15209 [D loss: 1.029603, acc: 16.41%] [G loss: 4.586100]\n",
      "epoch:19 step:15210 [D loss: 0.519916, acc: 85.16%] [G loss: 2.206252]\n",
      "epoch:19 step:15211 [D loss: 0.687984, acc: 57.81%] [G loss: 3.201960]\n",
      "epoch:19 step:15212 [D loss: 0.885088, acc: 35.94%] [G loss: 2.505121]\n",
      "epoch:19 step:15213 [D loss: 0.588400, acc: 60.94%] [G loss: 2.526048]\n",
      "epoch:19 step:15214 [D loss: 0.887306, acc: 31.25%] [G loss: 2.982609]\n",
      "epoch:19 step:15215 [D loss: 0.340604, acc: 94.53%] [G loss: 2.288252]\n",
      "epoch:19 step:15216 [D loss: 0.404984, acc: 78.91%] [G loss: 2.806621]\n",
      "epoch:19 step:15217 [D loss: 0.324840, acc: 99.22%] [G loss: 1.970126]\n",
      "epoch:19 step:15218 [D loss: 0.207022, acc: 95.31%] [G loss: 3.210454]\n",
      "epoch:19 step:15219 [D loss: 1.009588, acc: 48.44%] [G loss: 3.239824]\n",
      "epoch:19 step:15220 [D loss: 0.151496, acc: 99.22%] [G loss: 3.375326]\n",
      "epoch:19 step:15221 [D loss: 0.362834, acc: 95.31%] [G loss: 2.990531]\n",
      "epoch:19 step:15222 [D loss: 0.551550, acc: 78.91%] [G loss: 2.262171]\n",
      "epoch:19 step:15223 [D loss: 0.571232, acc: 72.66%] [G loss: 3.243324]\n",
      "epoch:19 step:15224 [D loss: 0.165974, acc: 97.66%] [G loss: 4.235376]\n",
      "epoch:19 step:15225 [D loss: 0.332789, acc: 90.62%] [G loss: 2.417520]\n",
      "epoch:19 step:15226 [D loss: 0.628441, acc: 63.28%] [G loss: 2.626611]\n",
      "epoch:19 step:15227 [D loss: 0.468030, acc: 84.38%] [G loss: 2.720380]\n",
      "epoch:19 step:15228 [D loss: 1.120592, acc: 14.06%] [G loss: 2.783560]\n",
      "epoch:19 step:15229 [D loss: 0.251581, acc: 96.88%] [G loss: 2.797722]\n",
      "epoch:19 step:15230 [D loss: 1.002627, acc: 32.03%] [G loss: 2.306294]\n",
      "epoch:19 step:15231 [D loss: 0.428749, acc: 87.50%] [G loss: 2.616471]\n",
      "epoch:19 step:15232 [D loss: 0.116694, acc: 100.00%] [G loss: 3.461839]\n",
      "epoch:19 step:15233 [D loss: 0.640482, acc: 55.47%] [G loss: 2.749404]\n",
      "epoch:19 step:15234 [D loss: 0.316777, acc: 93.75%] [G loss: 2.917003]\n",
      "epoch:19 step:15235 [D loss: 0.405459, acc: 91.41%] [G loss: 2.575474]\n",
      "epoch:19 step:15236 [D loss: 0.674366, acc: 58.59%] [G loss: 2.669890]\n",
      "epoch:19 step:15237 [D loss: 0.943885, acc: 43.75%] [G loss: 2.725742]\n",
      "epoch:19 step:15238 [D loss: 0.313914, acc: 88.28%] [G loss: 3.461110]\n",
      "epoch:19 step:15239 [D loss: 0.254161, acc: 98.44%] [G loss: 2.681852]\n",
      "epoch:19 step:15240 [D loss: 0.469652, acc: 72.66%] [G loss: 3.538584]\n",
      "epoch:19 step:15241 [D loss: 0.442676, acc: 79.69%] [G loss: 2.599002]\n",
      "epoch:19 step:15242 [D loss: 0.567762, acc: 69.53%] [G loss: 2.650013]\n",
      "epoch:19 step:15243 [D loss: 0.196414, acc: 98.44%] [G loss: 2.099462]\n",
      "epoch:19 step:15244 [D loss: 0.967579, acc: 35.16%] [G loss: 2.051631]\n",
      "epoch:19 step:15245 [D loss: 0.869832, acc: 32.03%] [G loss: 2.988355]\n",
      "epoch:19 step:15246 [D loss: 0.239961, acc: 98.44%] [G loss: 3.174797]\n",
      "epoch:19 step:15247 [D loss: 0.345774, acc: 87.50%] [G loss: 3.671178]\n",
      "epoch:19 step:15248 [D loss: 0.836233, acc: 48.44%] [G loss: 2.173693]\n",
      "epoch:19 step:15249 [D loss: 0.368982, acc: 90.62%] [G loss: 2.435773]\n",
      "epoch:19 step:15250 [D loss: 0.683094, acc: 61.72%] [G loss: 2.455686]\n",
      "epoch:19 step:15251 [D loss: 0.213067, acc: 95.31%] [G loss: 3.407609]\n",
      "epoch:19 step:15252 [D loss: 0.532050, acc: 67.97%] [G loss: 2.673779]\n",
      "epoch:19 step:15253 [D loss: 1.300569, acc: 27.34%] [G loss: 2.694522]\n",
      "epoch:19 step:15254 [D loss: 0.550673, acc: 74.22%] [G loss: 2.770709]\n",
      "epoch:19 step:15255 [D loss: 0.563904, acc: 78.12%] [G loss: 3.007476]\n",
      "epoch:19 step:15256 [D loss: 0.683539, acc: 51.56%] [G loss: 1.990449]\n",
      "epoch:19 step:15257 [D loss: 0.591612, acc: 60.94%] [G loss: 3.696698]\n",
      "epoch:19 step:15258 [D loss: 0.278544, acc: 92.19%] [G loss: 3.761046]\n",
      "epoch:19 step:15259 [D loss: 0.585731, acc: 68.75%] [G loss: 2.765867]\n",
      "epoch:19 step:15260 [D loss: 0.435360, acc: 83.59%] [G loss: 2.373523]\n",
      "epoch:19 step:15261 [D loss: 0.210576, acc: 100.00%] [G loss: 3.510942]\n",
      "epoch:19 step:15262 [D loss: 1.020069, acc: 36.72%] [G loss: 2.539701]\n",
      "epoch:19 step:15263 [D loss: 0.634251, acc: 60.94%] [G loss: 2.729953]\n",
      "epoch:19 step:15264 [D loss: 0.228546, acc: 96.09%] [G loss: 2.605928]\n",
      "epoch:19 step:15265 [D loss: 0.373399, acc: 89.84%] [G loss: 4.041754]\n",
      "epoch:19 step:15266 [D loss: 0.290216, acc: 98.44%] [G loss: 2.110233]\n",
      "epoch:19 step:15267 [D loss: 0.210703, acc: 99.22%] [G loss: 3.582180]\n",
      "epoch:19 step:15268 [D loss: 0.810498, acc: 48.44%] [G loss: 2.909643]\n",
      "epoch:19 step:15269 [D loss: 0.392247, acc: 94.53%] [G loss: 2.704380]\n",
      "epoch:19 step:15270 [D loss: 0.517443, acc: 74.22%] [G loss: 2.325882]\n",
      "epoch:19 step:15271 [D loss: 0.506148, acc: 70.31%] [G loss: 2.216278]\n",
      "epoch:19 step:15272 [D loss: 0.581591, acc: 63.28%] [G loss: 1.909623]\n",
      "epoch:19 step:15273 [D loss: 0.450315, acc: 78.12%] [G loss: 3.150927]\n",
      "epoch:19 step:15274 [D loss: 0.475197, acc: 83.59%] [G loss: 2.232092]\n",
      "epoch:19 step:15275 [D loss: 0.733630, acc: 53.12%] [G loss: 2.434084]\n",
      "epoch:19 step:15276 [D loss: 0.625145, acc: 69.53%] [G loss: 2.418403]\n",
      "epoch:19 step:15277 [D loss: 0.192732, acc: 98.44%] [G loss: 4.259176]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:19 step:15278 [D loss: 0.521657, acc: 78.12%] [G loss: 2.488787]\n",
      "epoch:19 step:15279 [D loss: 0.644143, acc: 65.62%] [G loss: 2.734035]\n",
      "epoch:19 step:15280 [D loss: 0.631258, acc: 64.06%] [G loss: 2.755860]\n",
      "epoch:19 step:15281 [D loss: 0.406622, acc: 91.41%] [G loss: 2.808332]\n",
      "epoch:19 step:15282 [D loss: 0.435906, acc: 75.00%] [G loss: 4.124674]\n",
      "epoch:19 step:15283 [D loss: 0.461973, acc: 78.91%] [G loss: 3.056114]\n",
      "epoch:19 step:15284 [D loss: 0.400025, acc: 89.06%] [G loss: 2.919203]\n",
      "epoch:19 step:15285 [D loss: 0.352846, acc: 92.97%] [G loss: 3.290914]\n",
      "epoch:19 step:15286 [D loss: 0.632867, acc: 66.41%] [G loss: 2.959767]\n",
      "epoch:19 step:15287 [D loss: 0.287180, acc: 98.44%] [G loss: 2.959085]\n",
      "epoch:19 step:15288 [D loss: 0.447982, acc: 76.56%] [G loss: 2.964275]\n",
      "epoch:19 step:15289 [D loss: 0.248382, acc: 98.44%] [G loss: 3.306797]\n",
      "epoch:19 step:15290 [D loss: 0.214487, acc: 95.31%] [G loss: 4.508763]\n",
      "epoch:19 step:15291 [D loss: 0.813907, acc: 50.78%] [G loss: 3.011631]\n",
      "epoch:19 step:15292 [D loss: 0.192213, acc: 98.44%] [G loss: 2.745903]\n",
      "epoch:19 step:15293 [D loss: 0.414837, acc: 92.19%] [G loss: 2.364315]\n",
      "epoch:19 step:15294 [D loss: 0.747200, acc: 54.69%] [G loss: 2.790699]\n",
      "epoch:19 step:15295 [D loss: 0.776301, acc: 46.88%] [G loss: 2.989771]\n",
      "epoch:19 step:15296 [D loss: 0.611185, acc: 72.66%] [G loss: 2.630871]\n",
      "epoch:19 step:15297 [D loss: 0.341635, acc: 92.19%] [G loss: 3.288485]\n",
      "epoch:19 step:15298 [D loss: 0.654221, acc: 57.81%] [G loss: 2.816570]\n",
      "epoch:19 step:15299 [D loss: 0.317420, acc: 93.75%] [G loss: 3.277456]\n",
      "epoch:19 step:15300 [D loss: 0.460863, acc: 73.44%] [G loss: 3.639893]\n",
      "epoch:19 step:15301 [D loss: 0.496265, acc: 70.31%] [G loss: 3.786018]\n",
      "epoch:19 step:15302 [D loss: 0.451418, acc: 83.59%] [G loss: 3.022686]\n",
      "epoch:19 step:15303 [D loss: 0.284465, acc: 96.09%] [G loss: 2.795871]\n",
      "epoch:19 step:15304 [D loss: 0.334619, acc: 94.53%] [G loss: 3.606558]\n",
      "epoch:19 step:15305 [D loss: 0.139496, acc: 100.00%] [G loss: 4.805587]\n",
      "epoch:19 step:15306 [D loss: 0.846944, acc: 36.72%] [G loss: 2.537264]\n",
      "epoch:19 step:15307 [D loss: 0.770611, acc: 46.88%] [G loss: 3.310212]\n",
      "epoch:19 step:15308 [D loss: 0.420528, acc: 89.06%] [G loss: 2.131766]\n",
      "epoch:19 step:15309 [D loss: 0.119091, acc: 100.00%] [G loss: 2.842538]\n",
      "epoch:19 step:15310 [D loss: 0.476005, acc: 81.25%] [G loss: 3.382277]\n",
      "epoch:19 step:15311 [D loss: 0.522365, acc: 71.09%] [G loss: 2.045487]\n",
      "epoch:19 step:15312 [D loss: 0.788385, acc: 49.22%] [G loss: 2.648425]\n",
      "epoch:19 step:15313 [D loss: 0.802512, acc: 52.34%] [G loss: 2.191371]\n",
      "epoch:19 step:15314 [D loss: 0.604764, acc: 60.16%] [G loss: 2.634304]\n",
      "epoch:19 step:15315 [D loss: 0.522706, acc: 72.66%] [G loss: 2.491721]\n",
      "epoch:19 step:15316 [D loss: 0.268291, acc: 96.09%] [G loss: 4.167753]\n",
      "epoch:19 step:15317 [D loss: 0.251848, acc: 97.66%] [G loss: 3.881622]\n",
      "epoch:19 step:15318 [D loss: 0.282300, acc: 90.62%] [G loss: 3.696639]\n",
      "epoch:19 step:15319 [D loss: 0.643927, acc: 59.38%] [G loss: 3.356124]\n",
      "epoch:19 step:15320 [D loss: 0.658652, acc: 64.06%] [G loss: 2.180158]\n",
      "epoch:19 step:15321 [D loss: 0.782422, acc: 48.44%] [G loss: 3.154742]\n",
      "epoch:19 step:15322 [D loss: 0.324620, acc: 94.53%] [G loss: 3.180951]\n",
      "epoch:19 step:15323 [D loss: 0.665673, acc: 55.47%] [G loss: 2.621318]\n",
      "epoch:19 step:15324 [D loss: 0.454317, acc: 78.12%] [G loss: 3.507871]\n",
      "epoch:19 step:15325 [D loss: 0.443793, acc: 85.94%] [G loss: 3.133849]\n",
      "epoch:19 step:15326 [D loss: 0.540817, acc: 77.34%] [G loss: 3.174414]\n",
      "epoch:19 step:15327 [D loss: 0.153632, acc: 98.44%] [G loss: 2.918864]\n",
      "epoch:19 step:15328 [D loss: 0.275633, acc: 99.22%] [G loss: 3.284926]\n",
      "epoch:19 step:15329 [D loss: 0.312085, acc: 88.28%] [G loss: 3.664670]\n",
      "epoch:19 step:15330 [D loss: 0.550276, acc: 65.62%] [G loss: 2.138578]\n",
      "epoch:19 step:15331 [D loss: 1.036790, acc: 17.97%] [G loss: 2.801190]\n",
      "epoch:19 step:15332 [D loss: 0.373784, acc: 92.19%] [G loss: 2.493155]\n",
      "epoch:19 step:15333 [D loss: 0.117745, acc: 100.00%] [G loss: 3.511595]\n",
      "epoch:19 step:15334 [D loss: 0.238690, acc: 100.00%] [G loss: 3.730804]\n",
      "epoch:19 step:15335 [D loss: 0.502252, acc: 85.16%] [G loss: 3.592961]\n",
      "epoch:19 step:15336 [D loss: 0.123559, acc: 100.00%] [G loss: 3.584042]\n",
      "epoch:19 step:15337 [D loss: 0.311697, acc: 96.88%] [G loss: 3.787594]\n",
      "epoch:19 step:15338 [D loss: 0.500891, acc: 72.66%] [G loss: 2.769861]\n",
      "epoch:19 step:15339 [D loss: 0.430670, acc: 89.06%] [G loss: 3.358724]\n",
      "epoch:19 step:15340 [D loss: 0.219194, acc: 94.53%] [G loss: 4.341824]\n",
      "epoch:19 step:15341 [D loss: 0.426306, acc: 76.56%] [G loss: 3.388999]\n",
      "epoch:19 step:15342 [D loss: 0.436736, acc: 86.72%] [G loss: 3.294548]\n",
      "epoch:19 step:15343 [D loss: 0.996448, acc: 25.00%] [G loss: 2.057904]\n",
      "epoch:19 step:15344 [D loss: 1.105820, acc: 17.97%] [G loss: 3.029514]\n",
      "epoch:19 step:15345 [D loss: 0.733995, acc: 51.56%] [G loss: 1.880418]\n",
      "epoch:19 step:15346 [D loss: 0.729084, acc: 53.91%] [G loss: 2.587829]\n",
      "epoch:19 step:15347 [D loss: 0.718355, acc: 53.91%] [G loss: 2.829873]\n",
      "epoch:19 step:15348 [D loss: 0.506594, acc: 65.62%] [G loss: 3.628293]\n",
      "epoch:19 step:15349 [D loss: 0.547197, acc: 71.09%] [G loss: 3.383568]\n",
      "epoch:19 step:15350 [D loss: 0.301609, acc: 90.62%] [G loss: 4.071355]\n",
      "epoch:19 step:15351 [D loss: 0.868420, acc: 49.22%] [G loss: 3.903177]\n",
      "epoch:19 step:15352 [D loss: 0.674352, acc: 60.16%] [G loss: 4.223623]\n",
      "epoch:19 step:15353 [D loss: 0.647491, acc: 64.06%] [G loss: 3.027973]\n",
      "epoch:19 step:15354 [D loss: 0.407077, acc: 85.94%] [G loss: 3.848825]\n",
      "epoch:19 step:15355 [D loss: 0.840905, acc: 40.62%] [G loss: 2.219429]\n",
      "epoch:19 step:15356 [D loss: 0.128470, acc: 99.22%] [G loss: 3.914608]\n",
      "epoch:19 step:15357 [D loss: 0.686956, acc: 63.28%] [G loss: 3.456068]\n",
      "epoch:19 step:15358 [D loss: 0.712956, acc: 52.34%] [G loss: 3.023180]\n",
      "epoch:19 step:15359 [D loss: 1.058958, acc: 50.00%] [G loss: 2.987002]\n",
      "epoch:19 step:15360 [D loss: 0.128208, acc: 100.00%] [G loss: 2.242569]\n",
      "epoch:19 step:15361 [D loss: 0.713775, acc: 51.56%] [G loss: 2.223293]\n",
      "epoch:19 step:15362 [D loss: 0.487123, acc: 75.00%] [G loss: 1.952820]\n",
      "epoch:19 step:15363 [D loss: 0.228987, acc: 100.00%] [G loss: 3.377348]\n",
      "epoch:19 step:15364 [D loss: 0.852384, acc: 40.62%] [G loss: 2.254211]\n",
      "epoch:19 step:15365 [D loss: 0.838600, acc: 42.97%] [G loss: 3.027598]\n",
      "epoch:19 step:15366 [D loss: 0.168442, acc: 98.44%] [G loss: 4.038334]\n",
      "epoch:19 step:15367 [D loss: 0.490963, acc: 76.56%] [G loss: 3.090566]\n",
      "epoch:19 step:15368 [D loss: 0.244419, acc: 98.44%] [G loss: 1.866565]\n",
      "epoch:19 step:15369 [D loss: 0.466264, acc: 78.12%] [G loss: 2.462789]\n",
      "epoch:19 step:15370 [D loss: 0.544530, acc: 72.66%] [G loss: 2.816691]\n",
      "epoch:19 step:15371 [D loss: 0.707745, acc: 53.12%] [G loss: 2.698480]\n",
      "epoch:19 step:15372 [D loss: 0.892761, acc: 40.62%] [G loss: 2.203681]\n",
      "epoch:19 step:15373 [D loss: 0.240322, acc: 98.44%] [G loss: 2.951323]\n",
      "epoch:19 step:15374 [D loss: 0.672716, acc: 58.59%] [G loss: 1.539935]\n",
      "epoch:19 step:15375 [D loss: 0.454245, acc: 76.56%] [G loss: 3.752432]\n",
      "epoch:19 step:15376 [D loss: 0.318045, acc: 94.53%] [G loss: 1.973421]\n",
      "epoch:19 step:15377 [D loss: 0.375290, acc: 94.53%] [G loss: 3.721989]\n",
      "epoch:19 step:15378 [D loss: 0.589374, acc: 70.31%] [G loss: 3.547860]\n",
      "epoch:19 step:15379 [D loss: 0.411160, acc: 85.94%] [G loss: 3.359948]\n",
      "epoch:19 step:15380 [D loss: 0.097246, acc: 100.00%] [G loss: 3.024386]\n",
      "epoch:19 step:15381 [D loss: 0.603579, acc: 66.41%] [G loss: 2.755309]\n",
      "epoch:19 step:15382 [D loss: 0.903837, acc: 40.62%] [G loss: 2.551213]\n",
      "epoch:19 step:15383 [D loss: 1.149833, acc: 14.06%] [G loss: 2.917930]\n",
      "epoch:19 step:15384 [D loss: 0.307676, acc: 96.88%] [G loss: 2.587505]\n",
      "epoch:19 step:15385 [D loss: 0.302325, acc: 89.84%] [G loss: 3.793146]\n",
      "epoch:19 step:15386 [D loss: 0.445075, acc: 87.50%] [G loss: 1.646668]\n",
      "epoch:19 step:15387 [D loss: 0.868491, acc: 50.00%] [G loss: 2.185342]\n",
      "epoch:19 step:15388 [D loss: 0.308968, acc: 96.09%] [G loss: 1.996911]\n",
      "epoch:19 step:15389 [D loss: 0.271903, acc: 98.44%] [G loss: 3.319684]\n",
      "epoch:19 step:15390 [D loss: 0.220593, acc: 97.66%] [G loss: 4.204137]\n",
      "epoch:19 step:15391 [D loss: 0.824640, acc: 43.75%] [G loss: 2.452413]\n",
      "epoch:19 step:15392 [D loss: 0.855427, acc: 46.09%] [G loss: 2.473746]\n",
      "epoch:19 step:15393 [D loss: 0.944270, acc: 43.75%] [G loss: 2.216693]\n",
      "epoch:19 step:15394 [D loss: 0.315880, acc: 95.31%] [G loss: 4.290820]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:19 step:15395 [D loss: 0.880506, acc: 34.38%] [G loss: 4.426606]\n",
      "epoch:19 step:15396 [D loss: 0.469022, acc: 85.94%] [G loss: 4.005524]\n",
      "epoch:19 step:15397 [D loss: 0.308715, acc: 91.41%] [G loss: 4.223731]\n",
      "epoch:19 step:15398 [D loss: 0.483013, acc: 72.66%] [G loss: 3.735909]\n",
      "epoch:19 step:15399 [D loss: 0.462734, acc: 76.56%] [G loss: 2.900654]\n",
      "epoch:19 step:15400 [D loss: 0.436495, acc: 78.91%] [G loss: 3.751536]\n",
      "##############\n",
      "[0.85576387 0.8592591  0.83163689 0.80608456 0.79113762 0.82759875\n",
      " 0.88346715 0.81463871 0.81695456 0.8503944 ]\n",
      "##########\n",
      "epoch:19 step:15401 [D loss: 0.734996, acc: 51.56%] [G loss: 2.815910]\n",
      "epoch:19 step:15402 [D loss: 0.354235, acc: 81.25%] [G loss: 4.547073]\n",
      "epoch:19 step:15403 [D loss: 0.928172, acc: 27.34%] [G loss: 4.382604]\n",
      "epoch:19 step:15404 [D loss: 0.479675, acc: 83.59%] [G loss: 2.867363]\n",
      "epoch:19 step:15405 [D loss: 0.384167, acc: 91.41%] [G loss: 2.247074]\n",
      "epoch:19 step:15406 [D loss: 0.748935, acc: 50.00%] [G loss: 2.524758]\n",
      "epoch:19 step:15407 [D loss: 0.689608, acc: 62.50%] [G loss: 1.643246]\n",
      "epoch:19 step:15408 [D loss: 0.430767, acc: 89.06%] [G loss: 2.052210]\n",
      "epoch:19 step:15409 [D loss: 0.753617, acc: 51.56%] [G loss: 3.678957]\n",
      "epoch:19 step:15410 [D loss: 0.128949, acc: 99.22%] [G loss: 2.850962]\n",
      "epoch:19 step:15411 [D loss: 0.470244, acc: 71.88%] [G loss: 3.603609]\n",
      "epoch:19 step:15412 [D loss: 0.250651, acc: 99.22%] [G loss: 2.539373]\n",
      "epoch:19 step:15413 [D loss: 0.452339, acc: 67.97%] [G loss: 4.465876]\n",
      "epoch:19 step:15414 [D loss: 0.463711, acc: 88.28%] [G loss: 2.445258]\n",
      "epoch:19 step:15415 [D loss: 0.281269, acc: 97.66%] [G loss: 3.707946]\n",
      "epoch:19 step:15416 [D loss: 0.388663, acc: 90.62%] [G loss: 3.146920]\n",
      "epoch:19 step:15417 [D loss: 0.274774, acc: 96.09%] [G loss: 2.416678]\n",
      "epoch:19 step:15418 [D loss: 0.530892, acc: 73.44%] [G loss: 3.474355]\n",
      "epoch:19 step:15419 [D loss: 0.572229, acc: 59.38%] [G loss: 2.832529]\n",
      "epoch:19 step:15420 [D loss: 0.189937, acc: 100.00%] [G loss: 3.657318]\n",
      "epoch:19 step:15421 [D loss: 0.194173, acc: 99.22%] [G loss: 3.743146]\n",
      "epoch:19 step:15422 [D loss: 0.371147, acc: 87.50%] [G loss: 3.505905]\n",
      "epoch:19 step:15423 [D loss: 0.800128, acc: 39.84%] [G loss: 3.244165]\n",
      "epoch:19 step:15424 [D loss: 1.130535, acc: 47.66%] [G loss: 1.917187]\n",
      "epoch:19 step:15425 [D loss: 0.443832, acc: 83.59%] [G loss: 3.382544]\n",
      "epoch:19 step:15426 [D loss: 0.735910, acc: 53.12%] [G loss: 2.842437]\n",
      "epoch:19 step:15427 [D loss: 0.694970, acc: 58.59%] [G loss: 2.251929]\n",
      "epoch:19 step:15428 [D loss: 0.696376, acc: 56.25%] [G loss: 2.665226]\n",
      "epoch:19 step:15429 [D loss: 0.491302, acc: 68.75%] [G loss: 3.421556]\n",
      "epoch:19 step:15430 [D loss: 0.888992, acc: 36.72%] [G loss: 2.113555]\n",
      "epoch:19 step:15431 [D loss: 0.684736, acc: 57.03%] [G loss: 2.731558]\n",
      "epoch:19 step:15432 [D loss: 0.441448, acc: 81.25%] [G loss: 2.772628]\n",
      "epoch:19 step:15433 [D loss: 1.364784, acc: 6.25%] [G loss: 2.640950]\n",
      "epoch:19 step:15434 [D loss: 0.458153, acc: 76.56%] [G loss: 3.257367]\n",
      "epoch:19 step:15435 [D loss: 0.530628, acc: 77.34%] [G loss: 2.503651]\n",
      "epoch:19 step:15436 [D loss: 0.661674, acc: 57.03%] [G loss: 3.051579]\n",
      "epoch:19 step:15437 [D loss: 0.199959, acc: 100.00%] [G loss: 5.091892]\n",
      "epoch:19 step:15438 [D loss: 0.729007, acc: 53.91%] [G loss: 2.931561]\n",
      "epoch:19 step:15439 [D loss: 0.800586, acc: 53.91%] [G loss: 2.845377]\n",
      "epoch:19 step:15440 [D loss: 0.379615, acc: 92.97%] [G loss: 3.057028]\n",
      "epoch:19 step:15441 [D loss: 0.329750, acc: 93.75%] [G loss: 2.783856]\n",
      "epoch:19 step:15442 [D loss: 0.720834, acc: 51.56%] [G loss: 4.518414]\n",
      "epoch:19 step:15443 [D loss: 0.495074, acc: 81.25%] [G loss: 3.919786]\n",
      "epoch:19 step:15444 [D loss: 0.501869, acc: 67.97%] [G loss: 2.910909]\n",
      "epoch:19 step:15445 [D loss: 0.174757, acc: 96.88%] [G loss: 4.330145]\n",
      "epoch:19 step:15446 [D loss: 0.739645, acc: 53.91%] [G loss: 3.154333]\n",
      "epoch:19 step:15447 [D loss: 0.307604, acc: 96.09%] [G loss: 2.864588]\n",
      "epoch:19 step:15448 [D loss: 0.412070, acc: 75.00%] [G loss: 3.501432]\n",
      "epoch:19 step:15449 [D loss: 0.396473, acc: 83.59%] [G loss: 3.149665]\n",
      "epoch:19 step:15450 [D loss: 0.513459, acc: 77.34%] [G loss: 2.214341]\n",
      "epoch:19 step:15451 [D loss: 0.867944, acc: 48.44%] [G loss: 2.229890]\n",
      "epoch:19 step:15452 [D loss: 0.468302, acc: 83.59%] [G loss: 3.700579]\n",
      "epoch:19 step:15453 [D loss: 0.291249, acc: 96.88%] [G loss: 3.581732]\n",
      "epoch:19 step:15454 [D loss: 0.296147, acc: 90.62%] [G loss: 3.340598]\n",
      "epoch:19 step:15455 [D loss: 0.491198, acc: 77.34%] [G loss: 4.574150]\n",
      "epoch:19 step:15456 [D loss: 0.734022, acc: 53.91%] [G loss: 3.230240]\n",
      "epoch:19 step:15457 [D loss: 0.489600, acc: 77.34%] [G loss: 2.538997]\n",
      "epoch:19 step:15458 [D loss: 0.768373, acc: 43.75%] [G loss: 3.000960]\n",
      "epoch:19 step:15459 [D loss: 0.848474, acc: 35.94%] [G loss: 3.141023]\n",
      "epoch:19 step:15460 [D loss: 0.296156, acc: 96.88%] [G loss: 2.246678]\n",
      "epoch:19 step:15461 [D loss: 0.277541, acc: 96.88%] [G loss: 3.007819]\n",
      "epoch:19 step:15462 [D loss: 0.281112, acc: 92.97%] [G loss: 2.103187]\n",
      "epoch:19 step:15463 [D loss: 0.445768, acc: 75.00%] [G loss: 3.061274]\n",
      "epoch:19 step:15464 [D loss: 0.578445, acc: 70.31%] [G loss: 1.492741]\n",
      "epoch:19 step:15465 [D loss: 0.601741, acc: 60.94%] [G loss: 2.689123]\n",
      "epoch:19 step:15466 [D loss: 0.275016, acc: 93.75%] [G loss: 2.973712]\n",
      "epoch:19 step:15467 [D loss: 0.850731, acc: 50.00%] [G loss: 2.362445]\n",
      "epoch:19 step:15468 [D loss: 0.643454, acc: 54.69%] [G loss: 2.460606]\n",
      "epoch:19 step:15469 [D loss: 0.149386, acc: 100.00%] [G loss: 4.078748]\n",
      "epoch:19 step:15470 [D loss: 0.313591, acc: 97.66%] [G loss: 2.901620]\n",
      "epoch:19 step:15471 [D loss: 0.262500, acc: 96.88%] [G loss: 3.229466]\n",
      "epoch:19 step:15472 [D loss: 0.299483, acc: 93.75%] [G loss: 3.382299]\n",
      "epoch:19 step:15473 [D loss: 0.818623, acc: 44.53%] [G loss: 2.156109]\n",
      "epoch:19 step:15474 [D loss: 0.538334, acc: 70.31%] [G loss: 2.193398]\n",
      "epoch:19 step:15475 [D loss: 0.363780, acc: 90.62%] [G loss: 3.290678]\n",
      "epoch:19 step:15476 [D loss: 0.470893, acc: 86.72%] [G loss: 2.483579]\n",
      "epoch:19 step:15477 [D loss: 0.714582, acc: 50.78%] [G loss: 2.835758]\n",
      "epoch:19 step:15478 [D loss: 0.699450, acc: 52.34%] [G loss: 2.771504]\n",
      "epoch:19 step:15479 [D loss: 0.436886, acc: 82.03%] [G loss: 3.551640]\n",
      "epoch:19 step:15480 [D loss: 1.273791, acc: 7.03%] [G loss: 2.596519]\n",
      "epoch:19 step:15481 [D loss: 0.461629, acc: 74.22%] [G loss: 3.848174]\n",
      "epoch:19 step:15482 [D loss: 0.498565, acc: 79.69%] [G loss: 2.354057]\n",
      "epoch:19 step:15483 [D loss: 0.385468, acc: 91.41%] [G loss: 2.219502]\n",
      "epoch:19 step:15484 [D loss: 0.449315, acc: 82.03%] [G loss: 3.294555]\n",
      "epoch:19 step:15485 [D loss: 0.573326, acc: 74.22%] [G loss: 2.345023]\n",
      "epoch:19 step:15486 [D loss: 0.425999, acc: 82.03%] [G loss: 2.397431]\n",
      "epoch:19 step:15487 [D loss: 0.513336, acc: 79.69%] [G loss: 1.714015]\n",
      "epoch:19 step:15488 [D loss: 0.613917, acc: 71.88%] [G loss: 3.344082]\n",
      "epoch:19 step:15489 [D loss: 0.644038, acc: 53.12%] [G loss: 3.103866]\n",
      "epoch:19 step:15490 [D loss: 0.720520, acc: 57.81%] [G loss: 3.646931]\n",
      "epoch:19 step:15491 [D loss: 0.540684, acc: 74.22%] [G loss: 2.710863]\n",
      "epoch:19 step:15492 [D loss: 0.432121, acc: 86.72%] [G loss: 2.835123]\n",
      "epoch:19 step:15493 [D loss: 0.558434, acc: 71.88%] [G loss: 3.347399]\n",
      "epoch:19 step:15494 [D loss: 0.199304, acc: 98.44%] [G loss: 4.201855]\n",
      "epoch:19 step:15495 [D loss: 0.907653, acc: 41.41%] [G loss: 3.769678]\n",
      "epoch:19 step:15496 [D loss: 0.346648, acc: 89.06%] [G loss: 3.454859]\n",
      "epoch:19 step:15497 [D loss: 0.420741, acc: 86.72%] [G loss: 3.014032]\n",
      "epoch:19 step:15498 [D loss: 0.378561, acc: 84.38%] [G loss: 3.398832]\n",
      "epoch:19 step:15499 [D loss: 0.460315, acc: 70.31%] [G loss: 2.319644]\n",
      "epoch:19 step:15500 [D loss: 0.138360, acc: 100.00%] [G loss: 2.769751]\n",
      "epoch:19 step:15501 [D loss: 0.474955, acc: 78.91%] [G loss: 2.737072]\n",
      "epoch:19 step:15502 [D loss: 0.243598, acc: 98.44%] [G loss: 3.275407]\n",
      "epoch:19 step:15503 [D loss: 0.463448, acc: 82.81%] [G loss: 3.121973]\n",
      "epoch:19 step:15504 [D loss: 0.329669, acc: 95.31%] [G loss: 1.550760]\n",
      "epoch:19 step:15505 [D loss: 0.447123, acc: 86.72%] [G loss: 4.218058]\n",
      "epoch:19 step:15506 [D loss: 0.217216, acc: 95.31%] [G loss: 4.532344]\n",
      "epoch:19 step:15507 [D loss: 0.567171, acc: 66.41%] [G loss: 3.085087]\n",
      "epoch:19 step:15508 [D loss: 0.879882, acc: 33.59%] [G loss: 2.300885]\n",
      "epoch:19 step:15509 [D loss: 0.558365, acc: 65.62%] [G loss: 2.525581]\n",
      "epoch:19 step:15510 [D loss: 0.279438, acc: 88.28%] [G loss: 3.474681]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:19 step:15511 [D loss: 1.179222, acc: 17.97%] [G loss: 1.941185]\n",
      "epoch:19 step:15512 [D loss: 0.585389, acc: 63.28%] [G loss: 3.845673]\n",
      "epoch:19 step:15513 [D loss: 0.609876, acc: 67.97%] [G loss: 1.694502]\n",
      "epoch:19 step:15514 [D loss: 0.425636, acc: 85.16%] [G loss: 4.230515]\n",
      "epoch:19 step:15515 [D loss: 0.935502, acc: 50.00%] [G loss: 2.091170]\n",
      "epoch:19 step:15516 [D loss: 0.333017, acc: 93.75%] [G loss: 2.402645]\n",
      "epoch:19 step:15517 [D loss: 0.341955, acc: 94.53%] [G loss: 3.731977]\n",
      "epoch:19 step:15518 [D loss: 0.117933, acc: 100.00%] [G loss: 3.061737]\n",
      "epoch:19 step:15519 [D loss: 0.357885, acc: 94.53%] [G loss: 3.060461]\n",
      "epoch:19 step:15520 [D loss: 0.327303, acc: 90.62%] [G loss: 2.409384]\n",
      "epoch:19 step:15521 [D loss: 0.530115, acc: 75.00%] [G loss: 3.953394]\n",
      "epoch:19 step:15522 [D loss: 0.640239, acc: 57.81%] [G loss: 2.834818]\n",
      "epoch:19 step:15523 [D loss: 0.698184, acc: 55.47%] [G loss: 2.629295]\n",
      "epoch:19 step:15524 [D loss: 0.246129, acc: 92.19%] [G loss: 3.293532]\n",
      "epoch:19 step:15525 [D loss: 1.170303, acc: 24.22%] [G loss: 3.141062]\n",
      "epoch:19 step:15526 [D loss: 0.534391, acc: 75.00%] [G loss: 2.426143]\n",
      "epoch:19 step:15527 [D loss: 0.329739, acc: 93.75%] [G loss: 2.546799]\n",
      "epoch:19 step:15528 [D loss: 0.493710, acc: 81.25%] [G loss: 3.012618]\n",
      "epoch:19 step:15529 [D loss: 0.102374, acc: 100.00%] [G loss: 4.712941]\n",
      "epoch:19 step:15530 [D loss: 0.495600, acc: 64.84%] [G loss: 3.208988]\n",
      "epoch:19 step:15531 [D loss: 0.884556, acc: 51.56%] [G loss: 2.149536]\n",
      "epoch:19 step:15532 [D loss: 0.460250, acc: 80.47%] [G loss: 2.097446]\n",
      "epoch:19 step:15533 [D loss: 0.591608, acc: 60.94%] [G loss: 2.963105]\n",
      "epoch:19 step:15534 [D loss: 0.392228, acc: 93.75%] [G loss: 2.905993]\n",
      "epoch:19 step:15535 [D loss: 0.731580, acc: 55.47%] [G loss: 2.713227]\n",
      "epoch:19 step:15536 [D loss: 0.950757, acc: 22.66%] [G loss: 2.805917]\n",
      "epoch:19 step:15537 [D loss: 0.326076, acc: 92.97%] [G loss: 2.375800]\n",
      "epoch:19 step:15538 [D loss: 0.769332, acc: 47.66%] [G loss: 3.054183]\n",
      "epoch:19 step:15539 [D loss: 0.468302, acc: 65.62%] [G loss: 3.478462]\n",
      "epoch:19 step:15540 [D loss: 0.782625, acc: 51.56%] [G loss: 2.561473]\n",
      "epoch:19 step:15541 [D loss: 0.446138, acc: 82.81%] [G loss: 3.354831]\n",
      "epoch:19 step:15542 [D loss: 0.861513, acc: 39.06%] [G loss: 4.075491]\n",
      "epoch:19 step:15543 [D loss: 0.314410, acc: 90.62%] [G loss: 2.942588]\n",
      "epoch:19 step:15544 [D loss: 0.364813, acc: 87.50%] [G loss: 2.729428]\n",
      "epoch:19 step:15545 [D loss: 0.256983, acc: 96.88%] [G loss: 3.625936]\n",
      "epoch:19 step:15546 [D loss: 0.583338, acc: 66.41%] [G loss: 2.560803]\n",
      "epoch:19 step:15547 [D loss: 0.266568, acc: 100.00%] [G loss: 3.567779]\n",
      "epoch:19 step:15548 [D loss: 0.491617, acc: 79.69%] [G loss: 1.608690]\n",
      "epoch:19 step:15549 [D loss: 0.301126, acc: 96.88%] [G loss: 3.123987]\n",
      "epoch:19 step:15550 [D loss: 0.277697, acc: 97.66%] [G loss: 4.016850]\n",
      "epoch:19 step:15551 [D loss: 1.448472, acc: 12.50%] [G loss: 2.280364]\n",
      "epoch:19 step:15552 [D loss: 0.275581, acc: 96.09%] [G loss: 3.371373]\n",
      "epoch:19 step:15553 [D loss: 0.386621, acc: 83.59%] [G loss: 1.617959]\n",
      "epoch:19 step:15554 [D loss: 0.156979, acc: 100.00%] [G loss: 3.838210]\n",
      "epoch:19 step:15555 [D loss: 0.211975, acc: 97.66%] [G loss: 3.172426]\n",
      "epoch:19 step:15556 [D loss: 0.542197, acc: 65.62%] [G loss: 3.433141]\n",
      "epoch:19 step:15557 [D loss: 0.202774, acc: 99.22%] [G loss: 3.615533]\n",
      "epoch:19 step:15558 [D loss: 0.844594, acc: 35.16%] [G loss: 3.445605]\n",
      "epoch:19 step:15559 [D loss: 0.387121, acc: 92.97%] [G loss: 3.521426]\n",
      "epoch:19 step:15560 [D loss: 0.269940, acc: 98.44%] [G loss: 2.593450]\n",
      "epoch:19 step:15561 [D loss: 0.292263, acc: 95.31%] [G loss: 2.408457]\n",
      "epoch:19 step:15562 [D loss: 0.200378, acc: 100.00%] [G loss: 3.159730]\n",
      "epoch:19 step:15563 [D loss: 1.297225, acc: 4.69%] [G loss: 2.302638]\n",
      "epoch:19 step:15564 [D loss: 0.956999, acc: 51.56%] [G loss: 2.291502]\n",
      "epoch:19 step:15565 [D loss: 0.219639, acc: 96.09%] [G loss: 3.904496]\n",
      "epoch:19 step:15566 [D loss: 0.611018, acc: 68.75%] [G loss: 3.450148]\n",
      "epoch:19 step:15567 [D loss: 0.408600, acc: 88.28%] [G loss: 3.294153]\n",
      "epoch:19 step:15568 [D loss: 0.325593, acc: 94.53%] [G loss: 3.349402]\n",
      "epoch:19 step:15569 [D loss: 0.315070, acc: 94.53%] [G loss: 2.636966]\n",
      "epoch:19 step:15570 [D loss: 0.667705, acc: 64.84%] [G loss: 3.447452]\n",
      "epoch:19 step:15571 [D loss: 0.520170, acc: 70.31%] [G loss: 2.546665]\n",
      "epoch:19 step:15572 [D loss: 0.731693, acc: 53.12%] [G loss: 2.366298]\n",
      "epoch:19 step:15573 [D loss: 0.778757, acc: 52.34%] [G loss: 4.482469]\n",
      "epoch:19 step:15574 [D loss: 0.354987, acc: 89.06%] [G loss: 3.494959]\n",
      "epoch:19 step:15575 [D loss: 0.218722, acc: 95.31%] [G loss: 5.261721]\n",
      "epoch:19 step:15576 [D loss: 0.779105, acc: 53.12%] [G loss: 3.018268]\n",
      "epoch:19 step:15577 [D loss: 0.468966, acc: 84.38%] [G loss: 3.176887]\n",
      "epoch:19 step:15578 [D loss: 0.172138, acc: 99.22%] [G loss: 2.830321]\n",
      "epoch:19 step:15579 [D loss: 0.510361, acc: 69.53%] [G loss: 3.934922]\n",
      "epoch:19 step:15580 [D loss: 0.335442, acc: 88.28%] [G loss: 3.638223]\n",
      "epoch:19 step:15581 [D loss: 0.582532, acc: 61.72%] [G loss: 2.582976]\n",
      "epoch:19 step:15582 [D loss: 0.309262, acc: 89.06%] [G loss: 3.013876]\n",
      "epoch:19 step:15583 [D loss: 0.984006, acc: 28.91%] [G loss: 2.284028]\n",
      "epoch:19 step:15584 [D loss: 0.555492, acc: 67.97%] [G loss: 2.760382]\n",
      "epoch:19 step:15585 [D loss: 0.710527, acc: 53.12%] [G loss: 1.922594]\n",
      "epoch:19 step:15586 [D loss: 0.869757, acc: 47.66%] [G loss: 2.553957]\n",
      "epoch:19 step:15587 [D loss: 0.951433, acc: 50.00%] [G loss: 2.966331]\n",
      "epoch:19 step:15588 [D loss: 0.442270, acc: 85.94%] [G loss: 3.894837]\n",
      "epoch:19 step:15589 [D loss: 0.938937, acc: 50.00%] [G loss: 2.653409]\n",
      "epoch:19 step:15590 [D loss: 0.679804, acc: 59.38%] [G loss: 3.077505]\n",
      "epoch:19 step:15591 [D loss: 0.273020, acc: 96.88%] [G loss: 1.855028]\n",
      "epoch:19 step:15592 [D loss: 0.156026, acc: 99.22%] [G loss: 3.959440]\n",
      "epoch:19 step:15593 [D loss: 0.778180, acc: 51.56%] [G loss: 2.492427]\n",
      "epoch:19 step:15594 [D loss: 0.504937, acc: 71.88%] [G loss: 2.291540]\n",
      "epoch:19 step:15595 [D loss: 0.333711, acc: 95.31%] [G loss: 4.205278]\n",
      "epoch:19 step:15596 [D loss: 0.900124, acc: 38.28%] [G loss: 3.276084]\n",
      "epoch:19 step:15597 [D loss: 0.336532, acc: 87.50%] [G loss: 2.301543]\n",
      "epoch:19 step:15598 [D loss: 1.007609, acc: 17.97%] [G loss: 2.903673]\n",
      "epoch:19 step:15599 [D loss: 0.222141, acc: 95.31%] [G loss: 4.540192]\n",
      "epoch:19 step:15600 [D loss: 0.513861, acc: 75.78%] [G loss: 4.071060]\n",
      "##############\n",
      "[0.85009145 0.85747402 0.80251169 0.80004188 0.81145807 0.82127803\n",
      " 0.90016063 0.80533561 0.82791568 0.82821587]\n",
      "##########\n",
      "epoch:19 step:15601 [D loss: 0.480339, acc: 63.28%] [G loss: 4.594370]\n",
      "epoch:19 step:15602 [D loss: 0.428239, acc: 88.28%] [G loss: 3.828227]\n",
      "epoch:19 step:15603 [D loss: 0.715785, acc: 53.12%] [G loss: 2.402840]\n",
      "epoch:19 step:15604 [D loss: 0.544361, acc: 56.25%] [G loss: 3.381106]\n",
      "epoch:19 step:15605 [D loss: 0.254156, acc: 98.44%] [G loss: 3.267011]\n",
      "epoch:19 step:15606 [D loss: 0.510634, acc: 71.88%] [G loss: 3.276968]\n",
      "epoch:19 step:15607 [D loss: 0.629623, acc: 61.72%] [G loss: 2.614893]\n",
      "epoch:19 step:15608 [D loss: 1.081425, acc: 11.72%] [G loss: 3.084858]\n",
      "epoch:19 step:15609 [D loss: 0.635126, acc: 67.97%] [G loss: 2.956489]\n",
      "epoch:19 step:15610 [D loss: 0.628409, acc: 54.69%] [G loss: 5.005612]\n",
      "epoch:19 step:15611 [D loss: 0.138385, acc: 100.00%] [G loss: 3.502447]\n",
      "epoch:19 step:15612 [D loss: 0.591905, acc: 53.91%] [G loss: 3.141666]\n",
      "epoch:19 step:15613 [D loss: 0.420237, acc: 87.50%] [G loss: 2.470268]\n",
      "epoch:19 step:15614 [D loss: 0.522140, acc: 75.78%] [G loss: 3.065758]\n",
      "epoch:19 step:15615 [D loss: 0.295542, acc: 91.41%] [G loss: 3.582221]\n",
      "epoch:19 step:15616 [D loss: 0.559210, acc: 67.19%] [G loss: 2.731182]\n",
      "epoch:19 step:15617 [D loss: 0.492502, acc: 80.47%] [G loss: 3.568723]\n",
      "epoch:19 step:15618 [D loss: 0.597645, acc: 67.19%] [G loss: 3.043040]\n",
      "epoch:19 step:15619 [D loss: 0.534296, acc: 71.88%] [G loss: 1.686069]\n",
      "epoch:19 step:15620 [D loss: 0.562919, acc: 70.31%] [G loss: 3.083306]\n",
      "epoch:20 step:15621 [D loss: 0.303081, acc: 92.97%] [G loss: 2.559789]\n",
      "epoch:20 step:15622 [D loss: 0.369960, acc: 86.72%] [G loss: 2.717148]\n",
      "epoch:20 step:15623 [D loss: 0.429932, acc: 72.66%] [G loss: 2.653365]\n",
      "epoch:20 step:15624 [D loss: 0.405835, acc: 84.38%] [G loss: 3.182622]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:20 step:15625 [D loss: 0.462331, acc: 77.34%] [G loss: 2.793877]\n",
      "epoch:20 step:15626 [D loss: 0.747480, acc: 50.78%] [G loss: 2.998547]\n",
      "epoch:20 step:15627 [D loss: 0.304964, acc: 86.72%] [G loss: 2.563455]\n",
      "epoch:20 step:15628 [D loss: 0.287808, acc: 94.53%] [G loss: 3.094332]\n",
      "epoch:20 step:15629 [D loss: 0.322760, acc: 91.41%] [G loss: 2.897664]\n",
      "epoch:20 step:15630 [D loss: 0.300794, acc: 94.53%] [G loss: 2.227732]\n",
      "epoch:20 step:15631 [D loss: 0.485521, acc: 82.03%] [G loss: 3.181630]\n",
      "epoch:20 step:15632 [D loss: 0.630847, acc: 64.06%] [G loss: 3.231012]\n",
      "epoch:20 step:15633 [D loss: 0.124846, acc: 100.00%] [G loss: 5.070451]\n",
      "epoch:20 step:15634 [D loss: 0.574801, acc: 75.78%] [G loss: 3.388221]\n",
      "epoch:20 step:15635 [D loss: 0.810559, acc: 47.66%] [G loss: 2.628690]\n",
      "epoch:20 step:15636 [D loss: 0.478646, acc: 85.16%] [G loss: 2.882877]\n",
      "epoch:20 step:15637 [D loss: 0.178673, acc: 98.44%] [G loss: 4.373747]\n",
      "epoch:20 step:15638 [D loss: 0.201465, acc: 98.44%] [G loss: 3.626900]\n",
      "epoch:20 step:15639 [D loss: 0.375946, acc: 77.34%] [G loss: 2.575390]\n",
      "epoch:20 step:15640 [D loss: 0.429130, acc: 86.72%] [G loss: 2.973641]\n",
      "epoch:20 step:15641 [D loss: 0.291564, acc: 95.31%] [G loss: 3.413391]\n",
      "epoch:20 step:15642 [D loss: 0.709774, acc: 53.91%] [G loss: 1.686084]\n",
      "epoch:20 step:15643 [D loss: 0.247246, acc: 95.31%] [G loss: 3.340049]\n",
      "epoch:20 step:15644 [D loss: 0.838248, acc: 35.16%] [G loss: 2.735836]\n",
      "epoch:20 step:15645 [D loss: 0.462781, acc: 82.03%] [G loss: 2.379910]\n",
      "epoch:20 step:15646 [D loss: 0.148809, acc: 98.44%] [G loss: 3.989112]\n",
      "epoch:20 step:15647 [D loss: 0.798649, acc: 50.78%] [G loss: 2.647293]\n",
      "epoch:20 step:15648 [D loss: 0.273407, acc: 96.88%] [G loss: 2.833717]\n",
      "epoch:20 step:15649 [D loss: 0.239468, acc: 98.44%] [G loss: 2.761718]\n",
      "epoch:20 step:15650 [D loss: 0.621435, acc: 70.31%] [G loss: 3.090368]\n",
      "epoch:20 step:15651 [D loss: 0.461658, acc: 86.72%] [G loss: 3.401141]\n",
      "epoch:20 step:15652 [D loss: 0.165962, acc: 99.22%] [G loss: 2.312197]\n",
      "epoch:20 step:15653 [D loss: 0.315801, acc: 89.06%] [G loss: 3.235587]\n",
      "epoch:20 step:15654 [D loss: 0.688512, acc: 53.91%] [G loss: 2.905051]\n",
      "epoch:20 step:15655 [D loss: 0.402596, acc: 81.25%] [G loss: 2.968075]\n",
      "epoch:20 step:15656 [D loss: 0.349923, acc: 83.59%] [G loss: 4.944784]\n",
      "epoch:20 step:15657 [D loss: 0.534841, acc: 72.66%] [G loss: 4.207824]\n",
      "epoch:20 step:15658 [D loss: 0.508682, acc: 75.00%] [G loss: 3.279064]\n",
      "epoch:20 step:15659 [D loss: 0.290580, acc: 92.97%] [G loss: 3.474728]\n",
      "epoch:20 step:15660 [D loss: 0.477838, acc: 84.38%] [G loss: 2.758414]\n",
      "epoch:20 step:15661 [D loss: 0.301638, acc: 93.75%] [G loss: 3.870539]\n",
      "epoch:20 step:15662 [D loss: 0.726746, acc: 53.12%] [G loss: 3.602952]\n",
      "epoch:20 step:15663 [D loss: 0.484540, acc: 82.03%] [G loss: 2.540799]\n",
      "epoch:20 step:15664 [D loss: 0.373307, acc: 93.75%] [G loss: 2.779862]\n",
      "epoch:20 step:15665 [D loss: 0.509136, acc: 80.47%] [G loss: 3.139561]\n",
      "epoch:20 step:15666 [D loss: 0.558091, acc: 71.09%] [G loss: 1.593840]\n",
      "epoch:20 step:15667 [D loss: 0.828699, acc: 38.28%] [G loss: 2.495574]\n",
      "epoch:20 step:15668 [D loss: 0.412748, acc: 89.84%] [G loss: 2.030548]\n",
      "epoch:20 step:15669 [D loss: 0.878965, acc: 49.22%] [G loss: 2.569175]\n",
      "epoch:20 step:15670 [D loss: 0.203926, acc: 99.22%] [G loss: 3.053646]\n",
      "epoch:20 step:15671 [D loss: 0.688897, acc: 54.69%] [G loss: 3.019914]\n",
      "epoch:20 step:15672 [D loss: 0.133129, acc: 98.44%] [G loss: 3.629578]\n",
      "epoch:20 step:15673 [D loss: 0.702518, acc: 56.25%] [G loss: 2.917600]\n",
      "epoch:20 step:15674 [D loss: 0.406843, acc: 86.72%] [G loss: 3.219661]\n",
      "epoch:20 step:15675 [D loss: 0.805109, acc: 53.91%] [G loss: 3.370262]\n",
      "epoch:20 step:15676 [D loss: 0.791440, acc: 51.56%] [G loss: 1.955929]\n",
      "epoch:20 step:15677 [D loss: 0.427680, acc: 83.59%] [G loss: 2.852816]\n",
      "epoch:20 step:15678 [D loss: 0.368382, acc: 89.84%] [G loss: 2.544934]\n",
      "epoch:20 step:15679 [D loss: 0.430036, acc: 79.69%] [G loss: 2.693836]\n",
      "epoch:20 step:15680 [D loss: 0.250369, acc: 92.97%] [G loss: 2.950844]\n",
      "epoch:20 step:15681 [D loss: 0.442385, acc: 84.38%] [G loss: 3.001813]\n",
      "epoch:20 step:15682 [D loss: 0.443363, acc: 79.69%] [G loss: 2.132982]\n",
      "epoch:20 step:15683 [D loss: 0.277170, acc: 92.97%] [G loss: 3.169971]\n",
      "epoch:20 step:15684 [D loss: 0.272035, acc: 95.31%] [G loss: 3.957269]\n",
      "epoch:20 step:15685 [D loss: 0.606972, acc: 60.94%] [G loss: 2.807187]\n",
      "epoch:20 step:15686 [D loss: 0.502837, acc: 62.50%] [G loss: 2.727828]\n",
      "epoch:20 step:15687 [D loss: 1.250211, acc: 17.97%] [G loss: 2.538623]\n",
      "epoch:20 step:15688 [D loss: 0.375565, acc: 92.97%] [G loss: 1.697709]\n",
      "epoch:20 step:15689 [D loss: 0.391992, acc: 88.28%] [G loss: 2.936697]\n",
      "epoch:20 step:15690 [D loss: 0.519231, acc: 77.34%] [G loss: 2.878081]\n",
      "epoch:20 step:15691 [D loss: 0.545457, acc: 70.31%] [G loss: 3.620523]\n",
      "epoch:20 step:15692 [D loss: 0.723615, acc: 53.12%] [G loss: 2.826280]\n",
      "epoch:20 step:15693 [D loss: 0.256485, acc: 91.41%] [G loss: 4.317659]\n",
      "epoch:20 step:15694 [D loss: 0.507090, acc: 78.91%] [G loss: 4.186448]\n",
      "epoch:20 step:15695 [D loss: 0.553007, acc: 71.09%] [G loss: 2.671797]\n",
      "epoch:20 step:15696 [D loss: 0.322702, acc: 96.09%] [G loss: 2.611003]\n",
      "epoch:20 step:15697 [D loss: 0.483397, acc: 67.19%] [G loss: 2.506068]\n",
      "epoch:20 step:15698 [D loss: 0.453011, acc: 86.72%] [G loss: 3.880607]\n",
      "epoch:20 step:15699 [D loss: 0.254956, acc: 98.44%] [G loss: 2.544809]\n",
      "epoch:20 step:15700 [D loss: 0.109281, acc: 99.22%] [G loss: 3.472412]\n",
      "epoch:20 step:15701 [D loss: 0.307596, acc: 94.53%] [G loss: 3.220953]\n",
      "epoch:20 step:15702 [D loss: 0.373325, acc: 82.81%] [G loss: 3.089726]\n",
      "epoch:20 step:15703 [D loss: 1.048812, acc: 50.00%] [G loss: 1.612774]\n",
      "epoch:20 step:15704 [D loss: 0.290640, acc: 89.84%] [G loss: 3.937183]\n",
      "epoch:20 step:15705 [D loss: 0.382768, acc: 81.25%] [G loss: 3.140770]\n",
      "epoch:20 step:15706 [D loss: 0.292217, acc: 85.94%] [G loss: 3.984521]\n",
      "epoch:20 step:15707 [D loss: 0.938611, acc: 32.81%] [G loss: 2.502329]\n",
      "epoch:20 step:15708 [D loss: 0.868445, acc: 49.22%] [G loss: 3.262126]\n",
      "epoch:20 step:15709 [D loss: 0.148940, acc: 99.22%] [G loss: 2.878450]\n",
      "epoch:20 step:15710 [D loss: 1.204104, acc: 16.41%] [G loss: 2.338218]\n",
      "epoch:20 step:15711 [D loss: 0.125387, acc: 96.88%] [G loss: 3.658587]\n",
      "epoch:20 step:15712 [D loss: 0.308682, acc: 99.22%] [G loss: 3.523934]\n",
      "epoch:20 step:15713 [D loss: 0.531279, acc: 74.22%] [G loss: 2.270297]\n",
      "epoch:20 step:15714 [D loss: 0.733718, acc: 53.91%] [G loss: 3.379674]\n",
      "epoch:20 step:15715 [D loss: 0.480959, acc: 83.59%] [G loss: 3.519958]\n",
      "epoch:20 step:15716 [D loss: 0.218729, acc: 97.66%] [G loss: 2.727329]\n",
      "epoch:20 step:15717 [D loss: 0.466033, acc: 71.88%] [G loss: 4.391480]\n",
      "epoch:20 step:15718 [D loss: 0.727508, acc: 52.34%] [G loss: 3.367863]\n",
      "epoch:20 step:15719 [D loss: 0.240697, acc: 95.31%] [G loss: 3.697498]\n",
      "epoch:20 step:15720 [D loss: 0.281400, acc: 95.31%] [G loss: 1.999253]\n",
      "epoch:20 step:15721 [D loss: 0.558804, acc: 53.91%] [G loss: 4.481573]\n",
      "epoch:20 step:15722 [D loss: 0.934885, acc: 49.22%] [G loss: 2.937135]\n",
      "epoch:20 step:15723 [D loss: 0.397753, acc: 92.97%] [G loss: 2.947111]\n",
      "epoch:20 step:15724 [D loss: 0.703162, acc: 57.03%] [G loss: 3.165012]\n",
      "epoch:20 step:15725 [D loss: 0.292649, acc: 96.88%] [G loss: 3.294419]\n",
      "epoch:20 step:15726 [D loss: 0.604867, acc: 65.62%] [G loss: 2.941907]\n",
      "epoch:20 step:15727 [D loss: 0.413293, acc: 71.09%] [G loss: 3.667801]\n",
      "epoch:20 step:15728 [D loss: 0.208343, acc: 99.22%] [G loss: 2.626795]\n",
      "epoch:20 step:15729 [D loss: 0.550642, acc: 71.88%] [G loss: 2.703915]\n",
      "epoch:20 step:15730 [D loss: 0.152885, acc: 100.00%] [G loss: 3.126699]\n",
      "epoch:20 step:15731 [D loss: 0.468412, acc: 83.59%] [G loss: 3.973121]\n",
      "epoch:20 step:15732 [D loss: 0.763276, acc: 56.25%] [G loss: 2.805406]\n",
      "epoch:20 step:15733 [D loss: 0.482893, acc: 84.38%] [G loss: 2.841483]\n",
      "epoch:20 step:15734 [D loss: 0.990474, acc: 27.34%] [G loss: 3.492357]\n",
      "epoch:20 step:15735 [D loss: 1.403649, acc: 15.62%] [G loss: 2.565033]\n",
      "epoch:20 step:15736 [D loss: 0.447893, acc: 84.38%] [G loss: 3.943627]\n",
      "epoch:20 step:15737 [D loss: 0.521439, acc: 76.56%] [G loss: 3.266601]\n",
      "epoch:20 step:15738 [D loss: 0.210105, acc: 100.00%] [G loss: 3.556403]\n",
      "epoch:20 step:15739 [D loss: 0.536631, acc: 81.25%] [G loss: 2.877534]\n",
      "epoch:20 step:15740 [D loss: 0.506616, acc: 81.25%] [G loss: 5.773727]\n",
      "epoch:20 step:15741 [D loss: 0.742923, acc: 51.56%] [G loss: 2.153380]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:20 step:15742 [D loss: 0.294910, acc: 96.09%] [G loss: 3.505835]\n",
      "epoch:20 step:15743 [D loss: 0.254738, acc: 96.88%] [G loss: 3.410632]\n",
      "epoch:20 step:15744 [D loss: 0.961058, acc: 50.00%] [G loss: 3.585236]\n",
      "epoch:20 step:15745 [D loss: 0.920548, acc: 52.34%] [G loss: 2.332123]\n",
      "epoch:20 step:15746 [D loss: 0.634603, acc: 66.41%] [G loss: 1.909730]\n",
      "epoch:20 step:15747 [D loss: 0.656659, acc: 59.38%] [G loss: 2.469086]\n",
      "epoch:20 step:15748 [D loss: 0.352118, acc: 80.47%] [G loss: 3.222252]\n",
      "epoch:20 step:15749 [D loss: 0.261100, acc: 93.75%] [G loss: 4.432314]\n",
      "epoch:20 step:15750 [D loss: 0.638494, acc: 60.16%] [G loss: 2.471867]\n",
      "epoch:20 step:15751 [D loss: 0.482038, acc: 71.09%] [G loss: 2.906943]\n",
      "epoch:20 step:15752 [D loss: 0.680358, acc: 53.91%] [G loss: 1.500339]\n",
      "epoch:20 step:15753 [D loss: 0.851242, acc: 39.84%] [G loss: 2.287892]\n",
      "epoch:20 step:15754 [D loss: 0.597244, acc: 67.19%] [G loss: 3.450789]\n",
      "epoch:20 step:15755 [D loss: 0.394650, acc: 91.41%] [G loss: 2.596520]\n",
      "epoch:20 step:15756 [D loss: 0.531626, acc: 75.78%] [G loss: 2.399671]\n",
      "epoch:20 step:15757 [D loss: 0.620673, acc: 71.09%] [G loss: 2.984168]\n",
      "epoch:20 step:15758 [D loss: 0.304804, acc: 92.97%] [G loss: 2.996821]\n",
      "epoch:20 step:15759 [D loss: 0.193031, acc: 98.44%] [G loss: 3.036176]\n",
      "epoch:20 step:15760 [D loss: 0.501690, acc: 73.44%] [G loss: 3.098098]\n",
      "epoch:20 step:15761 [D loss: 0.200678, acc: 96.09%] [G loss: 2.557883]\n",
      "epoch:20 step:15762 [D loss: 0.706378, acc: 53.91%] [G loss: 3.886336]\n",
      "epoch:20 step:15763 [D loss: 0.387705, acc: 89.84%] [G loss: 2.846236]\n",
      "epoch:20 step:15764 [D loss: 0.805854, acc: 50.00%] [G loss: 2.259965]\n",
      "epoch:20 step:15765 [D loss: 0.308447, acc: 97.66%] [G loss: 2.576494]\n",
      "epoch:20 step:15766 [D loss: 0.789237, acc: 50.00%] [G loss: 2.599850]\n",
      "epoch:20 step:15767 [D loss: 0.714000, acc: 53.91%] [G loss: 2.644522]\n",
      "epoch:20 step:15768 [D loss: 0.376211, acc: 92.97%] [G loss: 2.985687]\n",
      "epoch:20 step:15769 [D loss: 1.018538, acc: 51.56%] [G loss: 2.748204]\n",
      "epoch:20 step:15770 [D loss: 0.264181, acc: 94.53%] [G loss: 3.070177]\n",
      "epoch:20 step:15771 [D loss: 0.161615, acc: 98.44%] [G loss: 3.648134]\n",
      "epoch:20 step:15772 [D loss: 0.259540, acc: 93.75%] [G loss: 3.449066]\n",
      "epoch:20 step:15773 [D loss: 0.408191, acc: 73.44%] [G loss: 2.896681]\n",
      "epoch:20 step:15774 [D loss: 0.342539, acc: 94.53%] [G loss: 3.034140]\n",
      "epoch:20 step:15775 [D loss: 0.609184, acc: 72.66%] [G loss: 2.318392]\n",
      "epoch:20 step:15776 [D loss: 0.355844, acc: 93.75%] [G loss: 1.651817]\n",
      "epoch:20 step:15777 [D loss: 0.620890, acc: 67.19%] [G loss: 2.537345]\n",
      "epoch:20 step:15778 [D loss: 0.362152, acc: 90.62%] [G loss: 3.256878]\n",
      "epoch:20 step:15779 [D loss: 0.551679, acc: 75.78%] [G loss: 2.800636]\n",
      "epoch:20 step:15780 [D loss: 0.671400, acc: 58.59%] [G loss: 3.076472]\n",
      "epoch:20 step:15781 [D loss: 0.532320, acc: 78.12%] [G loss: 4.398028]\n",
      "epoch:20 step:15782 [D loss: 0.135369, acc: 99.22%] [G loss: 3.224447]\n",
      "epoch:20 step:15783 [D loss: 1.021619, acc: 29.69%] [G loss: 3.301966]\n",
      "epoch:20 step:15784 [D loss: 0.110224, acc: 100.00%] [G loss: 4.901222]\n",
      "epoch:20 step:15785 [D loss: 0.452162, acc: 66.41%] [G loss: 3.957561]\n",
      "epoch:20 step:15786 [D loss: 0.541173, acc: 64.84%] [G loss: 2.775554]\n",
      "epoch:20 step:15787 [D loss: 0.382311, acc: 93.75%] [G loss: 2.230198]\n",
      "epoch:20 step:15788 [D loss: 0.375038, acc: 89.84%] [G loss: 2.558996]\n",
      "epoch:20 step:15789 [D loss: 0.407043, acc: 85.94%] [G loss: 3.542402]\n",
      "epoch:20 step:15790 [D loss: 0.653061, acc: 64.84%] [G loss: 2.470145]\n",
      "epoch:20 step:15791 [D loss: 0.244888, acc: 98.44%] [G loss: 2.382305]\n",
      "epoch:20 step:15792 [D loss: 0.912966, acc: 32.03%] [G loss: 3.259840]\n",
      "epoch:20 step:15793 [D loss: 0.552850, acc: 78.12%] [G loss: 2.920293]\n",
      "epoch:20 step:15794 [D loss: 0.184685, acc: 97.66%] [G loss: 5.574543]\n",
      "epoch:20 step:15795 [D loss: 0.599713, acc: 61.72%] [G loss: 3.008728]\n",
      "epoch:20 step:15796 [D loss: 0.864926, acc: 50.00%] [G loss: 4.007964]\n",
      "epoch:20 step:15797 [D loss: 0.394025, acc: 82.03%] [G loss: 3.112337]\n",
      "epoch:20 step:15798 [D loss: 0.248337, acc: 97.66%] [G loss: 2.226581]\n",
      "epoch:20 step:15799 [D loss: 0.233316, acc: 96.09%] [G loss: 2.995359]\n",
      "epoch:20 step:15800 [D loss: 0.280876, acc: 96.88%] [G loss: 2.804034]\n",
      "##############\n",
      "[0.8749131  0.8665063  0.81927644 0.81918616 0.81089069 0.83495076\n",
      " 0.91626802 0.82065759 0.81984277 0.86742185]\n",
      "##########\n",
      "epoch:20 step:15801 [D loss: 0.407693, acc: 85.94%] [G loss: 2.550902]\n",
      "epoch:20 step:15802 [D loss: 0.525644, acc: 80.47%] [G loss: 2.632520]\n",
      "epoch:20 step:15803 [D loss: 0.075052, acc: 100.00%] [G loss: 3.573764]\n",
      "epoch:20 step:15804 [D loss: 0.646025, acc: 65.62%] [G loss: 3.265608]\n",
      "epoch:20 step:15805 [D loss: 0.260123, acc: 91.41%] [G loss: 3.581919]\n",
      "epoch:20 step:15806 [D loss: 0.852074, acc: 50.78%] [G loss: 2.944367]\n",
      "epoch:20 step:15807 [D loss: 0.293883, acc: 96.09%] [G loss: 2.349387]\n",
      "epoch:20 step:15808 [D loss: 0.579832, acc: 70.31%] [G loss: 2.166877]\n",
      "epoch:20 step:15809 [D loss: 0.149070, acc: 99.22%] [G loss: 3.425959]\n",
      "epoch:20 step:15810 [D loss: 0.632940, acc: 59.38%] [G loss: 2.031440]\n",
      "epoch:20 step:15811 [D loss: 0.397357, acc: 81.25%] [G loss: 2.202930]\n",
      "epoch:20 step:15812 [D loss: 0.416352, acc: 82.81%] [G loss: 3.408516]\n",
      "epoch:20 step:15813 [D loss: 0.224810, acc: 97.66%] [G loss: 3.241575]\n",
      "epoch:20 step:15814 [D loss: 0.837834, acc: 48.44%] [G loss: 2.889711]\n",
      "epoch:20 step:15815 [D loss: 0.426813, acc: 85.16%] [G loss: 1.532595]\n",
      "epoch:20 step:15816 [D loss: 0.254585, acc: 96.09%] [G loss: 2.983889]\n",
      "epoch:20 step:15817 [D loss: 1.174910, acc: 35.94%] [G loss: 2.247094]\n",
      "epoch:20 step:15818 [D loss: 0.946476, acc: 42.19%] [G loss: 2.477833]\n",
      "epoch:20 step:15819 [D loss: 0.213176, acc: 98.44%] [G loss: 3.577481]\n",
      "epoch:20 step:15820 [D loss: 0.639220, acc: 54.69%] [G loss: 2.676812]\n",
      "epoch:20 step:15821 [D loss: 0.185942, acc: 99.22%] [G loss: 2.344734]\n",
      "epoch:20 step:15822 [D loss: 0.513656, acc: 78.91%] [G loss: 2.800364]\n",
      "epoch:20 step:15823 [D loss: 0.604737, acc: 68.75%] [G loss: 1.631317]\n",
      "epoch:20 step:15824 [D loss: 0.304750, acc: 92.97%] [G loss: 2.649531]\n",
      "epoch:20 step:15825 [D loss: 0.611764, acc: 65.62%] [G loss: 2.351787]\n",
      "epoch:20 step:15826 [D loss: 0.549771, acc: 74.22%] [G loss: 2.007403]\n",
      "epoch:20 step:15827 [D loss: 0.679143, acc: 57.03%] [G loss: 2.760808]\n",
      "epoch:20 step:15828 [D loss: 0.333986, acc: 94.53%] [G loss: 3.628496]\n",
      "epoch:20 step:15829 [D loss: 0.699301, acc: 57.81%] [G loss: 2.111372]\n",
      "epoch:20 step:15830 [D loss: 0.473745, acc: 82.03%] [G loss: 1.474133]\n",
      "epoch:20 step:15831 [D loss: 0.081931, acc: 99.22%] [G loss: 3.741153]\n",
      "epoch:20 step:15832 [D loss: 0.297755, acc: 96.09%] [G loss: 3.319818]\n",
      "epoch:20 step:15833 [D loss: 1.241983, acc: 12.50%] [G loss: 2.467103]\n",
      "epoch:20 step:15834 [D loss: 0.439152, acc: 71.88%] [G loss: 3.433126]\n",
      "epoch:20 step:15835 [D loss: 0.636214, acc: 67.19%] [G loss: 2.941036]\n",
      "epoch:20 step:15836 [D loss: 1.082566, acc: 42.97%] [G loss: 2.827272]\n",
      "epoch:20 step:15837 [D loss: 0.401553, acc: 83.59%] [G loss: 3.416835]\n",
      "epoch:20 step:15838 [D loss: 0.463676, acc: 75.78%] [G loss: 3.565375]\n",
      "epoch:20 step:15839 [D loss: 0.247779, acc: 98.44%] [G loss: 2.614042]\n",
      "epoch:20 step:15840 [D loss: 0.374167, acc: 94.53%] [G loss: 3.983897]\n",
      "epoch:20 step:15841 [D loss: 0.623811, acc: 60.16%] [G loss: 2.921124]\n",
      "epoch:20 step:15842 [D loss: 0.726166, acc: 51.56%] [G loss: 3.202344]\n",
      "epoch:20 step:15843 [D loss: 0.360580, acc: 92.97%] [G loss: 2.625925]\n",
      "epoch:20 step:15844 [D loss: 0.718791, acc: 53.91%] [G loss: 2.859163]\n",
      "epoch:20 step:15845 [D loss: 0.944937, acc: 48.44%] [G loss: 2.486984]\n",
      "epoch:20 step:15846 [D loss: 0.583582, acc: 60.16%] [G loss: 2.626292]\n",
      "epoch:20 step:15847 [D loss: 0.365788, acc: 87.50%] [G loss: 3.676602]\n",
      "epoch:20 step:15848 [D loss: 0.341862, acc: 93.75%] [G loss: 2.694086]\n",
      "epoch:20 step:15849 [D loss: 0.250795, acc: 95.31%] [G loss: 3.966392]\n",
      "epoch:20 step:15850 [D loss: 0.399484, acc: 77.34%] [G loss: 3.557107]\n",
      "epoch:20 step:15851 [D loss: 0.607413, acc: 57.81%] [G loss: 2.565003]\n",
      "epoch:20 step:15852 [D loss: 0.302722, acc: 82.03%] [G loss: 3.549770]\n",
      "epoch:20 step:15853 [D loss: 0.385064, acc: 82.03%] [G loss: 3.657398]\n",
      "epoch:20 step:15854 [D loss: 0.463604, acc: 86.72%] [G loss: 5.213860]\n",
      "epoch:20 step:15855 [D loss: 1.029109, acc: 21.09%] [G loss: 2.878809]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:20 step:15856 [D loss: 1.183960, acc: 36.72%] [G loss: 3.510360]\n",
      "epoch:20 step:15857 [D loss: 0.392888, acc: 79.69%] [G loss: 2.954664]\n",
      "epoch:20 step:15858 [D loss: 0.844923, acc: 42.19%] [G loss: 2.584151]\n",
      "epoch:20 step:15859 [D loss: 0.790357, acc: 53.91%] [G loss: 2.740743]\n",
      "epoch:20 step:15860 [D loss: 0.286431, acc: 89.06%] [G loss: 2.722250]\n",
      "epoch:20 step:15861 [D loss: 0.404499, acc: 86.72%] [G loss: 2.663999]\n",
      "epoch:20 step:15862 [D loss: 0.522625, acc: 74.22%] [G loss: 3.318621]\n",
      "epoch:20 step:15863 [D loss: 0.760631, acc: 42.97%] [G loss: 3.885970]\n",
      "epoch:20 step:15864 [D loss: 0.333094, acc: 91.41%] [G loss: 3.339736]\n",
      "epoch:20 step:15865 [D loss: 0.913966, acc: 46.88%] [G loss: 1.769790]\n",
      "epoch:20 step:15866 [D loss: 1.195596, acc: 35.16%] [G loss: 2.700045]\n",
      "epoch:20 step:15867 [D loss: 0.801863, acc: 46.09%] [G loss: 2.386810]\n",
      "epoch:20 step:15868 [D loss: 0.705739, acc: 48.44%] [G loss: 1.833427]\n",
      "epoch:20 step:15869 [D loss: 0.375763, acc: 93.75%] [G loss: 3.608941]\n",
      "epoch:20 step:15870 [D loss: 0.339339, acc: 97.66%] [G loss: 2.192600]\n",
      "epoch:20 step:15871 [D loss: 0.471199, acc: 69.53%] [G loss: 3.695783]\n",
      "epoch:20 step:15872 [D loss: 0.598637, acc: 64.06%] [G loss: 2.642742]\n",
      "epoch:20 step:15873 [D loss: 0.568029, acc: 60.16%] [G loss: 2.467228]\n",
      "epoch:20 step:15874 [D loss: 0.470393, acc: 85.16%] [G loss: 2.107398]\n",
      "epoch:20 step:15875 [D loss: 0.551765, acc: 63.28%] [G loss: 2.441189]\n",
      "epoch:20 step:15876 [D loss: 0.372763, acc: 88.28%] [G loss: 3.306505]\n",
      "epoch:20 step:15877 [D loss: 1.107833, acc: 48.44%] [G loss: 2.908068]\n",
      "epoch:20 step:15878 [D loss: 0.327492, acc: 96.88%] [G loss: 3.883172]\n",
      "epoch:20 step:15879 [D loss: 0.256558, acc: 99.22%] [G loss: 2.863253]\n",
      "epoch:20 step:15880 [D loss: 0.662055, acc: 59.38%] [G loss: 4.237624]\n",
      "epoch:20 step:15881 [D loss: 0.320788, acc: 93.75%] [G loss: 3.935350]\n",
      "epoch:20 step:15882 [D loss: 0.166403, acc: 99.22%] [G loss: 3.681119]\n",
      "epoch:20 step:15883 [D loss: 0.792695, acc: 50.00%] [G loss: 4.142445]\n",
      "epoch:20 step:15884 [D loss: 0.365324, acc: 83.59%] [G loss: 4.256805]\n",
      "epoch:20 step:15885 [D loss: 0.699415, acc: 60.94%] [G loss: 3.914039]\n",
      "epoch:20 step:15886 [D loss: 0.676074, acc: 57.03%] [G loss: 2.889611]\n",
      "epoch:20 step:15887 [D loss: 0.560122, acc: 65.62%] [G loss: 3.142112]\n",
      "epoch:20 step:15888 [D loss: 0.955584, acc: 50.78%] [G loss: 3.160123]\n",
      "epoch:20 step:15889 [D loss: 0.444180, acc: 75.78%] [G loss: 2.743762]\n",
      "epoch:20 step:15890 [D loss: 1.126592, acc: 19.53%] [G loss: 2.793966]\n",
      "epoch:20 step:15891 [D loss: 0.660359, acc: 60.94%] [G loss: 3.313648]\n",
      "epoch:20 step:15892 [D loss: 0.371204, acc: 92.97%] [G loss: 3.399508]\n",
      "epoch:20 step:15893 [D loss: 0.657733, acc: 61.72%] [G loss: 3.331731]\n",
      "epoch:20 step:15894 [D loss: 0.838449, acc: 37.50%] [G loss: 2.978450]\n",
      "epoch:20 step:15895 [D loss: 0.430745, acc: 89.06%] [G loss: 3.509537]\n",
      "epoch:20 step:15896 [D loss: 0.678864, acc: 59.38%] [G loss: 2.684616]\n",
      "epoch:20 step:15897 [D loss: 0.433858, acc: 89.06%] [G loss: 2.432248]\n",
      "epoch:20 step:15898 [D loss: 0.325131, acc: 96.88%] [G loss: 2.036544]\n",
      "epoch:20 step:15899 [D loss: 0.484444, acc: 83.59%] [G loss: 3.311880]\n",
      "epoch:20 step:15900 [D loss: 0.218330, acc: 100.00%] [G loss: 2.810572]\n",
      "epoch:20 step:15901 [D loss: 0.568572, acc: 70.31%] [G loss: 3.055575]\n",
      "epoch:20 step:15902 [D loss: 0.441710, acc: 85.16%] [G loss: 2.210875]\n",
      "epoch:20 step:15903 [D loss: 1.072291, acc: 51.56%] [G loss: 3.070536]\n",
      "epoch:20 step:15904 [D loss: 0.536224, acc: 76.56%] [G loss: 3.280993]\n",
      "epoch:20 step:15905 [D loss: 0.679084, acc: 57.81%] [G loss: 3.086658]\n",
      "epoch:20 step:15906 [D loss: 0.290120, acc: 96.88%] [G loss: 2.807945]\n",
      "epoch:20 step:15907 [D loss: 0.773826, acc: 46.88%] [G loss: 3.661470]\n",
      "epoch:20 step:15908 [D loss: 0.571068, acc: 75.00%] [G loss: 2.435239]\n",
      "epoch:20 step:15909 [D loss: 0.686799, acc: 54.69%] [G loss: 2.484791]\n",
      "epoch:20 step:15910 [D loss: 0.274828, acc: 96.09%] [G loss: 2.297443]\n",
      "epoch:20 step:15911 [D loss: 0.950925, acc: 25.00%] [G loss: 2.436212]\n",
      "epoch:20 step:15912 [D loss: 0.573993, acc: 67.19%] [G loss: 4.434922]\n",
      "epoch:20 step:15913 [D loss: 0.770242, acc: 46.09%] [G loss: 2.300948]\n",
      "epoch:20 step:15914 [D loss: 0.629824, acc: 65.62%] [G loss: 2.654822]\n",
      "epoch:20 step:15915 [D loss: 0.215159, acc: 98.44%] [G loss: 2.657927]\n",
      "epoch:20 step:15916 [D loss: 0.110281, acc: 100.00%] [G loss: 4.045827]\n",
      "epoch:20 step:15917 [D loss: 0.791428, acc: 44.53%] [G loss: 2.072972]\n",
      "epoch:20 step:15918 [D loss: 0.230283, acc: 97.66%] [G loss: 2.825971]\n",
      "epoch:20 step:15919 [D loss: 0.264541, acc: 96.09%] [G loss: 3.305051]\n",
      "epoch:20 step:15920 [D loss: 0.556310, acc: 74.22%] [G loss: 2.153775]\n",
      "epoch:20 step:15921 [D loss: 0.823344, acc: 42.97%] [G loss: 2.155818]\n",
      "epoch:20 step:15922 [D loss: 1.262861, acc: 36.72%] [G loss: 1.764215]\n",
      "epoch:20 step:15923 [D loss: 1.014821, acc: 25.00%] [G loss: 2.230384]\n",
      "epoch:20 step:15924 [D loss: 0.348276, acc: 92.19%] [G loss: 3.857790]\n",
      "epoch:20 step:15925 [D loss: 0.305744, acc: 93.75%] [G loss: 3.652569]\n",
      "epoch:20 step:15926 [D loss: 0.423272, acc: 72.66%] [G loss: 3.182505]\n",
      "epoch:20 step:15927 [D loss: 0.784239, acc: 46.88%] [G loss: 3.801701]\n",
      "epoch:20 step:15928 [D loss: 0.508511, acc: 65.62%] [G loss: 2.292724]\n",
      "epoch:20 step:15929 [D loss: 0.159644, acc: 100.00%] [G loss: 2.170027]\n",
      "epoch:20 step:15930 [D loss: 0.420389, acc: 84.38%] [G loss: 3.170048]\n",
      "epoch:20 step:15931 [D loss: 0.357908, acc: 95.31%] [G loss: 2.681319]\n",
      "epoch:20 step:15932 [D loss: 0.594813, acc: 67.97%] [G loss: 2.552516]\n",
      "epoch:20 step:15933 [D loss: 0.134817, acc: 100.00%] [G loss: 5.468712]\n",
      "epoch:20 step:15934 [D loss: 0.292801, acc: 96.88%] [G loss: 3.556269]\n",
      "epoch:20 step:15935 [D loss: 0.539514, acc: 68.75%] [G loss: 3.416372]\n",
      "epoch:20 step:15936 [D loss: 0.192089, acc: 96.88%] [G loss: 3.709855]\n",
      "epoch:20 step:15937 [D loss: 0.215584, acc: 100.00%] [G loss: 3.711828]\n",
      "epoch:20 step:15938 [D loss: 0.365220, acc: 89.84%] [G loss: 2.758554]\n",
      "epoch:20 step:15939 [D loss: 0.426512, acc: 79.69%] [G loss: 2.466415]\n",
      "epoch:20 step:15940 [D loss: 0.665808, acc: 60.94%] [G loss: 2.441803]\n",
      "epoch:20 step:15941 [D loss: 0.152632, acc: 98.44%] [G loss: 3.837643]\n",
      "epoch:20 step:15942 [D loss: 0.643098, acc: 57.81%] [G loss: 3.542674]\n",
      "epoch:20 step:15943 [D loss: 0.662768, acc: 53.91%] [G loss: 2.216902]\n",
      "epoch:20 step:15944 [D loss: 0.923856, acc: 40.62%] [G loss: 3.256669]\n",
      "epoch:20 step:15945 [D loss: 0.129117, acc: 99.22%] [G loss: 2.744695]\n",
      "epoch:20 step:15946 [D loss: 0.405949, acc: 82.03%] [G loss: 2.190799]\n",
      "epoch:20 step:15947 [D loss: 0.570206, acc: 75.00%] [G loss: 4.324604]\n",
      "epoch:20 step:15948 [D loss: 0.509620, acc: 78.91%] [G loss: 3.811802]\n",
      "epoch:20 step:15949 [D loss: 0.224612, acc: 96.88%] [G loss: 4.456373]\n",
      "epoch:20 step:15950 [D loss: 0.351196, acc: 94.53%] [G loss: 3.602902]\n",
      "epoch:20 step:15951 [D loss: 0.261439, acc: 99.22%] [G loss: 3.349783]\n",
      "epoch:20 step:15952 [D loss: 0.577686, acc: 71.09%] [G loss: 4.055295]\n",
      "epoch:20 step:15953 [D loss: 0.172995, acc: 99.22%] [G loss: 4.543787]\n",
      "epoch:20 step:15954 [D loss: 0.208507, acc: 97.66%] [G loss: 4.912533]\n",
      "epoch:20 step:15955 [D loss: 0.057754, acc: 100.00%] [G loss: 3.444487]\n",
      "epoch:20 step:15956 [D loss: 0.679999, acc: 56.25%] [G loss: 3.107057]\n",
      "epoch:20 step:15957 [D loss: 0.449436, acc: 69.53%] [G loss: 4.384167]\n",
      "epoch:20 step:15958 [D loss: 0.907179, acc: 30.47%] [G loss: 3.562269]\n",
      "epoch:20 step:15959 [D loss: 0.991564, acc: 50.00%] [G loss: 4.667881]\n",
      "epoch:20 step:15960 [D loss: 0.876419, acc: 32.03%] [G loss: 2.201939]\n",
      "epoch:20 step:15961 [D loss: 0.382479, acc: 89.84%] [G loss: 3.621399]\n",
      "epoch:20 step:15962 [D loss: 0.269823, acc: 96.09%] [G loss: 2.459219]\n",
      "epoch:20 step:15963 [D loss: 0.910456, acc: 29.69%] [G loss: 2.219797]\n",
      "epoch:20 step:15964 [D loss: 0.437184, acc: 82.81%] [G loss: 3.488898]\n",
      "epoch:20 step:15965 [D loss: 0.617925, acc: 56.25%] [G loss: 4.575222]\n",
      "epoch:20 step:15966 [D loss: 0.557594, acc: 77.34%] [G loss: 3.469732]\n",
      "epoch:20 step:15967 [D loss: 0.922189, acc: 41.41%] [G loss: 2.387823]\n",
      "epoch:20 step:15968 [D loss: 0.392689, acc: 89.84%] [G loss: 2.367536]\n",
      "epoch:20 step:15969 [D loss: 0.773242, acc: 51.56%] [G loss: 2.641078]\n",
      "epoch:20 step:15970 [D loss: 0.362898, acc: 89.84%] [G loss: 2.802275]\n",
      "epoch:20 step:15971 [D loss: 0.819166, acc: 50.78%] [G loss: 3.522605]\n",
      "epoch:20 step:15972 [D loss: 0.199122, acc: 98.44%] [G loss: 3.504328]\n",
      "epoch:20 step:15973 [D loss: 0.699859, acc: 58.59%] [G loss: 2.775121]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:20 step:15974 [D loss: 0.284720, acc: 97.66%] [G loss: 3.455490]\n",
      "epoch:20 step:15975 [D loss: 0.866866, acc: 35.94%] [G loss: 3.440825]\n",
      "epoch:20 step:15976 [D loss: 0.223275, acc: 96.09%] [G loss: 4.111458]\n",
      "epoch:20 step:15977 [D loss: 0.316254, acc: 98.44%] [G loss: 2.541852]\n",
      "epoch:20 step:15978 [D loss: 0.754512, acc: 54.69%] [G loss: 2.552176]\n",
      "epoch:20 step:15979 [D loss: 0.323653, acc: 95.31%] [G loss: 2.355044]\n",
      "epoch:20 step:15980 [D loss: 0.512802, acc: 71.88%] [G loss: 2.561593]\n",
      "epoch:20 step:15981 [D loss: 0.915280, acc: 30.47%] [G loss: 2.874519]\n",
      "epoch:20 step:15982 [D loss: 0.504835, acc: 78.91%] [G loss: 4.662459]\n",
      "epoch:20 step:15983 [D loss: 0.589618, acc: 64.06%] [G loss: 2.811955]\n",
      "epoch:20 step:15984 [D loss: 0.829198, acc: 42.19%] [G loss: 3.878245]\n",
      "epoch:20 step:15985 [D loss: 0.540939, acc: 78.12%] [G loss: 2.486190]\n",
      "epoch:20 step:15986 [D loss: 1.267601, acc: 4.69%] [G loss: 2.382663]\n",
      "epoch:20 step:15987 [D loss: 0.511159, acc: 75.00%] [G loss: 3.291658]\n",
      "epoch:20 step:15988 [D loss: 0.851882, acc: 51.56%] [G loss: 4.217128]\n",
      "epoch:20 step:15989 [D loss: 0.432173, acc: 72.66%] [G loss: 2.884284]\n",
      "epoch:20 step:15990 [D loss: 0.393145, acc: 85.16%] [G loss: 3.075346]\n",
      "epoch:20 step:15991 [D loss: 0.605896, acc: 64.06%] [G loss: 3.105186]\n",
      "epoch:20 step:15992 [D loss: 0.593016, acc: 61.72%] [G loss: 2.675025]\n",
      "epoch:20 step:15993 [D loss: 0.606782, acc: 65.62%] [G loss: 4.048362]\n",
      "epoch:20 step:15994 [D loss: 0.133755, acc: 100.00%] [G loss: 4.136895]\n",
      "epoch:20 step:15995 [D loss: 0.427167, acc: 74.22%] [G loss: 3.470639]\n",
      "epoch:20 step:15996 [D loss: 0.424983, acc: 89.06%] [G loss: 3.301880]\n",
      "epoch:20 step:15997 [D loss: 0.651193, acc: 56.25%] [G loss: 2.438876]\n",
      "epoch:20 step:15998 [D loss: 0.636545, acc: 67.19%] [G loss: 2.971407]\n",
      "epoch:20 step:15999 [D loss: 0.616527, acc: 58.59%] [G loss: 2.829877]\n",
      "epoch:20 step:16000 [D loss: 0.591583, acc: 73.44%] [G loss: 2.547177]\n",
      "##############\n",
      "[0.85959419 0.88084648 0.8037444  0.8021271  0.80093369 0.82920836\n",
      " 0.90176964 0.82422824 0.84527787 0.84164333]\n",
      "##########\n",
      "epoch:20 step:16001 [D loss: 0.403218, acc: 89.06%] [G loss: 2.488754]\n",
      "epoch:20 step:16002 [D loss: 0.469733, acc: 81.25%] [G loss: 1.952171]\n",
      "epoch:20 step:16003 [D loss: 0.618454, acc: 71.09%] [G loss: 1.891731]\n",
      "epoch:20 step:16004 [D loss: 0.387025, acc: 85.16%] [G loss: 3.460754]\n",
      "epoch:20 step:16005 [D loss: 0.335318, acc: 95.31%] [G loss: 3.829128]\n",
      "epoch:20 step:16006 [D loss: 0.509037, acc: 78.91%] [G loss: 2.568769]\n",
      "epoch:20 step:16007 [D loss: 0.428516, acc: 85.94%] [G loss: 3.380029]\n",
      "epoch:20 step:16008 [D loss: 0.293406, acc: 96.88%] [G loss: 3.802960]\n",
      "epoch:20 step:16009 [D loss: 0.458572, acc: 80.47%] [G loss: 2.317607]\n",
      "epoch:20 step:16010 [D loss: 0.369541, acc: 92.19%] [G loss: 2.916590]\n",
      "epoch:20 step:16011 [D loss: 0.891591, acc: 38.28%] [G loss: 3.374185]\n",
      "epoch:20 step:16012 [D loss: 0.877843, acc: 46.88%] [G loss: 3.005083]\n",
      "epoch:20 step:16013 [D loss: 0.983503, acc: 22.66%] [G loss: 2.215747]\n",
      "epoch:20 step:16014 [D loss: 0.310006, acc: 98.44%] [G loss: 3.976920]\n",
      "epoch:20 step:16015 [D loss: 0.671311, acc: 60.16%] [G loss: 3.027024]\n",
      "epoch:20 step:16016 [D loss: 0.497584, acc: 71.88%] [G loss: 2.531095]\n",
      "epoch:20 step:16017 [D loss: 0.441291, acc: 78.91%] [G loss: 2.299927]\n",
      "epoch:20 step:16018 [D loss: 0.491785, acc: 67.97%] [G loss: 2.813131]\n",
      "epoch:20 step:16019 [D loss: 0.477704, acc: 71.88%] [G loss: 3.538315]\n",
      "epoch:20 step:16020 [D loss: 0.293023, acc: 97.66%] [G loss: 3.242358]\n",
      "epoch:20 step:16021 [D loss: 0.325455, acc: 96.09%] [G loss: 3.032005]\n",
      "epoch:20 step:16022 [D loss: 0.254124, acc: 97.66%] [G loss: 2.150821]\n",
      "epoch:20 step:16023 [D loss: 0.871329, acc: 38.28%] [G loss: 3.489083]\n",
      "epoch:20 step:16024 [D loss: 0.436830, acc: 84.38%] [G loss: 2.598958]\n",
      "epoch:20 step:16025 [D loss: 0.490044, acc: 75.00%] [G loss: 2.108035]\n",
      "epoch:20 step:16026 [D loss: 0.694441, acc: 57.81%] [G loss: 2.369785]\n",
      "epoch:20 step:16027 [D loss: 0.089763, acc: 100.00%] [G loss: 3.672571]\n",
      "epoch:20 step:16028 [D loss: 0.321663, acc: 93.75%] [G loss: 3.590679]\n",
      "epoch:20 step:16029 [D loss: 0.576199, acc: 68.75%] [G loss: 2.977560]\n",
      "epoch:20 step:16030 [D loss: 0.589606, acc: 71.09%] [G loss: 3.695453]\n",
      "epoch:20 step:16031 [D loss: 0.610735, acc: 68.75%] [G loss: 3.813333]\n",
      "epoch:20 step:16032 [D loss: 0.240640, acc: 93.75%] [G loss: 3.767410]\n",
      "epoch:20 step:16033 [D loss: 0.382474, acc: 82.03%] [G loss: 2.510303]\n",
      "epoch:20 step:16034 [D loss: 0.332648, acc: 96.88%] [G loss: 2.539102]\n",
      "epoch:20 step:16035 [D loss: 0.479520, acc: 85.94%] [G loss: 3.239490]\n",
      "epoch:20 step:16036 [D loss: 0.314338, acc: 96.09%] [G loss: 4.354585]\n",
      "epoch:20 step:16037 [D loss: 0.577526, acc: 65.62%] [G loss: 3.549542]\n",
      "epoch:20 step:16038 [D loss: 0.283594, acc: 96.88%] [G loss: 3.254523]\n",
      "epoch:20 step:16039 [D loss: 0.257340, acc: 93.75%] [G loss: 4.968081]\n",
      "epoch:20 step:16040 [D loss: 0.503408, acc: 82.81%] [G loss: 3.269519]\n",
      "epoch:20 step:16041 [D loss: 0.331065, acc: 95.31%] [G loss: 3.341339]\n",
      "epoch:20 step:16042 [D loss: 0.167457, acc: 99.22%] [G loss: 3.501457]\n",
      "epoch:20 step:16043 [D loss: 1.004066, acc: 50.78%] [G loss: 3.120945]\n",
      "epoch:20 step:16044 [D loss: 0.394691, acc: 82.81%] [G loss: 3.804857]\n",
      "epoch:20 step:16045 [D loss: 0.321607, acc: 95.31%] [G loss: 3.743868]\n",
      "epoch:20 step:16046 [D loss: 1.137814, acc: 35.16%] [G loss: 2.541324]\n",
      "epoch:20 step:16047 [D loss: 0.231813, acc: 97.66%] [G loss: 3.350655]\n",
      "epoch:20 step:16048 [D loss: 0.512133, acc: 75.78%] [G loss: 2.759605]\n",
      "epoch:20 step:16049 [D loss: 0.464324, acc: 82.81%] [G loss: 3.678021]\n",
      "epoch:20 step:16050 [D loss: 0.390961, acc: 85.94%] [G loss: 2.842036]\n",
      "epoch:20 step:16051 [D loss: 0.518930, acc: 71.88%] [G loss: 2.784789]\n",
      "epoch:20 step:16052 [D loss: 0.426950, acc: 78.12%] [G loss: 3.570808]\n",
      "epoch:20 step:16053 [D loss: 0.562182, acc: 67.19%] [G loss: 2.846961]\n",
      "epoch:20 step:16054 [D loss: 0.164218, acc: 100.00%] [G loss: 3.424667]\n",
      "epoch:20 step:16055 [D loss: 0.307813, acc: 91.41%] [G loss: 3.868913]\n",
      "epoch:20 step:16056 [D loss: 0.910473, acc: 51.56%] [G loss: 4.137247]\n",
      "epoch:20 step:16057 [D loss: 0.395400, acc: 81.25%] [G loss: 3.239775]\n",
      "epoch:20 step:16058 [D loss: 0.722441, acc: 51.56%] [G loss: 2.834652]\n",
      "epoch:20 step:16059 [D loss: 0.499604, acc: 78.91%] [G loss: 3.911210]\n",
      "epoch:20 step:16060 [D loss: 0.765112, acc: 51.56%] [G loss: 4.192542]\n",
      "epoch:20 step:16061 [D loss: 0.856531, acc: 50.78%] [G loss: 2.929378]\n",
      "epoch:20 step:16062 [D loss: 0.206814, acc: 96.88%] [G loss: 2.802862]\n",
      "epoch:20 step:16063 [D loss: 0.602867, acc: 59.38%] [G loss: 2.288337]\n",
      "epoch:20 step:16064 [D loss: 0.522436, acc: 72.66%] [G loss: 2.563589]\n",
      "epoch:20 step:16065 [D loss: 1.311582, acc: 48.44%] [G loss: 3.273649]\n",
      "epoch:20 step:16066 [D loss: 0.444126, acc: 78.91%] [G loss: 3.623880]\n",
      "epoch:20 step:16067 [D loss: 0.407625, acc: 89.06%] [G loss: 2.710445]\n",
      "epoch:20 step:16068 [D loss: 0.655221, acc: 61.72%] [G loss: 3.086627]\n",
      "epoch:20 step:16069 [D loss: 0.439107, acc: 88.28%] [G loss: 3.133378]\n",
      "epoch:20 step:16070 [D loss: 0.325404, acc: 96.09%] [G loss: 3.482127]\n",
      "epoch:20 step:16071 [D loss: 0.428699, acc: 85.94%] [G loss: 3.951404]\n",
      "epoch:20 step:16072 [D loss: 0.154014, acc: 100.00%] [G loss: 4.470461]\n",
      "epoch:20 step:16073 [D loss: 0.710719, acc: 53.91%] [G loss: 5.021416]\n",
      "epoch:20 step:16074 [D loss: 0.213076, acc: 100.00%] [G loss: 2.989953]\n",
      "epoch:20 step:16075 [D loss: 1.038266, acc: 48.44%] [G loss: 2.261711]\n",
      "epoch:20 step:16076 [D loss: 0.268777, acc: 99.22%] [G loss: 2.622637]\n",
      "epoch:20 step:16077 [D loss: 0.475816, acc: 82.81%] [G loss: 2.906837]\n",
      "epoch:20 step:16078 [D loss: 0.290830, acc: 96.88%] [G loss: 4.975957]\n",
      "epoch:20 step:16079 [D loss: 1.059351, acc: 25.78%] [G loss: 2.459507]\n",
      "epoch:20 step:16080 [D loss: 0.406092, acc: 78.91%] [G loss: 3.522929]\n",
      "epoch:20 step:16081 [D loss: 0.137765, acc: 100.00%] [G loss: 3.400918]\n",
      "epoch:20 step:16082 [D loss: 0.324162, acc: 96.09%] [G loss: 3.858602]\n",
      "epoch:20 step:16083 [D loss: 0.558499, acc: 71.09%] [G loss: 4.432449]\n",
      "epoch:20 step:16084 [D loss: 0.187552, acc: 99.22%] [G loss: 3.057755]\n",
      "epoch:20 step:16085 [D loss: 0.481365, acc: 89.06%] [G loss: 3.234450]\n",
      "epoch:20 step:16086 [D loss: 0.113238, acc: 100.00%] [G loss: 3.308246]\n",
      "epoch:20 step:16087 [D loss: 0.609555, acc: 67.19%] [G loss: 2.670270]\n",
      "epoch:20 step:16088 [D loss: 0.256351, acc: 93.75%] [G loss: 2.778674]\n",
      "epoch:20 step:16089 [D loss: 0.499657, acc: 74.22%] [G loss: 4.751936]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:20 step:16090 [D loss: 0.045754, acc: 100.00%] [G loss: 2.485994]\n",
      "epoch:20 step:16091 [D loss: 1.007328, acc: 22.66%] [G loss: 3.633715]\n",
      "epoch:20 step:16092 [D loss: 0.390003, acc: 88.28%] [G loss: 2.812911]\n",
      "epoch:20 step:16093 [D loss: 0.985101, acc: 22.66%] [G loss: 2.920802]\n",
      "epoch:20 step:16094 [D loss: 0.463352, acc: 84.38%] [G loss: 2.179971]\n",
      "epoch:20 step:16095 [D loss: 0.212678, acc: 98.44%] [G loss: 2.288838]\n",
      "epoch:20 step:16096 [D loss: 0.289550, acc: 95.31%] [G loss: 2.858673]\n",
      "epoch:20 step:16097 [D loss: 0.239519, acc: 96.88%] [G loss: 3.126656]\n",
      "epoch:20 step:16098 [D loss: 0.081840, acc: 100.00%] [G loss: 3.537934]\n",
      "epoch:20 step:16099 [D loss: 0.777997, acc: 42.97%] [G loss: 1.927987]\n",
      "epoch:20 step:16100 [D loss: 0.588138, acc: 68.75%] [G loss: 3.346859]\n",
      "epoch:20 step:16101 [D loss: 0.623747, acc: 66.41%] [G loss: 2.328439]\n",
      "epoch:20 step:16102 [D loss: 1.648180, acc: 49.22%] [G loss: 2.918420]\n",
      "epoch:20 step:16103 [D loss: 0.289337, acc: 89.84%] [G loss: 2.873995]\n",
      "epoch:20 step:16104 [D loss: 1.051314, acc: 48.44%] [G loss: 2.414827]\n",
      "epoch:20 step:16105 [D loss: 0.106593, acc: 100.00%] [G loss: 1.871369]\n",
      "epoch:20 step:16106 [D loss: 0.357944, acc: 90.62%] [G loss: 3.356126]\n",
      "epoch:20 step:16107 [D loss: 0.355150, acc: 92.97%] [G loss: 3.461156]\n",
      "epoch:20 step:16108 [D loss: 0.466337, acc: 71.09%] [G loss: 3.892423]\n",
      "epoch:20 step:16109 [D loss: 0.815261, acc: 51.56%] [G loss: 2.424654]\n",
      "epoch:20 step:16110 [D loss: 0.097122, acc: 99.22%] [G loss: 5.815658]\n",
      "epoch:20 step:16111 [D loss: 0.716316, acc: 53.91%] [G loss: 3.645191]\n",
      "epoch:20 step:16112 [D loss: 0.467203, acc: 85.16%] [G loss: 3.053834]\n",
      "epoch:20 step:16113 [D loss: 0.479488, acc: 84.38%] [G loss: 3.758468]\n",
      "epoch:20 step:16114 [D loss: 0.655998, acc: 58.59%] [G loss: 2.377229]\n",
      "epoch:20 step:16115 [D loss: 0.174089, acc: 100.00%] [G loss: 3.465072]\n",
      "epoch:20 step:16116 [D loss: 0.671699, acc: 59.38%] [G loss: 2.899017]\n",
      "epoch:20 step:16117 [D loss: 0.318692, acc: 92.97%] [G loss: 3.257326]\n",
      "epoch:20 step:16118 [D loss: 0.506857, acc: 77.34%] [G loss: 2.751099]\n",
      "epoch:20 step:16119 [D loss: 0.599375, acc: 57.81%] [G loss: 3.783475]\n",
      "epoch:20 step:16120 [D loss: 0.702379, acc: 57.81%] [G loss: 2.785038]\n",
      "epoch:20 step:16121 [D loss: 0.582224, acc: 67.97%] [G loss: 2.972272]\n",
      "epoch:20 step:16122 [D loss: 0.277667, acc: 96.88%] [G loss: 3.407508]\n",
      "epoch:20 step:16123 [D loss: 0.386012, acc: 87.50%] [G loss: 2.755350]\n",
      "epoch:20 step:16124 [D loss: 0.763863, acc: 50.00%] [G loss: 2.287136]\n",
      "epoch:20 step:16125 [D loss: 0.946181, acc: 44.53%] [G loss: 2.744582]\n",
      "epoch:20 step:16126 [D loss: 0.269923, acc: 97.66%] [G loss: 1.382114]\n",
      "epoch:20 step:16127 [D loss: 0.481729, acc: 78.91%] [G loss: 2.425627]\n",
      "epoch:20 step:16128 [D loss: 0.293707, acc: 97.66%] [G loss: 2.804900]\n",
      "epoch:20 step:16129 [D loss: 0.186099, acc: 99.22%] [G loss: 4.909802]\n",
      "epoch:20 step:16130 [D loss: 0.693497, acc: 51.56%] [G loss: 2.659141]\n",
      "epoch:20 step:16131 [D loss: 0.127074, acc: 100.00%] [G loss: 6.644038]\n",
      "epoch:20 step:16132 [D loss: 0.589614, acc: 60.16%] [G loss: 3.998915]\n",
      "epoch:20 step:16133 [D loss: 0.709089, acc: 57.03%] [G loss: 2.913707]\n",
      "epoch:20 step:16134 [D loss: 0.257961, acc: 92.97%] [G loss: 3.404207]\n",
      "epoch:20 step:16135 [D loss: 0.511708, acc: 70.31%] [G loss: 2.928342]\n",
      "epoch:20 step:16136 [D loss: 0.311536, acc: 93.75%] [G loss: 3.066305]\n",
      "epoch:20 step:16137 [D loss: 0.532689, acc: 63.28%] [G loss: 4.802219]\n",
      "epoch:20 step:16138 [D loss: 0.557458, acc: 75.78%] [G loss: 3.073419]\n",
      "epoch:20 step:16139 [D loss: 0.599862, acc: 64.06%] [G loss: 2.895680]\n",
      "epoch:20 step:16140 [D loss: 0.128921, acc: 100.00%] [G loss: 3.865318]\n",
      "epoch:20 step:16141 [D loss: 0.355816, acc: 86.72%] [G loss: 3.885487]\n",
      "epoch:20 step:16142 [D loss: 0.805787, acc: 44.53%] [G loss: 4.550618]\n",
      "epoch:20 step:16143 [D loss: 0.524928, acc: 75.00%] [G loss: 3.050674]\n",
      "epoch:20 step:16144 [D loss: 0.518781, acc: 78.12%] [G loss: 3.149008]\n",
      "epoch:20 step:16145 [D loss: 0.840544, acc: 45.31%] [G loss: 3.018534]\n",
      "epoch:20 step:16146 [D loss: 1.243312, acc: 28.12%] [G loss: 2.388331]\n",
      "epoch:20 step:16147 [D loss: 0.429609, acc: 83.59%] [G loss: 2.377434]\n",
      "epoch:20 step:16148 [D loss: 0.584786, acc: 68.75%] [G loss: 2.641478]\n",
      "epoch:20 step:16149 [D loss: 0.365359, acc: 91.41%] [G loss: 4.783134]\n",
      "epoch:20 step:16150 [D loss: 0.592716, acc: 64.06%] [G loss: 2.932153]\n",
      "epoch:20 step:16151 [D loss: 0.825390, acc: 47.66%] [G loss: 2.853443]\n",
      "epoch:20 step:16152 [D loss: 0.556575, acc: 67.97%] [G loss: 3.171327]\n",
      "epoch:20 step:16153 [D loss: 0.574412, acc: 64.06%] [G loss: 4.125513]\n",
      "epoch:20 step:16154 [D loss: 0.467570, acc: 80.47%] [G loss: 2.917239]\n",
      "epoch:20 step:16155 [D loss: 0.697999, acc: 53.91%] [G loss: 2.505807]\n",
      "epoch:20 step:16156 [D loss: 0.568858, acc: 73.44%] [G loss: 3.840856]\n",
      "epoch:20 step:16157 [D loss: 0.487371, acc: 82.81%] [G loss: 2.788944]\n",
      "epoch:20 step:16158 [D loss: 0.357380, acc: 96.09%] [G loss: 3.010259]\n",
      "epoch:20 step:16159 [D loss: 0.625498, acc: 58.59%] [G loss: 3.233623]\n",
      "epoch:20 step:16160 [D loss: 0.599420, acc: 61.72%] [G loss: 2.755458]\n",
      "epoch:20 step:16161 [D loss: 0.411029, acc: 86.72%] [G loss: 3.497705]\n",
      "epoch:20 step:16162 [D loss: 0.593705, acc: 68.75%] [G loss: 2.157652]\n",
      "epoch:20 step:16163 [D loss: 0.957441, acc: 49.22%] [G loss: 3.569786]\n",
      "epoch:20 step:16164 [D loss: 0.755176, acc: 53.12%] [G loss: 2.713049]\n",
      "epoch:20 step:16165 [D loss: 0.608394, acc: 61.72%] [G loss: 2.907304]\n",
      "epoch:20 step:16166 [D loss: 0.317588, acc: 93.75%] [G loss: 2.559641]\n",
      "epoch:20 step:16167 [D loss: 0.542904, acc: 76.56%] [G loss: 3.155569]\n",
      "epoch:20 step:16168 [D loss: 0.554845, acc: 75.00%] [G loss: 2.283077]\n",
      "epoch:20 step:16169 [D loss: 0.236329, acc: 96.09%] [G loss: 2.454753]\n",
      "epoch:20 step:16170 [D loss: 0.299055, acc: 96.88%] [G loss: 2.361658]\n",
      "epoch:20 step:16171 [D loss: 0.391030, acc: 88.28%] [G loss: 2.290700]\n",
      "epoch:20 step:16172 [D loss: 0.753911, acc: 45.31%] [G loss: 2.721029]\n",
      "epoch:20 step:16173 [D loss: 0.675507, acc: 57.03%] [G loss: 2.136968]\n",
      "epoch:20 step:16174 [D loss: 1.315226, acc: 8.59%] [G loss: 3.007534]\n",
      "epoch:20 step:16175 [D loss: 0.240184, acc: 97.66%] [G loss: 3.891515]\n",
      "epoch:20 step:16176 [D loss: 0.497219, acc: 76.56%] [G loss: 3.165702]\n",
      "epoch:20 step:16177 [D loss: 0.268906, acc: 92.19%] [G loss: 4.589838]\n",
      "epoch:20 step:16178 [D loss: 0.582532, acc: 64.84%] [G loss: 3.447994]\n",
      "epoch:20 step:16179 [D loss: 0.874088, acc: 35.16%] [G loss: 2.110072]\n",
      "epoch:20 step:16180 [D loss: 0.539840, acc: 78.91%] [G loss: 3.512837]\n",
      "epoch:20 step:16181 [D loss: 0.364173, acc: 88.28%] [G loss: 4.364996]\n",
      "epoch:20 step:16182 [D loss: 0.667931, acc: 57.81%] [G loss: 3.398100]\n",
      "epoch:20 step:16183 [D loss: 0.525966, acc: 73.44%] [G loss: 3.295717]\n",
      "epoch:20 step:16184 [D loss: 0.362824, acc: 94.53%] [G loss: 3.941651]\n",
      "epoch:20 step:16185 [D loss: 0.492329, acc: 83.59%] [G loss: 2.554378]\n",
      "epoch:20 step:16186 [D loss: 0.356640, acc: 88.28%] [G loss: 5.231876]\n",
      "epoch:20 step:16187 [D loss: 0.170034, acc: 99.22%] [G loss: 2.343229]\n",
      "epoch:20 step:16188 [D loss: 0.355847, acc: 90.62%] [G loss: 2.276078]\n",
      "epoch:20 step:16189 [D loss: 0.367497, acc: 85.16%] [G loss: 2.845526]\n",
      "epoch:20 step:16190 [D loss: 0.537602, acc: 71.09%] [G loss: 2.675693]\n",
      "epoch:20 step:16191 [D loss: 0.463464, acc: 86.72%] [G loss: 2.545701]\n",
      "epoch:20 step:16192 [D loss: 0.402200, acc: 82.81%] [G loss: 2.740899]\n",
      "epoch:20 step:16193 [D loss: 0.456659, acc: 79.69%] [G loss: 3.941617]\n",
      "epoch:20 step:16194 [D loss: 0.620097, acc: 69.53%] [G loss: 2.310316]\n",
      "epoch:20 step:16195 [D loss: 0.667531, acc: 57.81%] [G loss: 2.031088]\n",
      "epoch:20 step:16196 [D loss: 0.356751, acc: 87.50%] [G loss: 2.441195]\n",
      "epoch:20 step:16197 [D loss: 0.401861, acc: 86.72%] [G loss: 3.148756]\n",
      "epoch:20 step:16198 [D loss: 0.795082, acc: 40.62%] [G loss: 2.263376]\n",
      "epoch:20 step:16199 [D loss: 0.410177, acc: 89.06%] [G loss: 4.243457]\n",
      "epoch:20 step:16200 [D loss: 0.378646, acc: 85.16%] [G loss: 2.838400]\n",
      "##############\n",
      "[0.84843147 0.8632955  0.8314244  0.8209974  0.80112521 0.81491622\n",
      " 0.89460623 0.81830827 0.80368331 0.82094206]\n",
      "##########\n",
      "epoch:20 step:16201 [D loss: 0.343210, acc: 92.97%] [G loss: 3.408860]\n",
      "epoch:20 step:16202 [D loss: 0.437477, acc: 90.62%] [G loss: 3.389168]\n",
      "epoch:20 step:16203 [D loss: 0.176787, acc: 97.66%] [G loss: 4.792656]\n",
      "epoch:20 step:16204 [D loss: 0.275960, acc: 97.66%] [G loss: 3.607104]\n",
      "epoch:20 step:16205 [D loss: 0.854187, acc: 51.56%] [G loss: 3.417369]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:20 step:16206 [D loss: 0.401405, acc: 72.66%] [G loss: 5.863173]\n",
      "epoch:20 step:16207 [D loss: 0.392204, acc: 80.47%] [G loss: 2.511991]\n",
      "epoch:20 step:16208 [D loss: 0.442179, acc: 78.12%] [G loss: 3.284964]\n",
      "epoch:20 step:16209 [D loss: 0.079681, acc: 100.00%] [G loss: 2.616179]\n",
      "epoch:20 step:16210 [D loss: 0.167831, acc: 100.00%] [G loss: 1.850613]\n",
      "epoch:20 step:16211 [D loss: 0.736719, acc: 53.91%] [G loss: 3.548818]\n",
      "epoch:20 step:16212 [D loss: 0.668481, acc: 57.03%] [G loss: 2.775972]\n",
      "epoch:20 step:16213 [D loss: 0.532963, acc: 71.09%] [G loss: 2.340148]\n",
      "epoch:20 step:16214 [D loss: 0.955067, acc: 33.59%] [G loss: 2.134363]\n",
      "epoch:20 step:16215 [D loss: 0.569236, acc: 71.88%] [G loss: 2.307477]\n",
      "epoch:20 step:16216 [D loss: 0.535630, acc: 72.66%] [G loss: 2.846084]\n",
      "epoch:20 step:16217 [D loss: 0.619636, acc: 64.84%] [G loss: 3.766163]\n",
      "epoch:20 step:16218 [D loss: 0.257477, acc: 97.66%] [G loss: 4.046976]\n",
      "epoch:20 step:16219 [D loss: 0.695985, acc: 57.81%] [G loss: 1.982498]\n",
      "epoch:20 step:16220 [D loss: 0.444862, acc: 79.69%] [G loss: 2.243516]\n",
      "epoch:20 step:16221 [D loss: 0.497557, acc: 78.91%] [G loss: 2.521439]\n",
      "epoch:20 step:16222 [D loss: 0.560100, acc: 62.50%] [G loss: 2.684271]\n",
      "epoch:20 step:16223 [D loss: 1.042537, acc: 21.88%] [G loss: 1.888361]\n",
      "epoch:20 step:16224 [D loss: 0.632049, acc: 62.50%] [G loss: 2.458622]\n",
      "epoch:20 step:16225 [D loss: 0.455931, acc: 82.81%] [G loss: 2.378297]\n",
      "epoch:20 step:16226 [D loss: 0.140985, acc: 100.00%] [G loss: 3.973301]\n",
      "epoch:20 step:16227 [D loss: 0.380700, acc: 82.81%] [G loss: 3.895021]\n",
      "epoch:20 step:16228 [D loss: 0.684935, acc: 58.59%] [G loss: 2.958503]\n",
      "epoch:20 step:16229 [D loss: 0.503530, acc: 66.41%] [G loss: 3.360056]\n",
      "epoch:20 step:16230 [D loss: 1.183927, acc: 25.78%] [G loss: 2.863133]\n",
      "epoch:20 step:16231 [D loss: 0.542721, acc: 73.44%] [G loss: 2.085138]\n",
      "epoch:20 step:16232 [D loss: 0.721123, acc: 55.47%] [G loss: 2.320628]\n",
      "epoch:20 step:16233 [D loss: 0.679267, acc: 55.47%] [G loss: 2.993912]\n",
      "epoch:20 step:16234 [D loss: 0.510349, acc: 75.00%] [G loss: 3.694549]\n",
      "epoch:20 step:16235 [D loss: 0.499411, acc: 78.12%] [G loss: 3.199368]\n",
      "epoch:20 step:16236 [D loss: 0.373719, acc: 94.53%] [G loss: 2.584098]\n",
      "epoch:20 step:16237 [D loss: 0.839108, acc: 43.75%] [G loss: 2.752624]\n",
      "epoch:20 step:16238 [D loss: 0.228306, acc: 99.22%] [G loss: 1.936268]\n",
      "epoch:20 step:16239 [D loss: 0.680617, acc: 59.38%] [G loss: 1.893022]\n",
      "epoch:20 step:16240 [D loss: 0.330367, acc: 95.31%] [G loss: 2.605658]\n",
      "epoch:20 step:16241 [D loss: 0.365301, acc: 90.62%] [G loss: 3.376391]\n",
      "epoch:20 step:16242 [D loss: 0.683471, acc: 59.38%] [G loss: 3.130332]\n",
      "epoch:20 step:16243 [D loss: 0.697112, acc: 56.25%] [G loss: 3.017278]\n",
      "epoch:20 step:16244 [D loss: 0.241775, acc: 96.09%] [G loss: 3.163423]\n",
      "epoch:20 step:16245 [D loss: 0.782775, acc: 48.44%] [G loss: 3.964323]\n",
      "epoch:20 step:16246 [D loss: 0.769747, acc: 49.22%] [G loss: 2.295629]\n",
      "epoch:20 step:16247 [D loss: 0.467896, acc: 86.72%] [G loss: 2.751917]\n",
      "epoch:20 step:16248 [D loss: 0.421593, acc: 88.28%] [G loss: 2.903054]\n",
      "epoch:20 step:16249 [D loss: 0.574140, acc: 74.22%] [G loss: 2.186293]\n",
      "epoch:20 step:16250 [D loss: 0.218037, acc: 100.00%] [G loss: 3.102209]\n",
      "epoch:20 step:16251 [D loss: 0.169890, acc: 100.00%] [G loss: 4.538478]\n",
      "epoch:20 step:16252 [D loss: 0.470706, acc: 78.91%] [G loss: 1.866340]\n",
      "epoch:20 step:16253 [D loss: 0.274814, acc: 96.88%] [G loss: 3.965802]\n",
      "epoch:20 step:16254 [D loss: 0.716191, acc: 53.12%] [G loss: 1.680470]\n",
      "epoch:20 step:16255 [D loss: 0.286365, acc: 91.41%] [G loss: 1.856562]\n",
      "epoch:20 step:16256 [D loss: 0.359114, acc: 85.16%] [G loss: 2.894355]\n",
      "epoch:20 step:16257 [D loss: 0.891034, acc: 53.12%] [G loss: 2.867316]\n",
      "epoch:20 step:16258 [D loss: 0.636861, acc: 64.06%] [G loss: 2.309366]\n",
      "epoch:20 step:16259 [D loss: 0.330356, acc: 92.97%] [G loss: 3.400118]\n",
      "epoch:20 step:16260 [D loss: 0.301476, acc: 98.44%] [G loss: 2.890208]\n",
      "epoch:20 step:16261 [D loss: 0.629597, acc: 61.72%] [G loss: 3.802143]\n",
      "epoch:20 step:16262 [D loss: 0.273716, acc: 96.88%] [G loss: 3.051440]\n",
      "epoch:20 step:16263 [D loss: 0.311810, acc: 92.97%] [G loss: 3.902273]\n",
      "epoch:20 step:16264 [D loss: 0.191281, acc: 99.22%] [G loss: 3.427888]\n",
      "epoch:20 step:16265 [D loss: 0.970604, acc: 26.56%] [G loss: 3.459420]\n",
      "epoch:20 step:16266 [D loss: 0.275196, acc: 96.09%] [G loss: 3.116045]\n",
      "epoch:20 step:16267 [D loss: 0.614462, acc: 67.19%] [G loss: 2.255168]\n",
      "epoch:20 step:16268 [D loss: 0.448795, acc: 71.88%] [G loss: 2.442827]\n",
      "epoch:20 step:16269 [D loss: 0.529058, acc: 76.56%] [G loss: 1.808908]\n",
      "epoch:20 step:16270 [D loss: 0.275825, acc: 97.66%] [G loss: 3.107378]\n",
      "epoch:20 step:16271 [D loss: 0.384007, acc: 92.19%] [G loss: 2.595792]\n",
      "epoch:20 step:16272 [D loss: 0.383485, acc: 92.97%] [G loss: 2.634058]\n",
      "epoch:20 step:16273 [D loss: 0.204793, acc: 96.88%] [G loss: 4.068609]\n",
      "epoch:20 step:16274 [D loss: 0.317942, acc: 95.31%] [G loss: 2.835218]\n",
      "epoch:20 step:16275 [D loss: 0.420927, acc: 90.62%] [G loss: 4.343692]\n",
      "epoch:20 step:16276 [D loss: 1.505450, acc: 0.00%] [G loss: 2.904924]\n",
      "epoch:20 step:16277 [D loss: 0.188108, acc: 100.00%] [G loss: 3.853115]\n",
      "epoch:20 step:16278 [D loss: 0.495097, acc: 69.53%] [G loss: 3.250570]\n",
      "epoch:20 step:16279 [D loss: 0.313885, acc: 93.75%] [G loss: 3.186829]\n",
      "epoch:20 step:16280 [D loss: 0.528651, acc: 79.69%] [G loss: 3.694674]\n",
      "epoch:20 step:16281 [D loss: 0.295731, acc: 96.88%] [G loss: 3.305212]\n",
      "epoch:20 step:16282 [D loss: 0.617465, acc: 66.41%] [G loss: 3.218270]\n",
      "epoch:20 step:16283 [D loss: 0.405626, acc: 89.84%] [G loss: 2.532663]\n",
      "epoch:20 step:16284 [D loss: 0.456021, acc: 78.12%] [G loss: 4.017900]\n",
      "epoch:20 step:16285 [D loss: 0.185472, acc: 100.00%] [G loss: 4.311354]\n",
      "epoch:20 step:16286 [D loss: 0.221122, acc: 98.44%] [G loss: 2.549962]\n",
      "epoch:20 step:16287 [D loss: 0.649711, acc: 64.06%] [G loss: 2.764785]\n",
      "epoch:20 step:16288 [D loss: 0.550270, acc: 64.84%] [G loss: 3.888887]\n",
      "epoch:20 step:16289 [D loss: 0.630078, acc: 61.72%] [G loss: 3.400103]\n",
      "epoch:20 step:16290 [D loss: 0.319482, acc: 96.09%] [G loss: 3.115997]\n",
      "epoch:20 step:16291 [D loss: 0.902944, acc: 51.56%] [G loss: 2.422518]\n",
      "epoch:20 step:16292 [D loss: 0.535223, acc: 71.88%] [G loss: 2.979258]\n",
      "epoch:20 step:16293 [D loss: 0.226208, acc: 98.44%] [G loss: 2.825882]\n",
      "epoch:20 step:16294 [D loss: 0.275642, acc: 96.09%] [G loss: 2.953569]\n",
      "epoch:20 step:16295 [D loss: 0.238556, acc: 94.53%] [G loss: 4.654541]\n",
      "epoch:20 step:16296 [D loss: 0.171168, acc: 100.00%] [G loss: 3.185450]\n",
      "epoch:20 step:16297 [D loss: 0.181740, acc: 96.88%] [G loss: 6.065607]\n",
      "epoch:20 step:16298 [D loss: 0.436170, acc: 77.34%] [G loss: 3.256258]\n",
      "epoch:20 step:16299 [D loss: 0.377401, acc: 92.19%] [G loss: 3.922967]\n",
      "epoch:20 step:16300 [D loss: 0.311936, acc: 94.53%] [G loss: 3.603922]\n",
      "epoch:20 step:16301 [D loss: 0.876568, acc: 47.66%] [G loss: 3.799701]\n",
      "epoch:20 step:16302 [D loss: 0.835275, acc: 53.12%] [G loss: 1.923409]\n",
      "epoch:20 step:16303 [D loss: 1.843021, acc: 8.59%] [G loss: 2.293119]\n",
      "epoch:20 step:16304 [D loss: 1.009582, acc: 50.78%] [G loss: 2.166912]\n",
      "epoch:20 step:16305 [D loss: 0.343514, acc: 92.97%] [G loss: 2.793953]\n",
      "epoch:20 step:16306 [D loss: 0.515567, acc: 75.00%] [G loss: 3.044960]\n",
      "epoch:20 step:16307 [D loss: 1.064843, acc: 39.06%] [G loss: 3.889229]\n",
      "epoch:20 step:16308 [D loss: 0.514819, acc: 79.69%] [G loss: 2.328824]\n",
      "epoch:20 step:16309 [D loss: 0.592515, acc: 69.53%] [G loss: 3.522288]\n",
      "epoch:20 step:16310 [D loss: 0.129388, acc: 100.00%] [G loss: 3.328549]\n",
      "epoch:20 step:16311 [D loss: 0.274642, acc: 87.50%] [G loss: 5.741904]\n",
      "epoch:20 step:16312 [D loss: 1.056269, acc: 35.16%] [G loss: 3.020931]\n",
      "epoch:20 step:16313 [D loss: 0.091784, acc: 100.00%] [G loss: 3.151126]\n",
      "epoch:20 step:16314 [D loss: 0.611962, acc: 64.06%] [G loss: 2.791987]\n",
      "epoch:20 step:16315 [D loss: 0.461018, acc: 78.12%] [G loss: 3.250257]\n",
      "epoch:20 step:16316 [D loss: 0.571648, acc: 60.16%] [G loss: 3.534316]\n",
      "epoch:20 step:16317 [D loss: 0.311341, acc: 89.84%] [G loss: 3.157763]\n",
      "epoch:20 step:16318 [D loss: 0.401849, acc: 91.41%] [G loss: 2.666545]\n",
      "epoch:20 step:16319 [D loss: 0.306481, acc: 92.19%] [G loss: 2.392251]\n",
      "epoch:20 step:16320 [D loss: 0.139173, acc: 100.00%] [G loss: 3.513958]\n",
      "epoch:20 step:16321 [D loss: 1.051241, acc: 34.38%] [G loss: 3.218013]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:20 step:16322 [D loss: 0.775073, acc: 52.34%] [G loss: 1.823177]\n",
      "epoch:20 step:16323 [D loss: 0.195701, acc: 94.53%] [G loss: 6.529095]\n",
      "epoch:20 step:16324 [D loss: 1.457952, acc: 7.81%] [G loss: 3.967106]\n",
      "epoch:20 step:16325 [D loss: 0.358518, acc: 92.19%] [G loss: 2.652466]\n",
      "epoch:20 step:16326 [D loss: 0.241255, acc: 98.44%] [G loss: 4.172039]\n",
      "epoch:20 step:16327 [D loss: 0.658177, acc: 63.28%] [G loss: 2.119659]\n",
      "epoch:20 step:16328 [D loss: 0.618964, acc: 58.59%] [G loss: 3.721612]\n",
      "epoch:20 step:16329 [D loss: 0.629281, acc: 63.28%] [G loss: 2.003285]\n",
      "epoch:20 step:16330 [D loss: 0.383998, acc: 90.62%] [G loss: 3.959075]\n",
      "epoch:20 step:16331 [D loss: 0.407862, acc: 85.16%] [G loss: 3.684393]\n",
      "epoch:20 step:16332 [D loss: 0.574652, acc: 62.50%] [G loss: 3.265704]\n",
      "epoch:20 step:16333 [D loss: 0.038801, acc: 100.00%] [G loss: 4.403531]\n",
      "epoch:20 step:16334 [D loss: 0.613399, acc: 59.38%] [G loss: 5.297396]\n",
      "epoch:20 step:16335 [D loss: 0.775158, acc: 51.56%] [G loss: 2.616755]\n",
      "epoch:20 step:16336 [D loss: 0.082127, acc: 100.00%] [G loss: 4.775047]\n",
      "epoch:20 step:16337 [D loss: 0.209889, acc: 98.44%] [G loss: 3.419685]\n",
      "epoch:20 step:16338 [D loss: 0.247227, acc: 96.88%] [G loss: 4.192255]\n",
      "epoch:20 step:16339 [D loss: 0.646335, acc: 60.94%] [G loss: 4.108994]\n",
      "epoch:20 step:16340 [D loss: 0.594032, acc: 60.94%] [G loss: 4.303179]\n",
      "epoch:20 step:16341 [D loss: 0.246784, acc: 93.75%] [G loss: 4.854019]\n",
      "epoch:20 step:16342 [D loss: 0.414551, acc: 75.78%] [G loss: 4.162351]\n",
      "epoch:20 step:16343 [D loss: 0.452790, acc: 81.25%] [G loss: 2.555950]\n",
      "epoch:20 step:16344 [D loss: 1.389606, acc: 8.59%] [G loss: 3.047914]\n",
      "epoch:20 step:16345 [D loss: 0.159440, acc: 99.22%] [G loss: 3.876275]\n",
      "epoch:20 step:16346 [D loss: 0.077470, acc: 100.00%] [G loss: 5.933916]\n",
      "epoch:20 step:16347 [D loss: 0.139472, acc: 100.00%] [G loss: 2.879107]\n",
      "epoch:20 step:16348 [D loss: 0.169305, acc: 100.00%] [G loss: 2.107502]\n",
      "epoch:20 step:16349 [D loss: 0.827133, acc: 50.00%] [G loss: 2.711019]\n",
      "epoch:20 step:16350 [D loss: 0.239024, acc: 94.53%] [G loss: 4.574465]\n",
      "epoch:20 step:16351 [D loss: 0.299269, acc: 93.75%] [G loss: 2.485431]\n",
      "epoch:20 step:16352 [D loss: 0.416594, acc: 78.12%] [G loss: 3.515172]\n",
      "epoch:20 step:16353 [D loss: 0.419907, acc: 87.50%] [G loss: 2.522151]\n",
      "epoch:20 step:16354 [D loss: 0.452327, acc: 81.25%] [G loss: 3.669718]\n",
      "epoch:20 step:16355 [D loss: 1.055307, acc: 50.00%] [G loss: 3.566991]\n",
      "epoch:20 step:16356 [D loss: 0.225289, acc: 98.44%] [G loss: 3.096404]\n",
      "epoch:20 step:16357 [D loss: 0.888421, acc: 51.56%] [G loss: 3.759340]\n",
      "epoch:20 step:16358 [D loss: 0.394661, acc: 93.75%] [G loss: 3.480690]\n",
      "epoch:20 step:16359 [D loss: 0.270932, acc: 98.44%] [G loss: 2.933578]\n",
      "epoch:20 step:16360 [D loss: 0.118138, acc: 100.00%] [G loss: 3.122622]\n",
      "epoch:20 step:16361 [D loss: 0.284678, acc: 93.75%] [G loss: 3.366675]\n",
      "epoch:20 step:16362 [D loss: 0.735176, acc: 55.47%] [G loss: 3.150094]\n",
      "epoch:20 step:16363 [D loss: 0.318249, acc: 90.62%] [G loss: 2.639267]\n",
      "epoch:20 step:16364 [D loss: 1.649121, acc: 3.91%] [G loss: 2.641502]\n",
      "epoch:20 step:16365 [D loss: 0.566169, acc: 71.88%] [G loss: 1.778212]\n",
      "epoch:20 step:16366 [D loss: 0.728501, acc: 60.16%] [G loss: 2.498951]\n",
      "epoch:20 step:16367 [D loss: 0.304346, acc: 93.75%] [G loss: 2.527822]\n",
      "epoch:20 step:16368 [D loss: 0.365559, acc: 87.50%] [G loss: 3.319448]\n",
      "epoch:20 step:16369 [D loss: 0.177483, acc: 97.66%] [G loss: 2.877141]\n",
      "epoch:20 step:16370 [D loss: 0.222062, acc: 100.00%] [G loss: 3.213162]\n",
      "epoch:20 step:16371 [D loss: 0.486948, acc: 74.22%] [G loss: 2.487845]\n",
      "epoch:20 step:16372 [D loss: 0.339810, acc: 92.19%] [G loss: 2.003922]\n",
      "epoch:20 step:16373 [D loss: 0.706760, acc: 59.38%] [G loss: 2.751278]\n",
      "epoch:20 step:16374 [D loss: 0.780271, acc: 55.47%] [G loss: 3.096797]\n",
      "epoch:20 step:16375 [D loss: 0.434326, acc: 85.94%] [G loss: 2.693084]\n",
      "epoch:20 step:16376 [D loss: 0.422348, acc: 79.69%] [G loss: 2.619692]\n",
      "epoch:20 step:16377 [D loss: 0.536541, acc: 75.00%] [G loss: 3.587459]\n",
      "epoch:20 step:16378 [D loss: 0.723789, acc: 56.25%] [G loss: 3.061033]\n",
      "epoch:20 step:16379 [D loss: 0.750605, acc: 50.00%] [G loss: 3.298728]\n",
      "epoch:20 step:16380 [D loss: 0.176658, acc: 100.00%] [G loss: 2.752041]\n",
      "epoch:20 step:16381 [D loss: 0.601281, acc: 57.81%] [G loss: 3.223141]\n",
      "epoch:20 step:16382 [D loss: 0.457451, acc: 66.41%] [G loss: 3.992861]\n",
      "epoch:20 step:16383 [D loss: 0.381241, acc: 78.12%] [G loss: 3.279509]\n",
      "epoch:20 step:16384 [D loss: 0.775906, acc: 53.12%] [G loss: 2.860165]\n",
      "epoch:20 step:16385 [D loss: 0.184347, acc: 98.44%] [G loss: 3.505284]\n",
      "epoch:20 step:16386 [D loss: 0.447747, acc: 80.47%] [G loss: 2.877449]\n",
      "epoch:20 step:16387 [D loss: 0.132765, acc: 100.00%] [G loss: 3.924954]\n",
      "epoch:20 step:16388 [D loss: 0.337994, acc: 96.88%] [G loss: 3.343410]\n",
      "epoch:20 step:16389 [D loss: 0.929039, acc: 47.66%] [G loss: 2.541337]\n",
      "epoch:20 step:16390 [D loss: 1.197299, acc: 46.09%] [G loss: 2.236788]\n",
      "epoch:20 step:16391 [D loss: 0.596185, acc: 60.94%] [G loss: 2.959223]\n",
      "epoch:20 step:16392 [D loss: 0.297468, acc: 97.66%] [G loss: 5.194945]\n",
      "epoch:20 step:16393 [D loss: 0.519686, acc: 64.06%] [G loss: 1.800513]\n",
      "epoch:20 step:16394 [D loss: 0.467356, acc: 64.84%] [G loss: 2.261945]\n",
      "epoch:20 step:16395 [D loss: 1.062589, acc: 21.88%] [G loss: 2.512523]\n",
      "epoch:20 step:16396 [D loss: 0.811108, acc: 39.06%] [G loss: 4.280672]\n",
      "epoch:20 step:16397 [D loss: 1.343654, acc: 10.16%] [G loss: 3.152817]\n",
      "epoch:20 step:16398 [D loss: 0.084619, acc: 99.22%] [G loss: 3.539704]\n",
      "epoch:20 step:16399 [D loss: 0.771341, acc: 48.44%] [G loss: 2.810240]\n",
      "epoch:20 step:16400 [D loss: 0.694933, acc: 56.25%] [G loss: 2.749404]\n",
      "##############\n",
      "[0.86744076 0.86752045 0.79815368 0.80965043 0.80549867 0.83341786\n",
      " 0.89426592 0.83150274 0.81504311 0.82444855]\n",
      "##########\n",
      "epoch:20 step:16401 [D loss: 0.974804, acc: 45.31%] [G loss: 1.733589]\n",
      "epoch:21 step:16402 [D loss: 0.097967, acc: 100.00%] [G loss: 3.088516]\n",
      "epoch:21 step:16403 [D loss: 0.449397, acc: 83.59%] [G loss: 2.995184]\n",
      "epoch:21 step:16404 [D loss: 0.722693, acc: 57.81%] [G loss: 3.426661]\n",
      "epoch:21 step:16405 [D loss: 0.445369, acc: 84.38%] [G loss: 1.787881]\n",
      "epoch:21 step:16406 [D loss: 0.277641, acc: 95.31%] [G loss: 2.337842]\n",
      "epoch:21 step:16407 [D loss: 0.326340, acc: 92.97%] [G loss: 2.308105]\n",
      "epoch:21 step:16408 [D loss: 0.241276, acc: 98.44%] [G loss: 2.835754]\n",
      "epoch:21 step:16409 [D loss: 0.346431, acc: 94.53%] [G loss: 3.239056]\n",
      "epoch:21 step:16410 [D loss: 0.334949, acc: 95.31%] [G loss: 2.969009]\n",
      "epoch:21 step:16411 [D loss: 0.309920, acc: 94.53%] [G loss: 3.536829]\n",
      "epoch:21 step:16412 [D loss: 0.141592, acc: 100.00%] [G loss: 3.287328]\n",
      "epoch:21 step:16413 [D loss: 0.672465, acc: 56.25%] [G loss: 2.948205]\n",
      "epoch:21 step:16414 [D loss: 0.444663, acc: 90.62%] [G loss: 4.326976]\n",
      "epoch:21 step:16415 [D loss: 0.473623, acc: 81.25%] [G loss: 3.495708]\n",
      "epoch:21 step:16416 [D loss: 0.429469, acc: 67.19%] [G loss: 3.513274]\n",
      "epoch:21 step:16417 [D loss: 0.542158, acc: 67.97%] [G loss: 2.442242]\n",
      "epoch:21 step:16418 [D loss: 0.216895, acc: 98.44%] [G loss: 3.078020]\n",
      "epoch:21 step:16419 [D loss: 0.656139, acc: 55.47%] [G loss: 4.256128]\n",
      "epoch:21 step:16420 [D loss: 0.289386, acc: 97.66%] [G loss: 2.725427]\n",
      "epoch:21 step:16421 [D loss: 0.542504, acc: 75.78%] [G loss: 2.804533]\n",
      "epoch:21 step:16422 [D loss: 0.328300, acc: 94.53%] [G loss: 2.240479]\n",
      "epoch:21 step:16423 [D loss: 0.561659, acc: 67.97%] [G loss: 2.097245]\n",
      "epoch:21 step:16424 [D loss: 0.367249, acc: 90.62%] [G loss: 2.504290]\n",
      "epoch:21 step:16425 [D loss: 0.646265, acc: 65.62%] [G loss: 3.414686]\n",
      "epoch:21 step:16426 [D loss: 0.926679, acc: 25.78%] [G loss: 2.630492]\n",
      "epoch:21 step:16427 [D loss: 0.169478, acc: 100.00%] [G loss: 2.972720]\n",
      "epoch:21 step:16428 [D loss: 0.275971, acc: 95.31%] [G loss: 2.841908]\n",
      "epoch:21 step:16429 [D loss: 0.310374, acc: 90.62%] [G loss: 2.539592]\n",
      "epoch:21 step:16430 [D loss: 0.418955, acc: 81.25%] [G loss: 3.934357]\n",
      "epoch:21 step:16431 [D loss: 0.210028, acc: 100.00%] [G loss: 3.751668]\n",
      "epoch:21 step:16432 [D loss: 0.325892, acc: 92.97%] [G loss: 2.146991]\n",
      "epoch:21 step:16433 [D loss: 0.395428, acc: 93.75%] [G loss: 3.485566]\n",
      "epoch:21 step:16434 [D loss: 0.808099, acc: 43.75%] [G loss: 3.547047]\n",
      "epoch:21 step:16435 [D loss: 0.328078, acc: 90.62%] [G loss: 3.284557]\n",
      "epoch:21 step:16436 [D loss: 0.236379, acc: 99.22%] [G loss: 2.828298]\n",
      "epoch:21 step:16437 [D loss: 0.554365, acc: 63.28%] [G loss: 3.465982]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:21 step:16438 [D loss: 0.063169, acc: 100.00%] [G loss: 3.411610]\n",
      "epoch:21 step:16439 [D loss: 0.968943, acc: 48.44%] [G loss: 1.937004]\n",
      "epoch:21 step:16440 [D loss: 0.970319, acc: 44.53%] [G loss: 2.616493]\n",
      "epoch:21 step:16441 [D loss: 0.754297, acc: 50.00%] [G loss: 2.821454]\n",
      "epoch:21 step:16442 [D loss: 0.546449, acc: 71.09%] [G loss: 3.127215]\n",
      "epoch:21 step:16443 [D loss: 0.355310, acc: 92.19%] [G loss: 3.693801]\n",
      "epoch:21 step:16444 [D loss: 1.094790, acc: 17.19%] [G loss: 2.258130]\n",
      "epoch:21 step:16445 [D loss: 0.688820, acc: 60.16%] [G loss: 2.795504]\n",
      "epoch:21 step:16446 [D loss: 0.829039, acc: 46.09%] [G loss: 1.802325]\n",
      "epoch:21 step:16447 [D loss: 0.326243, acc: 93.75%] [G loss: 2.776073]\n",
      "epoch:21 step:16448 [D loss: 0.885247, acc: 50.00%] [G loss: 2.459473]\n",
      "epoch:21 step:16449 [D loss: 0.143354, acc: 99.22%] [G loss: 3.025860]\n",
      "epoch:21 step:16450 [D loss: 0.771401, acc: 52.34%] [G loss: 3.166867]\n",
      "epoch:21 step:16451 [D loss: 0.412267, acc: 85.16%] [G loss: 2.848617]\n",
      "epoch:21 step:16452 [D loss: 0.569625, acc: 69.53%] [G loss: 1.641736]\n",
      "epoch:21 step:16453 [D loss: 0.237382, acc: 100.00%] [G loss: 3.198825]\n",
      "epoch:21 step:16454 [D loss: 0.456407, acc: 75.78%] [G loss: 3.198472]\n",
      "epoch:21 step:16455 [D loss: 0.917240, acc: 52.34%] [G loss: 2.290005]\n",
      "epoch:21 step:16456 [D loss: 1.417492, acc: 18.75%] [G loss: 2.847744]\n",
      "epoch:21 step:16457 [D loss: 1.161888, acc: 23.44%] [G loss: 1.885815]\n",
      "epoch:21 step:16458 [D loss: 0.265589, acc: 96.88%] [G loss: 2.860114]\n",
      "epoch:21 step:16459 [D loss: 0.314349, acc: 88.28%] [G loss: 5.042770]\n",
      "epoch:21 step:16460 [D loss: 0.889502, acc: 50.00%] [G loss: 3.339889]\n",
      "epoch:21 step:16461 [D loss: 0.508932, acc: 71.88%] [G loss: 2.519647]\n",
      "epoch:21 step:16462 [D loss: 1.587909, acc: 1.56%] [G loss: 2.708359]\n",
      "epoch:21 step:16463 [D loss: 0.233956, acc: 99.22%] [G loss: 3.921289]\n",
      "epoch:21 step:16464 [D loss: 0.173981, acc: 98.44%] [G loss: 4.146110]\n",
      "epoch:21 step:16465 [D loss: 0.592121, acc: 71.09%] [G loss: 2.649702]\n",
      "epoch:21 step:16466 [D loss: 0.421840, acc: 89.06%] [G loss: 3.130310]\n",
      "epoch:21 step:16467 [D loss: 0.354138, acc: 84.38%] [G loss: 3.065635]\n",
      "epoch:21 step:16468 [D loss: 1.136895, acc: 12.50%] [G loss: 3.614603]\n",
      "epoch:21 step:16469 [D loss: 0.331657, acc: 92.97%] [G loss: 2.724541]\n",
      "epoch:21 step:16470 [D loss: 0.420732, acc: 78.12%] [G loss: 3.734221]\n",
      "epoch:21 step:16471 [D loss: 0.326109, acc: 84.38%] [G loss: 2.408613]\n",
      "epoch:21 step:16472 [D loss: 0.606363, acc: 61.72%] [G loss: 1.844645]\n",
      "epoch:21 step:16473 [D loss: 0.636493, acc: 63.28%] [G loss: 3.306246]\n",
      "epoch:21 step:16474 [D loss: 0.392917, acc: 93.75%] [G loss: 3.111294]\n",
      "epoch:21 step:16475 [D loss: 0.387292, acc: 82.03%] [G loss: 4.463881]\n",
      "epoch:21 step:16476 [D loss: 0.231387, acc: 100.00%] [G loss: 3.720679]\n",
      "epoch:21 step:16477 [D loss: 0.737933, acc: 49.22%] [G loss: 3.060185]\n",
      "epoch:21 step:16478 [D loss: 0.486886, acc: 74.22%] [G loss: 3.824035]\n",
      "epoch:21 step:16479 [D loss: 0.230556, acc: 99.22%] [G loss: 3.273535]\n",
      "epoch:21 step:16480 [D loss: 0.379544, acc: 90.62%] [G loss: 2.277605]\n",
      "epoch:21 step:16481 [D loss: 0.338682, acc: 94.53%] [G loss: 2.128436]\n",
      "epoch:21 step:16482 [D loss: 0.195001, acc: 99.22%] [G loss: 2.570471]\n",
      "epoch:21 step:16483 [D loss: 0.325765, acc: 94.53%] [G loss: 1.796852]\n",
      "epoch:21 step:16484 [D loss: 0.352761, acc: 82.03%] [G loss: 4.301319]\n",
      "epoch:21 step:16485 [D loss: 0.854162, acc: 46.09%] [G loss: 3.912472]\n",
      "epoch:21 step:16486 [D loss: 0.222868, acc: 99.22%] [G loss: 3.523949]\n",
      "epoch:21 step:16487 [D loss: 0.453467, acc: 77.34%] [G loss: 2.739682]\n",
      "epoch:21 step:16488 [D loss: 0.431866, acc: 85.16%] [G loss: 2.208172]\n",
      "epoch:21 step:16489 [D loss: 0.557821, acc: 66.41%] [G loss: 2.526825]\n",
      "epoch:21 step:16490 [D loss: 0.081989, acc: 100.00%] [G loss: 2.548775]\n",
      "epoch:21 step:16491 [D loss: 0.601085, acc: 60.16%] [G loss: 4.169432]\n",
      "epoch:21 step:16492 [D loss: 0.461608, acc: 80.47%] [G loss: 2.555239]\n",
      "epoch:21 step:16493 [D loss: 0.188054, acc: 100.00%] [G loss: 4.106517]\n",
      "epoch:21 step:16494 [D loss: 0.364701, acc: 86.72%] [G loss: 3.460759]\n",
      "epoch:21 step:16495 [D loss: 0.530126, acc: 76.56%] [G loss: 3.692413]\n",
      "epoch:21 step:16496 [D loss: 0.237856, acc: 98.44%] [G loss: 3.309639]\n",
      "epoch:21 step:16497 [D loss: 0.318918, acc: 94.53%] [G loss: 2.684112]\n",
      "epoch:21 step:16498 [D loss: 0.663380, acc: 59.38%] [G loss: 2.272973]\n",
      "epoch:21 step:16499 [D loss: 0.313357, acc: 96.09%] [G loss: 4.933170]\n",
      "epoch:21 step:16500 [D loss: 0.170753, acc: 98.44%] [G loss: 4.337740]\n",
      "epoch:21 step:16501 [D loss: 1.141705, acc: 17.97%] [G loss: 3.976311]\n",
      "epoch:21 step:16502 [D loss: 0.595969, acc: 61.72%] [G loss: 3.461358]\n",
      "epoch:21 step:16503 [D loss: 0.280163, acc: 92.97%] [G loss: 4.050810]\n",
      "epoch:21 step:16504 [D loss: 0.808955, acc: 47.66%] [G loss: 3.595940]\n",
      "epoch:21 step:16505 [D loss: 0.311797, acc: 89.84%] [G loss: 3.621481]\n",
      "epoch:21 step:16506 [D loss: 0.942091, acc: 32.81%] [G loss: 3.432657]\n",
      "epoch:21 step:16507 [D loss: 0.171089, acc: 100.00%] [G loss: 3.475952]\n",
      "epoch:21 step:16508 [D loss: 1.150553, acc: 44.53%] [G loss: 2.042828]\n",
      "epoch:21 step:16509 [D loss: 0.230849, acc: 95.31%] [G loss: 1.720465]\n",
      "epoch:21 step:16510 [D loss: 0.334848, acc: 89.06%] [G loss: 2.022931]\n",
      "epoch:21 step:16511 [D loss: 0.424321, acc: 89.84%] [G loss: 2.324154]\n",
      "epoch:21 step:16512 [D loss: 0.448719, acc: 68.75%] [G loss: 3.593739]\n",
      "epoch:21 step:16513 [D loss: 0.429235, acc: 90.62%] [G loss: 4.379758]\n",
      "epoch:21 step:16514 [D loss: 0.327706, acc: 87.50%] [G loss: 3.764468]\n",
      "epoch:21 step:16515 [D loss: 0.899849, acc: 24.22%] [G loss: 2.353963]\n",
      "epoch:21 step:16516 [D loss: 1.160656, acc: 38.28%] [G loss: 3.973574]\n",
      "epoch:21 step:16517 [D loss: 0.424357, acc: 74.22%] [G loss: 3.015827]\n",
      "epoch:21 step:16518 [D loss: 0.606313, acc: 67.97%] [G loss: 4.669890]\n",
      "epoch:21 step:16519 [D loss: 0.043153, acc: 100.00%] [G loss: 4.155731]\n",
      "epoch:21 step:16520 [D loss: 0.523461, acc: 68.75%] [G loss: 2.271081]\n",
      "epoch:21 step:16521 [D loss: 0.663515, acc: 59.38%] [G loss: 4.064534]\n",
      "epoch:21 step:16522 [D loss: 0.464877, acc: 65.62%] [G loss: 3.745830]\n",
      "epoch:21 step:16523 [D loss: 0.729280, acc: 55.47%] [G loss: 2.516560]\n",
      "epoch:21 step:16524 [D loss: 0.278907, acc: 98.44%] [G loss: 3.014617]\n",
      "epoch:21 step:16525 [D loss: 1.782428, acc: 1.56%] [G loss: 3.552218]\n",
      "epoch:21 step:16526 [D loss: 0.595574, acc: 64.84%] [G loss: 1.880848]\n",
      "epoch:21 step:16527 [D loss: 0.549634, acc: 70.31%] [G loss: 2.521732]\n",
      "epoch:21 step:16528 [D loss: 0.354871, acc: 83.59%] [G loss: 3.345477]\n",
      "epoch:21 step:16529 [D loss: 0.884072, acc: 37.50%] [G loss: 3.653002]\n",
      "epoch:21 step:16530 [D loss: 0.155000, acc: 98.44%] [G loss: 5.288456]\n",
      "epoch:21 step:16531 [D loss: 0.420591, acc: 82.03%] [G loss: 2.280572]\n",
      "epoch:21 step:16532 [D loss: 0.079463, acc: 99.22%] [G loss: 3.870792]\n",
      "epoch:21 step:16533 [D loss: 0.248129, acc: 97.66%] [G loss: 3.892543]\n",
      "epoch:21 step:16534 [D loss: 0.817883, acc: 52.34%] [G loss: 2.661494]\n",
      "epoch:21 step:16535 [D loss: 0.367537, acc: 84.38%] [G loss: 2.709807]\n",
      "epoch:21 step:16536 [D loss: 0.349175, acc: 87.50%] [G loss: 2.127073]\n",
      "epoch:21 step:16537 [D loss: 0.360931, acc: 92.97%] [G loss: 3.929997]\n",
      "epoch:21 step:16538 [D loss: 0.249341, acc: 97.66%] [G loss: 2.690018]\n",
      "epoch:21 step:16539 [D loss: 0.123244, acc: 99.22%] [G loss: 2.888153]\n",
      "epoch:21 step:16540 [D loss: 0.195969, acc: 98.44%] [G loss: 4.124335]\n",
      "epoch:21 step:16541 [D loss: 0.566481, acc: 71.09%] [G loss: 3.246480]\n",
      "epoch:21 step:16542 [D loss: 0.491409, acc: 82.03%] [G loss: 1.723490]\n",
      "epoch:21 step:16543 [D loss: 0.953814, acc: 50.78%] [G loss: 2.370809]\n",
      "epoch:21 step:16544 [D loss: 0.375560, acc: 78.91%] [G loss: 2.484030]\n",
      "epoch:21 step:16545 [D loss: 0.654534, acc: 62.50%] [G loss: 3.573348]\n",
      "epoch:21 step:16546 [D loss: 1.098532, acc: 28.12%] [G loss: 2.952266]\n",
      "epoch:21 step:16547 [D loss: 0.309639, acc: 95.31%] [G loss: 2.689579]\n",
      "epoch:21 step:16548 [D loss: 0.383199, acc: 75.78%] [G loss: 2.984272]\n",
      "epoch:21 step:16549 [D loss: 0.548679, acc: 67.19%] [G loss: 3.964654]\n",
      "epoch:21 step:16550 [D loss: 0.298037, acc: 96.09%] [G loss: 3.552212]\n",
      "epoch:21 step:16551 [D loss: 0.517292, acc: 81.25%] [G loss: 2.116936]\n",
      "epoch:21 step:16552 [D loss: 0.946677, acc: 45.31%] [G loss: 2.289016]\n",
      "epoch:21 step:16553 [D loss: 0.259887, acc: 97.66%] [G loss: 3.801356]\n",
      "epoch:21 step:16554 [D loss: 0.153004, acc: 99.22%] [G loss: 4.003547]\n",
      "epoch:21 step:16555 [D loss: 0.486466, acc: 84.38%] [G loss: 2.883817]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:21 step:16556 [D loss: 0.706276, acc: 53.91%] [G loss: 2.369986]\n",
      "epoch:21 step:16557 [D loss: 0.621081, acc: 64.84%] [G loss: 3.070261]\n",
      "epoch:21 step:16558 [D loss: 0.173087, acc: 96.88%] [G loss: 4.351820]\n",
      "epoch:21 step:16559 [D loss: 0.600462, acc: 63.28%] [G loss: 3.738834]\n",
      "epoch:21 step:16560 [D loss: 0.135544, acc: 100.00%] [G loss: 5.267083]\n",
      "epoch:21 step:16561 [D loss: 0.458992, acc: 86.72%] [G loss: 3.043104]\n",
      "epoch:21 step:16562 [D loss: 0.168028, acc: 99.22%] [G loss: 3.926553]\n",
      "epoch:21 step:16563 [D loss: 0.270023, acc: 90.62%] [G loss: 4.648361]\n",
      "epoch:21 step:16564 [D loss: 0.411606, acc: 82.03%] [G loss: 2.967202]\n",
      "epoch:21 step:16565 [D loss: 0.239935, acc: 99.22%] [G loss: 2.767045]\n",
      "epoch:21 step:16566 [D loss: 0.241394, acc: 99.22%] [G loss: 2.382656]\n",
      "epoch:21 step:16567 [D loss: 1.008238, acc: 51.56%] [G loss: 3.479838]\n",
      "epoch:21 step:16568 [D loss: 0.691918, acc: 57.03%] [G loss: 2.329677]\n",
      "epoch:21 step:16569 [D loss: 0.422386, acc: 86.72%] [G loss: 2.784963]\n",
      "epoch:21 step:16570 [D loss: 0.416580, acc: 92.19%] [G loss: 2.609444]\n",
      "epoch:21 step:16571 [D loss: 0.422523, acc: 92.97%] [G loss: 3.076881]\n",
      "epoch:21 step:16572 [D loss: 0.442717, acc: 87.50%] [G loss: 4.082997]\n",
      "epoch:21 step:16573 [D loss: 0.521365, acc: 76.56%] [G loss: 3.629205]\n",
      "epoch:21 step:16574 [D loss: 0.481441, acc: 73.44%] [G loss: 2.789916]\n",
      "epoch:21 step:16575 [D loss: 0.464733, acc: 67.19%] [G loss: 2.897954]\n",
      "epoch:21 step:16576 [D loss: 0.671496, acc: 64.84%] [G loss: 2.446234]\n",
      "epoch:21 step:16577 [D loss: 0.620671, acc: 60.16%] [G loss: 3.786651]\n",
      "epoch:21 step:16578 [D loss: 0.766957, acc: 53.91%] [G loss: 2.638151]\n",
      "epoch:21 step:16579 [D loss: 0.501812, acc: 78.91%] [G loss: 2.154420]\n",
      "epoch:21 step:16580 [D loss: 0.787338, acc: 53.12%] [G loss: 2.903940]\n",
      "epoch:21 step:16581 [D loss: 0.818134, acc: 45.31%] [G loss: 2.797390]\n",
      "epoch:21 step:16582 [D loss: 0.323001, acc: 94.53%] [G loss: 1.572118]\n",
      "epoch:21 step:16583 [D loss: 0.553459, acc: 65.62%] [G loss: 2.622724]\n",
      "epoch:21 step:16584 [D loss: 0.396391, acc: 74.22%] [G loss: 2.180209]\n",
      "epoch:21 step:16585 [D loss: 0.700276, acc: 63.28%] [G loss: 4.637840]\n",
      "epoch:21 step:16586 [D loss: 0.531847, acc: 62.50%] [G loss: 3.100155]\n",
      "epoch:21 step:16587 [D loss: 0.167328, acc: 98.44%] [G loss: 3.440561]\n",
      "epoch:21 step:16588 [D loss: 0.046026, acc: 100.00%] [G loss: 4.708908]\n",
      "epoch:21 step:16589 [D loss: 0.334359, acc: 87.50%] [G loss: 2.524346]\n",
      "epoch:21 step:16590 [D loss: 0.150586, acc: 100.00%] [G loss: 4.825193]\n",
      "epoch:21 step:16591 [D loss: 0.466875, acc: 80.47%] [G loss: 3.416596]\n",
      "epoch:21 step:16592 [D loss: 0.355490, acc: 92.97%] [G loss: 3.347632]\n",
      "epoch:21 step:16593 [D loss: 1.003973, acc: 35.94%] [G loss: 3.918099]\n",
      "epoch:21 step:16594 [D loss: 0.469302, acc: 82.81%] [G loss: 3.324503]\n",
      "epoch:21 step:16595 [D loss: 0.443808, acc: 75.00%] [G loss: 2.572383]\n",
      "epoch:21 step:16596 [D loss: 0.671174, acc: 59.38%] [G loss: 3.616044]\n",
      "epoch:21 step:16597 [D loss: 0.243254, acc: 98.44%] [G loss: 3.437825]\n",
      "epoch:21 step:16598 [D loss: 0.482603, acc: 76.56%] [G loss: 3.201039]\n",
      "epoch:21 step:16599 [D loss: 0.474145, acc: 82.81%] [G loss: 1.163706]\n",
      "epoch:21 step:16600 [D loss: 0.260597, acc: 99.22%] [G loss: 3.782322]\n",
      "##############\n",
      "[0.86343558 0.87314979 0.81898022 0.83088325 0.78743136 0.81040267\n",
      " 0.89092716 0.81383622 0.83061567 0.83587701]\n",
      "##########\n",
      "epoch:21 step:16601 [D loss: 0.170511, acc: 96.88%] [G loss: 3.608152]\n",
      "epoch:21 step:16602 [D loss: 0.242060, acc: 96.88%] [G loss: 3.590912]\n",
      "epoch:21 step:16603 [D loss: 0.771602, acc: 46.88%] [G loss: 2.509130]\n",
      "epoch:21 step:16604 [D loss: 0.726162, acc: 54.69%] [G loss: 2.299494]\n",
      "epoch:21 step:16605 [D loss: 0.276137, acc: 96.88%] [G loss: 3.767062]\n",
      "epoch:21 step:16606 [D loss: 1.529635, acc: 6.25%] [G loss: 2.687171]\n",
      "epoch:21 step:16607 [D loss: 0.405404, acc: 90.62%] [G loss: 4.569950]\n",
      "epoch:21 step:16608 [D loss: 0.513944, acc: 65.62%] [G loss: 4.086686]\n",
      "epoch:21 step:16609 [D loss: 0.485412, acc: 66.41%] [G loss: 4.854035]\n",
      "epoch:21 step:16610 [D loss: 0.570353, acc: 73.44%] [G loss: 2.628871]\n",
      "epoch:21 step:16611 [D loss: 0.603750, acc: 69.53%] [G loss: 3.156096]\n",
      "epoch:21 step:16612 [D loss: 0.238131, acc: 98.44%] [G loss: 3.300708]\n",
      "epoch:21 step:16613 [D loss: 0.203350, acc: 99.22%] [G loss: 4.147297]\n",
      "epoch:21 step:16614 [D loss: 0.593418, acc: 60.94%] [G loss: 2.315920]\n",
      "epoch:21 step:16615 [D loss: 0.277994, acc: 92.19%] [G loss: 6.136026]\n",
      "epoch:21 step:16616 [D loss: 0.224875, acc: 99.22%] [G loss: 2.935719]\n",
      "epoch:21 step:16617 [D loss: 1.151851, acc: 28.12%] [G loss: 2.957295]\n",
      "epoch:21 step:16618 [D loss: 0.581956, acc: 67.97%] [G loss: 3.246412]\n",
      "epoch:21 step:16619 [D loss: 0.395768, acc: 88.28%] [G loss: 3.428063]\n",
      "epoch:21 step:16620 [D loss: 0.196039, acc: 98.44%] [G loss: 3.874484]\n",
      "epoch:21 step:16621 [D loss: 0.644913, acc: 60.16%] [G loss: 2.792711]\n",
      "epoch:21 step:16622 [D loss: 0.515634, acc: 75.78%] [G loss: 4.338707]\n",
      "epoch:21 step:16623 [D loss: 0.386467, acc: 83.59%] [G loss: 3.649631]\n",
      "epoch:21 step:16624 [D loss: 0.837507, acc: 39.84%] [G loss: 3.425526]\n",
      "epoch:21 step:16625 [D loss: 0.751360, acc: 51.56%] [G loss: 2.315468]\n",
      "epoch:21 step:16626 [D loss: 0.225723, acc: 98.44%] [G loss: 2.983061]\n",
      "epoch:21 step:16627 [D loss: 0.351638, acc: 94.53%] [G loss: 4.565488]\n",
      "epoch:21 step:16628 [D loss: 0.383825, acc: 90.62%] [G loss: 3.733334]\n",
      "epoch:21 step:16629 [D loss: 0.199290, acc: 98.44%] [G loss: 3.440017]\n",
      "epoch:21 step:16630 [D loss: 0.241225, acc: 100.00%] [G loss: 2.342186]\n",
      "epoch:21 step:16631 [D loss: 1.144198, acc: 16.41%] [G loss: 4.084828]\n",
      "epoch:21 step:16632 [D loss: 0.104934, acc: 97.66%] [G loss: 2.886779]\n",
      "epoch:21 step:16633 [D loss: 0.373411, acc: 95.31%] [G loss: 2.290640]\n",
      "epoch:21 step:16634 [D loss: 0.223666, acc: 98.44%] [G loss: 3.802632]\n",
      "epoch:21 step:16635 [D loss: 0.661654, acc: 53.12%] [G loss: 3.969527]\n",
      "epoch:21 step:16636 [D loss: 0.512500, acc: 67.19%] [G loss: 2.697527]\n",
      "epoch:21 step:16637 [D loss: 0.382841, acc: 87.50%] [G loss: 3.197063]\n",
      "epoch:21 step:16638 [D loss: 0.612051, acc: 69.53%] [G loss: 2.566452]\n",
      "epoch:21 step:16639 [D loss: 0.460892, acc: 84.38%] [G loss: 3.123489]\n",
      "epoch:21 step:16640 [D loss: 0.938146, acc: 44.53%] [G loss: 2.836108]\n",
      "epoch:21 step:16641 [D loss: 0.424995, acc: 78.12%] [G loss: 3.083487]\n",
      "epoch:21 step:16642 [D loss: 0.838328, acc: 50.00%] [G loss: 3.343455]\n",
      "epoch:21 step:16643 [D loss: 0.599873, acc: 69.53%] [G loss: 3.859898]\n",
      "epoch:21 step:16644 [D loss: 0.259963, acc: 98.44%] [G loss: 5.045449]\n",
      "epoch:21 step:16645 [D loss: 0.795515, acc: 51.56%] [G loss: 2.457851]\n",
      "epoch:21 step:16646 [D loss: 1.572041, acc: 32.81%] [G loss: 1.641788]\n",
      "epoch:21 step:16647 [D loss: 0.722578, acc: 53.12%] [G loss: 2.570174]\n",
      "epoch:21 step:16648 [D loss: 1.077412, acc: 21.09%] [G loss: 2.478898]\n",
      "epoch:21 step:16649 [D loss: 1.200562, acc: 18.75%] [G loss: 2.453594]\n",
      "epoch:21 step:16650 [D loss: 0.348607, acc: 95.31%] [G loss: 3.224816]\n",
      "epoch:21 step:16651 [D loss: 0.199442, acc: 97.66%] [G loss: 2.613558]\n",
      "epoch:21 step:16652 [D loss: 0.480729, acc: 68.75%] [G loss: 3.662099]\n",
      "epoch:21 step:16653 [D loss: 0.470654, acc: 71.09%] [G loss: 3.456038]\n",
      "epoch:21 step:16654 [D loss: 0.419032, acc: 80.47%] [G loss: 2.411770]\n",
      "epoch:21 step:16655 [D loss: 1.011071, acc: 41.41%] [G loss: 3.429344]\n",
      "epoch:21 step:16656 [D loss: 0.210505, acc: 99.22%] [G loss: 3.134521]\n",
      "epoch:21 step:16657 [D loss: 0.363771, acc: 89.06%] [G loss: 2.626631]\n",
      "epoch:21 step:16658 [D loss: 0.972299, acc: 21.09%] [G loss: 2.164223]\n",
      "epoch:21 step:16659 [D loss: 0.197385, acc: 99.22%] [G loss: 4.385233]\n",
      "epoch:21 step:16660 [D loss: 0.435563, acc: 91.41%] [G loss: 3.007737]\n",
      "epoch:21 step:16661 [D loss: 0.608513, acc: 71.88%] [G loss: 2.722645]\n",
      "epoch:21 step:16662 [D loss: 0.635077, acc: 67.97%] [G loss: 2.883746]\n",
      "epoch:21 step:16663 [D loss: 0.440726, acc: 84.38%] [G loss: 4.354407]\n",
      "epoch:21 step:16664 [D loss: 0.351150, acc: 83.59%] [G loss: 3.856730]\n",
      "epoch:21 step:16665 [D loss: 0.659903, acc: 62.50%] [G loss: 2.358389]\n",
      "epoch:21 step:16666 [D loss: 0.344114, acc: 92.19%] [G loss: 3.346255]\n",
      "epoch:21 step:16667 [D loss: 0.441133, acc: 82.03%] [G loss: 3.017795]\n",
      "epoch:21 step:16668 [D loss: 1.356819, acc: 4.69%] [G loss: 2.858084]\n",
      "epoch:21 step:16669 [D loss: 0.247182, acc: 92.97%] [G loss: 2.890016]\n",
      "epoch:21 step:16670 [D loss: 0.579558, acc: 60.16%] [G loss: 2.022266]\n",
      "epoch:21 step:16671 [D loss: 0.331860, acc: 90.62%] [G loss: 3.047292]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:21 step:16672 [D loss: 0.314227, acc: 88.28%] [G loss: 3.174324]\n",
      "epoch:21 step:16673 [D loss: 0.691137, acc: 51.56%] [G loss: 2.859164]\n",
      "epoch:21 step:16674 [D loss: 0.918041, acc: 50.78%] [G loss: 3.947085]\n",
      "epoch:21 step:16675 [D loss: 0.902231, acc: 31.25%] [G loss: 4.492062]\n",
      "epoch:21 step:16676 [D loss: 0.640821, acc: 63.28%] [G loss: 1.876366]\n",
      "epoch:21 step:16677 [D loss: 0.356079, acc: 92.19%] [G loss: 4.125595]\n",
      "epoch:21 step:16678 [D loss: 0.404466, acc: 82.81%] [G loss: 2.493017]\n",
      "epoch:21 step:16679 [D loss: 0.455141, acc: 88.28%] [G loss: 3.707900]\n",
      "epoch:21 step:16680 [D loss: 0.476203, acc: 87.50%] [G loss: 4.218367]\n",
      "epoch:21 step:16681 [D loss: 0.358902, acc: 93.75%] [G loss: 2.250085]\n",
      "epoch:21 step:16682 [D loss: 1.055317, acc: 46.09%] [G loss: 2.272372]\n",
      "epoch:21 step:16683 [D loss: 0.644994, acc: 60.94%] [G loss: 2.605926]\n",
      "epoch:21 step:16684 [D loss: 0.216039, acc: 98.44%] [G loss: 4.680371]\n",
      "epoch:21 step:16685 [D loss: 0.323756, acc: 95.31%] [G loss: 3.389536]\n",
      "epoch:21 step:16686 [D loss: 0.883632, acc: 38.28%] [G loss: 2.175602]\n",
      "epoch:21 step:16687 [D loss: 0.474531, acc: 67.19%] [G loss: 3.062126]\n",
      "epoch:21 step:16688 [D loss: 0.218287, acc: 94.53%] [G loss: 2.627043]\n",
      "epoch:21 step:16689 [D loss: 1.282081, acc: 43.75%] [G loss: 2.263790]\n",
      "epoch:21 step:16690 [D loss: 0.666240, acc: 62.50%] [G loss: 4.457163]\n",
      "epoch:21 step:16691 [D loss: 0.465848, acc: 81.25%] [G loss: 2.907619]\n",
      "epoch:21 step:16692 [D loss: 1.176613, acc: 42.97%] [G loss: 3.556986]\n",
      "epoch:21 step:16693 [D loss: 0.518040, acc: 67.97%] [G loss: 4.922606]\n",
      "epoch:21 step:16694 [D loss: 0.693240, acc: 57.81%] [G loss: 3.530035]\n",
      "epoch:21 step:16695 [D loss: 0.835120, acc: 50.00%] [G loss: 3.251569]\n",
      "epoch:21 step:16696 [D loss: 0.402811, acc: 89.06%] [G loss: 2.812238]\n",
      "epoch:21 step:16697 [D loss: 0.190346, acc: 100.00%] [G loss: 3.879599]\n",
      "epoch:21 step:16698 [D loss: 0.399697, acc: 89.84%] [G loss: 2.442708]\n",
      "epoch:21 step:16699 [D loss: 0.289187, acc: 95.31%] [G loss: 2.530729]\n",
      "epoch:21 step:16700 [D loss: 0.341755, acc: 92.97%] [G loss: 2.533862]\n",
      "epoch:21 step:16701 [D loss: 0.365026, acc: 86.72%] [G loss: 2.759761]\n",
      "epoch:21 step:16702 [D loss: 0.302324, acc: 95.31%] [G loss: 2.786205]\n",
      "epoch:21 step:16703 [D loss: 0.747895, acc: 53.91%] [G loss: 2.783277]\n",
      "epoch:21 step:16704 [D loss: 0.668942, acc: 57.03%] [G loss: 2.368920]\n",
      "epoch:21 step:16705 [D loss: 0.109435, acc: 100.00%] [G loss: 4.789252]\n",
      "epoch:21 step:16706 [D loss: 0.158556, acc: 99.22%] [G loss: 3.943680]\n",
      "epoch:21 step:16707 [D loss: 0.221618, acc: 98.44%] [G loss: 2.179401]\n",
      "epoch:21 step:16708 [D loss: 0.632047, acc: 56.25%] [G loss: 4.121217]\n",
      "epoch:21 step:16709 [D loss: 0.641830, acc: 57.81%] [G loss: 3.347011]\n",
      "epoch:21 step:16710 [D loss: 0.415286, acc: 86.72%] [G loss: 2.535470]\n",
      "epoch:21 step:16711 [D loss: 0.274087, acc: 96.88%] [G loss: 4.317486]\n",
      "epoch:21 step:16712 [D loss: 0.540340, acc: 60.16%] [G loss: 3.460588]\n",
      "epoch:21 step:16713 [D loss: 0.680516, acc: 58.59%] [G loss: 2.427973]\n",
      "epoch:21 step:16714 [D loss: 0.196547, acc: 98.44%] [G loss: 3.016479]\n",
      "epoch:21 step:16715 [D loss: 0.360383, acc: 89.06%] [G loss: 2.759424]\n",
      "epoch:21 step:16716 [D loss: 0.508516, acc: 71.88%] [G loss: 3.587130]\n",
      "epoch:21 step:16717 [D loss: 0.880144, acc: 47.66%] [G loss: 1.995626]\n",
      "epoch:21 step:16718 [D loss: 0.243454, acc: 96.88%] [G loss: 4.087450]\n",
      "epoch:21 step:16719 [D loss: 0.690734, acc: 57.81%] [G loss: 3.029504]\n",
      "epoch:21 step:16720 [D loss: 0.630223, acc: 61.72%] [G loss: 2.847023]\n",
      "epoch:21 step:16721 [D loss: 0.413013, acc: 81.25%] [G loss: 3.543414]\n",
      "epoch:21 step:16722 [D loss: 0.658524, acc: 59.38%] [G loss: 3.522406]\n",
      "epoch:21 step:16723 [D loss: 0.217682, acc: 98.44%] [G loss: 1.911808]\n",
      "epoch:21 step:16724 [D loss: 0.632404, acc: 60.16%] [G loss: 3.066610]\n",
      "epoch:21 step:16725 [D loss: 0.741192, acc: 49.22%] [G loss: 2.606786]\n",
      "epoch:21 step:16726 [D loss: 0.345952, acc: 86.72%] [G loss: 4.600200]\n",
      "epoch:21 step:16727 [D loss: 0.308249, acc: 87.50%] [G loss: 4.141694]\n",
      "epoch:21 step:16728 [D loss: 0.389180, acc: 88.28%] [G loss: 3.409569]\n",
      "epoch:21 step:16729 [D loss: 0.281064, acc: 96.09%] [G loss: 3.984672]\n",
      "epoch:21 step:16730 [D loss: 0.300563, acc: 92.19%] [G loss: 3.901745]\n",
      "epoch:21 step:16731 [D loss: 0.658070, acc: 53.91%] [G loss: 2.147077]\n",
      "epoch:21 step:16732 [D loss: 0.146130, acc: 98.44%] [G loss: 2.206634]\n",
      "epoch:21 step:16733 [D loss: 0.314414, acc: 93.75%] [G loss: 2.287689]\n",
      "epoch:21 step:16734 [D loss: 0.144126, acc: 100.00%] [G loss: 3.899366]\n",
      "epoch:21 step:16735 [D loss: 0.641515, acc: 55.47%] [G loss: 4.729527]\n",
      "epoch:21 step:16736 [D loss: 0.421856, acc: 85.94%] [G loss: 3.245241]\n",
      "epoch:21 step:16737 [D loss: 1.007980, acc: 41.41%] [G loss: 2.669653]\n",
      "epoch:21 step:16738 [D loss: 0.540456, acc: 78.91%] [G loss: 3.214368]\n",
      "epoch:21 step:16739 [D loss: 0.976215, acc: 36.72%] [G loss: 3.030246]\n",
      "epoch:21 step:16740 [D loss: 0.153641, acc: 100.00%] [G loss: 3.696827]\n",
      "epoch:21 step:16741 [D loss: 0.763207, acc: 49.22%] [G loss: 3.107735]\n",
      "epoch:21 step:16742 [D loss: 0.070238, acc: 99.22%] [G loss: 3.917579]\n",
      "epoch:21 step:16743 [D loss: 0.467141, acc: 68.75%] [G loss: 3.921871]\n",
      "epoch:21 step:16744 [D loss: 0.571139, acc: 69.53%] [G loss: 3.196445]\n",
      "epoch:21 step:16745 [D loss: 0.656017, acc: 61.72%] [G loss: 3.368334]\n",
      "epoch:21 step:16746 [D loss: 0.563357, acc: 67.97%] [G loss: 3.729153]\n",
      "epoch:21 step:16747 [D loss: 0.589327, acc: 73.44%] [G loss: 2.729198]\n",
      "epoch:21 step:16748 [D loss: 0.615445, acc: 68.75%] [G loss: 3.590786]\n",
      "epoch:21 step:16749 [D loss: 0.661575, acc: 62.50%] [G loss: 2.458096]\n",
      "epoch:21 step:16750 [D loss: 1.243152, acc: 8.59%] [G loss: 3.607185]\n",
      "epoch:21 step:16751 [D loss: 0.245517, acc: 96.09%] [G loss: 3.178411]\n",
      "epoch:21 step:16752 [D loss: 0.315506, acc: 89.84%] [G loss: 3.896258]\n",
      "epoch:21 step:16753 [D loss: 0.487598, acc: 70.31%] [G loss: 2.934262]\n",
      "epoch:21 step:16754 [D loss: 0.236863, acc: 97.66%] [G loss: 4.338778]\n",
      "epoch:21 step:16755 [D loss: 0.515623, acc: 73.44%] [G loss: 2.907253]\n",
      "epoch:21 step:16756 [D loss: 0.809405, acc: 39.06%] [G loss: 3.341539]\n",
      "epoch:21 step:16757 [D loss: 0.623992, acc: 75.00%] [G loss: 3.451587]\n",
      "epoch:21 step:16758 [D loss: 0.171597, acc: 98.44%] [G loss: 4.422434]\n",
      "epoch:21 step:16759 [D loss: 0.564177, acc: 71.88%] [G loss: 2.398332]\n",
      "epoch:21 step:16760 [D loss: 0.626742, acc: 57.81%] [G loss: 4.468924]\n",
      "epoch:21 step:16761 [D loss: 0.433476, acc: 84.38%] [G loss: 2.476149]\n",
      "epoch:21 step:16762 [D loss: 0.475829, acc: 82.81%] [G loss: 3.048127]\n",
      "epoch:21 step:16763 [D loss: 0.388831, acc: 83.59%] [G loss: 3.676812]\n",
      "epoch:21 step:16764 [D loss: 0.460249, acc: 68.75%] [G loss: 3.247381]\n",
      "epoch:21 step:16765 [D loss: 0.230044, acc: 97.66%] [G loss: 3.840225]\n",
      "epoch:21 step:16766 [D loss: 0.392739, acc: 88.28%] [G loss: 4.059987]\n",
      "epoch:21 step:16767 [D loss: 0.574500, acc: 68.75%] [G loss: 3.907720]\n",
      "epoch:21 step:16768 [D loss: 0.755260, acc: 50.00%] [G loss: 3.352874]\n",
      "epoch:21 step:16769 [D loss: 0.254131, acc: 96.09%] [G loss: 4.106894]\n",
      "epoch:21 step:16770 [D loss: 0.217390, acc: 94.53%] [G loss: 4.103471]\n",
      "epoch:21 step:16771 [D loss: 0.163997, acc: 99.22%] [G loss: 4.718058]\n",
      "epoch:21 step:16772 [D loss: 0.539071, acc: 59.38%] [G loss: 2.861884]\n",
      "epoch:21 step:16773 [D loss: 0.547588, acc: 72.66%] [G loss: 2.687731]\n",
      "epoch:21 step:16774 [D loss: 0.476174, acc: 76.56%] [G loss: 2.899829]\n",
      "epoch:21 step:16775 [D loss: 0.339785, acc: 89.06%] [G loss: 4.494396]\n",
      "epoch:21 step:16776 [D loss: 0.631600, acc: 60.16%] [G loss: 3.935160]\n",
      "epoch:21 step:16777 [D loss: 0.190121, acc: 98.44%] [G loss: 4.035303]\n",
      "epoch:21 step:16778 [D loss: 0.549992, acc: 75.00%] [G loss: 5.252975]\n",
      "epoch:21 step:16779 [D loss: 0.425523, acc: 89.06%] [G loss: 2.364654]\n",
      "epoch:21 step:16780 [D loss: 0.721262, acc: 57.81%] [G loss: 4.338802]\n",
      "epoch:21 step:16781 [D loss: 0.237478, acc: 94.53%] [G loss: 2.936692]\n",
      "epoch:21 step:16782 [D loss: 0.563811, acc: 71.88%] [G loss: 3.060006]\n",
      "epoch:21 step:16783 [D loss: 0.472473, acc: 82.81%] [G loss: 3.264777]\n",
      "epoch:21 step:16784 [D loss: 0.466251, acc: 84.38%] [G loss: 2.670800]\n",
      "epoch:21 step:16785 [D loss: 0.276943, acc: 94.53%] [G loss: 3.441428]\n",
      "epoch:21 step:16786 [D loss: 0.307558, acc: 96.09%] [G loss: 2.726933]\n",
      "epoch:21 step:16787 [D loss: 0.297931, acc: 96.88%] [G loss: 3.700988]\n",
      "epoch:21 step:16788 [D loss: 0.179216, acc: 97.66%] [G loss: 5.159617]\n",
      "epoch:21 step:16789 [D loss: 0.247033, acc: 98.44%] [G loss: 2.925599]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:21 step:16790 [D loss: 0.175767, acc: 97.66%] [G loss: 2.762308]\n",
      "epoch:21 step:16791 [D loss: 0.326144, acc: 95.31%] [G loss: 2.677197]\n",
      "epoch:21 step:16792 [D loss: 1.235897, acc: 16.41%] [G loss: 1.780536]\n",
      "epoch:21 step:16793 [D loss: 0.320874, acc: 94.53%] [G loss: 3.315849]\n",
      "epoch:21 step:16794 [D loss: 1.128396, acc: 18.75%] [G loss: 2.665456]\n",
      "epoch:21 step:16795 [D loss: 0.317591, acc: 92.97%] [G loss: 2.685181]\n",
      "epoch:21 step:16796 [D loss: 0.537179, acc: 68.75%] [G loss: 3.912805]\n",
      "epoch:21 step:16797 [D loss: 0.236798, acc: 99.22%] [G loss: 2.859899]\n",
      "epoch:21 step:16798 [D loss: 1.372767, acc: 22.66%] [G loss: 2.480481]\n",
      "epoch:21 step:16799 [D loss: 0.318148, acc: 90.62%] [G loss: 2.833155]\n",
      "epoch:21 step:16800 [D loss: 0.487096, acc: 79.69%] [G loss: 2.843007]\n",
      "##############\n",
      "[0.85970513 0.87605524 0.83567388 0.80821518 0.79070659 0.81873385\n",
      " 0.90108259 0.82598509 0.79880299 0.8428015 ]\n",
      "##########\n",
      "epoch:21 step:16801 [D loss: 0.121141, acc: 100.00%] [G loss: 3.914377]\n",
      "epoch:21 step:16802 [D loss: 0.132113, acc: 99.22%] [G loss: 3.427129]\n",
      "epoch:21 step:16803 [D loss: 0.325697, acc: 96.88%] [G loss: 2.197351]\n",
      "epoch:21 step:16804 [D loss: 0.294118, acc: 96.88%] [G loss: 3.840011]\n",
      "epoch:21 step:16805 [D loss: 0.543602, acc: 76.56%] [G loss: 2.667002]\n",
      "epoch:21 step:16806 [D loss: 0.371406, acc: 87.50%] [G loss: 4.351484]\n",
      "epoch:21 step:16807 [D loss: 0.544220, acc: 70.31%] [G loss: 3.090842]\n",
      "epoch:21 step:16808 [D loss: 0.224675, acc: 98.44%] [G loss: 2.916171]\n",
      "epoch:21 step:16809 [D loss: 0.571619, acc: 67.97%] [G loss: 4.416842]\n",
      "epoch:21 step:16810 [D loss: 0.471516, acc: 86.72%] [G loss: 3.372963]\n",
      "epoch:21 step:16811 [D loss: 0.347450, acc: 80.47%] [G loss: 3.629597]\n",
      "epoch:21 step:16812 [D loss: 0.255477, acc: 98.44%] [G loss: 5.145405]\n",
      "epoch:21 step:16813 [D loss: 0.144966, acc: 100.00%] [G loss: 3.435190]\n",
      "epoch:21 step:16814 [D loss: 0.360181, acc: 87.50%] [G loss: 4.237643]\n",
      "epoch:21 step:16815 [D loss: 0.687071, acc: 59.38%] [G loss: 3.466948]\n",
      "epoch:21 step:16816 [D loss: 0.846299, acc: 48.44%] [G loss: 2.314750]\n",
      "epoch:21 step:16817 [D loss: 0.713295, acc: 53.12%] [G loss: 1.724459]\n",
      "epoch:21 step:16818 [D loss: 0.330463, acc: 91.41%] [G loss: 3.783071]\n",
      "epoch:21 step:16819 [D loss: 0.306698, acc: 96.09%] [G loss: 2.857968]\n",
      "epoch:21 step:16820 [D loss: 0.220026, acc: 97.66%] [G loss: 3.855552]\n",
      "epoch:21 step:16821 [D loss: 0.336915, acc: 92.97%] [G loss: 3.032623]\n",
      "epoch:21 step:16822 [D loss: 0.941267, acc: 28.91%] [G loss: 2.454045]\n",
      "epoch:21 step:16823 [D loss: 0.330224, acc: 88.28%] [G loss: 5.192827]\n",
      "epoch:21 step:16824 [D loss: 1.006670, acc: 28.91%] [G loss: 4.676355]\n",
      "epoch:21 step:16825 [D loss: 0.757383, acc: 45.31%] [G loss: 4.061829]\n",
      "epoch:21 step:16826 [D loss: 0.899981, acc: 42.19%] [G loss: 1.976254]\n",
      "epoch:21 step:16827 [D loss: 0.447350, acc: 83.59%] [G loss: 5.656785]\n",
      "epoch:21 step:16828 [D loss: 0.283949, acc: 98.44%] [G loss: 3.280074]\n",
      "epoch:21 step:16829 [D loss: 0.121326, acc: 100.00%] [G loss: 5.366604]\n",
      "epoch:21 step:16830 [D loss: 0.319733, acc: 84.38%] [G loss: 3.654162]\n",
      "epoch:21 step:16831 [D loss: 0.255683, acc: 93.75%] [G loss: 3.881188]\n",
      "epoch:21 step:16832 [D loss: 1.103967, acc: 40.62%] [G loss: 2.022916]\n",
      "epoch:21 step:16833 [D loss: 0.212804, acc: 100.00%] [G loss: 2.909534]\n",
      "epoch:21 step:16834 [D loss: 0.329486, acc: 92.19%] [G loss: 3.534292]\n",
      "epoch:21 step:16835 [D loss: 0.379613, acc: 85.94%] [G loss: 4.933674]\n",
      "epoch:21 step:16836 [D loss: 0.154004, acc: 100.00%] [G loss: 3.485946]\n",
      "epoch:21 step:16837 [D loss: 1.233619, acc: 29.69%] [G loss: 2.457433]\n",
      "epoch:21 step:16838 [D loss: 0.390985, acc: 90.62%] [G loss: 2.900389]\n",
      "epoch:21 step:16839 [D loss: 0.289495, acc: 96.88%] [G loss: 3.443509]\n",
      "epoch:21 step:16840 [D loss: 0.306273, acc: 93.75%] [G loss: 2.883559]\n",
      "epoch:21 step:16841 [D loss: 0.712920, acc: 57.03%] [G loss: 2.098347]\n",
      "epoch:21 step:16842 [D loss: 0.996235, acc: 50.78%] [G loss: 3.297678]\n",
      "epoch:21 step:16843 [D loss: 0.527958, acc: 63.28%] [G loss: 2.894431]\n",
      "epoch:21 step:16844 [D loss: 0.748334, acc: 55.47%] [G loss: 2.931605]\n",
      "epoch:21 step:16845 [D loss: 0.557280, acc: 73.44%] [G loss: 3.223191]\n",
      "epoch:21 step:16846 [D loss: 0.578036, acc: 75.00%] [G loss: 1.830341]\n",
      "epoch:21 step:16847 [D loss: 0.548078, acc: 77.34%] [G loss: 2.464282]\n",
      "epoch:21 step:16848 [D loss: 0.308176, acc: 95.31%] [G loss: 3.724767]\n",
      "epoch:21 step:16849 [D loss: 0.202787, acc: 99.22%] [G loss: 4.392563]\n",
      "epoch:21 step:16850 [D loss: 0.500816, acc: 72.66%] [G loss: 2.840024]\n",
      "epoch:21 step:16851 [D loss: 0.458792, acc: 75.78%] [G loss: 2.920455]\n",
      "epoch:21 step:16852 [D loss: 0.275343, acc: 91.41%] [G loss: 5.412994]\n",
      "epoch:21 step:16853 [D loss: 0.319301, acc: 91.41%] [G loss: 3.546924]\n",
      "epoch:21 step:16854 [D loss: 0.423846, acc: 92.19%] [G loss: 3.198509]\n",
      "epoch:21 step:16855 [D loss: 0.732345, acc: 53.12%] [G loss: 4.627633]\n",
      "epoch:21 step:16856 [D loss: 0.476182, acc: 84.38%] [G loss: 2.740916]\n",
      "epoch:21 step:16857 [D loss: 0.375949, acc: 91.41%] [G loss: 2.990177]\n",
      "epoch:21 step:16858 [D loss: 1.083986, acc: 14.84%] [G loss: 2.336126]\n",
      "epoch:21 step:16859 [D loss: 0.253728, acc: 97.66%] [G loss: 2.845451]\n",
      "epoch:21 step:16860 [D loss: 0.095776, acc: 99.22%] [G loss: 4.285693]\n",
      "epoch:21 step:16861 [D loss: 0.924109, acc: 46.88%] [G loss: 2.932166]\n",
      "epoch:21 step:16862 [D loss: 0.204052, acc: 98.44%] [G loss: 3.760680]\n",
      "epoch:21 step:16863 [D loss: 0.374293, acc: 92.19%] [G loss: 2.927365]\n",
      "epoch:21 step:16864 [D loss: 0.492703, acc: 79.69%] [G loss: 3.001669]\n",
      "epoch:21 step:16865 [D loss: 0.673945, acc: 57.81%] [G loss: 2.978431]\n",
      "epoch:21 step:16866 [D loss: 0.601309, acc: 67.97%] [G loss: 1.714554]\n",
      "epoch:21 step:16867 [D loss: 0.149852, acc: 99.22%] [G loss: 3.542393]\n",
      "epoch:21 step:16868 [D loss: 0.698403, acc: 57.81%] [G loss: 2.843646]\n",
      "epoch:21 step:16869 [D loss: 0.727058, acc: 55.47%] [G loss: 3.225998]\n",
      "epoch:21 step:16870 [D loss: 0.368614, acc: 82.03%] [G loss: 3.152323]\n",
      "epoch:21 step:16871 [D loss: 1.026300, acc: 42.19%] [G loss: 3.483448]\n",
      "epoch:21 step:16872 [D loss: 0.292695, acc: 93.75%] [G loss: 2.635197]\n",
      "epoch:21 step:16873 [D loss: 0.693406, acc: 55.47%] [G loss: 2.044782]\n",
      "epoch:21 step:16874 [D loss: 0.664253, acc: 57.81%] [G loss: 3.386165]\n",
      "epoch:21 step:16875 [D loss: 0.742340, acc: 53.91%] [G loss: 3.854087]\n",
      "epoch:21 step:16876 [D loss: 0.731866, acc: 51.56%] [G loss: 4.590161]\n",
      "epoch:21 step:16877 [D loss: 0.254647, acc: 96.09%] [G loss: 4.786229]\n",
      "epoch:21 step:16878 [D loss: 0.317191, acc: 96.88%] [G loss: 3.780976]\n",
      "epoch:21 step:16879 [D loss: 0.269246, acc: 96.88%] [G loss: 3.107423]\n",
      "epoch:21 step:16880 [D loss: 1.188823, acc: 10.16%] [G loss: 2.908969]\n",
      "epoch:21 step:16881 [D loss: 0.340680, acc: 94.53%] [G loss: 1.398807]\n",
      "epoch:21 step:16882 [D loss: 0.740810, acc: 48.44%] [G loss: 3.068527]\n",
      "epoch:21 step:16883 [D loss: 1.989505, acc: 0.78%] [G loss: 1.756404]\n",
      "epoch:21 step:16884 [D loss: 0.457886, acc: 81.25%] [G loss: 2.252152]\n",
      "epoch:21 step:16885 [D loss: 0.446528, acc: 86.72%] [G loss: 2.370340]\n",
      "epoch:21 step:16886 [D loss: 0.158090, acc: 99.22%] [G loss: 2.971353]\n",
      "epoch:21 step:16887 [D loss: 0.938296, acc: 29.69%] [G loss: 2.419087]\n",
      "epoch:21 step:16888 [D loss: 0.451765, acc: 87.50%] [G loss: 4.673396]\n",
      "epoch:21 step:16889 [D loss: 0.368996, acc: 86.72%] [G loss: 3.693661]\n",
      "epoch:21 step:16890 [D loss: 0.313011, acc: 92.97%] [G loss: 2.495241]\n",
      "epoch:21 step:16891 [D loss: 0.209529, acc: 97.66%] [G loss: 4.122931]\n",
      "epoch:21 step:16892 [D loss: 0.521026, acc: 66.41%] [G loss: 4.699496]\n",
      "epoch:21 step:16893 [D loss: 0.618960, acc: 68.75%] [G loss: 3.641125]\n",
      "epoch:21 step:16894 [D loss: 0.781693, acc: 43.75%] [G loss: 3.313537]\n",
      "epoch:21 step:16895 [D loss: 0.210451, acc: 99.22%] [G loss: 4.502195]\n",
      "epoch:21 step:16896 [D loss: 0.293826, acc: 96.09%] [G loss: 3.496483]\n",
      "epoch:21 step:16897 [D loss: 0.540315, acc: 73.44%] [G loss: 4.110852]\n",
      "epoch:21 step:16898 [D loss: 0.174367, acc: 99.22%] [G loss: 3.730581]\n",
      "epoch:21 step:16899 [D loss: 0.417833, acc: 75.78%] [G loss: 3.621609]\n",
      "epoch:21 step:16900 [D loss: 0.343315, acc: 94.53%] [G loss: 3.364137]\n",
      "epoch:21 step:16901 [D loss: 0.819455, acc: 46.09%] [G loss: 2.805499]\n",
      "epoch:21 step:16902 [D loss: 0.531632, acc: 70.31%] [G loss: 2.212252]\n",
      "epoch:21 step:16903 [D loss: 0.445331, acc: 78.91%] [G loss: 2.646297]\n",
      "epoch:21 step:16904 [D loss: 0.290235, acc: 96.09%] [G loss: 2.573093]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:21 step:16905 [D loss: 1.542337, acc: 7.81%] [G loss: 1.754140]\n",
      "epoch:21 step:16906 [D loss: 1.052057, acc: 17.97%] [G loss: 2.585618]\n",
      "epoch:21 step:16907 [D loss: 0.607362, acc: 59.38%] [G loss: 2.429112]\n",
      "epoch:21 step:16908 [D loss: 0.811333, acc: 53.12%] [G loss: 4.010364]\n",
      "epoch:21 step:16909 [D loss: 0.485672, acc: 78.12%] [G loss: 3.364712]\n",
      "epoch:21 step:16910 [D loss: 0.175185, acc: 100.00%] [G loss: 4.475533]\n",
      "epoch:21 step:16911 [D loss: 0.355367, acc: 82.81%] [G loss: 4.600939]\n",
      "epoch:21 step:16912 [D loss: 0.078341, acc: 100.00%] [G loss: 4.246883]\n",
      "epoch:21 step:16913 [D loss: 0.621780, acc: 64.06%] [G loss: 2.788886]\n",
      "epoch:21 step:16914 [D loss: 0.573820, acc: 77.34%] [G loss: 2.179873]\n",
      "epoch:21 step:16915 [D loss: 0.423097, acc: 89.06%] [G loss: 3.323653]\n",
      "epoch:21 step:16916 [D loss: 0.862594, acc: 42.97%] [G loss: 2.354863]\n",
      "epoch:21 step:16917 [D loss: 0.845290, acc: 37.50%] [G loss: 3.228297]\n",
      "epoch:21 step:16918 [D loss: 0.121533, acc: 98.44%] [G loss: 3.943963]\n",
      "epoch:21 step:16919 [D loss: 0.651431, acc: 63.28%] [G loss: 3.418580]\n",
      "epoch:21 step:16920 [D loss: 0.818392, acc: 51.56%] [G loss: 2.719393]\n",
      "epoch:21 step:16921 [D loss: 0.329396, acc: 90.62%] [G loss: 2.616882]\n",
      "epoch:21 step:16922 [D loss: 0.997520, acc: 47.66%] [G loss: 1.815794]\n",
      "epoch:21 step:16923 [D loss: 0.503383, acc: 78.91%] [G loss: 3.005938]\n",
      "epoch:21 step:16924 [D loss: 0.308788, acc: 91.41%] [G loss: 4.451535]\n",
      "epoch:21 step:16925 [D loss: 0.773470, acc: 54.69%] [G loss: 3.285584]\n",
      "epoch:21 step:16926 [D loss: 0.796639, acc: 38.28%] [G loss: 2.784630]\n",
      "epoch:21 step:16927 [D loss: 0.405482, acc: 90.62%] [G loss: 2.719222]\n",
      "epoch:21 step:16928 [D loss: 0.652116, acc: 61.72%] [G loss: 3.302636]\n",
      "epoch:21 step:16929 [D loss: 0.103850, acc: 99.22%] [G loss: 4.368642]\n",
      "epoch:21 step:16930 [D loss: 0.158957, acc: 98.44%] [G loss: 3.623453]\n",
      "epoch:21 step:16931 [D loss: 0.755718, acc: 52.34%] [G loss: 2.753498]\n",
      "epoch:21 step:16932 [D loss: 0.869527, acc: 50.78%] [G loss: 3.113490]\n",
      "epoch:21 step:16933 [D loss: 0.366578, acc: 92.97%] [G loss: 2.364677]\n",
      "epoch:21 step:16934 [D loss: 0.475654, acc: 78.12%] [G loss: 2.518859]\n",
      "epoch:21 step:16935 [D loss: 0.428162, acc: 86.72%] [G loss: 4.983007]\n",
      "epoch:21 step:16936 [D loss: 0.489199, acc: 77.34%] [G loss: 2.503120]\n",
      "epoch:21 step:16937 [D loss: 0.193431, acc: 100.00%] [G loss: 4.003159]\n",
      "epoch:21 step:16938 [D loss: 0.641873, acc: 58.59%] [G loss: 3.380181]\n",
      "epoch:21 step:16939 [D loss: 0.121498, acc: 100.00%] [G loss: 3.565106]\n",
      "epoch:21 step:16940 [D loss: 0.821442, acc: 52.34%] [G loss: 3.652697]\n",
      "epoch:21 step:16941 [D loss: 0.357195, acc: 92.97%] [G loss: 4.548653]\n",
      "epoch:21 step:16942 [D loss: 0.477680, acc: 75.78%] [G loss: 3.711164]\n",
      "epoch:21 step:16943 [D loss: 0.300168, acc: 95.31%] [G loss: 2.304533]\n",
      "epoch:21 step:16944 [D loss: 0.397394, acc: 87.50%] [G loss: 3.307395]\n",
      "epoch:21 step:16945 [D loss: 0.664711, acc: 57.81%] [G loss: 3.316993]\n",
      "epoch:21 step:16946 [D loss: 0.899175, acc: 51.56%] [G loss: 2.426392]\n",
      "epoch:21 step:16947 [D loss: 0.205630, acc: 97.66%] [G loss: 3.890247]\n",
      "epoch:21 step:16948 [D loss: 0.285994, acc: 96.88%] [G loss: 3.424347]\n",
      "epoch:21 step:16949 [D loss: 0.844869, acc: 40.62%] [G loss: 2.827226]\n",
      "epoch:21 step:16950 [D loss: 1.019041, acc: 31.25%] [G loss: 2.108515]\n",
      "epoch:21 step:16951 [D loss: 0.399881, acc: 85.94%] [G loss: 2.588302]\n",
      "epoch:21 step:16952 [D loss: 0.615015, acc: 64.84%] [G loss: 2.430059]\n",
      "epoch:21 step:16953 [D loss: 0.588584, acc: 71.09%] [G loss: 3.170823]\n",
      "epoch:21 step:16954 [D loss: 0.416949, acc: 77.34%] [G loss: 2.490014]\n",
      "epoch:21 step:16955 [D loss: 0.381808, acc: 90.62%] [G loss: 2.832339]\n",
      "epoch:21 step:16956 [D loss: 0.663305, acc: 53.91%] [G loss: 3.788625]\n",
      "epoch:21 step:16957 [D loss: 0.333973, acc: 89.84%] [G loss: 3.234203]\n",
      "epoch:21 step:16958 [D loss: 0.542705, acc: 69.53%] [G loss: 3.215299]\n",
      "epoch:21 step:16959 [D loss: 0.665216, acc: 66.41%] [G loss: 2.252738]\n",
      "epoch:21 step:16960 [D loss: 0.438331, acc: 89.84%] [G loss: 2.590102]\n",
      "epoch:21 step:16961 [D loss: 0.481113, acc: 69.53%] [G loss: 2.567952]\n",
      "epoch:21 step:16962 [D loss: 0.276570, acc: 98.44%] [G loss: 3.254245]\n",
      "epoch:21 step:16963 [D loss: 0.406651, acc: 84.38%] [G loss: 3.164680]\n",
      "epoch:21 step:16964 [D loss: 0.419215, acc: 91.41%] [G loss: 3.347871]\n",
      "epoch:21 step:16965 [D loss: 0.682102, acc: 55.47%] [G loss: 3.271279]\n",
      "epoch:21 step:16966 [D loss: 0.471259, acc: 85.94%] [G loss: 2.231085]\n",
      "epoch:21 step:16967 [D loss: 1.161593, acc: 16.41%] [G loss: 3.721390]\n",
      "epoch:21 step:16968 [D loss: 0.731392, acc: 48.44%] [G loss: 2.502236]\n",
      "epoch:21 step:16969 [D loss: 0.594247, acc: 67.97%] [G loss: 2.967062]\n",
      "epoch:21 step:16970 [D loss: 0.273900, acc: 99.22%] [G loss: 3.277796]\n",
      "epoch:21 step:16971 [D loss: 0.694738, acc: 58.59%] [G loss: 2.622018]\n",
      "epoch:21 step:16972 [D loss: 0.486274, acc: 79.69%] [G loss: 4.237913]\n",
      "epoch:21 step:16973 [D loss: 0.391466, acc: 84.38%] [G loss: 3.184134]\n",
      "epoch:21 step:16974 [D loss: 1.171751, acc: 15.62%] [G loss: 2.278928]\n",
      "epoch:21 step:16975 [D loss: 0.314270, acc: 89.06%] [G loss: 3.178489]\n",
      "epoch:21 step:16976 [D loss: 0.695803, acc: 57.03%] [G loss: 2.658986]\n",
      "epoch:21 step:16977 [D loss: 0.370039, acc: 92.97%] [G loss: 3.389998]\n",
      "epoch:21 step:16978 [D loss: 0.300905, acc: 92.19%] [G loss: 3.041145]\n",
      "epoch:21 step:16979 [D loss: 0.576891, acc: 61.72%] [G loss: 2.865308]\n",
      "epoch:21 step:16980 [D loss: 0.674391, acc: 56.25%] [G loss: 2.841162]\n",
      "epoch:21 step:16981 [D loss: 0.251184, acc: 94.53%] [G loss: 3.757418]\n",
      "epoch:21 step:16982 [D loss: 0.224220, acc: 94.53%] [G loss: 3.734669]\n",
      "epoch:21 step:16983 [D loss: 0.629014, acc: 64.06%] [G loss: 3.447519]\n",
      "epoch:21 step:16984 [D loss: 0.374965, acc: 84.38%] [G loss: 3.954507]\n",
      "epoch:21 step:16985 [D loss: 0.181198, acc: 98.44%] [G loss: 2.418344]\n",
      "epoch:21 step:16986 [D loss: 0.821515, acc: 53.12%] [G loss: 3.716533]\n",
      "epoch:21 step:16987 [D loss: 0.296276, acc: 98.44%] [G loss: 3.573851]\n",
      "epoch:21 step:16988 [D loss: 0.679826, acc: 57.03%] [G loss: 2.747575]\n",
      "epoch:21 step:16989 [D loss: 0.413072, acc: 88.28%] [G loss: 3.846095]\n",
      "epoch:21 step:16990 [D loss: 0.445665, acc: 81.25%] [G loss: 2.953914]\n",
      "epoch:21 step:16991 [D loss: 0.460053, acc: 83.59%] [G loss: 3.072414]\n",
      "epoch:21 step:16992 [D loss: 0.299694, acc: 92.97%] [G loss: 2.347023]\n",
      "epoch:21 step:16993 [D loss: 0.643255, acc: 64.84%] [G loss: 2.535149]\n",
      "epoch:21 step:16994 [D loss: 0.267036, acc: 97.66%] [G loss: 3.272942]\n",
      "epoch:21 step:16995 [D loss: 0.813956, acc: 36.72%] [G loss: 2.810173]\n",
      "epoch:21 step:16996 [D loss: 0.385010, acc: 91.41%] [G loss: 2.137515]\n",
      "epoch:21 step:16997 [D loss: 0.358852, acc: 88.28%] [G loss: 3.132876]\n",
      "epoch:21 step:16998 [D loss: 0.628297, acc: 66.41%] [G loss: 3.618767]\n",
      "epoch:21 step:16999 [D loss: 0.276331, acc: 95.31%] [G loss: 2.631552]\n",
      "epoch:21 step:17000 [D loss: 0.679283, acc: 60.16%] [G loss: 2.462312]\n",
      "##############\n",
      "[0.84883099 0.86340879 0.80256464 0.81473002 0.7913707  0.84766261\n",
      " 0.89583244 0.84479066 0.82209864 0.83605508]\n",
      "##########\n",
      "epoch:21 step:17001 [D loss: 0.537982, acc: 66.41%] [G loss: 3.387792]\n",
      "epoch:21 step:17002 [D loss: 0.851195, acc: 41.41%] [G loss: 1.682606]\n",
      "epoch:21 step:17003 [D loss: 0.435537, acc: 78.91%] [G loss: 3.258049]\n",
      "epoch:21 step:17004 [D loss: 1.149475, acc: 46.88%] [G loss: 2.857401]\n",
      "epoch:21 step:17005 [D loss: 0.866933, acc: 42.19%] [G loss: 2.305287]\n",
      "epoch:21 step:17006 [D loss: 0.296857, acc: 96.88%] [G loss: 3.115110]\n",
      "epoch:21 step:17007 [D loss: 0.701002, acc: 57.81%] [G loss: 1.850410]\n",
      "epoch:21 step:17008 [D loss: 0.384915, acc: 78.12%] [G loss: 3.768126]\n",
      "epoch:21 step:17009 [D loss: 0.825185, acc: 46.88%] [G loss: 2.964263]\n",
      "epoch:21 step:17010 [D loss: 0.187581, acc: 100.00%] [G loss: 3.951420]\n",
      "epoch:21 step:17011 [D loss: 0.757767, acc: 50.78%] [G loss: 2.254203]\n",
      "epoch:21 step:17012 [D loss: 0.311842, acc: 90.62%] [G loss: 3.848527]\n",
      "epoch:21 step:17013 [D loss: 0.473336, acc: 67.19%] [G loss: 3.096987]\n",
      "epoch:21 step:17014 [D loss: 0.508138, acc: 77.34%] [G loss: 3.418440]\n",
      "epoch:21 step:17015 [D loss: 0.461482, acc: 73.44%] [G loss: 2.312378]\n",
      "epoch:21 step:17016 [D loss: 0.419368, acc: 83.59%] [G loss: 3.178109]\n",
      "epoch:21 step:17017 [D loss: 0.588545, acc: 70.31%] [G loss: 2.670466]\n",
      "epoch:21 step:17018 [D loss: 0.457821, acc: 80.47%] [G loss: 2.202353]\n",
      "epoch:21 step:17019 [D loss: 0.361573, acc: 91.41%] [G loss: 3.165818]\n",
      "epoch:21 step:17020 [D loss: 0.569759, acc: 69.53%] [G loss: 3.607367]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:21 step:17021 [D loss: 0.790966, acc: 53.12%] [G loss: 1.973941]\n",
      "epoch:21 step:17022 [D loss: 0.913155, acc: 30.47%] [G loss: 2.250973]\n",
      "epoch:21 step:17023 [D loss: 0.449099, acc: 82.03%] [G loss: 4.202535]\n",
      "epoch:21 step:17024 [D loss: 0.749238, acc: 51.56%] [G loss: 3.103732]\n",
      "epoch:21 step:17025 [D loss: 0.315443, acc: 87.50%] [G loss: 3.630091]\n",
      "epoch:21 step:17026 [D loss: 0.321004, acc: 95.31%] [G loss: 3.735037]\n",
      "epoch:21 step:17027 [D loss: 1.060499, acc: 19.53%] [G loss: 2.127990]\n",
      "epoch:21 step:17028 [D loss: 0.794210, acc: 46.09%] [G loss: 3.307948]\n",
      "epoch:21 step:17029 [D loss: 0.282358, acc: 95.31%] [G loss: 3.371825]\n",
      "epoch:21 step:17030 [D loss: 0.885739, acc: 38.28%] [G loss: 2.295890]\n",
      "epoch:21 step:17031 [D loss: 0.513784, acc: 72.66%] [G loss: 4.374932]\n",
      "epoch:21 step:17032 [D loss: 0.435454, acc: 80.47%] [G loss: 2.930341]\n",
      "epoch:21 step:17033 [D loss: 0.658195, acc: 56.25%] [G loss: 2.680339]\n",
      "epoch:21 step:17034 [D loss: 0.816548, acc: 47.66%] [G loss: 2.884544]\n",
      "epoch:21 step:17035 [D loss: 0.513644, acc: 82.03%] [G loss: 2.108044]\n",
      "epoch:21 step:17036 [D loss: 0.313836, acc: 95.31%] [G loss: 3.227285]\n",
      "epoch:21 step:17037 [D loss: 0.648793, acc: 61.72%] [G loss: 1.715701]\n",
      "epoch:21 step:17038 [D loss: 0.245345, acc: 93.75%] [G loss: 4.319236]\n",
      "epoch:21 step:17039 [D loss: 0.629718, acc: 67.19%] [G loss: 2.946019]\n",
      "epoch:21 step:17040 [D loss: 0.784338, acc: 46.09%] [G loss: 1.745925]\n",
      "epoch:21 step:17041 [D loss: 0.589827, acc: 66.41%] [G loss: 2.935462]\n",
      "epoch:21 step:17042 [D loss: 0.756855, acc: 49.22%] [G loss: 2.665851]\n",
      "epoch:21 step:17043 [D loss: 0.558544, acc: 75.78%] [G loss: 3.107635]\n",
      "epoch:21 step:17044 [D loss: 0.379685, acc: 88.28%] [G loss: 3.055683]\n",
      "epoch:21 step:17045 [D loss: 0.149184, acc: 100.00%] [G loss: 3.451206]\n",
      "epoch:21 step:17046 [D loss: 0.317117, acc: 96.88%] [G loss: 3.461286]\n",
      "epoch:21 step:17047 [D loss: 0.893384, acc: 31.25%] [G loss: 2.012335]\n",
      "epoch:21 step:17048 [D loss: 0.630392, acc: 68.75%] [G loss: 2.861197]\n",
      "epoch:21 step:17049 [D loss: 0.386605, acc: 89.06%] [G loss: 2.582250]\n",
      "epoch:21 step:17050 [D loss: 0.443811, acc: 82.81%] [G loss: 2.371299]\n",
      "epoch:21 step:17051 [D loss: 0.556414, acc: 77.34%] [G loss: 3.107297]\n",
      "epoch:21 step:17052 [D loss: 0.133761, acc: 99.22%] [G loss: 3.963576]\n",
      "epoch:21 step:17053 [D loss: 0.490910, acc: 82.03%] [G loss: 2.152561]\n",
      "epoch:21 step:17054 [D loss: 0.098998, acc: 99.22%] [G loss: 4.022336]\n",
      "epoch:21 step:17055 [D loss: 0.754470, acc: 57.81%] [G loss: 3.119913]\n",
      "epoch:21 step:17056 [D loss: 0.662145, acc: 55.47%] [G loss: 4.357519]\n",
      "epoch:21 step:17057 [D loss: 0.764602, acc: 48.44%] [G loss: 4.037769]\n",
      "epoch:21 step:17058 [D loss: 0.296671, acc: 85.94%] [G loss: 3.538664]\n",
      "epoch:21 step:17059 [D loss: 0.670827, acc: 64.84%] [G loss: 2.707351]\n",
      "epoch:21 step:17060 [D loss: 0.421779, acc: 76.56%] [G loss: 3.122001]\n",
      "epoch:21 step:17061 [D loss: 0.397973, acc: 83.59%] [G loss: 2.830977]\n",
      "epoch:21 step:17062 [D loss: 0.888107, acc: 32.81%] [G loss: 2.761519]\n",
      "epoch:21 step:17063 [D loss: 0.377988, acc: 87.50%] [G loss: 3.682060]\n",
      "epoch:21 step:17064 [D loss: 0.407052, acc: 92.19%] [G loss: 4.298285]\n",
      "epoch:21 step:17065 [D loss: 0.148063, acc: 100.00%] [G loss: 3.162755]\n",
      "epoch:21 step:17066 [D loss: 0.898647, acc: 36.72%] [G loss: 2.989375]\n",
      "epoch:21 step:17067 [D loss: 0.307760, acc: 97.66%] [G loss: 3.503224]\n",
      "epoch:21 step:17068 [D loss: 0.190772, acc: 99.22%] [G loss: 4.394857]\n",
      "epoch:21 step:17069 [D loss: 0.679200, acc: 53.12%] [G loss: 3.369718]\n",
      "epoch:21 step:17070 [D loss: 0.738384, acc: 50.00%] [G loss: 1.975916]\n",
      "epoch:21 step:17071 [D loss: 0.716893, acc: 51.56%] [G loss: 2.939295]\n",
      "epoch:21 step:17072 [D loss: 0.165691, acc: 100.00%] [G loss: 2.863513]\n",
      "epoch:21 step:17073 [D loss: 1.375495, acc: 20.31%] [G loss: 3.165577]\n",
      "epoch:21 step:17074 [D loss: 0.386891, acc: 85.16%] [G loss: 3.706349]\n",
      "epoch:21 step:17075 [D loss: 0.221951, acc: 96.88%] [G loss: 3.626495]\n",
      "epoch:21 step:17076 [D loss: 0.519331, acc: 78.91%] [G loss: 3.282259]\n",
      "epoch:21 step:17077 [D loss: 0.411752, acc: 79.69%] [G loss: 4.369760]\n",
      "epoch:21 step:17078 [D loss: 0.702209, acc: 53.12%] [G loss: 4.053976]\n",
      "epoch:21 step:17079 [D loss: 0.328313, acc: 94.53%] [G loss: 2.859416]\n",
      "epoch:21 step:17080 [D loss: 0.338410, acc: 86.72%] [G loss: 3.462401]\n",
      "epoch:21 step:17081 [D loss: 0.125792, acc: 100.00%] [G loss: 3.165450]\n",
      "epoch:21 step:17082 [D loss: 0.668348, acc: 56.25%] [G loss: 4.797025]\n",
      "epoch:21 step:17083 [D loss: 0.280553, acc: 95.31%] [G loss: 2.501110]\n",
      "epoch:21 step:17084 [D loss: 0.862189, acc: 47.66%] [G loss: 2.496648]\n",
      "epoch:21 step:17085 [D loss: 0.347449, acc: 87.50%] [G loss: 3.513936]\n",
      "epoch:21 step:17086 [D loss: 0.412958, acc: 85.94%] [G loss: 3.122167]\n",
      "epoch:21 step:17087 [D loss: 0.755050, acc: 46.88%] [G loss: 3.159433]\n",
      "epoch:21 step:17088 [D loss: 0.274905, acc: 89.84%] [G loss: 2.870924]\n",
      "epoch:21 step:17089 [D loss: 0.478459, acc: 82.03%] [G loss: 2.378530]\n",
      "epoch:21 step:17090 [D loss: 0.082158, acc: 100.00%] [G loss: 4.123225]\n",
      "epoch:21 step:17091 [D loss: 0.338249, acc: 79.69%] [G loss: 5.227029]\n",
      "epoch:21 step:17092 [D loss: 0.402197, acc: 88.28%] [G loss: 4.028851]\n",
      "epoch:21 step:17093 [D loss: 0.489766, acc: 69.53%] [G loss: 3.309366]\n",
      "epoch:21 step:17094 [D loss: 1.075179, acc: 48.44%] [G loss: 1.788414]\n",
      "epoch:21 step:17095 [D loss: 0.239966, acc: 99.22%] [G loss: 3.021119]\n",
      "epoch:21 step:17096 [D loss: 0.274537, acc: 93.75%] [G loss: 2.710145]\n",
      "epoch:21 step:17097 [D loss: 0.519237, acc: 74.22%] [G loss: 2.991796]\n",
      "epoch:21 step:17098 [D loss: 0.829539, acc: 53.12%] [G loss: 1.791784]\n",
      "epoch:21 step:17099 [D loss: 0.654768, acc: 56.25%] [G loss: 2.612392]\n",
      "epoch:21 step:17100 [D loss: 0.501293, acc: 83.59%] [G loss: 2.825889]\n",
      "epoch:21 step:17101 [D loss: 0.708581, acc: 53.12%] [G loss: 2.530045]\n",
      "epoch:21 step:17102 [D loss: 1.203915, acc: 30.47%] [G loss: 3.432134]\n",
      "epoch:21 step:17103 [D loss: 0.183402, acc: 100.00%] [G loss: 4.141515]\n",
      "epoch:21 step:17104 [D loss: 0.282044, acc: 92.19%] [G loss: 3.106638]\n",
      "epoch:21 step:17105 [D loss: 0.300956, acc: 93.75%] [G loss: 4.774329]\n",
      "epoch:21 step:17106 [D loss: 0.181789, acc: 100.00%] [G loss: 3.353136]\n",
      "epoch:21 step:17107 [D loss: 0.133871, acc: 100.00%] [G loss: 5.686728]\n",
      "epoch:21 step:17108 [D loss: 1.414202, acc: 14.84%] [G loss: 2.155649]\n",
      "epoch:21 step:17109 [D loss: 0.172920, acc: 98.44%] [G loss: 3.879670]\n",
      "epoch:21 step:17110 [D loss: 0.469184, acc: 82.03%] [G loss: 3.964417]\n",
      "epoch:21 step:17111 [D loss: 0.465193, acc: 83.59%] [G loss: 2.772552]\n",
      "epoch:21 step:17112 [D loss: 0.116351, acc: 100.00%] [G loss: 5.489829]\n",
      "epoch:21 step:17113 [D loss: 0.749496, acc: 51.56%] [G loss: 3.651278]\n",
      "epoch:21 step:17114 [D loss: 0.207496, acc: 97.66%] [G loss: 3.061340]\n",
      "epoch:21 step:17115 [D loss: 0.586376, acc: 63.28%] [G loss: 1.405624]\n",
      "epoch:21 step:17116 [D loss: 0.422334, acc: 86.72%] [G loss: 3.666255]\n",
      "epoch:21 step:17117 [D loss: 0.781722, acc: 48.44%] [G loss: 2.675339]\n",
      "epoch:21 step:17118 [D loss: 0.266588, acc: 95.31%] [G loss: 3.626458]\n",
      "epoch:21 step:17119 [D loss: 0.552429, acc: 58.59%] [G loss: 3.659781]\n",
      "epoch:21 step:17120 [D loss: 0.274184, acc: 92.19%] [G loss: 3.087467]\n",
      "epoch:21 step:17121 [D loss: 0.153320, acc: 99.22%] [G loss: 3.441074]\n",
      "epoch:21 step:17122 [D loss: 0.188898, acc: 100.00%] [G loss: 2.994739]\n",
      "epoch:21 step:17123 [D loss: 0.257620, acc: 95.31%] [G loss: 3.162025]\n",
      "epoch:21 step:17124 [D loss: 0.158704, acc: 98.44%] [G loss: 3.989384]\n",
      "epoch:21 step:17125 [D loss: 0.817829, acc: 51.56%] [G loss: 4.009737]\n",
      "epoch:21 step:17126 [D loss: 0.152609, acc: 100.00%] [G loss: 4.199501]\n",
      "epoch:21 step:17127 [D loss: 0.555486, acc: 58.59%] [G loss: 4.139508]\n",
      "epoch:21 step:17128 [D loss: 0.760195, acc: 57.81%] [G loss: 2.605598]\n",
      "epoch:21 step:17129 [D loss: 0.666288, acc: 54.69%] [G loss: 3.510879]\n",
      "epoch:21 step:17130 [D loss: 1.031893, acc: 31.25%] [G loss: 4.476748]\n",
      "epoch:21 step:17131 [D loss: 0.511085, acc: 80.47%] [G loss: 3.271072]\n",
      "epoch:21 step:17132 [D loss: 1.366033, acc: 44.53%] [G loss: 3.347216]\n",
      "epoch:21 step:17133 [D loss: 0.726748, acc: 52.34%] [G loss: 3.414417]\n",
      "epoch:21 step:17134 [D loss: 0.545187, acc: 74.22%] [G loss: 3.518789]\n",
      "epoch:21 step:17135 [D loss: 0.881885, acc: 35.94%] [G loss: 5.563048]\n",
      "epoch:21 step:17136 [D loss: 0.513046, acc: 74.22%] [G loss: 2.697104]\n",
      "epoch:21 step:17137 [D loss: 0.267908, acc: 95.31%] [G loss: 2.517108]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:21 step:17138 [D loss: 0.513906, acc: 79.69%] [G loss: 3.766595]\n",
      "epoch:21 step:17139 [D loss: 0.510521, acc: 67.97%] [G loss: 3.753972]\n",
      "epoch:21 step:17140 [D loss: 0.539519, acc: 71.09%] [G loss: 3.751790]\n",
      "epoch:21 step:17141 [D loss: 0.748718, acc: 52.34%] [G loss: 2.816842]\n",
      "epoch:21 step:17142 [D loss: 0.330070, acc: 92.97%] [G loss: 3.578149]\n",
      "epoch:21 step:17143 [D loss: 0.380671, acc: 88.28%] [G loss: 4.015338]\n",
      "epoch:21 step:17144 [D loss: 0.307657, acc: 94.53%] [G loss: 5.076472]\n",
      "epoch:21 step:17145 [D loss: 0.625857, acc: 66.41%] [G loss: 2.504613]\n",
      "epoch:21 step:17146 [D loss: 0.290451, acc: 96.09%] [G loss: 2.566437]\n",
      "epoch:21 step:17147 [D loss: 1.130674, acc: 15.62%] [G loss: 2.422969]\n",
      "epoch:21 step:17148 [D loss: 0.568601, acc: 75.00%] [G loss: 3.156002]\n",
      "epoch:21 step:17149 [D loss: 0.333261, acc: 92.19%] [G loss: 3.322569]\n",
      "epoch:21 step:17150 [D loss: 0.565352, acc: 65.62%] [G loss: 2.524394]\n",
      "epoch:21 step:17151 [D loss: 0.564507, acc: 76.56%] [G loss: 3.629577]\n",
      "epoch:21 step:17152 [D loss: 0.301584, acc: 95.31%] [G loss: 2.490959]\n",
      "epoch:21 step:17153 [D loss: 0.413568, acc: 78.91%] [G loss: 2.538835]\n",
      "epoch:21 step:17154 [D loss: 0.564600, acc: 68.75%] [G loss: 3.169677]\n",
      "epoch:21 step:17155 [D loss: 0.644260, acc: 64.84%] [G loss: 3.364328]\n",
      "epoch:21 step:17156 [D loss: 0.435092, acc: 89.84%] [G loss: 2.863953]\n",
      "epoch:21 step:17157 [D loss: 0.256451, acc: 96.09%] [G loss: 4.774784]\n",
      "epoch:21 step:17158 [D loss: 0.260373, acc: 96.09%] [G loss: 3.285082]\n",
      "epoch:21 step:17159 [D loss: 0.282388, acc: 96.88%] [G loss: 3.782004]\n",
      "epoch:21 step:17160 [D loss: 0.467871, acc: 83.59%] [G loss: 1.696315]\n",
      "epoch:21 step:17161 [D loss: 0.137028, acc: 100.00%] [G loss: 3.291600]\n",
      "epoch:21 step:17162 [D loss: 0.952019, acc: 30.47%] [G loss: 2.772841]\n",
      "epoch:21 step:17163 [D loss: 0.395456, acc: 78.12%] [G loss: 3.401124]\n",
      "epoch:21 step:17164 [D loss: 0.953298, acc: 50.78%] [G loss: 4.176428]\n",
      "epoch:21 step:17165 [D loss: 0.885586, acc: 33.59%] [G loss: 3.022290]\n",
      "epoch:21 step:17166 [D loss: 0.519557, acc: 68.75%] [G loss: 1.698281]\n",
      "epoch:21 step:17167 [D loss: 0.348059, acc: 93.75%] [G loss: 3.447340]\n",
      "epoch:21 step:17168 [D loss: 0.216920, acc: 98.44%] [G loss: 3.802381]\n",
      "epoch:21 step:17169 [D loss: 0.540472, acc: 77.34%] [G loss: 3.753507]\n",
      "epoch:21 step:17170 [D loss: 0.580505, acc: 63.28%] [G loss: 3.035581]\n",
      "epoch:21 step:17171 [D loss: 0.388846, acc: 88.28%] [G loss: 3.087215]\n",
      "epoch:21 step:17172 [D loss: 0.779395, acc: 43.75%] [G loss: 4.072417]\n",
      "epoch:21 step:17173 [D loss: 0.203689, acc: 97.66%] [G loss: 3.656724]\n",
      "epoch:21 step:17174 [D loss: 0.092383, acc: 100.00%] [G loss: 5.832096]\n",
      "epoch:21 step:17175 [D loss: 1.016707, acc: 33.59%] [G loss: 2.077953]\n",
      "epoch:21 step:17176 [D loss: 0.632127, acc: 61.72%] [G loss: 3.084971]\n",
      "epoch:21 step:17177 [D loss: 0.633670, acc: 61.72%] [G loss: 2.905247]\n",
      "epoch:21 step:17178 [D loss: 0.754625, acc: 57.03%] [G loss: 1.889181]\n",
      "epoch:21 step:17179 [D loss: 0.189842, acc: 99.22%] [G loss: 3.607563]\n",
      "epoch:21 step:17180 [D loss: 1.008785, acc: 50.00%] [G loss: 2.146175]\n",
      "epoch:21 step:17181 [D loss: 1.252359, acc: 9.38%] [G loss: 1.821841]\n",
      "epoch:21 step:17182 [D loss: 0.179150, acc: 97.66%] [G loss: 3.336660]\n",
      "epoch:22 step:17183 [D loss: 0.234703, acc: 94.53%] [G loss: 6.334392]\n",
      "epoch:22 step:17184 [D loss: 0.195435, acc: 98.44%] [G loss: 3.454141]\n",
      "epoch:22 step:17185 [D loss: 0.822015, acc: 49.22%] [G loss: 3.159410]\n",
      "epoch:22 step:17186 [D loss: 0.272339, acc: 93.75%] [G loss: 2.337938]\n",
      "epoch:22 step:17187 [D loss: 0.285817, acc: 93.75%] [G loss: 3.996027]\n",
      "epoch:22 step:17188 [D loss: 0.840310, acc: 37.50%] [G loss: 3.217876]\n",
      "epoch:22 step:17189 [D loss: 0.262076, acc: 93.75%] [G loss: 2.596973]\n",
      "epoch:22 step:17190 [D loss: 0.997545, acc: 36.72%] [G loss: 2.196589]\n",
      "epoch:22 step:17191 [D loss: 0.152131, acc: 100.00%] [G loss: 2.051855]\n",
      "epoch:22 step:17192 [D loss: 0.460506, acc: 69.53%] [G loss: 3.384868]\n",
      "epoch:22 step:17193 [D loss: 0.595231, acc: 70.31%] [G loss: 3.445265]\n",
      "epoch:22 step:17194 [D loss: 0.212693, acc: 98.44%] [G loss: 3.980130]\n",
      "epoch:22 step:17195 [D loss: 0.610580, acc: 57.03%] [G loss: 4.257664]\n",
      "epoch:22 step:17196 [D loss: 0.286182, acc: 92.19%] [G loss: 2.384218]\n",
      "epoch:22 step:17197 [D loss: 1.242792, acc: 31.25%] [G loss: 2.700657]\n",
      "epoch:22 step:17198 [D loss: 0.814869, acc: 52.34%] [G loss: 3.755674]\n",
      "epoch:22 step:17199 [D loss: 1.273921, acc: 50.00%] [G loss: 3.193918]\n",
      "epoch:22 step:17200 [D loss: 0.458823, acc: 71.09%] [G loss: 3.058650]\n",
      "##############\n",
      "[0.85751056 0.88459383 0.8264862  0.81018013 0.788427   0.83309613\n",
      " 0.88810084 0.84031276 0.82141001 0.84207009]\n",
      "##########\n",
      "epoch:22 step:17201 [D loss: 0.507956, acc: 83.59%] [G loss: 2.262561]\n",
      "epoch:22 step:17202 [D loss: 0.326560, acc: 93.75%] [G loss: 2.907076]\n",
      "epoch:22 step:17203 [D loss: 0.067548, acc: 99.22%] [G loss: 4.336777]\n",
      "epoch:22 step:17204 [D loss: 0.763993, acc: 53.12%] [G loss: 2.914784]\n",
      "epoch:22 step:17205 [D loss: 0.293489, acc: 88.28%] [G loss: 2.460245]\n",
      "epoch:22 step:17206 [D loss: 0.842332, acc: 46.88%] [G loss: 3.932241]\n",
      "epoch:22 step:17207 [D loss: 0.559957, acc: 67.19%] [G loss: 2.197897]\n",
      "epoch:22 step:17208 [D loss: 0.127386, acc: 100.00%] [G loss: 4.070884]\n",
      "epoch:22 step:17209 [D loss: 0.234259, acc: 96.09%] [G loss: 2.528018]\n",
      "epoch:22 step:17210 [D loss: 1.097789, acc: 46.88%] [G loss: 1.887603]\n",
      "epoch:22 step:17211 [D loss: 0.197295, acc: 100.00%] [G loss: 2.910918]\n",
      "epoch:22 step:17212 [D loss: 0.309705, acc: 93.75%] [G loss: 4.128296]\n",
      "epoch:22 step:17213 [D loss: 0.643775, acc: 55.47%] [G loss: 2.268939]\n",
      "epoch:22 step:17214 [D loss: 0.656094, acc: 56.25%] [G loss: 1.828428]\n",
      "epoch:22 step:17215 [D loss: 0.474848, acc: 82.81%] [G loss: 2.893160]\n",
      "epoch:22 step:17216 [D loss: 0.415606, acc: 85.16%] [G loss: 4.275045]\n",
      "epoch:22 step:17217 [D loss: 0.493596, acc: 64.84%] [G loss: 3.904142]\n",
      "epoch:22 step:17218 [D loss: 0.607450, acc: 55.47%] [G loss: 5.424478]\n",
      "epoch:22 step:17219 [D loss: 0.427664, acc: 75.00%] [G loss: 3.629032]\n",
      "epoch:22 step:17220 [D loss: 0.756154, acc: 53.91%] [G loss: 2.759910]\n",
      "epoch:22 step:17221 [D loss: 0.087737, acc: 98.44%] [G loss: 2.868167]\n",
      "epoch:22 step:17222 [D loss: 0.108682, acc: 100.00%] [G loss: 3.409038]\n",
      "epoch:22 step:17223 [D loss: 0.103388, acc: 100.00%] [G loss: 3.407744]\n",
      "epoch:22 step:17224 [D loss: 0.196082, acc: 98.44%] [G loss: 3.519466]\n",
      "epoch:22 step:17225 [D loss: 0.171883, acc: 97.66%] [G loss: 3.506520]\n",
      "epoch:22 step:17226 [D loss: 0.436336, acc: 82.03%] [G loss: 2.628453]\n",
      "epoch:22 step:17227 [D loss: 0.261266, acc: 95.31%] [G loss: 4.549074]\n",
      "epoch:22 step:17228 [D loss: 0.237610, acc: 96.09%] [G loss: 3.283274]\n",
      "epoch:22 step:17229 [D loss: 0.881508, acc: 48.44%] [G loss: 2.345209]\n",
      "epoch:22 step:17230 [D loss: 0.062753, acc: 100.00%] [G loss: 4.066031]\n",
      "epoch:22 step:17231 [D loss: 0.311601, acc: 94.53%] [G loss: 2.321904]\n",
      "epoch:22 step:17232 [D loss: 0.420405, acc: 87.50%] [G loss: 2.469590]\n",
      "epoch:22 step:17233 [D loss: 0.707182, acc: 54.69%] [G loss: 3.640018]\n",
      "epoch:22 step:17234 [D loss: 0.320281, acc: 95.31%] [G loss: 3.318386]\n",
      "epoch:22 step:17235 [D loss: 0.403633, acc: 89.06%] [G loss: 3.790411]\n",
      "epoch:22 step:17236 [D loss: 0.594655, acc: 64.06%] [G loss: 2.363944]\n",
      "epoch:22 step:17237 [D loss: 0.599727, acc: 64.06%] [G loss: 3.849644]\n",
      "epoch:22 step:17238 [D loss: 0.790267, acc: 50.78%] [G loss: 2.037067]\n",
      "epoch:22 step:17239 [D loss: 0.316862, acc: 89.06%] [G loss: 3.239689]\n",
      "epoch:22 step:17240 [D loss: 0.132741, acc: 100.00%] [G loss: 3.238873]\n",
      "epoch:22 step:17241 [D loss: 0.343846, acc: 97.66%] [G loss: 3.857633]\n",
      "epoch:22 step:17242 [D loss: 0.190362, acc: 99.22%] [G loss: 3.132275]\n",
      "epoch:22 step:17243 [D loss: 0.410536, acc: 75.00%] [G loss: 2.614099]\n",
      "epoch:22 step:17244 [D loss: 0.087406, acc: 100.00%] [G loss: 4.157845]\n",
      "epoch:22 step:17245 [D loss: 0.574880, acc: 72.66%] [G loss: 3.357381]\n",
      "epoch:22 step:17246 [D loss: 0.154152, acc: 100.00%] [G loss: 4.593119]\n",
      "epoch:22 step:17247 [D loss: 0.040302, acc: 100.00%] [G loss: 3.933179]\n",
      "epoch:22 step:17248 [D loss: 0.394166, acc: 90.62%] [G loss: 1.839551]\n",
      "epoch:22 step:17249 [D loss: 1.692175, acc: 21.09%] [G loss: 1.245879]\n",
      "epoch:22 step:17250 [D loss: 0.517384, acc: 77.34%] [G loss: 3.166068]\n",
      "epoch:22 step:17251 [D loss: 0.210676, acc: 96.88%] [G loss: 3.216480]\n",
      "epoch:22 step:17252 [D loss: 0.997405, acc: 50.00%] [G loss: 3.944939]\n",
      "epoch:22 step:17253 [D loss: 0.483138, acc: 71.88%] [G loss: 3.211999]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:22 step:17254 [D loss: 0.401000, acc: 76.56%] [G loss: 2.415629]\n",
      "epoch:22 step:17255 [D loss: 0.478137, acc: 67.97%] [G loss: 2.509279]\n",
      "epoch:22 step:17256 [D loss: 0.542890, acc: 70.31%] [G loss: 2.511218]\n",
      "epoch:22 step:17257 [D loss: 0.894825, acc: 32.81%] [G loss: 2.432378]\n",
      "epoch:22 step:17258 [D loss: 0.817360, acc: 50.78%] [G loss: 4.345536]\n",
      "epoch:22 step:17259 [D loss: 0.141202, acc: 99.22%] [G loss: 2.287356]\n",
      "epoch:22 step:17260 [D loss: 0.183755, acc: 96.09%] [G loss: 3.865626]\n",
      "epoch:22 step:17261 [D loss: 1.104617, acc: 51.56%] [G loss: 3.074903]\n",
      "epoch:22 step:17262 [D loss: 0.291342, acc: 95.31%] [G loss: 3.331685]\n",
      "epoch:22 step:17263 [D loss: 0.502504, acc: 67.19%] [G loss: 3.974605]\n",
      "epoch:22 step:17264 [D loss: 0.196203, acc: 99.22%] [G loss: 1.824687]\n",
      "epoch:22 step:17265 [D loss: 0.239062, acc: 96.88%] [G loss: 4.236406]\n",
      "epoch:22 step:17266 [D loss: 1.011614, acc: 32.81%] [G loss: 3.487371]\n",
      "epoch:22 step:17267 [D loss: 0.193617, acc: 98.44%] [G loss: 3.640557]\n",
      "epoch:22 step:17268 [D loss: 0.838360, acc: 39.06%] [G loss: 3.553808]\n",
      "epoch:22 step:17269 [D loss: 0.228575, acc: 97.66%] [G loss: 2.715656]\n",
      "epoch:22 step:17270 [D loss: 0.198802, acc: 99.22%] [G loss: 2.779499]\n",
      "epoch:22 step:17271 [D loss: 0.065623, acc: 100.00%] [G loss: 5.261637]\n",
      "epoch:22 step:17272 [D loss: 0.209733, acc: 96.88%] [G loss: 2.798645]\n",
      "epoch:22 step:17273 [D loss: 0.081078, acc: 99.22%] [G loss: 3.797176]\n",
      "epoch:22 step:17274 [D loss: 0.384855, acc: 74.22%] [G loss: 3.741162]\n",
      "epoch:22 step:17275 [D loss: 0.152607, acc: 98.44%] [G loss: 3.489823]\n",
      "epoch:22 step:17276 [D loss: 0.843305, acc: 52.34%] [G loss: 2.405227]\n",
      "epoch:22 step:17277 [D loss: 0.809912, acc: 50.00%] [G loss: 3.417716]\n",
      "epoch:22 step:17278 [D loss: 0.483416, acc: 71.09%] [G loss: 2.931233]\n",
      "epoch:22 step:17279 [D loss: 0.185609, acc: 98.44%] [G loss: 3.066236]\n",
      "epoch:22 step:17280 [D loss: 0.429259, acc: 86.72%] [G loss: 3.105931]\n",
      "epoch:22 step:17281 [D loss: 0.978318, acc: 50.00%] [G loss: 3.796022]\n",
      "epoch:22 step:17282 [D loss: 0.126117, acc: 100.00%] [G loss: 3.479507]\n",
      "epoch:22 step:17283 [D loss: 0.495022, acc: 62.50%] [G loss: 2.571049]\n",
      "epoch:22 step:17284 [D loss: 0.437562, acc: 82.03%] [G loss: 2.318435]\n",
      "epoch:22 step:17285 [D loss: 0.479583, acc: 66.41%] [G loss: 3.856781]\n",
      "epoch:22 step:17286 [D loss: 0.410194, acc: 80.47%] [G loss: 1.937189]\n",
      "epoch:22 step:17287 [D loss: 0.442177, acc: 81.25%] [G loss: 3.798659]\n",
      "epoch:22 step:17288 [D loss: 0.382707, acc: 95.31%] [G loss: 2.946045]\n",
      "epoch:22 step:17289 [D loss: 0.443779, acc: 74.22%] [G loss: 2.776939]\n",
      "epoch:22 step:17290 [D loss: 0.842757, acc: 51.56%] [G loss: 2.722568]\n",
      "epoch:22 step:17291 [D loss: 0.617293, acc: 61.72%] [G loss: 3.625497]\n",
      "epoch:22 step:17292 [D loss: 0.428212, acc: 76.56%] [G loss: 3.971713]\n",
      "epoch:22 step:17293 [D loss: 0.715638, acc: 54.69%] [G loss: 5.158160]\n",
      "epoch:22 step:17294 [D loss: 0.272443, acc: 94.53%] [G loss: 3.657576]\n",
      "epoch:22 step:17295 [D loss: 0.468598, acc: 83.59%] [G loss: 2.954253]\n",
      "epoch:22 step:17296 [D loss: 0.609767, acc: 56.25%] [G loss: 3.689766]\n",
      "epoch:22 step:17297 [D loss: 1.157989, acc: 14.06%] [G loss: 2.768775]\n",
      "epoch:22 step:17298 [D loss: 0.575383, acc: 67.19%] [G loss: 3.288639]\n",
      "epoch:22 step:17299 [D loss: 0.788067, acc: 50.00%] [G loss: 3.236293]\n",
      "epoch:22 step:17300 [D loss: 0.386613, acc: 90.62%] [G loss: 3.092059]\n",
      "epoch:22 step:17301 [D loss: 0.520479, acc: 63.28%] [G loss: 3.118022]\n",
      "epoch:22 step:17302 [D loss: 0.315354, acc: 83.59%] [G loss: 5.565925]\n",
      "epoch:22 step:17303 [D loss: 0.404656, acc: 78.91%] [G loss: 3.607473]\n",
      "epoch:22 step:17304 [D loss: 0.093207, acc: 100.00%] [G loss: 4.687451]\n",
      "epoch:22 step:17305 [D loss: 0.403758, acc: 88.28%] [G loss: 3.685776]\n",
      "epoch:22 step:17306 [D loss: 0.274958, acc: 96.88%] [G loss: 2.691286]\n",
      "epoch:22 step:17307 [D loss: 1.182142, acc: 21.09%] [G loss: 3.896723]\n",
      "epoch:22 step:17308 [D loss: 0.398360, acc: 86.72%] [G loss: 4.601973]\n",
      "epoch:22 step:17309 [D loss: 0.314631, acc: 92.97%] [G loss: 3.201454]\n",
      "epoch:22 step:17310 [D loss: 0.737134, acc: 53.12%] [G loss: 3.832304]\n",
      "epoch:22 step:17311 [D loss: 0.139142, acc: 100.00%] [G loss: 3.756094]\n",
      "epoch:22 step:17312 [D loss: 0.662402, acc: 54.69%] [G loss: 3.143975]\n",
      "epoch:22 step:17313 [D loss: 0.550282, acc: 60.16%] [G loss: 3.724933]\n",
      "epoch:22 step:17314 [D loss: 0.265223, acc: 97.66%] [G loss: 2.617582]\n",
      "epoch:22 step:17315 [D loss: 0.259792, acc: 97.66%] [G loss: 3.520722]\n",
      "epoch:22 step:17316 [D loss: 0.160658, acc: 99.22%] [G loss: 3.693218]\n",
      "epoch:22 step:17317 [D loss: 0.886902, acc: 32.03%] [G loss: 3.997984]\n",
      "epoch:22 step:17318 [D loss: 0.354272, acc: 89.84%] [G loss: 3.027615]\n",
      "epoch:22 step:17319 [D loss: 0.306936, acc: 96.88%] [G loss: 4.974369]\n",
      "epoch:22 step:17320 [D loss: 0.629629, acc: 61.72%] [G loss: 3.073116]\n",
      "epoch:22 step:17321 [D loss: 0.551211, acc: 74.22%] [G loss: 2.835591]\n",
      "epoch:22 step:17322 [D loss: 0.246105, acc: 92.97%] [G loss: 4.598195]\n",
      "epoch:22 step:17323 [D loss: 0.891290, acc: 41.41%] [G loss: 3.226800]\n",
      "epoch:22 step:17324 [D loss: 0.291072, acc: 95.31%] [G loss: 3.576339]\n",
      "epoch:22 step:17325 [D loss: 0.390831, acc: 87.50%] [G loss: 2.870909]\n",
      "epoch:22 step:17326 [D loss: 1.077338, acc: 46.09%] [G loss: 2.028331]\n",
      "epoch:22 step:17327 [D loss: 0.522273, acc: 79.69%] [G loss: 3.025587]\n",
      "epoch:22 step:17328 [D loss: 0.626207, acc: 63.28%] [G loss: 2.057817]\n",
      "epoch:22 step:17329 [D loss: 0.538812, acc: 77.34%] [G loss: 3.116190]\n",
      "epoch:22 step:17330 [D loss: 0.474823, acc: 78.91%] [G loss: 3.577974]\n",
      "epoch:22 step:17331 [D loss: 0.383816, acc: 93.75%] [G loss: 3.071247]\n",
      "epoch:22 step:17332 [D loss: 0.419954, acc: 87.50%] [G loss: 3.213570]\n",
      "epoch:22 step:17333 [D loss: 0.816620, acc: 51.56%] [G loss: 4.198620]\n",
      "epoch:22 step:17334 [D loss: 0.984450, acc: 50.00%] [G loss: 2.460040]\n",
      "epoch:22 step:17335 [D loss: 0.426111, acc: 81.25%] [G loss: 3.490804]\n",
      "epoch:22 step:17336 [D loss: 0.824794, acc: 50.00%] [G loss: 2.117778]\n",
      "epoch:22 step:17337 [D loss: 0.442786, acc: 81.25%] [G loss: 2.822050]\n",
      "epoch:22 step:17338 [D loss: 0.479909, acc: 77.34%] [G loss: 3.292488]\n",
      "epoch:22 step:17339 [D loss: 0.379535, acc: 89.06%] [G loss: 2.685377]\n",
      "epoch:22 step:17340 [D loss: 0.565363, acc: 75.00%] [G loss: 2.579500]\n",
      "epoch:22 step:17341 [D loss: 0.949909, acc: 39.84%] [G loss: 3.763929]\n",
      "epoch:22 step:17342 [D loss: 1.118411, acc: 25.00%] [G loss: 3.063058]\n",
      "epoch:22 step:17343 [D loss: 0.541130, acc: 67.19%] [G loss: 4.323070]\n",
      "epoch:22 step:17344 [D loss: 0.518449, acc: 77.34%] [G loss: 3.276550]\n",
      "epoch:22 step:17345 [D loss: 0.695550, acc: 53.12%] [G loss: 4.055289]\n",
      "epoch:22 step:17346 [D loss: 0.105864, acc: 100.00%] [G loss: 4.629992]\n",
      "epoch:22 step:17347 [D loss: 0.399097, acc: 92.97%] [G loss: 2.894238]\n",
      "epoch:22 step:17348 [D loss: 0.677644, acc: 57.81%] [G loss: 3.113790]\n",
      "epoch:22 step:17349 [D loss: 0.303505, acc: 91.41%] [G loss: 4.420927]\n",
      "epoch:22 step:17350 [D loss: 0.400572, acc: 90.62%] [G loss: 3.772113]\n",
      "epoch:22 step:17351 [D loss: 0.387588, acc: 80.47%] [G loss: 2.712475]\n",
      "epoch:22 step:17352 [D loss: 0.680614, acc: 58.59%] [G loss: 2.776498]\n",
      "epoch:22 step:17353 [D loss: 0.376818, acc: 75.00%] [G loss: 3.533559]\n",
      "epoch:22 step:17354 [D loss: 0.961447, acc: 41.41%] [G loss: 3.451233]\n",
      "epoch:22 step:17355 [D loss: 0.144681, acc: 100.00%] [G loss: 2.383892]\n",
      "epoch:22 step:17356 [D loss: 0.577221, acc: 70.31%] [G loss: 2.966183]\n",
      "epoch:22 step:17357 [D loss: 1.060135, acc: 28.91%] [G loss: 2.300623]\n",
      "epoch:22 step:17358 [D loss: 0.331412, acc: 93.75%] [G loss: 2.318349]\n",
      "epoch:22 step:17359 [D loss: 0.399048, acc: 88.28%] [G loss: 3.049045]\n",
      "epoch:22 step:17360 [D loss: 0.931134, acc: 38.28%] [G loss: 2.469375]\n",
      "epoch:22 step:17361 [D loss: 0.379493, acc: 89.06%] [G loss: 3.094187]\n",
      "epoch:22 step:17362 [D loss: 0.553075, acc: 60.94%] [G loss: 3.995506]\n",
      "epoch:22 step:17363 [D loss: 0.475400, acc: 77.34%] [G loss: 2.951765]\n",
      "epoch:22 step:17364 [D loss: 0.943886, acc: 38.28%] [G loss: 3.405028]\n",
      "epoch:22 step:17365 [D loss: 0.254025, acc: 97.66%] [G loss: 3.284441]\n",
      "epoch:22 step:17366 [D loss: 0.769643, acc: 44.53%] [G loss: 4.064668]\n",
      "epoch:22 step:17367 [D loss: 0.260520, acc: 99.22%] [G loss: 5.216545]\n",
      "epoch:22 step:17368 [D loss: 0.615113, acc: 64.06%] [G loss: 2.510806]\n",
      "epoch:22 step:17369 [D loss: 0.256760, acc: 96.09%] [G loss: 3.502688]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:22 step:17370 [D loss: 0.575819, acc: 64.84%] [G loss: 2.672518]\n",
      "epoch:22 step:17371 [D loss: 0.221033, acc: 96.09%] [G loss: 3.676244]\n",
      "epoch:22 step:17372 [D loss: 0.772928, acc: 50.78%] [G loss: 3.109866]\n",
      "epoch:22 step:17373 [D loss: 0.499911, acc: 77.34%] [G loss: 2.168807]\n",
      "epoch:22 step:17374 [D loss: 0.759845, acc: 54.69%] [G loss: 3.291508]\n",
      "epoch:22 step:17375 [D loss: 0.350374, acc: 89.84%] [G loss: 4.112189]\n",
      "epoch:22 step:17376 [D loss: 0.502216, acc: 71.88%] [G loss: 3.257018]\n",
      "epoch:22 step:17377 [D loss: 0.517124, acc: 81.25%] [G loss: 3.290884]\n",
      "epoch:22 step:17378 [D loss: 0.551648, acc: 62.50%] [G loss: 2.471425]\n",
      "epoch:22 step:17379 [D loss: 0.342969, acc: 85.94%] [G loss: 5.050674]\n",
      "epoch:22 step:17380 [D loss: 0.781647, acc: 53.91%] [G loss: 2.721221]\n",
      "epoch:22 step:17381 [D loss: 0.418558, acc: 85.94%] [G loss: 2.981911]\n",
      "epoch:22 step:17382 [D loss: 0.593230, acc: 60.94%] [G loss: 3.467008]\n",
      "epoch:22 step:17383 [D loss: 0.644465, acc: 60.16%] [G loss: 4.015901]\n",
      "epoch:22 step:17384 [D loss: 1.157206, acc: 19.53%] [G loss: 2.916837]\n",
      "epoch:22 step:17385 [D loss: 0.534691, acc: 75.78%] [G loss: 2.868478]\n",
      "epoch:22 step:17386 [D loss: 0.397277, acc: 88.28%] [G loss: 4.982181]\n",
      "epoch:22 step:17387 [D loss: 1.075831, acc: 24.22%] [G loss: 2.620471]\n",
      "epoch:22 step:17388 [D loss: 0.920017, acc: 34.38%] [G loss: 2.430240]\n",
      "epoch:22 step:17389 [D loss: 0.317455, acc: 96.88%] [G loss: 4.674054]\n",
      "epoch:22 step:17390 [D loss: 0.545503, acc: 62.50%] [G loss: 3.012365]\n",
      "epoch:22 step:17391 [D loss: 0.894206, acc: 51.56%] [G loss: 1.977575]\n",
      "epoch:22 step:17392 [D loss: 0.588065, acc: 64.84%] [G loss: 2.660104]\n",
      "epoch:22 step:17393 [D loss: 0.310938, acc: 96.09%] [G loss: 4.813949]\n",
      "epoch:22 step:17394 [D loss: 0.884564, acc: 51.56%] [G loss: 2.589747]\n",
      "epoch:22 step:17395 [D loss: 1.526645, acc: 38.28%] [G loss: 2.925240]\n",
      "epoch:22 step:17396 [D loss: 0.274663, acc: 93.75%] [G loss: 5.010650]\n",
      "epoch:22 step:17397 [D loss: 0.300951, acc: 91.41%] [G loss: 2.934537]\n",
      "epoch:22 step:17398 [D loss: 0.669710, acc: 63.28%] [G loss: 3.385701]\n",
      "epoch:22 step:17399 [D loss: 0.372378, acc: 90.62%] [G loss: 3.085929]\n",
      "epoch:22 step:17400 [D loss: 0.381654, acc: 87.50%] [G loss: 3.118858]\n",
      "##############\n",
      "[0.88888546 0.86797328 0.8190531  0.81010815 0.78157124 0.82240666\n",
      " 0.89598857 0.8149639  0.83250669 0.82043905]\n",
      "##########\n",
      "epoch:22 step:17401 [D loss: 0.444400, acc: 75.00%] [G loss: 3.492186]\n",
      "epoch:22 step:17402 [D loss: 0.463024, acc: 82.03%] [G loss: 2.826880]\n",
      "epoch:22 step:17403 [D loss: 0.554793, acc: 60.16%] [G loss: 1.869132]\n",
      "epoch:22 step:17404 [D loss: 0.627566, acc: 61.72%] [G loss: 2.674886]\n",
      "epoch:22 step:17405 [D loss: 0.473079, acc: 84.38%] [G loss: 2.535455]\n",
      "epoch:22 step:17406 [D loss: 0.500990, acc: 78.91%] [G loss: 1.902968]\n",
      "epoch:22 step:17407 [D loss: 0.136504, acc: 100.00%] [G loss: 4.078838]\n",
      "epoch:22 step:17408 [D loss: 0.422932, acc: 77.34%] [G loss: 2.628361]\n",
      "epoch:22 step:17409 [D loss: 0.503352, acc: 82.81%] [G loss: 2.825861]\n",
      "epoch:22 step:17410 [D loss: 0.434769, acc: 84.38%] [G loss: 2.696251]\n",
      "epoch:22 step:17411 [D loss: 0.226239, acc: 99.22%] [G loss: 3.751263]\n",
      "epoch:22 step:17412 [D loss: 0.724925, acc: 55.47%] [G loss: 2.509905]\n",
      "epoch:22 step:17413 [D loss: 0.223635, acc: 96.88%] [G loss: 5.777709]\n",
      "epoch:22 step:17414 [D loss: 0.674598, acc: 57.81%] [G loss: 2.689908]\n",
      "epoch:22 step:17415 [D loss: 0.134161, acc: 98.44%] [G loss: 3.902936]\n",
      "epoch:22 step:17416 [D loss: 0.559329, acc: 61.72%] [G loss: 3.936266]\n",
      "epoch:22 step:17417 [D loss: 0.592974, acc: 67.19%] [G loss: 3.012708]\n",
      "epoch:22 step:17418 [D loss: 0.277452, acc: 96.88%] [G loss: 3.035018]\n",
      "epoch:22 step:17419 [D loss: 0.595555, acc: 57.81%] [G loss: 3.062407]\n",
      "epoch:22 step:17420 [D loss: 0.570926, acc: 60.16%] [G loss: 3.145672]\n",
      "epoch:22 step:17421 [D loss: 0.450437, acc: 82.03%] [G loss: 3.020952]\n",
      "epoch:22 step:17422 [D loss: 0.366305, acc: 87.50%] [G loss: 2.381561]\n",
      "epoch:22 step:17423 [D loss: 0.260702, acc: 96.88%] [G loss: 3.119628]\n",
      "epoch:22 step:17424 [D loss: 0.222665, acc: 97.66%] [G loss: 4.297736]\n",
      "epoch:22 step:17425 [D loss: 0.540048, acc: 75.00%] [G loss: 3.099030]\n",
      "epoch:22 step:17426 [D loss: 0.322990, acc: 90.62%] [G loss: 2.685429]\n",
      "epoch:22 step:17427 [D loss: 1.161832, acc: 42.97%] [G loss: 2.749283]\n",
      "epoch:22 step:17428 [D loss: 0.194720, acc: 99.22%] [G loss: 2.819604]\n",
      "epoch:22 step:17429 [D loss: 0.739775, acc: 52.34%] [G loss: 1.568185]\n",
      "epoch:22 step:17430 [D loss: 0.604356, acc: 67.97%] [G loss: 3.139942]\n",
      "epoch:22 step:17431 [D loss: 0.198827, acc: 96.88%] [G loss: 2.731444]\n",
      "epoch:22 step:17432 [D loss: 0.308997, acc: 92.97%] [G loss: 2.004875]\n",
      "epoch:22 step:17433 [D loss: 0.636409, acc: 65.62%] [G loss: 3.977622]\n",
      "epoch:22 step:17434 [D loss: 0.453839, acc: 82.03%] [G loss: 2.784524]\n",
      "epoch:22 step:17435 [D loss: 1.259318, acc: 41.41%] [G loss: 3.638292]\n",
      "epoch:22 step:17436 [D loss: 0.832485, acc: 50.78%] [G loss: 3.399423]\n",
      "epoch:22 step:17437 [D loss: 0.522764, acc: 67.97%] [G loss: 3.537820]\n",
      "epoch:22 step:17438 [D loss: 0.345496, acc: 85.16%] [G loss: 3.822302]\n",
      "epoch:22 step:17439 [D loss: 0.951661, acc: 28.12%] [G loss: 2.970223]\n",
      "epoch:22 step:17440 [D loss: 0.388133, acc: 86.72%] [G loss: 3.145792]\n",
      "epoch:22 step:17441 [D loss: 0.653540, acc: 60.16%] [G loss: 3.111808]\n",
      "epoch:22 step:17442 [D loss: 0.296499, acc: 95.31%] [G loss: 3.097290]\n",
      "epoch:22 step:17443 [D loss: 0.309757, acc: 89.06%] [G loss: 2.811094]\n",
      "epoch:22 step:17444 [D loss: 0.191362, acc: 94.53%] [G loss: 3.512519]\n",
      "epoch:22 step:17445 [D loss: 0.125820, acc: 100.00%] [G loss: 2.896745]\n",
      "epoch:22 step:17446 [D loss: 0.436607, acc: 79.69%] [G loss: 3.212666]\n",
      "epoch:22 step:17447 [D loss: 0.346262, acc: 93.75%] [G loss: 2.457619]\n",
      "epoch:22 step:17448 [D loss: 0.452046, acc: 83.59%] [G loss: 4.947929]\n",
      "epoch:22 step:17449 [D loss: 0.478254, acc: 66.41%] [G loss: 2.498279]\n",
      "epoch:22 step:17450 [D loss: 0.323253, acc: 91.41%] [G loss: 3.157557]\n",
      "epoch:22 step:17451 [D loss: 1.299799, acc: 31.25%] [G loss: 2.079189]\n",
      "epoch:22 step:17452 [D loss: 0.500744, acc: 81.25%] [G loss: 2.307510]\n",
      "epoch:22 step:17453 [D loss: 0.597752, acc: 64.06%] [G loss: 1.375102]\n",
      "epoch:22 step:17454 [D loss: 0.434039, acc: 76.56%] [G loss: 3.477939]\n",
      "epoch:22 step:17455 [D loss: 0.370329, acc: 82.03%] [G loss: 3.425703]\n",
      "epoch:22 step:17456 [D loss: 0.225877, acc: 97.66%] [G loss: 5.610295]\n",
      "epoch:22 step:17457 [D loss: 1.248078, acc: 28.12%] [G loss: 2.568643]\n",
      "epoch:22 step:17458 [D loss: 0.118459, acc: 100.00%] [G loss: 3.139121]\n",
      "epoch:22 step:17459 [D loss: 0.848267, acc: 40.62%] [G loss: 2.320727]\n",
      "epoch:22 step:17460 [D loss: 0.467907, acc: 80.47%] [G loss: 2.767231]\n",
      "epoch:22 step:17461 [D loss: 0.509042, acc: 75.78%] [G loss: 4.498065]\n",
      "epoch:22 step:17462 [D loss: 0.240707, acc: 97.66%] [G loss: 3.566957]\n",
      "epoch:22 step:17463 [D loss: 0.541638, acc: 71.88%] [G loss: 3.061322]\n",
      "epoch:22 step:17464 [D loss: 0.535784, acc: 64.84%] [G loss: 3.211043]\n",
      "epoch:22 step:17465 [D loss: 0.765109, acc: 50.78%] [G loss: 3.010820]\n",
      "epoch:22 step:17466 [D loss: 0.203735, acc: 99.22%] [G loss: 3.202535]\n",
      "epoch:22 step:17467 [D loss: 0.518475, acc: 64.84%] [G loss: 4.902561]\n",
      "epoch:22 step:17468 [D loss: 0.460588, acc: 88.28%] [G loss: 2.720240]\n",
      "epoch:22 step:17469 [D loss: 0.359835, acc: 93.75%] [G loss: 5.110187]\n",
      "epoch:22 step:17470 [D loss: 0.605451, acc: 60.16%] [G loss: 2.055799]\n",
      "epoch:22 step:17471 [D loss: 0.072639, acc: 100.00%] [G loss: 3.664539]\n",
      "epoch:22 step:17472 [D loss: 0.793075, acc: 49.22%] [G loss: 3.366337]\n",
      "epoch:22 step:17473 [D loss: 0.746409, acc: 47.66%] [G loss: 2.885240]\n",
      "epoch:22 step:17474 [D loss: 0.327052, acc: 92.19%] [G loss: 3.258334]\n",
      "epoch:22 step:17475 [D loss: 0.460129, acc: 64.84%] [G loss: 2.276298]\n",
      "epoch:22 step:17476 [D loss: 1.145170, acc: 14.84%] [G loss: 2.534847]\n",
      "epoch:22 step:17477 [D loss: 0.422533, acc: 85.16%] [G loss: 3.699337]\n",
      "epoch:22 step:17478 [D loss: 0.411259, acc: 72.66%] [G loss: 4.618640]\n",
      "epoch:22 step:17479 [D loss: 0.710006, acc: 50.00%] [G loss: 3.209772]\n",
      "epoch:22 step:17480 [D loss: 0.365015, acc: 84.38%] [G loss: 2.487155]\n",
      "epoch:22 step:17481 [D loss: 0.155444, acc: 100.00%] [G loss: 4.181724]\n",
      "epoch:22 step:17482 [D loss: 0.865311, acc: 50.00%] [G loss: 2.914477]\n",
      "epoch:22 step:17483 [D loss: 0.300426, acc: 93.75%] [G loss: 3.237559]\n",
      "epoch:22 step:17484 [D loss: 0.892555, acc: 32.03%] [G loss: 3.554953]\n",
      "epoch:22 step:17485 [D loss: 0.684890, acc: 56.25%] [G loss: 3.630774]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:22 step:17486 [D loss: 0.638484, acc: 57.81%] [G loss: 2.995420]\n",
      "epoch:22 step:17487 [D loss: 0.187851, acc: 97.66%] [G loss: 2.965701]\n",
      "epoch:22 step:17488 [D loss: 0.546349, acc: 78.91%] [G loss: 4.379382]\n",
      "epoch:22 step:17489 [D loss: 0.688247, acc: 58.59%] [G loss: 2.435185]\n",
      "epoch:22 step:17490 [D loss: 1.015455, acc: 46.09%] [G loss: 2.595345]\n",
      "epoch:22 step:17491 [D loss: 0.231752, acc: 99.22%] [G loss: 4.145678]\n",
      "epoch:22 step:17492 [D loss: 0.460634, acc: 84.38%] [G loss: 2.543972]\n",
      "epoch:22 step:17493 [D loss: 0.466536, acc: 82.81%] [G loss: 4.026914]\n",
      "epoch:22 step:17494 [D loss: 0.266273, acc: 94.53%] [G loss: 2.396339]\n",
      "epoch:22 step:17495 [D loss: 0.204677, acc: 98.44%] [G loss: 2.849524]\n",
      "epoch:22 step:17496 [D loss: 1.100331, acc: 49.22%] [G loss: 2.670304]\n",
      "epoch:22 step:17497 [D loss: 0.919051, acc: 53.91%] [G loss: 3.398133]\n",
      "epoch:22 step:17498 [D loss: 0.838599, acc: 50.78%] [G loss: 2.498459]\n",
      "epoch:22 step:17499 [D loss: 0.181248, acc: 97.66%] [G loss: 3.019644]\n",
      "epoch:22 step:17500 [D loss: 0.233929, acc: 96.09%] [G loss: 2.663960]\n",
      "epoch:22 step:17501 [D loss: 0.720446, acc: 53.91%] [G loss: 3.446475]\n",
      "epoch:22 step:17502 [D loss: 1.105295, acc: 30.47%] [G loss: 3.678531]\n",
      "epoch:22 step:17503 [D loss: 0.545277, acc: 66.41%] [G loss: 3.595995]\n",
      "epoch:22 step:17504 [D loss: 0.237027, acc: 92.97%] [G loss: 4.108990]\n",
      "epoch:22 step:17505 [D loss: 0.309915, acc: 91.41%] [G loss: 4.080242]\n",
      "epoch:22 step:17506 [D loss: 0.295162, acc: 99.22%] [G loss: 3.572625]\n",
      "epoch:22 step:17507 [D loss: 0.137254, acc: 99.22%] [G loss: 5.588602]\n",
      "epoch:22 step:17508 [D loss: 0.505160, acc: 78.91%] [G loss: 3.136734]\n",
      "epoch:22 step:17509 [D loss: 0.164114, acc: 97.66%] [G loss: 3.083021]\n",
      "epoch:22 step:17510 [D loss: 0.145619, acc: 100.00%] [G loss: 3.739622]\n",
      "epoch:22 step:17511 [D loss: 0.671742, acc: 56.25%] [G loss: 3.432294]\n",
      "epoch:22 step:17512 [D loss: 0.309992, acc: 90.62%] [G loss: 3.779383]\n",
      "epoch:22 step:17513 [D loss: 0.300075, acc: 97.66%] [G loss: 2.639472]\n",
      "epoch:22 step:17514 [D loss: 0.411576, acc: 84.38%] [G loss: 2.994805]\n",
      "epoch:22 step:17515 [D loss: 0.049104, acc: 100.00%] [G loss: 4.984704]\n",
      "epoch:22 step:17516 [D loss: 0.635165, acc: 51.56%] [G loss: 3.407059]\n",
      "epoch:22 step:17517 [D loss: 0.421587, acc: 85.94%] [G loss: 3.669074]\n",
      "epoch:22 step:17518 [D loss: 0.444907, acc: 85.16%] [G loss: 2.718493]\n",
      "epoch:22 step:17519 [D loss: 0.544801, acc: 58.59%] [G loss: 2.549002]\n",
      "epoch:22 step:17520 [D loss: 0.668294, acc: 61.72%] [G loss: 3.870992]\n",
      "epoch:22 step:17521 [D loss: 0.290880, acc: 92.97%] [G loss: 4.024729]\n",
      "epoch:22 step:17522 [D loss: 1.108154, acc: 23.44%] [G loss: 2.650074]\n",
      "epoch:22 step:17523 [D loss: 0.334342, acc: 87.50%] [G loss: 3.158966]\n",
      "epoch:22 step:17524 [D loss: 0.934640, acc: 40.62%] [G loss: 3.773473]\n",
      "epoch:22 step:17525 [D loss: 0.645146, acc: 56.25%] [G loss: 2.589340]\n",
      "epoch:22 step:17526 [D loss: 0.402084, acc: 89.84%] [G loss: 1.552729]\n",
      "epoch:22 step:17527 [D loss: 0.797251, acc: 47.66%] [G loss: 3.332073]\n",
      "epoch:22 step:17528 [D loss: 0.367138, acc: 95.31%] [G loss: 3.872494]\n",
      "epoch:22 step:17529 [D loss: 0.172048, acc: 99.22%] [G loss: 3.319804]\n",
      "epoch:22 step:17530 [D loss: 0.443690, acc: 89.06%] [G loss: 4.045033]\n",
      "epoch:22 step:17531 [D loss: 0.464186, acc: 80.47%] [G loss: 3.016028]\n",
      "epoch:22 step:17532 [D loss: 0.430465, acc: 79.69%] [G loss: 2.983902]\n",
      "epoch:22 step:17533 [D loss: 0.523146, acc: 74.22%] [G loss: 3.161406]\n",
      "epoch:22 step:17534 [D loss: 0.657652, acc: 55.47%] [G loss: 4.478130]\n",
      "epoch:22 step:17535 [D loss: 0.972463, acc: 26.56%] [G loss: 2.893236]\n",
      "epoch:22 step:17536 [D loss: 0.299161, acc: 90.62%] [G loss: 3.658968]\n",
      "epoch:22 step:17537 [D loss: 0.282282, acc: 96.09%] [G loss: 3.402416]\n",
      "epoch:22 step:17538 [D loss: 0.307478, acc: 93.75%] [G loss: 3.483025]\n",
      "epoch:22 step:17539 [D loss: 0.575541, acc: 70.31%] [G loss: 3.476858]\n",
      "epoch:22 step:17540 [D loss: 0.490660, acc: 83.59%] [G loss: 3.233037]\n",
      "epoch:22 step:17541 [D loss: 0.534687, acc: 70.31%] [G loss: 3.585931]\n",
      "epoch:22 step:17542 [D loss: 0.592780, acc: 70.31%] [G loss: 3.140671]\n",
      "epoch:22 step:17543 [D loss: 0.565114, acc: 70.31%] [G loss: 2.505349]\n",
      "epoch:22 step:17544 [D loss: 0.479955, acc: 82.03%] [G loss: 3.307433]\n",
      "epoch:22 step:17545 [D loss: 0.273395, acc: 92.97%] [G loss: 2.610939]\n",
      "epoch:22 step:17546 [D loss: 0.377989, acc: 94.53%] [G loss: 4.284308]\n",
      "epoch:22 step:17547 [D loss: 0.261676, acc: 99.22%] [G loss: 3.736255]\n",
      "epoch:22 step:17548 [D loss: 1.034190, acc: 35.16%] [G loss: 3.202703]\n",
      "epoch:22 step:17549 [D loss: 0.419023, acc: 90.62%] [G loss: 4.023214]\n",
      "epoch:22 step:17550 [D loss: 0.191895, acc: 99.22%] [G loss: 4.042006]\n",
      "epoch:22 step:17551 [D loss: 0.703470, acc: 57.03%] [G loss: 3.735831]\n",
      "epoch:22 step:17552 [D loss: 0.534909, acc: 78.12%] [G loss: 2.780599]\n",
      "epoch:22 step:17553 [D loss: 0.220227, acc: 100.00%] [G loss: 2.886053]\n",
      "epoch:22 step:17554 [D loss: 0.412369, acc: 82.81%] [G loss: 3.247622]\n",
      "epoch:22 step:17555 [D loss: 0.717460, acc: 56.25%] [G loss: 3.476587]\n",
      "epoch:22 step:17556 [D loss: 0.213869, acc: 97.66%] [G loss: 4.980983]\n",
      "epoch:22 step:17557 [D loss: 0.182956, acc: 96.88%] [G loss: 3.358437]\n",
      "epoch:22 step:17558 [D loss: 0.432457, acc: 85.16%] [G loss: 2.523474]\n",
      "epoch:22 step:17559 [D loss: 0.956460, acc: 42.19%] [G loss: 2.672602]\n",
      "epoch:22 step:17560 [D loss: 0.235997, acc: 98.44%] [G loss: 3.071364]\n",
      "epoch:22 step:17561 [D loss: 0.460124, acc: 78.12%] [G loss: 2.932585]\n",
      "epoch:22 step:17562 [D loss: 0.366668, acc: 91.41%] [G loss: 3.076265]\n",
      "epoch:22 step:17563 [D loss: 0.805164, acc: 50.78%] [G loss: 1.783400]\n",
      "epoch:22 step:17564 [D loss: 0.723059, acc: 51.56%] [G loss: 3.122421]\n",
      "epoch:22 step:17565 [D loss: 0.839705, acc: 46.09%] [G loss: 2.014161]\n",
      "epoch:22 step:17566 [D loss: 0.246875, acc: 96.88%] [G loss: 3.309201]\n",
      "epoch:22 step:17567 [D loss: 0.428979, acc: 82.81%] [G loss: 2.810353]\n",
      "epoch:22 step:17568 [D loss: 0.362315, acc: 92.19%] [G loss: 4.044812]\n",
      "epoch:22 step:17569 [D loss: 0.408530, acc: 80.47%] [G loss: 3.189039]\n",
      "epoch:22 step:17570 [D loss: 0.847301, acc: 50.78%] [G loss: 3.685994]\n",
      "epoch:22 step:17571 [D loss: 0.240464, acc: 100.00%] [G loss: 3.349322]\n",
      "epoch:22 step:17572 [D loss: 0.840749, acc: 52.34%] [G loss: 2.868648]\n",
      "epoch:22 step:17573 [D loss: 1.264086, acc: 39.06%] [G loss: 4.050818]\n",
      "epoch:22 step:17574 [D loss: 0.718523, acc: 46.88%] [G loss: 3.709218]\n",
      "epoch:22 step:17575 [D loss: 1.031002, acc: 17.97%] [G loss: 3.395419]\n",
      "epoch:22 step:17576 [D loss: 0.125796, acc: 100.00%] [G loss: 4.034985]\n",
      "epoch:22 step:17577 [D loss: 0.235520, acc: 98.44%] [G loss: 3.719315]\n",
      "epoch:22 step:17578 [D loss: 0.177530, acc: 99.22%] [G loss: 2.764344]\n",
      "epoch:22 step:17579 [D loss: 0.752895, acc: 51.56%] [G loss: 3.283207]\n",
      "epoch:22 step:17580 [D loss: 0.278827, acc: 96.09%] [G loss: 3.301245]\n",
      "epoch:22 step:17581 [D loss: 0.174352, acc: 96.09%] [G loss: 3.772115]\n",
      "epoch:22 step:17582 [D loss: 0.381773, acc: 70.31%] [G loss: 4.489883]\n",
      "epoch:22 step:17583 [D loss: 0.088050, acc: 100.00%] [G loss: 4.095258]\n",
      "epoch:22 step:17584 [D loss: 0.325693, acc: 96.88%] [G loss: 2.308976]\n",
      "epoch:22 step:17585 [D loss: 0.539340, acc: 70.31%] [G loss: 4.027163]\n",
      "epoch:22 step:17586 [D loss: 0.738712, acc: 56.25%] [G loss: 2.613953]\n",
      "epoch:22 step:17587 [D loss: 0.331213, acc: 85.16%] [G loss: 3.747939]\n",
      "epoch:22 step:17588 [D loss: 0.579435, acc: 71.09%] [G loss: 2.527190]\n",
      "epoch:22 step:17589 [D loss: 0.341539, acc: 84.38%] [G loss: 2.706752]\n",
      "epoch:22 step:17590 [D loss: 0.328340, acc: 95.31%] [G loss: 5.393732]\n",
      "epoch:22 step:17591 [D loss: 0.585589, acc: 67.97%] [G loss: 4.130075]\n",
      "epoch:22 step:17592 [D loss: 0.946705, acc: 21.88%] [G loss: 4.608165]\n",
      "epoch:22 step:17593 [D loss: 0.339848, acc: 93.75%] [G loss: 3.362462]\n",
      "epoch:22 step:17594 [D loss: 0.406101, acc: 82.81%] [G loss: 2.966341]\n",
      "epoch:22 step:17595 [D loss: 0.552214, acc: 67.19%] [G loss: 3.280537]\n",
      "epoch:22 step:17596 [D loss: 0.964775, acc: 45.31%] [G loss: 2.714067]\n",
      "epoch:22 step:17597 [D loss: 0.909336, acc: 36.72%] [G loss: 2.615701]\n",
      "epoch:22 step:17598 [D loss: 0.433640, acc: 83.59%] [G loss: 3.563702]\n",
      "epoch:22 step:17599 [D loss: 0.170740, acc: 98.44%] [G loss: 3.960920]\n",
      "epoch:22 step:17600 [D loss: 0.460824, acc: 65.62%] [G loss: 4.190526]\n",
      "##############\n",
      "[0.84800792 0.86567676 0.81097152 0.79271458 0.7928725  0.81589543\n",
      " 0.90259609 0.80687047 0.80382924 0.85227656]\n",
      "##########\n",
      "epoch:22 step:17601 [D loss: 0.310270, acc: 83.59%] [G loss: 4.205599]\n",
      "epoch:22 step:17602 [D loss: 0.267714, acc: 98.44%] [G loss: 3.173479]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:22 step:17603 [D loss: 0.683726, acc: 58.59%] [G loss: 2.530245]\n",
      "epoch:22 step:17604 [D loss: 0.261503, acc: 90.62%] [G loss: 4.072810]\n",
      "epoch:22 step:17605 [D loss: 0.227134, acc: 98.44%] [G loss: 3.830974]\n",
      "epoch:22 step:17606 [D loss: 0.802356, acc: 43.75%] [G loss: 3.536724]\n",
      "epoch:22 step:17607 [D loss: 0.688910, acc: 59.38%] [G loss: 3.434772]\n",
      "epoch:22 step:17608 [D loss: 0.083898, acc: 100.00%] [G loss: 4.253900]\n",
      "epoch:22 step:17609 [D loss: 0.392036, acc: 87.50%] [G loss: 2.564872]\n",
      "epoch:22 step:17610 [D loss: 0.740711, acc: 49.22%] [G loss: 4.350769]\n",
      "epoch:22 step:17611 [D loss: 0.215789, acc: 97.66%] [G loss: 5.707431]\n",
      "epoch:22 step:17612 [D loss: 0.159551, acc: 100.00%] [G loss: 2.605217]\n",
      "epoch:22 step:17613 [D loss: 0.632169, acc: 64.06%] [G loss: 2.749127]\n",
      "epoch:22 step:17614 [D loss: 0.726399, acc: 53.91%] [G loss: 1.961950]\n",
      "epoch:22 step:17615 [D loss: 0.491733, acc: 66.41%] [G loss: 2.410526]\n",
      "epoch:22 step:17616 [D loss: 0.613897, acc: 53.91%] [G loss: 4.296203]\n",
      "epoch:22 step:17617 [D loss: 0.461541, acc: 71.88%] [G loss: 4.371597]\n",
      "epoch:22 step:17618 [D loss: 0.798919, acc: 54.69%] [G loss: 2.289998]\n",
      "epoch:22 step:17619 [D loss: 0.771281, acc: 49.22%] [G loss: 3.243385]\n",
      "epoch:22 step:17620 [D loss: 0.826706, acc: 51.56%] [G loss: 3.203240]\n",
      "epoch:22 step:17621 [D loss: 0.361581, acc: 81.25%] [G loss: 4.243793]\n",
      "epoch:22 step:17622 [D loss: 0.382417, acc: 80.47%] [G loss: 4.671126]\n",
      "epoch:22 step:17623 [D loss: 0.396423, acc: 85.94%] [G loss: 2.979321]\n",
      "epoch:22 step:17624 [D loss: 0.954565, acc: 30.47%] [G loss: 3.528522]\n",
      "epoch:22 step:17625 [D loss: 0.682593, acc: 53.91%] [G loss: 1.751582]\n",
      "epoch:22 step:17626 [D loss: 0.833567, acc: 45.31%] [G loss: 3.677417]\n",
      "epoch:22 step:17627 [D loss: 0.630146, acc: 61.72%] [G loss: 2.095033]\n",
      "epoch:22 step:17628 [D loss: 0.380158, acc: 89.84%] [G loss: 4.003238]\n",
      "epoch:22 step:17629 [D loss: 0.164533, acc: 99.22%] [G loss: 3.424440]\n",
      "epoch:22 step:17630 [D loss: 0.369537, acc: 92.19%] [G loss: 3.286904]\n",
      "epoch:22 step:17631 [D loss: 0.554254, acc: 71.09%] [G loss: 3.754877]\n",
      "epoch:22 step:17632 [D loss: 0.397700, acc: 92.19%] [G loss: 3.053555]\n",
      "epoch:22 step:17633 [D loss: 0.249081, acc: 89.84%] [G loss: 4.905672]\n",
      "epoch:22 step:17634 [D loss: 0.501651, acc: 80.47%] [G loss: 3.809355]\n",
      "epoch:22 step:17635 [D loss: 0.330865, acc: 92.19%] [G loss: 6.482234]\n",
      "epoch:22 step:17636 [D loss: 0.682203, acc: 54.69%] [G loss: 4.763856]\n",
      "epoch:22 step:17637 [D loss: 0.431217, acc: 72.66%] [G loss: 3.780530]\n",
      "epoch:22 step:17638 [D loss: 0.775986, acc: 50.78%] [G loss: 3.706564]\n",
      "epoch:22 step:17639 [D loss: 0.676369, acc: 60.16%] [G loss: 3.307469]\n",
      "epoch:22 step:17640 [D loss: 0.204350, acc: 97.66%] [G loss: 3.932553]\n",
      "epoch:22 step:17641 [D loss: 0.562807, acc: 70.31%] [G loss: 3.862375]\n",
      "epoch:22 step:17642 [D loss: 0.839399, acc: 40.62%] [G loss: 2.592063]\n",
      "epoch:22 step:17643 [D loss: 0.165299, acc: 99.22%] [G loss: 3.448555]\n",
      "epoch:22 step:17644 [D loss: 0.544710, acc: 77.34%] [G loss: 3.175945]\n",
      "epoch:22 step:17645 [D loss: 0.505091, acc: 73.44%] [G loss: 2.639497]\n",
      "epoch:22 step:17646 [D loss: 0.631549, acc: 64.06%] [G loss: 2.790054]\n",
      "epoch:22 step:17647 [D loss: 0.376719, acc: 95.31%] [G loss: 3.694290]\n",
      "epoch:22 step:17648 [D loss: 0.078879, acc: 100.00%] [G loss: 4.801765]\n",
      "epoch:22 step:17649 [D loss: 0.475594, acc: 85.16%] [G loss: 2.044159]\n",
      "epoch:22 step:17650 [D loss: 0.686108, acc: 64.06%] [G loss: 4.122858]\n",
      "epoch:22 step:17651 [D loss: 0.494161, acc: 78.91%] [G loss: 3.677722]\n",
      "epoch:22 step:17652 [D loss: 0.148580, acc: 100.00%] [G loss: 2.439345]\n",
      "epoch:22 step:17653 [D loss: 0.558286, acc: 71.09%] [G loss: 3.232671]\n",
      "epoch:22 step:17654 [D loss: 1.401402, acc: 16.41%] [G loss: 2.605330]\n",
      "epoch:22 step:17655 [D loss: 0.626640, acc: 65.62%] [G loss: 3.013911]\n",
      "epoch:22 step:17656 [D loss: 0.148188, acc: 100.00%] [G loss: 2.343604]\n",
      "epoch:22 step:17657 [D loss: 0.416347, acc: 82.03%] [G loss: 2.638295]\n",
      "epoch:22 step:17658 [D loss: 0.525690, acc: 70.31%] [G loss: 3.792683]\n",
      "epoch:22 step:17659 [D loss: 0.320852, acc: 92.97%] [G loss: 2.974004]\n",
      "epoch:22 step:17660 [D loss: 0.243987, acc: 97.66%] [G loss: 2.594573]\n",
      "epoch:22 step:17661 [D loss: 1.088980, acc: 39.84%] [G loss: 3.417140]\n",
      "epoch:22 step:17662 [D loss: 0.363576, acc: 85.94%] [G loss: 3.243392]\n",
      "epoch:22 step:17663 [D loss: 0.643106, acc: 63.28%] [G loss: 2.639448]\n",
      "epoch:22 step:17664 [D loss: 1.226449, acc: 42.97%] [G loss: 2.390619]\n",
      "epoch:22 step:17665 [D loss: 0.326223, acc: 92.19%] [G loss: 3.361768]\n",
      "epoch:22 step:17666 [D loss: 1.116983, acc: 25.78%] [G loss: 2.177059]\n",
      "epoch:22 step:17667 [D loss: 0.368863, acc: 92.19%] [G loss: 2.929249]\n",
      "epoch:22 step:17668 [D loss: 0.459804, acc: 80.47%] [G loss: 2.618733]\n",
      "epoch:22 step:17669 [D loss: 0.496157, acc: 82.03%] [G loss: 2.754025]\n",
      "epoch:22 step:17670 [D loss: 0.388532, acc: 89.84%] [G loss: 3.571167]\n",
      "epoch:22 step:17671 [D loss: 0.552201, acc: 61.72%] [G loss: 3.580417]\n",
      "epoch:22 step:17672 [D loss: 0.759102, acc: 53.12%] [G loss: 4.311120]\n",
      "epoch:22 step:17673 [D loss: 0.460684, acc: 85.16%] [G loss: 2.638777]\n",
      "epoch:22 step:17674 [D loss: 0.093713, acc: 100.00%] [G loss: 2.840559]\n",
      "epoch:22 step:17675 [D loss: 0.459053, acc: 84.38%] [G loss: 2.212496]\n",
      "epoch:22 step:17676 [D loss: 0.644559, acc: 54.69%] [G loss: 4.077857]\n",
      "epoch:22 step:17677 [D loss: 0.288301, acc: 96.88%] [G loss: 3.508973]\n",
      "epoch:22 step:17678 [D loss: 0.327004, acc: 96.09%] [G loss: 3.321701]\n",
      "epoch:22 step:17679 [D loss: 0.085349, acc: 100.00%] [G loss: 5.192430]\n",
      "epoch:22 step:17680 [D loss: 0.254513, acc: 95.31%] [G loss: 2.507954]\n",
      "epoch:22 step:17681 [D loss: 0.826822, acc: 32.03%] [G loss: 3.207430]\n",
      "epoch:22 step:17682 [D loss: 0.323853, acc: 95.31%] [G loss: 3.603398]\n",
      "epoch:22 step:17683 [D loss: 0.322066, acc: 94.53%] [G loss: 2.392081]\n",
      "epoch:22 step:17684 [D loss: 0.380500, acc: 90.62%] [G loss: 2.872459]\n",
      "epoch:22 step:17685 [D loss: 0.494115, acc: 77.34%] [G loss: 1.823758]\n",
      "epoch:22 step:17686 [D loss: 0.609057, acc: 69.53%] [G loss: 2.167666]\n",
      "epoch:22 step:17687 [D loss: 1.302314, acc: 11.72%] [G loss: 2.449683]\n",
      "epoch:22 step:17688 [D loss: 0.469339, acc: 84.38%] [G loss: 2.685033]\n",
      "epoch:22 step:17689 [D loss: 1.003541, acc: 38.28%] [G loss: 2.303434]\n",
      "epoch:22 step:17690 [D loss: 0.183625, acc: 99.22%] [G loss: 3.226303]\n",
      "epoch:22 step:17691 [D loss: 0.224532, acc: 100.00%] [G loss: 3.492726]\n",
      "epoch:22 step:17692 [D loss: 0.435929, acc: 83.59%] [G loss: 3.905208]\n",
      "epoch:22 step:17693 [D loss: 0.287167, acc: 90.62%] [G loss: 6.042177]\n",
      "epoch:22 step:17694 [D loss: 0.350016, acc: 78.12%] [G loss: 5.484639]\n",
      "epoch:22 step:17695 [D loss: 0.780447, acc: 53.12%] [G loss: 3.143285]\n",
      "epoch:22 step:17696 [D loss: 0.335088, acc: 91.41%] [G loss: 2.729916]\n",
      "epoch:22 step:17697 [D loss: 0.838882, acc: 45.31%] [G loss: 3.704713]\n",
      "epoch:22 step:17698 [D loss: 0.588847, acc: 64.84%] [G loss: 4.538572]\n",
      "epoch:22 step:17699 [D loss: 0.122208, acc: 100.00%] [G loss: 4.955039]\n",
      "epoch:22 step:17700 [D loss: 0.732794, acc: 56.25%] [G loss: 2.424877]\n",
      "epoch:22 step:17701 [D loss: 0.570470, acc: 65.62%] [G loss: 3.262487]\n",
      "epoch:22 step:17702 [D loss: 0.414827, acc: 85.16%] [G loss: 2.109466]\n",
      "epoch:22 step:17703 [D loss: 0.207141, acc: 97.66%] [G loss: 2.548917]\n",
      "epoch:22 step:17704 [D loss: 1.050127, acc: 21.09%] [G loss: 2.838794]\n",
      "epoch:22 step:17705 [D loss: 0.387919, acc: 81.25%] [G loss: 3.113712]\n",
      "epoch:22 step:17706 [D loss: 0.573566, acc: 71.88%] [G loss: 3.278831]\n",
      "epoch:22 step:17707 [D loss: 0.523820, acc: 78.91%] [G loss: 3.224156]\n",
      "epoch:22 step:17708 [D loss: 1.032028, acc: 25.78%] [G loss: 3.486361]\n",
      "epoch:22 step:17709 [D loss: 0.542221, acc: 73.44%] [G loss: 3.185434]\n",
      "epoch:22 step:17710 [D loss: 0.716235, acc: 56.25%] [G loss: 3.109140]\n",
      "epoch:22 step:17711 [D loss: 0.686742, acc: 57.03%] [G loss: 3.105676]\n",
      "epoch:22 step:17712 [D loss: 0.842691, acc: 53.91%] [G loss: 3.572660]\n",
      "epoch:22 step:17713 [D loss: 0.240688, acc: 99.22%] [G loss: 2.635484]\n",
      "epoch:22 step:17714 [D loss: 0.418351, acc: 87.50%] [G loss: 2.507676]\n",
      "epoch:22 step:17715 [D loss: 0.344482, acc: 86.72%] [G loss: 4.157584]\n",
      "epoch:22 step:17716 [D loss: 0.307203, acc: 96.09%] [G loss: 2.588922]\n",
      "epoch:22 step:17717 [D loss: 0.503465, acc: 75.78%] [G loss: 2.993171]\n",
      "epoch:22 step:17718 [D loss: 0.484174, acc: 77.34%] [G loss: 2.643023]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:22 step:17719 [D loss: 0.385049, acc: 80.47%] [G loss: 3.828307]\n",
      "epoch:22 step:17720 [D loss: 0.270712, acc: 98.44%] [G loss: 5.474110]\n",
      "epoch:22 step:17721 [D loss: 0.410017, acc: 88.28%] [G loss: 3.151353]\n",
      "epoch:22 step:17722 [D loss: 0.499262, acc: 83.59%] [G loss: 2.864888]\n",
      "epoch:22 step:17723 [D loss: 0.342464, acc: 92.97%] [G loss: 2.765053]\n",
      "epoch:22 step:17724 [D loss: 0.610678, acc: 61.72%] [G loss: 3.110106]\n",
      "epoch:22 step:17725 [D loss: 0.499472, acc: 78.12%] [G loss: 1.860039]\n",
      "epoch:22 step:17726 [D loss: 0.680011, acc: 59.38%] [G loss: 2.256441]\n",
      "epoch:22 step:17727 [D loss: 0.531686, acc: 82.03%] [G loss: 3.121605]\n",
      "epoch:22 step:17728 [D loss: 0.460765, acc: 78.91%] [G loss: 3.435214]\n",
      "epoch:22 step:17729 [D loss: 0.349389, acc: 92.97%] [G loss: 4.246104]\n",
      "epoch:22 step:17730 [D loss: 0.419981, acc: 74.22%] [G loss: 3.495275]\n",
      "epoch:22 step:17731 [D loss: 1.198829, acc: 29.69%] [G loss: 2.872306]\n",
      "epoch:22 step:17732 [D loss: 0.343833, acc: 89.06%] [G loss: 3.437203]\n",
      "epoch:22 step:17733 [D loss: 0.262355, acc: 96.88%] [G loss: 2.678439]\n",
      "epoch:22 step:17734 [D loss: 0.517932, acc: 80.47%] [G loss: 3.787853]\n",
      "epoch:22 step:17735 [D loss: 0.811414, acc: 47.66%] [G loss: 2.501728]\n",
      "epoch:22 step:17736 [D loss: 0.311632, acc: 92.19%] [G loss: 3.751663]\n",
      "epoch:22 step:17737 [D loss: 0.108835, acc: 100.00%] [G loss: 5.401563]\n",
      "epoch:22 step:17738 [D loss: 0.509700, acc: 67.97%] [G loss: 3.050099]\n",
      "epoch:22 step:17739 [D loss: 0.486553, acc: 80.47%] [G loss: 3.790133]\n",
      "epoch:22 step:17740 [D loss: 0.560197, acc: 75.78%] [G loss: 3.379090]\n",
      "epoch:22 step:17741 [D loss: 0.462245, acc: 83.59%] [G loss: 3.436769]\n",
      "epoch:22 step:17742 [D loss: 0.235494, acc: 97.66%] [G loss: 4.066353]\n",
      "epoch:22 step:17743 [D loss: 0.429241, acc: 77.34%] [G loss: 2.895293]\n",
      "epoch:22 step:17744 [D loss: 0.655729, acc: 55.47%] [G loss: 2.619822]\n",
      "epoch:22 step:17745 [D loss: 0.226898, acc: 96.88%] [G loss: 3.188425]\n",
      "epoch:22 step:17746 [D loss: 0.419014, acc: 71.09%] [G loss: 4.259066]\n",
      "epoch:22 step:17747 [D loss: 0.300987, acc: 93.75%] [G loss: 3.158496]\n",
      "epoch:22 step:17748 [D loss: 0.594561, acc: 64.06%] [G loss: 3.591967]\n",
      "epoch:22 step:17749 [D loss: 0.288848, acc: 96.88%] [G loss: 2.864982]\n",
      "epoch:22 step:17750 [D loss: 0.405016, acc: 87.50%] [G loss: 3.185061]\n",
      "epoch:22 step:17751 [D loss: 0.319720, acc: 94.53%] [G loss: 3.181212]\n",
      "epoch:22 step:17752 [D loss: 0.540166, acc: 64.84%] [G loss: 3.157126]\n",
      "epoch:22 step:17753 [D loss: 0.570364, acc: 63.28%] [G loss: 4.359718]\n",
      "epoch:22 step:17754 [D loss: 0.512320, acc: 60.94%] [G loss: 5.057383]\n",
      "epoch:22 step:17755 [D loss: 0.526932, acc: 80.47%] [G loss: 2.422590]\n",
      "epoch:22 step:17756 [D loss: 0.251222, acc: 93.75%] [G loss: 2.258820]\n",
      "epoch:22 step:17757 [D loss: 0.424854, acc: 78.12%] [G loss: 4.139685]\n",
      "epoch:22 step:17758 [D loss: 0.146213, acc: 100.00%] [G loss: 3.126558]\n",
      "epoch:22 step:17759 [D loss: 0.415918, acc: 86.72%] [G loss: 2.432150]\n",
      "epoch:22 step:17760 [D loss: 0.541548, acc: 79.69%] [G loss: 3.434266]\n",
      "epoch:22 step:17761 [D loss: 0.908864, acc: 34.38%] [G loss: 5.192881]\n",
      "epoch:22 step:17762 [D loss: 0.464614, acc: 74.22%] [G loss: 3.024265]\n",
      "epoch:22 step:17763 [D loss: 0.441502, acc: 75.00%] [G loss: 3.136680]\n",
      "epoch:22 step:17764 [D loss: 0.345389, acc: 89.84%] [G loss: 2.796569]\n",
      "epoch:22 step:17765 [D loss: 0.617575, acc: 63.28%] [G loss: 4.070021]\n",
      "epoch:22 step:17766 [D loss: 0.333466, acc: 93.75%] [G loss: 1.885191]\n",
      "epoch:22 step:17767 [D loss: 0.289046, acc: 95.31%] [G loss: 3.226668]\n",
      "epoch:22 step:17768 [D loss: 0.731733, acc: 61.72%] [G loss: 3.796519]\n",
      "epoch:22 step:17769 [D loss: 0.892006, acc: 42.19%] [G loss: 3.096541]\n",
      "epoch:22 step:17770 [D loss: 0.539280, acc: 76.56%] [G loss: 4.100497]\n",
      "epoch:22 step:17771 [D loss: 0.439312, acc: 78.12%] [G loss: 3.435024]\n",
      "epoch:22 step:17772 [D loss: 0.415518, acc: 78.12%] [G loss: 3.231744]\n",
      "epoch:22 step:17773 [D loss: 0.452720, acc: 82.81%] [G loss: 2.766809]\n",
      "epoch:22 step:17774 [D loss: 0.150198, acc: 100.00%] [G loss: 3.790829]\n",
      "epoch:22 step:17775 [D loss: 0.885819, acc: 39.84%] [G loss: 1.996648]\n",
      "epoch:22 step:17776 [D loss: 0.391983, acc: 86.72%] [G loss: 2.354825]\n",
      "epoch:22 step:17777 [D loss: 0.816846, acc: 50.78%] [G loss: 2.603851]\n",
      "epoch:22 step:17778 [D loss: 0.506575, acc: 81.25%] [G loss: 3.304257]\n",
      "epoch:22 step:17779 [D loss: 0.621955, acc: 64.06%] [G loss: 3.969329]\n",
      "epoch:22 step:17780 [D loss: 0.258068, acc: 95.31%] [G loss: 4.350646]\n",
      "epoch:22 step:17781 [D loss: 0.620337, acc: 59.38%] [G loss: 2.989756]\n",
      "epoch:22 step:17782 [D loss: 0.560508, acc: 74.22%] [G loss: 4.240615]\n",
      "epoch:22 step:17783 [D loss: 0.156258, acc: 99.22%] [G loss: 3.584285]\n",
      "epoch:22 step:17784 [D loss: 1.054330, acc: 24.22%] [G loss: 4.136349]\n",
      "epoch:22 step:17785 [D loss: 0.494407, acc: 84.38%] [G loss: 2.882728]\n",
      "epoch:22 step:17786 [D loss: 0.782477, acc: 49.22%] [G loss: 4.243986]\n",
      "epoch:22 step:17787 [D loss: 0.528790, acc: 77.34%] [G loss: 2.889179]\n",
      "epoch:22 step:17788 [D loss: 0.681489, acc: 60.94%] [G loss: 3.425815]\n",
      "epoch:22 step:17789 [D loss: 0.355799, acc: 90.62%] [G loss: 3.339211]\n",
      "epoch:22 step:17790 [D loss: 0.639882, acc: 59.38%] [G loss: 2.938387]\n",
      "epoch:22 step:17791 [D loss: 0.141999, acc: 99.22%] [G loss: 3.955795]\n",
      "epoch:22 step:17792 [D loss: 0.988092, acc: 32.81%] [G loss: 2.266789]\n",
      "epoch:22 step:17793 [D loss: 0.685567, acc: 56.25%] [G loss: 2.410780]\n",
      "epoch:22 step:17794 [D loss: 0.437847, acc: 91.41%] [G loss: 2.741729]\n",
      "epoch:22 step:17795 [D loss: 0.096767, acc: 100.00%] [G loss: 2.440220]\n",
      "epoch:22 step:17796 [D loss: 0.408179, acc: 89.84%] [G loss: 3.476301]\n",
      "epoch:22 step:17797 [D loss: 0.608343, acc: 64.06%] [G loss: 2.831017]\n",
      "epoch:22 step:17798 [D loss: 0.507402, acc: 79.69%] [G loss: 3.639809]\n",
      "epoch:22 step:17799 [D loss: 0.345762, acc: 91.41%] [G loss: 3.252743]\n",
      "epoch:22 step:17800 [D loss: 0.511033, acc: 82.03%] [G loss: 2.536459]\n",
      "##############\n",
      "[0.85672056 0.88507727 0.81115362 0.81200766 0.80024113 0.83252064\n",
      " 0.89727522 0.84337938 0.8175598  0.84286196]\n",
      "##########\n",
      "epoch:22 step:17801 [D loss: 0.480763, acc: 82.03%] [G loss: 2.460626]\n",
      "epoch:22 step:17802 [D loss: 0.578695, acc: 65.62%] [G loss: 3.219198]\n",
      "epoch:22 step:17803 [D loss: 0.542792, acc: 74.22%] [G loss: 3.006113]\n",
      "epoch:22 step:17804 [D loss: 0.594183, acc: 66.41%] [G loss: 3.886549]\n",
      "epoch:22 step:17805 [D loss: 0.409059, acc: 72.66%] [G loss: 3.414340]\n",
      "epoch:22 step:17806 [D loss: 0.430925, acc: 83.59%] [G loss: 4.176119]\n",
      "epoch:22 step:17807 [D loss: 0.426166, acc: 86.72%] [G loss: 2.546170]\n",
      "epoch:22 step:17808 [D loss: 0.290902, acc: 96.09%] [G loss: 3.217866]\n",
      "epoch:22 step:17809 [D loss: 0.187427, acc: 99.22%] [G loss: 2.940384]\n",
      "epoch:22 step:17810 [D loss: 0.744458, acc: 49.22%] [G loss: 4.630384]\n",
      "epoch:22 step:17811 [D loss: 0.514556, acc: 76.56%] [G loss: 1.736990]\n",
      "epoch:22 step:17812 [D loss: 0.424159, acc: 85.94%] [G loss: 4.454208]\n",
      "epoch:22 step:17813 [D loss: 0.252981, acc: 98.44%] [G loss: 2.433382]\n",
      "epoch:22 step:17814 [D loss: 0.278616, acc: 95.31%] [G loss: 2.954191]\n",
      "epoch:22 step:17815 [D loss: 0.234871, acc: 93.75%] [G loss: 4.504176]\n",
      "epoch:22 step:17816 [D loss: 0.900807, acc: 49.22%] [G loss: 3.440324]\n",
      "epoch:22 step:17817 [D loss: 0.185847, acc: 100.00%] [G loss: 3.457246]\n",
      "epoch:22 step:17818 [D loss: 0.261282, acc: 93.75%] [G loss: 4.189000]\n",
      "epoch:22 step:17819 [D loss: 0.565139, acc: 66.41%] [G loss: 4.148694]\n",
      "epoch:22 step:17820 [D loss: 0.412956, acc: 89.06%] [G loss: 3.084716]\n",
      "epoch:22 step:17821 [D loss: 0.610421, acc: 70.31%] [G loss: 2.894441]\n",
      "epoch:22 step:17822 [D loss: 0.484636, acc: 80.47%] [G loss: 3.920010]\n",
      "epoch:22 step:17823 [D loss: 0.177866, acc: 96.88%] [G loss: 5.228212]\n",
      "epoch:22 step:17824 [D loss: 0.178250, acc: 99.22%] [G loss: 3.834296]\n",
      "epoch:22 step:17825 [D loss: 0.962077, acc: 49.22%] [G loss: 3.249251]\n",
      "epoch:22 step:17826 [D loss: 0.381919, acc: 89.84%] [G loss: 3.173920]\n",
      "epoch:22 step:17827 [D loss: 0.347867, acc: 83.59%] [G loss: 3.401921]\n",
      "epoch:22 step:17828 [D loss: 0.528479, acc: 77.34%] [G loss: 2.389824]\n",
      "epoch:22 step:17829 [D loss: 0.513371, acc: 75.78%] [G loss: 3.468779]\n",
      "epoch:22 step:17830 [D loss: 0.468948, acc: 88.28%] [G loss: 2.919424]\n",
      "epoch:22 step:17831 [D loss: 0.889711, acc: 52.34%] [G loss: 2.224079]\n",
      "epoch:22 step:17832 [D loss: 0.626340, acc: 69.53%] [G loss: 4.821675]\n",
      "epoch:22 step:17833 [D loss: 0.284554, acc: 96.09%] [G loss: 2.829393]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:22 step:17834 [D loss: 0.623045, acc: 64.84%] [G loss: 2.166183]\n",
      "epoch:22 step:17835 [D loss: 0.212059, acc: 95.31%] [G loss: 5.367439]\n",
      "epoch:22 step:17836 [D loss: 0.149353, acc: 100.00%] [G loss: 5.084600]\n",
      "epoch:22 step:17837 [D loss: 0.289010, acc: 87.50%] [G loss: 4.602356]\n",
      "epoch:22 step:17838 [D loss: 1.021613, acc: 28.12%] [G loss: 3.679356]\n",
      "epoch:22 step:17839 [D loss: 0.242293, acc: 96.09%] [G loss: 3.850068]\n",
      "epoch:22 step:17840 [D loss: 0.425732, acc: 84.38%] [G loss: 2.585057]\n",
      "epoch:22 step:17841 [D loss: 0.754497, acc: 50.78%] [G loss: 3.293018]\n",
      "epoch:22 step:17842 [D loss: 0.942725, acc: 33.59%] [G loss: 4.186803]\n",
      "epoch:22 step:17843 [D loss: 0.339817, acc: 93.75%] [G loss: 3.371382]\n",
      "epoch:22 step:17844 [D loss: 0.474874, acc: 82.03%] [G loss: 4.749506]\n",
      "epoch:22 step:17845 [D loss: 0.398163, acc: 71.09%] [G loss: 4.034717]\n",
      "epoch:22 step:17846 [D loss: 0.273434, acc: 95.31%] [G loss: 3.895248]\n",
      "epoch:22 step:17847 [D loss: 1.374729, acc: 4.69%] [G loss: 3.125610]\n",
      "epoch:22 step:17848 [D loss: 0.639219, acc: 57.81%] [G loss: 2.824610]\n",
      "epoch:22 step:17849 [D loss: 0.321512, acc: 87.50%] [G loss: 2.787828]\n",
      "epoch:22 step:17850 [D loss: 0.459593, acc: 67.19%] [G loss: 5.949387]\n",
      "epoch:22 step:17851 [D loss: 0.426897, acc: 86.72%] [G loss: 3.713212]\n",
      "epoch:22 step:17852 [D loss: 0.599808, acc: 59.38%] [G loss: 3.165231]\n",
      "epoch:22 step:17853 [D loss: 0.819865, acc: 46.09%] [G loss: 4.045023]\n",
      "epoch:22 step:17854 [D loss: 0.492639, acc: 78.12%] [G loss: 3.186856]\n",
      "epoch:22 step:17855 [D loss: 0.430097, acc: 73.44%] [G loss: 3.443137]\n",
      "epoch:22 step:17856 [D loss: 0.189773, acc: 99.22%] [G loss: 3.537070]\n",
      "epoch:22 step:17857 [D loss: 0.633789, acc: 67.97%] [G loss: 3.880893]\n",
      "epoch:22 step:17858 [D loss: 0.326329, acc: 81.25%] [G loss: 4.544224]\n",
      "epoch:22 step:17859 [D loss: 0.278322, acc: 96.09%] [G loss: 4.292924]\n",
      "epoch:22 step:17860 [D loss: 0.469833, acc: 69.53%] [G loss: 2.369146]\n",
      "epoch:22 step:17861 [D loss: 0.984041, acc: 49.22%] [G loss: 4.489031]\n",
      "epoch:22 step:17862 [D loss: 0.147598, acc: 99.22%] [G loss: 3.908156]\n",
      "epoch:22 step:17863 [D loss: 0.685276, acc: 57.81%] [G loss: 2.272308]\n",
      "epoch:22 step:17864 [D loss: 0.266486, acc: 91.41%] [G loss: 3.892336]\n",
      "epoch:22 step:17865 [D loss: 0.428752, acc: 84.38%] [G loss: 3.754726]\n",
      "epoch:22 step:17866 [D loss: 0.265865, acc: 90.62%] [G loss: 3.460237]\n",
      "epoch:22 step:17867 [D loss: 0.553348, acc: 64.84%] [G loss: 3.167351]\n",
      "epoch:22 step:17868 [D loss: 0.829785, acc: 46.88%] [G loss: 2.897780]\n",
      "epoch:22 step:17869 [D loss: 0.563256, acc: 64.84%] [G loss: 2.230071]\n",
      "epoch:22 step:17870 [D loss: 0.188853, acc: 99.22%] [G loss: 2.265282]\n",
      "epoch:22 step:17871 [D loss: 0.435237, acc: 73.44%] [G loss: 3.094065]\n",
      "epoch:22 step:17872 [D loss: 0.287903, acc: 96.09%] [G loss: 3.124689]\n",
      "epoch:22 step:17873 [D loss: 0.617703, acc: 65.62%] [G loss: 2.910920]\n",
      "epoch:22 step:17874 [D loss: 0.457030, acc: 82.81%] [G loss: 2.794758]\n",
      "epoch:22 step:17875 [D loss: 0.761348, acc: 50.78%] [G loss: 1.915328]\n",
      "epoch:22 step:17876 [D loss: 0.358844, acc: 89.06%] [G loss: 2.813431]\n",
      "epoch:22 step:17877 [D loss: 0.176781, acc: 97.66%] [G loss: 3.931625]\n",
      "epoch:22 step:17878 [D loss: 0.556378, acc: 80.47%] [G loss: 2.324673]\n",
      "epoch:22 step:17879 [D loss: 0.315675, acc: 88.28%] [G loss: 3.712452]\n",
      "epoch:22 step:17880 [D loss: 0.807477, acc: 45.31%] [G loss: 2.827076]\n",
      "epoch:22 step:17881 [D loss: 0.455629, acc: 79.69%] [G loss: 2.429842]\n",
      "epoch:22 step:17882 [D loss: 0.281274, acc: 92.97%] [G loss: 2.982486]\n",
      "epoch:22 step:17883 [D loss: 1.234971, acc: 12.50%] [G loss: 3.006539]\n",
      "epoch:22 step:17884 [D loss: 0.296578, acc: 88.28%] [G loss: 3.110540]\n",
      "epoch:22 step:17885 [D loss: 0.489707, acc: 75.00%] [G loss: 2.917088]\n",
      "epoch:22 step:17886 [D loss: 0.502131, acc: 75.00%] [G loss: 3.834606]\n",
      "epoch:22 step:17887 [D loss: 0.560883, acc: 55.47%] [G loss: 3.339737]\n",
      "epoch:22 step:17888 [D loss: 0.936626, acc: 48.44%] [G loss: 3.570271]\n",
      "epoch:22 step:17889 [D loss: 0.201447, acc: 96.88%] [G loss: 4.265546]\n",
      "epoch:22 step:17890 [D loss: 1.395807, acc: 50.00%] [G loss: 3.120597]\n",
      "epoch:22 step:17891 [D loss: 0.268117, acc: 95.31%] [G loss: 3.052725]\n",
      "epoch:22 step:17892 [D loss: 0.214446, acc: 100.00%] [G loss: 4.011410]\n",
      "epoch:22 step:17893 [D loss: 0.026086, acc: 100.00%] [G loss: 6.304606]\n",
      "epoch:22 step:17894 [D loss: 0.760593, acc: 53.91%] [G loss: 2.976136]\n",
      "epoch:22 step:17895 [D loss: 0.371692, acc: 82.03%] [G loss: 3.162434]\n",
      "epoch:22 step:17896 [D loss: 0.843852, acc: 44.53%] [G loss: 2.594260]\n",
      "epoch:22 step:17897 [D loss: 0.391978, acc: 89.06%] [G loss: 2.104597]\n",
      "epoch:22 step:17898 [D loss: 0.571779, acc: 69.53%] [G loss: 3.711064]\n",
      "epoch:22 step:17899 [D loss: 0.364748, acc: 90.62%] [G loss: 2.241942]\n",
      "epoch:22 step:17900 [D loss: 0.338118, acc: 90.62%] [G loss: 4.115312]\n",
      "epoch:22 step:17901 [D loss: 0.679462, acc: 58.59%] [G loss: 3.041070]\n",
      "epoch:22 step:17902 [D loss: 0.644932, acc: 56.25%] [G loss: 3.048474]\n",
      "epoch:22 step:17903 [D loss: 0.326770, acc: 94.53%] [G loss: 2.770268]\n",
      "epoch:22 step:17904 [D loss: 0.625614, acc: 67.97%] [G loss: 6.888642]\n",
      "epoch:22 step:17905 [D loss: 0.469612, acc: 75.00%] [G loss: 3.082113]\n",
      "epoch:22 step:17906 [D loss: 0.842866, acc: 52.34%] [G loss: 2.372431]\n",
      "epoch:22 step:17907 [D loss: 0.643910, acc: 60.94%] [G loss: 2.681338]\n",
      "epoch:22 step:17908 [D loss: 0.052688, acc: 100.00%] [G loss: 4.097085]\n",
      "epoch:22 step:17909 [D loss: 0.713043, acc: 56.25%] [G loss: 2.680148]\n",
      "epoch:22 step:17910 [D loss: 0.264495, acc: 97.66%] [G loss: 2.941788]\n",
      "epoch:22 step:17911 [D loss: 0.299349, acc: 95.31%] [G loss: 2.948519]\n",
      "epoch:22 step:17912 [D loss: 0.495340, acc: 70.31%] [G loss: 2.497586]\n",
      "epoch:22 step:17913 [D loss: 0.867894, acc: 52.34%] [G loss: 3.086029]\n",
      "epoch:22 step:17914 [D loss: 0.631839, acc: 58.59%] [G loss: 1.821955]\n",
      "epoch:22 step:17915 [D loss: 0.799442, acc: 52.34%] [G loss: 4.739866]\n",
      "epoch:22 step:17916 [D loss: 0.879783, acc: 50.00%] [G loss: 2.383550]\n",
      "epoch:22 step:17917 [D loss: 0.265980, acc: 95.31%] [G loss: 4.282015]\n",
      "epoch:22 step:17918 [D loss: 0.517936, acc: 63.28%] [G loss: 4.950414]\n",
      "epoch:22 step:17919 [D loss: 0.791427, acc: 47.66%] [G loss: 3.287260]\n",
      "epoch:22 step:17920 [D loss: 0.550624, acc: 64.06%] [G loss: 3.965232]\n",
      "epoch:22 step:17921 [D loss: 0.582916, acc: 68.75%] [G loss: 2.940932]\n",
      "epoch:22 step:17922 [D loss: 0.389813, acc: 82.03%] [G loss: 3.853197]\n",
      "epoch:22 step:17923 [D loss: 0.173219, acc: 99.22%] [G loss: 2.511633]\n",
      "epoch:22 step:17924 [D loss: 1.111688, acc: 23.44%] [G loss: 3.074443]\n",
      "epoch:22 step:17925 [D loss: 0.164310, acc: 99.22%] [G loss: 2.607799]\n",
      "epoch:22 step:17926 [D loss: 0.838695, acc: 46.88%] [G loss: 1.813878]\n",
      "epoch:22 step:17927 [D loss: 0.767557, acc: 51.56%] [G loss: 3.049293]\n",
      "epoch:22 step:17928 [D loss: 0.278255, acc: 89.06%] [G loss: 3.045267]\n",
      "epoch:22 step:17929 [D loss: 0.250138, acc: 98.44%] [G loss: 3.417341]\n",
      "epoch:22 step:17930 [D loss: 0.191597, acc: 100.00%] [G loss: 2.998483]\n",
      "epoch:22 step:17931 [D loss: 0.939397, acc: 28.91%] [G loss: 4.597857]\n",
      "epoch:22 step:17932 [D loss: 0.398396, acc: 92.97%] [G loss: 2.025144]\n",
      "epoch:22 step:17933 [D loss: 0.695312, acc: 55.47%] [G loss: 2.532193]\n",
      "epoch:22 step:17934 [D loss: 0.334288, acc: 89.06%] [G loss: 2.799107]\n",
      "epoch:22 step:17935 [D loss: 0.553803, acc: 75.00%] [G loss: 4.085335]\n",
      "epoch:22 step:17936 [D loss: 0.534827, acc: 68.75%] [G loss: 2.614138]\n",
      "epoch:22 step:17937 [D loss: 0.559620, acc: 76.56%] [G loss: 3.626270]\n",
      "epoch:22 step:17938 [D loss: 0.177340, acc: 97.66%] [G loss: 4.506630]\n",
      "epoch:22 step:17939 [D loss: 0.743104, acc: 53.91%] [G loss: 3.567142]\n",
      "epoch:22 step:17940 [D loss: 0.615627, acc: 63.28%] [G loss: 3.117255]\n",
      "epoch:22 step:17941 [D loss: 0.718493, acc: 54.69%] [G loss: 2.623501]\n",
      "epoch:22 step:17942 [D loss: 0.128068, acc: 99.22%] [G loss: 4.245401]\n",
      "epoch:22 step:17943 [D loss: 0.536642, acc: 79.69%] [G loss: 3.636924]\n",
      "epoch:22 step:17944 [D loss: 0.542684, acc: 71.88%] [G loss: 3.658531]\n",
      "epoch:22 step:17945 [D loss: 0.551522, acc: 73.44%] [G loss: 3.595616]\n",
      "epoch:22 step:17946 [D loss: 0.349908, acc: 92.19%] [G loss: 4.503388]\n",
      "epoch:22 step:17947 [D loss: 0.405382, acc: 79.69%] [G loss: 3.458955]\n",
      "epoch:22 step:17948 [D loss: 0.587933, acc: 64.06%] [G loss: 3.508056]\n",
      "epoch:22 step:17949 [D loss: 0.236890, acc: 97.66%] [G loss: 3.611255]\n",
      "epoch:22 step:17950 [D loss: 0.212939, acc: 100.00%] [G loss: 3.591120]\n",
      "epoch:22 step:17951 [D loss: 0.892352, acc: 50.78%] [G loss: 4.015460]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:22 step:17952 [D loss: 0.287709, acc: 96.09%] [G loss: 3.122661]\n",
      "epoch:22 step:17953 [D loss: 0.342039, acc: 89.06%] [G loss: 3.968016]\n",
      "epoch:22 step:17954 [D loss: 0.228872, acc: 97.66%] [G loss: 3.370968]\n",
      "epoch:22 step:17955 [D loss: 0.040630, acc: 100.00%] [G loss: 4.271110]\n",
      "epoch:22 step:17956 [D loss: 0.529491, acc: 73.44%] [G loss: 3.009326]\n",
      "epoch:22 step:17957 [D loss: 0.749599, acc: 51.56%] [G loss: 3.206374]\n",
      "epoch:22 step:17958 [D loss: 0.668427, acc: 58.59%] [G loss: 2.370183]\n",
      "epoch:22 step:17959 [D loss: 1.486886, acc: 3.91%] [G loss: 2.369220]\n",
      "epoch:22 step:17960 [D loss: 0.319747, acc: 93.75%] [G loss: 2.948670]\n",
      "epoch:22 step:17961 [D loss: 1.008641, acc: 33.59%] [G loss: 3.500225]\n",
      "epoch:22 step:17962 [D loss: 1.318380, acc: 17.19%] [G loss: 2.885364]\n",
      "epoch:22 step:17963 [D loss: 0.478945, acc: 82.81%] [G loss: 3.717366]\n",
      "epoch:23 step:17964 [D loss: 0.414578, acc: 83.59%] [G loss: 4.847770]\n",
      "epoch:23 step:17965 [D loss: 0.261083, acc: 95.31%] [G loss: 4.266067]\n",
      "epoch:23 step:17966 [D loss: 0.706686, acc: 53.91%] [G loss: 3.355644]\n",
      "epoch:23 step:17967 [D loss: 0.514029, acc: 76.56%] [G loss: 3.891294]\n",
      "epoch:23 step:17968 [D loss: 0.132866, acc: 100.00%] [G loss: 3.786636]\n",
      "epoch:23 step:17969 [D loss: 1.032596, acc: 49.22%] [G loss: 3.535855]\n",
      "epoch:23 step:17970 [D loss: 0.516031, acc: 77.34%] [G loss: 2.830326]\n",
      "epoch:23 step:17971 [D loss: 0.482698, acc: 86.72%] [G loss: 5.546429]\n",
      "epoch:23 step:17972 [D loss: 0.337311, acc: 91.41%] [G loss: 3.556827]\n",
      "epoch:23 step:17973 [D loss: 0.241509, acc: 96.88%] [G loss: 3.840154]\n",
      "epoch:23 step:17974 [D loss: 0.424542, acc: 81.25%] [G loss: 2.269838]\n",
      "epoch:23 step:17975 [D loss: 0.313291, acc: 92.97%] [G loss: 3.937689]\n",
      "epoch:23 step:17976 [D loss: 0.362177, acc: 92.97%] [G loss: 3.914054]\n",
      "epoch:23 step:17977 [D loss: 0.147043, acc: 100.00%] [G loss: 2.671125]\n",
      "epoch:23 step:17978 [D loss: 0.654233, acc: 59.38%] [G loss: 4.106965]\n",
      "epoch:23 step:17979 [D loss: 0.206137, acc: 95.31%] [G loss: 2.457783]\n",
      "epoch:23 step:17980 [D loss: 0.145201, acc: 98.44%] [G loss: 4.725322]\n",
      "epoch:23 step:17981 [D loss: 0.378052, acc: 87.50%] [G loss: 4.431437]\n",
      "epoch:23 step:17982 [D loss: 0.398179, acc: 87.50%] [G loss: 3.415624]\n",
      "epoch:23 step:17983 [D loss: 0.625830, acc: 51.56%] [G loss: 3.455015]\n",
      "epoch:23 step:17984 [D loss: 0.947783, acc: 51.56%] [G loss: 3.167663]\n",
      "epoch:23 step:17985 [D loss: 0.343260, acc: 84.38%] [G loss: 2.953300]\n",
      "epoch:23 step:17986 [D loss: 0.349031, acc: 95.31%] [G loss: 3.485730]\n",
      "epoch:23 step:17987 [D loss: 0.366784, acc: 80.47%] [G loss: 4.967510]\n",
      "epoch:23 step:17988 [D loss: 0.441313, acc: 74.22%] [G loss: 2.956796]\n",
      "epoch:23 step:17989 [D loss: 0.461636, acc: 67.97%] [G loss: 3.249075]\n",
      "epoch:23 step:17990 [D loss: 0.396648, acc: 77.34%] [G loss: 4.183632]\n",
      "epoch:23 step:17991 [D loss: 0.564185, acc: 71.09%] [G loss: 2.511278]\n",
      "epoch:23 step:17992 [D loss: 0.539666, acc: 64.06%] [G loss: 2.273618]\n",
      "epoch:23 step:17993 [D loss: 0.334416, acc: 90.62%] [G loss: 3.911807]\n",
      "epoch:23 step:17994 [D loss: 0.286128, acc: 94.53%] [G loss: 2.444780]\n",
      "epoch:23 step:17995 [D loss: 0.386829, acc: 91.41%] [G loss: 1.661301]\n",
      "epoch:23 step:17996 [D loss: 1.253368, acc: 36.72%] [G loss: 1.989892]\n",
      "epoch:23 step:17997 [D loss: 0.223530, acc: 97.66%] [G loss: 4.174141]\n",
      "epoch:23 step:17998 [D loss: 0.574878, acc: 57.81%] [G loss: 3.125156]\n",
      "epoch:23 step:17999 [D loss: 0.885559, acc: 50.00%] [G loss: 2.826385]\n",
      "epoch:23 step:18000 [D loss: 0.259681, acc: 99.22%] [G loss: 3.644652]\n",
      "##############\n",
      "[0.85870344 0.87651647 0.81604155 0.80102781 0.82556642 0.82106774\n",
      " 0.8691213  0.82570374 0.80479052 0.82025449]\n",
      "##########\n",
      "epoch:23 step:18001 [D loss: 0.746563, acc: 56.25%] [G loss: 3.728937]\n",
      "epoch:23 step:18002 [D loss: 0.303752, acc: 92.97%] [G loss: 3.338813]\n",
      "epoch:23 step:18003 [D loss: 0.129321, acc: 99.22%] [G loss: 3.690378]\n",
      "epoch:23 step:18004 [D loss: 0.469812, acc: 84.38%] [G loss: 3.457759]\n",
      "epoch:23 step:18005 [D loss: 0.558317, acc: 71.88%] [G loss: 4.091120]\n",
      "epoch:23 step:18006 [D loss: 0.243170, acc: 96.88%] [G loss: 3.496124]\n",
      "epoch:23 step:18007 [D loss: 0.976808, acc: 37.50%] [G loss: 2.855401]\n",
      "epoch:23 step:18008 [D loss: 0.392242, acc: 74.22%] [G loss: 3.077703]\n",
      "epoch:23 step:18009 [D loss: 0.539183, acc: 69.53%] [G loss: 2.699322]\n",
      "epoch:23 step:18010 [D loss: 0.620383, acc: 63.28%] [G loss: 3.752755]\n",
      "epoch:23 step:18011 [D loss: 0.436721, acc: 68.75%] [G loss: 3.610401]\n",
      "epoch:23 step:18012 [D loss: 0.260621, acc: 94.53%] [G loss: 2.849306]\n",
      "epoch:23 step:18013 [D loss: 0.346803, acc: 89.84%] [G loss: 2.954690]\n",
      "epoch:23 step:18014 [D loss: 0.210532, acc: 98.44%] [G loss: 4.406330]\n",
      "epoch:23 step:18015 [D loss: 0.304050, acc: 98.44%] [G loss: 3.797830]\n",
      "epoch:23 step:18016 [D loss: 0.355477, acc: 90.62%] [G loss: 3.367478]\n",
      "epoch:23 step:18017 [D loss: 0.327571, acc: 85.94%] [G loss: 3.214553]\n",
      "epoch:23 step:18018 [D loss: 0.425627, acc: 84.38%] [G loss: 3.417347]\n",
      "epoch:23 step:18019 [D loss: 0.396842, acc: 84.38%] [G loss: 2.871401]\n",
      "epoch:23 step:18020 [D loss: 0.451254, acc: 73.44%] [G loss: 3.970192]\n",
      "epoch:23 step:18021 [D loss: 0.610077, acc: 64.06%] [G loss: 4.444294]\n",
      "epoch:23 step:18022 [D loss: 0.391713, acc: 83.59%] [G loss: 3.009575]\n",
      "epoch:23 step:18023 [D loss: 0.313380, acc: 89.06%] [G loss: 2.394639]\n",
      "epoch:23 step:18024 [D loss: 0.363513, acc: 89.84%] [G loss: 1.921549]\n",
      "epoch:23 step:18025 [D loss: 0.393403, acc: 85.94%] [G loss: 3.042620]\n",
      "epoch:23 step:18026 [D loss: 0.297916, acc: 93.75%] [G loss: 2.972630]\n",
      "epoch:23 step:18027 [D loss: 0.736399, acc: 51.56%] [G loss: 4.199145]\n",
      "epoch:23 step:18028 [D loss: 0.189778, acc: 98.44%] [G loss: 2.572940]\n",
      "epoch:23 step:18029 [D loss: 0.781509, acc: 50.78%] [G loss: 2.329406]\n",
      "epoch:23 step:18030 [D loss: 1.573255, acc: 5.47%] [G loss: 2.549030]\n",
      "epoch:23 step:18031 [D loss: 1.096437, acc: 35.94%] [G loss: 3.470869]\n",
      "epoch:23 step:18032 [D loss: 0.267659, acc: 91.41%] [G loss: 8.364532]\n",
      "epoch:23 step:18033 [D loss: 0.748129, acc: 56.25%] [G loss: 4.523436]\n",
      "epoch:23 step:18034 [D loss: 0.306308, acc: 97.66%] [G loss: 2.885017]\n",
      "epoch:23 step:18035 [D loss: 0.757227, acc: 56.25%] [G loss: 3.836239]\n",
      "epoch:23 step:18036 [D loss: 0.255434, acc: 92.97%] [G loss: 3.841115]\n",
      "epoch:23 step:18037 [D loss: 0.490851, acc: 71.09%] [G loss: 3.473906]\n",
      "epoch:23 step:18038 [D loss: 0.375027, acc: 96.09%] [G loss: 3.022150]\n",
      "epoch:23 step:18039 [D loss: 0.372293, acc: 81.25%] [G loss: 4.733305]\n",
      "epoch:23 step:18040 [D loss: 0.965282, acc: 23.44%] [G loss: 2.745775]\n",
      "epoch:23 step:18041 [D loss: 0.501791, acc: 75.78%] [G loss: 4.263397]\n",
      "epoch:23 step:18042 [D loss: 0.103677, acc: 99.22%] [G loss: 3.521578]\n",
      "epoch:23 step:18043 [D loss: 1.052203, acc: 21.09%] [G loss: 3.276235]\n",
      "epoch:23 step:18044 [D loss: 0.216846, acc: 96.09%] [G loss: 3.532749]\n",
      "epoch:23 step:18045 [D loss: 0.151419, acc: 98.44%] [G loss: 3.876199]\n",
      "epoch:23 step:18046 [D loss: 0.204317, acc: 98.44%] [G loss: 4.840286]\n",
      "epoch:23 step:18047 [D loss: 0.528163, acc: 81.25%] [G loss: 5.107285]\n",
      "epoch:23 step:18048 [D loss: 0.333395, acc: 97.66%] [G loss: 4.376177]\n",
      "epoch:23 step:18049 [D loss: 0.473584, acc: 81.25%] [G loss: 2.916650]\n",
      "epoch:23 step:18050 [D loss: 0.788952, acc: 47.66%] [G loss: 2.098845]\n",
      "epoch:23 step:18051 [D loss: 0.349487, acc: 88.28%] [G loss: 2.712886]\n",
      "epoch:23 step:18052 [D loss: 0.240656, acc: 98.44%] [G loss: 2.350710]\n",
      "epoch:23 step:18053 [D loss: 0.560402, acc: 73.44%] [G loss: 2.349041]\n",
      "epoch:23 step:18054 [D loss: 0.110466, acc: 100.00%] [G loss: 3.411358]\n",
      "epoch:23 step:18055 [D loss: 0.191407, acc: 97.66%] [G loss: 3.591977]\n",
      "epoch:23 step:18056 [D loss: 0.408748, acc: 88.28%] [G loss: 3.330942]\n",
      "epoch:23 step:18057 [D loss: 0.701804, acc: 58.59%] [G loss: 2.222689]\n",
      "epoch:23 step:18058 [D loss: 0.161498, acc: 97.66%] [G loss: 4.231097]\n",
      "epoch:23 step:18059 [D loss: 0.445350, acc: 81.25%] [G loss: 4.287056]\n",
      "epoch:23 step:18060 [D loss: 0.765010, acc: 50.78%] [G loss: 2.200190]\n",
      "epoch:23 step:18061 [D loss: 0.137385, acc: 100.00%] [G loss: 4.586792]\n",
      "epoch:23 step:18062 [D loss: 0.283992, acc: 95.31%] [G loss: 4.890224]\n",
      "epoch:23 step:18063 [D loss: 0.340926, acc: 85.94%] [G loss: 2.801933]\n",
      "epoch:23 step:18064 [D loss: 0.440434, acc: 77.34%] [G loss: 3.945988]\n",
      "epoch:23 step:18065 [D loss: 0.125841, acc: 100.00%] [G loss: 3.620055]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:23 step:18066 [D loss: 0.477841, acc: 80.47%] [G loss: 3.155964]\n",
      "epoch:23 step:18067 [D loss: 0.342998, acc: 89.06%] [G loss: 2.995297]\n",
      "epoch:23 step:18068 [D loss: 0.258057, acc: 95.31%] [G loss: 3.607728]\n",
      "epoch:23 step:18069 [D loss: 0.579648, acc: 63.28%] [G loss: 3.950789]\n",
      "epoch:23 step:18070 [D loss: 1.166515, acc: 46.09%] [G loss: 2.276989]\n",
      "epoch:23 step:18071 [D loss: 0.499133, acc: 78.12%] [G loss: 2.184793]\n",
      "epoch:23 step:18072 [D loss: 0.578570, acc: 64.84%] [G loss: 3.092863]\n",
      "epoch:23 step:18073 [D loss: 1.434317, acc: 29.69%] [G loss: 4.266969]\n",
      "epoch:23 step:18074 [D loss: 0.269711, acc: 93.75%] [G loss: 4.004587]\n",
      "epoch:23 step:18075 [D loss: 0.313562, acc: 91.41%] [G loss: 3.143567]\n",
      "epoch:23 step:18076 [D loss: 0.260644, acc: 100.00%] [G loss: 5.258509]\n",
      "epoch:23 step:18077 [D loss: 0.425342, acc: 85.94%] [G loss: 3.492993]\n",
      "epoch:23 step:18078 [D loss: 0.821817, acc: 50.78%] [G loss: 3.485099]\n",
      "epoch:23 step:18079 [D loss: 0.589402, acc: 65.62%] [G loss: 3.210803]\n",
      "epoch:23 step:18080 [D loss: 0.212190, acc: 99.22%] [G loss: 4.399793]\n",
      "epoch:23 step:18081 [D loss: 0.536338, acc: 75.00%] [G loss: 2.043365]\n",
      "epoch:23 step:18082 [D loss: 0.254536, acc: 94.53%] [G loss: 4.282422]\n",
      "epoch:23 step:18083 [D loss: 0.505587, acc: 79.69%] [G loss: 4.142793]\n",
      "epoch:23 step:18084 [D loss: 0.313963, acc: 87.50%] [G loss: 6.184604]\n",
      "epoch:23 step:18085 [D loss: 0.322117, acc: 92.97%] [G loss: 4.688419]\n",
      "epoch:23 step:18086 [D loss: 0.088498, acc: 100.00%] [G loss: 4.166756]\n",
      "epoch:23 step:18087 [D loss: 0.721778, acc: 57.03%] [G loss: 2.345244]\n",
      "epoch:23 step:18088 [D loss: 0.333955, acc: 97.66%] [G loss: 3.087023]\n",
      "epoch:23 step:18089 [D loss: 0.559458, acc: 75.78%] [G loss: 2.806408]\n",
      "epoch:23 step:18090 [D loss: 0.310563, acc: 92.19%] [G loss: 2.933186]\n",
      "epoch:23 step:18091 [D loss: 0.365149, acc: 87.50%] [G loss: 3.668825]\n",
      "epoch:23 step:18092 [D loss: 0.374729, acc: 84.38%] [G loss: 4.047813]\n",
      "epoch:23 step:18093 [D loss: 0.135518, acc: 100.00%] [G loss: 3.113947]\n",
      "epoch:23 step:18094 [D loss: 0.336752, acc: 86.72%] [G loss: 3.162104]\n",
      "epoch:23 step:18095 [D loss: 0.578084, acc: 71.09%] [G loss: 4.009309]\n",
      "epoch:23 step:18096 [D loss: 0.772846, acc: 50.00%] [G loss: 2.963208]\n",
      "epoch:23 step:18097 [D loss: 0.545986, acc: 71.88%] [G loss: 5.191215]\n",
      "epoch:23 step:18098 [D loss: 0.383460, acc: 88.28%] [G loss: 5.012101]\n",
      "epoch:23 step:18099 [D loss: 0.288320, acc: 89.84%] [G loss: 4.357209]\n",
      "epoch:23 step:18100 [D loss: 0.511507, acc: 74.22%] [G loss: 2.511387]\n",
      "epoch:23 step:18101 [D loss: 0.262386, acc: 96.88%] [G loss: 4.533441]\n",
      "epoch:23 step:18102 [D loss: 1.035245, acc: 48.44%] [G loss: 3.058471]\n",
      "epoch:23 step:18103 [D loss: 0.114533, acc: 100.00%] [G loss: 4.023116]\n",
      "epoch:23 step:18104 [D loss: 0.583493, acc: 64.06%] [G loss: 3.801844]\n",
      "epoch:23 step:18105 [D loss: 0.220105, acc: 96.09%] [G loss: 2.273578]\n",
      "epoch:23 step:18106 [D loss: 0.999498, acc: 20.31%] [G loss: 3.204324]\n",
      "epoch:23 step:18107 [D loss: 0.395267, acc: 86.72%] [G loss: 3.967519]\n",
      "epoch:23 step:18108 [D loss: 0.395592, acc: 80.47%] [G loss: 2.880787]\n",
      "epoch:23 step:18109 [D loss: 0.148330, acc: 99.22%] [G loss: 3.989685]\n",
      "epoch:23 step:18110 [D loss: 0.252499, acc: 94.53%] [G loss: 4.073470]\n",
      "epoch:23 step:18111 [D loss: 0.200991, acc: 97.66%] [G loss: 3.358098]\n",
      "epoch:23 step:18112 [D loss: 0.626462, acc: 61.72%] [G loss: 3.380461]\n",
      "epoch:23 step:18113 [D loss: 0.290005, acc: 95.31%] [G loss: 2.579439]\n",
      "epoch:23 step:18114 [D loss: 0.566448, acc: 71.88%] [G loss: 3.384825]\n",
      "epoch:23 step:18115 [D loss: 0.679068, acc: 65.62%] [G loss: 4.569857]\n",
      "epoch:23 step:18116 [D loss: 0.388455, acc: 87.50%] [G loss: 2.950162]\n",
      "epoch:23 step:18117 [D loss: 0.951240, acc: 50.00%] [G loss: 3.329973]\n",
      "epoch:23 step:18118 [D loss: 0.562587, acc: 69.53%] [G loss: 2.180970]\n",
      "epoch:23 step:18119 [D loss: 0.465579, acc: 70.31%] [G loss: 3.530371]\n",
      "epoch:23 step:18120 [D loss: 0.426502, acc: 82.81%] [G loss: 2.919381]\n",
      "epoch:23 step:18121 [D loss: 0.141905, acc: 100.00%] [G loss: 4.332231]\n",
      "epoch:23 step:18122 [D loss: 0.253190, acc: 96.88%] [G loss: 4.488172]\n",
      "epoch:23 step:18123 [D loss: 0.676127, acc: 52.34%] [G loss: 3.375547]\n",
      "epoch:23 step:18124 [D loss: 0.212538, acc: 98.44%] [G loss: 3.383643]\n",
      "epoch:23 step:18125 [D loss: 0.542227, acc: 81.25%] [G loss: 2.932451]\n",
      "epoch:23 step:18126 [D loss: 0.614159, acc: 65.62%] [G loss: 3.810414]\n",
      "epoch:23 step:18127 [D loss: 0.554607, acc: 60.94%] [G loss: 3.914380]\n",
      "epoch:23 step:18128 [D loss: 0.700832, acc: 58.59%] [G loss: 3.230086]\n",
      "epoch:23 step:18129 [D loss: 0.802209, acc: 39.84%] [G loss: 4.109149]\n",
      "epoch:23 step:18130 [D loss: 0.711459, acc: 57.03%] [G loss: 4.766957]\n",
      "epoch:23 step:18131 [D loss: 0.194704, acc: 94.53%] [G loss: 2.415212]\n",
      "epoch:23 step:18132 [D loss: 0.334993, acc: 95.31%] [G loss: 3.566858]\n",
      "epoch:23 step:18133 [D loss: 0.231129, acc: 98.44%] [G loss: 6.224541]\n",
      "epoch:23 step:18134 [D loss: 0.383294, acc: 85.16%] [G loss: 3.295093]\n",
      "epoch:23 step:18135 [D loss: 0.198482, acc: 99.22%] [G loss: 2.356637]\n",
      "epoch:23 step:18136 [D loss: 0.762883, acc: 49.22%] [G loss: 2.560028]\n",
      "epoch:23 step:18137 [D loss: 0.439848, acc: 79.69%] [G loss: 2.582169]\n",
      "epoch:23 step:18138 [D loss: 0.248685, acc: 98.44%] [G loss: 3.592609]\n",
      "epoch:23 step:18139 [D loss: 1.400551, acc: 46.88%] [G loss: 2.562102]\n",
      "epoch:23 step:18140 [D loss: 0.806597, acc: 47.66%] [G loss: 4.600029]\n",
      "epoch:23 step:18141 [D loss: 0.976387, acc: 23.44%] [G loss: 3.056972]\n",
      "epoch:23 step:18142 [D loss: 0.328940, acc: 96.09%] [G loss: 2.129528]\n",
      "epoch:23 step:18143 [D loss: 0.605231, acc: 71.09%] [G loss: 2.766628]\n",
      "epoch:23 step:18144 [D loss: 1.022125, acc: 25.78%] [G loss: 2.144747]\n",
      "epoch:23 step:18145 [D loss: 0.873007, acc: 40.62%] [G loss: 2.044816]\n",
      "epoch:23 step:18146 [D loss: 0.373441, acc: 89.84%] [G loss: 3.790957]\n",
      "epoch:23 step:18147 [D loss: 0.407700, acc: 81.25%] [G loss: 3.230134]\n",
      "epoch:23 step:18148 [D loss: 0.319258, acc: 94.53%] [G loss: 3.560277]\n",
      "epoch:23 step:18149 [D loss: 0.361093, acc: 92.97%] [G loss: 4.186569]\n",
      "epoch:23 step:18150 [D loss: 0.588019, acc: 74.22%] [G loss: 3.055503]\n",
      "epoch:23 step:18151 [D loss: 0.153688, acc: 98.44%] [G loss: 3.768195]\n",
      "epoch:23 step:18152 [D loss: 0.043969, acc: 100.00%] [G loss: 4.033828]\n",
      "epoch:23 step:18153 [D loss: 0.494806, acc: 83.59%] [G loss: 2.907526]\n",
      "epoch:23 step:18154 [D loss: 0.149730, acc: 99.22%] [G loss: 3.069649]\n",
      "epoch:23 step:18155 [D loss: 0.426113, acc: 84.38%] [G loss: 3.639249]\n",
      "epoch:23 step:18156 [D loss: 0.642919, acc: 55.47%] [G loss: 3.654205]\n",
      "epoch:23 step:18157 [D loss: 0.312029, acc: 86.72%] [G loss: 6.462743]\n",
      "epoch:23 step:18158 [D loss: 0.499489, acc: 78.91%] [G loss: 3.044018]\n",
      "epoch:23 step:18159 [D loss: 0.919372, acc: 33.59%] [G loss: 2.168818]\n",
      "epoch:23 step:18160 [D loss: 0.226491, acc: 98.44%] [G loss: 2.301939]\n",
      "epoch:23 step:18161 [D loss: 0.283343, acc: 95.31%] [G loss: 2.207900]\n",
      "epoch:23 step:18162 [D loss: 0.954228, acc: 41.41%] [G loss: 2.888596]\n",
      "epoch:23 step:18163 [D loss: 0.187870, acc: 99.22%] [G loss: 3.263086]\n",
      "epoch:23 step:18164 [D loss: 0.518638, acc: 77.34%] [G loss: 4.263468]\n",
      "epoch:23 step:18165 [D loss: 1.326956, acc: 10.94%] [G loss: 2.040804]\n",
      "epoch:23 step:18166 [D loss: 0.257064, acc: 96.88%] [G loss: 3.701069]\n",
      "epoch:23 step:18167 [D loss: 0.406407, acc: 84.38%] [G loss: 3.680389]\n",
      "epoch:23 step:18168 [D loss: 1.064588, acc: 46.09%] [G loss: 1.454502]\n",
      "epoch:23 step:18169 [D loss: 0.338633, acc: 83.59%] [G loss: 3.910397]\n",
      "epoch:23 step:18170 [D loss: 0.304831, acc: 97.66%] [G loss: 3.944846]\n",
      "epoch:23 step:18171 [D loss: 0.433311, acc: 81.25%] [G loss: 5.163163]\n",
      "epoch:23 step:18172 [D loss: 1.033367, acc: 44.53%] [G loss: 2.368705]\n",
      "epoch:23 step:18173 [D loss: 0.216168, acc: 94.53%] [G loss: 3.509552]\n",
      "epoch:23 step:18174 [D loss: 0.324150, acc: 92.97%] [G loss: 3.587288]\n",
      "epoch:23 step:18175 [D loss: 0.194120, acc: 99.22%] [G loss: 3.293165]\n",
      "epoch:23 step:18176 [D loss: 0.640447, acc: 64.06%] [G loss: 2.554566]\n",
      "epoch:23 step:18177 [D loss: 0.284098, acc: 96.09%] [G loss: 3.689144]\n",
      "epoch:23 step:18178 [D loss: 0.557595, acc: 70.31%] [G loss: 2.603648]\n",
      "epoch:23 step:18179 [D loss: 0.702856, acc: 55.47%] [G loss: 3.145898]\n",
      "epoch:23 step:18180 [D loss: 0.346760, acc: 92.97%] [G loss: 2.364408]\n",
      "epoch:23 step:18181 [D loss: 0.500837, acc: 68.75%] [G loss: 4.279041]\n",
      "epoch:23 step:18182 [D loss: 0.231678, acc: 96.88%] [G loss: 3.418316]\n",
      "epoch:23 step:18183 [D loss: 0.813901, acc: 49.22%] [G loss: 3.118312]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:23 step:18184 [D loss: 0.751114, acc: 54.69%] [G loss: 2.345317]\n",
      "epoch:23 step:18185 [D loss: 0.433264, acc: 82.03%] [G loss: 2.039165]\n",
      "epoch:23 step:18186 [D loss: 0.531221, acc: 73.44%] [G loss: 2.837846]\n",
      "epoch:23 step:18187 [D loss: 0.477867, acc: 82.81%] [G loss: 2.587056]\n",
      "epoch:23 step:18188 [D loss: 0.476639, acc: 78.12%] [G loss: 3.437498]\n",
      "epoch:23 step:18189 [D loss: 0.869619, acc: 52.34%] [G loss: 4.663419]\n",
      "epoch:23 step:18190 [D loss: 0.142733, acc: 100.00%] [G loss: 3.997789]\n",
      "epoch:23 step:18191 [D loss: 0.499804, acc: 71.09%] [G loss: 3.448415]\n",
      "epoch:23 step:18192 [D loss: 1.273654, acc: 42.19%] [G loss: 4.100433]\n",
      "epoch:23 step:18193 [D loss: 0.780899, acc: 53.12%] [G loss: 2.599909]\n",
      "epoch:23 step:18194 [D loss: 0.284251, acc: 96.09%] [G loss: 2.950836]\n",
      "epoch:23 step:18195 [D loss: 0.299692, acc: 88.28%] [G loss: 5.221732]\n",
      "epoch:23 step:18196 [D loss: 0.192376, acc: 99.22%] [G loss: 2.809717]\n",
      "epoch:23 step:18197 [D loss: 0.688651, acc: 57.81%] [G loss: 3.588293]\n",
      "epoch:23 step:18198 [D loss: 0.171218, acc: 99.22%] [G loss: 5.026284]\n",
      "epoch:23 step:18199 [D loss: 1.284076, acc: 10.94%] [G loss: 2.345605]\n",
      "epoch:23 step:18200 [D loss: 0.777482, acc: 53.12%] [G loss: 2.819048]\n",
      "##############\n",
      "[0.86953511 0.87358892 0.82377418 0.80697544 0.78291546 0.82252988\n",
      " 0.88780465 0.83099482 0.79627892 0.83372062]\n",
      "##########\n",
      "epoch:23 step:18201 [D loss: 0.613024, acc: 60.94%] [G loss: 3.343033]\n",
      "epoch:23 step:18202 [D loss: 0.367121, acc: 90.62%] [G loss: 3.111210]\n",
      "epoch:23 step:18203 [D loss: 0.682280, acc: 59.38%] [G loss: 2.387024]\n",
      "epoch:23 step:18204 [D loss: 0.195163, acc: 100.00%] [G loss: 3.594356]\n",
      "epoch:23 step:18205 [D loss: 0.246473, acc: 93.75%] [G loss: 4.536273]\n",
      "epoch:23 step:18206 [D loss: 0.158489, acc: 100.00%] [G loss: 2.962880]\n",
      "epoch:23 step:18207 [D loss: 0.626032, acc: 66.41%] [G loss: 3.692184]\n",
      "epoch:23 step:18208 [D loss: 0.616229, acc: 63.28%] [G loss: 2.651801]\n",
      "epoch:23 step:18209 [D loss: 0.225938, acc: 98.44%] [G loss: 3.824646]\n",
      "epoch:23 step:18210 [D loss: 0.557308, acc: 72.66%] [G loss: 3.196155]\n",
      "epoch:23 step:18211 [D loss: 0.181417, acc: 99.22%] [G loss: 4.385529]\n",
      "epoch:23 step:18212 [D loss: 0.537143, acc: 61.72%] [G loss: 3.265680]\n",
      "epoch:23 step:18213 [D loss: 0.242163, acc: 93.75%] [G loss: 4.212490]\n",
      "epoch:23 step:18214 [D loss: 0.226339, acc: 98.44%] [G loss: 5.855897]\n",
      "epoch:23 step:18215 [D loss: 0.447329, acc: 65.62%] [G loss: 6.131877]\n",
      "epoch:23 step:18216 [D loss: 0.493949, acc: 71.09%] [G loss: 2.815994]\n",
      "epoch:23 step:18217 [D loss: 0.801476, acc: 46.09%] [G loss: 1.819368]\n",
      "epoch:23 step:18218 [D loss: 0.608373, acc: 62.50%] [G loss: 4.584095]\n",
      "epoch:23 step:18219 [D loss: 0.595315, acc: 62.50%] [G loss: 2.940020]\n",
      "epoch:23 step:18220 [D loss: 0.277694, acc: 97.66%] [G loss: 2.896144]\n",
      "epoch:23 step:18221 [D loss: 0.481385, acc: 80.47%] [G loss: 3.347055]\n",
      "epoch:23 step:18222 [D loss: 0.786707, acc: 53.91%] [G loss: 2.774820]\n",
      "epoch:23 step:18223 [D loss: 0.236568, acc: 99.22%] [G loss: 3.893099]\n",
      "epoch:23 step:18224 [D loss: 0.198613, acc: 95.31%] [G loss: 4.952929]\n",
      "epoch:23 step:18225 [D loss: 0.222707, acc: 100.00%] [G loss: 3.393027]\n",
      "epoch:23 step:18226 [D loss: 0.464303, acc: 61.72%] [G loss: 4.470677]\n",
      "epoch:23 step:18227 [D loss: 0.550659, acc: 71.88%] [G loss: 4.064374]\n",
      "epoch:23 step:18228 [D loss: 0.245002, acc: 98.44%] [G loss: 4.314080]\n",
      "epoch:23 step:18229 [D loss: 0.214617, acc: 96.88%] [G loss: 4.423423]\n",
      "epoch:23 step:18230 [D loss: 1.058902, acc: 46.88%] [G loss: 3.148667]\n",
      "epoch:23 step:18231 [D loss: 0.265895, acc: 89.06%] [G loss: 4.160349]\n",
      "epoch:23 step:18232 [D loss: 0.359064, acc: 78.91%] [G loss: 2.561123]\n",
      "epoch:23 step:18233 [D loss: 0.385613, acc: 89.06%] [G loss: 3.875850]\n",
      "epoch:23 step:18234 [D loss: 0.502729, acc: 65.62%] [G loss: 2.849255]\n",
      "epoch:23 step:18235 [D loss: 0.377923, acc: 85.16%] [G loss: 4.006314]\n",
      "epoch:23 step:18236 [D loss: 0.225505, acc: 95.31%] [G loss: 1.941305]\n",
      "epoch:23 step:18237 [D loss: 0.887075, acc: 32.03%] [G loss: 3.770032]\n",
      "epoch:23 step:18238 [D loss: 0.404056, acc: 80.47%] [G loss: 3.404293]\n",
      "epoch:23 step:18239 [D loss: 0.155357, acc: 100.00%] [G loss: 4.695350]\n",
      "epoch:23 step:18240 [D loss: 0.176200, acc: 100.00%] [G loss: 3.759584]\n",
      "epoch:23 step:18241 [D loss: 0.383728, acc: 82.03%] [G loss: 4.895383]\n",
      "epoch:23 step:18242 [D loss: 0.817282, acc: 39.06%] [G loss: 3.553825]\n",
      "epoch:23 step:18243 [D loss: 0.139991, acc: 99.22%] [G loss: 4.087237]\n",
      "epoch:23 step:18244 [D loss: 1.196990, acc: 35.16%] [G loss: 3.155907]\n",
      "epoch:23 step:18245 [D loss: 0.694423, acc: 57.03%] [G loss: 3.232915]\n",
      "epoch:23 step:18246 [D loss: 0.221125, acc: 96.09%] [G loss: 2.686297]\n",
      "epoch:23 step:18247 [D loss: 0.302707, acc: 94.53%] [G loss: 4.254464]\n",
      "epoch:23 step:18248 [D loss: 0.675339, acc: 60.94%] [G loss: 3.316976]\n",
      "epoch:23 step:18249 [D loss: 0.513072, acc: 79.69%] [G loss: 3.465049]\n",
      "epoch:23 step:18250 [D loss: 0.997031, acc: 22.66%] [G loss: 3.509817]\n",
      "epoch:23 step:18251 [D loss: 0.444751, acc: 83.59%] [G loss: 2.274866]\n",
      "epoch:23 step:18252 [D loss: 1.041590, acc: 45.31%] [G loss: 3.119117]\n",
      "epoch:23 step:18253 [D loss: 0.658032, acc: 60.16%] [G loss: 3.797775]\n",
      "epoch:23 step:18254 [D loss: 0.656378, acc: 57.81%] [G loss: 3.143283]\n",
      "epoch:23 step:18255 [D loss: 0.432477, acc: 79.69%] [G loss: 2.634092]\n",
      "epoch:23 step:18256 [D loss: 0.435741, acc: 80.47%] [G loss: 4.231383]\n",
      "epoch:23 step:18257 [D loss: 0.800457, acc: 41.41%] [G loss: 2.958159]\n",
      "epoch:23 step:18258 [D loss: 0.517532, acc: 75.78%] [G loss: 3.125737]\n",
      "epoch:23 step:18259 [D loss: 0.227004, acc: 97.66%] [G loss: 4.773513]\n",
      "epoch:23 step:18260 [D loss: 0.793722, acc: 45.31%] [G loss: 3.205420]\n",
      "epoch:23 step:18261 [D loss: 0.681502, acc: 60.16%] [G loss: 4.491361]\n",
      "epoch:23 step:18262 [D loss: 0.353807, acc: 87.50%] [G loss: 2.890616]\n",
      "epoch:23 step:18263 [D loss: 0.589526, acc: 68.75%] [G loss: 3.989971]\n",
      "epoch:23 step:18264 [D loss: 0.617057, acc: 64.84%] [G loss: 3.930842]\n",
      "epoch:23 step:18265 [D loss: 0.932279, acc: 51.56%] [G loss: 2.319507]\n",
      "epoch:23 step:18266 [D loss: 0.212832, acc: 98.44%] [G loss: 3.859211]\n",
      "epoch:23 step:18267 [D loss: 0.197664, acc: 97.66%] [G loss: 3.913727]\n",
      "epoch:23 step:18268 [D loss: 0.132141, acc: 99.22%] [G loss: 3.781986]\n",
      "epoch:23 step:18269 [D loss: 0.258194, acc: 99.22%] [G loss: 3.639922]\n",
      "epoch:23 step:18270 [D loss: 0.682243, acc: 59.38%] [G loss: 3.925036]\n",
      "epoch:23 step:18271 [D loss: 0.395742, acc: 86.72%] [G loss: 6.278437]\n",
      "epoch:23 step:18272 [D loss: 0.267197, acc: 97.66%] [G loss: 4.090662]\n",
      "epoch:23 step:18273 [D loss: 0.969335, acc: 42.97%] [G loss: 4.687662]\n",
      "epoch:23 step:18274 [D loss: 0.521079, acc: 78.91%] [G loss: 3.678526]\n",
      "epoch:23 step:18275 [D loss: 0.540396, acc: 72.66%] [G loss: 1.766949]\n",
      "epoch:23 step:18276 [D loss: 1.121006, acc: 23.44%] [G loss: 3.944161]\n",
      "epoch:23 step:18277 [D loss: 0.154630, acc: 98.44%] [G loss: 3.612566]\n",
      "epoch:23 step:18278 [D loss: 1.078585, acc: 19.53%] [G loss: 3.008444]\n",
      "epoch:23 step:18279 [D loss: 0.404340, acc: 87.50%] [G loss: 1.937840]\n",
      "epoch:23 step:18280 [D loss: 0.584288, acc: 70.31%] [G loss: 3.312430]\n",
      "epoch:23 step:18281 [D loss: 0.305425, acc: 95.31%] [G loss: 3.869790]\n",
      "epoch:23 step:18282 [D loss: 0.593052, acc: 70.31%] [G loss: 2.588083]\n",
      "epoch:23 step:18283 [D loss: 0.385660, acc: 82.81%] [G loss: 3.463804]\n",
      "epoch:23 step:18284 [D loss: 0.248844, acc: 96.09%] [G loss: 3.514549]\n",
      "epoch:23 step:18285 [D loss: 0.559629, acc: 67.97%] [G loss: 2.717709]\n",
      "epoch:23 step:18286 [D loss: 0.464475, acc: 78.91%] [G loss: 2.317617]\n",
      "epoch:23 step:18287 [D loss: 0.595692, acc: 64.84%] [G loss: 3.492034]\n",
      "epoch:23 step:18288 [D loss: 0.576323, acc: 70.31%] [G loss: 4.307062]\n",
      "epoch:23 step:18289 [D loss: 0.486816, acc: 79.69%] [G loss: 2.851792]\n",
      "epoch:23 step:18290 [D loss: 0.462634, acc: 81.25%] [G loss: 4.743492]\n",
      "epoch:23 step:18291 [D loss: 0.312090, acc: 93.75%] [G loss: 2.456515]\n",
      "epoch:23 step:18292 [D loss: 0.186534, acc: 97.66%] [G loss: 3.658761]\n",
      "epoch:23 step:18293 [D loss: 0.414158, acc: 92.19%] [G loss: 4.566168]\n",
      "epoch:23 step:18294 [D loss: 0.437610, acc: 83.59%] [G loss: 4.000665]\n",
      "epoch:23 step:18295 [D loss: 0.135699, acc: 100.00%] [G loss: 4.651548]\n",
      "epoch:23 step:18296 [D loss: 0.393498, acc: 76.56%] [G loss: 5.395841]\n",
      "epoch:23 step:18297 [D loss: 0.353536, acc: 96.09%] [G loss: 3.374636]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:23 step:18298 [D loss: 0.199579, acc: 98.44%] [G loss: 3.376251]\n",
      "epoch:23 step:18299 [D loss: 0.637143, acc: 63.28%] [G loss: 2.921095]\n",
      "epoch:23 step:18300 [D loss: 0.926795, acc: 50.78%] [G loss: 2.763884]\n",
      "epoch:23 step:18301 [D loss: 0.351771, acc: 79.69%] [G loss: 2.729738]\n",
      "epoch:23 step:18302 [D loss: 0.209275, acc: 99.22%] [G loss: 4.640093]\n",
      "epoch:23 step:18303 [D loss: 0.520153, acc: 62.50%] [G loss: 2.097547]\n",
      "epoch:23 step:18304 [D loss: 0.455515, acc: 69.53%] [G loss: 3.799203]\n",
      "epoch:23 step:18305 [D loss: 0.753476, acc: 52.34%] [G loss: 3.660005]\n",
      "epoch:23 step:18306 [D loss: 0.840422, acc: 48.44%] [G loss: 3.178629]\n",
      "epoch:23 step:18307 [D loss: 0.199187, acc: 98.44%] [G loss: 3.174060]\n",
      "epoch:23 step:18308 [D loss: 0.136288, acc: 100.00%] [G loss: 2.758491]\n",
      "epoch:23 step:18309 [D loss: 0.373296, acc: 90.62%] [G loss: 5.103694]\n",
      "epoch:23 step:18310 [D loss: 0.811629, acc: 53.91%] [G loss: 2.591434]\n",
      "epoch:23 step:18311 [D loss: 0.512432, acc: 80.47%] [G loss: 1.990141]\n",
      "epoch:23 step:18312 [D loss: 0.457009, acc: 78.12%] [G loss: 2.398921]\n",
      "epoch:23 step:18313 [D loss: 0.546530, acc: 70.31%] [G loss: 3.162186]\n",
      "epoch:23 step:18314 [D loss: 0.489515, acc: 71.09%] [G loss: 3.826735]\n",
      "epoch:23 step:18315 [D loss: 0.293053, acc: 93.75%] [G loss: 3.399178]\n",
      "epoch:23 step:18316 [D loss: 0.950406, acc: 47.66%] [G loss: 4.078342]\n",
      "epoch:23 step:18317 [D loss: 0.333787, acc: 92.97%] [G loss: 4.429060]\n",
      "epoch:23 step:18318 [D loss: 1.321452, acc: 11.72%] [G loss: 2.731956]\n",
      "epoch:23 step:18319 [D loss: 0.618020, acc: 61.72%] [G loss: 2.469994]\n",
      "epoch:23 step:18320 [D loss: 0.140758, acc: 100.00%] [G loss: 4.334672]\n",
      "epoch:23 step:18321 [D loss: 0.544570, acc: 72.66%] [G loss: 1.905777]\n",
      "epoch:23 step:18322 [D loss: 0.515108, acc: 69.53%] [G loss: 3.001186]\n",
      "epoch:23 step:18323 [D loss: 0.946717, acc: 26.56%] [G loss: 2.997454]\n",
      "epoch:23 step:18324 [D loss: 0.415524, acc: 85.16%] [G loss: 2.185599]\n",
      "epoch:23 step:18325 [D loss: 0.231522, acc: 98.44%] [G loss: 4.280759]\n",
      "epoch:23 step:18326 [D loss: 0.271196, acc: 93.75%] [G loss: 4.031729]\n",
      "epoch:23 step:18327 [D loss: 0.448828, acc: 73.44%] [G loss: 2.689358]\n",
      "epoch:23 step:18328 [D loss: 0.275798, acc: 97.66%] [G loss: 4.371389]\n",
      "epoch:23 step:18329 [D loss: 1.394741, acc: 39.84%] [G loss: 4.024192]\n",
      "epoch:23 step:18330 [D loss: 0.532332, acc: 68.75%] [G loss: 2.825026]\n",
      "epoch:23 step:18331 [D loss: 0.552694, acc: 69.53%] [G loss: 3.270674]\n",
      "epoch:23 step:18332 [D loss: 0.962780, acc: 42.19%] [G loss: 3.597454]\n",
      "epoch:23 step:18333 [D loss: 0.388684, acc: 79.69%] [G loss: 4.032105]\n",
      "epoch:23 step:18334 [D loss: 0.498510, acc: 74.22%] [G loss: 3.430838]\n",
      "epoch:23 step:18335 [D loss: 0.807897, acc: 46.09%] [G loss: 2.958148]\n",
      "epoch:23 step:18336 [D loss: 0.830821, acc: 38.28%] [G loss: 2.249247]\n",
      "epoch:23 step:18337 [D loss: 0.295902, acc: 91.41%] [G loss: 3.924729]\n",
      "epoch:23 step:18338 [D loss: 0.325309, acc: 92.97%] [G loss: 2.839570]\n",
      "epoch:23 step:18339 [D loss: 0.532192, acc: 73.44%] [G loss: 3.201372]\n",
      "epoch:23 step:18340 [D loss: 0.389679, acc: 83.59%] [G loss: 3.369164]\n",
      "epoch:23 step:18341 [D loss: 0.276921, acc: 92.19%] [G loss: 4.247938]\n",
      "epoch:23 step:18342 [D loss: 0.383065, acc: 78.91%] [G loss: 2.882612]\n",
      "epoch:23 step:18343 [D loss: 0.784268, acc: 40.62%] [G loss: 2.846437]\n",
      "epoch:23 step:18344 [D loss: 0.560742, acc: 68.75%] [G loss: 2.556721]\n",
      "epoch:23 step:18345 [D loss: 0.179487, acc: 96.88%] [G loss: 4.256278]\n",
      "epoch:23 step:18346 [D loss: 0.286852, acc: 96.88%] [G loss: 4.038021]\n",
      "epoch:23 step:18347 [D loss: 0.544504, acc: 67.19%] [G loss: 5.393456]\n",
      "epoch:23 step:18348 [D loss: 0.404335, acc: 91.41%] [G loss: 3.199321]\n",
      "epoch:23 step:18349 [D loss: 0.969098, acc: 28.91%] [G loss: 4.075957]\n",
      "epoch:23 step:18350 [D loss: 0.396202, acc: 81.25%] [G loss: 4.806641]\n",
      "epoch:23 step:18351 [D loss: 0.073352, acc: 99.22%] [G loss: 3.567729]\n",
      "epoch:23 step:18352 [D loss: 0.408313, acc: 86.72%] [G loss: 3.947102]\n",
      "epoch:23 step:18353 [D loss: 0.822346, acc: 51.56%] [G loss: 3.291582]\n",
      "epoch:23 step:18354 [D loss: 0.482995, acc: 79.69%] [G loss: 2.610904]\n",
      "epoch:23 step:18355 [D loss: 0.529550, acc: 76.56%] [G loss: 2.669463]\n",
      "epoch:23 step:18356 [D loss: 0.818760, acc: 54.69%] [G loss: 2.366431]\n",
      "epoch:23 step:18357 [D loss: 0.486279, acc: 64.06%] [G loss: 3.602601]\n",
      "epoch:23 step:18358 [D loss: 0.492864, acc: 67.19%] [G loss: 3.184304]\n",
      "epoch:23 step:18359 [D loss: 0.533262, acc: 73.44%] [G loss: 4.663173]\n",
      "epoch:23 step:18360 [D loss: 0.725298, acc: 54.69%] [G loss: 4.408175]\n",
      "epoch:23 step:18361 [D loss: 0.310177, acc: 96.88%] [G loss: 3.825341]\n",
      "epoch:23 step:18362 [D loss: 0.140159, acc: 99.22%] [G loss: 3.517991]\n",
      "epoch:23 step:18363 [D loss: 0.092402, acc: 99.22%] [G loss: 3.867617]\n",
      "epoch:23 step:18364 [D loss: 0.595114, acc: 59.38%] [G loss: 5.165910]\n",
      "epoch:23 step:18365 [D loss: 0.156620, acc: 99.22%] [G loss: 3.950192]\n",
      "epoch:23 step:18366 [D loss: 0.180770, acc: 98.44%] [G loss: 3.932458]\n",
      "epoch:23 step:18367 [D loss: 0.250896, acc: 97.66%] [G loss: 3.559680]\n",
      "epoch:23 step:18368 [D loss: 0.468160, acc: 86.72%] [G loss: 3.520365]\n",
      "epoch:23 step:18369 [D loss: 0.612957, acc: 63.28%] [G loss: 3.861599]\n",
      "epoch:23 step:18370 [D loss: 0.246084, acc: 96.88%] [G loss: 4.880276]\n",
      "epoch:23 step:18371 [D loss: 0.342759, acc: 84.38%] [G loss: 4.281405]\n",
      "epoch:23 step:18372 [D loss: 0.414326, acc: 74.22%] [G loss: 3.297981]\n",
      "epoch:23 step:18373 [D loss: 0.106672, acc: 99.22%] [G loss: 5.588475]\n",
      "epoch:23 step:18374 [D loss: 0.486475, acc: 64.84%] [G loss: 4.127962]\n",
      "epoch:23 step:18375 [D loss: 0.751869, acc: 52.34%] [G loss: 3.114104]\n",
      "epoch:23 step:18376 [D loss: 0.156882, acc: 99.22%] [G loss: 3.408267]\n",
      "epoch:23 step:18377 [D loss: 0.541366, acc: 75.78%] [G loss: 3.454120]\n",
      "epoch:23 step:18378 [D loss: 1.068486, acc: 28.91%] [G loss: 1.647820]\n",
      "epoch:23 step:18379 [D loss: 1.280101, acc: 12.50%] [G loss: 3.816479]\n",
      "epoch:23 step:18380 [D loss: 0.283489, acc: 88.28%] [G loss: 4.359909]\n",
      "epoch:23 step:18381 [D loss: 0.739172, acc: 53.91%] [G loss: 2.891034]\n",
      "epoch:23 step:18382 [D loss: 0.242449, acc: 99.22%] [G loss: 2.726182]\n",
      "epoch:23 step:18383 [D loss: 0.485908, acc: 79.69%] [G loss: 2.724451]\n",
      "epoch:23 step:18384 [D loss: 0.690096, acc: 51.56%] [G loss: 3.096231]\n",
      "epoch:23 step:18385 [D loss: 0.141986, acc: 99.22%] [G loss: 5.410740]\n",
      "epoch:23 step:18386 [D loss: 0.481228, acc: 66.41%] [G loss: 3.246316]\n",
      "epoch:23 step:18387 [D loss: 0.663885, acc: 60.16%] [G loss: 3.625190]\n",
      "epoch:23 step:18388 [D loss: 0.286004, acc: 94.53%] [G loss: 1.730386]\n",
      "epoch:23 step:18389 [D loss: 0.105667, acc: 100.00%] [G loss: 4.088849]\n",
      "epoch:23 step:18390 [D loss: 0.623312, acc: 63.28%] [G loss: 2.196424]\n",
      "epoch:23 step:18391 [D loss: 0.204949, acc: 99.22%] [G loss: 2.797635]\n",
      "epoch:23 step:18392 [D loss: 0.369623, acc: 82.81%] [G loss: 4.086811]\n",
      "epoch:23 step:18393 [D loss: 0.661441, acc: 57.03%] [G loss: 4.713627]\n",
      "epoch:23 step:18394 [D loss: 0.974599, acc: 28.91%] [G loss: 1.582954]\n",
      "epoch:23 step:18395 [D loss: 0.680495, acc: 53.12%] [G loss: 3.070203]\n",
      "epoch:23 step:18396 [D loss: 0.417644, acc: 89.84%] [G loss: 2.545055]\n",
      "epoch:23 step:18397 [D loss: 0.226339, acc: 93.75%] [G loss: 4.815959]\n",
      "epoch:23 step:18398 [D loss: 0.460056, acc: 64.06%] [G loss: 5.477501]\n",
      "epoch:23 step:18399 [D loss: 0.242066, acc: 94.53%] [G loss: 3.592344]\n",
      "epoch:23 step:18400 [D loss: 0.798075, acc: 53.91%] [G loss: 3.188118]\n",
      "##############\n",
      "[0.86116354 0.88843992 0.82782235 0.80458811 0.76990767 0.82179373\n",
      " 0.88112745 0.82418578 0.81222626 0.84182546]\n",
      "##########\n",
      "epoch:23 step:18401 [D loss: 0.495546, acc: 83.59%] [G loss: 2.965020]\n",
      "epoch:23 step:18402 [D loss: 0.458665, acc: 82.81%] [G loss: 4.838305]\n",
      "epoch:23 step:18403 [D loss: 0.671578, acc: 64.06%] [G loss: 2.921986]\n",
      "epoch:23 step:18404 [D loss: 0.375479, acc: 83.59%] [G loss: 3.669638]\n",
      "epoch:23 step:18405 [D loss: 0.324632, acc: 94.53%] [G loss: 3.049439]\n",
      "epoch:23 step:18406 [D loss: 0.745808, acc: 55.47%] [G loss: 2.208820]\n",
      "epoch:23 step:18407 [D loss: 0.262370, acc: 93.75%] [G loss: 3.327102]\n",
      "epoch:23 step:18408 [D loss: 0.737484, acc: 52.34%] [G loss: 2.931995]\n",
      "epoch:23 step:18409 [D loss: 0.542338, acc: 67.19%] [G loss: 5.302086]\n",
      "epoch:23 step:18410 [D loss: 0.377661, acc: 92.97%] [G loss: 3.544935]\n",
      "epoch:23 step:18411 [D loss: 0.327245, acc: 94.53%] [G loss: 4.471929]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:23 step:18412 [D loss: 0.533738, acc: 71.09%] [G loss: 3.232429]\n",
      "epoch:23 step:18413 [D loss: 0.128666, acc: 100.00%] [G loss: 4.273558]\n",
      "epoch:23 step:18414 [D loss: 0.632015, acc: 63.28%] [G loss: 4.162803]\n",
      "epoch:23 step:18415 [D loss: 0.182986, acc: 100.00%] [G loss: 5.754827]\n",
      "epoch:23 step:18416 [D loss: 0.473879, acc: 66.41%] [G loss: 3.281011]\n",
      "epoch:23 step:18417 [D loss: 0.302431, acc: 92.97%] [G loss: 3.671685]\n",
      "epoch:23 step:18418 [D loss: 0.318569, acc: 84.38%] [G loss: 4.882664]\n",
      "epoch:23 step:18419 [D loss: 0.209868, acc: 99.22%] [G loss: 2.988571]\n",
      "epoch:23 step:18420 [D loss: 0.864500, acc: 33.59%] [G loss: 2.769609]\n",
      "epoch:23 step:18421 [D loss: 0.295879, acc: 96.09%] [G loss: 2.375854]\n",
      "epoch:23 step:18422 [D loss: 0.285997, acc: 89.06%] [G loss: 3.296482]\n",
      "epoch:23 step:18423 [D loss: 0.195018, acc: 96.88%] [G loss: 2.540770]\n",
      "epoch:23 step:18424 [D loss: 0.218353, acc: 96.88%] [G loss: 4.922091]\n",
      "epoch:23 step:18425 [D loss: 0.567603, acc: 74.22%] [G loss: 5.306991]\n",
      "epoch:23 step:18426 [D loss: 0.165334, acc: 98.44%] [G loss: 4.441257]\n",
      "epoch:23 step:18427 [D loss: 0.221375, acc: 96.88%] [G loss: 3.063059]\n",
      "epoch:23 step:18428 [D loss: 0.259558, acc: 97.66%] [G loss: 4.023940]\n",
      "epoch:23 step:18429 [D loss: 0.125099, acc: 100.00%] [G loss: 6.055928]\n",
      "epoch:23 step:18430 [D loss: 0.526459, acc: 60.94%] [G loss: 2.729352]\n",
      "epoch:23 step:18431 [D loss: 0.527202, acc: 78.12%] [G loss: 3.711898]\n",
      "epoch:23 step:18432 [D loss: 0.724927, acc: 50.00%] [G loss: 3.115237]\n",
      "epoch:23 step:18433 [D loss: 0.083926, acc: 100.00%] [G loss: 4.090613]\n",
      "epoch:23 step:18434 [D loss: 0.549589, acc: 60.94%] [G loss: 3.395662]\n",
      "epoch:23 step:18435 [D loss: 0.983872, acc: 34.38%] [G loss: 4.002617]\n",
      "epoch:23 step:18436 [D loss: 0.354525, acc: 91.41%] [G loss: 3.742635]\n",
      "epoch:23 step:18437 [D loss: 0.514494, acc: 77.34%] [G loss: 4.829576]\n",
      "epoch:23 step:18438 [D loss: 0.363943, acc: 92.19%] [G loss: 2.865522]\n",
      "epoch:23 step:18439 [D loss: 0.332952, acc: 84.38%] [G loss: 3.613771]\n",
      "epoch:23 step:18440 [D loss: 0.240073, acc: 92.97%] [G loss: 4.009062]\n",
      "epoch:23 step:18441 [D loss: 0.208908, acc: 98.44%] [G loss: 3.724608]\n",
      "epoch:23 step:18442 [D loss: 0.347683, acc: 87.50%] [G loss: 3.829088]\n",
      "epoch:23 step:18443 [D loss: 0.466824, acc: 74.22%] [G loss: 2.371462]\n",
      "epoch:23 step:18444 [D loss: 0.322628, acc: 95.31%] [G loss: 4.206721]\n",
      "epoch:23 step:18445 [D loss: 1.328469, acc: 32.03%] [G loss: 2.646471]\n",
      "epoch:23 step:18446 [D loss: 0.524675, acc: 67.97%] [G loss: 4.144205]\n",
      "epoch:23 step:18447 [D loss: 0.741870, acc: 53.91%] [G loss: 3.506108]\n",
      "epoch:23 step:18448 [D loss: 1.477857, acc: 28.12%] [G loss: 3.087482]\n",
      "epoch:23 step:18449 [D loss: 0.715086, acc: 60.16%] [G loss: 3.262297]\n",
      "epoch:23 step:18450 [D loss: 1.080960, acc: 17.19%] [G loss: 3.584090]\n",
      "epoch:23 step:18451 [D loss: 0.278417, acc: 95.31%] [G loss: 3.310874]\n",
      "epoch:23 step:18452 [D loss: 0.343758, acc: 87.50%] [G loss: 2.512232]\n",
      "epoch:23 step:18453 [D loss: 0.354374, acc: 82.81%] [G loss: 2.956050]\n",
      "epoch:23 step:18454 [D loss: 0.498814, acc: 82.03%] [G loss: 4.649497]\n",
      "epoch:23 step:18455 [D loss: 0.545282, acc: 69.53%] [G loss: 2.479563]\n",
      "epoch:23 step:18456 [D loss: 0.208141, acc: 96.09%] [G loss: 4.117830]\n",
      "epoch:23 step:18457 [D loss: 0.436681, acc: 79.69%] [G loss: 3.161139]\n",
      "epoch:23 step:18458 [D loss: 0.560348, acc: 71.09%] [G loss: 2.414959]\n",
      "epoch:23 step:18459 [D loss: 0.480409, acc: 82.03%] [G loss: 2.632568]\n",
      "epoch:23 step:18460 [D loss: 0.166267, acc: 97.66%] [G loss: 4.864568]\n",
      "epoch:23 step:18461 [D loss: 0.296287, acc: 96.09%] [G loss: 3.761662]\n",
      "epoch:23 step:18462 [D loss: 0.388583, acc: 83.59%] [G loss: 4.197147]\n",
      "epoch:23 step:18463 [D loss: 0.945637, acc: 50.78%] [G loss: 4.118614]\n",
      "epoch:23 step:18464 [D loss: 0.205238, acc: 100.00%] [G loss: 3.678417]\n",
      "epoch:23 step:18465 [D loss: 0.861895, acc: 50.00%] [G loss: 2.090322]\n",
      "epoch:23 step:18466 [D loss: 1.096552, acc: 35.16%] [G loss: 2.910173]\n",
      "epoch:23 step:18467 [D loss: 1.237083, acc: 37.50%] [G loss: 2.611780]\n",
      "epoch:23 step:18468 [D loss: 0.618065, acc: 60.16%] [G loss: 3.131058]\n",
      "epoch:23 step:18469 [D loss: 0.744634, acc: 53.12%] [G loss: 2.075562]\n",
      "epoch:23 step:18470 [D loss: 0.355669, acc: 92.97%] [G loss: 2.858302]\n",
      "epoch:23 step:18471 [D loss: 0.292162, acc: 97.66%] [G loss: 2.906419]\n",
      "epoch:23 step:18472 [D loss: 0.183313, acc: 99.22%] [G loss: 4.692956]\n",
      "epoch:23 step:18473 [D loss: 0.462563, acc: 82.03%] [G loss: 2.322500]\n",
      "epoch:23 step:18474 [D loss: 0.098368, acc: 100.00%] [G loss: 5.298425]\n",
      "epoch:23 step:18475 [D loss: 0.698396, acc: 54.69%] [G loss: 5.263235]\n",
      "epoch:23 step:18476 [D loss: 0.673448, acc: 57.81%] [G loss: 4.648918]\n",
      "epoch:23 step:18477 [D loss: 0.760023, acc: 51.56%] [G loss: 4.343951]\n",
      "epoch:23 step:18478 [D loss: 0.481905, acc: 83.59%] [G loss: 4.096391]\n",
      "epoch:23 step:18479 [D loss: 0.235691, acc: 99.22%] [G loss: 4.366753]\n",
      "epoch:23 step:18480 [D loss: 0.123506, acc: 99.22%] [G loss: 4.160021]\n",
      "epoch:23 step:18481 [D loss: 0.470394, acc: 64.84%] [G loss: 5.043777]\n",
      "epoch:23 step:18482 [D loss: 0.184507, acc: 98.44%] [G loss: 3.624668]\n",
      "epoch:23 step:18483 [D loss: 0.210136, acc: 98.44%] [G loss: 2.804068]\n",
      "epoch:23 step:18484 [D loss: 0.679897, acc: 53.12%] [G loss: 2.717436]\n",
      "epoch:23 step:18485 [D loss: 0.451334, acc: 85.94%] [G loss: 2.800014]\n",
      "epoch:23 step:18486 [D loss: 0.520468, acc: 78.12%] [G loss: 2.829094]\n",
      "epoch:23 step:18487 [D loss: 0.559168, acc: 71.09%] [G loss: 3.859726]\n",
      "epoch:23 step:18488 [D loss: 0.748620, acc: 42.97%] [G loss: 3.623281]\n",
      "epoch:23 step:18489 [D loss: 0.869953, acc: 52.34%] [G loss: 4.097219]\n",
      "epoch:23 step:18490 [D loss: 0.128512, acc: 100.00%] [G loss: 4.224401]\n",
      "epoch:23 step:18491 [D loss: 0.511874, acc: 74.22%] [G loss: 2.546857]\n",
      "epoch:23 step:18492 [D loss: 0.353010, acc: 92.97%] [G loss: 3.471690]\n",
      "epoch:23 step:18493 [D loss: 0.310485, acc: 96.88%] [G loss: 3.648676]\n",
      "epoch:23 step:18494 [D loss: 0.383697, acc: 82.03%] [G loss: 3.844467]\n",
      "epoch:23 step:18495 [D loss: 0.608929, acc: 66.41%] [G loss: 2.985191]\n",
      "epoch:23 step:18496 [D loss: 0.331791, acc: 93.75%] [G loss: 4.285640]\n",
      "epoch:23 step:18497 [D loss: 0.208571, acc: 97.66%] [G loss: 2.278253]\n",
      "epoch:23 step:18498 [D loss: 0.630880, acc: 62.50%] [G loss: 2.616832]\n",
      "epoch:23 step:18499 [D loss: 0.441093, acc: 79.69%] [G loss: 2.441788]\n",
      "epoch:23 step:18500 [D loss: 0.287493, acc: 91.41%] [G loss: 4.016654]\n",
      "epoch:23 step:18501 [D loss: 0.314120, acc: 89.06%] [G loss: 3.610669]\n",
      "epoch:23 step:18502 [D loss: 0.194200, acc: 97.66%] [G loss: 2.857815]\n",
      "epoch:23 step:18503 [D loss: 0.574776, acc: 64.84%] [G loss: 4.284304]\n",
      "epoch:23 step:18504 [D loss: 0.592372, acc: 61.72%] [G loss: 2.475965]\n",
      "epoch:23 step:18505 [D loss: 0.380102, acc: 78.91%] [G loss: 2.678959]\n",
      "epoch:23 step:18506 [D loss: 0.520272, acc: 61.72%] [G loss: 3.765719]\n",
      "epoch:23 step:18507 [D loss: 0.382424, acc: 89.06%] [G loss: 3.058652]\n",
      "epoch:23 step:18508 [D loss: 0.176577, acc: 98.44%] [G loss: 3.791437]\n",
      "epoch:23 step:18509 [D loss: 0.794106, acc: 45.31%] [G loss: 2.629348]\n",
      "epoch:23 step:18510 [D loss: 0.421556, acc: 87.50%] [G loss: 2.670394]\n",
      "epoch:23 step:18511 [D loss: 0.509611, acc: 79.69%] [G loss: 2.075475]\n",
      "epoch:23 step:18512 [D loss: 0.249182, acc: 92.97%] [G loss: 4.052859]\n",
      "epoch:23 step:18513 [D loss: 0.216228, acc: 99.22%] [G loss: 3.172726]\n",
      "epoch:23 step:18514 [D loss: 0.360656, acc: 82.81%] [G loss: 5.234344]\n",
      "epoch:23 step:18515 [D loss: 0.796013, acc: 55.47%] [G loss: 4.098739]\n",
      "epoch:23 step:18516 [D loss: 0.867840, acc: 45.31%] [G loss: 4.351363]\n",
      "epoch:23 step:18517 [D loss: 0.270002, acc: 98.44%] [G loss: 2.715714]\n",
      "epoch:23 step:18518 [D loss: 0.073115, acc: 100.00%] [G loss: 5.484203]\n",
      "epoch:23 step:18519 [D loss: 0.810066, acc: 50.78%] [G loss: 3.562109]\n",
      "epoch:23 step:18520 [D loss: 0.610085, acc: 64.06%] [G loss: 3.234628]\n",
      "epoch:23 step:18521 [D loss: 0.674439, acc: 52.34%] [G loss: 2.779476]\n",
      "epoch:23 step:18522 [D loss: 0.702119, acc: 53.91%] [G loss: 2.822261]\n",
      "epoch:23 step:18523 [D loss: 0.559257, acc: 60.94%] [G loss: 3.391110]\n",
      "epoch:23 step:18524 [D loss: 0.154693, acc: 100.00%] [G loss: 4.014490]\n",
      "epoch:23 step:18525 [D loss: 0.308265, acc: 91.41%] [G loss: 5.041569]\n",
      "epoch:23 step:18526 [D loss: 0.674409, acc: 56.25%] [G loss: 3.213438]\n",
      "epoch:23 step:18527 [D loss: 0.185005, acc: 97.66%] [G loss: 3.796544]\n",
      "epoch:23 step:18528 [D loss: 0.335075, acc: 89.84%] [G loss: 3.217703]\n",
      "epoch:23 step:18529 [D loss: 0.470205, acc: 84.38%] [G loss: 4.606518]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:23 step:18530 [D loss: 0.346061, acc: 82.81%] [G loss: 4.452844]\n",
      "epoch:23 step:18531 [D loss: 0.356729, acc: 93.75%] [G loss: 3.910536]\n",
      "epoch:23 step:18532 [D loss: 0.593651, acc: 54.69%] [G loss: 3.734510]\n",
      "epoch:23 step:18533 [D loss: 0.768211, acc: 53.91%] [G loss: 3.368575]\n",
      "epoch:23 step:18534 [D loss: 0.318950, acc: 91.41%] [G loss: 3.268572]\n",
      "epoch:23 step:18535 [D loss: 0.422248, acc: 79.69%] [G loss: 5.163591]\n",
      "epoch:23 step:18536 [D loss: 0.190327, acc: 100.00%] [G loss: 3.439219]\n",
      "epoch:23 step:18537 [D loss: 0.492565, acc: 83.59%] [G loss: 2.585979]\n",
      "epoch:23 step:18538 [D loss: 0.557781, acc: 61.72%] [G loss: 4.610212]\n",
      "epoch:23 step:18539 [D loss: 0.278297, acc: 96.88%] [G loss: 3.964101]\n",
      "epoch:23 step:18540 [D loss: 0.624486, acc: 56.25%] [G loss: 2.871116]\n",
      "epoch:23 step:18541 [D loss: 0.317684, acc: 89.06%] [G loss: 4.973378]\n",
      "epoch:23 step:18542 [D loss: 0.347878, acc: 87.50%] [G loss: 5.049762]\n",
      "epoch:23 step:18543 [D loss: 0.246172, acc: 97.66%] [G loss: 3.331998]\n",
      "epoch:23 step:18544 [D loss: 0.034375, acc: 100.00%] [G loss: 4.725708]\n",
      "epoch:23 step:18545 [D loss: 0.206591, acc: 96.09%] [G loss: 2.273038]\n",
      "epoch:23 step:18546 [D loss: 0.229971, acc: 98.44%] [G loss: 3.513058]\n",
      "epoch:23 step:18547 [D loss: 0.943413, acc: 48.44%] [G loss: 3.402196]\n",
      "epoch:23 step:18548 [D loss: 0.444178, acc: 86.72%] [G loss: 2.622169]\n",
      "epoch:23 step:18549 [D loss: 0.533496, acc: 67.19%] [G loss: 5.661300]\n",
      "epoch:23 step:18550 [D loss: 0.171456, acc: 97.66%] [G loss: 3.347330]\n",
      "epoch:23 step:18551 [D loss: 0.453610, acc: 78.12%] [G loss: 3.600386]\n",
      "epoch:23 step:18552 [D loss: 0.643184, acc: 59.38%] [G loss: 3.552614]\n",
      "epoch:23 step:18553 [D loss: 0.251252, acc: 92.97%] [G loss: 3.062767]\n",
      "epoch:23 step:18554 [D loss: 0.996642, acc: 50.00%] [G loss: 1.641604]\n",
      "epoch:23 step:18555 [D loss: 0.326586, acc: 85.94%] [G loss: 3.173621]\n",
      "epoch:23 step:18556 [D loss: 0.274535, acc: 91.41%] [G loss: 4.744991]\n",
      "epoch:23 step:18557 [D loss: 1.338997, acc: 11.72%] [G loss: 3.274250]\n",
      "epoch:23 step:18558 [D loss: 0.151507, acc: 99.22%] [G loss: 3.729132]\n",
      "epoch:23 step:18559 [D loss: 0.349410, acc: 92.19%] [G loss: 3.719818]\n",
      "epoch:23 step:18560 [D loss: 0.374061, acc: 91.41%] [G loss: 4.477777]\n",
      "epoch:23 step:18561 [D loss: 0.213915, acc: 96.09%] [G loss: 3.085476]\n",
      "epoch:23 step:18562 [D loss: 0.257513, acc: 92.97%] [G loss: 3.895060]\n",
      "epoch:23 step:18563 [D loss: 0.689140, acc: 58.59%] [G loss: 3.808627]\n",
      "epoch:23 step:18564 [D loss: 0.419546, acc: 88.28%] [G loss: 2.995474]\n",
      "epoch:23 step:18565 [D loss: 1.126281, acc: 50.00%] [G loss: 2.751595]\n",
      "epoch:23 step:18566 [D loss: 0.747157, acc: 54.69%] [G loss: 2.825276]\n",
      "epoch:23 step:18567 [D loss: 0.621406, acc: 66.41%] [G loss: 3.023595]\n",
      "epoch:23 step:18568 [D loss: 0.272577, acc: 89.06%] [G loss: 2.847424]\n",
      "epoch:23 step:18569 [D loss: 0.856284, acc: 53.12%] [G loss: 3.193373]\n",
      "epoch:23 step:18570 [D loss: 0.404640, acc: 88.28%] [G loss: 3.065272]\n",
      "epoch:23 step:18571 [D loss: 0.423908, acc: 75.00%] [G loss: 3.420136]\n",
      "epoch:23 step:18572 [D loss: 0.421228, acc: 75.78%] [G loss: 4.331359]\n",
      "epoch:23 step:18573 [D loss: 0.487335, acc: 79.69%] [G loss: 4.088686]\n",
      "epoch:23 step:18574 [D loss: 0.193832, acc: 100.00%] [G loss: 4.946835]\n",
      "epoch:23 step:18575 [D loss: 0.193284, acc: 99.22%] [G loss: 3.709304]\n",
      "epoch:23 step:18576 [D loss: 0.779617, acc: 52.34%] [G loss: 3.532015]\n",
      "epoch:23 step:18577 [D loss: 0.244293, acc: 98.44%] [G loss: 3.594345]\n",
      "epoch:23 step:18578 [D loss: 0.403802, acc: 84.38%] [G loss: 3.233344]\n",
      "epoch:23 step:18579 [D loss: 0.330780, acc: 89.84%] [G loss: 2.842894]\n",
      "epoch:23 step:18580 [D loss: 0.303898, acc: 96.09%] [G loss: 2.510185]\n",
      "epoch:23 step:18581 [D loss: 0.901496, acc: 42.97%] [G loss: 3.762951]\n",
      "epoch:23 step:18582 [D loss: 0.811355, acc: 45.31%] [G loss: 2.289208]\n",
      "epoch:23 step:18583 [D loss: 0.349724, acc: 84.38%] [G loss: 2.692462]\n",
      "epoch:23 step:18584 [D loss: 0.425315, acc: 89.06%] [G loss: 2.982246]\n",
      "epoch:23 step:18585 [D loss: 0.231002, acc: 99.22%] [G loss: 3.125768]\n",
      "epoch:23 step:18586 [D loss: 0.264316, acc: 96.88%] [G loss: 1.913460]\n",
      "epoch:23 step:18587 [D loss: 0.211386, acc: 99.22%] [G loss: 4.809171]\n",
      "epoch:23 step:18588 [D loss: 0.496141, acc: 82.03%] [G loss: 3.754682]\n",
      "epoch:23 step:18589 [D loss: 0.785487, acc: 44.53%] [G loss: 3.309766]\n",
      "epoch:23 step:18590 [D loss: 0.759887, acc: 48.44%] [G loss: 2.577826]\n",
      "epoch:23 step:18591 [D loss: 0.163497, acc: 97.66%] [G loss: 3.046206]\n",
      "epoch:23 step:18592 [D loss: 0.726972, acc: 52.34%] [G loss: 2.544925]\n",
      "epoch:23 step:18593 [D loss: 0.487375, acc: 64.84%] [G loss: 3.343158]\n",
      "epoch:23 step:18594 [D loss: 0.402012, acc: 86.72%] [G loss: 3.994851]\n",
      "epoch:23 step:18595 [D loss: 0.281224, acc: 93.75%] [G loss: 3.910802]\n",
      "epoch:23 step:18596 [D loss: 0.698658, acc: 57.81%] [G loss: 2.810403]\n",
      "epoch:23 step:18597 [D loss: 0.584825, acc: 56.25%] [G loss: 1.687539]\n",
      "epoch:23 step:18598 [D loss: 0.340064, acc: 97.66%] [G loss: 2.820332]\n",
      "epoch:23 step:18599 [D loss: 0.303409, acc: 94.53%] [G loss: 2.983856]\n",
      "epoch:23 step:18600 [D loss: 0.944123, acc: 48.44%] [G loss: 2.838330]\n",
      "##############\n",
      "[0.85276995 0.8689626  0.8127873  0.80053271 0.7908269  0.82712751\n",
      " 0.88217872 0.83402281 0.77961914 0.8478915 ]\n",
      "##########\n",
      "epoch:23 step:18601 [D loss: 0.351318, acc: 95.31%] [G loss: 2.150867]\n",
      "epoch:23 step:18602 [D loss: 0.202334, acc: 99.22%] [G loss: 4.041778]\n",
      "epoch:23 step:18603 [D loss: 0.415985, acc: 87.50%] [G loss: 3.916476]\n",
      "epoch:23 step:18604 [D loss: 0.833643, acc: 48.44%] [G loss: 2.629268]\n",
      "epoch:23 step:18605 [D loss: 0.791255, acc: 43.75%] [G loss: 3.530869]\n",
      "epoch:23 step:18606 [D loss: 0.613667, acc: 64.06%] [G loss: 3.199563]\n",
      "epoch:23 step:18607 [D loss: 0.483406, acc: 81.25%] [G loss: 2.245285]\n",
      "epoch:23 step:18608 [D loss: 0.558612, acc: 72.66%] [G loss: 2.333323]\n",
      "epoch:23 step:18609 [D loss: 0.403634, acc: 78.12%] [G loss: 3.627743]\n",
      "epoch:23 step:18610 [D loss: 0.741057, acc: 57.03%] [G loss: 1.592840]\n",
      "epoch:23 step:18611 [D loss: 0.421005, acc: 79.69%] [G loss: 4.295682]\n",
      "epoch:23 step:18612 [D loss: 0.153547, acc: 100.00%] [G loss: 3.213089]\n",
      "epoch:23 step:18613 [D loss: 0.543795, acc: 65.62%] [G loss: 3.341305]\n",
      "epoch:23 step:18614 [D loss: 0.417992, acc: 79.69%] [G loss: 5.018359]\n",
      "epoch:23 step:18615 [D loss: 0.344428, acc: 82.81%] [G loss: 5.115568]\n",
      "epoch:23 step:18616 [D loss: 0.126092, acc: 100.00%] [G loss: 3.426486]\n",
      "epoch:23 step:18617 [D loss: 0.413560, acc: 71.88%] [G loss: 5.078414]\n",
      "epoch:23 step:18618 [D loss: 0.467770, acc: 81.25%] [G loss: 3.750823]\n",
      "epoch:23 step:18619 [D loss: 0.582888, acc: 62.50%] [G loss: 3.650758]\n",
      "epoch:23 step:18620 [D loss: 0.239238, acc: 97.66%] [G loss: 3.247396]\n",
      "epoch:23 step:18621 [D loss: 0.662269, acc: 56.25%] [G loss: 4.576774]\n",
      "epoch:23 step:18622 [D loss: 0.210158, acc: 97.66%] [G loss: 3.895125]\n",
      "epoch:23 step:18623 [D loss: 0.210050, acc: 94.53%] [G loss: 6.245114]\n",
      "epoch:23 step:18624 [D loss: 0.295107, acc: 93.75%] [G loss: 3.883801]\n",
      "epoch:23 step:18625 [D loss: 0.202947, acc: 96.09%] [G loss: 4.903673]\n",
      "epoch:23 step:18626 [D loss: 0.213788, acc: 97.66%] [G loss: 3.996299]\n",
      "epoch:23 step:18627 [D loss: 0.210273, acc: 99.22%] [G loss: 3.567438]\n",
      "epoch:23 step:18628 [D loss: 0.702156, acc: 57.81%] [G loss: 5.344814]\n",
      "epoch:23 step:18629 [D loss: 0.264729, acc: 91.41%] [G loss: 3.982485]\n",
      "epoch:23 step:18630 [D loss: 0.609534, acc: 57.03%] [G loss: 3.433727]\n",
      "epoch:23 step:18631 [D loss: 0.408920, acc: 84.38%] [G loss: 3.527850]\n",
      "epoch:23 step:18632 [D loss: 0.912626, acc: 27.34%] [G loss: 2.841423]\n",
      "epoch:23 step:18633 [D loss: 0.319967, acc: 88.28%] [G loss: 3.688063]\n",
      "epoch:23 step:18634 [D loss: 0.238771, acc: 95.31%] [G loss: 4.281163]\n",
      "epoch:23 step:18635 [D loss: 0.805678, acc: 40.62%] [G loss: 2.364523]\n",
      "epoch:23 step:18636 [D loss: 0.183723, acc: 100.00%] [G loss: 4.340921]\n",
      "epoch:23 step:18637 [D loss: 0.229524, acc: 98.44%] [G loss: 4.079147]\n",
      "epoch:23 step:18638 [D loss: 0.851361, acc: 37.50%] [G loss: 4.267243]\n",
      "epoch:23 step:18639 [D loss: 0.140449, acc: 100.00%] [G loss: 2.476830]\n",
      "epoch:23 step:18640 [D loss: 0.306626, acc: 95.31%] [G loss: 4.112115]\n",
      "epoch:23 step:18641 [D loss: 0.800338, acc: 48.44%] [G loss: 3.189585]\n",
      "epoch:23 step:18642 [D loss: 0.599072, acc: 70.31%] [G loss: 2.900835]\n",
      "epoch:23 step:18643 [D loss: 0.506856, acc: 77.34%] [G loss: 2.861787]\n",
      "epoch:23 step:18644 [D loss: 0.513563, acc: 83.59%] [G loss: 2.359394]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:23 step:18645 [D loss: 0.659245, acc: 63.28%] [G loss: 2.669438]\n",
      "epoch:23 step:18646 [D loss: 1.204608, acc: 17.97%] [G loss: 4.043715]\n",
      "epoch:23 step:18647 [D loss: 0.866267, acc: 35.94%] [G loss: 2.962621]\n",
      "epoch:23 step:18648 [D loss: 0.201198, acc: 96.88%] [G loss: 4.134881]\n",
      "epoch:23 step:18649 [D loss: 1.299814, acc: 50.00%] [G loss: 4.800902]\n",
      "epoch:23 step:18650 [D loss: 0.413091, acc: 75.00%] [G loss: 2.826041]\n",
      "epoch:23 step:18651 [D loss: 0.648875, acc: 53.12%] [G loss: 3.187665]\n",
      "epoch:23 step:18652 [D loss: 0.453740, acc: 80.47%] [G loss: 3.324497]\n",
      "epoch:23 step:18653 [D loss: 0.121066, acc: 100.00%] [G loss: 5.062951]\n",
      "epoch:23 step:18654 [D loss: 0.326569, acc: 86.72%] [G loss: 3.956993]\n",
      "epoch:23 step:18655 [D loss: 0.642028, acc: 56.25%] [G loss: 4.050329]\n",
      "epoch:23 step:18656 [D loss: 0.495150, acc: 82.81%] [G loss: 3.692280]\n",
      "epoch:23 step:18657 [D loss: 0.686253, acc: 53.12%] [G loss: 3.068971]\n",
      "epoch:23 step:18658 [D loss: 0.515633, acc: 74.22%] [G loss: 3.475921]\n",
      "epoch:23 step:18659 [D loss: 0.500443, acc: 75.00%] [G loss: 3.449509]\n",
      "epoch:23 step:18660 [D loss: 0.761142, acc: 54.69%] [G loss: 1.502809]\n",
      "epoch:23 step:18661 [D loss: 0.300254, acc: 94.53%] [G loss: 3.050650]\n",
      "epoch:23 step:18662 [D loss: 0.736393, acc: 50.78%] [G loss: 2.834718]\n",
      "epoch:23 step:18663 [D loss: 0.295955, acc: 98.44%] [G loss: 3.088161]\n",
      "epoch:23 step:18664 [D loss: 0.875382, acc: 36.72%] [G loss: 4.325465]\n",
      "epoch:23 step:18665 [D loss: 0.481253, acc: 65.62%] [G loss: 2.758001]\n",
      "epoch:23 step:18666 [D loss: 0.277375, acc: 90.62%] [G loss: 3.382502]\n",
      "epoch:23 step:18667 [D loss: 0.270686, acc: 97.66%] [G loss: 3.872073]\n",
      "epoch:23 step:18668 [D loss: 0.587206, acc: 60.16%] [G loss: 4.142853]\n",
      "epoch:23 step:18669 [D loss: 0.504136, acc: 60.16%] [G loss: 3.430241]\n",
      "epoch:23 step:18670 [D loss: 0.662021, acc: 56.25%] [G loss: 2.931228]\n",
      "epoch:23 step:18671 [D loss: 0.114491, acc: 100.00%] [G loss: 4.145765]\n",
      "epoch:23 step:18672 [D loss: 1.183293, acc: 19.53%] [G loss: 3.778168]\n",
      "epoch:23 step:18673 [D loss: 0.233311, acc: 99.22%] [G loss: 2.977319]\n",
      "epoch:23 step:18674 [D loss: 0.239755, acc: 98.44%] [G loss: 4.700604]\n",
      "epoch:23 step:18675 [D loss: 0.341275, acc: 95.31%] [G loss: 3.763685]\n",
      "epoch:23 step:18676 [D loss: 0.154729, acc: 100.00%] [G loss: 3.760633]\n",
      "epoch:23 step:18677 [D loss: 0.410426, acc: 85.16%] [G loss: 3.180523]\n",
      "epoch:23 step:18678 [D loss: 0.696435, acc: 54.69%] [G loss: 2.919338]\n",
      "epoch:23 step:18679 [D loss: 0.427238, acc: 72.66%] [G loss: 4.175388]\n",
      "epoch:23 step:18680 [D loss: 0.167192, acc: 100.00%] [G loss: 4.574296]\n",
      "epoch:23 step:18681 [D loss: 0.128614, acc: 100.00%] [G loss: 5.880324]\n",
      "epoch:23 step:18682 [D loss: 0.419374, acc: 79.69%] [G loss: 4.778409]\n",
      "epoch:23 step:18683 [D loss: 0.280223, acc: 90.62%] [G loss: 4.496687]\n",
      "epoch:23 step:18684 [D loss: 0.597842, acc: 65.62%] [G loss: 4.142257]\n",
      "epoch:23 step:18685 [D loss: 0.108985, acc: 100.00%] [G loss: 4.473452]\n",
      "epoch:23 step:18686 [D loss: 0.100776, acc: 100.00%] [G loss: 3.623639]\n",
      "epoch:23 step:18687 [D loss: 0.410065, acc: 87.50%] [G loss: 3.545774]\n",
      "epoch:23 step:18688 [D loss: 0.422148, acc: 88.28%] [G loss: 2.506234]\n",
      "epoch:23 step:18689 [D loss: 0.349427, acc: 82.03%] [G loss: 3.902209]\n",
      "epoch:23 step:18690 [D loss: 0.445451, acc: 69.53%] [G loss: 2.789213]\n",
      "epoch:23 step:18691 [D loss: 0.697582, acc: 58.59%] [G loss: 2.982342]\n",
      "epoch:23 step:18692 [D loss: 0.744019, acc: 57.03%] [G loss: 4.366880]\n",
      "epoch:23 step:18693 [D loss: 0.203758, acc: 96.09%] [G loss: 3.284864]\n",
      "epoch:23 step:18694 [D loss: 0.420206, acc: 85.16%] [G loss: 4.100349]\n",
      "epoch:23 step:18695 [D loss: 0.177751, acc: 100.00%] [G loss: 4.697828]\n",
      "epoch:23 step:18696 [D loss: 0.427463, acc: 75.00%] [G loss: 3.914749]\n",
      "epoch:23 step:18697 [D loss: 1.318162, acc: 29.69%] [G loss: 2.105521]\n",
      "epoch:23 step:18698 [D loss: 0.336189, acc: 92.19%] [G loss: 3.731030]\n",
      "epoch:23 step:18699 [D loss: 0.090715, acc: 99.22%] [G loss: 4.566913]\n",
      "epoch:23 step:18700 [D loss: 0.369247, acc: 75.78%] [G loss: 4.927527]\n",
      "epoch:23 step:18701 [D loss: 0.179542, acc: 99.22%] [G loss: 4.046568]\n",
      "epoch:23 step:18702 [D loss: 0.462950, acc: 77.34%] [G loss: 3.282138]\n",
      "epoch:23 step:18703 [D loss: 0.126628, acc: 99.22%] [G loss: 3.533396]\n",
      "epoch:23 step:18704 [D loss: 0.042253, acc: 100.00%] [G loss: 4.143816]\n",
      "epoch:23 step:18705 [D loss: 0.376732, acc: 88.28%] [G loss: 2.572011]\n",
      "epoch:23 step:18706 [D loss: 0.849645, acc: 52.34%] [G loss: 2.666736]\n",
      "epoch:23 step:18707 [D loss: 0.626987, acc: 64.06%] [G loss: 2.465024]\n",
      "epoch:23 step:18708 [D loss: 0.224181, acc: 97.66%] [G loss: 3.717355]\n",
      "epoch:23 step:18709 [D loss: 0.615501, acc: 64.84%] [G loss: 3.207936]\n",
      "epoch:23 step:18710 [D loss: 0.222067, acc: 97.66%] [G loss: 4.279849]\n",
      "epoch:23 step:18711 [D loss: 0.098061, acc: 100.00%] [G loss: 3.584512]\n",
      "epoch:23 step:18712 [D loss: 0.558965, acc: 68.75%] [G loss: 4.373180]\n",
      "epoch:23 step:18713 [D loss: 0.923184, acc: 44.53%] [G loss: 4.776485]\n",
      "epoch:23 step:18714 [D loss: 0.623297, acc: 64.84%] [G loss: 3.199329]\n",
      "epoch:23 step:18715 [D loss: 0.303267, acc: 93.75%] [G loss: 4.978639]\n",
      "epoch:23 step:18716 [D loss: 0.229524, acc: 99.22%] [G loss: 5.038872]\n",
      "epoch:23 step:18717 [D loss: 0.855854, acc: 45.31%] [G loss: 3.988905]\n",
      "epoch:23 step:18718 [D loss: 0.835489, acc: 34.38%] [G loss: 2.906407]\n",
      "epoch:23 step:18719 [D loss: 0.123785, acc: 99.22%] [G loss: 5.355177]\n",
      "epoch:23 step:18720 [D loss: 0.072665, acc: 100.00%] [G loss: 3.057769]\n",
      "epoch:23 step:18721 [D loss: 0.401219, acc: 89.06%] [G loss: 3.421443]\n",
      "epoch:23 step:18722 [D loss: 1.104119, acc: 45.31%] [G loss: 2.250893]\n",
      "epoch:23 step:18723 [D loss: 0.179521, acc: 97.66%] [G loss: 4.717785]\n",
      "epoch:23 step:18724 [D loss: 0.205877, acc: 99.22%] [G loss: 3.920930]\n",
      "epoch:23 step:18725 [D loss: 0.713706, acc: 56.25%] [G loss: 4.744880]\n",
      "epoch:23 step:18726 [D loss: 0.393050, acc: 82.03%] [G loss: 3.621590]\n",
      "epoch:23 step:18727 [D loss: 0.552807, acc: 70.31%] [G loss: 4.557737]\n",
      "epoch:23 step:18728 [D loss: 0.584623, acc: 67.97%] [G loss: 5.357038]\n",
      "epoch:23 step:18729 [D loss: 0.678229, acc: 54.69%] [G loss: 1.908626]\n",
      "epoch:23 step:18730 [D loss: 0.172577, acc: 98.44%] [G loss: 4.095515]\n",
      "epoch:23 step:18731 [D loss: 0.269388, acc: 96.09%] [G loss: 3.103136]\n",
      "epoch:23 step:18732 [D loss: 0.794737, acc: 53.91%] [G loss: 3.373847]\n",
      "epoch:23 step:18733 [D loss: 0.452743, acc: 85.16%] [G loss: 2.578233]\n",
      "epoch:23 step:18734 [D loss: 1.360592, acc: 30.47%] [G loss: 3.789016]\n",
      "epoch:23 step:18735 [D loss: 0.227518, acc: 96.88%] [G loss: 4.228297]\n",
      "epoch:23 step:18736 [D loss: 0.162547, acc: 96.88%] [G loss: 4.509652]\n",
      "epoch:23 step:18737 [D loss: 0.865429, acc: 44.53%] [G loss: 2.866982]\n",
      "epoch:23 step:18738 [D loss: 0.403394, acc: 89.84%] [G loss: 3.028079]\n",
      "epoch:23 step:18739 [D loss: 0.376560, acc: 78.91%] [G loss: 3.411053]\n",
      "epoch:23 step:18740 [D loss: 0.273410, acc: 92.19%] [G loss: 3.273325]\n",
      "epoch:23 step:18741 [D loss: 1.305617, acc: 31.25%] [G loss: 4.521289]\n",
      "epoch:23 step:18742 [D loss: 1.685000, acc: 3.12%] [G loss: 4.820562]\n",
      "epoch:23 step:18743 [D loss: 0.336989, acc: 92.97%] [G loss: 2.491174]\n",
      "epoch:23 step:18744 [D loss: 0.497911, acc: 82.03%] [G loss: 3.703040]\n",
      "epoch:24 step:18745 [D loss: 0.428948, acc: 85.94%] [G loss: 2.973359]\n",
      "epoch:24 step:18746 [D loss: 0.647540, acc: 57.81%] [G loss: 2.981323]\n",
      "epoch:24 step:18747 [D loss: 0.411460, acc: 85.94%] [G loss: 4.487278]\n",
      "epoch:24 step:18748 [D loss: 0.400851, acc: 90.62%] [G loss: 4.743979]\n",
      "epoch:24 step:18749 [D loss: 0.928662, acc: 50.78%] [G loss: 6.421537]\n",
      "epoch:24 step:18750 [D loss: 0.500281, acc: 62.50%] [G loss: 4.657677]\n",
      "epoch:24 step:18751 [D loss: 1.238907, acc: 50.00%] [G loss: 2.264046]\n",
      "epoch:24 step:18752 [D loss: 0.668328, acc: 58.59%] [G loss: 3.320674]\n",
      "epoch:24 step:18753 [D loss: 0.258685, acc: 96.88%] [G loss: 2.812511]\n",
      "epoch:24 step:18754 [D loss: 1.108765, acc: 41.41%] [G loss: 2.820537]\n",
      "epoch:24 step:18755 [D loss: 0.384836, acc: 89.06%] [G loss: 4.420004]\n",
      "epoch:24 step:18756 [D loss: 0.989798, acc: 23.44%] [G loss: 4.492134]\n",
      "epoch:24 step:18757 [D loss: 0.124005, acc: 100.00%] [G loss: 4.302505]\n",
      "epoch:24 step:18758 [D loss: 0.391154, acc: 89.84%] [G loss: 3.824558]\n",
      "epoch:24 step:18759 [D loss: 0.975223, acc: 25.00%] [G loss: 3.237874]\n",
      "epoch:24 step:18760 [D loss: 0.193042, acc: 100.00%] [G loss: 2.357276]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:24 step:18761 [D loss: 0.231257, acc: 96.88%] [G loss: 4.459582]\n",
      "epoch:24 step:18762 [D loss: 0.497668, acc: 80.47%] [G loss: 4.389255]\n",
      "epoch:24 step:18763 [D loss: 0.667871, acc: 56.25%] [G loss: 4.433771]\n",
      "epoch:24 step:18764 [D loss: 1.098952, acc: 46.09%] [G loss: 4.192193]\n",
      "epoch:24 step:18765 [D loss: 0.311315, acc: 90.62%] [G loss: 3.463577]\n",
      "epoch:24 step:18766 [D loss: 0.535970, acc: 70.31%] [G loss: 4.245007]\n",
      "epoch:24 step:18767 [D loss: 0.218255, acc: 98.44%] [G loss: 3.711690]\n",
      "epoch:24 step:18768 [D loss: 0.946349, acc: 50.00%] [G loss: 3.784392]\n",
      "epoch:24 step:18769 [D loss: 1.008533, acc: 47.66%] [G loss: 3.764965]\n",
      "epoch:24 step:18770 [D loss: 0.452478, acc: 73.44%] [G loss: 3.462817]\n",
      "epoch:24 step:18771 [D loss: 0.213265, acc: 99.22%] [G loss: 3.142380]\n",
      "epoch:24 step:18772 [D loss: 0.246257, acc: 97.66%] [G loss: 4.753376]\n",
      "epoch:24 step:18773 [D loss: 0.456255, acc: 73.44%] [G loss: 5.513994]\n",
      "epoch:24 step:18774 [D loss: 0.222702, acc: 96.88%] [G loss: 3.040916]\n",
      "epoch:24 step:18775 [D loss: 0.365776, acc: 91.41%] [G loss: 4.163917]\n",
      "epoch:24 step:18776 [D loss: 0.415999, acc: 85.16%] [G loss: 2.927726]\n",
      "epoch:24 step:18777 [D loss: 0.774387, acc: 47.66%] [G loss: 3.241182]\n",
      "epoch:24 step:18778 [D loss: 0.695216, acc: 51.56%] [G loss: 3.034003]\n",
      "epoch:24 step:18779 [D loss: 0.325014, acc: 84.38%] [G loss: 4.035891]\n",
      "epoch:24 step:18780 [D loss: 0.090793, acc: 100.00%] [G loss: 4.012519]\n",
      "epoch:24 step:18781 [D loss: 0.240238, acc: 96.88%] [G loss: 3.428882]\n",
      "epoch:24 step:18782 [D loss: 0.417713, acc: 91.41%] [G loss: 3.254720]\n",
      "epoch:24 step:18783 [D loss: 0.236064, acc: 96.88%] [G loss: 2.553663]\n",
      "epoch:24 step:18784 [D loss: 0.339774, acc: 89.84%] [G loss: 3.071786]\n",
      "epoch:24 step:18785 [D loss: 1.089107, acc: 51.56%] [G loss: 2.833955]\n",
      "epoch:24 step:18786 [D loss: 0.659195, acc: 60.94%] [G loss: 4.325154]\n",
      "epoch:24 step:18787 [D loss: 0.446636, acc: 85.16%] [G loss: 2.362427]\n",
      "epoch:24 step:18788 [D loss: 0.992316, acc: 31.25%] [G loss: 1.636125]\n",
      "epoch:24 step:18789 [D loss: 0.625378, acc: 54.69%] [G loss: 4.076084]\n",
      "epoch:24 step:18790 [D loss: 0.792805, acc: 50.00%] [G loss: 2.500529]\n",
      "epoch:24 step:18791 [D loss: 0.280934, acc: 96.88%] [G loss: 3.301552]\n",
      "epoch:24 step:18792 [D loss: 0.197401, acc: 98.44%] [G loss: 4.225386]\n",
      "epoch:24 step:18793 [D loss: 0.246900, acc: 97.66%] [G loss: 1.950634]\n",
      "epoch:24 step:18794 [D loss: 0.614686, acc: 69.53%] [G loss: 3.587012]\n",
      "epoch:24 step:18795 [D loss: 1.070866, acc: 46.09%] [G loss: 3.219125]\n",
      "epoch:24 step:18796 [D loss: 0.329373, acc: 91.41%] [G loss: 3.211707]\n",
      "epoch:24 step:18797 [D loss: 0.289388, acc: 94.53%] [G loss: 4.610333]\n",
      "epoch:24 step:18798 [D loss: 0.572818, acc: 66.41%] [G loss: 4.061958]\n",
      "epoch:24 step:18799 [D loss: 0.768869, acc: 50.78%] [G loss: 3.254724]\n",
      "epoch:24 step:18800 [D loss: 0.748498, acc: 50.00%] [G loss: 3.468362]\n",
      "##############\n",
      "[0.85182129 0.84832938 0.84154588 0.79739217 0.7890792  0.80854989\n",
      " 0.91120961 0.84224563 0.81051006 0.84160856]\n",
      "##########\n",
      "epoch:24 step:18801 [D loss: 0.455947, acc: 72.66%] [G loss: 4.684859]\n",
      "epoch:24 step:18802 [D loss: 0.285430, acc: 97.66%] [G loss: 4.527668]\n",
      "epoch:24 step:18803 [D loss: 0.298577, acc: 90.62%] [G loss: 3.094140]\n",
      "epoch:24 step:18804 [D loss: 0.244056, acc: 97.66%] [G loss: 3.651084]\n",
      "epoch:24 step:18805 [D loss: 0.431324, acc: 89.06%] [G loss: 4.807455]\n",
      "epoch:24 step:18806 [D loss: 0.560896, acc: 65.62%] [G loss: 3.180063]\n",
      "epoch:24 step:18807 [D loss: 0.253243, acc: 97.66%] [G loss: 3.539455]\n",
      "epoch:24 step:18808 [D loss: 0.231655, acc: 98.44%] [G loss: 4.112351]\n",
      "epoch:24 step:18809 [D loss: 0.427704, acc: 84.38%] [G loss: 1.955222]\n",
      "epoch:24 step:18810 [D loss: 1.033975, acc: 20.31%] [G loss: 3.136305]\n",
      "epoch:24 step:18811 [D loss: 0.726062, acc: 57.03%] [G loss: 3.356013]\n",
      "epoch:24 step:18812 [D loss: 1.433851, acc: 32.81%] [G loss: 3.591680]\n",
      "epoch:24 step:18813 [D loss: 0.171830, acc: 99.22%] [G loss: 4.050866]\n",
      "epoch:24 step:18814 [D loss: 0.203613, acc: 96.88%] [G loss: 2.855917]\n",
      "epoch:24 step:18815 [D loss: 0.502815, acc: 75.78%] [G loss: 3.365748]\n",
      "epoch:24 step:18816 [D loss: 0.366392, acc: 90.62%] [G loss: 4.042015]\n",
      "epoch:24 step:18817 [D loss: 0.209051, acc: 95.31%] [G loss: 5.242869]\n",
      "epoch:24 step:18818 [D loss: 0.145071, acc: 98.44%] [G loss: 4.058108]\n",
      "epoch:24 step:18819 [D loss: 0.409135, acc: 70.31%] [G loss: 4.898634]\n",
      "epoch:24 step:18820 [D loss: 0.126418, acc: 100.00%] [G loss: 4.282360]\n",
      "epoch:24 step:18821 [D loss: 0.772215, acc: 44.53%] [G loss: 2.689404]\n",
      "epoch:24 step:18822 [D loss: 0.379153, acc: 90.62%] [G loss: 3.434147]\n",
      "epoch:24 step:18823 [D loss: 0.197218, acc: 99.22%] [G loss: 3.086363]\n",
      "epoch:24 step:18824 [D loss: 0.179350, acc: 96.88%] [G loss: 2.774186]\n",
      "epoch:24 step:18825 [D loss: 0.200862, acc: 97.66%] [G loss: 2.995445]\n",
      "epoch:24 step:18826 [D loss: 0.342265, acc: 93.75%] [G loss: 4.578011]\n",
      "epoch:24 step:18827 [D loss: 0.313985, acc: 94.53%] [G loss: 2.634771]\n",
      "epoch:24 step:18828 [D loss: 0.352331, acc: 92.97%] [G loss: 3.562025]\n",
      "epoch:24 step:18829 [D loss: 0.141168, acc: 100.00%] [G loss: 7.039759]\n",
      "epoch:24 step:18830 [D loss: 1.217256, acc: 10.16%] [G loss: 3.896907]\n",
      "epoch:24 step:18831 [D loss: 0.249796, acc: 97.66%] [G loss: 3.956465]\n",
      "epoch:24 step:18832 [D loss: 1.302739, acc: 10.94%] [G loss: 3.286272]\n",
      "epoch:24 step:18833 [D loss: 0.073474, acc: 100.00%] [G loss: 5.330537]\n",
      "epoch:24 step:18834 [D loss: 0.321607, acc: 96.09%] [G loss: 3.906741]\n",
      "epoch:24 step:18835 [D loss: 0.141165, acc: 100.00%] [G loss: 5.274439]\n",
      "epoch:24 step:18836 [D loss: 0.100098, acc: 99.22%] [G loss: 5.090045]\n",
      "epoch:24 step:18837 [D loss: 0.129167, acc: 100.00%] [G loss: 2.776041]\n",
      "epoch:24 step:18838 [D loss: 0.170300, acc: 100.00%] [G loss: 2.715728]\n",
      "epoch:24 step:18839 [D loss: 0.721787, acc: 53.91%] [G loss: 3.395754]\n",
      "epoch:24 step:18840 [D loss: 0.633576, acc: 58.59%] [G loss: 3.364949]\n",
      "epoch:24 step:18841 [D loss: 0.715790, acc: 53.91%] [G loss: 3.983584]\n",
      "epoch:24 step:18842 [D loss: 0.350462, acc: 86.72%] [G loss: 2.683182]\n",
      "epoch:24 step:18843 [D loss: 0.477123, acc: 82.81%] [G loss: 3.072320]\n",
      "epoch:24 step:18844 [D loss: 0.250905, acc: 93.75%] [G loss: 4.967168]\n",
      "epoch:24 step:18845 [D loss: 0.530268, acc: 59.38%] [G loss: 3.541021]\n",
      "epoch:24 step:18846 [D loss: 0.469367, acc: 70.31%] [G loss: 2.824745]\n",
      "epoch:24 step:18847 [D loss: 0.406671, acc: 76.56%] [G loss: 4.784196]\n",
      "epoch:24 step:18848 [D loss: 0.137581, acc: 98.44%] [G loss: 3.443776]\n",
      "epoch:24 step:18849 [D loss: 0.230289, acc: 96.88%] [G loss: 1.867154]\n",
      "epoch:24 step:18850 [D loss: 0.687456, acc: 57.03%] [G loss: 2.526941]\n",
      "epoch:24 step:18851 [D loss: 0.380946, acc: 89.84%] [G loss: 4.496846]\n",
      "epoch:24 step:18852 [D loss: 0.975635, acc: 46.09%] [G loss: 3.318998]\n",
      "epoch:24 step:18853 [D loss: 0.456723, acc: 81.25%] [G loss: 3.415179]\n",
      "epoch:24 step:18854 [D loss: 0.278377, acc: 94.53%] [G loss: 3.056861]\n",
      "epoch:24 step:18855 [D loss: 0.244508, acc: 97.66%] [G loss: 4.400140]\n",
      "epoch:24 step:18856 [D loss: 0.363637, acc: 87.50%] [G loss: 4.476616]\n",
      "epoch:24 step:18857 [D loss: 0.502779, acc: 71.09%] [G loss: 2.960110]\n",
      "epoch:24 step:18858 [D loss: 0.190865, acc: 97.66%] [G loss: 2.911669]\n",
      "epoch:24 step:18859 [D loss: 0.919120, acc: 46.09%] [G loss: 3.261809]\n",
      "epoch:24 step:18860 [D loss: 0.611072, acc: 56.25%] [G loss: 2.972290]\n",
      "epoch:24 step:18861 [D loss: 0.502483, acc: 71.88%] [G loss: 3.449011]\n",
      "epoch:24 step:18862 [D loss: 0.195037, acc: 98.44%] [G loss: 2.817866]\n",
      "epoch:24 step:18863 [D loss: 0.200148, acc: 99.22%] [G loss: 3.185624]\n",
      "epoch:24 step:18864 [D loss: 0.178315, acc: 99.22%] [G loss: 4.025105]\n",
      "epoch:24 step:18865 [D loss: 0.161422, acc: 100.00%] [G loss: 2.838957]\n",
      "epoch:24 step:18866 [D loss: 0.291303, acc: 94.53%] [G loss: 1.781922]\n",
      "epoch:24 step:18867 [D loss: 0.158379, acc: 98.44%] [G loss: 3.148898]\n",
      "epoch:24 step:18868 [D loss: 0.971156, acc: 39.84%] [G loss: 3.618449]\n",
      "epoch:24 step:18869 [D loss: 0.239572, acc: 96.88%] [G loss: 2.748792]\n",
      "epoch:24 step:18870 [D loss: 0.127526, acc: 99.22%] [G loss: 4.744617]\n",
      "epoch:24 step:18871 [D loss: 0.571532, acc: 62.50%] [G loss: 4.656847]\n",
      "epoch:24 step:18872 [D loss: 0.296007, acc: 89.84%] [G loss: 3.771483]\n",
      "epoch:24 step:18873 [D loss: 0.474320, acc: 81.25%] [G loss: 2.675144]\n",
      "epoch:24 step:18874 [D loss: 0.618459, acc: 57.81%] [G loss: 4.708349]\n",
      "epoch:24 step:18875 [D loss: 0.405891, acc: 76.56%] [G loss: 3.703006]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:24 step:18876 [D loss: 0.917426, acc: 37.50%] [G loss: 3.482187]\n",
      "epoch:24 step:18877 [D loss: 0.394820, acc: 94.53%] [G loss: 3.546386]\n",
      "epoch:24 step:18878 [D loss: 0.597753, acc: 73.44%] [G loss: 2.781962]\n",
      "epoch:24 step:18879 [D loss: 0.581338, acc: 66.41%] [G loss: 3.446019]\n",
      "epoch:24 step:18880 [D loss: 0.141817, acc: 100.00%] [G loss: 3.515718]\n",
      "epoch:24 step:18881 [D loss: 1.246776, acc: 49.22%] [G loss: 1.819543]\n",
      "epoch:24 step:18882 [D loss: 0.423351, acc: 78.91%] [G loss: 4.878346]\n",
      "epoch:24 step:18883 [D loss: 0.339789, acc: 85.94%] [G loss: 3.036163]\n",
      "epoch:24 step:18884 [D loss: 0.604931, acc: 57.03%] [G loss: 2.693650]\n",
      "epoch:24 step:18885 [D loss: 0.432098, acc: 83.59%] [G loss: 2.749423]\n",
      "epoch:24 step:18886 [D loss: 0.737611, acc: 53.91%] [G loss: 5.463634]\n",
      "epoch:24 step:18887 [D loss: 0.729989, acc: 52.34%] [G loss: 3.909081]\n",
      "epoch:24 step:18888 [D loss: 0.601707, acc: 68.75%] [G loss: 2.904204]\n",
      "epoch:24 step:18889 [D loss: 1.310837, acc: 50.00%] [G loss: 1.523073]\n",
      "epoch:24 step:18890 [D loss: 0.283835, acc: 92.19%] [G loss: 3.490147]\n",
      "epoch:24 step:18891 [D loss: 0.677691, acc: 53.91%] [G loss: 3.800579]\n",
      "epoch:24 step:18892 [D loss: 0.242265, acc: 95.31%] [G loss: 5.576712]\n",
      "epoch:24 step:18893 [D loss: 0.625020, acc: 64.84%] [G loss: 5.576746]\n",
      "epoch:24 step:18894 [D loss: 0.385768, acc: 89.84%] [G loss: 2.876442]\n",
      "epoch:24 step:18895 [D loss: 0.392270, acc: 82.81%] [G loss: 4.879483]\n",
      "epoch:24 step:18896 [D loss: 0.385718, acc: 88.28%] [G loss: 6.032848]\n",
      "epoch:24 step:18897 [D loss: 0.576725, acc: 68.75%] [G loss: 3.625369]\n",
      "epoch:24 step:18898 [D loss: 0.155751, acc: 100.00%] [G loss: 3.280196]\n",
      "epoch:24 step:18899 [D loss: 0.477104, acc: 78.91%] [G loss: 3.608932]\n",
      "epoch:24 step:18900 [D loss: 0.498807, acc: 72.66%] [G loss: 5.064466]\n",
      "epoch:24 step:18901 [D loss: 0.270902, acc: 94.53%] [G loss: 3.380384]\n",
      "epoch:24 step:18902 [D loss: 0.246969, acc: 96.88%] [G loss: 3.111954]\n",
      "epoch:24 step:18903 [D loss: 0.291931, acc: 90.62%] [G loss: 4.372938]\n",
      "epoch:24 step:18904 [D loss: 0.287689, acc: 94.53%] [G loss: 3.365462]\n",
      "epoch:24 step:18905 [D loss: 0.605886, acc: 55.47%] [G loss: 4.811419]\n",
      "epoch:24 step:18906 [D loss: 0.403376, acc: 82.03%] [G loss: 2.509821]\n",
      "epoch:24 step:18907 [D loss: 0.893861, acc: 50.00%] [G loss: 5.562813]\n",
      "epoch:24 step:18908 [D loss: 0.521168, acc: 60.16%] [G loss: 5.130768]\n",
      "epoch:24 step:18909 [D loss: 0.257345, acc: 97.66%] [G loss: 2.665201]\n",
      "epoch:24 step:18910 [D loss: 0.595713, acc: 67.19%] [G loss: 3.132725]\n",
      "epoch:24 step:18911 [D loss: 0.250428, acc: 92.19%] [G loss: 6.405980]\n",
      "epoch:24 step:18912 [D loss: 0.789902, acc: 50.00%] [G loss: 2.783618]\n",
      "epoch:24 step:18913 [D loss: 0.253436, acc: 96.88%] [G loss: 2.714880]\n",
      "epoch:24 step:18914 [D loss: 1.229590, acc: 13.28%] [G loss: 2.423043]\n",
      "epoch:24 step:18915 [D loss: 0.354295, acc: 89.84%] [G loss: 2.248998]\n",
      "epoch:24 step:18916 [D loss: 0.816549, acc: 50.00%] [G loss: 4.038406]\n",
      "epoch:24 step:18917 [D loss: 0.714955, acc: 60.16%] [G loss: 2.880212]\n",
      "epoch:24 step:18918 [D loss: 0.163401, acc: 96.88%] [G loss: 4.480093]\n",
      "epoch:24 step:18919 [D loss: 0.388402, acc: 89.06%] [G loss: 5.047396]\n",
      "epoch:24 step:18920 [D loss: 0.822388, acc: 53.12%] [G loss: 4.793634]\n",
      "epoch:24 step:18921 [D loss: 0.212268, acc: 99.22%] [G loss: 3.807351]\n",
      "epoch:24 step:18922 [D loss: 0.517537, acc: 67.97%] [G loss: 3.952523]\n",
      "epoch:24 step:18923 [D loss: 0.353962, acc: 95.31%] [G loss: 3.108275]\n",
      "epoch:24 step:18924 [D loss: 0.557245, acc: 67.19%] [G loss: 3.346705]\n",
      "epoch:24 step:18925 [D loss: 0.598366, acc: 67.19%] [G loss: 2.801618]\n",
      "epoch:24 step:18926 [D loss: 0.877934, acc: 48.44%] [G loss: 3.300842]\n",
      "epoch:24 step:18927 [D loss: 0.584852, acc: 62.50%] [G loss: 1.933060]\n",
      "epoch:24 step:18928 [D loss: 0.174735, acc: 97.66%] [G loss: 2.478835]\n",
      "epoch:24 step:18929 [D loss: 0.305427, acc: 96.09%] [G loss: 3.403358]\n",
      "epoch:24 step:18930 [D loss: 0.228068, acc: 100.00%] [G loss: 5.650833]\n",
      "epoch:24 step:18931 [D loss: 0.176533, acc: 99.22%] [G loss: 3.729057]\n",
      "epoch:24 step:18932 [D loss: 0.501575, acc: 67.97%] [G loss: 5.824679]\n",
      "epoch:24 step:18933 [D loss: 0.223777, acc: 93.75%] [G loss: 4.248752]\n",
      "epoch:24 step:18934 [D loss: 0.480693, acc: 79.69%] [G loss: 3.841976]\n",
      "epoch:24 step:18935 [D loss: 0.406010, acc: 80.47%] [G loss: 5.316754]\n",
      "epoch:24 step:18936 [D loss: 0.090915, acc: 100.00%] [G loss: 5.875013]\n",
      "epoch:24 step:18937 [D loss: 0.667590, acc: 55.47%] [G loss: 3.432350]\n",
      "epoch:24 step:18938 [D loss: 0.127579, acc: 100.00%] [G loss: 4.221637]\n",
      "epoch:24 step:18939 [D loss: 0.902169, acc: 34.38%] [G loss: 3.450028]\n",
      "epoch:24 step:18940 [D loss: 0.962967, acc: 32.81%] [G loss: 3.646481]\n",
      "epoch:24 step:18941 [D loss: 0.445143, acc: 83.59%] [G loss: 4.471208]\n",
      "epoch:24 step:18942 [D loss: 0.343093, acc: 95.31%] [G loss: 3.621792]\n",
      "epoch:24 step:18943 [D loss: 0.198856, acc: 98.44%] [G loss: 3.597190]\n",
      "epoch:24 step:18944 [D loss: 0.254469, acc: 92.97%] [G loss: 4.705116]\n",
      "epoch:24 step:18945 [D loss: 0.303326, acc: 88.28%] [G loss: 4.366772]\n",
      "epoch:24 step:18946 [D loss: 1.184841, acc: 21.09%] [G loss: 2.120857]\n",
      "epoch:24 step:18947 [D loss: 1.040456, acc: 48.44%] [G loss: 3.623568]\n",
      "epoch:24 step:18948 [D loss: 0.454354, acc: 72.66%] [G loss: 4.198455]\n",
      "epoch:24 step:18949 [D loss: 0.626866, acc: 65.62%] [G loss: 3.741889]\n",
      "epoch:24 step:18950 [D loss: 0.199486, acc: 97.66%] [G loss: 4.129363]\n",
      "epoch:24 step:18951 [D loss: 0.281539, acc: 97.66%] [G loss: 2.697277]\n",
      "epoch:24 step:18952 [D loss: 0.245369, acc: 99.22%] [G loss: 3.892577]\n",
      "epoch:24 step:18953 [D loss: 0.325237, acc: 95.31%] [G loss: 2.722638]\n",
      "epoch:24 step:18954 [D loss: 0.455304, acc: 67.97%] [G loss: 4.682517]\n",
      "epoch:24 step:18955 [D loss: 0.409974, acc: 78.91%] [G loss: 4.367370]\n",
      "epoch:24 step:18956 [D loss: 0.271140, acc: 96.09%] [G loss: 5.589139]\n",
      "epoch:24 step:18957 [D loss: 0.679715, acc: 60.94%] [G loss: 2.710323]\n",
      "epoch:24 step:18958 [D loss: 0.587564, acc: 67.19%] [G loss: 3.692872]\n",
      "epoch:24 step:18959 [D loss: 0.412416, acc: 67.19%] [G loss: 5.964402]\n",
      "epoch:24 step:18960 [D loss: 0.652073, acc: 57.03%] [G loss: 2.733150]\n",
      "epoch:24 step:18961 [D loss: 0.362953, acc: 89.06%] [G loss: 2.906359]\n",
      "epoch:24 step:18962 [D loss: 0.318234, acc: 93.75%] [G loss: 3.168516]\n",
      "epoch:24 step:18963 [D loss: 0.966648, acc: 34.38%] [G loss: 3.474581]\n",
      "epoch:24 step:18964 [D loss: 0.489380, acc: 69.53%] [G loss: 4.028191]\n",
      "epoch:24 step:18965 [D loss: 0.489340, acc: 82.81%] [G loss: 3.437320]\n",
      "epoch:24 step:18966 [D loss: 0.944898, acc: 38.28%] [G loss: 4.414652]\n",
      "epoch:24 step:18967 [D loss: 0.581458, acc: 60.16%] [G loss: 4.355900]\n",
      "epoch:24 step:18968 [D loss: 0.462978, acc: 77.34%] [G loss: 4.652019]\n",
      "epoch:24 step:18969 [D loss: 0.942929, acc: 42.97%] [G loss: 2.645956]\n",
      "epoch:24 step:18970 [D loss: 0.223689, acc: 98.44%] [G loss: 4.579938]\n",
      "epoch:24 step:18971 [D loss: 0.183900, acc: 100.00%] [G loss: 3.899168]\n",
      "epoch:24 step:18972 [D loss: 0.270368, acc: 92.19%] [G loss: 3.914889]\n",
      "epoch:24 step:18973 [D loss: 0.082804, acc: 100.00%] [G loss: 3.336960]\n",
      "epoch:24 step:18974 [D loss: 0.465015, acc: 67.97%] [G loss: 4.649740]\n",
      "epoch:24 step:18975 [D loss: 1.279355, acc: 50.78%] [G loss: 3.970713]\n",
      "epoch:24 step:18976 [D loss: 0.314290, acc: 93.75%] [G loss: 2.201623]\n",
      "epoch:24 step:18977 [D loss: 0.485625, acc: 82.03%] [G loss: 4.350172]\n",
      "epoch:24 step:18978 [D loss: 0.139852, acc: 99.22%] [G loss: 5.311043]\n",
      "epoch:24 step:18979 [D loss: 0.241657, acc: 97.66%] [G loss: 4.605103]\n",
      "epoch:24 step:18980 [D loss: 0.637488, acc: 57.81%] [G loss: 4.058771]\n",
      "epoch:24 step:18981 [D loss: 0.248979, acc: 92.97%] [G loss: 3.831322]\n",
      "epoch:24 step:18982 [D loss: 0.544983, acc: 62.50%] [G loss: 6.066183]\n",
      "epoch:24 step:18983 [D loss: 0.617571, acc: 62.50%] [G loss: 3.263968]\n",
      "epoch:24 step:18984 [D loss: 0.153774, acc: 99.22%] [G loss: 1.865158]\n",
      "epoch:24 step:18985 [D loss: 0.215916, acc: 98.44%] [G loss: 3.434659]\n",
      "epoch:24 step:18986 [D loss: 0.267566, acc: 90.62%] [G loss: 3.720418]\n",
      "epoch:24 step:18987 [D loss: 0.434617, acc: 85.16%] [G loss: 4.016587]\n",
      "epoch:24 step:18988 [D loss: 0.426181, acc: 83.59%] [G loss: 3.253167]\n",
      "epoch:24 step:18989 [D loss: 1.250835, acc: 9.38%] [G loss: 2.326585]\n",
      "epoch:24 step:18990 [D loss: 0.625657, acc: 64.06%] [G loss: 3.649372]\n",
      "epoch:24 step:18991 [D loss: 0.816273, acc: 51.56%] [G loss: 3.018750]\n",
      "epoch:24 step:18992 [D loss: 0.869720, acc: 48.44%] [G loss: 2.438681]\n",
      "epoch:24 step:18993 [D loss: 0.336450, acc: 92.97%] [G loss: 2.988191]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:24 step:18994 [D loss: 0.257503, acc: 91.41%] [G loss: 4.459301]\n",
      "epoch:24 step:18995 [D loss: 0.111972, acc: 99.22%] [G loss: 5.487015]\n",
      "epoch:24 step:18996 [D loss: 0.307092, acc: 93.75%] [G loss: 3.952641]\n",
      "epoch:24 step:18997 [D loss: 1.567629, acc: 6.25%] [G loss: 2.215126]\n",
      "epoch:24 step:18998 [D loss: 0.640290, acc: 66.41%] [G loss: 3.563539]\n",
      "epoch:24 step:18999 [D loss: 0.198666, acc: 100.00%] [G loss: 3.081579]\n",
      "epoch:24 step:19000 [D loss: 0.857637, acc: 50.78%] [G loss: 2.576687]\n",
      "##############\n",
      "[0.85867248 0.86557556 0.81597535 0.81906005 0.78289643 0.81971792\n",
      " 0.91429549 0.83153411 0.8129507  0.82640129]\n",
      "##########\n",
      "epoch:24 step:19001 [D loss: 1.020518, acc: 32.03%] [G loss: 4.760877]\n",
      "epoch:24 step:19002 [D loss: 0.344967, acc: 90.62%] [G loss: 3.209482]\n",
      "epoch:24 step:19003 [D loss: 0.867100, acc: 39.84%] [G loss: 4.697161]\n",
      "epoch:24 step:19004 [D loss: 1.356960, acc: 31.25%] [G loss: 3.273060]\n",
      "epoch:24 step:19005 [D loss: 0.673633, acc: 56.25%] [G loss: 3.365685]\n",
      "epoch:24 step:19006 [D loss: 0.499928, acc: 78.91%] [G loss: 4.393782]\n",
      "epoch:24 step:19007 [D loss: 0.547509, acc: 67.19%] [G loss: 5.687780]\n",
      "epoch:24 step:19008 [D loss: 0.327384, acc: 92.19%] [G loss: 3.336701]\n",
      "epoch:24 step:19009 [D loss: 0.431178, acc: 77.34%] [G loss: 2.345495]\n",
      "epoch:24 step:19010 [D loss: 0.124318, acc: 100.00%] [G loss: 4.513296]\n",
      "epoch:24 step:19011 [D loss: 0.592274, acc: 75.78%] [G loss: 2.945194]\n",
      "epoch:24 step:19012 [D loss: 0.268940, acc: 89.84%] [G loss: 4.322141]\n",
      "epoch:24 step:19013 [D loss: 0.844652, acc: 41.41%] [G loss: 2.212005]\n",
      "epoch:24 step:19014 [D loss: 0.764811, acc: 52.34%] [G loss: 3.247058]\n",
      "epoch:24 step:19015 [D loss: 0.455035, acc: 82.03%] [G loss: 3.591741]\n",
      "epoch:24 step:19016 [D loss: 0.428416, acc: 88.28%] [G loss: 3.411530]\n",
      "epoch:24 step:19017 [D loss: 0.250397, acc: 97.66%] [G loss: 1.752759]\n",
      "epoch:24 step:19018 [D loss: 0.433468, acc: 78.91%] [G loss: 2.225319]\n",
      "epoch:24 step:19019 [D loss: 1.246002, acc: 16.41%] [G loss: 3.403355]\n",
      "epoch:24 step:19020 [D loss: 0.537233, acc: 64.06%] [G loss: 4.513420]\n",
      "epoch:24 step:19021 [D loss: 0.664252, acc: 61.72%] [G loss: 2.939090]\n",
      "epoch:24 step:19022 [D loss: 0.550479, acc: 66.41%] [G loss: 3.373654]\n",
      "epoch:24 step:19023 [D loss: 0.448625, acc: 82.81%] [G loss: 2.683154]\n",
      "epoch:24 step:19024 [D loss: 0.268349, acc: 96.88%] [G loss: 3.122767]\n",
      "epoch:24 step:19025 [D loss: 0.345981, acc: 92.19%] [G loss: 3.612574]\n",
      "epoch:24 step:19026 [D loss: 0.537917, acc: 72.66%] [G loss: 2.133122]\n",
      "epoch:24 step:19027 [D loss: 0.202949, acc: 99.22%] [G loss: 2.435081]\n",
      "epoch:24 step:19028 [D loss: 0.320517, acc: 96.88%] [G loss: 3.609787]\n",
      "epoch:24 step:19029 [D loss: 0.728181, acc: 52.34%] [G loss: 2.837467]\n",
      "epoch:24 step:19030 [D loss: 0.304469, acc: 86.72%] [G loss: 4.240140]\n",
      "epoch:24 step:19031 [D loss: 1.285524, acc: 48.44%] [G loss: 4.472612]\n",
      "epoch:24 step:19032 [D loss: 0.744339, acc: 51.56%] [G loss: 3.338765]\n",
      "epoch:24 step:19033 [D loss: 0.203224, acc: 97.66%] [G loss: 3.815109]\n",
      "epoch:24 step:19034 [D loss: 0.377232, acc: 90.62%] [G loss: 3.749031]\n",
      "epoch:24 step:19035 [D loss: 1.137858, acc: 49.22%] [G loss: 1.806783]\n",
      "epoch:24 step:19036 [D loss: 0.213004, acc: 98.44%] [G loss: 3.398040]\n",
      "epoch:24 step:19037 [D loss: 0.426657, acc: 86.72%] [G loss: 3.315876]\n",
      "epoch:24 step:19038 [D loss: 0.833828, acc: 50.78%] [G loss: 2.924205]\n",
      "epoch:24 step:19039 [D loss: 0.460715, acc: 81.25%] [G loss: 2.941518]\n",
      "epoch:24 step:19040 [D loss: 0.243480, acc: 96.09%] [G loss: 3.914895]\n",
      "epoch:24 step:19041 [D loss: 0.436164, acc: 75.00%] [G loss: 3.656103]\n",
      "epoch:24 step:19042 [D loss: 1.047520, acc: 23.44%] [G loss: 4.097617]\n",
      "epoch:24 step:19043 [D loss: 0.378130, acc: 83.59%] [G loss: 4.225362]\n",
      "epoch:24 step:19044 [D loss: 0.534409, acc: 71.88%] [G loss: 3.436959]\n",
      "epoch:24 step:19045 [D loss: 0.601884, acc: 74.22%] [G loss: 2.020296]\n",
      "epoch:24 step:19046 [D loss: 1.051109, acc: 34.38%] [G loss: 2.929075]\n",
      "epoch:24 step:19047 [D loss: 0.380592, acc: 90.62%] [G loss: 3.094903]\n",
      "epoch:24 step:19048 [D loss: 0.194851, acc: 99.22%] [G loss: 3.186244]\n",
      "epoch:24 step:19049 [D loss: 0.638645, acc: 60.94%] [G loss: 4.151997]\n",
      "epoch:24 step:19050 [D loss: 0.132650, acc: 99.22%] [G loss: 2.927364]\n",
      "epoch:24 step:19051 [D loss: 0.426938, acc: 67.97%] [G loss: 3.717146]\n",
      "epoch:24 step:19052 [D loss: 0.757369, acc: 56.25%] [G loss: 3.431686]\n",
      "epoch:24 step:19053 [D loss: 0.331733, acc: 89.84%] [G loss: 3.686190]\n",
      "epoch:24 step:19054 [D loss: 0.472111, acc: 69.53%] [G loss: 4.084005]\n",
      "epoch:24 step:19055 [D loss: 0.862470, acc: 50.78%] [G loss: 2.269006]\n",
      "epoch:24 step:19056 [D loss: 0.363895, acc: 92.97%] [G loss: 3.206582]\n",
      "epoch:24 step:19057 [D loss: 0.877051, acc: 36.72%] [G loss: 2.506897]\n",
      "epoch:24 step:19058 [D loss: 0.533585, acc: 78.91%] [G loss: 3.005966]\n",
      "epoch:24 step:19059 [D loss: 0.741094, acc: 50.00%] [G loss: 4.485310]\n",
      "epoch:24 step:19060 [D loss: 0.816630, acc: 47.66%] [G loss: 2.839453]\n",
      "epoch:24 step:19061 [D loss: 0.470240, acc: 89.06%] [G loss: 3.920537]\n",
      "epoch:24 step:19062 [D loss: 0.446973, acc: 83.59%] [G loss: 3.018795]\n",
      "epoch:24 step:19063 [D loss: 0.712368, acc: 51.56%] [G loss: 2.931152]\n",
      "epoch:24 step:19064 [D loss: 0.441678, acc: 85.94%] [G loss: 2.991810]\n",
      "epoch:24 step:19065 [D loss: 0.333391, acc: 91.41%] [G loss: 3.622519]\n",
      "epoch:24 step:19066 [D loss: 0.233450, acc: 96.09%] [G loss: 2.886725]\n",
      "epoch:24 step:19067 [D loss: 0.432788, acc: 82.03%] [G loss: 3.690381]\n",
      "epoch:24 step:19068 [D loss: 0.606757, acc: 64.06%] [G loss: 3.700784]\n",
      "epoch:24 step:19069 [D loss: 0.274305, acc: 96.09%] [G loss: 3.797513]\n",
      "epoch:24 step:19070 [D loss: 0.208610, acc: 98.44%] [G loss: 3.118433]\n",
      "epoch:24 step:19071 [D loss: 0.365466, acc: 91.41%] [G loss: 2.636481]\n",
      "epoch:24 step:19072 [D loss: 0.493418, acc: 68.75%] [G loss: 2.522373]\n",
      "epoch:24 step:19073 [D loss: 0.357856, acc: 85.94%] [G loss: 4.785103]\n",
      "epoch:24 step:19074 [D loss: 0.432065, acc: 82.81%] [G loss: 3.610055]\n",
      "epoch:24 step:19075 [D loss: 0.277709, acc: 99.22%] [G loss: 4.059285]\n",
      "epoch:24 step:19076 [D loss: 0.411998, acc: 85.16%] [G loss: 4.670509]\n",
      "epoch:24 step:19077 [D loss: 0.516734, acc: 60.94%] [G loss: 4.453050]\n",
      "epoch:24 step:19078 [D loss: 0.634799, acc: 68.75%] [G loss: 2.859257]\n",
      "epoch:24 step:19079 [D loss: 0.301597, acc: 92.97%] [G loss: 4.922253]\n",
      "epoch:24 step:19080 [D loss: 0.456351, acc: 85.16%] [G loss: 3.075741]\n",
      "epoch:24 step:19081 [D loss: 0.824369, acc: 39.84%] [G loss: 3.136359]\n",
      "epoch:24 step:19082 [D loss: 0.778767, acc: 44.53%] [G loss: 2.234800]\n",
      "epoch:24 step:19083 [D loss: 0.128960, acc: 99.22%] [G loss: 2.368478]\n",
      "epoch:24 step:19084 [D loss: 1.200911, acc: 17.19%] [G loss: 2.145906]\n",
      "epoch:24 step:19085 [D loss: 0.177637, acc: 100.00%] [G loss: 3.519411]\n",
      "epoch:24 step:19086 [D loss: 0.852039, acc: 42.19%] [G loss: 4.108374]\n",
      "epoch:24 step:19087 [D loss: 1.262701, acc: 18.75%] [G loss: 4.316534]\n",
      "epoch:24 step:19088 [D loss: 0.333106, acc: 91.41%] [G loss: 3.882094]\n",
      "epoch:24 step:19089 [D loss: 1.020242, acc: 21.09%] [G loss: 2.279890]\n",
      "epoch:24 step:19090 [D loss: 0.303900, acc: 97.66%] [G loss: 3.819879]\n",
      "epoch:24 step:19091 [D loss: 0.586982, acc: 64.06%] [G loss: 3.819583]\n",
      "epoch:24 step:19092 [D loss: 1.096096, acc: 21.09%] [G loss: 3.235341]\n",
      "epoch:24 step:19093 [D loss: 0.157353, acc: 99.22%] [G loss: 3.957289]\n",
      "epoch:24 step:19094 [D loss: 0.774963, acc: 49.22%] [G loss: 3.738388]\n",
      "epoch:24 step:19095 [D loss: 0.944367, acc: 46.88%] [G loss: 2.440084]\n",
      "epoch:24 step:19096 [D loss: 0.198234, acc: 98.44%] [G loss: 3.662121]\n",
      "epoch:24 step:19097 [D loss: 0.949346, acc: 50.78%] [G loss: 4.231995]\n",
      "epoch:24 step:19098 [D loss: 0.165304, acc: 99.22%] [G loss: 3.758754]\n",
      "epoch:24 step:19099 [D loss: 1.546319, acc: 3.91%] [G loss: 3.804913]\n",
      "epoch:24 step:19100 [D loss: 0.519193, acc: 68.75%] [G loss: 3.134918]\n",
      "epoch:24 step:19101 [D loss: 0.498172, acc: 75.78%] [G loss: 3.408675]\n",
      "epoch:24 step:19102 [D loss: 0.267007, acc: 94.53%] [G loss: 5.637119]\n",
      "epoch:24 step:19103 [D loss: 0.400266, acc: 90.62%] [G loss: 3.069905]\n",
      "epoch:24 step:19104 [D loss: 0.567306, acc: 64.84%] [G loss: 3.347381]\n",
      "epoch:24 step:19105 [D loss: 0.456092, acc: 83.59%] [G loss: 3.273622]\n",
      "epoch:24 step:19106 [D loss: 0.408703, acc: 79.69%] [G loss: 3.723002]\n",
      "epoch:24 step:19107 [D loss: 0.262778, acc: 98.44%] [G loss: 3.906899]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:24 step:19108 [D loss: 0.259084, acc: 96.88%] [G loss: 3.517825]\n",
      "epoch:24 step:19109 [D loss: 0.239063, acc: 99.22%] [G loss: 4.478172]\n",
      "epoch:24 step:19110 [D loss: 0.911879, acc: 30.47%] [G loss: 4.151534]\n",
      "epoch:24 step:19111 [D loss: 0.095059, acc: 100.00%] [G loss: 4.051551]\n",
      "epoch:24 step:19112 [D loss: 0.471990, acc: 81.25%] [G loss: 4.131846]\n",
      "epoch:24 step:19113 [D loss: 0.327312, acc: 93.75%] [G loss: 4.000369]\n",
      "epoch:24 step:19114 [D loss: 0.390482, acc: 91.41%] [G loss: 2.368252]\n",
      "epoch:24 step:19115 [D loss: 0.173641, acc: 100.00%] [G loss: 4.120684]\n",
      "epoch:24 step:19116 [D loss: 0.565956, acc: 69.53%] [G loss: 4.649408]\n",
      "epoch:24 step:19117 [D loss: 0.858865, acc: 48.44%] [G loss: 3.456166]\n",
      "epoch:24 step:19118 [D loss: 0.249732, acc: 99.22%] [G loss: 2.884710]\n",
      "epoch:24 step:19119 [D loss: 0.311427, acc: 89.84%] [G loss: 3.027287]\n",
      "epoch:24 step:19120 [D loss: 0.370901, acc: 89.06%] [G loss: 4.706927]\n",
      "epoch:24 step:19121 [D loss: 0.632152, acc: 61.72%] [G loss: 4.376138]\n",
      "epoch:24 step:19122 [D loss: 0.366473, acc: 87.50%] [G loss: 3.464855]\n",
      "epoch:24 step:19123 [D loss: 1.097431, acc: 50.00%] [G loss: 3.566338]\n",
      "epoch:24 step:19124 [D loss: 0.426101, acc: 75.78%] [G loss: 3.660129]\n",
      "epoch:24 step:19125 [D loss: 0.390544, acc: 74.22%] [G loss: 5.650390]\n",
      "epoch:24 step:19126 [D loss: 0.636551, acc: 64.84%] [G loss: 2.749419]\n",
      "epoch:24 step:19127 [D loss: 0.231144, acc: 98.44%] [G loss: 3.871087]\n",
      "epoch:24 step:19128 [D loss: 0.195920, acc: 97.66%] [G loss: 3.542164]\n",
      "epoch:24 step:19129 [D loss: 0.448597, acc: 83.59%] [G loss: 3.698411]\n",
      "epoch:24 step:19130 [D loss: 0.473163, acc: 72.66%] [G loss: 2.537540]\n",
      "epoch:24 step:19131 [D loss: 0.405081, acc: 82.81%] [G loss: 2.006304]\n",
      "epoch:24 step:19132 [D loss: 0.550089, acc: 62.50%] [G loss: 3.186546]\n",
      "epoch:24 step:19133 [D loss: 0.988656, acc: 47.66%] [G loss: 3.677214]\n",
      "epoch:24 step:19134 [D loss: 0.783621, acc: 52.34%] [G loss: 2.522499]\n",
      "epoch:24 step:19135 [D loss: 0.303940, acc: 97.66%] [G loss: 3.325596]\n",
      "epoch:24 step:19136 [D loss: 0.375235, acc: 87.50%] [G loss: 3.778152]\n",
      "epoch:24 step:19137 [D loss: 0.655302, acc: 57.81%] [G loss: 3.329674]\n",
      "epoch:24 step:19138 [D loss: 0.265401, acc: 92.19%] [G loss: 4.175186]\n",
      "epoch:24 step:19139 [D loss: 0.192082, acc: 98.44%] [G loss: 3.415604]\n",
      "epoch:24 step:19140 [D loss: 0.386565, acc: 91.41%] [G loss: 3.078737]\n",
      "epoch:24 step:19141 [D loss: 0.987793, acc: 22.66%] [G loss: 3.422889]\n",
      "epoch:24 step:19142 [D loss: 0.478640, acc: 82.81%] [G loss: 3.155022]\n",
      "epoch:24 step:19143 [D loss: 0.441822, acc: 88.28%] [G loss: 3.009499]\n",
      "epoch:24 step:19144 [D loss: 0.315295, acc: 90.62%] [G loss: 3.452513]\n",
      "epoch:24 step:19145 [D loss: 0.483767, acc: 72.66%] [G loss: 4.144688]\n",
      "epoch:24 step:19146 [D loss: 0.454131, acc: 85.16%] [G loss: 3.104821]\n",
      "epoch:24 step:19147 [D loss: 0.713511, acc: 51.56%] [G loss: 2.612040]\n",
      "epoch:24 step:19148 [D loss: 0.478451, acc: 81.25%] [G loss: 4.570366]\n",
      "epoch:24 step:19149 [D loss: 0.274043, acc: 96.09%] [G loss: 2.073513]\n",
      "epoch:24 step:19150 [D loss: 0.156480, acc: 100.00%] [G loss: 3.319939]\n",
      "epoch:24 step:19151 [D loss: 0.209294, acc: 98.44%] [G loss: 3.455982]\n",
      "epoch:24 step:19152 [D loss: 0.556830, acc: 71.09%] [G loss: 4.286992]\n",
      "epoch:24 step:19153 [D loss: 0.114515, acc: 100.00%] [G loss: 2.723767]\n",
      "epoch:24 step:19154 [D loss: 0.385962, acc: 83.59%] [G loss: 5.590465]\n",
      "epoch:24 step:19155 [D loss: 0.170117, acc: 98.44%] [G loss: 4.011073]\n",
      "epoch:24 step:19156 [D loss: 0.281880, acc: 96.88%] [G loss: 3.628088]\n",
      "epoch:24 step:19157 [D loss: 0.140955, acc: 100.00%] [G loss: 3.625264]\n",
      "epoch:24 step:19158 [D loss: 0.494641, acc: 84.38%] [G loss: 4.864541]\n",
      "epoch:24 step:19159 [D loss: 0.459925, acc: 67.97%] [G loss: 2.765728]\n",
      "epoch:24 step:19160 [D loss: 0.742501, acc: 53.91%] [G loss: 4.231129]\n",
      "epoch:24 step:19161 [D loss: 0.488843, acc: 69.53%] [G loss: 2.263505]\n",
      "epoch:24 step:19162 [D loss: 0.449466, acc: 71.09%] [G loss: 2.123517]\n",
      "epoch:24 step:19163 [D loss: 0.676597, acc: 64.84%] [G loss: 3.011605]\n",
      "epoch:24 step:19164 [D loss: 0.805764, acc: 53.91%] [G loss: 4.677939]\n",
      "epoch:24 step:19165 [D loss: 0.477918, acc: 78.91%] [G loss: 2.943743]\n",
      "epoch:24 step:19166 [D loss: 0.151034, acc: 99.22%] [G loss: 4.417439]\n",
      "epoch:24 step:19167 [D loss: 0.111396, acc: 100.00%] [G loss: 4.058386]\n",
      "epoch:24 step:19168 [D loss: 0.257186, acc: 97.66%] [G loss: 4.051609]\n",
      "epoch:24 step:19169 [D loss: 0.201677, acc: 96.88%] [G loss: 4.758839]\n",
      "epoch:24 step:19170 [D loss: 0.636837, acc: 55.47%] [G loss: 2.468816]\n",
      "epoch:24 step:19171 [D loss: 0.945489, acc: 42.97%] [G loss: 2.592432]\n",
      "epoch:24 step:19172 [D loss: 0.830918, acc: 51.56%] [G loss: 2.441784]\n",
      "epoch:24 step:19173 [D loss: 0.296709, acc: 89.84%] [G loss: 5.517386]\n",
      "epoch:24 step:19174 [D loss: 0.424921, acc: 87.50%] [G loss: 2.600378]\n",
      "epoch:24 step:19175 [D loss: 0.310450, acc: 89.84%] [G loss: 2.774512]\n",
      "epoch:24 step:19176 [D loss: 0.461056, acc: 75.78%] [G loss: 2.722053]\n",
      "epoch:24 step:19177 [D loss: 0.286591, acc: 96.88%] [G loss: 2.838857]\n",
      "epoch:24 step:19178 [D loss: 0.236989, acc: 91.41%] [G loss: 6.371428]\n",
      "epoch:24 step:19179 [D loss: 0.506211, acc: 76.56%] [G loss: 4.980599]\n",
      "epoch:24 step:19180 [D loss: 0.565070, acc: 65.62%] [G loss: 4.087675]\n",
      "epoch:24 step:19181 [D loss: 0.534697, acc: 74.22%] [G loss: 3.480942]\n",
      "epoch:24 step:19182 [D loss: 0.678341, acc: 53.12%] [G loss: 1.919701]\n",
      "epoch:24 step:19183 [D loss: 0.757605, acc: 51.56%] [G loss: 1.951110]\n",
      "epoch:24 step:19184 [D loss: 0.387883, acc: 88.28%] [G loss: 4.639911]\n",
      "epoch:24 step:19185 [D loss: 0.325855, acc: 96.09%] [G loss: 1.708918]\n",
      "epoch:24 step:19186 [D loss: 0.568925, acc: 67.97%] [G loss: 3.874413]\n",
      "epoch:24 step:19187 [D loss: 0.227062, acc: 96.88%] [G loss: 4.198046]\n",
      "epoch:24 step:19188 [D loss: 0.252320, acc: 97.66%] [G loss: 2.556685]\n",
      "epoch:24 step:19189 [D loss: 0.433862, acc: 85.94%] [G loss: 2.799238]\n",
      "epoch:24 step:19190 [D loss: 0.428715, acc: 88.28%] [G loss: 2.777096]\n",
      "epoch:24 step:19191 [D loss: 0.234553, acc: 97.66%] [G loss: 3.795560]\n",
      "epoch:24 step:19192 [D loss: 0.302379, acc: 96.09%] [G loss: 1.597788]\n",
      "epoch:24 step:19193 [D loss: 0.405773, acc: 75.00%] [G loss: 3.882080]\n",
      "epoch:24 step:19194 [D loss: 0.905386, acc: 49.22%] [G loss: 3.868049]\n",
      "epoch:24 step:19195 [D loss: 0.545834, acc: 77.34%] [G loss: 3.219739]\n",
      "epoch:24 step:19196 [D loss: 0.310267, acc: 85.16%] [G loss: 3.942485]\n",
      "epoch:24 step:19197 [D loss: 0.397694, acc: 87.50%] [G loss: 3.342651]\n",
      "epoch:24 step:19198 [D loss: 0.427168, acc: 75.00%] [G loss: 5.256612]\n",
      "epoch:24 step:19199 [D loss: 0.423843, acc: 82.81%] [G loss: 4.429270]\n",
      "epoch:24 step:19200 [D loss: 0.386785, acc: 89.06%] [G loss: 3.997160]\n",
      "##############\n",
      "[0.85294853 0.84536163 0.82681607 0.80701748 0.8163756  0.83150174\n",
      " 0.88965275 0.83692957 0.79528074 0.83051034]\n",
      "##########\n",
      "epoch:24 step:19201 [D loss: 1.099545, acc: 50.00%] [G loss: 2.834884]\n",
      "epoch:24 step:19202 [D loss: 0.461070, acc: 67.19%] [G loss: 3.640553]\n",
      "epoch:24 step:19203 [D loss: 0.675156, acc: 56.25%] [G loss: 2.998888]\n",
      "epoch:24 step:19204 [D loss: 0.507648, acc: 75.78%] [G loss: 3.500807]\n",
      "epoch:24 step:19205 [D loss: 0.274072, acc: 97.66%] [G loss: 4.691864]\n",
      "epoch:24 step:19206 [D loss: 0.377395, acc: 83.59%] [G loss: 5.542309]\n",
      "epoch:24 step:19207 [D loss: 0.724624, acc: 58.59%] [G loss: 4.417953]\n",
      "epoch:24 step:19208 [D loss: 0.676318, acc: 59.38%] [G loss: 2.628842]\n",
      "epoch:24 step:19209 [D loss: 0.253712, acc: 96.88%] [G loss: 3.546772]\n",
      "epoch:24 step:19210 [D loss: 0.130431, acc: 99.22%] [G loss: 4.126842]\n",
      "epoch:24 step:19211 [D loss: 0.437636, acc: 73.44%] [G loss: 4.685689]\n",
      "epoch:24 step:19212 [D loss: 0.423106, acc: 82.81%] [G loss: 4.476131]\n",
      "epoch:24 step:19213 [D loss: 0.248428, acc: 100.00%] [G loss: 3.893234]\n",
      "epoch:24 step:19214 [D loss: 0.081685, acc: 100.00%] [G loss: 4.285430]\n",
      "epoch:24 step:19215 [D loss: 0.442252, acc: 82.03%] [G loss: 2.530026]\n",
      "epoch:24 step:19216 [D loss: 0.255377, acc: 95.31%] [G loss: 3.286988]\n",
      "epoch:24 step:19217 [D loss: 0.499590, acc: 67.19%] [G loss: 3.184223]\n",
      "epoch:24 step:19218 [D loss: 0.290056, acc: 88.28%] [G loss: 3.391726]\n",
      "epoch:24 step:19219 [D loss: 0.676644, acc: 57.81%] [G loss: 3.265040]\n",
      "epoch:24 step:19220 [D loss: 0.453166, acc: 71.88%] [G loss: 2.641039]\n",
      "epoch:24 step:19221 [D loss: 0.377909, acc: 92.97%] [G loss: 4.920282]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:24 step:19222 [D loss: 0.160801, acc: 100.00%] [G loss: 4.518106]\n",
      "epoch:24 step:19223 [D loss: 0.447988, acc: 75.00%] [G loss: 2.821589]\n",
      "epoch:24 step:19224 [D loss: 0.929628, acc: 29.69%] [G loss: 3.197104]\n",
      "epoch:24 step:19225 [D loss: 1.207247, acc: 26.56%] [G loss: 2.335900]\n",
      "epoch:24 step:19226 [D loss: 1.473400, acc: 31.25%] [G loss: 2.725130]\n",
      "epoch:24 step:19227 [D loss: 0.277178, acc: 94.53%] [G loss: 3.874359]\n",
      "epoch:24 step:19228 [D loss: 1.269724, acc: 35.16%] [G loss: 3.812155]\n",
      "epoch:24 step:19229 [D loss: 0.167302, acc: 97.66%] [G loss: 3.105387]\n",
      "epoch:24 step:19230 [D loss: 0.428752, acc: 73.44%] [G loss: 3.251469]\n",
      "epoch:24 step:19231 [D loss: 0.297804, acc: 92.97%] [G loss: 5.646678]\n",
      "epoch:24 step:19232 [D loss: 0.665825, acc: 57.03%] [G loss: 3.141859]\n",
      "epoch:24 step:19233 [D loss: 0.146732, acc: 100.00%] [G loss: 3.716827]\n",
      "epoch:24 step:19234 [D loss: 0.210588, acc: 95.31%] [G loss: 3.820297]\n",
      "epoch:24 step:19235 [D loss: 1.222523, acc: 13.28%] [G loss: 2.967765]\n",
      "epoch:24 step:19236 [D loss: 0.347541, acc: 94.53%] [G loss: 4.243785]\n",
      "epoch:24 step:19237 [D loss: 0.560775, acc: 65.62%] [G loss: 5.212748]\n",
      "epoch:24 step:19238 [D loss: 0.634982, acc: 61.72%] [G loss: 4.075950]\n",
      "epoch:24 step:19239 [D loss: 0.354332, acc: 84.38%] [G loss: 4.933729]\n",
      "epoch:24 step:19240 [D loss: 0.634996, acc: 60.94%] [G loss: 3.079561]\n",
      "epoch:24 step:19241 [D loss: 0.044739, acc: 100.00%] [G loss: 5.806731]\n",
      "epoch:24 step:19242 [D loss: 1.058193, acc: 50.00%] [G loss: 4.471148]\n",
      "epoch:24 step:19243 [D loss: 0.738131, acc: 50.00%] [G loss: 3.725588]\n",
      "epoch:24 step:19244 [D loss: 0.237491, acc: 93.75%] [G loss: 3.352311]\n",
      "epoch:24 step:19245 [D loss: 0.579029, acc: 62.50%] [G loss: 4.680789]\n",
      "epoch:24 step:19246 [D loss: 0.343385, acc: 85.94%] [G loss: 3.217297]\n",
      "epoch:24 step:19247 [D loss: 0.808436, acc: 44.53%] [G loss: 3.971772]\n",
      "epoch:24 step:19248 [D loss: 0.720055, acc: 51.56%] [G loss: 3.294761]\n",
      "epoch:24 step:19249 [D loss: 0.457369, acc: 86.72%] [G loss: 3.579565]\n",
      "epoch:24 step:19250 [D loss: 0.847997, acc: 50.78%] [G loss: 4.223579]\n",
      "epoch:24 step:19251 [D loss: 0.714261, acc: 54.69%] [G loss: 2.713538]\n",
      "epoch:24 step:19252 [D loss: 0.224992, acc: 99.22%] [G loss: 1.953533]\n",
      "epoch:24 step:19253 [D loss: 0.215270, acc: 98.44%] [G loss: 4.919828]\n",
      "epoch:24 step:19254 [D loss: 0.222155, acc: 97.66%] [G loss: 4.248538]\n",
      "epoch:24 step:19255 [D loss: 0.044608, acc: 100.00%] [G loss: 5.368365]\n",
      "epoch:24 step:19256 [D loss: 0.635505, acc: 58.59%] [G loss: 3.777122]\n",
      "epoch:24 step:19257 [D loss: 1.140827, acc: 24.22%] [G loss: 3.830493]\n",
      "epoch:24 step:19258 [D loss: 0.362045, acc: 91.41%] [G loss: 3.859696]\n",
      "epoch:24 step:19259 [D loss: 0.134534, acc: 98.44%] [G loss: 4.092959]\n",
      "epoch:24 step:19260 [D loss: 0.565766, acc: 60.94%] [G loss: 4.228247]\n",
      "epoch:24 step:19261 [D loss: 0.076143, acc: 100.00%] [G loss: 7.134165]\n",
      "epoch:24 step:19262 [D loss: 0.728772, acc: 55.47%] [G loss: 3.578324]\n",
      "epoch:24 step:19263 [D loss: 0.169863, acc: 97.66%] [G loss: 4.183342]\n",
      "epoch:24 step:19264 [D loss: 0.478339, acc: 82.81%] [G loss: 5.007509]\n",
      "epoch:24 step:19265 [D loss: 1.293989, acc: 14.06%] [G loss: 4.903466]\n",
      "epoch:24 step:19266 [D loss: 0.316005, acc: 90.62%] [G loss: 3.104387]\n",
      "epoch:24 step:19267 [D loss: 0.187827, acc: 98.44%] [G loss: 4.046280]\n",
      "epoch:24 step:19268 [D loss: 0.187379, acc: 100.00%] [G loss: 2.861285]\n",
      "epoch:24 step:19269 [D loss: 0.309209, acc: 93.75%] [G loss: 2.138679]\n",
      "epoch:24 step:19270 [D loss: 0.414509, acc: 89.84%] [G loss: 2.721880]\n",
      "epoch:24 step:19271 [D loss: 0.320955, acc: 86.72%] [G loss: 2.846633]\n",
      "epoch:24 step:19272 [D loss: 0.214561, acc: 96.88%] [G loss: 4.064957]\n",
      "epoch:24 step:19273 [D loss: 0.402724, acc: 88.28%] [G loss: 4.883642]\n",
      "epoch:24 step:19274 [D loss: 0.426000, acc: 78.91%] [G loss: 6.023409]\n",
      "epoch:24 step:19275 [D loss: 0.532722, acc: 62.50%] [G loss: 3.265450]\n",
      "epoch:24 step:19276 [D loss: 1.125766, acc: 27.34%] [G loss: 3.386241]\n",
      "epoch:24 step:19277 [D loss: 0.381019, acc: 91.41%] [G loss: 3.579695]\n",
      "epoch:24 step:19278 [D loss: 0.855570, acc: 40.62%] [G loss: 3.446137]\n",
      "epoch:24 step:19279 [D loss: 1.108766, acc: 31.25%] [G loss: 2.382661]\n",
      "epoch:24 step:19280 [D loss: 0.063070, acc: 100.00%] [G loss: 5.106309]\n",
      "epoch:24 step:19281 [D loss: 0.331255, acc: 90.62%] [G loss: 3.705592]\n",
      "epoch:24 step:19282 [D loss: 0.098652, acc: 100.00%] [G loss: 3.346293]\n",
      "epoch:24 step:19283 [D loss: 0.265577, acc: 99.22%] [G loss: 4.089262]\n",
      "epoch:24 step:19284 [D loss: 0.524825, acc: 67.97%] [G loss: 3.074918]\n",
      "epoch:24 step:19285 [D loss: 0.966052, acc: 34.38%] [G loss: 3.308594]\n",
      "epoch:24 step:19286 [D loss: 0.228036, acc: 93.75%] [G loss: 3.163095]\n",
      "epoch:24 step:19287 [D loss: 0.697888, acc: 60.94%] [G loss: 4.226034]\n",
      "epoch:24 step:19288 [D loss: 0.536100, acc: 78.12%] [G loss: 2.780860]\n",
      "epoch:24 step:19289 [D loss: 0.133917, acc: 100.00%] [G loss: 2.709233]\n",
      "epoch:24 step:19290 [D loss: 0.712322, acc: 56.25%] [G loss: 4.136341]\n",
      "epoch:24 step:19291 [D loss: 0.654946, acc: 61.72%] [G loss: 3.359420]\n",
      "epoch:24 step:19292 [D loss: 1.040349, acc: 26.56%] [G loss: 3.609374]\n",
      "epoch:24 step:19293 [D loss: 0.673619, acc: 61.72%] [G loss: 4.825386]\n",
      "epoch:24 step:19294 [D loss: 0.251242, acc: 94.53%] [G loss: 4.714505]\n",
      "epoch:24 step:19295 [D loss: 0.121816, acc: 100.00%] [G loss: 4.993487]\n",
      "epoch:24 step:19296 [D loss: 0.715791, acc: 57.81%] [G loss: 2.147085]\n",
      "epoch:24 step:19297 [D loss: 0.217848, acc: 97.66%] [G loss: 2.430621]\n",
      "epoch:24 step:19298 [D loss: 0.707162, acc: 53.91%] [G loss: 3.100334]\n",
      "epoch:24 step:19299 [D loss: 0.173213, acc: 97.66%] [G loss: 6.300154]\n",
      "epoch:24 step:19300 [D loss: 0.397110, acc: 77.34%] [G loss: 4.443158]\n",
      "epoch:24 step:19301 [D loss: 0.473820, acc: 84.38%] [G loss: 4.016136]\n",
      "epoch:24 step:19302 [D loss: 0.430416, acc: 88.28%] [G loss: 5.382897]\n",
      "epoch:24 step:19303 [D loss: 0.208690, acc: 96.88%] [G loss: 4.441389]\n",
      "epoch:24 step:19304 [D loss: 0.232031, acc: 96.88%] [G loss: 5.552544]\n",
      "epoch:24 step:19305 [D loss: 1.256823, acc: 40.62%] [G loss: 3.785529]\n",
      "epoch:24 step:19306 [D loss: 0.524964, acc: 75.78%] [G loss: 2.854198]\n",
      "epoch:24 step:19307 [D loss: 0.249555, acc: 96.09%] [G loss: 4.817298]\n",
      "epoch:24 step:19308 [D loss: 0.297299, acc: 95.31%] [G loss: 4.664365]\n",
      "epoch:24 step:19309 [D loss: 0.560089, acc: 65.62%] [G loss: 3.200532]\n",
      "epoch:24 step:19310 [D loss: 0.314861, acc: 91.41%] [G loss: 4.072606]\n",
      "epoch:24 step:19311 [D loss: 2.032390, acc: 10.16%] [G loss: 1.640149]\n",
      "epoch:24 step:19312 [D loss: 0.573628, acc: 54.69%] [G loss: 4.737342]\n",
      "epoch:24 step:19313 [D loss: 0.172103, acc: 99.22%] [G loss: 3.568040]\n",
      "epoch:24 step:19314 [D loss: 0.842240, acc: 35.16%] [G loss: 4.686046]\n",
      "epoch:24 step:19315 [D loss: 0.466745, acc: 76.56%] [G loss: 2.959701]\n",
      "epoch:24 step:19316 [D loss: 0.748872, acc: 52.34%] [G loss: 3.844095]\n",
      "epoch:24 step:19317 [D loss: 0.361670, acc: 78.91%] [G loss: 4.012609]\n",
      "epoch:24 step:19318 [D loss: 0.267379, acc: 94.53%] [G loss: 2.731491]\n",
      "epoch:24 step:19319 [D loss: 0.644210, acc: 59.38%] [G loss: 3.000402]\n",
      "epoch:24 step:19320 [D loss: 0.566764, acc: 72.66%] [G loss: 3.003121]\n",
      "epoch:24 step:19321 [D loss: 0.753864, acc: 51.56%] [G loss: 2.976806]\n",
      "epoch:24 step:19322 [D loss: 0.177774, acc: 97.66%] [G loss: 3.207347]\n",
      "epoch:24 step:19323 [D loss: 0.193609, acc: 98.44%] [G loss: 4.794138]\n",
      "epoch:24 step:19324 [D loss: 0.317963, acc: 89.06%] [G loss: 4.004741]\n",
      "epoch:24 step:19325 [D loss: 0.142813, acc: 96.88%] [G loss: 5.306872]\n",
      "epoch:24 step:19326 [D loss: 0.172020, acc: 99.22%] [G loss: 3.614601]\n",
      "epoch:24 step:19327 [D loss: 0.346167, acc: 87.50%] [G loss: 3.151766]\n",
      "epoch:24 step:19328 [D loss: 0.361847, acc: 78.91%] [G loss: 3.866340]\n",
      "epoch:24 step:19329 [D loss: 0.649724, acc: 58.59%] [G loss: 3.321710]\n",
      "epoch:24 step:19330 [D loss: 0.285243, acc: 95.31%] [G loss: 2.009839]\n",
      "epoch:24 step:19331 [D loss: 0.340915, acc: 81.25%] [G loss: 4.980128]\n",
      "epoch:24 step:19332 [D loss: 0.581398, acc: 64.84%] [G loss: 4.133447]\n",
      "epoch:24 step:19333 [D loss: 0.375977, acc: 90.62%] [G loss: 5.751054]\n",
      "epoch:24 step:19334 [D loss: 0.250433, acc: 96.09%] [G loss: 3.752704]\n",
      "epoch:24 step:19335 [D loss: 0.546540, acc: 61.72%] [G loss: 2.617252]\n",
      "epoch:24 step:19336 [D loss: 0.140542, acc: 100.00%] [G loss: 3.554606]\n",
      "epoch:24 step:19337 [D loss: 1.029032, acc: 50.00%] [G loss: 3.082944]\n",
      "epoch:24 step:19338 [D loss: 0.407780, acc: 78.91%] [G loss: 2.398675]\n",
      "epoch:24 step:19339 [D loss: 0.647133, acc: 60.16%] [G loss: 5.198414]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:24 step:19340 [D loss: 0.860525, acc: 47.66%] [G loss: 3.197809]\n",
      "epoch:24 step:19341 [D loss: 0.678958, acc: 57.03%] [G loss: 2.789877]\n",
      "epoch:24 step:19342 [D loss: 0.126325, acc: 100.00%] [G loss: 4.780759]\n",
      "epoch:24 step:19343 [D loss: 0.420946, acc: 85.16%] [G loss: 4.765185]\n",
      "epoch:24 step:19344 [D loss: 0.115572, acc: 100.00%] [G loss: 4.666121]\n",
      "epoch:24 step:19345 [D loss: 0.414051, acc: 85.94%] [G loss: 3.625271]\n",
      "epoch:24 step:19346 [D loss: 0.891403, acc: 50.78%] [G loss: 3.515904]\n",
      "epoch:24 step:19347 [D loss: 0.260961, acc: 92.19%] [G loss: 5.112279]\n",
      "epoch:24 step:19348 [D loss: 0.359035, acc: 92.19%] [G loss: 2.956953]\n",
      "epoch:24 step:19349 [D loss: 0.365090, acc: 92.97%] [G loss: 4.624788]\n",
      "epoch:24 step:19350 [D loss: 0.381340, acc: 89.84%] [G loss: 3.253979]\n",
      "epoch:24 step:19351 [D loss: 0.550864, acc: 68.75%] [G loss: 2.873245]\n",
      "epoch:24 step:19352 [D loss: 0.436254, acc: 78.12%] [G loss: 4.023330]\n",
      "epoch:24 step:19353 [D loss: 0.922775, acc: 50.78%] [G loss: 6.466132]\n",
      "epoch:24 step:19354 [D loss: 0.326937, acc: 92.19%] [G loss: 3.077820]\n",
      "epoch:24 step:19355 [D loss: 0.239430, acc: 100.00%] [G loss: 3.283558]\n",
      "epoch:24 step:19356 [D loss: 0.158120, acc: 97.66%] [G loss: 4.680040]\n",
      "epoch:24 step:19357 [D loss: 0.476389, acc: 82.81%] [G loss: 3.410268]\n",
      "epoch:24 step:19358 [D loss: 0.221034, acc: 98.44%] [G loss: 4.191269]\n",
      "epoch:24 step:19359 [D loss: 0.391320, acc: 91.41%] [G loss: 3.194542]\n",
      "epoch:24 step:19360 [D loss: 0.962985, acc: 25.78%] [G loss: 3.721262]\n",
      "epoch:24 step:19361 [D loss: 0.367111, acc: 85.94%] [G loss: 3.750785]\n",
      "epoch:24 step:19362 [D loss: 0.139414, acc: 100.00%] [G loss: 2.444349]\n",
      "epoch:24 step:19363 [D loss: 0.570971, acc: 71.09%] [G loss: 2.809998]\n",
      "epoch:24 step:19364 [D loss: 0.437372, acc: 82.03%] [G loss: 3.667398]\n",
      "epoch:24 step:19365 [D loss: 0.725825, acc: 51.56%] [G loss: 4.053039]\n",
      "epoch:24 step:19366 [D loss: 0.213735, acc: 94.53%] [G loss: 4.871099]\n",
      "epoch:24 step:19367 [D loss: 0.425254, acc: 87.50%] [G loss: 4.192415]\n",
      "epoch:24 step:19368 [D loss: 0.204554, acc: 99.22%] [G loss: 5.168535]\n",
      "epoch:24 step:19369 [D loss: 0.545127, acc: 71.88%] [G loss: 5.026496]\n",
      "epoch:24 step:19370 [D loss: 0.557531, acc: 73.44%] [G loss: 2.958076]\n",
      "epoch:24 step:19371 [D loss: 0.639849, acc: 70.31%] [G loss: 3.420399]\n",
      "epoch:24 step:19372 [D loss: 0.096933, acc: 100.00%] [G loss: 3.838699]\n",
      "epoch:24 step:19373 [D loss: 0.676582, acc: 60.16%] [G loss: 3.226810]\n",
      "epoch:24 step:19374 [D loss: 0.750580, acc: 51.56%] [G loss: 3.217566]\n",
      "epoch:24 step:19375 [D loss: 0.516521, acc: 75.78%] [G loss: 2.990029]\n",
      "epoch:24 step:19376 [D loss: 0.359832, acc: 91.41%] [G loss: 2.547161]\n",
      "epoch:24 step:19377 [D loss: 0.722651, acc: 57.03%] [G loss: 2.431795]\n",
      "epoch:24 step:19378 [D loss: 0.546007, acc: 77.34%] [G loss: 3.225618]\n",
      "epoch:24 step:19379 [D loss: 0.327855, acc: 86.72%] [G loss: 3.446007]\n",
      "epoch:24 step:19380 [D loss: 0.308999, acc: 94.53%] [G loss: 1.851948]\n",
      "epoch:24 step:19381 [D loss: 0.527312, acc: 71.09%] [G loss: 2.035106]\n",
      "epoch:24 step:19382 [D loss: 0.657859, acc: 60.16%] [G loss: 3.523498]\n",
      "epoch:24 step:19383 [D loss: 0.672361, acc: 64.06%] [G loss: 4.136309]\n",
      "epoch:24 step:19384 [D loss: 0.334216, acc: 87.50%] [G loss: 5.147619]\n",
      "epoch:24 step:19385 [D loss: 0.729048, acc: 55.47%] [G loss: 3.441457]\n",
      "epoch:24 step:19386 [D loss: 0.711394, acc: 58.59%] [G loss: 4.552750]\n",
      "epoch:24 step:19387 [D loss: 0.549612, acc: 78.12%] [G loss: 3.994559]\n",
      "epoch:24 step:19388 [D loss: 0.147203, acc: 100.00%] [G loss: 3.776323]\n",
      "epoch:24 step:19389 [D loss: 0.666349, acc: 57.81%] [G loss: 2.142249]\n",
      "epoch:24 step:19390 [D loss: 0.795353, acc: 43.75%] [G loss: 2.157367]\n",
      "epoch:24 step:19391 [D loss: 0.382587, acc: 74.22%] [G loss: 6.750432]\n",
      "epoch:24 step:19392 [D loss: 0.354344, acc: 92.97%] [G loss: 2.019802]\n",
      "epoch:24 step:19393 [D loss: 0.182825, acc: 100.00%] [G loss: 2.743698]\n",
      "epoch:24 step:19394 [D loss: 0.478214, acc: 76.56%] [G loss: 3.532489]\n",
      "epoch:24 step:19395 [D loss: 0.167271, acc: 99.22%] [G loss: 4.382601]\n",
      "epoch:24 step:19396 [D loss: 0.251189, acc: 96.09%] [G loss: 4.333320]\n",
      "epoch:24 step:19397 [D loss: 0.071325, acc: 100.00%] [G loss: 5.902800]\n",
      "epoch:24 step:19398 [D loss: 0.266205, acc: 97.66%] [G loss: 3.296813]\n",
      "epoch:24 step:19399 [D loss: 0.522296, acc: 77.34%] [G loss: 4.366008]\n",
      "epoch:24 step:19400 [D loss: 0.425017, acc: 84.38%] [G loss: 2.873518]\n",
      "##############\n",
      "[0.8467965  0.85800205 0.8078035  0.80986044 0.79505203 0.83163658\n",
      " 0.89983818 0.84016196 0.79442844 0.85098277]\n",
      "##########\n",
      "epoch:24 step:19401 [D loss: 0.331276, acc: 93.75%] [G loss: 3.460411]\n",
      "epoch:24 step:19402 [D loss: 0.628022, acc: 59.38%] [G loss: 4.444861]\n",
      "epoch:24 step:19403 [D loss: 0.208973, acc: 99.22%] [G loss: 5.598598]\n",
      "epoch:24 step:19404 [D loss: 0.587749, acc: 59.38%] [G loss: 3.524238]\n",
      "epoch:24 step:19405 [D loss: 0.073742, acc: 100.00%] [G loss: 3.341585]\n",
      "epoch:24 step:19406 [D loss: 0.299689, acc: 90.62%] [G loss: 3.124619]\n",
      "epoch:24 step:19407 [D loss: 0.527570, acc: 79.69%] [G loss: 4.581197]\n",
      "epoch:24 step:19408 [D loss: 0.373120, acc: 75.78%] [G loss: 4.165201]\n",
      "epoch:24 step:19409 [D loss: 0.626636, acc: 60.16%] [G loss: 4.009338]\n",
      "epoch:24 step:19410 [D loss: 0.467096, acc: 75.78%] [G loss: 3.412141]\n",
      "epoch:24 step:19411 [D loss: 0.127384, acc: 97.66%] [G loss: 4.022465]\n",
      "epoch:24 step:19412 [D loss: 0.683397, acc: 57.03%] [G loss: 3.839072]\n",
      "epoch:24 step:19413 [D loss: 1.066462, acc: 23.44%] [G loss: 5.354405]\n",
      "epoch:24 step:19414 [D loss: 0.774417, acc: 52.34%] [G loss: 2.032910]\n",
      "epoch:24 step:19415 [D loss: 0.563602, acc: 67.97%] [G loss: 4.267735]\n",
      "epoch:24 step:19416 [D loss: 0.318543, acc: 96.09%] [G loss: 2.682464]\n",
      "epoch:24 step:19417 [D loss: 0.221544, acc: 100.00%] [G loss: 3.544545]\n",
      "epoch:24 step:19418 [D loss: 0.242457, acc: 95.31%] [G loss: 4.577924]\n",
      "epoch:24 step:19419 [D loss: 0.477285, acc: 67.19%] [G loss: 5.829052]\n",
      "epoch:24 step:19420 [D loss: 0.574946, acc: 65.62%] [G loss: 2.748058]\n",
      "epoch:24 step:19421 [D loss: 0.437103, acc: 82.03%] [G loss: 5.189336]\n",
      "epoch:24 step:19422 [D loss: 0.184635, acc: 100.00%] [G loss: 2.660430]\n",
      "epoch:24 step:19423 [D loss: 0.429162, acc: 88.28%] [G loss: 3.409250]\n",
      "epoch:24 step:19424 [D loss: 0.232987, acc: 98.44%] [G loss: 3.327764]\n",
      "epoch:24 step:19425 [D loss: 0.216551, acc: 100.00%] [G loss: 3.043029]\n",
      "epoch:24 step:19426 [D loss: 0.363263, acc: 91.41%] [G loss: 3.797506]\n",
      "epoch:24 step:19427 [D loss: 0.242603, acc: 98.44%] [G loss: 3.623356]\n",
      "epoch:24 step:19428 [D loss: 0.643569, acc: 57.03%] [G loss: 4.190439]\n",
      "epoch:24 step:19429 [D loss: 0.549706, acc: 71.88%] [G loss: 4.006413]\n",
      "epoch:24 step:19430 [D loss: 1.093257, acc: 50.00%] [G loss: 2.672969]\n",
      "epoch:24 step:19431 [D loss: 0.594133, acc: 60.94%] [G loss: 5.235079]\n",
      "epoch:24 step:19432 [D loss: 0.601238, acc: 67.19%] [G loss: 4.000253]\n",
      "epoch:24 step:19433 [D loss: 0.717938, acc: 53.12%] [G loss: 3.484512]\n",
      "epoch:24 step:19434 [D loss: 0.540006, acc: 61.72%] [G loss: 5.192609]\n",
      "epoch:24 step:19435 [D loss: 0.123982, acc: 100.00%] [G loss: 3.970978]\n",
      "epoch:24 step:19436 [D loss: 1.150558, acc: 46.09%] [G loss: 5.609148]\n",
      "epoch:24 step:19437 [D loss: 0.604945, acc: 67.19%] [G loss: 2.867271]\n",
      "epoch:24 step:19438 [D loss: 0.061583, acc: 100.00%] [G loss: 5.492482]\n",
      "epoch:24 step:19439 [D loss: 0.289982, acc: 95.31%] [G loss: 3.425017]\n",
      "epoch:24 step:19440 [D loss: 0.514732, acc: 75.78%] [G loss: 3.574049]\n",
      "epoch:24 step:19441 [D loss: 0.762492, acc: 52.34%] [G loss: 3.258576]\n",
      "epoch:24 step:19442 [D loss: 0.180819, acc: 96.88%] [G loss: 4.536632]\n",
      "epoch:24 step:19443 [D loss: 0.803854, acc: 41.41%] [G loss: 3.658905]\n",
      "epoch:24 step:19444 [D loss: 0.854844, acc: 46.09%] [G loss: 3.763747]\n",
      "epoch:24 step:19445 [D loss: 0.584914, acc: 70.31%] [G loss: 4.351697]\n",
      "epoch:24 step:19446 [D loss: 1.060225, acc: 27.34%] [G loss: 3.845480]\n",
      "epoch:24 step:19447 [D loss: 0.728370, acc: 57.03%] [G loss: 3.639669]\n",
      "epoch:24 step:19448 [D loss: 0.943232, acc: 26.56%] [G loss: 4.400953]\n",
      "epoch:24 step:19449 [D loss: 0.541544, acc: 71.09%] [G loss: 3.872622]\n",
      "epoch:24 step:19450 [D loss: 1.063448, acc: 50.00%] [G loss: 3.523343]\n",
      "epoch:24 step:19451 [D loss: 0.435953, acc: 82.81%] [G loss: 3.266693]\n",
      "epoch:24 step:19452 [D loss: 0.857956, acc: 50.78%] [G loss: 3.252653]\n",
      "epoch:24 step:19453 [D loss: 0.127393, acc: 100.00%] [G loss: 2.760150]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:24 step:19454 [D loss: 0.592094, acc: 62.50%] [G loss: 3.770650]\n",
      "epoch:24 step:19455 [D loss: 0.306347, acc: 84.38%] [G loss: 6.238504]\n",
      "epoch:24 step:19456 [D loss: 0.387698, acc: 75.00%] [G loss: 3.255737]\n",
      "epoch:24 step:19457 [D loss: 0.256429, acc: 92.19%] [G loss: 4.955679]\n",
      "epoch:24 step:19458 [D loss: 0.308253, acc: 95.31%] [G loss: 3.711509]\n",
      "epoch:24 step:19459 [D loss: 0.509440, acc: 79.69%] [G loss: 5.033617]\n",
      "epoch:24 step:19460 [D loss: 0.235607, acc: 99.22%] [G loss: 3.529891]\n",
      "epoch:24 step:19461 [D loss: 0.188573, acc: 100.00%] [G loss: 4.471743]\n",
      "epoch:24 step:19462 [D loss: 0.374923, acc: 90.62%] [G loss: 3.486166]\n",
      "epoch:24 step:19463 [D loss: 0.483063, acc: 79.69%] [G loss: 2.739907]\n",
      "epoch:24 step:19464 [D loss: 0.291913, acc: 92.97%] [G loss: 2.899021]\n",
      "epoch:24 step:19465 [D loss: 0.218147, acc: 99.22%] [G loss: 4.027265]\n",
      "epoch:24 step:19466 [D loss: 0.491558, acc: 81.25%] [G loss: 4.719362]\n",
      "epoch:24 step:19467 [D loss: 0.146890, acc: 99.22%] [G loss: 4.653521]\n",
      "epoch:24 step:19468 [D loss: 0.589790, acc: 67.97%] [G loss: 4.208432]\n",
      "epoch:24 step:19469 [D loss: 0.887135, acc: 35.16%] [G loss: 2.618788]\n",
      "epoch:24 step:19470 [D loss: 0.048505, acc: 100.00%] [G loss: 7.543839]\n",
      "epoch:24 step:19471 [D loss: 0.550563, acc: 67.19%] [G loss: 2.046066]\n",
      "epoch:24 step:19472 [D loss: 0.382080, acc: 83.59%] [G loss: 4.692883]\n",
      "epoch:24 step:19473 [D loss: 0.444875, acc: 82.81%] [G loss: 3.380948]\n",
      "epoch:24 step:19474 [D loss: 0.402999, acc: 92.19%] [G loss: 3.925025]\n",
      "epoch:24 step:19475 [D loss: 0.696781, acc: 58.59%] [G loss: 4.285733]\n",
      "epoch:24 step:19476 [D loss: 0.749641, acc: 50.00%] [G loss: 2.396501]\n",
      "epoch:24 step:19477 [D loss: 0.549478, acc: 75.78%] [G loss: 3.605325]\n",
      "epoch:24 step:19478 [D loss: 0.888675, acc: 50.78%] [G loss: 3.951352]\n",
      "epoch:24 step:19479 [D loss: 0.837856, acc: 51.56%] [G loss: 6.376229]\n",
      "epoch:24 step:19480 [D loss: 0.226399, acc: 96.88%] [G loss: 3.872175]\n",
      "epoch:24 step:19481 [D loss: 0.239978, acc: 96.09%] [G loss: 2.608869]\n",
      "epoch:24 step:19482 [D loss: 0.797788, acc: 54.69%] [G loss: 3.199748]\n",
      "epoch:24 step:19483 [D loss: 1.028352, acc: 48.44%] [G loss: 3.968048]\n",
      "epoch:24 step:19484 [D loss: 0.223479, acc: 97.66%] [G loss: 4.218941]\n",
      "epoch:24 step:19485 [D loss: 0.323625, acc: 86.72%] [G loss: 2.580627]\n",
      "epoch:24 step:19486 [D loss: 0.926845, acc: 50.00%] [G loss: 2.483507]\n",
      "epoch:24 step:19487 [D loss: 0.153852, acc: 100.00%] [G loss: 3.339391]\n",
      "epoch:24 step:19488 [D loss: 0.452026, acc: 87.50%] [G loss: 3.566870]\n",
      "epoch:24 step:19489 [D loss: 0.400235, acc: 76.56%] [G loss: 3.779177]\n",
      "epoch:24 step:19490 [D loss: 0.729894, acc: 46.88%] [G loss: 3.249614]\n",
      "epoch:24 step:19491 [D loss: 0.498003, acc: 66.41%] [G loss: 4.062904]\n",
      "epoch:24 step:19492 [D loss: 0.420752, acc: 78.12%] [G loss: 2.990551]\n",
      "epoch:24 step:19493 [D loss: 0.432429, acc: 82.03%] [G loss: 4.912931]\n",
      "epoch:24 step:19494 [D loss: 0.372366, acc: 85.94%] [G loss: 2.368295]\n",
      "epoch:24 step:19495 [D loss: 0.940854, acc: 34.38%] [G loss: 4.078661]\n",
      "epoch:24 step:19496 [D loss: 0.424032, acc: 88.28%] [G loss: 4.857475]\n",
      "epoch:24 step:19497 [D loss: 0.491780, acc: 75.78%] [G loss: 3.774426]\n",
      "epoch:24 step:19498 [D loss: 0.748439, acc: 57.03%] [G loss: 5.188949]\n",
      "epoch:24 step:19499 [D loss: 0.903511, acc: 35.16%] [G loss: 5.182794]\n",
      "epoch:24 step:19500 [D loss: 0.307745, acc: 89.06%] [G loss: 2.412975]\n",
      "epoch:24 step:19501 [D loss: 0.529364, acc: 64.84%] [G loss: 3.432259]\n",
      "epoch:24 step:19502 [D loss: 0.485761, acc: 79.69%] [G loss: 3.278894]\n",
      "epoch:24 step:19503 [D loss: 0.414562, acc: 87.50%] [G loss: 2.447906]\n",
      "epoch:24 step:19504 [D loss: 0.202581, acc: 96.09%] [G loss: 4.587798]\n",
      "epoch:24 step:19505 [D loss: 0.488524, acc: 80.47%] [G loss: 3.763669]\n",
      "epoch:24 step:19506 [D loss: 0.418838, acc: 81.25%] [G loss: 3.839090]\n",
      "epoch:24 step:19507 [D loss: 0.710783, acc: 55.47%] [G loss: 3.797303]\n",
      "epoch:24 step:19508 [D loss: 0.740943, acc: 53.12%] [G loss: 4.265856]\n",
      "epoch:24 step:19509 [D loss: 0.669060, acc: 63.28%] [G loss: 4.372601]\n",
      "epoch:24 step:19510 [D loss: 0.563704, acc: 58.59%] [G loss: 4.764226]\n",
      "epoch:24 step:19511 [D loss: 0.251574, acc: 97.66%] [G loss: 3.813951]\n",
      "epoch:24 step:19512 [D loss: 0.553367, acc: 75.78%] [G loss: 2.639822]\n",
      "epoch:24 step:19513 [D loss: 0.837234, acc: 51.56%] [G loss: 4.730085]\n",
      "epoch:24 step:19514 [D loss: 0.969732, acc: 46.09%] [G loss: 3.647507]\n",
      "epoch:24 step:19515 [D loss: 0.527726, acc: 67.97%] [G loss: 3.658029]\n",
      "epoch:24 step:19516 [D loss: 0.491459, acc: 81.25%] [G loss: 2.610521]\n",
      "epoch:24 step:19517 [D loss: 0.110706, acc: 100.00%] [G loss: 5.722708]\n",
      "epoch:24 step:19518 [D loss: 0.173861, acc: 99.22%] [G loss: 4.015160]\n",
      "epoch:24 step:19519 [D loss: 0.833238, acc: 39.84%] [G loss: 4.929641]\n",
      "epoch:24 step:19520 [D loss: 0.195117, acc: 99.22%] [G loss: 3.616771]\n",
      "epoch:24 step:19521 [D loss: 0.176967, acc: 98.44%] [G loss: 2.891677]\n",
      "epoch:24 step:19522 [D loss: 0.391554, acc: 80.47%] [G loss: 3.539811]\n",
      "epoch:24 step:19523 [D loss: 0.558933, acc: 74.22%] [G loss: 2.703408]\n",
      "epoch:24 step:19524 [D loss: 0.416575, acc: 83.59%] [G loss: 3.566242]\n",
      "epoch:24 step:19525 [D loss: 0.179233, acc: 100.00%] [G loss: 4.086289]\n",
      "epoch:25 step:19526 [D loss: 0.351931, acc: 89.84%] [G loss: 4.698750]\n",
      "epoch:25 step:19527 [D loss: 0.125197, acc: 100.00%] [G loss: 4.029870]\n",
      "epoch:25 step:19528 [D loss: 0.809451, acc: 52.34%] [G loss: 3.507589]\n",
      "epoch:25 step:19529 [D loss: 0.147214, acc: 100.00%] [G loss: 2.474561]\n",
      "epoch:25 step:19530 [D loss: 0.814057, acc: 44.53%] [G loss: 3.062850]\n",
      "epoch:25 step:19531 [D loss: 0.519991, acc: 71.88%] [G loss: 4.343482]\n",
      "epoch:25 step:19532 [D loss: 0.401576, acc: 86.72%] [G loss: 2.134817]\n",
      "epoch:25 step:19533 [D loss: 0.293071, acc: 95.31%] [G loss: 3.570146]\n",
      "epoch:25 step:19534 [D loss: 0.339329, acc: 86.72%] [G loss: 4.579077]\n",
      "epoch:25 step:19535 [D loss: 0.259947, acc: 96.88%] [G loss: 4.526845]\n",
      "epoch:25 step:19536 [D loss: 0.959290, acc: 50.00%] [G loss: 2.829190]\n",
      "epoch:25 step:19537 [D loss: 0.165210, acc: 98.44%] [G loss: 4.907085]\n",
      "epoch:25 step:19538 [D loss: 0.469946, acc: 69.53%] [G loss: 4.446239]\n",
      "epoch:25 step:19539 [D loss: 0.225373, acc: 98.44%] [G loss: 4.197021]\n",
      "epoch:25 step:19540 [D loss: 0.790440, acc: 50.78%] [G loss: 3.197303]\n",
      "epoch:25 step:19541 [D loss: 0.717632, acc: 55.47%] [G loss: 3.569470]\n",
      "epoch:25 step:19542 [D loss: 0.282616, acc: 96.88%] [G loss: 3.858129]\n",
      "epoch:25 step:19543 [D loss: 0.350520, acc: 89.06%] [G loss: 3.563473]\n",
      "epoch:25 step:19544 [D loss: 0.681959, acc: 53.91%] [G loss: 4.781464]\n",
      "epoch:25 step:19545 [D loss: 0.248135, acc: 96.09%] [G loss: 3.094380]\n",
      "epoch:25 step:19546 [D loss: 0.145828, acc: 100.00%] [G loss: 3.557600]\n",
      "epoch:25 step:19547 [D loss: 0.719366, acc: 50.00%] [G loss: 3.432295]\n",
      "epoch:25 step:19548 [D loss: 0.204026, acc: 100.00%] [G loss: 4.601948]\n",
      "epoch:25 step:19549 [D loss: 0.520578, acc: 75.00%] [G loss: 3.595917]\n",
      "epoch:25 step:19550 [D loss: 0.560057, acc: 63.28%] [G loss: 2.420592]\n",
      "epoch:25 step:19551 [D loss: 0.696351, acc: 56.25%] [G loss: 4.402285]\n",
      "epoch:25 step:19552 [D loss: 0.093817, acc: 100.00%] [G loss: 2.238710]\n",
      "epoch:25 step:19553 [D loss: 0.321185, acc: 96.88%] [G loss: 5.226176]\n",
      "epoch:25 step:19554 [D loss: 0.146555, acc: 99.22%] [G loss: 4.235186]\n",
      "epoch:25 step:19555 [D loss: 0.171008, acc: 99.22%] [G loss: 6.312744]\n",
      "epoch:25 step:19556 [D loss: 0.740233, acc: 48.44%] [G loss: 2.556002]\n",
      "epoch:25 step:19557 [D loss: 0.396299, acc: 89.06%] [G loss: 3.268896]\n",
      "epoch:25 step:19558 [D loss: 0.594490, acc: 56.25%] [G loss: 2.533713]\n",
      "epoch:25 step:19559 [D loss: 0.560089, acc: 67.19%] [G loss: 4.688726]\n",
      "epoch:25 step:19560 [D loss: 0.106979, acc: 100.00%] [G loss: 2.700907]\n",
      "epoch:25 step:19561 [D loss: 0.854890, acc: 46.88%] [G loss: 4.282706]\n",
      "epoch:25 step:19562 [D loss: 0.403948, acc: 76.56%] [G loss: 5.559668]\n",
      "epoch:25 step:19563 [D loss: 0.751569, acc: 50.78%] [G loss: 2.820627]\n",
      "epoch:25 step:19564 [D loss: 0.543679, acc: 69.53%] [G loss: 3.895742]\n",
      "epoch:25 step:19565 [D loss: 0.877151, acc: 49.22%] [G loss: 4.098293]\n",
      "epoch:25 step:19566 [D loss: 0.487078, acc: 83.59%] [G loss: 4.775049]\n",
      "epoch:25 step:19567 [D loss: 0.144859, acc: 99.22%] [G loss: 4.478462]\n",
      "epoch:25 step:19568 [D loss: 0.276097, acc: 95.31%] [G loss: 2.997182]\n",
      "epoch:25 step:19569 [D loss: 1.708018, acc: 46.88%] [G loss: 2.723005]\n",
      "epoch:25 step:19570 [D loss: 0.301378, acc: 93.75%] [G loss: 2.611427]\n",
      "epoch:25 step:19571 [D loss: 0.386925, acc: 75.00%] [G loss: 5.018133]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:25 step:19572 [D loss: 1.344632, acc: 44.53%] [G loss: 2.723005]\n",
      "epoch:25 step:19573 [D loss: 0.274870, acc: 96.09%] [G loss: 2.957092]\n",
      "epoch:25 step:19574 [D loss: 0.457078, acc: 77.34%] [G loss: 6.985228]\n",
      "epoch:25 step:19575 [D loss: 0.682425, acc: 59.38%] [G loss: 2.611677]\n",
      "epoch:25 step:19576 [D loss: 0.389615, acc: 87.50%] [G loss: 2.524776]\n",
      "epoch:25 step:19577 [D loss: 0.503944, acc: 68.75%] [G loss: 4.665699]\n",
      "epoch:25 step:19578 [D loss: 0.585582, acc: 57.03%] [G loss: 4.887452]\n",
      "epoch:25 step:19579 [D loss: 0.665101, acc: 58.59%] [G loss: 5.379254]\n",
      "epoch:25 step:19580 [D loss: 0.241525, acc: 99.22%] [G loss: 3.354845]\n",
      "epoch:25 step:19581 [D loss: 0.529549, acc: 76.56%] [G loss: 4.091352]\n",
      "epoch:25 step:19582 [D loss: 0.448911, acc: 80.47%] [G loss: 3.438436]\n",
      "epoch:25 step:19583 [D loss: 0.260966, acc: 95.31%] [G loss: 4.865997]\n",
      "epoch:25 step:19584 [D loss: 0.153016, acc: 99.22%] [G loss: 3.415335]\n",
      "epoch:25 step:19585 [D loss: 0.521953, acc: 67.97%] [G loss: 5.681787]\n",
      "epoch:25 step:19586 [D loss: 0.268338, acc: 97.66%] [G loss: 2.926451]\n",
      "epoch:25 step:19587 [D loss: 0.669024, acc: 57.03%] [G loss: 3.008497]\n",
      "epoch:25 step:19588 [D loss: 0.394787, acc: 77.34%] [G loss: 3.094480]\n",
      "epoch:25 step:19589 [D loss: 0.293738, acc: 91.41%] [G loss: 3.688964]\n",
      "epoch:25 step:19590 [D loss: 0.447283, acc: 77.34%] [G loss: 3.867531]\n",
      "epoch:25 step:19591 [D loss: 0.479923, acc: 69.53%] [G loss: 4.140471]\n",
      "epoch:25 step:19592 [D loss: 0.557548, acc: 72.66%] [G loss: 3.477568]\n",
      "epoch:25 step:19593 [D loss: 0.437785, acc: 82.81%] [G loss: 4.595082]\n",
      "epoch:25 step:19594 [D loss: 0.536135, acc: 67.97%] [G loss: 3.881013]\n",
      "epoch:25 step:19595 [D loss: 0.843455, acc: 42.97%] [G loss: 2.766282]\n",
      "epoch:25 step:19596 [D loss: 0.686376, acc: 57.03%] [G loss: 4.207711]\n",
      "epoch:25 step:19597 [D loss: 0.258135, acc: 90.62%] [G loss: 4.189213]\n",
      "epoch:25 step:19598 [D loss: 0.284255, acc: 93.75%] [G loss: 2.377848]\n",
      "epoch:25 step:19599 [D loss: 0.391532, acc: 85.94%] [G loss: 3.128978]\n",
      "epoch:25 step:19600 [D loss: 0.193364, acc: 99.22%] [G loss: 3.437980]\n",
      "##############\n",
      "[0.85310675 0.86076445 0.80514364 0.82180097 0.78624994 0.8307165\n",
      " 0.87322661 0.84491301 0.83724573 0.8160256 ]\n",
      "##########\n",
      "epoch:25 step:19601 [D loss: 0.565619, acc: 73.44%] [G loss: 5.130525]\n",
      "epoch:25 step:19602 [D loss: 0.410249, acc: 82.81%] [G loss: 2.566694]\n",
      "epoch:25 step:19603 [D loss: 0.137281, acc: 100.00%] [G loss: 4.821590]\n",
      "epoch:25 step:19604 [D loss: 0.524788, acc: 66.41%] [G loss: 2.530253]\n",
      "epoch:25 step:19605 [D loss: 0.248073, acc: 99.22%] [G loss: 2.752282]\n",
      "epoch:25 step:19606 [D loss: 0.185796, acc: 98.44%] [G loss: 3.357829]\n",
      "epoch:25 step:19607 [D loss: 0.414344, acc: 88.28%] [G loss: 3.219666]\n",
      "epoch:25 step:19608 [D loss: 0.714425, acc: 54.69%] [G loss: 1.765293]\n",
      "epoch:25 step:19609 [D loss: 0.212029, acc: 96.09%] [G loss: 2.015100]\n",
      "epoch:25 step:19610 [D loss: 0.394726, acc: 87.50%] [G loss: 5.186513]\n",
      "epoch:25 step:19611 [D loss: 0.582634, acc: 63.28%] [G loss: 4.255526]\n",
      "epoch:25 step:19612 [D loss: 0.170984, acc: 96.09%] [G loss: 4.984046]\n",
      "epoch:25 step:19613 [D loss: 0.203757, acc: 99.22%] [G loss: 3.117182]\n",
      "epoch:25 step:19614 [D loss: 0.314719, acc: 85.16%] [G loss: 6.763359]\n",
      "epoch:25 step:19615 [D loss: 0.239898, acc: 94.53%] [G loss: 5.251112]\n",
      "epoch:25 step:19616 [D loss: 0.149898, acc: 100.00%] [G loss: 2.864374]\n",
      "epoch:25 step:19617 [D loss: 0.402935, acc: 83.59%] [G loss: 5.141808]\n",
      "epoch:25 step:19618 [D loss: 0.312138, acc: 96.09%] [G loss: 3.313634]\n",
      "epoch:25 step:19619 [D loss: 0.590621, acc: 60.16%] [G loss: 3.181998]\n",
      "epoch:25 step:19620 [D loss: 0.205734, acc: 97.66%] [G loss: 2.559293]\n",
      "epoch:25 step:19621 [D loss: 0.450662, acc: 75.00%] [G loss: 2.746256]\n",
      "epoch:25 step:19622 [D loss: 0.418532, acc: 85.94%] [G loss: 2.756891]\n",
      "epoch:25 step:19623 [D loss: 0.225157, acc: 99.22%] [G loss: 3.428274]\n",
      "epoch:25 step:19624 [D loss: 0.498421, acc: 77.34%] [G loss: 3.399939]\n",
      "epoch:25 step:19625 [D loss: 0.211728, acc: 96.88%] [G loss: 3.515099]\n",
      "epoch:25 step:19626 [D loss: 0.387269, acc: 85.94%] [G loss: 3.406186]\n",
      "epoch:25 step:19627 [D loss: 1.100841, acc: 43.75%] [G loss: 3.137312]\n",
      "epoch:25 step:19628 [D loss: 0.438848, acc: 84.38%] [G loss: 3.827261]\n",
      "epoch:25 step:19629 [D loss: 0.118434, acc: 100.00%] [G loss: 5.734601]\n",
      "epoch:25 step:19630 [D loss: 0.508115, acc: 77.34%] [G loss: 3.976171]\n",
      "epoch:25 step:19631 [D loss: 0.294040, acc: 92.97%] [G loss: 2.705388]\n",
      "epoch:25 step:19632 [D loss: 0.369622, acc: 75.78%] [G loss: 4.847470]\n",
      "epoch:25 step:19633 [D loss: 0.766919, acc: 53.12%] [G loss: 3.128526]\n",
      "epoch:25 step:19634 [D loss: 0.303348, acc: 96.88%] [G loss: 4.138661]\n",
      "epoch:25 step:19635 [D loss: 0.527873, acc: 67.19%] [G loss: 3.417348]\n",
      "epoch:25 step:19636 [D loss: 0.624172, acc: 62.50%] [G loss: 4.317446]\n",
      "epoch:25 step:19637 [D loss: 0.365248, acc: 88.28%] [G loss: 2.882105]\n",
      "epoch:25 step:19638 [D loss: 0.242205, acc: 96.09%] [G loss: 5.857635]\n",
      "epoch:25 step:19639 [D loss: 0.326180, acc: 88.28%] [G loss: 3.691719]\n",
      "epoch:25 step:19640 [D loss: 0.449745, acc: 82.03%] [G loss: 6.822055]\n",
      "epoch:25 step:19641 [D loss: 0.353040, acc: 93.75%] [G loss: 2.731673]\n",
      "epoch:25 step:19642 [D loss: 0.958857, acc: 28.91%] [G loss: 3.800947]\n",
      "epoch:25 step:19643 [D loss: 0.165841, acc: 100.00%] [G loss: 4.621518]\n",
      "epoch:25 step:19644 [D loss: 0.509656, acc: 61.72%] [G loss: 3.828699]\n",
      "epoch:25 step:19645 [D loss: 0.356713, acc: 95.31%] [G loss: 7.572117]\n",
      "epoch:25 step:19646 [D loss: 0.501232, acc: 67.97%] [G loss: 4.321531]\n",
      "epoch:25 step:19647 [D loss: 0.094066, acc: 100.00%] [G loss: 5.080225]\n",
      "epoch:25 step:19648 [D loss: 0.390243, acc: 76.56%] [G loss: 4.545277]\n",
      "epoch:25 step:19649 [D loss: 0.394843, acc: 92.19%] [G loss: 2.749183]\n",
      "epoch:25 step:19650 [D loss: 0.430069, acc: 74.22%] [G loss: 4.203821]\n",
      "epoch:25 step:19651 [D loss: 0.463985, acc: 82.81%] [G loss: 3.618180]\n",
      "epoch:25 step:19652 [D loss: 0.729025, acc: 52.34%] [G loss: 5.611694]\n",
      "epoch:25 step:19653 [D loss: 0.132529, acc: 97.66%] [G loss: 5.096164]\n",
      "epoch:25 step:19654 [D loss: 0.698940, acc: 57.81%] [G loss: 3.532392]\n",
      "epoch:25 step:19655 [D loss: 1.724285, acc: 7.03%] [G loss: 3.634666]\n",
      "epoch:25 step:19656 [D loss: 0.086148, acc: 100.00%] [G loss: 5.967271]\n",
      "epoch:25 step:19657 [D loss: 0.821001, acc: 46.09%] [G loss: 2.773220]\n",
      "epoch:25 step:19658 [D loss: 0.308020, acc: 96.88%] [G loss: 2.373913]\n",
      "epoch:25 step:19659 [D loss: 0.150918, acc: 100.00%] [G loss: 4.179726]\n",
      "epoch:25 step:19660 [D loss: 0.137887, acc: 100.00%] [G loss: 5.432089]\n",
      "epoch:25 step:19661 [D loss: 0.336743, acc: 86.72%] [G loss: 4.263759]\n",
      "epoch:25 step:19662 [D loss: 0.317891, acc: 84.38%] [G loss: 3.421013]\n",
      "epoch:25 step:19663 [D loss: 0.463207, acc: 82.81%] [G loss: 5.693078]\n",
      "epoch:25 step:19664 [D loss: 0.394099, acc: 82.81%] [G loss: 3.985598]\n",
      "epoch:25 step:19665 [D loss: 0.208494, acc: 94.53%] [G loss: 3.171408]\n",
      "epoch:25 step:19666 [D loss: 0.581315, acc: 67.97%] [G loss: 3.657711]\n",
      "epoch:25 step:19667 [D loss: 0.270007, acc: 92.97%] [G loss: 3.973975]\n",
      "epoch:25 step:19668 [D loss: 0.095580, acc: 100.00%] [G loss: 2.649680]\n",
      "epoch:25 step:19669 [D loss: 0.080377, acc: 100.00%] [G loss: 3.299559]\n",
      "epoch:25 step:19670 [D loss: 0.132748, acc: 100.00%] [G loss: 4.459288]\n",
      "epoch:25 step:19671 [D loss: 0.644049, acc: 57.03%] [G loss: 3.323809]\n",
      "epoch:25 step:19672 [D loss: 0.325813, acc: 92.97%] [G loss: 4.979428]\n",
      "epoch:25 step:19673 [D loss: 0.141844, acc: 99.22%] [G loss: 4.773614]\n",
      "epoch:25 step:19674 [D loss: 0.159966, acc: 100.00%] [G loss: 5.706872]\n",
      "epoch:25 step:19675 [D loss: 0.858274, acc: 46.88%] [G loss: 2.883698]\n",
      "epoch:25 step:19676 [D loss: 0.550035, acc: 67.19%] [G loss: 4.792973]\n",
      "epoch:25 step:19677 [D loss: 0.128066, acc: 100.00%] [G loss: 3.792948]\n",
      "epoch:25 step:19678 [D loss: 0.575139, acc: 67.97%] [G loss: 3.902041]\n",
      "epoch:25 step:19679 [D loss: 0.336958, acc: 90.62%] [G loss: 2.254989]\n",
      "epoch:25 step:19680 [D loss: 0.923557, acc: 27.34%] [G loss: 3.245358]\n",
      "epoch:25 step:19681 [D loss: 0.860681, acc: 52.34%] [G loss: 3.108133]\n",
      "epoch:25 step:19682 [D loss: 0.323089, acc: 92.19%] [G loss: 6.955843]\n",
      "epoch:25 step:19683 [D loss: 0.977442, acc: 49.22%] [G loss: 3.700984]\n",
      "epoch:25 step:19684 [D loss: 0.662056, acc: 53.91%] [G loss: 4.292867]\n",
      "epoch:25 step:19685 [D loss: 0.209128, acc: 99.22%] [G loss: 2.811793]\n",
      "epoch:25 step:19686 [D loss: 0.145783, acc: 100.00%] [G loss: 5.036830]\n",
      "epoch:25 step:19687 [D loss: 0.346828, acc: 90.62%] [G loss: 3.631377]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:25 step:19688 [D loss: 0.602112, acc: 64.84%] [G loss: 4.201445]\n",
      "epoch:25 step:19689 [D loss: 0.361270, acc: 83.59%] [G loss: 2.580989]\n",
      "epoch:25 step:19690 [D loss: 0.238027, acc: 93.75%] [G loss: 4.409256]\n",
      "epoch:25 step:19691 [D loss: 0.936383, acc: 46.09%] [G loss: 3.710700]\n",
      "epoch:25 step:19692 [D loss: 0.748612, acc: 51.56%] [G loss: 2.672003]\n",
      "epoch:25 step:19693 [D loss: 0.570145, acc: 63.28%] [G loss: 2.909525]\n",
      "epoch:25 step:19694 [D loss: 0.580978, acc: 75.00%] [G loss: 3.157749]\n",
      "epoch:25 step:19695 [D loss: 0.498318, acc: 64.84%] [G loss: 4.082280]\n",
      "epoch:25 step:19696 [D loss: 0.160208, acc: 98.44%] [G loss: 5.031561]\n",
      "epoch:25 step:19697 [D loss: 0.370759, acc: 93.75%] [G loss: 2.500943]\n",
      "epoch:25 step:19698 [D loss: 0.623014, acc: 71.09%] [G loss: 3.655467]\n",
      "epoch:25 step:19699 [D loss: 0.532280, acc: 78.12%] [G loss: 4.589095]\n",
      "epoch:25 step:19700 [D loss: 0.165926, acc: 100.00%] [G loss: 5.408605]\n",
      "epoch:25 step:19701 [D loss: 0.806785, acc: 53.91%] [G loss: 5.267589]\n",
      "epoch:25 step:19702 [D loss: 0.164784, acc: 99.22%] [G loss: 3.400657]\n",
      "epoch:25 step:19703 [D loss: 0.444592, acc: 71.09%] [G loss: 4.010632]\n",
      "epoch:25 step:19704 [D loss: 0.262859, acc: 97.66%] [G loss: 3.291199]\n",
      "epoch:25 step:19705 [D loss: 1.290158, acc: 46.09%] [G loss: 3.524734]\n",
      "epoch:25 step:19706 [D loss: 0.496383, acc: 82.81%] [G loss: 2.996535]\n",
      "epoch:25 step:19707 [D loss: 0.546571, acc: 60.94%] [G loss: 3.112485]\n",
      "epoch:25 step:19708 [D loss: 0.603848, acc: 64.06%] [G loss: 3.207627]\n",
      "epoch:25 step:19709 [D loss: 0.291746, acc: 92.97%] [G loss: 4.351052]\n",
      "epoch:25 step:19710 [D loss: 0.534196, acc: 74.22%] [G loss: 4.935029]\n",
      "epoch:25 step:19711 [D loss: 0.227224, acc: 96.88%] [G loss: 2.950887]\n",
      "epoch:25 step:19712 [D loss: 0.477294, acc: 71.09%] [G loss: 2.780552]\n",
      "epoch:25 step:19713 [D loss: 0.246170, acc: 96.09%] [G loss: 5.112466]\n",
      "epoch:25 step:19714 [D loss: 0.231193, acc: 96.09%] [G loss: 4.871442]\n",
      "epoch:25 step:19715 [D loss: 0.666829, acc: 60.16%] [G loss: 4.859772]\n",
      "epoch:25 step:19716 [D loss: 0.143173, acc: 98.44%] [G loss: 3.830890]\n",
      "epoch:25 step:19717 [D loss: 0.348564, acc: 88.28%] [G loss: 3.739598]\n",
      "epoch:25 step:19718 [D loss: 0.133722, acc: 99.22%] [G loss: 5.540379]\n",
      "epoch:25 step:19719 [D loss: 0.674391, acc: 57.81%] [G loss: 2.907450]\n",
      "epoch:25 step:19720 [D loss: 0.120339, acc: 99.22%] [G loss: 3.493884]\n",
      "epoch:25 step:19721 [D loss: 0.463862, acc: 78.12%] [G loss: 2.981322]\n",
      "epoch:25 step:19722 [D loss: 0.135587, acc: 100.00%] [G loss: 4.715892]\n",
      "epoch:25 step:19723 [D loss: 0.373727, acc: 89.84%] [G loss: 5.533304]\n",
      "epoch:25 step:19724 [D loss: 0.444476, acc: 85.94%] [G loss: 2.106809]\n",
      "epoch:25 step:19725 [D loss: 0.234383, acc: 97.66%] [G loss: 4.016233]\n",
      "epoch:25 step:19726 [D loss: 0.304764, acc: 95.31%] [G loss: 2.499754]\n",
      "epoch:25 step:19727 [D loss: 1.229443, acc: 20.31%] [G loss: 3.071349]\n",
      "epoch:25 step:19728 [D loss: 0.183754, acc: 98.44%] [G loss: 4.006735]\n",
      "epoch:25 step:19729 [D loss: 0.274189, acc: 96.09%] [G loss: 2.347439]\n",
      "epoch:25 step:19730 [D loss: 0.913110, acc: 30.47%] [G loss: 4.290396]\n",
      "epoch:25 step:19731 [D loss: 0.807571, acc: 50.00%] [G loss: 3.928589]\n",
      "epoch:25 step:19732 [D loss: 0.890431, acc: 50.78%] [G loss: 4.199012]\n",
      "epoch:25 step:19733 [D loss: 0.155262, acc: 99.22%] [G loss: 5.356018]\n",
      "epoch:25 step:19734 [D loss: 0.596345, acc: 60.16%] [G loss: 2.463683]\n",
      "epoch:25 step:19735 [D loss: 0.687887, acc: 56.25%] [G loss: 4.726814]\n",
      "epoch:25 step:19736 [D loss: 0.543866, acc: 61.72%] [G loss: 3.836703]\n",
      "epoch:25 step:19737 [D loss: 0.289681, acc: 95.31%] [G loss: 3.808572]\n",
      "epoch:25 step:19738 [D loss: 0.440009, acc: 75.78%] [G loss: 3.032937]\n",
      "epoch:25 step:19739 [D loss: 0.711811, acc: 54.69%] [G loss: 4.040987]\n",
      "epoch:25 step:19740 [D loss: 0.143475, acc: 100.00%] [G loss: 4.515047]\n",
      "epoch:25 step:19741 [D loss: 0.996257, acc: 42.97%] [G loss: 5.018168]\n",
      "epoch:25 step:19742 [D loss: 0.788292, acc: 52.34%] [G loss: 3.532094]\n",
      "epoch:25 step:19743 [D loss: 0.168694, acc: 97.66%] [G loss: 2.972737]\n",
      "epoch:25 step:19744 [D loss: 0.267419, acc: 91.41%] [G loss: 4.939084]\n",
      "epoch:25 step:19745 [D loss: 0.459179, acc: 70.31%] [G loss: 3.196659]\n",
      "epoch:25 step:19746 [D loss: 0.865099, acc: 52.34%] [G loss: 3.138884]\n",
      "epoch:25 step:19747 [D loss: 0.254656, acc: 96.09%] [G loss: 2.639077]\n",
      "epoch:25 step:19748 [D loss: 0.205919, acc: 99.22%] [G loss: 2.179119]\n",
      "epoch:25 step:19749 [D loss: 0.645676, acc: 56.25%] [G loss: 4.275324]\n",
      "epoch:25 step:19750 [D loss: 0.206972, acc: 96.88%] [G loss: 4.359564]\n",
      "epoch:25 step:19751 [D loss: 0.449507, acc: 72.66%] [G loss: 4.103981]\n",
      "epoch:25 step:19752 [D loss: 0.314032, acc: 96.09%] [G loss: 3.517147]\n",
      "epoch:25 step:19753 [D loss: 0.187838, acc: 97.66%] [G loss: 4.028591]\n",
      "epoch:25 step:19754 [D loss: 0.278791, acc: 92.97%] [G loss: 2.621551]\n",
      "epoch:25 step:19755 [D loss: 0.194390, acc: 100.00%] [G loss: 3.805859]\n",
      "epoch:25 step:19756 [D loss: 0.369726, acc: 77.34%] [G loss: 4.995365]\n",
      "epoch:25 step:19757 [D loss: 0.324552, acc: 82.03%] [G loss: 2.534603]\n",
      "epoch:25 step:19758 [D loss: 0.536730, acc: 67.97%] [G loss: 3.723144]\n",
      "epoch:25 step:19759 [D loss: 0.284918, acc: 88.28%] [G loss: 4.947384]\n",
      "epoch:25 step:19760 [D loss: 0.246063, acc: 97.66%] [G loss: 3.507635]\n",
      "epoch:25 step:19761 [D loss: 0.971901, acc: 28.12%] [G loss: 3.084059]\n",
      "epoch:25 step:19762 [D loss: 0.505332, acc: 62.50%] [G loss: 3.008957]\n",
      "epoch:25 step:19763 [D loss: 1.070242, acc: 26.56%] [G loss: 4.024260]\n",
      "epoch:25 step:19764 [D loss: 0.464018, acc: 85.16%] [G loss: 3.558762]\n",
      "epoch:25 step:19765 [D loss: 0.724974, acc: 53.91%] [G loss: 2.398528]\n",
      "epoch:25 step:19766 [D loss: 0.304225, acc: 92.97%] [G loss: 4.486694]\n",
      "epoch:25 step:19767 [D loss: 0.308008, acc: 89.06%] [G loss: 4.961787]\n",
      "epoch:25 step:19768 [D loss: 0.353737, acc: 92.19%] [G loss: 4.015241]\n",
      "epoch:25 step:19769 [D loss: 0.423641, acc: 78.12%] [G loss: 4.568190]\n",
      "epoch:25 step:19770 [D loss: 0.329002, acc: 91.41%] [G loss: 2.307860]\n",
      "epoch:25 step:19771 [D loss: 0.243865, acc: 96.88%] [G loss: 3.127923]\n",
      "epoch:25 step:19772 [D loss: 0.714498, acc: 50.78%] [G loss: 4.421392]\n",
      "epoch:25 step:19773 [D loss: 0.630136, acc: 65.62%] [G loss: 3.068979]\n",
      "epoch:25 step:19774 [D loss: 1.082627, acc: 50.78%] [G loss: 3.952410]\n",
      "epoch:25 step:19775 [D loss: 0.380376, acc: 88.28%] [G loss: 3.107550]\n",
      "epoch:25 step:19776 [D loss: 0.113134, acc: 99.22%] [G loss: 5.646439]\n",
      "epoch:25 step:19777 [D loss: 0.537901, acc: 59.38%] [G loss: 4.888778]\n",
      "epoch:25 step:19778 [D loss: 0.594642, acc: 67.19%] [G loss: 3.910203]\n",
      "epoch:25 step:19779 [D loss: 1.048660, acc: 28.91%] [G loss: 2.942284]\n",
      "epoch:25 step:19780 [D loss: 0.228857, acc: 98.44%] [G loss: 3.737569]\n",
      "epoch:25 step:19781 [D loss: 0.245249, acc: 92.19%] [G loss: 3.145790]\n",
      "epoch:25 step:19782 [D loss: 0.423151, acc: 81.25%] [G loss: 3.138535]\n",
      "epoch:25 step:19783 [D loss: 0.176592, acc: 100.00%] [G loss: 3.511326]\n",
      "epoch:25 step:19784 [D loss: 0.699204, acc: 54.69%] [G loss: 4.671117]\n",
      "epoch:25 step:19785 [D loss: 0.338046, acc: 89.06%] [G loss: 5.181765]\n",
      "epoch:25 step:19786 [D loss: 0.520689, acc: 71.88%] [G loss: 3.205303]\n",
      "epoch:25 step:19787 [D loss: 0.211850, acc: 100.00%] [G loss: 4.581613]\n",
      "epoch:25 step:19788 [D loss: 0.603471, acc: 61.72%] [G loss: 2.858342]\n",
      "epoch:25 step:19789 [D loss: 0.455499, acc: 67.97%] [G loss: 3.848197]\n",
      "epoch:25 step:19790 [D loss: 0.479779, acc: 73.44%] [G loss: 3.088674]\n",
      "epoch:25 step:19791 [D loss: 0.978051, acc: 48.44%] [G loss: 3.400486]\n",
      "epoch:25 step:19792 [D loss: 1.191163, acc: 25.78%] [G loss: 3.356568]\n",
      "epoch:25 step:19793 [D loss: 0.930734, acc: 37.50%] [G loss: 3.434012]\n",
      "epoch:25 step:19794 [D loss: 1.159787, acc: 47.66%] [G loss: 4.153050]\n",
      "epoch:25 step:19795 [D loss: 0.250387, acc: 94.53%] [G loss: 2.611424]\n",
      "epoch:25 step:19796 [D loss: 0.648908, acc: 58.59%] [G loss: 3.152450]\n",
      "epoch:25 step:19797 [D loss: 0.265434, acc: 95.31%] [G loss: 3.860737]\n",
      "epoch:25 step:19798 [D loss: 0.443505, acc: 85.16%] [G loss: 3.168139]\n",
      "epoch:25 step:19799 [D loss: 0.381230, acc: 83.59%] [G loss: 2.993148]\n",
      "epoch:25 step:19800 [D loss: 0.382216, acc: 91.41%] [G loss: 4.487253]\n",
      "##############\n",
      "[0.86942832 0.86164865 0.81581369 0.82775345 0.79750971 0.82630749\n",
      " 0.88759213 0.82931622 0.82856739 0.83110098]\n",
      "##########\n",
      "epoch:25 step:19801 [D loss: 0.772621, acc: 49.22%] [G loss: 3.471776]\n",
      "epoch:25 step:19802 [D loss: 0.210410, acc: 96.09%] [G loss: 3.648529]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:25 step:19803 [D loss: 0.099655, acc: 100.00%] [G loss: 5.805196]\n",
      "epoch:25 step:19804 [D loss: 0.347575, acc: 85.16%] [G loss: 2.932460]\n",
      "epoch:25 step:19805 [D loss: 0.275326, acc: 93.75%] [G loss: 3.899286]\n",
      "epoch:25 step:19806 [D loss: 0.173982, acc: 100.00%] [G loss: 4.097516]\n",
      "epoch:25 step:19807 [D loss: 0.332148, acc: 93.75%] [G loss: 3.120111]\n",
      "epoch:25 step:19808 [D loss: 0.494000, acc: 66.41%] [G loss: 4.018681]\n",
      "epoch:25 step:19809 [D loss: 0.370131, acc: 81.25%] [G loss: 3.215059]\n",
      "epoch:25 step:19810 [D loss: 0.410813, acc: 88.28%] [G loss: 2.860287]\n",
      "epoch:25 step:19811 [D loss: 0.473455, acc: 83.59%] [G loss: 3.674967]\n",
      "epoch:25 step:19812 [D loss: 0.838028, acc: 52.34%] [G loss: 4.332408]\n",
      "epoch:25 step:19813 [D loss: 0.181317, acc: 97.66%] [G loss: 3.112622]\n",
      "epoch:25 step:19814 [D loss: 0.335610, acc: 89.84%] [G loss: 3.537258]\n",
      "epoch:25 step:19815 [D loss: 0.092692, acc: 100.00%] [G loss: 3.082218]\n",
      "epoch:25 step:19816 [D loss: 0.179592, acc: 100.00%] [G loss: 3.627383]\n",
      "epoch:25 step:19817 [D loss: 0.266309, acc: 91.41%] [G loss: 2.964272]\n",
      "epoch:25 step:19818 [D loss: 0.642832, acc: 57.81%] [G loss: 5.924494]\n",
      "epoch:25 step:19819 [D loss: 0.287202, acc: 91.41%] [G loss: 3.088059]\n",
      "epoch:25 step:19820 [D loss: 0.386943, acc: 90.62%] [G loss: 4.410456]\n",
      "epoch:25 step:19821 [D loss: 0.207200, acc: 97.66%] [G loss: 4.643575]\n",
      "epoch:25 step:19822 [D loss: 0.483240, acc: 67.97%] [G loss: 3.611890]\n",
      "epoch:25 step:19823 [D loss: 0.555680, acc: 67.97%] [G loss: 2.682492]\n",
      "epoch:25 step:19824 [D loss: 0.324244, acc: 93.75%] [G loss: 2.336522]\n",
      "epoch:25 step:19825 [D loss: 0.380458, acc: 88.28%] [G loss: 3.368293]\n",
      "epoch:25 step:19826 [D loss: 0.328674, acc: 95.31%] [G loss: 5.720321]\n",
      "epoch:25 step:19827 [D loss: 0.299981, acc: 95.31%] [G loss: 3.058530]\n",
      "epoch:25 step:19828 [D loss: 0.171424, acc: 97.66%] [G loss: 3.591148]\n",
      "epoch:25 step:19829 [D loss: 0.197910, acc: 99.22%] [G loss: 4.721321]\n",
      "epoch:25 step:19830 [D loss: 0.068927, acc: 100.00%] [G loss: 6.149146]\n",
      "epoch:25 step:19831 [D loss: 0.427739, acc: 88.28%] [G loss: 4.484496]\n",
      "epoch:25 step:19832 [D loss: 0.434321, acc: 86.72%] [G loss: 4.532712]\n",
      "epoch:25 step:19833 [D loss: 0.504370, acc: 82.81%] [G loss: 3.046597]\n",
      "epoch:25 step:19834 [D loss: 0.308915, acc: 92.97%] [G loss: 4.728477]\n",
      "epoch:25 step:19835 [D loss: 0.148723, acc: 100.00%] [G loss: 5.486454]\n",
      "epoch:25 step:19836 [D loss: 0.499784, acc: 69.53%] [G loss: 3.451472]\n",
      "epoch:25 step:19837 [D loss: 0.387970, acc: 77.34%] [G loss: 3.193349]\n",
      "epoch:25 step:19838 [D loss: 0.450676, acc: 79.69%] [G loss: 1.318784]\n",
      "epoch:25 step:19839 [D loss: 0.455389, acc: 72.66%] [G loss: 4.095814]\n",
      "epoch:25 step:19840 [D loss: 0.208324, acc: 92.97%] [G loss: 2.683696]\n",
      "epoch:25 step:19841 [D loss: 0.547445, acc: 73.44%] [G loss: 2.792574]\n",
      "epoch:25 step:19842 [D loss: 0.438013, acc: 73.44%] [G loss: 5.000898]\n",
      "epoch:25 step:19843 [D loss: 0.393269, acc: 81.25%] [G loss: 3.680528]\n",
      "epoch:25 step:19844 [D loss: 0.197435, acc: 97.66%] [G loss: 3.702348]\n",
      "epoch:25 step:19845 [D loss: 0.692821, acc: 57.81%] [G loss: 3.725508]\n",
      "epoch:25 step:19846 [D loss: 0.565642, acc: 64.84%] [G loss: 2.842463]\n",
      "epoch:25 step:19847 [D loss: 0.252402, acc: 92.97%] [G loss: 4.026391]\n",
      "epoch:25 step:19848 [D loss: 0.352628, acc: 93.75%] [G loss: 3.983242]\n",
      "epoch:25 step:19849 [D loss: 0.404543, acc: 89.84%] [G loss: 2.993858]\n",
      "epoch:25 step:19850 [D loss: 0.173296, acc: 97.66%] [G loss: 5.319801]\n",
      "epoch:25 step:19851 [D loss: 0.490703, acc: 69.53%] [G loss: 7.642015]\n",
      "epoch:25 step:19852 [D loss: 0.083468, acc: 100.00%] [G loss: 3.117258]\n",
      "epoch:25 step:19853 [D loss: 0.200395, acc: 97.66%] [G loss: 3.214707]\n",
      "epoch:25 step:19854 [D loss: 0.338043, acc: 88.28%] [G loss: 3.093139]\n",
      "epoch:25 step:19855 [D loss: 1.127843, acc: 17.19%] [G loss: 4.528999]\n",
      "epoch:25 step:19856 [D loss: 0.819019, acc: 50.78%] [G loss: 4.415994]\n",
      "epoch:25 step:19857 [D loss: 0.476708, acc: 82.81%] [G loss: 3.483641]\n",
      "epoch:25 step:19858 [D loss: 0.200433, acc: 96.09%] [G loss: 5.025920]\n",
      "epoch:25 step:19859 [D loss: 1.529244, acc: 7.81%] [G loss: 3.192151]\n",
      "epoch:25 step:19860 [D loss: 0.061692, acc: 99.22%] [G loss: 6.169309]\n",
      "epoch:25 step:19861 [D loss: 0.415873, acc: 82.03%] [G loss: 4.208777]\n",
      "epoch:25 step:19862 [D loss: 0.403748, acc: 71.09%] [G loss: 5.047512]\n",
      "epoch:25 step:19863 [D loss: 0.668473, acc: 53.91%] [G loss: 4.539076]\n",
      "epoch:25 step:19864 [D loss: 0.399019, acc: 85.16%] [G loss: 3.811915]\n",
      "epoch:25 step:19865 [D loss: 0.888112, acc: 34.38%] [G loss: 3.681061]\n",
      "epoch:25 step:19866 [D loss: 0.100438, acc: 100.00%] [G loss: 3.769031]\n",
      "epoch:25 step:19867 [D loss: 0.664079, acc: 56.25%] [G loss: 3.007939]\n",
      "epoch:25 step:19868 [D loss: 1.729086, acc: 4.69%] [G loss: 2.694334]\n",
      "epoch:25 step:19869 [D loss: 0.187834, acc: 97.66%] [G loss: 5.587852]\n",
      "epoch:25 step:19870 [D loss: 1.332906, acc: 6.25%] [G loss: 2.405380]\n",
      "epoch:25 step:19871 [D loss: 0.158707, acc: 98.44%] [G loss: 6.083613]\n",
      "epoch:25 step:19872 [D loss: 0.372486, acc: 82.81%] [G loss: 6.250281]\n",
      "epoch:25 step:19873 [D loss: 1.431073, acc: 7.81%] [G loss: 4.760961]\n",
      "epoch:25 step:19874 [D loss: 0.451245, acc: 83.59%] [G loss: 4.583921]\n",
      "epoch:25 step:19875 [D loss: 0.168874, acc: 100.00%] [G loss: 3.752053]\n",
      "epoch:25 step:19876 [D loss: 1.014558, acc: 35.94%] [G loss: 3.312843]\n",
      "epoch:25 step:19877 [D loss: 0.190495, acc: 97.66%] [G loss: 3.729881]\n",
      "epoch:25 step:19878 [D loss: 0.842233, acc: 51.56%] [G loss: 4.285777]\n",
      "epoch:25 step:19879 [D loss: 0.440381, acc: 85.16%] [G loss: 3.886696]\n",
      "epoch:25 step:19880 [D loss: 0.962087, acc: 39.84%] [G loss: 3.910618]\n",
      "epoch:25 step:19881 [D loss: 0.259296, acc: 98.44%] [G loss: 4.180821]\n",
      "epoch:25 step:19882 [D loss: 0.449437, acc: 81.25%] [G loss: 3.798218]\n",
      "epoch:25 step:19883 [D loss: 0.561425, acc: 65.62%] [G loss: 3.694786]\n",
      "epoch:25 step:19884 [D loss: 0.090439, acc: 100.00%] [G loss: 4.505143]\n",
      "epoch:25 step:19885 [D loss: 0.626119, acc: 58.59%] [G loss: 3.926501]\n",
      "epoch:25 step:19886 [D loss: 0.387432, acc: 80.47%] [G loss: 3.599016]\n",
      "epoch:25 step:19887 [D loss: 0.421045, acc: 85.16%] [G loss: 4.909286]\n",
      "epoch:25 step:19888 [D loss: 0.825668, acc: 53.91%] [G loss: 2.898815]\n",
      "epoch:25 step:19889 [D loss: 0.247625, acc: 98.44%] [G loss: 5.153642]\n",
      "epoch:25 step:19890 [D loss: 0.292099, acc: 92.97%] [G loss: 5.205191]\n",
      "epoch:25 step:19891 [D loss: 0.721622, acc: 51.56%] [G loss: 6.547117]\n",
      "epoch:25 step:19892 [D loss: 0.539448, acc: 63.28%] [G loss: 4.704903]\n",
      "epoch:25 step:19893 [D loss: 0.249696, acc: 96.88%] [G loss: 3.721011]\n",
      "epoch:25 step:19894 [D loss: 0.611209, acc: 70.31%] [G loss: 2.748580]\n",
      "epoch:25 step:19895 [D loss: 0.759307, acc: 49.22%] [G loss: 3.558759]\n",
      "epoch:25 step:19896 [D loss: 0.556554, acc: 71.88%] [G loss: 3.984518]\n",
      "epoch:25 step:19897 [D loss: 0.338796, acc: 89.84%] [G loss: 3.418071]\n",
      "epoch:25 step:19898 [D loss: 0.788441, acc: 46.88%] [G loss: 3.883738]\n",
      "epoch:25 step:19899 [D loss: 0.080701, acc: 100.00%] [G loss: 2.557435]\n",
      "epoch:25 step:19900 [D loss: 1.328360, acc: 29.69%] [G loss: 4.272059]\n",
      "epoch:25 step:19901 [D loss: 0.908296, acc: 46.09%] [G loss: 2.390224]\n",
      "epoch:25 step:19902 [D loss: 0.675932, acc: 57.03%] [G loss: 3.112179]\n",
      "epoch:25 step:19903 [D loss: 0.395903, acc: 90.62%] [G loss: 5.268159]\n",
      "epoch:25 step:19904 [D loss: 0.199383, acc: 96.88%] [G loss: 1.768301]\n",
      "epoch:25 step:19905 [D loss: 0.245052, acc: 96.88%] [G loss: 5.001040]\n",
      "epoch:25 step:19906 [D loss: 0.217078, acc: 96.88%] [G loss: 3.289327]\n",
      "epoch:25 step:19907 [D loss: 0.331874, acc: 92.97%] [G loss: 4.246526]\n",
      "epoch:25 step:19908 [D loss: 0.403487, acc: 87.50%] [G loss: 4.312288]\n",
      "epoch:25 step:19909 [D loss: 0.385718, acc: 91.41%] [G loss: 4.022985]\n",
      "epoch:25 step:19910 [D loss: 0.117015, acc: 100.00%] [G loss: 5.344397]\n",
      "epoch:25 step:19911 [D loss: 0.240168, acc: 96.09%] [G loss: 2.582901]\n",
      "epoch:25 step:19912 [D loss: 0.170838, acc: 98.44%] [G loss: 3.971090]\n",
      "epoch:25 step:19913 [D loss: 0.352626, acc: 92.97%] [G loss: 3.651399]\n",
      "epoch:25 step:19914 [D loss: 0.153698, acc: 100.00%] [G loss: 3.259159]\n",
      "epoch:25 step:19915 [D loss: 0.934105, acc: 49.22%] [G loss: 2.744077]\n",
      "epoch:25 step:19916 [D loss: 0.488250, acc: 68.75%] [G loss: 5.965250]\n",
      "epoch:25 step:19917 [D loss: 0.247550, acc: 96.09%] [G loss: 6.681005]\n",
      "epoch:25 step:19918 [D loss: 0.304355, acc: 85.94%] [G loss: 3.234612]\n",
      "epoch:25 step:19919 [D loss: 0.115491, acc: 99.22%] [G loss: 7.275548]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:25 step:19920 [D loss: 0.565416, acc: 60.94%] [G loss: 4.303272]\n",
      "epoch:25 step:19921 [D loss: 0.678690, acc: 53.91%] [G loss: 3.585086]\n",
      "epoch:25 step:19922 [D loss: 0.458628, acc: 80.47%] [G loss: 4.116325]\n",
      "epoch:25 step:19923 [D loss: 0.852928, acc: 50.00%] [G loss: 3.682140]\n",
      "epoch:25 step:19924 [D loss: 0.176260, acc: 98.44%] [G loss: 4.994658]\n",
      "epoch:25 step:19925 [D loss: 0.218754, acc: 98.44%] [G loss: 3.602929]\n",
      "epoch:25 step:19926 [D loss: 0.113306, acc: 99.22%] [G loss: 3.667418]\n",
      "epoch:25 step:19927 [D loss: 0.884789, acc: 51.56%] [G loss: 5.126142]\n",
      "epoch:25 step:19928 [D loss: 0.243304, acc: 97.66%] [G loss: 3.601190]\n",
      "epoch:25 step:19929 [D loss: 0.391150, acc: 84.38%] [G loss: 4.219413]\n",
      "epoch:25 step:19930 [D loss: 1.112423, acc: 48.44%] [G loss: 3.012540]\n",
      "epoch:25 step:19931 [D loss: 0.427532, acc: 75.78%] [G loss: 4.836454]\n",
      "epoch:25 step:19932 [D loss: 0.217885, acc: 96.88%] [G loss: 4.689349]\n",
      "epoch:25 step:19933 [D loss: 0.198918, acc: 98.44%] [G loss: 4.548633]\n",
      "epoch:25 step:19934 [D loss: 0.219233, acc: 99.22%] [G loss: 4.245405]\n",
      "epoch:25 step:19935 [D loss: 0.509697, acc: 77.34%] [G loss: 2.552011]\n",
      "epoch:25 step:19936 [D loss: 0.231396, acc: 98.44%] [G loss: 3.579294]\n",
      "epoch:25 step:19937 [D loss: 0.345544, acc: 85.94%] [G loss: 3.004188]\n",
      "epoch:25 step:19938 [D loss: 0.249375, acc: 92.97%] [G loss: 3.378764]\n",
      "epoch:25 step:19939 [D loss: 0.268500, acc: 96.88%] [G loss: 2.850638]\n",
      "epoch:25 step:19940 [D loss: 0.289030, acc: 94.53%] [G loss: 3.382191]\n",
      "epoch:25 step:19941 [D loss: 0.229905, acc: 96.88%] [G loss: 4.120332]\n",
      "epoch:25 step:19942 [D loss: 0.196041, acc: 100.00%] [G loss: 3.655320]\n",
      "epoch:25 step:19943 [D loss: 0.320089, acc: 89.06%] [G loss: 3.924475]\n",
      "epoch:25 step:19944 [D loss: 0.165399, acc: 100.00%] [G loss: 3.797866]\n",
      "epoch:25 step:19945 [D loss: 0.928685, acc: 39.06%] [G loss: 3.779304]\n",
      "epoch:25 step:19946 [D loss: 0.973648, acc: 28.12%] [G loss: 3.608118]\n",
      "epoch:25 step:19947 [D loss: 0.104610, acc: 100.00%] [G loss: 5.373132]\n",
      "epoch:25 step:19948 [D loss: 0.399647, acc: 73.44%] [G loss: 4.715664]\n",
      "epoch:25 step:19949 [D loss: 1.597821, acc: 5.47%] [G loss: 3.022004]\n",
      "epoch:25 step:19950 [D loss: 0.339696, acc: 92.19%] [G loss: 5.233022]\n",
      "epoch:25 step:19951 [D loss: 0.099978, acc: 100.00%] [G loss: 5.155541]\n",
      "epoch:25 step:19952 [D loss: 0.902007, acc: 45.31%] [G loss: 2.867205]\n",
      "epoch:25 step:19953 [D loss: 1.163833, acc: 20.31%] [G loss: 3.677774]\n",
      "epoch:25 step:19954 [D loss: 0.448727, acc: 81.25%] [G loss: 5.077143]\n",
      "epoch:25 step:19955 [D loss: 0.228752, acc: 98.44%] [G loss: 4.416017]\n",
      "epoch:25 step:19956 [D loss: 0.848477, acc: 36.72%] [G loss: 3.587328]\n",
      "epoch:25 step:19957 [D loss: 0.542897, acc: 64.06%] [G loss: 4.127658]\n",
      "epoch:25 step:19958 [D loss: 0.163025, acc: 98.44%] [G loss: 2.731240]\n",
      "epoch:25 step:19959 [D loss: 0.233023, acc: 95.31%] [G loss: 2.698408]\n",
      "epoch:25 step:19960 [D loss: 0.117453, acc: 100.00%] [G loss: 5.638220]\n",
      "epoch:25 step:19961 [D loss: 0.527737, acc: 70.31%] [G loss: 2.693532]\n",
      "epoch:25 step:19962 [D loss: 0.142360, acc: 100.00%] [G loss: 4.262759]\n",
      "epoch:25 step:19963 [D loss: 0.347357, acc: 89.06%] [G loss: 4.550663]\n",
      "epoch:25 step:19964 [D loss: 0.681174, acc: 60.94%] [G loss: 4.277056]\n",
      "epoch:25 step:19965 [D loss: 0.457160, acc: 82.81%] [G loss: 5.029036]\n",
      "epoch:25 step:19966 [D loss: 0.237595, acc: 100.00%] [G loss: 3.950355]\n",
      "epoch:25 step:19967 [D loss: 0.651791, acc: 60.94%] [G loss: 4.501073]\n",
      "epoch:25 step:19968 [D loss: 0.304165, acc: 89.06%] [G loss: 2.946388]\n",
      "epoch:25 step:19969 [D loss: 1.068465, acc: 48.44%] [G loss: 4.112257]\n",
      "epoch:25 step:19970 [D loss: 0.850419, acc: 50.00%] [G loss: 4.458735]\n",
      "epoch:25 step:19971 [D loss: 0.272325, acc: 96.09%] [G loss: 2.813522]\n",
      "epoch:25 step:19972 [D loss: 1.145233, acc: 50.00%] [G loss: 3.621994]\n",
      "epoch:25 step:19973 [D loss: 0.532754, acc: 67.97%] [G loss: 3.621002]\n",
      "epoch:25 step:19974 [D loss: 0.689311, acc: 53.91%] [G loss: 3.355159]\n",
      "epoch:25 step:19975 [D loss: 0.607117, acc: 64.84%] [G loss: 2.218049]\n",
      "epoch:25 step:19976 [D loss: 0.793311, acc: 43.75%] [G loss: 2.830013]\n",
      "epoch:25 step:19977 [D loss: 0.425474, acc: 76.56%] [G loss: 2.754227]\n",
      "epoch:25 step:19978 [D loss: 1.058524, acc: 48.44%] [G loss: 5.241670]\n",
      "epoch:25 step:19979 [D loss: 0.065552, acc: 100.00%] [G loss: 4.324979]\n",
      "epoch:25 step:19980 [D loss: 0.269943, acc: 97.66%] [G loss: 3.203342]\n",
      "epoch:25 step:19981 [D loss: 0.330377, acc: 92.97%] [G loss: 2.760980]\n",
      "epoch:25 step:19982 [D loss: 1.058163, acc: 35.16%] [G loss: 2.074904]\n",
      "epoch:25 step:19983 [D loss: 0.225853, acc: 96.88%] [G loss: 5.905228]\n",
      "epoch:25 step:19984 [D loss: 0.472890, acc: 82.81%] [G loss: 4.197126]\n",
      "epoch:25 step:19985 [D loss: 0.226326, acc: 97.66%] [G loss: 3.176616]\n",
      "epoch:25 step:19986 [D loss: 0.720005, acc: 57.03%] [G loss: 4.241923]\n",
      "epoch:25 step:19987 [D loss: 0.293460, acc: 93.75%] [G loss: 3.056868]\n",
      "epoch:25 step:19988 [D loss: 0.192741, acc: 96.88%] [G loss: 4.017534]\n",
      "epoch:25 step:19989 [D loss: 0.844575, acc: 43.75%] [G loss: 2.332576]\n",
      "epoch:25 step:19990 [D loss: 0.423478, acc: 88.28%] [G loss: 2.467977]\n",
      "epoch:25 step:19991 [D loss: 0.033441, acc: 100.00%] [G loss: 6.514912]\n",
      "epoch:25 step:19992 [D loss: 0.697829, acc: 56.25%] [G loss: 4.588000]\n",
      "epoch:25 step:19993 [D loss: 0.686132, acc: 54.69%] [G loss: 3.880756]\n",
      "epoch:25 step:19994 [D loss: 0.702519, acc: 53.91%] [G loss: 4.380334]\n",
      "epoch:25 step:19995 [D loss: 0.156495, acc: 100.00%] [G loss: 4.614146]\n",
      "epoch:25 step:19996 [D loss: 0.903965, acc: 51.56%] [G loss: 3.861646]\n",
      "epoch:25 step:19997 [D loss: 0.897087, acc: 39.06%] [G loss: 4.165631]\n",
      "epoch:25 step:19998 [D loss: 1.052806, acc: 38.28%] [G loss: 2.577252]\n",
      "epoch:25 step:19999 [D loss: 0.104584, acc: 100.00%] [G loss: 3.522381]\n",
      "epoch:25 step:20000 [D loss: 0.229360, acc: 96.09%] [G loss: 4.426379]\n",
      "##############\n",
      "[0.85278952 0.86615438 0.82412124 0.82346599 0.81494939 0.82271262\n",
      " 0.90806093 0.84487241 0.80609821 0.85296719]\n",
      "##########\n",
      "epoch:25 step:20001 [D loss: 0.372140, acc: 91.41%] [G loss: 4.025195]\n",
      "epoch:25 step:20002 [D loss: 0.139024, acc: 100.00%] [G loss: 3.457634]\n",
      "epoch:25 step:20003 [D loss: 0.259608, acc: 92.19%] [G loss: 2.821137]\n",
      "epoch:25 step:20004 [D loss: 0.656959, acc: 60.16%] [G loss: 2.342356]\n",
      "epoch:25 step:20005 [D loss: 0.744818, acc: 56.25%] [G loss: 3.963186]\n",
      "epoch:25 step:20006 [D loss: 0.146311, acc: 98.44%] [G loss: 4.272621]\n",
      "epoch:25 step:20007 [D loss: 0.734710, acc: 51.56%] [G loss: 3.357839]\n",
      "epoch:25 step:20008 [D loss: 0.635979, acc: 59.38%] [G loss: 2.592997]\n",
      "epoch:25 step:20009 [D loss: 1.010092, acc: 39.06%] [G loss: 3.158693]\n",
      "epoch:25 step:20010 [D loss: 0.383747, acc: 89.84%] [G loss: 2.653786]\n",
      "epoch:25 step:20011 [D loss: 0.347408, acc: 96.09%] [G loss: 3.714654]\n",
      "epoch:25 step:20012 [D loss: 0.335727, acc: 84.38%] [G loss: 3.601224]\n",
      "epoch:25 step:20013 [D loss: 0.198033, acc: 99.22%] [G loss: 4.199797]\n",
      "epoch:25 step:20014 [D loss: 0.258401, acc: 92.97%] [G loss: 3.340505]\n",
      "epoch:25 step:20015 [D loss: 0.471287, acc: 70.31%] [G loss: 3.891432]\n",
      "epoch:25 step:20016 [D loss: 0.200170, acc: 98.44%] [G loss: 5.479753]\n",
      "epoch:25 step:20017 [D loss: 0.240168, acc: 100.00%] [G loss: 3.722220]\n",
      "epoch:25 step:20018 [D loss: 0.147823, acc: 100.00%] [G loss: 3.696579]\n",
      "epoch:25 step:20019 [D loss: 0.366162, acc: 92.19%] [G loss: 3.633173]\n",
      "epoch:25 step:20020 [D loss: 0.301598, acc: 95.31%] [G loss: 3.107862]\n",
      "epoch:25 step:20021 [D loss: 0.231730, acc: 98.44%] [G loss: 2.631991]\n",
      "epoch:25 step:20022 [D loss: 0.344262, acc: 85.16%] [G loss: 4.968971]\n",
      "epoch:25 step:20023 [D loss: 0.325928, acc: 96.09%] [G loss: 4.437917]\n",
      "epoch:25 step:20024 [D loss: 0.988634, acc: 28.12%] [G loss: 2.917441]\n",
      "epoch:25 step:20025 [D loss: 0.360256, acc: 89.06%] [G loss: 4.437551]\n",
      "epoch:25 step:20026 [D loss: 0.415258, acc: 88.28%] [G loss: 3.478612]\n",
      "epoch:25 step:20027 [D loss: 1.276197, acc: 7.81%] [G loss: 3.346439]\n",
      "epoch:25 step:20028 [D loss: 0.421463, acc: 85.94%] [G loss: 3.229770]\n",
      "epoch:25 step:20029 [D loss: 0.857644, acc: 39.84%] [G loss: 2.927992]\n",
      "epoch:25 step:20030 [D loss: 0.990739, acc: 51.56%] [G loss: 2.983764]\n",
      "epoch:25 step:20031 [D loss: 0.270469, acc: 98.44%] [G loss: 3.766843]\n",
      "epoch:25 step:20032 [D loss: 0.396440, acc: 86.72%] [G loss: 2.114496]\n",
      "epoch:25 step:20033 [D loss: 0.540730, acc: 67.97%] [G loss: 3.737496]\n",
      "epoch:25 step:20034 [D loss: 0.530633, acc: 68.75%] [G loss: 2.737595]\n",
      "epoch:25 step:20035 [D loss: 0.369507, acc: 90.62%] [G loss: 4.082461]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:25 step:20036 [D loss: 0.117836, acc: 100.00%] [G loss: 6.397590]\n",
      "epoch:25 step:20037 [D loss: 0.238671, acc: 90.62%] [G loss: 5.343687]\n",
      "epoch:25 step:20038 [D loss: 0.560534, acc: 67.19%] [G loss: 3.536076]\n",
      "epoch:25 step:20039 [D loss: 0.140377, acc: 100.00%] [G loss: 2.797779]\n",
      "epoch:25 step:20040 [D loss: 0.416787, acc: 88.28%] [G loss: 3.607813]\n",
      "epoch:25 step:20041 [D loss: 0.183655, acc: 100.00%] [G loss: 4.566918]\n",
      "epoch:25 step:20042 [D loss: 0.222717, acc: 96.09%] [G loss: 4.806666]\n",
      "epoch:25 step:20043 [D loss: 0.426007, acc: 84.38%] [G loss: 3.152812]\n",
      "epoch:25 step:20044 [D loss: 0.723917, acc: 53.91%] [G loss: 3.326401]\n",
      "epoch:25 step:20045 [D loss: 0.464118, acc: 79.69%] [G loss: 3.480337]\n",
      "epoch:25 step:20046 [D loss: 0.236377, acc: 95.31%] [G loss: 6.114208]\n",
      "epoch:25 step:20047 [D loss: 0.470929, acc: 71.88%] [G loss: 4.047146]\n",
      "epoch:25 step:20048 [D loss: 0.426255, acc: 79.69%] [G loss: 3.675810]\n",
      "epoch:25 step:20049 [D loss: 0.414987, acc: 89.84%] [G loss: 3.964818]\n",
      "epoch:25 step:20050 [D loss: 0.552520, acc: 64.84%] [G loss: 3.458394]\n",
      "epoch:25 step:20051 [D loss: 0.638010, acc: 64.84%] [G loss: 2.614467]\n",
      "epoch:25 step:20052 [D loss: 0.177588, acc: 100.00%] [G loss: 3.571659]\n",
      "epoch:25 step:20053 [D loss: 0.258002, acc: 97.66%] [G loss: 3.347575]\n",
      "epoch:25 step:20054 [D loss: 0.731693, acc: 52.34%] [G loss: 2.454090]\n",
      "epoch:25 step:20055 [D loss: 0.518439, acc: 76.56%] [G loss: 2.877381]\n",
      "epoch:25 step:20056 [D loss: 0.435957, acc: 81.25%] [G loss: 4.555233]\n",
      "epoch:25 step:20057 [D loss: 0.633968, acc: 67.97%] [G loss: 4.642147]\n",
      "epoch:25 step:20058 [D loss: 0.868696, acc: 45.31%] [G loss: 3.594561]\n",
      "epoch:25 step:20059 [D loss: 0.782400, acc: 51.56%] [G loss: 3.648922]\n",
      "epoch:25 step:20060 [D loss: 0.629761, acc: 57.03%] [G loss: 3.668995]\n",
      "epoch:25 step:20061 [D loss: 0.693553, acc: 55.47%] [G loss: 2.178363]\n",
      "epoch:25 step:20062 [D loss: 0.252307, acc: 97.66%] [G loss: 4.110599]\n",
      "epoch:25 step:20063 [D loss: 0.254456, acc: 97.66%] [G loss: 4.056295]\n",
      "epoch:25 step:20064 [D loss: 0.516152, acc: 71.09%] [G loss: 3.308830]\n",
      "epoch:25 step:20065 [D loss: 0.488346, acc: 66.41%] [G loss: 3.489246]\n",
      "epoch:25 step:20066 [D loss: 0.674143, acc: 57.81%] [G loss: 3.321354]\n",
      "epoch:25 step:20067 [D loss: 0.315243, acc: 88.28%] [G loss: 4.897298]\n",
      "epoch:25 step:20068 [D loss: 0.369807, acc: 90.62%] [G loss: 3.415483]\n",
      "epoch:25 step:20069 [D loss: 0.559472, acc: 67.97%] [G loss: 2.985363]\n",
      "epoch:25 step:20070 [D loss: 0.098829, acc: 100.00%] [G loss: 3.458373]\n",
      "epoch:25 step:20071 [D loss: 0.687861, acc: 60.94%] [G loss: 4.109797]\n",
      "epoch:25 step:20072 [D loss: 0.155136, acc: 100.00%] [G loss: 4.967103]\n",
      "epoch:25 step:20073 [D loss: 1.399577, acc: 10.94%] [G loss: 2.788615]\n",
      "epoch:25 step:20074 [D loss: 0.274071, acc: 96.88%] [G loss: 2.221167]\n",
      "epoch:25 step:20075 [D loss: 0.322822, acc: 85.16%] [G loss: 3.222791]\n",
      "epoch:25 step:20076 [D loss: 0.518521, acc: 69.53%] [G loss: 4.411982]\n",
      "epoch:25 step:20077 [D loss: 0.373085, acc: 79.69%] [G loss: 5.220963]\n",
      "epoch:25 step:20078 [D loss: 0.163023, acc: 99.22%] [G loss: 3.807530]\n",
      "epoch:25 step:20079 [D loss: 0.388969, acc: 89.84%] [G loss: 3.094060]\n",
      "epoch:25 step:20080 [D loss: 0.021535, acc: 100.00%] [G loss: 6.239674]\n",
      "epoch:25 step:20081 [D loss: 0.930056, acc: 47.66%] [G loss: 3.953100]\n",
      "epoch:25 step:20082 [D loss: 0.519829, acc: 64.06%] [G loss: 4.010922]\n",
      "epoch:25 step:20083 [D loss: 0.319230, acc: 93.75%] [G loss: 3.170402]\n",
      "epoch:25 step:20084 [D loss: 0.474081, acc: 73.44%] [G loss: 4.002476]\n",
      "epoch:25 step:20085 [D loss: 0.150809, acc: 98.44%] [G loss: 4.634817]\n",
      "epoch:25 step:20086 [D loss: 0.282132, acc: 93.75%] [G loss: 3.664780]\n",
      "epoch:25 step:20087 [D loss: 0.402959, acc: 82.03%] [G loss: 3.819798]\n",
      "epoch:25 step:20088 [D loss: 0.516848, acc: 72.66%] [G loss: 3.996378]\n",
      "epoch:25 step:20089 [D loss: 0.265633, acc: 96.09%] [G loss: 4.692948]\n",
      "epoch:25 step:20090 [D loss: 0.684929, acc: 57.81%] [G loss: 2.934366]\n",
      "epoch:25 step:20091 [D loss: 0.507175, acc: 78.91%] [G loss: 3.788781]\n",
      "epoch:25 step:20092 [D loss: 0.627481, acc: 63.28%] [G loss: 2.874224]\n",
      "epoch:25 step:20093 [D loss: 0.453623, acc: 78.12%] [G loss: 2.555286]\n",
      "epoch:25 step:20094 [D loss: 0.496704, acc: 76.56%] [G loss: 4.248430]\n",
      "epoch:25 step:20095 [D loss: 0.263060, acc: 96.88%] [G loss: 3.063911]\n",
      "epoch:25 step:20096 [D loss: 0.305234, acc: 92.97%] [G loss: 3.674102]\n",
      "epoch:25 step:20097 [D loss: 0.341978, acc: 91.41%] [G loss: 5.048945]\n",
      "epoch:25 step:20098 [D loss: 0.656959, acc: 59.38%] [G loss: 2.961698]\n",
      "epoch:25 step:20099 [D loss: 1.117838, acc: 50.00%] [G loss: 4.767257]\n",
      "epoch:25 step:20100 [D loss: 0.711870, acc: 58.59%] [G loss: 3.154216]\n",
      "epoch:25 step:20101 [D loss: 0.155299, acc: 98.44%] [G loss: 2.074664]\n",
      "epoch:25 step:20102 [D loss: 0.392424, acc: 89.06%] [G loss: 3.806167]\n",
      "epoch:25 step:20103 [D loss: 0.565708, acc: 61.72%] [G loss: 4.314336]\n",
      "epoch:25 step:20104 [D loss: 0.528387, acc: 71.88%] [G loss: 2.569624]\n",
      "epoch:25 step:20105 [D loss: 0.304082, acc: 96.88%] [G loss: 3.314862]\n",
      "epoch:25 step:20106 [D loss: 0.391698, acc: 86.72%] [G loss: 4.970800]\n",
      "epoch:25 step:20107 [D loss: 0.683285, acc: 59.38%] [G loss: 4.809561]\n",
      "epoch:25 step:20108 [D loss: 0.222313, acc: 96.88%] [G loss: 3.086916]\n",
      "epoch:25 step:20109 [D loss: 0.360465, acc: 85.16%] [G loss: 2.926754]\n",
      "epoch:25 step:20110 [D loss: 0.124756, acc: 100.00%] [G loss: 3.828969]\n",
      "epoch:25 step:20111 [D loss: 0.243155, acc: 97.66%] [G loss: 4.029707]\n",
      "epoch:25 step:20112 [D loss: 0.255051, acc: 93.75%] [G loss: 3.084071]\n",
      "epoch:25 step:20113 [D loss: 0.289618, acc: 94.53%] [G loss: 7.392167]\n",
      "epoch:25 step:20114 [D loss: 0.280122, acc: 95.31%] [G loss: 4.853794]\n",
      "epoch:25 step:20115 [D loss: 0.081953, acc: 100.00%] [G loss: 6.421322]\n",
      "epoch:25 step:20116 [D loss: 0.731561, acc: 60.94%] [G loss: 3.867042]\n",
      "epoch:25 step:20117 [D loss: 0.649016, acc: 61.72%] [G loss: 5.611589]\n",
      "epoch:25 step:20118 [D loss: 1.390466, acc: 20.31%] [G loss: 3.234485]\n",
      "epoch:25 step:20119 [D loss: 0.534400, acc: 77.34%] [G loss: 5.581470]\n",
      "epoch:25 step:20120 [D loss: 0.252500, acc: 96.88%] [G loss: 2.911171]\n",
      "epoch:25 step:20121 [D loss: 0.634668, acc: 61.72%] [G loss: 4.485758]\n",
      "epoch:25 step:20122 [D loss: 0.570710, acc: 69.53%] [G loss: 2.702508]\n",
      "epoch:25 step:20123 [D loss: 0.138763, acc: 97.66%] [G loss: 4.108168]\n",
      "epoch:25 step:20124 [D loss: 1.009825, acc: 28.91%] [G loss: 3.619517]\n",
      "epoch:25 step:20125 [D loss: 0.189876, acc: 96.88%] [G loss: 2.675822]\n",
      "epoch:25 step:20126 [D loss: 1.221997, acc: 46.88%] [G loss: 3.809839]\n",
      "epoch:25 step:20127 [D loss: 0.344536, acc: 94.53%] [G loss: 2.720391]\n",
      "epoch:25 step:20128 [D loss: 0.624002, acc: 60.94%] [G loss: 3.095378]\n",
      "epoch:25 step:20129 [D loss: 0.526140, acc: 64.84%] [G loss: 4.230888]\n",
      "epoch:25 step:20130 [D loss: 0.961788, acc: 43.75%] [G loss: 3.023733]\n",
      "epoch:25 step:20131 [D loss: 0.940787, acc: 35.94%] [G loss: 5.541165]\n",
      "epoch:25 step:20132 [D loss: 0.182350, acc: 98.44%] [G loss: 3.990354]\n",
      "epoch:25 step:20133 [D loss: 0.545775, acc: 69.53%] [G loss: 3.007520]\n",
      "epoch:25 step:20134 [D loss: 0.319405, acc: 92.19%] [G loss: 2.859158]\n",
      "epoch:25 step:20135 [D loss: 0.220095, acc: 93.75%] [G loss: 5.621936]\n",
      "epoch:25 step:20136 [D loss: 0.313569, acc: 95.31%] [G loss: 4.783509]\n",
      "epoch:25 step:20137 [D loss: 0.427440, acc: 82.81%] [G loss: 4.594507]\n",
      "epoch:25 step:20138 [D loss: 0.235669, acc: 96.88%] [G loss: 2.500771]\n",
      "epoch:25 step:20139 [D loss: 0.202131, acc: 99.22%] [G loss: 4.192944]\n",
      "epoch:25 step:20140 [D loss: 0.577344, acc: 73.44%] [G loss: 3.759020]\n",
      "epoch:25 step:20141 [D loss: 0.680379, acc: 58.59%] [G loss: 4.393916]\n",
      "epoch:25 step:20142 [D loss: 0.567881, acc: 76.56%] [G loss: 3.736717]\n",
      "epoch:25 step:20143 [D loss: 0.152636, acc: 98.44%] [G loss: 3.565460]\n",
      "epoch:25 step:20144 [D loss: 0.491973, acc: 71.88%] [G loss: 2.842789]\n",
      "epoch:25 step:20145 [D loss: 0.977815, acc: 50.78%] [G loss: 3.581066]\n",
      "epoch:25 step:20146 [D loss: 0.323026, acc: 92.97%] [G loss: 2.747075]\n",
      "epoch:25 step:20147 [D loss: 0.767608, acc: 57.03%] [G loss: 3.613387]\n",
      "epoch:25 step:20148 [D loss: 0.403612, acc: 88.28%] [G loss: 3.730595]\n",
      "epoch:25 step:20149 [D loss: 0.059239, acc: 100.00%] [G loss: 5.592374]\n",
      "epoch:25 step:20150 [D loss: 0.532073, acc: 64.06%] [G loss: 4.130886]\n",
      "epoch:25 step:20151 [D loss: 0.389459, acc: 85.94%] [G loss: 3.167413]\n",
      "epoch:25 step:20152 [D loss: 0.998591, acc: 28.12%] [G loss: 2.507422]\n",
      "epoch:25 step:20153 [D loss: 0.410705, acc: 91.41%] [G loss: 5.779529]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:25 step:20154 [D loss: 0.717056, acc: 54.69%] [G loss: 4.497029]\n",
      "epoch:25 step:20155 [D loss: 0.093877, acc: 100.00%] [G loss: 3.586708]\n",
      "epoch:25 step:20156 [D loss: 0.436726, acc: 71.09%] [G loss: 3.420791]\n",
      "epoch:25 step:20157 [D loss: 0.368710, acc: 92.19%] [G loss: 4.293470]\n",
      "epoch:25 step:20158 [D loss: 0.619609, acc: 56.25%] [G loss: 3.865756]\n",
      "epoch:25 step:20159 [D loss: 0.706926, acc: 56.25%] [G loss: 3.122027]\n",
      "epoch:25 step:20160 [D loss: 0.617200, acc: 60.94%] [G loss: 4.180117]\n",
      "epoch:25 step:20161 [D loss: 0.902126, acc: 43.75%] [G loss: 4.318019]\n",
      "epoch:25 step:20162 [D loss: 0.333467, acc: 86.72%] [G loss: 4.752135]\n",
      "epoch:25 step:20163 [D loss: 0.283643, acc: 92.97%] [G loss: 4.056064]\n",
      "epoch:25 step:20164 [D loss: 0.799647, acc: 42.97%] [G loss: 4.972705]\n",
      "epoch:25 step:20165 [D loss: 0.494314, acc: 78.12%] [G loss: 2.954494]\n",
      "epoch:25 step:20166 [D loss: 0.483025, acc: 78.12%] [G loss: 1.911360]\n",
      "epoch:25 step:20167 [D loss: 0.296500, acc: 91.41%] [G loss: 3.538922]\n",
      "epoch:25 step:20168 [D loss: 0.439160, acc: 80.47%] [G loss: 2.724505]\n",
      "epoch:25 step:20169 [D loss: 0.174567, acc: 99.22%] [G loss: 2.151319]\n",
      "epoch:25 step:20170 [D loss: 0.443387, acc: 83.59%] [G loss: 3.848498]\n",
      "epoch:25 step:20171 [D loss: 0.678299, acc: 54.69%] [G loss: 3.154727]\n",
      "epoch:25 step:20172 [D loss: 0.201526, acc: 97.66%] [G loss: 3.731630]\n",
      "epoch:25 step:20173 [D loss: 0.457117, acc: 84.38%] [G loss: 4.397542]\n",
      "epoch:25 step:20174 [D loss: 0.564349, acc: 74.22%] [G loss: 4.577924]\n",
      "epoch:25 step:20175 [D loss: 0.297080, acc: 96.88%] [G loss: 3.649159]\n",
      "epoch:25 step:20176 [D loss: 0.666877, acc: 53.91%] [G loss: 4.746065]\n",
      "epoch:25 step:20177 [D loss: 0.169962, acc: 98.44%] [G loss: 2.636977]\n",
      "epoch:25 step:20178 [D loss: 0.162139, acc: 100.00%] [G loss: 3.459831]\n",
      "epoch:25 step:20179 [D loss: 0.148043, acc: 99.22%] [G loss: 3.708662]\n",
      "epoch:25 step:20180 [D loss: 0.337733, acc: 82.03%] [G loss: 4.615501]\n",
      "epoch:25 step:20181 [D loss: 0.997067, acc: 46.09%] [G loss: 3.904110]\n",
      "epoch:25 step:20182 [D loss: 0.472542, acc: 84.38%] [G loss: 4.813173]\n",
      "epoch:25 step:20183 [D loss: 0.112811, acc: 99.22%] [G loss: 5.375581]\n",
      "epoch:25 step:20184 [D loss: 0.421331, acc: 71.09%] [G loss: 4.738159]\n",
      "epoch:25 step:20185 [D loss: 0.724684, acc: 50.00%] [G loss: 2.990932]\n",
      "epoch:25 step:20186 [D loss: 0.701899, acc: 60.16%] [G loss: 3.452930]\n",
      "epoch:25 step:20187 [D loss: 0.540747, acc: 67.19%] [G loss: 4.273640]\n",
      "epoch:25 step:20188 [D loss: 0.277296, acc: 92.97%] [G loss: 5.670251]\n",
      "epoch:25 step:20189 [D loss: 0.230925, acc: 96.88%] [G loss: 4.863491]\n",
      "epoch:25 step:20190 [D loss: 0.832728, acc: 53.12%] [G loss: 4.751985]\n",
      "epoch:25 step:20191 [D loss: 0.406931, acc: 88.28%] [G loss: 2.687747]\n",
      "epoch:25 step:20192 [D loss: 0.098361, acc: 99.22%] [G loss: 5.196869]\n",
      "epoch:25 step:20193 [D loss: 0.835569, acc: 51.56%] [G loss: 3.899585]\n",
      "epoch:25 step:20194 [D loss: 0.283333, acc: 98.44%] [G loss: 3.102589]\n",
      "epoch:25 step:20195 [D loss: 0.564008, acc: 67.97%] [G loss: 1.720324]\n",
      "epoch:25 step:20196 [D loss: 0.315109, acc: 92.97%] [G loss: 5.382173]\n",
      "epoch:25 step:20197 [D loss: 1.047050, acc: 46.88%] [G loss: 3.495322]\n",
      "epoch:25 step:20198 [D loss: 0.184725, acc: 98.44%] [G loss: 6.487098]\n",
      "epoch:25 step:20199 [D loss: 0.323580, acc: 89.06%] [G loss: 4.141870]\n",
      "epoch:25 step:20200 [D loss: 0.230577, acc: 96.09%] [G loss: 4.559797]\n",
      "##############\n",
      "[0.85364309 0.87249749 0.81623728 0.81692429 0.78520935 0.82034996\n",
      " 0.89023753 0.80514345 0.81885748 0.83303895]\n",
      "##########\n",
      "epoch:25 step:20201 [D loss: 0.204679, acc: 100.00%] [G loss: 4.248850]\n",
      "epoch:25 step:20202 [D loss: 0.195503, acc: 100.00%] [G loss: 4.639270]\n",
      "epoch:25 step:20203 [D loss: 0.571730, acc: 65.62%] [G loss: 4.520703]\n",
      "epoch:25 step:20204 [D loss: 0.234985, acc: 99.22%] [G loss: 3.997894]\n",
      "epoch:25 step:20205 [D loss: 0.193249, acc: 99.22%] [G loss: 3.724488]\n",
      "epoch:25 step:20206 [D loss: 0.260449, acc: 92.97%] [G loss: 4.304944]\n",
      "epoch:25 step:20207 [D loss: 0.267332, acc: 95.31%] [G loss: 4.548412]\n",
      "epoch:25 step:20208 [D loss: 0.878474, acc: 35.16%] [G loss: 2.335335]\n",
      "epoch:25 step:20209 [D loss: 0.700944, acc: 52.34%] [G loss: 3.574414]\n",
      "epoch:25 step:20210 [D loss: 0.379420, acc: 87.50%] [G loss: 3.453399]\n",
      "epoch:25 step:20211 [D loss: 0.087000, acc: 99.22%] [G loss: 3.591220]\n",
      "epoch:25 step:20212 [D loss: 0.566457, acc: 71.88%] [G loss: 4.411864]\n",
      "epoch:25 step:20213 [D loss: 0.205393, acc: 100.00%] [G loss: 2.490867]\n",
      "epoch:25 step:20214 [D loss: 0.576909, acc: 75.00%] [G loss: 4.263891]\n",
      "epoch:25 step:20215 [D loss: 0.038922, acc: 100.00%] [G loss: 7.977961]\n",
      "epoch:25 step:20216 [D loss: 0.106263, acc: 100.00%] [G loss: 2.448952]\n",
      "epoch:25 step:20217 [D loss: 1.636153, acc: 4.69%] [G loss: 4.504291]\n",
      "epoch:25 step:20218 [D loss: 1.189674, acc: 30.47%] [G loss: 1.805384]\n",
      "epoch:25 step:20219 [D loss: 0.064666, acc: 100.00%] [G loss: 6.504351]\n",
      "epoch:25 step:20220 [D loss: 0.535051, acc: 74.22%] [G loss: 2.757030]\n",
      "epoch:25 step:20221 [D loss: 0.483317, acc: 81.25%] [G loss: 3.540384]\n",
      "epoch:25 step:20222 [D loss: 0.513898, acc: 70.31%] [G loss: 3.804616]\n",
      "epoch:25 step:20223 [D loss: 0.104586, acc: 100.00%] [G loss: 3.279994]\n",
      "epoch:25 step:20224 [D loss: 0.309563, acc: 86.72%] [G loss: 4.851478]\n",
      "epoch:25 step:20225 [D loss: 1.242467, acc: 50.00%] [G loss: 2.198797]\n",
      "epoch:25 step:20226 [D loss: 0.376979, acc: 89.06%] [G loss: 3.305613]\n",
      "epoch:25 step:20227 [D loss: 0.203157, acc: 98.44%] [G loss: 3.161534]\n",
      "epoch:25 step:20228 [D loss: 0.392924, acc: 84.38%] [G loss: 2.337426]\n",
      "epoch:25 step:20229 [D loss: 0.272932, acc: 94.53%] [G loss: 3.836071]\n",
      "epoch:25 step:20230 [D loss: 0.948853, acc: 51.56%] [G loss: 4.017948]\n",
      "epoch:25 step:20231 [D loss: 0.184834, acc: 96.88%] [G loss: 5.468614]\n",
      "epoch:25 step:20232 [D loss: 0.676649, acc: 54.69%] [G loss: 4.616317]\n",
      "epoch:25 step:20233 [D loss: 0.098198, acc: 100.00%] [G loss: 4.704639]\n",
      "epoch:25 step:20234 [D loss: 0.717555, acc: 57.81%] [G loss: 2.974886]\n",
      "epoch:25 step:20235 [D loss: 0.261614, acc: 97.66%] [G loss: 3.190915]\n",
      "epoch:25 step:20236 [D loss: 0.027405, acc: 100.00%] [G loss: 5.649749]\n",
      "epoch:25 step:20237 [D loss: 0.153593, acc: 100.00%] [G loss: 2.780262]\n",
      "epoch:25 step:20238 [D loss: 0.484097, acc: 67.19%] [G loss: 4.638895]\n",
      "epoch:25 step:20239 [D loss: 0.554191, acc: 64.84%] [G loss: 3.054134]\n",
      "epoch:25 step:20240 [D loss: 0.772898, acc: 55.47%] [G loss: 3.531523]\n",
      "epoch:25 step:20241 [D loss: 0.349165, acc: 89.06%] [G loss: 5.248710]\n",
      "epoch:25 step:20242 [D loss: 0.329672, acc: 96.09%] [G loss: 3.386781]\n",
      "epoch:25 step:20243 [D loss: 0.657054, acc: 62.50%] [G loss: 5.078695]\n",
      "epoch:25 step:20244 [D loss: 0.450926, acc: 87.50%] [G loss: 3.169619]\n",
      "epoch:25 step:20245 [D loss: 0.268270, acc: 98.44%] [G loss: 3.437533]\n",
      "epoch:25 step:20246 [D loss: 0.181739, acc: 98.44%] [G loss: 3.877219]\n",
      "epoch:25 step:20247 [D loss: 0.635387, acc: 61.72%] [G loss: 5.004559]\n",
      "epoch:25 step:20248 [D loss: 0.024079, acc: 100.00%] [G loss: 5.240637]\n",
      "epoch:25 step:20249 [D loss: 0.446746, acc: 81.25%] [G loss: 2.473157]\n",
      "epoch:25 step:20250 [D loss: 0.427624, acc: 80.47%] [G loss: 3.591286]\n",
      "epoch:25 step:20251 [D loss: 0.088752, acc: 99.22%] [G loss: 5.084129]\n",
      "epoch:25 step:20252 [D loss: 0.994237, acc: 40.62%] [G loss: 2.253714]\n",
      "epoch:25 step:20253 [D loss: 0.686348, acc: 57.81%] [G loss: 2.997573]\n",
      "epoch:25 step:20254 [D loss: 0.609564, acc: 71.88%] [G loss: 3.551739]\n",
      "epoch:25 step:20255 [D loss: 0.269930, acc: 86.72%] [G loss: 6.301662]\n",
      "epoch:25 step:20256 [D loss: 0.539135, acc: 72.66%] [G loss: 3.723454]\n",
      "epoch:25 step:20257 [D loss: 0.362918, acc: 80.47%] [G loss: 4.637419]\n",
      "epoch:25 step:20258 [D loss: 0.081610, acc: 100.00%] [G loss: 3.955702]\n",
      "epoch:25 step:20259 [D loss: 1.012941, acc: 44.53%] [G loss: 3.728522]\n",
      "epoch:25 step:20260 [D loss: 0.414347, acc: 75.00%] [G loss: 4.453211]\n",
      "epoch:25 step:20261 [D loss: 0.290456, acc: 92.97%] [G loss: 4.344198]\n",
      "epoch:25 step:20262 [D loss: 0.945708, acc: 42.97%] [G loss: 5.142829]\n",
      "epoch:25 step:20263 [D loss: 0.144044, acc: 99.22%] [G loss: 5.631406]\n",
      "epoch:25 step:20264 [D loss: 0.172559, acc: 98.44%] [G loss: 3.909035]\n",
      "epoch:25 step:20265 [D loss: 0.537674, acc: 70.31%] [G loss: 3.984424]\n",
      "epoch:25 step:20266 [D loss: 0.410433, acc: 92.97%] [G loss: 2.398843]\n",
      "epoch:25 step:20267 [D loss: 0.424115, acc: 85.16%] [G loss: 3.727792]\n",
      "epoch:25 step:20268 [D loss: 0.531081, acc: 73.44%] [G loss: 4.260381]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:25 step:20269 [D loss: 0.540737, acc: 71.09%] [G loss: 3.600205]\n",
      "epoch:25 step:20270 [D loss: 0.449352, acc: 83.59%] [G loss: 2.483843]\n",
      "epoch:25 step:20271 [D loss: 0.307855, acc: 92.19%] [G loss: 5.505654]\n",
      "epoch:25 step:20272 [D loss: 0.382621, acc: 89.84%] [G loss: 2.834917]\n",
      "epoch:25 step:20273 [D loss: 0.879215, acc: 50.78%] [G loss: 3.636038]\n",
      "epoch:25 step:20274 [D loss: 0.276137, acc: 96.09%] [G loss: 3.116551]\n",
      "epoch:25 step:20275 [D loss: 1.065379, acc: 41.41%] [G loss: 2.065439]\n",
      "epoch:25 step:20276 [D loss: 0.252226, acc: 96.88%] [G loss: 2.449929]\n",
      "epoch:25 step:20277 [D loss: 0.287316, acc: 96.09%] [G loss: 3.479046]\n",
      "epoch:25 step:20278 [D loss: 0.357223, acc: 82.81%] [G loss: 5.172449]\n",
      "epoch:25 step:20279 [D loss: 1.150541, acc: 19.53%] [G loss: 2.177781]\n",
      "epoch:25 step:20280 [D loss: 0.482941, acc: 74.22%] [G loss: 2.727565]\n",
      "epoch:25 step:20281 [D loss: 0.205863, acc: 99.22%] [G loss: 3.168827]\n",
      "epoch:25 step:20282 [D loss: 0.646895, acc: 63.28%] [G loss: 2.996145]\n",
      "epoch:25 step:20283 [D loss: 0.496833, acc: 79.69%] [G loss: 5.921378]\n",
      "epoch:25 step:20284 [D loss: 0.718030, acc: 53.12%] [G loss: 4.396524]\n",
      "epoch:25 step:20285 [D loss: 0.058279, acc: 100.00%] [G loss: 7.015110]\n",
      "epoch:25 step:20286 [D loss: 0.781115, acc: 56.25%] [G loss: 5.632430]\n",
      "epoch:25 step:20287 [D loss: 0.259646, acc: 95.31%] [G loss: 4.665485]\n",
      "epoch:25 step:20288 [D loss: 0.239664, acc: 93.75%] [G loss: 2.559530]\n",
      "epoch:25 step:20289 [D loss: 0.867172, acc: 48.44%] [G loss: 3.962561]\n",
      "epoch:25 step:20290 [D loss: 0.191895, acc: 99.22%] [G loss: 5.138085]\n",
      "epoch:25 step:20291 [D loss: 0.438130, acc: 78.12%] [G loss: 3.686928]\n",
      "epoch:25 step:20292 [D loss: 0.371813, acc: 83.59%] [G loss: 3.536973]\n",
      "epoch:25 step:20293 [D loss: 0.445058, acc: 72.66%] [G loss: 3.671627]\n",
      "epoch:25 step:20294 [D loss: 0.682811, acc: 53.12%] [G loss: 3.999482]\n",
      "epoch:25 step:20295 [D loss: 1.362988, acc: 7.03%] [G loss: 3.878780]\n",
      "epoch:25 step:20296 [D loss: 0.608040, acc: 68.75%] [G loss: 3.007759]\n",
      "epoch:25 step:20297 [D loss: 0.302460, acc: 94.53%] [G loss: 2.921759]\n",
      "epoch:25 step:20298 [D loss: 0.103177, acc: 100.00%] [G loss: 6.176599]\n",
      "epoch:25 step:20299 [D loss: 0.575043, acc: 66.41%] [G loss: 2.820798]\n",
      "epoch:25 step:20300 [D loss: 0.441494, acc: 82.81%] [G loss: 3.348737]\n",
      "epoch:25 step:20301 [D loss: 1.070653, acc: 36.72%] [G loss: 5.344987]\n",
      "epoch:25 step:20302 [D loss: 0.518821, acc: 63.28%] [G loss: 4.533050]\n",
      "epoch:25 step:20303 [D loss: 0.719931, acc: 60.16%] [G loss: 3.520529]\n",
      "epoch:25 step:20304 [D loss: 0.375333, acc: 84.38%] [G loss: 3.910760]\n",
      "epoch:25 step:20305 [D loss: 0.572805, acc: 61.72%] [G loss: 4.155161]\n",
      "epoch:25 step:20306 [D loss: 0.025238, acc: 100.00%] [G loss: 5.324433]\n",
      "epoch:26 step:20307 [D loss: 0.711945, acc: 53.12%] [G loss: 3.919408]\n",
      "epoch:26 step:20308 [D loss: 0.101662, acc: 100.00%] [G loss: 4.706698]\n",
      "epoch:26 step:20309 [D loss: 0.429800, acc: 70.31%] [G loss: 2.965801]\n",
      "epoch:26 step:20310 [D loss: 0.272054, acc: 96.09%] [G loss: 3.108195]\n",
      "epoch:26 step:20311 [D loss: 0.331011, acc: 84.38%] [G loss: 5.431771]\n",
      "epoch:26 step:20312 [D loss: 0.292103, acc: 82.81%] [G loss: 4.956928]\n",
      "epoch:26 step:20313 [D loss: 0.060716, acc: 99.22%] [G loss: 4.020994]\n",
      "epoch:26 step:20314 [D loss: 0.565350, acc: 67.19%] [G loss: 3.338542]\n",
      "epoch:26 step:20315 [D loss: 0.160149, acc: 99.22%] [G loss: 2.338025]\n",
      "epoch:26 step:20316 [D loss: 0.409206, acc: 78.91%] [G loss: 3.407898]\n",
      "epoch:26 step:20317 [D loss: 0.173565, acc: 98.44%] [G loss: 4.261554]\n",
      "epoch:26 step:20318 [D loss: 0.861979, acc: 46.88%] [G loss: 1.944226]\n",
      "epoch:26 step:20319 [D loss: 0.116597, acc: 100.00%] [G loss: 5.585636]\n",
      "epoch:26 step:20320 [D loss: 0.231163, acc: 97.66%] [G loss: 2.674434]\n",
      "epoch:26 step:20321 [D loss: 0.251691, acc: 99.22%] [G loss: 6.294572]\n",
      "epoch:26 step:20322 [D loss: 0.311026, acc: 95.31%] [G loss: 4.587698]\n",
      "epoch:26 step:20323 [D loss: 0.288258, acc: 92.97%] [G loss: 5.644297]\n",
      "epoch:26 step:20324 [D loss: 0.369387, acc: 90.62%] [G loss: 3.452268]\n",
      "epoch:26 step:20325 [D loss: 0.122642, acc: 100.00%] [G loss: 3.968479]\n",
      "epoch:26 step:20326 [D loss: 0.458810, acc: 82.81%] [G loss: 2.794490]\n",
      "epoch:26 step:20327 [D loss: 0.201292, acc: 98.44%] [G loss: 5.151145]\n",
      "epoch:26 step:20328 [D loss: 0.587944, acc: 66.41%] [G loss: 5.256268]\n",
      "epoch:26 step:20329 [D loss: 0.369546, acc: 89.06%] [G loss: 4.938951]\n",
      "epoch:26 step:20330 [D loss: 0.286429, acc: 88.28%] [G loss: 2.621947]\n",
      "epoch:26 step:20331 [D loss: 1.079571, acc: 17.19%] [G loss: 4.950674]\n",
      "epoch:26 step:20332 [D loss: 0.280276, acc: 89.84%] [G loss: 4.858809]\n",
      "epoch:26 step:20333 [D loss: 0.208363, acc: 96.09%] [G loss: 4.138634]\n",
      "epoch:26 step:20334 [D loss: 1.488387, acc: 30.47%] [G loss: 2.214858]\n",
      "epoch:26 step:20335 [D loss: 0.287412, acc: 97.66%] [G loss: 5.269189]\n",
      "epoch:26 step:20336 [D loss: 0.104838, acc: 100.00%] [G loss: 4.908895]\n",
      "epoch:26 step:20337 [D loss: 0.144370, acc: 100.00%] [G loss: 2.936680]\n",
      "epoch:26 step:20338 [D loss: 0.258704, acc: 94.53%] [G loss: 3.924289]\n",
      "epoch:26 step:20339 [D loss: 0.245329, acc: 97.66%] [G loss: 4.886131]\n",
      "epoch:26 step:20340 [D loss: 0.128205, acc: 97.66%] [G loss: 5.947755]\n",
      "epoch:26 step:20341 [D loss: 0.280553, acc: 92.19%] [G loss: 2.691981]\n",
      "epoch:26 step:20342 [D loss: 0.505215, acc: 64.06%] [G loss: 2.518248]\n",
      "epoch:26 step:20343 [D loss: 0.251980, acc: 92.97%] [G loss: 4.555454]\n",
      "epoch:26 step:20344 [D loss: 1.409744, acc: 8.59%] [G loss: 4.756270]\n",
      "epoch:26 step:20345 [D loss: 0.140730, acc: 100.00%] [G loss: 3.758891]\n",
      "epoch:26 step:20346 [D loss: 0.225764, acc: 98.44%] [G loss: 3.893410]\n",
      "epoch:26 step:20347 [D loss: 0.290657, acc: 98.44%] [G loss: 3.062856]\n",
      "epoch:26 step:20348 [D loss: 0.678609, acc: 57.03%] [G loss: 4.292365]\n",
      "epoch:26 step:20349 [D loss: 1.248451, acc: 7.81%] [G loss: 2.321646]\n",
      "epoch:26 step:20350 [D loss: 2.656763, acc: 0.78%] [G loss: 2.734649]\n",
      "epoch:26 step:20351 [D loss: 0.275266, acc: 96.88%] [G loss: 3.322749]\n",
      "epoch:26 step:20352 [D loss: 0.304545, acc: 96.09%] [G loss: 2.466645]\n",
      "epoch:26 step:20353 [D loss: 0.588950, acc: 67.97%] [G loss: 3.576844]\n",
      "epoch:26 step:20354 [D loss: 0.283278, acc: 95.31%] [G loss: 3.512166]\n",
      "epoch:26 step:20355 [D loss: 0.467418, acc: 72.66%] [G loss: 3.118249]\n",
      "epoch:26 step:20356 [D loss: 0.780110, acc: 51.56%] [G loss: 3.027214]\n",
      "epoch:26 step:20357 [D loss: 0.754256, acc: 50.78%] [G loss: 3.428811]\n",
      "epoch:26 step:20358 [D loss: 0.106802, acc: 99.22%] [G loss: 5.101675]\n",
      "epoch:26 step:20359 [D loss: 0.424491, acc: 75.00%] [G loss: 4.344913]\n",
      "epoch:26 step:20360 [D loss: 0.252463, acc: 90.62%] [G loss: 6.424098]\n",
      "epoch:26 step:20361 [D loss: 0.086665, acc: 99.22%] [G loss: 4.355890]\n",
      "epoch:26 step:20362 [D loss: 0.368158, acc: 81.25%] [G loss: 3.697270]\n",
      "epoch:26 step:20363 [D loss: 0.138816, acc: 100.00%] [G loss: 4.351390]\n",
      "epoch:26 step:20364 [D loss: 0.613868, acc: 63.28%] [G loss: 3.725941]\n",
      "epoch:26 step:20365 [D loss: 0.254018, acc: 96.09%] [G loss: 3.150873]\n",
      "epoch:26 step:20366 [D loss: 0.318540, acc: 94.53%] [G loss: 3.901223]\n",
      "epoch:26 step:20367 [D loss: 0.858102, acc: 47.66%] [G loss: 3.234080]\n",
      "epoch:26 step:20368 [D loss: 0.640805, acc: 67.97%] [G loss: 6.677246]\n",
      "epoch:26 step:20369 [D loss: 0.127058, acc: 100.00%] [G loss: 3.079592]\n",
      "epoch:26 step:20370 [D loss: 0.387087, acc: 78.12%] [G loss: 3.405095]\n",
      "epoch:26 step:20371 [D loss: 0.537207, acc: 71.88%] [G loss: 4.303466]\n",
      "epoch:26 step:20372 [D loss: 0.333005, acc: 89.84%] [G loss: 2.381053]\n",
      "epoch:26 step:20373 [D loss: 1.057303, acc: 45.31%] [G loss: 3.268548]\n",
      "epoch:26 step:20374 [D loss: 0.224627, acc: 99.22%] [G loss: 2.945581]\n",
      "epoch:26 step:20375 [D loss: 0.361681, acc: 88.28%] [G loss: 3.536376]\n",
      "epoch:26 step:20376 [D loss: 0.433986, acc: 83.59%] [G loss: 4.753145]\n",
      "epoch:26 step:20377 [D loss: 0.990748, acc: 43.75%] [G loss: 3.755139]\n",
      "epoch:26 step:20378 [D loss: 0.344715, acc: 94.53%] [G loss: 4.479109]\n",
      "epoch:26 step:20379 [D loss: 0.648302, acc: 61.72%] [G loss: 3.267469]\n",
      "epoch:26 step:20380 [D loss: 0.295986, acc: 91.41%] [G loss: 3.788531]\n",
      "epoch:26 step:20381 [D loss: 0.904340, acc: 27.34%] [G loss: 3.219512]\n",
      "epoch:26 step:20382 [D loss: 0.744282, acc: 54.69%] [G loss: 5.646102]\n",
      "epoch:26 step:20383 [D loss: 0.639589, acc: 59.38%] [G loss: 5.483677]\n",
      "epoch:26 step:20384 [D loss: 0.290065, acc: 95.31%] [G loss: 1.968355]\n",
      "epoch:26 step:20385 [D loss: 0.222455, acc: 95.31%] [G loss: 2.725207]\n",
      "epoch:26 step:20386 [D loss: 0.393809, acc: 89.06%] [G loss: 4.286993]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:26 step:20387 [D loss: 0.080666, acc: 100.00%] [G loss: 4.221030]\n",
      "epoch:26 step:20388 [D loss: 0.201644, acc: 98.44%] [G loss: 3.574891]\n",
      "epoch:26 step:20389 [D loss: 0.200713, acc: 97.66%] [G loss: 3.081734]\n",
      "epoch:26 step:20390 [D loss: 0.791373, acc: 53.12%] [G loss: 3.429588]\n",
      "epoch:26 step:20391 [D loss: 0.117724, acc: 100.00%] [G loss: 5.578351]\n",
      "epoch:26 step:20392 [D loss: 0.967889, acc: 51.56%] [G loss: 4.203800]\n",
      "epoch:26 step:20393 [D loss: 0.296111, acc: 95.31%] [G loss: 3.821870]\n",
      "epoch:26 step:20394 [D loss: 0.284717, acc: 92.97%] [G loss: 3.867288]\n",
      "epoch:26 step:20395 [D loss: 0.813895, acc: 51.56%] [G loss: 4.949986]\n",
      "epoch:26 step:20396 [D loss: 0.259672, acc: 95.31%] [G loss: 3.796007]\n",
      "epoch:26 step:20397 [D loss: 0.398863, acc: 83.59%] [G loss: 2.781392]\n",
      "epoch:26 step:20398 [D loss: 1.591253, acc: 28.12%] [G loss: 7.076744]\n",
      "epoch:26 step:20399 [D loss: 0.191549, acc: 98.44%] [G loss: 4.074908]\n",
      "epoch:26 step:20400 [D loss: 0.557229, acc: 62.50%] [G loss: 5.279906]\n",
      "##############\n",
      "[0.86081881 0.87943861 0.81382171 0.83279146 0.80110304 0.84334028\n",
      " 0.90349558 0.85259469 0.82795124 0.82183901]\n",
      "##########\n",
      "epoch:26 step:20401 [D loss: 1.000696, acc: 49.22%] [G loss: 3.722882]\n",
      "epoch:26 step:20402 [D loss: 0.296754, acc: 98.44%] [G loss: 2.479504]\n",
      "epoch:26 step:20403 [D loss: 0.279292, acc: 89.84%] [G loss: 2.332614]\n",
      "epoch:26 step:20404 [D loss: 0.339799, acc: 92.97%] [G loss: 3.886595]\n",
      "epoch:26 step:20405 [D loss: 0.462541, acc: 79.69%] [G loss: 2.877621]\n",
      "epoch:26 step:20406 [D loss: 0.436272, acc: 82.03%] [G loss: 3.134047]\n",
      "epoch:26 step:20407 [D loss: 0.668823, acc: 60.16%] [G loss: 3.173823]\n",
      "epoch:26 step:20408 [D loss: 0.743860, acc: 51.56%] [G loss: 5.783922]\n",
      "epoch:26 step:20409 [D loss: 0.645652, acc: 56.25%] [G loss: 6.288435]\n",
      "epoch:26 step:20410 [D loss: 0.529166, acc: 73.44%] [G loss: 4.612520]\n",
      "epoch:26 step:20411 [D loss: 0.375720, acc: 80.47%] [G loss: 2.017782]\n",
      "epoch:26 step:20412 [D loss: 0.650769, acc: 63.28%] [G loss: 2.868645]\n",
      "epoch:26 step:20413 [D loss: 0.219121, acc: 99.22%] [G loss: 3.334316]\n",
      "epoch:26 step:20414 [D loss: 0.529989, acc: 83.59%] [G loss: 3.986758]\n",
      "epoch:26 step:20415 [D loss: 0.165820, acc: 99.22%] [G loss: 4.450576]\n",
      "epoch:26 step:20416 [D loss: 0.415084, acc: 89.06%] [G loss: 3.605998]\n",
      "epoch:26 step:20417 [D loss: 0.273614, acc: 95.31%] [G loss: 3.460116]\n",
      "epoch:26 step:20418 [D loss: 0.336818, acc: 96.09%] [G loss: 3.757534]\n",
      "epoch:26 step:20419 [D loss: 0.158564, acc: 99.22%] [G loss: 4.314010]\n",
      "epoch:26 step:20420 [D loss: 0.191553, acc: 98.44%] [G loss: 4.319942]\n",
      "epoch:26 step:20421 [D loss: 0.262997, acc: 87.50%] [G loss: 4.688530]\n",
      "epoch:26 step:20422 [D loss: 1.011572, acc: 50.00%] [G loss: 3.539956]\n",
      "epoch:26 step:20423 [D loss: 0.704014, acc: 53.12%] [G loss: 3.844553]\n",
      "epoch:26 step:20424 [D loss: 0.335823, acc: 85.94%] [G loss: 2.922565]\n",
      "epoch:26 step:20425 [D loss: 0.162953, acc: 100.00%] [G loss: 4.153886]\n",
      "epoch:26 step:20426 [D loss: 0.116853, acc: 98.44%] [G loss: 6.218077]\n",
      "epoch:26 step:20427 [D loss: 0.545910, acc: 62.50%] [G loss: 5.371485]\n",
      "epoch:26 step:20428 [D loss: 0.087777, acc: 100.00%] [G loss: 5.230896]\n",
      "epoch:26 step:20429 [D loss: 0.311523, acc: 90.62%] [G loss: 4.640425]\n",
      "epoch:26 step:20430 [D loss: 1.746802, acc: 3.91%] [G loss: 3.190397]\n",
      "epoch:26 step:20431 [D loss: 0.547833, acc: 75.00%] [G loss: 4.990702]\n",
      "epoch:26 step:20432 [D loss: 0.425384, acc: 89.84%] [G loss: 4.957566]\n",
      "epoch:26 step:20433 [D loss: 0.222178, acc: 96.09%] [G loss: 3.745710]\n",
      "epoch:26 step:20434 [D loss: 0.358043, acc: 93.75%] [G loss: 4.367465]\n",
      "epoch:26 step:20435 [D loss: 0.251545, acc: 96.88%] [G loss: 2.693083]\n",
      "epoch:26 step:20436 [D loss: 1.389973, acc: 20.31%] [G loss: 3.224172]\n",
      "epoch:26 step:20437 [D loss: 0.529828, acc: 75.78%] [G loss: 4.885040]\n",
      "epoch:26 step:20438 [D loss: 0.186952, acc: 99.22%] [G loss: 4.056062]\n",
      "epoch:26 step:20439 [D loss: 0.447646, acc: 75.78%] [G loss: 4.908100]\n",
      "epoch:26 step:20440 [D loss: 0.623302, acc: 62.50%] [G loss: 2.318355]\n",
      "epoch:26 step:20441 [D loss: 0.408963, acc: 85.16%] [G loss: 3.486184]\n",
      "epoch:26 step:20442 [D loss: 0.704206, acc: 58.59%] [G loss: 3.550035]\n",
      "epoch:26 step:20443 [D loss: 0.194867, acc: 99.22%] [G loss: 4.843398]\n",
      "epoch:26 step:20444 [D loss: 1.146815, acc: 15.62%] [G loss: 3.740611]\n",
      "epoch:26 step:20445 [D loss: 0.298504, acc: 95.31%] [G loss: 3.645417]\n",
      "epoch:26 step:20446 [D loss: 0.207848, acc: 99.22%] [G loss: 3.976529]\n",
      "epoch:26 step:20447 [D loss: 0.365931, acc: 85.16%] [G loss: 3.229226]\n",
      "epoch:26 step:20448 [D loss: 0.526998, acc: 68.75%] [G loss: 3.220178]\n",
      "epoch:26 step:20449 [D loss: 1.371301, acc: 38.28%] [G loss: 1.924736]\n",
      "epoch:26 step:20450 [D loss: 0.833984, acc: 38.28%] [G loss: 2.090681]\n",
      "epoch:26 step:20451 [D loss: 0.653859, acc: 57.03%] [G loss: 4.878621]\n",
      "epoch:26 step:20452 [D loss: 0.081836, acc: 100.00%] [G loss: 3.049246]\n",
      "epoch:26 step:20453 [D loss: 0.235504, acc: 93.75%] [G loss: 5.162287]\n",
      "epoch:26 step:20454 [D loss: 0.102346, acc: 100.00%] [G loss: 3.440184]\n",
      "epoch:26 step:20455 [D loss: 0.130258, acc: 99.22%] [G loss: 2.528432]\n",
      "epoch:26 step:20456 [D loss: 0.300056, acc: 93.75%] [G loss: 2.353659]\n",
      "epoch:26 step:20457 [D loss: 0.202412, acc: 96.88%] [G loss: 4.492713]\n",
      "epoch:26 step:20458 [D loss: 1.432683, acc: 27.34%] [G loss: 4.493492]\n",
      "epoch:26 step:20459 [D loss: 0.210646, acc: 96.09%] [G loss: 5.822711]\n",
      "epoch:26 step:20460 [D loss: 0.231487, acc: 92.19%] [G loss: 5.848314]\n",
      "epoch:26 step:20461 [D loss: 0.300668, acc: 97.66%] [G loss: 2.646967]\n",
      "epoch:26 step:20462 [D loss: 0.484615, acc: 78.91%] [G loss: 1.962163]\n",
      "epoch:26 step:20463 [D loss: 0.164273, acc: 99.22%] [G loss: 4.655778]\n",
      "epoch:26 step:20464 [D loss: 0.268297, acc: 97.66%] [G loss: 4.165467]\n",
      "epoch:26 step:20465 [D loss: 0.224496, acc: 99.22%] [G loss: 4.329236]\n",
      "epoch:26 step:20466 [D loss: 0.562971, acc: 76.56%] [G loss: 3.498227]\n",
      "epoch:26 step:20467 [D loss: 0.380909, acc: 78.12%] [G loss: 4.070498]\n",
      "epoch:26 step:20468 [D loss: 0.365016, acc: 87.50%] [G loss: 2.086922]\n",
      "epoch:26 step:20469 [D loss: 0.334680, acc: 87.50%] [G loss: 2.132434]\n",
      "epoch:26 step:20470 [D loss: 0.241642, acc: 99.22%] [G loss: 3.392107]\n",
      "epoch:26 step:20471 [D loss: 0.348215, acc: 92.19%] [G loss: 3.372334]\n",
      "epoch:26 step:20472 [D loss: 0.324015, acc: 82.03%] [G loss: 4.202765]\n",
      "epoch:26 step:20473 [D loss: 0.991929, acc: 45.31%] [G loss: 3.150970]\n",
      "epoch:26 step:20474 [D loss: 0.351934, acc: 94.53%] [G loss: 3.739053]\n",
      "epoch:26 step:20475 [D loss: 0.224994, acc: 97.66%] [G loss: 4.874537]\n",
      "epoch:26 step:20476 [D loss: 0.391862, acc: 90.62%] [G loss: 2.872994]\n",
      "epoch:26 step:20477 [D loss: 0.309278, acc: 96.09%] [G loss: 5.876863]\n",
      "epoch:26 step:20478 [D loss: 0.444553, acc: 83.59%] [G loss: 5.253154]\n",
      "epoch:26 step:20479 [D loss: 0.415234, acc: 89.06%] [G loss: 3.044695]\n",
      "epoch:26 step:20480 [D loss: 0.412259, acc: 79.69%] [G loss: 3.481427]\n",
      "epoch:26 step:20481 [D loss: 0.084048, acc: 100.00%] [G loss: 4.475360]\n",
      "epoch:26 step:20482 [D loss: 0.686874, acc: 57.81%] [G loss: 2.288909]\n",
      "epoch:26 step:20483 [D loss: 0.242541, acc: 92.97%] [G loss: 5.887136]\n",
      "epoch:26 step:20484 [D loss: 0.568106, acc: 69.53%] [G loss: 3.395437]\n",
      "epoch:26 step:20485 [D loss: 0.538425, acc: 75.00%] [G loss: 3.635571]\n",
      "epoch:26 step:20486 [D loss: 0.833544, acc: 52.34%] [G loss: 3.330467]\n",
      "epoch:26 step:20487 [D loss: 0.851510, acc: 35.16%] [G loss: 3.425659]\n",
      "epoch:26 step:20488 [D loss: 0.298443, acc: 91.41%] [G loss: 2.159503]\n",
      "epoch:26 step:20489 [D loss: 0.147156, acc: 99.22%] [G loss: 5.394655]\n",
      "epoch:26 step:20490 [D loss: 1.699351, acc: 2.34%] [G loss: 5.626575]\n",
      "epoch:26 step:20491 [D loss: 0.624328, acc: 67.97%] [G loss: 2.065665]\n",
      "epoch:26 step:20492 [D loss: 0.336270, acc: 86.72%] [G loss: 4.590635]\n",
      "epoch:26 step:20493 [D loss: 0.499194, acc: 66.41%] [G loss: 4.926360]\n",
      "epoch:26 step:20494 [D loss: 0.280032, acc: 89.06%] [G loss: 4.034090]\n",
      "epoch:26 step:20495 [D loss: 0.107446, acc: 100.00%] [G loss: 4.686795]\n",
      "epoch:26 step:20496 [D loss: 0.274656, acc: 93.75%] [G loss: 3.834543]\n",
      "epoch:26 step:20497 [D loss: 0.324443, acc: 94.53%] [G loss: 4.890541]\n",
      "epoch:26 step:20498 [D loss: 0.100885, acc: 100.00%] [G loss: 4.645970]\n",
      "epoch:26 step:20499 [D loss: 0.126446, acc: 100.00%] [G loss: 2.821863]\n",
      "epoch:26 step:20500 [D loss: 0.230573, acc: 96.88%] [G loss: 3.464755]\n",
      "epoch:26 step:20501 [D loss: 0.236397, acc: 99.22%] [G loss: 4.096487]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:26 step:20502 [D loss: 0.515648, acc: 75.78%] [G loss: 3.402437]\n",
      "epoch:26 step:20503 [D loss: 0.292410, acc: 85.94%] [G loss: 4.746055]\n",
      "epoch:26 step:20504 [D loss: 0.170692, acc: 99.22%] [G loss: 5.138405]\n",
      "epoch:26 step:20505 [D loss: 0.371963, acc: 76.56%] [G loss: 3.792917]\n",
      "epoch:26 step:20506 [D loss: 0.545274, acc: 78.91%] [G loss: 2.398861]\n",
      "epoch:26 step:20507 [D loss: 0.572424, acc: 70.31%] [G loss: 2.914026]\n",
      "epoch:26 step:20508 [D loss: 0.137572, acc: 98.44%] [G loss: 3.507414]\n",
      "epoch:26 step:20509 [D loss: 0.682771, acc: 55.47%] [G loss: 5.060661]\n",
      "epoch:26 step:20510 [D loss: 0.405556, acc: 80.47%] [G loss: 2.993485]\n",
      "epoch:26 step:20511 [D loss: 0.262970, acc: 96.88%] [G loss: 2.885239]\n",
      "epoch:26 step:20512 [D loss: 1.207647, acc: 49.22%] [G loss: 4.225635]\n",
      "epoch:26 step:20513 [D loss: 1.005640, acc: 49.22%] [G loss: 6.281235]\n",
      "epoch:26 step:20514 [D loss: 0.187548, acc: 96.09%] [G loss: 3.829207]\n",
      "epoch:26 step:20515 [D loss: 0.403615, acc: 75.78%] [G loss: 5.055955]\n",
      "epoch:26 step:20516 [D loss: 0.388603, acc: 89.06%] [G loss: 2.772595]\n",
      "epoch:26 step:20517 [D loss: 0.395901, acc: 78.12%] [G loss: 3.184350]\n",
      "epoch:26 step:20518 [D loss: 0.308917, acc: 94.53%] [G loss: 1.803879]\n",
      "epoch:26 step:20519 [D loss: 0.619191, acc: 58.59%] [G loss: 4.637378]\n",
      "epoch:26 step:20520 [D loss: 0.243419, acc: 95.31%] [G loss: 3.573909]\n",
      "epoch:26 step:20521 [D loss: 0.422462, acc: 77.34%] [G loss: 3.642967]\n",
      "epoch:26 step:20522 [D loss: 0.933603, acc: 49.22%] [G loss: 3.136826]\n",
      "epoch:26 step:20523 [D loss: 0.447491, acc: 85.16%] [G loss: 2.820306]\n",
      "epoch:26 step:20524 [D loss: 0.712390, acc: 57.81%] [G loss: 2.424409]\n",
      "epoch:26 step:20525 [D loss: 0.421741, acc: 82.81%] [G loss: 4.459835]\n",
      "epoch:26 step:20526 [D loss: 0.280480, acc: 94.53%] [G loss: 4.785000]\n",
      "epoch:26 step:20527 [D loss: 1.261245, acc: 12.50%] [G loss: 2.285539]\n",
      "epoch:26 step:20528 [D loss: 0.183888, acc: 100.00%] [G loss: 4.695641]\n",
      "epoch:26 step:20529 [D loss: 1.451143, acc: 39.84%] [G loss: 5.348718]\n",
      "epoch:26 step:20530 [D loss: 0.532865, acc: 80.47%] [G loss: 3.869681]\n",
      "epoch:26 step:20531 [D loss: 0.667950, acc: 53.91%] [G loss: 3.579777]\n",
      "epoch:26 step:20532 [D loss: 0.295402, acc: 88.28%] [G loss: 4.710765]\n",
      "epoch:26 step:20533 [D loss: 0.384528, acc: 82.81%] [G loss: 3.328723]\n",
      "epoch:26 step:20534 [D loss: 0.482545, acc: 79.69%] [G loss: 5.204470]\n",
      "epoch:26 step:20535 [D loss: 0.353377, acc: 86.72%] [G loss: 3.613958]\n",
      "epoch:26 step:20536 [D loss: 0.451281, acc: 71.88%] [G loss: 2.464362]\n",
      "epoch:26 step:20537 [D loss: 0.093685, acc: 100.00%] [G loss: 5.183378]\n",
      "epoch:26 step:20538 [D loss: 1.020678, acc: 47.66%] [G loss: 3.142702]\n",
      "epoch:26 step:20539 [D loss: 0.409836, acc: 80.47%] [G loss: 5.189468]\n",
      "epoch:26 step:20540 [D loss: 0.273072, acc: 95.31%] [G loss: 3.498900]\n",
      "epoch:26 step:20541 [D loss: 0.265821, acc: 93.75%] [G loss: 3.684459]\n",
      "epoch:26 step:20542 [D loss: 0.300948, acc: 90.62%] [G loss: 4.944931]\n",
      "epoch:26 step:20543 [D loss: 0.408668, acc: 75.78%] [G loss: 3.344569]\n",
      "epoch:26 step:20544 [D loss: 0.282069, acc: 97.66%] [G loss: 4.303612]\n",
      "epoch:26 step:20545 [D loss: 0.217974, acc: 98.44%] [G loss: 3.834068]\n",
      "epoch:26 step:20546 [D loss: 0.618975, acc: 60.94%] [G loss: 2.874809]\n",
      "epoch:26 step:20547 [D loss: 0.132374, acc: 98.44%] [G loss: 3.159872]\n",
      "epoch:26 step:20548 [D loss: 0.270937, acc: 96.09%] [G loss: 3.266222]\n",
      "epoch:26 step:20549 [D loss: 0.214030, acc: 100.00%] [G loss: 3.806357]\n",
      "epoch:26 step:20550 [D loss: 0.305317, acc: 88.28%] [G loss: 3.391060]\n",
      "epoch:26 step:20551 [D loss: 1.558670, acc: 10.16%] [G loss: 4.126220]\n",
      "epoch:26 step:20552 [D loss: 0.471568, acc: 78.91%] [G loss: 2.758168]\n",
      "epoch:26 step:20553 [D loss: 0.615311, acc: 69.53%] [G loss: 2.380366]\n",
      "epoch:26 step:20554 [D loss: 0.726198, acc: 56.25%] [G loss: 4.440278]\n",
      "epoch:26 step:20555 [D loss: 0.140067, acc: 100.00%] [G loss: 2.941607]\n",
      "epoch:26 step:20556 [D loss: 0.267921, acc: 89.84%] [G loss: 4.143652]\n",
      "epoch:26 step:20557 [D loss: 0.109314, acc: 100.00%] [G loss: 2.901749]\n",
      "epoch:26 step:20558 [D loss: 0.803683, acc: 42.19%] [G loss: 4.412611]\n",
      "epoch:26 step:20559 [D loss: 0.295061, acc: 94.53%] [G loss: 2.618535]\n",
      "epoch:26 step:20560 [D loss: 0.547515, acc: 74.22%] [G loss: 3.297236]\n",
      "epoch:26 step:20561 [D loss: 0.211528, acc: 99.22%] [G loss: 3.453526]\n",
      "epoch:26 step:20562 [D loss: 0.371880, acc: 89.06%] [G loss: 3.737988]\n",
      "epoch:26 step:20563 [D loss: 0.361211, acc: 92.97%] [G loss: 5.704541]\n",
      "epoch:26 step:20564 [D loss: 0.226876, acc: 93.75%] [G loss: 5.359297]\n",
      "epoch:26 step:20565 [D loss: 0.217298, acc: 98.44%] [G loss: 2.870310]\n",
      "epoch:26 step:20566 [D loss: 0.919831, acc: 45.31%] [G loss: 3.541465]\n",
      "epoch:26 step:20567 [D loss: 0.575508, acc: 64.84%] [G loss: 3.150913]\n",
      "epoch:26 step:20568 [D loss: 0.149080, acc: 99.22%] [G loss: 5.047523]\n",
      "epoch:26 step:20569 [D loss: 0.529514, acc: 65.62%] [G loss: 4.187143]\n",
      "epoch:26 step:20570 [D loss: 0.276424, acc: 96.88%] [G loss: 4.312047]\n",
      "epoch:26 step:20571 [D loss: 0.498297, acc: 67.97%] [G loss: 4.906523]\n",
      "epoch:26 step:20572 [D loss: 0.459187, acc: 66.41%] [G loss: 4.349359]\n",
      "epoch:26 step:20573 [D loss: 1.058764, acc: 28.12%] [G loss: 3.398505]\n",
      "epoch:26 step:20574 [D loss: 0.051394, acc: 100.00%] [G loss: 5.417821]\n",
      "epoch:26 step:20575 [D loss: 0.450422, acc: 74.22%] [G loss: 4.745158]\n",
      "epoch:26 step:20576 [D loss: 0.616353, acc: 61.72%] [G loss: 4.334126]\n",
      "epoch:26 step:20577 [D loss: 0.138220, acc: 100.00%] [G loss: 6.461342]\n",
      "epoch:26 step:20578 [D loss: 2.283647, acc: 50.00%] [G loss: 2.205692]\n",
      "epoch:26 step:20579 [D loss: 0.349462, acc: 92.19%] [G loss: 2.363245]\n",
      "epoch:26 step:20580 [D loss: 0.596916, acc: 67.97%] [G loss: 4.735898]\n",
      "epoch:26 step:20581 [D loss: 0.363796, acc: 90.62%] [G loss: 4.274995]\n",
      "epoch:26 step:20582 [D loss: 0.495842, acc: 70.31%] [G loss: 3.939302]\n",
      "epoch:26 step:20583 [D loss: 0.173240, acc: 98.44%] [G loss: 6.035629]\n",
      "epoch:26 step:20584 [D loss: 0.795900, acc: 53.12%] [G loss: 3.625661]\n",
      "epoch:26 step:20585 [D loss: 0.588992, acc: 72.66%] [G loss: 4.309820]\n",
      "epoch:26 step:20586 [D loss: 0.522568, acc: 61.72%] [G loss: 3.836786]\n",
      "epoch:26 step:20587 [D loss: 0.382831, acc: 89.84%] [G loss: 5.121415]\n",
      "epoch:26 step:20588 [D loss: 0.317807, acc: 95.31%] [G loss: 3.377984]\n",
      "epoch:26 step:20589 [D loss: 0.874070, acc: 35.94%] [G loss: 3.349522]\n",
      "epoch:26 step:20590 [D loss: 0.207691, acc: 96.88%] [G loss: 2.179882]\n",
      "epoch:26 step:20591 [D loss: 0.055901, acc: 100.00%] [G loss: 4.945593]\n",
      "epoch:26 step:20592 [D loss: 0.385289, acc: 92.97%] [G loss: 3.010913]\n",
      "epoch:26 step:20593 [D loss: 0.470588, acc: 78.12%] [G loss: 4.966681]\n",
      "epoch:26 step:20594 [D loss: 0.213655, acc: 99.22%] [G loss: 3.207127]\n",
      "epoch:26 step:20595 [D loss: 0.359622, acc: 78.91%] [G loss: 5.843824]\n",
      "epoch:26 step:20596 [D loss: 0.284593, acc: 92.19%] [G loss: 2.480135]\n",
      "epoch:26 step:20597 [D loss: 0.485708, acc: 77.34%] [G loss: 2.594976]\n",
      "epoch:26 step:20598 [D loss: 0.085995, acc: 100.00%] [G loss: 2.242044]\n",
      "epoch:26 step:20599 [D loss: 0.278541, acc: 94.53%] [G loss: 3.510345]\n",
      "epoch:26 step:20600 [D loss: 0.446258, acc: 82.03%] [G loss: 3.179774]\n",
      "##############\n",
      "[0.86062291 0.87083982 0.8072812  0.80549363 0.80692102 0.83231992\n",
      " 0.88948506 0.83729709 0.80610633 0.84645139]\n",
      "##########\n",
      "epoch:26 step:20601 [D loss: 0.471840, acc: 77.34%] [G loss: 2.192556]\n",
      "epoch:26 step:20602 [D loss: 0.315763, acc: 90.62%] [G loss: 5.510254]\n",
      "epoch:26 step:20603 [D loss: 1.609861, acc: 46.09%] [G loss: 4.670751]\n",
      "epoch:26 step:20604 [D loss: 0.924958, acc: 40.62%] [G loss: 2.989751]\n",
      "epoch:26 step:20605 [D loss: 0.326266, acc: 95.31%] [G loss: 3.038301]\n",
      "epoch:26 step:20606 [D loss: 0.773425, acc: 50.78%] [G loss: 4.112168]\n",
      "epoch:26 step:20607 [D loss: 0.267033, acc: 90.62%] [G loss: 5.260141]\n",
      "epoch:26 step:20608 [D loss: 0.476550, acc: 85.94%] [G loss: 2.839212]\n",
      "epoch:26 step:20609 [D loss: 0.640010, acc: 60.94%] [G loss: 3.007402]\n",
      "epoch:26 step:20610 [D loss: 0.825779, acc: 49.22%] [G loss: 4.170277]\n",
      "epoch:26 step:20611 [D loss: 0.243001, acc: 97.66%] [G loss: 4.466908]\n",
      "epoch:26 step:20612 [D loss: 0.320125, acc: 89.84%] [G loss: 4.742014]\n",
      "epoch:26 step:20613 [D loss: 0.301021, acc: 93.75%] [G loss: 4.994391]\n",
      "epoch:26 step:20614 [D loss: 0.175083, acc: 97.66%] [G loss: 4.340859]\n",
      "epoch:26 step:20615 [D loss: 0.479918, acc: 67.19%] [G loss: 3.505995]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:26 step:20616 [D loss: 0.183404, acc: 98.44%] [G loss: 4.768863]\n",
      "epoch:26 step:20617 [D loss: 0.303108, acc: 92.97%] [G loss: 3.657384]\n",
      "epoch:26 step:20618 [D loss: 0.547541, acc: 63.28%] [G loss: 4.343076]\n",
      "epoch:26 step:20619 [D loss: 0.767485, acc: 53.91%] [G loss: 3.733917]\n",
      "epoch:26 step:20620 [D loss: 1.064976, acc: 50.78%] [G loss: 3.092827]\n",
      "epoch:26 step:20621 [D loss: 0.376987, acc: 89.06%] [G loss: 4.095132]\n",
      "epoch:26 step:20622 [D loss: 0.637382, acc: 56.25%] [G loss: 3.899047]\n",
      "epoch:26 step:20623 [D loss: 1.131948, acc: 49.22%] [G loss: 3.706881]\n",
      "epoch:26 step:20624 [D loss: 0.386009, acc: 82.03%] [G loss: 5.542645]\n",
      "epoch:26 step:20625 [D loss: 0.158374, acc: 97.66%] [G loss: 3.966422]\n",
      "epoch:26 step:20626 [D loss: 0.567543, acc: 59.38%] [G loss: 4.945674]\n",
      "epoch:26 step:20627 [D loss: 0.064969, acc: 99.22%] [G loss: 3.818892]\n",
      "epoch:26 step:20628 [D loss: 0.453007, acc: 75.00%] [G loss: 6.248935]\n",
      "epoch:26 step:20629 [D loss: 0.038601, acc: 100.00%] [G loss: 4.193610]\n",
      "epoch:26 step:20630 [D loss: 0.213582, acc: 96.88%] [G loss: 4.710909]\n",
      "epoch:26 step:20631 [D loss: 0.037093, acc: 100.00%] [G loss: 4.180185]\n",
      "epoch:26 step:20632 [D loss: 0.353674, acc: 83.59%] [G loss: 4.662331]\n",
      "epoch:26 step:20633 [D loss: 0.542168, acc: 69.53%] [G loss: 2.746172]\n",
      "epoch:26 step:20634 [D loss: 0.495641, acc: 60.16%] [G loss: 4.620859]\n",
      "epoch:26 step:20635 [D loss: 0.426342, acc: 79.69%] [G loss: 4.028041]\n",
      "epoch:26 step:20636 [D loss: 0.502394, acc: 78.12%] [G loss: 3.755933]\n",
      "epoch:26 step:20637 [D loss: 0.197692, acc: 97.66%] [G loss: 3.188379]\n",
      "epoch:26 step:20638 [D loss: 0.726405, acc: 53.12%] [G loss: 3.799242]\n",
      "epoch:26 step:20639 [D loss: 0.208013, acc: 97.66%] [G loss: 6.321836]\n",
      "epoch:26 step:20640 [D loss: 0.624734, acc: 69.53%] [G loss: 4.210403]\n",
      "epoch:26 step:20641 [D loss: 0.357022, acc: 89.84%] [G loss: 2.122052]\n",
      "epoch:26 step:20642 [D loss: 0.255942, acc: 100.00%] [G loss: 3.121854]\n",
      "epoch:26 step:20643 [D loss: 0.759727, acc: 50.78%] [G loss: 3.252763]\n",
      "epoch:26 step:20644 [D loss: 0.724632, acc: 51.56%] [G loss: 2.676723]\n",
      "epoch:26 step:20645 [D loss: 0.465816, acc: 71.88%] [G loss: 4.753312]\n",
      "epoch:26 step:20646 [D loss: 1.511131, acc: 17.19%] [G loss: 2.654021]\n",
      "epoch:26 step:20647 [D loss: 0.580712, acc: 72.66%] [G loss: 3.107271]\n",
      "epoch:26 step:20648 [D loss: 0.850173, acc: 51.56%] [G loss: 6.344563]\n",
      "epoch:26 step:20649 [D loss: 0.723512, acc: 55.47%] [G loss: 3.711248]\n",
      "epoch:26 step:20650 [D loss: 0.717117, acc: 57.81%] [G loss: 4.023255]\n",
      "epoch:26 step:20651 [D loss: 0.408114, acc: 80.47%] [G loss: 4.175052]\n",
      "epoch:26 step:20652 [D loss: 0.244123, acc: 94.53%] [G loss: 4.167693]\n",
      "epoch:26 step:20653 [D loss: 0.217399, acc: 96.88%] [G loss: 3.325688]\n",
      "epoch:26 step:20654 [D loss: 0.162619, acc: 99.22%] [G loss: 3.534930]\n",
      "epoch:26 step:20655 [D loss: 0.346165, acc: 88.28%] [G loss: 2.807701]\n",
      "epoch:26 step:20656 [D loss: 0.458180, acc: 67.97%] [G loss: 2.841265]\n",
      "epoch:26 step:20657 [D loss: 0.294701, acc: 93.75%] [G loss: 4.779290]\n",
      "epoch:26 step:20658 [D loss: 0.393392, acc: 77.34%] [G loss: 3.576454]\n",
      "epoch:26 step:20659 [D loss: 0.217505, acc: 94.53%] [G loss: 3.851512]\n",
      "epoch:26 step:20660 [D loss: 0.860198, acc: 44.53%] [G loss: 3.948688]\n",
      "epoch:26 step:20661 [D loss: 1.487069, acc: 12.50%] [G loss: 3.455583]\n",
      "epoch:26 step:20662 [D loss: 0.241876, acc: 94.53%] [G loss: 4.073491]\n",
      "epoch:26 step:20663 [D loss: 0.763530, acc: 45.31%] [G loss: 3.365540]\n",
      "epoch:26 step:20664 [D loss: 0.500917, acc: 78.12%] [G loss: 2.368484]\n",
      "epoch:26 step:20665 [D loss: 0.147510, acc: 100.00%] [G loss: 5.105853]\n",
      "epoch:26 step:20666 [D loss: 0.784895, acc: 53.12%] [G loss: 6.438460]\n",
      "epoch:26 step:20667 [D loss: 0.891508, acc: 48.44%] [G loss: 3.832552]\n",
      "epoch:26 step:20668 [D loss: 0.413097, acc: 82.81%] [G loss: 3.168394]\n",
      "epoch:26 step:20669 [D loss: 0.669567, acc: 57.03%] [G loss: 3.421774]\n",
      "epoch:26 step:20670 [D loss: 0.099717, acc: 99.22%] [G loss: 3.501326]\n",
      "epoch:26 step:20671 [D loss: 0.235939, acc: 98.44%] [G loss: 2.826938]\n",
      "epoch:26 step:20672 [D loss: 0.748055, acc: 57.03%] [G loss: 4.613627]\n",
      "epoch:26 step:20673 [D loss: 0.215879, acc: 100.00%] [G loss: 3.430793]\n",
      "epoch:26 step:20674 [D loss: 1.187428, acc: 22.66%] [G loss: 3.134801]\n",
      "epoch:26 step:20675 [D loss: 0.319606, acc: 91.41%] [G loss: 4.569642]\n",
      "epoch:26 step:20676 [D loss: 0.458571, acc: 82.81%] [G loss: 3.900182]\n",
      "epoch:26 step:20677 [D loss: 0.272043, acc: 95.31%] [G loss: 5.978992]\n",
      "epoch:26 step:20678 [D loss: 0.155778, acc: 99.22%] [G loss: 3.212414]\n",
      "epoch:26 step:20679 [D loss: 0.581242, acc: 68.75%] [G loss: 3.138122]\n",
      "epoch:26 step:20680 [D loss: 0.228102, acc: 97.66%] [G loss: 2.868928]\n",
      "epoch:26 step:20681 [D loss: 0.265481, acc: 90.62%] [G loss: 3.795321]\n",
      "epoch:26 step:20682 [D loss: 0.288807, acc: 92.97%] [G loss: 2.529214]\n",
      "epoch:26 step:20683 [D loss: 0.332753, acc: 92.97%] [G loss: 3.036926]\n",
      "epoch:26 step:20684 [D loss: 0.317249, acc: 95.31%] [G loss: 3.875170]\n",
      "epoch:26 step:20685 [D loss: 0.286154, acc: 96.88%] [G loss: 3.610205]\n",
      "epoch:26 step:20686 [D loss: 0.913205, acc: 41.41%] [G loss: 3.583438]\n",
      "epoch:26 step:20687 [D loss: 0.463378, acc: 85.16%] [G loss: 3.267849]\n",
      "epoch:26 step:20688 [D loss: 0.316264, acc: 89.84%] [G loss: 4.377283]\n",
      "epoch:26 step:20689 [D loss: 0.666358, acc: 56.25%] [G loss: 3.153550]\n",
      "epoch:26 step:20690 [D loss: 0.256279, acc: 96.88%] [G loss: 2.535632]\n",
      "epoch:26 step:20691 [D loss: 0.127419, acc: 99.22%] [G loss: 2.806177]\n",
      "epoch:26 step:20692 [D loss: 0.276890, acc: 92.19%] [G loss: 3.879514]\n",
      "epoch:26 step:20693 [D loss: 0.201610, acc: 98.44%] [G loss: 5.625381]\n",
      "epoch:26 step:20694 [D loss: 0.208839, acc: 98.44%] [G loss: 3.348503]\n",
      "epoch:26 step:20695 [D loss: 0.561317, acc: 70.31%] [G loss: 2.645407]\n",
      "epoch:26 step:20696 [D loss: 0.680622, acc: 58.59%] [G loss: 2.673678]\n",
      "epoch:26 step:20697 [D loss: 0.333677, acc: 82.03%] [G loss: 2.931556]\n",
      "epoch:26 step:20698 [D loss: 0.971497, acc: 50.00%] [G loss: 5.125258]\n",
      "epoch:26 step:20699 [D loss: 1.035578, acc: 21.09%] [G loss: 3.810374]\n",
      "epoch:26 step:20700 [D loss: 0.051600, acc: 100.00%] [G loss: 6.383181]\n",
      "epoch:26 step:20701 [D loss: 0.345732, acc: 81.25%] [G loss: 4.258583]\n",
      "epoch:26 step:20702 [D loss: 0.481415, acc: 83.59%] [G loss: 3.372846]\n",
      "epoch:26 step:20703 [D loss: 0.402591, acc: 84.38%] [G loss: 4.788890]\n",
      "epoch:26 step:20704 [D loss: 0.840982, acc: 50.78%] [G loss: 3.358150]\n",
      "epoch:26 step:20705 [D loss: 0.270322, acc: 95.31%] [G loss: 3.141610]\n",
      "epoch:26 step:20706 [D loss: 0.127494, acc: 100.00%] [G loss: 4.407414]\n",
      "epoch:26 step:20707 [D loss: 0.038462, acc: 100.00%] [G loss: 6.834368]\n",
      "epoch:26 step:20708 [D loss: 0.241408, acc: 95.31%] [G loss: 4.514317]\n",
      "epoch:26 step:20709 [D loss: 0.317930, acc: 86.72%] [G loss: 3.029678]\n",
      "epoch:26 step:20710 [D loss: 0.293009, acc: 95.31%] [G loss: 2.887674]\n",
      "epoch:26 step:20711 [D loss: 0.477452, acc: 81.25%] [G loss: 4.408772]\n",
      "epoch:26 step:20712 [D loss: 0.768053, acc: 53.12%] [G loss: 2.510005]\n",
      "epoch:26 step:20713 [D loss: 0.090974, acc: 100.00%] [G loss: 3.131542]\n",
      "epoch:26 step:20714 [D loss: 0.134020, acc: 99.22%] [G loss: 6.265932]\n",
      "epoch:26 step:20715 [D loss: 0.501947, acc: 64.06%] [G loss: 4.755984]\n",
      "epoch:26 step:20716 [D loss: 0.191848, acc: 97.66%] [G loss: 3.511841]\n",
      "epoch:26 step:20717 [D loss: 0.526934, acc: 75.00%] [G loss: 4.042305]\n",
      "epoch:26 step:20718 [D loss: 1.047201, acc: 50.00%] [G loss: 2.474546]\n",
      "epoch:26 step:20719 [D loss: 0.814517, acc: 51.56%] [G loss: 2.536569]\n",
      "epoch:26 step:20720 [D loss: 1.140972, acc: 50.00%] [G loss: 3.838522]\n",
      "epoch:26 step:20721 [D loss: 0.442856, acc: 74.22%] [G loss: 1.722936]\n",
      "epoch:26 step:20722 [D loss: 0.463527, acc: 69.53%] [G loss: 3.744791]\n",
      "epoch:26 step:20723 [D loss: 0.449531, acc: 75.00%] [G loss: 2.366404]\n",
      "epoch:26 step:20724 [D loss: 0.439767, acc: 90.62%] [G loss: 3.625242]\n",
      "epoch:26 step:20725 [D loss: 0.242932, acc: 94.53%] [G loss: 4.319027]\n",
      "epoch:26 step:20726 [D loss: 0.351765, acc: 87.50%] [G loss: 3.136195]\n",
      "epoch:26 step:20727 [D loss: 0.218344, acc: 99.22%] [G loss: 5.315376]\n",
      "epoch:26 step:20728 [D loss: 0.340285, acc: 89.84%] [G loss: 3.568706]\n",
      "epoch:26 step:20729 [D loss: 0.522919, acc: 78.12%] [G loss: 3.336148]\n",
      "epoch:26 step:20730 [D loss: 0.452728, acc: 75.78%] [G loss: 3.276549]\n",
      "epoch:26 step:20731 [D loss: 0.212250, acc: 99.22%] [G loss: 3.221227]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:26 step:20732 [D loss: 0.269830, acc: 88.28%] [G loss: 4.418728]\n",
      "epoch:26 step:20733 [D loss: 0.230701, acc: 100.00%] [G loss: 2.114955]\n",
      "epoch:26 step:20734 [D loss: 0.615619, acc: 62.50%] [G loss: 6.288787]\n",
      "epoch:26 step:20735 [D loss: 0.202141, acc: 99.22%] [G loss: 6.364627]\n",
      "epoch:26 step:20736 [D loss: 0.139071, acc: 100.00%] [G loss: 4.061202]\n",
      "epoch:26 step:20737 [D loss: 0.442722, acc: 72.66%] [G loss: 2.573304]\n",
      "epoch:26 step:20738 [D loss: 0.284628, acc: 96.88%] [G loss: 4.504416]\n",
      "epoch:26 step:20739 [D loss: 0.589420, acc: 63.28%] [G loss: 3.040626]\n",
      "epoch:26 step:20740 [D loss: 0.161894, acc: 100.00%] [G loss: 6.740305]\n",
      "epoch:26 step:20741 [D loss: 0.281286, acc: 96.09%] [G loss: 5.012313]\n",
      "epoch:26 step:20742 [D loss: 0.937690, acc: 38.28%] [G loss: 5.034429]\n",
      "epoch:26 step:20743 [D loss: 0.561326, acc: 73.44%] [G loss: 4.250360]\n",
      "epoch:26 step:20744 [D loss: 0.223074, acc: 97.66%] [G loss: 6.081257]\n",
      "epoch:26 step:20745 [D loss: 0.977170, acc: 38.28%] [G loss: 3.407835]\n",
      "epoch:26 step:20746 [D loss: 0.889286, acc: 45.31%] [G loss: 3.656958]\n",
      "epoch:26 step:20747 [D loss: 0.421800, acc: 85.94%] [G loss: 4.556882]\n",
      "epoch:26 step:20748 [D loss: 0.561225, acc: 55.47%] [G loss: 5.050318]\n",
      "epoch:26 step:20749 [D loss: 0.099692, acc: 100.00%] [G loss: 5.373908]\n",
      "epoch:26 step:20750 [D loss: 0.355361, acc: 80.47%] [G loss: 3.438828]\n",
      "epoch:26 step:20751 [D loss: 0.283503, acc: 98.44%] [G loss: 2.403554]\n",
      "epoch:26 step:20752 [D loss: 0.100351, acc: 100.00%] [G loss: 5.152634]\n",
      "epoch:26 step:20753 [D loss: 0.462229, acc: 82.81%] [G loss: 4.006226]\n",
      "epoch:26 step:20754 [D loss: 0.158899, acc: 100.00%] [G loss: 3.789710]\n",
      "epoch:26 step:20755 [D loss: 0.538383, acc: 71.88%] [G loss: 3.599440]\n",
      "epoch:26 step:20756 [D loss: 0.135375, acc: 99.22%] [G loss: 3.568822]\n",
      "epoch:26 step:20757 [D loss: 0.444623, acc: 82.03%] [G loss: 4.029237]\n",
      "epoch:26 step:20758 [D loss: 0.197769, acc: 95.31%] [G loss: 6.392544]\n",
      "epoch:26 step:20759 [D loss: 0.562187, acc: 71.88%] [G loss: 4.774312]\n",
      "epoch:26 step:20760 [D loss: 0.290902, acc: 95.31%] [G loss: 5.039494]\n",
      "epoch:26 step:20761 [D loss: 0.456825, acc: 74.22%] [G loss: 3.535065]\n",
      "epoch:26 step:20762 [D loss: 0.159427, acc: 98.44%] [G loss: 2.533186]\n",
      "epoch:26 step:20763 [D loss: 0.890442, acc: 47.66%] [G loss: 4.505098]\n",
      "epoch:26 step:20764 [D loss: 0.533434, acc: 63.28%] [G loss: 3.313361]\n",
      "epoch:26 step:20765 [D loss: 0.274906, acc: 93.75%] [G loss: 2.894640]\n",
      "epoch:26 step:20766 [D loss: 0.349707, acc: 85.16%] [G loss: 3.732769]\n",
      "epoch:26 step:20767 [D loss: 0.313477, acc: 84.38%] [G loss: 3.969935]\n",
      "epoch:26 step:20768 [D loss: 0.238060, acc: 96.09%] [G loss: 3.088596]\n",
      "epoch:26 step:20769 [D loss: 0.814398, acc: 52.34%] [G loss: 6.386413]\n",
      "epoch:26 step:20770 [D loss: 0.364274, acc: 92.19%] [G loss: 2.862094]\n",
      "epoch:26 step:20771 [D loss: 0.839707, acc: 51.56%] [G loss: 3.378741]\n",
      "epoch:26 step:20772 [D loss: 0.233473, acc: 93.75%] [G loss: 5.097342]\n",
      "epoch:26 step:20773 [D loss: 0.407572, acc: 83.59%] [G loss: 3.208374]\n",
      "epoch:26 step:20774 [D loss: 0.627632, acc: 60.94%] [G loss: 5.418909]\n",
      "epoch:26 step:20775 [D loss: 0.104158, acc: 100.00%] [G loss: 3.809612]\n",
      "epoch:26 step:20776 [D loss: 0.207913, acc: 96.09%] [G loss: 3.362175]\n",
      "epoch:26 step:20777 [D loss: 0.468655, acc: 69.53%] [G loss: 2.708905]\n",
      "epoch:26 step:20778 [D loss: 0.207296, acc: 98.44%] [G loss: 3.762174]\n",
      "epoch:26 step:20779 [D loss: 1.073168, acc: 48.44%] [G loss: 4.648589]\n",
      "epoch:26 step:20780 [D loss: 0.635858, acc: 59.38%] [G loss: 5.028247]\n",
      "epoch:26 step:20781 [D loss: 0.224637, acc: 97.66%] [G loss: 3.495323]\n",
      "epoch:26 step:20782 [D loss: 0.279204, acc: 95.31%] [G loss: 2.401836]\n",
      "epoch:26 step:20783 [D loss: 0.142846, acc: 99.22%] [G loss: 3.710665]\n",
      "epoch:26 step:20784 [D loss: 0.102415, acc: 100.00%] [G loss: 4.900194]\n",
      "epoch:26 step:20785 [D loss: 1.191219, acc: 19.53%] [G loss: 3.694269]\n",
      "epoch:26 step:20786 [D loss: 1.351685, acc: 10.16%] [G loss: 4.309722]\n",
      "epoch:26 step:20787 [D loss: 0.141646, acc: 98.44%] [G loss: 2.002781]\n",
      "epoch:26 step:20788 [D loss: 1.310179, acc: 10.94%] [G loss: 3.301400]\n",
      "epoch:26 step:20789 [D loss: 0.295966, acc: 96.09%] [G loss: 3.586676]\n",
      "epoch:26 step:20790 [D loss: 0.452515, acc: 84.38%] [G loss: 3.914918]\n",
      "epoch:26 step:20791 [D loss: 0.357208, acc: 90.62%] [G loss: 2.705375]\n",
      "epoch:26 step:20792 [D loss: 0.653798, acc: 61.72%] [G loss: 2.984896]\n",
      "epoch:26 step:20793 [D loss: 0.354616, acc: 89.84%] [G loss: 4.452561]\n",
      "epoch:26 step:20794 [D loss: 0.200573, acc: 98.44%] [G loss: 3.909145]\n",
      "epoch:26 step:20795 [D loss: 0.302397, acc: 94.53%] [G loss: 4.146423]\n",
      "epoch:26 step:20796 [D loss: 0.031626, acc: 100.00%] [G loss: 6.538595]\n",
      "epoch:26 step:20797 [D loss: 0.326063, acc: 89.84%] [G loss: 3.529679]\n",
      "epoch:26 step:20798 [D loss: 0.296351, acc: 96.88%] [G loss: 4.178440]\n",
      "epoch:26 step:20799 [D loss: 0.134723, acc: 99.22%] [G loss: 5.507047]\n",
      "epoch:26 step:20800 [D loss: 0.251991, acc: 91.41%] [G loss: 5.975026]\n",
      "##############\n",
      "[0.85456261 0.86775017 0.81595806 0.8081396  0.82555935 0.82960625\n",
      " 0.91165889 0.81923331 0.83450962 0.80129549]\n",
      "##########\n",
      "epoch:26 step:20801 [D loss: 0.630479, acc: 64.06%] [G loss: 6.638843]\n",
      "epoch:26 step:20802 [D loss: 0.139623, acc: 99.22%] [G loss: 2.995453]\n",
      "epoch:26 step:20803 [D loss: 0.217064, acc: 94.53%] [G loss: 3.286380]\n",
      "epoch:26 step:20804 [D loss: 0.371916, acc: 89.84%] [G loss: 3.016751]\n",
      "epoch:26 step:20805 [D loss: 0.396736, acc: 89.84%] [G loss: 4.316532]\n",
      "epoch:26 step:20806 [D loss: 1.022127, acc: 34.38%] [G loss: 4.839930]\n",
      "epoch:26 step:20807 [D loss: 0.306816, acc: 88.28%] [G loss: 3.838388]\n",
      "epoch:26 step:20808 [D loss: 0.177453, acc: 98.44%] [G loss: 5.482490]\n",
      "epoch:26 step:20809 [D loss: 0.428098, acc: 77.34%] [G loss: 3.422858]\n",
      "epoch:26 step:20810 [D loss: 0.933282, acc: 41.41%] [G loss: 3.388075]\n",
      "epoch:26 step:20811 [D loss: 0.390116, acc: 92.19%] [G loss: 1.974412]\n",
      "epoch:26 step:20812 [D loss: 0.079536, acc: 99.22%] [G loss: 3.332317]\n",
      "epoch:26 step:20813 [D loss: 1.227206, acc: 28.12%] [G loss: 2.736968]\n",
      "epoch:26 step:20814 [D loss: 0.815840, acc: 53.12%] [G loss: 4.241444]\n",
      "epoch:26 step:20815 [D loss: 0.271213, acc: 96.09%] [G loss: 4.669661]\n",
      "epoch:26 step:20816 [D loss: 0.693424, acc: 58.59%] [G loss: 3.194243]\n",
      "epoch:26 step:20817 [D loss: 0.148258, acc: 99.22%] [G loss: 5.660530]\n",
      "epoch:26 step:20818 [D loss: 0.116682, acc: 100.00%] [G loss: 5.499914]\n",
      "epoch:26 step:20819 [D loss: 0.695640, acc: 50.00%] [G loss: 3.794960]\n",
      "epoch:26 step:20820 [D loss: 0.309501, acc: 93.75%] [G loss: 3.714467]\n",
      "epoch:26 step:20821 [D loss: 0.305124, acc: 96.88%] [G loss: 5.480488]\n",
      "epoch:26 step:20822 [D loss: 0.200356, acc: 96.88%] [G loss: 3.838458]\n",
      "epoch:26 step:20823 [D loss: 0.051277, acc: 100.00%] [G loss: 5.871661]\n",
      "epoch:26 step:20824 [D loss: 0.400437, acc: 85.16%] [G loss: 6.737929]\n",
      "epoch:26 step:20825 [D loss: 0.296989, acc: 98.44%] [G loss: 1.737929]\n",
      "epoch:26 step:20826 [D loss: 0.214632, acc: 96.88%] [G loss: 3.490567]\n",
      "epoch:26 step:20827 [D loss: 0.975561, acc: 32.03%] [G loss: 3.902906]\n",
      "epoch:26 step:20828 [D loss: 0.315555, acc: 96.09%] [G loss: 2.426669]\n",
      "epoch:26 step:20829 [D loss: 0.712204, acc: 57.03%] [G loss: 2.874945]\n",
      "epoch:26 step:20830 [D loss: 0.381240, acc: 77.34%] [G loss: 5.019102]\n",
      "epoch:26 step:20831 [D loss: 0.895360, acc: 51.56%] [G loss: 2.572997]\n",
      "epoch:26 step:20832 [D loss: 0.726296, acc: 54.69%] [G loss: 4.621032]\n",
      "epoch:26 step:20833 [D loss: 0.226883, acc: 96.88%] [G loss: 4.513303]\n",
      "epoch:26 step:20834 [D loss: 0.753017, acc: 51.56%] [G loss: 3.130567]\n",
      "epoch:26 step:20835 [D loss: 0.101327, acc: 100.00%] [G loss: 3.393684]\n",
      "epoch:26 step:20836 [D loss: 0.547285, acc: 69.53%] [G loss: 3.715414]\n",
      "epoch:26 step:20837 [D loss: 0.494051, acc: 73.44%] [G loss: 3.888260]\n",
      "epoch:26 step:20838 [D loss: 0.755574, acc: 52.34%] [G loss: 2.989080]\n",
      "epoch:26 step:20839 [D loss: 0.336319, acc: 95.31%] [G loss: 3.563855]\n",
      "epoch:26 step:20840 [D loss: 0.402265, acc: 72.66%] [G loss: 5.575539]\n",
      "epoch:26 step:20841 [D loss: 0.799924, acc: 50.78%] [G loss: 5.177004]\n",
      "epoch:26 step:20842 [D loss: 0.089596, acc: 99.22%] [G loss: 4.321395]\n",
      "epoch:26 step:20843 [D loss: 0.392669, acc: 82.81%] [G loss: 5.813745]\n",
      "epoch:26 step:20844 [D loss: 0.333475, acc: 91.41%] [G loss: 6.250585]\n",
      "epoch:26 step:20845 [D loss: 0.717168, acc: 54.69%] [G loss: 3.497252]\n",
      "epoch:26 step:20846 [D loss: 0.310731, acc: 93.75%] [G loss: 5.866711]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:26 step:20847 [D loss: 0.252618, acc: 97.66%] [G loss: 6.469112]\n",
      "epoch:26 step:20848 [D loss: 0.191856, acc: 99.22%] [G loss: 5.610326]\n",
      "epoch:26 step:20849 [D loss: 0.443475, acc: 80.47%] [G loss: 3.484028]\n",
      "epoch:26 step:20850 [D loss: 0.553631, acc: 71.09%] [G loss: 4.233819]\n",
      "epoch:26 step:20851 [D loss: 0.266277, acc: 93.75%] [G loss: 4.300548]\n",
      "epoch:26 step:20852 [D loss: 0.517194, acc: 79.69%] [G loss: 4.540318]\n",
      "epoch:26 step:20853 [D loss: 0.255844, acc: 93.75%] [G loss: 4.374664]\n",
      "epoch:26 step:20854 [D loss: 0.523444, acc: 72.66%] [G loss: 4.323296]\n",
      "epoch:26 step:20855 [D loss: 0.362130, acc: 87.50%] [G loss: 1.989676]\n",
      "epoch:26 step:20856 [D loss: 0.150871, acc: 99.22%] [G loss: 3.900060]\n",
      "epoch:26 step:20857 [D loss: 0.090149, acc: 100.00%] [G loss: 3.493034]\n",
      "epoch:26 step:20858 [D loss: 1.157066, acc: 50.00%] [G loss: 4.527938]\n",
      "epoch:26 step:20859 [D loss: 0.467298, acc: 78.12%] [G loss: 2.757564]\n",
      "epoch:26 step:20860 [D loss: 0.945680, acc: 47.66%] [G loss: 2.481472]\n",
      "epoch:26 step:20861 [D loss: 0.076610, acc: 100.00%] [G loss: 5.125587]\n",
      "epoch:26 step:20862 [D loss: 0.735846, acc: 53.91%] [G loss: 3.947918]\n",
      "epoch:26 step:20863 [D loss: 0.240142, acc: 95.31%] [G loss: 4.218054]\n",
      "epoch:26 step:20864 [D loss: 0.780354, acc: 47.66%] [G loss: 5.214696]\n",
      "epoch:26 step:20865 [D loss: 0.220986, acc: 98.44%] [G loss: 5.316084]\n",
      "epoch:26 step:20866 [D loss: 0.166341, acc: 96.09%] [G loss: 4.052019]\n",
      "epoch:26 step:20867 [D loss: 0.628856, acc: 61.72%] [G loss: 3.858639]\n",
      "epoch:26 step:20868 [D loss: 0.677795, acc: 61.72%] [G loss: 4.737607]\n",
      "epoch:26 step:20869 [D loss: 0.340959, acc: 96.09%] [G loss: 2.984153]\n",
      "epoch:26 step:20870 [D loss: 0.124590, acc: 98.44%] [G loss: 5.232764]\n",
      "epoch:26 step:20871 [D loss: 1.116406, acc: 29.69%] [G loss: 2.416975]\n",
      "epoch:26 step:20872 [D loss: 0.541051, acc: 74.22%] [G loss: 3.306483]\n",
      "epoch:26 step:20873 [D loss: 0.992929, acc: 50.78%] [G loss: 7.050210]\n",
      "epoch:26 step:20874 [D loss: 0.677314, acc: 60.16%] [G loss: 2.819041]\n",
      "epoch:26 step:20875 [D loss: 0.244065, acc: 93.75%] [G loss: 5.685196]\n",
      "epoch:26 step:20876 [D loss: 0.492724, acc: 82.03%] [G loss: 3.363468]\n",
      "epoch:26 step:20877 [D loss: 0.261732, acc: 92.19%] [G loss: 4.554464]\n",
      "epoch:26 step:20878 [D loss: 0.238169, acc: 98.44%] [G loss: 3.695038]\n",
      "epoch:26 step:20879 [D loss: 0.242510, acc: 94.53%] [G loss: 2.706607]\n",
      "epoch:26 step:20880 [D loss: 0.515019, acc: 80.47%] [G loss: 2.999618]\n",
      "epoch:26 step:20881 [D loss: 0.832735, acc: 52.34%] [G loss: 3.554289]\n",
      "epoch:26 step:20882 [D loss: 0.296484, acc: 92.19%] [G loss: 4.649801]\n",
      "epoch:26 step:20883 [D loss: 0.594146, acc: 64.06%] [G loss: 3.718762]\n",
      "epoch:26 step:20884 [D loss: 0.595781, acc: 62.50%] [G loss: 5.327896]\n",
      "epoch:26 step:20885 [D loss: 0.068684, acc: 100.00%] [G loss: 3.409962]\n",
      "epoch:26 step:20886 [D loss: 0.358964, acc: 90.62%] [G loss: 4.094308]\n",
      "epoch:26 step:20887 [D loss: 0.192392, acc: 99.22%] [G loss: 4.542533]\n",
      "epoch:26 step:20888 [D loss: 0.521579, acc: 75.00%] [G loss: 5.462725]\n",
      "epoch:26 step:20889 [D loss: 0.577000, acc: 70.31%] [G loss: 6.007502]\n",
      "epoch:26 step:20890 [D loss: 0.912541, acc: 48.44%] [G loss: 3.339093]\n",
      "epoch:26 step:20891 [D loss: 0.094151, acc: 100.00%] [G loss: 4.609569]\n",
      "epoch:26 step:20892 [D loss: 0.499459, acc: 83.59%] [G loss: 3.081824]\n",
      "epoch:26 step:20893 [D loss: 0.375540, acc: 85.94%] [G loss: 3.184996]\n",
      "epoch:26 step:20894 [D loss: 0.667074, acc: 59.38%] [G loss: 3.004244]\n",
      "epoch:26 step:20895 [D loss: 0.512398, acc: 72.66%] [G loss: 2.185841]\n",
      "epoch:26 step:20896 [D loss: 0.129582, acc: 99.22%] [G loss: 4.158054]\n",
      "epoch:26 step:20897 [D loss: 0.916912, acc: 43.75%] [G loss: 3.438910]\n",
      "epoch:26 step:20898 [D loss: 0.800557, acc: 42.19%] [G loss: 3.350422]\n",
      "epoch:26 step:20899 [D loss: 0.119017, acc: 99.22%] [G loss: 4.191486]\n",
      "epoch:26 step:20900 [D loss: 0.679580, acc: 59.38%] [G loss: 3.736566]\n",
      "epoch:26 step:20901 [D loss: 0.366499, acc: 88.28%] [G loss: 2.975196]\n",
      "epoch:26 step:20902 [D loss: 0.652225, acc: 56.25%] [G loss: 5.489788]\n",
      "epoch:26 step:20903 [D loss: 0.345273, acc: 90.62%] [G loss: 3.056404]\n",
      "epoch:26 step:20904 [D loss: 0.343171, acc: 86.72%] [G loss: 5.067905]\n",
      "epoch:26 step:20905 [D loss: 1.501732, acc: 23.44%] [G loss: 4.610386]\n",
      "epoch:26 step:20906 [D loss: 0.351039, acc: 92.19%] [G loss: 3.108177]\n",
      "epoch:26 step:20907 [D loss: 0.821453, acc: 42.19%] [G loss: 4.121380]\n",
      "epoch:26 step:20908 [D loss: 0.352586, acc: 92.97%] [G loss: 2.241046]\n",
      "epoch:26 step:20909 [D loss: 0.445894, acc: 85.16%] [G loss: 3.588079]\n",
      "epoch:26 step:20910 [D loss: 0.956822, acc: 50.00%] [G loss: 4.435263]\n",
      "epoch:26 step:20911 [D loss: 0.294026, acc: 95.31%] [G loss: 3.205530]\n",
      "epoch:26 step:20912 [D loss: 0.550432, acc: 71.09%] [G loss: 3.938828]\n",
      "epoch:26 step:20913 [D loss: 0.214453, acc: 95.31%] [G loss: 5.805794]\n",
      "epoch:26 step:20914 [D loss: 0.080493, acc: 100.00%] [G loss: 3.776141]\n",
      "epoch:26 step:20915 [D loss: 0.184264, acc: 96.09%] [G loss: 3.682416]\n",
      "epoch:26 step:20916 [D loss: 0.392597, acc: 87.50%] [G loss: 3.336490]\n",
      "epoch:26 step:20917 [D loss: 0.858367, acc: 38.28%] [G loss: 3.910584]\n",
      "epoch:26 step:20918 [D loss: 0.434182, acc: 78.91%] [G loss: 4.364904]\n",
      "epoch:26 step:20919 [D loss: 0.532663, acc: 62.50%] [G loss: 4.151442]\n",
      "epoch:26 step:20920 [D loss: 0.089578, acc: 100.00%] [G loss: 4.061007]\n",
      "epoch:26 step:20921 [D loss: 0.337860, acc: 83.59%] [G loss: 3.607322]\n",
      "epoch:26 step:20922 [D loss: 0.414521, acc: 89.06%] [G loss: 3.610519]\n",
      "epoch:26 step:20923 [D loss: 0.574715, acc: 64.84%] [G loss: 4.238657]\n",
      "epoch:26 step:20924 [D loss: 0.450530, acc: 85.94%] [G loss: 2.537998]\n",
      "epoch:26 step:20925 [D loss: 0.388799, acc: 85.16%] [G loss: 2.319776]\n",
      "epoch:26 step:20926 [D loss: 0.686724, acc: 57.81%] [G loss: 4.805523]\n",
      "epoch:26 step:20927 [D loss: 0.511844, acc: 67.97%] [G loss: 3.836195]\n",
      "epoch:26 step:20928 [D loss: 1.275627, acc: 9.38%] [G loss: 4.113405]\n",
      "epoch:26 step:20929 [D loss: 0.575675, acc: 67.97%] [G loss: 3.338935]\n",
      "epoch:26 step:20930 [D loss: 0.120608, acc: 100.00%] [G loss: 4.219659]\n",
      "epoch:26 step:20931 [D loss: 0.215341, acc: 96.88%] [G loss: 5.503857]\n",
      "epoch:26 step:20932 [D loss: 0.697639, acc: 57.81%] [G loss: 3.325040]\n",
      "epoch:26 step:20933 [D loss: 0.445107, acc: 85.16%] [G loss: 3.312527]\n",
      "epoch:26 step:20934 [D loss: 0.043370, acc: 100.00%] [G loss: 4.984563]\n",
      "epoch:26 step:20935 [D loss: 0.389710, acc: 82.81%] [G loss: 3.377667]\n",
      "epoch:26 step:20936 [D loss: 0.304348, acc: 84.38%] [G loss: 3.927443]\n",
      "epoch:26 step:20937 [D loss: 0.213643, acc: 96.88%] [G loss: 3.283171]\n",
      "epoch:26 step:20938 [D loss: 1.282817, acc: 22.66%] [G loss: 2.140220]\n",
      "epoch:26 step:20939 [D loss: 0.804472, acc: 51.56%] [G loss: 4.375935]\n",
      "epoch:26 step:20940 [D loss: 0.302598, acc: 95.31%] [G loss: 3.306999]\n",
      "epoch:26 step:20941 [D loss: 0.789144, acc: 50.78%] [G loss: 3.997501]\n",
      "epoch:26 step:20942 [D loss: 0.174594, acc: 99.22%] [G loss: 3.915014]\n",
      "epoch:26 step:20943 [D loss: 0.201632, acc: 99.22%] [G loss: 3.265641]\n",
      "epoch:26 step:20944 [D loss: 0.600307, acc: 64.84%] [G loss: 4.180274]\n",
      "epoch:26 step:20945 [D loss: 0.435682, acc: 70.31%] [G loss: 3.067153]\n",
      "epoch:26 step:20946 [D loss: 0.029537, acc: 100.00%] [G loss: 5.251073]\n",
      "epoch:26 step:20947 [D loss: 0.275829, acc: 96.88%] [G loss: 2.456618]\n",
      "epoch:26 step:20948 [D loss: 0.089032, acc: 100.00%] [G loss: 4.965802]\n",
      "epoch:26 step:20949 [D loss: 1.035908, acc: 32.81%] [G loss: 4.040191]\n",
      "epoch:26 step:20950 [D loss: 0.144339, acc: 98.44%] [G loss: 3.988338]\n",
      "epoch:26 step:20951 [D loss: 0.256389, acc: 92.19%] [G loss: 3.546851]\n",
      "epoch:26 step:20952 [D loss: 0.369273, acc: 82.81%] [G loss: 4.206539]\n",
      "epoch:26 step:20953 [D loss: 0.543198, acc: 72.66%] [G loss: 3.460684]\n",
      "epoch:26 step:20954 [D loss: 0.219670, acc: 97.66%] [G loss: 4.458145]\n",
      "epoch:26 step:20955 [D loss: 0.184836, acc: 98.44%] [G loss: 4.278735]\n",
      "epoch:26 step:20956 [D loss: 0.636276, acc: 64.06%] [G loss: 3.143902]\n",
      "epoch:26 step:20957 [D loss: 0.122183, acc: 99.22%] [G loss: 3.325900]\n",
      "epoch:26 step:20958 [D loss: 0.080647, acc: 100.00%] [G loss: 3.096050]\n",
      "epoch:26 step:20959 [D loss: 0.099148, acc: 99.22%] [G loss: 5.100511]\n",
      "epoch:26 step:20960 [D loss: 0.480575, acc: 72.66%] [G loss: 5.022380]\n",
      "epoch:26 step:20961 [D loss: 0.247269, acc: 99.22%] [G loss: 4.469429]\n",
      "epoch:26 step:20962 [D loss: 1.254598, acc: 50.00%] [G loss: 6.493193]\n",
      "epoch:26 step:20963 [D loss: 0.202673, acc: 96.09%] [G loss: 4.740506]\n",
      "epoch:26 step:20964 [D loss: 0.203969, acc: 96.88%] [G loss: 3.064590]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:26 step:20965 [D loss: 0.810624, acc: 51.56%] [G loss: 5.914492]\n",
      "epoch:26 step:20966 [D loss: 0.117635, acc: 100.00%] [G loss: 3.198056]\n",
      "epoch:26 step:20967 [D loss: 0.286762, acc: 90.62%] [G loss: 4.534614]\n",
      "epoch:26 step:20968 [D loss: 0.582537, acc: 60.16%] [G loss: 5.024100]\n",
      "epoch:26 step:20969 [D loss: 0.197973, acc: 97.66%] [G loss: 5.183173]\n",
      "epoch:26 step:20970 [D loss: 0.142037, acc: 100.00%] [G loss: 5.503320]\n",
      "epoch:26 step:20971 [D loss: 0.482257, acc: 79.69%] [G loss: 2.921573]\n",
      "epoch:26 step:20972 [D loss: 0.884366, acc: 51.56%] [G loss: 3.673143]\n",
      "epoch:26 step:20973 [D loss: 0.113443, acc: 100.00%] [G loss: 4.913954]\n",
      "epoch:26 step:20974 [D loss: 0.709613, acc: 52.34%] [G loss: 5.989231]\n",
      "epoch:26 step:20975 [D loss: 0.156600, acc: 100.00%] [G loss: 4.103804]\n",
      "epoch:26 step:20976 [D loss: 0.462831, acc: 82.81%] [G loss: 4.182664]\n",
      "epoch:26 step:20977 [D loss: 0.403966, acc: 79.69%] [G loss: 3.065363]\n",
      "epoch:26 step:20978 [D loss: 0.350870, acc: 89.06%] [G loss: 3.176521]\n",
      "epoch:26 step:20979 [D loss: 0.586765, acc: 67.19%] [G loss: 3.306881]\n",
      "epoch:26 step:20980 [D loss: 0.310092, acc: 89.84%] [G loss: 3.558759]\n",
      "epoch:26 step:20981 [D loss: 0.649340, acc: 64.84%] [G loss: 3.707997]\n",
      "epoch:26 step:20982 [D loss: 0.265627, acc: 96.09%] [G loss: 4.161779]\n",
      "epoch:26 step:20983 [D loss: 0.170297, acc: 99.22%] [G loss: 5.479392]\n",
      "epoch:26 step:20984 [D loss: 0.500389, acc: 80.47%] [G loss: 7.035854]\n",
      "epoch:26 step:20985 [D loss: 0.100477, acc: 100.00%] [G loss: 3.097039]\n",
      "epoch:26 step:20986 [D loss: 0.159722, acc: 98.44%] [G loss: 2.529898]\n",
      "epoch:26 step:20987 [D loss: 0.211042, acc: 99.22%] [G loss: 6.206255]\n",
      "epoch:26 step:20988 [D loss: 0.526390, acc: 75.78%] [G loss: 4.885149]\n",
      "epoch:26 step:20989 [D loss: 0.335134, acc: 91.41%] [G loss: 4.052551]\n",
      "epoch:26 step:20990 [D loss: 0.186912, acc: 100.00%] [G loss: 3.795095]\n",
      "epoch:26 step:20991 [D loss: 0.171581, acc: 99.22%] [G loss: 3.381945]\n",
      "epoch:26 step:20992 [D loss: 0.605899, acc: 68.75%] [G loss: 5.454955]\n",
      "epoch:26 step:20993 [D loss: 0.365052, acc: 87.50%] [G loss: 3.527717]\n",
      "epoch:26 step:20994 [D loss: 0.338589, acc: 93.75%] [G loss: 3.808752]\n",
      "epoch:26 step:20995 [D loss: 0.268341, acc: 95.31%] [G loss: 4.402278]\n",
      "epoch:26 step:20996 [D loss: 0.477929, acc: 66.41%] [G loss: 4.191615]\n",
      "epoch:26 step:20997 [D loss: 0.291023, acc: 98.44%] [G loss: 5.602689]\n",
      "epoch:26 step:20998 [D loss: 1.363814, acc: 28.12%] [G loss: 4.768747]\n",
      "epoch:26 step:20999 [D loss: 0.474430, acc: 81.25%] [G loss: 5.056744]\n",
      "epoch:26 step:21000 [D loss: 0.275657, acc: 95.31%] [G loss: 3.988994]\n",
      "##############\n",
      "[0.8589118  0.87446675 0.80759599 0.81275035 0.79882103 0.82415126\n",
      " 0.8698625  0.8432054  0.82270907 0.8208906 ]\n",
      "##########\n",
      "epoch:26 step:21001 [D loss: 0.163596, acc: 97.66%] [G loss: 4.077692]\n",
      "epoch:26 step:21002 [D loss: 0.661867, acc: 71.09%] [G loss: 4.510017]\n",
      "epoch:26 step:21003 [D loss: 1.000132, acc: 44.53%] [G loss: 3.561555]\n",
      "epoch:26 step:21004 [D loss: 0.313292, acc: 92.97%] [G loss: 3.551768]\n",
      "epoch:26 step:21005 [D loss: 0.741300, acc: 52.34%] [G loss: 4.046293]\n",
      "epoch:26 step:21006 [D loss: 0.624671, acc: 67.19%] [G loss: 4.625829]\n",
      "epoch:26 step:21007 [D loss: 0.161790, acc: 99.22%] [G loss: 3.576462]\n",
      "epoch:26 step:21008 [D loss: 0.691849, acc: 57.03%] [G loss: 2.289795]\n",
      "epoch:26 step:21009 [D loss: 0.304559, acc: 94.53%] [G loss: 2.654652]\n",
      "epoch:26 step:21010 [D loss: 0.517912, acc: 64.84%] [G loss: 4.206143]\n",
      "epoch:26 step:21011 [D loss: 0.502314, acc: 70.31%] [G loss: 3.514357]\n",
      "epoch:26 step:21012 [D loss: 0.671278, acc: 57.81%] [G loss: 3.934436]\n",
      "epoch:26 step:21013 [D loss: 0.272327, acc: 88.28%] [G loss: 4.056469]\n",
      "epoch:26 step:21014 [D loss: 0.366782, acc: 80.47%] [G loss: 3.851831]\n",
      "epoch:26 step:21015 [D loss: 0.308586, acc: 90.62%] [G loss: 4.183737]\n",
      "epoch:26 step:21016 [D loss: 0.351426, acc: 93.75%] [G loss: 2.235763]\n",
      "epoch:26 step:21017 [D loss: 0.209618, acc: 94.53%] [G loss: 6.570992]\n",
      "epoch:26 step:21018 [D loss: 0.251412, acc: 95.31%] [G loss: 2.221510]\n",
      "epoch:26 step:21019 [D loss: 0.434001, acc: 81.25%] [G loss: 3.714038]\n",
      "epoch:26 step:21020 [D loss: 0.222211, acc: 99.22%] [G loss: 4.184942]\n",
      "epoch:26 step:21021 [D loss: 0.686700, acc: 53.91%] [G loss: 4.907678]\n",
      "epoch:26 step:21022 [D loss: 0.635191, acc: 60.16%] [G loss: 6.307306]\n",
      "epoch:26 step:21023 [D loss: 0.129136, acc: 99.22%] [G loss: 4.386665]\n",
      "epoch:26 step:21024 [D loss: 0.159493, acc: 99.22%] [G loss: 3.836923]\n",
      "epoch:26 step:21025 [D loss: 0.749434, acc: 50.78%] [G loss: 3.676272]\n",
      "epoch:26 step:21026 [D loss: 0.494378, acc: 71.09%] [G loss: 2.024355]\n",
      "epoch:26 step:21027 [D loss: 0.641124, acc: 64.06%] [G loss: 2.750728]\n",
      "epoch:26 step:21028 [D loss: 0.147598, acc: 97.66%] [G loss: 4.897941]\n",
      "epoch:26 step:21029 [D loss: 0.086758, acc: 100.00%] [G loss: 4.176978]\n",
      "epoch:26 step:21030 [D loss: 0.354016, acc: 90.62%] [G loss: 3.750594]\n",
      "epoch:26 step:21031 [D loss: 0.637506, acc: 64.84%] [G loss: 4.609588]\n",
      "epoch:26 step:21032 [D loss: 0.302711, acc: 88.28%] [G loss: 3.625520]\n",
      "epoch:26 step:21033 [D loss: 0.371952, acc: 83.59%] [G loss: 3.662409]\n",
      "epoch:26 step:21034 [D loss: 0.855459, acc: 53.12%] [G loss: 3.336939]\n",
      "epoch:26 step:21035 [D loss: 0.473354, acc: 81.25%] [G loss: 3.924628]\n",
      "epoch:26 step:21036 [D loss: 0.248470, acc: 96.09%] [G loss: 2.631137]\n",
      "epoch:26 step:21037 [D loss: 0.746340, acc: 54.69%] [G loss: 4.056021]\n",
      "epoch:26 step:21038 [D loss: 0.594624, acc: 64.84%] [G loss: 4.205905]\n",
      "epoch:26 step:21039 [D loss: 0.929940, acc: 49.22%] [G loss: 2.726064]\n",
      "epoch:26 step:21040 [D loss: 1.179947, acc: 44.53%] [G loss: 4.690331]\n",
      "epoch:26 step:21041 [D loss: 0.120958, acc: 98.44%] [G loss: 3.833898]\n",
      "epoch:26 step:21042 [D loss: 0.341756, acc: 83.59%] [G loss: 3.363595]\n",
      "epoch:26 step:21043 [D loss: 0.042337, acc: 100.00%] [G loss: 7.113879]\n",
      "epoch:26 step:21044 [D loss: 0.463165, acc: 83.59%] [G loss: 7.137551]\n",
      "epoch:26 step:21045 [D loss: 0.229894, acc: 96.09%] [G loss: 3.362805]\n",
      "epoch:26 step:21046 [D loss: 0.193038, acc: 99.22%] [G loss: 3.672899]\n",
      "epoch:26 step:21047 [D loss: 0.489994, acc: 78.12%] [G loss: 4.942966]\n",
      "epoch:26 step:21048 [D loss: 0.576360, acc: 72.66%] [G loss: 3.499930]\n",
      "epoch:26 step:21049 [D loss: 0.660626, acc: 58.59%] [G loss: 4.471650]\n",
      "epoch:26 step:21050 [D loss: 0.610981, acc: 63.28%] [G loss: 3.889357]\n",
      "epoch:26 step:21051 [D loss: 0.263921, acc: 98.44%] [G loss: 2.375991]\n",
      "epoch:26 step:21052 [D loss: 0.437640, acc: 71.88%] [G loss: 5.521377]\n",
      "epoch:26 step:21053 [D loss: 0.668628, acc: 62.50%] [G loss: 4.396536]\n",
      "epoch:26 step:21054 [D loss: 0.378516, acc: 78.12%] [G loss: 3.871778]\n",
      "epoch:26 step:21055 [D loss: 0.415238, acc: 79.69%] [G loss: 3.797701]\n",
      "epoch:26 step:21056 [D loss: 0.610821, acc: 65.62%] [G loss: 4.951648]\n",
      "epoch:26 step:21057 [D loss: 0.741438, acc: 54.69%] [G loss: 2.794825]\n",
      "epoch:26 step:21058 [D loss: 0.175906, acc: 98.44%] [G loss: 3.869555]\n",
      "epoch:26 step:21059 [D loss: 0.768717, acc: 54.69%] [G loss: 5.867300]\n",
      "epoch:26 step:21060 [D loss: 0.323542, acc: 91.41%] [G loss: 4.557991]\n",
      "epoch:26 step:21061 [D loss: 0.470049, acc: 76.56%] [G loss: 3.351990]\n",
      "epoch:26 step:21062 [D loss: 0.153845, acc: 96.88%] [G loss: 7.148712]\n",
      "epoch:26 step:21063 [D loss: 0.369324, acc: 80.47%] [G loss: 4.925416]\n",
      "epoch:26 step:21064 [D loss: 0.231450, acc: 95.31%] [G loss: 3.719436]\n",
      "epoch:26 step:21065 [D loss: 0.814518, acc: 52.34%] [G loss: 4.369498]\n",
      "epoch:26 step:21066 [D loss: 0.159415, acc: 98.44%] [G loss: 7.038958]\n",
      "epoch:26 step:21067 [D loss: 0.268900, acc: 98.44%] [G loss: 4.160716]\n",
      "epoch:26 step:21068 [D loss: 0.215928, acc: 95.31%] [G loss: 4.753704]\n",
      "epoch:26 step:21069 [D loss: 0.423131, acc: 86.72%] [G loss: 3.687927]\n",
      "epoch:26 step:21070 [D loss: 0.147580, acc: 100.00%] [G loss: 4.185601]\n",
      "epoch:26 step:21071 [D loss: 0.119035, acc: 100.00%] [G loss: 5.013440]\n",
      "epoch:26 step:21072 [D loss: 0.114534, acc: 100.00%] [G loss: 4.427470]\n",
      "epoch:26 step:21073 [D loss: 0.768820, acc: 53.12%] [G loss: 4.560208]\n",
      "epoch:26 step:21074 [D loss: 0.345725, acc: 85.94%] [G loss: 4.705667]\n",
      "epoch:26 step:21075 [D loss: 0.685030, acc: 59.38%] [G loss: 3.379621]\n",
      "epoch:26 step:21076 [D loss: 0.248647, acc: 93.75%] [G loss: 4.173279]\n",
      "epoch:26 step:21077 [D loss: 0.596180, acc: 59.38%] [G loss: 3.951076]\n",
      "epoch:26 step:21078 [D loss: 0.297038, acc: 86.72%] [G loss: 3.375380]\n",
      "epoch:26 step:21079 [D loss: 0.588625, acc: 61.72%] [G loss: 5.176717]\n",
      "epoch:26 step:21080 [D loss: 0.268734, acc: 96.88%] [G loss: 5.102133]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:26 step:21081 [D loss: 0.243544, acc: 96.09%] [G loss: 3.534073]\n",
      "epoch:26 step:21082 [D loss: 0.545226, acc: 67.97%] [G loss: 5.401920]\n",
      "epoch:26 step:21083 [D loss: 0.479816, acc: 79.69%] [G loss: 3.628930]\n",
      "epoch:26 step:21084 [D loss: 0.354409, acc: 77.34%] [G loss: 3.244061]\n",
      "epoch:26 step:21085 [D loss: 0.712833, acc: 53.12%] [G loss: 5.880780]\n",
      "epoch:26 step:21086 [D loss: 0.398551, acc: 80.47%] [G loss: 4.373889]\n",
      "epoch:26 step:21087 [D loss: 0.602157, acc: 71.09%] [G loss: 3.235188]\n",
      "epoch:27 step:21088 [D loss: 0.948450, acc: 51.56%] [G loss: 2.237840]\n",
      "epoch:27 step:21089 [D loss: 0.330332, acc: 92.19%] [G loss: 2.605484]\n",
      "epoch:27 step:21090 [D loss: 0.416617, acc: 81.25%] [G loss: 3.588628]\n",
      "epoch:27 step:21091 [D loss: 0.595657, acc: 63.28%] [G loss: 4.068134]\n",
      "epoch:27 step:21092 [D loss: 0.432835, acc: 75.78%] [G loss: 5.127378]\n",
      "epoch:27 step:21093 [D loss: 0.429727, acc: 89.84%] [G loss: 2.970384]\n",
      "epoch:27 step:21094 [D loss: 0.341889, acc: 85.94%] [G loss: 2.528219]\n",
      "epoch:27 step:21095 [D loss: 0.174404, acc: 98.44%] [G loss: 5.056368]\n",
      "epoch:27 step:21096 [D loss: 0.891551, acc: 50.00%] [G loss: 4.764356]\n",
      "epoch:27 step:21097 [D loss: 0.697305, acc: 56.25%] [G loss: 4.262262]\n",
      "epoch:27 step:21098 [D loss: 0.133340, acc: 99.22%] [G loss: 4.286952]\n",
      "epoch:27 step:21099 [D loss: 0.534497, acc: 66.41%] [G loss: 5.889042]\n",
      "epoch:27 step:21100 [D loss: 0.237508, acc: 97.66%] [G loss: 5.381652]\n",
      "epoch:27 step:21101 [D loss: 0.199311, acc: 100.00%] [G loss: 3.234039]\n",
      "epoch:27 step:21102 [D loss: 1.105108, acc: 42.19%] [G loss: 4.175450]\n",
      "epoch:27 step:21103 [D loss: 0.455071, acc: 82.81%] [G loss: 2.342201]\n",
      "epoch:27 step:21104 [D loss: 0.377413, acc: 90.62%] [G loss: 4.059114]\n",
      "epoch:27 step:21105 [D loss: 0.523151, acc: 81.25%] [G loss: 4.422513]\n",
      "epoch:27 step:21106 [D loss: 0.435734, acc: 76.56%] [G loss: 5.575568]\n",
      "epoch:27 step:21107 [D loss: 0.926871, acc: 46.09%] [G loss: 3.913762]\n",
      "epoch:27 step:21108 [D loss: 0.237911, acc: 98.44%] [G loss: 5.138318]\n",
      "epoch:27 step:21109 [D loss: 0.182401, acc: 96.09%] [G loss: 6.581614]\n",
      "epoch:27 step:21110 [D loss: 0.243009, acc: 99.22%] [G loss: 4.445983]\n",
      "epoch:27 step:21111 [D loss: 1.242052, acc: 50.00%] [G loss: 5.724760]\n",
      "epoch:27 step:21112 [D loss: 0.896293, acc: 42.19%] [G loss: 4.233346]\n",
      "epoch:27 step:21113 [D loss: 0.142733, acc: 100.00%] [G loss: 2.195126]\n",
      "epoch:27 step:21114 [D loss: 0.319195, acc: 90.62%] [G loss: 2.964221]\n",
      "epoch:27 step:21115 [D loss: 0.212296, acc: 95.31%] [G loss: 5.203410]\n",
      "epoch:27 step:21116 [D loss: 0.087185, acc: 100.00%] [G loss: 5.552567]\n",
      "epoch:27 step:21117 [D loss: 0.144022, acc: 97.66%] [G loss: 5.267035]\n",
      "epoch:27 step:21118 [D loss: 1.286464, acc: 46.09%] [G loss: 4.972139]\n",
      "epoch:27 step:21119 [D loss: 0.536889, acc: 65.62%] [G loss: 6.120278]\n",
      "epoch:27 step:21120 [D loss: 0.672410, acc: 64.06%] [G loss: 4.903544]\n",
      "epoch:27 step:21121 [D loss: 0.550144, acc: 62.50%] [G loss: 3.342775]\n",
      "epoch:27 step:21122 [D loss: 0.132477, acc: 99.22%] [G loss: 4.403512]\n",
      "epoch:27 step:21123 [D loss: 0.147916, acc: 99.22%] [G loss: 6.477240]\n",
      "epoch:27 step:21124 [D loss: 0.594722, acc: 68.75%] [G loss: 4.696688]\n",
      "epoch:27 step:21125 [D loss: 0.179020, acc: 100.00%] [G loss: 3.398802]\n",
      "epoch:27 step:21126 [D loss: 0.431445, acc: 87.50%] [G loss: 5.478980]\n",
      "epoch:27 step:21127 [D loss: 0.151863, acc: 100.00%] [G loss: 4.379309]\n",
      "epoch:27 step:21128 [D loss: 0.181741, acc: 100.00%] [G loss: 3.752658]\n",
      "epoch:27 step:21129 [D loss: 0.300359, acc: 94.53%] [G loss: 3.697416]\n",
      "epoch:27 step:21130 [D loss: 0.737054, acc: 55.47%] [G loss: 2.452487]\n",
      "epoch:27 step:21131 [D loss: 0.347008, acc: 82.81%] [G loss: 5.918408]\n",
      "epoch:27 step:21132 [D loss: 0.505300, acc: 76.56%] [G loss: 3.533437]\n",
      "epoch:27 step:21133 [D loss: 0.338789, acc: 91.41%] [G loss: 3.036010]\n",
      "epoch:27 step:21134 [D loss: 0.370799, acc: 88.28%] [G loss: 1.844747]\n",
      "epoch:27 step:21135 [D loss: 0.134474, acc: 99.22%] [G loss: 2.732469]\n",
      "epoch:27 step:21136 [D loss: 0.540178, acc: 65.62%] [G loss: 3.264449]\n",
      "epoch:27 step:21137 [D loss: 0.736969, acc: 47.66%] [G loss: 2.812499]\n",
      "epoch:27 step:21138 [D loss: 0.278105, acc: 89.84%] [G loss: 5.224331]\n",
      "epoch:27 step:21139 [D loss: 0.232443, acc: 92.97%] [G loss: 5.126048]\n",
      "epoch:27 step:21140 [D loss: 0.243226, acc: 92.97%] [G loss: 3.275795]\n",
      "epoch:27 step:21141 [D loss: 0.585210, acc: 74.22%] [G loss: 2.927067]\n",
      "epoch:27 step:21142 [D loss: 0.356874, acc: 91.41%] [G loss: 4.932642]\n",
      "epoch:27 step:21143 [D loss: 1.277291, acc: 30.47%] [G loss: 5.163427]\n",
      "epoch:27 step:21144 [D loss: 0.536079, acc: 70.31%] [G loss: 6.217664]\n",
      "epoch:27 step:21145 [D loss: 0.965616, acc: 28.12%] [G loss: 3.694987]\n",
      "epoch:27 step:21146 [D loss: 0.264912, acc: 94.53%] [G loss: 3.300116]\n",
      "epoch:27 step:21147 [D loss: 0.231448, acc: 93.75%] [G loss: 4.161368]\n",
      "epoch:27 step:21148 [D loss: 0.390768, acc: 87.50%] [G loss: 3.226738]\n",
      "epoch:27 step:21149 [D loss: 0.659076, acc: 57.03%] [G loss: 4.407496]\n",
      "epoch:27 step:21150 [D loss: 0.708933, acc: 54.69%] [G loss: 3.830914]\n",
      "epoch:27 step:21151 [D loss: 0.181342, acc: 100.00%] [G loss: 2.223423]\n",
      "epoch:27 step:21152 [D loss: 0.904045, acc: 40.62%] [G loss: 2.583758]\n",
      "epoch:27 step:21153 [D loss: 0.277397, acc: 92.19%] [G loss: 4.177825]\n",
      "epoch:27 step:21154 [D loss: 0.332857, acc: 91.41%] [G loss: 4.334366]\n",
      "epoch:27 step:21155 [D loss: 0.427846, acc: 82.81%] [G loss: 2.747922]\n",
      "epoch:27 step:21156 [D loss: 0.137752, acc: 100.00%] [G loss: 3.299255]\n",
      "epoch:27 step:21157 [D loss: 0.565202, acc: 54.69%] [G loss: 3.557164]\n",
      "epoch:27 step:21158 [D loss: 0.147824, acc: 99.22%] [G loss: 2.145794]\n",
      "epoch:27 step:21159 [D loss: 0.514940, acc: 64.06%] [G loss: 4.788883]\n",
      "epoch:27 step:21160 [D loss: 0.119093, acc: 100.00%] [G loss: 4.259684]\n",
      "epoch:27 step:21161 [D loss: 0.268382, acc: 93.75%] [G loss: 6.757158]\n",
      "epoch:27 step:21162 [D loss: 0.378960, acc: 87.50%] [G loss: 3.761154]\n",
      "epoch:27 step:21163 [D loss: 0.169924, acc: 97.66%] [G loss: 4.973102]\n",
      "epoch:27 step:21164 [D loss: 0.734329, acc: 50.78%] [G loss: 4.070827]\n",
      "epoch:27 step:21165 [D loss: 0.793420, acc: 50.00%] [G loss: 2.346354]\n",
      "epoch:27 step:21166 [D loss: 0.391884, acc: 77.34%] [G loss: 3.761410]\n",
      "epoch:27 step:21167 [D loss: 0.526882, acc: 69.53%] [G loss: 3.799666]\n",
      "epoch:27 step:21168 [D loss: 0.561437, acc: 57.81%] [G loss: 2.522324]\n",
      "epoch:27 step:21169 [D loss: 0.581881, acc: 60.16%] [G loss: 3.950973]\n",
      "epoch:27 step:21170 [D loss: 0.827287, acc: 44.53%] [G loss: 3.847792]\n",
      "epoch:27 step:21171 [D loss: 0.413059, acc: 89.06%] [G loss: 4.103699]\n",
      "epoch:27 step:21172 [D loss: 0.503533, acc: 80.47%] [G loss: 3.489623]\n",
      "epoch:27 step:21173 [D loss: 0.519740, acc: 62.50%] [G loss: 2.131249]\n",
      "epoch:27 step:21174 [D loss: 0.145198, acc: 98.44%] [G loss: 7.547258]\n",
      "epoch:27 step:21175 [D loss: 0.710746, acc: 53.12%] [G loss: 2.612158]\n",
      "epoch:27 step:21176 [D loss: 0.066192, acc: 100.00%] [G loss: 4.362636]\n",
      "epoch:27 step:21177 [D loss: 0.362175, acc: 90.62%] [G loss: 5.895462]\n",
      "epoch:27 step:21178 [D loss: 0.256823, acc: 95.31%] [G loss: 3.620421]\n",
      "epoch:27 step:21179 [D loss: 0.054309, acc: 100.00%] [G loss: 7.773251]\n",
      "epoch:27 step:21180 [D loss: 0.447173, acc: 71.88%] [G loss: 4.376133]\n",
      "epoch:27 step:21181 [D loss: 0.830704, acc: 49.22%] [G loss: 4.429542]\n",
      "epoch:27 step:21182 [D loss: 0.099000, acc: 100.00%] [G loss: 3.079096]\n",
      "epoch:27 step:21183 [D loss: 0.337604, acc: 92.19%] [G loss: 5.068827]\n",
      "epoch:27 step:21184 [D loss: 0.516496, acc: 81.25%] [G loss: 2.695339]\n",
      "epoch:27 step:21185 [D loss: 0.319314, acc: 88.28%] [G loss: 4.508535]\n",
      "epoch:27 step:21186 [D loss: 0.212646, acc: 97.66%] [G loss: 3.159292]\n",
      "epoch:27 step:21187 [D loss: 0.458073, acc: 82.81%] [G loss: 3.644138]\n",
      "epoch:27 step:21188 [D loss: 0.362788, acc: 82.03%] [G loss: 5.488044]\n",
      "epoch:27 step:21189 [D loss: 0.321368, acc: 84.38%] [G loss: 5.424722]\n",
      "epoch:27 step:21190 [D loss: 0.445080, acc: 75.00%] [G loss: 3.558100]\n",
      "epoch:27 step:21191 [D loss: 0.474916, acc: 79.69%] [G loss: 4.031293]\n",
      "epoch:27 step:21192 [D loss: 0.291825, acc: 96.09%] [G loss: 2.991740]\n",
      "epoch:27 step:21193 [D loss: 0.372406, acc: 83.59%] [G loss: 3.084644]\n",
      "epoch:27 step:21194 [D loss: 0.707943, acc: 56.25%] [G loss: 5.150689]\n",
      "epoch:27 step:21195 [D loss: 0.255740, acc: 98.44%] [G loss: 5.198359]\n",
      "epoch:27 step:21196 [D loss: 0.468003, acc: 71.09%] [G loss: 2.534412]\n",
      "epoch:27 step:21197 [D loss: 0.466117, acc: 82.81%] [G loss: 2.771053]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:27 step:21198 [D loss: 0.373622, acc: 82.81%] [G loss: 5.286331]\n",
      "epoch:27 step:21199 [D loss: 1.537598, acc: 31.25%] [G loss: 3.552340]\n",
      "epoch:27 step:21200 [D loss: 0.063119, acc: 100.00%] [G loss: 6.438978]\n",
      "##############\n",
      "[0.84657883 0.85908034 0.79167937 0.80620527 0.78238514 0.81585051\n",
      " 0.90621972 0.81165077 0.82140038 0.84813331]\n",
      "##########\n",
      "epoch:27 step:21201 [D loss: 0.809633, acc: 52.34%] [G loss: 6.035850]\n",
      "epoch:27 step:21202 [D loss: 0.883197, acc: 45.31%] [G loss: 4.179921]\n",
      "epoch:27 step:21203 [D loss: 0.263443, acc: 94.53%] [G loss: 3.633323]\n",
      "epoch:27 step:21204 [D loss: 0.355637, acc: 80.47%] [G loss: 8.081285]\n",
      "epoch:27 step:21205 [D loss: 0.822683, acc: 50.78%] [G loss: 1.950997]\n",
      "epoch:27 step:21206 [D loss: 0.981767, acc: 51.56%] [G loss: 5.375406]\n",
      "epoch:27 step:21207 [D loss: 0.188307, acc: 96.09%] [G loss: 5.023412]\n",
      "epoch:27 step:21208 [D loss: 0.112778, acc: 99.22%] [G loss: 1.796493]\n",
      "epoch:27 step:21209 [D loss: 0.490836, acc: 66.41%] [G loss: 5.034829]\n",
      "epoch:27 step:21210 [D loss: 0.243553, acc: 97.66%] [G loss: 3.446604]\n",
      "epoch:27 step:21211 [D loss: 0.313714, acc: 96.09%] [G loss: 4.365370]\n",
      "epoch:27 step:21212 [D loss: 0.858065, acc: 46.09%] [G loss: 3.922085]\n",
      "epoch:27 step:21213 [D loss: 0.849264, acc: 38.28%] [G loss: 3.029519]\n",
      "epoch:27 step:21214 [D loss: 0.136923, acc: 99.22%] [G loss: 3.632537]\n",
      "epoch:27 step:21215 [D loss: 0.495049, acc: 78.91%] [G loss: 3.559397]\n",
      "epoch:27 step:21216 [D loss: 0.125376, acc: 99.22%] [G loss: 4.900076]\n",
      "epoch:27 step:21217 [D loss: 0.978762, acc: 46.88%] [G loss: 5.920195]\n",
      "epoch:27 step:21218 [D loss: 0.252464, acc: 96.88%] [G loss: 3.703863]\n",
      "epoch:27 step:21219 [D loss: 0.734415, acc: 51.56%] [G loss: 2.827248]\n",
      "epoch:27 step:21220 [D loss: 0.113934, acc: 99.22%] [G loss: 4.344498]\n",
      "epoch:27 step:21221 [D loss: 0.247335, acc: 97.66%] [G loss: 3.424803]\n",
      "epoch:27 step:21222 [D loss: 0.159597, acc: 100.00%] [G loss: 3.942534]\n",
      "epoch:27 step:21223 [D loss: 0.313383, acc: 96.09%] [G loss: 3.712760]\n",
      "epoch:27 step:21224 [D loss: 0.239321, acc: 93.75%] [G loss: 4.100030]\n",
      "epoch:27 step:21225 [D loss: 1.087836, acc: 27.34%] [G loss: 4.472764]\n",
      "epoch:27 step:21226 [D loss: 0.074117, acc: 100.00%] [G loss: 4.180252]\n",
      "epoch:27 step:21227 [D loss: 0.410479, acc: 90.62%] [G loss: 3.931440]\n",
      "epoch:27 step:21228 [D loss: 0.551133, acc: 71.09%] [G loss: 3.594000]\n",
      "epoch:27 step:21229 [D loss: 0.842413, acc: 51.56%] [G loss: 3.146460]\n",
      "epoch:27 step:21230 [D loss: 0.278740, acc: 96.09%] [G loss: 3.468793]\n",
      "epoch:27 step:21231 [D loss: 0.975258, acc: 37.50%] [G loss: 5.387406]\n",
      "epoch:27 step:21232 [D loss: 0.677015, acc: 55.47%] [G loss: 4.263025]\n",
      "epoch:27 step:21233 [D loss: 0.279470, acc: 98.44%] [G loss: 3.721215]\n",
      "epoch:27 step:21234 [D loss: 0.298014, acc: 92.97%] [G loss: 5.675197]\n",
      "epoch:27 step:21235 [D loss: 0.473550, acc: 77.34%] [G loss: 5.943756]\n",
      "epoch:27 step:21236 [D loss: 1.262813, acc: 50.00%] [G loss: 4.046521]\n",
      "epoch:27 step:21237 [D loss: 0.452724, acc: 68.75%] [G loss: 3.036354]\n",
      "epoch:27 step:21238 [D loss: 0.432553, acc: 85.16%] [G loss: 4.590583]\n",
      "epoch:27 step:21239 [D loss: 0.204919, acc: 95.31%] [G loss: 4.189376]\n",
      "epoch:27 step:21240 [D loss: 0.284930, acc: 99.22%] [G loss: 6.424050]\n",
      "epoch:27 step:21241 [D loss: 0.108836, acc: 99.22%] [G loss: 5.377149]\n",
      "epoch:27 step:21242 [D loss: 1.103386, acc: 45.31%] [G loss: 3.305223]\n",
      "epoch:27 step:21243 [D loss: 1.045548, acc: 49.22%] [G loss: 4.363524]\n",
      "epoch:27 step:21244 [D loss: 0.103662, acc: 100.00%] [G loss: 4.770207]\n",
      "epoch:27 step:21245 [D loss: 0.325933, acc: 90.62%] [G loss: 4.591553]\n",
      "epoch:27 step:21246 [D loss: 0.304154, acc: 90.62%] [G loss: 3.637083]\n",
      "epoch:27 step:21247 [D loss: 0.382250, acc: 83.59%] [G loss: 3.648667]\n",
      "epoch:27 step:21248 [D loss: 0.165833, acc: 99.22%] [G loss: 3.044789]\n",
      "epoch:27 step:21249 [D loss: 0.115598, acc: 100.00%] [G loss: 5.710297]\n",
      "epoch:27 step:21250 [D loss: 0.907495, acc: 47.66%] [G loss: 3.685485]\n",
      "epoch:27 step:21251 [D loss: 0.068351, acc: 100.00%] [G loss: 2.882136]\n",
      "epoch:27 step:21252 [D loss: 0.046852, acc: 100.00%] [G loss: 3.151916]\n",
      "epoch:27 step:21253 [D loss: 0.484420, acc: 76.56%] [G loss: 5.963302]\n",
      "epoch:27 step:21254 [D loss: 0.266678, acc: 91.41%] [G loss: 2.446046]\n",
      "epoch:27 step:21255 [D loss: 0.600891, acc: 60.94%] [G loss: 4.215162]\n",
      "epoch:27 step:21256 [D loss: 0.795672, acc: 51.56%] [G loss: 4.040318]\n",
      "epoch:27 step:21257 [D loss: 0.441036, acc: 76.56%] [G loss: 5.616793]\n",
      "epoch:27 step:21258 [D loss: 0.498637, acc: 69.53%] [G loss: 2.932535]\n",
      "epoch:27 step:21259 [D loss: 0.395737, acc: 78.12%] [G loss: 3.341886]\n",
      "epoch:27 step:21260 [D loss: 1.037349, acc: 35.16%] [G loss: 3.210825]\n",
      "epoch:27 step:21261 [D loss: 0.166457, acc: 100.00%] [G loss: 4.143250]\n",
      "epoch:27 step:21262 [D loss: 0.316521, acc: 90.62%] [G loss: 4.739071]\n",
      "epoch:27 step:21263 [D loss: 0.153972, acc: 98.44%] [G loss: 3.588257]\n",
      "epoch:27 step:21264 [D loss: 0.200370, acc: 96.09%] [G loss: 4.273760]\n",
      "epoch:27 step:21265 [D loss: 0.530483, acc: 67.97%] [G loss: 2.908127]\n",
      "epoch:27 step:21266 [D loss: 0.770418, acc: 47.66%] [G loss: 4.128469]\n",
      "epoch:27 step:21267 [D loss: 0.404221, acc: 90.62%] [G loss: 4.343445]\n",
      "epoch:27 step:21268 [D loss: 0.879819, acc: 47.66%] [G loss: 2.829298]\n",
      "epoch:27 step:21269 [D loss: 0.820538, acc: 51.56%] [G loss: 3.833118]\n",
      "epoch:27 step:21270 [D loss: 0.271056, acc: 94.53%] [G loss: 2.961694]\n",
      "epoch:27 step:21271 [D loss: 0.493540, acc: 64.06%] [G loss: 4.100068]\n",
      "epoch:27 step:21272 [D loss: 0.104099, acc: 100.00%] [G loss: 2.894482]\n",
      "epoch:27 step:21273 [D loss: 0.374193, acc: 88.28%] [G loss: 3.897324]\n",
      "epoch:27 step:21274 [D loss: 0.259204, acc: 95.31%] [G loss: 3.130679]\n",
      "epoch:27 step:21275 [D loss: 0.508333, acc: 70.31%] [G loss: 4.048287]\n",
      "epoch:27 step:21276 [D loss: 0.146251, acc: 99.22%] [G loss: 4.296437]\n",
      "epoch:27 step:21277 [D loss: 0.339199, acc: 85.16%] [G loss: 3.060912]\n",
      "epoch:27 step:21278 [D loss: 0.302398, acc: 94.53%] [G loss: 4.205334]\n",
      "epoch:27 step:21279 [D loss: 0.729936, acc: 54.69%] [G loss: 3.360697]\n",
      "epoch:27 step:21280 [D loss: 0.668593, acc: 59.38%] [G loss: 4.686669]\n",
      "epoch:27 step:21281 [D loss: 0.173769, acc: 97.66%] [G loss: 1.911248]\n",
      "epoch:27 step:21282 [D loss: 0.363403, acc: 87.50%] [G loss: 2.663714]\n",
      "epoch:27 step:21283 [D loss: 0.961009, acc: 35.94%] [G loss: 3.060879]\n",
      "epoch:27 step:21284 [D loss: 0.253215, acc: 96.09%] [G loss: 6.046134]\n",
      "epoch:27 step:21285 [D loss: 0.516981, acc: 63.28%] [G loss: 4.903274]\n",
      "epoch:27 step:21286 [D loss: 0.304315, acc: 91.41%] [G loss: 3.440052]\n",
      "epoch:27 step:21287 [D loss: 0.055652, acc: 100.00%] [G loss: 3.221883]\n",
      "epoch:27 step:21288 [D loss: 0.278567, acc: 91.41%] [G loss: 3.766007]\n",
      "epoch:27 step:21289 [D loss: 0.786419, acc: 54.69%] [G loss: 5.782105]\n",
      "epoch:27 step:21290 [D loss: 0.129873, acc: 100.00%] [G loss: 3.362294]\n",
      "epoch:27 step:21291 [D loss: 0.455777, acc: 77.34%] [G loss: 3.250906]\n",
      "epoch:27 step:21292 [D loss: 0.793442, acc: 53.12%] [G loss: 2.287059]\n",
      "epoch:27 step:21293 [D loss: 0.988802, acc: 42.97%] [G loss: 4.674856]\n",
      "epoch:27 step:21294 [D loss: 0.107944, acc: 99.22%] [G loss: 4.339961]\n",
      "epoch:27 step:21295 [D loss: 0.849920, acc: 39.84%] [G loss: 4.255660]\n",
      "epoch:27 step:21296 [D loss: 1.080975, acc: 21.88%] [G loss: 6.538726]\n",
      "epoch:27 step:21297 [D loss: 0.408804, acc: 89.06%] [G loss: 2.517304]\n",
      "epoch:27 step:21298 [D loss: 0.284587, acc: 97.66%] [G loss: 3.951898]\n",
      "epoch:27 step:21299 [D loss: 0.277585, acc: 90.62%] [G loss: 5.227806]\n",
      "epoch:27 step:21300 [D loss: 0.221384, acc: 97.66%] [G loss: 3.681464]\n",
      "epoch:27 step:21301 [D loss: 0.584079, acc: 67.97%] [G loss: 4.599634]\n",
      "epoch:27 step:21302 [D loss: 0.847158, acc: 50.00%] [G loss: 2.116453]\n",
      "epoch:27 step:21303 [D loss: 0.376655, acc: 78.91%] [G loss: 5.055256]\n",
      "epoch:27 step:21304 [D loss: 0.678442, acc: 56.25%] [G loss: 2.989402]\n",
      "epoch:27 step:21305 [D loss: 0.378505, acc: 89.06%] [G loss: 6.342790]\n",
      "epoch:27 step:21306 [D loss: 0.157635, acc: 100.00%] [G loss: 5.888393]\n",
      "epoch:27 step:21307 [D loss: 0.276428, acc: 88.28%] [G loss: 4.266484]\n",
      "epoch:27 step:21308 [D loss: 0.902083, acc: 46.88%] [G loss: 5.084525]\n",
      "epoch:27 step:21309 [D loss: 0.181921, acc: 98.44%] [G loss: 4.026150]\n",
      "epoch:27 step:21310 [D loss: 0.932222, acc: 51.56%] [G loss: 5.019324]\n",
      "epoch:27 step:21311 [D loss: 0.328906, acc: 81.25%] [G loss: 3.566754]\n",
      "epoch:27 step:21312 [D loss: 0.129726, acc: 99.22%] [G loss: 3.096305]\n",
      "epoch:27 step:21313 [D loss: 0.411560, acc: 79.69%] [G loss: 3.847965]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:27 step:21314 [D loss: 0.511875, acc: 64.06%] [G loss: 4.845151]\n",
      "epoch:27 step:21315 [D loss: 0.582137, acc: 73.44%] [G loss: 5.636058]\n",
      "epoch:27 step:21316 [D loss: 0.341810, acc: 86.72%] [G loss: 3.394895]\n",
      "epoch:27 step:21317 [D loss: 1.553286, acc: 4.69%] [G loss: 2.447191]\n",
      "epoch:27 step:21318 [D loss: 0.181598, acc: 98.44%] [G loss: 4.299913]\n",
      "epoch:27 step:21319 [D loss: 0.629699, acc: 61.72%] [G loss: 4.512782]\n",
      "epoch:27 step:21320 [D loss: 0.836557, acc: 51.56%] [G loss: 5.104799]\n",
      "epoch:27 step:21321 [D loss: 0.452330, acc: 71.88%] [G loss: 3.096038]\n",
      "epoch:27 step:21322 [D loss: 1.152570, acc: 19.53%] [G loss: 2.513801]\n",
      "epoch:27 step:21323 [D loss: 0.743257, acc: 50.00%] [G loss: 5.328491]\n",
      "epoch:27 step:21324 [D loss: 0.099521, acc: 99.22%] [G loss: 3.160948]\n",
      "epoch:27 step:21325 [D loss: 0.641989, acc: 62.50%] [G loss: 2.838352]\n",
      "epoch:27 step:21326 [D loss: 0.404245, acc: 89.84%] [G loss: 4.653090]\n",
      "epoch:27 step:21327 [D loss: 0.656722, acc: 55.47%] [G loss: 4.009153]\n",
      "epoch:27 step:21328 [D loss: 0.585437, acc: 59.38%] [G loss: 3.197066]\n",
      "epoch:27 step:21329 [D loss: 0.285609, acc: 94.53%] [G loss: 4.538918]\n",
      "epoch:27 step:21330 [D loss: 0.186529, acc: 99.22%] [G loss: 4.586485]\n",
      "epoch:27 step:21331 [D loss: 0.689113, acc: 56.25%] [G loss: 6.862006]\n",
      "epoch:27 step:21332 [D loss: 0.330462, acc: 77.34%] [G loss: 4.625216]\n",
      "epoch:27 step:21333 [D loss: 1.094798, acc: 49.22%] [G loss: 2.829429]\n",
      "epoch:27 step:21334 [D loss: 0.217122, acc: 96.09%] [G loss: 3.040580]\n",
      "epoch:27 step:21335 [D loss: 0.583590, acc: 75.78%] [G loss: 5.381473]\n",
      "epoch:27 step:21336 [D loss: 0.370902, acc: 89.84%] [G loss: 4.029925]\n",
      "epoch:27 step:21337 [D loss: 0.288607, acc: 96.88%] [G loss: 5.171548]\n",
      "epoch:27 step:21338 [D loss: 0.259408, acc: 91.41%] [G loss: 5.908748]\n",
      "epoch:27 step:21339 [D loss: 0.589063, acc: 64.06%] [G loss: 3.171670]\n",
      "epoch:27 step:21340 [D loss: 0.370532, acc: 90.62%] [G loss: 4.178887]\n",
      "epoch:27 step:21341 [D loss: 0.886749, acc: 50.78%] [G loss: 2.732663]\n",
      "epoch:27 step:21342 [D loss: 0.190237, acc: 96.88%] [G loss: 3.285928]\n",
      "epoch:27 step:21343 [D loss: 0.558625, acc: 75.00%] [G loss: 4.025319]\n",
      "epoch:27 step:21344 [D loss: 0.365413, acc: 93.75%] [G loss: 4.060044]\n",
      "epoch:27 step:21345 [D loss: 0.286794, acc: 92.97%] [G loss: 4.326968]\n",
      "epoch:27 step:21346 [D loss: 0.650770, acc: 56.25%] [G loss: 4.066564]\n",
      "epoch:27 step:21347 [D loss: 0.527462, acc: 78.12%] [G loss: 4.299134]\n",
      "epoch:27 step:21348 [D loss: 0.178417, acc: 97.66%] [G loss: 4.144107]\n",
      "epoch:27 step:21349 [D loss: 0.120711, acc: 100.00%] [G loss: 5.643913]\n",
      "epoch:27 step:21350 [D loss: 0.953688, acc: 52.34%] [G loss: 3.796628]\n",
      "epoch:27 step:21351 [D loss: 0.430950, acc: 78.91%] [G loss: 4.522947]\n",
      "epoch:27 step:21352 [D loss: 0.281325, acc: 94.53%] [G loss: 3.952523]\n",
      "epoch:27 step:21353 [D loss: 0.238208, acc: 99.22%] [G loss: 4.063012]\n",
      "epoch:27 step:21354 [D loss: 1.035757, acc: 25.78%] [G loss: 4.853199]\n",
      "epoch:27 step:21355 [D loss: 0.489844, acc: 78.12%] [G loss: 2.871670]\n",
      "epoch:27 step:21356 [D loss: 0.497651, acc: 64.06%] [G loss: 3.851571]\n",
      "epoch:27 step:21357 [D loss: 0.992527, acc: 31.25%] [G loss: 4.567683]\n",
      "epoch:27 step:21358 [D loss: 0.356823, acc: 89.06%] [G loss: 4.814321]\n",
      "epoch:27 step:21359 [D loss: 0.350772, acc: 85.16%] [G loss: 4.161150]\n",
      "epoch:27 step:21360 [D loss: 0.605559, acc: 64.84%] [G loss: 4.477827]\n",
      "epoch:27 step:21361 [D loss: 0.307164, acc: 92.19%] [G loss: 5.067622]\n",
      "epoch:27 step:21362 [D loss: 0.298061, acc: 89.06%] [G loss: 3.816732]\n",
      "epoch:27 step:21363 [D loss: 0.221578, acc: 97.66%] [G loss: 2.655553]\n",
      "epoch:27 step:21364 [D loss: 0.148918, acc: 100.00%] [G loss: 4.435139]\n",
      "epoch:27 step:21365 [D loss: 0.208345, acc: 97.66%] [G loss: 6.418003]\n",
      "epoch:27 step:21366 [D loss: 0.585048, acc: 64.06%] [G loss: 2.804569]\n",
      "epoch:27 step:21367 [D loss: 0.197471, acc: 97.66%] [G loss: 4.341796]\n",
      "epoch:27 step:21368 [D loss: 0.886118, acc: 42.97%] [G loss: 3.147591]\n",
      "epoch:27 step:21369 [D loss: 0.175694, acc: 99.22%] [G loss: 2.720034]\n",
      "epoch:27 step:21370 [D loss: 0.749343, acc: 51.56%] [G loss: 4.031304]\n",
      "epoch:27 step:21371 [D loss: 0.556902, acc: 71.09%] [G loss: 5.539726]\n",
      "epoch:27 step:21372 [D loss: 0.168864, acc: 98.44%] [G loss: 3.989242]\n",
      "epoch:27 step:21373 [D loss: 0.602821, acc: 70.31%] [G loss: 5.508954]\n",
      "epoch:27 step:21374 [D loss: 0.272031, acc: 89.84%] [G loss: 5.052881]\n",
      "epoch:27 step:21375 [D loss: 0.403452, acc: 81.25%] [G loss: 4.934504]\n",
      "epoch:27 step:21376 [D loss: 0.319232, acc: 86.72%] [G loss: 3.804389]\n",
      "epoch:27 step:21377 [D loss: 0.287763, acc: 95.31%] [G loss: 3.298242]\n",
      "epoch:27 step:21378 [D loss: 1.387210, acc: 11.72%] [G loss: 4.224168]\n",
      "epoch:27 step:21379 [D loss: 0.957427, acc: 49.22%] [G loss: 4.630389]\n",
      "epoch:27 step:21380 [D loss: 0.254026, acc: 92.97%] [G loss: 3.326511]\n",
      "epoch:27 step:21381 [D loss: 0.829804, acc: 51.56%] [G loss: 4.084844]\n",
      "epoch:27 step:21382 [D loss: 0.457303, acc: 78.12%] [G loss: 4.954888]\n",
      "epoch:27 step:21383 [D loss: 0.196022, acc: 96.09%] [G loss: 5.551285]\n",
      "epoch:27 step:21384 [D loss: 0.221287, acc: 95.31%] [G loss: 5.073061]\n",
      "epoch:27 step:21385 [D loss: 0.352939, acc: 88.28%] [G loss: 3.686697]\n",
      "epoch:27 step:21386 [D loss: 0.346302, acc: 93.75%] [G loss: 3.004473]\n",
      "epoch:27 step:21387 [D loss: 0.997588, acc: 50.00%] [G loss: 2.527327]\n",
      "epoch:27 step:21388 [D loss: 0.423860, acc: 80.47%] [G loss: 4.861479]\n",
      "epoch:27 step:21389 [D loss: 0.561351, acc: 73.44%] [G loss: 3.521846]\n",
      "epoch:27 step:21390 [D loss: 0.244721, acc: 93.75%] [G loss: 3.255365]\n",
      "epoch:27 step:21391 [D loss: 0.388913, acc: 85.16%] [G loss: 5.146060]\n",
      "epoch:27 step:21392 [D loss: 0.146502, acc: 100.00%] [G loss: 5.133206]\n",
      "epoch:27 step:21393 [D loss: 0.207384, acc: 92.97%] [G loss: 4.796970]\n",
      "epoch:27 step:21394 [D loss: 0.487631, acc: 76.56%] [G loss: 4.382196]\n",
      "epoch:27 step:21395 [D loss: 0.307161, acc: 89.84%] [G loss: 4.955383]\n",
      "epoch:27 step:21396 [D loss: 0.368567, acc: 91.41%] [G loss: 3.291695]\n",
      "epoch:27 step:21397 [D loss: 0.166086, acc: 98.44%] [G loss: 4.971274]\n",
      "epoch:27 step:21398 [D loss: 0.727589, acc: 53.12%] [G loss: 4.990928]\n",
      "epoch:27 step:21399 [D loss: 0.977789, acc: 49.22%] [G loss: 1.852629]\n",
      "epoch:27 step:21400 [D loss: 0.114922, acc: 100.00%] [G loss: 4.283678]\n",
      "##############\n",
      "[0.85357896 0.8664186  0.8314953  0.80438113 0.78208103 0.83071533\n",
      " 0.90618672 0.84076431 0.7827481  0.81597758]\n",
      "##########\n",
      "epoch:27 step:21401 [D loss: 0.727293, acc: 57.81%] [G loss: 4.485722]\n",
      "epoch:27 step:21402 [D loss: 1.454803, acc: 40.62%] [G loss: 3.981382]\n",
      "epoch:27 step:21403 [D loss: 0.517282, acc: 75.78%] [G loss: 4.828746]\n",
      "epoch:27 step:21404 [D loss: 0.302039, acc: 86.72%] [G loss: 5.308971]\n",
      "epoch:27 step:21405 [D loss: 0.320819, acc: 82.03%] [G loss: 3.209363]\n",
      "epoch:27 step:21406 [D loss: 0.884093, acc: 51.56%] [G loss: 3.607433]\n",
      "epoch:27 step:21407 [D loss: 0.260490, acc: 97.66%] [G loss: 4.089748]\n",
      "epoch:27 step:21408 [D loss: 0.592902, acc: 69.53%] [G loss: 4.384266]\n",
      "epoch:27 step:21409 [D loss: 1.017814, acc: 33.59%] [G loss: 3.720181]\n",
      "epoch:27 step:21410 [D loss: 0.281379, acc: 92.19%] [G loss: 5.277773]\n",
      "epoch:27 step:21411 [D loss: 0.194005, acc: 98.44%] [G loss: 4.145723]\n",
      "epoch:27 step:21412 [D loss: 0.567275, acc: 59.38%] [G loss: 3.428598]\n",
      "epoch:27 step:21413 [D loss: 0.181999, acc: 98.44%] [G loss: 3.741196]\n",
      "epoch:27 step:21414 [D loss: 0.161930, acc: 96.88%] [G loss: 5.560400]\n",
      "epoch:27 step:21415 [D loss: 0.641072, acc: 55.47%] [G loss: 5.579722]\n",
      "epoch:27 step:21416 [D loss: 0.053288, acc: 100.00%] [G loss: 6.253153]\n",
      "epoch:27 step:21417 [D loss: 0.120395, acc: 99.22%] [G loss: 4.108449]\n",
      "epoch:27 step:21418 [D loss: 0.171585, acc: 99.22%] [G loss: 4.862085]\n",
      "epoch:27 step:21419 [D loss: 0.690510, acc: 57.81%] [G loss: 2.610971]\n",
      "epoch:27 step:21420 [D loss: 0.200837, acc: 98.44%] [G loss: 4.599019]\n",
      "epoch:27 step:21421 [D loss: 0.444102, acc: 85.16%] [G loss: 3.493951]\n",
      "epoch:27 step:21422 [D loss: 0.186151, acc: 98.44%] [G loss: 6.037891]\n",
      "epoch:27 step:21423 [D loss: 0.135425, acc: 98.44%] [G loss: 3.834590]\n",
      "epoch:27 step:21424 [D loss: 1.443517, acc: 24.22%] [G loss: 4.394812]\n",
      "epoch:27 step:21425 [D loss: 0.292010, acc: 96.88%] [G loss: 3.688511]\n",
      "epoch:27 step:21426 [D loss: 0.136156, acc: 100.00%] [G loss: 3.868008]\n",
      "epoch:27 step:21427 [D loss: 0.175598, acc: 95.31%] [G loss: 4.608578]\n",
      "epoch:27 step:21428 [D loss: 0.204753, acc: 97.66%] [G loss: 2.738075]\n",
      "epoch:27 step:21429 [D loss: 0.387014, acc: 85.94%] [G loss: 4.544168]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:27 step:21430 [D loss: 0.748273, acc: 50.00%] [G loss: 4.474403]\n",
      "epoch:27 step:21431 [D loss: 0.094483, acc: 99.22%] [G loss: 3.595804]\n",
      "epoch:27 step:21432 [D loss: 0.247113, acc: 92.97%] [G loss: 4.802091]\n",
      "epoch:27 step:21433 [D loss: 0.263962, acc: 95.31%] [G loss: 3.659385]\n",
      "epoch:27 step:21434 [D loss: 0.097829, acc: 100.00%] [G loss: 4.835368]\n",
      "epoch:27 step:21435 [D loss: 0.725192, acc: 56.25%] [G loss: 3.537525]\n",
      "epoch:27 step:21436 [D loss: 0.212618, acc: 98.44%] [G loss: 3.640745]\n",
      "epoch:27 step:21437 [D loss: 0.103394, acc: 100.00%] [G loss: 5.371994]\n",
      "epoch:27 step:21438 [D loss: 0.292866, acc: 97.66%] [G loss: 3.266210]\n",
      "epoch:27 step:21439 [D loss: 0.565491, acc: 59.38%] [G loss: 4.870285]\n",
      "epoch:27 step:21440 [D loss: 0.647576, acc: 54.69%] [G loss: 5.900115]\n",
      "epoch:27 step:21441 [D loss: 0.585888, acc: 60.94%] [G loss: 5.629782]\n",
      "epoch:27 step:21442 [D loss: 0.849625, acc: 46.09%] [G loss: 2.943125]\n",
      "epoch:27 step:21443 [D loss: 1.263391, acc: 50.78%] [G loss: 2.701584]\n",
      "epoch:27 step:21444 [D loss: 0.352168, acc: 83.59%] [G loss: 3.695960]\n",
      "epoch:27 step:21445 [D loss: 0.762708, acc: 56.25%] [G loss: 2.959133]\n",
      "epoch:27 step:21446 [D loss: 0.391345, acc: 82.81%] [G loss: 5.727688]\n",
      "epoch:27 step:21447 [D loss: 0.075603, acc: 99.22%] [G loss: 3.203478]\n",
      "epoch:27 step:21448 [D loss: 0.201433, acc: 96.88%] [G loss: 5.319488]\n",
      "epoch:27 step:21449 [D loss: 0.133968, acc: 99.22%] [G loss: 3.951637]\n",
      "epoch:27 step:21450 [D loss: 0.317608, acc: 92.97%] [G loss: 3.170576]\n",
      "epoch:27 step:21451 [D loss: 0.545918, acc: 62.50%] [G loss: 3.074147]\n",
      "epoch:27 step:21452 [D loss: 0.202894, acc: 99.22%] [G loss: 3.668494]\n",
      "epoch:27 step:21453 [D loss: 0.122008, acc: 100.00%] [G loss: 4.085843]\n",
      "epoch:27 step:21454 [D loss: 0.799870, acc: 51.56%] [G loss: 4.202616]\n",
      "epoch:27 step:21455 [D loss: 0.287925, acc: 96.88%] [G loss: 3.140800]\n",
      "epoch:27 step:21456 [D loss: 0.420600, acc: 82.03%] [G loss: 2.261715]\n",
      "epoch:27 step:21457 [D loss: 0.459045, acc: 71.09%] [G loss: 4.426338]\n",
      "epoch:27 step:21458 [D loss: 0.472893, acc: 82.03%] [G loss: 3.946537]\n",
      "epoch:27 step:21459 [D loss: 0.159881, acc: 99.22%] [G loss: 3.999373]\n",
      "epoch:27 step:21460 [D loss: 0.383456, acc: 92.97%] [G loss: 3.555304]\n",
      "epoch:27 step:21461 [D loss: 0.464000, acc: 78.12%] [G loss: 2.599211]\n",
      "epoch:27 step:21462 [D loss: 0.664173, acc: 59.38%] [G loss: 3.343076]\n",
      "epoch:27 step:21463 [D loss: 0.272289, acc: 89.06%] [G loss: 4.684546]\n",
      "epoch:27 step:21464 [D loss: 0.076123, acc: 100.00%] [G loss: 5.723928]\n",
      "epoch:27 step:21465 [D loss: 0.461971, acc: 77.34%] [G loss: 3.292803]\n",
      "epoch:27 step:21466 [D loss: 0.194361, acc: 98.44%] [G loss: 3.701257]\n",
      "epoch:27 step:21467 [D loss: 0.244801, acc: 99.22%] [G loss: 2.474966]\n",
      "epoch:27 step:21468 [D loss: 0.158622, acc: 99.22%] [G loss: 3.941724]\n",
      "epoch:27 step:21469 [D loss: 0.230260, acc: 98.44%] [G loss: 5.469243]\n",
      "epoch:27 step:21470 [D loss: 0.806791, acc: 51.56%] [G loss: 3.949891]\n",
      "epoch:27 step:21471 [D loss: 0.407749, acc: 89.84%] [G loss: 3.553227]\n",
      "epoch:27 step:21472 [D loss: 0.252449, acc: 94.53%] [G loss: 3.262621]\n",
      "epoch:27 step:21473 [D loss: 1.285190, acc: 32.81%] [G loss: 3.963960]\n",
      "epoch:27 step:21474 [D loss: 0.272425, acc: 88.28%] [G loss: 3.818189]\n",
      "epoch:27 step:21475 [D loss: 0.163048, acc: 98.44%] [G loss: 3.870189]\n",
      "epoch:27 step:21476 [D loss: 0.301847, acc: 92.97%] [G loss: 5.267105]\n",
      "epoch:27 step:21477 [D loss: 0.513727, acc: 76.56%] [G loss: 3.560768]\n",
      "epoch:27 step:21478 [D loss: 0.540307, acc: 72.66%] [G loss: 3.536985]\n",
      "epoch:27 step:21479 [D loss: 0.213080, acc: 98.44%] [G loss: 5.230199]\n",
      "epoch:27 step:21480 [D loss: 0.715297, acc: 53.12%] [G loss: 4.738408]\n",
      "epoch:27 step:21481 [D loss: 0.385116, acc: 90.62%] [G loss: 4.509759]\n",
      "epoch:27 step:21482 [D loss: 0.279333, acc: 87.50%] [G loss: 5.472498]\n",
      "epoch:27 step:21483 [D loss: 0.178820, acc: 98.44%] [G loss: 3.066735]\n",
      "epoch:27 step:21484 [D loss: 0.487393, acc: 78.91%] [G loss: 3.882276]\n",
      "epoch:27 step:21485 [D loss: 0.361607, acc: 86.72%] [G loss: 3.553220]\n",
      "epoch:27 step:21486 [D loss: 0.062211, acc: 100.00%] [G loss: 3.988515]\n",
      "epoch:27 step:21487 [D loss: 0.158203, acc: 100.00%] [G loss: 4.727813]\n",
      "epoch:27 step:21488 [D loss: 0.086419, acc: 100.00%] [G loss: 6.003363]\n",
      "epoch:27 step:21489 [D loss: 0.443251, acc: 78.12%] [G loss: 5.486979]\n",
      "epoch:27 step:21490 [D loss: 0.925828, acc: 40.62%] [G loss: 4.271857]\n",
      "epoch:27 step:21491 [D loss: 0.334891, acc: 94.53%] [G loss: 5.339766]\n",
      "epoch:27 step:21492 [D loss: 0.315855, acc: 87.50%] [G loss: 5.615948]\n",
      "epoch:27 step:21493 [D loss: 0.212371, acc: 99.22%] [G loss: 4.427505]\n",
      "epoch:27 step:21494 [D loss: 0.153979, acc: 97.66%] [G loss: 7.319457]\n",
      "epoch:27 step:21495 [D loss: 1.634090, acc: 50.00%] [G loss: 3.407711]\n",
      "epoch:27 step:21496 [D loss: 0.279521, acc: 86.72%] [G loss: 7.602527]\n",
      "epoch:27 step:21497 [D loss: 0.869746, acc: 51.56%] [G loss: 3.909075]\n",
      "epoch:27 step:21498 [D loss: 0.912076, acc: 45.31%] [G loss: 5.090287]\n",
      "epoch:27 step:21499 [D loss: 0.424488, acc: 71.09%] [G loss: 4.247510]\n",
      "epoch:27 step:21500 [D loss: 0.314528, acc: 85.16%] [G loss: 3.176137]\n",
      "epoch:27 step:21501 [D loss: 1.190889, acc: 30.47%] [G loss: 5.125564]\n",
      "epoch:27 step:21502 [D loss: 0.766533, acc: 54.69%] [G loss: 5.348325]\n",
      "epoch:27 step:21503 [D loss: 0.311839, acc: 95.31%] [G loss: 4.391801]\n",
      "epoch:27 step:21504 [D loss: 0.136829, acc: 99.22%] [G loss: 5.483561]\n",
      "epoch:27 step:21505 [D loss: 0.821550, acc: 52.34%] [G loss: 4.643422]\n",
      "epoch:27 step:21506 [D loss: 0.103300, acc: 100.00%] [G loss: 4.858335]\n",
      "epoch:27 step:21507 [D loss: 0.996769, acc: 44.53%] [G loss: 2.594034]\n",
      "epoch:27 step:21508 [D loss: 0.206125, acc: 99.22%] [G loss: 3.787165]\n",
      "epoch:27 step:21509 [D loss: 0.113543, acc: 100.00%] [G loss: 8.541626]\n",
      "epoch:27 step:21510 [D loss: 0.678242, acc: 57.03%] [G loss: 3.791540]\n",
      "epoch:27 step:21511 [D loss: 0.266769, acc: 91.41%] [G loss: 7.429887]\n",
      "epoch:27 step:21512 [D loss: 0.285071, acc: 95.31%] [G loss: 3.502690]\n",
      "epoch:27 step:21513 [D loss: 0.774738, acc: 51.56%] [G loss: 2.918579]\n",
      "epoch:27 step:21514 [D loss: 0.077383, acc: 100.00%] [G loss: 3.124641]\n",
      "epoch:27 step:21515 [D loss: 0.285573, acc: 92.19%] [G loss: 4.740456]\n",
      "epoch:27 step:21516 [D loss: 0.409275, acc: 76.56%] [G loss: 6.413090]\n",
      "epoch:27 step:21517 [D loss: 0.308672, acc: 95.31%] [G loss: 4.322957]\n",
      "epoch:27 step:21518 [D loss: 0.218287, acc: 97.66%] [G loss: 3.836489]\n",
      "epoch:27 step:21519 [D loss: 0.667787, acc: 60.94%] [G loss: 4.982108]\n",
      "epoch:27 step:21520 [D loss: 0.571437, acc: 71.09%] [G loss: 3.795210]\n",
      "epoch:27 step:21521 [D loss: 0.073414, acc: 100.00%] [G loss: 4.399031]\n",
      "epoch:27 step:21522 [D loss: 0.661414, acc: 54.69%] [G loss: 3.965932]\n",
      "epoch:27 step:21523 [D loss: 0.596864, acc: 60.16%] [G loss: 4.199324]\n",
      "epoch:27 step:21524 [D loss: 0.704274, acc: 53.91%] [G loss: 3.603770]\n",
      "epoch:27 step:21525 [D loss: 0.128310, acc: 100.00%] [G loss: 3.480059]\n",
      "epoch:27 step:21526 [D loss: 0.254980, acc: 92.19%] [G loss: 4.561981]\n",
      "epoch:27 step:21527 [D loss: 0.483168, acc: 83.59%] [G loss: 3.212298]\n",
      "epoch:27 step:21528 [D loss: 0.214802, acc: 98.44%] [G loss: 4.362422]\n",
      "epoch:27 step:21529 [D loss: 0.158469, acc: 97.66%] [G loss: 2.692421]\n",
      "epoch:27 step:21530 [D loss: 0.177665, acc: 99.22%] [G loss: 2.533700]\n",
      "epoch:27 step:21531 [D loss: 1.007431, acc: 33.59%] [G loss: 3.241549]\n",
      "epoch:27 step:21532 [D loss: 0.921832, acc: 34.38%] [G loss: 3.275877]\n",
      "epoch:27 step:21533 [D loss: 0.150835, acc: 98.44%] [G loss: 3.883682]\n",
      "epoch:27 step:21534 [D loss: 0.112417, acc: 100.00%] [G loss: 5.329518]\n",
      "epoch:27 step:21535 [D loss: 1.331869, acc: 28.12%] [G loss: 2.947918]\n",
      "epoch:27 step:21536 [D loss: 0.595852, acc: 69.53%] [G loss: 3.474903]\n",
      "epoch:27 step:21537 [D loss: 0.540929, acc: 76.56%] [G loss: 3.493073]\n",
      "epoch:27 step:21538 [D loss: 0.974175, acc: 30.47%] [G loss: 3.484148]\n",
      "epoch:27 step:21539 [D loss: 0.241677, acc: 100.00%] [G loss: 5.317270]\n",
      "epoch:27 step:21540 [D loss: 0.302315, acc: 92.97%] [G loss: 3.845288]\n",
      "epoch:27 step:21541 [D loss: 1.030983, acc: 50.78%] [G loss: 2.793810]\n",
      "epoch:27 step:21542 [D loss: 0.407443, acc: 90.62%] [G loss: 3.793926]\n",
      "epoch:27 step:21543 [D loss: 0.397257, acc: 84.38%] [G loss: 2.746475]\n",
      "epoch:27 step:21544 [D loss: 0.978343, acc: 48.44%] [G loss: 3.812366]\n",
      "epoch:27 step:21545 [D loss: 0.704110, acc: 57.03%] [G loss: 3.627610]\n",
      "epoch:27 step:21546 [D loss: 0.169487, acc: 97.66%] [G loss: 3.741621]\n",
      "epoch:27 step:21547 [D loss: 0.750884, acc: 53.12%] [G loss: 2.589971]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:27 step:21548 [D loss: 0.657952, acc: 54.69%] [G loss: 4.507079]\n",
      "epoch:27 step:21549 [D loss: 0.027719, acc: 100.00%] [G loss: 5.426818]\n",
      "epoch:27 step:21550 [D loss: 0.540137, acc: 69.53%] [G loss: 3.960255]\n",
      "epoch:27 step:21551 [D loss: 0.556677, acc: 61.72%] [G loss: 2.726864]\n",
      "epoch:27 step:21552 [D loss: 0.368127, acc: 88.28%] [G loss: 4.082080]\n",
      "epoch:27 step:21553 [D loss: 0.043302, acc: 100.00%] [G loss: 4.769165]\n",
      "epoch:27 step:21554 [D loss: 0.562067, acc: 75.00%] [G loss: 3.584806]\n",
      "epoch:27 step:21555 [D loss: 0.296645, acc: 93.75%] [G loss: 6.678905]\n",
      "epoch:27 step:21556 [D loss: 0.525448, acc: 75.00%] [G loss: 3.627966]\n",
      "epoch:27 step:21557 [D loss: 0.021636, acc: 100.00%] [G loss: 10.252737]\n",
      "epoch:27 step:21558 [D loss: 0.390039, acc: 86.72%] [G loss: 4.414602]\n",
      "epoch:27 step:21559 [D loss: 0.376195, acc: 87.50%] [G loss: 2.123291]\n",
      "epoch:27 step:21560 [D loss: 0.713718, acc: 56.25%] [G loss: 6.220610]\n",
      "epoch:27 step:21561 [D loss: 0.235629, acc: 95.31%] [G loss: 4.776478]\n",
      "epoch:27 step:21562 [D loss: 0.503142, acc: 62.50%] [G loss: 3.459679]\n",
      "epoch:27 step:21563 [D loss: 1.086068, acc: 46.09%] [G loss: 2.348312]\n",
      "epoch:27 step:21564 [D loss: 0.159731, acc: 100.00%] [G loss: 3.613422]\n",
      "epoch:27 step:21565 [D loss: 0.646555, acc: 60.94%] [G loss: 5.963805]\n",
      "epoch:27 step:21566 [D loss: 0.484499, acc: 74.22%] [G loss: 4.105586]\n",
      "epoch:27 step:21567 [D loss: 0.257464, acc: 92.97%] [G loss: 3.003187]\n",
      "epoch:27 step:21568 [D loss: 0.708127, acc: 56.25%] [G loss: 3.917137]\n",
      "epoch:27 step:21569 [D loss: 0.359754, acc: 89.06%] [G loss: 3.595871]\n",
      "epoch:27 step:21570 [D loss: 0.241438, acc: 96.09%] [G loss: 3.011181]\n",
      "epoch:27 step:21571 [D loss: 0.172080, acc: 100.00%] [G loss: 3.924158]\n",
      "epoch:27 step:21572 [D loss: 0.360122, acc: 89.84%] [G loss: 4.304090]\n",
      "epoch:27 step:21573 [D loss: 0.536344, acc: 69.53%] [G loss: 2.981400]\n",
      "epoch:27 step:21574 [D loss: 1.168675, acc: 18.75%] [G loss: 4.365089]\n",
      "epoch:27 step:21575 [D loss: 0.387274, acc: 92.19%] [G loss: 6.027053]\n",
      "epoch:27 step:21576 [D loss: 0.313619, acc: 92.97%] [G loss: 4.016925]\n",
      "epoch:27 step:21577 [D loss: 0.198207, acc: 98.44%] [G loss: 6.164083]\n",
      "epoch:27 step:21578 [D loss: 1.280866, acc: 3.91%] [G loss: 3.413645]\n",
      "epoch:27 step:21579 [D loss: 0.568823, acc: 71.09%] [G loss: 5.039671]\n",
      "epoch:27 step:21580 [D loss: 0.234961, acc: 92.97%] [G loss: 6.408957]\n",
      "epoch:27 step:21581 [D loss: 0.175794, acc: 99.22%] [G loss: 3.713130]\n",
      "epoch:27 step:21582 [D loss: 0.139081, acc: 98.44%] [G loss: 3.678414]\n",
      "epoch:27 step:21583 [D loss: 0.422720, acc: 83.59%] [G loss: 2.745270]\n",
      "epoch:27 step:21584 [D loss: 0.161018, acc: 98.44%] [G loss: 6.751263]\n",
      "epoch:27 step:21585 [D loss: 0.317522, acc: 80.47%] [G loss: 6.307567]\n",
      "epoch:27 step:21586 [D loss: 0.528479, acc: 77.34%] [G loss: 4.740577]\n",
      "epoch:27 step:21587 [D loss: 0.426446, acc: 88.28%] [G loss: 3.410914]\n",
      "epoch:27 step:21588 [D loss: 0.252121, acc: 95.31%] [G loss: 4.670766]\n",
      "epoch:27 step:21589 [D loss: 0.514162, acc: 79.69%] [G loss: 4.219373]\n",
      "epoch:27 step:21590 [D loss: 0.688000, acc: 57.03%] [G loss: 5.512540]\n",
      "epoch:27 step:21591 [D loss: 0.361754, acc: 90.62%] [G loss: 3.436025]\n",
      "epoch:27 step:21592 [D loss: 0.321207, acc: 78.91%] [G loss: 4.687022]\n",
      "epoch:27 step:21593 [D loss: 1.119999, acc: 50.00%] [G loss: 3.370780]\n",
      "epoch:27 step:21594 [D loss: 0.299940, acc: 94.53%] [G loss: 2.601120]\n",
      "epoch:27 step:21595 [D loss: 0.718018, acc: 53.91%] [G loss: 3.227082]\n",
      "epoch:27 step:21596 [D loss: 0.595126, acc: 61.72%] [G loss: 5.714135]\n",
      "epoch:27 step:21597 [D loss: 0.298023, acc: 82.81%] [G loss: 4.181192]\n",
      "epoch:27 step:21598 [D loss: 0.199127, acc: 96.88%] [G loss: 5.001867]\n",
      "epoch:27 step:21599 [D loss: 0.247385, acc: 92.97%] [G loss: 5.195978]\n",
      "epoch:27 step:21600 [D loss: 0.717727, acc: 53.12%] [G loss: 2.390562]\n",
      "##############\n",
      "[0.84025355 0.85912675 0.80780968 0.82558568 0.77978989 0.81753307\n",
      " 0.90115636 0.81485301 0.79754179 0.84337145]\n",
      "##########\n",
      "epoch:27 step:21601 [D loss: 1.282197, acc: 25.00%] [G loss: 3.907751]\n",
      "epoch:27 step:21602 [D loss: 0.275829, acc: 97.66%] [G loss: 4.686563]\n",
      "epoch:27 step:21603 [D loss: 0.112495, acc: 98.44%] [G loss: 4.705994]\n",
      "epoch:27 step:21604 [D loss: 0.088768, acc: 100.00%] [G loss: 6.671503]\n",
      "epoch:27 step:21605 [D loss: 0.333721, acc: 86.72%] [G loss: 3.118299]\n",
      "epoch:27 step:21606 [D loss: 1.098499, acc: 35.94%] [G loss: 3.940936]\n",
      "epoch:27 step:21607 [D loss: 0.682094, acc: 58.59%] [G loss: 3.355536]\n",
      "epoch:27 step:21608 [D loss: 0.701329, acc: 55.47%] [G loss: 1.875475]\n",
      "epoch:27 step:21609 [D loss: 0.666434, acc: 57.81%] [G loss: 2.806258]\n",
      "epoch:27 step:21610 [D loss: 0.287892, acc: 94.53%] [G loss: 4.242886]\n",
      "epoch:27 step:21611 [D loss: 0.696931, acc: 55.47%] [G loss: 2.623057]\n",
      "epoch:27 step:21612 [D loss: 1.086395, acc: 50.00%] [G loss: 5.579979]\n",
      "epoch:27 step:21613 [D loss: 0.447421, acc: 86.72%] [G loss: 3.627989]\n",
      "epoch:27 step:21614 [D loss: 0.409864, acc: 69.53%] [G loss: 3.477380]\n",
      "epoch:27 step:21615 [D loss: 0.604069, acc: 60.16%] [G loss: 3.270827]\n",
      "epoch:27 step:21616 [D loss: 0.089149, acc: 100.00%] [G loss: 4.650363]\n",
      "epoch:27 step:21617 [D loss: 0.818013, acc: 46.88%] [G loss: 3.192104]\n",
      "epoch:27 step:21618 [D loss: 0.377531, acc: 87.50%] [G loss: 3.546026]\n",
      "epoch:27 step:21619 [D loss: 0.501793, acc: 73.44%] [G loss: 2.767371]\n",
      "epoch:27 step:21620 [D loss: 0.224996, acc: 96.88%] [G loss: 3.063537]\n",
      "epoch:27 step:21621 [D loss: 0.574209, acc: 69.53%] [G loss: 3.700304]\n",
      "epoch:27 step:21622 [D loss: 0.250314, acc: 99.22%] [G loss: 3.445377]\n",
      "epoch:27 step:21623 [D loss: 0.202348, acc: 98.44%] [G loss: 3.407470]\n",
      "epoch:27 step:21624 [D loss: 0.260854, acc: 96.88%] [G loss: 3.821143]\n",
      "epoch:27 step:21625 [D loss: 0.458998, acc: 81.25%] [G loss: 4.048822]\n",
      "epoch:27 step:21626 [D loss: 0.733624, acc: 56.25%] [G loss: 4.626001]\n",
      "epoch:27 step:21627 [D loss: 0.274271, acc: 96.88%] [G loss: 3.142478]\n",
      "epoch:27 step:21628 [D loss: 0.183970, acc: 97.66%] [G loss: 3.818748]\n",
      "epoch:27 step:21629 [D loss: 0.185445, acc: 98.44%] [G loss: 3.383718]\n",
      "epoch:27 step:21630 [D loss: 0.135098, acc: 100.00%] [G loss: 4.678453]\n",
      "epoch:27 step:21631 [D loss: 0.276999, acc: 96.09%] [G loss: 5.273532]\n",
      "epoch:27 step:21632 [D loss: 0.963504, acc: 50.00%] [G loss: 4.177522]\n",
      "epoch:27 step:21633 [D loss: 0.315331, acc: 90.62%] [G loss: 2.561861]\n",
      "epoch:27 step:21634 [D loss: 0.535414, acc: 77.34%] [G loss: 5.088904]\n",
      "epoch:27 step:21635 [D loss: 0.309080, acc: 91.41%] [G loss: 4.679684]\n",
      "epoch:27 step:21636 [D loss: 0.916367, acc: 31.25%] [G loss: 4.978615]\n",
      "epoch:27 step:21637 [D loss: 0.497360, acc: 75.00%] [G loss: 4.836357]\n",
      "epoch:27 step:21638 [D loss: 0.259065, acc: 99.22%] [G loss: 4.820675]\n",
      "epoch:27 step:21639 [D loss: 0.399990, acc: 89.06%] [G loss: 4.466377]\n",
      "epoch:27 step:21640 [D loss: 0.071285, acc: 100.00%] [G loss: 4.668607]\n",
      "epoch:27 step:21641 [D loss: 0.420998, acc: 80.47%] [G loss: 6.214256]\n",
      "epoch:27 step:21642 [D loss: 0.391466, acc: 80.47%] [G loss: 4.778427]\n",
      "epoch:27 step:21643 [D loss: 0.216120, acc: 100.00%] [G loss: 6.035908]\n",
      "epoch:27 step:21644 [D loss: 0.288260, acc: 93.75%] [G loss: 3.542047]\n",
      "epoch:27 step:21645 [D loss: 0.738770, acc: 54.69%] [G loss: 4.616354]\n",
      "epoch:27 step:21646 [D loss: 0.125376, acc: 99.22%] [G loss: 4.326519]\n",
      "epoch:27 step:21647 [D loss: 0.168536, acc: 98.44%] [G loss: 3.438524]\n",
      "epoch:27 step:21648 [D loss: 0.425952, acc: 78.91%] [G loss: 2.966496]\n",
      "epoch:27 step:21649 [D loss: 0.550723, acc: 78.91%] [G loss: 2.414248]\n",
      "epoch:27 step:21650 [D loss: 0.420669, acc: 69.53%] [G loss: 5.235290]\n",
      "epoch:27 step:21651 [D loss: 0.117291, acc: 100.00%] [G loss: 4.284955]\n",
      "epoch:27 step:21652 [D loss: 0.565105, acc: 60.94%] [G loss: 6.168594]\n",
      "epoch:27 step:21653 [D loss: 0.501217, acc: 73.44%] [G loss: 6.006634]\n",
      "epoch:27 step:21654 [D loss: 0.329040, acc: 94.53%] [G loss: 3.804737]\n",
      "epoch:27 step:21655 [D loss: 1.098671, acc: 28.12%] [G loss: 5.396823]\n",
      "epoch:27 step:21656 [D loss: 0.165565, acc: 97.66%] [G loss: 7.227718]\n",
      "epoch:27 step:21657 [D loss: 0.405418, acc: 84.38%] [G loss: 3.089245]\n",
      "epoch:27 step:21658 [D loss: 0.743523, acc: 49.22%] [G loss: 3.513502]\n",
      "epoch:27 step:21659 [D loss: 0.355803, acc: 82.81%] [G loss: 5.087194]\n",
      "epoch:27 step:21660 [D loss: 0.680268, acc: 59.38%] [G loss: 3.433475]\n",
      "epoch:27 step:21661 [D loss: 0.644895, acc: 60.94%] [G loss: 4.493196]\n",
      "epoch:27 step:21662 [D loss: 0.606337, acc: 59.38%] [G loss: 3.414512]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:27 step:21663 [D loss: 0.822031, acc: 45.31%] [G loss: 3.277783]\n",
      "epoch:27 step:21664 [D loss: 0.434055, acc: 73.44%] [G loss: 3.353178]\n",
      "epoch:27 step:21665 [D loss: 0.263296, acc: 96.88%] [G loss: 5.532009]\n",
      "epoch:27 step:21666 [D loss: 0.322261, acc: 92.19%] [G loss: 3.982076]\n",
      "epoch:27 step:21667 [D loss: 0.254598, acc: 96.09%] [G loss: 5.952466]\n",
      "epoch:27 step:21668 [D loss: 0.174535, acc: 99.22%] [G loss: 4.405048]\n",
      "epoch:27 step:21669 [D loss: 0.273487, acc: 93.75%] [G loss: 4.652400]\n",
      "epoch:27 step:21670 [D loss: 0.117171, acc: 100.00%] [G loss: 4.399148]\n",
      "epoch:27 step:21671 [D loss: 0.446773, acc: 85.16%] [G loss: 6.403262]\n",
      "epoch:27 step:21672 [D loss: 0.728374, acc: 57.03%] [G loss: 5.121920]\n",
      "epoch:27 step:21673 [D loss: 0.206553, acc: 96.09%] [G loss: 3.329683]\n",
      "epoch:27 step:21674 [D loss: 1.020112, acc: 21.09%] [G loss: 4.718998]\n",
      "epoch:27 step:21675 [D loss: 1.046622, acc: 30.47%] [G loss: 3.782881]\n",
      "epoch:27 step:21676 [D loss: 0.357121, acc: 90.62%] [G loss: 4.976655]\n",
      "epoch:27 step:21677 [D loss: 0.517642, acc: 75.78%] [G loss: 3.593202]\n",
      "epoch:27 step:21678 [D loss: 1.239847, acc: 49.22%] [G loss: 3.796196]\n",
      "epoch:27 step:21679 [D loss: 0.587004, acc: 71.88%] [G loss: 3.906211]\n",
      "epoch:27 step:21680 [D loss: 0.335471, acc: 88.28%] [G loss: 3.308730]\n",
      "epoch:27 step:21681 [D loss: 0.632884, acc: 64.06%] [G loss: 2.800203]\n",
      "epoch:27 step:21682 [D loss: 1.242422, acc: 48.44%] [G loss: 2.287026]\n",
      "epoch:27 step:21683 [D loss: 0.679544, acc: 57.81%] [G loss: 4.358128]\n",
      "epoch:27 step:21684 [D loss: 0.164507, acc: 100.00%] [G loss: 3.184682]\n",
      "epoch:27 step:21685 [D loss: 0.143605, acc: 100.00%] [G loss: 4.245012]\n",
      "epoch:27 step:21686 [D loss: 0.489097, acc: 83.59%] [G loss: 2.405393]\n",
      "epoch:27 step:21687 [D loss: 0.502715, acc: 79.69%] [G loss: 3.657429]\n",
      "epoch:27 step:21688 [D loss: 0.221767, acc: 98.44%] [G loss: 3.903527]\n",
      "epoch:27 step:21689 [D loss: 0.777873, acc: 57.03%] [G loss: 5.273710]\n",
      "epoch:27 step:21690 [D loss: 0.273723, acc: 93.75%] [G loss: 4.492910]\n",
      "epoch:27 step:21691 [D loss: 0.132767, acc: 100.00%] [G loss: 2.697059]\n",
      "epoch:27 step:21692 [D loss: 0.443760, acc: 77.34%] [G loss: 2.442878]\n",
      "epoch:27 step:21693 [D loss: 1.126454, acc: 49.22%] [G loss: 4.159120]\n",
      "epoch:27 step:21694 [D loss: 0.147920, acc: 99.22%] [G loss: 3.459705]\n",
      "epoch:27 step:21695 [D loss: 0.718881, acc: 55.47%] [G loss: 4.442678]\n",
      "epoch:27 step:21696 [D loss: 1.042909, acc: 48.44%] [G loss: 3.728519]\n",
      "epoch:27 step:21697 [D loss: 0.805468, acc: 52.34%] [G loss: 3.814987]\n",
      "epoch:27 step:21698 [D loss: 0.703901, acc: 53.12%] [G loss: 5.019104]\n",
      "epoch:27 step:21699 [D loss: 0.358688, acc: 84.38%] [G loss: 2.112730]\n",
      "epoch:27 step:21700 [D loss: 0.152203, acc: 100.00%] [G loss: 4.433410]\n",
      "epoch:27 step:21701 [D loss: 0.151406, acc: 99.22%] [G loss: 4.655441]\n",
      "epoch:27 step:21702 [D loss: 0.573873, acc: 69.53%] [G loss: 3.859849]\n",
      "epoch:27 step:21703 [D loss: 0.262072, acc: 96.88%] [G loss: 3.779920]\n",
      "epoch:27 step:21704 [D loss: 0.539649, acc: 68.75%] [G loss: 2.501351]\n",
      "epoch:27 step:21705 [D loss: 0.426049, acc: 79.69%] [G loss: 3.767330]\n",
      "epoch:27 step:21706 [D loss: 1.403472, acc: 25.00%] [G loss: 4.239842]\n",
      "epoch:27 step:21707 [D loss: 0.267215, acc: 92.19%] [G loss: 2.699389]\n",
      "epoch:27 step:21708 [D loss: 0.528804, acc: 72.66%] [G loss: 2.953336]\n",
      "epoch:27 step:21709 [D loss: 0.709305, acc: 53.91%] [G loss: 3.382650]\n",
      "epoch:27 step:21710 [D loss: 0.858190, acc: 40.62%] [G loss: 3.107613]\n",
      "epoch:27 step:21711 [D loss: 0.071130, acc: 100.00%] [G loss: 6.026406]\n",
      "epoch:27 step:21712 [D loss: 0.324385, acc: 91.41%] [G loss: 3.834163]\n",
      "epoch:27 step:21713 [D loss: 0.707964, acc: 57.81%] [G loss: 3.088116]\n",
      "epoch:27 step:21714 [D loss: 0.406097, acc: 89.84%] [G loss: 4.605835]\n",
      "epoch:27 step:21715 [D loss: 0.304122, acc: 85.94%] [G loss: 6.712206]\n",
      "epoch:27 step:21716 [D loss: 0.751715, acc: 58.59%] [G loss: 2.711269]\n",
      "epoch:27 step:21717 [D loss: 0.201839, acc: 99.22%] [G loss: 5.999797]\n",
      "epoch:27 step:21718 [D loss: 0.389158, acc: 85.16%] [G loss: 3.731007]\n",
      "epoch:27 step:21719 [D loss: 0.277748, acc: 94.53%] [G loss: 3.132390]\n",
      "epoch:27 step:21720 [D loss: 0.424897, acc: 81.25%] [G loss: 5.553139]\n",
      "epoch:27 step:21721 [D loss: 0.795407, acc: 51.56%] [G loss: 4.143964]\n",
      "epoch:27 step:21722 [D loss: 0.208186, acc: 99.22%] [G loss: 5.075123]\n",
      "epoch:27 step:21723 [D loss: 0.400670, acc: 86.72%] [G loss: 4.232533]\n",
      "epoch:27 step:21724 [D loss: 0.404237, acc: 85.16%] [G loss: 3.472348]\n",
      "epoch:27 step:21725 [D loss: 0.436130, acc: 77.34%] [G loss: 4.229934]\n",
      "epoch:27 step:21726 [D loss: 0.317761, acc: 87.50%] [G loss: 3.608230]\n",
      "epoch:27 step:21727 [D loss: 0.277543, acc: 96.88%] [G loss: 3.833655]\n",
      "epoch:27 step:21728 [D loss: 0.325177, acc: 92.19%] [G loss: 5.060534]\n",
      "epoch:27 step:21729 [D loss: 0.478242, acc: 70.31%] [G loss: 3.974865]\n",
      "epoch:27 step:21730 [D loss: 0.675926, acc: 57.03%] [G loss: 3.505850]\n",
      "epoch:27 step:21731 [D loss: 0.077625, acc: 99.22%] [G loss: 5.999220]\n",
      "epoch:27 step:21732 [D loss: 0.200183, acc: 96.88%] [G loss: 5.555188]\n",
      "epoch:27 step:21733 [D loss: 0.195330, acc: 96.88%] [G loss: 3.336640]\n",
      "epoch:27 step:21734 [D loss: 0.570160, acc: 64.84%] [G loss: 2.026954]\n",
      "epoch:27 step:21735 [D loss: 1.115405, acc: 50.00%] [G loss: 3.414838]\n",
      "epoch:27 step:21736 [D loss: 0.282457, acc: 92.19%] [G loss: 6.304395]\n",
      "epoch:27 step:21737 [D loss: 0.297335, acc: 89.84%] [G loss: 5.426814]\n",
      "epoch:27 step:21738 [D loss: 0.800812, acc: 54.69%] [G loss: 4.033182]\n",
      "epoch:27 step:21739 [D loss: 0.903916, acc: 51.56%] [G loss: 2.542314]\n",
      "epoch:27 step:21740 [D loss: 0.046214, acc: 100.00%] [G loss: 5.724226]\n",
      "epoch:27 step:21741 [D loss: 0.512934, acc: 76.56%] [G loss: 4.046118]\n",
      "epoch:27 step:21742 [D loss: 0.209504, acc: 95.31%] [G loss: 2.603130]\n",
      "epoch:27 step:21743 [D loss: 1.224613, acc: 50.00%] [G loss: 6.152587]\n",
      "epoch:27 step:21744 [D loss: 0.172438, acc: 98.44%] [G loss: 4.029666]\n",
      "epoch:27 step:21745 [D loss: 0.495505, acc: 71.88%] [G loss: 5.856935]\n",
      "epoch:27 step:21746 [D loss: 0.018763, acc: 100.00%] [G loss: 6.123673]\n",
      "epoch:27 step:21747 [D loss: 0.982494, acc: 36.72%] [G loss: 3.947783]\n",
      "epoch:27 step:21748 [D loss: 0.344844, acc: 92.97%] [G loss: 5.093437]\n",
      "epoch:27 step:21749 [D loss: 0.166207, acc: 99.22%] [G loss: 3.431720]\n",
      "epoch:27 step:21750 [D loss: 0.161149, acc: 98.44%] [G loss: 6.274204]\n",
      "epoch:27 step:21751 [D loss: 0.227995, acc: 91.41%] [G loss: 4.221431]\n",
      "epoch:27 step:21752 [D loss: 0.599502, acc: 67.19%] [G loss: 4.287127]\n",
      "epoch:27 step:21753 [D loss: 2.006833, acc: 2.34%] [G loss: 4.592139]\n",
      "epoch:27 step:21754 [D loss: 0.426781, acc: 67.97%] [G loss: 3.723099]\n",
      "epoch:27 step:21755 [D loss: 0.401300, acc: 74.22%] [G loss: 6.283984]\n",
      "epoch:27 step:21756 [D loss: 1.043782, acc: 50.00%] [G loss: 4.177511]\n",
      "epoch:27 step:21757 [D loss: 0.349026, acc: 95.31%] [G loss: 4.358282]\n",
      "epoch:27 step:21758 [D loss: 0.547324, acc: 65.62%] [G loss: 3.407632]\n",
      "epoch:27 step:21759 [D loss: 0.182298, acc: 98.44%] [G loss: 4.669269]\n",
      "epoch:27 step:21760 [D loss: 0.401583, acc: 81.25%] [G loss: 3.483141]\n",
      "epoch:27 step:21761 [D loss: 1.130767, acc: 29.69%] [G loss: 3.905630]\n",
      "epoch:27 step:21762 [D loss: 0.189950, acc: 98.44%] [G loss: 4.622003]\n",
      "epoch:27 step:21763 [D loss: 1.056630, acc: 50.00%] [G loss: 4.081484]\n",
      "epoch:27 step:21764 [D loss: 0.070656, acc: 100.00%] [G loss: 5.839065]\n",
      "epoch:27 step:21765 [D loss: 0.526850, acc: 68.75%] [G loss: 5.053150]\n",
      "epoch:27 step:21766 [D loss: 0.366038, acc: 85.94%] [G loss: 3.220551]\n",
      "epoch:27 step:21767 [D loss: 0.324363, acc: 92.97%] [G loss: 5.372510]\n",
      "epoch:27 step:21768 [D loss: 0.481354, acc: 64.06%] [G loss: 3.901000]\n",
      "epoch:27 step:21769 [D loss: 0.749868, acc: 55.47%] [G loss: 4.806788]\n",
      "epoch:27 step:21770 [D loss: 0.732474, acc: 51.56%] [G loss: 3.680771]\n",
      "epoch:27 step:21771 [D loss: 0.179728, acc: 98.44%] [G loss: 3.080793]\n",
      "epoch:27 step:21772 [D loss: 0.225147, acc: 96.09%] [G loss: 3.091257]\n",
      "epoch:27 step:21773 [D loss: 0.283936, acc: 93.75%] [G loss: 3.136415]\n",
      "epoch:27 step:21774 [D loss: 0.449790, acc: 81.25%] [G loss: 3.650786]\n",
      "epoch:27 step:21775 [D loss: 0.284129, acc: 95.31%] [G loss: 3.989045]\n",
      "epoch:27 step:21776 [D loss: 1.080136, acc: 48.44%] [G loss: 4.679092]\n",
      "epoch:27 step:21777 [D loss: 0.377593, acc: 77.34%] [G loss: 3.461174]\n",
      "epoch:27 step:21778 [D loss: 0.287949, acc: 91.41%] [G loss: 5.238790]\n",
      "epoch:27 step:21779 [D loss: 1.151368, acc: 47.66%] [G loss: 4.138847]\n",
      "epoch:27 step:21780 [D loss: 0.393496, acc: 85.16%] [G loss: 3.719140]\n",
      "epoch:27 step:21781 [D loss: 0.751702, acc: 56.25%] [G loss: 4.082354]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:27 step:21782 [D loss: 0.418585, acc: 84.38%] [G loss: 2.969211]\n",
      "epoch:27 step:21783 [D loss: 0.349786, acc: 92.97%] [G loss: 4.427151]\n",
      "epoch:27 step:21784 [D loss: 1.034727, acc: 36.72%] [G loss: 3.903344]\n",
      "epoch:27 step:21785 [D loss: 0.575972, acc: 70.31%] [G loss: 2.947072]\n",
      "epoch:27 step:21786 [D loss: 0.341511, acc: 91.41%] [G loss: 4.116767]\n",
      "epoch:27 step:21787 [D loss: 0.613054, acc: 64.84%] [G loss: 3.328426]\n",
      "epoch:27 step:21788 [D loss: 0.812932, acc: 46.88%] [G loss: 4.779680]\n",
      "epoch:27 step:21789 [D loss: 0.242671, acc: 96.09%] [G loss: 3.309093]\n",
      "epoch:27 step:21790 [D loss: 0.840120, acc: 48.44%] [G loss: 2.613522]\n",
      "epoch:27 step:21791 [D loss: 0.252249, acc: 96.09%] [G loss: 3.456208]\n",
      "epoch:27 step:21792 [D loss: 0.237997, acc: 100.00%] [G loss: 3.496912]\n",
      "epoch:27 step:21793 [D loss: 0.145079, acc: 100.00%] [G loss: 5.243886]\n",
      "epoch:27 step:21794 [D loss: 0.294475, acc: 92.97%] [G loss: 2.918215]\n",
      "epoch:27 step:21795 [D loss: 0.784918, acc: 53.12%] [G loss: 5.991026]\n",
      "epoch:27 step:21796 [D loss: 0.327477, acc: 93.75%] [G loss: 3.490583]\n",
      "epoch:27 step:21797 [D loss: 0.851753, acc: 50.78%] [G loss: 3.530540]\n",
      "epoch:27 step:21798 [D loss: 0.208486, acc: 94.53%] [G loss: 5.596098]\n",
      "epoch:27 step:21799 [D loss: 0.208625, acc: 97.66%] [G loss: 4.182384]\n",
      "epoch:27 step:21800 [D loss: 0.322076, acc: 83.59%] [G loss: 6.519197]\n",
      "##############\n",
      "[0.84668062 0.88806106 0.81611048 0.80756265 0.786076   0.8308169\n",
      " 0.88272457 0.83496294 0.78219278 0.82075753]\n",
      "##########\n",
      "epoch:27 step:21801 [D loss: 0.159792, acc: 100.00%] [G loss: 5.406764]\n",
      "epoch:27 step:21802 [D loss: 0.762639, acc: 48.44%] [G loss: 3.189899]\n",
      "epoch:27 step:21803 [D loss: 0.493938, acc: 67.19%] [G loss: 6.042909]\n",
      "epoch:27 step:21804 [D loss: 0.304969, acc: 92.19%] [G loss: 3.326520]\n",
      "epoch:27 step:21805 [D loss: 0.138378, acc: 99.22%] [G loss: 5.603336]\n",
      "epoch:27 step:21806 [D loss: 0.142575, acc: 98.44%] [G loss: 3.355022]\n",
      "epoch:27 step:21807 [D loss: 0.613081, acc: 64.84%] [G loss: 4.656642]\n",
      "epoch:27 step:21808 [D loss: 0.316331, acc: 88.28%] [G loss: 4.213559]\n",
      "epoch:27 step:21809 [D loss: 0.114928, acc: 100.00%] [G loss: 3.237367]\n",
      "epoch:27 step:21810 [D loss: 0.533026, acc: 58.59%] [G loss: 5.182518]\n",
      "epoch:27 step:21811 [D loss: 0.778438, acc: 53.91%] [G loss: 3.417305]\n",
      "epoch:27 step:21812 [D loss: 0.861593, acc: 53.91%] [G loss: 3.222425]\n",
      "epoch:27 step:21813 [D loss: 0.364634, acc: 78.91%] [G loss: 3.995698]\n",
      "epoch:27 step:21814 [D loss: 0.360792, acc: 89.84%] [G loss: 4.631389]\n",
      "epoch:27 step:21815 [D loss: 1.155900, acc: 28.91%] [G loss: 4.215086]\n",
      "epoch:27 step:21816 [D loss: 0.373400, acc: 85.16%] [G loss: 4.017576]\n",
      "epoch:27 step:21817 [D loss: 0.610856, acc: 69.53%] [G loss: 2.777154]\n",
      "epoch:27 step:21818 [D loss: 0.278530, acc: 93.75%] [G loss: 3.775762]\n",
      "epoch:27 step:21819 [D loss: 0.814144, acc: 51.56%] [G loss: 4.847125]\n",
      "epoch:27 step:21820 [D loss: 0.359651, acc: 86.72%] [G loss: 4.077603]\n",
      "epoch:27 step:21821 [D loss: 1.622113, acc: 5.47%] [G loss: 2.875703]\n",
      "epoch:27 step:21822 [D loss: 0.471183, acc: 74.22%] [G loss: 5.234735]\n",
      "epoch:27 step:21823 [D loss: 0.369273, acc: 78.91%] [G loss: 5.380994]\n",
      "epoch:27 step:21824 [D loss: 0.274925, acc: 89.84%] [G loss: 6.695837]\n",
      "epoch:27 step:21825 [D loss: 0.277655, acc: 90.62%] [G loss: 3.657958]\n",
      "epoch:27 step:21826 [D loss: 0.951999, acc: 45.31%] [G loss: 2.966833]\n",
      "epoch:27 step:21827 [D loss: 0.264855, acc: 94.53%] [G loss: 4.256699]\n",
      "epoch:27 step:21828 [D loss: 0.346982, acc: 93.75%] [G loss: 4.399676]\n",
      "epoch:27 step:21829 [D loss: 0.152116, acc: 99.22%] [G loss: 3.359835]\n",
      "epoch:27 step:21830 [D loss: 0.290641, acc: 93.75%] [G loss: 2.861987]\n",
      "epoch:27 step:21831 [D loss: 0.245373, acc: 98.44%] [G loss: 3.836449]\n",
      "epoch:27 step:21832 [D loss: 0.085673, acc: 100.00%] [G loss: 3.803171]\n",
      "epoch:27 step:21833 [D loss: 0.405835, acc: 89.06%] [G loss: 3.838766]\n",
      "epoch:27 step:21834 [D loss: 0.452251, acc: 85.94%] [G loss: 4.100990]\n",
      "epoch:27 step:21835 [D loss: 0.708276, acc: 57.81%] [G loss: 3.809305]\n",
      "epoch:27 step:21836 [D loss: 0.242544, acc: 96.09%] [G loss: 2.150495]\n",
      "epoch:27 step:21837 [D loss: 0.312906, acc: 94.53%] [G loss: 3.921570]\n",
      "epoch:27 step:21838 [D loss: 0.342070, acc: 90.62%] [G loss: 2.617137]\n",
      "epoch:27 step:21839 [D loss: 0.421217, acc: 70.31%] [G loss: 4.003389]\n",
      "epoch:27 step:21840 [D loss: 0.187532, acc: 99.22%] [G loss: 4.593294]\n",
      "epoch:27 step:21841 [D loss: 1.157436, acc: 28.91%] [G loss: 2.627729]\n",
      "epoch:27 step:21842 [D loss: 0.365076, acc: 84.38%] [G loss: 3.015310]\n",
      "epoch:27 step:21843 [D loss: 0.184441, acc: 97.66%] [G loss: 5.306293]\n",
      "epoch:27 step:21844 [D loss: 0.372576, acc: 89.84%] [G loss: 3.673931]\n",
      "epoch:27 step:21845 [D loss: 0.286773, acc: 97.66%] [G loss: 5.656404]\n",
      "epoch:27 step:21846 [D loss: 0.701174, acc: 56.25%] [G loss: 2.624714]\n",
      "epoch:27 step:21847 [D loss: 0.150784, acc: 97.66%] [G loss: 5.194642]\n",
      "epoch:27 step:21848 [D loss: 0.118819, acc: 98.44%] [G loss: 4.868651]\n",
      "epoch:27 step:21849 [D loss: 0.361970, acc: 82.81%] [G loss: 4.682544]\n",
      "epoch:27 step:21850 [D loss: 0.462526, acc: 69.53%] [G loss: 3.113333]\n",
      "epoch:27 step:21851 [D loss: 0.286275, acc: 98.44%] [G loss: 4.274892]\n",
      "epoch:27 step:21852 [D loss: 0.233471, acc: 96.88%] [G loss: 3.747098]\n",
      "epoch:27 step:21853 [D loss: 0.752075, acc: 53.91%] [G loss: 3.754332]\n",
      "epoch:27 step:21854 [D loss: 0.316956, acc: 95.31%] [G loss: 6.441518]\n",
      "epoch:27 step:21855 [D loss: 0.290633, acc: 92.97%] [G loss: 5.473818]\n",
      "epoch:27 step:21856 [D loss: 0.495978, acc: 74.22%] [G loss: 5.070110]\n",
      "epoch:27 step:21857 [D loss: 1.325354, acc: 11.72%] [G loss: 3.443879]\n",
      "epoch:27 step:21858 [D loss: 0.351116, acc: 90.62%] [G loss: 4.421880]\n",
      "epoch:27 step:21859 [D loss: 0.421397, acc: 73.44%] [G loss: 4.253632]\n",
      "epoch:27 step:21860 [D loss: 0.057748, acc: 100.00%] [G loss: 4.967984]\n",
      "epoch:27 step:21861 [D loss: 0.252183, acc: 96.88%] [G loss: 3.065196]\n",
      "epoch:27 step:21862 [D loss: 0.591176, acc: 74.22%] [G loss: 2.920350]\n",
      "epoch:27 step:21863 [D loss: 0.464744, acc: 70.31%] [G loss: 4.545355]\n",
      "epoch:27 step:21864 [D loss: 0.533777, acc: 69.53%] [G loss: 3.861315]\n",
      "epoch:27 step:21865 [D loss: 0.815425, acc: 50.78%] [G loss: 5.017128]\n",
      "epoch:27 step:21866 [D loss: 0.459376, acc: 78.12%] [G loss: 1.645047]\n",
      "epoch:27 step:21867 [D loss: 0.553555, acc: 69.53%] [G loss: 4.093925]\n",
      "epoch:27 step:21868 [D loss: 0.250727, acc: 97.66%] [G loss: 4.108235]\n",
      "epoch:28 step:21869 [D loss: 1.073516, acc: 35.94%] [G loss: 5.379353]\n",
      "epoch:28 step:21870 [D loss: 0.415710, acc: 89.06%] [G loss: 3.512953]\n",
      "epoch:28 step:21871 [D loss: 0.364631, acc: 87.50%] [G loss: 4.291421]\n",
      "epoch:28 step:21872 [D loss: 0.129520, acc: 99.22%] [G loss: 5.591980]\n",
      "epoch:28 step:21873 [D loss: 0.142649, acc: 97.66%] [G loss: 4.459840]\n",
      "epoch:28 step:21874 [D loss: 0.872986, acc: 46.88%] [G loss: 2.287010]\n",
      "epoch:28 step:21875 [D loss: 0.526922, acc: 68.75%] [G loss: 2.590348]\n",
      "epoch:28 step:21876 [D loss: 0.664216, acc: 60.16%] [G loss: 3.771230]\n",
      "epoch:28 step:21877 [D loss: 0.051174, acc: 100.00%] [G loss: 5.579432]\n",
      "epoch:28 step:21878 [D loss: 0.542336, acc: 63.28%] [G loss: 5.441280]\n",
      "epoch:28 step:21879 [D loss: 0.058872, acc: 100.00%] [G loss: 4.631483]\n",
      "epoch:28 step:21880 [D loss: 0.453083, acc: 82.81%] [G loss: 2.120562]\n",
      "epoch:28 step:21881 [D loss: 0.297641, acc: 93.75%] [G loss: 3.825868]\n",
      "epoch:28 step:21882 [D loss: 0.383980, acc: 82.03%] [G loss: 3.122060]\n",
      "epoch:28 step:21883 [D loss: 0.551326, acc: 65.62%] [G loss: 4.197103]\n",
      "epoch:28 step:21884 [D loss: 0.359457, acc: 85.16%] [G loss: 4.954260]\n",
      "epoch:28 step:21885 [D loss: 0.183760, acc: 97.66%] [G loss: 3.611247]\n",
      "epoch:28 step:21886 [D loss: 0.417545, acc: 85.16%] [G loss: 3.446173]\n",
      "epoch:28 step:21887 [D loss: 0.185360, acc: 98.44%] [G loss: 3.895463]\n",
      "epoch:28 step:21888 [D loss: 0.211144, acc: 95.31%] [G loss: 4.614560]\n",
      "epoch:28 step:21889 [D loss: 0.064743, acc: 100.00%] [G loss: 3.370080]\n",
      "epoch:28 step:21890 [D loss: 0.425610, acc: 83.59%] [G loss: 3.839925]\n",
      "epoch:28 step:21891 [D loss: 0.263644, acc: 92.97%] [G loss: 2.496749]\n",
      "epoch:28 step:21892 [D loss: 0.297143, acc: 87.50%] [G loss: 3.731503]\n",
      "epoch:28 step:21893 [D loss: 0.475814, acc: 67.97%] [G loss: 3.002518]\n",
      "epoch:28 step:21894 [D loss: 0.342523, acc: 78.91%] [G loss: 4.585721]\n",
      "epoch:28 step:21895 [D loss: 0.300596, acc: 85.16%] [G loss: 3.997474]\n",
      "epoch:28 step:21896 [D loss: 0.919551, acc: 42.19%] [G loss: 2.129134]\n",
      "epoch:28 step:21897 [D loss: 0.153325, acc: 100.00%] [G loss: 3.864684]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:28 step:21898 [D loss: 0.246693, acc: 96.09%] [G loss: 3.229162]\n",
      "epoch:28 step:21899 [D loss: 0.703192, acc: 54.69%] [G loss: 3.695916]\n",
      "epoch:28 step:21900 [D loss: 0.254874, acc: 100.00%] [G loss: 3.584847]\n",
      "epoch:28 step:21901 [D loss: 0.546582, acc: 68.75%] [G loss: 3.064767]\n",
      "epoch:28 step:21902 [D loss: 0.580353, acc: 67.97%] [G loss: 2.149591]\n",
      "epoch:28 step:21903 [D loss: 1.013454, acc: 24.22%] [G loss: 4.613281]\n",
      "epoch:28 step:21904 [D loss: 0.089002, acc: 100.00%] [G loss: 4.500369]\n",
      "epoch:28 step:21905 [D loss: 0.183819, acc: 99.22%] [G loss: 4.731271]\n",
      "epoch:28 step:21906 [D loss: 0.652364, acc: 54.69%] [G loss: 5.847939]\n",
      "epoch:28 step:21907 [D loss: 0.421290, acc: 68.75%] [G loss: 2.455390]\n",
      "epoch:28 step:21908 [D loss: 0.167256, acc: 98.44%] [G loss: 3.210176]\n",
      "epoch:28 step:21909 [D loss: 0.540051, acc: 61.72%] [G loss: 4.111350]\n",
      "epoch:28 step:21910 [D loss: 0.813333, acc: 52.34%] [G loss: 3.120977]\n",
      "epoch:28 step:21911 [D loss: 0.466830, acc: 78.12%] [G loss: 3.863072]\n",
      "epoch:28 step:21912 [D loss: 0.866255, acc: 50.78%] [G loss: 4.304745]\n",
      "epoch:28 step:21913 [D loss: 0.627475, acc: 62.50%] [G loss: 1.783031]\n",
      "epoch:28 step:21914 [D loss: 0.651884, acc: 61.72%] [G loss: 4.398263]\n",
      "epoch:28 step:21915 [D loss: 1.878350, acc: 44.53%] [G loss: 2.991026]\n",
      "epoch:28 step:21916 [D loss: 0.807826, acc: 48.44%] [G loss: 3.185827]\n",
      "epoch:28 step:21917 [D loss: 0.369851, acc: 81.25%] [G loss: 4.402103]\n",
      "epoch:28 step:21918 [D loss: 1.027669, acc: 41.41%] [G loss: 4.748857]\n",
      "epoch:28 step:21919 [D loss: 0.232337, acc: 93.75%] [G loss: 4.279606]\n",
      "epoch:28 step:21920 [D loss: 0.162081, acc: 99.22%] [G loss: 6.132394]\n",
      "epoch:28 step:21921 [D loss: 0.215940, acc: 95.31%] [G loss: 5.914247]\n",
      "epoch:28 step:21922 [D loss: 0.073305, acc: 100.00%] [G loss: 5.395379]\n",
      "epoch:28 step:21923 [D loss: 0.532954, acc: 57.81%] [G loss: 3.567517]\n",
      "epoch:28 step:21924 [D loss: 0.441275, acc: 77.34%] [G loss: 2.781055]\n",
      "epoch:28 step:21925 [D loss: 0.781378, acc: 53.12%] [G loss: 3.177425]\n",
      "epoch:28 step:21926 [D loss: 0.416350, acc: 80.47%] [G loss: 4.626532]\n",
      "epoch:28 step:21927 [D loss: 0.094053, acc: 99.22%] [G loss: 4.638425]\n",
      "epoch:28 step:21928 [D loss: 0.390638, acc: 78.12%] [G loss: 3.653264]\n",
      "epoch:28 step:21929 [D loss: 0.080238, acc: 100.00%] [G loss: 3.543881]\n",
      "epoch:28 step:21930 [D loss: 0.348096, acc: 84.38%] [G loss: 4.245434]\n",
      "epoch:28 step:21931 [D loss: 0.580697, acc: 71.09%] [G loss: 2.950496]\n",
      "epoch:28 step:21932 [D loss: 0.259649, acc: 96.88%] [G loss: 2.713672]\n",
      "epoch:28 step:21933 [D loss: 0.280441, acc: 95.31%] [G loss: 2.563487]\n",
      "epoch:28 step:21934 [D loss: 0.248874, acc: 90.62%] [G loss: 4.888268]\n",
      "epoch:28 step:21935 [D loss: 0.214300, acc: 94.53%] [G loss: 3.450120]\n",
      "epoch:28 step:21936 [D loss: 0.737626, acc: 53.91%] [G loss: 3.352484]\n",
      "epoch:28 step:21937 [D loss: 0.611894, acc: 62.50%] [G loss: 3.814054]\n",
      "epoch:28 step:21938 [D loss: 0.473439, acc: 70.31%] [G loss: 4.962578]\n",
      "epoch:28 step:21939 [D loss: 1.107143, acc: 16.41%] [G loss: 2.638336]\n",
      "epoch:28 step:21940 [D loss: 0.584985, acc: 73.44%] [G loss: 4.781077]\n",
      "epoch:28 step:21941 [D loss: 0.426373, acc: 77.34%] [G loss: 4.186705]\n",
      "epoch:28 step:21942 [D loss: 0.593943, acc: 57.03%] [G loss: 3.827246]\n",
      "epoch:28 step:21943 [D loss: 0.737410, acc: 53.91%] [G loss: 4.346659]\n",
      "epoch:28 step:21944 [D loss: 0.141705, acc: 99.22%] [G loss: 4.908712]\n",
      "epoch:28 step:21945 [D loss: 0.202874, acc: 99.22%] [G loss: 4.001121]\n",
      "epoch:28 step:21946 [D loss: 0.391750, acc: 91.41%] [G loss: 5.397133]\n",
      "epoch:28 step:21947 [D loss: 0.237911, acc: 97.66%] [G loss: 4.350470]\n",
      "epoch:28 step:21948 [D loss: 0.217923, acc: 96.88%] [G loss: 3.513748]\n",
      "epoch:28 step:21949 [D loss: 0.282825, acc: 95.31%] [G loss: 4.570355]\n",
      "epoch:28 step:21950 [D loss: 0.222698, acc: 97.66%] [G loss: 4.532536]\n",
      "epoch:28 step:21951 [D loss: 0.455364, acc: 83.59%] [G loss: 6.031406]\n",
      "epoch:28 step:21952 [D loss: 0.384233, acc: 91.41%] [G loss: 3.817735]\n",
      "epoch:28 step:21953 [D loss: 0.308404, acc: 94.53%] [G loss: 4.295483]\n",
      "epoch:28 step:21954 [D loss: 0.398223, acc: 83.59%] [G loss: 3.550821]\n",
      "epoch:28 step:21955 [D loss: 0.292850, acc: 94.53%] [G loss: 4.378970]\n",
      "epoch:28 step:21956 [D loss: 0.401920, acc: 86.72%] [G loss: 3.417478]\n",
      "epoch:28 step:21957 [D loss: 0.362510, acc: 77.34%] [G loss: 7.963282]\n",
      "epoch:28 step:21958 [D loss: 0.164323, acc: 98.44%] [G loss: 2.393110]\n",
      "epoch:28 step:21959 [D loss: 0.738294, acc: 53.12%] [G loss: 4.530893]\n",
      "epoch:28 step:21960 [D loss: 0.125934, acc: 99.22%] [G loss: 5.580037]\n",
      "epoch:28 step:21961 [D loss: 0.154111, acc: 99.22%] [G loss: 3.753953]\n",
      "epoch:28 step:21962 [D loss: 0.571954, acc: 62.50%] [G loss: 2.909099]\n",
      "epoch:28 step:21963 [D loss: 0.538153, acc: 69.53%] [G loss: 4.010690]\n",
      "epoch:28 step:21964 [D loss: 0.175791, acc: 95.31%] [G loss: 3.450658]\n",
      "epoch:28 step:21965 [D loss: 0.447077, acc: 75.78%] [G loss: 3.987392]\n",
      "epoch:28 step:21966 [D loss: 1.069440, acc: 50.00%] [G loss: 4.014521]\n",
      "epoch:28 step:21967 [D loss: 1.046833, acc: 39.06%] [G loss: 3.742796]\n",
      "epoch:28 step:21968 [D loss: 0.692673, acc: 57.03%] [G loss: 4.859301]\n",
      "epoch:28 step:21969 [D loss: 0.413370, acc: 70.31%] [G loss: 3.703744]\n",
      "epoch:28 step:21970 [D loss: 0.737584, acc: 53.91%] [G loss: 4.062315]\n",
      "epoch:28 step:21971 [D loss: 0.476450, acc: 78.12%] [G loss: 4.619030]\n",
      "epoch:28 step:21972 [D loss: 0.796807, acc: 56.25%] [G loss: 5.571774]\n",
      "epoch:28 step:21973 [D loss: 0.863817, acc: 43.75%] [G loss: 4.109784]\n",
      "epoch:28 step:21974 [D loss: 0.276511, acc: 87.50%] [G loss: 6.553259]\n",
      "epoch:28 step:21975 [D loss: 0.476813, acc: 63.28%] [G loss: 5.642276]\n",
      "epoch:28 step:21976 [D loss: 0.503678, acc: 71.09%] [G loss: 4.756674]\n",
      "epoch:28 step:21977 [D loss: 0.783531, acc: 52.34%] [G loss: 6.875419]\n",
      "epoch:28 step:21978 [D loss: 0.329589, acc: 79.69%] [G loss: 2.916224]\n",
      "epoch:28 step:21979 [D loss: 0.594320, acc: 71.88%] [G loss: 3.996876]\n",
      "epoch:28 step:21980 [D loss: 0.153435, acc: 98.44%] [G loss: 3.698306]\n",
      "epoch:28 step:21981 [D loss: 0.100444, acc: 99.22%] [G loss: 5.437053]\n",
      "epoch:28 step:21982 [D loss: 0.067438, acc: 100.00%] [G loss: 5.097664]\n",
      "epoch:28 step:21983 [D loss: 1.263573, acc: 12.50%] [G loss: 5.982608]\n",
      "epoch:28 step:21984 [D loss: 0.114929, acc: 99.22%] [G loss: 4.991956]\n",
      "epoch:28 step:21985 [D loss: 1.098902, acc: 50.00%] [G loss: 6.026640]\n",
      "epoch:28 step:21986 [D loss: 0.848093, acc: 51.56%] [G loss: 2.905815]\n",
      "epoch:28 step:21987 [D loss: 0.320554, acc: 88.28%] [G loss: 2.642152]\n",
      "epoch:28 step:21988 [D loss: 0.189073, acc: 96.88%] [G loss: 4.629120]\n",
      "epoch:28 step:21989 [D loss: 0.247556, acc: 100.00%] [G loss: 5.295822]\n",
      "epoch:28 step:21990 [D loss: 0.589633, acc: 67.97%] [G loss: 4.079012]\n",
      "epoch:28 step:21991 [D loss: 0.063002, acc: 100.00%] [G loss: 4.284163]\n",
      "epoch:28 step:21992 [D loss: 0.563929, acc: 65.62%] [G loss: 3.121900]\n",
      "epoch:28 step:21993 [D loss: 0.716930, acc: 53.91%] [G loss: 2.707288]\n",
      "epoch:28 step:21994 [D loss: 0.344893, acc: 91.41%] [G loss: 2.593222]\n",
      "epoch:28 step:21995 [D loss: 0.328048, acc: 91.41%] [G loss: 2.915107]\n",
      "epoch:28 step:21996 [D loss: 0.302258, acc: 85.16%] [G loss: 6.610624]\n",
      "epoch:28 step:21997 [D loss: 0.354952, acc: 92.97%] [G loss: 3.967924]\n",
      "epoch:28 step:21998 [D loss: 0.066226, acc: 100.00%] [G loss: 5.302241]\n",
      "epoch:28 step:21999 [D loss: 0.712413, acc: 53.12%] [G loss: 3.935892]\n",
      "epoch:28 step:22000 [D loss: 0.294239, acc: 89.06%] [G loss: 5.398979]\n",
      "##############\n",
      "[0.86203545 0.85685987 0.81283596 0.83182889 0.79156274 0.82145708\n",
      " 0.89457237 0.81549177 0.80573469 0.82796653]\n",
      "##########\n",
      "epoch:28 step:22001 [D loss: 1.754127, acc: 0.78%] [G loss: 5.255058]\n",
      "epoch:28 step:22002 [D loss: 0.538244, acc: 71.09%] [G loss: 4.178855]\n",
      "epoch:28 step:22003 [D loss: 0.444266, acc: 78.91%] [G loss: 4.273133]\n",
      "epoch:28 step:22004 [D loss: 0.169885, acc: 98.44%] [G loss: 3.451076]\n",
      "epoch:28 step:22005 [D loss: 0.267463, acc: 90.62%] [G loss: 3.995757]\n",
      "epoch:28 step:22006 [D loss: 0.687246, acc: 57.81%] [G loss: 5.768149]\n",
      "epoch:28 step:22007 [D loss: 0.563636, acc: 62.50%] [G loss: 4.242499]\n",
      "epoch:28 step:22008 [D loss: 0.221528, acc: 99.22%] [G loss: 2.753760]\n",
      "epoch:28 step:22009 [D loss: 0.414149, acc: 90.62%] [G loss: 3.915731]\n",
      "epoch:28 step:22010 [D loss: 0.348931, acc: 78.91%] [G loss: 6.714327]\n",
      "epoch:28 step:22011 [D loss: 1.140182, acc: 48.44%] [G loss: 3.011852]\n",
      "epoch:28 step:22012 [D loss: 0.071218, acc: 100.00%] [G loss: 4.295945]\n",
      "epoch:28 step:22013 [D loss: 0.231088, acc: 96.88%] [G loss: 3.815284]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:28 step:22014 [D loss: 0.205423, acc: 98.44%] [G loss: 4.673248]\n",
      "epoch:28 step:22015 [D loss: 0.434019, acc: 83.59%] [G loss: 2.228589]\n",
      "epoch:28 step:22016 [D loss: 0.537003, acc: 67.19%] [G loss: 3.736956]\n",
      "epoch:28 step:22017 [D loss: 0.128819, acc: 98.44%] [G loss: 3.663554]\n",
      "epoch:28 step:22018 [D loss: 0.324235, acc: 85.16%] [G loss: 3.604086]\n",
      "epoch:28 step:22019 [D loss: 1.065901, acc: 43.75%] [G loss: 3.679553]\n",
      "epoch:28 step:22020 [D loss: 0.874355, acc: 37.50%] [G loss: 4.198007]\n",
      "epoch:28 step:22021 [D loss: 0.281718, acc: 87.50%] [G loss: 5.353478]\n",
      "epoch:28 step:22022 [D loss: 0.596905, acc: 68.75%] [G loss: 3.549756]\n",
      "epoch:28 step:22023 [D loss: 0.620638, acc: 68.75%] [G loss: 5.186149]\n",
      "epoch:28 step:22024 [D loss: 0.287478, acc: 96.88%] [G loss: 5.483519]\n",
      "epoch:28 step:22025 [D loss: 0.330102, acc: 96.09%] [G loss: 5.799079]\n",
      "epoch:28 step:22026 [D loss: 0.260459, acc: 92.19%] [G loss: 5.237058]\n",
      "epoch:28 step:22027 [D loss: 0.239989, acc: 97.66%] [G loss: 3.731879]\n",
      "epoch:28 step:22028 [D loss: 0.168709, acc: 100.00%] [G loss: 3.503590]\n",
      "epoch:28 step:22029 [D loss: 0.516212, acc: 67.19%] [G loss: 5.247561]\n",
      "epoch:28 step:22030 [D loss: 0.502049, acc: 78.91%] [G loss: 3.844177]\n",
      "epoch:28 step:22031 [D loss: 0.853306, acc: 41.41%] [G loss: 4.849525]\n",
      "epoch:28 step:22032 [D loss: 0.305806, acc: 93.75%] [G loss: 4.759961]\n",
      "epoch:28 step:22033 [D loss: 0.481102, acc: 83.59%] [G loss: 3.249534]\n",
      "epoch:28 step:22034 [D loss: 0.552439, acc: 67.97%] [G loss: 3.348055]\n",
      "epoch:28 step:22035 [D loss: 0.427395, acc: 91.41%] [G loss: 2.891130]\n",
      "epoch:28 step:22036 [D loss: 0.973548, acc: 53.91%] [G loss: 2.833670]\n",
      "epoch:28 step:22037 [D loss: 0.463778, acc: 66.41%] [G loss: 3.831843]\n",
      "epoch:28 step:22038 [D loss: 0.358978, acc: 91.41%] [G loss: 4.577242]\n",
      "epoch:28 step:22039 [D loss: 0.500591, acc: 72.66%] [G loss: 3.061544]\n",
      "epoch:28 step:22040 [D loss: 0.436709, acc: 67.97%] [G loss: 3.586444]\n",
      "epoch:28 step:22041 [D loss: 0.613429, acc: 67.19%] [G loss: 2.942878]\n",
      "epoch:28 step:22042 [D loss: 0.301664, acc: 85.16%] [G loss: 4.200650]\n",
      "epoch:28 step:22043 [D loss: 0.034673, acc: 100.00%] [G loss: 3.968744]\n",
      "epoch:28 step:22044 [D loss: 0.369177, acc: 80.47%] [G loss: 3.616176]\n",
      "epoch:28 step:22045 [D loss: 0.312605, acc: 95.31%] [G loss: 4.623406]\n",
      "epoch:28 step:22046 [D loss: 0.603879, acc: 74.22%] [G loss: 5.620382]\n",
      "epoch:28 step:22047 [D loss: 1.230488, acc: 47.66%] [G loss: 3.227440]\n",
      "epoch:28 step:22048 [D loss: 0.086839, acc: 100.00%] [G loss: 6.467358]\n",
      "epoch:28 step:22049 [D loss: 0.693516, acc: 54.69%] [G loss: 5.414423]\n",
      "epoch:28 step:22050 [D loss: 0.347996, acc: 79.69%] [G loss: 6.045249]\n",
      "epoch:28 step:22051 [D loss: 0.444485, acc: 83.59%] [G loss: 3.790293]\n",
      "epoch:28 step:22052 [D loss: 0.361828, acc: 89.84%] [G loss: 5.288680]\n",
      "epoch:28 step:22053 [D loss: 0.111322, acc: 100.00%] [G loss: 3.379205]\n",
      "epoch:28 step:22054 [D loss: 0.165888, acc: 100.00%] [G loss: 4.566091]\n",
      "epoch:28 step:22055 [D loss: 0.062375, acc: 100.00%] [G loss: 2.807514]\n",
      "epoch:28 step:22056 [D loss: 0.259213, acc: 95.31%] [G loss: 4.041349]\n",
      "epoch:28 step:22057 [D loss: 0.771773, acc: 53.91%] [G loss: 5.554032]\n",
      "epoch:28 step:22058 [D loss: 0.274409, acc: 87.50%] [G loss: 3.770813]\n",
      "epoch:28 step:22059 [D loss: 0.521103, acc: 65.62%] [G loss: 6.835195]\n",
      "epoch:28 step:22060 [D loss: 0.074039, acc: 100.00%] [G loss: 4.319289]\n",
      "epoch:28 step:22061 [D loss: 0.299622, acc: 88.28%] [G loss: 3.777631]\n",
      "epoch:28 step:22062 [D loss: 0.827308, acc: 42.19%] [G loss: 2.896395]\n",
      "epoch:28 step:22063 [D loss: 0.325452, acc: 89.84%] [G loss: 3.405715]\n",
      "epoch:28 step:22064 [D loss: 0.518444, acc: 64.84%] [G loss: 4.221117]\n",
      "epoch:28 step:22065 [D loss: 0.130827, acc: 100.00%] [G loss: 4.472565]\n",
      "epoch:28 step:22066 [D loss: 0.108696, acc: 100.00%] [G loss: 3.947126]\n",
      "epoch:28 step:22067 [D loss: 0.412962, acc: 83.59%] [G loss: 5.179651]\n",
      "epoch:28 step:22068 [D loss: 0.640674, acc: 58.59%] [G loss: 5.768376]\n",
      "epoch:28 step:22069 [D loss: 0.299669, acc: 88.28%] [G loss: 3.243561]\n",
      "epoch:28 step:22070 [D loss: 0.440290, acc: 72.66%] [G loss: 4.014764]\n",
      "epoch:28 step:22071 [D loss: 0.719328, acc: 55.47%] [G loss: 2.977692]\n",
      "epoch:28 step:22072 [D loss: 1.173231, acc: 48.44%] [G loss: 2.734470]\n",
      "epoch:28 step:22073 [D loss: 0.998772, acc: 46.09%] [G loss: 3.405567]\n",
      "epoch:28 step:22074 [D loss: 0.320890, acc: 86.72%] [G loss: 4.916368]\n",
      "epoch:28 step:22075 [D loss: 0.426743, acc: 85.94%] [G loss: 4.810676]\n",
      "epoch:28 step:22076 [D loss: 0.360534, acc: 79.69%] [G loss: 4.624295]\n",
      "epoch:28 step:22077 [D loss: 0.669013, acc: 54.69%] [G loss: 3.973145]\n",
      "epoch:28 step:22078 [D loss: 0.469060, acc: 65.62%] [G loss: 3.613872]\n",
      "epoch:28 step:22079 [D loss: 0.399105, acc: 78.91%] [G loss: 4.149985]\n",
      "epoch:28 step:22080 [D loss: 0.377970, acc: 89.84%] [G loss: 4.955795]\n",
      "epoch:28 step:22081 [D loss: 1.134516, acc: 25.78%] [G loss: 3.962794]\n",
      "epoch:28 step:22082 [D loss: 1.147720, acc: 17.19%] [G loss: 3.375780]\n",
      "epoch:28 step:22083 [D loss: 1.259995, acc: 49.22%] [G loss: 3.565913]\n",
      "epoch:28 step:22084 [D loss: 1.616913, acc: 46.88%] [G loss: 2.785708]\n",
      "epoch:28 step:22085 [D loss: 0.154971, acc: 99.22%] [G loss: 3.830892]\n",
      "epoch:28 step:22086 [D loss: 0.678416, acc: 60.16%] [G loss: 2.719357]\n",
      "epoch:28 step:22087 [D loss: 0.322509, acc: 92.97%] [G loss: 4.116752]\n",
      "epoch:28 step:22088 [D loss: 0.628670, acc: 57.81%] [G loss: 4.141317]\n",
      "epoch:28 step:22089 [D loss: 0.238333, acc: 96.09%] [G loss: 5.477149]\n",
      "epoch:28 step:22090 [D loss: 0.237777, acc: 95.31%] [G loss: 3.382289]\n",
      "epoch:28 step:22091 [D loss: 0.846302, acc: 53.91%] [G loss: 5.823866]\n",
      "epoch:28 step:22092 [D loss: 0.746534, acc: 57.03%] [G loss: 2.689164]\n",
      "epoch:28 step:22093 [D loss: 0.231370, acc: 98.44%] [G loss: 3.743207]\n",
      "epoch:28 step:22094 [D loss: 0.352158, acc: 93.75%] [G loss: 5.378814]\n",
      "epoch:28 step:22095 [D loss: 0.067971, acc: 100.00%] [G loss: 4.353098]\n",
      "epoch:28 step:22096 [D loss: 0.305497, acc: 93.75%] [G loss: 3.302554]\n",
      "epoch:28 step:22097 [D loss: 1.983547, acc: 4.69%] [G loss: 3.576993]\n",
      "epoch:28 step:22098 [D loss: 2.626276, acc: 0.00%] [G loss: 4.875633]\n",
      "epoch:28 step:22099 [D loss: 0.236816, acc: 93.75%] [G loss: 2.831285]\n",
      "epoch:28 step:22100 [D loss: 0.374663, acc: 86.72%] [G loss: 3.521139]\n",
      "epoch:28 step:22101 [D loss: 0.476923, acc: 85.94%] [G loss: 3.970430]\n",
      "epoch:28 step:22102 [D loss: 0.246461, acc: 96.09%] [G loss: 4.591069]\n",
      "epoch:28 step:22103 [D loss: 0.664142, acc: 58.59%] [G loss: 3.166348]\n",
      "epoch:28 step:22104 [D loss: 0.675859, acc: 59.38%] [G loss: 3.516575]\n",
      "epoch:28 step:22105 [D loss: 0.631117, acc: 58.59%] [G loss: 4.341896]\n",
      "epoch:28 step:22106 [D loss: 1.195607, acc: 50.00%] [G loss: 1.667336]\n",
      "epoch:28 step:22107 [D loss: 0.540952, acc: 70.31%] [G loss: 3.765189]\n",
      "epoch:28 step:22108 [D loss: 0.288134, acc: 91.41%] [G loss: 5.491913]\n",
      "epoch:28 step:22109 [D loss: 0.506672, acc: 73.44%] [G loss: 4.705220]\n",
      "epoch:28 step:22110 [D loss: 0.171656, acc: 98.44%] [G loss: 4.765656]\n",
      "epoch:28 step:22111 [D loss: 0.128875, acc: 100.00%] [G loss: 3.843190]\n",
      "epoch:28 step:22112 [D loss: 0.436641, acc: 75.78%] [G loss: 5.415235]\n",
      "epoch:28 step:22113 [D loss: 0.636848, acc: 64.06%] [G loss: 4.287818]\n",
      "epoch:28 step:22114 [D loss: 0.475672, acc: 77.34%] [G loss: 3.870696]\n",
      "epoch:28 step:22115 [D loss: 1.170706, acc: 50.00%] [G loss: 3.547672]\n",
      "epoch:28 step:22116 [D loss: 0.602252, acc: 67.97%] [G loss: 3.947974]\n",
      "epoch:28 step:22117 [D loss: 0.638030, acc: 60.94%] [G loss: 3.606317]\n",
      "epoch:28 step:22118 [D loss: 0.086116, acc: 100.00%] [G loss: 4.187643]\n",
      "epoch:28 step:22119 [D loss: 0.325259, acc: 82.81%] [G loss: 5.007662]\n",
      "epoch:28 step:22120 [D loss: 0.330462, acc: 92.19%] [G loss: 4.877950]\n",
      "epoch:28 step:22121 [D loss: 1.343110, acc: 50.00%] [G loss: 4.882632]\n",
      "epoch:28 step:22122 [D loss: 1.572056, acc: 9.38%] [G loss: 2.281470]\n",
      "epoch:28 step:22123 [D loss: 0.208278, acc: 96.88%] [G loss: 2.998518]\n",
      "epoch:28 step:22124 [D loss: 0.328078, acc: 95.31%] [G loss: 3.736831]\n",
      "epoch:28 step:22125 [D loss: 0.519777, acc: 77.34%] [G loss: 3.076544]\n",
      "epoch:28 step:22126 [D loss: 0.243974, acc: 97.66%] [G loss: 3.613680]\n",
      "epoch:28 step:22127 [D loss: 0.599204, acc: 60.94%] [G loss: 4.540821]\n",
      "epoch:28 step:22128 [D loss: 0.927730, acc: 49.22%] [G loss: 4.476860]\n",
      "epoch:28 step:22129 [D loss: 0.393340, acc: 91.41%] [G loss: 3.257787]\n",
      "epoch:28 step:22130 [D loss: 0.257283, acc: 92.19%] [G loss: 5.019007]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:28 step:22131 [D loss: 0.412659, acc: 76.56%] [G loss: 3.782141]\n",
      "epoch:28 step:22132 [D loss: 0.288754, acc: 94.53%] [G loss: 5.159415]\n",
      "epoch:28 step:22133 [D loss: 0.447569, acc: 82.81%] [G loss: 2.601372]\n",
      "epoch:28 step:22134 [D loss: 0.381080, acc: 84.38%] [G loss: 3.517961]\n",
      "epoch:28 step:22135 [D loss: 0.857506, acc: 45.31%] [G loss: 4.307805]\n",
      "epoch:28 step:22136 [D loss: 0.262428, acc: 94.53%] [G loss: 3.687852]\n",
      "epoch:28 step:22137 [D loss: 0.696410, acc: 53.91%] [G loss: 4.346983]\n",
      "epoch:28 step:22138 [D loss: 0.225152, acc: 100.00%] [G loss: 3.180637]\n",
      "epoch:28 step:22139 [D loss: 0.184056, acc: 96.88%] [G loss: 3.200888]\n",
      "epoch:28 step:22140 [D loss: 0.587921, acc: 69.53%] [G loss: 3.556109]\n",
      "epoch:28 step:22141 [D loss: 0.264402, acc: 97.66%] [G loss: 3.862828]\n",
      "epoch:28 step:22142 [D loss: 0.475900, acc: 73.44%] [G loss: 4.329198]\n",
      "epoch:28 step:22143 [D loss: 0.210003, acc: 98.44%] [G loss: 3.298975]\n",
      "epoch:28 step:22144 [D loss: 0.252689, acc: 98.44%] [G loss: 2.385232]\n",
      "epoch:28 step:22145 [D loss: 0.782720, acc: 54.69%] [G loss: 3.244954]\n",
      "epoch:28 step:22146 [D loss: 0.879227, acc: 51.56%] [G loss: 4.759358]\n",
      "epoch:28 step:22147 [D loss: 0.336259, acc: 88.28%] [G loss: 2.857043]\n",
      "epoch:28 step:22148 [D loss: 0.558206, acc: 60.16%] [G loss: 4.424664]\n",
      "epoch:28 step:22149 [D loss: 0.865094, acc: 48.44%] [G loss: 3.456285]\n",
      "epoch:28 step:22150 [D loss: 0.176628, acc: 97.66%] [G loss: 5.045702]\n",
      "epoch:28 step:22151 [D loss: 0.140234, acc: 100.00%] [G loss: 4.168614]\n",
      "epoch:28 step:22152 [D loss: 0.470800, acc: 82.81%] [G loss: 3.738375]\n",
      "epoch:28 step:22153 [D loss: 0.333493, acc: 91.41%] [G loss: 3.646636]\n",
      "epoch:28 step:22154 [D loss: 0.875216, acc: 46.09%] [G loss: 3.805978]\n",
      "epoch:28 step:22155 [D loss: 0.419959, acc: 82.81%] [G loss: 3.327303]\n",
      "epoch:28 step:22156 [D loss: 1.071678, acc: 26.56%] [G loss: 1.829078]\n",
      "epoch:28 step:22157 [D loss: 0.677343, acc: 53.12%] [G loss: 4.801721]\n",
      "epoch:28 step:22158 [D loss: 0.684240, acc: 60.94%] [G loss: 3.987126]\n",
      "epoch:28 step:22159 [D loss: 0.321180, acc: 95.31%] [G loss: 2.913451]\n",
      "epoch:28 step:22160 [D loss: 0.040817, acc: 100.00%] [G loss: 5.407375]\n",
      "epoch:28 step:22161 [D loss: 0.296561, acc: 96.09%] [G loss: 3.205439]\n",
      "epoch:28 step:22162 [D loss: 0.146884, acc: 97.66%] [G loss: 4.107821]\n",
      "epoch:28 step:22163 [D loss: 0.235968, acc: 96.09%] [G loss: 4.246275]\n",
      "epoch:28 step:22164 [D loss: 0.301009, acc: 87.50%] [G loss: 7.549797]\n",
      "epoch:28 step:22165 [D loss: 0.095982, acc: 100.00%] [G loss: 3.898787]\n",
      "epoch:28 step:22166 [D loss: 0.611721, acc: 59.38%] [G loss: 4.565454]\n",
      "epoch:28 step:22167 [D loss: 0.233913, acc: 95.31%] [G loss: 3.250063]\n",
      "epoch:28 step:22168 [D loss: 0.290079, acc: 89.06%] [G loss: 3.892179]\n",
      "epoch:28 step:22169 [D loss: 0.577227, acc: 70.31%] [G loss: 3.775632]\n",
      "epoch:28 step:22170 [D loss: 0.469149, acc: 82.81%] [G loss: 3.254379]\n",
      "epoch:28 step:22171 [D loss: 0.617196, acc: 63.28%] [G loss: 3.333208]\n",
      "epoch:28 step:22172 [D loss: 0.300397, acc: 94.53%] [G loss: 3.387838]\n",
      "epoch:28 step:22173 [D loss: 0.324378, acc: 94.53%] [G loss: 4.004737]\n",
      "epoch:28 step:22174 [D loss: 0.348298, acc: 87.50%] [G loss: 5.375144]\n",
      "epoch:28 step:22175 [D loss: 0.842983, acc: 43.75%] [G loss: 4.074852]\n",
      "epoch:28 step:22176 [D loss: 0.677647, acc: 53.91%] [G loss: 1.939916]\n",
      "epoch:28 step:22177 [D loss: 0.651770, acc: 60.94%] [G loss: 4.090660]\n",
      "epoch:28 step:22178 [D loss: 0.509432, acc: 80.47%] [G loss: 4.360024]\n",
      "epoch:28 step:22179 [D loss: 0.297926, acc: 96.09%] [G loss: 3.425571]\n",
      "epoch:28 step:22180 [D loss: 0.472526, acc: 82.03%] [G loss: 3.996968]\n",
      "epoch:28 step:22181 [D loss: 0.508720, acc: 75.00%] [G loss: 3.256441]\n",
      "epoch:28 step:22182 [D loss: 0.249195, acc: 95.31%] [G loss: 4.427953]\n",
      "epoch:28 step:22183 [D loss: 0.655113, acc: 64.84%] [G loss: 3.069719]\n",
      "epoch:28 step:22184 [D loss: 0.323056, acc: 92.19%] [G loss: 4.863453]\n",
      "epoch:28 step:22185 [D loss: 0.449955, acc: 80.47%] [G loss: 5.427691]\n",
      "epoch:28 step:22186 [D loss: 0.215275, acc: 99.22%] [G loss: 3.154533]\n",
      "epoch:28 step:22187 [D loss: 0.126173, acc: 100.00%] [G loss: 3.048520]\n",
      "epoch:28 step:22188 [D loss: 0.333327, acc: 92.97%] [G loss: 2.986005]\n",
      "epoch:28 step:22189 [D loss: 0.260166, acc: 95.31%] [G loss: 5.015682]\n",
      "epoch:28 step:22190 [D loss: 0.314339, acc: 96.88%] [G loss: 3.944172]\n",
      "epoch:28 step:22191 [D loss: 0.535052, acc: 75.00%] [G loss: 4.135157]\n",
      "epoch:28 step:22192 [D loss: 0.741923, acc: 57.03%] [G loss: 4.351449]\n",
      "epoch:28 step:22193 [D loss: 0.341298, acc: 90.62%] [G loss: 3.515751]\n",
      "epoch:28 step:22194 [D loss: 0.256324, acc: 96.09%] [G loss: 2.597807]\n",
      "epoch:28 step:22195 [D loss: 0.335137, acc: 93.75%] [G loss: 4.022986]\n",
      "epoch:28 step:22196 [D loss: 1.274638, acc: 34.38%] [G loss: 5.182971]\n",
      "epoch:28 step:22197 [D loss: 0.207124, acc: 96.09%] [G loss: 5.615914]\n",
      "epoch:28 step:22198 [D loss: 0.329707, acc: 85.16%] [G loss: 3.231456]\n",
      "epoch:28 step:22199 [D loss: 0.166826, acc: 98.44%] [G loss: 4.780009]\n",
      "epoch:28 step:22200 [D loss: 0.708954, acc: 55.47%] [G loss: 5.461450]\n",
      "##############\n",
      "[0.85800485 0.86769577 0.81085702 0.8046154  0.77465716 0.81835533\n",
      " 0.88097619 0.83387024 0.80632968 0.81977832]\n",
      "##########\n",
      "epoch:28 step:22201 [D loss: 0.207229, acc: 96.88%] [G loss: 6.501396]\n",
      "epoch:28 step:22202 [D loss: 0.642412, acc: 58.59%] [G loss: 5.569758]\n",
      "epoch:28 step:22203 [D loss: 0.078304, acc: 100.00%] [G loss: 5.810702]\n",
      "epoch:28 step:22204 [D loss: 0.314723, acc: 91.41%] [G loss: 5.801073]\n",
      "epoch:28 step:22205 [D loss: 0.326729, acc: 92.97%] [G loss: 3.465493]\n",
      "epoch:28 step:22206 [D loss: 0.367179, acc: 91.41%] [G loss: 2.921775]\n",
      "epoch:28 step:22207 [D loss: 0.096565, acc: 100.00%] [G loss: 3.971914]\n",
      "epoch:28 step:22208 [D loss: 0.814335, acc: 41.41%] [G loss: 5.811364]\n",
      "epoch:28 step:22209 [D loss: 0.218728, acc: 98.44%] [G loss: 4.749480]\n",
      "epoch:28 step:22210 [D loss: 0.888510, acc: 36.72%] [G loss: 4.408738]\n",
      "epoch:28 step:22211 [D loss: 0.331427, acc: 92.97%] [G loss: 3.764464]\n",
      "epoch:28 step:22212 [D loss: 0.444375, acc: 84.38%] [G loss: 3.428270]\n",
      "epoch:28 step:22213 [D loss: 0.452404, acc: 78.12%] [G loss: 3.151940]\n",
      "epoch:28 step:22214 [D loss: 0.126679, acc: 100.00%] [G loss: 2.765308]\n",
      "epoch:28 step:22215 [D loss: 0.569219, acc: 75.00%] [G loss: 4.329615]\n",
      "epoch:28 step:22216 [D loss: 0.290498, acc: 94.53%] [G loss: 2.942489]\n",
      "epoch:28 step:22217 [D loss: 0.338527, acc: 90.62%] [G loss: 3.389519]\n",
      "epoch:28 step:22218 [D loss: 0.279732, acc: 93.75%] [G loss: 2.575963]\n",
      "epoch:28 step:22219 [D loss: 0.708694, acc: 55.47%] [G loss: 2.468441]\n",
      "epoch:28 step:22220 [D loss: 0.192565, acc: 97.66%] [G loss: 2.856098]\n",
      "epoch:28 step:22221 [D loss: 0.548228, acc: 70.31%] [G loss: 2.481427]\n",
      "epoch:28 step:22222 [D loss: 0.222519, acc: 99.22%] [G loss: 5.442312]\n",
      "epoch:28 step:22223 [D loss: 0.435929, acc: 73.44%] [G loss: 3.995287]\n",
      "epoch:28 step:22224 [D loss: 0.268406, acc: 96.88%] [G loss: 4.666793]\n",
      "epoch:28 step:22225 [D loss: 0.653809, acc: 54.69%] [G loss: 4.908719]\n",
      "epoch:28 step:22226 [D loss: 0.258370, acc: 96.09%] [G loss: 3.742389]\n",
      "epoch:28 step:22227 [D loss: 0.092118, acc: 100.00%] [G loss: 4.337840]\n",
      "epoch:28 step:22228 [D loss: 0.380555, acc: 92.97%] [G loss: 5.088427]\n",
      "epoch:28 step:22229 [D loss: 0.763940, acc: 50.78%] [G loss: 2.822882]\n",
      "epoch:28 step:22230 [D loss: 0.422665, acc: 87.50%] [G loss: 3.589583]\n",
      "epoch:28 step:22231 [D loss: 0.503570, acc: 62.50%] [G loss: 4.250863]\n",
      "epoch:28 step:22232 [D loss: 0.195905, acc: 97.66%] [G loss: 4.100808]\n",
      "epoch:28 step:22233 [D loss: 0.229001, acc: 96.88%] [G loss: 4.409945]\n",
      "epoch:28 step:22234 [D loss: 0.139858, acc: 100.00%] [G loss: 3.333054]\n",
      "epoch:28 step:22235 [D loss: 0.408638, acc: 89.84%] [G loss: 4.616834]\n",
      "epoch:28 step:22236 [D loss: 0.136152, acc: 98.44%] [G loss: 3.100472]\n",
      "epoch:28 step:22237 [D loss: 0.365109, acc: 92.19%] [G loss: 3.265339]\n",
      "epoch:28 step:22238 [D loss: 0.745546, acc: 53.91%] [G loss: 4.530038]\n",
      "epoch:28 step:22239 [D loss: 0.217061, acc: 96.88%] [G loss: 2.881617]\n",
      "epoch:28 step:22240 [D loss: 0.416771, acc: 75.78%] [G loss: 4.754353]\n",
      "epoch:28 step:22241 [D loss: 0.863160, acc: 50.00%] [G loss: 3.147932]\n",
      "epoch:28 step:22242 [D loss: 0.467429, acc: 78.91%] [G loss: 2.830388]\n",
      "epoch:28 step:22243 [D loss: 0.178989, acc: 98.44%] [G loss: 3.276353]\n",
      "epoch:28 step:22244 [D loss: 0.380680, acc: 88.28%] [G loss: 3.882173]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:28 step:22245 [D loss: 0.370495, acc: 87.50%] [G loss: 3.546500]\n",
      "epoch:28 step:22246 [D loss: 0.286530, acc: 89.06%] [G loss: 4.071072]\n",
      "epoch:28 step:22247 [D loss: 0.946099, acc: 50.00%] [G loss: 3.815313]\n",
      "epoch:28 step:22248 [D loss: 0.190602, acc: 98.44%] [G loss: 3.190032]\n",
      "epoch:28 step:22249 [D loss: 0.195675, acc: 96.09%] [G loss: 3.450181]\n",
      "epoch:28 step:22250 [D loss: 0.425660, acc: 83.59%] [G loss: 4.187955]\n",
      "epoch:28 step:22251 [D loss: 0.213339, acc: 96.88%] [G loss: 3.081490]\n",
      "epoch:28 step:22252 [D loss: 0.242140, acc: 96.88%] [G loss: 2.643678]\n",
      "epoch:28 step:22253 [D loss: 0.205070, acc: 100.00%] [G loss: 3.870930]\n",
      "epoch:28 step:22254 [D loss: 0.945191, acc: 40.62%] [G loss: 5.707392]\n",
      "epoch:28 step:22255 [D loss: 0.925927, acc: 32.81%] [G loss: 1.858995]\n",
      "epoch:28 step:22256 [D loss: 0.422134, acc: 78.91%] [G loss: 5.523099]\n",
      "epoch:28 step:22257 [D loss: 0.330018, acc: 94.53%] [G loss: 4.313221]\n",
      "epoch:28 step:22258 [D loss: 0.199446, acc: 97.66%] [G loss: 5.022784]\n",
      "epoch:28 step:22259 [D loss: 0.658308, acc: 60.16%] [G loss: 3.447921]\n",
      "epoch:28 step:22260 [D loss: 0.405783, acc: 78.12%] [G loss: 3.427852]\n",
      "epoch:28 step:22261 [D loss: 0.234592, acc: 96.09%] [G loss: 2.977326]\n",
      "epoch:28 step:22262 [D loss: 0.233787, acc: 96.09%] [G loss: 6.131214]\n",
      "epoch:28 step:22263 [D loss: 0.687393, acc: 56.25%] [G loss: 3.195140]\n",
      "epoch:28 step:22264 [D loss: 0.734617, acc: 55.47%] [G loss: 5.774474]\n",
      "epoch:28 step:22265 [D loss: 0.401513, acc: 80.47%] [G loss: 3.667153]\n",
      "epoch:28 step:22266 [D loss: 0.355742, acc: 82.81%] [G loss: 4.262209]\n",
      "epoch:28 step:22267 [D loss: 0.269608, acc: 91.41%] [G loss: 3.825729]\n",
      "epoch:28 step:22268 [D loss: 0.168558, acc: 100.00%] [G loss: 4.414655]\n",
      "epoch:28 step:22269 [D loss: 0.060801, acc: 100.00%] [G loss: 5.672448]\n",
      "epoch:28 step:22270 [D loss: 0.131518, acc: 99.22%] [G loss: 3.600507]\n",
      "epoch:28 step:22271 [D loss: 0.555890, acc: 67.97%] [G loss: 2.758632]\n",
      "epoch:28 step:22272 [D loss: 0.311938, acc: 91.41%] [G loss: 4.065361]\n",
      "epoch:28 step:22273 [D loss: 0.099675, acc: 100.00%] [G loss: 4.439203]\n",
      "epoch:28 step:22274 [D loss: 0.145762, acc: 99.22%] [G loss: 4.993129]\n",
      "epoch:28 step:22275 [D loss: 0.153032, acc: 98.44%] [G loss: 6.511317]\n",
      "epoch:28 step:22276 [D loss: 0.160874, acc: 97.66%] [G loss: 3.416630]\n",
      "epoch:28 step:22277 [D loss: 0.315236, acc: 96.88%] [G loss: 4.910820]\n",
      "epoch:28 step:22278 [D loss: 0.291691, acc: 96.09%] [G loss: 4.068439]\n",
      "epoch:28 step:22279 [D loss: 0.217627, acc: 98.44%] [G loss: 4.436460]\n",
      "epoch:28 step:22280 [D loss: 0.227291, acc: 97.66%] [G loss: 3.944747]\n",
      "epoch:28 step:22281 [D loss: 0.032532, acc: 100.00%] [G loss: 8.909450]\n",
      "epoch:28 step:22282 [D loss: 0.163264, acc: 99.22%] [G loss: 3.187616]\n",
      "epoch:28 step:22283 [D loss: 0.279591, acc: 97.66%] [G loss: 3.080159]\n",
      "epoch:28 step:22284 [D loss: 0.222322, acc: 98.44%] [G loss: 3.000145]\n",
      "epoch:28 step:22285 [D loss: 0.199352, acc: 96.88%] [G loss: 4.142792]\n",
      "epoch:28 step:22286 [D loss: 0.482855, acc: 67.19%] [G loss: 3.461177]\n",
      "epoch:28 step:22287 [D loss: 0.280725, acc: 97.66%] [G loss: 4.065405]\n",
      "epoch:28 step:22288 [D loss: 0.706563, acc: 56.25%] [G loss: 4.268126]\n",
      "epoch:28 step:22289 [D loss: 0.315580, acc: 94.53%] [G loss: 5.596436]\n",
      "epoch:28 step:22290 [D loss: 0.585336, acc: 57.03%] [G loss: 6.805240]\n",
      "epoch:28 step:22291 [D loss: 0.820361, acc: 48.44%] [G loss: 4.203530]\n",
      "epoch:28 step:22292 [D loss: 0.838236, acc: 46.09%] [G loss: 3.659944]\n",
      "epoch:28 step:22293 [D loss: 0.509311, acc: 65.62%] [G loss: 3.543808]\n",
      "epoch:28 step:22294 [D loss: 0.430384, acc: 87.50%] [G loss: 3.845269]\n",
      "epoch:28 step:22295 [D loss: 0.619444, acc: 64.84%] [G loss: 3.942559]\n",
      "epoch:28 step:22296 [D loss: 0.521179, acc: 82.03%] [G loss: 2.748928]\n",
      "epoch:28 step:22297 [D loss: 0.347781, acc: 79.69%] [G loss: 4.195931]\n",
      "epoch:28 step:22298 [D loss: 0.109642, acc: 98.44%] [G loss: 4.801066]\n",
      "epoch:28 step:22299 [D loss: 0.599951, acc: 74.22%] [G loss: 3.809251]\n",
      "epoch:28 step:22300 [D loss: 0.681242, acc: 54.69%] [G loss: 4.205877]\n",
      "epoch:28 step:22301 [D loss: 0.169455, acc: 99.22%] [G loss: 4.026597]\n",
      "epoch:28 step:22302 [D loss: 0.272657, acc: 90.62%] [G loss: 5.176181]\n",
      "epoch:28 step:22303 [D loss: 0.417588, acc: 77.34%] [G loss: 4.488176]\n",
      "epoch:28 step:22304 [D loss: 0.582581, acc: 55.47%] [G loss: 5.101237]\n",
      "epoch:28 step:22305 [D loss: 0.298191, acc: 96.88%] [G loss: 3.426807]\n",
      "epoch:28 step:22306 [D loss: 0.235373, acc: 96.09%] [G loss: 4.010228]\n",
      "epoch:28 step:22307 [D loss: 0.351645, acc: 82.03%] [G loss: 3.462349]\n",
      "epoch:28 step:22308 [D loss: 0.234461, acc: 97.66%] [G loss: 2.197167]\n",
      "epoch:28 step:22309 [D loss: 0.422269, acc: 74.22%] [G loss: 2.573376]\n",
      "epoch:28 step:22310 [D loss: 0.179287, acc: 98.44%] [G loss: 5.176376]\n",
      "epoch:28 step:22311 [D loss: 0.313412, acc: 93.75%] [G loss: 4.063707]\n",
      "epoch:28 step:22312 [D loss: 0.370638, acc: 86.72%] [G loss: 2.941716]\n",
      "epoch:28 step:22313 [D loss: 1.042045, acc: 44.53%] [G loss: 3.232049]\n",
      "epoch:28 step:22314 [D loss: 0.467406, acc: 81.25%] [G loss: 3.371360]\n",
      "epoch:28 step:22315 [D loss: 0.133693, acc: 97.66%] [G loss: 5.368743]\n",
      "epoch:28 step:22316 [D loss: 0.329863, acc: 92.97%] [G loss: 5.432735]\n",
      "epoch:28 step:22317 [D loss: 1.046988, acc: 49.22%] [G loss: 4.179146]\n",
      "epoch:28 step:22318 [D loss: 0.465243, acc: 80.47%] [G loss: 2.590718]\n",
      "epoch:28 step:22319 [D loss: 0.187744, acc: 97.66%] [G loss: 4.880950]\n",
      "epoch:28 step:22320 [D loss: 0.286349, acc: 92.19%] [G loss: 4.061632]\n",
      "epoch:28 step:22321 [D loss: 0.277168, acc: 96.09%] [G loss: 2.817538]\n",
      "epoch:28 step:22322 [D loss: 0.211480, acc: 97.66%] [G loss: 3.176723]\n",
      "epoch:28 step:22323 [D loss: 0.146665, acc: 98.44%] [G loss: 5.515244]\n",
      "epoch:28 step:22324 [D loss: 0.128057, acc: 98.44%] [G loss: 7.063707]\n",
      "epoch:28 step:22325 [D loss: 0.544144, acc: 65.62%] [G loss: 5.452622]\n",
      "epoch:28 step:22326 [D loss: 0.338347, acc: 85.16%] [G loss: 5.413165]\n",
      "epoch:28 step:22327 [D loss: 0.257179, acc: 89.06%] [G loss: 4.523137]\n",
      "epoch:28 step:22328 [D loss: 0.683881, acc: 57.03%] [G loss: 3.889301]\n",
      "epoch:28 step:22329 [D loss: 0.050459, acc: 100.00%] [G loss: 5.890402]\n",
      "epoch:28 step:22330 [D loss: 0.739976, acc: 54.69%] [G loss: 2.284272]\n",
      "epoch:28 step:22331 [D loss: 0.928710, acc: 48.44%] [G loss: 7.380150]\n",
      "epoch:28 step:22332 [D loss: 0.792251, acc: 50.78%] [G loss: 5.951205]\n",
      "epoch:28 step:22333 [D loss: 1.250679, acc: 49.22%] [G loss: 4.223436]\n",
      "epoch:28 step:22334 [D loss: 0.215587, acc: 93.75%] [G loss: 6.077312]\n",
      "epoch:28 step:22335 [D loss: 0.626988, acc: 60.94%] [G loss: 4.657665]\n",
      "epoch:28 step:22336 [D loss: 0.332978, acc: 81.25%] [G loss: 3.984024]\n",
      "epoch:28 step:22337 [D loss: 0.853422, acc: 51.56%] [G loss: 5.739818]\n",
      "epoch:28 step:22338 [D loss: 0.222603, acc: 96.88%] [G loss: 4.616876]\n",
      "epoch:28 step:22339 [D loss: 0.545383, acc: 69.53%] [G loss: 3.383363]\n",
      "epoch:28 step:22340 [D loss: 0.137723, acc: 100.00%] [G loss: 4.760685]\n",
      "epoch:28 step:22341 [D loss: 0.758394, acc: 53.91%] [G loss: 3.103110]\n",
      "epoch:28 step:22342 [D loss: 0.788785, acc: 47.66%] [G loss: 7.151689]\n",
      "epoch:28 step:22343 [D loss: 0.286928, acc: 95.31%] [G loss: 3.522567]\n",
      "epoch:28 step:22344 [D loss: 0.649951, acc: 59.38%] [G loss: 3.522245]\n",
      "epoch:28 step:22345 [D loss: 0.552650, acc: 68.75%] [G loss: 1.821347]\n",
      "epoch:28 step:22346 [D loss: 0.296810, acc: 97.66%] [G loss: 4.103562]\n",
      "epoch:28 step:22347 [D loss: 1.047411, acc: 28.91%] [G loss: 4.164643]\n",
      "epoch:28 step:22348 [D loss: 0.983202, acc: 32.03%] [G loss: 3.454894]\n",
      "epoch:28 step:22349 [D loss: 0.705361, acc: 55.47%] [G loss: 2.891018]\n",
      "epoch:28 step:22350 [D loss: 0.516856, acc: 67.19%] [G loss: 4.052209]\n",
      "epoch:28 step:22351 [D loss: 0.419841, acc: 72.66%] [G loss: 3.668188]\n",
      "epoch:28 step:22352 [D loss: 1.297298, acc: 34.38%] [G loss: 3.900384]\n",
      "epoch:28 step:22353 [D loss: 0.704911, acc: 59.38%] [G loss: 3.121632]\n",
      "epoch:28 step:22354 [D loss: 0.756355, acc: 45.31%] [G loss: 4.783764]\n",
      "epoch:28 step:22355 [D loss: 0.323479, acc: 92.97%] [G loss: 5.714821]\n",
      "epoch:28 step:22356 [D loss: 0.356742, acc: 88.28%] [G loss: 4.393197]\n",
      "epoch:28 step:22357 [D loss: 0.435454, acc: 78.12%] [G loss: 3.915849]\n",
      "epoch:28 step:22358 [D loss: 0.165984, acc: 99.22%] [G loss: 5.408966]\n",
      "epoch:28 step:22359 [D loss: 0.587656, acc: 70.31%] [G loss: 3.547653]\n",
      "epoch:28 step:22360 [D loss: 0.391794, acc: 82.81%] [G loss: 3.460177]\n",
      "epoch:28 step:22361 [D loss: 0.406108, acc: 88.28%] [G loss: 4.404928]\n",
      "epoch:28 step:22362 [D loss: 0.354552, acc: 96.09%] [G loss: 3.590946]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:28 step:22363 [D loss: 0.280521, acc: 96.09%] [G loss: 4.416773]\n",
      "epoch:28 step:22364 [D loss: 0.472002, acc: 78.91%] [G loss: 3.332560]\n",
      "epoch:28 step:22365 [D loss: 0.413920, acc: 78.12%] [G loss: 5.286391]\n",
      "epoch:28 step:22366 [D loss: 0.324793, acc: 91.41%] [G loss: 5.653532]\n",
      "epoch:28 step:22367 [D loss: 0.235618, acc: 93.75%] [G loss: 6.014502]\n",
      "epoch:28 step:22368 [D loss: 0.348391, acc: 85.16%] [G loss: 3.312493]\n",
      "epoch:28 step:22369 [D loss: 0.454194, acc: 68.75%] [G loss: 3.251474]\n",
      "epoch:28 step:22370 [D loss: 0.212657, acc: 97.66%] [G loss: 1.991838]\n",
      "epoch:28 step:22371 [D loss: 1.075231, acc: 31.25%] [G loss: 4.682350]\n",
      "epoch:28 step:22372 [D loss: 0.458865, acc: 79.69%] [G loss: 4.675207]\n",
      "epoch:28 step:22373 [D loss: 0.551512, acc: 77.34%] [G loss: 2.816437]\n",
      "epoch:28 step:22374 [D loss: 0.499292, acc: 78.91%] [G loss: 3.257751]\n",
      "epoch:28 step:22375 [D loss: 0.185933, acc: 99.22%] [G loss: 2.317466]\n",
      "epoch:28 step:22376 [D loss: 0.275214, acc: 94.53%] [G loss: 3.280057]\n",
      "epoch:28 step:22377 [D loss: 0.203212, acc: 100.00%] [G loss: 4.138040]\n",
      "epoch:28 step:22378 [D loss: 0.109873, acc: 100.00%] [G loss: 4.126495]\n",
      "epoch:28 step:22379 [D loss: 0.034800, acc: 100.00%] [G loss: 8.153627]\n",
      "epoch:28 step:22380 [D loss: 0.649564, acc: 64.06%] [G loss: 4.565554]\n",
      "epoch:28 step:22381 [D loss: 0.523588, acc: 71.88%] [G loss: 3.414218]\n",
      "epoch:28 step:22382 [D loss: 0.374912, acc: 81.25%] [G loss: 5.497536]\n",
      "epoch:28 step:22383 [D loss: 0.588736, acc: 63.28%] [G loss: 4.280766]\n",
      "epoch:28 step:22384 [D loss: 0.194618, acc: 96.88%] [G loss: 6.861871]\n",
      "epoch:28 step:22385 [D loss: 0.064006, acc: 100.00%] [G loss: 7.404887]\n",
      "epoch:28 step:22386 [D loss: 0.594038, acc: 68.75%] [G loss: 4.086860]\n",
      "epoch:28 step:22387 [D loss: 0.479987, acc: 78.12%] [G loss: 2.719518]\n",
      "epoch:28 step:22388 [D loss: 0.697318, acc: 55.47%] [G loss: 2.802318]\n",
      "epoch:28 step:22389 [D loss: 1.268406, acc: 50.00%] [G loss: 3.403692]\n",
      "epoch:28 step:22390 [D loss: 0.566128, acc: 69.53%] [G loss: 4.046997]\n",
      "epoch:28 step:22391 [D loss: 0.128822, acc: 100.00%] [G loss: 4.191274]\n",
      "epoch:28 step:22392 [D loss: 0.657993, acc: 64.84%] [G loss: 3.653833]\n",
      "epoch:28 step:22393 [D loss: 0.236546, acc: 96.88%] [G loss: 3.749654]\n",
      "epoch:28 step:22394 [D loss: 0.493138, acc: 81.25%] [G loss: 3.234244]\n",
      "epoch:28 step:22395 [D loss: 0.201222, acc: 96.88%] [G loss: 4.322199]\n",
      "epoch:28 step:22396 [D loss: 0.065224, acc: 100.00%] [G loss: 3.825611]\n",
      "epoch:28 step:22397 [D loss: 0.364219, acc: 92.97%] [G loss: 4.633312]\n",
      "epoch:28 step:22398 [D loss: 0.242623, acc: 96.09%] [G loss: 5.365180]\n",
      "epoch:28 step:22399 [D loss: 0.078282, acc: 98.44%] [G loss: 4.015884]\n",
      "epoch:28 step:22400 [D loss: 0.408161, acc: 80.47%] [G loss: 4.733839]\n",
      "##############\n",
      "[0.85791104 0.873623   0.81163819 0.81486312 0.78913926 0.84034613\n",
      " 0.88093502 0.84726693 0.83587046 0.83029933]\n",
      "##########\n",
      "epoch:28 step:22401 [D loss: 0.922782, acc: 51.56%] [G loss: 3.479345]\n",
      "epoch:28 step:22402 [D loss: 0.733868, acc: 50.00%] [G loss: 2.636020]\n",
      "epoch:28 step:22403 [D loss: 0.452046, acc: 78.91%] [G loss: 2.649082]\n",
      "epoch:28 step:22404 [D loss: 0.235631, acc: 98.44%] [G loss: 2.908546]\n",
      "epoch:28 step:22405 [D loss: 0.615476, acc: 60.16%] [G loss: 3.169275]\n",
      "epoch:28 step:22406 [D loss: 0.423712, acc: 74.22%] [G loss: 4.407475]\n",
      "epoch:28 step:22407 [D loss: 1.132794, acc: 45.31%] [G loss: 2.962709]\n",
      "epoch:28 step:22408 [D loss: 0.098647, acc: 100.00%] [G loss: 3.578535]\n",
      "epoch:28 step:22409 [D loss: 0.441080, acc: 85.16%] [G loss: 5.278020]\n",
      "epoch:28 step:22410 [D loss: 0.295408, acc: 84.38%] [G loss: 6.879444]\n",
      "epoch:28 step:22411 [D loss: 0.490484, acc: 70.31%] [G loss: 4.418204]\n",
      "epoch:28 step:22412 [D loss: 0.741831, acc: 55.47%] [G loss: 3.428324]\n",
      "epoch:28 step:22413 [D loss: 0.267745, acc: 96.09%] [G loss: 2.809430]\n",
      "epoch:28 step:22414 [D loss: 0.226263, acc: 96.09%] [G loss: 3.736456]\n",
      "epoch:28 step:22415 [D loss: 0.160681, acc: 99.22%] [G loss: 4.818528]\n",
      "epoch:28 step:22416 [D loss: 0.207731, acc: 98.44%] [G loss: 5.491695]\n",
      "epoch:28 step:22417 [D loss: 0.305698, acc: 96.88%] [G loss: 3.083765]\n",
      "epoch:28 step:22418 [D loss: 0.171571, acc: 96.09%] [G loss: 3.975119]\n",
      "epoch:28 step:22419 [D loss: 0.502331, acc: 71.88%] [G loss: 2.976605]\n",
      "epoch:28 step:22420 [D loss: 0.499716, acc: 72.66%] [G loss: 3.717550]\n",
      "epoch:28 step:22421 [D loss: 0.272774, acc: 91.41%] [G loss: 3.064557]\n",
      "epoch:28 step:22422 [D loss: 0.731817, acc: 50.78%] [G loss: 3.716281]\n",
      "epoch:28 step:22423 [D loss: 0.165733, acc: 97.66%] [G loss: 5.457940]\n",
      "epoch:28 step:22424 [D loss: 0.605735, acc: 55.47%] [G loss: 3.373783]\n",
      "epoch:28 step:22425 [D loss: 0.711941, acc: 58.59%] [G loss: 3.595628]\n",
      "epoch:28 step:22426 [D loss: 0.290349, acc: 92.97%] [G loss: 3.263583]\n",
      "epoch:28 step:22427 [D loss: 0.135178, acc: 99.22%] [G loss: 2.648593]\n",
      "epoch:28 step:22428 [D loss: 0.618527, acc: 57.03%] [G loss: 5.072787]\n",
      "epoch:28 step:22429 [D loss: 0.779142, acc: 53.91%] [G loss: 3.884840]\n",
      "epoch:28 step:22430 [D loss: 0.578356, acc: 72.66%] [G loss: 4.499254]\n",
      "epoch:28 step:22431 [D loss: 0.245291, acc: 90.62%] [G loss: 5.504696]\n",
      "epoch:28 step:22432 [D loss: 0.221147, acc: 96.09%] [G loss: 3.748895]\n",
      "epoch:28 step:22433 [D loss: 0.403670, acc: 85.94%] [G loss: 3.547495]\n",
      "epoch:28 step:22434 [D loss: 0.733164, acc: 56.25%] [G loss: 2.713797]\n",
      "epoch:28 step:22435 [D loss: 0.289970, acc: 94.53%] [G loss: 4.226030]\n",
      "epoch:28 step:22436 [D loss: 0.276876, acc: 95.31%] [G loss: 2.797868]\n",
      "epoch:28 step:22437 [D loss: 0.181962, acc: 96.88%] [G loss: 3.884917]\n",
      "epoch:28 step:22438 [D loss: 0.314540, acc: 91.41%] [G loss: 4.336756]\n",
      "epoch:28 step:22439 [D loss: 0.565952, acc: 71.09%] [G loss: 3.365577]\n",
      "epoch:28 step:22440 [D loss: 0.358787, acc: 86.72%] [G loss: 4.859194]\n",
      "epoch:28 step:22441 [D loss: 0.274152, acc: 90.62%] [G loss: 4.074264]\n",
      "epoch:28 step:22442 [D loss: 1.107819, acc: 50.00%] [G loss: 3.882931]\n",
      "epoch:28 step:22443 [D loss: 0.824797, acc: 53.91%] [G loss: 4.746021]\n",
      "epoch:28 step:22444 [D loss: 0.175542, acc: 98.44%] [G loss: 5.036482]\n",
      "epoch:28 step:22445 [D loss: 0.349436, acc: 89.06%] [G loss: 2.015433]\n",
      "epoch:28 step:22446 [D loss: 0.149667, acc: 100.00%] [G loss: 2.831182]\n",
      "epoch:28 step:22447 [D loss: 0.235735, acc: 97.66%] [G loss: 3.734286]\n",
      "epoch:28 step:22448 [D loss: 0.164385, acc: 99.22%] [G loss: 4.828407]\n",
      "epoch:28 step:22449 [D loss: 0.508063, acc: 65.62%] [G loss: 2.765412]\n",
      "epoch:28 step:22450 [D loss: 0.419845, acc: 68.75%] [G loss: 4.141154]\n",
      "epoch:28 step:22451 [D loss: 0.325772, acc: 92.19%] [G loss: 2.789427]\n",
      "epoch:28 step:22452 [D loss: 0.481797, acc: 77.34%] [G loss: 5.320880]\n",
      "epoch:28 step:22453 [D loss: 0.616811, acc: 67.19%] [G loss: 3.729412]\n",
      "epoch:28 step:22454 [D loss: 0.157009, acc: 100.00%] [G loss: 3.970645]\n",
      "epoch:28 step:22455 [D loss: 0.507671, acc: 77.34%] [G loss: 4.417613]\n",
      "epoch:28 step:22456 [D loss: 0.401324, acc: 85.16%] [G loss: 3.901071]\n",
      "epoch:28 step:22457 [D loss: 0.309748, acc: 92.97%] [G loss: 3.910800]\n",
      "epoch:28 step:22458 [D loss: 0.321117, acc: 89.84%] [G loss: 3.756779]\n",
      "epoch:28 step:22459 [D loss: 0.147624, acc: 98.44%] [G loss: 5.318958]\n",
      "epoch:28 step:22460 [D loss: 0.450098, acc: 82.03%] [G loss: 3.346737]\n",
      "epoch:28 step:22461 [D loss: 0.797709, acc: 46.88%] [G loss: 4.348565]\n",
      "epoch:28 step:22462 [D loss: 0.486113, acc: 72.66%] [G loss: 3.824149]\n",
      "epoch:28 step:22463 [D loss: 0.152327, acc: 100.00%] [G loss: 3.063066]\n",
      "epoch:28 step:22464 [D loss: 0.362556, acc: 81.25%] [G loss: 3.745544]\n",
      "epoch:28 step:22465 [D loss: 0.138608, acc: 100.00%] [G loss: 2.497098]\n",
      "epoch:28 step:22466 [D loss: 0.324238, acc: 83.59%] [G loss: 4.309854]\n",
      "epoch:28 step:22467 [D loss: 0.583208, acc: 70.31%] [G loss: 3.641385]\n",
      "epoch:28 step:22468 [D loss: 0.492649, acc: 66.41%] [G loss: 3.833982]\n",
      "epoch:28 step:22469 [D loss: 0.295795, acc: 92.97%] [G loss: 3.968727]\n",
      "epoch:28 step:22470 [D loss: 0.198064, acc: 94.53%] [G loss: 6.448911]\n",
      "epoch:28 step:22471 [D loss: 0.278298, acc: 92.19%] [G loss: 4.052340]\n",
      "epoch:28 step:22472 [D loss: 0.125228, acc: 100.00%] [G loss: 4.625929]\n",
      "epoch:28 step:22473 [D loss: 0.569921, acc: 69.53%] [G loss: 6.821007]\n",
      "epoch:28 step:22474 [D loss: 0.063149, acc: 100.00%] [G loss: 1.946912]\n",
      "epoch:28 step:22475 [D loss: 0.746876, acc: 56.25%] [G loss: 3.770198]\n",
      "epoch:28 step:22476 [D loss: 0.678923, acc: 60.16%] [G loss: 4.565311]\n",
      "epoch:28 step:22477 [D loss: 0.149431, acc: 99.22%] [G loss: 4.898248]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:28 step:22478 [D loss: 0.525212, acc: 66.41%] [G loss: 2.497798]\n",
      "epoch:28 step:22479 [D loss: 0.725119, acc: 56.25%] [G loss: 2.952990]\n",
      "epoch:28 step:22480 [D loss: 0.113683, acc: 100.00%] [G loss: 4.060781]\n",
      "epoch:28 step:22481 [D loss: 0.600142, acc: 62.50%] [G loss: 3.972336]\n",
      "epoch:28 step:22482 [D loss: 0.065861, acc: 100.00%] [G loss: 3.576737]\n",
      "epoch:28 step:22483 [D loss: 0.333678, acc: 80.47%] [G loss: 3.779040]\n",
      "epoch:28 step:22484 [D loss: 0.240547, acc: 96.88%] [G loss: 2.031036]\n",
      "epoch:28 step:22485 [D loss: 0.407838, acc: 84.38%] [G loss: 4.154917]\n",
      "epoch:28 step:22486 [D loss: 1.333042, acc: 10.94%] [G loss: 3.351210]\n",
      "epoch:28 step:22487 [D loss: 0.323980, acc: 86.72%] [G loss: 2.384082]\n",
      "epoch:28 step:22488 [D loss: 0.470969, acc: 79.69%] [G loss: 3.836253]\n",
      "epoch:28 step:22489 [D loss: 0.181982, acc: 99.22%] [G loss: 1.713922]\n",
      "epoch:28 step:22490 [D loss: 0.600984, acc: 67.19%] [G loss: 4.750211]\n",
      "epoch:28 step:22491 [D loss: 0.701202, acc: 57.03%] [G loss: 5.790260]\n",
      "epoch:28 step:22492 [D loss: 0.237825, acc: 90.62%] [G loss: 2.888538]\n",
      "epoch:28 step:22493 [D loss: 0.257762, acc: 89.84%] [G loss: 3.547791]\n",
      "epoch:28 step:22494 [D loss: 0.304879, acc: 98.44%] [G loss: 3.984051]\n",
      "epoch:28 step:22495 [D loss: 0.505339, acc: 67.97%] [G loss: 4.802758]\n",
      "epoch:28 step:22496 [D loss: 0.422304, acc: 83.59%] [G loss: 4.681007]\n",
      "epoch:28 step:22497 [D loss: 0.290216, acc: 92.19%] [G loss: 2.466671]\n",
      "epoch:28 step:22498 [D loss: 0.306426, acc: 97.66%] [G loss: 6.136139]\n",
      "epoch:28 step:22499 [D loss: 0.812965, acc: 53.91%] [G loss: 5.389092]\n",
      "epoch:28 step:22500 [D loss: 0.639746, acc: 63.28%] [G loss: 5.185308]\n",
      "epoch:28 step:22501 [D loss: 0.150734, acc: 99.22%] [G loss: 4.353428]\n",
      "epoch:28 step:22502 [D loss: 0.908152, acc: 49.22%] [G loss: 3.811878]\n",
      "epoch:28 step:22503 [D loss: 0.426585, acc: 75.78%] [G loss: 4.517222]\n",
      "epoch:28 step:22504 [D loss: 0.477675, acc: 79.69%] [G loss: 5.642842]\n",
      "epoch:28 step:22505 [D loss: 1.033365, acc: 52.34%] [G loss: 3.701883]\n",
      "epoch:28 step:22506 [D loss: 0.464229, acc: 78.12%] [G loss: 5.815210]\n",
      "epoch:28 step:22507 [D loss: 0.629939, acc: 64.84%] [G loss: 4.042072]\n",
      "epoch:28 step:22508 [D loss: 0.433302, acc: 81.25%] [G loss: 7.051012]\n",
      "epoch:28 step:22509 [D loss: 0.217271, acc: 98.44%] [G loss: 4.156962]\n",
      "epoch:28 step:22510 [D loss: 0.673796, acc: 55.47%] [G loss: 4.058303]\n",
      "epoch:28 step:22511 [D loss: 0.189757, acc: 99.22%] [G loss: 4.539624]\n",
      "epoch:28 step:22512 [D loss: 0.414273, acc: 71.88%] [G loss: 3.790119]\n",
      "epoch:28 step:22513 [D loss: 0.613336, acc: 62.50%] [G loss: 5.614102]\n",
      "epoch:28 step:22514 [D loss: 0.334154, acc: 88.28%] [G loss: 4.493497]\n",
      "epoch:28 step:22515 [D loss: 0.186860, acc: 98.44%] [G loss: 6.775221]\n",
      "epoch:28 step:22516 [D loss: 0.376497, acc: 82.81%] [G loss: 2.911011]\n",
      "epoch:28 step:22517 [D loss: 0.557521, acc: 74.22%] [G loss: 3.806221]\n",
      "epoch:28 step:22518 [D loss: 0.781066, acc: 55.47%] [G loss: 4.087335]\n",
      "epoch:28 step:22519 [D loss: 0.223923, acc: 92.97%] [G loss: 3.284967]\n",
      "epoch:28 step:22520 [D loss: 0.352926, acc: 89.06%] [G loss: 5.340014]\n",
      "epoch:28 step:22521 [D loss: 0.098892, acc: 100.00%] [G loss: 4.436297]\n",
      "epoch:28 step:22522 [D loss: 0.091893, acc: 100.00%] [G loss: 5.082548]\n",
      "epoch:28 step:22523 [D loss: 0.222913, acc: 96.09%] [G loss: 5.887885]\n",
      "epoch:28 step:22524 [D loss: 0.220292, acc: 97.66%] [G loss: 3.073064]\n",
      "epoch:28 step:22525 [D loss: 0.541419, acc: 72.66%] [G loss: 5.263863]\n",
      "epoch:28 step:22526 [D loss: 1.788676, acc: 7.03%] [G loss: 3.534178]\n",
      "epoch:28 step:22527 [D loss: 0.351433, acc: 89.06%] [G loss: 3.425994]\n",
      "epoch:28 step:22528 [D loss: 0.604052, acc: 62.50%] [G loss: 4.959997]\n",
      "epoch:28 step:22529 [D loss: 0.560326, acc: 60.16%] [G loss: 4.684518]\n",
      "epoch:28 step:22530 [D loss: 0.251607, acc: 94.53%] [G loss: 2.951632]\n",
      "epoch:28 step:22531 [D loss: 0.288133, acc: 97.66%] [G loss: 5.560848]\n",
      "epoch:28 step:22532 [D loss: 0.338311, acc: 91.41%] [G loss: 3.167881]\n",
      "epoch:28 step:22533 [D loss: 0.099228, acc: 100.00%] [G loss: 3.740389]\n",
      "epoch:28 step:22534 [D loss: 0.715099, acc: 56.25%] [G loss: 4.464744]\n",
      "epoch:28 step:22535 [D loss: 0.127200, acc: 98.44%] [G loss: 4.872341]\n",
      "epoch:28 step:22536 [D loss: 0.368220, acc: 92.19%] [G loss: 4.664901]\n",
      "epoch:28 step:22537 [D loss: 0.862736, acc: 48.44%] [G loss: 3.087482]\n",
      "epoch:28 step:22538 [D loss: 0.385750, acc: 88.28%] [G loss: 3.044366]\n",
      "epoch:28 step:22539 [D loss: 0.178749, acc: 98.44%] [G loss: 2.809929]\n",
      "epoch:28 step:22540 [D loss: 0.975633, acc: 32.81%] [G loss: 4.550074]\n",
      "epoch:28 step:22541 [D loss: 0.437526, acc: 69.53%] [G loss: 2.941254]\n",
      "epoch:28 step:22542 [D loss: 0.318338, acc: 91.41%] [G loss: 6.025272]\n",
      "epoch:28 step:22543 [D loss: 0.229534, acc: 96.88%] [G loss: 2.903844]\n",
      "epoch:28 step:22544 [D loss: 0.320621, acc: 89.84%] [G loss: 3.750912]\n",
      "epoch:28 step:22545 [D loss: 0.250148, acc: 96.88%] [G loss: 5.797363]\n",
      "epoch:28 step:22546 [D loss: 0.071856, acc: 100.00%] [G loss: 5.360860]\n",
      "epoch:28 step:22547 [D loss: 0.158435, acc: 99.22%] [G loss: 3.878895]\n",
      "epoch:28 step:22548 [D loss: 0.631981, acc: 67.19%] [G loss: 3.948272]\n",
      "epoch:28 step:22549 [D loss: 1.036942, acc: 25.78%] [G loss: 5.396828]\n",
      "epoch:28 step:22550 [D loss: 0.324366, acc: 92.97%] [G loss: 3.029553]\n",
      "epoch:28 step:22551 [D loss: 0.525536, acc: 78.12%] [G loss: 3.173952]\n",
      "epoch:28 step:22552 [D loss: 0.520892, acc: 77.34%] [G loss: 2.193779]\n",
      "epoch:28 step:22553 [D loss: 0.359676, acc: 91.41%] [G loss: 3.798615]\n",
      "epoch:28 step:22554 [D loss: 0.147812, acc: 98.44%] [G loss: 4.338622]\n",
      "epoch:28 step:22555 [D loss: 0.300995, acc: 91.41%] [G loss: 3.654503]\n",
      "epoch:28 step:22556 [D loss: 1.036983, acc: 25.00%] [G loss: 4.640809]\n",
      "epoch:28 step:22557 [D loss: 0.689913, acc: 57.81%] [G loss: 4.012488]\n",
      "epoch:28 step:22558 [D loss: 0.103677, acc: 100.00%] [G loss: 8.312185]\n",
      "epoch:28 step:22559 [D loss: 0.055999, acc: 100.00%] [G loss: 4.663621]\n",
      "epoch:28 step:22560 [D loss: 0.674484, acc: 60.94%] [G loss: 3.485343]\n",
      "epoch:28 step:22561 [D loss: 0.443879, acc: 79.69%] [G loss: 4.705163]\n",
      "epoch:28 step:22562 [D loss: 0.143789, acc: 100.00%] [G loss: 4.115022]\n",
      "epoch:28 step:22563 [D loss: 0.366290, acc: 85.94%] [G loss: 4.909381]\n",
      "epoch:28 step:22564 [D loss: 0.662186, acc: 63.28%] [G loss: 4.115141]\n",
      "epoch:28 step:22565 [D loss: 0.209438, acc: 96.09%] [G loss: 3.826606]\n",
      "epoch:28 step:22566 [D loss: 0.428100, acc: 87.50%] [G loss: 2.484763]\n",
      "epoch:28 step:22567 [D loss: 0.748892, acc: 57.03%] [G loss: 2.969725]\n",
      "epoch:28 step:22568 [D loss: 0.139516, acc: 100.00%] [G loss: 2.789751]\n",
      "epoch:28 step:22569 [D loss: 0.885849, acc: 38.28%] [G loss: 4.092066]\n",
      "epoch:28 step:22570 [D loss: 0.587102, acc: 70.31%] [G loss: 4.465208]\n",
      "epoch:28 step:22571 [D loss: 0.472108, acc: 75.78%] [G loss: 3.752208]\n",
      "epoch:28 step:22572 [D loss: 0.519079, acc: 80.47%] [G loss: 5.404432]\n",
      "epoch:28 step:22573 [D loss: 0.576993, acc: 59.38%] [G loss: 5.625288]\n",
      "epoch:28 step:22574 [D loss: 0.172235, acc: 97.66%] [G loss: 4.647279]\n",
      "epoch:28 step:22575 [D loss: 0.131190, acc: 100.00%] [G loss: 2.329413]\n",
      "epoch:28 step:22576 [D loss: 0.551231, acc: 73.44%] [G loss: 3.401269]\n",
      "epoch:28 step:22577 [D loss: 0.412894, acc: 78.12%] [G loss: 3.428497]\n",
      "epoch:28 step:22578 [D loss: 0.511145, acc: 71.88%] [G loss: 3.555828]\n",
      "epoch:28 step:22579 [D loss: 0.309626, acc: 81.25%] [G loss: 5.744658]\n",
      "epoch:28 step:22580 [D loss: 0.547243, acc: 71.09%] [G loss: 4.106485]\n",
      "epoch:28 step:22581 [D loss: 0.439507, acc: 86.72%] [G loss: 5.320093]\n",
      "epoch:28 step:22582 [D loss: 0.219603, acc: 95.31%] [G loss: 5.281845]\n",
      "epoch:28 step:22583 [D loss: 0.356922, acc: 92.97%] [G loss: 3.595125]\n",
      "epoch:28 step:22584 [D loss: 0.518980, acc: 71.09%] [G loss: 5.305843]\n",
      "epoch:28 step:22585 [D loss: 0.586927, acc: 68.75%] [G loss: 5.691373]\n",
      "epoch:28 step:22586 [D loss: 0.340748, acc: 84.38%] [G loss: 5.272999]\n",
      "epoch:28 step:22587 [D loss: 0.817359, acc: 52.34%] [G loss: 6.352849]\n",
      "epoch:28 step:22588 [D loss: 0.745369, acc: 53.91%] [G loss: 4.239909]\n",
      "epoch:28 step:22589 [D loss: 0.231578, acc: 95.31%] [G loss: 4.460948]\n",
      "epoch:28 step:22590 [D loss: 0.361387, acc: 88.28%] [G loss: 2.602105]\n",
      "epoch:28 step:22591 [D loss: 0.581314, acc: 57.81%] [G loss: 6.191886]\n",
      "epoch:28 step:22592 [D loss: 0.865267, acc: 53.91%] [G loss: 3.563044]\n",
      "epoch:28 step:22593 [D loss: 0.397023, acc: 85.94%] [G loss: 3.417107]\n",
      "epoch:28 step:22594 [D loss: 0.324979, acc: 89.06%] [G loss: 8.216637]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:28 step:22595 [D loss: 0.584501, acc: 71.88%] [G loss: 4.034826]\n",
      "epoch:28 step:22596 [D loss: 0.379321, acc: 91.41%] [G loss: 4.408642]\n",
      "epoch:28 step:22597 [D loss: 0.506803, acc: 76.56%] [G loss: 5.293402]\n",
      "epoch:28 step:22598 [D loss: 0.666417, acc: 60.94%] [G loss: 3.168474]\n",
      "epoch:28 step:22599 [D loss: 0.338849, acc: 92.19%] [G loss: 2.418610]\n",
      "epoch:28 step:22600 [D loss: 0.163733, acc: 100.00%] [G loss: 3.671062]\n",
      "##############\n",
      "[0.85487902 0.8890784  0.82708131 0.83503994 0.79661765 0.82683273\n",
      " 0.87901818 0.81349679 0.7845741  0.83096743]\n",
      "##########\n",
      "epoch:28 step:22601 [D loss: 0.296606, acc: 96.88%] [G loss: 6.144455]\n",
      "epoch:28 step:22602 [D loss: 1.297172, acc: 50.00%] [G loss: 4.146989]\n",
      "epoch:28 step:22603 [D loss: 0.282757, acc: 89.84%] [G loss: 4.736657]\n",
      "epoch:28 step:22604 [D loss: 0.376548, acc: 73.44%] [G loss: 5.237091]\n",
      "epoch:28 step:22605 [D loss: 0.089651, acc: 99.22%] [G loss: 4.492837]\n",
      "epoch:28 step:22606 [D loss: 0.214083, acc: 99.22%] [G loss: 5.578348]\n",
      "epoch:28 step:22607 [D loss: 0.443884, acc: 86.72%] [G loss: 5.590714]\n",
      "epoch:28 step:22608 [D loss: 0.298847, acc: 91.41%] [G loss: 3.934312]\n",
      "epoch:28 step:22609 [D loss: 0.726382, acc: 54.69%] [G loss: 4.320852]\n",
      "epoch:28 step:22610 [D loss: 0.566823, acc: 66.41%] [G loss: 6.289619]\n",
      "epoch:28 step:22611 [D loss: 1.280000, acc: 49.22%] [G loss: 3.045627]\n",
      "epoch:28 step:22612 [D loss: 0.359169, acc: 90.62%] [G loss: 3.964384]\n",
      "epoch:28 step:22613 [D loss: 0.202374, acc: 96.09%] [G loss: 5.470007]\n",
      "epoch:28 step:22614 [D loss: 0.884188, acc: 50.78%] [G loss: 5.022694]\n",
      "epoch:28 step:22615 [D loss: 1.768763, acc: 50.00%] [G loss: 3.196825]\n",
      "epoch:28 step:22616 [D loss: 0.460508, acc: 82.03%] [G loss: 3.605553]\n",
      "epoch:28 step:22617 [D loss: 0.244291, acc: 89.06%] [G loss: 4.970530]\n",
      "epoch:28 step:22618 [D loss: 0.452083, acc: 75.00%] [G loss: 3.195749]\n",
      "epoch:28 step:22619 [D loss: 0.715469, acc: 54.69%] [G loss: 4.186437]\n",
      "epoch:28 step:22620 [D loss: 0.382200, acc: 78.12%] [G loss: 4.182096]\n",
      "epoch:28 step:22621 [D loss: 0.904899, acc: 50.78%] [G loss: 3.231498]\n",
      "epoch:28 step:22622 [D loss: 0.744766, acc: 57.81%] [G loss: 3.274736]\n",
      "epoch:28 step:22623 [D loss: 0.702303, acc: 54.69%] [G loss: 3.941081]\n",
      "epoch:28 step:22624 [D loss: 0.165515, acc: 99.22%] [G loss: 3.455208]\n",
      "epoch:28 step:22625 [D loss: 0.262594, acc: 92.97%] [G loss: 4.874675]\n",
      "epoch:28 step:22626 [D loss: 0.141065, acc: 99.22%] [G loss: 3.510615]\n",
      "epoch:28 step:22627 [D loss: 0.281411, acc: 94.53%] [G loss: 3.532244]\n",
      "epoch:28 step:22628 [D loss: 0.410985, acc: 74.22%] [G loss: 5.788671]\n",
      "epoch:28 step:22629 [D loss: 0.379094, acc: 85.16%] [G loss: 3.631158]\n",
      "epoch:28 step:22630 [D loss: 0.187811, acc: 97.66%] [G loss: 2.986914]\n",
      "epoch:28 step:22631 [D loss: 0.280571, acc: 92.97%] [G loss: 5.722909]\n",
      "epoch:28 step:22632 [D loss: 0.899098, acc: 49.22%] [G loss: 3.943716]\n",
      "epoch:28 step:22633 [D loss: 0.396835, acc: 77.34%] [G loss: 1.577406]\n",
      "epoch:28 step:22634 [D loss: 0.517239, acc: 72.66%] [G loss: 4.452192]\n",
      "epoch:28 step:22635 [D loss: 0.085025, acc: 100.00%] [G loss: 3.764928]\n",
      "epoch:28 step:22636 [D loss: 0.107665, acc: 99.22%] [G loss: 3.459978]\n",
      "epoch:28 step:22637 [D loss: 1.646873, acc: 34.38%] [G loss: 3.432576]\n",
      "epoch:28 step:22638 [D loss: 0.772778, acc: 46.09%] [G loss: 3.738298]\n",
      "epoch:28 step:22639 [D loss: 0.348755, acc: 92.97%] [G loss: 4.189126]\n",
      "epoch:28 step:22640 [D loss: 0.070537, acc: 100.00%] [G loss: 4.986085]\n",
      "epoch:28 step:22641 [D loss: 0.071718, acc: 100.00%] [G loss: 5.324135]\n",
      "epoch:28 step:22642 [D loss: 0.704194, acc: 57.03%] [G loss: 3.472479]\n",
      "epoch:28 step:22643 [D loss: 0.471340, acc: 83.59%] [G loss: 3.344840]\n",
      "epoch:28 step:22644 [D loss: 0.732665, acc: 62.50%] [G loss: 4.779376]\n",
      "epoch:28 step:22645 [D loss: 0.172643, acc: 97.66%] [G loss: 3.111782]\n",
      "epoch:28 step:22646 [D loss: 0.580731, acc: 71.88%] [G loss: 2.078477]\n",
      "epoch:28 step:22647 [D loss: 1.414023, acc: 25.78%] [G loss: 4.931383]\n",
      "epoch:28 step:22648 [D loss: 0.171437, acc: 100.00%] [G loss: 3.361065]\n",
      "epoch:28 step:22649 [D loss: 0.155161, acc: 99.22%] [G loss: 4.290634]\n",
      "epoch:29 step:22650 [D loss: 0.958437, acc: 46.88%] [G loss: 3.480940]\n",
      "epoch:29 step:22651 [D loss: 0.393480, acc: 77.34%] [G loss: 4.954949]\n",
      "epoch:29 step:22652 [D loss: 0.184405, acc: 100.00%] [G loss: 4.531128]\n",
      "epoch:29 step:22653 [D loss: 1.051698, acc: 23.44%] [G loss: 5.102373]\n",
      "epoch:29 step:22654 [D loss: 0.159527, acc: 98.44%] [G loss: 3.795349]\n",
      "epoch:29 step:22655 [D loss: 0.462233, acc: 82.03%] [G loss: 5.479796]\n",
      "epoch:29 step:22656 [D loss: 0.709801, acc: 60.94%] [G loss: 2.334960]\n",
      "epoch:29 step:22657 [D loss: 0.304345, acc: 88.28%] [G loss: 5.835877]\n",
      "epoch:29 step:22658 [D loss: 1.111643, acc: 50.00%] [G loss: 3.415401]\n",
      "epoch:29 step:22659 [D loss: 0.474915, acc: 63.28%] [G loss: 3.406439]\n",
      "epoch:29 step:22660 [D loss: 0.519960, acc: 73.44%] [G loss: 5.219482]\n",
      "epoch:29 step:22661 [D loss: 0.336691, acc: 92.97%] [G loss: 3.915806]\n",
      "epoch:29 step:22662 [D loss: 0.573534, acc: 60.16%] [G loss: 3.801599]\n",
      "epoch:29 step:22663 [D loss: 0.680268, acc: 60.16%] [G loss: 5.047249]\n",
      "epoch:29 step:22664 [D loss: 0.856491, acc: 37.50%] [G loss: 3.478098]\n",
      "epoch:29 step:22665 [D loss: 0.130460, acc: 98.44%] [G loss: 2.925266]\n",
      "epoch:29 step:22666 [D loss: 0.560796, acc: 70.31%] [G loss: 2.733781]\n",
      "epoch:29 step:22667 [D loss: 0.645266, acc: 57.03%] [G loss: 4.158219]\n",
      "epoch:29 step:22668 [D loss: 0.946352, acc: 50.78%] [G loss: 4.034626]\n",
      "epoch:29 step:22669 [D loss: 0.364505, acc: 82.03%] [G loss: 3.243274]\n",
      "epoch:29 step:22670 [D loss: 0.367181, acc: 81.25%] [G loss: 4.311137]\n",
      "epoch:29 step:22671 [D loss: 0.215209, acc: 97.66%] [G loss: 4.146595]\n",
      "epoch:29 step:22672 [D loss: 0.185192, acc: 96.09%] [G loss: 5.170739]\n",
      "epoch:29 step:22673 [D loss: 0.814485, acc: 53.12%] [G loss: 3.660870]\n",
      "epoch:29 step:22674 [D loss: 0.478809, acc: 79.69%] [G loss: 3.309916]\n",
      "epoch:29 step:22675 [D loss: 0.089899, acc: 100.00%] [G loss: 3.910740]\n",
      "epoch:29 step:22676 [D loss: 0.391454, acc: 87.50%] [G loss: 2.833888]\n",
      "epoch:29 step:22677 [D loss: 0.950304, acc: 29.69%] [G loss: 3.934815]\n",
      "epoch:29 step:22678 [D loss: 0.579662, acc: 72.66%] [G loss: 3.510791]\n",
      "epoch:29 step:22679 [D loss: 0.298056, acc: 89.84%] [G loss: 2.374486]\n",
      "epoch:29 step:22680 [D loss: 0.410144, acc: 75.00%] [G loss: 3.860025]\n",
      "epoch:29 step:22681 [D loss: 0.231970, acc: 96.88%] [G loss: 4.556111]\n",
      "epoch:29 step:22682 [D loss: 0.194676, acc: 95.31%] [G loss: 4.218200]\n",
      "epoch:29 step:22683 [D loss: 0.461205, acc: 81.25%] [G loss: 2.769565]\n",
      "epoch:29 step:22684 [D loss: 0.150856, acc: 100.00%] [G loss: 4.049796]\n",
      "epoch:29 step:22685 [D loss: 0.300006, acc: 95.31%] [G loss: 3.673265]\n",
      "epoch:29 step:22686 [D loss: 0.165246, acc: 98.44%] [G loss: 4.457911]\n",
      "epoch:29 step:22687 [D loss: 0.244546, acc: 96.09%] [G loss: 3.698255]\n",
      "epoch:29 step:22688 [D loss: 0.951112, acc: 45.31%] [G loss: 3.643821]\n",
      "epoch:29 step:22689 [D loss: 0.241352, acc: 94.53%] [G loss: 4.226606]\n",
      "epoch:29 step:22690 [D loss: 0.639049, acc: 64.06%] [G loss: 2.936615]\n",
      "epoch:29 step:22691 [D loss: 0.277792, acc: 89.84%] [G loss: 2.856127]\n",
      "epoch:29 step:22692 [D loss: 1.117797, acc: 50.00%] [G loss: 5.353751]\n",
      "epoch:29 step:22693 [D loss: 0.260043, acc: 94.53%] [G loss: 3.825723]\n",
      "epoch:29 step:22694 [D loss: 0.795743, acc: 47.66%] [G loss: 4.272675]\n",
      "epoch:29 step:22695 [D loss: 0.432558, acc: 83.59%] [G loss: 4.356858]\n",
      "epoch:29 step:22696 [D loss: 0.711689, acc: 54.69%] [G loss: 3.225788]\n",
      "epoch:29 step:22697 [D loss: 0.251802, acc: 93.75%] [G loss: 3.836888]\n",
      "epoch:29 step:22698 [D loss: 0.255092, acc: 95.31%] [G loss: 3.805945]\n",
      "epoch:29 step:22699 [D loss: 0.456758, acc: 74.22%] [G loss: 3.448296]\n",
      "epoch:29 step:22700 [D loss: 0.743618, acc: 46.88%] [G loss: 2.267892]\n",
      "epoch:29 step:22701 [D loss: 0.130337, acc: 99.22%] [G loss: 5.523179]\n",
      "epoch:29 step:22702 [D loss: 0.286079, acc: 83.59%] [G loss: 6.595414]\n",
      "epoch:29 step:22703 [D loss: 0.118647, acc: 98.44%] [G loss: 3.584837]\n",
      "epoch:29 step:22704 [D loss: 0.247316, acc: 96.88%] [G loss: 2.657965]\n",
      "epoch:29 step:22705 [D loss: 0.460512, acc: 82.03%] [G loss: 4.429239]\n",
      "epoch:29 step:22706 [D loss: 0.238750, acc: 96.09%] [G loss: 3.806078]\n",
      "epoch:29 step:22707 [D loss: 0.791436, acc: 52.34%] [G loss: 2.639390]\n",
      "epoch:29 step:22708 [D loss: 0.143581, acc: 99.22%] [G loss: 3.967146]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:29 step:22709 [D loss: 0.179880, acc: 99.22%] [G loss: 3.721235]\n",
      "epoch:29 step:22710 [D loss: 0.627478, acc: 54.69%] [G loss: 4.606802]\n",
      "epoch:29 step:22711 [D loss: 0.118978, acc: 100.00%] [G loss: 3.355853]\n",
      "epoch:29 step:22712 [D loss: 0.603778, acc: 71.09%] [G loss: 4.076316]\n",
      "epoch:29 step:22713 [D loss: 0.603031, acc: 64.06%] [G loss: 3.931597]\n",
      "epoch:29 step:22714 [D loss: 0.392412, acc: 81.25%] [G loss: 4.456740]\n",
      "epoch:29 step:22715 [D loss: 0.337338, acc: 88.28%] [G loss: 4.470408]\n",
      "epoch:29 step:22716 [D loss: 0.947824, acc: 29.69%] [G loss: 6.587250]\n",
      "epoch:29 step:22717 [D loss: 0.342651, acc: 94.53%] [G loss: 2.385702]\n",
      "epoch:29 step:22718 [D loss: 0.089795, acc: 100.00%] [G loss: 2.595225]\n",
      "epoch:29 step:22719 [D loss: 0.211576, acc: 93.75%] [G loss: 4.555132]\n",
      "epoch:29 step:22720 [D loss: 0.421366, acc: 83.59%] [G loss: 4.661069]\n",
      "epoch:29 step:22721 [D loss: 0.518282, acc: 79.69%] [G loss: 5.009399]\n",
      "epoch:29 step:22722 [D loss: 0.048227, acc: 100.00%] [G loss: 3.991210]\n",
      "epoch:29 step:22723 [D loss: 0.390465, acc: 82.03%] [G loss: 3.123162]\n",
      "epoch:29 step:22724 [D loss: 0.337863, acc: 88.28%] [G loss: 4.315003]\n",
      "epoch:29 step:22725 [D loss: 0.307936, acc: 89.06%] [G loss: 4.276797]\n",
      "epoch:29 step:22726 [D loss: 0.428172, acc: 85.16%] [G loss: 6.079838]\n",
      "epoch:29 step:22727 [D loss: 0.091856, acc: 99.22%] [G loss: 5.374344]\n",
      "epoch:29 step:22728 [D loss: 0.051387, acc: 100.00%] [G loss: 4.183116]\n",
      "epoch:29 step:22729 [D loss: 0.778131, acc: 53.91%] [G loss: 3.102867]\n",
      "epoch:29 step:22730 [D loss: 0.751967, acc: 49.22%] [G loss: 2.922999]\n",
      "epoch:29 step:22731 [D loss: 0.170742, acc: 98.44%] [G loss: 3.410276]\n",
      "epoch:29 step:22732 [D loss: 0.355755, acc: 89.06%] [G loss: 7.181344]\n",
      "epoch:29 step:22733 [D loss: 0.816600, acc: 50.78%] [G loss: 4.635193]\n",
      "epoch:29 step:22734 [D loss: 0.058668, acc: 100.00%] [G loss: 6.963855]\n",
      "epoch:29 step:22735 [D loss: 0.402715, acc: 91.41%] [G loss: 4.089210]\n",
      "epoch:29 step:22736 [D loss: 0.692332, acc: 56.25%] [G loss: 4.515832]\n",
      "epoch:29 step:22737 [D loss: 0.336911, acc: 84.38%] [G loss: 4.935000]\n",
      "epoch:29 step:22738 [D loss: 0.205823, acc: 96.09%] [G loss: 9.006855]\n",
      "epoch:29 step:22739 [D loss: 0.159716, acc: 99.22%] [G loss: 3.927697]\n",
      "epoch:29 step:22740 [D loss: 0.079555, acc: 100.00%] [G loss: 6.900332]\n",
      "epoch:29 step:22741 [D loss: 0.361733, acc: 78.12%] [G loss: 4.519485]\n",
      "epoch:29 step:22742 [D loss: 0.535163, acc: 73.44%] [G loss: 6.048882]\n",
      "epoch:29 step:22743 [D loss: 0.811083, acc: 52.34%] [G loss: 3.813427]\n",
      "epoch:29 step:22744 [D loss: 0.534423, acc: 68.75%] [G loss: 4.974808]\n",
      "epoch:29 step:22745 [D loss: 0.601900, acc: 72.66%] [G loss: 3.793917]\n",
      "epoch:29 step:22746 [D loss: 0.207433, acc: 98.44%] [G loss: 4.270825]\n",
      "epoch:29 step:22747 [D loss: 0.164140, acc: 100.00%] [G loss: 4.230593]\n",
      "epoch:29 step:22748 [D loss: 0.209771, acc: 98.44%] [G loss: 3.475371]\n",
      "epoch:29 step:22749 [D loss: 0.416108, acc: 88.28%] [G loss: 6.214505]\n",
      "epoch:29 step:22750 [D loss: 0.448848, acc: 70.31%] [G loss: 3.008055]\n",
      "epoch:29 step:22751 [D loss: 0.226986, acc: 93.75%] [G loss: 4.400774]\n",
      "epoch:29 step:22752 [D loss: 0.425114, acc: 74.22%] [G loss: 5.892556]\n",
      "epoch:29 step:22753 [D loss: 0.276147, acc: 89.06%] [G loss: 3.676713]\n",
      "epoch:29 step:22754 [D loss: 0.409206, acc: 88.28%] [G loss: 4.044344]\n",
      "epoch:29 step:22755 [D loss: 0.400497, acc: 87.50%] [G loss: 3.014305]\n",
      "epoch:29 step:22756 [D loss: 0.589388, acc: 70.31%] [G loss: 3.853358]\n",
      "epoch:29 step:22757 [D loss: 0.091366, acc: 100.00%] [G loss: 5.201184]\n",
      "epoch:29 step:22758 [D loss: 0.372429, acc: 84.38%] [G loss: 3.486922]\n",
      "epoch:29 step:22759 [D loss: 0.507371, acc: 70.31%] [G loss: 4.982889]\n",
      "epoch:29 step:22760 [D loss: 0.619722, acc: 57.03%] [G loss: 5.549466]\n",
      "epoch:29 step:22761 [D loss: 1.184818, acc: 50.00%] [G loss: 3.920831]\n",
      "epoch:29 step:22762 [D loss: 0.433096, acc: 68.75%] [G loss: 5.560604]\n",
      "epoch:29 step:22763 [D loss: 0.140810, acc: 100.00%] [G loss: 4.091664]\n",
      "epoch:29 step:22764 [D loss: 1.200250, acc: 50.00%] [G loss: 4.019159]\n",
      "epoch:29 step:22765 [D loss: 0.402036, acc: 85.16%] [G loss: 3.745055]\n",
      "epoch:29 step:22766 [D loss: 0.370141, acc: 78.91%] [G loss: 5.151620]\n",
      "epoch:29 step:22767 [D loss: 0.292872, acc: 92.97%] [G loss: 5.354709]\n",
      "epoch:29 step:22768 [D loss: 0.096138, acc: 100.00%] [G loss: 5.245479]\n",
      "epoch:29 step:22769 [D loss: 0.795648, acc: 51.56%] [G loss: 6.551550]\n",
      "epoch:29 step:22770 [D loss: 0.424717, acc: 87.50%] [G loss: 3.519799]\n",
      "epoch:29 step:22771 [D loss: 0.035522, acc: 100.00%] [G loss: 4.777351]\n",
      "epoch:29 step:22772 [D loss: 0.686482, acc: 59.38%] [G loss: 3.312627]\n",
      "epoch:29 step:22773 [D loss: 0.456093, acc: 75.78%] [G loss: 2.599341]\n",
      "epoch:29 step:22774 [D loss: 0.656676, acc: 57.03%] [G loss: 2.238183]\n",
      "epoch:29 step:22775 [D loss: 0.619430, acc: 63.28%] [G loss: 3.454601]\n",
      "epoch:29 step:22776 [D loss: 0.707454, acc: 59.38%] [G loss: 4.071718]\n",
      "epoch:29 step:22777 [D loss: 0.301740, acc: 93.75%] [G loss: 5.075003]\n",
      "epoch:29 step:22778 [D loss: 0.578344, acc: 68.75%] [G loss: 6.260733]\n",
      "epoch:29 step:22779 [D loss: 0.507885, acc: 70.31%] [G loss: 6.458050]\n",
      "epoch:29 step:22780 [D loss: 0.803609, acc: 46.88%] [G loss: 5.554586]\n",
      "epoch:29 step:22781 [D loss: 0.291144, acc: 94.53%] [G loss: 2.399242]\n",
      "epoch:29 step:22782 [D loss: 0.163912, acc: 98.44%] [G loss: 4.091713]\n",
      "epoch:29 step:22783 [D loss: 0.395622, acc: 88.28%] [G loss: 3.020370]\n",
      "epoch:29 step:22784 [D loss: 0.341812, acc: 78.12%] [G loss: 3.494164]\n",
      "epoch:29 step:22785 [D loss: 0.150116, acc: 98.44%] [G loss: 5.836498]\n",
      "epoch:29 step:22786 [D loss: 0.568541, acc: 75.78%] [G loss: 3.538948]\n",
      "epoch:29 step:22787 [D loss: 0.817220, acc: 50.78%] [G loss: 3.608956]\n",
      "epoch:29 step:22788 [D loss: 0.655428, acc: 53.12%] [G loss: 6.476553]\n",
      "epoch:29 step:22789 [D loss: 0.245177, acc: 97.66%] [G loss: 3.499300]\n",
      "epoch:29 step:22790 [D loss: 0.707870, acc: 55.47%] [G loss: 4.232790]\n",
      "epoch:29 step:22791 [D loss: 0.134033, acc: 99.22%] [G loss: 5.041537]\n",
      "epoch:29 step:22792 [D loss: 0.374413, acc: 78.12%] [G loss: 5.149136]\n",
      "epoch:29 step:22793 [D loss: 0.245714, acc: 96.88%] [G loss: 3.883693]\n",
      "epoch:29 step:22794 [D loss: 0.830938, acc: 52.34%] [G loss: 4.414892]\n",
      "epoch:29 step:22795 [D loss: 0.260574, acc: 96.88%] [G loss: 4.352030]\n",
      "epoch:29 step:22796 [D loss: 0.206059, acc: 97.66%] [G loss: 4.025061]\n",
      "epoch:29 step:22797 [D loss: 0.741714, acc: 51.56%] [G loss: 5.194015]\n",
      "epoch:29 step:22798 [D loss: 0.237441, acc: 97.66%] [G loss: 4.092465]\n",
      "epoch:29 step:22799 [D loss: 0.126268, acc: 100.00%] [G loss: 4.386183]\n",
      "epoch:29 step:22800 [D loss: 0.320499, acc: 92.19%] [G loss: 3.319069]\n",
      "##############\n",
      "[0.86594641 0.86524359 0.80527488 0.80891517 0.8092754  0.81978925\n",
      " 0.88708904 0.8197581  0.80420838 0.83610603]\n",
      "##########\n",
      "epoch:29 step:22801 [D loss: 0.733428, acc: 57.81%] [G loss: 6.478532]\n",
      "epoch:29 step:22802 [D loss: 0.302406, acc: 87.50%] [G loss: 4.545193]\n",
      "epoch:29 step:22803 [D loss: 0.153559, acc: 99.22%] [G loss: 3.697965]\n",
      "epoch:29 step:22804 [D loss: 0.579898, acc: 64.06%] [G loss: 6.467693]\n",
      "epoch:29 step:22805 [D loss: 0.674650, acc: 52.34%] [G loss: 3.868762]\n",
      "epoch:29 step:22806 [D loss: 0.274528, acc: 93.75%] [G loss: 6.265518]\n",
      "epoch:29 step:22807 [D loss: 0.167181, acc: 97.66%] [G loss: 4.650294]\n",
      "epoch:29 step:22808 [D loss: 0.545703, acc: 70.31%] [G loss: 4.148693]\n",
      "epoch:29 step:22809 [D loss: 0.649252, acc: 61.72%] [G loss: 3.283819]\n",
      "epoch:29 step:22810 [D loss: 0.430756, acc: 84.38%] [G loss: 5.983581]\n",
      "epoch:29 step:22811 [D loss: 0.633562, acc: 60.16%] [G loss: 3.336257]\n",
      "epoch:29 step:22812 [D loss: 0.267318, acc: 96.09%] [G loss: 3.031005]\n",
      "epoch:29 step:22813 [D loss: 0.698118, acc: 59.38%] [G loss: 6.157142]\n",
      "epoch:29 step:22814 [D loss: 0.587108, acc: 73.44%] [G loss: 4.702968]\n",
      "epoch:29 step:22815 [D loss: 1.041055, acc: 28.91%] [G loss: 4.080567]\n",
      "epoch:29 step:22816 [D loss: 0.080401, acc: 100.00%] [G loss: 3.524874]\n",
      "epoch:29 step:22817 [D loss: 0.336471, acc: 89.84%] [G loss: 3.320603]\n",
      "epoch:29 step:22818 [D loss: 0.748636, acc: 48.44%] [G loss: 3.857566]\n",
      "epoch:29 step:22819 [D loss: 0.551589, acc: 68.75%] [G loss: 5.468172]\n",
      "epoch:29 step:22820 [D loss: 0.862127, acc: 51.56%] [G loss: 3.867782]\n",
      "epoch:29 step:22821 [D loss: 0.354334, acc: 95.31%] [G loss: 4.215988]\n",
      "epoch:29 step:22822 [D loss: 0.577736, acc: 75.00%] [G loss: 2.655819]\n",
      "epoch:29 step:22823 [D loss: 0.097587, acc: 99.22%] [G loss: 5.631208]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:29 step:22824 [D loss: 0.525642, acc: 61.72%] [G loss: 5.003163]\n",
      "epoch:29 step:22825 [D loss: 0.617124, acc: 64.06%] [G loss: 5.140423]\n",
      "epoch:29 step:22826 [D loss: 1.061239, acc: 50.00%] [G loss: 3.231986]\n",
      "epoch:29 step:22827 [D loss: 0.336680, acc: 77.34%] [G loss: 5.770504]\n",
      "epoch:29 step:22828 [D loss: 0.618400, acc: 61.72%] [G loss: 4.646010]\n",
      "epoch:29 step:22829 [D loss: 0.735250, acc: 55.47%] [G loss: 4.372392]\n",
      "epoch:29 step:22830 [D loss: 0.430912, acc: 74.22%] [G loss: 2.761839]\n",
      "epoch:29 step:22831 [D loss: 0.571576, acc: 63.28%] [G loss: 2.092862]\n",
      "epoch:29 step:22832 [D loss: 0.376050, acc: 92.97%] [G loss: 3.218636]\n",
      "epoch:29 step:22833 [D loss: 0.243549, acc: 97.66%] [G loss: 2.899683]\n",
      "epoch:29 step:22834 [D loss: 1.182477, acc: 14.06%] [G loss: 3.736781]\n",
      "epoch:29 step:22835 [D loss: 0.343022, acc: 87.50%] [G loss: 4.109657]\n",
      "epoch:29 step:22836 [D loss: 0.618553, acc: 57.81%] [G loss: 2.776511]\n",
      "epoch:29 step:22837 [D loss: 0.144110, acc: 94.53%] [G loss: 4.683660]\n",
      "epoch:29 step:22838 [D loss: 0.157995, acc: 100.00%] [G loss: 4.379505]\n",
      "epoch:29 step:22839 [D loss: 0.121536, acc: 100.00%] [G loss: 4.315287]\n",
      "epoch:29 step:22840 [D loss: 0.069062, acc: 100.00%] [G loss: 5.964465]\n",
      "epoch:29 step:22841 [D loss: 0.142037, acc: 100.00%] [G loss: 4.508132]\n",
      "epoch:29 step:22842 [D loss: 0.355345, acc: 86.72%] [G loss: 3.576761]\n",
      "epoch:29 step:22843 [D loss: 0.740921, acc: 49.22%] [G loss: 3.671002]\n",
      "epoch:29 step:22844 [D loss: 0.121841, acc: 100.00%] [G loss: 3.636469]\n",
      "epoch:29 step:22845 [D loss: 0.306758, acc: 86.72%] [G loss: 4.561054]\n",
      "epoch:29 step:22846 [D loss: 0.136791, acc: 98.44%] [G loss: 2.537768]\n",
      "epoch:29 step:22847 [D loss: 0.676570, acc: 56.25%] [G loss: 2.785293]\n",
      "epoch:29 step:22848 [D loss: 0.087111, acc: 100.00%] [G loss: 6.447144]\n",
      "epoch:29 step:22849 [D loss: 0.230884, acc: 96.09%] [G loss: 4.125568]\n",
      "epoch:29 step:22850 [D loss: 0.567775, acc: 68.75%] [G loss: 4.408699]\n",
      "epoch:29 step:22851 [D loss: 0.195949, acc: 100.00%] [G loss: 2.891641]\n",
      "epoch:29 step:22852 [D loss: 0.285764, acc: 96.09%] [G loss: 2.607309]\n",
      "epoch:29 step:22853 [D loss: 0.316602, acc: 91.41%] [G loss: 4.462748]\n",
      "epoch:29 step:22854 [D loss: 0.795861, acc: 50.78%] [G loss: 5.055144]\n",
      "epoch:29 step:22855 [D loss: 0.552640, acc: 72.66%] [G loss: 2.149331]\n",
      "epoch:29 step:22856 [D loss: 0.310782, acc: 96.88%] [G loss: 3.259660]\n",
      "epoch:29 step:22857 [D loss: 0.355331, acc: 86.72%] [G loss: 4.106307]\n",
      "epoch:29 step:22858 [D loss: 0.272697, acc: 88.28%] [G loss: 3.926692]\n",
      "epoch:29 step:22859 [D loss: 0.327223, acc: 98.44%] [G loss: 1.697103]\n",
      "epoch:29 step:22860 [D loss: 0.617997, acc: 62.50%] [G loss: 4.896657]\n",
      "epoch:29 step:22861 [D loss: 0.099532, acc: 100.00%] [G loss: 5.793169]\n",
      "epoch:29 step:22862 [D loss: 1.201463, acc: 50.00%] [G loss: 4.385269]\n",
      "epoch:29 step:22863 [D loss: 0.172255, acc: 97.66%] [G loss: 3.371883]\n",
      "epoch:29 step:22864 [D loss: 0.087297, acc: 100.00%] [G loss: 5.318910]\n",
      "epoch:29 step:22865 [D loss: 0.568077, acc: 70.31%] [G loss: 2.720572]\n",
      "epoch:29 step:22866 [D loss: 0.132203, acc: 99.22%] [G loss: 3.069642]\n",
      "epoch:29 step:22867 [D loss: 0.282064, acc: 92.97%] [G loss: 2.728884]\n",
      "epoch:29 step:22868 [D loss: 0.294750, acc: 90.62%] [G loss: 3.298663]\n",
      "epoch:29 step:22869 [D loss: 0.926774, acc: 48.44%] [G loss: 5.184505]\n",
      "epoch:29 step:22870 [D loss: 0.743695, acc: 55.47%] [G loss: 4.777745]\n",
      "epoch:29 step:22871 [D loss: 0.902356, acc: 44.53%] [G loss: 2.462623]\n",
      "epoch:29 step:22872 [D loss: 0.258255, acc: 96.09%] [G loss: 4.913489]\n",
      "epoch:29 step:22873 [D loss: 0.500450, acc: 75.78%] [G loss: 4.791345]\n",
      "epoch:29 step:22874 [D loss: 0.221628, acc: 94.53%] [G loss: 5.173632]\n",
      "epoch:29 step:22875 [D loss: 0.353652, acc: 92.97%] [G loss: 3.169798]\n",
      "epoch:29 step:22876 [D loss: 0.062050, acc: 100.00%] [G loss: 5.170176]\n",
      "epoch:29 step:22877 [D loss: 0.294450, acc: 87.50%] [G loss: 3.932527]\n",
      "epoch:29 step:22878 [D loss: 0.323383, acc: 88.28%] [G loss: 5.812396]\n",
      "epoch:29 step:22879 [D loss: 0.402140, acc: 85.94%] [G loss: 2.028275]\n",
      "epoch:29 step:22880 [D loss: 0.182199, acc: 98.44%] [G loss: 4.130795]\n",
      "epoch:29 step:22881 [D loss: 0.451236, acc: 82.81%] [G loss: 3.697398]\n",
      "epoch:29 step:22882 [D loss: 0.208044, acc: 96.09%] [G loss: 3.430750]\n",
      "epoch:29 step:22883 [D loss: 0.354517, acc: 91.41%] [G loss: 3.508762]\n",
      "epoch:29 step:22884 [D loss: 0.216320, acc: 96.88%] [G loss: 4.073281]\n",
      "epoch:29 step:22885 [D loss: 1.128120, acc: 35.16%] [G loss: 4.347258]\n",
      "epoch:29 step:22886 [D loss: 0.040215, acc: 100.00%] [G loss: 7.109838]\n",
      "epoch:29 step:22887 [D loss: 0.924847, acc: 33.59%] [G loss: 2.895900]\n",
      "epoch:29 step:22888 [D loss: 0.535034, acc: 76.56%] [G loss: 3.217828]\n",
      "epoch:29 step:22889 [D loss: 0.148349, acc: 98.44%] [G loss: 2.159319]\n",
      "epoch:29 step:22890 [D loss: 0.336163, acc: 93.75%] [G loss: 3.325472]\n",
      "epoch:29 step:22891 [D loss: 0.147918, acc: 100.00%] [G loss: 4.126001]\n",
      "epoch:29 step:22892 [D loss: 0.579087, acc: 64.06%] [G loss: 3.027185]\n",
      "epoch:29 step:22893 [D loss: 0.276704, acc: 89.06%] [G loss: 4.243243]\n",
      "epoch:29 step:22894 [D loss: 0.457023, acc: 83.59%] [G loss: 3.657801]\n",
      "epoch:29 step:22895 [D loss: 0.114604, acc: 98.44%] [G loss: 4.748959]\n",
      "epoch:29 step:22896 [D loss: 0.784385, acc: 53.91%] [G loss: 5.647552]\n",
      "epoch:29 step:22897 [D loss: 0.375500, acc: 77.34%] [G loss: 5.852103]\n",
      "epoch:29 step:22898 [D loss: 0.164315, acc: 100.00%] [G loss: 4.918344]\n",
      "epoch:29 step:22899 [D loss: 0.707605, acc: 57.03%] [G loss: 5.081793]\n",
      "epoch:29 step:22900 [D loss: 0.141767, acc: 99.22%] [G loss: 7.616691]\n",
      "epoch:29 step:22901 [D loss: 0.183541, acc: 99.22%] [G loss: 4.286621]\n",
      "epoch:29 step:22902 [D loss: 0.850524, acc: 51.56%] [G loss: 4.557424]\n",
      "epoch:29 step:22903 [D loss: 0.914916, acc: 50.00%] [G loss: 4.533638]\n",
      "epoch:29 step:22904 [D loss: 0.369200, acc: 81.25%] [G loss: 5.304751]\n",
      "epoch:29 step:22905 [D loss: 0.242375, acc: 91.41%] [G loss: 5.783132]\n",
      "epoch:29 step:22906 [D loss: 0.972639, acc: 51.56%] [G loss: 4.174464]\n",
      "epoch:29 step:22907 [D loss: 0.137012, acc: 99.22%] [G loss: 2.813715]\n",
      "epoch:29 step:22908 [D loss: 0.295117, acc: 85.94%] [G loss: 3.443484]\n",
      "epoch:29 step:22909 [D loss: 0.199706, acc: 99.22%] [G loss: 3.717849]\n",
      "epoch:29 step:22910 [D loss: 0.318069, acc: 89.84%] [G loss: 4.825032]\n",
      "epoch:29 step:22911 [D loss: 0.381912, acc: 76.56%] [G loss: 4.361435]\n",
      "epoch:29 step:22912 [D loss: 0.166363, acc: 99.22%] [G loss: 2.894238]\n",
      "epoch:29 step:22913 [D loss: 0.273198, acc: 96.88%] [G loss: 3.578042]\n",
      "epoch:29 step:22914 [D loss: 0.553921, acc: 61.72%] [G loss: 5.451071]\n",
      "epoch:29 step:22915 [D loss: 0.513794, acc: 67.19%] [G loss: 5.989251]\n",
      "epoch:29 step:22916 [D loss: 1.093308, acc: 20.31%] [G loss: 3.203582]\n",
      "epoch:29 step:22917 [D loss: 0.509262, acc: 72.66%] [G loss: 4.592752]\n",
      "epoch:29 step:22918 [D loss: 0.773235, acc: 52.34%] [G loss: 4.709155]\n",
      "epoch:29 step:22919 [D loss: 0.397159, acc: 86.72%] [G loss: 3.874416]\n",
      "epoch:29 step:22920 [D loss: 0.335839, acc: 89.84%] [G loss: 3.979690]\n",
      "epoch:29 step:22921 [D loss: 0.590657, acc: 57.81%] [G loss: 4.289328]\n",
      "epoch:29 step:22922 [D loss: 0.336555, acc: 92.97%] [G loss: 6.692863]\n",
      "epoch:29 step:22923 [D loss: 0.800726, acc: 55.47%] [G loss: 4.893258]\n",
      "epoch:29 step:22924 [D loss: 0.777857, acc: 50.00%] [G loss: 4.717293]\n",
      "epoch:29 step:22925 [D loss: 0.884370, acc: 48.44%] [G loss: 3.955267]\n",
      "epoch:29 step:22926 [D loss: 0.535202, acc: 58.59%] [G loss: 5.709876]\n",
      "epoch:29 step:22927 [D loss: 0.891141, acc: 49.22%] [G loss: 4.168886]\n",
      "epoch:29 step:22928 [D loss: 1.197663, acc: 14.84%] [G loss: 3.125384]\n",
      "epoch:29 step:22929 [D loss: 0.202989, acc: 95.31%] [G loss: 3.968772]\n",
      "epoch:29 step:22930 [D loss: 0.153566, acc: 97.66%] [G loss: 5.103146]\n",
      "epoch:29 step:22931 [D loss: 0.279918, acc: 93.75%] [G loss: 3.237959]\n",
      "epoch:29 step:22932 [D loss: 0.383057, acc: 89.06%] [G loss: 3.471061]\n",
      "epoch:29 step:22933 [D loss: 0.264538, acc: 93.75%] [G loss: 2.237803]\n",
      "epoch:29 step:22934 [D loss: 0.128068, acc: 97.66%] [G loss: 6.038006]\n",
      "epoch:29 step:22935 [D loss: 0.735542, acc: 48.44%] [G loss: 6.707398]\n",
      "epoch:29 step:22936 [D loss: 0.404783, acc: 93.75%] [G loss: 3.406336]\n",
      "epoch:29 step:22937 [D loss: 0.395440, acc: 75.00%] [G loss: 4.827563]\n",
      "epoch:29 step:22938 [D loss: 0.989576, acc: 41.41%] [G loss: 4.286022]\n",
      "epoch:29 step:22939 [D loss: 0.194224, acc: 99.22%] [G loss: 3.347829]\n",
      "epoch:29 step:22940 [D loss: 0.481344, acc: 83.59%] [G loss: 3.486609]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:29 step:22941 [D loss: 0.640099, acc: 64.06%] [G loss: 5.103500]\n",
      "epoch:29 step:22942 [D loss: 0.198757, acc: 99.22%] [G loss: 1.234369]\n",
      "epoch:29 step:22943 [D loss: 0.469987, acc: 82.81%] [G loss: 3.540328]\n",
      "epoch:29 step:22944 [D loss: 0.152490, acc: 98.44%] [G loss: 3.242810]\n",
      "epoch:29 step:22945 [D loss: 0.176400, acc: 97.66%] [G loss: 3.761887]\n",
      "epoch:29 step:22946 [D loss: 0.382220, acc: 89.06%] [G loss: 2.510183]\n",
      "epoch:29 step:22947 [D loss: 0.996274, acc: 23.44%] [G loss: 4.020537]\n",
      "epoch:29 step:22948 [D loss: 0.222203, acc: 99.22%] [G loss: 4.730654]\n",
      "epoch:29 step:22949 [D loss: 0.579377, acc: 71.88%] [G loss: 5.070937]\n",
      "epoch:29 step:22950 [D loss: 0.411470, acc: 88.28%] [G loss: 3.750306]\n",
      "epoch:29 step:22951 [D loss: 0.276066, acc: 97.66%] [G loss: 3.517473]\n",
      "epoch:29 step:22952 [D loss: 0.189639, acc: 98.44%] [G loss: 6.111055]\n",
      "epoch:29 step:22953 [D loss: 0.650110, acc: 59.38%] [G loss: 5.305031]\n",
      "epoch:29 step:22954 [D loss: 0.403033, acc: 74.22%] [G loss: 5.285623]\n",
      "epoch:29 step:22955 [D loss: 0.452659, acc: 82.81%] [G loss: 4.562765]\n",
      "epoch:29 step:22956 [D loss: 0.350806, acc: 87.50%] [G loss: 3.072801]\n",
      "epoch:29 step:22957 [D loss: 0.502457, acc: 78.12%] [G loss: 4.512152]\n",
      "epoch:29 step:22958 [D loss: 0.246549, acc: 96.09%] [G loss: 4.553290]\n",
      "epoch:29 step:22959 [D loss: 0.467488, acc: 75.00%] [G loss: 4.945304]\n",
      "epoch:29 step:22960 [D loss: 0.055110, acc: 100.00%] [G loss: 4.135739]\n",
      "epoch:29 step:22961 [D loss: 0.291234, acc: 91.41%] [G loss: 4.163270]\n",
      "epoch:29 step:22962 [D loss: 0.230021, acc: 95.31%] [G loss: 3.118853]\n",
      "epoch:29 step:22963 [D loss: 0.352971, acc: 79.69%] [G loss: 3.386141]\n",
      "epoch:29 step:22964 [D loss: 0.464368, acc: 76.56%] [G loss: 2.719931]\n",
      "epoch:29 step:22965 [D loss: 0.821176, acc: 40.62%] [G loss: 3.549233]\n",
      "epoch:29 step:22966 [D loss: 0.220707, acc: 98.44%] [G loss: 2.708237]\n",
      "epoch:29 step:22967 [D loss: 0.370763, acc: 89.84%] [G loss: 3.615345]\n",
      "epoch:29 step:22968 [D loss: 0.382876, acc: 89.06%] [G loss: 3.499098]\n",
      "epoch:29 step:22969 [D loss: 0.508158, acc: 81.25%] [G loss: 3.825677]\n",
      "epoch:29 step:22970 [D loss: 0.129918, acc: 99.22%] [G loss: 3.594978]\n",
      "epoch:29 step:22971 [D loss: 1.150124, acc: 29.69%] [G loss: 4.267813]\n",
      "epoch:29 step:22972 [D loss: 1.208035, acc: 50.00%] [G loss: 2.476679]\n",
      "epoch:29 step:22973 [D loss: 1.142333, acc: 39.84%] [G loss: 4.918018]\n",
      "epoch:29 step:22974 [D loss: 0.229882, acc: 96.88%] [G loss: 5.990940]\n",
      "epoch:29 step:22975 [D loss: 0.437929, acc: 74.22%] [G loss: 4.580194]\n",
      "epoch:29 step:22976 [D loss: 0.286399, acc: 93.75%] [G loss: 4.425816]\n",
      "epoch:29 step:22977 [D loss: 0.385034, acc: 84.38%] [G loss: 5.745240]\n",
      "epoch:29 step:22978 [D loss: 0.182740, acc: 96.09%] [G loss: 5.474864]\n",
      "epoch:29 step:22979 [D loss: 0.139898, acc: 99.22%] [G loss: 2.926475]\n",
      "epoch:29 step:22980 [D loss: 0.314705, acc: 85.16%] [G loss: 4.872531]\n",
      "epoch:29 step:22981 [D loss: 0.713931, acc: 54.69%] [G loss: 2.499274]\n",
      "epoch:29 step:22982 [D loss: 0.469445, acc: 68.75%] [G loss: 2.923397]\n",
      "epoch:29 step:22983 [D loss: 0.776592, acc: 53.91%] [G loss: 4.259352]\n",
      "epoch:29 step:22984 [D loss: 0.017611, acc: 100.00%] [G loss: 4.989387]\n",
      "epoch:29 step:22985 [D loss: 0.167185, acc: 97.66%] [G loss: 5.381375]\n",
      "epoch:29 step:22986 [D loss: 1.033971, acc: 42.97%] [G loss: 4.456790]\n",
      "epoch:29 step:22987 [D loss: 0.646296, acc: 59.38%] [G loss: 6.120871]\n",
      "epoch:29 step:22988 [D loss: 0.553378, acc: 63.28%] [G loss: 5.167696]\n",
      "epoch:29 step:22989 [D loss: 0.174802, acc: 99.22%] [G loss: 4.961685]\n",
      "epoch:29 step:22990 [D loss: 0.887716, acc: 52.34%] [G loss: 4.427524]\n",
      "epoch:29 step:22991 [D loss: 0.927732, acc: 36.72%] [G loss: 5.444774]\n",
      "epoch:29 step:22992 [D loss: 0.529293, acc: 67.19%] [G loss: 4.507655]\n",
      "epoch:29 step:22993 [D loss: 0.175572, acc: 97.66%] [G loss: 5.399318]\n",
      "epoch:29 step:22994 [D loss: 0.892708, acc: 36.72%] [G loss: 5.214151]\n",
      "epoch:29 step:22995 [D loss: 0.175220, acc: 100.00%] [G loss: 2.890880]\n",
      "epoch:29 step:22996 [D loss: 0.234109, acc: 94.53%] [G loss: 3.615966]\n",
      "epoch:29 step:22997 [D loss: 0.973467, acc: 41.41%] [G loss: 2.904293]\n",
      "epoch:29 step:22998 [D loss: 0.595409, acc: 67.19%] [G loss: 5.967346]\n",
      "epoch:29 step:22999 [D loss: 0.469060, acc: 64.06%] [G loss: 3.002487]\n",
      "epoch:29 step:23000 [D loss: 0.730465, acc: 52.34%] [G loss: 3.874320]\n",
      "##############\n",
      "[0.84065738 0.88738406 0.82710272 0.81998071 0.766961   0.83825791\n",
      " 0.86495368 0.8390106  0.82882769 0.84274267]\n",
      "##########\n",
      "epoch:29 step:23001 [D loss: 0.139550, acc: 98.44%] [G loss: 3.719019]\n",
      "epoch:29 step:23002 [D loss: 0.307630, acc: 92.97%] [G loss: 4.552618]\n",
      "epoch:29 step:23003 [D loss: 0.472480, acc: 79.69%] [G loss: 4.048131]\n",
      "epoch:29 step:23004 [D loss: 0.924187, acc: 49.22%] [G loss: 4.478237]\n",
      "epoch:29 step:23005 [D loss: 0.470818, acc: 64.84%] [G loss: 5.101624]\n",
      "epoch:29 step:23006 [D loss: 1.641051, acc: 26.56%] [G loss: 4.011926]\n",
      "epoch:29 step:23007 [D loss: 0.165744, acc: 99.22%] [G loss: 3.267344]\n",
      "epoch:29 step:23008 [D loss: 0.384342, acc: 79.69%] [G loss: 6.317095]\n",
      "epoch:29 step:23009 [D loss: 0.062717, acc: 100.00%] [G loss: 6.082973]\n",
      "epoch:29 step:23010 [D loss: 0.673690, acc: 55.47%] [G loss: 3.873085]\n",
      "epoch:29 step:23011 [D loss: 0.391896, acc: 85.94%] [G loss: 4.621149]\n",
      "epoch:29 step:23012 [D loss: 0.083616, acc: 100.00%] [G loss: 2.803530]\n",
      "epoch:29 step:23013 [D loss: 0.703602, acc: 51.56%] [G loss: 3.648613]\n",
      "epoch:29 step:23014 [D loss: 0.455228, acc: 71.09%] [G loss: 5.672974]\n",
      "epoch:29 step:23015 [D loss: 0.728591, acc: 53.91%] [G loss: 5.277180]\n",
      "epoch:29 step:23016 [D loss: 0.494776, acc: 71.09%] [G loss: 4.705121]\n",
      "epoch:29 step:23017 [D loss: 0.408196, acc: 79.69%] [G loss: 5.898597]\n",
      "epoch:29 step:23018 [D loss: 0.242554, acc: 92.19%] [G loss: 6.828735]\n",
      "epoch:29 step:23019 [D loss: 0.560744, acc: 60.16%] [G loss: 2.789049]\n",
      "epoch:29 step:23020 [D loss: 0.182061, acc: 99.22%] [G loss: 4.148905]\n",
      "epoch:29 step:23021 [D loss: 0.462550, acc: 67.97%] [G loss: 3.882068]\n",
      "epoch:29 step:23022 [D loss: 0.707471, acc: 57.03%] [G loss: 4.619619]\n",
      "epoch:29 step:23023 [D loss: 0.306337, acc: 92.19%] [G loss: 4.796248]\n",
      "epoch:29 step:23024 [D loss: 0.237857, acc: 96.88%] [G loss: 4.193480]\n",
      "epoch:29 step:23025 [D loss: 0.091306, acc: 98.44%] [G loss: 4.994593]\n",
      "epoch:29 step:23026 [D loss: 0.201634, acc: 96.09%] [G loss: 4.862204]\n",
      "epoch:29 step:23027 [D loss: 0.145897, acc: 99.22%] [G loss: 5.003975]\n",
      "epoch:29 step:23028 [D loss: 0.058913, acc: 100.00%] [G loss: 5.092755]\n",
      "epoch:29 step:23029 [D loss: 0.385883, acc: 80.47%] [G loss: 4.530667]\n",
      "epoch:29 step:23030 [D loss: 0.207890, acc: 95.31%] [G loss: 3.744399]\n",
      "epoch:29 step:23031 [D loss: 0.212721, acc: 96.88%] [G loss: 3.702271]\n",
      "epoch:29 step:23032 [D loss: 0.287864, acc: 96.88%] [G loss: 6.009514]\n",
      "epoch:29 step:23033 [D loss: 0.111505, acc: 100.00%] [G loss: 3.858148]\n",
      "epoch:29 step:23034 [D loss: 0.662244, acc: 55.47%] [G loss: 5.941606]\n",
      "epoch:29 step:23035 [D loss: 1.044992, acc: 49.22%] [G loss: 5.760964]\n",
      "epoch:29 step:23036 [D loss: 0.122338, acc: 100.00%] [G loss: 4.882314]\n",
      "epoch:29 step:23037 [D loss: 0.536142, acc: 77.34%] [G loss: 5.507617]\n",
      "epoch:29 step:23038 [D loss: 0.130751, acc: 100.00%] [G loss: 4.706458]\n",
      "epoch:29 step:23039 [D loss: 0.146915, acc: 100.00%] [G loss: 4.949950]\n",
      "epoch:29 step:23040 [D loss: 0.273852, acc: 92.19%] [G loss: 5.722830]\n",
      "epoch:29 step:23041 [D loss: 0.114495, acc: 100.00%] [G loss: 2.649053]\n",
      "epoch:29 step:23042 [D loss: 0.410929, acc: 85.16%] [G loss: 5.154602]\n",
      "epoch:29 step:23043 [D loss: 0.055653, acc: 100.00%] [G loss: 8.474782]\n",
      "epoch:29 step:23044 [D loss: 0.158005, acc: 98.44%] [G loss: 3.261763]\n",
      "epoch:29 step:23045 [D loss: 0.430166, acc: 75.78%] [G loss: 5.898360]\n",
      "epoch:29 step:23046 [D loss: 0.205843, acc: 99.22%] [G loss: 3.983075]\n",
      "epoch:29 step:23047 [D loss: 1.196655, acc: 42.19%] [G loss: 2.011854]\n",
      "epoch:29 step:23048 [D loss: 0.094631, acc: 99.22%] [G loss: 3.140526]\n",
      "epoch:29 step:23049 [D loss: 0.040449, acc: 100.00%] [G loss: 5.393063]\n",
      "epoch:29 step:23050 [D loss: 0.058444, acc: 100.00%] [G loss: 6.877657]\n",
      "epoch:29 step:23051 [D loss: 0.341162, acc: 89.84%] [G loss: 5.531626]\n",
      "epoch:29 step:23052 [D loss: 0.244825, acc: 90.62%] [G loss: 4.543538]\n",
      "epoch:29 step:23053 [D loss: 0.793600, acc: 45.31%] [G loss: 2.296406]\n",
      "epoch:29 step:23054 [D loss: 0.840702, acc: 42.19%] [G loss: 4.120941]\n",
      "epoch:29 step:23055 [D loss: 0.222647, acc: 98.44%] [G loss: 3.077551]\n",
      "epoch:29 step:23056 [D loss: 0.247614, acc: 98.44%] [G loss: 5.880436]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:29 step:23057 [D loss: 0.068080, acc: 99.22%] [G loss: 7.217346]\n",
      "epoch:29 step:23058 [D loss: 0.151166, acc: 96.09%] [G loss: 4.975880]\n",
      "epoch:29 step:23059 [D loss: 0.622926, acc: 62.50%] [G loss: 4.292239]\n",
      "epoch:29 step:23060 [D loss: 0.139452, acc: 99.22%] [G loss: 3.787842]\n",
      "epoch:29 step:23061 [D loss: 0.029624, acc: 100.00%] [G loss: 7.547671]\n",
      "epoch:29 step:23062 [D loss: 0.541539, acc: 59.38%] [G loss: 5.207719]\n",
      "epoch:29 step:23063 [D loss: 0.211845, acc: 99.22%] [G loss: 2.751478]\n",
      "epoch:29 step:23064 [D loss: 0.994106, acc: 40.62%] [G loss: 2.883141]\n",
      "epoch:29 step:23065 [D loss: 0.427867, acc: 82.03%] [G loss: 4.701592]\n",
      "epoch:29 step:23066 [D loss: 0.214188, acc: 94.53%] [G loss: 4.216663]\n",
      "epoch:29 step:23067 [D loss: 0.130526, acc: 100.00%] [G loss: 5.108025]\n",
      "epoch:29 step:23068 [D loss: 0.302034, acc: 86.72%] [G loss: 4.137252]\n",
      "epoch:29 step:23069 [D loss: 0.126397, acc: 99.22%] [G loss: 6.244098]\n",
      "epoch:29 step:23070 [D loss: 0.183529, acc: 97.66%] [G loss: 6.722695]\n",
      "epoch:29 step:23071 [D loss: 0.017327, acc: 100.00%] [G loss: 5.810376]\n",
      "epoch:29 step:23072 [D loss: 0.757823, acc: 55.47%] [G loss: 3.680790]\n",
      "epoch:29 step:23073 [D loss: 1.006497, acc: 50.00%] [G loss: 4.356277]\n",
      "epoch:29 step:23074 [D loss: 0.746053, acc: 53.91%] [G loss: 3.938998]\n",
      "epoch:29 step:23075 [D loss: 0.024133, acc: 100.00%] [G loss: 4.433435]\n",
      "epoch:29 step:23076 [D loss: 0.333152, acc: 89.06%] [G loss: 2.875531]\n",
      "epoch:29 step:23077 [D loss: 0.222479, acc: 94.53%] [G loss: 4.362248]\n",
      "epoch:29 step:23078 [D loss: 0.744515, acc: 53.12%] [G loss: 4.102448]\n",
      "epoch:29 step:23079 [D loss: 0.800153, acc: 50.00%] [G loss: 4.758230]\n",
      "epoch:29 step:23080 [D loss: 0.323166, acc: 88.28%] [G loss: 4.595998]\n",
      "epoch:29 step:23081 [D loss: 0.087945, acc: 100.00%] [G loss: 1.015344]\n",
      "epoch:29 step:23082 [D loss: 0.653842, acc: 64.06%] [G loss: 3.090257]\n",
      "epoch:29 step:23083 [D loss: 0.230092, acc: 94.53%] [G loss: 5.460854]\n",
      "epoch:29 step:23084 [D loss: 0.096906, acc: 100.00%] [G loss: 5.935455]\n",
      "epoch:29 step:23085 [D loss: 0.341841, acc: 80.47%] [G loss: 5.555028]\n",
      "epoch:29 step:23086 [D loss: 0.267392, acc: 92.19%] [G loss: 3.661440]\n",
      "epoch:29 step:23087 [D loss: 1.316295, acc: 49.22%] [G loss: 2.735457]\n",
      "epoch:29 step:23088 [D loss: 0.196753, acc: 99.22%] [G loss: 4.482798]\n",
      "epoch:29 step:23089 [D loss: 1.122380, acc: 42.97%] [G loss: 3.122030]\n",
      "epoch:29 step:23090 [D loss: 0.259478, acc: 97.66%] [G loss: 4.238131]\n",
      "epoch:29 step:23091 [D loss: 0.437583, acc: 71.88%] [G loss: 4.124235]\n",
      "epoch:29 step:23092 [D loss: 0.333564, acc: 92.97%] [G loss: 4.375366]\n",
      "epoch:29 step:23093 [D loss: 0.506760, acc: 71.88%] [G loss: 3.341271]\n",
      "epoch:29 step:23094 [D loss: 0.617185, acc: 66.41%] [G loss: 2.860085]\n",
      "epoch:29 step:23095 [D loss: 0.373099, acc: 80.47%] [G loss: 3.629007]\n",
      "epoch:29 step:23096 [D loss: 0.742764, acc: 52.34%] [G loss: 4.705386]\n",
      "epoch:29 step:23097 [D loss: 0.311071, acc: 89.84%] [G loss: 4.356379]\n",
      "epoch:29 step:23098 [D loss: 0.362128, acc: 83.59%] [G loss: 3.547854]\n",
      "epoch:29 step:23099 [D loss: 0.703601, acc: 54.69%] [G loss: 4.205873]\n",
      "epoch:29 step:23100 [D loss: 0.627234, acc: 60.94%] [G loss: 3.210376]\n",
      "epoch:29 step:23101 [D loss: 0.176274, acc: 98.44%] [G loss: 3.159514]\n",
      "epoch:29 step:23102 [D loss: 0.137729, acc: 100.00%] [G loss: 3.719815]\n",
      "epoch:29 step:23103 [D loss: 0.247921, acc: 96.88%] [G loss: 4.044892]\n",
      "epoch:29 step:23104 [D loss: 0.527384, acc: 72.66%] [G loss: 4.517829]\n",
      "epoch:29 step:23105 [D loss: 0.238906, acc: 96.88%] [G loss: 3.247657]\n",
      "epoch:29 step:23106 [D loss: 0.577287, acc: 60.94%] [G loss: 2.692158]\n",
      "epoch:29 step:23107 [D loss: 0.286030, acc: 89.84%] [G loss: 3.583933]\n",
      "epoch:29 step:23108 [D loss: 0.086846, acc: 100.00%] [G loss: 5.390240]\n",
      "epoch:29 step:23109 [D loss: 0.929810, acc: 50.00%] [G loss: 3.941432]\n",
      "epoch:29 step:23110 [D loss: 0.155699, acc: 100.00%] [G loss: 6.579138]\n",
      "epoch:29 step:23111 [D loss: 0.142822, acc: 96.88%] [G loss: 4.157548]\n",
      "epoch:29 step:23112 [D loss: 0.598199, acc: 70.31%] [G loss: 4.340158]\n",
      "epoch:29 step:23113 [D loss: 0.264293, acc: 92.19%] [G loss: 5.676203]\n",
      "epoch:29 step:23114 [D loss: 0.309061, acc: 87.50%] [G loss: 4.872567]\n",
      "epoch:29 step:23115 [D loss: 0.086846, acc: 99.22%] [G loss: 4.699069]\n",
      "epoch:29 step:23116 [D loss: 0.710740, acc: 53.12%] [G loss: 5.124961]\n",
      "epoch:29 step:23117 [D loss: 0.242327, acc: 96.09%] [G loss: 3.271998]\n",
      "epoch:29 step:23118 [D loss: 0.378204, acc: 80.47%] [G loss: 4.674571]\n",
      "epoch:29 step:23119 [D loss: 1.220924, acc: 15.62%] [G loss: 6.132462]\n",
      "epoch:29 step:23120 [D loss: 0.732690, acc: 51.56%] [G loss: 4.398656]\n",
      "epoch:29 step:23121 [D loss: 0.749578, acc: 58.59%] [G loss: 4.984443]\n",
      "epoch:29 step:23122 [D loss: 0.746610, acc: 52.34%] [G loss: 4.628274]\n",
      "epoch:29 step:23123 [D loss: 0.637828, acc: 64.84%] [G loss: 3.738104]\n",
      "epoch:29 step:23124 [D loss: 0.237483, acc: 94.53%] [G loss: 4.166002]\n",
      "epoch:29 step:23125 [D loss: 0.509987, acc: 76.56%] [G loss: 3.110913]\n",
      "epoch:29 step:23126 [D loss: 0.413424, acc: 85.16%] [G loss: 3.874116]\n",
      "epoch:29 step:23127 [D loss: 0.115121, acc: 99.22%] [G loss: 4.197063]\n",
      "epoch:29 step:23128 [D loss: 0.371128, acc: 89.06%] [G loss: 1.781255]\n",
      "epoch:29 step:23129 [D loss: 0.622486, acc: 69.53%] [G loss: 4.481606]\n",
      "epoch:29 step:23130 [D loss: 0.868164, acc: 49.22%] [G loss: 3.074401]\n",
      "epoch:29 step:23131 [D loss: 0.845704, acc: 52.34%] [G loss: 5.074582]\n",
      "epoch:29 step:23132 [D loss: 0.802072, acc: 53.91%] [G loss: 4.700640]\n",
      "epoch:29 step:23133 [D loss: 0.726422, acc: 54.69%] [G loss: 4.410193]\n",
      "epoch:29 step:23134 [D loss: 0.672813, acc: 56.25%] [G loss: 4.957056]\n",
      "epoch:29 step:23135 [D loss: 1.151706, acc: 19.53%] [G loss: 5.456369]\n",
      "epoch:29 step:23136 [D loss: 1.445151, acc: 49.22%] [G loss: 6.170076]\n",
      "epoch:29 step:23137 [D loss: 0.261090, acc: 95.31%] [G loss: 3.472809]\n",
      "epoch:29 step:23138 [D loss: 0.546103, acc: 68.75%] [G loss: 5.749214]\n",
      "epoch:29 step:23139 [D loss: 0.245946, acc: 92.19%] [G loss: 6.922747]\n",
      "epoch:29 step:23140 [D loss: 0.354122, acc: 90.62%] [G loss: 3.766952]\n",
      "epoch:29 step:23141 [D loss: 0.711773, acc: 52.34%] [G loss: 5.113902]\n",
      "epoch:29 step:23142 [D loss: 0.243297, acc: 93.75%] [G loss: 5.153601]\n",
      "epoch:29 step:23143 [D loss: 0.108577, acc: 100.00%] [G loss: 5.324767]\n",
      "epoch:29 step:23144 [D loss: 0.291268, acc: 92.19%] [G loss: 3.482703]\n",
      "epoch:29 step:23145 [D loss: 0.793175, acc: 51.56%] [G loss: 5.412210]\n",
      "epoch:29 step:23146 [D loss: 0.253878, acc: 89.06%] [G loss: 5.798641]\n",
      "epoch:29 step:23147 [D loss: 0.213375, acc: 94.53%] [G loss: 5.573952]\n",
      "epoch:29 step:23148 [D loss: 0.149534, acc: 100.00%] [G loss: 4.517033]\n",
      "epoch:29 step:23149 [D loss: 0.560269, acc: 63.28%] [G loss: 5.223463]\n",
      "epoch:29 step:23150 [D loss: 0.117013, acc: 100.00%] [G loss: 4.565106]\n",
      "epoch:29 step:23151 [D loss: 0.178213, acc: 98.44%] [G loss: 2.297161]\n",
      "epoch:29 step:23152 [D loss: 0.039157, acc: 100.00%] [G loss: 3.842687]\n",
      "epoch:29 step:23153 [D loss: 0.265757, acc: 96.88%] [G loss: 3.959838]\n",
      "epoch:29 step:23154 [D loss: 0.641721, acc: 60.16%] [G loss: 3.577559]\n",
      "epoch:29 step:23155 [D loss: 0.719508, acc: 53.12%] [G loss: 3.962649]\n",
      "epoch:29 step:23156 [D loss: 0.033709, acc: 100.00%] [G loss: 2.143763]\n",
      "epoch:29 step:23157 [D loss: 0.172082, acc: 99.22%] [G loss: 4.556064]\n",
      "epoch:29 step:23158 [D loss: 0.360683, acc: 91.41%] [G loss: 2.549551]\n",
      "epoch:29 step:23159 [D loss: 0.284448, acc: 95.31%] [G loss: 3.363263]\n",
      "epoch:29 step:23160 [D loss: 0.027073, acc: 100.00%] [G loss: 7.372951]\n",
      "epoch:29 step:23161 [D loss: 0.215271, acc: 94.53%] [G loss: 4.997223]\n",
      "epoch:29 step:23162 [D loss: 0.585160, acc: 67.19%] [G loss: 3.471529]\n",
      "epoch:29 step:23163 [D loss: 0.523377, acc: 77.34%] [G loss: 4.625762]\n",
      "epoch:29 step:23164 [D loss: 0.128580, acc: 100.00%] [G loss: 3.763965]\n",
      "epoch:29 step:23165 [D loss: 0.144982, acc: 99.22%] [G loss: 3.870547]\n",
      "epoch:29 step:23166 [D loss: 0.178021, acc: 96.88%] [G loss: 4.517109]\n",
      "epoch:29 step:23167 [D loss: 0.247148, acc: 96.88%] [G loss: 3.961658]\n",
      "epoch:29 step:23168 [D loss: 0.554254, acc: 62.50%] [G loss: 3.820488]\n",
      "epoch:29 step:23169 [D loss: 0.628796, acc: 64.06%] [G loss: 3.855665]\n",
      "epoch:29 step:23170 [D loss: 0.364599, acc: 88.28%] [G loss: 4.022019]\n",
      "epoch:29 step:23171 [D loss: 0.981444, acc: 32.81%] [G loss: 3.464927]\n",
      "epoch:29 step:23172 [D loss: 0.230344, acc: 97.66%] [G loss: 4.301852]\n",
      "epoch:29 step:23173 [D loss: 0.261335, acc: 98.44%] [G loss: 4.562504]\n",
      "epoch:29 step:23174 [D loss: 0.403037, acc: 90.62%] [G loss: 4.614373]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:29 step:23175 [D loss: 0.113703, acc: 99.22%] [G loss: 2.640926]\n",
      "epoch:29 step:23176 [D loss: 0.185114, acc: 99.22%] [G loss: 4.845546]\n",
      "epoch:29 step:23177 [D loss: 0.420110, acc: 87.50%] [G loss: 1.824814]\n",
      "epoch:29 step:23178 [D loss: 0.400595, acc: 89.84%] [G loss: 3.913852]\n",
      "epoch:29 step:23179 [D loss: 0.667208, acc: 61.72%] [G loss: 5.023406]\n",
      "epoch:29 step:23180 [D loss: 0.138294, acc: 100.00%] [G loss: 3.420116]\n",
      "epoch:29 step:23181 [D loss: 0.469777, acc: 78.12%] [G loss: 3.903558]\n",
      "epoch:29 step:23182 [D loss: 0.325382, acc: 79.69%] [G loss: 5.592592]\n",
      "epoch:29 step:23183 [D loss: 0.165862, acc: 99.22%] [G loss: 3.252130]\n",
      "epoch:29 step:23184 [D loss: 0.540905, acc: 68.75%] [G loss: 3.982521]\n",
      "epoch:29 step:23185 [D loss: 0.232123, acc: 97.66%] [G loss: 4.486187]\n",
      "epoch:29 step:23186 [D loss: 0.424211, acc: 89.84%] [G loss: 4.328793]\n",
      "epoch:29 step:23187 [D loss: 0.148275, acc: 98.44%] [G loss: 3.429972]\n",
      "epoch:29 step:23188 [D loss: 0.200844, acc: 99.22%] [G loss: 3.456209]\n",
      "epoch:29 step:23189 [D loss: 0.476955, acc: 67.19%] [G loss: 6.590694]\n",
      "epoch:29 step:23190 [D loss: 0.638133, acc: 56.25%] [G loss: 4.370885]\n",
      "epoch:29 step:23191 [D loss: 0.086997, acc: 100.00%] [G loss: 4.812571]\n",
      "epoch:29 step:23192 [D loss: 0.577576, acc: 58.59%] [G loss: 4.406338]\n",
      "epoch:29 step:23193 [D loss: 0.825779, acc: 53.91%] [G loss: 5.482463]\n",
      "epoch:29 step:23194 [D loss: 0.579170, acc: 71.09%] [G loss: 5.711682]\n",
      "epoch:29 step:23195 [D loss: 0.894107, acc: 44.53%] [G loss: 5.585280]\n",
      "epoch:29 step:23196 [D loss: 0.320619, acc: 93.75%] [G loss: 6.348898]\n",
      "epoch:29 step:23197 [D loss: 0.243704, acc: 97.66%] [G loss: 4.779774]\n",
      "epoch:29 step:23198 [D loss: 0.952615, acc: 50.00%] [G loss: 4.857309]\n",
      "epoch:29 step:23199 [D loss: 0.299667, acc: 85.16%] [G loss: 3.864124]\n",
      "epoch:29 step:23200 [D loss: 0.648867, acc: 56.25%] [G loss: 5.163720]\n",
      "##############\n",
      "[0.86174709 0.85790601 0.82128995 0.80932232 0.79539283 0.84138415\n",
      " 0.87870426 0.83778884 0.80827983 0.84415269]\n",
      "##########\n",
      "epoch:29 step:23201 [D loss: 0.923776, acc: 52.34%] [G loss: 4.502396]\n",
      "epoch:29 step:23202 [D loss: 0.541812, acc: 67.97%] [G loss: 5.395600]\n",
      "epoch:29 step:23203 [D loss: 0.767483, acc: 52.34%] [G loss: 4.282087]\n",
      "epoch:29 step:23204 [D loss: 0.010587, acc: 100.00%] [G loss: 7.230304]\n",
      "epoch:29 step:23205 [D loss: 0.507570, acc: 61.72%] [G loss: 5.236577]\n",
      "epoch:29 step:23206 [D loss: 0.081291, acc: 100.00%] [G loss: 3.477534]\n",
      "epoch:29 step:23207 [D loss: 0.768321, acc: 55.47%] [G loss: 3.801645]\n",
      "epoch:29 step:23208 [D loss: 0.325339, acc: 91.41%] [G loss: 5.008048]\n",
      "epoch:29 step:23209 [D loss: 0.227064, acc: 95.31%] [G loss: 4.220206]\n",
      "epoch:29 step:23210 [D loss: 0.201662, acc: 99.22%] [G loss: 4.809965]\n",
      "epoch:29 step:23211 [D loss: 0.595264, acc: 61.72%] [G loss: 3.176805]\n",
      "epoch:29 step:23212 [D loss: 0.234131, acc: 96.88%] [G loss: 3.684658]\n",
      "epoch:29 step:23213 [D loss: 1.012913, acc: 23.44%] [G loss: 4.393868]\n",
      "epoch:29 step:23214 [D loss: 0.332974, acc: 89.84%] [G loss: 2.633049]\n",
      "epoch:29 step:23215 [D loss: 0.079618, acc: 100.00%] [G loss: 4.182545]\n",
      "epoch:29 step:23216 [D loss: 0.395075, acc: 92.19%] [G loss: 3.343880]\n",
      "epoch:29 step:23217 [D loss: 0.401676, acc: 79.69%] [G loss: 6.880432]\n",
      "epoch:29 step:23218 [D loss: 0.171354, acc: 98.44%] [G loss: 5.297153]\n",
      "epoch:29 step:23219 [D loss: 0.354976, acc: 86.72%] [G loss: 4.609473]\n",
      "epoch:29 step:23220 [D loss: 0.321027, acc: 92.97%] [G loss: 3.493797]\n",
      "epoch:29 step:23221 [D loss: 0.321715, acc: 94.53%] [G loss: 5.110482]\n",
      "epoch:29 step:23222 [D loss: 0.188180, acc: 99.22%] [G loss: 5.417725]\n",
      "epoch:29 step:23223 [D loss: 0.529591, acc: 67.97%] [G loss: 4.153884]\n",
      "epoch:29 step:23224 [D loss: 0.278869, acc: 92.97%] [G loss: 2.692828]\n",
      "epoch:29 step:23225 [D loss: 0.527161, acc: 62.50%] [G loss: 4.651383]\n",
      "epoch:29 step:23226 [D loss: 0.740479, acc: 56.25%] [G loss: 3.982398]\n",
      "epoch:29 step:23227 [D loss: 0.310469, acc: 89.06%] [G loss: 3.116932]\n",
      "epoch:29 step:23228 [D loss: 0.268544, acc: 94.53%] [G loss: 3.256656]\n",
      "epoch:29 step:23229 [D loss: 0.775923, acc: 56.25%] [G loss: 5.693588]\n",
      "epoch:29 step:23230 [D loss: 0.471412, acc: 71.09%] [G loss: 3.413827]\n",
      "epoch:29 step:23231 [D loss: 0.086294, acc: 100.00%] [G loss: 4.788835]\n",
      "epoch:29 step:23232 [D loss: 0.263834, acc: 90.62%] [G loss: 3.195774]\n",
      "epoch:29 step:23233 [D loss: 0.561710, acc: 63.28%] [G loss: 2.880063]\n",
      "epoch:29 step:23234 [D loss: 0.263217, acc: 92.97%] [G loss: 4.619880]\n",
      "epoch:29 step:23235 [D loss: 0.124769, acc: 99.22%] [G loss: 3.918757]\n",
      "epoch:29 step:23236 [D loss: 0.210225, acc: 97.66%] [G loss: 3.929288]\n",
      "epoch:29 step:23237 [D loss: 0.378658, acc: 79.69%] [G loss: 4.989016]\n",
      "epoch:29 step:23238 [D loss: 0.167873, acc: 100.00%] [G loss: 4.428235]\n",
      "epoch:29 step:23239 [D loss: 0.601360, acc: 63.28%] [G loss: 3.719806]\n",
      "epoch:29 step:23240 [D loss: 0.179318, acc: 97.66%] [G loss: 2.476404]\n",
      "epoch:29 step:23241 [D loss: 0.614439, acc: 63.28%] [G loss: 4.420076]\n",
      "epoch:29 step:23242 [D loss: 0.326909, acc: 92.19%] [G loss: 4.282392]\n",
      "epoch:29 step:23243 [D loss: 0.837393, acc: 44.53%] [G loss: 1.776596]\n",
      "epoch:29 step:23244 [D loss: 0.169669, acc: 96.09%] [G loss: 4.179780]\n",
      "epoch:29 step:23245 [D loss: 0.249605, acc: 96.88%] [G loss: 4.044136]\n",
      "epoch:29 step:23246 [D loss: 0.367397, acc: 86.72%] [G loss: 4.153823]\n",
      "epoch:29 step:23247 [D loss: 0.350309, acc: 85.16%] [G loss: 5.577073]\n",
      "epoch:29 step:23248 [D loss: 0.465640, acc: 75.00%] [G loss: 2.266901]\n",
      "epoch:29 step:23249 [D loss: 0.715528, acc: 55.47%] [G loss: 3.225677]\n",
      "epoch:29 step:23250 [D loss: 0.300713, acc: 92.19%] [G loss: 3.489861]\n",
      "epoch:29 step:23251 [D loss: 0.382248, acc: 80.47%] [G loss: 3.554928]\n",
      "epoch:29 step:23252 [D loss: 0.527121, acc: 81.25%] [G loss: 2.759923]\n",
      "epoch:29 step:23253 [D loss: 0.804354, acc: 45.31%] [G loss: 3.563348]\n",
      "epoch:29 step:23254 [D loss: 0.524560, acc: 64.84%] [G loss: 5.383177]\n",
      "epoch:29 step:23255 [D loss: 0.484022, acc: 79.69%] [G loss: 3.636909]\n",
      "epoch:29 step:23256 [D loss: 0.274602, acc: 96.09%] [G loss: 2.491610]\n",
      "epoch:29 step:23257 [D loss: 0.170838, acc: 97.66%] [G loss: 3.902837]\n",
      "epoch:29 step:23258 [D loss: 0.212993, acc: 99.22%] [G loss: 5.242439]\n",
      "epoch:29 step:23259 [D loss: 0.306352, acc: 93.75%] [G loss: 3.614530]\n",
      "epoch:29 step:23260 [D loss: 0.293400, acc: 87.50%] [G loss: 3.629946]\n",
      "epoch:29 step:23261 [D loss: 0.467282, acc: 68.75%] [G loss: 3.775623]\n",
      "epoch:29 step:23262 [D loss: 0.413724, acc: 86.72%] [G loss: 2.039079]\n",
      "epoch:29 step:23263 [D loss: 0.148749, acc: 100.00%] [G loss: 4.318042]\n",
      "epoch:29 step:23264 [D loss: 0.602891, acc: 62.50%] [G loss: 4.001842]\n",
      "epoch:29 step:23265 [D loss: 0.428809, acc: 83.59%] [G loss: 3.325788]\n",
      "epoch:29 step:23266 [D loss: 0.186558, acc: 97.66%] [G loss: 6.128471]\n",
      "epoch:29 step:23267 [D loss: 0.308750, acc: 83.59%] [G loss: 2.958529]\n",
      "epoch:29 step:23268 [D loss: 0.566024, acc: 67.19%] [G loss: 3.439291]\n",
      "epoch:29 step:23269 [D loss: 0.657024, acc: 60.16%] [G loss: 4.407734]\n",
      "epoch:29 step:23270 [D loss: 0.166084, acc: 99.22%] [G loss: 3.946326]\n",
      "epoch:29 step:23271 [D loss: 0.391902, acc: 77.34%] [G loss: 5.697670]\n",
      "epoch:29 step:23272 [D loss: 0.877531, acc: 48.44%] [G loss: 3.705517]\n",
      "epoch:29 step:23273 [D loss: 0.289338, acc: 89.06%] [G loss: 3.207522]\n",
      "epoch:29 step:23274 [D loss: 0.192678, acc: 99.22%] [G loss: 4.442914]\n",
      "epoch:29 step:23275 [D loss: 0.495737, acc: 68.75%] [G loss: 4.545239]\n",
      "epoch:29 step:23276 [D loss: 0.654175, acc: 65.62%] [G loss: 3.556568]\n",
      "epoch:29 step:23277 [D loss: 0.399222, acc: 90.62%] [G loss: 4.232408]\n",
      "epoch:29 step:23278 [D loss: 0.774645, acc: 55.47%] [G loss: 4.205216]\n",
      "epoch:29 step:23279 [D loss: 0.928089, acc: 50.00%] [G loss: 3.495432]\n",
      "epoch:29 step:23280 [D loss: 0.273072, acc: 94.53%] [G loss: 4.055960]\n",
      "epoch:29 step:23281 [D loss: 0.538102, acc: 61.72%] [G loss: 3.751060]\n",
      "epoch:29 step:23282 [D loss: 1.184085, acc: 17.97%] [G loss: 4.066536]\n",
      "epoch:29 step:23283 [D loss: 0.776043, acc: 51.56%] [G loss: 2.789350]\n",
      "epoch:29 step:23284 [D loss: 0.154146, acc: 98.44%] [G loss: 5.532995]\n",
      "epoch:29 step:23285 [D loss: 0.378535, acc: 87.50%] [G loss: 5.197255]\n",
      "epoch:29 step:23286 [D loss: 1.270880, acc: 21.88%] [G loss: 4.641194]\n",
      "epoch:29 step:23287 [D loss: 0.115525, acc: 100.00%] [G loss: 4.681046]\n",
      "epoch:29 step:23288 [D loss: 0.426358, acc: 70.31%] [G loss: 5.717629]\n",
      "epoch:29 step:23289 [D loss: 0.144764, acc: 100.00%] [G loss: 4.092567]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:29 step:23290 [D loss: 0.103476, acc: 99.22%] [G loss: 2.811095]\n",
      "epoch:29 step:23291 [D loss: 0.519048, acc: 67.97%] [G loss: 3.792864]\n",
      "epoch:29 step:23292 [D loss: 0.379696, acc: 85.16%] [G loss: 6.022260]\n",
      "epoch:29 step:23293 [D loss: 0.434570, acc: 74.22%] [G loss: 3.680660]\n",
      "epoch:29 step:23294 [D loss: 0.421927, acc: 85.94%] [G loss: 4.290466]\n",
      "epoch:29 step:23295 [D loss: 0.545114, acc: 67.19%] [G loss: 4.113014]\n",
      "epoch:29 step:23296 [D loss: 0.241437, acc: 96.09%] [G loss: 2.074870]\n",
      "epoch:29 step:23297 [D loss: 0.426925, acc: 83.59%] [G loss: 3.046268]\n",
      "epoch:29 step:23298 [D loss: 0.482659, acc: 81.25%] [G loss: 1.672005]\n",
      "epoch:29 step:23299 [D loss: 0.123050, acc: 99.22%] [G loss: 6.980613]\n",
      "epoch:29 step:23300 [D loss: 0.410932, acc: 90.62%] [G loss: 4.847398]\n",
      "epoch:29 step:23301 [D loss: 0.373137, acc: 90.62%] [G loss: 2.724330]\n",
      "epoch:29 step:23302 [D loss: 0.107673, acc: 100.00%] [G loss: 7.837011]\n",
      "epoch:29 step:23303 [D loss: 0.356055, acc: 92.97%] [G loss: 4.715904]\n",
      "epoch:29 step:23304 [D loss: 0.175216, acc: 100.00%] [G loss: 5.795042]\n",
      "epoch:29 step:23305 [D loss: 0.478622, acc: 75.78%] [G loss: 6.369036]\n",
      "epoch:29 step:23306 [D loss: 0.058203, acc: 100.00%] [G loss: 3.803006]\n",
      "epoch:29 step:23307 [D loss: 0.779418, acc: 55.47%] [G loss: 4.026036]\n",
      "epoch:29 step:23308 [D loss: 0.369477, acc: 75.78%] [G loss: 4.101046]\n",
      "epoch:29 step:23309 [D loss: 0.929659, acc: 50.78%] [G loss: 3.784921]\n",
      "epoch:29 step:23310 [D loss: 0.320371, acc: 92.97%] [G loss: 4.235075]\n",
      "epoch:29 step:23311 [D loss: 0.113529, acc: 100.00%] [G loss: 7.119987]\n",
      "epoch:29 step:23312 [D loss: 0.513464, acc: 74.22%] [G loss: 3.900231]\n",
      "epoch:29 step:23313 [D loss: 0.276464, acc: 89.84%] [G loss: 3.756899]\n",
      "epoch:29 step:23314 [D loss: 0.383081, acc: 75.00%] [G loss: 3.274071]\n",
      "epoch:29 step:23315 [D loss: 1.209870, acc: 23.44%] [G loss: 4.566785]\n",
      "epoch:29 step:23316 [D loss: 0.295747, acc: 85.16%] [G loss: 4.315242]\n",
      "epoch:29 step:23317 [D loss: 0.278845, acc: 94.53%] [G loss: 3.928643]\n",
      "epoch:29 step:23318 [D loss: 0.349286, acc: 94.53%] [G loss: 3.520210]\n",
      "epoch:29 step:23319 [D loss: 0.353796, acc: 93.75%] [G loss: 5.133969]\n",
      "epoch:29 step:23320 [D loss: 0.157627, acc: 100.00%] [G loss: 4.401593]\n",
      "epoch:29 step:23321 [D loss: 0.258776, acc: 96.88%] [G loss: 5.701385]\n",
      "epoch:29 step:23322 [D loss: 0.168516, acc: 98.44%] [G loss: 4.411199]\n",
      "epoch:29 step:23323 [D loss: 0.096396, acc: 100.00%] [G loss: 5.561883]\n",
      "epoch:29 step:23324 [D loss: 0.374172, acc: 90.62%] [G loss: 3.210937]\n",
      "epoch:29 step:23325 [D loss: 0.450138, acc: 82.03%] [G loss: 5.980432]\n",
      "epoch:29 step:23326 [D loss: 0.261230, acc: 97.66%] [G loss: 4.091407]\n",
      "epoch:29 step:23327 [D loss: 0.310656, acc: 90.62%] [G loss: 4.607491]\n",
      "epoch:29 step:23328 [D loss: 0.105240, acc: 100.00%] [G loss: 4.007087]\n",
      "epoch:29 step:23329 [D loss: 0.133883, acc: 99.22%] [G loss: 4.211828]\n",
      "epoch:29 step:23330 [D loss: 0.813504, acc: 42.19%] [G loss: 5.105622]\n",
      "epoch:29 step:23331 [D loss: 0.281361, acc: 96.88%] [G loss: 3.678487]\n",
      "epoch:29 step:23332 [D loss: 0.098351, acc: 99.22%] [G loss: 5.119945]\n",
      "epoch:29 step:23333 [D loss: 1.360132, acc: 20.31%] [G loss: 5.744135]\n",
      "epoch:29 step:23334 [D loss: 0.123580, acc: 99.22%] [G loss: 4.027076]\n",
      "epoch:29 step:23335 [D loss: 0.084049, acc: 100.00%] [G loss: 3.625143]\n",
      "epoch:29 step:23336 [D loss: 0.046063, acc: 100.00%] [G loss: 2.719754]\n",
      "epoch:29 step:23337 [D loss: 0.314667, acc: 86.72%] [G loss: 5.599914]\n",
      "epoch:29 step:23338 [D loss: 0.738346, acc: 57.81%] [G loss: 3.434858]\n",
      "epoch:29 step:23339 [D loss: 0.087995, acc: 100.00%] [G loss: 5.436012]\n",
      "epoch:29 step:23340 [D loss: 0.146206, acc: 100.00%] [G loss: 7.150440]\n",
      "epoch:29 step:23341 [D loss: 1.081359, acc: 50.78%] [G loss: 6.042391]\n",
      "epoch:29 step:23342 [D loss: 1.203005, acc: 49.22%] [G loss: 3.790273]\n",
      "epoch:29 step:23343 [D loss: 0.499950, acc: 72.66%] [G loss: 2.764528]\n",
      "epoch:29 step:23344 [D loss: 0.310341, acc: 95.31%] [G loss: 2.826420]\n",
      "epoch:29 step:23345 [D loss: 0.492234, acc: 71.88%] [G loss: 4.855539]\n",
      "epoch:29 step:23346 [D loss: 0.199531, acc: 98.44%] [G loss: 4.990266]\n",
      "epoch:29 step:23347 [D loss: 0.360762, acc: 89.06%] [G loss: 5.166328]\n",
      "epoch:29 step:23348 [D loss: 0.280079, acc: 94.53%] [G loss: 5.962376]\n",
      "epoch:29 step:23349 [D loss: 0.444625, acc: 82.81%] [G loss: 3.888755]\n",
      "epoch:29 step:23350 [D loss: 0.197884, acc: 98.44%] [G loss: 2.500109]\n",
      "epoch:29 step:23351 [D loss: 0.519314, acc: 81.25%] [G loss: 4.336543]\n",
      "epoch:29 step:23352 [D loss: 0.124699, acc: 99.22%] [G loss: 5.475458]\n",
      "epoch:29 step:23353 [D loss: 0.127831, acc: 99.22%] [G loss: 3.613300]\n",
      "epoch:29 step:23354 [D loss: 0.260029, acc: 94.53%] [G loss: 5.082896]\n",
      "epoch:29 step:23355 [D loss: 0.227430, acc: 93.75%] [G loss: 5.790620]\n",
      "epoch:29 step:23356 [D loss: 0.450230, acc: 67.19%] [G loss: 3.414394]\n",
      "epoch:29 step:23357 [D loss: 0.161077, acc: 98.44%] [G loss: 6.186317]\n",
      "epoch:29 step:23358 [D loss: 0.228036, acc: 96.09%] [G loss: 4.464158]\n",
      "epoch:29 step:23359 [D loss: 0.345234, acc: 85.16%] [G loss: 4.196526]\n",
      "epoch:29 step:23360 [D loss: 0.079916, acc: 100.00%] [G loss: 7.883585]\n",
      "epoch:29 step:23361 [D loss: 0.282556, acc: 94.53%] [G loss: 3.929900]\n",
      "epoch:29 step:23362 [D loss: 0.305717, acc: 98.44%] [G loss: 6.595093]\n",
      "epoch:29 step:23363 [D loss: 0.432808, acc: 82.81%] [G loss: 3.447439]\n",
      "epoch:29 step:23364 [D loss: 0.785419, acc: 47.66%] [G loss: 5.328881]\n",
      "epoch:29 step:23365 [D loss: 0.266249, acc: 91.41%] [G loss: 5.495014]\n",
      "epoch:29 step:23366 [D loss: 0.262238, acc: 98.44%] [G loss: 6.300150]\n",
      "epoch:29 step:23367 [D loss: 0.154214, acc: 99.22%] [G loss: 6.062934]\n",
      "epoch:29 step:23368 [D loss: 0.034783, acc: 100.00%] [G loss: 6.263181]\n",
      "epoch:29 step:23369 [D loss: 0.028764, acc: 100.00%] [G loss: 3.145742]\n",
      "epoch:29 step:23370 [D loss: 0.705167, acc: 57.81%] [G loss: 4.218492]\n",
      "epoch:29 step:23371 [D loss: 0.650986, acc: 63.28%] [G loss: 7.497384]\n",
      "epoch:29 step:23372 [D loss: 0.256170, acc: 98.44%] [G loss: 6.427142]\n",
      "epoch:29 step:23373 [D loss: 0.547584, acc: 58.59%] [G loss: 4.270222]\n",
      "epoch:29 step:23374 [D loss: 0.690256, acc: 60.16%] [G loss: 1.938665]\n",
      "epoch:29 step:23375 [D loss: 0.184161, acc: 98.44%] [G loss: 5.787413]\n",
      "epoch:29 step:23376 [D loss: 0.645771, acc: 64.06%] [G loss: 4.368169]\n",
      "epoch:29 step:23377 [D loss: 0.161680, acc: 98.44%] [G loss: 5.165886]\n",
      "epoch:29 step:23378 [D loss: 0.130486, acc: 99.22%] [G loss: 3.942583]\n",
      "epoch:29 step:23379 [D loss: 0.862352, acc: 45.31%] [G loss: 6.199628]\n",
      "epoch:29 step:23380 [D loss: 0.123720, acc: 100.00%] [G loss: 3.333799]\n",
      "epoch:29 step:23381 [D loss: 0.655737, acc: 60.94%] [G loss: 5.294827]\n",
      "epoch:29 step:23382 [D loss: 0.237702, acc: 98.44%] [G loss: 5.292358]\n",
      "epoch:29 step:23383 [D loss: 0.995395, acc: 29.69%] [G loss: 3.261805]\n",
      "epoch:29 step:23384 [D loss: 0.366103, acc: 78.91%] [G loss: 6.165555]\n",
      "epoch:29 step:23385 [D loss: 0.144153, acc: 99.22%] [G loss: 4.303813]\n",
      "epoch:29 step:23386 [D loss: 0.621001, acc: 64.84%] [G loss: 4.905201]\n",
      "epoch:29 step:23387 [D loss: 0.105082, acc: 100.00%] [G loss: 3.960129]\n",
      "epoch:29 step:23388 [D loss: 0.378699, acc: 78.12%] [G loss: 4.546495]\n",
      "epoch:29 step:23389 [D loss: 0.427175, acc: 75.00%] [G loss: 3.837946]\n",
      "epoch:29 step:23390 [D loss: 0.682684, acc: 55.47%] [G loss: 4.969645]\n",
      "epoch:29 step:23391 [D loss: 0.861015, acc: 55.47%] [G loss: 3.353006]\n",
      "epoch:29 step:23392 [D loss: 0.230677, acc: 97.66%] [G loss: 3.726382]\n",
      "epoch:29 step:23393 [D loss: 0.531135, acc: 80.47%] [G loss: 4.413547]\n",
      "epoch:29 step:23394 [D loss: 0.108324, acc: 100.00%] [G loss: 4.581965]\n",
      "epoch:29 step:23395 [D loss: 1.122670, acc: 36.72%] [G loss: 5.934955]\n",
      "epoch:29 step:23396 [D loss: 0.882896, acc: 51.56%] [G loss: 4.823607]\n",
      "epoch:29 step:23397 [D loss: 0.142932, acc: 98.44%] [G loss: 3.903872]\n",
      "epoch:29 step:23398 [D loss: 0.898471, acc: 47.66%] [G loss: 5.074110]\n",
      "epoch:29 step:23399 [D loss: 0.068029, acc: 100.00%] [G loss: 3.255701]\n",
      "epoch:29 step:23400 [D loss: 1.213105, acc: 30.47%] [G loss: 7.100278]\n",
      "##############\n",
      "[0.85202055 0.88153842 0.82294678 0.81775073 0.79047117 0.82442701\n",
      " 0.92472672 0.81746581 0.81747632 0.83547719]\n",
      "##########\n",
      "epoch:29 step:23401 [D loss: 0.406380, acc: 74.22%] [G loss: 3.836232]\n",
      "epoch:29 step:23402 [D loss: 0.381962, acc: 93.75%] [G loss: 2.685209]\n",
      "epoch:29 step:23403 [D loss: 0.166178, acc: 97.66%] [G loss: 3.762057]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:29 step:23404 [D loss: 0.292386, acc: 97.66%] [G loss: 4.857891]\n",
      "epoch:29 step:23405 [D loss: 0.414249, acc: 75.00%] [G loss: 6.502017]\n",
      "epoch:29 step:23406 [D loss: 0.126550, acc: 100.00%] [G loss: 6.679150]\n",
      "epoch:29 step:23407 [D loss: 0.079755, acc: 100.00%] [G loss: 4.450356]\n",
      "epoch:29 step:23408 [D loss: 0.636147, acc: 54.69%] [G loss: 3.541462]\n",
      "epoch:29 step:23409 [D loss: 0.195947, acc: 95.31%] [G loss: 8.576687]\n",
      "epoch:29 step:23410 [D loss: 0.479374, acc: 64.84%] [G loss: 6.975210]\n",
      "epoch:29 step:23411 [D loss: 0.187952, acc: 99.22%] [G loss: 6.032839]\n",
      "epoch:29 step:23412 [D loss: 0.344530, acc: 85.16%] [G loss: 4.629892]\n",
      "epoch:29 step:23413 [D loss: 0.574362, acc: 67.19%] [G loss: 4.757881]\n",
      "epoch:29 step:23414 [D loss: 0.409717, acc: 75.00%] [G loss: 7.899710]\n",
      "epoch:29 step:23415 [D loss: 0.379515, acc: 89.06%] [G loss: 2.845078]\n",
      "epoch:29 step:23416 [D loss: 0.066989, acc: 100.00%] [G loss: 5.576867]\n",
      "epoch:29 step:23417 [D loss: 0.136633, acc: 100.00%] [G loss: 4.715589]\n",
      "epoch:29 step:23418 [D loss: 0.357780, acc: 83.59%] [G loss: 4.227849]\n",
      "epoch:29 step:23419 [D loss: 0.691241, acc: 57.03%] [G loss: 5.062994]\n",
      "epoch:29 step:23420 [D loss: 0.158296, acc: 97.66%] [G loss: 5.205276]\n",
      "epoch:29 step:23421 [D loss: 0.544182, acc: 61.72%] [G loss: 3.849831]\n",
      "epoch:29 step:23422 [D loss: 0.038156, acc: 100.00%] [G loss: 5.126081]\n",
      "epoch:29 step:23423 [D loss: 0.504911, acc: 76.56%] [G loss: 6.495411]\n",
      "epoch:29 step:23424 [D loss: 0.800068, acc: 50.00%] [G loss: 5.337916]\n",
      "epoch:29 step:23425 [D loss: 0.379904, acc: 92.19%] [G loss: 4.195517]\n",
      "epoch:29 step:23426 [D loss: 0.832475, acc: 47.66%] [G loss: 4.385779]\n",
      "epoch:29 step:23427 [D loss: 0.320811, acc: 93.75%] [G loss: 3.920131]\n",
      "epoch:29 step:23428 [D loss: 0.098184, acc: 99.22%] [G loss: 4.538784]\n",
      "epoch:29 step:23429 [D loss: 0.942723, acc: 50.00%] [G loss: 3.317887]\n",
      "epoch:29 step:23430 [D loss: 0.752965, acc: 55.47%] [G loss: 3.885834]\n",
      "epoch:30 step:23431 [D loss: 0.098626, acc: 100.00%] [G loss: 5.497897]\n",
      "epoch:30 step:23432 [D loss: 0.597253, acc: 63.28%] [G loss: 5.264123]\n",
      "epoch:30 step:23433 [D loss: 0.141899, acc: 99.22%] [G loss: 8.004770]\n",
      "epoch:30 step:23434 [D loss: 0.366204, acc: 82.81%] [G loss: 3.120106]\n",
      "epoch:30 step:23435 [D loss: 0.352290, acc: 85.16%] [G loss: 3.694600]\n",
      "epoch:30 step:23436 [D loss: 0.156918, acc: 98.44%] [G loss: 4.607285]\n",
      "epoch:30 step:23437 [D loss: 0.221902, acc: 95.31%] [G loss: 4.194539]\n",
      "epoch:30 step:23438 [D loss: 0.771565, acc: 52.34%] [G loss: 3.009860]\n",
      "epoch:30 step:23439 [D loss: 0.167962, acc: 100.00%] [G loss: 6.788587]\n",
      "epoch:30 step:23440 [D loss: 0.478465, acc: 71.88%] [G loss: 4.429660]\n",
      "epoch:30 step:23441 [D loss: 0.166161, acc: 99.22%] [G loss: 4.334028]\n",
      "epoch:30 step:23442 [D loss: 0.723115, acc: 51.56%] [G loss: 3.296205]\n",
      "epoch:30 step:23443 [D loss: 0.279651, acc: 90.62%] [G loss: 3.287000]\n",
      "epoch:30 step:23444 [D loss: 0.194482, acc: 98.44%] [G loss: 1.800144]\n",
      "epoch:30 step:23445 [D loss: 0.675749, acc: 60.94%] [G loss: 3.048418]\n",
      "epoch:30 step:23446 [D loss: 0.803306, acc: 45.31%] [G loss: 4.666268]\n",
      "epoch:30 step:23447 [D loss: 0.858807, acc: 39.06%] [G loss: 6.261297]\n",
      "epoch:30 step:23448 [D loss: 0.232177, acc: 94.53%] [G loss: 6.008522]\n",
      "epoch:30 step:23449 [D loss: 0.272947, acc: 85.16%] [G loss: 7.509130]\n",
      "epoch:30 step:23450 [D loss: 0.071231, acc: 100.00%] [G loss: 5.039295]\n",
      "epoch:30 step:23451 [D loss: 0.160341, acc: 97.66%] [G loss: 3.321165]\n",
      "epoch:30 step:23452 [D loss: 0.085839, acc: 100.00%] [G loss: 4.102236]\n",
      "epoch:30 step:23453 [D loss: 0.355231, acc: 82.03%] [G loss: 4.872344]\n",
      "epoch:30 step:23454 [D loss: 1.261925, acc: 19.53%] [G loss: 4.780720]\n",
      "epoch:30 step:23455 [D loss: 0.781132, acc: 55.47%] [G loss: 3.863298]\n",
      "epoch:30 step:23456 [D loss: 0.884020, acc: 48.44%] [G loss: 5.050723]\n",
      "epoch:30 step:23457 [D loss: 0.889113, acc: 51.56%] [G loss: 5.335312]\n",
      "epoch:30 step:23458 [D loss: 0.224892, acc: 96.09%] [G loss: 3.240028]\n",
      "epoch:30 step:23459 [D loss: 0.064460, acc: 100.00%] [G loss: 6.323156]\n",
      "epoch:30 step:23460 [D loss: 0.010848, acc: 100.00%] [G loss: 4.487167]\n",
      "epoch:30 step:23461 [D loss: 0.268637, acc: 96.09%] [G loss: 5.275744]\n",
      "epoch:30 step:23462 [D loss: 0.312655, acc: 88.28%] [G loss: 2.432443]\n",
      "epoch:30 step:23463 [D loss: 0.639157, acc: 64.84%] [G loss: 1.948474]\n",
      "epoch:30 step:23464 [D loss: 0.808619, acc: 52.34%] [G loss: 4.768573]\n",
      "epoch:30 step:23465 [D loss: 0.923220, acc: 39.06%] [G loss: 3.897170]\n",
      "epoch:30 step:23466 [D loss: 0.023399, acc: 100.00%] [G loss: 5.484576]\n",
      "epoch:30 step:23467 [D loss: 0.220611, acc: 95.31%] [G loss: 5.216669]\n",
      "epoch:30 step:23468 [D loss: 0.369726, acc: 90.62%] [G loss: 5.249228]\n",
      "epoch:30 step:23469 [D loss: 0.535503, acc: 66.41%] [G loss: 3.016683]\n",
      "epoch:30 step:23470 [D loss: 0.661377, acc: 61.72%] [G loss: 3.718587]\n",
      "epoch:30 step:23471 [D loss: 0.132352, acc: 98.44%] [G loss: 2.418564]\n",
      "epoch:30 step:23472 [D loss: 0.639240, acc: 59.38%] [G loss: 3.944962]\n",
      "epoch:30 step:23473 [D loss: 0.542189, acc: 67.19%] [G loss: 3.274029]\n",
      "epoch:30 step:23474 [D loss: 0.507321, acc: 67.97%] [G loss: 3.582604]\n",
      "epoch:30 step:23475 [D loss: 0.188532, acc: 98.44%] [G loss: 4.067967]\n",
      "epoch:30 step:23476 [D loss: 0.261772, acc: 96.09%] [G loss: 3.680384]\n",
      "epoch:30 step:23477 [D loss: 0.992959, acc: 39.06%] [G loss: 3.862998]\n",
      "epoch:30 step:23478 [D loss: 0.638819, acc: 66.41%] [G loss: 5.972472]\n",
      "epoch:30 step:23479 [D loss: 0.347570, acc: 87.50%] [G loss: 4.307345]\n",
      "epoch:30 step:23480 [D loss: 0.793977, acc: 40.62%] [G loss: 3.024698]\n",
      "epoch:30 step:23481 [D loss: 0.718852, acc: 57.03%] [G loss: 4.895496]\n",
      "epoch:30 step:23482 [D loss: 0.177820, acc: 98.44%] [G loss: 3.833069]\n",
      "epoch:30 step:23483 [D loss: 0.171646, acc: 97.66%] [G loss: 4.625674]\n",
      "epoch:30 step:23484 [D loss: 0.131529, acc: 99.22%] [G loss: 4.078144]\n",
      "epoch:30 step:23485 [D loss: 0.898199, acc: 51.56%] [G loss: 4.053335]\n",
      "epoch:30 step:23486 [D loss: 0.591101, acc: 59.38%] [G loss: 4.665438]\n",
      "epoch:30 step:23487 [D loss: 0.137064, acc: 99.22%] [G loss: 3.688772]\n",
      "epoch:30 step:23488 [D loss: 0.264676, acc: 91.41%] [G loss: 3.668664]\n",
      "epoch:30 step:23489 [D loss: 0.112012, acc: 100.00%] [G loss: 2.880118]\n",
      "epoch:30 step:23490 [D loss: 0.359166, acc: 84.38%] [G loss: 8.174954]\n",
      "epoch:30 step:23491 [D loss: 0.224007, acc: 96.88%] [G loss: 3.670339]\n",
      "epoch:30 step:23492 [D loss: 0.625276, acc: 56.25%] [G loss: 4.177523]\n",
      "epoch:30 step:23493 [D loss: 0.435993, acc: 70.31%] [G loss: 6.126672]\n",
      "epoch:30 step:23494 [D loss: 0.574477, acc: 69.53%] [G loss: 4.101511]\n",
      "epoch:30 step:23495 [D loss: 0.362214, acc: 89.06%] [G loss: 4.073595]\n",
      "epoch:30 step:23496 [D loss: 0.159975, acc: 98.44%] [G loss: 1.880914]\n",
      "epoch:30 step:23497 [D loss: 0.174308, acc: 99.22%] [G loss: 2.445473]\n",
      "epoch:30 step:23498 [D loss: 0.533843, acc: 71.88%] [G loss: 2.128050]\n",
      "epoch:30 step:23499 [D loss: 0.220043, acc: 100.00%] [G loss: 5.852249]\n",
      "epoch:30 step:23500 [D loss: 0.071201, acc: 100.00%] [G loss: 5.921198]\n",
      "epoch:30 step:23501 [D loss: 0.628458, acc: 64.06%] [G loss: 4.277514]\n",
      "epoch:30 step:23502 [D loss: 0.152091, acc: 100.00%] [G loss: 5.803644]\n",
      "epoch:30 step:23503 [D loss: 0.362877, acc: 88.28%] [G loss: 4.841848]\n",
      "epoch:30 step:23504 [D loss: 0.796912, acc: 48.44%] [G loss: 3.822216]\n",
      "epoch:30 step:23505 [D loss: 0.416092, acc: 76.56%] [G loss: 2.930991]\n",
      "epoch:30 step:23506 [D loss: 0.181572, acc: 99.22%] [G loss: 4.967268]\n",
      "epoch:30 step:23507 [D loss: 0.266122, acc: 92.97%] [G loss: 5.186219]\n",
      "epoch:30 step:23508 [D loss: 0.778136, acc: 57.81%] [G loss: 5.587481]\n",
      "epoch:30 step:23509 [D loss: 0.730094, acc: 57.03%] [G loss: 2.862837]\n",
      "epoch:30 step:23510 [D loss: 0.083614, acc: 100.00%] [G loss: 3.346414]\n",
      "epoch:30 step:23511 [D loss: 0.921467, acc: 49.22%] [G loss: 5.521011]\n",
      "epoch:30 step:23512 [D loss: 0.148467, acc: 98.44%] [G loss: 2.856182]\n",
      "epoch:30 step:23513 [D loss: 0.564447, acc: 65.62%] [G loss: 3.078267]\n",
      "epoch:30 step:23514 [D loss: 0.523914, acc: 75.00%] [G loss: 3.895075]\n",
      "epoch:30 step:23515 [D loss: 0.653853, acc: 58.59%] [G loss: 3.968813]\n",
      "epoch:30 step:23516 [D loss: 0.530179, acc: 75.00%] [G loss: 5.058909]\n",
      "epoch:30 step:23517 [D loss: 0.405925, acc: 76.56%] [G loss: 2.538994]\n",
      "epoch:30 step:23518 [D loss: 0.566379, acc: 66.41%] [G loss: 4.650371]\n",
      "epoch:30 step:23519 [D loss: 0.116382, acc: 99.22%] [G loss: 5.219820]\n",
      "epoch:30 step:23520 [D loss: 0.351704, acc: 87.50%] [G loss: 6.239417]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:30 step:23521 [D loss: 0.126470, acc: 99.22%] [G loss: 4.798863]\n",
      "epoch:30 step:23522 [D loss: 0.323309, acc: 89.84%] [G loss: 5.154026]\n",
      "epoch:30 step:23523 [D loss: 0.747410, acc: 50.00%] [G loss: 4.006588]\n",
      "epoch:30 step:23524 [D loss: 1.344907, acc: 36.72%] [G loss: 4.700461]\n",
      "epoch:30 step:23525 [D loss: 0.396877, acc: 83.59%] [G loss: 2.720344]\n",
      "epoch:30 step:23526 [D loss: 0.231475, acc: 92.97%] [G loss: 5.449004]\n",
      "epoch:30 step:23527 [D loss: 0.423286, acc: 78.12%] [G loss: 2.333258]\n",
      "epoch:30 step:23528 [D loss: 0.238675, acc: 92.97%] [G loss: 4.546284]\n",
      "epoch:30 step:23529 [D loss: 0.504965, acc: 64.84%] [G loss: 5.729555]\n",
      "epoch:30 step:23530 [D loss: 0.450710, acc: 82.03%] [G loss: 3.319007]\n",
      "epoch:30 step:23531 [D loss: 0.399208, acc: 82.03%] [G loss: 2.430011]\n",
      "epoch:30 step:23532 [D loss: 0.193306, acc: 99.22%] [G loss: 6.158029]\n",
      "epoch:30 step:23533 [D loss: 0.897718, acc: 37.50%] [G loss: 3.647859]\n",
      "epoch:30 step:23534 [D loss: 0.115984, acc: 99.22%] [G loss: 4.025068]\n",
      "epoch:30 step:23535 [D loss: 0.725080, acc: 57.81%] [G loss: 2.855146]\n",
      "epoch:30 step:23536 [D loss: 0.524457, acc: 78.91%] [G loss: 2.193652]\n",
      "epoch:30 step:23537 [D loss: 0.188885, acc: 100.00%] [G loss: 4.430008]\n",
      "epoch:30 step:23538 [D loss: 0.491879, acc: 81.25%] [G loss: 4.304946]\n",
      "epoch:30 step:23539 [D loss: 0.139780, acc: 99.22%] [G loss: 4.201311]\n",
      "epoch:30 step:23540 [D loss: 0.244474, acc: 96.09%] [G loss: 5.403795]\n",
      "epoch:30 step:23541 [D loss: 0.117244, acc: 99.22%] [G loss: 5.717896]\n",
      "epoch:30 step:23542 [D loss: 0.149420, acc: 98.44%] [G loss: 6.520409]\n",
      "epoch:30 step:23543 [D loss: 0.548302, acc: 65.62%] [G loss: 4.083856]\n",
      "epoch:30 step:23544 [D loss: 0.203625, acc: 98.44%] [G loss: 3.493820]\n",
      "epoch:30 step:23545 [D loss: 0.863466, acc: 52.34%] [G loss: 7.641645]\n",
      "epoch:30 step:23546 [D loss: 0.194282, acc: 100.00%] [G loss: 4.897569]\n",
      "epoch:30 step:23547 [D loss: 0.262512, acc: 92.19%] [G loss: 4.150419]\n",
      "epoch:30 step:23548 [D loss: 0.197016, acc: 95.31%] [G loss: 5.384954]\n",
      "epoch:30 step:23549 [D loss: 0.407569, acc: 84.38%] [G loss: 4.516695]\n",
      "epoch:30 step:23550 [D loss: 0.204606, acc: 97.66%] [G loss: 1.681175]\n",
      "epoch:30 step:23551 [D loss: 0.245007, acc: 98.44%] [G loss: 5.258406]\n",
      "epoch:30 step:23552 [D loss: 1.676800, acc: 44.53%] [G loss: 6.554891]\n",
      "epoch:30 step:23553 [D loss: 0.081932, acc: 100.00%] [G loss: 4.929668]\n",
      "epoch:30 step:23554 [D loss: 0.412567, acc: 85.16%] [G loss: 3.029953]\n",
      "epoch:30 step:23555 [D loss: 0.152508, acc: 98.44%] [G loss: 3.307474]\n",
      "epoch:30 step:23556 [D loss: 0.269208, acc: 96.09%] [G loss: 2.473291]\n",
      "epoch:30 step:23557 [D loss: 0.334381, acc: 89.84%] [G loss: 3.517696]\n",
      "epoch:30 step:23558 [D loss: 0.387163, acc: 84.38%] [G loss: 5.645062]\n",
      "epoch:30 step:23559 [D loss: 0.123075, acc: 100.00%] [G loss: 3.127941]\n",
      "epoch:30 step:23560 [D loss: 0.177711, acc: 93.75%] [G loss: 5.598792]\n",
      "epoch:30 step:23561 [D loss: 0.738651, acc: 56.25%] [G loss: 4.082970]\n",
      "epoch:30 step:23562 [D loss: 0.404461, acc: 84.38%] [G loss: 5.292673]\n",
      "epoch:30 step:23563 [D loss: 0.114864, acc: 100.00%] [G loss: 5.332366]\n",
      "epoch:30 step:23564 [D loss: 0.366103, acc: 89.84%] [G loss: 3.847687]\n",
      "epoch:30 step:23565 [D loss: 0.241613, acc: 98.44%] [G loss: 5.354956]\n",
      "epoch:30 step:23566 [D loss: 0.497067, acc: 79.69%] [G loss: 3.982534]\n",
      "epoch:30 step:23567 [D loss: 0.163944, acc: 96.88%] [G loss: 7.300501]\n",
      "epoch:30 step:23568 [D loss: 0.967223, acc: 32.03%] [G loss: 6.590883]\n",
      "epoch:30 step:23569 [D loss: 0.232681, acc: 100.00%] [G loss: 3.995099]\n",
      "epoch:30 step:23570 [D loss: 0.312594, acc: 96.09%] [G loss: 2.478993]\n",
      "epoch:30 step:23571 [D loss: 0.396111, acc: 89.84%] [G loss: 3.409244]\n",
      "epoch:30 step:23572 [D loss: 1.040174, acc: 50.00%] [G loss: 3.470332]\n",
      "epoch:30 step:23573 [D loss: 0.832184, acc: 50.78%] [G loss: 5.165144]\n",
      "epoch:30 step:23574 [D loss: 0.636290, acc: 64.84%] [G loss: 4.137816]\n",
      "epoch:30 step:23575 [D loss: 0.073115, acc: 100.00%] [G loss: 5.161125]\n",
      "epoch:30 step:23576 [D loss: 0.161421, acc: 100.00%] [G loss: 4.866255]\n",
      "epoch:30 step:23577 [D loss: 0.545222, acc: 57.81%] [G loss: 5.239748]\n",
      "epoch:30 step:23578 [D loss: 0.444394, acc: 77.34%] [G loss: 4.237030]\n",
      "epoch:30 step:23579 [D loss: 0.474495, acc: 67.97%] [G loss: 6.747458]\n",
      "epoch:30 step:23580 [D loss: 0.423974, acc: 75.00%] [G loss: 4.418907]\n",
      "epoch:30 step:23581 [D loss: 0.163140, acc: 98.44%] [G loss: 3.145949]\n",
      "epoch:30 step:23582 [D loss: 0.195599, acc: 96.88%] [G loss: 4.109045]\n",
      "epoch:30 step:23583 [D loss: 0.125184, acc: 100.00%] [G loss: 6.813385]\n",
      "epoch:30 step:23584 [D loss: 0.286343, acc: 95.31%] [G loss: 4.975787]\n",
      "epoch:30 step:23585 [D loss: 0.652256, acc: 61.72%] [G loss: 4.832551]\n",
      "epoch:30 step:23586 [D loss: 0.187445, acc: 96.88%] [G loss: 4.205784]\n",
      "epoch:30 step:23587 [D loss: 0.094314, acc: 100.00%] [G loss: 5.188958]\n",
      "epoch:30 step:23588 [D loss: 0.133770, acc: 100.00%] [G loss: 6.462988]\n",
      "epoch:30 step:23589 [D loss: 0.491749, acc: 78.91%] [G loss: 4.078195]\n",
      "epoch:30 step:23590 [D loss: 0.473081, acc: 82.81%] [G loss: 4.529020]\n",
      "epoch:30 step:23591 [D loss: 0.153381, acc: 100.00%] [G loss: 3.968601]\n",
      "epoch:30 step:23592 [D loss: 0.170139, acc: 96.88%] [G loss: 4.543865]\n",
      "epoch:30 step:23593 [D loss: 0.330015, acc: 84.38%] [G loss: 5.926158]\n",
      "epoch:30 step:23594 [D loss: 0.156899, acc: 99.22%] [G loss: 3.705917]\n",
      "epoch:30 step:23595 [D loss: 0.754054, acc: 52.34%] [G loss: 4.855352]\n",
      "epoch:30 step:23596 [D loss: 0.556961, acc: 59.38%] [G loss: 4.478909]\n",
      "epoch:30 step:23597 [D loss: 0.600168, acc: 60.16%] [G loss: 5.714233]\n",
      "epoch:30 step:23598 [D loss: 0.519713, acc: 66.41%] [G loss: 5.036700]\n",
      "epoch:30 step:23599 [D loss: 0.307983, acc: 86.72%] [G loss: 4.250390]\n",
      "epoch:30 step:23600 [D loss: 0.058252, acc: 100.00%] [G loss: 8.319771]\n",
      "##############\n",
      "[0.8554625  0.86803418 0.82127066 0.81786689 0.78829782 0.83457355\n",
      " 0.8859061  0.83805895 0.8086385  0.83280933]\n",
      "##########\n",
      "epoch:30 step:23601 [D loss: 0.219553, acc: 98.44%] [G loss: 4.078928]\n",
      "epoch:30 step:23602 [D loss: 0.367001, acc: 77.34%] [G loss: 3.211273]\n",
      "epoch:30 step:23603 [D loss: 0.437247, acc: 77.34%] [G loss: 2.423108]\n",
      "epoch:30 step:23604 [D loss: 0.214328, acc: 98.44%] [G loss: 4.623964]\n",
      "epoch:30 step:23605 [D loss: 0.044681, acc: 100.00%] [G loss: 6.477021]\n",
      "epoch:30 step:23606 [D loss: 0.918052, acc: 48.44%] [G loss: 4.504889]\n",
      "epoch:30 step:23607 [D loss: 0.263944, acc: 95.31%] [G loss: 4.334336]\n",
      "epoch:30 step:23608 [D loss: 1.081541, acc: 50.00%] [G loss: 1.840019]\n",
      "epoch:30 step:23609 [D loss: 0.179915, acc: 100.00%] [G loss: 5.080030]\n",
      "epoch:30 step:23610 [D loss: 0.795808, acc: 55.47%] [G loss: 5.619860]\n",
      "epoch:30 step:23611 [D loss: 0.704645, acc: 54.69%] [G loss: 4.243730]\n",
      "epoch:30 step:23612 [D loss: 0.554933, acc: 72.66%] [G loss: 4.944754]\n",
      "epoch:30 step:23613 [D loss: 0.392429, acc: 88.28%] [G loss: 5.625631]\n",
      "epoch:30 step:23614 [D loss: 0.313075, acc: 92.19%] [G loss: 4.479961]\n",
      "epoch:30 step:23615 [D loss: 0.535854, acc: 67.97%] [G loss: 3.586126]\n",
      "epoch:30 step:23616 [D loss: 0.599278, acc: 67.19%] [G loss: 3.274138]\n",
      "epoch:30 step:23617 [D loss: 0.678530, acc: 57.81%] [G loss: 4.897067]\n",
      "epoch:30 step:23618 [D loss: 0.345156, acc: 90.62%] [G loss: 4.133142]\n",
      "epoch:30 step:23619 [D loss: 0.134718, acc: 98.44%] [G loss: 7.506380]\n",
      "epoch:30 step:23620 [D loss: 0.262329, acc: 94.53%] [G loss: 6.826886]\n",
      "epoch:30 step:23621 [D loss: 0.984425, acc: 50.00%] [G loss: 6.935308]\n",
      "epoch:30 step:23622 [D loss: 0.089927, acc: 100.00%] [G loss: 6.092077]\n",
      "epoch:30 step:23623 [D loss: 0.393270, acc: 73.44%] [G loss: 5.446294]\n",
      "epoch:30 step:23624 [D loss: 0.250119, acc: 95.31%] [G loss: 3.707624]\n",
      "epoch:30 step:23625 [D loss: 0.303103, acc: 90.62%] [G loss: 5.922003]\n",
      "epoch:30 step:23626 [D loss: 0.322693, acc: 92.19%] [G loss: 7.016524]\n",
      "epoch:30 step:23627 [D loss: 0.227420, acc: 94.53%] [G loss: 2.921055]\n",
      "epoch:30 step:23628 [D loss: 0.060941, acc: 100.00%] [G loss: 5.600910]\n",
      "epoch:30 step:23629 [D loss: 0.169442, acc: 99.22%] [G loss: 4.547325]\n",
      "epoch:30 step:23630 [D loss: 0.350283, acc: 90.62%] [G loss: 6.699382]\n",
      "epoch:30 step:23631 [D loss: 0.405789, acc: 85.94%] [G loss: 2.913671]\n",
      "epoch:30 step:23632 [D loss: 0.145254, acc: 99.22%] [G loss: 3.623937]\n",
      "epoch:30 step:23633 [D loss: 0.189450, acc: 98.44%] [G loss: 3.939165]\n",
      "epoch:30 step:23634 [D loss: 0.174351, acc: 97.66%] [G loss: 2.882033]\n",
      "epoch:30 step:23635 [D loss: 0.161945, acc: 99.22%] [G loss: 4.203491]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:30 step:23636 [D loss: 0.047254, acc: 100.00%] [G loss: 4.388979]\n",
      "epoch:30 step:23637 [D loss: 0.702165, acc: 53.91%] [G loss: 4.077673]\n",
      "epoch:30 step:23638 [D loss: 0.825416, acc: 51.56%] [G loss: 3.738809]\n",
      "epoch:30 step:23639 [D loss: 0.071005, acc: 100.00%] [G loss: 2.797902]\n",
      "epoch:30 step:23640 [D loss: 1.313365, acc: 10.16%] [G loss: 5.656663]\n",
      "epoch:30 step:23641 [D loss: 0.350215, acc: 84.38%] [G loss: 4.024059]\n",
      "epoch:30 step:23642 [D loss: 0.227433, acc: 94.53%] [G loss: 3.624321]\n",
      "epoch:30 step:23643 [D loss: 0.999759, acc: 44.53%] [G loss: 4.402106]\n",
      "epoch:30 step:23644 [D loss: 0.837024, acc: 53.91%] [G loss: 4.677566]\n",
      "epoch:30 step:23645 [D loss: 0.426649, acc: 74.22%] [G loss: 2.586426]\n",
      "epoch:30 step:23646 [D loss: 0.292627, acc: 92.19%] [G loss: 5.666548]\n",
      "epoch:30 step:23647 [D loss: 0.686160, acc: 58.59%] [G loss: 4.342358]\n",
      "epoch:30 step:23648 [D loss: 0.167547, acc: 97.66%] [G loss: 3.277983]\n",
      "epoch:30 step:23649 [D loss: 0.312137, acc: 88.28%] [G loss: 4.617631]\n",
      "epoch:30 step:23650 [D loss: 0.196342, acc: 99.22%] [G loss: 4.441570]\n",
      "epoch:30 step:23651 [D loss: 0.551613, acc: 76.56%] [G loss: 6.164698]\n",
      "epoch:30 step:23652 [D loss: 0.556923, acc: 72.66%] [G loss: 5.185295]\n",
      "epoch:30 step:23653 [D loss: 0.198866, acc: 97.66%] [G loss: 4.417761]\n",
      "epoch:30 step:23654 [D loss: 0.815240, acc: 51.56%] [G loss: 3.609804]\n",
      "epoch:30 step:23655 [D loss: 0.800630, acc: 50.00%] [G loss: 5.732536]\n",
      "epoch:30 step:23656 [D loss: 0.164851, acc: 100.00%] [G loss: 3.141389]\n",
      "epoch:30 step:23657 [D loss: 0.081992, acc: 100.00%] [G loss: 8.389679]\n",
      "epoch:30 step:23658 [D loss: 0.264028, acc: 93.75%] [G loss: 5.549813]\n",
      "epoch:30 step:23659 [D loss: 0.454583, acc: 76.56%] [G loss: 5.549431]\n",
      "epoch:30 step:23660 [D loss: 0.417809, acc: 86.72%] [G loss: 5.073392]\n",
      "epoch:30 step:23661 [D loss: 0.778687, acc: 50.78%] [G loss: 6.634492]\n",
      "epoch:30 step:23662 [D loss: 0.160682, acc: 100.00%] [G loss: 6.784493]\n",
      "epoch:30 step:23663 [D loss: 0.126882, acc: 100.00%] [G loss: 3.355848]\n",
      "epoch:30 step:23664 [D loss: 0.384622, acc: 83.59%] [G loss: 3.255179]\n",
      "epoch:30 step:23665 [D loss: 0.182370, acc: 99.22%] [G loss: 2.533448]\n",
      "epoch:30 step:23666 [D loss: 0.194850, acc: 100.00%] [G loss: 4.953966]\n",
      "epoch:30 step:23667 [D loss: 0.076832, acc: 100.00%] [G loss: 5.545325]\n",
      "epoch:30 step:23668 [D loss: 0.445325, acc: 84.38%] [G loss: 1.850353]\n",
      "epoch:30 step:23669 [D loss: 0.461062, acc: 82.81%] [G loss: 3.624184]\n",
      "epoch:30 step:23670 [D loss: 0.362174, acc: 92.19%] [G loss: 3.234505]\n",
      "epoch:30 step:23671 [D loss: 0.057549, acc: 100.00%] [G loss: 5.261009]\n",
      "epoch:30 step:23672 [D loss: 0.042775, acc: 100.00%] [G loss: 6.310185]\n",
      "epoch:30 step:23673 [D loss: 1.174150, acc: 50.00%] [G loss: 4.680303]\n",
      "epoch:30 step:23674 [D loss: 0.282311, acc: 89.06%] [G loss: 7.833221]\n",
      "epoch:30 step:23675 [D loss: 0.829491, acc: 50.78%] [G loss: 4.096347]\n",
      "epoch:30 step:23676 [D loss: 0.040365, acc: 100.00%] [G loss: 3.322217]\n",
      "epoch:30 step:23677 [D loss: 0.413770, acc: 84.38%] [G loss: 4.299755]\n",
      "epoch:30 step:23678 [D loss: 0.978148, acc: 50.00%] [G loss: 2.597562]\n",
      "epoch:30 step:23679 [D loss: 0.041224, acc: 100.00%] [G loss: 4.785715]\n",
      "epoch:30 step:23680 [D loss: 0.305031, acc: 94.53%] [G loss: 3.050363]\n",
      "epoch:30 step:23681 [D loss: 0.067821, acc: 100.00%] [G loss: 6.549001]\n",
      "epoch:30 step:23682 [D loss: 0.206756, acc: 95.31%] [G loss: 4.259367]\n",
      "epoch:30 step:23683 [D loss: 0.645933, acc: 65.62%] [G loss: 5.860378]\n",
      "epoch:30 step:23684 [D loss: 0.132122, acc: 100.00%] [G loss: 3.767215]\n",
      "epoch:30 step:23685 [D loss: 0.182307, acc: 99.22%] [G loss: 6.857259]\n",
      "epoch:30 step:23686 [D loss: 0.177312, acc: 98.44%] [G loss: 1.801721]\n",
      "epoch:30 step:23687 [D loss: 0.151985, acc: 99.22%] [G loss: 2.396529]\n",
      "epoch:30 step:23688 [D loss: 0.125834, acc: 100.00%] [G loss: 4.695930]\n",
      "epoch:30 step:23689 [D loss: 0.254408, acc: 95.31%] [G loss: 3.835524]\n",
      "epoch:30 step:23690 [D loss: 0.488200, acc: 78.91%] [G loss: 4.750505]\n",
      "epoch:30 step:23691 [D loss: 0.926551, acc: 26.56%] [G loss: 5.281382]\n",
      "epoch:30 step:23692 [D loss: 0.004951, acc: 100.00%] [G loss: 6.703678]\n",
      "epoch:30 step:23693 [D loss: 0.257259, acc: 94.53%] [G loss: 4.497149]\n",
      "epoch:30 step:23694 [D loss: 0.249923, acc: 92.19%] [G loss: 3.983678]\n",
      "epoch:30 step:23695 [D loss: 0.398406, acc: 88.28%] [G loss: 3.645858]\n",
      "epoch:30 step:23696 [D loss: 0.723800, acc: 56.25%] [G loss: 4.757667]\n",
      "epoch:30 step:23697 [D loss: 1.745572, acc: 49.22%] [G loss: 3.900274]\n",
      "epoch:30 step:23698 [D loss: 0.156835, acc: 98.44%] [G loss: 5.530538]\n",
      "epoch:30 step:23699 [D loss: 0.864588, acc: 32.81%] [G loss: 4.652785]\n",
      "epoch:30 step:23700 [D loss: 0.293943, acc: 85.94%] [G loss: 4.946024]\n",
      "epoch:30 step:23701 [D loss: 0.339019, acc: 82.03%] [G loss: 3.527397]\n",
      "epoch:30 step:23702 [D loss: 0.531394, acc: 76.56%] [G loss: 4.396906]\n",
      "epoch:30 step:23703 [D loss: 0.872610, acc: 52.34%] [G loss: 4.405632]\n",
      "epoch:30 step:23704 [D loss: 0.411579, acc: 85.94%] [G loss: 5.004688]\n",
      "epoch:30 step:23705 [D loss: 0.520818, acc: 66.41%] [G loss: 4.837543]\n",
      "epoch:30 step:23706 [D loss: 1.024869, acc: 46.88%] [G loss: 2.729659]\n",
      "epoch:30 step:23707 [D loss: 0.095177, acc: 98.44%] [G loss: 6.991866]\n",
      "epoch:30 step:23708 [D loss: 0.099622, acc: 100.00%] [G loss: 3.991764]\n",
      "epoch:30 step:23709 [D loss: 0.876568, acc: 53.12%] [G loss: 7.575908]\n",
      "epoch:30 step:23710 [D loss: 0.527058, acc: 69.53%] [G loss: 5.591845]\n",
      "epoch:30 step:23711 [D loss: 0.890568, acc: 39.06%] [G loss: 3.364650]\n",
      "epoch:30 step:23712 [D loss: 0.232058, acc: 96.09%] [G loss: 6.596583]\n",
      "epoch:30 step:23713 [D loss: 0.547561, acc: 71.88%] [G loss: 5.735332]\n",
      "epoch:30 step:23714 [D loss: 0.270708, acc: 91.41%] [G loss: 2.946219]\n",
      "epoch:30 step:23715 [D loss: 0.611631, acc: 67.97%] [G loss: 2.363937]\n",
      "epoch:30 step:23716 [D loss: 0.613050, acc: 59.38%] [G loss: 4.386351]\n",
      "epoch:30 step:23717 [D loss: 0.654647, acc: 61.72%] [G loss: 6.542188]\n",
      "epoch:30 step:23718 [D loss: 0.505548, acc: 73.44%] [G loss: 4.800606]\n",
      "epoch:30 step:23719 [D loss: 1.080865, acc: 48.44%] [G loss: 5.789713]\n",
      "epoch:30 step:23720 [D loss: 0.279982, acc: 93.75%] [G loss: 3.737356]\n",
      "epoch:30 step:23721 [D loss: 1.391884, acc: 23.44%] [G loss: 2.993677]\n",
      "epoch:30 step:23722 [D loss: 0.113819, acc: 99.22%] [G loss: 7.260268]\n",
      "epoch:30 step:23723 [D loss: 0.163281, acc: 100.00%] [G loss: 5.752434]\n",
      "epoch:30 step:23724 [D loss: 0.499553, acc: 74.22%] [G loss: 3.946450]\n",
      "epoch:30 step:23725 [D loss: 0.313442, acc: 91.41%] [G loss: 2.977758]\n",
      "epoch:30 step:23726 [D loss: 0.660358, acc: 55.47%] [G loss: 7.368743]\n",
      "epoch:30 step:23727 [D loss: 0.174280, acc: 96.88%] [G loss: 4.243068]\n",
      "epoch:30 step:23728 [D loss: 0.646963, acc: 56.25%] [G loss: 4.454477]\n",
      "epoch:30 step:23729 [D loss: 0.220275, acc: 92.97%] [G loss: 4.020875]\n",
      "epoch:30 step:23730 [D loss: 0.291231, acc: 88.28%] [G loss: 3.546580]\n",
      "epoch:30 step:23731 [D loss: 1.035722, acc: 19.53%] [G loss: 3.500561]\n",
      "epoch:30 step:23732 [D loss: 0.484353, acc: 78.91%] [G loss: 4.371305]\n",
      "epoch:30 step:23733 [D loss: 0.458348, acc: 85.16%] [G loss: 5.402113]\n",
      "epoch:30 step:23734 [D loss: 0.088581, acc: 100.00%] [G loss: 5.423067]\n",
      "epoch:30 step:23735 [D loss: 0.073124, acc: 100.00%] [G loss: 5.037527]\n",
      "epoch:30 step:23736 [D loss: 0.092164, acc: 100.00%] [G loss: 3.704639]\n",
      "epoch:30 step:23737 [D loss: 0.095284, acc: 99.22%] [G loss: 5.015696]\n",
      "epoch:30 step:23738 [D loss: 0.250534, acc: 96.88%] [G loss: 3.224015]\n",
      "epoch:30 step:23739 [D loss: 0.495282, acc: 75.78%] [G loss: 5.123126]\n",
      "epoch:30 step:23740 [D loss: 0.544268, acc: 64.06%] [G loss: 4.842990]\n",
      "epoch:30 step:23741 [D loss: 0.482918, acc: 71.88%] [G loss: 5.258368]\n",
      "epoch:30 step:23742 [D loss: 0.366026, acc: 76.56%] [G loss: 4.389289]\n",
      "epoch:30 step:23743 [D loss: 0.269895, acc: 96.09%] [G loss: 3.189624]\n",
      "epoch:30 step:23744 [D loss: 0.240920, acc: 89.06%] [G loss: 4.949881]\n",
      "epoch:30 step:23745 [D loss: 1.683902, acc: 4.69%] [G loss: 4.109343]\n",
      "epoch:30 step:23746 [D loss: 0.181160, acc: 99.22%] [G loss: 2.760298]\n",
      "epoch:30 step:23747 [D loss: 0.205437, acc: 96.88%] [G loss: 3.381701]\n",
      "epoch:30 step:23748 [D loss: 0.231292, acc: 96.88%] [G loss: 5.762968]\n",
      "epoch:30 step:23749 [D loss: 0.097057, acc: 99.22%] [G loss: 5.284417]\n",
      "epoch:30 step:23750 [D loss: 0.447990, acc: 76.56%] [G loss: 3.541248]\n",
      "epoch:30 step:23751 [D loss: 0.923839, acc: 50.78%] [G loss: 4.483632]\n",
      "epoch:30 step:23752 [D loss: 0.441658, acc: 86.72%] [G loss: 4.842967]\n",
      "epoch:30 step:23753 [D loss: 0.384588, acc: 75.78%] [G loss: 6.533531]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:30 step:23754 [D loss: 0.361105, acc: 90.62%] [G loss: 4.586959]\n",
      "epoch:30 step:23755 [D loss: 0.055855, acc: 100.00%] [G loss: 4.753364]\n",
      "epoch:30 step:23756 [D loss: 0.199642, acc: 97.66%] [G loss: 2.859090]\n",
      "epoch:30 step:23757 [D loss: 0.266250, acc: 92.97%] [G loss: 3.969818]\n",
      "epoch:30 step:23758 [D loss: 0.233298, acc: 97.66%] [G loss: 4.064019]\n",
      "epoch:30 step:23759 [D loss: 0.734874, acc: 51.56%] [G loss: 6.525751]\n",
      "epoch:30 step:23760 [D loss: 0.096057, acc: 100.00%] [G loss: 4.646304]\n",
      "epoch:30 step:23761 [D loss: 0.252769, acc: 95.31%] [G loss: 3.183833]\n",
      "epoch:30 step:23762 [D loss: 0.802972, acc: 52.34%] [G loss: 6.861391]\n",
      "epoch:30 step:23763 [D loss: 1.592042, acc: 50.00%] [G loss: 5.468117]\n",
      "epoch:30 step:23764 [D loss: 0.215128, acc: 99.22%] [G loss: 3.220739]\n",
      "epoch:30 step:23765 [D loss: 0.073367, acc: 100.00%] [G loss: 5.705087]\n",
      "epoch:30 step:23766 [D loss: 1.481626, acc: 10.16%] [G loss: 4.298808]\n",
      "epoch:30 step:23767 [D loss: 0.682817, acc: 56.25%] [G loss: 5.099787]\n",
      "epoch:30 step:23768 [D loss: 0.167024, acc: 96.09%] [G loss: 3.633149]\n",
      "epoch:30 step:23769 [D loss: 0.070303, acc: 99.22%] [G loss: 6.137620]\n",
      "epoch:30 step:23770 [D loss: 0.313214, acc: 92.19%] [G loss: 4.189691]\n",
      "epoch:30 step:23771 [D loss: 0.316860, acc: 87.50%] [G loss: 6.638328]\n",
      "epoch:30 step:23772 [D loss: 0.335125, acc: 86.72%] [G loss: 2.855864]\n",
      "epoch:30 step:23773 [D loss: 0.739128, acc: 53.12%] [G loss: 5.150792]\n",
      "epoch:30 step:23774 [D loss: 0.659751, acc: 60.94%] [G loss: 4.456059]\n",
      "epoch:30 step:23775 [D loss: 0.337967, acc: 93.75%] [G loss: 4.226914]\n",
      "epoch:30 step:23776 [D loss: 0.164609, acc: 100.00%] [G loss: 4.917816]\n",
      "epoch:30 step:23777 [D loss: 0.292067, acc: 90.62%] [G loss: 5.189373]\n",
      "epoch:30 step:23778 [D loss: 0.401461, acc: 75.78%] [G loss: 4.024450]\n",
      "epoch:30 step:23779 [D loss: 0.373251, acc: 92.19%] [G loss: 3.701212]\n",
      "epoch:30 step:23780 [D loss: 0.428201, acc: 76.56%] [G loss: 5.917161]\n",
      "epoch:30 step:23781 [D loss: 0.623664, acc: 65.62%] [G loss: 5.469378]\n",
      "epoch:30 step:23782 [D loss: 0.041054, acc: 100.00%] [G loss: 6.088494]\n",
      "epoch:30 step:23783 [D loss: 0.565906, acc: 66.41%] [G loss: 3.610597]\n",
      "epoch:30 step:23784 [D loss: 0.435315, acc: 76.56%] [G loss: 3.117368]\n",
      "epoch:30 step:23785 [D loss: 1.119228, acc: 51.56%] [G loss: 5.277316]\n",
      "epoch:30 step:23786 [D loss: 0.135143, acc: 99.22%] [G loss: 3.272348]\n",
      "epoch:30 step:23787 [D loss: 0.299061, acc: 96.09%] [G loss: 5.380158]\n",
      "epoch:30 step:23788 [D loss: 0.450464, acc: 69.53%] [G loss: 2.355775]\n",
      "epoch:30 step:23789 [D loss: 0.099695, acc: 100.00%] [G loss: 6.776196]\n",
      "epoch:30 step:23790 [D loss: 0.313875, acc: 90.62%] [G loss: 7.532974]\n",
      "epoch:30 step:23791 [D loss: 0.112293, acc: 99.22%] [G loss: 5.414373]\n",
      "epoch:30 step:23792 [D loss: 0.059605, acc: 100.00%] [G loss: 2.990238]\n",
      "epoch:30 step:23793 [D loss: 0.261717, acc: 98.44%] [G loss: 3.214171]\n",
      "epoch:30 step:23794 [D loss: 0.301900, acc: 94.53%] [G loss: 3.761334]\n",
      "epoch:30 step:23795 [D loss: 0.964948, acc: 50.78%] [G loss: 3.841324]\n",
      "epoch:30 step:23796 [D loss: 0.411398, acc: 74.22%] [G loss: 4.972500]\n",
      "epoch:30 step:23797 [D loss: 0.446317, acc: 82.03%] [G loss: 5.128058]\n",
      "epoch:30 step:23798 [D loss: 0.203267, acc: 96.88%] [G loss: 4.082210]\n",
      "epoch:30 step:23799 [D loss: 0.207750, acc: 96.88%] [G loss: 3.043928]\n",
      "epoch:30 step:23800 [D loss: 0.588820, acc: 71.09%] [G loss: 4.207301]\n",
      "##############\n",
      "[0.86108855 0.86179537 0.82252663 0.7980063  0.80132972 0.82499648\n",
      " 0.89418689 0.84739676 0.82308973 0.83039878]\n",
      "##########\n",
      "epoch:30 step:23801 [D loss: 0.620178, acc: 63.28%] [G loss: 2.182585]\n",
      "epoch:30 step:23802 [D loss: 0.029910, acc: 100.00%] [G loss: 3.937404]\n",
      "epoch:30 step:23803 [D loss: 1.024143, acc: 50.00%] [G loss: 6.899068]\n",
      "epoch:30 step:23804 [D loss: 0.174243, acc: 97.66%] [G loss: 5.233763]\n",
      "epoch:30 step:23805 [D loss: 0.493874, acc: 58.59%] [G loss: 4.595096]\n",
      "epoch:30 step:23806 [D loss: 1.235774, acc: 40.62%] [G loss: 4.582448]\n",
      "epoch:30 step:23807 [D loss: 0.377595, acc: 81.25%] [G loss: 3.030838]\n",
      "epoch:30 step:23808 [D loss: 0.650504, acc: 63.28%] [G loss: 3.053745]\n",
      "epoch:30 step:23809 [D loss: 0.504509, acc: 71.09%] [G loss: 4.729274]\n",
      "epoch:30 step:23810 [D loss: 0.179379, acc: 97.66%] [G loss: 3.442222]\n",
      "epoch:30 step:23811 [D loss: 0.607080, acc: 71.88%] [G loss: 3.308622]\n",
      "epoch:30 step:23812 [D loss: 0.324456, acc: 89.84%] [G loss: 5.627126]\n",
      "epoch:30 step:23813 [D loss: 0.496979, acc: 86.72%] [G loss: 1.649679]\n",
      "epoch:30 step:23814 [D loss: 0.238085, acc: 93.75%] [G loss: 4.848257]\n",
      "epoch:30 step:23815 [D loss: 0.568611, acc: 67.97%] [G loss: 4.303802]\n",
      "epoch:30 step:23816 [D loss: 0.270495, acc: 91.41%] [G loss: 4.995559]\n",
      "epoch:30 step:23817 [D loss: 0.189432, acc: 98.44%] [G loss: 5.355705]\n",
      "epoch:30 step:23818 [D loss: 0.138003, acc: 98.44%] [G loss: 6.917244]\n",
      "epoch:30 step:23819 [D loss: 0.473465, acc: 82.81%] [G loss: 3.893194]\n",
      "epoch:30 step:23820 [D loss: 0.891618, acc: 50.78%] [G loss: 3.373242]\n",
      "epoch:30 step:23821 [D loss: 0.040401, acc: 100.00%] [G loss: 3.133626]\n",
      "epoch:30 step:23822 [D loss: 0.726441, acc: 50.00%] [G loss: 3.644918]\n",
      "epoch:30 step:23823 [D loss: 0.420304, acc: 77.34%] [G loss: 3.940244]\n",
      "epoch:30 step:23824 [D loss: 0.095828, acc: 99.22%] [G loss: 6.476769]\n",
      "epoch:30 step:23825 [D loss: 0.365058, acc: 82.03%] [G loss: 3.002947]\n",
      "epoch:30 step:23826 [D loss: 0.570558, acc: 67.97%] [G loss: 5.125506]\n",
      "epoch:30 step:23827 [D loss: 0.168078, acc: 96.88%] [G loss: 5.020884]\n",
      "epoch:30 step:23828 [D loss: 0.118322, acc: 97.66%] [G loss: 3.217731]\n",
      "epoch:30 step:23829 [D loss: 0.253401, acc: 96.09%] [G loss: 5.410924]\n",
      "epoch:30 step:23830 [D loss: 0.149620, acc: 98.44%] [G loss: 3.372311]\n",
      "epoch:30 step:23831 [D loss: 0.012270, acc: 100.00%] [G loss: 7.114332]\n",
      "epoch:30 step:23832 [D loss: 0.199549, acc: 99.22%] [G loss: 4.069768]\n",
      "epoch:30 step:23833 [D loss: 0.595383, acc: 60.16%] [G loss: 6.077564]\n",
      "epoch:30 step:23834 [D loss: 0.240753, acc: 88.28%] [G loss: 4.111185]\n",
      "epoch:30 step:23835 [D loss: 0.142620, acc: 100.00%] [G loss: 4.849930]\n",
      "epoch:30 step:23836 [D loss: 0.754985, acc: 53.91%] [G loss: 4.376517]\n",
      "epoch:30 step:23837 [D loss: 0.634406, acc: 60.16%] [G loss: 4.747297]\n",
      "epoch:30 step:23838 [D loss: 0.834255, acc: 50.78%] [G loss: 4.531833]\n",
      "epoch:30 step:23839 [D loss: 0.545241, acc: 67.19%] [G loss: 4.459967]\n",
      "epoch:30 step:23840 [D loss: 0.494482, acc: 79.69%] [G loss: 5.211068]\n",
      "epoch:30 step:23841 [D loss: 1.012921, acc: 36.72%] [G loss: 4.201804]\n",
      "epoch:30 step:23842 [D loss: 0.528118, acc: 61.72%] [G loss: 4.688551]\n",
      "epoch:30 step:23843 [D loss: 0.896753, acc: 52.34%] [G loss: 4.307610]\n",
      "epoch:30 step:23844 [D loss: 0.878844, acc: 38.28%] [G loss: 7.296371]\n",
      "epoch:30 step:23845 [D loss: 0.829756, acc: 51.56%] [G loss: 3.594376]\n",
      "epoch:30 step:23846 [D loss: 0.456207, acc: 81.25%] [G loss: 4.256759]\n",
      "epoch:30 step:23847 [D loss: 0.830927, acc: 52.34%] [G loss: 2.548388]\n",
      "epoch:30 step:23848 [D loss: 0.472175, acc: 69.53%] [G loss: 7.762336]\n",
      "epoch:30 step:23849 [D loss: 0.420087, acc: 80.47%] [G loss: 3.812231]\n",
      "epoch:30 step:23850 [D loss: 0.137408, acc: 99.22%] [G loss: 4.239020]\n",
      "epoch:30 step:23851 [D loss: 0.545093, acc: 61.72%] [G loss: 2.328435]\n",
      "epoch:30 step:23852 [D loss: 0.435226, acc: 78.91%] [G loss: 5.918318]\n",
      "epoch:30 step:23853 [D loss: 0.147653, acc: 100.00%] [G loss: 5.663886]\n",
      "epoch:30 step:23854 [D loss: 0.090770, acc: 100.00%] [G loss: 4.917087]\n",
      "epoch:30 step:23855 [D loss: 0.221160, acc: 92.19%] [G loss: 8.115021]\n",
      "epoch:30 step:23856 [D loss: 0.137545, acc: 98.44%] [G loss: 7.717427]\n",
      "epoch:30 step:23857 [D loss: 0.455211, acc: 72.66%] [G loss: 3.537313]\n",
      "epoch:30 step:23858 [D loss: 0.592019, acc: 66.41%] [G loss: 4.649284]\n",
      "epoch:30 step:23859 [D loss: 0.143708, acc: 96.88%] [G loss: 4.767449]\n",
      "epoch:30 step:23860 [D loss: 0.185242, acc: 98.44%] [G loss: 4.735121]\n",
      "epoch:30 step:23861 [D loss: 0.522855, acc: 71.88%] [G loss: 4.678549]\n",
      "epoch:30 step:23862 [D loss: 0.213285, acc: 98.44%] [G loss: 3.278799]\n",
      "epoch:30 step:23863 [D loss: 1.339987, acc: 32.81%] [G loss: 2.642780]\n",
      "epoch:30 step:23864 [D loss: 0.358055, acc: 88.28%] [G loss: 3.283058]\n",
      "epoch:30 step:23865 [D loss: 0.238552, acc: 99.22%] [G loss: 4.328165]\n",
      "epoch:30 step:23866 [D loss: 1.171491, acc: 28.12%] [G loss: 5.456590]\n",
      "epoch:30 step:23867 [D loss: 0.044282, acc: 100.00%] [G loss: 5.167137]\n",
      "epoch:30 step:23868 [D loss: 0.564210, acc: 71.88%] [G loss: 4.296849]\n",
      "epoch:30 step:23869 [D loss: 0.350842, acc: 92.19%] [G loss: 2.798107]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:30 step:23870 [D loss: 0.329382, acc: 89.84%] [G loss: 4.053536]\n",
      "epoch:30 step:23871 [D loss: 0.207037, acc: 98.44%] [G loss: 4.200370]\n",
      "epoch:30 step:23872 [D loss: 0.419361, acc: 82.81%] [G loss: 4.870784]\n",
      "epoch:30 step:23873 [D loss: 0.154419, acc: 99.22%] [G loss: 4.621852]\n",
      "epoch:30 step:23874 [D loss: 0.293499, acc: 95.31%] [G loss: 4.146214]\n",
      "epoch:30 step:23875 [D loss: 1.026596, acc: 46.09%] [G loss: 2.183441]\n",
      "epoch:30 step:23876 [D loss: 0.179579, acc: 97.66%] [G loss: 4.256962]\n",
      "epoch:30 step:23877 [D loss: 0.235919, acc: 92.19%] [G loss: 5.051316]\n",
      "epoch:30 step:23878 [D loss: 0.131988, acc: 100.00%] [G loss: 2.035258]\n",
      "epoch:30 step:23879 [D loss: 0.671623, acc: 53.91%] [G loss: 4.642048]\n",
      "epoch:30 step:23880 [D loss: 0.544430, acc: 71.09%] [G loss: 6.077959]\n",
      "epoch:30 step:23881 [D loss: 0.377214, acc: 78.91%] [G loss: 3.570426]\n",
      "epoch:30 step:23882 [D loss: 0.639585, acc: 60.94%] [G loss: 3.334292]\n",
      "epoch:30 step:23883 [D loss: 0.503308, acc: 67.97%] [G loss: 5.515779]\n",
      "epoch:30 step:23884 [D loss: 0.899816, acc: 31.25%] [G loss: 5.634854]\n",
      "epoch:30 step:23885 [D loss: 0.048910, acc: 100.00%] [G loss: 5.591878]\n",
      "epoch:30 step:23886 [D loss: 0.291961, acc: 91.41%] [G loss: 5.945621]\n",
      "epoch:30 step:23887 [D loss: 0.207517, acc: 98.44%] [G loss: 3.000996]\n",
      "epoch:30 step:23888 [D loss: 0.996976, acc: 26.56%] [G loss: 3.096808]\n",
      "epoch:30 step:23889 [D loss: 0.063772, acc: 100.00%] [G loss: 5.770301]\n",
      "epoch:30 step:23890 [D loss: 0.404521, acc: 88.28%] [G loss: 4.455614]\n",
      "epoch:30 step:23891 [D loss: 0.081784, acc: 100.00%] [G loss: 5.073091]\n",
      "epoch:30 step:23892 [D loss: 0.190659, acc: 94.53%] [G loss: 4.792390]\n",
      "epoch:30 step:23893 [D loss: 0.148984, acc: 99.22%] [G loss: 4.447207]\n",
      "epoch:30 step:23894 [D loss: 0.240797, acc: 91.41%] [G loss: 4.043106]\n",
      "epoch:30 step:23895 [D loss: 0.786648, acc: 50.78%] [G loss: 2.797673]\n",
      "epoch:30 step:23896 [D loss: 0.384265, acc: 76.56%] [G loss: 6.033562]\n",
      "epoch:30 step:23897 [D loss: 0.505808, acc: 72.66%] [G loss: 4.031502]\n",
      "epoch:30 step:23898 [D loss: 0.961860, acc: 50.78%] [G loss: 5.328660]\n",
      "epoch:30 step:23899 [D loss: 0.482830, acc: 74.22%] [G loss: 4.240495]\n",
      "epoch:30 step:23900 [D loss: 0.185326, acc: 96.09%] [G loss: 4.695370]\n",
      "epoch:30 step:23901 [D loss: 0.425949, acc: 85.94%] [G loss: 3.709263]\n",
      "epoch:30 step:23902 [D loss: 0.659708, acc: 57.81%] [G loss: 3.851604]\n",
      "epoch:30 step:23903 [D loss: 0.789195, acc: 53.12%] [G loss: 2.732740]\n",
      "epoch:30 step:23904 [D loss: 0.642872, acc: 64.06%] [G loss: 4.342992]\n",
      "epoch:30 step:23905 [D loss: 0.284063, acc: 93.75%] [G loss: 5.860273]\n",
      "epoch:30 step:23906 [D loss: 1.022703, acc: 51.56%] [G loss: 6.890090]\n",
      "epoch:30 step:23907 [D loss: 0.533920, acc: 74.22%] [G loss: 3.028969]\n",
      "epoch:30 step:23908 [D loss: 0.208856, acc: 95.31%] [G loss: 3.519692]\n",
      "epoch:30 step:23909 [D loss: 0.261860, acc: 96.88%] [G loss: 3.437511]\n",
      "epoch:30 step:23910 [D loss: 0.473820, acc: 71.88%] [G loss: 2.573947]\n",
      "epoch:30 step:23911 [D loss: 0.342326, acc: 88.28%] [G loss: 3.626309]\n",
      "epoch:30 step:23912 [D loss: 0.570737, acc: 58.59%] [G loss: 5.653270]\n",
      "epoch:30 step:23913 [D loss: 1.125800, acc: 50.00%] [G loss: 4.229864]\n",
      "epoch:30 step:23914 [D loss: 0.601700, acc: 69.53%] [G loss: 5.646547]\n",
      "epoch:30 step:23915 [D loss: 0.464148, acc: 82.81%] [G loss: 6.291357]\n",
      "epoch:30 step:23916 [D loss: 0.238016, acc: 94.53%] [G loss: 4.050313]\n",
      "epoch:30 step:23917 [D loss: 0.792828, acc: 53.12%] [G loss: 7.509389]\n",
      "epoch:30 step:23918 [D loss: 0.112836, acc: 100.00%] [G loss: 4.314821]\n",
      "epoch:30 step:23919 [D loss: 0.339495, acc: 87.50%] [G loss: 5.312696]\n",
      "epoch:30 step:23920 [D loss: 0.058722, acc: 99.22%] [G loss: 4.790245]\n",
      "epoch:30 step:23921 [D loss: 0.140461, acc: 100.00%] [G loss: 3.796032]\n",
      "epoch:30 step:23922 [D loss: 0.107900, acc: 99.22%] [G loss: 7.120035]\n",
      "epoch:30 step:23923 [D loss: 0.232819, acc: 96.88%] [G loss: 3.483551]\n",
      "epoch:30 step:23924 [D loss: 0.301785, acc: 92.19%] [G loss: 4.221975]\n",
      "epoch:30 step:23925 [D loss: 0.495316, acc: 82.03%] [G loss: 5.956336]\n",
      "epoch:30 step:23926 [D loss: 0.158268, acc: 100.00%] [G loss: 2.896881]\n",
      "epoch:30 step:23927 [D loss: 0.089641, acc: 100.00%] [G loss: 5.866135]\n",
      "epoch:30 step:23928 [D loss: 0.176118, acc: 96.09%] [G loss: 4.875674]\n",
      "epoch:30 step:23929 [D loss: 0.495949, acc: 79.69%] [G loss: 5.499366]\n",
      "epoch:30 step:23930 [D loss: 0.721474, acc: 53.12%] [G loss: 5.337636]\n",
      "epoch:30 step:23931 [D loss: 0.350608, acc: 82.81%] [G loss: 4.918587]\n",
      "epoch:30 step:23932 [D loss: 0.195832, acc: 99.22%] [G loss: 5.704350]\n",
      "epoch:30 step:23933 [D loss: 0.515899, acc: 75.00%] [G loss: 3.494079]\n",
      "epoch:30 step:23934 [D loss: 0.095762, acc: 100.00%] [G loss: 7.419640]\n",
      "epoch:30 step:23935 [D loss: 1.135378, acc: 48.44%] [G loss: 2.472019]\n",
      "epoch:30 step:23936 [D loss: 0.606568, acc: 67.19%] [G loss: 1.848554]\n",
      "epoch:30 step:23937 [D loss: 0.302965, acc: 86.72%] [G loss: 4.073063]\n",
      "epoch:30 step:23938 [D loss: 0.495559, acc: 64.06%] [G loss: 5.058728]\n",
      "epoch:30 step:23939 [D loss: 0.704022, acc: 54.69%] [G loss: 5.082659]\n",
      "epoch:30 step:23940 [D loss: 0.679656, acc: 58.59%] [G loss: 4.531402]\n",
      "epoch:30 step:23941 [D loss: 0.110444, acc: 97.66%] [G loss: 5.460392]\n",
      "epoch:30 step:23942 [D loss: 0.278635, acc: 94.53%] [G loss: 4.008975]\n",
      "epoch:30 step:23943 [D loss: 0.368365, acc: 78.91%] [G loss: 3.314590]\n",
      "epoch:30 step:23944 [D loss: 0.552543, acc: 73.44%] [G loss: 4.545170]\n",
      "epoch:30 step:23945 [D loss: 0.767901, acc: 52.34%] [G loss: 3.871608]\n",
      "epoch:30 step:23946 [D loss: 0.253500, acc: 92.19%] [G loss: 3.275027]\n",
      "epoch:30 step:23947 [D loss: 0.121727, acc: 99.22%] [G loss: 5.563222]\n",
      "epoch:30 step:23948 [D loss: 0.216742, acc: 97.66%] [G loss: 4.133204]\n",
      "epoch:30 step:23949 [D loss: 1.107840, acc: 40.62%] [G loss: 2.574929]\n",
      "epoch:30 step:23950 [D loss: 0.610870, acc: 63.28%] [G loss: 2.499924]\n",
      "epoch:30 step:23951 [D loss: 0.142939, acc: 98.44%] [G loss: 3.268266]\n",
      "epoch:30 step:23952 [D loss: 0.433853, acc: 78.12%] [G loss: 3.203171]\n",
      "epoch:30 step:23953 [D loss: 0.080875, acc: 100.00%] [G loss: 5.269071]\n",
      "epoch:30 step:23954 [D loss: 0.878273, acc: 51.56%] [G loss: 4.057123]\n",
      "epoch:30 step:23955 [D loss: 0.752324, acc: 52.34%] [G loss: 4.102460]\n",
      "epoch:30 step:23956 [D loss: 0.626574, acc: 65.62%] [G loss: 7.031199]\n",
      "epoch:30 step:23957 [D loss: 0.272475, acc: 95.31%] [G loss: 3.541713]\n",
      "epoch:30 step:23958 [D loss: 0.862007, acc: 44.53%] [G loss: 3.091273]\n",
      "epoch:30 step:23959 [D loss: 0.344063, acc: 86.72%] [G loss: 2.935608]\n",
      "epoch:30 step:23960 [D loss: 0.535949, acc: 71.88%] [G loss: 5.506315]\n",
      "epoch:30 step:23961 [D loss: 0.251309, acc: 94.53%] [G loss: 1.745869]\n",
      "epoch:30 step:23962 [D loss: 0.175169, acc: 98.44%] [G loss: 5.351989]\n",
      "epoch:30 step:23963 [D loss: 0.847895, acc: 51.56%] [G loss: 5.661467]\n",
      "epoch:30 step:23964 [D loss: 0.455075, acc: 82.81%] [G loss: 4.399166]\n",
      "epoch:30 step:23965 [D loss: 0.336435, acc: 91.41%] [G loss: 4.916490]\n",
      "epoch:30 step:23966 [D loss: 0.546977, acc: 63.28%] [G loss: 6.317201]\n",
      "epoch:30 step:23967 [D loss: 0.100590, acc: 99.22%] [G loss: 7.078743]\n",
      "epoch:30 step:23968 [D loss: 0.053754, acc: 100.00%] [G loss: 6.767731]\n",
      "epoch:30 step:23969 [D loss: 0.423294, acc: 88.28%] [G loss: 3.938539]\n",
      "epoch:30 step:23970 [D loss: 0.335227, acc: 88.28%] [G loss: 5.071505]\n",
      "epoch:30 step:23971 [D loss: 0.079095, acc: 100.00%] [G loss: 6.010973]\n",
      "epoch:30 step:23972 [D loss: 0.042237, acc: 100.00%] [G loss: 3.451415]\n",
      "epoch:30 step:23973 [D loss: 0.584879, acc: 67.97%] [G loss: 5.813818]\n",
      "epoch:30 step:23974 [D loss: 1.262866, acc: 10.16%] [G loss: 4.999193]\n",
      "epoch:30 step:23975 [D loss: 0.243243, acc: 94.53%] [G loss: 4.390481]\n",
      "epoch:30 step:23976 [D loss: 0.201394, acc: 96.88%] [G loss: 2.966536]\n",
      "epoch:30 step:23977 [D loss: 0.256772, acc: 90.62%] [G loss: 2.695717]\n",
      "epoch:30 step:23978 [D loss: 0.136365, acc: 99.22%] [G loss: 5.620891]\n",
      "epoch:30 step:23979 [D loss: 0.244886, acc: 95.31%] [G loss: 4.337144]\n",
      "epoch:30 step:23980 [D loss: 0.106876, acc: 100.00%] [G loss: 5.752148]\n",
      "epoch:30 step:23981 [D loss: 0.501443, acc: 66.41%] [G loss: 4.939555]\n",
      "epoch:30 step:23982 [D loss: 0.283751, acc: 92.19%] [G loss: 4.248456]\n",
      "epoch:30 step:23983 [D loss: 0.169809, acc: 99.22%] [G loss: 3.781769]\n",
      "epoch:30 step:23984 [D loss: 0.141269, acc: 100.00%] [G loss: 3.978955]\n",
      "epoch:30 step:23985 [D loss: 0.066551, acc: 100.00%] [G loss: 4.632194]\n",
      "epoch:30 step:23986 [D loss: 0.763813, acc: 50.00%] [G loss: 4.596241]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:30 step:23987 [D loss: 0.143733, acc: 100.00%] [G loss: 4.922982]\n",
      "epoch:30 step:23988 [D loss: 0.192840, acc: 99.22%] [G loss: 3.259465]\n",
      "epoch:30 step:23989 [D loss: 0.400016, acc: 85.94%] [G loss: 6.262484]\n",
      "epoch:30 step:23990 [D loss: 0.366778, acc: 77.34%] [G loss: 4.638225]\n",
      "epoch:30 step:23991 [D loss: 0.246322, acc: 97.66%] [G loss: 3.813079]\n",
      "epoch:30 step:23992 [D loss: 0.275002, acc: 93.75%] [G loss: 3.283917]\n",
      "epoch:30 step:23993 [D loss: 0.641527, acc: 67.19%] [G loss: 6.698274]\n",
      "epoch:30 step:23994 [D loss: 0.148282, acc: 100.00%] [G loss: 4.239280]\n",
      "epoch:30 step:23995 [D loss: 0.610104, acc: 64.84%] [G loss: 1.718718]\n",
      "epoch:30 step:23996 [D loss: 0.506054, acc: 78.12%] [G loss: 4.631639]\n",
      "epoch:30 step:23997 [D loss: 0.653764, acc: 58.59%] [G loss: 4.909318]\n",
      "epoch:30 step:23998 [D loss: 1.306572, acc: 14.06%] [G loss: 4.564317]\n",
      "epoch:30 step:23999 [D loss: 0.692267, acc: 53.91%] [G loss: 6.335552]\n",
      "epoch:30 step:24000 [D loss: 0.298420, acc: 91.41%] [G loss: 3.269828]\n",
      "##############\n",
      "[0.86031683 0.85986389 0.81462041 0.82694097 0.80860046 0.84423663\n",
      " 0.91302365 0.81520279 0.82300017 0.82717806]\n",
      "##########\n",
      "epoch:30 step:24001 [D loss: 0.431522, acc: 85.16%] [G loss: 5.179176]\n",
      "epoch:30 step:24002 [D loss: 0.456701, acc: 84.38%] [G loss: 4.073113]\n",
      "epoch:30 step:24003 [D loss: 0.684012, acc: 63.28%] [G loss: 5.092310]\n",
      "epoch:30 step:24004 [D loss: 0.699965, acc: 61.72%] [G loss: 3.099675]\n",
      "epoch:30 step:24005 [D loss: 0.264916, acc: 96.09%] [G loss: 3.020216]\n",
      "epoch:30 step:24006 [D loss: 0.755605, acc: 59.38%] [G loss: 2.537053]\n",
      "epoch:30 step:24007 [D loss: 0.203682, acc: 96.88%] [G loss: 5.473063]\n",
      "epoch:30 step:24008 [D loss: 0.086492, acc: 100.00%] [G loss: 3.911636]\n",
      "epoch:30 step:24009 [D loss: 0.394343, acc: 85.94%] [G loss: 6.309747]\n",
      "epoch:30 step:24010 [D loss: 0.260868, acc: 90.62%] [G loss: 3.760169]\n",
      "epoch:30 step:24011 [D loss: 0.601898, acc: 61.72%] [G loss: 5.226952]\n",
      "epoch:30 step:24012 [D loss: 0.313612, acc: 84.38%] [G loss: 5.900703]\n",
      "epoch:30 step:24013 [D loss: 0.358597, acc: 88.28%] [G loss: 5.136691]\n",
      "epoch:30 step:24014 [D loss: 0.092178, acc: 100.00%] [G loss: 4.927972]\n",
      "epoch:30 step:24015 [D loss: 0.321346, acc: 91.41%] [G loss: 3.834136]\n",
      "epoch:30 step:24016 [D loss: 0.245324, acc: 97.66%] [G loss: 6.109447]\n",
      "epoch:30 step:24017 [D loss: 0.271489, acc: 94.53%] [G loss: 4.195547]\n",
      "epoch:30 step:24018 [D loss: 0.192210, acc: 97.66%] [G loss: 4.485948]\n",
      "epoch:30 step:24019 [D loss: 0.160441, acc: 99.22%] [G loss: 3.705156]\n",
      "epoch:30 step:24020 [D loss: 0.054583, acc: 100.00%] [G loss: 3.027059]\n",
      "epoch:30 step:24021 [D loss: 0.331109, acc: 85.16%] [G loss: 3.738071]\n",
      "epoch:30 step:24022 [D loss: 0.295917, acc: 92.97%] [G loss: 4.117446]\n",
      "epoch:30 step:24023 [D loss: 0.396383, acc: 86.72%] [G loss: 4.416030]\n",
      "epoch:30 step:24024 [D loss: 0.401265, acc: 80.47%] [G loss: 5.039797]\n",
      "epoch:30 step:24025 [D loss: 0.256397, acc: 97.66%] [G loss: 3.229346]\n",
      "epoch:30 step:24026 [D loss: 1.126513, acc: 50.00%] [G loss: 2.044923]\n",
      "epoch:30 step:24027 [D loss: 0.318767, acc: 95.31%] [G loss: 2.398803]\n",
      "epoch:30 step:24028 [D loss: 0.302987, acc: 92.19%] [G loss: 5.678405]\n",
      "epoch:30 step:24029 [D loss: 0.670265, acc: 60.16%] [G loss: 4.251797]\n",
      "epoch:30 step:24030 [D loss: 0.313840, acc: 95.31%] [G loss: 4.130754]\n",
      "epoch:30 step:24031 [D loss: 0.773303, acc: 48.44%] [G loss: 4.944863]\n",
      "epoch:30 step:24032 [D loss: 0.244733, acc: 98.44%] [G loss: 4.445118]\n",
      "epoch:30 step:24033 [D loss: 0.134191, acc: 100.00%] [G loss: 3.379809]\n",
      "epoch:30 step:24034 [D loss: 0.604059, acc: 64.84%] [G loss: 2.166391]\n",
      "epoch:30 step:24035 [D loss: 0.711300, acc: 58.59%] [G loss: 4.985546]\n",
      "epoch:30 step:24036 [D loss: 1.304812, acc: 42.97%] [G loss: 4.737417]\n",
      "epoch:30 step:24037 [D loss: 0.606470, acc: 65.62%] [G loss: 3.649617]\n",
      "epoch:30 step:24038 [D loss: 0.304495, acc: 93.75%] [G loss: 4.451727]\n",
      "epoch:30 step:24039 [D loss: 0.532066, acc: 61.72%] [G loss: 5.549407]\n",
      "epoch:30 step:24040 [D loss: 0.247246, acc: 92.19%] [G loss: 3.805550]\n",
      "epoch:30 step:24041 [D loss: 0.114012, acc: 99.22%] [G loss: 2.224885]\n",
      "epoch:30 step:24042 [D loss: 0.243254, acc: 94.53%] [G loss: 3.186092]\n",
      "epoch:30 step:24043 [D loss: 0.754859, acc: 57.03%] [G loss: 3.622862]\n",
      "epoch:30 step:24044 [D loss: 0.070591, acc: 100.00%] [G loss: 5.203396]\n",
      "epoch:30 step:24045 [D loss: 0.220416, acc: 92.97%] [G loss: 7.524254]\n",
      "epoch:30 step:24046 [D loss: 0.275122, acc: 89.06%] [G loss: 5.070911]\n",
      "epoch:30 step:24047 [D loss: 1.244173, acc: 19.53%] [G loss: 6.204217]\n",
      "epoch:30 step:24048 [D loss: 0.579694, acc: 69.53%] [G loss: 3.531146]\n",
      "epoch:30 step:24049 [D loss: 0.367464, acc: 75.00%] [G loss: 4.100289]\n",
      "epoch:30 step:24050 [D loss: 0.194657, acc: 99.22%] [G loss: 3.239500]\n",
      "epoch:30 step:24051 [D loss: 0.349668, acc: 93.75%] [G loss: 4.454119]\n",
      "epoch:30 step:24052 [D loss: 0.429053, acc: 78.12%] [G loss: 4.422283]\n",
      "epoch:30 step:24053 [D loss: 0.134774, acc: 99.22%] [G loss: 2.594329]\n",
      "epoch:30 step:24054 [D loss: 0.250089, acc: 92.19%] [G loss: 3.135100]\n",
      "epoch:30 step:24055 [D loss: 0.055088, acc: 99.22%] [G loss: 3.767771]\n",
      "epoch:30 step:24056 [D loss: 0.799537, acc: 50.00%] [G loss: 5.315488]\n",
      "epoch:30 step:24057 [D loss: 0.529703, acc: 69.53%] [G loss: 2.731955]\n",
      "epoch:30 step:24058 [D loss: 0.131274, acc: 97.66%] [G loss: 4.478827]\n",
      "epoch:30 step:24059 [D loss: 0.232274, acc: 92.19%] [G loss: 3.840358]\n",
      "epoch:30 step:24060 [D loss: 0.110583, acc: 99.22%] [G loss: 2.752879]\n",
      "epoch:30 step:24061 [D loss: 0.080796, acc: 100.00%] [G loss: 3.910517]\n",
      "epoch:30 step:24062 [D loss: 0.302473, acc: 93.75%] [G loss: 2.067996]\n",
      "epoch:30 step:24063 [D loss: 0.743131, acc: 57.03%] [G loss: 2.822722]\n",
      "epoch:30 step:24064 [D loss: 0.488154, acc: 67.19%] [G loss: 4.222545]\n",
      "epoch:30 step:24065 [D loss: 0.834756, acc: 49.22%] [G loss: 4.026297]\n",
      "epoch:30 step:24066 [D loss: 0.787207, acc: 52.34%] [G loss: 4.313891]\n",
      "epoch:30 step:24067 [D loss: 0.316471, acc: 89.84%] [G loss: 3.643890]\n",
      "epoch:30 step:24068 [D loss: 0.193754, acc: 96.88%] [G loss: 3.789346]\n",
      "epoch:30 step:24069 [D loss: 0.176478, acc: 94.53%] [G loss: 7.837741]\n",
      "epoch:30 step:24070 [D loss: 0.299981, acc: 92.97%] [G loss: 3.872060]\n",
      "epoch:30 step:24071 [D loss: 1.034438, acc: 41.41%] [G loss: 5.076915]\n",
      "epoch:30 step:24072 [D loss: 0.234950, acc: 95.31%] [G loss: 2.851696]\n",
      "epoch:30 step:24073 [D loss: 0.893801, acc: 50.78%] [G loss: 3.504296]\n",
      "epoch:30 step:24074 [D loss: 0.271557, acc: 96.88%] [G loss: 4.222870]\n",
      "epoch:30 step:24075 [D loss: 0.621821, acc: 61.72%] [G loss: 5.830871]\n",
      "epoch:30 step:24076 [D loss: 1.187255, acc: 49.22%] [G loss: 4.620592]\n",
      "epoch:30 step:24077 [D loss: 0.052506, acc: 100.00%] [G loss: 3.556821]\n",
      "epoch:30 step:24078 [D loss: 0.332017, acc: 85.94%] [G loss: 4.855000]\n",
      "epoch:30 step:24079 [D loss: 0.107845, acc: 100.00%] [G loss: 4.934310]\n",
      "epoch:30 step:24080 [D loss: 0.148216, acc: 99.22%] [G loss: 2.896255]\n",
      "epoch:30 step:24081 [D loss: 0.248967, acc: 92.97%] [G loss: 3.549059]\n",
      "epoch:30 step:24082 [D loss: 0.213380, acc: 96.09%] [G loss: 3.346792]\n",
      "epoch:30 step:24083 [D loss: 0.117516, acc: 100.00%] [G loss: 5.326301]\n",
      "epoch:30 step:24084 [D loss: 0.625946, acc: 62.50%] [G loss: 6.373573]\n",
      "epoch:30 step:24085 [D loss: 0.177611, acc: 99.22%] [G loss: 7.286602]\n",
      "epoch:30 step:24086 [D loss: 0.291694, acc: 93.75%] [G loss: 4.611305]\n",
      "epoch:30 step:24087 [D loss: 0.388956, acc: 78.12%] [G loss: 3.712344]\n",
      "epoch:30 step:24088 [D loss: 0.311567, acc: 95.31%] [G loss: 4.544982]\n",
      "epoch:30 step:24089 [D loss: 0.222242, acc: 93.75%] [G loss: 5.163442]\n",
      "epoch:30 step:24090 [D loss: 0.355765, acc: 78.91%] [G loss: 3.213423]\n",
      "epoch:30 step:24091 [D loss: 0.054004, acc: 100.00%] [G loss: 6.688910]\n",
      "epoch:30 step:24092 [D loss: 0.373744, acc: 87.50%] [G loss: 8.451540]\n",
      "epoch:30 step:24093 [D loss: 0.162843, acc: 97.66%] [G loss: 4.512036]\n",
      "epoch:30 step:24094 [D loss: 0.176300, acc: 96.88%] [G loss: 3.015318]\n",
      "epoch:30 step:24095 [D loss: 0.386396, acc: 77.34%] [G loss: 6.630583]\n",
      "epoch:30 step:24096 [D loss: 0.259489, acc: 94.53%] [G loss: 4.881849]\n",
      "epoch:30 step:24097 [D loss: 0.145593, acc: 98.44%] [G loss: 4.706820]\n",
      "epoch:30 step:24098 [D loss: 0.571489, acc: 59.38%] [G loss: 5.170369]\n",
      "epoch:30 step:24099 [D loss: 0.335579, acc: 90.62%] [G loss: 4.749244]\n",
      "epoch:30 step:24100 [D loss: 0.503055, acc: 79.69%] [G loss: 3.841607]\n",
      "epoch:30 step:24101 [D loss: 0.064846, acc: 100.00%] [G loss: 6.779659]\n",
      "epoch:30 step:24102 [D loss: 0.667741, acc: 63.28%] [G loss: 2.676313]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:30 step:24103 [D loss: 0.424211, acc: 88.28%] [G loss: 4.733501]\n",
      "epoch:30 step:24104 [D loss: 0.069015, acc: 100.00%] [G loss: 5.511152]\n",
      "epoch:30 step:24105 [D loss: 0.069073, acc: 100.00%] [G loss: 4.565585]\n",
      "epoch:30 step:24106 [D loss: 0.160542, acc: 99.22%] [G loss: 4.072544]\n",
      "epoch:30 step:24107 [D loss: 1.300143, acc: 39.84%] [G loss: 5.536580]\n",
      "epoch:30 step:24108 [D loss: 0.362828, acc: 90.62%] [G loss: 3.777848]\n",
      "epoch:30 step:24109 [D loss: 0.176688, acc: 100.00%] [G loss: 5.436126]\n",
      "epoch:30 step:24110 [D loss: 0.123200, acc: 100.00%] [G loss: 6.242411]\n",
      "epoch:30 step:24111 [D loss: 0.566495, acc: 72.66%] [G loss: 4.279761]\n",
      "epoch:30 step:24112 [D loss: 0.046196, acc: 100.00%] [G loss: 4.673684]\n",
      "epoch:30 step:24113 [D loss: 0.539558, acc: 73.44%] [G loss: 5.856026]\n",
      "epoch:30 step:24114 [D loss: 1.281398, acc: 32.03%] [G loss: 3.344455]\n",
      "epoch:30 step:24115 [D loss: 1.786538, acc: 1.56%] [G loss: 4.747042]\n",
      "epoch:30 step:24116 [D loss: 0.179156, acc: 99.22%] [G loss: 3.879262]\n",
      "epoch:30 step:24117 [D loss: 0.438560, acc: 81.25%] [G loss: 5.269437]\n",
      "epoch:30 step:24118 [D loss: 0.293616, acc: 94.53%] [G loss: 3.750776]\n",
      "epoch:30 step:24119 [D loss: 0.542715, acc: 71.09%] [G loss: 5.534135]\n",
      "epoch:30 step:24120 [D loss: 0.477895, acc: 72.66%] [G loss: 6.122587]\n",
      "epoch:30 step:24121 [D loss: 0.457929, acc: 84.38%] [G loss: 4.400550]\n",
      "epoch:30 step:24122 [D loss: 0.684382, acc: 57.81%] [G loss: 5.984614]\n",
      "epoch:30 step:24123 [D loss: 0.444350, acc: 85.16%] [G loss: 3.603309]\n",
      "epoch:30 step:24124 [D loss: 0.108513, acc: 99.22%] [G loss: 6.034903]\n",
      "epoch:30 step:24125 [D loss: 0.086355, acc: 100.00%] [G loss: 5.280371]\n",
      "epoch:30 step:24126 [D loss: 0.353324, acc: 91.41%] [G loss: 2.365331]\n",
      "epoch:30 step:24127 [D loss: 0.326812, acc: 90.62%] [G loss: 4.137912]\n",
      "epoch:30 step:24128 [D loss: 0.156646, acc: 100.00%] [G loss: 3.615309]\n",
      "epoch:30 step:24129 [D loss: 0.138010, acc: 98.44%] [G loss: 3.639109]\n",
      "epoch:30 step:24130 [D loss: 0.369326, acc: 81.25%] [G loss: 3.741963]\n",
      "epoch:30 step:24131 [D loss: 0.356912, acc: 85.16%] [G loss: 4.321661]\n",
      "epoch:30 step:24132 [D loss: 0.912958, acc: 50.78%] [G loss: 3.553782]\n",
      "epoch:30 step:24133 [D loss: 0.355324, acc: 91.41%] [G loss: 3.429302]\n",
      "epoch:30 step:24134 [D loss: 0.279222, acc: 92.97%] [G loss: 2.485896]\n",
      "epoch:30 step:24135 [D loss: 0.124713, acc: 100.00%] [G loss: 3.413848]\n",
      "epoch:30 step:24136 [D loss: 0.241850, acc: 91.41%] [G loss: 3.247776]\n",
      "epoch:30 step:24137 [D loss: 0.101585, acc: 100.00%] [G loss: 4.268361]\n",
      "epoch:30 step:24138 [D loss: 0.146216, acc: 99.22%] [G loss: 3.221487]\n",
      "epoch:30 step:24139 [D loss: 0.287889, acc: 92.97%] [G loss: 3.658993]\n",
      "epoch:30 step:24140 [D loss: 0.248995, acc: 95.31%] [G loss: 6.078179]\n",
      "epoch:30 step:24141 [D loss: 0.121116, acc: 100.00%] [G loss: 4.332248]\n",
      "epoch:30 step:24142 [D loss: 0.765236, acc: 53.12%] [G loss: 5.309328]\n",
      "epoch:30 step:24143 [D loss: 0.081325, acc: 99.22%] [G loss: 8.447531]\n",
      "epoch:30 step:24144 [D loss: 0.430040, acc: 83.59%] [G loss: 5.143465]\n",
      "epoch:30 step:24145 [D loss: 0.220466, acc: 100.00%] [G loss: 4.403135]\n",
      "epoch:30 step:24146 [D loss: 0.486308, acc: 79.69%] [G loss: 7.787154]\n",
      "epoch:30 step:24147 [D loss: 0.071918, acc: 100.00%] [G loss: 4.483210]\n",
      "epoch:30 step:24148 [D loss: 0.099156, acc: 100.00%] [G loss: 5.101139]\n",
      "epoch:30 step:24149 [D loss: 0.597263, acc: 67.19%] [G loss: 6.592006]\n",
      "epoch:30 step:24150 [D loss: 0.564164, acc: 63.28%] [G loss: 3.488368]\n",
      "epoch:30 step:24151 [D loss: 0.353140, acc: 94.53%] [G loss: 4.588707]\n",
      "epoch:30 step:24152 [D loss: 0.113087, acc: 99.22%] [G loss: 3.653664]\n",
      "epoch:30 step:24153 [D loss: 0.046840, acc: 100.00%] [G loss: 3.866192]\n",
      "epoch:30 step:24154 [D loss: 0.248894, acc: 91.41%] [G loss: 3.608644]\n",
      "epoch:30 step:24155 [D loss: 0.484502, acc: 79.69%] [G loss: 5.577262]\n",
      "epoch:30 step:24156 [D loss: 0.194647, acc: 98.44%] [G loss: 4.309119]\n",
      "epoch:30 step:24157 [D loss: 0.269137, acc: 94.53%] [G loss: 3.690736]\n",
      "epoch:30 step:24158 [D loss: 0.434843, acc: 75.00%] [G loss: 2.084169]\n",
      "epoch:30 step:24159 [D loss: 0.454790, acc: 85.16%] [G loss: 3.801116]\n",
      "epoch:30 step:24160 [D loss: 0.410846, acc: 84.38%] [G loss: 4.870848]\n",
      "epoch:30 step:24161 [D loss: 0.362144, acc: 87.50%] [G loss: 5.053062]\n",
      "epoch:30 step:24162 [D loss: 0.533566, acc: 74.22%] [G loss: 3.367928]\n",
      "epoch:30 step:24163 [D loss: 0.115762, acc: 100.00%] [G loss: 2.502095]\n",
      "epoch:30 step:24164 [D loss: 0.467527, acc: 82.03%] [G loss: 3.937267]\n",
      "epoch:30 step:24165 [D loss: 0.388138, acc: 74.22%] [G loss: 4.562289]\n",
      "epoch:30 step:24166 [D loss: 0.059806, acc: 100.00%] [G loss: 4.230664]\n",
      "epoch:30 step:24167 [D loss: 0.081717, acc: 100.00%] [G loss: 5.810385]\n",
      "epoch:30 step:24168 [D loss: 0.220441, acc: 96.09%] [G loss: 5.248466]\n",
      "epoch:30 step:24169 [D loss: 0.191197, acc: 98.44%] [G loss: 6.575651]\n",
      "epoch:30 step:24170 [D loss: 0.429297, acc: 78.91%] [G loss: 4.292240]\n",
      "epoch:30 step:24171 [D loss: 0.397662, acc: 88.28%] [G loss: 5.447091]\n",
      "epoch:30 step:24172 [D loss: 0.300385, acc: 94.53%] [G loss: 4.152348]\n",
      "epoch:30 step:24173 [D loss: 0.720260, acc: 51.56%] [G loss: 5.481591]\n",
      "epoch:30 step:24174 [D loss: 0.816451, acc: 53.91%] [G loss: 4.276601]\n",
      "epoch:30 step:24175 [D loss: 0.364624, acc: 84.38%] [G loss: 2.040023]\n",
      "epoch:30 step:24176 [D loss: 0.659074, acc: 61.72%] [G loss: 3.955900]\n",
      "epoch:30 step:24177 [D loss: 0.335930, acc: 86.72%] [G loss: 6.306685]\n",
      "epoch:30 step:24178 [D loss: 0.215284, acc: 94.53%] [G loss: 4.274634]\n",
      "epoch:30 step:24179 [D loss: 0.351147, acc: 95.31%] [G loss: 3.630611]\n",
      "epoch:30 step:24180 [D loss: 0.338413, acc: 90.62%] [G loss: 3.764760]\n",
      "epoch:30 step:24181 [D loss: 0.372531, acc: 77.34%] [G loss: 5.555627]\n",
      "epoch:30 step:24182 [D loss: 0.833597, acc: 52.34%] [G loss: 4.286175]\n",
      "epoch:30 step:24183 [D loss: 0.243585, acc: 92.19%] [G loss: 5.349551]\n",
      "epoch:30 step:24184 [D loss: 1.156496, acc: 46.09%] [G loss: 7.235888]\n",
      "epoch:30 step:24185 [D loss: 1.071956, acc: 49.22%] [G loss: 5.605918]\n",
      "epoch:30 step:24186 [D loss: 0.126782, acc: 98.44%] [G loss: 4.454479]\n",
      "epoch:30 step:24187 [D loss: 0.736680, acc: 58.59%] [G loss: 7.310000]\n",
      "epoch:30 step:24188 [D loss: 0.738650, acc: 56.25%] [G loss: 4.033772]\n",
      "epoch:30 step:24189 [D loss: 0.491169, acc: 80.47%] [G loss: 5.991409]\n",
      "epoch:30 step:24190 [D loss: 0.037463, acc: 100.00%] [G loss: 8.804245]\n",
      "epoch:30 step:24191 [D loss: 0.218236, acc: 95.31%] [G loss: 6.332646]\n",
      "epoch:30 step:24192 [D loss: 0.184652, acc: 96.09%] [G loss: 5.270761]\n",
      "epoch:30 step:24193 [D loss: 0.206985, acc: 95.31%] [G loss: 5.992882]\n",
      "epoch:30 step:24194 [D loss: 0.267002, acc: 92.97%] [G loss: 3.734932]\n",
      "epoch:30 step:24195 [D loss: 0.106532, acc: 99.22%] [G loss: 5.645444]\n",
      "epoch:30 step:24196 [D loss: 0.186626, acc: 99.22%] [G loss: 3.974275]\n",
      "epoch:30 step:24197 [D loss: 0.254258, acc: 94.53%] [G loss: 2.784147]\n",
      "epoch:30 step:24198 [D loss: 0.026045, acc: 100.00%] [G loss: 7.996065]\n",
      "epoch:30 step:24199 [D loss: 0.785157, acc: 52.34%] [G loss: 4.612431]\n",
      "epoch:30 step:24200 [D loss: 0.080725, acc: 100.00%] [G loss: 6.405727]\n",
      "##############\n",
      "[0.85358342 0.87305504 0.83388009 0.81483124 0.81486521 0.82636385\n",
      " 0.90015917 0.82011198 0.77714832 0.82448606]\n",
      "##########\n",
      "epoch:30 step:24201 [D loss: 0.251835, acc: 96.88%] [G loss: 2.140200]\n",
      "epoch:30 step:24202 [D loss: 0.288531, acc: 92.97%] [G loss: 4.723061]\n",
      "epoch:30 step:24203 [D loss: 0.937382, acc: 50.78%] [G loss: 6.319802]\n",
      "epoch:30 step:24204 [D loss: 0.529134, acc: 71.09%] [G loss: 4.983830]\n",
      "epoch:30 step:24205 [D loss: 0.257198, acc: 89.06%] [G loss: 5.371341]\n",
      "epoch:30 step:24206 [D loss: 0.123333, acc: 100.00%] [G loss: 5.122446]\n",
      "epoch:30 step:24207 [D loss: 1.044302, acc: 40.62%] [G loss: 3.713050]\n",
      "epoch:30 step:24208 [D loss: 0.395675, acc: 89.84%] [G loss: 1.701356]\n",
      "epoch:30 step:24209 [D loss: 0.391949, acc: 78.12%] [G loss: 3.138046]\n",
      "epoch:30 step:24210 [D loss: 0.400522, acc: 84.38%] [G loss: 4.610971]\n",
      "epoch:30 step:24211 [D loss: 0.407185, acc: 82.81%] [G loss: 2.933525]\n",
      "epoch:31 step:24212 [D loss: 0.355254, acc: 79.69%] [G loss: 3.588868]\n",
      "epoch:31 step:24213 [D loss: 0.618591, acc: 64.84%] [G loss: 4.894804]\n",
      "epoch:31 step:24214 [D loss: 0.210519, acc: 97.66%] [G loss: 2.786304]\n",
      "epoch:31 step:24215 [D loss: 1.006393, acc: 42.97%] [G loss: 3.807409]\n",
      "epoch:31 step:24216 [D loss: 0.287392, acc: 92.97%] [G loss: 2.075412]\n",
      "epoch:31 step:24217 [D loss: 0.236836, acc: 93.75%] [G loss: 2.357263]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:31 step:24218 [D loss: 0.207491, acc: 96.09%] [G loss: 3.326307]\n",
      "epoch:31 step:24219 [D loss: 0.396500, acc: 78.91%] [G loss: 3.307931]\n",
      "epoch:31 step:24220 [D loss: 0.258104, acc: 92.97%] [G loss: 5.038651]\n",
      "epoch:31 step:24221 [D loss: 0.190911, acc: 99.22%] [G loss: 3.827492]\n",
      "epoch:31 step:24222 [D loss: 0.532715, acc: 69.53%] [G loss: 3.119628]\n",
      "epoch:31 step:24223 [D loss: 0.912078, acc: 42.19%] [G loss: 3.220175]\n",
      "epoch:31 step:24224 [D loss: 0.419279, acc: 71.88%] [G loss: 4.889997]\n",
      "epoch:31 step:24225 [D loss: 0.221723, acc: 93.75%] [G loss: 5.819436]\n",
      "epoch:31 step:24226 [D loss: 0.519655, acc: 70.31%] [G loss: 3.816000]\n",
      "epoch:31 step:24227 [D loss: 0.259019, acc: 96.88%] [G loss: 3.713971]\n",
      "epoch:31 step:24228 [D loss: 0.245533, acc: 92.19%] [G loss: 4.244779]\n",
      "epoch:31 step:24229 [D loss: 0.287855, acc: 95.31%] [G loss: 4.852433]\n",
      "epoch:31 step:24230 [D loss: 0.181913, acc: 99.22%] [G loss: 4.496061]\n",
      "epoch:31 step:24231 [D loss: 0.156294, acc: 99.22%] [G loss: 4.618903]\n",
      "epoch:31 step:24232 [D loss: 0.085177, acc: 100.00%] [G loss: 7.138703]\n",
      "epoch:31 step:24233 [D loss: 0.534669, acc: 74.22%] [G loss: 4.632031]\n",
      "epoch:31 step:24234 [D loss: 0.214706, acc: 97.66%] [G loss: 2.953945]\n",
      "epoch:31 step:24235 [D loss: 2.216467, acc: 0.78%] [G loss: 3.974872]\n",
      "epoch:31 step:24236 [D loss: 0.015800, acc: 100.00%] [G loss: 6.676198]\n",
      "epoch:31 step:24237 [D loss: 0.721947, acc: 54.69%] [G loss: 5.503530]\n",
      "epoch:31 step:24238 [D loss: 0.402084, acc: 69.53%] [G loss: 3.348709]\n",
      "epoch:31 step:24239 [D loss: 0.215097, acc: 94.53%] [G loss: 4.858789]\n",
      "epoch:31 step:24240 [D loss: 0.545907, acc: 75.78%] [G loss: 5.798831]\n",
      "epoch:31 step:24241 [D loss: 0.071168, acc: 100.00%] [G loss: 7.205275]\n",
      "epoch:31 step:24242 [D loss: 0.501559, acc: 72.66%] [G loss: 5.589014]\n",
      "epoch:31 step:24243 [D loss: 0.411210, acc: 84.38%] [G loss: 2.314118]\n",
      "epoch:31 step:24244 [D loss: 0.361248, acc: 88.28%] [G loss: 4.301920]\n",
      "epoch:31 step:24245 [D loss: 0.692432, acc: 63.28%] [G loss: 3.986761]\n",
      "epoch:31 step:24246 [D loss: 0.479521, acc: 77.34%] [G loss: 3.435761]\n",
      "epoch:31 step:24247 [D loss: 0.041280, acc: 100.00%] [G loss: 5.659012]\n",
      "epoch:31 step:24248 [D loss: 0.535075, acc: 70.31%] [G loss: 4.616210]\n",
      "epoch:31 step:24249 [D loss: 0.201737, acc: 95.31%] [G loss: 3.953835]\n",
      "epoch:31 step:24250 [D loss: 0.390677, acc: 88.28%] [G loss: 4.636144]\n",
      "epoch:31 step:24251 [D loss: 0.177504, acc: 98.44%] [G loss: 4.159385]\n",
      "epoch:31 step:24252 [D loss: 0.201092, acc: 96.88%] [G loss: 3.241198]\n",
      "epoch:31 step:24253 [D loss: 0.290638, acc: 92.97%] [G loss: 3.350623]\n",
      "epoch:31 step:24254 [D loss: 0.231199, acc: 92.97%] [G loss: 5.197472]\n",
      "epoch:31 step:24255 [D loss: 0.158052, acc: 100.00%] [G loss: 4.180117]\n",
      "epoch:31 step:24256 [D loss: 0.443184, acc: 74.22%] [G loss: 3.598533]\n",
      "epoch:31 step:24257 [D loss: 0.928865, acc: 39.06%] [G loss: 5.725390]\n",
      "epoch:31 step:24258 [D loss: 0.131781, acc: 99.22%] [G loss: 2.618903]\n",
      "epoch:31 step:24259 [D loss: 0.290546, acc: 92.19%] [G loss: 3.855286]\n",
      "epoch:31 step:24260 [D loss: 1.427106, acc: 22.66%] [G loss: 5.460011]\n",
      "epoch:31 step:24261 [D loss: 0.616609, acc: 63.28%] [G loss: 3.632400]\n",
      "epoch:31 step:24262 [D loss: 0.406703, acc: 78.12%] [G loss: 4.776899]\n",
      "epoch:31 step:24263 [D loss: 0.109486, acc: 99.22%] [G loss: 3.883226]\n",
      "epoch:31 step:24264 [D loss: 0.242349, acc: 96.88%] [G loss: 4.585251]\n",
      "epoch:31 step:24265 [D loss: 0.094472, acc: 100.00%] [G loss: 3.564178]\n",
      "epoch:31 step:24266 [D loss: 0.360875, acc: 78.91%] [G loss: 7.703806]\n",
      "epoch:31 step:24267 [D loss: 0.274972, acc: 95.31%] [G loss: 3.947986]\n",
      "epoch:31 step:24268 [D loss: 0.258230, acc: 94.53%] [G loss: 5.278270]\n",
      "epoch:31 step:24269 [D loss: 0.345648, acc: 92.19%] [G loss: 4.564446]\n",
      "epoch:31 step:24270 [D loss: 0.085071, acc: 100.00%] [G loss: 4.857893]\n",
      "epoch:31 step:24271 [D loss: 0.326943, acc: 89.06%] [G loss: 2.630373]\n",
      "epoch:31 step:24272 [D loss: 0.261887, acc: 94.53%] [G loss: 2.210210]\n",
      "epoch:31 step:24273 [D loss: 0.184742, acc: 96.88%] [G loss: 3.810900]\n",
      "epoch:31 step:24274 [D loss: 0.150836, acc: 99.22%] [G loss: 4.753342]\n",
      "epoch:31 step:24275 [D loss: 0.309928, acc: 93.75%] [G loss: 4.882024]\n",
      "epoch:31 step:24276 [D loss: 0.535521, acc: 81.25%] [G loss: 4.263601]\n",
      "epoch:31 step:24277 [D loss: 0.697077, acc: 56.25%] [G loss: 5.620422]\n",
      "epoch:31 step:24278 [D loss: 0.280302, acc: 93.75%] [G loss: 2.940470]\n",
      "epoch:31 step:24279 [D loss: 1.169788, acc: 17.19%] [G loss: 5.223603]\n",
      "epoch:31 step:24280 [D loss: 0.673460, acc: 55.47%] [G loss: 3.019344]\n",
      "epoch:31 step:24281 [D loss: 0.262592, acc: 90.62%] [G loss: 5.813223]\n",
      "epoch:31 step:24282 [D loss: 0.349218, acc: 77.34%] [G loss: 2.917758]\n",
      "epoch:31 step:24283 [D loss: 0.955536, acc: 28.12%] [G loss: 4.140956]\n",
      "epoch:31 step:24284 [D loss: 0.365684, acc: 83.59%] [G loss: 3.166509]\n",
      "epoch:31 step:24285 [D loss: 0.121722, acc: 100.00%] [G loss: 6.129284]\n",
      "epoch:31 step:24286 [D loss: 0.799296, acc: 42.97%] [G loss: 3.686170]\n",
      "epoch:31 step:24287 [D loss: 0.415986, acc: 84.38%] [G loss: 6.878116]\n",
      "epoch:31 step:24288 [D loss: 0.355934, acc: 92.19%] [G loss: 5.275724]\n",
      "epoch:31 step:24289 [D loss: 0.292483, acc: 87.50%] [G loss: 5.089058]\n",
      "epoch:31 step:24290 [D loss: 0.813786, acc: 53.12%] [G loss: 3.600414]\n",
      "epoch:31 step:24291 [D loss: 0.342927, acc: 86.72%] [G loss: 3.238628]\n",
      "epoch:31 step:24292 [D loss: 0.542858, acc: 70.31%] [G loss: 6.509056]\n",
      "epoch:31 step:24293 [D loss: 0.170430, acc: 95.31%] [G loss: 5.044023]\n",
      "epoch:31 step:24294 [D loss: 0.072825, acc: 100.00%] [G loss: 4.576515]\n",
      "epoch:31 step:24295 [D loss: 0.567499, acc: 68.75%] [G loss: 3.882053]\n",
      "epoch:31 step:24296 [D loss: 0.153005, acc: 98.44%] [G loss: 3.424584]\n",
      "epoch:31 step:24297 [D loss: 0.268933, acc: 95.31%] [G loss: 5.285751]\n",
      "epoch:31 step:24298 [D loss: 0.381223, acc: 89.06%] [G loss: 4.765088]\n",
      "epoch:31 step:24299 [D loss: 0.422854, acc: 82.81%] [G loss: 4.484720]\n",
      "epoch:31 step:24300 [D loss: 0.501167, acc: 68.75%] [G loss: 3.659374]\n",
      "epoch:31 step:24301 [D loss: 0.221007, acc: 98.44%] [G loss: 7.068225]\n",
      "epoch:31 step:24302 [D loss: 0.065112, acc: 100.00%] [G loss: 6.606778]\n",
      "epoch:31 step:24303 [D loss: 0.181393, acc: 96.88%] [G loss: 6.661504]\n",
      "epoch:31 step:24304 [D loss: 0.444083, acc: 82.03%] [G loss: 8.346520]\n",
      "epoch:31 step:24305 [D loss: 0.717515, acc: 54.69%] [G loss: 4.906223]\n",
      "epoch:31 step:24306 [D loss: 0.754243, acc: 52.34%] [G loss: 5.178801]\n",
      "epoch:31 step:24307 [D loss: 0.287271, acc: 85.16%] [G loss: 5.346915]\n",
      "epoch:31 step:24308 [D loss: 0.211787, acc: 93.75%] [G loss: 2.985591]\n",
      "epoch:31 step:24309 [D loss: 0.188835, acc: 97.66%] [G loss: 4.300314]\n",
      "epoch:31 step:24310 [D loss: 0.300911, acc: 85.16%] [G loss: 3.575518]\n",
      "epoch:31 step:24311 [D loss: 0.311313, acc: 87.50%] [G loss: 6.643774]\n",
      "epoch:31 step:24312 [D loss: 0.311400, acc: 96.88%] [G loss: 3.451924]\n",
      "epoch:31 step:24313 [D loss: 0.282907, acc: 91.41%] [G loss: 5.888590]\n",
      "epoch:31 step:24314 [D loss: 0.498118, acc: 68.75%] [G loss: 5.585069]\n",
      "epoch:31 step:24315 [D loss: 0.881027, acc: 51.56%] [G loss: 4.733643]\n",
      "epoch:31 step:24316 [D loss: 0.533426, acc: 63.28%] [G loss: 6.352765]\n",
      "epoch:31 step:24317 [D loss: 0.287451, acc: 92.19%] [G loss: 3.318730]\n",
      "epoch:31 step:24318 [D loss: 0.292240, acc: 93.75%] [G loss: 4.401073]\n",
      "epoch:31 step:24319 [D loss: 0.363331, acc: 89.84%] [G loss: 6.411492]\n",
      "epoch:31 step:24320 [D loss: 0.133757, acc: 99.22%] [G loss: 3.969866]\n",
      "epoch:31 step:24321 [D loss: 0.156410, acc: 98.44%] [G loss: 4.297503]\n",
      "epoch:31 step:24322 [D loss: 1.224517, acc: 14.06%] [G loss: 4.594610]\n",
      "epoch:31 step:24323 [D loss: 0.608333, acc: 57.03%] [G loss: 5.075463]\n",
      "epoch:31 step:24324 [D loss: 0.131204, acc: 99.22%] [G loss: 4.383369]\n",
      "epoch:31 step:24325 [D loss: 0.230132, acc: 96.88%] [G loss: 4.523328]\n",
      "epoch:31 step:24326 [D loss: 0.115579, acc: 100.00%] [G loss: 2.935135]\n",
      "epoch:31 step:24327 [D loss: 1.240263, acc: 28.12%] [G loss: 5.112436]\n",
      "epoch:31 step:24328 [D loss: 0.334221, acc: 77.34%] [G loss: 3.460405]\n",
      "epoch:31 step:24329 [D loss: 0.243529, acc: 95.31%] [G loss: 5.711167]\n",
      "epoch:31 step:24330 [D loss: 0.180645, acc: 96.09%] [G loss: 6.035364]\n",
      "epoch:31 step:24331 [D loss: 0.759185, acc: 51.56%] [G loss: 2.971164]\n",
      "epoch:31 step:24332 [D loss: 0.068979, acc: 99.22%] [G loss: 7.109569]\n",
      "epoch:31 step:24333 [D loss: 0.097816, acc: 100.00%] [G loss: 5.833442]\n",
      "epoch:31 step:24334 [D loss: 0.351432, acc: 82.81%] [G loss: 5.537988]\n",
      "epoch:31 step:24335 [D loss: 0.304730, acc: 92.97%] [G loss: 4.457507]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:31 step:24336 [D loss: 0.828495, acc: 37.50%] [G loss: 3.803567]\n",
      "epoch:31 step:24337 [D loss: 0.152955, acc: 98.44%] [G loss: 5.465422]\n",
      "epoch:31 step:24338 [D loss: 0.582456, acc: 72.66%] [G loss: 4.071507]\n",
      "epoch:31 step:24339 [D loss: 0.313625, acc: 87.50%] [G loss: 4.693919]\n",
      "epoch:31 step:24340 [D loss: 0.262292, acc: 92.97%] [G loss: 6.285754]\n",
      "epoch:31 step:24341 [D loss: 1.384506, acc: 49.22%] [G loss: 4.336694]\n",
      "epoch:31 step:24342 [D loss: 0.886630, acc: 38.28%] [G loss: 4.322096]\n",
      "epoch:31 step:24343 [D loss: 0.693033, acc: 55.47%] [G loss: 3.477560]\n",
      "epoch:31 step:24344 [D loss: 0.483849, acc: 69.53%] [G loss: 2.147025]\n",
      "epoch:31 step:24345 [D loss: 0.838121, acc: 50.00%] [G loss: 3.987452]\n",
      "epoch:31 step:24346 [D loss: 0.547849, acc: 66.41%] [G loss: 7.230580]\n",
      "epoch:31 step:24347 [D loss: 0.272874, acc: 97.66%] [G loss: 5.252113]\n",
      "epoch:31 step:24348 [D loss: 0.099714, acc: 100.00%] [G loss: 3.004665]\n",
      "epoch:31 step:24349 [D loss: 0.704671, acc: 56.25%] [G loss: 3.281255]\n",
      "epoch:31 step:24350 [D loss: 0.260992, acc: 95.31%] [G loss: 4.782529]\n",
      "epoch:31 step:24351 [D loss: 0.301215, acc: 93.75%] [G loss: 6.316563]\n",
      "epoch:31 step:24352 [D loss: 0.208911, acc: 96.88%] [G loss: 3.381337]\n",
      "epoch:31 step:24353 [D loss: 0.221361, acc: 96.88%] [G loss: 5.920131]\n",
      "epoch:31 step:24354 [D loss: 0.223405, acc: 93.75%] [G loss: 8.442966]\n",
      "epoch:31 step:24355 [D loss: 0.296852, acc: 89.06%] [G loss: 5.806100]\n",
      "epoch:31 step:24356 [D loss: 0.129590, acc: 100.00%] [G loss: 4.636272]\n",
      "epoch:31 step:24357 [D loss: 0.092475, acc: 100.00%] [G loss: 4.528004]\n",
      "epoch:31 step:24358 [D loss: 0.448428, acc: 74.22%] [G loss: 5.190908]\n",
      "epoch:31 step:24359 [D loss: 0.392367, acc: 86.72%] [G loss: 3.961373]\n",
      "epoch:31 step:24360 [D loss: 0.088008, acc: 100.00%] [G loss: 6.874010]\n",
      "epoch:31 step:24361 [D loss: 0.607459, acc: 60.16%] [G loss: 4.303729]\n",
      "epoch:31 step:24362 [D loss: 0.320839, acc: 87.50%] [G loss: 2.962080]\n",
      "epoch:31 step:24363 [D loss: 0.598845, acc: 60.94%] [G loss: 4.848245]\n",
      "epoch:31 step:24364 [D loss: 0.261592, acc: 90.62%] [G loss: 4.946771]\n",
      "epoch:31 step:24365 [D loss: 0.783353, acc: 48.44%] [G loss: 4.458803]\n",
      "epoch:31 step:24366 [D loss: 0.515561, acc: 78.12%] [G loss: 4.391628]\n",
      "epoch:31 step:24367 [D loss: 0.732044, acc: 54.69%] [G loss: 6.945697]\n",
      "epoch:31 step:24368 [D loss: 0.492211, acc: 64.84%] [G loss: 3.759721]\n",
      "epoch:31 step:24369 [D loss: 0.076444, acc: 99.22%] [G loss: 5.839353]\n",
      "epoch:31 step:24370 [D loss: 0.317624, acc: 87.50%] [G loss: 4.363760]\n",
      "epoch:31 step:24371 [D loss: 0.087047, acc: 100.00%] [G loss: 7.314317]\n",
      "epoch:31 step:24372 [D loss: 0.293420, acc: 94.53%] [G loss: 5.724180]\n",
      "epoch:31 step:24373 [D loss: 0.271079, acc: 96.09%] [G loss: 3.289909]\n",
      "epoch:31 step:24374 [D loss: 0.221413, acc: 97.66%] [G loss: 5.532569]\n",
      "epoch:31 step:24375 [D loss: 0.103366, acc: 100.00%] [G loss: 2.041618]\n",
      "epoch:31 step:24376 [D loss: 0.286287, acc: 93.75%] [G loss: 5.802747]\n",
      "epoch:31 step:24377 [D loss: 0.543447, acc: 71.88%] [G loss: 4.305721]\n",
      "epoch:31 step:24378 [D loss: 0.089592, acc: 100.00%] [G loss: 4.366844]\n",
      "epoch:31 step:24379 [D loss: 0.288773, acc: 85.94%] [G loss: 7.087328]\n",
      "epoch:31 step:24380 [D loss: 0.179649, acc: 100.00%] [G loss: 2.145597]\n",
      "epoch:31 step:24381 [D loss: 0.626899, acc: 54.69%] [G loss: 3.614452]\n",
      "epoch:31 step:24382 [D loss: 0.879099, acc: 41.41%] [G loss: 3.306987]\n",
      "epoch:31 step:24383 [D loss: 0.675199, acc: 54.69%] [G loss: 4.554886]\n",
      "epoch:31 step:24384 [D loss: 0.880909, acc: 39.84%] [G loss: 3.959813]\n",
      "epoch:31 step:24385 [D loss: 0.026421, acc: 100.00%] [G loss: 2.582524]\n",
      "epoch:31 step:24386 [D loss: 0.433647, acc: 82.03%] [G loss: 6.123526]\n",
      "epoch:31 step:24387 [D loss: 0.612878, acc: 65.62%] [G loss: 4.561094]\n",
      "epoch:31 step:24388 [D loss: 0.378755, acc: 76.56%] [G loss: 4.946685]\n",
      "epoch:31 step:24389 [D loss: 0.835609, acc: 50.78%] [G loss: 4.529549]\n",
      "epoch:31 step:24390 [D loss: 0.430888, acc: 87.50%] [G loss: 4.644819]\n",
      "epoch:31 step:24391 [D loss: 0.883383, acc: 53.91%] [G loss: 4.503303]\n",
      "epoch:31 step:24392 [D loss: 0.649358, acc: 62.50%] [G loss: 4.086345]\n",
      "epoch:31 step:24393 [D loss: 0.279096, acc: 96.88%] [G loss: 3.107390]\n",
      "epoch:31 step:24394 [D loss: 0.060257, acc: 100.00%] [G loss: 3.652207]\n",
      "epoch:31 step:24395 [D loss: 0.275243, acc: 90.62%] [G loss: 4.555220]\n",
      "epoch:31 step:24396 [D loss: 0.535588, acc: 71.88%] [G loss: 4.393549]\n",
      "epoch:31 step:24397 [D loss: 0.469874, acc: 82.03%] [G loss: 3.594788]\n",
      "epoch:31 step:24398 [D loss: 0.202969, acc: 98.44%] [G loss: 4.899518]\n",
      "epoch:31 step:24399 [D loss: 0.157059, acc: 97.66%] [G loss: 4.306045]\n",
      "epoch:31 step:24400 [D loss: 0.313121, acc: 84.38%] [G loss: 6.384605]\n",
      "##############\n",
      "[0.83181537 0.87415056 0.83269732 0.814849   0.77760856 0.79462214\n",
      " 0.87943763 0.83689172 0.79500047 0.85469392]\n",
      "##########\n",
      "epoch:31 step:24401 [D loss: 0.767111, acc: 53.12%] [G loss: 5.927204]\n",
      "epoch:31 step:24402 [D loss: 0.076021, acc: 100.00%] [G loss: 7.022680]\n",
      "epoch:31 step:24403 [D loss: 1.518599, acc: 50.00%] [G loss: 2.072420]\n",
      "epoch:31 step:24404 [D loss: 0.141250, acc: 97.66%] [G loss: 5.227715]\n",
      "epoch:31 step:24405 [D loss: 1.001244, acc: 46.09%] [G loss: 4.365795]\n",
      "epoch:31 step:24406 [D loss: 0.170296, acc: 99.22%] [G loss: 4.771360]\n",
      "epoch:31 step:24407 [D loss: 0.500198, acc: 78.12%] [G loss: 4.882439]\n",
      "epoch:31 step:24408 [D loss: 0.461791, acc: 83.59%] [G loss: 4.854216]\n",
      "epoch:31 step:24409 [D loss: 0.144360, acc: 99.22%] [G loss: 4.955538]\n",
      "epoch:31 step:24410 [D loss: 0.290992, acc: 94.53%] [G loss: 5.032457]\n",
      "epoch:31 step:24411 [D loss: 0.386108, acc: 81.25%] [G loss: 3.875655]\n",
      "epoch:31 step:24412 [D loss: 0.285584, acc: 92.97%] [G loss: 5.317206]\n",
      "epoch:31 step:24413 [D loss: 0.652902, acc: 59.38%] [G loss: 5.560264]\n",
      "epoch:31 step:24414 [D loss: 0.567594, acc: 70.31%] [G loss: 4.929561]\n",
      "epoch:31 step:24415 [D loss: 1.062048, acc: 22.66%] [G loss: 3.245952]\n",
      "epoch:31 step:24416 [D loss: 0.188745, acc: 94.53%] [G loss: 5.517290]\n",
      "epoch:31 step:24417 [D loss: 0.102488, acc: 99.22%] [G loss: 5.219598]\n",
      "epoch:31 step:24418 [D loss: 0.435401, acc: 89.06%] [G loss: 3.826179]\n",
      "epoch:31 step:24419 [D loss: 0.374293, acc: 81.25%] [G loss: 4.888467]\n",
      "epoch:31 step:24420 [D loss: 0.501654, acc: 68.75%] [G loss: 6.481661]\n",
      "epoch:31 step:24421 [D loss: 0.342694, acc: 92.19%] [G loss: 6.328104]\n",
      "epoch:31 step:24422 [D loss: 0.078563, acc: 99.22%] [G loss: 4.802194]\n",
      "epoch:31 step:24423 [D loss: 0.093155, acc: 100.00%] [G loss: 6.073903]\n",
      "epoch:31 step:24424 [D loss: 1.040488, acc: 35.94%] [G loss: 4.247298]\n",
      "epoch:31 step:24425 [D loss: 0.347017, acc: 76.56%] [G loss: 9.211439]\n",
      "epoch:31 step:24426 [D loss: 0.300238, acc: 92.97%] [G loss: 4.047304]\n",
      "epoch:31 step:24427 [D loss: 0.687727, acc: 53.91%] [G loss: 4.714410]\n",
      "epoch:31 step:24428 [D loss: 0.282785, acc: 92.97%] [G loss: 2.604551]\n",
      "epoch:31 step:24429 [D loss: 0.167384, acc: 99.22%] [G loss: 4.070922]\n",
      "epoch:31 step:24430 [D loss: 0.364823, acc: 86.72%] [G loss: 5.802568]\n",
      "epoch:31 step:24431 [D loss: 0.242072, acc: 91.41%] [G loss: 4.114753]\n",
      "epoch:31 step:24432 [D loss: 0.366811, acc: 90.62%] [G loss: 4.277331]\n",
      "epoch:31 step:24433 [D loss: 0.140714, acc: 98.44%] [G loss: 3.936934]\n",
      "epoch:31 step:24434 [D loss: 0.739964, acc: 51.56%] [G loss: 6.937538]\n",
      "epoch:31 step:24435 [D loss: 0.671582, acc: 53.91%] [G loss: 3.591179]\n",
      "epoch:31 step:24436 [D loss: 0.940875, acc: 32.03%] [G loss: 4.170079]\n",
      "epoch:31 step:24437 [D loss: 0.223308, acc: 97.66%] [G loss: 6.634235]\n",
      "epoch:31 step:24438 [D loss: 0.338422, acc: 81.25%] [G loss: 5.425717]\n",
      "epoch:31 step:24439 [D loss: 0.253371, acc: 94.53%] [G loss: 6.666306]\n",
      "epoch:31 step:24440 [D loss: 0.723211, acc: 50.78%] [G loss: 3.295151]\n",
      "epoch:31 step:24441 [D loss: 0.966938, acc: 41.41%] [G loss: 2.373813]\n",
      "epoch:31 step:24442 [D loss: 0.181392, acc: 96.09%] [G loss: 3.438583]\n",
      "epoch:31 step:24443 [D loss: 0.076145, acc: 100.00%] [G loss: 5.797694]\n",
      "epoch:31 step:24444 [D loss: 0.394526, acc: 89.06%] [G loss: 4.462439]\n",
      "epoch:31 step:24445 [D loss: 0.399797, acc: 85.94%] [G loss: 3.754173]\n",
      "epoch:31 step:24446 [D loss: 0.362137, acc: 91.41%] [G loss: 5.177431]\n",
      "epoch:31 step:24447 [D loss: 0.562169, acc: 59.38%] [G loss: 6.537350]\n",
      "epoch:31 step:24448 [D loss: 0.222866, acc: 94.53%] [G loss: 6.537751]\n",
      "epoch:31 step:24449 [D loss: 1.080611, acc: 50.00%] [G loss: 4.329584]\n",
      "epoch:31 step:24450 [D loss: 0.492514, acc: 67.19%] [G loss: 4.047243]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:31 step:24451 [D loss: 1.012400, acc: 26.56%] [G loss: 5.139795]\n",
      "epoch:31 step:24452 [D loss: 0.169758, acc: 99.22%] [G loss: 3.466999]\n",
      "epoch:31 step:24453 [D loss: 0.041668, acc: 100.00%] [G loss: 7.230248]\n",
      "epoch:31 step:24454 [D loss: 0.845668, acc: 50.00%] [G loss: 2.816171]\n",
      "epoch:31 step:24455 [D loss: 0.329866, acc: 93.75%] [G loss: 7.135848]\n",
      "epoch:31 step:24456 [D loss: 0.221964, acc: 94.53%] [G loss: 3.292480]\n",
      "epoch:31 step:24457 [D loss: 2.061955, acc: 9.38%] [G loss: 4.676722]\n",
      "epoch:31 step:24458 [D loss: 0.337649, acc: 89.84%] [G loss: 2.305665]\n",
      "epoch:31 step:24459 [D loss: 0.330172, acc: 84.38%] [G loss: 5.257295]\n",
      "epoch:31 step:24460 [D loss: 0.282683, acc: 89.84%] [G loss: 7.090370]\n",
      "epoch:31 step:24461 [D loss: 0.372213, acc: 89.06%] [G loss: 5.151253]\n",
      "epoch:31 step:24462 [D loss: 0.208474, acc: 96.88%] [G loss: 6.736192]\n",
      "epoch:31 step:24463 [D loss: 0.088810, acc: 99.22%] [G loss: 6.042663]\n",
      "epoch:31 step:24464 [D loss: 1.120634, acc: 44.53%] [G loss: 4.661575]\n",
      "epoch:31 step:24465 [D loss: 0.458443, acc: 83.59%] [G loss: 2.627699]\n",
      "epoch:31 step:24466 [D loss: 0.331570, acc: 86.72%] [G loss: 2.035164]\n",
      "epoch:31 step:24467 [D loss: 0.376608, acc: 82.81%] [G loss: 3.620958]\n",
      "epoch:31 step:24468 [D loss: 1.352858, acc: 38.28%] [G loss: 3.702146]\n",
      "epoch:31 step:24469 [D loss: 0.278323, acc: 92.19%] [G loss: 4.364074]\n",
      "epoch:31 step:24470 [D loss: 0.438899, acc: 82.81%] [G loss: 3.786205]\n",
      "epoch:31 step:24471 [D loss: 0.954107, acc: 50.78%] [G loss: 3.671311]\n",
      "epoch:31 step:24472 [D loss: 0.197927, acc: 95.31%] [G loss: 3.807628]\n",
      "epoch:31 step:24473 [D loss: 0.104469, acc: 100.00%] [G loss: 3.101166]\n",
      "epoch:31 step:24474 [D loss: 0.231236, acc: 92.97%] [G loss: 5.102534]\n",
      "epoch:31 step:24475 [D loss: 0.085650, acc: 100.00%] [G loss: 4.374640]\n",
      "epoch:31 step:24476 [D loss: 0.556948, acc: 57.03%] [G loss: 3.877521]\n",
      "epoch:31 step:24477 [D loss: 0.372601, acc: 83.59%] [G loss: 3.299778]\n",
      "epoch:31 step:24478 [D loss: 1.479946, acc: 17.97%] [G loss: 5.701863]\n",
      "epoch:31 step:24479 [D loss: 0.055139, acc: 100.00%] [G loss: 4.599703]\n",
      "epoch:31 step:24480 [D loss: 0.346394, acc: 92.97%] [G loss: 5.901321]\n",
      "epoch:31 step:24481 [D loss: 0.075177, acc: 100.00%] [G loss: 5.216508]\n",
      "epoch:31 step:24482 [D loss: 0.141800, acc: 99.22%] [G loss: 4.376398]\n",
      "epoch:31 step:24483 [D loss: 0.143188, acc: 99.22%] [G loss: 4.461736]\n",
      "epoch:31 step:24484 [D loss: 0.209676, acc: 96.88%] [G loss: 3.621439]\n",
      "epoch:31 step:24485 [D loss: 0.432841, acc: 73.44%] [G loss: 3.381708]\n",
      "epoch:31 step:24486 [D loss: 0.216558, acc: 95.31%] [G loss: 2.695397]\n",
      "epoch:31 step:24487 [D loss: 0.711629, acc: 57.03%] [G loss: 3.345930]\n",
      "epoch:31 step:24488 [D loss: 0.558260, acc: 60.94%] [G loss: 3.449018]\n",
      "epoch:31 step:24489 [D loss: 0.176390, acc: 98.44%] [G loss: 5.525464]\n",
      "epoch:31 step:24490 [D loss: 0.329837, acc: 92.97%] [G loss: 6.026007]\n",
      "epoch:31 step:24491 [D loss: 0.773896, acc: 52.34%] [G loss: 2.959687]\n",
      "epoch:31 step:24492 [D loss: 0.569610, acc: 67.19%] [G loss: 4.275331]\n",
      "epoch:31 step:24493 [D loss: 0.517492, acc: 65.62%] [G loss: 4.489585]\n",
      "epoch:31 step:24494 [D loss: 0.483363, acc: 82.03%] [G loss: 6.167108]\n",
      "epoch:31 step:24495 [D loss: 0.148354, acc: 99.22%] [G loss: 3.905810]\n",
      "epoch:31 step:24496 [D loss: 0.413144, acc: 92.19%] [G loss: 5.165340]\n",
      "epoch:31 step:24497 [D loss: 1.156336, acc: 45.31%] [G loss: 6.046741]\n",
      "epoch:31 step:24498 [D loss: 0.389641, acc: 76.56%] [G loss: 4.022973]\n",
      "epoch:31 step:24499 [D loss: 0.113538, acc: 100.00%] [G loss: 5.231304]\n",
      "epoch:31 step:24500 [D loss: 0.116086, acc: 100.00%] [G loss: 4.061504]\n",
      "epoch:31 step:24501 [D loss: 0.326532, acc: 85.94%] [G loss: 4.890874]\n",
      "epoch:31 step:24502 [D loss: 0.814572, acc: 44.53%] [G loss: 4.318128]\n",
      "epoch:31 step:24503 [D loss: 0.193236, acc: 96.88%] [G loss: 3.380458]\n",
      "epoch:31 step:24504 [D loss: 0.698278, acc: 59.38%] [G loss: 4.525573]\n",
      "epoch:31 step:24505 [D loss: 0.628989, acc: 58.59%] [G loss: 5.219659]\n",
      "epoch:31 step:24506 [D loss: 0.120023, acc: 99.22%] [G loss: 5.842658]\n",
      "epoch:31 step:24507 [D loss: 0.304740, acc: 85.16%] [G loss: 7.279234]\n",
      "epoch:31 step:24508 [D loss: 0.257248, acc: 96.88%] [G loss: 4.504771]\n",
      "epoch:31 step:24509 [D loss: 0.276877, acc: 88.28%] [G loss: 5.026070]\n",
      "epoch:31 step:24510 [D loss: 0.563239, acc: 59.38%] [G loss: 4.779994]\n",
      "epoch:31 step:24511 [D loss: 0.936752, acc: 50.78%] [G loss: 5.047798]\n",
      "epoch:31 step:24512 [D loss: 0.250145, acc: 92.97%] [G loss: 3.367601]\n",
      "epoch:31 step:24513 [D loss: 0.585315, acc: 65.62%] [G loss: 3.691643]\n",
      "epoch:31 step:24514 [D loss: 0.283930, acc: 92.97%] [G loss: 2.692867]\n",
      "epoch:31 step:24515 [D loss: 0.074786, acc: 99.22%] [G loss: 5.282077]\n",
      "epoch:31 step:24516 [D loss: 0.304063, acc: 86.72%] [G loss: 5.089616]\n",
      "epoch:31 step:24517 [D loss: 0.124070, acc: 98.44%] [G loss: 4.354140]\n",
      "epoch:31 step:24518 [D loss: 0.100668, acc: 100.00%] [G loss: 3.861203]\n",
      "epoch:31 step:24519 [D loss: 0.318263, acc: 86.72%] [G loss: 5.394402]\n",
      "epoch:31 step:24520 [D loss: 0.504112, acc: 72.66%] [G loss: 2.778409]\n",
      "epoch:31 step:24521 [D loss: 0.235790, acc: 96.88%] [G loss: 5.954802]\n",
      "epoch:31 step:24522 [D loss: 0.121638, acc: 99.22%] [G loss: 6.679960]\n",
      "epoch:31 step:24523 [D loss: 0.264622, acc: 94.53%] [G loss: 3.883342]\n",
      "epoch:31 step:24524 [D loss: 0.302189, acc: 93.75%] [G loss: 4.429128]\n",
      "epoch:31 step:24525 [D loss: 0.597044, acc: 55.47%] [G loss: 5.164101]\n",
      "epoch:31 step:24526 [D loss: 0.499112, acc: 71.09%] [G loss: 4.533739]\n",
      "epoch:31 step:24527 [D loss: 0.827544, acc: 54.69%] [G loss: 4.943425]\n",
      "epoch:31 step:24528 [D loss: 0.294614, acc: 91.41%] [G loss: 6.463133]\n",
      "epoch:31 step:24529 [D loss: 0.450761, acc: 76.56%] [G loss: 3.379584]\n",
      "epoch:31 step:24530 [D loss: 0.286210, acc: 92.19%] [G loss: 5.324626]\n",
      "epoch:31 step:24531 [D loss: 0.726519, acc: 54.69%] [G loss: 3.057616]\n",
      "epoch:31 step:24532 [D loss: 0.919074, acc: 46.88%] [G loss: 4.828966]\n",
      "epoch:31 step:24533 [D loss: 0.622566, acc: 63.28%] [G loss: 5.070411]\n",
      "epoch:31 step:24534 [D loss: 0.112155, acc: 100.00%] [G loss: 6.058382]\n",
      "epoch:31 step:24535 [D loss: 0.608231, acc: 69.53%] [G loss: 3.580383]\n",
      "epoch:31 step:24536 [D loss: 0.176890, acc: 99.22%] [G loss: 4.005029]\n",
      "epoch:31 step:24537 [D loss: 0.593741, acc: 65.62%] [G loss: 4.921349]\n",
      "epoch:31 step:24538 [D loss: 0.149663, acc: 99.22%] [G loss: 3.386590]\n",
      "epoch:31 step:24539 [D loss: 0.579196, acc: 70.31%] [G loss: 4.509794]\n",
      "epoch:31 step:24540 [D loss: 0.238850, acc: 89.84%] [G loss: 2.707175]\n",
      "epoch:31 step:24541 [D loss: 0.104547, acc: 99.22%] [G loss: 3.294431]\n",
      "epoch:31 step:24542 [D loss: 1.557242, acc: 4.69%] [G loss: 6.249453]\n",
      "epoch:31 step:24543 [D loss: 0.457810, acc: 85.94%] [G loss: 4.347829]\n",
      "epoch:31 step:24544 [D loss: 0.178983, acc: 96.09%] [G loss: 5.662917]\n",
      "epoch:31 step:24545 [D loss: 0.550762, acc: 60.16%] [G loss: 8.399071]\n",
      "epoch:31 step:24546 [D loss: 0.522941, acc: 68.75%] [G loss: 3.943867]\n",
      "epoch:31 step:24547 [D loss: 0.462302, acc: 80.47%] [G loss: 4.217435]\n",
      "epoch:31 step:24548 [D loss: 0.113991, acc: 100.00%] [G loss: 4.500570]\n",
      "epoch:31 step:24549 [D loss: 0.180049, acc: 96.09%] [G loss: 3.945177]\n",
      "epoch:31 step:24550 [D loss: 0.196336, acc: 97.66%] [G loss: 6.053856]\n",
      "epoch:31 step:24551 [D loss: 0.251670, acc: 91.41%] [G loss: 4.088953]\n",
      "epoch:31 step:24552 [D loss: 0.514443, acc: 74.22%] [G loss: 2.579439]\n",
      "epoch:31 step:24553 [D loss: 0.595056, acc: 63.28%] [G loss: 4.698492]\n",
      "epoch:31 step:24554 [D loss: 0.658807, acc: 58.59%] [G loss: 2.146401]\n",
      "epoch:31 step:24555 [D loss: 0.905981, acc: 51.56%] [G loss: 4.885705]\n",
      "epoch:31 step:24556 [D loss: 0.145488, acc: 99.22%] [G loss: 4.574758]\n",
      "epoch:31 step:24557 [D loss: 0.358957, acc: 90.62%] [G loss: 3.365236]\n",
      "epoch:31 step:24558 [D loss: 0.212346, acc: 95.31%] [G loss: 3.788002]\n",
      "epoch:31 step:24559 [D loss: 0.146471, acc: 97.66%] [G loss: 5.605403]\n",
      "epoch:31 step:24560 [D loss: 0.695251, acc: 62.50%] [G loss: 5.350686]\n",
      "epoch:31 step:24561 [D loss: 0.950568, acc: 50.78%] [G loss: 2.839899]\n",
      "epoch:31 step:24562 [D loss: 0.569522, acc: 71.09%] [G loss: 3.697057]\n",
      "epoch:31 step:24563 [D loss: 0.164144, acc: 97.66%] [G loss: 4.937692]\n",
      "epoch:31 step:24564 [D loss: 0.167209, acc: 99.22%] [G loss: 3.182686]\n",
      "epoch:31 step:24565 [D loss: 0.223905, acc: 100.00%] [G loss: 3.472588]\n",
      "epoch:31 step:24566 [D loss: 1.007522, acc: 48.44%] [G loss: 4.515194]\n",
      "epoch:31 step:24567 [D loss: 0.313149, acc: 89.84%] [G loss: 1.399079]\n",
      "epoch:31 step:24568 [D loss: 0.201105, acc: 96.09%] [G loss: 3.877691]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:31 step:24569 [D loss: 0.626111, acc: 63.28%] [G loss: 6.345325]\n",
      "epoch:31 step:24570 [D loss: 0.199936, acc: 96.09%] [G loss: 4.998479]\n",
      "epoch:31 step:24571 [D loss: 0.423358, acc: 84.38%] [G loss: 7.092534]\n",
      "epoch:31 step:24572 [D loss: 0.604815, acc: 67.97%] [G loss: 7.265808]\n",
      "epoch:31 step:24573 [D loss: 0.139577, acc: 98.44%] [G loss: 3.353552]\n",
      "epoch:31 step:24574 [D loss: 0.274543, acc: 92.19%] [G loss: 3.940972]\n",
      "epoch:31 step:24575 [D loss: 0.089521, acc: 99.22%] [G loss: 3.801413]\n",
      "epoch:31 step:24576 [D loss: 0.295986, acc: 93.75%] [G loss: 4.735824]\n",
      "epoch:31 step:24577 [D loss: 0.260642, acc: 99.22%] [G loss: 4.940758]\n",
      "epoch:31 step:24578 [D loss: 0.094560, acc: 99.22%] [G loss: 6.022031]\n",
      "epoch:31 step:24579 [D loss: 0.848351, acc: 49.22%] [G loss: 5.127379]\n",
      "epoch:31 step:24580 [D loss: 0.421207, acc: 81.25%] [G loss: 3.629684]\n",
      "epoch:31 step:24581 [D loss: 0.573593, acc: 62.50%] [G loss: 3.401567]\n",
      "epoch:31 step:24582 [D loss: 0.285889, acc: 90.62%] [G loss: 4.020956]\n",
      "epoch:31 step:24583 [D loss: 0.381465, acc: 92.97%] [G loss: 3.958134]\n",
      "epoch:31 step:24584 [D loss: 1.653600, acc: 7.81%] [G loss: 4.427601]\n",
      "epoch:31 step:24585 [D loss: 0.241215, acc: 90.62%] [G loss: 3.719786]\n",
      "epoch:31 step:24586 [D loss: 0.984732, acc: 50.00%] [G loss: 3.363200]\n",
      "epoch:31 step:24587 [D loss: 0.071912, acc: 98.44%] [G loss: 3.725470]\n",
      "epoch:31 step:24588 [D loss: 1.167309, acc: 49.22%] [G loss: 2.644469]\n",
      "epoch:31 step:24589 [D loss: 0.104495, acc: 100.00%] [G loss: 4.616994]\n",
      "epoch:31 step:24590 [D loss: 0.214857, acc: 97.66%] [G loss: 5.055753]\n",
      "epoch:31 step:24591 [D loss: 0.091091, acc: 100.00%] [G loss: 2.175497]\n",
      "epoch:31 step:24592 [D loss: 0.122835, acc: 100.00%] [G loss: 2.786037]\n",
      "epoch:31 step:24593 [D loss: 0.436952, acc: 72.66%] [G loss: 5.824836]\n",
      "epoch:31 step:24594 [D loss: 0.646351, acc: 62.50%] [G loss: 3.039288]\n",
      "epoch:31 step:24595 [D loss: 0.297626, acc: 87.50%] [G loss: 4.265476]\n",
      "epoch:31 step:24596 [D loss: 0.280774, acc: 93.75%] [G loss: 3.351691]\n",
      "epoch:31 step:24597 [D loss: 0.736182, acc: 56.25%] [G loss: 3.868567]\n",
      "epoch:31 step:24598 [D loss: 0.649951, acc: 59.38%] [G loss: 8.213967]\n",
      "epoch:31 step:24599 [D loss: 0.803740, acc: 54.69%] [G loss: 3.418278]\n",
      "epoch:31 step:24600 [D loss: 0.942710, acc: 42.97%] [G loss: 2.734587]\n",
      "##############\n",
      "[0.87438991 0.87174008 0.80774406 0.82559436 0.79196034 0.83224693\n",
      " 0.89015998 0.82522772 0.83130258 0.82917785]\n",
      "##########\n",
      "epoch:31 step:24601 [D loss: 0.459756, acc: 67.97%] [G loss: 5.095204]\n",
      "epoch:31 step:24602 [D loss: 0.082577, acc: 100.00%] [G loss: 6.101600]\n",
      "epoch:31 step:24603 [D loss: 0.127351, acc: 99.22%] [G loss: 5.221071]\n",
      "epoch:31 step:24604 [D loss: 0.149135, acc: 98.44%] [G loss: 4.846323]\n",
      "epoch:31 step:24605 [D loss: 0.171071, acc: 98.44%] [G loss: 7.011251]\n",
      "epoch:31 step:24606 [D loss: 0.614177, acc: 70.31%] [G loss: 4.529711]\n",
      "epoch:31 step:24607 [D loss: 0.142860, acc: 96.88%] [G loss: 2.740204]\n",
      "epoch:31 step:24608 [D loss: 1.233540, acc: 49.22%] [G loss: 5.537984]\n",
      "epoch:31 step:24609 [D loss: 0.324827, acc: 85.94%] [G loss: 3.925848]\n",
      "epoch:31 step:24610 [D loss: 0.653328, acc: 65.62%] [G loss: 4.615907]\n",
      "epoch:31 step:24611 [D loss: 0.511373, acc: 65.62%] [G loss: 3.055867]\n",
      "epoch:31 step:24612 [D loss: 0.095257, acc: 98.44%] [G loss: 5.606148]\n",
      "epoch:31 step:24613 [D loss: 0.434111, acc: 75.00%] [G loss: 4.245829]\n",
      "epoch:31 step:24614 [D loss: 0.762545, acc: 49.22%] [G loss: 5.104468]\n",
      "epoch:31 step:24615 [D loss: 0.166363, acc: 99.22%] [G loss: 5.495347]\n",
      "epoch:31 step:24616 [D loss: 0.924854, acc: 44.53%] [G loss: 5.363429]\n",
      "epoch:31 step:24617 [D loss: 0.311852, acc: 94.53%] [G loss: 4.010630]\n",
      "epoch:31 step:24618 [D loss: 0.134642, acc: 100.00%] [G loss: 6.537782]\n",
      "epoch:31 step:24619 [D loss: 0.429911, acc: 85.94%] [G loss: 6.018603]\n",
      "epoch:31 step:24620 [D loss: 0.179663, acc: 97.66%] [G loss: 4.821301]\n",
      "epoch:31 step:24621 [D loss: 1.663622, acc: 3.12%] [G loss: 5.151516]\n",
      "epoch:31 step:24622 [D loss: 0.646256, acc: 57.81%] [G loss: 4.539462]\n",
      "epoch:31 step:24623 [D loss: 0.037446, acc: 100.00%] [G loss: 6.815639]\n",
      "epoch:31 step:24624 [D loss: 0.331721, acc: 92.19%] [G loss: 3.694520]\n",
      "epoch:31 step:24625 [D loss: 0.091663, acc: 99.22%] [G loss: 2.792198]\n",
      "epoch:31 step:24626 [D loss: 0.633324, acc: 64.84%] [G loss: 2.501565]\n",
      "epoch:31 step:24627 [D loss: 0.312196, acc: 93.75%] [G loss: 2.283303]\n",
      "epoch:31 step:24628 [D loss: 0.123985, acc: 99.22%] [G loss: 4.521008]\n",
      "epoch:31 step:24629 [D loss: 0.234256, acc: 92.97%] [G loss: 3.755710]\n",
      "epoch:31 step:24630 [D loss: 0.216658, acc: 93.75%] [G loss: 3.278631]\n",
      "epoch:31 step:24631 [D loss: 0.439232, acc: 75.00%] [G loss: 6.510748]\n",
      "epoch:31 step:24632 [D loss: 0.711738, acc: 57.03%] [G loss: 3.815574]\n",
      "epoch:31 step:24633 [D loss: 0.543810, acc: 61.72%] [G loss: 6.067928]\n",
      "epoch:31 step:24634 [D loss: 0.717654, acc: 50.78%] [G loss: 4.732939]\n",
      "epoch:31 step:24635 [D loss: 0.499104, acc: 73.44%] [G loss: 7.229066]\n",
      "epoch:31 step:24636 [D loss: 0.569457, acc: 72.66%] [G loss: 5.435741]\n",
      "epoch:31 step:24637 [D loss: 0.140307, acc: 98.44%] [G loss: 5.587918]\n",
      "epoch:31 step:24638 [D loss: 0.577249, acc: 68.75%] [G loss: 2.750522]\n",
      "epoch:31 step:24639 [D loss: 0.572564, acc: 73.44%] [G loss: 3.439603]\n",
      "epoch:31 step:24640 [D loss: 0.261069, acc: 94.53%] [G loss: 3.181190]\n",
      "epoch:31 step:24641 [D loss: 0.074285, acc: 99.22%] [G loss: 5.954052]\n",
      "epoch:31 step:24642 [D loss: 0.350910, acc: 86.72%] [G loss: 5.014123]\n",
      "epoch:31 step:24643 [D loss: 0.136203, acc: 96.88%] [G loss: 5.249973]\n",
      "epoch:31 step:24644 [D loss: 0.606949, acc: 67.97%] [G loss: 2.876822]\n",
      "epoch:31 step:24645 [D loss: 0.695338, acc: 55.47%] [G loss: 5.766036]\n",
      "epoch:31 step:24646 [D loss: 0.118256, acc: 100.00%] [G loss: 5.866861]\n",
      "epoch:31 step:24647 [D loss: 0.101525, acc: 99.22%] [G loss: 3.979516]\n",
      "epoch:31 step:24648 [D loss: 0.593900, acc: 67.97%] [G loss: 5.007123]\n",
      "epoch:31 step:24649 [D loss: 0.505807, acc: 67.19%] [G loss: 3.526041]\n",
      "epoch:31 step:24650 [D loss: 0.209680, acc: 95.31%] [G loss: 3.526726]\n",
      "epoch:31 step:24651 [D loss: 0.362560, acc: 85.94%] [G loss: 4.766490]\n",
      "epoch:31 step:24652 [D loss: 0.222299, acc: 97.66%] [G loss: 5.161986]\n",
      "epoch:31 step:24653 [D loss: 0.138137, acc: 98.44%] [G loss: 4.124496]\n",
      "epoch:31 step:24654 [D loss: 0.134669, acc: 99.22%] [G loss: 4.048713]\n",
      "epoch:31 step:24655 [D loss: 0.186902, acc: 96.88%] [G loss: 5.586515]\n",
      "epoch:31 step:24656 [D loss: 0.963823, acc: 28.12%] [G loss: 3.323039]\n",
      "epoch:31 step:24657 [D loss: 0.621080, acc: 57.03%] [G loss: 3.712415]\n",
      "epoch:31 step:24658 [D loss: 0.146796, acc: 98.44%] [G loss: 4.756811]\n",
      "epoch:31 step:24659 [D loss: 0.161194, acc: 99.22%] [G loss: 6.478932]\n",
      "epoch:31 step:24660 [D loss: 0.820870, acc: 50.78%] [G loss: 4.214769]\n",
      "epoch:31 step:24661 [D loss: 0.300825, acc: 85.94%] [G loss: 3.575075]\n",
      "epoch:31 step:24662 [D loss: 0.341441, acc: 82.81%] [G loss: 8.740798]\n",
      "epoch:31 step:24663 [D loss: 0.337157, acc: 85.94%] [G loss: 6.087173]\n",
      "epoch:31 step:24664 [D loss: 0.709620, acc: 56.25%] [G loss: 4.592872]\n",
      "epoch:31 step:24665 [D loss: 0.122068, acc: 100.00%] [G loss: 3.307899]\n",
      "epoch:31 step:24666 [D loss: 0.743793, acc: 55.47%] [G loss: 5.155765]\n",
      "epoch:31 step:24667 [D loss: 0.224944, acc: 95.31%] [G loss: 3.960814]\n",
      "epoch:31 step:24668 [D loss: 0.546351, acc: 66.41%] [G loss: 4.208184]\n",
      "epoch:31 step:24669 [D loss: 0.203305, acc: 99.22%] [G loss: 5.286725]\n",
      "epoch:31 step:24670 [D loss: 0.192955, acc: 96.09%] [G loss: 5.611487]\n",
      "epoch:31 step:24671 [D loss: 0.175330, acc: 98.44%] [G loss: 3.571973]\n",
      "epoch:31 step:24672 [D loss: 0.211994, acc: 92.97%] [G loss: 6.548076]\n",
      "epoch:31 step:24673 [D loss: 0.224952, acc: 98.44%] [G loss: 5.773136]\n",
      "epoch:31 step:24674 [D loss: 0.203660, acc: 98.44%] [G loss: 5.432070]\n",
      "epoch:31 step:24675 [D loss: 1.002720, acc: 47.66%] [G loss: 3.119227]\n",
      "epoch:31 step:24676 [D loss: 0.947370, acc: 50.78%] [G loss: 5.408959]\n",
      "epoch:31 step:24677 [D loss: 0.005839, acc: 100.00%] [G loss: 6.038355]\n",
      "epoch:31 step:24678 [D loss: 1.141092, acc: 39.84%] [G loss: 5.124527]\n",
      "epoch:31 step:24679 [D loss: 0.076938, acc: 100.00%] [G loss: 6.197881]\n",
      "epoch:31 step:24680 [D loss: 0.305171, acc: 85.16%] [G loss: 4.231611]\n",
      "epoch:31 step:24681 [D loss: 0.024864, acc: 100.00%] [G loss: 6.036688]\n",
      "epoch:31 step:24682 [D loss: 0.394022, acc: 75.00%] [G loss: 5.168944]\n",
      "epoch:31 step:24683 [D loss: 0.189340, acc: 98.44%] [G loss: 4.895635]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:31 step:24684 [D loss: 1.109771, acc: 50.78%] [G loss: 3.141148]\n",
      "epoch:31 step:24685 [D loss: 0.210602, acc: 97.66%] [G loss: 4.587253]\n",
      "epoch:31 step:24686 [D loss: 0.628856, acc: 58.59%] [G loss: 5.506162]\n",
      "epoch:31 step:24687 [D loss: 0.452448, acc: 85.16%] [G loss: 2.332514]\n",
      "epoch:31 step:24688 [D loss: 0.691583, acc: 53.91%] [G loss: 6.502426]\n",
      "epoch:31 step:24689 [D loss: 0.081526, acc: 100.00%] [G loss: 4.638408]\n",
      "epoch:31 step:24690 [D loss: 1.195902, acc: 50.78%] [G loss: 4.720379]\n",
      "epoch:31 step:24691 [D loss: 0.433787, acc: 81.25%] [G loss: 6.562759]\n",
      "epoch:31 step:24692 [D loss: 0.491794, acc: 69.53%] [G loss: 4.414953]\n",
      "epoch:31 step:24693 [D loss: 0.684867, acc: 53.91%] [G loss: 2.037740]\n",
      "epoch:31 step:24694 [D loss: 0.924085, acc: 35.94%] [G loss: 2.955418]\n",
      "epoch:31 step:24695 [D loss: 0.757979, acc: 51.56%] [G loss: 5.277896]\n",
      "epoch:31 step:24696 [D loss: 0.190315, acc: 95.31%] [G loss: 3.487072]\n",
      "epoch:31 step:24697 [D loss: 0.447585, acc: 79.69%] [G loss: 3.653483]\n",
      "epoch:31 step:24698 [D loss: 0.200617, acc: 98.44%] [G loss: 3.814538]\n",
      "epoch:31 step:24699 [D loss: 0.175849, acc: 97.66%] [G loss: 6.205240]\n",
      "epoch:31 step:24700 [D loss: 0.416331, acc: 83.59%] [G loss: 3.853931]\n",
      "epoch:31 step:24701 [D loss: 0.046703, acc: 100.00%] [G loss: 7.989025]\n",
      "epoch:31 step:24702 [D loss: 0.428099, acc: 75.00%] [G loss: 4.517123]\n",
      "epoch:31 step:24703 [D loss: 0.145070, acc: 100.00%] [G loss: 6.629396]\n",
      "epoch:31 step:24704 [D loss: 0.105936, acc: 99.22%] [G loss: 4.076840]\n",
      "epoch:31 step:24705 [D loss: 0.342479, acc: 92.97%] [G loss: 5.599147]\n",
      "epoch:31 step:24706 [D loss: 0.039116, acc: 100.00%] [G loss: 5.914425]\n",
      "epoch:31 step:24707 [D loss: 0.835349, acc: 38.28%] [G loss: 5.998703]\n",
      "epoch:31 step:24708 [D loss: 0.048793, acc: 100.00%] [G loss: 4.714671]\n",
      "epoch:31 step:24709 [D loss: 0.398438, acc: 86.72%] [G loss: 3.828245]\n",
      "epoch:31 step:24710 [D loss: 0.540445, acc: 68.75%] [G loss: 1.692988]\n",
      "epoch:31 step:24711 [D loss: 0.647037, acc: 59.38%] [G loss: 2.813982]\n",
      "epoch:31 step:24712 [D loss: 0.279951, acc: 92.19%] [G loss: 3.841877]\n",
      "epoch:31 step:24713 [D loss: 0.433775, acc: 80.47%] [G loss: 4.760179]\n",
      "epoch:31 step:24714 [D loss: 0.965837, acc: 40.62%] [G loss: 4.147174]\n",
      "epoch:31 step:24715 [D loss: 0.371902, acc: 80.47%] [G loss: 4.872475]\n",
      "epoch:31 step:24716 [D loss: 1.330363, acc: 32.81%] [G loss: 3.722557]\n",
      "epoch:31 step:24717 [D loss: 0.551272, acc: 62.50%] [G loss: 6.620145]\n",
      "epoch:31 step:24718 [D loss: 1.190748, acc: 14.84%] [G loss: 3.709053]\n",
      "epoch:31 step:24719 [D loss: 0.026381, acc: 100.00%] [G loss: 5.088508]\n",
      "epoch:31 step:24720 [D loss: 0.888151, acc: 45.31%] [G loss: 6.617441]\n",
      "epoch:31 step:24721 [D loss: 0.587036, acc: 67.19%] [G loss: 4.206957]\n",
      "epoch:31 step:24722 [D loss: 0.175453, acc: 97.66%] [G loss: 4.286621]\n",
      "epoch:31 step:24723 [D loss: 1.161839, acc: 48.44%] [G loss: 6.271991]\n",
      "epoch:31 step:24724 [D loss: 1.034608, acc: 46.88%] [G loss: 4.809818]\n",
      "epoch:31 step:24725 [D loss: 0.167166, acc: 97.66%] [G loss: 3.898588]\n",
      "epoch:31 step:24726 [D loss: 0.244951, acc: 97.66%] [G loss: 3.765448]\n",
      "epoch:31 step:24727 [D loss: 0.206015, acc: 98.44%] [G loss: 5.675041]\n",
      "epoch:31 step:24728 [D loss: 0.516415, acc: 66.41%] [G loss: 6.358046]\n",
      "epoch:31 step:24729 [D loss: 0.145998, acc: 97.66%] [G loss: 7.086093]\n",
      "epoch:31 step:24730 [D loss: 0.577454, acc: 64.84%] [G loss: 2.977629]\n",
      "epoch:31 step:24731 [D loss: 0.206203, acc: 97.66%] [G loss: 4.960951]\n",
      "epoch:31 step:24732 [D loss: 0.514322, acc: 63.28%] [G loss: 4.598124]\n",
      "epoch:31 step:24733 [D loss: 0.524593, acc: 73.44%] [G loss: 4.774981]\n",
      "epoch:31 step:24734 [D loss: 0.556475, acc: 67.19%] [G loss: 4.840067]\n",
      "epoch:31 step:24735 [D loss: 0.117298, acc: 100.00%] [G loss: 6.386971]\n",
      "epoch:31 step:24736 [D loss: 1.198533, acc: 28.12%] [G loss: 3.163394]\n",
      "epoch:31 step:24737 [D loss: 0.408160, acc: 86.72%] [G loss: 3.177798]\n",
      "epoch:31 step:24738 [D loss: 0.043509, acc: 100.00%] [G loss: 5.905716]\n",
      "epoch:31 step:24739 [D loss: 0.362286, acc: 90.62%] [G loss: 2.927569]\n",
      "epoch:31 step:24740 [D loss: 0.122856, acc: 100.00%] [G loss: 3.776446]\n",
      "epoch:31 step:24741 [D loss: 0.256944, acc: 97.66%] [G loss: 3.865957]\n",
      "epoch:31 step:24742 [D loss: 0.148098, acc: 100.00%] [G loss: 4.587631]\n",
      "epoch:31 step:24743 [D loss: 0.409595, acc: 87.50%] [G loss: 3.592633]\n",
      "epoch:31 step:24744 [D loss: 0.140273, acc: 96.88%] [G loss: 3.431921]\n",
      "epoch:31 step:24745 [D loss: 0.095430, acc: 100.00%] [G loss: 3.609911]\n",
      "epoch:31 step:24746 [D loss: 0.437005, acc: 73.44%] [G loss: 2.553061]\n",
      "epoch:31 step:24747 [D loss: 0.171300, acc: 100.00%] [G loss: 5.441748]\n",
      "epoch:31 step:24748 [D loss: 0.219168, acc: 96.09%] [G loss: 5.057862]\n",
      "epoch:31 step:24749 [D loss: 0.283391, acc: 96.09%] [G loss: 5.666244]\n",
      "epoch:31 step:24750 [D loss: 1.660197, acc: 28.91%] [G loss: 2.344658]\n",
      "epoch:31 step:24751 [D loss: 0.739265, acc: 52.34%] [G loss: 2.449170]\n",
      "epoch:31 step:24752 [D loss: 0.114996, acc: 100.00%] [G loss: 3.750517]\n",
      "epoch:31 step:24753 [D loss: 0.521641, acc: 67.19%] [G loss: 3.862786]\n",
      "epoch:31 step:24754 [D loss: 0.238628, acc: 93.75%] [G loss: 4.157970]\n",
      "epoch:31 step:24755 [D loss: 0.289595, acc: 92.97%] [G loss: 3.806210]\n",
      "epoch:31 step:24756 [D loss: 0.127193, acc: 100.00%] [G loss: 5.475631]\n",
      "epoch:31 step:24757 [D loss: 0.198228, acc: 96.88%] [G loss: 5.773759]\n",
      "epoch:31 step:24758 [D loss: 0.613869, acc: 61.72%] [G loss: 3.669758]\n",
      "epoch:31 step:24759 [D loss: 0.390733, acc: 73.44%] [G loss: 3.494901]\n",
      "epoch:31 step:24760 [D loss: 1.207980, acc: 23.44%] [G loss: 3.123893]\n",
      "epoch:31 step:24761 [D loss: 0.044978, acc: 100.00%] [G loss: 3.374524]\n",
      "epoch:31 step:24762 [D loss: 0.185563, acc: 92.19%] [G loss: 6.019998]\n",
      "epoch:31 step:24763 [D loss: 0.078106, acc: 100.00%] [G loss: 4.986719]\n",
      "epoch:31 step:24764 [D loss: 0.107020, acc: 99.22%] [G loss: 4.551799]\n",
      "epoch:31 step:24765 [D loss: 0.387294, acc: 82.03%] [G loss: 5.017235]\n",
      "epoch:31 step:24766 [D loss: 0.079554, acc: 100.00%] [G loss: 4.721245]\n",
      "epoch:31 step:24767 [D loss: 0.217027, acc: 95.31%] [G loss: 4.702812]\n",
      "epoch:31 step:24768 [D loss: 0.916087, acc: 51.56%] [G loss: 6.318968]\n",
      "epoch:31 step:24769 [D loss: 0.380476, acc: 74.22%] [G loss: 4.973736]\n",
      "epoch:31 step:24770 [D loss: 0.525762, acc: 75.78%] [G loss: 6.934241]\n",
      "epoch:31 step:24771 [D loss: 0.073958, acc: 100.00%] [G loss: 5.029893]\n",
      "epoch:31 step:24772 [D loss: 0.358217, acc: 83.59%] [G loss: 5.897347]\n",
      "epoch:31 step:24773 [D loss: 0.145816, acc: 99.22%] [G loss: 5.022646]\n",
      "epoch:31 step:24774 [D loss: 0.323737, acc: 81.25%] [G loss: 4.555269]\n",
      "epoch:31 step:24775 [D loss: 0.049579, acc: 100.00%] [G loss: 4.501840]\n",
      "epoch:31 step:24776 [D loss: 0.221942, acc: 99.22%] [G loss: 4.265881]\n",
      "epoch:31 step:24777 [D loss: 0.342573, acc: 92.19%] [G loss: 3.423576]\n",
      "epoch:31 step:24778 [D loss: 0.212777, acc: 98.44%] [G loss: 3.726940]\n",
      "epoch:31 step:24779 [D loss: 0.290110, acc: 89.84%] [G loss: 3.679766]\n",
      "epoch:31 step:24780 [D loss: 0.306436, acc: 86.72%] [G loss: 4.317519]\n",
      "epoch:31 step:24781 [D loss: 0.267047, acc: 92.97%] [G loss: 2.032218]\n",
      "epoch:31 step:24782 [D loss: 0.122454, acc: 98.44%] [G loss: 5.216070]\n",
      "epoch:31 step:24783 [D loss: 0.317736, acc: 89.06%] [G loss: 4.176339]\n",
      "epoch:31 step:24784 [D loss: 0.205499, acc: 98.44%] [G loss: 3.933184]\n",
      "epoch:31 step:24785 [D loss: 0.913479, acc: 50.78%] [G loss: 3.870612]\n",
      "epoch:31 step:24786 [D loss: 0.146712, acc: 100.00%] [G loss: 4.301399]\n",
      "epoch:31 step:24787 [D loss: 0.594855, acc: 59.38%] [G loss: 2.441254]\n",
      "epoch:31 step:24788 [D loss: 0.653209, acc: 60.16%] [G loss: 3.302463]\n",
      "epoch:31 step:24789 [D loss: 0.350277, acc: 92.97%] [G loss: 4.438144]\n",
      "epoch:31 step:24790 [D loss: 0.388304, acc: 84.38%] [G loss: 3.631091]\n",
      "epoch:31 step:24791 [D loss: 0.777438, acc: 57.03%] [G loss: 3.295043]\n",
      "epoch:31 step:24792 [D loss: 0.067429, acc: 100.00%] [G loss: 5.200013]\n",
      "epoch:31 step:24793 [D loss: 0.636689, acc: 67.19%] [G loss: 3.970767]\n",
      "epoch:31 step:24794 [D loss: 0.260683, acc: 96.09%] [G loss: 3.711265]\n",
      "epoch:31 step:24795 [D loss: 0.450565, acc: 82.03%] [G loss: 6.446424]\n",
      "epoch:31 step:24796 [D loss: 0.713012, acc: 53.12%] [G loss: 5.589649]\n",
      "epoch:31 step:24797 [D loss: 0.267455, acc: 93.75%] [G loss: 5.707261]\n",
      "epoch:31 step:24798 [D loss: 0.394158, acc: 75.78%] [G loss: 3.560312]\n",
      "epoch:31 step:24799 [D loss: 0.431468, acc: 82.03%] [G loss: 7.049911]\n",
      "epoch:31 step:24800 [D loss: 0.461181, acc: 73.44%] [G loss: 6.414899]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##############\n",
      "[0.85865982 0.87081378 0.82682847 0.80320414 0.79621475 0.82401886\n",
      " 0.87290984 0.85561422 0.79973324 0.81360252]\n",
      "##########\n",
      "epoch:31 step:24801 [D loss: 0.299298, acc: 96.88%] [G loss: 4.136166]\n",
      "epoch:31 step:24802 [D loss: 0.160954, acc: 98.44%] [G loss: 4.673625]\n",
      "epoch:31 step:24803 [D loss: 0.303981, acc: 92.19%] [G loss: 4.424278]\n",
      "epoch:31 step:24804 [D loss: 0.843797, acc: 45.31%] [G loss: 5.154005]\n",
      "epoch:31 step:24805 [D loss: 0.611844, acc: 60.94%] [G loss: 3.194054]\n",
      "epoch:31 step:24806 [D loss: 0.060678, acc: 100.00%] [G loss: 6.663893]\n",
      "epoch:31 step:24807 [D loss: 0.647144, acc: 55.47%] [G loss: 5.122395]\n",
      "epoch:31 step:24808 [D loss: 0.581557, acc: 64.84%] [G loss: 4.482104]\n",
      "epoch:31 step:24809 [D loss: 0.036893, acc: 100.00%] [G loss: 5.660344]\n",
      "epoch:31 step:24810 [D loss: 0.392644, acc: 86.72%] [G loss: 5.259882]\n",
      "epoch:31 step:24811 [D loss: 0.127612, acc: 100.00%] [G loss: 5.747752]\n",
      "epoch:31 step:24812 [D loss: 0.426421, acc: 78.12%] [G loss: 4.475393]\n",
      "epoch:31 step:24813 [D loss: 0.112303, acc: 99.22%] [G loss: 4.544258]\n",
      "epoch:31 step:24814 [D loss: 0.752580, acc: 56.25%] [G loss: 5.893662]\n",
      "epoch:31 step:24815 [D loss: 0.547729, acc: 68.75%] [G loss: 3.027511]\n",
      "epoch:31 step:24816 [D loss: 0.302651, acc: 87.50%] [G loss: 6.157338]\n",
      "epoch:31 step:24817 [D loss: 0.798736, acc: 47.66%] [G loss: 4.700021]\n",
      "epoch:31 step:24818 [D loss: 0.170428, acc: 96.88%] [G loss: 3.909094]\n",
      "epoch:31 step:24819 [D loss: 0.595422, acc: 67.19%] [G loss: 4.605698]\n",
      "epoch:31 step:24820 [D loss: 0.275288, acc: 92.97%] [G loss: 5.492537]\n",
      "epoch:31 step:24821 [D loss: 0.359364, acc: 90.62%] [G loss: 2.598572]\n",
      "epoch:31 step:24822 [D loss: 0.450465, acc: 78.91%] [G loss: 5.924719]\n",
      "epoch:31 step:24823 [D loss: 0.182696, acc: 96.09%] [G loss: 6.380474]\n",
      "epoch:31 step:24824 [D loss: 0.763348, acc: 54.69%] [G loss: 3.642754]\n",
      "epoch:31 step:24825 [D loss: 0.201702, acc: 99.22%] [G loss: 4.395881]\n",
      "epoch:31 step:24826 [D loss: 0.618216, acc: 66.41%] [G loss: 3.878284]\n",
      "epoch:31 step:24827 [D loss: 0.363069, acc: 92.19%] [G loss: 5.782612]\n",
      "epoch:31 step:24828 [D loss: 0.092530, acc: 100.00%] [G loss: 6.547315]\n",
      "epoch:31 step:24829 [D loss: 0.630084, acc: 61.72%] [G loss: 3.474094]\n",
      "epoch:31 step:24830 [D loss: 0.764717, acc: 52.34%] [G loss: 2.431936]\n",
      "epoch:31 step:24831 [D loss: 0.414112, acc: 90.62%] [G loss: 4.896379]\n",
      "epoch:31 step:24832 [D loss: 0.187881, acc: 98.44%] [G loss: 3.282545]\n",
      "epoch:31 step:24833 [D loss: 0.700132, acc: 60.16%] [G loss: 4.999036]\n",
      "epoch:31 step:24834 [D loss: 0.260747, acc: 91.41%] [G loss: 4.525590]\n",
      "epoch:31 step:24835 [D loss: 0.232817, acc: 92.97%] [G loss: 5.644327]\n",
      "epoch:31 step:24836 [D loss: 0.043437, acc: 100.00%] [G loss: 8.089834]\n",
      "epoch:31 step:24837 [D loss: 0.375518, acc: 92.97%] [G loss: 3.015096]\n",
      "epoch:31 step:24838 [D loss: 0.329175, acc: 92.97%] [G loss: 3.614580]\n",
      "epoch:31 step:24839 [D loss: 0.198121, acc: 98.44%] [G loss: 5.388378]\n",
      "epoch:31 step:24840 [D loss: 0.119633, acc: 100.00%] [G loss: 8.294463]\n",
      "epoch:31 step:24841 [D loss: 0.049198, acc: 100.00%] [G loss: 5.774613]\n",
      "epoch:31 step:24842 [D loss: 0.833743, acc: 52.34%] [G loss: 2.658873]\n",
      "epoch:31 step:24843 [D loss: 0.358879, acc: 83.59%] [G loss: 5.550686]\n",
      "epoch:31 step:24844 [D loss: 0.580088, acc: 71.88%] [G loss: 4.667244]\n",
      "epoch:31 step:24845 [D loss: 0.367660, acc: 83.59%] [G loss: 3.487128]\n",
      "epoch:31 step:24846 [D loss: 0.405948, acc: 80.47%] [G loss: 4.321998]\n",
      "epoch:31 step:24847 [D loss: 0.588611, acc: 68.75%] [G loss: 4.038327]\n",
      "epoch:31 step:24848 [D loss: 0.268058, acc: 91.41%] [G loss: 3.338526]\n",
      "epoch:31 step:24849 [D loss: 0.157522, acc: 99.22%] [G loss: 4.328197]\n",
      "epoch:31 step:24850 [D loss: 0.140877, acc: 100.00%] [G loss: 2.756208]\n",
      "epoch:31 step:24851 [D loss: 0.447939, acc: 80.47%] [G loss: 5.888038]\n",
      "epoch:31 step:24852 [D loss: 0.357135, acc: 77.34%] [G loss: 3.750271]\n",
      "epoch:31 step:24853 [D loss: 0.071251, acc: 100.00%] [G loss: 4.470170]\n",
      "epoch:31 step:24854 [D loss: 1.041404, acc: 34.38%] [G loss: 5.319234]\n",
      "epoch:31 step:24855 [D loss: 0.461702, acc: 71.88%] [G loss: 5.129520]\n",
      "epoch:31 step:24856 [D loss: 0.313642, acc: 92.97%] [G loss: 5.957856]\n",
      "epoch:31 step:24857 [D loss: 0.208856, acc: 97.66%] [G loss: 5.332266]\n",
      "epoch:31 step:24858 [D loss: 0.601193, acc: 61.72%] [G loss: 4.588623]\n",
      "epoch:31 step:24859 [D loss: 0.035412, acc: 100.00%] [G loss: 4.361244]\n",
      "epoch:31 step:24860 [D loss: 0.157044, acc: 98.44%] [G loss: 4.705579]\n",
      "epoch:31 step:24861 [D loss: 0.949823, acc: 50.78%] [G loss: 4.502663]\n",
      "epoch:31 step:24862 [D loss: 0.319531, acc: 96.09%] [G loss: 3.814600]\n",
      "epoch:31 step:24863 [D loss: 0.253687, acc: 94.53%] [G loss: 5.413820]\n",
      "epoch:31 step:24864 [D loss: 0.070414, acc: 100.00%] [G loss: 4.455431]\n",
      "epoch:31 step:24865 [D loss: 0.662863, acc: 63.28%] [G loss: 6.285927]\n",
      "epoch:31 step:24866 [D loss: 0.743926, acc: 53.91%] [G loss: 4.783999]\n",
      "epoch:31 step:24867 [D loss: 0.557819, acc: 74.22%] [G loss: 4.805379]\n",
      "epoch:31 step:24868 [D loss: 1.116812, acc: 50.78%] [G loss: 4.491892]\n",
      "epoch:31 step:24869 [D loss: 0.490940, acc: 80.47%] [G loss: 5.239950]\n",
      "epoch:31 step:24870 [D loss: 0.180049, acc: 100.00%] [G loss: 5.250317]\n",
      "epoch:31 step:24871 [D loss: 0.412698, acc: 83.59%] [G loss: 3.283304]\n",
      "epoch:31 step:24872 [D loss: 1.032524, acc: 45.31%] [G loss: 4.836127]\n",
      "epoch:31 step:24873 [D loss: 0.156585, acc: 98.44%] [G loss: 3.527528]\n",
      "epoch:31 step:24874 [D loss: 0.777329, acc: 49.22%] [G loss: 6.299345]\n",
      "epoch:31 step:24875 [D loss: 0.421797, acc: 84.38%] [G loss: 7.228416]\n",
      "epoch:31 step:24876 [D loss: 0.697150, acc: 56.25%] [G loss: 4.283436]\n",
      "epoch:31 step:24877 [D loss: 0.286049, acc: 88.28%] [G loss: 4.311626]\n",
      "epoch:31 step:24878 [D loss: 0.074266, acc: 100.00%] [G loss: 5.298615]\n",
      "epoch:31 step:24879 [D loss: 1.239842, acc: 50.00%] [G loss: 8.226946]\n",
      "epoch:31 step:24880 [D loss: 0.232488, acc: 94.53%] [G loss: 3.819227]\n",
      "epoch:31 step:24881 [D loss: 0.385171, acc: 80.47%] [G loss: 3.683012]\n",
      "epoch:31 step:24882 [D loss: 0.256816, acc: 98.44%] [G loss: 4.936062]\n",
      "epoch:31 step:24883 [D loss: 0.238473, acc: 97.66%] [G loss: 6.898829]\n",
      "epoch:31 step:24884 [D loss: 0.235377, acc: 96.88%] [G loss: 5.337922]\n",
      "epoch:31 step:24885 [D loss: 0.486329, acc: 77.34%] [G loss: 8.149684]\n",
      "epoch:31 step:24886 [D loss: 1.146115, acc: 33.59%] [G loss: 4.397431]\n",
      "epoch:31 step:24887 [D loss: 0.172593, acc: 100.00%] [G loss: 3.183043]\n",
      "epoch:31 step:24888 [D loss: 0.353310, acc: 79.69%] [G loss: 4.511009]\n",
      "epoch:31 step:24889 [D loss: 0.361327, acc: 85.94%] [G loss: 4.373412]\n",
      "epoch:31 step:24890 [D loss: 0.364484, acc: 85.16%] [G loss: 5.312832]\n",
      "epoch:31 step:24891 [D loss: 0.076057, acc: 100.00%] [G loss: 4.875237]\n",
      "epoch:31 step:24892 [D loss: 0.429785, acc: 75.00%] [G loss: 4.388390]\n",
      "epoch:31 step:24893 [D loss: 0.275533, acc: 92.97%] [G loss: 3.467229]\n",
      "epoch:31 step:24894 [D loss: 0.987149, acc: 50.00%] [G loss: 5.625218]\n",
      "epoch:31 step:24895 [D loss: 0.738844, acc: 54.69%] [G loss: 2.980150]\n",
      "epoch:31 step:24896 [D loss: 0.097136, acc: 100.00%] [G loss: 4.336796]\n",
      "epoch:31 step:24897 [D loss: 0.129998, acc: 100.00%] [G loss: 4.165417]\n",
      "epoch:31 step:24898 [D loss: 0.659022, acc: 57.81%] [G loss: 5.470653]\n",
      "epoch:31 step:24899 [D loss: 0.395204, acc: 88.28%] [G loss: 4.540093]\n",
      "epoch:31 step:24900 [D loss: 1.059178, acc: 32.81%] [G loss: 4.513680]\n",
      "epoch:31 step:24901 [D loss: 0.101010, acc: 99.22%] [G loss: 5.189517]\n",
      "epoch:31 step:24902 [D loss: 0.613864, acc: 61.72%] [G loss: 4.499638]\n",
      "epoch:31 step:24903 [D loss: 0.344574, acc: 80.47%] [G loss: 2.551564]\n",
      "epoch:31 step:24904 [D loss: 0.510854, acc: 83.59%] [G loss: 3.197468]\n",
      "epoch:31 step:24905 [D loss: 0.549442, acc: 59.38%] [G loss: 3.651206]\n",
      "epoch:31 step:24906 [D loss: 0.873517, acc: 52.34%] [G loss: 3.463672]\n",
      "epoch:31 step:24907 [D loss: 0.218209, acc: 97.66%] [G loss: 4.511986]\n",
      "epoch:31 step:24908 [D loss: 0.263160, acc: 92.19%] [G loss: 4.632663]\n",
      "epoch:31 step:24909 [D loss: 0.854417, acc: 51.56%] [G loss: 3.443148]\n",
      "epoch:31 step:24910 [D loss: 0.594869, acc: 61.72%] [G loss: 3.418133]\n",
      "epoch:31 step:24911 [D loss: 0.354997, acc: 78.12%] [G loss: 5.273184]\n",
      "epoch:31 step:24912 [D loss: 0.606847, acc: 63.28%] [G loss: 5.408470]\n",
      "epoch:31 step:24913 [D loss: 0.186966, acc: 97.66%] [G loss: 3.608364]\n",
      "epoch:31 step:24914 [D loss: 0.370091, acc: 81.25%] [G loss: 3.536379]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:31 step:24915 [D loss: 1.090667, acc: 50.00%] [G loss: 4.934281]\n",
      "epoch:31 step:24916 [D loss: 0.028966, acc: 100.00%] [G loss: 4.895175]\n",
      "epoch:31 step:24917 [D loss: 0.164206, acc: 96.88%] [G loss: 4.343906]\n",
      "epoch:31 step:24918 [D loss: 1.401798, acc: 49.22%] [G loss: 7.472545]\n",
      "epoch:31 step:24919 [D loss: 0.138156, acc: 96.88%] [G loss: 7.690498]\n",
      "epoch:31 step:24920 [D loss: 0.676446, acc: 58.59%] [G loss: 3.121454]\n",
      "epoch:31 step:24921 [D loss: 0.248388, acc: 93.75%] [G loss: 4.488210]\n",
      "epoch:31 step:24922 [D loss: 0.157087, acc: 98.44%] [G loss: 5.125408]\n",
      "epoch:31 step:24923 [D loss: 1.167089, acc: 37.50%] [G loss: 2.901563]\n",
      "epoch:31 step:24924 [D loss: 0.240150, acc: 95.31%] [G loss: 5.924527]\n",
      "epoch:31 step:24925 [D loss: 0.865987, acc: 48.44%] [G loss: 6.761617]\n",
      "epoch:31 step:24926 [D loss: 0.209351, acc: 94.53%] [G loss: 4.125558]\n",
      "epoch:31 step:24927 [D loss: 0.376482, acc: 94.53%] [G loss: 5.337951]\n",
      "epoch:31 step:24928 [D loss: 0.047526, acc: 100.00%] [G loss: 7.044350]\n",
      "epoch:31 step:24929 [D loss: 0.157498, acc: 99.22%] [G loss: 5.228318]\n",
      "epoch:31 step:24930 [D loss: 0.152477, acc: 96.88%] [G loss: 4.386321]\n",
      "epoch:31 step:24931 [D loss: 0.194035, acc: 98.44%] [G loss: 4.553377]\n",
      "epoch:31 step:24932 [D loss: 0.251460, acc: 96.88%] [G loss: 5.240194]\n",
      "epoch:31 step:24933 [D loss: 0.115520, acc: 100.00%] [G loss: 4.078426]\n",
      "epoch:31 step:24934 [D loss: 0.067901, acc: 100.00%] [G loss: 6.767007]\n",
      "epoch:31 step:24935 [D loss: 0.682690, acc: 60.94%] [G loss: 3.538992]\n",
      "epoch:31 step:24936 [D loss: 0.379237, acc: 89.06%] [G loss: 4.246812]\n",
      "epoch:31 step:24937 [D loss: 0.060299, acc: 100.00%] [G loss: 2.216148]\n",
      "epoch:31 step:24938 [D loss: 0.259748, acc: 94.53%] [G loss: 4.538338]\n",
      "epoch:31 step:24939 [D loss: 0.386926, acc: 89.84%] [G loss: 3.272416]\n",
      "epoch:31 step:24940 [D loss: 0.120904, acc: 100.00%] [G loss: 5.827329]\n",
      "epoch:31 step:24941 [D loss: 0.465159, acc: 74.22%] [G loss: 3.413605]\n",
      "epoch:31 step:24942 [D loss: 0.220074, acc: 97.66%] [G loss: 6.873530]\n",
      "epoch:31 step:24943 [D loss: 0.237927, acc: 98.44%] [G loss: 3.002804]\n",
      "epoch:31 step:24944 [D loss: 0.353976, acc: 85.94%] [G loss: 5.390193]\n",
      "epoch:31 step:24945 [D loss: 0.711778, acc: 57.81%] [G loss: 6.316105]\n",
      "epoch:31 step:24946 [D loss: 0.508601, acc: 65.62%] [G loss: 5.352414]\n",
      "epoch:31 step:24947 [D loss: 0.329154, acc: 81.25%] [G loss: 7.579160]\n",
      "epoch:31 step:24948 [D loss: 0.300002, acc: 94.53%] [G loss: 5.365427]\n",
      "epoch:31 step:24949 [D loss: 0.149474, acc: 100.00%] [G loss: 5.152368]\n",
      "epoch:31 step:24950 [D loss: 0.310740, acc: 93.75%] [G loss: 3.185261]\n",
      "epoch:31 step:24951 [D loss: 0.332263, acc: 91.41%] [G loss: 3.912202]\n",
      "epoch:31 step:24952 [D loss: 0.165889, acc: 98.44%] [G loss: 3.810248]\n",
      "epoch:31 step:24953 [D loss: 0.343223, acc: 82.81%] [G loss: 1.865252]\n",
      "epoch:31 step:24954 [D loss: 0.199844, acc: 95.31%] [G loss: 4.031747]\n",
      "epoch:31 step:24955 [D loss: 0.559184, acc: 72.66%] [G loss: 2.151112]\n",
      "epoch:31 step:24956 [D loss: 0.292967, acc: 90.62%] [G loss: 4.465576]\n",
      "epoch:31 step:24957 [D loss: 1.230334, acc: 43.75%] [G loss: 4.384615]\n",
      "epoch:31 step:24958 [D loss: 0.421709, acc: 82.81%] [G loss: 5.201547]\n",
      "epoch:31 step:24959 [D loss: 0.636159, acc: 63.28%] [G loss: 5.883586]\n",
      "epoch:31 step:24960 [D loss: 0.298095, acc: 99.22%] [G loss: 5.092567]\n",
      "epoch:31 step:24961 [D loss: 0.781429, acc: 52.34%] [G loss: 5.216116]\n",
      "epoch:31 step:24962 [D loss: 1.208867, acc: 48.44%] [G loss: 3.289095]\n",
      "epoch:31 step:24963 [D loss: 0.153971, acc: 99.22%] [G loss: 4.616758]\n",
      "epoch:31 step:24964 [D loss: 0.584706, acc: 59.38%] [G loss: 6.396168]\n",
      "epoch:31 step:24965 [D loss: 0.840527, acc: 39.84%] [G loss: 6.336997]\n",
      "epoch:31 step:24966 [D loss: 0.174878, acc: 96.09%] [G loss: 3.930374]\n",
      "epoch:31 step:24967 [D loss: 0.088473, acc: 100.00%] [G loss: 4.142341]\n",
      "epoch:31 step:24968 [D loss: 0.107864, acc: 100.00%] [G loss: 4.834323]\n",
      "epoch:31 step:24969 [D loss: 0.636568, acc: 60.94%] [G loss: 6.399989]\n",
      "epoch:31 step:24970 [D loss: 0.788036, acc: 55.47%] [G loss: 4.004147]\n",
      "epoch:31 step:24971 [D loss: 0.016224, acc: 100.00%] [G loss: 8.363205]\n",
      "epoch:31 step:24972 [D loss: 0.245029, acc: 96.09%] [G loss: 3.454911]\n",
      "epoch:31 step:24973 [D loss: 0.079818, acc: 100.00%] [G loss: 5.936085]\n",
      "epoch:31 step:24974 [D loss: 1.100648, acc: 41.41%] [G loss: 4.450941]\n",
      "epoch:31 step:24975 [D loss: 0.538216, acc: 62.50%] [G loss: 5.656101]\n",
      "epoch:31 step:24976 [D loss: 0.466231, acc: 68.75%] [G loss: 4.994683]\n",
      "epoch:31 step:24977 [D loss: 0.401960, acc: 84.38%] [G loss: 2.849377]\n",
      "epoch:31 step:24978 [D loss: 0.149522, acc: 96.09%] [G loss: 5.209844]\n",
      "epoch:31 step:24979 [D loss: 0.074770, acc: 100.00%] [G loss: 5.059019]\n",
      "epoch:31 step:24980 [D loss: 1.125856, acc: 29.69%] [G loss: 3.988156]\n",
      "epoch:31 step:24981 [D loss: 0.228860, acc: 94.53%] [G loss: 3.019638]\n",
      "epoch:31 step:24982 [D loss: 0.352102, acc: 91.41%] [G loss: 3.240509]\n",
      "epoch:31 step:24983 [D loss: 1.088412, acc: 50.78%] [G loss: 3.837806]\n",
      "epoch:31 step:24984 [D loss: 0.062439, acc: 100.00%] [G loss: 6.147350]\n",
      "epoch:31 step:24985 [D loss: 0.338330, acc: 80.47%] [G loss: 6.547425]\n",
      "epoch:31 step:24986 [D loss: 0.814722, acc: 46.88%] [G loss: 6.316117]\n",
      "epoch:31 step:24987 [D loss: 0.412118, acc: 82.03%] [G loss: 3.140921]\n",
      "epoch:31 step:24988 [D loss: 2.014950, acc: 3.12%] [G loss: 3.744538]\n",
      "epoch:31 step:24989 [D loss: 0.318695, acc: 92.97%] [G loss: 4.348315]\n",
      "epoch:31 step:24990 [D loss: 0.441082, acc: 76.56%] [G loss: 3.960268]\n",
      "epoch:31 step:24991 [D loss: 0.310526, acc: 86.72%] [G loss: 2.817436]\n",
      "epoch:31 step:24992 [D loss: 0.250271, acc: 94.53%] [G loss: 3.439843]\n",
      "epoch:32 step:24993 [D loss: 0.114069, acc: 100.00%] [G loss: 4.996164]\n",
      "epoch:32 step:24994 [D loss: 0.133778, acc: 99.22%] [G loss: 2.195675]\n",
      "epoch:32 step:24995 [D loss: 0.926351, acc: 44.53%] [G loss: 3.253805]\n",
      "epoch:32 step:24996 [D loss: 0.316622, acc: 94.53%] [G loss: 3.311366]\n",
      "epoch:32 step:24997 [D loss: 0.105043, acc: 99.22%] [G loss: 5.468548]\n",
      "epoch:32 step:24998 [D loss: 0.541247, acc: 75.78%] [G loss: 3.751170]\n",
      "epoch:32 step:24999 [D loss: 0.140003, acc: 100.00%] [G loss: 1.944908]\n",
      "epoch:32 step:25000 [D loss: 0.343582, acc: 89.06%] [G loss: 4.394400]\n",
      "##############\n",
      "[0.86667263 0.87818589 0.82015573 0.83503499 0.79027364 0.8156338\n",
      " 0.87908563 0.80905279 0.79140468 0.83097686]\n",
      "##########\n",
      "epoch:32 step:25001 [D loss: 0.151612, acc: 98.44%] [G loss: 4.695378]\n",
      "epoch:32 step:25002 [D loss: 0.526778, acc: 75.78%] [G loss: 2.422633]\n",
      "epoch:32 step:25003 [D loss: 0.418741, acc: 86.72%] [G loss: 4.438809]\n",
      "epoch:32 step:25004 [D loss: 0.789604, acc: 46.09%] [G loss: 5.296879]\n",
      "epoch:32 step:25005 [D loss: 0.817286, acc: 51.56%] [G loss: 2.415825]\n",
      "epoch:32 step:25006 [D loss: 0.398277, acc: 80.47%] [G loss: 4.864550]\n",
      "epoch:32 step:25007 [D loss: 0.392745, acc: 76.56%] [G loss: 4.050307]\n",
      "epoch:32 step:25008 [D loss: 0.229417, acc: 96.88%] [G loss: 3.739341]\n",
      "epoch:32 step:25009 [D loss: 0.770521, acc: 53.12%] [G loss: 4.174594]\n",
      "epoch:32 step:25010 [D loss: 0.196810, acc: 97.66%] [G loss: 3.351044]\n",
      "epoch:32 step:25011 [D loss: 0.304775, acc: 94.53%] [G loss: 4.832355]\n",
      "epoch:32 step:25012 [D loss: 0.118696, acc: 99.22%] [G loss: 6.522552]\n",
      "epoch:32 step:25013 [D loss: 0.345593, acc: 85.94%] [G loss: 6.230886]\n",
      "epoch:32 step:25014 [D loss: 0.419016, acc: 74.22%] [G loss: 5.296261]\n",
      "epoch:32 step:25015 [D loss: 0.217547, acc: 98.44%] [G loss: 2.400860]\n",
      "epoch:32 step:25016 [D loss: 0.308722, acc: 82.81%] [G loss: 6.576548]\n",
      "epoch:32 step:25017 [D loss: 0.883914, acc: 39.84%] [G loss: 4.668369]\n",
      "epoch:32 step:25018 [D loss: 0.624102, acc: 67.19%] [G loss: 5.682168]\n",
      "epoch:32 step:25019 [D loss: 0.137313, acc: 100.00%] [G loss: 5.680551]\n",
      "epoch:32 step:25020 [D loss: 0.402632, acc: 80.47%] [G loss: 4.415514]\n",
      "epoch:32 step:25021 [D loss: 1.401492, acc: 50.00%] [G loss: 3.342172]\n",
      "epoch:32 step:25022 [D loss: 0.091027, acc: 99.22%] [G loss: 5.467561]\n",
      "epoch:32 step:25023 [D loss: 0.311300, acc: 89.06%] [G loss: 5.037944]\n",
      "epoch:32 step:25024 [D loss: 0.356625, acc: 92.19%] [G loss: 6.938109]\n",
      "epoch:32 step:25025 [D loss: 1.233875, acc: 10.94%] [G loss: 3.246527]\n",
      "epoch:32 step:25026 [D loss: 1.094441, acc: 51.56%] [G loss: 4.802007]\n",
      "epoch:32 step:25027 [D loss: 0.043153, acc: 100.00%] [G loss: 5.211304]\n",
      "epoch:32 step:25028 [D loss: 0.043337, acc: 100.00%] [G loss: 4.793485]\n",
      "epoch:32 step:25029 [D loss: 0.022011, acc: 100.00%] [G loss: 6.117278]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:32 step:25030 [D loss: 0.385979, acc: 81.25%] [G loss: 3.285230]\n",
      "epoch:32 step:25031 [D loss: 0.179222, acc: 97.66%] [G loss: 4.280343]\n",
      "epoch:32 step:25032 [D loss: 0.752449, acc: 50.78%] [G loss: 4.801868]\n",
      "epoch:32 step:25033 [D loss: 0.761888, acc: 50.00%] [G loss: 2.955858]\n",
      "epoch:32 step:25034 [D loss: 0.588986, acc: 57.81%] [G loss: 3.475485]\n",
      "epoch:32 step:25035 [D loss: 1.250067, acc: 21.09%] [G loss: 5.678713]\n",
      "epoch:32 step:25036 [D loss: 0.207583, acc: 95.31%] [G loss: 3.593848]\n",
      "epoch:32 step:25037 [D loss: 0.822885, acc: 45.31%] [G loss: 6.009480]\n",
      "epoch:32 step:25038 [D loss: 1.251643, acc: 14.84%] [G loss: 3.399928]\n",
      "epoch:32 step:25039 [D loss: 0.344637, acc: 85.94%] [G loss: 2.758518]\n",
      "epoch:32 step:25040 [D loss: 0.554658, acc: 60.16%] [G loss: 5.612556]\n",
      "epoch:32 step:25041 [D loss: 1.139505, acc: 28.12%] [G loss: 4.560863]\n",
      "epoch:32 step:25042 [D loss: 0.145092, acc: 99.22%] [G loss: 3.639667]\n",
      "epoch:32 step:25043 [D loss: 0.366050, acc: 89.06%] [G loss: 3.659584]\n",
      "epoch:32 step:25044 [D loss: 0.100444, acc: 98.44%] [G loss: 5.763009]\n",
      "epoch:32 step:25045 [D loss: 0.240334, acc: 92.19%] [G loss: 6.317369]\n",
      "epoch:32 step:25046 [D loss: 0.108469, acc: 100.00%] [G loss: 5.368936]\n",
      "epoch:32 step:25047 [D loss: 0.448357, acc: 74.22%] [G loss: 8.500539]\n",
      "epoch:32 step:25048 [D loss: 0.335753, acc: 87.50%] [G loss: 3.810017]\n",
      "epoch:32 step:25049 [D loss: 0.238795, acc: 98.44%] [G loss: 5.232971]\n",
      "epoch:32 step:25050 [D loss: 0.589232, acc: 69.53%] [G loss: 3.504241]\n",
      "epoch:32 step:25051 [D loss: 0.278819, acc: 92.97%] [G loss: 4.091004]\n",
      "epoch:32 step:25052 [D loss: 0.225654, acc: 97.66%] [G loss: 4.638845]\n",
      "epoch:32 step:25053 [D loss: 0.328090, acc: 93.75%] [G loss: 2.878239]\n",
      "epoch:32 step:25054 [D loss: 1.003801, acc: 35.16%] [G loss: 6.282815]\n",
      "epoch:32 step:25055 [D loss: 0.392904, acc: 87.50%] [G loss: 3.441698]\n",
      "epoch:32 step:25056 [D loss: 0.707662, acc: 55.47%] [G loss: 6.443716]\n",
      "epoch:32 step:25057 [D loss: 0.606715, acc: 58.59%] [G loss: 3.243383]\n",
      "epoch:32 step:25058 [D loss: 0.317720, acc: 92.19%] [G loss: 4.861045]\n",
      "epoch:32 step:25059 [D loss: 0.284056, acc: 96.88%] [G loss: 4.810533]\n",
      "epoch:32 step:25060 [D loss: 0.285807, acc: 95.31%] [G loss: 5.269439]\n",
      "epoch:32 step:25061 [D loss: 0.132750, acc: 100.00%] [G loss: 5.803814]\n",
      "epoch:32 step:25062 [D loss: 0.235794, acc: 97.66%] [G loss: 4.690137]\n",
      "epoch:32 step:25063 [D loss: 0.867706, acc: 53.12%] [G loss: 6.635920]\n",
      "epoch:32 step:25064 [D loss: 0.427745, acc: 70.31%] [G loss: 3.534219]\n",
      "epoch:32 step:25065 [D loss: 0.182906, acc: 97.66%] [G loss: 3.417491]\n",
      "epoch:32 step:25066 [D loss: 0.326972, acc: 82.03%] [G loss: 4.930468]\n",
      "epoch:32 step:25067 [D loss: 0.687013, acc: 60.16%] [G loss: 5.122880]\n",
      "epoch:32 step:25068 [D loss: 0.075214, acc: 100.00%] [G loss: 5.809034]\n",
      "epoch:32 step:25069 [D loss: 0.289677, acc: 85.94%] [G loss: 4.808815]\n",
      "epoch:32 step:25070 [D loss: 0.671365, acc: 60.94%] [G loss: 5.280043]\n",
      "epoch:32 step:25071 [D loss: 0.381431, acc: 87.50%] [G loss: 4.832008]\n",
      "epoch:32 step:25072 [D loss: 0.446552, acc: 82.03%] [G loss: 3.907884]\n",
      "epoch:32 step:25073 [D loss: 0.228073, acc: 96.09%] [G loss: 3.637388]\n",
      "epoch:32 step:25074 [D loss: 0.618800, acc: 63.28%] [G loss: 3.948132]\n",
      "epoch:32 step:25075 [D loss: 0.110561, acc: 99.22%] [G loss: 6.092716]\n",
      "epoch:32 step:25076 [D loss: 0.208506, acc: 96.88%] [G loss: 2.933570]\n",
      "epoch:32 step:25077 [D loss: 1.082544, acc: 40.62%] [G loss: 4.817715]\n",
      "epoch:32 step:25078 [D loss: 0.209944, acc: 95.31%] [G loss: 4.843320]\n",
      "epoch:32 step:25079 [D loss: 1.064445, acc: 17.19%] [G loss: 3.942335]\n",
      "epoch:32 step:25080 [D loss: 0.754558, acc: 50.00%] [G loss: 3.291162]\n",
      "epoch:32 step:25081 [D loss: 0.060859, acc: 99.22%] [G loss: 5.332968]\n",
      "epoch:32 step:25082 [D loss: 0.819798, acc: 50.78%] [G loss: 5.958909]\n",
      "epoch:32 step:25083 [D loss: 0.086425, acc: 98.44%] [G loss: 5.697067]\n",
      "epoch:32 step:25084 [D loss: 0.291336, acc: 95.31%] [G loss: 5.960173]\n",
      "epoch:32 step:25085 [D loss: 0.181303, acc: 95.31%] [G loss: 4.446190]\n",
      "epoch:32 step:25086 [D loss: 0.305166, acc: 85.94%] [G loss: 3.293705]\n",
      "epoch:32 step:25087 [D loss: 0.845546, acc: 47.66%] [G loss: 3.265012]\n",
      "epoch:32 step:25088 [D loss: 0.328495, acc: 92.19%] [G loss: 6.258993]\n",
      "epoch:32 step:25089 [D loss: 0.317045, acc: 91.41%] [G loss: 3.613165]\n",
      "epoch:32 step:25090 [D loss: 0.184280, acc: 96.88%] [G loss: 3.183513]\n",
      "epoch:32 step:25091 [D loss: 0.387879, acc: 90.62%] [G loss: 6.735347]\n",
      "epoch:32 step:25092 [D loss: 0.599639, acc: 69.53%] [G loss: 4.560062]\n",
      "epoch:32 step:25093 [D loss: 0.357677, acc: 93.75%] [G loss: 2.837192]\n",
      "epoch:32 step:25094 [D loss: 0.100981, acc: 99.22%] [G loss: 7.113717]\n",
      "epoch:32 step:25095 [D loss: 0.203236, acc: 95.31%] [G loss: 3.884779]\n",
      "epoch:32 step:25096 [D loss: 0.098163, acc: 100.00%] [G loss: 8.027338]\n",
      "epoch:32 step:25097 [D loss: 0.339579, acc: 90.62%] [G loss: 4.124578]\n",
      "epoch:32 step:25098 [D loss: 0.098064, acc: 100.00%] [G loss: 3.650395]\n",
      "epoch:32 step:25099 [D loss: 0.224877, acc: 96.09%] [G loss: 3.603951]\n",
      "epoch:32 step:25100 [D loss: 0.160977, acc: 99.22%] [G loss: 2.939382]\n",
      "epoch:32 step:25101 [D loss: 0.275841, acc: 92.97%] [G loss: 5.524598]\n",
      "epoch:32 step:25102 [D loss: 0.876108, acc: 36.72%] [G loss: 3.479246]\n",
      "epoch:32 step:25103 [D loss: 0.070295, acc: 100.00%] [G loss: 4.645647]\n",
      "epoch:32 step:25104 [D loss: 0.540969, acc: 70.31%] [G loss: 4.111796]\n",
      "epoch:32 step:25105 [D loss: 0.152385, acc: 97.66%] [G loss: 3.395444]\n",
      "epoch:32 step:25106 [D loss: 0.519095, acc: 78.12%] [G loss: 5.152794]\n",
      "epoch:32 step:25107 [D loss: 0.967017, acc: 32.03%] [G loss: 5.848218]\n",
      "epoch:32 step:25108 [D loss: 0.742333, acc: 55.47%] [G loss: 7.845890]\n",
      "epoch:32 step:25109 [D loss: 0.298006, acc: 90.62%] [G loss: 7.607867]\n",
      "epoch:32 step:25110 [D loss: 0.146682, acc: 100.00%] [G loss: 5.066360]\n",
      "epoch:32 step:25111 [D loss: 0.487580, acc: 81.25%] [G loss: 4.537772]\n",
      "epoch:32 step:25112 [D loss: 0.410184, acc: 77.34%] [G loss: 8.110760]\n",
      "epoch:32 step:25113 [D loss: 0.137797, acc: 99.22%] [G loss: 4.815637]\n",
      "epoch:32 step:25114 [D loss: 0.166881, acc: 97.66%] [G loss: 7.202687]\n",
      "epoch:32 step:25115 [D loss: 0.047090, acc: 100.00%] [G loss: 6.593129]\n",
      "epoch:32 step:25116 [D loss: 0.351772, acc: 89.84%] [G loss: 5.513189]\n",
      "epoch:32 step:25117 [D loss: 0.187555, acc: 96.88%] [G loss: 6.220168]\n",
      "epoch:32 step:25118 [D loss: 0.098457, acc: 100.00%] [G loss: 4.300129]\n",
      "epoch:32 step:25119 [D loss: 1.603837, acc: 5.47%] [G loss: 4.573174]\n",
      "epoch:32 step:25120 [D loss: 0.278093, acc: 86.72%] [G loss: 5.196410]\n",
      "epoch:32 step:25121 [D loss: 0.484018, acc: 76.56%] [G loss: 3.648770]\n",
      "epoch:32 step:25122 [D loss: 1.408095, acc: 50.00%] [G loss: 3.821098]\n",
      "epoch:32 step:25123 [D loss: 0.801130, acc: 53.12%] [G loss: 4.894979]\n",
      "epoch:32 step:25124 [D loss: 0.446555, acc: 82.03%] [G loss: 2.890700]\n",
      "epoch:32 step:25125 [D loss: 0.513631, acc: 78.12%] [G loss: 2.706689]\n",
      "epoch:32 step:25126 [D loss: 0.385503, acc: 89.06%] [G loss: 2.781200]\n",
      "epoch:32 step:25127 [D loss: 0.299646, acc: 85.16%] [G loss: 2.136803]\n",
      "epoch:32 step:25128 [D loss: 0.274154, acc: 92.97%] [G loss: 3.970827]\n",
      "epoch:32 step:25129 [D loss: 0.461109, acc: 72.66%] [G loss: 5.049175]\n",
      "epoch:32 step:25130 [D loss: 0.759724, acc: 54.69%] [G loss: 3.007320]\n",
      "epoch:32 step:25131 [D loss: 0.232113, acc: 95.31%] [G loss: 2.302433]\n",
      "epoch:32 step:25132 [D loss: 0.918525, acc: 39.06%] [G loss: 6.784868]\n",
      "epoch:32 step:25133 [D loss: 0.175564, acc: 98.44%] [G loss: 3.029381]\n",
      "epoch:32 step:25134 [D loss: 0.571665, acc: 67.19%] [G loss: 4.285168]\n",
      "epoch:32 step:25135 [D loss: 0.233817, acc: 94.53%] [G loss: 4.257731]\n",
      "epoch:32 step:25136 [D loss: 1.074439, acc: 23.44%] [G loss: 4.714190]\n",
      "epoch:32 step:25137 [D loss: 0.063777, acc: 100.00%] [G loss: 4.141343]\n",
      "epoch:32 step:25138 [D loss: 0.057405, acc: 100.00%] [G loss: 7.171095]\n",
      "epoch:32 step:25139 [D loss: 0.354913, acc: 89.06%] [G loss: 5.545863]\n",
      "epoch:32 step:25140 [D loss: 0.306755, acc: 85.16%] [G loss: 4.944549]\n",
      "epoch:32 step:25141 [D loss: 0.404225, acc: 75.78%] [G loss: 5.682720]\n",
      "epoch:32 step:25142 [D loss: 0.415195, acc: 88.28%] [G loss: 2.653669]\n",
      "epoch:32 step:25143 [D loss: 0.715985, acc: 51.56%] [G loss: 4.415720]\n",
      "epoch:32 step:25144 [D loss: 0.310040, acc: 90.62%] [G loss: 3.835146]\n",
      "epoch:32 step:25145 [D loss: 0.416567, acc: 85.16%] [G loss: 3.375992]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:32 step:25146 [D loss: 0.277568, acc: 97.66%] [G loss: 3.167804]\n",
      "epoch:32 step:25147 [D loss: 0.217380, acc: 99.22%] [G loss: 4.437895]\n",
      "epoch:32 step:25148 [D loss: 0.218895, acc: 97.66%] [G loss: 4.816033]\n",
      "epoch:32 step:25149 [D loss: 0.097103, acc: 99.22%] [G loss: 7.572670]\n",
      "epoch:32 step:25150 [D loss: 0.111978, acc: 100.00%] [G loss: 4.594767]\n",
      "epoch:32 step:25151 [D loss: 0.660287, acc: 61.72%] [G loss: 5.378706]\n",
      "epoch:32 step:25152 [D loss: 0.167766, acc: 97.66%] [G loss: 4.310587]\n",
      "epoch:32 step:25153 [D loss: 0.130875, acc: 100.00%] [G loss: 6.582530]\n",
      "epoch:32 step:25154 [D loss: 0.265946, acc: 98.44%] [G loss: 4.142731]\n",
      "epoch:32 step:25155 [D loss: 0.434331, acc: 70.31%] [G loss: 5.268450]\n",
      "epoch:32 step:25156 [D loss: 0.174829, acc: 96.88%] [G loss: 4.640613]\n",
      "epoch:32 step:25157 [D loss: 0.092126, acc: 100.00%] [G loss: 3.811880]\n",
      "epoch:32 step:25158 [D loss: 0.885658, acc: 45.31%] [G loss: 5.076758]\n",
      "epoch:32 step:25159 [D loss: 0.344719, acc: 91.41%] [G loss: 1.555187]\n",
      "epoch:32 step:25160 [D loss: 0.497789, acc: 70.31%] [G loss: 5.118801]\n",
      "epoch:32 step:25161 [D loss: 1.130211, acc: 26.56%] [G loss: 3.765780]\n",
      "epoch:32 step:25162 [D loss: 0.978181, acc: 45.31%] [G loss: 3.298993]\n",
      "epoch:32 step:25163 [D loss: 0.210987, acc: 92.97%] [G loss: 3.164380]\n",
      "epoch:32 step:25164 [D loss: 0.520789, acc: 73.44%] [G loss: 6.146207]\n",
      "epoch:32 step:25165 [D loss: 0.852818, acc: 50.78%] [G loss: 5.555375]\n",
      "epoch:32 step:25166 [D loss: 0.264047, acc: 95.31%] [G loss: 5.993019]\n",
      "epoch:32 step:25167 [D loss: 0.014986, acc: 100.00%] [G loss: 5.663972]\n",
      "epoch:32 step:25168 [D loss: 0.363740, acc: 89.06%] [G loss: 5.493302]\n",
      "epoch:32 step:25169 [D loss: 0.238055, acc: 92.97%] [G loss: 4.665534]\n",
      "epoch:32 step:25170 [D loss: 0.417344, acc: 72.66%] [G loss: 5.776309]\n",
      "epoch:32 step:25171 [D loss: 0.848129, acc: 51.56%] [G loss: 4.947232]\n",
      "epoch:32 step:25172 [D loss: 0.076979, acc: 100.00%] [G loss: 5.468938]\n",
      "epoch:32 step:25173 [D loss: 0.230548, acc: 98.44%] [G loss: 4.567982]\n",
      "epoch:32 step:25174 [D loss: 0.187228, acc: 99.22%] [G loss: 4.817187]\n",
      "epoch:32 step:25175 [D loss: 0.748308, acc: 49.22%] [G loss: 6.557936]\n",
      "epoch:32 step:25176 [D loss: 0.156405, acc: 96.88%] [G loss: 6.068659]\n",
      "epoch:32 step:25177 [D loss: 0.365961, acc: 86.72%] [G loss: 2.702222]\n",
      "epoch:32 step:25178 [D loss: 0.167116, acc: 96.09%] [G loss: 6.045084]\n",
      "epoch:32 step:25179 [D loss: 0.104761, acc: 100.00%] [G loss: 5.880570]\n",
      "epoch:32 step:25180 [D loss: 0.926156, acc: 42.19%] [G loss: 7.887737]\n",
      "epoch:32 step:25181 [D loss: 0.052036, acc: 100.00%] [G loss: 5.897464]\n",
      "epoch:32 step:25182 [D loss: 0.256626, acc: 93.75%] [G loss: 5.092715]\n",
      "epoch:32 step:25183 [D loss: 0.045056, acc: 100.00%] [G loss: 4.905254]\n",
      "epoch:32 step:25184 [D loss: 0.629211, acc: 64.06%] [G loss: 6.942139]\n",
      "epoch:32 step:25185 [D loss: 0.115395, acc: 98.44%] [G loss: 6.287230]\n",
      "epoch:32 step:25186 [D loss: 0.318021, acc: 89.06%] [G loss: 8.335613]\n",
      "epoch:32 step:25187 [D loss: 0.120932, acc: 100.00%] [G loss: 6.259418]\n",
      "epoch:32 step:25188 [D loss: 0.081279, acc: 100.00%] [G loss: 4.189311]\n",
      "epoch:32 step:25189 [D loss: 0.279796, acc: 95.31%] [G loss: 5.304856]\n",
      "epoch:32 step:25190 [D loss: 0.489788, acc: 67.19%] [G loss: 5.055671]\n",
      "epoch:32 step:25191 [D loss: 0.432339, acc: 82.03%] [G loss: 5.691528]\n",
      "epoch:32 step:25192 [D loss: 0.406662, acc: 73.44%] [G loss: 4.665153]\n",
      "epoch:32 step:25193 [D loss: 0.256625, acc: 98.44%] [G loss: 3.035018]\n",
      "epoch:32 step:25194 [D loss: 0.226550, acc: 94.53%] [G loss: 4.275848]\n",
      "epoch:32 step:25195 [D loss: 0.253840, acc: 95.31%] [G loss: 4.251987]\n",
      "epoch:32 step:25196 [D loss: 0.642322, acc: 60.16%] [G loss: 5.100503]\n",
      "epoch:32 step:25197 [D loss: 0.171862, acc: 98.44%] [G loss: 3.461223]\n",
      "epoch:32 step:25198 [D loss: 0.624569, acc: 61.72%] [G loss: 7.142754]\n",
      "epoch:32 step:25199 [D loss: 1.030113, acc: 52.34%] [G loss: 7.031825]\n",
      "epoch:32 step:25200 [D loss: 0.220248, acc: 100.00%] [G loss: 4.717844]\n",
      "##############\n",
      "[0.86915826 0.8615274  0.81727637 0.80893415 0.79973508 0.83144057\n",
      " 0.90099223 0.82623235 0.80760067 0.84089684]\n",
      "##########\n",
      "epoch:32 step:25201 [D loss: 0.311669, acc: 95.31%] [G loss: 5.079154]\n",
      "epoch:32 step:25202 [D loss: 0.465960, acc: 82.03%] [G loss: 4.211923]\n",
      "epoch:32 step:25203 [D loss: 0.419454, acc: 79.69%] [G loss: 5.388772]\n",
      "epoch:32 step:25204 [D loss: 0.918292, acc: 51.56%] [G loss: 3.028210]\n",
      "epoch:32 step:25205 [D loss: 0.462068, acc: 84.38%] [G loss: 6.155076]\n",
      "epoch:32 step:25206 [D loss: 0.060339, acc: 100.00%] [G loss: 4.392281]\n",
      "epoch:32 step:25207 [D loss: 0.858781, acc: 41.41%] [G loss: 6.174933]\n",
      "epoch:32 step:25208 [D loss: 0.369200, acc: 88.28%] [G loss: 5.804423]\n",
      "epoch:32 step:25209 [D loss: 0.335586, acc: 93.75%] [G loss: 3.656076]\n",
      "epoch:32 step:25210 [D loss: 0.058401, acc: 100.00%] [G loss: 4.669616]\n",
      "epoch:32 step:25211 [D loss: 0.547959, acc: 66.41%] [G loss: 4.983121]\n",
      "epoch:32 step:25212 [D loss: 1.412141, acc: 50.00%] [G loss: 7.432067]\n",
      "epoch:32 step:25213 [D loss: 0.543759, acc: 69.53%] [G loss: 3.562335]\n",
      "epoch:32 step:25214 [D loss: 1.041942, acc: 50.78%] [G loss: 2.867629]\n",
      "epoch:32 step:25215 [D loss: 0.720899, acc: 50.78%] [G loss: 8.031269]\n",
      "epoch:32 step:25216 [D loss: 0.589515, acc: 64.06%] [G loss: 3.333513]\n",
      "epoch:32 step:25217 [D loss: 0.095041, acc: 100.00%] [G loss: 3.222619]\n",
      "epoch:32 step:25218 [D loss: 0.339466, acc: 85.16%] [G loss: 4.855790]\n",
      "epoch:32 step:25219 [D loss: 0.199715, acc: 96.88%] [G loss: 6.312113]\n",
      "epoch:32 step:25220 [D loss: 0.043042, acc: 100.00%] [G loss: 4.773269]\n",
      "epoch:32 step:25221 [D loss: 0.479187, acc: 79.69%] [G loss: 2.758724]\n",
      "epoch:32 step:25222 [D loss: 0.256813, acc: 86.72%] [G loss: 5.790752]\n",
      "epoch:32 step:25223 [D loss: 0.031635, acc: 100.00%] [G loss: 5.597295]\n",
      "epoch:32 step:25224 [D loss: 0.376228, acc: 75.00%] [G loss: 6.503800]\n",
      "epoch:32 step:25225 [D loss: 0.497663, acc: 64.06%] [G loss: 4.968047]\n",
      "epoch:32 step:25226 [D loss: 0.486106, acc: 75.78%] [G loss: 5.908536]\n",
      "epoch:32 step:25227 [D loss: 0.227866, acc: 94.53%] [G loss: 3.182636]\n",
      "epoch:32 step:25228 [D loss: 0.364905, acc: 92.19%] [G loss: 4.355861]\n",
      "epoch:32 step:25229 [D loss: 0.128753, acc: 100.00%] [G loss: 3.786957]\n",
      "epoch:32 step:25230 [D loss: 0.602043, acc: 65.62%] [G loss: 1.968106]\n",
      "epoch:32 step:25231 [D loss: 0.203869, acc: 97.66%] [G loss: 3.179821]\n",
      "epoch:32 step:25232 [D loss: 0.375856, acc: 80.47%] [G loss: 3.184145]\n",
      "epoch:32 step:25233 [D loss: 0.172412, acc: 99.22%] [G loss: 4.138512]\n",
      "epoch:32 step:25234 [D loss: 0.129002, acc: 99.22%] [G loss: 5.518204]\n",
      "epoch:32 step:25235 [D loss: 0.326701, acc: 85.16%] [G loss: 4.521640]\n",
      "epoch:32 step:25236 [D loss: 0.042355, acc: 99.22%] [G loss: 3.749113]\n",
      "epoch:32 step:25237 [D loss: 0.393372, acc: 85.94%] [G loss: 3.335658]\n",
      "epoch:32 step:25238 [D loss: 0.120526, acc: 100.00%] [G loss: 5.091271]\n",
      "epoch:32 step:25239 [D loss: 0.385540, acc: 83.59%] [G loss: 3.800989]\n",
      "epoch:32 step:25240 [D loss: 1.522312, acc: 38.28%] [G loss: 4.839432]\n",
      "epoch:32 step:25241 [D loss: 0.693343, acc: 54.69%] [G loss: 4.322409]\n",
      "epoch:32 step:25242 [D loss: 0.098490, acc: 100.00%] [G loss: 5.171581]\n",
      "epoch:32 step:25243 [D loss: 0.116982, acc: 99.22%] [G loss: 5.806785]\n",
      "epoch:32 step:25244 [D loss: 0.323173, acc: 81.25%] [G loss: 5.531178]\n",
      "epoch:32 step:25245 [D loss: 1.005530, acc: 48.44%] [G loss: 4.283229]\n",
      "epoch:32 step:25246 [D loss: 0.804201, acc: 56.25%] [G loss: 3.356567]\n",
      "epoch:32 step:25247 [D loss: 0.334462, acc: 85.16%] [G loss: 3.321060]\n",
      "epoch:32 step:25248 [D loss: 0.642623, acc: 67.19%] [G loss: 3.745119]\n",
      "epoch:32 step:25249 [D loss: 0.190177, acc: 96.88%] [G loss: 1.334229]\n",
      "epoch:32 step:25250 [D loss: 0.346362, acc: 91.41%] [G loss: 5.122454]\n",
      "epoch:32 step:25251 [D loss: 0.358752, acc: 79.69%] [G loss: 5.088945]\n",
      "epoch:32 step:25252 [D loss: 1.134611, acc: 49.22%] [G loss: 2.146042]\n",
      "epoch:32 step:25253 [D loss: 0.121290, acc: 100.00%] [G loss: 5.567506]\n",
      "epoch:32 step:25254 [D loss: 0.778883, acc: 50.00%] [G loss: 4.697430]\n",
      "epoch:32 step:25255 [D loss: 0.431392, acc: 71.88%] [G loss: 6.152944]\n",
      "epoch:32 step:25256 [D loss: 0.173780, acc: 96.88%] [G loss: 5.295979]\n",
      "epoch:32 step:25257 [D loss: 0.175511, acc: 99.22%] [G loss: 6.098294]\n",
      "epoch:32 step:25258 [D loss: 0.224980, acc: 93.75%] [G loss: 4.503257]\n",
      "epoch:32 step:25259 [D loss: 1.008240, acc: 42.97%] [G loss: 6.065636]\n",
      "epoch:32 step:25260 [D loss: 1.613580, acc: 50.00%] [G loss: 4.663185]\n",
      "epoch:32 step:25261 [D loss: 0.158610, acc: 98.44%] [G loss: 5.450377]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:32 step:25262 [D loss: 0.119964, acc: 100.00%] [G loss: 3.916350]\n",
      "epoch:32 step:25263 [D loss: 0.059185, acc: 100.00%] [G loss: 5.636123]\n",
      "epoch:32 step:25264 [D loss: 0.354770, acc: 82.81%] [G loss: 3.477105]\n",
      "epoch:32 step:25265 [D loss: 0.234641, acc: 97.66%] [G loss: 4.493285]\n",
      "epoch:32 step:25266 [D loss: 0.438607, acc: 69.53%] [G loss: 4.203486]\n",
      "epoch:32 step:25267 [D loss: 0.413665, acc: 89.06%] [G loss: 5.562873]\n",
      "epoch:32 step:25268 [D loss: 0.292125, acc: 91.41%] [G loss: 3.182543]\n",
      "epoch:32 step:25269 [D loss: 0.081608, acc: 100.00%] [G loss: 6.404190]\n",
      "epoch:32 step:25270 [D loss: 0.168214, acc: 100.00%] [G loss: 3.621884]\n",
      "epoch:32 step:25271 [D loss: 0.758157, acc: 53.12%] [G loss: 3.504612]\n",
      "epoch:32 step:25272 [D loss: 0.232006, acc: 96.88%] [G loss: 3.102607]\n",
      "epoch:32 step:25273 [D loss: 0.591808, acc: 66.41%] [G loss: 5.012034]\n",
      "epoch:32 step:25274 [D loss: 0.434154, acc: 83.59%] [G loss: 5.352792]\n",
      "epoch:32 step:25275 [D loss: 0.236991, acc: 99.22%] [G loss: 4.726454]\n",
      "epoch:32 step:25276 [D loss: 0.505602, acc: 76.56%] [G loss: 4.163356]\n",
      "epoch:32 step:25277 [D loss: 0.265988, acc: 92.19%] [G loss: 4.916730]\n",
      "epoch:32 step:25278 [D loss: 0.519717, acc: 71.88%] [G loss: 3.230903]\n",
      "epoch:32 step:25279 [D loss: 0.746711, acc: 54.69%] [G loss: 7.862601]\n",
      "epoch:32 step:25280 [D loss: 0.122430, acc: 100.00%] [G loss: 6.464998]\n",
      "epoch:32 step:25281 [D loss: 0.960278, acc: 50.78%] [G loss: 7.067552]\n",
      "epoch:32 step:25282 [D loss: 0.197515, acc: 100.00%] [G loss: 4.715227]\n",
      "epoch:32 step:25283 [D loss: 0.383997, acc: 76.56%] [G loss: 5.000976]\n",
      "epoch:32 step:25284 [D loss: 0.179754, acc: 97.66%] [G loss: 5.025134]\n",
      "epoch:32 step:25285 [D loss: 0.107643, acc: 100.00%] [G loss: 5.649106]\n",
      "epoch:32 step:25286 [D loss: 0.202121, acc: 99.22%] [G loss: 5.703594]\n",
      "epoch:32 step:25287 [D loss: 0.799806, acc: 40.62%] [G loss: 2.460089]\n",
      "epoch:32 step:25288 [D loss: 0.183576, acc: 96.88%] [G loss: 3.897746]\n",
      "epoch:32 step:25289 [D loss: 1.349823, acc: 20.31%] [G loss: 5.081909]\n",
      "epoch:32 step:25290 [D loss: 0.277963, acc: 85.16%] [G loss: 3.769318]\n",
      "epoch:32 step:25291 [D loss: 0.041180, acc: 100.00%] [G loss: 4.921542]\n",
      "epoch:32 step:25292 [D loss: 0.276745, acc: 89.84%] [G loss: 3.609461]\n",
      "epoch:32 step:25293 [D loss: 0.788975, acc: 56.25%] [G loss: 5.936516]\n",
      "epoch:32 step:25294 [D loss: 1.058950, acc: 52.34%] [G loss: 5.395351]\n",
      "epoch:32 step:25295 [D loss: 0.799707, acc: 49.22%] [G loss: 3.484251]\n",
      "epoch:32 step:25296 [D loss: 0.196452, acc: 95.31%] [G loss: 3.652006]\n",
      "epoch:32 step:25297 [D loss: 0.121979, acc: 99.22%] [G loss: 4.829498]\n",
      "epoch:32 step:25298 [D loss: 1.259830, acc: 17.97%] [G loss: 5.561239]\n",
      "epoch:32 step:25299 [D loss: 0.171381, acc: 98.44%] [G loss: 3.829215]\n",
      "epoch:32 step:25300 [D loss: 0.586114, acc: 68.75%] [G loss: 2.915303]\n",
      "epoch:32 step:25301 [D loss: 0.755793, acc: 53.12%] [G loss: 3.461327]\n",
      "epoch:32 step:25302 [D loss: 0.303363, acc: 90.62%] [G loss: 5.249967]\n",
      "epoch:32 step:25303 [D loss: 0.878135, acc: 48.44%] [G loss: 4.928917]\n",
      "epoch:32 step:25304 [D loss: 0.088819, acc: 100.00%] [G loss: 3.290570]\n",
      "epoch:32 step:25305 [D loss: 0.693534, acc: 60.16%] [G loss: 6.330317]\n",
      "epoch:32 step:25306 [D loss: 0.270550, acc: 91.41%] [G loss: 3.269959]\n",
      "epoch:32 step:25307 [D loss: 1.358385, acc: 31.25%] [G loss: 5.620988]\n",
      "epoch:32 step:25308 [D loss: 0.378948, acc: 87.50%] [G loss: 3.616860]\n",
      "epoch:32 step:25309 [D loss: 0.448978, acc: 82.03%] [G loss: 3.599395]\n",
      "epoch:32 step:25310 [D loss: 0.531701, acc: 75.00%] [G loss: 3.440387]\n",
      "epoch:32 step:25311 [D loss: 0.091005, acc: 100.00%] [G loss: 4.073187]\n",
      "epoch:32 step:25312 [D loss: 0.688683, acc: 60.16%] [G loss: 5.097197]\n",
      "epoch:32 step:25313 [D loss: 0.197016, acc: 92.97%] [G loss: 5.561409]\n",
      "epoch:32 step:25314 [D loss: 0.220753, acc: 93.75%] [G loss: 5.658080]\n",
      "epoch:32 step:25315 [D loss: 0.079632, acc: 99.22%] [G loss: 4.546308]\n",
      "epoch:32 step:25316 [D loss: 0.376127, acc: 85.94%] [G loss: 4.297261]\n",
      "epoch:32 step:25317 [D loss: 0.353726, acc: 93.75%] [G loss: 3.416839]\n",
      "epoch:32 step:25318 [D loss: 0.021791, acc: 100.00%] [G loss: 3.818072]\n",
      "epoch:32 step:25319 [D loss: 0.258381, acc: 98.44%] [G loss: 2.546018]\n",
      "epoch:32 step:25320 [D loss: 0.319943, acc: 85.94%] [G loss: 4.997332]\n",
      "epoch:32 step:25321 [D loss: 0.442495, acc: 67.97%] [G loss: 5.228769]\n",
      "epoch:32 step:25322 [D loss: 0.192074, acc: 98.44%] [G loss: 4.358297]\n",
      "epoch:32 step:25323 [D loss: 0.212892, acc: 98.44%] [G loss: 4.664814]\n",
      "epoch:32 step:25324 [D loss: 0.162823, acc: 99.22%] [G loss: 3.348519]\n",
      "epoch:32 step:25325 [D loss: 0.093600, acc: 99.22%] [G loss: 3.197837]\n",
      "epoch:32 step:25326 [D loss: 0.840386, acc: 51.56%] [G loss: 2.973796]\n",
      "epoch:32 step:25327 [D loss: 0.016566, acc: 100.00%] [G loss: 7.091559]\n",
      "epoch:32 step:25328 [D loss: 1.001903, acc: 47.66%] [G loss: 5.140271]\n",
      "epoch:32 step:25329 [D loss: 0.112312, acc: 100.00%] [G loss: 4.747194]\n",
      "epoch:32 step:25330 [D loss: 0.208867, acc: 98.44%] [G loss: 4.411665]\n",
      "epoch:32 step:25331 [D loss: 0.768204, acc: 55.47%] [G loss: 4.692812]\n",
      "epoch:32 step:25332 [D loss: 0.259645, acc: 92.19%] [G loss: 4.058713]\n",
      "epoch:32 step:25333 [D loss: 0.128473, acc: 98.44%] [G loss: 3.937654]\n",
      "epoch:32 step:25334 [D loss: 0.121029, acc: 99.22%] [G loss: 3.894539]\n",
      "epoch:32 step:25335 [D loss: 0.211910, acc: 98.44%] [G loss: 4.033488]\n",
      "epoch:32 step:25336 [D loss: 0.229260, acc: 94.53%] [G loss: 4.773493]\n",
      "epoch:32 step:25337 [D loss: 0.332053, acc: 87.50%] [G loss: 4.069965]\n",
      "epoch:32 step:25338 [D loss: 1.710541, acc: 42.97%] [G loss: 5.578794]\n",
      "epoch:32 step:25339 [D loss: 0.109114, acc: 99.22%] [G loss: 3.779720]\n",
      "epoch:32 step:25340 [D loss: 1.108154, acc: 32.03%] [G loss: 4.173550]\n",
      "epoch:32 step:25341 [D loss: 0.315983, acc: 92.19%] [G loss: 6.331682]\n",
      "epoch:32 step:25342 [D loss: 0.496800, acc: 73.44%] [G loss: 2.078464]\n",
      "epoch:32 step:25343 [D loss: 0.080344, acc: 100.00%] [G loss: 7.953142]\n",
      "epoch:32 step:25344 [D loss: 0.280422, acc: 91.41%] [G loss: 4.075663]\n",
      "epoch:32 step:25345 [D loss: 0.226619, acc: 98.44%] [G loss: 3.278152]\n",
      "epoch:32 step:25346 [D loss: 1.515397, acc: 49.22%] [G loss: 5.156717]\n",
      "epoch:32 step:25347 [D loss: 0.749658, acc: 55.47%] [G loss: 5.478824]\n",
      "epoch:32 step:25348 [D loss: 0.437348, acc: 85.16%] [G loss: 6.490744]\n",
      "epoch:32 step:25349 [D loss: 0.238379, acc: 98.44%] [G loss: 4.248271]\n",
      "epoch:32 step:25350 [D loss: 0.160241, acc: 99.22%] [G loss: 5.426490]\n",
      "epoch:32 step:25351 [D loss: 0.320547, acc: 92.19%] [G loss: 4.790874]\n",
      "epoch:32 step:25352 [D loss: 0.098584, acc: 100.00%] [G loss: 5.752420]\n",
      "epoch:32 step:25353 [D loss: 0.264600, acc: 88.28%] [G loss: 5.099305]\n",
      "epoch:32 step:25354 [D loss: 0.199869, acc: 100.00%] [G loss: 5.133033]\n",
      "epoch:32 step:25355 [D loss: 0.308934, acc: 95.31%] [G loss: 4.023260]\n",
      "epoch:32 step:25356 [D loss: 0.546493, acc: 75.00%] [G loss: 4.388741]\n",
      "epoch:32 step:25357 [D loss: 0.380319, acc: 82.81%] [G loss: 4.008735]\n",
      "epoch:32 step:25358 [D loss: 0.226143, acc: 97.66%] [G loss: 3.252014]\n",
      "epoch:32 step:25359 [D loss: 0.738161, acc: 52.34%] [G loss: 2.880851]\n",
      "epoch:32 step:25360 [D loss: 0.383821, acc: 92.97%] [G loss: 2.887660]\n",
      "epoch:32 step:25361 [D loss: 0.639728, acc: 56.25%] [G loss: 4.159186]\n",
      "epoch:32 step:25362 [D loss: 0.485002, acc: 75.78%] [G loss: 4.921116]\n",
      "epoch:32 step:25363 [D loss: 0.196668, acc: 99.22%] [G loss: 7.332641]\n",
      "epoch:32 step:25364 [D loss: 0.318844, acc: 87.50%] [G loss: 2.541391]\n",
      "epoch:32 step:25365 [D loss: 0.387846, acc: 78.91%] [G loss: 5.614804]\n",
      "epoch:32 step:25366 [D loss: 0.342117, acc: 81.25%] [G loss: 5.404209]\n",
      "epoch:32 step:25367 [D loss: 0.147405, acc: 100.00%] [G loss: 4.531321]\n",
      "epoch:32 step:25368 [D loss: 1.009941, acc: 47.66%] [G loss: 3.398397]\n",
      "epoch:32 step:25369 [D loss: 0.768878, acc: 50.00%] [G loss: 2.823258]\n",
      "epoch:32 step:25370 [D loss: 0.159260, acc: 99.22%] [G loss: 6.368840]\n",
      "epoch:32 step:25371 [D loss: 0.604683, acc: 66.41%] [G loss: 5.690982]\n",
      "epoch:32 step:25372 [D loss: 0.302760, acc: 95.31%] [G loss: 2.910046]\n",
      "epoch:32 step:25373 [D loss: 0.307142, acc: 92.19%] [G loss: 2.721409]\n",
      "epoch:32 step:25374 [D loss: 0.823703, acc: 47.66%] [G loss: 3.114526]\n",
      "epoch:32 step:25375 [D loss: 1.400595, acc: 42.97%] [G loss: 4.369813]\n",
      "epoch:32 step:25376 [D loss: 1.094556, acc: 50.78%] [G loss: 4.464953]\n",
      "epoch:32 step:25377 [D loss: 0.345292, acc: 88.28%] [G loss: 5.435833]\n",
      "epoch:32 step:25378 [D loss: 0.430726, acc: 83.59%] [G loss: 2.887445]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:32 step:25379 [D loss: 0.121061, acc: 99.22%] [G loss: 4.968439]\n",
      "epoch:32 step:25380 [D loss: 0.561452, acc: 60.16%] [G loss: 4.080859]\n",
      "epoch:32 step:25381 [D loss: 0.208035, acc: 95.31%] [G loss: 5.929110]\n",
      "epoch:32 step:25382 [D loss: 0.291348, acc: 91.41%] [G loss: 7.411515]\n",
      "epoch:32 step:25383 [D loss: 0.336130, acc: 92.19%] [G loss: 5.973821]\n",
      "epoch:32 step:25384 [D loss: 0.231479, acc: 96.88%] [G loss: 3.877648]\n",
      "epoch:32 step:25385 [D loss: 0.599890, acc: 61.72%] [G loss: 5.725443]\n",
      "epoch:32 step:25386 [D loss: 0.108368, acc: 99.22%] [G loss: 3.151394]\n",
      "epoch:32 step:25387 [D loss: 0.115918, acc: 98.44%] [G loss: 5.327980]\n",
      "epoch:32 step:25388 [D loss: 0.580544, acc: 67.19%] [G loss: 5.012857]\n",
      "epoch:32 step:25389 [D loss: 0.501821, acc: 77.34%] [G loss: 3.283238]\n",
      "epoch:32 step:25390 [D loss: 1.445840, acc: 49.22%] [G loss: 2.788906]\n",
      "epoch:32 step:25391 [D loss: 0.059472, acc: 100.00%] [G loss: 5.134193]\n",
      "epoch:32 step:25392 [D loss: 0.721664, acc: 53.91%] [G loss: 8.398913]\n",
      "epoch:32 step:25393 [D loss: 0.061137, acc: 100.00%] [G loss: 6.162216]\n",
      "epoch:32 step:25394 [D loss: 0.518756, acc: 67.97%] [G loss: 6.638992]\n",
      "epoch:32 step:25395 [D loss: 0.917157, acc: 51.56%] [G loss: 5.461349]\n",
      "epoch:32 step:25396 [D loss: 0.450516, acc: 87.50%] [G loss: 2.591428]\n",
      "epoch:32 step:25397 [D loss: 0.142295, acc: 99.22%] [G loss: 3.807775]\n",
      "epoch:32 step:25398 [D loss: 1.078563, acc: 50.00%] [G loss: 6.465837]\n",
      "epoch:32 step:25399 [D loss: 0.044748, acc: 100.00%] [G loss: 6.014193]\n",
      "epoch:32 step:25400 [D loss: 0.501172, acc: 66.41%] [G loss: 4.692847]\n",
      "##############\n",
      "[0.86390503 0.85589888 0.8089281  0.81492972 0.82130788 0.82700519\n",
      " 0.87976913 0.81836913 0.81677862 0.83781953]\n",
      "##########\n",
      "epoch:32 step:25401 [D loss: 0.273519, acc: 89.06%] [G loss: 2.590431]\n",
      "epoch:32 step:25402 [D loss: 0.257339, acc: 96.09%] [G loss: 6.006576]\n",
      "epoch:32 step:25403 [D loss: 0.492296, acc: 73.44%] [G loss: 4.894102]\n",
      "epoch:32 step:25404 [D loss: 0.834127, acc: 50.78%] [G loss: 6.110018]\n",
      "epoch:32 step:25405 [D loss: 0.761724, acc: 57.03%] [G loss: 5.722596]\n",
      "epoch:32 step:25406 [D loss: 0.102754, acc: 100.00%] [G loss: 6.840161]\n",
      "epoch:32 step:25407 [D loss: 0.080917, acc: 100.00%] [G loss: 4.652000]\n",
      "epoch:32 step:25408 [D loss: 0.273602, acc: 96.88%] [G loss: 4.450826]\n",
      "epoch:32 step:25409 [D loss: 0.931586, acc: 51.56%] [G loss: 6.208335]\n",
      "epoch:32 step:25410 [D loss: 0.517806, acc: 79.69%] [G loss: 3.226025]\n",
      "epoch:32 step:25411 [D loss: 0.145473, acc: 99.22%] [G loss: 6.140945]\n",
      "epoch:32 step:25412 [D loss: 0.152433, acc: 97.66%] [G loss: 2.856858]\n",
      "epoch:32 step:25413 [D loss: 2.016710, acc: 3.91%] [G loss: 4.230677]\n",
      "epoch:32 step:25414 [D loss: 0.375582, acc: 82.81%] [G loss: 3.512626]\n",
      "epoch:32 step:25415 [D loss: 0.973394, acc: 36.72%] [G loss: 4.853768]\n",
      "epoch:32 step:25416 [D loss: 0.602834, acc: 60.94%] [G loss: 4.940627]\n",
      "epoch:32 step:25417 [D loss: 0.835710, acc: 49.22%] [G loss: 3.568856]\n",
      "epoch:32 step:25418 [D loss: 0.125696, acc: 99.22%] [G loss: 5.948529]\n",
      "epoch:32 step:25419 [D loss: 1.544667, acc: 17.19%] [G loss: 2.584687]\n",
      "epoch:32 step:25420 [D loss: 0.194771, acc: 95.31%] [G loss: 4.282204]\n",
      "epoch:32 step:25421 [D loss: 0.347088, acc: 92.19%] [G loss: 3.112111]\n",
      "epoch:32 step:25422 [D loss: 0.544495, acc: 67.97%] [G loss: 2.656096]\n",
      "epoch:32 step:25423 [D loss: 0.862220, acc: 39.84%] [G loss: 2.846671]\n",
      "epoch:32 step:25424 [D loss: 0.674113, acc: 64.84%] [G loss: 4.206683]\n",
      "epoch:32 step:25425 [D loss: 0.694660, acc: 56.25%] [G loss: 2.919049]\n",
      "epoch:32 step:25426 [D loss: 0.024186, acc: 100.00%] [G loss: 5.722544]\n",
      "epoch:32 step:25427 [D loss: 0.046511, acc: 100.00%] [G loss: 3.682131]\n",
      "epoch:32 step:25428 [D loss: 0.316299, acc: 86.72%] [G loss: 4.496421]\n",
      "epoch:32 step:25429 [D loss: 0.286868, acc: 98.44%] [G loss: 5.155803]\n",
      "epoch:32 step:25430 [D loss: 0.082755, acc: 100.00%] [G loss: 6.525149]\n",
      "epoch:32 step:25431 [D loss: 0.452080, acc: 80.47%] [G loss: 2.908145]\n",
      "epoch:32 step:25432 [D loss: 0.694228, acc: 56.25%] [G loss: 6.756143]\n",
      "epoch:32 step:25433 [D loss: 0.419305, acc: 78.12%] [G loss: 6.323655]\n",
      "epoch:32 step:25434 [D loss: 0.389695, acc: 80.47%] [G loss: 3.064956]\n",
      "epoch:32 step:25435 [D loss: 0.837282, acc: 56.25%] [G loss: 5.467927]\n",
      "epoch:32 step:25436 [D loss: 0.115980, acc: 99.22%] [G loss: 5.035411]\n",
      "epoch:32 step:25437 [D loss: 0.707168, acc: 56.25%] [G loss: 6.191908]\n",
      "epoch:32 step:25438 [D loss: 0.217041, acc: 96.88%] [G loss: 4.027635]\n",
      "epoch:32 step:25439 [D loss: 0.354572, acc: 82.81%] [G loss: 5.408787]\n",
      "epoch:32 step:25440 [D loss: 0.200864, acc: 96.88%] [G loss: 3.096048]\n",
      "epoch:32 step:25441 [D loss: 0.066486, acc: 100.00%] [G loss: 4.196890]\n",
      "epoch:32 step:25442 [D loss: 0.362192, acc: 89.06%] [G loss: 3.763503]\n",
      "epoch:32 step:25443 [D loss: 0.388962, acc: 90.62%] [G loss: 4.026721]\n",
      "epoch:32 step:25444 [D loss: 0.236660, acc: 96.09%] [G loss: 4.244394]\n",
      "epoch:32 step:25445 [D loss: 0.997869, acc: 50.78%] [G loss: 5.180719]\n",
      "epoch:32 step:25446 [D loss: 0.074555, acc: 100.00%] [G loss: 4.747411]\n",
      "epoch:32 step:25447 [D loss: 0.181879, acc: 96.09%] [G loss: 5.743605]\n",
      "epoch:32 step:25448 [D loss: 1.348274, acc: 48.44%] [G loss: 5.555869]\n",
      "epoch:32 step:25449 [D loss: 0.676754, acc: 52.34%] [G loss: 5.194156]\n",
      "epoch:32 step:25450 [D loss: 0.110060, acc: 99.22%] [G loss: 4.860890]\n",
      "epoch:32 step:25451 [D loss: 0.307207, acc: 93.75%] [G loss: 7.158162]\n",
      "epoch:32 step:25452 [D loss: 0.521661, acc: 71.09%] [G loss: 5.068194]\n",
      "epoch:32 step:25453 [D loss: 0.016201, acc: 100.00%] [G loss: 10.068124]\n",
      "epoch:32 step:25454 [D loss: 0.905057, acc: 51.56%] [G loss: 4.631873]\n",
      "epoch:32 step:25455 [D loss: 0.481723, acc: 69.53%] [G loss: 5.965281]\n",
      "epoch:32 step:25456 [D loss: 0.752460, acc: 54.69%] [G loss: 5.905927]\n",
      "epoch:32 step:25457 [D loss: 0.894233, acc: 49.22%] [G loss: 5.687542]\n",
      "epoch:32 step:25458 [D loss: 0.441123, acc: 70.31%] [G loss: 5.324636]\n",
      "epoch:32 step:25459 [D loss: 0.271516, acc: 96.88%] [G loss: 3.298172]\n",
      "epoch:32 step:25460 [D loss: 0.096020, acc: 100.00%] [G loss: 3.172956]\n",
      "epoch:32 step:25461 [D loss: 0.406133, acc: 81.25%] [G loss: 4.950457]\n",
      "epoch:32 step:25462 [D loss: 0.041407, acc: 100.00%] [G loss: 5.103212]\n",
      "epoch:32 step:25463 [D loss: 0.385101, acc: 84.38%] [G loss: 3.660031]\n",
      "epoch:32 step:25464 [D loss: 0.178978, acc: 98.44%] [G loss: 2.441746]\n",
      "epoch:32 step:25465 [D loss: 0.582818, acc: 67.97%] [G loss: 3.919514]\n",
      "epoch:32 step:25466 [D loss: 0.317254, acc: 95.31%] [G loss: 3.026082]\n",
      "epoch:32 step:25467 [D loss: 0.802477, acc: 51.56%] [G loss: 4.195119]\n",
      "epoch:32 step:25468 [D loss: 0.338555, acc: 82.81%] [G loss: 3.747138]\n",
      "epoch:32 step:25469 [D loss: 0.156699, acc: 99.22%] [G loss: 3.137998]\n",
      "epoch:32 step:25470 [D loss: 0.109105, acc: 99.22%] [G loss: 6.650022]\n",
      "epoch:32 step:25471 [D loss: 0.574864, acc: 67.19%] [G loss: 3.375443]\n",
      "epoch:32 step:25472 [D loss: 0.144183, acc: 100.00%] [G loss: 3.201687]\n",
      "epoch:32 step:25473 [D loss: 0.412358, acc: 89.84%] [G loss: 2.310518]\n",
      "epoch:32 step:25474 [D loss: 0.659369, acc: 62.50%] [G loss: 5.347133]\n",
      "epoch:32 step:25475 [D loss: 0.550090, acc: 63.28%] [G loss: 2.825925]\n",
      "epoch:32 step:25476 [D loss: 1.004226, acc: 51.56%] [G loss: 6.168780]\n",
      "epoch:32 step:25477 [D loss: 0.448517, acc: 71.88%] [G loss: 4.416982]\n",
      "epoch:32 step:25478 [D loss: 0.761366, acc: 52.34%] [G loss: 4.223659]\n",
      "epoch:32 step:25479 [D loss: 0.266925, acc: 93.75%] [G loss: 3.282487]\n",
      "epoch:32 step:25480 [D loss: 0.768708, acc: 53.12%] [G loss: 5.778689]\n",
      "epoch:32 step:25481 [D loss: 0.258229, acc: 91.41%] [G loss: 3.808231]\n",
      "epoch:32 step:25482 [D loss: 0.017157, acc: 100.00%] [G loss: 6.639090]\n",
      "epoch:32 step:25483 [D loss: 0.539553, acc: 75.00%] [G loss: 3.535672]\n",
      "epoch:32 step:25484 [D loss: 0.125988, acc: 100.00%] [G loss: 3.182782]\n",
      "epoch:32 step:25485 [D loss: 0.237271, acc: 97.66%] [G loss: 3.958841]\n",
      "epoch:32 step:25486 [D loss: 0.183815, acc: 95.31%] [G loss: 4.442488]\n",
      "epoch:32 step:25487 [D loss: 0.699890, acc: 53.91%] [G loss: 4.486952]\n",
      "epoch:32 step:25488 [D loss: 0.466995, acc: 73.44%] [G loss: 4.774483]\n",
      "epoch:32 step:25489 [D loss: 0.372473, acc: 91.41%] [G loss: 6.095927]\n",
      "epoch:32 step:25490 [D loss: 0.297239, acc: 94.53%] [G loss: 6.751937]\n",
      "epoch:32 step:25491 [D loss: 0.613143, acc: 57.81%] [G loss: 2.049340]\n",
      "epoch:32 step:25492 [D loss: 1.249103, acc: 19.53%] [G loss: 4.740350]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:32 step:25493 [D loss: 0.283428, acc: 96.09%] [G loss: 4.046135]\n",
      "epoch:32 step:25494 [D loss: 1.235101, acc: 34.38%] [G loss: 4.810822]\n",
      "epoch:32 step:25495 [D loss: 0.306184, acc: 91.41%] [G loss: 4.982921]\n",
      "epoch:32 step:25496 [D loss: 0.084434, acc: 100.00%] [G loss: 5.654683]\n",
      "epoch:32 step:25497 [D loss: 0.583395, acc: 67.97%] [G loss: 4.459557]\n",
      "epoch:32 step:25498 [D loss: 0.180531, acc: 100.00%] [G loss: 3.129525]\n",
      "epoch:32 step:25499 [D loss: 0.522892, acc: 71.09%] [G loss: 4.512005]\n",
      "epoch:32 step:25500 [D loss: 0.379978, acc: 77.34%] [G loss: 4.881921]\n",
      "epoch:32 step:25501 [D loss: 0.303367, acc: 89.84%] [G loss: 3.135954]\n",
      "epoch:32 step:25502 [D loss: 0.365549, acc: 82.03%] [G loss: 2.748682]\n",
      "epoch:32 step:25503 [D loss: 0.074489, acc: 99.22%] [G loss: 7.837811]\n",
      "epoch:32 step:25504 [D loss: 0.038862, acc: 100.00%] [G loss: 5.525678]\n",
      "epoch:32 step:25505 [D loss: 0.670927, acc: 66.41%] [G loss: 4.447478]\n",
      "epoch:32 step:25506 [D loss: 0.096419, acc: 100.00%] [G loss: 8.080060]\n",
      "epoch:32 step:25507 [D loss: 0.811778, acc: 45.31%] [G loss: 3.606596]\n",
      "epoch:32 step:25508 [D loss: 0.278133, acc: 91.41%] [G loss: 3.187647]\n",
      "epoch:32 step:25509 [D loss: 0.145862, acc: 98.44%] [G loss: 5.877488]\n",
      "epoch:32 step:25510 [D loss: 0.321950, acc: 95.31%] [G loss: 4.242172]\n",
      "epoch:32 step:25511 [D loss: 0.895855, acc: 36.72%] [G loss: 3.606968]\n",
      "epoch:32 step:25512 [D loss: 0.475764, acc: 74.22%] [G loss: 4.957902]\n",
      "epoch:32 step:25513 [D loss: 0.342157, acc: 89.06%] [G loss: 6.178887]\n",
      "epoch:32 step:25514 [D loss: 0.771437, acc: 49.22%] [G loss: 3.010747]\n",
      "epoch:32 step:25515 [D loss: 0.755865, acc: 52.34%] [G loss: 5.477577]\n",
      "epoch:32 step:25516 [D loss: 0.280360, acc: 92.19%] [G loss: 3.380891]\n",
      "epoch:32 step:25517 [D loss: 0.509472, acc: 66.41%] [G loss: 6.708682]\n",
      "epoch:32 step:25518 [D loss: 0.686705, acc: 57.81%] [G loss: 4.610849]\n",
      "epoch:32 step:25519 [D loss: 1.066728, acc: 50.78%] [G loss: 5.270575]\n",
      "epoch:32 step:25520 [D loss: 0.135810, acc: 99.22%] [G loss: 5.325202]\n",
      "epoch:32 step:25521 [D loss: 0.314978, acc: 85.94%] [G loss: 4.503594]\n",
      "epoch:32 step:25522 [D loss: 0.448405, acc: 78.91%] [G loss: 4.486085]\n",
      "epoch:32 step:25523 [D loss: 0.397665, acc: 80.47%] [G loss: 4.390505]\n",
      "epoch:32 step:25524 [D loss: 0.742116, acc: 52.34%] [G loss: 4.309395]\n",
      "epoch:32 step:25525 [D loss: 0.309681, acc: 88.28%] [G loss: 5.087057]\n",
      "epoch:32 step:25526 [D loss: 1.072536, acc: 35.16%] [G loss: 2.559880]\n",
      "epoch:32 step:25527 [D loss: 0.342767, acc: 81.25%] [G loss: 4.641448]\n",
      "epoch:32 step:25528 [D loss: 0.231370, acc: 97.66%] [G loss: 3.654191]\n",
      "epoch:32 step:25529 [D loss: 0.299683, acc: 88.28%] [G loss: 4.994140]\n",
      "epoch:32 step:25530 [D loss: 0.119896, acc: 100.00%] [G loss: 2.476797]\n",
      "epoch:32 step:25531 [D loss: 0.166773, acc: 99.22%] [G loss: 3.391629]\n",
      "epoch:32 step:25532 [D loss: 1.860150, acc: 36.72%] [G loss: 4.261923]\n",
      "epoch:32 step:25533 [D loss: 0.167298, acc: 99.22%] [G loss: 6.475060]\n",
      "epoch:32 step:25534 [D loss: 0.126658, acc: 100.00%] [G loss: 6.168633]\n",
      "epoch:32 step:25535 [D loss: 0.140526, acc: 99.22%] [G loss: 4.011851]\n",
      "epoch:32 step:25536 [D loss: 0.358773, acc: 82.03%] [G loss: 2.858572]\n",
      "epoch:32 step:25537 [D loss: 0.279862, acc: 92.97%] [G loss: 3.743609]\n",
      "epoch:32 step:25538 [D loss: 0.130278, acc: 100.00%] [G loss: 2.942708]\n",
      "epoch:32 step:25539 [D loss: 0.418429, acc: 74.22%] [G loss: 5.460474]\n",
      "epoch:32 step:25540 [D loss: 0.325137, acc: 86.72%] [G loss: 5.871672]\n",
      "epoch:32 step:25541 [D loss: 0.663592, acc: 60.16%] [G loss: 4.140329]\n",
      "epoch:32 step:25542 [D loss: 0.295031, acc: 86.72%] [G loss: 6.062328]\n",
      "epoch:32 step:25543 [D loss: 0.508215, acc: 71.88%] [G loss: 4.610082]\n",
      "epoch:32 step:25544 [D loss: 0.743334, acc: 56.25%] [G loss: 4.665121]\n",
      "epoch:32 step:25545 [D loss: 0.900248, acc: 39.06%] [G loss: 7.164503]\n",
      "epoch:32 step:25546 [D loss: 0.086940, acc: 100.00%] [G loss: 3.745440]\n",
      "epoch:32 step:25547 [D loss: 0.206385, acc: 92.19%] [G loss: 3.510064]\n",
      "epoch:32 step:25548 [D loss: 0.870752, acc: 50.78%] [G loss: 5.295113]\n",
      "epoch:32 step:25549 [D loss: 0.361045, acc: 85.16%] [G loss: 4.194573]\n",
      "epoch:32 step:25550 [D loss: 0.071590, acc: 100.00%] [G loss: 3.185736]\n",
      "epoch:32 step:25551 [D loss: 0.201877, acc: 97.66%] [G loss: 6.699008]\n",
      "epoch:32 step:25552 [D loss: 0.097504, acc: 100.00%] [G loss: 5.404012]\n",
      "epoch:32 step:25553 [D loss: 1.319468, acc: 14.06%] [G loss: 6.939486]\n",
      "epoch:32 step:25554 [D loss: 0.440425, acc: 85.16%] [G loss: 4.376050]\n",
      "epoch:32 step:25555 [D loss: 0.283095, acc: 90.62%] [G loss: 4.463964]\n",
      "epoch:32 step:25556 [D loss: 0.296077, acc: 91.41%] [G loss: 3.678633]\n",
      "epoch:32 step:25557 [D loss: 0.342084, acc: 94.53%] [G loss: 5.289515]\n",
      "epoch:32 step:25558 [D loss: 0.388848, acc: 79.69%] [G loss: 5.600018]\n",
      "epoch:32 step:25559 [D loss: 0.170678, acc: 98.44%] [G loss: 4.678910]\n",
      "epoch:32 step:25560 [D loss: 0.285963, acc: 87.50%] [G loss: 4.534697]\n",
      "epoch:32 step:25561 [D loss: 0.340591, acc: 89.06%] [G loss: 4.188113]\n",
      "epoch:32 step:25562 [D loss: 0.571828, acc: 69.53%] [G loss: 5.827427]\n",
      "epoch:32 step:25563 [D loss: 0.587158, acc: 57.81%] [G loss: 5.084000]\n",
      "epoch:32 step:25564 [D loss: 0.204228, acc: 98.44%] [G loss: 5.089746]\n",
      "epoch:32 step:25565 [D loss: 0.977164, acc: 42.19%] [G loss: 4.872066]\n",
      "epoch:32 step:25566 [D loss: 0.622060, acc: 68.75%] [G loss: 2.405093]\n",
      "epoch:32 step:25567 [D loss: 0.750615, acc: 52.34%] [G loss: 3.298189]\n",
      "epoch:32 step:25568 [D loss: 1.335838, acc: 26.56%] [G loss: 4.911585]\n",
      "epoch:32 step:25569 [D loss: 0.306626, acc: 92.97%] [G loss: 3.655530]\n",
      "epoch:32 step:25570 [D loss: 0.794195, acc: 53.91%] [G loss: 5.303211]\n",
      "epoch:32 step:25571 [D loss: 0.144697, acc: 100.00%] [G loss: 6.159164]\n",
      "epoch:32 step:25572 [D loss: 0.143301, acc: 99.22%] [G loss: 6.955219]\n",
      "epoch:32 step:25573 [D loss: 0.229888, acc: 99.22%] [G loss: 5.679847]\n",
      "epoch:32 step:25574 [D loss: 0.261624, acc: 89.84%] [G loss: 3.778068]\n",
      "epoch:32 step:25575 [D loss: 0.341949, acc: 82.03%] [G loss: 4.091064]\n",
      "epoch:32 step:25576 [D loss: 0.504739, acc: 80.47%] [G loss: 4.215257]\n",
      "epoch:32 step:25577 [D loss: 0.210531, acc: 99.22%] [G loss: 3.045145]\n",
      "epoch:32 step:25578 [D loss: 0.305346, acc: 89.06%] [G loss: 1.929611]\n",
      "epoch:32 step:25579 [D loss: 0.497019, acc: 67.19%] [G loss: 6.286792]\n",
      "epoch:32 step:25580 [D loss: 0.207806, acc: 100.00%] [G loss: 6.701255]\n",
      "epoch:32 step:25581 [D loss: 0.156558, acc: 99.22%] [G loss: 5.060616]\n",
      "epoch:32 step:25582 [D loss: 0.133350, acc: 100.00%] [G loss: 3.817297]\n",
      "epoch:32 step:25583 [D loss: 1.398465, acc: 50.00%] [G loss: 2.534107]\n",
      "epoch:32 step:25584 [D loss: 0.383538, acc: 89.06%] [G loss: 2.958410]\n",
      "epoch:32 step:25585 [D loss: 0.259561, acc: 90.62%] [G loss: 3.826931]\n",
      "epoch:32 step:25586 [D loss: 0.429868, acc: 74.22%] [G loss: 4.716848]\n",
      "epoch:32 step:25587 [D loss: 0.206225, acc: 96.09%] [G loss: 4.493837]\n",
      "epoch:32 step:25588 [D loss: 0.843680, acc: 46.09%] [G loss: 5.259048]\n",
      "epoch:32 step:25589 [D loss: 0.452434, acc: 82.03%] [G loss: 3.613583]\n",
      "epoch:32 step:25590 [D loss: 0.147686, acc: 98.44%] [G loss: 4.586520]\n",
      "epoch:32 step:25591 [D loss: 0.951632, acc: 50.78%] [G loss: 3.293628]\n",
      "epoch:32 step:25592 [D loss: 1.130234, acc: 44.53%] [G loss: 4.646139]\n",
      "epoch:32 step:25593 [D loss: 0.098041, acc: 99.22%] [G loss: 3.709613]\n",
      "epoch:32 step:25594 [D loss: 0.115493, acc: 100.00%] [G loss: 6.029541]\n",
      "epoch:32 step:25595 [D loss: 0.502134, acc: 71.88%] [G loss: 4.670912]\n",
      "epoch:32 step:25596 [D loss: 0.510276, acc: 70.31%] [G loss: 3.157656]\n",
      "epoch:32 step:25597 [D loss: 0.258356, acc: 96.09%] [G loss: 2.860199]\n",
      "epoch:32 step:25598 [D loss: 0.266307, acc: 96.88%] [G loss: 3.529079]\n",
      "epoch:32 step:25599 [D loss: 0.831346, acc: 49.22%] [G loss: 4.133955]\n",
      "epoch:32 step:25600 [D loss: 0.246494, acc: 94.53%] [G loss: 2.620484]\n",
      "##############\n",
      "[0.84691895 0.85840727 0.82815941 0.82500338 0.77727418 0.82849534\n",
      " 0.89726207 0.83570803 0.83508637 0.82907676]\n",
      "##########\n",
      "epoch:32 step:25601 [D loss: 0.090505, acc: 99.22%] [G loss: 5.527957]\n",
      "epoch:32 step:25602 [D loss: 0.548677, acc: 73.44%] [G loss: 2.906053]\n",
      "epoch:32 step:25603 [D loss: 0.302414, acc: 94.53%] [G loss: 1.635468]\n",
      "epoch:32 step:25604 [D loss: 1.175130, acc: 34.38%] [G loss: 5.098400]\n",
      "epoch:32 step:25605 [D loss: 0.162086, acc: 96.88%] [G loss: 4.969673]\n",
      "epoch:32 step:25606 [D loss: 0.214377, acc: 93.75%] [G loss: 4.044759]\n",
      "epoch:32 step:25607 [D loss: 0.183727, acc: 97.66%] [G loss: 4.384850]\n",
      "epoch:32 step:25608 [D loss: 0.444061, acc: 70.31%] [G loss: 3.714313]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:32 step:25609 [D loss: 0.221919, acc: 97.66%] [G loss: 4.022645]\n",
      "epoch:32 step:25610 [D loss: 0.327445, acc: 93.75%] [G loss: 5.021721]\n",
      "epoch:32 step:25611 [D loss: 0.868616, acc: 53.91%] [G loss: 5.087522]\n",
      "epoch:32 step:25612 [D loss: 0.255571, acc: 94.53%] [G loss: 5.357470]\n",
      "epoch:32 step:25613 [D loss: 0.898201, acc: 48.44%] [G loss: 4.507304]\n",
      "epoch:32 step:25614 [D loss: 0.247059, acc: 94.53%] [G loss: 4.357873]\n",
      "epoch:32 step:25615 [D loss: 0.080310, acc: 100.00%] [G loss: 5.347917]\n",
      "epoch:32 step:25616 [D loss: 0.450176, acc: 82.81%] [G loss: 6.184188]\n",
      "epoch:32 step:25617 [D loss: 0.068930, acc: 100.00%] [G loss: 3.820788]\n",
      "epoch:32 step:25618 [D loss: 0.250630, acc: 94.53%] [G loss: 5.238559]\n",
      "epoch:32 step:25619 [D loss: 1.307684, acc: 33.59%] [G loss: 3.653522]\n",
      "epoch:32 step:25620 [D loss: 0.141225, acc: 98.44%] [G loss: 6.169155]\n",
      "epoch:32 step:25621 [D loss: 0.450446, acc: 72.66%] [G loss: 5.566913]\n",
      "epoch:32 step:25622 [D loss: 0.180922, acc: 97.66%] [G loss: 5.400760]\n",
      "epoch:32 step:25623 [D loss: 0.213770, acc: 95.31%] [G loss: 5.244174]\n",
      "epoch:32 step:25624 [D loss: 0.544885, acc: 66.41%] [G loss: 2.531001]\n",
      "epoch:32 step:25625 [D loss: 0.153427, acc: 100.00%] [G loss: 3.821217]\n",
      "epoch:32 step:25626 [D loss: 0.331246, acc: 93.75%] [G loss: 4.316430]\n",
      "epoch:32 step:25627 [D loss: 0.212560, acc: 97.66%] [G loss: 2.554774]\n",
      "epoch:32 step:25628 [D loss: 1.037091, acc: 50.00%] [G loss: 4.332079]\n",
      "epoch:32 step:25629 [D loss: 0.491887, acc: 67.19%] [G loss: 3.835744]\n",
      "epoch:32 step:25630 [D loss: 0.370842, acc: 83.59%] [G loss: 4.393281]\n",
      "epoch:32 step:25631 [D loss: 0.305251, acc: 90.62%] [G loss: 6.613481]\n",
      "epoch:32 step:25632 [D loss: 0.750714, acc: 53.12%] [G loss: 4.145537]\n",
      "epoch:32 step:25633 [D loss: 0.068707, acc: 100.00%] [G loss: 4.836345]\n",
      "epoch:32 step:25634 [D loss: 0.244633, acc: 92.97%] [G loss: 5.115614]\n",
      "epoch:32 step:25635 [D loss: 0.373690, acc: 89.84%] [G loss: 2.943474]\n",
      "epoch:32 step:25636 [D loss: 0.566690, acc: 69.53%] [G loss: 3.138220]\n",
      "epoch:32 step:25637 [D loss: 0.281789, acc: 86.72%] [G loss: 7.562906]\n",
      "epoch:32 step:25638 [D loss: 0.706945, acc: 61.72%] [G loss: 3.764358]\n",
      "epoch:32 step:25639 [D loss: 1.019622, acc: 50.00%] [G loss: 1.327222]\n",
      "epoch:32 step:25640 [D loss: 0.146793, acc: 98.44%] [G loss: 5.229894]\n",
      "epoch:32 step:25641 [D loss: 0.489505, acc: 70.31%] [G loss: 4.065726]\n",
      "epoch:32 step:25642 [D loss: 0.703442, acc: 53.12%] [G loss: 5.067860]\n",
      "epoch:32 step:25643 [D loss: 0.209211, acc: 94.53%] [G loss: 5.274310]\n",
      "epoch:32 step:25644 [D loss: 0.521040, acc: 64.84%] [G loss: 5.596333]\n",
      "epoch:32 step:25645 [D loss: 0.102582, acc: 98.44%] [G loss: 6.278546]\n",
      "epoch:32 step:25646 [D loss: 0.131589, acc: 99.22%] [G loss: 2.793845]\n",
      "epoch:32 step:25647 [D loss: 0.097156, acc: 100.00%] [G loss: 5.610647]\n",
      "epoch:32 step:25648 [D loss: 0.703139, acc: 56.25%] [G loss: 5.419765]\n",
      "epoch:32 step:25649 [D loss: 0.713492, acc: 55.47%] [G loss: 4.786725]\n",
      "epoch:32 step:25650 [D loss: 0.520167, acc: 75.78%] [G loss: 4.969228]\n",
      "epoch:32 step:25651 [D loss: 0.113838, acc: 100.00%] [G loss: 3.595069]\n",
      "epoch:32 step:25652 [D loss: 0.571293, acc: 72.66%] [G loss: 5.717233]\n",
      "epoch:32 step:25653 [D loss: 0.274245, acc: 96.09%] [G loss: 4.269248]\n",
      "epoch:32 step:25654 [D loss: 0.314354, acc: 92.97%] [G loss: 4.847263]\n",
      "epoch:32 step:25655 [D loss: 0.353308, acc: 93.75%] [G loss: 4.943315]\n",
      "epoch:32 step:25656 [D loss: 0.091784, acc: 98.44%] [G loss: 6.092470]\n",
      "epoch:32 step:25657 [D loss: 0.521399, acc: 71.88%] [G loss: 3.945952]\n",
      "epoch:32 step:25658 [D loss: 0.970389, acc: 31.25%] [G loss: 4.542425]\n",
      "epoch:32 step:25659 [D loss: 0.156246, acc: 98.44%] [G loss: 7.501481]\n",
      "epoch:32 step:25660 [D loss: 0.301183, acc: 87.50%] [G loss: 3.213288]\n",
      "epoch:32 step:25661 [D loss: 0.429677, acc: 79.69%] [G loss: 4.001263]\n",
      "epoch:32 step:25662 [D loss: 0.579199, acc: 65.62%] [G loss: 4.368268]\n",
      "epoch:32 step:25663 [D loss: 0.123378, acc: 98.44%] [G loss: 4.801795]\n",
      "epoch:32 step:25664 [D loss: 0.233852, acc: 98.44%] [G loss: 4.108099]\n",
      "epoch:32 step:25665 [D loss: 0.317805, acc: 87.50%] [G loss: 4.452256]\n",
      "epoch:32 step:25666 [D loss: 0.105275, acc: 99.22%] [G loss: 4.503350]\n",
      "epoch:32 step:25667 [D loss: 0.145659, acc: 100.00%] [G loss: 2.809780]\n",
      "epoch:32 step:25668 [D loss: 0.174704, acc: 96.09%] [G loss: 3.672490]\n",
      "epoch:32 step:25669 [D loss: 0.094417, acc: 98.44%] [G loss: 5.059415]\n",
      "epoch:32 step:25670 [D loss: 0.074438, acc: 100.00%] [G loss: 4.829233]\n",
      "epoch:32 step:25671 [D loss: 0.657524, acc: 55.47%] [G loss: 7.516204]\n",
      "epoch:32 step:25672 [D loss: 0.364714, acc: 88.28%] [G loss: 6.703107]\n",
      "epoch:32 step:25673 [D loss: 0.271755, acc: 93.75%] [G loss: 4.306331]\n",
      "epoch:32 step:25674 [D loss: 0.332700, acc: 91.41%] [G loss: 2.656376]\n",
      "epoch:32 step:25675 [D loss: 0.199354, acc: 96.09%] [G loss: 5.776251]\n",
      "epoch:32 step:25676 [D loss: 0.364247, acc: 91.41%] [G loss: 5.152650]\n",
      "epoch:32 step:25677 [D loss: 0.134432, acc: 99.22%] [G loss: 6.205222]\n",
      "epoch:32 step:25678 [D loss: 0.315884, acc: 92.97%] [G loss: 6.452064]\n",
      "epoch:32 step:25679 [D loss: 0.441544, acc: 75.00%] [G loss: 4.156618]\n",
      "epoch:32 step:25680 [D loss: 0.069381, acc: 100.00%] [G loss: 4.636687]\n",
      "epoch:32 step:25681 [D loss: 0.560432, acc: 71.09%] [G loss: 4.723874]\n",
      "epoch:32 step:25682 [D loss: 0.137871, acc: 99.22%] [G loss: 6.519649]\n",
      "epoch:32 step:25683 [D loss: 0.391745, acc: 82.81%] [G loss: 9.860147]\n",
      "epoch:32 step:25684 [D loss: 0.224706, acc: 98.44%] [G loss: 4.020761]\n",
      "epoch:32 step:25685 [D loss: 0.978663, acc: 39.06%] [G loss: 4.858719]\n",
      "epoch:32 step:25686 [D loss: 0.360429, acc: 87.50%] [G loss: 5.210856]\n",
      "epoch:32 step:25687 [D loss: 0.299426, acc: 88.28%] [G loss: 5.615433]\n",
      "epoch:32 step:25688 [D loss: 0.111295, acc: 98.44%] [G loss: 6.007085]\n",
      "epoch:32 step:25689 [D loss: 0.264111, acc: 89.06%] [G loss: 4.513672]\n",
      "epoch:32 step:25690 [D loss: 0.145584, acc: 100.00%] [G loss: 2.496647]\n",
      "epoch:32 step:25691 [D loss: 0.376609, acc: 86.72%] [G loss: 3.336919]\n",
      "epoch:32 step:25692 [D loss: 0.766260, acc: 47.66%] [G loss: 2.914835]\n",
      "epoch:32 step:25693 [D loss: 0.271446, acc: 96.09%] [G loss: 5.044281]\n",
      "epoch:32 step:25694 [D loss: 0.550041, acc: 69.53%] [G loss: 5.168192]\n",
      "epoch:32 step:25695 [D loss: 0.611843, acc: 69.53%] [G loss: 5.441500]\n",
      "epoch:32 step:25696 [D loss: 0.106110, acc: 100.00%] [G loss: 6.590997]\n",
      "epoch:32 step:25697 [D loss: 0.472060, acc: 78.12%] [G loss: 5.214243]\n",
      "epoch:32 step:25698 [D loss: 0.212312, acc: 97.66%] [G loss: 5.370955]\n",
      "epoch:32 step:25699 [D loss: 0.526110, acc: 74.22%] [G loss: 4.225493]\n",
      "epoch:32 step:25700 [D loss: 0.239327, acc: 95.31%] [G loss: 2.462819]\n",
      "epoch:32 step:25701 [D loss: 0.710945, acc: 58.59%] [G loss: 4.289497]\n",
      "epoch:32 step:25702 [D loss: 1.940389, acc: 9.38%] [G loss: 4.007731]\n",
      "epoch:32 step:25703 [D loss: 0.023191, acc: 100.00%] [G loss: 6.995559]\n",
      "epoch:32 step:25704 [D loss: 0.317571, acc: 83.59%] [G loss: 4.820397]\n",
      "epoch:32 step:25705 [D loss: 0.086415, acc: 100.00%] [G loss: 4.787628]\n",
      "epoch:32 step:25706 [D loss: 0.157814, acc: 100.00%] [G loss: 5.071499]\n",
      "epoch:32 step:25707 [D loss: 0.502116, acc: 71.88%] [G loss: 4.714195]\n",
      "epoch:32 step:25708 [D loss: 0.091549, acc: 100.00%] [G loss: 7.318439]\n",
      "epoch:32 step:25709 [D loss: 0.101419, acc: 99.22%] [G loss: 6.133717]\n",
      "epoch:32 step:25710 [D loss: 0.162837, acc: 99.22%] [G loss: 7.465133]\n",
      "epoch:32 step:25711 [D loss: 0.314705, acc: 92.97%] [G loss: 6.355480]\n",
      "epoch:32 step:25712 [D loss: 0.157894, acc: 98.44%] [G loss: 2.775427]\n",
      "epoch:32 step:25713 [D loss: 0.128933, acc: 98.44%] [G loss: 3.346329]\n",
      "epoch:32 step:25714 [D loss: 0.494766, acc: 64.84%] [G loss: 3.802953]\n",
      "epoch:32 step:25715 [D loss: 0.111132, acc: 99.22%] [G loss: 4.152059]\n",
      "epoch:32 step:25716 [D loss: 0.216795, acc: 95.31%] [G loss: 4.793614]\n",
      "epoch:32 step:25717 [D loss: 0.396868, acc: 75.78%] [G loss: 5.208593]\n",
      "epoch:32 step:25718 [D loss: 0.839031, acc: 51.56%] [G loss: 4.699286]\n",
      "epoch:32 step:25719 [D loss: 0.070898, acc: 100.00%] [G loss: 5.811075]\n",
      "epoch:32 step:25720 [D loss: 0.646521, acc: 57.81%] [G loss: 4.229940]\n",
      "epoch:32 step:25721 [D loss: 0.178986, acc: 97.66%] [G loss: 3.211473]\n",
      "epoch:32 step:25722 [D loss: 0.277964, acc: 93.75%] [G loss: 3.345742]\n",
      "epoch:32 step:25723 [D loss: 0.608243, acc: 65.62%] [G loss: 4.151275]\n",
      "epoch:32 step:25724 [D loss: 0.398193, acc: 85.94%] [G loss: 4.328317]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:32 step:25725 [D loss: 0.664656, acc: 58.59%] [G loss: 5.602976]\n",
      "epoch:32 step:25726 [D loss: 0.671746, acc: 58.59%] [G loss: 3.539835]\n",
      "epoch:32 step:25727 [D loss: 0.137319, acc: 99.22%] [G loss: 4.581980]\n",
      "epoch:32 step:25728 [D loss: 0.264675, acc: 88.28%] [G loss: 6.384647]\n",
      "epoch:32 step:25729 [D loss: 0.454766, acc: 87.50%] [G loss: 6.160231]\n",
      "epoch:32 step:25730 [D loss: 0.210451, acc: 93.75%] [G loss: 5.925735]\n",
      "epoch:32 step:25731 [D loss: 0.346672, acc: 88.28%] [G loss: 5.410759]\n",
      "epoch:32 step:25732 [D loss: 0.282327, acc: 96.88%] [G loss: 7.327596]\n",
      "epoch:32 step:25733 [D loss: 0.241609, acc: 94.53%] [G loss: 5.887502]\n",
      "epoch:32 step:25734 [D loss: 0.322472, acc: 88.28%] [G loss: 6.493817]\n",
      "epoch:32 step:25735 [D loss: 0.996838, acc: 29.69%] [G loss: 5.253486]\n",
      "epoch:32 step:25736 [D loss: 0.080521, acc: 100.00%] [G loss: 3.461957]\n",
      "epoch:32 step:25737 [D loss: 0.110302, acc: 100.00%] [G loss: 3.588242]\n",
      "epoch:32 step:25738 [D loss: 0.675769, acc: 65.62%] [G loss: 6.397837]\n",
      "epoch:32 step:25739 [D loss: 0.470996, acc: 78.12%] [G loss: 3.717644]\n",
      "epoch:32 step:25740 [D loss: 0.311900, acc: 92.19%] [G loss: 4.552195]\n",
      "epoch:32 step:25741 [D loss: 0.543144, acc: 67.97%] [G loss: 5.413884]\n",
      "epoch:32 step:25742 [D loss: 0.423208, acc: 78.91%] [G loss: 5.347608]\n",
      "epoch:32 step:25743 [D loss: 0.537831, acc: 74.22%] [G loss: 5.062520]\n",
      "epoch:32 step:25744 [D loss: 1.312971, acc: 38.28%] [G loss: 3.945473]\n",
      "epoch:32 step:25745 [D loss: 0.265303, acc: 88.28%] [G loss: 7.100084]\n",
      "epoch:32 step:25746 [D loss: 0.122475, acc: 97.66%] [G loss: 2.731140]\n",
      "epoch:32 step:25747 [D loss: 0.207110, acc: 98.44%] [G loss: 4.562372]\n",
      "epoch:32 step:25748 [D loss: 0.248419, acc: 95.31%] [G loss: 2.150272]\n",
      "epoch:32 step:25749 [D loss: 0.167045, acc: 100.00%] [G loss: 4.881542]\n",
      "epoch:32 step:25750 [D loss: 0.531469, acc: 67.19%] [G loss: 3.922185]\n",
      "epoch:32 step:25751 [D loss: 0.675918, acc: 57.81%] [G loss: 2.936919]\n",
      "epoch:32 step:25752 [D loss: 0.021951, acc: 100.00%] [G loss: 9.846769]\n",
      "epoch:32 step:25753 [D loss: 0.219254, acc: 96.09%] [G loss: 4.429761]\n",
      "epoch:32 step:25754 [D loss: 0.080406, acc: 100.00%] [G loss: 3.790710]\n",
      "epoch:32 step:25755 [D loss: 0.342099, acc: 92.97%] [G loss: 4.170402]\n",
      "epoch:32 step:25756 [D loss: 0.157764, acc: 99.22%] [G loss: 6.392933]\n",
      "epoch:32 step:25757 [D loss: 0.360989, acc: 81.25%] [G loss: 7.018041]\n",
      "epoch:32 step:25758 [D loss: 0.170938, acc: 98.44%] [G loss: 2.719340]\n",
      "epoch:32 step:25759 [D loss: 0.044471, acc: 100.00%] [G loss: 4.539586]\n",
      "epoch:32 step:25760 [D loss: 0.577962, acc: 71.09%] [G loss: 4.530593]\n",
      "epoch:32 step:25761 [D loss: 1.170772, acc: 50.00%] [G loss: 6.448590]\n",
      "epoch:32 step:25762 [D loss: 0.626885, acc: 58.59%] [G loss: 6.234133]\n",
      "epoch:32 step:25763 [D loss: 0.316695, acc: 92.97%] [G loss: 5.819115]\n",
      "epoch:32 step:25764 [D loss: 0.187082, acc: 96.88%] [G loss: 5.511096]\n",
      "epoch:32 step:25765 [D loss: 0.165724, acc: 96.09%] [G loss: 8.580548]\n",
      "epoch:32 step:25766 [D loss: 0.388413, acc: 87.50%] [G loss: 2.933220]\n",
      "epoch:32 step:25767 [D loss: 0.925806, acc: 40.62%] [G loss: 3.602638]\n",
      "epoch:32 step:25768 [D loss: 0.737632, acc: 53.12%] [G loss: 7.451084]\n",
      "epoch:32 step:25769 [D loss: 1.042317, acc: 19.53%] [G loss: 3.455374]\n",
      "epoch:32 step:25770 [D loss: 0.200859, acc: 96.09%] [G loss: 7.315573]\n",
      "epoch:32 step:25771 [D loss: 0.277459, acc: 89.84%] [G loss: 6.629726]\n",
      "epoch:32 step:25772 [D loss: 0.196435, acc: 98.44%] [G loss: 6.070043]\n",
      "epoch:32 step:25773 [D loss: 0.086137, acc: 98.44%] [G loss: 3.749090]\n",
      "epoch:33 step:25774 [D loss: 0.391946, acc: 85.94%] [G loss: 5.099307]\n",
      "epoch:33 step:25775 [D loss: 0.033671, acc: 100.00%] [G loss: 4.410944]\n",
      "epoch:33 step:25776 [D loss: 0.649755, acc: 63.28%] [G loss: 3.847172]\n",
      "epoch:33 step:25777 [D loss: 0.351293, acc: 82.81%] [G loss: 5.866194]\n",
      "epoch:33 step:25778 [D loss: 0.809058, acc: 50.78%] [G loss: 4.811871]\n",
      "epoch:33 step:25779 [D loss: 0.565094, acc: 63.28%] [G loss: 8.120147]\n",
      "epoch:33 step:25780 [D loss: 0.422530, acc: 84.38%] [G loss: 3.698333]\n",
      "epoch:33 step:25781 [D loss: 0.499720, acc: 73.44%] [G loss: 6.931329]\n",
      "epoch:33 step:25782 [D loss: 0.735945, acc: 50.00%] [G loss: 6.775642]\n",
      "epoch:33 step:25783 [D loss: 0.379329, acc: 81.25%] [G loss: 3.628057]\n",
      "epoch:33 step:25784 [D loss: 0.261170, acc: 93.75%] [G loss: 6.575104]\n",
      "epoch:33 step:25785 [D loss: 0.136247, acc: 98.44%] [G loss: 4.780838]\n",
      "epoch:33 step:25786 [D loss: 0.339871, acc: 87.50%] [G loss: 3.612033]\n",
      "epoch:33 step:25787 [D loss: 1.192419, acc: 49.22%] [G loss: 4.786560]\n",
      "epoch:33 step:25788 [D loss: 0.662806, acc: 56.25%] [G loss: 7.100518]\n",
      "epoch:33 step:25789 [D loss: 0.169361, acc: 95.31%] [G loss: 4.612381]\n",
      "epoch:33 step:25790 [D loss: 0.200891, acc: 96.88%] [G loss: 5.887729]\n",
      "epoch:33 step:25791 [D loss: 0.429515, acc: 86.72%] [G loss: 6.438152]\n",
      "epoch:33 step:25792 [D loss: 0.849952, acc: 36.72%] [G loss: 4.402328]\n",
      "epoch:33 step:25793 [D loss: 0.856938, acc: 50.78%] [G loss: 4.376193]\n",
      "epoch:33 step:25794 [D loss: 0.372103, acc: 81.25%] [G loss: 4.830601]\n",
      "epoch:33 step:25795 [D loss: 0.107843, acc: 100.00%] [G loss: 5.792825]\n",
      "epoch:33 step:25796 [D loss: 0.516493, acc: 68.75%] [G loss: 4.920445]\n",
      "epoch:33 step:25797 [D loss: 0.394098, acc: 83.59%] [G loss: 6.679768]\n",
      "epoch:33 step:25798 [D loss: 0.583366, acc: 71.09%] [G loss: 4.458923]\n",
      "epoch:33 step:25799 [D loss: 0.727392, acc: 56.25%] [G loss: 5.229183]\n",
      "epoch:33 step:25800 [D loss: 0.523933, acc: 78.12%] [G loss: 3.831926]\n",
      "##############\n",
      "[0.86578204 0.85111723 0.82806939 0.79099633 0.78845462 0.81477173\n",
      " 0.89046791 0.82744768 0.7987005  0.84000403]\n",
      "##########\n",
      "epoch:33 step:25801 [D loss: 0.361530, acc: 83.59%] [G loss: 5.023945]\n",
      "epoch:33 step:25802 [D loss: 0.116260, acc: 100.00%] [G loss: 2.878609]\n",
      "epoch:33 step:25803 [D loss: 0.045133, acc: 100.00%] [G loss: 9.755657]\n",
      "epoch:33 step:25804 [D loss: 0.262813, acc: 93.75%] [G loss: 9.237663]\n",
      "epoch:33 step:25805 [D loss: 0.175308, acc: 100.00%] [G loss: 7.127815]\n",
      "epoch:33 step:25806 [D loss: 0.622970, acc: 65.62%] [G loss: 4.119516]\n",
      "epoch:33 step:25807 [D loss: 0.276978, acc: 94.53%] [G loss: 4.066086]\n",
      "epoch:33 step:25808 [D loss: 0.447164, acc: 82.81%] [G loss: 2.195692]\n",
      "epoch:33 step:25809 [D loss: 0.125715, acc: 99.22%] [G loss: 4.933553]\n",
      "epoch:33 step:25810 [D loss: 0.422510, acc: 72.66%] [G loss: 5.117090]\n",
      "epoch:33 step:25811 [D loss: 0.173319, acc: 93.75%] [G loss: 4.943061]\n",
      "epoch:33 step:25812 [D loss: 0.337849, acc: 82.81%] [G loss: 5.180896]\n",
      "epoch:33 step:25813 [D loss: 0.094435, acc: 100.00%] [G loss: 5.379258]\n",
      "epoch:33 step:25814 [D loss: 0.290080, acc: 92.97%] [G loss: 4.792633]\n",
      "epoch:33 step:25815 [D loss: 0.147521, acc: 98.44%] [G loss: 4.972383]\n",
      "epoch:33 step:25816 [D loss: 0.200467, acc: 93.75%] [G loss: 3.928675]\n",
      "epoch:33 step:25817 [D loss: 0.306366, acc: 92.97%] [G loss: 3.258881]\n",
      "epoch:33 step:25818 [D loss: 0.133324, acc: 99.22%] [G loss: 6.156909]\n",
      "epoch:33 step:25819 [D loss: 0.057263, acc: 100.00%] [G loss: 3.310322]\n",
      "epoch:33 step:25820 [D loss: 1.114119, acc: 21.88%] [G loss: 4.221605]\n",
      "epoch:33 step:25821 [D loss: 0.346434, acc: 85.94%] [G loss: 5.036434]\n",
      "epoch:33 step:25822 [D loss: 0.965291, acc: 50.00%] [G loss: 3.736279]\n",
      "epoch:33 step:25823 [D loss: 0.420292, acc: 77.34%] [G loss: 4.431359]\n",
      "epoch:33 step:25824 [D loss: 0.336924, acc: 87.50%] [G loss: 4.014764]\n",
      "epoch:33 step:25825 [D loss: 0.655105, acc: 56.25%] [G loss: 4.814400]\n",
      "epoch:33 step:25826 [D loss: 0.414798, acc: 82.81%] [G loss: 2.762804]\n",
      "epoch:33 step:25827 [D loss: 0.241144, acc: 97.66%] [G loss: 3.091711]\n",
      "epoch:33 step:25828 [D loss: 0.035361, acc: 100.00%] [G loss: 4.916004]\n",
      "epoch:33 step:25829 [D loss: 0.403046, acc: 77.34%] [G loss: 4.950114]\n",
      "epoch:33 step:25830 [D loss: 0.352932, acc: 92.19%] [G loss: 5.496961]\n",
      "epoch:33 step:25831 [D loss: 0.090786, acc: 100.00%] [G loss: 6.170902]\n",
      "epoch:33 step:25832 [D loss: 0.379151, acc: 86.72%] [G loss: 4.391072]\n",
      "epoch:33 step:25833 [D loss: 0.216401, acc: 96.09%] [G loss: 4.578404]\n",
      "epoch:33 step:25834 [D loss: 0.052575, acc: 100.00%] [G loss: 3.137244]\n",
      "epoch:33 step:25835 [D loss: 0.407992, acc: 85.16%] [G loss: 6.871499]\n",
      "epoch:33 step:25836 [D loss: 0.165835, acc: 97.66%] [G loss: 5.452800]\n",
      "epoch:33 step:25837 [D loss: 0.567374, acc: 70.31%] [G loss: 4.407674]\n",
      "epoch:33 step:25838 [D loss: 0.250923, acc: 92.97%] [G loss: 5.653114]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:33 step:25839 [D loss: 0.405495, acc: 81.25%] [G loss: 4.230953]\n",
      "epoch:33 step:25840 [D loss: 0.513363, acc: 78.12%] [G loss: 4.116018]\n",
      "epoch:33 step:25841 [D loss: 0.919336, acc: 42.19%] [G loss: 2.185824]\n",
      "epoch:33 step:25842 [D loss: 0.145027, acc: 97.66%] [G loss: 3.952291]\n",
      "epoch:33 step:25843 [D loss: 0.120048, acc: 100.00%] [G loss: 4.958692]\n",
      "epoch:33 step:25844 [D loss: 0.935808, acc: 52.34%] [G loss: 7.175177]\n",
      "epoch:33 step:25845 [D loss: 0.388402, acc: 78.91%] [G loss: 2.680806]\n",
      "epoch:33 step:25846 [D loss: 1.155201, acc: 50.00%] [G loss: 3.299767]\n",
      "epoch:33 step:25847 [D loss: 0.199614, acc: 97.66%] [G loss: 2.836286]\n",
      "epoch:33 step:25848 [D loss: 0.801570, acc: 53.91%] [G loss: 3.338689]\n",
      "epoch:33 step:25849 [D loss: 0.268328, acc: 93.75%] [G loss: 7.578904]\n",
      "epoch:33 step:25850 [D loss: 0.195396, acc: 97.66%] [G loss: 2.407984]\n",
      "epoch:33 step:25851 [D loss: 0.512853, acc: 78.12%] [G loss: 4.274030]\n",
      "epoch:33 step:25852 [D loss: 1.055420, acc: 35.94%] [G loss: 4.779294]\n",
      "epoch:33 step:25853 [D loss: 0.472766, acc: 75.78%] [G loss: 5.505555]\n",
      "epoch:33 step:25854 [D loss: 0.996844, acc: 43.75%] [G loss: 5.323410]\n",
      "epoch:33 step:25855 [D loss: 0.161373, acc: 100.00%] [G loss: 2.968233]\n",
      "epoch:33 step:25856 [D loss: 0.130791, acc: 99.22%] [G loss: 4.411326]\n",
      "epoch:33 step:25857 [D loss: 0.809222, acc: 54.69%] [G loss: 4.507361]\n",
      "epoch:33 step:25858 [D loss: 0.924604, acc: 50.00%] [G loss: 5.890391]\n",
      "epoch:33 step:25859 [D loss: 0.935805, acc: 34.38%] [G loss: 3.544998]\n",
      "epoch:33 step:25860 [D loss: 0.562765, acc: 66.41%] [G loss: 3.750921]\n",
      "epoch:33 step:25861 [D loss: 0.416624, acc: 73.44%] [G loss: 3.574259]\n",
      "epoch:33 step:25862 [D loss: 0.213860, acc: 93.75%] [G loss: 5.642164]\n",
      "epoch:33 step:25863 [D loss: 0.072037, acc: 100.00%] [G loss: 5.568359]\n",
      "epoch:33 step:25864 [D loss: 0.044826, acc: 100.00%] [G loss: 5.653088]\n",
      "epoch:33 step:25865 [D loss: 0.080593, acc: 99.22%] [G loss: 5.907712]\n",
      "epoch:33 step:25866 [D loss: 0.654649, acc: 60.16%] [G loss: 3.980912]\n",
      "epoch:33 step:25867 [D loss: 0.716639, acc: 60.16%] [G loss: 4.999321]\n",
      "epoch:33 step:25868 [D loss: 0.197305, acc: 96.09%] [G loss: 2.883339]\n",
      "epoch:33 step:25869 [D loss: 0.197757, acc: 95.31%] [G loss: 6.958200]\n",
      "epoch:33 step:25870 [D loss: 1.392846, acc: 10.94%] [G loss: 5.389510]\n",
      "epoch:33 step:25871 [D loss: 0.247150, acc: 95.31%] [G loss: 4.950248]\n",
      "epoch:33 step:25872 [D loss: 0.127416, acc: 99.22%] [G loss: 4.057914]\n",
      "epoch:33 step:25873 [D loss: 0.080317, acc: 99.22%] [G loss: 2.240625]\n",
      "epoch:33 step:25874 [D loss: 1.299308, acc: 41.41%] [G loss: 4.090390]\n",
      "epoch:33 step:25875 [D loss: 0.269166, acc: 92.19%] [G loss: 4.717965]\n",
      "epoch:33 step:25876 [D loss: 0.062936, acc: 100.00%] [G loss: 6.414760]\n",
      "epoch:33 step:25877 [D loss: 0.656537, acc: 52.34%] [G loss: 4.449738]\n",
      "epoch:33 step:25878 [D loss: 0.465170, acc: 68.75%] [G loss: 6.076596]\n",
      "epoch:33 step:25879 [D loss: 0.831144, acc: 52.34%] [G loss: 4.207283]\n",
      "epoch:33 step:25880 [D loss: 0.299156, acc: 83.59%] [G loss: 5.159479]\n",
      "epoch:33 step:25881 [D loss: 0.614549, acc: 55.47%] [G loss: 6.900601]\n",
      "epoch:33 step:25882 [D loss: 1.584876, acc: 50.00%] [G loss: 4.748642]\n",
      "epoch:33 step:25883 [D loss: 0.076549, acc: 100.00%] [G loss: 4.450646]\n",
      "epoch:33 step:25884 [D loss: 0.300624, acc: 95.31%] [G loss: 3.084353]\n",
      "epoch:33 step:25885 [D loss: 0.160915, acc: 99.22%] [G loss: 5.583821]\n",
      "epoch:33 step:25886 [D loss: 0.169906, acc: 99.22%] [G loss: 4.210070]\n",
      "epoch:33 step:25887 [D loss: 0.118476, acc: 99.22%] [G loss: 6.958135]\n",
      "epoch:33 step:25888 [D loss: 0.363549, acc: 85.94%] [G loss: 2.935297]\n",
      "epoch:33 step:25889 [D loss: 0.221405, acc: 96.88%] [G loss: 3.903631]\n",
      "epoch:33 step:25890 [D loss: 0.424495, acc: 87.50%] [G loss: 4.442496]\n",
      "epoch:33 step:25891 [D loss: 0.065020, acc: 99.22%] [G loss: 5.518075]\n",
      "epoch:33 step:25892 [D loss: 0.096849, acc: 98.44%] [G loss: 6.237342]\n",
      "epoch:33 step:25893 [D loss: 0.329476, acc: 82.03%] [G loss: 5.318969]\n",
      "epoch:33 step:25894 [D loss: 0.296389, acc: 93.75%] [G loss: 4.144464]\n",
      "epoch:33 step:25895 [D loss: 0.115954, acc: 98.44%] [G loss: 6.345357]\n",
      "epoch:33 step:25896 [D loss: 0.242382, acc: 99.22%] [G loss: 5.482863]\n",
      "epoch:33 step:25897 [D loss: 0.771866, acc: 56.25%] [G loss: 7.079727]\n",
      "epoch:33 step:25898 [D loss: 1.181025, acc: 31.25%] [G loss: 5.268039]\n",
      "epoch:33 step:25899 [D loss: 0.086933, acc: 100.00%] [G loss: 5.528803]\n",
      "epoch:33 step:25900 [D loss: 0.466353, acc: 74.22%] [G loss: 2.434690]\n",
      "epoch:33 step:25901 [D loss: 0.602950, acc: 67.97%] [G loss: 4.067781]\n",
      "epoch:33 step:25902 [D loss: 0.260951, acc: 96.09%] [G loss: 3.686498]\n",
      "epoch:33 step:25903 [D loss: 1.266243, acc: 48.44%] [G loss: 7.186358]\n",
      "epoch:33 step:25904 [D loss: 0.671047, acc: 56.25%] [G loss: 2.033945]\n",
      "epoch:33 step:25905 [D loss: 0.608027, acc: 65.62%] [G loss: 5.567643]\n",
      "epoch:33 step:25906 [D loss: 0.167618, acc: 97.66%] [G loss: 5.549930]\n",
      "epoch:33 step:25907 [D loss: 0.248980, acc: 90.62%] [G loss: 4.272357]\n",
      "epoch:33 step:25908 [D loss: 0.070624, acc: 100.00%] [G loss: 3.961177]\n",
      "epoch:33 step:25909 [D loss: 0.144607, acc: 100.00%] [G loss: 4.429572]\n",
      "epoch:33 step:25910 [D loss: 0.144933, acc: 99.22%] [G loss: 5.893003]\n",
      "epoch:33 step:25911 [D loss: 0.190204, acc: 100.00%] [G loss: 4.838525]\n",
      "epoch:33 step:25912 [D loss: 0.515537, acc: 83.59%] [G loss: 4.212144]\n",
      "epoch:33 step:25913 [D loss: 0.155295, acc: 98.44%] [G loss: 4.560219]\n",
      "epoch:33 step:25914 [D loss: 0.673425, acc: 60.16%] [G loss: 3.477178]\n",
      "epoch:33 step:25915 [D loss: 0.454282, acc: 83.59%] [G loss: 5.691156]\n",
      "epoch:33 step:25916 [D loss: 0.237944, acc: 90.62%] [G loss: 4.009321]\n",
      "epoch:33 step:25917 [D loss: 0.229797, acc: 97.66%] [G loss: 4.324448]\n",
      "epoch:33 step:25918 [D loss: 0.825196, acc: 52.34%] [G loss: 5.786022]\n",
      "epoch:33 step:25919 [D loss: 0.185064, acc: 97.66%] [G loss: 3.276644]\n",
      "epoch:33 step:25920 [D loss: 0.355734, acc: 90.62%] [G loss: 2.786675]\n",
      "epoch:33 step:25921 [D loss: 0.087567, acc: 100.00%] [G loss: 7.675389]\n",
      "epoch:33 step:25922 [D loss: 0.389241, acc: 81.25%] [G loss: 6.633298]\n",
      "epoch:33 step:25923 [D loss: 0.823960, acc: 49.22%] [G loss: 5.724698]\n",
      "epoch:33 step:25924 [D loss: 0.196979, acc: 98.44%] [G loss: 3.448274]\n",
      "epoch:33 step:25925 [D loss: 1.426685, acc: 39.84%] [G loss: 4.793546]\n",
      "epoch:33 step:25926 [D loss: 0.066653, acc: 100.00%] [G loss: 6.513430]\n",
      "epoch:33 step:25927 [D loss: 0.026135, acc: 100.00%] [G loss: 6.008767]\n",
      "epoch:33 step:25928 [D loss: 0.112237, acc: 100.00%] [G loss: 2.569186]\n",
      "epoch:33 step:25929 [D loss: 0.119394, acc: 100.00%] [G loss: 6.001639]\n",
      "epoch:33 step:25930 [D loss: 0.695213, acc: 54.69%] [G loss: 6.191502]\n",
      "epoch:33 step:25931 [D loss: 0.145520, acc: 97.66%] [G loss: 7.110699]\n",
      "epoch:33 step:25932 [D loss: 0.491116, acc: 75.00%] [G loss: 6.663433]\n",
      "epoch:33 step:25933 [D loss: 0.523977, acc: 77.34%] [G loss: 5.400539]\n",
      "epoch:33 step:25934 [D loss: 0.276502, acc: 90.62%] [G loss: 6.054722]\n",
      "epoch:33 step:25935 [D loss: 0.104688, acc: 100.00%] [G loss: 3.001700]\n",
      "epoch:33 step:25936 [D loss: 0.106079, acc: 98.44%] [G loss: 5.705147]\n",
      "epoch:33 step:25937 [D loss: 0.371265, acc: 84.38%] [G loss: 5.143022]\n",
      "epoch:33 step:25938 [D loss: 0.292204, acc: 91.41%] [G loss: 4.341595]\n",
      "epoch:33 step:25939 [D loss: 0.236334, acc: 92.97%] [G loss: 5.642991]\n",
      "epoch:33 step:25940 [D loss: 0.842063, acc: 52.34%] [G loss: 4.560801]\n",
      "epoch:33 step:25941 [D loss: 0.449440, acc: 75.78%] [G loss: 3.887759]\n",
      "epoch:33 step:25942 [D loss: 0.406641, acc: 72.66%] [G loss: 3.801101]\n",
      "epoch:33 step:25943 [D loss: 0.609339, acc: 67.19%] [G loss: 5.305227]\n",
      "epoch:33 step:25944 [D loss: 0.417810, acc: 85.94%] [G loss: 3.718337]\n",
      "epoch:33 step:25945 [D loss: 0.538231, acc: 77.34%] [G loss: 2.884796]\n",
      "epoch:33 step:25946 [D loss: 1.180985, acc: 25.00%] [G loss: 3.541820]\n",
      "epoch:33 step:25947 [D loss: 0.137368, acc: 99.22%] [G loss: 5.595908]\n",
      "epoch:33 step:25948 [D loss: 0.152413, acc: 100.00%] [G loss: 7.343189]\n",
      "epoch:33 step:25949 [D loss: 0.599013, acc: 57.81%] [G loss: 8.409388]\n",
      "epoch:33 step:25950 [D loss: 0.693633, acc: 55.47%] [G loss: 5.513888]\n",
      "epoch:33 step:25951 [D loss: 0.185058, acc: 98.44%] [G loss: 3.598816]\n",
      "epoch:33 step:25952 [D loss: 0.045127, acc: 100.00%] [G loss: 3.933223]\n",
      "epoch:33 step:25953 [D loss: 0.373464, acc: 77.34%] [G loss: 4.727040]\n",
      "epoch:33 step:25954 [D loss: 0.391926, acc: 89.84%] [G loss: 4.524234]\n",
      "epoch:33 step:25955 [D loss: 0.678085, acc: 57.03%] [G loss: 4.691248]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:33 step:25956 [D loss: 0.489312, acc: 83.59%] [G loss: 4.769983]\n",
      "epoch:33 step:25957 [D loss: 0.313082, acc: 85.16%] [G loss: 3.096444]\n",
      "epoch:33 step:25958 [D loss: 0.054791, acc: 100.00%] [G loss: 3.537160]\n",
      "epoch:33 step:25959 [D loss: 0.089767, acc: 99.22%] [G loss: 5.678262]\n",
      "epoch:33 step:25960 [D loss: 0.461868, acc: 78.12%] [G loss: 4.246743]\n",
      "epoch:33 step:25961 [D loss: 0.174369, acc: 98.44%] [G loss: 5.459723]\n",
      "epoch:33 step:25962 [D loss: 0.050327, acc: 100.00%] [G loss: 6.019429]\n",
      "epoch:33 step:25963 [D loss: 0.124457, acc: 100.00%] [G loss: 5.264627]\n",
      "epoch:33 step:25964 [D loss: 0.547618, acc: 71.09%] [G loss: 4.399055]\n",
      "epoch:33 step:25965 [D loss: 0.230348, acc: 96.88%] [G loss: 4.592882]\n",
      "epoch:33 step:25966 [D loss: 0.173251, acc: 98.44%] [G loss: 2.999354]\n",
      "epoch:33 step:25967 [D loss: 0.199354, acc: 96.09%] [G loss: 6.848745]\n",
      "epoch:33 step:25968 [D loss: 0.760946, acc: 52.34%] [G loss: 4.704756]\n",
      "epoch:33 step:25969 [D loss: 0.106930, acc: 100.00%] [G loss: 7.241648]\n",
      "epoch:33 step:25970 [D loss: 0.206808, acc: 96.88%] [G loss: 2.847920]\n",
      "epoch:33 step:25971 [D loss: 0.050205, acc: 100.00%] [G loss: 2.394368]\n",
      "epoch:33 step:25972 [D loss: 0.269702, acc: 99.22%] [G loss: 2.911269]\n",
      "epoch:33 step:25973 [D loss: 0.059192, acc: 100.00%] [G loss: 4.246256]\n",
      "epoch:33 step:25974 [D loss: 0.135932, acc: 100.00%] [G loss: 3.333418]\n",
      "epoch:33 step:25975 [D loss: 1.344877, acc: 3.91%] [G loss: 4.996473]\n",
      "epoch:33 step:25976 [D loss: 0.839233, acc: 46.88%] [G loss: 4.461540]\n",
      "epoch:33 step:25977 [D loss: 0.963831, acc: 31.25%] [G loss: 5.741788]\n",
      "epoch:33 step:25978 [D loss: 0.088473, acc: 99.22%] [G loss: 4.337446]\n",
      "epoch:33 step:25979 [D loss: 0.092500, acc: 100.00%] [G loss: 5.222794]\n",
      "epoch:33 step:25980 [D loss: 0.217779, acc: 95.31%] [G loss: 6.496146]\n",
      "epoch:33 step:25981 [D loss: 0.553999, acc: 60.94%] [G loss: 5.518071]\n",
      "epoch:33 step:25982 [D loss: 0.240722, acc: 94.53%] [G loss: 3.565221]\n",
      "epoch:33 step:25983 [D loss: 0.492900, acc: 83.59%] [G loss: 4.099996]\n",
      "epoch:33 step:25984 [D loss: 0.044880, acc: 100.00%] [G loss: 5.313990]\n",
      "epoch:33 step:25985 [D loss: 0.032434, acc: 100.00%] [G loss: 4.514019]\n",
      "epoch:33 step:25986 [D loss: 0.256437, acc: 98.44%] [G loss: 2.884452]\n",
      "epoch:33 step:25987 [D loss: 0.133138, acc: 98.44%] [G loss: 4.769500]\n",
      "epoch:33 step:25988 [D loss: 1.157146, acc: 48.44%] [G loss: 3.901257]\n",
      "epoch:33 step:25989 [D loss: 0.642538, acc: 61.72%] [G loss: 7.204019]\n",
      "epoch:33 step:25990 [D loss: 0.415932, acc: 74.22%] [G loss: 5.106622]\n",
      "epoch:33 step:25991 [D loss: 0.159909, acc: 98.44%] [G loss: 4.904404]\n",
      "epoch:33 step:25992 [D loss: 0.519712, acc: 66.41%] [G loss: 6.099451]\n",
      "epoch:33 step:25993 [D loss: 0.354029, acc: 84.38%] [G loss: 4.465548]\n",
      "epoch:33 step:25994 [D loss: 0.773247, acc: 52.34%] [G loss: 8.613200]\n",
      "epoch:33 step:25995 [D loss: 0.169728, acc: 96.88%] [G loss: 6.293104]\n",
      "epoch:33 step:25996 [D loss: 0.485351, acc: 62.50%] [G loss: 4.765950]\n",
      "epoch:33 step:25997 [D loss: 0.158159, acc: 100.00%] [G loss: 7.238251]\n",
      "epoch:33 step:25998 [D loss: 0.872667, acc: 42.19%] [G loss: 5.532683]\n",
      "epoch:33 step:25999 [D loss: 0.053254, acc: 100.00%] [G loss: 4.124304]\n",
      "epoch:33 step:26000 [D loss: 0.075540, acc: 100.00%] [G loss: 6.046034]\n",
      "##############\n",
      "[0.8661591  0.88633502 0.81461555 0.83508258 0.8023008  0.81594656\n",
      " 0.88815106 0.8231716  0.79617392 0.83729986]\n",
      "##########\n",
      "epoch:33 step:26001 [D loss: 0.125023, acc: 100.00%] [G loss: 2.354377]\n",
      "epoch:33 step:26002 [D loss: 0.772446, acc: 50.78%] [G loss: 4.452257]\n",
      "epoch:33 step:26003 [D loss: 1.096187, acc: 50.78%] [G loss: 5.938492]\n",
      "epoch:33 step:26004 [D loss: 0.520503, acc: 60.16%] [G loss: 3.959973]\n",
      "epoch:33 step:26005 [D loss: 1.049751, acc: 50.00%] [G loss: 3.626173]\n",
      "epoch:33 step:26006 [D loss: 0.194533, acc: 94.53%] [G loss: 5.319766]\n",
      "epoch:33 step:26007 [D loss: 0.218221, acc: 94.53%] [G loss: 3.093659]\n",
      "epoch:33 step:26008 [D loss: 0.220730, acc: 98.44%] [G loss: 3.965368]\n",
      "epoch:33 step:26009 [D loss: 0.325811, acc: 89.06%] [G loss: 5.646888]\n",
      "epoch:33 step:26010 [D loss: 0.268880, acc: 96.88%] [G loss: 4.468844]\n",
      "epoch:33 step:26011 [D loss: 1.029263, acc: 21.88%] [G loss: 4.898258]\n",
      "epoch:33 step:26012 [D loss: 0.171905, acc: 98.44%] [G loss: 2.294532]\n",
      "epoch:33 step:26013 [D loss: 0.370902, acc: 89.84%] [G loss: 3.728268]\n",
      "epoch:33 step:26014 [D loss: 0.159956, acc: 96.09%] [G loss: 5.740843]\n",
      "epoch:33 step:26015 [D loss: 0.075109, acc: 99.22%] [G loss: 5.089630]\n",
      "epoch:33 step:26016 [D loss: 0.641824, acc: 61.72%] [G loss: 5.642016]\n",
      "epoch:33 step:26017 [D loss: 0.198594, acc: 100.00%] [G loss: 9.398442]\n",
      "epoch:33 step:26018 [D loss: 0.286120, acc: 94.53%] [G loss: 4.688034]\n",
      "epoch:33 step:26019 [D loss: 0.192243, acc: 98.44%] [G loss: 3.542145]\n",
      "epoch:33 step:26020 [D loss: 0.221160, acc: 97.66%] [G loss: 5.744248]\n",
      "epoch:33 step:26021 [D loss: 0.247796, acc: 97.66%] [G loss: 3.441847]\n",
      "epoch:33 step:26022 [D loss: 0.521603, acc: 61.72%] [G loss: 4.495664]\n",
      "epoch:33 step:26023 [D loss: 0.111966, acc: 98.44%] [G loss: 8.706147]\n",
      "epoch:33 step:26024 [D loss: 0.047980, acc: 99.22%] [G loss: 5.748147]\n",
      "epoch:33 step:26025 [D loss: 0.121250, acc: 100.00%] [G loss: 6.173916]\n",
      "epoch:33 step:26026 [D loss: 0.571233, acc: 64.06%] [G loss: 3.818320]\n",
      "epoch:33 step:26027 [D loss: 2.381580, acc: 6.25%] [G loss: 3.329326]\n",
      "epoch:33 step:26028 [D loss: 0.691357, acc: 57.81%] [G loss: 2.905657]\n",
      "epoch:33 step:26029 [D loss: 0.187328, acc: 97.66%] [G loss: 5.381840]\n",
      "epoch:33 step:26030 [D loss: 0.344488, acc: 88.28%] [G loss: 4.997715]\n",
      "epoch:33 step:26031 [D loss: 0.097207, acc: 100.00%] [G loss: 4.255200]\n",
      "epoch:33 step:26032 [D loss: 0.200873, acc: 96.88%] [G loss: 2.422851]\n",
      "epoch:33 step:26033 [D loss: 0.370728, acc: 85.94%] [G loss: 3.096601]\n",
      "epoch:33 step:26034 [D loss: 0.815298, acc: 52.34%] [G loss: 1.875608]\n",
      "epoch:33 step:26035 [D loss: 0.675798, acc: 57.03%] [G loss: 5.085776]\n",
      "epoch:33 step:26036 [D loss: 0.572444, acc: 64.06%] [G loss: 4.384636]\n",
      "epoch:33 step:26037 [D loss: 0.546732, acc: 71.88%] [G loss: 5.985383]\n",
      "epoch:33 step:26038 [D loss: 0.299474, acc: 87.50%] [G loss: 3.903087]\n",
      "epoch:33 step:26039 [D loss: 0.543874, acc: 70.31%] [G loss: 4.070954]\n",
      "epoch:33 step:26040 [D loss: 0.106247, acc: 99.22%] [G loss: 5.094580]\n",
      "epoch:33 step:26041 [D loss: 0.346748, acc: 90.62%] [G loss: 5.258562]\n",
      "epoch:33 step:26042 [D loss: 0.465708, acc: 84.38%] [G loss: 4.683101]\n",
      "epoch:33 step:26043 [D loss: 0.396632, acc: 78.12%] [G loss: 4.514030]\n",
      "epoch:33 step:26044 [D loss: 0.361014, acc: 89.06%] [G loss: 6.535149]\n",
      "epoch:33 step:26045 [D loss: 0.614508, acc: 63.28%] [G loss: 9.156906]\n",
      "epoch:33 step:26046 [D loss: 0.497125, acc: 64.84%] [G loss: 3.666957]\n",
      "epoch:33 step:26047 [D loss: 0.366701, acc: 89.84%] [G loss: 5.055209]\n",
      "epoch:33 step:26048 [D loss: 0.195734, acc: 96.88%] [G loss: 6.443275]\n",
      "epoch:33 step:26049 [D loss: 0.308031, acc: 93.75%] [G loss: 6.390595]\n",
      "epoch:33 step:26050 [D loss: 0.259413, acc: 90.62%] [G loss: 5.729988]\n",
      "epoch:33 step:26051 [D loss: 0.045273, acc: 99.22%] [G loss: 5.946979]\n",
      "epoch:33 step:26052 [D loss: 0.978424, acc: 32.81%] [G loss: 3.932164]\n",
      "epoch:33 step:26053 [D loss: 0.412472, acc: 88.28%] [G loss: 3.964497]\n",
      "epoch:33 step:26054 [D loss: 0.221658, acc: 96.88%] [G loss: 2.474321]\n",
      "epoch:33 step:26055 [D loss: 0.720219, acc: 54.69%] [G loss: 4.639472]\n",
      "epoch:33 step:26056 [D loss: 0.393985, acc: 87.50%] [G loss: 6.251240]\n",
      "epoch:33 step:26057 [D loss: 0.129569, acc: 100.00%] [G loss: 4.510028]\n",
      "epoch:33 step:26058 [D loss: 0.161404, acc: 98.44%] [G loss: 5.043711]\n",
      "epoch:33 step:26059 [D loss: 0.086066, acc: 100.00%] [G loss: 3.021191]\n",
      "epoch:33 step:26060 [D loss: 0.205291, acc: 99.22%] [G loss: 4.244982]\n",
      "epoch:33 step:26061 [D loss: 0.176477, acc: 98.44%] [G loss: 5.294365]\n",
      "epoch:33 step:26062 [D loss: 0.060078, acc: 100.00%] [G loss: 7.117190]\n",
      "epoch:33 step:26063 [D loss: 0.551878, acc: 64.84%] [G loss: 3.122520]\n",
      "epoch:33 step:26064 [D loss: 1.101457, acc: 50.78%] [G loss: 4.861685]\n",
      "epoch:33 step:26065 [D loss: 0.468748, acc: 85.16%] [G loss: 4.704099]\n",
      "epoch:33 step:26066 [D loss: 0.355636, acc: 84.38%] [G loss: 6.113530]\n",
      "epoch:33 step:26067 [D loss: 0.797387, acc: 48.44%] [G loss: 6.048086]\n",
      "epoch:33 step:26068 [D loss: 1.368658, acc: 35.94%] [G loss: 3.992765]\n",
      "epoch:33 step:26069 [D loss: 0.056339, acc: 100.00%] [G loss: 9.182801]\n",
      "epoch:33 step:26070 [D loss: 0.422703, acc: 74.22%] [G loss: 6.593349]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:33 step:26071 [D loss: 0.249089, acc: 96.09%] [G loss: 5.902007]\n",
      "epoch:33 step:26072 [D loss: 0.318179, acc: 90.62%] [G loss: 2.909652]\n",
      "epoch:33 step:26073 [D loss: 0.053569, acc: 100.00%] [G loss: 2.833409]\n",
      "epoch:33 step:26074 [D loss: 0.879729, acc: 45.31%] [G loss: 5.978616]\n",
      "epoch:33 step:26075 [D loss: 0.395876, acc: 90.62%] [G loss: 4.187666]\n",
      "epoch:33 step:26076 [D loss: 0.240962, acc: 98.44%] [G loss: 4.750002]\n",
      "epoch:33 step:26077 [D loss: 0.141610, acc: 100.00%] [G loss: 4.771662]\n",
      "epoch:33 step:26078 [D loss: 0.286568, acc: 94.53%] [G loss: 5.216552]\n",
      "epoch:33 step:26079 [D loss: 0.056514, acc: 100.00%] [G loss: 4.037941]\n",
      "epoch:33 step:26080 [D loss: 0.069324, acc: 100.00%] [G loss: 4.062039]\n",
      "epoch:33 step:26081 [D loss: 0.922506, acc: 46.88%] [G loss: 6.928553]\n",
      "epoch:33 step:26082 [D loss: 0.187165, acc: 98.44%] [G loss: 3.226877]\n",
      "epoch:33 step:26083 [D loss: 0.147642, acc: 100.00%] [G loss: 4.033796]\n",
      "epoch:33 step:26084 [D loss: 1.776974, acc: 36.72%] [G loss: 3.891086]\n",
      "epoch:33 step:26085 [D loss: 0.825515, acc: 49.22%] [G loss: 4.964902]\n",
      "epoch:33 step:26086 [D loss: 0.365055, acc: 87.50%] [G loss: 4.042728]\n",
      "epoch:33 step:26087 [D loss: 0.841145, acc: 51.56%] [G loss: 4.909355]\n",
      "epoch:33 step:26088 [D loss: 0.947375, acc: 40.62%] [G loss: 4.546740]\n",
      "epoch:33 step:26089 [D loss: 0.378365, acc: 86.72%] [G loss: 1.725371]\n",
      "epoch:33 step:26090 [D loss: 0.425621, acc: 82.03%] [G loss: 8.270125]\n",
      "epoch:33 step:26091 [D loss: 0.606159, acc: 67.97%] [G loss: 2.249093]\n",
      "epoch:33 step:26092 [D loss: 0.200403, acc: 96.88%] [G loss: 3.696136]\n",
      "epoch:33 step:26093 [D loss: 0.465072, acc: 82.81%] [G loss: 2.859020]\n",
      "epoch:33 step:26094 [D loss: 0.370333, acc: 80.47%] [G loss: 5.239302]\n",
      "epoch:33 step:26095 [D loss: 0.200020, acc: 96.09%] [G loss: 6.682560]\n",
      "epoch:33 step:26096 [D loss: 0.321258, acc: 94.53%] [G loss: 4.368305]\n",
      "epoch:33 step:26097 [D loss: 0.854934, acc: 42.97%] [G loss: 4.215298]\n",
      "epoch:33 step:26098 [D loss: 0.059991, acc: 100.00%] [G loss: 6.439450]\n",
      "epoch:33 step:26099 [D loss: 0.508840, acc: 70.31%] [G loss: 4.581187]\n",
      "epoch:33 step:26100 [D loss: 0.530377, acc: 71.09%] [G loss: 4.603236]\n",
      "epoch:33 step:26101 [D loss: 0.581761, acc: 67.19%] [G loss: 7.041811]\n",
      "epoch:33 step:26102 [D loss: 0.132441, acc: 99.22%] [G loss: 6.882242]\n",
      "epoch:33 step:26103 [D loss: 0.382829, acc: 74.22%] [G loss: 4.473686]\n",
      "epoch:33 step:26104 [D loss: 0.330607, acc: 86.72%] [G loss: 4.382654]\n",
      "epoch:33 step:26105 [D loss: 1.687088, acc: 7.03%] [G loss: 5.356011]\n",
      "epoch:33 step:26106 [D loss: 0.045545, acc: 100.00%] [G loss: 6.652672]\n",
      "epoch:33 step:26107 [D loss: 0.235038, acc: 93.75%] [G loss: 2.342148]\n",
      "epoch:33 step:26108 [D loss: 0.068614, acc: 100.00%] [G loss: 5.361293]\n",
      "epoch:33 step:26109 [D loss: 0.397459, acc: 82.03%] [G loss: 6.716030]\n",
      "epoch:33 step:26110 [D loss: 0.290763, acc: 92.97%] [G loss: 7.662537]\n",
      "epoch:33 step:26111 [D loss: 0.373663, acc: 90.62%] [G loss: 4.480418]\n",
      "epoch:33 step:26112 [D loss: 0.020828, acc: 100.00%] [G loss: 7.881455]\n",
      "epoch:33 step:26113 [D loss: 0.263249, acc: 90.62%] [G loss: 5.958385]\n",
      "epoch:33 step:26114 [D loss: 0.433694, acc: 78.12%] [G loss: 5.590596]\n",
      "epoch:33 step:26115 [D loss: 0.163200, acc: 98.44%] [G loss: 4.687222]\n",
      "epoch:33 step:26116 [D loss: 0.819115, acc: 48.44%] [G loss: 3.035427]\n",
      "epoch:33 step:26117 [D loss: 0.045050, acc: 99.22%] [G loss: 7.033293]\n",
      "epoch:33 step:26118 [D loss: 0.573205, acc: 58.59%] [G loss: 5.098963]\n",
      "epoch:33 step:26119 [D loss: 0.208542, acc: 95.31%] [G loss: 4.569253]\n",
      "epoch:33 step:26120 [D loss: 0.935807, acc: 41.41%] [G loss: 3.505911]\n",
      "epoch:33 step:26121 [D loss: 0.692007, acc: 55.47%] [G loss: 2.364905]\n",
      "epoch:33 step:26122 [D loss: 0.511138, acc: 75.78%] [G loss: 6.576165]\n",
      "epoch:33 step:26123 [D loss: 0.301816, acc: 87.50%] [G loss: 4.870862]\n",
      "epoch:33 step:26124 [D loss: 0.858378, acc: 35.16%] [G loss: 3.497404]\n",
      "epoch:33 step:26125 [D loss: 0.018721, acc: 100.00%] [G loss: 7.704857]\n",
      "epoch:33 step:26126 [D loss: 0.636190, acc: 60.94%] [G loss: 4.022140]\n",
      "epoch:33 step:26127 [D loss: 0.353600, acc: 76.56%] [G loss: 5.103050]\n",
      "epoch:33 step:26128 [D loss: 0.233843, acc: 96.09%] [G loss: 5.209010]\n",
      "epoch:33 step:26129 [D loss: 0.208796, acc: 99.22%] [G loss: 2.870733]\n",
      "epoch:33 step:26130 [D loss: 0.164226, acc: 99.22%] [G loss: 7.058465]\n",
      "epoch:33 step:26131 [D loss: 0.255294, acc: 97.66%] [G loss: 4.799633]\n",
      "epoch:33 step:26132 [D loss: 0.038285, acc: 100.00%] [G loss: 4.999681]\n",
      "epoch:33 step:26133 [D loss: 0.090703, acc: 100.00%] [G loss: 4.427264]\n",
      "epoch:33 step:26134 [D loss: 0.337905, acc: 94.53%] [G loss: 2.959901]\n",
      "epoch:33 step:26135 [D loss: 0.062919, acc: 100.00%] [G loss: 3.742029]\n",
      "epoch:33 step:26136 [D loss: 0.963840, acc: 50.78%] [G loss: 4.234389]\n",
      "epoch:33 step:26137 [D loss: 0.231064, acc: 91.41%] [G loss: 4.380032]\n",
      "epoch:33 step:26138 [D loss: 0.105958, acc: 100.00%] [G loss: 4.365819]\n",
      "epoch:33 step:26139 [D loss: 0.559333, acc: 74.22%] [G loss: 3.662989]\n",
      "epoch:33 step:26140 [D loss: 0.426402, acc: 80.47%] [G loss: 7.732018]\n",
      "epoch:33 step:26141 [D loss: 0.114927, acc: 99.22%] [G loss: 5.047983]\n",
      "epoch:33 step:26142 [D loss: 0.655469, acc: 63.28%] [G loss: 2.880519]\n",
      "epoch:33 step:26143 [D loss: 0.892429, acc: 39.06%] [G loss: 6.291323]\n",
      "epoch:33 step:26144 [D loss: 0.546547, acc: 64.06%] [G loss: 4.120707]\n",
      "epoch:33 step:26145 [D loss: 0.391127, acc: 86.72%] [G loss: 5.294409]\n",
      "epoch:33 step:26146 [D loss: 0.363603, acc: 79.69%] [G loss: 4.489339]\n",
      "epoch:33 step:26147 [D loss: 0.396811, acc: 76.56%] [G loss: 2.657425]\n",
      "epoch:33 step:26148 [D loss: 0.440989, acc: 71.09%] [G loss: 2.970230]\n",
      "epoch:33 step:26149 [D loss: 0.544787, acc: 69.53%] [G loss: 1.966443]\n",
      "epoch:33 step:26150 [D loss: 0.565044, acc: 72.66%] [G loss: 5.413492]\n",
      "epoch:33 step:26151 [D loss: 0.365896, acc: 81.25%] [G loss: 4.147960]\n",
      "epoch:33 step:26152 [D loss: 0.334690, acc: 92.19%] [G loss: 3.303963]\n",
      "epoch:33 step:26153 [D loss: 0.295475, acc: 95.31%] [G loss: 5.358667]\n",
      "epoch:33 step:26154 [D loss: 0.113472, acc: 97.66%] [G loss: 4.336738]\n",
      "epoch:33 step:26155 [D loss: 0.102677, acc: 100.00%] [G loss: 4.360689]\n",
      "epoch:33 step:26156 [D loss: 0.682768, acc: 58.59%] [G loss: 2.283679]\n",
      "epoch:33 step:26157 [D loss: 0.539698, acc: 59.38%] [G loss: 7.394014]\n",
      "epoch:33 step:26158 [D loss: 0.327904, acc: 92.97%] [G loss: 6.736687]\n",
      "epoch:33 step:26159 [D loss: 0.678377, acc: 60.94%] [G loss: 3.001296]\n",
      "epoch:33 step:26160 [D loss: 0.092512, acc: 100.00%] [G loss: 3.102990]\n",
      "epoch:33 step:26161 [D loss: 0.127315, acc: 100.00%] [G loss: 5.755935]\n",
      "epoch:33 step:26162 [D loss: 0.464831, acc: 71.09%] [G loss: 6.545386]\n",
      "epoch:33 step:26163 [D loss: 0.619788, acc: 57.81%] [G loss: 2.303008]\n",
      "epoch:33 step:26164 [D loss: 0.538161, acc: 73.44%] [G loss: 5.463572]\n",
      "epoch:33 step:26165 [D loss: 0.209903, acc: 97.66%] [G loss: 6.284190]\n",
      "epoch:33 step:26166 [D loss: 0.466331, acc: 67.97%] [G loss: 3.692883]\n",
      "epoch:33 step:26167 [D loss: 0.688112, acc: 55.47%] [G loss: 4.337403]\n",
      "epoch:33 step:26168 [D loss: 0.171984, acc: 96.09%] [G loss: 5.320307]\n",
      "epoch:33 step:26169 [D loss: 0.050435, acc: 100.00%] [G loss: 5.960488]\n",
      "epoch:33 step:26170 [D loss: 0.866506, acc: 50.78%] [G loss: 6.904445]\n",
      "epoch:33 step:26171 [D loss: 0.703862, acc: 53.91%] [G loss: 3.697804]\n",
      "epoch:33 step:26172 [D loss: 0.150452, acc: 96.88%] [G loss: 3.172364]\n",
      "epoch:33 step:26173 [D loss: 0.112119, acc: 98.44%] [G loss: 6.266673]\n",
      "epoch:33 step:26174 [D loss: 0.050876, acc: 100.00%] [G loss: 5.496624]\n",
      "epoch:33 step:26175 [D loss: 0.171133, acc: 94.53%] [G loss: 4.022080]\n",
      "epoch:33 step:26176 [D loss: 0.822649, acc: 48.44%] [G loss: 2.985107]\n",
      "epoch:33 step:26177 [D loss: 0.279619, acc: 92.19%] [G loss: 4.319652]\n",
      "epoch:33 step:26178 [D loss: 0.162386, acc: 99.22%] [G loss: 4.164027]\n",
      "epoch:33 step:26179 [D loss: 0.615864, acc: 64.84%] [G loss: 3.105066]\n",
      "epoch:33 step:26180 [D loss: 0.580624, acc: 67.97%] [G loss: 5.567407]\n",
      "epoch:33 step:26181 [D loss: 0.237519, acc: 97.66%] [G loss: 6.268388]\n",
      "epoch:33 step:26182 [D loss: 0.473866, acc: 62.50%] [G loss: 6.778239]\n",
      "epoch:33 step:26183 [D loss: 0.422990, acc: 76.56%] [G loss: 3.173471]\n",
      "epoch:33 step:26184 [D loss: 0.603442, acc: 62.50%] [G loss: 4.202343]\n",
      "epoch:33 step:26185 [D loss: 0.862062, acc: 47.66%] [G loss: 3.041584]\n",
      "epoch:33 step:26186 [D loss: 0.514483, acc: 78.91%] [G loss: 3.789201]\n",
      "epoch:33 step:26187 [D loss: 1.630736, acc: 21.09%] [G loss: 5.360602]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:33 step:26188 [D loss: 0.264728, acc: 94.53%] [G loss: 4.638865]\n",
      "epoch:33 step:26189 [D loss: 0.118511, acc: 100.00%] [G loss: 5.903234]\n",
      "epoch:33 step:26190 [D loss: 0.236549, acc: 98.44%] [G loss: 6.107399]\n",
      "epoch:33 step:26191 [D loss: 0.574504, acc: 69.53%] [G loss: 5.578490]\n",
      "epoch:33 step:26192 [D loss: 0.158934, acc: 99.22%] [G loss: 5.297873]\n",
      "epoch:33 step:26193 [D loss: 0.152789, acc: 100.00%] [G loss: 5.735560]\n",
      "epoch:33 step:26194 [D loss: 0.501860, acc: 78.12%] [G loss: 6.166238]\n",
      "epoch:33 step:26195 [D loss: 0.235163, acc: 90.62%] [G loss: 5.524288]\n",
      "epoch:33 step:26196 [D loss: 0.225612, acc: 98.44%] [G loss: 3.402256]\n",
      "epoch:33 step:26197 [D loss: 0.776237, acc: 54.69%] [G loss: 5.671084]\n",
      "epoch:33 step:26198 [D loss: 0.757219, acc: 50.00%] [G loss: 5.867158]\n",
      "epoch:33 step:26199 [D loss: 0.250465, acc: 96.88%] [G loss: 4.289238]\n",
      "epoch:33 step:26200 [D loss: 0.783580, acc: 45.31%] [G loss: 3.302657]\n",
      "##############\n",
      "[0.88074934 0.86105509 0.81789463 0.79697526 0.78973997 0.82378581\n",
      " 0.88914659 0.82702491 0.82095392 0.85356314]\n",
      "##########\n",
      "epoch:33 step:26201 [D loss: 0.379586, acc: 82.03%] [G loss: 8.121874]\n",
      "epoch:33 step:26202 [D loss: 0.289256, acc: 88.28%] [G loss: 5.016071]\n",
      "epoch:33 step:26203 [D loss: 0.121777, acc: 99.22%] [G loss: 3.296554]\n",
      "epoch:33 step:26204 [D loss: 0.480305, acc: 72.66%] [G loss: 5.038012]\n",
      "epoch:33 step:26205 [D loss: 1.163016, acc: 42.19%] [G loss: 3.715441]\n",
      "epoch:33 step:26206 [D loss: 0.175786, acc: 99.22%] [G loss: 4.104940]\n",
      "epoch:33 step:26207 [D loss: 0.033361, acc: 100.00%] [G loss: 6.096448]\n",
      "epoch:33 step:26208 [D loss: 0.055022, acc: 99.22%] [G loss: 4.182150]\n",
      "epoch:33 step:26209 [D loss: 0.450116, acc: 85.94%] [G loss: 3.498540]\n",
      "epoch:33 step:26210 [D loss: 0.374015, acc: 79.69%] [G loss: 3.712521]\n",
      "epoch:33 step:26211 [D loss: 0.246965, acc: 95.31%] [G loss: 5.616881]\n",
      "epoch:33 step:26212 [D loss: 0.796477, acc: 51.56%] [G loss: 5.463839]\n",
      "epoch:33 step:26213 [D loss: 0.371869, acc: 81.25%] [G loss: 4.621537]\n",
      "epoch:33 step:26214 [D loss: 0.291269, acc: 92.19%] [G loss: 3.099505]\n",
      "epoch:33 step:26215 [D loss: 0.261189, acc: 90.62%] [G loss: 4.029847]\n",
      "epoch:33 step:26216 [D loss: 0.723809, acc: 50.00%] [G loss: 2.018699]\n",
      "epoch:33 step:26217 [D loss: 0.684458, acc: 60.16%] [G loss: 5.416905]\n",
      "epoch:33 step:26218 [D loss: 0.768354, acc: 53.12%] [G loss: 4.247848]\n",
      "epoch:33 step:26219 [D loss: 0.331944, acc: 91.41%] [G loss: 4.868840]\n",
      "epoch:33 step:26220 [D loss: 0.191743, acc: 94.53%] [G loss: 3.482464]\n",
      "epoch:33 step:26221 [D loss: 0.598761, acc: 60.94%] [G loss: 4.773350]\n",
      "epoch:33 step:26222 [D loss: 0.467759, acc: 67.97%] [G loss: 5.807924]\n",
      "epoch:33 step:26223 [D loss: 0.258962, acc: 95.31%] [G loss: 7.191525]\n",
      "epoch:33 step:26224 [D loss: 0.291122, acc: 87.50%] [G loss: 5.338318]\n",
      "epoch:33 step:26225 [D loss: 0.409799, acc: 90.62%] [G loss: 4.487504]\n",
      "epoch:33 step:26226 [D loss: 0.095054, acc: 100.00%] [G loss: 5.581962]\n",
      "epoch:33 step:26227 [D loss: 0.231503, acc: 97.66%] [G loss: 4.943414]\n",
      "epoch:33 step:26228 [D loss: 0.262195, acc: 92.19%] [G loss: 4.009425]\n",
      "epoch:33 step:26229 [D loss: 0.484487, acc: 83.59%] [G loss: 4.644100]\n",
      "epoch:33 step:26230 [D loss: 1.456972, acc: 50.78%] [G loss: 3.875589]\n",
      "epoch:33 step:26231 [D loss: 0.069083, acc: 100.00%] [G loss: 7.713900]\n",
      "epoch:33 step:26232 [D loss: 0.105180, acc: 99.22%] [G loss: 2.848585]\n",
      "epoch:33 step:26233 [D loss: 1.407022, acc: 42.97%] [G loss: 3.311629]\n",
      "epoch:33 step:26234 [D loss: 0.158556, acc: 100.00%] [G loss: 5.437896]\n",
      "epoch:33 step:26235 [D loss: 0.062238, acc: 100.00%] [G loss: 5.483184]\n",
      "epoch:33 step:26236 [D loss: 0.523968, acc: 71.88%] [G loss: 3.309318]\n",
      "epoch:33 step:26237 [D loss: 0.314495, acc: 95.31%] [G loss: 2.577479]\n",
      "epoch:33 step:26238 [D loss: 0.627451, acc: 64.84%] [G loss: 7.193267]\n",
      "epoch:33 step:26239 [D loss: 0.447376, acc: 67.97%] [G loss: 7.270229]\n",
      "epoch:33 step:26240 [D loss: 0.076612, acc: 100.00%] [G loss: 3.384220]\n",
      "epoch:33 step:26241 [D loss: 1.009248, acc: 50.78%] [G loss: 7.044043]\n",
      "epoch:33 step:26242 [D loss: 0.862362, acc: 33.59%] [G loss: 6.059764]\n",
      "epoch:33 step:26243 [D loss: 0.247387, acc: 90.62%] [G loss: 6.116501]\n",
      "epoch:33 step:26244 [D loss: 0.171828, acc: 96.88%] [G loss: 3.061284]\n",
      "epoch:33 step:26245 [D loss: 0.282296, acc: 94.53%] [G loss: 5.119542]\n",
      "epoch:33 step:26246 [D loss: 0.373809, acc: 82.81%] [G loss: 4.443724]\n",
      "epoch:33 step:26247 [D loss: 0.355363, acc: 89.06%] [G loss: 4.955806]\n",
      "epoch:33 step:26248 [D loss: 0.289484, acc: 89.84%] [G loss: 4.499989]\n",
      "epoch:33 step:26249 [D loss: 0.702767, acc: 57.81%] [G loss: 2.417362]\n",
      "epoch:33 step:26250 [D loss: 0.777589, acc: 54.69%] [G loss: 4.266853]\n",
      "epoch:33 step:26251 [D loss: 0.021896, acc: 100.00%] [G loss: 10.240150]\n",
      "epoch:33 step:26252 [D loss: 1.090721, acc: 17.97%] [G loss: 5.369955]\n",
      "epoch:33 step:26253 [D loss: 1.551792, acc: 35.94%] [G loss: 5.181005]\n",
      "epoch:33 step:26254 [D loss: 0.642534, acc: 64.84%] [G loss: 3.498478]\n",
      "epoch:33 step:26255 [D loss: 0.642165, acc: 60.94%] [G loss: 6.105964]\n",
      "epoch:33 step:26256 [D loss: 0.913059, acc: 51.56%] [G loss: 6.548896]\n",
      "epoch:33 step:26257 [D loss: 0.081460, acc: 100.00%] [G loss: 4.298344]\n",
      "epoch:33 step:26258 [D loss: 0.081126, acc: 99.22%] [G loss: 5.173882]\n",
      "epoch:33 step:26259 [D loss: 1.190888, acc: 29.69%] [G loss: 5.277871]\n",
      "epoch:33 step:26260 [D loss: 0.461925, acc: 82.81%] [G loss: 4.486451]\n",
      "epoch:33 step:26261 [D loss: 0.534286, acc: 66.41%] [G loss: 6.741685]\n",
      "epoch:33 step:26262 [D loss: 0.229939, acc: 93.75%] [G loss: 6.066990]\n",
      "epoch:33 step:26263 [D loss: 0.049628, acc: 99.22%] [G loss: 6.567165]\n",
      "epoch:33 step:26264 [D loss: 0.074117, acc: 100.00%] [G loss: 5.457150]\n",
      "epoch:33 step:26265 [D loss: 0.046854, acc: 100.00%] [G loss: 6.151018]\n",
      "epoch:33 step:26266 [D loss: 0.159131, acc: 97.66%] [G loss: 5.329088]\n",
      "epoch:33 step:26267 [D loss: 0.820419, acc: 44.53%] [G loss: 4.134486]\n",
      "epoch:33 step:26268 [D loss: 0.072415, acc: 100.00%] [G loss: 7.554686]\n",
      "epoch:33 step:26269 [D loss: 0.632269, acc: 62.50%] [G loss: 4.888391]\n",
      "epoch:33 step:26270 [D loss: 0.107054, acc: 99.22%] [G loss: 4.691438]\n",
      "epoch:33 step:26271 [D loss: 0.246958, acc: 92.19%] [G loss: 2.542763]\n",
      "epoch:33 step:26272 [D loss: 0.594102, acc: 57.81%] [G loss: 5.954945]\n",
      "epoch:33 step:26273 [D loss: 0.831911, acc: 49.22%] [G loss: 5.167049]\n",
      "epoch:33 step:26274 [D loss: 0.372286, acc: 87.50%] [G loss: 2.207543]\n",
      "epoch:33 step:26275 [D loss: 0.300875, acc: 96.88%] [G loss: 6.124978]\n",
      "epoch:33 step:26276 [D loss: 0.274006, acc: 89.84%] [G loss: 4.524199]\n",
      "epoch:33 step:26277 [D loss: 0.403663, acc: 85.94%] [G loss: 5.209889]\n",
      "epoch:33 step:26278 [D loss: 0.760986, acc: 56.25%] [G loss: 2.789108]\n",
      "epoch:33 step:26279 [D loss: 0.266541, acc: 94.53%] [G loss: 2.853963]\n",
      "epoch:33 step:26280 [D loss: 0.902686, acc: 42.19%] [G loss: 1.876257]\n",
      "epoch:33 step:26281 [D loss: 0.584194, acc: 60.16%] [G loss: 4.842787]\n",
      "epoch:33 step:26282 [D loss: 0.445254, acc: 82.03%] [G loss: 3.698083]\n",
      "epoch:33 step:26283 [D loss: 0.683220, acc: 60.16%] [G loss: 3.670350]\n",
      "epoch:33 step:26284 [D loss: 0.133040, acc: 99.22%] [G loss: 7.869419]\n",
      "epoch:33 step:26285 [D loss: 0.803186, acc: 51.56%] [G loss: 3.781303]\n",
      "epoch:33 step:26286 [D loss: 0.464706, acc: 73.44%] [G loss: 3.223530]\n",
      "epoch:33 step:26287 [D loss: 0.242772, acc: 96.09%] [G loss: 4.384847]\n",
      "epoch:33 step:26288 [D loss: 0.285993, acc: 88.28%] [G loss: 2.997347]\n",
      "epoch:33 step:26289 [D loss: 0.983216, acc: 46.88%] [G loss: 5.296271]\n",
      "epoch:33 step:26290 [D loss: 0.132189, acc: 100.00%] [G loss: 6.342303]\n",
      "epoch:33 step:26291 [D loss: 0.174924, acc: 97.66%] [G loss: 6.417917]\n",
      "epoch:33 step:26292 [D loss: 0.634252, acc: 60.94%] [G loss: 5.509844]\n",
      "epoch:33 step:26293 [D loss: 0.126735, acc: 100.00%] [G loss: 2.595775]\n",
      "epoch:33 step:26294 [D loss: 0.255278, acc: 96.88%] [G loss: 2.963583]\n",
      "epoch:33 step:26295 [D loss: 0.204505, acc: 98.44%] [G loss: 2.473954]\n",
      "epoch:33 step:26296 [D loss: 0.171763, acc: 99.22%] [G loss: 3.520235]\n",
      "epoch:33 step:26297 [D loss: 1.165523, acc: 21.09%] [G loss: 4.274324]\n",
      "epoch:33 step:26298 [D loss: 0.367256, acc: 88.28%] [G loss: 3.383303]\n",
      "epoch:33 step:26299 [D loss: 0.121612, acc: 100.00%] [G loss: 4.279706]\n",
      "epoch:33 step:26300 [D loss: 0.149770, acc: 96.88%] [G loss: 5.041194]\n",
      "epoch:33 step:26301 [D loss: 0.187537, acc: 95.31%] [G loss: 3.702698]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:33 step:26302 [D loss: 0.344930, acc: 82.81%] [G loss: 6.127377]\n",
      "epoch:33 step:26303 [D loss: 0.741557, acc: 53.12%] [G loss: 4.517704]\n",
      "epoch:33 step:26304 [D loss: 0.314465, acc: 84.38%] [G loss: 4.831950]\n",
      "epoch:33 step:26305 [D loss: 0.680598, acc: 63.28%] [G loss: 3.595535]\n",
      "epoch:33 step:26306 [D loss: 0.506170, acc: 79.69%] [G loss: 4.897591]\n",
      "epoch:33 step:26307 [D loss: 0.162561, acc: 98.44%] [G loss: 3.960474]\n",
      "epoch:33 step:26308 [D loss: 0.860330, acc: 42.19%] [G loss: 4.463838]\n",
      "epoch:33 step:26309 [D loss: 0.281446, acc: 90.62%] [G loss: 5.145742]\n",
      "epoch:33 step:26310 [D loss: 0.054671, acc: 100.00%] [G loss: 4.440428]\n",
      "epoch:33 step:26311 [D loss: 0.581811, acc: 61.72%] [G loss: 5.429018]\n",
      "epoch:33 step:26312 [D loss: 0.469714, acc: 78.91%] [G loss: 4.717021]\n",
      "epoch:33 step:26313 [D loss: 0.967945, acc: 49.22%] [G loss: 5.398219]\n",
      "epoch:33 step:26314 [D loss: 0.518426, acc: 69.53%] [G loss: 6.090135]\n",
      "epoch:33 step:26315 [D loss: 0.057772, acc: 100.00%] [G loss: 4.716190]\n",
      "epoch:33 step:26316 [D loss: 0.237794, acc: 92.97%] [G loss: 5.076944]\n",
      "epoch:33 step:26317 [D loss: 0.215364, acc: 99.22%] [G loss: 3.571675]\n",
      "epoch:33 step:26318 [D loss: 0.495541, acc: 78.91%] [G loss: 4.871671]\n",
      "epoch:33 step:26319 [D loss: 0.060036, acc: 100.00%] [G loss: 2.775622]\n",
      "epoch:33 step:26320 [D loss: 0.310457, acc: 95.31%] [G loss: 3.130660]\n",
      "epoch:33 step:26321 [D loss: 0.091863, acc: 100.00%] [G loss: 5.646386]\n",
      "epoch:33 step:26322 [D loss: 0.127343, acc: 100.00%] [G loss: 4.924237]\n",
      "epoch:33 step:26323 [D loss: 0.381888, acc: 90.62%] [G loss: 4.549973]\n",
      "epoch:33 step:26324 [D loss: 0.249057, acc: 95.31%] [G loss: 3.446587]\n",
      "epoch:33 step:26325 [D loss: 0.338000, acc: 91.41%] [G loss: 4.218597]\n",
      "epoch:33 step:26326 [D loss: 0.876990, acc: 40.62%] [G loss: 5.944834]\n",
      "epoch:33 step:26327 [D loss: 0.765882, acc: 57.81%] [G loss: 8.839546]\n",
      "epoch:33 step:26328 [D loss: 0.052378, acc: 100.00%] [G loss: 5.301737]\n",
      "epoch:33 step:26329 [D loss: 0.186170, acc: 96.09%] [G loss: 4.430877]\n",
      "epoch:33 step:26330 [D loss: 0.174990, acc: 99.22%] [G loss: 4.241946]\n",
      "epoch:33 step:26331 [D loss: 0.401009, acc: 85.94%] [G loss: 6.734629]\n",
      "epoch:33 step:26332 [D loss: 0.086816, acc: 99.22%] [G loss: 5.451788]\n",
      "epoch:33 step:26333 [D loss: 0.506762, acc: 68.75%] [G loss: 6.140018]\n",
      "epoch:33 step:26334 [D loss: 0.172425, acc: 96.88%] [G loss: 6.626796]\n",
      "epoch:33 step:26335 [D loss: 1.458888, acc: 13.28%] [G loss: 5.197358]\n",
      "epoch:33 step:26336 [D loss: 0.302420, acc: 92.97%] [G loss: 5.830709]\n",
      "epoch:33 step:26337 [D loss: 0.086330, acc: 100.00%] [G loss: 3.094611]\n",
      "epoch:33 step:26338 [D loss: 0.522577, acc: 71.09%] [G loss: 3.821933]\n",
      "epoch:33 step:26339 [D loss: 0.396830, acc: 86.72%] [G loss: 3.247247]\n",
      "epoch:33 step:26340 [D loss: 0.957897, acc: 32.03%] [G loss: 5.483350]\n",
      "epoch:33 step:26341 [D loss: 0.539680, acc: 71.88%] [G loss: 4.895201]\n",
      "epoch:33 step:26342 [D loss: 0.073858, acc: 100.00%] [G loss: 6.873239]\n",
      "epoch:33 step:26343 [D loss: 0.542479, acc: 64.84%] [G loss: 4.234122]\n",
      "epoch:33 step:26344 [D loss: 1.235175, acc: 16.41%] [G loss: 5.166412]\n",
      "epoch:33 step:26345 [D loss: 0.249658, acc: 93.75%] [G loss: 7.088946]\n",
      "epoch:33 step:26346 [D loss: 0.391866, acc: 86.72%] [G loss: 4.378623]\n",
      "epoch:33 step:26347 [D loss: 0.330913, acc: 88.28%] [G loss: 1.941961]\n",
      "epoch:33 step:26348 [D loss: 0.373933, acc: 86.72%] [G loss: 3.626565]\n",
      "epoch:33 step:26349 [D loss: 0.565647, acc: 61.72%] [G loss: 4.543072]\n",
      "epoch:33 step:26350 [D loss: 0.198721, acc: 96.88%] [G loss: 6.715391]\n",
      "epoch:33 step:26351 [D loss: 0.320119, acc: 92.19%] [G loss: 7.253917]\n",
      "epoch:33 step:26352 [D loss: 0.153008, acc: 100.00%] [G loss: 5.050039]\n",
      "epoch:33 step:26353 [D loss: 0.343834, acc: 92.19%] [G loss: 6.363052]\n",
      "epoch:33 step:26354 [D loss: 0.166670, acc: 99.22%] [G loss: 4.754106]\n",
      "epoch:33 step:26355 [D loss: 0.249709, acc: 95.31%] [G loss: 4.502053]\n",
      "epoch:33 step:26356 [D loss: 0.223138, acc: 91.41%] [G loss: 7.233932]\n",
      "epoch:33 step:26357 [D loss: 0.300912, acc: 92.19%] [G loss: 3.324982]\n",
      "epoch:33 step:26358 [D loss: 0.417555, acc: 87.50%] [G loss: 5.206739]\n",
      "epoch:33 step:26359 [D loss: 0.551449, acc: 70.31%] [G loss: 4.849435]\n",
      "epoch:33 step:26360 [D loss: 0.249376, acc: 93.75%] [G loss: 4.985094]\n",
      "epoch:33 step:26361 [D loss: 0.356681, acc: 78.12%] [G loss: 4.686277]\n",
      "epoch:33 step:26362 [D loss: 0.140110, acc: 99.22%] [G loss: 3.907900]\n",
      "epoch:33 step:26363 [D loss: 0.239476, acc: 97.66%] [G loss: 3.281973]\n",
      "epoch:33 step:26364 [D loss: 0.159266, acc: 98.44%] [G loss: 4.884093]\n",
      "epoch:33 step:26365 [D loss: 0.346697, acc: 83.59%] [G loss: 4.237451]\n",
      "epoch:33 step:26366 [D loss: 0.678336, acc: 60.94%] [G loss: 4.206295]\n",
      "epoch:33 step:26367 [D loss: 0.363095, acc: 87.50%] [G loss: 1.930310]\n",
      "epoch:33 step:26368 [D loss: 0.410992, acc: 81.25%] [G loss: 5.909469]\n",
      "epoch:33 step:26369 [D loss: 0.240668, acc: 92.19%] [G loss: 5.589779]\n",
      "epoch:33 step:26370 [D loss: 0.204766, acc: 97.66%] [G loss: 5.044517]\n",
      "epoch:33 step:26371 [D loss: 0.293161, acc: 82.81%] [G loss: 4.761056]\n",
      "epoch:33 step:26372 [D loss: 0.309726, acc: 90.62%] [G loss: 3.347203]\n",
      "epoch:33 step:26373 [D loss: 0.154908, acc: 100.00%] [G loss: 4.653383]\n",
      "epoch:33 step:26374 [D loss: 0.733566, acc: 50.00%] [G loss: 5.825207]\n",
      "epoch:33 step:26375 [D loss: 0.580669, acc: 69.53%] [G loss: 3.958058]\n",
      "epoch:33 step:26376 [D loss: 0.323923, acc: 89.06%] [G loss: 3.557936]\n",
      "epoch:33 step:26377 [D loss: 1.147549, acc: 45.31%] [G loss: 3.742652]\n",
      "epoch:33 step:26378 [D loss: 0.067156, acc: 100.00%] [G loss: 4.392990]\n",
      "epoch:33 step:26379 [D loss: 0.823495, acc: 50.78%] [G loss: 4.342880]\n",
      "epoch:33 step:26380 [D loss: 0.942177, acc: 31.25%] [G loss: 3.637530]\n",
      "epoch:33 step:26381 [D loss: 0.982117, acc: 51.56%] [G loss: 4.993158]\n",
      "epoch:33 step:26382 [D loss: 0.098539, acc: 100.00%] [G loss: 5.932295]\n",
      "epoch:33 step:26383 [D loss: 0.744108, acc: 57.03%] [G loss: 8.276440]\n",
      "epoch:33 step:26384 [D loss: 0.357065, acc: 89.84%] [G loss: 4.526052]\n",
      "epoch:33 step:26385 [D loss: 0.046131, acc: 100.00%] [G loss: 5.027965]\n",
      "epoch:33 step:26386 [D loss: 0.357713, acc: 90.62%] [G loss: 2.889262]\n",
      "epoch:33 step:26387 [D loss: 0.106290, acc: 98.44%] [G loss: 5.088825]\n",
      "epoch:33 step:26388 [D loss: 0.124905, acc: 97.66%] [G loss: 6.229247]\n",
      "epoch:33 step:26389 [D loss: 0.486349, acc: 78.91%] [G loss: 4.766281]\n",
      "epoch:33 step:26390 [D loss: 0.883055, acc: 46.09%] [G loss: 6.448882]\n",
      "epoch:33 step:26391 [D loss: 0.249044, acc: 94.53%] [G loss: 5.046482]\n",
      "epoch:33 step:26392 [D loss: 1.128312, acc: 20.31%] [G loss: 5.516277]\n",
      "epoch:33 step:26393 [D loss: 1.337165, acc: 38.28%] [G loss: 4.287683]\n",
      "epoch:33 step:26394 [D loss: 1.475569, acc: 28.12%] [G loss: 6.442848]\n",
      "epoch:33 step:26395 [D loss: 0.463785, acc: 71.88%] [G loss: 4.421316]\n",
      "epoch:33 step:26396 [D loss: 0.109003, acc: 100.00%] [G loss: 3.437786]\n",
      "epoch:33 step:26397 [D loss: 0.112528, acc: 100.00%] [G loss: 8.357368]\n",
      "epoch:33 step:26398 [D loss: 0.062189, acc: 100.00%] [G loss: 6.237745]\n",
      "epoch:33 step:26399 [D loss: 0.268180, acc: 91.41%] [G loss: 2.687696]\n",
      "epoch:33 step:26400 [D loss: 0.440757, acc: 75.00%] [G loss: 3.108078]\n",
      "##############\n",
      "[0.86487749 0.89177536 0.82345839 0.82137983 0.79368787 0.82797732\n",
      " 0.86974254 0.81243538 0.80473185 0.83860312]\n",
      "##########\n",
      "epoch:33 step:26401 [D loss: 0.237142, acc: 98.44%] [G loss: 6.636469]\n",
      "epoch:33 step:26402 [D loss: 0.556092, acc: 60.94%] [G loss: 5.330590]\n",
      "epoch:33 step:26403 [D loss: 0.079042, acc: 100.00%] [G loss: 4.084044]\n",
      "epoch:33 step:26404 [D loss: 0.365544, acc: 92.97%] [G loss: 4.104022]\n",
      "epoch:33 step:26405 [D loss: 0.285546, acc: 93.75%] [G loss: 4.635156]\n",
      "epoch:33 step:26406 [D loss: 0.151604, acc: 100.00%] [G loss: 3.892873]\n",
      "epoch:33 step:26407 [D loss: 0.165633, acc: 97.66%] [G loss: 4.176507]\n",
      "epoch:33 step:26408 [D loss: 0.059051, acc: 99.22%] [G loss: 8.668318]\n",
      "epoch:33 step:26409 [D loss: 0.194152, acc: 100.00%] [G loss: 4.945716]\n",
      "epoch:33 step:26410 [D loss: 0.147346, acc: 100.00%] [G loss: 4.335299]\n",
      "epoch:33 step:26411 [D loss: 0.329919, acc: 95.31%] [G loss: 2.939201]\n",
      "epoch:33 step:26412 [D loss: 0.242831, acc: 93.75%] [G loss: 6.343162]\n",
      "epoch:33 step:26413 [D loss: 0.066264, acc: 99.22%] [G loss: 4.566647]\n",
      "epoch:33 step:26414 [D loss: 0.373528, acc: 83.59%] [G loss: 4.159613]\n",
      "epoch:33 step:26415 [D loss: 0.173005, acc: 100.00%] [G loss: 5.696489]\n",
      "epoch:33 step:26416 [D loss: 0.440753, acc: 73.44%] [G loss: 5.144735]\n",
      "epoch:33 step:26417 [D loss: 0.124597, acc: 99.22%] [G loss: 4.827048]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:33 step:26418 [D loss: 0.212921, acc: 96.88%] [G loss: 4.902215]\n",
      "epoch:33 step:26419 [D loss: 0.392951, acc: 79.69%] [G loss: 2.778632]\n",
      "epoch:33 step:26420 [D loss: 0.207773, acc: 97.66%] [G loss: 3.455352]\n",
      "epoch:33 step:26421 [D loss: 0.122436, acc: 99.22%] [G loss: 5.034452]\n",
      "epoch:33 step:26422 [D loss: 0.657899, acc: 54.69%] [G loss: 5.685080]\n",
      "epoch:33 step:26423 [D loss: 0.106856, acc: 100.00%] [G loss: 3.742523]\n",
      "epoch:33 step:26424 [D loss: 0.213041, acc: 94.53%] [G loss: 3.881747]\n",
      "epoch:33 step:26425 [D loss: 0.111191, acc: 100.00%] [G loss: 4.839988]\n",
      "epoch:33 step:26426 [D loss: 0.573667, acc: 66.41%] [G loss: 6.584180]\n",
      "epoch:33 step:26427 [D loss: 0.068841, acc: 100.00%] [G loss: 5.183009]\n",
      "epoch:33 step:26428 [D loss: 0.103859, acc: 100.00%] [G loss: 5.915328]\n",
      "epoch:33 step:26429 [D loss: 1.021611, acc: 52.34%] [G loss: 8.958312]\n",
      "epoch:33 step:26430 [D loss: 0.418786, acc: 85.16%] [G loss: 4.343728]\n",
      "epoch:33 step:26431 [D loss: 0.449562, acc: 84.38%] [G loss: 4.276487]\n",
      "epoch:33 step:26432 [D loss: 0.241306, acc: 91.41%] [G loss: 4.995180]\n",
      "epoch:33 step:26433 [D loss: 0.484490, acc: 82.03%] [G loss: 4.835236]\n",
      "epoch:33 step:26434 [D loss: 0.098740, acc: 100.00%] [G loss: 5.598292]\n",
      "epoch:33 step:26435 [D loss: 0.666912, acc: 60.94%] [G loss: 5.080312]\n",
      "epoch:33 step:26436 [D loss: 0.088167, acc: 100.00%] [G loss: 5.535799]\n",
      "epoch:33 step:26437 [D loss: 0.450114, acc: 75.78%] [G loss: 4.721983]\n",
      "epoch:33 step:26438 [D loss: 0.401173, acc: 88.28%] [G loss: 4.071976]\n",
      "epoch:33 step:26439 [D loss: 0.691766, acc: 57.81%] [G loss: 2.133891]\n",
      "epoch:33 step:26440 [D loss: 0.047300, acc: 100.00%] [G loss: 5.639812]\n",
      "epoch:33 step:26441 [D loss: 1.117865, acc: 51.56%] [G loss: 4.322725]\n",
      "epoch:33 step:26442 [D loss: 0.242270, acc: 96.09%] [G loss: 4.815007]\n",
      "epoch:33 step:26443 [D loss: 0.268227, acc: 96.88%] [G loss: 5.531322]\n",
      "epoch:33 step:26444 [D loss: 0.299980, acc: 90.62%] [G loss: 4.514734]\n",
      "epoch:33 step:26445 [D loss: 0.470335, acc: 82.03%] [G loss: 4.065038]\n",
      "epoch:33 step:26446 [D loss: 0.188272, acc: 95.31%] [G loss: 7.777813]\n",
      "epoch:33 step:26447 [D loss: 0.141990, acc: 96.88%] [G loss: 6.155736]\n",
      "epoch:33 step:26448 [D loss: 0.430474, acc: 75.78%] [G loss: 7.019512]\n",
      "epoch:33 step:26449 [D loss: 0.356753, acc: 87.50%] [G loss: 8.002465]\n",
      "epoch:33 step:26450 [D loss: 0.199338, acc: 96.88%] [G loss: 6.301530]\n",
      "epoch:33 step:26451 [D loss: 0.185050, acc: 99.22%] [G loss: 4.133497]\n",
      "epoch:33 step:26452 [D loss: 0.444803, acc: 80.47%] [G loss: 3.425880]\n",
      "epoch:33 step:26453 [D loss: 1.014589, acc: 21.88%] [G loss: 3.295239]\n",
      "epoch:33 step:26454 [D loss: 0.740020, acc: 55.47%] [G loss: 9.173948]\n",
      "epoch:33 step:26455 [D loss: 0.345578, acc: 87.50%] [G loss: 5.441596]\n",
      "epoch:33 step:26456 [D loss: 0.337902, acc: 92.19%] [G loss: 4.424636]\n",
      "epoch:33 step:26457 [D loss: 0.251500, acc: 96.88%] [G loss: 3.793220]\n",
      "epoch:33 step:26458 [D loss: 0.199311, acc: 98.44%] [G loss: 5.764320]\n",
      "epoch:33 step:26459 [D loss: 0.122005, acc: 100.00%] [G loss: 4.802450]\n",
      "epoch:33 step:26460 [D loss: 0.789067, acc: 55.47%] [G loss: 5.845564]\n",
      "epoch:33 step:26461 [D loss: 0.770208, acc: 53.91%] [G loss: 4.029299]\n",
      "epoch:33 step:26462 [D loss: 0.136996, acc: 100.00%] [G loss: 5.435960]\n",
      "epoch:33 step:26463 [D loss: 0.088070, acc: 100.00%] [G loss: 4.326106]\n",
      "epoch:33 step:26464 [D loss: 0.114957, acc: 98.44%] [G loss: 5.104063]\n",
      "epoch:33 step:26465 [D loss: 0.591518, acc: 62.50%] [G loss: 6.912675]\n",
      "epoch:33 step:26466 [D loss: 0.575440, acc: 57.81%] [G loss: 5.914369]\n",
      "epoch:33 step:26467 [D loss: 0.638993, acc: 59.38%] [G loss: 4.701323]\n",
      "epoch:33 step:26468 [D loss: 0.246515, acc: 96.09%] [G loss: 4.648205]\n",
      "epoch:33 step:26469 [D loss: 0.487233, acc: 76.56%] [G loss: 4.799316]\n",
      "epoch:33 step:26470 [D loss: 0.367785, acc: 82.03%] [G loss: 4.417008]\n",
      "epoch:33 step:26471 [D loss: 0.392930, acc: 82.03%] [G loss: 3.957046]\n",
      "epoch:33 step:26472 [D loss: 0.111498, acc: 99.22%] [G loss: 4.765592]\n",
      "epoch:33 step:26473 [D loss: 0.309947, acc: 89.06%] [G loss: 3.047097]\n",
      "epoch:33 step:26474 [D loss: 0.155346, acc: 98.44%] [G loss: 3.249403]\n",
      "epoch:33 step:26475 [D loss: 0.488278, acc: 77.34%] [G loss: 5.447168]\n",
      "epoch:33 step:26476 [D loss: 0.239144, acc: 96.88%] [G loss: 3.848363]\n",
      "epoch:33 step:26477 [D loss: 0.119339, acc: 99.22%] [G loss: 2.770685]\n",
      "epoch:33 step:26478 [D loss: 0.198057, acc: 95.31%] [G loss: 5.624646]\n",
      "epoch:33 step:26479 [D loss: 0.316684, acc: 86.72%] [G loss: 3.374309]\n",
      "epoch:33 step:26480 [D loss: 0.028709, acc: 100.00%] [G loss: 3.832450]\n",
      "epoch:33 step:26481 [D loss: 1.100552, acc: 50.78%] [G loss: 6.916739]\n",
      "epoch:33 step:26482 [D loss: 0.566850, acc: 63.28%] [G loss: 3.610302]\n",
      "epoch:33 step:26483 [D loss: 0.649076, acc: 57.81%] [G loss: 6.168024]\n",
      "epoch:33 step:26484 [D loss: 0.050767, acc: 100.00%] [G loss: 7.250049]\n",
      "epoch:33 step:26485 [D loss: 0.624859, acc: 62.50%] [G loss: 5.178561]\n",
      "epoch:33 step:26486 [D loss: 0.420596, acc: 69.53%] [G loss: 8.022982]\n",
      "epoch:33 step:26487 [D loss: 0.152810, acc: 99.22%] [G loss: 7.066583]\n",
      "epoch:33 step:26488 [D loss: 0.426590, acc: 67.97%] [G loss: 7.314584]\n",
      "epoch:33 step:26489 [D loss: 0.357801, acc: 89.06%] [G loss: 6.045363]\n",
      "epoch:33 step:26490 [D loss: 0.048160, acc: 100.00%] [G loss: 8.994770]\n",
      "epoch:33 step:26491 [D loss: 0.232569, acc: 92.97%] [G loss: 6.580559]\n",
      "epoch:33 step:26492 [D loss: 0.683467, acc: 62.50%] [G loss: 5.430149]\n",
      "epoch:33 step:26493 [D loss: 0.349442, acc: 92.97%] [G loss: 4.404130]\n",
      "epoch:33 step:26494 [D loss: 1.115528, acc: 50.00%] [G loss: 8.146720]\n",
      "epoch:33 step:26495 [D loss: 0.201541, acc: 94.53%] [G loss: 4.973508]\n",
      "epoch:33 step:26496 [D loss: 0.069732, acc: 99.22%] [G loss: 5.904481]\n",
      "epoch:33 step:26497 [D loss: 0.384301, acc: 75.78%] [G loss: 4.552135]\n",
      "epoch:33 step:26498 [D loss: 0.294550, acc: 96.09%] [G loss: 3.474476]\n",
      "epoch:33 step:26499 [D loss: 0.109101, acc: 100.00%] [G loss: 7.384144]\n",
      "epoch:33 step:26500 [D loss: 0.254428, acc: 99.22%] [G loss: 4.617379]\n",
      "epoch:33 step:26501 [D loss: 0.801944, acc: 53.91%] [G loss: 6.996613]\n",
      "epoch:33 step:26502 [D loss: 0.844647, acc: 47.66%] [G loss: 4.901018]\n",
      "epoch:33 step:26503 [D loss: 0.745512, acc: 55.47%] [G loss: 4.055308]\n",
      "epoch:33 step:26504 [D loss: 0.678228, acc: 57.03%] [G loss: 4.728772]\n",
      "epoch:33 step:26505 [D loss: 0.084866, acc: 100.00%] [G loss: 4.755172]\n",
      "epoch:33 step:26506 [D loss: 0.737656, acc: 53.12%] [G loss: 4.939502]\n",
      "epoch:33 step:26507 [D loss: 1.162785, acc: 19.53%] [G loss: 6.652279]\n",
      "epoch:33 step:26508 [D loss: 0.136647, acc: 99.22%] [G loss: 5.098641]\n",
      "epoch:33 step:26509 [D loss: 0.620386, acc: 57.81%] [G loss: 6.856188]\n",
      "epoch:33 step:26510 [D loss: 0.011100, acc: 100.00%] [G loss: 7.548533]\n",
      "epoch:33 step:26511 [D loss: 1.473444, acc: 50.00%] [G loss: 5.835208]\n",
      "epoch:33 step:26512 [D loss: 0.425590, acc: 75.78%] [G loss: 4.510116]\n",
      "epoch:33 step:26513 [D loss: 0.056524, acc: 100.00%] [G loss: 4.149107]\n",
      "epoch:33 step:26514 [D loss: 0.158241, acc: 96.88%] [G loss: 3.081163]\n",
      "epoch:33 step:26515 [D loss: 0.265706, acc: 93.75%] [G loss: 3.539225]\n",
      "epoch:33 step:26516 [D loss: 0.186495, acc: 98.44%] [G loss: 5.969396]\n",
      "epoch:33 step:26517 [D loss: 0.502009, acc: 68.75%] [G loss: 4.722946]\n",
      "epoch:33 step:26518 [D loss: 0.086615, acc: 100.00%] [G loss: 4.956418]\n",
      "epoch:33 step:26519 [D loss: 0.723393, acc: 53.91%] [G loss: 6.593437]\n",
      "epoch:33 step:26520 [D loss: 0.395364, acc: 81.25%] [G loss: 3.966325]\n",
      "epoch:33 step:26521 [D loss: 0.971845, acc: 28.12%] [G loss: 6.593536]\n",
      "epoch:33 step:26522 [D loss: 0.826478, acc: 50.00%] [G loss: 5.041177]\n",
      "epoch:33 step:26523 [D loss: 0.385825, acc: 83.59%] [G loss: 6.538663]\n",
      "epoch:33 step:26524 [D loss: 0.512791, acc: 63.28%] [G loss: 4.407462]\n",
      "epoch:33 step:26525 [D loss: 0.047305, acc: 100.00%] [G loss: 5.023114]\n",
      "epoch:33 step:26526 [D loss: 0.239500, acc: 97.66%] [G loss: 3.142469]\n",
      "epoch:33 step:26527 [D loss: 0.121281, acc: 100.00%] [G loss: 3.825097]\n",
      "epoch:33 step:26528 [D loss: 0.123800, acc: 98.44%] [G loss: 3.317378]\n",
      "epoch:33 step:26529 [D loss: 0.024660, acc: 100.00%] [G loss: 4.855239]\n",
      "epoch:33 step:26530 [D loss: 0.103529, acc: 99.22%] [G loss: 4.277265]\n",
      "epoch:33 step:26531 [D loss: 0.564741, acc: 71.88%] [G loss: 3.910320]\n",
      "epoch:33 step:26532 [D loss: 0.459260, acc: 69.53%] [G loss: 5.675842]\n",
      "epoch:33 step:26533 [D loss: 0.425884, acc: 72.66%] [G loss: 8.973349]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:33 step:26534 [D loss: 0.035421, acc: 100.00%] [G loss: 6.703568]\n",
      "epoch:33 step:26535 [D loss: 0.486375, acc: 72.66%] [G loss: 6.119181]\n",
      "epoch:33 step:26536 [D loss: 0.520575, acc: 71.09%] [G loss: 1.848725]\n",
      "epoch:33 step:26537 [D loss: 1.339436, acc: 16.41%] [G loss: 4.920438]\n",
      "epoch:33 step:26538 [D loss: 1.251118, acc: 48.44%] [G loss: 3.291167]\n",
      "epoch:33 step:26539 [D loss: 0.204014, acc: 98.44%] [G loss: 3.614124]\n",
      "epoch:33 step:26540 [D loss: 0.020789, acc: 100.00%] [G loss: 5.633177]\n",
      "epoch:33 step:26541 [D loss: 0.198679, acc: 99.22%] [G loss: 2.907114]\n",
      "epoch:33 step:26542 [D loss: 0.621568, acc: 70.31%] [G loss: 4.606963]\n",
      "epoch:33 step:26543 [D loss: 0.485661, acc: 70.31%] [G loss: 2.497372]\n",
      "epoch:33 step:26544 [D loss: 0.274983, acc: 92.97%] [G loss: 3.248505]\n",
      "epoch:33 step:26545 [D loss: 0.066628, acc: 100.00%] [G loss: 4.224751]\n",
      "epoch:33 step:26546 [D loss: 0.044774, acc: 100.00%] [G loss: 8.783737]\n",
      "epoch:33 step:26547 [D loss: 0.209017, acc: 97.66%] [G loss: 4.798907]\n",
      "epoch:33 step:26548 [D loss: 0.998991, acc: 28.91%] [G loss: 5.037799]\n",
      "epoch:33 step:26549 [D loss: 0.347719, acc: 82.03%] [G loss: 3.953646]\n",
      "epoch:33 step:26550 [D loss: 0.668319, acc: 58.59%] [G loss: 2.320110]\n",
      "epoch:33 step:26551 [D loss: 0.431456, acc: 85.16%] [G loss: 2.889689]\n",
      "epoch:33 step:26552 [D loss: 0.118919, acc: 100.00%] [G loss: 2.374254]\n",
      "epoch:33 step:26553 [D loss: 0.558061, acc: 62.50%] [G loss: 2.962476]\n",
      "epoch:33 step:26554 [D loss: 0.175849, acc: 99.22%] [G loss: 6.110397]\n",
      "epoch:34 step:26555 [D loss: 0.869074, acc: 42.97%] [G loss: 3.466597]\n",
      "epoch:34 step:26556 [D loss: 0.467590, acc: 81.25%] [G loss: 3.634581]\n",
      "epoch:34 step:26557 [D loss: 0.424272, acc: 84.38%] [G loss: 3.876280]\n",
      "epoch:34 step:26558 [D loss: 0.399030, acc: 72.66%] [G loss: 7.137596]\n",
      "epoch:34 step:26559 [D loss: 0.533418, acc: 75.00%] [G loss: 4.353045]\n",
      "epoch:34 step:26560 [D loss: 1.262152, acc: 47.66%] [G loss: 5.007136]\n",
      "epoch:34 step:26561 [D loss: 0.625477, acc: 64.84%] [G loss: 3.975758]\n",
      "epoch:34 step:26562 [D loss: 0.810549, acc: 53.12%] [G loss: 3.676186]\n",
      "epoch:34 step:26563 [D loss: 0.108317, acc: 100.00%] [G loss: 3.613653]\n",
      "epoch:34 step:26564 [D loss: 0.198697, acc: 96.88%] [G loss: 2.540883]\n",
      "epoch:34 step:26565 [D loss: 1.071328, acc: 40.62%] [G loss: 4.283750]\n",
      "epoch:34 step:26566 [D loss: 0.629730, acc: 62.50%] [G loss: 3.748154]\n",
      "epoch:34 step:26567 [D loss: 0.364027, acc: 80.47%] [G loss: 5.847398]\n",
      "epoch:34 step:26568 [D loss: 0.167159, acc: 96.88%] [G loss: 2.391752]\n",
      "epoch:34 step:26569 [D loss: 0.610984, acc: 61.72%] [G loss: 1.483487]\n",
      "epoch:34 step:26570 [D loss: 0.227000, acc: 98.44%] [G loss: 5.328646]\n",
      "epoch:34 step:26571 [D loss: 0.643793, acc: 56.25%] [G loss: 3.130283]\n",
      "epoch:34 step:26572 [D loss: 0.083876, acc: 100.00%] [G loss: 4.609157]\n",
      "epoch:34 step:26573 [D loss: 0.451196, acc: 84.38%] [G loss: 5.188937]\n",
      "epoch:34 step:26574 [D loss: 0.160342, acc: 99.22%] [G loss: 3.416034]\n",
      "epoch:34 step:26575 [D loss: 0.788992, acc: 50.78%] [G loss: 4.314566]\n",
      "epoch:34 step:26576 [D loss: 0.182700, acc: 100.00%] [G loss: 4.278286]\n",
      "epoch:34 step:26577 [D loss: 0.329239, acc: 92.97%] [G loss: 4.082852]\n",
      "epoch:34 step:26578 [D loss: 0.452702, acc: 73.44%] [G loss: 3.209573]\n",
      "epoch:34 step:26579 [D loss: 0.638178, acc: 56.25%] [G loss: 3.624912]\n",
      "epoch:34 step:26580 [D loss: 0.324913, acc: 89.84%] [G loss: 3.655720]\n",
      "epoch:34 step:26581 [D loss: 0.439802, acc: 69.53%] [G loss: 4.225568]\n",
      "epoch:34 step:26582 [D loss: 0.646027, acc: 61.72%] [G loss: 4.600984]\n",
      "epoch:34 step:26583 [D loss: 0.730999, acc: 57.81%] [G loss: 7.937090]\n",
      "epoch:34 step:26584 [D loss: 0.151399, acc: 99.22%] [G loss: 6.111903]\n",
      "epoch:34 step:26585 [D loss: 0.229574, acc: 92.97%] [G loss: 5.556338]\n",
      "epoch:34 step:26586 [D loss: 0.227434, acc: 93.75%] [G loss: 6.502571]\n",
      "epoch:34 step:26587 [D loss: 0.542075, acc: 71.09%] [G loss: 4.235471]\n",
      "epoch:34 step:26588 [D loss: 0.377648, acc: 89.84%] [G loss: 4.662252]\n",
      "epoch:34 step:26589 [D loss: 0.203664, acc: 97.66%] [G loss: 1.533209]\n",
      "epoch:34 step:26590 [D loss: 0.234224, acc: 90.62%] [G loss: 3.860090]\n",
      "epoch:34 step:26591 [D loss: 0.158573, acc: 98.44%] [G loss: 4.510606]\n",
      "epoch:34 step:26592 [D loss: 0.304001, acc: 91.41%] [G loss: 5.910164]\n",
      "epoch:34 step:26593 [D loss: 0.270867, acc: 96.88%] [G loss: 5.259605]\n",
      "epoch:34 step:26594 [D loss: 0.331532, acc: 91.41%] [G loss: 3.072383]\n",
      "epoch:34 step:26595 [D loss: 0.549397, acc: 66.41%] [G loss: 3.453667]\n",
      "epoch:34 step:26596 [D loss: 0.349173, acc: 89.06%] [G loss: 3.285793]\n",
      "epoch:34 step:26597 [D loss: 0.135608, acc: 99.22%] [G loss: 6.562524]\n",
      "epoch:34 step:26598 [D loss: 0.596374, acc: 64.84%] [G loss: 4.671643]\n",
      "epoch:34 step:26599 [D loss: 0.208374, acc: 96.09%] [G loss: 4.083162]\n",
      "epoch:34 step:26600 [D loss: 0.159079, acc: 99.22%] [G loss: 4.194032]\n",
      "##############\n",
      "[0.8769573  0.87061349 0.82493049 0.8132794  0.78897729 0.83062012\n",
      " 0.90111084 0.83024624 0.80246567 0.80865467]\n",
      "##########\n",
      "epoch:34 step:26601 [D loss: 0.738626, acc: 57.03%] [G loss: 4.073045]\n",
      "epoch:34 step:26602 [D loss: 0.237576, acc: 93.75%] [G loss: 5.031131]\n",
      "epoch:34 step:26603 [D loss: 0.765731, acc: 51.56%] [G loss: 5.367664]\n",
      "epoch:34 step:26604 [D loss: 0.407234, acc: 82.81%] [G loss: 5.569849]\n",
      "epoch:34 step:26605 [D loss: 0.387023, acc: 87.50%] [G loss: 4.753127]\n",
      "epoch:34 step:26606 [D loss: 0.109556, acc: 98.44%] [G loss: 6.514600]\n",
      "epoch:34 step:26607 [D loss: 0.123593, acc: 99.22%] [G loss: 4.294933]\n",
      "epoch:34 step:26608 [D loss: 0.211725, acc: 97.66%] [G loss: 4.629807]\n",
      "epoch:34 step:26609 [D loss: 0.065760, acc: 100.00%] [G loss: 4.710304]\n",
      "epoch:34 step:26610 [D loss: 0.067317, acc: 100.00%] [G loss: 3.808279]\n",
      "epoch:34 step:26611 [D loss: 0.054853, acc: 100.00%] [G loss: 6.479427]\n",
      "epoch:34 step:26612 [D loss: 0.200292, acc: 98.44%] [G loss: 3.846940]\n",
      "epoch:34 step:26613 [D loss: 0.038331, acc: 100.00%] [G loss: 4.732141]\n",
      "epoch:34 step:26614 [D loss: 0.597570, acc: 66.41%] [G loss: 4.790751]\n",
      "epoch:34 step:26615 [D loss: 0.200856, acc: 97.66%] [G loss: 3.050589]\n",
      "epoch:34 step:26616 [D loss: 0.528253, acc: 64.84%] [G loss: 6.535647]\n",
      "epoch:34 step:26617 [D loss: 0.471927, acc: 67.97%] [G loss: 4.153472]\n",
      "epoch:34 step:26618 [D loss: 0.518105, acc: 76.56%] [G loss: 5.064467]\n",
      "epoch:34 step:26619 [D loss: 1.431708, acc: 7.81%] [G loss: 7.211123]\n",
      "epoch:34 step:26620 [D loss: 0.144159, acc: 98.44%] [G loss: 4.315444]\n",
      "epoch:34 step:26621 [D loss: 0.524170, acc: 67.97%] [G loss: 2.566392]\n",
      "epoch:34 step:26622 [D loss: 0.196759, acc: 96.88%] [G loss: 4.079454]\n",
      "epoch:34 step:26623 [D loss: 0.706143, acc: 53.12%] [G loss: 8.443441]\n",
      "epoch:34 step:26624 [D loss: 0.821664, acc: 53.91%] [G loss: 7.487314]\n",
      "epoch:34 step:26625 [D loss: 1.077937, acc: 50.78%] [G loss: 4.060478]\n",
      "epoch:34 step:26626 [D loss: 0.493105, acc: 73.44%] [G loss: 3.891929]\n",
      "epoch:34 step:26627 [D loss: 0.322511, acc: 86.72%] [G loss: 4.902966]\n",
      "epoch:34 step:26628 [D loss: 0.519766, acc: 65.62%] [G loss: 6.371469]\n",
      "epoch:34 step:26629 [D loss: 0.338409, acc: 78.91%] [G loss: 3.619522]\n",
      "epoch:34 step:26630 [D loss: 0.381726, acc: 85.16%] [G loss: 4.329005]\n",
      "epoch:34 step:26631 [D loss: 0.596885, acc: 66.41%] [G loss: 4.552288]\n",
      "epoch:34 step:26632 [D loss: 0.217332, acc: 92.97%] [G loss: 2.997702]\n",
      "epoch:34 step:26633 [D loss: 0.151990, acc: 97.66%] [G loss: 4.205536]\n",
      "epoch:34 step:26634 [D loss: 0.614083, acc: 60.94%] [G loss: 5.144785]\n",
      "epoch:34 step:26635 [D loss: 0.338384, acc: 88.28%] [G loss: 4.897671]\n",
      "epoch:34 step:26636 [D loss: 0.240696, acc: 98.44%] [G loss: 3.597178]\n",
      "epoch:34 step:26637 [D loss: 0.551591, acc: 71.09%] [G loss: 5.038653]\n",
      "epoch:34 step:26638 [D loss: 0.340234, acc: 83.59%] [G loss: 4.906284]\n",
      "epoch:34 step:26639 [D loss: 0.545081, acc: 65.62%] [G loss: 5.330282]\n",
      "epoch:34 step:26640 [D loss: 0.737328, acc: 56.25%] [G loss: 5.773247]\n",
      "epoch:34 step:26641 [D loss: 0.429977, acc: 75.78%] [G loss: 4.965161]\n",
      "epoch:34 step:26642 [D loss: 0.232236, acc: 92.97%] [G loss: 5.987191]\n",
      "epoch:34 step:26643 [D loss: 1.102170, acc: 50.00%] [G loss: 5.904286]\n",
      "epoch:34 step:26644 [D loss: 0.237860, acc: 94.53%] [G loss: 5.012701]\n",
      "epoch:34 step:26645 [D loss: 0.053365, acc: 99.22%] [G loss: 10.472399]\n",
      "epoch:34 step:26646 [D loss: 0.062942, acc: 100.00%] [G loss: 8.013733]\n",
      "epoch:34 step:26647 [D loss: 0.118127, acc: 100.00%] [G loss: 3.641434]\n",
      "epoch:34 step:26648 [D loss: 0.392469, acc: 89.84%] [G loss: 3.379690]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:34 step:26649 [D loss: 0.651860, acc: 61.72%] [G loss: 5.209420]\n",
      "epoch:34 step:26650 [D loss: 0.088273, acc: 100.00%] [G loss: 5.042323]\n",
      "epoch:34 step:26651 [D loss: 1.006048, acc: 51.56%] [G loss: 5.078387]\n",
      "epoch:34 step:26652 [D loss: 0.390426, acc: 77.34%] [G loss: 5.908577]\n",
      "epoch:34 step:26653 [D loss: 0.331140, acc: 86.72%] [G loss: 4.332153]\n",
      "epoch:34 step:26654 [D loss: 0.435083, acc: 72.66%] [G loss: 4.086166]\n",
      "epoch:34 step:26655 [D loss: 0.118565, acc: 99.22%] [G loss: 3.111779]\n",
      "epoch:34 step:26656 [D loss: 0.123211, acc: 97.66%] [G loss: 5.486655]\n",
      "epoch:34 step:26657 [D loss: 0.324920, acc: 83.59%] [G loss: 6.369455]\n",
      "epoch:34 step:26658 [D loss: 0.189952, acc: 99.22%] [G loss: 6.351543]\n",
      "epoch:34 step:26659 [D loss: 0.093065, acc: 100.00%] [G loss: 4.809468]\n",
      "epoch:34 step:26660 [D loss: 0.494031, acc: 78.12%] [G loss: 4.190282]\n",
      "epoch:34 step:26661 [D loss: 0.092543, acc: 100.00%] [G loss: 7.133645]\n",
      "epoch:34 step:26662 [D loss: 0.106911, acc: 100.00%] [G loss: 3.700604]\n",
      "epoch:34 step:26663 [D loss: 0.208693, acc: 98.44%] [G loss: 7.888381]\n",
      "epoch:34 step:26664 [D loss: 0.081827, acc: 100.00%] [G loss: 4.659464]\n",
      "epoch:34 step:26665 [D loss: 0.448020, acc: 74.22%] [G loss: 5.511316]\n",
      "epoch:34 step:26666 [D loss: 0.361112, acc: 78.91%] [G loss: 3.623548]\n",
      "epoch:34 step:26667 [D loss: 0.911548, acc: 50.00%] [G loss: 4.928488]\n",
      "epoch:34 step:26668 [D loss: 0.239529, acc: 94.53%] [G loss: 2.233219]\n",
      "epoch:34 step:26669 [D loss: 0.773201, acc: 54.69%] [G loss: 6.073745]\n",
      "epoch:34 step:26670 [D loss: 0.742291, acc: 55.47%] [G loss: 3.675968]\n",
      "epoch:34 step:26671 [D loss: 1.734713, acc: 9.38%] [G loss: 4.546500]\n",
      "epoch:34 step:26672 [D loss: 0.033289, acc: 100.00%] [G loss: 4.411758]\n",
      "epoch:34 step:26673 [D loss: 0.590085, acc: 66.41%] [G loss: 7.147412]\n",
      "epoch:34 step:26674 [D loss: 0.188964, acc: 99.22%] [G loss: 6.039483]\n",
      "epoch:34 step:26675 [D loss: 0.491223, acc: 66.41%] [G loss: 5.724936]\n",
      "epoch:34 step:26676 [D loss: 0.114519, acc: 99.22%] [G loss: 7.296014]\n",
      "epoch:34 step:26677 [D loss: 0.233969, acc: 92.19%] [G loss: 4.362405]\n",
      "epoch:34 step:26678 [D loss: 0.108263, acc: 100.00%] [G loss: 5.087339]\n",
      "epoch:34 step:26679 [D loss: 0.101535, acc: 99.22%] [G loss: 7.966779]\n",
      "epoch:34 step:26680 [D loss: 0.073046, acc: 100.00%] [G loss: 4.609555]\n",
      "epoch:34 step:26681 [D loss: 0.212790, acc: 95.31%] [G loss: 5.271791]\n",
      "epoch:34 step:26682 [D loss: 1.478655, acc: 9.38%] [G loss: 8.001173]\n",
      "epoch:34 step:26683 [D loss: 0.639620, acc: 62.50%] [G loss: 6.758636]\n",
      "epoch:34 step:26684 [D loss: 0.214241, acc: 96.88%] [G loss: 3.181341]\n",
      "epoch:34 step:26685 [D loss: 1.431446, acc: 7.81%] [G loss: 4.536462]\n",
      "epoch:34 step:26686 [D loss: 0.364979, acc: 78.91%] [G loss: 6.037464]\n",
      "epoch:34 step:26687 [D loss: 1.121148, acc: 44.53%] [G loss: 4.012784]\n",
      "epoch:34 step:26688 [D loss: 0.535779, acc: 76.56%] [G loss: 3.910588]\n",
      "epoch:34 step:26689 [D loss: 0.335926, acc: 89.06%] [G loss: 4.736680]\n",
      "epoch:34 step:26690 [D loss: 0.149825, acc: 99.22%] [G loss: 4.632788]\n",
      "epoch:34 step:26691 [D loss: 0.087202, acc: 99.22%] [G loss: 5.964239]\n",
      "epoch:34 step:26692 [D loss: 0.212330, acc: 93.75%] [G loss: 6.951826]\n",
      "epoch:34 step:26693 [D loss: 0.659448, acc: 57.81%] [G loss: 6.346744]\n",
      "epoch:34 step:26694 [D loss: 0.205748, acc: 96.88%] [G loss: 5.297000]\n",
      "epoch:34 step:26695 [D loss: 0.405302, acc: 78.12%] [G loss: 3.146849]\n",
      "epoch:34 step:26696 [D loss: 0.284447, acc: 95.31%] [G loss: 5.015227]\n",
      "epoch:34 step:26697 [D loss: 0.155536, acc: 100.00%] [G loss: 6.579993]\n",
      "epoch:34 step:26698 [D loss: 0.417175, acc: 83.59%] [G loss: 5.092822]\n",
      "epoch:34 step:26699 [D loss: 0.583962, acc: 61.72%] [G loss: 5.891574]\n",
      "epoch:34 step:26700 [D loss: 0.044796, acc: 100.00%] [G loss: 6.299924]\n",
      "epoch:34 step:26701 [D loss: 0.283781, acc: 85.16%] [G loss: 7.543253]\n",
      "epoch:34 step:26702 [D loss: 0.325543, acc: 90.62%] [G loss: 3.040267]\n",
      "epoch:34 step:26703 [D loss: 0.626924, acc: 57.81%] [G loss: 7.090012]\n",
      "epoch:34 step:26704 [D loss: 0.225094, acc: 93.75%] [G loss: 2.718536]\n",
      "epoch:34 step:26705 [D loss: 0.360269, acc: 78.12%] [G loss: 5.132155]\n",
      "epoch:34 step:26706 [D loss: 0.364517, acc: 87.50%] [G loss: 5.834649]\n",
      "epoch:34 step:26707 [D loss: 0.211601, acc: 93.75%] [G loss: 7.684814]\n",
      "epoch:34 step:26708 [D loss: 0.266741, acc: 91.41%] [G loss: 5.036912]\n",
      "epoch:34 step:26709 [D loss: 0.792458, acc: 49.22%] [G loss: 9.255498]\n",
      "epoch:34 step:26710 [D loss: 0.309829, acc: 92.97%] [G loss: 3.904583]\n",
      "epoch:34 step:26711 [D loss: 0.063538, acc: 100.00%] [G loss: 6.039082]\n",
      "epoch:34 step:26712 [D loss: 0.350478, acc: 81.25%] [G loss: 6.206660]\n",
      "epoch:34 step:26713 [D loss: 0.128478, acc: 99.22%] [G loss: 4.962029]\n",
      "epoch:34 step:26714 [D loss: 1.193418, acc: 17.19%] [G loss: 3.312310]\n",
      "epoch:34 step:26715 [D loss: 0.239661, acc: 96.09%] [G loss: 3.309860]\n",
      "epoch:34 step:26716 [D loss: 0.364549, acc: 78.12%] [G loss: 5.863426]\n",
      "epoch:34 step:26717 [D loss: 0.360767, acc: 78.91%] [G loss: 1.631600]\n",
      "epoch:34 step:26718 [D loss: 0.799202, acc: 51.56%] [G loss: 4.051096]\n",
      "epoch:34 step:26719 [D loss: 0.138285, acc: 100.00%] [G loss: 6.394129]\n",
      "epoch:34 step:26720 [D loss: 0.232436, acc: 97.66%] [G loss: 4.619106]\n",
      "epoch:34 step:26721 [D loss: 0.260467, acc: 98.44%] [G loss: 3.296734]\n",
      "epoch:34 step:26722 [D loss: 0.531701, acc: 71.09%] [G loss: 4.005983]\n",
      "epoch:34 step:26723 [D loss: 0.166520, acc: 97.66%] [G loss: 3.957784]\n",
      "epoch:34 step:26724 [D loss: 0.261003, acc: 95.31%] [G loss: 5.293855]\n",
      "epoch:34 step:26725 [D loss: 0.725911, acc: 53.12%] [G loss: 4.038932]\n",
      "epoch:34 step:26726 [D loss: 0.209391, acc: 97.66%] [G loss: 3.297568]\n",
      "epoch:34 step:26727 [D loss: 0.617998, acc: 64.84%] [G loss: 5.637641]\n",
      "epoch:34 step:26728 [D loss: 0.603396, acc: 54.69%] [G loss: 5.835317]\n",
      "epoch:34 step:26729 [D loss: 0.285802, acc: 93.75%] [G loss: 8.556948]\n",
      "epoch:34 step:26730 [D loss: 0.108239, acc: 100.00%] [G loss: 3.604285]\n",
      "epoch:34 step:26731 [D loss: 0.163004, acc: 97.66%] [G loss: 4.276501]\n",
      "epoch:34 step:26732 [D loss: 0.249326, acc: 95.31%] [G loss: 4.291673]\n",
      "epoch:34 step:26733 [D loss: 0.494970, acc: 65.62%] [G loss: 3.488883]\n",
      "epoch:34 step:26734 [D loss: 0.070659, acc: 100.00%] [G loss: 5.041230]\n",
      "epoch:34 step:26735 [D loss: 0.712066, acc: 55.47%] [G loss: 4.744181]\n",
      "epoch:34 step:26736 [D loss: 0.163295, acc: 99.22%] [G loss: 5.148520]\n",
      "epoch:34 step:26737 [D loss: 0.210381, acc: 95.31%] [G loss: 5.854157]\n",
      "epoch:34 step:26738 [D loss: 0.364404, acc: 83.59%] [G loss: 4.353464]\n",
      "epoch:34 step:26739 [D loss: 0.651910, acc: 64.06%] [G loss: 5.604971]\n",
      "epoch:34 step:26740 [D loss: 0.094022, acc: 100.00%] [G loss: 3.946859]\n",
      "epoch:34 step:26741 [D loss: 0.299013, acc: 93.75%] [G loss: 3.367505]\n",
      "epoch:34 step:26742 [D loss: 0.103566, acc: 98.44%] [G loss: 5.459121]\n",
      "epoch:34 step:26743 [D loss: 0.800777, acc: 50.00%] [G loss: 7.074875]\n",
      "epoch:34 step:26744 [D loss: 0.654154, acc: 62.50%] [G loss: 6.118539]\n",
      "epoch:34 step:26745 [D loss: 0.301467, acc: 89.84%] [G loss: 7.530822]\n",
      "epoch:34 step:26746 [D loss: 0.238532, acc: 92.19%] [G loss: 4.244956]\n",
      "epoch:34 step:26747 [D loss: 0.117561, acc: 100.00%] [G loss: 4.835775]\n",
      "epoch:34 step:26748 [D loss: 0.495534, acc: 73.44%] [G loss: 4.632351]\n",
      "epoch:34 step:26749 [D loss: 0.275080, acc: 94.53%] [G loss: 2.951287]\n",
      "epoch:34 step:26750 [D loss: 0.727809, acc: 57.81%] [G loss: 2.242000]\n",
      "epoch:34 step:26751 [D loss: 0.854966, acc: 51.56%] [G loss: 6.142000]\n",
      "epoch:34 step:26752 [D loss: 0.462052, acc: 63.28%] [G loss: 4.928946]\n",
      "epoch:34 step:26753 [D loss: 0.408165, acc: 74.22%] [G loss: 5.000288]\n",
      "epoch:34 step:26754 [D loss: 0.017666, acc: 100.00%] [G loss: 4.172056]\n",
      "epoch:34 step:26755 [D loss: 0.505364, acc: 65.62%] [G loss: 5.075647]\n",
      "epoch:34 step:26756 [D loss: 0.153220, acc: 98.44%] [G loss: 3.583397]\n",
      "epoch:34 step:26757 [D loss: 0.063210, acc: 100.00%] [G loss: 3.059041]\n",
      "epoch:34 step:26758 [D loss: 2.080634, acc: 50.00%] [G loss: 3.613917]\n",
      "epoch:34 step:26759 [D loss: 0.285809, acc: 87.50%] [G loss: 4.521332]\n",
      "epoch:34 step:26760 [D loss: 0.129221, acc: 100.00%] [G loss: 5.605691]\n",
      "epoch:34 step:26761 [D loss: 0.121240, acc: 100.00%] [G loss: 5.533066]\n",
      "epoch:34 step:26762 [D loss: 0.309805, acc: 92.97%] [G loss: 2.626531]\n",
      "epoch:34 step:26763 [D loss: 0.384541, acc: 83.59%] [G loss: 3.451262]\n",
      "epoch:34 step:26764 [D loss: 0.710130, acc: 54.69%] [G loss: 3.003748]\n",
      "epoch:34 step:26765 [D loss: 0.218136, acc: 96.09%] [G loss: 8.486955]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:34 step:26766 [D loss: 0.077930, acc: 100.00%] [G loss: 4.667679]\n",
      "epoch:34 step:26767 [D loss: 0.295988, acc: 84.38%] [G loss: 5.017922]\n",
      "epoch:34 step:26768 [D loss: 0.266401, acc: 92.97%] [G loss: 5.116579]\n",
      "epoch:34 step:26769 [D loss: 0.585518, acc: 70.31%] [G loss: 4.864277]\n",
      "epoch:34 step:26770 [D loss: 0.182251, acc: 98.44%] [G loss: 3.894632]\n",
      "epoch:34 step:26771 [D loss: 0.339158, acc: 82.81%] [G loss: 4.317978]\n",
      "epoch:34 step:26772 [D loss: 0.078652, acc: 100.00%] [G loss: 2.550343]\n",
      "epoch:34 step:26773 [D loss: 0.295879, acc: 91.41%] [G loss: 4.058755]\n",
      "epoch:34 step:26774 [D loss: 0.098506, acc: 100.00%] [G loss: 2.530797]\n",
      "epoch:34 step:26775 [D loss: 0.172962, acc: 98.44%] [G loss: 4.492528]\n",
      "epoch:34 step:26776 [D loss: 0.331469, acc: 87.50%] [G loss: 7.497200]\n",
      "epoch:34 step:26777 [D loss: 0.290037, acc: 95.31%] [G loss: 2.758691]\n",
      "epoch:34 step:26778 [D loss: 0.449226, acc: 75.00%] [G loss: 7.123415]\n",
      "epoch:34 step:26779 [D loss: 0.924712, acc: 52.34%] [G loss: 3.912215]\n",
      "epoch:34 step:26780 [D loss: 0.026140, acc: 100.00%] [G loss: 4.984246]\n",
      "epoch:34 step:26781 [D loss: 0.205904, acc: 96.88%] [G loss: 5.087857]\n",
      "epoch:34 step:26782 [D loss: 0.431777, acc: 85.94%] [G loss: 3.329946]\n",
      "epoch:34 step:26783 [D loss: 0.459493, acc: 75.78%] [G loss: 5.193274]\n",
      "epoch:34 step:26784 [D loss: 0.582494, acc: 60.94%] [G loss: 7.244465]\n",
      "epoch:34 step:26785 [D loss: 0.299499, acc: 97.66%] [G loss: 5.134071]\n",
      "epoch:34 step:26786 [D loss: 0.474547, acc: 76.56%] [G loss: 3.006663]\n",
      "epoch:34 step:26787 [D loss: 0.696474, acc: 53.91%] [G loss: 4.774080]\n",
      "epoch:34 step:26788 [D loss: 0.284604, acc: 91.41%] [G loss: 5.752402]\n",
      "epoch:34 step:26789 [D loss: 1.729149, acc: 46.09%] [G loss: 5.510326]\n",
      "epoch:34 step:26790 [D loss: 0.742436, acc: 58.59%] [G loss: 6.398159]\n",
      "epoch:34 step:26791 [D loss: 0.176224, acc: 96.09%] [G loss: 5.036195]\n",
      "epoch:34 step:26792 [D loss: 0.262047, acc: 96.88%] [G loss: 1.989541]\n",
      "epoch:34 step:26793 [D loss: 0.078514, acc: 100.00%] [G loss: 4.233531]\n",
      "epoch:34 step:26794 [D loss: 0.662056, acc: 61.72%] [G loss: 2.627199]\n",
      "epoch:34 step:26795 [D loss: 0.407261, acc: 84.38%] [G loss: 6.459254]\n",
      "epoch:34 step:26796 [D loss: 0.147595, acc: 98.44%] [G loss: 5.098331]\n",
      "epoch:34 step:26797 [D loss: 0.270603, acc: 92.97%] [G loss: 5.260397]\n",
      "epoch:34 step:26798 [D loss: 0.085652, acc: 100.00%] [G loss: 2.433311]\n",
      "epoch:34 step:26799 [D loss: 0.103627, acc: 98.44%] [G loss: 4.899586]\n",
      "epoch:34 step:26800 [D loss: 0.871645, acc: 46.88%] [G loss: 4.668235]\n",
      "##############\n",
      "[0.87285215 0.86487    0.83650077 0.81833134 0.79682875 0.83902821\n",
      " 0.89047591 0.81723618 0.81522308 0.80682446]\n",
      "##########\n",
      "epoch:34 step:26801 [D loss: 0.098648, acc: 100.00%] [G loss: 6.510093]\n",
      "epoch:34 step:26802 [D loss: 0.368627, acc: 91.41%] [G loss: 4.045128]\n",
      "epoch:34 step:26803 [D loss: 0.026656, acc: 100.00%] [G loss: 7.318254]\n",
      "epoch:34 step:26804 [D loss: 0.029345, acc: 100.00%] [G loss: 4.392198]\n",
      "epoch:34 step:26805 [D loss: 0.030379, acc: 100.00%] [G loss: 5.967360]\n",
      "epoch:34 step:26806 [D loss: 0.286994, acc: 87.50%] [G loss: 6.448236]\n",
      "epoch:34 step:26807 [D loss: 1.094140, acc: 36.72%] [G loss: 4.628162]\n",
      "epoch:34 step:26808 [D loss: 0.119109, acc: 98.44%] [G loss: 4.611277]\n",
      "epoch:34 step:26809 [D loss: 0.385024, acc: 86.72%] [G loss: 4.525705]\n",
      "epoch:34 step:26810 [D loss: 0.125619, acc: 100.00%] [G loss: 7.339423]\n",
      "epoch:34 step:26811 [D loss: 0.273005, acc: 89.84%] [G loss: 3.105727]\n",
      "epoch:34 step:26812 [D loss: 0.215472, acc: 96.88%] [G loss: 4.965108]\n",
      "epoch:34 step:26813 [D loss: 0.467799, acc: 74.22%] [G loss: 2.269155]\n",
      "epoch:34 step:26814 [D loss: 0.584165, acc: 66.41%] [G loss: 3.971880]\n",
      "epoch:34 step:26815 [D loss: 0.845961, acc: 52.34%] [G loss: 3.769633]\n",
      "epoch:34 step:26816 [D loss: 0.391448, acc: 78.12%] [G loss: 6.934686]\n",
      "epoch:34 step:26817 [D loss: 0.280531, acc: 89.84%] [G loss: 3.333350]\n",
      "epoch:34 step:26818 [D loss: 0.447266, acc: 82.03%] [G loss: 5.322520]\n",
      "epoch:34 step:26819 [D loss: 0.084254, acc: 100.00%] [G loss: 3.468390]\n",
      "epoch:34 step:26820 [D loss: 0.739501, acc: 46.88%] [G loss: 5.149673]\n",
      "epoch:34 step:26821 [D loss: 0.418125, acc: 87.50%] [G loss: 3.175690]\n",
      "epoch:34 step:26822 [D loss: 0.376450, acc: 89.84%] [G loss: 2.706812]\n",
      "epoch:34 step:26823 [D loss: 0.274998, acc: 98.44%] [G loss: 4.610265]\n",
      "epoch:34 step:26824 [D loss: 0.927830, acc: 38.28%] [G loss: 6.586176]\n",
      "epoch:34 step:26825 [D loss: 0.239282, acc: 91.41%] [G loss: 5.049163]\n",
      "epoch:34 step:26826 [D loss: 0.067309, acc: 100.00%] [G loss: 3.670269]\n",
      "epoch:34 step:26827 [D loss: 0.108811, acc: 100.00%] [G loss: 6.177586]\n",
      "epoch:34 step:26828 [D loss: 0.084894, acc: 99.22%] [G loss: 5.359281]\n",
      "epoch:34 step:26829 [D loss: 0.643542, acc: 60.94%] [G loss: 6.592978]\n",
      "epoch:34 step:26830 [D loss: 0.429564, acc: 86.72%] [G loss: 6.994946]\n",
      "epoch:34 step:26831 [D loss: 0.597182, acc: 59.38%] [G loss: 9.352392]\n",
      "epoch:34 step:26832 [D loss: 0.954097, acc: 50.78%] [G loss: 5.001202]\n",
      "epoch:34 step:26833 [D loss: 0.119620, acc: 99.22%] [G loss: 5.492167]\n",
      "epoch:34 step:26834 [D loss: 0.529311, acc: 65.62%] [G loss: 2.687591]\n",
      "epoch:34 step:26835 [D loss: 0.207681, acc: 97.66%] [G loss: 2.826388]\n",
      "epoch:34 step:26836 [D loss: 0.425347, acc: 78.91%] [G loss: 4.934752]\n",
      "epoch:34 step:26837 [D loss: 0.267628, acc: 95.31%] [G loss: 3.564611]\n",
      "epoch:34 step:26838 [D loss: 0.306430, acc: 93.75%] [G loss: 5.094191]\n",
      "epoch:34 step:26839 [D loss: 0.146927, acc: 98.44%] [G loss: 5.915376]\n",
      "epoch:34 step:26840 [D loss: 0.720074, acc: 56.25%] [G loss: 5.766297]\n",
      "epoch:34 step:26841 [D loss: 0.120127, acc: 97.66%] [G loss: 3.999681]\n",
      "epoch:34 step:26842 [D loss: 0.265905, acc: 96.09%] [G loss: 3.148925]\n",
      "epoch:34 step:26843 [D loss: 0.317431, acc: 85.94%] [G loss: 4.111243]\n",
      "epoch:34 step:26844 [D loss: 0.271917, acc: 96.09%] [G loss: 3.980334]\n",
      "epoch:34 step:26845 [D loss: 0.216473, acc: 96.09%] [G loss: 4.807069]\n",
      "epoch:34 step:26846 [D loss: 0.040367, acc: 100.00%] [G loss: 5.757004]\n",
      "epoch:34 step:26847 [D loss: 0.438980, acc: 83.59%] [G loss: 6.676657]\n",
      "epoch:34 step:26848 [D loss: 0.096853, acc: 100.00%] [G loss: 4.860606]\n",
      "epoch:34 step:26849 [D loss: 0.829033, acc: 53.12%] [G loss: 4.067258]\n",
      "epoch:34 step:26850 [D loss: 0.043512, acc: 100.00%] [G loss: 8.313107]\n",
      "epoch:34 step:26851 [D loss: 0.707634, acc: 53.12%] [G loss: 6.765052]\n",
      "epoch:34 step:26852 [D loss: 0.348281, acc: 92.19%] [G loss: 4.294500]\n",
      "epoch:34 step:26853 [D loss: 0.050569, acc: 99.22%] [G loss: 3.782272]\n",
      "epoch:34 step:26854 [D loss: 0.460838, acc: 67.97%] [G loss: 4.070286]\n",
      "epoch:34 step:26855 [D loss: 0.209031, acc: 96.09%] [G loss: 2.768829]\n",
      "epoch:34 step:26856 [D loss: 0.212020, acc: 98.44%] [G loss: 5.969844]\n",
      "epoch:34 step:26857 [D loss: 1.487082, acc: 8.59%] [G loss: 8.989079]\n",
      "epoch:34 step:26858 [D loss: 0.574197, acc: 67.97%] [G loss: 3.992520]\n",
      "epoch:34 step:26859 [D loss: 1.277376, acc: 50.00%] [G loss: 4.038438]\n",
      "epoch:34 step:26860 [D loss: 0.063693, acc: 100.00%] [G loss: 5.396054]\n",
      "epoch:34 step:26861 [D loss: 1.302136, acc: 50.00%] [G loss: 3.750772]\n",
      "epoch:34 step:26862 [D loss: 0.590216, acc: 65.62%] [G loss: 3.364421]\n",
      "epoch:34 step:26863 [D loss: 0.339680, acc: 82.81%] [G loss: 2.543562]\n",
      "epoch:34 step:26864 [D loss: 0.878539, acc: 51.56%] [G loss: 6.407643]\n",
      "epoch:34 step:26865 [D loss: 0.765971, acc: 54.69%] [G loss: 4.226135]\n",
      "epoch:34 step:26866 [D loss: 0.566959, acc: 70.31%] [G loss: 5.010343]\n",
      "epoch:34 step:26867 [D loss: 0.308165, acc: 92.19%] [G loss: 3.686583]\n",
      "epoch:34 step:26868 [D loss: 0.029925, acc: 100.00%] [G loss: 5.550724]\n",
      "epoch:34 step:26869 [D loss: 0.118826, acc: 100.00%] [G loss: 5.243586]\n",
      "epoch:34 step:26870 [D loss: 0.311500, acc: 90.62%] [G loss: 4.937089]\n",
      "epoch:34 step:26871 [D loss: 0.193472, acc: 96.09%] [G loss: 4.945264]\n",
      "epoch:34 step:26872 [D loss: 0.423486, acc: 81.25%] [G loss: 3.894816]\n",
      "epoch:34 step:26873 [D loss: 0.906690, acc: 47.66%] [G loss: 4.279978]\n",
      "epoch:34 step:26874 [D loss: 0.718545, acc: 53.91%] [G loss: 6.028328]\n",
      "epoch:34 step:26875 [D loss: 0.200849, acc: 100.00%] [G loss: 3.905842]\n",
      "epoch:34 step:26876 [D loss: 0.239349, acc: 94.53%] [G loss: 4.717517]\n",
      "epoch:34 step:26877 [D loss: 0.328074, acc: 92.97%] [G loss: 3.395430]\n",
      "epoch:34 step:26878 [D loss: 0.066474, acc: 100.00%] [G loss: 5.442150]\n",
      "epoch:34 step:26879 [D loss: 0.069624, acc: 100.00%] [G loss: 3.354757]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:34 step:26880 [D loss: 0.199774, acc: 100.00%] [G loss: 5.055740]\n",
      "epoch:34 step:26881 [D loss: 1.249105, acc: 21.88%] [G loss: 4.833101]\n",
      "epoch:34 step:26882 [D loss: 0.633898, acc: 71.88%] [G loss: 4.233867]\n",
      "epoch:34 step:26883 [D loss: 0.082908, acc: 100.00%] [G loss: 8.285410]\n",
      "epoch:34 step:26884 [D loss: 0.119585, acc: 99.22%] [G loss: 6.602961]\n",
      "epoch:34 step:26885 [D loss: 0.405753, acc: 89.84%] [G loss: 6.739890]\n",
      "epoch:34 step:26886 [D loss: 0.492305, acc: 76.56%] [G loss: 4.051092]\n",
      "epoch:34 step:26887 [D loss: 0.199472, acc: 94.53%] [G loss: 4.352456]\n",
      "epoch:34 step:26888 [D loss: 0.232732, acc: 94.53%] [G loss: 4.229506]\n",
      "epoch:34 step:26889 [D loss: 0.063763, acc: 100.00%] [G loss: 4.420562]\n",
      "epoch:34 step:26890 [D loss: 0.640949, acc: 60.94%] [G loss: 3.975845]\n",
      "epoch:34 step:26891 [D loss: 0.965805, acc: 51.56%] [G loss: 7.847054]\n",
      "epoch:34 step:26892 [D loss: 0.275148, acc: 96.09%] [G loss: 3.714228]\n",
      "epoch:34 step:26893 [D loss: 0.232378, acc: 97.66%] [G loss: 5.883011]\n",
      "epoch:34 step:26894 [D loss: 0.136720, acc: 98.44%] [G loss: 3.805327]\n",
      "epoch:34 step:26895 [D loss: 0.303263, acc: 92.97%] [G loss: 6.482291]\n",
      "epoch:34 step:26896 [D loss: 0.056915, acc: 100.00%] [G loss: 6.083227]\n",
      "epoch:34 step:26897 [D loss: 0.329111, acc: 85.16%] [G loss: 5.825451]\n",
      "epoch:34 step:26898 [D loss: 0.260120, acc: 93.75%] [G loss: 2.922088]\n",
      "epoch:34 step:26899 [D loss: 0.256721, acc: 94.53%] [G loss: 5.414642]\n",
      "epoch:34 step:26900 [D loss: 0.037013, acc: 100.00%] [G loss: 5.970618]\n",
      "epoch:34 step:26901 [D loss: 0.174960, acc: 99.22%] [G loss: 5.946842]\n",
      "epoch:34 step:26902 [D loss: 0.531084, acc: 69.53%] [G loss: 5.176911]\n",
      "epoch:34 step:26903 [D loss: 0.523224, acc: 61.72%] [G loss: 6.088225]\n",
      "epoch:34 step:26904 [D loss: 0.858572, acc: 48.44%] [G loss: 4.288043]\n",
      "epoch:34 step:26905 [D loss: 0.441445, acc: 82.03%] [G loss: 3.819470]\n",
      "epoch:34 step:26906 [D loss: 0.419281, acc: 85.16%] [G loss: 5.310790]\n",
      "epoch:34 step:26907 [D loss: 0.184345, acc: 99.22%] [G loss: 3.302157]\n",
      "epoch:34 step:26908 [D loss: 0.382865, acc: 89.84%] [G loss: 4.022719]\n",
      "epoch:34 step:26909 [D loss: 0.490944, acc: 68.75%] [G loss: 2.422757]\n",
      "epoch:34 step:26910 [D loss: 0.388795, acc: 92.19%] [G loss: 3.258802]\n",
      "epoch:34 step:26911 [D loss: 0.222242, acc: 97.66%] [G loss: 4.148211]\n",
      "epoch:34 step:26912 [D loss: 0.152754, acc: 96.88%] [G loss: 4.765152]\n",
      "epoch:34 step:26913 [D loss: 0.053301, acc: 100.00%] [G loss: 2.747287]\n",
      "epoch:34 step:26914 [D loss: 0.096155, acc: 100.00%] [G loss: 4.587460]\n",
      "epoch:34 step:26915 [D loss: 0.348038, acc: 88.28%] [G loss: 6.864014]\n",
      "epoch:34 step:26916 [D loss: 0.316442, acc: 91.41%] [G loss: 5.734358]\n",
      "epoch:34 step:26917 [D loss: 0.542475, acc: 64.06%] [G loss: 4.227467]\n",
      "epoch:34 step:26918 [D loss: 0.298529, acc: 92.97%] [G loss: 4.815599]\n",
      "epoch:34 step:26919 [D loss: 0.248103, acc: 95.31%] [G loss: 7.188983]\n",
      "epoch:34 step:26920 [D loss: 0.985336, acc: 39.84%] [G loss: 4.945910]\n",
      "epoch:34 step:26921 [D loss: 0.252676, acc: 95.31%] [G loss: 4.271640]\n",
      "epoch:34 step:26922 [D loss: 0.118522, acc: 100.00%] [G loss: 5.294616]\n",
      "epoch:34 step:26923 [D loss: 0.249199, acc: 95.31%] [G loss: 3.407281]\n",
      "epoch:34 step:26924 [D loss: 0.428832, acc: 84.38%] [G loss: 3.588566]\n",
      "epoch:34 step:26925 [D loss: 0.418988, acc: 89.06%] [G loss: 5.179348]\n",
      "epoch:34 step:26926 [D loss: 0.140380, acc: 99.22%] [G loss: 7.672309]\n",
      "epoch:34 step:26927 [D loss: 0.299408, acc: 87.50%] [G loss: 5.435209]\n",
      "epoch:34 step:26928 [D loss: 0.360427, acc: 89.06%] [G loss: 3.867918]\n",
      "epoch:34 step:26929 [D loss: 0.099357, acc: 100.00%] [G loss: 6.366312]\n",
      "epoch:34 step:26930 [D loss: 0.119559, acc: 98.44%] [G loss: 4.215104]\n",
      "epoch:34 step:26931 [D loss: 0.124222, acc: 100.00%] [G loss: 4.628029]\n",
      "epoch:34 step:26932 [D loss: 0.537817, acc: 73.44%] [G loss: 4.754374]\n",
      "epoch:34 step:26933 [D loss: 0.195477, acc: 98.44%] [G loss: 5.928061]\n",
      "epoch:34 step:26934 [D loss: 0.134602, acc: 100.00%] [G loss: 4.855865]\n",
      "epoch:34 step:26935 [D loss: 0.301771, acc: 92.97%] [G loss: 3.695714]\n",
      "epoch:34 step:26936 [D loss: 0.532766, acc: 69.53%] [G loss: 4.761751]\n",
      "epoch:34 step:26937 [D loss: 0.196059, acc: 96.88%] [G loss: 3.957344]\n",
      "epoch:34 step:26938 [D loss: 0.320587, acc: 88.28%] [G loss: 2.689330]\n",
      "epoch:34 step:26939 [D loss: 0.081855, acc: 100.00%] [G loss: 6.215240]\n",
      "epoch:34 step:26940 [D loss: 0.630514, acc: 61.72%] [G loss: 5.145443]\n",
      "epoch:34 step:26941 [D loss: 0.064533, acc: 99.22%] [G loss: 4.146683]\n",
      "epoch:34 step:26942 [D loss: 0.306375, acc: 87.50%] [G loss: 2.343600]\n",
      "epoch:34 step:26943 [D loss: 0.505932, acc: 72.66%] [G loss: 3.923025]\n",
      "epoch:34 step:26944 [D loss: 1.548767, acc: 47.66%] [G loss: 6.856445]\n",
      "epoch:34 step:26945 [D loss: 0.825965, acc: 53.12%] [G loss: 6.314074]\n",
      "epoch:34 step:26946 [D loss: 0.437865, acc: 69.53%] [G loss: 6.670755]\n",
      "epoch:34 step:26947 [D loss: 0.405355, acc: 86.72%] [G loss: 5.870816]\n",
      "epoch:34 step:26948 [D loss: 0.881987, acc: 53.12%] [G loss: 2.108756]\n",
      "epoch:34 step:26949 [D loss: 0.175684, acc: 96.88%] [G loss: 3.305634]\n",
      "epoch:34 step:26950 [D loss: 0.246050, acc: 89.06%] [G loss: 7.170152]\n",
      "epoch:34 step:26951 [D loss: 0.330748, acc: 91.41%] [G loss: 5.732266]\n",
      "epoch:34 step:26952 [D loss: 0.382380, acc: 80.47%] [G loss: 7.640449]\n",
      "epoch:34 step:26953 [D loss: 0.359943, acc: 85.16%] [G loss: 6.690345]\n",
      "epoch:34 step:26954 [D loss: 0.114261, acc: 99.22%] [G loss: 7.593860]\n",
      "epoch:34 step:26955 [D loss: 0.468959, acc: 65.62%] [G loss: 5.287883]\n",
      "epoch:34 step:26956 [D loss: 0.664743, acc: 55.47%] [G loss: 8.489439]\n",
      "epoch:34 step:26957 [D loss: 0.830213, acc: 44.53%] [G loss: 6.443801]\n",
      "epoch:34 step:26958 [D loss: 0.332831, acc: 87.50%] [G loss: 4.551531]\n",
      "epoch:34 step:26959 [D loss: 0.203408, acc: 95.31%] [G loss: 5.020392]\n",
      "epoch:34 step:26960 [D loss: 0.382146, acc: 81.25%] [G loss: 3.804968]\n",
      "epoch:34 step:26961 [D loss: 0.255144, acc: 90.62%] [G loss: 7.350221]\n",
      "epoch:34 step:26962 [D loss: 0.452141, acc: 72.66%] [G loss: 6.348989]\n",
      "epoch:34 step:26963 [D loss: 0.407412, acc: 72.66%] [G loss: 6.050553]\n",
      "epoch:34 step:26964 [D loss: 0.303586, acc: 93.75%] [G loss: 4.087473]\n",
      "epoch:34 step:26965 [D loss: 0.138104, acc: 98.44%] [G loss: 3.770050]\n",
      "epoch:34 step:26966 [D loss: 0.153258, acc: 100.00%] [G loss: 5.355822]\n",
      "epoch:34 step:26967 [D loss: 0.378781, acc: 83.59%] [G loss: 5.079300]\n",
      "epoch:34 step:26968 [D loss: 0.581012, acc: 63.28%] [G loss: 7.490192]\n",
      "epoch:34 step:26969 [D loss: 0.295671, acc: 93.75%] [G loss: 6.159450]\n",
      "epoch:34 step:26970 [D loss: 0.371492, acc: 89.84%] [G loss: 3.456445]\n",
      "epoch:34 step:26971 [D loss: 0.084663, acc: 100.00%] [G loss: 6.827638]\n",
      "epoch:34 step:26972 [D loss: 0.125769, acc: 99.22%] [G loss: 6.026742]\n",
      "epoch:34 step:26973 [D loss: 0.287694, acc: 88.28%] [G loss: 6.853436]\n",
      "epoch:34 step:26974 [D loss: 0.106443, acc: 100.00%] [G loss: 3.773022]\n",
      "epoch:34 step:26975 [D loss: 0.116698, acc: 100.00%] [G loss: 3.745685]\n",
      "epoch:34 step:26976 [D loss: 0.673585, acc: 54.69%] [G loss: 6.130930]\n",
      "epoch:34 step:26977 [D loss: 0.099256, acc: 99.22%] [G loss: 3.241836]\n",
      "epoch:34 step:26978 [D loss: 0.866454, acc: 51.56%] [G loss: 4.643110]\n",
      "epoch:34 step:26979 [D loss: 1.521950, acc: 26.56%] [G loss: 6.270332]\n",
      "epoch:34 step:26980 [D loss: 0.081109, acc: 99.22%] [G loss: 4.725076]\n",
      "epoch:34 step:26981 [D loss: 0.366901, acc: 80.47%] [G loss: 6.909282]\n",
      "epoch:34 step:26982 [D loss: 0.180197, acc: 95.31%] [G loss: 7.349538]\n",
      "epoch:34 step:26983 [D loss: 0.702556, acc: 60.16%] [G loss: 6.376798]\n",
      "epoch:34 step:26984 [D loss: 0.987867, acc: 51.56%] [G loss: 5.102861]\n",
      "epoch:34 step:26985 [D loss: 0.343359, acc: 90.62%] [G loss: 4.670135]\n",
      "epoch:34 step:26986 [D loss: 0.340009, acc: 91.41%] [G loss: 5.227572]\n",
      "epoch:34 step:26987 [D loss: 0.989466, acc: 31.25%] [G loss: 4.254023]\n",
      "epoch:34 step:26988 [D loss: 0.133660, acc: 98.44%] [G loss: 5.058079]\n",
      "epoch:34 step:26989 [D loss: 0.090304, acc: 100.00%] [G loss: 6.462157]\n",
      "epoch:34 step:26990 [D loss: 0.258666, acc: 95.31%] [G loss: 2.315837]\n",
      "epoch:34 step:26991 [D loss: 0.103619, acc: 100.00%] [G loss: 2.332269]\n",
      "epoch:34 step:26992 [D loss: 0.725813, acc: 51.56%] [G loss: 5.187847]\n",
      "epoch:34 step:26993 [D loss: 0.196787, acc: 98.44%] [G loss: 5.897197]\n",
      "epoch:34 step:26994 [D loss: 0.109176, acc: 98.44%] [G loss: 4.029567]\n",
      "epoch:34 step:26995 [D loss: 0.329717, acc: 85.16%] [G loss: 5.283778]\n",
      "epoch:34 step:26996 [D loss: 0.637891, acc: 55.47%] [G loss: 6.228141]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:34 step:26997 [D loss: 0.307276, acc: 90.62%] [G loss: 3.694191]\n",
      "epoch:34 step:26998 [D loss: 0.451586, acc: 65.62%] [G loss: 8.126467]\n",
      "epoch:34 step:26999 [D loss: 0.379075, acc: 78.12%] [G loss: 3.257970]\n",
      "epoch:34 step:27000 [D loss: 0.225061, acc: 96.09%] [G loss: 3.811065]\n",
      "##############\n",
      "[0.88074648 0.87045735 0.7999229  0.8222589  0.80272954 0.82450223\n",
      " 0.89017487 0.82046673 0.81081191 0.82588185]\n",
      "##########\n",
      "epoch:34 step:27001 [D loss: 0.187751, acc: 99.22%] [G loss: 6.324597]\n",
      "epoch:34 step:27002 [D loss: 0.192592, acc: 95.31%] [G loss: 3.650972]\n",
      "epoch:34 step:27003 [D loss: 0.853241, acc: 45.31%] [G loss: 4.890688]\n",
      "epoch:34 step:27004 [D loss: 0.240079, acc: 95.31%] [G loss: 5.852602]\n",
      "epoch:34 step:27005 [D loss: 0.022810, acc: 100.00%] [G loss: 6.062334]\n",
      "epoch:34 step:27006 [D loss: 0.441132, acc: 82.81%] [G loss: 3.468014]\n",
      "epoch:34 step:27007 [D loss: 0.352778, acc: 91.41%] [G loss: 5.496761]\n",
      "epoch:34 step:27008 [D loss: 0.123343, acc: 98.44%] [G loss: 6.142384]\n",
      "epoch:34 step:27009 [D loss: 0.281115, acc: 95.31%] [G loss: 6.068844]\n",
      "epoch:34 step:27010 [D loss: 1.165460, acc: 39.84%] [G loss: 6.992068]\n",
      "epoch:34 step:27011 [D loss: 0.285178, acc: 88.28%] [G loss: 4.122821]\n",
      "epoch:34 step:27012 [D loss: 0.197412, acc: 97.66%] [G loss: 3.912250]\n",
      "epoch:34 step:27013 [D loss: 0.555657, acc: 66.41%] [G loss: 4.120649]\n",
      "epoch:34 step:27014 [D loss: 0.082588, acc: 100.00%] [G loss: 5.640908]\n",
      "epoch:34 step:27015 [D loss: 0.353777, acc: 85.94%] [G loss: 4.120134]\n",
      "epoch:34 step:27016 [D loss: 0.194108, acc: 99.22%] [G loss: 6.946514]\n",
      "epoch:34 step:27017 [D loss: 0.090707, acc: 99.22%] [G loss: 4.633161]\n",
      "epoch:34 step:27018 [D loss: 0.383805, acc: 90.62%] [G loss: 3.193637]\n",
      "epoch:34 step:27019 [D loss: 0.309714, acc: 86.72%] [G loss: 2.933193]\n",
      "epoch:34 step:27020 [D loss: 0.024352, acc: 100.00%] [G loss: 8.225002]\n",
      "epoch:34 step:27021 [D loss: 0.470861, acc: 70.31%] [G loss: 5.903861]\n",
      "epoch:34 step:27022 [D loss: 0.706966, acc: 63.28%] [G loss: 5.620656]\n",
      "epoch:34 step:27023 [D loss: 0.194821, acc: 99.22%] [G loss: 4.315285]\n",
      "epoch:34 step:27024 [D loss: 0.110685, acc: 99.22%] [G loss: 8.091683]\n",
      "epoch:34 step:27025 [D loss: 0.691205, acc: 56.25%] [G loss: 5.216918]\n",
      "epoch:34 step:27026 [D loss: 0.265842, acc: 93.75%] [G loss: 5.214034]\n",
      "epoch:34 step:27027 [D loss: 0.974656, acc: 53.91%] [G loss: 2.711987]\n",
      "epoch:34 step:27028 [D loss: 0.351289, acc: 92.19%] [G loss: 5.896218]\n",
      "epoch:34 step:27029 [D loss: 0.186871, acc: 96.09%] [G loss: 2.827009]\n",
      "epoch:34 step:27030 [D loss: 0.199464, acc: 95.31%] [G loss: 5.903121]\n",
      "epoch:34 step:27031 [D loss: 0.551106, acc: 62.50%] [G loss: 3.564757]\n",
      "epoch:34 step:27032 [D loss: 0.025280, acc: 100.00%] [G loss: 5.090569]\n",
      "epoch:34 step:27033 [D loss: 0.889602, acc: 48.44%] [G loss: 6.480105]\n",
      "epoch:34 step:27034 [D loss: 1.335277, acc: 43.75%] [G loss: 4.561159]\n",
      "epoch:34 step:27035 [D loss: 0.365490, acc: 83.59%] [G loss: 5.086378]\n",
      "epoch:34 step:27036 [D loss: 0.077135, acc: 100.00%] [G loss: 4.952487]\n",
      "epoch:34 step:27037 [D loss: 0.053161, acc: 100.00%] [G loss: 3.709381]\n",
      "epoch:34 step:27038 [D loss: 0.115698, acc: 98.44%] [G loss: 4.920177]\n",
      "epoch:34 step:27039 [D loss: 0.439126, acc: 85.16%] [G loss: 5.516455]\n",
      "epoch:34 step:27040 [D loss: 0.785396, acc: 53.12%] [G loss: 6.504585]\n",
      "epoch:34 step:27041 [D loss: 0.524654, acc: 80.47%] [G loss: 4.069673]\n",
      "epoch:34 step:27042 [D loss: 0.474785, acc: 82.03%] [G loss: 4.758104]\n",
      "epoch:34 step:27043 [D loss: 0.245681, acc: 89.06%] [G loss: 6.150552]\n",
      "epoch:34 step:27044 [D loss: 0.074585, acc: 100.00%] [G loss: 6.655123]\n",
      "epoch:34 step:27045 [D loss: 0.553700, acc: 71.88%] [G loss: 3.593720]\n",
      "epoch:34 step:27046 [D loss: 0.169822, acc: 98.44%] [G loss: 4.123752]\n",
      "epoch:34 step:27047 [D loss: 0.286078, acc: 86.72%] [G loss: 4.625870]\n",
      "epoch:34 step:27048 [D loss: 0.136783, acc: 100.00%] [G loss: 4.959220]\n",
      "epoch:34 step:27049 [D loss: 0.226022, acc: 96.09%] [G loss: 5.847950]\n",
      "epoch:34 step:27050 [D loss: 0.835629, acc: 55.47%] [G loss: 7.884350]\n",
      "epoch:34 step:27051 [D loss: 0.758216, acc: 53.12%] [G loss: 6.623441]\n",
      "epoch:34 step:27052 [D loss: 0.329464, acc: 93.75%] [G loss: 5.309607]\n",
      "epoch:34 step:27053 [D loss: 0.485471, acc: 80.47%] [G loss: 6.296129]\n",
      "epoch:34 step:27054 [D loss: 0.104954, acc: 100.00%] [G loss: 5.357586]\n",
      "epoch:34 step:27055 [D loss: 0.205313, acc: 96.88%] [G loss: 4.762509]\n",
      "epoch:34 step:27056 [D loss: 0.167798, acc: 99.22%] [G loss: 2.958926]\n",
      "epoch:34 step:27057 [D loss: 0.203171, acc: 97.66%] [G loss: 5.895349]\n",
      "epoch:34 step:27058 [D loss: 0.254338, acc: 97.66%] [G loss: 4.439219]\n",
      "epoch:34 step:27059 [D loss: 0.168636, acc: 100.00%] [G loss: 3.174511]\n",
      "epoch:34 step:27060 [D loss: 0.205669, acc: 96.09%] [G loss: 6.002645]\n",
      "epoch:34 step:27061 [D loss: 0.524388, acc: 60.94%] [G loss: 4.969571]\n",
      "epoch:34 step:27062 [D loss: 0.754143, acc: 53.12%] [G loss: 7.152854]\n",
      "epoch:34 step:27063 [D loss: 0.083082, acc: 99.22%] [G loss: 5.340935]\n",
      "epoch:34 step:27064 [D loss: 0.624220, acc: 61.72%] [G loss: 4.112051]\n",
      "epoch:34 step:27065 [D loss: 0.014771, acc: 100.00%] [G loss: 9.680336]\n",
      "epoch:34 step:27066 [D loss: 0.193317, acc: 99.22%] [G loss: 7.418799]\n",
      "epoch:34 step:27067 [D loss: 1.809256, acc: 50.00%] [G loss: 6.230078]\n",
      "epoch:34 step:27068 [D loss: 0.493023, acc: 72.66%] [G loss: 4.570891]\n",
      "epoch:34 step:27069 [D loss: 0.243141, acc: 97.66%] [G loss: 3.726084]\n",
      "epoch:34 step:27070 [D loss: 0.059949, acc: 100.00%] [G loss: 4.286621]\n",
      "epoch:34 step:27071 [D loss: 0.108028, acc: 99.22%] [G loss: 5.024889]\n",
      "epoch:34 step:27072 [D loss: 0.072324, acc: 100.00%] [G loss: 5.778859]\n",
      "epoch:34 step:27073 [D loss: 0.462525, acc: 68.75%] [G loss: 5.679119]\n",
      "epoch:34 step:27074 [D loss: 0.550501, acc: 71.09%] [G loss: 3.662673]\n",
      "epoch:34 step:27075 [D loss: 0.305561, acc: 85.94%] [G loss: 4.355234]\n",
      "epoch:34 step:27076 [D loss: 0.085498, acc: 100.00%] [G loss: 7.883865]\n",
      "epoch:34 step:27077 [D loss: 0.357766, acc: 89.06%] [G loss: 5.403229]\n",
      "epoch:34 step:27078 [D loss: 0.212419, acc: 96.09%] [G loss: 3.921898]\n",
      "epoch:34 step:27079 [D loss: 0.361545, acc: 87.50%] [G loss: 5.695424]\n",
      "epoch:34 step:27080 [D loss: 0.368372, acc: 82.81%] [G loss: 6.384686]\n",
      "epoch:34 step:27081 [D loss: 0.152639, acc: 98.44%] [G loss: 3.203088]\n",
      "epoch:34 step:27082 [D loss: 1.009407, acc: 32.81%] [G loss: 4.013445]\n",
      "epoch:34 step:27083 [D loss: 0.856300, acc: 52.34%] [G loss: 4.886513]\n",
      "epoch:34 step:27084 [D loss: 0.099533, acc: 97.66%] [G loss: 6.411738]\n",
      "epoch:34 step:27085 [D loss: 0.364603, acc: 90.62%] [G loss: 5.639567]\n",
      "epoch:34 step:27086 [D loss: 0.420846, acc: 82.03%] [G loss: 1.999501]\n",
      "epoch:34 step:27087 [D loss: 0.162721, acc: 96.09%] [G loss: 5.312258]\n",
      "epoch:34 step:27088 [D loss: 0.404497, acc: 89.06%] [G loss: 3.313637]\n",
      "epoch:34 step:27089 [D loss: 1.825089, acc: 1.56%] [G loss: 4.749359]\n",
      "epoch:34 step:27090 [D loss: 0.413103, acc: 81.25%] [G loss: 3.931814]\n",
      "epoch:34 step:27091 [D loss: 0.230747, acc: 95.31%] [G loss: 8.124652]\n",
      "epoch:34 step:27092 [D loss: 0.437648, acc: 71.88%] [G loss: 7.226370]\n",
      "epoch:34 step:27093 [D loss: 0.347425, acc: 81.25%] [G loss: 7.822322]\n",
      "epoch:34 step:27094 [D loss: 0.280843, acc: 94.53%] [G loss: 3.558366]\n",
      "epoch:34 step:27095 [D loss: 0.574030, acc: 60.94%] [G loss: 4.369514]\n",
      "epoch:34 step:27096 [D loss: 0.094775, acc: 100.00%] [G loss: 3.885043]\n",
      "epoch:34 step:27097 [D loss: 0.411231, acc: 75.00%] [G loss: 4.457036]\n",
      "epoch:34 step:27098 [D loss: 0.249122, acc: 94.53%] [G loss: 7.670550]\n",
      "epoch:34 step:27099 [D loss: 0.174990, acc: 98.44%] [G loss: 5.544041]\n",
      "epoch:34 step:27100 [D loss: 0.168452, acc: 99.22%] [G loss: 3.785314]\n",
      "epoch:34 step:27101 [D loss: 0.129753, acc: 99.22%] [G loss: 4.616249]\n",
      "epoch:34 step:27102 [D loss: 1.234194, acc: 50.78%] [G loss: 4.739364]\n",
      "epoch:34 step:27103 [D loss: 0.177283, acc: 95.31%] [G loss: 4.500049]\n",
      "epoch:34 step:27104 [D loss: 0.528052, acc: 65.62%] [G loss: 5.418274]\n",
      "epoch:34 step:27105 [D loss: 0.318116, acc: 89.84%] [G loss: 5.618769]\n",
      "epoch:34 step:27106 [D loss: 0.196964, acc: 97.66%] [G loss: 3.759071]\n",
      "epoch:34 step:27107 [D loss: 0.137994, acc: 99.22%] [G loss: 1.910565]\n",
      "epoch:34 step:27108 [D loss: 0.362913, acc: 85.16%] [G loss: 9.066248]\n",
      "epoch:34 step:27109 [D loss: 0.190221, acc: 92.97%] [G loss: 3.739827]\n",
      "epoch:34 step:27110 [D loss: 0.045469, acc: 100.00%] [G loss: 7.068711]\n",
      "epoch:34 step:27111 [D loss: 0.595921, acc: 61.72%] [G loss: 5.830068]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:34 step:27112 [D loss: 0.359119, acc: 78.91%] [G loss: 6.467636]\n",
      "epoch:34 step:27113 [D loss: 0.370128, acc: 76.56%] [G loss: 8.246143]\n",
      "epoch:34 step:27114 [D loss: 0.359684, acc: 86.72%] [G loss: 7.477856]\n",
      "epoch:34 step:27115 [D loss: 0.047770, acc: 100.00%] [G loss: 4.306149]\n",
      "epoch:34 step:27116 [D loss: 0.264537, acc: 90.62%] [G loss: 5.858603]\n",
      "epoch:34 step:27117 [D loss: 0.703525, acc: 57.81%] [G loss: 4.110708]\n",
      "epoch:34 step:27118 [D loss: 0.155505, acc: 96.88%] [G loss: 4.141831]\n",
      "epoch:34 step:27119 [D loss: 0.527022, acc: 75.78%] [G loss: 3.266605]\n",
      "epoch:34 step:27120 [D loss: 0.177484, acc: 99.22%] [G loss: 4.313644]\n",
      "epoch:34 step:27121 [D loss: 0.766226, acc: 53.12%] [G loss: 4.779737]\n",
      "epoch:34 step:27122 [D loss: 0.245542, acc: 96.88%] [G loss: 4.163580]\n",
      "epoch:34 step:27123 [D loss: 1.014707, acc: 50.00%] [G loss: 7.434772]\n",
      "epoch:34 step:27124 [D loss: 0.253307, acc: 91.41%] [G loss: 6.356544]\n",
      "epoch:34 step:27125 [D loss: 0.473047, acc: 75.00%] [G loss: 4.896683]\n",
      "epoch:34 step:27126 [D loss: 0.112026, acc: 99.22%] [G loss: 6.576397]\n",
      "epoch:34 step:27127 [D loss: 0.639087, acc: 61.72%] [G loss: 3.889524]\n",
      "epoch:34 step:27128 [D loss: 0.616476, acc: 68.75%] [G loss: 6.061154]\n",
      "epoch:34 step:27129 [D loss: 0.116327, acc: 99.22%] [G loss: 5.082602]\n",
      "epoch:34 step:27130 [D loss: 0.154385, acc: 100.00%] [G loss: 4.682624]\n",
      "epoch:34 step:27131 [D loss: 0.181269, acc: 97.66%] [G loss: 5.091047]\n",
      "epoch:34 step:27132 [D loss: 0.070396, acc: 99.22%] [G loss: 8.446028]\n",
      "epoch:34 step:27133 [D loss: 0.588750, acc: 65.62%] [G loss: 7.269839]\n",
      "epoch:34 step:27134 [D loss: 0.137947, acc: 100.00%] [G loss: 5.801920]\n",
      "epoch:34 step:27135 [D loss: 0.231489, acc: 99.22%] [G loss: 4.740878]\n",
      "epoch:34 step:27136 [D loss: 0.240817, acc: 97.66%] [G loss: 4.109034]\n",
      "epoch:34 step:27137 [D loss: 0.339020, acc: 89.84%] [G loss: 5.783609]\n",
      "epoch:34 step:27138 [D loss: 0.660968, acc: 64.06%] [G loss: 5.379403]\n",
      "epoch:34 step:27139 [D loss: 0.401600, acc: 89.06%] [G loss: 6.661049]\n",
      "epoch:34 step:27140 [D loss: 0.333888, acc: 89.84%] [G loss: 7.505190]\n",
      "epoch:34 step:27141 [D loss: 0.194360, acc: 99.22%] [G loss: 5.303420]\n",
      "epoch:34 step:27142 [D loss: 0.320190, acc: 88.28%] [G loss: 8.387178]\n",
      "epoch:34 step:27143 [D loss: 0.334608, acc: 89.06%] [G loss: 5.180656]\n",
      "epoch:34 step:27144 [D loss: 0.143272, acc: 100.00%] [G loss: 3.811569]\n",
      "epoch:34 step:27145 [D loss: 0.380768, acc: 87.50%] [G loss: 7.207188]\n",
      "epoch:34 step:27146 [D loss: 0.245667, acc: 94.53%] [G loss: 3.787385]\n",
      "epoch:34 step:27147 [D loss: 0.542507, acc: 73.44%] [G loss: 3.958428]\n",
      "epoch:34 step:27148 [D loss: 0.141403, acc: 100.00%] [G loss: 5.162612]\n",
      "epoch:34 step:27149 [D loss: 0.309902, acc: 92.19%] [G loss: 6.112730]\n",
      "epoch:34 step:27150 [D loss: 1.161380, acc: 34.38%] [G loss: 5.918815]\n",
      "epoch:34 step:27151 [D loss: 0.376045, acc: 74.22%] [G loss: 4.620954]\n",
      "epoch:34 step:27152 [D loss: 0.289035, acc: 90.62%] [G loss: 5.385774]\n",
      "epoch:34 step:27153 [D loss: 0.177660, acc: 97.66%] [G loss: 2.527613]\n",
      "epoch:34 step:27154 [D loss: 0.272544, acc: 92.97%] [G loss: 4.389581]\n",
      "epoch:34 step:27155 [D loss: 0.139462, acc: 97.66%] [G loss: 6.079054]\n",
      "epoch:34 step:27156 [D loss: 0.442364, acc: 83.59%] [G loss: 4.343904]\n",
      "epoch:34 step:27157 [D loss: 0.160550, acc: 97.66%] [G loss: 7.919709]\n",
      "epoch:34 step:27158 [D loss: 0.396287, acc: 84.38%] [G loss: 4.066699]\n",
      "epoch:34 step:27159 [D loss: 0.678775, acc: 57.81%] [G loss: 6.982204]\n",
      "epoch:34 step:27160 [D loss: 0.102972, acc: 100.00%] [G loss: 4.248156]\n",
      "epoch:34 step:27161 [D loss: 0.172692, acc: 99.22%] [G loss: 7.106499]\n",
      "epoch:34 step:27162 [D loss: 0.104125, acc: 99.22%] [G loss: 3.838653]\n",
      "epoch:34 step:27163 [D loss: 0.167689, acc: 99.22%] [G loss: 5.548194]\n",
      "epoch:34 step:27164 [D loss: 0.446121, acc: 85.16%] [G loss: 3.858656]\n",
      "epoch:34 step:27165 [D loss: 0.865856, acc: 52.34%] [G loss: 6.585599]\n",
      "epoch:34 step:27166 [D loss: 0.539956, acc: 62.50%] [G loss: 6.296266]\n",
      "epoch:34 step:27167 [D loss: 0.151769, acc: 96.09%] [G loss: 5.417310]\n",
      "epoch:34 step:27168 [D loss: 0.280616, acc: 95.31%] [G loss: 5.427209]\n",
      "epoch:34 step:27169 [D loss: 0.628284, acc: 66.41%] [G loss: 6.086779]\n",
      "epoch:34 step:27170 [D loss: 0.041313, acc: 99.22%] [G loss: 6.289788]\n",
      "epoch:34 step:27171 [D loss: 0.449557, acc: 70.31%] [G loss: 8.437587]\n",
      "epoch:34 step:27172 [D loss: 0.403096, acc: 75.00%] [G loss: 5.322794]\n",
      "epoch:34 step:27173 [D loss: 0.422855, acc: 78.91%] [G loss: 5.019799]\n",
      "epoch:34 step:27174 [D loss: 0.543870, acc: 60.94%] [G loss: 6.482520]\n",
      "epoch:34 step:27175 [D loss: 0.134004, acc: 98.44%] [G loss: 7.694556]\n",
      "epoch:34 step:27176 [D loss: 0.022830, acc: 100.00%] [G loss: 6.810826]\n",
      "epoch:34 step:27177 [D loss: 0.834867, acc: 39.06%] [G loss: 5.791247]\n",
      "epoch:34 step:27178 [D loss: 0.029642, acc: 100.00%] [G loss: 6.273763]\n",
      "epoch:34 step:27179 [D loss: 0.071714, acc: 100.00%] [G loss: 2.739007]\n",
      "epoch:34 step:27180 [D loss: 0.320544, acc: 92.19%] [G loss: 4.369166]\n",
      "epoch:34 step:27181 [D loss: 0.880512, acc: 40.62%] [G loss: 3.980999]\n",
      "epoch:34 step:27182 [D loss: 0.097759, acc: 99.22%] [G loss: 4.215718]\n",
      "epoch:34 step:27183 [D loss: 0.258112, acc: 96.88%] [G loss: 7.451114]\n",
      "epoch:34 step:27184 [D loss: 0.158900, acc: 99.22%] [G loss: 3.933550]\n",
      "epoch:34 step:27185 [D loss: 0.509369, acc: 74.22%] [G loss: 6.503123]\n",
      "epoch:34 step:27186 [D loss: 0.736841, acc: 56.25%] [G loss: 7.023614]\n",
      "epoch:34 step:27187 [D loss: 0.107335, acc: 99.22%] [G loss: 4.336867]\n",
      "epoch:34 step:27188 [D loss: 0.071672, acc: 98.44%] [G loss: 5.081100]\n",
      "epoch:34 step:27189 [D loss: 0.955149, acc: 50.00%] [G loss: 5.067864]\n",
      "epoch:34 step:27190 [D loss: 0.309138, acc: 85.16%] [G loss: 3.825010]\n",
      "epoch:34 step:27191 [D loss: 0.849565, acc: 50.00%] [G loss: 6.778541]\n",
      "epoch:34 step:27192 [D loss: 0.923826, acc: 42.19%] [G loss: 4.926446]\n",
      "epoch:34 step:27193 [D loss: 0.738584, acc: 58.59%] [G loss: 6.833420]\n",
      "epoch:34 step:27194 [D loss: 0.133689, acc: 99.22%] [G loss: 6.626575]\n",
      "epoch:34 step:27195 [D loss: 0.074891, acc: 100.00%] [G loss: 8.373585]\n",
      "epoch:34 step:27196 [D loss: 0.076665, acc: 100.00%] [G loss: 5.138070]\n",
      "epoch:34 step:27197 [D loss: 1.343497, acc: 43.75%] [G loss: 2.785783]\n",
      "epoch:34 step:27198 [D loss: 0.649765, acc: 53.91%] [G loss: 8.122087]\n",
      "epoch:34 step:27199 [D loss: 0.084304, acc: 100.00%] [G loss: 6.798941]\n",
      "epoch:34 step:27200 [D loss: 0.193904, acc: 99.22%] [G loss: 4.823588]\n",
      "##############\n",
      "[0.85976715 0.85172285 0.8123538  0.811786   0.80616793 0.80689017\n",
      " 0.87616642 0.7940974  0.79999552 0.83166489]\n",
      "##########\n",
      "epoch:34 step:27201 [D loss: 0.871002, acc: 45.31%] [G loss: 4.778276]\n",
      "epoch:34 step:27202 [D loss: 0.208722, acc: 98.44%] [G loss: 5.781333]\n",
      "epoch:34 step:27203 [D loss: 0.359899, acc: 92.19%] [G loss: 5.038136]\n",
      "epoch:34 step:27204 [D loss: 0.445799, acc: 71.88%] [G loss: 8.104435]\n",
      "epoch:34 step:27205 [D loss: 0.957618, acc: 50.00%] [G loss: 4.201491]\n",
      "epoch:34 step:27206 [D loss: 0.378009, acc: 82.81%] [G loss: 6.166023]\n",
      "epoch:34 step:27207 [D loss: 0.644499, acc: 56.25%] [G loss: 3.582110]\n",
      "epoch:34 step:27208 [D loss: 0.258012, acc: 98.44%] [G loss: 5.102345]\n",
      "epoch:34 step:27209 [D loss: 0.463480, acc: 71.88%] [G loss: 5.851606]\n",
      "epoch:34 step:27210 [D loss: 1.606341, acc: 25.00%] [G loss: 5.816345]\n",
      "epoch:34 step:27211 [D loss: 0.125960, acc: 99.22%] [G loss: 4.145878]\n",
      "epoch:34 step:27212 [D loss: 0.519965, acc: 68.75%] [G loss: 5.537519]\n",
      "epoch:34 step:27213 [D loss: 0.735602, acc: 57.03%] [G loss: 6.179975]\n",
      "epoch:34 step:27214 [D loss: 0.095575, acc: 99.22%] [G loss: 6.320491]\n",
      "epoch:34 step:27215 [D loss: 0.486220, acc: 76.56%] [G loss: 5.176161]\n",
      "epoch:34 step:27216 [D loss: 0.326201, acc: 92.19%] [G loss: 4.855395]\n",
      "epoch:34 step:27217 [D loss: 0.207724, acc: 96.88%] [G loss: 6.315334]\n",
      "epoch:34 step:27218 [D loss: 0.375223, acc: 81.25%] [G loss: 5.487518]\n",
      "epoch:34 step:27219 [D loss: 0.295307, acc: 88.28%] [G loss: 5.352103]\n",
      "epoch:34 step:27220 [D loss: 0.198214, acc: 96.09%] [G loss: 4.620282]\n",
      "epoch:34 step:27221 [D loss: 0.568813, acc: 56.25%] [G loss: 7.344791]\n",
      "epoch:34 step:27222 [D loss: 0.170284, acc: 100.00%] [G loss: 4.619590]\n",
      "epoch:34 step:27223 [D loss: 0.514754, acc: 68.75%] [G loss: 4.485471]\n",
      "epoch:34 step:27224 [D loss: 0.373847, acc: 82.03%] [G loss: 5.387879]\n",
      "epoch:34 step:27225 [D loss: 0.319979, acc: 88.28%] [G loss: 6.437726]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:34 step:27226 [D loss: 0.854215, acc: 51.56%] [G loss: 7.682137]\n",
      "epoch:34 step:27227 [D loss: 0.231729, acc: 97.66%] [G loss: 4.390604]\n",
      "epoch:34 step:27228 [D loss: 0.082634, acc: 100.00%] [G loss: 5.789169]\n",
      "epoch:34 step:27229 [D loss: 0.194668, acc: 96.09%] [G loss: 7.939721]\n",
      "epoch:34 step:27230 [D loss: 0.120608, acc: 100.00%] [G loss: 4.355561]\n",
      "epoch:34 step:27231 [D loss: 0.261029, acc: 97.66%] [G loss: 4.976821]\n",
      "epoch:34 step:27232 [D loss: 0.154436, acc: 99.22%] [G loss: 6.191373]\n",
      "epoch:34 step:27233 [D loss: 0.027929, acc: 100.00%] [G loss: 4.787430]\n",
      "epoch:34 step:27234 [D loss: 0.151418, acc: 100.00%] [G loss: 2.889819]\n",
      "epoch:34 step:27235 [D loss: 0.103903, acc: 100.00%] [G loss: 3.854241]\n",
      "epoch:34 step:27236 [D loss: 0.080379, acc: 100.00%] [G loss: 3.952860]\n",
      "epoch:34 step:27237 [D loss: 0.249945, acc: 96.09%] [G loss: 6.360271]\n",
      "epoch:34 step:27238 [D loss: 0.214532, acc: 98.44%] [G loss: 5.090305]\n",
      "epoch:34 step:27239 [D loss: 0.179014, acc: 99.22%] [G loss: 4.854877]\n",
      "epoch:34 step:27240 [D loss: 0.239522, acc: 94.53%] [G loss: 3.886613]\n",
      "epoch:34 step:27241 [D loss: 0.264146, acc: 98.44%] [G loss: 3.738869]\n",
      "epoch:34 step:27242 [D loss: 0.296400, acc: 92.97%] [G loss: 7.418647]\n",
      "epoch:34 step:27243 [D loss: 0.323419, acc: 89.84%] [G loss: 4.131432]\n",
      "epoch:34 step:27244 [D loss: 0.034528, acc: 100.00%] [G loss: 3.713067]\n",
      "epoch:34 step:27245 [D loss: 0.937554, acc: 32.03%] [G loss: 9.128384]\n",
      "epoch:34 step:27246 [D loss: 0.805563, acc: 47.66%] [G loss: 7.703671]\n",
      "epoch:34 step:27247 [D loss: 0.788668, acc: 53.12%] [G loss: 2.393506]\n",
      "epoch:34 step:27248 [D loss: 1.001285, acc: 50.00%] [G loss: 5.731658]\n",
      "epoch:34 step:27249 [D loss: 1.009378, acc: 50.78%] [G loss: 3.242853]\n",
      "epoch:34 step:27250 [D loss: 0.795479, acc: 50.00%] [G loss: 4.848384]\n",
      "epoch:34 step:27251 [D loss: 0.445434, acc: 80.47%] [G loss: 5.283895]\n",
      "epoch:34 step:27252 [D loss: 1.278878, acc: 51.56%] [G loss: 6.045253]\n",
      "epoch:34 step:27253 [D loss: 0.085018, acc: 100.00%] [G loss: 3.101620]\n",
      "epoch:34 step:27254 [D loss: 0.275004, acc: 91.41%] [G loss: 4.255474]\n",
      "epoch:34 step:27255 [D loss: 1.032720, acc: 31.25%] [G loss: 5.077500]\n",
      "epoch:34 step:27256 [D loss: 1.381574, acc: 20.31%] [G loss: 5.252351]\n",
      "epoch:34 step:27257 [D loss: 0.206935, acc: 97.66%] [G loss: 5.358071]\n",
      "epoch:34 step:27258 [D loss: 0.346684, acc: 88.28%] [G loss: 3.860343]\n",
      "epoch:34 step:27259 [D loss: 0.267979, acc: 90.62%] [G loss: 4.498831]\n",
      "epoch:34 step:27260 [D loss: 0.250634, acc: 92.97%] [G loss: 3.990531]\n",
      "epoch:34 step:27261 [D loss: 0.072963, acc: 100.00%] [G loss: 3.986713]\n",
      "epoch:34 step:27262 [D loss: 0.218938, acc: 95.31%] [G loss: 5.775450]\n",
      "epoch:34 step:27263 [D loss: 0.901525, acc: 42.97%] [G loss: 5.133948]\n",
      "epoch:34 step:27264 [D loss: 0.115160, acc: 100.00%] [G loss: 4.944397]\n",
      "epoch:34 step:27265 [D loss: 0.260310, acc: 86.72%] [G loss: 5.962693]\n",
      "epoch:34 step:27266 [D loss: 0.059093, acc: 100.00%] [G loss: 4.805286]\n",
      "epoch:34 step:27267 [D loss: 0.052592, acc: 99.22%] [G loss: 5.074769]\n",
      "epoch:34 step:27268 [D loss: 0.076636, acc: 100.00%] [G loss: 7.765298]\n",
      "epoch:34 step:27269 [D loss: 0.373462, acc: 87.50%] [G loss: 3.038187]\n",
      "epoch:34 step:27270 [D loss: 0.385173, acc: 88.28%] [G loss: 5.916855]\n",
      "epoch:34 step:27271 [D loss: 0.086384, acc: 100.00%] [G loss: 4.509615]\n",
      "epoch:34 step:27272 [D loss: 0.344547, acc: 89.84%] [G loss: 4.471281]\n",
      "epoch:34 step:27273 [D loss: 1.052439, acc: 44.53%] [G loss: 4.476203]\n",
      "epoch:34 step:27274 [D loss: 0.467625, acc: 67.19%] [G loss: 3.685205]\n",
      "epoch:34 step:27275 [D loss: 0.051335, acc: 100.00%] [G loss: 7.090802]\n",
      "epoch:34 step:27276 [D loss: 1.092743, acc: 50.00%] [G loss: 6.010526]\n",
      "epoch:34 step:27277 [D loss: 0.025820, acc: 100.00%] [G loss: 4.477897]\n",
      "epoch:34 step:27278 [D loss: 0.390362, acc: 73.44%] [G loss: 5.016428]\n",
      "epoch:34 step:27279 [D loss: 0.316275, acc: 95.31%] [G loss: 3.766575]\n",
      "epoch:34 step:27280 [D loss: 0.709062, acc: 53.91%] [G loss: 8.781725]\n",
      "epoch:34 step:27281 [D loss: 0.245637, acc: 93.75%] [G loss: 4.593612]\n",
      "epoch:34 step:27282 [D loss: 0.245151, acc: 94.53%] [G loss: 5.139183]\n",
      "epoch:34 step:27283 [D loss: 0.787863, acc: 52.34%] [G loss: 6.704998]\n",
      "epoch:34 step:27284 [D loss: 0.567186, acc: 66.41%] [G loss: 4.618740]\n",
      "epoch:34 step:27285 [D loss: 1.294015, acc: 49.22%] [G loss: 4.406690]\n",
      "epoch:34 step:27286 [D loss: 0.499523, acc: 71.09%] [G loss: 3.716810]\n",
      "epoch:34 step:27287 [D loss: 0.123004, acc: 99.22%] [G loss: 3.395081]\n",
      "epoch:34 step:27288 [D loss: 0.336421, acc: 81.25%] [G loss: 6.174274]\n",
      "epoch:34 step:27289 [D loss: 0.275632, acc: 96.88%] [G loss: 3.291361]\n",
      "epoch:34 step:27290 [D loss: 0.648149, acc: 60.16%] [G loss: 6.881416]\n",
      "epoch:34 step:27291 [D loss: 0.131791, acc: 100.00%] [G loss: 5.144097]\n",
      "epoch:34 step:27292 [D loss: 0.839249, acc: 51.56%] [G loss: 10.012402]\n",
      "epoch:34 step:27293 [D loss: 0.189032, acc: 96.09%] [G loss: 5.738792]\n",
      "epoch:34 step:27294 [D loss: 0.334795, acc: 90.62%] [G loss: 6.888110]\n",
      "epoch:34 step:27295 [D loss: 0.205974, acc: 99.22%] [G loss: 3.879009]\n",
      "epoch:34 step:27296 [D loss: 0.475808, acc: 78.91%] [G loss: 7.010919]\n",
      "epoch:34 step:27297 [D loss: 0.022272, acc: 100.00%] [G loss: 7.236203]\n",
      "epoch:34 step:27298 [D loss: 0.432366, acc: 86.72%] [G loss: 5.467662]\n",
      "epoch:34 step:27299 [D loss: 0.204906, acc: 97.66%] [G loss: 4.679915]\n",
      "epoch:34 step:27300 [D loss: 0.104627, acc: 99.22%] [G loss: 4.646734]\n",
      "epoch:34 step:27301 [D loss: 0.990075, acc: 51.56%] [G loss: 5.829073]\n",
      "epoch:34 step:27302 [D loss: 0.041486, acc: 100.00%] [G loss: 4.787267]\n",
      "epoch:34 step:27303 [D loss: 0.137245, acc: 99.22%] [G loss: 7.489720]\n",
      "epoch:34 step:27304 [D loss: 0.328048, acc: 96.09%] [G loss: 3.339648]\n",
      "epoch:34 step:27305 [D loss: 0.887299, acc: 51.56%] [G loss: 4.964751]\n",
      "epoch:34 step:27306 [D loss: 0.596747, acc: 56.25%] [G loss: 5.210764]\n",
      "epoch:34 step:27307 [D loss: 0.549114, acc: 71.09%] [G loss: 5.641538]\n",
      "epoch:34 step:27308 [D loss: 0.494503, acc: 66.41%] [G loss: 6.543325]\n",
      "epoch:34 step:27309 [D loss: 0.392319, acc: 82.03%] [G loss: 4.785168]\n",
      "epoch:34 step:27310 [D loss: 0.164067, acc: 100.00%] [G loss: 4.767926]\n",
      "epoch:34 step:27311 [D loss: 0.105445, acc: 99.22%] [G loss: 5.805104]\n",
      "epoch:34 step:27312 [D loss: 0.483251, acc: 66.41%] [G loss: 3.808759]\n",
      "epoch:34 step:27313 [D loss: 0.189710, acc: 99.22%] [G loss: 4.403988]\n",
      "epoch:34 step:27314 [D loss: 1.045275, acc: 50.78%] [G loss: 8.036024]\n",
      "epoch:34 step:27315 [D loss: 0.290791, acc: 92.97%] [G loss: 3.953379]\n",
      "epoch:34 step:27316 [D loss: 0.310206, acc: 94.53%] [G loss: 4.228668]\n",
      "epoch:34 step:27317 [D loss: 0.092509, acc: 100.00%] [G loss: 4.622841]\n",
      "epoch:34 step:27318 [D loss: 0.162038, acc: 100.00%] [G loss: 5.574381]\n",
      "epoch:34 step:27319 [D loss: 0.220688, acc: 98.44%] [G loss: 5.600679]\n",
      "epoch:34 step:27320 [D loss: 0.086574, acc: 99.22%] [G loss: 4.268022]\n",
      "epoch:34 step:27321 [D loss: 1.315820, acc: 50.78%] [G loss: 5.439742]\n",
      "epoch:34 step:27322 [D loss: 0.242666, acc: 91.41%] [G loss: 3.430860]\n",
      "epoch:34 step:27323 [D loss: 0.222986, acc: 97.66%] [G loss: 4.767729]\n",
      "epoch:34 step:27324 [D loss: 0.393280, acc: 83.59%] [G loss: 3.529337]\n",
      "epoch:34 step:27325 [D loss: 0.489320, acc: 80.47%] [G loss: 4.956297]\n",
      "epoch:34 step:27326 [D loss: 0.054622, acc: 100.00%] [G loss: 5.767446]\n",
      "epoch:34 step:27327 [D loss: 0.033590, acc: 100.00%] [G loss: 9.392995]\n",
      "epoch:34 step:27328 [D loss: 0.146837, acc: 100.00%] [G loss: 3.829243]\n",
      "epoch:34 step:27329 [D loss: 0.144227, acc: 96.88%] [G loss: 4.974532]\n",
      "epoch:34 step:27330 [D loss: 0.560396, acc: 68.75%] [G loss: 7.974366]\n",
      "epoch:34 step:27331 [D loss: 0.880316, acc: 44.53%] [G loss: 4.787481]\n",
      "epoch:34 step:27332 [D loss: 0.135621, acc: 100.00%] [G loss: 3.018614]\n",
      "epoch:34 step:27333 [D loss: 0.537626, acc: 76.56%] [G loss: 3.753293]\n",
      "epoch:34 step:27334 [D loss: 1.592088, acc: 48.44%] [G loss: 2.790653]\n",
      "epoch:34 step:27335 [D loss: 1.390538, acc: 28.12%] [G loss: 3.512780]\n",
      "epoch:35 step:27336 [D loss: 0.094389, acc: 100.00%] [G loss: 2.132841]\n",
      "epoch:35 step:27337 [D loss: 0.326124, acc: 89.06%] [G loss: 2.216300]\n",
      "epoch:35 step:27338 [D loss: 0.386942, acc: 90.62%] [G loss: 5.875678]\n",
      "epoch:35 step:27339 [D loss: 0.605547, acc: 67.19%] [G loss: 3.172660]\n",
      "epoch:35 step:27340 [D loss: 0.369801, acc: 78.91%] [G loss: 2.839425]\n",
      "epoch:35 step:27341 [D loss: 0.770913, acc: 53.91%] [G loss: 5.553847]\n",
      "epoch:35 step:27342 [D loss: 0.084660, acc: 100.00%] [G loss: 6.721351]\n",
      "epoch:35 step:27343 [D loss: 0.934665, acc: 52.34%] [G loss: 3.914288]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:35 step:27344 [D loss: 0.178795, acc: 98.44%] [G loss: 4.753643]\n",
      "epoch:35 step:27345 [D loss: 0.323377, acc: 88.28%] [G loss: 6.810400]\n",
      "epoch:35 step:27346 [D loss: 0.085145, acc: 100.00%] [G loss: 7.187631]\n",
      "epoch:35 step:27347 [D loss: 0.685974, acc: 53.12%] [G loss: 5.134360]\n",
      "epoch:35 step:27348 [D loss: 0.400969, acc: 77.34%] [G loss: 4.903951]\n",
      "epoch:35 step:27349 [D loss: 0.989653, acc: 52.34%] [G loss: 4.359985]\n",
      "epoch:35 step:27350 [D loss: 0.868124, acc: 51.56%] [G loss: 5.572771]\n",
      "epoch:35 step:27351 [D loss: 0.247929, acc: 91.41%] [G loss: 5.598498]\n",
      "epoch:35 step:27352 [D loss: 0.296325, acc: 89.06%] [G loss: 4.161419]\n",
      "epoch:35 step:27353 [D loss: 0.055923, acc: 100.00%] [G loss: 4.402068]\n",
      "epoch:35 step:27354 [D loss: 0.081331, acc: 100.00%] [G loss: 4.501719]\n",
      "epoch:35 step:27355 [D loss: 0.259626, acc: 96.88%] [G loss: 3.024224]\n",
      "epoch:35 step:27356 [D loss: 0.127809, acc: 99.22%] [G loss: 2.716159]\n",
      "epoch:35 step:27357 [D loss: 0.119101, acc: 98.44%] [G loss: 4.349624]\n",
      "epoch:35 step:27358 [D loss: 0.646441, acc: 67.19%] [G loss: 3.162453]\n",
      "epoch:35 step:27359 [D loss: 1.449678, acc: 46.88%] [G loss: 4.452323]\n",
      "epoch:35 step:27360 [D loss: 0.612346, acc: 62.50%] [G loss: 4.916204]\n",
      "epoch:35 step:27361 [D loss: 0.153102, acc: 97.66%] [G loss: 5.222466]\n",
      "epoch:35 step:27362 [D loss: 0.753106, acc: 56.25%] [G loss: 5.435467]\n",
      "epoch:35 step:27363 [D loss: 0.245071, acc: 97.66%] [G loss: 6.525930]\n",
      "epoch:35 step:27364 [D loss: 0.153441, acc: 97.66%] [G loss: 4.857807]\n",
      "epoch:35 step:27365 [D loss: 0.167202, acc: 96.88%] [G loss: 8.004541]\n",
      "epoch:35 step:27366 [D loss: 0.057723, acc: 100.00%] [G loss: 5.523450]\n",
      "epoch:35 step:27367 [D loss: 0.134597, acc: 98.44%] [G loss: 4.225562]\n",
      "epoch:35 step:27368 [D loss: 0.592287, acc: 60.94%] [G loss: 4.324221]\n",
      "epoch:35 step:27369 [D loss: 0.384282, acc: 79.69%] [G loss: 3.784243]\n",
      "epoch:35 step:27370 [D loss: 0.359300, acc: 82.03%] [G loss: 5.881944]\n",
      "epoch:35 step:27371 [D loss: 0.036200, acc: 100.00%] [G loss: 4.553594]\n",
      "epoch:35 step:27372 [D loss: 1.238499, acc: 50.00%] [G loss: 3.649686]\n",
      "epoch:35 step:27373 [D loss: 0.896932, acc: 48.44%] [G loss: 7.328483]\n",
      "epoch:35 step:27374 [D loss: 0.342227, acc: 90.62%] [G loss: 3.176094]\n",
      "epoch:35 step:27375 [D loss: 0.118070, acc: 100.00%] [G loss: 5.392587]\n",
      "epoch:35 step:27376 [D loss: 1.121610, acc: 50.78%] [G loss: 2.858377]\n",
      "epoch:35 step:27377 [D loss: 0.205451, acc: 94.53%] [G loss: 4.221452]\n",
      "epoch:35 step:27378 [D loss: 0.448915, acc: 82.03%] [G loss: 3.160495]\n",
      "epoch:35 step:27379 [D loss: 1.731297, acc: 4.69%] [G loss: 5.383540]\n",
      "epoch:35 step:27380 [D loss: 0.621275, acc: 55.47%] [G loss: 4.296931]\n",
      "epoch:35 step:27381 [D loss: 0.123196, acc: 99.22%] [G loss: 3.756008]\n",
      "epoch:35 step:27382 [D loss: 0.808582, acc: 52.34%] [G loss: 5.598792]\n",
      "epoch:35 step:27383 [D loss: 1.020823, acc: 44.53%] [G loss: 3.337667]\n",
      "epoch:35 step:27384 [D loss: 0.118191, acc: 100.00%] [G loss: 3.473154]\n",
      "epoch:35 step:27385 [D loss: 0.209778, acc: 96.88%] [G loss: 2.794304]\n",
      "epoch:35 step:27386 [D loss: 0.473622, acc: 75.00%] [G loss: 4.780320]\n",
      "epoch:35 step:27387 [D loss: 0.124868, acc: 98.44%] [G loss: 6.930271]\n",
      "epoch:35 step:27388 [D loss: 0.364736, acc: 82.81%] [G loss: 5.998432]\n",
      "epoch:35 step:27389 [D loss: 0.271796, acc: 92.97%] [G loss: 3.369534]\n",
      "epoch:35 step:27390 [D loss: 0.106178, acc: 98.44%] [G loss: 5.155776]\n",
      "epoch:35 step:27391 [D loss: 0.312647, acc: 84.38%] [G loss: 3.394576]\n",
      "epoch:35 step:27392 [D loss: 0.101423, acc: 99.22%] [G loss: 5.079060]\n",
      "epoch:35 step:27393 [D loss: 1.291456, acc: 14.06%] [G loss: 7.214342]\n",
      "epoch:35 step:27394 [D loss: 0.058024, acc: 100.00%] [G loss: 3.914855]\n",
      "epoch:35 step:27395 [D loss: 0.103351, acc: 100.00%] [G loss: 4.305113]\n",
      "epoch:35 step:27396 [D loss: 0.086527, acc: 99.22%] [G loss: 5.521909]\n",
      "epoch:35 step:27397 [D loss: 0.826024, acc: 51.56%] [G loss: 5.355354]\n",
      "epoch:35 step:27398 [D loss: 0.891474, acc: 53.91%] [G loss: 3.285285]\n",
      "epoch:35 step:27399 [D loss: 0.939263, acc: 51.56%] [G loss: 4.136699]\n",
      "epoch:35 step:27400 [D loss: 0.197833, acc: 95.31%] [G loss: 3.211036]\n",
      "##############\n",
      "[0.8570661  0.86210367 0.82264589 0.81525046 0.78752477 0.80977645\n",
      " 0.88988751 0.82890675 0.80217819 0.82342355]\n",
      "##########\n",
      "epoch:35 step:27401 [D loss: 0.314137, acc: 94.53%] [G loss: 4.245898]\n",
      "epoch:35 step:27402 [D loss: 0.189585, acc: 96.09%] [G loss: 2.331987]\n",
      "epoch:35 step:27403 [D loss: 0.148455, acc: 97.66%] [G loss: 3.888928]\n",
      "epoch:35 step:27404 [D loss: 0.139051, acc: 99.22%] [G loss: 4.090846]\n",
      "epoch:35 step:27405 [D loss: 0.435395, acc: 85.16%] [G loss: 5.792870]\n",
      "epoch:35 step:27406 [D loss: 0.238202, acc: 96.88%] [G loss: 4.779700]\n",
      "epoch:35 step:27407 [D loss: 0.236443, acc: 94.53%] [G loss: 3.504554]\n",
      "epoch:35 step:27408 [D loss: 0.475691, acc: 68.75%] [G loss: 4.793484]\n",
      "epoch:35 step:27409 [D loss: 0.618486, acc: 60.94%] [G loss: 4.517582]\n",
      "epoch:35 step:27410 [D loss: 0.136419, acc: 99.22%] [G loss: 6.418895]\n",
      "epoch:35 step:27411 [D loss: 0.102783, acc: 98.44%] [G loss: 3.240830]\n",
      "epoch:35 step:27412 [D loss: 0.485280, acc: 81.25%] [G loss: 4.892760]\n",
      "epoch:35 step:27413 [D loss: 0.278975, acc: 95.31%] [G loss: 3.599718]\n",
      "epoch:35 step:27414 [D loss: 0.164198, acc: 99.22%] [G loss: 2.005697]\n",
      "epoch:35 step:27415 [D loss: 0.100453, acc: 100.00%] [G loss: 3.863490]\n",
      "epoch:35 step:27416 [D loss: 0.357914, acc: 87.50%] [G loss: 5.036324]\n",
      "epoch:35 step:27417 [D loss: 0.340027, acc: 92.19%] [G loss: 4.044382]\n",
      "epoch:35 step:27418 [D loss: 0.862535, acc: 51.56%] [G loss: 5.425228]\n",
      "epoch:35 step:27419 [D loss: 1.390268, acc: 50.00%] [G loss: 5.602063]\n",
      "epoch:35 step:27420 [D loss: 0.343652, acc: 79.69%] [G loss: 5.310396]\n",
      "epoch:35 step:27421 [D loss: 0.221972, acc: 96.88%] [G loss: 5.772859]\n",
      "epoch:35 step:27422 [D loss: 0.550973, acc: 66.41%] [G loss: 3.483445]\n",
      "epoch:35 step:27423 [D loss: 0.182111, acc: 97.66%] [G loss: 6.085656]\n",
      "epoch:35 step:27424 [D loss: 0.065460, acc: 100.00%] [G loss: 4.609094]\n",
      "epoch:35 step:27425 [D loss: 0.134607, acc: 97.66%] [G loss: 7.004366]\n",
      "epoch:35 step:27426 [D loss: 0.140282, acc: 97.66%] [G loss: 7.068403]\n",
      "epoch:35 step:27427 [D loss: 0.032895, acc: 100.00%] [G loss: 7.601575]\n",
      "epoch:35 step:27428 [D loss: 0.259330, acc: 93.75%] [G loss: 5.289412]\n",
      "epoch:35 step:27429 [D loss: 0.319520, acc: 92.97%] [G loss: 5.230791]\n",
      "epoch:35 step:27430 [D loss: 0.168226, acc: 98.44%] [G loss: 5.158367]\n",
      "epoch:35 step:27431 [D loss: 0.369857, acc: 83.59%] [G loss: 4.201803]\n",
      "epoch:35 step:27432 [D loss: 0.480119, acc: 75.78%] [G loss: 4.902733]\n",
      "epoch:35 step:27433 [D loss: 0.653363, acc: 58.59%] [G loss: 3.030833]\n",
      "epoch:35 step:27434 [D loss: 0.080948, acc: 100.00%] [G loss: 5.458023]\n",
      "epoch:35 step:27435 [D loss: 0.368927, acc: 84.38%] [G loss: 7.539822]\n",
      "epoch:35 step:27436 [D loss: 0.310347, acc: 92.97%] [G loss: 6.091415]\n",
      "epoch:35 step:27437 [D loss: 0.098762, acc: 100.00%] [G loss: 5.706514]\n",
      "epoch:35 step:27438 [D loss: 0.087417, acc: 100.00%] [G loss: 5.140360]\n",
      "epoch:35 step:27439 [D loss: 0.148693, acc: 99.22%] [G loss: 5.432880]\n",
      "epoch:35 step:27440 [D loss: 0.253699, acc: 92.19%] [G loss: 5.072308]\n",
      "epoch:35 step:27441 [D loss: 0.279377, acc: 93.75%] [G loss: 3.880513]\n",
      "epoch:35 step:27442 [D loss: 0.157147, acc: 99.22%] [G loss: 4.206953]\n",
      "epoch:35 step:27443 [D loss: 0.252931, acc: 96.09%] [G loss: 6.456102]\n",
      "epoch:35 step:27444 [D loss: 0.056971, acc: 100.00%] [G loss: 6.601792]\n",
      "epoch:35 step:27445 [D loss: 0.690376, acc: 56.25%] [G loss: 6.693826]\n",
      "epoch:35 step:27446 [D loss: 1.617408, acc: 50.00%] [G loss: 5.587413]\n",
      "epoch:35 step:27447 [D loss: 0.153831, acc: 96.88%] [G loss: 6.378306]\n",
      "epoch:35 step:27448 [D loss: 0.097171, acc: 99.22%] [G loss: 6.762231]\n",
      "epoch:35 step:27449 [D loss: 0.041567, acc: 100.00%] [G loss: 6.872506]\n",
      "epoch:35 step:27450 [D loss: 0.347221, acc: 92.19%] [G loss: 6.664050]\n",
      "epoch:35 step:27451 [D loss: 0.396580, acc: 85.94%] [G loss: 5.272323]\n",
      "epoch:35 step:27452 [D loss: 0.214062, acc: 96.09%] [G loss: 2.393667]\n",
      "epoch:35 step:27453 [D loss: 0.161964, acc: 100.00%] [G loss: 3.482211]\n",
      "epoch:35 step:27454 [D loss: 0.229140, acc: 92.97%] [G loss: 3.663963]\n",
      "epoch:35 step:27455 [D loss: 0.218380, acc: 97.66%] [G loss: 8.321842]\n",
      "epoch:35 step:27456 [D loss: 0.341623, acc: 86.72%] [G loss: 3.649767]\n",
      "epoch:35 step:27457 [D loss: 0.071625, acc: 99.22%] [G loss: 10.503038]\n",
      "epoch:35 step:27458 [D loss: 0.233310, acc: 95.31%] [G loss: 3.253491]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:35 step:27459 [D loss: 0.419302, acc: 75.00%] [G loss: 5.104760]\n",
      "epoch:35 step:27460 [D loss: 0.563500, acc: 64.84%] [G loss: 3.346784]\n",
      "epoch:35 step:27461 [D loss: 0.040316, acc: 100.00%] [G loss: 3.769170]\n",
      "epoch:35 step:27462 [D loss: 0.514664, acc: 65.62%] [G loss: 4.643172]\n",
      "epoch:35 step:27463 [D loss: 0.197135, acc: 97.66%] [G loss: 6.041735]\n",
      "epoch:35 step:27464 [D loss: 0.474360, acc: 69.53%] [G loss: 3.583252]\n",
      "epoch:35 step:27465 [D loss: 0.533131, acc: 64.06%] [G loss: 5.922177]\n",
      "epoch:35 step:27466 [D loss: 1.459509, acc: 11.72%] [G loss: 5.867424]\n",
      "epoch:35 step:27467 [D loss: 0.378886, acc: 84.38%] [G loss: 4.587660]\n",
      "epoch:35 step:27468 [D loss: 0.591022, acc: 63.28%] [G loss: 3.049860]\n",
      "epoch:35 step:27469 [D loss: 0.252341, acc: 94.53%] [G loss: 3.076143]\n",
      "epoch:35 step:27470 [D loss: 0.256017, acc: 93.75%] [G loss: 4.952852]\n",
      "epoch:35 step:27471 [D loss: 0.335571, acc: 92.19%] [G loss: 5.543672]\n",
      "epoch:35 step:27472 [D loss: 0.024084, acc: 100.00%] [G loss: 5.321566]\n",
      "epoch:35 step:27473 [D loss: 0.801439, acc: 50.00%] [G loss: 4.103858]\n",
      "epoch:35 step:27474 [D loss: 0.171019, acc: 98.44%] [G loss: 7.256941]\n",
      "epoch:35 step:27475 [D loss: 0.423949, acc: 80.47%] [G loss: 5.516318]\n",
      "epoch:35 step:27476 [D loss: 0.080618, acc: 100.00%] [G loss: 7.037962]\n",
      "epoch:35 step:27477 [D loss: 0.376405, acc: 88.28%] [G loss: 4.667377]\n",
      "epoch:35 step:27478 [D loss: 0.334285, acc: 92.19%] [G loss: 2.836674]\n",
      "epoch:35 step:27479 [D loss: 0.212794, acc: 96.09%] [G loss: 4.972085]\n",
      "epoch:35 step:27480 [D loss: 0.466339, acc: 84.38%] [G loss: 3.861690]\n",
      "epoch:35 step:27481 [D loss: 0.130975, acc: 100.00%] [G loss: 6.392245]\n",
      "epoch:35 step:27482 [D loss: 0.407005, acc: 84.38%] [G loss: 4.612441]\n",
      "epoch:35 step:27483 [D loss: 0.047632, acc: 100.00%] [G loss: 5.428945]\n",
      "epoch:35 step:27484 [D loss: 0.549908, acc: 78.12%] [G loss: 7.143931]\n",
      "epoch:35 step:27485 [D loss: 0.149425, acc: 97.66%] [G loss: 5.309190]\n",
      "epoch:35 step:27486 [D loss: 0.104213, acc: 99.22%] [G loss: 3.703537]\n",
      "epoch:35 step:27487 [D loss: 0.504612, acc: 77.34%] [G loss: 6.130894]\n",
      "epoch:35 step:27488 [D loss: 0.161027, acc: 96.09%] [G loss: 4.925597]\n",
      "epoch:35 step:27489 [D loss: 0.583829, acc: 68.75%] [G loss: 5.286493]\n",
      "epoch:35 step:27490 [D loss: 0.420844, acc: 74.22%] [G loss: 3.694502]\n",
      "epoch:35 step:27491 [D loss: 0.330195, acc: 85.94%] [G loss: 5.075336]\n",
      "epoch:35 step:27492 [D loss: 0.151169, acc: 98.44%] [G loss: 3.795666]\n",
      "epoch:35 step:27493 [D loss: 0.139446, acc: 98.44%] [G loss: 5.195306]\n",
      "epoch:35 step:27494 [D loss: 0.508896, acc: 77.34%] [G loss: 7.943721]\n",
      "epoch:35 step:27495 [D loss: 0.203709, acc: 93.75%] [G loss: 5.739640]\n",
      "epoch:35 step:27496 [D loss: 0.091032, acc: 100.00%] [G loss: 6.929407]\n",
      "epoch:35 step:27497 [D loss: 0.071387, acc: 100.00%] [G loss: 3.917660]\n",
      "epoch:35 step:27498 [D loss: 0.189178, acc: 94.53%] [G loss: 2.716492]\n",
      "epoch:35 step:27499 [D loss: 1.106906, acc: 28.91%] [G loss: 7.744371]\n",
      "epoch:35 step:27500 [D loss: 0.286164, acc: 89.06%] [G loss: 4.597817]\n",
      "epoch:35 step:27501 [D loss: 0.619705, acc: 65.62%] [G loss: 3.582393]\n",
      "epoch:35 step:27502 [D loss: 0.156306, acc: 98.44%] [G loss: 5.763414]\n",
      "epoch:35 step:27503 [D loss: 0.235231, acc: 94.53%] [G loss: 4.390252]\n",
      "epoch:35 step:27504 [D loss: 0.702072, acc: 57.03%] [G loss: 4.524631]\n",
      "epoch:35 step:27505 [D loss: 0.126431, acc: 99.22%] [G loss: 2.905184]\n",
      "epoch:35 step:27506 [D loss: 0.363206, acc: 78.12%] [G loss: 5.004335]\n",
      "epoch:35 step:27507 [D loss: 0.621824, acc: 64.06%] [G loss: 6.059493]\n",
      "epoch:35 step:27508 [D loss: 1.125136, acc: 40.62%] [G loss: 3.235319]\n",
      "epoch:35 step:27509 [D loss: 0.074406, acc: 100.00%] [G loss: 6.151017]\n",
      "epoch:35 step:27510 [D loss: 0.118905, acc: 100.00%] [G loss: 4.572489]\n",
      "epoch:35 step:27511 [D loss: 0.105318, acc: 100.00%] [G loss: 7.906308]\n",
      "epoch:35 step:27512 [D loss: 0.030677, acc: 100.00%] [G loss: 6.546090]\n",
      "epoch:35 step:27513 [D loss: 0.607703, acc: 64.06%] [G loss: 4.674682]\n",
      "epoch:35 step:27514 [D loss: 0.512953, acc: 71.88%] [G loss: 3.168654]\n",
      "epoch:35 step:27515 [D loss: 0.172428, acc: 98.44%] [G loss: 5.781276]\n",
      "epoch:35 step:27516 [D loss: 0.867275, acc: 42.19%] [G loss: 5.069704]\n",
      "epoch:35 step:27517 [D loss: 0.246452, acc: 92.97%] [G loss: 4.264114]\n",
      "epoch:35 step:27518 [D loss: 1.057217, acc: 24.22%] [G loss: 5.027895]\n",
      "epoch:35 step:27519 [D loss: 0.411527, acc: 86.72%] [G loss: 5.294672]\n",
      "epoch:35 step:27520 [D loss: 0.143765, acc: 99.22%] [G loss: 4.014414]\n",
      "epoch:35 step:27521 [D loss: 0.131035, acc: 97.66%] [G loss: 5.764692]\n",
      "epoch:35 step:27522 [D loss: 0.245752, acc: 91.41%] [G loss: 3.564615]\n",
      "epoch:35 step:27523 [D loss: 0.199344, acc: 98.44%] [G loss: 5.183551]\n",
      "epoch:35 step:27524 [D loss: 0.123534, acc: 99.22%] [G loss: 9.063210]\n",
      "epoch:35 step:27525 [D loss: 0.188898, acc: 96.09%] [G loss: 6.619473]\n",
      "epoch:35 step:27526 [D loss: 0.269263, acc: 92.97%] [G loss: 5.409577]\n",
      "epoch:35 step:27527 [D loss: 0.196659, acc: 97.66%] [G loss: 5.047656]\n",
      "epoch:35 step:27528 [D loss: 0.184144, acc: 97.66%] [G loss: 6.738624]\n",
      "epoch:35 step:27529 [D loss: 0.118720, acc: 97.66%] [G loss: 6.842813]\n",
      "epoch:35 step:27530 [D loss: 0.165034, acc: 97.66%] [G loss: 4.919041]\n",
      "epoch:35 step:27531 [D loss: 0.360219, acc: 89.06%] [G loss: 5.036160]\n",
      "epoch:35 step:27532 [D loss: 0.441771, acc: 75.00%] [G loss: 4.550050]\n",
      "epoch:35 step:27533 [D loss: 0.367259, acc: 75.78%] [G loss: 6.855680]\n",
      "epoch:35 step:27534 [D loss: 0.014254, acc: 100.00%] [G loss: 4.868300]\n",
      "epoch:35 step:27535 [D loss: 0.188016, acc: 98.44%] [G loss: 5.519882]\n",
      "epoch:35 step:27536 [D loss: 0.786038, acc: 51.56%] [G loss: 5.434068]\n",
      "epoch:35 step:27537 [D loss: 0.908365, acc: 41.41%] [G loss: 3.615637]\n",
      "epoch:35 step:27538 [D loss: 0.198094, acc: 93.75%] [G loss: 5.548372]\n",
      "epoch:35 step:27539 [D loss: 0.145832, acc: 99.22%] [G loss: 5.976790]\n",
      "epoch:35 step:27540 [D loss: 0.317381, acc: 93.75%] [G loss: 5.344294]\n",
      "epoch:35 step:27541 [D loss: 0.248244, acc: 92.97%] [G loss: 4.069574]\n",
      "epoch:35 step:27542 [D loss: 0.315518, acc: 82.03%] [G loss: 6.125810]\n",
      "epoch:35 step:27543 [D loss: 0.684791, acc: 55.47%] [G loss: 3.514830]\n",
      "epoch:35 step:27544 [D loss: 0.365550, acc: 81.25%] [G loss: 4.030565]\n",
      "epoch:35 step:27545 [D loss: 0.667698, acc: 56.25%] [G loss: 4.073391]\n",
      "epoch:35 step:27546 [D loss: 0.431294, acc: 83.59%] [G loss: 3.835656]\n",
      "epoch:35 step:27547 [D loss: 0.017244, acc: 100.00%] [G loss: 6.527300]\n",
      "epoch:35 step:27548 [D loss: 0.632042, acc: 60.16%] [G loss: 5.188680]\n",
      "epoch:35 step:27549 [D loss: 0.104811, acc: 100.00%] [G loss: 4.666718]\n",
      "epoch:35 step:27550 [D loss: 0.164404, acc: 97.66%] [G loss: 2.884196]\n",
      "epoch:35 step:27551 [D loss: 1.503498, acc: 34.38%] [G loss: 8.292721]\n",
      "epoch:35 step:27552 [D loss: 0.266982, acc: 96.88%] [G loss: 3.984719]\n",
      "epoch:35 step:27553 [D loss: 0.177720, acc: 99.22%] [G loss: 3.670981]\n",
      "epoch:35 step:27554 [D loss: 0.058035, acc: 100.00%] [G loss: 6.536810]\n",
      "epoch:35 step:27555 [D loss: 0.312882, acc: 87.50%] [G loss: 5.873298]\n",
      "epoch:35 step:27556 [D loss: 0.847204, acc: 51.56%] [G loss: 6.369983]\n",
      "epoch:35 step:27557 [D loss: 0.085832, acc: 100.00%] [G loss: 4.676530]\n",
      "epoch:35 step:27558 [D loss: 0.447885, acc: 80.47%] [G loss: 4.046525]\n",
      "epoch:35 step:27559 [D loss: 0.519893, acc: 64.06%] [G loss: 5.379643]\n",
      "epoch:35 step:27560 [D loss: 0.139383, acc: 99.22%] [G loss: 3.915609]\n",
      "epoch:35 step:27561 [D loss: 0.242784, acc: 90.62%] [G loss: 4.794549]\n",
      "epoch:35 step:27562 [D loss: 0.108882, acc: 99.22%] [G loss: 6.022561]\n",
      "epoch:35 step:27563 [D loss: 0.194444, acc: 96.88%] [G loss: 7.115786]\n",
      "epoch:35 step:27564 [D loss: 0.097051, acc: 100.00%] [G loss: 3.737310]\n",
      "epoch:35 step:27565 [D loss: 0.473338, acc: 73.44%] [G loss: 7.716146]\n",
      "epoch:35 step:27566 [D loss: 0.135094, acc: 98.44%] [G loss: 4.682458]\n",
      "epoch:35 step:27567 [D loss: 0.115312, acc: 98.44%] [G loss: 5.087201]\n",
      "epoch:35 step:27568 [D loss: 0.264764, acc: 88.28%] [G loss: 5.575160]\n",
      "epoch:35 step:27569 [D loss: 0.030644, acc: 100.00%] [G loss: 5.833526]\n",
      "epoch:35 step:27570 [D loss: 0.297652, acc: 93.75%] [G loss: 6.858943]\n",
      "epoch:35 step:27571 [D loss: 0.556053, acc: 67.97%] [G loss: 6.742909]\n",
      "epoch:35 step:27572 [D loss: 0.200793, acc: 96.88%] [G loss: 5.478420]\n",
      "epoch:35 step:27573 [D loss: 0.650291, acc: 57.81%] [G loss: 6.349390]\n",
      "epoch:35 step:27574 [D loss: 0.334827, acc: 90.62%] [G loss: 5.429860]\n",
      "epoch:35 step:27575 [D loss: 0.450421, acc: 85.16%] [G loss: 3.928673]\n",
      "epoch:35 step:27576 [D loss: 0.390636, acc: 75.00%] [G loss: 5.052965]\n",
      "epoch:35 step:27577 [D loss: 0.130295, acc: 98.44%] [G loss: 5.368982]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:35 step:27578 [D loss: 0.025881, acc: 100.00%] [G loss: 5.156687]\n",
      "epoch:35 step:27579 [D loss: 0.336463, acc: 86.72%] [G loss: 9.529867]\n",
      "epoch:35 step:27580 [D loss: 0.650756, acc: 57.81%] [G loss: 7.610528]\n",
      "epoch:35 step:27581 [D loss: 0.225810, acc: 98.44%] [G loss: 5.928767]\n",
      "epoch:35 step:27582 [D loss: 0.734071, acc: 54.69%] [G loss: 4.533193]\n",
      "epoch:35 step:27583 [D loss: 0.104348, acc: 100.00%] [G loss: 7.084681]\n",
      "epoch:35 step:27584 [D loss: 0.021669, acc: 100.00%] [G loss: 8.726860]\n",
      "epoch:35 step:27585 [D loss: 0.368709, acc: 75.78%] [G loss: 7.436947]\n",
      "epoch:35 step:27586 [D loss: 0.238335, acc: 92.19%] [G loss: 4.870791]\n",
      "epoch:35 step:27587 [D loss: 0.116004, acc: 100.00%] [G loss: 5.803436]\n",
      "epoch:35 step:27588 [D loss: 0.778016, acc: 52.34%] [G loss: 5.424664]\n",
      "epoch:35 step:27589 [D loss: 0.144040, acc: 100.00%] [G loss: 2.376125]\n",
      "epoch:35 step:27590 [D loss: 1.711210, acc: 50.00%] [G loss: 5.108265]\n",
      "epoch:35 step:27591 [D loss: 0.261939, acc: 94.53%] [G loss: 3.174152]\n",
      "epoch:35 step:27592 [D loss: 1.273579, acc: 47.66%] [G loss: 4.257026]\n",
      "epoch:35 step:27593 [D loss: 0.269415, acc: 97.66%] [G loss: 4.490041]\n",
      "epoch:35 step:27594 [D loss: 0.101539, acc: 99.22%] [G loss: 2.861062]\n",
      "epoch:35 step:27595 [D loss: 0.273224, acc: 89.84%] [G loss: 3.564702]\n",
      "epoch:35 step:27596 [D loss: 0.059865, acc: 100.00%] [G loss: 5.874235]\n",
      "epoch:35 step:27597 [D loss: 0.152378, acc: 100.00%] [G loss: 6.854331]\n",
      "epoch:35 step:27598 [D loss: 0.281011, acc: 93.75%] [G loss: 2.666585]\n",
      "epoch:35 step:27599 [D loss: 0.493843, acc: 79.69%] [G loss: 5.741074]\n",
      "epoch:35 step:27600 [D loss: 0.307069, acc: 91.41%] [G loss: 3.081594]\n",
      "##############\n",
      "[0.86434032 0.85214856 0.8332715  0.80387938 0.78241535 0.83677389\n",
      " 0.88918364 0.82759779 0.80196927 0.83070529]\n",
      "##########\n",
      "epoch:35 step:27601 [D loss: 0.055374, acc: 100.00%] [G loss: 4.489715]\n",
      "epoch:35 step:27602 [D loss: 0.103649, acc: 99.22%] [G loss: 5.619254]\n",
      "epoch:35 step:27603 [D loss: 0.137684, acc: 98.44%] [G loss: 4.027035]\n",
      "epoch:35 step:27604 [D loss: 0.030733, acc: 100.00%] [G loss: 3.120487]\n",
      "epoch:35 step:27605 [D loss: 0.141161, acc: 99.22%] [G loss: 7.059133]\n",
      "epoch:35 step:27606 [D loss: 0.116504, acc: 100.00%] [G loss: 6.189204]\n",
      "epoch:35 step:27607 [D loss: 0.292833, acc: 92.97%] [G loss: 4.544329]\n",
      "epoch:35 step:27608 [D loss: 0.175173, acc: 99.22%] [G loss: 5.680997]\n",
      "epoch:35 step:27609 [D loss: 0.606440, acc: 62.50%] [G loss: 3.741059]\n",
      "epoch:35 step:27610 [D loss: 1.685670, acc: 28.91%] [G loss: 6.010619]\n",
      "epoch:35 step:27611 [D loss: 0.608272, acc: 57.81%] [G loss: 4.099714]\n",
      "epoch:35 step:27612 [D loss: 0.281318, acc: 95.31%] [G loss: 8.103683]\n",
      "epoch:35 step:27613 [D loss: 0.161891, acc: 97.66%] [G loss: 7.678139]\n",
      "epoch:35 step:27614 [D loss: 0.022535, acc: 100.00%] [G loss: 5.514905]\n",
      "epoch:35 step:27615 [D loss: 0.090365, acc: 100.00%] [G loss: 2.524282]\n",
      "epoch:35 step:27616 [D loss: 0.477530, acc: 71.88%] [G loss: 5.358510]\n",
      "epoch:35 step:27617 [D loss: 0.545344, acc: 61.72%] [G loss: 4.655058]\n",
      "epoch:35 step:27618 [D loss: 0.179401, acc: 99.22%] [G loss: 4.592095]\n",
      "epoch:35 step:27619 [D loss: 0.842746, acc: 51.56%] [G loss: 3.197384]\n",
      "epoch:35 step:27620 [D loss: 0.017414, acc: 100.00%] [G loss: 3.964970]\n",
      "epoch:35 step:27621 [D loss: 0.332707, acc: 86.72%] [G loss: 4.639328]\n",
      "epoch:35 step:27622 [D loss: 0.134899, acc: 97.66%] [G loss: 4.819570]\n",
      "epoch:35 step:27623 [D loss: 0.240958, acc: 92.97%] [G loss: 6.220177]\n",
      "epoch:35 step:27624 [D loss: 0.059132, acc: 100.00%] [G loss: 5.002473]\n",
      "epoch:35 step:27625 [D loss: 0.659191, acc: 57.03%] [G loss: 4.079398]\n",
      "epoch:35 step:27626 [D loss: 0.930576, acc: 50.78%] [G loss: 5.162368]\n",
      "epoch:35 step:27627 [D loss: 0.101500, acc: 99.22%] [G loss: 6.591181]\n",
      "epoch:35 step:27628 [D loss: 0.040296, acc: 100.00%] [G loss: 2.848441]\n",
      "epoch:35 step:27629 [D loss: 0.508463, acc: 75.78%] [G loss: 6.012961]\n",
      "epoch:35 step:27630 [D loss: 0.462449, acc: 79.69%] [G loss: 4.065881]\n",
      "epoch:35 step:27631 [D loss: 0.063248, acc: 100.00%] [G loss: 6.409588]\n",
      "epoch:35 step:27632 [D loss: 0.098273, acc: 99.22%] [G loss: 4.248627]\n",
      "epoch:35 step:27633 [D loss: 1.792171, acc: 12.50%] [G loss: 4.450682]\n",
      "epoch:35 step:27634 [D loss: 0.107257, acc: 100.00%] [G loss: 5.243908]\n",
      "epoch:35 step:27635 [D loss: 0.197876, acc: 96.88%] [G loss: 5.440563]\n",
      "epoch:35 step:27636 [D loss: 0.629925, acc: 59.38%] [G loss: 5.509866]\n",
      "epoch:35 step:27637 [D loss: 0.270792, acc: 94.53%] [G loss: 3.463946]\n",
      "epoch:35 step:27638 [D loss: 0.197448, acc: 95.31%] [G loss: 4.940853]\n",
      "epoch:35 step:27639 [D loss: 0.341034, acc: 84.38%] [G loss: 7.304814]\n",
      "epoch:35 step:27640 [D loss: 0.517577, acc: 75.00%] [G loss: 6.595488]\n",
      "epoch:35 step:27641 [D loss: 0.107713, acc: 99.22%] [G loss: 7.388616]\n",
      "epoch:35 step:27642 [D loss: 0.151565, acc: 98.44%] [G loss: 5.852529]\n",
      "epoch:35 step:27643 [D loss: 0.246877, acc: 95.31%] [G loss: 3.561614]\n",
      "epoch:35 step:27644 [D loss: 0.186979, acc: 98.44%] [G loss: 4.465415]\n",
      "epoch:35 step:27645 [D loss: 1.045231, acc: 50.78%] [G loss: 5.854758]\n",
      "epoch:35 step:27646 [D loss: 0.194387, acc: 94.53%] [G loss: 3.445380]\n",
      "epoch:35 step:27647 [D loss: 0.800110, acc: 50.78%] [G loss: 7.677276]\n",
      "epoch:35 step:27648 [D loss: 0.433541, acc: 83.59%] [G loss: 6.209405]\n",
      "epoch:35 step:27649 [D loss: 0.292047, acc: 86.72%] [G loss: 4.584106]\n",
      "epoch:35 step:27650 [D loss: 0.125098, acc: 99.22%] [G loss: 4.132446]\n",
      "epoch:35 step:27651 [D loss: 0.204621, acc: 97.66%] [G loss: 4.481953]\n",
      "epoch:35 step:27652 [D loss: 0.436133, acc: 82.81%] [G loss: 4.596520]\n",
      "epoch:35 step:27653 [D loss: 1.000541, acc: 46.09%] [G loss: 4.440942]\n",
      "epoch:35 step:27654 [D loss: 0.164506, acc: 97.66%] [G loss: 2.668290]\n",
      "epoch:35 step:27655 [D loss: 0.794177, acc: 56.25%] [G loss: 5.179253]\n",
      "epoch:35 step:27656 [D loss: 1.216870, acc: 50.00%] [G loss: 3.601066]\n",
      "epoch:35 step:27657 [D loss: 0.126281, acc: 98.44%] [G loss: 5.772849]\n",
      "epoch:35 step:27658 [D loss: 0.144852, acc: 100.00%] [G loss: 5.531701]\n",
      "epoch:35 step:27659 [D loss: 0.384273, acc: 91.41%] [G loss: 4.974535]\n",
      "epoch:35 step:27660 [D loss: 0.328380, acc: 88.28%] [G loss: 6.013561]\n",
      "epoch:35 step:27661 [D loss: 0.261020, acc: 94.53%] [G loss: 5.291798]\n",
      "epoch:35 step:27662 [D loss: 0.330303, acc: 93.75%] [G loss: 3.836752]\n",
      "epoch:35 step:27663 [D loss: 0.192064, acc: 98.44%] [G loss: 6.916365]\n",
      "epoch:35 step:27664 [D loss: 0.153357, acc: 96.09%] [G loss: 7.292821]\n",
      "epoch:35 step:27665 [D loss: 0.103397, acc: 100.00%] [G loss: 8.338351]\n",
      "epoch:35 step:27666 [D loss: 0.167118, acc: 99.22%] [G loss: 4.850119]\n",
      "epoch:35 step:27667 [D loss: 0.069042, acc: 100.00%] [G loss: 4.131055]\n",
      "epoch:35 step:27668 [D loss: 0.174431, acc: 95.31%] [G loss: 5.429230]\n",
      "epoch:35 step:27669 [D loss: 0.555687, acc: 63.28%] [G loss: 4.387352]\n",
      "epoch:35 step:27670 [D loss: 0.223797, acc: 94.53%] [G loss: 7.717001]\n",
      "epoch:35 step:27671 [D loss: 0.074747, acc: 100.00%] [G loss: 6.126309]\n",
      "epoch:35 step:27672 [D loss: 0.229442, acc: 92.97%] [G loss: 7.055735]\n",
      "epoch:35 step:27673 [D loss: 0.812248, acc: 54.69%] [G loss: 6.546610]\n",
      "epoch:35 step:27674 [D loss: 0.191315, acc: 98.44%] [G loss: 5.110948]\n",
      "epoch:35 step:27675 [D loss: 0.567396, acc: 70.31%] [G loss: 6.615508]\n",
      "epoch:35 step:27676 [D loss: 0.150775, acc: 98.44%] [G loss: 3.193389]\n",
      "epoch:35 step:27677 [D loss: 0.329408, acc: 92.19%] [G loss: 6.726700]\n",
      "epoch:35 step:27678 [D loss: 0.366790, acc: 91.41%] [G loss: 4.603173]\n",
      "epoch:35 step:27679 [D loss: 0.361679, acc: 82.81%] [G loss: 3.794770]\n",
      "epoch:35 step:27680 [D loss: 0.092319, acc: 99.22%] [G loss: 5.060960]\n",
      "epoch:35 step:27681 [D loss: 1.550410, acc: 19.53%] [G loss: 4.108012]\n",
      "epoch:35 step:27682 [D loss: 0.116555, acc: 100.00%] [G loss: 5.914861]\n",
      "epoch:35 step:27683 [D loss: 1.646561, acc: 23.44%] [G loss: 8.254679]\n",
      "epoch:35 step:27684 [D loss: 0.052621, acc: 100.00%] [G loss: 3.511782]\n",
      "epoch:35 step:27685 [D loss: 0.263822, acc: 92.19%] [G loss: 4.147301]\n",
      "epoch:35 step:27686 [D loss: 0.230850, acc: 93.75%] [G loss: 6.488830]\n",
      "epoch:35 step:27687 [D loss: 0.005800, acc: 100.00%] [G loss: 7.370413]\n",
      "epoch:35 step:27688 [D loss: 0.670232, acc: 61.72%] [G loss: 5.548540]\n",
      "epoch:35 step:27689 [D loss: 0.110617, acc: 100.00%] [G loss: 2.198274]\n",
      "epoch:35 step:27690 [D loss: 1.301289, acc: 18.75%] [G loss: 5.362538]\n",
      "epoch:35 step:27691 [D loss: 0.514262, acc: 78.91%] [G loss: 4.279471]\n",
      "epoch:35 step:27692 [D loss: 0.166103, acc: 97.66%] [G loss: 6.299719]\n",
      "epoch:35 step:27693 [D loss: 0.221295, acc: 97.66%] [G loss: 2.629067]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:35 step:27694 [D loss: 0.505338, acc: 71.88%] [G loss: 7.233271]\n",
      "epoch:35 step:27695 [D loss: 0.569893, acc: 60.16%] [G loss: 7.066143]\n",
      "epoch:35 step:27696 [D loss: 0.148906, acc: 98.44%] [G loss: 5.440810]\n",
      "epoch:35 step:27697 [D loss: 0.610206, acc: 54.69%] [G loss: 6.200030]\n",
      "epoch:35 step:27698 [D loss: 1.003170, acc: 28.91%] [G loss: 4.486546]\n",
      "epoch:35 step:27699 [D loss: 0.775076, acc: 54.69%] [G loss: 4.746938]\n",
      "epoch:35 step:27700 [D loss: 0.079384, acc: 100.00%] [G loss: 5.813084]\n",
      "epoch:35 step:27701 [D loss: 0.680878, acc: 60.16%] [G loss: 6.690745]\n",
      "epoch:35 step:27702 [D loss: 0.056231, acc: 99.22%] [G loss: 4.863739]\n",
      "epoch:35 step:27703 [D loss: 0.163894, acc: 99.22%] [G loss: 4.855973]\n",
      "epoch:35 step:27704 [D loss: 0.210679, acc: 96.09%] [G loss: 4.360381]\n",
      "epoch:35 step:27705 [D loss: 0.209022, acc: 98.44%] [G loss: 3.980385]\n",
      "epoch:35 step:27706 [D loss: 0.314938, acc: 85.94%] [G loss: 4.829445]\n",
      "epoch:35 step:27707 [D loss: 0.222962, acc: 97.66%] [G loss: 5.124956]\n",
      "epoch:35 step:27708 [D loss: 0.964351, acc: 37.50%] [G loss: 5.966142]\n",
      "epoch:35 step:27709 [D loss: 0.160154, acc: 99.22%] [G loss: 3.029309]\n",
      "epoch:35 step:27710 [D loss: 0.243608, acc: 91.41%] [G loss: 6.608171]\n",
      "epoch:35 step:27711 [D loss: 0.275941, acc: 95.31%] [G loss: 3.030112]\n",
      "epoch:35 step:27712 [D loss: 0.060863, acc: 100.00%] [G loss: 5.022023]\n",
      "epoch:35 step:27713 [D loss: 0.135217, acc: 99.22%] [G loss: 4.162492]\n",
      "epoch:35 step:27714 [D loss: 0.063970, acc: 100.00%] [G loss: 7.750010]\n",
      "epoch:35 step:27715 [D loss: 0.026672, acc: 100.00%] [G loss: 6.350261]\n",
      "epoch:35 step:27716 [D loss: 0.171825, acc: 99.22%] [G loss: 4.467569]\n",
      "epoch:35 step:27717 [D loss: 0.221039, acc: 95.31%] [G loss: 4.813733]\n",
      "epoch:35 step:27718 [D loss: 0.752355, acc: 53.12%] [G loss: 4.767255]\n",
      "epoch:35 step:27719 [D loss: 0.041383, acc: 99.22%] [G loss: 5.493875]\n",
      "epoch:35 step:27720 [D loss: 0.204528, acc: 95.31%] [G loss: 4.325747]\n",
      "epoch:35 step:27721 [D loss: 0.471377, acc: 67.97%] [G loss: 4.794758]\n",
      "epoch:35 step:27722 [D loss: 0.096167, acc: 100.00%] [G loss: 6.062867]\n",
      "epoch:35 step:27723 [D loss: 0.524509, acc: 66.41%] [G loss: 4.778547]\n",
      "epoch:35 step:27724 [D loss: 0.853676, acc: 50.00%] [G loss: 3.237840]\n",
      "epoch:35 step:27725 [D loss: 0.154255, acc: 96.88%] [G loss: 5.056796]\n",
      "epoch:35 step:27726 [D loss: 0.261687, acc: 89.06%] [G loss: 6.407020]\n",
      "epoch:35 step:27727 [D loss: 0.099037, acc: 100.00%] [G loss: 4.721293]\n",
      "epoch:35 step:27728 [D loss: 0.616589, acc: 64.84%] [G loss: 4.559292]\n",
      "epoch:35 step:27729 [D loss: 0.167935, acc: 100.00%] [G loss: 2.922670]\n",
      "epoch:35 step:27730 [D loss: 0.241037, acc: 96.09%] [G loss: 5.780025]\n",
      "epoch:35 step:27731 [D loss: 0.322127, acc: 93.75%] [G loss: 5.766115]\n",
      "epoch:35 step:27732 [D loss: 0.629987, acc: 65.62%] [G loss: 3.275834]\n",
      "epoch:35 step:27733 [D loss: 0.210254, acc: 96.88%] [G loss: 6.182412]\n",
      "epoch:35 step:27734 [D loss: 0.540615, acc: 62.50%] [G loss: 6.727423]\n",
      "epoch:35 step:27735 [D loss: 0.312420, acc: 96.88%] [G loss: 4.234963]\n",
      "epoch:35 step:27736 [D loss: 0.025669, acc: 100.00%] [G loss: 9.917360]\n",
      "epoch:35 step:27737 [D loss: 0.107260, acc: 99.22%] [G loss: 4.172945]\n",
      "epoch:35 step:27738 [D loss: 0.347350, acc: 81.25%] [G loss: 7.390191]\n",
      "epoch:35 step:27739 [D loss: 0.184435, acc: 96.88%] [G loss: 5.318089]\n",
      "epoch:35 step:27740 [D loss: 0.518069, acc: 70.31%] [G loss: 5.661372]\n",
      "epoch:35 step:27741 [D loss: 0.362325, acc: 87.50%] [G loss: 5.040606]\n",
      "epoch:35 step:27742 [D loss: 0.011565, acc: 100.00%] [G loss: 6.681244]\n",
      "epoch:35 step:27743 [D loss: 0.215196, acc: 96.88%] [G loss: 6.014696]\n",
      "epoch:35 step:27744 [D loss: 1.136302, acc: 51.56%] [G loss: 6.135623]\n",
      "epoch:35 step:27745 [D loss: 0.738246, acc: 57.03%] [G loss: 4.989370]\n",
      "epoch:35 step:27746 [D loss: 0.106814, acc: 99.22%] [G loss: 6.319931]\n",
      "epoch:35 step:27747 [D loss: 0.671572, acc: 59.38%] [G loss: 4.884047]\n",
      "epoch:35 step:27748 [D loss: 0.021652, acc: 100.00%] [G loss: 5.398787]\n",
      "epoch:35 step:27749 [D loss: 0.291465, acc: 92.97%] [G loss: 5.874949]\n",
      "epoch:35 step:27750 [D loss: 0.264335, acc: 96.09%] [G loss: 1.489836]\n",
      "epoch:35 step:27751 [D loss: 0.360985, acc: 75.78%] [G loss: 8.116290]\n",
      "epoch:35 step:27752 [D loss: 0.614845, acc: 59.38%] [G loss: 3.953023]\n",
      "epoch:35 step:27753 [D loss: 0.184345, acc: 94.53%] [G loss: 4.551045]\n",
      "epoch:35 step:27754 [D loss: 0.570956, acc: 64.84%] [G loss: 4.688492]\n",
      "epoch:35 step:27755 [D loss: 0.208779, acc: 92.97%] [G loss: 3.756356]\n",
      "epoch:35 step:27756 [D loss: 0.393660, acc: 84.38%] [G loss: 4.727651]\n",
      "epoch:35 step:27757 [D loss: 0.030865, acc: 100.00%] [G loss: 6.159527]\n",
      "epoch:35 step:27758 [D loss: 0.138159, acc: 97.66%] [G loss: 3.549179]\n",
      "epoch:35 step:27759 [D loss: 0.455663, acc: 68.75%] [G loss: 3.548414]\n",
      "epoch:35 step:27760 [D loss: 0.341799, acc: 92.97%] [G loss: 4.374885]\n",
      "epoch:35 step:27761 [D loss: 0.052407, acc: 100.00%] [G loss: 7.164522]\n",
      "epoch:35 step:27762 [D loss: 1.682460, acc: 43.75%] [G loss: 7.258738]\n",
      "epoch:35 step:27763 [D loss: 0.101078, acc: 100.00%] [G loss: 5.102035]\n",
      "epoch:35 step:27764 [D loss: 0.133428, acc: 98.44%] [G loss: 7.345426]\n",
      "epoch:35 step:27765 [D loss: 0.305977, acc: 93.75%] [G loss: 8.040195]\n",
      "epoch:35 step:27766 [D loss: 0.595348, acc: 68.75%] [G loss: 3.854403]\n",
      "epoch:35 step:27767 [D loss: 0.197224, acc: 99.22%] [G loss: 4.272801]\n",
      "epoch:35 step:27768 [D loss: 0.895849, acc: 51.56%] [G loss: 5.009398]\n",
      "epoch:35 step:27769 [D loss: 0.035920, acc: 100.00%] [G loss: 7.931308]\n",
      "epoch:35 step:27770 [D loss: 0.419700, acc: 73.44%] [G loss: 4.397063]\n",
      "epoch:35 step:27771 [D loss: 0.597672, acc: 61.72%] [G loss: 4.531823]\n",
      "epoch:35 step:27772 [D loss: 0.128882, acc: 100.00%] [G loss: 5.150080]\n",
      "epoch:35 step:27773 [D loss: 0.125190, acc: 100.00%] [G loss: 7.669805]\n",
      "epoch:35 step:27774 [D loss: 0.057853, acc: 100.00%] [G loss: 4.488570]\n",
      "epoch:35 step:27775 [D loss: 0.645141, acc: 64.06%] [G loss: 3.278721]\n",
      "epoch:35 step:27776 [D loss: 0.337539, acc: 92.97%] [G loss: 7.127397]\n",
      "epoch:35 step:27777 [D loss: 0.439601, acc: 68.75%] [G loss: 7.144925]\n",
      "epoch:35 step:27778 [D loss: 0.154183, acc: 98.44%] [G loss: 3.849425]\n",
      "epoch:35 step:27779 [D loss: 0.058265, acc: 99.22%] [G loss: 4.741066]\n",
      "epoch:35 step:27780 [D loss: 0.739726, acc: 55.47%] [G loss: 5.354842]\n",
      "epoch:35 step:27781 [D loss: 0.128539, acc: 100.00%] [G loss: 3.876452]\n",
      "epoch:35 step:27782 [D loss: 0.279819, acc: 91.41%] [G loss: 4.256217]\n",
      "epoch:35 step:27783 [D loss: 0.356399, acc: 88.28%] [G loss: 3.559042]\n",
      "epoch:35 step:27784 [D loss: 0.081244, acc: 100.00%] [G loss: 5.461729]\n",
      "epoch:35 step:27785 [D loss: 0.111499, acc: 100.00%] [G loss: 6.347721]\n",
      "epoch:35 step:27786 [D loss: 0.126519, acc: 98.44%] [G loss: 4.602710]\n",
      "epoch:35 step:27787 [D loss: 0.237332, acc: 92.19%] [G loss: 4.857613]\n",
      "epoch:35 step:27788 [D loss: 0.289386, acc: 97.66%] [G loss: 5.434145]\n",
      "epoch:35 step:27789 [D loss: 0.802846, acc: 50.00%] [G loss: 4.416902]\n",
      "epoch:35 step:27790 [D loss: 0.576472, acc: 67.19%] [G loss: 9.656733]\n",
      "epoch:35 step:27791 [D loss: 0.352950, acc: 88.28%] [G loss: 7.185695]\n",
      "epoch:35 step:27792 [D loss: 0.467109, acc: 69.53%] [G loss: 4.626366]\n",
      "epoch:35 step:27793 [D loss: 0.054857, acc: 100.00%] [G loss: 7.809456]\n",
      "epoch:35 step:27794 [D loss: 0.499508, acc: 67.19%] [G loss: 3.193604]\n",
      "epoch:35 step:27795 [D loss: 0.279687, acc: 92.97%] [G loss: 10.638449]\n",
      "epoch:35 step:27796 [D loss: 0.036902, acc: 100.00%] [G loss: 6.095520]\n",
      "epoch:35 step:27797 [D loss: 0.039141, acc: 100.00%] [G loss: 4.484283]\n",
      "epoch:35 step:27798 [D loss: 0.229574, acc: 95.31%] [G loss: 4.149509]\n",
      "epoch:35 step:27799 [D loss: 0.336547, acc: 91.41%] [G loss: 4.903934]\n",
      "epoch:35 step:27800 [D loss: 0.191369, acc: 98.44%] [G loss: 4.159365]\n",
      "##############\n",
      "[0.85808601 0.8651256  0.84020831 0.81660258 0.77706174 0.84714137\n",
      " 0.91202262 0.81127403 0.80472587 0.82430594]\n",
      "##########\n",
      "epoch:35 step:27801 [D loss: 0.149516, acc: 97.66%] [G loss: 5.755774]\n",
      "epoch:35 step:27802 [D loss: 1.166230, acc: 38.28%] [G loss: 5.838687]\n",
      "epoch:35 step:27803 [D loss: 0.835185, acc: 52.34%] [G loss: 3.735687]\n",
      "epoch:35 step:27804 [D loss: 0.317355, acc: 92.97%] [G loss: 3.490467]\n",
      "epoch:35 step:27805 [D loss: 0.154438, acc: 100.00%] [G loss: 7.545775]\n",
      "epoch:35 step:27806 [D loss: 0.935822, acc: 50.00%] [G loss: 3.263728]\n",
      "epoch:35 step:27807 [D loss: 0.261364, acc: 87.50%] [G loss: 6.796100]\n",
      "epoch:35 step:27808 [D loss: 0.319864, acc: 93.75%] [G loss: 4.544951]\n",
      "epoch:35 step:27809 [D loss: 0.207287, acc: 99.22%] [G loss: 5.620793]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:35 step:27810 [D loss: 0.639709, acc: 62.50%] [G loss: 5.800145]\n",
      "epoch:35 step:27811 [D loss: 0.217562, acc: 96.09%] [G loss: 3.068960]\n",
      "epoch:35 step:27812 [D loss: 0.101765, acc: 100.00%] [G loss: 4.868518]\n",
      "epoch:35 step:27813 [D loss: 0.391654, acc: 77.34%] [G loss: 6.334718]\n",
      "epoch:35 step:27814 [D loss: 0.658402, acc: 60.94%] [G loss: 5.978606]\n",
      "epoch:35 step:27815 [D loss: 0.099721, acc: 100.00%] [G loss: 5.596183]\n",
      "epoch:35 step:27816 [D loss: 0.242821, acc: 96.09%] [G loss: 3.465020]\n",
      "epoch:35 step:27817 [D loss: 0.580220, acc: 71.09%] [G loss: 6.086519]\n",
      "epoch:35 step:27818 [D loss: 0.276299, acc: 93.75%] [G loss: 6.204280]\n",
      "epoch:35 step:27819 [D loss: 0.196041, acc: 98.44%] [G loss: 6.283690]\n",
      "epoch:35 step:27820 [D loss: 0.516623, acc: 80.47%] [G loss: 3.433630]\n",
      "epoch:35 step:27821 [D loss: 1.243607, acc: 50.00%] [G loss: 6.666265]\n",
      "epoch:35 step:27822 [D loss: 0.780838, acc: 55.47%] [G loss: 5.025337]\n",
      "epoch:35 step:27823 [D loss: 0.424319, acc: 75.00%] [G loss: 5.038901]\n",
      "epoch:35 step:27824 [D loss: 0.234488, acc: 94.53%] [G loss: 3.630892]\n",
      "epoch:35 step:27825 [D loss: 0.317786, acc: 84.38%] [G loss: 6.380025]\n",
      "epoch:35 step:27826 [D loss: 0.089907, acc: 100.00%] [G loss: 6.228978]\n",
      "epoch:35 step:27827 [D loss: 0.043930, acc: 100.00%] [G loss: 8.382376]\n",
      "epoch:35 step:27828 [D loss: 0.126604, acc: 99.22%] [G loss: 9.822866]\n",
      "epoch:35 step:27829 [D loss: 0.718658, acc: 56.25%] [G loss: 4.538387]\n",
      "epoch:35 step:27830 [D loss: 0.830567, acc: 50.00%] [G loss: 8.302558]\n",
      "epoch:35 step:27831 [D loss: 0.068088, acc: 99.22%] [G loss: 6.599320]\n",
      "epoch:35 step:27832 [D loss: 0.287361, acc: 91.41%] [G loss: 5.710444]\n",
      "epoch:35 step:27833 [D loss: 0.444568, acc: 85.94%] [G loss: 6.719963]\n",
      "epoch:35 step:27834 [D loss: 0.220801, acc: 96.09%] [G loss: 3.746311]\n",
      "epoch:35 step:27835 [D loss: 0.691561, acc: 57.03%] [G loss: 6.598093]\n",
      "epoch:35 step:27836 [D loss: 0.436104, acc: 75.78%] [G loss: 3.710616]\n",
      "epoch:35 step:27837 [D loss: 0.148672, acc: 98.44%] [G loss: 6.070465]\n",
      "epoch:35 step:27838 [D loss: 0.311558, acc: 86.72%] [G loss: 4.145166]\n",
      "epoch:35 step:27839 [D loss: 0.826132, acc: 44.53%] [G loss: 6.367671]\n",
      "epoch:35 step:27840 [D loss: 0.230418, acc: 96.09%] [G loss: 5.743885]\n",
      "epoch:35 step:27841 [D loss: 0.132201, acc: 100.00%] [G loss: 4.250776]\n",
      "epoch:35 step:27842 [D loss: 0.636424, acc: 59.38%] [G loss: 2.446780]\n",
      "epoch:35 step:27843 [D loss: 0.682668, acc: 57.81%] [G loss: 4.054920]\n",
      "epoch:35 step:27844 [D loss: 0.358315, acc: 85.16%] [G loss: 5.625206]\n",
      "epoch:35 step:27845 [D loss: 0.388398, acc: 75.78%] [G loss: 5.146791]\n",
      "epoch:35 step:27846 [D loss: 0.022374, acc: 100.00%] [G loss: 6.501460]\n",
      "epoch:35 step:27847 [D loss: 0.118046, acc: 100.00%] [G loss: 5.474202]\n",
      "epoch:35 step:27848 [D loss: 0.497165, acc: 60.94%] [G loss: 3.717603]\n",
      "epoch:35 step:27849 [D loss: 0.483610, acc: 70.31%] [G loss: 4.730008]\n",
      "epoch:35 step:27850 [D loss: 0.663749, acc: 59.38%] [G loss: 5.321722]\n",
      "epoch:35 step:27851 [D loss: 1.269644, acc: 41.41%] [G loss: 7.372102]\n",
      "epoch:35 step:27852 [D loss: 0.212083, acc: 96.88%] [G loss: 5.409504]\n",
      "epoch:35 step:27853 [D loss: 0.388548, acc: 81.25%] [G loss: 4.601129]\n",
      "epoch:35 step:27854 [D loss: 0.205364, acc: 97.66%] [G loss: 5.307139]\n",
      "epoch:35 step:27855 [D loss: 0.101067, acc: 98.44%] [G loss: 5.341815]\n",
      "epoch:35 step:27856 [D loss: 1.071134, acc: 50.00%] [G loss: 4.413971]\n",
      "epoch:35 step:27857 [D loss: 0.798298, acc: 54.69%] [G loss: 4.557822]\n",
      "epoch:35 step:27858 [D loss: 0.368797, acc: 90.62%] [G loss: 6.397024]\n",
      "epoch:35 step:27859 [D loss: 0.379045, acc: 90.62%] [G loss: 5.142930]\n",
      "epoch:35 step:27860 [D loss: 0.508845, acc: 78.91%] [G loss: 2.984989]\n",
      "epoch:35 step:27861 [D loss: 0.664115, acc: 57.03%] [G loss: 5.304671]\n",
      "epoch:35 step:27862 [D loss: 0.850048, acc: 54.69%] [G loss: 5.240575]\n",
      "epoch:35 step:27863 [D loss: 0.129150, acc: 99.22%] [G loss: 5.983974]\n",
      "epoch:35 step:27864 [D loss: 0.106919, acc: 100.00%] [G loss: 6.231273]\n",
      "epoch:35 step:27865 [D loss: 0.324222, acc: 83.59%] [G loss: 4.776159]\n",
      "epoch:35 step:27866 [D loss: 0.295384, acc: 92.19%] [G loss: 1.952429]\n",
      "epoch:35 step:27867 [D loss: 0.306572, acc: 84.38%] [G loss: 5.067081]\n",
      "epoch:35 step:27868 [D loss: 0.384525, acc: 75.78%] [G loss: 4.924223]\n",
      "epoch:35 step:27869 [D loss: 0.822012, acc: 52.34%] [G loss: 4.642063]\n",
      "epoch:35 step:27870 [D loss: 0.838549, acc: 53.12%] [G loss: 3.999842]\n",
      "epoch:35 step:27871 [D loss: 0.274084, acc: 92.19%] [G loss: 4.389805]\n",
      "epoch:35 step:27872 [D loss: 0.280975, acc: 95.31%] [G loss: 6.218843]\n",
      "epoch:35 step:27873 [D loss: 0.058575, acc: 100.00%] [G loss: 5.715194]\n",
      "epoch:35 step:27874 [D loss: 0.615826, acc: 68.75%] [G loss: 8.068836]\n",
      "epoch:35 step:27875 [D loss: 0.434433, acc: 72.66%] [G loss: 6.985517]\n",
      "epoch:35 step:27876 [D loss: 0.198728, acc: 93.75%] [G loss: 4.938824]\n",
      "epoch:35 step:27877 [D loss: 0.252486, acc: 89.84%] [G loss: 5.399127]\n",
      "epoch:35 step:27878 [D loss: 0.239885, acc: 97.66%] [G loss: 3.790601]\n",
      "epoch:35 step:27879 [D loss: 0.437963, acc: 75.78%] [G loss: 6.709161]\n",
      "epoch:35 step:27880 [D loss: 0.732228, acc: 52.34%] [G loss: 3.907308]\n",
      "epoch:35 step:27881 [D loss: 0.209996, acc: 94.53%] [G loss: 3.539261]\n",
      "epoch:35 step:27882 [D loss: 0.472971, acc: 67.97%] [G loss: 7.329256]\n",
      "epoch:35 step:27883 [D loss: 0.755229, acc: 56.25%] [G loss: 5.708840]\n",
      "epoch:35 step:27884 [D loss: 0.494623, acc: 63.28%] [G loss: 7.227627]\n",
      "epoch:35 step:27885 [D loss: 0.221305, acc: 96.09%] [G loss: 3.510567]\n",
      "epoch:35 step:27886 [D loss: 0.338876, acc: 95.31%] [G loss: 4.832123]\n",
      "epoch:35 step:27887 [D loss: 0.240001, acc: 89.84%] [G loss: 10.154789]\n",
      "epoch:35 step:27888 [D loss: 0.221805, acc: 99.22%] [G loss: 4.922518]\n",
      "epoch:35 step:27889 [D loss: 0.320896, acc: 92.19%] [G loss: 4.505466]\n",
      "epoch:35 step:27890 [D loss: 0.195792, acc: 96.88%] [G loss: 6.658349]\n",
      "epoch:35 step:27891 [D loss: 0.721553, acc: 59.38%] [G loss: 3.005693]\n",
      "epoch:35 step:27892 [D loss: 0.471614, acc: 75.78%] [G loss: 2.922534]\n",
      "epoch:35 step:27893 [D loss: 0.163949, acc: 96.09%] [G loss: 7.307150]\n",
      "epoch:35 step:27894 [D loss: 0.042864, acc: 100.00%] [G loss: 6.180332]\n",
      "epoch:35 step:27895 [D loss: 0.296407, acc: 84.38%] [G loss: 4.208918]\n",
      "epoch:35 step:27896 [D loss: 0.260972, acc: 93.75%] [G loss: 6.363562]\n",
      "epoch:35 step:27897 [D loss: 0.147419, acc: 100.00%] [G loss: 7.076822]\n",
      "epoch:35 step:27898 [D loss: 0.183864, acc: 95.31%] [G loss: 7.438851]\n",
      "epoch:35 step:27899 [D loss: 0.485767, acc: 71.88%] [G loss: 5.163351]\n",
      "epoch:35 step:27900 [D loss: 0.596598, acc: 64.84%] [G loss: 4.651209]\n",
      "epoch:35 step:27901 [D loss: 0.097946, acc: 100.00%] [G loss: 2.124555]\n",
      "epoch:35 step:27902 [D loss: 0.517240, acc: 78.12%] [G loss: 5.379686]\n",
      "epoch:35 step:27903 [D loss: 0.617786, acc: 67.19%] [G loss: 3.885022]\n",
      "epoch:35 step:27904 [D loss: 0.057451, acc: 100.00%] [G loss: 4.991868]\n",
      "epoch:35 step:27905 [D loss: 1.030922, acc: 49.22%] [G loss: 4.584089]\n",
      "epoch:35 step:27906 [D loss: 0.794048, acc: 46.09%] [G loss: 5.904311]\n",
      "epoch:35 step:27907 [D loss: 0.249934, acc: 95.31%] [G loss: 6.105598]\n",
      "epoch:35 step:27908 [D loss: 0.520856, acc: 75.00%] [G loss: 3.987348]\n",
      "epoch:35 step:27909 [D loss: 0.106796, acc: 99.22%] [G loss: 3.911320]\n",
      "epoch:35 step:27910 [D loss: 0.270697, acc: 91.41%] [G loss: 3.375470]\n",
      "epoch:35 step:27911 [D loss: 0.299281, acc: 86.72%] [G loss: 3.920511]\n",
      "epoch:35 step:27912 [D loss: 0.057095, acc: 100.00%] [G loss: 4.355416]\n",
      "epoch:35 step:27913 [D loss: 0.155538, acc: 98.44%] [G loss: 8.157984]\n",
      "epoch:35 step:27914 [D loss: 0.210325, acc: 98.44%] [G loss: 8.268022]\n",
      "epoch:35 step:27915 [D loss: 0.290313, acc: 94.53%] [G loss: 4.345159]\n",
      "epoch:35 step:27916 [D loss: 0.171238, acc: 100.00%] [G loss: 7.440187]\n",
      "epoch:35 step:27917 [D loss: 0.208772, acc: 96.88%] [G loss: 5.925126]\n",
      "epoch:35 step:27918 [D loss: 0.277483, acc: 92.19%] [G loss: 5.514383]\n",
      "epoch:35 step:27919 [D loss: 0.446368, acc: 82.81%] [G loss: 2.511955]\n",
      "epoch:35 step:27920 [D loss: 0.433311, acc: 75.00%] [G loss: 1.924591]\n",
      "epoch:35 step:27921 [D loss: 0.311968, acc: 85.16%] [G loss: 5.443199]\n",
      "epoch:35 step:27922 [D loss: 0.602393, acc: 59.38%] [G loss: 3.241584]\n",
      "epoch:35 step:27923 [D loss: 0.037972, acc: 100.00%] [G loss: 3.952377]\n",
      "epoch:35 step:27924 [D loss: 0.674173, acc: 57.03%] [G loss: 7.388986]\n",
      "epoch:35 step:27925 [D loss: 0.122521, acc: 99.22%] [G loss: 7.102695]\n",
      "epoch:35 step:27926 [D loss: 0.379767, acc: 85.16%] [G loss: 8.013527]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:35 step:27927 [D loss: 0.268738, acc: 95.31%] [G loss: 7.174582]\n",
      "epoch:35 step:27928 [D loss: 0.790957, acc: 52.34%] [G loss: 5.493186]\n",
      "epoch:35 step:27929 [D loss: 0.390222, acc: 76.56%] [G loss: 4.528601]\n",
      "epoch:35 step:27930 [D loss: 0.051339, acc: 100.00%] [G loss: 7.325078]\n",
      "epoch:35 step:27931 [D loss: 0.758642, acc: 56.25%] [G loss: 6.999379]\n",
      "epoch:35 step:27932 [D loss: 0.207849, acc: 92.97%] [G loss: 6.563166]\n",
      "epoch:35 step:27933 [D loss: 0.376597, acc: 82.03%] [G loss: 5.281854]\n",
      "epoch:35 step:27934 [D loss: 1.699156, acc: 14.06%] [G loss: 3.026604]\n",
      "epoch:35 step:27935 [D loss: 0.175477, acc: 97.66%] [G loss: 3.787694]\n",
      "epoch:35 step:27936 [D loss: 0.131027, acc: 100.00%] [G loss: 5.953322]\n",
      "epoch:35 step:27937 [D loss: 0.300219, acc: 86.72%] [G loss: 5.647021]\n",
      "epoch:35 step:27938 [D loss: 0.867389, acc: 53.12%] [G loss: 6.010060]\n",
      "epoch:35 step:27939 [D loss: 0.795121, acc: 55.47%] [G loss: 4.584520]\n",
      "epoch:35 step:27940 [D loss: 0.709859, acc: 56.25%] [G loss: 6.501451]\n",
      "epoch:35 step:27941 [D loss: 0.628216, acc: 57.81%] [G loss: 4.012541]\n",
      "epoch:35 step:27942 [D loss: 0.419221, acc: 79.69%] [G loss: 4.320359]\n",
      "epoch:35 step:27943 [D loss: 0.349583, acc: 84.38%] [G loss: 5.125375]\n",
      "epoch:35 step:27944 [D loss: 0.291798, acc: 92.97%] [G loss: 8.851166]\n",
      "epoch:35 step:27945 [D loss: 0.562794, acc: 64.06%] [G loss: 5.297766]\n",
      "epoch:35 step:27946 [D loss: 0.206058, acc: 97.66%] [G loss: 4.465941]\n",
      "epoch:35 step:27947 [D loss: 0.152551, acc: 98.44%] [G loss: 3.237323]\n",
      "epoch:35 step:27948 [D loss: 0.176972, acc: 97.66%] [G loss: 7.102836]\n",
      "epoch:35 step:27949 [D loss: 0.025663, acc: 100.00%] [G loss: 4.776623]\n",
      "epoch:35 step:27950 [D loss: 0.458733, acc: 74.22%] [G loss: 5.016453]\n",
      "epoch:35 step:27951 [D loss: 0.144701, acc: 96.88%] [G loss: 4.380463]\n",
      "epoch:35 step:27952 [D loss: 0.211278, acc: 96.88%] [G loss: 4.597980]\n",
      "epoch:35 step:27953 [D loss: 0.131902, acc: 98.44%] [G loss: 3.587684]\n",
      "epoch:35 step:27954 [D loss: 0.437275, acc: 81.25%] [G loss: 4.380381]\n",
      "epoch:35 step:27955 [D loss: 0.228399, acc: 91.41%] [G loss: 5.669752]\n",
      "epoch:35 step:27956 [D loss: 0.215192, acc: 98.44%] [G loss: 5.640162]\n",
      "epoch:35 step:27957 [D loss: 0.276484, acc: 86.72%] [G loss: 5.908643]\n",
      "epoch:35 step:27958 [D loss: 0.501273, acc: 78.12%] [G loss: 4.457835]\n",
      "epoch:35 step:27959 [D loss: 0.037371, acc: 100.00%] [G loss: 7.043609]\n",
      "epoch:35 step:27960 [D loss: 0.708596, acc: 56.25%] [G loss: 5.678241]\n",
      "epoch:35 step:27961 [D loss: 0.206059, acc: 96.09%] [G loss: 4.343388]\n",
      "epoch:35 step:27962 [D loss: 0.408510, acc: 85.94%] [G loss: 3.628186]\n",
      "epoch:35 step:27963 [D loss: 0.260662, acc: 93.75%] [G loss: 4.986469]\n",
      "epoch:35 step:27964 [D loss: 0.112926, acc: 98.44%] [G loss: 6.440825]\n",
      "epoch:35 step:27965 [D loss: 0.064375, acc: 100.00%] [G loss: 5.992736]\n",
      "epoch:35 step:27966 [D loss: 0.371576, acc: 86.72%] [G loss: 4.909280]\n",
      "epoch:35 step:27967 [D loss: 0.507022, acc: 75.00%] [G loss: 6.432524]\n",
      "epoch:35 step:27968 [D loss: 0.311175, acc: 92.97%] [G loss: 3.607352]\n",
      "epoch:35 step:27969 [D loss: 0.583623, acc: 66.41%] [G loss: 5.550305]\n",
      "epoch:35 step:27970 [D loss: 0.762955, acc: 53.91%] [G loss: 6.334914]\n",
      "epoch:35 step:27971 [D loss: 0.508839, acc: 61.72%] [G loss: 6.414881]\n",
      "epoch:35 step:27972 [D loss: 0.048385, acc: 100.00%] [G loss: 4.374224]\n",
      "epoch:35 step:27973 [D loss: 0.179265, acc: 98.44%] [G loss: 3.493392]\n",
      "epoch:35 step:27974 [D loss: 0.251485, acc: 91.41%] [G loss: 6.813468]\n",
      "epoch:35 step:27975 [D loss: 0.076473, acc: 100.00%] [G loss: 5.402375]\n",
      "epoch:35 step:27976 [D loss: 0.441237, acc: 82.03%] [G loss: 4.188086]\n",
      "epoch:35 step:27977 [D loss: 0.060704, acc: 100.00%] [G loss: 4.465209]\n",
      "epoch:35 step:27978 [D loss: 0.139434, acc: 100.00%] [G loss: 3.703180]\n",
      "epoch:35 step:27979 [D loss: 0.212006, acc: 96.88%] [G loss: 6.817451]\n",
      "epoch:35 step:27980 [D loss: 0.598736, acc: 60.94%] [G loss: 3.515500]\n",
      "epoch:35 step:27981 [D loss: 0.517535, acc: 76.56%] [G loss: 3.900381]\n",
      "epoch:35 step:27982 [D loss: 0.694700, acc: 59.38%] [G loss: 4.042606]\n",
      "epoch:35 step:27983 [D loss: 0.326348, acc: 85.94%] [G loss: 3.746200]\n",
      "epoch:35 step:27984 [D loss: 0.783851, acc: 50.78%] [G loss: 3.918361]\n",
      "epoch:35 step:27985 [D loss: 0.149834, acc: 98.44%] [G loss: 6.596354]\n",
      "epoch:35 step:27986 [D loss: 0.235467, acc: 95.31%] [G loss: 3.771850]\n",
      "epoch:35 step:27987 [D loss: 0.261761, acc: 92.19%] [G loss: 6.718425]\n",
      "epoch:35 step:27988 [D loss: 0.008816, acc: 100.00%] [G loss: 9.420064]\n",
      "epoch:35 step:27989 [D loss: 0.103269, acc: 98.44%] [G loss: 6.418319]\n",
      "epoch:35 step:27990 [D loss: 0.047732, acc: 100.00%] [G loss: 5.619678]\n",
      "epoch:35 step:27991 [D loss: 0.008034, acc: 100.00%] [G loss: 7.721943]\n",
      "epoch:35 step:27992 [D loss: 0.443056, acc: 82.81%] [G loss: 6.377081]\n",
      "epoch:35 step:27993 [D loss: 0.189552, acc: 97.66%] [G loss: 3.809799]\n",
      "epoch:35 step:27994 [D loss: 0.061603, acc: 100.00%] [G loss: 7.251824]\n",
      "epoch:35 step:27995 [D loss: 0.634169, acc: 63.28%] [G loss: 4.951356]\n",
      "epoch:35 step:27996 [D loss: 0.143534, acc: 98.44%] [G loss: 2.342054]\n",
      "epoch:35 step:27997 [D loss: 0.110337, acc: 100.00%] [G loss: 5.121479]\n",
      "epoch:35 step:27998 [D loss: 0.157968, acc: 96.09%] [G loss: 5.894543]\n",
      "epoch:35 step:27999 [D loss: 0.347285, acc: 83.59%] [G loss: 6.005190]\n",
      "epoch:35 step:28000 [D loss: 0.729095, acc: 57.03%] [G loss: 3.394044]\n",
      "##############\n",
      "[0.87537794 0.86230992 0.81411223 0.82597004 0.83250516 0.83044451\n",
      " 0.86928842 0.83229968 0.8118093  0.84372248]\n",
      "##########\n",
      "epoch:35 step:28001 [D loss: 0.624193, acc: 55.47%] [G loss: 6.688502]\n",
      "epoch:35 step:28002 [D loss: 0.172181, acc: 94.53%] [G loss: 5.714742]\n",
      "epoch:35 step:28003 [D loss: 0.534858, acc: 73.44%] [G loss: 4.908092]\n",
      "epoch:35 step:28004 [D loss: 1.236672, acc: 33.59%] [G loss: 6.722237]\n",
      "epoch:35 step:28005 [D loss: 0.171915, acc: 100.00%] [G loss: 6.479696]\n",
      "epoch:35 step:28006 [D loss: 0.070102, acc: 99.22%] [G loss: 5.528912]\n",
      "epoch:35 step:28007 [D loss: 0.439827, acc: 78.12%] [G loss: 6.692222]\n",
      "epoch:35 step:28008 [D loss: 0.115543, acc: 98.44%] [G loss: 7.702616]\n",
      "epoch:35 step:28009 [D loss: 0.220556, acc: 97.66%] [G loss: 6.932800]\n",
      "epoch:35 step:28010 [D loss: 0.041592, acc: 100.00%] [G loss: 4.707844]\n",
      "epoch:35 step:28011 [D loss: 0.673977, acc: 65.62%] [G loss: 7.349526]\n",
      "epoch:35 step:28012 [D loss: 0.033905, acc: 100.00%] [G loss: 5.261257]\n",
      "epoch:35 step:28013 [D loss: 0.214062, acc: 94.53%] [G loss: 5.287780]\n",
      "epoch:35 step:28014 [D loss: 0.153850, acc: 96.88%] [G loss: 7.961877]\n",
      "epoch:35 step:28015 [D loss: 0.180489, acc: 99.22%] [G loss: 5.618795]\n",
      "epoch:35 step:28016 [D loss: 0.080865, acc: 100.00%] [G loss: 5.450281]\n",
      "epoch:35 step:28017 [D loss: 0.418236, acc: 82.81%] [G loss: 5.185605]\n",
      "epoch:35 step:28018 [D loss: 0.224970, acc: 99.22%] [G loss: 4.200003]\n",
      "epoch:35 step:28019 [D loss: 0.290863, acc: 90.62%] [G loss: 4.952898]\n",
      "epoch:35 step:28020 [D loss: 0.196754, acc: 96.09%] [G loss: 4.877341]\n",
      "epoch:35 step:28021 [D loss: 0.368307, acc: 90.62%] [G loss: 5.618715]\n",
      "epoch:35 step:28022 [D loss: 0.442509, acc: 75.00%] [G loss: 5.902256]\n",
      "epoch:35 step:28023 [D loss: 0.093590, acc: 99.22%] [G loss: 8.266687]\n",
      "epoch:35 step:28024 [D loss: 0.407583, acc: 75.00%] [G loss: 5.154997]\n",
      "epoch:35 step:28025 [D loss: 0.419597, acc: 72.66%] [G loss: 8.007689]\n",
      "epoch:35 step:28026 [D loss: 0.468896, acc: 80.47%] [G loss: 6.428857]\n",
      "epoch:35 step:28027 [D loss: 0.719578, acc: 55.47%] [G loss: 8.017347]\n",
      "epoch:35 step:28028 [D loss: 1.020896, acc: 32.03%] [G loss: 4.920774]\n",
      "epoch:35 step:28029 [D loss: 0.604580, acc: 68.75%] [G loss: 4.444304]\n",
      "epoch:35 step:28030 [D loss: 0.404685, acc: 74.22%] [G loss: 4.684878]\n",
      "epoch:35 step:28031 [D loss: 0.522298, acc: 68.75%] [G loss: 7.350236]\n",
      "epoch:35 step:28032 [D loss: 0.168914, acc: 97.66%] [G loss: 7.299695]\n",
      "epoch:35 step:28033 [D loss: 0.278512, acc: 88.28%] [G loss: 2.796201]\n",
      "epoch:35 step:28034 [D loss: 0.331406, acc: 86.72%] [G loss: 4.254212]\n",
      "epoch:35 step:28035 [D loss: 0.064073, acc: 100.00%] [G loss: 4.097149]\n",
      "epoch:35 step:28036 [D loss: 1.393036, acc: 10.16%] [G loss: 5.674246]\n",
      "epoch:35 step:28037 [D loss: 0.175286, acc: 97.66%] [G loss: 6.532211]\n",
      "epoch:35 step:28038 [D loss: 0.095284, acc: 100.00%] [G loss: 3.411119]\n",
      "epoch:35 step:28039 [D loss: 0.040097, acc: 100.00%] [G loss: 7.073695]\n",
      "epoch:35 step:28040 [D loss: 0.067164, acc: 100.00%] [G loss: 5.247516]\n",
      "epoch:35 step:28041 [D loss: 1.209721, acc: 35.94%] [G loss: 6.424702]\n",
      "epoch:35 step:28042 [D loss: 0.098803, acc: 99.22%] [G loss: 4.041602]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:35 step:28043 [D loss: 0.124479, acc: 98.44%] [G loss: 4.517876]\n",
      "epoch:35 step:28044 [D loss: 0.340001, acc: 86.72%] [G loss: 7.070741]\n",
      "epoch:35 step:28045 [D loss: 0.088091, acc: 99.22%] [G loss: 5.667204]\n",
      "epoch:35 step:28046 [D loss: 0.058180, acc: 100.00%] [G loss: 8.990561]\n",
      "epoch:35 step:28047 [D loss: 0.479759, acc: 67.97%] [G loss: 5.923164]\n",
      "epoch:35 step:28048 [D loss: 0.398707, acc: 78.12%] [G loss: 5.139309]\n",
      "epoch:35 step:28049 [D loss: 0.044264, acc: 100.00%] [G loss: 4.187154]\n",
      "epoch:35 step:28050 [D loss: 0.126511, acc: 99.22%] [G loss: 6.618938]\n",
      "epoch:35 step:28051 [D loss: 0.292906, acc: 84.38%] [G loss: 5.807081]\n",
      "epoch:35 step:28052 [D loss: 0.092459, acc: 100.00%] [G loss: 6.692086]\n",
      "epoch:35 step:28053 [D loss: 0.655374, acc: 60.94%] [G loss: 6.677418]\n",
      "epoch:35 step:28054 [D loss: 0.126594, acc: 99.22%] [G loss: 6.145880]\n",
      "epoch:35 step:28055 [D loss: 0.285109, acc: 85.94%] [G loss: 4.460380]\n",
      "epoch:35 step:28056 [D loss: 0.132781, acc: 97.66%] [G loss: 3.473116]\n",
      "epoch:35 step:28057 [D loss: 0.243766, acc: 96.88%] [G loss: 4.067852]\n",
      "epoch:35 step:28058 [D loss: 0.026716, acc: 100.00%] [G loss: 5.830217]\n",
      "epoch:35 step:28059 [D loss: 0.061244, acc: 100.00%] [G loss: 5.678281]\n",
      "epoch:35 step:28060 [D loss: 0.319506, acc: 89.84%] [G loss: 4.386842]\n",
      "epoch:35 step:28061 [D loss: 0.312062, acc: 86.72%] [G loss: 5.915516]\n",
      "epoch:35 step:28062 [D loss: 0.096788, acc: 99.22%] [G loss: 5.249679]\n",
      "epoch:35 step:28063 [D loss: 0.209139, acc: 97.66%] [G loss: 1.770530]\n",
      "epoch:35 step:28064 [D loss: 0.467228, acc: 82.81%] [G loss: 5.181389]\n",
      "epoch:35 step:28065 [D loss: 0.209766, acc: 95.31%] [G loss: 5.822213]\n",
      "epoch:35 step:28066 [D loss: 0.398428, acc: 87.50%] [G loss: 3.442796]\n",
      "epoch:35 step:28067 [D loss: 0.216378, acc: 96.88%] [G loss: 3.752481]\n",
      "epoch:35 step:28068 [D loss: 0.335961, acc: 85.94%] [G loss: 6.105361]\n",
      "epoch:35 step:28069 [D loss: 0.426853, acc: 72.66%] [G loss: 6.367447]\n",
      "epoch:35 step:28070 [D loss: 0.738825, acc: 56.25%] [G loss: 5.620080]\n",
      "epoch:35 step:28071 [D loss: 0.039178, acc: 100.00%] [G loss: 5.562129]\n",
      "epoch:35 step:28072 [D loss: 0.096827, acc: 100.00%] [G loss: 10.974885]\n",
      "epoch:35 step:28073 [D loss: 0.125991, acc: 98.44%] [G loss: 4.941414]\n",
      "epoch:35 step:28074 [D loss: 0.250299, acc: 96.88%] [G loss: 5.314985]\n",
      "epoch:35 step:28075 [D loss: 0.602759, acc: 68.75%] [G loss: 4.833924]\n",
      "epoch:35 step:28076 [D loss: 1.001019, acc: 35.94%] [G loss: 6.015893]\n",
      "epoch:35 step:28077 [D loss: 0.388705, acc: 81.25%] [G loss: 5.173382]\n",
      "epoch:35 step:28078 [D loss: 0.051528, acc: 100.00%] [G loss: 7.224189]\n",
      "epoch:35 step:28079 [D loss: 0.408399, acc: 82.81%] [G loss: 4.615006]\n",
      "epoch:35 step:28080 [D loss: 0.068217, acc: 100.00%] [G loss: 5.219975]\n",
      "epoch:35 step:28081 [D loss: 0.577969, acc: 62.50%] [G loss: 3.743164]\n",
      "epoch:35 step:28082 [D loss: 0.163651, acc: 96.09%] [G loss: 5.487721]\n",
      "epoch:35 step:28083 [D loss: 0.707774, acc: 58.59%] [G loss: 6.472862]\n",
      "epoch:35 step:28084 [D loss: 0.794218, acc: 52.34%] [G loss: 6.112211]\n",
      "epoch:35 step:28085 [D loss: 0.187896, acc: 99.22%] [G loss: 4.580762]\n",
      "epoch:35 step:28086 [D loss: 0.692291, acc: 55.47%] [G loss: 5.481900]\n",
      "epoch:35 step:28087 [D loss: 0.172091, acc: 96.88%] [G loss: 5.663290]\n",
      "epoch:35 step:28088 [D loss: 0.272033, acc: 94.53%] [G loss: 5.150500]\n",
      "epoch:35 step:28089 [D loss: 0.082288, acc: 100.00%] [G loss: 6.428165]\n",
      "epoch:35 step:28090 [D loss: 0.201238, acc: 97.66%] [G loss: 5.083808]\n",
      "epoch:35 step:28091 [D loss: 0.174749, acc: 97.66%] [G loss: 4.815690]\n",
      "epoch:35 step:28092 [D loss: 0.090562, acc: 100.00%] [G loss: 5.966201]\n",
      "epoch:35 step:28093 [D loss: 0.423406, acc: 82.81%] [G loss: 3.877091]\n",
      "epoch:35 step:28094 [D loss: 0.580978, acc: 66.41%] [G loss: 4.911497]\n",
      "epoch:35 step:28095 [D loss: 0.899936, acc: 52.34%] [G loss: 4.387259]\n",
      "epoch:35 step:28096 [D loss: 0.103468, acc: 99.22%] [G loss: 5.173476]\n",
      "epoch:35 step:28097 [D loss: 0.505382, acc: 77.34%] [G loss: 4.086033]\n",
      "epoch:35 step:28098 [D loss: 0.019342, acc: 100.00%] [G loss: 4.960790]\n",
      "epoch:35 step:28099 [D loss: 0.222324, acc: 92.97%] [G loss: 10.358050]\n",
      "epoch:35 step:28100 [D loss: 0.132983, acc: 99.22%] [G loss: 6.040594]\n",
      "epoch:35 step:28101 [D loss: 0.147321, acc: 99.22%] [G loss: 4.372593]\n",
      "epoch:35 step:28102 [D loss: 0.154650, acc: 100.00%] [G loss: 5.655017]\n",
      "epoch:35 step:28103 [D loss: 0.072369, acc: 99.22%] [G loss: 6.395864]\n",
      "epoch:35 step:28104 [D loss: 1.097141, acc: 41.41%] [G loss: 5.513182]\n",
      "epoch:35 step:28105 [D loss: 0.422378, acc: 72.66%] [G loss: 4.637102]\n",
      "epoch:35 step:28106 [D loss: 0.036743, acc: 100.00%] [G loss: 3.914838]\n",
      "epoch:35 step:28107 [D loss: 0.113604, acc: 99.22%] [G loss: 6.933536]\n",
      "epoch:35 step:28108 [D loss: 0.171420, acc: 95.31%] [G loss: 8.337957]\n",
      "epoch:35 step:28109 [D loss: 1.075489, acc: 44.53%] [G loss: 6.841264]\n",
      "epoch:35 step:28110 [D loss: 0.277377, acc: 89.84%] [G loss: 4.042783]\n",
      "epoch:35 step:28111 [D loss: 0.320486, acc: 82.03%] [G loss: 5.794481]\n",
      "epoch:35 step:28112 [D loss: 0.552340, acc: 75.00%] [G loss: 8.281239]\n",
      "epoch:35 step:28113 [D loss: 0.064943, acc: 100.00%] [G loss: 5.665419]\n",
      "epoch:35 step:28114 [D loss: 0.744046, acc: 55.47%] [G loss: 4.938361]\n",
      "epoch:35 step:28115 [D loss: 0.226128, acc: 92.97%] [G loss: 3.730347]\n",
      "epoch:35 step:28116 [D loss: 0.273932, acc: 93.75%] [G loss: 5.643715]\n",
      "epoch:36 step:28117 [D loss: 0.239312, acc: 92.19%] [G loss: 4.787635]\n",
      "epoch:36 step:28118 [D loss: 0.270965, acc: 90.62%] [G loss: 5.758952]\n",
      "epoch:36 step:28119 [D loss: 0.389244, acc: 84.38%] [G loss: 6.593964]\n",
      "epoch:36 step:28120 [D loss: 0.007205, acc: 100.00%] [G loss: 11.276855]\n",
      "epoch:36 step:28121 [D loss: 0.022933, acc: 100.00%] [G loss: 5.282176]\n",
      "epoch:36 step:28122 [D loss: 0.137458, acc: 99.22%] [G loss: 8.380539]\n",
      "epoch:36 step:28123 [D loss: 0.939936, acc: 53.12%] [G loss: 1.850376]\n",
      "epoch:36 step:28124 [D loss: 0.015526, acc: 100.00%] [G loss: 8.082987]\n",
      "epoch:36 step:28125 [D loss: 0.296850, acc: 94.53%] [G loss: 3.813680]\n",
      "epoch:36 step:28126 [D loss: 0.287399, acc: 87.50%] [G loss: 8.328594]\n",
      "epoch:36 step:28127 [D loss: 0.857603, acc: 52.34%] [G loss: 7.647506]\n",
      "epoch:36 step:28128 [D loss: 1.592321, acc: 6.25%] [G loss: 5.028741]\n",
      "epoch:36 step:28129 [D loss: 0.209927, acc: 97.66%] [G loss: 5.842253]\n",
      "epoch:36 step:28130 [D loss: 0.561190, acc: 78.12%] [G loss: 5.689360]\n",
      "epoch:36 step:28131 [D loss: 0.225054, acc: 96.88%] [G loss: 5.263236]\n",
      "epoch:36 step:28132 [D loss: 0.326193, acc: 85.94%] [G loss: 4.160270]\n",
      "epoch:36 step:28133 [D loss: 0.400307, acc: 78.12%] [G loss: 3.703313]\n",
      "epoch:36 step:28134 [D loss: 0.498865, acc: 69.53%] [G loss: 5.555630]\n",
      "epoch:36 step:28135 [D loss: 0.474541, acc: 79.69%] [G loss: 5.318401]\n",
      "epoch:36 step:28136 [D loss: 0.119811, acc: 98.44%] [G loss: 7.604504]\n",
      "epoch:36 step:28137 [D loss: 0.366870, acc: 77.34%] [G loss: 5.405532]\n",
      "epoch:36 step:28138 [D loss: 0.173185, acc: 97.66%] [G loss: 6.390375]\n",
      "epoch:36 step:28139 [D loss: 0.419546, acc: 89.84%] [G loss: 5.011557]\n",
      "epoch:36 step:28140 [D loss: 1.196953, acc: 50.78%] [G loss: 7.387507]\n",
      "epoch:36 step:28141 [D loss: 0.115020, acc: 99.22%] [G loss: 4.996433]\n",
      "epoch:36 step:28142 [D loss: 0.457072, acc: 65.62%] [G loss: 6.204406]\n",
      "epoch:36 step:28143 [D loss: 0.544558, acc: 74.22%] [G loss: 4.030187]\n",
      "epoch:36 step:28144 [D loss: 0.270993, acc: 89.06%] [G loss: 6.062198]\n",
      "epoch:36 step:28145 [D loss: 0.066408, acc: 100.00%] [G loss: 7.029177]\n",
      "epoch:36 step:28146 [D loss: 0.032314, acc: 100.00%] [G loss: 8.667915]\n",
      "epoch:36 step:28147 [D loss: 0.244494, acc: 97.66%] [G loss: 4.193194]\n",
      "epoch:36 step:28148 [D loss: 0.630706, acc: 67.19%] [G loss: 6.421686]\n",
      "epoch:36 step:28149 [D loss: 0.400594, acc: 79.69%] [G loss: 4.644970]\n",
      "epoch:36 step:28150 [D loss: 0.514376, acc: 72.66%] [G loss: 7.569458]\n",
      "epoch:36 step:28151 [D loss: 0.323361, acc: 83.59%] [G loss: 7.175522]\n",
      "epoch:36 step:28152 [D loss: 0.043217, acc: 100.00%] [G loss: 4.204942]\n",
      "epoch:36 step:28153 [D loss: 0.064180, acc: 100.00%] [G loss: 4.906893]\n",
      "epoch:36 step:28154 [D loss: 0.646632, acc: 65.62%] [G loss: 4.832602]\n",
      "epoch:36 step:28155 [D loss: 0.948688, acc: 52.34%] [G loss: 4.188011]\n",
      "epoch:36 step:28156 [D loss: 0.212983, acc: 94.53%] [G loss: 5.393923]\n",
      "epoch:36 step:28157 [D loss: 0.211921, acc: 93.75%] [G loss: 5.645550]\n",
      "epoch:36 step:28158 [D loss: 0.152677, acc: 96.88%] [G loss: 6.193691]\n",
      "epoch:36 step:28159 [D loss: 0.388134, acc: 84.38%] [G loss: 3.911991]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:36 step:28160 [D loss: 0.446617, acc: 80.47%] [G loss: 6.166971]\n",
      "epoch:36 step:28161 [D loss: 0.127742, acc: 97.66%] [G loss: 7.189224]\n",
      "epoch:36 step:28162 [D loss: 1.882071, acc: 16.41%] [G loss: 6.471849]\n",
      "epoch:36 step:28163 [D loss: 0.140122, acc: 99.22%] [G loss: 4.855566]\n",
      "epoch:36 step:28164 [D loss: 0.869556, acc: 56.25%] [G loss: 5.675636]\n",
      "epoch:36 step:28165 [D loss: 0.136850, acc: 98.44%] [G loss: 4.215488]\n",
      "epoch:36 step:28166 [D loss: 0.217721, acc: 96.88%] [G loss: 4.792797]\n",
      "epoch:36 step:28167 [D loss: 0.282037, acc: 90.62%] [G loss: 4.502901]\n",
      "epoch:36 step:28168 [D loss: 0.020075, acc: 100.00%] [G loss: 3.696370]\n",
      "epoch:36 step:28169 [D loss: 0.046538, acc: 100.00%] [G loss: 7.632687]\n",
      "epoch:36 step:28170 [D loss: 0.178836, acc: 98.44%] [G loss: 3.555704]\n",
      "epoch:36 step:28171 [D loss: 0.364929, acc: 79.69%] [G loss: 4.610237]\n",
      "epoch:36 step:28172 [D loss: 0.247471, acc: 89.06%] [G loss: 4.976449]\n",
      "epoch:36 step:28173 [D loss: 0.285105, acc: 90.62%] [G loss: 8.222665]\n",
      "epoch:36 step:28174 [D loss: 0.067043, acc: 99.22%] [G loss: 6.092829]\n",
      "epoch:36 step:28175 [D loss: 0.686812, acc: 57.03%] [G loss: 4.899709]\n",
      "epoch:36 step:28176 [D loss: 0.159031, acc: 98.44%] [G loss: 6.098050]\n",
      "epoch:36 step:28177 [D loss: 0.249429, acc: 96.88%] [G loss: 3.063970]\n",
      "epoch:36 step:28178 [D loss: 0.014868, acc: 100.00%] [G loss: 7.739228]\n",
      "epoch:36 step:28179 [D loss: 1.078062, acc: 48.44%] [G loss: 4.431540]\n",
      "epoch:36 step:28180 [D loss: 0.356262, acc: 86.72%] [G loss: 5.468750]\n",
      "epoch:36 step:28181 [D loss: 0.494110, acc: 74.22%] [G loss: 7.676904]\n",
      "epoch:36 step:28182 [D loss: 0.207151, acc: 95.31%] [G loss: 5.050653]\n",
      "epoch:36 step:28183 [D loss: 1.205009, acc: 51.56%] [G loss: 3.356510]\n",
      "epoch:36 step:28184 [D loss: 0.455545, acc: 74.22%] [G loss: 2.853464]\n",
      "epoch:36 step:28185 [D loss: 0.525829, acc: 65.62%] [G loss: 8.375925]\n",
      "epoch:36 step:28186 [D loss: 0.399954, acc: 79.69%] [G loss: 7.847959]\n",
      "epoch:36 step:28187 [D loss: 0.308693, acc: 93.75%] [G loss: 5.279922]\n",
      "epoch:36 step:28188 [D loss: 0.054645, acc: 100.00%] [G loss: 4.145829]\n",
      "epoch:36 step:28189 [D loss: 1.082330, acc: 26.56%] [G loss: 4.699389]\n",
      "epoch:36 step:28190 [D loss: 0.167560, acc: 96.88%] [G loss: 4.548719]\n",
      "epoch:36 step:28191 [D loss: 0.653840, acc: 54.69%] [G loss: 2.935665]\n",
      "epoch:36 step:28192 [D loss: 0.405015, acc: 77.34%] [G loss: 8.573132]\n",
      "epoch:36 step:28193 [D loss: 0.036900, acc: 100.00%] [G loss: 5.310996]\n",
      "epoch:36 step:28194 [D loss: 0.827752, acc: 46.09%] [G loss: 3.818880]\n",
      "epoch:36 step:28195 [D loss: 0.198342, acc: 94.53%] [G loss: 6.468443]\n",
      "epoch:36 step:28196 [D loss: 0.226211, acc: 93.75%] [G loss: 5.777675]\n",
      "epoch:36 step:28197 [D loss: 0.403455, acc: 78.12%] [G loss: 6.258180]\n",
      "epoch:36 step:28198 [D loss: 0.472875, acc: 71.88%] [G loss: 5.709935]\n",
      "epoch:36 step:28199 [D loss: 0.525395, acc: 63.28%] [G loss: 4.342592]\n",
      "epoch:36 step:28200 [D loss: 0.628613, acc: 60.16%] [G loss: 7.754558]\n",
      "##############\n",
      "[0.8529099  0.87947572 0.81745729 0.82526928 0.7868759  0.82700218\n",
      " 0.87739758 0.79574508 0.80845151 0.84387926]\n",
      "##########\n",
      "epoch:36 step:28201 [D loss: 0.046409, acc: 100.00%] [G loss: 3.314876]\n",
      "epoch:36 step:28202 [D loss: 0.232850, acc: 98.44%] [G loss: 4.378064]\n",
      "epoch:36 step:28203 [D loss: 0.268987, acc: 87.50%] [G loss: 8.044231]\n",
      "epoch:36 step:28204 [D loss: 0.696585, acc: 60.16%] [G loss: 6.477644]\n",
      "epoch:36 step:28205 [D loss: 0.043734, acc: 100.00%] [G loss: 7.528437]\n",
      "epoch:36 step:28206 [D loss: 0.034191, acc: 100.00%] [G loss: 4.606476]\n",
      "epoch:36 step:28207 [D loss: 0.107124, acc: 100.00%] [G loss: 7.524517]\n",
      "epoch:36 step:28208 [D loss: 0.703023, acc: 60.94%] [G loss: 8.166855]\n",
      "epoch:36 step:28209 [D loss: 0.411616, acc: 74.22%] [G loss: 6.623846]\n",
      "epoch:36 step:28210 [D loss: 0.475936, acc: 75.00%] [G loss: 6.232203]\n",
      "epoch:36 step:28211 [D loss: 0.186615, acc: 95.31%] [G loss: 7.537537]\n",
      "epoch:36 step:28212 [D loss: 0.165409, acc: 98.44%] [G loss: 5.686518]\n",
      "epoch:36 step:28213 [D loss: 0.143392, acc: 99.22%] [G loss: 4.437429]\n",
      "epoch:36 step:28214 [D loss: 0.491011, acc: 71.09%] [G loss: 5.632715]\n",
      "epoch:36 step:28215 [D loss: 0.433844, acc: 71.88%] [G loss: 4.468074]\n",
      "epoch:36 step:28216 [D loss: 0.051131, acc: 100.00%] [G loss: 5.701719]\n",
      "epoch:36 step:28217 [D loss: 0.174753, acc: 97.66%] [G loss: 4.349971]\n",
      "epoch:36 step:28218 [D loss: 0.307272, acc: 94.53%] [G loss: 3.752773]\n",
      "epoch:36 step:28219 [D loss: 0.203212, acc: 97.66%] [G loss: 2.680184]\n",
      "epoch:36 step:28220 [D loss: 0.043476, acc: 100.00%] [G loss: 4.550043]\n",
      "epoch:36 step:28221 [D loss: 0.435806, acc: 79.69%] [G loss: 5.994299]\n",
      "epoch:36 step:28222 [D loss: 1.053503, acc: 26.56%] [G loss: 6.848678]\n",
      "epoch:36 step:28223 [D loss: 0.717326, acc: 53.91%] [G loss: 4.452990]\n",
      "epoch:36 step:28224 [D loss: 0.328987, acc: 82.81%] [G loss: 5.518229]\n",
      "epoch:36 step:28225 [D loss: 0.462945, acc: 79.69%] [G loss: 7.529033]\n",
      "epoch:36 step:28226 [D loss: 0.404691, acc: 86.72%] [G loss: 6.980073]\n",
      "epoch:36 step:28227 [D loss: 0.140822, acc: 100.00%] [G loss: 5.556758]\n",
      "epoch:36 step:28228 [D loss: 0.164393, acc: 95.31%] [G loss: 5.542057]\n",
      "epoch:36 step:28229 [D loss: 0.044291, acc: 100.00%] [G loss: 4.218400]\n",
      "epoch:36 step:28230 [D loss: 0.125160, acc: 100.00%] [G loss: 4.623330]\n",
      "epoch:36 step:28231 [D loss: 1.104013, acc: 36.72%] [G loss: 4.682646]\n",
      "epoch:36 step:28232 [D loss: 0.270439, acc: 96.88%] [G loss: 5.582641]\n",
      "epoch:36 step:28233 [D loss: 0.201203, acc: 96.88%] [G loss: 7.396030]\n",
      "epoch:36 step:28234 [D loss: 0.252039, acc: 95.31%] [G loss: 5.333536]\n",
      "epoch:36 step:28235 [D loss: 0.390125, acc: 76.56%] [G loss: 5.377319]\n",
      "epoch:36 step:28236 [D loss: 0.810943, acc: 53.12%] [G loss: 3.900697]\n",
      "epoch:36 step:28237 [D loss: 0.580182, acc: 64.06%] [G loss: 6.449185]\n",
      "epoch:36 step:28238 [D loss: 0.308495, acc: 84.38%] [G loss: 7.290576]\n",
      "epoch:36 step:28239 [D loss: 0.186328, acc: 92.97%] [G loss: 8.816254]\n",
      "epoch:36 step:28240 [D loss: 0.699710, acc: 55.47%] [G loss: 9.067117]\n",
      "epoch:36 step:28241 [D loss: 0.046667, acc: 100.00%] [G loss: 4.506444]\n",
      "epoch:36 step:28242 [D loss: 0.837523, acc: 51.56%] [G loss: 7.117830]\n",
      "epoch:36 step:28243 [D loss: 0.162582, acc: 97.66%] [G loss: 5.438555]\n",
      "epoch:36 step:28244 [D loss: 0.197674, acc: 91.41%] [G loss: 5.283339]\n",
      "epoch:36 step:28245 [D loss: 0.203017, acc: 98.44%] [G loss: 3.962412]\n",
      "epoch:36 step:28246 [D loss: 0.202726, acc: 99.22%] [G loss: 5.806956]\n",
      "epoch:36 step:28247 [D loss: 0.611885, acc: 67.97%] [G loss: 4.427632]\n",
      "epoch:36 step:28248 [D loss: 0.078076, acc: 100.00%] [G loss: 5.376812]\n",
      "epoch:36 step:28249 [D loss: 0.055197, acc: 100.00%] [G loss: 5.335697]\n",
      "epoch:36 step:28250 [D loss: 0.382976, acc: 81.25%] [G loss: 3.754363]\n",
      "epoch:36 step:28251 [D loss: 0.334566, acc: 80.47%] [G loss: 9.171866]\n",
      "epoch:36 step:28252 [D loss: 0.715001, acc: 57.03%] [G loss: 7.460483]\n",
      "epoch:36 step:28253 [D loss: 0.429872, acc: 71.09%] [G loss: 5.719729]\n",
      "epoch:36 step:28254 [D loss: 0.480838, acc: 66.41%] [G loss: 6.472315]\n",
      "epoch:36 step:28255 [D loss: 0.357502, acc: 82.81%] [G loss: 4.032738]\n",
      "epoch:36 step:28256 [D loss: 0.112479, acc: 100.00%] [G loss: 7.735621]\n",
      "epoch:36 step:28257 [D loss: 0.754577, acc: 55.47%] [G loss: 8.204375]\n",
      "epoch:36 step:28258 [D loss: 0.549068, acc: 72.66%] [G loss: 3.960837]\n",
      "epoch:36 step:28259 [D loss: 0.324592, acc: 83.59%] [G loss: 4.849744]\n",
      "epoch:36 step:28260 [D loss: 0.037393, acc: 100.00%] [G loss: 4.963814]\n",
      "epoch:36 step:28261 [D loss: 0.835678, acc: 52.34%] [G loss: 4.751502]\n",
      "epoch:36 step:28262 [D loss: 0.082519, acc: 100.00%] [G loss: 5.787434]\n",
      "epoch:36 step:28263 [D loss: 0.336229, acc: 84.38%] [G loss: 7.826147]\n",
      "epoch:36 step:28264 [D loss: 0.107515, acc: 100.00%] [G loss: 6.335987]\n",
      "epoch:36 step:28265 [D loss: 0.128220, acc: 99.22%] [G loss: 4.263330]\n",
      "epoch:36 step:28266 [D loss: 0.061903, acc: 100.00%] [G loss: 4.714941]\n",
      "epoch:36 step:28267 [D loss: 0.054053, acc: 100.00%] [G loss: 3.458920]\n",
      "epoch:36 step:28268 [D loss: 0.593597, acc: 70.31%] [G loss: 4.582150]\n",
      "epoch:36 step:28269 [D loss: 0.311019, acc: 93.75%] [G loss: 3.315465]\n",
      "epoch:36 step:28270 [D loss: 0.322122, acc: 93.75%] [G loss: 4.674589]\n",
      "epoch:36 step:28271 [D loss: 0.482214, acc: 75.78%] [G loss: 5.021502]\n",
      "epoch:36 step:28272 [D loss: 0.582134, acc: 60.16%] [G loss: 8.222793]\n",
      "epoch:36 step:28273 [D loss: 0.301107, acc: 86.72%] [G loss: 7.499394]\n",
      "epoch:36 step:28274 [D loss: 0.563786, acc: 73.44%] [G loss: 8.001699]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:36 step:28275 [D loss: 0.717743, acc: 53.12%] [G loss: 5.117201]\n",
      "epoch:36 step:28276 [D loss: 0.394176, acc: 86.72%] [G loss: 7.181219]\n",
      "epoch:36 step:28277 [D loss: 0.037697, acc: 100.00%] [G loss: 5.810010]\n",
      "epoch:36 step:28278 [D loss: 0.141908, acc: 100.00%] [G loss: 4.741288]\n",
      "epoch:36 step:28279 [D loss: 0.166791, acc: 97.66%] [G loss: 4.679634]\n",
      "epoch:36 step:28280 [D loss: 0.614677, acc: 60.16%] [G loss: 5.348476]\n",
      "epoch:36 step:28281 [D loss: 0.303183, acc: 89.06%] [G loss: 3.418898]\n",
      "epoch:36 step:28282 [D loss: 0.615820, acc: 60.94%] [G loss: 6.311947]\n",
      "epoch:36 step:28283 [D loss: 0.524477, acc: 69.53%] [G loss: 4.894303]\n",
      "epoch:36 step:28284 [D loss: 0.426104, acc: 77.34%] [G loss: 4.677143]\n",
      "epoch:36 step:28285 [D loss: 0.104348, acc: 98.44%] [G loss: 2.864159]\n",
      "epoch:36 step:28286 [D loss: 0.210638, acc: 94.53%] [G loss: 6.314953]\n",
      "epoch:36 step:28287 [D loss: 0.122368, acc: 99.22%] [G loss: 4.688208]\n",
      "epoch:36 step:28288 [D loss: 0.528363, acc: 79.69%] [G loss: 4.738136]\n",
      "epoch:36 step:28289 [D loss: 0.210739, acc: 96.88%] [G loss: 3.910472]\n",
      "epoch:36 step:28290 [D loss: 0.061342, acc: 100.00%] [G loss: 7.171607]\n",
      "epoch:36 step:28291 [D loss: 0.284147, acc: 95.31%] [G loss: 7.271833]\n",
      "epoch:36 step:28292 [D loss: 0.110619, acc: 100.00%] [G loss: 5.478461]\n",
      "epoch:36 step:28293 [D loss: 0.155620, acc: 98.44%] [G loss: 2.626579]\n",
      "epoch:36 step:28294 [D loss: 0.650669, acc: 60.16%] [G loss: 5.036931]\n",
      "epoch:36 step:28295 [D loss: 0.563536, acc: 62.50%] [G loss: 5.507908]\n",
      "epoch:36 step:28296 [D loss: 0.132204, acc: 100.00%] [G loss: 6.437730]\n",
      "epoch:36 step:28297 [D loss: 0.117985, acc: 99.22%] [G loss: 7.196753]\n",
      "epoch:36 step:28298 [D loss: 0.374613, acc: 89.06%] [G loss: 2.254072]\n",
      "epoch:36 step:28299 [D loss: 0.411305, acc: 88.28%] [G loss: 5.506621]\n",
      "epoch:36 step:28300 [D loss: 0.442637, acc: 84.38%] [G loss: 5.594672]\n",
      "epoch:36 step:28301 [D loss: 0.270170, acc: 92.19%] [G loss: 6.212032]\n",
      "epoch:36 step:28302 [D loss: 1.091448, acc: 26.56%] [G loss: 5.047740]\n",
      "epoch:36 step:28303 [D loss: 0.131419, acc: 100.00%] [G loss: 3.117610]\n",
      "epoch:36 step:28304 [D loss: 0.021105, acc: 100.00%] [G loss: 4.694674]\n",
      "epoch:36 step:28305 [D loss: 0.139971, acc: 98.44%] [G loss: 8.210613]\n",
      "epoch:36 step:28306 [D loss: 0.266970, acc: 96.88%] [G loss: 4.882132]\n",
      "epoch:36 step:28307 [D loss: 0.142841, acc: 99.22%] [G loss: 2.968385]\n",
      "epoch:36 step:28308 [D loss: 0.176385, acc: 98.44%] [G loss: 3.461202]\n",
      "epoch:36 step:28309 [D loss: 0.166962, acc: 96.88%] [G loss: 9.177043]\n",
      "epoch:36 step:28310 [D loss: 0.425232, acc: 71.88%] [G loss: 7.417258]\n",
      "epoch:36 step:28311 [D loss: 0.530786, acc: 71.09%] [G loss: 5.088883]\n",
      "epoch:36 step:28312 [D loss: 0.250124, acc: 92.19%] [G loss: 8.888487]\n",
      "epoch:36 step:28313 [D loss: 0.703002, acc: 57.03%] [G loss: 7.147982]\n",
      "epoch:36 step:28314 [D loss: 0.030914, acc: 100.00%] [G loss: 7.900340]\n",
      "epoch:36 step:28315 [D loss: 0.067895, acc: 100.00%] [G loss: 3.762124]\n",
      "epoch:36 step:28316 [D loss: 1.074770, acc: 46.88%] [G loss: 6.397380]\n",
      "epoch:36 step:28317 [D loss: 0.373001, acc: 81.25%] [G loss: 7.062315]\n",
      "epoch:36 step:28318 [D loss: 1.062432, acc: 50.78%] [G loss: 5.173269]\n",
      "epoch:36 step:28319 [D loss: 0.798331, acc: 54.69%] [G loss: 3.492558]\n",
      "epoch:36 step:28320 [D loss: 0.521264, acc: 60.94%] [G loss: 5.099961]\n",
      "epoch:36 step:28321 [D loss: 0.863736, acc: 49.22%] [G loss: 5.621163]\n",
      "epoch:36 step:28322 [D loss: 0.214562, acc: 96.09%] [G loss: 4.465307]\n",
      "epoch:36 step:28323 [D loss: 0.491515, acc: 77.34%] [G loss: 4.148592]\n",
      "epoch:36 step:28324 [D loss: 0.289968, acc: 92.19%] [G loss: 4.546494]\n",
      "epoch:36 step:28325 [D loss: 0.183456, acc: 98.44%] [G loss: 3.305446]\n",
      "epoch:36 step:28326 [D loss: 0.454434, acc: 70.31%] [G loss: 5.347313]\n",
      "epoch:36 step:28327 [D loss: 0.081362, acc: 100.00%] [G loss: 6.339076]\n",
      "epoch:36 step:28328 [D loss: 0.024440, acc: 100.00%] [G loss: 6.567867]\n",
      "epoch:36 step:28329 [D loss: 1.337623, acc: 49.22%] [G loss: 6.110982]\n",
      "epoch:36 step:28330 [D loss: 0.856047, acc: 51.56%] [G loss: 5.139934]\n",
      "epoch:36 step:28331 [D loss: 0.048946, acc: 100.00%] [G loss: 7.721014]\n",
      "epoch:36 step:28332 [D loss: 0.176881, acc: 96.09%] [G loss: 3.382460]\n",
      "epoch:36 step:28333 [D loss: 0.739876, acc: 53.91%] [G loss: 5.913106]\n",
      "epoch:36 step:28334 [D loss: 0.057031, acc: 100.00%] [G loss: 5.719188]\n",
      "epoch:36 step:28335 [D loss: 1.180770, acc: 23.44%] [G loss: 5.313767]\n",
      "epoch:36 step:28336 [D loss: 0.784939, acc: 53.12%] [G loss: 3.858741]\n",
      "epoch:36 step:28337 [D loss: 0.791106, acc: 48.44%] [G loss: 3.830088]\n",
      "epoch:36 step:28338 [D loss: 0.914921, acc: 40.62%] [G loss: 7.014833]\n",
      "epoch:36 step:28339 [D loss: 0.564406, acc: 68.75%] [G loss: 3.829609]\n",
      "epoch:36 step:28340 [D loss: 0.078853, acc: 100.00%] [G loss: 6.093683]\n",
      "epoch:36 step:28341 [D loss: 0.213521, acc: 90.62%] [G loss: 6.669149]\n",
      "epoch:36 step:28342 [D loss: 0.358367, acc: 82.03%] [G loss: 5.060390]\n",
      "epoch:36 step:28343 [D loss: 0.049229, acc: 99.22%] [G loss: 5.822111]\n",
      "epoch:36 step:28344 [D loss: 0.527161, acc: 63.28%] [G loss: 3.631456]\n",
      "epoch:36 step:28345 [D loss: 0.174383, acc: 96.09%] [G loss: 5.197008]\n",
      "epoch:36 step:28346 [D loss: 0.286870, acc: 87.50%] [G loss: 5.956040]\n",
      "epoch:36 step:28347 [D loss: 0.143110, acc: 99.22%] [G loss: 3.140185]\n",
      "epoch:36 step:28348 [D loss: 0.274972, acc: 94.53%] [G loss: 6.123362]\n",
      "epoch:36 step:28349 [D loss: 0.354270, acc: 82.81%] [G loss: 4.566030]\n",
      "epoch:36 step:28350 [D loss: 0.138664, acc: 98.44%] [G loss: 3.175037]\n",
      "epoch:36 step:28351 [D loss: 1.351752, acc: 50.00%] [G loss: 7.838659]\n",
      "epoch:36 step:28352 [D loss: 0.048991, acc: 100.00%] [G loss: 4.617160]\n",
      "epoch:36 step:28353 [D loss: 0.724393, acc: 56.25%] [G loss: 7.925638]\n",
      "epoch:36 step:28354 [D loss: 0.421959, acc: 81.25%] [G loss: 3.800292]\n",
      "epoch:36 step:28355 [D loss: 0.152969, acc: 98.44%] [G loss: 4.688156]\n",
      "epoch:36 step:28356 [D loss: 0.509755, acc: 75.00%] [G loss: 3.993299]\n",
      "epoch:36 step:28357 [D loss: 0.319718, acc: 93.75%] [G loss: 4.802070]\n",
      "epoch:36 step:28358 [D loss: 0.192585, acc: 96.09%] [G loss: 5.007581]\n",
      "epoch:36 step:28359 [D loss: 0.302346, acc: 95.31%] [G loss: 5.622682]\n",
      "epoch:36 step:28360 [D loss: 0.379921, acc: 78.12%] [G loss: 6.133462]\n",
      "epoch:36 step:28361 [D loss: 0.344006, acc: 78.12%] [G loss: 7.664307]\n",
      "epoch:36 step:28362 [D loss: 0.038625, acc: 100.00%] [G loss: 6.444892]\n",
      "epoch:36 step:28363 [D loss: 0.291003, acc: 97.66%] [G loss: 5.038703]\n",
      "epoch:36 step:28364 [D loss: 0.560963, acc: 64.06%] [G loss: 6.566772]\n",
      "epoch:36 step:28365 [D loss: 0.247537, acc: 94.53%] [G loss: 5.819152]\n",
      "epoch:36 step:28366 [D loss: 0.046832, acc: 100.00%] [G loss: 6.233536]\n",
      "epoch:36 step:28367 [D loss: 0.050065, acc: 100.00%] [G loss: 6.797794]\n",
      "epoch:36 step:28368 [D loss: 0.169403, acc: 98.44%] [G loss: 4.254467]\n",
      "epoch:36 step:28369 [D loss: 0.201409, acc: 97.66%] [G loss: 3.665114]\n",
      "epoch:36 step:28370 [D loss: 0.756221, acc: 52.34%] [G loss: 6.363106]\n",
      "epoch:36 step:28371 [D loss: 0.042833, acc: 100.00%] [G loss: 4.902530]\n",
      "epoch:36 step:28372 [D loss: 0.489080, acc: 63.28%] [G loss: 4.411987]\n",
      "epoch:36 step:28373 [D loss: 0.210246, acc: 96.09%] [G loss: 4.412626]\n",
      "epoch:36 step:28374 [D loss: 0.070774, acc: 100.00%] [G loss: 6.480232]\n",
      "epoch:36 step:28375 [D loss: 0.523011, acc: 64.06%] [G loss: 4.508675]\n",
      "epoch:36 step:28376 [D loss: 0.990957, acc: 53.12%] [G loss: 4.181122]\n",
      "epoch:36 step:28377 [D loss: 0.160767, acc: 99.22%] [G loss: 1.736742]\n",
      "epoch:36 step:28378 [D loss: 0.090381, acc: 98.44%] [G loss: 5.231454]\n",
      "epoch:36 step:28379 [D loss: 0.471610, acc: 66.41%] [G loss: 5.941549]\n",
      "epoch:36 step:28380 [D loss: 0.105302, acc: 99.22%] [G loss: 5.104697]\n",
      "epoch:36 step:28381 [D loss: 0.732188, acc: 54.69%] [G loss: 3.402332]\n",
      "epoch:36 step:28382 [D loss: 0.164800, acc: 98.44%] [G loss: 5.988233]\n",
      "epoch:36 step:28383 [D loss: 0.201239, acc: 97.66%] [G loss: 4.173372]\n",
      "epoch:36 step:28384 [D loss: 0.197561, acc: 92.97%] [G loss: 3.385072]\n",
      "epoch:36 step:28385 [D loss: 0.174572, acc: 97.66%] [G loss: 3.944255]\n",
      "epoch:36 step:28386 [D loss: 0.348042, acc: 80.47%] [G loss: 6.510116]\n",
      "epoch:36 step:28387 [D loss: 0.154057, acc: 97.66%] [G loss: 5.866112]\n",
      "epoch:36 step:28388 [D loss: 0.136559, acc: 98.44%] [G loss: 4.972288]\n",
      "epoch:36 step:28389 [D loss: 0.074802, acc: 100.00%] [G loss: 4.068705]\n",
      "epoch:36 step:28390 [D loss: 0.180685, acc: 100.00%] [G loss: 3.157025]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:36 step:28391 [D loss: 0.708334, acc: 57.81%] [G loss: 3.991089]\n",
      "epoch:36 step:28392 [D loss: 0.487967, acc: 74.22%] [G loss: 3.224796]\n",
      "epoch:36 step:28393 [D loss: 0.052256, acc: 100.00%] [G loss: 5.161429]\n",
      "epoch:36 step:28394 [D loss: 0.326664, acc: 89.84%] [G loss: 6.232420]\n",
      "epoch:36 step:28395 [D loss: 0.340987, acc: 80.47%] [G loss: 6.728577]\n",
      "epoch:36 step:28396 [D loss: 0.076099, acc: 100.00%] [G loss: 3.511226]\n",
      "epoch:36 step:28397 [D loss: 0.120754, acc: 100.00%] [G loss: 6.637725]\n",
      "epoch:36 step:28398 [D loss: 0.284326, acc: 94.53%] [G loss: 6.650480]\n",
      "epoch:36 step:28399 [D loss: 0.158867, acc: 97.66%] [G loss: 3.851559]\n",
      "epoch:36 step:28400 [D loss: 0.214619, acc: 94.53%] [G loss: 4.149565]\n",
      "##############\n",
      "[0.8675545  0.88402951 0.81480957 0.83474908 0.77068201 0.83315835\n",
      " 0.87297817 0.80835376 0.82084573 0.83311631]\n",
      "##########\n",
      "epoch:36 step:28401 [D loss: 0.095820, acc: 99.22%] [G loss: 5.298763]\n",
      "epoch:36 step:28402 [D loss: 0.248030, acc: 94.53%] [G loss: 4.668793]\n",
      "epoch:36 step:28403 [D loss: 0.373193, acc: 92.19%] [G loss: 6.398298]\n",
      "epoch:36 step:28404 [D loss: 0.169475, acc: 99.22%] [G loss: 5.667261]\n",
      "epoch:36 step:28405 [D loss: 0.225566, acc: 94.53%] [G loss: 5.434819]\n",
      "epoch:36 step:28406 [D loss: 0.636901, acc: 57.03%] [G loss: 7.357156]\n",
      "epoch:36 step:28407 [D loss: 0.450409, acc: 68.75%] [G loss: 3.209218]\n",
      "epoch:36 step:28408 [D loss: 0.158856, acc: 97.66%] [G loss: 4.734025]\n",
      "epoch:36 step:28409 [D loss: 0.216478, acc: 93.75%] [G loss: 5.744412]\n",
      "epoch:36 step:28410 [D loss: 0.167090, acc: 99.22%] [G loss: 3.396257]\n",
      "epoch:36 step:28411 [D loss: 1.929595, acc: 4.69%] [G loss: 4.615152]\n",
      "epoch:36 step:28412 [D loss: 0.277424, acc: 89.06%] [G loss: 4.792448]\n",
      "epoch:36 step:28413 [D loss: 0.289592, acc: 96.09%] [G loss: 3.455185]\n",
      "epoch:36 step:28414 [D loss: 0.433250, acc: 83.59%] [G loss: 6.684965]\n",
      "epoch:36 step:28415 [D loss: 0.318317, acc: 82.81%] [G loss: 4.545753]\n",
      "epoch:36 step:28416 [D loss: 1.055417, acc: 39.84%] [G loss: 8.387823]\n",
      "epoch:36 step:28417 [D loss: 0.135008, acc: 99.22%] [G loss: 3.551037]\n",
      "epoch:36 step:28418 [D loss: 0.056576, acc: 100.00%] [G loss: 4.697309]\n",
      "epoch:36 step:28419 [D loss: 0.151601, acc: 99.22%] [G loss: 5.555576]\n",
      "epoch:36 step:28420 [D loss: 0.048162, acc: 100.00%] [G loss: 3.432370]\n",
      "epoch:36 step:28421 [D loss: 0.120103, acc: 99.22%] [G loss: 4.364717]\n",
      "epoch:36 step:28422 [D loss: 0.303590, acc: 84.38%] [G loss: 5.503470]\n",
      "epoch:36 step:28423 [D loss: 0.633965, acc: 57.03%] [G loss: 7.811505]\n",
      "epoch:36 step:28424 [D loss: 0.292922, acc: 91.41%] [G loss: 6.201827]\n",
      "epoch:36 step:28425 [D loss: 0.540288, acc: 75.78%] [G loss: 6.235785]\n",
      "epoch:36 step:28426 [D loss: 0.518610, acc: 66.41%] [G loss: 5.230485]\n",
      "epoch:36 step:28427 [D loss: 0.065291, acc: 100.00%] [G loss: 6.985955]\n",
      "epoch:36 step:28428 [D loss: 0.365026, acc: 82.03%] [G loss: 2.661596]\n",
      "epoch:36 step:28429 [D loss: 1.959776, acc: 0.78%] [G loss: 10.291359]\n",
      "epoch:36 step:28430 [D loss: 1.250242, acc: 50.00%] [G loss: 5.591324]\n",
      "epoch:36 step:28431 [D loss: 0.184880, acc: 92.19%] [G loss: 7.257688]\n",
      "epoch:36 step:28432 [D loss: 0.268569, acc: 85.16%] [G loss: 7.477880]\n",
      "epoch:36 step:28433 [D loss: 0.639811, acc: 57.03%] [G loss: 4.957346]\n",
      "epoch:36 step:28434 [D loss: 0.445146, acc: 71.88%] [G loss: 5.990078]\n",
      "epoch:36 step:28435 [D loss: 0.462581, acc: 69.53%] [G loss: 3.584544]\n",
      "epoch:36 step:28436 [D loss: 0.166265, acc: 98.44%] [G loss: 6.285981]\n",
      "epoch:36 step:28437 [D loss: 0.783078, acc: 54.69%] [G loss: 4.509012]\n",
      "epoch:36 step:28438 [D loss: 0.288542, acc: 85.16%] [G loss: 6.415555]\n",
      "epoch:36 step:28439 [D loss: 0.294780, acc: 85.94%] [G loss: 5.911160]\n",
      "epoch:36 step:28440 [D loss: 0.179195, acc: 97.66%] [G loss: 2.472147]\n",
      "epoch:36 step:28441 [D loss: 0.216235, acc: 96.09%] [G loss: 3.353650]\n",
      "epoch:36 step:28442 [D loss: 0.279606, acc: 88.28%] [G loss: 4.432300]\n",
      "epoch:36 step:28443 [D loss: 0.072430, acc: 100.00%] [G loss: 5.994065]\n",
      "epoch:36 step:28444 [D loss: 0.367380, acc: 80.47%] [G loss: 3.532015]\n",
      "epoch:36 step:28445 [D loss: 0.677872, acc: 61.72%] [G loss: 5.625349]\n",
      "epoch:36 step:28446 [D loss: 0.622683, acc: 57.81%] [G loss: 6.211863]\n",
      "epoch:36 step:28447 [D loss: 0.029779, acc: 100.00%] [G loss: 6.969532]\n",
      "epoch:36 step:28448 [D loss: 0.474865, acc: 71.09%] [G loss: 3.899138]\n",
      "epoch:36 step:28449 [D loss: 0.120314, acc: 100.00%] [G loss: 6.876717]\n",
      "epoch:36 step:28450 [D loss: 0.209526, acc: 99.22%] [G loss: 4.134930]\n",
      "epoch:36 step:28451 [D loss: 0.044019, acc: 100.00%] [G loss: 6.625977]\n",
      "epoch:36 step:28452 [D loss: 0.314083, acc: 92.19%] [G loss: 4.001720]\n",
      "epoch:36 step:28453 [D loss: 0.376935, acc: 78.12%] [G loss: 4.617547]\n",
      "epoch:36 step:28454 [D loss: 0.240803, acc: 94.53%] [G loss: 6.674383]\n",
      "epoch:36 step:28455 [D loss: 0.049043, acc: 100.00%] [G loss: 6.290724]\n",
      "epoch:36 step:28456 [D loss: 0.104751, acc: 100.00%] [G loss: 4.068792]\n",
      "epoch:36 step:28457 [D loss: 0.072400, acc: 100.00%] [G loss: 5.411528]\n",
      "epoch:36 step:28458 [D loss: 0.241819, acc: 96.88%] [G loss: 3.969859]\n",
      "epoch:36 step:28459 [D loss: 0.297805, acc: 92.19%] [G loss: 4.836138]\n",
      "epoch:36 step:28460 [D loss: 0.087910, acc: 100.00%] [G loss: 6.549896]\n",
      "epoch:36 step:28461 [D loss: 0.240490, acc: 94.53%] [G loss: 3.622357]\n",
      "epoch:36 step:28462 [D loss: 0.200096, acc: 96.09%] [G loss: 5.546332]\n",
      "epoch:36 step:28463 [D loss: 0.474549, acc: 82.81%] [G loss: 6.785970]\n",
      "epoch:36 step:28464 [D loss: 0.025544, acc: 100.00%] [G loss: 8.125841]\n",
      "epoch:36 step:28465 [D loss: 0.204441, acc: 96.88%] [G loss: 4.421674]\n",
      "epoch:36 step:28466 [D loss: 0.186963, acc: 96.88%] [G loss: 6.083742]\n",
      "epoch:36 step:28467 [D loss: 1.271519, acc: 50.00%] [G loss: 3.227411]\n",
      "epoch:36 step:28468 [D loss: 0.038367, acc: 100.00%] [G loss: 6.235674]\n",
      "epoch:36 step:28469 [D loss: 1.301687, acc: 50.00%] [G loss: 8.561033]\n",
      "epoch:36 step:28470 [D loss: 0.503195, acc: 74.22%] [G loss: 6.027854]\n",
      "epoch:36 step:28471 [D loss: 1.285185, acc: 49.22%] [G loss: 5.848038]\n",
      "epoch:36 step:28472 [D loss: 0.385712, acc: 72.66%] [G loss: 4.919752]\n",
      "epoch:36 step:28473 [D loss: 0.935296, acc: 36.72%] [G loss: 5.150263]\n",
      "epoch:36 step:28474 [D loss: 0.201772, acc: 97.66%] [G loss: 3.336367]\n",
      "epoch:36 step:28475 [D loss: 0.195434, acc: 98.44%] [G loss: 7.618119]\n",
      "epoch:36 step:28476 [D loss: 0.524265, acc: 65.62%] [G loss: 7.133108]\n",
      "epoch:36 step:28477 [D loss: 0.093577, acc: 100.00%] [G loss: 3.867618]\n",
      "epoch:36 step:28478 [D loss: 0.081154, acc: 100.00%] [G loss: 3.796778]\n",
      "epoch:36 step:28479 [D loss: 0.642573, acc: 62.50%] [G loss: 4.798744]\n",
      "epoch:36 step:28480 [D loss: 0.178716, acc: 97.66%] [G loss: 6.367343]\n",
      "epoch:36 step:28481 [D loss: 0.565799, acc: 71.09%] [G loss: 4.876621]\n",
      "epoch:36 step:28482 [D loss: 0.196394, acc: 92.19%] [G loss: 7.163176]\n",
      "epoch:36 step:28483 [D loss: 0.535887, acc: 65.62%] [G loss: 4.259162]\n",
      "epoch:36 step:28484 [D loss: 0.166386, acc: 98.44%] [G loss: 5.810598]\n",
      "epoch:36 step:28485 [D loss: 1.571666, acc: 42.19%] [G loss: 5.723419]\n",
      "epoch:36 step:28486 [D loss: 0.361072, acc: 85.94%] [G loss: 4.877361]\n",
      "epoch:36 step:28487 [D loss: 0.670792, acc: 57.81%] [G loss: 5.208976]\n",
      "epoch:36 step:28488 [D loss: 0.140702, acc: 99.22%] [G loss: 3.624032]\n",
      "epoch:36 step:28489 [D loss: 0.699952, acc: 55.47%] [G loss: 6.669997]\n",
      "epoch:36 step:28490 [D loss: 0.126719, acc: 98.44%] [G loss: 4.326072]\n",
      "epoch:36 step:28491 [D loss: 0.738785, acc: 56.25%] [G loss: 5.205337]\n",
      "epoch:36 step:28492 [D loss: 0.063736, acc: 100.00%] [G loss: 3.312212]\n",
      "epoch:36 step:28493 [D loss: 0.719481, acc: 55.47%] [G loss: 5.915325]\n",
      "epoch:36 step:28494 [D loss: 0.811327, acc: 55.47%] [G loss: 4.281275]\n",
      "epoch:36 step:28495 [D loss: 0.089448, acc: 100.00%] [G loss: 4.057323]\n",
      "epoch:36 step:28496 [D loss: 0.091293, acc: 100.00%] [G loss: 5.053057]\n",
      "epoch:36 step:28497 [D loss: 0.224824, acc: 92.19%] [G loss: 8.670462]\n",
      "epoch:36 step:28498 [D loss: 0.547614, acc: 64.06%] [G loss: 4.524047]\n",
      "epoch:36 step:28499 [D loss: 1.065670, acc: 28.91%] [G loss: 6.642418]\n",
      "epoch:36 step:28500 [D loss: 0.156307, acc: 97.66%] [G loss: 3.845447]\n",
      "epoch:36 step:28501 [D loss: 0.585450, acc: 63.28%] [G loss: 4.211254]\n",
      "epoch:36 step:28502 [D loss: 0.048188, acc: 100.00%] [G loss: 5.767187]\n",
      "epoch:36 step:28503 [D loss: 0.044617, acc: 100.00%] [G loss: 5.111345]\n",
      "epoch:36 step:28504 [D loss: 0.373803, acc: 80.47%] [G loss: 3.893090]\n",
      "epoch:36 step:28505 [D loss: 0.264323, acc: 93.75%] [G loss: 1.824820]\n",
      "epoch:36 step:28506 [D loss: 1.015159, acc: 31.25%] [G loss: 5.504953]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:36 step:28507 [D loss: 0.047774, acc: 100.00%] [G loss: 4.313472]\n",
      "epoch:36 step:28508 [D loss: 0.537933, acc: 67.19%] [G loss: 5.245340]\n",
      "epoch:36 step:28509 [D loss: 0.171372, acc: 96.88%] [G loss: 4.827067]\n",
      "epoch:36 step:28510 [D loss: 0.069398, acc: 99.22%] [G loss: 6.637645]\n",
      "epoch:36 step:28511 [D loss: 0.325928, acc: 93.75%] [G loss: 3.535239]\n",
      "epoch:36 step:28512 [D loss: 0.203569, acc: 96.09%] [G loss: 2.548671]\n",
      "epoch:36 step:28513 [D loss: 0.311671, acc: 95.31%] [G loss: 7.058182]\n",
      "epoch:36 step:28514 [D loss: 0.188216, acc: 98.44%] [G loss: 6.115317]\n",
      "epoch:36 step:28515 [D loss: 0.047316, acc: 100.00%] [G loss: 4.535623]\n",
      "epoch:36 step:28516 [D loss: 0.125462, acc: 97.66%] [G loss: 4.812505]\n",
      "epoch:36 step:28517 [D loss: 0.219896, acc: 92.19%] [G loss: 10.044735]\n",
      "epoch:36 step:28518 [D loss: 0.587259, acc: 70.31%] [G loss: 5.257068]\n",
      "epoch:36 step:28519 [D loss: 1.100495, acc: 29.69%] [G loss: 4.691322]\n",
      "epoch:36 step:28520 [D loss: 1.135073, acc: 22.66%] [G loss: 5.517024]\n",
      "epoch:36 step:28521 [D loss: 0.092113, acc: 97.66%] [G loss: 4.894548]\n",
      "epoch:36 step:28522 [D loss: 0.912612, acc: 51.56%] [G loss: 5.441341]\n",
      "epoch:36 step:28523 [D loss: 0.179017, acc: 97.66%] [G loss: 6.455165]\n",
      "epoch:36 step:28524 [D loss: 0.034532, acc: 100.00%] [G loss: 3.175282]\n",
      "epoch:36 step:28525 [D loss: 0.881650, acc: 51.56%] [G loss: 5.941464]\n",
      "epoch:36 step:28526 [D loss: 0.587774, acc: 71.88%] [G loss: 5.977939]\n",
      "epoch:36 step:28527 [D loss: 0.265881, acc: 88.28%] [G loss: 5.389932]\n",
      "epoch:36 step:28528 [D loss: 0.032645, acc: 100.00%] [G loss: 8.841118]\n",
      "epoch:36 step:28529 [D loss: 0.106414, acc: 98.44%] [G loss: 5.387636]\n",
      "epoch:36 step:28530 [D loss: 0.033421, acc: 100.00%] [G loss: 5.229151]\n",
      "epoch:36 step:28531 [D loss: 0.160601, acc: 97.66%] [G loss: 4.478812]\n",
      "epoch:36 step:28532 [D loss: 0.124483, acc: 100.00%] [G loss: 7.241291]\n",
      "epoch:36 step:28533 [D loss: 0.280525, acc: 92.19%] [G loss: 4.012770]\n",
      "epoch:36 step:28534 [D loss: 0.146146, acc: 99.22%] [G loss: 6.563070]\n",
      "epoch:36 step:28535 [D loss: 0.230523, acc: 96.09%] [G loss: 4.873548]\n",
      "epoch:36 step:28536 [D loss: 0.239385, acc: 96.09%] [G loss: 3.187010]\n",
      "epoch:36 step:28537 [D loss: 0.321312, acc: 84.38%] [G loss: 6.271192]\n",
      "epoch:36 step:28538 [D loss: 0.071548, acc: 100.00%] [G loss: 6.529345]\n",
      "epoch:36 step:28539 [D loss: 0.663492, acc: 57.81%] [G loss: 5.888240]\n",
      "epoch:36 step:28540 [D loss: 0.288401, acc: 91.41%] [G loss: 5.443619]\n",
      "epoch:36 step:28541 [D loss: 0.298914, acc: 89.84%] [G loss: 5.054801]\n",
      "epoch:36 step:28542 [D loss: 0.406168, acc: 87.50%] [G loss: 5.491082]\n",
      "epoch:36 step:28543 [D loss: 0.192585, acc: 97.66%] [G loss: 5.375797]\n",
      "epoch:36 step:28544 [D loss: 0.054166, acc: 100.00%] [G loss: 4.235803]\n",
      "epoch:36 step:28545 [D loss: 0.160201, acc: 96.88%] [G loss: 6.550074]\n",
      "epoch:36 step:28546 [D loss: 0.882815, acc: 53.12%] [G loss: 6.441153]\n",
      "epoch:36 step:28547 [D loss: 0.858195, acc: 35.94%] [G loss: 3.275920]\n",
      "epoch:36 step:28548 [D loss: 0.710767, acc: 52.34%] [G loss: 4.990846]\n",
      "epoch:36 step:28549 [D loss: 0.200874, acc: 93.75%] [G loss: 4.777777]\n",
      "epoch:36 step:28550 [D loss: 0.162866, acc: 97.66%] [G loss: 7.428944]\n",
      "epoch:36 step:28551 [D loss: 0.213782, acc: 96.88%] [G loss: 6.487468]\n",
      "epoch:36 step:28552 [D loss: 0.241303, acc: 90.62%] [G loss: 5.010564]\n",
      "epoch:36 step:28553 [D loss: 0.490032, acc: 77.34%] [G loss: 5.640654]\n",
      "epoch:36 step:28554 [D loss: 0.159521, acc: 98.44%] [G loss: 4.953544]\n",
      "epoch:36 step:28555 [D loss: 0.101340, acc: 99.22%] [G loss: 5.360645]\n",
      "epoch:36 step:28556 [D loss: 0.591231, acc: 74.22%] [G loss: 7.275782]\n",
      "epoch:36 step:28557 [D loss: 0.096853, acc: 99.22%] [G loss: 7.754479]\n",
      "epoch:36 step:28558 [D loss: 0.191051, acc: 96.88%] [G loss: 5.884225]\n",
      "epoch:36 step:28559 [D loss: 0.695135, acc: 60.94%] [G loss: 4.664733]\n",
      "epoch:36 step:28560 [D loss: 0.175837, acc: 94.53%] [G loss: 6.790725]\n",
      "epoch:36 step:28561 [D loss: 0.297831, acc: 89.84%] [G loss: 4.162641]\n",
      "epoch:36 step:28562 [D loss: 0.376567, acc: 86.72%] [G loss: 5.695616]\n",
      "epoch:36 step:28563 [D loss: 1.299197, acc: 47.66%] [G loss: 5.849977]\n",
      "epoch:36 step:28564 [D loss: 0.211911, acc: 99.22%] [G loss: 4.984806]\n",
      "epoch:36 step:28565 [D loss: 0.342461, acc: 82.03%] [G loss: 7.488019]\n",
      "epoch:36 step:28566 [D loss: 0.242039, acc: 88.28%] [G loss: 3.376547]\n",
      "epoch:36 step:28567 [D loss: 0.196164, acc: 93.75%] [G loss: 6.443902]\n",
      "epoch:36 step:28568 [D loss: 0.065544, acc: 100.00%] [G loss: 4.950063]\n",
      "epoch:36 step:28569 [D loss: 0.329944, acc: 91.41%] [G loss: 4.755801]\n",
      "epoch:36 step:28570 [D loss: 0.130886, acc: 100.00%] [G loss: 4.359854]\n",
      "epoch:36 step:28571 [D loss: 0.335148, acc: 85.94%] [G loss: 5.696795]\n",
      "epoch:36 step:28572 [D loss: 0.411698, acc: 79.69%] [G loss: 8.179036]\n",
      "epoch:36 step:28573 [D loss: 0.297278, acc: 85.16%] [G loss: 9.630116]\n",
      "epoch:36 step:28574 [D loss: 0.894257, acc: 53.12%] [G loss: 6.770107]\n",
      "epoch:36 step:28575 [D loss: 0.156628, acc: 96.88%] [G loss: 4.726107]\n",
      "epoch:36 step:28576 [D loss: 0.220640, acc: 91.41%] [G loss: 4.880099]\n",
      "epoch:36 step:28577 [D loss: 0.196190, acc: 95.31%] [G loss: 5.162871]\n",
      "epoch:36 step:28578 [D loss: 0.021840, acc: 100.00%] [G loss: 6.781047]\n",
      "epoch:36 step:28579 [D loss: 1.053126, acc: 46.88%] [G loss: 7.072055]\n",
      "epoch:36 step:28580 [D loss: 0.479384, acc: 72.66%] [G loss: 4.402758]\n",
      "epoch:36 step:28581 [D loss: 0.395705, acc: 85.94%] [G loss: 3.136543]\n",
      "epoch:36 step:28582 [D loss: 0.048381, acc: 100.00%] [G loss: 9.598717]\n",
      "epoch:36 step:28583 [D loss: 0.566314, acc: 60.16%] [G loss: 4.639073]\n",
      "epoch:36 step:28584 [D loss: 0.370501, acc: 86.72%] [G loss: 5.601271]\n",
      "epoch:36 step:28585 [D loss: 0.099943, acc: 100.00%] [G loss: 6.520012]\n",
      "epoch:36 step:28586 [D loss: 0.054079, acc: 100.00%] [G loss: 8.123018]\n",
      "epoch:36 step:28587 [D loss: 0.239422, acc: 96.88%] [G loss: 2.502786]\n",
      "epoch:36 step:28588 [D loss: 0.279929, acc: 89.06%] [G loss: 6.023168]\n",
      "epoch:36 step:28589 [D loss: 0.352938, acc: 79.69%] [G loss: 5.629571]\n",
      "epoch:36 step:28590 [D loss: 0.226767, acc: 93.75%] [G loss: 4.721436]\n",
      "epoch:36 step:28591 [D loss: 0.090408, acc: 98.44%] [G loss: 5.216424]\n",
      "epoch:36 step:28592 [D loss: 0.118742, acc: 99.22%] [G loss: 5.989329]\n",
      "epoch:36 step:28593 [D loss: 0.069502, acc: 100.00%] [G loss: 5.823229]\n",
      "epoch:36 step:28594 [D loss: 0.145483, acc: 98.44%] [G loss: 5.999497]\n",
      "epoch:36 step:28595 [D loss: 1.019024, acc: 51.56%] [G loss: 5.225745]\n",
      "epoch:36 step:28596 [D loss: 0.592725, acc: 58.59%] [G loss: 7.834743]\n",
      "epoch:36 step:28597 [D loss: 0.187250, acc: 96.88%] [G loss: 3.739421]\n",
      "epoch:36 step:28598 [D loss: 0.167009, acc: 98.44%] [G loss: 5.863640]\n",
      "epoch:36 step:28599 [D loss: 0.153229, acc: 96.09%] [G loss: 7.124489]\n",
      "epoch:36 step:28600 [D loss: 0.381484, acc: 89.84%] [G loss: 3.504876]\n",
      "##############\n",
      "[0.85601436 0.87710392 0.81652908 0.81652313 0.79293817 0.82627982\n",
      " 0.87405584 0.8249381  0.83640768 0.81503271]\n",
      "##########\n",
      "epoch:36 step:28601 [D loss: 0.102938, acc: 100.00%] [G loss: 5.068405]\n",
      "epoch:36 step:28602 [D loss: 0.976074, acc: 27.34%] [G loss: 6.298995]\n",
      "epoch:36 step:28603 [D loss: 0.437068, acc: 68.75%] [G loss: 3.864338]\n",
      "epoch:36 step:28604 [D loss: 0.185149, acc: 97.66%] [G loss: 8.239220]\n",
      "epoch:36 step:28605 [D loss: 0.220726, acc: 96.09%] [G loss: 4.485085]\n",
      "epoch:36 step:28606 [D loss: 0.155749, acc: 96.88%] [G loss: 7.263434]\n",
      "epoch:36 step:28607 [D loss: 0.239060, acc: 92.97%] [G loss: 2.943794]\n",
      "epoch:36 step:28608 [D loss: 0.056021, acc: 100.00%] [G loss: 6.798905]\n",
      "epoch:36 step:28609 [D loss: 0.928662, acc: 53.91%] [G loss: 6.442472]\n",
      "epoch:36 step:28610 [D loss: 0.522422, acc: 64.06%] [G loss: 5.681192]\n",
      "epoch:36 step:28611 [D loss: 0.770430, acc: 50.78%] [G loss: 4.711272]\n",
      "epoch:36 step:28612 [D loss: 0.913446, acc: 52.34%] [G loss: 7.315306]\n",
      "epoch:36 step:28613 [D loss: 0.324511, acc: 86.72%] [G loss: 6.499596]\n",
      "epoch:36 step:28614 [D loss: 0.069426, acc: 100.00%] [G loss: 6.462564]\n",
      "epoch:36 step:28615 [D loss: 0.530995, acc: 71.88%] [G loss: 5.799653]\n",
      "epoch:36 step:28616 [D loss: 0.627302, acc: 67.19%] [G loss: 7.100895]\n",
      "epoch:36 step:28617 [D loss: 0.183046, acc: 96.88%] [G loss: 6.168414]\n",
      "epoch:36 step:28618 [D loss: 0.211698, acc: 97.66%] [G loss: 7.478995]\n",
      "epoch:36 step:28619 [D loss: 0.344540, acc: 92.97%] [G loss: 4.471739]\n",
      "epoch:36 step:28620 [D loss: 0.274600, acc: 89.06%] [G loss: 5.173402]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:36 step:28621 [D loss: 0.690380, acc: 64.06%] [G loss: 6.184161]\n",
      "epoch:36 step:28622 [D loss: 0.562270, acc: 69.53%] [G loss: 7.132620]\n",
      "epoch:36 step:28623 [D loss: 0.064619, acc: 100.00%] [G loss: 3.929808]\n",
      "epoch:36 step:28624 [D loss: 0.032818, acc: 100.00%] [G loss: 3.361554]\n",
      "epoch:36 step:28625 [D loss: 0.093037, acc: 100.00%] [G loss: 5.086513]\n",
      "epoch:36 step:28626 [D loss: 1.071098, acc: 50.78%] [G loss: 3.679983]\n",
      "epoch:36 step:28627 [D loss: 0.028208, acc: 100.00%] [G loss: 10.587424]\n",
      "epoch:36 step:28628 [D loss: 0.011288, acc: 100.00%] [G loss: 6.882087]\n",
      "epoch:36 step:28629 [D loss: 0.448763, acc: 82.81%] [G loss: 6.322508]\n",
      "epoch:36 step:28630 [D loss: 0.118055, acc: 98.44%] [G loss: 4.172563]\n",
      "epoch:36 step:28631 [D loss: 0.782699, acc: 56.25%] [G loss: 7.097001]\n",
      "epoch:36 step:28632 [D loss: 0.230660, acc: 91.41%] [G loss: 5.706184]\n",
      "epoch:36 step:28633 [D loss: 0.076370, acc: 100.00%] [G loss: 5.737303]\n",
      "epoch:36 step:28634 [D loss: 0.144907, acc: 96.88%] [G loss: 5.302529]\n",
      "epoch:36 step:28635 [D loss: 0.697314, acc: 57.03%] [G loss: 5.678094]\n",
      "epoch:36 step:28636 [D loss: 0.136471, acc: 99.22%] [G loss: 4.383337]\n",
      "epoch:36 step:28637 [D loss: 0.725213, acc: 57.03%] [G loss: 7.556811]\n",
      "epoch:36 step:28638 [D loss: 0.578147, acc: 66.41%] [G loss: 5.215245]\n",
      "epoch:36 step:28639 [D loss: 0.162553, acc: 98.44%] [G loss: 5.433137]\n",
      "epoch:36 step:28640 [D loss: 0.298290, acc: 89.84%] [G loss: 4.712163]\n",
      "epoch:36 step:28641 [D loss: 0.246592, acc: 96.09%] [G loss: 5.442941]\n",
      "epoch:36 step:28642 [D loss: 1.128889, acc: 51.56%] [G loss: 4.832122]\n",
      "epoch:36 step:28643 [D loss: 0.848884, acc: 55.47%] [G loss: 5.721264]\n",
      "epoch:36 step:28644 [D loss: 0.057725, acc: 100.00%] [G loss: 5.638800]\n",
      "epoch:36 step:28645 [D loss: 0.153163, acc: 97.66%] [G loss: 4.773337]\n",
      "epoch:36 step:28646 [D loss: 0.168202, acc: 98.44%] [G loss: 4.036520]\n",
      "epoch:36 step:28647 [D loss: 0.906651, acc: 49.22%] [G loss: 8.022286]\n",
      "epoch:36 step:28648 [D loss: 0.231161, acc: 96.88%] [G loss: 3.873926]\n",
      "epoch:36 step:28649 [D loss: 1.292940, acc: 50.78%] [G loss: 2.674284]\n",
      "epoch:36 step:28650 [D loss: 0.324397, acc: 90.62%] [G loss: 3.728242]\n",
      "epoch:36 step:28651 [D loss: 0.492940, acc: 69.53%] [G loss: 4.808111]\n",
      "epoch:36 step:28652 [D loss: 0.352373, acc: 89.84%] [G loss: 3.295589]\n",
      "epoch:36 step:28653 [D loss: 0.056241, acc: 100.00%] [G loss: 4.759008]\n",
      "epoch:36 step:28654 [D loss: 0.030928, acc: 100.00%] [G loss: 8.308907]\n",
      "epoch:36 step:28655 [D loss: 0.302477, acc: 95.31%] [G loss: 5.731076]\n",
      "epoch:36 step:28656 [D loss: 0.379764, acc: 82.81%] [G loss: 6.596919]\n",
      "epoch:36 step:28657 [D loss: 0.367440, acc: 75.78%] [G loss: 4.627993]\n",
      "epoch:36 step:28658 [D loss: 0.024722, acc: 100.00%] [G loss: 7.321695]\n",
      "epoch:36 step:28659 [D loss: 0.182991, acc: 98.44%] [G loss: 4.131958]\n",
      "epoch:36 step:28660 [D loss: 0.471073, acc: 82.03%] [G loss: 2.868680]\n",
      "epoch:36 step:28661 [D loss: 0.354760, acc: 83.59%] [G loss: 2.779567]\n",
      "epoch:36 step:28662 [D loss: 0.292623, acc: 82.81%] [G loss: 3.654748]\n",
      "epoch:36 step:28663 [D loss: 0.217621, acc: 98.44%] [G loss: 6.686187]\n",
      "epoch:36 step:28664 [D loss: 0.201146, acc: 96.09%] [G loss: 5.337376]\n",
      "epoch:36 step:28665 [D loss: 0.246660, acc: 95.31%] [G loss: 4.680332]\n",
      "epoch:36 step:28666 [D loss: 0.506578, acc: 67.19%] [G loss: 7.109232]\n",
      "epoch:36 step:28667 [D loss: 0.052216, acc: 100.00%] [G loss: 2.913969]\n",
      "epoch:36 step:28668 [D loss: 0.464381, acc: 70.31%] [G loss: 5.650136]\n",
      "epoch:36 step:28669 [D loss: 0.147831, acc: 100.00%] [G loss: 5.256338]\n",
      "epoch:36 step:28670 [D loss: 0.670338, acc: 62.50%] [G loss: 3.743340]\n",
      "epoch:36 step:28671 [D loss: 0.059890, acc: 100.00%] [G loss: 7.875706]\n",
      "epoch:36 step:28672 [D loss: 0.672830, acc: 60.16%] [G loss: 5.612007]\n",
      "epoch:36 step:28673 [D loss: 0.319772, acc: 92.19%] [G loss: 4.317004]\n",
      "epoch:36 step:28674 [D loss: 0.522796, acc: 74.22%] [G loss: 5.260669]\n",
      "epoch:36 step:28675 [D loss: 0.075145, acc: 100.00%] [G loss: 4.466251]\n",
      "epoch:36 step:28676 [D loss: 0.029497, acc: 100.00%] [G loss: 4.154228]\n",
      "epoch:36 step:28677 [D loss: 0.436559, acc: 75.00%] [G loss: 5.155161]\n",
      "epoch:36 step:28678 [D loss: 0.099372, acc: 99.22%] [G loss: 4.099030]\n",
      "epoch:36 step:28679 [D loss: 0.244863, acc: 93.75%] [G loss: 5.982724]\n",
      "epoch:36 step:28680 [D loss: 0.670175, acc: 60.94%] [G loss: 4.933789]\n",
      "epoch:36 step:28681 [D loss: 0.152654, acc: 97.66%] [G loss: 2.705839]\n",
      "epoch:36 step:28682 [D loss: 0.411806, acc: 74.22%] [G loss: 7.417408]\n",
      "epoch:36 step:28683 [D loss: 0.053973, acc: 100.00%] [G loss: 5.170384]\n",
      "epoch:36 step:28684 [D loss: 0.281648, acc: 96.88%] [G loss: 3.164273]\n",
      "epoch:36 step:28685 [D loss: 0.129532, acc: 100.00%] [G loss: 6.167080]\n",
      "epoch:36 step:28686 [D loss: 1.098832, acc: 28.91%] [G loss: 4.545081]\n",
      "epoch:36 step:28687 [D loss: 0.391455, acc: 89.06%] [G loss: 4.305466]\n",
      "epoch:36 step:28688 [D loss: 0.083488, acc: 100.00%] [G loss: 8.163258]\n",
      "epoch:36 step:28689 [D loss: 0.225312, acc: 95.31%] [G loss: 3.183477]\n",
      "epoch:36 step:28690 [D loss: 0.105872, acc: 100.00%] [G loss: 3.339643]\n",
      "epoch:36 step:28691 [D loss: 0.634138, acc: 66.41%] [G loss: 4.250459]\n",
      "epoch:36 step:28692 [D loss: 0.121040, acc: 99.22%] [G loss: 4.968086]\n",
      "epoch:36 step:28693 [D loss: 0.836009, acc: 51.56%] [G loss: 5.744878]\n",
      "epoch:36 step:28694 [D loss: 0.791612, acc: 53.12%] [G loss: 6.194812]\n",
      "epoch:36 step:28695 [D loss: 0.067384, acc: 100.00%] [G loss: 5.674238]\n",
      "epoch:36 step:28696 [D loss: 0.482507, acc: 82.03%] [G loss: 5.210785]\n",
      "epoch:36 step:28697 [D loss: 0.149481, acc: 100.00%] [G loss: 7.009066]\n",
      "epoch:36 step:28698 [D loss: 0.242139, acc: 95.31%] [G loss: 5.165261]\n",
      "epoch:36 step:28699 [D loss: 0.330806, acc: 82.81%] [G loss: 4.786532]\n",
      "epoch:36 step:28700 [D loss: 0.200515, acc: 95.31%] [G loss: 4.467512]\n",
      "epoch:36 step:28701 [D loss: 1.017076, acc: 50.00%] [G loss: 8.866144]\n",
      "epoch:36 step:28702 [D loss: 0.063749, acc: 100.00%] [G loss: 6.401748]\n",
      "epoch:36 step:28703 [D loss: 0.592524, acc: 67.97%] [G loss: 3.667219]\n",
      "epoch:36 step:28704 [D loss: 0.405656, acc: 80.47%] [G loss: 4.810308]\n",
      "epoch:36 step:28705 [D loss: 0.032858, acc: 100.00%] [G loss: 7.392156]\n",
      "epoch:36 step:28706 [D loss: 0.200752, acc: 93.75%] [G loss: 4.645544]\n",
      "epoch:36 step:28707 [D loss: 0.444783, acc: 77.34%] [G loss: 5.417616]\n",
      "epoch:36 step:28708 [D loss: 1.100475, acc: 46.09%] [G loss: 5.195710]\n",
      "epoch:36 step:28709 [D loss: 0.450354, acc: 81.25%] [G loss: 3.729297]\n",
      "epoch:36 step:28710 [D loss: 0.427487, acc: 71.09%] [G loss: 6.312798]\n",
      "epoch:36 step:28711 [D loss: 0.364311, acc: 89.06%] [G loss: 5.083182]\n",
      "epoch:36 step:28712 [D loss: 0.108773, acc: 99.22%] [G loss: 6.100558]\n",
      "epoch:36 step:28713 [D loss: 0.265292, acc: 93.75%] [G loss: 6.221718]\n",
      "epoch:36 step:28714 [D loss: 0.132024, acc: 98.44%] [G loss: 7.232915]\n",
      "epoch:36 step:28715 [D loss: 0.290049, acc: 93.75%] [G loss: 3.470407]\n",
      "epoch:36 step:28716 [D loss: 0.485805, acc: 75.78%] [G loss: 6.873544]\n",
      "epoch:36 step:28717 [D loss: 0.164503, acc: 100.00%] [G loss: 5.334268]\n",
      "epoch:36 step:28718 [D loss: 0.232386, acc: 99.22%] [G loss: 4.907802]\n",
      "epoch:36 step:28719 [D loss: 0.171621, acc: 98.44%] [G loss: 3.955952]\n",
      "epoch:36 step:28720 [D loss: 0.557150, acc: 71.88%] [G loss: 4.412030]\n",
      "epoch:36 step:28721 [D loss: 0.535112, acc: 66.41%] [G loss: 4.737818]\n",
      "epoch:36 step:28722 [D loss: 0.374193, acc: 82.81%] [G loss: 6.034196]\n",
      "epoch:36 step:28723 [D loss: 0.406980, acc: 78.12%] [G loss: 6.139497]\n",
      "epoch:36 step:28724 [D loss: 0.254600, acc: 92.97%] [G loss: 1.938452]\n",
      "epoch:36 step:28725 [D loss: 0.122087, acc: 98.44%] [G loss: 2.691255]\n",
      "epoch:36 step:28726 [D loss: 1.180578, acc: 33.59%] [G loss: 7.012487]\n",
      "epoch:36 step:28727 [D loss: 0.348834, acc: 81.25%] [G loss: 5.705115]\n",
      "epoch:36 step:28728 [D loss: 0.242846, acc: 96.09%] [G loss: 3.723996]\n",
      "epoch:36 step:28729 [D loss: 0.201076, acc: 96.88%] [G loss: 6.800199]\n",
      "epoch:36 step:28730 [D loss: 0.047557, acc: 99.22%] [G loss: 8.520975]\n",
      "epoch:36 step:28731 [D loss: 0.103570, acc: 99.22%] [G loss: 4.665678]\n",
      "epoch:36 step:28732 [D loss: 0.267314, acc: 94.53%] [G loss: 5.926225]\n",
      "epoch:36 step:28733 [D loss: 0.098326, acc: 100.00%] [G loss: 6.343027]\n",
      "epoch:36 step:28734 [D loss: 0.260671, acc: 96.88%] [G loss: 6.213454]\n",
      "epoch:36 step:28735 [D loss: 0.140143, acc: 99.22%] [G loss: 3.117195]\n",
      "epoch:36 step:28736 [D loss: 0.521516, acc: 65.62%] [G loss: 2.922359]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:36 step:28737 [D loss: 0.255904, acc: 96.09%] [G loss: 3.831104]\n",
      "epoch:36 step:28738 [D loss: 0.971118, acc: 51.56%] [G loss: 4.839264]\n",
      "epoch:36 step:28739 [D loss: 0.683092, acc: 58.59%] [G loss: 5.565589]\n",
      "epoch:36 step:28740 [D loss: 0.072317, acc: 100.00%] [G loss: 4.281178]\n",
      "epoch:36 step:28741 [D loss: 0.078311, acc: 100.00%] [G loss: 5.464122]\n",
      "epoch:36 step:28742 [D loss: 0.601790, acc: 73.44%] [G loss: 4.670613]\n",
      "epoch:36 step:28743 [D loss: 0.749761, acc: 56.25%] [G loss: 5.890087]\n",
      "epoch:36 step:28744 [D loss: 0.610437, acc: 60.94%] [G loss: 4.827926]\n",
      "epoch:36 step:28745 [D loss: 0.036539, acc: 100.00%] [G loss: 5.015273]\n",
      "epoch:36 step:28746 [D loss: 0.040398, acc: 99.22%] [G loss: 6.949251]\n",
      "epoch:36 step:28747 [D loss: 0.472074, acc: 70.31%] [G loss: 4.762160]\n",
      "epoch:36 step:28748 [D loss: 0.436921, acc: 83.59%] [G loss: 6.400831]\n",
      "epoch:36 step:28749 [D loss: 0.787258, acc: 57.03%] [G loss: 6.584761]\n",
      "epoch:36 step:28750 [D loss: 1.830005, acc: 19.53%] [G loss: 4.858068]\n",
      "epoch:36 step:28751 [D loss: 0.261320, acc: 87.50%] [G loss: 5.521177]\n",
      "epoch:36 step:28752 [D loss: 0.584404, acc: 63.28%] [G loss: 6.692440]\n",
      "epoch:36 step:28753 [D loss: 0.038233, acc: 100.00%] [G loss: 5.286135]\n",
      "epoch:36 step:28754 [D loss: 0.800812, acc: 53.12%] [G loss: 3.052723]\n",
      "epoch:36 step:28755 [D loss: 0.139563, acc: 100.00%] [G loss: 3.985072]\n",
      "epoch:36 step:28756 [D loss: 0.487191, acc: 66.41%] [G loss: 5.596022]\n",
      "epoch:36 step:28757 [D loss: 0.361569, acc: 78.12%] [G loss: 7.107647]\n",
      "epoch:36 step:28758 [D loss: 0.146618, acc: 96.88%] [G loss: 5.036027]\n",
      "epoch:36 step:28759 [D loss: 0.134125, acc: 98.44%] [G loss: 7.039135]\n",
      "epoch:36 step:28760 [D loss: 0.128629, acc: 100.00%] [G loss: 5.244550]\n",
      "epoch:36 step:28761 [D loss: 0.268588, acc: 91.41%] [G loss: 6.442511]\n",
      "epoch:36 step:28762 [D loss: 0.768996, acc: 52.34%] [G loss: 2.036148]\n",
      "epoch:36 step:28763 [D loss: 0.124593, acc: 100.00%] [G loss: 6.338983]\n",
      "epoch:36 step:28764 [D loss: 0.118961, acc: 99.22%] [G loss: 2.020776]\n",
      "epoch:36 step:28765 [D loss: 0.054969, acc: 100.00%] [G loss: 4.326171]\n",
      "epoch:36 step:28766 [D loss: 0.921957, acc: 33.59%] [G loss: 7.480577]\n",
      "epoch:36 step:28767 [D loss: 1.498932, acc: 18.75%] [G loss: 6.069554]\n",
      "epoch:36 step:28768 [D loss: 0.189895, acc: 96.88%] [G loss: 7.419892]\n",
      "epoch:36 step:28769 [D loss: 0.128207, acc: 98.44%] [G loss: 2.829311]\n",
      "epoch:36 step:28770 [D loss: 0.327859, acc: 80.47%] [G loss: 6.984424]\n",
      "epoch:36 step:28771 [D loss: 0.098648, acc: 98.44%] [G loss: 6.856774]\n",
      "epoch:36 step:28772 [D loss: 0.254383, acc: 89.84%] [G loss: 5.588556]\n",
      "epoch:36 step:28773 [D loss: 0.481715, acc: 68.75%] [G loss: 6.048265]\n",
      "epoch:36 step:28774 [D loss: 1.685368, acc: 19.53%] [G loss: 5.466661]\n",
      "epoch:36 step:28775 [D loss: 0.195954, acc: 93.75%] [G loss: 4.093292]\n",
      "epoch:36 step:28776 [D loss: 0.417173, acc: 69.53%] [G loss: 6.186581]\n",
      "epoch:36 step:28777 [D loss: 0.076797, acc: 100.00%] [G loss: 4.417203]\n",
      "epoch:36 step:28778 [D loss: 0.194202, acc: 94.53%] [G loss: 4.848513]\n",
      "epoch:36 step:28779 [D loss: 0.058850, acc: 100.00%] [G loss: 7.717995]\n",
      "epoch:36 step:28780 [D loss: 0.034055, acc: 100.00%] [G loss: 4.906207]\n",
      "epoch:36 step:28781 [D loss: 0.365476, acc: 92.97%] [G loss: 6.052686]\n",
      "epoch:36 step:28782 [D loss: 1.346380, acc: 9.38%] [G loss: 3.331444]\n",
      "epoch:36 step:28783 [D loss: 0.092702, acc: 99.22%] [G loss: 8.009031]\n",
      "epoch:36 step:28784 [D loss: 0.448041, acc: 82.81%] [G loss: 5.459771]\n",
      "epoch:36 step:28785 [D loss: 0.387027, acc: 75.78%] [G loss: 8.945730]\n",
      "epoch:36 step:28786 [D loss: 0.273396, acc: 96.09%] [G loss: 3.207627]\n",
      "epoch:36 step:28787 [D loss: 0.101902, acc: 100.00%] [G loss: 3.517469]\n",
      "epoch:36 step:28788 [D loss: 0.082936, acc: 99.22%] [G loss: 5.206310]\n",
      "epoch:36 step:28789 [D loss: 0.067529, acc: 100.00%] [G loss: 5.305750]\n",
      "epoch:36 step:28790 [D loss: 0.271361, acc: 93.75%] [G loss: 6.150046]\n",
      "epoch:36 step:28791 [D loss: 0.638555, acc: 56.25%] [G loss: 3.453008]\n",
      "epoch:36 step:28792 [D loss: 0.514036, acc: 66.41%] [G loss: 6.397888]\n",
      "epoch:36 step:28793 [D loss: 0.428258, acc: 84.38%] [G loss: 6.932082]\n",
      "epoch:36 step:28794 [D loss: 0.262914, acc: 94.53%] [G loss: 4.317253]\n",
      "epoch:36 step:28795 [D loss: 0.141727, acc: 98.44%] [G loss: 4.154078]\n",
      "epoch:36 step:28796 [D loss: 0.148632, acc: 98.44%] [G loss: 4.592539]\n",
      "epoch:36 step:28797 [D loss: 0.556230, acc: 67.97%] [G loss: 4.112283]\n",
      "epoch:36 step:28798 [D loss: 0.127904, acc: 100.00%] [G loss: 4.693499]\n",
      "epoch:36 step:28799 [D loss: 0.167233, acc: 97.66%] [G loss: 4.383731]\n",
      "epoch:36 step:28800 [D loss: 0.615168, acc: 66.41%] [G loss: 6.438287]\n",
      "##############\n",
      "[0.86503419 0.86427584 0.79961337 0.80368344 0.79459135 0.8326235\n",
      " 0.89901952 0.82995734 0.82774506 0.8343621 ]\n",
      "##########\n",
      "epoch:36 step:28801 [D loss: 0.646053, acc: 63.28%] [G loss: 5.526566]\n",
      "epoch:36 step:28802 [D loss: 0.141423, acc: 99.22%] [G loss: 3.501400]\n",
      "epoch:36 step:28803 [D loss: 1.126535, acc: 45.31%] [G loss: 6.493019]\n",
      "epoch:36 step:28804 [D loss: 0.170539, acc: 97.66%] [G loss: 6.679014]\n",
      "epoch:36 step:28805 [D loss: 0.595143, acc: 59.38%] [G loss: 6.182585]\n",
      "epoch:36 step:28806 [D loss: 0.041872, acc: 100.00%] [G loss: 7.508295]\n",
      "epoch:36 step:28807 [D loss: 0.297101, acc: 85.16%] [G loss: 4.923894]\n",
      "epoch:36 step:28808 [D loss: 0.136434, acc: 100.00%] [G loss: 7.540245]\n",
      "epoch:36 step:28809 [D loss: 0.518292, acc: 78.91%] [G loss: 6.422999]\n",
      "epoch:36 step:28810 [D loss: 0.182856, acc: 98.44%] [G loss: 5.464036]\n",
      "epoch:36 step:28811 [D loss: 0.651374, acc: 63.28%] [G loss: 5.275015]\n",
      "epoch:36 step:28812 [D loss: 1.076253, acc: 50.78%] [G loss: 4.410022]\n",
      "epoch:36 step:28813 [D loss: 0.379013, acc: 80.47%] [G loss: 5.915123]\n",
      "epoch:36 step:28814 [D loss: 0.170890, acc: 98.44%] [G loss: 4.665478]\n",
      "epoch:36 step:28815 [D loss: 1.169033, acc: 23.44%] [G loss: 4.867250]\n",
      "epoch:36 step:28816 [D loss: 0.237836, acc: 95.31%] [G loss: 5.185063]\n",
      "epoch:36 step:28817 [D loss: 0.124335, acc: 100.00%] [G loss: 3.929008]\n",
      "epoch:36 step:28818 [D loss: 0.448349, acc: 85.94%] [G loss: 4.407807]\n",
      "epoch:36 step:28819 [D loss: 0.423906, acc: 75.00%] [G loss: 5.601431]\n",
      "epoch:36 step:28820 [D loss: 0.244835, acc: 91.41%] [G loss: 8.101240]\n",
      "epoch:36 step:28821 [D loss: 0.238019, acc: 90.62%] [G loss: 4.427197]\n",
      "epoch:36 step:28822 [D loss: 0.008068, acc: 100.00%] [G loss: 8.732003]\n",
      "epoch:36 step:28823 [D loss: 0.830096, acc: 45.31%] [G loss: 8.598756]\n",
      "epoch:36 step:28824 [D loss: 0.038833, acc: 100.00%] [G loss: 6.461554]\n",
      "epoch:36 step:28825 [D loss: 0.506088, acc: 70.31%] [G loss: 3.309877]\n",
      "epoch:36 step:28826 [D loss: 1.043869, acc: 50.78%] [G loss: 4.831537]\n",
      "epoch:36 step:28827 [D loss: 0.012315, acc: 100.00%] [G loss: 8.214605]\n",
      "epoch:36 step:28828 [D loss: 0.315582, acc: 89.06%] [G loss: 4.307688]\n",
      "epoch:36 step:28829 [D loss: 0.184177, acc: 97.66%] [G loss: 3.306684]\n",
      "epoch:36 step:28830 [D loss: 0.057028, acc: 100.00%] [G loss: 5.499233]\n",
      "epoch:36 step:28831 [D loss: 0.343568, acc: 89.06%] [G loss: 2.374826]\n",
      "epoch:36 step:28832 [D loss: 0.161630, acc: 97.66%] [G loss: 2.826537]\n",
      "epoch:36 step:28833 [D loss: 0.293839, acc: 91.41%] [G loss: 7.114778]\n",
      "epoch:36 step:28834 [D loss: 0.444996, acc: 68.75%] [G loss: 7.285454]\n",
      "epoch:36 step:28835 [D loss: 0.894010, acc: 50.78%] [G loss: 4.783243]\n",
      "epoch:36 step:28836 [D loss: 0.064811, acc: 100.00%] [G loss: 6.078720]\n",
      "epoch:36 step:28837 [D loss: 0.639380, acc: 60.94%] [G loss: 6.689916]\n",
      "epoch:36 step:28838 [D loss: 0.094487, acc: 99.22%] [G loss: 4.367697]\n",
      "epoch:36 step:28839 [D loss: 0.370905, acc: 78.91%] [G loss: 5.523118]\n",
      "epoch:36 step:28840 [D loss: 0.451050, acc: 70.31%] [G loss: 3.969580]\n",
      "epoch:36 step:28841 [D loss: 0.395532, acc: 85.16%] [G loss: 6.400108]\n",
      "epoch:36 step:28842 [D loss: 0.613953, acc: 62.50%] [G loss: 6.014001]\n",
      "epoch:36 step:28843 [D loss: 0.212312, acc: 93.75%] [G loss: 9.118303]\n",
      "epoch:36 step:28844 [D loss: 0.364098, acc: 84.38%] [G loss: 4.766079]\n",
      "epoch:36 step:28845 [D loss: 0.278179, acc: 96.09%] [G loss: 5.913356]\n",
      "epoch:36 step:28846 [D loss: 0.138677, acc: 100.00%] [G loss: 4.092821]\n",
      "epoch:36 step:28847 [D loss: 0.221091, acc: 96.88%] [G loss: 4.451137]\n",
      "epoch:36 step:28848 [D loss: 0.247534, acc: 92.19%] [G loss: 4.831708]\n",
      "epoch:36 step:28849 [D loss: 0.153629, acc: 100.00%] [G loss: 5.195361]\n",
      "epoch:36 step:28850 [D loss: 0.252220, acc: 94.53%] [G loss: 4.902744]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:36 step:28851 [D loss: 0.036820, acc: 100.00%] [G loss: 7.096813]\n",
      "epoch:36 step:28852 [D loss: 0.018551, acc: 100.00%] [G loss: 5.129584]\n",
      "epoch:36 step:28853 [D loss: 0.332225, acc: 80.47%] [G loss: 7.016725]\n",
      "epoch:36 step:28854 [D loss: 0.062269, acc: 100.00%] [G loss: 6.478135]\n",
      "epoch:36 step:28855 [D loss: 0.269734, acc: 88.28%] [G loss: 2.919254]\n",
      "epoch:36 step:28856 [D loss: 0.234008, acc: 93.75%] [G loss: 4.913853]\n",
      "epoch:36 step:28857 [D loss: 0.121391, acc: 99.22%] [G loss: 4.929003]\n",
      "epoch:36 step:28858 [D loss: 0.253950, acc: 98.44%] [G loss: 4.840427]\n",
      "epoch:36 step:28859 [D loss: 0.328714, acc: 92.19%] [G loss: 5.278344]\n",
      "epoch:36 step:28860 [D loss: 0.458965, acc: 82.81%] [G loss: 5.273925]\n",
      "epoch:36 step:28861 [D loss: 0.128233, acc: 100.00%] [G loss: 5.211469]\n",
      "epoch:36 step:28862 [D loss: 0.532015, acc: 70.31%] [G loss: 6.094991]\n",
      "epoch:36 step:28863 [D loss: 0.123919, acc: 99.22%] [G loss: 6.481135]\n",
      "epoch:36 step:28864 [D loss: 0.666451, acc: 57.81%] [G loss: 3.921802]\n",
      "epoch:36 step:28865 [D loss: 0.150500, acc: 100.00%] [G loss: 3.953142]\n",
      "epoch:36 step:28866 [D loss: 0.164975, acc: 99.22%] [G loss: 3.932142]\n",
      "epoch:36 step:28867 [D loss: 0.575254, acc: 70.31%] [G loss: 3.175668]\n",
      "epoch:36 step:28868 [D loss: 0.124182, acc: 99.22%] [G loss: 3.844295]\n",
      "epoch:36 step:28869 [D loss: 0.193679, acc: 96.88%] [G loss: 4.775936]\n",
      "epoch:36 step:28870 [D loss: 0.053951, acc: 99.22%] [G loss: 4.627075]\n",
      "epoch:36 step:28871 [D loss: 0.208024, acc: 97.66%] [G loss: 3.330163]\n",
      "epoch:36 step:28872 [D loss: 0.516114, acc: 81.25%] [G loss: 4.896932]\n",
      "epoch:36 step:28873 [D loss: 0.214077, acc: 96.88%] [G loss: 5.754271]\n",
      "epoch:36 step:28874 [D loss: 0.335787, acc: 91.41%] [G loss: 5.624637]\n",
      "epoch:36 step:28875 [D loss: 0.209800, acc: 98.44%] [G loss: 3.540874]\n",
      "epoch:36 step:28876 [D loss: 0.220459, acc: 92.19%] [G loss: 8.710249]\n",
      "epoch:36 step:28877 [D loss: 0.119868, acc: 98.44%] [G loss: 4.690764]\n",
      "epoch:36 step:28878 [D loss: 0.034435, acc: 100.00%] [G loss: 4.329334]\n",
      "epoch:36 step:28879 [D loss: 0.174739, acc: 98.44%] [G loss: 6.341414]\n",
      "epoch:36 step:28880 [D loss: 1.110421, acc: 40.62%] [G loss: 4.614015]\n",
      "epoch:36 step:28881 [D loss: 1.029742, acc: 43.75%] [G loss: 8.407904]\n",
      "epoch:36 step:28882 [D loss: 0.651638, acc: 61.72%] [G loss: 7.110620]\n",
      "epoch:36 step:28883 [D loss: 0.196121, acc: 96.09%] [G loss: 6.632549]\n",
      "epoch:36 step:28884 [D loss: 0.774290, acc: 52.34%] [G loss: 5.322337]\n",
      "epoch:36 step:28885 [D loss: 0.392249, acc: 87.50%] [G loss: 4.746451]\n",
      "epoch:36 step:28886 [D loss: 0.218686, acc: 96.09%] [G loss: 6.211167]\n",
      "epoch:36 step:28887 [D loss: 0.628244, acc: 62.50%] [G loss: 4.887172]\n",
      "epoch:36 step:28888 [D loss: 0.238958, acc: 92.97%] [G loss: 5.856421]\n",
      "epoch:36 step:28889 [D loss: 0.080177, acc: 100.00%] [G loss: 5.046953]\n",
      "epoch:36 step:28890 [D loss: 0.198312, acc: 96.09%] [G loss: 7.910240]\n",
      "epoch:36 step:28891 [D loss: 0.434829, acc: 78.12%] [G loss: 5.780626]\n",
      "epoch:36 step:28892 [D loss: 0.558007, acc: 67.19%] [G loss: 4.096098]\n",
      "epoch:36 step:28893 [D loss: 0.325036, acc: 89.84%] [G loss: 4.951205]\n",
      "epoch:36 step:28894 [D loss: 0.162989, acc: 97.66%] [G loss: 4.463631]\n",
      "epoch:36 step:28895 [D loss: 0.710826, acc: 57.03%] [G loss: 6.613530]\n",
      "epoch:36 step:28896 [D loss: 0.526671, acc: 70.31%] [G loss: 4.613317]\n",
      "epoch:36 step:28897 [D loss: 0.113048, acc: 100.00%] [G loss: 3.921446]\n",
      "epoch:37 step:28898 [D loss: 0.459842, acc: 79.69%] [G loss: 4.007950]\n",
      "epoch:37 step:28899 [D loss: 0.050936, acc: 99.22%] [G loss: 7.159082]\n",
      "epoch:37 step:28900 [D loss: 0.141901, acc: 100.00%] [G loss: 6.842518]\n",
      "epoch:37 step:28901 [D loss: 0.672993, acc: 57.81%] [G loss: 5.500194]\n",
      "epoch:37 step:28902 [D loss: 0.153754, acc: 100.00%] [G loss: 4.786417]\n",
      "epoch:37 step:28903 [D loss: 0.141185, acc: 100.00%] [G loss: 4.593919]\n",
      "epoch:37 step:28904 [D loss: 0.906095, acc: 51.56%] [G loss: 3.418897]\n",
      "epoch:37 step:28905 [D loss: 0.408788, acc: 84.38%] [G loss: 6.863244]\n",
      "epoch:37 step:28906 [D loss: 0.174178, acc: 98.44%] [G loss: 5.108575]\n",
      "epoch:37 step:28907 [D loss: 0.530236, acc: 75.78%] [G loss: 6.877406]\n",
      "epoch:37 step:28908 [D loss: 0.068307, acc: 100.00%] [G loss: 9.111105]\n",
      "epoch:37 step:28909 [D loss: 0.231678, acc: 95.31%] [G loss: 6.841216]\n",
      "epoch:37 step:28910 [D loss: 0.122505, acc: 99.22%] [G loss: 5.895339]\n",
      "epoch:37 step:28911 [D loss: 0.387405, acc: 85.94%] [G loss: 6.715180]\n",
      "epoch:37 step:28912 [D loss: 0.185112, acc: 98.44%] [G loss: 6.541705]\n",
      "epoch:37 step:28913 [D loss: 0.797372, acc: 51.56%] [G loss: 5.517081]\n",
      "epoch:37 step:28914 [D loss: 0.418907, acc: 87.50%] [G loss: 5.263843]\n",
      "epoch:37 step:28915 [D loss: 0.451856, acc: 82.81%] [G loss: 6.820422]\n",
      "epoch:37 step:28916 [D loss: 0.271303, acc: 92.19%] [G loss: 3.994427]\n",
      "epoch:37 step:28917 [D loss: 0.616666, acc: 60.94%] [G loss: 4.954680]\n",
      "epoch:37 step:28918 [D loss: 0.134655, acc: 99.22%] [G loss: 5.246453]\n",
      "epoch:37 step:28919 [D loss: 0.114087, acc: 100.00%] [G loss: 6.702659]\n",
      "epoch:37 step:28920 [D loss: 0.122089, acc: 100.00%] [G loss: 5.534705]\n",
      "epoch:37 step:28921 [D loss: 0.340847, acc: 85.16%] [G loss: 4.320984]\n",
      "epoch:37 step:28922 [D loss: 0.454352, acc: 70.31%] [G loss: 8.914011]\n",
      "epoch:37 step:28923 [D loss: 0.571964, acc: 62.50%] [G loss: 4.637817]\n",
      "epoch:37 step:28924 [D loss: 0.113301, acc: 100.00%] [G loss: 5.206660]\n",
      "epoch:37 step:28925 [D loss: 0.400045, acc: 71.88%] [G loss: 7.569173]\n",
      "epoch:37 step:28926 [D loss: 0.084847, acc: 99.22%] [G loss: 6.143613]\n",
      "epoch:37 step:28927 [D loss: 0.141991, acc: 95.31%] [G loss: 6.484466]\n",
      "epoch:37 step:28928 [D loss: 0.132801, acc: 99.22%] [G loss: 4.341557]\n",
      "epoch:37 step:28929 [D loss: 0.051291, acc: 100.00%] [G loss: 4.732753]\n",
      "epoch:37 step:28930 [D loss: 0.227105, acc: 91.41%] [G loss: 6.700634]\n",
      "epoch:37 step:28931 [D loss: 0.221258, acc: 97.66%] [G loss: 7.261316]\n",
      "epoch:37 step:28932 [D loss: 0.364704, acc: 81.25%] [G loss: 4.679227]\n",
      "epoch:37 step:28933 [D loss: 1.192148, acc: 51.56%] [G loss: 3.659358]\n",
      "epoch:37 step:28934 [D loss: 0.515837, acc: 64.06%] [G loss: 6.196178]\n",
      "epoch:37 step:28935 [D loss: 0.326720, acc: 92.97%] [G loss: 4.078309]\n",
      "epoch:37 step:28936 [D loss: 0.456011, acc: 81.25%] [G loss: 4.119670]\n",
      "epoch:37 step:28937 [D loss: 0.313094, acc: 88.28%] [G loss: 5.247174]\n",
      "epoch:37 step:28938 [D loss: 0.300920, acc: 87.50%] [G loss: 4.600051]\n",
      "epoch:37 step:28939 [D loss: 0.391913, acc: 81.25%] [G loss: 5.404981]\n",
      "epoch:37 step:28940 [D loss: 0.427145, acc: 82.81%] [G loss: 4.349139]\n",
      "epoch:37 step:28941 [D loss: 0.295315, acc: 90.62%] [G loss: 4.594323]\n",
      "epoch:37 step:28942 [D loss: 0.034429, acc: 100.00%] [G loss: 5.777640]\n",
      "epoch:37 step:28943 [D loss: 0.163179, acc: 96.88%] [G loss: 3.376652]\n",
      "epoch:37 step:28944 [D loss: 0.357389, acc: 84.38%] [G loss: 8.427423]\n",
      "epoch:37 step:28945 [D loss: 0.135137, acc: 98.44%] [G loss: 4.941774]\n",
      "epoch:37 step:28946 [D loss: 0.987985, acc: 49.22%] [G loss: 6.441331]\n",
      "epoch:37 step:28947 [D loss: 0.249233, acc: 91.41%] [G loss: 4.688798]\n",
      "epoch:37 step:28948 [D loss: 0.694318, acc: 55.47%] [G loss: 7.204955]\n",
      "epoch:37 step:28949 [D loss: 0.104103, acc: 98.44%] [G loss: 5.318181]\n",
      "epoch:37 step:28950 [D loss: 0.317894, acc: 84.38%] [G loss: 4.881780]\n",
      "epoch:37 step:28951 [D loss: 0.027656, acc: 100.00%] [G loss: 4.132850]\n",
      "epoch:37 step:28952 [D loss: 0.330856, acc: 82.03%] [G loss: 6.666119]\n",
      "epoch:37 step:28953 [D loss: 0.190007, acc: 96.09%] [G loss: 9.080273]\n",
      "epoch:37 step:28954 [D loss: 0.133721, acc: 98.44%] [G loss: 6.429924]\n",
      "epoch:37 step:28955 [D loss: 0.071963, acc: 100.00%] [G loss: 5.946944]\n",
      "epoch:37 step:28956 [D loss: 0.075128, acc: 100.00%] [G loss: 4.907724]\n",
      "epoch:37 step:28957 [D loss: 0.939948, acc: 46.88%] [G loss: 5.412498]\n",
      "epoch:37 step:28958 [D loss: 1.486381, acc: 49.22%] [G loss: 4.251997]\n",
      "epoch:37 step:28959 [D loss: 0.108731, acc: 100.00%] [G loss: 3.923896]\n",
      "epoch:37 step:28960 [D loss: 0.282923, acc: 87.50%] [G loss: 4.011960]\n",
      "epoch:37 step:28961 [D loss: 0.205799, acc: 95.31%] [G loss: 3.729218]\n",
      "epoch:37 step:28962 [D loss: 0.228715, acc: 97.66%] [G loss: 5.195653]\n",
      "epoch:37 step:28963 [D loss: 0.339637, acc: 93.75%] [G loss: 6.125704]\n",
      "epoch:37 step:28964 [D loss: 0.441119, acc: 74.22%] [G loss: 4.533689]\n",
      "epoch:37 step:28965 [D loss: 0.051450, acc: 100.00%] [G loss: 6.947076]\n",
      "epoch:37 step:28966 [D loss: 0.290127, acc: 88.28%] [G loss: 4.322446]\n",
      "epoch:37 step:28967 [D loss: 0.191158, acc: 98.44%] [G loss: 5.372309]\n",
      "epoch:37 step:28968 [D loss: 0.186151, acc: 96.88%] [G loss: 7.027972]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:37 step:28969 [D loss: 0.251092, acc: 96.88%] [G loss: 6.065387]\n",
      "epoch:37 step:28970 [D loss: 0.940295, acc: 50.78%] [G loss: 3.968734]\n",
      "epoch:37 step:28971 [D loss: 0.370834, acc: 92.19%] [G loss: 4.020110]\n",
      "epoch:37 step:28972 [D loss: 1.152805, acc: 38.28%] [G loss: 5.825314]\n",
      "epoch:37 step:28973 [D loss: 0.624408, acc: 65.62%] [G loss: 7.751816]\n",
      "epoch:37 step:28974 [D loss: 0.156520, acc: 97.66%] [G loss: 3.461371]\n",
      "epoch:37 step:28975 [D loss: 0.208001, acc: 95.31%] [G loss: 5.140121]\n",
      "epoch:37 step:28976 [D loss: 0.091533, acc: 100.00%] [G loss: 3.454290]\n",
      "epoch:37 step:28977 [D loss: 0.118658, acc: 99.22%] [G loss: 4.692419]\n",
      "epoch:37 step:28978 [D loss: 0.368611, acc: 89.84%] [G loss: 6.910775]\n",
      "epoch:37 step:28979 [D loss: 0.215371, acc: 96.88%] [G loss: 3.340432]\n",
      "epoch:37 step:28980 [D loss: 0.215219, acc: 97.66%] [G loss: 4.919141]\n",
      "epoch:37 step:28981 [D loss: 0.190067, acc: 97.66%] [G loss: 3.714212]\n",
      "epoch:37 step:28982 [D loss: 0.032863, acc: 100.00%] [G loss: 5.401522]\n",
      "epoch:37 step:28983 [D loss: 0.731430, acc: 57.03%] [G loss: 4.029102]\n",
      "epoch:37 step:28984 [D loss: 1.067006, acc: 49.22%] [G loss: 7.411325]\n",
      "epoch:37 step:28985 [D loss: 0.622572, acc: 66.41%] [G loss: 4.896015]\n",
      "epoch:37 step:28986 [D loss: 0.023891, acc: 100.00%] [G loss: 8.072846]\n",
      "epoch:37 step:28987 [D loss: 1.360356, acc: 50.00%] [G loss: 4.325602]\n",
      "epoch:37 step:28988 [D loss: 0.173265, acc: 96.09%] [G loss: 4.841684]\n",
      "epoch:37 step:28989 [D loss: 0.056647, acc: 100.00%] [G loss: 6.536513]\n",
      "epoch:37 step:28990 [D loss: 0.390281, acc: 89.06%] [G loss: 2.295560]\n",
      "epoch:37 step:28991 [D loss: 0.343041, acc: 82.81%] [G loss: 4.084301]\n",
      "epoch:37 step:28992 [D loss: 0.077513, acc: 100.00%] [G loss: 6.626724]\n",
      "epoch:37 step:28993 [D loss: 0.057958, acc: 100.00%] [G loss: 5.057680]\n",
      "epoch:37 step:28994 [D loss: 0.480526, acc: 73.44%] [G loss: 5.469048]\n",
      "epoch:37 step:28995 [D loss: 0.061563, acc: 99.22%] [G loss: 6.619320]\n",
      "epoch:37 step:28996 [D loss: 0.302501, acc: 92.19%] [G loss: 4.172759]\n",
      "epoch:37 step:28997 [D loss: 0.203060, acc: 94.53%] [G loss: 4.609966]\n",
      "epoch:37 step:28998 [D loss: 0.286837, acc: 97.66%] [G loss: 5.331439]\n",
      "epoch:37 step:28999 [D loss: 0.356354, acc: 82.81%] [G loss: 3.806255]\n",
      "epoch:37 step:29000 [D loss: 0.029316, acc: 100.00%] [G loss: 6.644037]\n",
      "##############\n",
      "[0.86055956 0.89059138 0.81517156 0.80132512 0.77774849 0.8252175\n",
      " 0.87659351 0.83444566 0.8234386  0.82062383]\n",
      "##########\n",
      "epoch:37 step:29001 [D loss: 0.009050, acc: 100.00%] [G loss: 4.226304]\n",
      "epoch:37 step:29002 [D loss: 0.720518, acc: 55.47%] [G loss: 6.097842]\n",
      "epoch:37 step:29003 [D loss: 0.969297, acc: 46.09%] [G loss: 3.663567]\n",
      "epoch:37 step:29004 [D loss: 0.235427, acc: 92.19%] [G loss: 4.726180]\n",
      "epoch:37 step:29005 [D loss: 0.255452, acc: 92.19%] [G loss: 4.828483]\n",
      "epoch:37 step:29006 [D loss: 0.074092, acc: 100.00%] [G loss: 4.854180]\n",
      "epoch:37 step:29007 [D loss: 0.456819, acc: 74.22%] [G loss: 5.463444]\n",
      "epoch:37 step:29008 [D loss: 0.141126, acc: 100.00%] [G loss: 4.253953]\n",
      "epoch:37 step:29009 [D loss: 0.138582, acc: 97.66%] [G loss: 5.383419]\n",
      "epoch:37 step:29010 [D loss: 0.099777, acc: 98.44%] [G loss: 6.683815]\n",
      "epoch:37 step:29011 [D loss: 0.157078, acc: 97.66%] [G loss: 7.766912]\n",
      "epoch:37 step:29012 [D loss: 0.521377, acc: 75.78%] [G loss: 6.928413]\n",
      "epoch:37 step:29013 [D loss: 0.331909, acc: 85.94%] [G loss: 5.351265]\n",
      "epoch:37 step:29014 [D loss: 0.061269, acc: 100.00%] [G loss: 5.108522]\n",
      "epoch:37 step:29015 [D loss: 0.511691, acc: 77.34%] [G loss: 3.673468]\n",
      "epoch:37 step:29016 [D loss: 0.225446, acc: 91.41%] [G loss: 3.247044]\n",
      "epoch:37 step:29017 [D loss: 0.306762, acc: 89.06%] [G loss: 5.956178]\n",
      "epoch:37 step:29018 [D loss: 0.498469, acc: 72.66%] [G loss: 3.918210]\n",
      "epoch:37 step:29019 [D loss: 0.019507, acc: 100.00%] [G loss: 6.045854]\n",
      "epoch:37 step:29020 [D loss: 0.097476, acc: 100.00%] [G loss: 3.097827]\n",
      "epoch:37 step:29021 [D loss: 0.006380, acc: 100.00%] [G loss: 5.699775]\n",
      "epoch:37 step:29022 [D loss: 0.553355, acc: 73.44%] [G loss: 6.995529]\n",
      "epoch:37 step:29023 [D loss: 0.204333, acc: 93.75%] [G loss: 7.000744]\n",
      "epoch:37 step:29024 [D loss: 0.554080, acc: 64.84%] [G loss: 5.744468]\n",
      "epoch:37 step:29025 [D loss: 0.008846, acc: 100.00%] [G loss: 9.341408]\n",
      "epoch:37 step:29026 [D loss: 0.142263, acc: 98.44%] [G loss: 3.862337]\n",
      "epoch:37 step:29027 [D loss: 0.512007, acc: 78.91%] [G loss: 4.869021]\n",
      "epoch:37 step:29028 [D loss: 0.044466, acc: 100.00%] [G loss: 5.392919]\n",
      "epoch:37 step:29029 [D loss: 0.096117, acc: 100.00%] [G loss: 4.474420]\n",
      "epoch:37 step:29030 [D loss: 1.018161, acc: 35.16%] [G loss: 9.656584]\n",
      "epoch:37 step:29031 [D loss: 0.323146, acc: 83.59%] [G loss: 6.565453]\n",
      "epoch:37 step:29032 [D loss: 1.208948, acc: 50.78%] [G loss: 9.466819]\n",
      "epoch:37 step:29033 [D loss: 0.478085, acc: 66.41%] [G loss: 5.115877]\n",
      "epoch:37 step:29034 [D loss: 0.097152, acc: 99.22%] [G loss: 6.130635]\n",
      "epoch:37 step:29035 [D loss: 0.266644, acc: 92.97%] [G loss: 4.836635]\n",
      "epoch:37 step:29036 [D loss: 0.106811, acc: 99.22%] [G loss: 4.827597]\n",
      "epoch:37 step:29037 [D loss: 0.063359, acc: 100.00%] [G loss: 8.308414]\n",
      "epoch:37 step:29038 [D loss: 0.101087, acc: 98.44%] [G loss: 8.020952]\n",
      "epoch:37 step:29039 [D loss: 0.104320, acc: 100.00%] [G loss: 7.228224]\n",
      "epoch:37 step:29040 [D loss: 0.478176, acc: 82.03%] [G loss: 5.644683]\n",
      "epoch:37 step:29041 [D loss: 0.550766, acc: 60.94%] [G loss: 4.103867]\n",
      "epoch:37 step:29042 [D loss: 0.137514, acc: 100.00%] [G loss: 2.979445]\n",
      "epoch:37 step:29043 [D loss: 0.192695, acc: 98.44%] [G loss: 6.211023]\n",
      "epoch:37 step:29044 [D loss: 0.125309, acc: 98.44%] [G loss: 6.418164]\n",
      "epoch:37 step:29045 [D loss: 0.316166, acc: 91.41%] [G loss: 4.437780]\n",
      "epoch:37 step:29046 [D loss: 0.360072, acc: 91.41%] [G loss: 5.450596]\n",
      "epoch:37 step:29047 [D loss: 0.310602, acc: 92.97%] [G loss: 5.349237]\n",
      "epoch:37 step:29048 [D loss: 0.720306, acc: 55.47%] [G loss: 10.191850]\n",
      "epoch:37 step:29049 [D loss: 0.626846, acc: 61.72%] [G loss: 7.901395]\n",
      "epoch:37 step:29050 [D loss: 0.336692, acc: 87.50%] [G loss: 6.699658]\n",
      "epoch:37 step:29051 [D loss: 0.209350, acc: 98.44%] [G loss: 4.588649]\n",
      "epoch:37 step:29052 [D loss: 0.418339, acc: 78.12%] [G loss: 7.335948]\n",
      "epoch:37 step:29053 [D loss: 0.200778, acc: 95.31%] [G loss: 5.791647]\n",
      "epoch:37 step:29054 [D loss: 0.615451, acc: 56.25%] [G loss: 4.459898]\n",
      "epoch:37 step:29055 [D loss: 0.064983, acc: 100.00%] [G loss: 3.164226]\n",
      "epoch:37 step:29056 [D loss: 0.271294, acc: 90.62%] [G loss: 4.391071]\n",
      "epoch:37 step:29057 [D loss: 2.027553, acc: 10.16%] [G loss: 6.517797]\n",
      "epoch:37 step:29058 [D loss: 0.120693, acc: 99.22%] [G loss: 8.740970]\n",
      "epoch:37 step:29059 [D loss: 0.121607, acc: 99.22%] [G loss: 5.328920]\n",
      "epoch:37 step:29060 [D loss: 0.130308, acc: 98.44%] [G loss: 5.355675]\n",
      "epoch:37 step:29061 [D loss: 0.367472, acc: 75.00%] [G loss: 5.038476]\n",
      "epoch:37 step:29062 [D loss: 0.089941, acc: 99.22%] [G loss: 5.236281]\n",
      "epoch:37 step:29063 [D loss: 0.931997, acc: 53.12%] [G loss: 7.988737]\n",
      "epoch:37 step:29064 [D loss: 0.121914, acc: 100.00%] [G loss: 5.520356]\n",
      "epoch:37 step:29065 [D loss: 0.015003, acc: 100.00%] [G loss: 5.938641]\n",
      "epoch:37 step:29066 [D loss: 0.151181, acc: 100.00%] [G loss: 4.183553]\n",
      "epoch:37 step:29067 [D loss: 0.285975, acc: 89.84%] [G loss: 4.877340]\n",
      "epoch:37 step:29068 [D loss: 0.943324, acc: 52.34%] [G loss: 5.951276]\n",
      "epoch:37 step:29069 [D loss: 1.420067, acc: 30.47%] [G loss: 5.501050]\n",
      "epoch:37 step:29070 [D loss: 0.093365, acc: 99.22%] [G loss: 2.663969]\n",
      "epoch:37 step:29071 [D loss: 0.058847, acc: 100.00%] [G loss: 8.298771]\n",
      "epoch:37 step:29072 [D loss: 0.121357, acc: 99.22%] [G loss: 8.554771]\n",
      "epoch:37 step:29073 [D loss: 0.522607, acc: 65.62%] [G loss: 4.952507]\n",
      "epoch:37 step:29074 [D loss: 0.470424, acc: 67.97%] [G loss: 4.799914]\n",
      "epoch:37 step:29075 [D loss: 0.270202, acc: 89.84%] [G loss: 4.547304]\n",
      "epoch:37 step:29076 [D loss: 0.069102, acc: 99.22%] [G loss: 5.374209]\n",
      "epoch:37 step:29077 [D loss: 1.448174, acc: 50.00%] [G loss: 6.796085]\n",
      "epoch:37 step:29078 [D loss: 0.058054, acc: 100.00%] [G loss: 4.311013]\n",
      "epoch:37 step:29079 [D loss: 0.202732, acc: 92.19%] [G loss: 4.638584]\n",
      "epoch:37 step:29080 [D loss: 0.194091, acc: 92.19%] [G loss: 8.334690]\n",
      "epoch:37 step:29081 [D loss: 0.089987, acc: 100.00%] [G loss: 8.190868]\n",
      "epoch:37 step:29082 [D loss: 0.578245, acc: 70.31%] [G loss: 5.105109]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:37 step:29083 [D loss: 0.158075, acc: 97.66%] [G loss: 7.624203]\n",
      "epoch:37 step:29084 [D loss: 0.341550, acc: 92.19%] [G loss: 5.931446]\n",
      "epoch:37 step:29085 [D loss: 0.083972, acc: 99.22%] [G loss: 5.444607]\n",
      "epoch:37 step:29086 [D loss: 0.224882, acc: 92.19%] [G loss: 10.282782]\n",
      "epoch:37 step:29087 [D loss: 0.119438, acc: 99.22%] [G loss: 4.212273]\n",
      "epoch:37 step:29088 [D loss: 0.092848, acc: 99.22%] [G loss: 5.301800]\n",
      "epoch:37 step:29089 [D loss: 0.166140, acc: 98.44%] [G loss: 10.990213]\n",
      "epoch:37 step:29090 [D loss: 0.721752, acc: 60.16%] [G loss: 6.836050]\n",
      "epoch:37 step:29091 [D loss: 0.052227, acc: 100.00%] [G loss: 4.765032]\n",
      "epoch:37 step:29092 [D loss: 0.540890, acc: 61.72%] [G loss: 6.772134]\n",
      "epoch:37 step:29093 [D loss: 0.049842, acc: 100.00%] [G loss: 6.224509]\n",
      "epoch:37 step:29094 [D loss: 0.984536, acc: 51.56%] [G loss: 6.323886]\n",
      "epoch:37 step:29095 [D loss: 0.254602, acc: 93.75%] [G loss: 7.315862]\n",
      "epoch:37 step:29096 [D loss: 0.268135, acc: 96.09%] [G loss: 6.204068]\n",
      "epoch:37 step:29097 [D loss: 0.183681, acc: 94.53%] [G loss: 8.881622]\n",
      "epoch:37 step:29098 [D loss: 2.222091, acc: 50.00%] [G loss: 5.401731]\n",
      "epoch:37 step:29099 [D loss: 0.118204, acc: 96.88%] [G loss: 3.938396]\n",
      "epoch:37 step:29100 [D loss: 0.424828, acc: 74.22%] [G loss: 3.277728]\n",
      "epoch:37 step:29101 [D loss: 0.103285, acc: 100.00%] [G loss: 3.585361]\n",
      "epoch:37 step:29102 [D loss: 0.044491, acc: 100.00%] [G loss: 5.315829]\n",
      "epoch:37 step:29103 [D loss: 0.685951, acc: 65.62%] [G loss: 6.663539]\n",
      "epoch:37 step:29104 [D loss: 0.090980, acc: 99.22%] [G loss: 10.134295]\n",
      "epoch:37 step:29105 [D loss: 0.196255, acc: 92.97%] [G loss: 5.377035]\n",
      "epoch:37 step:29106 [D loss: 1.196934, acc: 50.00%] [G loss: 7.101276]\n",
      "epoch:37 step:29107 [D loss: 1.023721, acc: 50.00%] [G loss: 5.257856]\n",
      "epoch:37 step:29108 [D loss: 0.220864, acc: 96.88%] [G loss: 4.001134]\n",
      "epoch:37 step:29109 [D loss: 0.353149, acc: 81.25%] [G loss: 10.536472]\n",
      "epoch:37 step:29110 [D loss: 0.535213, acc: 77.34%] [G loss: 6.229112]\n",
      "epoch:37 step:29111 [D loss: 0.364892, acc: 83.59%] [G loss: 3.785563]\n",
      "epoch:37 step:29112 [D loss: 0.217438, acc: 92.19%] [G loss: 7.671217]\n",
      "epoch:37 step:29113 [D loss: 0.243409, acc: 93.75%] [G loss: 6.393517]\n",
      "epoch:37 step:29114 [D loss: 0.231757, acc: 92.97%] [G loss: 6.135087]\n",
      "epoch:37 step:29115 [D loss: 0.931219, acc: 46.09%] [G loss: 4.624473]\n",
      "epoch:37 step:29116 [D loss: 0.693700, acc: 57.03%] [G loss: 5.100315]\n",
      "epoch:37 step:29117 [D loss: 0.035170, acc: 100.00%] [G loss: 6.077262]\n",
      "epoch:37 step:29118 [D loss: 0.257571, acc: 89.06%] [G loss: 6.340736]\n",
      "epoch:37 step:29119 [D loss: 0.088756, acc: 99.22%] [G loss: 5.876297]\n",
      "epoch:37 step:29120 [D loss: 0.054112, acc: 100.00%] [G loss: 7.569818]\n",
      "epoch:37 step:29121 [D loss: 0.824093, acc: 48.44%] [G loss: 8.595209]\n",
      "epoch:37 step:29122 [D loss: 0.591392, acc: 69.53%] [G loss: 4.450121]\n",
      "epoch:37 step:29123 [D loss: 0.031969, acc: 100.00%] [G loss: 4.298808]\n",
      "epoch:37 step:29124 [D loss: 0.327281, acc: 90.62%] [G loss: 4.096831]\n",
      "epoch:37 step:29125 [D loss: 0.981817, acc: 52.34%] [G loss: 10.327870]\n",
      "epoch:37 step:29126 [D loss: 0.025190, acc: 100.00%] [G loss: 4.322915]\n",
      "epoch:37 step:29127 [D loss: 0.725053, acc: 55.47%] [G loss: 7.748642]\n",
      "epoch:37 step:29128 [D loss: 0.589636, acc: 60.16%] [G loss: 9.677975]\n",
      "epoch:37 step:29129 [D loss: 0.109031, acc: 99.22%] [G loss: 4.469043]\n",
      "epoch:37 step:29130 [D loss: 0.665391, acc: 55.47%] [G loss: 5.651663]\n",
      "epoch:37 step:29131 [D loss: 0.749873, acc: 53.12%] [G loss: 7.184280]\n",
      "epoch:37 step:29132 [D loss: 0.162529, acc: 98.44%] [G loss: 6.424266]\n",
      "epoch:37 step:29133 [D loss: 0.068823, acc: 100.00%] [G loss: 3.194484]\n",
      "epoch:37 step:29134 [D loss: 0.088147, acc: 100.00%] [G loss: 6.775104]\n",
      "epoch:37 step:29135 [D loss: 0.202193, acc: 98.44%] [G loss: 4.136674]\n",
      "epoch:37 step:29136 [D loss: 0.132024, acc: 99.22%] [G loss: 5.170481]\n",
      "epoch:37 step:29137 [D loss: 0.459186, acc: 78.12%] [G loss: 4.826650]\n",
      "epoch:37 step:29138 [D loss: 0.023162, acc: 100.00%] [G loss: 4.226417]\n",
      "epoch:37 step:29139 [D loss: 0.051724, acc: 100.00%] [G loss: 6.353024]\n",
      "epoch:37 step:29140 [D loss: 0.585859, acc: 69.53%] [G loss: 7.282081]\n",
      "epoch:37 step:29141 [D loss: 0.031676, acc: 100.00%] [G loss: 8.768211]\n",
      "epoch:37 step:29142 [D loss: 0.217721, acc: 89.84%] [G loss: 5.920793]\n",
      "epoch:37 step:29143 [D loss: 0.359622, acc: 89.06%] [G loss: 8.035663]\n",
      "epoch:37 step:29144 [D loss: 0.204561, acc: 96.88%] [G loss: 4.528175]\n",
      "epoch:37 step:29145 [D loss: 0.533277, acc: 65.62%] [G loss: 6.809957]\n",
      "epoch:37 step:29146 [D loss: 0.929675, acc: 50.00%] [G loss: 8.429728]\n",
      "epoch:37 step:29147 [D loss: 0.129255, acc: 96.09%] [G loss: 5.794546]\n",
      "epoch:37 step:29148 [D loss: 0.022771, acc: 100.00%] [G loss: 8.963188]\n",
      "epoch:37 step:29149 [D loss: 0.170533, acc: 96.88%] [G loss: 3.813879]\n",
      "epoch:37 step:29150 [D loss: 1.344233, acc: 39.06%] [G loss: 7.944371]\n",
      "epoch:37 step:29151 [D loss: 0.323990, acc: 90.62%] [G loss: 4.847086]\n",
      "epoch:37 step:29152 [D loss: 0.159420, acc: 97.66%] [G loss: 5.062031]\n",
      "epoch:37 step:29153 [D loss: 0.151704, acc: 100.00%] [G loss: 6.771030]\n",
      "epoch:37 step:29154 [D loss: 0.362771, acc: 92.19%] [G loss: 3.868191]\n",
      "epoch:37 step:29155 [D loss: 0.414542, acc: 76.56%] [G loss: 4.220870]\n",
      "epoch:37 step:29156 [D loss: 0.060577, acc: 100.00%] [G loss: 2.929420]\n",
      "epoch:37 step:29157 [D loss: 0.133377, acc: 98.44%] [G loss: 6.685812]\n",
      "epoch:37 step:29158 [D loss: 0.619007, acc: 66.41%] [G loss: 7.636273]\n",
      "epoch:37 step:29159 [D loss: 0.032424, acc: 100.00%] [G loss: 9.189847]\n",
      "epoch:37 step:29160 [D loss: 0.185663, acc: 96.88%] [G loss: 7.113873]\n",
      "epoch:37 step:29161 [D loss: 0.378899, acc: 80.47%] [G loss: 6.022978]\n",
      "epoch:37 step:29162 [D loss: 0.332962, acc: 78.91%] [G loss: 7.825652]\n",
      "epoch:37 step:29163 [D loss: 0.239848, acc: 90.62%] [G loss: 4.570380]\n",
      "epoch:37 step:29164 [D loss: 0.564813, acc: 69.53%] [G loss: 3.093884]\n",
      "epoch:37 step:29165 [D loss: 0.359412, acc: 83.59%] [G loss: 3.800670]\n",
      "epoch:37 step:29166 [D loss: 0.090463, acc: 100.00%] [G loss: 3.760531]\n",
      "epoch:37 step:29167 [D loss: 0.610467, acc: 56.25%] [G loss: 5.991436]\n",
      "epoch:37 step:29168 [D loss: 0.237130, acc: 94.53%] [G loss: 7.792953]\n",
      "epoch:37 step:29169 [D loss: 0.209771, acc: 96.88%] [G loss: 5.933176]\n",
      "epoch:37 step:29170 [D loss: 0.996712, acc: 50.00%] [G loss: 5.102919]\n",
      "epoch:37 step:29171 [D loss: 0.614996, acc: 55.47%] [G loss: 7.117407]\n",
      "epoch:37 step:29172 [D loss: 0.045781, acc: 100.00%] [G loss: 4.463349]\n",
      "epoch:37 step:29173 [D loss: 0.118054, acc: 100.00%] [G loss: 5.630832]\n",
      "epoch:37 step:29174 [D loss: 0.173230, acc: 97.66%] [G loss: 7.850214]\n",
      "epoch:37 step:29175 [D loss: 0.045139, acc: 100.00%] [G loss: 5.680171]\n",
      "epoch:37 step:29176 [D loss: 0.051443, acc: 100.00%] [G loss: 6.769554]\n",
      "epoch:37 step:29177 [D loss: 0.292110, acc: 93.75%] [G loss: 3.310917]\n",
      "epoch:37 step:29178 [D loss: 0.360442, acc: 89.06%] [G loss: 7.337243]\n",
      "epoch:37 step:29179 [D loss: 0.466665, acc: 64.84%] [G loss: 5.102792]\n",
      "epoch:37 step:29180 [D loss: 0.195641, acc: 95.31%] [G loss: 4.790729]\n",
      "epoch:37 step:29181 [D loss: 0.593623, acc: 64.84%] [G loss: 5.653963]\n",
      "epoch:37 step:29182 [D loss: 0.223672, acc: 96.88%] [G loss: 6.355987]\n",
      "epoch:37 step:29183 [D loss: 0.208920, acc: 98.44%] [G loss: 5.288063]\n",
      "epoch:37 step:29184 [D loss: 0.175913, acc: 100.00%] [G loss: 5.364071]\n",
      "epoch:37 step:29185 [D loss: 0.176368, acc: 98.44%] [G loss: 2.270174]\n",
      "epoch:37 step:29186 [D loss: 0.110425, acc: 99.22%] [G loss: 4.092569]\n",
      "epoch:37 step:29187 [D loss: 0.158270, acc: 99.22%] [G loss: 4.561281]\n",
      "epoch:37 step:29188 [D loss: 0.270797, acc: 97.66%] [G loss: 3.218300]\n",
      "epoch:37 step:29189 [D loss: 0.452482, acc: 75.78%] [G loss: 4.824068]\n",
      "epoch:37 step:29190 [D loss: 0.099279, acc: 100.00%] [G loss: 6.757194]\n",
      "epoch:37 step:29191 [D loss: 0.485581, acc: 73.44%] [G loss: 5.122197]\n",
      "epoch:37 step:29192 [D loss: 1.081757, acc: 32.03%] [G loss: 4.439567]\n",
      "epoch:37 step:29193 [D loss: 0.247982, acc: 89.84%] [G loss: 4.713918]\n",
      "epoch:37 step:29194 [D loss: 0.775578, acc: 54.69%] [G loss: 6.796434]\n",
      "epoch:37 step:29195 [D loss: 0.201174, acc: 97.66%] [G loss: 4.548299]\n",
      "epoch:37 step:29196 [D loss: 0.482476, acc: 64.84%] [G loss: 4.630047]\n",
      "epoch:37 step:29197 [D loss: 0.092084, acc: 100.00%] [G loss: 4.478529]\n",
      "epoch:37 step:29198 [D loss: 0.331721, acc: 93.75%] [G loss: 4.063005]\n",
      "epoch:37 step:29199 [D loss: 0.591270, acc: 68.75%] [G loss: 6.470383]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:37 step:29200 [D loss: 0.203819, acc: 97.66%] [G loss: 4.806736]\n",
      "##############\n",
      "[0.86670332 0.89216654 0.80387703 0.80237064 0.79488243 0.82738609\n",
      " 0.91440658 0.84324187 0.80811995 0.81531906]\n",
      "##########\n",
      "epoch:37 step:29201 [D loss: 0.416410, acc: 89.06%] [G loss: 6.959500]\n",
      "epoch:37 step:29202 [D loss: 0.278414, acc: 85.94%] [G loss: 6.535648]\n",
      "epoch:37 step:29203 [D loss: 0.116236, acc: 100.00%] [G loss: 5.458387]\n",
      "epoch:37 step:29204 [D loss: 0.076735, acc: 100.00%] [G loss: 4.908710]\n",
      "epoch:37 step:29205 [D loss: 0.533802, acc: 61.72%] [G loss: 2.441004]\n",
      "epoch:37 step:29206 [D loss: 0.451849, acc: 68.75%] [G loss: 4.751847]\n",
      "epoch:37 step:29207 [D loss: 0.351885, acc: 82.81%] [G loss: 5.198743]\n",
      "epoch:37 step:29208 [D loss: 1.388691, acc: 29.69%] [G loss: 7.122282]\n",
      "epoch:37 step:29209 [D loss: 0.344809, acc: 79.69%] [G loss: 4.966895]\n",
      "epoch:37 step:29210 [D loss: 0.129339, acc: 98.44%] [G loss: 8.626112]\n",
      "epoch:37 step:29211 [D loss: 0.068508, acc: 100.00%] [G loss: 5.112288]\n",
      "epoch:37 step:29212 [D loss: 0.218333, acc: 98.44%] [G loss: 5.799379]\n",
      "epoch:37 step:29213 [D loss: 0.116197, acc: 99.22%] [G loss: 3.088615]\n",
      "epoch:37 step:29214 [D loss: 0.582666, acc: 64.06%] [G loss: 2.830347]\n",
      "epoch:37 step:29215 [D loss: 0.906744, acc: 50.78%] [G loss: 6.878601]\n",
      "epoch:37 step:29216 [D loss: 0.176669, acc: 98.44%] [G loss: 4.891289]\n",
      "epoch:37 step:29217 [D loss: 0.123670, acc: 98.44%] [G loss: 5.574080]\n",
      "epoch:37 step:29218 [D loss: 0.136932, acc: 98.44%] [G loss: 3.462242]\n",
      "epoch:37 step:29219 [D loss: 0.540509, acc: 61.72%] [G loss: 5.338845]\n",
      "epoch:37 step:29220 [D loss: 0.325843, acc: 87.50%] [G loss: 4.261785]\n",
      "epoch:37 step:29221 [D loss: 1.166865, acc: 24.22%] [G loss: 6.940796]\n",
      "epoch:37 step:29222 [D loss: 0.141811, acc: 99.22%] [G loss: 3.824029]\n",
      "epoch:37 step:29223 [D loss: 0.520172, acc: 67.19%] [G loss: 5.601588]\n",
      "epoch:37 step:29224 [D loss: 0.460705, acc: 74.22%] [G loss: 6.262848]\n",
      "epoch:37 step:29225 [D loss: 1.093548, acc: 31.25%] [G loss: 6.605697]\n",
      "epoch:37 step:29226 [D loss: 0.050217, acc: 100.00%] [G loss: 6.733877]\n",
      "epoch:37 step:29227 [D loss: 0.621016, acc: 65.62%] [G loss: 4.620414]\n",
      "epoch:37 step:29228 [D loss: 0.940953, acc: 35.94%] [G loss: 4.811447]\n",
      "epoch:37 step:29229 [D loss: 0.189239, acc: 98.44%] [G loss: 4.509915]\n",
      "epoch:37 step:29230 [D loss: 0.029216, acc: 100.00%] [G loss: 7.533058]\n",
      "epoch:37 step:29231 [D loss: 0.161768, acc: 98.44%] [G loss: 5.185009]\n",
      "epoch:37 step:29232 [D loss: 0.032336, acc: 100.00%] [G loss: 10.141222]\n",
      "epoch:37 step:29233 [D loss: 0.197152, acc: 96.88%] [G loss: 4.721526]\n",
      "epoch:37 step:29234 [D loss: 0.132805, acc: 97.66%] [G loss: 2.736500]\n",
      "epoch:37 step:29235 [D loss: 0.183271, acc: 96.09%] [G loss: 7.572927]\n",
      "epoch:37 step:29236 [D loss: 0.093059, acc: 100.00%] [G loss: 6.012315]\n",
      "epoch:37 step:29237 [D loss: 0.853110, acc: 54.69%] [G loss: 5.614322]\n",
      "epoch:37 step:29238 [D loss: 0.816923, acc: 53.12%] [G loss: 8.557063]\n",
      "epoch:37 step:29239 [D loss: 0.246478, acc: 94.53%] [G loss: 3.432820]\n",
      "epoch:37 step:29240 [D loss: 0.303256, acc: 94.53%] [G loss: 7.110064]\n",
      "epoch:37 step:29241 [D loss: 0.170215, acc: 99.22%] [G loss: 5.857459]\n",
      "epoch:37 step:29242 [D loss: 0.409016, acc: 72.66%] [G loss: 8.672548]\n",
      "epoch:37 step:29243 [D loss: 0.185363, acc: 95.31%] [G loss: 5.360389]\n",
      "epoch:37 step:29244 [D loss: 0.175354, acc: 100.00%] [G loss: 5.247125]\n",
      "epoch:37 step:29245 [D loss: 0.022381, acc: 100.00%] [G loss: 4.488901]\n",
      "epoch:37 step:29246 [D loss: 0.433303, acc: 85.94%] [G loss: 3.154435]\n",
      "epoch:37 step:29247 [D loss: 0.356309, acc: 84.38%] [G loss: 9.819555]\n",
      "epoch:37 step:29248 [D loss: 0.233609, acc: 93.75%] [G loss: 4.273415]\n",
      "epoch:37 step:29249 [D loss: 0.352511, acc: 78.91%] [G loss: 9.936903]\n",
      "epoch:37 step:29250 [D loss: 0.841572, acc: 52.34%] [G loss: 4.103030]\n",
      "epoch:37 step:29251 [D loss: 1.745861, acc: 45.31%] [G loss: 4.123881]\n",
      "epoch:37 step:29252 [D loss: 0.092261, acc: 100.00%] [G loss: 4.983437]\n",
      "epoch:37 step:29253 [D loss: 0.677436, acc: 60.16%] [G loss: 6.729164]\n",
      "epoch:37 step:29254 [D loss: 0.140473, acc: 100.00%] [G loss: 5.290765]\n",
      "epoch:37 step:29255 [D loss: 0.789434, acc: 54.69%] [G loss: 7.559036]\n",
      "epoch:37 step:29256 [D loss: 0.523768, acc: 69.53%] [G loss: 4.522710]\n",
      "epoch:37 step:29257 [D loss: 0.242386, acc: 91.41%] [G loss: 4.885351]\n",
      "epoch:37 step:29258 [D loss: 0.210266, acc: 92.19%] [G loss: 3.878500]\n",
      "epoch:37 step:29259 [D loss: 0.207878, acc: 96.88%] [G loss: 6.003684]\n",
      "epoch:37 step:29260 [D loss: 0.606197, acc: 60.94%] [G loss: 10.312666]\n",
      "epoch:37 step:29261 [D loss: 0.308756, acc: 88.28%] [G loss: 4.681096]\n",
      "epoch:37 step:29262 [D loss: 0.306326, acc: 85.94%] [G loss: 5.912934]\n",
      "epoch:37 step:29263 [D loss: 0.111253, acc: 99.22%] [G loss: 2.285512]\n",
      "epoch:37 step:29264 [D loss: 0.095111, acc: 99.22%] [G loss: 4.885948]\n",
      "epoch:37 step:29265 [D loss: 0.557235, acc: 74.22%] [G loss: 5.391946]\n",
      "epoch:37 step:29266 [D loss: 1.274386, acc: 48.44%] [G loss: 6.267021]\n",
      "epoch:37 step:29267 [D loss: 0.211688, acc: 95.31%] [G loss: 5.358832]\n",
      "epoch:37 step:29268 [D loss: 0.213920, acc: 94.53%] [G loss: 3.051058]\n",
      "epoch:37 step:29269 [D loss: 0.224773, acc: 92.97%] [G loss: 4.897323]\n",
      "epoch:37 step:29270 [D loss: 0.169016, acc: 96.88%] [G loss: 5.500773]\n",
      "epoch:37 step:29271 [D loss: 0.456714, acc: 75.78%] [G loss: 5.178574]\n",
      "epoch:37 step:29272 [D loss: 0.172093, acc: 94.53%] [G loss: 5.304608]\n",
      "epoch:37 step:29273 [D loss: 0.065713, acc: 100.00%] [G loss: 9.206637]\n",
      "epoch:37 step:29274 [D loss: 0.489573, acc: 81.25%] [G loss: 7.065164]\n",
      "epoch:37 step:29275 [D loss: 1.180961, acc: 50.00%] [G loss: 5.177301]\n",
      "epoch:37 step:29276 [D loss: 0.218262, acc: 94.53%] [G loss: 5.240032]\n",
      "epoch:37 step:29277 [D loss: 1.151047, acc: 50.00%] [G loss: 6.596800]\n",
      "epoch:37 step:29278 [D loss: 1.480925, acc: 50.00%] [G loss: 5.080644]\n",
      "epoch:37 step:29279 [D loss: 0.587909, acc: 64.84%] [G loss: 5.229426]\n",
      "epoch:37 step:29280 [D loss: 0.116510, acc: 100.00%] [G loss: 5.819829]\n",
      "epoch:37 step:29281 [D loss: 0.400027, acc: 85.94%] [G loss: 7.068116]\n",
      "epoch:37 step:29282 [D loss: 0.162798, acc: 99.22%] [G loss: 2.359169]\n",
      "epoch:37 step:29283 [D loss: 0.087062, acc: 99.22%] [G loss: 4.776927]\n",
      "epoch:37 step:29284 [D loss: 0.550978, acc: 60.94%] [G loss: 5.211303]\n",
      "epoch:37 step:29285 [D loss: 0.818850, acc: 53.91%] [G loss: 5.712786]\n",
      "epoch:37 step:29286 [D loss: 0.251355, acc: 92.19%] [G loss: 5.128144]\n",
      "epoch:37 step:29287 [D loss: 0.017554, acc: 100.00%] [G loss: 4.707929]\n",
      "epoch:37 step:29288 [D loss: 0.393459, acc: 79.69%] [G loss: 6.613038]\n",
      "epoch:37 step:29289 [D loss: 0.146013, acc: 99.22%] [G loss: 4.285804]\n",
      "epoch:37 step:29290 [D loss: 0.403005, acc: 88.28%] [G loss: 5.118500]\n",
      "epoch:37 step:29291 [D loss: 0.057702, acc: 100.00%] [G loss: 7.414434]\n",
      "epoch:37 step:29292 [D loss: 0.181305, acc: 99.22%] [G loss: 5.554216]\n",
      "epoch:37 step:29293 [D loss: 0.134982, acc: 98.44%] [G loss: 5.755469]\n",
      "epoch:37 step:29294 [D loss: 0.226310, acc: 99.22%] [G loss: 5.400992]\n",
      "epoch:37 step:29295 [D loss: 0.603972, acc: 71.09%] [G loss: 5.477807]\n",
      "epoch:37 step:29296 [D loss: 0.042662, acc: 100.00%] [G loss: 5.501487]\n",
      "epoch:37 step:29297 [D loss: 0.184244, acc: 96.88%] [G loss: 7.776824]\n",
      "epoch:37 step:29298 [D loss: 0.679873, acc: 55.47%] [G loss: 7.348260]\n",
      "epoch:37 step:29299 [D loss: 0.129583, acc: 98.44%] [G loss: 3.827112]\n",
      "epoch:37 step:29300 [D loss: 0.180808, acc: 95.31%] [G loss: 6.677126]\n",
      "epoch:37 step:29301 [D loss: 0.769238, acc: 54.69%] [G loss: 7.332833]\n",
      "epoch:37 step:29302 [D loss: 0.049245, acc: 100.00%] [G loss: 4.862371]\n",
      "epoch:37 step:29303 [D loss: 0.959512, acc: 50.00%] [G loss: 3.390787]\n",
      "epoch:37 step:29304 [D loss: 0.033777, acc: 100.00%] [G loss: 3.668401]\n",
      "epoch:37 step:29305 [D loss: 0.253305, acc: 92.97%] [G loss: 3.638840]\n",
      "epoch:37 step:29306 [D loss: 1.904604, acc: 50.00%] [G loss: 9.299120]\n",
      "epoch:37 step:29307 [D loss: 0.220796, acc: 95.31%] [G loss: 5.843494]\n",
      "epoch:37 step:29308 [D loss: 0.061703, acc: 100.00%] [G loss: 6.817262]\n",
      "epoch:37 step:29309 [D loss: 0.776022, acc: 56.25%] [G loss: 3.728697]\n",
      "epoch:37 step:29310 [D loss: 0.498959, acc: 64.84%] [G loss: 7.115540]\n",
      "epoch:37 step:29311 [D loss: 0.326964, acc: 91.41%] [G loss: 3.220466]\n",
      "epoch:37 step:29312 [D loss: 0.110354, acc: 100.00%] [G loss: 2.787042]\n",
      "epoch:37 step:29313 [D loss: 0.244630, acc: 96.88%] [G loss: 6.553382]\n",
      "epoch:37 step:29314 [D loss: 0.322204, acc: 84.38%] [G loss: 6.327582]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:37 step:29315 [D loss: 0.153318, acc: 99.22%] [G loss: 6.646686]\n",
      "epoch:37 step:29316 [D loss: 0.121489, acc: 100.00%] [G loss: 2.967423]\n",
      "epoch:37 step:29317 [D loss: 1.182582, acc: 50.00%] [G loss: 6.354704]\n",
      "epoch:37 step:29318 [D loss: 0.432307, acc: 71.09%] [G loss: 1.912619]\n",
      "epoch:37 step:29319 [D loss: 0.129726, acc: 100.00%] [G loss: 6.483593]\n",
      "epoch:37 step:29320 [D loss: 0.536455, acc: 75.00%] [G loss: 4.272956]\n",
      "epoch:37 step:29321 [D loss: 0.098869, acc: 99.22%] [G loss: 2.130661]\n",
      "epoch:37 step:29322 [D loss: 0.288811, acc: 94.53%] [G loss: 7.881600]\n",
      "epoch:37 step:29323 [D loss: 0.387782, acc: 89.84%] [G loss: 6.081433]\n",
      "epoch:37 step:29324 [D loss: 1.146575, acc: 52.34%] [G loss: 5.826934]\n",
      "epoch:37 step:29325 [D loss: 0.149842, acc: 99.22%] [G loss: 3.354084]\n",
      "epoch:37 step:29326 [D loss: 0.173148, acc: 98.44%] [G loss: 4.475680]\n",
      "epoch:37 step:29327 [D loss: 0.242706, acc: 94.53%] [G loss: 5.517668]\n",
      "epoch:37 step:29328 [D loss: 0.061706, acc: 100.00%] [G loss: 5.183708]\n",
      "epoch:37 step:29329 [D loss: 0.120818, acc: 98.44%] [G loss: 3.000355]\n",
      "epoch:37 step:29330 [D loss: 0.287360, acc: 89.06%] [G loss: 5.096359]\n",
      "epoch:37 step:29331 [D loss: 0.110967, acc: 100.00%] [G loss: 4.745583]\n",
      "epoch:37 step:29332 [D loss: 0.111799, acc: 98.44%] [G loss: 6.479158]\n",
      "epoch:37 step:29333 [D loss: 0.706879, acc: 55.47%] [G loss: 8.631551]\n",
      "epoch:37 step:29334 [D loss: 0.526442, acc: 63.28%] [G loss: 3.865541]\n",
      "epoch:37 step:29335 [D loss: 0.166909, acc: 99.22%] [G loss: 3.473239]\n",
      "epoch:37 step:29336 [D loss: 0.665700, acc: 59.38%] [G loss: 5.288174]\n",
      "epoch:37 step:29337 [D loss: 0.212759, acc: 97.66%] [G loss: 6.018039]\n",
      "epoch:37 step:29338 [D loss: 0.396030, acc: 84.38%] [G loss: 3.660937]\n",
      "epoch:37 step:29339 [D loss: 0.018149, acc: 100.00%] [G loss: 6.329898]\n",
      "epoch:37 step:29340 [D loss: 0.362417, acc: 89.06%] [G loss: 3.339659]\n",
      "epoch:37 step:29341 [D loss: 0.090192, acc: 100.00%] [G loss: 8.073440]\n",
      "epoch:37 step:29342 [D loss: 0.322826, acc: 82.03%] [G loss: 8.164048]\n",
      "epoch:37 step:29343 [D loss: 0.060719, acc: 100.00%] [G loss: 6.410823]\n",
      "epoch:37 step:29344 [D loss: 0.168665, acc: 96.09%] [G loss: 4.337231]\n",
      "epoch:37 step:29345 [D loss: 0.557775, acc: 67.97%] [G loss: 6.195304]\n",
      "epoch:37 step:29346 [D loss: 0.210915, acc: 94.53%] [G loss: 5.819081]\n",
      "epoch:37 step:29347 [D loss: 0.716095, acc: 57.03%] [G loss: 7.138857]\n",
      "epoch:37 step:29348 [D loss: 0.105735, acc: 99.22%] [G loss: 4.327762]\n",
      "epoch:37 step:29349 [D loss: 0.176112, acc: 96.88%] [G loss: 4.552911]\n",
      "epoch:37 step:29350 [D loss: 0.099671, acc: 100.00%] [G loss: 5.744554]\n",
      "epoch:37 step:29351 [D loss: 0.076761, acc: 100.00%] [G loss: 4.400303]\n",
      "epoch:37 step:29352 [D loss: 0.139089, acc: 98.44%] [G loss: 5.643462]\n",
      "epoch:37 step:29353 [D loss: 0.692026, acc: 61.72%] [G loss: 8.211344]\n",
      "epoch:37 step:29354 [D loss: 0.501743, acc: 67.97%] [G loss: 2.239298]\n",
      "epoch:37 step:29355 [D loss: 0.422951, acc: 86.72%] [G loss: 6.382340]\n",
      "epoch:37 step:29356 [D loss: 0.426166, acc: 82.03%] [G loss: 4.841752]\n",
      "epoch:37 step:29357 [D loss: 0.992516, acc: 38.28%] [G loss: 8.241956]\n",
      "epoch:37 step:29358 [D loss: 0.023676, acc: 100.00%] [G loss: 6.847974]\n",
      "epoch:37 step:29359 [D loss: 0.393984, acc: 75.78%] [G loss: 9.673510]\n",
      "epoch:37 step:29360 [D loss: 0.215209, acc: 95.31%] [G loss: 7.098854]\n",
      "epoch:37 step:29361 [D loss: 0.178041, acc: 97.66%] [G loss: 3.782619]\n",
      "epoch:37 step:29362 [D loss: 0.312534, acc: 83.59%] [G loss: 6.106520]\n",
      "epoch:37 step:29363 [D loss: 0.001328, acc: 100.00%] [G loss: 8.587604]\n",
      "epoch:37 step:29364 [D loss: 0.725956, acc: 58.59%] [G loss: 6.703075]\n",
      "epoch:37 step:29365 [D loss: 0.073846, acc: 99.22%] [G loss: 2.149471]\n",
      "epoch:37 step:29366 [D loss: 0.492513, acc: 67.97%] [G loss: 7.599138]\n",
      "epoch:37 step:29367 [D loss: 1.109434, acc: 50.00%] [G loss: 14.719597]\n",
      "epoch:37 step:29368 [D loss: 0.127579, acc: 100.00%] [G loss: 5.621527]\n",
      "epoch:37 step:29369 [D loss: 0.264705, acc: 91.41%] [G loss: 2.779826]\n",
      "epoch:37 step:29370 [D loss: 0.485925, acc: 68.75%] [G loss: 5.735865]\n",
      "epoch:37 step:29371 [D loss: 0.282646, acc: 85.94%] [G loss: 5.909187]\n",
      "epoch:37 step:29372 [D loss: 0.127156, acc: 98.44%] [G loss: 4.869656]\n",
      "epoch:37 step:29373 [D loss: 0.378596, acc: 81.25%] [G loss: 5.299024]\n",
      "epoch:37 step:29374 [D loss: 0.132281, acc: 99.22%] [G loss: 5.889917]\n",
      "epoch:37 step:29375 [D loss: 0.341864, acc: 89.84%] [G loss: 6.174948]\n",
      "epoch:37 step:29376 [D loss: 0.756067, acc: 55.47%] [G loss: 4.638522]\n",
      "epoch:37 step:29377 [D loss: 0.417628, acc: 75.00%] [G loss: 6.328277]\n",
      "epoch:37 step:29378 [D loss: 0.188435, acc: 95.31%] [G loss: 3.525408]\n",
      "epoch:37 step:29379 [D loss: 0.173758, acc: 97.66%] [G loss: 7.099973]\n",
      "epoch:37 step:29380 [D loss: 0.404214, acc: 87.50%] [G loss: 6.542610]\n",
      "epoch:37 step:29381 [D loss: 0.061710, acc: 100.00%] [G loss: 6.857630]\n",
      "epoch:37 step:29382 [D loss: 0.594899, acc: 67.97%] [G loss: 6.238821]\n",
      "epoch:37 step:29383 [D loss: 0.062728, acc: 99.22%] [G loss: 4.136143]\n",
      "epoch:37 step:29384 [D loss: 0.270776, acc: 91.41%] [G loss: 4.916590]\n",
      "epoch:37 step:29385 [D loss: 0.180908, acc: 96.09%] [G loss: 7.059512]\n",
      "epoch:37 step:29386 [D loss: 0.121124, acc: 99.22%] [G loss: 5.046696]\n",
      "epoch:37 step:29387 [D loss: 0.027353, acc: 100.00%] [G loss: 7.351105]\n",
      "epoch:37 step:29388 [D loss: 0.357596, acc: 85.16%] [G loss: 2.838850]\n",
      "epoch:37 step:29389 [D loss: 0.082205, acc: 100.00%] [G loss: 9.242354]\n",
      "epoch:37 step:29390 [D loss: 0.043901, acc: 100.00%] [G loss: 8.197739]\n",
      "epoch:37 step:29391 [D loss: 0.253438, acc: 90.62%] [G loss: 5.568655]\n",
      "epoch:37 step:29392 [D loss: 0.037771, acc: 100.00%] [G loss: 7.452789]\n",
      "epoch:37 step:29393 [D loss: 0.524069, acc: 79.69%] [G loss: 6.900543]\n",
      "epoch:37 step:29394 [D loss: 0.131064, acc: 97.66%] [G loss: 6.764708]\n",
      "epoch:37 step:29395 [D loss: 0.518389, acc: 61.72%] [G loss: 5.552283]\n",
      "epoch:37 step:29396 [D loss: 0.286682, acc: 92.19%] [G loss: 3.607379]\n",
      "epoch:37 step:29397 [D loss: 0.115092, acc: 99.22%] [G loss: 6.531361]\n",
      "epoch:37 step:29398 [D loss: 0.055418, acc: 100.00%] [G loss: 6.416499]\n",
      "epoch:37 step:29399 [D loss: 0.326635, acc: 83.59%] [G loss: 5.789429]\n",
      "epoch:37 step:29400 [D loss: 0.288933, acc: 96.88%] [G loss: 5.645922]\n",
      "##############\n",
      "[0.8575826  0.86844216 0.80520129 0.8099792  0.78549153 0.83093553\n",
      " 0.88218667 0.846415   0.82315541 0.83808114]\n",
      "##########\n",
      "epoch:37 step:29401 [D loss: 0.782019, acc: 53.12%] [G loss: 4.889311]\n",
      "epoch:37 step:29402 [D loss: 0.132523, acc: 99.22%] [G loss: 2.631916]\n",
      "epoch:37 step:29403 [D loss: 0.062009, acc: 99.22%] [G loss: 5.714516]\n",
      "epoch:37 step:29404 [D loss: 0.331851, acc: 89.06%] [G loss: 4.237350]\n",
      "epoch:37 step:29405 [D loss: 0.261848, acc: 94.53%] [G loss: 4.765936]\n",
      "epoch:37 step:29406 [D loss: 0.235028, acc: 95.31%] [G loss: 4.187521]\n",
      "epoch:37 step:29407 [D loss: 0.271255, acc: 92.19%] [G loss: 4.305809]\n",
      "epoch:37 step:29408 [D loss: 0.018325, acc: 100.00%] [G loss: 8.078348]\n",
      "epoch:37 step:29409 [D loss: 0.012237, acc: 100.00%] [G loss: 10.291346]\n",
      "epoch:37 step:29410 [D loss: 0.578684, acc: 64.84%] [G loss: 4.830863]\n",
      "epoch:37 step:29411 [D loss: 0.474402, acc: 71.09%] [G loss: 3.308420]\n",
      "epoch:37 step:29412 [D loss: 0.481415, acc: 74.22%] [G loss: 3.452213]\n",
      "epoch:37 step:29413 [D loss: 0.450458, acc: 82.81%] [G loss: 2.308103]\n",
      "epoch:37 step:29414 [D loss: 0.035461, acc: 100.00%] [G loss: 6.647686]\n",
      "epoch:37 step:29415 [D loss: 0.298680, acc: 94.53%] [G loss: 6.520527]\n",
      "epoch:37 step:29416 [D loss: 0.458129, acc: 69.53%] [G loss: 7.062253]\n",
      "epoch:37 step:29417 [D loss: 0.599858, acc: 61.72%] [G loss: 5.094632]\n",
      "epoch:37 step:29418 [D loss: 0.312709, acc: 91.41%] [G loss: 5.176099]\n",
      "epoch:37 step:29419 [D loss: 1.713844, acc: 30.47%] [G loss: 5.356280]\n",
      "epoch:37 step:29420 [D loss: 0.363863, acc: 80.47%] [G loss: 3.427263]\n",
      "epoch:37 step:29421 [D loss: 1.283370, acc: 46.09%] [G loss: 4.012543]\n",
      "epoch:37 step:29422 [D loss: 0.487700, acc: 75.00%] [G loss: 2.608061]\n",
      "epoch:37 step:29423 [D loss: 0.805111, acc: 43.75%] [G loss: 4.410249]\n",
      "epoch:37 step:29424 [D loss: 0.251403, acc: 89.06%] [G loss: 7.262564]\n",
      "epoch:37 step:29425 [D loss: 0.219316, acc: 94.53%] [G loss: 6.452215]\n",
      "epoch:37 step:29426 [D loss: 0.105903, acc: 99.22%] [G loss: 4.649963]\n",
      "epoch:37 step:29427 [D loss: 0.466659, acc: 77.34%] [G loss: 8.217985]\n",
      "epoch:37 step:29428 [D loss: 0.214749, acc: 95.31%] [G loss: 4.705567]\n",
      "epoch:37 step:29429 [D loss: 0.387116, acc: 78.12%] [G loss: 7.354821]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:37 step:29430 [D loss: 0.030289, acc: 100.00%] [G loss: 3.292432]\n",
      "epoch:37 step:29431 [D loss: 0.381469, acc: 74.22%] [G loss: 4.324861]\n",
      "epoch:37 step:29432 [D loss: 0.805104, acc: 55.47%] [G loss: 5.700506]\n",
      "epoch:37 step:29433 [D loss: 0.238379, acc: 92.19%] [G loss: 8.573779]\n",
      "epoch:37 step:29434 [D loss: 0.140722, acc: 99.22%] [G loss: 5.611584]\n",
      "epoch:37 step:29435 [D loss: 0.304228, acc: 87.50%] [G loss: 5.383059]\n",
      "epoch:37 step:29436 [D loss: 0.230389, acc: 94.53%] [G loss: 4.413873]\n",
      "epoch:37 step:29437 [D loss: 0.295350, acc: 92.19%] [G loss: 5.538547]\n",
      "epoch:37 step:29438 [D loss: 0.190616, acc: 94.53%] [G loss: 3.916022]\n",
      "epoch:37 step:29439 [D loss: 0.616307, acc: 57.03%] [G loss: 2.389483]\n",
      "epoch:37 step:29440 [D loss: 0.076839, acc: 100.00%] [G loss: 3.973845]\n",
      "epoch:37 step:29441 [D loss: 0.431140, acc: 71.09%] [G loss: 6.830051]\n",
      "epoch:37 step:29442 [D loss: 0.724026, acc: 52.34%] [G loss: 6.757247]\n",
      "epoch:37 step:29443 [D loss: 1.081210, acc: 50.00%] [G loss: 5.676557]\n",
      "epoch:37 step:29444 [D loss: 0.168029, acc: 97.66%] [G loss: 3.669873]\n",
      "epoch:37 step:29445 [D loss: 0.473313, acc: 75.00%] [G loss: 4.342315]\n",
      "epoch:37 step:29446 [D loss: 0.190755, acc: 97.66%] [G loss: 6.950055]\n",
      "epoch:37 step:29447 [D loss: 0.132216, acc: 100.00%] [G loss: 7.005313]\n",
      "epoch:37 step:29448 [D loss: 0.398588, acc: 78.91%] [G loss: 2.330155]\n",
      "epoch:37 step:29449 [D loss: 0.887624, acc: 39.84%] [G loss: 4.619460]\n",
      "epoch:37 step:29450 [D loss: 0.651507, acc: 60.94%] [G loss: 4.312431]\n",
      "epoch:37 step:29451 [D loss: 0.661338, acc: 61.72%] [G loss: 4.067382]\n",
      "epoch:37 step:29452 [D loss: 0.179512, acc: 99.22%] [G loss: 6.333516]\n",
      "epoch:37 step:29453 [D loss: 0.899290, acc: 46.88%] [G loss: 8.541077]\n",
      "epoch:37 step:29454 [D loss: 0.287250, acc: 92.97%] [G loss: 4.978575]\n",
      "epoch:37 step:29455 [D loss: 0.326991, acc: 78.91%] [G loss: 5.999374]\n",
      "epoch:37 step:29456 [D loss: 0.264574, acc: 96.09%] [G loss: 5.853885]\n",
      "epoch:37 step:29457 [D loss: 0.093721, acc: 100.00%] [G loss: 5.641872]\n",
      "epoch:37 step:29458 [D loss: 0.167492, acc: 97.66%] [G loss: 6.206104]\n",
      "epoch:37 step:29459 [D loss: 0.507160, acc: 83.59%] [G loss: 6.458268]\n",
      "epoch:37 step:29460 [D loss: 0.165948, acc: 98.44%] [G loss: 4.868748]\n",
      "epoch:37 step:29461 [D loss: 0.189641, acc: 97.66%] [G loss: 6.040165]\n",
      "epoch:37 step:29462 [D loss: 0.110594, acc: 97.66%] [G loss: 7.162453]\n",
      "epoch:37 step:29463 [D loss: 0.221371, acc: 94.53%] [G loss: 5.712216]\n",
      "epoch:37 step:29464 [D loss: 1.164405, acc: 48.44%] [G loss: 2.576265]\n",
      "epoch:37 step:29465 [D loss: 0.513432, acc: 64.84%] [G loss: 5.263201]\n",
      "epoch:37 step:29466 [D loss: 0.206032, acc: 95.31%] [G loss: 4.327086]\n",
      "epoch:37 step:29467 [D loss: 0.251832, acc: 96.09%] [G loss: 4.170881]\n",
      "epoch:37 step:29468 [D loss: 0.073879, acc: 100.00%] [G loss: 5.912545]\n",
      "epoch:37 step:29469 [D loss: 0.247164, acc: 95.31%] [G loss: 5.298829]\n",
      "epoch:37 step:29470 [D loss: 0.063840, acc: 100.00%] [G loss: 7.072949]\n",
      "epoch:37 step:29471 [D loss: 0.103359, acc: 100.00%] [G loss: 5.528762]\n",
      "epoch:37 step:29472 [D loss: 0.759776, acc: 47.66%] [G loss: 3.452468]\n",
      "epoch:37 step:29473 [D loss: 0.212423, acc: 97.66%] [G loss: 4.326947]\n",
      "epoch:37 step:29474 [D loss: 0.131965, acc: 100.00%] [G loss: 4.674834]\n",
      "epoch:37 step:29475 [D loss: 0.032374, acc: 100.00%] [G loss: 7.919754]\n",
      "epoch:37 step:29476 [D loss: 0.034653, acc: 100.00%] [G loss: 3.896193]\n",
      "epoch:37 step:29477 [D loss: 0.043628, acc: 100.00%] [G loss: 3.266210]\n",
      "epoch:37 step:29478 [D loss: 0.973258, acc: 27.34%] [G loss: 8.503989]\n",
      "epoch:37 step:29479 [D loss: 0.543330, acc: 71.88%] [G loss: 9.178898]\n",
      "epoch:37 step:29480 [D loss: 1.076716, acc: 50.78%] [G loss: 7.000079]\n",
      "epoch:37 step:29481 [D loss: 0.136467, acc: 98.44%] [G loss: 4.280761]\n",
      "epoch:37 step:29482 [D loss: 0.012921, acc: 100.00%] [G loss: 7.809871]\n",
      "epoch:37 step:29483 [D loss: 0.106222, acc: 100.00%] [G loss: 6.584666]\n",
      "epoch:37 step:29484 [D loss: 0.694059, acc: 59.38%] [G loss: 5.615222]\n",
      "epoch:37 step:29485 [D loss: 0.170263, acc: 98.44%] [G loss: 4.352151]\n",
      "epoch:37 step:29486 [D loss: 0.090128, acc: 99.22%] [G loss: 7.850137]\n",
      "epoch:37 step:29487 [D loss: 0.122097, acc: 99.22%] [G loss: 8.433682]\n",
      "epoch:37 step:29488 [D loss: 0.116340, acc: 97.66%] [G loss: 4.802696]\n",
      "epoch:37 step:29489 [D loss: 0.091246, acc: 100.00%] [G loss: 4.880374]\n",
      "epoch:37 step:29490 [D loss: 0.526660, acc: 77.34%] [G loss: 5.164616]\n",
      "epoch:37 step:29491 [D loss: 0.112776, acc: 100.00%] [G loss: 4.028409]\n",
      "epoch:37 step:29492 [D loss: 0.100291, acc: 99.22%] [G loss: 4.949225]\n",
      "epoch:37 step:29493 [D loss: 0.090321, acc: 96.88%] [G loss: 7.459156]\n",
      "epoch:37 step:29494 [D loss: 0.132216, acc: 99.22%] [G loss: 7.243566]\n",
      "epoch:37 step:29495 [D loss: 0.006551, acc: 100.00%] [G loss: 7.004430]\n",
      "epoch:37 step:29496 [D loss: 0.529707, acc: 72.66%] [G loss: 3.690853]\n",
      "epoch:37 step:29497 [D loss: 0.574685, acc: 65.62%] [G loss: 3.892142]\n",
      "epoch:37 step:29498 [D loss: 0.189400, acc: 97.66%] [G loss: 3.108544]\n",
      "epoch:37 step:29499 [D loss: 0.890665, acc: 43.75%] [G loss: 7.530619]\n",
      "epoch:37 step:29500 [D loss: 0.495277, acc: 66.41%] [G loss: 7.078481]\n",
      "epoch:37 step:29501 [D loss: 0.857854, acc: 54.69%] [G loss: 7.709181]\n",
      "epoch:37 step:29502 [D loss: 0.161616, acc: 98.44%] [G loss: 4.313550]\n",
      "epoch:37 step:29503 [D loss: 0.530803, acc: 60.94%] [G loss: 5.012873]\n",
      "epoch:37 step:29504 [D loss: 0.185122, acc: 96.09%] [G loss: 3.705942]\n",
      "epoch:37 step:29505 [D loss: 0.288086, acc: 93.75%] [G loss: 3.097135]\n",
      "epoch:37 step:29506 [D loss: 0.061456, acc: 100.00%] [G loss: 4.072093]\n",
      "epoch:37 step:29507 [D loss: 0.232847, acc: 92.19%] [G loss: 3.181960]\n",
      "epoch:37 step:29508 [D loss: 0.274172, acc: 89.84%] [G loss: 4.191834]\n",
      "epoch:37 step:29509 [D loss: 0.461687, acc: 68.75%] [G loss: 5.667102]\n",
      "epoch:37 step:29510 [D loss: 0.110797, acc: 99.22%] [G loss: 4.047400]\n",
      "epoch:37 step:29511 [D loss: 0.446183, acc: 68.75%] [G loss: 6.988457]\n",
      "epoch:37 step:29512 [D loss: 0.603209, acc: 67.19%] [G loss: 4.902249]\n",
      "epoch:37 step:29513 [D loss: 0.374270, acc: 75.78%] [G loss: 4.795636]\n",
      "epoch:37 step:29514 [D loss: 0.547952, acc: 62.50%] [G loss: 7.923171]\n",
      "epoch:37 step:29515 [D loss: 0.345556, acc: 86.72%] [G loss: 3.254403]\n",
      "epoch:37 step:29516 [D loss: 0.380635, acc: 80.47%] [G loss: 4.027698]\n",
      "epoch:37 step:29517 [D loss: 0.805467, acc: 57.03%] [G loss: 4.369408]\n",
      "epoch:37 step:29518 [D loss: 0.212443, acc: 97.66%] [G loss: 6.340171]\n",
      "epoch:37 step:29519 [D loss: 0.705204, acc: 58.59%] [G loss: 4.969532]\n",
      "epoch:37 step:29520 [D loss: 0.203012, acc: 92.97%] [G loss: 2.487353]\n",
      "epoch:37 step:29521 [D loss: 0.082212, acc: 100.00%] [G loss: 4.817883]\n",
      "epoch:37 step:29522 [D loss: 0.462928, acc: 69.53%] [G loss: 7.875272]\n",
      "epoch:37 step:29523 [D loss: 0.344721, acc: 84.38%] [G loss: 4.416703]\n",
      "epoch:37 step:29524 [D loss: 0.239399, acc: 96.09%] [G loss: 4.763605]\n",
      "epoch:37 step:29525 [D loss: 0.611480, acc: 59.38%] [G loss: 6.935519]\n",
      "epoch:37 step:29526 [D loss: 0.614020, acc: 64.84%] [G loss: 6.447588]\n",
      "epoch:37 step:29527 [D loss: 0.161918, acc: 100.00%] [G loss: 4.242534]\n",
      "epoch:37 step:29528 [D loss: 0.208310, acc: 95.31%] [G loss: 5.941751]\n",
      "epoch:37 step:29529 [D loss: 0.307414, acc: 90.62%] [G loss: 5.441675]\n",
      "epoch:37 step:29530 [D loss: 1.364051, acc: 14.06%] [G loss: 5.615197]\n",
      "epoch:37 step:29531 [D loss: 0.256654, acc: 93.75%] [G loss: 5.221290]\n",
      "epoch:37 step:29532 [D loss: 0.164146, acc: 100.00%] [G loss: 5.715226]\n",
      "epoch:37 step:29533 [D loss: 0.415714, acc: 80.47%] [G loss: 4.889681]\n",
      "epoch:37 step:29534 [D loss: 0.083756, acc: 100.00%] [G loss: 5.482246]\n",
      "epoch:37 step:29535 [D loss: 0.028618, acc: 100.00%] [G loss: 11.543620]\n",
      "epoch:37 step:29536 [D loss: 0.547487, acc: 78.12%] [G loss: 6.566627]\n",
      "epoch:37 step:29537 [D loss: 0.146300, acc: 99.22%] [G loss: 6.404634]\n",
      "epoch:37 step:29538 [D loss: 0.060532, acc: 100.00%] [G loss: 7.857231]\n",
      "epoch:37 step:29539 [D loss: 0.029604, acc: 100.00%] [G loss: 4.115142]\n",
      "epoch:37 step:29540 [D loss: 0.491607, acc: 82.03%] [G loss: 5.657189]\n",
      "epoch:37 step:29541 [D loss: 0.285114, acc: 95.31%] [G loss: 5.910779]\n",
      "epoch:37 step:29542 [D loss: 0.219597, acc: 96.09%] [G loss: 1.584340]\n",
      "epoch:37 step:29543 [D loss: 0.341607, acc: 92.19%] [G loss: 5.537529]\n",
      "epoch:37 step:29544 [D loss: 0.143300, acc: 97.66%] [G loss: 2.076888]\n",
      "epoch:37 step:29545 [D loss: 0.763102, acc: 54.69%] [G loss: 5.882042]\n",
      "epoch:37 step:29546 [D loss: 0.272963, acc: 98.44%] [G loss: 6.586780]\n",
      "epoch:37 step:29547 [D loss: 0.130901, acc: 98.44%] [G loss: 3.350703]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:37 step:29548 [D loss: 0.273745, acc: 91.41%] [G loss: 4.156186]\n",
      "epoch:37 step:29549 [D loss: 0.079847, acc: 100.00%] [G loss: 4.581519]\n",
      "epoch:37 step:29550 [D loss: 0.057785, acc: 100.00%] [G loss: 3.599396]\n",
      "epoch:37 step:29551 [D loss: 0.087080, acc: 99.22%] [G loss: 4.355026]\n",
      "epoch:37 step:29552 [D loss: 0.022714, acc: 100.00%] [G loss: 9.471249]\n",
      "epoch:37 step:29553 [D loss: 0.614988, acc: 57.81%] [G loss: 7.907572]\n",
      "epoch:37 step:29554 [D loss: 0.606852, acc: 64.84%] [G loss: 4.456823]\n",
      "epoch:37 step:29555 [D loss: 0.398123, acc: 83.59%] [G loss: 5.607455]\n",
      "epoch:37 step:29556 [D loss: 0.054596, acc: 100.00%] [G loss: 8.650419]\n",
      "epoch:37 step:29557 [D loss: 0.029527, acc: 100.00%] [G loss: 5.194919]\n",
      "epoch:37 step:29558 [D loss: 0.253188, acc: 90.62%] [G loss: 5.405220]\n",
      "epoch:37 step:29559 [D loss: 0.363686, acc: 78.12%] [G loss: 7.801744]\n",
      "epoch:37 step:29560 [D loss: 0.085186, acc: 100.00%] [G loss: 8.288109]\n",
      "epoch:37 step:29561 [D loss: 0.345354, acc: 89.84%] [G loss: 6.007336]\n",
      "epoch:37 step:29562 [D loss: 0.679448, acc: 62.50%] [G loss: 6.400408]\n",
      "epoch:37 step:29563 [D loss: 0.321878, acc: 82.81%] [G loss: 2.197327]\n",
      "epoch:37 step:29564 [D loss: 0.204902, acc: 94.53%] [G loss: 6.919281]\n",
      "epoch:37 step:29565 [D loss: 0.061819, acc: 100.00%] [G loss: 2.701725]\n",
      "epoch:37 step:29566 [D loss: 0.209987, acc: 96.09%] [G loss: 6.528976]\n",
      "epoch:37 step:29567 [D loss: 0.699070, acc: 55.47%] [G loss: 7.951013]\n",
      "epoch:37 step:29568 [D loss: 0.514833, acc: 71.88%] [G loss: 6.947058]\n",
      "epoch:37 step:29569 [D loss: 0.387599, acc: 81.25%] [G loss: 5.414652]\n",
      "epoch:37 step:29570 [D loss: 0.055224, acc: 100.00%] [G loss: 6.984973]\n",
      "epoch:37 step:29571 [D loss: 0.027344, acc: 100.00%] [G loss: 3.719067]\n",
      "epoch:37 step:29572 [D loss: 0.118621, acc: 96.88%] [G loss: 6.132967]\n",
      "epoch:37 step:29573 [D loss: 0.329851, acc: 94.53%] [G loss: 8.750705]\n",
      "epoch:37 step:29574 [D loss: 0.156596, acc: 99.22%] [G loss: 3.665071]\n",
      "epoch:37 step:29575 [D loss: 0.356085, acc: 91.41%] [G loss: 6.540422]\n",
      "epoch:37 step:29576 [D loss: 0.039438, acc: 99.22%] [G loss: 6.840925]\n",
      "epoch:37 step:29577 [D loss: 0.231646, acc: 97.66%] [G loss: 5.210777]\n",
      "epoch:37 step:29578 [D loss: 0.137298, acc: 97.66%] [G loss: 3.769495]\n",
      "epoch:37 step:29579 [D loss: 0.223154, acc: 95.31%] [G loss: 7.230939]\n",
      "epoch:37 step:29580 [D loss: 0.164143, acc: 99.22%] [G loss: 6.167676]\n",
      "epoch:37 step:29581 [D loss: 0.423847, acc: 77.34%] [G loss: 1.827049]\n",
      "epoch:37 step:29582 [D loss: 0.539850, acc: 64.06%] [G loss: 5.438009]\n",
      "epoch:37 step:29583 [D loss: 0.154044, acc: 100.00%] [G loss: 4.394337]\n",
      "epoch:37 step:29584 [D loss: 0.099961, acc: 99.22%] [G loss: 6.729095]\n",
      "epoch:37 step:29585 [D loss: 0.088595, acc: 99.22%] [G loss: 7.411488]\n",
      "epoch:37 step:29586 [D loss: 0.471422, acc: 67.19%] [G loss: 5.399539]\n",
      "epoch:37 step:29587 [D loss: 0.017378, acc: 100.00%] [G loss: 6.552021]\n",
      "epoch:37 step:29588 [D loss: 0.216252, acc: 90.62%] [G loss: 8.542256]\n",
      "epoch:37 step:29589 [D loss: 0.504093, acc: 75.00%] [G loss: 4.973676]\n",
      "epoch:37 step:29590 [D loss: 0.074112, acc: 99.22%] [G loss: 3.553472]\n",
      "epoch:37 step:29591 [D loss: 0.638743, acc: 62.50%] [G loss: 7.560256]\n",
      "epoch:37 step:29592 [D loss: 0.783567, acc: 49.22%] [G loss: 4.949265]\n",
      "epoch:37 step:29593 [D loss: 0.225946, acc: 96.09%] [G loss: 4.506483]\n",
      "epoch:37 step:29594 [D loss: 0.765669, acc: 55.47%] [G loss: 8.080730]\n",
      "epoch:37 step:29595 [D loss: 0.036638, acc: 100.00%] [G loss: 5.774882]\n",
      "epoch:37 step:29596 [D loss: 0.153517, acc: 99.22%] [G loss: 5.697886]\n",
      "epoch:37 step:29597 [D loss: 0.086740, acc: 99.22%] [G loss: 6.140629]\n",
      "epoch:37 step:29598 [D loss: 0.768440, acc: 53.91%] [G loss: 4.869678]\n",
      "epoch:37 step:29599 [D loss: 0.154806, acc: 96.88%] [G loss: 4.901585]\n",
      "epoch:37 step:29600 [D loss: 0.498401, acc: 71.09%] [G loss: 3.109111]\n",
      "##############\n",
      "[0.85344632 0.86676797 0.81556027 0.80105352 0.77541949 0.82533817\n",
      " 0.88478227 0.81363152 0.81674591 0.82563146]\n",
      "##########\n",
      "epoch:37 step:29601 [D loss: 0.035571, acc: 100.00%] [G loss: 4.006697]\n",
      "epoch:37 step:29602 [D loss: 0.923331, acc: 52.34%] [G loss: 4.530161]\n",
      "epoch:37 step:29603 [D loss: 0.748266, acc: 55.47%] [G loss: 8.478750]\n",
      "epoch:37 step:29604 [D loss: 0.714197, acc: 51.56%] [G loss: 7.333065]\n",
      "epoch:37 step:29605 [D loss: 0.050921, acc: 100.00%] [G loss: 4.442455]\n",
      "epoch:37 step:29606 [D loss: 0.374883, acc: 83.59%] [G loss: 5.292480]\n",
      "epoch:37 step:29607 [D loss: 0.761046, acc: 56.25%] [G loss: 4.317811]\n",
      "epoch:37 step:29608 [D loss: 0.035369, acc: 100.00%] [G loss: 8.294796]\n",
      "epoch:37 step:29609 [D loss: 0.077943, acc: 100.00%] [G loss: 5.704765]\n",
      "epoch:37 step:29610 [D loss: 0.169932, acc: 99.22%] [G loss: 4.966689]\n",
      "epoch:37 step:29611 [D loss: 0.207522, acc: 96.09%] [G loss: 3.318717]\n",
      "epoch:37 step:29612 [D loss: 0.260594, acc: 93.75%] [G loss: 4.237452]\n",
      "epoch:37 step:29613 [D loss: 1.115969, acc: 36.72%] [G loss: 9.864382]\n",
      "epoch:37 step:29614 [D loss: 0.227375, acc: 96.88%] [G loss: 4.911843]\n",
      "epoch:37 step:29615 [D loss: 0.302661, acc: 92.97%] [G loss: 6.702025]\n",
      "epoch:37 step:29616 [D loss: 0.492395, acc: 77.34%] [G loss: 7.041465]\n",
      "epoch:37 step:29617 [D loss: 0.118235, acc: 100.00%] [G loss: 3.335959]\n",
      "epoch:37 step:29618 [D loss: 0.356292, acc: 82.03%] [G loss: 6.736243]\n",
      "epoch:37 step:29619 [D loss: 0.747019, acc: 48.44%] [G loss: 4.048091]\n",
      "epoch:37 step:29620 [D loss: 0.023396, acc: 100.00%] [G loss: 7.953296]\n",
      "epoch:37 step:29621 [D loss: 1.317698, acc: 46.09%] [G loss: 6.770181]\n",
      "epoch:37 step:29622 [D loss: 0.040455, acc: 100.00%] [G loss: 4.659636]\n",
      "epoch:37 step:29623 [D loss: 0.196698, acc: 93.75%] [G loss: 4.568675]\n",
      "epoch:37 step:29624 [D loss: 0.326633, acc: 92.97%] [G loss: 6.377188]\n",
      "epoch:37 step:29625 [D loss: 0.358540, acc: 88.28%] [G loss: 4.404199]\n",
      "epoch:37 step:29626 [D loss: 0.407862, acc: 86.72%] [G loss: 5.736890]\n",
      "epoch:37 step:29627 [D loss: 0.143412, acc: 98.44%] [G loss: 6.389059]\n",
      "epoch:37 step:29628 [D loss: 0.796528, acc: 46.88%] [G loss: 5.153157]\n",
      "epoch:37 step:29629 [D loss: 0.320289, acc: 85.16%] [G loss: 7.314519]\n",
      "epoch:37 step:29630 [D loss: 0.721365, acc: 57.03%] [G loss: 5.818221]\n",
      "epoch:37 step:29631 [D loss: 0.186708, acc: 97.66%] [G loss: 3.842142]\n",
      "epoch:37 step:29632 [D loss: 0.095776, acc: 100.00%] [G loss: 7.079646]\n",
      "epoch:37 step:29633 [D loss: 0.271181, acc: 85.94%] [G loss: 3.223158]\n",
      "epoch:37 step:29634 [D loss: 0.147835, acc: 99.22%] [G loss: 8.120625]\n",
      "epoch:37 step:29635 [D loss: 0.254061, acc: 92.97%] [G loss: 5.080497]\n",
      "epoch:37 step:29636 [D loss: 0.258213, acc: 90.62%] [G loss: 3.109439]\n",
      "epoch:37 step:29637 [D loss: 0.439636, acc: 76.56%] [G loss: 6.547259]\n",
      "epoch:37 step:29638 [D loss: 0.077610, acc: 100.00%] [G loss: 3.112025]\n",
      "epoch:37 step:29639 [D loss: 0.050731, acc: 100.00%] [G loss: 5.567822]\n",
      "epoch:37 step:29640 [D loss: 0.444396, acc: 83.59%] [G loss: 3.412203]\n",
      "epoch:37 step:29641 [D loss: 0.149462, acc: 98.44%] [G loss: 3.633878]\n",
      "epoch:37 step:29642 [D loss: 0.132025, acc: 100.00%] [G loss: 4.717004]\n",
      "epoch:37 step:29643 [D loss: 0.334727, acc: 92.97%] [G loss: 5.553253]\n",
      "epoch:37 step:29644 [D loss: 0.163259, acc: 99.22%] [G loss: 6.152870]\n",
      "epoch:37 step:29645 [D loss: 0.042201, acc: 100.00%] [G loss: 2.718007]\n",
      "epoch:37 step:29646 [D loss: 0.057667, acc: 100.00%] [G loss: 5.780001]\n",
      "epoch:37 step:29647 [D loss: 0.296380, acc: 92.97%] [G loss: 4.531794]\n",
      "epoch:37 step:29648 [D loss: 0.143496, acc: 97.66%] [G loss: 6.477201]\n",
      "epoch:37 step:29649 [D loss: 0.229404, acc: 99.22%] [G loss: 5.031140]\n",
      "epoch:37 step:29650 [D loss: 0.429744, acc: 80.47%] [G loss: 6.276903]\n",
      "epoch:37 step:29651 [D loss: 0.162872, acc: 96.09%] [G loss: 4.783847]\n",
      "epoch:37 step:29652 [D loss: 0.495260, acc: 71.88%] [G loss: 5.289918]\n",
      "epoch:37 step:29653 [D loss: 0.316554, acc: 85.94%] [G loss: 4.010900]\n",
      "epoch:37 step:29654 [D loss: 0.332128, acc: 89.06%] [G loss: 5.180860]\n",
      "epoch:37 step:29655 [D loss: 0.476665, acc: 76.56%] [G loss: 5.446072]\n",
      "epoch:37 step:29656 [D loss: 0.522909, acc: 64.06%] [G loss: 4.124592]\n",
      "epoch:37 step:29657 [D loss: 0.903717, acc: 52.34%] [G loss: 7.905554]\n",
      "epoch:37 step:29658 [D loss: 0.135823, acc: 98.44%] [G loss: 5.496904]\n",
      "epoch:37 step:29659 [D loss: 0.078983, acc: 100.00%] [G loss: 6.278642]\n",
      "epoch:37 step:29660 [D loss: 0.256952, acc: 89.84%] [G loss: 5.384065]\n",
      "epoch:37 step:29661 [D loss: 0.142437, acc: 100.00%] [G loss: 6.794907]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:37 step:29662 [D loss: 0.020790, acc: 100.00%] [G loss: 3.471820]\n",
      "epoch:37 step:29663 [D loss: 0.262707, acc: 95.31%] [G loss: 3.151883]\n",
      "epoch:37 step:29664 [D loss: 0.006321, acc: 100.00%] [G loss: 5.358445]\n",
      "epoch:37 step:29665 [D loss: 0.174994, acc: 98.44%] [G loss: 4.931287]\n",
      "epoch:37 step:29666 [D loss: 0.489290, acc: 71.09%] [G loss: 4.496211]\n",
      "epoch:37 step:29667 [D loss: 0.512911, acc: 73.44%] [G loss: 8.831786]\n",
      "epoch:37 step:29668 [D loss: 0.152020, acc: 98.44%] [G loss: 4.934184]\n",
      "epoch:37 step:29669 [D loss: 0.692648, acc: 55.47%] [G loss: 5.365174]\n",
      "epoch:37 step:29670 [D loss: 0.041573, acc: 100.00%] [G loss: 9.780371]\n",
      "epoch:37 step:29671 [D loss: 0.535016, acc: 71.09%] [G loss: 6.632915]\n",
      "epoch:37 step:29672 [D loss: 0.540761, acc: 67.97%] [G loss: 7.237107]\n",
      "epoch:37 step:29673 [D loss: 0.432726, acc: 82.81%] [G loss: 4.193574]\n",
      "epoch:37 step:29674 [D loss: 0.895794, acc: 53.12%] [G loss: 5.063967]\n",
      "epoch:37 step:29675 [D loss: 0.870979, acc: 48.44%] [G loss: 9.119042]\n",
      "epoch:37 step:29676 [D loss: 0.193438, acc: 96.88%] [G loss: 5.241718]\n",
      "epoch:37 step:29677 [D loss: 0.526806, acc: 65.62%] [G loss: 5.643153]\n",
      "epoch:37 step:29678 [D loss: 0.139718, acc: 98.44%] [G loss: 4.769160]\n",
      "epoch:38 step:29679 [D loss: 0.385056, acc: 88.28%] [G loss: 6.811853]\n",
      "epoch:38 step:29680 [D loss: 0.025735, acc: 100.00%] [G loss: 5.822583]\n",
      "epoch:38 step:29681 [D loss: 1.208956, acc: 50.78%] [G loss: 1.533935]\n",
      "epoch:38 step:29682 [D loss: 0.409295, acc: 69.53%] [G loss: 6.634655]\n",
      "epoch:38 step:29683 [D loss: 0.188074, acc: 97.66%] [G loss: 6.496495]\n",
      "epoch:38 step:29684 [D loss: 0.254117, acc: 89.06%] [G loss: 3.682787]\n",
      "epoch:38 step:29685 [D loss: 1.063896, acc: 51.56%] [G loss: 6.324847]\n",
      "epoch:38 step:29686 [D loss: 0.058111, acc: 100.00%] [G loss: 4.703242]\n",
      "epoch:38 step:29687 [D loss: 0.272557, acc: 91.41%] [G loss: 9.975023]\n",
      "epoch:38 step:29688 [D loss: 0.309788, acc: 88.28%] [G loss: 5.839785]\n",
      "epoch:38 step:29689 [D loss: 0.146127, acc: 98.44%] [G loss: 5.820402]\n",
      "epoch:38 step:29690 [D loss: 0.102272, acc: 100.00%] [G loss: 5.658338]\n",
      "epoch:38 step:29691 [D loss: 0.115802, acc: 99.22%] [G loss: 7.212663]\n",
      "epoch:38 step:29692 [D loss: 0.468043, acc: 67.97%] [G loss: 5.194977]\n",
      "epoch:38 step:29693 [D loss: 1.597366, acc: 36.72%] [G loss: 4.667621]\n",
      "epoch:38 step:29694 [D loss: 0.292352, acc: 90.62%] [G loss: 6.343139]\n",
      "epoch:38 step:29695 [D loss: 0.418140, acc: 72.66%] [G loss: 4.043420]\n",
      "epoch:38 step:29696 [D loss: 0.084670, acc: 100.00%] [G loss: 3.926845]\n",
      "epoch:38 step:29697 [D loss: 0.248392, acc: 93.75%] [G loss: 4.977795]\n",
      "epoch:38 step:29698 [D loss: 0.672238, acc: 60.16%] [G loss: 5.000079]\n",
      "epoch:38 step:29699 [D loss: 0.255177, acc: 92.19%] [G loss: 4.158560]\n",
      "epoch:38 step:29700 [D loss: 0.068589, acc: 100.00%] [G loss: 5.178026]\n",
      "epoch:38 step:29701 [D loss: 0.609134, acc: 64.84%] [G loss: 5.269753]\n",
      "epoch:38 step:29702 [D loss: 0.589024, acc: 61.72%] [G loss: 6.805914]\n",
      "epoch:38 step:29703 [D loss: 0.344185, acc: 86.72%] [G loss: 4.622275]\n",
      "epoch:38 step:29704 [D loss: 0.354871, acc: 78.91%] [G loss: 4.290177]\n",
      "epoch:38 step:29705 [D loss: 0.432994, acc: 82.81%] [G loss: 4.466217]\n",
      "epoch:38 step:29706 [D loss: 0.661466, acc: 59.38%] [G loss: 7.932148]\n",
      "epoch:38 step:29707 [D loss: 0.061093, acc: 100.00%] [G loss: 4.184190]\n",
      "epoch:38 step:29708 [D loss: 0.252792, acc: 89.06%] [G loss: 5.660338]\n",
      "epoch:38 step:29709 [D loss: 0.081960, acc: 100.00%] [G loss: 4.653086]\n",
      "epoch:38 step:29710 [D loss: 0.872689, acc: 49.22%] [G loss: 2.731525]\n",
      "epoch:38 step:29711 [D loss: 0.698431, acc: 65.62%] [G loss: 6.616066]\n",
      "epoch:38 step:29712 [D loss: 0.211534, acc: 92.97%] [G loss: 5.143236]\n",
      "epoch:38 step:29713 [D loss: 0.462452, acc: 74.22%] [G loss: 9.232709]\n",
      "epoch:38 step:29714 [D loss: 0.513528, acc: 67.97%] [G loss: 7.025105]\n",
      "epoch:38 step:29715 [D loss: 0.039573, acc: 100.00%] [G loss: 6.063170]\n",
      "epoch:38 step:29716 [D loss: 0.046652, acc: 100.00%] [G loss: 5.042449]\n",
      "epoch:38 step:29717 [D loss: 0.307514, acc: 87.50%] [G loss: 2.609118]\n",
      "epoch:38 step:29718 [D loss: 0.365033, acc: 81.25%] [G loss: 8.566966]\n",
      "epoch:38 step:29719 [D loss: 0.509445, acc: 74.22%] [G loss: 6.660614]\n",
      "epoch:38 step:29720 [D loss: 0.575602, acc: 69.53%] [G loss: 5.341309]\n",
      "epoch:38 step:29721 [D loss: 0.240380, acc: 92.19%] [G loss: 8.216700]\n",
      "epoch:38 step:29722 [D loss: 0.404066, acc: 80.47%] [G loss: 2.257972]\n",
      "epoch:38 step:29723 [D loss: 0.065256, acc: 100.00%] [G loss: 9.845114]\n",
      "epoch:38 step:29724 [D loss: 0.320701, acc: 82.81%] [G loss: 5.663853]\n",
      "epoch:38 step:29725 [D loss: 0.115268, acc: 99.22%] [G loss: 3.969945]\n",
      "epoch:38 step:29726 [D loss: 0.126847, acc: 99.22%] [G loss: 3.651033]\n",
      "epoch:38 step:29727 [D loss: 0.260255, acc: 95.31%] [G loss: 6.171141]\n",
      "epoch:38 step:29728 [D loss: 0.078282, acc: 100.00%] [G loss: 3.005762]\n",
      "epoch:38 step:29729 [D loss: 0.362401, acc: 82.81%] [G loss: 6.767551]\n",
      "epoch:38 step:29730 [D loss: 0.204195, acc: 96.88%] [G loss: 5.477459]\n",
      "epoch:38 step:29731 [D loss: 0.246005, acc: 89.84%] [G loss: 3.340133]\n",
      "epoch:38 step:29732 [D loss: 1.016366, acc: 50.78%] [G loss: 6.667735]\n",
      "epoch:38 step:29733 [D loss: 0.232873, acc: 95.31%] [G loss: 6.177759]\n",
      "epoch:38 step:29734 [D loss: 0.147306, acc: 99.22%] [G loss: 7.739924]\n",
      "epoch:38 step:29735 [D loss: 0.473790, acc: 75.00%] [G loss: 4.621995]\n",
      "epoch:38 step:29736 [D loss: 0.407373, acc: 74.22%] [G loss: 8.192348]\n",
      "epoch:38 step:29737 [D loss: 0.780316, acc: 52.34%] [G loss: 5.294661]\n",
      "epoch:38 step:29738 [D loss: 0.395076, acc: 85.94%] [G loss: 6.587014]\n",
      "epoch:38 step:29739 [D loss: 0.818413, acc: 53.91%] [G loss: 2.657697]\n",
      "epoch:38 step:29740 [D loss: 0.058407, acc: 100.00%] [G loss: 6.888107]\n",
      "epoch:38 step:29741 [D loss: 0.253611, acc: 89.84%] [G loss: 8.614136]\n",
      "epoch:38 step:29742 [D loss: 0.181094, acc: 98.44%] [G loss: 6.298563]\n",
      "epoch:38 step:29743 [D loss: 0.497404, acc: 69.53%] [G loss: 3.777180]\n",
      "epoch:38 step:29744 [D loss: 0.079651, acc: 100.00%] [G loss: 4.191334]\n",
      "epoch:38 step:29745 [D loss: 1.320694, acc: 16.41%] [G loss: 9.004729]\n",
      "epoch:38 step:29746 [D loss: 1.137106, acc: 49.22%] [G loss: 6.378316]\n",
      "epoch:38 step:29747 [D loss: 0.139397, acc: 97.66%] [G loss: 6.173279]\n",
      "epoch:38 step:29748 [D loss: 0.477826, acc: 78.12%] [G loss: 3.736179]\n",
      "epoch:38 step:29749 [D loss: 0.180501, acc: 96.88%] [G loss: 2.547381]\n",
      "epoch:38 step:29750 [D loss: 0.029929, acc: 100.00%] [G loss: 4.408940]\n",
      "epoch:38 step:29751 [D loss: 0.176761, acc: 96.88%] [G loss: 5.718150]\n",
      "epoch:38 step:29752 [D loss: 0.301667, acc: 91.41%] [G loss: 7.770371]\n",
      "epoch:38 step:29753 [D loss: 0.094434, acc: 99.22%] [G loss: 5.035534]\n",
      "epoch:38 step:29754 [D loss: 0.628439, acc: 63.28%] [G loss: 7.306166]\n",
      "epoch:38 step:29755 [D loss: 0.699898, acc: 57.81%] [G loss: 5.649786]\n",
      "epoch:38 step:29756 [D loss: 0.491221, acc: 74.22%] [G loss: 5.529364]\n",
      "epoch:38 step:29757 [D loss: 0.145958, acc: 97.66%] [G loss: 5.462309]\n",
      "epoch:38 step:29758 [D loss: 0.269063, acc: 96.88%] [G loss: 4.023959]\n",
      "epoch:38 step:29759 [D loss: 0.169307, acc: 98.44%] [G loss: 3.601702]\n",
      "epoch:38 step:29760 [D loss: 0.264188, acc: 85.94%] [G loss: 8.048503]\n",
      "epoch:38 step:29761 [D loss: 0.052470, acc: 100.00%] [G loss: 4.739266]\n",
      "epoch:38 step:29762 [D loss: 0.929826, acc: 39.06%] [G loss: 5.651031]\n",
      "epoch:38 step:29763 [D loss: 0.050724, acc: 99.22%] [G loss: 7.015145]\n",
      "epoch:38 step:29764 [D loss: 0.219814, acc: 97.66%] [G loss: 5.240002]\n",
      "epoch:38 step:29765 [D loss: 0.211322, acc: 95.31%] [G loss: 3.095977]\n",
      "epoch:38 step:29766 [D loss: 0.145740, acc: 99.22%] [G loss: 4.242385]\n",
      "epoch:38 step:29767 [D loss: 0.153703, acc: 96.09%] [G loss: 6.866677]\n",
      "epoch:38 step:29768 [D loss: 0.812051, acc: 52.34%] [G loss: 7.252729]\n",
      "epoch:38 step:29769 [D loss: 0.006772, acc: 100.00%] [G loss: 7.800716]\n",
      "epoch:38 step:29770 [D loss: 0.103153, acc: 97.66%] [G loss: 7.444355]\n",
      "epoch:38 step:29771 [D loss: 0.417420, acc: 85.16%] [G loss: 5.554408]\n",
      "epoch:38 step:29772 [D loss: 0.191729, acc: 98.44%] [G loss: 5.385632]\n",
      "epoch:38 step:29773 [D loss: 0.621141, acc: 62.50%] [G loss: 4.545292]\n",
      "epoch:38 step:29774 [D loss: 0.662582, acc: 64.84%] [G loss: 7.825289]\n",
      "epoch:38 step:29775 [D loss: 0.663963, acc: 59.38%] [G loss: 6.167874]\n",
      "epoch:38 step:29776 [D loss: 0.487978, acc: 68.75%] [G loss: 6.690153]\n",
      "epoch:38 step:29777 [D loss: 0.207886, acc: 93.75%] [G loss: 6.043204]\n",
      "epoch:38 step:29778 [D loss: 0.745607, acc: 53.91%] [G loss: 7.214358]\n",
      "epoch:38 step:29779 [D loss: 0.290170, acc: 95.31%] [G loss: 3.661505]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:38 step:29780 [D loss: 0.772829, acc: 54.69%] [G loss: 5.986751]\n",
      "epoch:38 step:29781 [D loss: 0.069131, acc: 100.00%] [G loss: 5.737167]\n",
      "epoch:38 step:29782 [D loss: 0.031658, acc: 100.00%] [G loss: 4.812878]\n",
      "epoch:38 step:29783 [D loss: 0.499206, acc: 75.78%] [G loss: 5.892999]\n",
      "epoch:38 step:29784 [D loss: 0.824742, acc: 46.88%] [G loss: 5.740978]\n",
      "epoch:38 step:29785 [D loss: 0.200805, acc: 95.31%] [G loss: 6.058027]\n",
      "epoch:38 step:29786 [D loss: 0.335494, acc: 85.16%] [G loss: 3.164267]\n",
      "epoch:38 step:29787 [D loss: 0.551625, acc: 68.75%] [G loss: 4.699309]\n",
      "epoch:38 step:29788 [D loss: 0.546514, acc: 65.62%] [G loss: 3.547790]\n",
      "epoch:38 step:29789 [D loss: 0.502624, acc: 78.91%] [G loss: 8.610944]\n",
      "epoch:38 step:29790 [D loss: 0.128492, acc: 99.22%] [G loss: 8.069164]\n",
      "epoch:38 step:29791 [D loss: 0.045551, acc: 100.00%] [G loss: 3.257398]\n",
      "epoch:38 step:29792 [D loss: 0.553491, acc: 67.97%] [G loss: 4.032710]\n",
      "epoch:38 step:29793 [D loss: 0.918031, acc: 52.34%] [G loss: 6.119438]\n",
      "epoch:38 step:29794 [D loss: 0.229304, acc: 95.31%] [G loss: 4.016183]\n",
      "epoch:38 step:29795 [D loss: 0.098284, acc: 99.22%] [G loss: 7.424008]\n",
      "epoch:38 step:29796 [D loss: 0.190712, acc: 94.53%] [G loss: 6.396204]\n",
      "epoch:38 step:29797 [D loss: 0.138885, acc: 97.66%] [G loss: 4.243945]\n",
      "epoch:38 step:29798 [D loss: 0.006194, acc: 100.00%] [G loss: 6.319758]\n",
      "epoch:38 step:29799 [D loss: 0.466771, acc: 78.12%] [G loss: 6.156764]\n",
      "epoch:38 step:29800 [D loss: 0.004122, acc: 100.00%] [G loss: 5.832943]\n",
      "##############\n",
      "[0.87332759 0.86091787 0.82435993 0.81885796 0.78831119 0.82256721\n",
      " 0.87456848 0.81195345 0.80974663 0.84243417]\n",
      "##########\n",
      "epoch:38 step:29801 [D loss: 0.365433, acc: 78.91%] [G loss: 7.348865]\n",
      "epoch:38 step:29802 [D loss: 0.174977, acc: 96.88%] [G loss: 6.454892]\n",
      "epoch:38 step:29803 [D loss: 0.018809, acc: 100.00%] [G loss: 6.553512]\n",
      "epoch:38 step:29804 [D loss: 0.156379, acc: 100.00%] [G loss: 3.763535]\n",
      "epoch:38 step:29805 [D loss: 0.255267, acc: 96.09%] [G loss: 4.645010]\n",
      "epoch:38 step:29806 [D loss: 0.433523, acc: 74.22%] [G loss: 8.164734]\n",
      "epoch:38 step:29807 [D loss: 0.118306, acc: 99.22%] [G loss: 8.219650]\n",
      "epoch:38 step:29808 [D loss: 0.677453, acc: 55.47%] [G loss: 8.959979]\n",
      "epoch:38 step:29809 [D loss: 0.187547, acc: 96.88%] [G loss: 8.603592]\n",
      "epoch:38 step:29810 [D loss: 1.487420, acc: 50.00%] [G loss: 4.537656]\n",
      "epoch:38 step:29811 [D loss: 0.167105, acc: 96.88%] [G loss: 4.825538]\n",
      "epoch:38 step:29812 [D loss: 0.468244, acc: 77.34%] [G loss: 5.356688]\n",
      "epoch:38 step:29813 [D loss: 0.101320, acc: 97.66%] [G loss: 7.966796]\n",
      "epoch:38 step:29814 [D loss: 0.035409, acc: 100.00%] [G loss: 3.312260]\n",
      "epoch:38 step:29815 [D loss: 0.324692, acc: 88.28%] [G loss: 4.981769]\n",
      "epoch:38 step:29816 [D loss: 0.194203, acc: 98.44%] [G loss: 6.856946]\n",
      "epoch:38 step:29817 [D loss: 1.151583, acc: 25.00%] [G loss: 2.764228]\n",
      "epoch:38 step:29818 [D loss: 0.198081, acc: 94.53%] [G loss: 4.219272]\n",
      "epoch:38 step:29819 [D loss: 0.088367, acc: 99.22%] [G loss: 4.630554]\n",
      "epoch:38 step:29820 [D loss: 0.105462, acc: 99.22%] [G loss: 5.693305]\n",
      "epoch:38 step:29821 [D loss: 0.574368, acc: 62.50%] [G loss: 6.171413]\n",
      "epoch:38 step:29822 [D loss: 0.187403, acc: 96.88%] [G loss: 4.818302]\n",
      "epoch:38 step:29823 [D loss: 0.372598, acc: 91.41%] [G loss: 4.915933]\n",
      "epoch:38 step:29824 [D loss: 0.063149, acc: 100.00%] [G loss: 3.017818]\n",
      "epoch:38 step:29825 [D loss: 0.052334, acc: 100.00%] [G loss: 4.631713]\n",
      "epoch:38 step:29826 [D loss: 0.693390, acc: 56.25%] [G loss: 6.966646]\n",
      "epoch:38 step:29827 [D loss: 0.253612, acc: 93.75%] [G loss: 4.328804]\n",
      "epoch:38 step:29828 [D loss: 0.364983, acc: 82.81%] [G loss: 9.495419]\n",
      "epoch:38 step:29829 [D loss: 0.282070, acc: 89.84%] [G loss: 8.491984]\n",
      "epoch:38 step:29830 [D loss: 0.302768, acc: 94.53%] [G loss: 3.778694]\n",
      "epoch:38 step:29831 [D loss: 0.071511, acc: 98.44%] [G loss: 5.479581]\n",
      "epoch:38 step:29832 [D loss: 0.282886, acc: 89.06%] [G loss: 7.065043]\n",
      "epoch:38 step:29833 [D loss: 0.994145, acc: 35.16%] [G loss: 7.079630]\n",
      "epoch:38 step:29834 [D loss: 0.063919, acc: 100.00%] [G loss: 5.192656]\n",
      "epoch:38 step:29835 [D loss: 0.068197, acc: 100.00%] [G loss: 6.874696]\n",
      "epoch:38 step:29836 [D loss: 0.418827, acc: 75.00%] [G loss: 6.703828]\n",
      "epoch:38 step:29837 [D loss: 0.707496, acc: 52.34%] [G loss: 9.758667]\n",
      "epoch:38 step:29838 [D loss: 0.096778, acc: 99.22%] [G loss: 8.125572]\n",
      "epoch:38 step:29839 [D loss: 0.050115, acc: 100.00%] [G loss: 3.808963]\n",
      "epoch:38 step:29840 [D loss: 0.130660, acc: 100.00%] [G loss: 4.887714]\n",
      "epoch:38 step:29841 [D loss: 0.401223, acc: 81.25%] [G loss: 3.589735]\n",
      "epoch:38 step:29842 [D loss: 0.564947, acc: 66.41%] [G loss: 6.575381]\n",
      "epoch:38 step:29843 [D loss: 0.746978, acc: 53.12%] [G loss: 5.104544]\n",
      "epoch:38 step:29844 [D loss: 0.239260, acc: 92.97%] [G loss: 3.982512]\n",
      "epoch:38 step:29845 [D loss: 0.263001, acc: 90.62%] [G loss: 7.074282]\n",
      "epoch:38 step:29846 [D loss: 0.754652, acc: 58.59%] [G loss: 7.368331]\n",
      "epoch:38 step:29847 [D loss: 1.775183, acc: 49.22%] [G loss: 6.545318]\n",
      "epoch:38 step:29848 [D loss: 0.486168, acc: 74.22%] [G loss: 4.692417]\n",
      "epoch:38 step:29849 [D loss: 0.157394, acc: 99.22%] [G loss: 3.107721]\n",
      "epoch:38 step:29850 [D loss: 0.682225, acc: 54.69%] [G loss: 4.110319]\n",
      "epoch:38 step:29851 [D loss: 0.412350, acc: 82.81%] [G loss: 7.434689]\n",
      "epoch:38 step:29852 [D loss: 0.166454, acc: 100.00%] [G loss: 6.700499]\n",
      "epoch:38 step:29853 [D loss: 0.283894, acc: 87.50%] [G loss: 10.439804]\n",
      "epoch:38 step:29854 [D loss: 0.684426, acc: 61.72%] [G loss: 4.753292]\n",
      "epoch:38 step:29855 [D loss: 0.530737, acc: 74.22%] [G loss: 6.578026]\n",
      "epoch:38 step:29856 [D loss: 0.613602, acc: 61.72%] [G loss: 4.152624]\n",
      "epoch:38 step:29857 [D loss: 0.287022, acc: 88.28%] [G loss: 4.951153]\n",
      "epoch:38 step:29858 [D loss: 0.340489, acc: 89.84%] [G loss: 6.892889]\n",
      "epoch:38 step:29859 [D loss: 0.295224, acc: 88.28%] [G loss: 5.479977]\n",
      "epoch:38 step:29860 [D loss: 0.590997, acc: 60.16%] [G loss: 3.794442]\n",
      "epoch:38 step:29861 [D loss: 1.276764, acc: 24.22%] [G loss: 3.939767]\n",
      "epoch:38 step:29862 [D loss: 1.442923, acc: 37.50%] [G loss: 9.792938]\n",
      "epoch:38 step:29863 [D loss: 0.301941, acc: 89.06%] [G loss: 4.978747]\n",
      "epoch:38 step:29864 [D loss: 0.037901, acc: 100.00%] [G loss: 3.745854]\n",
      "epoch:38 step:29865 [D loss: 1.425931, acc: 30.47%] [G loss: 4.902123]\n",
      "epoch:38 step:29866 [D loss: 0.871894, acc: 44.53%] [G loss: 6.442177]\n",
      "epoch:38 step:29867 [D loss: 0.008965, acc: 100.00%] [G loss: 9.370271]\n",
      "epoch:38 step:29868 [D loss: 0.465873, acc: 69.53%] [G loss: 5.848126]\n",
      "epoch:38 step:29869 [D loss: 0.195522, acc: 95.31%] [G loss: 7.189949]\n",
      "epoch:38 step:29870 [D loss: 0.105507, acc: 99.22%] [G loss: 7.532578]\n",
      "epoch:38 step:29871 [D loss: 0.034413, acc: 99.22%] [G loss: 8.460258]\n",
      "epoch:38 step:29872 [D loss: 0.594753, acc: 76.56%] [G loss: 5.068542]\n",
      "epoch:38 step:29873 [D loss: 0.037116, acc: 100.00%] [G loss: 4.778677]\n",
      "epoch:38 step:29874 [D loss: 0.950646, acc: 35.16%] [G loss: 2.804392]\n",
      "epoch:38 step:29875 [D loss: 0.154532, acc: 100.00%] [G loss: 4.917931]\n",
      "epoch:38 step:29876 [D loss: 0.677417, acc: 53.12%] [G loss: 6.696953]\n",
      "epoch:38 step:29877 [D loss: 0.164839, acc: 99.22%] [G loss: 5.042149]\n",
      "epoch:38 step:29878 [D loss: 0.100396, acc: 99.22%] [G loss: 4.503210]\n",
      "epoch:38 step:29879 [D loss: 0.482558, acc: 73.44%] [G loss: 7.443168]\n",
      "epoch:38 step:29880 [D loss: 0.650062, acc: 61.72%] [G loss: 4.613053]\n",
      "epoch:38 step:29881 [D loss: 0.204477, acc: 95.31%] [G loss: 4.404557]\n",
      "epoch:38 step:29882 [D loss: 0.370071, acc: 81.25%] [G loss: 2.742531]\n",
      "epoch:38 step:29883 [D loss: 0.159301, acc: 100.00%] [G loss: 7.841482]\n",
      "epoch:38 step:29884 [D loss: 0.392298, acc: 81.25%] [G loss: 9.658159]\n",
      "epoch:38 step:29885 [D loss: 0.326647, acc: 83.59%] [G loss: 11.072283]\n",
      "epoch:38 step:29886 [D loss: 0.160805, acc: 99.22%] [G loss: 2.404622]\n",
      "epoch:38 step:29887 [D loss: 0.577247, acc: 58.59%] [G loss: 6.472470]\n",
      "epoch:38 step:29888 [D loss: 1.106699, acc: 41.41%] [G loss: 2.977891]\n",
      "epoch:38 step:29889 [D loss: 0.333702, acc: 87.50%] [G loss: 6.312248]\n",
      "epoch:38 step:29890 [D loss: 0.011622, acc: 100.00%] [G loss: 6.582096]\n",
      "epoch:38 step:29891 [D loss: 0.130569, acc: 99.22%] [G loss: 6.218726]\n",
      "epoch:38 step:29892 [D loss: 0.079465, acc: 100.00%] [G loss: 7.646566]\n",
      "epoch:38 step:29893 [D loss: 0.771211, acc: 54.69%] [G loss: 6.216170]\n",
      "epoch:38 step:29894 [D loss: 0.138232, acc: 100.00%] [G loss: 5.418458]\n",
      "epoch:38 step:29895 [D loss: 0.848008, acc: 50.78%] [G loss: 4.768660]\n",
      "epoch:38 step:29896 [D loss: 0.249701, acc: 92.97%] [G loss: 6.573584]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:38 step:29897 [D loss: 0.157146, acc: 96.88%] [G loss: 4.182480]\n",
      "epoch:38 step:29898 [D loss: 0.225046, acc: 93.75%] [G loss: 4.642637]\n",
      "epoch:38 step:29899 [D loss: 0.456254, acc: 82.81%] [G loss: 5.578283]\n",
      "epoch:38 step:29900 [D loss: 0.505597, acc: 82.81%] [G loss: 5.361186]\n",
      "epoch:38 step:29901 [D loss: 0.247668, acc: 89.06%] [G loss: 2.995940]\n",
      "epoch:38 step:29902 [D loss: 0.120590, acc: 99.22%] [G loss: 7.215044]\n",
      "epoch:38 step:29903 [D loss: 1.641838, acc: 7.81%] [G loss: 9.960350]\n",
      "epoch:38 step:29904 [D loss: 0.359322, acc: 78.91%] [G loss: 5.615197]\n",
      "epoch:38 step:29905 [D loss: 0.165974, acc: 99.22%] [G loss: 4.940186]\n",
      "epoch:38 step:29906 [D loss: 0.143668, acc: 97.66%] [G loss: 8.688717]\n",
      "epoch:38 step:29907 [D loss: 0.670414, acc: 57.03%] [G loss: 6.894260]\n",
      "epoch:38 step:29908 [D loss: 0.413112, acc: 86.72%] [G loss: 5.226303]\n",
      "epoch:38 step:29909 [D loss: 0.349134, acc: 90.62%] [G loss: 2.927471]\n",
      "epoch:38 step:29910 [D loss: 0.206503, acc: 96.88%] [G loss: 3.507509]\n",
      "epoch:38 step:29911 [D loss: 0.105916, acc: 100.00%] [G loss: 2.666386]\n",
      "epoch:38 step:29912 [D loss: 0.735052, acc: 54.69%] [G loss: 7.964377]\n",
      "epoch:38 step:29913 [D loss: 0.833093, acc: 55.47%] [G loss: 5.639635]\n",
      "epoch:38 step:29914 [D loss: 0.259706, acc: 90.62%] [G loss: 2.821676]\n",
      "epoch:38 step:29915 [D loss: 0.084864, acc: 100.00%] [G loss: 7.218806]\n",
      "epoch:38 step:29916 [D loss: 0.497494, acc: 66.41%] [G loss: 6.835060]\n",
      "epoch:38 step:29917 [D loss: 0.292778, acc: 89.06%] [G loss: 3.852690]\n",
      "epoch:38 step:29918 [D loss: 0.247689, acc: 92.97%] [G loss: 3.214532]\n",
      "epoch:38 step:29919 [D loss: 0.303547, acc: 92.97%] [G loss: 6.121309]\n",
      "epoch:38 step:29920 [D loss: 0.067532, acc: 100.00%] [G loss: 7.772666]\n",
      "epoch:38 step:29921 [D loss: 0.109791, acc: 99.22%] [G loss: 3.171303]\n",
      "epoch:38 step:29922 [D loss: 0.018686, acc: 100.00%] [G loss: 7.707839]\n",
      "epoch:38 step:29923 [D loss: 0.412806, acc: 73.44%] [G loss: 6.423425]\n",
      "epoch:38 step:29924 [D loss: 0.882097, acc: 49.22%] [G loss: 7.742146]\n",
      "epoch:38 step:29925 [D loss: 0.239604, acc: 94.53%] [G loss: 3.454798]\n",
      "epoch:38 step:29926 [D loss: 1.017041, acc: 51.56%] [G loss: 6.600286]\n",
      "epoch:38 step:29927 [D loss: 1.681962, acc: 50.78%] [G loss: 6.197651]\n",
      "epoch:38 step:29928 [D loss: 0.070393, acc: 99.22%] [G loss: 5.438570]\n",
      "epoch:38 step:29929 [D loss: 0.086110, acc: 100.00%] [G loss: 4.248632]\n",
      "epoch:38 step:29930 [D loss: 0.817293, acc: 52.34%] [G loss: 4.998655]\n",
      "epoch:38 step:29931 [D loss: 0.072084, acc: 100.00%] [G loss: 5.020112]\n",
      "epoch:38 step:29932 [D loss: 0.279141, acc: 94.53%] [G loss: 6.583937]\n",
      "epoch:38 step:29933 [D loss: 0.526141, acc: 75.78%] [G loss: 5.312964]\n",
      "epoch:38 step:29934 [D loss: 0.396657, acc: 85.16%] [G loss: 7.488346]\n",
      "epoch:38 step:29935 [D loss: 0.114843, acc: 100.00%] [G loss: 7.005395]\n",
      "epoch:38 step:29936 [D loss: 0.521377, acc: 76.56%] [G loss: 3.311914]\n",
      "epoch:38 step:29937 [D loss: 0.573611, acc: 75.00%] [G loss: 4.565007]\n",
      "epoch:38 step:29938 [D loss: 0.727394, acc: 53.91%] [G loss: 5.876334]\n",
      "epoch:38 step:29939 [D loss: 0.888478, acc: 49.22%] [G loss: 4.745888]\n",
      "epoch:38 step:29940 [D loss: 0.076256, acc: 100.00%] [G loss: 4.373913]\n",
      "epoch:38 step:29941 [D loss: 0.294140, acc: 93.75%] [G loss: 3.876595]\n",
      "epoch:38 step:29942 [D loss: 0.082372, acc: 100.00%] [G loss: 6.648325]\n",
      "epoch:38 step:29943 [D loss: 0.073205, acc: 100.00%] [G loss: 5.323776]\n",
      "epoch:38 step:29944 [D loss: 0.622789, acc: 60.94%] [G loss: 5.333078]\n",
      "epoch:38 step:29945 [D loss: 0.181595, acc: 99.22%] [G loss: 5.050384]\n",
      "epoch:38 step:29946 [D loss: 0.076126, acc: 100.00%] [G loss: 5.196675]\n",
      "epoch:38 step:29947 [D loss: 0.261560, acc: 89.84%] [G loss: 7.443921]\n",
      "epoch:38 step:29948 [D loss: 0.042166, acc: 100.00%] [G loss: 9.306025]\n",
      "epoch:38 step:29949 [D loss: 0.231155, acc: 92.19%] [G loss: 7.140842]\n",
      "epoch:38 step:29950 [D loss: 0.136316, acc: 100.00%] [G loss: 4.371884]\n",
      "epoch:38 step:29951 [D loss: 0.391531, acc: 78.91%] [G loss: 6.352452]\n",
      "epoch:38 step:29952 [D loss: 0.104241, acc: 100.00%] [G loss: 6.916491]\n",
      "epoch:38 step:29953 [D loss: 1.315510, acc: 49.22%] [G loss: 6.799321]\n",
      "epoch:38 step:29954 [D loss: 0.256507, acc: 92.19%] [G loss: 7.087992]\n",
      "epoch:38 step:29955 [D loss: 0.145660, acc: 97.66%] [G loss: 3.143314]\n",
      "epoch:38 step:29956 [D loss: 0.164022, acc: 99.22%] [G loss: 7.778183]\n",
      "epoch:38 step:29957 [D loss: 0.241053, acc: 92.19%] [G loss: 5.837321]\n",
      "epoch:38 step:29958 [D loss: 1.118852, acc: 25.00%] [G loss: 7.382156]\n",
      "epoch:38 step:29959 [D loss: 0.275646, acc: 86.72%] [G loss: 4.833639]\n",
      "epoch:38 step:29960 [D loss: 0.173916, acc: 98.44%] [G loss: 5.027514]\n",
      "epoch:38 step:29961 [D loss: 0.272635, acc: 92.19%] [G loss: 6.187717]\n",
      "epoch:38 step:29962 [D loss: 0.543604, acc: 64.84%] [G loss: 8.793631]\n",
      "epoch:38 step:29963 [D loss: 0.175791, acc: 98.44%] [G loss: 6.103784]\n",
      "epoch:38 step:29964 [D loss: 0.029286, acc: 100.00%] [G loss: 6.937503]\n",
      "epoch:38 step:29965 [D loss: 0.231924, acc: 93.75%] [G loss: 5.177433]\n",
      "epoch:38 step:29966 [D loss: 0.965288, acc: 49.22%] [G loss: 4.786092]\n",
      "epoch:38 step:29967 [D loss: 0.344500, acc: 88.28%] [G loss: 4.552770]\n",
      "epoch:38 step:29968 [D loss: 0.395285, acc: 73.44%] [G loss: 8.891424]\n",
      "epoch:38 step:29969 [D loss: 0.322637, acc: 84.38%] [G loss: 6.744757]\n",
      "epoch:38 step:29970 [D loss: 0.332489, acc: 88.28%] [G loss: 4.378459]\n",
      "epoch:38 step:29971 [D loss: 0.091687, acc: 100.00%] [G loss: 2.142429]\n",
      "epoch:38 step:29972 [D loss: 1.163452, acc: 29.69%] [G loss: 7.115381]\n",
      "epoch:38 step:29973 [D loss: 0.214625, acc: 95.31%] [G loss: 4.276290]\n",
      "epoch:38 step:29974 [D loss: 0.112222, acc: 100.00%] [G loss: 6.322956]\n",
      "epoch:38 step:29975 [D loss: 0.318970, acc: 91.41%] [G loss: 3.460350]\n",
      "epoch:38 step:29976 [D loss: 0.564000, acc: 62.50%] [G loss: 6.989217]\n",
      "epoch:38 step:29977 [D loss: 0.018453, acc: 100.00%] [G loss: 7.111447]\n",
      "epoch:38 step:29978 [D loss: 0.289413, acc: 88.28%] [G loss: 1.382910]\n",
      "epoch:38 step:29979 [D loss: 0.040843, acc: 100.00%] [G loss: 4.241779]\n",
      "epoch:38 step:29980 [D loss: 0.265475, acc: 92.97%] [G loss: 4.260592]\n",
      "epoch:38 step:29981 [D loss: 0.280263, acc: 93.75%] [G loss: 3.175750]\n",
      "epoch:38 step:29982 [D loss: 0.973138, acc: 53.12%] [G loss: 5.978957]\n",
      "epoch:38 step:29983 [D loss: 0.282162, acc: 85.16%] [G loss: 4.272096]\n",
      "epoch:38 step:29984 [D loss: 0.077758, acc: 99.22%] [G loss: 4.537618]\n",
      "epoch:38 step:29985 [D loss: 0.112750, acc: 100.00%] [G loss: 7.207516]\n",
      "epoch:38 step:29986 [D loss: 0.725457, acc: 53.12%] [G loss: 4.606857]\n",
      "epoch:38 step:29987 [D loss: 0.785636, acc: 53.12%] [G loss: 4.644294]\n",
      "epoch:38 step:29988 [D loss: 0.036050, acc: 100.00%] [G loss: 4.507967]\n",
      "epoch:38 step:29989 [D loss: 0.317380, acc: 82.81%] [G loss: 5.762616]\n",
      "epoch:38 step:29990 [D loss: 0.136168, acc: 99.22%] [G loss: 5.317246]\n",
      "epoch:38 step:29991 [D loss: 0.050655, acc: 100.00%] [G loss: 4.988327]\n",
      "epoch:38 step:29992 [D loss: 0.177176, acc: 96.88%] [G loss: 8.534407]\n",
      "epoch:38 step:29993 [D loss: 0.697145, acc: 54.69%] [G loss: 7.945683]\n",
      "epoch:38 step:29994 [D loss: 0.559675, acc: 60.94%] [G loss: 3.204568]\n",
      "epoch:38 step:29995 [D loss: 0.487846, acc: 70.31%] [G loss: 3.283748]\n",
      "epoch:38 step:29996 [D loss: 0.362425, acc: 89.84%] [G loss: 2.524677]\n",
      "epoch:38 step:29997 [D loss: 0.814631, acc: 48.44%] [G loss: 4.755954]\n",
      "epoch:38 step:29998 [D loss: 0.222908, acc: 92.19%] [G loss: 2.801208]\n",
      "epoch:38 step:29999 [D loss: 0.096221, acc: 100.00%] [G loss: 7.877816]\n",
      "epoch:38 step:30000 [D loss: 0.031571, acc: 100.00%] [G loss: 4.317810]\n",
      "##############\n",
      "[0.85933748 0.87848212 0.80709725 0.81007416 0.81572474 0.84245736\n",
      " 0.88512948 0.81964342 0.80595146 0.84283458]\n",
      "##########\n",
      "epoch:38 step:30001 [D loss: 0.121624, acc: 98.44%] [G loss: 7.115082]\n",
      "epoch:38 step:30002 [D loss: 1.161942, acc: 17.97%] [G loss: 6.372166]\n",
      "epoch:38 step:30003 [D loss: 0.111586, acc: 98.44%] [G loss: 3.021899]\n",
      "epoch:38 step:30004 [D loss: 1.155447, acc: 26.56%] [G loss: 7.996273]\n",
      "epoch:38 step:30005 [D loss: 1.232590, acc: 50.00%] [G loss: 2.600978]\n",
      "epoch:38 step:30006 [D loss: 0.044535, acc: 100.00%] [G loss: 4.378455]\n",
      "epoch:38 step:30007 [D loss: 0.061293, acc: 100.00%] [G loss: 7.576252]\n",
      "epoch:38 step:30008 [D loss: 0.221665, acc: 92.97%] [G loss: 6.890507]\n",
      "epoch:38 step:30009 [D loss: 0.292155, acc: 86.72%] [G loss: 6.598900]\n",
      "epoch:38 step:30010 [D loss: 0.157940, acc: 97.66%] [G loss: 4.150321]\n",
      "epoch:38 step:30011 [D loss: 0.278918, acc: 89.06%] [G loss: 7.843468]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:38 step:30012 [D loss: 0.211816, acc: 96.88%] [G loss: 3.437096]\n",
      "epoch:38 step:30013 [D loss: 0.023365, acc: 100.00%] [G loss: 9.069734]\n",
      "epoch:38 step:30014 [D loss: 0.027582, acc: 100.00%] [G loss: 3.076118]\n",
      "epoch:38 step:30015 [D loss: 0.170670, acc: 100.00%] [G loss: 6.197124]\n",
      "epoch:38 step:30016 [D loss: 0.445801, acc: 73.44%] [G loss: 7.376185]\n",
      "epoch:38 step:30017 [D loss: 0.009274, acc: 100.00%] [G loss: 6.020651]\n",
      "epoch:38 step:30018 [D loss: 0.048890, acc: 100.00%] [G loss: 6.521292]\n",
      "epoch:38 step:30019 [D loss: 0.174317, acc: 96.88%] [G loss: 6.406060]\n",
      "epoch:38 step:30020 [D loss: 0.610235, acc: 65.62%] [G loss: 6.433944]\n",
      "epoch:38 step:30021 [D loss: 0.337900, acc: 85.16%] [G loss: 7.224793]\n",
      "epoch:38 step:30022 [D loss: 0.114333, acc: 99.22%] [G loss: 4.138668]\n",
      "epoch:38 step:30023 [D loss: 0.183959, acc: 98.44%] [G loss: 8.330715]\n",
      "epoch:38 step:30024 [D loss: 0.268777, acc: 91.41%] [G loss: 5.822852]\n",
      "epoch:38 step:30025 [D loss: 0.292915, acc: 93.75%] [G loss: 2.413354]\n",
      "epoch:38 step:30026 [D loss: 0.051361, acc: 100.00%] [G loss: 7.091298]\n",
      "epoch:38 step:30027 [D loss: 0.208045, acc: 97.66%] [G loss: 3.185365]\n",
      "epoch:38 step:30028 [D loss: 0.743611, acc: 55.47%] [G loss: 5.876791]\n",
      "epoch:38 step:30029 [D loss: 1.630653, acc: 50.00%] [G loss: 3.783721]\n",
      "epoch:38 step:30030 [D loss: 0.083064, acc: 99.22%] [G loss: 2.624926]\n",
      "epoch:38 step:30031 [D loss: 0.906632, acc: 47.66%] [G loss: 8.347113]\n",
      "epoch:38 step:30032 [D loss: 0.424621, acc: 78.12%] [G loss: 6.069554]\n",
      "epoch:38 step:30033 [D loss: 0.304268, acc: 92.97%] [G loss: 3.525559]\n",
      "epoch:38 step:30034 [D loss: 0.457201, acc: 71.88%] [G loss: 4.824269]\n",
      "epoch:38 step:30035 [D loss: 0.435680, acc: 67.19%] [G loss: 6.500111]\n",
      "epoch:38 step:30036 [D loss: 0.126049, acc: 98.44%] [G loss: 3.221027]\n",
      "epoch:38 step:30037 [D loss: 0.044869, acc: 100.00%] [G loss: 4.224391]\n",
      "epoch:38 step:30038 [D loss: 0.920721, acc: 50.00%] [G loss: 2.528059]\n",
      "epoch:38 step:30039 [D loss: 0.659612, acc: 56.25%] [G loss: 9.843296]\n",
      "epoch:38 step:30040 [D loss: 0.235323, acc: 95.31%] [G loss: 5.631696]\n",
      "epoch:38 step:30041 [D loss: 0.779895, acc: 53.12%] [G loss: 5.605825]\n",
      "epoch:38 step:30042 [D loss: 1.039994, acc: 47.66%] [G loss: 9.160505]\n",
      "epoch:38 step:30043 [D loss: 0.556659, acc: 60.16%] [G loss: 5.854507]\n",
      "epoch:38 step:30044 [D loss: 0.816090, acc: 41.41%] [G loss: 9.821369]\n",
      "epoch:38 step:30045 [D loss: 0.345264, acc: 90.62%] [G loss: 5.090828]\n",
      "epoch:38 step:30046 [D loss: 0.871681, acc: 52.34%] [G loss: 6.499613]\n",
      "epoch:38 step:30047 [D loss: 0.250589, acc: 95.31%] [G loss: 3.999945]\n",
      "epoch:38 step:30048 [D loss: 0.330116, acc: 85.94%] [G loss: 5.899913]\n",
      "epoch:38 step:30049 [D loss: 0.606431, acc: 67.97%] [G loss: 3.567144]\n",
      "epoch:38 step:30050 [D loss: 0.188250, acc: 96.88%] [G loss: 4.577087]\n",
      "epoch:38 step:30051 [D loss: 0.531480, acc: 78.12%] [G loss: 3.465577]\n",
      "epoch:38 step:30052 [D loss: 0.087281, acc: 100.00%] [G loss: 8.017786]\n",
      "epoch:38 step:30053 [D loss: 0.115925, acc: 100.00%] [G loss: 3.231830]\n",
      "epoch:38 step:30054 [D loss: 0.275548, acc: 90.62%] [G loss: 7.579544]\n",
      "epoch:38 step:30055 [D loss: 0.904900, acc: 53.91%] [G loss: 3.928101]\n",
      "epoch:38 step:30056 [D loss: 0.193097, acc: 93.75%] [G loss: 3.365702]\n",
      "epoch:38 step:30057 [D loss: 0.216970, acc: 95.31%] [G loss: 6.310047]\n",
      "epoch:38 step:30058 [D loss: 1.329936, acc: 46.09%] [G loss: 7.632595]\n",
      "epoch:38 step:30059 [D loss: 0.260071, acc: 89.84%] [G loss: 4.414474]\n",
      "epoch:38 step:30060 [D loss: 0.268851, acc: 92.19%] [G loss: 4.229297]\n",
      "epoch:38 step:30061 [D loss: 0.381015, acc: 78.91%] [G loss: 9.070026]\n",
      "epoch:38 step:30062 [D loss: 0.215032, acc: 95.31%] [G loss: 4.691816]\n",
      "epoch:38 step:30063 [D loss: 0.147133, acc: 99.22%] [G loss: 7.256338]\n",
      "epoch:38 step:30064 [D loss: 0.961708, acc: 50.78%] [G loss: 2.380552]\n",
      "epoch:38 step:30065 [D loss: 0.224394, acc: 92.19%] [G loss: 6.974419]\n",
      "epoch:38 step:30066 [D loss: 0.191486, acc: 96.09%] [G loss: 5.844375]\n",
      "epoch:38 step:30067 [D loss: 0.091777, acc: 99.22%] [G loss: 9.300325]\n",
      "epoch:38 step:30068 [D loss: 0.349482, acc: 87.50%] [G loss: 5.601856]\n",
      "epoch:38 step:30069 [D loss: 0.180230, acc: 99.22%] [G loss: 7.759321]\n",
      "epoch:38 step:30070 [D loss: 0.085161, acc: 99.22%] [G loss: 7.387959]\n",
      "epoch:38 step:30071 [D loss: 0.965085, acc: 48.44%] [G loss: 3.762791]\n",
      "epoch:38 step:30072 [D loss: 0.703397, acc: 60.94%] [G loss: 4.293711]\n",
      "epoch:38 step:30073 [D loss: 0.435937, acc: 70.31%] [G loss: 6.727114]\n",
      "epoch:38 step:30074 [D loss: 0.648563, acc: 63.28%] [G loss: 8.120093]\n",
      "epoch:38 step:30075 [D loss: 0.201773, acc: 97.66%] [G loss: 6.021719]\n",
      "epoch:38 step:30076 [D loss: 0.101335, acc: 98.44%] [G loss: 3.678951]\n",
      "epoch:38 step:30077 [D loss: 0.071359, acc: 100.00%] [G loss: 3.553573]\n",
      "epoch:38 step:30078 [D loss: 1.121953, acc: 50.00%] [G loss: 4.690670]\n",
      "epoch:38 step:30079 [D loss: 0.144614, acc: 98.44%] [G loss: 9.664376]\n",
      "epoch:38 step:30080 [D loss: 0.291164, acc: 87.50%] [G loss: 6.160519]\n",
      "epoch:38 step:30081 [D loss: 0.044651, acc: 100.00%] [G loss: 6.216989]\n",
      "epoch:38 step:30082 [D loss: 0.769053, acc: 57.81%] [G loss: 5.421726]\n",
      "epoch:38 step:30083 [D loss: 0.638559, acc: 66.41%] [G loss: 5.885817]\n",
      "epoch:38 step:30084 [D loss: 0.051714, acc: 100.00%] [G loss: 2.256183]\n",
      "epoch:38 step:30085 [D loss: 0.052914, acc: 99.22%] [G loss: 6.773832]\n",
      "epoch:38 step:30086 [D loss: 0.054156, acc: 99.22%] [G loss: 4.847113]\n",
      "epoch:38 step:30087 [D loss: 0.196573, acc: 96.88%] [G loss: 8.781990]\n",
      "epoch:38 step:30088 [D loss: 0.611969, acc: 62.50%] [G loss: 10.271404]\n",
      "epoch:38 step:30089 [D loss: 0.120425, acc: 98.44%] [G loss: 7.467937]\n",
      "epoch:38 step:30090 [D loss: 0.340755, acc: 90.62%] [G loss: 7.414742]\n",
      "epoch:38 step:30091 [D loss: 0.592537, acc: 65.62%] [G loss: 5.212540]\n",
      "epoch:38 step:30092 [D loss: 0.084099, acc: 100.00%] [G loss: 3.807443]\n",
      "epoch:38 step:30093 [D loss: 0.653145, acc: 64.06%] [G loss: 3.326471]\n",
      "epoch:38 step:30094 [D loss: 1.381552, acc: 35.16%] [G loss: 8.044327]\n",
      "epoch:38 step:30095 [D loss: 0.249559, acc: 93.75%] [G loss: 4.729815]\n",
      "epoch:38 step:30096 [D loss: 0.095012, acc: 100.00%] [G loss: 6.739260]\n",
      "epoch:38 step:30097 [D loss: 0.244237, acc: 90.62%] [G loss: 4.386978]\n",
      "epoch:38 step:30098 [D loss: 0.099677, acc: 100.00%] [G loss: 2.872889]\n",
      "epoch:38 step:30099 [D loss: 0.220457, acc: 93.75%] [G loss: 5.921617]\n",
      "epoch:38 step:30100 [D loss: 0.167825, acc: 98.44%] [G loss: 5.897756]\n",
      "epoch:38 step:30101 [D loss: 0.337226, acc: 91.41%] [G loss: 5.828757]\n",
      "epoch:38 step:30102 [D loss: 0.183252, acc: 98.44%] [G loss: 3.187181]\n",
      "epoch:38 step:30103 [D loss: 0.566502, acc: 71.09%] [G loss: 5.394399]\n",
      "epoch:38 step:30104 [D loss: 0.091529, acc: 99.22%] [G loss: 1.157575]\n",
      "epoch:38 step:30105 [D loss: 0.356189, acc: 82.03%] [G loss: 4.781219]\n",
      "epoch:38 step:30106 [D loss: 0.620195, acc: 66.41%] [G loss: 6.568938]\n",
      "epoch:38 step:30107 [D loss: 0.361444, acc: 85.16%] [G loss: 5.256948]\n",
      "epoch:38 step:30108 [D loss: 0.507400, acc: 68.75%] [G loss: 7.164970]\n",
      "epoch:38 step:30109 [D loss: 0.360001, acc: 78.12%] [G loss: 3.560410]\n",
      "epoch:38 step:30110 [D loss: 0.568006, acc: 65.62%] [G loss: 2.848732]\n",
      "epoch:38 step:30111 [D loss: 0.422681, acc: 87.50%] [G loss: 4.571797]\n",
      "epoch:38 step:30112 [D loss: 0.048421, acc: 100.00%] [G loss: 5.801920]\n",
      "epoch:38 step:30113 [D loss: 0.040882, acc: 99.22%] [G loss: 8.825550]\n",
      "epoch:38 step:30114 [D loss: 0.142427, acc: 100.00%] [G loss: 5.009673]\n",
      "epoch:38 step:30115 [D loss: 1.120062, acc: 28.12%] [G loss: 4.868738]\n",
      "epoch:38 step:30116 [D loss: 0.157185, acc: 99.22%] [G loss: 6.079618]\n",
      "epoch:38 step:30117 [D loss: 0.310944, acc: 85.94%] [G loss: 3.626425]\n",
      "epoch:38 step:30118 [D loss: 0.079012, acc: 99.22%] [G loss: 4.766906]\n",
      "epoch:38 step:30119 [D loss: 0.328992, acc: 87.50%] [G loss: 4.973001]\n",
      "epoch:38 step:30120 [D loss: 0.445053, acc: 72.66%] [G loss: 4.209889]\n",
      "epoch:38 step:30121 [D loss: 0.434186, acc: 72.66%] [G loss: 6.097375]\n",
      "epoch:38 step:30122 [D loss: 0.433560, acc: 71.09%] [G loss: 7.346691]\n",
      "epoch:38 step:30123 [D loss: 0.984657, acc: 50.00%] [G loss: 4.025494]\n",
      "epoch:38 step:30124 [D loss: 0.065453, acc: 99.22%] [G loss: 4.967313]\n",
      "epoch:38 step:30125 [D loss: 0.337685, acc: 89.06%] [G loss: 6.871649]\n",
      "epoch:38 step:30126 [D loss: 0.034543, acc: 100.00%] [G loss: 5.390580]\n",
      "epoch:38 step:30127 [D loss: 0.470272, acc: 81.25%] [G loss: 4.833859]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:38 step:30128 [D loss: 0.111118, acc: 98.44%] [G loss: 4.328849]\n",
      "epoch:38 step:30129 [D loss: 0.047422, acc: 100.00%] [G loss: 7.468872]\n",
      "epoch:38 step:30130 [D loss: 1.223685, acc: 25.78%] [G loss: 3.332253]\n",
      "epoch:38 step:30131 [D loss: 0.825870, acc: 41.41%] [G loss: 8.443783]\n",
      "epoch:38 step:30132 [D loss: 0.508506, acc: 79.69%] [G loss: 8.111816]\n",
      "epoch:38 step:30133 [D loss: 0.151554, acc: 99.22%] [G loss: 4.362111]\n",
      "epoch:38 step:30134 [D loss: 0.094720, acc: 100.00%] [G loss: 7.051651]\n",
      "epoch:38 step:30135 [D loss: 0.661206, acc: 57.03%] [G loss: 6.137158]\n",
      "epoch:38 step:30136 [D loss: 0.301423, acc: 92.19%] [G loss: 5.288693]\n",
      "epoch:38 step:30137 [D loss: 0.683620, acc: 54.69%] [G loss: 5.252176]\n",
      "epoch:38 step:30138 [D loss: 0.264621, acc: 93.75%] [G loss: 8.646784]\n",
      "epoch:38 step:30139 [D loss: 0.017364, acc: 100.00%] [G loss: 7.512904]\n",
      "epoch:38 step:30140 [D loss: 0.137143, acc: 100.00%] [G loss: 5.836247]\n",
      "epoch:38 step:30141 [D loss: 0.158462, acc: 100.00%] [G loss: 7.463499]\n",
      "epoch:38 step:30142 [D loss: 0.817908, acc: 52.34%] [G loss: 6.255984]\n",
      "epoch:38 step:30143 [D loss: 0.729426, acc: 61.72%] [G loss: 3.708565]\n",
      "epoch:38 step:30144 [D loss: 0.027054, acc: 100.00%] [G loss: 8.821599]\n",
      "epoch:38 step:30145 [D loss: 0.479436, acc: 82.03%] [G loss: 3.641913]\n",
      "epoch:38 step:30146 [D loss: 0.610297, acc: 67.19%] [G loss: 4.859602]\n",
      "epoch:38 step:30147 [D loss: 0.104433, acc: 100.00%] [G loss: 5.322337]\n",
      "epoch:38 step:30148 [D loss: 0.031205, acc: 100.00%] [G loss: 7.372291]\n",
      "epoch:38 step:30149 [D loss: 0.545768, acc: 68.75%] [G loss: 4.678633]\n",
      "epoch:38 step:30150 [D loss: 0.229061, acc: 95.31%] [G loss: 7.497401]\n",
      "epoch:38 step:30151 [D loss: 0.909509, acc: 38.28%] [G loss: 6.388115]\n",
      "epoch:38 step:30152 [D loss: 0.134434, acc: 99.22%] [G loss: 4.444645]\n",
      "epoch:38 step:30153 [D loss: 0.312594, acc: 86.72%] [G loss: 4.340453]\n",
      "epoch:38 step:30154 [D loss: 0.314248, acc: 90.62%] [G loss: 5.508931]\n",
      "epoch:38 step:30155 [D loss: 0.359382, acc: 85.16%] [G loss: 6.353623]\n",
      "epoch:38 step:30156 [D loss: 0.855802, acc: 50.78%] [G loss: 7.751663]\n",
      "epoch:38 step:30157 [D loss: 0.216164, acc: 92.97%] [G loss: 6.473902]\n",
      "epoch:38 step:30158 [D loss: 0.124490, acc: 98.44%] [G loss: 7.180068]\n",
      "epoch:38 step:30159 [D loss: 1.105716, acc: 34.38%] [G loss: 5.859468]\n",
      "epoch:38 step:30160 [D loss: 0.295305, acc: 92.97%] [G loss: 4.738202]\n",
      "epoch:38 step:30161 [D loss: 0.370509, acc: 88.28%] [G loss: 5.907115]\n",
      "epoch:38 step:30162 [D loss: 0.176642, acc: 97.66%] [G loss: 4.901236]\n",
      "epoch:38 step:30163 [D loss: 0.267366, acc: 91.41%] [G loss: 3.118436]\n",
      "epoch:38 step:30164 [D loss: 0.449665, acc: 79.69%] [G loss: 5.710238]\n",
      "epoch:38 step:30165 [D loss: 0.233894, acc: 95.31%] [G loss: 3.423265]\n",
      "epoch:38 step:30166 [D loss: 0.125920, acc: 96.88%] [G loss: 4.571866]\n",
      "epoch:38 step:30167 [D loss: 0.887302, acc: 52.34%] [G loss: 3.169627]\n",
      "epoch:38 step:30168 [D loss: 0.078211, acc: 100.00%] [G loss: 6.651636]\n",
      "epoch:38 step:30169 [D loss: 0.724566, acc: 61.72%] [G loss: 3.606105]\n",
      "epoch:38 step:30170 [D loss: 0.185343, acc: 97.66%] [G loss: 5.399060]\n",
      "epoch:38 step:30171 [D loss: 0.281918, acc: 89.06%] [G loss: 6.665398]\n",
      "epoch:38 step:30172 [D loss: 0.098454, acc: 100.00%] [G loss: 4.913498]\n",
      "epoch:38 step:30173 [D loss: 0.066927, acc: 100.00%] [G loss: 7.344357]\n",
      "epoch:38 step:30174 [D loss: 0.041805, acc: 100.00%] [G loss: 4.086713]\n",
      "epoch:38 step:30175 [D loss: 0.164164, acc: 96.09%] [G loss: 7.506021]\n",
      "epoch:38 step:30176 [D loss: 0.180081, acc: 96.88%] [G loss: 8.217366]\n",
      "epoch:38 step:30177 [D loss: 0.117743, acc: 99.22%] [G loss: 4.660646]\n",
      "epoch:38 step:30178 [D loss: 0.472246, acc: 80.47%] [G loss: 5.137303]\n",
      "epoch:38 step:30179 [D loss: 0.268380, acc: 90.62%] [G loss: 5.777339]\n",
      "epoch:38 step:30180 [D loss: 0.480722, acc: 68.75%] [G loss: 4.619304]\n",
      "epoch:38 step:30181 [D loss: 0.035965, acc: 100.00%] [G loss: 5.187599]\n",
      "epoch:38 step:30182 [D loss: 0.474949, acc: 71.88%] [G loss: 6.268478]\n",
      "epoch:38 step:30183 [D loss: 0.552049, acc: 75.00%] [G loss: 3.774820]\n",
      "epoch:38 step:30184 [D loss: 1.674191, acc: 42.19%] [G loss: 3.073168]\n",
      "epoch:38 step:30185 [D loss: 0.487204, acc: 77.34%] [G loss: 5.207650]\n",
      "epoch:38 step:30186 [D loss: 0.183240, acc: 99.22%] [G loss: 6.885640]\n",
      "epoch:38 step:30187 [D loss: 0.505769, acc: 66.41%] [G loss: 3.607459]\n",
      "epoch:38 step:30188 [D loss: 0.493114, acc: 74.22%] [G loss: 1.583535]\n",
      "epoch:38 step:30189 [D loss: 0.114041, acc: 100.00%] [G loss: 5.470735]\n",
      "epoch:38 step:30190 [D loss: 0.059974, acc: 100.00%] [G loss: 3.647539]\n",
      "epoch:38 step:30191 [D loss: 0.254053, acc: 96.88%] [G loss: 3.385486]\n",
      "epoch:38 step:30192 [D loss: 0.546719, acc: 75.78%] [G loss: 4.026309]\n",
      "epoch:38 step:30193 [D loss: 0.852761, acc: 58.59%] [G loss: 9.647182]\n",
      "epoch:38 step:30194 [D loss: 0.065213, acc: 100.00%] [G loss: 7.997647]\n",
      "epoch:38 step:30195 [D loss: 0.464946, acc: 71.09%] [G loss: 4.622527]\n",
      "epoch:38 step:30196 [D loss: 0.078213, acc: 100.00%] [G loss: 5.724541]\n",
      "epoch:38 step:30197 [D loss: 0.303249, acc: 90.62%] [G loss: 4.670563]\n",
      "epoch:38 step:30198 [D loss: 0.049190, acc: 100.00%] [G loss: 5.878337]\n",
      "epoch:38 step:30199 [D loss: 0.401305, acc: 84.38%] [G loss: 6.366679]\n",
      "epoch:38 step:30200 [D loss: 0.311214, acc: 84.38%] [G loss: 5.512596]\n",
      "##############\n",
      "[0.85580542 0.88389428 0.8001371  0.81840431 0.80262766 0.8414951\n",
      " 0.90071647 0.81648728 0.79602275 0.83919633]\n",
      "##########\n",
      "epoch:38 step:30201 [D loss: 0.249550, acc: 96.09%] [G loss: 3.620752]\n",
      "epoch:38 step:30202 [D loss: 0.925892, acc: 42.19%] [G loss: 4.796227]\n",
      "epoch:38 step:30203 [D loss: 0.821090, acc: 50.78%] [G loss: 6.049008]\n",
      "epoch:38 step:30204 [D loss: 0.289039, acc: 88.28%] [G loss: 5.343219]\n",
      "epoch:38 step:30205 [D loss: 0.739996, acc: 57.03%] [G loss: 3.610540]\n",
      "epoch:38 step:30206 [D loss: 0.625108, acc: 55.47%] [G loss: 4.891392]\n",
      "epoch:38 step:30207 [D loss: 0.063618, acc: 100.00%] [G loss: 7.850571]\n",
      "epoch:38 step:30208 [D loss: 0.471177, acc: 64.06%] [G loss: 4.350755]\n",
      "epoch:38 step:30209 [D loss: 0.455337, acc: 82.03%] [G loss: 7.371127]\n",
      "epoch:38 step:30210 [D loss: 0.374365, acc: 82.81%] [G loss: 4.386097]\n",
      "epoch:38 step:30211 [D loss: 0.231405, acc: 93.75%] [G loss: 3.581614]\n",
      "epoch:38 step:30212 [D loss: 0.816499, acc: 52.34%] [G loss: 5.993685]\n",
      "epoch:38 step:30213 [D loss: 0.151902, acc: 99.22%] [G loss: 5.201138]\n",
      "epoch:38 step:30214 [D loss: 0.168752, acc: 97.66%] [G loss: 2.986993]\n",
      "epoch:38 step:30215 [D loss: 0.019235, acc: 100.00%] [G loss: 8.094158]\n",
      "epoch:38 step:30216 [D loss: 0.264601, acc: 96.88%] [G loss: 2.861583]\n",
      "epoch:38 step:30217 [D loss: 0.335163, acc: 94.53%] [G loss: 7.156761]\n",
      "epoch:38 step:30218 [D loss: 0.323370, acc: 92.97%] [G loss: 3.294209]\n",
      "epoch:38 step:30219 [D loss: 0.261074, acc: 93.75%] [G loss: 6.383612]\n",
      "epoch:38 step:30220 [D loss: 0.158412, acc: 98.44%] [G loss: 7.556332]\n",
      "epoch:38 step:30221 [D loss: 0.108960, acc: 100.00%] [G loss: 5.519399]\n",
      "epoch:38 step:30222 [D loss: 0.495719, acc: 64.84%] [G loss: 4.780924]\n",
      "epoch:38 step:30223 [D loss: 0.238101, acc: 92.97%] [G loss: 5.823313]\n",
      "epoch:38 step:30224 [D loss: 0.177306, acc: 96.88%] [G loss: 4.774465]\n",
      "epoch:38 step:30225 [D loss: 0.254640, acc: 89.84%] [G loss: 5.113177]\n",
      "epoch:38 step:30226 [D loss: 0.168395, acc: 98.44%] [G loss: 4.178574]\n",
      "epoch:38 step:30227 [D loss: 0.237550, acc: 97.66%] [G loss: 4.201904]\n",
      "epoch:38 step:30228 [D loss: 0.108388, acc: 99.22%] [G loss: 6.188808]\n",
      "epoch:38 step:30229 [D loss: 0.219897, acc: 94.53%] [G loss: 6.640039]\n",
      "epoch:38 step:30230 [D loss: 0.246865, acc: 91.41%] [G loss: 8.743222]\n",
      "epoch:38 step:30231 [D loss: 0.447193, acc: 66.41%] [G loss: 5.442261]\n",
      "epoch:38 step:30232 [D loss: 0.179773, acc: 98.44%] [G loss: 7.889998]\n",
      "epoch:38 step:30233 [D loss: 0.098985, acc: 100.00%] [G loss: 7.103570]\n",
      "epoch:38 step:30234 [D loss: 0.215086, acc: 96.88%] [G loss: 6.029794]\n",
      "epoch:38 step:30235 [D loss: 0.549723, acc: 70.31%] [G loss: 6.993972]\n",
      "epoch:38 step:30236 [D loss: 0.138933, acc: 99.22%] [G loss: 1.863874]\n",
      "epoch:38 step:30237 [D loss: 0.105880, acc: 99.22%] [G loss: 5.646968]\n",
      "epoch:38 step:30238 [D loss: 0.314069, acc: 91.41%] [G loss: 5.445184]\n",
      "epoch:38 step:30239 [D loss: 0.095349, acc: 100.00%] [G loss: 8.288518]\n",
      "epoch:38 step:30240 [D loss: 0.379165, acc: 79.69%] [G loss: 8.337852]\n",
      "epoch:38 step:30241 [D loss: 0.391714, acc: 88.28%] [G loss: 5.280610]\n",
      "epoch:38 step:30242 [D loss: 0.179790, acc: 95.31%] [G loss: 5.857268]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:38 step:30243 [D loss: 0.213890, acc: 93.75%] [G loss: 7.397643]\n",
      "epoch:38 step:30244 [D loss: 0.085873, acc: 100.00%] [G loss: 4.572442]\n",
      "epoch:38 step:30245 [D loss: 0.188283, acc: 99.22%] [G loss: 6.006831]\n",
      "epoch:38 step:30246 [D loss: 1.004979, acc: 25.78%] [G loss: 6.511366]\n",
      "epoch:38 step:30247 [D loss: 0.154334, acc: 96.09%] [G loss: 3.982315]\n",
      "epoch:38 step:30248 [D loss: 1.438466, acc: 29.69%] [G loss: 4.730211]\n",
      "epoch:38 step:30249 [D loss: 1.635782, acc: 41.41%] [G loss: 5.203557]\n",
      "epoch:38 step:30250 [D loss: 1.527259, acc: 46.88%] [G loss: 6.498805]\n",
      "epoch:38 step:30251 [D loss: 0.755502, acc: 51.56%] [G loss: 2.829209]\n",
      "epoch:38 step:30252 [D loss: 0.550401, acc: 63.28%] [G loss: 3.578001]\n",
      "epoch:38 step:30253 [D loss: 0.557768, acc: 62.50%] [G loss: 5.117029]\n",
      "epoch:38 step:30254 [D loss: 0.370261, acc: 92.19%] [G loss: 2.766666]\n",
      "epoch:38 step:30255 [D loss: 0.492269, acc: 80.47%] [G loss: 3.188179]\n",
      "epoch:38 step:30256 [D loss: 0.713409, acc: 55.47%] [G loss: 5.833079]\n",
      "epoch:38 step:30257 [D loss: 0.093859, acc: 100.00%] [G loss: 3.505019]\n",
      "epoch:38 step:30258 [D loss: 0.134644, acc: 100.00%] [G loss: 6.342413]\n",
      "epoch:38 step:30259 [D loss: 0.078724, acc: 99.22%] [G loss: 9.747756]\n",
      "epoch:38 step:30260 [D loss: 0.114792, acc: 100.00%] [G loss: 4.316104]\n",
      "epoch:38 step:30261 [D loss: 0.365845, acc: 81.25%] [G loss: 7.031314]\n",
      "epoch:38 step:30262 [D loss: 0.311525, acc: 91.41%] [G loss: 4.981747]\n",
      "epoch:38 step:30263 [D loss: 0.182622, acc: 96.09%] [G loss: 6.293686]\n",
      "epoch:38 step:30264 [D loss: 0.328613, acc: 85.16%] [G loss: 5.665891]\n",
      "epoch:38 step:30265 [D loss: 0.090672, acc: 100.00%] [G loss: 6.110665]\n",
      "epoch:38 step:30266 [D loss: 0.233047, acc: 89.84%] [G loss: 7.619659]\n",
      "epoch:38 step:30267 [D loss: 0.087524, acc: 100.00%] [G loss: 6.421068]\n",
      "epoch:38 step:30268 [D loss: 0.332018, acc: 87.50%] [G loss: 3.431502]\n",
      "epoch:38 step:30269 [D loss: 0.325479, acc: 93.75%] [G loss: 2.900140]\n",
      "epoch:38 step:30270 [D loss: 1.014442, acc: 29.69%] [G loss: 4.409356]\n",
      "epoch:38 step:30271 [D loss: 0.081031, acc: 100.00%] [G loss: 5.186262]\n",
      "epoch:38 step:30272 [D loss: 0.928443, acc: 49.22%] [G loss: 4.949712]\n",
      "epoch:38 step:30273 [D loss: 1.017266, acc: 50.78%] [G loss: 6.445628]\n",
      "epoch:38 step:30274 [D loss: 0.687383, acc: 61.72%] [G loss: 4.896336]\n",
      "epoch:38 step:30275 [D loss: 0.235014, acc: 97.66%] [G loss: 5.114556]\n",
      "epoch:38 step:30276 [D loss: 0.527219, acc: 64.84%] [G loss: 5.792271]\n",
      "epoch:38 step:30277 [D loss: 0.269914, acc: 91.41%] [G loss: 4.263363]\n",
      "epoch:38 step:30278 [D loss: 1.630762, acc: 7.03%] [G loss: 5.156070]\n",
      "epoch:38 step:30279 [D loss: 0.431442, acc: 69.53%] [G loss: 6.842657]\n",
      "epoch:38 step:30280 [D loss: 0.204460, acc: 93.75%] [G loss: 3.682034]\n",
      "epoch:38 step:30281 [D loss: 0.051918, acc: 100.00%] [G loss: 5.200319]\n",
      "epoch:38 step:30282 [D loss: 0.188686, acc: 96.09%] [G loss: 4.912462]\n",
      "epoch:38 step:30283 [D loss: 0.234206, acc: 96.88%] [G loss: 6.889737]\n",
      "epoch:38 step:30284 [D loss: 0.209846, acc: 92.19%] [G loss: 5.403906]\n",
      "epoch:38 step:30285 [D loss: 0.134865, acc: 99.22%] [G loss: 4.138429]\n",
      "epoch:38 step:30286 [D loss: 0.230356, acc: 96.88%] [G loss: 5.336915]\n",
      "epoch:38 step:30287 [D loss: 0.078858, acc: 100.00%] [G loss: 7.953868]\n",
      "epoch:38 step:30288 [D loss: 0.144769, acc: 100.00%] [G loss: 3.406564]\n",
      "epoch:38 step:30289 [D loss: 0.137440, acc: 97.66%] [G loss: 5.465558]\n",
      "epoch:38 step:30290 [D loss: 0.153225, acc: 97.66%] [G loss: 3.880619]\n",
      "epoch:38 step:30291 [D loss: 0.136256, acc: 99.22%] [G loss: 6.922818]\n",
      "epoch:38 step:30292 [D loss: 0.237515, acc: 90.62%] [G loss: 5.288800]\n",
      "epoch:38 step:30293 [D loss: 0.119848, acc: 98.44%] [G loss: 5.740962]\n",
      "epoch:38 step:30294 [D loss: 0.155715, acc: 97.66%] [G loss: 6.559225]\n",
      "epoch:38 step:30295 [D loss: 0.103550, acc: 99.22%] [G loss: 4.777210]\n",
      "epoch:38 step:30296 [D loss: 0.061615, acc: 100.00%] [G loss: 6.602458]\n",
      "epoch:38 step:30297 [D loss: 0.353997, acc: 88.28%] [G loss: 3.573965]\n",
      "epoch:38 step:30298 [D loss: 0.575125, acc: 67.97%] [G loss: 4.782126]\n",
      "epoch:38 step:30299 [D loss: 0.115926, acc: 99.22%] [G loss: 5.037664]\n",
      "epoch:38 step:30300 [D loss: 0.204376, acc: 96.09%] [G loss: 6.212723]\n",
      "epoch:38 step:30301 [D loss: 0.449018, acc: 84.38%] [G loss: 5.654900]\n",
      "epoch:38 step:30302 [D loss: 0.146736, acc: 100.00%] [G loss: 3.056201]\n",
      "epoch:38 step:30303 [D loss: 0.156571, acc: 97.66%] [G loss: 5.076620]\n",
      "epoch:38 step:30304 [D loss: 0.596016, acc: 61.72%] [G loss: 6.165445]\n",
      "epoch:38 step:30305 [D loss: 0.417875, acc: 86.72%] [G loss: 5.186917]\n",
      "epoch:38 step:30306 [D loss: 0.212032, acc: 93.75%] [G loss: 5.338975]\n",
      "epoch:38 step:30307 [D loss: 0.552255, acc: 63.28%] [G loss: 7.637331]\n",
      "epoch:38 step:30308 [D loss: 0.082270, acc: 100.00%] [G loss: 5.340771]\n",
      "epoch:38 step:30309 [D loss: 0.424318, acc: 82.81%] [G loss: 6.400683]\n",
      "epoch:38 step:30310 [D loss: 0.406738, acc: 78.12%] [G loss: 5.971644]\n",
      "epoch:38 step:30311 [D loss: 0.261476, acc: 88.28%] [G loss: 4.959930]\n",
      "epoch:38 step:30312 [D loss: 0.634013, acc: 61.72%] [G loss: 7.593820]\n",
      "epoch:38 step:30313 [D loss: 0.230632, acc: 95.31%] [G loss: 7.797775]\n",
      "epoch:38 step:30314 [D loss: 0.170565, acc: 99.22%] [G loss: 4.059784]\n",
      "epoch:38 step:30315 [D loss: 0.664881, acc: 60.94%] [G loss: 5.257553]\n",
      "epoch:38 step:30316 [D loss: 0.161545, acc: 97.66%] [G loss: 2.373837]\n",
      "epoch:38 step:30317 [D loss: 0.285602, acc: 92.97%] [G loss: 4.520783]\n",
      "epoch:38 step:30318 [D loss: 0.212942, acc: 94.53%] [G loss: 3.802152]\n",
      "epoch:38 step:30319 [D loss: 0.187660, acc: 98.44%] [G loss: 5.161032]\n",
      "epoch:38 step:30320 [D loss: 0.093058, acc: 100.00%] [G loss: 4.083036]\n",
      "epoch:38 step:30321 [D loss: 0.457444, acc: 71.88%] [G loss: 5.534253]\n",
      "epoch:38 step:30322 [D loss: 0.267932, acc: 88.28%] [G loss: 3.773539]\n",
      "epoch:38 step:30323 [D loss: 0.885824, acc: 51.56%] [G loss: 4.843789]\n",
      "epoch:38 step:30324 [D loss: 0.564995, acc: 64.84%] [G loss: 4.524118]\n",
      "epoch:38 step:30325 [D loss: 0.148437, acc: 99.22%] [G loss: 7.102938]\n",
      "epoch:38 step:30326 [D loss: 0.732313, acc: 53.12%] [G loss: 6.631919]\n",
      "epoch:38 step:30327 [D loss: 0.405421, acc: 78.91%] [G loss: 6.097561]\n",
      "epoch:38 step:30328 [D loss: 0.095917, acc: 100.00%] [G loss: 2.202332]\n",
      "epoch:38 step:30329 [D loss: 0.276926, acc: 85.16%] [G loss: 5.823230]\n",
      "epoch:38 step:30330 [D loss: 0.235796, acc: 96.09%] [G loss: 2.809422]\n",
      "epoch:38 step:30331 [D loss: 0.111526, acc: 100.00%] [G loss: 4.849272]\n",
      "epoch:38 step:30332 [D loss: 0.177223, acc: 98.44%] [G loss: 3.923104]\n",
      "epoch:38 step:30333 [D loss: 0.083872, acc: 100.00%] [G loss: 9.068473]\n",
      "epoch:38 step:30334 [D loss: 0.304634, acc: 91.41%] [G loss: 9.001108]\n",
      "epoch:38 step:30335 [D loss: 0.137860, acc: 100.00%] [G loss: 1.473826]\n",
      "epoch:38 step:30336 [D loss: 1.251158, acc: 50.00%] [G loss: 6.339278]\n",
      "epoch:38 step:30337 [D loss: 0.565982, acc: 71.88%] [G loss: 5.151983]\n",
      "epoch:38 step:30338 [D loss: 0.607856, acc: 57.81%] [G loss: 4.976624]\n",
      "epoch:38 step:30339 [D loss: 0.228782, acc: 96.09%] [G loss: 5.743343]\n",
      "epoch:38 step:30340 [D loss: 0.342159, acc: 87.50%] [G loss: 5.105045]\n",
      "epoch:38 step:30341 [D loss: 0.776014, acc: 60.16%] [G loss: 5.025248]\n",
      "epoch:38 step:30342 [D loss: 0.238137, acc: 94.53%] [G loss: 5.326587]\n",
      "epoch:38 step:30343 [D loss: 0.878937, acc: 41.41%] [G loss: 7.264076]\n",
      "epoch:38 step:30344 [D loss: 0.137736, acc: 99.22%] [G loss: 4.994555]\n",
      "epoch:38 step:30345 [D loss: 0.535119, acc: 60.94%] [G loss: 8.404201]\n",
      "epoch:38 step:30346 [D loss: 0.130160, acc: 100.00%] [G loss: 6.517345]\n",
      "epoch:38 step:30347 [D loss: 0.364059, acc: 77.34%] [G loss: 7.411720]\n",
      "epoch:38 step:30348 [D loss: 0.052353, acc: 100.00%] [G loss: 4.597691]\n",
      "epoch:38 step:30349 [D loss: 0.145345, acc: 98.44%] [G loss: 7.054245]\n",
      "epoch:38 step:30350 [D loss: 0.397017, acc: 82.03%] [G loss: 6.237915]\n",
      "epoch:38 step:30351 [D loss: 0.222760, acc: 94.53%] [G loss: 4.796540]\n",
      "epoch:38 step:30352 [D loss: 0.045160, acc: 100.00%] [G loss: 3.895468]\n",
      "epoch:38 step:30353 [D loss: 1.152985, acc: 28.12%] [G loss: 6.671054]\n",
      "epoch:38 step:30354 [D loss: 0.173744, acc: 96.88%] [G loss: 6.452164]\n",
      "epoch:38 step:30355 [D loss: 0.478342, acc: 75.78%] [G loss: 8.819248]\n",
      "epoch:38 step:30356 [D loss: 0.140913, acc: 99.22%] [G loss: 4.345092]\n",
      "epoch:38 step:30357 [D loss: 0.135101, acc: 99.22%] [G loss: 6.319556]\n",
      "epoch:38 step:30358 [D loss: 0.057076, acc: 100.00%] [G loss: 4.925690]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:38 step:30359 [D loss: 0.321992, acc: 92.97%] [G loss: 3.274760]\n",
      "epoch:38 step:30360 [D loss: 0.556108, acc: 73.44%] [G loss: 10.299021]\n",
      "epoch:38 step:30361 [D loss: 0.091289, acc: 99.22%] [G loss: 6.064946]\n",
      "epoch:38 step:30362 [D loss: 0.149232, acc: 99.22%] [G loss: 4.208112]\n",
      "epoch:38 step:30363 [D loss: 0.269623, acc: 96.88%] [G loss: 6.711523]\n",
      "epoch:38 step:30364 [D loss: 0.117421, acc: 100.00%] [G loss: 6.224274]\n",
      "epoch:38 step:30365 [D loss: 0.401537, acc: 89.06%] [G loss: 3.937360]\n",
      "epoch:38 step:30366 [D loss: 0.073431, acc: 100.00%] [G loss: 4.657894]\n",
      "epoch:38 step:30367 [D loss: 0.636408, acc: 57.81%] [G loss: 6.624526]\n",
      "epoch:38 step:30368 [D loss: 0.521008, acc: 67.19%] [G loss: 8.968544]\n",
      "epoch:38 step:30369 [D loss: 0.096634, acc: 99.22%] [G loss: 5.432726]\n",
      "epoch:38 step:30370 [D loss: 0.391600, acc: 90.62%] [G loss: 5.947350]\n",
      "epoch:38 step:30371 [D loss: 0.251747, acc: 98.44%] [G loss: 3.582007]\n",
      "epoch:38 step:30372 [D loss: 0.130487, acc: 97.66%] [G loss: 5.207972]\n",
      "epoch:38 step:30373 [D loss: 0.080622, acc: 99.22%] [G loss: 7.694320]\n",
      "epoch:38 step:30374 [D loss: 0.260319, acc: 89.84%] [G loss: 8.519769]\n",
      "epoch:38 step:30375 [D loss: 0.535818, acc: 60.16%] [G loss: 6.760408]\n",
      "epoch:38 step:30376 [D loss: 0.012877, acc: 100.00%] [G loss: 5.482702]\n",
      "epoch:38 step:30377 [D loss: 0.050800, acc: 100.00%] [G loss: 6.465248]\n",
      "epoch:38 step:30378 [D loss: 0.747507, acc: 58.59%] [G loss: 6.486275]\n",
      "epoch:38 step:30379 [D loss: 0.656255, acc: 61.72%] [G loss: 7.030739]\n",
      "epoch:38 step:30380 [D loss: 0.060404, acc: 100.00%] [G loss: 5.641628]\n",
      "epoch:38 step:30381 [D loss: 0.760561, acc: 52.34%] [G loss: 3.559696]\n",
      "epoch:38 step:30382 [D loss: 0.015627, acc: 100.00%] [G loss: 5.748116]\n",
      "epoch:38 step:30383 [D loss: 0.618946, acc: 55.47%] [G loss: 6.946688]\n",
      "epoch:38 step:30384 [D loss: 0.261768, acc: 96.09%] [G loss: 5.850250]\n",
      "epoch:38 step:30385 [D loss: 0.842987, acc: 50.00%] [G loss: 8.018087]\n",
      "epoch:38 step:30386 [D loss: 0.134383, acc: 100.00%] [G loss: 6.832169]\n",
      "epoch:38 step:30387 [D loss: 0.146737, acc: 99.22%] [G loss: 2.584857]\n",
      "epoch:38 step:30388 [D loss: 0.408424, acc: 83.59%] [G loss: 5.274117]\n",
      "epoch:38 step:30389 [D loss: 0.278174, acc: 88.28%] [G loss: 8.830806]\n",
      "epoch:38 step:30390 [D loss: 0.263146, acc: 89.84%] [G loss: 6.993817]\n",
      "epoch:38 step:30391 [D loss: 0.141113, acc: 98.44%] [G loss: 7.899016]\n",
      "epoch:38 step:30392 [D loss: 0.183320, acc: 98.44%] [G loss: 6.186064]\n",
      "epoch:38 step:30393 [D loss: 0.601689, acc: 62.50%] [G loss: 7.344277]\n",
      "epoch:38 step:30394 [D loss: 0.159689, acc: 98.44%] [G loss: 4.480498]\n",
      "epoch:38 step:30395 [D loss: 0.062291, acc: 100.00%] [G loss: 5.676295]\n",
      "epoch:38 step:30396 [D loss: 0.074952, acc: 100.00%] [G loss: 5.414093]\n",
      "epoch:38 step:30397 [D loss: 0.039301, acc: 100.00%] [G loss: 5.807416]\n",
      "epoch:38 step:30398 [D loss: 0.122994, acc: 99.22%] [G loss: 5.025476]\n",
      "epoch:38 step:30399 [D loss: 0.230951, acc: 94.53%] [G loss: 4.354880]\n",
      "epoch:38 step:30400 [D loss: 0.010421, acc: 100.00%] [G loss: 7.316427]\n",
      "##############\n",
      "[0.85342586 0.87090593 0.82175831 0.81468515 0.78873487 0.81817246\n",
      " 0.87741606 0.8364921  0.80354781 0.84054621]\n",
      "##########\n",
      "epoch:38 step:30401 [D loss: 0.025374, acc: 100.00%] [G loss: 7.536876]\n",
      "epoch:38 step:30402 [D loss: 0.140581, acc: 100.00%] [G loss: 7.785599]\n",
      "epoch:38 step:30403 [D loss: 0.418030, acc: 79.69%] [G loss: 6.907681]\n",
      "epoch:38 step:30404 [D loss: 0.054297, acc: 99.22%] [G loss: 10.469332]\n",
      "epoch:38 step:30405 [D loss: 0.267837, acc: 88.28%] [G loss: 5.920933]\n",
      "epoch:38 step:30406 [D loss: 0.103627, acc: 98.44%] [G loss: 6.925036]\n",
      "epoch:38 step:30407 [D loss: 0.075828, acc: 100.00%] [G loss: 6.981394]\n",
      "epoch:38 step:30408 [D loss: 0.285400, acc: 92.19%] [G loss: 9.178677]\n",
      "epoch:38 step:30409 [D loss: 0.410046, acc: 75.78%] [G loss: 3.655674]\n",
      "epoch:38 step:30410 [D loss: 0.087168, acc: 100.00%] [G loss: 5.179597]\n",
      "epoch:38 step:30411 [D loss: 0.667342, acc: 57.03%] [G loss: 4.251234]\n",
      "epoch:38 step:30412 [D loss: 0.704326, acc: 64.84%] [G loss: 5.861300]\n",
      "epoch:38 step:30413 [D loss: 0.265216, acc: 86.72%] [G loss: 6.382789]\n",
      "epoch:38 step:30414 [D loss: 0.059464, acc: 100.00%] [G loss: 5.292523]\n",
      "epoch:38 step:30415 [D loss: 0.178470, acc: 98.44%] [G loss: 4.372028]\n",
      "epoch:38 step:30416 [D loss: 0.929397, acc: 41.41%] [G loss: 9.015289]\n",
      "epoch:38 step:30417 [D loss: 0.068321, acc: 100.00%] [G loss: 4.253090]\n",
      "epoch:38 step:30418 [D loss: 0.443155, acc: 82.03%] [G loss: 3.784647]\n",
      "epoch:38 step:30419 [D loss: 0.194532, acc: 96.09%] [G loss: 4.110695]\n",
      "epoch:38 step:30420 [D loss: 0.947855, acc: 53.91%] [G loss: 8.695651]\n",
      "epoch:38 step:30421 [D loss: 0.061843, acc: 100.00%] [G loss: 4.468184]\n",
      "epoch:38 step:30422 [D loss: 0.761744, acc: 54.69%] [G loss: 5.990424]\n",
      "epoch:38 step:30423 [D loss: 0.173431, acc: 96.88%] [G loss: 6.139995]\n",
      "epoch:38 step:30424 [D loss: 0.359655, acc: 85.94%] [G loss: 7.814775]\n",
      "epoch:38 step:30425 [D loss: 0.253401, acc: 97.66%] [G loss: 4.752300]\n",
      "epoch:38 step:30426 [D loss: 0.465138, acc: 81.25%] [G loss: 6.086171]\n",
      "epoch:38 step:30427 [D loss: 1.016747, acc: 25.78%] [G loss: 6.237380]\n",
      "epoch:38 step:30428 [D loss: 0.470339, acc: 72.66%] [G loss: 6.197475]\n",
      "epoch:38 step:30429 [D loss: 1.164247, acc: 46.88%] [G loss: 7.062115]\n",
      "epoch:38 step:30430 [D loss: 0.622113, acc: 67.19%] [G loss: 6.050350]\n",
      "epoch:38 step:30431 [D loss: 0.038240, acc: 100.00%] [G loss: 3.319532]\n",
      "epoch:38 step:30432 [D loss: 0.034455, acc: 100.00%] [G loss: 6.729280]\n",
      "epoch:38 step:30433 [D loss: 0.225424, acc: 89.84%] [G loss: 7.267915]\n",
      "epoch:38 step:30434 [D loss: 0.783428, acc: 56.25%] [G loss: 6.097241]\n",
      "epoch:38 step:30435 [D loss: 0.567840, acc: 64.06%] [G loss: 6.201855]\n",
      "epoch:38 step:30436 [D loss: 0.117167, acc: 98.44%] [G loss: 5.642813]\n",
      "epoch:38 step:30437 [D loss: 0.381285, acc: 86.72%] [G loss: 5.097527]\n",
      "epoch:38 step:30438 [D loss: 0.132522, acc: 98.44%] [G loss: 12.884005]\n",
      "epoch:38 step:30439 [D loss: 0.149150, acc: 100.00%] [G loss: 6.631917]\n",
      "epoch:38 step:30440 [D loss: 0.165994, acc: 96.88%] [G loss: 5.664116]\n",
      "epoch:38 step:30441 [D loss: 0.033854, acc: 100.00%] [G loss: 5.443711]\n",
      "epoch:38 step:30442 [D loss: 0.095056, acc: 99.22%] [G loss: 4.232081]\n",
      "epoch:38 step:30443 [D loss: 0.225598, acc: 95.31%] [G loss: 9.761430]\n",
      "epoch:38 step:30444 [D loss: 0.523807, acc: 73.44%] [G loss: 5.152766]\n",
      "epoch:38 step:30445 [D loss: 0.130461, acc: 100.00%] [G loss: 11.357685]\n",
      "epoch:38 step:30446 [D loss: 0.302047, acc: 90.62%] [G loss: 6.262611]\n",
      "epoch:38 step:30447 [D loss: 0.649061, acc: 71.88%] [G loss: 2.857368]\n",
      "epoch:38 step:30448 [D loss: 0.089721, acc: 100.00%] [G loss: 5.020468]\n",
      "epoch:38 step:30449 [D loss: 0.288445, acc: 92.97%] [G loss: 7.082707]\n",
      "epoch:38 step:30450 [D loss: 0.013915, acc: 100.00%] [G loss: 7.959638]\n",
      "epoch:38 step:30451 [D loss: 0.022547, acc: 100.00%] [G loss: 11.557625]\n",
      "epoch:38 step:30452 [D loss: 0.179077, acc: 96.88%] [G loss: 7.914660]\n",
      "epoch:38 step:30453 [D loss: 0.158891, acc: 96.88%] [G loss: 6.511682]\n",
      "epoch:38 step:30454 [D loss: 0.155722, acc: 98.44%] [G loss: 4.275425]\n",
      "epoch:38 step:30455 [D loss: 0.623394, acc: 62.50%] [G loss: 6.185404]\n",
      "epoch:38 step:30456 [D loss: 1.802484, acc: 45.31%] [G loss: 7.698398]\n",
      "epoch:38 step:30457 [D loss: 0.160793, acc: 98.44%] [G loss: 5.509072]\n",
      "epoch:38 step:30458 [D loss: 0.992737, acc: 51.56%] [G loss: 10.228002]\n",
      "epoch:38 step:30459 [D loss: 0.438887, acc: 74.22%] [G loss: 2.576410]\n",
      "epoch:39 step:30460 [D loss: 0.057768, acc: 100.00%] [G loss: 4.529031]\n",
      "epoch:39 step:30461 [D loss: 0.353566, acc: 92.19%] [G loss: 5.336361]\n",
      "epoch:39 step:30462 [D loss: 0.844833, acc: 49.22%] [G loss: 5.381868]\n",
      "epoch:39 step:30463 [D loss: 0.687755, acc: 52.34%] [G loss: 3.902409]\n",
      "epoch:39 step:30464 [D loss: 0.466854, acc: 79.69%] [G loss: 4.726745]\n",
      "epoch:39 step:30465 [D loss: 0.678304, acc: 64.06%] [G loss: 6.728055]\n",
      "epoch:39 step:30466 [D loss: 0.114121, acc: 99.22%] [G loss: 5.068923]\n",
      "epoch:39 step:30467 [D loss: 0.060294, acc: 100.00%] [G loss: 5.714100]\n",
      "epoch:39 step:30468 [D loss: 0.380248, acc: 76.56%] [G loss: 6.519117]\n",
      "epoch:39 step:30469 [D loss: 0.281808, acc: 89.84%] [G loss: 6.097193]\n",
      "epoch:39 step:30470 [D loss: 0.299422, acc: 84.38%] [G loss: 7.524164]\n",
      "epoch:39 step:30471 [D loss: 0.153625, acc: 100.00%] [G loss: 3.056318]\n",
      "epoch:39 step:30472 [D loss: 0.115546, acc: 100.00%] [G loss: 5.833120]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:39 step:30473 [D loss: 0.179870, acc: 96.09%] [G loss: 7.370548]\n",
      "epoch:39 step:30474 [D loss: 0.594949, acc: 62.50%] [G loss: 3.710479]\n",
      "epoch:39 step:30475 [D loss: 0.297283, acc: 97.66%] [G loss: 2.694929]\n",
      "epoch:39 step:30476 [D loss: 0.079717, acc: 100.00%] [G loss: 5.717418]\n",
      "epoch:39 step:30477 [D loss: 0.307268, acc: 91.41%] [G loss: 10.228245]\n",
      "epoch:39 step:30478 [D loss: 0.212584, acc: 98.44%] [G loss: 6.277249]\n",
      "epoch:39 step:30479 [D loss: 0.169553, acc: 97.66%] [G loss: 4.602617]\n",
      "epoch:39 step:30480 [D loss: 0.121411, acc: 98.44%] [G loss: 7.133392]\n",
      "epoch:39 step:30481 [D loss: 0.174805, acc: 99.22%] [G loss: 7.107921]\n",
      "epoch:39 step:30482 [D loss: 0.075307, acc: 100.00%] [G loss: 8.124077]\n",
      "epoch:39 step:30483 [D loss: 0.578448, acc: 71.88%] [G loss: 7.077315]\n",
      "epoch:39 step:30484 [D loss: 0.216139, acc: 97.66%] [G loss: 3.621109]\n",
      "epoch:39 step:30485 [D loss: 0.949634, acc: 32.81%] [G loss: 7.896435]\n",
      "epoch:39 step:30486 [D loss: 0.073024, acc: 100.00%] [G loss: 5.068245]\n",
      "epoch:39 step:30487 [D loss: 0.142730, acc: 98.44%] [G loss: 3.526341]\n",
      "epoch:39 step:30488 [D loss: 0.162542, acc: 96.88%] [G loss: 6.293803]\n",
      "epoch:39 step:30489 [D loss: 0.038424, acc: 100.00%] [G loss: 7.621637]\n",
      "epoch:39 step:30490 [D loss: 0.251791, acc: 92.19%] [G loss: 4.188903]\n",
      "epoch:39 step:30491 [D loss: 0.013056, acc: 100.00%] [G loss: 4.546995]\n",
      "epoch:39 step:30492 [D loss: 0.044177, acc: 100.00%] [G loss: 3.548510]\n",
      "epoch:39 step:30493 [D loss: 1.004665, acc: 26.56%] [G loss: 7.265367]\n",
      "epoch:39 step:30494 [D loss: 0.886708, acc: 41.41%] [G loss: 11.181684]\n",
      "epoch:39 step:30495 [D loss: 0.601614, acc: 62.50%] [G loss: 7.252077]\n",
      "epoch:39 step:30496 [D loss: 0.074240, acc: 100.00%] [G loss: 7.599475]\n",
      "epoch:39 step:30497 [D loss: 0.255915, acc: 88.28%] [G loss: 7.392683]\n",
      "epoch:39 step:30498 [D loss: 0.307841, acc: 89.84%] [G loss: 6.125834]\n",
      "epoch:39 step:30499 [D loss: 0.563041, acc: 67.19%] [G loss: 6.557959]\n",
      "epoch:39 step:30500 [D loss: 0.312753, acc: 90.62%] [G loss: 4.779311]\n",
      "epoch:39 step:30501 [D loss: 0.337164, acc: 93.75%] [G loss: 5.311869]\n",
      "epoch:39 step:30502 [D loss: 0.577592, acc: 57.81%] [G loss: 3.564814]\n",
      "epoch:39 step:30503 [D loss: 1.256253, acc: 48.44%] [G loss: 6.173685]\n",
      "epoch:39 step:30504 [D loss: 0.632456, acc: 67.97%] [G loss: 6.270398]\n",
      "epoch:39 step:30505 [D loss: 0.066229, acc: 100.00%] [G loss: 3.572351]\n",
      "epoch:39 step:30506 [D loss: 0.765870, acc: 57.03%] [G loss: 6.068471]\n",
      "epoch:39 step:30507 [D loss: 0.215899, acc: 94.53%] [G loss: 8.150361]\n",
      "epoch:39 step:30508 [D loss: 0.051042, acc: 100.00%] [G loss: 6.243082]\n",
      "epoch:39 step:30509 [D loss: 0.869728, acc: 35.94%] [G loss: 6.179143]\n",
      "epoch:39 step:30510 [D loss: 0.192268, acc: 98.44%] [G loss: 6.899240]\n",
      "epoch:39 step:30511 [D loss: 0.331112, acc: 91.41%] [G loss: 5.426515]\n",
      "epoch:39 step:30512 [D loss: 0.047016, acc: 100.00%] [G loss: 4.344282]\n",
      "epoch:39 step:30513 [D loss: 0.201552, acc: 95.31%] [G loss: 6.214240]\n",
      "epoch:39 step:30514 [D loss: 0.096883, acc: 99.22%] [G loss: 3.329793]\n",
      "epoch:39 step:30515 [D loss: 0.026198, acc: 100.00%] [G loss: 8.394373]\n",
      "epoch:39 step:30516 [D loss: 0.249017, acc: 94.53%] [G loss: 8.781677]\n",
      "epoch:39 step:30517 [D loss: 0.143176, acc: 98.44%] [G loss: 4.133668]\n",
      "epoch:39 step:30518 [D loss: 0.047084, acc: 100.00%] [G loss: 5.513844]\n",
      "epoch:39 step:30519 [D loss: 0.014251, acc: 100.00%] [G loss: 5.296011]\n",
      "epoch:39 step:30520 [D loss: 0.121392, acc: 99.22%] [G loss: 5.400367]\n",
      "epoch:39 step:30521 [D loss: 0.017549, acc: 100.00%] [G loss: 10.712234]\n",
      "epoch:39 step:30522 [D loss: 0.401270, acc: 77.34%] [G loss: 6.110882]\n",
      "epoch:39 step:30523 [D loss: 0.687527, acc: 57.81%] [G loss: 2.940130]\n",
      "epoch:39 step:30524 [D loss: 0.394991, acc: 82.03%] [G loss: 3.707437]\n",
      "epoch:39 step:30525 [D loss: 0.328085, acc: 87.50%] [G loss: 3.020201]\n",
      "epoch:39 step:30526 [D loss: 0.877435, acc: 53.12%] [G loss: 6.476865]\n",
      "epoch:39 step:30527 [D loss: 0.484393, acc: 81.25%] [G loss: 6.812267]\n",
      "epoch:39 step:30528 [D loss: 0.068593, acc: 99.22%] [G loss: 5.048739]\n",
      "epoch:39 step:30529 [D loss: 0.715239, acc: 54.69%] [G loss: 5.397179]\n",
      "epoch:39 step:30530 [D loss: 0.026551, acc: 100.00%] [G loss: 8.098037]\n",
      "epoch:39 step:30531 [D loss: 0.914083, acc: 42.97%] [G loss: 6.496684]\n",
      "epoch:39 step:30532 [D loss: 0.152374, acc: 100.00%] [G loss: 4.785298]\n",
      "epoch:39 step:30533 [D loss: 0.151240, acc: 99.22%] [G loss: 7.176252]\n",
      "epoch:39 step:30534 [D loss: 0.270148, acc: 88.28%] [G loss: 5.040482]\n",
      "epoch:39 step:30535 [D loss: 0.318774, acc: 82.03%] [G loss: 4.600974]\n",
      "epoch:39 step:30536 [D loss: 0.038034, acc: 100.00%] [G loss: 4.118834]\n",
      "epoch:39 step:30537 [D loss: 1.463093, acc: 23.44%] [G loss: 8.035580]\n",
      "epoch:39 step:30538 [D loss: 0.123647, acc: 99.22%] [G loss: 5.344755]\n",
      "epoch:39 step:30539 [D loss: 0.947423, acc: 52.34%] [G loss: 7.745346]\n",
      "epoch:39 step:30540 [D loss: 0.397619, acc: 80.47%] [G loss: 10.199059]\n",
      "epoch:39 step:30541 [D loss: 0.172342, acc: 97.66%] [G loss: 4.819880]\n",
      "epoch:39 step:30542 [D loss: 0.191473, acc: 97.66%] [G loss: 6.122863]\n",
      "epoch:39 step:30543 [D loss: 0.373548, acc: 85.94%] [G loss: 9.063908]\n",
      "epoch:39 step:30544 [D loss: 0.093029, acc: 99.22%] [G loss: 3.715942]\n",
      "epoch:39 step:30545 [D loss: 0.150898, acc: 95.31%] [G loss: 9.140318]\n",
      "epoch:39 step:30546 [D loss: 0.905465, acc: 37.50%] [G loss: 4.885938]\n",
      "epoch:39 step:30547 [D loss: 0.393917, acc: 79.69%] [G loss: 2.539199]\n",
      "epoch:39 step:30548 [D loss: 0.023078, acc: 100.00%] [G loss: 7.847529]\n",
      "epoch:39 step:30549 [D loss: 0.032274, acc: 100.00%] [G loss: 5.581104]\n",
      "epoch:39 step:30550 [D loss: 0.580833, acc: 64.84%] [G loss: 7.138207]\n",
      "epoch:39 step:30551 [D loss: 0.129489, acc: 97.66%] [G loss: 4.165623]\n",
      "epoch:39 step:30552 [D loss: 0.141803, acc: 99.22%] [G loss: 5.121800]\n",
      "epoch:39 step:30553 [D loss: 0.282791, acc: 89.84%] [G loss: 4.491744]\n",
      "epoch:39 step:30554 [D loss: 0.418540, acc: 78.91%] [G loss: 7.614898]\n",
      "epoch:39 step:30555 [D loss: 0.506022, acc: 67.19%] [G loss: 5.111149]\n",
      "epoch:39 step:30556 [D loss: 0.592524, acc: 59.38%] [G loss: 4.228837]\n",
      "epoch:39 step:30557 [D loss: 0.016473, acc: 100.00%] [G loss: 10.339199]\n",
      "epoch:39 step:30558 [D loss: 0.049944, acc: 100.00%] [G loss: 5.071193]\n",
      "epoch:39 step:30559 [D loss: 0.231374, acc: 96.88%] [G loss: 5.001862]\n",
      "epoch:39 step:30560 [D loss: 0.656081, acc: 60.94%] [G loss: 4.887549]\n",
      "epoch:39 step:30561 [D loss: 0.053093, acc: 100.00%] [G loss: 6.663631]\n",
      "epoch:39 step:30562 [D loss: 0.782130, acc: 55.47%] [G loss: 6.436027]\n",
      "epoch:39 step:30563 [D loss: 0.149063, acc: 97.66%] [G loss: 5.076254]\n",
      "epoch:39 step:30564 [D loss: 0.400566, acc: 74.22%] [G loss: 5.434768]\n",
      "epoch:39 step:30565 [D loss: 0.272460, acc: 94.53%] [G loss: 5.506804]\n",
      "epoch:39 step:30566 [D loss: 0.503753, acc: 68.75%] [G loss: 3.851007]\n",
      "epoch:39 step:30567 [D loss: 0.412195, acc: 82.81%] [G loss: 4.214148]\n",
      "epoch:39 step:30568 [D loss: 0.541902, acc: 70.31%] [G loss: 3.062118]\n",
      "epoch:39 step:30569 [D loss: 0.602216, acc: 53.91%] [G loss: 5.027226]\n",
      "epoch:39 step:30570 [D loss: 0.121100, acc: 100.00%] [G loss: 6.925436]\n",
      "epoch:39 step:30571 [D loss: 0.098524, acc: 100.00%] [G loss: 6.913343]\n",
      "epoch:39 step:30572 [D loss: 0.061150, acc: 100.00%] [G loss: 5.165011]\n",
      "epoch:39 step:30573 [D loss: 0.423275, acc: 80.47%] [G loss: 7.503269]\n",
      "epoch:39 step:30574 [D loss: 0.625479, acc: 65.62%] [G loss: 4.967109]\n",
      "epoch:39 step:30575 [D loss: 0.680398, acc: 62.50%] [G loss: 6.163333]\n",
      "epoch:39 step:30576 [D loss: 0.379403, acc: 90.62%] [G loss: 5.840684]\n",
      "epoch:39 step:30577 [D loss: 0.239563, acc: 92.97%] [G loss: 3.949313]\n",
      "epoch:39 step:30578 [D loss: 0.397465, acc: 77.34%] [G loss: 7.318857]\n",
      "epoch:39 step:30579 [D loss: 0.901437, acc: 50.00%] [G loss: 5.813461]\n",
      "epoch:39 step:30580 [D loss: 0.106830, acc: 100.00%] [G loss: 5.370749]\n",
      "epoch:39 step:30581 [D loss: 0.029625, acc: 100.00%] [G loss: 9.015370]\n",
      "epoch:39 step:30582 [D loss: 0.382588, acc: 78.12%] [G loss: 6.484466]\n",
      "epoch:39 step:30583 [D loss: 0.023526, acc: 100.00%] [G loss: 4.727492]\n",
      "epoch:39 step:30584 [D loss: 0.100005, acc: 100.00%] [G loss: 4.624391]\n",
      "epoch:39 step:30585 [D loss: 0.190593, acc: 97.66%] [G loss: 7.330534]\n",
      "epoch:39 step:30586 [D loss: 0.053167, acc: 100.00%] [G loss: 5.508029]\n",
      "epoch:39 step:30587 [D loss: 0.161530, acc: 100.00%] [G loss: 4.925742]\n",
      "epoch:39 step:30588 [D loss: 0.572585, acc: 75.78%] [G loss: 8.833689]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:39 step:30589 [D loss: 0.612911, acc: 67.19%] [G loss: 6.742199]\n",
      "epoch:39 step:30590 [D loss: 0.179533, acc: 98.44%] [G loss: 3.702865]\n",
      "epoch:39 step:30591 [D loss: 0.538193, acc: 72.66%] [G loss: 6.271629]\n",
      "epoch:39 step:30592 [D loss: 0.416607, acc: 82.81%] [G loss: 4.427761]\n",
      "epoch:39 step:30593 [D loss: 0.082214, acc: 100.00%] [G loss: 6.346729]\n",
      "epoch:39 step:30594 [D loss: 0.737826, acc: 50.78%] [G loss: 7.856438]\n",
      "epoch:39 step:30595 [D loss: 0.126995, acc: 99.22%] [G loss: 7.558449]\n",
      "epoch:39 step:30596 [D loss: 0.071014, acc: 100.00%] [G loss: 5.780212]\n",
      "epoch:39 step:30597 [D loss: 0.075331, acc: 100.00%] [G loss: 8.144260]\n",
      "epoch:39 step:30598 [D loss: 0.295144, acc: 92.97%] [G loss: 7.344378]\n",
      "epoch:39 step:30599 [D loss: 0.119367, acc: 100.00%] [G loss: 5.476905]\n",
      "epoch:39 step:30600 [D loss: 0.292303, acc: 87.50%] [G loss: 5.415555]\n",
      "##############\n",
      "[0.85270429 0.87907208 0.81966895 0.79316182 0.78450204 0.83002111\n",
      " 0.89832745 0.81721587 0.81372167 0.84630545]\n",
      "##########\n",
      "epoch:39 step:30601 [D loss: 0.044948, acc: 100.00%] [G loss: 6.680813]\n",
      "epoch:39 step:30602 [D loss: 0.575119, acc: 68.75%] [G loss: 6.624125]\n",
      "epoch:39 step:30603 [D loss: 0.764088, acc: 54.69%] [G loss: 6.865377]\n",
      "epoch:39 step:30604 [D loss: 0.056312, acc: 100.00%] [G loss: 2.037354]\n",
      "epoch:39 step:30605 [D loss: 0.508751, acc: 69.53%] [G loss: 4.002279]\n",
      "epoch:39 step:30606 [D loss: 0.279224, acc: 95.31%] [G loss: 9.366098]\n",
      "epoch:39 step:30607 [D loss: 0.020471, acc: 100.00%] [G loss: 10.394363]\n",
      "epoch:39 step:30608 [D loss: 0.069368, acc: 100.00%] [G loss: 5.429182]\n",
      "epoch:39 step:30609 [D loss: 0.135180, acc: 99.22%] [G loss: 8.095410]\n",
      "epoch:39 step:30610 [D loss: 0.773136, acc: 52.34%] [G loss: 5.670979]\n",
      "epoch:39 step:30611 [D loss: 0.556342, acc: 64.06%] [G loss: 7.192300]\n",
      "epoch:39 step:30612 [D loss: 0.147986, acc: 100.00%] [G loss: 3.031883]\n",
      "epoch:39 step:30613 [D loss: 0.272416, acc: 95.31%] [G loss: 5.367733]\n",
      "epoch:39 step:30614 [D loss: 0.042924, acc: 100.00%] [G loss: 6.647735]\n",
      "epoch:39 step:30615 [D loss: 0.410696, acc: 88.28%] [G loss: 6.918693]\n",
      "epoch:39 step:30616 [D loss: 0.212649, acc: 96.88%] [G loss: 2.873348]\n",
      "epoch:39 step:30617 [D loss: 0.196209, acc: 98.44%] [G loss: 6.556963]\n",
      "epoch:39 step:30618 [D loss: 0.620363, acc: 69.53%] [G loss: 3.869233]\n",
      "epoch:39 step:30619 [D loss: 0.189157, acc: 98.44%] [G loss: 5.195814]\n",
      "epoch:39 step:30620 [D loss: 0.025289, acc: 100.00%] [G loss: 7.165167]\n",
      "epoch:39 step:30621 [D loss: 0.117501, acc: 100.00%] [G loss: 4.993045]\n",
      "epoch:39 step:30622 [D loss: 0.308277, acc: 92.19%] [G loss: 4.486914]\n",
      "epoch:39 step:30623 [D loss: 0.021328, acc: 100.00%] [G loss: 6.616568]\n",
      "epoch:39 step:30624 [D loss: 0.753813, acc: 53.12%] [G loss: 2.786964]\n",
      "epoch:39 step:30625 [D loss: 0.198735, acc: 98.44%] [G loss: 6.921568]\n",
      "epoch:39 step:30626 [D loss: 0.284492, acc: 89.06%] [G loss: 8.830076]\n",
      "epoch:39 step:30627 [D loss: 0.187729, acc: 96.88%] [G loss: 6.177286]\n",
      "epoch:39 step:30628 [D loss: 0.550615, acc: 59.38%] [G loss: 7.200119]\n",
      "epoch:39 step:30629 [D loss: 0.845319, acc: 53.12%] [G loss: 5.488460]\n",
      "epoch:39 step:30630 [D loss: 0.807711, acc: 49.22%] [G loss: 5.016422]\n",
      "epoch:39 step:30631 [D loss: 0.053677, acc: 100.00%] [G loss: 4.230466]\n",
      "epoch:39 step:30632 [D loss: 0.724063, acc: 55.47%] [G loss: 7.131659]\n",
      "epoch:39 step:30633 [D loss: 0.016703, acc: 100.00%] [G loss: 9.380400]\n",
      "epoch:39 step:30634 [D loss: 0.025220, acc: 100.00%] [G loss: 10.112493]\n",
      "epoch:39 step:30635 [D loss: 0.480851, acc: 82.03%] [G loss: 5.004639]\n",
      "epoch:39 step:30636 [D loss: 0.214850, acc: 97.66%] [G loss: 5.322404]\n",
      "epoch:39 step:30637 [D loss: 0.204178, acc: 94.53%] [G loss: 8.333976]\n",
      "epoch:39 step:30638 [D loss: 0.592337, acc: 59.38%] [G loss: 6.131363]\n",
      "epoch:39 step:30639 [D loss: 0.514080, acc: 72.66%] [G loss: 4.080769]\n",
      "epoch:39 step:30640 [D loss: 0.537030, acc: 68.75%] [G loss: 8.975724]\n",
      "epoch:39 step:30641 [D loss: 0.130324, acc: 98.44%] [G loss: 5.591409]\n",
      "epoch:39 step:30642 [D loss: 0.153032, acc: 99.22%] [G loss: 2.906402]\n",
      "epoch:39 step:30643 [D loss: 0.922122, acc: 52.34%] [G loss: 6.984178]\n",
      "epoch:39 step:30644 [D loss: 0.225588, acc: 93.75%] [G loss: 5.411390]\n",
      "epoch:39 step:30645 [D loss: 0.084901, acc: 100.00%] [G loss: 5.976631]\n",
      "epoch:39 step:30646 [D loss: 0.299189, acc: 94.53%] [G loss: 4.699848]\n",
      "epoch:39 step:30647 [D loss: 0.328481, acc: 90.62%] [G loss: 4.128338]\n",
      "epoch:39 step:30648 [D loss: 0.075334, acc: 100.00%] [G loss: 6.340038]\n",
      "epoch:39 step:30649 [D loss: 1.066428, acc: 42.97%] [G loss: 7.568962]\n",
      "epoch:39 step:30650 [D loss: 0.527593, acc: 67.19%] [G loss: 4.632597]\n",
      "epoch:39 step:30651 [D loss: 0.104041, acc: 100.00%] [G loss: 4.223192]\n",
      "epoch:39 step:30652 [D loss: 0.209157, acc: 96.88%] [G loss: 5.406339]\n",
      "epoch:39 step:30653 [D loss: 0.780536, acc: 51.56%] [G loss: 9.117478]\n",
      "epoch:39 step:30654 [D loss: 0.177100, acc: 96.88%] [G loss: 3.893915]\n",
      "epoch:39 step:30655 [D loss: 0.108526, acc: 100.00%] [G loss: 7.746480]\n",
      "epoch:39 step:30656 [D loss: 1.445207, acc: 43.75%] [G loss: 7.291585]\n",
      "epoch:39 step:30657 [D loss: 0.039501, acc: 100.00%] [G loss: 6.907366]\n",
      "epoch:39 step:30658 [D loss: 0.139230, acc: 98.44%] [G loss: 8.505930]\n",
      "epoch:39 step:30659 [D loss: 0.073513, acc: 100.00%] [G loss: 5.770947]\n",
      "epoch:39 step:30660 [D loss: 0.338858, acc: 90.62%] [G loss: 6.954117]\n",
      "epoch:39 step:30661 [D loss: 0.973025, acc: 40.62%] [G loss: 5.967060]\n",
      "epoch:39 step:30662 [D loss: 0.343744, acc: 83.59%] [G loss: 6.395821]\n",
      "epoch:39 step:30663 [D loss: 1.243812, acc: 50.00%] [G loss: 7.183715]\n",
      "epoch:39 step:30664 [D loss: 0.107337, acc: 99.22%] [G loss: 8.587008]\n",
      "epoch:39 step:30665 [D loss: 0.152159, acc: 97.66%] [G loss: 5.320996]\n",
      "epoch:39 step:30666 [D loss: 1.556734, acc: 7.81%] [G loss: 7.909522]\n",
      "epoch:39 step:30667 [D loss: 1.024172, acc: 45.31%] [G loss: 7.992423]\n",
      "epoch:39 step:30668 [D loss: 0.969137, acc: 47.66%] [G loss: 8.738255]\n",
      "epoch:39 step:30669 [D loss: 0.497983, acc: 66.41%] [G loss: 5.645922]\n",
      "epoch:39 step:30670 [D loss: 0.752727, acc: 51.56%] [G loss: 5.599045]\n",
      "epoch:39 step:30671 [D loss: 0.022107, acc: 100.00%] [G loss: 8.495367]\n",
      "epoch:39 step:30672 [D loss: 0.996638, acc: 51.56%] [G loss: 5.226338]\n",
      "epoch:39 step:30673 [D loss: 0.050860, acc: 100.00%] [G loss: 5.087929]\n",
      "epoch:39 step:30674 [D loss: 1.421105, acc: 48.44%] [G loss: 7.021193]\n",
      "epoch:39 step:30675 [D loss: 0.267521, acc: 88.28%] [G loss: 10.120568]\n",
      "epoch:39 step:30676 [D loss: 0.072845, acc: 99.22%] [G loss: 5.901229]\n",
      "epoch:39 step:30677 [D loss: 0.197266, acc: 97.66%] [G loss: 4.140989]\n",
      "epoch:39 step:30678 [D loss: 0.202421, acc: 93.75%] [G loss: 5.300113]\n",
      "epoch:39 step:30679 [D loss: 0.028293, acc: 100.00%] [G loss: 6.717759]\n",
      "epoch:39 step:30680 [D loss: 0.081850, acc: 99.22%] [G loss: 4.400141]\n",
      "epoch:39 step:30681 [D loss: 0.391735, acc: 86.72%] [G loss: 6.273761]\n",
      "epoch:39 step:30682 [D loss: 1.281255, acc: 50.78%] [G loss: 5.896760]\n",
      "epoch:39 step:30683 [D loss: 0.421791, acc: 77.34%] [G loss: 6.469187]\n",
      "epoch:39 step:30684 [D loss: 0.209920, acc: 93.75%] [G loss: 3.537886]\n",
      "epoch:39 step:30685 [D loss: 0.304256, acc: 95.31%] [G loss: 8.295887]\n",
      "epoch:39 step:30686 [D loss: 0.059782, acc: 100.00%] [G loss: 5.593995]\n",
      "epoch:39 step:30687 [D loss: 0.085627, acc: 100.00%] [G loss: 5.582257]\n",
      "epoch:39 step:30688 [D loss: 0.147990, acc: 98.44%] [G loss: 5.775267]\n",
      "epoch:39 step:30689 [D loss: 1.561489, acc: 34.38%] [G loss: 6.301029]\n",
      "epoch:39 step:30690 [D loss: 0.227583, acc: 91.41%] [G loss: 6.042793]\n",
      "epoch:39 step:30691 [D loss: 0.528402, acc: 67.97%] [G loss: 3.516343]\n",
      "epoch:39 step:30692 [D loss: 0.130523, acc: 99.22%] [G loss: 7.683422]\n",
      "epoch:39 step:30693 [D loss: 0.178575, acc: 94.53%] [G loss: 5.569016]\n",
      "epoch:39 step:30694 [D loss: 0.172752, acc: 96.88%] [G loss: 5.298364]\n",
      "epoch:39 step:30695 [D loss: 0.710650, acc: 59.38%] [G loss: 4.328526]\n",
      "epoch:39 step:30696 [D loss: 0.023751, acc: 100.00%] [G loss: 4.867733]\n",
      "epoch:39 step:30697 [D loss: 0.367592, acc: 82.81%] [G loss: 3.265570]\n",
      "epoch:39 step:30698 [D loss: 0.487431, acc: 78.12%] [G loss: 5.585021]\n",
      "epoch:39 step:30699 [D loss: 0.307410, acc: 82.03%] [G loss: 4.222756]\n",
      "epoch:39 step:30700 [D loss: 0.351594, acc: 85.16%] [G loss: 3.829633]\n",
      "epoch:39 step:30701 [D loss: 0.327156, acc: 79.69%] [G loss: 4.119547]\n",
      "epoch:39 step:30702 [D loss: 0.188137, acc: 98.44%] [G loss: 2.977453]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:39 step:30703 [D loss: 0.074513, acc: 99.22%] [G loss: 5.320024]\n",
      "epoch:39 step:30704 [D loss: 0.250075, acc: 91.41%] [G loss: 5.716585]\n",
      "epoch:39 step:30705 [D loss: 0.394081, acc: 85.16%] [G loss: 4.234001]\n",
      "epoch:39 step:30706 [D loss: 0.665754, acc: 63.28%] [G loss: 3.468996]\n",
      "epoch:39 step:30707 [D loss: 0.145818, acc: 99.22%] [G loss: 5.765565]\n",
      "epoch:39 step:30708 [D loss: 0.194836, acc: 96.09%] [G loss: 8.143283]\n",
      "epoch:39 step:30709 [D loss: 0.083711, acc: 99.22%] [G loss: 5.270988]\n",
      "epoch:39 step:30710 [D loss: 0.031949, acc: 100.00%] [G loss: 8.954510]\n",
      "epoch:39 step:30711 [D loss: 0.431586, acc: 84.38%] [G loss: 6.732715]\n",
      "epoch:39 step:30712 [D loss: 0.199836, acc: 100.00%] [G loss: 3.839781]\n",
      "epoch:39 step:30713 [D loss: 0.665427, acc: 60.16%] [G loss: 6.184123]\n",
      "epoch:39 step:30714 [D loss: 0.204358, acc: 98.44%] [G loss: 5.715470]\n",
      "epoch:39 step:30715 [D loss: 0.084805, acc: 100.00%] [G loss: 5.572513]\n",
      "epoch:39 step:30716 [D loss: 1.370913, acc: 17.19%] [G loss: 7.323884]\n",
      "epoch:39 step:30717 [D loss: 1.235897, acc: 14.84%] [G loss: 5.198385]\n",
      "epoch:39 step:30718 [D loss: 0.887751, acc: 51.56%] [G loss: 6.999739]\n",
      "epoch:39 step:30719 [D loss: 0.064967, acc: 100.00%] [G loss: 7.432973]\n",
      "epoch:39 step:30720 [D loss: 0.703870, acc: 55.47%] [G loss: 4.957910]\n",
      "epoch:39 step:30721 [D loss: 0.035821, acc: 100.00%] [G loss: 9.731675]\n",
      "epoch:39 step:30722 [D loss: 0.571016, acc: 66.41%] [G loss: 7.677058]\n",
      "epoch:39 step:30723 [D loss: 0.211462, acc: 93.75%] [G loss: 5.268538]\n",
      "epoch:39 step:30724 [D loss: 0.219436, acc: 95.31%] [G loss: 4.037758]\n",
      "epoch:39 step:30725 [D loss: 0.007220, acc: 100.00%] [G loss: 4.162076]\n",
      "epoch:39 step:30726 [D loss: 0.225112, acc: 92.97%] [G loss: 4.862510]\n",
      "epoch:39 step:30727 [D loss: 0.250444, acc: 94.53%] [G loss: 5.128234]\n",
      "epoch:39 step:30728 [D loss: 0.401969, acc: 81.25%] [G loss: 3.011798]\n",
      "epoch:39 step:30729 [D loss: 0.220170, acc: 92.97%] [G loss: 3.687030]\n",
      "epoch:39 step:30730 [D loss: 0.598649, acc: 64.84%] [G loss: 5.073292]\n",
      "epoch:39 step:30731 [D loss: 0.139482, acc: 100.00%] [G loss: 5.232788]\n",
      "epoch:39 step:30732 [D loss: 0.408404, acc: 77.34%] [G loss: 4.964403]\n",
      "epoch:39 step:30733 [D loss: 0.345510, acc: 82.03%] [G loss: 6.133206]\n",
      "epoch:39 step:30734 [D loss: 0.308570, acc: 86.72%] [G loss: 5.026567]\n",
      "epoch:39 step:30735 [D loss: 0.233033, acc: 95.31%] [G loss: 3.976962]\n",
      "epoch:39 step:30736 [D loss: 0.155402, acc: 99.22%] [G loss: 4.264512]\n",
      "epoch:39 step:30737 [D loss: 0.026703, acc: 100.00%] [G loss: 8.340420]\n",
      "epoch:39 step:30738 [D loss: 0.211948, acc: 97.66%] [G loss: 3.289440]\n",
      "epoch:39 step:30739 [D loss: 0.153593, acc: 100.00%] [G loss: 2.341455]\n",
      "epoch:39 step:30740 [D loss: 0.095945, acc: 100.00%] [G loss: 5.507825]\n",
      "epoch:39 step:30741 [D loss: 0.053950, acc: 100.00%] [G loss: 6.305248]\n",
      "epoch:39 step:30742 [D loss: 0.183959, acc: 97.66%] [G loss: 7.032964]\n",
      "epoch:39 step:30743 [D loss: 0.105144, acc: 100.00%] [G loss: 7.344697]\n",
      "epoch:39 step:30744 [D loss: 0.564863, acc: 71.09%] [G loss: 4.411443]\n",
      "epoch:39 step:30745 [D loss: 0.606662, acc: 60.94%] [G loss: 6.533231]\n",
      "epoch:39 step:30746 [D loss: 0.364518, acc: 88.28%] [G loss: 6.147568]\n",
      "epoch:39 step:30747 [D loss: 0.264166, acc: 90.62%] [G loss: 5.138738]\n",
      "epoch:39 step:30748 [D loss: 0.714752, acc: 54.69%] [G loss: 9.384288]\n",
      "epoch:39 step:30749 [D loss: 0.314450, acc: 85.16%] [G loss: 6.148162]\n",
      "epoch:39 step:30750 [D loss: 0.100894, acc: 99.22%] [G loss: 3.509466]\n",
      "epoch:39 step:30751 [D loss: 0.128828, acc: 98.44%] [G loss: 4.452104]\n",
      "epoch:39 step:30752 [D loss: 0.489557, acc: 78.12%] [G loss: 6.266096]\n",
      "epoch:39 step:30753 [D loss: 0.167334, acc: 94.53%] [G loss: 3.269582]\n",
      "epoch:39 step:30754 [D loss: 0.808483, acc: 50.78%] [G loss: 4.017694]\n",
      "epoch:39 step:30755 [D loss: 0.010682, acc: 100.00%] [G loss: 8.321609]\n",
      "epoch:39 step:30756 [D loss: 0.572756, acc: 72.66%] [G loss: 7.868382]\n",
      "epoch:39 step:30757 [D loss: 0.864126, acc: 50.78%] [G loss: 7.707986]\n",
      "epoch:39 step:30758 [D loss: 0.129629, acc: 100.00%] [G loss: 5.260803]\n",
      "epoch:39 step:30759 [D loss: 0.357810, acc: 85.16%] [G loss: 5.607589]\n",
      "epoch:39 step:30760 [D loss: 0.185449, acc: 97.66%] [G loss: 6.600353]\n",
      "epoch:39 step:30761 [D loss: 0.089681, acc: 99.22%] [G loss: 6.042056]\n",
      "epoch:39 step:30762 [D loss: 0.129987, acc: 99.22%] [G loss: 6.424849]\n",
      "epoch:39 step:30763 [D loss: 0.086332, acc: 100.00%] [G loss: 5.472575]\n",
      "epoch:39 step:30764 [D loss: 0.090563, acc: 100.00%] [G loss: 4.567430]\n",
      "epoch:39 step:30765 [D loss: 0.403756, acc: 73.44%] [G loss: 6.521954]\n",
      "epoch:39 step:30766 [D loss: 0.190628, acc: 98.44%] [G loss: 4.598860]\n",
      "epoch:39 step:30767 [D loss: 0.291875, acc: 92.19%] [G loss: 6.103709]\n",
      "epoch:39 step:30768 [D loss: 0.863066, acc: 53.91%] [G loss: 5.103777]\n",
      "epoch:39 step:30769 [D loss: 0.179231, acc: 97.66%] [G loss: 7.397523]\n",
      "epoch:39 step:30770 [D loss: 1.472581, acc: 50.00%] [G loss: 6.213667]\n",
      "epoch:39 step:30771 [D loss: 0.456848, acc: 73.44%] [G loss: 6.188065]\n",
      "epoch:39 step:30772 [D loss: 0.053687, acc: 100.00%] [G loss: 3.378400]\n",
      "epoch:39 step:30773 [D loss: 1.085832, acc: 50.00%] [G loss: 5.778918]\n",
      "epoch:39 step:30774 [D loss: 0.632890, acc: 67.19%] [G loss: 4.593080]\n",
      "epoch:39 step:30775 [D loss: 0.495484, acc: 82.03%] [G loss: 5.169232]\n",
      "epoch:39 step:30776 [D loss: 0.384192, acc: 87.50%] [G loss: 5.368014]\n",
      "epoch:39 step:30777 [D loss: 0.738726, acc: 57.03%] [G loss: 7.692941]\n",
      "epoch:39 step:30778 [D loss: 0.622878, acc: 62.50%] [G loss: 4.354568]\n",
      "epoch:39 step:30779 [D loss: 0.261170, acc: 95.31%] [G loss: 4.657650]\n",
      "epoch:39 step:30780 [D loss: 0.145395, acc: 100.00%] [G loss: 6.424486]\n",
      "epoch:39 step:30781 [D loss: 0.569133, acc: 62.50%] [G loss: 6.272483]\n",
      "epoch:39 step:30782 [D loss: 0.192137, acc: 99.22%] [G loss: 3.867772]\n",
      "epoch:39 step:30783 [D loss: 0.677192, acc: 60.94%] [G loss: 5.586205]\n",
      "epoch:39 step:30784 [D loss: 0.807929, acc: 53.12%] [G loss: 10.642963]\n",
      "epoch:39 step:30785 [D loss: 0.041213, acc: 100.00%] [G loss: 2.792815]\n",
      "epoch:39 step:30786 [D loss: 0.197080, acc: 98.44%] [G loss: 4.528077]\n",
      "epoch:39 step:30787 [D loss: 1.170359, acc: 39.84%] [G loss: 5.645066]\n",
      "epoch:39 step:30788 [D loss: 0.038240, acc: 100.00%] [G loss: 5.107877]\n",
      "epoch:39 step:30789 [D loss: 0.095228, acc: 99.22%] [G loss: 2.865499]\n",
      "epoch:39 step:30790 [D loss: 0.068517, acc: 100.00%] [G loss: 3.097964]\n",
      "epoch:39 step:30791 [D loss: 0.445264, acc: 79.69%] [G loss: 7.126515]\n",
      "epoch:39 step:30792 [D loss: 0.332382, acc: 81.25%] [G loss: 7.635267]\n",
      "epoch:39 step:30793 [D loss: 0.162926, acc: 97.66%] [G loss: 1.441071]\n",
      "epoch:39 step:30794 [D loss: 0.133486, acc: 98.44%] [G loss: 3.980478]\n",
      "epoch:39 step:30795 [D loss: 0.030070, acc: 100.00%] [G loss: 7.645441]\n",
      "epoch:39 step:30796 [D loss: 0.453274, acc: 75.00%] [G loss: 5.939956]\n",
      "epoch:39 step:30797 [D loss: 0.783129, acc: 53.12%] [G loss: 6.503557]\n",
      "epoch:39 step:30798 [D loss: 1.203705, acc: 50.00%] [G loss: 3.752162]\n",
      "epoch:39 step:30799 [D loss: 0.531229, acc: 63.28%] [G loss: 4.754500]\n",
      "epoch:39 step:30800 [D loss: 1.048433, acc: 50.00%] [G loss: 5.270456]\n",
      "##############\n",
      "[0.85889303 0.88975171 0.8092972  0.80819916 0.78364239 0.82401998\n",
      " 0.87206401 0.82497228 0.77689569 0.83016369]\n",
      "##########\n",
      "epoch:39 step:30801 [D loss: 0.498339, acc: 65.62%] [G loss: 5.057683]\n",
      "epoch:39 step:30802 [D loss: 0.442414, acc: 72.66%] [G loss: 5.793921]\n",
      "epoch:39 step:30803 [D loss: 0.647259, acc: 57.03%] [G loss: 7.300360]\n",
      "epoch:39 step:30804 [D loss: 0.132491, acc: 97.66%] [G loss: 3.995278]\n",
      "epoch:39 step:30805 [D loss: 0.482300, acc: 70.31%] [G loss: 6.915514]\n",
      "epoch:39 step:30806 [D loss: 0.064805, acc: 100.00%] [G loss: 3.349471]\n",
      "epoch:39 step:30807 [D loss: 0.064873, acc: 100.00%] [G loss: 5.992548]\n",
      "epoch:39 step:30808 [D loss: 0.488586, acc: 66.41%] [G loss: 6.611322]\n",
      "epoch:39 step:30809 [D loss: 1.197156, acc: 50.00%] [G loss: 6.623187]\n",
      "epoch:39 step:30810 [D loss: 0.180284, acc: 96.09%] [G loss: 4.151505]\n",
      "epoch:39 step:30811 [D loss: 0.173804, acc: 95.31%] [G loss: 7.523090]\n",
      "epoch:39 step:30812 [D loss: 0.067906, acc: 100.00%] [G loss: 6.655735]\n",
      "epoch:39 step:30813 [D loss: 0.795850, acc: 53.12%] [G loss: 7.005245]\n",
      "epoch:39 step:30814 [D loss: 0.235100, acc: 98.44%] [G loss: 3.910052]\n",
      "epoch:39 step:30815 [D loss: 0.379687, acc: 78.12%] [G loss: 3.853416]\n",
      "epoch:39 step:30816 [D loss: 0.161934, acc: 96.09%] [G loss: 5.731446]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:39 step:30817 [D loss: 0.123060, acc: 99.22%] [G loss: 5.361921]\n",
      "epoch:39 step:30818 [D loss: 0.189199, acc: 96.09%] [G loss: 5.595381]\n",
      "epoch:39 step:30819 [D loss: 0.631160, acc: 65.62%] [G loss: 4.526386]\n",
      "epoch:39 step:30820 [D loss: 0.031552, acc: 100.00%] [G loss: 7.909519]\n",
      "epoch:39 step:30821 [D loss: 1.404005, acc: 50.00%] [G loss: 7.634643]\n",
      "epoch:39 step:30822 [D loss: 1.131779, acc: 52.34%] [G loss: 5.077540]\n",
      "epoch:39 step:30823 [D loss: 0.135500, acc: 99.22%] [G loss: 6.996148]\n",
      "epoch:39 step:30824 [D loss: 1.105712, acc: 50.00%] [G loss: 5.984910]\n",
      "epoch:39 step:30825 [D loss: 0.466637, acc: 70.31%] [G loss: 6.662264]\n",
      "epoch:39 step:30826 [D loss: 0.029926, acc: 100.00%] [G loss: 4.812466]\n",
      "epoch:39 step:30827 [D loss: 0.129610, acc: 100.00%] [G loss: 6.796710]\n",
      "epoch:39 step:30828 [D loss: 1.244612, acc: 21.09%] [G loss: 6.020914]\n",
      "epoch:39 step:30829 [D loss: 0.136791, acc: 97.66%] [G loss: 8.188504]\n",
      "epoch:39 step:30830 [D loss: 0.139478, acc: 100.00%] [G loss: 7.373571]\n",
      "epoch:39 step:30831 [D loss: 0.649688, acc: 57.81%] [G loss: 6.116697]\n",
      "epoch:39 step:30832 [D loss: 0.096132, acc: 100.00%] [G loss: 3.924556]\n",
      "epoch:39 step:30833 [D loss: 0.384596, acc: 86.72%] [G loss: 3.693620]\n",
      "epoch:39 step:30834 [D loss: 0.223976, acc: 96.88%] [G loss: 2.653581]\n",
      "epoch:39 step:30835 [D loss: 0.435146, acc: 78.12%] [G loss: 8.848244]\n",
      "epoch:39 step:30836 [D loss: 0.236958, acc: 93.75%] [G loss: 4.985682]\n",
      "epoch:39 step:30837 [D loss: 0.099415, acc: 100.00%] [G loss: 5.786319]\n",
      "epoch:39 step:30838 [D loss: 0.025626, acc: 100.00%] [G loss: 6.570300]\n",
      "epoch:39 step:30839 [D loss: 0.018175, acc: 100.00%] [G loss: 6.452694]\n",
      "epoch:39 step:30840 [D loss: 0.335206, acc: 83.59%] [G loss: 9.775782]\n",
      "epoch:39 step:30841 [D loss: 0.092988, acc: 99.22%] [G loss: 9.022538]\n",
      "epoch:39 step:30842 [D loss: 0.067857, acc: 100.00%] [G loss: 3.834830]\n",
      "epoch:39 step:30843 [D loss: 0.515428, acc: 66.41%] [G loss: 3.842029]\n",
      "epoch:39 step:30844 [D loss: 0.231914, acc: 95.31%] [G loss: 4.037717]\n",
      "epoch:39 step:30845 [D loss: 0.077212, acc: 100.00%] [G loss: 4.973619]\n",
      "epoch:39 step:30846 [D loss: 0.247882, acc: 94.53%] [G loss: 4.189143]\n",
      "epoch:39 step:30847 [D loss: 1.439021, acc: 49.22%] [G loss: 5.186869]\n",
      "epoch:39 step:30848 [D loss: 0.497169, acc: 74.22%] [G loss: 5.552301]\n",
      "epoch:39 step:30849 [D loss: 1.862428, acc: 26.56%] [G loss: 7.363836]\n",
      "epoch:39 step:30850 [D loss: 0.655039, acc: 56.25%] [G loss: 5.857992]\n",
      "epoch:39 step:30851 [D loss: 0.579527, acc: 64.06%] [G loss: 5.942381]\n",
      "epoch:39 step:30852 [D loss: 1.211058, acc: 28.91%] [G loss: 5.316962]\n",
      "epoch:39 step:30853 [D loss: 0.226710, acc: 91.41%] [G loss: 5.384734]\n",
      "epoch:39 step:30854 [D loss: 0.512620, acc: 75.00%] [G loss: 6.328329]\n",
      "epoch:39 step:30855 [D loss: 0.414365, acc: 73.44%] [G loss: 5.661100]\n",
      "epoch:39 step:30856 [D loss: 0.111017, acc: 97.66%] [G loss: 10.148388]\n",
      "epoch:39 step:30857 [D loss: 1.207111, acc: 50.78%] [G loss: 4.468502]\n",
      "epoch:39 step:30858 [D loss: 0.225471, acc: 94.53%] [G loss: 5.802711]\n",
      "epoch:39 step:30859 [D loss: 0.031216, acc: 100.00%] [G loss: 6.835810]\n",
      "epoch:39 step:30860 [D loss: 0.004302, acc: 100.00%] [G loss: 7.023978]\n",
      "epoch:39 step:30861 [D loss: 0.056239, acc: 99.22%] [G loss: 5.354392]\n",
      "epoch:39 step:30862 [D loss: 0.414412, acc: 86.72%] [G loss: 5.782399]\n",
      "epoch:39 step:30863 [D loss: 0.840514, acc: 49.22%] [G loss: 3.257878]\n",
      "epoch:39 step:30864 [D loss: 0.410138, acc: 87.50%] [G loss: 4.374689]\n",
      "epoch:39 step:30865 [D loss: 0.357144, acc: 78.91%] [G loss: 7.389323]\n",
      "epoch:39 step:30866 [D loss: 0.256455, acc: 89.84%] [G loss: 4.296722]\n",
      "epoch:39 step:30867 [D loss: 0.096760, acc: 100.00%] [G loss: 6.500653]\n",
      "epoch:39 step:30868 [D loss: 0.674315, acc: 52.34%] [G loss: 6.635950]\n",
      "epoch:39 step:30869 [D loss: 0.099340, acc: 100.00%] [G loss: 2.810322]\n",
      "epoch:39 step:30870 [D loss: 0.272677, acc: 91.41%] [G loss: 3.200872]\n",
      "epoch:39 step:30871 [D loss: 0.217136, acc: 91.41%] [G loss: 7.375332]\n",
      "epoch:39 step:30872 [D loss: 0.128342, acc: 98.44%] [G loss: 4.530189]\n",
      "epoch:39 step:30873 [D loss: 0.577502, acc: 72.66%] [G loss: 8.083465]\n",
      "epoch:39 step:30874 [D loss: 0.150662, acc: 100.00%] [G loss: 5.222796]\n",
      "epoch:39 step:30875 [D loss: 0.067329, acc: 99.22%] [G loss: 6.584124]\n",
      "epoch:39 step:30876 [D loss: 0.118453, acc: 98.44%] [G loss: 9.244671]\n",
      "epoch:39 step:30877 [D loss: 0.708629, acc: 55.47%] [G loss: 3.846983]\n",
      "epoch:39 step:30878 [D loss: 0.254827, acc: 91.41%] [G loss: 3.529176]\n",
      "epoch:39 step:30879 [D loss: 0.077079, acc: 100.00%] [G loss: 6.007973]\n",
      "epoch:39 step:30880 [D loss: 0.411514, acc: 70.31%] [G loss: 6.895401]\n",
      "epoch:39 step:30881 [D loss: 0.215912, acc: 94.53%] [G loss: 7.604695]\n",
      "epoch:39 step:30882 [D loss: 0.349711, acc: 85.16%] [G loss: 6.647282]\n",
      "epoch:39 step:30883 [D loss: 0.179201, acc: 99.22%] [G loss: 7.038617]\n",
      "epoch:39 step:30884 [D loss: 0.963892, acc: 46.88%] [G loss: 7.744340]\n",
      "epoch:39 step:30885 [D loss: 0.902586, acc: 54.69%] [G loss: 4.854068]\n",
      "epoch:39 step:30886 [D loss: 0.925105, acc: 35.94%] [G loss: 7.716708]\n",
      "epoch:39 step:30887 [D loss: 0.616553, acc: 62.50%] [G loss: 10.121153]\n",
      "epoch:39 step:30888 [D loss: 0.329165, acc: 90.62%] [G loss: 6.460284]\n",
      "epoch:39 step:30889 [D loss: 0.065262, acc: 100.00%] [G loss: 4.302280]\n",
      "epoch:39 step:30890 [D loss: 0.706219, acc: 55.47%] [G loss: 8.718592]\n",
      "epoch:39 step:30891 [D loss: 0.398122, acc: 78.91%] [G loss: 6.334921]\n",
      "epoch:39 step:30892 [D loss: 0.122693, acc: 100.00%] [G loss: 3.213599]\n",
      "epoch:39 step:30893 [D loss: 0.270082, acc: 91.41%] [G loss: 6.761980]\n",
      "epoch:39 step:30894 [D loss: 0.208868, acc: 96.88%] [G loss: 4.680299]\n",
      "epoch:39 step:30895 [D loss: 0.150546, acc: 100.00%] [G loss: 3.280278]\n",
      "epoch:39 step:30896 [D loss: 0.451103, acc: 79.69%] [G loss: 4.298752]\n",
      "epoch:39 step:30897 [D loss: 0.319796, acc: 86.72%] [G loss: 4.760611]\n",
      "epoch:39 step:30898 [D loss: 0.397794, acc: 88.28%] [G loss: 5.133722]\n",
      "epoch:39 step:30899 [D loss: 0.276218, acc: 88.28%] [G loss: 3.898537]\n",
      "epoch:39 step:30900 [D loss: 0.889254, acc: 53.12%] [G loss: 5.666182]\n",
      "epoch:39 step:30901 [D loss: 0.157928, acc: 98.44%] [G loss: 7.748291]\n",
      "epoch:39 step:30902 [D loss: 0.284678, acc: 86.72%] [G loss: 10.531569]\n",
      "epoch:39 step:30903 [D loss: 0.315276, acc: 94.53%] [G loss: 6.988135]\n",
      "epoch:39 step:30904 [D loss: 0.125600, acc: 99.22%] [G loss: 6.605778]\n",
      "epoch:39 step:30905 [D loss: 0.139768, acc: 100.00%] [G loss: 6.313175]\n",
      "epoch:39 step:30906 [D loss: 0.106956, acc: 100.00%] [G loss: 4.490675]\n",
      "epoch:39 step:30907 [D loss: 0.101928, acc: 98.44%] [G loss: 4.574182]\n",
      "epoch:39 step:30908 [D loss: 0.035631, acc: 100.00%] [G loss: 6.112936]\n",
      "epoch:39 step:30909 [D loss: 0.031840, acc: 100.00%] [G loss: 4.935977]\n",
      "epoch:39 step:30910 [D loss: 0.305556, acc: 91.41%] [G loss: 5.549391]\n",
      "epoch:39 step:30911 [D loss: 0.384233, acc: 78.91%] [G loss: 2.833910]\n",
      "epoch:39 step:30912 [D loss: 0.345735, acc: 89.06%] [G loss: 5.354812]\n",
      "epoch:39 step:30913 [D loss: 0.164561, acc: 97.66%] [G loss: 4.500165]\n",
      "epoch:39 step:30914 [D loss: 0.443051, acc: 70.31%] [G loss: 7.786295]\n",
      "epoch:39 step:30915 [D loss: 0.396075, acc: 89.06%] [G loss: 5.576605]\n",
      "epoch:39 step:30916 [D loss: 0.316114, acc: 92.97%] [G loss: 2.847651]\n",
      "epoch:39 step:30917 [D loss: 0.141682, acc: 98.44%] [G loss: 7.634970]\n",
      "epoch:39 step:30918 [D loss: 0.111092, acc: 99.22%] [G loss: 4.262892]\n",
      "epoch:39 step:30919 [D loss: 0.064168, acc: 99.22%] [G loss: 5.754417]\n",
      "epoch:39 step:30920 [D loss: 0.022988, acc: 100.00%] [G loss: 9.686766]\n",
      "epoch:39 step:30921 [D loss: 0.082947, acc: 99.22%] [G loss: 4.780801]\n",
      "epoch:39 step:30922 [D loss: 0.099763, acc: 100.00%] [G loss: 8.994802]\n",
      "epoch:39 step:30923 [D loss: 0.040264, acc: 100.00%] [G loss: 10.917860]\n",
      "epoch:39 step:30924 [D loss: 0.965574, acc: 39.84%] [G loss: 5.843022]\n",
      "epoch:39 step:30925 [D loss: 0.136486, acc: 98.44%] [G loss: 8.567291]\n",
      "epoch:39 step:30926 [D loss: 0.581256, acc: 69.53%] [G loss: 6.345591]\n",
      "epoch:39 step:30927 [D loss: 0.206426, acc: 96.09%] [G loss: 8.152443]\n",
      "epoch:39 step:30928 [D loss: 0.174182, acc: 97.66%] [G loss: 7.680564]\n",
      "epoch:39 step:30929 [D loss: 1.201238, acc: 51.56%] [G loss: 6.194085]\n",
      "epoch:39 step:30930 [D loss: 0.970825, acc: 51.56%] [G loss: 9.406713]\n",
      "epoch:39 step:30931 [D loss: 0.178813, acc: 97.66%] [G loss: 6.141892]\n",
      "epoch:39 step:30932 [D loss: 0.541060, acc: 73.44%] [G loss: 4.701618]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:39 step:30933 [D loss: 0.523458, acc: 66.41%] [G loss: 4.870537]\n",
      "epoch:39 step:30934 [D loss: 0.387124, acc: 77.34%] [G loss: 5.685417]\n",
      "epoch:39 step:30935 [D loss: 0.200912, acc: 96.09%] [G loss: 5.943318]\n",
      "epoch:39 step:30936 [D loss: 0.118590, acc: 99.22%] [G loss: 5.768182]\n",
      "epoch:39 step:30937 [D loss: 0.034076, acc: 100.00%] [G loss: 7.471357]\n",
      "epoch:39 step:30938 [D loss: 0.271282, acc: 96.88%] [G loss: 3.520363]\n",
      "epoch:39 step:30939 [D loss: 0.485821, acc: 68.75%] [G loss: 4.516720]\n",
      "epoch:39 step:30940 [D loss: 0.187598, acc: 98.44%] [G loss: 4.618056]\n",
      "epoch:39 step:30941 [D loss: 0.378258, acc: 75.00%] [G loss: 2.659951]\n",
      "epoch:39 step:30942 [D loss: 0.978473, acc: 36.72%] [G loss: 7.015972]\n",
      "epoch:39 step:30943 [D loss: 1.035925, acc: 29.69%] [G loss: 2.987603]\n",
      "epoch:39 step:30944 [D loss: 0.879824, acc: 46.88%] [G loss: 6.989715]\n",
      "epoch:39 step:30945 [D loss: 0.973456, acc: 32.81%] [G loss: 4.073891]\n",
      "epoch:39 step:30946 [D loss: 0.125217, acc: 99.22%] [G loss: 7.309114]\n",
      "epoch:39 step:30947 [D loss: 0.126589, acc: 99.22%] [G loss: 7.202305]\n",
      "epoch:39 step:30948 [D loss: 0.569859, acc: 62.50%] [G loss: 7.987467]\n",
      "epoch:39 step:30949 [D loss: 0.430125, acc: 70.31%] [G loss: 8.283104]\n",
      "epoch:39 step:30950 [D loss: 0.358298, acc: 89.06%] [G loss: 3.783278]\n",
      "epoch:39 step:30951 [D loss: 0.150309, acc: 100.00%] [G loss: 7.333876]\n",
      "epoch:39 step:30952 [D loss: 0.638949, acc: 60.94%] [G loss: 10.928046]\n",
      "epoch:39 step:30953 [D loss: 0.204161, acc: 96.09%] [G loss: 4.919998]\n",
      "epoch:39 step:30954 [D loss: 0.291861, acc: 92.19%] [G loss: 8.126216]\n",
      "epoch:39 step:30955 [D loss: 0.375325, acc: 89.84%] [G loss: 5.208196]\n",
      "epoch:39 step:30956 [D loss: 0.572717, acc: 61.72%] [G loss: 8.575560]\n",
      "epoch:39 step:30957 [D loss: 0.526565, acc: 65.62%] [G loss: 8.040760]\n",
      "epoch:39 step:30958 [D loss: 0.139010, acc: 99.22%] [G loss: 8.130080]\n",
      "epoch:39 step:30959 [D loss: 0.512141, acc: 78.91%] [G loss: 8.295323]\n",
      "epoch:39 step:30960 [D loss: 0.182381, acc: 97.66%] [G loss: 6.032279]\n",
      "epoch:39 step:30961 [D loss: 0.980018, acc: 37.50%] [G loss: 7.889880]\n",
      "epoch:39 step:30962 [D loss: 0.178429, acc: 99.22%] [G loss: 6.240596]\n",
      "epoch:39 step:30963 [D loss: 0.354287, acc: 79.69%] [G loss: 4.713221]\n",
      "epoch:39 step:30964 [D loss: 0.837384, acc: 52.34%] [G loss: 6.202106]\n",
      "epoch:39 step:30965 [D loss: 0.332522, acc: 89.06%] [G loss: 2.688716]\n",
      "epoch:39 step:30966 [D loss: 0.203560, acc: 96.09%] [G loss: 5.013250]\n",
      "epoch:39 step:30967 [D loss: 0.690852, acc: 57.03%] [G loss: 4.816536]\n",
      "epoch:39 step:30968 [D loss: 0.280932, acc: 93.75%] [G loss: 4.610404]\n",
      "epoch:39 step:30969 [D loss: 0.502715, acc: 73.44%] [G loss: 3.879234]\n",
      "epoch:39 step:30970 [D loss: 1.133798, acc: 50.78%] [G loss: 7.185760]\n",
      "epoch:39 step:30971 [D loss: 0.091410, acc: 99.22%] [G loss: 5.805227]\n",
      "epoch:39 step:30972 [D loss: 0.857897, acc: 52.34%] [G loss: 11.326540]\n",
      "epoch:39 step:30973 [D loss: 0.300411, acc: 89.84%] [G loss: 7.889105]\n",
      "epoch:39 step:30974 [D loss: 0.285176, acc: 84.38%] [G loss: 5.462766]\n",
      "epoch:39 step:30975 [D loss: 0.296839, acc: 92.97%] [G loss: 8.433394]\n",
      "epoch:39 step:30976 [D loss: 0.135412, acc: 96.88%] [G loss: 8.647829]\n",
      "epoch:39 step:30977 [D loss: 0.227017, acc: 96.09%] [G loss: 4.616584]\n",
      "epoch:39 step:30978 [D loss: 0.150834, acc: 98.44%] [G loss: 5.384213]\n",
      "epoch:39 step:30979 [D loss: 0.660258, acc: 60.94%] [G loss: 5.327116]\n",
      "epoch:39 step:30980 [D loss: 0.320396, acc: 80.47%] [G loss: 6.696195]\n",
      "epoch:39 step:30981 [D loss: 0.732654, acc: 52.34%] [G loss: 8.264296]\n",
      "epoch:39 step:30982 [D loss: 0.168795, acc: 100.00%] [G loss: 5.828840]\n",
      "epoch:39 step:30983 [D loss: 0.036612, acc: 100.00%] [G loss: 4.681664]\n",
      "epoch:39 step:30984 [D loss: 0.243111, acc: 93.75%] [G loss: 3.788271]\n",
      "epoch:39 step:30985 [D loss: 0.052618, acc: 100.00%] [G loss: 5.590794]\n",
      "epoch:39 step:30986 [D loss: 0.250258, acc: 88.28%] [G loss: 7.330256]\n",
      "epoch:39 step:30987 [D loss: 0.481707, acc: 75.78%] [G loss: 3.711704]\n",
      "epoch:39 step:30988 [D loss: 0.131577, acc: 100.00%] [G loss: 6.709991]\n",
      "epoch:39 step:30989 [D loss: 0.488959, acc: 79.69%] [G loss: 8.557198]\n",
      "epoch:39 step:30990 [D loss: 0.481319, acc: 65.62%] [G loss: 3.840198]\n",
      "epoch:39 step:30991 [D loss: 0.192402, acc: 98.44%] [G loss: 6.201512]\n",
      "epoch:39 step:30992 [D loss: 0.871998, acc: 42.19%] [G loss: 9.139627]\n",
      "epoch:39 step:30993 [D loss: 0.295053, acc: 92.97%] [G loss: 4.018852]\n",
      "epoch:39 step:30994 [D loss: 0.431976, acc: 79.69%] [G loss: 5.451660]\n",
      "epoch:39 step:30995 [D loss: 0.589015, acc: 67.97%] [G loss: 3.076738]\n",
      "epoch:39 step:30996 [D loss: 0.097639, acc: 99.22%] [G loss: 5.232726]\n",
      "epoch:39 step:30997 [D loss: 0.032067, acc: 100.00%] [G loss: 4.781476]\n",
      "epoch:39 step:30998 [D loss: 0.188483, acc: 98.44%] [G loss: 6.938353]\n",
      "epoch:39 step:30999 [D loss: 1.170762, acc: 39.84%] [G loss: 5.656116]\n",
      "epoch:39 step:31000 [D loss: 0.085776, acc: 100.00%] [G loss: 5.437685]\n",
      "##############\n",
      "[0.86035575 0.86412106 0.81593796 0.79945636 0.8020637  0.80679555\n",
      " 0.87917648 0.81072863 0.82812188 0.82739152]\n",
      "##########\n",
      "epoch:39 step:31001 [D loss: 0.840764, acc: 52.34%] [G loss: 4.133835]\n",
      "epoch:39 step:31002 [D loss: 0.101166, acc: 100.00%] [G loss: 6.283680]\n",
      "epoch:39 step:31003 [D loss: 0.384441, acc: 81.25%] [G loss: 5.278662]\n",
      "epoch:39 step:31004 [D loss: 0.306464, acc: 88.28%] [G loss: 5.214000]\n",
      "epoch:39 step:31005 [D loss: 0.724597, acc: 59.38%] [G loss: 6.119713]\n",
      "epoch:39 step:31006 [D loss: 0.312768, acc: 95.31%] [G loss: 5.708606]\n",
      "epoch:39 step:31007 [D loss: 0.081492, acc: 100.00%] [G loss: 4.061473]\n",
      "epoch:39 step:31008 [D loss: 0.578945, acc: 72.66%] [G loss: 4.824238]\n",
      "epoch:39 step:31009 [D loss: 0.244829, acc: 94.53%] [G loss: 4.472025]\n",
      "epoch:39 step:31010 [D loss: 0.217597, acc: 99.22%] [G loss: 9.440113]\n",
      "epoch:39 step:31011 [D loss: 0.660965, acc: 57.03%] [G loss: 6.779308]\n",
      "epoch:39 step:31012 [D loss: 0.859177, acc: 52.34%] [G loss: 7.352103]\n",
      "epoch:39 step:31013 [D loss: 0.673246, acc: 55.47%] [G loss: 7.290870]\n",
      "epoch:39 step:31014 [D loss: 0.032663, acc: 100.00%] [G loss: 2.370332]\n",
      "epoch:39 step:31015 [D loss: 0.282582, acc: 89.06%] [G loss: 5.938503]\n",
      "epoch:39 step:31016 [D loss: 0.283290, acc: 92.97%] [G loss: 3.432593]\n",
      "epoch:39 step:31017 [D loss: 0.245528, acc: 94.53%] [G loss: 3.302940]\n",
      "epoch:39 step:31018 [D loss: 0.171887, acc: 96.09%] [G loss: 5.211682]\n",
      "epoch:39 step:31019 [D loss: 0.478385, acc: 73.44%] [G loss: 6.270987]\n",
      "epoch:39 step:31020 [D loss: 0.006764, acc: 100.00%] [G loss: 6.403522]\n",
      "epoch:39 step:31021 [D loss: 0.202679, acc: 97.66%] [G loss: 5.181647]\n",
      "epoch:39 step:31022 [D loss: 0.083894, acc: 100.00%] [G loss: 3.372487]\n",
      "epoch:39 step:31023 [D loss: 0.350485, acc: 79.69%] [G loss: 8.856959]\n",
      "epoch:39 step:31024 [D loss: 0.109005, acc: 100.00%] [G loss: 3.754371]\n",
      "epoch:39 step:31025 [D loss: 0.191811, acc: 97.66%] [G loss: 3.808210]\n",
      "epoch:39 step:31026 [D loss: 0.194444, acc: 96.88%] [G loss: 6.752271]\n",
      "epoch:39 step:31027 [D loss: 0.929882, acc: 50.00%] [G loss: 5.690311]\n",
      "epoch:39 step:31028 [D loss: 0.165485, acc: 99.22%] [G loss: 4.893005]\n",
      "epoch:39 step:31029 [D loss: 1.183638, acc: 28.12%] [G loss: 4.219864]\n",
      "epoch:39 step:31030 [D loss: 0.366454, acc: 79.69%] [G loss: 7.050436]\n",
      "epoch:39 step:31031 [D loss: 0.147542, acc: 99.22%] [G loss: 6.445645]\n",
      "epoch:39 step:31032 [D loss: 0.189103, acc: 97.66%] [G loss: 6.971275]\n",
      "epoch:39 step:31033 [D loss: 0.600022, acc: 64.06%] [G loss: 7.906590]\n",
      "epoch:39 step:31034 [D loss: 0.613684, acc: 60.94%] [G loss: 6.271527]\n",
      "epoch:39 step:31035 [D loss: 0.154019, acc: 97.66%] [G loss: 4.420864]\n",
      "epoch:39 step:31036 [D loss: 0.062897, acc: 100.00%] [G loss: 6.915712]\n",
      "epoch:39 step:31037 [D loss: 0.187908, acc: 97.66%] [G loss: 5.905940]\n",
      "epoch:39 step:31038 [D loss: 0.662393, acc: 63.28%] [G loss: 5.897230]\n",
      "epoch:39 step:31039 [D loss: 0.198484, acc: 96.09%] [G loss: 6.200477]\n",
      "epoch:39 step:31040 [D loss: 0.093060, acc: 99.22%] [G loss: 4.587552]\n",
      "epoch:39 step:31041 [D loss: 0.853661, acc: 54.69%] [G loss: 5.000373]\n",
      "epoch:39 step:31042 [D loss: 0.027097, acc: 100.00%] [G loss: 4.884479]\n",
      "epoch:39 step:31043 [D loss: 0.066368, acc: 100.00%] [G loss: 3.229615]\n",
      "epoch:39 step:31044 [D loss: 0.032311, acc: 100.00%] [G loss: 8.078979]\n",
      "epoch:39 step:31045 [D loss: 0.183704, acc: 97.66%] [G loss: 4.815791]\n",
      "epoch:39 step:31046 [D loss: 0.214200, acc: 96.09%] [G loss: 5.110016]\n",
      "epoch:39 step:31047 [D loss: 0.038058, acc: 100.00%] [G loss: 6.756783]\n",
      "epoch:39 step:31048 [D loss: 0.284852, acc: 92.19%] [G loss: 5.558513]\n",
      "epoch:39 step:31049 [D loss: 0.200446, acc: 95.31%] [G loss: 5.131342]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:39 step:31050 [D loss: 0.261459, acc: 95.31%] [G loss: 4.263216]\n",
      "epoch:39 step:31051 [D loss: 0.035965, acc: 100.00%] [G loss: 4.630241]\n",
      "epoch:39 step:31052 [D loss: 0.166413, acc: 98.44%] [G loss: 6.842939]\n",
      "epoch:39 step:31053 [D loss: 0.401959, acc: 78.12%] [G loss: 3.682141]\n",
      "epoch:39 step:31054 [D loss: 0.751930, acc: 53.12%] [G loss: 5.710304]\n",
      "epoch:39 step:31055 [D loss: 0.148228, acc: 98.44%] [G loss: 2.706431]\n",
      "epoch:39 step:31056 [D loss: 0.102132, acc: 100.00%] [G loss: 4.268122]\n",
      "epoch:39 step:31057 [D loss: 0.605552, acc: 57.81%] [G loss: 7.756533]\n",
      "epoch:39 step:31058 [D loss: 0.313704, acc: 91.41%] [G loss: 2.489755]\n",
      "epoch:39 step:31059 [D loss: 0.351202, acc: 80.47%] [G loss: 5.594867]\n",
      "epoch:39 step:31060 [D loss: 0.092382, acc: 100.00%] [G loss: 4.848786]\n",
      "epoch:39 step:31061 [D loss: 0.129896, acc: 99.22%] [G loss: 5.006797]\n",
      "epoch:39 step:31062 [D loss: 0.910567, acc: 52.34%] [G loss: 7.695164]\n",
      "epoch:39 step:31063 [D loss: 0.044385, acc: 100.00%] [G loss: 5.698951]\n",
      "epoch:39 step:31064 [D loss: 0.364024, acc: 90.62%] [G loss: 5.393858]\n",
      "epoch:39 step:31065 [D loss: 0.372871, acc: 91.41%] [G loss: 4.982915]\n",
      "epoch:39 step:31066 [D loss: 0.418939, acc: 86.72%] [G loss: 4.887099]\n",
      "epoch:39 step:31067 [D loss: 0.565149, acc: 64.84%] [G loss: 4.065240]\n",
      "epoch:39 step:31068 [D loss: 0.166181, acc: 97.66%] [G loss: 4.900280]\n",
      "epoch:39 step:31069 [D loss: 0.075701, acc: 100.00%] [G loss: 3.107010]\n",
      "epoch:39 step:31070 [D loss: 0.077115, acc: 100.00%] [G loss: 7.203686]\n",
      "epoch:39 step:31071 [D loss: 0.145450, acc: 97.66%] [G loss: 4.588905]\n",
      "epoch:39 step:31072 [D loss: 0.406599, acc: 87.50%] [G loss: 5.518517]\n",
      "epoch:39 step:31073 [D loss: 0.023807, acc: 100.00%] [G loss: 7.563762]\n",
      "epoch:39 step:31074 [D loss: 0.337238, acc: 92.19%] [G loss: 6.817706]\n",
      "epoch:39 step:31075 [D loss: 0.061761, acc: 100.00%] [G loss: 8.519290]\n",
      "epoch:39 step:31076 [D loss: 0.315479, acc: 85.94%] [G loss: 2.817349]\n",
      "epoch:39 step:31077 [D loss: 0.177088, acc: 97.66%] [G loss: 3.826596]\n",
      "epoch:39 step:31078 [D loss: 0.039354, acc: 100.00%] [G loss: 1.849235]\n",
      "epoch:39 step:31079 [D loss: 0.476073, acc: 71.09%] [G loss: 4.229698]\n",
      "epoch:39 step:31080 [D loss: 0.384357, acc: 88.28%] [G loss: 5.471394]\n",
      "epoch:39 step:31081 [D loss: 0.855255, acc: 43.75%] [G loss: 4.873160]\n",
      "epoch:39 step:31082 [D loss: 0.538979, acc: 69.53%] [G loss: 5.571863]\n",
      "epoch:39 step:31083 [D loss: 0.109382, acc: 100.00%] [G loss: 3.493308]\n",
      "epoch:39 step:31084 [D loss: 0.157982, acc: 99.22%] [G loss: 5.208036]\n",
      "epoch:39 step:31085 [D loss: 0.068320, acc: 100.00%] [G loss: 2.704539]\n",
      "epoch:39 step:31086 [D loss: 0.094200, acc: 99.22%] [G loss: 6.414343]\n",
      "epoch:39 step:31087 [D loss: 0.062210, acc: 99.22%] [G loss: 6.301003]\n",
      "epoch:39 step:31088 [D loss: 0.682080, acc: 60.16%] [G loss: 6.721931]\n",
      "epoch:39 step:31089 [D loss: 0.376052, acc: 91.41%] [G loss: 4.124777]\n",
      "epoch:39 step:31090 [D loss: 0.496191, acc: 69.53%] [G loss: 6.678652]\n",
      "epoch:39 step:31091 [D loss: 0.292839, acc: 92.19%] [G loss: 4.945483]\n",
      "epoch:39 step:31092 [D loss: 0.462934, acc: 78.12%] [G loss: 4.580068]\n",
      "epoch:39 step:31093 [D loss: 0.051866, acc: 100.00%] [G loss: 8.492900]\n",
      "epoch:39 step:31094 [D loss: 0.356096, acc: 88.28%] [G loss: 8.075214]\n",
      "epoch:39 step:31095 [D loss: 0.474118, acc: 74.22%] [G loss: 3.456292]\n",
      "epoch:39 step:31096 [D loss: 0.313803, acc: 92.19%] [G loss: 4.677966]\n",
      "epoch:39 step:31097 [D loss: 0.314930, acc: 82.03%] [G loss: 7.932696]\n",
      "epoch:39 step:31098 [D loss: 0.614443, acc: 55.47%] [G loss: 5.952777]\n",
      "epoch:39 step:31099 [D loss: 0.698642, acc: 57.03%] [G loss: 8.506689]\n",
      "epoch:39 step:31100 [D loss: 0.141499, acc: 99.22%] [G loss: 4.853742]\n",
      "epoch:39 step:31101 [D loss: 1.079839, acc: 50.78%] [G loss: 5.609072]\n",
      "epoch:39 step:31102 [D loss: 0.189828, acc: 94.53%] [G loss: 7.290155]\n",
      "epoch:39 step:31103 [D loss: 0.701758, acc: 53.91%] [G loss: 8.923092]\n",
      "epoch:39 step:31104 [D loss: 0.293420, acc: 91.41%] [G loss: 7.954639]\n",
      "epoch:39 step:31105 [D loss: 1.840349, acc: 15.62%] [G loss: 5.109198]\n",
      "epoch:39 step:31106 [D loss: 0.253662, acc: 96.88%] [G loss: 3.396249]\n",
      "epoch:39 step:31107 [D loss: 0.043534, acc: 100.00%] [G loss: 4.831020]\n",
      "epoch:39 step:31108 [D loss: 0.073418, acc: 100.00%] [G loss: 7.178130]\n",
      "epoch:39 step:31109 [D loss: 0.209754, acc: 96.88%] [G loss: 3.892497]\n",
      "epoch:39 step:31110 [D loss: 0.061257, acc: 100.00%] [G loss: 5.227614]\n",
      "epoch:39 step:31111 [D loss: 0.272589, acc: 96.09%] [G loss: 8.163588]\n",
      "epoch:39 step:31112 [D loss: 0.316294, acc: 86.72%] [G loss: 4.120900]\n",
      "epoch:39 step:31113 [D loss: 0.156314, acc: 96.09%] [G loss: 7.179836]\n",
      "epoch:39 step:31114 [D loss: 0.058712, acc: 100.00%] [G loss: 7.098922]\n",
      "epoch:39 step:31115 [D loss: 0.839720, acc: 50.78%] [G loss: 7.064658]\n",
      "epoch:39 step:31116 [D loss: 0.388078, acc: 78.12%] [G loss: 2.480809]\n",
      "epoch:39 step:31117 [D loss: 0.259792, acc: 92.97%] [G loss: 6.422041]\n",
      "epoch:39 step:31118 [D loss: 0.059620, acc: 100.00%] [G loss: 5.731417]\n",
      "epoch:39 step:31119 [D loss: 0.479961, acc: 75.78%] [G loss: 6.052965]\n",
      "epoch:39 step:31120 [D loss: 0.067092, acc: 100.00%] [G loss: 6.073092]\n",
      "epoch:39 step:31121 [D loss: 0.659568, acc: 55.47%] [G loss: 6.042286]\n",
      "epoch:39 step:31122 [D loss: 0.181688, acc: 97.66%] [G loss: 3.817467]\n",
      "epoch:39 step:31123 [D loss: 0.037782, acc: 100.00%] [G loss: 7.901413]\n",
      "epoch:39 step:31124 [D loss: 0.598916, acc: 67.97%] [G loss: 6.710182]\n",
      "epoch:39 step:31125 [D loss: 0.218806, acc: 96.09%] [G loss: 5.375008]\n",
      "epoch:39 step:31126 [D loss: 0.125942, acc: 98.44%] [G loss: 8.264572]\n",
      "epoch:39 step:31127 [D loss: 0.009411, acc: 100.00%] [G loss: 5.500407]\n",
      "epoch:39 step:31128 [D loss: 0.551770, acc: 67.19%] [G loss: 5.694780]\n",
      "epoch:39 step:31129 [D loss: 0.188899, acc: 96.09%] [G loss: 6.629843]\n",
      "epoch:39 step:31130 [D loss: 0.078018, acc: 100.00%] [G loss: 6.074762]\n",
      "epoch:39 step:31131 [D loss: 1.276484, acc: 16.41%] [G loss: 5.524621]\n",
      "epoch:39 step:31132 [D loss: 0.210254, acc: 95.31%] [G loss: 6.105951]\n",
      "epoch:39 step:31133 [D loss: 0.355631, acc: 90.62%] [G loss: 3.774495]\n",
      "epoch:39 step:31134 [D loss: 0.263145, acc: 96.88%] [G loss: 6.420097]\n",
      "epoch:39 step:31135 [D loss: 0.072398, acc: 100.00%] [G loss: 7.060503]\n",
      "epoch:39 step:31136 [D loss: 0.302283, acc: 88.28%] [G loss: 3.823644]\n",
      "epoch:39 step:31137 [D loss: 0.569595, acc: 72.66%] [G loss: 5.408255]\n",
      "epoch:39 step:31138 [D loss: 0.605481, acc: 64.84%] [G loss: 5.735725]\n",
      "epoch:39 step:31139 [D loss: 0.263411, acc: 96.09%] [G loss: 5.012162]\n",
      "epoch:39 step:31140 [D loss: 0.815940, acc: 56.25%] [G loss: 5.032410]\n",
      "epoch:39 step:31141 [D loss: 0.043852, acc: 100.00%] [G loss: 6.148436]\n",
      "epoch:39 step:31142 [D loss: 0.438656, acc: 71.88%] [G loss: 6.950789]\n",
      "epoch:39 step:31143 [D loss: 0.732030, acc: 54.69%] [G loss: 6.243502]\n",
      "epoch:39 step:31144 [D loss: 0.024292, acc: 100.00%] [G loss: 8.030298]\n",
      "epoch:39 step:31145 [D loss: 0.759109, acc: 53.91%] [G loss: 8.379423]\n",
      "epoch:39 step:31146 [D loss: 0.083649, acc: 99.22%] [G loss: 6.506298]\n",
      "epoch:39 step:31147 [D loss: 0.048871, acc: 100.00%] [G loss: 6.233146]\n",
      "epoch:39 step:31148 [D loss: 0.267775, acc: 87.50%] [G loss: 5.932976]\n",
      "epoch:39 step:31149 [D loss: 0.081708, acc: 100.00%] [G loss: 10.538431]\n",
      "epoch:39 step:31150 [D loss: 0.029130, acc: 100.00%] [G loss: 6.111927]\n",
      "epoch:39 step:31151 [D loss: 0.171826, acc: 100.00%] [G loss: 6.366823]\n",
      "epoch:39 step:31152 [D loss: 0.529172, acc: 70.31%] [G loss: 7.592970]\n",
      "epoch:39 step:31153 [D loss: 0.479634, acc: 75.00%] [G loss: 4.236110]\n",
      "epoch:39 step:31154 [D loss: 0.143340, acc: 97.66%] [G loss: 5.905746]\n",
      "epoch:39 step:31155 [D loss: 0.273084, acc: 87.50%] [G loss: 4.874345]\n",
      "epoch:39 step:31156 [D loss: 0.077306, acc: 100.00%] [G loss: 2.480116]\n",
      "epoch:39 step:31157 [D loss: 0.048435, acc: 100.00%] [G loss: 9.218462]\n",
      "epoch:39 step:31158 [D loss: 0.201608, acc: 98.44%] [G loss: 3.019675]\n",
      "epoch:39 step:31159 [D loss: 0.069630, acc: 100.00%] [G loss: 6.096977]\n",
      "epoch:39 step:31160 [D loss: 0.172827, acc: 100.00%] [G loss: 3.406521]\n",
      "epoch:39 step:31161 [D loss: 0.250964, acc: 93.75%] [G loss: 4.723568]\n",
      "epoch:39 step:31162 [D loss: 0.295358, acc: 92.97%] [G loss: 3.261758]\n",
      "epoch:39 step:31163 [D loss: 0.288666, acc: 89.06%] [G loss: 6.354738]\n",
      "epoch:39 step:31164 [D loss: 1.142645, acc: 50.00%] [G loss: 5.335485]\n",
      "epoch:39 step:31165 [D loss: 0.652576, acc: 61.72%] [G loss: 4.818734]\n",
      "epoch:39 step:31166 [D loss: 0.325860, acc: 85.94%] [G loss: 6.298778]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:39 step:31167 [D loss: 1.136819, acc: 50.00%] [G loss: 10.056036]\n",
      "epoch:39 step:31168 [D loss: 0.067204, acc: 100.00%] [G loss: 3.869740]\n",
      "epoch:39 step:31169 [D loss: 0.221176, acc: 94.53%] [G loss: 5.907946]\n",
      "epoch:39 step:31170 [D loss: 0.033197, acc: 100.00%] [G loss: 10.538681]\n",
      "epoch:39 step:31171 [D loss: 0.115313, acc: 98.44%] [G loss: 6.050720]\n",
      "epoch:39 step:31172 [D loss: 0.170903, acc: 96.09%] [G loss: 5.796669]\n",
      "epoch:39 step:31173 [D loss: 0.097352, acc: 98.44%] [G loss: 8.943130]\n",
      "epoch:39 step:31174 [D loss: 0.071837, acc: 100.00%] [G loss: 10.146143]\n",
      "epoch:39 step:31175 [D loss: 0.062545, acc: 100.00%] [G loss: 5.788932]\n",
      "epoch:39 step:31176 [D loss: 0.076559, acc: 100.00%] [G loss: 6.389109]\n",
      "epoch:39 step:31177 [D loss: 0.194294, acc: 95.31%] [G loss: 5.688004]\n",
      "epoch:39 step:31178 [D loss: 0.756233, acc: 54.69%] [G loss: 4.967380]\n",
      "epoch:39 step:31179 [D loss: 0.027143, acc: 100.00%] [G loss: 5.197497]\n",
      "epoch:39 step:31180 [D loss: 0.373156, acc: 89.06%] [G loss: 6.291927]\n",
      "epoch:39 step:31181 [D loss: 0.412050, acc: 77.34%] [G loss: 7.501025]\n",
      "epoch:39 step:31182 [D loss: 0.135398, acc: 100.00%] [G loss: 6.460076]\n",
      "epoch:39 step:31183 [D loss: 0.022683, acc: 100.00%] [G loss: 4.438140]\n",
      "epoch:39 step:31184 [D loss: 0.053921, acc: 100.00%] [G loss: 5.071877]\n",
      "epoch:39 step:31185 [D loss: 0.031588, acc: 100.00%] [G loss: 8.677794]\n",
      "epoch:39 step:31186 [D loss: 0.706288, acc: 56.25%] [G loss: 6.334754]\n",
      "epoch:39 step:31187 [D loss: 0.108841, acc: 100.00%] [G loss: 5.000340]\n",
      "epoch:39 step:31188 [D loss: 0.447675, acc: 79.69%] [G loss: 6.361564]\n",
      "epoch:39 step:31189 [D loss: 0.585460, acc: 58.59%] [G loss: 6.328036]\n",
      "epoch:39 step:31190 [D loss: 0.809071, acc: 52.34%] [G loss: 8.104897]\n",
      "epoch:39 step:31191 [D loss: 0.150716, acc: 98.44%] [G loss: 6.797381]\n",
      "epoch:39 step:31192 [D loss: 0.428371, acc: 74.22%] [G loss: 4.984017]\n",
      "epoch:39 step:31193 [D loss: 0.427307, acc: 78.12%] [G loss: 3.049866]\n",
      "epoch:39 step:31194 [D loss: 0.025818, acc: 100.00%] [G loss: 5.843574]\n",
      "epoch:39 step:31195 [D loss: 0.217844, acc: 97.66%] [G loss: 2.983535]\n",
      "epoch:39 step:31196 [D loss: 0.194897, acc: 97.66%] [G loss: 10.576319]\n",
      "epoch:39 step:31197 [D loss: 0.700742, acc: 56.25%] [G loss: 5.926476]\n",
      "epoch:39 step:31198 [D loss: 0.107339, acc: 100.00%] [G loss: 5.256250]\n",
      "epoch:39 step:31199 [D loss: 0.969451, acc: 46.88%] [G loss: 8.748999]\n",
      "epoch:39 step:31200 [D loss: 0.215390, acc: 94.53%] [G loss: 4.608427]\n",
      "##############\n",
      "[0.85598664 0.88867739 0.83012878 0.82845409 0.79238675 0.82266244\n",
      " 0.8932173  0.82485891 0.82949741 0.83342947]\n",
      "##########\n",
      "epoch:39 step:31201 [D loss: 0.336659, acc: 85.16%] [G loss: 9.532158]\n",
      "epoch:39 step:31202 [D loss: 0.312123, acc: 95.31%] [G loss: 8.290590]\n",
      "epoch:39 step:31203 [D loss: 1.006136, acc: 50.78%] [G loss: 3.184163]\n",
      "epoch:39 step:31204 [D loss: 0.142453, acc: 100.00%] [G loss: 5.447941]\n",
      "epoch:39 step:31205 [D loss: 0.765935, acc: 51.56%] [G loss: 11.879004]\n",
      "epoch:39 step:31206 [D loss: 0.310193, acc: 92.19%] [G loss: 3.654691]\n",
      "epoch:39 step:31207 [D loss: 0.099203, acc: 100.00%] [G loss: 2.975698]\n",
      "epoch:39 step:31208 [D loss: 0.355411, acc: 90.62%] [G loss: 8.210666]\n",
      "epoch:39 step:31209 [D loss: 0.256763, acc: 97.66%] [G loss: 3.942487]\n",
      "epoch:39 step:31210 [D loss: 0.046107, acc: 100.00%] [G loss: 4.011904]\n",
      "epoch:39 step:31211 [D loss: 0.491471, acc: 70.31%] [G loss: 4.994391]\n",
      "epoch:39 step:31212 [D loss: 0.255316, acc: 94.53%] [G loss: 6.804613]\n",
      "epoch:39 step:31213 [D loss: 0.033874, acc: 100.00%] [G loss: 5.482886]\n",
      "epoch:39 step:31214 [D loss: 0.014744, acc: 100.00%] [G loss: 8.074189]\n",
      "epoch:39 step:31215 [D loss: 0.071219, acc: 100.00%] [G loss: 2.858166]\n",
      "epoch:39 step:31216 [D loss: 0.279282, acc: 90.62%] [G loss: 3.265402]\n",
      "epoch:39 step:31217 [D loss: 0.308579, acc: 84.38%] [G loss: 7.441143]\n",
      "epoch:39 step:31218 [D loss: 0.426681, acc: 83.59%] [G loss: 4.231626]\n",
      "epoch:39 step:31219 [D loss: 0.024365, acc: 100.00%] [G loss: 10.263315]\n",
      "epoch:39 step:31220 [D loss: 0.224773, acc: 93.75%] [G loss: 10.539825]\n",
      "epoch:39 step:31221 [D loss: 1.074317, acc: 50.78%] [G loss: 7.899877]\n",
      "epoch:39 step:31222 [D loss: 0.054245, acc: 100.00%] [G loss: 5.804388]\n",
      "epoch:39 step:31223 [D loss: 0.842609, acc: 51.56%] [G loss: 9.079741]\n",
      "epoch:39 step:31224 [D loss: 0.154201, acc: 97.66%] [G loss: 6.101234]\n",
      "epoch:39 step:31225 [D loss: 0.100360, acc: 100.00%] [G loss: 4.206545]\n",
      "epoch:39 step:31226 [D loss: 0.031466, acc: 100.00%] [G loss: 8.340668]\n",
      "epoch:39 step:31227 [D loss: 0.048974, acc: 100.00%] [G loss: 5.381872]\n",
      "epoch:39 step:31228 [D loss: 0.101366, acc: 99.22%] [G loss: 4.909412]\n",
      "epoch:39 step:31229 [D loss: 0.672446, acc: 57.03%] [G loss: 6.227346]\n",
      "epoch:39 step:31230 [D loss: 0.152855, acc: 96.09%] [G loss: 7.534849]\n",
      "epoch:39 step:31231 [D loss: 1.336278, acc: 31.25%] [G loss: 8.951551]\n",
      "epoch:39 step:31232 [D loss: 0.169100, acc: 97.66%] [G loss: 7.241480]\n",
      "epoch:39 step:31233 [D loss: 0.151246, acc: 98.44%] [G loss: 5.550567]\n",
      "epoch:39 step:31234 [D loss: 0.066687, acc: 100.00%] [G loss: 5.825413]\n",
      "epoch:39 step:31235 [D loss: 0.254957, acc: 97.66%] [G loss: 5.555725]\n",
      "epoch:39 step:31236 [D loss: 0.630712, acc: 61.72%] [G loss: 6.851941]\n",
      "epoch:39 step:31237 [D loss: 0.216613, acc: 96.09%] [G loss: 4.556213]\n",
      "epoch:39 step:31238 [D loss: 0.025486, acc: 100.00%] [G loss: 5.781416]\n",
      "epoch:39 step:31239 [D loss: 0.276814, acc: 89.06%] [G loss: 4.060206]\n",
      "epoch:39 step:31240 [D loss: 0.627780, acc: 67.19%] [G loss: 4.450404]\n",
      "epoch:40 step:31241 [D loss: 0.039345, acc: 100.00%] [G loss: 5.678470]\n",
      "epoch:40 step:31242 [D loss: 0.093675, acc: 100.00%] [G loss: 6.417748]\n",
      "epoch:40 step:31243 [D loss: 1.153676, acc: 26.56%] [G loss: 6.264721]\n",
      "epoch:40 step:31244 [D loss: 0.117061, acc: 98.44%] [G loss: 5.802948]\n",
      "epoch:40 step:31245 [D loss: 0.146707, acc: 97.66%] [G loss: 4.968437]\n",
      "epoch:40 step:31246 [D loss: 0.386168, acc: 78.12%] [G loss: 2.879536]\n",
      "epoch:40 step:31247 [D loss: 0.174276, acc: 94.53%] [G loss: 6.211702]\n",
      "epoch:40 step:31248 [D loss: 0.394350, acc: 82.03%] [G loss: 6.522737]\n",
      "epoch:40 step:31249 [D loss: 0.570369, acc: 60.94%] [G loss: 9.302873]\n",
      "epoch:40 step:31250 [D loss: 0.081040, acc: 100.00%] [G loss: 8.222662]\n",
      "epoch:40 step:31251 [D loss: 0.187237, acc: 94.53%] [G loss: 2.304050]\n",
      "epoch:40 step:31252 [D loss: 0.485823, acc: 79.69%] [G loss: 4.660363]\n",
      "epoch:40 step:31253 [D loss: 0.077704, acc: 100.00%] [G loss: 6.127682]\n",
      "epoch:40 step:31254 [D loss: 0.196364, acc: 96.09%] [G loss: 5.134022]\n",
      "epoch:40 step:31255 [D loss: 0.292943, acc: 95.31%] [G loss: 3.950984]\n",
      "epoch:40 step:31256 [D loss: 0.285373, acc: 85.94%] [G loss: 5.410038]\n",
      "epoch:40 step:31257 [D loss: 0.266300, acc: 96.09%] [G loss: 3.989379]\n",
      "epoch:40 step:31258 [D loss: 0.151976, acc: 98.44%] [G loss: 2.233651]\n",
      "epoch:40 step:31259 [D loss: 0.786895, acc: 53.91%] [G loss: 6.455683]\n",
      "epoch:40 step:31260 [D loss: 0.679851, acc: 60.94%] [G loss: 6.395073]\n",
      "epoch:40 step:31261 [D loss: 0.109574, acc: 99.22%] [G loss: 5.270539]\n",
      "epoch:40 step:31262 [D loss: 0.616347, acc: 68.75%] [G loss: 5.832557]\n",
      "epoch:40 step:31263 [D loss: 0.055708, acc: 100.00%] [G loss: 3.567400]\n",
      "epoch:40 step:31264 [D loss: 0.479277, acc: 75.78%] [G loss: 5.794246]\n",
      "epoch:40 step:31265 [D loss: 0.149470, acc: 96.88%] [G loss: 5.454277]\n",
      "epoch:40 step:31266 [D loss: 0.141045, acc: 99.22%] [G loss: 3.570471]\n",
      "epoch:40 step:31267 [D loss: 0.217536, acc: 96.09%] [G loss: 4.417399]\n",
      "epoch:40 step:31268 [D loss: 0.434609, acc: 71.88%] [G loss: 6.337022]\n",
      "epoch:40 step:31269 [D loss: 0.785981, acc: 51.56%] [G loss: 5.779888]\n",
      "epoch:40 step:31270 [D loss: 0.021242, acc: 100.00%] [G loss: 11.033132]\n",
      "epoch:40 step:31271 [D loss: 0.095826, acc: 100.00%] [G loss: 4.988520]\n",
      "epoch:40 step:31272 [D loss: 0.222511, acc: 99.22%] [G loss: 3.545312]\n",
      "epoch:40 step:31273 [D loss: 0.039142, acc: 100.00%] [G loss: 6.135271]\n",
      "epoch:40 step:31274 [D loss: 0.372538, acc: 81.25%] [G loss: 6.470706]\n",
      "epoch:40 step:31275 [D loss: 0.315279, acc: 91.41%] [G loss: 5.788908]\n",
      "epoch:40 step:31276 [D loss: 0.021018, acc: 100.00%] [G loss: 8.552889]\n",
      "epoch:40 step:31277 [D loss: 0.865203, acc: 46.09%] [G loss: 7.800390]\n",
      "epoch:40 step:31278 [D loss: 0.949181, acc: 51.56%] [G loss: 5.221785]\n",
      "epoch:40 step:31279 [D loss: 0.509017, acc: 67.19%] [G loss: 6.765901]\n",
      "epoch:40 step:31280 [D loss: 0.393943, acc: 72.66%] [G loss: 9.344773]\n",
      "epoch:40 step:31281 [D loss: 1.753593, acc: 50.78%] [G loss: 6.062346]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:40 step:31282 [D loss: 0.080026, acc: 100.00%] [G loss: 5.191004]\n",
      "epoch:40 step:31283 [D loss: 1.682517, acc: 50.00%] [G loss: 8.715492]\n",
      "epoch:40 step:31284 [D loss: 0.286241, acc: 85.16%] [G loss: 5.716202]\n",
      "epoch:40 step:31285 [D loss: 0.399688, acc: 72.66%] [G loss: 6.894504]\n",
      "epoch:40 step:31286 [D loss: 0.625742, acc: 60.16%] [G loss: 4.688271]\n",
      "epoch:40 step:31287 [D loss: 0.241567, acc: 87.50%] [G loss: 6.020142]\n",
      "epoch:40 step:31288 [D loss: 0.177583, acc: 95.31%] [G loss: 4.545314]\n",
      "epoch:40 step:31289 [D loss: 0.405973, acc: 71.88%] [G loss: 3.726478]\n",
      "epoch:40 step:31290 [D loss: 0.808053, acc: 53.91%] [G loss: 6.447964]\n",
      "epoch:40 step:31291 [D loss: 0.712507, acc: 56.25%] [G loss: 4.902604]\n",
      "epoch:40 step:31292 [D loss: 0.321801, acc: 82.03%] [G loss: 4.100562]\n",
      "epoch:40 step:31293 [D loss: 0.108968, acc: 98.44%] [G loss: 4.475088]\n",
      "epoch:40 step:31294 [D loss: 0.153651, acc: 98.44%] [G loss: 4.394575]\n",
      "epoch:40 step:31295 [D loss: 0.354342, acc: 89.84%] [G loss: 3.911250]\n",
      "epoch:40 step:31296 [D loss: 0.785982, acc: 52.34%] [G loss: 8.472107]\n",
      "epoch:40 step:31297 [D loss: 0.073451, acc: 99.22%] [G loss: 3.499014]\n",
      "epoch:40 step:31298 [D loss: 0.119966, acc: 98.44%] [G loss: 7.919353]\n",
      "epoch:40 step:31299 [D loss: 0.250024, acc: 92.97%] [G loss: 5.415660]\n",
      "epoch:40 step:31300 [D loss: 0.054884, acc: 99.22%] [G loss: 4.409501]\n",
      "epoch:40 step:31301 [D loss: 0.026416, acc: 100.00%] [G loss: 3.723484]\n",
      "epoch:40 step:31302 [D loss: 0.164018, acc: 97.66%] [G loss: 5.729494]\n",
      "epoch:40 step:31303 [D loss: 0.217790, acc: 97.66%] [G loss: 8.125871]\n",
      "epoch:40 step:31304 [D loss: 0.107177, acc: 99.22%] [G loss: 4.049071]\n",
      "epoch:40 step:31305 [D loss: 0.736134, acc: 57.81%] [G loss: 9.087631]\n",
      "epoch:40 step:31306 [D loss: 0.709167, acc: 60.16%] [G loss: 4.927147]\n",
      "epoch:40 step:31307 [D loss: 0.097708, acc: 100.00%] [G loss: 5.577640]\n",
      "epoch:40 step:31308 [D loss: 0.078433, acc: 99.22%] [G loss: 7.941096]\n",
      "epoch:40 step:31309 [D loss: 0.372038, acc: 88.28%] [G loss: 4.670489]\n",
      "epoch:40 step:31310 [D loss: 0.314867, acc: 87.50%] [G loss: 2.345328]\n",
      "epoch:40 step:31311 [D loss: 0.659895, acc: 59.38%] [G loss: 2.483976]\n",
      "epoch:40 step:31312 [D loss: 0.048672, acc: 100.00%] [G loss: 8.359106]\n",
      "epoch:40 step:31313 [D loss: 0.252066, acc: 91.41%] [G loss: 6.457593]\n",
      "epoch:40 step:31314 [D loss: 0.093092, acc: 100.00%] [G loss: 7.654234]\n",
      "epoch:40 step:31315 [D loss: 0.174428, acc: 98.44%] [G loss: 6.955192]\n",
      "epoch:40 step:31316 [D loss: 0.252444, acc: 94.53%] [G loss: 4.002640]\n",
      "epoch:40 step:31317 [D loss: 0.209059, acc: 97.66%] [G loss: 2.574898]\n",
      "epoch:40 step:31318 [D loss: 0.263361, acc: 89.06%] [G loss: 2.863260]\n",
      "epoch:40 step:31319 [D loss: 0.143843, acc: 99.22%] [G loss: 4.339128]\n",
      "epoch:40 step:31320 [D loss: 1.639261, acc: 8.59%] [G loss: 6.310497]\n",
      "epoch:40 step:31321 [D loss: 0.743130, acc: 53.91%] [G loss: 2.706781]\n",
      "epoch:40 step:31322 [D loss: 0.116251, acc: 99.22%] [G loss: 1.943506]\n",
      "epoch:40 step:31323 [D loss: 0.235479, acc: 93.75%] [G loss: 7.464058]\n",
      "epoch:40 step:31324 [D loss: 0.379069, acc: 80.47%] [G loss: 4.516931]\n",
      "epoch:40 step:31325 [D loss: 0.101103, acc: 100.00%] [G loss: 5.349241]\n",
      "epoch:40 step:31326 [D loss: 0.366444, acc: 79.69%] [G loss: 3.206284]\n",
      "epoch:40 step:31327 [D loss: 0.306230, acc: 89.84%] [G loss: 5.032349]\n",
      "epoch:40 step:31328 [D loss: 0.259648, acc: 90.62%] [G loss: 3.810705]\n",
      "epoch:40 step:31329 [D loss: 0.371315, acc: 75.78%] [G loss: 9.020136]\n",
      "epoch:40 step:31330 [D loss: 0.047858, acc: 100.00%] [G loss: 4.462660]\n",
      "epoch:40 step:31331 [D loss: 0.128225, acc: 97.66%] [G loss: 6.569183]\n",
      "epoch:40 step:31332 [D loss: 0.041115, acc: 100.00%] [G loss: 5.274380]\n",
      "epoch:40 step:31333 [D loss: 0.556417, acc: 67.97%] [G loss: 5.194307]\n",
      "epoch:40 step:31334 [D loss: 0.982379, acc: 53.91%] [G loss: 3.488043]\n",
      "epoch:40 step:31335 [D loss: 0.955378, acc: 50.78%] [G loss: 3.751016]\n",
      "epoch:40 step:31336 [D loss: 0.064958, acc: 99.22%] [G loss: 5.369339]\n",
      "epoch:40 step:31337 [D loss: 0.176505, acc: 98.44%] [G loss: 3.138419]\n",
      "epoch:40 step:31338 [D loss: 0.106950, acc: 100.00%] [G loss: 6.249370]\n",
      "epoch:40 step:31339 [D loss: 0.156961, acc: 98.44%] [G loss: 3.833739]\n",
      "epoch:40 step:31340 [D loss: 0.061129, acc: 100.00%] [G loss: 8.406220]\n",
      "epoch:40 step:31341 [D loss: 0.557018, acc: 71.88%] [G loss: 5.350595]\n",
      "epoch:40 step:31342 [D loss: 0.582576, acc: 64.06%] [G loss: 5.442347]\n",
      "epoch:40 step:31343 [D loss: 0.137191, acc: 98.44%] [G loss: 5.484788]\n",
      "epoch:40 step:31344 [D loss: 0.397725, acc: 78.12%] [G loss: 7.653944]\n",
      "epoch:40 step:31345 [D loss: 0.805501, acc: 50.78%] [G loss: 5.707830]\n",
      "epoch:40 step:31346 [D loss: 0.108719, acc: 100.00%] [G loss: 7.617553]\n",
      "epoch:40 step:31347 [D loss: 0.510454, acc: 62.50%] [G loss: 3.741507]\n",
      "epoch:40 step:31348 [D loss: 0.170695, acc: 98.44%] [G loss: 7.711199]\n",
      "epoch:40 step:31349 [D loss: 0.339993, acc: 86.72%] [G loss: 5.263111]\n",
      "epoch:40 step:31350 [D loss: 0.454026, acc: 71.88%] [G loss: 4.736491]\n",
      "epoch:40 step:31351 [D loss: 0.039045, acc: 99.22%] [G loss: 8.270446]\n",
      "epoch:40 step:31352 [D loss: 0.080190, acc: 99.22%] [G loss: 5.207010]\n",
      "epoch:40 step:31353 [D loss: 0.750644, acc: 58.59%] [G loss: 7.914136]\n",
      "epoch:40 step:31354 [D loss: 0.313230, acc: 85.16%] [G loss: 4.351439]\n",
      "epoch:40 step:31355 [D loss: 0.085330, acc: 100.00%] [G loss: 4.735566]\n",
      "epoch:40 step:31356 [D loss: 0.443657, acc: 82.81%] [G loss: 7.266489]\n",
      "epoch:40 step:31357 [D loss: 0.068989, acc: 100.00%] [G loss: 6.206636]\n",
      "epoch:40 step:31358 [D loss: 0.391752, acc: 79.69%] [G loss: 2.818344]\n",
      "epoch:40 step:31359 [D loss: 0.058026, acc: 100.00%] [G loss: 5.590481]\n",
      "epoch:40 step:31360 [D loss: 0.065139, acc: 100.00%] [G loss: 9.719575]\n",
      "epoch:40 step:31361 [D loss: 0.249866, acc: 97.66%] [G loss: 4.129973]\n",
      "epoch:40 step:31362 [D loss: 0.180175, acc: 94.53%] [G loss: 9.187416]\n",
      "epoch:40 step:31363 [D loss: 0.038079, acc: 100.00%] [G loss: 5.454889]\n",
      "epoch:40 step:31364 [D loss: 0.140563, acc: 98.44%] [G loss: 7.816259]\n",
      "epoch:40 step:31365 [D loss: 0.572776, acc: 67.19%] [G loss: 6.844299]\n",
      "epoch:40 step:31366 [D loss: 0.410277, acc: 76.56%] [G loss: 4.598451]\n",
      "epoch:40 step:31367 [D loss: 0.129387, acc: 100.00%] [G loss: 5.348656]\n",
      "epoch:40 step:31368 [D loss: 0.472945, acc: 71.88%] [G loss: 7.198292]\n",
      "epoch:40 step:31369 [D loss: 0.911634, acc: 50.78%] [G loss: 6.087381]\n",
      "epoch:40 step:31370 [D loss: 0.617910, acc: 63.28%] [G loss: 5.691762]\n",
      "epoch:40 step:31371 [D loss: 0.192598, acc: 96.09%] [G loss: 4.921694]\n",
      "epoch:40 step:31372 [D loss: 0.303638, acc: 91.41%] [G loss: 4.793117]\n",
      "epoch:40 step:31373 [D loss: 0.530343, acc: 64.84%] [G loss: 5.302614]\n",
      "epoch:40 step:31374 [D loss: 0.310466, acc: 92.19%] [G loss: 6.395159]\n",
      "epoch:40 step:31375 [D loss: 0.261328, acc: 92.97%] [G loss: 9.175422]\n",
      "epoch:40 step:31376 [D loss: 0.042547, acc: 100.00%] [G loss: 8.145267]\n",
      "epoch:40 step:31377 [D loss: 0.298327, acc: 85.16%] [G loss: 5.091424]\n",
      "epoch:40 step:31378 [D loss: 0.250232, acc: 96.09%] [G loss: 4.802251]\n",
      "epoch:40 step:31379 [D loss: 0.155717, acc: 97.66%] [G loss: 6.288732]\n",
      "epoch:40 step:31380 [D loss: 0.207571, acc: 96.88%] [G loss: 6.379418]\n",
      "epoch:40 step:31381 [D loss: 0.156210, acc: 100.00%] [G loss: 4.611259]\n",
      "epoch:40 step:31382 [D loss: 0.070693, acc: 100.00%] [G loss: 5.042740]\n",
      "epoch:40 step:31383 [D loss: 0.053976, acc: 99.22%] [G loss: 6.948812]\n",
      "epoch:40 step:31384 [D loss: 0.106740, acc: 97.66%] [G loss: 3.626137]\n",
      "epoch:40 step:31385 [D loss: 0.326027, acc: 80.47%] [G loss: 6.182264]\n",
      "epoch:40 step:31386 [D loss: 0.056191, acc: 100.00%] [G loss: 6.785861]\n",
      "epoch:40 step:31387 [D loss: 0.689124, acc: 57.03%] [G loss: 7.683200]\n",
      "epoch:40 step:31388 [D loss: 0.164037, acc: 98.44%] [G loss: 4.757365]\n",
      "epoch:40 step:31389 [D loss: 0.119251, acc: 97.66%] [G loss: 6.764571]\n",
      "epoch:40 step:31390 [D loss: 0.451657, acc: 72.66%] [G loss: 5.821293]\n",
      "epoch:40 step:31391 [D loss: 0.261648, acc: 92.19%] [G loss: 4.106923]\n",
      "epoch:40 step:31392 [D loss: 0.088201, acc: 100.00%] [G loss: 5.565331]\n",
      "epoch:40 step:31393 [D loss: 0.067885, acc: 100.00%] [G loss: 6.607089]\n",
      "epoch:40 step:31394 [D loss: 0.551606, acc: 70.31%] [G loss: 6.815441]\n",
      "epoch:40 step:31395 [D loss: 0.745526, acc: 54.69%] [G loss: 5.768031]\n",
      "epoch:40 step:31396 [D loss: 0.807051, acc: 53.91%] [G loss: 4.704393]\n",
      "epoch:40 step:31397 [D loss: 0.065608, acc: 100.00%] [G loss: 6.721433]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:40 step:31398 [D loss: 0.248665, acc: 95.31%] [G loss: 8.788807]\n",
      "epoch:40 step:31399 [D loss: 0.261316, acc: 87.50%] [G loss: 6.951694]\n",
      "epoch:40 step:31400 [D loss: 0.801940, acc: 51.56%] [G loss: 7.919193]\n",
      "##############\n",
      "[0.86911639 0.86431471 0.81008143 0.83183655 0.79578202 0.83040301\n",
      " 0.88942256 0.82914351 0.80584337 0.82657603]\n",
      "##########\n",
      "epoch:40 step:31401 [D loss: 0.028787, acc: 100.00%] [G loss: 8.355669]\n",
      "epoch:40 step:31402 [D loss: 0.350776, acc: 76.56%] [G loss: 6.860839]\n",
      "epoch:40 step:31403 [D loss: 0.708248, acc: 58.59%] [G loss: 3.538554]\n",
      "epoch:40 step:31404 [D loss: 0.547535, acc: 67.19%] [G loss: 5.725466]\n",
      "epoch:40 step:31405 [D loss: 0.122992, acc: 99.22%] [G loss: 4.848927]\n",
      "epoch:40 step:31406 [D loss: 0.466363, acc: 78.91%] [G loss: 5.911164]\n",
      "epoch:40 step:31407 [D loss: 0.876984, acc: 55.47%] [G loss: 7.987911]\n",
      "epoch:40 step:31408 [D loss: 0.218097, acc: 92.19%] [G loss: 8.543275]\n",
      "epoch:40 step:31409 [D loss: 0.491667, acc: 69.53%] [G loss: 7.642851]\n",
      "epoch:40 step:31410 [D loss: 1.919145, acc: 1.56%] [G loss: 5.250574]\n",
      "epoch:40 step:31411 [D loss: 0.628712, acc: 60.16%] [G loss: 8.256350]\n",
      "epoch:40 step:31412 [D loss: 0.476871, acc: 84.38%] [G loss: 6.755680]\n",
      "epoch:40 step:31413 [D loss: 0.845941, acc: 47.66%] [G loss: 7.965482]\n",
      "epoch:40 step:31414 [D loss: 0.050125, acc: 99.22%] [G loss: 6.807451]\n",
      "epoch:40 step:31415 [D loss: 0.188387, acc: 97.66%] [G loss: 7.104583]\n",
      "epoch:40 step:31416 [D loss: 1.077814, acc: 51.56%] [G loss: 8.011962]\n",
      "epoch:40 step:31417 [D loss: 0.086074, acc: 100.00%] [G loss: 7.879551]\n",
      "epoch:40 step:31418 [D loss: 0.141887, acc: 100.00%] [G loss: 7.120044]\n",
      "epoch:40 step:31419 [D loss: 0.202022, acc: 98.44%] [G loss: 3.962987]\n",
      "epoch:40 step:31420 [D loss: 0.143801, acc: 99.22%] [G loss: 6.787836]\n",
      "epoch:40 step:31421 [D loss: 0.154918, acc: 94.53%] [G loss: 4.449801]\n",
      "epoch:40 step:31422 [D loss: 0.027996, acc: 99.22%] [G loss: 5.555807]\n",
      "epoch:40 step:31423 [D loss: 0.266205, acc: 93.75%] [G loss: 5.680691]\n",
      "epoch:40 step:31424 [D loss: 0.037803, acc: 100.00%] [G loss: 7.988971]\n",
      "epoch:40 step:31425 [D loss: 0.160660, acc: 99.22%] [G loss: 4.743361]\n",
      "epoch:40 step:31426 [D loss: 0.347658, acc: 81.25%] [G loss: 4.871813]\n",
      "epoch:40 step:31427 [D loss: 0.308913, acc: 92.19%] [G loss: 2.826000]\n",
      "epoch:40 step:31428 [D loss: 0.095972, acc: 100.00%] [G loss: 5.153296]\n",
      "epoch:40 step:31429 [D loss: 0.051709, acc: 100.00%] [G loss: 8.830276]\n",
      "epoch:40 step:31430 [D loss: 0.078389, acc: 100.00%] [G loss: 6.387916]\n",
      "epoch:40 step:31431 [D loss: 0.351852, acc: 83.59%] [G loss: 8.545326]\n",
      "epoch:40 step:31432 [D loss: 0.044360, acc: 99.22%] [G loss: 5.750781]\n",
      "epoch:40 step:31433 [D loss: 0.678840, acc: 59.38%] [G loss: 9.818740]\n",
      "epoch:40 step:31434 [D loss: 0.196520, acc: 95.31%] [G loss: 5.793508]\n",
      "epoch:40 step:31435 [D loss: 0.608276, acc: 58.59%] [G loss: 5.827421]\n",
      "epoch:40 step:31436 [D loss: 0.314436, acc: 91.41%] [G loss: 3.846974]\n",
      "epoch:40 step:31437 [D loss: 1.046100, acc: 48.44%] [G loss: 6.522364]\n",
      "epoch:40 step:31438 [D loss: 0.432064, acc: 89.84%] [G loss: 7.061533]\n",
      "epoch:40 step:31439 [D loss: 0.137404, acc: 97.66%] [G loss: 6.810575]\n",
      "epoch:40 step:31440 [D loss: 0.219867, acc: 94.53%] [G loss: 8.358097]\n",
      "epoch:40 step:31441 [D loss: 2.065524, acc: 9.38%] [G loss: 6.611938]\n",
      "epoch:40 step:31442 [D loss: 0.171269, acc: 98.44%] [G loss: 3.717945]\n",
      "epoch:40 step:31443 [D loss: 0.190396, acc: 93.75%] [G loss: 3.434968]\n",
      "epoch:40 step:31444 [D loss: 0.080841, acc: 100.00%] [G loss: 7.377868]\n",
      "epoch:40 step:31445 [D loss: 0.293380, acc: 87.50%] [G loss: 5.688168]\n",
      "epoch:40 step:31446 [D loss: 0.385999, acc: 75.78%] [G loss: 4.708008]\n",
      "epoch:40 step:31447 [D loss: 0.020777, acc: 100.00%] [G loss: 5.004685]\n",
      "epoch:40 step:31448 [D loss: 0.050981, acc: 100.00%] [G loss: 7.102662]\n",
      "epoch:40 step:31449 [D loss: 0.294079, acc: 86.72%] [G loss: 9.279810]\n",
      "epoch:40 step:31450 [D loss: 0.248998, acc: 95.31%] [G loss: 3.321726]\n",
      "epoch:40 step:31451 [D loss: 0.855564, acc: 50.78%] [G loss: 5.835211]\n",
      "epoch:40 step:31452 [D loss: 0.089628, acc: 100.00%] [G loss: 6.382768]\n",
      "epoch:40 step:31453 [D loss: 0.682455, acc: 60.16%] [G loss: 6.434459]\n",
      "epoch:40 step:31454 [D loss: 0.493926, acc: 60.94%] [G loss: 6.219007]\n",
      "epoch:40 step:31455 [D loss: 0.097294, acc: 97.66%] [G loss: 4.605678]\n",
      "epoch:40 step:31456 [D loss: 0.114353, acc: 98.44%] [G loss: 3.120938]\n",
      "epoch:40 step:31457 [D loss: 0.089969, acc: 100.00%] [G loss: 4.626497]\n",
      "epoch:40 step:31458 [D loss: 0.438367, acc: 83.59%] [G loss: 3.754544]\n",
      "epoch:40 step:31459 [D loss: 0.164605, acc: 98.44%] [G loss: 5.163823]\n",
      "epoch:40 step:31460 [D loss: 0.228158, acc: 95.31%] [G loss: 7.259752]\n",
      "epoch:40 step:31461 [D loss: 0.117407, acc: 100.00%] [G loss: 4.105333]\n",
      "epoch:40 step:31462 [D loss: 0.274392, acc: 88.28%] [G loss: 6.114589]\n",
      "epoch:40 step:31463 [D loss: 0.083658, acc: 99.22%] [G loss: 5.627943]\n",
      "epoch:40 step:31464 [D loss: 0.812958, acc: 47.66%] [G loss: 5.198356]\n",
      "epoch:40 step:31465 [D loss: 0.036696, acc: 100.00%] [G loss: 6.306978]\n",
      "epoch:40 step:31466 [D loss: 0.173593, acc: 99.22%] [G loss: 3.794355]\n",
      "epoch:40 step:31467 [D loss: 0.311821, acc: 86.72%] [G loss: 4.526457]\n",
      "epoch:40 step:31468 [D loss: 0.486896, acc: 77.34%] [G loss: 3.852587]\n",
      "epoch:40 step:31469 [D loss: 0.501462, acc: 62.50%] [G loss: 8.350636]\n",
      "epoch:40 step:31470 [D loss: 0.389030, acc: 78.91%] [G loss: 5.314503]\n",
      "epoch:40 step:31471 [D loss: 0.149502, acc: 97.66%] [G loss: 4.662644]\n",
      "epoch:40 step:31472 [D loss: 0.226411, acc: 93.75%] [G loss: 4.318559]\n",
      "epoch:40 step:31473 [D loss: 0.353828, acc: 85.94%] [G loss: 6.606479]\n",
      "epoch:40 step:31474 [D loss: 0.326994, acc: 86.72%] [G loss: 8.135293]\n",
      "epoch:40 step:31475 [D loss: 0.393817, acc: 72.66%] [G loss: 6.996606]\n",
      "epoch:40 step:31476 [D loss: 0.165269, acc: 99.22%] [G loss: 5.003783]\n",
      "epoch:40 step:31477 [D loss: 0.257432, acc: 86.72%] [G loss: 6.224466]\n",
      "epoch:40 step:31478 [D loss: 0.819279, acc: 52.34%] [G loss: 5.344119]\n",
      "epoch:40 step:31479 [D loss: 0.270007, acc: 95.31%] [G loss: 4.742486]\n",
      "epoch:40 step:31480 [D loss: 0.419492, acc: 72.66%] [G loss: 5.567106]\n",
      "epoch:40 step:31481 [D loss: 0.435031, acc: 77.34%] [G loss: 8.315054]\n",
      "epoch:40 step:31482 [D loss: 0.109355, acc: 98.44%] [G loss: 6.142262]\n",
      "epoch:40 step:31483 [D loss: 0.725814, acc: 54.69%] [G loss: 5.650745]\n",
      "epoch:40 step:31484 [D loss: 0.106657, acc: 99.22%] [G loss: 6.696948]\n",
      "epoch:40 step:31485 [D loss: 0.319408, acc: 90.62%] [G loss: 6.390396]\n",
      "epoch:40 step:31486 [D loss: 0.343933, acc: 81.25%] [G loss: 5.496567]\n",
      "epoch:40 step:31487 [D loss: 0.146551, acc: 99.22%] [G loss: 6.050069]\n",
      "epoch:40 step:31488 [D loss: 0.153290, acc: 98.44%] [G loss: 6.616457]\n",
      "epoch:40 step:31489 [D loss: 0.441109, acc: 85.94%] [G loss: 6.850038]\n",
      "epoch:40 step:31490 [D loss: 0.096494, acc: 100.00%] [G loss: 6.645787]\n",
      "epoch:40 step:31491 [D loss: 0.701589, acc: 53.91%] [G loss: 8.494708]\n",
      "epoch:40 step:31492 [D loss: 0.094503, acc: 100.00%] [G loss: 4.700021]\n",
      "epoch:40 step:31493 [D loss: 0.911037, acc: 52.34%] [G loss: 7.299401]\n",
      "epoch:40 step:31494 [D loss: 0.361646, acc: 80.47%] [G loss: 5.305620]\n",
      "epoch:40 step:31495 [D loss: 0.355158, acc: 85.94%] [G loss: 3.313730]\n",
      "epoch:40 step:31496 [D loss: 0.244908, acc: 88.28%] [G loss: 7.468727]\n",
      "epoch:40 step:31497 [D loss: 0.644368, acc: 60.94%] [G loss: 6.189642]\n",
      "epoch:40 step:31498 [D loss: 0.044408, acc: 100.00%] [G loss: 6.856038]\n",
      "epoch:40 step:31499 [D loss: 0.135544, acc: 99.22%] [G loss: 5.036805]\n",
      "epoch:40 step:31500 [D loss: 0.234840, acc: 94.53%] [G loss: 6.267241]\n",
      "epoch:40 step:31501 [D loss: 0.110756, acc: 100.00%] [G loss: 4.687238]\n",
      "epoch:40 step:31502 [D loss: 0.089913, acc: 100.00%] [G loss: 3.884075]\n",
      "epoch:40 step:31503 [D loss: 0.383624, acc: 89.06%] [G loss: 8.837963]\n",
      "epoch:40 step:31504 [D loss: 0.232869, acc: 97.66%] [G loss: 4.677828]\n",
      "epoch:40 step:31505 [D loss: 0.073628, acc: 100.00%] [G loss: 7.148602]\n",
      "epoch:40 step:31506 [D loss: 1.150467, acc: 25.78%] [G loss: 5.827051]\n",
      "epoch:40 step:31507 [D loss: 0.355590, acc: 88.28%] [G loss: 3.811352]\n",
      "epoch:40 step:31508 [D loss: 0.160605, acc: 100.00%] [G loss: 4.045854]\n",
      "epoch:40 step:31509 [D loss: 0.930856, acc: 28.91%] [G loss: 6.458384]\n",
      "epoch:40 step:31510 [D loss: 0.129840, acc: 99.22%] [G loss: 6.127694]\n",
      "epoch:40 step:31511 [D loss: 0.083527, acc: 99.22%] [G loss: 6.682240]\n",
      "epoch:40 step:31512 [D loss: 0.058007, acc: 100.00%] [G loss: 4.096151]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:40 step:31513 [D loss: 1.041253, acc: 30.47%] [G loss: 7.287177]\n",
      "epoch:40 step:31514 [D loss: 0.087599, acc: 100.00%] [G loss: 3.149346]\n",
      "epoch:40 step:31515 [D loss: 0.080926, acc: 99.22%] [G loss: 5.286074]\n",
      "epoch:40 step:31516 [D loss: 0.205688, acc: 94.53%] [G loss: 7.146819]\n",
      "epoch:40 step:31517 [D loss: 0.131484, acc: 98.44%] [G loss: 3.273705]\n",
      "epoch:40 step:31518 [D loss: 0.094486, acc: 99.22%] [G loss: 7.496390]\n",
      "epoch:40 step:31519 [D loss: 0.282927, acc: 92.97%] [G loss: 5.099089]\n",
      "epoch:40 step:31520 [D loss: 0.107485, acc: 99.22%] [G loss: 4.999273]\n",
      "epoch:40 step:31521 [D loss: 0.051833, acc: 100.00%] [G loss: 5.431158]\n",
      "epoch:40 step:31522 [D loss: 0.117969, acc: 100.00%] [G loss: 6.040462]\n",
      "epoch:40 step:31523 [D loss: 0.190939, acc: 94.53%] [G loss: 4.443188]\n",
      "epoch:40 step:31524 [D loss: 0.199878, acc: 96.88%] [G loss: 6.920424]\n",
      "epoch:40 step:31525 [D loss: 0.168327, acc: 96.88%] [G loss: 2.043153]\n",
      "epoch:40 step:31526 [D loss: 0.168025, acc: 99.22%] [G loss: 7.466714]\n",
      "epoch:40 step:31527 [D loss: 0.438946, acc: 79.69%] [G loss: 7.215418]\n",
      "epoch:40 step:31528 [D loss: 0.219900, acc: 96.88%] [G loss: 4.911347]\n",
      "epoch:40 step:31529 [D loss: 0.102906, acc: 100.00%] [G loss: 3.187705]\n",
      "epoch:40 step:31530 [D loss: 0.193838, acc: 96.88%] [G loss: 4.678985]\n",
      "epoch:40 step:31531 [D loss: 0.074126, acc: 100.00%] [G loss: 5.260637]\n",
      "epoch:40 step:31532 [D loss: 0.250758, acc: 97.66%] [G loss: 4.701428]\n",
      "epoch:40 step:31533 [D loss: 0.189641, acc: 97.66%] [G loss: 6.250890]\n",
      "epoch:40 step:31534 [D loss: 0.916407, acc: 52.34%] [G loss: 3.603466]\n",
      "epoch:40 step:31535 [D loss: 0.337012, acc: 80.47%] [G loss: 7.107673]\n",
      "epoch:40 step:31536 [D loss: 0.094918, acc: 100.00%] [G loss: 5.956112]\n",
      "epoch:40 step:31537 [D loss: 0.781166, acc: 53.91%] [G loss: 10.051991]\n",
      "epoch:40 step:31538 [D loss: 0.115033, acc: 100.00%] [G loss: 7.577850]\n",
      "epoch:40 step:31539 [D loss: 0.055262, acc: 99.22%] [G loss: 6.127810]\n",
      "epoch:40 step:31540 [D loss: 0.335595, acc: 90.62%] [G loss: 4.510219]\n",
      "epoch:40 step:31541 [D loss: 0.951693, acc: 50.78%] [G loss: 4.474750]\n",
      "epoch:40 step:31542 [D loss: 0.138881, acc: 98.44%] [G loss: 4.827700]\n",
      "epoch:40 step:31543 [D loss: 1.379755, acc: 22.66%] [G loss: 6.565099]\n",
      "epoch:40 step:31544 [D loss: 0.540831, acc: 65.62%] [G loss: 8.932220]\n",
      "epoch:40 step:31545 [D loss: 0.173369, acc: 98.44%] [G loss: 3.923698]\n",
      "epoch:40 step:31546 [D loss: 0.317246, acc: 82.81%] [G loss: 4.874732]\n",
      "epoch:40 step:31547 [D loss: 0.062873, acc: 100.00%] [G loss: 5.958246]\n",
      "epoch:40 step:31548 [D loss: 0.485388, acc: 79.69%] [G loss: 6.797990]\n",
      "epoch:40 step:31549 [D loss: 0.486791, acc: 75.00%] [G loss: 6.347497]\n",
      "epoch:40 step:31550 [D loss: 0.092429, acc: 100.00%] [G loss: 5.379318]\n",
      "epoch:40 step:31551 [D loss: 0.596371, acc: 69.53%] [G loss: 5.173893]\n",
      "epoch:40 step:31552 [D loss: 0.138037, acc: 99.22%] [G loss: 7.952518]\n",
      "epoch:40 step:31553 [D loss: 1.163393, acc: 24.22%] [G loss: 6.022017]\n",
      "epoch:40 step:31554 [D loss: 0.251036, acc: 93.75%] [G loss: 5.480398]\n",
      "epoch:40 step:31555 [D loss: 0.601432, acc: 57.81%] [G loss: 6.502998]\n",
      "epoch:40 step:31556 [D loss: 0.152373, acc: 98.44%] [G loss: 7.023069]\n",
      "epoch:40 step:31557 [D loss: 0.386989, acc: 77.34%] [G loss: 5.374480]\n",
      "epoch:40 step:31558 [D loss: 1.131396, acc: 38.28%] [G loss: 4.646374]\n",
      "epoch:40 step:31559 [D loss: 0.056101, acc: 100.00%] [G loss: 6.281763]\n",
      "epoch:40 step:31560 [D loss: 0.941372, acc: 32.81%] [G loss: 6.706964]\n",
      "epoch:40 step:31561 [D loss: 0.017378, acc: 100.00%] [G loss: 4.271070]\n",
      "epoch:40 step:31562 [D loss: 0.059228, acc: 100.00%] [G loss: 5.443092]\n",
      "epoch:40 step:31563 [D loss: 0.446396, acc: 85.16%] [G loss: 5.062984]\n",
      "epoch:40 step:31564 [D loss: 0.024170, acc: 100.00%] [G loss: 5.848127]\n",
      "epoch:40 step:31565 [D loss: 0.024994, acc: 100.00%] [G loss: 4.638386]\n",
      "epoch:40 step:31566 [D loss: 0.097232, acc: 99.22%] [G loss: 8.413889]\n",
      "epoch:40 step:31567 [D loss: 0.092094, acc: 100.00%] [G loss: 4.737617]\n",
      "epoch:40 step:31568 [D loss: 0.897026, acc: 50.78%] [G loss: 8.638894]\n",
      "epoch:40 step:31569 [D loss: 0.007623, acc: 100.00%] [G loss: 5.869401]\n",
      "epoch:40 step:31570 [D loss: 0.279065, acc: 86.72%] [G loss: 5.664001]\n",
      "epoch:40 step:31571 [D loss: 0.174571, acc: 96.88%] [G loss: 4.902313]\n",
      "epoch:40 step:31572 [D loss: 0.218414, acc: 94.53%] [G loss: 6.016093]\n",
      "epoch:40 step:31573 [D loss: 0.025182, acc: 100.00%] [G loss: 7.997220]\n",
      "epoch:40 step:31574 [D loss: 0.203458, acc: 95.31%] [G loss: 4.804067]\n",
      "epoch:40 step:31575 [D loss: 0.259933, acc: 90.62%] [G loss: 7.090905]\n",
      "epoch:40 step:31576 [D loss: 0.048481, acc: 100.00%] [G loss: 7.384520]\n",
      "epoch:40 step:31577 [D loss: 0.072575, acc: 100.00%] [G loss: 4.177804]\n",
      "epoch:40 step:31578 [D loss: 0.127433, acc: 98.44%] [G loss: 2.872993]\n",
      "epoch:40 step:31579 [D loss: 0.018967, acc: 100.00%] [G loss: 5.636218]\n",
      "epoch:40 step:31580 [D loss: 0.057955, acc: 100.00%] [G loss: 3.546966]\n",
      "epoch:40 step:31581 [D loss: 0.029296, acc: 100.00%] [G loss: 11.076717]\n",
      "epoch:40 step:31582 [D loss: 0.178200, acc: 97.66%] [G loss: 7.208552]\n",
      "epoch:40 step:31583 [D loss: 0.957089, acc: 46.88%] [G loss: 5.750620]\n",
      "epoch:40 step:31584 [D loss: 0.801810, acc: 50.78%] [G loss: 3.799118]\n",
      "epoch:40 step:31585 [D loss: 0.348009, acc: 82.81%] [G loss: 3.629157]\n",
      "epoch:40 step:31586 [D loss: 0.406549, acc: 77.34%] [G loss: 9.316050]\n",
      "epoch:40 step:31587 [D loss: 0.207017, acc: 97.66%] [G loss: 3.533892]\n",
      "epoch:40 step:31588 [D loss: 0.295819, acc: 93.75%] [G loss: 4.794599]\n",
      "epoch:40 step:31589 [D loss: 0.051802, acc: 100.00%] [G loss: 6.436183]\n",
      "epoch:40 step:31590 [D loss: 0.550066, acc: 66.41%] [G loss: 5.014874]\n",
      "epoch:40 step:31591 [D loss: 0.272715, acc: 85.16%] [G loss: 6.937393]\n",
      "epoch:40 step:31592 [D loss: 0.268876, acc: 89.84%] [G loss: 5.206429]\n",
      "epoch:40 step:31593 [D loss: 0.016392, acc: 100.00%] [G loss: 7.695211]\n",
      "epoch:40 step:31594 [D loss: 0.425805, acc: 75.00%] [G loss: 8.051716]\n",
      "epoch:40 step:31595 [D loss: 0.922004, acc: 48.44%] [G loss: 5.910620]\n",
      "epoch:40 step:31596 [D loss: 0.368188, acc: 84.38%] [G loss: 6.187390]\n",
      "epoch:40 step:31597 [D loss: 0.295983, acc: 85.16%] [G loss: 4.991780]\n",
      "epoch:40 step:31598 [D loss: 0.190738, acc: 96.88%] [G loss: 3.548893]\n",
      "epoch:40 step:31599 [D loss: 1.265983, acc: 44.53%] [G loss: 6.749856]\n",
      "epoch:40 step:31600 [D loss: 0.221099, acc: 97.66%] [G loss: 5.233473]\n",
      "##############\n",
      "[0.87000297 0.87097643 0.80244471 0.79455924 0.80075629 0.81205175\n",
      " 0.89632661 0.83155765 0.82874632 0.82706216]\n",
      "##########\n",
      "epoch:40 step:31601 [D loss: 0.380436, acc: 80.47%] [G loss: 4.508801]\n",
      "epoch:40 step:31602 [D loss: 0.098879, acc: 99.22%] [G loss: 5.523235]\n",
      "epoch:40 step:31603 [D loss: 0.062942, acc: 100.00%] [G loss: 2.799634]\n",
      "epoch:40 step:31604 [D loss: 0.236618, acc: 95.31%] [G loss: 4.823698]\n",
      "epoch:40 step:31605 [D loss: 0.195878, acc: 100.00%] [G loss: 5.413919]\n",
      "epoch:40 step:31606 [D loss: 0.514704, acc: 72.66%] [G loss: 4.733677]\n",
      "epoch:40 step:31607 [D loss: 0.503746, acc: 66.41%] [G loss: 7.478591]\n",
      "epoch:40 step:31608 [D loss: 0.333740, acc: 95.31%] [G loss: 8.084060]\n",
      "epoch:40 step:31609 [D loss: 0.270456, acc: 92.19%] [G loss: 5.212099]\n",
      "epoch:40 step:31610 [D loss: 0.453893, acc: 69.53%] [G loss: 6.880666]\n",
      "epoch:40 step:31611 [D loss: 0.526210, acc: 66.41%] [G loss: 3.998263]\n",
      "epoch:40 step:31612 [D loss: 0.157841, acc: 98.44%] [G loss: 5.023971]\n",
      "epoch:40 step:31613 [D loss: 0.805275, acc: 56.25%] [G loss: 7.673927]\n",
      "epoch:40 step:31614 [D loss: 0.341577, acc: 82.81%] [G loss: 7.574584]\n",
      "epoch:40 step:31615 [D loss: 0.295479, acc: 91.41%] [G loss: 4.792338]\n",
      "epoch:40 step:31616 [D loss: 0.124710, acc: 98.44%] [G loss: 6.290922]\n",
      "epoch:40 step:31617 [D loss: 0.230635, acc: 96.09%] [G loss: 6.708488]\n",
      "epoch:40 step:31618 [D loss: 1.249188, acc: 50.78%] [G loss: 4.927863]\n",
      "epoch:40 step:31619 [D loss: 0.383172, acc: 74.22%] [G loss: 3.613061]\n",
      "epoch:40 step:31620 [D loss: 0.109635, acc: 100.00%] [G loss: 4.439313]\n",
      "epoch:40 step:31621 [D loss: 0.090826, acc: 98.44%] [G loss: 7.475128]\n",
      "epoch:40 step:31622 [D loss: 0.349081, acc: 85.16%] [G loss: 5.498482]\n",
      "epoch:40 step:31623 [D loss: 0.396634, acc: 80.47%] [G loss: 6.252552]\n",
      "epoch:40 step:31624 [D loss: 0.093775, acc: 100.00%] [G loss: 4.365749]\n",
      "epoch:40 step:31625 [D loss: 0.425575, acc: 84.38%] [G loss: 4.998362]\n",
      "epoch:40 step:31626 [D loss: 0.039036, acc: 100.00%] [G loss: 4.889606]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:40 step:31627 [D loss: 0.089737, acc: 99.22%] [G loss: 5.509514]\n",
      "epoch:40 step:31628 [D loss: 0.410850, acc: 76.56%] [G loss: 6.319471]\n",
      "epoch:40 step:31629 [D loss: 0.887336, acc: 50.00%] [G loss: 4.650458]\n",
      "epoch:40 step:31630 [D loss: 0.156458, acc: 96.88%] [G loss: 4.590361]\n",
      "epoch:40 step:31631 [D loss: 0.167447, acc: 99.22%] [G loss: 7.259410]\n",
      "epoch:40 step:31632 [D loss: 0.103967, acc: 98.44%] [G loss: 5.255899]\n",
      "epoch:40 step:31633 [D loss: 0.833497, acc: 53.12%] [G loss: 4.542836]\n",
      "epoch:40 step:31634 [D loss: 0.012739, acc: 100.00%] [G loss: 5.423440]\n",
      "epoch:40 step:31635 [D loss: 0.958611, acc: 50.78%] [G loss: 4.740544]\n",
      "epoch:40 step:31636 [D loss: 0.109218, acc: 99.22%] [G loss: 5.227745]\n",
      "epoch:40 step:31637 [D loss: 1.658885, acc: 10.16%] [G loss: 7.315245]\n",
      "epoch:40 step:31638 [D loss: 0.549851, acc: 71.88%] [G loss: 4.299596]\n",
      "epoch:40 step:31639 [D loss: 1.092828, acc: 39.84%] [G loss: 5.082742]\n",
      "epoch:40 step:31640 [D loss: 0.826803, acc: 50.78%] [G loss: 7.172518]\n",
      "epoch:40 step:31641 [D loss: 0.014767, acc: 100.00%] [G loss: 7.477104]\n",
      "epoch:40 step:31642 [D loss: 0.074939, acc: 100.00%] [G loss: 5.089760]\n",
      "epoch:40 step:31643 [D loss: 0.635305, acc: 61.72%] [G loss: 8.315018]\n",
      "epoch:40 step:31644 [D loss: 1.222265, acc: 50.78%] [G loss: 5.293654]\n",
      "epoch:40 step:31645 [D loss: 0.291910, acc: 92.97%] [G loss: 7.819938]\n",
      "epoch:40 step:31646 [D loss: 0.203147, acc: 92.19%] [G loss: 7.998497]\n",
      "epoch:40 step:31647 [D loss: 0.054457, acc: 100.00%] [G loss: 3.530554]\n",
      "epoch:40 step:31648 [D loss: 0.030703, acc: 100.00%] [G loss: 5.946762]\n",
      "epoch:40 step:31649 [D loss: 0.149717, acc: 96.88%] [G loss: 5.822080]\n",
      "epoch:40 step:31650 [D loss: 0.201780, acc: 96.09%] [G loss: 7.392808]\n",
      "epoch:40 step:31651 [D loss: 0.975523, acc: 38.28%] [G loss: 6.500093]\n",
      "epoch:40 step:31652 [D loss: 0.078833, acc: 99.22%] [G loss: 5.600364]\n",
      "epoch:40 step:31653 [D loss: 0.110556, acc: 100.00%] [G loss: 6.364000]\n",
      "epoch:40 step:31654 [D loss: 0.702916, acc: 55.47%] [G loss: 6.158358]\n",
      "epoch:40 step:31655 [D loss: 0.135216, acc: 98.44%] [G loss: 3.734278]\n",
      "epoch:40 step:31656 [D loss: 0.199992, acc: 92.19%] [G loss: 7.742901]\n",
      "epoch:40 step:31657 [D loss: 0.374970, acc: 79.69%] [G loss: 6.238895]\n",
      "epoch:40 step:31658 [D loss: 0.239117, acc: 95.31%] [G loss: 7.745182]\n",
      "epoch:40 step:31659 [D loss: 0.881683, acc: 47.66%] [G loss: 8.567266]\n",
      "epoch:40 step:31660 [D loss: 0.954087, acc: 51.56%] [G loss: 10.773930]\n",
      "epoch:40 step:31661 [D loss: 0.116317, acc: 98.44%] [G loss: 3.897664]\n",
      "epoch:40 step:31662 [D loss: 0.978662, acc: 47.66%] [G loss: 4.635894]\n",
      "epoch:40 step:31663 [D loss: 0.341751, acc: 89.84%] [G loss: 3.842140]\n",
      "epoch:40 step:31664 [D loss: 0.165612, acc: 96.09%] [G loss: 3.399082]\n",
      "epoch:40 step:31665 [D loss: 0.130344, acc: 98.44%] [G loss: 5.931137]\n",
      "epoch:40 step:31666 [D loss: 0.274931, acc: 89.84%] [G loss: 4.551789]\n",
      "epoch:40 step:31667 [D loss: 0.241123, acc: 91.41%] [G loss: 5.451785]\n",
      "epoch:40 step:31668 [D loss: 0.153265, acc: 97.66%] [G loss: 5.978446]\n",
      "epoch:40 step:31669 [D loss: 0.569760, acc: 68.75%] [G loss: 6.099719]\n",
      "epoch:40 step:31670 [D loss: 0.170579, acc: 99.22%] [G loss: 4.566577]\n",
      "epoch:40 step:31671 [D loss: 0.312869, acc: 89.06%] [G loss: 3.244385]\n",
      "epoch:40 step:31672 [D loss: 0.166592, acc: 97.66%] [G loss: 3.144736]\n",
      "epoch:40 step:31673 [D loss: 0.294201, acc: 93.75%] [G loss: 5.648264]\n",
      "epoch:40 step:31674 [D loss: 0.235613, acc: 94.53%] [G loss: 6.309447]\n",
      "epoch:40 step:31675 [D loss: 0.088325, acc: 100.00%] [G loss: 7.749934]\n",
      "epoch:40 step:31676 [D loss: 0.184260, acc: 98.44%] [G loss: 6.698725]\n",
      "epoch:40 step:31677 [D loss: 0.279604, acc: 94.53%] [G loss: 6.123374]\n",
      "epoch:40 step:31678 [D loss: 0.262246, acc: 92.19%] [G loss: 7.328190]\n",
      "epoch:40 step:31679 [D loss: 0.166521, acc: 97.66%] [G loss: 5.383283]\n",
      "epoch:40 step:31680 [D loss: 0.778061, acc: 53.91%] [G loss: 6.247857]\n",
      "epoch:40 step:31681 [D loss: 0.139296, acc: 100.00%] [G loss: 7.548254]\n",
      "epoch:40 step:31682 [D loss: 0.419532, acc: 88.28%] [G loss: 5.628963]\n",
      "epoch:40 step:31683 [D loss: 0.311090, acc: 85.16%] [G loss: 3.172403]\n",
      "epoch:40 step:31684 [D loss: 0.173810, acc: 96.88%] [G loss: 5.761735]\n",
      "epoch:40 step:31685 [D loss: 0.106217, acc: 100.00%] [G loss: 4.800403]\n",
      "epoch:40 step:31686 [D loss: 0.098143, acc: 100.00%] [G loss: 8.240768]\n",
      "epoch:40 step:31687 [D loss: 0.172460, acc: 96.88%] [G loss: 4.084190]\n",
      "epoch:40 step:31688 [D loss: 0.198623, acc: 94.53%] [G loss: 6.925349]\n",
      "epoch:40 step:31689 [D loss: 0.666683, acc: 55.47%] [G loss: 5.856547]\n",
      "epoch:40 step:31690 [D loss: 0.350103, acc: 88.28%] [G loss: 7.808562]\n",
      "epoch:40 step:31691 [D loss: 0.921626, acc: 51.56%] [G loss: 5.346533]\n",
      "epoch:40 step:31692 [D loss: 0.173872, acc: 98.44%] [G loss: 3.957323]\n",
      "epoch:40 step:31693 [D loss: 0.245417, acc: 91.41%] [G loss: 6.472941]\n",
      "epoch:40 step:31694 [D loss: 0.512834, acc: 78.12%] [G loss: 7.541101]\n",
      "epoch:40 step:31695 [D loss: 0.292672, acc: 93.75%] [G loss: 4.948771]\n",
      "epoch:40 step:31696 [D loss: 1.139470, acc: 35.94%] [G loss: 7.270427]\n",
      "epoch:40 step:31697 [D loss: 0.289309, acc: 94.53%] [G loss: 4.792833]\n",
      "epoch:40 step:31698 [D loss: 0.045428, acc: 100.00%] [G loss: 8.941027]\n",
      "epoch:40 step:31699 [D loss: 0.994327, acc: 53.12%] [G loss: 5.630022]\n",
      "epoch:40 step:31700 [D loss: 0.069545, acc: 100.00%] [G loss: 3.010458]\n",
      "epoch:40 step:31701 [D loss: 0.065179, acc: 100.00%] [G loss: 10.697132]\n",
      "epoch:40 step:31702 [D loss: 0.281016, acc: 89.06%] [G loss: 4.944722]\n",
      "epoch:40 step:31703 [D loss: 0.445914, acc: 72.66%] [G loss: 10.240157]\n",
      "epoch:40 step:31704 [D loss: 0.239151, acc: 90.62%] [G loss: 5.708625]\n",
      "epoch:40 step:31705 [D loss: 0.359651, acc: 89.06%] [G loss: 6.613078]\n",
      "epoch:40 step:31706 [D loss: 0.123377, acc: 99.22%] [G loss: 8.933990]\n",
      "epoch:40 step:31707 [D loss: 0.076270, acc: 100.00%] [G loss: 3.354800]\n",
      "epoch:40 step:31708 [D loss: 0.165944, acc: 99.22%] [G loss: 5.366290]\n",
      "epoch:40 step:31709 [D loss: 0.128394, acc: 99.22%] [G loss: 6.124982]\n",
      "epoch:40 step:31710 [D loss: 0.029739, acc: 100.00%] [G loss: 8.366779]\n",
      "epoch:40 step:31711 [D loss: 0.026800, acc: 100.00%] [G loss: 8.639681]\n",
      "epoch:40 step:31712 [D loss: 0.798025, acc: 48.44%] [G loss: 7.526562]\n",
      "epoch:40 step:31713 [D loss: 0.386985, acc: 76.56%] [G loss: 4.584827]\n",
      "epoch:40 step:31714 [D loss: 0.029324, acc: 100.00%] [G loss: 6.313275]\n",
      "epoch:40 step:31715 [D loss: 0.604399, acc: 60.94%] [G loss: 7.857767]\n",
      "epoch:40 step:31716 [D loss: 0.786604, acc: 48.44%] [G loss: 3.375787]\n",
      "epoch:40 step:31717 [D loss: 0.422440, acc: 83.59%] [G loss: 6.265635]\n",
      "epoch:40 step:31718 [D loss: 0.029632, acc: 100.00%] [G loss: 8.124301]\n",
      "epoch:40 step:31719 [D loss: 0.204116, acc: 96.88%] [G loss: 5.339041]\n",
      "epoch:40 step:31720 [D loss: 0.407658, acc: 85.94%] [G loss: 4.964779]\n",
      "epoch:40 step:31721 [D loss: 0.559922, acc: 67.97%] [G loss: 6.737541]\n",
      "epoch:40 step:31722 [D loss: 0.298974, acc: 92.19%] [G loss: 6.090322]\n",
      "epoch:40 step:31723 [D loss: 0.298688, acc: 96.09%] [G loss: 4.491654]\n",
      "epoch:40 step:31724 [D loss: 0.094802, acc: 100.00%] [G loss: 4.768247]\n",
      "epoch:40 step:31725 [D loss: 0.869480, acc: 40.62%] [G loss: 4.228031]\n",
      "epoch:40 step:31726 [D loss: 0.171981, acc: 97.66%] [G loss: 4.805530]\n",
      "epoch:40 step:31727 [D loss: 1.662990, acc: 9.38%] [G loss: 10.249454]\n",
      "epoch:40 step:31728 [D loss: 0.032553, acc: 100.00%] [G loss: 7.304491]\n",
      "epoch:40 step:31729 [D loss: 0.250008, acc: 89.06%] [G loss: 6.377947]\n",
      "epoch:40 step:31730 [D loss: 0.314226, acc: 83.59%] [G loss: 8.457099]\n",
      "epoch:40 step:31731 [D loss: 0.076680, acc: 99.22%] [G loss: 7.481634]\n",
      "epoch:40 step:31732 [D loss: 0.255206, acc: 92.19%] [G loss: 3.849115]\n",
      "epoch:40 step:31733 [D loss: 0.041186, acc: 100.00%] [G loss: 7.242325]\n",
      "epoch:40 step:31734 [D loss: 0.654817, acc: 64.06%] [G loss: 4.401885]\n",
      "epoch:40 step:31735 [D loss: 0.029000, acc: 100.00%] [G loss: 9.152316]\n",
      "epoch:40 step:31736 [D loss: 0.151514, acc: 96.88%] [G loss: 6.389180]\n",
      "epoch:40 step:31737 [D loss: 0.094004, acc: 99.22%] [G loss: 8.770975]\n",
      "epoch:40 step:31738 [D loss: 0.036828, acc: 100.00%] [G loss: 7.164274]\n",
      "epoch:40 step:31739 [D loss: 1.303438, acc: 32.81%] [G loss: 5.511959]\n",
      "epoch:40 step:31740 [D loss: 0.311104, acc: 87.50%] [G loss: 6.448503]\n",
      "epoch:40 step:31741 [D loss: 0.265959, acc: 89.84%] [G loss: 5.020728]\n",
      "epoch:40 step:31742 [D loss: 0.345397, acc: 83.59%] [G loss: 3.429219]\n",
      "epoch:40 step:31743 [D loss: 0.050134, acc: 99.22%] [G loss: 7.601701]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:40 step:31744 [D loss: 0.461236, acc: 77.34%] [G loss: 4.025198]\n",
      "epoch:40 step:31745 [D loss: 0.154388, acc: 96.09%] [G loss: 3.375817]\n",
      "epoch:40 step:31746 [D loss: 0.484287, acc: 80.47%] [G loss: 4.021987]\n",
      "epoch:40 step:31747 [D loss: 0.248591, acc: 95.31%] [G loss: 4.207640]\n",
      "epoch:40 step:31748 [D loss: 0.168714, acc: 95.31%] [G loss: 6.337382]\n",
      "epoch:40 step:31749 [D loss: 0.293544, acc: 91.41%] [G loss: 6.490436]\n",
      "epoch:40 step:31750 [D loss: 0.116728, acc: 99.22%] [G loss: 5.630867]\n",
      "epoch:40 step:31751 [D loss: 0.018244, acc: 100.00%] [G loss: 10.083730]\n",
      "epoch:40 step:31752 [D loss: 0.259739, acc: 93.75%] [G loss: 2.669596]\n",
      "epoch:40 step:31753 [D loss: 0.192486, acc: 99.22%] [G loss: 7.981021]\n",
      "epoch:40 step:31754 [D loss: 0.917405, acc: 52.34%] [G loss: 1.989711]\n",
      "epoch:40 step:31755 [D loss: 0.109995, acc: 98.44%] [G loss: 6.626039]\n",
      "epoch:40 step:31756 [D loss: 0.357995, acc: 78.91%] [G loss: 6.171061]\n",
      "epoch:40 step:31757 [D loss: 0.713563, acc: 53.91%] [G loss: 8.609348]\n",
      "epoch:40 step:31758 [D loss: 0.303780, acc: 85.16%] [G loss: 7.927539]\n",
      "epoch:40 step:31759 [D loss: 1.824015, acc: 38.28%] [G loss: 8.102164]\n",
      "epoch:40 step:31760 [D loss: 0.185622, acc: 97.66%] [G loss: 3.805121]\n",
      "epoch:40 step:31761 [D loss: 0.587571, acc: 60.16%] [G loss: 6.335125]\n",
      "epoch:40 step:31762 [D loss: 0.747821, acc: 51.56%] [G loss: 5.212920]\n",
      "epoch:40 step:31763 [D loss: 0.073027, acc: 100.00%] [G loss: 5.592672]\n",
      "epoch:40 step:31764 [D loss: 0.132893, acc: 100.00%] [G loss: 7.281933]\n",
      "epoch:40 step:31765 [D loss: 0.783667, acc: 57.81%] [G loss: 6.130577]\n",
      "epoch:40 step:31766 [D loss: 0.166815, acc: 96.88%] [G loss: 5.666664]\n",
      "epoch:40 step:31767 [D loss: 0.855861, acc: 50.00%] [G loss: 10.122448]\n",
      "epoch:40 step:31768 [D loss: 0.234552, acc: 90.62%] [G loss: 5.041980]\n",
      "epoch:40 step:31769 [D loss: 0.808889, acc: 49.22%] [G loss: 4.373119]\n",
      "epoch:40 step:31770 [D loss: 0.014656, acc: 100.00%] [G loss: 6.571589]\n",
      "epoch:40 step:31771 [D loss: 0.571301, acc: 60.94%] [G loss: 7.311625]\n",
      "epoch:40 step:31772 [D loss: 0.377837, acc: 78.12%] [G loss: 3.895117]\n",
      "epoch:40 step:31773 [D loss: 0.049871, acc: 100.00%] [G loss: 6.741471]\n",
      "epoch:40 step:31774 [D loss: 0.555170, acc: 68.75%] [G loss: 4.193540]\n",
      "epoch:40 step:31775 [D loss: 0.230354, acc: 96.88%] [G loss: 6.694671]\n",
      "epoch:40 step:31776 [D loss: 0.600814, acc: 64.06%] [G loss: 5.806573]\n",
      "epoch:40 step:31777 [D loss: 0.022328, acc: 100.00%] [G loss: 8.902522]\n",
      "epoch:40 step:31778 [D loss: 0.028389, acc: 100.00%] [G loss: 6.569350]\n",
      "epoch:40 step:31779 [D loss: 0.171687, acc: 96.88%] [G loss: 7.799381]\n",
      "epoch:40 step:31780 [D loss: 0.283048, acc: 87.50%] [G loss: 7.553392]\n",
      "epoch:40 step:31781 [D loss: 0.080056, acc: 99.22%] [G loss: 4.930276]\n",
      "epoch:40 step:31782 [D loss: 0.364199, acc: 89.84%] [G loss: 5.799603]\n",
      "epoch:40 step:31783 [D loss: 0.085061, acc: 100.00%] [G loss: 5.357239]\n",
      "epoch:40 step:31784 [D loss: 0.108341, acc: 99.22%] [G loss: 6.062128]\n",
      "epoch:40 step:31785 [D loss: 0.257868, acc: 92.97%] [G loss: 5.170188]\n",
      "epoch:40 step:31786 [D loss: 0.500485, acc: 74.22%] [G loss: 6.234368]\n",
      "epoch:40 step:31787 [D loss: 0.084707, acc: 98.44%] [G loss: 6.229607]\n",
      "epoch:40 step:31788 [D loss: 0.074986, acc: 100.00%] [G loss: 6.009253]\n",
      "epoch:40 step:31789 [D loss: 0.568900, acc: 67.19%] [G loss: 4.832969]\n",
      "epoch:40 step:31790 [D loss: 0.021855, acc: 100.00%] [G loss: 6.128497]\n",
      "epoch:40 step:31791 [D loss: 0.669280, acc: 64.84%] [G loss: 7.760666]\n",
      "epoch:40 step:31792 [D loss: 0.246355, acc: 96.88%] [G loss: 3.748622]\n",
      "epoch:40 step:31793 [D loss: 0.397535, acc: 85.16%] [G loss: 6.124863]\n",
      "epoch:40 step:31794 [D loss: 0.520458, acc: 72.66%] [G loss: 5.027990]\n",
      "epoch:40 step:31795 [D loss: 0.013726, acc: 100.00%] [G loss: 8.258714]\n",
      "epoch:40 step:31796 [D loss: 0.043739, acc: 100.00%] [G loss: 5.356678]\n",
      "epoch:40 step:31797 [D loss: 0.088093, acc: 100.00%] [G loss: 5.437798]\n",
      "epoch:40 step:31798 [D loss: 0.421993, acc: 79.69%] [G loss: 5.891345]\n",
      "epoch:40 step:31799 [D loss: 0.296885, acc: 87.50%] [G loss: 5.268662]\n",
      "epoch:40 step:31800 [D loss: 0.104339, acc: 99.22%] [G loss: 8.146379]\n",
      "##############\n",
      "[0.8604241  0.87347901 0.83155623 0.82016852 0.76658756 0.81444758\n",
      " 0.87589147 0.80939738 0.79117555 0.82826439]\n",
      "##########\n",
      "epoch:40 step:31801 [D loss: 0.103735, acc: 98.44%] [G loss: 7.369910]\n",
      "epoch:40 step:31802 [D loss: 1.445557, acc: 46.09%] [G loss: 2.538183]\n",
      "epoch:40 step:31803 [D loss: 0.300085, acc: 86.72%] [G loss: 2.118937]\n",
      "epoch:40 step:31804 [D loss: 0.338822, acc: 79.69%] [G loss: 9.067947]\n",
      "epoch:40 step:31805 [D loss: 0.287225, acc: 95.31%] [G loss: 4.630196]\n",
      "epoch:40 step:31806 [D loss: 0.283800, acc: 95.31%] [G loss: 4.946888]\n",
      "epoch:40 step:31807 [D loss: 0.425662, acc: 78.12%] [G loss: 5.095714]\n",
      "epoch:40 step:31808 [D loss: 0.515680, acc: 71.88%] [G loss: 5.138206]\n",
      "epoch:40 step:31809 [D loss: 0.087722, acc: 98.44%] [G loss: 7.568999]\n",
      "epoch:40 step:31810 [D loss: 0.205050, acc: 94.53%] [G loss: 7.330312]\n",
      "epoch:40 step:31811 [D loss: 0.095722, acc: 100.00%] [G loss: 6.401788]\n",
      "epoch:40 step:31812 [D loss: 0.291160, acc: 96.88%] [G loss: 5.681490]\n",
      "epoch:40 step:31813 [D loss: 0.547962, acc: 64.06%] [G loss: 6.862813]\n",
      "epoch:40 step:31814 [D loss: 0.119379, acc: 97.66%] [G loss: 4.595300]\n",
      "epoch:40 step:31815 [D loss: 0.334270, acc: 89.06%] [G loss: 3.243115]\n",
      "epoch:40 step:31816 [D loss: 0.239006, acc: 96.09%] [G loss: 6.654022]\n",
      "epoch:40 step:31817 [D loss: 0.149853, acc: 99.22%] [G loss: 2.335246]\n",
      "epoch:40 step:31818 [D loss: 0.215785, acc: 99.22%] [G loss: 7.265521]\n",
      "epoch:40 step:31819 [D loss: 0.166714, acc: 98.44%] [G loss: 2.942054]\n",
      "epoch:40 step:31820 [D loss: 0.216047, acc: 99.22%] [G loss: 5.854197]\n",
      "epoch:40 step:31821 [D loss: 0.135047, acc: 100.00%] [G loss: 5.573759]\n",
      "epoch:40 step:31822 [D loss: 0.223962, acc: 92.19%] [G loss: 5.523795]\n",
      "epoch:40 step:31823 [D loss: 0.031773, acc: 100.00%] [G loss: 5.408391]\n",
      "epoch:40 step:31824 [D loss: 0.620115, acc: 59.38%] [G loss: 6.177069]\n",
      "epoch:40 step:31825 [D loss: 0.429618, acc: 69.53%] [G loss: 5.760323]\n",
      "epoch:40 step:31826 [D loss: 0.491852, acc: 69.53%] [G loss: 8.643898]\n",
      "epoch:40 step:31827 [D loss: 0.437824, acc: 79.69%] [G loss: 7.123532]\n",
      "epoch:40 step:31828 [D loss: 0.197376, acc: 96.09%] [G loss: 6.872686]\n",
      "epoch:40 step:31829 [D loss: 0.084602, acc: 100.00%] [G loss: 5.194411]\n",
      "epoch:40 step:31830 [D loss: 0.450149, acc: 82.03%] [G loss: 6.487076]\n",
      "epoch:40 step:31831 [D loss: 0.109193, acc: 99.22%] [G loss: 5.420128]\n",
      "epoch:40 step:31832 [D loss: 0.420360, acc: 83.59%] [G loss: 4.695382]\n",
      "epoch:40 step:31833 [D loss: 0.082476, acc: 100.00%] [G loss: 5.802011]\n",
      "epoch:40 step:31834 [D loss: 0.139613, acc: 99.22%] [G loss: 4.488175]\n",
      "epoch:40 step:31835 [D loss: 0.089651, acc: 99.22%] [G loss: 6.026643]\n",
      "epoch:40 step:31836 [D loss: 0.115928, acc: 98.44%] [G loss: 7.272397]\n",
      "epoch:40 step:31837 [D loss: 0.482611, acc: 63.28%] [G loss: 7.096491]\n",
      "epoch:40 step:31838 [D loss: 0.045839, acc: 100.00%] [G loss: 4.926518]\n",
      "epoch:40 step:31839 [D loss: 1.360700, acc: 50.00%] [G loss: 6.101755]\n",
      "epoch:40 step:31840 [D loss: 0.170650, acc: 99.22%] [G loss: 5.224307]\n",
      "epoch:40 step:31841 [D loss: 0.046185, acc: 100.00%] [G loss: 4.366928]\n",
      "epoch:40 step:31842 [D loss: 1.053916, acc: 51.56%] [G loss: 8.597256]\n",
      "epoch:40 step:31843 [D loss: 0.214413, acc: 94.53%] [G loss: 5.051650]\n",
      "epoch:40 step:31844 [D loss: 0.311514, acc: 91.41%] [G loss: 7.243516]\n",
      "epoch:40 step:31845 [D loss: 0.299851, acc: 88.28%] [G loss: 6.213277]\n",
      "epoch:40 step:31846 [D loss: 0.096092, acc: 100.00%] [G loss: 8.153381]\n",
      "epoch:40 step:31847 [D loss: 0.195661, acc: 96.88%] [G loss: 2.972567]\n",
      "epoch:40 step:31848 [D loss: 0.109749, acc: 99.22%] [G loss: 4.871135]\n",
      "epoch:40 step:31849 [D loss: 0.659878, acc: 60.94%] [G loss: 7.522598]\n",
      "epoch:40 step:31850 [D loss: 0.206851, acc: 98.44%] [G loss: 5.622892]\n",
      "epoch:40 step:31851 [D loss: 0.225073, acc: 98.44%] [G loss: 5.040210]\n",
      "epoch:40 step:31852 [D loss: 0.189777, acc: 96.88%] [G loss: 2.235665]\n",
      "epoch:40 step:31853 [D loss: 1.002829, acc: 35.94%] [G loss: 8.581135]\n",
      "epoch:40 step:31854 [D loss: 0.435355, acc: 71.09%] [G loss: 8.891973]\n",
      "epoch:40 step:31855 [D loss: 0.079189, acc: 98.44%] [G loss: 8.960358]\n",
      "epoch:40 step:31856 [D loss: 0.531569, acc: 74.22%] [G loss: 5.801161]\n",
      "epoch:40 step:31857 [D loss: 0.579668, acc: 61.72%] [G loss: 10.749090]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:40 step:31858 [D loss: 0.179750, acc: 95.31%] [G loss: 7.332439]\n",
      "epoch:40 step:31859 [D loss: 0.778586, acc: 50.00%] [G loss: 3.354509]\n",
      "epoch:40 step:31860 [D loss: 0.401410, acc: 71.88%] [G loss: 7.629346]\n",
      "epoch:40 step:31861 [D loss: 0.811907, acc: 51.56%] [G loss: 5.853682]\n",
      "epoch:40 step:31862 [D loss: 0.180552, acc: 97.66%] [G loss: 5.982641]\n",
      "epoch:40 step:31863 [D loss: 0.311475, acc: 82.03%] [G loss: 7.012778]\n",
      "epoch:40 step:31864 [D loss: 0.206892, acc: 96.09%] [G loss: 7.473267]\n",
      "epoch:40 step:31865 [D loss: 0.149054, acc: 95.31%] [G loss: 6.327888]\n",
      "epoch:40 step:31866 [D loss: 0.162181, acc: 96.88%] [G loss: 5.972092]\n",
      "epoch:40 step:31867 [D loss: 0.010687, acc: 100.00%] [G loss: 6.845676]\n",
      "epoch:40 step:31868 [D loss: 0.136025, acc: 98.44%] [G loss: 4.468344]\n",
      "epoch:40 step:31869 [D loss: 0.119237, acc: 98.44%] [G loss: 4.114466]\n",
      "epoch:40 step:31870 [D loss: 0.163478, acc: 95.31%] [G loss: 9.938745]\n",
      "epoch:40 step:31871 [D loss: 0.112296, acc: 99.22%] [G loss: 7.568823]\n",
      "epoch:40 step:31872 [D loss: 0.167861, acc: 96.88%] [G loss: 3.123703]\n",
      "epoch:40 step:31873 [D loss: 0.493596, acc: 78.12%] [G loss: 6.384346]\n",
      "epoch:40 step:31874 [D loss: 1.061026, acc: 30.47%] [G loss: 8.182043]\n",
      "epoch:40 step:31875 [D loss: 0.055491, acc: 100.00%] [G loss: 4.725990]\n",
      "epoch:40 step:31876 [D loss: 0.269650, acc: 92.97%] [G loss: 2.416685]\n",
      "epoch:40 step:31877 [D loss: 0.089382, acc: 98.44%] [G loss: 5.525857]\n",
      "epoch:40 step:31878 [D loss: 0.257517, acc: 95.31%] [G loss: 6.516555]\n",
      "epoch:40 step:31879 [D loss: 0.304116, acc: 87.50%] [G loss: 9.531488]\n",
      "epoch:40 step:31880 [D loss: 0.050587, acc: 100.00%] [G loss: 3.478390]\n",
      "epoch:40 step:31881 [D loss: 0.128759, acc: 98.44%] [G loss: 4.529079]\n",
      "epoch:40 step:31882 [D loss: 0.020429, acc: 100.00%] [G loss: 9.219749]\n",
      "epoch:40 step:31883 [D loss: 0.203439, acc: 99.22%] [G loss: 4.764529]\n",
      "epoch:40 step:31884 [D loss: 0.400493, acc: 79.69%] [G loss: 3.449190]\n",
      "epoch:40 step:31885 [D loss: 0.578502, acc: 59.38%] [G loss: 5.476047]\n",
      "epoch:40 step:31886 [D loss: 0.812374, acc: 53.12%] [G loss: 10.420795]\n",
      "epoch:40 step:31887 [D loss: 0.499194, acc: 71.09%] [G loss: 5.237110]\n",
      "epoch:40 step:31888 [D loss: 0.007036, acc: 100.00%] [G loss: 7.720512]\n",
      "epoch:40 step:31889 [D loss: 0.332054, acc: 83.59%] [G loss: 5.019619]\n",
      "epoch:40 step:31890 [D loss: 0.603103, acc: 67.97%] [G loss: 6.932568]\n",
      "epoch:40 step:31891 [D loss: 0.699490, acc: 53.91%] [G loss: 6.138649]\n",
      "epoch:40 step:31892 [D loss: 0.274903, acc: 91.41%] [G loss: 5.968532]\n",
      "epoch:40 step:31893 [D loss: 0.013101, acc: 100.00%] [G loss: 6.298262]\n",
      "epoch:40 step:31894 [D loss: 0.051801, acc: 100.00%] [G loss: 8.862719]\n",
      "epoch:40 step:31895 [D loss: 0.115361, acc: 100.00%] [G loss: 5.785361]\n",
      "epoch:40 step:31896 [D loss: 0.304796, acc: 85.16%] [G loss: 3.401049]\n",
      "epoch:40 step:31897 [D loss: 0.717653, acc: 57.81%] [G loss: 6.053802]\n",
      "epoch:40 step:31898 [D loss: 0.171229, acc: 97.66%] [G loss: 5.884243]\n",
      "epoch:40 step:31899 [D loss: 0.031191, acc: 100.00%] [G loss: 8.597031]\n",
      "epoch:40 step:31900 [D loss: 0.410010, acc: 78.91%] [G loss: 5.916695]\n",
      "epoch:40 step:31901 [D loss: 0.803142, acc: 53.12%] [G loss: 5.753253]\n",
      "epoch:40 step:31902 [D loss: 0.737120, acc: 57.03%] [G loss: 7.477015]\n",
      "epoch:40 step:31903 [D loss: 0.150626, acc: 99.22%] [G loss: 4.616904]\n",
      "epoch:40 step:31904 [D loss: 0.151353, acc: 97.66%] [G loss: 4.859370]\n",
      "epoch:40 step:31905 [D loss: 0.052740, acc: 100.00%] [G loss: 8.875885]\n",
      "epoch:40 step:31906 [D loss: 0.764866, acc: 55.47%] [G loss: 5.518454]\n",
      "epoch:40 step:31907 [D loss: 0.764343, acc: 52.34%] [G loss: 4.738894]\n",
      "epoch:40 step:31908 [D loss: 0.074899, acc: 100.00%] [G loss: 4.724027]\n",
      "epoch:40 step:31909 [D loss: 0.108601, acc: 100.00%] [G loss: 7.316597]\n",
      "epoch:40 step:31910 [D loss: 0.153234, acc: 98.44%] [G loss: 3.235063]\n",
      "epoch:40 step:31911 [D loss: 0.242318, acc: 92.19%] [G loss: 8.683339]\n",
      "epoch:40 step:31912 [D loss: 0.034511, acc: 99.22%] [G loss: 4.168882]\n",
      "epoch:40 step:31913 [D loss: 0.424039, acc: 83.59%] [G loss: 7.594086]\n",
      "epoch:40 step:31914 [D loss: 0.131797, acc: 99.22%] [G loss: 3.264692]\n",
      "epoch:40 step:31915 [D loss: 0.024688, acc: 100.00%] [G loss: 8.043702]\n",
      "epoch:40 step:31916 [D loss: 0.166292, acc: 96.88%] [G loss: 3.589138]\n",
      "epoch:40 step:31917 [D loss: 0.054006, acc: 100.00%] [G loss: 8.165178]\n",
      "epoch:40 step:31918 [D loss: 0.170478, acc: 98.44%] [G loss: 4.597094]\n",
      "epoch:40 step:31919 [D loss: 0.194985, acc: 97.66%] [G loss: 3.358397]\n",
      "epoch:40 step:31920 [D loss: 0.441999, acc: 79.69%] [G loss: 4.399495]\n",
      "epoch:40 step:31921 [D loss: 0.108094, acc: 100.00%] [G loss: 3.474329]\n",
      "epoch:40 step:31922 [D loss: 0.574730, acc: 69.53%] [G loss: 7.979620]\n",
      "epoch:40 step:31923 [D loss: 0.099196, acc: 99.22%] [G loss: 6.139831]\n",
      "epoch:40 step:31924 [D loss: 0.680308, acc: 57.81%] [G loss: 2.263998]\n",
      "epoch:40 step:31925 [D loss: 0.121688, acc: 98.44%] [G loss: 4.530359]\n",
      "epoch:40 step:31926 [D loss: 0.269606, acc: 92.19%] [G loss: 7.111230]\n",
      "epoch:40 step:31927 [D loss: 0.343953, acc: 82.81%] [G loss: 8.895151]\n",
      "epoch:40 step:31928 [D loss: 0.194336, acc: 94.53%] [G loss: 5.944694]\n",
      "epoch:40 step:31929 [D loss: 0.363401, acc: 84.38%] [G loss: 4.830283]\n",
      "epoch:40 step:31930 [D loss: 0.013601, acc: 100.00%] [G loss: 10.566753]\n",
      "epoch:40 step:31931 [D loss: 0.112643, acc: 100.00%] [G loss: 5.322463]\n",
      "epoch:40 step:31932 [D loss: 0.070435, acc: 100.00%] [G loss: 5.965811]\n",
      "epoch:40 step:31933 [D loss: 0.172399, acc: 96.88%] [G loss: 5.865938]\n",
      "epoch:40 step:31934 [D loss: 0.573784, acc: 71.88%] [G loss: 7.245057]\n",
      "epoch:40 step:31935 [D loss: 0.092039, acc: 100.00%] [G loss: 5.519281]\n",
      "epoch:40 step:31936 [D loss: 0.980270, acc: 50.00%] [G loss: 7.801963]\n",
      "epoch:40 step:31937 [D loss: 0.590165, acc: 67.19%] [G loss: 4.135890]\n",
      "epoch:40 step:31938 [D loss: 0.344777, acc: 91.41%] [G loss: 4.275186]\n",
      "epoch:40 step:31939 [D loss: 0.344410, acc: 82.03%] [G loss: 9.105003]\n",
      "epoch:40 step:31940 [D loss: 0.353363, acc: 79.69%] [G loss: 4.627060]\n",
      "epoch:40 step:31941 [D loss: 0.505881, acc: 78.91%] [G loss: 6.488762]\n",
      "epoch:40 step:31942 [D loss: 1.071178, acc: 50.00%] [G loss: 4.048466]\n",
      "epoch:40 step:31943 [D loss: 0.205623, acc: 96.09%] [G loss: 9.500973]\n",
      "epoch:40 step:31944 [D loss: 0.594237, acc: 60.94%] [G loss: 5.727298]\n",
      "epoch:40 step:31945 [D loss: 0.432758, acc: 71.09%] [G loss: 7.436640]\n",
      "epoch:40 step:31946 [D loss: 0.271294, acc: 88.28%] [G loss: 7.324409]\n",
      "epoch:40 step:31947 [D loss: 0.397893, acc: 77.34%] [G loss: 6.657668]\n",
      "epoch:40 step:31948 [D loss: 0.895960, acc: 50.78%] [G loss: 6.270692]\n",
      "epoch:40 step:31949 [D loss: 0.072076, acc: 100.00%] [G loss: 3.675711]\n",
      "epoch:40 step:31950 [D loss: 0.130038, acc: 100.00%] [G loss: 3.672514]\n",
      "epoch:40 step:31951 [D loss: 0.225123, acc: 91.41%] [G loss: 7.302146]\n",
      "epoch:40 step:31952 [D loss: 0.633349, acc: 63.28%] [G loss: 6.772740]\n",
      "epoch:40 step:31953 [D loss: 1.048350, acc: 50.78%] [G loss: 12.995464]\n",
      "epoch:40 step:31954 [D loss: 0.194427, acc: 96.09%] [G loss: 5.577679]\n",
      "epoch:40 step:31955 [D loss: 0.029142, acc: 100.00%] [G loss: 7.809761]\n",
      "epoch:40 step:31956 [D loss: 0.189298, acc: 95.31%] [G loss: 3.007869]\n",
      "epoch:40 step:31957 [D loss: 0.037012, acc: 100.00%] [G loss: 5.468436]\n",
      "epoch:40 step:31958 [D loss: 0.105261, acc: 100.00%] [G loss: 9.115687]\n",
      "epoch:40 step:31959 [D loss: 0.929633, acc: 51.56%] [G loss: 10.302649]\n",
      "epoch:40 step:31960 [D loss: 0.030261, acc: 100.00%] [G loss: 4.036587]\n",
      "epoch:40 step:31961 [D loss: 0.026092, acc: 100.00%] [G loss: 8.668038]\n",
      "epoch:40 step:31962 [D loss: 0.233932, acc: 93.75%] [G loss: 2.478495]\n",
      "epoch:40 step:31963 [D loss: 0.096706, acc: 99.22%] [G loss: 8.081974]\n",
      "epoch:40 step:31964 [D loss: 0.075070, acc: 100.00%] [G loss: 6.462681]\n",
      "epoch:40 step:31965 [D loss: 0.023332, acc: 100.00%] [G loss: 6.053445]\n",
      "epoch:40 step:31966 [D loss: 0.028143, acc: 100.00%] [G loss: 10.038021]\n",
      "epoch:40 step:31967 [D loss: 0.045211, acc: 99.22%] [G loss: 5.888758]\n",
      "epoch:40 step:31968 [D loss: 0.070888, acc: 100.00%] [G loss: 5.587599]\n",
      "epoch:40 step:31969 [D loss: 0.156694, acc: 97.66%] [G loss: 7.401247]\n",
      "epoch:40 step:31970 [D loss: 0.396044, acc: 82.81%] [G loss: 9.104993]\n",
      "epoch:40 step:31971 [D loss: 0.257460, acc: 92.97%] [G loss: 9.854746]\n",
      "epoch:40 step:31972 [D loss: 0.098083, acc: 100.00%] [G loss: 6.138230]\n",
      "epoch:40 step:31973 [D loss: 0.106104, acc: 99.22%] [G loss: 4.001581]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:40 step:31974 [D loss: 0.124414, acc: 98.44%] [G loss: 7.226694]\n",
      "epoch:40 step:31975 [D loss: 0.143715, acc: 97.66%] [G loss: 6.970652]\n",
      "epoch:40 step:31976 [D loss: 0.077102, acc: 100.00%] [G loss: 4.188245]\n",
      "epoch:40 step:31977 [D loss: 0.099209, acc: 99.22%] [G loss: 6.316668]\n",
      "epoch:40 step:31978 [D loss: 0.171896, acc: 96.88%] [G loss: 3.618590]\n",
      "epoch:40 step:31979 [D loss: 0.707086, acc: 53.12%] [G loss: 5.849426]\n",
      "epoch:40 step:31980 [D loss: 0.375017, acc: 87.50%] [G loss: 7.000469]\n",
      "epoch:40 step:31981 [D loss: 0.134049, acc: 96.88%] [G loss: 5.002251]\n",
      "epoch:40 step:31982 [D loss: 0.218351, acc: 96.09%] [G loss: 8.628857]\n",
      "epoch:40 step:31983 [D loss: 1.148293, acc: 50.78%] [G loss: 7.019484]\n",
      "epoch:40 step:31984 [D loss: 0.233716, acc: 95.31%] [G loss: 3.052028]\n",
      "epoch:40 step:31985 [D loss: 0.133530, acc: 99.22%] [G loss: 3.911037]\n",
      "epoch:40 step:31986 [D loss: 0.270420, acc: 96.09%] [G loss: 6.878735]\n",
      "epoch:40 step:31987 [D loss: 0.619881, acc: 64.06%] [G loss: 6.495278]\n",
      "epoch:40 step:31988 [D loss: 0.275227, acc: 96.88%] [G loss: 6.398266]\n",
      "epoch:40 step:31989 [D loss: 0.843758, acc: 50.78%] [G loss: 3.930460]\n",
      "epoch:40 step:31990 [D loss: 0.232879, acc: 96.88%] [G loss: 6.498989]\n",
      "epoch:40 step:31991 [D loss: 1.416474, acc: 50.00%] [G loss: 9.579340]\n",
      "epoch:40 step:31992 [D loss: 0.064627, acc: 99.22%] [G loss: 6.867049]\n",
      "epoch:40 step:31993 [D loss: 0.298401, acc: 85.94%] [G loss: 5.604620]\n",
      "epoch:40 step:31994 [D loss: 0.038981, acc: 100.00%] [G loss: 8.383751]\n",
      "epoch:40 step:31995 [D loss: 0.152992, acc: 97.66%] [G loss: 2.820581]\n",
      "epoch:40 step:31996 [D loss: 0.332240, acc: 82.81%] [G loss: 3.442533]\n",
      "epoch:40 step:31997 [D loss: 0.244624, acc: 91.41%] [G loss: 6.658234]\n",
      "epoch:40 step:31998 [D loss: 0.052929, acc: 100.00%] [G loss: 5.747709]\n",
      "epoch:40 step:31999 [D loss: 1.067185, acc: 29.69%] [G loss: 7.571745]\n",
      "epoch:40 step:32000 [D loss: 0.071984, acc: 99.22%] [G loss: 7.817610]\n",
      "##############\n",
      "[0.86948575 0.88192255 0.81946136 0.80616249 0.78972131 0.81735438\n",
      " 0.89061712 0.81218435 0.80415018 0.83108733]\n",
      "##########\n",
      "epoch:40 step:32001 [D loss: 0.203208, acc: 95.31%] [G loss: 6.200303]\n",
      "epoch:40 step:32002 [D loss: 0.478229, acc: 75.78%] [G loss: 7.822905]\n",
      "epoch:40 step:32003 [D loss: 0.137857, acc: 98.44%] [G loss: 4.683017]\n",
      "epoch:40 step:32004 [D loss: 0.268018, acc: 96.88%] [G loss: 6.561654]\n",
      "epoch:40 step:32005 [D loss: 0.153906, acc: 96.88%] [G loss: 3.795766]\n",
      "epoch:40 step:32006 [D loss: 0.075419, acc: 100.00%] [G loss: 8.901682]\n",
      "epoch:40 step:32007 [D loss: 0.108779, acc: 99.22%] [G loss: 4.872535]\n",
      "epoch:40 step:32008 [D loss: 0.013658, acc: 100.00%] [G loss: 4.492712]\n",
      "epoch:40 step:32009 [D loss: 1.526179, acc: 12.50%] [G loss: 9.167406]\n",
      "epoch:40 step:32010 [D loss: 0.589146, acc: 60.94%] [G loss: 7.028811]\n",
      "epoch:40 step:32011 [D loss: 1.063308, acc: 48.44%] [G loss: 6.265468]\n",
      "epoch:40 step:32012 [D loss: 0.256518, acc: 89.06%] [G loss: 5.622195]\n",
      "epoch:40 step:32013 [D loss: 0.097515, acc: 100.00%] [G loss: 3.972980]\n",
      "epoch:40 step:32014 [D loss: 0.183378, acc: 97.66%] [G loss: 6.302108]\n",
      "epoch:40 step:32015 [D loss: 0.301940, acc: 89.06%] [G loss: 8.221437]\n",
      "epoch:40 step:32016 [D loss: 0.656102, acc: 60.94%] [G loss: 7.558338]\n",
      "epoch:40 step:32017 [D loss: 0.155604, acc: 99.22%] [G loss: 3.666101]\n",
      "epoch:40 step:32018 [D loss: 1.094535, acc: 45.31%] [G loss: 5.763801]\n",
      "epoch:40 step:32019 [D loss: 0.317709, acc: 89.06%] [G loss: 5.682880]\n",
      "epoch:40 step:32020 [D loss: 0.555336, acc: 65.62%] [G loss: 5.881248]\n",
      "epoch:40 step:32021 [D loss: 0.183313, acc: 97.66%] [G loss: 3.792811]\n",
      "epoch:41 step:32022 [D loss: 0.368960, acc: 82.81%] [G loss: 4.400302]\n",
      "epoch:41 step:32023 [D loss: 0.032985, acc: 100.00%] [G loss: 3.810035]\n",
      "epoch:41 step:32024 [D loss: 0.138326, acc: 99.22%] [G loss: 5.568335]\n",
      "epoch:41 step:32025 [D loss: 0.182141, acc: 96.88%] [G loss: 5.535748]\n",
      "epoch:41 step:32026 [D loss: 0.192041, acc: 94.53%] [G loss: 7.913909]\n",
      "epoch:41 step:32027 [D loss: 0.237173, acc: 95.31%] [G loss: 4.261325]\n",
      "epoch:41 step:32028 [D loss: 0.083383, acc: 99.22%] [G loss: 6.159618]\n",
      "epoch:41 step:32029 [D loss: 0.048515, acc: 100.00%] [G loss: 7.688651]\n",
      "epoch:41 step:32030 [D loss: 0.074564, acc: 100.00%] [G loss: 5.073968]\n",
      "epoch:41 step:32031 [D loss: 0.126699, acc: 97.66%] [G loss: 6.702798]\n",
      "epoch:41 step:32032 [D loss: 0.103760, acc: 99.22%] [G loss: 6.172948]\n",
      "epoch:41 step:32033 [D loss: 0.397536, acc: 90.62%] [G loss: 4.408728]\n",
      "epoch:41 step:32034 [D loss: 1.203938, acc: 50.00%] [G loss: 6.374826]\n",
      "epoch:41 step:32035 [D loss: 0.168109, acc: 97.66%] [G loss: 8.894443]\n",
      "epoch:41 step:32036 [D loss: 0.553430, acc: 61.72%] [G loss: 7.674678]\n",
      "epoch:41 step:32037 [D loss: 0.124000, acc: 98.44%] [G loss: 5.700318]\n",
      "epoch:41 step:32038 [D loss: 0.154247, acc: 96.88%] [G loss: 6.366088]\n",
      "epoch:41 step:32039 [D loss: 0.119533, acc: 100.00%] [G loss: 6.729772]\n",
      "epoch:41 step:32040 [D loss: 0.124128, acc: 97.66%] [G loss: 4.477688]\n",
      "epoch:41 step:32041 [D loss: 0.059765, acc: 99.22%] [G loss: 6.304789]\n",
      "epoch:41 step:32042 [D loss: 1.004407, acc: 53.12%] [G loss: 6.736930]\n",
      "epoch:41 step:32043 [D loss: 0.075692, acc: 100.00%] [G loss: 4.171474]\n",
      "epoch:41 step:32044 [D loss: 0.361088, acc: 89.06%] [G loss: 6.067002]\n",
      "epoch:41 step:32045 [D loss: 1.545751, acc: 50.78%] [G loss: 10.213840]\n",
      "epoch:41 step:32046 [D loss: 0.085632, acc: 99.22%] [G loss: 5.469176]\n",
      "epoch:41 step:32047 [D loss: 0.077525, acc: 99.22%] [G loss: 8.666785]\n",
      "epoch:41 step:32048 [D loss: 0.027532, acc: 100.00%] [G loss: 5.143748]\n",
      "epoch:41 step:32049 [D loss: 0.834873, acc: 51.56%] [G loss: 8.230486]\n",
      "epoch:41 step:32050 [D loss: 0.165348, acc: 97.66%] [G loss: 5.224349]\n",
      "epoch:41 step:32051 [D loss: 1.040582, acc: 50.00%] [G loss: 7.280987]\n",
      "epoch:41 step:32052 [D loss: 0.139171, acc: 98.44%] [G loss: 6.971283]\n",
      "epoch:41 step:32053 [D loss: 0.151787, acc: 100.00%] [G loss: 5.612355]\n",
      "epoch:41 step:32054 [D loss: 0.037606, acc: 100.00%] [G loss: 5.042748]\n",
      "epoch:41 step:32055 [D loss: 0.261333, acc: 89.84%] [G loss: 4.272501]\n",
      "epoch:41 step:32056 [D loss: 0.752113, acc: 56.25%] [G loss: 5.306627]\n",
      "epoch:41 step:32057 [D loss: 0.027161, acc: 100.00%] [G loss: 5.359001]\n",
      "epoch:41 step:32058 [D loss: 0.729147, acc: 54.69%] [G loss: 7.376856]\n",
      "epoch:41 step:32059 [D loss: 0.270791, acc: 89.06%] [G loss: 4.817855]\n",
      "epoch:41 step:32060 [D loss: 0.164161, acc: 96.88%] [G loss: 3.092063]\n",
      "epoch:41 step:32061 [D loss: 0.109791, acc: 98.44%] [G loss: 5.963783]\n",
      "epoch:41 step:32062 [D loss: 0.123649, acc: 100.00%] [G loss: 8.739817]\n",
      "epoch:41 step:32063 [D loss: 0.259974, acc: 96.88%] [G loss: 5.509621]\n",
      "epoch:41 step:32064 [D loss: 0.037015, acc: 100.00%] [G loss: 5.939504]\n",
      "epoch:41 step:32065 [D loss: 0.394881, acc: 83.59%] [G loss: 5.408381]\n",
      "epoch:41 step:32066 [D loss: 0.503253, acc: 64.06%] [G loss: 6.384127]\n",
      "epoch:41 step:32067 [D loss: 0.791451, acc: 54.69%] [G loss: 6.329745]\n",
      "epoch:41 step:32068 [D loss: 0.084950, acc: 99.22%] [G loss: 4.186685]\n",
      "epoch:41 step:32069 [D loss: 0.542299, acc: 63.28%] [G loss: 4.377756]\n",
      "epoch:41 step:32070 [D loss: 0.145700, acc: 98.44%] [G loss: 7.451596]\n",
      "epoch:41 step:32071 [D loss: 0.359425, acc: 79.69%] [G loss: 5.321522]\n",
      "epoch:41 step:32072 [D loss: 0.519508, acc: 69.53%] [G loss: 5.796225]\n",
      "epoch:41 step:32073 [D loss: 0.016169, acc: 100.00%] [G loss: 2.531680]\n",
      "epoch:41 step:32074 [D loss: 0.205157, acc: 95.31%] [G loss: 7.214706]\n",
      "epoch:41 step:32075 [D loss: 0.250125, acc: 92.97%] [G loss: 4.399271]\n",
      "epoch:41 step:32076 [D loss: 0.409600, acc: 77.34%] [G loss: 6.078723]\n",
      "epoch:41 step:32077 [D loss: 0.268691, acc: 93.75%] [G loss: 6.093594]\n",
      "epoch:41 step:32078 [D loss: 0.027936, acc: 100.00%] [G loss: 8.950148]\n",
      "epoch:41 step:32079 [D loss: 0.106494, acc: 100.00%] [G loss: 4.028792]\n",
      "epoch:41 step:32080 [D loss: 0.108766, acc: 98.44%] [G loss: 2.378338]\n",
      "epoch:41 step:32081 [D loss: 0.269362, acc: 91.41%] [G loss: 6.227504]\n",
      "epoch:41 step:32082 [D loss: 0.059543, acc: 100.00%] [G loss: 6.936843]\n",
      "epoch:41 step:32083 [D loss: 0.056099, acc: 100.00%] [G loss: 7.240705]\n",
      "epoch:41 step:32084 [D loss: 0.059071, acc: 100.00%] [G loss: 3.901535]\n",
      "epoch:41 step:32085 [D loss: 1.462579, acc: 17.97%] [G loss: 9.035061]\n",
      "epoch:41 step:32086 [D loss: 0.096006, acc: 100.00%] [G loss: 3.153824]\n",
      "epoch:41 step:32087 [D loss: 0.365575, acc: 73.44%] [G loss: 2.117836]\n",
      "epoch:41 step:32088 [D loss: 0.557817, acc: 69.53%] [G loss: 5.321567]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:41 step:32089 [D loss: 0.066548, acc: 99.22%] [G loss: 7.573626]\n",
      "epoch:41 step:32090 [D loss: 0.345427, acc: 82.03%] [G loss: 6.768284]\n",
      "epoch:41 step:32091 [D loss: 0.143477, acc: 99.22%] [G loss: 5.614966]\n",
      "epoch:41 step:32092 [D loss: 0.271444, acc: 93.75%] [G loss: 5.491445]\n",
      "epoch:41 step:32093 [D loss: 0.137757, acc: 98.44%] [G loss: 9.001469]\n",
      "epoch:41 step:32094 [D loss: 0.279712, acc: 89.06%] [G loss: 6.746165]\n",
      "epoch:41 step:32095 [D loss: 0.530262, acc: 72.66%] [G loss: 7.807212]\n",
      "epoch:41 step:32096 [D loss: 0.034499, acc: 100.00%] [G loss: 5.078053]\n",
      "epoch:41 step:32097 [D loss: 0.100952, acc: 100.00%] [G loss: 5.042840]\n",
      "epoch:41 step:32098 [D loss: 0.482374, acc: 74.22%] [G loss: 3.580313]\n",
      "epoch:41 step:32099 [D loss: 0.060570, acc: 100.00%] [G loss: 7.307115]\n",
      "epoch:41 step:32100 [D loss: 0.429998, acc: 85.16%] [G loss: 6.062802]\n",
      "epoch:41 step:32101 [D loss: 0.195911, acc: 96.09%] [G loss: 4.275633]\n",
      "epoch:41 step:32102 [D loss: 0.434853, acc: 82.81%] [G loss: 6.008342]\n",
      "epoch:41 step:32103 [D loss: 0.157788, acc: 97.66%] [G loss: 6.555377]\n",
      "epoch:41 step:32104 [D loss: 1.188601, acc: 44.53%] [G loss: 7.359367]\n",
      "epoch:41 step:32105 [D loss: 0.160853, acc: 100.00%] [G loss: 4.477387]\n",
      "epoch:41 step:32106 [D loss: 0.219122, acc: 96.09%] [G loss: 6.489358]\n",
      "epoch:41 step:32107 [D loss: 0.750214, acc: 54.69%] [G loss: 4.584156]\n",
      "epoch:41 step:32108 [D loss: 0.787136, acc: 56.25%] [G loss: 5.138299]\n",
      "epoch:41 step:32109 [D loss: 0.120986, acc: 100.00%] [G loss: 5.012599]\n",
      "epoch:41 step:32110 [D loss: 0.099625, acc: 99.22%] [G loss: 9.128260]\n",
      "epoch:41 step:32111 [D loss: 0.109831, acc: 99.22%] [G loss: 3.963147]\n",
      "epoch:41 step:32112 [D loss: 0.014765, acc: 100.00%] [G loss: 7.939919]\n",
      "epoch:41 step:32113 [D loss: 0.024265, acc: 100.00%] [G loss: 8.346441]\n",
      "epoch:41 step:32114 [D loss: 0.562364, acc: 64.84%] [G loss: 10.209198]\n",
      "epoch:41 step:32115 [D loss: 0.335927, acc: 93.75%] [G loss: 4.059289]\n",
      "epoch:41 step:32116 [D loss: 0.219350, acc: 94.53%] [G loss: 6.849467]\n",
      "epoch:41 step:32117 [D loss: 0.105294, acc: 99.22%] [G loss: 5.250356]\n",
      "epoch:41 step:32118 [D loss: 1.227194, acc: 48.44%] [G loss: 8.354336]\n",
      "epoch:41 step:32119 [D loss: 0.924155, acc: 51.56%] [G loss: 7.486162]\n",
      "epoch:41 step:32120 [D loss: 0.148071, acc: 100.00%] [G loss: 6.484526]\n",
      "epoch:41 step:32121 [D loss: 0.041762, acc: 100.00%] [G loss: 3.918032]\n",
      "epoch:41 step:32122 [D loss: 0.134780, acc: 98.44%] [G loss: 6.203391]\n",
      "epoch:41 step:32123 [D loss: 0.032971, acc: 100.00%] [G loss: 6.138517]\n",
      "epoch:41 step:32124 [D loss: 0.196597, acc: 93.75%] [G loss: 5.992817]\n",
      "epoch:41 step:32125 [D loss: 0.216490, acc: 98.44%] [G loss: 2.899423]\n",
      "epoch:41 step:32126 [D loss: 1.421631, acc: 37.50%] [G loss: 7.981289]\n",
      "epoch:41 step:32127 [D loss: 0.868378, acc: 53.12%] [G loss: 5.591835]\n",
      "epoch:41 step:32128 [D loss: 0.932653, acc: 51.56%] [G loss: 8.254991]\n",
      "epoch:41 step:32129 [D loss: 0.718300, acc: 54.69%] [G loss: 6.026569]\n",
      "epoch:41 step:32130 [D loss: 0.031993, acc: 100.00%] [G loss: 8.372810]\n",
      "epoch:41 step:32131 [D loss: 1.568821, acc: 30.47%] [G loss: 5.518942]\n",
      "epoch:41 step:32132 [D loss: 1.300508, acc: 50.78%] [G loss: 4.418443]\n",
      "epoch:41 step:32133 [D loss: 0.254602, acc: 92.19%] [G loss: 9.118837]\n",
      "epoch:41 step:32134 [D loss: 0.266286, acc: 91.41%] [G loss: 9.782026]\n",
      "epoch:41 step:32135 [D loss: 0.456798, acc: 81.25%] [G loss: 7.369431]\n",
      "epoch:41 step:32136 [D loss: 0.194151, acc: 96.09%] [G loss: 5.313828]\n",
      "epoch:41 step:32137 [D loss: 0.364796, acc: 89.06%] [G loss: 4.294401]\n",
      "epoch:41 step:32138 [D loss: 0.090909, acc: 100.00%] [G loss: 4.251247]\n",
      "epoch:41 step:32139 [D loss: 0.100976, acc: 100.00%] [G loss: 6.749124]\n",
      "epoch:41 step:32140 [D loss: 0.019147, acc: 100.00%] [G loss: 5.999378]\n",
      "epoch:41 step:32141 [D loss: 0.097504, acc: 100.00%] [G loss: 7.739948]\n",
      "epoch:41 step:32142 [D loss: 0.070401, acc: 100.00%] [G loss: 5.097143]\n",
      "epoch:41 step:32143 [D loss: 0.045024, acc: 98.44%] [G loss: 11.141487]\n",
      "epoch:41 step:32144 [D loss: 0.619438, acc: 67.97%] [G loss: 6.200807]\n",
      "epoch:41 step:32145 [D loss: 0.159110, acc: 95.31%] [G loss: 10.312097]\n",
      "epoch:41 step:32146 [D loss: 0.015178, acc: 100.00%] [G loss: 6.880816]\n",
      "epoch:41 step:32147 [D loss: 0.036665, acc: 100.00%] [G loss: 5.066814]\n",
      "epoch:41 step:32148 [D loss: 0.069127, acc: 100.00%] [G loss: 8.472189]\n",
      "epoch:41 step:32149 [D loss: 0.354129, acc: 85.16%] [G loss: 8.064550]\n",
      "epoch:41 step:32150 [D loss: 0.465088, acc: 68.75%] [G loss: 6.474978]\n",
      "epoch:41 step:32151 [D loss: 0.052879, acc: 100.00%] [G loss: 7.541447]\n",
      "epoch:41 step:32152 [D loss: 0.865018, acc: 51.56%] [G loss: 8.476973]\n",
      "epoch:41 step:32153 [D loss: 0.296209, acc: 93.75%] [G loss: 4.641428]\n",
      "epoch:41 step:32154 [D loss: 0.328791, acc: 82.81%] [G loss: 4.334995]\n",
      "epoch:41 step:32155 [D loss: 0.184761, acc: 98.44%] [G loss: 6.534616]\n",
      "epoch:41 step:32156 [D loss: 0.168794, acc: 100.00%] [G loss: 8.755944]\n",
      "epoch:41 step:32157 [D loss: 0.364071, acc: 82.81%] [G loss: 8.483305]\n",
      "epoch:41 step:32158 [D loss: 0.353499, acc: 82.81%] [G loss: 7.201669]\n",
      "epoch:41 step:32159 [D loss: 0.116219, acc: 99.22%] [G loss: 3.231658]\n",
      "epoch:41 step:32160 [D loss: 0.662067, acc: 64.06%] [G loss: 5.333013]\n",
      "epoch:41 step:32161 [D loss: 0.122518, acc: 99.22%] [G loss: 7.062901]\n",
      "epoch:41 step:32162 [D loss: 0.296378, acc: 89.06%] [G loss: 5.523415]\n",
      "epoch:41 step:32163 [D loss: 0.324126, acc: 89.06%] [G loss: 5.508157]\n",
      "epoch:41 step:32164 [D loss: 0.418254, acc: 80.47%] [G loss: 7.175561]\n",
      "epoch:41 step:32165 [D loss: 0.294027, acc: 88.28%] [G loss: 3.595622]\n",
      "epoch:41 step:32166 [D loss: 0.134467, acc: 99.22%] [G loss: 5.279896]\n",
      "epoch:41 step:32167 [D loss: 0.069771, acc: 100.00%] [G loss: 5.199914]\n",
      "epoch:41 step:32168 [D loss: 0.059974, acc: 100.00%] [G loss: 5.946049]\n",
      "epoch:41 step:32169 [D loss: 0.226876, acc: 96.09%] [G loss: 5.369684]\n",
      "epoch:41 step:32170 [D loss: 0.265560, acc: 93.75%] [G loss: 5.147061]\n",
      "epoch:41 step:32171 [D loss: 0.110836, acc: 100.00%] [G loss: 3.741364]\n",
      "epoch:41 step:32172 [D loss: 0.165349, acc: 99.22%] [G loss: 7.049850]\n",
      "epoch:41 step:32173 [D loss: 0.576467, acc: 58.59%] [G loss: 6.831809]\n",
      "epoch:41 step:32174 [D loss: 0.201015, acc: 92.19%] [G loss: 5.639009]\n",
      "epoch:41 step:32175 [D loss: 0.579573, acc: 61.72%] [G loss: 6.034685]\n",
      "epoch:41 step:32176 [D loss: 0.040084, acc: 100.00%] [G loss: 8.554123]\n",
      "epoch:41 step:32177 [D loss: 0.737063, acc: 53.91%] [G loss: 10.294344]\n",
      "epoch:41 step:32178 [D loss: 0.321294, acc: 83.59%] [G loss: 6.434807]\n",
      "epoch:41 step:32179 [D loss: 0.191945, acc: 95.31%] [G loss: 4.411674]\n",
      "epoch:41 step:32180 [D loss: 0.053688, acc: 100.00%] [G loss: 6.425700]\n",
      "epoch:41 step:32181 [D loss: 0.139981, acc: 97.66%] [G loss: 4.281432]\n",
      "epoch:41 step:32182 [D loss: 0.220859, acc: 90.62%] [G loss: 6.684364]\n",
      "epoch:41 step:32183 [D loss: 0.167843, acc: 98.44%] [G loss: 5.329842]\n",
      "epoch:41 step:32184 [D loss: 0.226856, acc: 94.53%] [G loss: 9.733553]\n",
      "epoch:41 step:32185 [D loss: 0.115511, acc: 98.44%] [G loss: 6.577749]\n",
      "epoch:41 step:32186 [D loss: 0.368791, acc: 87.50%] [G loss: 4.780863]\n",
      "epoch:41 step:32187 [D loss: 0.153001, acc: 96.88%] [G loss: 5.071891]\n",
      "epoch:41 step:32188 [D loss: 0.078697, acc: 99.22%] [G loss: 5.166431]\n",
      "epoch:41 step:32189 [D loss: 0.070135, acc: 99.22%] [G loss: 6.659221]\n",
      "epoch:41 step:32190 [D loss: 0.098788, acc: 99.22%] [G loss: 4.508395]\n",
      "epoch:41 step:32191 [D loss: 0.711318, acc: 53.12%] [G loss: 5.941486]\n",
      "epoch:41 step:32192 [D loss: 0.702921, acc: 52.34%] [G loss: 8.906594]\n",
      "epoch:41 step:32193 [D loss: 1.598678, acc: 50.00%] [G loss: 3.355340]\n",
      "epoch:41 step:32194 [D loss: 0.447298, acc: 67.97%] [G loss: 6.771275]\n",
      "epoch:41 step:32195 [D loss: 0.010293, acc: 100.00%] [G loss: 6.657878]\n",
      "epoch:41 step:32196 [D loss: 0.004074, acc: 100.00%] [G loss: 10.125332]\n",
      "epoch:41 step:32197 [D loss: 0.162416, acc: 99.22%] [G loss: 4.811255]\n",
      "epoch:41 step:32198 [D loss: 0.487662, acc: 73.44%] [G loss: 7.650054]\n",
      "epoch:41 step:32199 [D loss: 1.835423, acc: 50.00%] [G loss: 1.928954]\n",
      "epoch:41 step:32200 [D loss: 0.425795, acc: 76.56%] [G loss: 9.513208]\n",
      "##############\n",
      "[0.84431272 0.84407143 0.82038455 0.82920423 0.8007439  0.82971576\n",
      " 0.87802415 0.80680683 0.8119471  0.8138798 ]\n",
      "##########\n",
      "epoch:41 step:32201 [D loss: 0.189376, acc: 96.09%] [G loss: 5.216474]\n",
      "epoch:41 step:32202 [D loss: 0.077580, acc: 100.00%] [G loss: 1.561139]\n",
      "epoch:41 step:32203 [D loss: 0.168370, acc: 98.44%] [G loss: 3.731909]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:41 step:32204 [D loss: 0.208328, acc: 96.09%] [G loss: 5.060610]\n",
      "epoch:41 step:32205 [D loss: 0.204871, acc: 99.22%] [G loss: 2.587840]\n",
      "epoch:41 step:32206 [D loss: 0.307208, acc: 93.75%] [G loss: 6.861240]\n",
      "epoch:41 step:32207 [D loss: 0.022787, acc: 100.00%] [G loss: 5.570219]\n",
      "epoch:41 step:32208 [D loss: 0.277111, acc: 97.66%] [G loss: 4.335248]\n",
      "epoch:41 step:32209 [D loss: 0.148369, acc: 99.22%] [G loss: 5.361350]\n",
      "epoch:41 step:32210 [D loss: 0.016962, acc: 100.00%] [G loss: 10.106432]\n",
      "epoch:41 step:32211 [D loss: 0.119102, acc: 100.00%] [G loss: 3.406914]\n",
      "epoch:41 step:32212 [D loss: 0.179671, acc: 96.09%] [G loss: 6.445064]\n",
      "epoch:41 step:32213 [D loss: 0.312960, acc: 88.28%] [G loss: 7.562380]\n",
      "epoch:41 step:32214 [D loss: 0.053263, acc: 100.00%] [G loss: 10.128455]\n",
      "epoch:41 step:32215 [D loss: 0.064795, acc: 100.00%] [G loss: 7.788630]\n",
      "epoch:41 step:32216 [D loss: 0.420172, acc: 73.44%] [G loss: 5.426827]\n",
      "epoch:41 step:32217 [D loss: 0.080592, acc: 99.22%] [G loss: 5.336947]\n",
      "epoch:41 step:32218 [D loss: 0.827531, acc: 53.12%] [G loss: 6.595421]\n",
      "epoch:41 step:32219 [D loss: 0.374636, acc: 75.00%] [G loss: 5.442758]\n",
      "epoch:41 step:32220 [D loss: 0.351758, acc: 80.47%] [G loss: 9.094151]\n",
      "epoch:41 step:32221 [D loss: 0.220582, acc: 95.31%] [G loss: 5.485023]\n",
      "epoch:41 step:32222 [D loss: 0.519528, acc: 75.78%] [G loss: 4.913404]\n",
      "epoch:41 step:32223 [D loss: 0.217766, acc: 95.31%] [G loss: 8.431681]\n",
      "epoch:41 step:32224 [D loss: 0.260615, acc: 89.84%] [G loss: 7.265219]\n",
      "epoch:41 step:32225 [D loss: 1.065294, acc: 24.22%] [G loss: 11.070202]\n",
      "epoch:41 step:32226 [D loss: 0.016508, acc: 100.00%] [G loss: 7.509783]\n",
      "epoch:41 step:32227 [D loss: 0.086067, acc: 100.00%] [G loss: 3.422160]\n",
      "epoch:41 step:32228 [D loss: 0.130742, acc: 99.22%] [G loss: 7.696701]\n",
      "epoch:41 step:32229 [D loss: 0.033394, acc: 100.00%] [G loss: 7.342771]\n",
      "epoch:41 step:32230 [D loss: 0.042822, acc: 99.22%] [G loss: 5.666615]\n",
      "epoch:41 step:32231 [D loss: 0.455128, acc: 82.81%] [G loss: 7.215133]\n",
      "epoch:41 step:32232 [D loss: 0.128613, acc: 100.00%] [G loss: 2.735588]\n",
      "epoch:41 step:32233 [D loss: 0.545425, acc: 59.38%] [G loss: 8.686504]\n",
      "epoch:41 step:32234 [D loss: 0.438404, acc: 85.94%] [G loss: 5.412618]\n",
      "epoch:41 step:32235 [D loss: 0.060545, acc: 100.00%] [G loss: 6.583685]\n",
      "epoch:41 step:32236 [D loss: 0.219625, acc: 95.31%] [G loss: 5.363149]\n",
      "epoch:41 step:32237 [D loss: 0.251476, acc: 96.09%] [G loss: 3.462471]\n",
      "epoch:41 step:32238 [D loss: 0.216661, acc: 96.88%] [G loss: 5.166817]\n",
      "epoch:41 step:32239 [D loss: 0.361770, acc: 80.47%] [G loss: 6.832137]\n",
      "epoch:41 step:32240 [D loss: 0.346741, acc: 89.84%] [G loss: 6.755620]\n",
      "epoch:41 step:32241 [D loss: 1.289930, acc: 43.75%] [G loss: 6.016129]\n",
      "epoch:41 step:32242 [D loss: 0.091623, acc: 100.00%] [G loss: 5.182996]\n",
      "epoch:41 step:32243 [D loss: 0.212099, acc: 95.31%] [G loss: 6.364383]\n",
      "epoch:41 step:32244 [D loss: 0.074724, acc: 100.00%] [G loss: 5.852330]\n",
      "epoch:41 step:32245 [D loss: 0.597123, acc: 62.50%] [G loss: 7.925505]\n",
      "epoch:41 step:32246 [D loss: 0.054638, acc: 100.00%] [G loss: 6.944975]\n",
      "epoch:41 step:32247 [D loss: 0.179937, acc: 94.53%] [G loss: 4.236156]\n",
      "epoch:41 step:32248 [D loss: 0.166080, acc: 97.66%] [G loss: 8.183727]\n",
      "epoch:41 step:32249 [D loss: 0.197035, acc: 99.22%] [G loss: 5.094834]\n",
      "epoch:41 step:32250 [D loss: 1.161003, acc: 42.19%] [G loss: 4.972190]\n",
      "epoch:41 step:32251 [D loss: 0.035852, acc: 100.00%] [G loss: 4.401142]\n",
      "epoch:41 step:32252 [D loss: 1.352709, acc: 50.00%] [G loss: 7.585620]\n",
      "epoch:41 step:32253 [D loss: 0.178057, acc: 96.88%] [G loss: 4.908931]\n",
      "epoch:41 step:32254 [D loss: 0.362770, acc: 91.41%] [G loss: 6.019476]\n",
      "epoch:41 step:32255 [D loss: 0.291088, acc: 89.84%] [G loss: 5.769696]\n",
      "epoch:41 step:32256 [D loss: 0.101210, acc: 100.00%] [G loss: 6.306517]\n",
      "epoch:41 step:32257 [D loss: 0.176689, acc: 98.44%] [G loss: 6.411142]\n",
      "epoch:41 step:32258 [D loss: 0.007053, acc: 100.00%] [G loss: 7.477548]\n",
      "epoch:41 step:32259 [D loss: 0.877374, acc: 42.19%] [G loss: 7.232073]\n",
      "epoch:41 step:32260 [D loss: 0.152642, acc: 97.66%] [G loss: 4.178136]\n",
      "epoch:41 step:32261 [D loss: 0.335079, acc: 90.62%] [G loss: 4.747377]\n",
      "epoch:41 step:32262 [D loss: 0.581779, acc: 68.75%] [G loss: 3.310906]\n",
      "epoch:41 step:32263 [D loss: 0.246393, acc: 94.53%] [G loss: 6.249202]\n",
      "epoch:41 step:32264 [D loss: 0.546200, acc: 61.72%] [G loss: 11.106133]\n",
      "epoch:41 step:32265 [D loss: 0.065169, acc: 99.22%] [G loss: 7.317299]\n",
      "epoch:41 step:32266 [D loss: 0.343881, acc: 90.62%] [G loss: 4.684015]\n",
      "epoch:41 step:32267 [D loss: 0.303604, acc: 87.50%] [G loss: 4.558378]\n",
      "epoch:41 step:32268 [D loss: 0.293021, acc: 92.97%] [G loss: 7.278821]\n",
      "epoch:41 step:32269 [D loss: 0.372499, acc: 89.06%] [G loss: 5.089120]\n",
      "epoch:41 step:32270 [D loss: 0.113752, acc: 98.44%] [G loss: 6.265960]\n",
      "epoch:41 step:32271 [D loss: 0.729203, acc: 55.47%] [G loss: 7.834002]\n",
      "epoch:41 step:32272 [D loss: 0.169528, acc: 95.31%] [G loss: 7.413942]\n",
      "epoch:41 step:32273 [D loss: 0.204187, acc: 96.09%] [G loss: 6.661101]\n",
      "epoch:41 step:32274 [D loss: 1.654495, acc: 6.25%] [G loss: 5.660874]\n",
      "epoch:41 step:32275 [D loss: 0.155503, acc: 94.53%] [G loss: 9.440451]\n",
      "epoch:41 step:32276 [D loss: 0.944375, acc: 51.56%] [G loss: 7.636528]\n",
      "epoch:41 step:32277 [D loss: 0.132269, acc: 97.66%] [G loss: 7.356786]\n",
      "epoch:41 step:32278 [D loss: 0.189165, acc: 97.66%] [G loss: 3.842626]\n",
      "epoch:41 step:32279 [D loss: 0.118969, acc: 97.66%] [G loss: 5.194846]\n",
      "epoch:41 step:32280 [D loss: 1.833888, acc: 3.12%] [G loss: 9.099430]\n",
      "epoch:41 step:32281 [D loss: 0.040901, acc: 100.00%] [G loss: 4.156134]\n",
      "epoch:41 step:32282 [D loss: 0.052604, acc: 100.00%] [G loss: 5.822156]\n",
      "epoch:41 step:32283 [D loss: 1.069993, acc: 50.78%] [G loss: 6.068513]\n",
      "epoch:41 step:32284 [D loss: 0.260085, acc: 94.53%] [G loss: 4.223558]\n",
      "epoch:41 step:32285 [D loss: 0.107628, acc: 100.00%] [G loss: 3.823229]\n",
      "epoch:41 step:32286 [D loss: 1.706384, acc: 7.81%] [G loss: 5.481326]\n",
      "epoch:41 step:32287 [D loss: 0.686896, acc: 59.38%] [G loss: 7.336990]\n",
      "epoch:41 step:32288 [D loss: 0.212223, acc: 98.44%] [G loss: 2.773042]\n",
      "epoch:41 step:32289 [D loss: 0.229622, acc: 96.09%] [G loss: 5.811948]\n",
      "epoch:41 step:32290 [D loss: 0.495588, acc: 78.12%] [G loss: 3.921872]\n",
      "epoch:41 step:32291 [D loss: 0.062109, acc: 100.00%] [G loss: 6.314776]\n",
      "epoch:41 step:32292 [D loss: 0.040659, acc: 100.00%] [G loss: 10.707049]\n",
      "epoch:41 step:32293 [D loss: 0.185456, acc: 96.09%] [G loss: 6.028790]\n",
      "epoch:41 step:32294 [D loss: 0.176822, acc: 98.44%] [G loss: 4.453691]\n",
      "epoch:41 step:32295 [D loss: 0.320156, acc: 83.59%] [G loss: 3.329513]\n",
      "epoch:41 step:32296 [D loss: 0.512611, acc: 66.41%] [G loss: 5.036745]\n",
      "epoch:41 step:32297 [D loss: 0.135462, acc: 96.88%] [G loss: 5.362283]\n",
      "epoch:41 step:32298 [D loss: 0.030513, acc: 100.00%] [G loss: 5.319611]\n",
      "epoch:41 step:32299 [D loss: 0.156271, acc: 97.66%] [G loss: 7.511337]\n",
      "epoch:41 step:32300 [D loss: 0.549692, acc: 67.97%] [G loss: 5.684856]\n",
      "epoch:41 step:32301 [D loss: 0.434622, acc: 82.81%] [G loss: 7.338337]\n",
      "epoch:41 step:32302 [D loss: 0.394322, acc: 82.03%] [G loss: 3.515697]\n",
      "epoch:41 step:32303 [D loss: 0.240473, acc: 92.97%] [G loss: 4.964078]\n",
      "epoch:41 step:32304 [D loss: 0.098399, acc: 99.22%] [G loss: 6.501509]\n",
      "epoch:41 step:32305 [D loss: 0.325806, acc: 86.72%] [G loss: 5.674448]\n",
      "epoch:41 step:32306 [D loss: 0.819389, acc: 46.09%] [G loss: 3.839132]\n",
      "epoch:41 step:32307 [D loss: 0.095816, acc: 99.22%] [G loss: 7.273458]\n",
      "epoch:41 step:32308 [D loss: 0.171341, acc: 96.88%] [G loss: 7.138061]\n",
      "epoch:41 step:32309 [D loss: 0.423733, acc: 76.56%] [G loss: 4.031456]\n",
      "epoch:41 step:32310 [D loss: 0.078917, acc: 100.00%] [G loss: 4.122346]\n",
      "epoch:41 step:32311 [D loss: 0.237367, acc: 97.66%] [G loss: 3.466011]\n",
      "epoch:41 step:32312 [D loss: 0.360875, acc: 83.59%] [G loss: 4.757699]\n",
      "epoch:41 step:32313 [D loss: 0.089880, acc: 98.44%] [G loss: 11.953869]\n",
      "epoch:41 step:32314 [D loss: 0.550963, acc: 63.28%] [G loss: 5.824673]\n",
      "epoch:41 step:32315 [D loss: 0.512947, acc: 67.97%] [G loss: 5.294966]\n",
      "epoch:41 step:32316 [D loss: 0.163849, acc: 97.66%] [G loss: 3.844037]\n",
      "epoch:41 step:32317 [D loss: 0.396281, acc: 75.78%] [G loss: 4.683169]\n",
      "epoch:41 step:32318 [D loss: 0.147454, acc: 96.09%] [G loss: 6.667907]\n",
      "epoch:41 step:32319 [D loss: 0.095403, acc: 100.00%] [G loss: 5.346298]\n",
      "epoch:41 step:32320 [D loss: 0.055583, acc: 100.00%] [G loss: 5.031607]\n",
      "epoch:41 step:32321 [D loss: 0.139500, acc: 97.66%] [G loss: 5.832387]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:41 step:32322 [D loss: 0.122922, acc: 100.00%] [G loss: 4.327532]\n",
      "epoch:41 step:32323 [D loss: 0.383740, acc: 88.28%] [G loss: 6.620399]\n",
      "epoch:41 step:32324 [D loss: 0.016079, acc: 100.00%] [G loss: 8.292863]\n",
      "epoch:41 step:32325 [D loss: 0.319658, acc: 82.03%] [G loss: 6.504287]\n",
      "epoch:41 step:32326 [D loss: 0.080835, acc: 100.00%] [G loss: 3.035957]\n",
      "epoch:41 step:32327 [D loss: 0.071286, acc: 100.00%] [G loss: 5.882472]\n",
      "epoch:41 step:32328 [D loss: 1.150832, acc: 20.31%] [G loss: 8.709579]\n",
      "epoch:41 step:32329 [D loss: 0.828719, acc: 48.44%] [G loss: 5.589440]\n",
      "epoch:41 step:32330 [D loss: 0.122350, acc: 97.66%] [G loss: 6.590545]\n",
      "epoch:41 step:32331 [D loss: 0.136247, acc: 100.00%] [G loss: 4.625759]\n",
      "epoch:41 step:32332 [D loss: 1.149908, acc: 23.44%] [G loss: 7.396052]\n",
      "epoch:41 step:32333 [D loss: 0.085264, acc: 100.00%] [G loss: 4.497593]\n",
      "epoch:41 step:32334 [D loss: 0.450446, acc: 71.09%] [G loss: 6.470861]\n",
      "epoch:41 step:32335 [D loss: 0.036735, acc: 100.00%] [G loss: 6.773092]\n",
      "epoch:41 step:32336 [D loss: 1.660600, acc: 15.62%] [G loss: 6.831864]\n",
      "epoch:41 step:32337 [D loss: 0.134895, acc: 98.44%] [G loss: 4.892981]\n",
      "epoch:41 step:32338 [D loss: 0.076146, acc: 99.22%] [G loss: 5.049142]\n",
      "epoch:41 step:32339 [D loss: 0.543766, acc: 68.75%] [G loss: 7.303455]\n",
      "epoch:41 step:32340 [D loss: 0.161100, acc: 96.88%] [G loss: 5.242901]\n",
      "epoch:41 step:32341 [D loss: 1.082957, acc: 31.25%] [G loss: 5.738707]\n",
      "epoch:41 step:32342 [D loss: 0.091214, acc: 99.22%] [G loss: 6.088135]\n",
      "epoch:41 step:32343 [D loss: 0.303019, acc: 93.75%] [G loss: 5.774933]\n",
      "epoch:41 step:32344 [D loss: 0.362664, acc: 84.38%] [G loss: 5.193420]\n",
      "epoch:41 step:32345 [D loss: 0.059938, acc: 100.00%] [G loss: 3.370032]\n",
      "epoch:41 step:32346 [D loss: 0.253096, acc: 94.53%] [G loss: 3.411824]\n",
      "epoch:41 step:32347 [D loss: 0.253766, acc: 96.09%] [G loss: 5.579305]\n",
      "epoch:41 step:32348 [D loss: 0.980590, acc: 38.28%] [G loss: 5.395485]\n",
      "epoch:41 step:32349 [D loss: 0.730668, acc: 54.69%] [G loss: 4.911070]\n",
      "epoch:41 step:32350 [D loss: 0.025479, acc: 100.00%] [G loss: 6.431424]\n",
      "epoch:41 step:32351 [D loss: 1.141562, acc: 45.31%] [G loss: 7.679780]\n",
      "epoch:41 step:32352 [D loss: 0.062412, acc: 100.00%] [G loss: 4.810301]\n",
      "epoch:41 step:32353 [D loss: 0.222131, acc: 97.66%] [G loss: 2.771449]\n",
      "epoch:41 step:32354 [D loss: 0.041438, acc: 100.00%] [G loss: 8.744425]\n",
      "epoch:41 step:32355 [D loss: 0.416583, acc: 84.38%] [G loss: 5.318501]\n",
      "epoch:41 step:32356 [D loss: 0.019200, acc: 100.00%] [G loss: 4.665234]\n",
      "epoch:41 step:32357 [D loss: 0.187374, acc: 95.31%] [G loss: 6.769541]\n",
      "epoch:41 step:32358 [D loss: 0.337502, acc: 89.84%] [G loss: 5.684881]\n",
      "epoch:41 step:32359 [D loss: 0.132312, acc: 99.22%] [G loss: 8.443445]\n",
      "epoch:41 step:32360 [D loss: 0.046186, acc: 100.00%] [G loss: 5.489101]\n",
      "epoch:41 step:32361 [D loss: 0.162924, acc: 100.00%] [G loss: 2.949529]\n",
      "epoch:41 step:32362 [D loss: 0.288068, acc: 84.38%] [G loss: 6.295547]\n",
      "epoch:41 step:32363 [D loss: 0.554744, acc: 68.75%] [G loss: 8.785907]\n",
      "epoch:41 step:32364 [D loss: 0.149849, acc: 98.44%] [G loss: 5.465945]\n",
      "epoch:41 step:32365 [D loss: 0.031942, acc: 100.00%] [G loss: 5.193423]\n",
      "epoch:41 step:32366 [D loss: 0.268053, acc: 93.75%] [G loss: 10.452429]\n",
      "epoch:41 step:32367 [D loss: 0.190123, acc: 97.66%] [G loss: 6.587637]\n",
      "epoch:41 step:32368 [D loss: 0.519382, acc: 74.22%] [G loss: 4.187420]\n",
      "epoch:41 step:32369 [D loss: 0.185711, acc: 97.66%] [G loss: 5.951015]\n",
      "epoch:41 step:32370 [D loss: 0.306917, acc: 87.50%] [G loss: 6.008096]\n",
      "epoch:41 step:32371 [D loss: 0.285606, acc: 94.53%] [G loss: 4.413843]\n",
      "epoch:41 step:32372 [D loss: 0.073224, acc: 100.00%] [G loss: 1.749587]\n",
      "epoch:41 step:32373 [D loss: 0.406938, acc: 73.44%] [G loss: 6.087600]\n",
      "epoch:41 step:32374 [D loss: 0.042769, acc: 99.22%] [G loss: 6.296531]\n",
      "epoch:41 step:32375 [D loss: 1.530163, acc: 34.38%] [G loss: 7.591192]\n",
      "epoch:41 step:32376 [D loss: 0.464557, acc: 67.19%] [G loss: 6.984472]\n",
      "epoch:41 step:32377 [D loss: 0.263491, acc: 87.50%] [G loss: 8.256102]\n",
      "epoch:41 step:32378 [D loss: 0.073687, acc: 100.00%] [G loss: 4.241472]\n",
      "epoch:41 step:32379 [D loss: 0.158817, acc: 96.09%] [G loss: 2.274234]\n",
      "epoch:41 step:32380 [D loss: 0.873103, acc: 50.78%] [G loss: 4.216510]\n",
      "epoch:41 step:32381 [D loss: 0.124105, acc: 100.00%] [G loss: 3.218418]\n",
      "epoch:41 step:32382 [D loss: 0.115648, acc: 99.22%] [G loss: 4.311554]\n",
      "epoch:41 step:32383 [D loss: 0.140433, acc: 98.44%] [G loss: 5.776164]\n",
      "epoch:41 step:32384 [D loss: 1.541737, acc: 46.09%] [G loss: 4.326042]\n",
      "epoch:41 step:32385 [D loss: 0.228662, acc: 92.19%] [G loss: 5.978741]\n",
      "epoch:41 step:32386 [D loss: 0.104732, acc: 100.00%] [G loss: 7.201025]\n",
      "epoch:41 step:32387 [D loss: 0.426496, acc: 74.22%] [G loss: 5.785278]\n",
      "epoch:41 step:32388 [D loss: 0.027868, acc: 100.00%] [G loss: 4.821952]\n",
      "epoch:41 step:32389 [D loss: 0.279381, acc: 87.50%] [G loss: 7.994002]\n",
      "epoch:41 step:32390 [D loss: 0.198567, acc: 97.66%] [G loss: 7.065250]\n",
      "epoch:41 step:32391 [D loss: 0.837637, acc: 43.75%] [G loss: 7.215453]\n",
      "epoch:41 step:32392 [D loss: 0.168362, acc: 94.53%] [G loss: 5.189894]\n",
      "epoch:41 step:32393 [D loss: 0.455335, acc: 82.03%] [G loss: 3.120332]\n",
      "epoch:41 step:32394 [D loss: 0.431640, acc: 82.81%] [G loss: 7.707885]\n",
      "epoch:41 step:32395 [D loss: 0.420410, acc: 76.56%] [G loss: 3.192336]\n",
      "epoch:41 step:32396 [D loss: 0.318827, acc: 86.72%] [G loss: 5.643155]\n",
      "epoch:41 step:32397 [D loss: 0.450811, acc: 77.34%] [G loss: 4.266913]\n",
      "epoch:41 step:32398 [D loss: 0.465470, acc: 76.56%] [G loss: 9.553619]\n",
      "epoch:41 step:32399 [D loss: 0.053849, acc: 100.00%] [G loss: 3.439400]\n",
      "epoch:41 step:32400 [D loss: 0.067239, acc: 99.22%] [G loss: 7.706957]\n",
      "##############\n",
      "[0.85425815 0.86190497 0.82001441 0.81927036 0.79911428 0.83831688\n",
      " 0.89579354 0.83481947 0.78321534 0.82554753]\n",
      "##########\n",
      "epoch:41 step:32401 [D loss: 0.079151, acc: 98.44%] [G loss: 8.435318]\n",
      "epoch:41 step:32402 [D loss: 0.293101, acc: 90.62%] [G loss: 3.966555]\n",
      "epoch:41 step:32403 [D loss: 0.197748, acc: 97.66%] [G loss: 5.427855]\n",
      "epoch:41 step:32404 [D loss: 0.287974, acc: 87.50%] [G loss: 7.845963]\n",
      "epoch:41 step:32405 [D loss: 0.213378, acc: 92.19%] [G loss: 6.453568]\n",
      "epoch:41 step:32406 [D loss: 0.213807, acc: 93.75%] [G loss: 4.223207]\n",
      "epoch:41 step:32407 [D loss: 0.101839, acc: 98.44%] [G loss: 7.281618]\n",
      "epoch:41 step:32408 [D loss: 0.156928, acc: 95.31%] [G loss: 3.753153]\n",
      "epoch:41 step:32409 [D loss: 0.130185, acc: 99.22%] [G loss: 5.682522]\n",
      "epoch:41 step:32410 [D loss: 0.467081, acc: 74.22%] [G loss: 6.031531]\n",
      "epoch:41 step:32411 [D loss: 1.041304, acc: 50.00%] [G loss: 6.469982]\n",
      "epoch:41 step:32412 [D loss: 0.041660, acc: 100.00%] [G loss: 4.877248]\n",
      "epoch:41 step:32413 [D loss: 0.176670, acc: 96.88%] [G loss: 4.695488]\n",
      "epoch:41 step:32414 [D loss: 0.821042, acc: 51.56%] [G loss: 6.269550]\n",
      "epoch:41 step:32415 [D loss: 0.120243, acc: 96.88%] [G loss: 5.879892]\n",
      "epoch:41 step:32416 [D loss: 0.028264, acc: 100.00%] [G loss: 5.555056]\n",
      "epoch:41 step:32417 [D loss: 0.743888, acc: 58.59%] [G loss: 6.904342]\n",
      "epoch:41 step:32418 [D loss: 0.946547, acc: 50.00%] [G loss: 7.317321]\n",
      "epoch:41 step:32419 [D loss: 0.849375, acc: 50.78%] [G loss: 4.413291]\n",
      "epoch:41 step:32420 [D loss: 0.507896, acc: 72.66%] [G loss: 5.744024]\n",
      "epoch:41 step:32421 [D loss: 0.403264, acc: 72.66%] [G loss: 8.256134]\n",
      "epoch:41 step:32422 [D loss: 0.070414, acc: 98.44%] [G loss: 8.310411]\n",
      "epoch:41 step:32423 [D loss: 0.647117, acc: 57.03%] [G loss: 5.836489]\n",
      "epoch:41 step:32424 [D loss: 0.111596, acc: 100.00%] [G loss: 7.083738]\n",
      "epoch:41 step:32425 [D loss: 0.386944, acc: 76.56%] [G loss: 7.608095]\n",
      "epoch:41 step:32426 [D loss: 0.350851, acc: 88.28%] [G loss: 6.080380]\n",
      "epoch:41 step:32427 [D loss: 0.335810, acc: 85.94%] [G loss: 5.010669]\n",
      "epoch:41 step:32428 [D loss: 0.516503, acc: 69.53%] [G loss: 9.864722]\n",
      "epoch:41 step:32429 [D loss: 0.250855, acc: 96.09%] [G loss: 3.919561]\n",
      "epoch:41 step:32430 [D loss: 0.117151, acc: 99.22%] [G loss: 5.495941]\n",
      "epoch:41 step:32431 [D loss: 0.206497, acc: 97.66%] [G loss: 7.054567]\n",
      "epoch:41 step:32432 [D loss: 0.450668, acc: 72.66%] [G loss: 5.936685]\n",
      "epoch:41 step:32433 [D loss: 0.032367, acc: 100.00%] [G loss: 3.143426]\n",
      "epoch:41 step:32434 [D loss: 0.129383, acc: 98.44%] [G loss: 6.144456]\n",
      "epoch:41 step:32435 [D loss: 0.050704, acc: 100.00%] [G loss: 6.779570]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:41 step:32436 [D loss: 0.345813, acc: 94.53%] [G loss: 4.675848]\n",
      "epoch:41 step:32437 [D loss: 0.933863, acc: 51.56%] [G loss: 5.821149]\n",
      "epoch:41 step:32438 [D loss: 1.147304, acc: 50.00%] [G loss: 2.343495]\n",
      "epoch:41 step:32439 [D loss: 0.107300, acc: 99.22%] [G loss: 3.876229]\n",
      "epoch:41 step:32440 [D loss: 0.152153, acc: 98.44%] [G loss: 4.818551]\n",
      "epoch:41 step:32441 [D loss: 0.089784, acc: 99.22%] [G loss: 7.133711]\n",
      "epoch:41 step:32442 [D loss: 0.461135, acc: 81.25%] [G loss: 10.791254]\n",
      "epoch:41 step:32443 [D loss: 0.032220, acc: 100.00%] [G loss: 6.056637]\n",
      "epoch:41 step:32444 [D loss: 0.101935, acc: 100.00%] [G loss: 6.086535]\n",
      "epoch:41 step:32445 [D loss: 0.043499, acc: 100.00%] [G loss: 5.527864]\n",
      "epoch:41 step:32446 [D loss: 0.973372, acc: 46.09%] [G loss: 3.723812]\n",
      "epoch:41 step:32447 [D loss: 0.186232, acc: 96.88%] [G loss: 6.679022]\n",
      "epoch:41 step:32448 [D loss: 0.859259, acc: 53.12%] [G loss: 10.089323]\n",
      "epoch:41 step:32449 [D loss: 0.598410, acc: 60.16%] [G loss: 4.819869]\n",
      "epoch:41 step:32450 [D loss: 0.083276, acc: 100.00%] [G loss: 4.928518]\n",
      "epoch:41 step:32451 [D loss: 0.143934, acc: 98.44%] [G loss: 6.642670]\n",
      "epoch:41 step:32452 [D loss: 0.331082, acc: 89.84%] [G loss: 6.198258]\n",
      "epoch:41 step:32453 [D loss: 1.725694, acc: 7.03%] [G loss: 5.605428]\n",
      "epoch:41 step:32454 [D loss: 0.234367, acc: 89.06%] [G loss: 1.504721]\n",
      "epoch:41 step:32455 [D loss: 0.186457, acc: 98.44%] [G loss: 8.469532]\n",
      "epoch:41 step:32456 [D loss: 0.114702, acc: 99.22%] [G loss: 5.187057]\n",
      "epoch:41 step:32457 [D loss: 0.245398, acc: 92.97%] [G loss: 4.541814]\n",
      "epoch:41 step:32458 [D loss: 0.403038, acc: 71.88%] [G loss: 4.802519]\n",
      "epoch:41 step:32459 [D loss: 0.025885, acc: 100.00%] [G loss: 5.956492]\n",
      "epoch:41 step:32460 [D loss: 0.038928, acc: 100.00%] [G loss: 5.919568]\n",
      "epoch:41 step:32461 [D loss: 1.353162, acc: 14.06%] [G loss: 6.650241]\n",
      "epoch:41 step:32462 [D loss: 0.478553, acc: 70.31%] [G loss: 3.776900]\n",
      "epoch:41 step:32463 [D loss: 0.238397, acc: 92.97%] [G loss: 4.231447]\n",
      "epoch:41 step:32464 [D loss: 0.215371, acc: 95.31%] [G loss: 7.205114]\n",
      "epoch:41 step:32465 [D loss: 0.280263, acc: 93.75%] [G loss: 6.703983]\n",
      "epoch:41 step:32466 [D loss: 0.180680, acc: 96.88%] [G loss: 6.826757]\n",
      "epoch:41 step:32467 [D loss: 0.273293, acc: 95.31%] [G loss: 4.472266]\n",
      "epoch:41 step:32468 [D loss: 0.087253, acc: 100.00%] [G loss: 5.525426]\n",
      "epoch:41 step:32469 [D loss: 1.423554, acc: 50.00%] [G loss: 5.161719]\n",
      "epoch:41 step:32470 [D loss: 0.466122, acc: 65.62%] [G loss: 7.709084]\n",
      "epoch:41 step:32471 [D loss: 0.082378, acc: 98.44%] [G loss: 5.942221]\n",
      "epoch:41 step:32472 [D loss: 0.386783, acc: 80.47%] [G loss: 6.367518]\n",
      "epoch:41 step:32473 [D loss: 0.544728, acc: 64.06%] [G loss: 5.158991]\n",
      "epoch:41 step:32474 [D loss: 0.462257, acc: 78.91%] [G loss: 5.665460]\n",
      "epoch:41 step:32475 [D loss: 0.674147, acc: 55.47%] [G loss: 3.974633]\n",
      "epoch:41 step:32476 [D loss: 0.922611, acc: 50.78%] [G loss: 7.357546]\n",
      "epoch:41 step:32477 [D loss: 0.056673, acc: 100.00%] [G loss: 4.701634]\n",
      "epoch:41 step:32478 [D loss: 0.600366, acc: 66.41%] [G loss: 3.341924]\n",
      "epoch:41 step:32479 [D loss: 0.435195, acc: 78.12%] [G loss: 6.847149]\n",
      "epoch:41 step:32480 [D loss: 0.112100, acc: 96.88%] [G loss: 7.111658]\n",
      "epoch:41 step:32481 [D loss: 0.046360, acc: 100.00%] [G loss: 9.607926]\n",
      "epoch:41 step:32482 [D loss: 0.157476, acc: 98.44%] [G loss: 9.743677]\n",
      "epoch:41 step:32483 [D loss: 0.058489, acc: 100.00%] [G loss: 7.927481]\n",
      "epoch:41 step:32484 [D loss: 0.364559, acc: 80.47%] [G loss: 7.514592]\n",
      "epoch:41 step:32485 [D loss: 0.272154, acc: 89.06%] [G loss: 4.961264]\n",
      "epoch:41 step:32486 [D loss: 0.217017, acc: 94.53%] [G loss: 8.219131]\n",
      "epoch:41 step:32487 [D loss: 0.914110, acc: 53.12%] [G loss: 4.787226]\n",
      "epoch:41 step:32488 [D loss: 0.900789, acc: 46.88%] [G loss: 7.414908]\n",
      "epoch:41 step:32489 [D loss: 0.098955, acc: 100.00%] [G loss: 4.112553]\n",
      "epoch:41 step:32490 [D loss: 0.225090, acc: 99.22%] [G loss: 5.368764]\n",
      "epoch:41 step:32491 [D loss: 0.552776, acc: 69.53%] [G loss: 7.057358]\n",
      "epoch:41 step:32492 [D loss: 0.053424, acc: 100.00%] [G loss: 7.719286]\n",
      "epoch:41 step:32493 [D loss: 0.165147, acc: 95.31%] [G loss: 6.571712]\n",
      "epoch:41 step:32494 [D loss: 0.047966, acc: 100.00%] [G loss: 7.330800]\n",
      "epoch:41 step:32495 [D loss: 0.084574, acc: 100.00%] [G loss: 4.822756]\n",
      "epoch:41 step:32496 [D loss: 0.071105, acc: 100.00%] [G loss: 4.294970]\n",
      "epoch:41 step:32497 [D loss: 1.062587, acc: 28.12%] [G loss: 5.481413]\n",
      "epoch:41 step:32498 [D loss: 0.996549, acc: 50.78%] [G loss: 4.235332]\n",
      "epoch:41 step:32499 [D loss: 0.206331, acc: 93.75%] [G loss: 9.890761]\n",
      "epoch:41 step:32500 [D loss: 0.484462, acc: 76.56%] [G loss: 3.535173]\n",
      "epoch:41 step:32501 [D loss: 1.171778, acc: 15.62%] [G loss: 4.818413]\n",
      "epoch:41 step:32502 [D loss: 0.273644, acc: 96.88%] [G loss: 3.182049]\n",
      "epoch:41 step:32503 [D loss: 0.431375, acc: 78.91%] [G loss: 5.695824]\n",
      "epoch:41 step:32504 [D loss: 0.097505, acc: 99.22%] [G loss: 3.695446]\n",
      "epoch:41 step:32505 [D loss: 0.325214, acc: 79.69%] [G loss: 6.534980]\n",
      "epoch:41 step:32506 [D loss: 0.134147, acc: 98.44%] [G loss: 5.089631]\n",
      "epoch:41 step:32507 [D loss: 0.139302, acc: 98.44%] [G loss: 5.075380]\n",
      "epoch:41 step:32508 [D loss: 0.219117, acc: 92.97%] [G loss: 7.637942]\n",
      "epoch:41 step:32509 [D loss: 0.091013, acc: 99.22%] [G loss: 8.834415]\n",
      "epoch:41 step:32510 [D loss: 0.833617, acc: 53.91%] [G loss: 5.817069]\n",
      "epoch:41 step:32511 [D loss: 0.371838, acc: 81.25%] [G loss: 4.860897]\n",
      "epoch:41 step:32512 [D loss: 0.343276, acc: 78.91%] [G loss: 5.277565]\n",
      "epoch:41 step:32513 [D loss: 0.943008, acc: 50.78%] [G loss: 6.858075]\n",
      "epoch:41 step:32514 [D loss: 0.062149, acc: 100.00%] [G loss: 7.248193]\n",
      "epoch:41 step:32515 [D loss: 0.075775, acc: 100.00%] [G loss: 5.528907]\n",
      "epoch:41 step:32516 [D loss: 0.020765, acc: 100.00%] [G loss: 5.653358]\n",
      "epoch:41 step:32517 [D loss: 0.201847, acc: 93.75%] [G loss: 5.967087]\n",
      "epoch:41 step:32518 [D loss: 0.315666, acc: 82.03%] [G loss: 5.751024]\n",
      "epoch:41 step:32519 [D loss: 0.110864, acc: 99.22%] [G loss: 6.022870]\n",
      "epoch:41 step:32520 [D loss: 0.300033, acc: 87.50%] [G loss: 5.027156]\n",
      "epoch:41 step:32521 [D loss: 0.121796, acc: 100.00%] [G loss: 6.425436]\n",
      "epoch:41 step:32522 [D loss: 0.040148, acc: 100.00%] [G loss: 1.770465]\n",
      "epoch:41 step:32523 [D loss: 0.029448, acc: 100.00%] [G loss: 5.434041]\n",
      "epoch:41 step:32524 [D loss: 0.191049, acc: 96.88%] [G loss: 5.672743]\n",
      "epoch:41 step:32525 [D loss: 0.389930, acc: 77.34%] [G loss: 6.348192]\n",
      "epoch:41 step:32526 [D loss: 1.281067, acc: 28.91%] [G loss: 3.877951]\n",
      "epoch:41 step:32527 [D loss: 0.646264, acc: 64.84%] [G loss: 4.342116]\n",
      "epoch:41 step:32528 [D loss: 0.873582, acc: 46.09%] [G loss: 3.440330]\n",
      "epoch:41 step:32529 [D loss: 0.107384, acc: 98.44%] [G loss: 5.368639]\n",
      "epoch:41 step:32530 [D loss: 0.052618, acc: 100.00%] [G loss: 6.083957]\n",
      "epoch:41 step:32531 [D loss: 0.037136, acc: 99.22%] [G loss: 4.177512]\n",
      "epoch:41 step:32532 [D loss: 0.079230, acc: 99.22%] [G loss: 6.502654]\n",
      "epoch:41 step:32533 [D loss: 0.302487, acc: 89.84%] [G loss: 5.084197]\n",
      "epoch:41 step:32534 [D loss: 0.758880, acc: 58.59%] [G loss: 4.772086]\n",
      "epoch:41 step:32535 [D loss: 0.115911, acc: 98.44%] [G loss: 3.637942]\n",
      "epoch:41 step:32536 [D loss: 0.251792, acc: 91.41%] [G loss: 4.039768]\n",
      "epoch:41 step:32537 [D loss: 0.061284, acc: 100.00%] [G loss: 4.798000]\n",
      "epoch:41 step:32538 [D loss: 0.068423, acc: 100.00%] [G loss: 4.882393]\n",
      "epoch:41 step:32539 [D loss: 0.207748, acc: 98.44%] [G loss: 8.202253]\n",
      "epoch:41 step:32540 [D loss: 0.135793, acc: 99.22%] [G loss: 7.308178]\n",
      "epoch:41 step:32541 [D loss: 0.324123, acc: 89.06%] [G loss: 5.204352]\n",
      "epoch:41 step:32542 [D loss: 0.405503, acc: 82.81%] [G loss: 6.574972]\n",
      "epoch:41 step:32543 [D loss: 0.229909, acc: 96.88%] [G loss: 5.651010]\n",
      "epoch:41 step:32544 [D loss: 0.131212, acc: 100.00%] [G loss: 5.670785]\n",
      "epoch:41 step:32545 [D loss: 0.146154, acc: 98.44%] [G loss: 6.352521]\n",
      "epoch:41 step:32546 [D loss: 0.441799, acc: 76.56%] [G loss: 2.480662]\n",
      "epoch:41 step:32547 [D loss: 0.153933, acc: 97.66%] [G loss: 6.868184]\n",
      "epoch:41 step:32548 [D loss: 0.128043, acc: 98.44%] [G loss: 8.745756]\n",
      "epoch:41 step:32549 [D loss: 0.548693, acc: 75.78%] [G loss: 6.143473]\n",
      "epoch:41 step:32550 [D loss: 0.236200, acc: 91.41%] [G loss: 2.383842]\n",
      "epoch:41 step:32551 [D loss: 0.016501, acc: 100.00%] [G loss: 7.417957]\n",
      "epoch:41 step:32552 [D loss: 0.222034, acc: 96.09%] [G loss: 4.856800]\n",
      "epoch:41 step:32553 [D loss: 0.208879, acc: 97.66%] [G loss: 3.248044]\n",
      "epoch:41 step:32554 [D loss: 0.137800, acc: 99.22%] [G loss: 3.480546]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:41 step:32555 [D loss: 0.075749, acc: 100.00%] [G loss: 8.768977]\n",
      "epoch:41 step:32556 [D loss: 0.349427, acc: 87.50%] [G loss: 4.645110]\n",
      "epoch:41 step:32557 [D loss: 0.323441, acc: 80.47%] [G loss: 5.806951]\n",
      "epoch:41 step:32558 [D loss: 0.336703, acc: 82.81%] [G loss: 4.918733]\n",
      "epoch:41 step:32559 [D loss: 0.036747, acc: 100.00%] [G loss: 4.443024]\n",
      "epoch:41 step:32560 [D loss: 0.450923, acc: 80.47%] [G loss: 6.733174]\n",
      "epoch:41 step:32561 [D loss: 0.448637, acc: 72.66%] [G loss: 9.075832]\n",
      "epoch:41 step:32562 [D loss: 0.356964, acc: 84.38%] [G loss: 7.990952]\n",
      "epoch:41 step:32563 [D loss: 0.026503, acc: 100.00%] [G loss: 6.251685]\n",
      "epoch:41 step:32564 [D loss: 0.048274, acc: 100.00%] [G loss: 4.245102]\n",
      "epoch:41 step:32565 [D loss: 0.277722, acc: 94.53%] [G loss: 5.767926]\n",
      "epoch:41 step:32566 [D loss: 0.609742, acc: 63.28%] [G loss: 6.098609]\n",
      "epoch:41 step:32567 [D loss: 0.084583, acc: 100.00%] [G loss: 4.317614]\n",
      "epoch:41 step:32568 [D loss: 0.483101, acc: 66.41%] [G loss: 6.984537]\n",
      "epoch:41 step:32569 [D loss: 0.105757, acc: 99.22%] [G loss: 6.467756]\n",
      "epoch:41 step:32570 [D loss: 0.760782, acc: 52.34%] [G loss: 6.001295]\n",
      "epoch:41 step:32571 [D loss: 0.264756, acc: 89.84%] [G loss: 7.236447]\n",
      "epoch:41 step:32572 [D loss: 0.422465, acc: 86.72%] [G loss: 6.440448]\n",
      "epoch:41 step:32573 [D loss: 0.067303, acc: 100.00%] [G loss: 4.227601]\n",
      "epoch:41 step:32574 [D loss: 1.486513, acc: 34.38%] [G loss: 7.930920]\n",
      "epoch:41 step:32575 [D loss: 0.222721, acc: 96.88%] [G loss: 6.899502]\n",
      "epoch:41 step:32576 [D loss: 0.064670, acc: 99.22%] [G loss: 7.059429]\n",
      "epoch:41 step:32577 [D loss: 0.359413, acc: 79.69%] [G loss: 6.326015]\n",
      "epoch:41 step:32578 [D loss: 0.082433, acc: 100.00%] [G loss: 1.737228]\n",
      "epoch:41 step:32579 [D loss: 0.672527, acc: 57.03%] [G loss: 9.154392]\n",
      "epoch:41 step:32580 [D loss: 0.790990, acc: 52.34%] [G loss: 6.514843]\n",
      "epoch:41 step:32581 [D loss: 0.143994, acc: 97.66%] [G loss: 6.165125]\n",
      "epoch:41 step:32582 [D loss: 0.410636, acc: 79.69%] [G loss: 7.597134]\n",
      "epoch:41 step:32583 [D loss: 0.417744, acc: 72.66%] [G loss: 4.326543]\n",
      "epoch:41 step:32584 [D loss: 1.073942, acc: 50.78%] [G loss: 6.250602]\n",
      "epoch:41 step:32585 [D loss: 0.330754, acc: 90.62%] [G loss: 8.784676]\n",
      "epoch:41 step:32586 [D loss: 0.192253, acc: 96.09%] [G loss: 9.111019]\n",
      "epoch:41 step:32587 [D loss: 0.296030, acc: 89.84%] [G loss: 2.229197]\n",
      "epoch:41 step:32588 [D loss: 0.150838, acc: 98.44%] [G loss: 5.542809]\n",
      "epoch:41 step:32589 [D loss: 0.466474, acc: 69.53%] [G loss: 7.748611]\n",
      "epoch:41 step:32590 [D loss: 0.087801, acc: 100.00%] [G loss: 6.881077]\n",
      "epoch:41 step:32591 [D loss: 0.094046, acc: 99.22%] [G loss: 4.055465]\n",
      "epoch:41 step:32592 [D loss: 0.043373, acc: 100.00%] [G loss: 8.512361]\n",
      "epoch:41 step:32593 [D loss: 0.165866, acc: 98.44%] [G loss: 5.852488]\n",
      "epoch:41 step:32594 [D loss: 0.110786, acc: 100.00%] [G loss: 5.786122]\n",
      "epoch:41 step:32595 [D loss: 0.540872, acc: 71.09%] [G loss: 3.150905]\n",
      "epoch:41 step:32596 [D loss: 0.129604, acc: 100.00%] [G loss: 4.833550]\n",
      "epoch:41 step:32597 [D loss: 0.134212, acc: 100.00%] [G loss: 5.342152]\n",
      "epoch:41 step:32598 [D loss: 0.309259, acc: 93.75%] [G loss: 5.376690]\n",
      "epoch:41 step:32599 [D loss: 0.016565, acc: 100.00%] [G loss: 8.214273]\n",
      "epoch:41 step:32600 [D loss: 0.150644, acc: 98.44%] [G loss: 4.916058]\n",
      "##############\n",
      "[0.86459449 0.86506456 0.80087701 0.82718481 0.78912738 0.81946091\n",
      " 0.86117527 0.8526748  0.7996829  0.82924506]\n",
      "##########\n",
      "epoch:41 step:32601 [D loss: 0.061203, acc: 100.00%] [G loss: 7.140651]\n",
      "epoch:41 step:32602 [D loss: 0.042513, acc: 100.00%] [G loss: 8.392168]\n",
      "epoch:41 step:32603 [D loss: 0.403119, acc: 82.81%] [G loss: 9.041060]\n",
      "epoch:41 step:32604 [D loss: 0.317216, acc: 82.03%] [G loss: 6.518330]\n",
      "epoch:41 step:32605 [D loss: 0.315988, acc: 87.50%] [G loss: 4.604627]\n",
      "epoch:41 step:32606 [D loss: 0.051120, acc: 100.00%] [G loss: 7.634951]\n",
      "epoch:41 step:32607 [D loss: 0.029191, acc: 100.00%] [G loss: 5.279570]\n",
      "epoch:41 step:32608 [D loss: 0.078424, acc: 100.00%] [G loss: 9.533064]\n",
      "epoch:41 step:32609 [D loss: 0.199596, acc: 96.88%] [G loss: 9.264183]\n",
      "epoch:41 step:32610 [D loss: 0.552766, acc: 72.66%] [G loss: 8.754987]\n",
      "epoch:41 step:32611 [D loss: 0.589197, acc: 63.28%] [G loss: 6.480772]\n",
      "epoch:41 step:32612 [D loss: 0.010025, acc: 100.00%] [G loss: 7.060390]\n",
      "epoch:41 step:32613 [D loss: 0.557882, acc: 64.06%] [G loss: 4.722580]\n",
      "epoch:41 step:32614 [D loss: 0.422973, acc: 69.53%] [G loss: 2.877569]\n",
      "epoch:41 step:32615 [D loss: 0.316398, acc: 81.25%] [G loss: 5.212862]\n",
      "epoch:41 step:32616 [D loss: 0.083147, acc: 99.22%] [G loss: 2.917408]\n",
      "epoch:41 step:32617 [D loss: 0.331001, acc: 91.41%] [G loss: 6.061174]\n",
      "epoch:41 step:32618 [D loss: 0.280398, acc: 96.09%] [G loss: 5.449799]\n",
      "epoch:41 step:32619 [D loss: 1.191847, acc: 50.00%] [G loss: 5.286595]\n",
      "epoch:41 step:32620 [D loss: 0.076023, acc: 99.22%] [G loss: 5.800926]\n",
      "epoch:41 step:32621 [D loss: 0.745967, acc: 56.25%] [G loss: 6.589209]\n",
      "epoch:41 step:32622 [D loss: 0.250623, acc: 89.84%] [G loss: 6.025502]\n",
      "epoch:41 step:32623 [D loss: 0.107718, acc: 99.22%] [G loss: 6.027957]\n",
      "epoch:41 step:32624 [D loss: 0.055245, acc: 99.22%] [G loss: 6.099380]\n",
      "epoch:41 step:32625 [D loss: 0.261531, acc: 91.41%] [G loss: 5.330663]\n",
      "epoch:41 step:32626 [D loss: 0.574513, acc: 62.50%] [G loss: 4.191363]\n",
      "epoch:41 step:32627 [D loss: 0.226036, acc: 95.31%] [G loss: 5.778525]\n",
      "epoch:41 step:32628 [D loss: 2.914611, acc: 47.66%] [G loss: 4.011178]\n",
      "epoch:41 step:32629 [D loss: 0.331871, acc: 87.50%] [G loss: 8.211899]\n",
      "epoch:41 step:32630 [D loss: 0.623659, acc: 59.38%] [G loss: 4.192724]\n",
      "epoch:41 step:32631 [D loss: 1.252383, acc: 28.12%] [G loss: 5.209914]\n",
      "epoch:41 step:32632 [D loss: 0.193873, acc: 95.31%] [G loss: 4.882113]\n",
      "epoch:41 step:32633 [D loss: 0.250847, acc: 92.19%] [G loss: 5.024858]\n",
      "epoch:41 step:32634 [D loss: 0.107629, acc: 100.00%] [G loss: 7.096293]\n",
      "epoch:41 step:32635 [D loss: 0.227640, acc: 96.09%] [G loss: 11.070159]\n",
      "epoch:41 step:32636 [D loss: 0.219853, acc: 92.19%] [G loss: 7.893379]\n",
      "epoch:41 step:32637 [D loss: 0.941086, acc: 52.34%] [G loss: 5.501918]\n",
      "epoch:41 step:32638 [D loss: 0.151815, acc: 96.09%] [G loss: 7.781821]\n",
      "epoch:41 step:32639 [D loss: 0.389294, acc: 74.22%] [G loss: 8.202242]\n",
      "epoch:41 step:32640 [D loss: 0.340048, acc: 95.31%] [G loss: 2.744686]\n",
      "epoch:41 step:32641 [D loss: 0.337539, acc: 79.69%] [G loss: 4.871165]\n",
      "epoch:41 step:32642 [D loss: 0.729264, acc: 57.81%] [G loss: 7.345908]\n",
      "epoch:41 step:32643 [D loss: 0.107352, acc: 99.22%] [G loss: 8.680430]\n",
      "epoch:41 step:32644 [D loss: 0.057507, acc: 100.00%] [G loss: 6.054306]\n",
      "epoch:41 step:32645 [D loss: 0.009409, acc: 100.00%] [G loss: 7.828083]\n",
      "epoch:41 step:32646 [D loss: 0.824993, acc: 53.12%] [G loss: 5.327786]\n",
      "epoch:41 step:32647 [D loss: 0.436875, acc: 75.00%] [G loss: 10.459949]\n",
      "epoch:41 step:32648 [D loss: 0.291180, acc: 93.75%] [G loss: 5.922557]\n",
      "epoch:41 step:32649 [D loss: 0.130670, acc: 100.00%] [G loss: 6.677691]\n",
      "epoch:41 step:32650 [D loss: 0.584685, acc: 63.28%] [G loss: 7.091120]\n",
      "epoch:41 step:32651 [D loss: 0.019141, acc: 100.00%] [G loss: 11.088581]\n",
      "epoch:41 step:32652 [D loss: 0.066994, acc: 100.00%] [G loss: 3.201534]\n",
      "epoch:41 step:32653 [D loss: 0.177164, acc: 99.22%] [G loss: 5.275958]\n",
      "epoch:41 step:32654 [D loss: 0.074207, acc: 100.00%] [G loss: 6.421490]\n",
      "epoch:41 step:32655 [D loss: 0.661061, acc: 57.81%] [G loss: 5.187615]\n",
      "epoch:41 step:32656 [D loss: 0.566126, acc: 71.09%] [G loss: 8.520533]\n",
      "epoch:41 step:32657 [D loss: 0.774080, acc: 55.47%] [G loss: 7.189556]\n",
      "epoch:41 step:32658 [D loss: 0.094716, acc: 100.00%] [G loss: 3.700786]\n",
      "epoch:41 step:32659 [D loss: 0.563462, acc: 67.97%] [G loss: 8.396147]\n",
      "epoch:41 step:32660 [D loss: 0.131707, acc: 99.22%] [G loss: 6.837037]\n",
      "epoch:41 step:32661 [D loss: 0.014854, acc: 100.00%] [G loss: 9.411721]\n",
      "epoch:41 step:32662 [D loss: 0.028666, acc: 100.00%] [G loss: 3.377003]\n",
      "epoch:41 step:32663 [D loss: 1.587672, acc: 46.88%] [G loss: 8.520030]\n",
      "epoch:41 step:32664 [D loss: 0.300069, acc: 88.28%] [G loss: 5.426053]\n",
      "epoch:41 step:32665 [D loss: 0.504484, acc: 68.75%] [G loss: 8.174236]\n",
      "epoch:41 step:32666 [D loss: 0.514679, acc: 64.06%] [G loss: 3.499228]\n",
      "epoch:41 step:32667 [D loss: 0.306753, acc: 90.62%] [G loss: 4.543565]\n",
      "epoch:41 step:32668 [D loss: 0.118843, acc: 98.44%] [G loss: 5.932408]\n",
      "epoch:41 step:32669 [D loss: 0.137106, acc: 98.44%] [G loss: 6.928615]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:41 step:32670 [D loss: 0.204353, acc: 95.31%] [G loss: 4.098476]\n",
      "epoch:41 step:32671 [D loss: 0.840594, acc: 43.75%] [G loss: 6.199344]\n",
      "epoch:41 step:32672 [D loss: 0.067624, acc: 100.00%] [G loss: 6.617849]\n",
      "epoch:41 step:32673 [D loss: 0.145523, acc: 97.66%] [G loss: 7.431350]\n",
      "epoch:41 step:32674 [D loss: 0.121267, acc: 98.44%] [G loss: 2.909136]\n",
      "epoch:41 step:32675 [D loss: 0.132800, acc: 100.00%] [G loss: 6.329456]\n",
      "epoch:41 step:32676 [D loss: 0.081639, acc: 99.22%] [G loss: 6.361798]\n",
      "epoch:41 step:32677 [D loss: 0.470483, acc: 78.91%] [G loss: 3.302950]\n",
      "epoch:41 step:32678 [D loss: 0.574600, acc: 64.06%] [G loss: 6.163438]\n",
      "epoch:41 step:32679 [D loss: 0.289901, acc: 88.28%] [G loss: 5.557114]\n",
      "epoch:41 step:32680 [D loss: 0.499063, acc: 73.44%] [G loss: 9.009056]\n",
      "epoch:41 step:32681 [D loss: 1.114725, acc: 21.09%] [G loss: 7.452063]\n",
      "epoch:41 step:32682 [D loss: 0.561386, acc: 67.97%] [G loss: 4.526786]\n",
      "epoch:41 step:32683 [D loss: 0.023173, acc: 100.00%] [G loss: 6.692797]\n",
      "epoch:41 step:32684 [D loss: 0.333115, acc: 90.62%] [G loss: 7.317738]\n",
      "epoch:41 step:32685 [D loss: 0.230756, acc: 91.41%] [G loss: 2.018984]\n",
      "epoch:41 step:32686 [D loss: 0.076598, acc: 100.00%] [G loss: 2.062903]\n",
      "epoch:41 step:32687 [D loss: 0.090272, acc: 100.00%] [G loss: 3.766742]\n",
      "epoch:41 step:32688 [D loss: 0.029700, acc: 100.00%] [G loss: 4.664080]\n",
      "epoch:41 step:32689 [D loss: 0.071594, acc: 100.00%] [G loss: 5.803868]\n",
      "epoch:41 step:32690 [D loss: 0.094705, acc: 98.44%] [G loss: 5.932327]\n",
      "epoch:41 step:32691 [D loss: 0.061332, acc: 100.00%] [G loss: 5.646906]\n",
      "epoch:41 step:32692 [D loss: 0.707857, acc: 53.91%] [G loss: 4.170079]\n",
      "epoch:41 step:32693 [D loss: 0.176962, acc: 99.22%] [G loss: 4.182678]\n",
      "epoch:41 step:32694 [D loss: 0.102324, acc: 99.22%] [G loss: 4.630626]\n",
      "epoch:41 step:32695 [D loss: 0.153138, acc: 96.09%] [G loss: 5.944863]\n",
      "epoch:41 step:32696 [D loss: 0.554701, acc: 72.66%] [G loss: 5.355221]\n",
      "epoch:41 step:32697 [D loss: 0.217051, acc: 97.66%] [G loss: 6.997479]\n",
      "epoch:41 step:32698 [D loss: 0.069711, acc: 100.00%] [G loss: 6.791165]\n",
      "epoch:41 step:32699 [D loss: 0.162926, acc: 97.66%] [G loss: 4.953753]\n",
      "epoch:41 step:32700 [D loss: 0.290074, acc: 89.84%] [G loss: 2.109902]\n",
      "epoch:41 step:32701 [D loss: 0.080369, acc: 100.00%] [G loss: 2.753152]\n",
      "epoch:41 step:32702 [D loss: 0.155715, acc: 98.44%] [G loss: 7.526940]\n",
      "epoch:41 step:32703 [D loss: 0.177573, acc: 95.31%] [G loss: 8.922696]\n",
      "epoch:41 step:32704 [D loss: 0.284862, acc: 92.19%] [G loss: 5.820348]\n",
      "epoch:41 step:32705 [D loss: 0.139935, acc: 98.44%] [G loss: 6.818698]\n",
      "epoch:41 step:32706 [D loss: 0.075339, acc: 100.00%] [G loss: 3.872456]\n",
      "epoch:41 step:32707 [D loss: 0.034636, acc: 100.00%] [G loss: 2.255485]\n",
      "epoch:41 step:32708 [D loss: 0.186351, acc: 98.44%] [G loss: 5.671268]\n",
      "epoch:41 step:32709 [D loss: 0.250137, acc: 96.09%] [G loss: 6.271403]\n",
      "epoch:41 step:32710 [D loss: 0.166256, acc: 100.00%] [G loss: 3.202635]\n",
      "epoch:41 step:32711 [D loss: 0.106331, acc: 98.44%] [G loss: 5.371977]\n",
      "epoch:41 step:32712 [D loss: 0.020600, acc: 100.00%] [G loss: 7.949060]\n",
      "epoch:41 step:32713 [D loss: 0.876614, acc: 50.00%] [G loss: 8.462031]\n",
      "epoch:41 step:32714 [D loss: 0.245483, acc: 94.53%] [G loss: 6.491965]\n",
      "epoch:41 step:32715 [D loss: 0.112191, acc: 99.22%] [G loss: 8.217252]\n",
      "epoch:41 step:32716 [D loss: 0.549765, acc: 67.97%] [G loss: 7.253619]\n",
      "epoch:41 step:32717 [D loss: 0.049381, acc: 100.00%] [G loss: 7.873337]\n",
      "epoch:41 step:32718 [D loss: 1.693929, acc: 50.00%] [G loss: 10.089768]\n",
      "epoch:41 step:32719 [D loss: 0.124135, acc: 100.00%] [G loss: 7.661854]\n",
      "epoch:41 step:32720 [D loss: 1.623753, acc: 50.00%] [G loss: 4.732327]\n",
      "epoch:41 step:32721 [D loss: 0.073360, acc: 100.00%] [G loss: 6.213167]\n",
      "epoch:41 step:32722 [D loss: 0.075867, acc: 100.00%] [G loss: 3.255854]\n",
      "epoch:41 step:32723 [D loss: 0.847148, acc: 53.91%] [G loss: 8.874720]\n",
      "epoch:41 step:32724 [D loss: 0.025526, acc: 100.00%] [G loss: 7.181980]\n",
      "epoch:41 step:32725 [D loss: 1.218162, acc: 50.00%] [G loss: 6.744448]\n",
      "epoch:41 step:32726 [D loss: 0.026015, acc: 100.00%] [G loss: 6.132504]\n",
      "epoch:41 step:32727 [D loss: 0.118768, acc: 99.22%] [G loss: 6.947127]\n",
      "epoch:41 step:32728 [D loss: 0.349533, acc: 90.62%] [G loss: 5.794427]\n",
      "epoch:41 step:32729 [D loss: 0.021245, acc: 100.00%] [G loss: 8.318642]\n",
      "epoch:41 step:32730 [D loss: 0.447185, acc: 67.19%] [G loss: 7.605556]\n",
      "epoch:41 step:32731 [D loss: 0.522385, acc: 67.19%] [G loss: 5.318049]\n",
      "epoch:41 step:32732 [D loss: 0.111509, acc: 98.44%] [G loss: 8.763126]\n",
      "epoch:41 step:32733 [D loss: 0.266548, acc: 90.62%] [G loss: 5.693375]\n",
      "epoch:41 step:32734 [D loss: 0.035538, acc: 100.00%] [G loss: 6.820186]\n",
      "epoch:41 step:32735 [D loss: 0.483794, acc: 74.22%] [G loss: 3.219876]\n",
      "epoch:41 step:32736 [D loss: 0.254454, acc: 95.31%] [G loss: 5.728633]\n",
      "epoch:41 step:32737 [D loss: 0.118011, acc: 98.44%] [G loss: 6.415509]\n",
      "epoch:41 step:32738 [D loss: 0.097099, acc: 100.00%] [G loss: 7.435516]\n",
      "epoch:41 step:32739 [D loss: 0.555276, acc: 72.66%] [G loss: 7.334008]\n",
      "epoch:41 step:32740 [D loss: 0.077896, acc: 100.00%] [G loss: 3.395011]\n",
      "epoch:41 step:32741 [D loss: 0.128293, acc: 100.00%] [G loss: 5.349965]\n",
      "epoch:41 step:32742 [D loss: 0.101205, acc: 100.00%] [G loss: 7.530305]\n",
      "epoch:41 step:32743 [D loss: 0.156045, acc: 98.44%] [G loss: 2.541493]\n",
      "epoch:41 step:32744 [D loss: 0.024763, acc: 100.00%] [G loss: 5.605282]\n",
      "epoch:41 step:32745 [D loss: 1.236900, acc: 49.22%] [G loss: 7.787275]\n",
      "epoch:41 step:32746 [D loss: 1.626550, acc: 50.00%] [G loss: 5.935725]\n",
      "epoch:41 step:32747 [D loss: 0.180065, acc: 97.66%] [G loss: 6.347862]\n",
      "epoch:41 step:32748 [D loss: 0.195357, acc: 98.44%] [G loss: 5.008845]\n",
      "epoch:41 step:32749 [D loss: 0.191240, acc: 97.66%] [G loss: 5.683670]\n",
      "epoch:41 step:32750 [D loss: 0.921564, acc: 34.38%] [G loss: 3.393897]\n",
      "epoch:41 step:32751 [D loss: 0.191244, acc: 96.09%] [G loss: 2.710514]\n",
      "epoch:41 step:32752 [D loss: 0.040756, acc: 100.00%] [G loss: 3.062329]\n",
      "epoch:41 step:32753 [D loss: 0.642176, acc: 61.72%] [G loss: 6.155521]\n",
      "epoch:41 step:32754 [D loss: 0.063221, acc: 100.00%] [G loss: 4.149416]\n",
      "epoch:41 step:32755 [D loss: 0.180538, acc: 97.66%] [G loss: 4.693412]\n",
      "epoch:41 step:32756 [D loss: 0.305667, acc: 88.28%] [G loss: 5.915122]\n",
      "epoch:41 step:32757 [D loss: 0.046004, acc: 100.00%] [G loss: 4.893536]\n",
      "epoch:41 step:32758 [D loss: 0.360741, acc: 78.12%] [G loss: 9.599831]\n",
      "epoch:41 step:32759 [D loss: 0.369965, acc: 79.69%] [G loss: 4.037790]\n",
      "epoch:41 step:32760 [D loss: 0.092132, acc: 100.00%] [G loss: 3.685428]\n",
      "epoch:41 step:32761 [D loss: 0.467400, acc: 74.22%] [G loss: 4.285142]\n",
      "epoch:41 step:32762 [D loss: 0.125006, acc: 100.00%] [G loss: 4.299952]\n",
      "epoch:41 step:32763 [D loss: 0.670338, acc: 61.72%] [G loss: 8.241043]\n",
      "epoch:41 step:32764 [D loss: 0.321660, acc: 89.06%] [G loss: 3.663911]\n",
      "epoch:41 step:32765 [D loss: 0.169666, acc: 96.88%] [G loss: 3.609561]\n",
      "epoch:41 step:32766 [D loss: 0.842581, acc: 50.78%] [G loss: 6.517772]\n",
      "epoch:41 step:32767 [D loss: 0.025488, acc: 100.00%] [G loss: 4.089338]\n",
      "epoch:41 step:32768 [D loss: 0.360807, acc: 79.69%] [G loss: 7.983586]\n",
      "epoch:41 step:32769 [D loss: 0.230245, acc: 94.53%] [G loss: 4.338594]\n",
      "epoch:41 step:32770 [D loss: 0.109883, acc: 99.22%] [G loss: 5.278216]\n",
      "epoch:41 step:32771 [D loss: 0.924733, acc: 42.19%] [G loss: 6.395675]\n",
      "epoch:41 step:32772 [D loss: 0.074233, acc: 100.00%] [G loss: 7.191496]\n",
      "epoch:41 step:32773 [D loss: 0.194649, acc: 95.31%] [G loss: 10.685905]\n",
      "epoch:41 step:32774 [D loss: 0.497716, acc: 69.53%] [G loss: 4.683487]\n",
      "epoch:41 step:32775 [D loss: 0.107348, acc: 99.22%] [G loss: 2.943330]\n",
      "epoch:41 step:32776 [D loss: 0.393887, acc: 85.16%] [G loss: 8.427656]\n",
      "epoch:41 step:32777 [D loss: 0.529387, acc: 75.78%] [G loss: 7.501627]\n",
      "epoch:41 step:32778 [D loss: 0.253382, acc: 92.19%] [G loss: 6.168359]\n",
      "epoch:41 step:32779 [D loss: 0.367989, acc: 80.47%] [G loss: 5.947207]\n",
      "epoch:41 step:32780 [D loss: 0.347719, acc: 83.59%] [G loss: 5.240664]\n",
      "epoch:41 step:32781 [D loss: 0.019323, acc: 100.00%] [G loss: 11.564458]\n",
      "epoch:41 step:32782 [D loss: 0.202935, acc: 95.31%] [G loss: 4.733994]\n",
      "epoch:41 step:32783 [D loss: 0.033858, acc: 100.00%] [G loss: 3.957097]\n",
      "epoch:41 step:32784 [D loss: 0.939411, acc: 49.22%] [G loss: 3.085769]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:41 step:32785 [D loss: 0.270240, acc: 89.84%] [G loss: 6.878973]\n",
      "epoch:41 step:32786 [D loss: 0.028013, acc: 100.00%] [G loss: 8.135260]\n",
      "epoch:41 step:32787 [D loss: 0.179199, acc: 98.44%] [G loss: 7.024390]\n",
      "epoch:41 step:32788 [D loss: 1.148110, acc: 50.00%] [G loss: 5.362237]\n",
      "epoch:41 step:32789 [D loss: 0.175534, acc: 96.88%] [G loss: 8.537055]\n",
      "epoch:41 step:32790 [D loss: 0.158231, acc: 97.66%] [G loss: 7.605431]\n",
      "epoch:41 step:32791 [D loss: 0.162745, acc: 96.09%] [G loss: 5.051555]\n",
      "epoch:41 step:32792 [D loss: 0.160956, acc: 98.44%] [G loss: 4.284602]\n",
      "epoch:41 step:32793 [D loss: 0.304414, acc: 88.28%] [G loss: 8.025873]\n",
      "epoch:41 step:32794 [D loss: 0.152385, acc: 94.53%] [G loss: 9.523460]\n",
      "epoch:41 step:32795 [D loss: 0.463181, acc: 78.12%] [G loss: 8.293531]\n",
      "epoch:41 step:32796 [D loss: 0.061664, acc: 100.00%] [G loss: 4.674983]\n",
      "epoch:41 step:32797 [D loss: 0.333235, acc: 82.81%] [G loss: 4.173384]\n",
      "epoch:41 step:32798 [D loss: 1.288693, acc: 16.41%] [G loss: 5.051188]\n",
      "epoch:41 step:32799 [D loss: 0.186068, acc: 98.44%] [G loss: 5.112380]\n",
      "epoch:41 step:32800 [D loss: 0.078909, acc: 100.00%] [G loss: 4.515806]\n",
      "##############\n",
      "[0.84987436 0.86029886 0.8355685  0.80125633 0.79246789 0.85500846\n",
      " 0.89904958 0.80919057 0.80871127 0.83544682]\n",
      "##########\n",
      "epoch:41 step:32801 [D loss: 0.231741, acc: 92.19%] [G loss: 6.105064]\n",
      "epoch:41 step:32802 [D loss: 0.472851, acc: 82.03%] [G loss: 4.951082]\n",
      "epoch:42 step:32803 [D loss: 0.295637, acc: 94.53%] [G loss: 7.922131]\n",
      "epoch:42 step:32804 [D loss: 0.152914, acc: 96.09%] [G loss: 7.364937]\n",
      "epoch:42 step:32805 [D loss: 0.679323, acc: 55.47%] [G loss: 7.857522]\n",
      "epoch:42 step:32806 [D loss: 0.067087, acc: 99.22%] [G loss: 4.776205]\n",
      "epoch:42 step:32807 [D loss: 0.066790, acc: 100.00%] [G loss: 7.958284]\n",
      "epoch:42 step:32808 [D loss: 0.501642, acc: 79.69%] [G loss: 3.020386]\n",
      "epoch:42 step:32809 [D loss: 0.593644, acc: 67.97%] [G loss: 6.962176]\n",
      "epoch:42 step:32810 [D loss: 0.561444, acc: 70.31%] [G loss: 7.224897]\n",
      "epoch:42 step:32811 [D loss: 0.058564, acc: 100.00%] [G loss: 7.411178]\n",
      "epoch:42 step:32812 [D loss: 0.399073, acc: 78.91%] [G loss: 8.063455]\n",
      "epoch:42 step:32813 [D loss: 0.060292, acc: 100.00%] [G loss: 9.330037]\n",
      "epoch:42 step:32814 [D loss: 0.650829, acc: 56.25%] [G loss: 8.216719]\n",
      "epoch:42 step:32815 [D loss: 1.722330, acc: 2.34%] [G loss: 10.032032]\n",
      "epoch:42 step:32816 [D loss: 0.264923, acc: 92.19%] [G loss: 5.626583]\n",
      "epoch:42 step:32817 [D loss: 1.540637, acc: 50.78%] [G loss: 5.384176]\n",
      "epoch:42 step:32818 [D loss: 0.405962, acc: 78.91%] [G loss: 5.370674]\n",
      "epoch:42 step:32819 [D loss: 0.435342, acc: 72.66%] [G loss: 8.015145]\n",
      "epoch:42 step:32820 [D loss: 0.427306, acc: 78.12%] [G loss: 9.042578]\n",
      "epoch:42 step:32821 [D loss: 0.249656, acc: 88.28%] [G loss: 8.383295]\n",
      "epoch:42 step:32822 [D loss: 1.308223, acc: 50.00%] [G loss: 1.955598]\n",
      "epoch:42 step:32823 [D loss: 0.151572, acc: 97.66%] [G loss: 8.550938]\n",
      "epoch:42 step:32824 [D loss: 0.383762, acc: 76.56%] [G loss: 8.445020]\n",
      "epoch:42 step:32825 [D loss: 0.144306, acc: 98.44%] [G loss: 6.448152]\n",
      "epoch:42 step:32826 [D loss: 0.812053, acc: 53.91%] [G loss: 5.665106]\n",
      "epoch:42 step:32827 [D loss: 0.291784, acc: 85.16%] [G loss: 4.860650]\n",
      "epoch:42 step:32828 [D loss: 0.507313, acc: 73.44%] [G loss: 4.416467]\n",
      "epoch:42 step:32829 [D loss: 1.337120, acc: 50.00%] [G loss: 4.980156]\n",
      "epoch:42 step:32830 [D loss: 1.080871, acc: 29.69%] [G loss: 7.359687]\n",
      "epoch:42 step:32831 [D loss: 0.207740, acc: 94.53%] [G loss: 6.243867]\n",
      "epoch:42 step:32832 [D loss: 0.025341, acc: 100.00%] [G loss: 8.137850]\n",
      "epoch:42 step:32833 [D loss: 0.119600, acc: 96.88%] [G loss: 9.443939]\n",
      "epoch:42 step:32834 [D loss: 0.525931, acc: 78.12%] [G loss: 10.091591]\n",
      "epoch:42 step:32835 [D loss: 0.975150, acc: 53.12%] [G loss: 9.732225]\n",
      "epoch:42 step:32836 [D loss: 0.152329, acc: 96.88%] [G loss: 3.829383]\n",
      "epoch:42 step:32837 [D loss: 0.573891, acc: 64.84%] [G loss: 3.631740]\n",
      "epoch:42 step:32838 [D loss: 0.100441, acc: 98.44%] [G loss: 5.219191]\n",
      "epoch:42 step:32839 [D loss: 0.359978, acc: 88.28%] [G loss: 9.730236]\n",
      "epoch:42 step:32840 [D loss: 0.067103, acc: 100.00%] [G loss: 6.502365]\n",
      "epoch:42 step:32841 [D loss: 0.457573, acc: 77.34%] [G loss: 10.047253]\n",
      "epoch:42 step:32842 [D loss: 0.599409, acc: 64.84%] [G loss: 6.050701]\n",
      "epoch:42 step:32843 [D loss: 0.554713, acc: 67.97%] [G loss: 5.837595]\n",
      "epoch:42 step:32844 [D loss: 0.153738, acc: 98.44%] [G loss: 4.784042]\n",
      "epoch:42 step:32845 [D loss: 0.285021, acc: 95.31%] [G loss: 3.443741]\n",
      "epoch:42 step:32846 [D loss: 0.369315, acc: 87.50%] [G loss: 4.735322]\n",
      "epoch:42 step:32847 [D loss: 0.167925, acc: 96.09%] [G loss: 8.240473]\n",
      "epoch:42 step:32848 [D loss: 0.126061, acc: 99.22%] [G loss: 6.830814]\n",
      "epoch:42 step:32849 [D loss: 0.064039, acc: 100.00%] [G loss: 7.177517]\n",
      "epoch:42 step:32850 [D loss: 1.407331, acc: 49.22%] [G loss: 9.082544]\n",
      "epoch:42 step:32851 [D loss: 0.482085, acc: 67.19%] [G loss: 5.959338]\n",
      "epoch:42 step:32852 [D loss: 0.376914, acc: 84.38%] [G loss: 6.581980]\n",
      "epoch:42 step:32853 [D loss: 0.135763, acc: 99.22%] [G loss: 4.556804]\n",
      "epoch:42 step:32854 [D loss: 0.356546, acc: 78.12%] [G loss: 8.377715]\n",
      "epoch:42 step:32855 [D loss: 0.259198, acc: 91.41%] [G loss: 5.499421]\n",
      "epoch:42 step:32856 [D loss: 0.015898, acc: 100.00%] [G loss: 6.719080]\n",
      "epoch:42 step:32857 [D loss: 0.385516, acc: 88.28%] [G loss: 7.353576]\n",
      "epoch:42 step:32858 [D loss: 0.077112, acc: 99.22%] [G loss: 7.597698]\n",
      "epoch:42 step:32859 [D loss: 0.158094, acc: 97.66%] [G loss: 4.045565]\n",
      "epoch:42 step:32860 [D loss: 0.159153, acc: 98.44%] [G loss: 5.938295]\n",
      "epoch:42 step:32861 [D loss: 0.104065, acc: 100.00%] [G loss: 6.908068]\n",
      "epoch:42 step:32862 [D loss: 0.233759, acc: 94.53%] [G loss: 5.584860]\n",
      "epoch:42 step:32863 [D loss: 0.137846, acc: 99.22%] [G loss: 6.816976]\n",
      "epoch:42 step:32864 [D loss: 0.081203, acc: 99.22%] [G loss: 7.350146]\n",
      "epoch:42 step:32865 [D loss: 0.222106, acc: 96.88%] [G loss: 8.225658]\n",
      "epoch:42 step:32866 [D loss: 0.065041, acc: 100.00%] [G loss: 3.133155]\n",
      "epoch:42 step:32867 [D loss: 0.533960, acc: 73.44%] [G loss: 2.877354]\n",
      "epoch:42 step:32868 [D loss: 0.226440, acc: 99.22%] [G loss: 7.954461]\n",
      "epoch:42 step:32869 [D loss: 0.450204, acc: 83.59%] [G loss: 4.799836]\n",
      "epoch:42 step:32870 [D loss: 0.289372, acc: 91.41%] [G loss: 3.549757]\n",
      "epoch:42 step:32871 [D loss: 0.182142, acc: 95.31%] [G loss: 5.130937]\n",
      "epoch:42 step:32872 [D loss: 0.608204, acc: 66.41%] [G loss: 8.352718]\n",
      "epoch:42 step:32873 [D loss: 0.645345, acc: 62.50%] [G loss: 5.690882]\n",
      "epoch:42 step:32874 [D loss: 0.071013, acc: 100.00%] [G loss: 6.858445]\n",
      "epoch:42 step:32875 [D loss: 0.314257, acc: 91.41%] [G loss: 7.742510]\n",
      "epoch:42 step:32876 [D loss: 0.166159, acc: 96.88%] [G loss: 6.058603]\n",
      "epoch:42 step:32877 [D loss: 0.110905, acc: 100.00%] [G loss: 5.411897]\n",
      "epoch:42 step:32878 [D loss: 0.516554, acc: 67.97%] [G loss: 5.744487]\n",
      "epoch:42 step:32879 [D loss: 1.058934, acc: 50.00%] [G loss: 6.101395]\n",
      "epoch:42 step:32880 [D loss: 0.105977, acc: 97.66%] [G loss: 2.814628]\n",
      "epoch:42 step:32881 [D loss: 0.060962, acc: 100.00%] [G loss: 6.843375]\n",
      "epoch:42 step:32882 [D loss: 0.174298, acc: 99.22%] [G loss: 4.107841]\n",
      "epoch:42 step:32883 [D loss: 0.204757, acc: 91.41%] [G loss: 3.243637]\n",
      "epoch:42 step:32884 [D loss: 0.488748, acc: 69.53%] [G loss: 5.901822]\n",
      "epoch:42 step:32885 [D loss: 0.122312, acc: 98.44%] [G loss: 5.464962]\n",
      "epoch:42 step:32886 [D loss: 0.096063, acc: 99.22%] [G loss: 6.932314]\n",
      "epoch:42 step:32887 [D loss: 0.547166, acc: 68.75%] [G loss: 5.300811]\n",
      "epoch:42 step:32888 [D loss: 0.518846, acc: 66.41%] [G loss: 10.159445]\n",
      "epoch:42 step:32889 [D loss: 0.632581, acc: 60.16%] [G loss: 7.861459]\n",
      "epoch:42 step:32890 [D loss: 0.559421, acc: 63.28%] [G loss: 4.913203]\n",
      "epoch:42 step:32891 [D loss: 0.009993, acc: 100.00%] [G loss: 7.927586]\n",
      "epoch:42 step:32892 [D loss: 0.043499, acc: 100.00%] [G loss: 7.473557]\n",
      "epoch:42 step:32893 [D loss: 0.044275, acc: 100.00%] [G loss: 6.235938]\n",
      "epoch:42 step:32894 [D loss: 0.098098, acc: 100.00%] [G loss: 7.083836]\n",
      "epoch:42 step:32895 [D loss: 0.673465, acc: 56.25%] [G loss: 5.616710]\n",
      "epoch:42 step:32896 [D loss: 0.173641, acc: 97.66%] [G loss: 3.904388]\n",
      "epoch:42 step:32897 [D loss: 0.554760, acc: 64.06%] [G loss: 8.504089]\n",
      "epoch:42 step:32898 [D loss: 0.113415, acc: 98.44%] [G loss: 5.643368]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:42 step:32899 [D loss: 0.092389, acc: 100.00%] [G loss: 4.873857]\n",
      "epoch:42 step:32900 [D loss: 0.181091, acc: 98.44%] [G loss: 7.166659]\n",
      "epoch:42 step:32901 [D loss: 0.617630, acc: 55.47%] [G loss: 5.829386]\n",
      "epoch:42 step:32902 [D loss: 0.101081, acc: 99.22%] [G loss: 5.812885]\n",
      "epoch:42 step:32903 [D loss: 0.665236, acc: 55.47%] [G loss: 6.886415]\n",
      "epoch:42 step:32904 [D loss: 0.178348, acc: 98.44%] [G loss: 10.380005]\n",
      "epoch:42 step:32905 [D loss: 0.378098, acc: 85.94%] [G loss: 6.055666]\n",
      "epoch:42 step:32906 [D loss: 0.023582, acc: 100.00%] [G loss: 8.849759]\n",
      "epoch:42 step:32907 [D loss: 0.232482, acc: 88.28%] [G loss: 6.730211]\n",
      "epoch:42 step:32908 [D loss: 0.184671, acc: 98.44%] [G loss: 2.557265]\n",
      "epoch:42 step:32909 [D loss: 0.146348, acc: 99.22%] [G loss: 3.995208]\n",
      "epoch:42 step:32910 [D loss: 0.689970, acc: 53.12%] [G loss: 7.776548]\n",
      "epoch:42 step:32911 [D loss: 0.192539, acc: 94.53%] [G loss: 3.971792]\n",
      "epoch:42 step:32912 [D loss: 0.133181, acc: 100.00%] [G loss: 5.606796]\n",
      "epoch:42 step:32913 [D loss: 1.268780, acc: 50.00%] [G loss: 5.184134]\n",
      "epoch:42 step:32914 [D loss: 0.296274, acc: 85.16%] [G loss: 8.878012]\n",
      "epoch:42 step:32915 [D loss: 0.427348, acc: 73.44%] [G loss: 6.203785]\n",
      "epoch:42 step:32916 [D loss: 0.169586, acc: 96.88%] [G loss: 2.502051]\n",
      "epoch:42 step:32917 [D loss: 0.042405, acc: 100.00%] [G loss: 3.660423]\n",
      "epoch:42 step:32918 [D loss: 0.901572, acc: 37.50%] [G loss: 5.138906]\n",
      "epoch:42 step:32919 [D loss: 0.043276, acc: 100.00%] [G loss: 5.085583]\n",
      "epoch:42 step:32920 [D loss: 0.100931, acc: 100.00%] [G loss: 4.181970]\n",
      "epoch:42 step:32921 [D loss: 0.234775, acc: 94.53%] [G loss: 3.795611]\n",
      "epoch:42 step:32922 [D loss: 0.069321, acc: 100.00%] [G loss: 8.053633]\n",
      "epoch:42 step:32923 [D loss: 0.104841, acc: 100.00%] [G loss: 7.812081]\n",
      "epoch:42 step:32924 [D loss: 0.170177, acc: 96.09%] [G loss: 4.968763]\n",
      "epoch:42 step:32925 [D loss: 0.227803, acc: 92.97%] [G loss: 9.725193]\n",
      "epoch:42 step:32926 [D loss: 0.207988, acc: 97.66%] [G loss: 8.462555]\n",
      "epoch:42 step:32927 [D loss: 0.200947, acc: 96.09%] [G loss: 4.165337]\n",
      "epoch:42 step:32928 [D loss: 0.384837, acc: 81.25%] [G loss: 4.561353]\n",
      "epoch:42 step:32929 [D loss: 0.335592, acc: 89.84%] [G loss: 5.498435]\n",
      "epoch:42 step:32930 [D loss: 1.666949, acc: 50.00%] [G loss: 7.689178]\n",
      "epoch:42 step:32931 [D loss: 0.365565, acc: 78.91%] [G loss: 7.887901]\n",
      "epoch:42 step:32932 [D loss: 0.357722, acc: 79.69%] [G loss: 12.021727]\n",
      "epoch:42 step:32933 [D loss: 0.569610, acc: 71.09%] [G loss: 4.759522]\n",
      "epoch:42 step:32934 [D loss: 1.110072, acc: 22.66%] [G loss: 10.831347]\n",
      "epoch:42 step:32935 [D loss: 0.060101, acc: 100.00%] [G loss: 10.145899]\n",
      "epoch:42 step:32936 [D loss: 0.118150, acc: 100.00%] [G loss: 7.129662]\n",
      "epoch:42 step:32937 [D loss: 0.013571, acc: 100.00%] [G loss: 5.913173]\n",
      "epoch:42 step:32938 [D loss: 0.296989, acc: 95.31%] [G loss: 8.628887]\n",
      "epoch:42 step:32939 [D loss: 0.082364, acc: 100.00%] [G loss: 9.541689]\n",
      "epoch:42 step:32940 [D loss: 0.796396, acc: 56.25%] [G loss: 6.595997]\n",
      "epoch:42 step:32941 [D loss: 0.930940, acc: 52.34%] [G loss: 5.686993]\n",
      "epoch:42 step:32942 [D loss: 0.714687, acc: 55.47%] [G loss: 5.312937]\n",
      "epoch:42 step:32943 [D loss: 1.130732, acc: 37.50%] [G loss: 7.249029]\n",
      "epoch:42 step:32944 [D loss: 0.374285, acc: 78.91%] [G loss: 6.726185]\n",
      "epoch:42 step:32945 [D loss: 0.297991, acc: 92.97%] [G loss: 6.431983]\n",
      "epoch:42 step:32946 [D loss: 0.535386, acc: 64.06%] [G loss: 6.684436]\n",
      "epoch:42 step:32947 [D loss: 1.050154, acc: 50.78%] [G loss: 6.873498]\n",
      "epoch:42 step:32948 [D loss: 0.100098, acc: 98.44%] [G loss: 5.096686]\n",
      "epoch:42 step:32949 [D loss: 0.057304, acc: 100.00%] [G loss: 5.394214]\n",
      "epoch:42 step:32950 [D loss: 1.165246, acc: 44.53%] [G loss: 8.327950]\n",
      "epoch:42 step:32951 [D loss: 0.270416, acc: 90.62%] [G loss: 5.655014]\n",
      "epoch:42 step:32952 [D loss: 0.869825, acc: 53.91%] [G loss: 3.014908]\n",
      "epoch:42 step:32953 [D loss: 0.151089, acc: 98.44%] [G loss: 4.259780]\n",
      "epoch:42 step:32954 [D loss: 0.039179, acc: 100.00%] [G loss: 6.697566]\n",
      "epoch:42 step:32955 [D loss: 0.120095, acc: 100.00%] [G loss: 5.245140]\n",
      "epoch:42 step:32956 [D loss: 0.110159, acc: 98.44%] [G loss: 6.408635]\n",
      "epoch:42 step:32957 [D loss: 0.080607, acc: 100.00%] [G loss: 6.303406]\n",
      "epoch:42 step:32958 [D loss: 0.714979, acc: 57.03%] [G loss: 10.389627]\n",
      "epoch:42 step:32959 [D loss: 0.119651, acc: 97.66%] [G loss: 7.023225]\n",
      "epoch:42 step:32960 [D loss: 0.090236, acc: 99.22%] [G loss: 5.653385]\n",
      "epoch:42 step:32961 [D loss: 0.172246, acc: 96.88%] [G loss: 3.989140]\n",
      "epoch:42 step:32962 [D loss: 0.193826, acc: 99.22%] [G loss: 4.243310]\n",
      "epoch:42 step:32963 [D loss: 0.104120, acc: 99.22%] [G loss: 8.691017]\n",
      "epoch:42 step:32964 [D loss: 0.107173, acc: 98.44%] [G loss: 7.173104]\n",
      "epoch:42 step:32965 [D loss: 0.144175, acc: 98.44%] [G loss: 5.300647]\n",
      "epoch:42 step:32966 [D loss: 0.353557, acc: 90.62%] [G loss: 4.536511]\n",
      "epoch:42 step:32967 [D loss: 0.110672, acc: 100.00%] [G loss: 4.533277]\n",
      "epoch:42 step:32968 [D loss: 0.561502, acc: 71.09%] [G loss: 6.859447]\n",
      "epoch:42 step:32969 [D loss: 0.780214, acc: 53.91%] [G loss: 5.824515]\n",
      "epoch:42 step:32970 [D loss: 0.098033, acc: 99.22%] [G loss: 8.183928]\n",
      "epoch:42 step:32971 [D loss: 0.158026, acc: 96.88%] [G loss: 10.201677]\n",
      "epoch:42 step:32972 [D loss: 0.299479, acc: 82.81%] [G loss: 7.614155]\n",
      "epoch:42 step:32973 [D loss: 0.216363, acc: 97.66%] [G loss: 5.511008]\n",
      "epoch:42 step:32974 [D loss: 0.097507, acc: 99.22%] [G loss: 4.854085]\n",
      "epoch:42 step:32975 [D loss: 0.101930, acc: 100.00%] [G loss: 3.654375]\n",
      "epoch:42 step:32976 [D loss: 0.153473, acc: 98.44%] [G loss: 5.767207]\n",
      "epoch:42 step:32977 [D loss: 0.820235, acc: 50.00%] [G loss: 8.533097]\n",
      "epoch:42 step:32978 [D loss: 0.834692, acc: 53.12%] [G loss: 7.207712]\n",
      "epoch:42 step:32979 [D loss: 0.116948, acc: 100.00%] [G loss: 6.416188]\n",
      "epoch:42 step:32980 [D loss: 0.436047, acc: 75.78%] [G loss: 8.155633]\n",
      "epoch:42 step:32981 [D loss: 0.344799, acc: 81.25%] [G loss: 2.746939]\n",
      "epoch:42 step:32982 [D loss: 0.571275, acc: 62.50%] [G loss: 7.368018]\n",
      "epoch:42 step:32983 [D loss: 0.148276, acc: 99.22%] [G loss: 4.833372]\n",
      "epoch:42 step:32984 [D loss: 0.291884, acc: 96.09%] [G loss: 4.318624]\n",
      "epoch:42 step:32985 [D loss: 0.371723, acc: 87.50%] [G loss: 7.500648]\n",
      "epoch:42 step:32986 [D loss: 0.029918, acc: 100.00%] [G loss: 5.971418]\n",
      "epoch:42 step:32987 [D loss: 0.055412, acc: 100.00%] [G loss: 4.326995]\n",
      "epoch:42 step:32988 [D loss: 0.656394, acc: 62.50%] [G loss: 4.169972]\n",
      "epoch:42 step:32989 [D loss: 0.533960, acc: 66.41%] [G loss: 6.187986]\n",
      "epoch:42 step:32990 [D loss: 0.028037, acc: 100.00%] [G loss: 4.214670]\n",
      "epoch:42 step:32991 [D loss: 0.052637, acc: 100.00%] [G loss: 11.312362]\n",
      "epoch:42 step:32992 [D loss: 0.867822, acc: 50.00%] [G loss: 7.948630]\n",
      "epoch:42 step:32993 [D loss: 0.326143, acc: 91.41%] [G loss: 6.212478]\n",
      "epoch:42 step:32994 [D loss: 0.200025, acc: 94.53%] [G loss: 4.485440]\n",
      "epoch:42 step:32995 [D loss: 0.012778, acc: 100.00%] [G loss: 3.093977]\n",
      "epoch:42 step:32996 [D loss: 0.042072, acc: 100.00%] [G loss: 4.836245]\n",
      "epoch:42 step:32997 [D loss: 1.228794, acc: 42.97%] [G loss: 6.990504]\n",
      "epoch:42 step:32998 [D loss: 0.294880, acc: 85.16%] [G loss: 5.817011]\n",
      "epoch:42 step:32999 [D loss: 0.077552, acc: 99.22%] [G loss: 5.799086]\n",
      "epoch:42 step:33000 [D loss: 0.022942, acc: 100.00%] [G loss: 7.116856]\n",
      "##############\n",
      "[0.85099492 0.8665522  0.82726715 0.81924324 0.78392874 0.81275984\n",
      " 0.86967353 0.82090962 0.80071935 0.84549616]\n",
      "##########\n",
      "epoch:42 step:33001 [D loss: 0.085239, acc: 99.22%] [G loss: 7.784715]\n",
      "epoch:42 step:33002 [D loss: 0.141206, acc: 99.22%] [G loss: 3.194527]\n",
      "epoch:42 step:33003 [D loss: 0.008082, acc: 100.00%] [G loss: 5.567662]\n",
      "epoch:42 step:33004 [D loss: 0.476929, acc: 71.09%] [G loss: 9.018286]\n",
      "epoch:42 step:33005 [D loss: 0.224504, acc: 95.31%] [G loss: 5.589468]\n",
      "epoch:42 step:33006 [D loss: 0.055792, acc: 100.00%] [G loss: 6.235362]\n",
      "epoch:42 step:33007 [D loss: 0.065426, acc: 98.44%] [G loss: 6.671164]\n",
      "epoch:42 step:33008 [D loss: 0.322931, acc: 92.97%] [G loss: 7.311504]\n",
      "epoch:42 step:33009 [D loss: 0.112514, acc: 99.22%] [G loss: 5.222111]\n",
      "epoch:42 step:33010 [D loss: 0.099548, acc: 100.00%] [G loss: 4.941749]\n",
      "epoch:42 step:33011 [D loss: 0.117788, acc: 100.00%] [G loss: 2.855919]\n",
      "epoch:42 step:33012 [D loss: 0.365819, acc: 80.47%] [G loss: 5.419485]\n",
      "epoch:42 step:33013 [D loss: 0.315009, acc: 88.28%] [G loss: 4.801784]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:42 step:33014 [D loss: 0.022670, acc: 100.00%] [G loss: 2.818126]\n",
      "epoch:42 step:33015 [D loss: 0.202999, acc: 97.66%] [G loss: 6.896759]\n",
      "epoch:42 step:33016 [D loss: 0.829463, acc: 47.66%] [G loss: 5.248883]\n",
      "epoch:42 step:33017 [D loss: 0.226509, acc: 95.31%] [G loss: 8.172176]\n",
      "epoch:42 step:33018 [D loss: 0.033965, acc: 100.00%] [G loss: 3.304943]\n",
      "epoch:42 step:33019 [D loss: 0.063459, acc: 99.22%] [G loss: 6.075848]\n",
      "epoch:42 step:33020 [D loss: 0.338872, acc: 82.81%] [G loss: 7.433745]\n",
      "epoch:42 step:33021 [D loss: 0.111913, acc: 99.22%] [G loss: 4.830390]\n",
      "epoch:42 step:33022 [D loss: 0.058330, acc: 99.22%] [G loss: 6.986749]\n",
      "epoch:42 step:33023 [D loss: 0.471672, acc: 69.53%] [G loss: 6.700585]\n",
      "epoch:42 step:33024 [D loss: 0.025229, acc: 100.00%] [G loss: 4.251304]\n",
      "epoch:42 step:33025 [D loss: 1.050072, acc: 50.00%] [G loss: 9.391319]\n",
      "epoch:42 step:33026 [D loss: 0.154250, acc: 99.22%] [G loss: 9.381351]\n",
      "epoch:42 step:33027 [D loss: 0.337673, acc: 88.28%] [G loss: 5.152717]\n",
      "epoch:42 step:33028 [D loss: 0.165220, acc: 98.44%] [G loss: 7.112770]\n",
      "epoch:42 step:33029 [D loss: 0.235747, acc: 90.62%] [G loss: 6.568801]\n",
      "epoch:42 step:33030 [D loss: 0.254298, acc: 89.84%] [G loss: 7.320892]\n",
      "epoch:42 step:33031 [D loss: 0.359914, acc: 86.72%] [G loss: 3.335149]\n",
      "epoch:42 step:33032 [D loss: 0.370538, acc: 75.78%] [G loss: 3.937542]\n",
      "epoch:42 step:33033 [D loss: 0.029021, acc: 100.00%] [G loss: 6.291943]\n",
      "epoch:42 step:33034 [D loss: 0.276022, acc: 96.09%] [G loss: 6.048077]\n",
      "epoch:42 step:33035 [D loss: 0.030567, acc: 100.00%] [G loss: 6.319825]\n",
      "epoch:42 step:33036 [D loss: 0.055687, acc: 100.00%] [G loss: 5.978126]\n",
      "epoch:42 step:33037 [D loss: 0.249726, acc: 96.88%] [G loss: 5.406589]\n",
      "epoch:42 step:33038 [D loss: 0.120180, acc: 99.22%] [G loss: 8.236379]\n",
      "epoch:42 step:33039 [D loss: 0.046018, acc: 100.00%] [G loss: 6.249715]\n",
      "epoch:42 step:33040 [D loss: 0.254514, acc: 95.31%] [G loss: 3.553847]\n",
      "epoch:42 step:33041 [D loss: 0.172639, acc: 97.66%] [G loss: 5.666679]\n",
      "epoch:42 step:33042 [D loss: 0.317065, acc: 92.19%] [G loss: 5.338465]\n",
      "epoch:42 step:33043 [D loss: 0.612525, acc: 62.50%] [G loss: 9.438967]\n",
      "epoch:42 step:33044 [D loss: 0.541403, acc: 61.72%] [G loss: 8.926931]\n",
      "epoch:42 step:33045 [D loss: 0.032062, acc: 100.00%] [G loss: 4.094614]\n",
      "epoch:42 step:33046 [D loss: 0.167704, acc: 98.44%] [G loss: 6.179590]\n",
      "epoch:42 step:33047 [D loss: 0.598677, acc: 62.50%] [G loss: 9.583817]\n",
      "epoch:42 step:33048 [D loss: 0.591268, acc: 66.41%] [G loss: 5.217371]\n",
      "epoch:42 step:33049 [D loss: 0.480867, acc: 68.75%] [G loss: 6.469542]\n",
      "epoch:42 step:33050 [D loss: 0.183889, acc: 98.44%] [G loss: 6.121069]\n",
      "epoch:42 step:33051 [D loss: 0.047328, acc: 100.00%] [G loss: 9.242888]\n",
      "epoch:42 step:33052 [D loss: 0.166578, acc: 99.22%] [G loss: 2.609593]\n",
      "epoch:42 step:33053 [D loss: 0.165669, acc: 96.88%] [G loss: 5.411185]\n",
      "epoch:42 step:33054 [D loss: 0.041806, acc: 100.00%] [G loss: 5.541766]\n",
      "epoch:42 step:33055 [D loss: 0.477856, acc: 76.56%] [G loss: 4.847791]\n",
      "epoch:42 step:33056 [D loss: 0.118899, acc: 99.22%] [G loss: 3.242712]\n",
      "epoch:42 step:33057 [D loss: 0.210493, acc: 92.19%] [G loss: 8.576029]\n",
      "epoch:42 step:33058 [D loss: 0.072312, acc: 100.00%] [G loss: 8.390362]\n",
      "epoch:42 step:33059 [D loss: 0.202588, acc: 99.22%] [G loss: 4.034842]\n",
      "epoch:42 step:33060 [D loss: 0.145046, acc: 96.88%] [G loss: 6.280823]\n",
      "epoch:42 step:33061 [D loss: 0.451317, acc: 74.22%] [G loss: 3.419377]\n",
      "epoch:42 step:33062 [D loss: 0.820316, acc: 50.00%] [G loss: 6.844047]\n",
      "epoch:42 step:33063 [D loss: 0.465380, acc: 80.47%] [G loss: 6.432059]\n",
      "epoch:42 step:33064 [D loss: 0.008003, acc: 100.00%] [G loss: 9.724531]\n",
      "epoch:42 step:33065 [D loss: 0.130322, acc: 100.00%] [G loss: 2.284185]\n",
      "epoch:42 step:33066 [D loss: 0.037042, acc: 100.00%] [G loss: 6.058250]\n",
      "epoch:42 step:33067 [D loss: 0.300722, acc: 93.75%] [G loss: 2.210599]\n",
      "epoch:42 step:33068 [D loss: 0.284152, acc: 85.94%] [G loss: 7.195123]\n",
      "epoch:42 step:33069 [D loss: 0.179272, acc: 97.66%] [G loss: 3.618246]\n",
      "epoch:42 step:33070 [D loss: 0.482902, acc: 66.41%] [G loss: 4.122345]\n",
      "epoch:42 step:33071 [D loss: 0.375019, acc: 83.59%] [G loss: 4.722437]\n",
      "epoch:42 step:33072 [D loss: 0.297981, acc: 84.38%] [G loss: 8.799937]\n",
      "epoch:42 step:33073 [D loss: 0.255192, acc: 90.62%] [G loss: 5.142120]\n",
      "epoch:42 step:33074 [D loss: 0.035736, acc: 100.00%] [G loss: 4.282425]\n",
      "epoch:42 step:33075 [D loss: 0.283356, acc: 83.59%] [G loss: 5.722412]\n",
      "epoch:42 step:33076 [D loss: 0.692755, acc: 57.03%] [G loss: 8.673315]\n",
      "epoch:42 step:33077 [D loss: 0.473389, acc: 67.19%] [G loss: 6.411651]\n",
      "epoch:42 step:33078 [D loss: 0.119460, acc: 100.00%] [G loss: 3.711844]\n",
      "epoch:42 step:33079 [D loss: 0.075965, acc: 99.22%] [G loss: 8.363609]\n",
      "epoch:42 step:33080 [D loss: 0.080195, acc: 100.00%] [G loss: 6.899507]\n",
      "epoch:42 step:33081 [D loss: 0.026391, acc: 100.00%] [G loss: 4.849575]\n",
      "epoch:42 step:33082 [D loss: 0.838642, acc: 52.34%] [G loss: 5.102269]\n",
      "epoch:42 step:33083 [D loss: 0.226538, acc: 93.75%] [G loss: 5.720293]\n",
      "epoch:42 step:33084 [D loss: 0.319542, acc: 85.94%] [G loss: 8.362772]\n",
      "epoch:42 step:33085 [D loss: 0.166142, acc: 98.44%] [G loss: 5.311223]\n",
      "epoch:42 step:33086 [D loss: 0.952419, acc: 50.78%] [G loss: 4.001882]\n",
      "epoch:42 step:33087 [D loss: 0.051887, acc: 100.00%] [G loss: 4.405277]\n",
      "epoch:42 step:33088 [D loss: 0.439984, acc: 70.31%] [G loss: 7.108824]\n",
      "epoch:42 step:33089 [D loss: 0.003877, acc: 100.00%] [G loss: 3.050011]\n",
      "epoch:42 step:33090 [D loss: 0.892757, acc: 50.00%] [G loss: 5.531055]\n",
      "epoch:42 step:33091 [D loss: 0.107996, acc: 97.66%] [G loss: 5.520151]\n",
      "epoch:42 step:33092 [D loss: 0.393389, acc: 79.69%] [G loss: 6.518472]\n",
      "epoch:42 step:33093 [D loss: 1.050175, acc: 50.00%] [G loss: 8.666755]\n",
      "epoch:42 step:33094 [D loss: 0.565522, acc: 63.28%] [G loss: 6.746922]\n",
      "epoch:42 step:33095 [D loss: 0.027122, acc: 100.00%] [G loss: 5.961936]\n",
      "epoch:42 step:33096 [D loss: 0.101043, acc: 98.44%] [G loss: 8.565590]\n",
      "epoch:42 step:33097 [D loss: 0.074144, acc: 100.00%] [G loss: 7.116901]\n",
      "epoch:42 step:33098 [D loss: 0.021277, acc: 100.00%] [G loss: 6.408017]\n",
      "epoch:42 step:33099 [D loss: 0.084347, acc: 100.00%] [G loss: 6.211571]\n",
      "epoch:42 step:33100 [D loss: 0.604527, acc: 66.41%] [G loss: 7.572174]\n",
      "epoch:42 step:33101 [D loss: 0.286301, acc: 93.75%] [G loss: 6.527695]\n",
      "epoch:42 step:33102 [D loss: 0.182834, acc: 95.31%] [G loss: 7.612835]\n",
      "epoch:42 step:33103 [D loss: 0.216138, acc: 98.44%] [G loss: 5.250241]\n",
      "epoch:42 step:33104 [D loss: 0.070326, acc: 100.00%] [G loss: 4.072988]\n",
      "epoch:42 step:33105 [D loss: 0.440080, acc: 71.88%] [G loss: 6.793437]\n",
      "epoch:42 step:33106 [D loss: 0.085806, acc: 99.22%] [G loss: 4.950288]\n",
      "epoch:42 step:33107 [D loss: 0.037745, acc: 100.00%] [G loss: 8.943489]\n",
      "epoch:42 step:33108 [D loss: 0.236933, acc: 91.41%] [G loss: 7.651254]\n",
      "epoch:42 step:33109 [D loss: 0.595567, acc: 60.94%] [G loss: 6.496221]\n",
      "epoch:42 step:33110 [D loss: 0.097876, acc: 99.22%] [G loss: 5.879822]\n",
      "epoch:42 step:33111 [D loss: 1.189021, acc: 50.00%] [G loss: 7.674351]\n",
      "epoch:42 step:33112 [D loss: 0.178256, acc: 94.53%] [G loss: 6.059965]\n",
      "epoch:42 step:33113 [D loss: 0.282712, acc: 92.97%] [G loss: 7.354747]\n",
      "epoch:42 step:33114 [D loss: 0.284945, acc: 92.19%] [G loss: 8.155180]\n",
      "epoch:42 step:33115 [D loss: 0.015269, acc: 100.00%] [G loss: 4.634744]\n",
      "epoch:42 step:33116 [D loss: 0.240495, acc: 95.31%] [G loss: 4.174284]\n",
      "epoch:42 step:33117 [D loss: 0.092141, acc: 99.22%] [G loss: 3.113385]\n",
      "epoch:42 step:33118 [D loss: 0.153693, acc: 98.44%] [G loss: 6.663205]\n",
      "epoch:42 step:33119 [D loss: 0.317033, acc: 90.62%] [G loss: 5.578642]\n",
      "epoch:42 step:33120 [D loss: 0.575903, acc: 64.06%] [G loss: 7.840892]\n",
      "epoch:42 step:33121 [D loss: 0.029253, acc: 100.00%] [G loss: 7.003276]\n",
      "epoch:42 step:33122 [D loss: 0.194273, acc: 98.44%] [G loss: 5.057995]\n",
      "epoch:42 step:33123 [D loss: 0.351005, acc: 79.69%] [G loss: 4.993706]\n",
      "epoch:42 step:33124 [D loss: 0.068980, acc: 100.00%] [G loss: 3.432793]\n",
      "epoch:42 step:33125 [D loss: 0.284787, acc: 90.62%] [G loss: 4.314487]\n",
      "epoch:42 step:33126 [D loss: 0.042336, acc: 100.00%] [G loss: 4.940933]\n",
      "epoch:42 step:33127 [D loss: 1.025179, acc: 52.34%] [G loss: 6.648748]\n",
      "epoch:42 step:33128 [D loss: 0.153282, acc: 96.88%] [G loss: 9.553800]\n",
      "epoch:42 step:33129 [D loss: 1.021131, acc: 47.66%] [G loss: 4.888161]\n",
      "epoch:42 step:33130 [D loss: 1.109461, acc: 46.88%] [G loss: 3.708701]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:42 step:33131 [D loss: 0.092174, acc: 99.22%] [G loss: 4.004212]\n",
      "epoch:42 step:33132 [D loss: 0.154499, acc: 98.44%] [G loss: 4.580041]\n",
      "epoch:42 step:33133 [D loss: 0.177767, acc: 96.09%] [G loss: 5.055990]\n",
      "epoch:42 step:33134 [D loss: 0.670633, acc: 62.50%] [G loss: 7.225563]\n",
      "epoch:42 step:33135 [D loss: 0.286125, acc: 85.16%] [G loss: 8.967890]\n",
      "epoch:42 step:33136 [D loss: 0.282315, acc: 85.16%] [G loss: 5.489486]\n",
      "epoch:42 step:33137 [D loss: 0.166352, acc: 96.09%] [G loss: 9.677153]\n",
      "epoch:42 step:33138 [D loss: 0.057225, acc: 100.00%] [G loss: 4.997343]\n",
      "epoch:42 step:33139 [D loss: 0.170024, acc: 97.66%] [G loss: 3.488271]\n",
      "epoch:42 step:33140 [D loss: 0.068122, acc: 100.00%] [G loss: 9.118708]\n",
      "epoch:42 step:33141 [D loss: 0.036854, acc: 100.00%] [G loss: 10.629668]\n",
      "epoch:42 step:33142 [D loss: 0.046256, acc: 100.00%] [G loss: 6.770094]\n",
      "epoch:42 step:33143 [D loss: 0.156365, acc: 99.22%] [G loss: 3.828722]\n",
      "epoch:42 step:33144 [D loss: 0.042123, acc: 100.00%] [G loss: 5.307456]\n",
      "epoch:42 step:33145 [D loss: 0.614336, acc: 60.94%] [G loss: 7.357606]\n",
      "epoch:42 step:33146 [D loss: 0.135654, acc: 98.44%] [G loss: 8.811592]\n",
      "epoch:42 step:33147 [D loss: 0.081141, acc: 100.00%] [G loss: 7.282641]\n",
      "epoch:42 step:33148 [D loss: 0.228694, acc: 97.66%] [G loss: 6.760354]\n",
      "epoch:42 step:33149 [D loss: 0.109440, acc: 100.00%] [G loss: 6.237123]\n",
      "epoch:42 step:33150 [D loss: 0.216530, acc: 97.66%] [G loss: 8.683652]\n",
      "epoch:42 step:33151 [D loss: 0.814294, acc: 53.91%] [G loss: 10.193031]\n",
      "epoch:42 step:33152 [D loss: 0.624067, acc: 60.94%] [G loss: 2.096717]\n",
      "epoch:42 step:33153 [D loss: 0.962561, acc: 50.78%] [G loss: 4.670489]\n",
      "epoch:42 step:33154 [D loss: 0.201551, acc: 93.75%] [G loss: 6.087903]\n",
      "epoch:42 step:33155 [D loss: 0.814216, acc: 49.22%] [G loss: 5.565960]\n",
      "epoch:42 step:33156 [D loss: 0.037106, acc: 100.00%] [G loss: 5.543834]\n",
      "epoch:42 step:33157 [D loss: 1.237958, acc: 19.53%] [G loss: 7.730273]\n",
      "epoch:42 step:33158 [D loss: 0.149105, acc: 99.22%] [G loss: 3.288142]\n",
      "epoch:42 step:33159 [D loss: 0.609049, acc: 66.41%] [G loss: 5.426872]\n",
      "epoch:42 step:33160 [D loss: 0.112103, acc: 99.22%] [G loss: 5.735523]\n",
      "epoch:42 step:33161 [D loss: 0.574851, acc: 62.50%] [G loss: 5.628203]\n",
      "epoch:42 step:33162 [D loss: 0.217941, acc: 93.75%] [G loss: 6.861765]\n",
      "epoch:42 step:33163 [D loss: 0.708955, acc: 57.03%] [G loss: 12.449027]\n",
      "epoch:42 step:33164 [D loss: 0.453519, acc: 75.00%] [G loss: 4.589343]\n",
      "epoch:42 step:33165 [D loss: 0.273141, acc: 92.19%] [G loss: 7.822859]\n",
      "epoch:42 step:33166 [D loss: 0.085917, acc: 99.22%] [G loss: 7.132826]\n",
      "epoch:42 step:33167 [D loss: 0.195571, acc: 93.75%] [G loss: 3.924436]\n",
      "epoch:42 step:33168 [D loss: 0.463196, acc: 67.19%] [G loss: 6.622968]\n",
      "epoch:42 step:33169 [D loss: 0.048784, acc: 100.00%] [G loss: 7.606878]\n",
      "epoch:42 step:33170 [D loss: 0.223404, acc: 93.75%] [G loss: 5.874676]\n",
      "epoch:42 step:33171 [D loss: 0.724952, acc: 58.59%] [G loss: 3.947250]\n",
      "epoch:42 step:33172 [D loss: 0.535132, acc: 62.50%] [G loss: 6.628487]\n",
      "epoch:42 step:33173 [D loss: 0.680826, acc: 63.28%] [G loss: 5.161180]\n",
      "epoch:42 step:33174 [D loss: 0.077526, acc: 100.00%] [G loss: 3.194780]\n",
      "epoch:42 step:33175 [D loss: 0.122728, acc: 99.22%] [G loss: 3.004069]\n",
      "epoch:42 step:33176 [D loss: 0.028409, acc: 100.00%] [G loss: 1.376273]\n",
      "epoch:42 step:33177 [D loss: 1.688123, acc: 45.31%] [G loss: 4.814922]\n",
      "epoch:42 step:33178 [D loss: 0.094289, acc: 99.22%] [G loss: 5.823727]\n",
      "epoch:42 step:33179 [D loss: 1.313408, acc: 50.00%] [G loss: 7.613643]\n",
      "epoch:42 step:33180 [D loss: 0.535417, acc: 71.88%] [G loss: 7.320806]\n",
      "epoch:42 step:33181 [D loss: 0.119045, acc: 98.44%] [G loss: 7.558873]\n",
      "epoch:42 step:33182 [D loss: 0.294270, acc: 83.59%] [G loss: 4.948545]\n",
      "epoch:42 step:33183 [D loss: 0.156226, acc: 97.66%] [G loss: 5.788942]\n",
      "epoch:42 step:33184 [D loss: 0.140697, acc: 97.66%] [G loss: 7.303286]\n",
      "epoch:42 step:33185 [D loss: 0.101562, acc: 99.22%] [G loss: 10.049740]\n",
      "epoch:42 step:33186 [D loss: 0.265736, acc: 94.53%] [G loss: 3.849519]\n",
      "epoch:42 step:33187 [D loss: 0.254813, acc: 92.97%] [G loss: 6.082913]\n",
      "epoch:42 step:33188 [D loss: 0.299120, acc: 91.41%] [G loss: 7.718231]\n",
      "epoch:42 step:33189 [D loss: 1.016553, acc: 50.78%] [G loss: 8.056257]\n",
      "epoch:42 step:33190 [D loss: 0.740153, acc: 53.91%] [G loss: 6.133649]\n",
      "epoch:42 step:33191 [D loss: 0.141420, acc: 97.66%] [G loss: 6.097316]\n",
      "epoch:42 step:33192 [D loss: 0.470580, acc: 70.31%] [G loss: 6.320198]\n",
      "epoch:42 step:33193 [D loss: 0.157718, acc: 99.22%] [G loss: 6.373193]\n",
      "epoch:42 step:33194 [D loss: 0.521762, acc: 62.50%] [G loss: 7.889393]\n",
      "epoch:42 step:33195 [D loss: 0.040310, acc: 99.22%] [G loss: 3.464082]\n",
      "epoch:42 step:33196 [D loss: 0.032434, acc: 100.00%] [G loss: 7.832076]\n",
      "epoch:42 step:33197 [D loss: 0.359903, acc: 85.94%] [G loss: 4.288276]\n",
      "epoch:42 step:33198 [D loss: 0.085849, acc: 100.00%] [G loss: 3.635298]\n",
      "epoch:42 step:33199 [D loss: 0.018019, acc: 100.00%] [G loss: 8.073137]\n",
      "epoch:42 step:33200 [D loss: 0.664443, acc: 66.41%] [G loss: 5.892970]\n",
      "##############\n",
      "[0.86614168 0.87353215 0.82457603 0.80117538 0.79012245 0.81991797\n",
      " 0.86970888 0.80864758 0.81558557 0.83274558]\n",
      "##########\n",
      "epoch:42 step:33201 [D loss: 0.309355, acc: 85.94%] [G loss: 5.980659]\n",
      "epoch:42 step:33202 [D loss: 0.102971, acc: 100.00%] [G loss: 6.081487]\n",
      "epoch:42 step:33203 [D loss: 0.054433, acc: 100.00%] [G loss: 10.287941]\n",
      "epoch:42 step:33204 [D loss: 0.016305, acc: 100.00%] [G loss: 6.357501]\n",
      "epoch:42 step:33205 [D loss: 0.485410, acc: 73.44%] [G loss: 8.303698]\n",
      "epoch:42 step:33206 [D loss: 0.079839, acc: 100.00%] [G loss: 5.098431]\n",
      "epoch:42 step:33207 [D loss: 0.235480, acc: 94.53%] [G loss: 6.521275]\n",
      "epoch:42 step:33208 [D loss: 0.091694, acc: 98.44%] [G loss: 9.720930]\n",
      "epoch:42 step:33209 [D loss: 0.094954, acc: 100.00%] [G loss: 6.229878]\n",
      "epoch:42 step:33210 [D loss: 0.114616, acc: 98.44%] [G loss: 3.082462]\n",
      "epoch:42 step:33211 [D loss: 0.107121, acc: 99.22%] [G loss: 7.840061]\n",
      "epoch:42 step:33212 [D loss: 0.165711, acc: 97.66%] [G loss: 5.090289]\n",
      "epoch:42 step:33213 [D loss: 0.618814, acc: 61.72%] [G loss: 8.908206]\n",
      "epoch:42 step:33214 [D loss: 0.189855, acc: 97.66%] [G loss: 4.230565]\n",
      "epoch:42 step:33215 [D loss: 0.053618, acc: 99.22%] [G loss: 3.600625]\n",
      "epoch:42 step:33216 [D loss: 1.323839, acc: 50.00%] [G loss: 3.500049]\n",
      "epoch:42 step:33217 [D loss: 0.751546, acc: 54.69%] [G loss: 9.895218]\n",
      "epoch:42 step:33218 [D loss: 0.535827, acc: 75.78%] [G loss: 6.973127]\n",
      "epoch:42 step:33219 [D loss: 1.125340, acc: 46.88%] [G loss: 7.766913]\n",
      "epoch:42 step:33220 [D loss: 0.059671, acc: 99.22%] [G loss: 5.325424]\n",
      "epoch:42 step:33221 [D loss: 0.047154, acc: 100.00%] [G loss: 4.417894]\n",
      "epoch:42 step:33222 [D loss: 0.083777, acc: 100.00%] [G loss: 6.244358]\n",
      "epoch:42 step:33223 [D loss: 0.342037, acc: 78.91%] [G loss: 9.479946]\n",
      "epoch:42 step:33224 [D loss: 0.066790, acc: 100.00%] [G loss: 10.925803]\n",
      "epoch:42 step:33225 [D loss: 0.377999, acc: 81.25%] [G loss: 6.957031]\n",
      "epoch:42 step:33226 [D loss: 0.149572, acc: 97.66%] [G loss: 6.322142]\n",
      "epoch:42 step:33227 [D loss: 0.624109, acc: 60.16%] [G loss: 5.045053]\n",
      "epoch:42 step:33228 [D loss: 0.062794, acc: 100.00%] [G loss: 9.029609]\n",
      "epoch:42 step:33229 [D loss: 0.880013, acc: 53.12%] [G loss: 7.836803]\n",
      "epoch:42 step:33230 [D loss: 0.204944, acc: 95.31%] [G loss: 6.263200]\n",
      "epoch:42 step:33231 [D loss: 0.487401, acc: 72.66%] [G loss: 8.066439]\n",
      "epoch:42 step:33232 [D loss: 0.770169, acc: 53.91%] [G loss: 7.789310]\n",
      "epoch:42 step:33233 [D loss: 0.663395, acc: 56.25%] [G loss: 4.832208]\n",
      "epoch:42 step:33234 [D loss: 0.396339, acc: 79.69%] [G loss: 7.377804]\n",
      "epoch:42 step:33235 [D loss: 0.920733, acc: 37.50%] [G loss: 6.466121]\n",
      "epoch:42 step:33236 [D loss: 0.070562, acc: 100.00%] [G loss: 7.784940]\n",
      "epoch:42 step:33237 [D loss: 0.013626, acc: 100.00%] [G loss: 5.004102]\n",
      "epoch:42 step:33238 [D loss: 0.544964, acc: 77.34%] [G loss: 4.860600]\n",
      "epoch:42 step:33239 [D loss: 0.583198, acc: 64.84%] [G loss: 5.062096]\n",
      "epoch:42 step:33240 [D loss: 0.640496, acc: 59.38%] [G loss: 4.989868]\n",
      "epoch:42 step:33241 [D loss: 0.316877, acc: 88.28%] [G loss: 3.972784]\n",
      "epoch:42 step:33242 [D loss: 0.967287, acc: 52.34%] [G loss: 10.110991]\n",
      "epoch:42 step:33243 [D loss: 0.749458, acc: 51.56%] [G loss: 4.878388]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:42 step:33244 [D loss: 0.047999, acc: 100.00%] [G loss: 7.915310]\n",
      "epoch:42 step:33245 [D loss: 1.101152, acc: 50.00%] [G loss: 4.057921]\n",
      "epoch:42 step:33246 [D loss: 0.167429, acc: 97.66%] [G loss: 6.727199]\n",
      "epoch:42 step:33247 [D loss: 0.344133, acc: 82.81%] [G loss: 6.804902]\n",
      "epoch:42 step:33248 [D loss: 0.117902, acc: 99.22%] [G loss: 6.266453]\n",
      "epoch:42 step:33249 [D loss: 0.327734, acc: 89.06%] [G loss: 5.708370]\n",
      "epoch:42 step:33250 [D loss: 0.150512, acc: 97.66%] [G loss: 8.174911]\n",
      "epoch:42 step:33251 [D loss: 0.517764, acc: 68.75%] [G loss: 5.645782]\n",
      "epoch:42 step:33252 [D loss: 0.070675, acc: 100.00%] [G loss: 6.980735]\n",
      "epoch:42 step:33253 [D loss: 0.494747, acc: 82.81%] [G loss: 5.945616]\n",
      "epoch:42 step:33254 [D loss: 0.121682, acc: 97.66%] [G loss: 3.043418]\n",
      "epoch:42 step:33255 [D loss: 0.088324, acc: 100.00%] [G loss: 7.590743]\n",
      "epoch:42 step:33256 [D loss: 0.081612, acc: 100.00%] [G loss: 3.825426]\n",
      "epoch:42 step:33257 [D loss: 0.155469, acc: 98.44%] [G loss: 5.234473]\n",
      "epoch:42 step:33258 [D loss: 0.087685, acc: 100.00%] [G loss: 8.528992]\n",
      "epoch:42 step:33259 [D loss: 0.452506, acc: 86.72%] [G loss: 4.522597]\n",
      "epoch:42 step:33260 [D loss: 0.376057, acc: 80.47%] [G loss: 5.403624]\n",
      "epoch:42 step:33261 [D loss: 0.132327, acc: 98.44%] [G loss: 4.299361]\n",
      "epoch:42 step:33262 [D loss: 0.712600, acc: 54.69%] [G loss: 8.990854]\n",
      "epoch:42 step:33263 [D loss: 0.244772, acc: 90.62%] [G loss: 7.877823]\n",
      "epoch:42 step:33264 [D loss: 0.289868, acc: 85.16%] [G loss: 6.685044]\n",
      "epoch:42 step:33265 [D loss: 0.239306, acc: 96.88%] [G loss: 4.873373]\n",
      "epoch:42 step:33266 [D loss: 0.169194, acc: 95.31%] [G loss: 6.207768]\n",
      "epoch:42 step:33267 [D loss: 0.352830, acc: 77.34%] [G loss: 7.745842]\n",
      "epoch:42 step:33268 [D loss: 0.643909, acc: 57.81%] [G loss: 7.478940]\n",
      "epoch:42 step:33269 [D loss: 0.376958, acc: 81.25%] [G loss: 6.287604]\n",
      "epoch:42 step:33270 [D loss: 0.793207, acc: 51.56%] [G loss: 4.918833]\n",
      "epoch:42 step:33271 [D loss: 0.641039, acc: 58.59%] [G loss: 4.134886]\n",
      "epoch:42 step:33272 [D loss: 0.016606, acc: 100.00%] [G loss: 8.646971]\n",
      "epoch:42 step:33273 [D loss: 0.981501, acc: 50.00%] [G loss: 5.864981]\n",
      "epoch:42 step:33274 [D loss: 0.738260, acc: 57.81%] [G loss: 6.878067]\n",
      "epoch:42 step:33275 [D loss: 0.781974, acc: 56.25%] [G loss: 7.764640]\n",
      "epoch:42 step:33276 [D loss: 0.839073, acc: 51.56%] [G loss: 5.357991]\n",
      "epoch:42 step:33277 [D loss: 0.080560, acc: 99.22%] [G loss: 5.545485]\n",
      "epoch:42 step:33278 [D loss: 0.672924, acc: 69.53%] [G loss: 8.092300]\n",
      "epoch:42 step:33279 [D loss: 0.398676, acc: 79.69%] [G loss: 6.936357]\n",
      "epoch:42 step:33280 [D loss: 0.424432, acc: 74.22%] [G loss: 5.959899]\n",
      "epoch:42 step:33281 [D loss: 0.867836, acc: 50.78%] [G loss: 7.980217]\n",
      "epoch:42 step:33282 [D loss: 0.110219, acc: 98.44%] [G loss: 5.004072]\n",
      "epoch:42 step:33283 [D loss: 0.427129, acc: 86.72%] [G loss: 7.179373]\n",
      "epoch:42 step:33284 [D loss: 0.480767, acc: 71.88%] [G loss: 2.410109]\n",
      "epoch:42 step:33285 [D loss: 0.654980, acc: 61.72%] [G loss: 9.605507]\n",
      "epoch:42 step:33286 [D loss: 0.147533, acc: 97.66%] [G loss: 4.712536]\n",
      "epoch:42 step:33287 [D loss: 1.304294, acc: 50.00%] [G loss: 7.646668]\n",
      "epoch:42 step:33288 [D loss: 1.876370, acc: 18.75%] [G loss: 7.042315]\n",
      "epoch:42 step:33289 [D loss: 0.150624, acc: 98.44%] [G loss: 5.231759]\n",
      "epoch:42 step:33290 [D loss: 0.105110, acc: 100.00%] [G loss: 7.107753]\n",
      "epoch:42 step:33291 [D loss: 0.327553, acc: 85.16%] [G loss: 4.083277]\n",
      "epoch:42 step:33292 [D loss: 0.268603, acc: 85.94%] [G loss: 4.743075]\n",
      "epoch:42 step:33293 [D loss: 0.036099, acc: 100.00%] [G loss: 7.700835]\n",
      "epoch:42 step:33294 [D loss: 0.074929, acc: 100.00%] [G loss: 5.399220]\n",
      "epoch:42 step:33295 [D loss: 0.063146, acc: 100.00%] [G loss: 4.767673]\n",
      "epoch:42 step:33296 [D loss: 0.098663, acc: 100.00%] [G loss: 10.072992]\n",
      "epoch:42 step:33297 [D loss: 0.185860, acc: 98.44%] [G loss: 7.523612]\n",
      "epoch:42 step:33298 [D loss: 0.085595, acc: 100.00%] [G loss: 5.700913]\n",
      "epoch:42 step:33299 [D loss: 0.208057, acc: 92.19%] [G loss: 7.934407]\n",
      "epoch:42 step:33300 [D loss: 0.200610, acc: 95.31%] [G loss: 5.261351]\n",
      "epoch:42 step:33301 [D loss: 0.175831, acc: 96.88%] [G loss: 6.424694]\n",
      "epoch:42 step:33302 [D loss: 0.163457, acc: 99.22%] [G loss: 6.381904]\n",
      "epoch:42 step:33303 [D loss: 0.666976, acc: 57.81%] [G loss: 5.330644]\n",
      "epoch:42 step:33304 [D loss: 0.064212, acc: 100.00%] [G loss: 8.210622]\n",
      "epoch:42 step:33305 [D loss: 0.295750, acc: 89.84%] [G loss: 4.079469]\n",
      "epoch:42 step:33306 [D loss: 0.065289, acc: 100.00%] [G loss: 5.028623]\n",
      "epoch:42 step:33307 [D loss: 0.045108, acc: 100.00%] [G loss: 4.064309]\n",
      "epoch:42 step:33308 [D loss: 0.072216, acc: 100.00%] [G loss: 7.842642]\n",
      "epoch:42 step:33309 [D loss: 0.289522, acc: 87.50%] [G loss: 4.610997]\n",
      "epoch:42 step:33310 [D loss: 0.567539, acc: 60.94%] [G loss: 6.995221]\n",
      "epoch:42 step:33311 [D loss: 0.568646, acc: 66.41%] [G loss: 7.294592]\n",
      "epoch:42 step:33312 [D loss: 0.475145, acc: 68.75%] [G loss: 5.765098]\n",
      "epoch:42 step:33313 [D loss: 0.041029, acc: 100.00%] [G loss: 9.563463]\n",
      "epoch:42 step:33314 [D loss: 0.274768, acc: 92.97%] [G loss: 8.097377]\n",
      "epoch:42 step:33315 [D loss: 0.059954, acc: 100.00%] [G loss: 6.734878]\n",
      "epoch:42 step:33316 [D loss: 0.499660, acc: 64.06%] [G loss: 4.305378]\n",
      "epoch:42 step:33317 [D loss: 0.519813, acc: 67.19%] [G loss: 3.880751]\n",
      "epoch:42 step:33318 [D loss: 0.723730, acc: 59.38%] [G loss: 7.094702]\n",
      "epoch:42 step:33319 [D loss: 0.053538, acc: 99.22%] [G loss: 5.984155]\n",
      "epoch:42 step:33320 [D loss: 0.473491, acc: 69.53%] [G loss: 9.598739]\n",
      "epoch:42 step:33321 [D loss: 0.198795, acc: 98.44%] [G loss: 6.499456]\n",
      "epoch:42 step:33322 [D loss: 0.108079, acc: 99.22%] [G loss: 7.742785]\n",
      "epoch:42 step:33323 [D loss: 0.398675, acc: 78.91%] [G loss: 4.163523]\n",
      "epoch:42 step:33324 [D loss: 0.172587, acc: 96.88%] [G loss: 4.905524]\n",
      "epoch:42 step:33325 [D loss: 0.215701, acc: 94.53%] [G loss: 10.231865]\n",
      "epoch:42 step:33326 [D loss: 0.107716, acc: 100.00%] [G loss: 8.371696]\n",
      "epoch:42 step:33327 [D loss: 0.847251, acc: 51.56%] [G loss: 7.473951]\n",
      "epoch:42 step:33328 [D loss: 0.077052, acc: 100.00%] [G loss: 2.749973]\n",
      "epoch:42 step:33329 [D loss: 0.062380, acc: 100.00%] [G loss: 7.262924]\n",
      "epoch:42 step:33330 [D loss: 0.497350, acc: 69.53%] [G loss: 3.410356]\n",
      "epoch:42 step:33331 [D loss: 0.099463, acc: 99.22%] [G loss: 4.604296]\n",
      "epoch:42 step:33332 [D loss: 0.150848, acc: 97.66%] [G loss: 6.232572]\n",
      "epoch:42 step:33333 [D loss: 0.075941, acc: 100.00%] [G loss: 6.101929]\n",
      "epoch:42 step:33334 [D loss: 0.332969, acc: 92.97%] [G loss: 5.158642]\n",
      "epoch:42 step:33335 [D loss: 0.228635, acc: 95.31%] [G loss: 4.943594]\n",
      "epoch:42 step:33336 [D loss: 0.245160, acc: 96.09%] [G loss: 4.916039]\n",
      "epoch:42 step:33337 [D loss: 0.682467, acc: 64.84%] [G loss: 4.210833]\n",
      "epoch:42 step:33338 [D loss: 0.482136, acc: 67.97%] [G loss: 5.891503]\n",
      "epoch:42 step:33339 [D loss: 0.126056, acc: 99.22%] [G loss: 5.612428]\n",
      "epoch:42 step:33340 [D loss: 0.183514, acc: 96.88%] [G loss: 5.643928]\n",
      "epoch:42 step:33341 [D loss: 0.152918, acc: 99.22%] [G loss: 5.998663]\n",
      "epoch:42 step:33342 [D loss: 1.051541, acc: 31.25%] [G loss: 8.356380]\n",
      "epoch:42 step:33343 [D loss: 0.133922, acc: 98.44%] [G loss: 6.321626]\n",
      "epoch:42 step:33344 [D loss: 0.009211, acc: 100.00%] [G loss: 4.936799]\n",
      "epoch:42 step:33345 [D loss: 0.229992, acc: 94.53%] [G loss: 7.065207]\n",
      "epoch:42 step:33346 [D loss: 0.008336, acc: 100.00%] [G loss: 6.861054]\n",
      "epoch:42 step:33347 [D loss: 0.904655, acc: 46.09%] [G loss: 7.385150]\n",
      "epoch:42 step:33348 [D loss: 0.250444, acc: 94.53%] [G loss: 6.026982]\n",
      "epoch:42 step:33349 [D loss: 0.295889, acc: 94.53%] [G loss: 5.804090]\n",
      "epoch:42 step:33350 [D loss: 0.482764, acc: 74.22%] [G loss: 4.468422]\n",
      "epoch:42 step:33351 [D loss: 0.143417, acc: 98.44%] [G loss: 6.918877]\n",
      "epoch:42 step:33352 [D loss: 0.267198, acc: 93.75%] [G loss: 4.685943]\n",
      "epoch:42 step:33353 [D loss: 0.378744, acc: 79.69%] [G loss: 5.631359]\n",
      "epoch:42 step:33354 [D loss: 0.626102, acc: 61.72%] [G loss: 6.107535]\n",
      "epoch:42 step:33355 [D loss: 0.714574, acc: 59.38%] [G loss: 3.430278]\n",
      "epoch:42 step:33356 [D loss: 1.577762, acc: 50.00%] [G loss: 6.975408]\n",
      "epoch:42 step:33357 [D loss: 0.987226, acc: 50.00%] [G loss: 4.682376]\n",
      "epoch:42 step:33358 [D loss: 0.121430, acc: 98.44%] [G loss: 5.603198]\n",
      "epoch:42 step:33359 [D loss: 1.299029, acc: 35.16%] [G loss: 8.982039]\n",
      "epoch:42 step:33360 [D loss: 0.094618, acc: 100.00%] [G loss: 4.504253]\n",
      "epoch:42 step:33361 [D loss: 0.137445, acc: 96.88%] [G loss: 5.778982]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:42 step:33362 [D loss: 0.020446, acc: 100.00%] [G loss: 4.993216]\n",
      "epoch:42 step:33363 [D loss: 0.116216, acc: 100.00%] [G loss: 6.289740]\n",
      "epoch:42 step:33364 [D loss: 0.287536, acc: 96.09%] [G loss: 5.114744]\n",
      "epoch:42 step:33365 [D loss: 0.785030, acc: 54.69%] [G loss: 6.166384]\n",
      "epoch:42 step:33366 [D loss: 0.182892, acc: 97.66%] [G loss: 6.096156]\n",
      "epoch:42 step:33367 [D loss: 0.240935, acc: 94.53%] [G loss: 5.078597]\n",
      "epoch:42 step:33368 [D loss: 0.045844, acc: 100.00%] [G loss: 4.020298]\n",
      "epoch:42 step:33369 [D loss: 0.286024, acc: 90.62%] [G loss: 4.641654]\n",
      "epoch:42 step:33370 [D loss: 0.101685, acc: 100.00%] [G loss: 5.210091]\n",
      "epoch:42 step:33371 [D loss: 0.153537, acc: 97.66%] [G loss: 6.610737]\n",
      "epoch:42 step:33372 [D loss: 0.121273, acc: 99.22%] [G loss: 6.370369]\n",
      "epoch:42 step:33373 [D loss: 0.850562, acc: 52.34%] [G loss: 5.465620]\n",
      "epoch:42 step:33374 [D loss: 0.211647, acc: 96.09%] [G loss: 7.450034]\n",
      "epoch:42 step:33375 [D loss: 0.304218, acc: 92.97%] [G loss: 2.579243]\n",
      "epoch:42 step:33376 [D loss: 0.433292, acc: 79.69%] [G loss: 5.027510]\n",
      "epoch:42 step:33377 [D loss: 0.275007, acc: 95.31%] [G loss: 3.743857]\n",
      "epoch:42 step:33378 [D loss: 0.483384, acc: 71.09%] [G loss: 2.778785]\n",
      "epoch:42 step:33379 [D loss: 0.133028, acc: 97.66%] [G loss: 5.211222]\n",
      "epoch:42 step:33380 [D loss: 0.046155, acc: 100.00%] [G loss: 5.401127]\n",
      "epoch:42 step:33381 [D loss: 0.158936, acc: 96.88%] [G loss: 6.251774]\n",
      "epoch:42 step:33382 [D loss: 0.494925, acc: 79.69%] [G loss: 6.846853]\n",
      "epoch:42 step:33383 [D loss: 0.014006, acc: 100.00%] [G loss: 5.566673]\n",
      "epoch:42 step:33384 [D loss: 0.226432, acc: 97.66%] [G loss: 6.737624]\n",
      "epoch:42 step:33385 [D loss: 0.415989, acc: 80.47%] [G loss: 6.064889]\n",
      "epoch:42 step:33386 [D loss: 0.599594, acc: 64.84%] [G loss: 8.212384]\n",
      "epoch:42 step:33387 [D loss: 0.028721, acc: 100.00%] [G loss: 7.043631]\n",
      "epoch:42 step:33388 [D loss: 0.143804, acc: 100.00%] [G loss: 5.758942]\n",
      "epoch:42 step:33389 [D loss: 0.521584, acc: 62.50%] [G loss: 2.862632]\n",
      "epoch:42 step:33390 [D loss: 0.031498, acc: 100.00%] [G loss: 8.541454]\n",
      "epoch:42 step:33391 [D loss: 0.365309, acc: 80.47%] [G loss: 6.014795]\n",
      "epoch:42 step:33392 [D loss: 0.169382, acc: 96.09%] [G loss: 7.743998]\n",
      "epoch:42 step:33393 [D loss: 0.334145, acc: 83.59%] [G loss: 6.723283]\n",
      "epoch:42 step:33394 [D loss: 0.476582, acc: 69.53%] [G loss: 5.783327]\n",
      "epoch:42 step:33395 [D loss: 0.452474, acc: 81.25%] [G loss: 5.023315]\n",
      "epoch:42 step:33396 [D loss: 0.660457, acc: 60.16%] [G loss: 4.402617]\n",
      "epoch:42 step:33397 [D loss: 0.009429, acc: 100.00%] [G loss: 7.586992]\n",
      "epoch:42 step:33398 [D loss: 0.127782, acc: 98.44%] [G loss: 2.253591]\n",
      "epoch:42 step:33399 [D loss: 0.034846, acc: 100.00%] [G loss: 7.563270]\n",
      "epoch:42 step:33400 [D loss: 0.111055, acc: 100.00%] [G loss: 3.772278]\n",
      "##############\n",
      "[0.85942234 0.86185041 0.81931254 0.8034249  0.78921667 0.79915308\n",
      " 0.89455121 0.81225873 0.81191381 0.8392845 ]\n",
      "##########\n",
      "epoch:42 step:33401 [D loss: 0.078427, acc: 100.00%] [G loss: 5.043931]\n",
      "epoch:42 step:33402 [D loss: 0.013918, acc: 100.00%] [G loss: 9.063906]\n",
      "epoch:42 step:33403 [D loss: 0.356263, acc: 84.38%] [G loss: 6.683367]\n",
      "epoch:42 step:33404 [D loss: 0.126824, acc: 99.22%] [G loss: 4.670804]\n",
      "epoch:42 step:33405 [D loss: 0.280713, acc: 91.41%] [G loss: 5.227242]\n",
      "epoch:42 step:33406 [D loss: 1.200770, acc: 22.66%] [G loss: 4.334738]\n",
      "epoch:42 step:33407 [D loss: 0.161919, acc: 96.09%] [G loss: 6.680154]\n",
      "epoch:42 step:33408 [D loss: 0.100232, acc: 99.22%] [G loss: 9.121292]\n",
      "epoch:42 step:33409 [D loss: 0.296335, acc: 86.72%] [G loss: 4.482172]\n",
      "epoch:42 step:33410 [D loss: 0.346502, acc: 86.72%] [G loss: 4.412384]\n",
      "epoch:42 step:33411 [D loss: 0.198299, acc: 97.66%] [G loss: 1.383908]\n",
      "epoch:42 step:33412 [D loss: 0.058234, acc: 100.00%] [G loss: 8.105413]\n",
      "epoch:42 step:33413 [D loss: 0.078870, acc: 100.00%] [G loss: 6.406631]\n",
      "epoch:42 step:33414 [D loss: 0.387686, acc: 82.81%] [G loss: 3.092863]\n",
      "epoch:42 step:33415 [D loss: 0.092282, acc: 100.00%] [G loss: 6.963054]\n",
      "epoch:42 step:33416 [D loss: 0.023169, acc: 100.00%] [G loss: 5.427725]\n",
      "epoch:42 step:33417 [D loss: 0.127702, acc: 99.22%] [G loss: 4.761515]\n",
      "epoch:42 step:33418 [D loss: 0.397180, acc: 82.81%] [G loss: 5.707151]\n",
      "epoch:42 step:33419 [D loss: 0.160356, acc: 96.88%] [G loss: 6.146813]\n",
      "epoch:42 step:33420 [D loss: 0.255088, acc: 89.84%] [G loss: 2.881918]\n",
      "epoch:42 step:33421 [D loss: 0.264914, acc: 96.88%] [G loss: 4.119238]\n",
      "epoch:42 step:33422 [D loss: 0.390168, acc: 78.91%] [G loss: 4.237557]\n",
      "epoch:42 step:33423 [D loss: 0.071087, acc: 99.22%] [G loss: 4.565843]\n",
      "epoch:42 step:33424 [D loss: 0.136497, acc: 98.44%] [G loss: 7.501014]\n",
      "epoch:42 step:33425 [D loss: 0.672800, acc: 60.16%] [G loss: 5.016423]\n",
      "epoch:42 step:33426 [D loss: 0.251880, acc: 95.31%] [G loss: 10.378198]\n",
      "epoch:42 step:33427 [D loss: 0.210580, acc: 98.44%] [G loss: 5.098242]\n",
      "epoch:42 step:33428 [D loss: 0.230957, acc: 93.75%] [G loss: 3.151837]\n",
      "epoch:42 step:33429 [D loss: 0.427493, acc: 74.22%] [G loss: 4.177014]\n",
      "epoch:42 step:33430 [D loss: 0.153987, acc: 96.88%] [G loss: 7.237643]\n",
      "epoch:42 step:33431 [D loss: 0.220366, acc: 92.19%] [G loss: 9.128347]\n",
      "epoch:42 step:33432 [D loss: 1.526861, acc: 9.38%] [G loss: 6.427934]\n",
      "epoch:42 step:33433 [D loss: 0.423889, acc: 86.72%] [G loss: 5.557561]\n",
      "epoch:42 step:33434 [D loss: 0.373746, acc: 89.84%] [G loss: 3.032767]\n",
      "epoch:42 step:33435 [D loss: 1.224824, acc: 50.00%] [G loss: 8.364825]\n",
      "epoch:42 step:33436 [D loss: 0.538510, acc: 64.84%] [G loss: 5.921838]\n",
      "epoch:42 step:33437 [D loss: 0.179691, acc: 98.44%] [G loss: 4.869330]\n",
      "epoch:42 step:33438 [D loss: 0.188959, acc: 94.53%] [G loss: 4.924407]\n",
      "epoch:42 step:33439 [D loss: 0.035722, acc: 100.00%] [G loss: 6.905731]\n",
      "epoch:42 step:33440 [D loss: 0.262256, acc: 93.75%] [G loss: 8.358942]\n",
      "epoch:42 step:33441 [D loss: 0.275824, acc: 89.84%] [G loss: 8.835500]\n",
      "epoch:42 step:33442 [D loss: 0.214480, acc: 95.31%] [G loss: 7.477249]\n",
      "epoch:42 step:33443 [D loss: 0.225423, acc: 96.09%] [G loss: 3.286212]\n",
      "epoch:42 step:33444 [D loss: 0.137302, acc: 98.44%] [G loss: 5.607398]\n",
      "epoch:42 step:33445 [D loss: 0.141810, acc: 98.44%] [G loss: 7.113384]\n",
      "epoch:42 step:33446 [D loss: 0.113101, acc: 100.00%] [G loss: 3.217188]\n",
      "epoch:42 step:33447 [D loss: 0.734609, acc: 57.03%] [G loss: 3.929996]\n",
      "epoch:42 step:33448 [D loss: 0.536282, acc: 61.72%] [G loss: 6.986523]\n",
      "epoch:42 step:33449 [D loss: 0.690898, acc: 55.47%] [G loss: 6.250017]\n",
      "epoch:42 step:33450 [D loss: 0.072815, acc: 100.00%] [G loss: 6.339377]\n",
      "epoch:42 step:33451 [D loss: 0.067932, acc: 100.00%] [G loss: 8.227334]\n",
      "epoch:42 step:33452 [D loss: 0.216791, acc: 96.09%] [G loss: 3.027679]\n",
      "epoch:42 step:33453 [D loss: 0.153710, acc: 99.22%] [G loss: 6.273515]\n",
      "epoch:42 step:33454 [D loss: 0.093465, acc: 99.22%] [G loss: 5.533569]\n",
      "epoch:42 step:33455 [D loss: 0.028916, acc: 100.00%] [G loss: 7.892380]\n",
      "epoch:42 step:33456 [D loss: 0.500946, acc: 78.12%] [G loss: 4.079833]\n",
      "epoch:42 step:33457 [D loss: 0.011037, acc: 100.00%] [G loss: 5.557326]\n",
      "epoch:42 step:33458 [D loss: 0.916434, acc: 50.78%] [G loss: 9.567664]\n",
      "epoch:42 step:33459 [D loss: 1.609344, acc: 49.22%] [G loss: 5.187834]\n",
      "epoch:42 step:33460 [D loss: 0.073770, acc: 100.00%] [G loss: 5.591772]\n",
      "epoch:42 step:33461 [D loss: 0.148514, acc: 100.00%] [G loss: 6.427645]\n",
      "epoch:42 step:33462 [D loss: 0.309473, acc: 87.50%] [G loss: 5.459711]\n",
      "epoch:42 step:33463 [D loss: 0.260950, acc: 89.84%] [G loss: 5.890808]\n",
      "epoch:42 step:33464 [D loss: 0.022241, acc: 100.00%] [G loss: 7.685205]\n",
      "epoch:42 step:33465 [D loss: 0.020503, acc: 100.00%] [G loss: 5.915743]\n",
      "epoch:42 step:33466 [D loss: 0.128009, acc: 98.44%] [G loss: 7.297801]\n",
      "epoch:42 step:33467 [D loss: 0.079841, acc: 100.00%] [G loss: 5.542353]\n",
      "epoch:42 step:33468 [D loss: 0.278302, acc: 95.31%] [G loss: 3.407037]\n",
      "epoch:42 step:33469 [D loss: 0.026628, acc: 100.00%] [G loss: 10.687179]\n",
      "epoch:42 step:33470 [D loss: 0.173179, acc: 97.66%] [G loss: 3.840772]\n",
      "epoch:42 step:33471 [D loss: 0.160416, acc: 98.44%] [G loss: 7.173001]\n",
      "epoch:42 step:33472 [D loss: 0.129859, acc: 100.00%] [G loss: 3.305366]\n",
      "epoch:42 step:33473 [D loss: 0.262984, acc: 98.44%] [G loss: 8.000227]\n",
      "epoch:42 step:33474 [D loss: 0.205802, acc: 97.66%] [G loss: 6.288702]\n",
      "epoch:42 step:33475 [D loss: 0.091919, acc: 100.00%] [G loss: 3.364512]\n",
      "epoch:42 step:33476 [D loss: 0.099861, acc: 100.00%] [G loss: 4.049209]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:42 step:33477 [D loss: 0.082596, acc: 100.00%] [G loss: 4.909777]\n",
      "epoch:42 step:33478 [D loss: 0.046588, acc: 100.00%] [G loss: 7.395271]\n",
      "epoch:42 step:33479 [D loss: 0.213897, acc: 96.88%] [G loss: 6.143042]\n",
      "epoch:42 step:33480 [D loss: 0.065591, acc: 100.00%] [G loss: 3.546654]\n",
      "epoch:42 step:33481 [D loss: 0.148248, acc: 98.44%] [G loss: 3.856998]\n",
      "epoch:42 step:33482 [D loss: 0.551795, acc: 73.44%] [G loss: 7.777628]\n",
      "epoch:42 step:33483 [D loss: 0.515913, acc: 75.78%] [G loss: 7.399084]\n",
      "epoch:42 step:33484 [D loss: 0.311725, acc: 92.19%] [G loss: 4.935044]\n",
      "epoch:42 step:33485 [D loss: 0.799817, acc: 51.56%] [G loss: 5.900361]\n",
      "epoch:42 step:33486 [D loss: 0.253421, acc: 93.75%] [G loss: 7.262903]\n",
      "epoch:42 step:33487 [D loss: 0.215620, acc: 98.44%] [G loss: 4.536850]\n",
      "epoch:42 step:33488 [D loss: 0.071076, acc: 99.22%] [G loss: 5.454103]\n",
      "epoch:42 step:33489 [D loss: 0.603503, acc: 62.50%] [G loss: 7.930246]\n",
      "epoch:42 step:33490 [D loss: 0.036392, acc: 99.22%] [G loss: 9.736920]\n",
      "epoch:42 step:33491 [D loss: 0.717304, acc: 55.47%] [G loss: 8.349788]\n",
      "epoch:42 step:33492 [D loss: 0.533095, acc: 62.50%] [G loss: 9.978849]\n",
      "epoch:42 step:33493 [D loss: 0.266872, acc: 90.62%] [G loss: 4.090599]\n",
      "epoch:42 step:33494 [D loss: 0.059263, acc: 100.00%] [G loss: 8.142633]\n",
      "epoch:42 step:33495 [D loss: 0.271413, acc: 96.09%] [G loss: 4.953144]\n",
      "epoch:42 step:33496 [D loss: 0.040351, acc: 100.00%] [G loss: 3.897737]\n",
      "epoch:42 step:33497 [D loss: 0.862814, acc: 52.34%] [G loss: 11.164687]\n",
      "epoch:42 step:33498 [D loss: 1.373169, acc: 50.00%] [G loss: 5.579075]\n",
      "epoch:42 step:33499 [D loss: 0.124320, acc: 100.00%] [G loss: 6.435669]\n",
      "epoch:42 step:33500 [D loss: 0.025109, acc: 100.00%] [G loss: 8.603220]\n",
      "epoch:42 step:33501 [D loss: 0.173130, acc: 96.09%] [G loss: 6.108013]\n",
      "epoch:42 step:33502 [D loss: 0.280753, acc: 95.31%] [G loss: 4.551092]\n",
      "epoch:42 step:33503 [D loss: 0.383634, acc: 89.84%] [G loss: 6.773835]\n",
      "epoch:42 step:33504 [D loss: 0.293274, acc: 92.97%] [G loss: 5.711909]\n",
      "epoch:42 step:33505 [D loss: 0.151427, acc: 99.22%] [G loss: 8.235185]\n",
      "epoch:42 step:33506 [D loss: 0.094204, acc: 100.00%] [G loss: 5.064301]\n",
      "epoch:42 step:33507 [D loss: 0.134529, acc: 97.66%] [G loss: 7.440142]\n",
      "epoch:42 step:33508 [D loss: 0.189652, acc: 99.22%] [G loss: 4.871536]\n",
      "epoch:42 step:33509 [D loss: 0.099816, acc: 100.00%] [G loss: 5.360977]\n",
      "epoch:42 step:33510 [D loss: 0.086345, acc: 100.00%] [G loss: 7.005969]\n",
      "epoch:42 step:33511 [D loss: 0.055413, acc: 100.00%] [G loss: 8.207928]\n",
      "epoch:42 step:33512 [D loss: 0.315797, acc: 91.41%] [G loss: 4.012374]\n",
      "epoch:42 step:33513 [D loss: 0.230176, acc: 92.19%] [G loss: 5.311841]\n",
      "epoch:42 step:33514 [D loss: 0.318672, acc: 85.16%] [G loss: 8.051196]\n",
      "epoch:42 step:33515 [D loss: 0.187181, acc: 96.88%] [G loss: 4.936781]\n",
      "epoch:42 step:33516 [D loss: 0.482422, acc: 78.12%] [G loss: 3.471482]\n",
      "epoch:42 step:33517 [D loss: 0.076461, acc: 100.00%] [G loss: 4.598790]\n",
      "epoch:42 step:33518 [D loss: 0.620933, acc: 63.28%] [G loss: 8.667036]\n",
      "epoch:42 step:33519 [D loss: 0.094338, acc: 100.00%] [G loss: 5.349484]\n",
      "epoch:42 step:33520 [D loss: 1.349738, acc: 38.28%] [G loss: 8.781282]\n",
      "epoch:42 step:33521 [D loss: 0.015819, acc: 100.00%] [G loss: 5.265823]\n",
      "epoch:42 step:33522 [D loss: 0.133629, acc: 100.00%] [G loss: 6.438835]\n",
      "epoch:42 step:33523 [D loss: 0.490885, acc: 78.12%] [G loss: 7.082822]\n",
      "epoch:42 step:33524 [D loss: 0.088509, acc: 99.22%] [G loss: 8.033430]\n",
      "epoch:42 step:33525 [D loss: 0.017830, acc: 100.00%] [G loss: 7.608956]\n",
      "epoch:42 step:33526 [D loss: 0.365831, acc: 78.12%] [G loss: 6.524040]\n",
      "epoch:42 step:33527 [D loss: 0.064900, acc: 99.22%] [G loss: 5.427033]\n",
      "epoch:42 step:33528 [D loss: 0.668876, acc: 53.12%] [G loss: 6.200363]\n",
      "epoch:42 step:33529 [D loss: 0.286125, acc: 82.81%] [G loss: 9.480588]\n",
      "epoch:42 step:33530 [D loss: 0.786530, acc: 52.34%] [G loss: 7.344059]\n",
      "epoch:42 step:33531 [D loss: 0.717560, acc: 57.03%] [G loss: 8.636755]\n",
      "epoch:42 step:33532 [D loss: 0.474869, acc: 72.66%] [G loss: 9.648661]\n",
      "epoch:42 step:33533 [D loss: 0.699751, acc: 57.81%] [G loss: 7.835588]\n",
      "epoch:42 step:33534 [D loss: 0.094047, acc: 99.22%] [G loss: 5.114082]\n",
      "epoch:42 step:33535 [D loss: 0.079610, acc: 100.00%] [G loss: 6.047476]\n",
      "epoch:42 step:33536 [D loss: 0.655218, acc: 62.50%] [G loss: 5.922900]\n",
      "epoch:42 step:33537 [D loss: 1.035618, acc: 51.56%] [G loss: 6.809717]\n",
      "epoch:42 step:33538 [D loss: 0.195720, acc: 94.53%] [G loss: 6.056639]\n",
      "epoch:42 step:33539 [D loss: 0.123342, acc: 99.22%] [G loss: 8.113798]\n",
      "epoch:42 step:33540 [D loss: 0.501321, acc: 66.41%] [G loss: 6.806315]\n",
      "epoch:42 step:33541 [D loss: 0.339774, acc: 85.94%] [G loss: 5.260319]\n",
      "epoch:42 step:33542 [D loss: 0.040632, acc: 100.00%] [G loss: 5.601680]\n",
      "epoch:42 step:33543 [D loss: 0.297359, acc: 92.97%] [G loss: 4.950811]\n",
      "epoch:42 step:33544 [D loss: 0.684367, acc: 53.91%] [G loss: 6.188881]\n",
      "epoch:42 step:33545 [D loss: 0.167251, acc: 96.88%] [G loss: 3.560466]\n",
      "epoch:42 step:33546 [D loss: 0.560189, acc: 68.75%] [G loss: 3.907016]\n",
      "epoch:42 step:33547 [D loss: 0.180094, acc: 95.31%] [G loss: 3.607600]\n",
      "epoch:42 step:33548 [D loss: 0.180420, acc: 96.88%] [G loss: 6.290729]\n",
      "epoch:42 step:33549 [D loss: 0.091471, acc: 100.00%] [G loss: 3.470747]\n",
      "epoch:42 step:33550 [D loss: 0.155488, acc: 98.44%] [G loss: 5.582015]\n",
      "epoch:42 step:33551 [D loss: 0.773264, acc: 49.22%] [G loss: 8.400908]\n",
      "epoch:42 step:33552 [D loss: 0.611758, acc: 65.62%] [G loss: 6.914166]\n",
      "epoch:42 step:33553 [D loss: 0.901359, acc: 51.56%] [G loss: 6.638917]\n",
      "epoch:42 step:33554 [D loss: 0.013398, acc: 100.00%] [G loss: 6.394172]\n",
      "epoch:42 step:33555 [D loss: 0.687466, acc: 53.91%] [G loss: 10.899450]\n",
      "epoch:42 step:33556 [D loss: 0.072051, acc: 100.00%] [G loss: 5.371449]\n",
      "epoch:42 step:33557 [D loss: 0.328486, acc: 82.81%] [G loss: 2.581197]\n",
      "epoch:42 step:33558 [D loss: 0.794170, acc: 50.00%] [G loss: 7.723922]\n",
      "epoch:42 step:33559 [D loss: 0.522985, acc: 68.75%] [G loss: 6.614991]\n",
      "epoch:42 step:33560 [D loss: 0.088101, acc: 99.22%] [G loss: 3.508712]\n",
      "epoch:42 step:33561 [D loss: 1.707646, acc: 35.94%] [G loss: 5.780434]\n",
      "epoch:42 step:33562 [D loss: 0.145890, acc: 98.44%] [G loss: 7.567769]\n",
      "epoch:42 step:33563 [D loss: 0.525320, acc: 67.97%] [G loss: 6.825431]\n",
      "epoch:42 step:33564 [D loss: 0.042806, acc: 100.00%] [G loss: 7.978405]\n",
      "epoch:42 step:33565 [D loss: 0.077943, acc: 100.00%] [G loss: 4.840461]\n",
      "epoch:42 step:33566 [D loss: 0.246761, acc: 89.84%] [G loss: 8.485767]\n",
      "epoch:42 step:33567 [D loss: 0.124136, acc: 97.66%] [G loss: 6.244402]\n",
      "epoch:42 step:33568 [D loss: 0.671708, acc: 60.94%] [G loss: 4.391895]\n",
      "epoch:42 step:33569 [D loss: 0.057118, acc: 100.00%] [G loss: 5.765749]\n",
      "epoch:42 step:33570 [D loss: 0.091794, acc: 99.22%] [G loss: 5.863468]\n",
      "epoch:42 step:33571 [D loss: 0.929615, acc: 51.56%] [G loss: 7.168418]\n",
      "epoch:42 step:33572 [D loss: 0.196786, acc: 95.31%] [G loss: 5.963201]\n",
      "epoch:42 step:33573 [D loss: 0.180453, acc: 95.31%] [G loss: 6.934175]\n",
      "epoch:42 step:33574 [D loss: 0.103168, acc: 100.00%] [G loss: 4.867579]\n",
      "epoch:42 step:33575 [D loss: 0.134327, acc: 96.88%] [G loss: 7.024370]\n",
      "epoch:42 step:33576 [D loss: 0.158669, acc: 97.66%] [G loss: 5.381684]\n",
      "epoch:42 step:33577 [D loss: 0.217329, acc: 91.41%] [G loss: 4.920227]\n",
      "epoch:42 step:33578 [D loss: 1.332258, acc: 24.22%] [G loss: 7.169824]\n",
      "epoch:42 step:33579 [D loss: 1.405867, acc: 50.78%] [G loss: 7.547435]\n",
      "epoch:42 step:33580 [D loss: 0.303548, acc: 84.38%] [G loss: 6.789494]\n",
      "epoch:42 step:33581 [D loss: 0.100543, acc: 100.00%] [G loss: 3.270891]\n",
      "epoch:42 step:33582 [D loss: 0.176668, acc: 95.31%] [G loss: 7.557829]\n",
      "epoch:42 step:33583 [D loss: 0.320250, acc: 92.97%] [G loss: 2.627309]\n",
      "epoch:43 step:33584 [D loss: 0.163653, acc: 97.66%] [G loss: 4.469540]\n",
      "epoch:43 step:33585 [D loss: 0.104409, acc: 99.22%] [G loss: 7.618487]\n",
      "epoch:43 step:33586 [D loss: 0.823465, acc: 53.91%] [G loss: 7.401542]\n",
      "epoch:43 step:33587 [D loss: 0.593937, acc: 59.38%] [G loss: 5.206433]\n",
      "epoch:43 step:33588 [D loss: 1.709646, acc: 11.72%] [G loss: 8.556871]\n",
      "epoch:43 step:33589 [D loss: 0.103593, acc: 100.00%] [G loss: 5.612462]\n",
      "epoch:43 step:33590 [D loss: 0.296963, acc: 96.09%] [G loss: 5.997057]\n",
      "epoch:43 step:33591 [D loss: 0.077767, acc: 100.00%] [G loss: 5.179607]\n",
      "epoch:43 step:33592 [D loss: 0.028326, acc: 100.00%] [G loss: 6.491953]\n",
      "epoch:43 step:33593 [D loss: 0.423795, acc: 78.91%] [G loss: 5.895922]\n",
      "epoch:43 step:33594 [D loss: 0.258001, acc: 91.41%] [G loss: 5.709404]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:43 step:33595 [D loss: 0.169797, acc: 100.00%] [G loss: 5.368953]\n",
      "epoch:43 step:33596 [D loss: 0.131280, acc: 97.66%] [G loss: 4.110645]\n",
      "epoch:43 step:33597 [D loss: 0.207179, acc: 99.22%] [G loss: 8.405313]\n",
      "epoch:43 step:33598 [D loss: 0.129473, acc: 98.44%] [G loss: 7.425112]\n",
      "epoch:43 step:33599 [D loss: 0.589192, acc: 64.06%] [G loss: 4.546860]\n",
      "epoch:43 step:33600 [D loss: 0.535021, acc: 64.06%] [G loss: 8.024378]\n",
      "##############\n",
      "[0.86614602 0.86362991 0.82839458 0.83111218 0.78197859 0.83033388\n",
      " 0.87680368 0.81712075 0.80060685 0.82241595]\n",
      "##########\n",
      "epoch:43 step:33601 [D loss: 0.149310, acc: 98.44%] [G loss: 6.996278]\n",
      "epoch:43 step:33602 [D loss: 0.130098, acc: 98.44%] [G loss: 5.748540]\n",
      "epoch:43 step:33603 [D loss: 0.266178, acc: 94.53%] [G loss: 8.663239]\n",
      "epoch:43 step:33604 [D loss: 0.325582, acc: 81.25%] [G loss: 5.467524]\n",
      "epoch:43 step:33605 [D loss: 0.257399, acc: 95.31%] [G loss: 4.574903]\n",
      "epoch:43 step:33606 [D loss: 0.163069, acc: 98.44%] [G loss: 3.273861]\n",
      "epoch:43 step:33607 [D loss: 1.024027, acc: 47.66%] [G loss: 5.471258]\n",
      "epoch:43 step:33608 [D loss: 1.449165, acc: 50.78%] [G loss: 2.217016]\n",
      "epoch:43 step:33609 [D loss: 0.084508, acc: 100.00%] [G loss: 5.772964]\n",
      "epoch:43 step:33610 [D loss: 0.190603, acc: 99.22%] [G loss: 5.143314]\n",
      "epoch:43 step:33611 [D loss: 0.585950, acc: 70.31%] [G loss: 9.703668]\n",
      "epoch:43 step:33612 [D loss: 0.383130, acc: 85.16%] [G loss: 7.623933]\n",
      "epoch:43 step:33613 [D loss: 0.339789, acc: 80.47%] [G loss: 8.612598]\n",
      "epoch:43 step:33614 [D loss: 0.112932, acc: 99.22%] [G loss: 6.766530]\n",
      "epoch:43 step:33615 [D loss: 0.050799, acc: 100.00%] [G loss: 7.504561]\n",
      "epoch:43 step:33616 [D loss: 0.081369, acc: 100.00%] [G loss: 4.506499]\n",
      "epoch:43 step:33617 [D loss: 0.042709, acc: 100.00%] [G loss: 8.335278]\n",
      "epoch:43 step:33618 [D loss: 1.844011, acc: 7.03%] [G loss: 7.108243]\n",
      "epoch:43 step:33619 [D loss: 0.233501, acc: 96.09%] [G loss: 7.385362]\n",
      "epoch:43 step:33620 [D loss: 0.212110, acc: 95.31%] [G loss: 7.255522]\n",
      "epoch:43 step:33621 [D loss: 1.017659, acc: 52.34%] [G loss: 10.962421]\n",
      "epoch:43 step:33622 [D loss: 0.296625, acc: 84.38%] [G loss: 5.627751]\n",
      "epoch:43 step:33623 [D loss: 0.374759, acc: 75.78%] [G loss: 7.129596]\n",
      "epoch:43 step:33624 [D loss: 0.063382, acc: 99.22%] [G loss: 4.651775]\n",
      "epoch:43 step:33625 [D loss: 0.361566, acc: 79.69%] [G loss: 6.890074]\n",
      "epoch:43 step:33626 [D loss: 0.662936, acc: 53.91%] [G loss: 4.892233]\n",
      "epoch:43 step:33627 [D loss: 0.411796, acc: 73.44%] [G loss: 3.717400]\n",
      "epoch:43 step:33628 [D loss: 0.130582, acc: 100.00%] [G loss: 7.514733]\n",
      "epoch:43 step:33629 [D loss: 0.216590, acc: 91.41%] [G loss: 7.752161]\n",
      "epoch:43 step:33630 [D loss: 0.295997, acc: 83.59%] [G loss: 5.517805]\n",
      "epoch:43 step:33631 [D loss: 0.083837, acc: 100.00%] [G loss: 4.177505]\n",
      "epoch:43 step:33632 [D loss: 0.058274, acc: 100.00%] [G loss: 3.677229]\n",
      "epoch:43 step:33633 [D loss: 1.369660, acc: 50.00%] [G loss: 5.847705]\n",
      "epoch:43 step:33634 [D loss: 0.535697, acc: 62.50%] [G loss: 6.004353]\n",
      "epoch:43 step:33635 [D loss: 0.194417, acc: 96.09%] [G loss: 6.251965]\n",
      "epoch:43 step:33636 [D loss: 1.101385, acc: 50.78%] [G loss: 4.099695]\n",
      "epoch:43 step:33637 [D loss: 0.925050, acc: 54.69%] [G loss: 5.029215]\n",
      "epoch:43 step:33638 [D loss: 0.067640, acc: 100.00%] [G loss: 5.842246]\n",
      "epoch:43 step:33639 [D loss: 0.432362, acc: 74.22%] [G loss: 9.590319]\n",
      "epoch:43 step:33640 [D loss: 0.132401, acc: 99.22%] [G loss: 3.643077]\n",
      "epoch:43 step:33641 [D loss: 1.219335, acc: 50.78%] [G loss: 11.661386]\n",
      "epoch:43 step:33642 [D loss: 0.324736, acc: 86.72%] [G loss: 6.895608]\n",
      "epoch:43 step:33643 [D loss: 0.178428, acc: 94.53%] [G loss: 6.394722]\n",
      "epoch:43 step:33644 [D loss: 0.135939, acc: 97.66%] [G loss: 5.358029]\n",
      "epoch:43 step:33645 [D loss: 0.138598, acc: 98.44%] [G loss: 5.999002]\n",
      "epoch:43 step:33646 [D loss: 0.132021, acc: 99.22%] [G loss: 4.718204]\n",
      "epoch:43 step:33647 [D loss: 0.260481, acc: 95.31%] [G loss: 4.512876]\n",
      "epoch:43 step:33648 [D loss: 0.064246, acc: 100.00%] [G loss: 5.703019]\n",
      "epoch:43 step:33649 [D loss: 0.040581, acc: 100.00%] [G loss: 4.662101]\n",
      "epoch:43 step:33650 [D loss: 0.149910, acc: 97.66%] [G loss: 3.068455]\n",
      "epoch:43 step:33651 [D loss: 0.435542, acc: 84.38%] [G loss: 5.420555]\n",
      "epoch:43 step:33652 [D loss: 0.152234, acc: 98.44%] [G loss: 6.017877]\n",
      "epoch:43 step:33653 [D loss: 1.381359, acc: 18.75%] [G loss: 6.175534]\n",
      "epoch:43 step:33654 [D loss: 0.409294, acc: 75.78%] [G loss: 5.775638]\n",
      "epoch:43 step:33655 [D loss: 0.089153, acc: 98.44%] [G loss: 7.202453]\n",
      "epoch:43 step:33656 [D loss: 0.357346, acc: 88.28%] [G loss: 4.105046]\n",
      "epoch:43 step:33657 [D loss: 0.144608, acc: 99.22%] [G loss: 6.114278]\n",
      "epoch:43 step:33658 [D loss: 0.706744, acc: 53.91%] [G loss: 7.146783]\n",
      "epoch:43 step:33659 [D loss: 0.798270, acc: 57.81%] [G loss: 4.940326]\n",
      "epoch:43 step:33660 [D loss: 0.030599, acc: 100.00%] [G loss: 8.370624]\n",
      "epoch:43 step:33661 [D loss: 0.072735, acc: 98.44%] [G loss: 8.321491]\n",
      "epoch:43 step:33662 [D loss: 0.106600, acc: 100.00%] [G loss: 4.122190]\n",
      "epoch:43 step:33663 [D loss: 0.061759, acc: 100.00%] [G loss: 12.086914]\n",
      "epoch:43 step:33664 [D loss: 0.411530, acc: 83.59%] [G loss: 5.890798]\n",
      "epoch:43 step:33665 [D loss: 0.267625, acc: 89.84%] [G loss: 5.930800]\n",
      "epoch:43 step:33666 [D loss: 0.194511, acc: 94.53%] [G loss: 3.676409]\n",
      "epoch:43 step:33667 [D loss: 0.660169, acc: 54.69%] [G loss: 10.045040]\n",
      "epoch:43 step:33668 [D loss: 0.054453, acc: 100.00%] [G loss: 9.104235]\n",
      "epoch:43 step:33669 [D loss: 0.066267, acc: 100.00%] [G loss: 7.500557]\n",
      "epoch:43 step:33670 [D loss: 0.464489, acc: 71.09%] [G loss: 11.002567]\n",
      "epoch:43 step:33671 [D loss: 0.108839, acc: 98.44%] [G loss: 4.839813]\n",
      "epoch:43 step:33672 [D loss: 0.009900, acc: 100.00%] [G loss: 6.480556]\n",
      "epoch:43 step:33673 [D loss: 0.124919, acc: 99.22%] [G loss: 6.253215]\n",
      "epoch:43 step:33674 [D loss: 0.278411, acc: 89.84%] [G loss: 4.408164]\n",
      "epoch:43 step:33675 [D loss: 0.142227, acc: 95.31%] [G loss: 9.217931]\n",
      "epoch:43 step:33676 [D loss: 0.319402, acc: 84.38%] [G loss: 7.492890]\n",
      "epoch:43 step:33677 [D loss: 0.118286, acc: 99.22%] [G loss: 7.870246]\n",
      "epoch:43 step:33678 [D loss: 0.916586, acc: 38.28%] [G loss: 7.460629]\n",
      "epoch:43 step:33679 [D loss: 0.179617, acc: 96.09%] [G loss: 4.924420]\n",
      "epoch:43 step:33680 [D loss: 0.013250, acc: 100.00%] [G loss: 8.384235]\n",
      "epoch:43 step:33681 [D loss: 0.121209, acc: 100.00%] [G loss: 2.357584]\n",
      "epoch:43 step:33682 [D loss: 0.650354, acc: 57.81%] [G loss: 5.837177]\n",
      "epoch:43 step:33683 [D loss: 0.210262, acc: 96.09%] [G loss: 5.338253]\n",
      "epoch:43 step:33684 [D loss: 0.755608, acc: 53.91%] [G loss: 5.693881]\n",
      "epoch:43 step:33685 [D loss: 0.004414, acc: 100.00%] [G loss: 7.204732]\n",
      "epoch:43 step:33686 [D loss: 0.990744, acc: 37.50%] [G loss: 7.372108]\n",
      "epoch:43 step:33687 [D loss: 0.730984, acc: 53.91%] [G loss: 5.918068]\n",
      "epoch:43 step:33688 [D loss: 0.662926, acc: 66.41%] [G loss: 7.197080]\n",
      "epoch:43 step:33689 [D loss: 0.216176, acc: 95.31%] [G loss: 9.236710]\n",
      "epoch:43 step:33690 [D loss: 0.588359, acc: 63.28%] [G loss: 5.849074]\n",
      "epoch:43 step:33691 [D loss: 0.137169, acc: 98.44%] [G loss: 10.027483]\n",
      "epoch:43 step:33692 [D loss: 0.846331, acc: 50.00%] [G loss: 5.947247]\n",
      "epoch:43 step:33693 [D loss: 0.095727, acc: 100.00%] [G loss: 5.731421]\n",
      "epoch:43 step:33694 [D loss: 0.170152, acc: 98.44%] [G loss: 7.319071]\n",
      "epoch:43 step:33695 [D loss: 0.006287, acc: 100.00%] [G loss: 8.434698]\n",
      "epoch:43 step:33696 [D loss: 0.186851, acc: 98.44%] [G loss: 7.061500]\n",
      "epoch:43 step:33697 [D loss: 0.876756, acc: 50.00%] [G loss: 3.777713]\n",
      "epoch:43 step:33698 [D loss: 0.460140, acc: 78.12%] [G loss: 2.408499]\n",
      "epoch:43 step:33699 [D loss: 0.245395, acc: 94.53%] [G loss: 5.506094]\n",
      "epoch:43 step:33700 [D loss: 0.082705, acc: 100.00%] [G loss: 7.756583]\n",
      "epoch:43 step:33701 [D loss: 0.355158, acc: 82.03%] [G loss: 6.280532]\n",
      "epoch:43 step:33702 [D loss: 0.026851, acc: 100.00%] [G loss: 6.577179]\n",
      "epoch:43 step:33703 [D loss: 0.433874, acc: 81.25%] [G loss: 4.338512]\n",
      "epoch:43 step:33704 [D loss: 0.509713, acc: 72.66%] [G loss: 6.267912]\n",
      "epoch:43 step:33705 [D loss: 0.248575, acc: 96.09%] [G loss: 6.325974]\n",
      "epoch:43 step:33706 [D loss: 0.021197, acc: 100.00%] [G loss: 6.294769]\n",
      "epoch:43 step:33707 [D loss: 0.232469, acc: 95.31%] [G loss: 6.933877]\n",
      "epoch:43 step:33708 [D loss: 0.169415, acc: 99.22%] [G loss: 6.136408]\n",
      "epoch:43 step:33709 [D loss: 0.148933, acc: 98.44%] [G loss: 4.151172]\n",
      "epoch:43 step:33710 [D loss: 0.087237, acc: 100.00%] [G loss: 4.996237]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:43 step:33711 [D loss: 0.085130, acc: 100.00%] [G loss: 7.499293]\n",
      "epoch:43 step:33712 [D loss: 0.244012, acc: 89.84%] [G loss: 5.664432]\n",
      "epoch:43 step:33713 [D loss: 0.171646, acc: 98.44%] [G loss: 4.386317]\n",
      "epoch:43 step:33714 [D loss: 0.169326, acc: 97.66%] [G loss: 5.350308]\n",
      "epoch:43 step:33715 [D loss: 0.093453, acc: 100.00%] [G loss: 9.320505]\n",
      "epoch:43 step:33716 [D loss: 1.402136, acc: 16.41%] [G loss: 7.401925]\n",
      "epoch:43 step:33717 [D loss: 0.559557, acc: 63.28%] [G loss: 4.897489]\n",
      "epoch:43 step:33718 [D loss: 0.056983, acc: 99.22%] [G loss: 7.284244]\n",
      "epoch:43 step:33719 [D loss: 0.042514, acc: 100.00%] [G loss: 11.713225]\n",
      "epoch:43 step:33720 [D loss: 0.344345, acc: 90.62%] [G loss: 5.643270]\n",
      "epoch:43 step:33721 [D loss: 0.976302, acc: 41.41%] [G loss: 5.142268]\n",
      "epoch:43 step:33722 [D loss: 0.074229, acc: 99.22%] [G loss: 4.478186]\n",
      "epoch:43 step:33723 [D loss: 0.662497, acc: 59.38%] [G loss: 5.009478]\n",
      "epoch:43 step:33724 [D loss: 0.516980, acc: 67.97%] [G loss: 5.926717]\n",
      "epoch:43 step:33725 [D loss: 0.164138, acc: 99.22%] [G loss: 4.023979]\n",
      "epoch:43 step:33726 [D loss: 0.048085, acc: 100.00%] [G loss: 6.235837]\n",
      "epoch:43 step:33727 [D loss: 0.202065, acc: 97.66%] [G loss: 5.181026]\n",
      "epoch:43 step:33728 [D loss: 0.451695, acc: 73.44%] [G loss: 3.663291]\n",
      "epoch:43 step:33729 [D loss: 0.167127, acc: 97.66%] [G loss: 6.062108]\n",
      "epoch:43 step:33730 [D loss: 0.426727, acc: 77.34%] [G loss: 10.293912]\n",
      "epoch:43 step:33731 [D loss: 0.058801, acc: 100.00%] [G loss: 6.966928]\n",
      "epoch:43 step:33732 [D loss: 0.137897, acc: 97.66%] [G loss: 7.599263]\n",
      "epoch:43 step:33733 [D loss: 0.011003, acc: 100.00%] [G loss: 4.152067]\n",
      "epoch:43 step:33734 [D loss: 0.216248, acc: 93.75%] [G loss: 4.200124]\n",
      "epoch:43 step:33735 [D loss: 0.059805, acc: 100.00%] [G loss: 4.352160]\n",
      "epoch:43 step:33736 [D loss: 0.024627, acc: 100.00%] [G loss: 5.134898]\n",
      "epoch:43 step:33737 [D loss: 0.115649, acc: 97.66%] [G loss: 6.935263]\n",
      "epoch:43 step:33738 [D loss: 0.055694, acc: 100.00%] [G loss: 6.998100]\n",
      "epoch:43 step:33739 [D loss: 0.252453, acc: 95.31%] [G loss: 8.702995]\n",
      "epoch:43 step:33740 [D loss: 0.111793, acc: 100.00%] [G loss: 2.987014]\n",
      "epoch:43 step:33741 [D loss: 0.165470, acc: 99.22%] [G loss: 4.972672]\n",
      "epoch:43 step:33742 [D loss: 0.045535, acc: 100.00%] [G loss: 3.169497]\n",
      "epoch:43 step:33743 [D loss: 0.354599, acc: 84.38%] [G loss: 8.196491]\n",
      "epoch:43 step:33744 [D loss: 0.106825, acc: 99.22%] [G loss: 4.280597]\n",
      "epoch:43 step:33745 [D loss: 0.045448, acc: 100.00%] [G loss: 3.419776]\n",
      "epoch:43 step:33746 [D loss: 0.226446, acc: 96.09%] [G loss: 1.146730]\n",
      "epoch:43 step:33747 [D loss: 0.115704, acc: 98.44%] [G loss: 3.959977]\n",
      "epoch:43 step:33748 [D loss: 0.554900, acc: 73.44%] [G loss: 6.337809]\n",
      "epoch:43 step:33749 [D loss: 0.736872, acc: 58.59%] [G loss: 5.928310]\n",
      "epoch:43 step:33750 [D loss: 1.249978, acc: 50.78%] [G loss: 10.494748]\n",
      "epoch:43 step:33751 [D loss: 0.354138, acc: 84.38%] [G loss: 5.736748]\n",
      "epoch:43 step:33752 [D loss: 0.215645, acc: 96.09%] [G loss: 7.901995]\n",
      "epoch:43 step:33753 [D loss: 0.046041, acc: 100.00%] [G loss: 3.928981]\n",
      "epoch:43 step:33754 [D loss: 0.095821, acc: 99.22%] [G loss: 10.032686]\n",
      "epoch:43 step:33755 [D loss: 0.200940, acc: 97.66%] [G loss: 4.997625]\n",
      "epoch:43 step:33756 [D loss: 0.194773, acc: 96.88%] [G loss: 8.100202]\n",
      "epoch:43 step:33757 [D loss: 0.612387, acc: 55.47%] [G loss: 11.312785]\n",
      "epoch:43 step:33758 [D loss: 0.026525, acc: 100.00%] [G loss: 8.126032]\n",
      "epoch:43 step:33759 [D loss: 1.099138, acc: 29.69%] [G loss: 9.945842]\n",
      "epoch:43 step:33760 [D loss: 0.396249, acc: 78.12%] [G loss: 5.703275]\n",
      "epoch:43 step:33761 [D loss: 0.606750, acc: 62.50%] [G loss: 3.705963]\n",
      "epoch:43 step:33762 [D loss: 0.286530, acc: 87.50%] [G loss: 4.679244]\n",
      "epoch:43 step:33763 [D loss: 0.049281, acc: 100.00%] [G loss: 6.096828]\n",
      "epoch:43 step:33764 [D loss: 0.712970, acc: 50.78%] [G loss: 1.982393]\n",
      "epoch:43 step:33765 [D loss: 0.100621, acc: 99.22%] [G loss: 4.368386]\n",
      "epoch:43 step:33766 [D loss: 0.149146, acc: 96.88%] [G loss: 6.469899]\n",
      "epoch:43 step:33767 [D loss: 0.024629, acc: 100.00%] [G loss: 7.402695]\n",
      "epoch:43 step:33768 [D loss: 0.207432, acc: 98.44%] [G loss: 6.268055]\n",
      "epoch:43 step:33769 [D loss: 0.115933, acc: 98.44%] [G loss: 5.102415]\n",
      "epoch:43 step:33770 [D loss: 0.069942, acc: 100.00%] [G loss: 5.837877]\n",
      "epoch:43 step:33771 [D loss: 0.268621, acc: 89.84%] [G loss: 4.349854]\n",
      "epoch:43 step:33772 [D loss: 0.284456, acc: 86.72%] [G loss: 4.845143]\n",
      "epoch:43 step:33773 [D loss: 0.771184, acc: 54.69%] [G loss: 8.298391]\n",
      "epoch:43 step:33774 [D loss: 0.378296, acc: 82.03%] [G loss: 8.302361]\n",
      "epoch:43 step:33775 [D loss: 0.256080, acc: 88.28%] [G loss: 4.224798]\n",
      "epoch:43 step:33776 [D loss: 0.219806, acc: 92.97%] [G loss: 8.098185]\n",
      "epoch:43 step:33777 [D loss: 0.347504, acc: 82.81%] [G loss: 7.245048]\n",
      "epoch:43 step:33778 [D loss: 0.488936, acc: 68.75%] [G loss: 4.895840]\n",
      "epoch:43 step:33779 [D loss: 0.331276, acc: 90.62%] [G loss: 6.433066]\n",
      "epoch:43 step:33780 [D loss: 0.129759, acc: 97.66%] [G loss: 4.863533]\n",
      "epoch:43 step:33781 [D loss: 0.048715, acc: 100.00%] [G loss: 9.624588]\n",
      "epoch:43 step:33782 [D loss: 0.676256, acc: 56.25%] [G loss: 9.000645]\n",
      "epoch:43 step:33783 [D loss: 0.162077, acc: 96.88%] [G loss: 8.154810]\n",
      "epoch:43 step:33784 [D loss: 0.027128, acc: 100.00%] [G loss: 5.878409]\n",
      "epoch:43 step:33785 [D loss: 0.371566, acc: 86.72%] [G loss: 2.980216]\n",
      "epoch:43 step:33786 [D loss: 0.127887, acc: 99.22%] [G loss: 4.524008]\n",
      "epoch:43 step:33787 [D loss: 0.705818, acc: 60.16%] [G loss: 4.999720]\n",
      "epoch:43 step:33788 [D loss: 0.127653, acc: 99.22%] [G loss: 1.673299]\n",
      "epoch:43 step:33789 [D loss: 0.362003, acc: 83.59%] [G loss: 8.863824]\n",
      "epoch:43 step:33790 [D loss: 0.281143, acc: 89.06%] [G loss: 6.398049]\n",
      "epoch:43 step:33791 [D loss: 0.219493, acc: 92.19%] [G loss: 6.043495]\n",
      "epoch:43 step:33792 [D loss: 0.148714, acc: 98.44%] [G loss: 7.080399]\n",
      "epoch:43 step:33793 [D loss: 1.095344, acc: 42.97%] [G loss: 5.219395]\n",
      "epoch:43 step:33794 [D loss: 0.129126, acc: 98.44%] [G loss: 9.221711]\n",
      "epoch:43 step:33795 [D loss: 0.055285, acc: 100.00%] [G loss: 9.565699]\n",
      "epoch:43 step:33796 [D loss: 0.333502, acc: 80.47%] [G loss: 5.113049]\n",
      "epoch:43 step:33797 [D loss: 0.022390, acc: 100.00%] [G loss: 7.596661]\n",
      "epoch:43 step:33798 [D loss: 0.123372, acc: 100.00%] [G loss: 5.966678]\n",
      "epoch:43 step:33799 [D loss: 0.225471, acc: 92.97%] [G loss: 5.089738]\n",
      "epoch:43 step:33800 [D loss: 0.061248, acc: 100.00%] [G loss: 4.456684]\n",
      "##############\n",
      "[0.86486314 0.85745521 0.81329343 0.81387596 0.76619079 0.82403663\n",
      " 0.90300733 0.83789003 0.8001294  0.82681628]\n",
      "##########\n",
      "epoch:43 step:33801 [D loss: 0.034170, acc: 100.00%] [G loss: 4.025519]\n",
      "epoch:43 step:33802 [D loss: 0.448920, acc: 67.19%] [G loss: 7.249952]\n",
      "epoch:43 step:33803 [D loss: 0.289887, acc: 90.62%] [G loss: 5.090832]\n",
      "epoch:43 step:33804 [D loss: 0.537290, acc: 72.66%] [G loss: 5.308051]\n",
      "epoch:43 step:33805 [D loss: 0.565137, acc: 64.06%] [G loss: 5.176053]\n",
      "epoch:43 step:33806 [D loss: 0.045968, acc: 100.00%] [G loss: 3.362086]\n",
      "epoch:43 step:33807 [D loss: 0.639780, acc: 65.62%] [G loss: 10.797224]\n",
      "epoch:43 step:33808 [D loss: 0.113089, acc: 98.44%] [G loss: 3.908271]\n",
      "epoch:43 step:33809 [D loss: 0.130817, acc: 99.22%] [G loss: 7.366042]\n",
      "epoch:43 step:33810 [D loss: 0.383109, acc: 78.12%] [G loss: 11.238350]\n",
      "epoch:43 step:33811 [D loss: 0.250100, acc: 92.97%] [G loss: 8.149530]\n",
      "epoch:43 step:33812 [D loss: 0.120124, acc: 98.44%] [G loss: 4.166882]\n",
      "epoch:43 step:33813 [D loss: 1.766753, acc: 46.88%] [G loss: 8.830299]\n",
      "epoch:43 step:33814 [D loss: 0.041751, acc: 100.00%] [G loss: 7.963356]\n",
      "epoch:43 step:33815 [D loss: 1.170682, acc: 27.34%] [G loss: 5.934533]\n",
      "epoch:43 step:33816 [D loss: 0.439672, acc: 71.09%] [G loss: 3.840532]\n",
      "epoch:43 step:33817 [D loss: 0.230493, acc: 96.88%] [G loss: 6.772421]\n",
      "epoch:43 step:33818 [D loss: 0.227891, acc: 96.09%] [G loss: 5.981063]\n",
      "epoch:43 step:33819 [D loss: 0.296998, acc: 85.94%] [G loss: 7.758895]\n",
      "epoch:43 step:33820 [D loss: 0.418269, acc: 85.16%] [G loss: 3.803907]\n",
      "epoch:43 step:33821 [D loss: 0.074840, acc: 100.00%] [G loss: 7.662278]\n",
      "epoch:43 step:33822 [D loss: 0.179926, acc: 96.09%] [G loss: 5.112966]\n",
      "epoch:43 step:33823 [D loss: 0.355192, acc: 87.50%] [G loss: 7.403993]\n",
      "epoch:43 step:33824 [D loss: 0.139262, acc: 96.88%] [G loss: 6.896440]\n",
      "epoch:43 step:33825 [D loss: 0.041717, acc: 100.00%] [G loss: 5.779751]\n",
      "epoch:43 step:33826 [D loss: 0.381160, acc: 79.69%] [G loss: 7.142143]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:43 step:33827 [D loss: 0.138932, acc: 96.88%] [G loss: 12.324828]\n",
      "epoch:43 step:33828 [D loss: 0.341167, acc: 80.47%] [G loss: 10.672456]\n",
      "epoch:43 step:33829 [D loss: 0.191077, acc: 98.44%] [G loss: 4.156437]\n",
      "epoch:43 step:33830 [D loss: 0.159549, acc: 99.22%] [G loss: 6.030078]\n",
      "epoch:43 step:33831 [D loss: 0.159921, acc: 97.66%] [G loss: 5.499796]\n",
      "epoch:43 step:33832 [D loss: 1.053112, acc: 50.00%] [G loss: 6.702761]\n",
      "epoch:43 step:33833 [D loss: 0.231082, acc: 92.19%] [G loss: 6.946564]\n",
      "epoch:43 step:33834 [D loss: 0.268253, acc: 93.75%] [G loss: 6.934769]\n",
      "epoch:43 step:33835 [D loss: 0.281701, acc: 89.06%] [G loss: 8.877038]\n",
      "epoch:43 step:33836 [D loss: 0.307413, acc: 87.50%] [G loss: 3.744170]\n",
      "epoch:43 step:33837 [D loss: 0.498630, acc: 80.47%] [G loss: 8.923994]\n",
      "epoch:43 step:33838 [D loss: 0.233295, acc: 92.97%] [G loss: 5.683841]\n",
      "epoch:43 step:33839 [D loss: 0.653757, acc: 67.19%] [G loss: 7.443336]\n",
      "epoch:43 step:33840 [D loss: 0.122683, acc: 99.22%] [G loss: 6.708666]\n",
      "epoch:43 step:33841 [D loss: 0.129888, acc: 98.44%] [G loss: 8.550479]\n",
      "epoch:43 step:33842 [D loss: 0.422900, acc: 81.25%] [G loss: 7.657864]\n",
      "epoch:43 step:33843 [D loss: 0.352114, acc: 82.81%] [G loss: 6.413768]\n",
      "epoch:43 step:33844 [D loss: 0.029004, acc: 100.00%] [G loss: 7.864298]\n",
      "epoch:43 step:33845 [D loss: 0.090244, acc: 100.00%] [G loss: 6.415119]\n",
      "epoch:43 step:33846 [D loss: 0.474378, acc: 72.66%] [G loss: 8.549700]\n",
      "epoch:43 step:33847 [D loss: 0.137711, acc: 99.22%] [G loss: 4.827829]\n",
      "epoch:43 step:33848 [D loss: 0.174116, acc: 95.31%] [G loss: 5.537404]\n",
      "epoch:43 step:33849 [D loss: 0.577410, acc: 60.16%] [G loss: 6.805045]\n",
      "epoch:43 step:33850 [D loss: 0.169093, acc: 97.66%] [G loss: 5.801442]\n",
      "epoch:43 step:33851 [D loss: 0.474922, acc: 65.62%] [G loss: 5.397830]\n",
      "epoch:43 step:33852 [D loss: 0.171281, acc: 99.22%] [G loss: 6.757602]\n",
      "epoch:43 step:33853 [D loss: 1.891898, acc: 32.03%] [G loss: 7.398699]\n",
      "epoch:43 step:33854 [D loss: 0.146935, acc: 98.44%] [G loss: 6.505878]\n",
      "epoch:43 step:33855 [D loss: 0.070146, acc: 100.00%] [G loss: 6.076491]\n",
      "epoch:43 step:33856 [D loss: 0.327009, acc: 84.38%] [G loss: 3.770007]\n",
      "epoch:43 step:33857 [D loss: 1.198243, acc: 50.00%] [G loss: 14.517405]\n",
      "epoch:43 step:33858 [D loss: 0.620511, acc: 56.25%] [G loss: 4.372265]\n",
      "epoch:43 step:33859 [D loss: 0.103593, acc: 98.44%] [G loss: 3.794571]\n",
      "epoch:43 step:33860 [D loss: 0.078682, acc: 100.00%] [G loss: 7.132131]\n",
      "epoch:43 step:33861 [D loss: 0.210328, acc: 93.75%] [G loss: 13.692117]\n",
      "epoch:43 step:33862 [D loss: 0.150649, acc: 98.44%] [G loss: 7.609107]\n",
      "epoch:43 step:33863 [D loss: 0.487231, acc: 68.75%] [G loss: 6.599978]\n",
      "epoch:43 step:33864 [D loss: 0.114398, acc: 99.22%] [G loss: 4.703663]\n",
      "epoch:43 step:33865 [D loss: 1.377243, acc: 49.22%] [G loss: 4.790144]\n",
      "epoch:43 step:33866 [D loss: 0.049051, acc: 100.00%] [G loss: 6.700098]\n",
      "epoch:43 step:33867 [D loss: 1.004204, acc: 52.34%] [G loss: 5.831450]\n",
      "epoch:43 step:33868 [D loss: 0.821105, acc: 53.12%] [G loss: 3.805414]\n",
      "epoch:43 step:33869 [D loss: 0.196813, acc: 93.75%] [G loss: 7.375861]\n",
      "epoch:43 step:33870 [D loss: 0.580008, acc: 66.41%] [G loss: 9.228683]\n",
      "epoch:43 step:33871 [D loss: 0.232976, acc: 96.88%] [G loss: 7.195405]\n",
      "epoch:43 step:33872 [D loss: 0.358291, acc: 83.59%] [G loss: 6.261749]\n",
      "epoch:43 step:33873 [D loss: 0.423070, acc: 80.47%] [G loss: 4.980038]\n",
      "epoch:43 step:33874 [D loss: 0.035054, acc: 100.00%] [G loss: 7.312139]\n",
      "epoch:43 step:33875 [D loss: 0.055387, acc: 100.00%] [G loss: 7.609354]\n",
      "epoch:43 step:33876 [D loss: 0.155826, acc: 96.88%] [G loss: 7.325546]\n",
      "epoch:43 step:33877 [D loss: 0.028633, acc: 100.00%] [G loss: 5.639663]\n",
      "epoch:43 step:33878 [D loss: 0.156209, acc: 99.22%] [G loss: 1.808178]\n",
      "epoch:43 step:33879 [D loss: 0.077858, acc: 100.00%] [G loss: 7.629636]\n",
      "epoch:43 step:33880 [D loss: 0.016824, acc: 100.00%] [G loss: 5.957479]\n",
      "epoch:43 step:33881 [D loss: 0.128429, acc: 99.22%] [G loss: 3.818354]\n",
      "epoch:43 step:33882 [D loss: 0.125945, acc: 97.66%] [G loss: 3.603696]\n",
      "epoch:43 step:33883 [D loss: 0.054630, acc: 100.00%] [G loss: 5.812487]\n",
      "epoch:43 step:33884 [D loss: 0.086354, acc: 100.00%] [G loss: 6.150202]\n",
      "epoch:43 step:33885 [D loss: 0.015153, acc: 100.00%] [G loss: 8.417824]\n",
      "epoch:43 step:33886 [D loss: 0.736956, acc: 53.12%] [G loss: 3.683258]\n",
      "epoch:43 step:33887 [D loss: 0.185617, acc: 96.09%] [G loss: 7.011677]\n",
      "epoch:43 step:33888 [D loss: 0.341368, acc: 85.16%] [G loss: 5.769914]\n",
      "epoch:43 step:33889 [D loss: 0.327490, acc: 79.69%] [G loss: 8.504900]\n",
      "epoch:43 step:33890 [D loss: 0.073629, acc: 100.00%] [G loss: 7.811136]\n",
      "epoch:43 step:33891 [D loss: 0.231755, acc: 94.53%] [G loss: 7.601298]\n",
      "epoch:43 step:33892 [D loss: 0.285354, acc: 89.06%] [G loss: 10.518924]\n",
      "epoch:43 step:33893 [D loss: 0.289197, acc: 95.31%] [G loss: 6.164699]\n",
      "epoch:43 step:33894 [D loss: 0.487430, acc: 84.38%] [G loss: 6.952688]\n",
      "epoch:43 step:33895 [D loss: 0.172696, acc: 100.00%] [G loss: 4.916028]\n",
      "epoch:43 step:33896 [D loss: 0.983047, acc: 42.19%] [G loss: 8.771000]\n",
      "epoch:43 step:33897 [D loss: 0.040843, acc: 99.22%] [G loss: 6.958942]\n",
      "epoch:43 step:33898 [D loss: 0.203332, acc: 92.97%] [G loss: 3.973375]\n",
      "epoch:43 step:33899 [D loss: 0.233314, acc: 96.88%] [G loss: 4.270290]\n",
      "epoch:43 step:33900 [D loss: 0.143132, acc: 98.44%] [G loss: 3.888619]\n",
      "epoch:43 step:33901 [D loss: 0.160676, acc: 97.66%] [G loss: 4.571209]\n",
      "epoch:43 step:33902 [D loss: 0.016027, acc: 100.00%] [G loss: 5.582393]\n",
      "epoch:43 step:33903 [D loss: 0.658894, acc: 61.72%] [G loss: 6.303202]\n",
      "epoch:43 step:33904 [D loss: 0.155907, acc: 99.22%] [G loss: 6.654949]\n",
      "epoch:43 step:33905 [D loss: 0.083655, acc: 100.00%] [G loss: 7.185981]\n",
      "epoch:43 step:33906 [D loss: 0.326712, acc: 85.16%] [G loss: 7.709069]\n",
      "epoch:43 step:33907 [D loss: 0.359947, acc: 79.69%] [G loss: 6.401327]\n",
      "epoch:43 step:33908 [D loss: 0.186079, acc: 99.22%] [G loss: 5.095383]\n",
      "epoch:43 step:33909 [D loss: 0.045955, acc: 100.00%] [G loss: 5.845458]\n",
      "epoch:43 step:33910 [D loss: 0.306882, acc: 93.75%] [G loss: 9.263988]\n",
      "epoch:43 step:33911 [D loss: 0.497465, acc: 64.84%] [G loss: 7.216724]\n",
      "epoch:43 step:33912 [D loss: 0.004865, acc: 100.00%] [G loss: 8.343864]\n",
      "epoch:43 step:33913 [D loss: 0.260067, acc: 90.62%] [G loss: 6.560996]\n",
      "epoch:43 step:33914 [D loss: 1.379988, acc: 37.50%] [G loss: 8.436699]\n",
      "epoch:43 step:33915 [D loss: 0.111362, acc: 98.44%] [G loss: 5.654548]\n",
      "epoch:43 step:33916 [D loss: 0.035575, acc: 100.00%] [G loss: 6.533651]\n",
      "epoch:43 step:33917 [D loss: 0.330826, acc: 83.59%] [G loss: 9.470755]\n",
      "epoch:43 step:33918 [D loss: 0.034355, acc: 100.00%] [G loss: 4.057010]\n",
      "epoch:43 step:33919 [D loss: 0.098962, acc: 100.00%] [G loss: 6.469614]\n",
      "epoch:43 step:33920 [D loss: 0.161709, acc: 96.88%] [G loss: 3.018326]\n",
      "epoch:43 step:33921 [D loss: 0.358806, acc: 82.03%] [G loss: 6.090405]\n",
      "epoch:43 step:33922 [D loss: 0.030524, acc: 100.00%] [G loss: 6.551532]\n",
      "epoch:43 step:33923 [D loss: 0.315902, acc: 80.47%] [G loss: 8.024733]\n",
      "epoch:43 step:33924 [D loss: 0.077876, acc: 100.00%] [G loss: 8.358400]\n",
      "epoch:43 step:33925 [D loss: 0.194283, acc: 94.53%] [G loss: 3.369898]\n",
      "epoch:43 step:33926 [D loss: 0.014121, acc: 100.00%] [G loss: 7.584217]\n",
      "epoch:43 step:33927 [D loss: 0.037403, acc: 100.00%] [G loss: 9.200474]\n",
      "epoch:43 step:33928 [D loss: 0.106388, acc: 100.00%] [G loss: 3.945584]\n",
      "epoch:43 step:33929 [D loss: 0.309593, acc: 87.50%] [G loss: 6.956061]\n",
      "epoch:43 step:33930 [D loss: 0.249628, acc: 93.75%] [G loss: 6.518182]\n",
      "epoch:43 step:33931 [D loss: 0.282581, acc: 89.84%] [G loss: 4.359384]\n",
      "epoch:43 step:33932 [D loss: 0.431660, acc: 75.78%] [G loss: 9.320305]\n",
      "epoch:43 step:33933 [D loss: 0.304547, acc: 85.16%] [G loss: 7.638648]\n",
      "epoch:43 step:33934 [D loss: 0.391729, acc: 82.03%] [G loss: 10.122201]\n",
      "epoch:43 step:33935 [D loss: 0.775160, acc: 50.78%] [G loss: 9.826029]\n",
      "epoch:43 step:33936 [D loss: 0.148380, acc: 96.09%] [G loss: 4.005747]\n",
      "epoch:43 step:33937 [D loss: 0.440855, acc: 74.22%] [G loss: 4.479127]\n",
      "epoch:43 step:33938 [D loss: 0.134561, acc: 98.44%] [G loss: 3.846344]\n",
      "epoch:43 step:33939 [D loss: 0.912196, acc: 46.09%] [G loss: 6.776172]\n",
      "epoch:43 step:33940 [D loss: 0.076205, acc: 100.00%] [G loss: 8.992598]\n",
      "epoch:43 step:33941 [D loss: 0.211750, acc: 96.88%] [G loss: 5.227033]\n",
      "epoch:43 step:33942 [D loss: 0.131323, acc: 99.22%] [G loss: 4.409461]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:43 step:33943 [D loss: 0.741535, acc: 52.34%] [G loss: 9.385293]\n",
      "epoch:43 step:33944 [D loss: 0.115555, acc: 99.22%] [G loss: 9.061599]\n",
      "epoch:43 step:33945 [D loss: 0.465426, acc: 71.88%] [G loss: 5.656427]\n",
      "epoch:43 step:33946 [D loss: 0.191042, acc: 96.09%] [G loss: 7.468690]\n",
      "epoch:43 step:33947 [D loss: 0.209768, acc: 96.09%] [G loss: 8.054406]\n",
      "epoch:43 step:33948 [D loss: 0.238673, acc: 96.09%] [G loss: 7.098312]\n",
      "epoch:43 step:33949 [D loss: 0.553752, acc: 69.53%] [G loss: 5.751334]\n",
      "epoch:43 step:33950 [D loss: 0.079863, acc: 100.00%] [G loss: 6.334043]\n",
      "epoch:43 step:33951 [D loss: 0.035293, acc: 100.00%] [G loss: 5.435095]\n",
      "epoch:43 step:33952 [D loss: 0.071671, acc: 100.00%] [G loss: 4.165201]\n",
      "epoch:43 step:33953 [D loss: 0.450266, acc: 82.81%] [G loss: 7.012054]\n",
      "epoch:43 step:33954 [D loss: 0.060174, acc: 100.00%] [G loss: 5.397531]\n",
      "epoch:43 step:33955 [D loss: 0.131876, acc: 100.00%] [G loss: 4.383020]\n",
      "epoch:43 step:33956 [D loss: 0.117545, acc: 98.44%] [G loss: 8.180936]\n",
      "epoch:43 step:33957 [D loss: 0.324573, acc: 89.84%] [G loss: 5.390101]\n",
      "epoch:43 step:33958 [D loss: 0.051625, acc: 100.00%] [G loss: 6.705856]\n",
      "epoch:43 step:33959 [D loss: 0.075628, acc: 100.00%] [G loss: 4.834456]\n",
      "epoch:43 step:33960 [D loss: 0.428372, acc: 89.06%] [G loss: 5.659093]\n",
      "epoch:43 step:33961 [D loss: 0.295426, acc: 93.75%] [G loss: 3.825367]\n",
      "epoch:43 step:33962 [D loss: 0.051946, acc: 100.00%] [G loss: 4.277849]\n",
      "epoch:43 step:33963 [D loss: 0.940004, acc: 52.34%] [G loss: 4.813929]\n",
      "epoch:43 step:33964 [D loss: 0.085211, acc: 99.22%] [G loss: 8.226352]\n",
      "epoch:43 step:33965 [D loss: 0.166589, acc: 94.53%] [G loss: 6.060174]\n",
      "epoch:43 step:33966 [D loss: 0.197006, acc: 96.88%] [G loss: 8.631191]\n",
      "epoch:43 step:33967 [D loss: 0.507966, acc: 76.56%] [G loss: 5.052199]\n",
      "epoch:43 step:33968 [D loss: 0.678947, acc: 67.19%] [G loss: 5.389017]\n",
      "epoch:43 step:33969 [D loss: 0.077611, acc: 99.22%] [G loss: 5.219658]\n",
      "epoch:43 step:33970 [D loss: 0.193066, acc: 97.66%] [G loss: 3.771625]\n",
      "epoch:43 step:33971 [D loss: 0.623106, acc: 57.81%] [G loss: 5.282932]\n",
      "epoch:43 step:33972 [D loss: 0.435311, acc: 75.00%] [G loss: 6.750930]\n",
      "epoch:43 step:33973 [D loss: 0.229230, acc: 94.53%] [G loss: 5.496599]\n",
      "epoch:43 step:33974 [D loss: 0.659669, acc: 62.50%] [G loss: 4.606255]\n",
      "epoch:43 step:33975 [D loss: 0.055768, acc: 100.00%] [G loss: 7.319061]\n",
      "epoch:43 step:33976 [D loss: 0.244099, acc: 92.97%] [G loss: 8.283352]\n",
      "epoch:43 step:33977 [D loss: 0.230052, acc: 93.75%] [G loss: 6.970677]\n",
      "epoch:43 step:33978 [D loss: 0.072974, acc: 99.22%] [G loss: 8.511058]\n",
      "epoch:43 step:33979 [D loss: 0.252408, acc: 91.41%] [G loss: 7.577087]\n",
      "epoch:43 step:33980 [D loss: 0.258947, acc: 86.72%] [G loss: 9.199492]\n",
      "epoch:43 step:33981 [D loss: 0.591544, acc: 59.38%] [G loss: 6.510742]\n",
      "epoch:43 step:33982 [D loss: 0.114572, acc: 100.00%] [G loss: 7.009385]\n",
      "epoch:43 step:33983 [D loss: 0.251310, acc: 100.00%] [G loss: 8.822334]\n",
      "epoch:43 step:33984 [D loss: 0.015469, acc: 100.00%] [G loss: 7.949238]\n",
      "epoch:43 step:33985 [D loss: 0.059485, acc: 100.00%] [G loss: 6.646769]\n",
      "epoch:43 step:33986 [D loss: 0.856844, acc: 53.91%] [G loss: 4.632565]\n",
      "epoch:43 step:33987 [D loss: 0.711123, acc: 56.25%] [G loss: 7.106453]\n",
      "epoch:43 step:33988 [D loss: 0.189683, acc: 96.09%] [G loss: 6.843463]\n",
      "epoch:43 step:33989 [D loss: 0.305629, acc: 89.06%] [G loss: 6.449628]\n",
      "epoch:43 step:33990 [D loss: 0.822754, acc: 53.91%] [G loss: 4.419847]\n",
      "epoch:43 step:33991 [D loss: 0.068375, acc: 100.00%] [G loss: 7.258128]\n",
      "epoch:43 step:33992 [D loss: 0.033443, acc: 100.00%] [G loss: 9.758695]\n",
      "epoch:43 step:33993 [D loss: 0.016306, acc: 100.00%] [G loss: 8.933056]\n",
      "epoch:43 step:33994 [D loss: 0.115023, acc: 97.66%] [G loss: 7.373859]\n",
      "epoch:43 step:33995 [D loss: 0.427735, acc: 71.09%] [G loss: 4.420977]\n",
      "epoch:43 step:33996 [D loss: 0.295313, acc: 87.50%] [G loss: 4.385344]\n",
      "epoch:43 step:33997 [D loss: 0.275474, acc: 96.09%] [G loss: 7.128983]\n",
      "epoch:43 step:33998 [D loss: 0.012903, acc: 100.00%] [G loss: 6.268382]\n",
      "epoch:43 step:33999 [D loss: 0.094774, acc: 100.00%] [G loss: 8.759229]\n",
      "epoch:43 step:34000 [D loss: 0.638378, acc: 60.16%] [G loss: 5.415235]\n",
      "##############\n",
      "[0.86569582 0.87482993 0.81547118 0.80032514 0.77488162 0.8237555\n",
      " 0.87896224 0.81164925 0.81339116 0.83922689]\n",
      "##########\n",
      "epoch:43 step:34001 [D loss: 0.240316, acc: 93.75%] [G loss: 4.293003]\n",
      "epoch:43 step:34002 [D loss: 0.919503, acc: 50.00%] [G loss: 7.891739]\n",
      "epoch:43 step:34003 [D loss: 0.119187, acc: 98.44%] [G loss: 6.172456]\n",
      "epoch:43 step:34004 [D loss: 0.273729, acc: 94.53%] [G loss: 8.887443]\n",
      "epoch:43 step:34005 [D loss: 0.081764, acc: 100.00%] [G loss: 3.360924]\n",
      "epoch:43 step:34006 [D loss: 0.287814, acc: 89.84%] [G loss: 2.716528]\n",
      "epoch:43 step:34007 [D loss: 0.104238, acc: 98.44%] [G loss: 5.871326]\n",
      "epoch:43 step:34008 [D loss: 0.337549, acc: 89.06%] [G loss: 3.727609]\n",
      "epoch:43 step:34009 [D loss: 0.073448, acc: 99.22%] [G loss: 6.233757]\n",
      "epoch:43 step:34010 [D loss: 0.174230, acc: 99.22%] [G loss: 5.930717]\n",
      "epoch:43 step:34011 [D loss: 0.073892, acc: 99.22%] [G loss: 7.267117]\n",
      "epoch:43 step:34012 [D loss: 0.158987, acc: 99.22%] [G loss: 4.737865]\n",
      "epoch:43 step:34013 [D loss: 0.485322, acc: 71.09%] [G loss: 3.702875]\n",
      "epoch:43 step:34014 [D loss: 0.798780, acc: 50.78%] [G loss: 10.627525]\n",
      "epoch:43 step:34015 [D loss: 0.379841, acc: 82.81%] [G loss: 2.983039]\n",
      "epoch:43 step:34016 [D loss: 0.078601, acc: 100.00%] [G loss: 6.210598]\n",
      "epoch:43 step:34017 [D loss: 0.028723, acc: 100.00%] [G loss: 6.691048]\n",
      "epoch:43 step:34018 [D loss: 0.174429, acc: 99.22%] [G loss: 5.928823]\n",
      "epoch:43 step:34019 [D loss: 0.153606, acc: 97.66%] [G loss: 6.685142]\n",
      "epoch:43 step:34020 [D loss: 0.482549, acc: 75.78%] [G loss: 6.884410]\n",
      "epoch:43 step:34021 [D loss: 0.015870, acc: 100.00%] [G loss: 4.911984]\n",
      "epoch:43 step:34022 [D loss: 1.588591, acc: 50.00%] [G loss: 11.827740]\n",
      "epoch:43 step:34023 [D loss: 1.118059, acc: 51.56%] [G loss: 8.025698]\n",
      "epoch:43 step:34024 [D loss: 0.174615, acc: 96.88%] [G loss: 7.197333]\n",
      "epoch:43 step:34025 [D loss: 0.312688, acc: 85.16%] [G loss: 2.687106]\n",
      "epoch:43 step:34026 [D loss: 0.183460, acc: 95.31%] [G loss: 5.261261]\n",
      "epoch:43 step:34027 [D loss: 0.052881, acc: 100.00%] [G loss: 4.929872]\n",
      "epoch:43 step:34028 [D loss: 0.416534, acc: 85.94%] [G loss: 7.402124]\n",
      "epoch:43 step:34029 [D loss: 0.147689, acc: 98.44%] [G loss: 3.974054]\n",
      "epoch:43 step:34030 [D loss: 1.598119, acc: 50.00%] [G loss: 5.750542]\n",
      "epoch:43 step:34031 [D loss: 0.106117, acc: 100.00%] [G loss: 4.446549]\n",
      "epoch:43 step:34032 [D loss: 0.214798, acc: 94.53%] [G loss: 5.960729]\n",
      "epoch:43 step:34033 [D loss: 0.012811, acc: 100.00%] [G loss: 6.869640]\n",
      "epoch:43 step:34034 [D loss: 0.108238, acc: 98.44%] [G loss: 8.479725]\n",
      "epoch:43 step:34035 [D loss: 0.554497, acc: 66.41%] [G loss: 6.681825]\n",
      "epoch:43 step:34036 [D loss: 0.854655, acc: 51.56%] [G loss: 3.797666]\n",
      "epoch:43 step:34037 [D loss: 0.114974, acc: 99.22%] [G loss: 4.536080]\n",
      "epoch:43 step:34038 [D loss: 0.159313, acc: 99.22%] [G loss: 8.445030]\n",
      "epoch:43 step:34039 [D loss: 0.406301, acc: 77.34%] [G loss: 5.378756]\n",
      "epoch:43 step:34040 [D loss: 0.650489, acc: 59.38%] [G loss: 4.655527]\n",
      "epoch:43 step:34041 [D loss: 0.444961, acc: 82.03%] [G loss: 3.955589]\n",
      "epoch:43 step:34042 [D loss: 0.009492, acc: 100.00%] [G loss: 5.782529]\n",
      "epoch:43 step:34043 [D loss: 0.140311, acc: 98.44%] [G loss: 6.592484]\n",
      "epoch:43 step:34044 [D loss: 0.078695, acc: 100.00%] [G loss: 8.659986]\n",
      "epoch:43 step:34045 [D loss: 0.041215, acc: 100.00%] [G loss: 6.585168]\n",
      "epoch:43 step:34046 [D loss: 0.799531, acc: 50.78%] [G loss: 7.008240]\n",
      "epoch:43 step:34047 [D loss: 0.123239, acc: 99.22%] [G loss: 5.973261]\n",
      "epoch:43 step:34048 [D loss: 0.067985, acc: 100.00%] [G loss: 4.410064]\n",
      "epoch:43 step:34049 [D loss: 0.222076, acc: 93.75%] [G loss: 5.427350]\n",
      "epoch:43 step:34050 [D loss: 0.165038, acc: 97.66%] [G loss: 3.826777]\n",
      "epoch:43 step:34051 [D loss: 0.365709, acc: 92.97%] [G loss: 6.875070]\n",
      "epoch:43 step:34052 [D loss: 0.062033, acc: 99.22%] [G loss: 4.479909]\n",
      "epoch:43 step:34053 [D loss: 0.094481, acc: 99.22%] [G loss: 7.187257]\n",
      "epoch:43 step:34054 [D loss: 0.564962, acc: 63.28%] [G loss: 9.040925]\n",
      "epoch:43 step:34055 [D loss: 0.045210, acc: 100.00%] [G loss: 5.466716]\n",
      "epoch:43 step:34056 [D loss: 0.512769, acc: 60.16%] [G loss: 5.177885]\n",
      "epoch:43 step:34057 [D loss: 0.380718, acc: 79.69%] [G loss: 4.251368]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:43 step:34058 [D loss: 0.101842, acc: 99.22%] [G loss: 5.072269]\n",
      "epoch:43 step:34059 [D loss: 0.086222, acc: 98.44%] [G loss: 6.378050]\n",
      "epoch:43 step:34060 [D loss: 0.519271, acc: 71.88%] [G loss: 3.678126]\n",
      "epoch:43 step:34061 [D loss: 0.003810, acc: 100.00%] [G loss: 4.783190]\n",
      "epoch:43 step:34062 [D loss: 0.313746, acc: 90.62%] [G loss: 6.896308]\n",
      "epoch:43 step:34063 [D loss: 0.739797, acc: 50.00%] [G loss: 4.310297]\n",
      "epoch:43 step:34064 [D loss: 1.018754, acc: 50.00%] [G loss: 6.863888]\n",
      "epoch:43 step:34065 [D loss: 0.900304, acc: 50.78%] [G loss: 7.554729]\n",
      "epoch:43 step:34066 [D loss: 0.808133, acc: 55.47%] [G loss: 4.252282]\n",
      "epoch:43 step:34067 [D loss: 0.430191, acc: 83.59%] [G loss: 5.094664]\n",
      "epoch:43 step:34068 [D loss: 0.139329, acc: 98.44%] [G loss: 5.955882]\n",
      "epoch:43 step:34069 [D loss: 0.138336, acc: 99.22%] [G loss: 6.205432]\n",
      "epoch:43 step:34070 [D loss: 0.062090, acc: 100.00%] [G loss: 5.679786]\n",
      "epoch:43 step:34071 [D loss: 0.144246, acc: 99.22%] [G loss: 6.633171]\n",
      "epoch:43 step:34072 [D loss: 0.673241, acc: 62.50%] [G loss: 5.162657]\n",
      "epoch:43 step:34073 [D loss: 0.205425, acc: 94.53%] [G loss: 7.192241]\n",
      "epoch:43 step:34074 [D loss: 0.261965, acc: 90.62%] [G loss: 7.568781]\n",
      "epoch:43 step:34075 [D loss: 0.108270, acc: 99.22%] [G loss: 4.806249]\n",
      "epoch:43 step:34076 [D loss: 0.263491, acc: 96.09%] [G loss: 1.947627]\n",
      "epoch:43 step:34077 [D loss: 0.364078, acc: 82.81%] [G loss: 7.496617]\n",
      "epoch:43 step:34078 [D loss: 0.357477, acc: 83.59%] [G loss: 5.166746]\n",
      "epoch:43 step:34079 [D loss: 1.248410, acc: 50.00%] [G loss: 9.404736]\n",
      "epoch:43 step:34080 [D loss: 0.742296, acc: 57.03%] [G loss: 10.199911]\n",
      "epoch:43 step:34081 [D loss: 0.088056, acc: 100.00%] [G loss: 3.430995]\n",
      "epoch:43 step:34082 [D loss: 0.394552, acc: 86.72%] [G loss: 5.678489]\n",
      "epoch:43 step:34083 [D loss: 0.157245, acc: 96.88%] [G loss: 7.537766]\n",
      "epoch:43 step:34084 [D loss: 0.073599, acc: 100.00%] [G loss: 4.235699]\n",
      "epoch:43 step:34085 [D loss: 0.227570, acc: 94.53%] [G loss: 6.582973]\n",
      "epoch:43 step:34086 [D loss: 0.535049, acc: 63.28%] [G loss: 6.334978]\n",
      "epoch:43 step:34087 [D loss: 0.553456, acc: 60.16%] [G loss: 9.456896]\n",
      "epoch:43 step:34088 [D loss: 0.537591, acc: 68.75%] [G loss: 6.708663]\n",
      "epoch:43 step:34089 [D loss: 0.261320, acc: 89.84%] [G loss: 4.136680]\n",
      "epoch:43 step:34090 [D loss: 0.553158, acc: 59.38%] [G loss: 4.946220]\n",
      "epoch:43 step:34091 [D loss: 0.416296, acc: 87.50%] [G loss: 5.162648]\n",
      "epoch:43 step:34092 [D loss: 0.510505, acc: 66.41%] [G loss: 3.302159]\n",
      "epoch:43 step:34093 [D loss: 0.327478, acc: 91.41%] [G loss: 4.354720]\n",
      "epoch:43 step:34094 [D loss: 0.026162, acc: 99.22%] [G loss: 7.777294]\n",
      "epoch:43 step:34095 [D loss: 0.084141, acc: 100.00%] [G loss: 4.247488]\n",
      "epoch:43 step:34096 [D loss: 0.216559, acc: 92.97%] [G loss: 6.692817]\n",
      "epoch:43 step:34097 [D loss: 0.521875, acc: 68.75%] [G loss: 7.967152]\n",
      "epoch:43 step:34098 [D loss: 0.196983, acc: 94.53%] [G loss: 4.705724]\n",
      "epoch:43 step:34099 [D loss: 0.386130, acc: 83.59%] [G loss: 4.301225]\n",
      "epoch:43 step:34100 [D loss: 0.184265, acc: 94.53%] [G loss: 4.541090]\n",
      "epoch:43 step:34101 [D loss: 0.025943, acc: 100.00%] [G loss: 5.915847]\n",
      "epoch:43 step:34102 [D loss: 0.166626, acc: 99.22%] [G loss: 5.569576]\n",
      "epoch:43 step:34103 [D loss: 0.376660, acc: 79.69%] [G loss: 9.843565]\n",
      "epoch:43 step:34104 [D loss: 0.028238, acc: 100.00%] [G loss: 8.384290]\n",
      "epoch:43 step:34105 [D loss: 1.063289, acc: 51.56%] [G loss: 5.551275]\n",
      "epoch:43 step:34106 [D loss: 0.299044, acc: 90.62%] [G loss: 5.435573]\n",
      "epoch:43 step:34107 [D loss: 0.322000, acc: 91.41%] [G loss: 7.494145]\n",
      "epoch:43 step:34108 [D loss: 0.351973, acc: 89.84%] [G loss: 5.282207]\n",
      "epoch:43 step:34109 [D loss: 0.028572, acc: 99.22%] [G loss: 5.548811]\n",
      "epoch:43 step:34110 [D loss: 0.221120, acc: 96.88%] [G loss: 4.249557]\n",
      "epoch:43 step:34111 [D loss: 0.137720, acc: 100.00%] [G loss: 4.015098]\n",
      "epoch:43 step:34112 [D loss: 0.059861, acc: 100.00%] [G loss: 7.978501]\n",
      "epoch:43 step:34113 [D loss: 1.248279, acc: 14.06%] [G loss: 7.477662]\n",
      "epoch:43 step:34114 [D loss: 0.563301, acc: 59.38%] [G loss: 3.093925]\n",
      "epoch:43 step:34115 [D loss: 0.918122, acc: 53.12%] [G loss: 4.109760]\n",
      "epoch:43 step:34116 [D loss: 0.368533, acc: 89.84%] [G loss: 6.975153]\n",
      "epoch:43 step:34117 [D loss: 0.603796, acc: 64.84%] [G loss: 7.860641]\n",
      "epoch:43 step:34118 [D loss: 1.158378, acc: 50.00%] [G loss: 5.566710]\n",
      "epoch:43 step:34119 [D loss: 0.218753, acc: 97.66%] [G loss: 5.913374]\n",
      "epoch:43 step:34120 [D loss: 1.646223, acc: 33.59%] [G loss: 6.779292]\n",
      "epoch:43 step:34121 [D loss: 0.012851, acc: 100.00%] [G loss: 5.130800]\n",
      "epoch:43 step:34122 [D loss: 0.167067, acc: 97.66%] [G loss: 6.075595]\n",
      "epoch:43 step:34123 [D loss: 0.077321, acc: 99.22%] [G loss: 3.384002]\n",
      "epoch:43 step:34124 [D loss: 0.825808, acc: 50.78%] [G loss: 2.513059]\n",
      "epoch:43 step:34125 [D loss: 0.198926, acc: 93.75%] [G loss: 8.896375]\n",
      "epoch:43 step:34126 [D loss: 0.711564, acc: 56.25%] [G loss: 3.998498]\n",
      "epoch:43 step:34127 [D loss: 0.167356, acc: 95.31%] [G loss: 6.618778]\n",
      "epoch:43 step:34128 [D loss: 1.028440, acc: 35.16%] [G loss: 2.850173]\n",
      "epoch:43 step:34129 [D loss: 0.350786, acc: 90.62%] [G loss: 5.427428]\n",
      "epoch:43 step:34130 [D loss: 0.086419, acc: 99.22%] [G loss: 9.028675]\n",
      "epoch:43 step:34131 [D loss: 0.370060, acc: 81.25%] [G loss: 2.939004]\n",
      "epoch:43 step:34132 [D loss: 0.160138, acc: 100.00%] [G loss: 6.646544]\n",
      "epoch:43 step:34133 [D loss: 0.042939, acc: 100.00%] [G loss: 5.964439]\n",
      "epoch:43 step:34134 [D loss: 0.114272, acc: 98.44%] [G loss: 8.494701]\n",
      "epoch:43 step:34135 [D loss: 0.034374, acc: 100.00%] [G loss: 7.162904]\n",
      "epoch:43 step:34136 [D loss: 1.841564, acc: 49.22%] [G loss: 6.916330]\n",
      "epoch:43 step:34137 [D loss: 0.151755, acc: 98.44%] [G loss: 2.321974]\n",
      "epoch:43 step:34138 [D loss: 1.365682, acc: 49.22%] [G loss: 9.285817]\n",
      "epoch:43 step:34139 [D loss: 0.389880, acc: 75.00%] [G loss: 8.250690]\n",
      "epoch:43 step:34140 [D loss: 0.310152, acc: 93.75%] [G loss: 6.504284]\n",
      "epoch:43 step:34141 [D loss: 0.150353, acc: 97.66%] [G loss: 5.827075]\n",
      "epoch:43 step:34142 [D loss: 0.831935, acc: 50.00%] [G loss: 4.581777]\n",
      "epoch:43 step:34143 [D loss: 0.230254, acc: 97.66%] [G loss: 7.473275]\n",
      "epoch:43 step:34144 [D loss: 0.127930, acc: 98.44%] [G loss: 6.807113]\n",
      "epoch:43 step:34145 [D loss: 0.676410, acc: 60.16%] [G loss: 5.771790]\n",
      "epoch:43 step:34146 [D loss: 0.123110, acc: 98.44%] [G loss: 3.265005]\n",
      "epoch:43 step:34147 [D loss: 0.117087, acc: 100.00%] [G loss: 8.419215]\n",
      "epoch:43 step:34148 [D loss: 0.179490, acc: 98.44%] [G loss: 8.017674]\n",
      "epoch:43 step:34149 [D loss: 0.074449, acc: 100.00%] [G loss: 4.976853]\n",
      "epoch:43 step:34150 [D loss: 0.061555, acc: 100.00%] [G loss: 3.834105]\n",
      "epoch:43 step:34151 [D loss: 1.157396, acc: 50.78%] [G loss: 3.812921]\n",
      "epoch:43 step:34152 [D loss: 0.417021, acc: 75.00%] [G loss: 9.433968]\n",
      "epoch:43 step:34153 [D loss: 0.445480, acc: 79.69%] [G loss: 6.360856]\n",
      "epoch:43 step:34154 [D loss: 0.457448, acc: 80.47%] [G loss: 6.117256]\n",
      "epoch:43 step:34155 [D loss: 0.128524, acc: 97.66%] [G loss: 4.130522]\n",
      "epoch:43 step:34156 [D loss: 0.207513, acc: 94.53%] [G loss: 8.444382]\n",
      "epoch:43 step:34157 [D loss: 0.369949, acc: 75.78%] [G loss: 6.276086]\n",
      "epoch:43 step:34158 [D loss: 0.654079, acc: 60.16%] [G loss: 2.480221]\n",
      "epoch:43 step:34159 [D loss: 0.107138, acc: 98.44%] [G loss: 5.892443]\n",
      "epoch:43 step:34160 [D loss: 0.599708, acc: 64.06%] [G loss: 7.648286]\n",
      "epoch:43 step:34161 [D loss: 0.036340, acc: 100.00%] [G loss: 5.789490]\n",
      "epoch:43 step:34162 [D loss: 0.069130, acc: 100.00%] [G loss: 5.309276]\n",
      "epoch:43 step:34163 [D loss: 0.154405, acc: 97.66%] [G loss: 4.411452]\n",
      "epoch:43 step:34164 [D loss: 0.065404, acc: 100.00%] [G loss: 9.488121]\n",
      "epoch:43 step:34165 [D loss: 0.146881, acc: 99.22%] [G loss: 6.621035]\n",
      "epoch:43 step:34166 [D loss: 0.240840, acc: 95.31%] [G loss: 7.822564]\n",
      "epoch:43 step:34167 [D loss: 0.024812, acc: 100.00%] [G loss: 3.943651]\n",
      "epoch:43 step:34168 [D loss: 0.345377, acc: 87.50%] [G loss: 7.193618]\n",
      "epoch:43 step:34169 [D loss: 0.081625, acc: 99.22%] [G loss: 5.366220]\n",
      "epoch:43 step:34170 [D loss: 0.236003, acc: 96.09%] [G loss: 5.221238]\n",
      "epoch:43 step:34171 [D loss: 1.396432, acc: 14.84%] [G loss: 7.040357]\n",
      "epoch:43 step:34172 [D loss: 0.041094, acc: 100.00%] [G loss: 5.083610]\n",
      "epoch:43 step:34173 [D loss: 0.041133, acc: 100.00%] [G loss: 5.077673]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:43 step:34174 [D loss: 0.053176, acc: 99.22%] [G loss: 7.346033]\n",
      "epoch:43 step:34175 [D loss: 0.127666, acc: 99.22%] [G loss: 5.470176]\n",
      "epoch:43 step:34176 [D loss: 0.593450, acc: 64.06%] [G loss: 8.409986]\n",
      "epoch:43 step:34177 [D loss: 0.227732, acc: 89.06%] [G loss: 7.956021]\n",
      "epoch:43 step:34178 [D loss: 0.581314, acc: 58.59%] [G loss: 7.030436]\n",
      "epoch:43 step:34179 [D loss: 0.282109, acc: 95.31%] [G loss: 3.655849]\n",
      "epoch:43 step:34180 [D loss: 0.187146, acc: 97.66%] [G loss: 8.125329]\n",
      "epoch:43 step:34181 [D loss: 0.918006, acc: 39.84%] [G loss: 8.200992]\n",
      "epoch:43 step:34182 [D loss: 0.166674, acc: 98.44%] [G loss: 3.616771]\n",
      "epoch:43 step:34183 [D loss: 0.032879, acc: 100.00%] [G loss: 5.255659]\n",
      "epoch:43 step:34184 [D loss: 0.675769, acc: 63.28%] [G loss: 4.033855]\n",
      "epoch:43 step:34185 [D loss: 0.674789, acc: 53.91%] [G loss: 6.601188]\n",
      "epoch:43 step:34186 [D loss: 0.107605, acc: 98.44%] [G loss: 6.340364]\n",
      "epoch:43 step:34187 [D loss: 0.438185, acc: 72.66%] [G loss: 8.444311]\n",
      "epoch:43 step:34188 [D loss: 2.003179, acc: 3.12%] [G loss: 6.443927]\n",
      "epoch:43 step:34189 [D loss: 0.096936, acc: 99.22%] [G loss: 6.614671]\n",
      "epoch:43 step:34190 [D loss: 0.308524, acc: 88.28%] [G loss: 4.315060]\n",
      "epoch:43 step:34191 [D loss: 0.312749, acc: 82.81%] [G loss: 5.561635]\n",
      "epoch:43 step:34192 [D loss: 0.627262, acc: 67.97%] [G loss: 5.304532]\n",
      "epoch:43 step:34193 [D loss: 0.754007, acc: 53.12%] [G loss: 7.347436]\n",
      "epoch:43 step:34194 [D loss: 0.194289, acc: 99.22%] [G loss: 6.524884]\n",
      "epoch:43 step:34195 [D loss: 0.368602, acc: 85.16%] [G loss: 2.422059]\n",
      "epoch:43 step:34196 [D loss: 0.634207, acc: 61.72%] [G loss: 7.680830]\n",
      "epoch:43 step:34197 [D loss: 0.007380, acc: 100.00%] [G loss: 8.848440]\n",
      "epoch:43 step:34198 [D loss: 1.116900, acc: 51.56%] [G loss: 6.683868]\n",
      "epoch:43 step:34199 [D loss: 0.002673, acc: 100.00%] [G loss: 7.849749]\n",
      "epoch:43 step:34200 [D loss: 0.495632, acc: 73.44%] [G loss: 5.920887]\n",
      "##############\n",
      "[0.8711232  0.84410371 0.83212207 0.81657175 0.7785277  0.84119091\n",
      " 0.89461867 0.81400934 0.81906939 0.81325679]\n",
      "##########\n",
      "epoch:43 step:34201 [D loss: 1.048821, acc: 50.00%] [G loss: 6.676815]\n",
      "epoch:43 step:34202 [D loss: 0.842555, acc: 43.75%] [G loss: 6.772597]\n",
      "epoch:43 step:34203 [D loss: 0.021482, acc: 100.00%] [G loss: 9.752537]\n",
      "epoch:43 step:34204 [D loss: 0.170037, acc: 97.66%] [G loss: 6.204643]\n",
      "epoch:43 step:34205 [D loss: 0.478676, acc: 72.66%] [G loss: 2.798275]\n",
      "epoch:43 step:34206 [D loss: 0.610768, acc: 64.06%] [G loss: 7.069722]\n",
      "epoch:43 step:34207 [D loss: 0.134449, acc: 99.22%] [G loss: 6.529831]\n",
      "epoch:43 step:34208 [D loss: 1.301098, acc: 50.00%] [G loss: 12.731394]\n",
      "epoch:43 step:34209 [D loss: 0.426616, acc: 85.16%] [G loss: 5.263519]\n",
      "epoch:43 step:34210 [D loss: 0.449805, acc: 82.81%] [G loss: 5.336401]\n",
      "epoch:43 step:34211 [D loss: 1.405860, acc: 50.00%] [G loss: 6.207571]\n",
      "epoch:43 step:34212 [D loss: 0.223004, acc: 96.88%] [G loss: 5.609301]\n",
      "epoch:43 step:34213 [D loss: 0.386670, acc: 85.94%] [G loss: 8.229506]\n",
      "epoch:43 step:34214 [D loss: 0.243756, acc: 94.53%] [G loss: 8.111937]\n",
      "epoch:43 step:34215 [D loss: 0.305509, acc: 92.19%] [G loss: 8.333385]\n",
      "epoch:43 step:34216 [D loss: 0.129338, acc: 100.00%] [G loss: 5.064846]\n",
      "epoch:43 step:34217 [D loss: 0.191560, acc: 94.53%] [G loss: 4.854015]\n",
      "epoch:43 step:34218 [D loss: 0.414981, acc: 81.25%] [G loss: 6.002011]\n",
      "epoch:43 step:34219 [D loss: 0.287340, acc: 89.06%] [G loss: 5.802910]\n",
      "epoch:43 step:34220 [D loss: 0.228550, acc: 93.75%] [G loss: 6.425878]\n",
      "epoch:43 step:34221 [D loss: 0.470049, acc: 73.44%] [G loss: 3.842029]\n",
      "epoch:43 step:34222 [D loss: 0.118554, acc: 97.66%] [G loss: 7.738697]\n",
      "epoch:43 step:34223 [D loss: 0.083348, acc: 98.44%] [G loss: 11.640985]\n",
      "epoch:43 step:34224 [D loss: 0.184067, acc: 97.66%] [G loss: 5.456957]\n",
      "epoch:43 step:34225 [D loss: 0.120435, acc: 99.22%] [G loss: 4.563193]\n",
      "epoch:43 step:34226 [D loss: 0.578059, acc: 71.09%] [G loss: 8.144082]\n",
      "epoch:43 step:34227 [D loss: 0.501586, acc: 75.78%] [G loss: 8.300606]\n",
      "epoch:43 step:34228 [D loss: 0.614970, acc: 71.09%] [G loss: 8.129605]\n",
      "epoch:43 step:34229 [D loss: 0.490422, acc: 82.03%] [G loss: 7.793611]\n",
      "epoch:43 step:34230 [D loss: 0.155269, acc: 98.44%] [G loss: 7.212488]\n",
      "epoch:43 step:34231 [D loss: 0.741538, acc: 58.59%] [G loss: 8.593222]\n",
      "epoch:43 step:34232 [D loss: 0.421018, acc: 78.91%] [G loss: 6.211998]\n",
      "epoch:43 step:34233 [D loss: 0.374802, acc: 79.69%] [G loss: 4.735095]\n",
      "epoch:43 step:34234 [D loss: 0.289841, acc: 86.72%] [G loss: 8.585318]\n",
      "epoch:43 step:34235 [D loss: 0.274313, acc: 96.88%] [G loss: 6.771517]\n",
      "epoch:43 step:34236 [D loss: 1.008324, acc: 50.78%] [G loss: 6.450557]\n",
      "epoch:43 step:34237 [D loss: 0.205589, acc: 95.31%] [G loss: 5.558677]\n",
      "epoch:43 step:34238 [D loss: 0.131298, acc: 98.44%] [G loss: 4.978850]\n",
      "epoch:43 step:34239 [D loss: 1.096005, acc: 49.22%] [G loss: 8.325838]\n",
      "epoch:43 step:34240 [D loss: 0.107629, acc: 99.22%] [G loss: 5.612572]\n",
      "epoch:43 step:34241 [D loss: 2.256597, acc: 3.91%] [G loss: 7.046355]\n",
      "epoch:43 step:34242 [D loss: 0.085633, acc: 100.00%] [G loss: 7.989584]\n",
      "epoch:43 step:34243 [D loss: 0.174948, acc: 98.44%] [G loss: 4.333937]\n",
      "epoch:43 step:34244 [D loss: 0.143194, acc: 98.44%] [G loss: 5.460910]\n",
      "epoch:43 step:34245 [D loss: 0.054895, acc: 100.00%] [G loss: 4.459724]\n",
      "epoch:43 step:34246 [D loss: 0.075149, acc: 99.22%] [G loss: 8.311646]\n",
      "epoch:43 step:34247 [D loss: 0.342170, acc: 85.94%] [G loss: 6.339761]\n",
      "epoch:43 step:34248 [D loss: 0.279658, acc: 92.19%] [G loss: 3.771190]\n",
      "epoch:43 step:34249 [D loss: 0.098120, acc: 99.22%] [G loss: 5.037179]\n",
      "epoch:43 step:34250 [D loss: 0.979961, acc: 51.56%] [G loss: 10.582591]\n",
      "epoch:43 step:34251 [D loss: 0.975253, acc: 50.78%] [G loss: 6.700905]\n",
      "epoch:43 step:34252 [D loss: 0.206585, acc: 95.31%] [G loss: 7.457483]\n",
      "epoch:43 step:34253 [D loss: 0.084192, acc: 100.00%] [G loss: 5.280280]\n",
      "epoch:43 step:34254 [D loss: 0.161724, acc: 96.09%] [G loss: 10.042708]\n",
      "epoch:43 step:34255 [D loss: 0.153885, acc: 96.09%] [G loss: 5.375329]\n",
      "epoch:43 step:34256 [D loss: 0.341235, acc: 95.31%] [G loss: 5.791741]\n",
      "epoch:43 step:34257 [D loss: 0.045444, acc: 100.00%] [G loss: 6.456201]\n",
      "epoch:43 step:34258 [D loss: 0.275017, acc: 90.62%] [G loss: 3.128928]\n",
      "epoch:43 step:34259 [D loss: 0.023361, acc: 100.00%] [G loss: 5.868504]\n",
      "epoch:43 step:34260 [D loss: 0.060022, acc: 100.00%] [G loss: 7.145311]\n",
      "epoch:43 step:34261 [D loss: 0.151443, acc: 98.44%] [G loss: 6.153324]\n",
      "epoch:43 step:34262 [D loss: 0.397991, acc: 76.56%] [G loss: 9.872436]\n",
      "epoch:43 step:34263 [D loss: 0.397928, acc: 78.91%] [G loss: 3.954559]\n",
      "epoch:43 step:34264 [D loss: 0.341344, acc: 92.19%] [G loss: 6.727589]\n",
      "epoch:43 step:34265 [D loss: 0.578683, acc: 67.19%] [G loss: 4.062592]\n",
      "epoch:43 step:34266 [D loss: 0.364871, acc: 77.34%] [G loss: 6.012330]\n",
      "epoch:43 step:34267 [D loss: 0.251421, acc: 88.28%] [G loss: 6.852361]\n",
      "epoch:43 step:34268 [D loss: 0.281042, acc: 90.62%] [G loss: 7.047408]\n",
      "epoch:43 step:34269 [D loss: 1.209134, acc: 50.78%] [G loss: 7.399911]\n",
      "epoch:43 step:34270 [D loss: 0.472153, acc: 79.69%] [G loss: 5.539322]\n",
      "epoch:43 step:34271 [D loss: 0.627791, acc: 58.59%] [G loss: 8.497555]\n",
      "epoch:43 step:34272 [D loss: 0.237668, acc: 91.41%] [G loss: 5.352177]\n",
      "epoch:43 step:34273 [D loss: 0.268913, acc: 85.16%] [G loss: 7.275654]\n",
      "epoch:43 step:34274 [D loss: 1.225192, acc: 50.00%] [G loss: 5.171534]\n",
      "epoch:43 step:34275 [D loss: 0.656959, acc: 59.38%] [G loss: 8.557673]\n",
      "epoch:43 step:34276 [D loss: 0.140885, acc: 99.22%] [G loss: 5.225942]\n",
      "epoch:43 step:34277 [D loss: 0.111999, acc: 99.22%] [G loss: 6.042443]\n",
      "epoch:43 step:34278 [D loss: 0.056711, acc: 100.00%] [G loss: 3.489471]\n",
      "epoch:43 step:34279 [D loss: 0.594859, acc: 67.19%] [G loss: 6.841485]\n",
      "epoch:43 step:34280 [D loss: 0.132157, acc: 99.22%] [G loss: 4.214268]\n",
      "epoch:43 step:34281 [D loss: 0.085000, acc: 99.22%] [G loss: 5.925169]\n",
      "epoch:43 step:34282 [D loss: 0.135466, acc: 96.88%] [G loss: 5.061512]\n",
      "epoch:43 step:34283 [D loss: 0.072596, acc: 100.00%] [G loss: 2.766270]\n",
      "epoch:43 step:34284 [D loss: 0.661230, acc: 54.69%] [G loss: 6.675302]\n",
      "epoch:43 step:34285 [D loss: 0.232706, acc: 93.75%] [G loss: 6.740964]\n",
      "epoch:43 step:34286 [D loss: 0.063689, acc: 100.00%] [G loss: 4.874662]\n",
      "epoch:43 step:34287 [D loss: 0.253786, acc: 93.75%] [G loss: 9.564747]\n",
      "epoch:43 step:34288 [D loss: 0.266477, acc: 87.50%] [G loss: 4.204150]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:43 step:34289 [D loss: 0.131357, acc: 98.44%] [G loss: 4.556299]\n",
      "epoch:43 step:34290 [D loss: 1.016890, acc: 50.78%] [G loss: 10.520165]\n",
      "epoch:43 step:34291 [D loss: 0.039888, acc: 100.00%] [G loss: 9.647672]\n",
      "epoch:43 step:34292 [D loss: 0.051762, acc: 100.00%] [G loss: 3.068187]\n",
      "epoch:43 step:34293 [D loss: 0.219340, acc: 93.75%] [G loss: 2.902796]\n",
      "epoch:43 step:34294 [D loss: 0.044257, acc: 100.00%] [G loss: 10.970505]\n",
      "epoch:43 step:34295 [D loss: 0.200907, acc: 96.88%] [G loss: 5.916763]\n",
      "epoch:43 step:34296 [D loss: 0.215725, acc: 96.88%] [G loss: 7.835303]\n",
      "epoch:43 step:34297 [D loss: 0.256178, acc: 95.31%] [G loss: 5.192904]\n",
      "epoch:43 step:34298 [D loss: 0.566792, acc: 57.81%] [G loss: 8.614683]\n",
      "epoch:43 step:34299 [D loss: 0.855324, acc: 53.12%] [G loss: 5.470448]\n",
      "epoch:43 step:34300 [D loss: 0.118202, acc: 97.66%] [G loss: 8.218629]\n",
      "epoch:43 step:34301 [D loss: 0.478473, acc: 68.75%] [G loss: 8.857935]\n",
      "epoch:43 step:34302 [D loss: 0.270507, acc: 92.19%] [G loss: 5.597202]\n",
      "epoch:43 step:34303 [D loss: 0.836165, acc: 46.09%] [G loss: 4.111831]\n",
      "epoch:43 step:34304 [D loss: 0.050878, acc: 100.00%] [G loss: 7.898681]\n",
      "epoch:43 step:34305 [D loss: 0.166960, acc: 99.22%] [G loss: 2.246957]\n",
      "epoch:43 step:34306 [D loss: 0.022087, acc: 100.00%] [G loss: 5.166911]\n",
      "epoch:43 step:34307 [D loss: 0.366388, acc: 89.06%] [G loss: 4.366079]\n",
      "epoch:43 step:34308 [D loss: 0.198445, acc: 93.75%] [G loss: 7.216770]\n",
      "epoch:43 step:34309 [D loss: 0.070335, acc: 100.00%] [G loss: 8.121238]\n",
      "epoch:43 step:34310 [D loss: 0.544797, acc: 69.53%] [G loss: 3.697819]\n",
      "epoch:43 step:34311 [D loss: 0.082258, acc: 100.00%] [G loss: 5.064792]\n",
      "epoch:43 step:34312 [D loss: 0.375585, acc: 81.25%] [G loss: 7.588066]\n",
      "epoch:43 step:34313 [D loss: 0.172381, acc: 98.44%] [G loss: 3.041459]\n",
      "epoch:43 step:34314 [D loss: 0.875665, acc: 44.53%] [G loss: 5.418465]\n",
      "epoch:43 step:34315 [D loss: 0.257211, acc: 91.41%] [G loss: 2.089865]\n",
      "epoch:43 step:34316 [D loss: 0.266851, acc: 91.41%] [G loss: 5.783535]\n",
      "epoch:43 step:34317 [D loss: 0.238196, acc: 95.31%] [G loss: 5.463857]\n",
      "epoch:43 step:34318 [D loss: 0.019489, acc: 100.00%] [G loss: 6.420192]\n",
      "epoch:43 step:34319 [D loss: 0.027347, acc: 100.00%] [G loss: 5.336465]\n",
      "epoch:43 step:34320 [D loss: 0.036020, acc: 100.00%] [G loss: 6.203105]\n",
      "epoch:43 step:34321 [D loss: 0.347710, acc: 82.03%] [G loss: 4.494734]\n",
      "epoch:43 step:34322 [D loss: 0.233296, acc: 94.53%] [G loss: 2.010140]\n",
      "epoch:43 step:34323 [D loss: 0.124810, acc: 100.00%] [G loss: 4.828515]\n",
      "epoch:43 step:34324 [D loss: 0.167730, acc: 97.66%] [G loss: 5.134085]\n",
      "epoch:43 step:34325 [D loss: 0.195172, acc: 98.44%] [G loss: 4.488337]\n",
      "epoch:43 step:34326 [D loss: 0.073723, acc: 100.00%] [G loss: 4.207122]\n",
      "epoch:43 step:34327 [D loss: 0.321356, acc: 92.97%] [G loss: 4.342966]\n",
      "epoch:43 step:34328 [D loss: 0.140222, acc: 98.44%] [G loss: 7.078231]\n",
      "epoch:43 step:34329 [D loss: 0.113192, acc: 100.00%] [G loss: 6.205366]\n",
      "epoch:43 step:34330 [D loss: 0.578811, acc: 65.62%] [G loss: 7.425725]\n",
      "epoch:43 step:34331 [D loss: 0.079388, acc: 100.00%] [G loss: 4.816938]\n",
      "epoch:43 step:34332 [D loss: 0.082794, acc: 100.00%] [G loss: 5.708692]\n",
      "epoch:43 step:34333 [D loss: 0.589913, acc: 67.97%] [G loss: 4.315041]\n",
      "epoch:43 step:34334 [D loss: 0.024164, acc: 100.00%] [G loss: 5.831278]\n",
      "epoch:43 step:34335 [D loss: 0.259487, acc: 94.53%] [G loss: 7.678713]\n",
      "epoch:43 step:34336 [D loss: 0.493608, acc: 78.91%] [G loss: 7.328171]\n",
      "epoch:43 step:34337 [D loss: 0.061996, acc: 100.00%] [G loss: 1.662551]\n",
      "epoch:43 step:34338 [D loss: 0.184668, acc: 97.66%] [G loss: 7.527915]\n",
      "epoch:43 step:34339 [D loss: 0.232799, acc: 90.62%] [G loss: 5.257187]\n",
      "epoch:43 step:34340 [D loss: 0.181797, acc: 95.31%] [G loss: 7.013924]\n",
      "epoch:43 step:34341 [D loss: 1.260010, acc: 50.00%] [G loss: 8.390693]\n",
      "epoch:43 step:34342 [D loss: 0.340068, acc: 85.16%] [G loss: 5.366463]\n",
      "epoch:43 step:34343 [D loss: 0.299448, acc: 83.59%] [G loss: 9.450425]\n",
      "epoch:43 step:34344 [D loss: 0.024381, acc: 100.00%] [G loss: 7.148456]\n",
      "epoch:43 step:34345 [D loss: 0.356217, acc: 83.59%] [G loss: 6.698305]\n",
      "epoch:43 step:34346 [D loss: 0.205563, acc: 96.09%] [G loss: 6.645713]\n",
      "epoch:43 step:34347 [D loss: 0.102346, acc: 98.44%] [G loss: 8.170927]\n",
      "epoch:43 step:34348 [D loss: 0.054287, acc: 99.22%] [G loss: 6.306208]\n",
      "epoch:43 step:34349 [D loss: 0.331757, acc: 90.62%] [G loss: 6.134328]\n",
      "epoch:43 step:34350 [D loss: 0.122906, acc: 96.88%] [G loss: 6.808318]\n",
      "epoch:43 step:34351 [D loss: 0.081866, acc: 99.22%] [G loss: 5.656423]\n",
      "epoch:43 step:34352 [D loss: 0.364664, acc: 82.03%] [G loss: 6.281329]\n",
      "epoch:43 step:34353 [D loss: 0.189323, acc: 94.53%] [G loss: 8.755708]\n",
      "epoch:43 step:34354 [D loss: 0.010774, acc: 100.00%] [G loss: 6.145967]\n",
      "epoch:43 step:34355 [D loss: 0.188345, acc: 96.88%] [G loss: 4.064735]\n",
      "epoch:43 step:34356 [D loss: 0.016528, acc: 100.00%] [G loss: 8.519155]\n",
      "epoch:43 step:34357 [D loss: 0.781752, acc: 53.12%] [G loss: 4.980996]\n",
      "epoch:43 step:34358 [D loss: 0.215328, acc: 95.31%] [G loss: 7.884428]\n",
      "epoch:43 step:34359 [D loss: 0.121179, acc: 100.00%] [G loss: 5.369586]\n",
      "epoch:43 step:34360 [D loss: 0.106810, acc: 99.22%] [G loss: 3.644320]\n",
      "epoch:43 step:34361 [D loss: 0.195905, acc: 96.09%] [G loss: 4.225739]\n",
      "epoch:43 step:34362 [D loss: 0.182453, acc: 98.44%] [G loss: 5.771784]\n",
      "epoch:43 step:34363 [D loss: 0.356243, acc: 79.69%] [G loss: 4.476795]\n",
      "epoch:43 step:34364 [D loss: 0.362396, acc: 81.25%] [G loss: 1.959856]\n",
      "epoch:44 step:34365 [D loss: 0.515148, acc: 79.69%] [G loss: 5.530183]\n",
      "epoch:44 step:34366 [D loss: 0.027438, acc: 100.00%] [G loss: 7.461180]\n",
      "epoch:44 step:34367 [D loss: 0.096639, acc: 100.00%] [G loss: 5.199049]\n",
      "epoch:44 step:34368 [D loss: 0.097780, acc: 100.00%] [G loss: 3.961865]\n",
      "epoch:44 step:34369 [D loss: 0.241673, acc: 89.84%] [G loss: 7.171556]\n",
      "epoch:44 step:34370 [D loss: 0.376034, acc: 78.12%] [G loss: 3.930699]\n",
      "epoch:44 step:34371 [D loss: 1.023098, acc: 50.00%] [G loss: 6.353468]\n",
      "epoch:44 step:34372 [D loss: 0.042834, acc: 100.00%] [G loss: 6.680950]\n",
      "epoch:44 step:34373 [D loss: 0.567728, acc: 67.19%] [G loss: 7.534256]\n",
      "epoch:44 step:34374 [D loss: 0.073953, acc: 100.00%] [G loss: 4.675270]\n",
      "epoch:44 step:34375 [D loss: 0.061023, acc: 100.00%] [G loss: 6.636246]\n",
      "epoch:44 step:34376 [D loss: 0.355726, acc: 80.47%] [G loss: 8.377396]\n",
      "epoch:44 step:34377 [D loss: 0.731657, acc: 59.38%] [G loss: 8.167573]\n",
      "epoch:44 step:34378 [D loss: 0.700281, acc: 60.16%] [G loss: 7.172500]\n",
      "epoch:44 step:34379 [D loss: 0.238314, acc: 96.09%] [G loss: 7.885345]\n",
      "epoch:44 step:34380 [D loss: 0.460768, acc: 68.75%] [G loss: 7.708929]\n",
      "epoch:44 step:34381 [D loss: 0.035408, acc: 100.00%] [G loss: 6.703074]\n",
      "epoch:44 step:34382 [D loss: 0.053997, acc: 100.00%] [G loss: 4.873645]\n",
      "epoch:44 step:34383 [D loss: 0.333262, acc: 92.19%] [G loss: 5.187093]\n",
      "epoch:44 step:34384 [D loss: 0.564943, acc: 63.28%] [G loss: 7.258611]\n",
      "epoch:44 step:34385 [D loss: 0.105817, acc: 98.44%] [G loss: 6.967611]\n",
      "epoch:44 step:34386 [D loss: 0.008196, acc: 100.00%] [G loss: 5.131300]\n",
      "epoch:44 step:34387 [D loss: 0.411564, acc: 78.91%] [G loss: 4.785350]\n",
      "epoch:44 step:34388 [D loss: 0.095991, acc: 100.00%] [G loss: 9.852112]\n",
      "epoch:44 step:34389 [D loss: 1.066746, acc: 53.12%] [G loss: 9.935431]\n",
      "epoch:44 step:34390 [D loss: 0.139478, acc: 99.22%] [G loss: 6.174306]\n",
      "epoch:44 step:34391 [D loss: 0.039171, acc: 100.00%] [G loss: 7.466617]\n",
      "epoch:44 step:34392 [D loss: 0.196156, acc: 94.53%] [G loss: 4.446252]\n",
      "epoch:44 step:34393 [D loss: 0.134452, acc: 98.44%] [G loss: 5.126303]\n",
      "epoch:44 step:34394 [D loss: 0.003909, acc: 100.00%] [G loss: 8.472980]\n",
      "epoch:44 step:34395 [D loss: 0.996385, acc: 46.88%] [G loss: 9.643552]\n",
      "epoch:44 step:34396 [D loss: 0.262100, acc: 92.19%] [G loss: 4.505134]\n",
      "epoch:44 step:34397 [D loss: 0.158325, acc: 99.22%] [G loss: 7.926641]\n",
      "epoch:44 step:34398 [D loss: 0.151620, acc: 97.66%] [G loss: 3.750083]\n",
      "epoch:44 step:34399 [D loss: 0.418552, acc: 72.66%] [G loss: 6.628783]\n",
      "epoch:44 step:34400 [D loss: 0.752330, acc: 53.12%] [G loss: 10.932045]\n",
      "##############\n",
      "[0.84766193 0.85642658 0.83792057 0.80680673 0.77722095 0.8201265\n",
      " 0.87912837 0.83767931 0.8386015  0.82556998]\n",
      "##########\n",
      "epoch:44 step:34401 [D loss: 0.018320, acc: 100.00%] [G loss: 6.618767]\n",
      "epoch:44 step:34402 [D loss: 0.248529, acc: 95.31%] [G loss: 9.459124]\n",
      "epoch:44 step:34403 [D loss: 0.882340, acc: 53.12%] [G loss: 8.819563]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:44 step:34404 [D loss: 0.118037, acc: 100.00%] [G loss: 6.293820]\n",
      "epoch:44 step:34405 [D loss: 0.182896, acc: 93.75%] [G loss: 6.556199]\n",
      "epoch:44 step:34406 [D loss: 0.057345, acc: 100.00%] [G loss: 3.789805]\n",
      "epoch:44 step:34407 [D loss: 0.066353, acc: 100.00%] [G loss: 5.212804]\n",
      "epoch:44 step:34408 [D loss: 0.027535, acc: 100.00%] [G loss: 5.699379]\n",
      "epoch:44 step:34409 [D loss: 0.181319, acc: 96.88%] [G loss: 4.263267]\n",
      "epoch:44 step:34410 [D loss: 0.214193, acc: 97.66%] [G loss: 7.966438]\n",
      "epoch:44 step:34411 [D loss: 0.437522, acc: 74.22%] [G loss: 5.017280]\n",
      "epoch:44 step:34412 [D loss: 0.860752, acc: 53.12%] [G loss: 9.032625]\n",
      "epoch:44 step:34413 [D loss: 0.439200, acc: 73.44%] [G loss: 6.029676]\n",
      "epoch:44 step:34414 [D loss: 0.214592, acc: 95.31%] [G loss: 6.972286]\n",
      "epoch:44 step:34415 [D loss: 0.692023, acc: 56.25%] [G loss: 6.189327]\n",
      "epoch:44 step:34416 [D loss: 0.235124, acc: 89.06%] [G loss: 6.907228]\n",
      "epoch:44 step:34417 [D loss: 0.490760, acc: 76.56%] [G loss: 6.360622]\n",
      "epoch:44 step:34418 [D loss: 0.209653, acc: 96.88%] [G loss: 5.411945]\n",
      "epoch:44 step:34419 [D loss: 0.994903, acc: 31.25%] [G loss: 12.429789]\n",
      "epoch:44 step:34420 [D loss: 0.171027, acc: 96.88%] [G loss: 3.679267]\n",
      "epoch:44 step:34421 [D loss: 0.121229, acc: 98.44%] [G loss: 5.499552]\n",
      "epoch:44 step:34422 [D loss: 0.260855, acc: 96.88%] [G loss: 4.368325]\n",
      "epoch:44 step:34423 [D loss: 0.116243, acc: 99.22%] [G loss: 8.122297]\n",
      "epoch:44 step:34424 [D loss: 0.150201, acc: 97.66%] [G loss: 2.325390]\n",
      "epoch:44 step:34425 [D loss: 0.066054, acc: 100.00%] [G loss: 6.106498]\n",
      "epoch:44 step:34426 [D loss: 0.104380, acc: 99.22%] [G loss: 4.269365]\n",
      "epoch:44 step:34427 [D loss: 0.069391, acc: 100.00%] [G loss: 4.276933]\n",
      "epoch:44 step:34428 [D loss: 0.406210, acc: 83.59%] [G loss: 3.975014]\n",
      "epoch:44 step:34429 [D loss: 0.865026, acc: 39.84%] [G loss: 4.827998]\n",
      "epoch:44 step:34430 [D loss: 0.612580, acc: 63.28%] [G loss: 5.789442]\n",
      "epoch:44 step:34431 [D loss: 0.529963, acc: 75.00%] [G loss: 9.462273]\n",
      "epoch:44 step:34432 [D loss: 0.567352, acc: 70.31%] [G loss: 4.815461]\n",
      "epoch:44 step:34433 [D loss: 0.022391, acc: 100.00%] [G loss: 4.585667]\n",
      "epoch:44 step:34434 [D loss: 0.180463, acc: 96.88%] [G loss: 5.233296]\n",
      "epoch:44 step:34435 [D loss: 0.189513, acc: 98.44%] [G loss: 4.908905]\n",
      "epoch:44 step:34436 [D loss: 0.129136, acc: 99.22%] [G loss: 4.120984]\n",
      "epoch:44 step:34437 [D loss: 0.108451, acc: 100.00%] [G loss: 6.104924]\n",
      "epoch:44 step:34438 [D loss: 0.271045, acc: 95.31%] [G loss: 5.331905]\n",
      "epoch:44 step:34439 [D loss: 0.116179, acc: 96.88%] [G loss: 5.872513]\n",
      "epoch:44 step:34440 [D loss: 0.180603, acc: 96.09%] [G loss: 6.110400]\n",
      "epoch:44 step:34441 [D loss: 0.374140, acc: 85.94%] [G loss: 3.534180]\n",
      "epoch:44 step:34442 [D loss: 0.086989, acc: 100.00%] [G loss: 1.327448]\n",
      "epoch:44 step:34443 [D loss: 0.358237, acc: 82.03%] [G loss: 5.944735]\n",
      "epoch:44 step:34444 [D loss: 0.746482, acc: 54.69%] [G loss: 4.852149]\n",
      "epoch:44 step:34445 [D loss: 0.040072, acc: 100.00%] [G loss: 5.746593]\n",
      "epoch:44 step:34446 [D loss: 0.577426, acc: 67.97%] [G loss: 8.661524]\n",
      "epoch:44 step:34447 [D loss: 0.199369, acc: 94.53%] [G loss: 6.130142]\n",
      "epoch:44 step:34448 [D loss: 0.270435, acc: 87.50%] [G loss: 10.482841]\n",
      "epoch:44 step:34449 [D loss: 0.025312, acc: 100.00%] [G loss: 9.163618]\n",
      "epoch:44 step:34450 [D loss: 0.024363, acc: 100.00%] [G loss: 6.520839]\n",
      "epoch:44 step:34451 [D loss: 0.136881, acc: 95.31%] [G loss: 5.846932]\n",
      "epoch:44 step:34452 [D loss: 0.962843, acc: 36.72%] [G loss: 5.854580]\n",
      "epoch:44 step:34453 [D loss: 0.098329, acc: 100.00%] [G loss: 9.604506]\n",
      "epoch:44 step:34454 [D loss: 0.025597, acc: 100.00%] [G loss: 5.323451]\n",
      "epoch:44 step:34455 [D loss: 0.067830, acc: 100.00%] [G loss: 9.648943]\n",
      "epoch:44 step:34456 [D loss: 0.018187, acc: 100.00%] [G loss: 9.620651]\n",
      "epoch:44 step:34457 [D loss: 0.121372, acc: 99.22%] [G loss: 7.279789]\n",
      "epoch:44 step:34458 [D loss: 0.157589, acc: 97.66%] [G loss: 4.779747]\n",
      "epoch:44 step:34459 [D loss: 0.551945, acc: 72.66%] [G loss: 5.897782]\n",
      "epoch:44 step:34460 [D loss: 0.331203, acc: 90.62%] [G loss: 5.095682]\n",
      "epoch:44 step:34461 [D loss: 0.241109, acc: 90.62%] [G loss: 3.256368]\n",
      "epoch:44 step:34462 [D loss: 0.117560, acc: 99.22%] [G loss: 6.096071]\n",
      "epoch:44 step:34463 [D loss: 0.328564, acc: 88.28%] [G loss: 4.568134]\n",
      "epoch:44 step:34464 [D loss: 0.159432, acc: 98.44%] [G loss: 5.126344]\n",
      "epoch:44 step:34465 [D loss: 0.189277, acc: 98.44%] [G loss: 8.593824]\n",
      "epoch:44 step:34466 [D loss: 0.032036, acc: 100.00%] [G loss: 6.532331]\n",
      "epoch:44 step:34467 [D loss: 0.580971, acc: 71.09%] [G loss: 4.585189]\n",
      "epoch:44 step:34468 [D loss: 0.338976, acc: 82.03%] [G loss: 7.260952]\n",
      "epoch:44 step:34469 [D loss: 0.173361, acc: 96.88%] [G loss: 6.767438]\n",
      "epoch:44 step:34470 [D loss: 0.073939, acc: 100.00%] [G loss: 4.047219]\n",
      "epoch:44 step:34471 [D loss: 0.124389, acc: 99.22%] [G loss: 5.750801]\n",
      "epoch:44 step:34472 [D loss: 1.853987, acc: 50.00%] [G loss: 4.600652]\n",
      "epoch:44 step:34473 [D loss: 0.038285, acc: 100.00%] [G loss: 5.970666]\n",
      "epoch:44 step:34474 [D loss: 1.043433, acc: 50.78%] [G loss: 9.017200]\n",
      "epoch:44 step:34475 [D loss: 0.417503, acc: 67.97%] [G loss: 8.307292]\n",
      "epoch:44 step:34476 [D loss: 1.627494, acc: 50.00%] [G loss: 6.891702]\n",
      "epoch:44 step:34477 [D loss: 0.081230, acc: 100.00%] [G loss: 5.328841]\n",
      "epoch:44 step:34478 [D loss: 0.089641, acc: 99.22%] [G loss: 5.488703]\n",
      "epoch:44 step:34479 [D loss: 0.963680, acc: 32.81%] [G loss: 9.153502]\n",
      "epoch:44 step:34480 [D loss: 0.054722, acc: 100.00%] [G loss: 6.483328]\n",
      "epoch:44 step:34481 [D loss: 0.104288, acc: 100.00%] [G loss: 4.414887]\n",
      "epoch:44 step:34482 [D loss: 0.195709, acc: 99.22%] [G loss: 4.819963]\n",
      "epoch:44 step:34483 [D loss: 0.069668, acc: 100.00%] [G loss: 9.227631]\n",
      "epoch:44 step:34484 [D loss: 0.004380, acc: 100.00%] [G loss: 8.658860]\n",
      "epoch:44 step:34485 [D loss: 0.071088, acc: 100.00%] [G loss: 6.206717]\n",
      "epoch:44 step:34486 [D loss: 0.066813, acc: 100.00%] [G loss: 4.788208]\n",
      "epoch:44 step:34487 [D loss: 0.204407, acc: 93.75%] [G loss: 4.650220]\n",
      "epoch:44 step:34488 [D loss: 0.931042, acc: 46.09%] [G loss: 9.183568]\n",
      "epoch:44 step:34489 [D loss: 0.211414, acc: 95.31%] [G loss: 5.180219]\n",
      "epoch:44 step:34490 [D loss: 0.554756, acc: 59.38%] [G loss: 8.578376]\n",
      "epoch:44 step:34491 [D loss: 0.105746, acc: 99.22%] [G loss: 7.247553]\n",
      "epoch:44 step:34492 [D loss: 0.649296, acc: 64.84%] [G loss: 7.054750]\n",
      "epoch:44 step:34493 [D loss: 1.596668, acc: 50.00%] [G loss: 6.087794]\n",
      "epoch:44 step:34494 [D loss: 0.703961, acc: 56.25%] [G loss: 4.175919]\n",
      "epoch:44 step:34495 [D loss: 0.145863, acc: 99.22%] [G loss: 5.179411]\n",
      "epoch:44 step:34496 [D loss: 0.534075, acc: 75.00%] [G loss: 4.042979]\n",
      "epoch:44 step:34497 [D loss: 0.077665, acc: 100.00%] [G loss: 8.302204]\n",
      "epoch:44 step:34498 [D loss: 0.098006, acc: 98.44%] [G loss: 6.771399]\n",
      "epoch:44 step:34499 [D loss: 0.472389, acc: 85.16%] [G loss: 9.783175]\n",
      "epoch:44 step:34500 [D loss: 1.019051, acc: 50.00%] [G loss: 3.892147]\n",
      "epoch:44 step:34501 [D loss: 0.068882, acc: 99.22%] [G loss: 7.225763]\n",
      "epoch:44 step:34502 [D loss: 0.358790, acc: 80.47%] [G loss: 5.298121]\n",
      "epoch:44 step:34503 [D loss: 0.356234, acc: 85.16%] [G loss: 5.035010]\n",
      "epoch:44 step:34504 [D loss: 0.123874, acc: 100.00%] [G loss: 4.959970]\n",
      "epoch:44 step:34505 [D loss: 0.098228, acc: 100.00%] [G loss: 1.770424]\n",
      "epoch:44 step:34506 [D loss: 0.136537, acc: 100.00%] [G loss: 4.415908]\n",
      "epoch:44 step:34507 [D loss: 1.072777, acc: 32.03%] [G loss: 6.214164]\n",
      "epoch:44 step:34508 [D loss: 0.407917, acc: 83.59%] [G loss: 5.325062]\n",
      "epoch:44 step:34509 [D loss: 0.319517, acc: 92.97%] [G loss: 7.008636]\n",
      "epoch:44 step:34510 [D loss: 0.585078, acc: 58.59%] [G loss: 3.980617]\n",
      "epoch:44 step:34511 [D loss: 0.032057, acc: 100.00%] [G loss: 4.257082]\n",
      "epoch:44 step:34512 [D loss: 0.060349, acc: 99.22%] [G loss: 8.185209]\n",
      "epoch:44 step:34513 [D loss: 0.057965, acc: 100.00%] [G loss: 6.562037]\n",
      "epoch:44 step:34514 [D loss: 0.072721, acc: 100.00%] [G loss: 2.843576]\n",
      "epoch:44 step:34515 [D loss: 0.898846, acc: 53.12%] [G loss: 7.736726]\n",
      "epoch:44 step:34516 [D loss: 0.215696, acc: 94.53%] [G loss: 3.469764]\n",
      "epoch:44 step:34517 [D loss: 0.074701, acc: 100.00%] [G loss: 6.228378]\n",
      "epoch:44 step:34518 [D loss: 0.015987, acc: 100.00%] [G loss: 8.364738]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:44 step:34519 [D loss: 0.053922, acc: 100.00%] [G loss: 7.234774]\n",
      "epoch:44 step:34520 [D loss: 0.403544, acc: 75.00%] [G loss: 8.302226]\n",
      "epoch:44 step:34521 [D loss: 0.331438, acc: 94.53%] [G loss: 5.889187]\n",
      "epoch:44 step:34522 [D loss: 0.030314, acc: 100.00%] [G loss: 4.768821]\n",
      "epoch:44 step:34523 [D loss: 0.723374, acc: 53.12%] [G loss: 6.143983]\n",
      "epoch:44 step:34524 [D loss: 0.464963, acc: 71.88%] [G loss: 8.606047]\n",
      "epoch:44 step:34525 [D loss: 0.774360, acc: 53.12%] [G loss: 7.927815]\n",
      "epoch:44 step:34526 [D loss: 0.182381, acc: 96.88%] [G loss: 6.835618]\n",
      "epoch:44 step:34527 [D loss: 1.619496, acc: 44.53%] [G loss: 6.939138]\n",
      "epoch:44 step:34528 [D loss: 0.170176, acc: 98.44%] [G loss: 5.479788]\n",
      "epoch:44 step:34529 [D loss: 0.339054, acc: 78.91%] [G loss: 4.978007]\n",
      "epoch:44 step:34530 [D loss: 0.165990, acc: 97.66%] [G loss: 4.595466]\n",
      "epoch:44 step:34531 [D loss: 0.170295, acc: 96.88%] [G loss: 7.659335]\n",
      "epoch:44 step:34532 [D loss: 0.090507, acc: 100.00%] [G loss: 5.538351]\n",
      "epoch:44 step:34533 [D loss: 0.100413, acc: 100.00%] [G loss: 4.129155]\n",
      "epoch:44 step:34534 [D loss: 0.114461, acc: 100.00%] [G loss: 3.033277]\n",
      "epoch:44 step:34535 [D loss: 0.106783, acc: 99.22%] [G loss: 6.788415]\n",
      "epoch:44 step:34536 [D loss: 0.447285, acc: 79.69%] [G loss: 4.808138]\n",
      "epoch:44 step:34537 [D loss: 0.174473, acc: 99.22%] [G loss: 3.850430]\n",
      "epoch:44 step:34538 [D loss: 0.250954, acc: 92.97%] [G loss: 4.805489]\n",
      "epoch:44 step:34539 [D loss: 0.306088, acc: 89.84%] [G loss: 7.677277]\n",
      "epoch:44 step:34540 [D loss: 0.093322, acc: 100.00%] [G loss: 6.253619]\n",
      "epoch:44 step:34541 [D loss: 0.251175, acc: 96.09%] [G loss: 5.333389]\n",
      "epoch:44 step:34542 [D loss: 0.102338, acc: 100.00%] [G loss: 4.765274]\n",
      "epoch:44 step:34543 [D loss: 1.558213, acc: 8.59%] [G loss: 7.394476]\n",
      "epoch:44 step:34544 [D loss: 0.043794, acc: 100.00%] [G loss: 7.472958]\n",
      "epoch:44 step:34545 [D loss: 0.306941, acc: 93.75%] [G loss: 7.801814]\n",
      "epoch:44 step:34546 [D loss: 0.203663, acc: 98.44%] [G loss: 4.367426]\n",
      "epoch:44 step:34547 [D loss: 0.593588, acc: 72.66%] [G loss: 6.078708]\n",
      "epoch:44 step:34548 [D loss: 0.069156, acc: 100.00%] [G loss: 5.210708]\n",
      "epoch:44 step:34549 [D loss: 1.068002, acc: 50.00%] [G loss: 8.203247]\n",
      "epoch:44 step:34550 [D loss: 0.444672, acc: 81.25%] [G loss: 2.817883]\n",
      "epoch:44 step:34551 [D loss: 0.773324, acc: 59.38%] [G loss: 3.753807]\n",
      "epoch:44 step:34552 [D loss: 0.323668, acc: 91.41%] [G loss: 3.207013]\n",
      "epoch:44 step:34553 [D loss: 0.017387, acc: 100.00%] [G loss: 5.486397]\n",
      "epoch:44 step:34554 [D loss: 0.499375, acc: 69.53%] [G loss: 4.558503]\n",
      "epoch:44 step:34555 [D loss: 0.120778, acc: 98.44%] [G loss: 6.023656]\n",
      "epoch:44 step:34556 [D loss: 0.566736, acc: 65.62%] [G loss: 7.366692]\n",
      "epoch:44 step:34557 [D loss: 0.615835, acc: 68.75%] [G loss: 3.531511]\n",
      "epoch:44 step:34558 [D loss: 0.260432, acc: 89.06%] [G loss: 6.315731]\n",
      "epoch:44 step:34559 [D loss: 0.083624, acc: 100.00%] [G loss: 3.969227]\n",
      "epoch:44 step:34560 [D loss: 0.333116, acc: 89.84%] [G loss: 5.752002]\n",
      "epoch:44 step:34561 [D loss: 0.033369, acc: 100.00%] [G loss: 6.654408]\n",
      "epoch:44 step:34562 [D loss: 0.104914, acc: 100.00%] [G loss: 6.198949]\n",
      "epoch:44 step:34563 [D loss: 0.351926, acc: 85.16%] [G loss: 4.656094]\n",
      "epoch:44 step:34564 [D loss: 0.083073, acc: 98.44%] [G loss: 5.739202]\n",
      "epoch:44 step:34565 [D loss: 0.309731, acc: 89.06%] [G loss: 7.072290]\n",
      "epoch:44 step:34566 [D loss: 0.159959, acc: 97.66%] [G loss: 6.591981]\n",
      "epoch:44 step:34567 [D loss: 0.405430, acc: 83.59%] [G loss: 5.410306]\n",
      "epoch:44 step:34568 [D loss: 0.106246, acc: 98.44%] [G loss: 5.874736]\n",
      "epoch:44 step:34569 [D loss: 0.238179, acc: 97.66%] [G loss: 5.479197]\n",
      "epoch:44 step:34570 [D loss: 0.026681, acc: 100.00%] [G loss: 7.898093]\n",
      "epoch:44 step:34571 [D loss: 0.087214, acc: 99.22%] [G loss: 3.028726]\n",
      "epoch:44 step:34572 [D loss: 0.200417, acc: 97.66%] [G loss: 2.572996]\n",
      "epoch:44 step:34573 [D loss: 0.024268, acc: 100.00%] [G loss: 8.039635]\n",
      "epoch:44 step:34574 [D loss: 0.519103, acc: 75.00%] [G loss: 5.836265]\n",
      "epoch:44 step:34575 [D loss: 1.665370, acc: 42.19%] [G loss: 6.671354]\n",
      "epoch:44 step:34576 [D loss: 0.074354, acc: 100.00%] [G loss: 3.887215]\n",
      "epoch:44 step:34577 [D loss: 0.860291, acc: 48.44%] [G loss: 6.023053]\n",
      "epoch:44 step:34578 [D loss: 0.017521, acc: 100.00%] [G loss: 6.545897]\n",
      "epoch:44 step:34579 [D loss: 0.045452, acc: 100.00%] [G loss: 9.108353]\n",
      "epoch:44 step:34580 [D loss: 0.043706, acc: 100.00%] [G loss: 4.440741]\n",
      "epoch:44 step:34581 [D loss: 0.182888, acc: 96.09%] [G loss: 4.445332]\n",
      "epoch:44 step:34582 [D loss: 0.023578, acc: 100.00%] [G loss: 5.296009]\n",
      "epoch:44 step:34583 [D loss: 0.119794, acc: 98.44%] [G loss: 3.756497]\n",
      "epoch:44 step:34584 [D loss: 0.396751, acc: 82.81%] [G loss: 4.943963]\n",
      "epoch:44 step:34585 [D loss: 0.144168, acc: 98.44%] [G loss: 3.236266]\n",
      "epoch:44 step:34586 [D loss: 0.657268, acc: 55.47%] [G loss: 5.611527]\n",
      "epoch:44 step:34587 [D loss: 0.046056, acc: 100.00%] [G loss: 5.840880]\n",
      "epoch:44 step:34588 [D loss: 0.044467, acc: 100.00%] [G loss: 6.715547]\n",
      "epoch:44 step:34589 [D loss: 0.537098, acc: 75.00%] [G loss: 8.164460]\n",
      "epoch:44 step:34590 [D loss: 0.052485, acc: 100.00%] [G loss: 4.180145]\n",
      "epoch:44 step:34591 [D loss: 0.317328, acc: 83.59%] [G loss: 5.529953]\n",
      "epoch:44 step:34592 [D loss: 0.143725, acc: 96.88%] [G loss: 6.819767]\n",
      "epoch:44 step:34593 [D loss: 0.068195, acc: 100.00%] [G loss: 5.818810]\n",
      "epoch:44 step:34594 [D loss: 0.353559, acc: 79.69%] [G loss: 6.319712]\n",
      "epoch:44 step:34595 [D loss: 0.321980, acc: 88.28%] [G loss: 3.158450]\n",
      "epoch:44 step:34596 [D loss: 0.495447, acc: 75.78%] [G loss: 8.773700]\n",
      "epoch:44 step:34597 [D loss: 0.049581, acc: 99.22%] [G loss: 5.878143]\n",
      "epoch:44 step:34598 [D loss: 0.603690, acc: 65.62%] [G loss: 4.652476]\n",
      "epoch:44 step:34599 [D loss: 0.393428, acc: 84.38%] [G loss: 6.881878]\n",
      "epoch:44 step:34600 [D loss: 0.417377, acc: 71.09%] [G loss: 6.175972]\n",
      "##############\n",
      "[0.86133499 0.84651288 0.79975549 0.81989105 0.7985675  0.81637947\n",
      " 0.89660726 0.83480546 0.81043238 0.81606312]\n",
      "##########\n",
      "epoch:44 step:34601 [D loss: 0.100778, acc: 99.22%] [G loss: 5.847425]\n",
      "epoch:44 step:34602 [D loss: 0.131321, acc: 98.44%] [G loss: 6.332642]\n",
      "epoch:44 step:34603 [D loss: 1.002330, acc: 50.00%] [G loss: 3.943230]\n",
      "epoch:44 step:34604 [D loss: 0.734682, acc: 54.69%] [G loss: 3.095445]\n",
      "epoch:44 step:34605 [D loss: 0.714382, acc: 54.69%] [G loss: 4.452684]\n",
      "epoch:44 step:34606 [D loss: 0.161287, acc: 97.66%] [G loss: 5.550324]\n",
      "epoch:44 step:34607 [D loss: 0.135369, acc: 99.22%] [G loss: 4.771110]\n",
      "epoch:44 step:34608 [D loss: 0.048096, acc: 100.00%] [G loss: 7.480884]\n",
      "epoch:44 step:34609 [D loss: 0.081407, acc: 100.00%] [G loss: 5.961769]\n",
      "epoch:44 step:34610 [D loss: 0.341271, acc: 93.75%] [G loss: 7.564797]\n",
      "epoch:44 step:34611 [D loss: 0.110236, acc: 99.22%] [G loss: 6.958605]\n",
      "epoch:44 step:34612 [D loss: 0.212845, acc: 94.53%] [G loss: 5.435775]\n",
      "epoch:44 step:34613 [D loss: 0.226281, acc: 96.88%] [G loss: 5.649950]\n",
      "epoch:44 step:34614 [D loss: 0.010719, acc: 100.00%] [G loss: 5.714186]\n",
      "epoch:44 step:34615 [D loss: 0.111505, acc: 99.22%] [G loss: 5.283658]\n",
      "epoch:44 step:34616 [D loss: 0.051634, acc: 100.00%] [G loss: 5.677442]\n",
      "epoch:44 step:34617 [D loss: 0.613563, acc: 69.53%] [G loss: 4.303741]\n",
      "epoch:44 step:34618 [D loss: 0.098594, acc: 100.00%] [G loss: 8.258989]\n",
      "epoch:44 step:34619 [D loss: 0.050690, acc: 100.00%] [G loss: 11.081366]\n",
      "epoch:44 step:34620 [D loss: 0.045509, acc: 100.00%] [G loss: 5.469037]\n",
      "epoch:44 step:34621 [D loss: 0.483617, acc: 68.75%] [G loss: 1.851169]\n",
      "epoch:44 step:34622 [D loss: 0.067786, acc: 100.00%] [G loss: 4.458966]\n",
      "epoch:44 step:34623 [D loss: 0.463585, acc: 76.56%] [G loss: 4.958928]\n",
      "epoch:44 step:34624 [D loss: 0.402208, acc: 76.56%] [G loss: 3.389453]\n",
      "epoch:44 step:34625 [D loss: 0.191114, acc: 98.44%] [G loss: 4.126054]\n",
      "epoch:44 step:34626 [D loss: 0.136476, acc: 100.00%] [G loss: 7.573568]\n",
      "epoch:44 step:34627 [D loss: 0.455560, acc: 71.09%] [G loss: 6.462897]\n",
      "epoch:44 step:34628 [D loss: 0.100324, acc: 99.22%] [G loss: 7.344584]\n",
      "epoch:44 step:34629 [D loss: 0.144514, acc: 100.00%] [G loss: 6.108105]\n",
      "epoch:44 step:34630 [D loss: 0.551044, acc: 70.31%] [G loss: 8.525785]\n",
      "epoch:44 step:34631 [D loss: 0.046485, acc: 100.00%] [G loss: 5.115056]\n",
      "epoch:44 step:34632 [D loss: 0.245212, acc: 93.75%] [G loss: 5.781715]\n",
      "epoch:44 step:34633 [D loss: 0.472162, acc: 77.34%] [G loss: 4.534193]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:44 step:34634 [D loss: 1.286372, acc: 40.62%] [G loss: 6.803688]\n",
      "epoch:44 step:34635 [D loss: 0.047521, acc: 99.22%] [G loss: 5.890140]\n",
      "epoch:44 step:34636 [D loss: 0.031530, acc: 100.00%] [G loss: 6.075184]\n",
      "epoch:44 step:34637 [D loss: 0.035935, acc: 100.00%] [G loss: 4.668305]\n",
      "epoch:44 step:34638 [D loss: 0.130658, acc: 99.22%] [G loss: 8.342726]\n",
      "epoch:44 step:34639 [D loss: 0.406479, acc: 90.62%] [G loss: 7.621998]\n",
      "epoch:44 step:34640 [D loss: 0.092782, acc: 100.00%] [G loss: 6.137032]\n",
      "epoch:44 step:34641 [D loss: 0.410095, acc: 74.22%] [G loss: 8.361021]\n",
      "epoch:44 step:34642 [D loss: 0.064164, acc: 100.00%] [G loss: 5.042528]\n",
      "epoch:44 step:34643 [D loss: 0.078679, acc: 99.22%] [G loss: 8.595995]\n",
      "epoch:44 step:34644 [D loss: 0.113776, acc: 99.22%] [G loss: 9.205588]\n",
      "epoch:44 step:34645 [D loss: 0.820867, acc: 46.09%] [G loss: 5.142358]\n",
      "epoch:44 step:34646 [D loss: 0.080494, acc: 100.00%] [G loss: 6.898854]\n",
      "epoch:44 step:34647 [D loss: 0.533934, acc: 73.44%] [G loss: 6.406322]\n",
      "epoch:44 step:34648 [D loss: 0.096183, acc: 99.22%] [G loss: 3.137236]\n",
      "epoch:44 step:34649 [D loss: 0.528613, acc: 64.06%] [G loss: 7.016152]\n",
      "epoch:44 step:34650 [D loss: 0.099639, acc: 99.22%] [G loss: 7.663955]\n",
      "epoch:44 step:34651 [D loss: 0.205927, acc: 92.97%] [G loss: 7.564998]\n",
      "epoch:44 step:34652 [D loss: 0.082028, acc: 100.00%] [G loss: 4.768733]\n",
      "epoch:44 step:34653 [D loss: 0.307865, acc: 92.97%] [G loss: 4.704035]\n",
      "epoch:44 step:34654 [D loss: 0.143640, acc: 99.22%] [G loss: 5.482293]\n",
      "epoch:44 step:34655 [D loss: 0.140481, acc: 97.66%] [G loss: 10.366508]\n",
      "epoch:44 step:34656 [D loss: 0.067973, acc: 99.22%] [G loss: 5.468285]\n",
      "epoch:44 step:34657 [D loss: 0.141722, acc: 99.22%] [G loss: 3.313428]\n",
      "epoch:44 step:34658 [D loss: 0.152828, acc: 99.22%] [G loss: 2.362607]\n",
      "epoch:44 step:34659 [D loss: 0.897889, acc: 50.78%] [G loss: 6.572958]\n",
      "epoch:44 step:34660 [D loss: 0.188457, acc: 93.75%] [G loss: 6.882928]\n",
      "epoch:44 step:34661 [D loss: 0.046795, acc: 100.00%] [G loss: 7.024106]\n",
      "epoch:44 step:34662 [D loss: 0.170800, acc: 97.66%] [G loss: 6.998247]\n",
      "epoch:44 step:34663 [D loss: 0.119829, acc: 99.22%] [G loss: 6.087254]\n",
      "epoch:44 step:34664 [D loss: 0.343793, acc: 89.84%] [G loss: 5.095754]\n",
      "epoch:44 step:34665 [D loss: 0.280409, acc: 94.53%] [G loss: 4.605769]\n",
      "epoch:44 step:34666 [D loss: 0.462423, acc: 74.22%] [G loss: 5.857262]\n",
      "epoch:44 step:34667 [D loss: 0.177986, acc: 93.75%] [G loss: 6.371980]\n",
      "epoch:44 step:34668 [D loss: 0.653331, acc: 57.81%] [G loss: 4.823887]\n",
      "epoch:44 step:34669 [D loss: 0.111823, acc: 99.22%] [G loss: 6.916587]\n",
      "epoch:44 step:34670 [D loss: 0.124362, acc: 100.00%] [G loss: 9.185883]\n",
      "epoch:44 step:34671 [D loss: 0.797004, acc: 54.69%] [G loss: 7.111560]\n",
      "epoch:44 step:34672 [D loss: 0.296958, acc: 85.16%] [G loss: 4.385036]\n",
      "epoch:44 step:34673 [D loss: 0.225994, acc: 96.88%] [G loss: 4.825308]\n",
      "epoch:44 step:34674 [D loss: 0.412548, acc: 72.66%] [G loss: 5.838836]\n",
      "epoch:44 step:34675 [D loss: 0.819318, acc: 53.12%] [G loss: 4.332056]\n",
      "epoch:44 step:34676 [D loss: 0.364687, acc: 76.56%] [G loss: 8.712851]\n",
      "epoch:44 step:34677 [D loss: 0.020592, acc: 100.00%] [G loss: 9.317224]\n",
      "epoch:44 step:34678 [D loss: 0.433348, acc: 85.94%] [G loss: 7.402395]\n",
      "epoch:44 step:34679 [D loss: 0.048083, acc: 100.00%] [G loss: 3.546058]\n",
      "epoch:44 step:34680 [D loss: 0.203349, acc: 93.75%] [G loss: 8.771988]\n",
      "epoch:44 step:34681 [D loss: 0.121881, acc: 99.22%] [G loss: 3.421019]\n",
      "epoch:44 step:34682 [D loss: 0.080739, acc: 100.00%] [G loss: 8.532999]\n",
      "epoch:44 step:34683 [D loss: 0.039399, acc: 100.00%] [G loss: 2.918120]\n",
      "epoch:44 step:34684 [D loss: 0.086484, acc: 100.00%] [G loss: 4.544339]\n",
      "epoch:44 step:34685 [D loss: 0.194443, acc: 96.09%] [G loss: 5.837551]\n",
      "epoch:44 step:34686 [D loss: 0.170049, acc: 96.09%] [G loss: 7.548546]\n",
      "epoch:44 step:34687 [D loss: 0.149861, acc: 96.88%] [G loss: 6.069214]\n",
      "epoch:44 step:34688 [D loss: 0.170381, acc: 97.66%] [G loss: 6.208040]\n",
      "epoch:44 step:34689 [D loss: 0.017861, acc: 100.00%] [G loss: 7.585362]\n",
      "epoch:44 step:34690 [D loss: 0.169623, acc: 95.31%] [G loss: 5.973451]\n",
      "epoch:44 step:34691 [D loss: 0.146459, acc: 100.00%] [G loss: 5.906265]\n",
      "epoch:44 step:34692 [D loss: 0.379618, acc: 79.69%] [G loss: 4.581114]\n",
      "epoch:44 step:34693 [D loss: 0.268513, acc: 95.31%] [G loss: 6.446063]\n",
      "epoch:44 step:34694 [D loss: 0.405160, acc: 76.56%] [G loss: 6.088883]\n",
      "epoch:44 step:34695 [D loss: 0.632884, acc: 60.94%] [G loss: 6.470189]\n",
      "epoch:44 step:34696 [D loss: 1.122641, acc: 30.47%] [G loss: 8.354784]\n",
      "epoch:44 step:34697 [D loss: 0.007454, acc: 100.00%] [G loss: 7.279224]\n",
      "epoch:44 step:34698 [D loss: 1.165351, acc: 50.78%] [G loss: 8.475466]\n",
      "epoch:44 step:34699 [D loss: 1.646635, acc: 50.00%] [G loss: 7.990840]\n",
      "epoch:44 step:34700 [D loss: 0.061023, acc: 99.22%] [G loss: 4.931569]\n",
      "epoch:44 step:34701 [D loss: 0.276980, acc: 87.50%] [G loss: 4.633478]\n",
      "epoch:44 step:34702 [D loss: 0.202489, acc: 94.53%] [G loss: 7.405149]\n",
      "epoch:44 step:34703 [D loss: 0.029989, acc: 100.00%] [G loss: 7.133401]\n",
      "epoch:44 step:34704 [D loss: 0.074694, acc: 99.22%] [G loss: 4.923545]\n",
      "epoch:44 step:34705 [D loss: 0.099892, acc: 98.44%] [G loss: 6.662861]\n",
      "epoch:44 step:34706 [D loss: 0.049318, acc: 100.00%] [G loss: 6.570356]\n",
      "epoch:44 step:34707 [D loss: 0.166339, acc: 98.44%] [G loss: 7.090279]\n",
      "epoch:44 step:34708 [D loss: 0.062732, acc: 99.22%] [G loss: 9.214943]\n",
      "epoch:44 step:34709 [D loss: 0.085732, acc: 100.00%] [G loss: 4.396416]\n",
      "epoch:44 step:34710 [D loss: 0.155005, acc: 99.22%] [G loss: 6.970168]\n",
      "epoch:44 step:34711 [D loss: 0.296717, acc: 85.94%] [G loss: 7.119030]\n",
      "epoch:44 step:34712 [D loss: 0.172585, acc: 94.53%] [G loss: 5.501097]\n",
      "epoch:44 step:34713 [D loss: 0.074816, acc: 100.00%] [G loss: 4.139563]\n",
      "epoch:44 step:34714 [D loss: 0.291671, acc: 92.97%] [G loss: 6.222920]\n",
      "epoch:44 step:34715 [D loss: 0.059108, acc: 100.00%] [G loss: 10.794106]\n",
      "epoch:44 step:34716 [D loss: 0.179233, acc: 98.44%] [G loss: 5.078374]\n",
      "epoch:44 step:34717 [D loss: 0.614378, acc: 59.38%] [G loss: 8.896523]\n",
      "epoch:44 step:34718 [D loss: 0.518976, acc: 78.91%] [G loss: 7.044868]\n",
      "epoch:44 step:34719 [D loss: 1.709624, acc: 48.44%] [G loss: 6.358770]\n",
      "epoch:44 step:34720 [D loss: 0.157790, acc: 99.22%] [G loss: 3.288719]\n",
      "epoch:44 step:34721 [D loss: 0.720840, acc: 55.47%] [G loss: 5.188066]\n",
      "epoch:44 step:34722 [D loss: 0.041590, acc: 99.22%] [G loss: 4.550238]\n",
      "epoch:44 step:34723 [D loss: 0.181264, acc: 98.44%] [G loss: 6.376482]\n",
      "epoch:44 step:34724 [D loss: 0.098258, acc: 100.00%] [G loss: 7.033637]\n",
      "epoch:44 step:34725 [D loss: 0.270002, acc: 89.84%] [G loss: 5.817299]\n",
      "epoch:44 step:34726 [D loss: 0.152232, acc: 100.00%] [G loss: 7.050926]\n",
      "epoch:44 step:34727 [D loss: 0.633893, acc: 60.16%] [G loss: 7.209706]\n",
      "epoch:44 step:34728 [D loss: 0.686529, acc: 60.16%] [G loss: 4.377135]\n",
      "epoch:44 step:34729 [D loss: 0.295499, acc: 87.50%] [G loss: 5.737245]\n",
      "epoch:44 step:34730 [D loss: 0.036177, acc: 100.00%] [G loss: 5.672762]\n",
      "epoch:44 step:34731 [D loss: 0.626246, acc: 71.09%] [G loss: 7.585685]\n",
      "epoch:44 step:34732 [D loss: 0.073841, acc: 99.22%] [G loss: 2.661516]\n",
      "epoch:44 step:34733 [D loss: 0.320551, acc: 84.38%] [G loss: 5.663978]\n",
      "epoch:44 step:34734 [D loss: 0.020200, acc: 100.00%] [G loss: 6.111634]\n",
      "epoch:44 step:34735 [D loss: 1.222004, acc: 42.19%] [G loss: 7.462340]\n",
      "epoch:44 step:34736 [D loss: 0.039866, acc: 100.00%] [G loss: 5.466122]\n",
      "epoch:44 step:34737 [D loss: 0.430818, acc: 68.75%] [G loss: 7.132654]\n",
      "epoch:44 step:34738 [D loss: 0.643138, acc: 65.62%] [G loss: 6.120765]\n",
      "epoch:44 step:34739 [D loss: 0.685622, acc: 55.47%] [G loss: 5.503126]\n",
      "epoch:44 step:34740 [D loss: 0.158110, acc: 99.22%] [G loss: 5.938244]\n",
      "epoch:44 step:34741 [D loss: 0.217602, acc: 93.75%] [G loss: 8.529663]\n",
      "epoch:44 step:34742 [D loss: 0.389161, acc: 82.03%] [G loss: 5.611145]\n",
      "epoch:44 step:34743 [D loss: 0.140664, acc: 99.22%] [G loss: 4.610192]\n",
      "epoch:44 step:34744 [D loss: 0.238528, acc: 89.84%] [G loss: 8.856725]\n",
      "epoch:44 step:34745 [D loss: 1.124867, acc: 51.56%] [G loss: 8.448896]\n",
      "epoch:44 step:34746 [D loss: 0.470504, acc: 75.78%] [G loss: 7.029018]\n",
      "epoch:44 step:34747 [D loss: 0.524893, acc: 64.84%] [G loss: 7.509090]\n",
      "epoch:44 step:34748 [D loss: 0.438256, acc: 71.88%] [G loss: 7.548975]\n",
      "epoch:44 step:34749 [D loss: 0.404837, acc: 82.81%] [G loss: 3.859277]\n",
      "epoch:44 step:34750 [D loss: 0.264439, acc: 85.94%] [G loss: 3.483567]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:44 step:34751 [D loss: 0.208111, acc: 96.88%] [G loss: 4.163638]\n",
      "epoch:44 step:34752 [D loss: 0.061505, acc: 100.00%] [G loss: 6.935394]\n",
      "epoch:44 step:34753 [D loss: 0.353378, acc: 80.47%] [G loss: 6.747910]\n",
      "epoch:44 step:34754 [D loss: 0.302416, acc: 85.16%] [G loss: 8.730328]\n",
      "epoch:44 step:34755 [D loss: 0.350720, acc: 77.34%] [G loss: 5.468797]\n",
      "epoch:44 step:34756 [D loss: 0.362881, acc: 89.06%] [G loss: 8.495514]\n",
      "epoch:44 step:34757 [D loss: 0.143178, acc: 99.22%] [G loss: 6.052872]\n",
      "epoch:44 step:34758 [D loss: 0.072321, acc: 100.00%] [G loss: 7.388249]\n",
      "epoch:44 step:34759 [D loss: 0.546547, acc: 69.53%] [G loss: 8.231180]\n",
      "epoch:44 step:34760 [D loss: 0.675288, acc: 57.03%] [G loss: 4.215293]\n",
      "epoch:44 step:34761 [D loss: 0.265997, acc: 92.97%] [G loss: 7.062768]\n",
      "epoch:44 step:34762 [D loss: 1.065456, acc: 50.78%] [G loss: 8.969966]\n",
      "epoch:44 step:34763 [D loss: 0.349686, acc: 77.34%] [G loss: 4.674339]\n",
      "epoch:44 step:34764 [D loss: 0.069784, acc: 99.22%] [G loss: 3.821082]\n",
      "epoch:44 step:34765 [D loss: 0.014509, acc: 100.00%] [G loss: 8.028625]\n",
      "epoch:44 step:34766 [D loss: 0.176202, acc: 96.88%] [G loss: 6.902835]\n",
      "epoch:44 step:34767 [D loss: 0.088645, acc: 100.00%] [G loss: 5.863007]\n",
      "epoch:44 step:34768 [D loss: 0.049877, acc: 99.22%] [G loss: 7.688996]\n",
      "epoch:44 step:34769 [D loss: 0.265569, acc: 93.75%] [G loss: 5.408510]\n",
      "epoch:44 step:34770 [D loss: 0.904593, acc: 48.44%] [G loss: 6.375017]\n",
      "epoch:44 step:34771 [D loss: 0.142072, acc: 98.44%] [G loss: 4.143787]\n",
      "epoch:44 step:34772 [D loss: 0.969186, acc: 26.56%] [G loss: 5.473194]\n",
      "epoch:44 step:34773 [D loss: 0.107932, acc: 100.00%] [G loss: 6.749602]\n",
      "epoch:44 step:34774 [D loss: 0.422406, acc: 75.00%] [G loss: 7.786753]\n",
      "epoch:44 step:34775 [D loss: 0.232337, acc: 96.09%] [G loss: 5.750954]\n",
      "epoch:44 step:34776 [D loss: 0.055946, acc: 100.00%] [G loss: 6.771213]\n",
      "epoch:44 step:34777 [D loss: 0.024368, acc: 100.00%] [G loss: 7.456140]\n",
      "epoch:44 step:34778 [D loss: 0.412579, acc: 76.56%] [G loss: 9.672153]\n",
      "epoch:44 step:34779 [D loss: 0.931501, acc: 50.00%] [G loss: 3.901806]\n",
      "epoch:44 step:34780 [D loss: 0.044280, acc: 100.00%] [G loss: 5.731421]\n",
      "epoch:44 step:34781 [D loss: 0.308589, acc: 86.72%] [G loss: 5.012593]\n",
      "epoch:44 step:34782 [D loss: 0.015258, acc: 100.00%] [G loss: 8.148022]\n",
      "epoch:44 step:34783 [D loss: 0.174223, acc: 95.31%] [G loss: 4.417594]\n",
      "epoch:44 step:34784 [D loss: 0.294912, acc: 89.06%] [G loss: 9.577130]\n",
      "epoch:44 step:34785 [D loss: 1.018544, acc: 31.25%] [G loss: 7.692672]\n",
      "epoch:44 step:34786 [D loss: 0.015575, acc: 100.00%] [G loss: 5.425504]\n",
      "epoch:44 step:34787 [D loss: 0.069157, acc: 100.00%] [G loss: 5.470005]\n",
      "epoch:44 step:34788 [D loss: 0.058116, acc: 99.22%] [G loss: 9.188562]\n",
      "epoch:44 step:34789 [D loss: 0.150976, acc: 96.88%] [G loss: 5.846150]\n",
      "epoch:44 step:34790 [D loss: 0.154674, acc: 100.00%] [G loss: 6.601588]\n",
      "epoch:44 step:34791 [D loss: 0.591369, acc: 57.03%] [G loss: 4.598149]\n",
      "epoch:44 step:34792 [D loss: 0.655764, acc: 57.81%] [G loss: 8.016114]\n",
      "epoch:44 step:34793 [D loss: 0.178229, acc: 97.66%] [G loss: 7.962856]\n",
      "epoch:44 step:34794 [D loss: 0.325329, acc: 82.03%] [G loss: 8.879900]\n",
      "epoch:44 step:34795 [D loss: 0.090796, acc: 98.44%] [G loss: 5.299013]\n",
      "epoch:44 step:34796 [D loss: 0.164319, acc: 97.66%] [G loss: 4.196885]\n",
      "epoch:44 step:34797 [D loss: 0.910739, acc: 50.78%] [G loss: 4.064862]\n",
      "epoch:44 step:34798 [D loss: 0.126418, acc: 99.22%] [G loss: 6.936891]\n",
      "epoch:44 step:34799 [D loss: 0.258867, acc: 90.62%] [G loss: 7.218575]\n",
      "epoch:44 step:34800 [D loss: 0.248345, acc: 96.09%] [G loss: 8.546715]\n",
      "##############\n",
      "[0.84921646 0.8797103  0.81692479 0.82538826 0.80332344 0.81612885\n",
      " 0.88430092 0.82759464 0.7995458  0.82906093]\n",
      "##########\n",
      "epoch:44 step:34801 [D loss: 0.891168, acc: 41.41%] [G loss: 5.457370]\n",
      "epoch:44 step:34802 [D loss: 0.037360, acc: 100.00%] [G loss: 7.231461]\n",
      "epoch:44 step:34803 [D loss: 0.036865, acc: 100.00%] [G loss: 7.296949]\n",
      "epoch:44 step:34804 [D loss: 0.868240, acc: 52.34%] [G loss: 10.568576]\n",
      "epoch:44 step:34805 [D loss: 0.023783, acc: 100.00%] [G loss: 2.505074]\n",
      "epoch:44 step:34806 [D loss: 0.113377, acc: 100.00%] [G loss: 4.409997]\n",
      "epoch:44 step:34807 [D loss: 0.128011, acc: 98.44%] [G loss: 8.508362]\n",
      "epoch:44 step:34808 [D loss: 0.194577, acc: 96.09%] [G loss: 4.219664]\n",
      "epoch:44 step:34809 [D loss: 0.078092, acc: 100.00%] [G loss: 6.021132]\n",
      "epoch:44 step:34810 [D loss: 0.113936, acc: 100.00%] [G loss: 3.629465]\n",
      "epoch:44 step:34811 [D loss: 0.450179, acc: 75.00%] [G loss: 8.753531]\n",
      "epoch:44 step:34812 [D loss: 0.024195, acc: 100.00%] [G loss: 5.922654]\n",
      "epoch:44 step:34813 [D loss: 0.134356, acc: 96.09%] [G loss: 8.071292]\n",
      "epoch:44 step:34814 [D loss: 0.425165, acc: 83.59%] [G loss: 4.901628]\n",
      "epoch:44 step:34815 [D loss: 0.891072, acc: 51.56%] [G loss: 3.658979]\n",
      "epoch:44 step:34816 [D loss: 0.055601, acc: 100.00%] [G loss: 5.415557]\n",
      "epoch:44 step:34817 [D loss: 0.566273, acc: 66.41%] [G loss: 7.943582]\n",
      "epoch:44 step:34818 [D loss: 0.150354, acc: 97.66%] [G loss: 6.409367]\n",
      "epoch:44 step:34819 [D loss: 0.050369, acc: 100.00%] [G loss: 6.355961]\n",
      "epoch:44 step:34820 [D loss: 0.085056, acc: 100.00%] [G loss: 7.092077]\n",
      "epoch:44 step:34821 [D loss: 0.937263, acc: 53.12%] [G loss: 7.033751]\n",
      "epoch:44 step:34822 [D loss: 0.189452, acc: 93.75%] [G loss: 4.419106]\n",
      "epoch:44 step:34823 [D loss: 0.058412, acc: 100.00%] [G loss: 8.805309]\n",
      "epoch:44 step:34824 [D loss: 0.143308, acc: 97.66%] [G loss: 5.135366]\n",
      "epoch:44 step:34825 [D loss: 0.039325, acc: 100.00%] [G loss: 6.177174]\n",
      "epoch:44 step:34826 [D loss: 0.061462, acc: 100.00%] [G loss: 7.144770]\n",
      "epoch:44 step:34827 [D loss: 0.165610, acc: 95.31%] [G loss: 3.804054]\n",
      "epoch:44 step:34828 [D loss: 0.083653, acc: 100.00%] [G loss: 7.703927]\n",
      "epoch:44 step:34829 [D loss: 0.720489, acc: 55.47%] [G loss: 7.431672]\n",
      "epoch:44 step:34830 [D loss: 0.182721, acc: 94.53%] [G loss: 5.645987]\n",
      "epoch:44 step:34831 [D loss: 0.124151, acc: 99.22%] [G loss: 6.194269]\n",
      "epoch:44 step:34832 [D loss: 0.215957, acc: 95.31%] [G loss: 4.979350]\n",
      "epoch:44 step:34833 [D loss: 0.076798, acc: 100.00%] [G loss: 5.522456]\n",
      "epoch:44 step:34834 [D loss: 0.175869, acc: 93.75%] [G loss: 5.002223]\n",
      "epoch:44 step:34835 [D loss: 0.019170, acc: 100.00%] [G loss: 6.470914]\n",
      "epoch:44 step:34836 [D loss: 1.287036, acc: 46.09%] [G loss: 5.647201]\n",
      "epoch:44 step:34837 [D loss: 0.066614, acc: 100.00%] [G loss: 8.198166]\n",
      "epoch:44 step:34838 [D loss: 0.397917, acc: 79.69%] [G loss: 10.430405]\n",
      "epoch:44 step:34839 [D loss: 0.249689, acc: 92.97%] [G loss: 6.368947]\n",
      "epoch:44 step:34840 [D loss: 1.067253, acc: 31.25%] [G loss: 7.371155]\n",
      "epoch:44 step:34841 [D loss: 0.130065, acc: 99.22%] [G loss: 4.386428]\n",
      "epoch:44 step:34842 [D loss: 0.040554, acc: 100.00%] [G loss: 7.870230]\n",
      "epoch:44 step:34843 [D loss: 0.110826, acc: 100.00%] [G loss: 3.640687]\n",
      "epoch:44 step:34844 [D loss: 0.070615, acc: 100.00%] [G loss: 5.108732]\n",
      "epoch:44 step:34845 [D loss: 0.894796, acc: 52.34%] [G loss: 6.566824]\n",
      "epoch:44 step:34846 [D loss: 0.140494, acc: 99.22%] [G loss: 5.611079]\n",
      "epoch:44 step:34847 [D loss: 0.180906, acc: 96.09%] [G loss: 5.491536]\n",
      "epoch:44 step:34848 [D loss: 0.968225, acc: 49.22%] [G loss: 9.026716]\n",
      "epoch:44 step:34849 [D loss: 0.282128, acc: 87.50%] [G loss: 5.622458]\n",
      "epoch:44 step:34850 [D loss: 0.087152, acc: 99.22%] [G loss: 7.183888]\n",
      "epoch:44 step:34851 [D loss: 0.032909, acc: 100.00%] [G loss: 6.700694]\n",
      "epoch:44 step:34852 [D loss: 0.003681, acc: 100.00%] [G loss: 8.032427]\n",
      "epoch:44 step:34853 [D loss: 0.932711, acc: 38.28%] [G loss: 8.017969]\n",
      "epoch:44 step:34854 [D loss: 0.907250, acc: 52.34%] [G loss: 12.173286]\n",
      "epoch:44 step:34855 [D loss: 0.893013, acc: 50.78%] [G loss: 10.841608]\n",
      "epoch:44 step:34856 [D loss: 0.121377, acc: 98.44%] [G loss: 3.249462]\n",
      "epoch:44 step:34857 [D loss: 0.058982, acc: 100.00%] [G loss: 4.396595]\n",
      "epoch:44 step:34858 [D loss: 0.461122, acc: 69.53%] [G loss: 8.059510]\n",
      "epoch:44 step:34859 [D loss: 0.337717, acc: 84.38%] [G loss: 6.214943]\n",
      "epoch:44 step:34860 [D loss: 0.163125, acc: 97.66%] [G loss: 7.432456]\n",
      "epoch:44 step:34861 [D loss: 0.082727, acc: 100.00%] [G loss: 9.347754]\n",
      "epoch:44 step:34862 [D loss: 0.053552, acc: 99.22%] [G loss: 7.522294]\n",
      "epoch:44 step:34863 [D loss: 0.063702, acc: 100.00%] [G loss: 5.155449]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:44 step:34864 [D loss: 0.159105, acc: 99.22%] [G loss: 5.388267]\n",
      "epoch:44 step:34865 [D loss: 0.825252, acc: 57.03%] [G loss: 8.441217]\n",
      "epoch:44 step:34866 [D loss: 0.057069, acc: 100.00%] [G loss: 6.421711]\n",
      "epoch:44 step:34867 [D loss: 0.436176, acc: 69.53%] [G loss: 7.674433]\n",
      "epoch:44 step:34868 [D loss: 0.686997, acc: 57.03%] [G loss: 7.513051]\n",
      "epoch:44 step:34869 [D loss: 0.365184, acc: 89.06%] [G loss: 5.185252]\n",
      "epoch:44 step:34870 [D loss: 0.036132, acc: 100.00%] [G loss: 5.542324]\n",
      "epoch:44 step:34871 [D loss: 0.058936, acc: 100.00%] [G loss: 7.774097]\n",
      "epoch:44 step:34872 [D loss: 0.367907, acc: 78.12%] [G loss: 8.169283]\n",
      "epoch:44 step:34873 [D loss: 0.290014, acc: 96.88%] [G loss: 5.177737]\n",
      "epoch:44 step:34874 [D loss: 0.103553, acc: 100.00%] [G loss: 3.617758]\n",
      "epoch:44 step:34875 [D loss: 0.082502, acc: 100.00%] [G loss: 11.519950]\n",
      "epoch:44 step:34876 [D loss: 0.244420, acc: 98.44%] [G loss: 7.836329]\n",
      "epoch:44 step:34877 [D loss: 0.893982, acc: 47.66%] [G loss: 7.686185]\n",
      "epoch:44 step:34878 [D loss: 0.328630, acc: 88.28%] [G loss: 2.934690]\n",
      "epoch:44 step:34879 [D loss: 0.122571, acc: 98.44%] [G loss: 2.865601]\n",
      "epoch:44 step:34880 [D loss: 0.392064, acc: 77.34%] [G loss: 4.581555]\n",
      "epoch:44 step:34881 [D loss: 0.111981, acc: 98.44%] [G loss: 9.765440]\n",
      "epoch:44 step:34882 [D loss: 0.543739, acc: 61.72%] [G loss: 6.787602]\n",
      "epoch:44 step:34883 [D loss: 0.118921, acc: 100.00%] [G loss: 6.361216]\n",
      "epoch:44 step:34884 [D loss: 0.339481, acc: 93.75%] [G loss: 5.860649]\n",
      "epoch:44 step:34885 [D loss: 0.033762, acc: 100.00%] [G loss: 3.458554]\n",
      "epoch:44 step:34886 [D loss: 0.213006, acc: 95.31%] [G loss: 7.891754]\n",
      "epoch:44 step:34887 [D loss: 0.246285, acc: 92.19%] [G loss: 3.938772]\n",
      "epoch:44 step:34888 [D loss: 0.133075, acc: 98.44%] [G loss: 5.714595]\n",
      "epoch:44 step:34889 [D loss: 0.356298, acc: 89.06%] [G loss: 5.168571]\n",
      "epoch:44 step:34890 [D loss: 0.204619, acc: 96.88%] [G loss: 6.434804]\n",
      "epoch:44 step:34891 [D loss: 0.010795, acc: 100.00%] [G loss: 6.505004]\n",
      "epoch:44 step:34892 [D loss: 0.038406, acc: 100.00%] [G loss: 6.137832]\n",
      "epoch:44 step:34893 [D loss: 0.137763, acc: 98.44%] [G loss: 7.316652]\n",
      "epoch:44 step:34894 [D loss: 0.171812, acc: 98.44%] [G loss: 3.965667]\n",
      "epoch:44 step:34895 [D loss: 0.091538, acc: 100.00%] [G loss: 3.620971]\n",
      "epoch:44 step:34896 [D loss: 0.357547, acc: 92.19%] [G loss: 7.082444]\n",
      "epoch:44 step:34897 [D loss: 0.313993, acc: 86.72%] [G loss: 4.331641]\n",
      "epoch:44 step:34898 [D loss: 0.091647, acc: 99.22%] [G loss: 3.311285]\n",
      "epoch:44 step:34899 [D loss: 0.997887, acc: 35.94%] [G loss: 4.217646]\n",
      "epoch:44 step:34900 [D loss: 0.101353, acc: 100.00%] [G loss: 4.265795]\n",
      "epoch:44 step:34901 [D loss: 0.015206, acc: 100.00%] [G loss: 8.316580]\n",
      "epoch:44 step:34902 [D loss: 0.140735, acc: 98.44%] [G loss: 7.574483]\n",
      "epoch:44 step:34903 [D loss: 1.034771, acc: 44.53%] [G loss: 7.739177]\n",
      "epoch:44 step:34904 [D loss: 0.903049, acc: 52.34%] [G loss: 6.126527]\n",
      "epoch:44 step:34905 [D loss: 0.091815, acc: 99.22%] [G loss: 5.445220]\n",
      "epoch:44 step:34906 [D loss: 0.073541, acc: 100.00%] [G loss: 7.377097]\n",
      "epoch:44 step:34907 [D loss: 0.309416, acc: 89.84%] [G loss: 7.558651]\n",
      "epoch:44 step:34908 [D loss: 0.200691, acc: 96.88%] [G loss: 5.315588]\n",
      "epoch:44 step:34909 [D loss: 0.944992, acc: 52.34%] [G loss: 6.341166]\n",
      "epoch:44 step:34910 [D loss: 0.480520, acc: 71.88%] [G loss: 6.616059]\n",
      "epoch:44 step:34911 [D loss: 0.200922, acc: 97.66%] [G loss: 5.595825]\n",
      "epoch:44 step:34912 [D loss: 0.324352, acc: 84.38%] [G loss: 2.702202]\n",
      "epoch:44 step:34913 [D loss: 0.211672, acc: 94.53%] [G loss: 5.289378]\n",
      "epoch:44 step:34914 [D loss: 0.135839, acc: 100.00%] [G loss: 4.845118]\n",
      "epoch:44 step:34915 [D loss: 0.273271, acc: 92.97%] [G loss: 3.997575]\n",
      "epoch:44 step:34916 [D loss: 0.556115, acc: 61.72%] [G loss: 5.816741]\n",
      "epoch:44 step:34917 [D loss: 0.624873, acc: 65.62%] [G loss: 5.878201]\n",
      "epoch:44 step:34918 [D loss: 0.547872, acc: 75.00%] [G loss: 3.534678]\n",
      "epoch:44 step:34919 [D loss: 0.067585, acc: 100.00%] [G loss: 6.178607]\n",
      "epoch:44 step:34920 [D loss: 0.732567, acc: 59.38%] [G loss: 7.805202]\n",
      "epoch:44 step:34921 [D loss: 0.078791, acc: 100.00%] [G loss: 5.536143]\n",
      "epoch:44 step:34922 [D loss: 0.023689, acc: 100.00%] [G loss: 6.863352]\n",
      "epoch:44 step:34923 [D loss: 0.389413, acc: 76.56%] [G loss: 6.462614]\n",
      "epoch:44 step:34924 [D loss: 0.058389, acc: 100.00%] [G loss: 3.999384]\n",
      "epoch:44 step:34925 [D loss: 0.272715, acc: 97.66%] [G loss: 6.956663]\n",
      "epoch:44 step:34926 [D loss: 0.097545, acc: 99.22%] [G loss: 5.536790]\n",
      "epoch:44 step:34927 [D loss: 0.668933, acc: 57.81%] [G loss: 6.712428]\n",
      "epoch:44 step:34928 [D loss: 0.218716, acc: 95.31%] [G loss: 6.689891]\n",
      "epoch:44 step:34929 [D loss: 0.492371, acc: 73.44%] [G loss: 8.078420]\n",
      "epoch:44 step:34930 [D loss: 0.188042, acc: 96.09%] [G loss: 7.279917]\n",
      "epoch:44 step:34931 [D loss: 0.518600, acc: 75.00%] [G loss: 6.426429]\n",
      "epoch:44 step:34932 [D loss: 0.064314, acc: 99.22%] [G loss: 5.405986]\n",
      "epoch:44 step:34933 [D loss: 0.013336, acc: 100.00%] [G loss: 10.165428]\n",
      "epoch:44 step:34934 [D loss: 2.458842, acc: 1.56%] [G loss: 7.637709]\n",
      "epoch:44 step:34935 [D loss: 0.060173, acc: 99.22%] [G loss: 3.466288]\n",
      "epoch:44 step:34936 [D loss: 0.050717, acc: 100.00%] [G loss: 8.539978]\n",
      "epoch:44 step:34937 [D loss: 0.328276, acc: 90.62%] [G loss: 6.521360]\n",
      "epoch:44 step:34938 [D loss: 0.807751, acc: 53.91%] [G loss: 5.527941]\n",
      "epoch:44 step:34939 [D loss: 1.503362, acc: 47.66%] [G loss: 8.470757]\n",
      "epoch:44 step:34940 [D loss: 0.259021, acc: 89.84%] [G loss: 5.901154]\n",
      "epoch:44 step:34941 [D loss: 0.108201, acc: 100.00%] [G loss: 3.763560]\n",
      "epoch:44 step:34942 [D loss: 0.370148, acc: 80.47%] [G loss: 6.040162]\n",
      "epoch:44 step:34943 [D loss: 0.320639, acc: 82.03%] [G loss: 9.986111]\n",
      "epoch:44 step:34944 [D loss: 0.392554, acc: 85.16%] [G loss: 5.779054]\n",
      "epoch:44 step:34945 [D loss: 0.166543, acc: 96.88%] [G loss: 5.893670]\n",
      "epoch:44 step:34946 [D loss: 0.171512, acc: 97.66%] [G loss: 1.754768]\n",
      "epoch:44 step:34947 [D loss: 0.119747, acc: 99.22%] [G loss: 4.610274]\n",
      "epoch:44 step:34948 [D loss: 0.014286, acc: 100.00%] [G loss: 6.088009]\n",
      "epoch:44 step:34949 [D loss: 0.080903, acc: 100.00%] [G loss: 6.524010]\n",
      "epoch:44 step:34950 [D loss: 0.524804, acc: 65.62%] [G loss: 8.848856]\n",
      "epoch:44 step:34951 [D loss: 0.091674, acc: 100.00%] [G loss: 4.023846]\n",
      "epoch:44 step:34952 [D loss: 0.911550, acc: 50.00%] [G loss: 9.114841]\n",
      "epoch:44 step:34953 [D loss: 0.191683, acc: 97.66%] [G loss: 5.795086]\n",
      "epoch:44 step:34954 [D loss: 0.124653, acc: 99.22%] [G loss: 6.936074]\n",
      "epoch:44 step:34955 [D loss: 0.200168, acc: 96.88%] [G loss: 10.010756]\n",
      "epoch:44 step:34956 [D loss: 0.297898, acc: 91.41%] [G loss: 4.702854]\n",
      "epoch:44 step:34957 [D loss: 0.205642, acc: 92.19%] [G loss: 6.386943]\n",
      "epoch:44 step:34958 [D loss: 0.107276, acc: 99.22%] [G loss: 5.176938]\n",
      "epoch:44 step:34959 [D loss: 0.237935, acc: 96.88%] [G loss: 6.371782]\n",
      "epoch:44 step:34960 [D loss: 0.682659, acc: 58.59%] [G loss: 5.812517]\n",
      "epoch:44 step:34961 [D loss: 0.356714, acc: 88.28%] [G loss: 6.171965]\n",
      "epoch:44 step:34962 [D loss: 0.256368, acc: 90.62%] [G loss: 6.951375]\n",
      "epoch:44 step:34963 [D loss: 0.095266, acc: 99.22%] [G loss: 6.705307]\n",
      "epoch:44 step:34964 [D loss: 0.141972, acc: 98.44%] [G loss: 6.226343]\n",
      "epoch:44 step:34965 [D loss: 0.097328, acc: 100.00%] [G loss: 7.353164]\n",
      "epoch:44 step:34966 [D loss: 0.070594, acc: 100.00%] [G loss: 7.692910]\n",
      "epoch:44 step:34967 [D loss: 0.719231, acc: 55.47%] [G loss: 12.087995]\n",
      "epoch:44 step:34968 [D loss: 0.282924, acc: 95.31%] [G loss: 6.722969]\n",
      "epoch:44 step:34969 [D loss: 0.402674, acc: 73.44%] [G loss: 7.999195]\n",
      "epoch:44 step:34970 [D loss: 0.175408, acc: 98.44%] [G loss: 4.951220]\n",
      "epoch:44 step:34971 [D loss: 0.602092, acc: 68.75%] [G loss: 4.615551]\n",
      "epoch:44 step:34972 [D loss: 1.210420, acc: 17.19%] [G loss: 9.589512]\n",
      "epoch:44 step:34973 [D loss: 0.087591, acc: 100.00%] [G loss: 4.577101]\n",
      "epoch:44 step:34974 [D loss: 0.027989, acc: 100.00%] [G loss: 7.264851]\n",
      "epoch:44 step:34975 [D loss: 0.229701, acc: 96.88%] [G loss: 3.403759]\n",
      "epoch:44 step:34976 [D loss: 0.581828, acc: 66.41%] [G loss: 6.121287]\n",
      "epoch:44 step:34977 [D loss: 0.365336, acc: 76.56%] [G loss: 6.555931]\n",
      "epoch:44 step:34978 [D loss: 0.460493, acc: 81.25%] [G loss: 8.221025]\n",
      "epoch:44 step:34979 [D loss: 0.191962, acc: 92.97%] [G loss: 10.199753]\n",
      "epoch:44 step:34980 [D loss: 0.120173, acc: 97.66%] [G loss: 7.265306]\n",
      "epoch:44 step:34981 [D loss: 0.047780, acc: 100.00%] [G loss: 7.264838]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:44 step:34982 [D loss: 0.548285, acc: 67.19%] [G loss: 9.834039]\n",
      "epoch:44 step:34983 [D loss: 0.302888, acc: 88.28%] [G loss: 5.709078]\n",
      "epoch:44 step:34984 [D loss: 1.492405, acc: 45.31%] [G loss: 5.486368]\n",
      "epoch:44 step:34985 [D loss: 0.178604, acc: 96.88%] [G loss: 7.162234]\n",
      "epoch:44 step:34986 [D loss: 0.900586, acc: 52.34%] [G loss: 7.655956]\n",
      "epoch:44 step:34987 [D loss: 0.305691, acc: 85.16%] [G loss: 5.498793]\n",
      "epoch:44 step:34988 [D loss: 0.976416, acc: 51.56%] [G loss: 10.020573]\n",
      "epoch:44 step:34989 [D loss: 0.316138, acc: 82.81%] [G loss: 9.197275]\n",
      "epoch:44 step:34990 [D loss: 0.369965, acc: 76.56%] [G loss: 7.499990]\n",
      "epoch:44 step:34991 [D loss: 0.414374, acc: 79.69%] [G loss: 4.843638]\n",
      "epoch:44 step:34992 [D loss: 0.020705, acc: 100.00%] [G loss: 8.505558]\n",
      "epoch:44 step:34993 [D loss: 0.340651, acc: 82.81%] [G loss: 5.557947]\n",
      "epoch:44 step:34994 [D loss: 0.127995, acc: 100.00%] [G loss: 6.445660]\n",
      "epoch:44 step:34995 [D loss: 0.212382, acc: 94.53%] [G loss: 5.389438]\n",
      "epoch:44 step:34996 [D loss: 1.289817, acc: 50.78%] [G loss: 5.349727]\n",
      "epoch:44 step:34997 [D loss: 1.122319, acc: 50.78%] [G loss: 10.311040]\n",
      "epoch:44 step:34998 [D loss: 0.274502, acc: 87.50%] [G loss: 5.968812]\n",
      "epoch:44 step:34999 [D loss: 0.534920, acc: 74.22%] [G loss: 6.858333]\n",
      "epoch:44 step:35000 [D loss: 0.278581, acc: 91.41%] [G loss: 5.227829]\n",
      "##############\n",
      "[0.87114824 0.87266637 0.82237972 0.80890177 0.8067816  0.80636749\n",
      " 0.88897433 0.80758916 0.80161104 0.81243065]\n",
      "##########\n",
      "epoch:44 step:35001 [D loss: 0.429018, acc: 71.88%] [G loss: 7.696458]\n",
      "epoch:44 step:35002 [D loss: 0.102078, acc: 100.00%] [G loss: 4.863727]\n",
      "epoch:44 step:35003 [D loss: 0.335765, acc: 79.69%] [G loss: 9.086061]\n",
      "epoch:44 step:35004 [D loss: 0.433751, acc: 72.66%] [G loss: 8.258044]\n",
      "epoch:44 step:35005 [D loss: 0.197700, acc: 96.88%] [G loss: 4.409146]\n",
      "epoch:44 step:35006 [D loss: 0.199523, acc: 97.66%] [G loss: 4.445998]\n",
      "epoch:44 step:35007 [D loss: 0.280334, acc: 90.62%] [G loss: 8.576841]\n",
      "epoch:44 step:35008 [D loss: 0.217027, acc: 92.19%] [G loss: 4.175266]\n",
      "epoch:44 step:35009 [D loss: 0.161382, acc: 96.88%] [G loss: 6.316106]\n",
      "epoch:44 step:35010 [D loss: 0.304903, acc: 93.75%] [G loss: 7.306192]\n",
      "epoch:44 step:35011 [D loss: 0.042697, acc: 100.00%] [G loss: 4.284003]\n",
      "epoch:44 step:35012 [D loss: 0.438027, acc: 69.53%] [G loss: 9.260670]\n",
      "epoch:44 step:35013 [D loss: 0.224610, acc: 91.41%] [G loss: 8.196058]\n",
      "epoch:44 step:35014 [D loss: 0.320386, acc: 93.75%] [G loss: 2.651730]\n",
      "epoch:44 step:35015 [D loss: 0.405506, acc: 83.59%] [G loss: 5.205882]\n",
      "epoch:44 step:35016 [D loss: 0.342440, acc: 81.25%] [G loss: 6.667071]\n",
      "epoch:44 step:35017 [D loss: 0.074993, acc: 100.00%] [G loss: 9.737026]\n",
      "epoch:44 step:35018 [D loss: 0.035127, acc: 100.00%] [G loss: 7.251635]\n",
      "epoch:44 step:35019 [D loss: 0.604086, acc: 60.94%] [G loss: 3.389458]\n",
      "epoch:44 step:35020 [D loss: 0.120543, acc: 100.00%] [G loss: 8.014903]\n",
      "epoch:44 step:35021 [D loss: 0.744035, acc: 54.69%] [G loss: 6.441496]\n",
      "epoch:44 step:35022 [D loss: 0.149009, acc: 97.66%] [G loss: 5.185980]\n",
      "epoch:44 step:35023 [D loss: 0.595736, acc: 60.94%] [G loss: 7.814467]\n",
      "epoch:44 step:35024 [D loss: 0.112254, acc: 98.44%] [G loss: 6.125550]\n",
      "epoch:44 step:35025 [D loss: 0.483430, acc: 68.75%] [G loss: 7.984894]\n",
      "epoch:44 step:35026 [D loss: 0.128320, acc: 98.44%] [G loss: 7.589170]\n",
      "epoch:44 step:35027 [D loss: 0.119041, acc: 99.22%] [G loss: 6.050681]\n",
      "epoch:44 step:35028 [D loss: 0.027360, acc: 100.00%] [G loss: 4.757101]\n",
      "epoch:44 step:35029 [D loss: 0.268070, acc: 88.28%] [G loss: 5.838547]\n",
      "epoch:44 step:35030 [D loss: 0.122739, acc: 100.00%] [G loss: 3.199828]\n",
      "epoch:44 step:35031 [D loss: 0.031408, acc: 100.00%] [G loss: 10.930611]\n",
      "epoch:44 step:35032 [D loss: 0.206916, acc: 94.53%] [G loss: 4.644422]\n",
      "epoch:44 step:35033 [D loss: 0.202122, acc: 98.44%] [G loss: 4.398357]\n",
      "epoch:44 step:35034 [D loss: 0.855802, acc: 48.44%] [G loss: 5.419269]\n",
      "epoch:44 step:35035 [D loss: 0.095526, acc: 99.22%] [G loss: 7.107561]\n",
      "epoch:44 step:35036 [D loss: 0.039880, acc: 100.00%] [G loss: 7.787168]\n",
      "epoch:44 step:35037 [D loss: 0.056144, acc: 100.00%] [G loss: 7.763803]\n",
      "epoch:44 step:35038 [D loss: 0.078995, acc: 100.00%] [G loss: 5.425082]\n",
      "epoch:44 step:35039 [D loss: 0.095256, acc: 99.22%] [G loss: 4.508985]\n",
      "epoch:44 step:35040 [D loss: 0.036235, acc: 100.00%] [G loss: 8.497469]\n",
      "epoch:44 step:35041 [D loss: 0.313306, acc: 85.16%] [G loss: 7.179021]\n",
      "epoch:44 step:35042 [D loss: 1.184965, acc: 18.75%] [G loss: 7.715614]\n",
      "epoch:44 step:35043 [D loss: 0.070410, acc: 100.00%] [G loss: 8.114019]\n",
      "epoch:44 step:35044 [D loss: 0.261374, acc: 90.62%] [G loss: 8.561369]\n",
      "epoch:44 step:35045 [D loss: 1.092298, acc: 49.22%] [G loss: 10.145395]\n",
      "epoch:44 step:35046 [D loss: 0.022515, acc: 100.00%] [G loss: 7.076055]\n",
      "epoch:44 step:35047 [D loss: 0.147778, acc: 98.44%] [G loss: 6.474002]\n",
      "epoch:44 step:35048 [D loss: 0.022789, acc: 100.00%] [G loss: 6.527640]\n",
      "epoch:44 step:35049 [D loss: 0.187764, acc: 96.09%] [G loss: 6.909016]\n",
      "epoch:44 step:35050 [D loss: 0.156384, acc: 96.09%] [G loss: 4.768430]\n",
      "epoch:44 step:35051 [D loss: 0.267436, acc: 93.75%] [G loss: 5.180905]\n",
      "epoch:44 step:35052 [D loss: 0.178392, acc: 97.66%] [G loss: 8.624248]\n",
      "epoch:44 step:35053 [D loss: 0.038610, acc: 100.00%] [G loss: 5.138618]\n",
      "epoch:44 step:35054 [D loss: 0.132008, acc: 100.00%] [G loss: 10.913302]\n",
      "epoch:44 step:35055 [D loss: 0.418589, acc: 69.53%] [G loss: 8.271332]\n",
      "epoch:44 step:35056 [D loss: 1.220477, acc: 21.88%] [G loss: 5.857666]\n",
      "epoch:44 step:35057 [D loss: 0.162992, acc: 98.44%] [G loss: 5.509123]\n",
      "epoch:44 step:35058 [D loss: 0.120497, acc: 99.22%] [G loss: 5.954672]\n",
      "epoch:44 step:35059 [D loss: 0.219292, acc: 93.75%] [G loss: 3.736264]\n",
      "epoch:44 step:35060 [D loss: 0.297288, acc: 86.72%] [G loss: 4.337208]\n",
      "epoch:44 step:35061 [D loss: 1.124984, acc: 30.47%] [G loss: 7.170440]\n",
      "epoch:44 step:35062 [D loss: 0.477489, acc: 68.75%] [G loss: 6.834266]\n",
      "epoch:44 step:35063 [D loss: 0.337144, acc: 93.75%] [G loss: 6.255494]\n",
      "epoch:44 step:35064 [D loss: 0.255080, acc: 91.41%] [G loss: 7.007925]\n",
      "epoch:44 step:35065 [D loss: 0.593882, acc: 69.53%] [G loss: 5.571423]\n",
      "epoch:44 step:35066 [D loss: 0.058088, acc: 100.00%] [G loss: 7.603487]\n",
      "epoch:44 step:35067 [D loss: 0.141528, acc: 95.31%] [G loss: 6.208012]\n",
      "epoch:44 step:35068 [D loss: 0.234392, acc: 95.31%] [G loss: 6.640483]\n",
      "epoch:44 step:35069 [D loss: 0.068703, acc: 100.00%] [G loss: 9.458099]\n",
      "epoch:44 step:35070 [D loss: 0.931633, acc: 53.91%] [G loss: 8.130545]\n",
      "epoch:44 step:35071 [D loss: 0.292627, acc: 87.50%] [G loss: 6.893222]\n",
      "epoch:44 step:35072 [D loss: 1.000230, acc: 50.78%] [G loss: 9.791322]\n",
      "epoch:44 step:35073 [D loss: 0.233095, acc: 89.84%] [G loss: 3.880053]\n",
      "epoch:44 step:35074 [D loss: 0.533176, acc: 60.16%] [G loss: 7.134045]\n",
      "epoch:44 step:35075 [D loss: 0.392073, acc: 73.44%] [G loss: 5.482551]\n",
      "epoch:44 step:35076 [D loss: 0.047230, acc: 100.00%] [G loss: 8.039474]\n",
      "epoch:44 step:35077 [D loss: 0.127953, acc: 99.22%] [G loss: 9.326566]\n",
      "epoch:44 step:35078 [D loss: 0.097073, acc: 99.22%] [G loss: 6.521543]\n",
      "epoch:44 step:35079 [D loss: 0.046364, acc: 100.00%] [G loss: 8.062582]\n",
      "epoch:44 step:35080 [D loss: 0.167629, acc: 99.22%] [G loss: 8.100401]\n",
      "epoch:44 step:35081 [D loss: 0.124172, acc: 100.00%] [G loss: 6.878905]\n",
      "epoch:44 step:35082 [D loss: 0.089258, acc: 100.00%] [G loss: 7.120994]\n",
      "epoch:44 step:35083 [D loss: 0.386488, acc: 81.25%] [G loss: 4.863727]\n",
      "epoch:44 step:35084 [D loss: 0.654011, acc: 56.25%] [G loss: 5.393404]\n",
      "epoch:44 step:35085 [D loss: 0.536269, acc: 75.78%] [G loss: 9.489237]\n",
      "epoch:44 step:35086 [D loss: 0.327921, acc: 93.75%] [G loss: 4.400611]\n",
      "epoch:44 step:35087 [D loss: 0.003695, acc: 100.00%] [G loss: 7.838639]\n",
      "epoch:44 step:35088 [D loss: 0.031078, acc: 100.00%] [G loss: 6.861160]\n",
      "epoch:44 step:35089 [D loss: 0.006762, acc: 100.00%] [G loss: 6.900557]\n",
      "epoch:44 step:35090 [D loss: 0.060013, acc: 99.22%] [G loss: 7.609078]\n",
      "epoch:44 step:35091 [D loss: 0.223554, acc: 97.66%] [G loss: 4.780016]\n",
      "epoch:44 step:35092 [D loss: 0.123426, acc: 100.00%] [G loss: 2.962728]\n",
      "epoch:44 step:35093 [D loss: 0.078738, acc: 99.22%] [G loss: 9.823907]\n",
      "epoch:44 step:35094 [D loss: 0.388496, acc: 83.59%] [G loss: 7.060137]\n",
      "epoch:44 step:35095 [D loss: 0.043009, acc: 100.00%] [G loss: 6.771328]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:44 step:35096 [D loss: 0.428842, acc: 83.59%] [G loss: 4.057294]\n",
      "epoch:44 step:35097 [D loss: 0.524851, acc: 65.62%] [G loss: 5.001120]\n",
      "epoch:44 step:35098 [D loss: 0.288870, acc: 95.31%] [G loss: 4.414175]\n",
      "epoch:44 step:35099 [D loss: 0.500095, acc: 66.41%] [G loss: 7.952526]\n",
      "epoch:44 step:35100 [D loss: 0.705815, acc: 57.81%] [G loss: 6.866859]\n",
      "epoch:44 step:35101 [D loss: 0.026069, acc: 100.00%] [G loss: 5.697357]\n",
      "epoch:44 step:35102 [D loss: 0.171727, acc: 97.66%] [G loss: 5.242314]\n",
      "epoch:44 step:35103 [D loss: 0.292389, acc: 89.06%] [G loss: 6.727517]\n",
      "epoch:44 step:35104 [D loss: 0.131104, acc: 97.66%] [G loss: 8.196037]\n",
      "epoch:44 step:35105 [D loss: 0.082404, acc: 99.22%] [G loss: 3.296890]\n",
      "epoch:44 step:35106 [D loss: 0.224259, acc: 93.75%] [G loss: 5.398842]\n",
      "epoch:44 step:35107 [D loss: 0.995227, acc: 50.78%] [G loss: 9.229156]\n",
      "epoch:44 step:35108 [D loss: 0.032993, acc: 100.00%] [G loss: 4.447073]\n",
      "epoch:44 step:35109 [D loss: 0.090193, acc: 100.00%] [G loss: 8.896335]\n",
      "epoch:44 step:35110 [D loss: 0.115379, acc: 99.22%] [G loss: 5.845956]\n",
      "epoch:44 step:35111 [D loss: 0.231603, acc: 92.97%] [G loss: 5.756200]\n",
      "epoch:44 step:35112 [D loss: 0.348074, acc: 87.50%] [G loss: 6.153132]\n",
      "epoch:44 step:35113 [D loss: 0.123146, acc: 99.22%] [G loss: 3.790796]\n",
      "epoch:44 step:35114 [D loss: 0.203919, acc: 94.53%] [G loss: 6.031056]\n",
      "epoch:44 step:35115 [D loss: 0.123774, acc: 98.44%] [G loss: 4.852605]\n",
      "epoch:44 step:35116 [D loss: 0.100649, acc: 99.22%] [G loss: 4.189312]\n",
      "epoch:44 step:35117 [D loss: 0.250562, acc: 96.09%] [G loss: 5.304080]\n",
      "epoch:44 step:35118 [D loss: 0.798420, acc: 53.12%] [G loss: 7.520459]\n",
      "epoch:44 step:35119 [D loss: 0.048639, acc: 100.00%] [G loss: 2.806971]\n",
      "epoch:44 step:35120 [D loss: 1.443392, acc: 48.44%] [G loss: 3.903624]\n",
      "epoch:44 step:35121 [D loss: 0.246084, acc: 95.31%] [G loss: 5.967219]\n",
      "epoch:44 step:35122 [D loss: 0.121544, acc: 99.22%] [G loss: 7.262334]\n",
      "epoch:44 step:35123 [D loss: 0.219922, acc: 91.41%] [G loss: 5.989549]\n",
      "epoch:44 step:35124 [D loss: 0.073271, acc: 98.44%] [G loss: 7.614073]\n",
      "epoch:44 step:35125 [D loss: 0.081481, acc: 99.22%] [G loss: 3.247966]\n",
      "epoch:44 step:35126 [D loss: 0.052398, acc: 100.00%] [G loss: 8.423660]\n",
      "epoch:44 step:35127 [D loss: 0.042117, acc: 100.00%] [G loss: 6.848643]\n",
      "epoch:44 step:35128 [D loss: 0.493961, acc: 75.78%] [G loss: 6.286548]\n",
      "epoch:44 step:35129 [D loss: 0.032020, acc: 100.00%] [G loss: 5.403194]\n",
      "epoch:44 step:35130 [D loss: 0.723731, acc: 54.69%] [G loss: 9.263105]\n",
      "epoch:44 step:35131 [D loss: 0.357466, acc: 77.34%] [G loss: 5.827517]\n",
      "epoch:44 step:35132 [D loss: 0.064372, acc: 100.00%] [G loss: 8.797565]\n",
      "epoch:44 step:35133 [D loss: 0.070734, acc: 99.22%] [G loss: 4.857398]\n",
      "epoch:44 step:35134 [D loss: 0.279170, acc: 95.31%] [G loss: 5.767019]\n",
      "epoch:44 step:35135 [D loss: 0.182186, acc: 97.66%] [G loss: 4.773904]\n",
      "epoch:44 step:35136 [D loss: 0.243841, acc: 94.53%] [G loss: 4.497013]\n",
      "epoch:44 step:35137 [D loss: 0.069432, acc: 98.44%] [G loss: 7.024291]\n",
      "epoch:44 step:35138 [D loss: 0.058208, acc: 100.00%] [G loss: 4.751365]\n",
      "epoch:44 step:35139 [D loss: 0.019130, acc: 100.00%] [G loss: 8.684781]\n",
      "epoch:44 step:35140 [D loss: 0.485808, acc: 68.75%] [G loss: 5.978370]\n",
      "epoch:44 step:35141 [D loss: 0.847535, acc: 55.47%] [G loss: 5.802930]\n",
      "epoch:44 step:35142 [D loss: 0.040226, acc: 100.00%] [G loss: 6.408447]\n",
      "epoch:44 step:35143 [D loss: 0.039121, acc: 100.00%] [G loss: 7.782015]\n",
      "epoch:44 step:35144 [D loss: 0.276283, acc: 93.75%] [G loss: 4.346288]\n",
      "epoch:44 step:35145 [D loss: 1.806611, acc: 12.50%] [G loss: 5.554503]\n",
      "epoch:45 step:35146 [D loss: 0.653325, acc: 58.59%] [G loss: 3.873987]\n",
      "epoch:45 step:35147 [D loss: 0.205603, acc: 96.88%] [G loss: 8.430107]\n",
      "epoch:45 step:35148 [D loss: 0.046797, acc: 100.00%] [G loss: 8.194872]\n",
      "epoch:45 step:35149 [D loss: 0.045198, acc: 100.00%] [G loss: 5.420513]\n",
      "epoch:45 step:35150 [D loss: 0.467176, acc: 74.22%] [G loss: 3.955114]\n",
      "epoch:45 step:35151 [D loss: 2.399121, acc: 0.78%] [G loss: 7.261167]\n",
      "epoch:45 step:35152 [D loss: 0.198021, acc: 94.53%] [G loss: 5.627574]\n",
      "epoch:45 step:35153 [D loss: 0.386335, acc: 81.25%] [G loss: 8.015352]\n",
      "epoch:45 step:35154 [D loss: 0.646556, acc: 64.06%] [G loss: 9.464334]\n",
      "epoch:45 step:35155 [D loss: 0.841881, acc: 48.44%] [G loss: 1.873070]\n",
      "epoch:45 step:35156 [D loss: 0.188072, acc: 98.44%] [G loss: 4.168139]\n",
      "epoch:45 step:35157 [D loss: 0.226806, acc: 96.88%] [G loss: 6.835586]\n",
      "epoch:45 step:35158 [D loss: 1.148484, acc: 22.66%] [G loss: 8.371634]\n",
      "epoch:45 step:35159 [D loss: 0.067388, acc: 100.00%] [G loss: 5.844920]\n",
      "epoch:45 step:35160 [D loss: 0.991454, acc: 47.66%] [G loss: 8.196620]\n",
      "epoch:45 step:35161 [D loss: 0.425129, acc: 78.12%] [G loss: 4.726803]\n",
      "epoch:45 step:35162 [D loss: 0.400500, acc: 83.59%] [G loss: 6.322818]\n",
      "epoch:45 step:35163 [D loss: 0.316002, acc: 82.81%] [G loss: 6.902012]\n",
      "epoch:45 step:35164 [D loss: 0.019553, acc: 100.00%] [G loss: 7.036269]\n",
      "epoch:45 step:35165 [D loss: 0.020118, acc: 100.00%] [G loss: 3.347309]\n",
      "epoch:45 step:35166 [D loss: 0.285212, acc: 84.38%] [G loss: 10.157042]\n",
      "epoch:45 step:35167 [D loss: 0.024303, acc: 100.00%] [G loss: 9.214897]\n",
      "epoch:45 step:35168 [D loss: 0.116470, acc: 97.66%] [G loss: 4.509120]\n",
      "epoch:45 step:35169 [D loss: 0.049132, acc: 100.00%] [G loss: 6.240848]\n",
      "epoch:45 step:35170 [D loss: 0.069134, acc: 100.00%] [G loss: 8.108145]\n",
      "epoch:45 step:35171 [D loss: 0.103561, acc: 99.22%] [G loss: 3.604743]\n",
      "epoch:45 step:35172 [D loss: 0.088273, acc: 100.00%] [G loss: 4.704908]\n",
      "epoch:45 step:35173 [D loss: 0.034512, acc: 100.00%] [G loss: 6.664882]\n",
      "epoch:45 step:35174 [D loss: 0.751244, acc: 52.34%] [G loss: 5.078497]\n",
      "epoch:45 step:35175 [D loss: 0.009750, acc: 100.00%] [G loss: 6.647322]\n",
      "epoch:45 step:35176 [D loss: 0.075599, acc: 99.22%] [G loss: 7.958777]\n",
      "epoch:45 step:35177 [D loss: 0.107681, acc: 99.22%] [G loss: 7.055137]\n",
      "epoch:45 step:35178 [D loss: 0.452676, acc: 71.88%] [G loss: 7.382994]\n",
      "epoch:45 step:35179 [D loss: 0.582564, acc: 61.72%] [G loss: 6.125345]\n",
      "epoch:45 step:35180 [D loss: 0.254517, acc: 91.41%] [G loss: 5.687694]\n",
      "epoch:45 step:35181 [D loss: 0.346382, acc: 82.81%] [G loss: 5.944355]\n",
      "epoch:45 step:35182 [D loss: 0.056697, acc: 100.00%] [G loss: 7.534841]\n",
      "epoch:45 step:35183 [D loss: 0.226924, acc: 95.31%] [G loss: 3.934960]\n",
      "epoch:45 step:35184 [D loss: 0.255684, acc: 90.62%] [G loss: 3.436343]\n",
      "epoch:45 step:35185 [D loss: 0.658710, acc: 56.25%] [G loss: 9.772905]\n",
      "epoch:45 step:35186 [D loss: 0.375344, acc: 75.78%] [G loss: 9.332892]\n",
      "epoch:45 step:35187 [D loss: 0.104830, acc: 100.00%] [G loss: 4.075867]\n",
      "epoch:45 step:35188 [D loss: 0.076429, acc: 100.00%] [G loss: 5.175209]\n",
      "epoch:45 step:35189 [D loss: 0.189611, acc: 96.09%] [G loss: 6.489739]\n",
      "epoch:45 step:35190 [D loss: 0.266288, acc: 87.50%] [G loss: 4.085641]\n",
      "epoch:45 step:35191 [D loss: 0.204033, acc: 94.53%] [G loss: 5.472720]\n",
      "epoch:45 step:35192 [D loss: 0.445948, acc: 81.25%] [G loss: 4.972525]\n",
      "epoch:45 step:35193 [D loss: 0.070014, acc: 100.00%] [G loss: 3.674278]\n",
      "epoch:45 step:35194 [D loss: 0.245897, acc: 86.72%] [G loss: 7.097458]\n",
      "epoch:45 step:35195 [D loss: 0.727374, acc: 54.69%] [G loss: 6.224771]\n",
      "epoch:45 step:35196 [D loss: 0.553895, acc: 65.62%] [G loss: 3.778039]\n",
      "epoch:45 step:35197 [D loss: 0.653712, acc: 64.06%] [G loss: 7.873185]\n",
      "epoch:45 step:35198 [D loss: 0.757214, acc: 53.91%] [G loss: 8.224396]\n",
      "epoch:45 step:35199 [D loss: 0.099252, acc: 100.00%] [G loss: 6.592021]\n",
      "epoch:45 step:35200 [D loss: 0.044823, acc: 100.00%] [G loss: 8.622543]\n",
      "##############\n",
      "[0.85017346 0.87730312 0.80509707 0.8248151  0.76531658 0.82486022\n",
      " 0.91770241 0.83197645 0.77668804 0.80278249]\n",
      "##########\n",
      "epoch:45 step:35201 [D loss: 0.386211, acc: 84.38%] [G loss: 9.084633]\n",
      "epoch:45 step:35202 [D loss: 0.160251, acc: 99.22%] [G loss: 5.536356]\n",
      "epoch:45 step:35203 [D loss: 0.076717, acc: 100.00%] [G loss: 5.522427]\n",
      "epoch:45 step:35204 [D loss: 0.195800, acc: 95.31%] [G loss: 6.241596]\n",
      "epoch:45 step:35205 [D loss: 1.167686, acc: 13.28%] [G loss: 6.082788]\n",
      "epoch:45 step:35206 [D loss: 0.235571, acc: 95.31%] [G loss: 4.517537]\n",
      "epoch:45 step:35207 [D loss: 0.011003, acc: 100.00%] [G loss: 8.173313]\n",
      "epoch:45 step:35208 [D loss: 0.048334, acc: 100.00%] [G loss: 5.022647]\n",
      "epoch:45 step:35209 [D loss: 1.040398, acc: 47.66%] [G loss: 5.522527]\n",
      "epoch:45 step:35210 [D loss: 0.163925, acc: 93.75%] [G loss: 7.144996]\n",
      "epoch:45 step:35211 [D loss: 0.035736, acc: 100.00%] [G loss: 4.552479]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:45 step:35212 [D loss: 0.256578, acc: 92.19%] [G loss: 5.087623]\n",
      "epoch:45 step:35213 [D loss: 0.670810, acc: 57.03%] [G loss: 3.816787]\n",
      "epoch:45 step:35214 [D loss: 0.170765, acc: 96.09%] [G loss: 3.126538]\n",
      "epoch:45 step:35215 [D loss: 0.101428, acc: 99.22%] [G loss: 5.985399]\n",
      "epoch:45 step:35216 [D loss: 0.658775, acc: 63.28%] [G loss: 6.267300]\n",
      "epoch:45 step:35217 [D loss: 0.640315, acc: 67.19%] [G loss: 9.473158]\n",
      "epoch:45 step:35218 [D loss: 0.131189, acc: 97.66%] [G loss: 5.032692]\n",
      "epoch:45 step:35219 [D loss: 0.297929, acc: 88.28%] [G loss: 7.888365]\n",
      "epoch:45 step:35220 [D loss: 0.234768, acc: 88.28%] [G loss: 6.805435]\n",
      "epoch:45 step:35221 [D loss: 0.195223, acc: 95.31%] [G loss: 6.242472]\n",
      "epoch:45 step:35222 [D loss: 0.514661, acc: 64.84%] [G loss: 8.818935]\n",
      "epoch:45 step:35223 [D loss: 0.821006, acc: 51.56%] [G loss: 5.943256]\n",
      "epoch:45 step:35224 [D loss: 0.129508, acc: 99.22%] [G loss: 7.928343]\n",
      "epoch:45 step:35225 [D loss: 0.114930, acc: 97.66%] [G loss: 6.626122]\n",
      "epoch:45 step:35226 [D loss: 0.486632, acc: 69.53%] [G loss: 8.630198]\n",
      "epoch:45 step:35227 [D loss: 0.007450, acc: 100.00%] [G loss: 10.626155]\n",
      "epoch:45 step:35228 [D loss: 0.360655, acc: 79.69%] [G loss: 8.517853]\n",
      "epoch:45 step:35229 [D loss: 0.059301, acc: 100.00%] [G loss: 5.854353]\n",
      "epoch:45 step:35230 [D loss: 0.067428, acc: 100.00%] [G loss: 5.759663]\n",
      "epoch:45 step:35231 [D loss: 0.030583, acc: 100.00%] [G loss: 6.164529]\n",
      "epoch:45 step:35232 [D loss: 0.243296, acc: 93.75%] [G loss: 4.088399]\n",
      "epoch:45 step:35233 [D loss: 0.803269, acc: 50.78%] [G loss: 6.693655]\n",
      "epoch:45 step:35234 [D loss: 0.025393, acc: 100.00%] [G loss: 12.476054]\n",
      "epoch:45 step:35235 [D loss: 0.026097, acc: 100.00%] [G loss: 6.862870]\n",
      "epoch:45 step:35236 [D loss: 0.148429, acc: 98.44%] [G loss: 9.683358]\n",
      "epoch:45 step:35237 [D loss: 0.036313, acc: 100.00%] [G loss: 3.469318]\n",
      "epoch:45 step:35238 [D loss: 0.146504, acc: 96.09%] [G loss: 6.146133]\n",
      "epoch:45 step:35239 [D loss: 0.132041, acc: 97.66%] [G loss: 5.289730]\n",
      "epoch:45 step:35240 [D loss: 0.417133, acc: 78.12%] [G loss: 4.338231]\n",
      "epoch:45 step:35241 [D loss: 0.796891, acc: 38.28%] [G loss: 5.400167]\n",
      "epoch:45 step:35242 [D loss: 0.605418, acc: 67.19%] [G loss: 6.267407]\n",
      "epoch:45 step:35243 [D loss: 0.384428, acc: 78.91%] [G loss: 6.206567]\n",
      "epoch:45 step:35244 [D loss: 0.075319, acc: 100.00%] [G loss: 5.072972]\n",
      "epoch:45 step:35245 [D loss: 0.029799, acc: 100.00%] [G loss: 7.142529]\n",
      "epoch:45 step:35246 [D loss: 0.317906, acc: 91.41%] [G loss: 7.373360]\n",
      "epoch:45 step:35247 [D loss: 0.014374, acc: 100.00%] [G loss: 7.222017]\n",
      "epoch:45 step:35248 [D loss: 0.124463, acc: 100.00%] [G loss: 7.661288]\n",
      "epoch:45 step:35249 [D loss: 0.014495, acc: 100.00%] [G loss: 5.169127]\n",
      "epoch:45 step:35250 [D loss: 0.474518, acc: 81.25%] [G loss: 5.792573]\n",
      "epoch:45 step:35251 [D loss: 0.154688, acc: 96.88%] [G loss: 3.978234]\n",
      "epoch:45 step:35252 [D loss: 0.257244, acc: 94.53%] [G loss: 7.456320]\n",
      "epoch:45 step:35253 [D loss: 0.391261, acc: 81.25%] [G loss: 4.209505]\n",
      "epoch:45 step:35254 [D loss: 0.061381, acc: 100.00%] [G loss: 7.510010]\n",
      "epoch:45 step:35255 [D loss: 0.089183, acc: 99.22%] [G loss: 6.280987]\n",
      "epoch:45 step:35256 [D loss: 0.459168, acc: 70.31%] [G loss: 4.737316]\n",
      "epoch:45 step:35257 [D loss: 0.351458, acc: 90.62%] [G loss: 5.950813]\n",
      "epoch:45 step:35258 [D loss: 0.266702, acc: 86.72%] [G loss: 10.990631]\n",
      "epoch:45 step:35259 [D loss: 0.780025, acc: 53.91%] [G loss: 5.855390]\n",
      "epoch:45 step:35260 [D loss: 0.086742, acc: 100.00%] [G loss: 5.461997]\n",
      "epoch:45 step:35261 [D loss: 0.383934, acc: 87.50%] [G loss: 8.548786]\n",
      "epoch:45 step:35262 [D loss: 0.605971, acc: 67.97%] [G loss: 7.505511]\n",
      "epoch:45 step:35263 [D loss: 0.326378, acc: 82.03%] [G loss: 6.506042]\n",
      "epoch:45 step:35264 [D loss: 0.039366, acc: 100.00%] [G loss: 6.451139]\n",
      "epoch:45 step:35265 [D loss: 0.200143, acc: 96.88%] [G loss: 4.995040]\n",
      "epoch:45 step:35266 [D loss: 0.589722, acc: 59.38%] [G loss: 8.720873]\n",
      "epoch:45 step:35267 [D loss: 0.004944, acc: 100.00%] [G loss: 7.063512]\n",
      "epoch:45 step:35268 [D loss: 0.116942, acc: 97.66%] [G loss: 8.235135]\n",
      "epoch:45 step:35269 [D loss: 0.035996, acc: 100.00%] [G loss: 5.115067]\n",
      "epoch:45 step:35270 [D loss: 0.213154, acc: 93.75%] [G loss: 9.529062]\n",
      "epoch:45 step:35271 [D loss: 0.370096, acc: 82.03%] [G loss: 3.567014]\n",
      "epoch:45 step:35272 [D loss: 0.753968, acc: 54.69%] [G loss: 5.969197]\n",
      "epoch:45 step:35273 [D loss: 0.216981, acc: 92.97%] [G loss: 9.716031]\n",
      "epoch:45 step:35274 [D loss: 1.170381, acc: 31.25%] [G loss: 11.841781]\n",
      "epoch:45 step:35275 [D loss: 0.173398, acc: 96.88%] [G loss: 4.495340]\n",
      "epoch:45 step:35276 [D loss: 0.023281, acc: 100.00%] [G loss: 2.870161]\n",
      "epoch:45 step:35277 [D loss: 0.255692, acc: 90.62%] [G loss: 5.666797]\n",
      "epoch:45 step:35278 [D loss: 0.248541, acc: 95.31%] [G loss: 6.120499]\n",
      "epoch:45 step:35279 [D loss: 0.149563, acc: 95.31%] [G loss: 7.736803]\n",
      "epoch:45 step:35280 [D loss: 0.266889, acc: 90.62%] [G loss: 12.130651]\n",
      "epoch:45 step:35281 [D loss: 0.308254, acc: 93.75%] [G loss: 5.900655]\n",
      "epoch:45 step:35282 [D loss: 0.308997, acc: 88.28%] [G loss: 4.860347]\n",
      "epoch:45 step:35283 [D loss: 0.033831, acc: 100.00%] [G loss: 7.764471]\n",
      "epoch:45 step:35284 [D loss: 0.344145, acc: 85.94%] [G loss: 3.388452]\n",
      "epoch:45 step:35285 [D loss: 0.101382, acc: 100.00%] [G loss: 1.694857]\n",
      "epoch:45 step:35286 [D loss: 1.012150, acc: 32.03%] [G loss: 9.495637]\n",
      "epoch:45 step:35287 [D loss: 0.214530, acc: 96.88%] [G loss: 6.983039]\n",
      "epoch:45 step:35288 [D loss: 0.338513, acc: 89.84%] [G loss: 3.833061]\n",
      "epoch:45 step:35289 [D loss: 0.088190, acc: 100.00%] [G loss: 9.710267]\n",
      "epoch:45 step:35290 [D loss: 1.007939, acc: 50.78%] [G loss: 8.974588]\n",
      "epoch:45 step:35291 [D loss: 0.297612, acc: 94.53%] [G loss: 5.095472]\n",
      "epoch:45 step:35292 [D loss: 0.363423, acc: 75.78%] [G loss: 6.829611]\n",
      "epoch:45 step:35293 [D loss: 0.055135, acc: 100.00%] [G loss: 8.215907]\n",
      "epoch:45 step:35294 [D loss: 0.169760, acc: 99.22%] [G loss: 4.737960]\n",
      "epoch:45 step:35295 [D loss: 0.123201, acc: 100.00%] [G loss: 3.914453]\n",
      "epoch:45 step:35296 [D loss: 0.326079, acc: 85.94%] [G loss: 4.637451]\n",
      "epoch:45 step:35297 [D loss: 0.308904, acc: 89.06%] [G loss: 6.298972]\n",
      "epoch:45 step:35298 [D loss: 0.076065, acc: 100.00%] [G loss: 8.238486]\n",
      "epoch:45 step:35299 [D loss: 0.818157, acc: 55.47%] [G loss: 4.914957]\n",
      "epoch:45 step:35300 [D loss: 0.288681, acc: 85.94%] [G loss: 7.124021]\n",
      "epoch:45 step:35301 [D loss: 0.020970, acc: 100.00%] [G loss: 7.301648]\n",
      "epoch:45 step:35302 [D loss: 0.044974, acc: 100.00%] [G loss: 9.462574]\n",
      "epoch:45 step:35303 [D loss: 0.468505, acc: 83.59%] [G loss: 4.861394]\n",
      "epoch:45 step:35304 [D loss: 0.251252, acc: 94.53%] [G loss: 8.430874]\n",
      "epoch:45 step:35305 [D loss: 0.162312, acc: 100.00%] [G loss: 5.243918]\n",
      "epoch:45 step:35306 [D loss: 0.008201, acc: 100.00%] [G loss: 12.470142]\n",
      "epoch:45 step:35307 [D loss: 0.090164, acc: 100.00%] [G loss: 5.168116]\n",
      "epoch:45 step:35308 [D loss: 0.125002, acc: 98.44%] [G loss: 6.153389]\n",
      "epoch:45 step:35309 [D loss: 0.386226, acc: 78.12%] [G loss: 5.960657]\n",
      "epoch:45 step:35310 [D loss: 0.347268, acc: 82.81%] [G loss: 4.997851]\n",
      "epoch:45 step:35311 [D loss: 1.452771, acc: 49.22%] [G loss: 5.481633]\n",
      "epoch:45 step:35312 [D loss: 0.197360, acc: 96.88%] [G loss: 4.987719]\n",
      "epoch:45 step:35313 [D loss: 0.188720, acc: 94.53%] [G loss: 6.494930]\n",
      "epoch:45 step:35314 [D loss: 0.068894, acc: 100.00%] [G loss: 5.199407]\n",
      "epoch:45 step:35315 [D loss: 0.596181, acc: 63.28%] [G loss: 6.165000]\n",
      "epoch:45 step:35316 [D loss: 0.060219, acc: 100.00%] [G loss: 5.521988]\n",
      "epoch:45 step:35317 [D loss: 0.738852, acc: 56.25%] [G loss: 5.641898]\n",
      "epoch:45 step:35318 [D loss: 0.511456, acc: 68.75%] [G loss: 6.614435]\n",
      "epoch:45 step:35319 [D loss: 0.977668, acc: 52.34%] [G loss: 9.540031]\n",
      "epoch:45 step:35320 [D loss: 0.044660, acc: 100.00%] [G loss: 5.744411]\n",
      "epoch:45 step:35321 [D loss: 0.013977, acc: 100.00%] [G loss: 9.080492]\n",
      "epoch:45 step:35322 [D loss: 0.199487, acc: 96.09%] [G loss: 4.375997]\n",
      "epoch:45 step:35323 [D loss: 0.394684, acc: 86.72%] [G loss: 6.245190]\n",
      "epoch:45 step:35324 [D loss: 0.240132, acc: 95.31%] [G loss: 5.867216]\n",
      "epoch:45 step:35325 [D loss: 0.148677, acc: 98.44%] [G loss: 6.908499]\n",
      "epoch:45 step:35326 [D loss: 0.436360, acc: 78.91%] [G loss: 6.665622]\n",
      "epoch:45 step:35327 [D loss: 0.489968, acc: 67.97%] [G loss: 4.702373]\n",
      "epoch:45 step:35328 [D loss: 0.044727, acc: 100.00%] [G loss: 4.806213]\n",
      "epoch:45 step:35329 [D loss: 0.013150, acc: 100.00%] [G loss: 1.750574]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:45 step:35330 [D loss: 0.338649, acc: 83.59%] [G loss: 5.458617]\n",
      "epoch:45 step:35331 [D loss: 0.174376, acc: 97.66%] [G loss: 6.907032]\n",
      "epoch:45 step:35332 [D loss: 0.281589, acc: 91.41%] [G loss: 7.177214]\n",
      "epoch:45 step:35333 [D loss: 0.039534, acc: 100.00%] [G loss: 4.156745]\n",
      "epoch:45 step:35334 [D loss: 0.050310, acc: 99.22%] [G loss: 8.683762]\n",
      "epoch:45 step:35335 [D loss: 0.149289, acc: 98.44%] [G loss: 7.273824]\n",
      "epoch:45 step:35336 [D loss: 0.225680, acc: 92.97%] [G loss: 4.123652]\n",
      "epoch:45 step:35337 [D loss: 0.285020, acc: 88.28%] [G loss: 4.323025]\n",
      "epoch:45 step:35338 [D loss: 0.362061, acc: 87.50%] [G loss: 11.661274]\n",
      "epoch:45 step:35339 [D loss: 0.013086, acc: 100.00%] [G loss: 8.704701]\n",
      "epoch:45 step:35340 [D loss: 0.617193, acc: 65.62%] [G loss: 9.818416]\n",
      "epoch:45 step:35341 [D loss: 0.041882, acc: 100.00%] [G loss: 7.812850]\n",
      "epoch:45 step:35342 [D loss: 0.113278, acc: 100.00%] [G loss: 6.146672]\n",
      "epoch:45 step:35343 [D loss: 0.287646, acc: 83.59%] [G loss: 6.222249]\n",
      "epoch:45 step:35344 [D loss: 0.322363, acc: 91.41%] [G loss: 4.256599]\n",
      "epoch:45 step:35345 [D loss: 0.294351, acc: 86.72%] [G loss: 5.073185]\n",
      "epoch:45 step:35346 [D loss: 0.838773, acc: 52.34%] [G loss: 6.974790]\n",
      "epoch:45 step:35347 [D loss: 0.326772, acc: 90.62%] [G loss: 3.318790]\n",
      "epoch:45 step:35348 [D loss: 0.072309, acc: 99.22%] [G loss: 4.629481]\n",
      "epoch:45 step:35349 [D loss: 0.302760, acc: 90.62%] [G loss: 4.999215]\n",
      "epoch:45 step:35350 [D loss: 0.288727, acc: 88.28%] [G loss: 3.280834]\n",
      "epoch:45 step:35351 [D loss: 0.366634, acc: 78.12%] [G loss: 6.105635]\n",
      "epoch:45 step:35352 [D loss: 1.161600, acc: 26.56%] [G loss: 11.851317]\n",
      "epoch:45 step:35353 [D loss: 0.026942, acc: 100.00%] [G loss: 7.214989]\n",
      "epoch:45 step:35354 [D loss: 0.839218, acc: 51.56%] [G loss: 6.768892]\n",
      "epoch:45 step:35355 [D loss: 0.168427, acc: 100.00%] [G loss: 4.674668]\n",
      "epoch:45 step:35356 [D loss: 0.107681, acc: 98.44%] [G loss: 4.515838]\n",
      "epoch:45 step:35357 [D loss: 0.056200, acc: 100.00%] [G loss: 8.099180]\n",
      "epoch:45 step:35358 [D loss: 0.320796, acc: 89.84%] [G loss: 8.031242]\n",
      "epoch:45 step:35359 [D loss: 0.039121, acc: 100.00%] [G loss: 3.395859]\n",
      "epoch:45 step:35360 [D loss: 0.201560, acc: 96.09%] [G loss: 7.988820]\n",
      "epoch:45 step:35361 [D loss: 0.026324, acc: 100.00%] [G loss: 4.627532]\n",
      "epoch:45 step:35362 [D loss: 0.061761, acc: 100.00%] [G loss: 6.281894]\n",
      "epoch:45 step:35363 [D loss: 0.086883, acc: 100.00%] [G loss: 3.761876]\n",
      "epoch:45 step:35364 [D loss: 0.261266, acc: 93.75%] [G loss: 4.649237]\n",
      "epoch:45 step:35365 [D loss: 0.474272, acc: 83.59%] [G loss: 4.357858]\n",
      "epoch:45 step:35366 [D loss: 0.218973, acc: 92.19%] [G loss: 3.221798]\n",
      "epoch:45 step:35367 [D loss: 0.033995, acc: 100.00%] [G loss: 6.470235]\n",
      "epoch:45 step:35368 [D loss: 0.751695, acc: 53.91%] [G loss: 7.250239]\n",
      "epoch:45 step:35369 [D loss: 0.012953, acc: 100.00%] [G loss: 5.596658]\n",
      "epoch:45 step:35370 [D loss: 0.422085, acc: 71.09%] [G loss: 8.139544]\n",
      "epoch:45 step:35371 [D loss: 0.370787, acc: 86.72%] [G loss: 5.909776]\n",
      "epoch:45 step:35372 [D loss: 0.132318, acc: 98.44%] [G loss: 4.879871]\n",
      "epoch:45 step:35373 [D loss: 0.179658, acc: 98.44%] [G loss: 6.525467]\n",
      "epoch:45 step:35374 [D loss: 0.186804, acc: 95.31%] [G loss: 8.757040]\n",
      "epoch:45 step:35375 [D loss: 0.307885, acc: 92.97%] [G loss: 4.733506]\n",
      "epoch:45 step:35376 [D loss: 0.301874, acc: 83.59%] [G loss: 7.704010]\n",
      "epoch:45 step:35377 [D loss: 0.435346, acc: 78.91%] [G loss: 5.473605]\n",
      "epoch:45 step:35378 [D loss: 0.264818, acc: 88.28%] [G loss: 7.313438]\n",
      "epoch:45 step:35379 [D loss: 0.104232, acc: 99.22%] [G loss: 6.319181]\n",
      "epoch:45 step:35380 [D loss: 0.130086, acc: 96.88%] [G loss: 5.385243]\n",
      "epoch:45 step:35381 [D loss: 0.108185, acc: 99.22%] [G loss: 11.621723]\n",
      "epoch:45 step:35382 [D loss: 0.856337, acc: 53.91%] [G loss: 5.272459]\n",
      "epoch:45 step:35383 [D loss: 0.098176, acc: 99.22%] [G loss: 4.667032]\n",
      "epoch:45 step:35384 [D loss: 0.146744, acc: 96.88%] [G loss: 6.035336]\n",
      "epoch:45 step:35385 [D loss: 1.095339, acc: 26.56%] [G loss: 6.337661]\n",
      "epoch:45 step:35386 [D loss: 0.006009, acc: 100.00%] [G loss: 9.346848]\n",
      "epoch:45 step:35387 [D loss: 0.014814, acc: 100.00%] [G loss: 6.451070]\n",
      "epoch:45 step:35388 [D loss: 0.032047, acc: 100.00%] [G loss: 5.345459]\n",
      "epoch:45 step:35389 [D loss: 0.560516, acc: 74.22%] [G loss: 10.429157]\n",
      "epoch:45 step:35390 [D loss: 0.106212, acc: 99.22%] [G loss: 5.152704]\n",
      "epoch:45 step:35391 [D loss: 1.006458, acc: 51.56%] [G loss: 7.422778]\n",
      "epoch:45 step:35392 [D loss: 0.174211, acc: 97.66%] [G loss: 6.811620]\n",
      "epoch:45 step:35393 [D loss: 0.338629, acc: 82.81%] [G loss: 6.562724]\n",
      "epoch:45 step:35394 [D loss: 0.327040, acc: 86.72%] [G loss: 6.229816]\n",
      "epoch:45 step:35395 [D loss: 0.163177, acc: 98.44%] [G loss: 3.334774]\n",
      "epoch:45 step:35396 [D loss: 0.585335, acc: 61.72%] [G loss: 6.509006]\n",
      "epoch:45 step:35397 [D loss: 0.038124, acc: 100.00%] [G loss: 7.075483]\n",
      "epoch:45 step:35398 [D loss: 0.508686, acc: 68.75%] [G loss: 8.937849]\n",
      "epoch:45 step:35399 [D loss: 2.140495, acc: 0.78%] [G loss: 6.964088]\n",
      "epoch:45 step:35400 [D loss: 0.037966, acc: 99.22%] [G loss: 8.083239]\n",
      "##############\n",
      "[0.85226603 0.88286484 0.8216351  0.81407974 0.77966122 0.83277286\n",
      " 0.89772074 0.83462315 0.79876059 0.82457467]\n",
      "##########\n",
      "epoch:45 step:35401 [D loss: 0.864622, acc: 49.22%] [G loss: 5.770957]\n",
      "epoch:45 step:35402 [D loss: 0.219248, acc: 92.97%] [G loss: 6.222754]\n",
      "epoch:45 step:35403 [D loss: 0.358994, acc: 83.59%] [G loss: 5.587708]\n",
      "epoch:45 step:35404 [D loss: 0.064811, acc: 100.00%] [G loss: 6.365978]\n",
      "epoch:45 step:35405 [D loss: 0.123129, acc: 99.22%] [G loss: 12.260756]\n",
      "epoch:45 step:35406 [D loss: 0.419119, acc: 79.69%] [G loss: 6.285645]\n",
      "epoch:45 step:35407 [D loss: 0.302003, acc: 85.16%] [G loss: 10.485212]\n",
      "epoch:45 step:35408 [D loss: 0.009260, acc: 100.00%] [G loss: 6.378631]\n",
      "epoch:45 step:35409 [D loss: 0.413902, acc: 76.56%] [G loss: 5.580112]\n",
      "epoch:45 step:35410 [D loss: 0.499170, acc: 71.88%] [G loss: 4.400753]\n",
      "epoch:45 step:35411 [D loss: 0.395923, acc: 78.91%] [G loss: 5.124288]\n",
      "epoch:45 step:35412 [D loss: 0.914181, acc: 50.78%] [G loss: 5.239655]\n",
      "epoch:45 step:35413 [D loss: 0.118300, acc: 100.00%] [G loss: 7.470696]\n",
      "epoch:45 step:35414 [D loss: 0.139396, acc: 97.66%] [G loss: 6.742250]\n",
      "epoch:45 step:35415 [D loss: 0.286570, acc: 87.50%] [G loss: 8.005522]\n",
      "epoch:45 step:35416 [D loss: 0.157198, acc: 96.88%] [G loss: 6.003861]\n",
      "epoch:45 step:35417 [D loss: 0.019782, acc: 100.00%] [G loss: 7.476583]\n",
      "epoch:45 step:35418 [D loss: 0.048242, acc: 100.00%] [G loss: 4.004486]\n",
      "epoch:45 step:35419 [D loss: 0.055145, acc: 100.00%] [G loss: 8.540994]\n",
      "epoch:45 step:35420 [D loss: 0.091510, acc: 98.44%] [G loss: 6.891224]\n",
      "epoch:45 step:35421 [D loss: 0.303892, acc: 90.62%] [G loss: 7.920560]\n",
      "epoch:45 step:35422 [D loss: 1.851697, acc: 27.34%] [G loss: 9.460075]\n",
      "epoch:45 step:35423 [D loss: 0.633419, acc: 60.16%] [G loss: 5.982240]\n",
      "epoch:45 step:35424 [D loss: 0.202170, acc: 95.31%] [G loss: 3.424881]\n",
      "epoch:45 step:35425 [D loss: 0.081595, acc: 99.22%] [G loss: 8.396786]\n",
      "epoch:45 step:35426 [D loss: 0.168342, acc: 96.09%] [G loss: 7.575137]\n",
      "epoch:45 step:35427 [D loss: 0.182006, acc: 98.44%] [G loss: 5.088770]\n",
      "epoch:45 step:35428 [D loss: 0.264070, acc: 96.09%] [G loss: 7.265210]\n",
      "epoch:45 step:35429 [D loss: 0.171796, acc: 96.09%] [G loss: 11.449102]\n",
      "epoch:45 step:35430 [D loss: 0.586974, acc: 64.06%] [G loss: 7.890224]\n",
      "epoch:45 step:35431 [D loss: 0.340148, acc: 80.47%] [G loss: 3.473511]\n",
      "epoch:45 step:35432 [D loss: 0.257648, acc: 87.50%] [G loss: 9.908244]\n",
      "epoch:45 step:35433 [D loss: 0.057171, acc: 100.00%] [G loss: 4.529463]\n",
      "epoch:45 step:35434 [D loss: 0.061232, acc: 100.00%] [G loss: 3.404502]\n",
      "epoch:45 step:35435 [D loss: 0.023855, acc: 100.00%] [G loss: 7.431993]\n",
      "epoch:45 step:35436 [D loss: 0.104821, acc: 99.22%] [G loss: 9.874800]\n",
      "epoch:45 step:35437 [D loss: 1.047702, acc: 50.78%] [G loss: 7.980986]\n",
      "epoch:45 step:35438 [D loss: 0.159355, acc: 96.88%] [G loss: 4.552730]\n",
      "epoch:45 step:35439 [D loss: 0.045089, acc: 100.00%] [G loss: 3.843727]\n",
      "epoch:45 step:35440 [D loss: 0.311760, acc: 89.84%] [G loss: 4.068801]\n",
      "epoch:45 step:35441 [D loss: 0.071466, acc: 99.22%] [G loss: 8.128311]\n",
      "epoch:45 step:35442 [D loss: 0.196758, acc: 93.75%] [G loss: 5.199135]\n",
      "epoch:45 step:35443 [D loss: 0.190331, acc: 96.88%] [G loss: 6.247919]\n",
      "epoch:45 step:35444 [D loss: 0.204940, acc: 96.88%] [G loss: 6.862851]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:45 step:35445 [D loss: 0.881411, acc: 49.22%] [G loss: 7.449507]\n",
      "epoch:45 step:35446 [D loss: 0.216486, acc: 96.88%] [G loss: 4.919851]\n",
      "epoch:45 step:35447 [D loss: 0.259740, acc: 96.09%] [G loss: 6.870818]\n",
      "epoch:45 step:35448 [D loss: 0.779594, acc: 53.12%] [G loss: 9.322621]\n",
      "epoch:45 step:35449 [D loss: 1.917059, acc: 50.00%] [G loss: 9.936013]\n",
      "epoch:45 step:35450 [D loss: 0.164563, acc: 98.44%] [G loss: 5.008792]\n",
      "epoch:45 step:35451 [D loss: 0.188159, acc: 92.97%] [G loss: 6.621335]\n",
      "epoch:45 step:35452 [D loss: 0.073609, acc: 100.00%] [G loss: 8.130246]\n",
      "epoch:45 step:35453 [D loss: 0.426964, acc: 75.78%] [G loss: 5.095539]\n",
      "epoch:45 step:35454 [D loss: 0.049409, acc: 100.00%] [G loss: 8.266129]\n",
      "epoch:45 step:35455 [D loss: 0.297807, acc: 91.41%] [G loss: 7.758378]\n",
      "epoch:45 step:35456 [D loss: 0.520900, acc: 68.75%] [G loss: 4.927959]\n",
      "epoch:45 step:35457 [D loss: 0.194472, acc: 96.88%] [G loss: 8.370087]\n",
      "epoch:45 step:35458 [D loss: 0.310619, acc: 92.97%] [G loss: 6.615852]\n",
      "epoch:45 step:35459 [D loss: 0.514490, acc: 80.47%] [G loss: 9.926903]\n",
      "epoch:45 step:35460 [D loss: 0.244123, acc: 90.62%] [G loss: 5.143384]\n",
      "epoch:45 step:35461 [D loss: 0.484744, acc: 71.88%] [G loss: 4.045897]\n",
      "epoch:45 step:35462 [D loss: 0.239442, acc: 90.62%] [G loss: 8.613050]\n",
      "epoch:45 step:35463 [D loss: 0.480522, acc: 65.62%] [G loss: 2.305613]\n",
      "epoch:45 step:35464 [D loss: 0.280221, acc: 97.66%] [G loss: 5.031248]\n",
      "epoch:45 step:35465 [D loss: 0.519382, acc: 65.62%] [G loss: 10.697691]\n",
      "epoch:45 step:35466 [D loss: 0.055827, acc: 100.00%] [G loss: 8.006842]\n",
      "epoch:45 step:35467 [D loss: 0.091108, acc: 100.00%] [G loss: 4.434718]\n",
      "epoch:45 step:35468 [D loss: 0.621829, acc: 63.28%] [G loss: 5.279756]\n",
      "epoch:45 step:35469 [D loss: 0.362996, acc: 83.59%] [G loss: 3.881943]\n",
      "epoch:45 step:35470 [D loss: 0.075138, acc: 100.00%] [G loss: 5.602010]\n",
      "epoch:45 step:35471 [D loss: 0.095969, acc: 98.44%] [G loss: 8.312531]\n",
      "epoch:45 step:35472 [D loss: 0.612013, acc: 64.06%] [G loss: 6.509485]\n",
      "epoch:45 step:35473 [D loss: 0.713397, acc: 57.03%] [G loss: 8.143136]\n",
      "epoch:45 step:35474 [D loss: 0.019704, acc: 100.00%] [G loss: 5.925804]\n",
      "epoch:45 step:35475 [D loss: 0.377573, acc: 85.94%] [G loss: 5.609422]\n",
      "epoch:45 step:35476 [D loss: 0.098389, acc: 100.00%] [G loss: 6.528884]\n",
      "epoch:45 step:35477 [D loss: 0.162125, acc: 100.00%] [G loss: 3.985203]\n",
      "epoch:45 step:35478 [D loss: 0.636288, acc: 57.03%] [G loss: 11.373447]\n",
      "epoch:45 step:35479 [D loss: 0.157789, acc: 99.22%] [G loss: 5.259672]\n",
      "epoch:45 step:35480 [D loss: 0.149553, acc: 96.88%] [G loss: 6.205346]\n",
      "epoch:45 step:35481 [D loss: 0.759490, acc: 56.25%] [G loss: 10.950779]\n",
      "epoch:45 step:35482 [D loss: 1.070564, acc: 50.78%] [G loss: 6.964365]\n",
      "epoch:45 step:35483 [D loss: 0.245875, acc: 91.41%] [G loss: 5.489174]\n",
      "epoch:45 step:35484 [D loss: 0.117425, acc: 98.44%] [G loss: 7.726297]\n",
      "epoch:45 step:35485 [D loss: 0.379389, acc: 75.00%] [G loss: 5.233250]\n",
      "epoch:45 step:35486 [D loss: 0.046954, acc: 99.22%] [G loss: 7.910683]\n",
      "epoch:45 step:35487 [D loss: 0.567372, acc: 61.72%] [G loss: 12.719979]\n",
      "epoch:45 step:35488 [D loss: 0.057865, acc: 99.22%] [G loss: 5.845275]\n",
      "epoch:45 step:35489 [D loss: 0.395845, acc: 89.84%] [G loss: 7.541228]\n",
      "epoch:45 step:35490 [D loss: 0.022978, acc: 100.00%] [G loss: 5.797822]\n",
      "epoch:45 step:35491 [D loss: 0.064687, acc: 99.22%] [G loss: 8.733804]\n",
      "epoch:45 step:35492 [D loss: 0.167483, acc: 97.66%] [G loss: 2.918626]\n",
      "epoch:45 step:35493 [D loss: 0.725815, acc: 57.03%] [G loss: 5.565635]\n",
      "epoch:45 step:35494 [D loss: 0.532245, acc: 73.44%] [G loss: 5.133503]\n",
      "epoch:45 step:35495 [D loss: 0.605588, acc: 62.50%] [G loss: 10.431088]\n",
      "epoch:45 step:35496 [D loss: 0.286477, acc: 90.62%] [G loss: 6.649067]\n",
      "epoch:45 step:35497 [D loss: 0.451811, acc: 71.88%] [G loss: 10.224905]\n",
      "epoch:45 step:35498 [D loss: 0.034816, acc: 100.00%] [G loss: 5.650298]\n",
      "epoch:45 step:35499 [D loss: 0.431214, acc: 83.59%] [G loss: 8.038438]\n",
      "epoch:45 step:35500 [D loss: 0.294375, acc: 86.72%] [G loss: 5.544431]\n",
      "epoch:45 step:35501 [D loss: 0.053402, acc: 100.00%] [G loss: 5.571298]\n",
      "epoch:45 step:35502 [D loss: 0.034607, acc: 100.00%] [G loss: 8.042955]\n",
      "epoch:45 step:35503 [D loss: 0.310219, acc: 87.50%] [G loss: 6.604297]\n",
      "epoch:45 step:35504 [D loss: 0.480431, acc: 69.53%] [G loss: 7.155818]\n",
      "epoch:45 step:35505 [D loss: 0.124328, acc: 99.22%] [G loss: 6.354194]\n",
      "epoch:45 step:35506 [D loss: 0.052809, acc: 100.00%] [G loss: 7.871020]\n",
      "epoch:45 step:35507 [D loss: 0.262418, acc: 94.53%] [G loss: 6.026401]\n",
      "epoch:45 step:35508 [D loss: 0.247788, acc: 88.28%] [G loss: 8.030901]\n",
      "epoch:45 step:35509 [D loss: 0.142530, acc: 99.22%] [G loss: 8.245630]\n",
      "epoch:45 step:35510 [D loss: 0.159829, acc: 98.44%] [G loss: 7.520217]\n",
      "epoch:45 step:35511 [D loss: 0.471915, acc: 67.97%] [G loss: 11.010415]\n",
      "epoch:45 step:35512 [D loss: 0.046597, acc: 100.00%] [G loss: 5.705579]\n",
      "epoch:45 step:35513 [D loss: 2.855963, acc: 28.12%] [G loss: 5.510898]\n",
      "epoch:45 step:35514 [D loss: 0.418847, acc: 77.34%] [G loss: 6.839437]\n",
      "epoch:45 step:35515 [D loss: 0.542075, acc: 61.72%] [G loss: 13.675844]\n",
      "epoch:45 step:35516 [D loss: 0.107063, acc: 100.00%] [G loss: 3.640958]\n",
      "epoch:45 step:35517 [D loss: 0.598800, acc: 61.72%] [G loss: 8.926338]\n",
      "epoch:45 step:35518 [D loss: 0.917485, acc: 36.72%] [G loss: 7.311399]\n",
      "epoch:45 step:35519 [D loss: 0.143462, acc: 97.66%] [G loss: 6.698796]\n",
      "epoch:45 step:35520 [D loss: 0.288284, acc: 95.31%] [G loss: 7.881398]\n",
      "epoch:45 step:35521 [D loss: 0.196927, acc: 96.09%] [G loss: 5.751042]\n",
      "epoch:45 step:35522 [D loss: 0.419783, acc: 75.00%] [G loss: 8.946089]\n",
      "epoch:45 step:35523 [D loss: 0.227405, acc: 98.44%] [G loss: 6.825485]\n",
      "epoch:45 step:35524 [D loss: 0.795443, acc: 53.91%] [G loss: 7.872171]\n",
      "epoch:45 step:35525 [D loss: 0.131071, acc: 100.00%] [G loss: 4.007319]\n",
      "epoch:45 step:35526 [D loss: 0.331552, acc: 82.81%] [G loss: 8.710201]\n",
      "epoch:45 step:35527 [D loss: 0.090525, acc: 99.22%] [G loss: 8.599121]\n",
      "epoch:45 step:35528 [D loss: 0.002120, acc: 100.00%] [G loss: 7.477433]\n",
      "epoch:45 step:35529 [D loss: 0.184393, acc: 97.66%] [G loss: 6.612423]\n",
      "epoch:45 step:35530 [D loss: 0.339388, acc: 89.84%] [G loss: 8.521957]\n",
      "epoch:45 step:35531 [D loss: 0.005266, acc: 100.00%] [G loss: 9.438835]\n",
      "epoch:45 step:35532 [D loss: 0.423552, acc: 72.66%] [G loss: 9.049350]\n",
      "epoch:45 step:35533 [D loss: 0.140946, acc: 98.44%] [G loss: 7.484115]\n",
      "epoch:45 step:35534 [D loss: 0.261236, acc: 92.19%] [G loss: 7.916210]\n",
      "epoch:45 step:35535 [D loss: 0.036503, acc: 100.00%] [G loss: 4.779608]\n",
      "epoch:45 step:35536 [D loss: 0.455127, acc: 80.47%] [G loss: 8.433912]\n",
      "epoch:45 step:35537 [D loss: 0.499787, acc: 66.41%] [G loss: 8.529665]\n",
      "epoch:45 step:35538 [D loss: 0.084636, acc: 100.00%] [G loss: 6.200866]\n",
      "epoch:45 step:35539 [D loss: 0.063206, acc: 100.00%] [G loss: 5.231088]\n",
      "epoch:45 step:35540 [D loss: 0.256053, acc: 89.84%] [G loss: 7.346350]\n",
      "epoch:45 step:35541 [D loss: 0.242282, acc: 94.53%] [G loss: 7.030293]\n",
      "epoch:45 step:35542 [D loss: 0.371420, acc: 76.56%] [G loss: 6.772729]\n",
      "epoch:45 step:35543 [D loss: 0.345480, acc: 79.69%] [G loss: 9.279227]\n",
      "epoch:45 step:35544 [D loss: 0.448417, acc: 75.78%] [G loss: 7.265773]\n",
      "epoch:45 step:35545 [D loss: 0.385080, acc: 76.56%] [G loss: 5.594345]\n",
      "epoch:45 step:35546 [D loss: 0.021839, acc: 100.00%] [G loss: 7.909964]\n",
      "epoch:45 step:35547 [D loss: 0.023799, acc: 100.00%] [G loss: 6.741158]\n",
      "epoch:45 step:35548 [D loss: 0.127628, acc: 98.44%] [G loss: 3.677466]\n",
      "epoch:45 step:35549 [D loss: 0.351678, acc: 82.03%] [G loss: 7.199944]\n",
      "epoch:45 step:35550 [D loss: 0.259975, acc: 91.41%] [G loss: 5.384977]\n",
      "epoch:45 step:35551 [D loss: 0.066656, acc: 100.00%] [G loss: 7.028407]\n",
      "epoch:45 step:35552 [D loss: 0.560175, acc: 60.16%] [G loss: 9.560999]\n",
      "epoch:45 step:35553 [D loss: 0.164344, acc: 96.88%] [G loss: 4.542286]\n",
      "epoch:45 step:35554 [D loss: 0.323740, acc: 83.59%] [G loss: 6.817196]\n",
      "epoch:45 step:35555 [D loss: 0.007586, acc: 100.00%] [G loss: 12.876907]\n",
      "epoch:45 step:35556 [D loss: 0.288537, acc: 89.84%] [G loss: 5.376039]\n",
      "epoch:45 step:35557 [D loss: 0.151731, acc: 99.22%] [G loss: 8.399254]\n",
      "epoch:45 step:35558 [D loss: 0.210265, acc: 96.09%] [G loss: 5.237762]\n",
      "epoch:45 step:35559 [D loss: 0.343424, acc: 82.03%] [G loss: 4.025461]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:45 step:35560 [D loss: 0.162831, acc: 96.88%] [G loss: 5.004291]\n",
      "epoch:45 step:35561 [D loss: 1.029983, acc: 50.78%] [G loss: 5.513720]\n",
      "epoch:45 step:35562 [D loss: 0.094813, acc: 99.22%] [G loss: 7.164388]\n",
      "epoch:45 step:35563 [D loss: 0.417410, acc: 80.47%] [G loss: 7.401760]\n",
      "epoch:45 step:35564 [D loss: 0.768234, acc: 52.34%] [G loss: 8.930968]\n",
      "epoch:45 step:35565 [D loss: 0.173999, acc: 99.22%] [G loss: 7.331744]\n",
      "epoch:45 step:35566 [D loss: 0.037352, acc: 100.00%] [G loss: 8.056993]\n",
      "epoch:45 step:35567 [D loss: 0.431811, acc: 89.06%] [G loss: 6.750411]\n",
      "epoch:45 step:35568 [D loss: 0.379451, acc: 78.91%] [G loss: 2.251038]\n",
      "epoch:45 step:35569 [D loss: 0.038378, acc: 100.00%] [G loss: 7.630702]\n",
      "epoch:45 step:35570 [D loss: 0.548375, acc: 73.44%] [G loss: 5.960741]\n",
      "epoch:45 step:35571 [D loss: 0.386535, acc: 78.12%] [G loss: 5.035942]\n",
      "epoch:45 step:35572 [D loss: 0.080392, acc: 100.00%] [G loss: 6.674218]\n",
      "epoch:45 step:35573 [D loss: 0.435688, acc: 82.03%] [G loss: 8.547361]\n",
      "epoch:45 step:35574 [D loss: 0.133198, acc: 96.88%] [G loss: 5.786715]\n",
      "epoch:45 step:35575 [D loss: 0.423988, acc: 75.00%] [G loss: 7.079762]\n",
      "epoch:45 step:35576 [D loss: 0.819706, acc: 52.34%] [G loss: 5.227787]\n",
      "epoch:45 step:35577 [D loss: 1.774191, acc: 25.78%] [G loss: 8.273676]\n",
      "epoch:45 step:35578 [D loss: 0.385310, acc: 88.28%] [G loss: 5.513393]\n",
      "epoch:45 step:35579 [D loss: 0.050063, acc: 100.00%] [G loss: 7.394064]\n",
      "epoch:45 step:35580 [D loss: 0.139520, acc: 97.66%] [G loss: 7.473033]\n",
      "epoch:45 step:35581 [D loss: 0.142686, acc: 97.66%] [G loss: 8.858239]\n",
      "epoch:45 step:35582 [D loss: 0.413005, acc: 72.66%] [G loss: 8.452732]\n",
      "epoch:45 step:35583 [D loss: 0.330905, acc: 84.38%] [G loss: 9.163145]\n",
      "epoch:45 step:35584 [D loss: 0.096520, acc: 99.22%] [G loss: 4.943914]\n",
      "epoch:45 step:35585 [D loss: 0.136433, acc: 99.22%] [G loss: 6.420335]\n",
      "epoch:45 step:35586 [D loss: 0.090461, acc: 98.44%] [G loss: 5.033468]\n",
      "epoch:45 step:35587 [D loss: 0.186967, acc: 95.31%] [G loss: 5.978370]\n",
      "epoch:45 step:35588 [D loss: 0.043228, acc: 100.00%] [G loss: 3.317293]\n",
      "epoch:45 step:35589 [D loss: 0.139454, acc: 96.09%] [G loss: 6.922422]\n",
      "epoch:45 step:35590 [D loss: 2.098790, acc: 48.44%] [G loss: 6.753907]\n",
      "epoch:45 step:35591 [D loss: 0.272191, acc: 89.06%] [G loss: 5.206474]\n",
      "epoch:45 step:35592 [D loss: 0.918937, acc: 51.56%] [G loss: 9.034439]\n",
      "epoch:45 step:35593 [D loss: 0.616427, acc: 60.16%] [G loss: 4.009887]\n",
      "epoch:45 step:35594 [D loss: 0.101860, acc: 99.22%] [G loss: 9.147570]\n",
      "epoch:45 step:35595 [D loss: 0.161037, acc: 98.44%] [G loss: 6.396295]\n",
      "epoch:45 step:35596 [D loss: 0.180569, acc: 98.44%] [G loss: 3.662148]\n",
      "epoch:45 step:35597 [D loss: 0.194800, acc: 92.97%] [G loss: 7.897277]\n",
      "epoch:45 step:35598 [D loss: 0.223859, acc: 96.09%] [G loss: 5.170975]\n",
      "epoch:45 step:35599 [D loss: 0.214761, acc: 97.66%] [G loss: 6.742407]\n",
      "epoch:45 step:35600 [D loss: 0.343247, acc: 80.47%] [G loss: 5.107474]\n",
      "##############\n",
      "[0.84923168 0.86739176 0.80212003 0.80130383 0.77218202 0.81168022\n",
      " 0.89911428 0.83565803 0.81827916 0.85000303]\n",
      "##########\n",
      "epoch:45 step:35601 [D loss: 0.081982, acc: 100.00%] [G loss: 8.284682]\n",
      "epoch:45 step:35602 [D loss: 1.466542, acc: 20.31%] [G loss: 3.961994]\n",
      "epoch:45 step:35603 [D loss: 0.401196, acc: 89.06%] [G loss: 5.882044]\n",
      "epoch:45 step:35604 [D loss: 0.062893, acc: 100.00%] [G loss: 5.158317]\n",
      "epoch:45 step:35605 [D loss: 0.270371, acc: 94.53%] [G loss: 5.351647]\n",
      "epoch:45 step:35606 [D loss: 0.271805, acc: 92.19%] [G loss: 7.915244]\n",
      "epoch:45 step:35607 [D loss: 0.034391, acc: 100.00%] [G loss: 9.574457]\n",
      "epoch:45 step:35608 [D loss: 0.484046, acc: 67.97%] [G loss: 5.090643]\n",
      "epoch:45 step:35609 [D loss: 0.041204, acc: 100.00%] [G loss: 6.998102]\n",
      "epoch:45 step:35610 [D loss: 0.731963, acc: 55.47%] [G loss: 8.957802]\n",
      "epoch:45 step:35611 [D loss: 0.053189, acc: 100.00%] [G loss: 7.122440]\n",
      "epoch:45 step:35612 [D loss: 0.305775, acc: 82.03%] [G loss: 7.267283]\n",
      "epoch:45 step:35613 [D loss: 0.989574, acc: 50.78%] [G loss: 4.657975]\n",
      "epoch:45 step:35614 [D loss: 0.680438, acc: 57.03%] [G loss: 5.844899]\n",
      "epoch:45 step:35615 [D loss: 0.037537, acc: 100.00%] [G loss: 9.096844]\n",
      "epoch:45 step:35616 [D loss: 0.924971, acc: 52.34%] [G loss: 10.512964]\n",
      "epoch:45 step:35617 [D loss: 0.276857, acc: 89.84%] [G loss: 4.769791]\n",
      "epoch:45 step:35618 [D loss: 0.016630, acc: 100.00%] [G loss: 5.315624]\n",
      "epoch:45 step:35619 [D loss: 0.147020, acc: 99.22%] [G loss: 5.170597]\n",
      "epoch:45 step:35620 [D loss: 0.147364, acc: 97.66%] [G loss: 5.060341]\n",
      "epoch:45 step:35621 [D loss: 0.257488, acc: 93.75%] [G loss: 6.975020]\n",
      "epoch:45 step:35622 [D loss: 0.115253, acc: 99.22%] [G loss: 4.537424]\n",
      "epoch:45 step:35623 [D loss: 0.324552, acc: 88.28%] [G loss: 5.028706]\n",
      "epoch:45 step:35624 [D loss: 0.379983, acc: 88.28%] [G loss: 3.944539]\n",
      "epoch:45 step:35625 [D loss: 0.025824, acc: 99.22%] [G loss: 6.900359]\n",
      "epoch:45 step:35626 [D loss: 0.250447, acc: 92.97%] [G loss: 6.558776]\n",
      "epoch:45 step:35627 [D loss: 0.925844, acc: 50.78%] [G loss: 8.283216]\n",
      "epoch:45 step:35628 [D loss: 0.246908, acc: 95.31%] [G loss: 6.379517]\n",
      "epoch:45 step:35629 [D loss: 0.521875, acc: 67.19%] [G loss: 3.930693]\n",
      "epoch:45 step:35630 [D loss: 0.328234, acc: 89.84%] [G loss: 5.130369]\n",
      "epoch:45 step:35631 [D loss: 0.691875, acc: 54.69%] [G loss: 6.030649]\n",
      "epoch:45 step:35632 [D loss: 0.638124, acc: 63.28%] [G loss: 8.214058]\n",
      "epoch:45 step:35633 [D loss: 0.023490, acc: 100.00%] [G loss: 5.287574]\n",
      "epoch:45 step:35634 [D loss: 0.311438, acc: 85.16%] [G loss: 4.850120]\n",
      "epoch:45 step:35635 [D loss: 0.235334, acc: 90.62%] [G loss: 7.440035]\n",
      "epoch:45 step:35636 [D loss: 0.019801, acc: 100.00%] [G loss: 9.149824]\n",
      "epoch:45 step:35637 [D loss: 0.032443, acc: 100.00%] [G loss: 7.767794]\n",
      "epoch:45 step:35638 [D loss: 0.196314, acc: 98.44%] [G loss: 5.341945]\n",
      "epoch:45 step:35639 [D loss: 0.515296, acc: 61.72%] [G loss: 9.296330]\n",
      "epoch:45 step:35640 [D loss: 0.215918, acc: 97.66%] [G loss: 7.693551]\n",
      "epoch:45 step:35641 [D loss: 0.445240, acc: 78.12%] [G loss: 6.675220]\n",
      "epoch:45 step:35642 [D loss: 0.162584, acc: 96.09%] [G loss: 10.744356]\n",
      "epoch:45 step:35643 [D loss: 0.068109, acc: 99.22%] [G loss: 7.983645]\n",
      "epoch:45 step:35644 [D loss: 0.232833, acc: 98.44%] [G loss: 7.293468]\n",
      "epoch:45 step:35645 [D loss: 0.152764, acc: 99.22%] [G loss: 4.370398]\n",
      "epoch:45 step:35646 [D loss: 0.067470, acc: 100.00%] [G loss: 5.503527]\n",
      "epoch:45 step:35647 [D loss: 0.022866, acc: 100.00%] [G loss: 8.678515]\n",
      "epoch:45 step:35648 [D loss: 0.586958, acc: 64.06%] [G loss: 7.678607]\n",
      "epoch:45 step:35649 [D loss: 0.398860, acc: 83.59%] [G loss: 2.861583]\n",
      "epoch:45 step:35650 [D loss: 0.170886, acc: 97.66%] [G loss: 4.262033]\n",
      "epoch:45 step:35651 [D loss: 0.117422, acc: 97.66%] [G loss: 3.432791]\n",
      "epoch:45 step:35652 [D loss: 0.832497, acc: 52.34%] [G loss: 4.739510]\n",
      "epoch:45 step:35653 [D loss: 0.052940, acc: 100.00%] [G loss: 6.739779]\n",
      "epoch:45 step:35654 [D loss: 0.071024, acc: 100.00%] [G loss: 4.575294]\n",
      "epoch:45 step:35655 [D loss: 1.096370, acc: 44.53%] [G loss: 6.158913]\n",
      "epoch:45 step:35656 [D loss: 0.935385, acc: 50.00%] [G loss: 10.153277]\n",
      "epoch:45 step:35657 [D loss: 0.049008, acc: 100.00%] [G loss: 4.692908]\n",
      "epoch:45 step:35658 [D loss: 0.062763, acc: 99.22%] [G loss: 5.169790]\n",
      "epoch:45 step:35659 [D loss: 0.578811, acc: 67.19%] [G loss: 6.127454]\n",
      "epoch:45 step:35660 [D loss: 0.290871, acc: 88.28%] [G loss: 3.401256]\n",
      "epoch:45 step:35661 [D loss: 0.561984, acc: 71.09%] [G loss: 6.021539]\n",
      "epoch:45 step:35662 [D loss: 0.327097, acc: 88.28%] [G loss: 7.402426]\n",
      "epoch:45 step:35663 [D loss: 0.022798, acc: 100.00%] [G loss: 11.436535]\n",
      "epoch:45 step:35664 [D loss: 0.222006, acc: 95.31%] [G loss: 4.574682]\n",
      "epoch:45 step:35665 [D loss: 0.330986, acc: 84.38%] [G loss: 6.975381]\n",
      "epoch:45 step:35666 [D loss: 0.379214, acc: 83.59%] [G loss: 5.977687]\n",
      "epoch:45 step:35667 [D loss: 0.187972, acc: 97.66%] [G loss: 5.221843]\n",
      "epoch:45 step:35668 [D loss: 0.164239, acc: 100.00%] [G loss: 7.272012]\n",
      "epoch:45 step:35669 [D loss: 0.181018, acc: 96.09%] [G loss: 9.364456]\n",
      "epoch:45 step:35670 [D loss: 0.563238, acc: 63.28%] [G loss: 8.199851]\n",
      "epoch:45 step:35671 [D loss: 0.168310, acc: 96.09%] [G loss: 2.460970]\n",
      "epoch:45 step:35672 [D loss: 0.059667, acc: 100.00%] [G loss: 7.780983]\n",
      "epoch:45 step:35673 [D loss: 0.418261, acc: 82.81%] [G loss: 7.719928]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:45 step:35674 [D loss: 0.045083, acc: 100.00%] [G loss: 2.866179]\n",
      "epoch:45 step:35675 [D loss: 0.270632, acc: 89.84%] [G loss: 6.354277]\n",
      "epoch:45 step:35676 [D loss: 1.853470, acc: 50.00%] [G loss: 5.366635]\n",
      "epoch:45 step:35677 [D loss: 0.436321, acc: 74.22%] [G loss: 7.470947]\n",
      "epoch:45 step:35678 [D loss: 0.798491, acc: 52.34%] [G loss: 9.699383]\n",
      "epoch:45 step:35679 [D loss: 0.169816, acc: 97.66%] [G loss: 9.214106]\n",
      "epoch:45 step:35680 [D loss: 0.479586, acc: 85.94%] [G loss: 4.722039]\n",
      "epoch:45 step:35681 [D loss: 0.171750, acc: 96.88%] [G loss: 7.224165]\n",
      "epoch:45 step:35682 [D loss: 0.066270, acc: 100.00%] [G loss: 5.954821]\n",
      "epoch:45 step:35683 [D loss: 0.015877, acc: 100.00%] [G loss: 7.253525]\n",
      "epoch:45 step:35684 [D loss: 0.710676, acc: 55.47%] [G loss: 8.756622]\n",
      "epoch:45 step:35685 [D loss: 0.230085, acc: 96.88%] [G loss: 3.769237]\n",
      "epoch:45 step:35686 [D loss: 0.131170, acc: 99.22%] [G loss: 7.804685]\n",
      "epoch:45 step:35687 [D loss: 0.097733, acc: 99.22%] [G loss: 5.431824]\n",
      "epoch:45 step:35688 [D loss: 0.057099, acc: 100.00%] [G loss: 5.857702]\n",
      "epoch:45 step:35689 [D loss: 0.739339, acc: 53.12%] [G loss: 7.066446]\n",
      "epoch:45 step:35690 [D loss: 0.604658, acc: 56.25%] [G loss: 6.164420]\n",
      "epoch:45 step:35691 [D loss: 0.187253, acc: 99.22%] [G loss: 5.091110]\n",
      "epoch:45 step:35692 [D loss: 0.280491, acc: 97.66%] [G loss: 6.258587]\n",
      "epoch:45 step:35693 [D loss: 0.148269, acc: 99.22%] [G loss: 4.158762]\n",
      "epoch:45 step:35694 [D loss: 0.158105, acc: 98.44%] [G loss: 4.589288]\n",
      "epoch:45 step:35695 [D loss: 0.766243, acc: 52.34%] [G loss: 6.077297]\n",
      "epoch:45 step:35696 [D loss: 0.141888, acc: 99.22%] [G loss: 4.069101]\n",
      "epoch:45 step:35697 [D loss: 0.135563, acc: 98.44%] [G loss: 7.936192]\n",
      "epoch:45 step:35698 [D loss: 0.084028, acc: 99.22%] [G loss: 6.494661]\n",
      "epoch:45 step:35699 [D loss: 0.063455, acc: 100.00%] [G loss: 3.150022]\n",
      "epoch:45 step:35700 [D loss: 0.029159, acc: 99.22%] [G loss: 4.905871]\n",
      "epoch:45 step:35701 [D loss: 0.249690, acc: 93.75%] [G loss: 6.976862]\n",
      "epoch:45 step:35702 [D loss: 0.104837, acc: 96.88%] [G loss: 10.083324]\n",
      "epoch:45 step:35703 [D loss: 0.435831, acc: 74.22%] [G loss: 4.113956]\n",
      "epoch:45 step:35704 [D loss: 0.175650, acc: 95.31%] [G loss: 6.942059]\n",
      "epoch:45 step:35705 [D loss: 0.100083, acc: 100.00%] [G loss: 5.749243]\n",
      "epoch:45 step:35706 [D loss: 0.070338, acc: 99.22%] [G loss: 6.490665]\n",
      "epoch:45 step:35707 [D loss: 0.108783, acc: 100.00%] [G loss: 6.722796]\n",
      "epoch:45 step:35708 [D loss: 0.068770, acc: 100.00%] [G loss: 3.855272]\n",
      "epoch:45 step:35709 [D loss: 0.086492, acc: 99.22%] [G loss: 9.266815]\n",
      "epoch:45 step:35710 [D loss: 0.500035, acc: 64.06%] [G loss: 6.456804]\n",
      "epoch:45 step:35711 [D loss: 0.273150, acc: 88.28%] [G loss: 6.939713]\n",
      "epoch:45 step:35712 [D loss: 0.126738, acc: 99.22%] [G loss: 4.704223]\n",
      "epoch:45 step:35713 [D loss: 0.333632, acc: 82.81%] [G loss: 5.251015]\n",
      "epoch:45 step:35714 [D loss: 0.076404, acc: 99.22%] [G loss: 11.300327]\n",
      "epoch:45 step:35715 [D loss: 0.508851, acc: 78.91%] [G loss: 6.791969]\n",
      "epoch:45 step:35716 [D loss: 0.100235, acc: 99.22%] [G loss: 4.067032]\n",
      "epoch:45 step:35717 [D loss: 0.296639, acc: 95.31%] [G loss: 3.355122]\n",
      "epoch:45 step:35718 [D loss: 1.593000, acc: 15.62%] [G loss: 7.341216]\n",
      "epoch:45 step:35719 [D loss: 0.319715, acc: 83.59%] [G loss: 3.154373]\n",
      "epoch:45 step:35720 [D loss: 0.139993, acc: 98.44%] [G loss: 7.172009]\n",
      "epoch:45 step:35721 [D loss: 0.478775, acc: 73.44%] [G loss: 8.024300]\n",
      "epoch:45 step:35722 [D loss: 0.079802, acc: 100.00%] [G loss: 5.173594]\n",
      "epoch:45 step:35723 [D loss: 0.772766, acc: 53.91%] [G loss: 6.166628]\n",
      "epoch:45 step:35724 [D loss: 0.160161, acc: 98.44%] [G loss: 2.174952]\n",
      "epoch:45 step:35725 [D loss: 0.027173, acc: 100.00%] [G loss: 6.962739]\n",
      "epoch:45 step:35726 [D loss: 1.529189, acc: 11.72%] [G loss: 7.497906]\n",
      "epoch:45 step:35727 [D loss: 0.571983, acc: 70.31%] [G loss: 5.182798]\n",
      "epoch:45 step:35728 [D loss: 0.239756, acc: 89.06%] [G loss: 8.045517]\n",
      "epoch:45 step:35729 [D loss: 0.143304, acc: 98.44%] [G loss: 4.098935]\n",
      "epoch:45 step:35730 [D loss: 0.201958, acc: 97.66%] [G loss: 9.537857]\n",
      "epoch:45 step:35731 [D loss: 0.403324, acc: 79.69%] [G loss: 4.751945]\n",
      "epoch:45 step:35732 [D loss: 0.705526, acc: 57.03%] [G loss: 6.316810]\n",
      "epoch:45 step:35733 [D loss: 0.157203, acc: 98.44%] [G loss: 6.923194]\n",
      "epoch:45 step:35734 [D loss: 0.011721, acc: 100.00%] [G loss: 6.383130]\n",
      "epoch:45 step:35735 [D loss: 0.184398, acc: 95.31%] [G loss: 6.067565]\n",
      "epoch:45 step:35736 [D loss: 0.044020, acc: 100.00%] [G loss: 6.703053]\n",
      "epoch:45 step:35737 [D loss: 0.247724, acc: 93.75%] [G loss: 2.717202]\n",
      "epoch:45 step:35738 [D loss: 0.204539, acc: 91.41%] [G loss: 5.642524]\n",
      "epoch:45 step:35739 [D loss: 0.233064, acc: 96.88%] [G loss: 6.229285]\n",
      "epoch:45 step:35740 [D loss: 0.652221, acc: 57.81%] [G loss: 9.530107]\n",
      "epoch:45 step:35741 [D loss: 0.957681, acc: 51.56%] [G loss: 2.387795]\n",
      "epoch:45 step:35742 [D loss: 0.167260, acc: 98.44%] [G loss: 3.999056]\n",
      "epoch:45 step:35743 [D loss: 0.067411, acc: 98.44%] [G loss: 5.334471]\n",
      "epoch:45 step:35744 [D loss: 0.125309, acc: 98.44%] [G loss: 6.589042]\n",
      "epoch:45 step:35745 [D loss: 0.038166, acc: 100.00%] [G loss: 5.560290]\n",
      "epoch:45 step:35746 [D loss: 0.493439, acc: 74.22%] [G loss: 7.866269]\n",
      "epoch:45 step:35747 [D loss: 0.135338, acc: 100.00%] [G loss: 6.866117]\n",
      "epoch:45 step:35748 [D loss: 0.010804, acc: 100.00%] [G loss: 6.538807]\n",
      "epoch:45 step:35749 [D loss: 0.465927, acc: 71.88%] [G loss: 4.949865]\n",
      "epoch:45 step:35750 [D loss: 0.057961, acc: 100.00%] [G loss: 4.557416]\n",
      "epoch:45 step:35751 [D loss: 0.963223, acc: 44.53%] [G loss: 4.870383]\n",
      "epoch:45 step:35752 [D loss: 0.121544, acc: 99.22%] [G loss: 5.431303]\n",
      "epoch:45 step:35753 [D loss: 0.626797, acc: 63.28%] [G loss: 6.605649]\n",
      "epoch:45 step:35754 [D loss: 1.363385, acc: 46.09%] [G loss: 9.627725]\n",
      "epoch:45 step:35755 [D loss: 0.136113, acc: 97.66%] [G loss: 4.541783]\n",
      "epoch:45 step:35756 [D loss: 0.843677, acc: 54.69%] [G loss: 9.040149]\n",
      "epoch:45 step:35757 [D loss: 0.110418, acc: 100.00%] [G loss: 3.309709]\n",
      "epoch:45 step:35758 [D loss: 0.189657, acc: 96.88%] [G loss: 3.671355]\n",
      "epoch:45 step:35759 [D loss: 0.007140, acc: 100.00%] [G loss: 7.377367]\n",
      "epoch:45 step:35760 [D loss: 0.099933, acc: 100.00%] [G loss: 5.534826]\n",
      "epoch:45 step:35761 [D loss: 0.199620, acc: 97.66%] [G loss: 5.287638]\n",
      "epoch:45 step:35762 [D loss: 0.140866, acc: 97.66%] [G loss: 7.411740]\n",
      "epoch:45 step:35763 [D loss: 0.066207, acc: 100.00%] [G loss: 5.054239]\n",
      "epoch:45 step:35764 [D loss: 0.465493, acc: 78.91%] [G loss: 7.123415]\n",
      "epoch:45 step:35765 [D loss: 0.693427, acc: 60.94%] [G loss: 5.927776]\n",
      "epoch:45 step:35766 [D loss: 0.006725, acc: 100.00%] [G loss: 6.973596]\n",
      "epoch:45 step:35767 [D loss: 0.083356, acc: 100.00%] [G loss: 7.675492]\n",
      "epoch:45 step:35768 [D loss: 0.240111, acc: 91.41%] [G loss: 5.593395]\n",
      "epoch:45 step:35769 [D loss: 0.351270, acc: 79.69%] [G loss: 5.908954]\n",
      "epoch:45 step:35770 [D loss: 0.208162, acc: 98.44%] [G loss: 7.776932]\n",
      "epoch:45 step:35771 [D loss: 0.024022, acc: 100.00%] [G loss: 3.220435]\n",
      "epoch:45 step:35772 [D loss: 0.312203, acc: 93.75%] [G loss: 5.808540]\n",
      "epoch:45 step:35773 [D loss: 0.185957, acc: 94.53%] [G loss: 5.712749]\n",
      "epoch:45 step:35774 [D loss: 0.121805, acc: 100.00%] [G loss: 3.671716]\n",
      "epoch:45 step:35775 [D loss: 0.007989, acc: 100.00%] [G loss: 10.353069]\n",
      "epoch:45 step:35776 [D loss: 0.443147, acc: 71.09%] [G loss: 5.302599]\n",
      "epoch:45 step:35777 [D loss: 0.721366, acc: 57.03%] [G loss: 7.880525]\n",
      "epoch:45 step:35778 [D loss: 0.733774, acc: 54.69%] [G loss: 4.591306]\n",
      "epoch:45 step:35779 [D loss: 0.024437, acc: 100.00%] [G loss: 5.112991]\n",
      "epoch:45 step:35780 [D loss: 0.269982, acc: 86.72%] [G loss: 8.778453]\n",
      "epoch:45 step:35781 [D loss: 1.184982, acc: 50.00%] [G loss: 5.953740]\n",
      "epoch:45 step:35782 [D loss: 0.113602, acc: 97.66%] [G loss: 4.268338]\n",
      "epoch:45 step:35783 [D loss: 0.135970, acc: 98.44%] [G loss: 4.738248]\n",
      "epoch:45 step:35784 [D loss: 0.169738, acc: 97.66%] [G loss: 5.978538]\n",
      "epoch:45 step:35785 [D loss: 0.096169, acc: 100.00%] [G loss: 2.701801]\n",
      "epoch:45 step:35786 [D loss: 0.318360, acc: 91.41%] [G loss: 6.285589]\n",
      "epoch:45 step:35787 [D loss: 0.158070, acc: 97.66%] [G loss: 5.083730]\n",
      "epoch:45 step:35788 [D loss: 0.219086, acc: 93.75%] [G loss: 8.946206]\n",
      "epoch:45 step:35789 [D loss: 0.126358, acc: 97.66%] [G loss: 8.834154]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:45 step:35790 [D loss: 0.507495, acc: 76.56%] [G loss: 5.421273]\n",
      "epoch:45 step:35791 [D loss: 0.297540, acc: 95.31%] [G loss: 5.247416]\n",
      "epoch:45 step:35792 [D loss: 0.147920, acc: 96.09%] [G loss: 7.136513]\n",
      "epoch:45 step:35793 [D loss: 0.908007, acc: 50.78%] [G loss: 5.282362]\n",
      "epoch:45 step:35794 [D loss: 0.060434, acc: 100.00%] [G loss: 4.647239]\n",
      "epoch:45 step:35795 [D loss: 0.916609, acc: 49.22%] [G loss: 8.775002]\n",
      "epoch:45 step:35796 [D loss: 0.012445, acc: 100.00%] [G loss: 3.986831]\n",
      "epoch:45 step:35797 [D loss: 0.331619, acc: 82.03%] [G loss: 5.649664]\n",
      "epoch:45 step:35798 [D loss: 0.052542, acc: 100.00%] [G loss: 8.638603]\n",
      "epoch:45 step:35799 [D loss: 0.176891, acc: 100.00%] [G loss: 4.726562]\n",
      "epoch:45 step:35800 [D loss: 0.003007, acc: 100.00%] [G loss: 8.584671]\n",
      "##############\n",
      "[0.86111691 0.87588803 0.80135216 0.82570988 0.79938789 0.82486606\n",
      " 0.8761579  0.79390062 0.82276225 0.83636062]\n",
      "##########\n",
      "epoch:45 step:35801 [D loss: 0.083305, acc: 100.00%] [G loss: 8.718110]\n",
      "epoch:45 step:35802 [D loss: 1.564755, acc: 50.00%] [G loss: 8.599520]\n",
      "epoch:45 step:35803 [D loss: 1.547196, acc: 50.00%] [G loss: 3.645842]\n",
      "epoch:45 step:35804 [D loss: 0.091837, acc: 99.22%] [G loss: 3.221475]\n",
      "epoch:45 step:35805 [D loss: 0.575106, acc: 56.25%] [G loss: 6.750696]\n",
      "epoch:45 step:35806 [D loss: 1.939050, acc: 0.78%] [G loss: 7.268842]\n",
      "epoch:45 step:35807 [D loss: 0.882830, acc: 52.34%] [G loss: 5.839527]\n",
      "epoch:45 step:35808 [D loss: 0.242558, acc: 92.19%] [G loss: 5.563715]\n",
      "epoch:45 step:35809 [D loss: 0.054875, acc: 100.00%] [G loss: 7.536547]\n",
      "epoch:45 step:35810 [D loss: 0.049400, acc: 100.00%] [G loss: 8.663401]\n",
      "epoch:45 step:35811 [D loss: 0.052086, acc: 100.00%] [G loss: 0.872374]\n",
      "epoch:45 step:35812 [D loss: 0.019368, acc: 100.00%] [G loss: 10.160293]\n",
      "epoch:45 step:35813 [D loss: 0.224256, acc: 96.09%] [G loss: 3.795533]\n",
      "epoch:45 step:35814 [D loss: 0.087119, acc: 99.22%] [G loss: 4.255819]\n",
      "epoch:45 step:35815 [D loss: 0.639572, acc: 64.84%] [G loss: 5.099206]\n",
      "epoch:45 step:35816 [D loss: 0.044612, acc: 100.00%] [G loss: 6.704330]\n",
      "epoch:45 step:35817 [D loss: 0.149813, acc: 96.09%] [G loss: 3.037860]\n",
      "epoch:45 step:35818 [D loss: 0.034985, acc: 100.00%] [G loss: 7.511066]\n",
      "epoch:45 step:35819 [D loss: 0.045632, acc: 100.00%] [G loss: 6.753752]\n",
      "epoch:45 step:35820 [D loss: 0.521383, acc: 68.75%] [G loss: 5.085539]\n",
      "epoch:45 step:35821 [D loss: 0.736352, acc: 55.47%] [G loss: 7.678128]\n",
      "epoch:45 step:35822 [D loss: 0.125792, acc: 99.22%] [G loss: 9.365588]\n",
      "epoch:45 step:35823 [D loss: 0.053652, acc: 100.00%] [G loss: 4.254048]\n",
      "epoch:45 step:35824 [D loss: 0.340089, acc: 85.16%] [G loss: 11.930684]\n",
      "epoch:45 step:35825 [D loss: 0.230107, acc: 97.66%] [G loss: 4.406891]\n",
      "epoch:45 step:35826 [D loss: 0.193595, acc: 96.88%] [G loss: 6.458462]\n",
      "epoch:45 step:35827 [D loss: 0.791072, acc: 46.09%] [G loss: 6.241919]\n",
      "epoch:45 step:35828 [D loss: 0.173284, acc: 98.44%] [G loss: 4.539491]\n",
      "epoch:45 step:35829 [D loss: 0.809415, acc: 49.22%] [G loss: 5.157909]\n",
      "epoch:45 step:35830 [D loss: 0.452774, acc: 84.38%] [G loss: 3.393960]\n",
      "epoch:45 step:35831 [D loss: 0.037847, acc: 100.00%] [G loss: 1.671624]\n",
      "epoch:45 step:35832 [D loss: 0.130460, acc: 98.44%] [G loss: 5.900427]\n",
      "epoch:45 step:35833 [D loss: 0.072014, acc: 99.22%] [G loss: 7.667306]\n",
      "epoch:45 step:35834 [D loss: 1.082917, acc: 48.44%] [G loss: 7.993287]\n",
      "epoch:45 step:35835 [D loss: 0.029826, acc: 100.00%] [G loss: 8.665646]\n",
      "epoch:45 step:35836 [D loss: 0.103557, acc: 98.44%] [G loss: 5.187345]\n",
      "epoch:45 step:35837 [D loss: 0.195214, acc: 94.53%] [G loss: 8.108809]\n",
      "epoch:45 step:35838 [D loss: 0.231372, acc: 94.53%] [G loss: 4.865950]\n",
      "epoch:45 step:35839 [D loss: 0.081514, acc: 100.00%] [G loss: 3.730855]\n",
      "epoch:45 step:35840 [D loss: 0.203142, acc: 95.31%] [G loss: 3.133554]\n",
      "epoch:45 step:35841 [D loss: 0.031028, acc: 100.00%] [G loss: 6.460242]\n",
      "epoch:45 step:35842 [D loss: 0.086872, acc: 100.00%] [G loss: 4.930090]\n",
      "epoch:45 step:35843 [D loss: 0.040590, acc: 99.22%] [G loss: 6.763118]\n",
      "epoch:45 step:35844 [D loss: 0.081772, acc: 99.22%] [G loss: 9.926631]\n",
      "epoch:45 step:35845 [D loss: 0.065858, acc: 100.00%] [G loss: 6.517781]\n",
      "epoch:45 step:35846 [D loss: 0.020258, acc: 100.00%] [G loss: 5.026622]\n",
      "epoch:45 step:35847 [D loss: 0.024802, acc: 100.00%] [G loss: 7.336182]\n",
      "epoch:45 step:35848 [D loss: 0.289690, acc: 94.53%] [G loss: 5.676002]\n",
      "epoch:45 step:35849 [D loss: 0.122362, acc: 100.00%] [G loss: 8.010439]\n",
      "epoch:45 step:35850 [D loss: 0.013542, acc: 100.00%] [G loss: 9.179064]\n",
      "epoch:45 step:35851 [D loss: 0.470365, acc: 68.75%] [G loss: 8.888166]\n",
      "epoch:45 step:35852 [D loss: 0.575612, acc: 59.38%] [G loss: 7.231665]\n",
      "epoch:45 step:35853 [D loss: 1.029021, acc: 28.91%] [G loss: 12.112412]\n",
      "epoch:45 step:35854 [D loss: 1.949083, acc: 50.00%] [G loss: 7.147898]\n",
      "epoch:45 step:35855 [D loss: 0.171452, acc: 98.44%] [G loss: 4.577619]\n",
      "epoch:45 step:35856 [D loss: 0.065575, acc: 99.22%] [G loss: 8.225019]\n",
      "epoch:45 step:35857 [D loss: 0.631314, acc: 57.81%] [G loss: 7.922753]\n",
      "epoch:45 step:35858 [D loss: 0.022578, acc: 100.00%] [G loss: 8.491550]\n",
      "epoch:45 step:35859 [D loss: 0.109377, acc: 98.44%] [G loss: 8.035263]\n",
      "epoch:45 step:35860 [D loss: 0.073679, acc: 98.44%] [G loss: 3.010670]\n",
      "epoch:45 step:35861 [D loss: 0.332803, acc: 87.50%] [G loss: 7.227721]\n",
      "epoch:45 step:35862 [D loss: 0.067116, acc: 100.00%] [G loss: 4.616505]\n",
      "epoch:45 step:35863 [D loss: 0.180034, acc: 98.44%] [G loss: 9.080067]\n",
      "epoch:45 step:35864 [D loss: 0.553711, acc: 66.41%] [G loss: 5.707957]\n",
      "epoch:45 step:35865 [D loss: 0.193027, acc: 96.09%] [G loss: 6.174879]\n",
      "epoch:45 step:35866 [D loss: 0.029602, acc: 100.00%] [G loss: 5.168135]\n",
      "epoch:45 step:35867 [D loss: 0.536212, acc: 71.88%] [G loss: 6.413997]\n",
      "epoch:45 step:35868 [D loss: 0.005463, acc: 100.00%] [G loss: 10.427335]\n",
      "epoch:45 step:35869 [D loss: 0.170579, acc: 96.09%] [G loss: 7.978877]\n",
      "epoch:45 step:35870 [D loss: 0.090091, acc: 100.00%] [G loss: 6.947234]\n",
      "epoch:45 step:35871 [D loss: 0.093702, acc: 100.00%] [G loss: 5.585079]\n",
      "epoch:45 step:35872 [D loss: 0.142146, acc: 100.00%] [G loss: 11.121224]\n",
      "epoch:45 step:35873 [D loss: 0.113597, acc: 100.00%] [G loss: 6.017075]\n",
      "epoch:45 step:35874 [D loss: 0.035197, acc: 100.00%] [G loss: 7.904168]\n",
      "epoch:45 step:35875 [D loss: 0.293808, acc: 96.09%] [G loss: 6.039311]\n",
      "epoch:45 step:35876 [D loss: 1.097628, acc: 47.66%] [G loss: 4.468428]\n",
      "epoch:45 step:35877 [D loss: 0.140169, acc: 97.66%] [G loss: 6.202368]\n",
      "epoch:45 step:35878 [D loss: 0.829779, acc: 51.56%] [G loss: 6.553224]\n",
      "epoch:45 step:35879 [D loss: 0.920958, acc: 50.78%] [G loss: 4.452783]\n",
      "epoch:45 step:35880 [D loss: 0.257382, acc: 91.41%] [G loss: 5.166217]\n",
      "epoch:45 step:35881 [D loss: 0.189870, acc: 95.31%] [G loss: 5.139527]\n",
      "epoch:45 step:35882 [D loss: 0.025270, acc: 100.00%] [G loss: 7.237522]\n",
      "epoch:45 step:35883 [D loss: 0.474182, acc: 77.34%] [G loss: 8.503708]\n",
      "epoch:45 step:35884 [D loss: 0.031600, acc: 100.00%] [G loss: 3.064666]\n",
      "epoch:45 step:35885 [D loss: 0.767852, acc: 58.59%] [G loss: 9.251296]\n",
      "epoch:45 step:35886 [D loss: 0.598614, acc: 71.88%] [G loss: 5.837193]\n",
      "epoch:45 step:35887 [D loss: 0.672176, acc: 60.94%] [G loss: 8.955936]\n",
      "epoch:45 step:35888 [D loss: 0.157254, acc: 97.66%] [G loss: 3.352825]\n",
      "epoch:45 step:35889 [D loss: 0.237398, acc: 96.09%] [G loss: 6.469235]\n",
      "epoch:45 step:35890 [D loss: 0.030567, acc: 100.00%] [G loss: 7.704589]\n",
      "epoch:45 step:35891 [D loss: 0.168644, acc: 99.22%] [G loss: 5.450768]\n",
      "epoch:45 step:35892 [D loss: 0.162201, acc: 98.44%] [G loss: 6.891847]\n",
      "epoch:45 step:35893 [D loss: 0.016370, acc: 100.00%] [G loss: 5.678837]\n",
      "epoch:45 step:35894 [D loss: 0.348707, acc: 82.03%] [G loss: 6.252482]\n",
      "epoch:45 step:35895 [D loss: 0.680247, acc: 57.81%] [G loss: 8.266754]\n",
      "epoch:45 step:35896 [D loss: 0.252852, acc: 87.50%] [G loss: 6.121671]\n",
      "epoch:45 step:35897 [D loss: 0.230491, acc: 97.66%] [G loss: 5.845700]\n",
      "epoch:45 step:35898 [D loss: 0.242828, acc: 94.53%] [G loss: 3.315702]\n",
      "epoch:45 step:35899 [D loss: 0.816495, acc: 53.91%] [G loss: 7.749813]\n",
      "epoch:45 step:35900 [D loss: 0.211981, acc: 96.88%] [G loss: 3.561586]\n",
      "epoch:45 step:35901 [D loss: 0.410119, acc: 71.09%] [G loss: 6.060721]\n",
      "epoch:45 step:35902 [D loss: 0.109162, acc: 99.22%] [G loss: 10.873484]\n",
      "epoch:45 step:35903 [D loss: 0.429155, acc: 78.91%] [G loss: 4.613423]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:45 step:35904 [D loss: 0.326708, acc: 92.19%] [G loss: 4.789648]\n",
      "epoch:45 step:35905 [D loss: 0.031527, acc: 100.00%] [G loss: 11.985535]\n",
      "epoch:45 step:35906 [D loss: 0.320181, acc: 89.84%] [G loss: 5.113536]\n",
      "epoch:45 step:35907 [D loss: 0.008826, acc: 100.00%] [G loss: 6.857801]\n",
      "epoch:45 step:35908 [D loss: 0.355854, acc: 89.06%] [G loss: 6.368044]\n",
      "epoch:45 step:35909 [D loss: 0.418770, acc: 72.66%] [G loss: 10.678201]\n",
      "epoch:45 step:35910 [D loss: 0.149090, acc: 96.88%] [G loss: 7.715464]\n",
      "epoch:45 step:35911 [D loss: 0.037807, acc: 100.00%] [G loss: 4.765256]\n",
      "epoch:45 step:35912 [D loss: 1.021303, acc: 52.34%] [G loss: 7.579394]\n",
      "epoch:45 step:35913 [D loss: 0.248860, acc: 91.41%] [G loss: 8.007671]\n",
      "epoch:45 step:35914 [D loss: 0.859504, acc: 50.78%] [G loss: 7.474563]\n",
      "epoch:45 step:35915 [D loss: 0.030430, acc: 100.00%] [G loss: 6.302691]\n",
      "epoch:45 step:35916 [D loss: 0.305314, acc: 84.38%] [G loss: 7.498729]\n",
      "epoch:45 step:35917 [D loss: 0.021652, acc: 100.00%] [G loss: 6.457798]\n",
      "epoch:45 step:35918 [D loss: 0.347631, acc: 83.59%] [G loss: 10.115810]\n",
      "epoch:45 step:35919 [D loss: 0.477324, acc: 70.31%] [G loss: 11.965464]\n",
      "epoch:45 step:35920 [D loss: 0.472704, acc: 78.12%] [G loss: 7.600979]\n",
      "epoch:45 step:35921 [D loss: 0.670718, acc: 63.28%] [G loss: 5.920962]\n",
      "epoch:45 step:35922 [D loss: 0.427789, acc: 82.81%] [G loss: 8.972091]\n",
      "epoch:45 step:35923 [D loss: 0.530501, acc: 66.41%] [G loss: 8.389183]\n",
      "epoch:45 step:35924 [D loss: 0.245509, acc: 94.53%] [G loss: 4.958881]\n",
      "epoch:45 step:35925 [D loss: 0.283547, acc: 90.62%] [G loss: 4.057049]\n",
      "epoch:45 step:35926 [D loss: 0.147348, acc: 97.66%] [G loss: 4.888988]\n",
      "epoch:46 step:35927 [D loss: 0.048623, acc: 100.00%] [G loss: 6.269110]\n",
      "epoch:46 step:35928 [D loss: 0.243334, acc: 96.09%] [G loss: 5.333181]\n",
      "epoch:46 step:35929 [D loss: 0.059449, acc: 100.00%] [G loss: 3.465599]\n",
      "epoch:46 step:35930 [D loss: 0.038734, acc: 100.00%] [G loss: 5.408116]\n",
      "epoch:46 step:35931 [D loss: 0.284126, acc: 89.06%] [G loss: 4.370734]\n",
      "epoch:46 step:35932 [D loss: 0.049990, acc: 100.00%] [G loss: 6.680171]\n",
      "epoch:46 step:35933 [D loss: 0.309426, acc: 89.06%] [G loss: 4.363053]\n",
      "epoch:46 step:35934 [D loss: 0.451997, acc: 85.94%] [G loss: 5.882362]\n",
      "epoch:46 step:35935 [D loss: 0.033322, acc: 100.00%] [G loss: 8.814069]\n",
      "epoch:46 step:35936 [D loss: 0.844657, acc: 53.12%] [G loss: 9.627803]\n",
      "epoch:46 step:35937 [D loss: 0.349716, acc: 78.91%] [G loss: 12.191100]\n",
      "epoch:46 step:35938 [D loss: 0.024291, acc: 100.00%] [G loss: 11.276459]\n",
      "epoch:46 step:35939 [D loss: 0.146814, acc: 97.66%] [G loss: 8.794306]\n",
      "epoch:46 step:35940 [D loss: 0.136784, acc: 98.44%] [G loss: 8.006052]\n",
      "epoch:46 step:35941 [D loss: 0.186940, acc: 94.53%] [G loss: 2.373206]\n",
      "epoch:46 step:35942 [D loss: 0.295454, acc: 92.97%] [G loss: 7.566739]\n",
      "epoch:46 step:35943 [D loss: 0.306190, acc: 85.94%] [G loss: 5.876606]\n",
      "epoch:46 step:35944 [D loss: 0.358313, acc: 82.81%] [G loss: 6.734156]\n",
      "epoch:46 step:35945 [D loss: 0.186419, acc: 99.22%] [G loss: 5.980158]\n",
      "epoch:46 step:35946 [D loss: 0.414251, acc: 78.12%] [G loss: 5.858218]\n",
      "epoch:46 step:35947 [D loss: 0.105827, acc: 99.22%] [G loss: 6.835931]\n",
      "epoch:46 step:35948 [D loss: 0.106439, acc: 98.44%] [G loss: 6.109653]\n",
      "epoch:46 step:35949 [D loss: 0.101460, acc: 99.22%] [G loss: 5.835900]\n",
      "epoch:46 step:35950 [D loss: 0.041413, acc: 100.00%] [G loss: 5.399155]\n",
      "epoch:46 step:35951 [D loss: 1.374535, acc: 13.28%] [G loss: 8.833762]\n",
      "epoch:46 step:35952 [D loss: 0.209772, acc: 95.31%] [G loss: 5.507528]\n",
      "epoch:46 step:35953 [D loss: 0.131948, acc: 99.22%] [G loss: 5.157482]\n",
      "epoch:46 step:35954 [D loss: 0.202668, acc: 94.53%] [G loss: 3.141373]\n",
      "epoch:46 step:35955 [D loss: 0.479597, acc: 68.75%] [G loss: 5.953691]\n",
      "epoch:46 step:35956 [D loss: 0.034768, acc: 100.00%] [G loss: 7.168941]\n",
      "epoch:46 step:35957 [D loss: 0.911904, acc: 57.81%] [G loss: 6.983701]\n",
      "epoch:46 step:35958 [D loss: 0.307038, acc: 86.72%] [G loss: 5.470523]\n",
      "epoch:46 step:35959 [D loss: 0.479271, acc: 71.09%] [G loss: 5.350085]\n",
      "epoch:46 step:35960 [D loss: 0.055941, acc: 100.00%] [G loss: 4.206214]\n",
      "epoch:46 step:35961 [D loss: 0.152775, acc: 96.09%] [G loss: 7.240014]\n",
      "epoch:46 step:35962 [D loss: 0.122639, acc: 100.00%] [G loss: 6.186811]\n",
      "epoch:46 step:35963 [D loss: 0.384883, acc: 80.47%] [G loss: 7.871036]\n",
      "epoch:46 step:35964 [D loss: 0.609641, acc: 60.94%] [G loss: 11.761145]\n",
      "epoch:46 step:35965 [D loss: 0.194815, acc: 96.88%] [G loss: 7.181499]\n",
      "epoch:46 step:35966 [D loss: 0.190865, acc: 96.88%] [G loss: 9.747412]\n",
      "epoch:46 step:35967 [D loss: 0.084949, acc: 100.00%] [G loss: 7.539904]\n",
      "epoch:46 step:35968 [D loss: 0.084771, acc: 100.00%] [G loss: 6.512379]\n",
      "epoch:46 step:35969 [D loss: 0.541314, acc: 64.84%] [G loss: 6.447353]\n",
      "epoch:46 step:35970 [D loss: 0.213902, acc: 93.75%] [G loss: 5.809746]\n",
      "epoch:46 step:35971 [D loss: 0.079325, acc: 99.22%] [G loss: 3.369216]\n",
      "epoch:46 step:35972 [D loss: 1.148136, acc: 50.00%] [G loss: 6.871485]\n",
      "epoch:46 step:35973 [D loss: 0.280831, acc: 92.19%] [G loss: 7.415051]\n",
      "epoch:46 step:35974 [D loss: 0.232217, acc: 91.41%] [G loss: 6.358262]\n",
      "epoch:46 step:35975 [D loss: 0.819328, acc: 50.00%] [G loss: 6.781483]\n",
      "epoch:46 step:35976 [D loss: 0.171673, acc: 96.09%] [G loss: 6.353838]\n",
      "epoch:46 step:35977 [D loss: 0.053726, acc: 100.00%] [G loss: 6.548558]\n",
      "epoch:46 step:35978 [D loss: 0.012380, acc: 100.00%] [G loss: 11.275824]\n",
      "epoch:46 step:35979 [D loss: 0.242750, acc: 92.19%] [G loss: 7.064336]\n",
      "epoch:46 step:35980 [D loss: 0.032620, acc: 100.00%] [G loss: 7.818709]\n",
      "epoch:46 step:35981 [D loss: 0.106574, acc: 99.22%] [G loss: 3.790720]\n",
      "epoch:46 step:35982 [D loss: 0.225329, acc: 98.44%] [G loss: 4.965919]\n",
      "epoch:46 step:35983 [D loss: 0.057649, acc: 100.00%] [G loss: 5.227711]\n",
      "epoch:46 step:35984 [D loss: 0.084758, acc: 100.00%] [G loss: 6.824077]\n",
      "epoch:46 step:35985 [D loss: 0.027886, acc: 100.00%] [G loss: 9.061062]\n",
      "epoch:46 step:35986 [D loss: 0.214727, acc: 96.09%] [G loss: 4.862331]\n",
      "epoch:46 step:35987 [D loss: 0.091831, acc: 100.00%] [G loss: 6.119532]\n",
      "epoch:46 step:35988 [D loss: 0.925879, acc: 50.00%] [G loss: 6.732993]\n",
      "epoch:46 step:35989 [D loss: 0.236915, acc: 92.97%] [G loss: 5.599377]\n",
      "epoch:46 step:35990 [D loss: 1.179256, acc: 48.44%] [G loss: 9.099591]\n",
      "epoch:46 step:35991 [D loss: 0.317622, acc: 89.06%] [G loss: 7.124549]\n",
      "epoch:46 step:35992 [D loss: 0.178299, acc: 96.09%] [G loss: 9.694239]\n",
      "epoch:46 step:35993 [D loss: 0.068517, acc: 100.00%] [G loss: 7.558219]\n",
      "epoch:46 step:35994 [D loss: 0.300856, acc: 89.06%] [G loss: 6.412529]\n",
      "epoch:46 step:35995 [D loss: 0.290044, acc: 90.62%] [G loss: 4.318409]\n",
      "epoch:46 step:35996 [D loss: 0.095014, acc: 99.22%] [G loss: 5.615930]\n",
      "epoch:46 step:35997 [D loss: 0.866246, acc: 41.41%] [G loss: 10.123454]\n",
      "epoch:46 step:35998 [D loss: 0.479082, acc: 82.81%] [G loss: 8.470698]\n",
      "epoch:46 step:35999 [D loss: 0.232549, acc: 90.62%] [G loss: 7.900950]\n",
      "epoch:46 step:36000 [D loss: 0.666821, acc: 64.84%] [G loss: 4.989782]\n",
      "##############\n",
      "[0.8569031  0.85844042 0.82875168 0.80061376 0.75608439 0.8092743\n",
      " 0.89884215 0.81120839 0.80658691 0.81712075]\n",
      "##########\n",
      "epoch:46 step:36001 [D loss: 0.492883, acc: 73.44%] [G loss: 7.514360]\n",
      "epoch:46 step:36002 [D loss: 0.166743, acc: 98.44%] [G loss: 5.776575]\n",
      "epoch:46 step:36003 [D loss: 0.668622, acc: 62.50%] [G loss: 8.682923]\n",
      "epoch:46 step:36004 [D loss: 0.203870, acc: 96.88%] [G loss: 6.264698]\n",
      "epoch:46 step:36005 [D loss: 0.237214, acc: 89.84%] [G loss: 4.595994]\n",
      "epoch:46 step:36006 [D loss: 0.082165, acc: 99.22%] [G loss: 8.211153]\n",
      "epoch:46 step:36007 [D loss: 0.378524, acc: 82.03%] [G loss: 7.446092]\n",
      "epoch:46 step:36008 [D loss: 0.888297, acc: 52.34%] [G loss: 6.242767]\n",
      "epoch:46 step:36009 [D loss: 0.202581, acc: 94.53%] [G loss: 6.812737]\n",
      "epoch:46 step:36010 [D loss: 0.536072, acc: 71.09%] [G loss: 9.334038]\n",
      "epoch:46 step:36011 [D loss: 0.056508, acc: 100.00%] [G loss: 2.415708]\n",
      "epoch:46 step:36012 [D loss: 0.397384, acc: 85.16%] [G loss: 4.722208]\n",
      "epoch:46 step:36013 [D loss: 0.468857, acc: 78.91%] [G loss: 4.836073]\n",
      "epoch:46 step:36014 [D loss: 0.366656, acc: 82.03%] [G loss: 9.006563]\n",
      "epoch:46 step:36015 [D loss: 0.128802, acc: 96.88%] [G loss: 7.538422]\n",
      "epoch:46 step:36016 [D loss: 0.723369, acc: 57.81%] [G loss: 4.263452]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:46 step:36017 [D loss: 0.004502, acc: 100.00%] [G loss: 9.085337]\n",
      "epoch:46 step:36018 [D loss: 0.447131, acc: 70.31%] [G loss: 7.337889]\n",
      "epoch:46 step:36019 [D loss: 0.421681, acc: 76.56%] [G loss: 7.785539]\n",
      "epoch:46 step:36020 [D loss: 0.446412, acc: 86.72%] [G loss: 6.018367]\n",
      "epoch:46 step:36021 [D loss: 0.341743, acc: 82.81%] [G loss: 7.733422]\n",
      "epoch:46 step:36022 [D loss: 0.185964, acc: 96.88%] [G loss: 5.053417]\n",
      "epoch:46 step:36023 [D loss: 0.520555, acc: 67.19%] [G loss: 6.277244]\n",
      "epoch:46 step:36024 [D loss: 2.949545, acc: 50.00%] [G loss: 4.200664]\n",
      "epoch:46 step:36025 [D loss: 0.684011, acc: 53.12%] [G loss: 8.607852]\n",
      "epoch:46 step:36026 [D loss: 0.074620, acc: 100.00%] [G loss: 5.373409]\n",
      "epoch:46 step:36027 [D loss: 0.308063, acc: 92.97%] [G loss: 6.674106]\n",
      "epoch:46 step:36028 [D loss: 0.018324, acc: 100.00%] [G loss: 7.026913]\n",
      "epoch:46 step:36029 [D loss: 1.556655, acc: 47.66%] [G loss: 7.196903]\n",
      "epoch:46 step:36030 [D loss: 0.121765, acc: 98.44%] [G loss: 7.191333]\n",
      "epoch:46 step:36031 [D loss: 0.786876, acc: 53.91%] [G loss: 8.685779]\n",
      "epoch:46 step:36032 [D loss: 0.200886, acc: 94.53%] [G loss: 3.111546]\n",
      "epoch:46 step:36033 [D loss: 0.421140, acc: 75.00%] [G loss: 7.342803]\n",
      "epoch:46 step:36034 [D loss: 0.011150, acc: 100.00%] [G loss: 7.349122]\n",
      "epoch:46 step:36035 [D loss: 0.088212, acc: 99.22%] [G loss: 5.649371]\n",
      "epoch:46 step:36036 [D loss: 0.170898, acc: 96.09%] [G loss: 7.157362]\n",
      "epoch:46 step:36037 [D loss: 0.059469, acc: 100.00%] [G loss: 6.701770]\n",
      "epoch:46 step:36038 [D loss: 0.099634, acc: 100.00%] [G loss: 5.994119]\n",
      "epoch:46 step:36039 [D loss: 0.217041, acc: 93.75%] [G loss: 5.867815]\n",
      "epoch:46 step:36040 [D loss: 0.107620, acc: 99.22%] [G loss: 3.298292]\n",
      "epoch:46 step:36041 [D loss: 0.440751, acc: 76.56%] [G loss: 4.777102]\n",
      "epoch:46 step:36042 [D loss: 0.077134, acc: 99.22%] [G loss: 4.620193]\n",
      "epoch:46 step:36043 [D loss: 0.314220, acc: 92.97%] [G loss: 5.807951]\n",
      "epoch:46 step:36044 [D loss: 0.082366, acc: 100.00%] [G loss: 3.664939]\n",
      "epoch:46 step:36045 [D loss: 0.356092, acc: 92.19%] [G loss: 5.843208]\n",
      "epoch:46 step:36046 [D loss: 0.570267, acc: 57.81%] [G loss: 6.727927]\n",
      "epoch:46 step:36047 [D loss: 0.096732, acc: 99.22%] [G loss: 8.353816]\n",
      "epoch:46 step:36048 [D loss: 0.008068, acc: 100.00%] [G loss: 10.908923]\n",
      "epoch:46 step:36049 [D loss: 0.283538, acc: 87.50%] [G loss: 7.974603]\n",
      "epoch:46 step:36050 [D loss: 0.322401, acc: 87.50%] [G loss: 7.150614]\n",
      "epoch:46 step:36051 [D loss: 1.170136, acc: 20.31%] [G loss: 7.976638]\n",
      "epoch:46 step:36052 [D loss: 0.144319, acc: 100.00%] [G loss: 6.528327]\n",
      "epoch:46 step:36053 [D loss: 0.324403, acc: 87.50%] [G loss: 3.566332]\n",
      "epoch:46 step:36054 [D loss: 0.293153, acc: 88.28%] [G loss: 7.895690]\n",
      "epoch:46 step:36055 [D loss: 0.051583, acc: 100.00%] [G loss: 7.560522]\n",
      "epoch:46 step:36056 [D loss: 0.174781, acc: 97.66%] [G loss: 4.987038]\n",
      "epoch:46 step:36057 [D loss: 0.070680, acc: 99.22%] [G loss: 3.194278]\n",
      "epoch:46 step:36058 [D loss: 0.240866, acc: 96.09%] [G loss: 5.939893]\n",
      "epoch:46 step:36059 [D loss: 0.274000, acc: 89.06%] [G loss: 4.499832]\n",
      "epoch:46 step:36060 [D loss: 0.350386, acc: 77.34%] [G loss: 5.836310]\n",
      "epoch:46 step:36061 [D loss: 0.026209, acc: 100.00%] [G loss: 8.400075]\n",
      "epoch:46 step:36062 [D loss: 0.779442, acc: 52.34%] [G loss: 8.184462]\n",
      "epoch:46 step:36063 [D loss: 0.125491, acc: 98.44%] [G loss: 5.740371]\n",
      "epoch:46 step:36064 [D loss: 2.022442, acc: 4.69%] [G loss: 8.003316]\n",
      "epoch:46 step:36065 [D loss: 0.263634, acc: 87.50%] [G loss: 5.502085]\n",
      "epoch:46 step:36066 [D loss: 0.483350, acc: 78.91%] [G loss: 7.129063]\n",
      "epoch:46 step:36067 [D loss: 0.520500, acc: 75.00%] [G loss: 7.972752]\n",
      "epoch:46 step:36068 [D loss: 0.052697, acc: 100.00%] [G loss: 6.215370]\n",
      "epoch:46 step:36069 [D loss: 0.212480, acc: 96.88%] [G loss: 5.511579]\n",
      "epoch:46 step:36070 [D loss: 1.210201, acc: 50.00%] [G loss: 7.373176]\n",
      "epoch:46 step:36071 [D loss: 0.044468, acc: 100.00%] [G loss: 6.543215]\n",
      "epoch:46 step:36072 [D loss: 0.282712, acc: 84.38%] [G loss: 6.351629]\n",
      "epoch:46 step:36073 [D loss: 0.623108, acc: 63.28%] [G loss: 6.802930]\n",
      "epoch:46 step:36074 [D loss: 0.079764, acc: 100.00%] [G loss: 5.431438]\n",
      "epoch:46 step:36075 [D loss: 1.233685, acc: 33.59%] [G loss: 9.433363]\n",
      "epoch:46 step:36076 [D loss: 0.419053, acc: 80.47%] [G loss: 5.912273]\n",
      "epoch:46 step:36077 [D loss: 0.063662, acc: 100.00%] [G loss: 6.273467]\n",
      "epoch:46 step:36078 [D loss: 1.402221, acc: 50.00%] [G loss: 9.038541]\n",
      "epoch:46 step:36079 [D loss: 0.078531, acc: 100.00%] [G loss: 8.741659]\n",
      "epoch:46 step:36080 [D loss: 0.061169, acc: 100.00%] [G loss: 8.138212]\n",
      "epoch:46 step:36081 [D loss: 0.285572, acc: 84.38%] [G loss: 9.769296]\n",
      "epoch:46 step:36082 [D loss: 0.171056, acc: 97.66%] [G loss: 7.441829]\n",
      "epoch:46 step:36083 [D loss: 0.212719, acc: 99.22%] [G loss: 5.291515]\n",
      "epoch:46 step:36084 [D loss: 0.257034, acc: 96.88%] [G loss: 6.782755]\n",
      "epoch:46 step:36085 [D loss: 0.241993, acc: 94.53%] [G loss: 8.266861]\n",
      "epoch:46 step:36086 [D loss: 0.045784, acc: 100.00%] [G loss: 7.688576]\n",
      "epoch:46 step:36087 [D loss: 0.053468, acc: 99.22%] [G loss: 8.515324]\n",
      "epoch:46 step:36088 [D loss: 0.016029, acc: 100.00%] [G loss: 8.977452]\n",
      "epoch:46 step:36089 [D loss: 0.338993, acc: 91.41%] [G loss: 3.509049]\n",
      "epoch:46 step:36090 [D loss: 0.028110, acc: 100.00%] [G loss: 6.090353]\n",
      "epoch:46 step:36091 [D loss: 0.317429, acc: 85.16%] [G loss: 5.657631]\n",
      "epoch:46 step:36092 [D loss: 0.246002, acc: 96.88%] [G loss: 6.230874]\n",
      "epoch:46 step:36093 [D loss: 0.167825, acc: 96.88%] [G loss: 4.924047]\n",
      "epoch:46 step:36094 [D loss: 0.039271, acc: 100.00%] [G loss: 3.500274]\n",
      "epoch:46 step:36095 [D loss: 0.283836, acc: 89.84%] [G loss: 3.686799]\n",
      "epoch:46 step:36096 [D loss: 0.087148, acc: 99.22%] [G loss: 6.441542]\n",
      "epoch:46 step:36097 [D loss: 0.146445, acc: 96.88%] [G loss: 7.750926]\n",
      "epoch:46 step:36098 [D loss: 0.290603, acc: 86.72%] [G loss: 5.523373]\n",
      "epoch:46 step:36099 [D loss: 0.226409, acc: 96.88%] [G loss: 4.128712]\n",
      "epoch:46 step:36100 [D loss: 0.013336, acc: 100.00%] [G loss: 11.239668]\n",
      "epoch:46 step:36101 [D loss: 0.274786, acc: 89.06%] [G loss: 11.210643]\n",
      "epoch:46 step:36102 [D loss: 0.196338, acc: 95.31%] [G loss: 11.002487]\n",
      "epoch:46 step:36103 [D loss: 0.158949, acc: 97.66%] [G loss: 3.987339]\n",
      "epoch:46 step:36104 [D loss: 0.420556, acc: 82.81%] [G loss: 10.716511]\n",
      "epoch:46 step:36105 [D loss: 0.090890, acc: 100.00%] [G loss: 7.858772]\n",
      "epoch:46 step:36106 [D loss: 0.444973, acc: 76.56%] [G loss: 6.065738]\n",
      "epoch:46 step:36107 [D loss: 0.071282, acc: 100.00%] [G loss: 4.607081]\n",
      "epoch:46 step:36108 [D loss: 0.077025, acc: 100.00%] [G loss: 5.712773]\n",
      "epoch:46 step:36109 [D loss: 0.101728, acc: 100.00%] [G loss: 5.787632]\n",
      "epoch:46 step:36110 [D loss: 0.715885, acc: 64.06%] [G loss: 8.864269]\n",
      "epoch:46 step:36111 [D loss: 0.051659, acc: 100.00%] [G loss: 5.763030]\n",
      "epoch:46 step:36112 [D loss: 0.499275, acc: 69.53%] [G loss: 8.906847]\n",
      "epoch:46 step:36113 [D loss: 0.048417, acc: 100.00%] [G loss: 3.591957]\n",
      "epoch:46 step:36114 [D loss: 0.015419, acc: 100.00%] [G loss: 6.175771]\n",
      "epoch:46 step:36115 [D loss: 0.022852, acc: 100.00%] [G loss: 9.638943]\n",
      "epoch:46 step:36116 [D loss: 0.067047, acc: 100.00%] [G loss: 5.834999]\n",
      "epoch:46 step:36117 [D loss: 0.325877, acc: 87.50%] [G loss: 10.282836]\n",
      "epoch:46 step:36118 [D loss: 0.206799, acc: 96.09%] [G loss: 5.570029]\n",
      "epoch:46 step:36119 [D loss: 0.176086, acc: 95.31%] [G loss: 6.275012]\n",
      "epoch:46 step:36120 [D loss: 1.344090, acc: 11.72%] [G loss: 6.647321]\n",
      "epoch:46 step:36121 [D loss: 0.161286, acc: 97.66%] [G loss: 3.850468]\n",
      "epoch:46 step:36122 [D loss: 0.595795, acc: 61.72%] [G loss: 6.353785]\n",
      "epoch:46 step:36123 [D loss: 0.088627, acc: 100.00%] [G loss: 6.235202]\n",
      "epoch:46 step:36124 [D loss: 0.073629, acc: 99.22%] [G loss: 8.795323]\n",
      "epoch:46 step:36125 [D loss: 0.005079, acc: 100.00%] [G loss: 7.561805]\n",
      "epoch:46 step:36126 [D loss: 0.129949, acc: 98.44%] [G loss: 8.235065]\n",
      "epoch:46 step:36127 [D loss: 0.067970, acc: 99.22%] [G loss: 4.863547]\n",
      "epoch:46 step:36128 [D loss: 0.335448, acc: 90.62%] [G loss: 4.891018]\n",
      "epoch:46 step:36129 [D loss: 0.477789, acc: 68.75%] [G loss: 5.959090]\n",
      "epoch:46 step:36130 [D loss: 0.147952, acc: 97.66%] [G loss: 5.393821]\n",
      "epoch:46 step:36131 [D loss: 0.170492, acc: 95.31%] [G loss: 6.972494]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:46 step:36132 [D loss: 0.152572, acc: 96.09%] [G loss: 5.752911]\n",
      "epoch:46 step:36133 [D loss: 0.231670, acc: 95.31%] [G loss: 9.179716]\n",
      "epoch:46 step:36134 [D loss: 0.259045, acc: 88.28%] [G loss: 3.576947]\n",
      "epoch:46 step:36135 [D loss: 0.414669, acc: 85.16%] [G loss: 3.309774]\n",
      "epoch:46 step:36136 [D loss: 0.653224, acc: 61.72%] [G loss: 3.695501]\n",
      "epoch:46 step:36137 [D loss: 1.723700, acc: 30.47%] [G loss: 10.793251]\n",
      "epoch:46 step:36138 [D loss: 0.010179, acc: 100.00%] [G loss: 8.219450]\n",
      "epoch:46 step:36139 [D loss: 0.103117, acc: 99.22%] [G loss: 5.960514]\n",
      "epoch:46 step:36140 [D loss: 0.118835, acc: 100.00%] [G loss: 6.393643]\n",
      "epoch:46 step:36141 [D loss: 0.107085, acc: 100.00%] [G loss: 4.989533]\n",
      "epoch:46 step:36142 [D loss: 0.225704, acc: 94.53%] [G loss: 7.215989]\n",
      "epoch:46 step:36143 [D loss: 1.237150, acc: 50.00%] [G loss: 7.632828]\n",
      "epoch:46 step:36144 [D loss: 0.149308, acc: 96.88%] [G loss: 6.137940]\n",
      "epoch:46 step:36145 [D loss: 0.954519, acc: 51.56%] [G loss: 10.708968]\n",
      "epoch:46 step:36146 [D loss: 0.788650, acc: 50.78%] [G loss: 5.650523]\n",
      "epoch:46 step:36147 [D loss: 0.292764, acc: 87.50%] [G loss: 5.080164]\n",
      "epoch:46 step:36148 [D loss: 0.167499, acc: 96.88%] [G loss: 4.538589]\n",
      "epoch:46 step:36149 [D loss: 0.066531, acc: 100.00%] [G loss: 6.301501]\n",
      "epoch:46 step:36150 [D loss: 0.257960, acc: 95.31%] [G loss: 8.131889]\n",
      "epoch:46 step:36151 [D loss: 0.254787, acc: 87.50%] [G loss: 6.496958]\n",
      "epoch:46 step:36152 [D loss: 0.142320, acc: 100.00%] [G loss: 8.036581]\n",
      "epoch:46 step:36153 [D loss: 0.078911, acc: 99.22%] [G loss: 5.224054]\n",
      "epoch:46 step:36154 [D loss: 0.538926, acc: 71.09%] [G loss: 8.352949]\n",
      "epoch:46 step:36155 [D loss: 0.733865, acc: 53.91%] [G loss: 5.117661]\n",
      "epoch:46 step:36156 [D loss: 0.065206, acc: 100.00%] [G loss: 3.143450]\n",
      "epoch:46 step:36157 [D loss: 0.921311, acc: 40.62%] [G loss: 7.598786]\n",
      "epoch:46 step:36158 [D loss: 0.372980, acc: 87.50%] [G loss: 6.635118]\n",
      "epoch:46 step:36159 [D loss: 0.437210, acc: 71.88%] [G loss: 9.009741]\n",
      "epoch:46 step:36160 [D loss: 0.347848, acc: 85.16%] [G loss: 3.205716]\n",
      "epoch:46 step:36161 [D loss: 0.739960, acc: 53.12%] [G loss: 4.938110]\n",
      "epoch:46 step:36162 [D loss: 0.030080, acc: 100.00%] [G loss: 7.275962]\n",
      "epoch:46 step:36163 [D loss: 0.630451, acc: 61.72%] [G loss: 5.631272]\n",
      "epoch:46 step:36164 [D loss: 0.815405, acc: 51.56%] [G loss: 9.174198]\n",
      "epoch:46 step:36165 [D loss: 0.297593, acc: 85.16%] [G loss: 4.934891]\n",
      "epoch:46 step:36166 [D loss: 0.094380, acc: 99.22%] [G loss: 3.573350]\n",
      "epoch:46 step:36167 [D loss: 0.213145, acc: 92.19%] [G loss: 4.660727]\n",
      "epoch:46 step:36168 [D loss: 0.050955, acc: 99.22%] [G loss: 6.017637]\n",
      "epoch:46 step:36169 [D loss: 0.289200, acc: 91.41%] [G loss: 5.528523]\n",
      "epoch:46 step:36170 [D loss: 0.170060, acc: 94.53%] [G loss: 5.150182]\n",
      "epoch:46 step:36171 [D loss: 0.127346, acc: 98.44%] [G loss: 6.136000]\n",
      "epoch:46 step:36172 [D loss: 0.483920, acc: 80.47%] [G loss: 4.885200]\n",
      "epoch:46 step:36173 [D loss: 0.169833, acc: 96.88%] [G loss: 5.463284]\n",
      "epoch:46 step:36174 [D loss: 0.014534, acc: 100.00%] [G loss: 3.914001]\n",
      "epoch:46 step:36175 [D loss: 0.157077, acc: 96.88%] [G loss: 8.866404]\n",
      "epoch:46 step:36176 [D loss: 0.267436, acc: 95.31%] [G loss: 9.618186]\n",
      "epoch:46 step:36177 [D loss: 0.037638, acc: 100.00%] [G loss: 4.325900]\n",
      "epoch:46 step:36178 [D loss: 0.184352, acc: 95.31%] [G loss: 6.189560]\n",
      "epoch:46 step:36179 [D loss: 0.042260, acc: 100.00%] [G loss: 5.578292]\n",
      "epoch:46 step:36180 [D loss: 0.345869, acc: 93.75%] [G loss: 7.586201]\n",
      "epoch:46 step:36181 [D loss: 0.069733, acc: 100.00%] [G loss: 7.270226]\n",
      "epoch:46 step:36182 [D loss: 0.168831, acc: 96.88%] [G loss: 9.750267]\n",
      "epoch:46 step:36183 [D loss: 0.035339, acc: 100.00%] [G loss: 3.842672]\n",
      "epoch:46 step:36184 [D loss: 0.159306, acc: 97.66%] [G loss: 7.058418]\n",
      "epoch:46 step:36185 [D loss: 0.082849, acc: 100.00%] [G loss: 1.728630]\n",
      "epoch:46 step:36186 [D loss: 0.078873, acc: 100.00%] [G loss: 5.481642]\n",
      "epoch:46 step:36187 [D loss: 0.706932, acc: 56.25%] [G loss: 6.704022]\n",
      "epoch:46 step:36188 [D loss: 0.064186, acc: 100.00%] [G loss: 9.396032]\n",
      "epoch:46 step:36189 [D loss: 1.168861, acc: 28.12%] [G loss: 7.626409]\n",
      "epoch:46 step:36190 [D loss: 0.008015, acc: 100.00%] [G loss: 8.414897]\n",
      "epoch:46 step:36191 [D loss: 0.265540, acc: 89.84%] [G loss: 10.852586]\n",
      "epoch:46 step:36192 [D loss: 0.920027, acc: 48.44%] [G loss: 5.151190]\n",
      "epoch:46 step:36193 [D loss: 0.067867, acc: 100.00%] [G loss: 4.918664]\n",
      "epoch:46 step:36194 [D loss: 0.122602, acc: 98.44%] [G loss: 8.036602]\n",
      "epoch:46 step:36195 [D loss: 0.381903, acc: 75.78%] [G loss: 8.443557]\n",
      "epoch:46 step:36196 [D loss: 0.152142, acc: 99.22%] [G loss: 4.206557]\n",
      "epoch:46 step:36197 [D loss: 0.018364, acc: 100.00%] [G loss: 5.973781]\n",
      "epoch:46 step:36198 [D loss: 0.948117, acc: 50.78%] [G loss: 10.290978]\n",
      "epoch:46 step:36199 [D loss: 0.088188, acc: 100.00%] [G loss: 7.677926]\n",
      "epoch:46 step:36200 [D loss: 0.357352, acc: 87.50%] [G loss: 4.488687]\n",
      "##############\n",
      "[0.86165226 0.8577247  0.81180457 0.80892757 0.80001188 0.84838923\n",
      " 0.8837994  0.83872555 0.83720779 0.84406934]\n",
      "##########\n",
      "epoch:46 step:36201 [D loss: 0.994308, acc: 50.00%] [G loss: 6.889553]\n",
      "epoch:46 step:36202 [D loss: 0.464665, acc: 82.81%] [G loss: 7.038917]\n",
      "epoch:46 step:36203 [D loss: 0.424124, acc: 77.34%] [G loss: 3.329428]\n",
      "epoch:46 step:36204 [D loss: 0.135139, acc: 98.44%] [G loss: 11.502792]\n",
      "epoch:46 step:36205 [D loss: 0.565826, acc: 65.62%] [G loss: 8.798242]\n",
      "epoch:46 step:36206 [D loss: 0.131415, acc: 99.22%] [G loss: 7.517431]\n",
      "epoch:46 step:36207 [D loss: 0.023765, acc: 100.00%] [G loss: 6.624195]\n",
      "epoch:46 step:36208 [D loss: 0.429391, acc: 76.56%] [G loss: 6.383943]\n",
      "epoch:46 step:36209 [D loss: 0.124720, acc: 100.00%] [G loss: 5.347801]\n",
      "epoch:46 step:36210 [D loss: 0.380177, acc: 79.69%] [G loss: 2.309550]\n",
      "epoch:46 step:36211 [D loss: 0.056169, acc: 100.00%] [G loss: 4.963696]\n",
      "epoch:46 step:36212 [D loss: 0.150150, acc: 99.22%] [G loss: 5.833349]\n",
      "epoch:46 step:36213 [D loss: 0.554359, acc: 67.19%] [G loss: 6.922159]\n",
      "epoch:46 step:36214 [D loss: 0.212544, acc: 95.31%] [G loss: 9.703140]\n",
      "epoch:46 step:36215 [D loss: 0.031702, acc: 100.00%] [G loss: 5.929357]\n",
      "epoch:46 step:36216 [D loss: 0.200394, acc: 98.44%] [G loss: 3.650226]\n",
      "epoch:46 step:36217 [D loss: 0.132139, acc: 100.00%] [G loss: 4.099694]\n",
      "epoch:46 step:36218 [D loss: 0.800848, acc: 55.47%] [G loss: 6.168820]\n",
      "epoch:46 step:36219 [D loss: 0.687647, acc: 58.59%] [G loss: 5.359363]\n",
      "epoch:46 step:36220 [D loss: 0.152657, acc: 99.22%] [G loss: 7.150360]\n",
      "epoch:46 step:36221 [D loss: 0.092171, acc: 100.00%] [G loss: 5.287570]\n",
      "epoch:46 step:36222 [D loss: 0.030232, acc: 100.00%] [G loss: 8.193914]\n",
      "epoch:46 step:36223 [D loss: 0.143356, acc: 99.22%] [G loss: 4.215383]\n",
      "epoch:46 step:36224 [D loss: 0.381353, acc: 79.69%] [G loss: 6.377258]\n",
      "epoch:46 step:36225 [D loss: 0.321450, acc: 86.72%] [G loss: 6.690682]\n",
      "epoch:46 step:36226 [D loss: 0.677974, acc: 57.03%] [G loss: 8.172793]\n",
      "epoch:46 step:36227 [D loss: 0.341432, acc: 78.91%] [G loss: 5.103026]\n",
      "epoch:46 step:36228 [D loss: 0.033215, acc: 100.00%] [G loss: 5.050471]\n",
      "epoch:46 step:36229 [D loss: 0.382028, acc: 80.47%] [G loss: 4.323269]\n",
      "epoch:46 step:36230 [D loss: 0.067779, acc: 100.00%] [G loss: 6.400294]\n",
      "epoch:46 step:36231 [D loss: 0.086729, acc: 100.00%] [G loss: 8.397074]\n",
      "epoch:46 step:36232 [D loss: 0.018143, acc: 100.00%] [G loss: 8.686632]\n",
      "epoch:46 step:36233 [D loss: 0.135162, acc: 98.44%] [G loss: 5.503478]\n",
      "epoch:46 step:36234 [D loss: 0.073494, acc: 100.00%] [G loss: 3.837125]\n",
      "epoch:46 step:36235 [D loss: 0.534580, acc: 78.12%] [G loss: 5.674386]\n",
      "epoch:46 step:36236 [D loss: 0.112356, acc: 98.44%] [G loss: 3.844739]\n",
      "epoch:46 step:36237 [D loss: 0.522999, acc: 71.88%] [G loss: 3.618941]\n",
      "epoch:46 step:36238 [D loss: 0.881799, acc: 53.12%] [G loss: 7.148412]\n",
      "epoch:46 step:36239 [D loss: 0.241664, acc: 95.31%] [G loss: 7.277611]\n",
      "epoch:46 step:36240 [D loss: 0.134581, acc: 99.22%] [G loss: 4.509004]\n",
      "epoch:46 step:36241 [D loss: 0.021246, acc: 100.00%] [G loss: 8.549616]\n",
      "epoch:46 step:36242 [D loss: 0.084309, acc: 99.22%] [G loss: 7.661357]\n",
      "epoch:46 step:36243 [D loss: 0.529179, acc: 66.41%] [G loss: 5.616913]\n",
      "epoch:46 step:36244 [D loss: 0.310995, acc: 89.84%] [G loss: 3.125193]\n",
      "epoch:46 step:36245 [D loss: 0.108772, acc: 97.66%] [G loss: 5.167259]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:46 step:36246 [D loss: 0.092500, acc: 100.00%] [G loss: 5.079147]\n",
      "epoch:46 step:36247 [D loss: 0.157430, acc: 95.31%] [G loss: 2.884760]\n",
      "epoch:46 step:36248 [D loss: 0.022421, acc: 100.00%] [G loss: 8.127462]\n",
      "epoch:46 step:36249 [D loss: 0.413280, acc: 78.12%] [G loss: 5.423829]\n",
      "epoch:46 step:36250 [D loss: 0.343295, acc: 83.59%] [G loss: 4.984377]\n",
      "epoch:46 step:36251 [D loss: 0.404495, acc: 77.34%] [G loss: 6.198247]\n",
      "epoch:46 step:36252 [D loss: 0.648501, acc: 66.41%] [G loss: 5.363671]\n",
      "epoch:46 step:36253 [D loss: 0.240775, acc: 91.41%] [G loss: 3.750863]\n",
      "epoch:46 step:36254 [D loss: 0.296841, acc: 90.62%] [G loss: 4.466481]\n",
      "epoch:46 step:36255 [D loss: 0.151060, acc: 98.44%] [G loss: 4.740990]\n",
      "epoch:46 step:36256 [D loss: 0.217344, acc: 96.09%] [G loss: 6.373964]\n",
      "epoch:46 step:36257 [D loss: 0.086447, acc: 99.22%] [G loss: 8.248344]\n",
      "epoch:46 step:36258 [D loss: 0.295243, acc: 87.50%] [G loss: 3.712483]\n",
      "epoch:46 step:36259 [D loss: 0.012119, acc: 100.00%] [G loss: 8.513299]\n",
      "epoch:46 step:36260 [D loss: 0.239508, acc: 92.19%] [G loss: 6.315551]\n",
      "epoch:46 step:36261 [D loss: 0.012178, acc: 100.00%] [G loss: 8.349342]\n",
      "epoch:46 step:36262 [D loss: 0.066608, acc: 100.00%] [G loss: 5.499335]\n",
      "epoch:46 step:36263 [D loss: 0.069425, acc: 100.00%] [G loss: 6.907817]\n",
      "epoch:46 step:36264 [D loss: 0.099909, acc: 99.22%] [G loss: 9.027123]\n",
      "epoch:46 step:36265 [D loss: 0.642329, acc: 57.81%] [G loss: 5.732412]\n",
      "epoch:46 step:36266 [D loss: 0.309939, acc: 84.38%] [G loss: 13.592710]\n",
      "epoch:46 step:36267 [D loss: 0.207459, acc: 96.88%] [G loss: 8.607260]\n",
      "epoch:46 step:36268 [D loss: 0.107146, acc: 100.00%] [G loss: 5.899492]\n",
      "epoch:46 step:36269 [D loss: 0.006881, acc: 100.00%] [G loss: 6.745852]\n",
      "epoch:46 step:36270 [D loss: 0.055474, acc: 100.00%] [G loss: 6.708346]\n",
      "epoch:46 step:36271 [D loss: 0.072069, acc: 100.00%] [G loss: 4.884270]\n",
      "epoch:46 step:36272 [D loss: 0.066245, acc: 100.00%] [G loss: 2.658962]\n",
      "epoch:46 step:36273 [D loss: 0.259695, acc: 96.88%] [G loss: 3.804182]\n",
      "epoch:46 step:36274 [D loss: 0.138910, acc: 98.44%] [G loss: 3.505016]\n",
      "epoch:46 step:36275 [D loss: 0.414739, acc: 73.44%] [G loss: 6.492835]\n",
      "epoch:46 step:36276 [D loss: 0.813748, acc: 58.59%] [G loss: 5.428612]\n",
      "epoch:46 step:36277 [D loss: 0.580637, acc: 76.56%] [G loss: 8.139122]\n",
      "epoch:46 step:36278 [D loss: 0.076140, acc: 97.66%] [G loss: 8.765732]\n",
      "epoch:46 step:36279 [D loss: 0.100486, acc: 100.00%] [G loss: 4.557727]\n",
      "epoch:46 step:36280 [D loss: 0.246266, acc: 95.31%] [G loss: 6.048907]\n",
      "epoch:46 step:36281 [D loss: 1.241557, acc: 22.66%] [G loss: 8.184534]\n",
      "epoch:46 step:36282 [D loss: 0.032424, acc: 100.00%] [G loss: 9.517731]\n",
      "epoch:46 step:36283 [D loss: 0.468183, acc: 72.66%] [G loss: 9.433722]\n",
      "epoch:46 step:36284 [D loss: 1.802764, acc: 50.00%] [G loss: 6.936705]\n",
      "epoch:46 step:36285 [D loss: 0.052368, acc: 100.00%] [G loss: 5.435481]\n",
      "epoch:46 step:36286 [D loss: 0.043044, acc: 100.00%] [G loss: 6.208347]\n",
      "epoch:46 step:36287 [D loss: 0.784884, acc: 54.69%] [G loss: 9.898673]\n",
      "epoch:46 step:36288 [D loss: 0.316606, acc: 83.59%] [G loss: 7.804479]\n",
      "epoch:46 step:36289 [D loss: 0.142766, acc: 98.44%] [G loss: 3.811091]\n",
      "epoch:46 step:36290 [D loss: 1.317744, acc: 17.19%] [G loss: 7.574624]\n",
      "epoch:46 step:36291 [D loss: 0.074854, acc: 100.00%] [G loss: 2.683664]\n",
      "epoch:46 step:36292 [D loss: 0.920846, acc: 53.91%] [G loss: 7.392947]\n",
      "epoch:46 step:36293 [D loss: 0.063556, acc: 100.00%] [G loss: 5.436393]\n",
      "epoch:46 step:36294 [D loss: 1.129396, acc: 51.56%] [G loss: 9.437072]\n",
      "epoch:46 step:36295 [D loss: 1.224880, acc: 24.22%] [G loss: 8.302312]\n",
      "epoch:46 step:36296 [D loss: 0.264684, acc: 92.97%] [G loss: 3.017267]\n",
      "epoch:46 step:36297 [D loss: 0.454242, acc: 78.91%] [G loss: 6.325440]\n",
      "epoch:46 step:36298 [D loss: 0.193360, acc: 92.97%] [G loss: 7.194882]\n",
      "epoch:46 step:36299 [D loss: 0.160086, acc: 97.66%] [G loss: 6.453027]\n",
      "epoch:46 step:36300 [D loss: 0.034902, acc: 100.00%] [G loss: 7.758191]\n",
      "epoch:46 step:36301 [D loss: 0.279419, acc: 89.84%] [G loss: 7.675860]\n",
      "epoch:46 step:36302 [D loss: 0.631328, acc: 64.84%] [G loss: 6.922999]\n",
      "epoch:46 step:36303 [D loss: 0.214784, acc: 95.31%] [G loss: 4.939588]\n",
      "epoch:46 step:36304 [D loss: 0.581372, acc: 68.75%] [G loss: 6.716576]\n",
      "epoch:46 step:36305 [D loss: 0.133392, acc: 99.22%] [G loss: 7.037267]\n",
      "epoch:46 step:36306 [D loss: 0.209664, acc: 97.66%] [G loss: 3.718842]\n",
      "epoch:46 step:36307 [D loss: 0.041723, acc: 100.00%] [G loss: 5.756921]\n",
      "epoch:46 step:36308 [D loss: 0.133838, acc: 98.44%] [G loss: 3.336745]\n",
      "epoch:46 step:36309 [D loss: 0.248303, acc: 91.41%] [G loss: 6.820110]\n",
      "epoch:46 step:36310 [D loss: 0.325534, acc: 81.25%] [G loss: 9.260239]\n",
      "epoch:46 step:36311 [D loss: 0.026513, acc: 100.00%] [G loss: 9.923555]\n",
      "epoch:46 step:36312 [D loss: 0.036323, acc: 100.00%] [G loss: 9.938522]\n",
      "epoch:46 step:36313 [D loss: 0.015889, acc: 100.00%] [G loss: 7.220848]\n",
      "epoch:46 step:36314 [D loss: 0.019899, acc: 100.00%] [G loss: 8.587875]\n",
      "epoch:46 step:36315 [D loss: 0.019210, acc: 100.00%] [G loss: 1.541180]\n",
      "epoch:46 step:36316 [D loss: 0.357802, acc: 84.38%] [G loss: 3.513046]\n",
      "epoch:46 step:36317 [D loss: 0.035493, acc: 100.00%] [G loss: 6.101183]\n",
      "epoch:46 step:36318 [D loss: 0.063873, acc: 100.00%] [G loss: 3.725485]\n",
      "epoch:46 step:36319 [D loss: 0.090360, acc: 100.00%] [G loss: 4.979778]\n",
      "epoch:46 step:36320 [D loss: 0.259141, acc: 94.53%] [G loss: 4.682382]\n",
      "epoch:46 step:36321 [D loss: 0.339580, acc: 82.81%] [G loss: 3.091136]\n",
      "epoch:46 step:36322 [D loss: 0.047179, acc: 100.00%] [G loss: 5.665540]\n",
      "epoch:46 step:36323 [D loss: 0.491286, acc: 63.28%] [G loss: 4.825397]\n",
      "epoch:46 step:36324 [D loss: 0.062172, acc: 99.22%] [G loss: 7.008614]\n",
      "epoch:46 step:36325 [D loss: 0.394951, acc: 82.03%] [G loss: 5.230960]\n",
      "epoch:46 step:36326 [D loss: 0.247758, acc: 98.44%] [G loss: 6.575273]\n",
      "epoch:46 step:36327 [D loss: 0.000714, acc: 100.00%] [G loss: 7.518567]\n",
      "epoch:46 step:36328 [D loss: 0.130145, acc: 97.66%] [G loss: 5.449879]\n",
      "epoch:46 step:36329 [D loss: 0.268749, acc: 89.84%] [G loss: 10.978188]\n",
      "epoch:46 step:36330 [D loss: 0.048286, acc: 100.00%] [G loss: 3.337694]\n",
      "epoch:46 step:36331 [D loss: 0.018524, acc: 100.00%] [G loss: 8.819679]\n",
      "epoch:46 step:36332 [D loss: 0.295117, acc: 83.59%] [G loss: 6.297720]\n",
      "epoch:46 step:36333 [D loss: 0.494237, acc: 71.09%] [G loss: 5.874212]\n",
      "epoch:46 step:36334 [D loss: 0.090920, acc: 100.00%] [G loss: 6.295221]\n",
      "epoch:46 step:36335 [D loss: 0.847951, acc: 53.91%] [G loss: 8.851519]\n",
      "epoch:46 step:36336 [D loss: 0.313542, acc: 92.19%] [G loss: 5.401039]\n",
      "epoch:46 step:36337 [D loss: 0.091374, acc: 99.22%] [G loss: 4.289812]\n",
      "epoch:46 step:36338 [D loss: 0.216293, acc: 92.97%] [G loss: 5.023205]\n",
      "epoch:46 step:36339 [D loss: 0.116063, acc: 100.00%] [G loss: 3.430047]\n",
      "epoch:46 step:36340 [D loss: 0.238212, acc: 98.44%] [G loss: 5.226088]\n",
      "epoch:46 step:36341 [D loss: 0.686509, acc: 60.16%] [G loss: 7.297147]\n",
      "epoch:46 step:36342 [D loss: 0.154210, acc: 96.88%] [G loss: 4.559333]\n",
      "epoch:46 step:36343 [D loss: 0.928311, acc: 49.22%] [G loss: 7.617822]\n",
      "epoch:46 step:36344 [D loss: 0.117304, acc: 97.66%] [G loss: 8.491722]\n",
      "epoch:46 step:36345 [D loss: 0.050042, acc: 100.00%] [G loss: 7.781961]\n",
      "epoch:46 step:36346 [D loss: 0.237002, acc: 92.97%] [G loss: 10.129393]\n",
      "epoch:46 step:36347 [D loss: 0.243210, acc: 95.31%] [G loss: 9.019124]\n",
      "epoch:46 step:36348 [D loss: 0.368277, acc: 84.38%] [G loss: 8.517704]\n",
      "epoch:46 step:36349 [D loss: 0.959516, acc: 34.38%] [G loss: 6.813857]\n",
      "epoch:46 step:36350 [D loss: 0.420786, acc: 71.88%] [G loss: 4.841513]\n",
      "epoch:46 step:36351 [D loss: 0.135971, acc: 100.00%] [G loss: 5.505859]\n",
      "epoch:46 step:36352 [D loss: 0.578268, acc: 65.62%] [G loss: 3.270473]\n",
      "epoch:46 step:36353 [D loss: 0.350854, acc: 90.62%] [G loss: 8.406466]\n",
      "epoch:46 step:36354 [D loss: 0.199921, acc: 93.75%] [G loss: 8.939956]\n",
      "epoch:46 step:36355 [D loss: 0.641083, acc: 67.97%] [G loss: 7.378588]\n",
      "epoch:46 step:36356 [D loss: 0.363562, acc: 75.00%] [G loss: 10.195101]\n",
      "epoch:46 step:36357 [D loss: 0.047468, acc: 100.00%] [G loss: 6.512963]\n",
      "epoch:46 step:36358 [D loss: 0.623081, acc: 63.28%] [G loss: 5.000285]\n",
      "epoch:46 step:36359 [D loss: 0.104383, acc: 99.22%] [G loss: 9.078753]\n",
      "epoch:46 step:36360 [D loss: 0.026436, acc: 100.00%] [G loss: 10.025417]\n",
      "epoch:46 step:36361 [D loss: 0.053314, acc: 100.00%] [G loss: 8.884032]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:46 step:36362 [D loss: 0.224097, acc: 91.41%] [G loss: 6.835952]\n",
      "epoch:46 step:36363 [D loss: 0.090232, acc: 100.00%] [G loss: 5.503106]\n",
      "epoch:46 step:36364 [D loss: 0.469876, acc: 71.88%] [G loss: 9.064505]\n",
      "epoch:46 step:36365 [D loss: 0.020022, acc: 100.00%] [G loss: 6.622345]\n",
      "epoch:46 step:36366 [D loss: 0.229263, acc: 92.97%] [G loss: 3.311659]\n",
      "epoch:46 step:36367 [D loss: 0.384359, acc: 83.59%] [G loss: 4.113742]\n",
      "epoch:46 step:36368 [D loss: 0.015646, acc: 100.00%] [G loss: 6.346198]\n",
      "epoch:46 step:36369 [D loss: 0.170386, acc: 97.66%] [G loss: 7.535268]\n",
      "epoch:46 step:36370 [D loss: 0.153605, acc: 96.88%] [G loss: 5.544720]\n",
      "epoch:46 step:36371 [D loss: 0.112819, acc: 99.22%] [G loss: 2.356931]\n",
      "epoch:46 step:36372 [D loss: 0.041549, acc: 100.00%] [G loss: 6.831144]\n",
      "epoch:46 step:36373 [D loss: 1.657343, acc: 16.41%] [G loss: 9.108906]\n",
      "epoch:46 step:36374 [D loss: 0.211449, acc: 98.44%] [G loss: 7.697068]\n",
      "epoch:46 step:36375 [D loss: 0.200686, acc: 96.88%] [G loss: 6.562160]\n",
      "epoch:46 step:36376 [D loss: 0.148833, acc: 98.44%] [G loss: 3.031864]\n",
      "epoch:46 step:36377 [D loss: 0.476205, acc: 65.62%] [G loss: 10.143114]\n",
      "epoch:46 step:36378 [D loss: 0.535241, acc: 65.62%] [G loss: 4.980115]\n",
      "epoch:46 step:36379 [D loss: 0.247648, acc: 96.88%] [G loss: 10.715080]\n",
      "epoch:46 step:36380 [D loss: 0.072184, acc: 100.00%] [G loss: 3.557262]\n",
      "epoch:46 step:36381 [D loss: 0.050550, acc: 100.00%] [G loss: 4.626749]\n",
      "epoch:46 step:36382 [D loss: 0.093308, acc: 98.44%] [G loss: 9.940783]\n",
      "epoch:46 step:36383 [D loss: 1.251477, acc: 50.00%] [G loss: 2.625709]\n",
      "epoch:46 step:36384 [D loss: 0.264511, acc: 89.06%] [G loss: 6.177221]\n",
      "epoch:46 step:36385 [D loss: 0.882411, acc: 53.12%] [G loss: 6.891495]\n",
      "epoch:46 step:36386 [D loss: 2.559564, acc: 17.19%] [G loss: 5.898087]\n",
      "epoch:46 step:36387 [D loss: 0.494533, acc: 63.28%] [G loss: 8.358183]\n",
      "epoch:46 step:36388 [D loss: 0.011619, acc: 100.00%] [G loss: 4.994961]\n",
      "epoch:46 step:36389 [D loss: 0.428457, acc: 67.97%] [G loss: 8.263720]\n",
      "epoch:46 step:36390 [D loss: 0.393987, acc: 78.91%] [G loss: 7.453277]\n",
      "epoch:46 step:36391 [D loss: 0.111624, acc: 98.44%] [G loss: 3.613878]\n",
      "epoch:46 step:36392 [D loss: 0.090141, acc: 99.22%] [G loss: 6.964687]\n",
      "epoch:46 step:36393 [D loss: 0.146717, acc: 99.22%] [G loss: 4.466933]\n",
      "epoch:46 step:36394 [D loss: 0.766065, acc: 53.12%] [G loss: 2.897161]\n",
      "epoch:46 step:36395 [D loss: 0.562776, acc: 61.72%] [G loss: 4.045772]\n",
      "epoch:46 step:36396 [D loss: 0.158293, acc: 97.66%] [G loss: 4.331238]\n",
      "epoch:46 step:36397 [D loss: 0.887260, acc: 51.56%] [G loss: 8.753458]\n",
      "epoch:46 step:36398 [D loss: 0.162670, acc: 98.44%] [G loss: 6.606441]\n",
      "epoch:46 step:36399 [D loss: 0.143935, acc: 97.66%] [G loss: 6.318212]\n",
      "epoch:46 step:36400 [D loss: 0.213872, acc: 93.75%] [G loss: 5.882551]\n",
      "##############\n",
      "[0.85412956 0.83867624 0.84645913 0.81802964 0.78678987 0.81210972\n",
      " 0.89147877 0.81946885 0.80881497 0.82465088]\n",
      "##########\n",
      "epoch:46 step:36401 [D loss: 0.060343, acc: 100.00%] [G loss: 3.319741]\n",
      "epoch:46 step:36402 [D loss: 1.061614, acc: 50.00%] [G loss: 6.542418]\n",
      "epoch:46 step:36403 [D loss: 0.196635, acc: 97.66%] [G loss: 6.789097]\n",
      "epoch:46 step:36404 [D loss: 0.041481, acc: 100.00%] [G loss: 7.622937]\n",
      "epoch:46 step:36405 [D loss: 0.795260, acc: 53.12%] [G loss: 7.201483]\n",
      "epoch:46 step:36406 [D loss: 0.176091, acc: 99.22%] [G loss: 2.195507]\n",
      "epoch:46 step:36407 [D loss: 0.215440, acc: 96.09%] [G loss: 6.847473]\n",
      "epoch:46 step:36408 [D loss: 0.112649, acc: 99.22%] [G loss: 4.518441]\n",
      "epoch:46 step:36409 [D loss: 0.251813, acc: 92.19%] [G loss: 5.788428]\n",
      "epoch:46 step:36410 [D loss: 0.043864, acc: 100.00%] [G loss: 5.118868]\n",
      "epoch:46 step:36411 [D loss: 0.049550, acc: 100.00%] [G loss: 7.073405]\n",
      "epoch:46 step:36412 [D loss: 2.351142, acc: 3.12%] [G loss: 5.902280]\n",
      "epoch:46 step:36413 [D loss: 0.215486, acc: 93.75%] [G loss: 6.135999]\n",
      "epoch:46 step:36414 [D loss: 0.157555, acc: 97.66%] [G loss: 8.366974]\n",
      "epoch:46 step:36415 [D loss: 0.041566, acc: 100.00%] [G loss: 6.062730]\n",
      "epoch:46 step:36416 [D loss: 0.005653, acc: 100.00%] [G loss: 10.628699]\n",
      "epoch:46 step:36417 [D loss: 0.059206, acc: 100.00%] [G loss: 4.468729]\n",
      "epoch:46 step:36418 [D loss: 0.069060, acc: 99.22%] [G loss: 9.239584]\n",
      "epoch:46 step:36419 [D loss: 0.539455, acc: 60.94%] [G loss: 9.572577]\n",
      "epoch:46 step:36420 [D loss: 0.035821, acc: 100.00%] [G loss: 7.221300]\n",
      "epoch:46 step:36421 [D loss: 0.317500, acc: 82.81%] [G loss: 6.620491]\n",
      "epoch:46 step:36422 [D loss: 0.254263, acc: 92.97%] [G loss: 6.024311]\n",
      "epoch:46 step:36423 [D loss: 0.815978, acc: 50.78%] [G loss: 12.359783]\n",
      "epoch:46 step:36424 [D loss: 0.182533, acc: 98.44%] [G loss: 3.373790]\n",
      "epoch:46 step:36425 [D loss: 0.270609, acc: 91.41%] [G loss: 7.296233]\n",
      "epoch:46 step:36426 [D loss: 0.011619, acc: 100.00%] [G loss: 6.695204]\n",
      "epoch:46 step:36427 [D loss: 0.187691, acc: 97.66%] [G loss: 4.202949]\n",
      "epoch:46 step:36428 [D loss: 0.027971, acc: 100.00%] [G loss: 4.233159]\n",
      "epoch:46 step:36429 [D loss: 0.163353, acc: 96.88%] [G loss: 5.893173]\n",
      "epoch:46 step:36430 [D loss: 0.824135, acc: 54.69%] [G loss: 4.689324]\n",
      "epoch:46 step:36431 [D loss: 0.783756, acc: 57.03%] [G loss: 7.432554]\n",
      "epoch:46 step:36432 [D loss: 0.037093, acc: 100.00%] [G loss: 5.696130]\n",
      "epoch:46 step:36433 [D loss: 0.348698, acc: 81.25%] [G loss: 3.207101]\n",
      "epoch:46 step:36434 [D loss: 0.165453, acc: 98.44%] [G loss: 6.892395]\n",
      "epoch:46 step:36435 [D loss: 0.121524, acc: 99.22%] [G loss: 6.220120]\n",
      "epoch:46 step:36436 [D loss: 0.171030, acc: 95.31%] [G loss: 5.456491]\n",
      "epoch:46 step:36437 [D loss: 0.052940, acc: 100.00%] [G loss: 13.290066]\n",
      "epoch:46 step:36438 [D loss: 0.073253, acc: 100.00%] [G loss: 2.857374]\n",
      "epoch:46 step:36439 [D loss: 0.218353, acc: 93.75%] [G loss: 5.340782]\n",
      "epoch:46 step:36440 [D loss: 0.530505, acc: 65.62%] [G loss: 8.371132]\n",
      "epoch:46 step:36441 [D loss: 0.126467, acc: 99.22%] [G loss: 5.032281]\n",
      "epoch:46 step:36442 [D loss: 0.101839, acc: 99.22%] [G loss: 6.540489]\n",
      "epoch:46 step:36443 [D loss: 0.193661, acc: 91.41%] [G loss: 9.067430]\n",
      "epoch:46 step:36444 [D loss: 0.051986, acc: 100.00%] [G loss: 5.385337]\n",
      "epoch:46 step:36445 [D loss: 0.145441, acc: 96.09%] [G loss: 5.231371]\n",
      "epoch:46 step:36446 [D loss: 0.106786, acc: 99.22%] [G loss: 7.044608]\n",
      "epoch:46 step:36447 [D loss: 0.844374, acc: 50.78%] [G loss: 5.167064]\n",
      "epoch:46 step:36448 [D loss: 0.774776, acc: 53.12%] [G loss: 10.368413]\n",
      "epoch:46 step:36449 [D loss: 0.218523, acc: 95.31%] [G loss: 5.378878]\n",
      "epoch:46 step:36450 [D loss: 0.612483, acc: 65.62%] [G loss: 7.457776]\n",
      "epoch:46 step:36451 [D loss: 0.112344, acc: 99.22%] [G loss: 5.378400]\n",
      "epoch:46 step:36452 [D loss: 0.635250, acc: 67.19%] [G loss: 10.129300]\n",
      "epoch:46 step:36453 [D loss: 0.662730, acc: 58.59%] [G loss: 8.084666]\n",
      "epoch:46 step:36454 [D loss: 0.412463, acc: 75.00%] [G loss: 3.856365]\n",
      "epoch:46 step:36455 [D loss: 0.203910, acc: 92.97%] [G loss: 5.958675]\n",
      "epoch:46 step:36456 [D loss: 0.377853, acc: 82.81%] [G loss: 6.051953]\n",
      "epoch:46 step:36457 [D loss: 1.439546, acc: 28.91%] [G loss: 7.140570]\n",
      "epoch:46 step:36458 [D loss: 0.154214, acc: 97.66%] [G loss: 5.402133]\n",
      "epoch:46 step:36459 [D loss: 0.009528, acc: 100.00%] [G loss: 7.464102]\n",
      "epoch:46 step:36460 [D loss: 0.078056, acc: 99.22%] [G loss: 8.461266]\n",
      "epoch:46 step:36461 [D loss: 1.297078, acc: 48.44%] [G loss: 7.670614]\n",
      "epoch:46 step:36462 [D loss: 1.501833, acc: 50.00%] [G loss: 5.910831]\n",
      "epoch:46 step:36463 [D loss: 0.037673, acc: 100.00%] [G loss: 5.749530]\n",
      "epoch:46 step:36464 [D loss: 0.297752, acc: 85.94%] [G loss: 5.406505]\n",
      "epoch:46 step:36465 [D loss: 0.294255, acc: 94.53%] [G loss: 5.657389]\n",
      "epoch:46 step:36466 [D loss: 0.223759, acc: 92.19%] [G loss: 5.881007]\n",
      "epoch:46 step:36467 [D loss: 0.172332, acc: 96.09%] [G loss: 8.865950]\n",
      "epoch:46 step:36468 [D loss: 0.154079, acc: 99.22%] [G loss: 9.857790]\n",
      "epoch:46 step:36469 [D loss: 0.045194, acc: 100.00%] [G loss: 8.933260]\n",
      "epoch:46 step:36470 [D loss: 0.187895, acc: 97.66%] [G loss: 6.630978]\n",
      "epoch:46 step:36471 [D loss: 0.307913, acc: 90.62%] [G loss: 6.207890]\n",
      "epoch:46 step:36472 [D loss: 0.335865, acc: 81.25%] [G loss: 4.231620]\n",
      "epoch:46 step:36473 [D loss: 0.012770, acc: 100.00%] [G loss: 6.574921]\n",
      "epoch:46 step:36474 [D loss: 0.209681, acc: 95.31%] [G loss: 5.326789]\n",
      "epoch:46 step:36475 [D loss: 0.600751, acc: 58.59%] [G loss: 2.755493]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:46 step:36476 [D loss: 0.276981, acc: 92.97%] [G loss: 9.309380]\n",
      "epoch:46 step:36477 [D loss: 0.135790, acc: 98.44%] [G loss: 5.845015]\n",
      "epoch:46 step:36478 [D loss: 0.707634, acc: 57.81%] [G loss: 7.802599]\n",
      "epoch:46 step:36479 [D loss: 0.142972, acc: 98.44%] [G loss: 9.021231]\n",
      "epoch:46 step:36480 [D loss: 0.362082, acc: 77.34%] [G loss: 4.004477]\n",
      "epoch:46 step:36481 [D loss: 0.430696, acc: 67.97%] [G loss: 9.301313]\n",
      "epoch:46 step:36482 [D loss: 0.870174, acc: 41.41%] [G loss: 9.482041]\n",
      "epoch:46 step:36483 [D loss: 0.511916, acc: 77.34%] [G loss: 11.207077]\n",
      "epoch:46 step:36484 [D loss: 0.649804, acc: 62.50%] [G loss: 7.701191]\n",
      "epoch:46 step:36485 [D loss: 0.162657, acc: 98.44%] [G loss: 9.565430]\n",
      "epoch:46 step:36486 [D loss: 0.019103, acc: 100.00%] [G loss: 8.351648]\n",
      "epoch:46 step:36487 [D loss: 0.122702, acc: 99.22%] [G loss: 6.695220]\n",
      "epoch:46 step:36488 [D loss: 0.687460, acc: 61.72%] [G loss: 8.260870]\n",
      "epoch:46 step:36489 [D loss: 0.595046, acc: 64.06%] [G loss: 5.950551]\n",
      "epoch:46 step:36490 [D loss: 0.286407, acc: 92.97%] [G loss: 7.482967]\n",
      "epoch:46 step:36491 [D loss: 0.254730, acc: 95.31%] [G loss: 5.365831]\n",
      "epoch:46 step:36492 [D loss: 0.122209, acc: 98.44%] [G loss: 8.000963]\n",
      "epoch:46 step:36493 [D loss: 1.159718, acc: 16.41%] [G loss: 10.499308]\n",
      "epoch:46 step:36494 [D loss: 0.165376, acc: 100.00%] [G loss: 5.957341]\n",
      "epoch:46 step:36495 [D loss: 0.070018, acc: 98.44%] [G loss: 10.096436]\n",
      "epoch:46 step:36496 [D loss: 0.410803, acc: 75.78%] [G loss: 5.604646]\n",
      "epoch:46 step:36497 [D loss: 0.401750, acc: 83.59%] [G loss: 10.268215]\n",
      "epoch:46 step:36498 [D loss: 0.022488, acc: 100.00%] [G loss: 4.596893]\n",
      "epoch:46 step:36499 [D loss: 0.194097, acc: 99.22%] [G loss: 7.717578]\n",
      "epoch:46 step:36500 [D loss: 0.056282, acc: 100.00%] [G loss: 6.213550]\n",
      "epoch:46 step:36501 [D loss: 0.076732, acc: 100.00%] [G loss: 7.995059]\n",
      "epoch:46 step:36502 [D loss: 0.097072, acc: 99.22%] [G loss: 6.321489]\n",
      "epoch:46 step:36503 [D loss: 0.452384, acc: 68.75%] [G loss: 4.985490]\n",
      "epoch:46 step:36504 [D loss: 0.071041, acc: 99.22%] [G loss: 3.521996]\n",
      "epoch:46 step:36505 [D loss: 0.206496, acc: 96.88%] [G loss: 5.718913]\n",
      "epoch:46 step:36506 [D loss: 1.945452, acc: 14.84%] [G loss: 6.799951]\n",
      "epoch:46 step:36507 [D loss: 0.158095, acc: 100.00%] [G loss: 4.653791]\n",
      "epoch:46 step:36508 [D loss: 0.502191, acc: 67.19%] [G loss: 7.485441]\n",
      "epoch:46 step:36509 [D loss: 0.095860, acc: 100.00%] [G loss: 10.787005]\n",
      "epoch:46 step:36510 [D loss: 0.692846, acc: 53.91%] [G loss: 4.191224]\n",
      "epoch:46 step:36511 [D loss: 0.679847, acc: 61.72%] [G loss: 6.825689]\n",
      "epoch:46 step:36512 [D loss: 0.192505, acc: 96.88%] [G loss: 8.458314]\n",
      "epoch:46 step:36513 [D loss: 0.154334, acc: 99.22%] [G loss: 7.983768]\n",
      "epoch:46 step:36514 [D loss: 0.279676, acc: 87.50%] [G loss: 5.445986]\n",
      "epoch:46 step:36515 [D loss: 0.567200, acc: 57.81%] [G loss: 4.708109]\n",
      "epoch:46 step:36516 [D loss: 0.412827, acc: 75.00%] [G loss: 8.603006]\n",
      "epoch:46 step:36517 [D loss: 0.117738, acc: 97.66%] [G loss: 6.643785]\n",
      "epoch:46 step:36518 [D loss: 0.304371, acc: 85.16%] [G loss: 3.825468]\n",
      "epoch:46 step:36519 [D loss: 0.013806, acc: 100.00%] [G loss: 11.373873]\n",
      "epoch:46 step:36520 [D loss: 0.274897, acc: 94.53%] [G loss: 6.655305]\n",
      "epoch:46 step:36521 [D loss: 1.044112, acc: 50.78%] [G loss: 8.058426]\n",
      "epoch:46 step:36522 [D loss: 0.011064, acc: 100.00%] [G loss: 6.885205]\n",
      "epoch:46 step:36523 [D loss: 0.608080, acc: 58.59%] [G loss: 9.873043]\n",
      "epoch:46 step:36524 [D loss: 0.289539, acc: 92.97%] [G loss: 5.219841]\n",
      "epoch:46 step:36525 [D loss: 0.080964, acc: 100.00%] [G loss: 8.275813]\n",
      "epoch:46 step:36526 [D loss: 0.072152, acc: 99.22%] [G loss: 6.825637]\n",
      "epoch:46 step:36527 [D loss: 0.114047, acc: 98.44%] [G loss: 8.485353]\n",
      "epoch:46 step:36528 [D loss: 0.152608, acc: 98.44%] [G loss: 5.892729]\n",
      "epoch:46 step:36529 [D loss: 0.926417, acc: 51.56%] [G loss: 6.274933]\n",
      "epoch:46 step:36530 [D loss: 0.091334, acc: 99.22%] [G loss: 6.785180]\n",
      "epoch:46 step:36531 [D loss: 0.194032, acc: 96.09%] [G loss: 5.709077]\n",
      "epoch:46 step:36532 [D loss: 0.583751, acc: 67.19%] [G loss: 6.354144]\n",
      "epoch:46 step:36533 [D loss: 0.130794, acc: 98.44%] [G loss: 5.697462]\n",
      "epoch:46 step:36534 [D loss: 0.107683, acc: 100.00%] [G loss: 2.834321]\n",
      "epoch:46 step:36535 [D loss: 0.397419, acc: 89.06%] [G loss: 9.501961]\n",
      "epoch:46 step:36536 [D loss: 0.118983, acc: 100.00%] [G loss: 5.167170]\n",
      "epoch:46 step:36537 [D loss: 0.200174, acc: 93.75%] [G loss: 6.576264]\n",
      "epoch:46 step:36538 [D loss: 0.306264, acc: 91.41%] [G loss: 5.356538]\n",
      "epoch:46 step:36539 [D loss: 0.699933, acc: 56.25%] [G loss: 7.990693]\n",
      "epoch:46 step:36540 [D loss: 0.011667, acc: 100.00%] [G loss: 9.114601]\n",
      "epoch:46 step:36541 [D loss: 0.092442, acc: 100.00%] [G loss: 6.507686]\n",
      "epoch:46 step:36542 [D loss: 0.225590, acc: 93.75%] [G loss: 8.647750]\n",
      "epoch:46 step:36543 [D loss: 0.203003, acc: 96.09%] [G loss: 2.285038]\n",
      "epoch:46 step:36544 [D loss: 0.051346, acc: 100.00%] [G loss: 5.573566]\n",
      "epoch:46 step:36545 [D loss: 0.818702, acc: 46.88%] [G loss: 7.088914]\n",
      "epoch:46 step:36546 [D loss: 0.390578, acc: 77.34%] [G loss: 2.779300]\n",
      "epoch:46 step:36547 [D loss: 0.133009, acc: 98.44%] [G loss: 7.859061]\n",
      "epoch:46 step:36548 [D loss: 0.692103, acc: 57.03%] [G loss: 8.675484]\n",
      "epoch:46 step:36549 [D loss: 0.153722, acc: 97.66%] [G loss: 4.925127]\n",
      "epoch:46 step:36550 [D loss: 0.133284, acc: 98.44%] [G loss: 9.678176]\n",
      "epoch:46 step:36551 [D loss: 0.028802, acc: 100.00%] [G loss: 7.893418]\n",
      "epoch:46 step:36552 [D loss: 0.215284, acc: 97.66%] [G loss: 3.047776]\n",
      "epoch:46 step:36553 [D loss: 0.515930, acc: 71.09%] [G loss: 4.714619]\n",
      "epoch:46 step:36554 [D loss: 0.800809, acc: 57.03%] [G loss: 7.209553]\n",
      "epoch:46 step:36555 [D loss: 0.167582, acc: 99.22%] [G loss: 8.900161]\n",
      "epoch:46 step:36556 [D loss: 0.010529, acc: 100.00%] [G loss: 8.361251]\n",
      "epoch:46 step:36557 [D loss: 0.012726, acc: 100.00%] [G loss: 6.828077]\n",
      "epoch:46 step:36558 [D loss: 0.123480, acc: 98.44%] [G loss: 7.015493]\n",
      "epoch:46 step:36559 [D loss: 0.098825, acc: 100.00%] [G loss: 7.486689]\n",
      "epoch:46 step:36560 [D loss: 0.423323, acc: 75.78%] [G loss: 4.455841]\n",
      "epoch:46 step:36561 [D loss: 0.539027, acc: 69.53%] [G loss: 10.705972]\n",
      "epoch:46 step:36562 [D loss: 0.076371, acc: 99.22%] [G loss: 6.276158]\n",
      "epoch:46 step:36563 [D loss: 0.217086, acc: 97.66%] [G loss: 4.126686]\n",
      "epoch:46 step:36564 [D loss: 0.731579, acc: 60.16%] [G loss: 7.509997]\n",
      "epoch:46 step:36565 [D loss: 0.396442, acc: 75.00%] [G loss: 9.859266]\n",
      "epoch:46 step:36566 [D loss: 0.411458, acc: 78.12%] [G loss: 7.887685]\n",
      "epoch:46 step:36567 [D loss: 0.331642, acc: 78.91%] [G loss: 5.271785]\n",
      "epoch:46 step:36568 [D loss: 0.457300, acc: 76.56%] [G loss: 7.644459]\n",
      "epoch:46 step:36569 [D loss: 0.164358, acc: 97.66%] [G loss: 4.560124]\n",
      "epoch:46 step:36570 [D loss: 0.152929, acc: 96.88%] [G loss: 6.908988]\n",
      "epoch:46 step:36571 [D loss: 0.111581, acc: 98.44%] [G loss: 6.760195]\n",
      "epoch:46 step:36572 [D loss: 0.120174, acc: 100.00%] [G loss: 7.522380]\n",
      "epoch:46 step:36573 [D loss: 0.129204, acc: 99.22%] [G loss: 6.911732]\n",
      "epoch:46 step:36574 [D loss: 0.435703, acc: 77.34%] [G loss: 10.754468]\n",
      "epoch:46 step:36575 [D loss: 0.086839, acc: 100.00%] [G loss: 7.330103]\n",
      "epoch:46 step:36576 [D loss: 0.009402, acc: 100.00%] [G loss: 9.362167]\n",
      "epoch:46 step:36577 [D loss: 0.062927, acc: 100.00%] [G loss: 5.128996]\n",
      "epoch:46 step:36578 [D loss: 0.116823, acc: 99.22%] [G loss: 5.539515]\n",
      "epoch:46 step:36579 [D loss: 0.114891, acc: 99.22%] [G loss: 7.360806]\n",
      "epoch:46 step:36580 [D loss: 0.106773, acc: 99.22%] [G loss: 6.874895]\n",
      "epoch:46 step:36581 [D loss: 0.173346, acc: 96.09%] [G loss: 1.980877]\n",
      "epoch:46 step:36582 [D loss: 0.201053, acc: 97.66%] [G loss: 5.044686]\n",
      "epoch:46 step:36583 [D loss: 0.159228, acc: 96.88%] [G loss: 4.673879]\n",
      "epoch:46 step:36584 [D loss: 0.204301, acc: 96.09%] [G loss: 2.751130]\n",
      "epoch:46 step:36585 [D loss: 0.046358, acc: 100.00%] [G loss: 5.556358]\n",
      "epoch:46 step:36586 [D loss: 0.601866, acc: 66.41%] [G loss: 7.113156]\n",
      "epoch:46 step:36587 [D loss: 0.024972, acc: 100.00%] [G loss: 7.245973]\n",
      "epoch:46 step:36588 [D loss: 0.034094, acc: 100.00%] [G loss: 8.071719]\n",
      "epoch:46 step:36589 [D loss: 0.110192, acc: 100.00%] [G loss: 3.593765]\n",
      "epoch:46 step:36590 [D loss: 0.071170, acc: 100.00%] [G loss: 6.607099]\n",
      "epoch:46 step:36591 [D loss: 0.435895, acc: 84.38%] [G loss: 4.174978]\n",
      "epoch:46 step:36592 [D loss: 0.064717, acc: 100.00%] [G loss: 4.290597]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:46 step:36593 [D loss: 0.093374, acc: 100.00%] [G loss: 7.732137]\n",
      "epoch:46 step:36594 [D loss: 0.746360, acc: 57.03%] [G loss: 4.138069]\n",
      "epoch:46 step:36595 [D loss: 0.069364, acc: 100.00%] [G loss: 7.065967]\n",
      "epoch:46 step:36596 [D loss: 0.455983, acc: 67.97%] [G loss: 8.053658]\n",
      "epoch:46 step:36597 [D loss: 0.540621, acc: 63.28%] [G loss: 4.256178]\n",
      "epoch:46 step:36598 [D loss: 0.476776, acc: 67.97%] [G loss: 10.194771]\n",
      "epoch:46 step:36599 [D loss: 0.078116, acc: 100.00%] [G loss: 9.163075]\n",
      "epoch:46 step:36600 [D loss: 0.516726, acc: 77.34%] [G loss: 7.168838]\n",
      "##############\n",
      "[0.86081704 0.8780125  0.81113058 0.81127355 0.78679014 0.83631413\n",
      " 0.87822754 0.83954861 0.81947074 0.81343211]\n",
      "##########\n",
      "epoch:46 step:36601 [D loss: 0.095084, acc: 99.22%] [G loss: 6.260042]\n",
      "epoch:46 step:36602 [D loss: 0.035162, acc: 99.22%] [G loss: 6.577138]\n",
      "epoch:46 step:36603 [D loss: 0.056300, acc: 100.00%] [G loss: 5.843848]\n",
      "epoch:46 step:36604 [D loss: 0.042823, acc: 100.00%] [G loss: 5.780455]\n",
      "epoch:46 step:36605 [D loss: 0.100041, acc: 100.00%] [G loss: 8.040154]\n",
      "epoch:46 step:36606 [D loss: 0.244574, acc: 96.09%] [G loss: 4.340048]\n",
      "epoch:46 step:36607 [D loss: 0.109984, acc: 98.44%] [G loss: 4.218103]\n",
      "epoch:46 step:36608 [D loss: 0.463005, acc: 71.88%] [G loss: 7.325188]\n",
      "epoch:46 step:36609 [D loss: 0.528522, acc: 71.09%] [G loss: 5.743822]\n",
      "epoch:46 step:36610 [D loss: 0.587254, acc: 63.28%] [G loss: 8.519961]\n",
      "epoch:46 step:36611 [D loss: 0.175709, acc: 96.09%] [G loss: 3.703512]\n",
      "epoch:46 step:36612 [D loss: 0.073836, acc: 100.00%] [G loss: 7.413988]\n",
      "epoch:46 step:36613 [D loss: 0.058245, acc: 100.00%] [G loss: 3.993172]\n",
      "epoch:46 step:36614 [D loss: 0.073466, acc: 99.22%] [G loss: 9.238626]\n",
      "epoch:46 step:36615 [D loss: 0.063788, acc: 100.00%] [G loss: 9.495891]\n",
      "epoch:46 step:36616 [D loss: 0.024112, acc: 100.00%] [G loss: 7.678146]\n",
      "epoch:46 step:36617 [D loss: 0.145589, acc: 96.88%] [G loss: 6.328863]\n",
      "epoch:46 step:36618 [D loss: 0.238321, acc: 90.62%] [G loss: 7.189078]\n",
      "epoch:46 step:36619 [D loss: 0.815480, acc: 52.34%] [G loss: 11.572076]\n",
      "epoch:46 step:36620 [D loss: 0.838036, acc: 46.88%] [G loss: 4.367566]\n",
      "epoch:46 step:36621 [D loss: 0.050405, acc: 100.00%] [G loss: 6.565402]\n",
      "epoch:46 step:36622 [D loss: 0.245198, acc: 92.19%] [G loss: 6.539971]\n",
      "epoch:46 step:36623 [D loss: 0.239130, acc: 95.31%] [G loss: 5.912483]\n",
      "epoch:46 step:36624 [D loss: 0.017208, acc: 99.22%] [G loss: 8.027025]\n",
      "epoch:46 step:36625 [D loss: 0.251929, acc: 92.97%] [G loss: 2.264712]\n",
      "epoch:46 step:36626 [D loss: 0.215141, acc: 96.88%] [G loss: 4.341023]\n",
      "epoch:46 step:36627 [D loss: 0.071854, acc: 100.00%] [G loss: 5.404358]\n",
      "epoch:46 step:36628 [D loss: 0.224943, acc: 94.53%] [G loss: 9.487482]\n",
      "epoch:46 step:36629 [D loss: 0.018637, acc: 100.00%] [G loss: 3.307817]\n",
      "epoch:46 step:36630 [D loss: 1.583814, acc: 50.00%] [G loss: 5.160634]\n",
      "epoch:46 step:36631 [D loss: 0.055742, acc: 100.00%] [G loss: 4.639183]\n",
      "epoch:46 step:36632 [D loss: 0.856598, acc: 53.91%] [G loss: 10.632370]\n",
      "epoch:46 step:36633 [D loss: 0.131490, acc: 97.66%] [G loss: 7.472295]\n",
      "epoch:46 step:36634 [D loss: 0.078495, acc: 100.00%] [G loss: 7.097980]\n",
      "epoch:46 step:36635 [D loss: 0.054411, acc: 100.00%] [G loss: 6.097816]\n",
      "epoch:46 step:36636 [D loss: 0.296082, acc: 86.72%] [G loss: 7.210877]\n",
      "epoch:46 step:36637 [D loss: 0.585935, acc: 58.59%] [G loss: 5.925408]\n",
      "epoch:46 step:36638 [D loss: 0.108873, acc: 98.44%] [G loss: 5.967454]\n",
      "epoch:46 step:36639 [D loss: 0.066485, acc: 100.00%] [G loss: 2.284060]\n",
      "epoch:46 step:36640 [D loss: 0.774236, acc: 51.56%] [G loss: 8.626030]\n",
      "epoch:46 step:36641 [D loss: 0.456098, acc: 71.88%] [G loss: 8.464426]\n",
      "epoch:46 step:36642 [D loss: 0.290359, acc: 84.38%] [G loss: 8.737781]\n",
      "epoch:46 step:36643 [D loss: 0.222616, acc: 96.88%] [G loss: 9.571151]\n",
      "epoch:46 step:36644 [D loss: 0.007567, acc: 100.00%] [G loss: 7.205581]\n",
      "epoch:46 step:36645 [D loss: 0.076418, acc: 100.00%] [G loss: 2.963695]\n",
      "epoch:46 step:36646 [D loss: 0.142954, acc: 99.22%] [G loss: 8.159165]\n",
      "epoch:46 step:36647 [D loss: 0.106643, acc: 100.00%] [G loss: 10.371807]\n",
      "epoch:46 step:36648 [D loss: 0.041620, acc: 100.00%] [G loss: 8.019197]\n",
      "epoch:46 step:36649 [D loss: 0.140074, acc: 97.66%] [G loss: 8.270165]\n",
      "epoch:46 step:36650 [D loss: 0.132625, acc: 98.44%] [G loss: 6.077177]\n",
      "epoch:46 step:36651 [D loss: 0.047382, acc: 100.00%] [G loss: 6.168219]\n",
      "epoch:46 step:36652 [D loss: 0.357882, acc: 79.69%] [G loss: 9.054594]\n",
      "epoch:46 step:36653 [D loss: 0.132380, acc: 97.66%] [G loss: 6.939766]\n",
      "epoch:46 step:36654 [D loss: 0.126631, acc: 99.22%] [G loss: 3.184308]\n",
      "epoch:46 step:36655 [D loss: 0.175252, acc: 98.44%] [G loss: 5.660941]\n",
      "epoch:46 step:36656 [D loss: 0.227115, acc: 96.88%] [G loss: 6.442914]\n",
      "epoch:46 step:36657 [D loss: 0.293439, acc: 92.19%] [G loss: 5.854354]\n",
      "epoch:46 step:36658 [D loss: 0.631245, acc: 60.16%] [G loss: 6.330268]\n",
      "epoch:46 step:36659 [D loss: 0.322827, acc: 85.94%] [G loss: 6.041480]\n",
      "epoch:46 step:36660 [D loss: 1.243353, acc: 50.00%] [G loss: 4.665845]\n",
      "epoch:46 step:36661 [D loss: 0.070152, acc: 100.00%] [G loss: 12.147945]\n",
      "epoch:46 step:36662 [D loss: 0.118180, acc: 97.66%] [G loss: 10.665052]\n",
      "epoch:46 step:36663 [D loss: 0.051514, acc: 100.00%] [G loss: 3.442778]\n",
      "epoch:46 step:36664 [D loss: 0.399474, acc: 71.09%] [G loss: 8.175270]\n",
      "epoch:46 step:36665 [D loss: 0.115648, acc: 100.00%] [G loss: 7.770744]\n",
      "epoch:46 step:36666 [D loss: 0.170586, acc: 96.09%] [G loss: 6.450916]\n",
      "epoch:46 step:36667 [D loss: 0.126490, acc: 100.00%] [G loss: 5.360889]\n",
      "epoch:46 step:36668 [D loss: 0.165918, acc: 100.00%] [G loss: 3.796769]\n",
      "epoch:46 step:36669 [D loss: 0.336278, acc: 92.19%] [G loss: 8.515376]\n",
      "epoch:46 step:36670 [D loss: 0.367447, acc: 85.94%] [G loss: 5.089844]\n",
      "epoch:46 step:36671 [D loss: 0.352966, acc: 77.34%] [G loss: 5.552054]\n",
      "epoch:46 step:36672 [D loss: 0.400003, acc: 81.25%] [G loss: 4.814560]\n",
      "epoch:46 step:36673 [D loss: 0.209967, acc: 94.53%] [G loss: 8.066664]\n",
      "epoch:46 step:36674 [D loss: 0.402010, acc: 73.44%] [G loss: 5.669328]\n",
      "epoch:46 step:36675 [D loss: 0.166517, acc: 96.88%] [G loss: 4.532936]\n",
      "epoch:46 step:36676 [D loss: 0.166068, acc: 97.66%] [G loss: 4.180980]\n",
      "epoch:46 step:36677 [D loss: 0.730944, acc: 55.47%] [G loss: 3.524672]\n",
      "epoch:46 step:36678 [D loss: 0.136266, acc: 96.88%] [G loss: 7.183712]\n",
      "epoch:46 step:36679 [D loss: 0.278940, acc: 88.28%] [G loss: 5.229415]\n",
      "epoch:46 step:36680 [D loss: 0.093551, acc: 99.22%] [G loss: 7.350827]\n",
      "epoch:46 step:36681 [D loss: 0.240897, acc: 95.31%] [G loss: 5.136199]\n",
      "epoch:46 step:36682 [D loss: 0.846940, acc: 51.56%] [G loss: 3.778606]\n",
      "epoch:46 step:36683 [D loss: 0.303933, acc: 83.59%] [G loss: 8.183397]\n",
      "epoch:46 step:36684 [D loss: 0.076238, acc: 100.00%] [G loss: 10.955822]\n",
      "epoch:46 step:36685 [D loss: 0.106959, acc: 99.22%] [G loss: 5.108477]\n",
      "epoch:46 step:36686 [D loss: 0.129682, acc: 97.66%] [G loss: 9.975042]\n",
      "epoch:46 step:36687 [D loss: 0.925360, acc: 39.06%] [G loss: 6.854994]\n",
      "epoch:46 step:36688 [D loss: 0.125645, acc: 99.22%] [G loss: 2.624365]\n",
      "epoch:46 step:36689 [D loss: 0.993050, acc: 39.06%] [G loss: 8.051775]\n",
      "epoch:46 step:36690 [D loss: 0.023370, acc: 100.00%] [G loss: 6.605556]\n",
      "epoch:46 step:36691 [D loss: 0.706008, acc: 55.47%] [G loss: 10.003167]\n",
      "epoch:46 step:36692 [D loss: 0.206075, acc: 92.97%] [G loss: 2.978912]\n",
      "epoch:46 step:36693 [D loss: 0.081389, acc: 100.00%] [G loss: 7.089200]\n",
      "epoch:46 step:36694 [D loss: 0.185729, acc: 94.53%] [G loss: 6.918468]\n",
      "epoch:46 step:36695 [D loss: 0.146413, acc: 96.88%] [G loss: 7.768088]\n",
      "epoch:46 step:36696 [D loss: 0.671192, acc: 62.50%] [G loss: 8.233829]\n",
      "epoch:46 step:36697 [D loss: 0.203580, acc: 92.97%] [G loss: 7.765254]\n",
      "epoch:46 step:36698 [D loss: 0.057946, acc: 100.00%] [G loss: 9.596752]\n",
      "epoch:46 step:36699 [D loss: 0.023793, acc: 100.00%] [G loss: 8.435879]\n",
      "epoch:46 step:36700 [D loss: 0.007118, acc: 100.00%] [G loss: 8.834698]\n",
      "epoch:46 step:36701 [D loss: 0.164298, acc: 100.00%] [G loss: 4.732611]\n",
      "epoch:46 step:36702 [D loss: 0.126631, acc: 99.22%] [G loss: 6.491665]\n",
      "epoch:46 step:36703 [D loss: 0.761366, acc: 57.03%] [G loss: 5.112797]\n",
      "epoch:46 step:36704 [D loss: 0.077776, acc: 100.00%] [G loss: 3.933918]\n",
      "epoch:46 step:36705 [D loss: 0.680429, acc: 60.94%] [G loss: 6.087647]\n",
      "epoch:46 step:36706 [D loss: 0.454503, acc: 72.66%] [G loss: 5.102377]\n",
      "epoch:46 step:36707 [D loss: 1.711300, acc: 50.00%] [G loss: 5.416057]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:47 step:36708 [D loss: 0.159859, acc: 100.00%] [G loss: 6.873876]\n",
      "epoch:47 step:36709 [D loss: 0.091964, acc: 100.00%] [G loss: 5.067050]\n",
      "epoch:47 step:36710 [D loss: 0.069672, acc: 100.00%] [G loss: 8.263354]\n",
      "epoch:47 step:36711 [D loss: 0.154621, acc: 98.44%] [G loss: 3.206435]\n",
      "epoch:47 step:36712 [D loss: 0.243020, acc: 96.09%] [G loss: 5.661190]\n",
      "epoch:47 step:36713 [D loss: 0.316729, acc: 83.59%] [G loss: 6.819056]\n",
      "epoch:47 step:36714 [D loss: 0.021817, acc: 100.00%] [G loss: 9.605938]\n",
      "epoch:47 step:36715 [D loss: 0.666100, acc: 57.81%] [G loss: 7.865323]\n",
      "epoch:47 step:36716 [D loss: 0.112674, acc: 100.00%] [G loss: 7.770644]\n",
      "epoch:47 step:36717 [D loss: 0.185886, acc: 99.22%] [G loss: 4.523825]\n",
      "epoch:47 step:36718 [D loss: 0.168203, acc: 96.88%] [G loss: 6.752146]\n",
      "epoch:47 step:36719 [D loss: 0.355870, acc: 79.69%] [G loss: 6.797790]\n",
      "epoch:47 step:36720 [D loss: 0.625018, acc: 63.28%] [G loss: 8.469387]\n",
      "epoch:47 step:36721 [D loss: 0.029778, acc: 100.00%] [G loss: 4.554295]\n",
      "epoch:47 step:36722 [D loss: 0.229577, acc: 91.41%] [G loss: 6.479991]\n",
      "epoch:47 step:36723 [D loss: 0.436964, acc: 70.31%] [G loss: 5.821050]\n",
      "epoch:47 step:36724 [D loss: 0.068045, acc: 100.00%] [G loss: 4.874489]\n",
      "epoch:47 step:36725 [D loss: 0.004758, acc: 100.00%] [G loss: 6.688484]\n",
      "epoch:47 step:36726 [D loss: 0.050451, acc: 100.00%] [G loss: 5.784997]\n",
      "epoch:47 step:36727 [D loss: 0.184690, acc: 95.31%] [G loss: 6.383916]\n",
      "epoch:47 step:36728 [D loss: 0.085269, acc: 100.00%] [G loss: 9.979920]\n",
      "epoch:47 step:36729 [D loss: 0.513262, acc: 65.62%] [G loss: 8.024124]\n",
      "epoch:47 step:36730 [D loss: 0.824013, acc: 55.47%] [G loss: 7.635033]\n",
      "epoch:47 step:36731 [D loss: 0.150801, acc: 96.88%] [G loss: 4.909301]\n",
      "epoch:47 step:36732 [D loss: 0.330038, acc: 79.69%] [G loss: 7.470884]\n",
      "epoch:47 step:36733 [D loss: 0.084437, acc: 100.00%] [G loss: 7.510909]\n",
      "epoch:47 step:36734 [D loss: 0.095819, acc: 100.00%] [G loss: 4.879200]\n",
      "epoch:47 step:36735 [D loss: 0.214075, acc: 95.31%] [G loss: 6.077009]\n",
      "epoch:47 step:36736 [D loss: 0.030583, acc: 100.00%] [G loss: 4.672935]\n",
      "epoch:47 step:36737 [D loss: 0.084806, acc: 98.44%] [G loss: 7.777761]\n",
      "epoch:47 step:36738 [D loss: 0.021458, acc: 100.00%] [G loss: 5.309344]\n",
      "epoch:47 step:36739 [D loss: 0.053874, acc: 100.00%] [G loss: 4.884013]\n",
      "epoch:47 step:36740 [D loss: 0.052933, acc: 100.00%] [G loss: 4.757103]\n",
      "epoch:47 step:36741 [D loss: 0.231044, acc: 92.19%] [G loss: 7.145273]\n",
      "epoch:47 step:36742 [D loss: 0.042858, acc: 100.00%] [G loss: 6.134016]\n",
      "epoch:47 step:36743 [D loss: 0.713562, acc: 55.47%] [G loss: 7.989817]\n",
      "epoch:47 step:36744 [D loss: 0.815952, acc: 54.69%] [G loss: 10.119259]\n",
      "epoch:47 step:36745 [D loss: 0.310351, acc: 91.41%] [G loss: 6.669433]\n",
      "epoch:47 step:36746 [D loss: 0.080684, acc: 99.22%] [G loss: 7.992962]\n",
      "epoch:47 step:36747 [D loss: 0.176268, acc: 96.88%] [G loss: 9.680542]\n",
      "epoch:47 step:36748 [D loss: 0.459050, acc: 79.69%] [G loss: 6.257895]\n",
      "epoch:47 step:36749 [D loss: 0.086910, acc: 99.22%] [G loss: 4.396899]\n",
      "epoch:47 step:36750 [D loss: 0.295962, acc: 85.94%] [G loss: 6.160918]\n",
      "epoch:47 step:36751 [D loss: 0.152710, acc: 94.53%] [G loss: 8.716000]\n",
      "epoch:47 step:36752 [D loss: 0.131894, acc: 98.44%] [G loss: 5.620644]\n",
      "epoch:47 step:36753 [D loss: 1.261814, acc: 39.84%] [G loss: 8.976292]\n",
      "epoch:47 step:36754 [D loss: 0.414585, acc: 78.91%] [G loss: 6.266311]\n",
      "epoch:47 step:36755 [D loss: 0.691118, acc: 57.81%] [G loss: 7.908242]\n",
      "epoch:47 step:36756 [D loss: 0.095678, acc: 100.00%] [G loss: 7.317999]\n",
      "epoch:47 step:36757 [D loss: 0.613173, acc: 60.94%] [G loss: 8.617403]\n",
      "epoch:47 step:36758 [D loss: 0.368647, acc: 80.47%] [G loss: 5.409327]\n",
      "epoch:47 step:36759 [D loss: 0.111340, acc: 99.22%] [G loss: 6.945684]\n",
      "epoch:47 step:36760 [D loss: 0.027651, acc: 100.00%] [G loss: 9.946544]\n",
      "epoch:47 step:36761 [D loss: 0.337338, acc: 78.12%] [G loss: 11.060528]\n",
      "epoch:47 step:36762 [D loss: 1.335162, acc: 28.12%] [G loss: 9.027532]\n",
      "epoch:47 step:36763 [D loss: 0.081444, acc: 99.22%] [G loss: 5.446502]\n",
      "epoch:47 step:36764 [D loss: 0.051007, acc: 100.00%] [G loss: 8.281483]\n",
      "epoch:47 step:36765 [D loss: 0.625532, acc: 63.28%] [G loss: 17.635342]\n",
      "epoch:47 step:36766 [D loss: 0.036783, acc: 100.00%] [G loss: 6.183289]\n",
      "epoch:47 step:36767 [D loss: 0.153071, acc: 99.22%] [G loss: 7.948561]\n",
      "epoch:47 step:36768 [D loss: 0.026379, acc: 100.00%] [G loss: 8.056849]\n",
      "epoch:47 step:36769 [D loss: 0.052275, acc: 100.00%] [G loss: 3.756854]\n",
      "epoch:47 step:36770 [D loss: 0.422644, acc: 84.38%] [G loss: 3.531333]\n",
      "epoch:47 step:36771 [D loss: 0.150681, acc: 97.66%] [G loss: 5.490594]\n",
      "epoch:47 step:36772 [D loss: 0.400595, acc: 83.59%] [G loss: 2.328534]\n",
      "epoch:47 step:36773 [D loss: 0.227788, acc: 92.19%] [G loss: 5.368327]\n",
      "epoch:47 step:36774 [D loss: 0.074503, acc: 100.00%] [G loss: 7.237656]\n",
      "epoch:47 step:36775 [D loss: 0.448635, acc: 82.03%] [G loss: 3.903484]\n",
      "epoch:47 step:36776 [D loss: 0.050766, acc: 100.00%] [G loss: 5.645000]\n",
      "epoch:47 step:36777 [D loss: 0.222254, acc: 94.53%] [G loss: 6.493650]\n",
      "epoch:47 step:36778 [D loss: 0.123210, acc: 99.22%] [G loss: 4.390011]\n",
      "epoch:47 step:36779 [D loss: 0.426837, acc: 81.25%] [G loss: 6.323886]\n",
      "epoch:47 step:36780 [D loss: 1.096163, acc: 21.88%] [G loss: 7.257402]\n",
      "epoch:47 step:36781 [D loss: 0.133652, acc: 98.44%] [G loss: 7.719400]\n",
      "epoch:47 step:36782 [D loss: 0.176110, acc: 98.44%] [G loss: 6.162448]\n",
      "epoch:47 step:36783 [D loss: 0.130070, acc: 99.22%] [G loss: 4.328510]\n",
      "epoch:47 step:36784 [D loss: 0.209669, acc: 98.44%] [G loss: 6.984711]\n",
      "epoch:47 step:36785 [D loss: 0.355167, acc: 83.59%] [G loss: 7.873647]\n",
      "epoch:47 step:36786 [D loss: 0.066174, acc: 100.00%] [G loss: 8.467009]\n",
      "epoch:47 step:36787 [D loss: 0.048777, acc: 100.00%] [G loss: 3.397881]\n",
      "epoch:47 step:36788 [D loss: 0.588471, acc: 68.75%] [G loss: 8.023856]\n",
      "epoch:47 step:36789 [D loss: 0.038338, acc: 100.00%] [G loss: 7.743798]\n",
      "epoch:47 step:36790 [D loss: 0.033496, acc: 100.00%] [G loss: 5.317136]\n",
      "epoch:47 step:36791 [D loss: 0.321705, acc: 93.75%] [G loss: 7.597975]\n",
      "epoch:47 step:36792 [D loss: 0.201840, acc: 94.53%] [G loss: 8.602542]\n",
      "epoch:47 step:36793 [D loss: 0.464477, acc: 69.53%] [G loss: 4.569034]\n",
      "epoch:47 step:36794 [D loss: 0.323198, acc: 86.72%] [G loss: 6.557417]\n",
      "epoch:47 step:36795 [D loss: 0.447387, acc: 72.66%] [G loss: 5.679019]\n",
      "epoch:47 step:36796 [D loss: 0.135821, acc: 96.88%] [G loss: 11.413416]\n",
      "epoch:47 step:36797 [D loss: 0.162510, acc: 96.88%] [G loss: 8.856719]\n",
      "epoch:47 step:36798 [D loss: 0.123052, acc: 97.66%] [G loss: 8.431614]\n",
      "epoch:47 step:36799 [D loss: 0.112902, acc: 98.44%] [G loss: 4.580696]\n",
      "epoch:47 step:36800 [D loss: 0.235267, acc: 93.75%] [G loss: 6.364138]\n",
      "##############\n",
      "[0.87887023 0.86282034 0.80161452 0.81243751 0.78902102 0.82502745\n",
      " 0.87023161 0.80098702 0.82030903 0.83891578]\n",
      "##########\n",
      "epoch:47 step:36801 [D loss: 0.070136, acc: 100.00%] [G loss: 4.679717]\n",
      "epoch:47 step:36802 [D loss: 0.122923, acc: 99.22%] [G loss: 4.575476]\n",
      "epoch:47 step:36803 [D loss: 0.114564, acc: 100.00%] [G loss: 4.047044]\n",
      "epoch:47 step:36804 [D loss: 0.416775, acc: 84.38%] [G loss: 8.446838]\n",
      "epoch:47 step:36805 [D loss: 0.788089, acc: 53.91%] [G loss: 7.056304]\n",
      "epoch:47 step:36806 [D loss: 0.047366, acc: 100.00%] [G loss: 6.127090]\n",
      "epoch:47 step:36807 [D loss: 0.089183, acc: 99.22%] [G loss: 8.899721]\n",
      "epoch:47 step:36808 [D loss: 0.096898, acc: 97.66%] [G loss: 4.810595]\n",
      "epoch:47 step:36809 [D loss: 0.608330, acc: 57.03%] [G loss: 8.095154]\n",
      "epoch:47 step:36810 [D loss: 0.027871, acc: 100.00%] [G loss: 5.002121]\n",
      "epoch:47 step:36811 [D loss: 0.076515, acc: 100.00%] [G loss: 6.952616]\n",
      "epoch:47 step:36812 [D loss: 0.106277, acc: 100.00%] [G loss: 6.131730]\n",
      "epoch:47 step:36813 [D loss: 0.221590, acc: 93.75%] [G loss: 6.852983]\n",
      "epoch:47 step:36814 [D loss: 0.084279, acc: 99.22%] [G loss: 12.872497]\n",
      "epoch:47 step:36815 [D loss: 0.576828, acc: 66.41%] [G loss: 8.228121]\n",
      "epoch:47 step:36816 [D loss: 0.023591, acc: 100.00%] [G loss: 9.132178]\n",
      "epoch:47 step:36817 [D loss: 0.228052, acc: 98.44%] [G loss: 6.267589]\n",
      "epoch:47 step:36818 [D loss: 1.484654, acc: 46.09%] [G loss: 9.080594]\n",
      "epoch:47 step:36819 [D loss: 0.102126, acc: 100.00%] [G loss: 10.214914]\n",
      "epoch:47 step:36820 [D loss: 0.669906, acc: 56.25%] [G loss: 8.209685]\n",
      "epoch:47 step:36821 [D loss: 0.244867, acc: 91.41%] [G loss: 5.696296]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:47 step:36822 [D loss: 0.215706, acc: 92.19%] [G loss: 7.156164]\n",
      "epoch:47 step:36823 [D loss: 0.115470, acc: 99.22%] [G loss: 3.968359]\n",
      "epoch:47 step:36824 [D loss: 0.229822, acc: 94.53%] [G loss: 9.260892]\n",
      "epoch:47 step:36825 [D loss: 0.927806, acc: 52.34%] [G loss: 7.168344]\n",
      "epoch:47 step:36826 [D loss: 0.092115, acc: 99.22%] [G loss: 9.205542]\n",
      "epoch:47 step:36827 [D loss: 0.025500, acc: 100.00%] [G loss: 6.744060]\n",
      "epoch:47 step:36828 [D loss: 0.873439, acc: 52.34%] [G loss: 8.907281]\n",
      "epoch:47 step:36829 [D loss: 0.329082, acc: 82.81%] [G loss: 8.186741]\n",
      "epoch:47 step:36830 [D loss: 0.012865, acc: 100.00%] [G loss: 8.085115]\n",
      "epoch:47 step:36831 [D loss: 0.085667, acc: 100.00%] [G loss: 3.856734]\n",
      "epoch:47 step:36832 [D loss: 0.356037, acc: 76.56%] [G loss: 6.491385]\n",
      "epoch:47 step:36833 [D loss: 0.764238, acc: 57.81%] [G loss: 5.446837]\n",
      "epoch:47 step:36834 [D loss: 0.163606, acc: 96.09%] [G loss: 3.647429]\n",
      "epoch:47 step:36835 [D loss: 0.028558, acc: 100.00%] [G loss: 9.489495]\n",
      "epoch:47 step:36836 [D loss: 1.919139, acc: 50.00%] [G loss: 7.597965]\n",
      "epoch:47 step:36837 [D loss: 0.037170, acc: 100.00%] [G loss: 7.455572]\n",
      "epoch:47 step:36838 [D loss: 0.976615, acc: 50.78%] [G loss: 10.002625]\n",
      "epoch:47 step:36839 [D loss: 0.098847, acc: 100.00%] [G loss: 10.372574]\n",
      "epoch:47 step:36840 [D loss: 0.287863, acc: 92.19%] [G loss: 7.650350]\n",
      "epoch:47 step:36841 [D loss: 0.401326, acc: 83.59%] [G loss: 2.547500]\n",
      "epoch:47 step:36842 [D loss: 0.031157, acc: 100.00%] [G loss: 5.976377]\n",
      "epoch:47 step:36843 [D loss: 0.036049, acc: 100.00%] [G loss: 5.781803]\n",
      "epoch:47 step:36844 [D loss: 0.014974, acc: 100.00%] [G loss: 8.394913]\n",
      "epoch:47 step:36845 [D loss: 0.285949, acc: 89.06%] [G loss: 5.791161]\n",
      "epoch:47 step:36846 [D loss: 0.168838, acc: 98.44%] [G loss: 5.928755]\n",
      "epoch:47 step:36847 [D loss: 0.494053, acc: 75.00%] [G loss: 8.404545]\n",
      "epoch:47 step:36848 [D loss: 0.239002, acc: 89.06%] [G loss: 5.810371]\n",
      "epoch:47 step:36849 [D loss: 0.193059, acc: 93.75%] [G loss: 4.732775]\n",
      "epoch:47 step:36850 [D loss: 0.629381, acc: 64.06%] [G loss: 6.233040]\n",
      "epoch:47 step:36851 [D loss: 0.786118, acc: 53.12%] [G loss: 6.284595]\n",
      "epoch:47 step:36852 [D loss: 0.340153, acc: 84.38%] [G loss: 5.803600]\n",
      "epoch:47 step:36853 [D loss: 0.059120, acc: 100.00%] [G loss: 8.593382]\n",
      "epoch:47 step:36854 [D loss: 0.072080, acc: 100.00%] [G loss: 2.873786]\n",
      "epoch:47 step:36855 [D loss: 0.578890, acc: 60.16%] [G loss: 8.192877]\n",
      "epoch:47 step:36856 [D loss: 0.396437, acc: 77.34%] [G loss: 6.850243]\n",
      "epoch:47 step:36857 [D loss: 0.398414, acc: 84.38%] [G loss: 6.659461]\n",
      "epoch:47 step:36858 [D loss: 0.089971, acc: 99.22%] [G loss: 4.890631]\n",
      "epoch:47 step:36859 [D loss: 0.086912, acc: 100.00%] [G loss: 6.037786]\n",
      "epoch:47 step:36860 [D loss: 0.062074, acc: 100.00%] [G loss: 4.447690]\n",
      "epoch:47 step:36861 [D loss: 0.022751, acc: 100.00%] [G loss: 11.500350]\n",
      "epoch:47 step:36862 [D loss: 0.199035, acc: 97.66%] [G loss: 8.081409]\n",
      "epoch:47 step:36863 [D loss: 0.053944, acc: 99.22%] [G loss: 9.814323]\n",
      "epoch:47 step:36864 [D loss: 0.033152, acc: 99.22%] [G loss: 8.158560]\n",
      "epoch:47 step:36865 [D loss: 0.327080, acc: 92.97%] [G loss: 4.914760]\n",
      "epoch:47 step:36866 [D loss: 0.004593, acc: 100.00%] [G loss: 8.571905]\n",
      "epoch:47 step:36867 [D loss: 0.364840, acc: 79.69%] [G loss: 3.981925]\n",
      "epoch:47 step:36868 [D loss: 0.170121, acc: 96.88%] [G loss: 11.080235]\n",
      "epoch:47 step:36869 [D loss: 0.088952, acc: 98.44%] [G loss: 9.481915]\n",
      "epoch:47 step:36870 [D loss: 0.439105, acc: 80.47%] [G loss: 5.689425]\n",
      "epoch:47 step:36871 [D loss: 0.287049, acc: 86.72%] [G loss: 11.088989]\n",
      "epoch:47 step:36872 [D loss: 0.177343, acc: 93.75%] [G loss: 6.477132]\n",
      "epoch:47 step:36873 [D loss: 0.274337, acc: 90.62%] [G loss: 5.863255]\n",
      "epoch:47 step:36874 [D loss: 0.272191, acc: 89.84%] [G loss: 7.758505]\n",
      "epoch:47 step:36875 [D loss: 0.045334, acc: 100.00%] [G loss: 7.656631]\n",
      "epoch:47 step:36876 [D loss: 0.422937, acc: 80.47%] [G loss: 3.038663]\n",
      "epoch:47 step:36877 [D loss: 0.068720, acc: 99.22%] [G loss: 4.669959]\n",
      "epoch:47 step:36878 [D loss: 1.183062, acc: 48.44%] [G loss: 4.500242]\n",
      "epoch:47 step:36879 [D loss: 0.448831, acc: 69.53%] [G loss: 5.032714]\n",
      "epoch:47 step:36880 [D loss: 0.131672, acc: 97.66%] [G loss: 6.516009]\n",
      "epoch:47 step:36881 [D loss: 1.055357, acc: 50.78%] [G loss: 7.791011]\n",
      "epoch:47 step:36882 [D loss: 0.171974, acc: 97.66%] [G loss: 8.294720]\n",
      "epoch:47 step:36883 [D loss: 0.006664, acc: 100.00%] [G loss: 5.178554]\n",
      "epoch:47 step:36884 [D loss: 0.623531, acc: 60.16%] [G loss: 7.021743]\n",
      "epoch:47 step:36885 [D loss: 0.009203, acc: 100.00%] [G loss: 7.426169]\n",
      "epoch:47 step:36886 [D loss: 0.393317, acc: 86.72%] [G loss: 5.175015]\n",
      "epoch:47 step:36887 [D loss: 0.101537, acc: 100.00%] [G loss: 3.404337]\n",
      "epoch:47 step:36888 [D loss: 0.188352, acc: 99.22%] [G loss: 3.703210]\n",
      "epoch:47 step:36889 [D loss: 0.137304, acc: 97.66%] [G loss: 5.630629]\n",
      "epoch:47 step:36890 [D loss: 0.090898, acc: 99.22%] [G loss: 3.760988]\n",
      "epoch:47 step:36891 [D loss: 0.365157, acc: 88.28%] [G loss: 7.185365]\n",
      "epoch:47 step:36892 [D loss: 0.138653, acc: 100.00%] [G loss: 6.696095]\n",
      "epoch:47 step:36893 [D loss: 0.132729, acc: 100.00%] [G loss: 3.416849]\n",
      "epoch:47 step:36894 [D loss: 0.126281, acc: 100.00%] [G loss: 6.309825]\n",
      "epoch:47 step:36895 [D loss: 0.279284, acc: 95.31%] [G loss: 7.612113]\n",
      "epoch:47 step:36896 [D loss: 0.129839, acc: 96.09%] [G loss: 6.760062]\n",
      "epoch:47 step:36897 [D loss: 0.181399, acc: 95.31%] [G loss: 4.582113]\n",
      "epoch:47 step:36898 [D loss: 0.163845, acc: 95.31%] [G loss: 10.850861]\n",
      "epoch:47 step:36899 [D loss: 0.012404, acc: 100.00%] [G loss: 5.028629]\n",
      "epoch:47 step:36900 [D loss: 0.256121, acc: 91.41%] [G loss: 6.902999]\n",
      "epoch:47 step:36901 [D loss: 0.011156, acc: 100.00%] [G loss: 4.392280]\n",
      "epoch:47 step:36902 [D loss: 0.653927, acc: 62.50%] [G loss: 7.746088]\n",
      "epoch:47 step:36903 [D loss: 0.245697, acc: 94.53%] [G loss: 5.483072]\n",
      "epoch:47 step:36904 [D loss: 0.007741, acc: 100.00%] [G loss: 7.896118]\n",
      "epoch:47 step:36905 [D loss: 0.346746, acc: 86.72%] [G loss: 8.440784]\n",
      "epoch:47 step:36906 [D loss: 0.039314, acc: 99.22%] [G loss: 6.381560]\n",
      "epoch:47 step:36907 [D loss: 0.343663, acc: 85.16%] [G loss: 5.573307]\n",
      "epoch:47 step:36908 [D loss: 0.087048, acc: 98.44%] [G loss: 6.808805]\n",
      "epoch:47 step:36909 [D loss: 0.789952, acc: 49.22%] [G loss: 4.938794]\n",
      "epoch:47 step:36910 [D loss: 0.660725, acc: 58.59%] [G loss: 1.496913]\n",
      "epoch:47 step:36911 [D loss: 0.884075, acc: 52.34%] [G loss: 10.790193]\n",
      "epoch:47 step:36912 [D loss: 0.173077, acc: 96.09%] [G loss: 6.619843]\n",
      "epoch:47 step:36913 [D loss: 0.506261, acc: 64.06%] [G loss: 8.158278]\n",
      "epoch:47 step:36914 [D loss: 0.064385, acc: 100.00%] [G loss: 6.662439]\n",
      "epoch:47 step:36915 [D loss: 0.245185, acc: 96.09%] [G loss: 4.409340]\n",
      "epoch:47 step:36916 [D loss: 0.600053, acc: 59.38%] [G loss: 7.135887]\n",
      "epoch:47 step:36917 [D loss: 0.200961, acc: 94.53%] [G loss: 8.181759]\n",
      "epoch:47 step:36918 [D loss: 0.043994, acc: 100.00%] [G loss: 8.993206]\n",
      "epoch:47 step:36919 [D loss: 0.114838, acc: 99.22%] [G loss: 6.716047]\n",
      "epoch:47 step:36920 [D loss: 0.402419, acc: 73.44%] [G loss: 5.917979]\n",
      "epoch:47 step:36921 [D loss: 0.115950, acc: 100.00%] [G loss: 8.259008]\n",
      "epoch:47 step:36922 [D loss: 0.618467, acc: 66.41%] [G loss: 7.052372]\n",
      "epoch:47 step:36923 [D loss: 1.079660, acc: 31.25%] [G loss: 5.724035]\n",
      "epoch:47 step:36924 [D loss: 0.606343, acc: 59.38%] [G loss: 5.282619]\n",
      "epoch:47 step:36925 [D loss: 0.897316, acc: 54.69%] [G loss: 8.834356]\n",
      "epoch:47 step:36926 [D loss: 0.027777, acc: 100.00%] [G loss: 6.632777]\n",
      "epoch:47 step:36927 [D loss: 0.292743, acc: 86.72%] [G loss: 9.112745]\n",
      "epoch:47 step:36928 [D loss: 0.244567, acc: 97.66%] [G loss: 5.281169]\n",
      "epoch:47 step:36929 [D loss: 1.023054, acc: 52.34%] [G loss: 8.717690]\n",
      "epoch:47 step:36930 [D loss: 0.020305, acc: 100.00%] [G loss: 6.442932]\n",
      "epoch:47 step:36931 [D loss: 0.471415, acc: 71.09%] [G loss: 8.018060]\n",
      "epoch:47 step:36932 [D loss: 0.062800, acc: 99.22%] [G loss: 7.593292]\n",
      "epoch:47 step:36933 [D loss: 0.480249, acc: 82.03%] [G loss: 5.377460]\n",
      "epoch:47 step:36934 [D loss: 0.003041, acc: 100.00%] [G loss: 13.495562]\n",
      "epoch:47 step:36935 [D loss: 0.008682, acc: 100.00%] [G loss: 8.604337]\n",
      "epoch:47 step:36936 [D loss: 0.238222, acc: 93.75%] [G loss: 9.134765]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:47 step:36937 [D loss: 0.569332, acc: 74.22%] [G loss: 7.086747]\n",
      "epoch:47 step:36938 [D loss: 0.153113, acc: 99.22%] [G loss: 4.609475]\n",
      "epoch:47 step:36939 [D loss: 0.050940, acc: 100.00%] [G loss: 5.501626]\n",
      "epoch:47 step:36940 [D loss: 0.226415, acc: 94.53%] [G loss: 5.597688]\n",
      "epoch:47 step:36941 [D loss: 0.743167, acc: 54.69%] [G loss: 5.035033]\n",
      "epoch:47 step:36942 [D loss: 1.350968, acc: 21.88%] [G loss: 5.239132]\n",
      "epoch:47 step:36943 [D loss: 0.069090, acc: 100.00%] [G loss: 7.278108]\n",
      "epoch:47 step:36944 [D loss: 0.169996, acc: 97.66%] [G loss: 7.182597]\n",
      "epoch:47 step:36945 [D loss: 0.103363, acc: 100.00%] [G loss: 5.013959]\n",
      "epoch:47 step:36946 [D loss: 0.046141, acc: 100.00%] [G loss: 4.518812]\n",
      "epoch:47 step:36947 [D loss: 0.336678, acc: 90.62%] [G loss: 5.679462]\n",
      "epoch:47 step:36948 [D loss: 0.088455, acc: 99.22%] [G loss: 6.254386]\n",
      "epoch:47 step:36949 [D loss: 0.004493, acc: 100.00%] [G loss: 9.492105]\n",
      "epoch:47 step:36950 [D loss: 0.076739, acc: 100.00%] [G loss: 7.569076]\n",
      "epoch:47 step:36951 [D loss: 0.080833, acc: 100.00%] [G loss: 10.042215]\n",
      "epoch:47 step:36952 [D loss: 1.069168, acc: 51.56%] [G loss: 7.830031]\n",
      "epoch:47 step:36953 [D loss: 0.031203, acc: 100.00%] [G loss: 3.589143]\n",
      "epoch:47 step:36954 [D loss: 0.256745, acc: 92.19%] [G loss: 6.054298]\n",
      "epoch:47 step:36955 [D loss: 0.164606, acc: 97.66%] [G loss: 5.253229]\n",
      "epoch:47 step:36956 [D loss: 0.137242, acc: 98.44%] [G loss: 4.022905]\n",
      "epoch:47 step:36957 [D loss: 0.330230, acc: 85.94%] [G loss: 8.368240]\n",
      "epoch:47 step:36958 [D loss: 0.176900, acc: 95.31%] [G loss: 3.392525]\n",
      "epoch:47 step:36959 [D loss: 0.665494, acc: 63.28%] [G loss: 4.356846]\n",
      "epoch:47 step:36960 [D loss: 0.546584, acc: 64.84%] [G loss: 5.211656]\n",
      "epoch:47 step:36961 [D loss: 0.578578, acc: 62.50%] [G loss: 5.959498]\n",
      "epoch:47 step:36962 [D loss: 0.202643, acc: 99.22%] [G loss: 7.135423]\n",
      "epoch:47 step:36963 [D loss: 0.980124, acc: 52.34%] [G loss: 7.900218]\n",
      "epoch:47 step:36964 [D loss: 0.318799, acc: 92.19%] [G loss: 2.735413]\n",
      "epoch:47 step:36965 [D loss: 0.459074, acc: 78.12%] [G loss: 9.054670]\n",
      "epoch:47 step:36966 [D loss: 0.107069, acc: 99.22%] [G loss: 3.475080]\n",
      "epoch:47 step:36967 [D loss: 0.094753, acc: 98.44%] [G loss: 6.762341]\n",
      "epoch:47 step:36968 [D loss: 0.056008, acc: 100.00%] [G loss: 2.917878]\n",
      "epoch:47 step:36969 [D loss: 0.037116, acc: 100.00%] [G loss: 3.526907]\n",
      "epoch:47 step:36970 [D loss: 0.449225, acc: 75.78%] [G loss: 11.594771]\n",
      "epoch:47 step:36971 [D loss: 0.362923, acc: 85.94%] [G loss: 8.386919]\n",
      "epoch:47 step:36972 [D loss: 0.083980, acc: 99.22%] [G loss: 9.497126]\n",
      "epoch:47 step:36973 [D loss: 0.108796, acc: 97.66%] [G loss: 6.491747]\n",
      "epoch:47 step:36974 [D loss: 0.093973, acc: 100.00%] [G loss: 1.616835]\n",
      "epoch:47 step:36975 [D loss: 0.062634, acc: 100.00%] [G loss: 5.248494]\n",
      "epoch:47 step:36976 [D loss: 0.133735, acc: 98.44%] [G loss: 5.002652]\n",
      "epoch:47 step:36977 [D loss: 0.579262, acc: 69.53%] [G loss: 12.295443]\n",
      "epoch:47 step:36978 [D loss: 0.036815, acc: 100.00%] [G loss: 8.345984]\n",
      "epoch:47 step:36979 [D loss: 0.645176, acc: 57.81%] [G loss: 8.200125]\n",
      "epoch:47 step:36980 [D loss: 0.483880, acc: 69.53%] [G loss: 5.743072]\n",
      "epoch:47 step:36981 [D loss: 0.093650, acc: 100.00%] [G loss: 3.402148]\n",
      "epoch:47 step:36982 [D loss: 0.130242, acc: 98.44%] [G loss: 5.196646]\n",
      "epoch:47 step:36983 [D loss: 0.072589, acc: 100.00%] [G loss: 5.643039]\n",
      "epoch:47 step:36984 [D loss: 0.072254, acc: 99.22%] [G loss: 11.791820]\n",
      "epoch:47 step:36985 [D loss: 0.075647, acc: 100.00%] [G loss: 7.586361]\n",
      "epoch:47 step:36986 [D loss: 0.045200, acc: 100.00%] [G loss: 2.336051]\n",
      "epoch:47 step:36987 [D loss: 0.048087, acc: 100.00%] [G loss: 6.012236]\n",
      "epoch:47 step:36988 [D loss: 0.274359, acc: 89.06%] [G loss: 3.088924]\n",
      "epoch:47 step:36989 [D loss: 0.109813, acc: 100.00%] [G loss: 6.127645]\n",
      "epoch:47 step:36990 [D loss: 0.030254, acc: 100.00%] [G loss: 7.765606]\n",
      "epoch:47 step:36991 [D loss: 0.070029, acc: 100.00%] [G loss: 6.991465]\n",
      "epoch:47 step:36992 [D loss: 0.091256, acc: 100.00%] [G loss: 4.367693]\n",
      "epoch:47 step:36993 [D loss: 0.029984, acc: 100.00%] [G loss: 8.361441]\n",
      "epoch:47 step:36994 [D loss: 2.472786, acc: 15.62%] [G loss: 9.825356]\n",
      "epoch:47 step:36995 [D loss: 0.157904, acc: 98.44%] [G loss: 6.605055]\n",
      "epoch:47 step:36996 [D loss: 0.268004, acc: 92.97%] [G loss: 6.804239]\n",
      "epoch:47 step:36997 [D loss: 0.823132, acc: 55.47%] [G loss: 6.348347]\n",
      "epoch:47 step:36998 [D loss: 0.684118, acc: 56.25%] [G loss: 9.529189]\n",
      "epoch:47 step:36999 [D loss: 0.079018, acc: 99.22%] [G loss: 8.295696]\n",
      "epoch:47 step:37000 [D loss: 0.517817, acc: 69.53%] [G loss: 5.394851]\n",
      "##############\n",
      "[0.85683011 0.87065245 0.82113594 0.80237806 0.79895518 0.83340891\n",
      " 0.9127969  0.85255565 0.79559262 0.81667156]\n",
      "##########\n",
      "epoch:47 step:37001 [D loss: 0.552078, acc: 65.62%] [G loss: 6.900723]\n",
      "epoch:47 step:37002 [D loss: 0.623371, acc: 63.28%] [G loss: 5.997264]\n",
      "epoch:47 step:37003 [D loss: 0.076762, acc: 100.00%] [G loss: 8.050956]\n",
      "epoch:47 step:37004 [D loss: 0.195742, acc: 95.31%] [G loss: 3.903039]\n",
      "epoch:47 step:37005 [D loss: 0.591141, acc: 67.97%] [G loss: 7.806553]\n",
      "epoch:47 step:37006 [D loss: 0.076488, acc: 99.22%] [G loss: 9.038927]\n",
      "epoch:47 step:37007 [D loss: 0.206446, acc: 92.97%] [G loss: 6.938829]\n",
      "epoch:47 step:37008 [D loss: 0.393366, acc: 79.69%] [G loss: 4.140896]\n",
      "epoch:47 step:37009 [D loss: 0.275126, acc: 89.84%] [G loss: 3.838684]\n",
      "epoch:47 step:37010 [D loss: 0.085284, acc: 100.00%] [G loss: 4.090076]\n",
      "epoch:47 step:37011 [D loss: 0.471951, acc: 79.69%] [G loss: 6.731058]\n",
      "epoch:47 step:37012 [D loss: 0.523986, acc: 66.41%] [G loss: 12.837994]\n",
      "epoch:47 step:37013 [D loss: 0.400626, acc: 77.34%] [G loss: 6.609948]\n",
      "epoch:47 step:37014 [D loss: 0.618096, acc: 61.72%] [G loss: 10.866982]\n",
      "epoch:47 step:37015 [D loss: 0.297204, acc: 84.38%] [G loss: 10.312383]\n",
      "epoch:47 step:37016 [D loss: 0.174614, acc: 96.88%] [G loss: 4.607234]\n",
      "epoch:47 step:37017 [D loss: 0.096617, acc: 100.00%] [G loss: 5.819272]\n",
      "epoch:47 step:37018 [D loss: 0.467802, acc: 74.22%] [G loss: 5.298779]\n",
      "epoch:47 step:37019 [D loss: 0.182672, acc: 97.66%] [G loss: 10.310925]\n",
      "epoch:47 step:37020 [D loss: 0.018129, acc: 100.00%] [G loss: 5.121879]\n",
      "epoch:47 step:37021 [D loss: 0.537776, acc: 70.31%] [G loss: 7.208628]\n",
      "epoch:47 step:37022 [D loss: 0.212723, acc: 96.09%] [G loss: 4.950288]\n",
      "epoch:47 step:37023 [D loss: 0.272443, acc: 92.97%] [G loss: 7.345565]\n",
      "epoch:47 step:37024 [D loss: 0.999195, acc: 53.12%] [G loss: 7.092620]\n",
      "epoch:47 step:37025 [D loss: 0.091645, acc: 100.00%] [G loss: 8.366253]\n",
      "epoch:47 step:37026 [D loss: 0.453093, acc: 69.53%] [G loss: 8.186406]\n",
      "epoch:47 step:37027 [D loss: 0.295484, acc: 92.19%] [G loss: 4.054901]\n",
      "epoch:47 step:37028 [D loss: 0.170177, acc: 96.09%] [G loss: 9.784984]\n",
      "epoch:47 step:37029 [D loss: 0.106514, acc: 99.22%] [G loss: 11.091590]\n",
      "epoch:47 step:37030 [D loss: 0.294717, acc: 92.19%] [G loss: 4.274336]\n",
      "epoch:47 step:37031 [D loss: 0.705793, acc: 56.25%] [G loss: 6.105830]\n",
      "epoch:47 step:37032 [D loss: 0.070388, acc: 100.00%] [G loss: 5.664804]\n",
      "epoch:47 step:37033 [D loss: 0.163337, acc: 97.66%] [G loss: 6.953941]\n",
      "epoch:47 step:37034 [D loss: 0.271170, acc: 93.75%] [G loss: 6.581099]\n",
      "epoch:47 step:37035 [D loss: 0.513253, acc: 76.56%] [G loss: 5.637069]\n",
      "epoch:47 step:37036 [D loss: 0.138625, acc: 99.22%] [G loss: 4.739280]\n",
      "epoch:47 step:37037 [D loss: 0.206654, acc: 97.66%] [G loss: 3.813185]\n",
      "epoch:47 step:37038 [D loss: 0.918812, acc: 50.00%] [G loss: 8.266910]\n",
      "epoch:47 step:37039 [D loss: 0.112346, acc: 99.22%] [G loss: 8.167030]\n",
      "epoch:47 step:37040 [D loss: 0.295660, acc: 86.72%] [G loss: 6.677209]\n",
      "epoch:47 step:37041 [D loss: 0.035379, acc: 100.00%] [G loss: 7.982599]\n",
      "epoch:47 step:37042 [D loss: 0.059144, acc: 100.00%] [G loss: 8.334286]\n",
      "epoch:47 step:37043 [D loss: 0.053779, acc: 100.00%] [G loss: 5.559661]\n",
      "epoch:47 step:37044 [D loss: 0.018104, acc: 100.00%] [G loss: 9.203053]\n",
      "epoch:47 step:37045 [D loss: 0.662562, acc: 64.06%] [G loss: 9.622219]\n",
      "epoch:47 step:37046 [D loss: 0.037849, acc: 100.00%] [G loss: 4.842970]\n",
      "epoch:47 step:37047 [D loss: 0.022691, acc: 100.00%] [G loss: 7.131791]\n",
      "epoch:47 step:37048 [D loss: 0.165665, acc: 96.09%] [G loss: 5.636331]\n",
      "epoch:47 step:37049 [D loss: 0.086765, acc: 100.00%] [G loss: 5.185007]\n",
      "epoch:47 step:37050 [D loss: 0.124565, acc: 100.00%] [G loss: 7.299898]\n",
      "epoch:47 step:37051 [D loss: 0.047368, acc: 100.00%] [G loss: 6.777340]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:47 step:37052 [D loss: 1.532476, acc: 47.66%] [G loss: 5.849267]\n",
      "epoch:47 step:37053 [D loss: 0.062399, acc: 100.00%] [G loss: 6.350763]\n",
      "epoch:47 step:37054 [D loss: 0.091391, acc: 100.00%] [G loss: 6.466405]\n",
      "epoch:47 step:37055 [D loss: 1.087655, acc: 50.00%] [G loss: 8.857222]\n",
      "epoch:47 step:37056 [D loss: 0.247408, acc: 94.53%] [G loss: 4.634572]\n",
      "epoch:47 step:37057 [D loss: 0.021666, acc: 100.00%] [G loss: 7.448360]\n",
      "epoch:47 step:37058 [D loss: 0.012504, acc: 100.00%] [G loss: 7.351213]\n",
      "epoch:47 step:37059 [D loss: 0.768668, acc: 53.91%] [G loss: 5.841425]\n",
      "epoch:47 step:37060 [D loss: 0.040159, acc: 100.00%] [G loss: 5.533616]\n",
      "epoch:47 step:37061 [D loss: 0.066331, acc: 100.00%] [G loss: 7.053891]\n",
      "epoch:47 step:37062 [D loss: 0.925571, acc: 50.78%] [G loss: 6.396430]\n",
      "epoch:47 step:37063 [D loss: 0.763190, acc: 51.56%] [G loss: 7.251251]\n",
      "epoch:47 step:37064 [D loss: 0.019173, acc: 100.00%] [G loss: 3.500075]\n",
      "epoch:47 step:37065 [D loss: 0.347259, acc: 91.41%] [G loss: 6.332294]\n",
      "epoch:47 step:37066 [D loss: 0.052736, acc: 100.00%] [G loss: 5.209681]\n",
      "epoch:47 step:37067 [D loss: 0.187677, acc: 100.00%] [G loss: 6.074286]\n",
      "epoch:47 step:37068 [D loss: 0.038000, acc: 100.00%] [G loss: 5.154131]\n",
      "epoch:47 step:37069 [D loss: 1.105501, acc: 43.75%] [G loss: 7.583672]\n",
      "epoch:47 step:37070 [D loss: 0.078093, acc: 100.00%] [G loss: 6.459384]\n",
      "epoch:47 step:37071 [D loss: 0.637640, acc: 58.59%] [G loss: 6.628584]\n",
      "epoch:47 step:37072 [D loss: 0.103043, acc: 100.00%] [G loss: 3.892589]\n",
      "epoch:47 step:37073 [D loss: 0.055781, acc: 98.44%] [G loss: 6.473726]\n",
      "epoch:47 step:37074 [D loss: 1.251120, acc: 50.78%] [G loss: 5.945170]\n",
      "epoch:47 step:37075 [D loss: 0.527957, acc: 64.84%] [G loss: 7.576669]\n",
      "epoch:47 step:37076 [D loss: 0.803213, acc: 53.91%] [G loss: 7.985752]\n",
      "epoch:47 step:37077 [D loss: 0.342404, acc: 79.69%] [G loss: 5.289258]\n",
      "epoch:47 step:37078 [D loss: 0.014357, acc: 100.00%] [G loss: 8.305107]\n",
      "epoch:47 step:37079 [D loss: 0.031914, acc: 100.00%] [G loss: 1.880899]\n",
      "epoch:47 step:37080 [D loss: 0.108376, acc: 100.00%] [G loss: 4.219747]\n",
      "epoch:47 step:37081 [D loss: 0.170267, acc: 96.09%] [G loss: 6.491271]\n",
      "epoch:47 step:37082 [D loss: 0.524191, acc: 69.53%] [G loss: 4.458751]\n",
      "epoch:47 step:37083 [D loss: 1.243471, acc: 50.00%] [G loss: 12.627020]\n",
      "epoch:47 step:37084 [D loss: 0.053285, acc: 99.22%] [G loss: 8.256930]\n",
      "epoch:47 step:37085 [D loss: 0.943328, acc: 51.56%] [G loss: 10.130880]\n",
      "epoch:47 step:37086 [D loss: 0.090231, acc: 99.22%] [G loss: 6.682166]\n",
      "epoch:47 step:37087 [D loss: 0.583734, acc: 71.88%] [G loss: 6.684116]\n",
      "epoch:47 step:37088 [D loss: 0.342147, acc: 92.19%] [G loss: 3.513896]\n",
      "epoch:47 step:37089 [D loss: 1.224417, acc: 50.78%] [G loss: 7.912541]\n",
      "epoch:47 step:37090 [D loss: 0.596814, acc: 60.94%] [G loss: 6.651893]\n",
      "epoch:47 step:37091 [D loss: 0.409481, acc: 80.47%] [G loss: 5.696501]\n",
      "epoch:47 step:37092 [D loss: 0.266042, acc: 89.84%] [G loss: 5.040798]\n",
      "epoch:47 step:37093 [D loss: 0.652407, acc: 61.72%] [G loss: 6.110990]\n",
      "epoch:47 step:37094 [D loss: 0.057763, acc: 99.22%] [G loss: 6.197719]\n",
      "epoch:47 step:37095 [D loss: 0.542217, acc: 70.31%] [G loss: 6.937056]\n",
      "epoch:47 step:37096 [D loss: 0.254001, acc: 96.09%] [G loss: 6.423582]\n",
      "epoch:47 step:37097 [D loss: 0.463918, acc: 73.44%] [G loss: 6.930468]\n",
      "epoch:47 step:37098 [D loss: 0.081188, acc: 100.00%] [G loss: 3.752553]\n",
      "epoch:47 step:37099 [D loss: 0.037113, acc: 100.00%] [G loss: 9.748152]\n",
      "epoch:47 step:37100 [D loss: 0.135927, acc: 99.22%] [G loss: 5.540300]\n",
      "epoch:47 step:37101 [D loss: 0.207970, acc: 92.19%] [G loss: 6.626045]\n",
      "epoch:47 step:37102 [D loss: 0.507587, acc: 75.00%] [G loss: 8.342772]\n",
      "epoch:47 step:37103 [D loss: 0.097165, acc: 99.22%] [G loss: 4.510735]\n",
      "epoch:47 step:37104 [D loss: 0.164883, acc: 95.31%] [G loss: 4.730761]\n",
      "epoch:47 step:37105 [D loss: 0.210519, acc: 94.53%] [G loss: 5.506811]\n",
      "epoch:47 step:37106 [D loss: 0.022433, acc: 100.00%] [G loss: 8.670771]\n",
      "epoch:47 step:37107 [D loss: 0.003819, acc: 100.00%] [G loss: 10.679733]\n",
      "epoch:47 step:37108 [D loss: 0.018185, acc: 100.00%] [G loss: 5.939075]\n",
      "epoch:47 step:37109 [D loss: 0.121613, acc: 97.66%] [G loss: 6.085747]\n",
      "epoch:47 step:37110 [D loss: 0.045506, acc: 100.00%] [G loss: 6.245349]\n",
      "epoch:47 step:37111 [D loss: 0.464323, acc: 84.38%] [G loss: 7.345902]\n",
      "epoch:47 step:37112 [D loss: 0.117423, acc: 99.22%] [G loss: 1.710574]\n",
      "epoch:47 step:37113 [D loss: 0.252889, acc: 97.66%] [G loss: 5.629008]\n",
      "epoch:47 step:37114 [D loss: 0.057070, acc: 100.00%] [G loss: 5.630573]\n",
      "epoch:47 step:37115 [D loss: 0.048665, acc: 100.00%] [G loss: 4.256263]\n",
      "epoch:47 step:37116 [D loss: 0.274008, acc: 89.84%] [G loss: 5.030519]\n",
      "epoch:47 step:37117 [D loss: 0.023969, acc: 100.00%] [G loss: 5.942343]\n",
      "epoch:47 step:37118 [D loss: 0.091733, acc: 99.22%] [G loss: 6.726829]\n",
      "epoch:47 step:37119 [D loss: 0.085702, acc: 98.44%] [G loss: 6.049780]\n",
      "epoch:47 step:37120 [D loss: 0.053593, acc: 100.00%] [G loss: 7.144210]\n",
      "epoch:47 step:37121 [D loss: 1.619519, acc: 50.00%] [G loss: 6.218070]\n",
      "epoch:47 step:37122 [D loss: 0.145711, acc: 99.22%] [G loss: 4.067346]\n",
      "epoch:47 step:37123 [D loss: 0.411414, acc: 71.09%] [G loss: 8.381203]\n",
      "epoch:47 step:37124 [D loss: 0.116708, acc: 98.44%] [G loss: 8.480766]\n",
      "epoch:47 step:37125 [D loss: 0.274978, acc: 87.50%] [G loss: 9.362368]\n",
      "epoch:47 step:37126 [D loss: 0.017140, acc: 100.00%] [G loss: 7.669164]\n",
      "epoch:47 step:37127 [D loss: 0.116645, acc: 99.22%] [G loss: 2.942783]\n",
      "epoch:47 step:37128 [D loss: 0.323591, acc: 80.47%] [G loss: 5.806354]\n",
      "epoch:47 step:37129 [D loss: 0.205989, acc: 92.97%] [G loss: 9.614882]\n",
      "epoch:47 step:37130 [D loss: 0.734760, acc: 57.81%] [G loss: 6.530710]\n",
      "epoch:47 step:37131 [D loss: 0.081239, acc: 99.22%] [G loss: 5.987538]\n",
      "epoch:47 step:37132 [D loss: 0.374974, acc: 82.81%] [G loss: 7.490301]\n",
      "epoch:47 step:37133 [D loss: 0.443015, acc: 80.47%] [G loss: 5.304590]\n",
      "epoch:47 step:37134 [D loss: 0.231771, acc: 95.31%] [G loss: 6.210216]\n",
      "epoch:47 step:37135 [D loss: 0.605177, acc: 60.94%] [G loss: 7.802238]\n",
      "epoch:47 step:37136 [D loss: 0.102139, acc: 97.66%] [G loss: 5.457205]\n",
      "epoch:47 step:37137 [D loss: 0.503231, acc: 67.97%] [G loss: 11.005626]\n",
      "epoch:47 step:37138 [D loss: 0.031696, acc: 100.00%] [G loss: 4.533225]\n",
      "epoch:47 step:37139 [D loss: 0.260210, acc: 93.75%] [G loss: 6.790263]\n",
      "epoch:47 step:37140 [D loss: 0.020354, acc: 100.00%] [G loss: 9.479168]\n",
      "epoch:47 step:37141 [D loss: 0.164369, acc: 98.44%] [G loss: 9.665498]\n",
      "epoch:47 step:37142 [D loss: 0.738671, acc: 53.12%] [G loss: 6.630801]\n",
      "epoch:47 step:37143 [D loss: 0.181026, acc: 96.09%] [G loss: 7.066710]\n",
      "epoch:47 step:37144 [D loss: 0.163976, acc: 96.88%] [G loss: 6.167320]\n",
      "epoch:47 step:37145 [D loss: 0.061476, acc: 100.00%] [G loss: 3.203388]\n",
      "epoch:47 step:37146 [D loss: 0.155720, acc: 95.31%] [G loss: 4.428085]\n",
      "epoch:47 step:37147 [D loss: 0.120541, acc: 99.22%] [G loss: 3.028661]\n",
      "epoch:47 step:37148 [D loss: 0.033364, acc: 100.00%] [G loss: 7.233539]\n",
      "epoch:47 step:37149 [D loss: 0.049200, acc: 100.00%] [G loss: 5.780694]\n",
      "epoch:47 step:37150 [D loss: 0.275331, acc: 95.31%] [G loss: 3.550813]\n",
      "epoch:47 step:37151 [D loss: 0.418633, acc: 89.06%] [G loss: 5.172712]\n",
      "epoch:47 step:37152 [D loss: 0.214558, acc: 94.53%] [G loss: 4.386811]\n",
      "epoch:47 step:37153 [D loss: 0.321845, acc: 89.06%] [G loss: 4.558311]\n",
      "epoch:47 step:37154 [D loss: 0.121555, acc: 100.00%] [G loss: 5.996243]\n",
      "epoch:47 step:37155 [D loss: 0.309163, acc: 84.38%] [G loss: 7.959721]\n",
      "epoch:47 step:37156 [D loss: 0.972737, acc: 51.56%] [G loss: 7.326597]\n",
      "epoch:47 step:37157 [D loss: 0.429142, acc: 75.00%] [G loss: 10.943925]\n",
      "epoch:47 step:37158 [D loss: 0.084706, acc: 100.00%] [G loss: 4.070273]\n",
      "epoch:47 step:37159 [D loss: 0.101495, acc: 100.00%] [G loss: 6.118569]\n",
      "epoch:47 step:37160 [D loss: 0.238666, acc: 94.53%] [G loss: 8.541766]\n",
      "epoch:47 step:37161 [D loss: 0.281518, acc: 88.28%] [G loss: 8.349524]\n",
      "epoch:47 step:37162 [D loss: 0.363862, acc: 76.56%] [G loss: 6.787118]\n",
      "epoch:47 step:37163 [D loss: 0.061128, acc: 99.22%] [G loss: 6.292170]\n",
      "epoch:47 step:37164 [D loss: 0.210822, acc: 91.41%] [G loss: 8.501348]\n",
      "epoch:47 step:37165 [D loss: 1.264101, acc: 25.00%] [G loss: 5.603574]\n",
      "epoch:47 step:37166 [D loss: 0.783057, acc: 58.59%] [G loss: 4.859447]\n",
      "epoch:47 step:37167 [D loss: 0.394922, acc: 76.56%] [G loss: 6.475528]\n",
      "epoch:47 step:37168 [D loss: 0.129504, acc: 99.22%] [G loss: 6.609831]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:47 step:37169 [D loss: 0.002296, acc: 100.00%] [G loss: 7.879540]\n",
      "epoch:47 step:37170 [D loss: 0.461532, acc: 65.62%] [G loss: 11.470392]\n",
      "epoch:47 step:37171 [D loss: 0.428754, acc: 81.25%] [G loss: 8.941509]\n",
      "epoch:47 step:37172 [D loss: 0.144077, acc: 97.66%] [G loss: 6.866666]\n",
      "epoch:47 step:37173 [D loss: 0.287643, acc: 84.38%] [G loss: 9.100216]\n",
      "epoch:47 step:37174 [D loss: 0.474360, acc: 72.66%] [G loss: 7.832479]\n",
      "epoch:47 step:37175 [D loss: 0.243443, acc: 92.97%] [G loss: 9.290968]\n",
      "epoch:47 step:37176 [D loss: 0.047711, acc: 100.00%] [G loss: 6.958153]\n",
      "epoch:47 step:37177 [D loss: 0.011527, acc: 100.00%] [G loss: 10.595711]\n",
      "epoch:47 step:37178 [D loss: 0.288869, acc: 85.16%] [G loss: 8.008157]\n",
      "epoch:47 step:37179 [D loss: 0.025713, acc: 100.00%] [G loss: 6.261153]\n",
      "epoch:47 step:37180 [D loss: 0.125603, acc: 96.88%] [G loss: 4.372096]\n",
      "epoch:47 step:37181 [D loss: 1.013188, acc: 36.72%] [G loss: 9.872706]\n",
      "epoch:47 step:37182 [D loss: 0.127384, acc: 98.44%] [G loss: 6.719387]\n",
      "epoch:47 step:37183 [D loss: 0.105062, acc: 99.22%] [G loss: 7.612901]\n",
      "epoch:47 step:37184 [D loss: 0.151674, acc: 99.22%] [G loss: 7.887036]\n",
      "epoch:47 step:37185 [D loss: 0.003512, acc: 100.00%] [G loss: 12.264750]\n",
      "epoch:47 step:37186 [D loss: 0.100985, acc: 99.22%] [G loss: 7.496942]\n",
      "epoch:47 step:37187 [D loss: 0.035193, acc: 100.00%] [G loss: 7.330194]\n",
      "epoch:47 step:37188 [D loss: 0.041768, acc: 100.00%] [G loss: 6.812666]\n",
      "epoch:47 step:37189 [D loss: 0.025814, acc: 100.00%] [G loss: 3.718473]\n",
      "epoch:47 step:37190 [D loss: 0.087183, acc: 100.00%] [G loss: 8.023636]\n",
      "epoch:47 step:37191 [D loss: 0.448674, acc: 67.97%] [G loss: 4.636307]\n",
      "epoch:47 step:37192 [D loss: 0.584821, acc: 64.84%] [G loss: 5.543118]\n",
      "epoch:47 step:37193 [D loss: 0.197726, acc: 91.41%] [G loss: 4.174787]\n",
      "epoch:47 step:37194 [D loss: 0.374495, acc: 89.84%] [G loss: 8.322488]\n",
      "epoch:47 step:37195 [D loss: 0.383274, acc: 85.16%] [G loss: 5.915293]\n",
      "epoch:47 step:37196 [D loss: 0.161159, acc: 97.66%] [G loss: 6.249183]\n",
      "epoch:47 step:37197 [D loss: 0.093773, acc: 98.44%] [G loss: 7.317307]\n",
      "epoch:47 step:37198 [D loss: 0.068888, acc: 100.00%] [G loss: 6.084282]\n",
      "epoch:47 step:37199 [D loss: 0.345253, acc: 93.75%] [G loss: 5.379346]\n",
      "epoch:47 step:37200 [D loss: 0.716495, acc: 54.69%] [G loss: 5.271738]\n",
      "##############\n",
      "[0.87228582 0.89482362 0.81136327 0.81615464 0.78967378 0.82531189\n",
      " 0.88675377 0.81455416 0.82804799 0.85027613]\n",
      "##########\n",
      "epoch:47 step:37201 [D loss: 0.033905, acc: 100.00%] [G loss: 9.034002]\n",
      "epoch:47 step:37202 [D loss: 0.400203, acc: 74.22%] [G loss: 6.822417]\n",
      "epoch:47 step:37203 [D loss: 0.540884, acc: 68.75%] [G loss: 4.251495]\n",
      "epoch:47 step:37204 [D loss: 0.001349, acc: 100.00%] [G loss: 10.748888]\n",
      "epoch:47 step:37205 [D loss: 0.641607, acc: 61.72%] [G loss: 6.784429]\n",
      "epoch:47 step:37206 [D loss: 0.347676, acc: 85.16%] [G loss: 6.143434]\n",
      "epoch:47 step:37207 [D loss: 0.491007, acc: 78.12%] [G loss: 9.201069]\n",
      "epoch:47 step:37208 [D loss: 0.107285, acc: 99.22%] [G loss: 3.748850]\n",
      "epoch:47 step:37209 [D loss: 0.175597, acc: 99.22%] [G loss: 8.446135]\n",
      "epoch:47 step:37210 [D loss: 0.454781, acc: 75.00%] [G loss: 9.555272]\n",
      "epoch:47 step:37211 [D loss: 0.491899, acc: 78.91%] [G loss: 6.747714]\n",
      "epoch:47 step:37212 [D loss: 0.083505, acc: 100.00%] [G loss: 5.382745]\n",
      "epoch:47 step:37213 [D loss: 0.143723, acc: 97.66%] [G loss: 4.530674]\n",
      "epoch:47 step:37214 [D loss: 0.312869, acc: 91.41%] [G loss: 5.276255]\n",
      "epoch:47 step:37215 [D loss: 0.037379, acc: 100.00%] [G loss: 5.927981]\n",
      "epoch:47 step:37216 [D loss: 0.396994, acc: 75.00%] [G loss: 4.181735]\n",
      "epoch:47 step:37217 [D loss: 0.105963, acc: 100.00%] [G loss: 3.801494]\n",
      "epoch:47 step:37218 [D loss: 0.076118, acc: 100.00%] [G loss: 11.508371]\n",
      "epoch:47 step:37219 [D loss: 0.198124, acc: 95.31%] [G loss: 6.230401]\n",
      "epoch:47 step:37220 [D loss: 0.036528, acc: 100.00%] [G loss: 7.374528]\n",
      "epoch:47 step:37221 [D loss: 0.018129, acc: 100.00%] [G loss: 5.544170]\n",
      "epoch:47 step:37222 [D loss: 0.589832, acc: 67.19%] [G loss: 6.519932]\n",
      "epoch:47 step:37223 [D loss: 0.974200, acc: 51.56%] [G loss: 2.597433]\n",
      "epoch:47 step:37224 [D loss: 0.131931, acc: 99.22%] [G loss: 7.149781]\n",
      "epoch:47 step:37225 [D loss: 0.021133, acc: 100.00%] [G loss: 6.046242]\n",
      "epoch:47 step:37226 [D loss: 0.678801, acc: 59.38%] [G loss: 8.250343]\n",
      "epoch:47 step:37227 [D loss: 0.180088, acc: 95.31%] [G loss: 5.727501]\n",
      "epoch:47 step:37228 [D loss: 0.922069, acc: 52.34%] [G loss: 5.362451]\n",
      "epoch:47 step:37229 [D loss: 0.099154, acc: 100.00%] [G loss: 7.974448]\n",
      "epoch:47 step:37230 [D loss: 1.070477, acc: 52.34%] [G loss: 7.203113]\n",
      "epoch:47 step:37231 [D loss: 0.055204, acc: 100.00%] [G loss: 9.136698]\n",
      "epoch:47 step:37232 [D loss: 0.309950, acc: 85.94%] [G loss: 6.320008]\n",
      "epoch:47 step:37233 [D loss: 0.119102, acc: 98.44%] [G loss: 10.121838]\n",
      "epoch:47 step:37234 [D loss: 0.122130, acc: 99.22%] [G loss: 5.724898]\n",
      "epoch:47 step:37235 [D loss: 0.339159, acc: 87.50%] [G loss: 7.680554]\n",
      "epoch:47 step:37236 [D loss: 0.284466, acc: 88.28%] [G loss: 11.918910]\n",
      "epoch:47 step:37237 [D loss: 0.154580, acc: 98.44%] [G loss: 6.400894]\n",
      "epoch:47 step:37238 [D loss: 0.327627, acc: 84.38%] [G loss: 5.733216]\n",
      "epoch:47 step:37239 [D loss: 0.085109, acc: 98.44%] [G loss: 4.845888]\n",
      "epoch:47 step:37240 [D loss: 0.089839, acc: 98.44%] [G loss: 6.738323]\n",
      "epoch:47 step:37241 [D loss: 0.958549, acc: 53.12%] [G loss: 6.053576]\n",
      "epoch:47 step:37242 [D loss: 0.208421, acc: 93.75%] [G loss: 6.819146]\n",
      "epoch:47 step:37243 [D loss: 0.193903, acc: 96.88%] [G loss: 5.999084]\n",
      "epoch:47 step:37244 [D loss: 0.442832, acc: 79.69%] [G loss: 9.509154]\n",
      "epoch:47 step:37245 [D loss: 0.034119, acc: 100.00%] [G loss: 6.046108]\n",
      "epoch:47 step:37246 [D loss: 0.257728, acc: 93.75%] [G loss: 6.749492]\n",
      "epoch:47 step:37247 [D loss: 0.359529, acc: 86.72%] [G loss: 7.131026]\n",
      "epoch:47 step:37248 [D loss: 0.020493, acc: 100.00%] [G loss: 9.625214]\n",
      "epoch:47 step:37249 [D loss: 0.018675, acc: 100.00%] [G loss: 2.689980]\n",
      "epoch:47 step:37250 [D loss: 0.654919, acc: 55.47%] [G loss: 8.240731]\n",
      "epoch:47 step:37251 [D loss: 0.351742, acc: 81.25%] [G loss: 6.490006]\n",
      "epoch:47 step:37252 [D loss: 0.092328, acc: 99.22%] [G loss: 3.920176]\n",
      "epoch:47 step:37253 [D loss: 0.042780, acc: 100.00%] [G loss: 5.210788]\n",
      "epoch:47 step:37254 [D loss: 0.025233, acc: 100.00%] [G loss: 6.904455]\n",
      "epoch:47 step:37255 [D loss: 0.086112, acc: 100.00%] [G loss: 5.086222]\n",
      "epoch:47 step:37256 [D loss: 0.216678, acc: 95.31%] [G loss: 7.464037]\n",
      "epoch:47 step:37257 [D loss: 0.044037, acc: 100.00%] [G loss: 7.950471]\n",
      "epoch:47 step:37258 [D loss: 0.078910, acc: 100.00%] [G loss: 6.536198]\n",
      "epoch:47 step:37259 [D loss: 0.090178, acc: 100.00%] [G loss: 6.253738]\n",
      "epoch:47 step:37260 [D loss: 0.319130, acc: 81.25%] [G loss: 6.280204]\n",
      "epoch:47 step:37261 [D loss: 0.471407, acc: 78.12%] [G loss: 9.356203]\n",
      "epoch:47 step:37262 [D loss: 0.021455, acc: 100.00%] [G loss: 9.471611]\n",
      "epoch:47 step:37263 [D loss: 0.530672, acc: 69.53%] [G loss: 7.214089]\n",
      "epoch:47 step:37264 [D loss: 0.296468, acc: 88.28%] [G loss: 5.002244]\n",
      "epoch:47 step:37265 [D loss: 0.292299, acc: 88.28%] [G loss: 8.231822]\n",
      "epoch:47 step:37266 [D loss: 0.025013, acc: 100.00%] [G loss: 3.881444]\n",
      "epoch:47 step:37267 [D loss: 0.273134, acc: 89.84%] [G loss: 9.031775]\n",
      "epoch:47 step:37268 [D loss: 0.029694, acc: 100.00%] [G loss: 7.850705]\n",
      "epoch:47 step:37269 [D loss: 0.618585, acc: 66.41%] [G loss: 4.589910]\n",
      "epoch:47 step:37270 [D loss: 0.264631, acc: 96.09%] [G loss: 4.129339]\n",
      "epoch:47 step:37271 [D loss: 0.126997, acc: 98.44%] [G loss: 3.726075]\n",
      "epoch:47 step:37272 [D loss: 0.052687, acc: 100.00%] [G loss: 8.732070]\n",
      "epoch:47 step:37273 [D loss: 0.240478, acc: 96.88%] [G loss: 7.545209]\n",
      "epoch:47 step:37274 [D loss: 0.668607, acc: 60.16%] [G loss: 6.154237]\n",
      "epoch:47 step:37275 [D loss: 0.064001, acc: 99.22%] [G loss: 4.868941]\n",
      "epoch:47 step:37276 [D loss: 1.129227, acc: 50.78%] [G loss: 8.381214]\n",
      "epoch:47 step:37277 [D loss: 0.268744, acc: 86.72%] [G loss: 6.803469]\n",
      "epoch:47 step:37278 [D loss: 0.637659, acc: 61.72%] [G loss: 9.536970]\n",
      "epoch:47 step:37279 [D loss: 0.310475, acc: 93.75%] [G loss: 7.948503]\n",
      "epoch:47 step:37280 [D loss: 0.073666, acc: 99.22%] [G loss: 6.934507]\n",
      "epoch:47 step:37281 [D loss: 0.068806, acc: 100.00%] [G loss: 5.394263]\n",
      "epoch:47 step:37282 [D loss: 0.037308, acc: 100.00%] [G loss: 7.882704]\n",
      "epoch:47 step:37283 [D loss: 0.265726, acc: 93.75%] [G loss: 5.304681]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:47 step:37284 [D loss: 0.462577, acc: 79.69%] [G loss: 7.291802]\n",
      "epoch:47 step:37285 [D loss: 0.015008, acc: 100.00%] [G loss: 6.051848]\n",
      "epoch:47 step:37286 [D loss: 0.958015, acc: 50.00%] [G loss: 8.301840]\n",
      "epoch:47 step:37287 [D loss: 0.112243, acc: 96.88%] [G loss: 6.498103]\n",
      "epoch:47 step:37288 [D loss: 0.410589, acc: 74.22%] [G loss: 6.970566]\n",
      "epoch:47 step:37289 [D loss: 0.396780, acc: 77.34%] [G loss: 7.196914]\n",
      "epoch:47 step:37290 [D loss: 0.238648, acc: 97.66%] [G loss: 4.910506]\n",
      "epoch:47 step:37291 [D loss: 0.269421, acc: 94.53%] [G loss: 6.083055]\n",
      "epoch:47 step:37292 [D loss: 0.120024, acc: 98.44%] [G loss: 8.465730]\n",
      "epoch:47 step:37293 [D loss: 0.067978, acc: 100.00%] [G loss: 10.442179]\n",
      "epoch:47 step:37294 [D loss: 0.042642, acc: 100.00%] [G loss: 4.503998]\n",
      "epoch:47 step:37295 [D loss: 0.542975, acc: 64.84%] [G loss: 8.000137]\n",
      "epoch:47 step:37296 [D loss: 0.709529, acc: 57.81%] [G loss: 8.020348]\n",
      "epoch:47 step:37297 [D loss: 0.076767, acc: 98.44%] [G loss: 9.369656]\n",
      "epoch:47 step:37298 [D loss: 0.661599, acc: 54.69%] [G loss: 9.583849]\n",
      "epoch:47 step:37299 [D loss: 0.080897, acc: 100.00%] [G loss: 6.468728]\n",
      "epoch:47 step:37300 [D loss: 0.184736, acc: 98.44%] [G loss: 5.894192]\n",
      "epoch:47 step:37301 [D loss: 0.141602, acc: 96.88%] [G loss: 5.267792]\n",
      "epoch:47 step:37302 [D loss: 0.317364, acc: 91.41%] [G loss: 6.716846]\n",
      "epoch:47 step:37303 [D loss: 0.521948, acc: 73.44%] [G loss: 8.255209]\n",
      "epoch:47 step:37304 [D loss: 0.154677, acc: 97.66%] [G loss: 4.668366]\n",
      "epoch:47 step:37305 [D loss: 0.205504, acc: 96.88%] [G loss: 7.121660]\n",
      "epoch:47 step:37306 [D loss: 0.047860, acc: 100.00%] [G loss: 4.002611]\n",
      "epoch:47 step:37307 [D loss: 0.083603, acc: 100.00%] [G loss: 5.269532]\n",
      "epoch:47 step:37308 [D loss: 0.004029, acc: 100.00%] [G loss: 9.198532]\n",
      "epoch:47 step:37309 [D loss: 0.350476, acc: 86.72%] [G loss: 8.371873]\n",
      "epoch:47 step:37310 [D loss: 0.101673, acc: 99.22%] [G loss: 5.391884]\n",
      "epoch:47 step:37311 [D loss: 0.137775, acc: 97.66%] [G loss: 3.158208]\n",
      "epoch:47 step:37312 [D loss: 0.671756, acc: 54.69%] [G loss: 7.126323]\n",
      "epoch:47 step:37313 [D loss: 0.061195, acc: 100.00%] [G loss: 6.572830]\n",
      "epoch:47 step:37314 [D loss: 0.615938, acc: 61.72%] [G loss: 8.685733]\n",
      "epoch:47 step:37315 [D loss: 0.150940, acc: 96.88%] [G loss: 5.947700]\n",
      "epoch:47 step:37316 [D loss: 0.371188, acc: 82.81%] [G loss: 6.956156]\n",
      "epoch:47 step:37317 [D loss: 0.668165, acc: 62.50%] [G loss: 6.099801]\n",
      "epoch:47 step:37318 [D loss: 0.025761, acc: 100.00%] [G loss: 5.423053]\n",
      "epoch:47 step:37319 [D loss: 0.329099, acc: 82.81%] [G loss: 8.357890]\n",
      "epoch:47 step:37320 [D loss: 0.106591, acc: 100.00%] [G loss: 5.485434]\n",
      "epoch:47 step:37321 [D loss: 0.099892, acc: 100.00%] [G loss: 6.283994]\n",
      "epoch:47 step:37322 [D loss: 0.127570, acc: 99.22%] [G loss: 4.451648]\n",
      "epoch:47 step:37323 [D loss: 0.189135, acc: 93.75%] [G loss: 4.333757]\n",
      "epoch:47 step:37324 [D loss: 0.146276, acc: 99.22%] [G loss: 8.357660]\n",
      "epoch:47 step:37325 [D loss: 0.642585, acc: 60.94%] [G loss: 9.110920]\n",
      "epoch:47 step:37326 [D loss: 0.173866, acc: 96.88%] [G loss: 4.630997]\n",
      "epoch:47 step:37327 [D loss: 0.068185, acc: 100.00%] [G loss: 6.798402]\n",
      "epoch:47 step:37328 [D loss: 0.708247, acc: 56.25%] [G loss: 5.901500]\n",
      "epoch:47 step:37329 [D loss: 0.223093, acc: 94.53%] [G loss: 5.117387]\n",
      "epoch:47 step:37330 [D loss: 0.297406, acc: 83.59%] [G loss: 7.534623]\n",
      "epoch:47 step:37331 [D loss: 0.082473, acc: 99.22%] [G loss: 7.162228]\n",
      "epoch:47 step:37332 [D loss: 0.200394, acc: 96.09%] [G loss: 5.290585]\n",
      "epoch:47 step:37333 [D loss: 0.597877, acc: 62.50%] [G loss: 5.087041]\n",
      "epoch:47 step:37334 [D loss: 0.417612, acc: 82.03%] [G loss: 8.677297]\n",
      "epoch:47 step:37335 [D loss: 0.278436, acc: 89.84%] [G loss: 10.103764]\n",
      "epoch:47 step:37336 [D loss: 0.115403, acc: 99.22%] [G loss: 9.624763]\n",
      "epoch:47 step:37337 [D loss: 0.041997, acc: 99.22%] [G loss: 10.747419]\n",
      "epoch:47 step:37338 [D loss: 0.077176, acc: 100.00%] [G loss: 7.157667]\n",
      "epoch:47 step:37339 [D loss: 0.459692, acc: 71.88%] [G loss: 6.937880]\n",
      "epoch:47 step:37340 [D loss: 0.149364, acc: 100.00%] [G loss: 3.769722]\n",
      "epoch:47 step:37341 [D loss: 0.188148, acc: 96.09%] [G loss: 4.606618]\n",
      "epoch:47 step:37342 [D loss: 0.070034, acc: 100.00%] [G loss: 6.690016]\n",
      "epoch:47 step:37343 [D loss: 0.291275, acc: 95.31%] [G loss: 2.781746]\n",
      "epoch:47 step:37344 [D loss: 0.149519, acc: 100.00%] [G loss: 7.389427]\n",
      "epoch:47 step:37345 [D loss: 0.593235, acc: 60.94%] [G loss: 7.139446]\n",
      "epoch:47 step:37346 [D loss: 0.098068, acc: 100.00%] [G loss: 5.347072]\n",
      "epoch:47 step:37347 [D loss: 0.036240, acc: 100.00%] [G loss: 4.370922]\n",
      "epoch:47 step:37348 [D loss: 0.019974, acc: 100.00%] [G loss: 5.962068]\n",
      "epoch:47 step:37349 [D loss: 0.187910, acc: 93.75%] [G loss: 11.230793]\n",
      "epoch:47 step:37350 [D loss: 0.342192, acc: 93.75%] [G loss: 3.497611]\n",
      "epoch:47 step:37351 [D loss: 0.119733, acc: 98.44%] [G loss: 7.364758]\n",
      "epoch:47 step:37352 [D loss: 0.063249, acc: 100.00%] [G loss: 5.574221]\n",
      "epoch:47 step:37353 [D loss: 0.120302, acc: 99.22%] [G loss: 5.292629]\n",
      "epoch:47 step:37354 [D loss: 0.156057, acc: 98.44%] [G loss: 5.750278]\n",
      "epoch:47 step:37355 [D loss: 0.109776, acc: 99.22%] [G loss: 5.588336]\n",
      "epoch:47 step:37356 [D loss: 0.337648, acc: 88.28%] [G loss: 2.764373]\n",
      "epoch:47 step:37357 [D loss: 0.027461, acc: 100.00%] [G loss: 8.779404]\n",
      "epoch:47 step:37358 [D loss: 3.093148, acc: 50.00%] [G loss: 5.015611]\n",
      "epoch:47 step:37359 [D loss: 0.383657, acc: 89.06%] [G loss: 5.224147]\n",
      "epoch:47 step:37360 [D loss: 0.008862, acc: 100.00%] [G loss: 4.927936]\n",
      "epoch:47 step:37361 [D loss: 0.176622, acc: 96.09%] [G loss: 7.198146]\n",
      "epoch:47 step:37362 [D loss: 0.350266, acc: 78.12%] [G loss: 4.740464]\n",
      "epoch:47 step:37363 [D loss: 0.032785, acc: 100.00%] [G loss: 6.403975]\n",
      "epoch:47 step:37364 [D loss: 0.205881, acc: 98.44%] [G loss: 5.888037]\n",
      "epoch:47 step:37365 [D loss: 0.209147, acc: 94.53%] [G loss: 4.124286]\n",
      "epoch:47 step:37366 [D loss: 0.094810, acc: 100.00%] [G loss: 5.395319]\n",
      "epoch:47 step:37367 [D loss: 0.080518, acc: 100.00%] [G loss: 5.368812]\n",
      "epoch:47 step:37368 [D loss: 0.509673, acc: 60.94%] [G loss: 3.218184]\n",
      "epoch:47 step:37369 [D loss: 0.172952, acc: 97.66%] [G loss: 5.620647]\n",
      "epoch:47 step:37370 [D loss: 0.458482, acc: 66.41%] [G loss: 7.636133]\n",
      "epoch:47 step:37371 [D loss: 1.704967, acc: 5.47%] [G loss: 6.778653]\n",
      "epoch:47 step:37372 [D loss: 0.463086, acc: 71.88%] [G loss: 6.337667]\n",
      "epoch:47 step:37373 [D loss: 0.160238, acc: 100.00%] [G loss: 3.540085]\n",
      "epoch:47 step:37374 [D loss: 0.007682, acc: 100.00%] [G loss: 7.877211]\n",
      "epoch:47 step:37375 [D loss: 0.346295, acc: 82.03%] [G loss: 10.902013]\n",
      "epoch:47 step:37376 [D loss: 0.151845, acc: 97.66%] [G loss: 6.644277]\n",
      "epoch:47 step:37377 [D loss: 0.142823, acc: 98.44%] [G loss: 5.226063]\n",
      "epoch:47 step:37378 [D loss: 0.057995, acc: 100.00%] [G loss: 5.693583]\n",
      "epoch:47 step:37379 [D loss: 0.346505, acc: 85.16%] [G loss: 5.377702]\n",
      "epoch:47 step:37380 [D loss: 0.406723, acc: 72.66%] [G loss: 7.477815]\n",
      "epoch:47 step:37381 [D loss: 0.029113, acc: 100.00%] [G loss: 3.527225]\n",
      "epoch:47 step:37382 [D loss: 0.134733, acc: 100.00%] [G loss: 6.990762]\n",
      "epoch:47 step:37383 [D loss: 0.099510, acc: 99.22%] [G loss: 3.797461]\n",
      "epoch:47 step:37384 [D loss: 0.586931, acc: 64.06%] [G loss: 7.702384]\n",
      "epoch:47 step:37385 [D loss: 0.192009, acc: 92.97%] [G loss: 7.450872]\n",
      "epoch:47 step:37386 [D loss: 2.187818, acc: 50.00%] [G loss: 7.861090]\n",
      "epoch:47 step:37387 [D loss: 0.079854, acc: 100.00%] [G loss: 6.546239]\n",
      "epoch:47 step:37388 [D loss: 0.816186, acc: 51.56%] [G loss: 4.864568]\n",
      "epoch:47 step:37389 [D loss: 0.056783, acc: 99.22%] [G loss: 6.531715]\n",
      "epoch:47 step:37390 [D loss: 0.130664, acc: 100.00%] [G loss: 5.615236]\n",
      "epoch:47 step:37391 [D loss: 0.036545, acc: 100.00%] [G loss: 8.173146]\n",
      "epoch:47 step:37392 [D loss: 0.098117, acc: 98.44%] [G loss: 5.306088]\n",
      "epoch:47 step:37393 [D loss: 0.080543, acc: 99.22%] [G loss: 8.199851]\n",
      "epoch:47 step:37394 [D loss: 1.238864, acc: 49.22%] [G loss: 10.838081]\n",
      "epoch:47 step:37395 [D loss: 0.105759, acc: 100.00%] [G loss: 7.057496]\n",
      "epoch:47 step:37396 [D loss: 0.136988, acc: 96.88%] [G loss: 8.076222]\n",
      "epoch:47 step:37397 [D loss: 0.124507, acc: 98.44%] [G loss: 8.123033]\n",
      "epoch:47 step:37398 [D loss: 0.380158, acc: 82.03%] [G loss: 7.855267]\n",
      "epoch:47 step:37399 [D loss: 0.003214, acc: 100.00%] [G loss: 7.032422]\n",
      "epoch:47 step:37400 [D loss: 0.225008, acc: 92.19%] [G loss: 6.202708]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##############\n",
      "[0.86369252 0.86820841 0.82091977 0.80651701 0.7935698  0.82142762\n",
      " 0.88200691 0.82847589 0.8012142  0.82274595]\n",
      "##########\n",
      "epoch:47 step:37401 [D loss: 0.204477, acc: 94.53%] [G loss: 3.166763]\n",
      "epoch:47 step:37402 [D loss: 0.006616, acc: 100.00%] [G loss: 7.489242]\n",
      "epoch:47 step:37403 [D loss: 0.334334, acc: 82.03%] [G loss: 5.043569]\n",
      "epoch:47 step:37404 [D loss: 0.144501, acc: 100.00%] [G loss: 4.131389]\n",
      "epoch:47 step:37405 [D loss: 0.144424, acc: 100.00%] [G loss: 9.470940]\n",
      "epoch:47 step:37406 [D loss: 0.281051, acc: 85.16%] [G loss: 8.755530]\n",
      "epoch:47 step:37407 [D loss: 0.176651, acc: 99.22%] [G loss: 5.475409]\n",
      "epoch:47 step:37408 [D loss: 0.162576, acc: 96.09%] [G loss: 4.273707]\n",
      "epoch:47 step:37409 [D loss: 0.149821, acc: 99.22%] [G loss: 6.015162]\n",
      "epoch:47 step:37410 [D loss: 0.438891, acc: 79.69%] [G loss: 4.757392]\n",
      "epoch:47 step:37411 [D loss: 0.057503, acc: 100.00%] [G loss: 7.090505]\n",
      "epoch:47 step:37412 [D loss: 0.030299, acc: 100.00%] [G loss: 5.369012]\n",
      "epoch:47 step:37413 [D loss: 0.296717, acc: 92.19%] [G loss: 7.781728]\n",
      "epoch:47 step:37414 [D loss: 0.347717, acc: 90.62%] [G loss: 9.847123]\n",
      "epoch:47 step:37415 [D loss: 0.012798, acc: 100.00%] [G loss: 5.884094]\n",
      "epoch:47 step:37416 [D loss: 0.036725, acc: 99.22%] [G loss: 7.059223]\n",
      "epoch:47 step:37417 [D loss: 0.939681, acc: 45.31%] [G loss: 7.482283]\n",
      "epoch:47 step:37418 [D loss: 0.236419, acc: 89.84%] [G loss: 6.044440]\n",
      "epoch:47 step:37419 [D loss: 0.181395, acc: 98.44%] [G loss: 9.427544]\n",
      "epoch:47 step:37420 [D loss: 0.029037, acc: 99.22%] [G loss: 9.055140]\n",
      "epoch:47 step:37421 [D loss: 0.324289, acc: 78.91%] [G loss: 14.141500]\n",
      "epoch:47 step:37422 [D loss: 0.226991, acc: 92.19%] [G loss: 5.072280]\n",
      "epoch:47 step:37423 [D loss: 0.005288, acc: 100.00%] [G loss: 3.358362]\n",
      "epoch:47 step:37424 [D loss: 0.039403, acc: 100.00%] [G loss: 8.471702]\n",
      "epoch:47 step:37425 [D loss: 0.111550, acc: 99.22%] [G loss: 8.680006]\n",
      "epoch:47 step:37426 [D loss: 0.148636, acc: 99.22%] [G loss: 4.363870]\n",
      "epoch:47 step:37427 [D loss: 0.287275, acc: 86.72%] [G loss: 7.602298]\n",
      "epoch:47 step:37428 [D loss: 0.195671, acc: 92.97%] [G loss: 7.314700]\n",
      "epoch:47 step:37429 [D loss: 0.138415, acc: 99.22%] [G loss: 4.593545]\n",
      "epoch:47 step:37430 [D loss: 0.044768, acc: 100.00%] [G loss: 11.288967]\n",
      "epoch:47 step:37431 [D loss: 0.051557, acc: 100.00%] [G loss: 3.677121]\n",
      "epoch:47 step:37432 [D loss: 0.230247, acc: 92.97%] [G loss: 4.503361]\n",
      "epoch:47 step:37433 [D loss: 0.021929, acc: 100.00%] [G loss: 5.840808]\n",
      "epoch:47 step:37434 [D loss: 0.029035, acc: 100.00%] [G loss: 4.863421]\n",
      "epoch:47 step:37435 [D loss: 0.238151, acc: 93.75%] [G loss: 9.861335]\n",
      "epoch:47 step:37436 [D loss: 0.512583, acc: 69.53%] [G loss: 5.063373]\n",
      "epoch:47 step:37437 [D loss: 0.028759, acc: 100.00%] [G loss: 4.856599]\n",
      "epoch:47 step:37438 [D loss: 0.318009, acc: 87.50%] [G loss: 4.286281]\n",
      "epoch:47 step:37439 [D loss: 0.045122, acc: 100.00%] [G loss: 5.179418]\n",
      "epoch:47 step:37440 [D loss: 0.156787, acc: 100.00%] [G loss: 7.073944]\n",
      "epoch:47 step:37441 [D loss: 0.749396, acc: 56.25%] [G loss: 11.616426]\n",
      "epoch:47 step:37442 [D loss: 0.211836, acc: 96.09%] [G loss: 3.649629]\n",
      "epoch:47 step:37443 [D loss: 0.122477, acc: 98.44%] [G loss: 7.487732]\n",
      "epoch:47 step:37444 [D loss: 0.371026, acc: 81.25%] [G loss: 6.308041]\n",
      "epoch:47 step:37445 [D loss: 1.151905, acc: 44.53%] [G loss: 7.393179]\n",
      "epoch:47 step:37446 [D loss: 0.212339, acc: 92.97%] [G loss: 8.038166]\n",
      "epoch:47 step:37447 [D loss: 1.467181, acc: 50.00%] [G loss: 14.305230]\n",
      "epoch:47 step:37448 [D loss: 0.063121, acc: 100.00%] [G loss: 4.005509]\n",
      "epoch:47 step:37449 [D loss: 0.925394, acc: 50.78%] [G loss: 7.388570]\n",
      "epoch:47 step:37450 [D loss: 0.002773, acc: 100.00%] [G loss: 6.376890]\n",
      "epoch:47 step:37451 [D loss: 0.386123, acc: 76.56%] [G loss: 6.288769]\n",
      "epoch:47 step:37452 [D loss: 0.371689, acc: 87.50%] [G loss: 7.628049]\n",
      "epoch:47 step:37453 [D loss: 0.246462, acc: 91.41%] [G loss: 7.834385]\n",
      "epoch:47 step:37454 [D loss: 0.006101, acc: 100.00%] [G loss: 9.662702]\n",
      "epoch:47 step:37455 [D loss: 0.155347, acc: 98.44%] [G loss: 5.004624]\n",
      "epoch:47 step:37456 [D loss: 0.176953, acc: 96.88%] [G loss: 4.185221]\n",
      "epoch:47 step:37457 [D loss: 0.223167, acc: 92.97%] [G loss: 7.398587]\n",
      "epoch:47 step:37458 [D loss: 0.227237, acc: 94.53%] [G loss: 7.819738]\n",
      "epoch:47 step:37459 [D loss: 0.014833, acc: 100.00%] [G loss: 5.482370]\n",
      "epoch:47 step:37460 [D loss: 0.289569, acc: 85.16%] [G loss: 6.978896]\n",
      "epoch:47 step:37461 [D loss: 0.105144, acc: 100.00%] [G loss: 4.069942]\n",
      "epoch:47 step:37462 [D loss: 0.037270, acc: 100.00%] [G loss: 7.348198]\n",
      "epoch:47 step:37463 [D loss: 1.124164, acc: 23.44%] [G loss: 12.399972]\n",
      "epoch:47 step:37464 [D loss: 0.018620, acc: 100.00%] [G loss: 6.335512]\n",
      "epoch:47 step:37465 [D loss: 0.081947, acc: 98.44%] [G loss: 5.746343]\n",
      "epoch:47 step:37466 [D loss: 0.157048, acc: 97.66%] [G loss: 5.424103]\n",
      "epoch:47 step:37467 [D loss: 0.015005, acc: 100.00%] [G loss: 9.139425]\n",
      "epoch:47 step:37468 [D loss: 0.006297, acc: 100.00%] [G loss: 6.949613]\n",
      "epoch:47 step:37469 [D loss: 0.274748, acc: 88.28%] [G loss: 7.616096]\n",
      "epoch:47 step:37470 [D loss: 0.064565, acc: 100.00%] [G loss: 7.126959]\n",
      "epoch:47 step:37471 [D loss: 0.510326, acc: 75.00%] [G loss: 4.590949]\n",
      "epoch:47 step:37472 [D loss: 0.003807, acc: 100.00%] [G loss: 7.698387]\n",
      "epoch:47 step:37473 [D loss: 1.991806, acc: 46.09%] [G loss: 7.698366]\n",
      "epoch:47 step:37474 [D loss: 0.888425, acc: 50.78%] [G loss: 6.060206]\n",
      "epoch:47 step:37475 [D loss: 0.012523, acc: 100.00%] [G loss: 8.049500]\n",
      "epoch:47 step:37476 [D loss: 0.247910, acc: 92.97%] [G loss: 4.740073]\n",
      "epoch:47 step:37477 [D loss: 0.216633, acc: 92.19%] [G loss: 9.563046]\n",
      "epoch:47 step:37478 [D loss: 0.438480, acc: 76.56%] [G loss: 6.141562]\n",
      "epoch:47 step:37479 [D loss: 0.568585, acc: 61.72%] [G loss: 7.591326]\n",
      "epoch:47 step:37480 [D loss: 0.000435, acc: 100.00%] [G loss: 8.337219]\n",
      "epoch:47 step:37481 [D loss: 0.038922, acc: 99.22%] [G loss: 5.593131]\n",
      "epoch:47 step:37482 [D loss: 0.264705, acc: 96.88%] [G loss: 7.581022]\n",
      "epoch:47 step:37483 [D loss: 0.286560, acc: 92.19%] [G loss: 5.325870]\n",
      "epoch:47 step:37484 [D loss: 0.046074, acc: 99.22%] [G loss: 4.398232]\n",
      "epoch:47 step:37485 [D loss: 0.688408, acc: 57.03%] [G loss: 6.663119]\n",
      "epoch:47 step:37486 [D loss: 0.040403, acc: 100.00%] [G loss: 11.412939]\n",
      "epoch:47 step:37487 [D loss: 1.833265, acc: 50.00%] [G loss: 8.299482]\n",
      "epoch:47 step:37488 [D loss: 0.407034, acc: 83.59%] [G loss: 5.361587]\n",
      "epoch:48 step:37489 [D loss: 0.293614, acc: 85.16%] [G loss: 7.106696]\n",
      "epoch:48 step:37490 [D loss: 0.158172, acc: 98.44%] [G loss: 5.192307]\n",
      "epoch:48 step:37491 [D loss: 1.637746, acc: 46.88%] [G loss: 9.305423]\n",
      "epoch:48 step:37492 [D loss: 0.022298, acc: 100.00%] [G loss: 6.633140]\n",
      "epoch:48 step:37493 [D loss: 0.085790, acc: 100.00%] [G loss: 5.332373]\n",
      "epoch:48 step:37494 [D loss: 0.262627, acc: 90.62%] [G loss: 5.821229]\n",
      "epoch:48 step:37495 [D loss: 0.199918, acc: 95.31%] [G loss: 5.696530]\n",
      "epoch:48 step:37496 [D loss: 0.041254, acc: 100.00%] [G loss: 6.298420]\n",
      "epoch:48 step:37497 [D loss: 0.052416, acc: 99.22%] [G loss: 6.062424]\n",
      "epoch:48 step:37498 [D loss: 0.180169, acc: 94.53%] [G loss: 6.796271]\n",
      "epoch:48 step:37499 [D loss: 0.134785, acc: 98.44%] [G loss: 6.008861]\n",
      "epoch:48 step:37500 [D loss: 0.261331, acc: 89.06%] [G loss: 5.690869]\n",
      "epoch:48 step:37501 [D loss: 0.041753, acc: 100.00%] [G loss: 4.731383]\n",
      "epoch:48 step:37502 [D loss: 0.026317, acc: 100.00%] [G loss: 7.524027]\n",
      "epoch:48 step:37503 [D loss: 1.102925, acc: 52.34%] [G loss: 4.651027]\n",
      "epoch:48 step:37504 [D loss: 0.489993, acc: 67.19%] [G loss: 10.161422]\n",
      "epoch:48 step:37505 [D loss: 0.393760, acc: 87.50%] [G loss: 4.679672]\n",
      "epoch:48 step:37506 [D loss: 0.082032, acc: 100.00%] [G loss: 11.396721]\n",
      "epoch:48 step:37507 [D loss: 0.300871, acc: 84.38%] [G loss: 6.363576]\n",
      "epoch:48 step:37508 [D loss: 0.096143, acc: 100.00%] [G loss: 8.211828]\n",
      "epoch:48 step:37509 [D loss: 0.022766, acc: 100.00%] [G loss: 7.156698]\n",
      "epoch:48 step:37510 [D loss: 0.171850, acc: 98.44%] [G loss: 7.211073]\n",
      "epoch:48 step:37511 [D loss: 0.185021, acc: 92.97%] [G loss: 6.650929]\n",
      "epoch:48 step:37512 [D loss: 1.001796, acc: 51.56%] [G loss: 4.503312]\n",
      "epoch:48 step:37513 [D loss: 0.136337, acc: 98.44%] [G loss: 7.740034]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:48 step:37514 [D loss: 0.932857, acc: 52.34%] [G loss: 10.125059]\n",
      "epoch:48 step:37515 [D loss: 0.263909, acc: 92.97%] [G loss: 6.912609]\n",
      "epoch:48 step:37516 [D loss: 0.612406, acc: 59.38%] [G loss: 6.665191]\n",
      "epoch:48 step:37517 [D loss: 0.149676, acc: 97.66%] [G loss: 5.192183]\n",
      "epoch:48 step:37518 [D loss: 0.051056, acc: 100.00%] [G loss: 6.293174]\n",
      "epoch:48 step:37519 [D loss: 0.007070, acc: 100.00%] [G loss: 8.243599]\n",
      "epoch:48 step:37520 [D loss: 0.175704, acc: 96.09%] [G loss: 8.098057]\n",
      "epoch:48 step:37521 [D loss: 0.716731, acc: 60.16%] [G loss: 9.787868]\n",
      "epoch:48 step:37522 [D loss: 1.389511, acc: 50.00%] [G loss: 7.500962]\n",
      "epoch:48 step:37523 [D loss: 0.109000, acc: 97.66%] [G loss: 5.416262]\n",
      "epoch:48 step:37524 [D loss: 0.564990, acc: 61.72%] [G loss: 8.240633]\n",
      "epoch:48 step:37525 [D loss: 0.112157, acc: 100.00%] [G loss: 6.129649]\n",
      "epoch:48 step:37526 [D loss: 0.514174, acc: 75.00%] [G loss: 6.185561]\n",
      "epoch:48 step:37527 [D loss: 0.098975, acc: 98.44%] [G loss: 7.373857]\n",
      "epoch:48 step:37528 [D loss: 0.130209, acc: 100.00%] [G loss: 5.079645]\n",
      "epoch:48 step:37529 [D loss: 0.083017, acc: 99.22%] [G loss: 3.907442]\n",
      "epoch:48 step:37530 [D loss: 0.197410, acc: 99.22%] [G loss: 6.278372]\n",
      "epoch:48 step:37531 [D loss: 0.064397, acc: 100.00%] [G loss: 9.792381]\n",
      "epoch:48 step:37532 [D loss: 0.633533, acc: 60.94%] [G loss: 8.164573]\n",
      "epoch:48 step:37533 [D loss: 0.116215, acc: 98.44%] [G loss: 3.588444]\n",
      "epoch:48 step:37534 [D loss: 0.139242, acc: 97.66%] [G loss: 8.194137]\n",
      "epoch:48 step:37535 [D loss: 0.025080, acc: 100.00%] [G loss: 8.044136]\n",
      "epoch:48 step:37536 [D loss: 0.352363, acc: 89.84%] [G loss: 8.528549]\n",
      "epoch:48 step:37537 [D loss: 0.146741, acc: 97.66%] [G loss: 5.445652]\n",
      "epoch:48 step:37538 [D loss: 0.192064, acc: 92.19%] [G loss: 5.451220]\n",
      "epoch:48 step:37539 [D loss: 0.219837, acc: 96.09%] [G loss: 5.781087]\n",
      "epoch:48 step:37540 [D loss: 0.869604, acc: 52.34%] [G loss: 10.448391]\n",
      "epoch:48 step:37541 [D loss: 0.030700, acc: 100.00%] [G loss: 6.114505]\n",
      "epoch:48 step:37542 [D loss: 0.047318, acc: 100.00%] [G loss: 6.455844]\n",
      "epoch:48 step:37543 [D loss: 0.142223, acc: 99.22%] [G loss: 7.872255]\n",
      "epoch:48 step:37544 [D loss: 0.260366, acc: 89.84%] [G loss: 3.020563]\n",
      "epoch:48 step:37545 [D loss: 0.671662, acc: 58.59%] [G loss: 6.067654]\n",
      "epoch:48 step:37546 [D loss: 0.501527, acc: 71.88%] [G loss: 10.568449]\n",
      "epoch:48 step:37547 [D loss: 0.017691, acc: 100.00%] [G loss: 4.601335]\n",
      "epoch:48 step:37548 [D loss: 0.096373, acc: 97.66%] [G loss: 5.665030]\n",
      "epoch:48 step:37549 [D loss: 0.032731, acc: 100.00%] [G loss: 4.023827]\n",
      "epoch:48 step:37550 [D loss: 0.069289, acc: 99.22%] [G loss: 8.559937]\n",
      "epoch:48 step:37551 [D loss: 0.069207, acc: 99.22%] [G loss: 6.695755]\n",
      "epoch:48 step:37552 [D loss: 0.174896, acc: 99.22%] [G loss: 1.709482]\n",
      "epoch:48 step:37553 [D loss: 0.299080, acc: 86.72%] [G loss: 5.442768]\n",
      "epoch:48 step:37554 [D loss: 0.033608, acc: 100.00%] [G loss: 7.107752]\n",
      "epoch:48 step:37555 [D loss: 0.229316, acc: 98.44%] [G loss: 5.888325]\n",
      "epoch:48 step:37556 [D loss: 1.418688, acc: 50.78%] [G loss: 5.562355]\n",
      "epoch:48 step:37557 [D loss: 0.400485, acc: 75.00%] [G loss: 7.280433]\n",
      "epoch:48 step:37558 [D loss: 0.205337, acc: 93.75%] [G loss: 6.861793]\n",
      "epoch:48 step:37559 [D loss: 1.002616, acc: 49.22%] [G loss: 6.926259]\n",
      "epoch:48 step:37560 [D loss: 0.098629, acc: 100.00%] [G loss: 4.101479]\n",
      "epoch:48 step:37561 [D loss: 0.092628, acc: 100.00%] [G loss: 5.326400]\n",
      "epoch:48 step:37562 [D loss: 0.734054, acc: 57.81%] [G loss: 7.805895]\n",
      "epoch:48 step:37563 [D loss: 0.118690, acc: 99.22%] [G loss: 2.715072]\n",
      "epoch:48 step:37564 [D loss: 0.114763, acc: 100.00%] [G loss: 6.843962]\n",
      "epoch:48 step:37565 [D loss: 0.010476, acc: 100.00%] [G loss: 8.060785]\n",
      "epoch:48 step:37566 [D loss: 0.504073, acc: 75.78%] [G loss: 3.548557]\n",
      "epoch:48 step:37567 [D loss: 0.913362, acc: 50.78%] [G loss: 7.917502]\n",
      "epoch:48 step:37568 [D loss: 0.742992, acc: 53.12%] [G loss: 6.418519]\n",
      "epoch:48 step:37569 [D loss: 0.027666, acc: 100.00%] [G loss: 2.314155]\n",
      "epoch:48 step:37570 [D loss: 0.069656, acc: 100.00%] [G loss: 8.452953]\n",
      "epoch:48 step:37571 [D loss: 0.157393, acc: 99.22%] [G loss: 5.994158]\n",
      "epoch:48 step:37572 [D loss: 0.102330, acc: 98.44%] [G loss: 7.114079]\n",
      "epoch:48 step:37573 [D loss: 0.052388, acc: 100.00%] [G loss: 7.295706]\n",
      "epoch:48 step:37574 [D loss: 0.518058, acc: 75.78%] [G loss: 7.662865]\n",
      "epoch:48 step:37575 [D loss: 0.178433, acc: 99.22%] [G loss: 6.228815]\n",
      "epoch:48 step:37576 [D loss: 1.493960, acc: 50.00%] [G loss: 6.054293]\n",
      "epoch:48 step:37577 [D loss: 0.000994, acc: 100.00%] [G loss: 4.075857]\n",
      "epoch:48 step:37578 [D loss: 1.528375, acc: 46.09%] [G loss: 7.595482]\n",
      "epoch:48 step:37579 [D loss: 0.007653, acc: 100.00%] [G loss: 9.857527]\n",
      "epoch:48 step:37580 [D loss: 0.011545, acc: 100.00%] [G loss: 7.768806]\n",
      "epoch:48 step:37581 [D loss: 0.206997, acc: 93.75%] [G loss: 6.912791]\n",
      "epoch:48 step:37582 [D loss: 0.704927, acc: 54.69%] [G loss: 7.054670]\n",
      "epoch:48 step:37583 [D loss: 0.633580, acc: 67.19%] [G loss: 5.792520]\n",
      "epoch:48 step:37584 [D loss: 0.165058, acc: 96.09%] [G loss: 6.782286]\n",
      "epoch:48 step:37585 [D loss: 1.408213, acc: 50.78%] [G loss: 7.115787]\n",
      "epoch:48 step:37586 [D loss: 0.103702, acc: 100.00%] [G loss: 3.188699]\n",
      "epoch:48 step:37587 [D loss: 0.084524, acc: 100.00%] [G loss: 4.580614]\n",
      "epoch:48 step:37588 [D loss: 0.126813, acc: 97.66%] [G loss: 7.595426]\n",
      "epoch:48 step:37589 [D loss: 0.707862, acc: 52.34%] [G loss: 4.689198]\n",
      "epoch:48 step:37590 [D loss: 0.010499, acc: 100.00%] [G loss: 8.874928]\n",
      "epoch:48 step:37591 [D loss: 0.272106, acc: 82.81%] [G loss: 6.339440]\n",
      "epoch:48 step:37592 [D loss: 0.066297, acc: 100.00%] [G loss: 5.934829]\n",
      "epoch:48 step:37593 [D loss: 0.501305, acc: 74.22%] [G loss: 4.791078]\n",
      "epoch:48 step:37594 [D loss: 1.680979, acc: 48.44%] [G loss: 6.280634]\n",
      "epoch:48 step:37595 [D loss: 0.120704, acc: 98.44%] [G loss: 9.775992]\n",
      "epoch:48 step:37596 [D loss: 0.392926, acc: 81.25%] [G loss: 6.155497]\n",
      "epoch:48 step:37597 [D loss: 1.050306, acc: 51.56%] [G loss: 11.348879]\n",
      "epoch:48 step:37598 [D loss: 0.583845, acc: 60.16%] [G loss: 4.722500]\n",
      "epoch:48 step:37599 [D loss: 0.333670, acc: 82.81%] [G loss: 6.169731]\n",
      "epoch:48 step:37600 [D loss: 0.103016, acc: 98.44%] [G loss: 7.315136]\n",
      "##############\n",
      "[0.86082013 0.87206827 0.78971052 0.82966202 0.76937368 0.82291038\n",
      " 0.87906933 0.81610121 0.79491181 0.8132335 ]\n",
      "##########\n",
      "epoch:48 step:37601 [D loss: 0.254445, acc: 88.28%] [G loss: 6.839745]\n",
      "epoch:48 step:37602 [D loss: 0.158016, acc: 98.44%] [G loss: 5.466269]\n",
      "epoch:48 step:37603 [D loss: 0.606721, acc: 67.19%] [G loss: 7.520212]\n",
      "epoch:48 step:37604 [D loss: 0.474966, acc: 68.75%] [G loss: 6.210338]\n",
      "epoch:48 step:37605 [D loss: 0.125840, acc: 98.44%] [G loss: 5.958982]\n",
      "epoch:48 step:37606 [D loss: 0.024809, acc: 100.00%] [G loss: 6.130800]\n",
      "epoch:48 step:37607 [D loss: 0.051605, acc: 100.00%] [G loss: 9.012720]\n",
      "epoch:48 step:37608 [D loss: 0.006317, acc: 100.00%] [G loss: 8.696459]\n",
      "epoch:48 step:37609 [D loss: 0.536264, acc: 73.44%] [G loss: 8.876858]\n",
      "epoch:48 step:37610 [D loss: 0.018995, acc: 100.00%] [G loss: 12.136952]\n",
      "epoch:48 step:37611 [D loss: 0.086796, acc: 99.22%] [G loss: 5.942228]\n",
      "epoch:48 step:37612 [D loss: 0.025085, acc: 100.00%] [G loss: 9.245527]\n",
      "epoch:48 step:37613 [D loss: 0.161484, acc: 97.66%] [G loss: 10.756035]\n",
      "epoch:48 step:37614 [D loss: 0.120411, acc: 98.44%] [G loss: 3.371975]\n",
      "epoch:48 step:37615 [D loss: 0.891896, acc: 38.28%] [G loss: 11.095453]\n",
      "epoch:48 step:37616 [D loss: 1.334471, acc: 50.00%] [G loss: 5.777057]\n",
      "epoch:48 step:37617 [D loss: 0.371520, acc: 75.78%] [G loss: 7.127997]\n",
      "epoch:48 step:37618 [D loss: 0.193413, acc: 94.53%] [G loss: 6.778116]\n",
      "epoch:48 step:37619 [D loss: 0.080122, acc: 98.44%] [G loss: 7.210659]\n",
      "epoch:48 step:37620 [D loss: 0.128523, acc: 96.88%] [G loss: 3.850572]\n",
      "epoch:48 step:37621 [D loss: 0.168176, acc: 96.09%] [G loss: 7.615685]\n",
      "epoch:48 step:37622 [D loss: 0.027899, acc: 100.00%] [G loss: 9.788786]\n",
      "epoch:48 step:37623 [D loss: 0.084949, acc: 100.00%] [G loss: 9.555037]\n",
      "epoch:48 step:37624 [D loss: 0.045552, acc: 100.00%] [G loss: 6.536721]\n",
      "epoch:48 step:37625 [D loss: 0.504115, acc: 70.31%] [G loss: 6.641768]\n",
      "epoch:48 step:37626 [D loss: 1.393695, acc: 16.41%] [G loss: 7.965783]\n",
      "epoch:48 step:37627 [D loss: 0.249644, acc: 93.75%] [G loss: 4.308384]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:48 step:37628 [D loss: 0.498299, acc: 71.09%] [G loss: 7.583035]\n",
      "epoch:48 step:37629 [D loss: 0.066781, acc: 100.00%] [G loss: 5.984319]\n",
      "epoch:48 step:37630 [D loss: 0.692029, acc: 54.69%] [G loss: 11.895861]\n",
      "epoch:48 step:37631 [D loss: 0.560894, acc: 67.97%] [G loss: 5.396427]\n",
      "epoch:48 step:37632 [D loss: 0.439230, acc: 73.44%] [G loss: 4.587311]\n",
      "epoch:48 step:37633 [D loss: 0.219371, acc: 96.88%] [G loss: 5.677770]\n",
      "epoch:48 step:37634 [D loss: 0.136894, acc: 99.22%] [G loss: 6.649835]\n",
      "epoch:48 step:37635 [D loss: 0.037822, acc: 100.00%] [G loss: 9.791218]\n",
      "epoch:48 step:37636 [D loss: 0.086699, acc: 100.00%] [G loss: 5.938665]\n",
      "epoch:48 step:37637 [D loss: 0.103656, acc: 100.00%] [G loss: 7.246002]\n",
      "epoch:48 step:37638 [D loss: 0.104771, acc: 100.00%] [G loss: 5.976928]\n",
      "epoch:48 step:37639 [D loss: 0.574875, acc: 64.06%] [G loss: 7.384707]\n",
      "epoch:48 step:37640 [D loss: 0.043434, acc: 100.00%] [G loss: 5.374602]\n",
      "epoch:48 step:37641 [D loss: 0.637307, acc: 57.81%] [G loss: 10.734413]\n",
      "epoch:48 step:37642 [D loss: 0.013837, acc: 100.00%] [G loss: 12.372767]\n",
      "epoch:48 step:37643 [D loss: 0.097750, acc: 100.00%] [G loss: 8.102264]\n",
      "epoch:48 step:37644 [D loss: 0.046073, acc: 99.22%] [G loss: 3.271730]\n",
      "epoch:48 step:37645 [D loss: 0.379465, acc: 90.62%] [G loss: 6.514458]\n",
      "epoch:48 step:37646 [D loss: 0.034298, acc: 100.00%] [G loss: 5.076209]\n",
      "epoch:48 step:37647 [D loss: 0.113208, acc: 100.00%] [G loss: 7.439681]\n",
      "epoch:48 step:37648 [D loss: 0.334348, acc: 91.41%] [G loss: 7.637689]\n",
      "epoch:48 step:37649 [D loss: 0.806800, acc: 52.34%] [G loss: 11.055311]\n",
      "epoch:48 step:37650 [D loss: 0.035669, acc: 100.00%] [G loss: 6.634461]\n",
      "epoch:48 step:37651 [D loss: 1.297131, acc: 50.78%] [G loss: 8.139849]\n",
      "epoch:48 step:37652 [D loss: 0.085712, acc: 99.22%] [G loss: 8.711170]\n",
      "epoch:48 step:37653 [D loss: 0.739235, acc: 56.25%] [G loss: 3.472583]\n",
      "epoch:48 step:37654 [D loss: 0.136783, acc: 99.22%] [G loss: 8.387317]\n",
      "epoch:48 step:37655 [D loss: 0.354063, acc: 89.06%] [G loss: 4.825132]\n",
      "epoch:48 step:37656 [D loss: 0.640237, acc: 58.59%] [G loss: 9.113869]\n",
      "epoch:48 step:37657 [D loss: 1.288408, acc: 50.00%] [G loss: 4.302011]\n",
      "epoch:48 step:37658 [D loss: 0.407100, acc: 84.38%] [G loss: 8.640377]\n",
      "epoch:48 step:37659 [D loss: 1.206178, acc: 50.00%] [G loss: 7.826321]\n",
      "epoch:48 step:37660 [D loss: 0.263635, acc: 93.75%] [G loss: 10.315207]\n",
      "epoch:48 step:37661 [D loss: 0.401092, acc: 89.06%] [G loss: 4.085724]\n",
      "epoch:48 step:37662 [D loss: 0.246418, acc: 92.97%] [G loss: 4.478635]\n",
      "epoch:48 step:37663 [D loss: 0.278389, acc: 88.28%] [G loss: 6.735454]\n",
      "epoch:48 step:37664 [D loss: 0.017539, acc: 100.00%] [G loss: 6.321939]\n",
      "epoch:48 step:37665 [D loss: 0.140005, acc: 96.88%] [G loss: 7.166091]\n",
      "epoch:48 step:37666 [D loss: 0.358573, acc: 78.12%] [G loss: 3.605551]\n",
      "epoch:48 step:37667 [D loss: 0.936728, acc: 49.22%] [G loss: 8.218283]\n",
      "epoch:48 step:37668 [D loss: 0.030467, acc: 100.00%] [G loss: 6.831123]\n",
      "epoch:48 step:37669 [D loss: 0.501674, acc: 68.75%] [G loss: 5.843826]\n",
      "epoch:48 step:37670 [D loss: 0.037172, acc: 99.22%] [G loss: 9.446815]\n",
      "epoch:48 step:37671 [D loss: 0.687962, acc: 60.94%] [G loss: 5.198187]\n",
      "epoch:48 step:37672 [D loss: 0.091545, acc: 100.00%] [G loss: 5.095568]\n",
      "epoch:48 step:37673 [D loss: 0.087265, acc: 100.00%] [G loss: 3.401964]\n",
      "epoch:48 step:37674 [D loss: 0.623095, acc: 65.62%] [G loss: 4.785660]\n",
      "epoch:48 step:37675 [D loss: 0.723648, acc: 57.03%] [G loss: 5.007111]\n",
      "epoch:48 step:37676 [D loss: 0.013302, acc: 100.00%] [G loss: 4.669376]\n",
      "epoch:48 step:37677 [D loss: 0.012407, acc: 100.00%] [G loss: 9.560726]\n",
      "epoch:48 step:37678 [D loss: 0.066352, acc: 100.00%] [G loss: 8.094604]\n",
      "epoch:48 step:37679 [D loss: 0.380622, acc: 87.50%] [G loss: 6.243223]\n",
      "epoch:48 step:37680 [D loss: 0.189072, acc: 98.44%] [G loss: 6.193662]\n",
      "epoch:48 step:37681 [D loss: 0.016069, acc: 100.00%] [G loss: 5.834038]\n",
      "epoch:48 step:37682 [D loss: 0.143712, acc: 96.88%] [G loss: 6.711306]\n",
      "epoch:48 step:37683 [D loss: 0.625160, acc: 60.94%] [G loss: 7.795499]\n",
      "epoch:48 step:37684 [D loss: 0.108435, acc: 99.22%] [G loss: 4.482656]\n",
      "epoch:48 step:37685 [D loss: 0.080127, acc: 100.00%] [G loss: 7.878558]\n",
      "epoch:48 step:37686 [D loss: 0.048200, acc: 99.22%] [G loss: 9.059587]\n",
      "epoch:48 step:37687 [D loss: 0.041848, acc: 100.00%] [G loss: 5.810711]\n",
      "epoch:48 step:37688 [D loss: 0.324215, acc: 84.38%] [G loss: 8.961000]\n",
      "epoch:48 step:37689 [D loss: 0.223140, acc: 97.66%] [G loss: 3.901856]\n",
      "epoch:48 step:37690 [D loss: 0.356363, acc: 83.59%] [G loss: 2.372500]\n",
      "epoch:48 step:37691 [D loss: 0.145803, acc: 96.88%] [G loss: 6.617129]\n",
      "epoch:48 step:37692 [D loss: 0.301191, acc: 89.06%] [G loss: 9.431740]\n",
      "epoch:48 step:37693 [D loss: 0.510508, acc: 80.47%] [G loss: 7.106440]\n",
      "epoch:48 step:37694 [D loss: 0.088743, acc: 99.22%] [G loss: 7.224657]\n",
      "epoch:48 step:37695 [D loss: 0.276066, acc: 92.97%] [G loss: 6.543560]\n",
      "epoch:48 step:37696 [D loss: 0.263238, acc: 86.72%] [G loss: 4.137827]\n",
      "epoch:48 step:37697 [D loss: 0.573784, acc: 63.28%] [G loss: 7.692345]\n",
      "epoch:48 step:37698 [D loss: 1.026774, acc: 44.53%] [G loss: 5.717579]\n",
      "epoch:48 step:37699 [D loss: 0.043401, acc: 99.22%] [G loss: 7.670364]\n",
      "epoch:48 step:37700 [D loss: 0.012070, acc: 100.00%] [G loss: 10.694134]\n",
      "epoch:48 step:37701 [D loss: 0.249671, acc: 94.53%] [G loss: 7.340814]\n",
      "epoch:48 step:37702 [D loss: 0.375827, acc: 81.25%] [G loss: 4.618073]\n",
      "epoch:48 step:37703 [D loss: 0.216450, acc: 92.97%] [G loss: 9.267564]\n",
      "epoch:48 step:37704 [D loss: 0.074634, acc: 99.22%] [G loss: 9.266644]\n",
      "epoch:48 step:37705 [D loss: 0.027298, acc: 100.00%] [G loss: 5.617118]\n",
      "epoch:48 step:37706 [D loss: 0.554477, acc: 71.09%] [G loss: 5.099144]\n",
      "epoch:48 step:37707 [D loss: 0.496016, acc: 76.56%] [G loss: 8.846574]\n",
      "epoch:48 step:37708 [D loss: 0.072300, acc: 100.00%] [G loss: 6.098619]\n",
      "epoch:48 step:37709 [D loss: 0.984353, acc: 46.09%] [G loss: 7.647241]\n",
      "epoch:48 step:37710 [D loss: 0.026915, acc: 100.00%] [G loss: 5.752813]\n",
      "epoch:48 step:37711 [D loss: 0.030441, acc: 100.00%] [G loss: 8.640106]\n",
      "epoch:48 step:37712 [D loss: 0.022170, acc: 100.00%] [G loss: 7.089495]\n",
      "epoch:48 step:37713 [D loss: 0.663777, acc: 57.81%] [G loss: 5.453221]\n",
      "epoch:48 step:37714 [D loss: 0.236498, acc: 92.19%] [G loss: 12.124783]\n",
      "epoch:48 step:37715 [D loss: 0.301038, acc: 92.19%] [G loss: 6.546093]\n",
      "epoch:48 step:37716 [D loss: 0.040838, acc: 100.00%] [G loss: 13.354808]\n",
      "epoch:48 step:37717 [D loss: 0.083614, acc: 100.00%] [G loss: 8.327407]\n",
      "epoch:48 step:37718 [D loss: 0.416628, acc: 81.25%] [G loss: 5.714481]\n",
      "epoch:48 step:37719 [D loss: 0.271221, acc: 88.28%] [G loss: 6.603387]\n",
      "epoch:48 step:37720 [D loss: 0.530573, acc: 73.44%] [G loss: 4.320362]\n",
      "epoch:48 step:37721 [D loss: 0.086681, acc: 100.00%] [G loss: 8.553737]\n",
      "epoch:48 step:37722 [D loss: 0.624404, acc: 60.16%] [G loss: 3.175289]\n",
      "epoch:48 step:37723 [D loss: 0.192920, acc: 95.31%] [G loss: 7.277537]\n",
      "epoch:48 step:37724 [D loss: 0.083540, acc: 100.00%] [G loss: 6.320080]\n",
      "epoch:48 step:37725 [D loss: 0.203378, acc: 96.88%] [G loss: 4.713755]\n",
      "epoch:48 step:37726 [D loss: 0.224676, acc: 96.09%] [G loss: 7.796456]\n",
      "epoch:48 step:37727 [D loss: 0.858493, acc: 52.34%] [G loss: 8.332227]\n",
      "epoch:48 step:37728 [D loss: 0.022366, acc: 100.00%] [G loss: 5.530399]\n",
      "epoch:48 step:37729 [D loss: 0.056573, acc: 100.00%] [G loss: 5.781519]\n",
      "epoch:48 step:37730 [D loss: 0.027122, acc: 100.00%] [G loss: 9.407112]\n",
      "epoch:48 step:37731 [D loss: 0.386222, acc: 88.28%] [G loss: 5.164141]\n",
      "epoch:48 step:37732 [D loss: 0.934655, acc: 53.12%] [G loss: 4.116832]\n",
      "epoch:48 step:37733 [D loss: 0.026416, acc: 100.00%] [G loss: 9.111450]\n",
      "epoch:48 step:37734 [D loss: 1.286746, acc: 50.00%] [G loss: 11.637638]\n",
      "epoch:48 step:37735 [D loss: 0.935862, acc: 55.47%] [G loss: 5.628707]\n",
      "epoch:48 step:37736 [D loss: 0.330883, acc: 82.03%] [G loss: 7.050143]\n",
      "epoch:48 step:37737 [D loss: 0.031196, acc: 100.00%] [G loss: 8.949312]\n",
      "epoch:48 step:37738 [D loss: 0.133611, acc: 97.66%] [G loss: 7.965471]\n",
      "epoch:48 step:37739 [D loss: 0.453376, acc: 77.34%] [G loss: 3.933614]\n",
      "epoch:48 step:37740 [D loss: 0.285956, acc: 93.75%] [G loss: 3.938813]\n",
      "epoch:48 step:37741 [D loss: 0.183049, acc: 93.75%] [G loss: 8.312773]\n",
      "epoch:48 step:37742 [D loss: 0.263448, acc: 87.50%] [G loss: 7.204764]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:48 step:37743 [D loss: 0.167562, acc: 97.66%] [G loss: 8.284718]\n",
      "epoch:48 step:37744 [D loss: 0.113035, acc: 100.00%] [G loss: 5.198558]\n",
      "epoch:48 step:37745 [D loss: 0.205692, acc: 90.62%] [G loss: 4.452773]\n",
      "epoch:48 step:37746 [D loss: 0.079275, acc: 100.00%] [G loss: 5.265318]\n",
      "epoch:48 step:37747 [D loss: 0.756453, acc: 53.91%] [G loss: 14.403114]\n",
      "epoch:48 step:37748 [D loss: 1.056661, acc: 50.00%] [G loss: 6.233333]\n",
      "epoch:48 step:37749 [D loss: 0.085627, acc: 100.00%] [G loss: 6.358297]\n",
      "epoch:48 step:37750 [D loss: 0.203708, acc: 96.88%] [G loss: 9.140877]\n",
      "epoch:48 step:37751 [D loss: 0.495677, acc: 66.41%] [G loss: 9.371021]\n",
      "epoch:48 step:37752 [D loss: 0.089974, acc: 99.22%] [G loss: 7.310156]\n",
      "epoch:48 step:37753 [D loss: 0.680099, acc: 59.38%] [G loss: 5.289100]\n",
      "epoch:48 step:37754 [D loss: 0.214790, acc: 95.31%] [G loss: 5.023932]\n",
      "epoch:48 step:37755 [D loss: 1.410323, acc: 33.59%] [G loss: 8.220095]\n",
      "epoch:48 step:37756 [D loss: 0.341752, acc: 80.47%] [G loss: 7.719777]\n",
      "epoch:48 step:37757 [D loss: 0.160915, acc: 99.22%] [G loss: 5.902349]\n",
      "epoch:48 step:37758 [D loss: 0.148157, acc: 96.88%] [G loss: 5.874762]\n",
      "epoch:48 step:37759 [D loss: 0.380052, acc: 82.81%] [G loss: 3.613656]\n",
      "epoch:48 step:37760 [D loss: 0.077718, acc: 99.22%] [G loss: 7.133422]\n",
      "epoch:48 step:37761 [D loss: 0.247215, acc: 89.06%] [G loss: 7.964246]\n",
      "epoch:48 step:37762 [D loss: 0.075861, acc: 100.00%] [G loss: 7.363986]\n",
      "epoch:48 step:37763 [D loss: 0.061814, acc: 100.00%] [G loss: 4.299014]\n",
      "epoch:48 step:37764 [D loss: 0.155042, acc: 97.66%] [G loss: 4.852661]\n",
      "epoch:48 step:37765 [D loss: 0.208894, acc: 96.88%] [G loss: 5.272394]\n",
      "epoch:48 step:37766 [D loss: 0.337723, acc: 87.50%] [G loss: 4.283670]\n",
      "epoch:48 step:37767 [D loss: 0.081160, acc: 100.00%] [G loss: 7.319074]\n",
      "epoch:48 step:37768 [D loss: 0.610103, acc: 57.03%] [G loss: 6.195435]\n",
      "epoch:48 step:37769 [D loss: 0.037243, acc: 99.22%] [G loss: 11.085281]\n",
      "epoch:48 step:37770 [D loss: 0.110986, acc: 99.22%] [G loss: 4.743474]\n",
      "epoch:48 step:37771 [D loss: 0.184089, acc: 97.66%] [G loss: 7.363605]\n",
      "epoch:48 step:37772 [D loss: 0.725878, acc: 55.47%] [G loss: 4.085572]\n",
      "epoch:48 step:37773 [D loss: 0.072797, acc: 100.00%] [G loss: 8.634640]\n",
      "epoch:48 step:37774 [D loss: 0.065621, acc: 100.00%] [G loss: 7.191900]\n",
      "epoch:48 step:37775 [D loss: 0.101804, acc: 98.44%] [G loss: 10.187614]\n",
      "epoch:48 step:37776 [D loss: 0.041482, acc: 100.00%] [G loss: 5.998988]\n",
      "epoch:48 step:37777 [D loss: 0.038790, acc: 100.00%] [G loss: 7.566726]\n",
      "epoch:48 step:37778 [D loss: 0.123799, acc: 99.22%] [G loss: 7.627087]\n",
      "epoch:48 step:37779 [D loss: 0.233804, acc: 90.62%] [G loss: 5.325607]\n",
      "epoch:48 step:37780 [D loss: 0.062441, acc: 98.44%] [G loss: 10.334930]\n",
      "epoch:48 step:37781 [D loss: 0.297300, acc: 93.75%] [G loss: 2.528114]\n",
      "epoch:48 step:37782 [D loss: 0.138401, acc: 97.66%] [G loss: 5.961636]\n",
      "epoch:48 step:37783 [D loss: 0.847353, acc: 51.56%] [G loss: 4.062942]\n",
      "epoch:48 step:37784 [D loss: 0.197004, acc: 95.31%] [G loss: 7.948689]\n",
      "epoch:48 step:37785 [D loss: 0.768538, acc: 56.25%] [G loss: 5.665055]\n",
      "epoch:48 step:37786 [D loss: 0.049037, acc: 100.00%] [G loss: 10.718750]\n",
      "epoch:48 step:37787 [D loss: 0.127490, acc: 97.66%] [G loss: 6.847394]\n",
      "epoch:48 step:37788 [D loss: 0.082985, acc: 100.00%] [G loss: 7.814670]\n",
      "epoch:48 step:37789 [D loss: 0.686772, acc: 59.38%] [G loss: 9.270056]\n",
      "epoch:48 step:37790 [D loss: 0.156582, acc: 99.22%] [G loss: 6.084133]\n",
      "epoch:48 step:37791 [D loss: 0.396150, acc: 84.38%] [G loss: 6.445553]\n",
      "epoch:48 step:37792 [D loss: 0.108204, acc: 98.44%] [G loss: 6.600746]\n",
      "epoch:48 step:37793 [D loss: 0.495947, acc: 78.12%] [G loss: 9.937572]\n",
      "epoch:48 step:37794 [D loss: 0.041418, acc: 100.00%] [G loss: 11.509798]\n",
      "epoch:48 step:37795 [D loss: 0.061558, acc: 100.00%] [G loss: 8.630699]\n",
      "epoch:48 step:37796 [D loss: 0.689170, acc: 56.25%] [G loss: 7.010961]\n",
      "epoch:48 step:37797 [D loss: 0.149236, acc: 93.75%] [G loss: 3.319652]\n",
      "epoch:48 step:37798 [D loss: 0.998875, acc: 50.78%] [G loss: 2.531859]\n",
      "epoch:48 step:37799 [D loss: 0.712822, acc: 55.47%] [G loss: 8.101171]\n",
      "epoch:48 step:37800 [D loss: 0.136029, acc: 100.00%] [G loss: 8.120480]\n",
      "##############\n",
      "[0.84515958 0.87260774 0.82525005 0.81192656 0.78984665 0.82120687\n",
      " 0.89448448 0.84393149 0.83261231 0.81890406]\n",
      "##########\n",
      "epoch:48 step:37801 [D loss: 0.374704, acc: 78.91%] [G loss: 10.275579]\n",
      "epoch:48 step:37802 [D loss: 0.161604, acc: 96.88%] [G loss: 9.154008]\n",
      "epoch:48 step:37803 [D loss: 0.831802, acc: 53.12%] [G loss: 4.276024]\n",
      "epoch:48 step:37804 [D loss: 0.600829, acc: 59.38%] [G loss: 8.358157]\n",
      "epoch:48 step:37805 [D loss: 0.109835, acc: 99.22%] [G loss: 9.472361]\n",
      "epoch:48 step:37806 [D loss: 0.310737, acc: 85.94%] [G loss: 7.386355]\n",
      "epoch:48 step:37807 [D loss: 0.068815, acc: 100.00%] [G loss: 4.275253]\n",
      "epoch:48 step:37808 [D loss: 0.074566, acc: 100.00%] [G loss: 4.364928]\n",
      "epoch:48 step:37809 [D loss: 0.230120, acc: 96.88%] [G loss: 4.429852]\n",
      "epoch:48 step:37810 [D loss: 0.059508, acc: 100.00%] [G loss: 5.590858]\n",
      "epoch:48 step:37811 [D loss: 0.414254, acc: 84.38%] [G loss: 5.967878]\n",
      "epoch:48 step:37812 [D loss: 0.073496, acc: 99.22%] [G loss: 4.645562]\n",
      "epoch:48 step:37813 [D loss: 0.881806, acc: 50.78%] [G loss: 7.352321]\n",
      "epoch:48 step:37814 [D loss: 0.367846, acc: 84.38%] [G loss: 5.611203]\n",
      "epoch:48 step:37815 [D loss: 0.078868, acc: 99.22%] [G loss: 7.380237]\n",
      "epoch:48 step:37816 [D loss: 0.291126, acc: 92.97%] [G loss: 4.742215]\n",
      "epoch:48 step:37817 [D loss: 0.868530, acc: 56.25%] [G loss: 5.909090]\n",
      "epoch:48 step:37818 [D loss: 0.171094, acc: 96.88%] [G loss: 2.785649]\n",
      "epoch:48 step:37819 [D loss: 0.103672, acc: 99.22%] [G loss: 4.038876]\n",
      "epoch:48 step:37820 [D loss: 0.336620, acc: 88.28%] [G loss: 6.743681]\n",
      "epoch:48 step:37821 [D loss: 0.185200, acc: 95.31%] [G loss: 11.428976]\n",
      "epoch:48 step:37822 [D loss: 0.835848, acc: 51.56%] [G loss: 5.632822]\n",
      "epoch:48 step:37823 [D loss: 0.078667, acc: 99.22%] [G loss: 7.893272]\n",
      "epoch:48 step:37824 [D loss: 0.053884, acc: 100.00%] [G loss: 8.554440]\n",
      "epoch:48 step:37825 [D loss: 0.076196, acc: 100.00%] [G loss: 7.005414]\n",
      "epoch:48 step:37826 [D loss: 0.217643, acc: 96.88%] [G loss: 4.458652]\n",
      "epoch:48 step:37827 [D loss: 0.216629, acc: 92.97%] [G loss: 7.724610]\n",
      "epoch:48 step:37828 [D loss: 0.150491, acc: 99.22%] [G loss: 9.183784]\n",
      "epoch:48 step:37829 [D loss: 0.206536, acc: 92.97%] [G loss: 6.264678]\n",
      "epoch:48 step:37830 [D loss: 0.014697, acc: 100.00%] [G loss: 7.251645]\n",
      "epoch:48 step:37831 [D loss: 0.162957, acc: 95.31%] [G loss: 6.261807]\n",
      "epoch:48 step:37832 [D loss: 1.771613, acc: 6.25%] [G loss: 11.095705]\n",
      "epoch:48 step:37833 [D loss: 0.409790, acc: 79.69%] [G loss: 7.683322]\n",
      "epoch:48 step:37834 [D loss: 0.139646, acc: 99.22%] [G loss: 5.810352]\n",
      "epoch:48 step:37835 [D loss: 0.405153, acc: 86.72%] [G loss: 7.008642]\n",
      "epoch:48 step:37836 [D loss: 0.236712, acc: 94.53%] [G loss: 6.941185]\n",
      "epoch:48 step:37837 [D loss: 0.241329, acc: 97.66%] [G loss: 8.254021]\n",
      "epoch:48 step:37838 [D loss: 0.038516, acc: 100.00%] [G loss: 8.962979]\n",
      "epoch:48 step:37839 [D loss: 0.190351, acc: 91.41%] [G loss: 7.173888]\n",
      "epoch:48 step:37840 [D loss: 0.046095, acc: 100.00%] [G loss: 9.116481]\n",
      "epoch:48 step:37841 [D loss: 0.123162, acc: 100.00%] [G loss: 5.939794]\n",
      "epoch:48 step:37842 [D loss: 0.236935, acc: 94.53%] [G loss: 4.191978]\n",
      "epoch:48 step:37843 [D loss: 0.586246, acc: 64.06%] [G loss: 8.420592]\n",
      "epoch:48 step:37844 [D loss: 0.220288, acc: 96.88%] [G loss: 4.176243]\n",
      "epoch:48 step:37845 [D loss: 0.035498, acc: 100.00%] [G loss: 8.729506]\n",
      "epoch:48 step:37846 [D loss: 0.401298, acc: 87.50%] [G loss: 4.626846]\n",
      "epoch:48 step:37847 [D loss: 0.062858, acc: 99.22%] [G loss: 3.914262]\n",
      "epoch:48 step:37848 [D loss: 0.075840, acc: 100.00%] [G loss: 4.565910]\n",
      "epoch:48 step:37849 [D loss: 0.184529, acc: 96.88%] [G loss: 12.024744]\n",
      "epoch:48 step:37850 [D loss: 0.343272, acc: 78.12%] [G loss: 7.165882]\n",
      "epoch:48 step:37851 [D loss: 0.252512, acc: 95.31%] [G loss: 6.082113]\n",
      "epoch:48 step:37852 [D loss: 0.227186, acc: 96.09%] [G loss: 4.599261]\n",
      "epoch:48 step:37853 [D loss: 0.020846, acc: 100.00%] [G loss: 7.588705]\n",
      "epoch:48 step:37854 [D loss: 0.008075, acc: 100.00%] [G loss: 8.812846]\n",
      "epoch:48 step:37855 [D loss: 0.064990, acc: 100.00%] [G loss: 6.147030]\n",
      "epoch:48 step:37856 [D loss: 0.007834, acc: 100.00%] [G loss: 7.691050]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:48 step:37857 [D loss: 0.401206, acc: 84.38%] [G loss: 4.235101]\n",
      "epoch:48 step:37858 [D loss: 0.399316, acc: 89.06%] [G loss: 6.125442]\n",
      "epoch:48 step:37859 [D loss: 0.433675, acc: 83.59%] [G loss: 4.115504]\n",
      "epoch:48 step:37860 [D loss: 0.489857, acc: 76.56%] [G loss: 8.077453]\n",
      "epoch:48 step:37861 [D loss: 0.051174, acc: 100.00%] [G loss: 6.124699]\n",
      "epoch:48 step:37862 [D loss: 0.182557, acc: 97.66%] [G loss: 4.404652]\n",
      "epoch:48 step:37863 [D loss: 0.595806, acc: 54.69%] [G loss: 7.664956]\n",
      "epoch:48 step:37864 [D loss: 0.049838, acc: 100.00%] [G loss: 7.871402]\n",
      "epoch:48 step:37865 [D loss: 0.334333, acc: 84.38%] [G loss: 6.951498]\n",
      "epoch:48 step:37866 [D loss: 0.109925, acc: 98.44%] [G loss: 4.852724]\n",
      "epoch:48 step:37867 [D loss: 0.254904, acc: 92.97%] [G loss: 6.659424]\n",
      "epoch:48 step:37868 [D loss: 0.047065, acc: 100.00%] [G loss: 7.216786]\n",
      "epoch:48 step:37869 [D loss: 0.148260, acc: 97.66%] [G loss: 6.552585]\n",
      "epoch:48 step:37870 [D loss: 0.111984, acc: 97.66%] [G loss: 4.873939]\n",
      "epoch:48 step:37871 [D loss: 0.107089, acc: 99.22%] [G loss: 3.169631]\n",
      "epoch:48 step:37872 [D loss: 0.118979, acc: 98.44%] [G loss: 5.471615]\n",
      "epoch:48 step:37873 [D loss: 0.132731, acc: 99.22%] [G loss: 7.242241]\n",
      "epoch:48 step:37874 [D loss: 0.160983, acc: 96.88%] [G loss: 6.338018]\n",
      "epoch:48 step:37875 [D loss: 0.321412, acc: 78.12%] [G loss: 7.554126]\n",
      "epoch:48 step:37876 [D loss: 0.073939, acc: 100.00%] [G loss: 6.571305]\n",
      "epoch:48 step:37877 [D loss: 0.563457, acc: 64.06%] [G loss: 6.736333]\n",
      "epoch:48 step:37878 [D loss: 0.013618, acc: 100.00%] [G loss: 7.083738]\n",
      "epoch:48 step:37879 [D loss: 0.129993, acc: 99.22%] [G loss: 6.347985]\n",
      "epoch:48 step:37880 [D loss: 0.061000, acc: 100.00%] [G loss: 6.645725]\n",
      "epoch:48 step:37881 [D loss: 0.042094, acc: 100.00%] [G loss: 5.611146]\n",
      "epoch:48 step:37882 [D loss: 0.016800, acc: 100.00%] [G loss: 6.997584]\n",
      "epoch:48 step:37883 [D loss: 0.445703, acc: 77.34%] [G loss: 8.194776]\n",
      "epoch:48 step:37884 [D loss: 0.734377, acc: 55.47%] [G loss: 10.197709]\n",
      "epoch:48 step:37885 [D loss: 0.093341, acc: 100.00%] [G loss: 10.305265]\n",
      "epoch:48 step:37886 [D loss: 0.750329, acc: 54.69%] [G loss: 4.016450]\n",
      "epoch:48 step:37887 [D loss: 0.049838, acc: 100.00%] [G loss: 6.305022]\n",
      "epoch:48 step:37888 [D loss: 0.130557, acc: 100.00%] [G loss: 5.745911]\n",
      "epoch:48 step:37889 [D loss: 0.049145, acc: 100.00%] [G loss: 9.283073]\n",
      "epoch:48 step:37890 [D loss: 0.176550, acc: 99.22%] [G loss: 8.650420]\n",
      "epoch:48 step:37891 [D loss: 0.524804, acc: 62.50%] [G loss: 8.283210]\n",
      "epoch:48 step:37892 [D loss: 0.806679, acc: 53.12%] [G loss: 6.130347]\n",
      "epoch:48 step:37893 [D loss: 0.009448, acc: 100.00%] [G loss: 3.161831]\n",
      "epoch:48 step:37894 [D loss: 0.229833, acc: 89.06%] [G loss: 10.040556]\n",
      "epoch:48 step:37895 [D loss: 0.041100, acc: 100.00%] [G loss: 6.792758]\n",
      "epoch:48 step:37896 [D loss: 0.196142, acc: 97.66%] [G loss: 3.738095]\n",
      "epoch:48 step:37897 [D loss: 0.090683, acc: 99.22%] [G loss: 8.518250]\n",
      "epoch:48 step:37898 [D loss: 0.027834, acc: 100.00%] [G loss: 8.290276]\n",
      "epoch:48 step:37899 [D loss: 1.613721, acc: 27.34%] [G loss: 6.830193]\n",
      "epoch:48 step:37900 [D loss: 0.135587, acc: 98.44%] [G loss: 10.802182]\n",
      "epoch:48 step:37901 [D loss: 0.231816, acc: 92.19%] [G loss: 10.173155]\n",
      "epoch:48 step:37902 [D loss: 0.154772, acc: 96.09%] [G loss: 5.718716]\n",
      "epoch:48 step:37903 [D loss: 0.072378, acc: 100.00%] [G loss: 4.740552]\n",
      "epoch:48 step:37904 [D loss: 0.345250, acc: 84.38%] [G loss: 5.476065]\n",
      "epoch:48 step:37905 [D loss: 0.038243, acc: 100.00%] [G loss: 4.757578]\n",
      "epoch:48 step:37906 [D loss: 0.590863, acc: 58.59%] [G loss: 8.185499]\n",
      "epoch:48 step:37907 [D loss: 0.004244, acc: 100.00%] [G loss: 7.492542]\n",
      "epoch:48 step:37908 [D loss: 0.266508, acc: 89.06%] [G loss: 7.419491]\n",
      "epoch:48 step:37909 [D loss: 0.168690, acc: 96.88%] [G loss: 5.902212]\n",
      "epoch:48 step:37910 [D loss: 0.036996, acc: 100.00%] [G loss: 8.377387]\n",
      "epoch:48 step:37911 [D loss: 0.056752, acc: 100.00%] [G loss: 6.308881]\n",
      "epoch:48 step:37912 [D loss: 0.340349, acc: 83.59%] [G loss: 8.305361]\n",
      "epoch:48 step:37913 [D loss: 0.662480, acc: 55.47%] [G loss: 6.503651]\n",
      "epoch:48 step:37914 [D loss: 0.238470, acc: 95.31%] [G loss: 3.312197]\n",
      "epoch:48 step:37915 [D loss: 0.369948, acc: 89.06%] [G loss: 8.123323]\n",
      "epoch:48 step:37916 [D loss: 0.158805, acc: 97.66%] [G loss: 8.625729]\n",
      "epoch:48 step:37917 [D loss: 0.031574, acc: 100.00%] [G loss: 6.749125]\n",
      "epoch:48 step:37918 [D loss: 0.018599, acc: 100.00%] [G loss: 4.626722]\n",
      "epoch:48 step:37919 [D loss: 0.280398, acc: 93.75%] [G loss: 5.492147]\n",
      "epoch:48 step:37920 [D loss: 0.076116, acc: 99.22%] [G loss: 7.070383]\n",
      "epoch:48 step:37921 [D loss: 0.338682, acc: 83.59%] [G loss: 5.409136]\n",
      "epoch:48 step:37922 [D loss: 0.064046, acc: 99.22%] [G loss: 9.035761]\n",
      "epoch:48 step:37923 [D loss: 0.017007, acc: 100.00%] [G loss: 7.895333]\n",
      "epoch:48 step:37924 [D loss: 0.069691, acc: 100.00%] [G loss: 5.543681]\n",
      "epoch:48 step:37925 [D loss: 0.591879, acc: 72.66%] [G loss: 8.069944]\n",
      "epoch:48 step:37926 [D loss: 0.018035, acc: 100.00%] [G loss: 8.241476]\n",
      "epoch:48 step:37927 [D loss: 0.035612, acc: 100.00%] [G loss: 6.036903]\n",
      "epoch:48 step:37928 [D loss: 0.081728, acc: 100.00%] [G loss: 10.716897]\n",
      "epoch:48 step:37929 [D loss: 0.123304, acc: 98.44%] [G loss: 3.902504]\n",
      "epoch:48 step:37930 [D loss: 0.056949, acc: 100.00%] [G loss: 5.662764]\n",
      "epoch:48 step:37931 [D loss: 0.086868, acc: 99.22%] [G loss: 5.287786]\n",
      "epoch:48 step:37932 [D loss: 0.171719, acc: 97.66%] [G loss: 7.772410]\n",
      "epoch:48 step:37933 [D loss: 0.023807, acc: 100.00%] [G loss: 4.807314]\n",
      "epoch:48 step:37934 [D loss: 0.099478, acc: 100.00%] [G loss: 10.305698]\n",
      "epoch:48 step:37935 [D loss: 0.490053, acc: 69.53%] [G loss: 13.216187]\n",
      "epoch:48 step:37936 [D loss: 0.350506, acc: 78.91%] [G loss: 5.567626]\n",
      "epoch:48 step:37937 [D loss: 0.276666, acc: 91.41%] [G loss: 9.446383]\n",
      "epoch:48 step:37938 [D loss: 0.063569, acc: 100.00%] [G loss: 10.534090]\n",
      "epoch:48 step:37939 [D loss: 0.292425, acc: 89.06%] [G loss: 5.966858]\n",
      "epoch:48 step:37940 [D loss: 0.104941, acc: 99.22%] [G loss: 2.227771]\n",
      "epoch:48 step:37941 [D loss: 1.037256, acc: 50.00%] [G loss: 5.928680]\n",
      "epoch:48 step:37942 [D loss: 0.409437, acc: 78.91%] [G loss: 5.316276]\n",
      "epoch:48 step:37943 [D loss: 0.427183, acc: 72.66%] [G loss: 7.378894]\n",
      "epoch:48 step:37944 [D loss: 1.230026, acc: 50.00%] [G loss: 3.451498]\n",
      "epoch:48 step:37945 [D loss: 0.097025, acc: 98.44%] [G loss: 9.079880]\n",
      "epoch:48 step:37946 [D loss: 0.486947, acc: 65.62%] [G loss: 7.615761]\n",
      "epoch:48 step:37947 [D loss: 0.639276, acc: 60.94%] [G loss: 7.448476]\n",
      "epoch:48 step:37948 [D loss: 0.273024, acc: 92.97%] [G loss: 4.551501]\n",
      "epoch:48 step:37949 [D loss: 0.008043, acc: 100.00%] [G loss: 8.460477]\n",
      "epoch:48 step:37950 [D loss: 0.084945, acc: 99.22%] [G loss: 4.595378]\n",
      "epoch:48 step:37951 [D loss: 0.012384, acc: 100.00%] [G loss: 7.858175]\n",
      "epoch:48 step:37952 [D loss: 0.356171, acc: 78.12%] [G loss: 2.990889]\n",
      "epoch:48 step:37953 [D loss: 0.055067, acc: 100.00%] [G loss: 5.134038]\n",
      "epoch:48 step:37954 [D loss: 0.011233, acc: 100.00%] [G loss: 9.467604]\n",
      "epoch:48 step:37955 [D loss: 0.111916, acc: 99.22%] [G loss: 6.263777]\n",
      "epoch:48 step:37956 [D loss: 0.067263, acc: 100.00%] [G loss: 5.069918]\n",
      "epoch:48 step:37957 [D loss: 0.265374, acc: 93.75%] [G loss: 2.140159]\n",
      "epoch:48 step:37958 [D loss: 0.036558, acc: 100.00%] [G loss: 10.773767]\n",
      "epoch:48 step:37959 [D loss: 0.470190, acc: 77.34%] [G loss: 7.090657]\n",
      "epoch:48 step:37960 [D loss: 0.033532, acc: 100.00%] [G loss: 4.551278]\n",
      "epoch:48 step:37961 [D loss: 0.268756, acc: 91.41%] [G loss: 7.492413]\n",
      "epoch:48 step:37962 [D loss: 0.112281, acc: 99.22%] [G loss: 6.541882]\n",
      "epoch:48 step:37963 [D loss: 1.329736, acc: 14.84%] [G loss: 7.099312]\n",
      "epoch:48 step:37964 [D loss: 0.211890, acc: 95.31%] [G loss: 7.776222]\n",
      "epoch:48 step:37965 [D loss: 0.339189, acc: 82.03%] [G loss: 9.457109]\n",
      "epoch:48 step:37966 [D loss: 0.492538, acc: 68.75%] [G loss: 11.074651]\n",
      "epoch:48 step:37967 [D loss: 0.052941, acc: 98.44%] [G loss: 9.218117]\n",
      "epoch:48 step:37968 [D loss: 0.563763, acc: 66.41%] [G loss: 4.842883]\n",
      "epoch:48 step:37969 [D loss: 0.469780, acc: 80.47%] [G loss: 6.846823]\n",
      "epoch:48 step:37970 [D loss: 1.443074, acc: 50.00%] [G loss: 11.787103]\n",
      "epoch:48 step:37971 [D loss: 1.497146, acc: 50.00%] [G loss: 7.660200]\n",
      "epoch:48 step:37972 [D loss: 1.634056, acc: 50.00%] [G loss: 8.235123]\n",
      "epoch:48 step:37973 [D loss: 0.753630, acc: 53.91%] [G loss: 9.231235]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:48 step:37974 [D loss: 1.029272, acc: 50.00%] [G loss: 7.142654]\n",
      "epoch:48 step:37975 [D loss: 0.987457, acc: 52.34%] [G loss: 7.713956]\n",
      "epoch:48 step:37976 [D loss: 0.356675, acc: 92.97%] [G loss: 4.476276]\n",
      "epoch:48 step:37977 [D loss: 0.588142, acc: 66.41%] [G loss: 6.418498]\n",
      "epoch:48 step:37978 [D loss: 0.025274, acc: 100.00%] [G loss: 5.730869]\n",
      "epoch:48 step:37979 [D loss: 0.017509, acc: 100.00%] [G loss: 7.308370]\n",
      "epoch:48 step:37980 [D loss: 1.215013, acc: 18.75%] [G loss: 10.178765]\n",
      "epoch:48 step:37981 [D loss: 0.051668, acc: 100.00%] [G loss: 9.335729]\n",
      "epoch:48 step:37982 [D loss: 0.120106, acc: 99.22%] [G loss: 9.573018]\n",
      "epoch:48 step:37983 [D loss: 0.002204, acc: 100.00%] [G loss: 7.041793]\n",
      "epoch:48 step:37984 [D loss: 0.113327, acc: 99.22%] [G loss: 6.057266]\n",
      "epoch:48 step:37985 [D loss: 0.165992, acc: 96.09%] [G loss: 9.413612]\n",
      "epoch:48 step:37986 [D loss: 1.326284, acc: 20.31%] [G loss: 9.549107]\n",
      "epoch:48 step:37987 [D loss: 0.371707, acc: 77.34%] [G loss: 5.736203]\n",
      "epoch:48 step:37988 [D loss: 0.099011, acc: 99.22%] [G loss: 3.768713]\n",
      "epoch:48 step:37989 [D loss: 0.093686, acc: 98.44%] [G loss: 5.116850]\n",
      "epoch:48 step:37990 [D loss: 0.473848, acc: 71.09%] [G loss: 9.958460]\n",
      "epoch:48 step:37991 [D loss: 0.118173, acc: 99.22%] [G loss: 9.980564]\n",
      "epoch:48 step:37992 [D loss: 0.809826, acc: 53.91%] [G loss: 6.738277]\n",
      "epoch:48 step:37993 [D loss: 0.381838, acc: 80.47%] [G loss: 4.081196]\n",
      "epoch:48 step:37994 [D loss: 0.411017, acc: 85.16%] [G loss: 6.503423]\n",
      "epoch:48 step:37995 [D loss: 1.532681, acc: 6.25%] [G loss: 7.236912]\n",
      "epoch:48 step:37996 [D loss: 0.042221, acc: 100.00%] [G loss: 4.559797]\n",
      "epoch:48 step:37997 [D loss: 0.084048, acc: 100.00%] [G loss: 2.918096]\n",
      "epoch:48 step:37998 [D loss: 0.014761, acc: 100.00%] [G loss: 4.282646]\n",
      "epoch:48 step:37999 [D loss: 0.001035, acc: 100.00%] [G loss: 14.146824]\n",
      "epoch:48 step:38000 [D loss: 0.134631, acc: 96.88%] [G loss: 11.170566]\n",
      "##############\n",
      "[0.84121646 0.85256212 0.80601277 0.79287209 0.81242972 0.82409438\n",
      " 0.89598129 0.8167772  0.81765864 0.84541682]\n",
      "##########\n",
      "epoch:48 step:38001 [D loss: 1.101767, acc: 49.22%] [G loss: 7.982688]\n",
      "epoch:48 step:38002 [D loss: 0.119477, acc: 96.88%] [G loss: 6.220549]\n",
      "epoch:48 step:38003 [D loss: 0.234675, acc: 91.41%] [G loss: 8.099792]\n",
      "epoch:48 step:38004 [D loss: 0.127965, acc: 98.44%] [G loss: 10.637520]\n",
      "epoch:48 step:38005 [D loss: 0.012065, acc: 100.00%] [G loss: 13.067811]\n",
      "epoch:48 step:38006 [D loss: 0.030142, acc: 100.00%] [G loss: 5.114315]\n",
      "epoch:48 step:38007 [D loss: 0.993719, acc: 50.00%] [G loss: 5.698956]\n",
      "epoch:48 step:38008 [D loss: 0.032026, acc: 100.00%] [G loss: 9.860732]\n",
      "epoch:48 step:38009 [D loss: 0.339389, acc: 86.72%] [G loss: 10.214741]\n",
      "epoch:48 step:38010 [D loss: 0.231254, acc: 92.19%] [G loss: 4.600256]\n",
      "epoch:48 step:38011 [D loss: 0.246230, acc: 87.50%] [G loss: 11.193423]\n",
      "epoch:48 step:38012 [D loss: 0.053219, acc: 100.00%] [G loss: 8.336361]\n",
      "epoch:48 step:38013 [D loss: 0.602888, acc: 73.44%] [G loss: 4.012924]\n",
      "epoch:48 step:38014 [D loss: 0.253539, acc: 92.97%] [G loss: 7.955794]\n",
      "epoch:48 step:38015 [D loss: 0.030464, acc: 100.00%] [G loss: 7.513348]\n",
      "epoch:48 step:38016 [D loss: 0.125897, acc: 98.44%] [G loss: 3.619543]\n",
      "epoch:48 step:38017 [D loss: 0.254485, acc: 91.41%] [G loss: 5.321978]\n",
      "epoch:48 step:38018 [D loss: 0.136488, acc: 98.44%] [G loss: 4.017227]\n",
      "epoch:48 step:38019 [D loss: 0.164152, acc: 96.88%] [G loss: 6.496550]\n",
      "epoch:48 step:38020 [D loss: 0.236858, acc: 93.75%] [G loss: 4.841566]\n",
      "epoch:48 step:38021 [D loss: 0.268000, acc: 95.31%] [G loss: 6.125824]\n",
      "epoch:48 step:38022 [D loss: 0.047333, acc: 100.00%] [G loss: 4.596544]\n",
      "epoch:48 step:38023 [D loss: 0.201400, acc: 96.09%] [G loss: 5.967475]\n",
      "epoch:48 step:38024 [D loss: 0.036077, acc: 100.00%] [G loss: 5.723089]\n",
      "epoch:48 step:38025 [D loss: 0.064833, acc: 99.22%] [G loss: 9.970448]\n",
      "epoch:48 step:38026 [D loss: 0.026657, acc: 100.00%] [G loss: 6.368767]\n",
      "epoch:48 step:38027 [D loss: 0.498179, acc: 67.97%] [G loss: 6.640739]\n",
      "epoch:48 step:38028 [D loss: 0.074232, acc: 100.00%] [G loss: 4.964966]\n",
      "epoch:48 step:38029 [D loss: 0.131369, acc: 98.44%] [G loss: 8.818870]\n",
      "epoch:48 step:38030 [D loss: 0.234911, acc: 91.41%] [G loss: 7.483570]\n",
      "epoch:48 step:38031 [D loss: 0.453567, acc: 70.31%] [G loss: 6.480339]\n",
      "epoch:48 step:38032 [D loss: 0.038551, acc: 100.00%] [G loss: 6.648701]\n",
      "epoch:48 step:38033 [D loss: 0.019458, acc: 100.00%] [G loss: 5.937222]\n",
      "epoch:48 step:38034 [D loss: 0.431792, acc: 75.00%] [G loss: 5.924575]\n",
      "epoch:48 step:38035 [D loss: 0.016629, acc: 100.00%] [G loss: 7.122369]\n",
      "epoch:48 step:38036 [D loss: 0.328672, acc: 85.94%] [G loss: 5.176035]\n",
      "epoch:48 step:38037 [D loss: 0.145069, acc: 97.66%] [G loss: 6.371242]\n",
      "epoch:48 step:38038 [D loss: 0.356873, acc: 78.12%] [G loss: 6.090748]\n",
      "epoch:48 step:38039 [D loss: 0.416592, acc: 89.06%] [G loss: 6.754199]\n",
      "epoch:48 step:38040 [D loss: 0.269522, acc: 93.75%] [G loss: 6.906804]\n",
      "epoch:48 step:38041 [D loss: 0.503323, acc: 76.56%] [G loss: 11.080225]\n",
      "epoch:48 step:38042 [D loss: 0.286622, acc: 93.75%] [G loss: 2.559095]\n",
      "epoch:48 step:38043 [D loss: 0.045372, acc: 99.22%] [G loss: 8.184361]\n",
      "epoch:48 step:38044 [D loss: 0.133675, acc: 98.44%] [G loss: 3.601797]\n",
      "epoch:48 step:38045 [D loss: 0.055156, acc: 100.00%] [G loss: 7.474294]\n",
      "epoch:48 step:38046 [D loss: 0.559043, acc: 65.62%] [G loss: 8.651846]\n",
      "epoch:48 step:38047 [D loss: 0.141354, acc: 98.44%] [G loss: 4.845886]\n",
      "epoch:48 step:38048 [D loss: 0.258491, acc: 98.44%] [G loss: 7.481287]\n",
      "epoch:48 step:38049 [D loss: 0.135054, acc: 99.22%] [G loss: 11.896461]\n",
      "epoch:48 step:38050 [D loss: 0.370127, acc: 79.69%] [G loss: 9.057875]\n",
      "epoch:48 step:38051 [D loss: 0.040566, acc: 100.00%] [G loss: 7.177462]\n",
      "epoch:48 step:38052 [D loss: 0.043919, acc: 99.22%] [G loss: 11.217419]\n",
      "epoch:48 step:38053 [D loss: 0.114726, acc: 97.66%] [G loss: 7.970927]\n",
      "epoch:48 step:38054 [D loss: 0.016479, acc: 100.00%] [G loss: 5.789517]\n",
      "epoch:48 step:38055 [D loss: 0.103712, acc: 99.22%] [G loss: 6.732184]\n",
      "epoch:48 step:38056 [D loss: 0.373812, acc: 88.28%] [G loss: 8.241134]\n",
      "epoch:48 step:38057 [D loss: 0.022963, acc: 100.00%] [G loss: 9.487844]\n",
      "epoch:48 step:38058 [D loss: 0.329629, acc: 89.84%] [G loss: 5.561962]\n",
      "epoch:48 step:38059 [D loss: 0.028490, acc: 100.00%] [G loss: 5.249590]\n",
      "epoch:48 step:38060 [D loss: 0.071000, acc: 99.22%] [G loss: 6.230201]\n",
      "epoch:48 step:38061 [D loss: 0.278630, acc: 95.31%] [G loss: 8.162342]\n",
      "epoch:48 step:38062 [D loss: 0.446989, acc: 76.56%] [G loss: 7.871452]\n",
      "epoch:48 step:38063 [D loss: 0.269295, acc: 92.19%] [G loss: 3.031849]\n",
      "epoch:48 step:38064 [D loss: 0.056360, acc: 100.00%] [G loss: 4.305059]\n",
      "epoch:48 step:38065 [D loss: 0.345551, acc: 80.47%] [G loss: 4.818970]\n",
      "epoch:48 step:38066 [D loss: 0.137780, acc: 97.66%] [G loss: 4.908054]\n",
      "epoch:48 step:38067 [D loss: 0.073849, acc: 100.00%] [G loss: 4.398871]\n",
      "epoch:48 step:38068 [D loss: 0.266038, acc: 89.06%] [G loss: 6.199304]\n",
      "epoch:48 step:38069 [D loss: 0.032224, acc: 100.00%] [G loss: 8.195390]\n",
      "epoch:48 step:38070 [D loss: 0.488247, acc: 81.25%] [G loss: 6.705702]\n",
      "epoch:48 step:38071 [D loss: 0.129466, acc: 98.44%] [G loss: 6.334074]\n",
      "epoch:48 step:38072 [D loss: 0.205194, acc: 93.75%] [G loss: 5.009213]\n",
      "epoch:48 step:38073 [D loss: 0.077397, acc: 99.22%] [G loss: 6.234074]\n",
      "epoch:48 step:38074 [D loss: 0.395233, acc: 77.34%] [G loss: 7.814078]\n",
      "epoch:48 step:38075 [D loss: 0.482252, acc: 77.34%] [G loss: 5.754060]\n",
      "epoch:48 step:38076 [D loss: 0.410482, acc: 75.78%] [G loss: 8.187351]\n",
      "epoch:48 step:38077 [D loss: 0.453989, acc: 84.38%] [G loss: 8.989733]\n",
      "epoch:48 step:38078 [D loss: 0.205684, acc: 92.19%] [G loss: 5.085701]\n",
      "epoch:48 step:38079 [D loss: 0.296435, acc: 84.38%] [G loss: 10.562499]\n",
      "epoch:48 step:38080 [D loss: 0.633444, acc: 60.16%] [G loss: 9.590450]\n",
      "epoch:48 step:38081 [D loss: 0.644915, acc: 55.47%] [G loss: 1.772337]\n",
      "epoch:48 step:38082 [D loss: 0.186833, acc: 97.66%] [G loss: 4.994519]\n",
      "epoch:48 step:38083 [D loss: 0.509037, acc: 64.84%] [G loss: 11.343960]\n",
      "epoch:48 step:38084 [D loss: 0.385850, acc: 82.03%] [G loss: 8.758124]\n",
      "epoch:48 step:38085 [D loss: 0.962595, acc: 39.06%] [G loss: 8.975441]\n",
      "epoch:48 step:38086 [D loss: 0.578875, acc: 60.16%] [G loss: 8.213165]\n",
      "epoch:48 step:38087 [D loss: 0.041596, acc: 100.00%] [G loss: 10.818500]\n",
      "epoch:48 step:38088 [D loss: 0.353920, acc: 80.47%] [G loss: 11.930490]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:48 step:38089 [D loss: 0.089165, acc: 100.00%] [G loss: 9.602098]\n",
      "epoch:48 step:38090 [D loss: 0.564857, acc: 64.06%] [G loss: 9.992518]\n",
      "epoch:48 step:38091 [D loss: 0.404850, acc: 73.44%] [G loss: 6.233444]\n",
      "epoch:48 step:38092 [D loss: 0.025130, acc: 100.00%] [G loss: 3.814867]\n",
      "epoch:48 step:38093 [D loss: 0.086213, acc: 99.22%] [G loss: 7.807617]\n",
      "epoch:48 step:38094 [D loss: 0.807325, acc: 51.56%] [G loss: 8.803486]\n",
      "epoch:48 step:38095 [D loss: 0.023663, acc: 100.00%] [G loss: 1.559184]\n",
      "epoch:48 step:38096 [D loss: 0.416804, acc: 73.44%] [G loss: 5.710975]\n",
      "epoch:48 step:38097 [D loss: 0.136204, acc: 97.66%] [G loss: 6.267288]\n",
      "epoch:48 step:38098 [D loss: 0.148647, acc: 96.88%] [G loss: 5.364898]\n",
      "epoch:48 step:38099 [D loss: 0.271296, acc: 96.09%] [G loss: 9.965609]\n",
      "epoch:48 step:38100 [D loss: 0.050997, acc: 100.00%] [G loss: 9.385069]\n",
      "epoch:48 step:38101 [D loss: 0.783682, acc: 53.91%] [G loss: 8.076077]\n",
      "epoch:48 step:38102 [D loss: 0.642741, acc: 57.81%] [G loss: 12.757418]\n",
      "epoch:48 step:38103 [D loss: 0.010651, acc: 100.00%] [G loss: 6.334668]\n",
      "epoch:48 step:38104 [D loss: 0.770576, acc: 53.12%] [G loss: 9.672575]\n",
      "epoch:48 step:38105 [D loss: 0.270508, acc: 90.62%] [G loss: 9.069642]\n",
      "epoch:48 step:38106 [D loss: 0.012963, acc: 100.00%] [G loss: 7.456468]\n",
      "epoch:48 step:38107 [D loss: 1.034440, acc: 50.78%] [G loss: 7.587286]\n",
      "epoch:48 step:38108 [D loss: 0.417010, acc: 86.72%] [G loss: 6.310473]\n",
      "epoch:48 step:38109 [D loss: 0.996237, acc: 50.78%] [G loss: 9.374871]\n",
      "epoch:48 step:38110 [D loss: 0.084677, acc: 98.44%] [G loss: 6.213258]\n",
      "epoch:48 step:38111 [D loss: 0.068711, acc: 99.22%] [G loss: 7.810226]\n",
      "epoch:48 step:38112 [D loss: 0.647905, acc: 54.69%] [G loss: 11.146984]\n",
      "epoch:48 step:38113 [D loss: 0.070260, acc: 99.22%] [G loss: 7.325702]\n",
      "epoch:48 step:38114 [D loss: 0.282771, acc: 96.88%] [G loss: 5.095829]\n",
      "epoch:48 step:38115 [D loss: 0.146330, acc: 98.44%] [G loss: 6.363021]\n",
      "epoch:48 step:38116 [D loss: 0.120550, acc: 99.22%] [G loss: 8.429599]\n",
      "epoch:48 step:38117 [D loss: 0.356459, acc: 84.38%] [G loss: 6.157158]\n",
      "epoch:48 step:38118 [D loss: 0.189563, acc: 92.97%] [G loss: 13.811596]\n",
      "epoch:48 step:38119 [D loss: 0.120285, acc: 100.00%] [G loss: 10.167025]\n",
      "epoch:48 step:38120 [D loss: 0.146800, acc: 97.66%] [G loss: 4.317017]\n",
      "epoch:48 step:38121 [D loss: 0.449777, acc: 73.44%] [G loss: 6.407123]\n",
      "epoch:48 step:38122 [D loss: 0.409623, acc: 74.22%] [G loss: 5.454937]\n",
      "epoch:48 step:38123 [D loss: 0.226544, acc: 94.53%] [G loss: 2.981853]\n",
      "epoch:48 step:38124 [D loss: 0.447225, acc: 75.78%] [G loss: 7.752272]\n",
      "epoch:48 step:38125 [D loss: 0.261289, acc: 94.53%] [G loss: 5.300026]\n",
      "epoch:48 step:38126 [D loss: 0.107877, acc: 98.44%] [G loss: 7.553577]\n",
      "epoch:48 step:38127 [D loss: 0.198329, acc: 92.97%] [G loss: 5.278526]\n",
      "epoch:48 step:38128 [D loss: 0.024083, acc: 100.00%] [G loss: 6.828805]\n",
      "epoch:48 step:38129 [D loss: 0.050869, acc: 100.00%] [G loss: 9.181694]\n",
      "epoch:48 step:38130 [D loss: 0.196599, acc: 92.19%] [G loss: 10.996487]\n",
      "epoch:48 step:38131 [D loss: 0.275300, acc: 89.84%] [G loss: 7.814642]\n",
      "epoch:48 step:38132 [D loss: 0.048807, acc: 100.00%] [G loss: 6.683598]\n",
      "epoch:48 step:38133 [D loss: 0.482360, acc: 76.56%] [G loss: 5.817669]\n",
      "epoch:48 step:38134 [D loss: 1.453315, acc: 50.00%] [G loss: 10.434340]\n",
      "epoch:48 step:38135 [D loss: 0.171046, acc: 94.53%] [G loss: 5.255183]\n",
      "epoch:48 step:38136 [D loss: 0.205962, acc: 93.75%] [G loss: 10.291951]\n",
      "epoch:48 step:38137 [D loss: 0.182596, acc: 95.31%] [G loss: 5.734309]\n",
      "epoch:48 step:38138 [D loss: 0.109768, acc: 100.00%] [G loss: 10.041173]\n",
      "epoch:48 step:38139 [D loss: 0.050031, acc: 100.00%] [G loss: 8.315417]\n",
      "epoch:48 step:38140 [D loss: 0.332367, acc: 89.84%] [G loss: 6.349298]\n",
      "epoch:48 step:38141 [D loss: 0.038384, acc: 100.00%] [G loss: 3.733780]\n",
      "epoch:48 step:38142 [D loss: 0.046524, acc: 99.22%] [G loss: 6.840384]\n",
      "epoch:48 step:38143 [D loss: 0.084637, acc: 99.22%] [G loss: 9.355347]\n",
      "epoch:48 step:38144 [D loss: 0.935667, acc: 53.91%] [G loss: 9.017090]\n",
      "epoch:48 step:38145 [D loss: 1.731676, acc: 50.00%] [G loss: 8.986546]\n",
      "epoch:48 step:38146 [D loss: 0.135195, acc: 97.66%] [G loss: 3.099378]\n",
      "epoch:48 step:38147 [D loss: 0.234798, acc: 93.75%] [G loss: 5.762542]\n",
      "epoch:48 step:38148 [D loss: 0.145533, acc: 97.66%] [G loss: 7.991343]\n",
      "epoch:48 step:38149 [D loss: 0.081647, acc: 99.22%] [G loss: 2.663546]\n",
      "epoch:48 step:38150 [D loss: 0.184395, acc: 92.19%] [G loss: 9.634200]\n",
      "epoch:48 step:38151 [D loss: 0.223294, acc: 93.75%] [G loss: 3.261085]\n",
      "epoch:48 step:38152 [D loss: 0.193947, acc: 97.66%] [G loss: 9.413833]\n",
      "epoch:48 step:38153 [D loss: 0.154437, acc: 100.00%] [G loss: 9.601867]\n",
      "epoch:48 step:38154 [D loss: 0.354767, acc: 80.47%] [G loss: 3.704012]\n",
      "epoch:48 step:38155 [D loss: 0.027148, acc: 100.00%] [G loss: 8.548450]\n",
      "epoch:48 step:38156 [D loss: 0.024867, acc: 100.00%] [G loss: 4.847588]\n",
      "epoch:48 step:38157 [D loss: 0.148163, acc: 100.00%] [G loss: 7.328382]\n",
      "epoch:48 step:38158 [D loss: 0.205440, acc: 95.31%] [G loss: 5.789908]\n",
      "epoch:48 step:38159 [D loss: 0.008727, acc: 100.00%] [G loss: 7.780181]\n",
      "epoch:48 step:38160 [D loss: 0.066543, acc: 100.00%] [G loss: 7.268067]\n",
      "epoch:48 step:38161 [D loss: 0.060981, acc: 100.00%] [G loss: 6.292719]\n",
      "epoch:48 step:38162 [D loss: 0.392613, acc: 80.47%] [G loss: 6.274999]\n",
      "epoch:48 step:38163 [D loss: 0.199671, acc: 96.09%] [G loss: 5.607669]\n",
      "epoch:48 step:38164 [D loss: 0.141502, acc: 97.66%] [G loss: 5.941344]\n",
      "epoch:48 step:38165 [D loss: 0.007547, acc: 100.00%] [G loss: 10.940728]\n",
      "epoch:48 step:38166 [D loss: 0.232309, acc: 92.97%] [G loss: 6.009006]\n",
      "epoch:48 step:38167 [D loss: 0.089377, acc: 100.00%] [G loss: 11.130388]\n",
      "epoch:48 step:38168 [D loss: 0.065184, acc: 100.00%] [G loss: 8.249359]\n",
      "epoch:48 step:38169 [D loss: 0.582933, acc: 68.75%] [G loss: 9.324850]\n",
      "epoch:48 step:38170 [D loss: 0.190374, acc: 96.09%] [G loss: 8.248008]\n",
      "epoch:48 step:38171 [D loss: 0.764741, acc: 57.81%] [G loss: 5.492377]\n",
      "epoch:48 step:38172 [D loss: 0.094589, acc: 100.00%] [G loss: 7.539183]\n",
      "epoch:48 step:38173 [D loss: 0.116041, acc: 99.22%] [G loss: 7.345950]\n",
      "epoch:48 step:38174 [D loss: 0.363168, acc: 84.38%] [G loss: 3.714894]\n",
      "epoch:48 step:38175 [D loss: 0.225383, acc: 92.19%] [G loss: 7.365734]\n",
      "epoch:48 step:38176 [D loss: 0.006107, acc: 100.00%] [G loss: 8.291773]\n",
      "epoch:48 step:38177 [D loss: 0.000692, acc: 100.00%] [G loss: 8.833860]\n",
      "epoch:48 step:38178 [D loss: 0.012447, acc: 100.00%] [G loss: 7.558386]\n",
      "epoch:48 step:38179 [D loss: 0.523044, acc: 73.44%] [G loss: 7.973621]\n",
      "epoch:48 step:38180 [D loss: 0.021115, acc: 100.00%] [G loss: 7.874274]\n",
      "epoch:48 step:38181 [D loss: 0.125623, acc: 99.22%] [G loss: 6.051441]\n",
      "epoch:48 step:38182 [D loss: 0.264138, acc: 89.06%] [G loss: 4.728149]\n",
      "epoch:48 step:38183 [D loss: 0.091813, acc: 100.00%] [G loss: 6.653352]\n",
      "epoch:48 step:38184 [D loss: 0.126408, acc: 97.66%] [G loss: 8.423872]\n",
      "epoch:48 step:38185 [D loss: 0.805507, acc: 49.22%] [G loss: 10.001452]\n",
      "epoch:48 step:38186 [D loss: 0.041451, acc: 100.00%] [G loss: 3.831150]\n",
      "epoch:48 step:38187 [D loss: 0.397728, acc: 70.31%] [G loss: 9.401764]\n",
      "epoch:48 step:38188 [D loss: 0.487160, acc: 82.03%] [G loss: 5.667908]\n",
      "epoch:48 step:38189 [D loss: 0.056661, acc: 100.00%] [G loss: 4.246574]\n",
      "epoch:48 step:38190 [D loss: 0.032706, acc: 100.00%] [G loss: 7.760380]\n",
      "epoch:48 step:38191 [D loss: 0.372575, acc: 82.03%] [G loss: 8.750120]\n",
      "epoch:48 step:38192 [D loss: 0.282867, acc: 89.06%] [G loss: 4.599348]\n",
      "epoch:48 step:38193 [D loss: 0.187115, acc: 96.09%] [G loss: 6.317788]\n",
      "epoch:48 step:38194 [D loss: 0.285792, acc: 93.75%] [G loss: 10.979107]\n",
      "epoch:48 step:38195 [D loss: 0.423981, acc: 68.75%] [G loss: 6.572562]\n",
      "epoch:48 step:38196 [D loss: 0.082680, acc: 98.44%] [G loss: 11.143654]\n",
      "epoch:48 step:38197 [D loss: 0.050166, acc: 100.00%] [G loss: 4.076685]\n",
      "epoch:48 step:38198 [D loss: 0.022855, acc: 100.00%] [G loss: 6.485485]\n",
      "epoch:48 step:38199 [D loss: 0.001462, acc: 100.00%] [G loss: 16.142143]\n",
      "epoch:48 step:38200 [D loss: 0.275955, acc: 87.50%] [G loss: 4.461925]\n",
      "##############\n",
      "[0.85196239 0.88450892 0.80810208 0.79723911 0.79169129 0.82219024\n",
      " 0.91578854 0.82299566 0.79875278 0.82005344]\n",
      "##########\n",
      "epoch:48 step:38201 [D loss: 0.038236, acc: 100.00%] [G loss: 5.348823]\n",
      "epoch:48 step:38202 [D loss: 0.114811, acc: 98.44%] [G loss: 8.275976]\n",
      "epoch:48 step:38203 [D loss: 0.037329, acc: 100.00%] [G loss: 4.598842]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:48 step:38204 [D loss: 0.468471, acc: 78.12%] [G loss: 7.351600]\n",
      "epoch:48 step:38205 [D loss: 0.479961, acc: 68.75%] [G loss: 7.930646]\n",
      "epoch:48 step:38206 [D loss: 0.464964, acc: 66.41%] [G loss: 8.712290]\n",
      "epoch:48 step:38207 [D loss: 1.276629, acc: 47.66%] [G loss: 8.984997]\n",
      "epoch:48 step:38208 [D loss: 0.152961, acc: 99.22%] [G loss: 4.792531]\n",
      "epoch:48 step:38209 [D loss: 0.045638, acc: 100.00%] [G loss: 5.301922]\n",
      "epoch:48 step:38210 [D loss: 0.124348, acc: 98.44%] [G loss: 4.802938]\n",
      "epoch:48 step:38211 [D loss: 0.063195, acc: 100.00%] [G loss: 6.214961]\n",
      "epoch:48 step:38212 [D loss: 0.165839, acc: 99.22%] [G loss: 3.588748]\n",
      "epoch:48 step:38213 [D loss: 0.028197, acc: 100.00%] [G loss: 3.379148]\n",
      "epoch:48 step:38214 [D loss: 0.014199, acc: 100.00%] [G loss: 16.937195]\n",
      "epoch:48 step:38215 [D loss: 0.250868, acc: 96.09%] [G loss: 6.416268]\n",
      "epoch:48 step:38216 [D loss: 2.534811, acc: 0.00%] [G loss: 10.118697]\n",
      "epoch:48 step:38217 [D loss: 0.452978, acc: 82.03%] [G loss: 6.742166]\n",
      "epoch:48 step:38218 [D loss: 0.383340, acc: 85.94%] [G loss: 4.218549]\n",
      "epoch:48 step:38219 [D loss: 0.082667, acc: 99.22%] [G loss: 8.342131]\n",
      "epoch:48 step:38220 [D loss: 0.157481, acc: 96.09%] [G loss: 12.830156]\n",
      "epoch:48 step:38221 [D loss: 0.297751, acc: 92.19%] [G loss: 8.732157]\n",
      "epoch:48 step:38222 [D loss: 0.024091, acc: 100.00%] [G loss: 6.162380]\n",
      "epoch:48 step:38223 [D loss: 0.020684, acc: 100.00%] [G loss: 9.163485]\n",
      "epoch:48 step:38224 [D loss: 0.201277, acc: 94.53%] [G loss: 7.336465]\n",
      "epoch:48 step:38225 [D loss: 0.191111, acc: 94.53%] [G loss: 11.240202]\n",
      "epoch:48 step:38226 [D loss: 0.374492, acc: 85.94%] [G loss: 11.087011]\n",
      "epoch:48 step:38227 [D loss: 0.103985, acc: 100.00%] [G loss: 5.394089]\n",
      "epoch:48 step:38228 [D loss: 0.011160, acc: 100.00%] [G loss: 6.204160]\n",
      "epoch:48 step:38229 [D loss: 0.041870, acc: 99.22%] [G loss: 4.230256]\n",
      "epoch:48 step:38230 [D loss: 0.243482, acc: 92.19%] [G loss: 3.882359]\n",
      "epoch:48 step:38231 [D loss: 0.175208, acc: 96.88%] [G loss: 4.717710]\n",
      "epoch:48 step:38232 [D loss: 0.301544, acc: 86.72%] [G loss: 6.340071]\n",
      "epoch:48 step:38233 [D loss: 0.041084, acc: 100.00%] [G loss: 9.356123]\n",
      "epoch:48 step:38234 [D loss: 0.023449, acc: 99.22%] [G loss: 10.206364]\n",
      "epoch:48 step:38235 [D loss: 0.062306, acc: 99.22%] [G loss: 5.080056]\n",
      "epoch:48 step:38236 [D loss: 0.189944, acc: 99.22%] [G loss: 5.903013]\n",
      "epoch:48 step:38237 [D loss: 0.446905, acc: 72.66%] [G loss: 12.307923]\n",
      "epoch:48 step:38238 [D loss: 0.455561, acc: 78.12%] [G loss: 7.847329]\n",
      "epoch:48 step:38239 [D loss: 0.053377, acc: 100.00%] [G loss: 8.252601]\n",
      "epoch:48 step:38240 [D loss: 0.050645, acc: 100.00%] [G loss: 6.635593]\n",
      "epoch:48 step:38241 [D loss: 0.220302, acc: 96.09%] [G loss: 7.818789]\n",
      "epoch:48 step:38242 [D loss: 0.085053, acc: 98.44%] [G loss: 5.274956]\n",
      "epoch:48 step:38243 [D loss: 0.120964, acc: 100.00%] [G loss: 6.885992]\n",
      "epoch:48 step:38244 [D loss: 0.231373, acc: 90.62%] [G loss: 8.540928]\n",
      "epoch:48 step:38245 [D loss: 0.952535, acc: 35.94%] [G loss: 6.694282]\n",
      "epoch:48 step:38246 [D loss: 0.543046, acc: 66.41%] [G loss: 7.007520]\n",
      "epoch:48 step:38247 [D loss: 0.166018, acc: 96.88%] [G loss: 6.067715]\n",
      "epoch:48 step:38248 [D loss: 0.120013, acc: 97.66%] [G loss: 11.938452]\n",
      "epoch:48 step:38249 [D loss: 0.323887, acc: 81.25%] [G loss: 3.670923]\n",
      "epoch:48 step:38250 [D loss: 0.217519, acc: 96.88%] [G loss: 7.572111]\n",
      "epoch:48 step:38251 [D loss: 0.034193, acc: 100.00%] [G loss: 6.046405]\n",
      "epoch:48 step:38252 [D loss: 1.311579, acc: 50.78%] [G loss: 10.150638]\n",
      "epoch:48 step:38253 [D loss: 0.287925, acc: 84.38%] [G loss: 4.878502]\n",
      "epoch:48 step:38254 [D loss: 0.024028, acc: 100.00%] [G loss: 2.982688]\n",
      "epoch:48 step:38255 [D loss: 0.246968, acc: 89.84%] [G loss: 9.999695]\n",
      "epoch:48 step:38256 [D loss: 0.180254, acc: 98.44%] [G loss: 9.637165]\n",
      "epoch:48 step:38257 [D loss: 0.168827, acc: 96.88%] [G loss: 4.899091]\n",
      "epoch:48 step:38258 [D loss: 0.121973, acc: 99.22%] [G loss: 7.242360]\n",
      "epoch:48 step:38259 [D loss: 0.655888, acc: 56.25%] [G loss: 8.012398]\n",
      "epoch:48 step:38260 [D loss: 0.007015, acc: 100.00%] [G loss: 6.111016]\n",
      "epoch:48 step:38261 [D loss: 0.002656, acc: 100.00%] [G loss: 12.639467]\n",
      "epoch:48 step:38262 [D loss: 2.497308, acc: 50.00%] [G loss: 10.643431]\n",
      "epoch:48 step:38263 [D loss: 0.222826, acc: 96.09%] [G loss: 7.025073]\n",
      "epoch:48 step:38264 [D loss: 0.070990, acc: 100.00%] [G loss: 6.397664]\n",
      "epoch:48 step:38265 [D loss: 2.245314, acc: 5.47%] [G loss: 10.751714]\n",
      "epoch:48 step:38266 [D loss: 0.052357, acc: 99.22%] [G loss: 8.003410]\n",
      "epoch:48 step:38267 [D loss: 0.113738, acc: 97.66%] [G loss: 8.515709]\n",
      "epoch:48 step:38268 [D loss: 0.488412, acc: 67.97%] [G loss: 9.078835]\n",
      "epoch:48 step:38269 [D loss: 0.193049, acc: 92.97%] [G loss: 5.766147]\n",
      "epoch:49 step:38270 [D loss: 0.557290, acc: 60.94%] [G loss: 8.767101]\n",
      "epoch:49 step:38271 [D loss: 0.011999, acc: 100.00%] [G loss: 13.595801]\n",
      "epoch:49 step:38272 [D loss: 3.043432, acc: 18.75%] [G loss: 9.528527]\n",
      "epoch:49 step:38273 [D loss: 0.396966, acc: 78.12%] [G loss: 7.298251]\n",
      "epoch:49 step:38274 [D loss: 0.403552, acc: 75.00%] [G loss: 10.513897]\n",
      "epoch:49 step:38275 [D loss: 1.391842, acc: 50.00%] [G loss: 7.426368]\n",
      "epoch:49 step:38276 [D loss: 0.240370, acc: 89.84%] [G loss: 3.196725]\n",
      "epoch:49 step:38277 [D loss: 0.204007, acc: 89.84%] [G loss: 11.500115]\n",
      "epoch:49 step:38278 [D loss: 0.205714, acc: 97.66%] [G loss: 5.220680]\n",
      "epoch:49 step:38279 [D loss: 0.402272, acc: 74.22%] [G loss: 7.130957]\n",
      "epoch:49 step:38280 [D loss: 0.114407, acc: 100.00%] [G loss: 7.521425]\n",
      "epoch:49 step:38281 [D loss: 0.022568, acc: 100.00%] [G loss: 10.723734]\n",
      "epoch:49 step:38282 [D loss: 0.122231, acc: 98.44%] [G loss: 6.457208]\n",
      "epoch:49 step:38283 [D loss: 0.051474, acc: 100.00%] [G loss: 5.285623]\n",
      "epoch:49 step:38284 [D loss: 0.378952, acc: 86.72%] [G loss: 4.737309]\n",
      "epoch:49 step:38285 [D loss: 0.120193, acc: 98.44%] [G loss: 5.008754]\n",
      "epoch:49 step:38286 [D loss: 0.366538, acc: 87.50%] [G loss: 2.625656]\n",
      "epoch:49 step:38287 [D loss: 0.118711, acc: 99.22%] [G loss: 5.406825]\n",
      "epoch:49 step:38288 [D loss: 0.364532, acc: 90.62%] [G loss: 8.499481]\n",
      "epoch:49 step:38289 [D loss: 0.224308, acc: 92.97%] [G loss: 9.798662]\n",
      "epoch:49 step:38290 [D loss: 0.196272, acc: 95.31%] [G loss: 7.791508]\n",
      "epoch:49 step:38291 [D loss: 0.332185, acc: 88.28%] [G loss: 5.062788]\n",
      "epoch:49 step:38292 [D loss: 0.029426, acc: 100.00%] [G loss: 6.097547]\n",
      "epoch:49 step:38293 [D loss: 0.072093, acc: 100.00%] [G loss: 3.957624]\n",
      "epoch:49 step:38294 [D loss: 0.040766, acc: 100.00%] [G loss: 8.733042]\n",
      "epoch:49 step:38295 [D loss: 0.019561, acc: 100.00%] [G loss: 8.622520]\n",
      "epoch:49 step:38296 [D loss: 0.015276, acc: 100.00%] [G loss: 6.876005]\n",
      "epoch:49 step:38297 [D loss: 0.268066, acc: 96.09%] [G loss: 10.344498]\n",
      "epoch:49 step:38298 [D loss: 0.721667, acc: 56.25%] [G loss: 10.814564]\n",
      "epoch:49 step:38299 [D loss: 0.374538, acc: 77.34%] [G loss: 10.683351]\n",
      "epoch:49 step:38300 [D loss: 0.171250, acc: 97.66%] [G loss: 9.276899]\n",
      "epoch:49 step:38301 [D loss: 0.483382, acc: 61.72%] [G loss: 9.194622]\n",
      "epoch:49 step:38302 [D loss: 0.264470, acc: 88.28%] [G loss: 7.418901]\n",
      "epoch:49 step:38303 [D loss: 0.116670, acc: 100.00%] [G loss: 5.819743]\n",
      "epoch:49 step:38304 [D loss: 0.077965, acc: 100.00%] [G loss: 3.946330]\n",
      "epoch:49 step:38305 [D loss: 0.055544, acc: 100.00%] [G loss: 9.170908]\n",
      "epoch:49 step:38306 [D loss: 0.181228, acc: 98.44%] [G loss: 8.755559]\n",
      "epoch:49 step:38307 [D loss: 0.084342, acc: 99.22%] [G loss: 4.196020]\n",
      "epoch:49 step:38308 [D loss: 0.021010, acc: 100.00%] [G loss: 7.285865]\n",
      "epoch:49 step:38309 [D loss: 0.145839, acc: 99.22%] [G loss: 7.074391]\n",
      "epoch:49 step:38310 [D loss: 0.558692, acc: 74.22%] [G loss: 7.576979]\n",
      "epoch:49 step:38311 [D loss: 0.278357, acc: 84.38%] [G loss: 7.811410]\n",
      "epoch:49 step:38312 [D loss: 0.281456, acc: 89.06%] [G loss: 6.480984]\n",
      "epoch:49 step:38313 [D loss: 0.126679, acc: 100.00%] [G loss: 8.654493]\n",
      "epoch:49 step:38314 [D loss: 0.046311, acc: 98.44%] [G loss: 5.424051]\n",
      "epoch:49 step:38315 [D loss: 0.366052, acc: 91.41%] [G loss: 4.680417]\n",
      "epoch:49 step:38316 [D loss: 0.174943, acc: 98.44%] [G loss: 7.130628]\n",
      "epoch:49 step:38317 [D loss: 0.103748, acc: 100.00%] [G loss: 8.574703]\n",
      "epoch:49 step:38318 [D loss: 0.328792, acc: 83.59%] [G loss: 7.931908]\n",
      "epoch:49 step:38319 [D loss: 0.425685, acc: 75.00%] [G loss: 5.226611]\n",
      "epoch:49 step:38320 [D loss: 0.068226, acc: 100.00%] [G loss: 7.836667]\n",
      "epoch:49 step:38321 [D loss: 0.002305, acc: 100.00%] [G loss: 8.352496]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:49 step:38322 [D loss: 0.081305, acc: 100.00%] [G loss: 6.121698]\n",
      "epoch:49 step:38323 [D loss: 0.179463, acc: 94.53%] [G loss: 11.336977]\n",
      "epoch:49 step:38324 [D loss: 0.010715, acc: 100.00%] [G loss: 12.436871]\n",
      "epoch:49 step:38325 [D loss: 0.308429, acc: 85.16%] [G loss: 6.581838]\n",
      "epoch:49 step:38326 [D loss: 0.108527, acc: 99.22%] [G loss: 7.801942]\n",
      "epoch:49 step:38327 [D loss: 0.080325, acc: 99.22%] [G loss: 6.540887]\n",
      "epoch:49 step:38328 [D loss: 0.313548, acc: 85.16%] [G loss: 3.862359]\n",
      "epoch:49 step:38329 [D loss: 0.414987, acc: 80.47%] [G loss: 6.866537]\n",
      "epoch:49 step:38330 [D loss: 1.020608, acc: 32.81%] [G loss: 8.609684]\n",
      "epoch:49 step:38331 [D loss: 0.095899, acc: 99.22%] [G loss: 6.029203]\n",
      "epoch:49 step:38332 [D loss: 0.146793, acc: 99.22%] [G loss: 8.380031]\n",
      "epoch:49 step:38333 [D loss: 0.456967, acc: 74.22%] [G loss: 4.151274]\n",
      "epoch:49 step:38334 [D loss: 0.375466, acc: 78.91%] [G loss: 8.254163]\n",
      "epoch:49 step:38335 [D loss: 0.421838, acc: 71.88%] [G loss: 7.566250]\n",
      "epoch:49 step:38336 [D loss: 0.106220, acc: 99.22%] [G loss: 5.726471]\n",
      "epoch:49 step:38337 [D loss: 0.445901, acc: 81.25%] [G loss: 5.582593]\n",
      "epoch:49 step:38338 [D loss: 0.160599, acc: 97.66%] [G loss: 9.043394]\n",
      "epoch:49 step:38339 [D loss: 0.277423, acc: 89.06%] [G loss: 5.950160]\n",
      "epoch:49 step:38340 [D loss: 0.755848, acc: 54.69%] [G loss: 11.082428]\n",
      "epoch:49 step:38341 [D loss: 0.313761, acc: 87.50%] [G loss: 5.941987]\n",
      "epoch:49 step:38342 [D loss: 0.173645, acc: 94.53%] [G loss: 7.696579]\n",
      "epoch:49 step:38343 [D loss: 0.061181, acc: 99.22%] [G loss: 5.841496]\n",
      "epoch:49 step:38344 [D loss: 0.528742, acc: 71.88%] [G loss: 3.617367]\n",
      "epoch:49 step:38345 [D loss: 0.049943, acc: 100.00%] [G loss: 7.344491]\n",
      "epoch:49 step:38346 [D loss: 0.186254, acc: 92.97%] [G loss: 11.176239]\n",
      "epoch:49 step:38347 [D loss: 0.491589, acc: 71.88%] [G loss: 7.319318]\n",
      "epoch:49 step:38348 [D loss: 0.022369, acc: 100.00%] [G loss: 8.471763]\n",
      "epoch:49 step:38349 [D loss: 0.111931, acc: 99.22%] [G loss: 8.121354]\n",
      "epoch:49 step:38350 [D loss: 0.037764, acc: 100.00%] [G loss: 6.604885]\n",
      "epoch:49 step:38351 [D loss: 0.259431, acc: 94.53%] [G loss: 6.030549]\n",
      "epoch:49 step:38352 [D loss: 0.051260, acc: 99.22%] [G loss: 9.374298]\n",
      "epoch:49 step:38353 [D loss: 0.557903, acc: 59.38%] [G loss: 7.108338]\n",
      "epoch:49 step:38354 [D loss: 0.152791, acc: 99.22%] [G loss: 4.683422]\n",
      "epoch:49 step:38355 [D loss: 0.689035, acc: 56.25%] [G loss: 7.125881]\n",
      "epoch:49 step:38356 [D loss: 0.084877, acc: 99.22%] [G loss: 7.832909]\n",
      "epoch:49 step:38357 [D loss: 0.610115, acc: 71.09%] [G loss: 7.601874]\n",
      "epoch:49 step:38358 [D loss: 0.001023, acc: 100.00%] [G loss: 7.565171]\n",
      "epoch:49 step:38359 [D loss: 0.242321, acc: 90.62%] [G loss: 8.293044]\n",
      "epoch:49 step:38360 [D loss: 0.057091, acc: 100.00%] [G loss: 9.918797]\n",
      "epoch:49 step:38361 [D loss: 0.019122, acc: 100.00%] [G loss: 11.246612]\n",
      "epoch:49 step:38362 [D loss: 0.127285, acc: 100.00%] [G loss: 7.656497]\n",
      "epoch:49 step:38363 [D loss: 0.020829, acc: 100.00%] [G loss: 8.934399]\n",
      "epoch:49 step:38364 [D loss: 1.040195, acc: 48.44%] [G loss: 6.376829]\n",
      "epoch:49 step:38365 [D loss: 1.122545, acc: 36.72%] [G loss: 6.693217]\n",
      "epoch:49 step:38366 [D loss: 0.151134, acc: 100.00%] [G loss: 5.507993]\n",
      "epoch:49 step:38367 [D loss: 0.574833, acc: 64.84%] [G loss: 9.700270]\n",
      "epoch:49 step:38368 [D loss: 0.005537, acc: 100.00%] [G loss: 8.646842]\n",
      "epoch:49 step:38369 [D loss: 0.307192, acc: 87.50%] [G loss: 8.092987]\n",
      "epoch:49 step:38370 [D loss: 0.208852, acc: 96.88%] [G loss: 3.309474]\n",
      "epoch:49 step:38371 [D loss: 0.019297, acc: 99.22%] [G loss: 6.418727]\n",
      "epoch:49 step:38372 [D loss: 0.113779, acc: 98.44%] [G loss: 6.169961]\n",
      "epoch:49 step:38373 [D loss: 0.107901, acc: 99.22%] [G loss: 6.135148]\n",
      "epoch:49 step:38374 [D loss: 0.483250, acc: 78.91%] [G loss: 9.521822]\n",
      "epoch:49 step:38375 [D loss: 0.080647, acc: 99.22%] [G loss: 8.026361]\n",
      "epoch:49 step:38376 [D loss: 0.020870, acc: 100.00%] [G loss: 4.301053]\n",
      "epoch:49 step:38377 [D loss: 0.052248, acc: 100.00%] [G loss: 4.557724]\n",
      "epoch:49 step:38378 [D loss: 0.040852, acc: 100.00%] [G loss: 3.293859]\n",
      "epoch:49 step:38379 [D loss: 0.631464, acc: 65.62%] [G loss: 10.289903]\n",
      "epoch:49 step:38380 [D loss: 0.411950, acc: 73.44%] [G loss: 7.084525]\n",
      "epoch:49 step:38381 [D loss: 0.103636, acc: 99.22%] [G loss: 6.884231]\n",
      "epoch:49 step:38382 [D loss: 0.049741, acc: 100.00%] [G loss: 6.145549]\n",
      "epoch:49 step:38383 [D loss: 0.073377, acc: 100.00%] [G loss: 4.493002]\n",
      "epoch:49 step:38384 [D loss: 0.088682, acc: 100.00%] [G loss: 11.900962]\n",
      "epoch:49 step:38385 [D loss: 0.502060, acc: 72.66%] [G loss: 6.565598]\n",
      "epoch:49 step:38386 [D loss: 1.320317, acc: 22.66%] [G loss: 7.004748]\n",
      "epoch:49 step:38387 [D loss: 0.143130, acc: 100.00%] [G loss: 9.012689]\n",
      "epoch:49 step:38388 [D loss: 0.006543, acc: 100.00%] [G loss: 5.053063]\n",
      "epoch:49 step:38389 [D loss: 1.125786, acc: 24.22%] [G loss: 8.606832]\n",
      "epoch:49 step:38390 [D loss: 0.031424, acc: 100.00%] [G loss: 7.180898]\n",
      "epoch:49 step:38391 [D loss: 0.636068, acc: 59.38%] [G loss: 7.520488]\n",
      "epoch:49 step:38392 [D loss: 0.950976, acc: 35.16%] [G loss: 9.527303]\n",
      "epoch:49 step:38393 [D loss: 0.178756, acc: 97.66%] [G loss: 5.664528]\n",
      "epoch:49 step:38394 [D loss: 0.149785, acc: 95.31%] [G loss: 9.803370]\n",
      "epoch:49 step:38395 [D loss: 0.319259, acc: 80.47%] [G loss: 4.309914]\n",
      "epoch:49 step:38396 [D loss: 0.416571, acc: 82.03%] [G loss: 5.826165]\n",
      "epoch:49 step:38397 [D loss: 0.151393, acc: 96.09%] [G loss: 7.610683]\n",
      "epoch:49 step:38398 [D loss: 1.332678, acc: 50.00%] [G loss: 9.236555]\n",
      "epoch:49 step:38399 [D loss: 0.259196, acc: 89.06%] [G loss: 3.573982]\n",
      "epoch:49 step:38400 [D loss: 0.763328, acc: 59.38%] [G loss: 9.611264]\n",
      "##############\n",
      "[0.89066133 0.87192155 0.80427634 0.81744273 0.77084316 0.81661849\n",
      " 0.87992668 0.82817684 0.81990427 0.8308782 ]\n",
      "##########\n",
      "epoch:49 step:38401 [D loss: 0.018094, acc: 100.00%] [G loss: 9.621918]\n",
      "epoch:49 step:38402 [D loss: 0.090665, acc: 100.00%] [G loss: 6.357104]\n",
      "epoch:49 step:38403 [D loss: 0.254299, acc: 91.41%] [G loss: 6.592823]\n",
      "epoch:49 step:38404 [D loss: 0.140692, acc: 99.22%] [G loss: 8.130918]\n",
      "epoch:49 step:38405 [D loss: 0.106921, acc: 99.22%] [G loss: 6.264082]\n",
      "epoch:49 step:38406 [D loss: 0.014414, acc: 100.00%] [G loss: 2.373554]\n",
      "epoch:49 step:38407 [D loss: 0.149440, acc: 98.44%] [G loss: 4.001004]\n",
      "epoch:49 step:38408 [D loss: 0.139338, acc: 97.66%] [G loss: 6.736237]\n",
      "epoch:49 step:38409 [D loss: 0.234817, acc: 97.66%] [G loss: 4.538507]\n",
      "epoch:49 step:38410 [D loss: 0.613495, acc: 58.59%] [G loss: 6.275608]\n",
      "epoch:49 step:38411 [D loss: 0.004601, acc: 100.00%] [G loss: 11.697336]\n",
      "epoch:49 step:38412 [D loss: 0.250406, acc: 92.97%] [G loss: 6.516434]\n",
      "epoch:49 step:38413 [D loss: 0.067492, acc: 100.00%] [G loss: 6.796989]\n",
      "epoch:49 step:38414 [D loss: 0.054784, acc: 100.00%] [G loss: 4.263061]\n",
      "epoch:49 step:38415 [D loss: 0.235169, acc: 94.53%] [G loss: 5.089981]\n",
      "epoch:49 step:38416 [D loss: 0.273071, acc: 86.72%] [G loss: 10.960381]\n",
      "epoch:49 step:38417 [D loss: 0.777725, acc: 53.12%] [G loss: 6.675323]\n",
      "epoch:49 step:38418 [D loss: 0.231258, acc: 96.09%] [G loss: 6.576837]\n",
      "epoch:49 step:38419 [D loss: 0.283550, acc: 84.38%] [G loss: 9.045080]\n",
      "epoch:49 step:38420 [D loss: 0.095904, acc: 99.22%] [G loss: 9.155083]\n",
      "epoch:49 step:38421 [D loss: 0.322069, acc: 83.59%] [G loss: 4.310461]\n",
      "epoch:49 step:38422 [D loss: 0.100639, acc: 100.00%] [G loss: 6.995727]\n",
      "epoch:49 step:38423 [D loss: 0.288925, acc: 85.16%] [G loss: 5.494402]\n",
      "epoch:49 step:38424 [D loss: 0.532209, acc: 64.84%] [G loss: 7.053838]\n",
      "epoch:49 step:38425 [D loss: 0.300163, acc: 89.06%] [G loss: 3.703187]\n",
      "epoch:49 step:38426 [D loss: 0.068577, acc: 100.00%] [G loss: 10.995718]\n",
      "epoch:49 step:38427 [D loss: 0.019921, acc: 100.00%] [G loss: 6.890692]\n",
      "epoch:49 step:38428 [D loss: 0.825602, acc: 53.91%] [G loss: 7.628377]\n",
      "epoch:49 step:38429 [D loss: 0.014856, acc: 100.00%] [G loss: 8.853315]\n",
      "epoch:49 step:38430 [D loss: 0.006368, acc: 100.00%] [G loss: 10.241751]\n",
      "epoch:49 step:38431 [D loss: 0.397032, acc: 82.81%] [G loss: 8.891306]\n",
      "epoch:49 step:38432 [D loss: 0.115950, acc: 97.66%] [G loss: 5.136149]\n",
      "epoch:49 step:38433 [D loss: 0.111416, acc: 99.22%] [G loss: 5.101101]\n",
      "epoch:49 step:38434 [D loss: 0.026992, acc: 100.00%] [G loss: 8.964245]\n",
      "epoch:49 step:38435 [D loss: 0.520663, acc: 69.53%] [G loss: 3.859020]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:49 step:38436 [D loss: 0.076630, acc: 100.00%] [G loss: 7.755841]\n",
      "epoch:49 step:38437 [D loss: 0.101068, acc: 100.00%] [G loss: 12.359290]\n",
      "epoch:49 step:38438 [D loss: 0.178578, acc: 97.66%] [G loss: 2.499695]\n",
      "epoch:49 step:38439 [D loss: 0.872918, acc: 50.00%] [G loss: 3.628184]\n",
      "epoch:49 step:38440 [D loss: 0.065303, acc: 100.00%] [G loss: 7.064052]\n",
      "epoch:49 step:38441 [D loss: 0.286339, acc: 85.94%] [G loss: 7.194332]\n",
      "epoch:49 step:38442 [D loss: 0.026011, acc: 100.00%] [G loss: 8.594386]\n",
      "epoch:49 step:38443 [D loss: 0.088538, acc: 99.22%] [G loss: 4.996043]\n",
      "epoch:49 step:38444 [D loss: 0.004322, acc: 100.00%] [G loss: 12.456936]\n",
      "epoch:49 step:38445 [D loss: 0.078720, acc: 100.00%] [G loss: 7.173073]\n",
      "epoch:49 step:38446 [D loss: 0.194107, acc: 90.62%] [G loss: 10.867989]\n",
      "epoch:49 step:38447 [D loss: 0.440040, acc: 71.88%] [G loss: 6.498681]\n",
      "epoch:49 step:38448 [D loss: 0.435574, acc: 80.47%] [G loss: 6.683297]\n",
      "epoch:49 step:38449 [D loss: 0.107962, acc: 99.22%] [G loss: 7.455588]\n",
      "epoch:49 step:38450 [D loss: 0.080200, acc: 99.22%] [G loss: 5.802474]\n",
      "epoch:49 step:38451 [D loss: 0.240146, acc: 93.75%] [G loss: 7.073057]\n",
      "epoch:49 step:38452 [D loss: 0.039695, acc: 100.00%] [G loss: 8.298071]\n",
      "epoch:49 step:38453 [D loss: 0.190245, acc: 98.44%] [G loss: 9.247366]\n",
      "epoch:49 step:38454 [D loss: 0.804784, acc: 48.44%] [G loss: 7.100329]\n",
      "epoch:49 step:38455 [D loss: 0.532337, acc: 63.28%] [G loss: 8.782665]\n",
      "epoch:49 step:38456 [D loss: 0.195726, acc: 95.31%] [G loss: 8.387188]\n",
      "epoch:49 step:38457 [D loss: 0.777791, acc: 50.78%] [G loss: 6.100353]\n",
      "epoch:49 step:38458 [D loss: 0.063881, acc: 100.00%] [G loss: 8.239563]\n",
      "epoch:49 step:38459 [D loss: 0.133976, acc: 96.88%] [G loss: 6.874864]\n",
      "epoch:49 step:38460 [D loss: 0.633203, acc: 59.38%] [G loss: 8.153034]\n",
      "epoch:49 step:38461 [D loss: 0.104226, acc: 100.00%] [G loss: 7.429797]\n",
      "epoch:49 step:38462 [D loss: 0.030741, acc: 100.00%] [G loss: 4.240968]\n",
      "epoch:49 step:38463 [D loss: 0.039711, acc: 100.00%] [G loss: 7.719923]\n",
      "epoch:49 step:38464 [D loss: 0.224165, acc: 91.41%] [G loss: 7.799995]\n",
      "epoch:49 step:38465 [D loss: 0.437298, acc: 87.50%] [G loss: 4.890441]\n",
      "epoch:49 step:38466 [D loss: 0.529649, acc: 65.62%] [G loss: 5.100608]\n",
      "epoch:49 step:38467 [D loss: 0.019058, acc: 100.00%] [G loss: 4.890231]\n",
      "epoch:49 step:38468 [D loss: 0.465229, acc: 71.09%] [G loss: 10.918285]\n",
      "epoch:49 step:38469 [D loss: 0.085172, acc: 100.00%] [G loss: 9.240969]\n",
      "epoch:49 step:38470 [D loss: 0.699458, acc: 55.47%] [G loss: 9.842764]\n",
      "epoch:49 step:38471 [D loss: 0.785990, acc: 44.53%] [G loss: 6.831018]\n",
      "epoch:49 step:38472 [D loss: 0.279248, acc: 87.50%] [G loss: 10.333817]\n",
      "epoch:49 step:38473 [D loss: 0.062684, acc: 99.22%] [G loss: 5.301461]\n",
      "epoch:49 step:38474 [D loss: 0.152885, acc: 99.22%] [G loss: 4.208216]\n",
      "epoch:49 step:38475 [D loss: 0.024716, acc: 100.00%] [G loss: 4.550871]\n",
      "epoch:49 step:38476 [D loss: 0.106652, acc: 99.22%] [G loss: 5.780041]\n",
      "epoch:49 step:38477 [D loss: 0.825240, acc: 50.00%] [G loss: 7.656177]\n",
      "epoch:49 step:38478 [D loss: 0.140298, acc: 98.44%] [G loss: 5.917099]\n",
      "epoch:49 step:38479 [D loss: 0.241103, acc: 89.06%] [G loss: 13.069185]\n",
      "epoch:49 step:38480 [D loss: 0.353375, acc: 79.69%] [G loss: 7.922078]\n",
      "epoch:49 step:38481 [D loss: 0.004066, acc: 100.00%] [G loss: 8.955347]\n",
      "epoch:49 step:38482 [D loss: 1.747622, acc: 46.09%] [G loss: 8.243561]\n",
      "epoch:49 step:38483 [D loss: 0.013630, acc: 100.00%] [G loss: 7.735703]\n",
      "epoch:49 step:38484 [D loss: 0.082257, acc: 100.00%] [G loss: 7.390345]\n",
      "epoch:49 step:38485 [D loss: 0.242726, acc: 89.06%] [G loss: 7.426438]\n",
      "epoch:49 step:38486 [D loss: 0.052855, acc: 100.00%] [G loss: 3.889597]\n",
      "epoch:49 step:38487 [D loss: 0.082310, acc: 100.00%] [G loss: 6.982666]\n",
      "epoch:49 step:38488 [D loss: 0.063849, acc: 100.00%] [G loss: 6.232864]\n",
      "epoch:49 step:38489 [D loss: 0.017976, acc: 100.00%] [G loss: 8.320696]\n",
      "epoch:49 step:38490 [D loss: 0.235476, acc: 93.75%] [G loss: 11.063781]\n",
      "epoch:49 step:38491 [D loss: 0.438316, acc: 77.34%] [G loss: 7.335306]\n",
      "epoch:49 step:38492 [D loss: 1.041167, acc: 34.38%] [G loss: 11.589982]\n",
      "epoch:49 step:38493 [D loss: 1.191818, acc: 52.34%] [G loss: 4.008789]\n",
      "epoch:49 step:38494 [D loss: 0.547603, acc: 63.28%] [G loss: 6.984574]\n",
      "epoch:49 step:38495 [D loss: 0.006351, acc: 100.00%] [G loss: 11.146211]\n",
      "epoch:49 step:38496 [D loss: 0.035606, acc: 100.00%] [G loss: 9.715866]\n",
      "epoch:49 step:38497 [D loss: 0.088524, acc: 100.00%] [G loss: 7.100002]\n",
      "epoch:49 step:38498 [D loss: 0.085400, acc: 98.44%] [G loss: 5.313170]\n",
      "epoch:49 step:38499 [D loss: 0.041678, acc: 100.00%] [G loss: 6.969534]\n",
      "epoch:49 step:38500 [D loss: 0.008922, acc: 100.00%] [G loss: 6.852156]\n",
      "epoch:49 step:38501 [D loss: 0.046932, acc: 100.00%] [G loss: 5.319755]\n",
      "epoch:49 step:38502 [D loss: 1.310137, acc: 28.91%] [G loss: 9.914626]\n",
      "epoch:49 step:38503 [D loss: 1.028883, acc: 52.34%] [G loss: 6.875470]\n",
      "epoch:49 step:38504 [D loss: 0.026392, acc: 100.00%] [G loss: 8.691059]\n",
      "epoch:49 step:38505 [D loss: 0.044148, acc: 99.22%] [G loss: 4.068084]\n",
      "epoch:49 step:38506 [D loss: 0.216212, acc: 93.75%] [G loss: 7.058336]\n",
      "epoch:49 step:38507 [D loss: 0.035131, acc: 100.00%] [G loss: 6.355838]\n",
      "epoch:49 step:38508 [D loss: 0.038066, acc: 100.00%] [G loss: 8.694312]\n",
      "epoch:49 step:38509 [D loss: 0.218127, acc: 94.53%] [G loss: 7.136388]\n",
      "epoch:49 step:38510 [D loss: 0.384324, acc: 77.34%] [G loss: 7.387084]\n",
      "epoch:49 step:38511 [D loss: 0.013486, acc: 100.00%] [G loss: 6.999102]\n",
      "epoch:49 step:38512 [D loss: 0.541534, acc: 69.53%] [G loss: 3.336717]\n",
      "epoch:49 step:38513 [D loss: 0.018530, acc: 100.00%] [G loss: 6.127630]\n",
      "epoch:49 step:38514 [D loss: 0.012266, acc: 100.00%] [G loss: 8.785789]\n",
      "epoch:49 step:38515 [D loss: 0.311218, acc: 86.72%] [G loss: 4.498476]\n",
      "epoch:49 step:38516 [D loss: 0.490619, acc: 75.78%] [G loss: 6.106827]\n",
      "epoch:49 step:38517 [D loss: 0.361405, acc: 78.12%] [G loss: 7.757317]\n",
      "epoch:49 step:38518 [D loss: 0.609507, acc: 57.03%] [G loss: 11.181019]\n",
      "epoch:49 step:38519 [D loss: 0.469958, acc: 66.41%] [G loss: 7.092505]\n",
      "epoch:49 step:38520 [D loss: 0.780660, acc: 57.03%] [G loss: 9.653332]\n",
      "epoch:49 step:38521 [D loss: 0.944062, acc: 46.09%] [G loss: 6.958592]\n",
      "epoch:49 step:38522 [D loss: 0.040506, acc: 100.00%] [G loss: 8.642136]\n",
      "epoch:49 step:38523 [D loss: 0.112342, acc: 98.44%] [G loss: 6.080422]\n",
      "epoch:49 step:38524 [D loss: 0.217849, acc: 91.41%] [G loss: 7.368666]\n",
      "epoch:49 step:38525 [D loss: 0.617663, acc: 56.25%] [G loss: 8.141006]\n",
      "epoch:49 step:38526 [D loss: 0.013402, acc: 100.00%] [G loss: 6.608078]\n",
      "epoch:49 step:38527 [D loss: 0.103834, acc: 98.44%] [G loss: 10.087738]\n",
      "epoch:49 step:38528 [D loss: 0.353618, acc: 93.75%] [G loss: 7.835738]\n",
      "epoch:49 step:38529 [D loss: 0.138356, acc: 100.00%] [G loss: 3.113402]\n",
      "epoch:49 step:38530 [D loss: 0.113127, acc: 98.44%] [G loss: 9.826560]\n",
      "epoch:49 step:38531 [D loss: 0.026919, acc: 100.00%] [G loss: 7.903096]\n",
      "epoch:49 step:38532 [D loss: 0.050521, acc: 100.00%] [G loss: 6.738132]\n",
      "epoch:49 step:38533 [D loss: 0.020430, acc: 100.00%] [G loss: 4.774605]\n",
      "epoch:49 step:38534 [D loss: 0.287460, acc: 92.97%] [G loss: 7.196113]\n",
      "epoch:49 step:38535 [D loss: 0.008261, acc: 100.00%] [G loss: 7.926093]\n",
      "epoch:49 step:38536 [D loss: 0.077163, acc: 100.00%] [G loss: 5.304344]\n",
      "epoch:49 step:38537 [D loss: 0.588131, acc: 67.97%] [G loss: 6.773130]\n",
      "epoch:49 step:38538 [D loss: 0.618937, acc: 60.94%] [G loss: 9.339822]\n",
      "epoch:49 step:38539 [D loss: 0.014570, acc: 100.00%] [G loss: 7.319479]\n",
      "epoch:49 step:38540 [D loss: 0.123224, acc: 100.00%] [G loss: 10.997010]\n",
      "epoch:49 step:38541 [D loss: 0.103255, acc: 100.00%] [G loss: 7.304965]\n",
      "epoch:49 step:38542 [D loss: 0.649417, acc: 56.25%] [G loss: 9.266722]\n",
      "epoch:49 step:38543 [D loss: 0.187221, acc: 96.09%] [G loss: 5.033231]\n",
      "epoch:49 step:38544 [D loss: 0.278792, acc: 91.41%] [G loss: 3.120276]\n",
      "epoch:49 step:38545 [D loss: 1.256390, acc: 50.00%] [G loss: 11.542397]\n",
      "epoch:49 step:38546 [D loss: 0.347313, acc: 78.91%] [G loss: 3.893393]\n",
      "epoch:49 step:38547 [D loss: 0.390025, acc: 76.56%] [G loss: 11.243897]\n",
      "epoch:49 step:38548 [D loss: 0.158409, acc: 98.44%] [G loss: 5.620121]\n",
      "epoch:49 step:38549 [D loss: 0.062358, acc: 100.00%] [G loss: 7.198982]\n",
      "epoch:49 step:38550 [D loss: 0.151960, acc: 96.09%] [G loss: 6.346137]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:49 step:38551 [D loss: 0.423764, acc: 69.53%] [G loss: 8.530737]\n",
      "epoch:49 step:38552 [D loss: 0.117837, acc: 98.44%] [G loss: 5.181237]\n",
      "epoch:49 step:38553 [D loss: 0.477706, acc: 73.44%] [G loss: 3.767008]\n",
      "epoch:49 step:38554 [D loss: 0.053201, acc: 100.00%] [G loss: 8.114046]\n",
      "epoch:49 step:38555 [D loss: 0.181742, acc: 99.22%] [G loss: 4.745957]\n",
      "epoch:49 step:38556 [D loss: 0.039271, acc: 100.00%] [G loss: 4.462261]\n",
      "epoch:49 step:38557 [D loss: 0.279723, acc: 87.50%] [G loss: 6.286064]\n",
      "epoch:49 step:38558 [D loss: 0.567253, acc: 60.94%] [G loss: 9.052530]\n",
      "epoch:49 step:38559 [D loss: 0.226586, acc: 95.31%] [G loss: 9.158396]\n",
      "epoch:49 step:38560 [D loss: 1.552159, acc: 50.78%] [G loss: 6.234169]\n",
      "epoch:49 step:38561 [D loss: 0.051991, acc: 100.00%] [G loss: 8.151899]\n",
      "epoch:49 step:38562 [D loss: 0.301250, acc: 83.59%] [G loss: 8.110260]\n",
      "epoch:49 step:38563 [D loss: 0.253228, acc: 89.84%] [G loss: 6.672089]\n",
      "epoch:49 step:38564 [D loss: 0.344194, acc: 84.38%] [G loss: 7.311913]\n",
      "epoch:49 step:38565 [D loss: 0.258131, acc: 89.06%] [G loss: 8.737305]\n",
      "epoch:49 step:38566 [D loss: 0.124004, acc: 98.44%] [G loss: 6.132604]\n",
      "epoch:49 step:38567 [D loss: 0.053617, acc: 100.00%] [G loss: 6.524761]\n",
      "epoch:49 step:38568 [D loss: 0.152326, acc: 96.09%] [G loss: 7.692907]\n",
      "epoch:49 step:38569 [D loss: 0.293031, acc: 91.41%] [G loss: 4.481020]\n",
      "epoch:49 step:38570 [D loss: 0.021756, acc: 100.00%] [G loss: 9.620728]\n",
      "epoch:49 step:38571 [D loss: 0.567984, acc: 60.16%] [G loss: 5.109001]\n",
      "epoch:49 step:38572 [D loss: 0.030211, acc: 100.00%] [G loss: 5.576205]\n",
      "epoch:49 step:38573 [D loss: 0.645568, acc: 62.50%] [G loss: 5.079193]\n",
      "epoch:49 step:38574 [D loss: 0.019260, acc: 100.00%] [G loss: 8.766562]\n",
      "epoch:49 step:38575 [D loss: 0.027751, acc: 100.00%] [G loss: 8.877397]\n",
      "epoch:49 step:38576 [D loss: 0.417158, acc: 78.91%] [G loss: 11.774461]\n",
      "epoch:49 step:38577 [D loss: 0.052457, acc: 100.00%] [G loss: 5.118398]\n",
      "epoch:49 step:38578 [D loss: 0.812350, acc: 53.12%] [G loss: 8.144536]\n",
      "epoch:49 step:38579 [D loss: 0.104483, acc: 99.22%] [G loss: 8.588655]\n",
      "epoch:49 step:38580 [D loss: 1.153484, acc: 50.00%] [G loss: 12.996838]\n",
      "epoch:49 step:38581 [D loss: 0.053645, acc: 99.22%] [G loss: 6.168048]\n",
      "epoch:49 step:38582 [D loss: 0.179547, acc: 97.66%] [G loss: 8.646044]\n",
      "epoch:49 step:38583 [D loss: 0.296224, acc: 89.84%] [G loss: 8.136658]\n",
      "epoch:49 step:38584 [D loss: 0.129679, acc: 98.44%] [G loss: 4.976694]\n",
      "epoch:49 step:38585 [D loss: 0.068217, acc: 100.00%] [G loss: 6.251059]\n",
      "epoch:49 step:38586 [D loss: 0.043481, acc: 100.00%] [G loss: 7.613772]\n",
      "epoch:49 step:38587 [D loss: 0.458118, acc: 68.75%] [G loss: 7.054035]\n",
      "epoch:49 step:38588 [D loss: 0.845321, acc: 53.12%] [G loss: 6.369680]\n",
      "epoch:49 step:38589 [D loss: 0.054536, acc: 100.00%] [G loss: 6.576233]\n",
      "epoch:49 step:38590 [D loss: 0.175230, acc: 96.09%] [G loss: 8.011612]\n",
      "epoch:49 step:38591 [D loss: 0.186125, acc: 96.09%] [G loss: 7.070029]\n",
      "epoch:49 step:38592 [D loss: 0.572070, acc: 67.19%] [G loss: 5.041505]\n",
      "epoch:49 step:38593 [D loss: 0.479998, acc: 66.41%] [G loss: 9.694690]\n",
      "epoch:49 step:38594 [D loss: 0.228044, acc: 92.97%] [G loss: 6.688297]\n",
      "epoch:49 step:38595 [D loss: 0.762352, acc: 53.91%] [G loss: 6.625255]\n",
      "epoch:49 step:38596 [D loss: 0.260390, acc: 93.75%] [G loss: 9.089649]\n",
      "epoch:49 step:38597 [D loss: 0.585911, acc: 67.19%] [G loss: 11.243370]\n",
      "epoch:49 step:38598 [D loss: 0.016634, acc: 100.00%] [G loss: 6.550004]\n",
      "epoch:49 step:38599 [D loss: 0.066834, acc: 100.00%] [G loss: 7.884730]\n",
      "epoch:49 step:38600 [D loss: 0.053039, acc: 100.00%] [G loss: 5.340533]\n",
      "##############\n",
      "[0.85847458 0.88305487 0.81373238 0.81272804 0.79393776 0.81750548\n",
      " 0.88668968 0.8140828  0.80263152 0.8215257 ]\n",
      "##########\n",
      "epoch:49 step:38601 [D loss: 0.152736, acc: 97.66%] [G loss: 7.226038]\n",
      "epoch:49 step:38602 [D loss: 0.059900, acc: 100.00%] [G loss: 7.366910]\n",
      "epoch:49 step:38603 [D loss: 1.189601, acc: 50.78%] [G loss: 9.482859]\n",
      "epoch:49 step:38604 [D loss: 0.098372, acc: 100.00%] [G loss: 6.379853]\n",
      "epoch:49 step:38605 [D loss: 0.142867, acc: 98.44%] [G loss: 9.118855]\n",
      "epoch:49 step:38606 [D loss: 0.088875, acc: 100.00%] [G loss: 6.055371]\n",
      "epoch:49 step:38607 [D loss: 0.339441, acc: 85.94%] [G loss: 9.795731]\n",
      "epoch:49 step:38608 [D loss: 0.030809, acc: 100.00%] [G loss: 7.493435]\n",
      "epoch:49 step:38609 [D loss: 0.225404, acc: 91.41%] [G loss: 5.909415]\n",
      "epoch:49 step:38610 [D loss: 0.014961, acc: 100.00%] [G loss: 11.006432]\n",
      "epoch:49 step:38611 [D loss: 0.072123, acc: 99.22%] [G loss: 10.184241]\n",
      "epoch:49 step:38612 [D loss: 0.030266, acc: 100.00%] [G loss: 8.148998]\n",
      "epoch:49 step:38613 [D loss: 2.242111, acc: 41.41%] [G loss: 10.325192]\n",
      "epoch:49 step:38614 [D loss: 0.203732, acc: 92.97%] [G loss: 6.109554]\n",
      "epoch:49 step:38615 [D loss: 0.176458, acc: 93.75%] [G loss: 6.779522]\n",
      "epoch:49 step:38616 [D loss: 0.165441, acc: 98.44%] [G loss: 9.626423]\n",
      "epoch:49 step:38617 [D loss: 0.094407, acc: 100.00%] [G loss: 10.667153]\n",
      "epoch:49 step:38618 [D loss: 0.178171, acc: 96.09%] [G loss: 4.224286]\n",
      "epoch:49 step:38619 [D loss: 0.419768, acc: 74.22%] [G loss: 7.629926]\n",
      "epoch:49 step:38620 [D loss: 0.149783, acc: 98.44%] [G loss: 8.229252]\n",
      "epoch:49 step:38621 [D loss: 0.038097, acc: 100.00%] [G loss: 6.888286]\n",
      "epoch:49 step:38622 [D loss: 0.378845, acc: 84.38%] [G loss: 3.247748]\n",
      "epoch:49 step:38623 [D loss: 0.075414, acc: 100.00%] [G loss: 4.581574]\n",
      "epoch:49 step:38624 [D loss: 0.244522, acc: 92.97%] [G loss: 7.747705]\n",
      "epoch:49 step:38625 [D loss: 0.253327, acc: 89.84%] [G loss: 5.115353]\n",
      "epoch:49 step:38626 [D loss: 0.630907, acc: 53.12%] [G loss: 5.977101]\n",
      "epoch:49 step:38627 [D loss: 0.138369, acc: 99.22%] [G loss: 3.129320]\n",
      "epoch:49 step:38628 [D loss: 0.148357, acc: 99.22%] [G loss: 5.296876]\n",
      "epoch:49 step:38629 [D loss: 0.020212, acc: 99.22%] [G loss: 9.091770]\n",
      "epoch:49 step:38630 [D loss: 0.078477, acc: 99.22%] [G loss: 7.009394]\n",
      "epoch:49 step:38631 [D loss: 0.773336, acc: 51.56%] [G loss: 6.607574]\n",
      "epoch:49 step:38632 [D loss: 0.019237, acc: 100.00%] [G loss: 5.261961]\n",
      "epoch:49 step:38633 [D loss: 0.191964, acc: 93.75%] [G loss: 7.609392]\n",
      "epoch:49 step:38634 [D loss: 0.448283, acc: 70.31%] [G loss: 8.732356]\n",
      "epoch:49 step:38635 [D loss: 1.473235, acc: 50.00%] [G loss: 8.697042]\n",
      "epoch:49 step:38636 [D loss: 0.545459, acc: 64.06%] [G loss: 8.434280]\n",
      "epoch:49 step:38637 [D loss: 0.022737, acc: 100.00%] [G loss: 8.366787]\n",
      "epoch:49 step:38638 [D loss: 1.334091, acc: 50.78%] [G loss: 5.077586]\n",
      "epoch:49 step:38639 [D loss: 0.733829, acc: 57.81%] [G loss: 9.431293]\n",
      "epoch:49 step:38640 [D loss: 0.016254, acc: 100.00%] [G loss: 7.357520]\n",
      "epoch:49 step:38641 [D loss: 0.068389, acc: 99.22%] [G loss: 5.665577]\n",
      "epoch:49 step:38642 [D loss: 0.110255, acc: 99.22%] [G loss: 7.317999]\n",
      "epoch:49 step:38643 [D loss: 0.008469, acc: 100.00%] [G loss: 6.526044]\n",
      "epoch:49 step:38644 [D loss: 0.072927, acc: 100.00%] [G loss: 5.093709]\n",
      "epoch:49 step:38645 [D loss: 0.420596, acc: 72.66%] [G loss: 6.236224]\n",
      "epoch:49 step:38646 [D loss: 0.344537, acc: 83.59%] [G loss: 8.716533]\n",
      "epoch:49 step:38647 [D loss: 1.345632, acc: 50.00%] [G loss: 9.566006]\n",
      "epoch:49 step:38648 [D loss: 0.889180, acc: 51.56%] [G loss: 8.553162]\n",
      "epoch:49 step:38649 [D loss: 0.952812, acc: 38.28%] [G loss: 8.736477]\n",
      "epoch:49 step:38650 [D loss: 0.311012, acc: 88.28%] [G loss: 3.725061]\n",
      "epoch:49 step:38651 [D loss: 0.012871, acc: 100.00%] [G loss: 7.505812]\n",
      "epoch:49 step:38652 [D loss: 0.363429, acc: 75.78%] [G loss: 5.932243]\n",
      "epoch:49 step:38653 [D loss: 0.853213, acc: 53.91%] [G loss: 6.781041]\n",
      "epoch:49 step:38654 [D loss: 0.522023, acc: 78.12%] [G loss: 5.707783]\n",
      "epoch:49 step:38655 [D loss: 0.201249, acc: 99.22%] [G loss: 5.154871]\n",
      "epoch:49 step:38656 [D loss: 0.613024, acc: 57.81%] [G loss: 6.295342]\n",
      "epoch:49 step:38657 [D loss: 0.390820, acc: 72.66%] [G loss: 3.358779]\n",
      "epoch:49 step:38658 [D loss: 0.101977, acc: 98.44%] [G loss: 6.800710]\n",
      "epoch:49 step:38659 [D loss: 0.033921, acc: 100.00%] [G loss: 9.095631]\n",
      "epoch:49 step:38660 [D loss: 0.249792, acc: 89.06%] [G loss: 8.979052]\n",
      "epoch:49 step:38661 [D loss: 0.863965, acc: 53.91%] [G loss: 6.543951]\n",
      "epoch:49 step:38662 [D loss: 0.326175, acc: 78.91%] [G loss: 6.099714]\n",
      "epoch:49 step:38663 [D loss: 0.058148, acc: 99.22%] [G loss: 8.410875]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:49 step:38664 [D loss: 0.189158, acc: 97.66%] [G loss: 4.872511]\n",
      "epoch:49 step:38665 [D loss: 0.026453, acc: 100.00%] [G loss: 5.773404]\n",
      "epoch:49 step:38666 [D loss: 0.334460, acc: 94.53%] [G loss: 6.437474]\n",
      "epoch:49 step:38667 [D loss: 0.538228, acc: 67.97%] [G loss: 8.666069]\n",
      "epoch:49 step:38668 [D loss: 0.245148, acc: 96.09%] [G loss: 7.552814]\n",
      "epoch:49 step:38669 [D loss: 0.006729, acc: 100.00%] [G loss: 6.136456]\n",
      "epoch:49 step:38670 [D loss: 0.013069, acc: 100.00%] [G loss: 9.730010]\n",
      "epoch:49 step:38671 [D loss: 1.074475, acc: 50.78%] [G loss: 5.950663]\n",
      "epoch:49 step:38672 [D loss: 0.036213, acc: 100.00%] [G loss: 4.977769]\n",
      "epoch:49 step:38673 [D loss: 1.449870, acc: 50.00%] [G loss: 5.730835]\n",
      "epoch:49 step:38674 [D loss: 0.048322, acc: 100.00%] [G loss: 9.248395]\n",
      "epoch:49 step:38675 [D loss: 0.079308, acc: 100.00%] [G loss: 11.329140]\n",
      "epoch:49 step:38676 [D loss: 0.669197, acc: 57.03%] [G loss: 8.424559]\n",
      "epoch:49 step:38677 [D loss: 0.148571, acc: 97.66%] [G loss: 3.063459]\n",
      "epoch:49 step:38678 [D loss: 0.605471, acc: 62.50%] [G loss: 7.822338]\n",
      "epoch:49 step:38679 [D loss: 0.610991, acc: 59.38%] [G loss: 11.191751]\n",
      "epoch:49 step:38680 [D loss: 0.328572, acc: 91.41%] [G loss: 8.263670]\n",
      "epoch:49 step:38681 [D loss: 0.259968, acc: 92.97%] [G loss: 5.340886]\n",
      "epoch:49 step:38682 [D loss: 0.337383, acc: 80.47%] [G loss: 9.529419]\n",
      "epoch:49 step:38683 [D loss: 0.377134, acc: 74.22%] [G loss: 3.703289]\n",
      "epoch:49 step:38684 [D loss: 0.298182, acc: 91.41%] [G loss: 5.612969]\n",
      "epoch:49 step:38685 [D loss: 0.035803, acc: 100.00%] [G loss: 7.958675]\n",
      "epoch:49 step:38686 [D loss: 0.302246, acc: 89.06%] [G loss: 5.247103]\n",
      "epoch:49 step:38687 [D loss: 0.112613, acc: 99.22%] [G loss: 5.246736]\n",
      "epoch:49 step:38688 [D loss: 0.948233, acc: 51.56%] [G loss: 7.515149]\n",
      "epoch:49 step:38689 [D loss: 0.067019, acc: 100.00%] [G loss: 7.699955]\n",
      "epoch:49 step:38690 [D loss: 0.547961, acc: 64.84%] [G loss: 7.886329]\n",
      "epoch:49 step:38691 [D loss: 0.644830, acc: 58.59%] [G loss: 3.602075]\n",
      "epoch:49 step:38692 [D loss: 0.038787, acc: 100.00%] [G loss: 7.762904]\n",
      "epoch:49 step:38693 [D loss: 0.079002, acc: 100.00%] [G loss: 5.681735]\n",
      "epoch:49 step:38694 [D loss: 0.719016, acc: 54.69%] [G loss: 11.836853]\n",
      "epoch:49 step:38695 [D loss: 0.011337, acc: 100.00%] [G loss: 5.781941]\n",
      "epoch:49 step:38696 [D loss: 0.403462, acc: 71.09%] [G loss: 6.109493]\n",
      "epoch:49 step:38697 [D loss: 0.002699, acc: 100.00%] [G loss: 10.776293]\n",
      "epoch:49 step:38698 [D loss: 0.002835, acc: 100.00%] [G loss: 9.241385]\n",
      "epoch:49 step:38699 [D loss: 0.071005, acc: 99.22%] [G loss: 6.331692]\n",
      "epoch:49 step:38700 [D loss: 0.091996, acc: 99.22%] [G loss: 10.458601]\n",
      "epoch:49 step:38701 [D loss: 0.036173, acc: 100.00%] [G loss: 4.244336]\n",
      "epoch:49 step:38702 [D loss: 0.086111, acc: 99.22%] [G loss: 5.748399]\n",
      "epoch:49 step:38703 [D loss: 0.435775, acc: 73.44%] [G loss: 8.418146]\n",
      "epoch:49 step:38704 [D loss: 0.004158, acc: 100.00%] [G loss: 7.557307]\n",
      "epoch:49 step:38705 [D loss: 0.235342, acc: 92.19%] [G loss: 3.291948]\n",
      "epoch:49 step:38706 [D loss: 0.525233, acc: 61.72%] [G loss: 8.405545]\n",
      "epoch:49 step:38707 [D loss: 0.097146, acc: 100.00%] [G loss: 8.048681]\n",
      "epoch:49 step:38708 [D loss: 1.031278, acc: 50.00%] [G loss: 2.253481]\n",
      "epoch:49 step:38709 [D loss: 0.098594, acc: 98.44%] [G loss: 9.482309]\n",
      "epoch:49 step:38710 [D loss: 0.496570, acc: 76.56%] [G loss: 4.613806]\n",
      "epoch:49 step:38711 [D loss: 0.548796, acc: 59.38%] [G loss: 5.020541]\n",
      "epoch:49 step:38712 [D loss: 0.225265, acc: 96.88%] [G loss: 3.798775]\n",
      "epoch:49 step:38713 [D loss: 0.201939, acc: 96.88%] [G loss: 4.794330]\n",
      "epoch:49 step:38714 [D loss: 0.219063, acc: 96.09%] [G loss: 6.445305]\n",
      "epoch:49 step:38715 [D loss: 0.509923, acc: 73.44%] [G loss: 9.498098]\n",
      "epoch:49 step:38716 [D loss: 0.223962, acc: 94.53%] [G loss: 3.771142]\n",
      "epoch:49 step:38717 [D loss: 0.051255, acc: 100.00%] [G loss: 9.288628]\n",
      "epoch:49 step:38718 [D loss: 0.062041, acc: 100.00%] [G loss: 8.534508]\n",
      "epoch:49 step:38719 [D loss: 0.534658, acc: 64.84%] [G loss: 10.766520]\n",
      "epoch:49 step:38720 [D loss: 0.100482, acc: 99.22%] [G loss: 9.087631]\n",
      "epoch:49 step:38721 [D loss: 0.188731, acc: 94.53%] [G loss: 13.364565]\n",
      "epoch:49 step:38722 [D loss: 0.136080, acc: 98.44%] [G loss: 4.400519]\n",
      "epoch:49 step:38723 [D loss: 0.029836, acc: 100.00%] [G loss: 5.753004]\n",
      "epoch:49 step:38724 [D loss: 0.040800, acc: 100.00%] [G loss: 7.179261]\n",
      "epoch:49 step:38725 [D loss: 1.164794, acc: 47.66%] [G loss: 4.188964]\n",
      "epoch:49 step:38726 [D loss: 0.844398, acc: 52.34%] [G loss: 11.356276]\n",
      "epoch:49 step:38727 [D loss: 0.054876, acc: 100.00%] [G loss: 4.000199]\n",
      "epoch:49 step:38728 [D loss: 0.845829, acc: 53.12%] [G loss: 5.990475]\n",
      "epoch:49 step:38729 [D loss: 0.082865, acc: 100.00%] [G loss: 5.493560]\n",
      "epoch:49 step:38730 [D loss: 0.029843, acc: 100.00%] [G loss: 9.004082]\n",
      "epoch:49 step:38731 [D loss: 0.188661, acc: 96.09%] [G loss: 11.466132]\n",
      "epoch:49 step:38732 [D loss: 0.077373, acc: 100.00%] [G loss: 11.544842]\n",
      "epoch:49 step:38733 [D loss: 0.173311, acc: 99.22%] [G loss: 5.181952]\n",
      "epoch:49 step:38734 [D loss: 0.830366, acc: 51.56%] [G loss: 8.989305]\n",
      "epoch:49 step:38735 [D loss: 0.120853, acc: 98.44%] [G loss: 10.692928]\n",
      "epoch:49 step:38736 [D loss: 0.280863, acc: 86.72%] [G loss: 6.266716]\n",
      "epoch:49 step:38737 [D loss: 0.198050, acc: 95.31%] [G loss: 5.555304]\n",
      "epoch:49 step:38738 [D loss: 0.052854, acc: 100.00%] [G loss: 2.936923]\n",
      "epoch:49 step:38739 [D loss: 0.008966, acc: 100.00%] [G loss: 11.852542]\n",
      "epoch:49 step:38740 [D loss: 0.214485, acc: 91.41%] [G loss: 10.869756]\n",
      "epoch:49 step:38741 [D loss: 1.204491, acc: 50.78%] [G loss: 7.046963]\n",
      "epoch:49 step:38742 [D loss: 0.126602, acc: 98.44%] [G loss: 5.877462]\n",
      "epoch:49 step:38743 [D loss: 0.162865, acc: 95.31%] [G loss: 8.567152]\n",
      "epoch:49 step:38744 [D loss: 0.183714, acc: 95.31%] [G loss: 7.066563]\n",
      "epoch:49 step:38745 [D loss: 0.308326, acc: 82.03%] [G loss: 10.197553]\n",
      "epoch:49 step:38746 [D loss: 0.205943, acc: 93.75%] [G loss: 4.331364]\n",
      "epoch:49 step:38747 [D loss: 0.031362, acc: 100.00%] [G loss: 8.216307]\n",
      "epoch:49 step:38748 [D loss: 0.514675, acc: 75.00%] [G loss: 7.724176]\n",
      "epoch:49 step:38749 [D loss: 0.183029, acc: 98.44%] [G loss: 7.570792]\n",
      "epoch:49 step:38750 [D loss: 0.019274, acc: 100.00%] [G loss: 3.372015]\n",
      "epoch:49 step:38751 [D loss: 0.371038, acc: 76.56%] [G loss: 3.384115]\n",
      "epoch:49 step:38752 [D loss: 0.134234, acc: 98.44%] [G loss: 5.465821]\n",
      "epoch:49 step:38753 [D loss: 1.535639, acc: 9.38%] [G loss: 10.758285]\n",
      "epoch:49 step:38754 [D loss: 0.265108, acc: 94.53%] [G loss: 3.567877]\n",
      "epoch:49 step:38755 [D loss: 0.090908, acc: 100.00%] [G loss: 3.987099]\n",
      "epoch:49 step:38756 [D loss: 0.067431, acc: 100.00%] [G loss: 2.415620]\n",
      "epoch:49 step:38757 [D loss: 0.193696, acc: 96.88%] [G loss: 8.560553]\n",
      "epoch:49 step:38758 [D loss: 0.118545, acc: 100.00%] [G loss: 6.023733]\n",
      "epoch:49 step:38759 [D loss: 0.145706, acc: 96.88%] [G loss: 7.713705]\n",
      "epoch:49 step:38760 [D loss: 1.191828, acc: 50.00%] [G loss: 4.091174]\n",
      "epoch:49 step:38761 [D loss: 0.022418, acc: 100.00%] [G loss: 8.139613]\n",
      "epoch:49 step:38762 [D loss: 0.122123, acc: 100.00%] [G loss: 3.446344]\n",
      "epoch:49 step:38763 [D loss: 0.274060, acc: 89.84%] [G loss: 5.106219]\n",
      "epoch:49 step:38764 [D loss: 0.117360, acc: 98.44%] [G loss: 8.118035]\n",
      "epoch:49 step:38765 [D loss: 0.953053, acc: 42.97%] [G loss: 5.917147]\n",
      "epoch:49 step:38766 [D loss: 0.255216, acc: 89.06%] [G loss: 10.864301]\n",
      "epoch:49 step:38767 [D loss: 0.182017, acc: 98.44%] [G loss: 7.800085]\n",
      "epoch:49 step:38768 [D loss: 0.385199, acc: 76.56%] [G loss: 9.514749]\n",
      "epoch:49 step:38769 [D loss: 0.145000, acc: 99.22%] [G loss: 6.049064]\n",
      "epoch:49 step:38770 [D loss: 0.317100, acc: 92.97%] [G loss: 6.526646]\n",
      "epoch:49 step:38771 [D loss: 0.594139, acc: 61.72%] [G loss: 9.041024]\n",
      "epoch:49 step:38772 [D loss: 0.569172, acc: 66.41%] [G loss: 8.782974]\n",
      "epoch:49 step:38773 [D loss: 0.053919, acc: 100.00%] [G loss: 4.913834]\n",
      "epoch:49 step:38774 [D loss: 0.365267, acc: 75.78%] [G loss: 6.339555]\n",
      "epoch:49 step:38775 [D loss: 0.134014, acc: 98.44%] [G loss: 6.198247]\n",
      "epoch:49 step:38776 [D loss: 0.452886, acc: 70.31%] [G loss: 3.186207]\n",
      "epoch:49 step:38777 [D loss: 0.029800, acc: 100.00%] [G loss: 4.767062]\n",
      "epoch:49 step:38778 [D loss: 0.268212, acc: 92.97%] [G loss: 6.192602]\n",
      "epoch:49 step:38779 [D loss: 0.275569, acc: 89.06%] [G loss: 5.212989]\n",
      "epoch:49 step:38780 [D loss: 0.093724, acc: 99.22%] [G loss: 13.666836]\n",
      "epoch:49 step:38781 [D loss: 0.081928, acc: 100.00%] [G loss: 5.449140]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:49 step:38782 [D loss: 0.039981, acc: 100.00%] [G loss: 4.255907]\n",
      "epoch:49 step:38783 [D loss: 0.118269, acc: 100.00%] [G loss: 5.453391]\n",
      "epoch:49 step:38784 [D loss: 0.156674, acc: 99.22%] [G loss: 6.586004]\n",
      "epoch:49 step:38785 [D loss: 0.226852, acc: 92.19%] [G loss: 4.651856]\n",
      "epoch:49 step:38786 [D loss: 0.236631, acc: 89.06%] [G loss: 12.362565]\n",
      "epoch:49 step:38787 [D loss: 1.241973, acc: 32.03%] [G loss: 8.816689]\n",
      "epoch:49 step:38788 [D loss: 0.370883, acc: 82.03%] [G loss: 7.244182]\n",
      "epoch:49 step:38789 [D loss: 1.178324, acc: 50.78%] [G loss: 5.758637]\n",
      "epoch:49 step:38790 [D loss: 0.059728, acc: 100.00%] [G loss: 6.455717]\n",
      "epoch:49 step:38791 [D loss: 0.131316, acc: 100.00%] [G loss: 6.418021]\n",
      "epoch:49 step:38792 [D loss: 0.546852, acc: 61.72%] [G loss: 8.198114]\n",
      "epoch:49 step:38793 [D loss: 0.255787, acc: 88.28%] [G loss: 8.474720]\n",
      "epoch:49 step:38794 [D loss: 0.151264, acc: 99.22%] [G loss: 3.539345]\n",
      "epoch:49 step:38795 [D loss: 0.085886, acc: 99.22%] [G loss: 3.142316]\n",
      "epoch:49 step:38796 [D loss: 0.254415, acc: 95.31%] [G loss: 5.467390]\n",
      "epoch:49 step:38797 [D loss: 0.087550, acc: 100.00%] [G loss: 7.147813]\n",
      "epoch:49 step:38798 [D loss: 0.263089, acc: 94.53%] [G loss: 6.954771]\n",
      "epoch:49 step:38799 [D loss: 0.060111, acc: 100.00%] [G loss: 6.596525]\n",
      "epoch:49 step:38800 [D loss: 0.775803, acc: 52.34%] [G loss: 9.798697]\n",
      "##############\n",
      "[0.84085121 0.87380261 0.82137655 0.80214341 0.77356817 0.84138847\n",
      " 0.91448097 0.83023698 0.80089707 0.83733499]\n",
      "##########\n",
      "epoch:49 step:38801 [D loss: 2.298834, acc: 43.75%] [G loss: 4.773383]\n",
      "epoch:49 step:38802 [D loss: 0.097368, acc: 98.44%] [G loss: 7.054685]\n",
      "epoch:49 step:38803 [D loss: 0.207802, acc: 98.44%] [G loss: 4.190565]\n",
      "epoch:49 step:38804 [D loss: 0.862060, acc: 46.09%] [G loss: 10.165041]\n",
      "epoch:49 step:38805 [D loss: 0.223051, acc: 96.88%] [G loss: 4.751339]\n",
      "epoch:49 step:38806 [D loss: 0.025864, acc: 100.00%] [G loss: 12.533978]\n",
      "epoch:49 step:38807 [D loss: 0.287271, acc: 86.72%] [G loss: 7.203430]\n",
      "epoch:49 step:38808 [D loss: 0.562821, acc: 68.75%] [G loss: 11.598228]\n",
      "epoch:49 step:38809 [D loss: 0.499266, acc: 74.22%] [G loss: 3.988324]\n",
      "epoch:49 step:38810 [D loss: 0.206107, acc: 95.31%] [G loss: 5.153967]\n",
      "epoch:49 step:38811 [D loss: 0.007793, acc: 100.00%] [G loss: 8.595551]\n",
      "epoch:49 step:38812 [D loss: 0.055265, acc: 100.00%] [G loss: 9.061072]\n",
      "epoch:49 step:38813 [D loss: 0.157835, acc: 98.44%] [G loss: 3.809547]\n",
      "epoch:49 step:38814 [D loss: 0.480046, acc: 78.12%] [G loss: 5.860900]\n",
      "epoch:49 step:38815 [D loss: 0.076340, acc: 99.22%] [G loss: 6.801314]\n",
      "epoch:49 step:38816 [D loss: 0.150012, acc: 97.66%] [G loss: 6.794480]\n",
      "epoch:49 step:38817 [D loss: 0.553483, acc: 59.38%] [G loss: 8.603244]\n",
      "epoch:49 step:38818 [D loss: 0.491713, acc: 67.19%] [G loss: 9.100160]\n",
      "epoch:49 step:38819 [D loss: 0.077428, acc: 100.00%] [G loss: 10.216970]\n",
      "epoch:49 step:38820 [D loss: 0.085709, acc: 100.00%] [G loss: 7.758984]\n",
      "epoch:49 step:38821 [D loss: 0.121679, acc: 99.22%] [G loss: 5.929653]\n",
      "epoch:49 step:38822 [D loss: 0.103186, acc: 99.22%] [G loss: 5.126428]\n",
      "epoch:49 step:38823 [D loss: 0.943620, acc: 37.50%] [G loss: 6.810982]\n",
      "epoch:49 step:38824 [D loss: 0.393895, acc: 74.22%] [G loss: 6.951496]\n",
      "epoch:49 step:38825 [D loss: 0.009245, acc: 100.00%] [G loss: 6.259624]\n",
      "epoch:49 step:38826 [D loss: 0.460393, acc: 80.47%] [G loss: 6.893031]\n",
      "epoch:49 step:38827 [D loss: 0.084862, acc: 100.00%] [G loss: 10.408220]\n",
      "epoch:49 step:38828 [D loss: 0.069112, acc: 98.44%] [G loss: 6.641029]\n",
      "epoch:49 step:38829 [D loss: 0.721117, acc: 54.69%] [G loss: 5.997905]\n",
      "epoch:49 step:38830 [D loss: 0.083869, acc: 99.22%] [G loss: 8.254572]\n",
      "epoch:49 step:38831 [D loss: 0.174688, acc: 96.88%] [G loss: 7.445402]\n",
      "epoch:49 step:38832 [D loss: 0.879021, acc: 51.56%] [G loss: 8.951260]\n",
      "epoch:49 step:38833 [D loss: 0.010721, acc: 100.00%] [G loss: 8.500363]\n",
      "epoch:49 step:38834 [D loss: 0.587098, acc: 60.94%] [G loss: 9.449825]\n",
      "epoch:49 step:38835 [D loss: 0.004247, acc: 100.00%] [G loss: 8.108421]\n",
      "epoch:49 step:38836 [D loss: 0.230308, acc: 96.88%] [G loss: 5.080456]\n",
      "epoch:49 step:38837 [D loss: 0.085417, acc: 99.22%] [G loss: 5.549229]\n",
      "epoch:49 step:38838 [D loss: 0.115421, acc: 99.22%] [G loss: 10.491398]\n",
      "epoch:49 step:38839 [D loss: 0.349569, acc: 78.91%] [G loss: 6.244782]\n",
      "epoch:49 step:38840 [D loss: 0.306412, acc: 81.25%] [G loss: 5.011748]\n",
      "epoch:49 step:38841 [D loss: 0.445347, acc: 71.09%] [G loss: 7.840087]\n",
      "epoch:49 step:38842 [D loss: 0.288386, acc: 89.06%] [G loss: 6.998963]\n",
      "epoch:49 step:38843 [D loss: 0.890495, acc: 51.56%] [G loss: 4.563024]\n",
      "epoch:49 step:38844 [D loss: 0.862058, acc: 51.56%] [G loss: 8.783150]\n",
      "epoch:49 step:38845 [D loss: 0.350793, acc: 85.16%] [G loss: 8.674990]\n",
      "epoch:49 step:38846 [D loss: 0.185723, acc: 95.31%] [G loss: 8.749752]\n",
      "epoch:49 step:38847 [D loss: 1.124970, acc: 45.31%] [G loss: 11.322640]\n",
      "epoch:49 step:38848 [D loss: 0.218321, acc: 96.09%] [G loss: 7.726020]\n",
      "epoch:49 step:38849 [D loss: 0.352904, acc: 79.69%] [G loss: 9.935905]\n",
      "epoch:49 step:38850 [D loss: 0.427152, acc: 87.50%] [G loss: 7.548763]\n",
      "epoch:49 step:38851 [D loss: 0.781316, acc: 51.56%] [G loss: 5.814291]\n",
      "epoch:49 step:38852 [D loss: 0.449429, acc: 73.44%] [G loss: 9.051497]\n",
      "epoch:49 step:38853 [D loss: 0.012636, acc: 100.00%] [G loss: 11.704119]\n",
      "epoch:49 step:38854 [D loss: 0.032190, acc: 99.22%] [G loss: 9.723162]\n",
      "epoch:49 step:38855 [D loss: 0.262116, acc: 89.84%] [G loss: 7.163723]\n",
      "epoch:49 step:38856 [D loss: 0.092842, acc: 100.00%] [G loss: 6.149767]\n",
      "epoch:49 step:38857 [D loss: 0.277684, acc: 85.94%] [G loss: 11.108900]\n",
      "epoch:49 step:38858 [D loss: 0.039312, acc: 100.00%] [G loss: 5.339078]\n",
      "epoch:49 step:38859 [D loss: 0.030976, acc: 100.00%] [G loss: 4.563787]\n",
      "epoch:49 step:38860 [D loss: 0.012564, acc: 100.00%] [G loss: 8.291281]\n",
      "epoch:49 step:38861 [D loss: 0.542957, acc: 75.78%] [G loss: 4.226140]\n",
      "epoch:49 step:38862 [D loss: 0.141656, acc: 97.66%] [G loss: 4.645514]\n",
      "epoch:49 step:38863 [D loss: 0.026285, acc: 100.00%] [G loss: 3.014956]\n",
      "epoch:49 step:38864 [D loss: 0.478664, acc: 67.97%] [G loss: 6.510523]\n",
      "epoch:49 step:38865 [D loss: 0.115486, acc: 100.00%] [G loss: 5.365754]\n",
      "epoch:49 step:38866 [D loss: 0.057774, acc: 100.00%] [G loss: 5.517817]\n",
      "epoch:49 step:38867 [D loss: 0.803154, acc: 55.47%] [G loss: 9.489631]\n",
      "epoch:49 step:38868 [D loss: 0.103730, acc: 99.22%] [G loss: 5.083429]\n",
      "epoch:49 step:38869 [D loss: 0.651037, acc: 57.81%] [G loss: 6.532444]\n",
      "epoch:49 step:38870 [D loss: 0.199196, acc: 97.66%] [G loss: 3.750304]\n",
      "epoch:49 step:38871 [D loss: 0.014565, acc: 100.00%] [G loss: 5.605394]\n",
      "epoch:49 step:38872 [D loss: 0.234406, acc: 94.53%] [G loss: 3.525197]\n",
      "epoch:49 step:38873 [D loss: 0.929759, acc: 53.91%] [G loss: 9.757405]\n",
      "epoch:49 step:38874 [D loss: 0.085233, acc: 99.22%] [G loss: 4.566803]\n",
      "epoch:49 step:38875 [D loss: 0.086431, acc: 100.00%] [G loss: 5.681234]\n",
      "epoch:49 step:38876 [D loss: 0.061640, acc: 99.22%] [G loss: 7.292784]\n",
      "epoch:49 step:38877 [D loss: 0.099527, acc: 98.44%] [G loss: 1.944633]\n",
      "epoch:49 step:38878 [D loss: 0.312646, acc: 91.41%] [G loss: 2.730840]\n",
      "epoch:49 step:38879 [D loss: 1.037207, acc: 31.25%] [G loss: 9.681606]\n",
      "epoch:49 step:38880 [D loss: 0.389912, acc: 86.72%] [G loss: 7.265957]\n",
      "epoch:49 step:38881 [D loss: 0.047016, acc: 100.00%] [G loss: 6.445676]\n",
      "epoch:49 step:38882 [D loss: 0.019372, acc: 100.00%] [G loss: 5.575502]\n",
      "epoch:49 step:38883 [D loss: 0.315028, acc: 83.59%] [G loss: 9.601333]\n",
      "epoch:49 step:38884 [D loss: 2.244302, acc: 48.44%] [G loss: 5.995213]\n",
      "epoch:49 step:38885 [D loss: 0.106954, acc: 100.00%] [G loss: 5.917503]\n",
      "epoch:49 step:38886 [D loss: 0.363541, acc: 83.59%] [G loss: 5.452261]\n",
      "epoch:49 step:38887 [D loss: 0.146267, acc: 96.09%] [G loss: 5.317496]\n",
      "epoch:49 step:38888 [D loss: 0.109349, acc: 99.22%] [G loss: 5.604703]\n",
      "epoch:49 step:38889 [D loss: 0.205926, acc: 96.09%] [G loss: 6.472898]\n",
      "epoch:49 step:38890 [D loss: 0.040832, acc: 100.00%] [G loss: 6.039485]\n",
      "epoch:49 step:38891 [D loss: 0.405412, acc: 84.38%] [G loss: 5.489160]\n",
      "epoch:49 step:38892 [D loss: 0.442213, acc: 78.91%] [G loss: 6.949737]\n",
      "epoch:49 step:38893 [D loss: 0.313554, acc: 83.59%] [G loss: 10.209677]\n",
      "epoch:49 step:38894 [D loss: 0.103846, acc: 99.22%] [G loss: 7.091691]\n",
      "epoch:49 step:38895 [D loss: 0.040640, acc: 100.00%] [G loss: 7.163787]\n",
      "epoch:49 step:38896 [D loss: 0.614153, acc: 61.72%] [G loss: 7.949308]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:49 step:38897 [D loss: 0.260278, acc: 97.66%] [G loss: 6.999849]\n",
      "epoch:49 step:38898 [D loss: 0.028922, acc: 100.00%] [G loss: 7.855912]\n",
      "epoch:49 step:38899 [D loss: 0.010246, acc: 100.00%] [G loss: 9.136208]\n",
      "epoch:49 step:38900 [D loss: 0.134998, acc: 100.00%] [G loss: 9.387511]\n",
      "epoch:49 step:38901 [D loss: 0.036227, acc: 100.00%] [G loss: 7.029159]\n",
      "epoch:49 step:38902 [D loss: 0.074968, acc: 100.00%] [G loss: 5.934005]\n",
      "epoch:49 step:38903 [D loss: 0.230944, acc: 94.53%] [G loss: 5.348897]\n",
      "epoch:49 step:38904 [D loss: 0.022346, acc: 100.00%] [G loss: 5.916573]\n",
      "epoch:49 step:38905 [D loss: 1.225581, acc: 32.03%] [G loss: 6.450384]\n",
      "epoch:49 step:38906 [D loss: 0.348525, acc: 83.59%] [G loss: 4.882794]\n",
      "epoch:49 step:38907 [D loss: 0.156505, acc: 96.88%] [G loss: 6.306778]\n",
      "epoch:49 step:38908 [D loss: 0.441782, acc: 69.53%] [G loss: 5.093012]\n",
      "epoch:49 step:38909 [D loss: 0.232287, acc: 95.31%] [G loss: 3.488748]\n",
      "epoch:49 step:38910 [D loss: 0.046697, acc: 100.00%] [G loss: 8.076378]\n",
      "epoch:49 step:38911 [D loss: 0.619505, acc: 58.59%] [G loss: 11.254777]\n",
      "epoch:49 step:38912 [D loss: 0.474662, acc: 77.34%] [G loss: 6.020986]\n",
      "epoch:49 step:38913 [D loss: 0.106635, acc: 100.00%] [G loss: 5.263736]\n",
      "epoch:49 step:38914 [D loss: 0.316353, acc: 83.59%] [G loss: 5.801679]\n",
      "epoch:49 step:38915 [D loss: 0.066691, acc: 100.00%] [G loss: 5.763364]\n",
      "epoch:49 step:38916 [D loss: 0.208680, acc: 96.88%] [G loss: 5.827254]\n",
      "epoch:49 step:38917 [D loss: 0.331996, acc: 80.47%] [G loss: 3.496927]\n",
      "epoch:49 step:38918 [D loss: 0.306598, acc: 82.03%] [G loss: 6.903109]\n",
      "epoch:49 step:38919 [D loss: 0.672121, acc: 57.03%] [G loss: 10.905527]\n",
      "epoch:49 step:38920 [D loss: 0.658931, acc: 56.25%] [G loss: 6.056688]\n",
      "epoch:49 step:38921 [D loss: 0.710662, acc: 57.81%] [G loss: 7.311293]\n",
      "epoch:49 step:38922 [D loss: 0.020513, acc: 100.00%] [G loss: 7.656281]\n",
      "epoch:49 step:38923 [D loss: 0.426038, acc: 72.66%] [G loss: 6.951067]\n",
      "epoch:49 step:38924 [D loss: 0.081186, acc: 100.00%] [G loss: 9.344639]\n",
      "epoch:49 step:38925 [D loss: 0.079202, acc: 100.00%] [G loss: 7.480887]\n",
      "epoch:49 step:38926 [D loss: 0.611563, acc: 61.72%] [G loss: 3.550552]\n",
      "epoch:49 step:38927 [D loss: 0.300267, acc: 87.50%] [G loss: 3.143086]\n",
      "epoch:49 step:38928 [D loss: 0.298072, acc: 91.41%] [G loss: 8.223410]\n",
      "epoch:49 step:38929 [D loss: 0.130734, acc: 98.44%] [G loss: 3.455335]\n",
      "epoch:49 step:38930 [D loss: 0.567295, acc: 66.41%] [G loss: 7.976488]\n",
      "epoch:49 step:38931 [D loss: 0.050804, acc: 100.00%] [G loss: 4.105464]\n",
      "epoch:49 step:38932 [D loss: 1.108561, acc: 33.59%] [G loss: 11.709438]\n",
      "epoch:49 step:38933 [D loss: 0.148552, acc: 97.66%] [G loss: 5.414243]\n",
      "epoch:49 step:38934 [D loss: 0.285613, acc: 93.75%] [G loss: 3.736003]\n",
      "epoch:49 step:38935 [D loss: 0.040788, acc: 100.00%] [G loss: 4.776802]\n",
      "epoch:49 step:38936 [D loss: 0.012308, acc: 100.00%] [G loss: 11.349773]\n",
      "epoch:49 step:38937 [D loss: 0.242844, acc: 91.41%] [G loss: 4.828357]\n",
      "epoch:49 step:38938 [D loss: 1.206890, acc: 51.56%] [G loss: 8.905703]\n",
      "epoch:49 step:38939 [D loss: 0.069835, acc: 99.22%] [G loss: 7.160917]\n",
      "epoch:49 step:38940 [D loss: 0.038551, acc: 99.22%] [G loss: 8.417521]\n",
      "epoch:49 step:38941 [D loss: 0.959227, acc: 51.56%] [G loss: 4.800786]\n",
      "epoch:49 step:38942 [D loss: 0.563649, acc: 75.00%] [G loss: 9.310045]\n",
      "epoch:49 step:38943 [D loss: 0.068929, acc: 99.22%] [G loss: 6.237253]\n",
      "epoch:49 step:38944 [D loss: 0.071109, acc: 100.00%] [G loss: 2.630079]\n",
      "epoch:49 step:38945 [D loss: 0.315352, acc: 87.50%] [G loss: 6.526147]\n",
      "epoch:49 step:38946 [D loss: 0.298544, acc: 82.03%] [G loss: 7.498535]\n",
      "epoch:49 step:38947 [D loss: 0.426296, acc: 74.22%] [G loss: 4.687912]\n",
      "epoch:49 step:38948 [D loss: 0.106559, acc: 99.22%] [G loss: 4.505179]\n",
      "epoch:49 step:38949 [D loss: 0.438205, acc: 64.84%] [G loss: 10.284440]\n",
      "epoch:49 step:38950 [D loss: 0.014199, acc: 100.00%] [G loss: 7.107935]\n",
      "epoch:49 step:38951 [D loss: 0.072185, acc: 100.00%] [G loss: 5.801823]\n",
      "epoch:49 step:38952 [D loss: 0.839500, acc: 49.22%] [G loss: 9.419807]\n",
      "epoch:49 step:38953 [D loss: 0.405526, acc: 71.09%] [G loss: 4.909690]\n",
      "epoch:49 step:38954 [D loss: 0.362229, acc: 84.38%] [G loss: 5.292458]\n",
      "epoch:49 step:38955 [D loss: 0.669542, acc: 64.06%] [G loss: 5.874339]\n",
      "epoch:49 step:38956 [D loss: 0.110885, acc: 100.00%] [G loss: 5.993398]\n",
      "epoch:49 step:38957 [D loss: 0.006589, acc: 100.00%] [G loss: 7.181040]\n",
      "epoch:49 step:38958 [D loss: 0.115454, acc: 96.88%] [G loss: 8.459209]\n",
      "epoch:49 step:38959 [D loss: 0.947349, acc: 52.34%] [G loss: 6.271652]\n",
      "epoch:49 step:38960 [D loss: 0.051855, acc: 100.00%] [G loss: 6.477609]\n",
      "epoch:49 step:38961 [D loss: 0.302783, acc: 85.16%] [G loss: 8.435220]\n",
      "epoch:49 step:38962 [D loss: 0.114272, acc: 99.22%] [G loss: 4.637149]\n",
      "epoch:49 step:38963 [D loss: 0.163565, acc: 97.66%] [G loss: 5.214303]\n",
      "epoch:49 step:38964 [D loss: 0.969226, acc: 39.06%] [G loss: 8.016127]\n",
      "epoch:49 step:38965 [D loss: 0.046754, acc: 100.00%] [G loss: 6.676290]\n",
      "epoch:49 step:38966 [D loss: 0.091890, acc: 99.22%] [G loss: 6.680067]\n",
      "epoch:49 step:38967 [D loss: 0.224456, acc: 96.88%] [G loss: 8.996349]\n",
      "epoch:49 step:38968 [D loss: 0.503125, acc: 79.69%] [G loss: 6.120419]\n",
      "epoch:49 step:38969 [D loss: 0.061249, acc: 99.22%] [G loss: 5.828313]\n",
      "epoch:49 step:38970 [D loss: 0.694274, acc: 60.94%] [G loss: 5.937095]\n",
      "epoch:49 step:38971 [D loss: 0.335182, acc: 85.16%] [G loss: 3.607274]\n",
      "epoch:49 step:38972 [D loss: 0.053960, acc: 100.00%] [G loss: 8.375506]\n",
      "epoch:49 step:38973 [D loss: 0.328620, acc: 91.41%] [G loss: 5.478729]\n",
      "epoch:49 step:38974 [D loss: 0.037588, acc: 100.00%] [G loss: 3.077730]\n",
      "epoch:49 step:38975 [D loss: 0.111567, acc: 99.22%] [G loss: 4.604216]\n",
      "epoch:49 step:38976 [D loss: 0.150994, acc: 95.31%] [G loss: 7.073084]\n",
      "epoch:49 step:38977 [D loss: 0.047162, acc: 100.00%] [G loss: 7.497744]\n",
      "epoch:49 step:38978 [D loss: 0.240672, acc: 92.97%] [G loss: 9.783974]\n",
      "epoch:49 step:38979 [D loss: 0.199443, acc: 95.31%] [G loss: 6.408244]\n",
      "epoch:49 step:38980 [D loss: 0.379577, acc: 75.78%] [G loss: 8.376811]\n",
      "epoch:49 step:38981 [D loss: 0.070636, acc: 100.00%] [G loss: 3.873975]\n",
      "epoch:49 step:38982 [D loss: 0.015012, acc: 100.00%] [G loss: 5.202238]\n",
      "epoch:49 step:38983 [D loss: 0.056327, acc: 99.22%] [G loss: 7.571448]\n",
      "epoch:49 step:38984 [D loss: 0.008688, acc: 100.00%] [G loss: 8.659542]\n",
      "epoch:49 step:38985 [D loss: 0.648649, acc: 61.72%] [G loss: 11.755295]\n",
      "epoch:49 step:38986 [D loss: 0.314696, acc: 88.28%] [G loss: 7.344044]\n",
      "epoch:49 step:38987 [D loss: 0.186411, acc: 96.88%] [G loss: 5.342991]\n",
      "epoch:49 step:38988 [D loss: 0.206062, acc: 94.53%] [G loss: 5.611034]\n",
      "epoch:49 step:38989 [D loss: 0.250117, acc: 96.09%] [G loss: 3.959623]\n",
      "epoch:49 step:38990 [D loss: 0.049918, acc: 100.00%] [G loss: 8.858732]\n",
      "epoch:49 step:38991 [D loss: 0.487887, acc: 71.88%] [G loss: 6.252216]\n",
      "epoch:49 step:38992 [D loss: 0.699804, acc: 57.03%] [G loss: 6.911236]\n",
      "epoch:49 step:38993 [D loss: 0.731174, acc: 57.81%] [G loss: 7.996188]\n",
      "epoch:49 step:38994 [D loss: 0.223046, acc: 92.19%] [G loss: 9.490227]\n",
      "epoch:49 step:38995 [D loss: 0.002879, acc: 100.00%] [G loss: 14.717060]\n",
      "epoch:49 step:38996 [D loss: 0.129915, acc: 100.00%] [G loss: 7.456684]\n",
      "epoch:49 step:38997 [D loss: 0.466012, acc: 73.44%] [G loss: 5.020862]\n",
      "epoch:49 step:38998 [D loss: 0.313322, acc: 87.50%] [G loss: 6.525935]\n",
      "epoch:49 step:38999 [D loss: 0.131797, acc: 97.66%] [G loss: 3.608959]\n",
      "epoch:49 step:39000 [D loss: 1.222272, acc: 19.53%] [G loss: 5.824924]\n",
      "##############\n",
      "[0.85753899 0.87643984 0.82599716 0.80934497 0.80475875 0.82426933\n",
      " 0.89344825 0.8117508  0.82317283 0.83698705]\n",
      "##########\n",
      "epoch:49 step:39001 [D loss: 0.123017, acc: 97.66%] [G loss: 3.580440]\n",
      "epoch:49 step:39002 [D loss: 0.079402, acc: 100.00%] [G loss: 3.772941]\n",
      "epoch:49 step:39003 [D loss: 0.101771, acc: 98.44%] [G loss: 3.080386]\n",
      "epoch:49 step:39004 [D loss: 0.116247, acc: 100.00%] [G loss: 12.241212]\n",
      "epoch:49 step:39005 [D loss: 0.069235, acc: 100.00%] [G loss: 5.510322]\n",
      "epoch:49 step:39006 [D loss: 0.056127, acc: 99.22%] [G loss: 7.209872]\n",
      "epoch:49 step:39007 [D loss: 0.359846, acc: 82.03%] [G loss: 7.416655]\n",
      "epoch:49 step:39008 [D loss: 0.859220, acc: 52.34%] [G loss: 4.073372]\n",
      "epoch:49 step:39009 [D loss: 0.274864, acc: 87.50%] [G loss: 8.941146]\n",
      "epoch:49 step:39010 [D loss: 0.026268, acc: 100.00%] [G loss: 5.945437]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:49 step:39011 [D loss: 0.060452, acc: 100.00%] [G loss: 5.075298]\n",
      "epoch:49 step:39012 [D loss: 0.038305, acc: 100.00%] [G loss: 3.982856]\n",
      "epoch:49 step:39013 [D loss: 0.468784, acc: 68.75%] [G loss: 8.088291]\n",
      "epoch:49 step:39014 [D loss: 0.015616, acc: 100.00%] [G loss: 3.510086]\n",
      "epoch:49 step:39015 [D loss: 0.251260, acc: 96.88%] [G loss: 7.022685]\n",
      "epoch:49 step:39016 [D loss: 0.301280, acc: 87.50%] [G loss: 6.738506]\n",
      "epoch:49 step:39017 [D loss: 1.113481, acc: 41.41%] [G loss: 6.728136]\n",
      "epoch:49 step:39018 [D loss: 0.131283, acc: 99.22%] [G loss: 5.010524]\n",
      "epoch:49 step:39019 [D loss: 0.591739, acc: 60.16%] [G loss: 9.147638]\n",
      "epoch:49 step:39020 [D loss: 0.243865, acc: 92.97%] [G loss: 4.156609]\n",
      "epoch:49 step:39021 [D loss: 0.503930, acc: 75.78%] [G loss: 7.829105]\n",
      "epoch:49 step:39022 [D loss: 0.177347, acc: 96.88%] [G loss: 5.180837]\n",
      "epoch:49 step:39023 [D loss: 0.348344, acc: 84.38%] [G loss: 7.755022]\n",
      "epoch:49 step:39024 [D loss: 0.336666, acc: 85.16%] [G loss: 9.306794]\n",
      "epoch:49 step:39025 [D loss: 0.114341, acc: 100.00%] [G loss: 5.553103]\n",
      "epoch:49 step:39026 [D loss: 0.039208, acc: 100.00%] [G loss: 3.116221]\n",
      "epoch:49 step:39027 [D loss: 0.282579, acc: 86.72%] [G loss: 5.793193]\n",
      "epoch:49 step:39028 [D loss: 0.281576, acc: 92.97%] [G loss: 2.282691]\n",
      "epoch:49 step:39029 [D loss: 0.008946, acc: 100.00%] [G loss: 13.076097]\n",
      "epoch:49 step:39030 [D loss: 0.224221, acc: 93.75%] [G loss: 11.479109]\n",
      "epoch:49 step:39031 [D loss: 0.153508, acc: 96.88%] [G loss: 4.272408]\n",
      "epoch:49 step:39032 [D loss: 0.025559, acc: 100.00%] [G loss: 6.875237]\n",
      "epoch:49 step:39033 [D loss: 0.009718, acc: 100.00%] [G loss: 2.685307]\n",
      "epoch:49 step:39034 [D loss: 0.106144, acc: 99.22%] [G loss: 10.098876]\n",
      "epoch:49 step:39035 [D loss: 0.424340, acc: 74.22%] [G loss: 5.293522]\n",
      "epoch:49 step:39036 [D loss: 0.151807, acc: 98.44%] [G loss: 7.992787]\n",
      "epoch:49 step:39037 [D loss: 0.005577, acc: 100.00%] [G loss: 7.227016]\n",
      "epoch:49 step:39038 [D loss: 0.118965, acc: 99.22%] [G loss: 5.492081]\n",
      "epoch:49 step:39039 [D loss: 0.243769, acc: 92.97%] [G loss: 4.842126]\n",
      "epoch:49 step:39040 [D loss: 0.090659, acc: 100.00%] [G loss: 4.930067]\n",
      "epoch:49 step:39041 [D loss: 0.043643, acc: 100.00%] [G loss: 4.896447]\n",
      "epoch:49 step:39042 [D loss: 0.198418, acc: 93.75%] [G loss: 11.940430]\n",
      "epoch:49 step:39043 [D loss: 0.173619, acc: 94.53%] [G loss: 3.877055]\n",
      "epoch:49 step:39044 [D loss: 0.248778, acc: 96.09%] [G loss: 3.183073]\n",
      "epoch:49 step:39045 [D loss: 0.058905, acc: 100.00%] [G loss: 4.671291]\n",
      "epoch:49 step:39046 [D loss: 0.469654, acc: 73.44%] [G loss: 5.835335]\n",
      "epoch:49 step:39047 [D loss: 0.245312, acc: 91.41%] [G loss: 8.162237]\n",
      "epoch:49 step:39048 [D loss: 0.178143, acc: 98.44%] [G loss: 7.616233]\n",
      "epoch:49 step:39049 [D loss: 0.333553, acc: 92.19%] [G loss: 7.437212]\n",
      "epoch:49 step:39050 [D loss: 0.099942, acc: 100.00%] [G loss: 7.422725]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.datasets import cifar10\n",
    "from torch.utils.data import Dataset\n",
    "import torch.utils.data as Data\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, imgs, transform=None):\n",
    "        # super().__init__()\n",
    "        self.imgs = imgs\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.imgs)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img = self.imgs[index]\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "        else:\n",
    "            img = torch.from_numpy(img)\n",
    "        img=img.reshape([3,32,32])\n",
    "        return img\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import model\n",
    "import torch.nn.functional as F\n",
    "model = model.cifar10(128)\n",
    "model.load_state_dict(torch.load('./log/default/best-85.pth'))\n",
    "model.cuda()\n",
    "def EuclideanDistances(A, B):\n",
    "    BT = B.transpose()\n",
    "    # vecProd = A * BT\n",
    "    vecProd = np.dot(A, BT)\n",
    "    # print(vecProd)\n",
    "    SqA = A ** 2\n",
    "    # print(SqA)\n",
    "    sumSqA = np.matrix(np.sum(SqA, axis=1))\n",
    "    sumSqAEx = np.tile(sumSqA.transpose(), (1, vecProd.shape[1]))\n",
    "    # print(sumSqAEx)\n",
    "\n",
    "    SqB = B ** 2\n",
    "    sumSqB = np.sum(SqB, axis=1)\n",
    "    sumSqBEx = np.tile(sumSqB, (vecProd.shape[0], 1))\n",
    "    SqED = sumSqBEx + sumSqAEx - 2 * vecProd\n",
    "    SqED[SqED < 0] = 0.0\n",
    "    ED = np.sqrt(SqED)\n",
    "    return np.divide(ED.sum(), ED.shape[0] * ED.shape[1])\n",
    "\n",
    "\n",
    "def cal_distance_image_real(images, labels):\n",
    "    x_dataset = MyDataset(images)\n",
    "    # print(x_dataset[0].shape)\n",
    "    x_real_loader = Data.DataLoader(dataset=x_dataset, batch_size=200, shuffle=True)\n",
    "    y_logits = []\n",
    "    for i, data in enumerate(x_real_loader):\n",
    "        # indx_target = target.clone()\n",
    "        data = data.cuda()\n",
    "        data = Variable(data, volatile=True)\n",
    "        output = model(data)\n",
    "        pred = F.softmax(output).cpu().detach().numpy()\n",
    "        y_logits += [i for i in pred]\n",
    "    dict = {}\n",
    "    all_dis = []\n",
    "    for i in range(10):\n",
    "        dict[i] = []\n",
    "    for i in range(len(labels)):\n",
    "        dict[labels[i]].append(y_logits[i])\n",
    "    for i in range(10):\n",
    "        dict[i] = np.array(dict[i])\n",
    "        if len(dict[i]):\n",
    "            dis = EuclideanDistances(dict[i], dict[i])  # 生成图片的紧度\n",
    "        else:\n",
    "            dis = -1\n",
    "        all_dis.append(dis)\n",
    "    return np.array(all_dis)\n",
    "\n",
    "\n",
    "def cal_distance_image_fake(images):\n",
    "    x_dataset = MyDataset(images)\n",
    "    # print(x_dataset[0].shape)\n",
    "    x_real_loader = Data.DataLoader(dataset=x_dataset, batch_size=200, shuffle=True)\n",
    "    y_logits = []\n",
    "    labels=[]\n",
    "    for i, data in enumerate(x_real_loader):\n",
    "        # indx_target = target.clone()\n",
    "        data = data.cuda()\n",
    "        data = Variable(data, volatile=True)\n",
    "        output = model(data)\n",
    "        pred = output.data.max(1)[1]\n",
    "        labels += [i for i in pred.cpu().numpy()]\n",
    "        pred = F.softmax(output).cpu().detach().numpy()\n",
    "        y_logits += [i for i in pred]\n",
    "\n",
    "    dict = {}\n",
    "    all_dis = []\n",
    "    for i in range(10):\n",
    "        dict[i] = []\n",
    "    for i in range(len(labels)):\n",
    "        dict[labels[i]].append(y_logits[i])\n",
    "    for i in range(10):\n",
    "        dict[i] = np.array(dict[i])\n",
    "        if len(dict[i]):\n",
    "            dis = EuclideanDistances(dict[i], dict[i])  # 生成图片的紧度\n",
    "        else:\n",
    "            dis = -1\n",
    "        all_dis.append(dis)\n",
    "    return np.array(all_dis)\n",
    "\n",
    "import os\n",
    "if not os.path.isdir('saved_models_{}'.format('bigan')):\n",
    "    os.mkdir('saved_models_{}'.format('bigan'))\n",
    "f = open('saved_models_{}/log_collapse1.txt'.format('bigan'), mode='w')\n",
    "import torch.utils.data as Data\n",
    "import cv2\n",
    "\n",
    "\n",
    "from keras.datasets import cifar10\n",
    "from keras.layers import Input, Dense, Reshape, Flatten, Dropout, multiply, GaussianNoise\n",
    "from keras.layers import BatchNormalization, Activation, Embedding, ZeroPadding2D\n",
    "from keras.layers import MaxPooling2D, concatenate\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.layers.convolutional import UpSampling2D, Conv2D\n",
    "from keras.models import Sequential, Model\n",
    "from keras.optimizers import Adam\n",
    "from keras import losses\n",
    "from keras.utils import to_categorical\n",
    "import keras.backend as K\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "class BIGAN():\n",
    "    def __init__(self):\n",
    "        self.img_rows = 32\n",
    "        self.img_cols = 32\n",
    "        self.channels = 3\n",
    "        self.img_shape = (self.img_rows, self.img_cols, self.channels)\n",
    "        self.latent_dim = 100\n",
    "        self.x = []\n",
    "        self.y = np.zeros((31, 1), dtype=np.int)\n",
    "        self.y = list(self.y)\n",
    "        for i in range(31):\n",
    "            self.y[i] = []\n",
    "\n",
    "        optimizer = Adam(0.0002, 0.5)\n",
    "\n",
    "        # Build and compile the discriminator\n",
    "        self.discriminator = self.build_discriminator()\n",
    "        self.discriminator.compile(loss=['binary_crossentropy'],\n",
    "            optimizer=optimizer,\n",
    "            metrics=['accuracy'])\n",
    "\n",
    "        # Build the generator\n",
    "        self.generator = self.build_generator()\n",
    "\n",
    "        # Build the encoder\n",
    "        self.encoder = self.build_encoder()\n",
    "\n",
    "        # The part of the bigan that trains the discriminator and encoder\n",
    "        self.discriminator.trainable = False\n",
    "\n",
    "        # Generate image from sampled noise\n",
    "        z = Input(shape=(self.latent_dim, ))\n",
    "        img_ = self.generator(z)\n",
    "\n",
    "        # Encode image\n",
    "        img = Input(shape=self.img_shape)\n",
    "        z_ = self.encoder(img)\n",
    "\n",
    "        # Latent -> img is fake, and img -> latent is valid\n",
    "        fake = self.discriminator([z, img_])\n",
    "        valid = self.discriminator([z_, img])\n",
    "\n",
    "        # Set up and compile the combined model\n",
    "        # Trains generator to fool the discriminator\n",
    "        self.bigan_generator = Model([z, img], [fake, valid])\n",
    "        self.bigan_generator.compile(loss=['binary_crossentropy', 'binary_crossentropy'],\n",
    "            optimizer=optimizer)\n",
    "\n",
    "    def build_encoder(self):\n",
    "        model = Sequential()\n",
    "        model.add(Conv2D(32, kernel_size=3, strides=2, input_shape=self.img_shape, padding=\"same\"))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dropout(0.25))\n",
    "        model.add(Conv2D(64, kernel_size=3, strides=2, padding=\"same\"))\n",
    "        # model.add(ZeroPadding2D(padding=((0, 1), (0, 1))))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dropout(0.25))\n",
    "        model.add(Conv2D(128, kernel_size=3, strides=2, padding=\"same\"))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dropout(0.25))\n",
    "        model.add(Conv2D(256, kernel_size=3, strides=1, padding=\"same\"))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dropout(0.25))\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(self.latent_dim))\n",
    "\n",
    "        model.summary()\n",
    "        img = Input(shape=self.img_shape)\n",
    "        z = model(img)\n",
    "\n",
    "        return Model(img, z)\n",
    "\n",
    "    def build_generator(self):\n",
    "        model = Sequential()\n",
    "\n",
    "        model.add(Dense(128 * 8 * 8, activation=\"relu\", input_dim=self.latent_dim))\n",
    "        model.add(Reshape((8, 8, 128)))\n",
    "        model.add(UpSampling2D())\n",
    "        model.add(Conv2D(128, kernel_size=3, padding=\"same\"))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(UpSampling2D())\n",
    "        model.add(Conv2D(64, kernel_size=3, padding=\"same\"))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(Conv2D(self.channels, kernel_size=3, padding=\"same\"))\n",
    "        model.add(Activation(\"tanh\"))\n",
    "\n",
    "        model.summary()\n",
    "        z = Input(shape=(self.latent_dim,))\n",
    "        gen_img = model(z)\n",
    "\n",
    "        return Model(z, gen_img)\n",
    "\n",
    "    def build_discriminator(self):\n",
    "\n",
    "        z = Input(shape=(self.latent_dim,))\n",
    "        img = Input(shape=self.img_shape)\n",
    "        d_in = concatenate([z, Flatten()(img)])\n",
    "\n",
    "        model = Dense(32 * 32 * 3)(d_in)\n",
    "        model = Reshape((32, 32, 3))(model)\n",
    "        model = Conv2D(32, kernel_size=3, strides=2, padding=\"same\")(model)\n",
    "        model = LeakyReLU(alpha=0.2)(model)\n",
    "        model = Dropout(0.25)(model)\n",
    "        model = Conv2D(64, kernel_size=3, strides=2, padding=\"same\")(model)\n",
    "        model = ZeroPadding2D(padding=((0, 1), (0, 1)))(model)\n",
    "        model = BatchNormalization(momentum=0.8)(model)\n",
    "        model = LeakyReLU(alpha=0.2)(model)\n",
    "        model = Dropout(0.25)(model)\n",
    "        model = Conv2D(128, kernel_size=3, strides=2, padding=\"same\")(model)\n",
    "        model = BatchNormalization(momentum=0.8)(model)\n",
    "        model = LeakyReLU(alpha=0.2)(model)\n",
    "        model = Dropout(0.25)(model)\n",
    "        model = Conv2D(256, kernel_size=3, strides=1, padding=\"same\")(model)\n",
    "        model = BatchNormalization(momentum=0.8)(model)\n",
    "        model = LeakyReLU(alpha=0.2)(model)\n",
    "        model = Dropout(0.25)(model)\n",
    "        model = Flatten()(model)\n",
    "        validity = Dense(1, activation=\"sigmoid\")(model)\n",
    "\n",
    "        return Model([z, img], validity)\n",
    "\n",
    "    def train(self, epochs, batch_size=128, sample_interval=50):\n",
    "\n",
    "        # Load the dataset\n",
    "        (X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
    "\n",
    "        # Rescale -1 to 1\n",
    "        X_train = (X_train.astype(np.float32) - 127.5) / 127.5\n",
    "        X_test = (X_test.astype(np.float32) - 127.5) / 127.5\n",
    "\n",
    "        # Adversarial ground truths\n",
    "        valid = np.ones((batch_size, 1))\n",
    "        fake = np.zeros((batch_size, 1))\n",
    "\n",
    "        nb_batches = int(X_train.shape[0] / batch_size)\n",
    "        global_step = 0\n",
    "        steps = []\n",
    "        values = []\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "\n",
    "            # ---------------------\n",
    "            #  Train Discriminator\n",
    "            # ---------------------\n",
    "\n",
    "            # Select a random batch of images\n",
    "            # idx = np.random.randint(0, X_train.shape[0], batch_size)\n",
    "            for index in range(nb_batches):\n",
    "                global_step += 1\n",
    "                # progress_bar.update(index)\n",
    "\n",
    "                # get a batch of real images\n",
    "                image_batch = X_train[index * batch_size:(index + 1) * batch_size]\n",
    "                z = np.random.normal(size=(batch_size, self.latent_dim))\n",
    "                imgs_ = self.generator.predict(z)\n",
    "\n",
    "                # Select a random batch of images and encode\n",
    "                # idx = np.random.randint(0, X_train.shape[0], batch_size)\n",
    "                # imgs = X_train[idx]\n",
    "                z_ = self.encoder.predict(image_batch)\n",
    "\n",
    "                # Train the discriminator (img -> z is valid, z -> img is fake)\n",
    "                d_loss_real = self.discriminator.train_on_batch([z_, image_batch], valid)\n",
    "                d_loss_fake = self.discriminator.train_on_batch([z, imgs_], fake)\n",
    "                d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
    "\n",
    "                # ---------------------\n",
    "                #  Train Generator\n",
    "                # ---------------------\n",
    "\n",
    "                # Train the generator (z -> img is valid and img -> z is is invalid)\n",
    "                g_loss = self.bigan_generator.train_on_batch([z, image_batch], [valid, fake])\n",
    "\n",
    "                # Plot the progress\n",
    "                print(\"epoch:%d step:%d [D loss: %f, acc: %.2f%%] [G loss: %f]\" % (epoch, global_step, d_loss[0],\n",
    "                                                                                   100 * d_loss[1], g_loss[0]))\n",
    "                sample_num=5000\n",
    "\n",
    "                if global_step % sample_interval == 0:\n",
    "                    self.mode_drop(X_test,y_test,sample_num, global_step)\n",
    "\n",
    "\n",
    "    def mode_drop(self, x_test,y_test,sample_num, global_step):\n",
    "        r, c = 10, 1000\n",
    "        noise = np.random.normal(0, 1, (r * c, 100))\n",
    "        # sampled_labels = np.array([num for _ in range(r) for num in range(c)])\n",
    "        gen_imgs = self.generator.predict([noise])\n",
    "        # Rescale images 0 - 1\n",
    "        gen_imgs = 0.5 * gen_imgs + 0.5\n",
    "        labels = np.squeeze(y_test[:sample_num])\n",
    "        labels = np.squeeze(labels)\n",
    "        dis_real = cal_distance_image_real(x_test[:sample_num], labels)\n",
    "        dis_fake = cal_distance_image_fake(gen_imgs)\n",
    "        dis_cha = dis_real - dis_fake\n",
    "        print('##############')\n",
    "        # print(dis_real)\n",
    "        # print(dis_fake)\n",
    "        print(dis_cha)\n",
    "        print('##########')\n",
    "        f.writelines('\\n')\n",
    "        f.writelines('step:' + str(global_step))\n",
    "        f.writelines('\\n')\n",
    "        f.writelines('紧度')\n",
    "        f.writelines('\\n')\n",
    "        f.writelines(' %.8f ' % (i) for i in dis_cha)\n",
    "        f.writelines('\\n')\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    bigan = BIGAN()\n",
    "    bigan.train(epochs=50, batch_size=64, sample_interval=200)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pppppppp [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
