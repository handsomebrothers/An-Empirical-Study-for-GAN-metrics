{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-*-coding:utf-8-*-\n",
    "import util\n",
    "import tensorflow as tf\n",
    "MNIST_CLASSIFIER_FROZEN_GRAPH = './classify_mnist_graph_def.pb'\n",
    "INPUT_TENSOR = 'inputs:0'\n",
    "OUTPUT_TENSOR = 'logits:0'\n",
    "def EuclideanDistances(A, B):\n",
    "\n",
    "    BT = B.transpose()\n",
    "    # vecProd = A * BT\n",
    "    vecProd = np.dot(A, BT)\n",
    "    # print(vecProd)\n",
    "    SqA = A ** 2\n",
    "    # print(SqA)\n",
    "    sumSqA = np.matrix(np.sum(SqA, axis=1))\n",
    "    sumSqAEx = np.tile(sumSqA.transpose(), (1, vecProd.shape[1]))\n",
    "    # print(sumSqAEx)\n",
    "\n",
    "    SqB = B ** 2\n",
    "    sumSqB = np.sum(SqB, axis=1)\n",
    "    sumSqBEx = np.tile(sumSqB, (vecProd.shape[0], 1))\n",
    "    SqED = sumSqBEx + sumSqAEx - 2 * vecProd\n",
    "    SqED[SqED < 0] = 0.0\n",
    "    ED = np.sqrt(SqED)\n",
    "    return np.divide(ED.sum(),ED.shape[0]*ED.shape[1])\n",
    "def cal_distance_image_real(images,labels):\n",
    "    eval_images=tf.convert_to_tensor(images)\n",
    "    y_logits=util.mnist_logits(eval_images, MNIST_CLASSIFIER_FROZEN_GRAPH, INPUT_TENSOR, OUTPUT_TENSOR)\n",
    "    y_logits=tf.Session().run(y_logits)\n",
    "    dict={}\n",
    "    all_dis=[]\n",
    "    for i in range(10):\n",
    "        dict[i]=[]\n",
    "    for i in range(len(labels)):\n",
    "        dict[labels[i]].append(y_logits[i])\n",
    "    for i in range(10):\n",
    "        dict[i]=np.array(dict[i])\n",
    "        if len(dict[i]):\n",
    "            dis = EuclideanDistances(dict[i], dict[i])  # 生成图片的紧度\n",
    "        else:\n",
    "            dis = -1\n",
    "        all_dis.append(dis)\n",
    "    return np.array(all_dis)\n",
    "def cal_distance_image_fake(images):\n",
    "    eval_images=tf.convert_to_tensor(images)\n",
    "    y_logits=util.mnist_logits(eval_images, MNIST_CLASSIFIER_FROZEN_GRAPH, INPUT_TENSOR, OUTPUT_TENSOR)\n",
    "    y_logits=tf.Session().run(y_logits)\n",
    "    labels = tf.Session().run(tf.argmax(y_logits, 1))\n",
    "    dict={}\n",
    "    all_dis=[]\n",
    "    for i in range(10):\n",
    "        dict[i]=[]\n",
    "    for i in range(len(labels)):\n",
    "        dict[labels[i]].append(y_logits[i])\n",
    "    for i in range(10):\n",
    "        dict[i]=np.array(dict[i])\n",
    "        if len(dict[i]):\n",
    "            dis = EuclideanDistances(dict[i], dict[i])  # 生成图片的紧度\n",
    "        else:\n",
    "            dis = -1\n",
    "        all_dis.append(dis)\n",
    "    return np.array(all_dis)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_1 (Flatten)          (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)    (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 533,505\n",
      "Trainable params: 533,505\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_4 (Dense)              (None, 256)               25856     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)    (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 512)               131584    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 1024)              525312    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_5 (LeakyReLU)    (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 1024)              4096      \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 784)               803600    \n",
      "_________________________________________________________________\n",
      "reshape_1 (Reshape)          (None, 28, 28, 1)         0         \n",
      "=================================================================\n",
      "Total params: 1,493,520\n",
      "Trainable params: 1,489,936\n",
      "Non-trainable params: 3,584\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/imi432_006/anaconda3/envs/tf/lib/python3.5/site-packages/keras/engine/training.py:490: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "  'Discrepancy between trainable weights and collected trainable'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0 step:1 [D loss: 0.543107, acc.: 50.78%] [G loss: 0.298934]\n",
      "epoch:0 step:2 [D loss: 0.485043, acc.: 59.38%] [G loss: 0.109027]\n",
      "epoch:0 step:3 [D loss: 0.366065, acc.: 75.00%] [G loss: 0.150807]\n",
      "epoch:0 step:4 [D loss: 0.256559, acc.: 93.75%] [G loss: 0.377074]\n",
      "epoch:0 step:5 [D loss: 0.226749, acc.: 97.66%] [G loss: 0.650972]\n",
      "epoch:0 step:6 [D loss: 0.168205, acc.: 100.00%] [G loss: 0.883893]\n",
      "epoch:0 step:7 [D loss: 0.162598, acc.: 100.00%] [G loss: 1.106005]\n",
      "epoch:0 step:8 [D loss: 0.117471, acc.: 100.00%] [G loss: 1.324349]\n",
      "epoch:0 step:9 [D loss: 0.132987, acc.: 100.00%] [G loss: 1.316670]\n",
      "epoch:0 step:10 [D loss: 0.113404, acc.: 100.00%] [G loss: 1.588310]\n",
      "epoch:0 step:11 [D loss: 0.110259, acc.: 100.00%] [G loss: 1.651841]\n",
      "epoch:0 step:12 [D loss: 0.101780, acc.: 100.00%] [G loss: 1.903466]\n",
      "epoch:0 step:13 [D loss: 0.088110, acc.: 100.00%] [G loss: 2.007510]\n",
      "epoch:0 step:14 [D loss: 0.088028, acc.: 100.00%] [G loss: 2.278149]\n",
      "epoch:0 step:15 [D loss: 0.081257, acc.: 100.00%] [G loss: 2.288930]\n",
      "epoch:0 step:16 [D loss: 0.072200, acc.: 100.00%] [G loss: 2.592303]\n",
      "epoch:0 step:17 [D loss: 0.072900, acc.: 100.00%] [G loss: 2.745750]\n",
      "epoch:0 step:18 [D loss: 0.064421, acc.: 100.00%] [G loss: 2.909514]\n",
      "epoch:0 step:19 [D loss: 0.064535, acc.: 100.00%] [G loss: 2.881959]\n",
      "epoch:0 step:20 [D loss: 0.060194, acc.: 100.00%] [G loss: 3.224694]\n",
      "epoch:0 step:21 [D loss: 0.054518, acc.: 100.00%] [G loss: 3.317939]\n",
      "epoch:0 step:22 [D loss: 0.047336, acc.: 100.00%] [G loss: 3.794353]\n",
      "epoch:0 step:23 [D loss: 0.049611, acc.: 100.00%] [G loss: 3.780716]\n",
      "epoch:0 step:24 [D loss: 0.042084, acc.: 100.00%] [G loss: 4.137320]\n",
      "epoch:0 step:25 [D loss: 0.039155, acc.: 100.00%] [G loss: 4.102852]\n",
      "epoch:0 step:26 [D loss: 0.039756, acc.: 100.00%] [G loss: 4.270515]\n",
      "epoch:0 step:27 [D loss: 0.035639, acc.: 100.00%] [G loss: 4.508704]\n",
      "epoch:0 step:28 [D loss: 0.038636, acc.: 100.00%] [G loss: 4.481187]\n",
      "epoch:0 step:29 [D loss: 0.035085, acc.: 100.00%] [G loss: 4.628951]\n",
      "epoch:0 step:30 [D loss: 0.033965, acc.: 100.00%] [G loss: 4.642435]\n",
      "epoch:0 step:31 [D loss: 0.031093, acc.: 100.00%] [G loss: 5.024810]\n",
      "epoch:0 step:32 [D loss: 0.031371, acc.: 100.00%] [G loss: 5.183672]\n",
      "epoch:0 step:33 [D loss: 0.026555, acc.: 100.00%] [G loss: 5.384934]\n",
      "epoch:0 step:34 [D loss: 0.026311, acc.: 100.00%] [G loss: 5.307948]\n",
      "epoch:0 step:35 [D loss: 0.028337, acc.: 100.00%] [G loss: 5.353200]\n",
      "epoch:0 step:36 [D loss: 0.022917, acc.: 100.00%] [G loss: 5.770340]\n",
      "epoch:0 step:37 [D loss: 0.022759, acc.: 100.00%] [G loss: 6.115350]\n",
      "epoch:0 step:38 [D loss: 0.027811, acc.: 100.00%] [G loss: 5.708802]\n",
      "epoch:0 step:39 [D loss: 0.024562, acc.: 100.00%] [G loss: 6.040533]\n",
      "epoch:0 step:40 [D loss: 0.021959, acc.: 100.00%] [G loss: 6.122448]\n",
      "epoch:0 step:41 [D loss: 0.020387, acc.: 100.00%] [G loss: 6.346574]\n",
      "epoch:0 step:42 [D loss: 0.020804, acc.: 100.00%] [G loss: 6.456322]\n",
      "epoch:0 step:43 [D loss: 0.022592, acc.: 100.00%] [G loss: 6.231067]\n",
      "epoch:0 step:44 [D loss: 0.022649, acc.: 100.00%] [G loss: 6.450253]\n",
      "epoch:0 step:45 [D loss: 0.020929, acc.: 100.00%] [G loss: 6.613473]\n",
      "epoch:0 step:46 [D loss: 0.020939, acc.: 100.00%] [G loss: 7.420425]\n",
      "epoch:0 step:47 [D loss: 0.018960, acc.: 100.00%] [G loss: 7.358021]\n",
      "epoch:0 step:48 [D loss: 0.016071, acc.: 100.00%] [G loss: 7.119596]\n",
      "epoch:0 step:49 [D loss: 0.019296, acc.: 100.00%] [G loss: 6.943687]\n",
      "epoch:0 step:50 [D loss: 0.018134, acc.: 100.00%] [G loss: 7.342638]\n",
      "epoch:0 step:51 [D loss: 0.015232, acc.: 100.00%] [G loss: 7.488739]\n",
      "epoch:0 step:52 [D loss: 0.016790, acc.: 100.00%] [G loss: 7.583282]\n",
      "epoch:0 step:53 [D loss: 0.020602, acc.: 100.00%] [G loss: 7.504665]\n",
      "epoch:0 step:54 [D loss: 0.017897, acc.: 100.00%] [G loss: 7.671804]\n",
      "epoch:0 step:55 [D loss: 0.014096, acc.: 100.00%] [G loss: 7.387138]\n",
      "epoch:0 step:56 [D loss: 0.020497, acc.: 100.00%] [G loss: 7.913992]\n",
      "epoch:0 step:57 [D loss: 0.020335, acc.: 100.00%] [G loss: 7.901545]\n",
      "epoch:0 step:58 [D loss: 0.015548, acc.: 100.00%] [G loss: 7.691882]\n",
      "epoch:0 step:59 [D loss: 0.019452, acc.: 100.00%] [G loss: 8.329576]\n",
      "epoch:0 step:60 [D loss: 0.013647, acc.: 100.00%] [G loss: 8.300814]\n",
      "epoch:0 step:61 [D loss: 0.016137, acc.: 100.00%] [G loss: 8.053288]\n",
      "epoch:0 step:62 [D loss: 0.015715, acc.: 100.00%] [G loss: 7.927619]\n",
      "epoch:0 step:63 [D loss: 0.016372, acc.: 100.00%] [G loss: 8.321899]\n",
      "epoch:0 step:64 [D loss: 0.019307, acc.: 100.00%] [G loss: 8.514524]\n",
      "epoch:0 step:65 [D loss: 0.015142, acc.: 100.00%] [G loss: 8.379103]\n",
      "epoch:0 step:66 [D loss: 0.014164, acc.: 100.00%] [G loss: 8.526659]\n",
      "epoch:0 step:67 [D loss: 0.018734, acc.: 100.00%] [G loss: 8.195797]\n",
      "epoch:0 step:68 [D loss: 0.016590, acc.: 100.00%] [G loss: 8.481557]\n",
      "epoch:0 step:69 [D loss: 0.015764, acc.: 100.00%] [G loss: 8.154290]\n",
      "epoch:0 step:70 [D loss: 0.019392, acc.: 100.00%] [G loss: 8.439311]\n",
      "epoch:0 step:71 [D loss: 0.017709, acc.: 100.00%] [G loss: 8.685599]\n",
      "epoch:0 step:72 [D loss: 0.015120, acc.: 100.00%] [G loss: 8.304066]\n",
      "epoch:0 step:73 [D loss: 0.014356, acc.: 100.00%] [G loss: 8.492290]\n",
      "epoch:0 step:74 [D loss: 0.022154, acc.: 100.00%] [G loss: 8.540625]\n",
      "epoch:0 step:75 [D loss: 0.014002, acc.: 100.00%] [G loss: 8.677958]\n",
      "epoch:0 step:76 [D loss: 0.016735, acc.: 100.00%] [G loss: 8.947024]\n",
      "epoch:0 step:77 [D loss: 0.018718, acc.: 100.00%] [G loss: 9.144426]\n",
      "epoch:0 step:78 [D loss: 0.016914, acc.: 100.00%] [G loss: 9.888350]\n",
      "epoch:0 step:79 [D loss: 0.019264, acc.: 100.00%] [G loss: 9.075581]\n",
      "epoch:0 step:80 [D loss: 0.016989, acc.: 100.00%] [G loss: 9.080841]\n",
      "epoch:0 step:81 [D loss: 0.017007, acc.: 100.00%] [G loss: 8.987045]\n",
      "epoch:0 step:82 [D loss: 0.017290, acc.: 100.00%] [G loss: 9.166116]\n",
      "epoch:0 step:83 [D loss: 0.016816, acc.: 100.00%] [G loss: 9.083138]\n",
      "epoch:0 step:84 [D loss: 0.024200, acc.: 100.00%] [G loss: 9.361596]\n",
      "epoch:0 step:85 [D loss: 0.032512, acc.: 100.00%] [G loss: 9.432028]\n",
      "epoch:0 step:86 [D loss: 0.031478, acc.: 100.00%] [G loss: 9.458736]\n",
      "epoch:0 step:87 [D loss: 0.031868, acc.: 100.00%] [G loss: 10.831568]\n",
      "epoch:0 step:88 [D loss: 0.157951, acc.: 92.19%] [G loss: 14.892922]\n",
      "epoch:0 step:89 [D loss: 0.685009, acc.: 80.47%] [G loss: 16.616825]\n",
      "epoch:0 step:90 [D loss: 0.127247, acc.: 92.19%] [G loss: 14.409027]\n",
      "epoch:0 step:91 [D loss: 0.027716, acc.: 100.00%] [G loss: 12.853603]\n",
      "epoch:0 step:92 [D loss: 0.027854, acc.: 100.00%] [G loss: 13.503038]\n",
      "epoch:0 step:93 [D loss: 0.021274, acc.: 100.00%] [G loss: 12.202741]\n",
      "epoch:0 step:94 [D loss: 0.060726, acc.: 99.22%] [G loss: 9.493985]\n",
      "epoch:0 step:95 [D loss: 0.024589, acc.: 100.00%] [G loss: 9.415169]\n",
      "epoch:0 step:96 [D loss: 0.028780, acc.: 100.00%] [G loss: 9.151812]\n",
      "epoch:0 step:97 [D loss: 0.052555, acc.: 98.44%] [G loss: 10.752670]\n",
      "epoch:0 step:98 [D loss: 0.024013, acc.: 100.00%] [G loss: 10.410002]\n",
      "epoch:0 step:99 [D loss: 0.067821, acc.: 99.22%] [G loss: 8.726175]\n",
      "epoch:0 step:100 [D loss: 0.046653, acc.: 100.00%] [G loss: 8.998748]\n",
      "epoch:0 step:101 [D loss: 0.102421, acc.: 97.66%] [G loss: 8.546150]\n",
      "epoch:0 step:102 [D loss: 0.025028, acc.: 100.00%] [G loss: 8.790211]\n",
      "epoch:0 step:103 [D loss: 0.051282, acc.: 100.00%] [G loss: 9.139352]\n",
      "epoch:0 step:104 [D loss: 0.089077, acc.: 98.44%] [G loss: 7.655836]\n",
      "epoch:0 step:105 [D loss: 0.024070, acc.: 100.00%] [G loss: 7.233019]\n",
      "epoch:0 step:106 [D loss: 0.080845, acc.: 96.88%] [G loss: 9.199387]\n",
      "epoch:0 step:107 [D loss: 0.514295, acc.: 82.81%] [G loss: 8.107115]\n",
      "epoch:0 step:108 [D loss: 0.051090, acc.: 100.00%] [G loss: 9.555153]\n",
      "epoch:0 step:109 [D loss: 0.542931, acc.: 75.78%] [G loss: 6.871181]\n",
      "epoch:0 step:110 [D loss: 0.065547, acc.: 99.22%] [G loss: 10.107060]\n",
      "epoch:0 step:111 [D loss: 0.050839, acc.: 100.00%] [G loss: 8.052870]\n",
      "epoch:0 step:112 [D loss: 0.070169, acc.: 99.22%] [G loss: 9.329168]\n",
      "epoch:0 step:113 [D loss: 0.116297, acc.: 96.88%] [G loss: 10.377321]\n",
      "epoch:0 step:114 [D loss: 0.096450, acc.: 98.44%] [G loss: 7.381714]\n",
      "epoch:0 step:115 [D loss: 0.053948, acc.: 99.22%] [G loss: 7.295408]\n",
      "epoch:0 step:116 [D loss: 0.053829, acc.: 99.22%] [G loss: 9.193322]\n",
      "epoch:0 step:117 [D loss: 0.048310, acc.: 100.00%] [G loss: 9.689543]\n",
      "epoch:0 step:118 [D loss: 0.103266, acc.: 98.44%] [G loss: 10.457325]\n",
      "epoch:0 step:119 [D loss: 0.205513, acc.: 90.62%] [G loss: 8.913132]\n",
      "epoch:0 step:120 [D loss: 0.102805, acc.: 99.22%] [G loss: 7.446466]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0 step:121 [D loss: 0.057464, acc.: 100.00%] [G loss: 9.109513]\n",
      "epoch:0 step:122 [D loss: 0.353837, acc.: 83.59%] [G loss: 9.608680]\n",
      "epoch:0 step:123 [D loss: 0.178020, acc.: 92.97%] [G loss: 7.406180]\n",
      "epoch:0 step:124 [D loss: 0.147613, acc.: 94.53%] [G loss: 8.493693]\n",
      "epoch:0 step:125 [D loss: 0.413089, acc.: 82.81%] [G loss: 9.821875]\n",
      "epoch:0 step:126 [D loss: 0.723798, acc.: 73.44%] [G loss: 6.927329]\n",
      "epoch:0 step:127 [D loss: 0.198574, acc.: 90.62%] [G loss: 9.713606]\n",
      "epoch:0 step:128 [D loss: 0.097447, acc.: 96.09%] [G loss: 12.247216]\n",
      "epoch:0 step:129 [D loss: 0.143822, acc.: 96.09%] [G loss: 11.634010]\n",
      "epoch:0 step:130 [D loss: 0.275716, acc.: 91.41%] [G loss: 7.175950]\n",
      "epoch:0 step:131 [D loss: 0.081023, acc.: 97.66%] [G loss: 9.156990]\n",
      "epoch:0 step:132 [D loss: 0.074912, acc.: 97.66%] [G loss: 9.167073]\n",
      "epoch:0 step:133 [D loss: 0.147457, acc.: 96.09%] [G loss: 7.600654]\n",
      "epoch:0 step:134 [D loss: 0.134759, acc.: 96.09%] [G loss: 8.189727]\n",
      "epoch:0 step:135 [D loss: 0.176502, acc.: 95.31%] [G loss: 7.047235]\n",
      "epoch:0 step:136 [D loss: 0.078947, acc.: 99.22%] [G loss: 8.047266]\n",
      "epoch:0 step:137 [D loss: 0.306389, acc.: 85.94%] [G loss: 6.799400]\n",
      "epoch:0 step:138 [D loss: 0.083776, acc.: 99.22%] [G loss: 7.817381]\n",
      "epoch:0 step:139 [D loss: 0.658554, acc.: 72.66%] [G loss: 7.666039]\n",
      "epoch:0 step:140 [D loss: 0.339406, acc.: 82.03%] [G loss: 7.899059]\n",
      "epoch:0 step:141 [D loss: 0.063436, acc.: 100.00%] [G loss: 13.901338]\n",
      "epoch:0 step:142 [D loss: 0.054520, acc.: 99.22%] [G loss: 11.604281]\n",
      "epoch:0 step:143 [D loss: 0.053104, acc.: 100.00%] [G loss: 9.021008]\n",
      "epoch:0 step:144 [D loss: 0.070279, acc.: 100.00%] [G loss: 7.717684]\n",
      "epoch:0 step:145 [D loss: 0.052518, acc.: 100.00%] [G loss: 8.319764]\n",
      "epoch:0 step:146 [D loss: 0.297072, acc.: 85.94%] [G loss: 7.751232]\n",
      "epoch:0 step:147 [D loss: 0.409099, acc.: 84.38%] [G loss: 8.283072]\n",
      "epoch:0 step:148 [D loss: 0.608343, acc.: 71.09%] [G loss: 6.022988]\n",
      "epoch:0 step:149 [D loss: 0.198610, acc.: 88.28%] [G loss: 7.027868]\n",
      "epoch:0 step:150 [D loss: 0.096789, acc.: 98.44%] [G loss: 8.972200]\n",
      "epoch:0 step:151 [D loss: 0.155571, acc.: 96.09%] [G loss: 8.093657]\n",
      "epoch:0 step:152 [D loss: 0.146087, acc.: 96.09%] [G loss: 6.753802]\n",
      "epoch:0 step:153 [D loss: 0.093831, acc.: 99.22%] [G loss: 6.648298]\n",
      "epoch:0 step:154 [D loss: 0.133686, acc.: 99.22%] [G loss: 6.494176]\n",
      "epoch:0 step:155 [D loss: 0.423095, acc.: 82.03%] [G loss: 8.783318]\n",
      "epoch:0 step:156 [D loss: 0.805997, acc.: 65.62%] [G loss: 5.746932]\n",
      "epoch:0 step:157 [D loss: 0.192148, acc.: 91.41%] [G loss: 7.635515]\n",
      "epoch:0 step:158 [D loss: 0.100753, acc.: 97.66%] [G loss: 8.475029]\n",
      "epoch:0 step:159 [D loss: 0.193640, acc.: 91.41%] [G loss: 8.143357]\n",
      "epoch:0 step:160 [D loss: 0.333353, acc.: 85.16%] [G loss: 4.473675]\n",
      "epoch:0 step:161 [D loss: 0.099874, acc.: 99.22%] [G loss: 7.253398]\n",
      "epoch:0 step:162 [D loss: 0.358216, acc.: 83.59%] [G loss: 6.991375]\n",
      "epoch:0 step:163 [D loss: 0.221514, acc.: 92.97%] [G loss: 6.216765]\n",
      "epoch:0 step:164 [D loss: 0.119011, acc.: 100.00%] [G loss: 4.966721]\n",
      "epoch:0 step:165 [D loss: 0.209354, acc.: 96.09%] [G loss: 4.778089]\n",
      "epoch:0 step:166 [D loss: 0.121376, acc.: 100.00%] [G loss: 6.755557]\n",
      "epoch:0 step:167 [D loss: 0.440255, acc.: 79.69%] [G loss: 4.683924]\n",
      "epoch:0 step:168 [D loss: 0.088656, acc.: 99.22%] [G loss: 6.301780]\n",
      "epoch:0 step:169 [D loss: 0.350725, acc.: 83.59%] [G loss: 4.988702]\n",
      "epoch:0 step:170 [D loss: 0.177209, acc.: 96.88%] [G loss: 8.069395]\n",
      "epoch:0 step:171 [D loss: 1.263710, acc.: 53.91%] [G loss: 5.699194]\n",
      "epoch:0 step:172 [D loss: 0.248788, acc.: 88.28%] [G loss: 6.737764]\n",
      "epoch:0 step:173 [D loss: 0.129052, acc.: 99.22%] [G loss: 7.192963]\n",
      "epoch:0 step:174 [D loss: 0.268081, acc.: 91.41%] [G loss: 6.069191]\n",
      "epoch:0 step:175 [D loss: 0.097839, acc.: 99.22%] [G loss: 6.729690]\n",
      "epoch:0 step:176 [D loss: 0.170049, acc.: 96.09%] [G loss: 5.219606]\n",
      "epoch:0 step:177 [D loss: 0.151661, acc.: 97.66%] [G loss: 6.231339]\n",
      "epoch:0 step:178 [D loss: 0.142376, acc.: 97.66%] [G loss: 6.516700]\n",
      "epoch:0 step:179 [D loss: 0.539051, acc.: 76.56%] [G loss: 4.514282]\n",
      "epoch:0 step:180 [D loss: 0.153298, acc.: 96.88%] [G loss: 8.117838]\n",
      "epoch:0 step:181 [D loss: 0.587582, acc.: 69.53%] [G loss: 4.212636]\n",
      "epoch:0 step:182 [D loss: 0.149683, acc.: 95.31%] [G loss: 6.746892]\n",
      "epoch:0 step:183 [D loss: 0.184852, acc.: 96.88%] [G loss: 5.343153]\n",
      "epoch:0 step:184 [D loss: 0.125516, acc.: 97.66%] [G loss: 5.680771]\n",
      "epoch:0 step:185 [D loss: 0.197374, acc.: 93.75%] [G loss: 5.673507]\n",
      "epoch:0 step:186 [D loss: 0.235937, acc.: 96.09%] [G loss: 6.227137]\n",
      "epoch:0 step:187 [D loss: 0.377744, acc.: 82.03%] [G loss: 4.976607]\n",
      "epoch:0 step:188 [D loss: 0.404747, acc.: 78.12%] [G loss: 3.533381]\n",
      "epoch:0 step:189 [D loss: 0.308843, acc.: 87.50%] [G loss: 6.228701]\n",
      "epoch:0 step:190 [D loss: 0.377875, acc.: 82.03%] [G loss: 5.231530]\n",
      "epoch:0 step:191 [D loss: 0.259679, acc.: 90.62%] [G loss: 5.136074]\n",
      "epoch:0 step:192 [D loss: 0.391211, acc.: 82.03%] [G loss: 4.797797]\n",
      "epoch:0 step:193 [D loss: 0.324176, acc.: 87.50%] [G loss: 5.215646]\n",
      "epoch:0 step:194 [D loss: 0.301564, acc.: 88.28%] [G loss: 6.992193]\n",
      "epoch:0 step:195 [D loss: 0.798730, acc.: 57.81%] [G loss: 2.597549]\n",
      "epoch:0 step:196 [D loss: 0.176979, acc.: 96.88%] [G loss: 7.965905]\n",
      "epoch:0 step:197 [D loss: 1.085828, acc.: 46.88%] [G loss: 3.282455]\n",
      "epoch:0 step:198 [D loss: 0.498918, acc.: 71.09%] [G loss: 5.321315]\n",
      "epoch:0 step:199 [D loss: 0.153130, acc.: 98.44%] [G loss: 7.634719]\n",
      "epoch:0 step:200 [D loss: 0.572491, acc.: 71.88%] [G loss: 2.867275]\n",
      "WARNING:tensorflow:From /home/imi432_006/anaconda3/envs/tf/lib/python3.5/site-packages/tensorflow/contrib/gan/python/eval/python/classifier_metrics_impl.py:185: FastGFile.__init__ (from tensorflow.python.platform.gfile) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.gfile.GFile.\n",
      "##############\n",
      "[ 7.00403026  7.59974359 13.25367035  9.74316447  8.65115902 11.98333983\n",
      " 11.27914699  9.65214154  9.62101226 10.29102348]\n",
      "##########\n",
      "epoch:0 step:201 [D loss: 0.211405, acc.: 94.53%] [G loss: 6.683182]\n",
      "epoch:0 step:202 [D loss: 0.390326, acc.: 85.16%] [G loss: 3.803800]\n",
      "epoch:0 step:203 [D loss: 0.334260, acc.: 83.59%] [G loss: 4.238925]\n",
      "epoch:0 step:204 [D loss: 0.296385, acc.: 89.84%] [G loss: 3.763796]\n",
      "epoch:0 step:205 [D loss: 0.331807, acc.: 89.06%] [G loss: 5.232614]\n",
      "epoch:0 step:206 [D loss: 0.399579, acc.: 82.81%] [G loss: 3.230982]\n",
      "epoch:0 step:207 [D loss: 0.336747, acc.: 89.84%] [G loss: 3.665817]\n",
      "epoch:0 step:208 [D loss: 0.321678, acc.: 95.31%] [G loss: 3.528446]\n",
      "epoch:0 step:209 [D loss: 0.476351, acc.: 75.78%] [G loss: 4.162993]\n",
      "epoch:0 step:210 [D loss: 0.561162, acc.: 67.97%] [G loss: 3.331047]\n",
      "epoch:0 step:211 [D loss: 0.291281, acc.: 92.97%] [G loss: 4.719779]\n",
      "epoch:0 step:212 [D loss: 0.984182, acc.: 42.97%] [G loss: 0.858810]\n",
      "epoch:0 step:213 [D loss: 0.216134, acc.: 95.31%] [G loss: 6.927873]\n",
      "epoch:0 step:214 [D loss: 1.661449, acc.: 18.75%] [G loss: 1.562151]\n",
      "epoch:0 step:215 [D loss: 0.835545, acc.: 55.47%] [G loss: 0.510005]\n",
      "epoch:0 step:216 [D loss: 0.196860, acc.: 96.09%] [G loss: 4.199252]\n",
      "epoch:0 step:217 [D loss: 0.424612, acc.: 87.50%] [G loss: 2.240311]\n",
      "epoch:0 step:218 [D loss: 0.259352, acc.: 97.66%] [G loss: 2.596640]\n",
      "epoch:0 step:219 [D loss: 0.337692, acc.: 90.62%] [G loss: 2.664117]\n",
      "epoch:0 step:220 [D loss: 0.941608, acc.: 39.84%] [G loss: 0.327138]\n",
      "epoch:0 step:221 [D loss: 0.389100, acc.: 78.91%] [G loss: 2.439990]\n",
      "epoch:0 step:222 [D loss: 0.379903, acc.: 91.41%] [G loss: 2.794069]\n",
      "epoch:0 step:223 [D loss: 0.384203, acc.: 89.84%] [G loss: 2.121073]\n",
      "epoch:0 step:224 [D loss: 0.701751, acc.: 54.69%] [G loss: 0.702404]\n",
      "epoch:0 step:225 [D loss: 0.456655, acc.: 69.53%] [G loss: 2.184819]\n",
      "epoch:0 step:226 [D loss: 0.526269, acc.: 75.78%] [G loss: 1.682180]\n",
      "epoch:0 step:227 [D loss: 0.493162, acc.: 75.78%] [G loss: 2.297980]\n",
      "epoch:0 step:228 [D loss: 0.466155, acc.: 79.69%] [G loss: 2.625685]\n",
      "epoch:0 step:229 [D loss: 0.869456, acc.: 42.19%] [G loss: 0.363584]\n",
      "epoch:0 step:230 [D loss: 0.334725, acc.: 87.50%] [G loss: 3.528443]\n",
      "epoch:0 step:231 [D loss: 0.580387, acc.: 72.66%] [G loss: 1.533902]\n",
      "epoch:0 step:232 [D loss: 0.387928, acc.: 86.72%] [G loss: 2.484664]\n",
      "epoch:0 step:233 [D loss: 1.000984, acc.: 35.16%] [G loss: 0.216849]\n",
      "epoch:0 step:234 [D loss: 0.461458, acc.: 69.53%] [G loss: 2.658579]\n",
      "epoch:0 step:235 [D loss: 0.682638, acc.: 57.81%] [G loss: 0.727819]\n",
      "epoch:0 step:236 [D loss: 0.589508, acc.: 63.28%] [G loss: 0.893571]\n",
      "epoch:0 step:237 [D loss: 0.556304, acc.: 67.97%] [G loss: 1.152408]\n",
      "epoch:0 step:238 [D loss: 0.563197, acc.: 71.09%] [G loss: 1.223580]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0 step:239 [D loss: 0.620870, acc.: 56.25%] [G loss: 0.969680]\n",
      "epoch:0 step:240 [D loss: 0.447437, acc.: 82.81%] [G loss: 1.376672]\n",
      "epoch:0 step:241 [D loss: 0.632635, acc.: 61.72%] [G loss: 0.965925]\n",
      "epoch:0 step:242 [D loss: 0.580505, acc.: 64.06%] [G loss: 1.471174]\n",
      "epoch:0 step:243 [D loss: 0.840901, acc.: 39.84%] [G loss: 0.284160]\n",
      "epoch:0 step:244 [D loss: 0.519187, acc.: 67.19%] [G loss: 1.408783]\n",
      "epoch:0 step:245 [D loss: 0.817913, acc.: 40.62%] [G loss: 0.321905]\n",
      "epoch:0 step:246 [D loss: 0.601597, acc.: 58.59%] [G loss: 0.583119]\n",
      "epoch:0 step:247 [D loss: 0.555876, acc.: 69.53%] [G loss: 1.015525]\n",
      "epoch:0 step:248 [D loss: 0.663671, acc.: 53.12%] [G loss: 0.428447]\n",
      "epoch:0 step:249 [D loss: 0.743452, acc.: 43.75%] [G loss: 0.389581]\n",
      "epoch:0 step:250 [D loss: 0.508553, acc.: 67.19%] [G loss: 1.352936]\n",
      "epoch:0 step:251 [D loss: 0.896252, acc.: 33.59%] [G loss: 0.133144]\n",
      "epoch:0 step:252 [D loss: 0.593632, acc.: 53.91%] [G loss: 0.552189]\n",
      "epoch:0 step:253 [D loss: 0.618776, acc.: 67.97%] [G loss: 0.583567]\n",
      "epoch:0 step:254 [D loss: 0.629115, acc.: 63.28%] [G loss: 0.422666]\n",
      "epoch:0 step:255 [D loss: 0.596767, acc.: 64.06%] [G loss: 0.485038]\n",
      "epoch:0 step:256 [D loss: 0.662888, acc.: 50.00%] [G loss: 0.415107]\n",
      "epoch:0 step:257 [D loss: 0.508324, acc.: 73.44%] [G loss: 0.904415]\n",
      "epoch:0 step:258 [D loss: 0.661983, acc.: 54.69%] [G loss: 0.357919]\n",
      "epoch:0 step:259 [D loss: 0.615378, acc.: 56.25%] [G loss: 0.479932]\n",
      "epoch:0 step:260 [D loss: 0.617034, acc.: 64.06%] [G loss: 0.470681]\n",
      "epoch:0 step:261 [D loss: 0.671957, acc.: 59.38%] [G loss: 0.505102]\n",
      "epoch:0 step:262 [D loss: 0.626044, acc.: 62.50%] [G loss: 0.431749]\n",
      "epoch:0 step:263 [D loss: 0.854228, acc.: 31.25%] [G loss: 0.063996]\n",
      "epoch:0 step:264 [D loss: 0.551414, acc.: 59.38%] [G loss: 0.423559]\n",
      "epoch:0 step:265 [D loss: 0.656787, acc.: 63.28%] [G loss: 0.400333]\n",
      "epoch:0 step:266 [D loss: 0.707452, acc.: 44.53%] [G loss: 0.235530]\n",
      "epoch:0 step:267 [D loss: 0.545006, acc.: 71.09%] [G loss: 0.575508]\n",
      "epoch:0 step:268 [D loss: 0.785625, acc.: 44.53%] [G loss: 0.111334]\n",
      "epoch:0 step:269 [D loss: 0.714023, acc.: 42.97%] [G loss: 0.101240]\n",
      "epoch:0 step:270 [D loss: 0.613158, acc.: 55.47%] [G loss: 0.267914]\n",
      "epoch:0 step:271 [D loss: 0.696629, acc.: 46.88%] [G loss: 0.217189]\n",
      "epoch:0 step:272 [D loss: 0.607800, acc.: 58.59%] [G loss: 0.286521]\n",
      "epoch:0 step:273 [D loss: 0.619515, acc.: 57.81%] [G loss: 0.360095]\n",
      "epoch:0 step:274 [D loss: 0.713565, acc.: 46.09%] [G loss: 0.142430]\n",
      "epoch:0 step:275 [D loss: 0.609802, acc.: 55.47%] [G loss: 0.218032]\n",
      "epoch:0 step:276 [D loss: 0.677484, acc.: 46.88%] [G loss: 0.239879]\n",
      "epoch:0 step:277 [D loss: 0.568424, acc.: 72.66%] [G loss: 0.246389]\n",
      "epoch:0 step:278 [D loss: 0.596335, acc.: 61.72%] [G loss: 0.300148]\n",
      "epoch:0 step:279 [D loss: 0.589619, acc.: 57.81%] [G loss: 0.403029]\n",
      "epoch:0 step:280 [D loss: 0.532085, acc.: 78.12%] [G loss: 0.426227]\n",
      "epoch:0 step:281 [D loss: 0.665722, acc.: 53.12%] [G loss: 0.235632]\n",
      "epoch:0 step:282 [D loss: 0.591523, acc.: 58.59%] [G loss: 0.330896]\n",
      "epoch:0 step:283 [D loss: 0.626571, acc.: 57.03%] [G loss: 0.287564]\n",
      "epoch:0 step:284 [D loss: 0.579481, acc.: 64.06%] [G loss: 0.403041]\n",
      "epoch:0 step:285 [D loss: 0.609496, acc.: 62.50%] [G loss: 0.313155]\n",
      "epoch:0 step:286 [D loss: 0.562719, acc.: 70.31%] [G loss: 0.475506]\n",
      "epoch:0 step:287 [D loss: 0.560047, acc.: 75.00%] [G loss: 0.346969]\n",
      "epoch:0 step:288 [D loss: 0.646014, acc.: 56.25%] [G loss: 0.280858]\n",
      "epoch:0 step:289 [D loss: 0.540162, acc.: 70.31%] [G loss: 0.521313]\n",
      "epoch:0 step:290 [D loss: 0.721998, acc.: 47.66%] [G loss: 0.141714]\n",
      "epoch:0 step:291 [D loss: 0.725015, acc.: 42.97%] [G loss: 0.114067]\n",
      "epoch:0 step:292 [D loss: 0.624264, acc.: 51.56%] [G loss: 0.157053]\n",
      "epoch:0 step:293 [D loss: 0.645345, acc.: 54.69%] [G loss: 0.155843]\n",
      "epoch:0 step:294 [D loss: 0.634632, acc.: 54.69%] [G loss: 0.152346]\n",
      "epoch:0 step:295 [D loss: 0.691540, acc.: 43.75%] [G loss: 0.107436]\n",
      "epoch:0 step:296 [D loss: 0.622043, acc.: 57.81%] [G loss: 0.170033]\n",
      "epoch:0 step:297 [D loss: 0.606849, acc.: 62.50%] [G loss: 0.153112]\n",
      "epoch:0 step:298 [D loss: 0.628032, acc.: 57.03%] [G loss: 0.133979]\n",
      "epoch:0 step:299 [D loss: 0.590123, acc.: 65.62%] [G loss: 0.213431]\n",
      "epoch:0 step:300 [D loss: 0.633550, acc.: 59.38%] [G loss: 0.150796]\n",
      "epoch:0 step:301 [D loss: 0.759672, acc.: 38.28%] [G loss: 0.069692]\n",
      "epoch:0 step:302 [D loss: 0.607948, acc.: 50.00%] [G loss: 0.152251]\n",
      "epoch:0 step:303 [D loss: 0.712889, acc.: 43.75%] [G loss: 0.092189]\n",
      "epoch:0 step:304 [D loss: 0.605005, acc.: 58.59%] [G loss: 0.154996]\n",
      "epoch:0 step:305 [D loss: 0.592082, acc.: 64.06%] [G loss: 0.198267]\n",
      "epoch:0 step:306 [D loss: 0.584787, acc.: 74.22%] [G loss: 0.230817]\n",
      "epoch:0 step:307 [D loss: 0.556394, acc.: 70.31%] [G loss: 0.233523]\n",
      "epoch:0 step:308 [D loss: 0.663475, acc.: 54.69%] [G loss: 0.140219]\n",
      "epoch:0 step:309 [D loss: 0.629775, acc.: 56.25%] [G loss: 0.136844]\n",
      "epoch:0 step:310 [D loss: 0.580965, acc.: 61.72%] [G loss: 0.221794]\n",
      "epoch:0 step:311 [D loss: 0.637279, acc.: 60.16%] [G loss: 0.145221]\n",
      "epoch:0 step:312 [D loss: 0.757257, acc.: 35.16%] [G loss: 0.043673]\n",
      "epoch:0 step:313 [D loss: 0.649730, acc.: 48.44%] [G loss: 0.070214]\n",
      "epoch:0 step:314 [D loss: 0.545882, acc.: 68.75%] [G loss: 0.245589]\n",
      "epoch:0 step:315 [D loss: 0.609082, acc.: 67.19%] [G loss: 0.202279]\n",
      "epoch:0 step:316 [D loss: 0.726318, acc.: 41.41%] [G loss: 0.050508]\n",
      "epoch:0 step:317 [D loss: 0.595159, acc.: 55.47%] [G loss: 0.081858]\n",
      "epoch:0 step:318 [D loss: 0.612751, acc.: 52.34%] [G loss: 0.089264]\n",
      "epoch:0 step:319 [D loss: 0.598594, acc.: 62.50%] [G loss: 0.099811]\n",
      "epoch:0 step:320 [D loss: 0.571139, acc.: 64.84%] [G loss: 0.129908]\n",
      "epoch:0 step:321 [D loss: 0.615667, acc.: 64.84%] [G loss: 0.093426]\n",
      "epoch:0 step:322 [D loss: 0.581342, acc.: 61.72%] [G loss: 0.117428]\n",
      "epoch:0 step:323 [D loss: 0.565248, acc.: 69.53%] [G loss: 0.182291]\n",
      "epoch:0 step:324 [D loss: 0.548290, acc.: 74.22%] [G loss: 0.203116]\n",
      "epoch:0 step:325 [D loss: 0.598435, acc.: 64.84%] [G loss: 0.128960]\n",
      "epoch:0 step:326 [D loss: 0.579720, acc.: 62.50%] [G loss: 0.146679]\n",
      "epoch:0 step:327 [D loss: 0.579798, acc.: 64.06%] [G loss: 0.148140]\n",
      "epoch:0 step:328 [D loss: 0.645191, acc.: 57.03%] [G loss: 0.149929]\n",
      "epoch:0 step:329 [D loss: 0.588608, acc.: 61.72%] [G loss: 0.154736]\n",
      "epoch:0 step:330 [D loss: 0.608056, acc.: 57.81%] [G loss: 0.091819]\n",
      "epoch:0 step:331 [D loss: 0.585039, acc.: 62.50%] [G loss: 0.134499]\n",
      "epoch:0 step:332 [D loss: 0.607369, acc.: 61.72%] [G loss: 0.101608]\n",
      "epoch:0 step:333 [D loss: 0.611435, acc.: 58.59%] [G loss: 0.112680]\n",
      "epoch:0 step:334 [D loss: 0.607786, acc.: 56.25%] [G loss: 0.103483]\n",
      "epoch:0 step:335 [D loss: 0.589907, acc.: 61.72%] [G loss: 0.121897]\n",
      "epoch:0 step:336 [D loss: 0.530330, acc.: 79.69%] [G loss: 0.202897]\n",
      "epoch:0 step:337 [D loss: 0.576072, acc.: 75.00%] [G loss: 0.163891]\n",
      "epoch:0 step:338 [D loss: 0.542155, acc.: 75.78%] [G loss: 0.190848]\n",
      "epoch:0 step:339 [D loss: 0.578564, acc.: 67.97%] [G loss: 0.166191]\n",
      "epoch:0 step:340 [D loss: 0.548690, acc.: 74.22%] [G loss: 0.209160]\n",
      "epoch:0 step:341 [D loss: 0.607570, acc.: 67.97%] [G loss: 0.129308]\n",
      "epoch:0 step:342 [D loss: 0.537821, acc.: 75.00%] [G loss: 0.170897]\n",
      "epoch:0 step:343 [D loss: 0.542220, acc.: 76.56%] [G loss: 0.233802]\n",
      "epoch:0 step:344 [D loss: 0.516026, acc.: 82.81%] [G loss: 0.282129]\n",
      "epoch:0 step:345 [D loss: 0.695633, acc.: 49.22%] [G loss: 0.059613]\n",
      "epoch:0 step:346 [D loss: 0.616811, acc.: 54.69%] [G loss: 0.051674]\n",
      "epoch:0 step:347 [D loss: 0.550412, acc.: 71.88%] [G loss: 0.109814]\n",
      "epoch:0 step:348 [D loss: 0.584403, acc.: 62.50%] [G loss: 0.107346]\n",
      "epoch:0 step:349 [D loss: 0.607538, acc.: 58.59%] [G loss: 0.068469]\n",
      "epoch:0 step:350 [D loss: 0.566301, acc.: 62.50%] [G loss: 0.115420]\n",
      "epoch:0 step:351 [D loss: 0.584785, acc.: 66.41%] [G loss: 0.116024]\n",
      "epoch:0 step:352 [D loss: 0.627279, acc.: 50.78%] [G loss: 0.072260]\n",
      "epoch:0 step:353 [D loss: 0.564141, acc.: 66.41%] [G loss: 0.098306]\n",
      "epoch:0 step:354 [D loss: 0.563327, acc.: 74.22%] [G loss: 0.143937]\n",
      "epoch:0 step:355 [D loss: 0.561771, acc.: 80.47%] [G loss: 0.201837]\n",
      "epoch:0 step:356 [D loss: 0.530489, acc.: 83.59%] [G loss: 0.198850]\n",
      "epoch:0 step:357 [D loss: 0.552645, acc.: 77.34%] [G loss: 0.147603]\n",
      "epoch:0 step:358 [D loss: 0.515481, acc.: 75.78%] [G loss: 0.228960]\n",
      "epoch:0 step:359 [D loss: 0.566024, acc.: 74.22%] [G loss: 0.189439]\n",
      "epoch:0 step:360 [D loss: 0.600406, acc.: 62.50%] [G loss: 0.135886]\n",
      "epoch:0 step:361 [D loss: 0.568411, acc.: 72.66%] [G loss: 0.151187]\n",
      "epoch:0 step:362 [D loss: 0.562173, acc.: 75.00%] [G loss: 0.132656]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0 step:363 [D loss: 0.519070, acc.: 75.00%] [G loss: 0.176670]\n",
      "epoch:0 step:364 [D loss: 0.539806, acc.: 79.69%] [G loss: 0.201134]\n",
      "epoch:0 step:365 [D loss: 0.595313, acc.: 64.06%] [G loss: 0.124028]\n",
      "epoch:0 step:366 [D loss: 0.564042, acc.: 70.31%] [G loss: 0.158878]\n",
      "epoch:0 step:367 [D loss: 0.530726, acc.: 75.00%] [G loss: 0.177371]\n",
      "epoch:0 step:368 [D loss: 0.571145, acc.: 71.88%] [G loss: 0.127029]\n",
      "epoch:0 step:369 [D loss: 0.614346, acc.: 60.94%] [G loss: 0.089975]\n",
      "epoch:0 step:370 [D loss: 0.616225, acc.: 57.03%] [G loss: 0.091989]\n",
      "epoch:0 step:371 [D loss: 0.633505, acc.: 56.25%] [G loss: 0.085816]\n",
      "epoch:0 step:372 [D loss: 0.585481, acc.: 61.72%] [G loss: 0.096527]\n",
      "epoch:0 step:373 [D loss: 0.591415, acc.: 70.31%] [G loss: 0.082142]\n",
      "epoch:0 step:374 [D loss: 0.622347, acc.: 57.81%] [G loss: 0.078645]\n",
      "epoch:0 step:375 [D loss: 0.515391, acc.: 83.59%] [G loss: 0.179197]\n",
      "epoch:0 step:376 [D loss: 0.514447, acc.: 81.25%] [G loss: 0.198882]\n",
      "epoch:0 step:377 [D loss: 0.522896, acc.: 85.94%] [G loss: 0.178586]\n",
      "epoch:0 step:378 [D loss: 0.503109, acc.: 82.81%] [G loss: 0.214602]\n",
      "epoch:0 step:379 [D loss: 0.538771, acc.: 80.47%] [G loss: 0.170550]\n",
      "epoch:0 step:380 [D loss: 0.623987, acc.: 65.62%] [G loss: 0.184300]\n",
      "epoch:0 step:381 [D loss: 0.546653, acc.: 73.44%] [G loss: 0.239052]\n",
      "epoch:0 step:382 [D loss: 0.627053, acc.: 64.84%] [G loss: 0.130838]\n",
      "epoch:0 step:383 [D loss: 0.585877, acc.: 63.28%] [G loss: 0.108510]\n",
      "epoch:0 step:384 [D loss: 0.588466, acc.: 61.72%] [G loss: 0.136977]\n",
      "epoch:0 step:385 [D loss: 0.611041, acc.: 68.75%] [G loss: 0.139031]\n",
      "epoch:0 step:386 [D loss: 0.546036, acc.: 71.09%] [G loss: 0.154960]\n",
      "epoch:0 step:387 [D loss: 0.579233, acc.: 69.53%] [G loss: 0.209962]\n",
      "epoch:0 step:388 [D loss: 0.541189, acc.: 82.03%] [G loss: 0.213938]\n",
      "epoch:0 step:389 [D loss: 0.619945, acc.: 67.97%] [G loss: 0.120328]\n",
      "epoch:0 step:390 [D loss: 0.568825, acc.: 74.22%] [G loss: 0.126571]\n",
      "epoch:0 step:391 [D loss: 0.583709, acc.: 67.19%] [G loss: 0.129243]\n",
      "epoch:0 step:392 [D loss: 0.542565, acc.: 80.47%] [G loss: 0.230005]\n",
      "epoch:0 step:393 [D loss: 0.632513, acc.: 61.72%] [G loss: 0.120657]\n",
      "epoch:0 step:394 [D loss: 0.617240, acc.: 60.94%] [G loss: 0.092183]\n",
      "epoch:0 step:395 [D loss: 0.615710, acc.: 58.59%] [G loss: 0.077447]\n",
      "epoch:0 step:396 [D loss: 0.651555, acc.: 53.12%] [G loss: 0.093867]\n",
      "epoch:0 step:397 [D loss: 0.543563, acc.: 70.31%] [G loss: 0.130219]\n",
      "epoch:0 step:398 [D loss: 0.544144, acc.: 79.69%] [G loss: 0.217836]\n",
      "epoch:0 step:399 [D loss: 0.539201, acc.: 82.81%] [G loss: 0.199976]\n",
      "epoch:0 step:400 [D loss: 0.660167, acc.: 56.25%] [G loss: 0.082722]\n",
      "##############\n",
      "[ 6.10848252  5.3250572  10.73063415  8.92959045  8.30176088  9.72222634\n",
      "  8.70883286  9.15064703  9.13034984  8.08738   ]\n",
      "##########\n",
      "epoch:0 step:401 [D loss: 0.555703, acc.: 74.22%] [G loss: 0.103381]\n",
      "epoch:0 step:402 [D loss: 0.601221, acc.: 65.62%] [G loss: 0.140793]\n",
      "epoch:0 step:403 [D loss: 0.597346, acc.: 71.88%] [G loss: 0.094930]\n",
      "epoch:0 step:404 [D loss: 0.630038, acc.: 66.41%] [G loss: 0.098909]\n",
      "epoch:0 step:405 [D loss: 0.609026, acc.: 67.19%] [G loss: 0.166261]\n",
      "epoch:0 step:406 [D loss: 0.619711, acc.: 67.19%] [G loss: 0.093313]\n",
      "epoch:0 step:407 [D loss: 0.566676, acc.: 73.44%] [G loss: 0.153325]\n",
      "epoch:0 step:408 [D loss: 0.561928, acc.: 78.12%] [G loss: 0.135951]\n",
      "epoch:0 step:409 [D loss: 0.570013, acc.: 69.53%] [G loss: 0.168747]\n",
      "epoch:0 step:410 [D loss: 0.578700, acc.: 66.41%] [G loss: 0.139814]\n",
      "epoch:0 step:411 [D loss: 0.610813, acc.: 65.62%] [G loss: 0.120696]\n",
      "epoch:0 step:412 [D loss: 0.550240, acc.: 78.12%] [G loss: 0.183144]\n",
      "epoch:0 step:413 [D loss: 0.614228, acc.: 69.53%] [G loss: 0.097838]\n",
      "epoch:0 step:414 [D loss: 0.562784, acc.: 73.44%] [G loss: 0.112294]\n",
      "epoch:0 step:415 [D loss: 0.595812, acc.: 64.84%] [G loss: 0.150932]\n",
      "epoch:0 step:416 [D loss: 0.588353, acc.: 64.84%] [G loss: 0.151498]\n",
      "epoch:0 step:417 [D loss: 0.601522, acc.: 69.53%] [G loss: 0.140142]\n",
      "epoch:0 step:418 [D loss: 0.585064, acc.: 68.75%] [G loss: 0.126768]\n",
      "epoch:0 step:419 [D loss: 0.566193, acc.: 65.62%] [G loss: 0.165048]\n",
      "epoch:0 step:420 [D loss: 0.577296, acc.: 69.53%] [G loss: 0.139437]\n",
      "epoch:0 step:421 [D loss: 0.629198, acc.: 63.28%] [G loss: 0.084443]\n",
      "epoch:0 step:422 [D loss: 0.584632, acc.: 64.06%] [G loss: 0.097906]\n",
      "epoch:0 step:423 [D loss: 0.598004, acc.: 60.16%] [G loss: 0.112959]\n",
      "epoch:0 step:424 [D loss: 0.602216, acc.: 65.62%] [G loss: 0.128862]\n",
      "epoch:0 step:425 [D loss: 0.626167, acc.: 61.72%] [G loss: 0.099148]\n",
      "epoch:0 step:426 [D loss: 0.559479, acc.: 75.00%] [G loss: 0.152992]\n",
      "epoch:0 step:427 [D loss: 0.613861, acc.: 66.41%] [G loss: 0.120288]\n",
      "epoch:0 step:428 [D loss: 0.569228, acc.: 73.44%] [G loss: 0.165514]\n",
      "epoch:0 step:429 [D loss: 0.604178, acc.: 64.84%] [G loss: 0.136047]\n",
      "epoch:0 step:430 [D loss: 0.562568, acc.: 76.56%] [G loss: 0.126435]\n",
      "epoch:0 step:431 [D loss: 0.601189, acc.: 65.62%] [G loss: 0.101861]\n",
      "epoch:0 step:432 [D loss: 0.644043, acc.: 64.06%] [G loss: 0.075614]\n",
      "epoch:0 step:433 [D loss: 0.578809, acc.: 63.28%] [G loss: 0.110236]\n",
      "epoch:0 step:434 [D loss: 0.601939, acc.: 63.28%] [G loss: 0.114279]\n",
      "epoch:0 step:435 [D loss: 0.598537, acc.: 66.41%] [G loss: 0.104225]\n",
      "epoch:0 step:436 [D loss: 0.583528, acc.: 70.31%] [G loss: 0.122422]\n",
      "epoch:0 step:437 [D loss: 0.639871, acc.: 53.91%] [G loss: 0.067222]\n",
      "epoch:0 step:438 [D loss: 0.520638, acc.: 75.00%] [G loss: 0.121756]\n",
      "epoch:0 step:439 [D loss: 0.554601, acc.: 74.22%] [G loss: 0.128967]\n",
      "epoch:0 step:440 [D loss: 0.588017, acc.: 67.19%] [G loss: 0.110488]\n",
      "epoch:0 step:441 [D loss: 0.588333, acc.: 67.97%] [G loss: 0.093536]\n",
      "epoch:0 step:442 [D loss: 0.554231, acc.: 75.78%] [G loss: 0.121180]\n",
      "epoch:0 step:443 [D loss: 0.585665, acc.: 67.19%] [G loss: 0.117278]\n",
      "epoch:0 step:444 [D loss: 0.582491, acc.: 68.75%] [G loss: 0.118582]\n",
      "epoch:0 step:445 [D loss: 0.580218, acc.: 71.09%] [G loss: 0.137333]\n",
      "epoch:0 step:446 [D loss: 0.546753, acc.: 74.22%] [G loss: 0.156238]\n",
      "epoch:0 step:447 [D loss: 0.496033, acc.: 88.28%] [G loss: 0.191311]\n",
      "epoch:0 step:448 [D loss: 0.713228, acc.: 51.56%] [G loss: 0.057204]\n",
      "epoch:0 step:449 [D loss: 0.622646, acc.: 58.59%] [G loss: 0.071225]\n",
      "epoch:0 step:450 [D loss: 0.543460, acc.: 73.44%] [G loss: 0.102031]\n",
      "epoch:0 step:451 [D loss: 0.613510, acc.: 66.41%] [G loss: 0.095570]\n",
      "epoch:0 step:452 [D loss: 0.611094, acc.: 65.62%] [G loss: 0.077894]\n",
      "epoch:0 step:453 [D loss: 0.604711, acc.: 69.53%] [G loss: 0.079712]\n",
      "epoch:0 step:454 [D loss: 0.581810, acc.: 67.97%] [G loss: 0.082922]\n",
      "epoch:0 step:455 [D loss: 0.583957, acc.: 73.44%] [G loss: 0.094509]\n",
      "epoch:0 step:456 [D loss: 0.602147, acc.: 67.19%] [G loss: 0.069438]\n",
      "epoch:0 step:457 [D loss: 0.598642, acc.: 61.72%] [G loss: 0.080289]\n",
      "epoch:0 step:458 [D loss: 0.579955, acc.: 73.44%] [G loss: 0.102581]\n",
      "epoch:0 step:459 [D loss: 0.571410, acc.: 77.34%] [G loss: 0.124064]\n",
      "epoch:0 step:460 [D loss: 0.580447, acc.: 71.09%] [G loss: 0.104104]\n",
      "epoch:0 step:461 [D loss: 0.562783, acc.: 73.44%] [G loss: 0.101272]\n",
      "epoch:0 step:462 [D loss: 0.572183, acc.: 76.56%] [G loss: 0.095383]\n",
      "epoch:0 step:463 [D loss: 0.604101, acc.: 70.31%] [G loss: 0.077844]\n",
      "epoch:0 step:464 [D loss: 0.582960, acc.: 74.22%] [G loss: 0.075481]\n",
      "epoch:0 step:465 [D loss: 0.589053, acc.: 73.44%] [G loss: 0.075800]\n",
      "epoch:0 step:466 [D loss: 0.548413, acc.: 75.00%] [G loss: 0.106186]\n",
      "epoch:0 step:467 [D loss: 0.593755, acc.: 67.19%] [G loss: 0.093582]\n",
      "epoch:0 step:468 [D loss: 0.561609, acc.: 80.47%] [G loss: 0.091761]\n",
      "epoch:0 step:469 [D loss: 0.585560, acc.: 70.31%] [G loss: 0.126335]\n",
      "epoch:0 step:470 [D loss: 0.589453, acc.: 71.09%] [G loss: 0.112419]\n",
      "epoch:0 step:471 [D loss: 0.574805, acc.: 75.00%] [G loss: 0.122472]\n",
      "epoch:0 step:472 [D loss: 0.609695, acc.: 66.41%] [G loss: 0.092326]\n",
      "epoch:0 step:473 [D loss: 0.602371, acc.: 70.31%] [G loss: 0.092947]\n",
      "epoch:0 step:474 [D loss: 0.617607, acc.: 60.94%] [G loss: 0.076379]\n",
      "epoch:0 step:475 [D loss: 0.592209, acc.: 69.53%] [G loss: 0.092169]\n",
      "epoch:0 step:476 [D loss: 0.571713, acc.: 75.78%] [G loss: 0.077744]\n",
      "epoch:0 step:477 [D loss: 0.585315, acc.: 69.53%] [G loss: 0.065624]\n",
      "epoch:0 step:478 [D loss: 0.553768, acc.: 77.34%] [G loss: 0.081650]\n",
      "epoch:0 step:479 [D loss: 0.519357, acc.: 80.47%] [G loss: 0.104898]\n",
      "epoch:0 step:480 [D loss: 0.551571, acc.: 79.69%] [G loss: 0.111918]\n",
      "epoch:0 step:481 [D loss: 0.563685, acc.: 68.75%] [G loss: 0.167246]\n",
      "epoch:0 step:482 [D loss: 0.625711, acc.: 64.06%] [G loss: 0.102798]\n",
      "epoch:0 step:483 [D loss: 0.596632, acc.: 64.84%] [G loss: 0.090220]\n",
      "epoch:0 step:484 [D loss: 0.556022, acc.: 79.69%] [G loss: 0.111343]\n",
      "epoch:0 step:485 [D loss: 0.550585, acc.: 82.81%] [G loss: 0.101339]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0 step:486 [D loss: 0.610523, acc.: 64.84%] [G loss: 0.087111]\n",
      "epoch:0 step:487 [D loss: 0.593914, acc.: 68.75%] [G loss: 0.083928]\n",
      "epoch:0 step:488 [D loss: 0.585089, acc.: 67.97%] [G loss: 0.118403]\n",
      "epoch:0 step:489 [D loss: 0.570597, acc.: 76.56%] [G loss: 0.105998]\n",
      "epoch:0 step:490 [D loss: 0.562677, acc.: 75.00%] [G loss: 0.115395]\n",
      "epoch:0 step:491 [D loss: 0.547714, acc.: 81.25%] [G loss: 0.115088]\n",
      "epoch:0 step:492 [D loss: 0.599106, acc.: 67.97%] [G loss: 0.114244]\n",
      "epoch:0 step:493 [D loss: 0.571968, acc.: 71.88%] [G loss: 0.080642]\n",
      "epoch:0 step:494 [D loss: 0.544331, acc.: 77.34%] [G loss: 0.130306]\n",
      "epoch:0 step:495 [D loss: 0.592846, acc.: 68.75%] [G loss: 0.142920]\n",
      "epoch:0 step:496 [D loss: 0.603133, acc.: 69.53%] [G loss: 0.118188]\n",
      "epoch:0 step:497 [D loss: 0.597607, acc.: 71.88%] [G loss: 0.100732]\n",
      "epoch:0 step:498 [D loss: 0.572558, acc.: 75.78%] [G loss: 0.087310]\n",
      "epoch:0 step:499 [D loss: 0.576051, acc.: 71.88%] [G loss: 0.121947]\n",
      "epoch:0 step:500 [D loss: 0.588683, acc.: 70.31%] [G loss: 0.075650]\n",
      "epoch:0 step:501 [D loss: 0.608312, acc.: 64.06%] [G loss: 0.065796]\n",
      "epoch:0 step:502 [D loss: 0.586656, acc.: 69.53%] [G loss: 0.058933]\n",
      "epoch:0 step:503 [D loss: 0.566596, acc.: 70.31%] [G loss: 0.074553]\n",
      "epoch:0 step:504 [D loss: 0.528096, acc.: 78.12%] [G loss: 0.125844]\n",
      "epoch:0 step:505 [D loss: 0.570477, acc.: 71.88%] [G loss: 0.112213]\n",
      "epoch:0 step:506 [D loss: 0.540635, acc.: 78.91%] [G loss: 0.145556]\n",
      "epoch:0 step:507 [D loss: 0.548649, acc.: 77.34%] [G loss: 0.132216]\n",
      "epoch:0 step:508 [D loss: 0.523849, acc.: 79.69%] [G loss: 0.167990]\n",
      "epoch:0 step:509 [D loss: 0.579976, acc.: 72.66%] [G loss: 0.146393]\n",
      "epoch:0 step:510 [D loss: 0.615218, acc.: 60.16%] [G loss: 0.109169]\n",
      "epoch:0 step:511 [D loss: 0.618540, acc.: 69.53%] [G loss: 0.071879]\n",
      "epoch:0 step:512 [D loss: 0.553436, acc.: 77.34%] [G loss: 0.083888]\n",
      "epoch:0 step:513 [D loss: 0.564932, acc.: 71.88%] [G loss: 0.095335]\n",
      "epoch:0 step:514 [D loss: 0.554073, acc.: 78.12%] [G loss: 0.121878]\n",
      "epoch:0 step:515 [D loss: 0.557077, acc.: 79.69%] [G loss: 0.120996]\n",
      "epoch:0 step:516 [D loss: 0.572040, acc.: 74.22%] [G loss: 0.098285]\n",
      "epoch:0 step:517 [D loss: 0.569044, acc.: 76.56%] [G loss: 0.077363]\n",
      "epoch:0 step:518 [D loss: 0.554901, acc.: 67.97%] [G loss: 0.087342]\n",
      "epoch:0 step:519 [D loss: 0.548130, acc.: 75.78%] [G loss: 0.099665]\n",
      "epoch:0 step:520 [D loss: 0.526844, acc.: 83.59%] [G loss: 0.134783]\n",
      "epoch:0 step:521 [D loss: 0.583010, acc.: 76.56%] [G loss: 0.092777]\n",
      "epoch:0 step:522 [D loss: 0.534092, acc.: 80.47%] [G loss: 0.106585]\n",
      "epoch:0 step:523 [D loss: 0.514868, acc.: 82.81%] [G loss: 0.151565]\n",
      "epoch:0 step:524 [D loss: 0.603045, acc.: 74.22%] [G loss: 0.101208]\n",
      "epoch:0 step:525 [D loss: 0.571072, acc.: 73.44%] [G loss: 0.083826]\n",
      "epoch:0 step:526 [D loss: 0.525793, acc.: 83.59%] [G loss: 0.112500]\n",
      "epoch:0 step:527 [D loss: 0.543301, acc.: 78.91%] [G loss: 0.126175]\n",
      "epoch:0 step:528 [D loss: 0.523981, acc.: 85.16%] [G loss: 0.131432]\n",
      "epoch:0 step:529 [D loss: 0.549752, acc.: 81.25%] [G loss: 0.162154]\n",
      "epoch:0 step:530 [D loss: 0.508581, acc.: 85.16%] [G loss: 0.180776]\n",
      "epoch:0 step:531 [D loss: 0.535551, acc.: 84.38%] [G loss: 0.139787]\n",
      "epoch:0 step:532 [D loss: 0.499979, acc.: 82.81%] [G loss: 0.152061]\n",
      "epoch:0 step:533 [D loss: 0.492695, acc.: 86.72%] [G loss: 0.215733]\n",
      "epoch:0 step:534 [D loss: 0.509139, acc.: 86.72%] [G loss: 0.218631]\n",
      "epoch:0 step:535 [D loss: 0.592695, acc.: 72.66%] [G loss: 0.132180]\n",
      "epoch:0 step:536 [D loss: 0.564096, acc.: 71.88%] [G loss: 0.115422]\n",
      "epoch:0 step:537 [D loss: 0.530284, acc.: 75.00%] [G loss: 0.154712]\n",
      "epoch:0 step:538 [D loss: 0.531746, acc.: 79.69%] [G loss: 0.149963]\n",
      "epoch:0 step:539 [D loss: 0.579633, acc.: 74.22%] [G loss: 0.108760]\n",
      "epoch:0 step:540 [D loss: 0.551549, acc.: 82.03%] [G loss: 0.117019]\n",
      "epoch:0 step:541 [D loss: 0.521817, acc.: 82.81%] [G loss: 0.138514]\n",
      "epoch:0 step:542 [D loss: 0.550069, acc.: 81.25%] [G loss: 0.132527]\n",
      "epoch:0 step:543 [D loss: 0.551379, acc.: 75.78%] [G loss: 0.137708]\n",
      "epoch:0 step:544 [D loss: 0.509969, acc.: 82.03%] [G loss: 0.172996]\n",
      "epoch:0 step:545 [D loss: 0.494554, acc.: 85.94%] [G loss: 0.178435]\n",
      "epoch:0 step:546 [D loss: 0.477551, acc.: 89.84%] [G loss: 0.228387]\n",
      "epoch:0 step:547 [D loss: 0.495810, acc.: 83.59%] [G loss: 0.212772]\n",
      "epoch:0 step:548 [D loss: 0.538013, acc.: 78.12%] [G loss: 0.211861]\n",
      "epoch:0 step:549 [D loss: 0.541245, acc.: 79.69%] [G loss: 0.155011]\n",
      "epoch:0 step:550 [D loss: 0.521709, acc.: 77.34%] [G loss: 0.164863]\n",
      "epoch:0 step:551 [D loss: 0.476485, acc.: 89.06%] [G loss: 0.226414]\n",
      "epoch:0 step:552 [D loss: 0.512010, acc.: 82.03%] [G loss: 0.231011]\n",
      "epoch:0 step:553 [D loss: 0.548436, acc.: 75.00%] [G loss: 0.205511]\n",
      "epoch:0 step:554 [D loss: 0.512876, acc.: 84.38%] [G loss: 0.195961]\n",
      "epoch:0 step:555 [D loss: 0.546984, acc.: 77.34%] [G loss: 0.186499]\n",
      "epoch:0 step:556 [D loss: 0.511450, acc.: 78.12%] [G loss: 0.173843]\n",
      "epoch:0 step:557 [D loss: 0.485741, acc.: 84.38%] [G loss: 0.202339]\n",
      "epoch:0 step:558 [D loss: 0.515449, acc.: 79.69%] [G loss: 0.211651]\n",
      "epoch:0 step:559 [D loss: 0.588625, acc.: 70.31%] [G loss: 0.130247]\n",
      "epoch:0 step:560 [D loss: 0.544552, acc.: 75.78%] [G loss: 0.139366]\n",
      "epoch:0 step:561 [D loss: 0.563854, acc.: 78.12%] [G loss: 0.139526]\n",
      "epoch:0 step:562 [D loss: 0.591587, acc.: 71.09%] [G loss: 0.121893]\n",
      "epoch:0 step:563 [D loss: 0.538374, acc.: 80.47%] [G loss: 0.125757]\n",
      "epoch:0 step:564 [D loss: 0.521146, acc.: 82.03%] [G loss: 0.142492]\n",
      "epoch:0 step:565 [D loss: 0.521370, acc.: 76.56%] [G loss: 0.177378]\n",
      "epoch:0 step:566 [D loss: 0.556855, acc.: 76.56%] [G loss: 0.152018]\n",
      "epoch:0 step:567 [D loss: 0.516353, acc.: 74.22%] [G loss: 0.233780]\n",
      "epoch:0 step:568 [D loss: 0.522673, acc.: 79.69%] [G loss: 0.237597]\n",
      "epoch:0 step:569 [D loss: 0.536523, acc.: 80.47%] [G loss: 0.180271]\n",
      "epoch:0 step:570 [D loss: 0.542122, acc.: 76.56%] [G loss: 0.155600]\n",
      "epoch:0 step:571 [D loss: 0.502800, acc.: 83.59%] [G loss: 0.175065]\n",
      "epoch:0 step:572 [D loss: 0.551139, acc.: 75.78%] [G loss: 0.174716]\n",
      "epoch:0 step:573 [D loss: 0.534013, acc.: 76.56%] [G loss: 0.183013]\n",
      "epoch:0 step:574 [D loss: 0.538929, acc.: 78.91%] [G loss: 0.207314]\n",
      "epoch:0 step:575 [D loss: 0.506383, acc.: 82.81%] [G loss: 0.272104]\n",
      "epoch:0 step:576 [D loss: 0.510979, acc.: 82.81%] [G loss: 0.211809]\n",
      "epoch:0 step:577 [D loss: 0.584694, acc.: 70.31%] [G loss: 0.159280]\n",
      "epoch:0 step:578 [D loss: 0.523737, acc.: 75.78%] [G loss: 0.173076]\n",
      "epoch:0 step:579 [D loss: 0.530585, acc.: 76.56%] [G loss: 0.206685]\n",
      "epoch:0 step:580 [D loss: 0.511572, acc.: 82.03%] [G loss: 0.190936]\n",
      "epoch:0 step:581 [D loss: 0.495729, acc.: 79.69%] [G loss: 0.242864]\n",
      "epoch:0 step:582 [D loss: 0.457192, acc.: 86.72%] [G loss: 0.321979]\n",
      "epoch:0 step:583 [D loss: 0.564714, acc.: 69.53%] [G loss: 0.237773]\n",
      "epoch:0 step:584 [D loss: 0.562572, acc.: 71.09%] [G loss: 0.189107]\n",
      "epoch:0 step:585 [D loss: 0.570779, acc.: 70.31%] [G loss: 0.193110]\n",
      "epoch:0 step:586 [D loss: 0.556071, acc.: 73.44%] [G loss: 0.178220]\n",
      "epoch:0 step:587 [D loss: 0.646613, acc.: 60.16%] [G loss: 0.122113]\n",
      "epoch:0 step:588 [D loss: 0.626671, acc.: 58.59%] [G loss: 0.127803]\n",
      "epoch:0 step:589 [D loss: 0.537843, acc.: 75.78%] [G loss: 0.196202]\n",
      "epoch:0 step:590 [D loss: 0.560640, acc.: 77.34%] [G loss: 0.206014]\n",
      "epoch:0 step:591 [D loss: 0.641184, acc.: 64.84%] [G loss: 0.107607]\n",
      "epoch:0 step:592 [D loss: 0.584724, acc.: 67.19%] [G loss: 0.091860]\n",
      "epoch:0 step:593 [D loss: 0.517487, acc.: 76.56%] [G loss: 0.117589]\n",
      "epoch:0 step:594 [D loss: 0.490557, acc.: 86.72%] [G loss: 0.198920]\n",
      "epoch:0 step:595 [D loss: 0.563551, acc.: 66.41%] [G loss: 0.176731]\n",
      "epoch:0 step:596 [D loss: 0.555696, acc.: 71.88%] [G loss: 0.193140]\n",
      "epoch:0 step:597 [D loss: 0.586501, acc.: 69.53%] [G loss: 0.177107]\n",
      "epoch:0 step:598 [D loss: 0.586086, acc.: 72.66%] [G loss: 0.147180]\n",
      "epoch:0 step:599 [D loss: 0.541955, acc.: 75.00%] [G loss: 0.151090]\n",
      "epoch:0 step:600 [D loss: 0.563089, acc.: 69.53%] [G loss: 0.109161]\n",
      "##############\n",
      "[ 5.65846305  6.59974359 10.11992505  8.76047088  7.77309047  9.15082749\n",
      "  8.80489199  8.74288557  8.67531666  7.27531163]\n",
      "##########\n",
      "epoch:0 step:601 [D loss: 0.551959, acc.: 75.00%] [G loss: 0.160029]\n",
      "epoch:0 step:602 [D loss: 0.504207, acc.: 88.28%] [G loss: 0.226791]\n",
      "epoch:0 step:603 [D loss: 0.555059, acc.: 73.44%] [G loss: 0.217638]\n",
      "epoch:0 step:604 [D loss: 0.587382, acc.: 71.88%] [G loss: 0.181333]\n",
      "epoch:0 step:605 [D loss: 0.543660, acc.: 78.12%] [G loss: 0.190429]\n",
      "epoch:0 step:606 [D loss: 0.557742, acc.: 78.12%] [G loss: 0.178535]\n",
      "epoch:0 step:607 [D loss: 0.571607, acc.: 75.78%] [G loss: 0.146923]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0 step:608 [D loss: 0.560683, acc.: 78.12%] [G loss: 0.155945]\n",
      "epoch:0 step:609 [D loss: 0.553784, acc.: 73.44%] [G loss: 0.181501]\n",
      "epoch:0 step:610 [D loss: 0.565884, acc.: 79.69%] [G loss: 0.180954]\n",
      "epoch:0 step:611 [D loss: 0.569566, acc.: 72.66%] [G loss: 0.169181]\n",
      "epoch:0 step:612 [D loss: 0.575769, acc.: 71.88%] [G loss: 0.169923]\n",
      "epoch:0 step:613 [D loss: 0.532651, acc.: 74.22%] [G loss: 0.175893]\n",
      "epoch:0 step:614 [D loss: 0.517136, acc.: 78.12%] [G loss: 0.235781]\n",
      "epoch:0 step:615 [D loss: 0.584381, acc.: 74.22%] [G loss: 0.164903]\n",
      "epoch:0 step:616 [D loss: 0.595608, acc.: 64.06%] [G loss: 0.165502]\n",
      "epoch:0 step:617 [D loss: 0.541557, acc.: 81.25%] [G loss: 0.184159]\n",
      "epoch:0 step:618 [D loss: 0.544462, acc.: 75.00%] [G loss: 0.187532]\n",
      "epoch:0 step:619 [D loss: 0.532491, acc.: 78.91%] [G loss: 0.231238]\n",
      "epoch:0 step:620 [D loss: 0.572191, acc.: 75.00%] [G loss: 0.172832]\n",
      "epoch:0 step:621 [D loss: 0.592476, acc.: 67.97%] [G loss: 0.151772]\n",
      "epoch:0 step:622 [D loss: 0.611499, acc.: 67.97%] [G loss: 0.117685]\n",
      "epoch:0 step:623 [D loss: 0.556615, acc.: 77.34%] [G loss: 0.143360]\n",
      "epoch:0 step:624 [D loss: 0.558599, acc.: 72.66%] [G loss: 0.166386]\n",
      "epoch:0 step:625 [D loss: 0.567476, acc.: 72.66%] [G loss: 0.171461]\n",
      "epoch:0 step:626 [D loss: 0.563012, acc.: 73.44%] [G loss: 0.197820]\n",
      "epoch:0 step:627 [D loss: 0.538299, acc.: 78.91%] [G loss: 0.205959]\n",
      "epoch:0 step:628 [D loss: 0.548307, acc.: 75.00%] [G loss: 0.214912]\n",
      "epoch:0 step:629 [D loss: 0.556980, acc.: 80.47%] [G loss: 0.178569]\n",
      "epoch:0 step:630 [D loss: 0.552884, acc.: 75.78%] [G loss: 0.165722]\n",
      "epoch:0 step:631 [D loss: 0.574219, acc.: 69.53%] [G loss: 0.148388]\n",
      "epoch:0 step:632 [D loss: 0.576041, acc.: 71.88%] [G loss: 0.181882]\n",
      "epoch:0 step:633 [D loss: 0.552989, acc.: 72.66%] [G loss: 0.222454]\n",
      "epoch:0 step:634 [D loss: 0.519728, acc.: 84.38%] [G loss: 0.198035]\n",
      "epoch:0 step:635 [D loss: 0.540865, acc.: 80.47%] [G loss: 0.192047]\n",
      "epoch:0 step:636 [D loss: 0.598844, acc.: 71.09%] [G loss: 0.153230]\n",
      "epoch:0 step:637 [D loss: 0.587188, acc.: 62.50%] [G loss: 0.235707]\n",
      "epoch:0 step:638 [D loss: 0.537321, acc.: 81.25%] [G loss: 0.248629]\n",
      "epoch:0 step:639 [D loss: 0.604689, acc.: 69.53%] [G loss: 0.141227]\n",
      "epoch:0 step:640 [D loss: 0.547288, acc.: 75.78%] [G loss: 0.178568]\n",
      "epoch:0 step:641 [D loss: 0.579443, acc.: 71.88%] [G loss: 0.177327]\n",
      "epoch:0 step:642 [D loss: 0.537067, acc.: 78.91%] [G loss: 0.155030]\n",
      "epoch:0 step:643 [D loss: 0.564109, acc.: 74.22%] [G loss: 0.156185]\n",
      "epoch:0 step:644 [D loss: 0.527648, acc.: 80.47%] [G loss: 0.185607]\n",
      "epoch:0 step:645 [D loss: 0.526680, acc.: 84.38%] [G loss: 0.177463]\n",
      "epoch:0 step:646 [D loss: 0.543715, acc.: 80.47%] [G loss: 0.216139]\n",
      "epoch:0 step:647 [D loss: 0.520353, acc.: 83.59%] [G loss: 0.208601]\n",
      "epoch:0 step:648 [D loss: 0.500505, acc.: 84.38%] [G loss: 0.236800]\n",
      "epoch:0 step:649 [D loss: 0.500766, acc.: 80.47%] [G loss: 0.291602]\n",
      "epoch:0 step:650 [D loss: 0.534276, acc.: 76.56%] [G loss: 0.263790]\n",
      "epoch:0 step:651 [D loss: 0.534490, acc.: 80.47%] [G loss: 0.184643]\n",
      "epoch:0 step:652 [D loss: 0.546043, acc.: 82.81%] [G loss: 0.169215]\n",
      "epoch:0 step:653 [D loss: 0.524698, acc.: 73.44%] [G loss: 0.212290]\n",
      "epoch:0 step:654 [D loss: 0.502277, acc.: 82.03%] [G loss: 0.247942]\n",
      "epoch:0 step:655 [D loss: 0.550247, acc.: 76.56%] [G loss: 0.215721]\n",
      "epoch:0 step:656 [D loss: 0.553693, acc.: 75.78%] [G loss: 0.199503]\n",
      "epoch:0 step:657 [D loss: 0.524943, acc.: 82.03%] [G loss: 0.233780]\n",
      "epoch:0 step:658 [D loss: 0.554503, acc.: 80.47%] [G loss: 0.176327]\n",
      "epoch:0 step:659 [D loss: 0.492009, acc.: 82.03%] [G loss: 0.173242]\n",
      "epoch:0 step:660 [D loss: 0.498976, acc.: 84.38%] [G loss: 0.208149]\n",
      "epoch:0 step:661 [D loss: 0.518483, acc.: 78.91%] [G loss: 0.260670]\n",
      "epoch:0 step:662 [D loss: 0.593446, acc.: 73.44%] [G loss: 0.180757]\n",
      "epoch:0 step:663 [D loss: 0.597739, acc.: 69.53%] [G loss: 0.118617]\n",
      "epoch:0 step:664 [D loss: 0.566644, acc.: 75.00%] [G loss: 0.132481]\n",
      "epoch:0 step:665 [D loss: 0.525822, acc.: 81.25%] [G loss: 0.137913]\n",
      "epoch:0 step:666 [D loss: 0.495597, acc.: 89.84%] [G loss: 0.173300]\n",
      "epoch:0 step:667 [D loss: 0.502795, acc.: 91.41%] [G loss: 0.216358]\n",
      "epoch:0 step:668 [D loss: 0.511130, acc.: 84.38%] [G loss: 0.206185]\n",
      "epoch:0 step:669 [D loss: 0.498666, acc.: 89.06%] [G loss: 0.200875]\n",
      "epoch:0 step:670 [D loss: 0.535289, acc.: 80.47%] [G loss: 0.161316]\n",
      "epoch:0 step:671 [D loss: 0.548681, acc.: 81.25%] [G loss: 0.144752]\n",
      "epoch:0 step:672 [D loss: 0.569654, acc.: 75.00%] [G loss: 0.162791]\n",
      "epoch:0 step:673 [D loss: 0.515908, acc.: 76.56%] [G loss: 0.243970]\n",
      "epoch:0 step:674 [D loss: 0.525803, acc.: 81.25%] [G loss: 0.255073]\n",
      "epoch:0 step:675 [D loss: 0.572584, acc.: 74.22%] [G loss: 0.200615]\n",
      "epoch:0 step:676 [D loss: 0.536431, acc.: 82.03%] [G loss: 0.199226]\n",
      "epoch:0 step:677 [D loss: 0.494404, acc.: 85.94%] [G loss: 0.204570]\n",
      "epoch:0 step:678 [D loss: 0.516253, acc.: 79.69%] [G loss: 0.208494]\n",
      "epoch:0 step:679 [D loss: 0.538898, acc.: 80.47%] [G loss: 0.189744]\n",
      "epoch:0 step:680 [D loss: 0.530386, acc.: 77.34%] [G loss: 0.193163]\n",
      "epoch:0 step:681 [D loss: 0.539895, acc.: 74.22%] [G loss: 0.177944]\n",
      "epoch:0 step:682 [D loss: 0.499338, acc.: 83.59%] [G loss: 0.189269]\n",
      "epoch:0 step:683 [D loss: 0.508482, acc.: 83.59%] [G loss: 0.196159]\n",
      "epoch:0 step:684 [D loss: 0.538218, acc.: 76.56%] [G loss: 0.210796]\n",
      "epoch:0 step:685 [D loss: 0.527461, acc.: 78.91%] [G loss: 0.241462]\n",
      "epoch:0 step:686 [D loss: 0.492934, acc.: 85.94%] [G loss: 0.243576]\n",
      "epoch:0 step:687 [D loss: 0.539976, acc.: 75.78%] [G loss: 0.232720]\n",
      "epoch:0 step:688 [D loss: 0.518556, acc.: 80.47%] [G loss: 0.219946]\n",
      "epoch:0 step:689 [D loss: 0.559078, acc.: 73.44%] [G loss: 0.183829]\n",
      "epoch:0 step:690 [D loss: 0.559569, acc.: 68.75%] [G loss: 0.194721]\n",
      "epoch:0 step:691 [D loss: 0.568934, acc.: 72.66%] [G loss: 0.206912]\n",
      "epoch:0 step:692 [D loss: 0.528062, acc.: 77.34%] [G loss: 0.245763]\n",
      "epoch:0 step:693 [D loss: 0.494542, acc.: 81.25%] [G loss: 0.278468]\n",
      "epoch:0 step:694 [D loss: 0.476724, acc.: 89.84%] [G loss: 0.247259]\n",
      "epoch:0 step:695 [D loss: 0.498184, acc.: 78.91%] [G loss: 0.271303]\n",
      "epoch:0 step:696 [D loss: 0.523842, acc.: 82.81%] [G loss: 0.248894]\n",
      "epoch:0 step:697 [D loss: 0.546753, acc.: 79.69%] [G loss: 0.218911]\n",
      "epoch:0 step:698 [D loss: 0.485769, acc.: 88.28%] [G loss: 0.240654]\n",
      "epoch:0 step:699 [D loss: 0.527216, acc.: 85.94%] [G loss: 0.190254]\n",
      "epoch:0 step:700 [D loss: 0.545112, acc.: 71.88%] [G loss: 0.189556]\n",
      "epoch:0 step:701 [D loss: 0.515379, acc.: 85.94%] [G loss: 0.221969]\n",
      "epoch:0 step:702 [D loss: 0.515159, acc.: 85.94%] [G loss: 0.195467]\n",
      "epoch:0 step:703 [D loss: 0.544840, acc.: 80.47%] [G loss: 0.170896]\n",
      "epoch:0 step:704 [D loss: 0.506349, acc.: 82.81%] [G loss: 0.208207]\n",
      "epoch:0 step:705 [D loss: 0.522798, acc.: 85.16%] [G loss: 0.267160]\n",
      "epoch:0 step:706 [D loss: 0.527541, acc.: 83.59%] [G loss: 0.227201]\n",
      "epoch:0 step:707 [D loss: 0.470288, acc.: 89.84%] [G loss: 0.260095]\n",
      "epoch:0 step:708 [D loss: 0.474767, acc.: 89.84%] [G loss: 0.300236]\n",
      "epoch:0 step:709 [D loss: 0.440518, acc.: 89.06%] [G loss: 0.393892]\n",
      "epoch:0 step:710 [D loss: 0.649327, acc.: 64.06%] [G loss: 0.152983]\n",
      "epoch:0 step:711 [D loss: 0.603109, acc.: 68.75%] [G loss: 0.148718]\n",
      "epoch:0 step:712 [D loss: 0.512425, acc.: 78.91%] [G loss: 0.267309]\n",
      "epoch:0 step:713 [D loss: 0.494051, acc.: 79.69%] [G loss: 0.404748]\n",
      "epoch:0 step:714 [D loss: 0.523526, acc.: 82.81%] [G loss: 0.306093]\n",
      "epoch:0 step:715 [D loss: 0.556068, acc.: 74.22%] [G loss: 0.236212]\n",
      "epoch:0 step:716 [D loss: 0.618198, acc.: 62.50%] [G loss: 0.165367]\n",
      "epoch:0 step:717 [D loss: 0.515290, acc.: 80.47%] [G loss: 0.249503]\n",
      "epoch:0 step:718 [D loss: 0.521408, acc.: 81.25%] [G loss: 0.283810]\n",
      "epoch:0 step:719 [D loss: 0.605117, acc.: 70.31%] [G loss: 0.270870]\n",
      "epoch:0 step:720 [D loss: 0.615720, acc.: 67.19%] [G loss: 0.230540]\n",
      "epoch:0 step:721 [D loss: 0.577449, acc.: 76.56%] [G loss: 0.247867]\n",
      "epoch:0 step:722 [D loss: 0.563252, acc.: 71.88%] [G loss: 0.227477]\n",
      "epoch:0 step:723 [D loss: 0.660924, acc.: 57.81%] [G loss: 0.178565]\n",
      "epoch:0 step:724 [D loss: 0.526115, acc.: 82.03%] [G loss: 0.314372]\n",
      "epoch:0 step:725 [D loss: 0.600498, acc.: 73.44%] [G loss: 0.232128]\n",
      "epoch:0 step:726 [D loss: 0.598164, acc.: 68.75%] [G loss: 0.228037]\n",
      "epoch:0 step:727 [D loss: 0.597816, acc.: 61.72%] [G loss: 0.209011]\n",
      "epoch:0 step:728 [D loss: 0.617065, acc.: 68.75%] [G loss: 0.170598]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0 step:729 [D loss: 0.553652, acc.: 75.78%] [G loss: 0.210095]\n",
      "epoch:0 step:730 [D loss: 0.618446, acc.: 70.31%] [G loss: 0.187242]\n",
      "epoch:0 step:731 [D loss: 0.570858, acc.: 71.09%] [G loss: 0.219197]\n",
      "epoch:0 step:732 [D loss: 0.589058, acc.: 74.22%] [G loss: 0.190816]\n",
      "epoch:0 step:733 [D loss: 0.543955, acc.: 72.66%] [G loss: 0.220844]\n",
      "epoch:0 step:734 [D loss: 0.569099, acc.: 69.53%] [G loss: 0.242293]\n",
      "epoch:0 step:735 [D loss: 0.575723, acc.: 71.88%] [G loss: 0.213020]\n",
      "epoch:0 step:736 [D loss: 0.559681, acc.: 72.66%] [G loss: 0.212228]\n",
      "epoch:0 step:737 [D loss: 0.611392, acc.: 66.41%] [G loss: 0.178613]\n",
      "epoch:0 step:738 [D loss: 0.575532, acc.: 67.97%] [G loss: 0.217664]\n",
      "epoch:0 step:739 [D loss: 0.620380, acc.: 61.72%] [G loss: 0.160599]\n",
      "epoch:0 step:740 [D loss: 0.596371, acc.: 65.62%] [G loss: 0.131349]\n",
      "epoch:0 step:741 [D loss: 0.530233, acc.: 78.91%] [G loss: 0.219906]\n",
      "epoch:0 step:742 [D loss: 0.569651, acc.: 75.00%] [G loss: 0.245304]\n",
      "epoch:0 step:743 [D loss: 0.555610, acc.: 75.00%] [G loss: 0.240634]\n",
      "epoch:0 step:744 [D loss: 0.595749, acc.: 75.00%] [G loss: 0.163997]\n",
      "epoch:0 step:745 [D loss: 0.533513, acc.: 82.03%] [G loss: 0.213511]\n",
      "epoch:0 step:746 [D loss: 0.584669, acc.: 71.88%] [G loss: 0.186850]\n",
      "epoch:0 step:747 [D loss: 0.552796, acc.: 75.78%] [G loss: 0.177458]\n",
      "epoch:0 step:748 [D loss: 0.570061, acc.: 70.31%] [G loss: 0.178374]\n",
      "epoch:0 step:749 [D loss: 0.531199, acc.: 77.34%] [G loss: 0.220154]\n",
      "epoch:0 step:750 [D loss: 0.524266, acc.: 83.59%] [G loss: 0.243425]\n",
      "epoch:0 step:751 [D loss: 0.574878, acc.: 71.09%] [G loss: 0.218789]\n",
      "epoch:0 step:752 [D loss: 0.545165, acc.: 78.91%] [G loss: 0.210945]\n",
      "epoch:0 step:753 [D loss: 0.514857, acc.: 78.91%] [G loss: 0.230251]\n",
      "epoch:0 step:754 [D loss: 0.554194, acc.: 76.56%] [G loss: 0.226573]\n",
      "epoch:0 step:755 [D loss: 0.540837, acc.: 76.56%] [G loss: 0.232521]\n",
      "epoch:0 step:756 [D loss: 0.574005, acc.: 70.31%] [G loss: 0.234218]\n",
      "epoch:0 step:757 [D loss: 0.581115, acc.: 72.66%] [G loss: 0.184942]\n",
      "epoch:0 step:758 [D loss: 0.548278, acc.: 75.78%] [G loss: 0.215674]\n",
      "epoch:0 step:759 [D loss: 0.543613, acc.: 80.47%] [G loss: 0.171644]\n",
      "epoch:0 step:760 [D loss: 0.564317, acc.: 75.78%] [G loss: 0.167916]\n",
      "epoch:0 step:761 [D loss: 0.529570, acc.: 79.69%] [G loss: 0.201621]\n",
      "epoch:0 step:762 [D loss: 0.551668, acc.: 76.56%] [G loss: 0.219816]\n",
      "epoch:0 step:763 [D loss: 0.516506, acc.: 81.25%] [G loss: 0.243193]\n",
      "epoch:0 step:764 [D loss: 0.544764, acc.: 79.69%] [G loss: 0.245740]\n",
      "epoch:0 step:765 [D loss: 0.635336, acc.: 67.19%] [G loss: 0.130994]\n",
      "epoch:0 step:766 [D loss: 0.568769, acc.: 74.22%] [G loss: 0.129102]\n",
      "epoch:0 step:767 [D loss: 0.527745, acc.: 78.91%] [G loss: 0.169615]\n",
      "epoch:0 step:768 [D loss: 0.569091, acc.: 74.22%] [G loss: 0.196584]\n",
      "epoch:0 step:769 [D loss: 0.543343, acc.: 75.78%] [G loss: 0.260938]\n",
      "epoch:0 step:770 [D loss: 0.541780, acc.: 76.56%] [G loss: 0.222962]\n",
      "epoch:0 step:771 [D loss: 0.498792, acc.: 85.16%] [G loss: 0.236705]\n",
      "epoch:0 step:772 [D loss: 0.516337, acc.: 77.34%] [G loss: 0.264526]\n",
      "epoch:0 step:773 [D loss: 0.535946, acc.: 84.38%] [G loss: 0.245155]\n",
      "epoch:0 step:774 [D loss: 0.582849, acc.: 72.66%] [G loss: 0.167694]\n",
      "epoch:0 step:775 [D loss: 0.526834, acc.: 79.69%] [G loss: 0.203285]\n",
      "epoch:0 step:776 [D loss: 0.531659, acc.: 81.25%] [G loss: 0.212854]\n",
      "epoch:0 step:777 [D loss: 0.531797, acc.: 78.91%] [G loss: 0.213257]\n",
      "epoch:0 step:778 [D loss: 0.566839, acc.: 72.66%] [G loss: 0.203322]\n",
      "epoch:0 step:779 [D loss: 0.538229, acc.: 76.56%] [G loss: 0.289681]\n",
      "epoch:0 step:780 [D loss: 0.520363, acc.: 85.94%] [G loss: 0.261713]\n",
      "epoch:0 step:781 [D loss: 0.547986, acc.: 75.78%] [G loss: 0.255209]\n",
      "epoch:0 step:782 [D loss: 0.494891, acc.: 83.59%] [G loss: 0.313792]\n",
      "epoch:0 step:783 [D loss: 0.537434, acc.: 79.69%] [G loss: 0.231641]\n",
      "epoch:0 step:784 [D loss: 0.529735, acc.: 75.00%] [G loss: 0.180320]\n",
      "epoch:0 step:785 [D loss: 0.496843, acc.: 85.94%] [G loss: 0.219920]\n",
      "epoch:0 step:786 [D loss: 0.521259, acc.: 80.47%] [G loss: 0.271207]\n",
      "epoch:0 step:787 [D loss: 0.509014, acc.: 85.94%] [G loss: 0.322011]\n",
      "epoch:0 step:788 [D loss: 0.587539, acc.: 71.88%] [G loss: 0.184417]\n",
      "epoch:0 step:789 [D loss: 0.475672, acc.: 83.59%] [G loss: 0.212484]\n",
      "epoch:0 step:790 [D loss: 0.495424, acc.: 87.50%] [G loss: 0.247697]\n",
      "epoch:0 step:791 [D loss: 0.547104, acc.: 75.00%] [G loss: 0.241248]\n",
      "epoch:0 step:792 [D loss: 0.499312, acc.: 84.38%] [G loss: 0.274866]\n",
      "epoch:0 step:793 [D loss: 0.517103, acc.: 81.25%] [G loss: 0.298469]\n",
      "epoch:0 step:794 [D loss: 0.543248, acc.: 75.78%] [G loss: 0.301844]\n",
      "epoch:0 step:795 [D loss: 0.488015, acc.: 83.59%] [G loss: 0.333785]\n",
      "epoch:0 step:796 [D loss: 0.462461, acc.: 86.72%] [G loss: 0.337867]\n",
      "epoch:0 step:797 [D loss: 0.524210, acc.: 75.78%] [G loss: 0.302333]\n",
      "epoch:0 step:798 [D loss: 0.571075, acc.: 67.97%] [G loss: 0.259820]\n",
      "epoch:0 step:799 [D loss: 0.539334, acc.: 75.78%] [G loss: 0.283629]\n",
      "epoch:0 step:800 [D loss: 0.690155, acc.: 59.38%] [G loss: 0.183871]\n",
      "##############\n",
      "[ 5.1637397   7.59974359 10.45161499  7.7387851   7.55618385  8.67783491\n",
      "  8.48761813  8.47541386  8.26785272  7.01019052]\n",
      "##########\n",
      "epoch:0 step:801 [D loss: 0.532052, acc.: 75.78%] [G loss: 0.228276]\n",
      "epoch:0 step:802 [D loss: 0.516499, acc.: 72.66%] [G loss: 0.281954]\n",
      "epoch:0 step:803 [D loss: 0.513100, acc.: 79.69%] [G loss: 0.332626]\n",
      "epoch:0 step:804 [D loss: 0.590261, acc.: 72.66%] [G loss: 0.177337]\n",
      "epoch:0 step:805 [D loss: 0.601997, acc.: 70.31%] [G loss: 0.175939]\n",
      "epoch:0 step:806 [D loss: 0.490732, acc.: 80.47%] [G loss: 0.280640]\n",
      "epoch:0 step:807 [D loss: 0.533094, acc.: 81.25%] [G loss: 0.287671]\n",
      "epoch:0 step:808 [D loss: 0.548413, acc.: 81.25%] [G loss: 0.240827]\n",
      "epoch:0 step:809 [D loss: 0.564450, acc.: 75.00%] [G loss: 0.209222]\n",
      "epoch:0 step:810 [D loss: 0.508337, acc.: 87.50%] [G loss: 0.232894]\n",
      "epoch:0 step:811 [D loss: 0.539859, acc.: 81.25%] [G loss: 0.250753]\n",
      "epoch:0 step:812 [D loss: 0.527319, acc.: 85.16%] [G loss: 0.223710]\n",
      "epoch:0 step:813 [D loss: 0.524245, acc.: 80.47%] [G loss: 0.232895]\n",
      "epoch:0 step:814 [D loss: 0.528572, acc.: 79.69%] [G loss: 0.273331]\n",
      "epoch:0 step:815 [D loss: 0.589192, acc.: 75.78%] [G loss: 0.235200]\n",
      "epoch:0 step:816 [D loss: 0.498341, acc.: 84.38%] [G loss: 0.296471]\n",
      "epoch:0 step:817 [D loss: 0.469924, acc.: 88.28%] [G loss: 0.304565]\n",
      "epoch:0 step:818 [D loss: 0.545514, acc.: 75.00%] [G loss: 0.307907]\n",
      "epoch:0 step:819 [D loss: 0.525455, acc.: 81.25%] [G loss: 0.248370]\n",
      "epoch:0 step:820 [D loss: 0.534066, acc.: 76.56%] [G loss: 0.256806]\n",
      "epoch:0 step:821 [D loss: 0.524397, acc.: 82.03%] [G loss: 0.238877]\n",
      "epoch:0 step:822 [D loss: 0.484247, acc.: 85.94%] [G loss: 0.309200]\n",
      "epoch:0 step:823 [D loss: 0.504668, acc.: 82.03%] [G loss: 0.282704]\n",
      "epoch:0 step:824 [D loss: 0.492906, acc.: 91.41%] [G loss: 0.293749]\n",
      "epoch:0 step:825 [D loss: 0.507652, acc.: 80.47%] [G loss: 0.316154]\n",
      "epoch:0 step:826 [D loss: 0.490163, acc.: 84.38%] [G loss: 0.288274]\n",
      "epoch:0 step:827 [D loss: 0.519395, acc.: 79.69%] [G loss: 0.266894]\n",
      "epoch:0 step:828 [D loss: 0.532070, acc.: 75.00%] [G loss: 0.286660]\n",
      "epoch:0 step:829 [D loss: 0.487726, acc.: 84.38%] [G loss: 0.384978]\n",
      "epoch:0 step:830 [D loss: 0.516303, acc.: 88.28%] [G loss: 0.270158]\n",
      "epoch:0 step:831 [D loss: 0.504360, acc.: 80.47%] [G loss: 0.233229]\n",
      "epoch:0 step:832 [D loss: 0.502671, acc.: 78.91%] [G loss: 0.286939]\n",
      "epoch:0 step:833 [D loss: 0.557575, acc.: 75.78%] [G loss: 0.251717]\n",
      "epoch:0 step:834 [D loss: 0.547011, acc.: 74.22%] [G loss: 0.221208]\n",
      "epoch:0 step:835 [D loss: 0.538591, acc.: 75.78%] [G loss: 0.213393]\n",
      "epoch:0 step:836 [D loss: 0.509668, acc.: 80.47%] [G loss: 0.234852]\n",
      "epoch:0 step:837 [D loss: 0.496206, acc.: 83.59%] [G loss: 0.300657]\n",
      "epoch:0 step:838 [D loss: 0.512137, acc.: 85.94%] [G loss: 0.212575]\n",
      "epoch:0 step:839 [D loss: 0.545407, acc.: 78.91%] [G loss: 0.191235]\n",
      "epoch:0 step:840 [D loss: 0.513288, acc.: 78.91%] [G loss: 0.239910]\n",
      "epoch:0 step:841 [D loss: 0.489575, acc.: 82.03%] [G loss: 0.340930]\n",
      "epoch:0 step:842 [D loss: 0.527162, acc.: 82.81%] [G loss: 0.308904]\n",
      "epoch:0 step:843 [D loss: 0.553046, acc.: 75.00%] [G loss: 0.219764]\n",
      "epoch:0 step:844 [D loss: 0.551086, acc.: 79.69%] [G loss: 0.243853]\n",
      "epoch:0 step:845 [D loss: 0.520999, acc.: 85.94%] [G loss: 0.231139]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0 step:846 [D loss: 0.521127, acc.: 84.38%] [G loss: 0.254913]\n",
      "epoch:0 step:847 [D loss: 0.496412, acc.: 85.94%] [G loss: 0.292536]\n",
      "epoch:0 step:848 [D loss: 0.494326, acc.: 85.94%] [G loss: 0.269958]\n",
      "epoch:0 step:849 [D loss: 0.538807, acc.: 77.34%] [G loss: 0.259317]\n",
      "epoch:0 step:850 [D loss: 0.478081, acc.: 85.94%] [G loss: 0.344032]\n",
      "epoch:0 step:851 [D loss: 0.460877, acc.: 88.28%] [G loss: 0.385486]\n",
      "epoch:0 step:852 [D loss: 0.498949, acc.: 82.81%] [G loss: 0.369021]\n",
      "epoch:0 step:853 [D loss: 0.467827, acc.: 87.50%] [G loss: 0.344342]\n",
      "epoch:0 step:854 [D loss: 0.474157, acc.: 84.38%] [G loss: 0.386513]\n",
      "epoch:0 step:855 [D loss: 0.463534, acc.: 87.50%] [G loss: 0.379529]\n",
      "epoch:0 step:856 [D loss: 0.548435, acc.: 79.69%] [G loss: 0.289846]\n",
      "epoch:0 step:857 [D loss: 0.500269, acc.: 82.03%] [G loss: 0.437654]\n",
      "epoch:0 step:858 [D loss: 0.743504, acc.: 52.34%] [G loss: 0.201010]\n",
      "epoch:0 step:859 [D loss: 0.561468, acc.: 72.66%] [G loss: 0.229413]\n",
      "epoch:0 step:860 [D loss: 0.499623, acc.: 82.03%] [G loss: 0.315212]\n",
      "epoch:0 step:861 [D loss: 0.542773, acc.: 75.78%] [G loss: 0.341981]\n",
      "epoch:0 step:862 [D loss: 0.493679, acc.: 87.50%] [G loss: 0.277015]\n",
      "epoch:0 step:863 [D loss: 0.483634, acc.: 87.50%] [G loss: 0.272216]\n",
      "epoch:0 step:864 [D loss: 0.494742, acc.: 83.59%] [G loss: 0.262406]\n",
      "epoch:0 step:865 [D loss: 0.513254, acc.: 82.81%] [G loss: 0.242963]\n",
      "epoch:0 step:866 [D loss: 0.466651, acc.: 88.28%] [G loss: 0.329316]\n",
      "epoch:0 step:867 [D loss: 0.518232, acc.: 78.91%] [G loss: 0.275427]\n",
      "epoch:0 step:868 [D loss: 0.517359, acc.: 79.69%] [G loss: 0.290515]\n",
      "epoch:0 step:869 [D loss: 0.480040, acc.: 85.16%] [G loss: 0.270502]\n",
      "epoch:0 step:870 [D loss: 0.514614, acc.: 79.69%] [G loss: 0.292367]\n",
      "epoch:0 step:871 [D loss: 0.436271, acc.: 89.84%] [G loss: 0.406080]\n",
      "epoch:0 step:872 [D loss: 0.472421, acc.: 85.16%] [G loss: 0.424922]\n",
      "epoch:0 step:873 [D loss: 0.479310, acc.: 88.28%] [G loss: 0.315962]\n",
      "epoch:0 step:874 [D loss: 0.528650, acc.: 76.56%] [G loss: 0.256132]\n",
      "epoch:0 step:875 [D loss: 0.473259, acc.: 85.16%] [G loss: 0.342051]\n",
      "epoch:0 step:876 [D loss: 0.499469, acc.: 79.69%] [G loss: 0.303844]\n",
      "epoch:0 step:877 [D loss: 0.469163, acc.: 89.06%] [G loss: 0.347831]\n",
      "epoch:0 step:878 [D loss: 0.539824, acc.: 78.12%] [G loss: 0.321622]\n",
      "epoch:0 step:879 [D loss: 0.557376, acc.: 71.88%] [G loss: 0.321111]\n",
      "epoch:0 step:880 [D loss: 0.534214, acc.: 76.56%] [G loss: 0.286753]\n",
      "epoch:0 step:881 [D loss: 0.516617, acc.: 77.34%] [G loss: 0.284203]\n",
      "epoch:0 step:882 [D loss: 0.520701, acc.: 76.56%] [G loss: 0.263613]\n",
      "epoch:0 step:883 [D loss: 0.516960, acc.: 82.03%] [G loss: 0.312100]\n",
      "epoch:0 step:884 [D loss: 0.542539, acc.: 76.56%] [G loss: 0.309964]\n",
      "epoch:0 step:885 [D loss: 0.495960, acc.: 82.81%] [G loss: 0.307409]\n",
      "epoch:0 step:886 [D loss: 0.498815, acc.: 81.25%] [G loss: 0.384940]\n",
      "epoch:0 step:887 [D loss: 0.472449, acc.: 83.59%] [G loss: 0.387160]\n",
      "epoch:0 step:888 [D loss: 0.438676, acc.: 91.41%] [G loss: 0.431521]\n",
      "epoch:0 step:889 [D loss: 0.482947, acc.: 82.81%] [G loss: 0.393602]\n",
      "epoch:0 step:890 [D loss: 0.482284, acc.: 81.25%] [G loss: 0.348012]\n",
      "epoch:0 step:891 [D loss: 0.585129, acc.: 73.44%] [G loss: 0.250619]\n",
      "epoch:0 step:892 [D loss: 0.523025, acc.: 76.56%] [G loss: 0.239607]\n",
      "epoch:0 step:893 [D loss: 0.490755, acc.: 81.25%] [G loss: 0.384020]\n",
      "epoch:0 step:894 [D loss: 0.485644, acc.: 83.59%] [G loss: 0.446853]\n",
      "epoch:0 step:895 [D loss: 0.536808, acc.: 79.69%] [G loss: 0.349416]\n",
      "epoch:0 step:896 [D loss: 0.549883, acc.: 76.56%] [G loss: 0.249288]\n",
      "epoch:0 step:897 [D loss: 0.517386, acc.: 76.56%] [G loss: 0.262698]\n",
      "epoch:0 step:898 [D loss: 0.464908, acc.: 89.06%] [G loss: 0.360992]\n",
      "epoch:0 step:899 [D loss: 0.476238, acc.: 82.03%] [G loss: 0.426328]\n",
      "epoch:0 step:900 [D loss: 0.518145, acc.: 76.56%] [G loss: 0.350939]\n",
      "epoch:0 step:901 [D loss: 0.459325, acc.: 87.50%] [G loss: 0.374241]\n",
      "epoch:0 step:902 [D loss: 0.563035, acc.: 74.22%] [G loss: 0.325364]\n",
      "epoch:0 step:903 [D loss: 0.533184, acc.: 75.78%] [G loss: 0.282752]\n",
      "epoch:0 step:904 [D loss: 0.551360, acc.: 75.78%] [G loss: 0.318929]\n",
      "epoch:0 step:905 [D loss: 0.533904, acc.: 78.12%] [G loss: 0.343141]\n",
      "epoch:0 step:906 [D loss: 0.489585, acc.: 82.81%] [G loss: 0.387637]\n",
      "epoch:0 step:907 [D loss: 0.574034, acc.: 70.31%] [G loss: 0.359351]\n",
      "epoch:0 step:908 [D loss: 0.527344, acc.: 76.56%] [G loss: 0.362544]\n",
      "epoch:0 step:909 [D loss: 0.520105, acc.: 77.34%] [G loss: 0.405599]\n",
      "epoch:0 step:910 [D loss: 0.440172, acc.: 89.06%] [G loss: 0.529063]\n",
      "epoch:0 step:911 [D loss: 0.601163, acc.: 70.31%] [G loss: 0.259318]\n",
      "epoch:0 step:912 [D loss: 0.577908, acc.: 65.62%] [G loss: 0.294772]\n",
      "epoch:0 step:913 [D loss: 0.542763, acc.: 78.91%] [G loss: 0.351640]\n",
      "epoch:0 step:914 [D loss: 0.517457, acc.: 78.12%] [G loss: 0.379197]\n",
      "epoch:0 step:915 [D loss: 0.592918, acc.: 71.09%] [G loss: 0.257972]\n",
      "epoch:0 step:916 [D loss: 0.559458, acc.: 71.88%] [G loss: 0.216859]\n",
      "epoch:0 step:917 [D loss: 0.571768, acc.: 71.88%] [G loss: 0.340342]\n",
      "epoch:0 step:918 [D loss: 0.452193, acc.: 89.06%] [G loss: 0.554034]\n",
      "epoch:0 step:919 [D loss: 0.552439, acc.: 71.09%] [G loss: 0.349838]\n",
      "epoch:0 step:920 [D loss: 0.647570, acc.: 55.47%] [G loss: 0.311969]\n",
      "epoch:0 step:921 [D loss: 0.516615, acc.: 74.22%] [G loss: 0.407190]\n",
      "epoch:0 step:922 [D loss: 0.661065, acc.: 57.03%] [G loss: 0.172225]\n",
      "epoch:0 step:923 [D loss: 0.508291, acc.: 81.25%] [G loss: 0.234748]\n",
      "epoch:0 step:924 [D loss: 0.493210, acc.: 83.59%] [G loss: 0.452034]\n",
      "epoch:0 step:925 [D loss: 0.486981, acc.: 82.81%] [G loss: 0.451126]\n",
      "epoch:0 step:926 [D loss: 0.503378, acc.: 78.12%] [G loss: 0.500128]\n",
      "epoch:0 step:927 [D loss: 0.497383, acc.: 81.25%] [G loss: 0.421940]\n",
      "epoch:0 step:928 [D loss: 0.711320, acc.: 64.06%] [G loss: 0.186967]\n",
      "epoch:0 step:929 [D loss: 0.448161, acc.: 81.25%] [G loss: 0.348425]\n",
      "epoch:0 step:930 [D loss: 0.444009, acc.: 87.50%] [G loss: 0.428564]\n",
      "epoch:0 step:931 [D loss: 0.580402, acc.: 71.88%] [G loss: 0.265497]\n",
      "epoch:0 step:932 [D loss: 0.530953, acc.: 85.16%] [G loss: 0.222368]\n",
      "epoch:0 step:933 [D loss: 0.513540, acc.: 82.81%] [G loss: 0.224359]\n",
      "epoch:0 step:934 [D loss: 0.503723, acc.: 79.69%] [G loss: 0.299531]\n",
      "epoch:0 step:935 [D loss: 0.430359, acc.: 90.62%] [G loss: 0.343926]\n",
      "epoch:0 step:936 [D loss: 0.397658, acc.: 91.41%] [G loss: 0.462649]\n",
      "epoch:0 step:937 [D loss: 0.542123, acc.: 77.34%] [G loss: 0.343823]\n",
      "epoch:1 step:938 [D loss: 0.556809, acc.: 67.97%] [G loss: 0.302744]\n",
      "epoch:1 step:939 [D loss: 0.547620, acc.: 70.31%] [G loss: 0.283658]\n",
      "epoch:1 step:940 [D loss: 0.546591, acc.: 75.78%] [G loss: 0.315754]\n",
      "epoch:1 step:941 [D loss: 0.514181, acc.: 79.69%] [G loss: 0.286009]\n",
      "epoch:1 step:942 [D loss: 0.503616, acc.: 82.03%] [G loss: 0.254295]\n",
      "epoch:1 step:943 [D loss: 0.475964, acc.: 84.38%] [G loss: 0.281708]\n",
      "epoch:1 step:944 [D loss: 0.479404, acc.: 85.94%] [G loss: 0.242449]\n",
      "epoch:1 step:945 [D loss: 0.494389, acc.: 84.38%] [G loss: 0.263389]\n",
      "epoch:1 step:946 [D loss: 0.491639, acc.: 82.81%] [G loss: 0.338844]\n",
      "epoch:1 step:947 [D loss: 0.517079, acc.: 82.03%] [G loss: 0.318945]\n",
      "epoch:1 step:948 [D loss: 0.463166, acc.: 89.84%] [G loss: 0.350494]\n",
      "epoch:1 step:949 [D loss: 0.521421, acc.: 81.25%] [G loss: 0.287267]\n",
      "epoch:1 step:950 [D loss: 0.473228, acc.: 89.06%] [G loss: 0.289985]\n",
      "epoch:1 step:951 [D loss: 0.463879, acc.: 85.94%] [G loss: 0.334951]\n",
      "epoch:1 step:952 [D loss: 0.492001, acc.: 86.72%] [G loss: 0.346980]\n",
      "epoch:1 step:953 [D loss: 0.490326, acc.: 82.03%] [G loss: 0.367113]\n",
      "epoch:1 step:954 [D loss: 0.499959, acc.: 78.91%] [G loss: 0.315981]\n",
      "epoch:1 step:955 [D loss: 0.525626, acc.: 77.34%] [G loss: 0.278599]\n",
      "epoch:1 step:956 [D loss: 0.489050, acc.: 80.47%] [G loss: 0.285625]\n",
      "epoch:1 step:957 [D loss: 0.501006, acc.: 83.59%] [G loss: 0.297426]\n",
      "epoch:1 step:958 [D loss: 0.457430, acc.: 85.16%] [G loss: 0.435147]\n",
      "epoch:1 step:959 [D loss: 0.475115, acc.: 82.03%] [G loss: 0.427787]\n",
      "epoch:1 step:960 [D loss: 0.564427, acc.: 71.09%] [G loss: 0.254700]\n",
      "epoch:1 step:961 [D loss: 0.527083, acc.: 75.00%] [G loss: 0.316071]\n",
      "epoch:1 step:962 [D loss: 0.514660, acc.: 78.12%] [G loss: 0.306703]\n",
      "epoch:1 step:963 [D loss: 0.581589, acc.: 70.31%] [G loss: 0.243746]\n",
      "epoch:1 step:964 [D loss: 0.514215, acc.: 76.56%] [G loss: 0.232618]\n",
      "epoch:1 step:965 [D loss: 0.534166, acc.: 81.25%] [G loss: 0.239892]\n",
      "epoch:1 step:966 [D loss: 0.503687, acc.: 78.12%] [G loss: 0.249984]\n",
      "epoch:1 step:967 [D loss: 0.489870, acc.: 85.16%] [G loss: 0.290293]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1 step:968 [D loss: 0.461322, acc.: 85.94%] [G loss: 0.358800]\n",
      "epoch:1 step:969 [D loss: 0.486041, acc.: 82.03%] [G loss: 0.348026]\n",
      "epoch:1 step:970 [D loss: 0.464592, acc.: 84.38%] [G loss: 0.370861]\n",
      "epoch:1 step:971 [D loss: 0.462016, acc.: 84.38%] [G loss: 0.373088]\n",
      "epoch:1 step:972 [D loss: 0.450891, acc.: 85.94%] [G loss: 0.440899]\n",
      "epoch:1 step:973 [D loss: 0.428093, acc.: 92.97%] [G loss: 0.483226]\n",
      "epoch:1 step:974 [D loss: 0.586231, acc.: 72.66%] [G loss: 0.300908]\n",
      "epoch:1 step:975 [D loss: 0.632918, acc.: 62.50%] [G loss: 0.242821]\n",
      "epoch:1 step:976 [D loss: 0.517973, acc.: 75.78%] [G loss: 0.332585]\n",
      "epoch:1 step:977 [D loss: 0.508310, acc.: 83.59%] [G loss: 0.294871]\n",
      "epoch:1 step:978 [D loss: 0.514843, acc.: 79.69%] [G loss: 0.332649]\n",
      "epoch:1 step:979 [D loss: 0.508993, acc.: 76.56%] [G loss: 0.332563]\n",
      "epoch:1 step:980 [D loss: 0.526811, acc.: 75.00%] [G loss: 0.313506]\n",
      "epoch:1 step:981 [D loss: 0.552062, acc.: 74.22%] [G loss: 0.282159]\n",
      "epoch:1 step:982 [D loss: 0.474608, acc.: 82.81%] [G loss: 0.374237]\n",
      "epoch:1 step:983 [D loss: 0.517970, acc.: 78.91%] [G loss: 0.302031]\n",
      "epoch:1 step:984 [D loss: 0.526895, acc.: 82.03%] [G loss: 0.249773]\n",
      "epoch:1 step:985 [D loss: 0.517526, acc.: 81.25%] [G loss: 0.237089]\n",
      "epoch:1 step:986 [D loss: 0.522081, acc.: 80.47%] [G loss: 0.256212]\n",
      "epoch:1 step:987 [D loss: 0.499047, acc.: 83.59%] [G loss: 0.283899]\n",
      "epoch:1 step:988 [D loss: 0.502882, acc.: 85.16%] [G loss: 0.229162]\n",
      "epoch:1 step:989 [D loss: 0.508102, acc.: 78.12%] [G loss: 0.284250]\n",
      "epoch:1 step:990 [D loss: 0.444832, acc.: 85.94%] [G loss: 0.514258]\n",
      "epoch:1 step:991 [D loss: 0.509559, acc.: 85.94%] [G loss: 0.398779]\n",
      "epoch:1 step:992 [D loss: 0.513833, acc.: 79.69%] [G loss: 0.310755]\n",
      "epoch:1 step:993 [D loss: 0.526254, acc.: 77.34%] [G loss: 0.282377]\n",
      "epoch:1 step:994 [D loss: 0.485148, acc.: 84.38%] [G loss: 0.300600]\n",
      "epoch:1 step:995 [D loss: 0.562868, acc.: 69.53%] [G loss: 0.251186]\n",
      "epoch:1 step:996 [D loss: 0.494557, acc.: 82.81%] [G loss: 0.307799]\n",
      "epoch:1 step:997 [D loss: 0.485107, acc.: 82.81%] [G loss: 0.335641]\n",
      "epoch:1 step:998 [D loss: 0.513227, acc.: 75.00%] [G loss: 0.308553]\n",
      "epoch:1 step:999 [D loss: 0.506341, acc.: 80.47%] [G loss: 0.359384]\n",
      "epoch:1 step:1000 [D loss: 0.510966, acc.: 78.12%] [G loss: 0.282225]\n",
      "##############\n",
      "[ 5.34990812  4.42056982 10.37064113  7.42712827  6.85256185  8.57739313\n",
      "  8.06735979  7.47020521  7.83071275  6.64088646]\n",
      "##########\n",
      "epoch:1 step:1001 [D loss: 0.556494, acc.: 75.00%] [G loss: 0.217809]\n",
      "epoch:1 step:1002 [D loss: 0.536492, acc.: 78.12%] [G loss: 0.217601]\n",
      "epoch:1 step:1003 [D loss: 0.488149, acc.: 83.59%] [G loss: 0.275357]\n",
      "epoch:1 step:1004 [D loss: 0.486714, acc.: 87.50%] [G loss: 0.290999]\n",
      "epoch:1 step:1005 [D loss: 0.542168, acc.: 73.44%] [G loss: 0.238391]\n",
      "epoch:1 step:1006 [D loss: 0.486250, acc.: 85.94%] [G loss: 0.293406]\n",
      "epoch:1 step:1007 [D loss: 0.529643, acc.: 76.56%] [G loss: 0.317609]\n",
      "epoch:1 step:1008 [D loss: 0.498233, acc.: 84.38%] [G loss: 0.305884]\n",
      "epoch:1 step:1009 [D loss: 0.477744, acc.: 83.59%] [G loss: 0.326761]\n",
      "epoch:1 step:1010 [D loss: 0.490265, acc.: 85.16%] [G loss: 0.260748]\n",
      "epoch:1 step:1011 [D loss: 0.468508, acc.: 80.47%] [G loss: 0.344005]\n",
      "epoch:1 step:1012 [D loss: 0.517275, acc.: 82.81%] [G loss: 0.331470]\n",
      "epoch:1 step:1013 [D loss: 0.478390, acc.: 82.03%] [G loss: 0.329289]\n",
      "epoch:1 step:1014 [D loss: 0.449873, acc.: 85.94%] [G loss: 0.429438]\n",
      "epoch:1 step:1015 [D loss: 0.611492, acc.: 66.41%] [G loss: 0.264681]\n",
      "epoch:1 step:1016 [D loss: 0.531561, acc.: 79.69%] [G loss: 0.280118]\n",
      "epoch:1 step:1017 [D loss: 0.521933, acc.: 77.34%] [G loss: 0.256464]\n",
      "epoch:1 step:1018 [D loss: 0.541155, acc.: 76.56%] [G loss: 0.237287]\n",
      "epoch:1 step:1019 [D loss: 0.505752, acc.: 82.81%] [G loss: 0.310251]\n",
      "epoch:1 step:1020 [D loss: 0.465167, acc.: 83.59%] [G loss: 0.314169]\n",
      "epoch:1 step:1021 [D loss: 0.530881, acc.: 77.34%] [G loss: 0.319867]\n",
      "epoch:1 step:1022 [D loss: 0.502735, acc.: 78.12%] [G loss: 0.327445]\n",
      "epoch:1 step:1023 [D loss: 0.506085, acc.: 82.81%] [G loss: 0.326324]\n",
      "epoch:1 step:1024 [D loss: 0.509197, acc.: 81.25%] [G loss: 0.301636]\n",
      "epoch:1 step:1025 [D loss: 0.494325, acc.: 81.25%] [G loss: 0.292659]\n",
      "epoch:1 step:1026 [D loss: 0.528310, acc.: 79.69%] [G loss: 0.333720]\n",
      "epoch:1 step:1027 [D loss: 0.490109, acc.: 82.03%] [G loss: 0.343051]\n",
      "epoch:1 step:1028 [D loss: 0.531198, acc.: 77.34%] [G loss: 0.303595]\n",
      "epoch:1 step:1029 [D loss: 0.509557, acc.: 79.69%] [G loss: 0.332007]\n",
      "epoch:1 step:1030 [D loss: 0.522400, acc.: 75.78%] [G loss: 0.349464]\n",
      "epoch:1 step:1031 [D loss: 0.463788, acc.: 89.06%] [G loss: 0.392101]\n",
      "epoch:1 step:1032 [D loss: 0.546545, acc.: 75.78%] [G loss: 0.269533]\n",
      "epoch:1 step:1033 [D loss: 0.487152, acc.: 81.25%] [G loss: 0.309459]\n",
      "epoch:1 step:1034 [D loss: 0.500390, acc.: 83.59%] [G loss: 0.383029]\n",
      "epoch:1 step:1035 [D loss: 0.487604, acc.: 79.69%] [G loss: 0.378885]\n",
      "epoch:1 step:1036 [D loss: 0.511549, acc.: 82.03%] [G loss: 0.304030]\n",
      "epoch:1 step:1037 [D loss: 0.509350, acc.: 75.78%] [G loss: 0.354643]\n",
      "epoch:1 step:1038 [D loss: 0.487486, acc.: 84.38%] [G loss: 0.386669]\n",
      "epoch:1 step:1039 [D loss: 0.542759, acc.: 79.69%] [G loss: 0.272777]\n",
      "epoch:1 step:1040 [D loss: 0.453073, acc.: 85.16%] [G loss: 0.342869]\n",
      "epoch:1 step:1041 [D loss: 0.507947, acc.: 75.78%] [G loss: 0.354532]\n",
      "epoch:1 step:1042 [D loss: 0.574785, acc.: 71.88%] [G loss: 0.220406]\n",
      "epoch:1 step:1043 [D loss: 0.563436, acc.: 71.09%] [G loss: 0.237091]\n",
      "epoch:1 step:1044 [D loss: 0.560837, acc.: 75.00%] [G loss: 0.307827]\n",
      "epoch:1 step:1045 [D loss: 0.533632, acc.: 73.44%] [G loss: 0.334767]\n",
      "epoch:1 step:1046 [D loss: 0.483320, acc.: 89.06%] [G loss: 0.368532]\n",
      "epoch:1 step:1047 [D loss: 0.503983, acc.: 82.81%] [G loss: 0.316904]\n",
      "epoch:1 step:1048 [D loss: 0.494039, acc.: 85.94%] [G loss: 0.278474]\n",
      "epoch:1 step:1049 [D loss: 0.538822, acc.: 76.56%] [G loss: 0.230132]\n",
      "epoch:1 step:1050 [D loss: 0.500867, acc.: 79.69%] [G loss: 0.348356]\n",
      "epoch:1 step:1051 [D loss: 0.524121, acc.: 76.56%] [G loss: 0.339446]\n",
      "epoch:1 step:1052 [D loss: 0.562205, acc.: 75.78%] [G loss: 0.364364]\n",
      "epoch:1 step:1053 [D loss: 0.506632, acc.: 75.78%] [G loss: 0.382047]\n",
      "epoch:1 step:1054 [D loss: 0.516967, acc.: 83.59%] [G loss: 0.333736]\n",
      "epoch:1 step:1055 [D loss: 0.485462, acc.: 84.38%] [G loss: 0.290143]\n",
      "epoch:1 step:1056 [D loss: 0.494295, acc.: 77.34%] [G loss: 0.340228]\n",
      "epoch:1 step:1057 [D loss: 0.572411, acc.: 78.12%] [G loss: 0.276985]\n",
      "epoch:1 step:1058 [D loss: 0.560713, acc.: 76.56%] [G loss: 0.277031]\n",
      "epoch:1 step:1059 [D loss: 0.509636, acc.: 80.47%] [G loss: 0.293337]\n",
      "epoch:1 step:1060 [D loss: 0.494945, acc.: 84.38%] [G loss: 0.360844]\n",
      "epoch:1 step:1061 [D loss: 0.533805, acc.: 76.56%] [G loss: 0.250448]\n",
      "epoch:1 step:1062 [D loss: 0.468465, acc.: 80.47%] [G loss: 0.350592]\n",
      "epoch:1 step:1063 [D loss: 0.506152, acc.: 86.72%] [G loss: 0.342003]\n",
      "epoch:1 step:1064 [D loss: 0.505096, acc.: 79.69%] [G loss: 0.331885]\n",
      "epoch:1 step:1065 [D loss: 0.501459, acc.: 81.25%] [G loss: 0.259054]\n",
      "epoch:1 step:1066 [D loss: 0.543831, acc.: 73.44%] [G loss: 0.245750]\n",
      "epoch:1 step:1067 [D loss: 0.485121, acc.: 80.47%] [G loss: 0.356786]\n",
      "epoch:1 step:1068 [D loss: 0.483929, acc.: 85.94%] [G loss: 0.364246]\n",
      "epoch:1 step:1069 [D loss: 0.514370, acc.: 84.38%] [G loss: 0.297792]\n",
      "epoch:1 step:1070 [D loss: 0.464268, acc.: 82.03%] [G loss: 0.276449]\n",
      "epoch:1 step:1071 [D loss: 0.462085, acc.: 84.38%] [G loss: 0.365004]\n",
      "epoch:1 step:1072 [D loss: 0.447215, acc.: 87.50%] [G loss: 0.440321]\n",
      "epoch:1 step:1073 [D loss: 0.483684, acc.: 80.47%] [G loss: 0.390253]\n",
      "epoch:1 step:1074 [D loss: 0.494643, acc.: 82.81%] [G loss: 0.350313]\n",
      "epoch:1 step:1075 [D loss: 0.480612, acc.: 83.59%] [G loss: 0.307306]\n",
      "epoch:1 step:1076 [D loss: 0.482861, acc.: 79.69%] [G loss: 0.379341]\n",
      "epoch:1 step:1077 [D loss: 0.477161, acc.: 80.47%] [G loss: 0.396280]\n",
      "epoch:1 step:1078 [D loss: 0.425096, acc.: 86.72%] [G loss: 0.471188]\n",
      "epoch:1 step:1079 [D loss: 0.468228, acc.: 82.03%] [G loss: 0.414309]\n",
      "epoch:1 step:1080 [D loss: 0.531391, acc.: 77.34%] [G loss: 0.292343]\n",
      "epoch:1 step:1081 [D loss: 0.513402, acc.: 75.00%] [G loss: 0.303298]\n",
      "epoch:1 step:1082 [D loss: 0.482084, acc.: 82.03%] [G loss: 0.455385]\n",
      "epoch:1 step:1083 [D loss: 0.474468, acc.: 77.34%] [G loss: 0.427213]\n",
      "epoch:1 step:1084 [D loss: 0.525778, acc.: 72.66%] [G loss: 0.370245]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1 step:1085 [D loss: 0.514971, acc.: 78.12%] [G loss: 0.333570]\n",
      "epoch:1 step:1086 [D loss: 0.488206, acc.: 84.38%] [G loss: 0.324120]\n",
      "epoch:1 step:1087 [D loss: 0.493248, acc.: 82.03%] [G loss: 0.236368]\n",
      "epoch:1 step:1088 [D loss: 0.515686, acc.: 76.56%] [G loss: 0.307121]\n",
      "epoch:1 step:1089 [D loss: 0.421261, acc.: 89.06%] [G loss: 0.457553]\n",
      "epoch:1 step:1090 [D loss: 0.500960, acc.: 80.47%] [G loss: 0.376342]\n",
      "epoch:1 step:1091 [D loss: 0.549779, acc.: 77.34%] [G loss: 0.244543]\n",
      "epoch:1 step:1092 [D loss: 0.542242, acc.: 70.31%] [G loss: 0.242032]\n",
      "epoch:1 step:1093 [D loss: 0.488147, acc.: 82.03%] [G loss: 0.328771]\n",
      "epoch:1 step:1094 [D loss: 0.451879, acc.: 85.94%] [G loss: 0.376556]\n",
      "epoch:1 step:1095 [D loss: 0.508111, acc.: 85.16%] [G loss: 0.286291]\n",
      "epoch:1 step:1096 [D loss: 0.526963, acc.: 78.12%] [G loss: 0.278860]\n",
      "epoch:1 step:1097 [D loss: 0.553694, acc.: 76.56%] [G loss: 0.298272]\n",
      "epoch:1 step:1098 [D loss: 0.537274, acc.: 75.00%] [G loss: 0.328945]\n",
      "epoch:1 step:1099 [D loss: 0.410913, acc.: 88.28%] [G loss: 0.425994]\n",
      "epoch:1 step:1100 [D loss: 0.482096, acc.: 79.69%] [G loss: 0.406308]\n",
      "epoch:1 step:1101 [D loss: 0.468941, acc.: 85.16%] [G loss: 0.434435]\n",
      "epoch:1 step:1102 [D loss: 0.464618, acc.: 83.59%] [G loss: 0.397156]\n",
      "epoch:1 step:1103 [D loss: 0.484236, acc.: 80.47%] [G loss: 0.380556]\n",
      "epoch:1 step:1104 [D loss: 0.524727, acc.: 79.69%] [G loss: 0.295978]\n",
      "epoch:1 step:1105 [D loss: 0.508726, acc.: 80.47%] [G loss: 0.335883]\n",
      "epoch:1 step:1106 [D loss: 0.519983, acc.: 76.56%] [G loss: 0.260860]\n",
      "epoch:1 step:1107 [D loss: 0.454558, acc.: 82.03%] [G loss: 0.390700]\n",
      "epoch:1 step:1108 [D loss: 0.500032, acc.: 76.56%] [G loss: 0.370461]\n",
      "epoch:1 step:1109 [D loss: 0.475202, acc.: 82.03%] [G loss: 0.378140]\n",
      "epoch:1 step:1110 [D loss: 0.473683, acc.: 81.25%] [G loss: 0.447471]\n",
      "epoch:1 step:1111 [D loss: 0.476213, acc.: 81.25%] [G loss: 0.345333]\n",
      "epoch:1 step:1112 [D loss: 0.437203, acc.: 82.81%] [G loss: 0.424153]\n",
      "epoch:1 step:1113 [D loss: 0.503135, acc.: 76.56%] [G loss: 0.491240]\n",
      "epoch:1 step:1114 [D loss: 0.495394, acc.: 82.81%] [G loss: 0.470908]\n",
      "epoch:1 step:1115 [D loss: 0.489578, acc.: 82.03%] [G loss: 0.400610]\n",
      "epoch:1 step:1116 [D loss: 0.499280, acc.: 75.78%] [G loss: 0.356378]\n",
      "epoch:1 step:1117 [D loss: 0.510521, acc.: 78.12%] [G loss: 0.358620]\n",
      "epoch:1 step:1118 [D loss: 0.491590, acc.: 78.12%] [G loss: 0.337398]\n",
      "epoch:1 step:1119 [D loss: 0.475712, acc.: 84.38%] [G loss: 0.489452]\n",
      "epoch:1 step:1120 [D loss: 0.502352, acc.: 78.12%] [G loss: 0.368826]\n",
      "epoch:1 step:1121 [D loss: 0.529089, acc.: 78.91%] [G loss: 0.378951]\n",
      "epoch:1 step:1122 [D loss: 0.522091, acc.: 78.12%] [G loss: 0.305880]\n",
      "epoch:1 step:1123 [D loss: 0.513076, acc.: 82.03%] [G loss: 0.343709]\n",
      "epoch:1 step:1124 [D loss: 0.539371, acc.: 78.12%] [G loss: 0.358474]\n",
      "epoch:1 step:1125 [D loss: 0.504839, acc.: 81.25%] [G loss: 0.405476]\n",
      "epoch:1 step:1126 [D loss: 0.555387, acc.: 73.44%] [G loss: 0.335209]\n",
      "epoch:1 step:1127 [D loss: 0.461752, acc.: 80.47%] [G loss: 0.451491]\n",
      "epoch:1 step:1128 [D loss: 0.529701, acc.: 76.56%] [G loss: 0.360670]\n",
      "epoch:1 step:1129 [D loss: 0.576361, acc.: 67.97%] [G loss: 0.285656]\n",
      "epoch:1 step:1130 [D loss: 0.523181, acc.: 80.47%] [G loss: 0.294750]\n",
      "epoch:1 step:1131 [D loss: 0.516074, acc.: 77.34%] [G loss: 0.325448]\n",
      "epoch:1 step:1132 [D loss: 0.530975, acc.: 69.53%] [G loss: 0.411562]\n",
      "epoch:1 step:1133 [D loss: 0.511418, acc.: 78.12%] [G loss: 0.381935]\n",
      "epoch:1 step:1134 [D loss: 0.560613, acc.: 72.66%] [G loss: 0.292605]\n",
      "epoch:1 step:1135 [D loss: 0.465428, acc.: 84.38%] [G loss: 0.365975]\n",
      "epoch:1 step:1136 [D loss: 0.561444, acc.: 73.44%] [G loss: 0.299089]\n",
      "epoch:1 step:1137 [D loss: 0.511300, acc.: 82.03%] [G loss: 0.383459]\n",
      "epoch:1 step:1138 [D loss: 0.534683, acc.: 79.69%] [G loss: 0.308527]\n",
      "epoch:1 step:1139 [D loss: 0.484368, acc.: 81.25%] [G loss: 0.321161]\n",
      "epoch:1 step:1140 [D loss: 0.552263, acc.: 73.44%] [G loss: 0.254449]\n",
      "epoch:1 step:1141 [D loss: 0.439855, acc.: 83.59%] [G loss: 0.384522]\n",
      "epoch:1 step:1142 [D loss: 0.459318, acc.: 84.38%] [G loss: 0.374621]\n",
      "epoch:1 step:1143 [D loss: 0.457644, acc.: 85.16%] [G loss: 0.389534]\n",
      "epoch:1 step:1144 [D loss: 0.464999, acc.: 78.12%] [G loss: 0.425529]\n",
      "epoch:1 step:1145 [D loss: 0.439493, acc.: 89.06%] [G loss: 0.456497]\n",
      "epoch:1 step:1146 [D loss: 0.502130, acc.: 80.47%] [G loss: 0.345918]\n",
      "epoch:1 step:1147 [D loss: 0.510489, acc.: 78.12%] [G loss: 0.300734]\n",
      "epoch:1 step:1148 [D loss: 0.477255, acc.: 81.25%] [G loss: 0.345179]\n",
      "epoch:1 step:1149 [D loss: 0.470761, acc.: 82.81%] [G loss: 0.419758]\n",
      "epoch:1 step:1150 [D loss: 0.474545, acc.: 80.47%] [G loss: 0.420292]\n",
      "epoch:1 step:1151 [D loss: 0.599860, acc.: 67.97%] [G loss: 0.298335]\n",
      "epoch:1 step:1152 [D loss: 0.554829, acc.: 72.66%] [G loss: 0.291770]\n",
      "epoch:1 step:1153 [D loss: 0.512774, acc.: 79.69%] [G loss: 0.347649]\n",
      "epoch:1 step:1154 [D loss: 0.434116, acc.: 87.50%] [G loss: 0.397545]\n",
      "epoch:1 step:1155 [D loss: 0.514152, acc.: 85.94%] [G loss: 0.300153]\n",
      "epoch:1 step:1156 [D loss: 0.521024, acc.: 75.78%] [G loss: 0.327046]\n",
      "epoch:1 step:1157 [D loss: 0.572268, acc.: 73.44%] [G loss: 0.281986]\n",
      "epoch:1 step:1158 [D loss: 0.545099, acc.: 70.31%] [G loss: 0.353306]\n",
      "epoch:1 step:1159 [D loss: 0.488733, acc.: 80.47%] [G loss: 0.415268]\n",
      "epoch:1 step:1160 [D loss: 0.492736, acc.: 79.69%] [G loss: 0.341707]\n",
      "epoch:1 step:1161 [D loss: 0.486905, acc.: 78.91%] [G loss: 0.329766]\n",
      "epoch:1 step:1162 [D loss: 0.546053, acc.: 74.22%] [G loss: 0.315264]\n",
      "epoch:1 step:1163 [D loss: 0.418507, acc.: 91.41%] [G loss: 0.433737]\n",
      "epoch:1 step:1164 [D loss: 0.536372, acc.: 73.44%] [G loss: 0.339767]\n",
      "epoch:1 step:1165 [D loss: 0.476131, acc.: 79.69%] [G loss: 0.362612]\n",
      "epoch:1 step:1166 [D loss: 0.524059, acc.: 79.69%] [G loss: 0.292018]\n",
      "epoch:1 step:1167 [D loss: 0.475025, acc.: 81.25%] [G loss: 0.410293]\n",
      "epoch:1 step:1168 [D loss: 0.444303, acc.: 86.72%] [G loss: 0.547664]\n",
      "epoch:1 step:1169 [D loss: 0.492763, acc.: 85.16%] [G loss: 0.484295]\n",
      "epoch:1 step:1170 [D loss: 0.528170, acc.: 84.38%] [G loss: 0.425071]\n",
      "epoch:1 step:1171 [D loss: 0.477535, acc.: 81.25%] [G loss: 0.409524]\n",
      "epoch:1 step:1172 [D loss: 0.468119, acc.: 82.03%] [G loss: 0.357025]\n",
      "epoch:1 step:1173 [D loss: 0.502870, acc.: 79.69%] [G loss: 0.348606]\n",
      "epoch:1 step:1174 [D loss: 0.488773, acc.: 79.69%] [G loss: 0.329646]\n",
      "epoch:1 step:1175 [D loss: 0.464251, acc.: 85.94%] [G loss: 0.381798]\n",
      "epoch:1 step:1176 [D loss: 0.492124, acc.: 81.25%] [G loss: 0.388899]\n",
      "epoch:1 step:1177 [D loss: 0.495307, acc.: 79.69%] [G loss: 0.392292]\n",
      "epoch:1 step:1178 [D loss: 0.556631, acc.: 71.88%] [G loss: 0.372537]\n",
      "epoch:1 step:1179 [D loss: 0.486910, acc.: 84.38%] [G loss: 0.380743]\n",
      "epoch:1 step:1180 [D loss: 0.513791, acc.: 78.12%] [G loss: 0.292510]\n",
      "epoch:1 step:1181 [D loss: 0.486458, acc.: 81.25%] [G loss: 0.306442]\n",
      "epoch:1 step:1182 [D loss: 0.513964, acc.: 76.56%] [G loss: 0.311620]\n",
      "epoch:1 step:1183 [D loss: 0.518440, acc.: 78.91%] [G loss: 0.381238]\n",
      "epoch:1 step:1184 [D loss: 0.532756, acc.: 76.56%] [G loss: 0.304567]\n",
      "epoch:1 step:1185 [D loss: 0.555045, acc.: 69.53%] [G loss: 0.250889]\n",
      "epoch:1 step:1186 [D loss: 0.531393, acc.: 73.44%] [G loss: 0.291598]\n",
      "epoch:1 step:1187 [D loss: 0.511961, acc.: 78.91%] [G loss: 0.340896]\n",
      "epoch:1 step:1188 [D loss: 0.549827, acc.: 73.44%] [G loss: 0.249052]\n",
      "epoch:1 step:1189 [D loss: 0.518356, acc.: 75.78%] [G loss: 0.348506]\n",
      "epoch:1 step:1190 [D loss: 0.502702, acc.: 80.47%] [G loss: 0.351631]\n",
      "epoch:1 step:1191 [D loss: 0.485938, acc.: 82.81%] [G loss: 0.409982]\n",
      "epoch:1 step:1192 [D loss: 0.492699, acc.: 79.69%] [G loss: 0.489260]\n",
      "epoch:1 step:1193 [D loss: 0.485183, acc.: 80.47%] [G loss: 0.442603]\n",
      "epoch:1 step:1194 [D loss: 0.497782, acc.: 82.81%] [G loss: 0.375803]\n",
      "epoch:1 step:1195 [D loss: 0.475233, acc.: 82.81%] [G loss: 0.370884]\n",
      "epoch:1 step:1196 [D loss: 0.449986, acc.: 83.59%] [G loss: 0.452446]\n",
      "epoch:1 step:1197 [D loss: 0.524304, acc.: 74.22%] [G loss: 0.414875]\n",
      "epoch:1 step:1198 [D loss: 0.530321, acc.: 78.12%] [G loss: 0.349753]\n",
      "epoch:1 step:1199 [D loss: 0.537752, acc.: 71.09%] [G loss: 0.419645]\n",
      "epoch:1 step:1200 [D loss: 0.636084, acc.: 60.94%] [G loss: 0.287554]\n",
      "##############\n",
      "[5.15362874 3.59700212 8.83742372 7.07248672 6.66918315 7.89643297\n",
      " 7.63317882 7.03106671 7.60124707 5.79348913]\n",
      "##########\n",
      "epoch:1 step:1201 [D loss: 0.553085, acc.: 70.31%] [G loss: 0.293250]\n",
      "epoch:1 step:1202 [D loss: 0.557253, acc.: 67.97%] [G loss: 0.347407]\n",
      "epoch:1 step:1203 [D loss: 0.530486, acc.: 73.44%] [G loss: 0.317882]\n",
      "epoch:1 step:1204 [D loss: 0.539724, acc.: 73.44%] [G loss: 0.347440]\n",
      "epoch:1 step:1205 [D loss: 0.534295, acc.: 74.22%] [G loss: 0.372306]\n",
      "epoch:1 step:1206 [D loss: 0.607714, acc.: 67.97%] [G loss: 0.280260]\n",
      "epoch:1 step:1207 [D loss: 0.548800, acc.: 69.53%] [G loss: 0.291820]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1 step:1208 [D loss: 0.479847, acc.: 80.47%] [G loss: 0.380625]\n",
      "epoch:1 step:1209 [D loss: 0.548129, acc.: 71.88%] [G loss: 0.340617]\n",
      "epoch:1 step:1210 [D loss: 0.509303, acc.: 73.44%] [G loss: 0.338406]\n",
      "epoch:1 step:1211 [D loss: 0.575686, acc.: 70.31%] [G loss: 0.285327]\n",
      "epoch:1 step:1212 [D loss: 0.577930, acc.: 71.09%] [G loss: 0.305285]\n",
      "epoch:1 step:1213 [D loss: 0.574629, acc.: 64.84%] [G loss: 0.234532]\n",
      "epoch:1 step:1214 [D loss: 0.591801, acc.: 69.53%] [G loss: 0.261149]\n",
      "epoch:1 step:1215 [D loss: 0.586965, acc.: 71.09%] [G loss: 0.282604]\n",
      "epoch:1 step:1216 [D loss: 0.506720, acc.: 77.34%] [G loss: 0.301442]\n",
      "epoch:1 step:1217 [D loss: 0.511674, acc.: 83.59%] [G loss: 0.320378]\n",
      "epoch:1 step:1218 [D loss: 0.538539, acc.: 75.78%] [G loss: 0.278213]\n",
      "epoch:1 step:1219 [D loss: 0.546718, acc.: 74.22%] [G loss: 0.212003]\n",
      "epoch:1 step:1220 [D loss: 0.495196, acc.: 79.69%] [G loss: 0.235152]\n",
      "epoch:1 step:1221 [D loss: 0.476203, acc.: 84.38%] [G loss: 0.253533]\n",
      "epoch:1 step:1222 [D loss: 0.459188, acc.: 78.91%] [G loss: 0.367546]\n",
      "epoch:1 step:1223 [D loss: 0.453910, acc.: 85.94%] [G loss: 0.335445]\n",
      "epoch:1 step:1224 [D loss: 0.515191, acc.: 80.47%] [G loss: 0.393349]\n",
      "epoch:1 step:1225 [D loss: 0.550264, acc.: 71.09%] [G loss: 0.332337]\n",
      "epoch:1 step:1226 [D loss: 0.464569, acc.: 84.38%] [G loss: 0.365821]\n",
      "epoch:1 step:1227 [D loss: 0.523981, acc.: 77.34%] [G loss: 0.414741]\n",
      "epoch:1 step:1228 [D loss: 0.551791, acc.: 74.22%] [G loss: 0.372480]\n",
      "epoch:1 step:1229 [D loss: 0.561641, acc.: 75.78%] [G loss: 0.333043]\n",
      "epoch:1 step:1230 [D loss: 0.543580, acc.: 73.44%] [G loss: 0.258266]\n",
      "epoch:1 step:1231 [D loss: 0.513862, acc.: 82.81%] [G loss: 0.280048]\n",
      "epoch:1 step:1232 [D loss: 0.547406, acc.: 76.56%] [G loss: 0.306700]\n",
      "epoch:1 step:1233 [D loss: 0.454874, acc.: 85.16%] [G loss: 0.412694]\n",
      "epoch:1 step:1234 [D loss: 0.517305, acc.: 78.12%] [G loss: 0.318732]\n",
      "epoch:1 step:1235 [D loss: 0.526438, acc.: 76.56%] [G loss: 0.291201]\n",
      "epoch:1 step:1236 [D loss: 0.537315, acc.: 75.00%] [G loss: 0.316787]\n",
      "epoch:1 step:1237 [D loss: 0.527674, acc.: 76.56%] [G loss: 0.261448]\n",
      "epoch:1 step:1238 [D loss: 0.561325, acc.: 73.44%] [G loss: 0.232503]\n",
      "epoch:1 step:1239 [D loss: 0.518733, acc.: 84.38%] [G loss: 0.252430]\n",
      "epoch:1 step:1240 [D loss: 0.542201, acc.: 71.88%] [G loss: 0.232247]\n",
      "epoch:1 step:1241 [D loss: 0.473476, acc.: 82.03%] [G loss: 0.310309]\n",
      "epoch:1 step:1242 [D loss: 0.490449, acc.: 82.03%] [G loss: 0.301927]\n",
      "epoch:1 step:1243 [D loss: 0.510746, acc.: 80.47%] [G loss: 0.306351]\n",
      "epoch:1 step:1244 [D loss: 0.463562, acc.: 87.50%] [G loss: 0.321134]\n",
      "epoch:1 step:1245 [D loss: 0.442533, acc.: 85.16%] [G loss: 0.463718]\n",
      "epoch:1 step:1246 [D loss: 0.424663, acc.: 89.84%] [G loss: 0.461960]\n",
      "epoch:1 step:1247 [D loss: 0.496534, acc.: 78.91%] [G loss: 0.343023]\n",
      "epoch:1 step:1248 [D loss: 0.453409, acc.: 82.81%] [G loss: 0.414364]\n",
      "epoch:1 step:1249 [D loss: 0.411457, acc.: 87.50%] [G loss: 0.483074]\n",
      "epoch:1 step:1250 [D loss: 0.429727, acc.: 82.81%] [G loss: 0.546103]\n",
      "epoch:1 step:1251 [D loss: 0.444280, acc.: 82.03%] [G loss: 0.614749]\n",
      "epoch:1 step:1252 [D loss: 0.436969, acc.: 85.16%] [G loss: 0.508942]\n",
      "epoch:1 step:1253 [D loss: 0.653517, acc.: 66.41%] [G loss: 0.285765]\n",
      "epoch:1 step:1254 [D loss: 0.532750, acc.: 72.66%] [G loss: 0.307503]\n",
      "epoch:1 step:1255 [D loss: 0.572687, acc.: 73.44%] [G loss: 0.246668]\n",
      "epoch:1 step:1256 [D loss: 0.506329, acc.: 78.91%] [G loss: 0.319033]\n",
      "epoch:1 step:1257 [D loss: 0.518901, acc.: 82.03%] [G loss: 0.274334]\n",
      "epoch:1 step:1258 [D loss: 0.462238, acc.: 87.50%] [G loss: 0.308810]\n",
      "epoch:1 step:1259 [D loss: 0.505622, acc.: 79.69%] [G loss: 0.349269]\n",
      "epoch:1 step:1260 [D loss: 0.500339, acc.: 78.91%] [G loss: 0.356052]\n",
      "epoch:1 step:1261 [D loss: 0.501099, acc.: 77.34%] [G loss: 0.329029]\n",
      "epoch:1 step:1262 [D loss: 0.481364, acc.: 83.59%] [G loss: 0.342174]\n",
      "epoch:1 step:1263 [D loss: 0.483608, acc.: 82.03%] [G loss: 0.326959]\n",
      "epoch:1 step:1264 [D loss: 0.520724, acc.: 74.22%] [G loss: 0.308835]\n",
      "epoch:1 step:1265 [D loss: 0.485151, acc.: 82.81%] [G loss: 0.409015]\n",
      "epoch:1 step:1266 [D loss: 0.509596, acc.: 78.91%] [G loss: 0.317112]\n",
      "epoch:1 step:1267 [D loss: 0.516762, acc.: 81.25%] [G loss: 0.316224]\n",
      "epoch:1 step:1268 [D loss: 0.479015, acc.: 83.59%] [G loss: 0.324844]\n",
      "epoch:1 step:1269 [D loss: 0.478618, acc.: 82.03%] [G loss: 0.391821]\n",
      "epoch:1 step:1270 [D loss: 0.473601, acc.: 85.94%] [G loss: 0.397998]\n",
      "epoch:1 step:1271 [D loss: 0.511569, acc.: 79.69%] [G loss: 0.378208]\n",
      "epoch:1 step:1272 [D loss: 0.488242, acc.: 79.69%] [G loss: 0.390315]\n",
      "epoch:1 step:1273 [D loss: 0.448661, acc.: 83.59%] [G loss: 0.419479]\n",
      "epoch:1 step:1274 [D loss: 0.460910, acc.: 82.03%] [G loss: 0.479831]\n",
      "epoch:1 step:1275 [D loss: 0.495140, acc.: 80.47%] [G loss: 0.457760]\n",
      "epoch:1 step:1276 [D loss: 0.485040, acc.: 81.25%] [G loss: 0.463586]\n",
      "epoch:1 step:1277 [D loss: 0.457823, acc.: 82.81%] [G loss: 0.554841]\n",
      "epoch:1 step:1278 [D loss: 0.503950, acc.: 81.25%] [G loss: 0.374032]\n",
      "epoch:1 step:1279 [D loss: 0.464943, acc.: 88.28%] [G loss: 0.402847]\n",
      "epoch:1 step:1280 [D loss: 0.415187, acc.: 85.94%] [G loss: 0.548748]\n",
      "epoch:1 step:1281 [D loss: 0.379176, acc.: 92.19%] [G loss: 0.604838]\n",
      "epoch:1 step:1282 [D loss: 0.473235, acc.: 82.03%] [G loss: 0.542571]\n",
      "epoch:1 step:1283 [D loss: 0.468076, acc.: 82.81%] [G loss: 0.497542]\n",
      "epoch:1 step:1284 [D loss: 0.445728, acc.: 84.38%] [G loss: 0.617995]\n",
      "epoch:1 step:1285 [D loss: 0.559397, acc.: 71.09%] [G loss: 0.375067]\n",
      "epoch:1 step:1286 [D loss: 0.651046, acc.: 58.59%] [G loss: 0.264976]\n",
      "epoch:1 step:1287 [D loss: 0.442100, acc.: 88.28%] [G loss: 0.373391]\n",
      "epoch:1 step:1288 [D loss: 0.536009, acc.: 75.00%] [G loss: 0.495012]\n",
      "epoch:1 step:1289 [D loss: 0.579688, acc.: 67.97%] [G loss: 0.416681]\n",
      "epoch:1 step:1290 [D loss: 0.482386, acc.: 77.34%] [G loss: 0.472451]\n",
      "epoch:1 step:1291 [D loss: 0.423666, acc.: 87.50%] [G loss: 0.482238]\n",
      "epoch:1 step:1292 [D loss: 0.513521, acc.: 77.34%] [G loss: 0.383779]\n",
      "epoch:1 step:1293 [D loss: 0.426235, acc.: 87.50%] [G loss: 0.446903]\n",
      "epoch:1 step:1294 [D loss: 0.489485, acc.: 78.12%] [G loss: 0.379498]\n",
      "epoch:1 step:1295 [D loss: 0.381269, acc.: 90.62%] [G loss: 0.561260]\n",
      "epoch:1 step:1296 [D loss: 0.476317, acc.: 84.38%] [G loss: 0.444999]\n",
      "epoch:1 step:1297 [D loss: 0.464188, acc.: 81.25%] [G loss: 0.401199]\n",
      "epoch:1 step:1298 [D loss: 0.468426, acc.: 80.47%] [G loss: 0.388680]\n",
      "epoch:1 step:1299 [D loss: 0.485890, acc.: 81.25%] [G loss: 0.387322]\n",
      "epoch:1 step:1300 [D loss: 0.533258, acc.: 73.44%] [G loss: 0.332414]\n",
      "epoch:1 step:1301 [D loss: 0.426715, acc.: 84.38%] [G loss: 0.484522]\n",
      "epoch:1 step:1302 [D loss: 0.464321, acc.: 82.03%] [G loss: 0.396980]\n",
      "epoch:1 step:1303 [D loss: 0.439381, acc.: 84.38%] [G loss: 0.493789]\n",
      "epoch:1 step:1304 [D loss: 0.482526, acc.: 79.69%] [G loss: 0.438006]\n",
      "epoch:1 step:1305 [D loss: 0.451986, acc.: 84.38%] [G loss: 0.446839]\n",
      "epoch:1 step:1306 [D loss: 0.520820, acc.: 76.56%] [G loss: 0.441028]\n",
      "epoch:1 step:1307 [D loss: 0.537411, acc.: 76.56%] [G loss: 0.376413]\n",
      "epoch:1 step:1308 [D loss: 0.505982, acc.: 79.69%] [G loss: 0.393698]\n",
      "epoch:1 step:1309 [D loss: 0.485426, acc.: 78.12%] [G loss: 0.410274]\n",
      "epoch:1 step:1310 [D loss: 0.500266, acc.: 76.56%] [G loss: 0.441388]\n",
      "epoch:1 step:1311 [D loss: 0.462729, acc.: 87.50%] [G loss: 0.461859]\n",
      "epoch:1 step:1312 [D loss: 0.454447, acc.: 83.59%] [G loss: 0.402189]\n",
      "epoch:1 step:1313 [D loss: 0.546186, acc.: 75.00%] [G loss: 0.296584]\n",
      "epoch:1 step:1314 [D loss: 0.457338, acc.: 78.91%] [G loss: 0.432459]\n",
      "epoch:1 step:1315 [D loss: 0.460620, acc.: 82.81%] [G loss: 0.571099]\n",
      "epoch:1 step:1316 [D loss: 0.498131, acc.: 82.03%] [G loss: 0.464395]\n",
      "epoch:1 step:1317 [D loss: 0.457240, acc.: 88.28%] [G loss: 0.450376]\n",
      "epoch:1 step:1318 [D loss: 0.403399, acc.: 87.50%] [G loss: 0.504340]\n",
      "epoch:1 step:1319 [D loss: 0.501525, acc.: 75.00%] [G loss: 0.465137]\n",
      "epoch:1 step:1320 [D loss: 0.526162, acc.: 78.91%] [G loss: 0.391067]\n",
      "epoch:1 step:1321 [D loss: 0.509225, acc.: 76.56%] [G loss: 0.419347]\n",
      "epoch:1 step:1322 [D loss: 0.527562, acc.: 71.88%] [G loss: 0.417305]\n",
      "epoch:1 step:1323 [D loss: 0.466435, acc.: 82.81%] [G loss: 0.400743]\n",
      "epoch:1 step:1324 [D loss: 0.500143, acc.: 78.12%] [G loss: 0.480876]\n",
      "epoch:1 step:1325 [D loss: 0.427667, acc.: 90.62%] [G loss: 0.523540]\n",
      "epoch:1 step:1326 [D loss: 0.490221, acc.: 77.34%] [G loss: 0.427623]\n",
      "epoch:1 step:1327 [D loss: 0.546992, acc.: 77.34%] [G loss: 0.372685]\n",
      "epoch:1 step:1328 [D loss: 0.513895, acc.: 77.34%] [G loss: 0.446683]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1 step:1329 [D loss: 0.392587, acc.: 90.62%] [G loss: 0.562271]\n",
      "epoch:1 step:1330 [D loss: 0.528951, acc.: 74.22%] [G loss: 0.446891]\n",
      "epoch:1 step:1331 [D loss: 0.500023, acc.: 78.12%] [G loss: 0.459265]\n",
      "epoch:1 step:1332 [D loss: 0.459547, acc.: 84.38%] [G loss: 0.541933]\n",
      "epoch:1 step:1333 [D loss: 0.535044, acc.: 77.34%] [G loss: 0.470392]\n",
      "epoch:1 step:1334 [D loss: 0.424909, acc.: 83.59%] [G loss: 0.640002]\n",
      "epoch:1 step:1335 [D loss: 0.417538, acc.: 85.16%] [G loss: 0.767443]\n",
      "epoch:1 step:1336 [D loss: 0.426673, acc.: 85.16%] [G loss: 0.686448]\n",
      "epoch:1 step:1337 [D loss: 0.542355, acc.: 71.09%] [G loss: 0.413672]\n",
      "epoch:1 step:1338 [D loss: 0.530057, acc.: 67.97%] [G loss: 0.491828]\n",
      "epoch:1 step:1339 [D loss: 0.425820, acc.: 85.94%] [G loss: 0.582546]\n",
      "epoch:1 step:1340 [D loss: 0.425022, acc.: 86.72%] [G loss: 0.614313]\n",
      "epoch:1 step:1341 [D loss: 0.597588, acc.: 64.84%] [G loss: 0.444537]\n",
      "epoch:1 step:1342 [D loss: 0.511540, acc.: 71.88%] [G loss: 0.548761]\n",
      "epoch:1 step:1343 [D loss: 0.546858, acc.: 72.66%] [G loss: 0.538818]\n",
      "epoch:1 step:1344 [D loss: 0.497290, acc.: 80.47%] [G loss: 0.487274]\n",
      "epoch:1 step:1345 [D loss: 0.522053, acc.: 72.66%] [G loss: 0.402186]\n",
      "epoch:1 step:1346 [D loss: 0.488525, acc.: 80.47%] [G loss: 0.485486]\n",
      "epoch:1 step:1347 [D loss: 0.510231, acc.: 80.47%] [G loss: 0.413503]\n",
      "epoch:1 step:1348 [D loss: 0.486327, acc.: 83.59%] [G loss: 0.380037]\n",
      "epoch:1 step:1349 [D loss: 0.532155, acc.: 72.66%] [G loss: 0.454724]\n",
      "epoch:1 step:1350 [D loss: 0.489312, acc.: 81.25%] [G loss: 0.517130]\n",
      "epoch:1 step:1351 [D loss: 0.512781, acc.: 81.25%] [G loss: 0.460523]\n",
      "epoch:1 step:1352 [D loss: 0.528963, acc.: 71.09%] [G loss: 0.409159]\n",
      "epoch:1 step:1353 [D loss: 0.531133, acc.: 72.66%] [G loss: 0.399754]\n",
      "epoch:1 step:1354 [D loss: 0.509355, acc.: 80.47%] [G loss: 0.374965]\n",
      "epoch:1 step:1355 [D loss: 0.527106, acc.: 78.12%] [G loss: 0.324796]\n",
      "epoch:1 step:1356 [D loss: 0.492761, acc.: 79.69%] [G loss: 0.498748]\n",
      "epoch:1 step:1357 [D loss: 0.473050, acc.: 78.91%] [G loss: 0.484521]\n",
      "epoch:1 step:1358 [D loss: 0.556371, acc.: 74.22%] [G loss: 0.381532]\n",
      "epoch:1 step:1359 [D loss: 0.479955, acc.: 81.25%] [G loss: 0.407573]\n",
      "epoch:1 step:1360 [D loss: 0.466690, acc.: 84.38%] [G loss: 0.484580]\n",
      "epoch:1 step:1361 [D loss: 0.572692, acc.: 75.78%] [G loss: 0.379617]\n",
      "epoch:1 step:1362 [D loss: 0.547930, acc.: 74.22%] [G loss: 0.412958]\n",
      "epoch:1 step:1363 [D loss: 0.514974, acc.: 78.91%] [G loss: 0.376337]\n",
      "epoch:1 step:1364 [D loss: 0.496586, acc.: 80.47%] [G loss: 0.407559]\n",
      "epoch:1 step:1365 [D loss: 0.440694, acc.: 88.28%] [G loss: 0.537376]\n",
      "epoch:1 step:1366 [D loss: 0.486178, acc.: 82.81%] [G loss: 0.470085]\n",
      "epoch:1 step:1367 [D loss: 0.448561, acc.: 85.16%] [G loss: 0.507797]\n",
      "epoch:1 step:1368 [D loss: 0.508765, acc.: 78.91%] [G loss: 0.496403]\n",
      "epoch:1 step:1369 [D loss: 0.512282, acc.: 81.25%] [G loss: 0.443865]\n",
      "epoch:1 step:1370 [D loss: 0.524425, acc.: 77.34%] [G loss: 0.332563]\n",
      "epoch:1 step:1371 [D loss: 0.480800, acc.: 82.81%] [G loss: 0.396768]\n",
      "epoch:1 step:1372 [D loss: 0.488505, acc.: 80.47%] [G loss: 0.407464]\n",
      "epoch:1 step:1373 [D loss: 0.444044, acc.: 86.72%] [G loss: 0.511909]\n",
      "epoch:1 step:1374 [D loss: 0.606303, acc.: 71.09%] [G loss: 0.245791]\n",
      "epoch:1 step:1375 [D loss: 0.484372, acc.: 78.91%] [G loss: 0.309846]\n",
      "epoch:1 step:1376 [D loss: 0.471557, acc.: 82.03%] [G loss: 0.386216]\n",
      "epoch:1 step:1377 [D loss: 0.467808, acc.: 83.59%] [G loss: 0.394876]\n",
      "epoch:1 step:1378 [D loss: 0.505767, acc.: 71.88%] [G loss: 0.441194]\n",
      "epoch:1 step:1379 [D loss: 0.481373, acc.: 83.59%] [G loss: 0.431550]\n",
      "epoch:1 step:1380 [D loss: 0.489900, acc.: 80.47%] [G loss: 0.314745]\n",
      "epoch:1 step:1381 [D loss: 0.503992, acc.: 78.91%] [G loss: 0.385729]\n",
      "epoch:1 step:1382 [D loss: 0.458629, acc.: 84.38%] [G loss: 0.380480]\n",
      "epoch:1 step:1383 [D loss: 0.436094, acc.: 89.06%] [G loss: 0.463274]\n",
      "epoch:1 step:1384 [D loss: 0.420121, acc.: 86.72%] [G loss: 0.470268]\n",
      "epoch:1 step:1385 [D loss: 0.496402, acc.: 80.47%] [G loss: 0.432528]\n",
      "epoch:1 step:1386 [D loss: 0.487019, acc.: 81.25%] [G loss: 0.426589]\n",
      "epoch:1 step:1387 [D loss: 0.441959, acc.: 83.59%] [G loss: 0.478275]\n",
      "epoch:1 step:1388 [D loss: 0.449721, acc.: 85.16%] [G loss: 0.450558]\n",
      "epoch:1 step:1389 [D loss: 0.471007, acc.: 84.38%] [G loss: 0.477095]\n",
      "epoch:1 step:1390 [D loss: 0.520056, acc.: 78.91%] [G loss: 0.394267]\n",
      "epoch:1 step:1391 [D loss: 0.553040, acc.: 72.66%] [G loss: 0.387997]\n",
      "epoch:1 step:1392 [D loss: 0.487608, acc.: 78.91%] [G loss: 0.415745]\n",
      "epoch:1 step:1393 [D loss: 0.549643, acc.: 73.44%] [G loss: 0.361099]\n",
      "epoch:1 step:1394 [D loss: 0.516508, acc.: 78.12%] [G loss: 0.320689]\n",
      "epoch:1 step:1395 [D loss: 0.522646, acc.: 76.56%] [G loss: 0.359919]\n",
      "epoch:1 step:1396 [D loss: 0.501988, acc.: 80.47%] [G loss: 0.407750]\n",
      "epoch:1 step:1397 [D loss: 0.453311, acc.: 82.81%] [G loss: 0.364511]\n",
      "epoch:1 step:1398 [D loss: 0.451467, acc.: 82.03%] [G loss: 0.471475]\n",
      "epoch:1 step:1399 [D loss: 0.505700, acc.: 82.03%] [G loss: 0.330390]\n",
      "epoch:1 step:1400 [D loss: 0.554548, acc.: 71.88%] [G loss: 0.305138]\n",
      "##############\n",
      "[4.96339623 3.54159194 8.5652188  6.97047429 6.2981494  7.74693576\n",
      " 7.4848523  7.11406075 7.25765829 5.6410014 ]\n",
      "##########\n",
      "epoch:1 step:1401 [D loss: 0.498077, acc.: 79.69%] [G loss: 0.377679]\n",
      "epoch:1 step:1402 [D loss: 0.556785, acc.: 72.66%] [G loss: 0.330195]\n",
      "epoch:1 step:1403 [D loss: 0.526814, acc.: 74.22%] [G loss: 0.350407]\n",
      "epoch:1 step:1404 [D loss: 0.504226, acc.: 77.34%] [G loss: 0.510161]\n",
      "epoch:1 step:1405 [D loss: 0.498456, acc.: 79.69%] [G loss: 0.444781]\n",
      "epoch:1 step:1406 [D loss: 0.507019, acc.: 76.56%] [G loss: 0.393920]\n",
      "epoch:1 step:1407 [D loss: 0.509191, acc.: 79.69%] [G loss: 0.359608]\n",
      "epoch:1 step:1408 [D loss: 0.465455, acc.: 84.38%] [G loss: 0.398233]\n",
      "epoch:1 step:1409 [D loss: 0.456910, acc.: 83.59%] [G loss: 0.414503]\n",
      "epoch:1 step:1410 [D loss: 0.545031, acc.: 71.88%] [G loss: 0.348641]\n",
      "epoch:1 step:1411 [D loss: 0.501293, acc.: 76.56%] [G loss: 0.415859]\n",
      "epoch:1 step:1412 [D loss: 0.416337, acc.: 85.94%] [G loss: 0.558732]\n",
      "epoch:1 step:1413 [D loss: 0.507897, acc.: 77.34%] [G loss: 0.454194]\n",
      "epoch:1 step:1414 [D loss: 0.594536, acc.: 69.53%] [G loss: 0.263550]\n",
      "epoch:1 step:1415 [D loss: 0.554473, acc.: 73.44%] [G loss: 0.268904]\n",
      "epoch:1 step:1416 [D loss: 0.577999, acc.: 70.31%] [G loss: 0.301390]\n",
      "epoch:1 step:1417 [D loss: 0.529104, acc.: 78.91%] [G loss: 0.361735]\n",
      "epoch:1 step:1418 [D loss: 0.540640, acc.: 72.66%] [G loss: 0.443343]\n",
      "epoch:1 step:1419 [D loss: 0.589035, acc.: 71.88%] [G loss: 0.260639]\n",
      "epoch:1 step:1420 [D loss: 0.535506, acc.: 74.22%] [G loss: 0.347894]\n",
      "epoch:1 step:1421 [D loss: 0.506594, acc.: 81.25%] [G loss: 0.386121]\n",
      "epoch:1 step:1422 [D loss: 0.529417, acc.: 75.78%] [G loss: 0.344684]\n",
      "epoch:1 step:1423 [D loss: 0.530346, acc.: 78.12%] [G loss: 0.390887]\n",
      "epoch:1 step:1424 [D loss: 0.453820, acc.: 80.47%] [G loss: 0.506156]\n",
      "epoch:1 step:1425 [D loss: 0.463962, acc.: 83.59%] [G loss: 0.458986]\n",
      "epoch:1 step:1426 [D loss: 0.590554, acc.: 71.88%] [G loss: 0.293196]\n",
      "epoch:1 step:1427 [D loss: 0.532713, acc.: 75.78%] [G loss: 0.307990]\n",
      "epoch:1 step:1428 [D loss: 0.476003, acc.: 79.69%] [G loss: 0.415609]\n",
      "epoch:1 step:1429 [D loss: 0.560757, acc.: 69.53%] [G loss: 0.312742]\n",
      "epoch:1 step:1430 [D loss: 0.489734, acc.: 81.25%] [G loss: 0.368939]\n",
      "epoch:1 step:1431 [D loss: 0.454293, acc.: 86.72%] [G loss: 0.393516]\n",
      "epoch:1 step:1432 [D loss: 0.529801, acc.: 75.78%] [G loss: 0.388302]\n",
      "epoch:1 step:1433 [D loss: 0.569221, acc.: 71.88%] [G loss: 0.377472]\n",
      "epoch:1 step:1434 [D loss: 0.475041, acc.: 80.47%] [G loss: 0.389066]\n",
      "epoch:1 step:1435 [D loss: 0.447940, acc.: 80.47%] [G loss: 0.559449]\n",
      "epoch:1 step:1436 [D loss: 0.455130, acc.: 82.81%] [G loss: 0.491033]\n",
      "epoch:1 step:1437 [D loss: 0.650989, acc.: 64.06%] [G loss: 0.243224]\n",
      "epoch:1 step:1438 [D loss: 0.603183, acc.: 70.31%] [G loss: 0.227173]\n",
      "epoch:1 step:1439 [D loss: 0.533636, acc.: 78.91%] [G loss: 0.288244]\n",
      "epoch:1 step:1440 [D loss: 0.441309, acc.: 84.38%] [G loss: 0.535995]\n",
      "epoch:1 step:1441 [D loss: 0.500965, acc.: 76.56%] [G loss: 0.470011]\n",
      "epoch:1 step:1442 [D loss: 0.569804, acc.: 75.00%] [G loss: 0.380193]\n",
      "epoch:1 step:1443 [D loss: 0.447675, acc.: 86.72%] [G loss: 0.372904]\n",
      "epoch:1 step:1444 [D loss: 0.491428, acc.: 80.47%] [G loss: 0.347205]\n",
      "epoch:1 step:1445 [D loss: 0.476526, acc.: 79.69%] [G loss: 0.397262]\n",
      "epoch:1 step:1446 [D loss: 0.543205, acc.: 75.00%] [G loss: 0.378056]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1 step:1447 [D loss: 0.505431, acc.: 74.22%] [G loss: 0.344886]\n",
      "epoch:1 step:1448 [D loss: 0.481419, acc.: 82.03%] [G loss: 0.402999]\n",
      "epoch:1 step:1449 [D loss: 0.496931, acc.: 75.78%] [G loss: 0.377317]\n",
      "epoch:1 step:1450 [D loss: 0.476235, acc.: 75.78%] [G loss: 0.401879]\n",
      "epoch:1 step:1451 [D loss: 0.477878, acc.: 86.72%] [G loss: 0.406249]\n",
      "epoch:1 step:1452 [D loss: 0.454511, acc.: 82.81%] [G loss: 0.422880]\n",
      "epoch:1 step:1453 [D loss: 0.447019, acc.: 91.41%] [G loss: 0.435872]\n",
      "epoch:1 step:1454 [D loss: 0.550625, acc.: 75.00%] [G loss: 0.327524]\n",
      "epoch:1 step:1455 [D loss: 0.451856, acc.: 86.72%] [G loss: 0.411738]\n",
      "epoch:1 step:1456 [D loss: 0.487135, acc.: 78.12%] [G loss: 0.406801]\n",
      "epoch:1 step:1457 [D loss: 0.472989, acc.: 81.25%] [G loss: 0.419835]\n",
      "epoch:1 step:1458 [D loss: 0.429162, acc.: 90.62%] [G loss: 0.462935]\n",
      "epoch:1 step:1459 [D loss: 0.458600, acc.: 82.03%] [G loss: 0.463344]\n",
      "epoch:1 step:1460 [D loss: 0.473577, acc.: 81.25%] [G loss: 0.388281]\n",
      "epoch:1 step:1461 [D loss: 0.431890, acc.: 85.16%] [G loss: 0.440333]\n",
      "epoch:1 step:1462 [D loss: 0.557909, acc.: 75.78%] [G loss: 0.380028]\n",
      "epoch:1 step:1463 [D loss: 0.426652, acc.: 85.94%] [G loss: 0.515882]\n",
      "epoch:1 step:1464 [D loss: 0.529458, acc.: 75.00%] [G loss: 0.368173]\n",
      "epoch:1 step:1465 [D loss: 0.517230, acc.: 72.66%] [G loss: 0.337977]\n",
      "epoch:1 step:1466 [D loss: 0.442904, acc.: 86.72%] [G loss: 0.379641]\n",
      "epoch:1 step:1467 [D loss: 0.454925, acc.: 85.94%] [G loss: 0.321887]\n",
      "epoch:1 step:1468 [D loss: 0.499795, acc.: 79.69%] [G loss: 0.418338]\n",
      "epoch:1 step:1469 [D loss: 0.498203, acc.: 78.91%] [G loss: 0.396772]\n",
      "epoch:1 step:1470 [D loss: 0.479477, acc.: 82.81%] [G loss: 0.418368]\n",
      "epoch:1 step:1471 [D loss: 0.426788, acc.: 85.94%] [G loss: 0.472061]\n",
      "epoch:1 step:1472 [D loss: 0.498642, acc.: 79.69%] [G loss: 0.392379]\n",
      "epoch:1 step:1473 [D loss: 0.499355, acc.: 78.12%] [G loss: 0.399434]\n",
      "epoch:1 step:1474 [D loss: 0.447307, acc.: 81.25%] [G loss: 0.471762]\n",
      "epoch:1 step:1475 [D loss: 0.470580, acc.: 84.38%] [G loss: 0.393351]\n",
      "epoch:1 step:1476 [D loss: 0.469293, acc.: 84.38%] [G loss: 0.410097]\n",
      "epoch:1 step:1477 [D loss: 0.477742, acc.: 81.25%] [G loss: 0.308418]\n",
      "epoch:1 step:1478 [D loss: 0.444690, acc.: 85.16%] [G loss: 0.458472]\n",
      "epoch:1 step:1479 [D loss: 0.534919, acc.: 76.56%] [G loss: 0.443128]\n",
      "epoch:1 step:1480 [D loss: 0.514601, acc.: 76.56%] [G loss: 0.390707]\n",
      "epoch:1 step:1481 [D loss: 0.491025, acc.: 78.91%] [G loss: 0.480020]\n",
      "epoch:1 step:1482 [D loss: 0.484315, acc.: 75.78%] [G loss: 0.589315]\n",
      "epoch:1 step:1483 [D loss: 0.480132, acc.: 77.34%] [G loss: 0.444290]\n",
      "epoch:1 step:1484 [D loss: 0.458010, acc.: 85.16%] [G loss: 0.407171]\n",
      "epoch:1 step:1485 [D loss: 0.453146, acc.: 81.25%] [G loss: 0.430230]\n",
      "epoch:1 step:1486 [D loss: 0.450483, acc.: 81.25%] [G loss: 0.506991]\n",
      "epoch:1 step:1487 [D loss: 0.544404, acc.: 74.22%] [G loss: 0.324231]\n",
      "epoch:1 step:1488 [D loss: 0.474999, acc.: 82.81%] [G loss: 0.377623]\n",
      "epoch:1 step:1489 [D loss: 0.491616, acc.: 80.47%] [G loss: 0.462344]\n",
      "epoch:1 step:1490 [D loss: 0.468982, acc.: 82.81%] [G loss: 0.360060]\n",
      "epoch:1 step:1491 [D loss: 0.447817, acc.: 80.47%] [G loss: 0.506349]\n",
      "epoch:1 step:1492 [D loss: 0.453130, acc.: 76.56%] [G loss: 0.607877]\n",
      "epoch:1 step:1493 [D loss: 0.467024, acc.: 82.81%] [G loss: 0.468932]\n",
      "epoch:1 step:1494 [D loss: 0.467179, acc.: 85.16%] [G loss: 0.463574]\n",
      "epoch:1 step:1495 [D loss: 0.414641, acc.: 85.94%] [G loss: 0.504962]\n",
      "epoch:1 step:1496 [D loss: 0.546675, acc.: 78.12%] [G loss: 0.461870]\n",
      "epoch:1 step:1497 [D loss: 0.487229, acc.: 79.69%] [G loss: 0.382622]\n",
      "epoch:1 step:1498 [D loss: 0.471173, acc.: 80.47%] [G loss: 0.486798]\n",
      "epoch:1 step:1499 [D loss: 0.570542, acc.: 71.88%] [G loss: 0.366959]\n",
      "epoch:1 step:1500 [D loss: 0.518501, acc.: 79.69%] [G loss: 0.423143]\n",
      "epoch:1 step:1501 [D loss: 0.500603, acc.: 80.47%] [G loss: 0.352274]\n",
      "epoch:1 step:1502 [D loss: 0.504600, acc.: 80.47%] [G loss: 0.433555]\n",
      "epoch:1 step:1503 [D loss: 0.509381, acc.: 76.56%] [G loss: 0.471943]\n",
      "epoch:1 step:1504 [D loss: 0.460563, acc.: 80.47%] [G loss: 0.498343]\n",
      "epoch:1 step:1505 [D loss: 0.480206, acc.: 80.47%] [G loss: 0.472398]\n",
      "epoch:1 step:1506 [D loss: 0.507194, acc.: 77.34%] [G loss: 0.447356]\n",
      "epoch:1 step:1507 [D loss: 0.454549, acc.: 81.25%] [G loss: 0.540967]\n",
      "epoch:1 step:1508 [D loss: 0.458085, acc.: 78.91%] [G loss: 0.479384]\n",
      "epoch:1 step:1509 [D loss: 0.474473, acc.: 78.91%] [G loss: 0.432329]\n",
      "epoch:1 step:1510 [D loss: 0.448887, acc.: 82.81%] [G loss: 0.450568]\n",
      "epoch:1 step:1511 [D loss: 0.453377, acc.: 80.47%] [G loss: 0.491311]\n",
      "epoch:1 step:1512 [D loss: 0.442347, acc.: 84.38%] [G loss: 0.489008]\n",
      "epoch:1 step:1513 [D loss: 0.517409, acc.: 77.34%] [G loss: 0.375172]\n",
      "epoch:1 step:1514 [D loss: 0.513701, acc.: 81.25%] [G loss: 0.391743]\n",
      "epoch:1 step:1515 [D loss: 0.453941, acc.: 81.25%] [G loss: 0.427460]\n",
      "epoch:1 step:1516 [D loss: 0.495727, acc.: 78.91%] [G loss: 0.503771]\n",
      "epoch:1 step:1517 [D loss: 0.500049, acc.: 78.12%] [G loss: 0.505117]\n",
      "epoch:1 step:1518 [D loss: 0.455424, acc.: 84.38%] [G loss: 0.525034]\n",
      "epoch:1 step:1519 [D loss: 0.492244, acc.: 73.44%] [G loss: 0.630154]\n",
      "epoch:1 step:1520 [D loss: 0.536904, acc.: 80.47%] [G loss: 0.495680]\n",
      "epoch:1 step:1521 [D loss: 0.588304, acc.: 67.97%] [G loss: 0.366999]\n",
      "epoch:1 step:1522 [D loss: 0.563073, acc.: 71.88%] [G loss: 0.346382]\n",
      "epoch:1 step:1523 [D loss: 0.518149, acc.: 78.91%] [G loss: 0.323069]\n",
      "epoch:1 step:1524 [D loss: 0.479375, acc.: 80.47%] [G loss: 0.430038]\n",
      "epoch:1 step:1525 [D loss: 0.515029, acc.: 76.56%] [G loss: 0.357214]\n",
      "epoch:1 step:1526 [D loss: 0.460685, acc.: 83.59%] [G loss: 0.471570]\n",
      "epoch:1 step:1527 [D loss: 0.458317, acc.: 82.81%] [G loss: 0.501254]\n",
      "epoch:1 step:1528 [D loss: 0.565065, acc.: 64.06%] [G loss: 0.383220]\n",
      "epoch:1 step:1529 [D loss: 0.439588, acc.: 83.59%] [G loss: 0.593636]\n",
      "epoch:1 step:1530 [D loss: 0.525181, acc.: 72.66%] [G loss: 0.460673]\n",
      "epoch:1 step:1531 [D loss: 0.497779, acc.: 81.25%] [G loss: 0.426316]\n",
      "epoch:1 step:1532 [D loss: 0.502355, acc.: 81.25%] [G loss: 0.304009]\n",
      "epoch:1 step:1533 [D loss: 0.499728, acc.: 73.44%] [G loss: 0.490525]\n",
      "epoch:1 step:1534 [D loss: 0.514984, acc.: 72.66%] [G loss: 0.378340]\n",
      "epoch:1 step:1535 [D loss: 0.456545, acc.: 85.16%] [G loss: 0.497638]\n",
      "epoch:1 step:1536 [D loss: 0.557310, acc.: 66.41%] [G loss: 0.382416]\n",
      "epoch:1 step:1537 [D loss: 0.527503, acc.: 72.66%] [G loss: 0.325302]\n",
      "epoch:1 step:1538 [D loss: 0.512969, acc.: 81.25%] [G loss: 0.343409]\n",
      "epoch:1 step:1539 [D loss: 0.448598, acc.: 85.16%] [G loss: 0.405449]\n",
      "epoch:1 step:1540 [D loss: 0.470985, acc.: 85.16%] [G loss: 0.448561]\n",
      "epoch:1 step:1541 [D loss: 0.559707, acc.: 72.66%] [G loss: 0.324555]\n",
      "epoch:1 step:1542 [D loss: 0.486242, acc.: 80.47%] [G loss: 0.390037]\n",
      "epoch:1 step:1543 [D loss: 0.451292, acc.: 86.72%] [G loss: 0.357499]\n",
      "epoch:1 step:1544 [D loss: 0.534064, acc.: 77.34%] [G loss: 0.358597]\n",
      "epoch:1 step:1545 [D loss: 0.545322, acc.: 76.56%] [G loss: 0.340695]\n",
      "epoch:1 step:1546 [D loss: 0.462233, acc.: 82.81%] [G loss: 0.444228]\n",
      "epoch:1 step:1547 [D loss: 0.512720, acc.: 78.12%] [G loss: 0.412133]\n",
      "epoch:1 step:1548 [D loss: 0.454518, acc.: 83.59%] [G loss: 0.444937]\n",
      "epoch:1 step:1549 [D loss: 0.459189, acc.: 82.03%] [G loss: 0.443203]\n",
      "epoch:1 step:1550 [D loss: 0.497596, acc.: 80.47%] [G loss: 0.424577]\n",
      "epoch:1 step:1551 [D loss: 0.450432, acc.: 82.81%] [G loss: 0.441948]\n",
      "epoch:1 step:1552 [D loss: 0.511296, acc.: 78.91%] [G loss: 0.320198]\n",
      "epoch:1 step:1553 [D loss: 0.520850, acc.: 74.22%] [G loss: 0.358034]\n",
      "epoch:1 step:1554 [D loss: 0.542583, acc.: 70.31%] [G loss: 0.379424]\n",
      "epoch:1 step:1555 [D loss: 0.455721, acc.: 85.16%] [G loss: 0.454043]\n",
      "epoch:1 step:1556 [D loss: 0.430121, acc.: 84.38%] [G loss: 0.465344]\n",
      "epoch:1 step:1557 [D loss: 0.477461, acc.: 78.91%] [G loss: 0.414692]\n",
      "epoch:1 step:1558 [D loss: 0.507640, acc.: 80.47%] [G loss: 0.387621]\n",
      "epoch:1 step:1559 [D loss: 0.633813, acc.: 67.19%] [G loss: 0.263720]\n",
      "epoch:1 step:1560 [D loss: 0.468281, acc.: 79.69%] [G loss: 0.402455]\n",
      "epoch:1 step:1561 [D loss: 0.515642, acc.: 75.78%] [G loss: 0.505655]\n",
      "epoch:1 step:1562 [D loss: 0.519470, acc.: 77.34%] [G loss: 0.474240]\n",
      "epoch:1 step:1563 [D loss: 0.485267, acc.: 79.69%] [G loss: 0.378308]\n",
      "epoch:1 step:1564 [D loss: 0.486266, acc.: 78.91%] [G loss: 0.361434]\n",
      "epoch:1 step:1565 [D loss: 0.464352, acc.: 83.59%] [G loss: 0.429733]\n",
      "epoch:1 step:1566 [D loss: 0.453369, acc.: 82.81%] [G loss: 0.448124]\n",
      "epoch:1 step:1567 [D loss: 0.470758, acc.: 82.81%] [G loss: 0.422515]\n",
      "epoch:1 step:1568 [D loss: 0.448936, acc.: 85.94%] [G loss: 0.490994]\n",
      "epoch:1 step:1569 [D loss: 0.441030, acc.: 82.81%] [G loss: 0.572241]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1 step:1570 [D loss: 0.440381, acc.: 84.38%] [G loss: 0.540192]\n",
      "epoch:1 step:1571 [D loss: 0.485367, acc.: 78.91%] [G loss: 0.477883]\n",
      "epoch:1 step:1572 [D loss: 0.434558, acc.: 84.38%] [G loss: 0.484922]\n",
      "epoch:1 step:1573 [D loss: 0.519156, acc.: 79.69%] [G loss: 0.463066]\n",
      "epoch:1 step:1574 [D loss: 0.472347, acc.: 83.59%] [G loss: 0.415753]\n",
      "epoch:1 step:1575 [D loss: 0.439581, acc.: 89.06%] [G loss: 0.466072]\n",
      "epoch:1 step:1576 [D loss: 0.396657, acc.: 89.84%] [G loss: 0.590579]\n",
      "epoch:1 step:1577 [D loss: 0.485278, acc.: 81.25%] [G loss: 0.576157]\n",
      "epoch:1 step:1578 [D loss: 0.440271, acc.: 84.38%] [G loss: 0.546418]\n",
      "epoch:1 step:1579 [D loss: 0.441651, acc.: 83.59%] [G loss: 0.455649]\n",
      "epoch:1 step:1580 [D loss: 0.474337, acc.: 83.59%] [G loss: 0.507150]\n",
      "epoch:1 step:1581 [D loss: 0.516272, acc.: 78.12%] [G loss: 0.412577]\n",
      "epoch:1 step:1582 [D loss: 0.476369, acc.: 79.69%] [G loss: 0.432053]\n",
      "epoch:1 step:1583 [D loss: 0.493383, acc.: 78.91%] [G loss: 0.387234]\n",
      "epoch:1 step:1584 [D loss: 0.494320, acc.: 81.25%] [G loss: 0.541371]\n",
      "epoch:1 step:1585 [D loss: 0.435995, acc.: 82.03%] [G loss: 0.693862]\n",
      "epoch:1 step:1586 [D loss: 0.483441, acc.: 82.81%] [G loss: 0.551574]\n",
      "epoch:1 step:1587 [D loss: 0.470656, acc.: 83.59%] [G loss: 0.502907]\n",
      "epoch:1 step:1588 [D loss: 0.490393, acc.: 78.12%] [G loss: 0.453358]\n",
      "epoch:1 step:1589 [D loss: 0.558458, acc.: 71.88%] [G loss: 0.485769]\n",
      "epoch:1 step:1590 [D loss: 0.520685, acc.: 74.22%] [G loss: 0.388555]\n",
      "epoch:1 step:1591 [D loss: 0.470855, acc.: 80.47%] [G loss: 0.411245]\n",
      "epoch:1 step:1592 [D loss: 0.508371, acc.: 78.12%] [G loss: 0.347841]\n",
      "epoch:1 step:1593 [D loss: 0.493990, acc.: 78.91%] [G loss: 0.449969]\n",
      "epoch:1 step:1594 [D loss: 0.505309, acc.: 76.56%] [G loss: 0.413189]\n",
      "epoch:1 step:1595 [D loss: 0.490176, acc.: 78.91%] [G loss: 0.404879]\n",
      "epoch:1 step:1596 [D loss: 0.475445, acc.: 79.69%] [G loss: 0.467270]\n",
      "epoch:1 step:1597 [D loss: 0.445398, acc.: 80.47%] [G loss: 0.398288]\n",
      "epoch:1 step:1598 [D loss: 0.453480, acc.: 83.59%] [G loss: 0.451811]\n",
      "epoch:1 step:1599 [D loss: 0.561923, acc.: 74.22%] [G loss: 0.496634]\n",
      "epoch:1 step:1600 [D loss: 0.464494, acc.: 85.94%] [G loss: 0.446654]\n",
      "##############\n",
      "[5.04599632 3.75695913 8.50214306 6.76970447 6.47556892 7.59481635\n",
      " 7.11969482 6.90238636 7.19432513 5.35596617]\n",
      "##########\n",
      "epoch:1 step:1601 [D loss: 0.461195, acc.: 80.47%] [G loss: 0.508077]\n",
      "epoch:1 step:1602 [D loss: 0.472085, acc.: 82.81%] [G loss: 0.520282]\n",
      "epoch:1 step:1603 [D loss: 0.446559, acc.: 85.94%] [G loss: 0.584620]\n",
      "epoch:1 step:1604 [D loss: 0.459494, acc.: 82.81%] [G loss: 0.585948]\n",
      "epoch:1 step:1605 [D loss: 0.503202, acc.: 82.03%] [G loss: 0.462889]\n",
      "epoch:1 step:1606 [D loss: 0.442400, acc.: 80.47%] [G loss: 0.451858]\n",
      "epoch:1 step:1607 [D loss: 0.473748, acc.: 82.81%] [G loss: 0.519239]\n",
      "epoch:1 step:1608 [D loss: 0.474175, acc.: 79.69%] [G loss: 0.520575]\n",
      "epoch:1 step:1609 [D loss: 0.526657, acc.: 76.56%] [G loss: 0.499479]\n",
      "epoch:1 step:1610 [D loss: 0.502419, acc.: 75.78%] [G loss: 0.427062]\n",
      "epoch:1 step:1611 [D loss: 0.460754, acc.: 82.03%] [G loss: 0.523535]\n",
      "epoch:1 step:1612 [D loss: 0.513723, acc.: 71.09%] [G loss: 0.493723]\n",
      "epoch:1 step:1613 [D loss: 0.447329, acc.: 86.72%] [G loss: 0.616009]\n",
      "epoch:1 step:1614 [D loss: 0.431534, acc.: 84.38%] [G loss: 0.555622]\n",
      "epoch:1 step:1615 [D loss: 0.447861, acc.: 85.94%] [G loss: 0.502120]\n",
      "epoch:1 step:1616 [D loss: 0.453978, acc.: 82.03%] [G loss: 0.506827]\n",
      "epoch:1 step:1617 [D loss: 0.403865, acc.: 87.50%] [G loss: 0.582878]\n",
      "epoch:1 step:1618 [D loss: 0.475925, acc.: 85.16%] [G loss: 0.463741]\n",
      "epoch:1 step:1619 [D loss: 0.527482, acc.: 76.56%] [G loss: 0.402098]\n",
      "epoch:1 step:1620 [D loss: 0.498080, acc.: 75.00%] [G loss: 0.462626]\n",
      "epoch:1 step:1621 [D loss: 0.471498, acc.: 78.91%] [G loss: 0.427088]\n",
      "epoch:1 step:1622 [D loss: 0.491886, acc.: 78.12%] [G loss: 0.443012]\n",
      "epoch:1 step:1623 [D loss: 0.436684, acc.: 88.28%] [G loss: 0.481590]\n",
      "epoch:1 step:1624 [D loss: 0.462740, acc.: 84.38%] [G loss: 0.570431]\n",
      "epoch:1 step:1625 [D loss: 0.541644, acc.: 76.56%] [G loss: 0.524423]\n",
      "epoch:1 step:1626 [D loss: 0.467313, acc.: 84.38%] [G loss: 0.545021]\n",
      "epoch:1 step:1627 [D loss: 0.499537, acc.: 77.34%] [G loss: 0.503116]\n",
      "epoch:1 step:1628 [D loss: 0.469816, acc.: 83.59%] [G loss: 0.511300]\n",
      "epoch:1 step:1629 [D loss: 0.480838, acc.: 81.25%] [G loss: 0.440705]\n",
      "epoch:1 step:1630 [D loss: 0.488449, acc.: 77.34%] [G loss: 0.482158]\n",
      "epoch:1 step:1631 [D loss: 0.431665, acc.: 82.81%] [G loss: 0.552135]\n",
      "epoch:1 step:1632 [D loss: 0.456909, acc.: 82.81%] [G loss: 0.569083]\n",
      "epoch:1 step:1633 [D loss: 0.516779, acc.: 75.00%] [G loss: 0.445811]\n",
      "epoch:1 step:1634 [D loss: 0.456826, acc.: 81.25%] [G loss: 0.640474]\n",
      "epoch:1 step:1635 [D loss: 0.509265, acc.: 77.34%] [G loss: 0.465116]\n",
      "epoch:1 step:1636 [D loss: 0.498440, acc.: 77.34%] [G loss: 0.499995]\n",
      "epoch:1 step:1637 [D loss: 0.496213, acc.: 75.78%] [G loss: 0.467260]\n",
      "epoch:1 step:1638 [D loss: 0.486826, acc.: 78.12%] [G loss: 0.444285]\n",
      "epoch:1 step:1639 [D loss: 0.501971, acc.: 78.12%] [G loss: 0.485543]\n",
      "epoch:1 step:1640 [D loss: 0.528958, acc.: 71.09%] [G loss: 0.483667]\n",
      "epoch:1 step:1641 [D loss: 0.566727, acc.: 70.31%] [G loss: 0.409949]\n",
      "epoch:1 step:1642 [D loss: 0.564635, acc.: 71.09%] [G loss: 0.410849]\n",
      "epoch:1 step:1643 [D loss: 0.516504, acc.: 75.00%] [G loss: 0.518151]\n",
      "epoch:1 step:1644 [D loss: 0.437255, acc.: 82.81%] [G loss: 0.687986]\n",
      "epoch:1 step:1645 [D loss: 0.482481, acc.: 78.91%] [G loss: 0.680487]\n",
      "epoch:1 step:1646 [D loss: 0.468396, acc.: 79.69%] [G loss: 0.650353]\n",
      "epoch:1 step:1647 [D loss: 0.638830, acc.: 64.06%] [G loss: 0.493386]\n",
      "epoch:1 step:1648 [D loss: 0.577482, acc.: 71.09%] [G loss: 0.410300]\n",
      "epoch:1 step:1649 [D loss: 0.485185, acc.: 73.44%] [G loss: 0.440832]\n",
      "epoch:1 step:1650 [D loss: 0.482223, acc.: 76.56%] [G loss: 0.441930]\n",
      "epoch:1 step:1651 [D loss: 0.451597, acc.: 80.47%] [G loss: 0.469687]\n",
      "epoch:1 step:1652 [D loss: 0.509566, acc.: 80.47%] [G loss: 0.436945]\n",
      "epoch:1 step:1653 [D loss: 0.562872, acc.: 72.66%] [G loss: 0.336062]\n",
      "epoch:1 step:1654 [D loss: 0.542885, acc.: 75.78%] [G loss: 0.327218]\n",
      "epoch:1 step:1655 [D loss: 0.522038, acc.: 78.91%] [G loss: 0.328264]\n",
      "epoch:1 step:1656 [D loss: 0.562257, acc.: 69.53%] [G loss: 0.323535]\n",
      "epoch:1 step:1657 [D loss: 0.550989, acc.: 72.66%] [G loss: 0.466014]\n",
      "epoch:1 step:1658 [D loss: 0.531067, acc.: 74.22%] [G loss: 0.479643]\n",
      "epoch:1 step:1659 [D loss: 0.519286, acc.: 76.56%] [G loss: 0.378188]\n",
      "epoch:1 step:1660 [D loss: 0.543768, acc.: 75.00%] [G loss: 0.475109]\n",
      "epoch:1 step:1661 [D loss: 0.467608, acc.: 82.81%] [G loss: 0.457900]\n",
      "epoch:1 step:1662 [D loss: 0.476295, acc.: 79.69%] [G loss: 0.532289]\n",
      "epoch:1 step:1663 [D loss: 0.507242, acc.: 75.78%] [G loss: 0.452892]\n",
      "epoch:1 step:1664 [D loss: 0.584371, acc.: 73.44%] [G loss: 0.349605]\n",
      "epoch:1 step:1665 [D loss: 0.481769, acc.: 80.47%] [G loss: 0.403387]\n",
      "epoch:1 step:1666 [D loss: 0.480794, acc.: 78.12%] [G loss: 0.565100]\n",
      "epoch:1 step:1667 [D loss: 0.472738, acc.: 82.03%] [G loss: 0.631878]\n",
      "epoch:1 step:1668 [D loss: 0.486131, acc.: 82.03%] [G loss: 0.512463]\n",
      "epoch:1 step:1669 [D loss: 0.451102, acc.: 79.69%] [G loss: 0.543809]\n",
      "epoch:1 step:1670 [D loss: 0.472726, acc.: 75.78%] [G loss: 0.576031]\n",
      "epoch:1 step:1671 [D loss: 0.464495, acc.: 82.03%] [G loss: 0.575933]\n",
      "epoch:1 step:1672 [D loss: 0.570839, acc.: 71.88%] [G loss: 0.534987]\n",
      "epoch:1 step:1673 [D loss: 0.451952, acc.: 79.69%] [G loss: 0.527217]\n",
      "epoch:1 step:1674 [D loss: 0.479595, acc.: 78.91%] [G loss: 0.508195]\n",
      "epoch:1 step:1675 [D loss: 0.532871, acc.: 73.44%] [G loss: 0.393494]\n",
      "epoch:1 step:1676 [D loss: 0.559972, acc.: 73.44%] [G loss: 0.458960]\n",
      "epoch:1 step:1677 [D loss: 0.556300, acc.: 72.66%] [G loss: 0.318112]\n",
      "epoch:1 step:1678 [D loss: 0.504303, acc.: 73.44%] [G loss: 0.355158]\n",
      "epoch:1 step:1679 [D loss: 0.541189, acc.: 72.66%] [G loss: 0.397463]\n",
      "epoch:1 step:1680 [D loss: 0.509084, acc.: 76.56%] [G loss: 0.403466]\n",
      "epoch:1 step:1681 [D loss: 0.533120, acc.: 78.91%] [G loss: 0.349157]\n",
      "epoch:1 step:1682 [D loss: 0.478031, acc.: 80.47%] [G loss: 0.388865]\n",
      "epoch:1 step:1683 [D loss: 0.435862, acc.: 82.03%] [G loss: 0.540115]\n",
      "epoch:1 step:1684 [D loss: 0.428247, acc.: 85.16%] [G loss: 0.512586]\n",
      "epoch:1 step:1685 [D loss: 0.431145, acc.: 89.06%] [G loss: 0.507156]\n",
      "epoch:1 step:1686 [D loss: 0.493297, acc.: 78.91%] [G loss: 0.462072]\n",
      "epoch:1 step:1687 [D loss: 0.520665, acc.: 73.44%] [G loss: 0.411106]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1 step:1688 [D loss: 0.497848, acc.: 77.34%] [G loss: 0.510180]\n",
      "epoch:1 step:1689 [D loss: 0.481829, acc.: 75.00%] [G loss: 0.477934]\n",
      "epoch:1 step:1690 [D loss: 0.468061, acc.: 75.78%] [G loss: 0.487933]\n",
      "epoch:1 step:1691 [D loss: 0.445552, acc.: 82.81%] [G loss: 0.481796]\n",
      "epoch:1 step:1692 [D loss: 0.482968, acc.: 75.78%] [G loss: 0.589953]\n",
      "epoch:1 step:1693 [D loss: 0.468438, acc.: 83.59%] [G loss: 0.597975]\n",
      "epoch:1 step:1694 [D loss: 0.437825, acc.: 83.59%] [G loss: 0.595135]\n",
      "epoch:1 step:1695 [D loss: 0.473590, acc.: 81.25%] [G loss: 0.544500]\n",
      "epoch:1 step:1696 [D loss: 0.468714, acc.: 82.03%] [G loss: 0.465441]\n",
      "epoch:1 step:1697 [D loss: 0.474458, acc.: 80.47%] [G loss: 0.469372]\n",
      "epoch:1 step:1698 [D loss: 0.483881, acc.: 79.69%] [G loss: 0.497124]\n",
      "epoch:1 step:1699 [D loss: 0.511960, acc.: 75.78%] [G loss: 0.527732]\n",
      "epoch:1 step:1700 [D loss: 0.532238, acc.: 71.09%] [G loss: 0.438934]\n",
      "epoch:1 step:1701 [D loss: 0.500912, acc.: 79.69%] [G loss: 0.475127]\n",
      "epoch:1 step:1702 [D loss: 0.626138, acc.: 61.72%] [G loss: 0.357305]\n",
      "epoch:1 step:1703 [D loss: 0.575974, acc.: 71.88%] [G loss: 0.337404]\n",
      "epoch:1 step:1704 [D loss: 0.529807, acc.: 78.91%] [G loss: 0.364566]\n",
      "epoch:1 step:1705 [D loss: 0.498261, acc.: 78.12%] [G loss: 0.474170]\n",
      "epoch:1 step:1706 [D loss: 0.444872, acc.: 82.03%] [G loss: 0.608403]\n",
      "epoch:1 step:1707 [D loss: 0.490538, acc.: 80.47%] [G loss: 0.476989]\n",
      "epoch:1 step:1708 [D loss: 0.516205, acc.: 78.91%] [G loss: 0.376338]\n",
      "epoch:1 step:1709 [D loss: 0.500547, acc.: 78.12%] [G loss: 0.396768]\n",
      "epoch:1 step:1710 [D loss: 0.471981, acc.: 82.81%] [G loss: 0.464450]\n",
      "epoch:1 step:1711 [D loss: 0.556747, acc.: 76.56%] [G loss: 0.390668]\n",
      "epoch:1 step:1712 [D loss: 0.479708, acc.: 81.25%] [G loss: 0.444129]\n",
      "epoch:1 step:1713 [D loss: 0.537737, acc.: 74.22%] [G loss: 0.421069]\n",
      "epoch:1 step:1714 [D loss: 0.481506, acc.: 82.03%] [G loss: 0.342569]\n",
      "epoch:1 step:1715 [D loss: 0.554350, acc.: 73.44%] [G loss: 0.351467]\n",
      "epoch:1 step:1716 [D loss: 0.512181, acc.: 82.03%] [G loss: 0.391611]\n",
      "epoch:1 step:1717 [D loss: 0.476329, acc.: 79.69%] [G loss: 0.466961]\n",
      "epoch:1 step:1718 [D loss: 0.490982, acc.: 78.91%] [G loss: 0.394144]\n",
      "epoch:1 step:1719 [D loss: 0.484523, acc.: 80.47%] [G loss: 0.518807]\n",
      "epoch:1 step:1720 [D loss: 0.506213, acc.: 73.44%] [G loss: 0.483472]\n",
      "epoch:1 step:1721 [D loss: 0.513655, acc.: 77.34%] [G loss: 0.399611]\n",
      "epoch:1 step:1722 [D loss: 0.483971, acc.: 81.25%] [G loss: 0.380409]\n",
      "epoch:1 step:1723 [D loss: 0.440364, acc.: 87.50%] [G loss: 0.393518]\n",
      "epoch:1 step:1724 [D loss: 0.517645, acc.: 77.34%] [G loss: 0.424950]\n",
      "epoch:1 step:1725 [D loss: 0.548605, acc.: 75.78%] [G loss: 0.385288]\n",
      "epoch:1 step:1726 [D loss: 0.499923, acc.: 79.69%] [G loss: 0.380144]\n",
      "epoch:1 step:1727 [D loss: 0.480895, acc.: 79.69%] [G loss: 0.438478]\n",
      "epoch:1 step:1728 [D loss: 0.419067, acc.: 85.94%] [G loss: 0.499900]\n",
      "epoch:1 step:1729 [D loss: 0.408399, acc.: 85.16%] [G loss: 0.609818]\n",
      "epoch:1 step:1730 [D loss: 0.488299, acc.: 80.47%] [G loss: 0.600384]\n",
      "epoch:1 step:1731 [D loss: 0.535682, acc.: 72.66%] [G loss: 0.497663]\n",
      "epoch:1 step:1732 [D loss: 0.444399, acc.: 83.59%] [G loss: 0.496540]\n",
      "epoch:1 step:1733 [D loss: 0.472009, acc.: 82.03%] [G loss: 0.603739]\n",
      "epoch:1 step:1734 [D loss: 0.483769, acc.: 79.69%] [G loss: 0.558894]\n",
      "epoch:1 step:1735 [D loss: 0.497024, acc.: 78.12%] [G loss: 0.470250]\n",
      "epoch:1 step:1736 [D loss: 0.559953, acc.: 75.00%] [G loss: 0.391780]\n",
      "epoch:1 step:1737 [D loss: 0.495028, acc.: 78.91%] [G loss: 0.521477]\n",
      "epoch:1 step:1738 [D loss: 0.467635, acc.: 84.38%] [G loss: 0.556511]\n",
      "epoch:1 step:1739 [D loss: 0.428213, acc.: 86.72%] [G loss: 0.591959]\n",
      "epoch:1 step:1740 [D loss: 0.497274, acc.: 78.12%] [G loss: 0.528937]\n",
      "epoch:1 step:1741 [D loss: 0.502593, acc.: 79.69%] [G loss: 0.509622]\n",
      "epoch:1 step:1742 [D loss: 0.449943, acc.: 80.47%] [G loss: 0.557921]\n",
      "epoch:1 step:1743 [D loss: 0.419401, acc.: 87.50%] [G loss: 0.620813]\n",
      "epoch:1 step:1744 [D loss: 0.459666, acc.: 82.81%] [G loss: 0.605979]\n",
      "epoch:1 step:1745 [D loss: 0.585642, acc.: 67.97%] [G loss: 0.414445]\n",
      "epoch:1 step:1746 [D loss: 0.542897, acc.: 77.34%] [G loss: 0.386271]\n",
      "epoch:1 step:1747 [D loss: 0.481937, acc.: 81.25%] [G loss: 0.452343]\n",
      "epoch:1 step:1748 [D loss: 0.552268, acc.: 73.44%] [G loss: 0.430940]\n",
      "epoch:1 step:1749 [D loss: 0.505164, acc.: 81.25%] [G loss: 0.447560]\n",
      "epoch:1 step:1750 [D loss: 0.522696, acc.: 75.00%] [G loss: 0.401764]\n",
      "epoch:1 step:1751 [D loss: 0.525062, acc.: 77.34%] [G loss: 0.413380]\n",
      "epoch:1 step:1752 [D loss: 0.473182, acc.: 85.94%] [G loss: 0.615177]\n",
      "epoch:1 step:1753 [D loss: 0.470195, acc.: 78.12%] [G loss: 0.540870]\n",
      "epoch:1 step:1754 [D loss: 0.527621, acc.: 78.12%] [G loss: 0.488915]\n",
      "epoch:1 step:1755 [D loss: 0.473047, acc.: 85.94%] [G loss: 0.407364]\n",
      "epoch:1 step:1756 [D loss: 0.496855, acc.: 78.91%] [G loss: 0.457780]\n",
      "epoch:1 step:1757 [D loss: 0.526129, acc.: 78.12%] [G loss: 0.470486]\n",
      "epoch:1 step:1758 [D loss: 0.512861, acc.: 75.00%] [G loss: 0.409315]\n",
      "epoch:1 step:1759 [D loss: 0.434244, acc.: 86.72%] [G loss: 0.528692]\n",
      "epoch:1 step:1760 [D loss: 0.475723, acc.: 78.12%] [G loss: 0.422992]\n",
      "epoch:1 step:1761 [D loss: 0.512806, acc.: 79.69%] [G loss: 0.373897]\n",
      "epoch:1 step:1762 [D loss: 0.499576, acc.: 75.00%] [G loss: 0.504342]\n",
      "epoch:1 step:1763 [D loss: 0.559340, acc.: 72.66%] [G loss: 0.396943]\n",
      "epoch:1 step:1764 [D loss: 0.573533, acc.: 70.31%] [G loss: 0.429193]\n",
      "epoch:1 step:1765 [D loss: 0.512306, acc.: 79.69%] [G loss: 0.460227]\n",
      "epoch:1 step:1766 [D loss: 0.510418, acc.: 72.66%] [G loss: 0.457514]\n",
      "epoch:1 step:1767 [D loss: 0.482043, acc.: 80.47%] [G loss: 0.468168]\n",
      "epoch:1 step:1768 [D loss: 0.517420, acc.: 82.03%] [G loss: 0.428461]\n",
      "epoch:1 step:1769 [D loss: 0.460812, acc.: 84.38%] [G loss: 0.459057]\n",
      "epoch:1 step:1770 [D loss: 0.499164, acc.: 79.69%] [G loss: 0.434416]\n",
      "epoch:1 step:1771 [D loss: 0.441815, acc.: 86.72%] [G loss: 0.504290]\n",
      "epoch:1 step:1772 [D loss: 0.504426, acc.: 75.78%] [G loss: 0.551718]\n",
      "epoch:1 step:1773 [D loss: 0.494663, acc.: 79.69%] [G loss: 0.543102]\n",
      "epoch:1 step:1774 [D loss: 0.461012, acc.: 82.03%] [G loss: 0.550299]\n",
      "epoch:1 step:1775 [D loss: 0.539453, acc.: 75.78%] [G loss: 0.508721]\n",
      "epoch:1 step:1776 [D loss: 0.497385, acc.: 78.91%] [G loss: 0.543503]\n",
      "epoch:1 step:1777 [D loss: 0.504735, acc.: 80.47%] [G loss: 0.503222]\n",
      "epoch:1 step:1778 [D loss: 0.471921, acc.: 78.12%] [G loss: 0.447048]\n",
      "epoch:1 step:1779 [D loss: 0.507134, acc.: 75.00%] [G loss: 0.547767]\n",
      "epoch:1 step:1780 [D loss: 0.549149, acc.: 73.44%] [G loss: 0.477975]\n",
      "epoch:1 step:1781 [D loss: 0.555570, acc.: 72.66%] [G loss: 0.372915]\n",
      "epoch:1 step:1782 [D loss: 0.510812, acc.: 77.34%] [G loss: 0.398404]\n",
      "epoch:1 step:1783 [D loss: 0.528798, acc.: 73.44%] [G loss: 0.337087]\n",
      "epoch:1 step:1784 [D loss: 0.483845, acc.: 83.59%] [G loss: 0.420768]\n",
      "epoch:1 step:1785 [D loss: 0.436558, acc.: 89.06%] [G loss: 0.479037]\n",
      "epoch:1 step:1786 [D loss: 0.505776, acc.: 80.47%] [G loss: 0.441159]\n",
      "epoch:1 step:1787 [D loss: 0.543008, acc.: 71.88%] [G loss: 0.416469]\n",
      "epoch:1 step:1788 [D loss: 0.489664, acc.: 81.25%] [G loss: 0.492485]\n",
      "epoch:1 step:1789 [D loss: 0.464569, acc.: 78.12%] [G loss: 0.510235]\n",
      "epoch:1 step:1790 [D loss: 0.496457, acc.: 82.03%] [G loss: 0.562226]\n",
      "epoch:1 step:1791 [D loss: 0.384999, acc.: 89.06%] [G loss: 0.696543]\n",
      "epoch:1 step:1792 [D loss: 0.487442, acc.: 78.91%] [G loss: 0.509046]\n",
      "epoch:1 step:1793 [D loss: 0.520097, acc.: 79.69%] [G loss: 0.421263]\n",
      "epoch:1 step:1794 [D loss: 0.456172, acc.: 82.03%] [G loss: 0.572646]\n",
      "epoch:1 step:1795 [D loss: 0.587206, acc.: 69.53%] [G loss: 0.423258]\n",
      "epoch:1 step:1796 [D loss: 0.494865, acc.: 79.69%] [G loss: 0.467259]\n",
      "epoch:1 step:1797 [D loss: 0.492336, acc.: 78.12%] [G loss: 0.543956]\n",
      "epoch:1 step:1798 [D loss: 0.515977, acc.: 78.12%] [G loss: 0.463157]\n",
      "epoch:1 step:1799 [D loss: 0.469929, acc.: 85.94%] [G loss: 0.499744]\n",
      "epoch:1 step:1800 [D loss: 0.474979, acc.: 82.03%] [G loss: 0.501033]\n",
      "##############\n",
      "[4.71561343 2.89614434 8.45951415 6.62360234 6.33084873 7.4668411\n",
      " 6.679023   6.86807964 6.78912955 5.47687862]\n",
      "##########\n",
      "epoch:1 step:1801 [D loss: 0.451798, acc.: 85.94%] [G loss: 0.553347]\n",
      "epoch:1 step:1802 [D loss: 0.458528, acc.: 86.72%] [G loss: 0.518912]\n",
      "epoch:1 step:1803 [D loss: 0.470055, acc.: 83.59%] [G loss: 0.464217]\n",
      "epoch:1 step:1804 [D loss: 0.540437, acc.: 75.00%] [G loss: 0.397019]\n",
      "epoch:1 step:1805 [D loss: 0.485305, acc.: 78.91%] [G loss: 0.540548]\n",
      "epoch:1 step:1806 [D loss: 0.458850, acc.: 87.50%] [G loss: 0.552409]\n",
      "epoch:1 step:1807 [D loss: 0.435530, acc.: 86.72%] [G loss: 0.597303]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1 step:1808 [D loss: 0.507785, acc.: 81.25%] [G loss: 0.515280]\n",
      "epoch:1 step:1809 [D loss: 0.477019, acc.: 83.59%] [G loss: 0.514887]\n",
      "epoch:1 step:1810 [D loss: 0.508934, acc.: 81.25%] [G loss: 0.468321]\n",
      "epoch:1 step:1811 [D loss: 0.535278, acc.: 75.78%] [G loss: 0.524678]\n",
      "epoch:1 step:1812 [D loss: 0.416248, acc.: 85.16%] [G loss: 0.673549]\n",
      "epoch:1 step:1813 [D loss: 0.509467, acc.: 78.91%] [G loss: 0.444539]\n",
      "epoch:1 step:1814 [D loss: 0.461108, acc.: 82.03%] [G loss: 0.580027]\n",
      "epoch:1 step:1815 [D loss: 0.524297, acc.: 76.56%] [G loss: 0.496925]\n",
      "epoch:1 step:1816 [D loss: 0.519121, acc.: 75.78%] [G loss: 0.451012]\n",
      "epoch:1 step:1817 [D loss: 0.548582, acc.: 68.75%] [G loss: 0.455933]\n",
      "epoch:1 step:1818 [D loss: 0.495244, acc.: 82.03%] [G loss: 0.565849]\n",
      "epoch:1 step:1819 [D loss: 0.530512, acc.: 77.34%] [G loss: 0.522657]\n",
      "epoch:1 step:1820 [D loss: 0.526593, acc.: 75.00%] [G loss: 0.455638]\n",
      "epoch:1 step:1821 [D loss: 0.480665, acc.: 82.03%] [G loss: 0.521841]\n",
      "epoch:1 step:1822 [D loss: 0.481218, acc.: 82.81%] [G loss: 0.587709]\n",
      "epoch:1 step:1823 [D loss: 0.420406, acc.: 87.50%] [G loss: 0.749606]\n",
      "epoch:1 step:1824 [D loss: 0.447161, acc.: 84.38%] [G loss: 0.639136]\n",
      "epoch:1 step:1825 [D loss: 0.461236, acc.: 78.12%] [G loss: 0.612736]\n",
      "epoch:1 step:1826 [D loss: 0.479083, acc.: 82.03%] [G loss: 0.614544]\n",
      "epoch:1 step:1827 [D loss: 0.451784, acc.: 84.38%] [G loss: 0.545559]\n",
      "epoch:1 step:1828 [D loss: 0.543867, acc.: 76.56%] [G loss: 0.387400]\n",
      "epoch:1 step:1829 [D loss: 0.596951, acc.: 67.19%] [G loss: 0.439082]\n",
      "epoch:1 step:1830 [D loss: 0.534205, acc.: 75.00%] [G loss: 0.500205]\n",
      "epoch:1 step:1831 [D loss: 0.495608, acc.: 76.56%] [G loss: 0.502645]\n",
      "epoch:1 step:1832 [D loss: 0.505503, acc.: 78.12%] [G loss: 0.507315]\n",
      "epoch:1 step:1833 [D loss: 0.544291, acc.: 75.78%] [G loss: 0.435630]\n",
      "epoch:1 step:1834 [D loss: 0.471292, acc.: 79.69%] [G loss: 0.500999]\n",
      "epoch:1 step:1835 [D loss: 0.436175, acc.: 89.06%] [G loss: 0.486986]\n",
      "epoch:1 step:1836 [D loss: 0.489387, acc.: 78.91%] [G loss: 0.590823]\n",
      "epoch:1 step:1837 [D loss: 0.468269, acc.: 79.69%] [G loss: 0.572646]\n",
      "epoch:1 step:1838 [D loss: 0.512631, acc.: 76.56%] [G loss: 0.566582]\n",
      "epoch:1 step:1839 [D loss: 0.551412, acc.: 71.88%] [G loss: 0.366312]\n",
      "epoch:1 step:1840 [D loss: 0.509568, acc.: 77.34%] [G loss: 0.486682]\n",
      "epoch:1 step:1841 [D loss: 0.481530, acc.: 77.34%] [G loss: 0.511855]\n",
      "epoch:1 step:1842 [D loss: 0.491817, acc.: 82.81%] [G loss: 0.614578]\n",
      "epoch:1 step:1843 [D loss: 0.508391, acc.: 78.12%] [G loss: 0.533810]\n",
      "epoch:1 step:1844 [D loss: 0.511148, acc.: 78.91%] [G loss: 0.414151]\n",
      "epoch:1 step:1845 [D loss: 0.480749, acc.: 80.47%] [G loss: 0.457152]\n",
      "epoch:1 step:1846 [D loss: 0.450681, acc.: 83.59%] [G loss: 0.639704]\n",
      "epoch:1 step:1847 [D loss: 0.410209, acc.: 85.94%] [G loss: 0.649754]\n",
      "epoch:1 step:1848 [D loss: 0.407618, acc.: 89.06%] [G loss: 0.637252]\n",
      "epoch:1 step:1849 [D loss: 0.500751, acc.: 75.00%] [G loss: 0.549152]\n",
      "epoch:1 step:1850 [D loss: 0.510750, acc.: 75.00%] [G loss: 0.458457]\n",
      "epoch:1 step:1851 [D loss: 0.467904, acc.: 78.91%] [G loss: 0.563766]\n",
      "epoch:1 step:1852 [D loss: 0.542564, acc.: 74.22%] [G loss: 0.428074]\n",
      "epoch:1 step:1853 [D loss: 0.551657, acc.: 75.00%] [G loss: 0.335978]\n",
      "epoch:1 step:1854 [D loss: 0.563657, acc.: 69.53%] [G loss: 0.330413]\n",
      "epoch:1 step:1855 [D loss: 0.417259, acc.: 92.19%] [G loss: 0.502527]\n",
      "epoch:1 step:1856 [D loss: 0.503128, acc.: 82.03%] [G loss: 0.457349]\n",
      "epoch:1 step:1857 [D loss: 0.535686, acc.: 74.22%] [G loss: 0.459191]\n",
      "epoch:1 step:1858 [D loss: 0.390045, acc.: 84.38%] [G loss: 0.688868]\n",
      "epoch:1 step:1859 [D loss: 0.551980, acc.: 73.44%] [G loss: 0.448028]\n",
      "epoch:1 step:1860 [D loss: 0.458136, acc.: 80.47%] [G loss: 0.426133]\n",
      "epoch:1 step:1861 [D loss: 0.436258, acc.: 82.03%] [G loss: 0.666975]\n",
      "epoch:1 step:1862 [D loss: 0.383769, acc.: 88.28%] [G loss: 0.743629]\n",
      "epoch:1 step:1863 [D loss: 0.417917, acc.: 82.81%] [G loss: 0.765026]\n",
      "epoch:1 step:1864 [D loss: 0.418596, acc.: 84.38%] [G loss: 0.860471]\n",
      "epoch:1 step:1865 [D loss: 0.784732, acc.: 60.94%] [G loss: 0.393202]\n",
      "epoch:1 step:1866 [D loss: 0.479765, acc.: 78.91%] [G loss: 0.634985]\n",
      "epoch:1 step:1867 [D loss: 0.384856, acc.: 85.94%] [G loss: 0.892850]\n",
      "epoch:1 step:1868 [D loss: 0.527319, acc.: 75.00%] [G loss: 0.554721]\n",
      "epoch:1 step:1869 [D loss: 0.554841, acc.: 70.31%] [G loss: 0.485204]\n",
      "epoch:1 step:1870 [D loss: 0.440723, acc.: 82.81%] [G loss: 0.520822]\n",
      "epoch:1 step:1871 [D loss: 0.489122, acc.: 80.47%] [G loss: 0.480947]\n",
      "epoch:1 step:1872 [D loss: 0.449587, acc.: 78.12%] [G loss: 0.614843]\n",
      "epoch:1 step:1873 [D loss: 0.316891, acc.: 93.75%] [G loss: 1.009393]\n",
      "epoch:1 step:1874 [D loss: 0.564993, acc.: 70.31%] [G loss: 0.730096]\n",
      "epoch:2 step:1875 [D loss: 0.534192, acc.: 73.44%] [G loss: 0.579888]\n",
      "epoch:2 step:1876 [D loss: 0.485884, acc.: 78.91%] [G loss: 0.533741]\n",
      "epoch:2 step:1877 [D loss: 0.505002, acc.: 75.00%] [G loss: 0.546377]\n",
      "epoch:2 step:1878 [D loss: 0.473855, acc.: 74.22%] [G loss: 0.647980]\n",
      "epoch:2 step:1879 [D loss: 0.464164, acc.: 84.38%] [G loss: 0.602913]\n",
      "epoch:2 step:1880 [D loss: 0.480992, acc.: 78.12%] [G loss: 0.505719]\n",
      "epoch:2 step:1881 [D loss: 0.458883, acc.: 85.16%] [G loss: 0.501761]\n",
      "epoch:2 step:1882 [D loss: 0.467581, acc.: 80.47%] [G loss: 0.510703]\n",
      "epoch:2 step:1883 [D loss: 0.477674, acc.: 80.47%] [G loss: 0.601821]\n",
      "epoch:2 step:1884 [D loss: 0.502271, acc.: 78.91%] [G loss: 0.513227]\n",
      "epoch:2 step:1885 [D loss: 0.452768, acc.: 82.81%] [G loss: 0.502952]\n",
      "epoch:2 step:1886 [D loss: 0.488340, acc.: 78.91%] [G loss: 0.509738]\n",
      "epoch:2 step:1887 [D loss: 0.489222, acc.: 79.69%] [G loss: 0.602965]\n",
      "epoch:2 step:1888 [D loss: 0.517244, acc.: 82.03%] [G loss: 0.423550]\n",
      "epoch:2 step:1889 [D loss: 0.454276, acc.: 85.94%] [G loss: 0.370120]\n",
      "epoch:2 step:1890 [D loss: 0.422598, acc.: 88.28%] [G loss: 0.461233]\n",
      "epoch:2 step:1891 [D loss: 0.587588, acc.: 64.84%] [G loss: 0.450131]\n",
      "epoch:2 step:1892 [D loss: 0.529841, acc.: 74.22%] [G loss: 0.454683]\n",
      "epoch:2 step:1893 [D loss: 0.513916, acc.: 76.56%] [G loss: 0.493351]\n",
      "epoch:2 step:1894 [D loss: 0.529524, acc.: 76.56%] [G loss: 0.459166]\n",
      "epoch:2 step:1895 [D loss: 0.477684, acc.: 84.38%] [G loss: 0.409985]\n",
      "epoch:2 step:1896 [D loss: 0.425439, acc.: 83.59%] [G loss: 0.650108]\n",
      "epoch:2 step:1897 [D loss: 0.469327, acc.: 82.03%] [G loss: 0.668864]\n",
      "epoch:2 step:1898 [D loss: 0.463992, acc.: 79.69%] [G loss: 0.495663]\n",
      "epoch:2 step:1899 [D loss: 0.462350, acc.: 82.81%] [G loss: 0.514354]\n",
      "epoch:2 step:1900 [D loss: 0.500515, acc.: 80.47%] [G loss: 0.451832]\n",
      "epoch:2 step:1901 [D loss: 0.449508, acc.: 83.59%] [G loss: 0.463463]\n",
      "epoch:2 step:1902 [D loss: 0.467237, acc.: 84.38%] [G loss: 0.549348]\n",
      "epoch:2 step:1903 [D loss: 0.444531, acc.: 82.81%] [G loss: 0.606010]\n",
      "epoch:2 step:1904 [D loss: 0.473479, acc.: 78.91%] [G loss: 0.461899]\n",
      "epoch:2 step:1905 [D loss: 0.435965, acc.: 85.16%] [G loss: 0.625940]\n",
      "epoch:2 step:1906 [D loss: 0.488767, acc.: 78.91%] [G loss: 0.571475]\n",
      "epoch:2 step:1907 [D loss: 0.410975, acc.: 84.38%] [G loss: 0.624071]\n",
      "epoch:2 step:1908 [D loss: 0.418607, acc.: 85.16%] [G loss: 0.632775]\n",
      "epoch:2 step:1909 [D loss: 0.419119, acc.: 86.72%] [G loss: 0.684939]\n",
      "epoch:2 step:1910 [D loss: 0.399465, acc.: 86.72%] [G loss: 0.884329]\n",
      "epoch:2 step:1911 [D loss: 0.520749, acc.: 78.91%] [G loss: 0.458034]\n",
      "epoch:2 step:1912 [D loss: 0.566827, acc.: 72.66%] [G loss: 0.486226]\n",
      "epoch:2 step:1913 [D loss: 0.456656, acc.: 82.81%] [G loss: 0.706056]\n",
      "epoch:2 step:1914 [D loss: 0.461995, acc.: 77.34%] [G loss: 0.628309]\n",
      "epoch:2 step:1915 [D loss: 0.478188, acc.: 81.25%] [G loss: 0.534467]\n",
      "epoch:2 step:1916 [D loss: 0.512876, acc.: 75.00%] [G loss: 0.497686]\n",
      "epoch:2 step:1917 [D loss: 0.464249, acc.: 82.03%] [G loss: 0.420234]\n",
      "epoch:2 step:1918 [D loss: 0.489349, acc.: 75.78%] [G loss: 0.554716]\n",
      "epoch:2 step:1919 [D loss: 0.483052, acc.: 79.69%] [G loss: 0.508708]\n",
      "epoch:2 step:1920 [D loss: 0.440013, acc.: 87.50%] [G loss: 0.526284]\n",
      "epoch:2 step:1921 [D loss: 0.507597, acc.: 77.34%] [G loss: 0.410597]\n",
      "epoch:2 step:1922 [D loss: 0.475895, acc.: 81.25%] [G loss: 0.452758]\n",
      "epoch:2 step:1923 [D loss: 0.506374, acc.: 78.12%] [G loss: 0.396774]\n",
      "epoch:2 step:1924 [D loss: 0.477441, acc.: 82.81%] [G loss: 0.374619]\n",
      "epoch:2 step:1925 [D loss: 0.463609, acc.: 85.16%] [G loss: 0.507935]\n",
      "epoch:2 step:1926 [D loss: 0.532548, acc.: 73.44%] [G loss: 0.441007]\n",
      "epoch:2 step:1927 [D loss: 0.452289, acc.: 79.69%] [G loss: 0.697228]\n",
      "epoch:2 step:1928 [D loss: 0.461524, acc.: 82.81%] [G loss: 0.611748]\n",
      "epoch:2 step:1929 [D loss: 0.481082, acc.: 83.59%] [G loss: 0.553529]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:2 step:1930 [D loss: 0.498443, acc.: 73.44%] [G loss: 0.582920]\n",
      "epoch:2 step:1931 [D loss: 0.495505, acc.: 76.56%] [G loss: 0.494352]\n",
      "epoch:2 step:1932 [D loss: 0.469314, acc.: 81.25%] [G loss: 0.545968]\n",
      "epoch:2 step:1933 [D loss: 0.471962, acc.: 77.34%] [G loss: 0.606429]\n",
      "epoch:2 step:1934 [D loss: 0.438034, acc.: 82.03%] [G loss: 0.675024]\n",
      "epoch:2 step:1935 [D loss: 0.528424, acc.: 75.00%] [G loss: 0.501924]\n",
      "epoch:2 step:1936 [D loss: 0.529732, acc.: 73.44%] [G loss: 0.424785]\n",
      "epoch:2 step:1937 [D loss: 0.502658, acc.: 78.12%] [G loss: 0.401443]\n",
      "epoch:2 step:1938 [D loss: 0.521478, acc.: 78.91%] [G loss: 0.384759]\n",
      "epoch:2 step:1939 [D loss: 0.515458, acc.: 78.91%] [G loss: 0.365590]\n",
      "epoch:2 step:1940 [D loss: 0.522630, acc.: 75.00%] [G loss: 0.408206]\n",
      "epoch:2 step:1941 [D loss: 0.505071, acc.: 76.56%] [G loss: 0.399726]\n",
      "epoch:2 step:1942 [D loss: 0.459196, acc.: 84.38%] [G loss: 0.497438]\n",
      "epoch:2 step:1943 [D loss: 0.519031, acc.: 72.66%] [G loss: 0.436788]\n",
      "epoch:2 step:1944 [D loss: 0.498191, acc.: 78.91%] [G loss: 0.479047]\n",
      "epoch:2 step:1945 [D loss: 0.501840, acc.: 78.91%] [G loss: 0.498473]\n",
      "epoch:2 step:1946 [D loss: 0.447715, acc.: 85.16%] [G loss: 0.556604]\n",
      "epoch:2 step:1947 [D loss: 0.483185, acc.: 79.69%] [G loss: 0.490655]\n",
      "epoch:2 step:1948 [D loss: 0.516628, acc.: 71.88%] [G loss: 0.457433]\n",
      "epoch:2 step:1949 [D loss: 0.423759, acc.: 83.59%] [G loss: 0.773982]\n",
      "epoch:2 step:1950 [D loss: 0.407467, acc.: 83.59%] [G loss: 0.842009]\n",
      "epoch:2 step:1951 [D loss: 0.392809, acc.: 85.94%] [G loss: 0.820211]\n",
      "epoch:2 step:1952 [D loss: 0.589700, acc.: 69.53%] [G loss: 0.503321]\n",
      "epoch:2 step:1953 [D loss: 0.541641, acc.: 73.44%] [G loss: 0.445571]\n",
      "epoch:2 step:1954 [D loss: 0.577575, acc.: 70.31%] [G loss: 0.445812]\n",
      "epoch:2 step:1955 [D loss: 0.521979, acc.: 78.91%] [G loss: 0.457370]\n",
      "epoch:2 step:1956 [D loss: 0.480832, acc.: 81.25%] [G loss: 0.474792]\n",
      "epoch:2 step:1957 [D loss: 0.479064, acc.: 76.56%] [G loss: 0.475969]\n",
      "epoch:2 step:1958 [D loss: 0.483420, acc.: 80.47%] [G loss: 0.555742]\n",
      "epoch:2 step:1959 [D loss: 0.501354, acc.: 77.34%] [G loss: 0.517044]\n",
      "epoch:2 step:1960 [D loss: 0.506791, acc.: 79.69%] [G loss: 0.566009]\n",
      "epoch:2 step:1961 [D loss: 0.437759, acc.: 87.50%] [G loss: 0.622555]\n",
      "epoch:2 step:1962 [D loss: 0.524357, acc.: 81.25%] [G loss: 0.560248]\n",
      "epoch:2 step:1963 [D loss: 0.549593, acc.: 76.56%] [G loss: 0.380237]\n",
      "epoch:2 step:1964 [D loss: 0.472581, acc.: 78.12%] [G loss: 0.477198]\n",
      "epoch:2 step:1965 [D loss: 0.496826, acc.: 76.56%] [G loss: 0.559198]\n",
      "epoch:2 step:1966 [D loss: 0.549485, acc.: 70.31%] [G loss: 0.504075]\n",
      "epoch:2 step:1967 [D loss: 0.468794, acc.: 82.03%] [G loss: 0.584424]\n",
      "epoch:2 step:1968 [D loss: 0.443103, acc.: 84.38%] [G loss: 0.541762]\n",
      "epoch:2 step:1969 [D loss: 0.462763, acc.: 78.12%] [G loss: 0.567060]\n",
      "epoch:2 step:1970 [D loss: 0.418132, acc.: 85.94%] [G loss: 0.489711]\n",
      "epoch:2 step:1971 [D loss: 0.512445, acc.: 76.56%] [G loss: 0.567221]\n",
      "epoch:2 step:1972 [D loss: 0.517000, acc.: 75.00%] [G loss: 0.508606]\n",
      "epoch:2 step:1973 [D loss: 0.483242, acc.: 82.03%] [G loss: 0.449459]\n",
      "epoch:2 step:1974 [D loss: 0.464732, acc.: 83.59%] [G loss: 0.491102]\n",
      "epoch:2 step:1975 [D loss: 0.538936, acc.: 72.66%] [G loss: 0.508328]\n",
      "epoch:2 step:1976 [D loss: 0.529030, acc.: 78.12%] [G loss: 0.451640]\n",
      "epoch:2 step:1977 [D loss: 0.458309, acc.: 81.25%] [G loss: 0.491242]\n",
      "epoch:2 step:1978 [D loss: 0.525302, acc.: 73.44%] [G loss: 0.456098]\n",
      "epoch:2 step:1979 [D loss: 0.481018, acc.: 79.69%] [G loss: 0.539811]\n",
      "epoch:2 step:1980 [D loss: 0.579242, acc.: 67.97%] [G loss: 0.469686]\n",
      "epoch:2 step:1981 [D loss: 0.644997, acc.: 57.81%] [G loss: 0.445889]\n",
      "epoch:2 step:1982 [D loss: 0.537711, acc.: 78.12%] [G loss: 0.492996]\n",
      "epoch:2 step:1983 [D loss: 0.533296, acc.: 78.12%] [G loss: 0.474913]\n",
      "epoch:2 step:1984 [D loss: 0.541638, acc.: 73.44%] [G loss: 0.590112]\n",
      "epoch:2 step:1985 [D loss: 0.505316, acc.: 78.91%] [G loss: 0.459287]\n",
      "epoch:2 step:1986 [D loss: 0.503853, acc.: 80.47%] [G loss: 0.373318]\n",
      "epoch:2 step:1987 [D loss: 0.589843, acc.: 65.62%] [G loss: 0.329810]\n",
      "epoch:2 step:1988 [D loss: 0.583055, acc.: 71.09%] [G loss: 0.358627]\n",
      "epoch:2 step:1989 [D loss: 0.564672, acc.: 71.09%] [G loss: 0.529979]\n",
      "epoch:2 step:1990 [D loss: 0.557521, acc.: 77.34%] [G loss: 0.523258]\n",
      "epoch:2 step:1991 [D loss: 0.488075, acc.: 81.25%] [G loss: 0.648377]\n",
      "epoch:2 step:1992 [D loss: 0.502732, acc.: 78.91%] [G loss: 0.543741]\n",
      "epoch:2 step:1993 [D loss: 0.461458, acc.: 85.94%] [G loss: 0.602146]\n",
      "epoch:2 step:1994 [D loss: 0.596792, acc.: 67.97%] [G loss: 0.412192]\n",
      "epoch:2 step:1995 [D loss: 0.505248, acc.: 79.69%] [G loss: 0.434119]\n",
      "epoch:2 step:1996 [D loss: 0.507812, acc.: 78.12%] [G loss: 0.526338]\n",
      "epoch:2 step:1997 [D loss: 0.567627, acc.: 71.09%] [G loss: 0.448823]\n",
      "epoch:2 step:1998 [D loss: 0.567436, acc.: 71.09%] [G loss: 0.424865]\n",
      "epoch:2 step:1999 [D loss: 0.502012, acc.: 81.25%] [G loss: 0.470580]\n",
      "epoch:2 step:2000 [D loss: 0.479296, acc.: 82.03%] [G loss: 0.439838]\n",
      "##############\n",
      "[4.52524905 2.41321278 8.3576067  6.2732108  5.78360471 7.60604611\n",
      " 6.76358833 6.58428636 6.64234375 5.37461369]\n",
      "##########\n",
      "epoch:2 step:2001 [D loss: 0.514935, acc.: 78.12%] [G loss: 0.477716]\n",
      "epoch:2 step:2002 [D loss: 0.513962, acc.: 77.34%] [G loss: 0.389426]\n",
      "epoch:2 step:2003 [D loss: 0.521789, acc.: 75.00%] [G loss: 0.475723]\n",
      "epoch:2 step:2004 [D loss: 0.487151, acc.: 77.34%] [G loss: 0.393291]\n",
      "epoch:2 step:2005 [D loss: 0.437121, acc.: 84.38%] [G loss: 0.607725]\n",
      "epoch:2 step:2006 [D loss: 0.496954, acc.: 78.12%] [G loss: 0.526572]\n",
      "epoch:2 step:2007 [D loss: 0.579543, acc.: 70.31%] [G loss: 0.378656]\n",
      "epoch:2 step:2008 [D loss: 0.497723, acc.: 79.69%] [G loss: 0.437877]\n",
      "epoch:2 step:2009 [D loss: 0.441647, acc.: 87.50%] [G loss: 0.554055]\n",
      "epoch:2 step:2010 [D loss: 0.513819, acc.: 78.91%] [G loss: 0.510099]\n",
      "epoch:2 step:2011 [D loss: 0.540127, acc.: 71.09%] [G loss: 0.416302]\n",
      "epoch:2 step:2012 [D loss: 0.513172, acc.: 73.44%] [G loss: 0.403988]\n",
      "epoch:2 step:2013 [D loss: 0.543813, acc.: 78.12%] [G loss: 0.519752]\n",
      "epoch:2 step:2014 [D loss: 0.457755, acc.: 83.59%] [G loss: 0.484170]\n",
      "epoch:2 step:2015 [D loss: 0.459364, acc.: 82.81%] [G loss: 0.536900]\n",
      "epoch:2 step:2016 [D loss: 0.454168, acc.: 85.94%] [G loss: 0.497867]\n",
      "epoch:2 step:2017 [D loss: 0.544532, acc.: 71.88%] [G loss: 0.457433]\n",
      "epoch:2 step:2018 [D loss: 0.508003, acc.: 76.56%] [G loss: 0.517695]\n",
      "epoch:2 step:2019 [D loss: 0.482723, acc.: 80.47%] [G loss: 0.510569]\n",
      "epoch:2 step:2020 [D loss: 0.501980, acc.: 79.69%] [G loss: 0.446935]\n",
      "epoch:2 step:2021 [D loss: 0.529495, acc.: 75.78%] [G loss: 0.391042]\n",
      "epoch:2 step:2022 [D loss: 0.483506, acc.: 79.69%] [G loss: 0.417024]\n",
      "epoch:2 step:2023 [D loss: 0.409884, acc.: 85.16%] [G loss: 0.608402]\n",
      "epoch:2 step:2024 [D loss: 0.554110, acc.: 75.00%] [G loss: 0.560429]\n",
      "epoch:2 step:2025 [D loss: 0.468392, acc.: 81.25%] [G loss: 0.520680]\n",
      "epoch:2 step:2026 [D loss: 0.467607, acc.: 79.69%] [G loss: 0.687794]\n",
      "epoch:2 step:2027 [D loss: 0.515851, acc.: 75.78%] [G loss: 0.521490]\n",
      "epoch:2 step:2028 [D loss: 0.512745, acc.: 74.22%] [G loss: 0.394025]\n",
      "epoch:2 step:2029 [D loss: 0.463361, acc.: 80.47%] [G loss: 0.472402]\n",
      "epoch:2 step:2030 [D loss: 0.499247, acc.: 79.69%] [G loss: 0.513816]\n",
      "epoch:2 step:2031 [D loss: 0.458151, acc.: 82.81%] [G loss: 0.533547]\n",
      "epoch:2 step:2032 [D loss: 0.523359, acc.: 78.12%] [G loss: 0.428941]\n",
      "epoch:2 step:2033 [D loss: 0.479869, acc.: 78.91%] [G loss: 0.566251]\n",
      "epoch:2 step:2034 [D loss: 0.607658, acc.: 70.31%] [G loss: 0.413737]\n",
      "epoch:2 step:2035 [D loss: 0.575291, acc.: 71.88%] [G loss: 0.446496]\n",
      "epoch:2 step:2036 [D loss: 0.393441, acc.: 86.72%] [G loss: 0.480082]\n",
      "epoch:2 step:2037 [D loss: 0.488419, acc.: 80.47%] [G loss: 0.548249]\n",
      "epoch:2 step:2038 [D loss: 0.542025, acc.: 75.78%] [G loss: 0.521561]\n",
      "epoch:2 step:2039 [D loss: 0.489595, acc.: 79.69%] [G loss: 0.523968]\n",
      "epoch:2 step:2040 [D loss: 0.513678, acc.: 77.34%] [G loss: 0.479779]\n",
      "epoch:2 step:2041 [D loss: 0.498479, acc.: 78.91%] [G loss: 0.514210]\n",
      "epoch:2 step:2042 [D loss: 0.483777, acc.: 81.25%] [G loss: 0.526241]\n",
      "epoch:2 step:2043 [D loss: 0.502563, acc.: 77.34%] [G loss: 0.425727]\n",
      "epoch:2 step:2044 [D loss: 0.467941, acc.: 84.38%] [G loss: 0.444466]\n",
      "epoch:2 step:2045 [D loss: 0.477575, acc.: 82.03%] [G loss: 0.441916]\n",
      "epoch:2 step:2046 [D loss: 0.471486, acc.: 78.12%] [G loss: 0.468455]\n",
      "epoch:2 step:2047 [D loss: 0.462319, acc.: 84.38%] [G loss: 0.524296]\n",
      "epoch:2 step:2048 [D loss: 0.530907, acc.: 70.31%] [G loss: 0.512482]\n",
      "epoch:2 step:2049 [D loss: 0.486571, acc.: 81.25%] [G loss: 0.589402]\n",
      "epoch:2 step:2050 [D loss: 0.455562, acc.: 82.03%] [G loss: 0.614059]\n",
      "epoch:2 step:2051 [D loss: 0.491489, acc.: 78.12%] [G loss: 0.552035]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:2 step:2052 [D loss: 0.464105, acc.: 81.25%] [G loss: 0.523454]\n",
      "epoch:2 step:2053 [D loss: 0.488172, acc.: 75.78%] [G loss: 0.478320]\n",
      "epoch:2 step:2054 [D loss: 0.490078, acc.: 80.47%] [G loss: 0.505702]\n",
      "epoch:2 step:2055 [D loss: 0.452669, acc.: 80.47%] [G loss: 0.487822]\n",
      "epoch:2 step:2056 [D loss: 0.557918, acc.: 75.78%] [G loss: 0.425049]\n",
      "epoch:2 step:2057 [D loss: 0.493039, acc.: 74.22%] [G loss: 0.465155]\n",
      "epoch:2 step:2058 [D loss: 0.474021, acc.: 85.16%] [G loss: 0.475123]\n",
      "epoch:2 step:2059 [D loss: 0.547323, acc.: 75.78%] [G loss: 0.451119]\n",
      "epoch:2 step:2060 [D loss: 0.489895, acc.: 77.34%] [G loss: 0.454060]\n",
      "epoch:2 step:2061 [D loss: 0.572594, acc.: 69.53%] [G loss: 0.425615]\n",
      "epoch:2 step:2062 [D loss: 0.428529, acc.: 84.38%] [G loss: 0.538441]\n",
      "epoch:2 step:2063 [D loss: 0.487447, acc.: 78.12%] [G loss: 0.482573]\n",
      "epoch:2 step:2064 [D loss: 0.439475, acc.: 83.59%] [G loss: 0.588593]\n",
      "epoch:2 step:2065 [D loss: 0.464663, acc.: 82.03%] [G loss: 0.679198]\n",
      "epoch:2 step:2066 [D loss: 0.505503, acc.: 78.91%] [G loss: 0.644332]\n",
      "epoch:2 step:2067 [D loss: 0.472872, acc.: 85.94%] [G loss: 0.506635]\n",
      "epoch:2 step:2068 [D loss: 0.441604, acc.: 85.16%] [G loss: 0.524763]\n",
      "epoch:2 step:2069 [D loss: 0.557072, acc.: 73.44%] [G loss: 0.441438]\n",
      "epoch:2 step:2070 [D loss: 0.539932, acc.: 77.34%] [G loss: 0.476272]\n",
      "epoch:2 step:2071 [D loss: 0.501992, acc.: 75.00%] [G loss: 0.513663]\n",
      "epoch:2 step:2072 [D loss: 0.517598, acc.: 74.22%] [G loss: 0.628635]\n",
      "epoch:2 step:2073 [D loss: 0.513119, acc.: 75.78%] [G loss: 0.629455]\n",
      "epoch:2 step:2074 [D loss: 0.548090, acc.: 71.88%] [G loss: 0.467515]\n",
      "epoch:2 step:2075 [D loss: 0.494608, acc.: 81.25%] [G loss: 0.408417]\n",
      "epoch:2 step:2076 [D loss: 0.564545, acc.: 69.53%] [G loss: 0.392656]\n",
      "epoch:2 step:2077 [D loss: 0.592472, acc.: 71.09%] [G loss: 0.339432]\n",
      "epoch:2 step:2078 [D loss: 0.522202, acc.: 78.12%] [G loss: 0.323208]\n",
      "epoch:2 step:2079 [D loss: 0.502652, acc.: 76.56%] [G loss: 0.512571]\n",
      "epoch:2 step:2080 [D loss: 0.498638, acc.: 79.69%] [G loss: 0.512860]\n",
      "epoch:2 step:2081 [D loss: 0.436427, acc.: 86.72%] [G loss: 0.539759]\n",
      "epoch:2 step:2082 [D loss: 0.397076, acc.: 88.28%] [G loss: 0.645962]\n",
      "epoch:2 step:2083 [D loss: 0.514779, acc.: 77.34%] [G loss: 0.618475]\n",
      "epoch:2 step:2084 [D loss: 0.552210, acc.: 71.09%] [G loss: 0.458008]\n",
      "epoch:2 step:2085 [D loss: 0.515509, acc.: 78.12%] [G loss: 0.422090]\n",
      "epoch:2 step:2086 [D loss: 0.521307, acc.: 77.34%] [G loss: 0.414922]\n",
      "epoch:2 step:2087 [D loss: 0.500003, acc.: 78.12%] [G loss: 0.469402]\n",
      "epoch:2 step:2088 [D loss: 0.628866, acc.: 61.72%] [G loss: 0.329998]\n",
      "epoch:2 step:2089 [D loss: 0.541927, acc.: 75.78%] [G loss: 0.455896]\n",
      "epoch:2 step:2090 [D loss: 0.562041, acc.: 68.75%] [G loss: 0.374685]\n",
      "epoch:2 step:2091 [D loss: 0.483043, acc.: 80.47%] [G loss: 0.448869]\n",
      "epoch:2 step:2092 [D loss: 0.465538, acc.: 82.81%] [G loss: 0.484832]\n",
      "epoch:2 step:2093 [D loss: 0.518401, acc.: 79.69%] [G loss: 0.500111]\n",
      "epoch:2 step:2094 [D loss: 0.600719, acc.: 66.41%] [G loss: 0.403793]\n",
      "epoch:2 step:2095 [D loss: 0.415281, acc.: 84.38%] [G loss: 0.630807]\n",
      "epoch:2 step:2096 [D loss: 0.541850, acc.: 67.97%] [G loss: 0.594920]\n",
      "epoch:2 step:2097 [D loss: 0.440568, acc.: 82.03%] [G loss: 0.795850]\n",
      "epoch:2 step:2098 [D loss: 0.530016, acc.: 68.75%] [G loss: 0.450097]\n",
      "epoch:2 step:2099 [D loss: 0.562813, acc.: 69.53%] [G loss: 0.460251]\n",
      "epoch:2 step:2100 [D loss: 0.556360, acc.: 69.53%] [G loss: 0.422684]\n",
      "epoch:2 step:2101 [D loss: 0.540605, acc.: 72.66%] [G loss: 0.415157]\n",
      "epoch:2 step:2102 [D loss: 0.524797, acc.: 76.56%] [G loss: 0.375497]\n",
      "epoch:2 step:2103 [D loss: 0.497931, acc.: 79.69%] [G loss: 0.465069]\n",
      "epoch:2 step:2104 [D loss: 0.470875, acc.: 83.59%] [G loss: 0.523797]\n",
      "epoch:2 step:2105 [D loss: 0.483560, acc.: 78.91%] [G loss: 0.785703]\n",
      "epoch:2 step:2106 [D loss: 0.432753, acc.: 81.25%] [G loss: 0.907889]\n",
      "epoch:2 step:2107 [D loss: 0.537898, acc.: 76.56%] [G loss: 0.553371]\n",
      "epoch:2 step:2108 [D loss: 0.517391, acc.: 75.00%] [G loss: 0.379532]\n",
      "epoch:2 step:2109 [D loss: 0.494133, acc.: 78.12%] [G loss: 0.465699]\n",
      "epoch:2 step:2110 [D loss: 0.441687, acc.: 88.28%] [G loss: 0.524137]\n",
      "epoch:2 step:2111 [D loss: 0.526692, acc.: 74.22%] [G loss: 0.458163]\n",
      "epoch:2 step:2112 [D loss: 0.492295, acc.: 78.12%] [G loss: 0.557732]\n",
      "epoch:2 step:2113 [D loss: 0.501801, acc.: 78.12%] [G loss: 0.435054]\n",
      "epoch:2 step:2114 [D loss: 0.495916, acc.: 85.94%] [G loss: 0.497205]\n",
      "epoch:2 step:2115 [D loss: 0.521342, acc.: 75.78%] [G loss: 0.439441]\n",
      "epoch:2 step:2116 [D loss: 0.503318, acc.: 80.47%] [G loss: 0.381146]\n",
      "epoch:2 step:2117 [D loss: 0.450054, acc.: 87.50%] [G loss: 0.559891]\n",
      "epoch:2 step:2118 [D loss: 0.498071, acc.: 78.91%] [G loss: 0.465889]\n",
      "epoch:2 step:2119 [D loss: 0.530400, acc.: 78.12%] [G loss: 0.430077]\n",
      "epoch:2 step:2120 [D loss: 0.543385, acc.: 71.09%] [G loss: 0.384294]\n",
      "epoch:2 step:2121 [D loss: 0.528238, acc.: 78.91%] [G loss: 0.409536]\n",
      "epoch:2 step:2122 [D loss: 0.502800, acc.: 81.25%] [G loss: 0.414318]\n",
      "epoch:2 step:2123 [D loss: 0.537471, acc.: 72.66%] [G loss: 0.454368]\n",
      "epoch:2 step:2124 [D loss: 0.567311, acc.: 67.97%] [G loss: 0.284409]\n",
      "epoch:2 step:2125 [D loss: 0.560972, acc.: 71.88%] [G loss: 0.462254]\n",
      "epoch:2 step:2126 [D loss: 0.512292, acc.: 75.78%] [G loss: 0.457542]\n",
      "epoch:2 step:2127 [D loss: 0.527968, acc.: 74.22%] [G loss: 0.444637]\n",
      "epoch:2 step:2128 [D loss: 0.506419, acc.: 75.00%] [G loss: 0.429116]\n",
      "epoch:2 step:2129 [D loss: 0.481233, acc.: 78.91%] [G loss: 0.421538]\n",
      "epoch:2 step:2130 [D loss: 0.496727, acc.: 75.78%] [G loss: 0.481685]\n",
      "epoch:2 step:2131 [D loss: 0.560982, acc.: 67.19%] [G loss: 0.491625]\n",
      "epoch:2 step:2132 [D loss: 0.454479, acc.: 85.16%] [G loss: 0.615800]\n",
      "epoch:2 step:2133 [D loss: 0.485185, acc.: 78.91%] [G loss: 0.576291]\n",
      "epoch:2 step:2134 [D loss: 0.501747, acc.: 79.69%] [G loss: 0.539455]\n",
      "epoch:2 step:2135 [D loss: 0.488960, acc.: 76.56%] [G loss: 0.518314]\n",
      "epoch:2 step:2136 [D loss: 0.499310, acc.: 79.69%] [G loss: 0.542910]\n",
      "epoch:2 step:2137 [D loss: 0.612947, acc.: 68.75%] [G loss: 0.390157]\n",
      "epoch:2 step:2138 [D loss: 0.538138, acc.: 77.34%] [G loss: 0.316979]\n",
      "epoch:2 step:2139 [D loss: 0.519776, acc.: 74.22%] [G loss: 0.422974]\n",
      "epoch:2 step:2140 [D loss: 0.578731, acc.: 71.09%] [G loss: 0.397410]\n",
      "epoch:2 step:2141 [D loss: 0.549119, acc.: 69.53%] [G loss: 0.395561]\n",
      "epoch:2 step:2142 [D loss: 0.485382, acc.: 80.47%] [G loss: 0.461347]\n",
      "epoch:2 step:2143 [D loss: 0.541393, acc.: 76.56%] [G loss: 0.357626]\n",
      "epoch:2 step:2144 [D loss: 0.572731, acc.: 70.31%] [G loss: 0.305744]\n",
      "epoch:2 step:2145 [D loss: 0.451061, acc.: 85.94%] [G loss: 0.429005]\n",
      "epoch:2 step:2146 [D loss: 0.515107, acc.: 80.47%] [G loss: 0.461815]\n",
      "epoch:2 step:2147 [D loss: 0.474059, acc.: 80.47%] [G loss: 0.534703]\n",
      "epoch:2 step:2148 [D loss: 0.545261, acc.: 72.66%] [G loss: 0.412629]\n",
      "epoch:2 step:2149 [D loss: 0.575744, acc.: 73.44%] [G loss: 0.421902]\n",
      "epoch:2 step:2150 [D loss: 0.570077, acc.: 67.97%] [G loss: 0.308720]\n",
      "epoch:2 step:2151 [D loss: 0.555536, acc.: 71.88%] [G loss: 0.380433]\n",
      "epoch:2 step:2152 [D loss: 0.539334, acc.: 80.47%] [G loss: 0.437305]\n",
      "epoch:2 step:2153 [D loss: 0.496449, acc.: 75.78%] [G loss: 0.483838]\n",
      "epoch:2 step:2154 [D loss: 0.499007, acc.: 74.22%] [G loss: 0.546279]\n",
      "epoch:2 step:2155 [D loss: 0.581974, acc.: 69.53%] [G loss: 0.469237]\n",
      "epoch:2 step:2156 [D loss: 0.536736, acc.: 75.00%] [G loss: 0.355102]\n",
      "epoch:2 step:2157 [D loss: 0.498657, acc.: 79.69%] [G loss: 0.391013]\n",
      "epoch:2 step:2158 [D loss: 0.472421, acc.: 83.59%] [G loss: 0.476350]\n",
      "epoch:2 step:2159 [D loss: 0.463401, acc.: 82.03%] [G loss: 0.392644]\n",
      "epoch:2 step:2160 [D loss: 0.448893, acc.: 84.38%] [G loss: 0.464053]\n",
      "epoch:2 step:2161 [D loss: 0.521103, acc.: 74.22%] [G loss: 0.460392]\n",
      "epoch:2 step:2162 [D loss: 0.534649, acc.: 75.00%] [G loss: 0.467253]\n",
      "epoch:2 step:2163 [D loss: 0.471635, acc.: 78.12%] [G loss: 0.553958]\n",
      "epoch:2 step:2164 [D loss: 0.543782, acc.: 71.09%] [G loss: 0.379036]\n",
      "epoch:2 step:2165 [D loss: 0.518167, acc.: 79.69%] [G loss: 0.464620]\n",
      "epoch:2 step:2166 [D loss: 0.507691, acc.: 75.78%] [G loss: 0.500356]\n",
      "epoch:2 step:2167 [D loss: 0.488098, acc.: 82.81%] [G loss: 0.421276]\n",
      "epoch:2 step:2168 [D loss: 0.511100, acc.: 77.34%] [G loss: 0.397625]\n",
      "epoch:2 step:2169 [D loss: 0.466104, acc.: 80.47%] [G loss: 0.456011]\n",
      "epoch:2 step:2170 [D loss: 0.460991, acc.: 79.69%] [G loss: 0.475034]\n",
      "epoch:2 step:2171 [D loss: 0.546699, acc.: 74.22%] [G loss: 0.423055]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:2 step:2172 [D loss: 0.510341, acc.: 81.25%] [G loss: 0.459712]\n",
      "epoch:2 step:2173 [D loss: 0.477073, acc.: 79.69%] [G loss: 0.505852]\n",
      "epoch:2 step:2174 [D loss: 0.473462, acc.: 81.25%] [G loss: 0.586426]\n",
      "epoch:2 step:2175 [D loss: 0.591022, acc.: 72.66%] [G loss: 0.356444]\n",
      "epoch:2 step:2176 [D loss: 0.488283, acc.: 79.69%] [G loss: 0.461672]\n",
      "epoch:2 step:2177 [D loss: 0.462844, acc.: 79.69%] [G loss: 0.489132]\n",
      "epoch:2 step:2178 [D loss: 0.441666, acc.: 85.16%] [G loss: 0.559038]\n",
      "epoch:2 step:2179 [D loss: 0.499981, acc.: 79.69%] [G loss: 0.443022]\n",
      "epoch:2 step:2180 [D loss: 0.604943, acc.: 67.19%] [G loss: 0.448155]\n",
      "epoch:2 step:2181 [D loss: 0.457228, acc.: 82.81%] [G loss: 0.526737]\n",
      "epoch:2 step:2182 [D loss: 0.450160, acc.: 85.94%] [G loss: 0.483136]\n",
      "epoch:2 step:2183 [D loss: 0.430360, acc.: 82.03%] [G loss: 0.594618]\n",
      "epoch:2 step:2184 [D loss: 0.465088, acc.: 77.34%] [G loss: 0.813636]\n",
      "epoch:2 step:2185 [D loss: 0.458234, acc.: 79.69%] [G loss: 0.645484]\n",
      "epoch:2 step:2186 [D loss: 0.410491, acc.: 82.03%] [G loss: 0.688162]\n",
      "epoch:2 step:2187 [D loss: 0.420495, acc.: 83.59%] [G loss: 0.689605]\n",
      "epoch:2 step:2188 [D loss: 0.381529, acc.: 86.72%] [G loss: 0.867494]\n",
      "epoch:2 step:2189 [D loss: 0.402292, acc.: 85.16%] [G loss: 0.772578]\n",
      "epoch:2 step:2190 [D loss: 0.637611, acc.: 65.62%] [G loss: 0.512980]\n",
      "epoch:2 step:2191 [D loss: 0.553643, acc.: 67.19%] [G loss: 0.356279]\n",
      "epoch:2 step:2192 [D loss: 0.494342, acc.: 80.47%] [G loss: 0.388805]\n",
      "epoch:2 step:2193 [D loss: 0.483938, acc.: 75.00%] [G loss: 0.473071]\n",
      "epoch:2 step:2194 [D loss: 0.485284, acc.: 82.03%] [G loss: 0.419159]\n",
      "epoch:2 step:2195 [D loss: 0.440001, acc.: 82.03%] [G loss: 0.479617]\n",
      "epoch:2 step:2196 [D loss: 0.457844, acc.: 78.91%] [G loss: 0.627646]\n",
      "epoch:2 step:2197 [D loss: 0.544190, acc.: 74.22%] [G loss: 0.457120]\n",
      "epoch:2 step:2198 [D loss: 0.488104, acc.: 80.47%] [G loss: 0.455995]\n",
      "epoch:2 step:2199 [D loss: 0.470811, acc.: 78.91%] [G loss: 0.516233]\n",
      "epoch:2 step:2200 [D loss: 0.466517, acc.: 79.69%] [G loss: 0.457102]\n",
      "##############\n",
      "[4.48295271 2.65321461 7.85136998 6.14184363 5.48416244 7.32391508\n",
      " 7.1929019  6.25066611 6.47966307 4.87208869]\n",
      "##########\n",
      "epoch:2 step:2201 [D loss: 0.529015, acc.: 75.00%] [G loss: 0.451917]\n",
      "epoch:2 step:2202 [D loss: 0.539447, acc.: 71.88%] [G loss: 0.418335]\n",
      "epoch:2 step:2203 [D loss: 0.463911, acc.: 82.81%] [G loss: 0.515243]\n",
      "epoch:2 step:2204 [D loss: 0.518558, acc.: 72.66%] [G loss: 0.374344]\n",
      "epoch:2 step:2205 [D loss: 0.489641, acc.: 85.16%] [G loss: 0.393532]\n",
      "epoch:2 step:2206 [D loss: 0.483676, acc.: 82.03%] [G loss: 0.410753]\n",
      "epoch:2 step:2207 [D loss: 0.449543, acc.: 83.59%] [G loss: 0.530307]\n",
      "epoch:2 step:2208 [D loss: 0.496859, acc.: 76.56%] [G loss: 0.495232]\n",
      "epoch:2 step:2209 [D loss: 0.452012, acc.: 82.81%] [G loss: 0.637910]\n",
      "epoch:2 step:2210 [D loss: 0.479652, acc.: 77.34%] [G loss: 0.585036]\n",
      "epoch:2 step:2211 [D loss: 0.476654, acc.: 82.03%] [G loss: 0.563111]\n",
      "epoch:2 step:2212 [D loss: 0.516620, acc.: 72.66%] [G loss: 0.461202]\n",
      "epoch:2 step:2213 [D loss: 0.498424, acc.: 77.34%] [G loss: 0.491602]\n",
      "epoch:2 step:2214 [D loss: 0.484656, acc.: 77.34%] [G loss: 0.530604]\n",
      "epoch:2 step:2215 [D loss: 0.523493, acc.: 75.00%] [G loss: 0.484728]\n",
      "epoch:2 step:2216 [D loss: 0.504024, acc.: 82.03%] [G loss: 0.520814]\n",
      "epoch:2 step:2217 [D loss: 0.426165, acc.: 79.69%] [G loss: 0.577327]\n",
      "epoch:2 step:2218 [D loss: 0.466835, acc.: 75.78%] [G loss: 0.757529]\n",
      "epoch:2 step:2219 [D loss: 0.424277, acc.: 84.38%] [G loss: 0.610021]\n",
      "epoch:2 step:2220 [D loss: 0.472049, acc.: 75.00%] [G loss: 0.701002]\n",
      "epoch:2 step:2221 [D loss: 0.430055, acc.: 81.25%] [G loss: 0.796864]\n",
      "epoch:2 step:2222 [D loss: 0.558436, acc.: 68.75%] [G loss: 0.632584]\n",
      "epoch:2 step:2223 [D loss: 0.662306, acc.: 60.16%] [G loss: 0.388361]\n",
      "epoch:2 step:2224 [D loss: 0.430089, acc.: 82.03%] [G loss: 0.616891]\n",
      "epoch:2 step:2225 [D loss: 0.523423, acc.: 72.66%] [G loss: 0.604464]\n",
      "epoch:2 step:2226 [D loss: 0.555766, acc.: 69.53%] [G loss: 0.468225]\n",
      "epoch:2 step:2227 [D loss: 0.521012, acc.: 78.12%] [G loss: 0.469111]\n",
      "epoch:2 step:2228 [D loss: 0.416652, acc.: 85.16%] [G loss: 0.704306]\n",
      "epoch:2 step:2229 [D loss: 0.498107, acc.: 77.34%] [G loss: 0.574320]\n",
      "epoch:2 step:2230 [D loss: 0.487834, acc.: 75.78%] [G loss: 0.546848]\n",
      "epoch:2 step:2231 [D loss: 0.486725, acc.: 79.69%] [G loss: 0.558764]\n",
      "epoch:2 step:2232 [D loss: 0.393084, acc.: 86.72%] [G loss: 0.742772]\n",
      "epoch:2 step:2233 [D loss: 0.455880, acc.: 80.47%] [G loss: 0.705243]\n",
      "epoch:2 step:2234 [D loss: 0.470578, acc.: 82.03%] [G loss: 0.670215]\n",
      "epoch:2 step:2235 [D loss: 0.466613, acc.: 84.38%] [G loss: 0.574548]\n",
      "epoch:2 step:2236 [D loss: 0.500822, acc.: 80.47%] [G loss: 0.416569]\n",
      "epoch:2 step:2237 [D loss: 0.476860, acc.: 81.25%] [G loss: 0.463871]\n",
      "epoch:2 step:2238 [D loss: 0.489376, acc.: 76.56%] [G loss: 0.511552]\n",
      "epoch:2 step:2239 [D loss: 0.443548, acc.: 82.81%] [G loss: 0.652125]\n",
      "epoch:2 step:2240 [D loss: 0.406747, acc.: 82.81%] [G loss: 0.660745]\n",
      "epoch:2 step:2241 [D loss: 0.486083, acc.: 78.12%] [G loss: 0.768654]\n",
      "epoch:2 step:2242 [D loss: 0.464842, acc.: 79.69%] [G loss: 0.645890]\n",
      "epoch:2 step:2243 [D loss: 0.531102, acc.: 78.91%] [G loss: 0.537088]\n",
      "epoch:2 step:2244 [D loss: 0.552387, acc.: 71.88%] [G loss: 0.496910]\n",
      "epoch:2 step:2245 [D loss: 0.499668, acc.: 79.69%] [G loss: 0.539698]\n",
      "epoch:2 step:2246 [D loss: 0.434963, acc.: 86.72%] [G loss: 0.663299]\n",
      "epoch:2 step:2247 [D loss: 0.497988, acc.: 76.56%] [G loss: 0.540163]\n",
      "epoch:2 step:2248 [D loss: 0.478751, acc.: 78.91%] [G loss: 0.629876]\n",
      "epoch:2 step:2249 [D loss: 0.494777, acc.: 77.34%] [G loss: 0.472519]\n",
      "epoch:2 step:2250 [D loss: 0.584202, acc.: 63.28%] [G loss: 0.430964]\n",
      "epoch:2 step:2251 [D loss: 0.457615, acc.: 78.91%] [G loss: 0.420898]\n",
      "epoch:2 step:2252 [D loss: 0.427383, acc.: 85.16%] [G loss: 0.647464]\n",
      "epoch:2 step:2253 [D loss: 0.494535, acc.: 79.69%] [G loss: 0.575441]\n",
      "epoch:2 step:2254 [D loss: 0.546578, acc.: 75.00%] [G loss: 0.467287]\n",
      "epoch:2 step:2255 [D loss: 0.400986, acc.: 88.28%] [G loss: 0.630128]\n",
      "epoch:2 step:2256 [D loss: 0.471497, acc.: 78.12%] [G loss: 0.607003]\n",
      "epoch:2 step:2257 [D loss: 0.512681, acc.: 75.00%] [G loss: 0.588060]\n",
      "epoch:2 step:2258 [D loss: 0.475927, acc.: 82.03%] [G loss: 0.567042]\n",
      "epoch:2 step:2259 [D loss: 0.550199, acc.: 71.88%] [G loss: 0.565387]\n",
      "epoch:2 step:2260 [D loss: 0.482919, acc.: 75.78%] [G loss: 0.586654]\n",
      "epoch:2 step:2261 [D loss: 0.511596, acc.: 78.91%] [G loss: 0.490000]\n",
      "epoch:2 step:2262 [D loss: 0.459478, acc.: 80.47%] [G loss: 0.541820]\n",
      "epoch:2 step:2263 [D loss: 0.469244, acc.: 80.47%] [G loss: 0.551054]\n",
      "epoch:2 step:2264 [D loss: 0.545805, acc.: 68.75%] [G loss: 0.471029]\n",
      "epoch:2 step:2265 [D loss: 0.445554, acc.: 85.16%] [G loss: 0.498902]\n",
      "epoch:2 step:2266 [D loss: 0.388976, acc.: 85.94%] [G loss: 0.702205]\n",
      "epoch:2 step:2267 [D loss: 0.434399, acc.: 85.16%] [G loss: 0.683494]\n",
      "epoch:2 step:2268 [D loss: 0.463705, acc.: 82.03%] [G loss: 0.535216]\n",
      "epoch:2 step:2269 [D loss: 0.412301, acc.: 82.81%] [G loss: 0.644904]\n",
      "epoch:2 step:2270 [D loss: 0.489608, acc.: 75.78%] [G loss: 0.622207]\n",
      "epoch:2 step:2271 [D loss: 0.418187, acc.: 85.16%] [G loss: 0.866316]\n",
      "epoch:2 step:2272 [D loss: 0.374697, acc.: 89.06%] [G loss: 0.909564]\n",
      "epoch:2 step:2273 [D loss: 0.449492, acc.: 82.03%] [G loss: 0.917504]\n",
      "epoch:2 step:2274 [D loss: 0.562658, acc.: 73.44%] [G loss: 0.547525]\n",
      "epoch:2 step:2275 [D loss: 0.503983, acc.: 78.12%] [G loss: 0.551189]\n",
      "epoch:2 step:2276 [D loss: 0.424341, acc.: 79.69%] [G loss: 0.652797]\n",
      "epoch:2 step:2277 [D loss: 0.467060, acc.: 78.12%] [G loss: 0.659848]\n",
      "epoch:2 step:2278 [D loss: 0.551393, acc.: 71.09%] [G loss: 0.486427]\n",
      "epoch:2 step:2279 [D loss: 0.509329, acc.: 73.44%] [G loss: 0.486828]\n",
      "epoch:2 step:2280 [D loss: 0.455437, acc.: 81.25%] [G loss: 0.706443]\n",
      "epoch:2 step:2281 [D loss: 0.430071, acc.: 82.81%] [G loss: 0.612025]\n",
      "epoch:2 step:2282 [D loss: 0.519660, acc.: 72.66%] [G loss: 0.626012]\n",
      "epoch:2 step:2283 [D loss: 0.442543, acc.: 81.25%] [G loss: 0.642928]\n",
      "epoch:2 step:2284 [D loss: 0.495474, acc.: 78.91%] [G loss: 0.564069]\n",
      "epoch:2 step:2285 [D loss: 0.484375, acc.: 75.78%] [G loss: 0.579461]\n",
      "epoch:2 step:2286 [D loss: 0.500816, acc.: 75.78%] [G loss: 0.526477]\n",
      "epoch:2 step:2287 [D loss: 0.500661, acc.: 76.56%] [G loss: 0.508723]\n",
      "epoch:2 step:2288 [D loss: 0.512973, acc.: 78.91%] [G loss: 0.533337]\n",
      "epoch:2 step:2289 [D loss: 0.556969, acc.: 70.31%] [G loss: 0.538626]\n",
      "epoch:2 step:2290 [D loss: 0.515918, acc.: 74.22%] [G loss: 0.485695]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:2 step:2291 [D loss: 0.490239, acc.: 82.03%] [G loss: 0.483275]\n",
      "epoch:2 step:2292 [D loss: 0.520211, acc.: 74.22%] [G loss: 0.514351]\n",
      "epoch:2 step:2293 [D loss: 0.450242, acc.: 82.81%] [G loss: 0.734769]\n",
      "epoch:2 step:2294 [D loss: 0.504152, acc.: 73.44%] [G loss: 0.594934]\n",
      "epoch:2 step:2295 [D loss: 0.518022, acc.: 71.88%] [G loss: 0.596309]\n",
      "epoch:2 step:2296 [D loss: 0.507659, acc.: 78.12%] [G loss: 0.564680]\n",
      "epoch:2 step:2297 [D loss: 0.537159, acc.: 67.97%] [G loss: 0.439501]\n",
      "epoch:2 step:2298 [D loss: 0.491062, acc.: 82.03%] [G loss: 0.441551]\n",
      "epoch:2 step:2299 [D loss: 0.441280, acc.: 85.94%] [G loss: 0.612166]\n",
      "epoch:2 step:2300 [D loss: 0.434164, acc.: 82.03%] [G loss: 0.582817]\n",
      "epoch:2 step:2301 [D loss: 0.424202, acc.: 87.50%] [G loss: 0.676055]\n",
      "epoch:2 step:2302 [D loss: 0.431310, acc.: 78.91%] [G loss: 0.788493]\n",
      "epoch:2 step:2303 [D loss: 0.474611, acc.: 79.69%] [G loss: 0.676017]\n",
      "epoch:2 step:2304 [D loss: 0.429000, acc.: 84.38%] [G loss: 0.696038]\n",
      "epoch:2 step:2305 [D loss: 0.487448, acc.: 75.78%] [G loss: 0.705538]\n",
      "epoch:2 step:2306 [D loss: 0.567211, acc.: 68.75%] [G loss: 0.531880]\n",
      "epoch:2 step:2307 [D loss: 0.524268, acc.: 75.00%] [G loss: 0.549022]\n",
      "epoch:2 step:2308 [D loss: 0.494862, acc.: 79.69%] [G loss: 0.515499]\n",
      "epoch:2 step:2309 [D loss: 0.553164, acc.: 75.78%] [G loss: 0.404410]\n",
      "epoch:2 step:2310 [D loss: 0.464566, acc.: 79.69%] [G loss: 0.465302]\n",
      "epoch:2 step:2311 [D loss: 0.553707, acc.: 71.09%] [G loss: 0.458286]\n",
      "epoch:2 step:2312 [D loss: 0.526284, acc.: 75.78%] [G loss: 0.531474]\n",
      "epoch:2 step:2313 [D loss: 0.509211, acc.: 71.88%] [G loss: 0.499533]\n",
      "epoch:2 step:2314 [D loss: 0.465687, acc.: 79.69%] [G loss: 0.642027]\n",
      "epoch:2 step:2315 [D loss: 0.549053, acc.: 74.22%] [G loss: 0.589545]\n",
      "epoch:2 step:2316 [D loss: 0.535428, acc.: 73.44%] [G loss: 0.450389]\n",
      "epoch:2 step:2317 [D loss: 0.456118, acc.: 81.25%] [G loss: 0.583064]\n",
      "epoch:2 step:2318 [D loss: 0.565972, acc.: 73.44%] [G loss: 0.465529]\n",
      "epoch:2 step:2319 [D loss: 0.439678, acc.: 87.50%] [G loss: 0.591746]\n",
      "epoch:2 step:2320 [D loss: 0.456906, acc.: 88.28%] [G loss: 0.500854]\n",
      "epoch:2 step:2321 [D loss: 0.429334, acc.: 80.47%] [G loss: 0.697050]\n",
      "epoch:2 step:2322 [D loss: 0.507301, acc.: 78.91%] [G loss: 0.688219]\n",
      "epoch:2 step:2323 [D loss: 0.486750, acc.: 79.69%] [G loss: 0.561575]\n",
      "epoch:2 step:2324 [D loss: 0.467097, acc.: 82.81%] [G loss: 0.547415]\n",
      "epoch:2 step:2325 [D loss: 0.403655, acc.: 86.72%] [G loss: 0.728411]\n",
      "epoch:2 step:2326 [D loss: 0.449262, acc.: 81.25%] [G loss: 0.633621]\n",
      "epoch:2 step:2327 [D loss: 0.520567, acc.: 73.44%] [G loss: 0.571602]\n",
      "epoch:2 step:2328 [D loss: 0.506695, acc.: 78.12%] [G loss: 0.595669]\n",
      "epoch:2 step:2329 [D loss: 0.508782, acc.: 78.91%] [G loss: 0.428628]\n",
      "epoch:2 step:2330 [D loss: 0.565883, acc.: 70.31%] [G loss: 0.429316]\n",
      "epoch:2 step:2331 [D loss: 0.502339, acc.: 76.56%] [G loss: 0.509153]\n",
      "epoch:2 step:2332 [D loss: 0.470610, acc.: 82.03%] [G loss: 0.457056]\n",
      "epoch:2 step:2333 [D loss: 0.489357, acc.: 82.03%] [G loss: 0.453476]\n",
      "epoch:2 step:2334 [D loss: 0.456165, acc.: 79.69%] [G loss: 0.499041]\n",
      "epoch:2 step:2335 [D loss: 0.448046, acc.: 84.38%] [G loss: 0.481235]\n",
      "epoch:2 step:2336 [D loss: 0.480902, acc.: 77.34%] [G loss: 0.526296]\n",
      "epoch:2 step:2337 [D loss: 0.537023, acc.: 75.00%] [G loss: 0.502753]\n",
      "epoch:2 step:2338 [D loss: 0.503578, acc.: 75.78%] [G loss: 0.468709]\n",
      "epoch:2 step:2339 [D loss: 0.564060, acc.: 71.88%] [G loss: 0.452989]\n",
      "epoch:2 step:2340 [D loss: 0.464761, acc.: 78.91%] [G loss: 0.468413]\n",
      "epoch:2 step:2341 [D loss: 0.495193, acc.: 78.91%] [G loss: 0.574624]\n",
      "epoch:2 step:2342 [D loss: 0.521061, acc.: 74.22%] [G loss: 0.604550]\n",
      "epoch:2 step:2343 [D loss: 0.508587, acc.: 79.69%] [G loss: 0.577469]\n",
      "epoch:2 step:2344 [D loss: 0.491908, acc.: 77.34%] [G loss: 0.693622]\n",
      "epoch:2 step:2345 [D loss: 0.434957, acc.: 87.50%] [G loss: 0.694951]\n",
      "epoch:2 step:2346 [D loss: 0.473938, acc.: 80.47%] [G loss: 0.638617]\n",
      "epoch:2 step:2347 [D loss: 0.519672, acc.: 82.03%] [G loss: 0.628071]\n",
      "epoch:2 step:2348 [D loss: 0.442035, acc.: 85.16%] [G loss: 0.605504]\n",
      "epoch:2 step:2349 [D loss: 0.429684, acc.: 80.47%] [G loss: 0.836613]\n",
      "epoch:2 step:2350 [D loss: 0.551268, acc.: 77.34%] [G loss: 0.660703]\n",
      "epoch:2 step:2351 [D loss: 0.645427, acc.: 63.28%] [G loss: 0.325856]\n",
      "epoch:2 step:2352 [D loss: 0.572599, acc.: 67.19%] [G loss: 0.291896]\n",
      "epoch:2 step:2353 [D loss: 0.571192, acc.: 74.22%] [G loss: 0.462000]\n",
      "epoch:2 step:2354 [D loss: 0.488603, acc.: 79.69%] [G loss: 0.438799]\n",
      "epoch:2 step:2355 [D loss: 0.519565, acc.: 77.34%] [G loss: 0.523111]\n",
      "epoch:2 step:2356 [D loss: 0.533702, acc.: 70.31%] [G loss: 0.406434]\n",
      "epoch:2 step:2357 [D loss: 0.510420, acc.: 78.12%] [G loss: 0.514876]\n",
      "epoch:2 step:2358 [D loss: 0.513082, acc.: 77.34%] [G loss: 0.450423]\n",
      "epoch:2 step:2359 [D loss: 0.515296, acc.: 77.34%] [G loss: 0.551656]\n",
      "epoch:2 step:2360 [D loss: 0.509006, acc.: 77.34%] [G loss: 0.531140]\n",
      "epoch:2 step:2361 [D loss: 0.483705, acc.: 81.25%] [G loss: 0.441125]\n",
      "epoch:2 step:2362 [D loss: 0.494498, acc.: 73.44%] [G loss: 0.683245]\n",
      "epoch:2 step:2363 [D loss: 0.529656, acc.: 69.53%] [G loss: 0.616182]\n",
      "epoch:2 step:2364 [D loss: 0.542515, acc.: 75.00%] [G loss: 0.497447]\n",
      "epoch:2 step:2365 [D loss: 0.501972, acc.: 78.12%] [G loss: 0.525667]\n",
      "epoch:2 step:2366 [D loss: 0.494074, acc.: 77.34%] [G loss: 0.519104]\n",
      "epoch:2 step:2367 [D loss: 0.548826, acc.: 73.44%] [G loss: 0.428297]\n",
      "epoch:2 step:2368 [D loss: 0.492799, acc.: 79.69%] [G loss: 0.447112]\n",
      "epoch:2 step:2369 [D loss: 0.489592, acc.: 82.81%] [G loss: 0.733061]\n",
      "epoch:2 step:2370 [D loss: 0.515956, acc.: 75.00%] [G loss: 0.564860]\n",
      "epoch:2 step:2371 [D loss: 0.451948, acc.: 82.81%] [G loss: 0.732734]\n",
      "epoch:2 step:2372 [D loss: 0.420987, acc.: 82.03%] [G loss: 0.698333]\n",
      "epoch:2 step:2373 [D loss: 0.421548, acc.: 84.38%] [G loss: 0.850584]\n",
      "epoch:2 step:2374 [D loss: 0.627342, acc.: 68.75%] [G loss: 0.416229]\n",
      "epoch:2 step:2375 [D loss: 0.604761, acc.: 64.84%] [G loss: 0.358034]\n",
      "epoch:2 step:2376 [D loss: 0.536935, acc.: 78.91%] [G loss: 0.351654]\n",
      "epoch:2 step:2377 [D loss: 0.478585, acc.: 78.12%] [G loss: 0.498598]\n",
      "epoch:2 step:2378 [D loss: 0.423051, acc.: 83.59%] [G loss: 0.651568]\n",
      "epoch:2 step:2379 [D loss: 0.576596, acc.: 67.97%] [G loss: 0.546945]\n",
      "epoch:2 step:2380 [D loss: 0.446256, acc.: 83.59%] [G loss: 0.642368]\n",
      "epoch:2 step:2381 [D loss: 0.487926, acc.: 78.91%] [G loss: 0.521369]\n",
      "epoch:2 step:2382 [D loss: 0.439012, acc.: 78.91%] [G loss: 0.659844]\n",
      "epoch:2 step:2383 [D loss: 0.547907, acc.: 71.88%] [G loss: 0.623322]\n",
      "epoch:2 step:2384 [D loss: 0.589483, acc.: 68.75%] [G loss: 0.398845]\n",
      "epoch:2 step:2385 [D loss: 0.605317, acc.: 67.97%] [G loss: 0.413208]\n",
      "epoch:2 step:2386 [D loss: 0.498604, acc.: 75.78%] [G loss: 0.466202]\n",
      "epoch:2 step:2387 [D loss: 0.465975, acc.: 79.69%] [G loss: 0.659227]\n",
      "epoch:2 step:2388 [D loss: 0.484905, acc.: 79.69%] [G loss: 0.597524]\n",
      "epoch:2 step:2389 [D loss: 0.427441, acc.: 85.94%] [G loss: 0.602874]\n",
      "epoch:2 step:2390 [D loss: 0.448914, acc.: 82.81%] [G loss: 0.588098]\n",
      "epoch:2 step:2391 [D loss: 0.537909, acc.: 72.66%] [G loss: 0.494863]\n",
      "epoch:2 step:2392 [D loss: 0.440606, acc.: 82.81%] [G loss: 0.482827]\n",
      "epoch:2 step:2393 [D loss: 0.486919, acc.: 76.56%] [G loss: 0.597440]\n",
      "epoch:2 step:2394 [D loss: 0.466819, acc.: 78.91%] [G loss: 0.509899]\n",
      "epoch:2 step:2395 [D loss: 0.489952, acc.: 83.59%] [G loss: 0.522120]\n",
      "epoch:2 step:2396 [D loss: 0.496292, acc.: 81.25%] [G loss: 0.506281]\n",
      "epoch:2 step:2397 [D loss: 0.489320, acc.: 77.34%] [G loss: 0.481194]\n",
      "epoch:2 step:2398 [D loss: 0.516731, acc.: 75.78%] [G loss: 0.573905]\n",
      "epoch:2 step:2399 [D loss: 0.593078, acc.: 67.97%] [G loss: 0.436457]\n",
      "epoch:2 step:2400 [D loss: 0.520553, acc.: 73.44%] [G loss: 0.442176]\n",
      "##############\n",
      "[4.27811922 2.75400188 7.6146229  5.9997201  5.2109923  6.94569417\n",
      " 6.30959281 5.96931717 6.21417363 4.66286749]\n",
      "##########\n",
      "epoch:2 step:2401 [D loss: 0.501673, acc.: 80.47%] [G loss: 0.577910]\n",
      "epoch:2 step:2402 [D loss: 0.539835, acc.: 69.53%] [G loss: 0.418712]\n",
      "epoch:2 step:2403 [D loss: 0.513445, acc.: 74.22%] [G loss: 0.317440]\n",
      "epoch:2 step:2404 [D loss: 0.462914, acc.: 79.69%] [G loss: 0.488683]\n",
      "epoch:2 step:2405 [D loss: 0.542342, acc.: 75.00%] [G loss: 0.481957]\n",
      "epoch:2 step:2406 [D loss: 0.489214, acc.: 78.91%] [G loss: 0.465695]\n",
      "epoch:2 step:2407 [D loss: 0.460915, acc.: 79.69%] [G loss: 0.534019]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:2 step:2408 [D loss: 0.468189, acc.: 82.03%] [G loss: 0.552904]\n",
      "epoch:2 step:2409 [D loss: 0.557094, acc.: 71.09%] [G loss: 0.469890]\n",
      "epoch:2 step:2410 [D loss: 0.460815, acc.: 81.25%] [G loss: 0.549698]\n",
      "epoch:2 step:2411 [D loss: 0.454435, acc.: 82.81%] [G loss: 0.699114]\n",
      "epoch:2 step:2412 [D loss: 0.553176, acc.: 71.88%] [G loss: 0.502093]\n",
      "epoch:2 step:2413 [D loss: 0.531400, acc.: 77.34%] [G loss: 0.424234]\n",
      "epoch:2 step:2414 [D loss: 0.525118, acc.: 75.00%] [G loss: 0.532176]\n",
      "epoch:2 step:2415 [D loss: 0.412628, acc.: 86.72%] [G loss: 0.722866]\n",
      "epoch:2 step:2416 [D loss: 0.548388, acc.: 76.56%] [G loss: 0.470931]\n",
      "epoch:2 step:2417 [D loss: 0.550615, acc.: 70.31%] [G loss: 0.402788]\n",
      "epoch:2 step:2418 [D loss: 0.492188, acc.: 76.56%] [G loss: 0.461930]\n",
      "epoch:2 step:2419 [D loss: 0.497560, acc.: 77.34%] [G loss: 0.618394]\n",
      "epoch:2 step:2420 [D loss: 0.363385, acc.: 89.06%] [G loss: 0.703428]\n",
      "epoch:2 step:2421 [D loss: 0.419741, acc.: 84.38%] [G loss: 0.663703]\n",
      "epoch:2 step:2422 [D loss: 0.435910, acc.: 84.38%] [G loss: 0.567582]\n",
      "epoch:2 step:2423 [D loss: 0.496113, acc.: 78.91%] [G loss: 0.657832]\n",
      "epoch:2 step:2424 [D loss: 0.507484, acc.: 78.91%] [G loss: 0.531236]\n",
      "epoch:2 step:2425 [D loss: 0.461331, acc.: 83.59%] [G loss: 0.566105]\n",
      "epoch:2 step:2426 [D loss: 0.482194, acc.: 78.91%] [G loss: 0.590080]\n",
      "epoch:2 step:2427 [D loss: 0.532786, acc.: 75.00%] [G loss: 0.567871]\n",
      "epoch:2 step:2428 [D loss: 0.399132, acc.: 85.94%] [G loss: 0.591063]\n",
      "epoch:2 step:2429 [D loss: 0.434196, acc.: 82.03%] [G loss: 0.561250]\n",
      "epoch:2 step:2430 [D loss: 0.439572, acc.: 81.25%] [G loss: 0.686479]\n",
      "epoch:2 step:2431 [D loss: 0.508595, acc.: 75.00%] [G loss: 0.588471]\n",
      "epoch:2 step:2432 [D loss: 0.501724, acc.: 73.44%] [G loss: 0.537055]\n",
      "epoch:2 step:2433 [D loss: 0.525038, acc.: 75.78%] [G loss: 0.663650]\n",
      "epoch:2 step:2434 [D loss: 0.579461, acc.: 71.09%] [G loss: 0.533420]\n",
      "epoch:2 step:2435 [D loss: 0.495526, acc.: 77.34%] [G loss: 0.535687]\n",
      "epoch:2 step:2436 [D loss: 0.527305, acc.: 75.00%] [G loss: 0.575471]\n",
      "epoch:2 step:2437 [D loss: 0.570828, acc.: 74.22%] [G loss: 0.437380]\n",
      "epoch:2 step:2438 [D loss: 0.552831, acc.: 75.78%] [G loss: 0.460597]\n",
      "epoch:2 step:2439 [D loss: 0.457877, acc.: 83.59%] [G loss: 0.566359]\n",
      "epoch:2 step:2440 [D loss: 0.583514, acc.: 67.19%] [G loss: 0.436864]\n",
      "epoch:2 step:2441 [D loss: 0.486725, acc.: 75.78%] [G loss: 0.486528]\n",
      "epoch:2 step:2442 [D loss: 0.525265, acc.: 78.12%] [G loss: 0.504313]\n",
      "epoch:2 step:2443 [D loss: 0.544528, acc.: 75.00%] [G loss: 0.535189]\n",
      "epoch:2 step:2444 [D loss: 0.474493, acc.: 82.03%] [G loss: 0.564101]\n",
      "epoch:2 step:2445 [D loss: 0.516120, acc.: 75.78%] [G loss: 0.528957]\n",
      "epoch:2 step:2446 [D loss: 0.498575, acc.: 80.47%] [G loss: 0.527241]\n",
      "epoch:2 step:2447 [D loss: 0.541344, acc.: 71.88%] [G loss: 0.477991]\n",
      "epoch:2 step:2448 [D loss: 0.500047, acc.: 78.12%] [G loss: 0.602838]\n",
      "epoch:2 step:2449 [D loss: 0.459633, acc.: 78.12%] [G loss: 0.532475]\n",
      "epoch:2 step:2450 [D loss: 0.515245, acc.: 77.34%] [G loss: 0.615419]\n",
      "epoch:2 step:2451 [D loss: 0.491722, acc.: 77.34%] [G loss: 0.587675]\n",
      "epoch:2 step:2452 [D loss: 0.455478, acc.: 82.81%] [G loss: 0.636453]\n",
      "epoch:2 step:2453 [D loss: 0.456624, acc.: 85.16%] [G loss: 0.528688]\n",
      "epoch:2 step:2454 [D loss: 0.551565, acc.: 75.78%] [G loss: 0.625065]\n",
      "epoch:2 step:2455 [D loss: 0.464389, acc.: 82.03%] [G loss: 0.587371]\n",
      "epoch:2 step:2456 [D loss: 0.417435, acc.: 87.50%] [G loss: 0.613305]\n",
      "epoch:2 step:2457 [D loss: 0.456659, acc.: 80.47%] [G loss: 0.725121]\n",
      "epoch:2 step:2458 [D loss: 0.560851, acc.: 71.88%] [G loss: 0.475684]\n",
      "epoch:2 step:2459 [D loss: 0.537730, acc.: 70.31%] [G loss: 0.575182]\n",
      "epoch:2 step:2460 [D loss: 0.515774, acc.: 75.78%] [G loss: 0.441298]\n",
      "epoch:2 step:2461 [D loss: 0.491198, acc.: 77.34%] [G loss: 0.594176]\n",
      "epoch:2 step:2462 [D loss: 0.487043, acc.: 76.56%] [G loss: 0.725814]\n",
      "epoch:2 step:2463 [D loss: 0.409046, acc.: 84.38%] [G loss: 0.814200]\n",
      "epoch:2 step:2464 [D loss: 0.544980, acc.: 72.66%] [G loss: 0.561446]\n",
      "epoch:2 step:2465 [D loss: 0.542227, acc.: 77.34%] [G loss: 0.367235]\n",
      "epoch:2 step:2466 [D loss: 0.438594, acc.: 83.59%] [G loss: 0.636467]\n",
      "epoch:2 step:2467 [D loss: 0.541213, acc.: 78.12%] [G loss: 0.561452]\n",
      "epoch:2 step:2468 [D loss: 0.491571, acc.: 78.91%] [G loss: 0.504487]\n",
      "epoch:2 step:2469 [D loss: 0.499068, acc.: 75.78%] [G loss: 0.465219]\n",
      "epoch:2 step:2470 [D loss: 0.523197, acc.: 75.78%] [G loss: 0.620360]\n",
      "epoch:2 step:2471 [D loss: 0.537766, acc.: 71.09%] [G loss: 0.513628]\n",
      "epoch:2 step:2472 [D loss: 0.441285, acc.: 82.81%] [G loss: 0.580611]\n",
      "epoch:2 step:2473 [D loss: 0.517210, acc.: 74.22%] [G loss: 0.450679]\n",
      "epoch:2 step:2474 [D loss: 0.549527, acc.: 73.44%] [G loss: 0.416007]\n",
      "epoch:2 step:2475 [D loss: 0.514922, acc.: 75.78%] [G loss: 0.416915]\n",
      "epoch:2 step:2476 [D loss: 0.482575, acc.: 79.69%] [G loss: 0.570365]\n",
      "epoch:2 step:2477 [D loss: 0.467040, acc.: 82.03%] [G loss: 0.479902]\n",
      "epoch:2 step:2478 [D loss: 0.526343, acc.: 75.78%] [G loss: 0.428194]\n",
      "epoch:2 step:2479 [D loss: 0.426343, acc.: 85.94%] [G loss: 0.460705]\n",
      "epoch:2 step:2480 [D loss: 0.487311, acc.: 77.34%] [G loss: 0.490535]\n",
      "epoch:2 step:2481 [D loss: 0.533341, acc.: 74.22%] [G loss: 0.414883]\n",
      "epoch:2 step:2482 [D loss: 0.479611, acc.: 82.81%] [G loss: 0.442689]\n",
      "epoch:2 step:2483 [D loss: 0.440121, acc.: 82.81%] [G loss: 0.531228]\n",
      "epoch:2 step:2484 [D loss: 0.521477, acc.: 76.56%] [G loss: 0.569490]\n",
      "epoch:2 step:2485 [D loss: 0.476221, acc.: 75.78%] [G loss: 0.465740]\n",
      "epoch:2 step:2486 [D loss: 0.419205, acc.: 82.81%] [G loss: 0.667186]\n",
      "epoch:2 step:2487 [D loss: 0.443649, acc.: 82.81%] [G loss: 0.598557]\n",
      "epoch:2 step:2488 [D loss: 0.474121, acc.: 78.91%] [G loss: 0.581902]\n",
      "epoch:2 step:2489 [D loss: 0.519048, acc.: 74.22%] [G loss: 0.471499]\n",
      "epoch:2 step:2490 [D loss: 0.485819, acc.: 77.34%] [G loss: 0.553562]\n",
      "epoch:2 step:2491 [D loss: 0.516948, acc.: 75.00%] [G loss: 0.528035]\n",
      "epoch:2 step:2492 [D loss: 0.500859, acc.: 74.22%] [G loss: 0.539061]\n",
      "epoch:2 step:2493 [D loss: 0.497387, acc.: 73.44%] [G loss: 0.687745]\n",
      "epoch:2 step:2494 [D loss: 0.461351, acc.: 84.38%] [G loss: 0.670156]\n",
      "epoch:2 step:2495 [D loss: 0.560947, acc.: 73.44%] [G loss: 0.482388]\n",
      "epoch:2 step:2496 [D loss: 0.615048, acc.: 60.16%] [G loss: 0.465860]\n",
      "epoch:2 step:2497 [D loss: 0.477844, acc.: 78.12%] [G loss: 0.508287]\n",
      "epoch:2 step:2498 [D loss: 0.495344, acc.: 74.22%] [G loss: 0.630192]\n",
      "epoch:2 step:2499 [D loss: 0.496193, acc.: 80.47%] [G loss: 0.568503]\n",
      "epoch:2 step:2500 [D loss: 0.488158, acc.: 79.69%] [G loss: 0.469773]\n",
      "epoch:2 step:2501 [D loss: 0.446924, acc.: 82.03%] [G loss: 0.486260]\n",
      "epoch:2 step:2502 [D loss: 0.493085, acc.: 77.34%] [G loss: 0.565140]\n",
      "epoch:2 step:2503 [D loss: 0.429721, acc.: 86.72%] [G loss: 0.729315]\n",
      "epoch:2 step:2504 [D loss: 0.484698, acc.: 81.25%] [G loss: 0.552906]\n",
      "epoch:2 step:2505 [D loss: 0.427571, acc.: 86.72%] [G loss: 0.562029]\n",
      "epoch:2 step:2506 [D loss: 0.491501, acc.: 77.34%] [G loss: 0.522733]\n",
      "epoch:2 step:2507 [D loss: 0.478972, acc.: 84.38%] [G loss: 0.504126]\n",
      "epoch:2 step:2508 [D loss: 0.460716, acc.: 82.81%] [G loss: 0.523486]\n",
      "epoch:2 step:2509 [D loss: 0.450578, acc.: 82.03%] [G loss: 0.554822]\n",
      "epoch:2 step:2510 [D loss: 0.521374, acc.: 74.22%] [G loss: 0.530643]\n",
      "epoch:2 step:2511 [D loss: 0.424030, acc.: 85.16%] [G loss: 0.628726]\n",
      "epoch:2 step:2512 [D loss: 0.466661, acc.: 78.91%] [G loss: 0.581865]\n",
      "epoch:2 step:2513 [D loss: 0.355416, acc.: 89.84%] [G loss: 0.782949]\n",
      "epoch:2 step:2514 [D loss: 0.417601, acc.: 85.16%] [G loss: 0.892242]\n",
      "epoch:2 step:2515 [D loss: 0.425014, acc.: 80.47%] [G loss: 0.845387]\n",
      "epoch:2 step:2516 [D loss: 0.408642, acc.: 85.94%] [G loss: 0.954952]\n",
      "epoch:2 step:2517 [D loss: 0.524860, acc.: 73.44%] [G loss: 0.597257]\n",
      "epoch:2 step:2518 [D loss: 0.531530, acc.: 72.66%] [G loss: 0.560964]\n",
      "epoch:2 step:2519 [D loss: 0.512484, acc.: 75.78%] [G loss: 0.560891]\n",
      "epoch:2 step:2520 [D loss: 0.513221, acc.: 75.00%] [G loss: 0.655551]\n",
      "epoch:2 step:2521 [D loss: 0.466866, acc.: 78.91%] [G loss: 0.674904]\n",
      "epoch:2 step:2522 [D loss: 0.397673, acc.: 85.94%] [G loss: 0.842399]\n",
      "epoch:2 step:2523 [D loss: 0.499604, acc.: 75.78%] [G loss: 0.731281]\n",
      "epoch:2 step:2524 [D loss: 0.470587, acc.: 82.03%] [G loss: 0.714504]\n",
      "epoch:2 step:2525 [D loss: 0.484021, acc.: 79.69%] [G loss: 0.716241]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:2 step:2526 [D loss: 0.519265, acc.: 75.00%] [G loss: 0.658172]\n",
      "epoch:2 step:2527 [D loss: 0.500110, acc.: 79.69%] [G loss: 0.666765]\n",
      "epoch:2 step:2528 [D loss: 0.439731, acc.: 83.59%] [G loss: 0.726518]\n",
      "epoch:2 step:2529 [D loss: 0.494609, acc.: 79.69%] [G loss: 0.628433]\n",
      "epoch:2 step:2530 [D loss: 0.505711, acc.: 78.91%] [G loss: 0.638294]\n",
      "epoch:2 step:2531 [D loss: 0.421527, acc.: 86.72%] [G loss: 0.615506]\n",
      "epoch:2 step:2532 [D loss: 0.490959, acc.: 78.12%] [G loss: 0.652847]\n",
      "epoch:2 step:2533 [D loss: 0.498193, acc.: 77.34%] [G loss: 0.596603]\n",
      "epoch:2 step:2534 [D loss: 0.448972, acc.: 81.25%] [G loss: 0.681902]\n",
      "epoch:2 step:2535 [D loss: 0.411077, acc.: 83.59%] [G loss: 0.704856]\n",
      "epoch:2 step:2536 [D loss: 0.497029, acc.: 76.56%] [G loss: 0.570529]\n",
      "epoch:2 step:2537 [D loss: 0.400100, acc.: 82.81%] [G loss: 0.697725]\n",
      "epoch:2 step:2538 [D loss: 0.467912, acc.: 81.25%] [G loss: 0.684644]\n",
      "epoch:2 step:2539 [D loss: 0.490794, acc.: 71.09%] [G loss: 0.768614]\n",
      "epoch:2 step:2540 [D loss: 0.419980, acc.: 82.81%] [G loss: 0.924624]\n",
      "epoch:2 step:2541 [D loss: 0.551222, acc.: 70.31%] [G loss: 0.589872]\n",
      "epoch:2 step:2542 [D loss: 0.466986, acc.: 79.69%] [G loss: 0.612219]\n",
      "epoch:2 step:2543 [D loss: 0.432365, acc.: 85.16%] [G loss: 0.584179]\n",
      "epoch:2 step:2544 [D loss: 0.414976, acc.: 82.81%] [G loss: 0.751970]\n",
      "epoch:2 step:2545 [D loss: 0.527310, acc.: 75.00%] [G loss: 0.558580]\n",
      "epoch:2 step:2546 [D loss: 0.522430, acc.: 74.22%] [G loss: 0.630620]\n",
      "epoch:2 step:2547 [D loss: 0.521872, acc.: 72.66%] [G loss: 0.539300]\n",
      "epoch:2 step:2548 [D loss: 0.474789, acc.: 82.03%] [G loss: 0.563924]\n",
      "epoch:2 step:2549 [D loss: 0.497381, acc.: 75.78%] [G loss: 0.507667]\n",
      "epoch:2 step:2550 [D loss: 0.498663, acc.: 76.56%] [G loss: 0.585983]\n",
      "epoch:2 step:2551 [D loss: 0.378680, acc.: 87.50%] [G loss: 0.741379]\n",
      "epoch:2 step:2552 [D loss: 0.433857, acc.: 85.16%] [G loss: 0.608046]\n",
      "epoch:2 step:2553 [D loss: 0.428976, acc.: 82.81%] [G loss: 0.674240]\n",
      "epoch:2 step:2554 [D loss: 0.417073, acc.: 85.94%] [G loss: 0.629095]\n",
      "epoch:2 step:2555 [D loss: 0.432143, acc.: 83.59%] [G loss: 0.739775]\n",
      "epoch:2 step:2556 [D loss: 0.438430, acc.: 85.16%] [G loss: 0.643512]\n",
      "epoch:2 step:2557 [D loss: 0.477263, acc.: 79.69%] [G loss: 0.661891]\n",
      "epoch:2 step:2558 [D loss: 0.442253, acc.: 85.94%] [G loss: 0.556489]\n",
      "epoch:2 step:2559 [D loss: 0.483337, acc.: 82.03%] [G loss: 0.508973]\n",
      "epoch:2 step:2560 [D loss: 0.485525, acc.: 78.91%] [G loss: 0.610544]\n",
      "epoch:2 step:2561 [D loss: 0.484154, acc.: 79.69%] [G loss: 0.562151]\n",
      "epoch:2 step:2562 [D loss: 0.502831, acc.: 77.34%] [G loss: 0.528796]\n",
      "epoch:2 step:2563 [D loss: 0.453530, acc.: 80.47%] [G loss: 0.574408]\n",
      "epoch:2 step:2564 [D loss: 0.446256, acc.: 78.91%] [G loss: 0.735797]\n",
      "epoch:2 step:2565 [D loss: 0.437458, acc.: 85.16%] [G loss: 0.601912]\n",
      "epoch:2 step:2566 [D loss: 0.465286, acc.: 78.91%] [G loss: 0.634136]\n",
      "epoch:2 step:2567 [D loss: 0.468691, acc.: 78.91%] [G loss: 0.621707]\n",
      "epoch:2 step:2568 [D loss: 0.443267, acc.: 80.47%] [G loss: 0.749852]\n",
      "epoch:2 step:2569 [D loss: 0.438193, acc.: 82.81%] [G loss: 0.648948]\n",
      "epoch:2 step:2570 [D loss: 0.489401, acc.: 79.69%] [G loss: 0.576477]\n",
      "epoch:2 step:2571 [D loss: 0.408309, acc.: 82.03%] [G loss: 0.746833]\n",
      "epoch:2 step:2572 [D loss: 0.460035, acc.: 78.91%] [G loss: 0.762791]\n",
      "epoch:2 step:2573 [D loss: 0.466937, acc.: 81.25%] [G loss: 0.564184]\n",
      "epoch:2 step:2574 [D loss: 0.481275, acc.: 75.78%] [G loss: 0.713964]\n",
      "epoch:2 step:2575 [D loss: 0.483209, acc.: 79.69%] [G loss: 0.691035]\n",
      "epoch:2 step:2576 [D loss: 0.541594, acc.: 72.66%] [G loss: 0.608739]\n",
      "epoch:2 step:2577 [D loss: 0.493107, acc.: 76.56%] [G loss: 0.564932]\n",
      "epoch:2 step:2578 [D loss: 0.502146, acc.: 76.56%] [G loss: 0.616714]\n",
      "epoch:2 step:2579 [D loss: 0.463589, acc.: 78.91%] [G loss: 0.637803]\n",
      "epoch:2 step:2580 [D loss: 0.473921, acc.: 76.56%] [G loss: 0.641857]\n",
      "epoch:2 step:2581 [D loss: 0.419701, acc.: 85.94%] [G loss: 0.645259]\n",
      "epoch:2 step:2582 [D loss: 0.439576, acc.: 81.25%] [G loss: 0.745676]\n",
      "epoch:2 step:2583 [D loss: 0.442115, acc.: 80.47%] [G loss: 0.835979]\n",
      "epoch:2 step:2584 [D loss: 0.566464, acc.: 66.41%] [G loss: 0.615842]\n",
      "epoch:2 step:2585 [D loss: 0.524364, acc.: 74.22%] [G loss: 0.525286]\n",
      "epoch:2 step:2586 [D loss: 0.457148, acc.: 78.91%] [G loss: 0.544208]\n",
      "epoch:2 step:2587 [D loss: 0.505989, acc.: 79.69%] [G loss: 0.400763]\n",
      "epoch:2 step:2588 [D loss: 0.465144, acc.: 82.03%] [G loss: 0.523666]\n",
      "epoch:2 step:2589 [D loss: 0.458631, acc.: 82.81%] [G loss: 0.664361]\n",
      "epoch:2 step:2590 [D loss: 0.564650, acc.: 67.97%] [G loss: 0.438158]\n",
      "epoch:2 step:2591 [D loss: 0.526424, acc.: 78.12%] [G loss: 0.550175]\n",
      "epoch:2 step:2592 [D loss: 0.528169, acc.: 77.34%] [G loss: 0.443162]\n",
      "epoch:2 step:2593 [D loss: 0.475839, acc.: 80.47%] [G loss: 0.545681]\n",
      "epoch:2 step:2594 [D loss: 0.573093, acc.: 64.84%] [G loss: 0.460244]\n",
      "epoch:2 step:2595 [D loss: 0.515506, acc.: 78.91%] [G loss: 0.489510]\n",
      "epoch:2 step:2596 [D loss: 0.441646, acc.: 83.59%] [G loss: 0.629005]\n",
      "epoch:2 step:2597 [D loss: 0.511882, acc.: 76.56%] [G loss: 0.630008]\n",
      "epoch:2 step:2598 [D loss: 0.513796, acc.: 74.22%] [G loss: 0.623360]\n",
      "epoch:2 step:2599 [D loss: 0.455242, acc.: 82.81%] [G loss: 0.648660]\n",
      "epoch:2 step:2600 [D loss: 0.474900, acc.: 78.12%] [G loss: 0.591656]\n",
      "##############\n",
      "[4.14446107 3.19171326 7.83681375 5.83477811 5.20197932 7.02506973\n",
      " 6.62860296 5.86688606 6.3053189  4.46734213]\n",
      "##########\n",
      "epoch:2 step:2601 [D loss: 0.570513, acc.: 70.31%] [G loss: 0.385236]\n",
      "epoch:2 step:2602 [D loss: 0.506326, acc.: 77.34%] [G loss: 0.497518]\n",
      "epoch:2 step:2603 [D loss: 0.504261, acc.: 78.12%] [G loss: 0.498349]\n",
      "epoch:2 step:2604 [D loss: 0.455369, acc.: 80.47%] [G loss: 0.518057]\n",
      "epoch:2 step:2605 [D loss: 0.482568, acc.: 82.81%] [G loss: 0.559593]\n",
      "epoch:2 step:2606 [D loss: 0.428601, acc.: 84.38%] [G loss: 0.608348]\n",
      "epoch:2 step:2607 [D loss: 0.458665, acc.: 80.47%] [G loss: 0.679766]\n",
      "epoch:2 step:2608 [D loss: 0.398699, acc.: 86.72%] [G loss: 0.677263]\n",
      "epoch:2 step:2609 [D loss: 0.519107, acc.: 78.12%] [G loss: 0.478617]\n",
      "epoch:2 step:2610 [D loss: 0.397421, acc.: 88.28%] [G loss: 0.607571]\n",
      "epoch:2 step:2611 [D loss: 0.463458, acc.: 82.81%] [G loss: 0.596696]\n",
      "epoch:2 step:2612 [D loss: 0.474045, acc.: 79.69%] [G loss: 0.556570]\n",
      "epoch:2 step:2613 [D loss: 0.542426, acc.: 75.78%] [G loss: 0.534107]\n",
      "epoch:2 step:2614 [D loss: 0.518268, acc.: 75.78%] [G loss: 0.512234]\n",
      "epoch:2 step:2615 [D loss: 0.462583, acc.: 78.91%] [G loss: 0.502298]\n",
      "epoch:2 step:2616 [D loss: 0.539147, acc.: 68.75%] [G loss: 0.456036]\n",
      "epoch:2 step:2617 [D loss: 0.490066, acc.: 78.12%] [G loss: 0.628271]\n",
      "epoch:2 step:2618 [D loss: 0.553971, acc.: 70.31%] [G loss: 0.496587]\n",
      "epoch:2 step:2619 [D loss: 0.434776, acc.: 83.59%] [G loss: 0.466694]\n",
      "epoch:2 step:2620 [D loss: 0.394619, acc.: 83.59%] [G loss: 0.814023]\n",
      "epoch:2 step:2621 [D loss: 0.410706, acc.: 81.25%] [G loss: 0.745545]\n",
      "epoch:2 step:2622 [D loss: 0.444760, acc.: 82.03%] [G loss: 0.678492]\n",
      "epoch:2 step:2623 [D loss: 0.453463, acc.: 76.56%] [G loss: 0.694347]\n",
      "epoch:2 step:2624 [D loss: 0.441080, acc.: 84.38%] [G loss: 0.699918]\n",
      "epoch:2 step:2625 [D loss: 0.439218, acc.: 82.03%] [G loss: 0.723767]\n",
      "epoch:2 step:2626 [D loss: 0.451039, acc.: 78.91%] [G loss: 0.737350]\n",
      "epoch:2 step:2627 [D loss: 0.445105, acc.: 78.12%] [G loss: 0.718483]\n",
      "epoch:2 step:2628 [D loss: 0.472479, acc.: 75.78%] [G loss: 0.760754]\n",
      "epoch:2 step:2629 [D loss: 0.371654, acc.: 87.50%] [G loss: 0.823649]\n",
      "epoch:2 step:2630 [D loss: 0.454519, acc.: 85.16%] [G loss: 0.738897]\n",
      "epoch:2 step:2631 [D loss: 0.468159, acc.: 79.69%] [G loss: 0.778814]\n",
      "epoch:2 step:2632 [D loss: 0.457987, acc.: 77.34%] [G loss: 0.706549]\n",
      "epoch:2 step:2633 [D loss: 0.483803, acc.: 82.03%] [G loss: 0.630179]\n",
      "epoch:2 step:2634 [D loss: 0.436844, acc.: 85.16%] [G loss: 0.629074]\n",
      "epoch:2 step:2635 [D loss: 0.467529, acc.: 78.12%] [G loss: 0.607784]\n",
      "epoch:2 step:2636 [D loss: 0.484976, acc.: 75.78%] [G loss: 0.639709]\n",
      "epoch:2 step:2637 [D loss: 0.434560, acc.: 81.25%] [G loss: 0.671846]\n",
      "epoch:2 step:2638 [D loss: 0.456757, acc.: 80.47%] [G loss: 0.651521]\n",
      "epoch:2 step:2639 [D loss: 0.603445, acc.: 68.75%] [G loss: 0.601742]\n",
      "epoch:2 step:2640 [D loss: 0.613117, acc.: 66.41%] [G loss: 0.516050]\n",
      "epoch:2 step:2641 [D loss: 0.510981, acc.: 78.12%] [G loss: 0.634286]\n",
      "epoch:2 step:2642 [D loss: 0.474019, acc.: 82.81%] [G loss: 0.653378]\n",
      "epoch:2 step:2643 [D loss: 0.454501, acc.: 76.56%] [G loss: 0.792704]\n",
      "epoch:2 step:2644 [D loss: 0.475414, acc.: 78.91%] [G loss: 0.743704]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:2 step:2645 [D loss: 0.483999, acc.: 74.22%] [G loss: 0.612718]\n",
      "epoch:2 step:2646 [D loss: 0.462012, acc.: 78.12%] [G loss: 0.641337]\n",
      "epoch:2 step:2647 [D loss: 0.470106, acc.: 79.69%] [G loss: 0.661663]\n",
      "epoch:2 step:2648 [D loss: 0.522055, acc.: 75.78%] [G loss: 0.589088]\n",
      "epoch:2 step:2649 [D loss: 0.457930, acc.: 82.03%] [G loss: 0.736439]\n",
      "epoch:2 step:2650 [D loss: 0.509497, acc.: 73.44%] [G loss: 0.633034]\n",
      "epoch:2 step:2651 [D loss: 0.512988, acc.: 73.44%] [G loss: 0.585535]\n",
      "epoch:2 step:2652 [D loss: 0.500378, acc.: 75.00%] [G loss: 0.637634]\n",
      "epoch:2 step:2653 [D loss: 0.458918, acc.: 78.12%] [G loss: 0.662967]\n",
      "epoch:2 step:2654 [D loss: 0.464663, acc.: 82.03%] [G loss: 0.835678]\n",
      "epoch:2 step:2655 [D loss: 0.396813, acc.: 88.28%] [G loss: 0.762148]\n",
      "epoch:2 step:2656 [D loss: 0.464693, acc.: 78.91%] [G loss: 1.024244]\n",
      "epoch:2 step:2657 [D loss: 0.525714, acc.: 75.00%] [G loss: 0.696706]\n",
      "epoch:2 step:2658 [D loss: 0.492027, acc.: 78.91%] [G loss: 0.618539]\n",
      "epoch:2 step:2659 [D loss: 0.522291, acc.: 76.56%] [G loss: 0.561223]\n",
      "epoch:2 step:2660 [D loss: 0.425298, acc.: 87.50%] [G loss: 0.685930]\n",
      "epoch:2 step:2661 [D loss: 0.505271, acc.: 78.12%] [G loss: 0.694225]\n",
      "epoch:2 step:2662 [D loss: 0.537571, acc.: 72.66%] [G loss: 0.468623]\n",
      "epoch:2 step:2663 [D loss: 0.496633, acc.: 75.78%] [G loss: 0.487273]\n",
      "epoch:2 step:2664 [D loss: 0.475550, acc.: 81.25%] [G loss: 0.634376]\n",
      "epoch:2 step:2665 [D loss: 0.510730, acc.: 76.56%] [G loss: 0.577186]\n",
      "epoch:2 step:2666 [D loss: 0.395099, acc.: 82.03%] [G loss: 0.778598]\n",
      "epoch:2 step:2667 [D loss: 0.519619, acc.: 78.12%] [G loss: 0.725372]\n",
      "epoch:2 step:2668 [D loss: 0.553908, acc.: 72.66%] [G loss: 0.585796]\n",
      "epoch:2 step:2669 [D loss: 0.436709, acc.: 84.38%] [G loss: 0.680690]\n",
      "epoch:2 step:2670 [D loss: 0.483345, acc.: 73.44%] [G loss: 0.838280]\n",
      "epoch:2 step:2671 [D loss: 0.506424, acc.: 73.44%] [G loss: 0.741954]\n",
      "epoch:2 step:2672 [D loss: 0.477890, acc.: 78.12%] [G loss: 0.675739]\n",
      "epoch:2 step:2673 [D loss: 0.508973, acc.: 77.34%] [G loss: 0.636531]\n",
      "epoch:2 step:2674 [D loss: 0.562560, acc.: 72.66%] [G loss: 0.546980]\n",
      "epoch:2 step:2675 [D loss: 0.479871, acc.: 75.78%] [G loss: 0.586687]\n",
      "epoch:2 step:2676 [D loss: 0.513780, acc.: 74.22%] [G loss: 0.619583]\n",
      "epoch:2 step:2677 [D loss: 0.431359, acc.: 79.69%] [G loss: 0.803895]\n",
      "epoch:2 step:2678 [D loss: 0.412998, acc.: 89.06%] [G loss: 0.738692]\n",
      "epoch:2 step:2679 [D loss: 0.439804, acc.: 84.38%] [G loss: 0.624679]\n",
      "epoch:2 step:2680 [D loss: 0.399860, acc.: 85.94%] [G loss: 0.607704]\n",
      "epoch:2 step:2681 [D loss: 0.499186, acc.: 76.56%] [G loss: 0.622211]\n",
      "epoch:2 step:2682 [D loss: 0.507047, acc.: 78.91%] [G loss: 0.624326]\n",
      "epoch:2 step:2683 [D loss: 0.541826, acc.: 77.34%] [G loss: 0.569327]\n",
      "epoch:2 step:2684 [D loss: 0.466936, acc.: 82.03%] [G loss: 0.596052]\n",
      "epoch:2 step:2685 [D loss: 0.513983, acc.: 75.00%] [G loss: 0.530077]\n",
      "epoch:2 step:2686 [D loss: 0.537258, acc.: 72.66%] [G loss: 0.456882]\n",
      "epoch:2 step:2687 [D loss: 0.505471, acc.: 74.22%] [G loss: 0.579708]\n",
      "epoch:2 step:2688 [D loss: 0.461705, acc.: 82.03%] [G loss: 0.685840]\n",
      "epoch:2 step:2689 [D loss: 0.504840, acc.: 77.34%] [G loss: 0.702160]\n",
      "epoch:2 step:2690 [D loss: 0.476722, acc.: 78.91%] [G loss: 0.902018]\n",
      "epoch:2 step:2691 [D loss: 0.568774, acc.: 69.53%] [G loss: 0.573829]\n",
      "epoch:2 step:2692 [D loss: 0.513493, acc.: 74.22%] [G loss: 0.583030]\n",
      "epoch:2 step:2693 [D loss: 0.487584, acc.: 77.34%] [G loss: 0.619515]\n",
      "epoch:2 step:2694 [D loss: 0.539749, acc.: 71.88%] [G loss: 0.535684]\n",
      "epoch:2 step:2695 [D loss: 0.475038, acc.: 81.25%] [G loss: 0.468693]\n",
      "epoch:2 step:2696 [D loss: 0.434536, acc.: 81.25%] [G loss: 0.558249]\n",
      "epoch:2 step:2697 [D loss: 0.455190, acc.: 81.25%] [G loss: 0.721675]\n",
      "epoch:2 step:2698 [D loss: 0.606357, acc.: 71.09%] [G loss: 0.461471]\n",
      "epoch:2 step:2699 [D loss: 0.504363, acc.: 78.91%] [G loss: 0.438773]\n",
      "epoch:2 step:2700 [D loss: 0.506685, acc.: 74.22%] [G loss: 0.575835]\n",
      "epoch:2 step:2701 [D loss: 0.515915, acc.: 74.22%] [G loss: 0.601863]\n",
      "epoch:2 step:2702 [D loss: 0.488752, acc.: 81.25%] [G loss: 0.503158]\n",
      "epoch:2 step:2703 [D loss: 0.410901, acc.: 85.94%] [G loss: 0.655464]\n",
      "epoch:2 step:2704 [D loss: 0.446717, acc.: 85.94%] [G loss: 0.640612]\n",
      "epoch:2 step:2705 [D loss: 0.506928, acc.: 78.12%] [G loss: 0.556345]\n",
      "epoch:2 step:2706 [D loss: 0.474719, acc.: 79.69%] [G loss: 0.546851]\n",
      "epoch:2 step:2707 [D loss: 0.498267, acc.: 75.00%] [G loss: 0.567973]\n",
      "epoch:2 step:2708 [D loss: 0.473881, acc.: 80.47%] [G loss: 0.659045]\n",
      "epoch:2 step:2709 [D loss: 0.470526, acc.: 81.25%] [G loss: 0.636262]\n",
      "epoch:2 step:2710 [D loss: 0.546184, acc.: 68.75%] [G loss: 0.524948]\n",
      "epoch:2 step:2711 [D loss: 0.494059, acc.: 78.12%] [G loss: 0.729323]\n",
      "epoch:2 step:2712 [D loss: 0.516948, acc.: 71.09%] [G loss: 0.661127]\n",
      "epoch:2 step:2713 [D loss: 0.527168, acc.: 71.88%] [G loss: 0.591085]\n",
      "epoch:2 step:2714 [D loss: 0.512044, acc.: 78.12%] [G loss: 0.465071]\n",
      "epoch:2 step:2715 [D loss: 0.477497, acc.: 78.12%] [G loss: 0.661361]\n",
      "epoch:2 step:2716 [D loss: 0.481438, acc.: 82.03%] [G loss: 0.538180]\n",
      "epoch:2 step:2717 [D loss: 0.471116, acc.: 78.12%] [G loss: 0.591085]\n",
      "epoch:2 step:2718 [D loss: 0.571710, acc.: 71.88%] [G loss: 0.525002]\n",
      "epoch:2 step:2719 [D loss: 0.544447, acc.: 68.75%] [G loss: 0.624352]\n",
      "epoch:2 step:2720 [D loss: 0.494334, acc.: 75.00%] [G loss: 0.524747]\n",
      "epoch:2 step:2721 [D loss: 0.533452, acc.: 73.44%] [G loss: 0.414073]\n",
      "epoch:2 step:2722 [D loss: 0.437324, acc.: 88.28%] [G loss: 0.710405]\n",
      "epoch:2 step:2723 [D loss: 0.517594, acc.: 75.78%] [G loss: 0.680382]\n",
      "epoch:2 step:2724 [D loss: 0.459784, acc.: 81.25%] [G loss: 0.602773]\n",
      "epoch:2 step:2725 [D loss: 0.473089, acc.: 79.69%] [G loss: 0.590283]\n",
      "epoch:2 step:2726 [D loss: 0.448740, acc.: 82.03%] [G loss: 0.747779]\n",
      "epoch:2 step:2727 [D loss: 0.460781, acc.: 77.34%] [G loss: 0.694504]\n",
      "epoch:2 step:2728 [D loss: 0.392706, acc.: 85.94%] [G loss: 0.782865]\n",
      "epoch:2 step:2729 [D loss: 0.502747, acc.: 80.47%] [G loss: 0.692989]\n",
      "epoch:2 step:2730 [D loss: 0.515269, acc.: 75.78%] [G loss: 0.585025]\n",
      "epoch:2 step:2731 [D loss: 0.439863, acc.: 80.47%] [G loss: 0.579034]\n",
      "epoch:2 step:2732 [D loss: 0.631940, acc.: 67.19%] [G loss: 0.388791]\n",
      "epoch:2 step:2733 [D loss: 0.519093, acc.: 71.88%] [G loss: 0.591761]\n",
      "epoch:2 step:2734 [D loss: 0.535044, acc.: 73.44%] [G loss: 0.648101]\n",
      "epoch:2 step:2735 [D loss: 0.555396, acc.: 71.09%] [G loss: 0.485689]\n",
      "epoch:2 step:2736 [D loss: 0.562971, acc.: 72.66%] [G loss: 0.408535]\n",
      "epoch:2 step:2737 [D loss: 0.478169, acc.: 82.03%] [G loss: 0.574811]\n",
      "epoch:2 step:2738 [D loss: 0.481116, acc.: 78.91%] [G loss: 0.525347]\n",
      "epoch:2 step:2739 [D loss: 0.474136, acc.: 82.81%] [G loss: 0.462283]\n",
      "epoch:2 step:2740 [D loss: 0.532032, acc.: 73.44%] [G loss: 0.411474]\n",
      "epoch:2 step:2741 [D loss: 0.558431, acc.: 74.22%] [G loss: 0.431871]\n",
      "epoch:2 step:2742 [D loss: 0.490534, acc.: 79.69%] [G loss: 0.414238]\n",
      "epoch:2 step:2743 [D loss: 0.467276, acc.: 85.16%] [G loss: 0.485796]\n",
      "epoch:2 step:2744 [D loss: 0.488674, acc.: 81.25%] [G loss: 0.400085]\n",
      "epoch:2 step:2745 [D loss: 0.489508, acc.: 79.69%] [G loss: 0.607081]\n",
      "epoch:2 step:2746 [D loss: 0.504224, acc.: 75.78%] [G loss: 0.526666]\n",
      "epoch:2 step:2747 [D loss: 0.538383, acc.: 68.75%] [G loss: 0.546718]\n",
      "epoch:2 step:2748 [D loss: 0.467396, acc.: 82.81%] [G loss: 0.542726]\n",
      "epoch:2 step:2749 [D loss: 0.456524, acc.: 81.25%] [G loss: 0.521248]\n",
      "epoch:2 step:2750 [D loss: 0.423924, acc.: 85.94%] [G loss: 0.553400]\n",
      "epoch:2 step:2751 [D loss: 0.493649, acc.: 76.56%] [G loss: 0.501334]\n",
      "epoch:2 step:2752 [D loss: 0.544318, acc.: 71.88%] [G loss: 0.627673]\n",
      "epoch:2 step:2753 [D loss: 0.476310, acc.: 80.47%] [G loss: 0.577514]\n",
      "epoch:2 step:2754 [D loss: 0.613930, acc.: 64.84%] [G loss: 0.512545]\n",
      "epoch:2 step:2755 [D loss: 0.512595, acc.: 77.34%] [G loss: 0.508041]\n",
      "epoch:2 step:2756 [D loss: 0.505426, acc.: 75.78%] [G loss: 0.552411]\n",
      "epoch:2 step:2757 [D loss: 0.478396, acc.: 77.34%] [G loss: 0.635910]\n",
      "epoch:2 step:2758 [D loss: 0.393959, acc.: 85.94%] [G loss: 0.704576]\n",
      "epoch:2 step:2759 [D loss: 0.476150, acc.: 77.34%] [G loss: 0.728332]\n",
      "epoch:2 step:2760 [D loss: 0.439462, acc.: 80.47%] [G loss: 0.701482]\n",
      "epoch:2 step:2761 [D loss: 0.484361, acc.: 79.69%] [G loss: 0.605486]\n",
      "epoch:2 step:2762 [D loss: 0.465846, acc.: 75.78%] [G loss: 0.664305]\n",
      "epoch:2 step:2763 [D loss: 0.509920, acc.: 71.88%] [G loss: 0.663236]\n",
      "epoch:2 step:2764 [D loss: 0.458535, acc.: 80.47%] [G loss: 0.677896]\n",
      "epoch:2 step:2765 [D loss: 0.529862, acc.: 77.34%] [G loss: 0.657248]\n",
      "epoch:2 step:2766 [D loss: 0.600757, acc.: 71.09%] [G loss: 0.529803]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:2 step:2767 [D loss: 0.535754, acc.: 75.78%] [G loss: 0.630500]\n",
      "epoch:2 step:2768 [D loss: 0.469595, acc.: 80.47%] [G loss: 0.542326]\n",
      "epoch:2 step:2769 [D loss: 0.489524, acc.: 77.34%] [G loss: 0.592923]\n",
      "epoch:2 step:2770 [D loss: 0.554417, acc.: 68.75%] [G loss: 0.489878]\n",
      "epoch:2 step:2771 [D loss: 0.464056, acc.: 78.12%] [G loss: 0.599758]\n",
      "epoch:2 step:2772 [D loss: 0.489915, acc.: 78.91%] [G loss: 0.631616]\n",
      "epoch:2 step:2773 [D loss: 0.491405, acc.: 72.66%] [G loss: 0.699496]\n",
      "epoch:2 step:2774 [D loss: 0.528970, acc.: 73.44%] [G loss: 0.597987]\n",
      "epoch:2 step:2775 [D loss: 0.515775, acc.: 75.00%] [G loss: 0.627060]\n",
      "epoch:2 step:2776 [D loss: 0.562539, acc.: 65.62%] [G loss: 0.430714]\n",
      "epoch:2 step:2777 [D loss: 0.528081, acc.: 74.22%] [G loss: 0.436946]\n",
      "epoch:2 step:2778 [D loss: 0.433483, acc.: 86.72%] [G loss: 0.610363]\n",
      "epoch:2 step:2779 [D loss: 0.510384, acc.: 75.00%] [G loss: 0.677286]\n",
      "epoch:2 step:2780 [D loss: 0.512435, acc.: 72.66%] [G loss: 0.597645]\n",
      "epoch:2 step:2781 [D loss: 0.533830, acc.: 73.44%] [G loss: 0.732916]\n",
      "epoch:2 step:2782 [D loss: 0.472981, acc.: 82.81%] [G loss: 0.542906]\n",
      "epoch:2 step:2783 [D loss: 0.430985, acc.: 83.59%] [G loss: 0.673325]\n",
      "epoch:2 step:2784 [D loss: 0.454983, acc.: 81.25%] [G loss: 0.598922]\n",
      "epoch:2 step:2785 [D loss: 0.453701, acc.: 78.12%] [G loss: 0.608413]\n",
      "epoch:2 step:2786 [D loss: 0.461316, acc.: 82.03%] [G loss: 0.617731]\n",
      "epoch:2 step:2787 [D loss: 0.558965, acc.: 68.75%] [G loss: 0.545508]\n",
      "epoch:2 step:2788 [D loss: 0.498396, acc.: 79.69%] [G loss: 0.672128]\n",
      "epoch:2 step:2789 [D loss: 0.600814, acc.: 70.31%] [G loss: 0.491049]\n",
      "epoch:2 step:2790 [D loss: 0.541960, acc.: 69.53%] [G loss: 0.459105]\n",
      "epoch:2 step:2791 [D loss: 0.544176, acc.: 74.22%] [G loss: 0.496825]\n",
      "epoch:2 step:2792 [D loss: 0.451435, acc.: 82.03%] [G loss: 0.669412]\n",
      "epoch:2 step:2793 [D loss: 0.497284, acc.: 77.34%] [G loss: 0.597332]\n",
      "epoch:2 step:2794 [D loss: 0.644688, acc.: 65.62%] [G loss: 0.556918]\n",
      "epoch:2 step:2795 [D loss: 0.425044, acc.: 86.72%] [G loss: 0.687581]\n",
      "epoch:2 step:2796 [D loss: 0.547499, acc.: 68.75%] [G loss: 0.512434]\n",
      "epoch:2 step:2797 [D loss: 0.415907, acc.: 82.81%] [G loss: 0.618116]\n",
      "epoch:2 step:2798 [D loss: 0.440735, acc.: 82.03%] [G loss: 0.735247]\n",
      "epoch:2 step:2799 [D loss: 0.398153, acc.: 86.72%] [G loss: 0.801023]\n",
      "epoch:2 step:2800 [D loss: 0.466353, acc.: 78.12%] [G loss: 0.997632]\n",
      "##############\n",
      "[4.00859209 2.11051833 7.64434046 5.54511131 4.95288958 6.61021187\n",
      " 6.02903046 5.63144815 5.76927258 4.2269833 ]\n",
      "##########\n",
      "epoch:2 step:2801 [D loss: 0.455096, acc.: 82.03%] [G loss: 1.074407]\n",
      "epoch:2 step:2802 [D loss: 0.776825, acc.: 63.28%] [G loss: 0.801363]\n",
      "epoch:2 step:2803 [D loss: 0.403066, acc.: 81.25%] [G loss: 0.983389]\n",
      "epoch:2 step:2804 [D loss: 0.438105, acc.: 76.56%] [G loss: 0.893721]\n",
      "epoch:2 step:2805 [D loss: 0.554773, acc.: 69.53%] [G loss: 0.610413]\n",
      "epoch:2 step:2806 [D loss: 0.597508, acc.: 64.84%] [G loss: 0.414022]\n",
      "epoch:2 step:2807 [D loss: 0.443465, acc.: 86.72%] [G loss: 0.612670]\n",
      "epoch:2 step:2808 [D loss: 0.510572, acc.: 80.47%] [G loss: 0.584011]\n",
      "epoch:2 step:2809 [D loss: 0.480608, acc.: 75.78%] [G loss: 0.690494]\n",
      "epoch:2 step:2810 [D loss: 0.294680, acc.: 92.19%] [G loss: 1.117731]\n",
      "epoch:2 step:2811 [D loss: 0.442410, acc.: 83.59%] [G loss: 0.928716]\n",
      "epoch:3 step:2812 [D loss: 0.543345, acc.: 71.88%] [G loss: 0.647125]\n",
      "epoch:3 step:2813 [D loss: 0.484304, acc.: 77.34%] [G loss: 0.639036]\n",
      "epoch:3 step:2814 [D loss: 0.583266, acc.: 71.09%] [G loss: 0.749989]\n",
      "epoch:3 step:2815 [D loss: 0.475073, acc.: 77.34%] [G loss: 0.688695]\n",
      "epoch:3 step:2816 [D loss: 0.466395, acc.: 80.47%] [G loss: 0.697785]\n",
      "epoch:3 step:2817 [D loss: 0.505613, acc.: 71.09%] [G loss: 0.583587]\n",
      "epoch:3 step:2818 [D loss: 0.439604, acc.: 85.16%] [G loss: 0.742204]\n",
      "epoch:3 step:2819 [D loss: 0.499730, acc.: 72.66%] [G loss: 0.638375]\n",
      "epoch:3 step:2820 [D loss: 0.447184, acc.: 78.12%] [G loss: 0.686031]\n",
      "epoch:3 step:2821 [D loss: 0.530133, acc.: 75.78%] [G loss: 0.463268]\n",
      "epoch:3 step:2822 [D loss: 0.478294, acc.: 77.34%] [G loss: 0.600391]\n",
      "epoch:3 step:2823 [D loss: 0.502591, acc.: 74.22%] [G loss: 0.630739]\n",
      "epoch:3 step:2824 [D loss: 0.431814, acc.: 85.16%] [G loss: 0.558167]\n",
      "epoch:3 step:2825 [D loss: 0.497404, acc.: 75.00%] [G loss: 0.560998]\n",
      "epoch:3 step:2826 [D loss: 0.414414, acc.: 87.50%] [G loss: 0.533852]\n",
      "epoch:3 step:2827 [D loss: 0.471758, acc.: 77.34%] [G loss: 0.663003]\n",
      "epoch:3 step:2828 [D loss: 0.520670, acc.: 72.66%] [G loss: 0.591769]\n",
      "epoch:3 step:2829 [D loss: 0.475416, acc.: 75.78%] [G loss: 0.662627]\n",
      "epoch:3 step:2830 [D loss: 0.523542, acc.: 75.00%] [G loss: 0.584637]\n",
      "epoch:3 step:2831 [D loss: 0.562762, acc.: 71.09%] [G loss: 0.543337]\n",
      "epoch:3 step:2832 [D loss: 0.471185, acc.: 82.03%] [G loss: 0.600986]\n",
      "epoch:3 step:2833 [D loss: 0.424765, acc.: 84.38%] [G loss: 0.705383]\n",
      "epoch:3 step:2834 [D loss: 0.502902, acc.: 75.00%] [G loss: 0.684582]\n",
      "epoch:3 step:2835 [D loss: 0.486860, acc.: 78.91%] [G loss: 0.739842]\n",
      "epoch:3 step:2836 [D loss: 0.479569, acc.: 79.69%] [G loss: 0.615716]\n",
      "epoch:3 step:2837 [D loss: 0.476059, acc.: 75.00%] [G loss: 0.578363]\n",
      "epoch:3 step:2838 [D loss: 0.472526, acc.: 78.91%] [G loss: 0.583350]\n",
      "epoch:3 step:2839 [D loss: 0.523341, acc.: 75.00%] [G loss: 0.516336]\n",
      "epoch:3 step:2840 [D loss: 0.480046, acc.: 82.81%] [G loss: 0.666373]\n",
      "epoch:3 step:2841 [D loss: 0.518177, acc.: 77.34%] [G loss: 0.665624]\n",
      "epoch:3 step:2842 [D loss: 0.508450, acc.: 78.12%] [G loss: 0.726781]\n",
      "epoch:3 step:2843 [D loss: 0.529235, acc.: 75.00%] [G loss: 0.545712]\n",
      "epoch:3 step:2844 [D loss: 0.461813, acc.: 75.00%] [G loss: 0.677983]\n",
      "epoch:3 step:2845 [D loss: 0.476575, acc.: 79.69%] [G loss: 0.644233]\n",
      "epoch:3 step:2846 [D loss: 0.511514, acc.: 75.00%] [G loss: 0.686149]\n",
      "epoch:3 step:2847 [D loss: 0.425341, acc.: 82.03%] [G loss: 0.929680]\n",
      "epoch:3 step:2848 [D loss: 0.494369, acc.: 73.44%] [G loss: 0.679069]\n",
      "epoch:3 step:2849 [D loss: 0.564929, acc.: 66.41%] [G loss: 0.659366]\n",
      "epoch:3 step:2850 [D loss: 0.474661, acc.: 82.81%] [G loss: 0.624687]\n",
      "epoch:3 step:2851 [D loss: 0.481713, acc.: 80.47%] [G loss: 0.685491]\n",
      "epoch:3 step:2852 [D loss: 0.535544, acc.: 76.56%] [G loss: 0.608777]\n",
      "epoch:3 step:2853 [D loss: 0.451187, acc.: 82.03%] [G loss: 0.628354]\n",
      "epoch:3 step:2854 [D loss: 0.478540, acc.: 75.78%] [G loss: 0.525153]\n",
      "epoch:3 step:2855 [D loss: 0.494888, acc.: 81.25%] [G loss: 0.419215]\n",
      "epoch:3 step:2856 [D loss: 0.471128, acc.: 80.47%] [G loss: 0.547428]\n",
      "epoch:3 step:2857 [D loss: 0.505880, acc.: 75.00%] [G loss: 0.439586]\n",
      "epoch:3 step:2858 [D loss: 0.564217, acc.: 69.53%] [G loss: 0.457959]\n",
      "epoch:3 step:2859 [D loss: 0.553063, acc.: 70.31%] [G loss: 0.554569]\n",
      "epoch:3 step:2860 [D loss: 0.553247, acc.: 66.41%] [G loss: 0.467355]\n",
      "epoch:3 step:2861 [D loss: 0.512082, acc.: 79.69%] [G loss: 0.501732]\n",
      "epoch:3 step:2862 [D loss: 0.493151, acc.: 79.69%] [G loss: 0.529832]\n",
      "epoch:3 step:2863 [D loss: 0.504294, acc.: 73.44%] [G loss: 0.472438]\n",
      "epoch:3 step:2864 [D loss: 0.449103, acc.: 82.81%] [G loss: 0.536102]\n",
      "epoch:3 step:2865 [D loss: 0.464700, acc.: 81.25%] [G loss: 0.629474]\n",
      "epoch:3 step:2866 [D loss: 0.524487, acc.: 76.56%] [G loss: 0.558990]\n",
      "epoch:3 step:2867 [D loss: 0.490742, acc.: 76.56%] [G loss: 0.603708]\n",
      "epoch:3 step:2868 [D loss: 0.476761, acc.: 78.12%] [G loss: 0.582382]\n",
      "epoch:3 step:2869 [D loss: 0.522052, acc.: 74.22%] [G loss: 0.493318]\n",
      "epoch:3 step:2870 [D loss: 0.505283, acc.: 78.12%] [G loss: 0.615505]\n",
      "epoch:3 step:2871 [D loss: 0.504524, acc.: 75.00%] [G loss: 0.676027]\n",
      "epoch:3 step:2872 [D loss: 0.567486, acc.: 67.97%] [G loss: 0.528039]\n",
      "epoch:3 step:2873 [D loss: 0.565532, acc.: 71.09%] [G loss: 0.579343]\n",
      "epoch:3 step:2874 [D loss: 0.535052, acc.: 77.34%] [G loss: 0.543510]\n",
      "epoch:3 step:2875 [D loss: 0.549520, acc.: 75.00%] [G loss: 0.453116]\n",
      "epoch:3 step:2876 [D loss: 0.539692, acc.: 72.66%] [G loss: 0.448085]\n",
      "epoch:3 step:2877 [D loss: 0.510223, acc.: 78.91%] [G loss: 0.578876]\n",
      "epoch:3 step:2878 [D loss: 0.506639, acc.: 75.78%] [G loss: 0.671615]\n",
      "epoch:3 step:2879 [D loss: 0.539748, acc.: 71.88%] [G loss: 0.620804]\n",
      "epoch:3 step:2880 [D loss: 0.523968, acc.: 75.78%] [G loss: 0.546014]\n",
      "epoch:3 step:2881 [D loss: 0.506550, acc.: 77.34%] [G loss: 0.440501]\n",
      "epoch:3 step:2882 [D loss: 0.445696, acc.: 83.59%] [G loss: 0.600520]\n",
      "epoch:3 step:2883 [D loss: 0.477420, acc.: 80.47%] [G loss: 0.551377]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:3 step:2884 [D loss: 0.455214, acc.: 85.94%] [G loss: 0.546176]\n",
      "epoch:3 step:2885 [D loss: 0.454357, acc.: 79.69%] [G loss: 0.624385]\n",
      "epoch:3 step:2886 [D loss: 0.456406, acc.: 83.59%] [G loss: 0.631308]\n",
      "epoch:3 step:2887 [D loss: 0.461332, acc.: 77.34%] [G loss: 0.720420]\n",
      "epoch:3 step:2888 [D loss: 0.371295, acc.: 86.72%] [G loss: 0.994205]\n",
      "epoch:3 step:2889 [D loss: 0.584917, acc.: 64.84%] [G loss: 0.522355]\n",
      "epoch:3 step:2890 [D loss: 0.481392, acc.: 79.69%] [G loss: 0.543680]\n",
      "epoch:3 step:2891 [D loss: 0.516251, acc.: 73.44%] [G loss: 0.501527]\n",
      "epoch:3 step:2892 [D loss: 0.542843, acc.: 73.44%] [G loss: 0.457462]\n",
      "epoch:3 step:2893 [D loss: 0.475159, acc.: 76.56%] [G loss: 0.529572]\n",
      "epoch:3 step:2894 [D loss: 0.500127, acc.: 76.56%] [G loss: 0.571095]\n",
      "epoch:3 step:2895 [D loss: 0.530342, acc.: 71.88%] [G loss: 0.561951]\n",
      "epoch:3 step:2896 [D loss: 0.550762, acc.: 68.75%] [G loss: 0.535748]\n",
      "epoch:3 step:2897 [D loss: 0.460829, acc.: 85.94%] [G loss: 0.593949]\n",
      "epoch:3 step:2898 [D loss: 0.456222, acc.: 78.91%] [G loss: 0.746320]\n",
      "epoch:3 step:2899 [D loss: 0.530368, acc.: 71.09%] [G loss: 0.581146]\n",
      "epoch:3 step:2900 [D loss: 0.517774, acc.: 75.00%] [G loss: 0.626528]\n",
      "epoch:3 step:2901 [D loss: 0.476994, acc.: 80.47%] [G loss: 0.604494]\n",
      "epoch:3 step:2902 [D loss: 0.493735, acc.: 75.78%] [G loss: 0.605215]\n",
      "epoch:3 step:2903 [D loss: 0.475444, acc.: 78.12%] [G loss: 0.690619]\n",
      "epoch:3 step:2904 [D loss: 0.495760, acc.: 80.47%] [G loss: 0.568264]\n",
      "epoch:3 step:2905 [D loss: 0.451638, acc.: 84.38%] [G loss: 0.850139]\n",
      "epoch:3 step:2906 [D loss: 0.522405, acc.: 75.78%] [G loss: 0.560437]\n",
      "epoch:3 step:2907 [D loss: 0.452617, acc.: 82.03%] [G loss: 0.596940]\n",
      "epoch:3 step:2908 [D loss: 0.540684, acc.: 74.22%] [G loss: 0.700979]\n",
      "epoch:3 step:2909 [D loss: 0.476972, acc.: 77.34%] [G loss: 0.676942]\n",
      "epoch:3 step:2910 [D loss: 0.499269, acc.: 75.78%] [G loss: 0.630412]\n",
      "epoch:3 step:2911 [D loss: 0.454168, acc.: 78.91%] [G loss: 0.709867]\n",
      "epoch:3 step:2912 [D loss: 0.493448, acc.: 75.00%] [G loss: 0.616825]\n",
      "epoch:3 step:2913 [D loss: 0.539740, acc.: 71.88%] [G loss: 0.617358]\n",
      "epoch:3 step:2914 [D loss: 0.421085, acc.: 82.81%] [G loss: 0.665621]\n",
      "epoch:3 step:2915 [D loss: 0.505959, acc.: 76.56%] [G loss: 0.516792]\n",
      "epoch:3 step:2916 [D loss: 0.487482, acc.: 77.34%] [G loss: 0.754746]\n",
      "epoch:3 step:2917 [D loss: 0.563123, acc.: 69.53%] [G loss: 0.548619]\n",
      "epoch:3 step:2918 [D loss: 0.561326, acc.: 68.75%] [G loss: 0.544103]\n",
      "epoch:3 step:2919 [D loss: 0.553352, acc.: 72.66%] [G loss: 0.491794]\n",
      "epoch:3 step:2920 [D loss: 0.597075, acc.: 74.22%] [G loss: 0.588930]\n",
      "epoch:3 step:2921 [D loss: 0.530046, acc.: 78.12%] [G loss: 0.642247]\n",
      "epoch:3 step:2922 [D loss: 0.550422, acc.: 71.88%] [G loss: 0.543529]\n",
      "epoch:3 step:2923 [D loss: 0.535280, acc.: 70.31%] [G loss: 0.589422]\n",
      "epoch:3 step:2924 [D loss: 0.549308, acc.: 70.31%] [G loss: 0.548643]\n",
      "epoch:3 step:2925 [D loss: 0.519052, acc.: 80.47%] [G loss: 0.588645]\n",
      "epoch:3 step:2926 [D loss: 0.567877, acc.: 66.41%] [G loss: 0.593864]\n",
      "epoch:3 step:2927 [D loss: 0.521613, acc.: 75.00%] [G loss: 0.730833]\n",
      "epoch:3 step:2928 [D loss: 0.513702, acc.: 76.56%] [G loss: 0.589326]\n",
      "epoch:3 step:2929 [D loss: 0.514778, acc.: 75.78%] [G loss: 0.672609]\n",
      "epoch:3 step:2930 [D loss: 0.448063, acc.: 80.47%] [G loss: 0.786289]\n",
      "epoch:3 step:2931 [D loss: 0.588495, acc.: 74.22%] [G loss: 0.746383]\n",
      "epoch:3 step:2932 [D loss: 0.550438, acc.: 71.09%] [G loss: 0.479895]\n",
      "epoch:3 step:2933 [D loss: 0.568347, acc.: 65.62%] [G loss: 0.612954]\n",
      "epoch:3 step:2934 [D loss: 0.603110, acc.: 62.50%] [G loss: 0.513278]\n",
      "epoch:3 step:2935 [D loss: 0.515161, acc.: 78.12%] [G loss: 0.603246]\n",
      "epoch:3 step:2936 [D loss: 0.556530, acc.: 71.09%] [G loss: 0.454610]\n",
      "epoch:3 step:2937 [D loss: 0.490728, acc.: 78.91%] [G loss: 0.499912]\n",
      "epoch:3 step:2938 [D loss: 0.525979, acc.: 78.12%] [G loss: 0.543238]\n",
      "epoch:3 step:2939 [D loss: 0.461627, acc.: 83.59%] [G loss: 0.546953]\n",
      "epoch:3 step:2940 [D loss: 0.557726, acc.: 71.09%] [G loss: 0.552899]\n",
      "epoch:3 step:2941 [D loss: 0.535964, acc.: 70.31%] [G loss: 0.460143]\n",
      "epoch:3 step:2942 [D loss: 0.451932, acc.: 81.25%] [G loss: 0.487635]\n",
      "epoch:3 step:2943 [D loss: 0.529194, acc.: 73.44%] [G loss: 0.534845]\n",
      "epoch:3 step:2944 [D loss: 0.564593, acc.: 69.53%] [G loss: 0.465114]\n",
      "epoch:3 step:2945 [D loss: 0.479774, acc.: 76.56%] [G loss: 0.610228]\n",
      "epoch:3 step:2946 [D loss: 0.466720, acc.: 78.12%] [G loss: 0.586764]\n",
      "epoch:3 step:2947 [D loss: 0.581408, acc.: 72.66%] [G loss: 0.569850]\n",
      "epoch:3 step:2948 [D loss: 0.632531, acc.: 68.75%] [G loss: 0.511373]\n",
      "epoch:3 step:2949 [D loss: 0.532658, acc.: 75.78%] [G loss: 0.483378]\n",
      "epoch:3 step:2950 [D loss: 0.576538, acc.: 69.53%] [G loss: 0.589612]\n",
      "epoch:3 step:2951 [D loss: 0.594508, acc.: 71.88%] [G loss: 0.443104]\n",
      "epoch:3 step:2952 [D loss: 0.483839, acc.: 81.25%] [G loss: 0.566285]\n",
      "epoch:3 step:2953 [D loss: 0.499663, acc.: 80.47%] [G loss: 0.625494]\n",
      "epoch:3 step:2954 [D loss: 0.574094, acc.: 68.75%] [G loss: 0.548774]\n",
      "epoch:3 step:2955 [D loss: 0.445465, acc.: 83.59%] [G loss: 0.503300]\n",
      "epoch:3 step:2956 [D loss: 0.517062, acc.: 71.88%] [G loss: 0.620451]\n",
      "epoch:3 step:2957 [D loss: 0.452800, acc.: 82.03%] [G loss: 0.685830]\n",
      "epoch:3 step:2958 [D loss: 0.563247, acc.: 71.88%] [G loss: 0.542105]\n",
      "epoch:3 step:2959 [D loss: 0.489698, acc.: 78.91%] [G loss: 0.583218]\n",
      "epoch:3 step:2960 [D loss: 0.482403, acc.: 78.91%] [G loss: 0.507926]\n",
      "epoch:3 step:2961 [D loss: 0.544534, acc.: 75.78%] [G loss: 0.536656]\n",
      "epoch:3 step:2962 [D loss: 0.458740, acc.: 83.59%] [G loss: 0.579773]\n",
      "epoch:3 step:2963 [D loss: 0.465192, acc.: 79.69%] [G loss: 0.668190]\n",
      "epoch:3 step:2964 [D loss: 0.563815, acc.: 73.44%] [G loss: 0.516441]\n",
      "epoch:3 step:2965 [D loss: 0.458958, acc.: 83.59%] [G loss: 0.528444]\n",
      "epoch:3 step:2966 [D loss: 0.458712, acc.: 79.69%] [G loss: 0.602262]\n",
      "epoch:3 step:2967 [D loss: 0.526540, acc.: 75.78%] [G loss: 0.603843]\n",
      "epoch:3 step:2968 [D loss: 0.520163, acc.: 71.09%] [G loss: 0.711789]\n",
      "epoch:3 step:2969 [D loss: 0.491980, acc.: 73.44%] [G loss: 0.647789]\n",
      "epoch:3 step:2970 [D loss: 0.558415, acc.: 68.75%] [G loss: 0.559348]\n",
      "epoch:3 step:2971 [D loss: 0.535135, acc.: 71.88%] [G loss: 0.634947]\n",
      "epoch:3 step:2972 [D loss: 0.521336, acc.: 78.12%] [G loss: 0.567651]\n",
      "epoch:3 step:2973 [D loss: 0.423016, acc.: 85.94%] [G loss: 0.587665]\n",
      "epoch:3 step:2974 [D loss: 0.513239, acc.: 75.78%] [G loss: 0.580804]\n",
      "epoch:3 step:2975 [D loss: 0.490236, acc.: 78.12%] [G loss: 0.697613]\n",
      "epoch:3 step:2976 [D loss: 0.461548, acc.: 79.69%] [G loss: 0.531194]\n",
      "epoch:3 step:2977 [D loss: 0.566050, acc.: 70.31%] [G loss: 0.538926]\n",
      "epoch:3 step:2978 [D loss: 0.585149, acc.: 64.06%] [G loss: 0.527269]\n",
      "epoch:3 step:2979 [D loss: 0.509206, acc.: 78.12%] [G loss: 0.640263]\n",
      "epoch:3 step:2980 [D loss: 0.568578, acc.: 71.09%] [G loss: 0.446228]\n",
      "epoch:3 step:2981 [D loss: 0.492673, acc.: 78.91%] [G loss: 0.478077]\n",
      "epoch:3 step:2982 [D loss: 0.455395, acc.: 76.56%] [G loss: 0.562151]\n",
      "epoch:3 step:2983 [D loss: 0.535551, acc.: 71.09%] [G loss: 0.494990]\n",
      "epoch:3 step:2984 [D loss: 0.511961, acc.: 76.56%] [G loss: 0.449184]\n",
      "epoch:3 step:2985 [D loss: 0.535893, acc.: 69.53%] [G loss: 0.553412]\n",
      "epoch:3 step:2986 [D loss: 0.508631, acc.: 75.00%] [G loss: 0.627527]\n",
      "epoch:3 step:2987 [D loss: 0.490462, acc.: 78.12%] [G loss: 0.492888]\n",
      "epoch:3 step:2988 [D loss: 0.482191, acc.: 77.34%] [G loss: 0.591969]\n",
      "epoch:3 step:2989 [D loss: 0.571288, acc.: 73.44%] [G loss: 0.545052]\n",
      "epoch:3 step:2990 [D loss: 0.502358, acc.: 71.09%] [G loss: 0.609493]\n",
      "epoch:3 step:2991 [D loss: 0.602983, acc.: 64.06%] [G loss: 0.444077]\n",
      "epoch:3 step:2992 [D loss: 0.464539, acc.: 82.81%] [G loss: 0.518360]\n",
      "epoch:3 step:2993 [D loss: 0.557914, acc.: 75.00%] [G loss: 0.499796]\n",
      "epoch:3 step:2994 [D loss: 0.542902, acc.: 72.66%] [G loss: 0.445543]\n",
      "epoch:3 step:2995 [D loss: 0.549974, acc.: 71.09%] [G loss: 0.462534]\n",
      "epoch:3 step:2996 [D loss: 0.554721, acc.: 67.19%] [G loss: 0.435083]\n",
      "epoch:3 step:2997 [D loss: 0.538876, acc.: 77.34%] [G loss: 0.494455]\n",
      "epoch:3 step:2998 [D loss: 0.582670, acc.: 70.31%] [G loss: 0.558085]\n",
      "epoch:3 step:2999 [D loss: 0.512777, acc.: 71.88%] [G loss: 0.505971]\n",
      "epoch:3 step:3000 [D loss: 0.555952, acc.: 69.53%] [G loss: 0.532080]\n",
      "##############\n",
      "[3.84298238 1.9913469  7.38571481 5.50626072 4.80250952 6.88204248\n",
      " 6.12461704 5.43739547 5.63755173 4.25785871]\n",
      "##########\n",
      "epoch:3 step:3001 [D loss: 0.428930, acc.: 85.94%] [G loss: 0.615786]\n",
      "epoch:3 step:3002 [D loss: 0.520792, acc.: 76.56%] [G loss: 0.638283]\n",
      "epoch:3 step:3003 [D loss: 0.495940, acc.: 80.47%] [G loss: 0.573023]\n",
      "epoch:3 step:3004 [D loss: 0.511956, acc.: 77.34%] [G loss: 0.566135]\n",
      "epoch:3 step:3005 [D loss: 0.446825, acc.: 83.59%] [G loss: 0.536866]\n",
      "epoch:3 step:3006 [D loss: 0.589873, acc.: 68.75%] [G loss: 0.607638]\n",
      "epoch:3 step:3007 [D loss: 0.547829, acc.: 70.31%] [G loss: 0.541040]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:3 step:3008 [D loss: 0.519370, acc.: 74.22%] [G loss: 0.604782]\n",
      "epoch:3 step:3009 [D loss: 0.459307, acc.: 78.91%] [G loss: 0.652794]\n",
      "epoch:3 step:3010 [D loss: 0.510136, acc.: 75.00%] [G loss: 0.544466]\n",
      "epoch:3 step:3011 [D loss: 0.646044, acc.: 60.94%] [G loss: 0.408065]\n",
      "epoch:3 step:3012 [D loss: 0.551139, acc.: 69.53%] [G loss: 0.548842]\n",
      "epoch:3 step:3013 [D loss: 0.524681, acc.: 77.34%] [G loss: 0.513683]\n",
      "epoch:3 step:3014 [D loss: 0.555702, acc.: 67.97%] [G loss: 0.444575]\n",
      "epoch:3 step:3015 [D loss: 0.473246, acc.: 77.34%] [G loss: 0.527061]\n",
      "epoch:3 step:3016 [D loss: 0.499009, acc.: 76.56%] [G loss: 0.473810]\n",
      "epoch:3 step:3017 [D loss: 0.479964, acc.: 74.22%] [G loss: 0.501088]\n",
      "epoch:3 step:3018 [D loss: 0.391025, acc.: 87.50%] [G loss: 0.617981]\n",
      "epoch:3 step:3019 [D loss: 0.456725, acc.: 79.69%] [G loss: 0.660139]\n",
      "epoch:3 step:3020 [D loss: 0.503005, acc.: 78.91%] [G loss: 0.622534]\n",
      "epoch:3 step:3021 [D loss: 0.532357, acc.: 75.78%] [G loss: 0.511482]\n",
      "epoch:3 step:3022 [D loss: 0.561636, acc.: 68.75%] [G loss: 0.474594]\n",
      "epoch:3 step:3023 [D loss: 0.542940, acc.: 75.00%] [G loss: 0.402959]\n",
      "epoch:3 step:3024 [D loss: 0.461242, acc.: 82.81%] [G loss: 0.494844]\n",
      "epoch:3 step:3025 [D loss: 0.665067, acc.: 61.72%] [G loss: 0.390450]\n",
      "epoch:3 step:3026 [D loss: 0.557604, acc.: 72.66%] [G loss: 0.349025]\n",
      "epoch:3 step:3027 [D loss: 0.529834, acc.: 69.53%] [G loss: 0.512807]\n",
      "epoch:3 step:3028 [D loss: 0.470837, acc.: 79.69%] [G loss: 0.537031]\n",
      "epoch:3 step:3029 [D loss: 0.497291, acc.: 79.69%] [G loss: 0.530615]\n",
      "epoch:3 step:3030 [D loss: 0.524055, acc.: 78.91%] [G loss: 0.643115]\n",
      "epoch:3 step:3031 [D loss: 0.548130, acc.: 69.53%] [G loss: 0.565364]\n",
      "epoch:3 step:3032 [D loss: 0.451848, acc.: 78.12%] [G loss: 0.629667]\n",
      "epoch:3 step:3033 [D loss: 0.473959, acc.: 77.34%] [G loss: 0.696603]\n",
      "epoch:3 step:3034 [D loss: 0.476614, acc.: 78.12%] [G loss: 0.638713]\n",
      "epoch:3 step:3035 [D loss: 0.521823, acc.: 74.22%] [G loss: 0.561681]\n",
      "epoch:3 step:3036 [D loss: 0.576899, acc.: 65.62%] [G loss: 0.403596]\n",
      "epoch:3 step:3037 [D loss: 0.569179, acc.: 68.75%] [G loss: 0.472587]\n",
      "epoch:3 step:3038 [D loss: 0.542755, acc.: 74.22%] [G loss: 0.520363]\n",
      "epoch:3 step:3039 [D loss: 0.548555, acc.: 70.31%] [G loss: 0.453401]\n",
      "epoch:3 step:3040 [D loss: 0.449250, acc.: 83.59%] [G loss: 0.603464]\n",
      "epoch:3 step:3041 [D loss: 0.495192, acc.: 77.34%] [G loss: 0.536251]\n",
      "epoch:3 step:3042 [D loss: 0.445514, acc.: 82.03%] [G loss: 0.783178]\n",
      "epoch:3 step:3043 [D loss: 0.421303, acc.: 84.38%] [G loss: 0.762857]\n",
      "epoch:3 step:3044 [D loss: 0.557785, acc.: 71.88%] [G loss: 0.649289]\n",
      "epoch:3 step:3045 [D loss: 0.523288, acc.: 71.88%] [G loss: 0.768609]\n",
      "epoch:3 step:3046 [D loss: 0.578604, acc.: 70.31%] [G loss: 0.630405]\n",
      "epoch:3 step:3047 [D loss: 0.509439, acc.: 76.56%] [G loss: 0.608194]\n",
      "epoch:3 step:3048 [D loss: 0.530594, acc.: 74.22%] [G loss: 0.566293]\n",
      "epoch:3 step:3049 [D loss: 0.542593, acc.: 74.22%] [G loss: 0.427126]\n",
      "epoch:3 step:3050 [D loss: 0.502973, acc.: 75.78%] [G loss: 0.617987]\n",
      "epoch:3 step:3051 [D loss: 0.519074, acc.: 71.88%] [G loss: 0.455045]\n",
      "epoch:3 step:3052 [D loss: 0.516466, acc.: 74.22%] [G loss: 0.546811]\n",
      "epoch:3 step:3053 [D loss: 0.520834, acc.: 74.22%] [G loss: 0.589333]\n",
      "epoch:3 step:3054 [D loss: 0.491957, acc.: 77.34%] [G loss: 0.514149]\n",
      "epoch:3 step:3055 [D loss: 0.479027, acc.: 76.56%] [G loss: 0.680961]\n",
      "epoch:3 step:3056 [D loss: 0.475186, acc.: 78.12%] [G loss: 0.570183]\n",
      "epoch:3 step:3057 [D loss: 0.530040, acc.: 78.12%] [G loss: 0.530311]\n",
      "epoch:3 step:3058 [D loss: 0.606502, acc.: 64.06%] [G loss: 0.466025]\n",
      "epoch:3 step:3059 [D loss: 0.541534, acc.: 74.22%] [G loss: 0.501331]\n",
      "epoch:3 step:3060 [D loss: 0.588944, acc.: 70.31%] [G loss: 0.510473]\n",
      "epoch:3 step:3061 [D loss: 0.600636, acc.: 64.84%] [G loss: 0.378442]\n",
      "epoch:3 step:3062 [D loss: 0.628579, acc.: 61.72%] [G loss: 0.537151]\n",
      "epoch:3 step:3063 [D loss: 0.525205, acc.: 74.22%] [G loss: 0.467899]\n",
      "epoch:3 step:3064 [D loss: 0.510235, acc.: 75.00%] [G loss: 0.466193]\n",
      "epoch:3 step:3065 [D loss: 0.446896, acc.: 81.25%] [G loss: 0.608856]\n",
      "epoch:3 step:3066 [D loss: 0.478960, acc.: 79.69%] [G loss: 0.544829]\n",
      "epoch:3 step:3067 [D loss: 0.473742, acc.: 77.34%] [G loss: 0.508264]\n",
      "epoch:3 step:3068 [D loss: 0.509608, acc.: 76.56%] [G loss: 0.606802]\n",
      "epoch:3 step:3069 [D loss: 0.523083, acc.: 75.00%] [G loss: 0.442523]\n",
      "epoch:3 step:3070 [D loss: 0.479450, acc.: 76.56%] [G loss: 0.635971]\n",
      "epoch:3 step:3071 [D loss: 0.545314, acc.: 73.44%] [G loss: 0.603514]\n",
      "epoch:3 step:3072 [D loss: 0.477239, acc.: 75.00%] [G loss: 0.687510]\n",
      "epoch:3 step:3073 [D loss: 0.482696, acc.: 81.25%] [G loss: 0.534443]\n",
      "epoch:3 step:3074 [D loss: 0.603862, acc.: 70.31%] [G loss: 0.382904]\n",
      "epoch:3 step:3075 [D loss: 0.500189, acc.: 80.47%] [G loss: 0.388668]\n",
      "epoch:3 step:3076 [D loss: 0.546842, acc.: 71.88%] [G loss: 0.527989]\n",
      "epoch:3 step:3077 [D loss: 0.539726, acc.: 75.78%] [G loss: 0.539744]\n",
      "epoch:3 step:3078 [D loss: 0.539888, acc.: 74.22%] [G loss: 0.524082]\n",
      "epoch:3 step:3079 [D loss: 0.549767, acc.: 69.53%] [G loss: 0.412829]\n",
      "epoch:3 step:3080 [D loss: 0.550634, acc.: 71.88%] [G loss: 0.392511]\n",
      "epoch:3 step:3081 [D loss: 0.522932, acc.: 72.66%] [G loss: 0.447845]\n",
      "epoch:3 step:3082 [D loss: 0.488524, acc.: 76.56%] [G loss: 0.517883]\n",
      "epoch:3 step:3083 [D loss: 0.539512, acc.: 74.22%] [G loss: 0.424246]\n",
      "epoch:3 step:3084 [D loss: 0.531639, acc.: 75.00%] [G loss: 0.540042]\n",
      "epoch:3 step:3085 [D loss: 0.563828, acc.: 69.53%] [G loss: 0.511995]\n",
      "epoch:3 step:3086 [D loss: 0.581906, acc.: 67.19%] [G loss: 0.446883]\n",
      "epoch:3 step:3087 [D loss: 0.538306, acc.: 73.44%] [G loss: 0.454738]\n",
      "epoch:3 step:3088 [D loss: 0.584395, acc.: 66.41%] [G loss: 0.414142]\n",
      "epoch:3 step:3089 [D loss: 0.601817, acc.: 67.97%] [G loss: 0.451488]\n",
      "epoch:3 step:3090 [D loss: 0.486703, acc.: 82.81%] [G loss: 0.629652]\n",
      "epoch:3 step:3091 [D loss: 0.529036, acc.: 72.66%] [G loss: 0.508085]\n",
      "epoch:3 step:3092 [D loss: 0.616730, acc.: 67.97%] [G loss: 0.402285]\n",
      "epoch:3 step:3093 [D loss: 0.584242, acc.: 64.84%] [G loss: 0.427971]\n",
      "epoch:3 step:3094 [D loss: 0.502555, acc.: 78.12%] [G loss: 0.463903]\n",
      "epoch:3 step:3095 [D loss: 0.430377, acc.: 85.16%] [G loss: 0.516406]\n",
      "epoch:3 step:3096 [D loss: 0.445289, acc.: 82.81%] [G loss: 0.556381]\n",
      "epoch:3 step:3097 [D loss: 0.479076, acc.: 76.56%] [G loss: 0.699816]\n",
      "epoch:3 step:3098 [D loss: 0.575400, acc.: 70.31%] [G loss: 0.531219]\n",
      "epoch:3 step:3099 [D loss: 0.585080, acc.: 69.53%] [G loss: 0.457869]\n",
      "epoch:3 step:3100 [D loss: 0.509155, acc.: 72.66%] [G loss: 0.555520]\n",
      "epoch:3 step:3101 [D loss: 0.519681, acc.: 77.34%] [G loss: 0.511162]\n",
      "epoch:3 step:3102 [D loss: 0.525253, acc.: 72.66%] [G loss: 0.509811]\n",
      "epoch:3 step:3103 [D loss: 0.552278, acc.: 72.66%] [G loss: 0.546070]\n",
      "epoch:3 step:3104 [D loss: 0.512327, acc.: 78.12%] [G loss: 0.468752]\n",
      "epoch:3 step:3105 [D loss: 0.532308, acc.: 77.34%] [G loss: 0.546429]\n",
      "epoch:3 step:3106 [D loss: 0.536038, acc.: 75.78%] [G loss: 0.462037]\n",
      "epoch:3 step:3107 [D loss: 0.466490, acc.: 78.12%] [G loss: 0.480087]\n",
      "epoch:3 step:3108 [D loss: 0.618402, acc.: 67.19%] [G loss: 0.395365]\n",
      "epoch:3 step:3109 [D loss: 0.512102, acc.: 78.12%] [G loss: 0.428223]\n",
      "epoch:3 step:3110 [D loss: 0.565849, acc.: 73.44%] [G loss: 0.478266]\n",
      "epoch:3 step:3111 [D loss: 0.517712, acc.: 81.25%] [G loss: 0.405523]\n",
      "epoch:3 step:3112 [D loss: 0.566681, acc.: 75.78%] [G loss: 0.431881]\n",
      "epoch:3 step:3113 [D loss: 0.553481, acc.: 74.22%] [G loss: 0.430368]\n",
      "epoch:3 step:3114 [D loss: 0.469816, acc.: 84.38%] [G loss: 0.482193]\n",
      "epoch:3 step:3115 [D loss: 0.487017, acc.: 78.12%] [G loss: 0.421635]\n",
      "epoch:3 step:3116 [D loss: 0.475446, acc.: 83.59%] [G loss: 0.544778]\n",
      "epoch:3 step:3117 [D loss: 0.536208, acc.: 71.88%] [G loss: 0.571076]\n",
      "epoch:3 step:3118 [D loss: 0.488443, acc.: 70.31%] [G loss: 0.511909]\n",
      "epoch:3 step:3119 [D loss: 0.495955, acc.: 81.25%] [G loss: 0.578405]\n",
      "epoch:3 step:3120 [D loss: 0.478537, acc.: 77.34%] [G loss: 0.540786]\n",
      "epoch:3 step:3121 [D loss: 0.463354, acc.: 78.91%] [G loss: 0.635896]\n",
      "epoch:3 step:3122 [D loss: 0.450209, acc.: 75.00%] [G loss: 0.685161]\n",
      "epoch:3 step:3123 [D loss: 0.408731, acc.: 82.03%] [G loss: 0.806158]\n",
      "epoch:3 step:3124 [D loss: 0.466502, acc.: 79.69%] [G loss: 0.822087]\n",
      "epoch:3 step:3125 [D loss: 0.419456, acc.: 85.94%] [G loss: 0.940860]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:3 step:3126 [D loss: 0.446433, acc.: 80.47%] [G loss: 0.851298]\n",
      "epoch:3 step:3127 [D loss: 0.680934, acc.: 62.50%] [G loss: 0.496038]\n",
      "epoch:3 step:3128 [D loss: 0.608614, acc.: 67.97%] [G loss: 0.368875]\n",
      "epoch:3 step:3129 [D loss: 0.474201, acc.: 79.69%] [G loss: 0.449452]\n",
      "epoch:3 step:3130 [D loss: 0.562972, acc.: 69.53%] [G loss: 0.487105]\n",
      "epoch:3 step:3131 [D loss: 0.447096, acc.: 78.12%] [G loss: 0.518023]\n",
      "epoch:3 step:3132 [D loss: 0.473014, acc.: 76.56%] [G loss: 0.639679]\n",
      "epoch:3 step:3133 [D loss: 0.508710, acc.: 77.34%] [G loss: 0.558685]\n",
      "epoch:3 step:3134 [D loss: 0.581202, acc.: 67.97%] [G loss: 0.440655]\n",
      "epoch:3 step:3135 [D loss: 0.549410, acc.: 67.97%] [G loss: 0.368355]\n",
      "epoch:3 step:3136 [D loss: 0.515613, acc.: 76.56%] [G loss: 0.626576]\n",
      "epoch:3 step:3137 [D loss: 0.494695, acc.: 75.00%] [G loss: 0.673756]\n",
      "epoch:3 step:3138 [D loss: 0.519136, acc.: 77.34%] [G loss: 0.586999]\n",
      "epoch:3 step:3139 [D loss: 0.485656, acc.: 78.12%] [G loss: 0.524775]\n",
      "epoch:3 step:3140 [D loss: 0.495825, acc.: 75.78%] [G loss: 0.457470]\n",
      "epoch:3 step:3141 [D loss: 0.502199, acc.: 78.91%] [G loss: 0.505348]\n",
      "epoch:3 step:3142 [D loss: 0.497795, acc.: 75.00%] [G loss: 0.404166]\n",
      "epoch:3 step:3143 [D loss: 0.519737, acc.: 73.44%] [G loss: 0.414238]\n",
      "epoch:3 step:3144 [D loss: 0.489153, acc.: 78.91%] [G loss: 0.493340]\n",
      "epoch:3 step:3145 [D loss: 0.523911, acc.: 76.56%] [G loss: 0.621002]\n",
      "epoch:3 step:3146 [D loss: 0.500939, acc.: 77.34%] [G loss: 0.580304]\n",
      "epoch:3 step:3147 [D loss: 0.451517, acc.: 78.91%] [G loss: 0.709728]\n",
      "epoch:3 step:3148 [D loss: 0.471557, acc.: 80.47%] [G loss: 0.608262]\n",
      "epoch:3 step:3149 [D loss: 0.557110, acc.: 68.75%] [G loss: 0.584155]\n",
      "epoch:3 step:3150 [D loss: 0.494137, acc.: 80.47%] [G loss: 0.620745]\n",
      "epoch:3 step:3151 [D loss: 0.516855, acc.: 74.22%] [G loss: 0.557552]\n",
      "epoch:3 step:3152 [D loss: 0.597001, acc.: 72.66%] [G loss: 0.419254]\n",
      "epoch:3 step:3153 [D loss: 0.584662, acc.: 71.88%] [G loss: 0.456741]\n",
      "epoch:3 step:3154 [D loss: 0.454814, acc.: 78.91%] [G loss: 0.645672]\n",
      "epoch:3 step:3155 [D loss: 0.453957, acc.: 78.91%] [G loss: 0.547168]\n",
      "epoch:3 step:3156 [D loss: 0.473653, acc.: 81.25%] [G loss: 0.744355]\n",
      "epoch:3 step:3157 [D loss: 0.493929, acc.: 71.09%] [G loss: 0.832912]\n",
      "epoch:3 step:3158 [D loss: 0.447184, acc.: 82.81%] [G loss: 0.971776]\n",
      "epoch:3 step:3159 [D loss: 0.644100, acc.: 62.50%] [G loss: 0.483172]\n",
      "epoch:3 step:3160 [D loss: 0.652996, acc.: 63.28%] [G loss: 0.465236]\n",
      "epoch:3 step:3161 [D loss: 0.484295, acc.: 78.12%] [G loss: 0.556454]\n",
      "epoch:3 step:3162 [D loss: 0.486114, acc.: 79.69%] [G loss: 0.551552]\n",
      "epoch:3 step:3163 [D loss: 0.538659, acc.: 74.22%] [G loss: 0.604818]\n",
      "epoch:3 step:3164 [D loss: 0.585585, acc.: 70.31%] [G loss: 0.471448]\n",
      "epoch:3 step:3165 [D loss: 0.463780, acc.: 81.25%] [G loss: 0.680974]\n",
      "epoch:3 step:3166 [D loss: 0.584788, acc.: 67.19%] [G loss: 0.561408]\n",
      "epoch:3 step:3167 [D loss: 0.560839, acc.: 74.22%] [G loss: 0.482525]\n",
      "epoch:3 step:3168 [D loss: 0.456064, acc.: 81.25%] [G loss: 0.676686]\n",
      "epoch:3 step:3169 [D loss: 0.473403, acc.: 79.69%] [G loss: 0.747477]\n",
      "epoch:3 step:3170 [D loss: 0.488629, acc.: 78.91%] [G loss: 0.693574]\n",
      "epoch:3 step:3171 [D loss: 0.495939, acc.: 78.91%] [G loss: 0.594812]\n",
      "epoch:3 step:3172 [D loss: 0.551861, acc.: 75.78%] [G loss: 0.434573]\n",
      "epoch:3 step:3173 [D loss: 0.512351, acc.: 75.78%] [G loss: 0.571667]\n",
      "epoch:3 step:3174 [D loss: 0.493038, acc.: 74.22%] [G loss: 0.553217]\n",
      "epoch:3 step:3175 [D loss: 0.507059, acc.: 71.88%] [G loss: 0.643464]\n",
      "epoch:3 step:3176 [D loss: 0.489298, acc.: 74.22%] [G loss: 0.556106]\n",
      "epoch:3 step:3177 [D loss: 0.497248, acc.: 75.78%] [G loss: 0.693744]\n",
      "epoch:3 step:3178 [D loss: 0.551638, acc.: 74.22%] [G loss: 0.613220]\n",
      "epoch:3 step:3179 [D loss: 0.524201, acc.: 71.88%] [G loss: 0.599298]\n",
      "epoch:3 step:3180 [D loss: 0.492268, acc.: 75.78%] [G loss: 0.570642]\n",
      "epoch:3 step:3181 [D loss: 0.544733, acc.: 75.00%] [G loss: 0.495385]\n",
      "epoch:3 step:3182 [D loss: 0.513335, acc.: 78.91%] [G loss: 0.597084]\n",
      "epoch:3 step:3183 [D loss: 0.517585, acc.: 75.78%] [G loss: 0.523596]\n",
      "epoch:3 step:3184 [D loss: 0.528931, acc.: 78.91%] [G loss: 0.560422]\n",
      "epoch:3 step:3185 [D loss: 0.473957, acc.: 81.25%] [G loss: 0.493799]\n",
      "epoch:3 step:3186 [D loss: 0.569585, acc.: 73.44%] [G loss: 0.397469]\n",
      "epoch:3 step:3187 [D loss: 0.586726, acc.: 66.41%] [G loss: 0.448096]\n",
      "epoch:3 step:3188 [D loss: 0.583176, acc.: 69.53%] [G loss: 0.475668]\n",
      "epoch:3 step:3189 [D loss: 0.540233, acc.: 71.09%] [G loss: 0.650892]\n",
      "epoch:3 step:3190 [D loss: 0.563472, acc.: 71.88%] [G loss: 0.514264]\n",
      "epoch:3 step:3191 [D loss: 0.560078, acc.: 72.66%] [G loss: 0.471833]\n",
      "epoch:3 step:3192 [D loss: 0.449321, acc.: 82.81%] [G loss: 0.482328]\n",
      "epoch:3 step:3193 [D loss: 0.495059, acc.: 78.12%] [G loss: 0.541356]\n",
      "epoch:3 step:3194 [D loss: 0.621901, acc.: 62.50%] [G loss: 0.453618]\n",
      "epoch:3 step:3195 [D loss: 0.494294, acc.: 73.44%] [G loss: 0.578100]\n",
      "epoch:3 step:3196 [D loss: 0.541268, acc.: 73.44%] [G loss: 0.452460]\n",
      "epoch:3 step:3197 [D loss: 0.589478, acc.: 66.41%] [G loss: 0.415109]\n",
      "epoch:3 step:3198 [D loss: 0.564639, acc.: 72.66%] [G loss: 0.404962]\n",
      "epoch:3 step:3199 [D loss: 0.575822, acc.: 69.53%] [G loss: 0.479277]\n",
      "epoch:3 step:3200 [D loss: 0.538314, acc.: 75.78%] [G loss: 0.566093]\n",
      "##############\n",
      "[3.91134126 2.22978365 7.44498067 5.64688987 4.81480182 6.36306065\n",
      " 6.04360464 5.47670405 5.56427349 4.12404818]\n",
      "##########\n",
      "epoch:3 step:3201 [D loss: 0.563728, acc.: 67.19%] [G loss: 0.408299]\n",
      "epoch:3 step:3202 [D loss: 0.492939, acc.: 83.59%] [G loss: 0.567217]\n",
      "epoch:3 step:3203 [D loss: 0.451320, acc.: 78.12%] [G loss: 0.574318]\n",
      "epoch:3 step:3204 [D loss: 0.552191, acc.: 72.66%] [G loss: 0.480402]\n",
      "epoch:3 step:3205 [D loss: 0.507348, acc.: 77.34%] [G loss: 0.506607]\n",
      "epoch:3 step:3206 [D loss: 0.509940, acc.: 71.88%] [G loss: 0.490618]\n",
      "epoch:3 step:3207 [D loss: 0.505991, acc.: 77.34%] [G loss: 0.527387]\n",
      "epoch:3 step:3208 [D loss: 0.502056, acc.: 76.56%] [G loss: 0.515837]\n",
      "epoch:3 step:3209 [D loss: 0.513158, acc.: 71.88%] [G loss: 0.566153]\n",
      "epoch:3 step:3210 [D loss: 0.457650, acc.: 80.47%] [G loss: 0.654348]\n",
      "epoch:3 step:3211 [D loss: 0.594126, acc.: 64.84%] [G loss: 0.495064]\n",
      "epoch:3 step:3212 [D loss: 0.531689, acc.: 73.44%] [G loss: 0.509022]\n",
      "epoch:3 step:3213 [D loss: 0.413970, acc.: 83.59%] [G loss: 0.621469]\n",
      "epoch:3 step:3214 [D loss: 0.477585, acc.: 77.34%] [G loss: 0.523689]\n",
      "epoch:3 step:3215 [D loss: 0.555088, acc.: 70.31%] [G loss: 0.406403]\n",
      "epoch:3 step:3216 [D loss: 0.548552, acc.: 71.09%] [G loss: 0.490041]\n",
      "epoch:3 step:3217 [D loss: 0.505888, acc.: 75.00%] [G loss: 0.587704]\n",
      "epoch:3 step:3218 [D loss: 0.463103, acc.: 85.94%] [G loss: 0.711163]\n",
      "epoch:3 step:3219 [D loss: 0.493686, acc.: 76.56%] [G loss: 0.571829]\n",
      "epoch:3 step:3220 [D loss: 0.449700, acc.: 82.03%] [G loss: 0.616256]\n",
      "epoch:3 step:3221 [D loss: 0.519444, acc.: 72.66%] [G loss: 0.545498]\n",
      "epoch:3 step:3222 [D loss: 0.549659, acc.: 76.56%] [G loss: 0.472858]\n",
      "epoch:3 step:3223 [D loss: 0.557143, acc.: 71.09%] [G loss: 0.468120]\n",
      "epoch:3 step:3224 [D loss: 0.514931, acc.: 82.81%] [G loss: 0.540275]\n",
      "epoch:3 step:3225 [D loss: 0.487341, acc.: 79.69%] [G loss: 0.463258]\n",
      "epoch:3 step:3226 [D loss: 0.520262, acc.: 75.78%] [G loss: 0.565664]\n",
      "epoch:3 step:3227 [D loss: 0.544018, acc.: 70.31%] [G loss: 0.547104]\n",
      "epoch:3 step:3228 [D loss: 0.542295, acc.: 77.34%] [G loss: 0.423086]\n",
      "epoch:3 step:3229 [D loss: 0.600501, acc.: 66.41%] [G loss: 0.511164]\n",
      "epoch:3 step:3230 [D loss: 0.517675, acc.: 77.34%] [G loss: 0.478602]\n",
      "epoch:3 step:3231 [D loss: 0.514961, acc.: 75.00%] [G loss: 0.481970]\n",
      "epoch:3 step:3232 [D loss: 0.553430, acc.: 71.88%] [G loss: 0.403189]\n",
      "epoch:3 step:3233 [D loss: 0.497599, acc.: 72.66%] [G loss: 0.554796]\n",
      "epoch:3 step:3234 [D loss: 0.529897, acc.: 71.88%] [G loss: 0.505202]\n",
      "epoch:3 step:3235 [D loss: 0.536599, acc.: 73.44%] [G loss: 0.534660]\n",
      "epoch:3 step:3236 [D loss: 0.465386, acc.: 82.81%] [G loss: 0.510388]\n",
      "epoch:3 step:3237 [D loss: 0.430358, acc.: 82.03%] [G loss: 0.593955]\n",
      "epoch:3 step:3238 [D loss: 0.478350, acc.: 75.78%] [G loss: 0.607412]\n",
      "epoch:3 step:3239 [D loss: 0.477725, acc.: 77.34%] [G loss: 0.669365]\n",
      "epoch:3 step:3240 [D loss: 0.444897, acc.: 81.25%] [G loss: 0.645494]\n",
      "epoch:3 step:3241 [D loss: 0.453650, acc.: 81.25%] [G loss: 0.724512]\n",
      "epoch:3 step:3242 [D loss: 0.522108, acc.: 78.12%] [G loss: 0.635437]\n",
      "epoch:3 step:3243 [D loss: 0.592791, acc.: 66.41%] [G loss: 0.493929]\n",
      "epoch:3 step:3244 [D loss: 0.528597, acc.: 75.78%] [G loss: 0.468636]\n",
      "epoch:3 step:3245 [D loss: 0.521889, acc.: 72.66%] [G loss: 0.431678]\n",
      "epoch:3 step:3246 [D loss: 0.506139, acc.: 80.47%] [G loss: 0.502659]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:3 step:3247 [D loss: 0.472711, acc.: 77.34%] [G loss: 0.596656]\n",
      "epoch:3 step:3248 [D loss: 0.634767, acc.: 64.84%] [G loss: 0.427561]\n",
      "epoch:3 step:3249 [D loss: 0.541985, acc.: 71.09%] [G loss: 0.474123]\n",
      "epoch:3 step:3250 [D loss: 0.483138, acc.: 76.56%] [G loss: 0.508027]\n",
      "epoch:3 step:3251 [D loss: 0.459670, acc.: 76.56%] [G loss: 0.660945]\n",
      "epoch:3 step:3252 [D loss: 0.540440, acc.: 67.19%] [G loss: 0.585622]\n",
      "epoch:3 step:3253 [D loss: 0.519220, acc.: 74.22%] [G loss: 0.491050]\n",
      "epoch:3 step:3254 [D loss: 0.473806, acc.: 82.81%] [G loss: 0.563755]\n",
      "epoch:3 step:3255 [D loss: 0.492547, acc.: 74.22%] [G loss: 0.678875]\n",
      "epoch:3 step:3256 [D loss: 0.467310, acc.: 80.47%] [G loss: 0.639722]\n",
      "epoch:3 step:3257 [D loss: 0.491977, acc.: 78.91%] [G loss: 0.612889]\n",
      "epoch:3 step:3258 [D loss: 0.517632, acc.: 72.66%] [G loss: 0.685036]\n",
      "epoch:3 step:3259 [D loss: 0.548044, acc.: 75.00%] [G loss: 0.659693]\n",
      "epoch:3 step:3260 [D loss: 0.531408, acc.: 75.00%] [G loss: 0.534235]\n",
      "epoch:3 step:3261 [D loss: 0.494081, acc.: 77.34%] [G loss: 0.600774]\n",
      "epoch:3 step:3262 [D loss: 0.435618, acc.: 82.81%] [G loss: 0.703882]\n",
      "epoch:3 step:3263 [D loss: 0.480910, acc.: 78.12%] [G loss: 0.635560]\n",
      "epoch:3 step:3264 [D loss: 0.480433, acc.: 78.12%] [G loss: 0.652779]\n",
      "epoch:3 step:3265 [D loss: 0.550331, acc.: 72.66%] [G loss: 0.518537]\n",
      "epoch:3 step:3266 [D loss: 0.548021, acc.: 70.31%] [G loss: 0.510042]\n",
      "epoch:3 step:3267 [D loss: 0.583540, acc.: 67.19%] [G loss: 0.386433]\n",
      "epoch:3 step:3268 [D loss: 0.533687, acc.: 75.00%] [G loss: 0.484603]\n",
      "epoch:3 step:3269 [D loss: 0.475876, acc.: 80.47%] [G loss: 0.657637]\n",
      "epoch:3 step:3270 [D loss: 0.532688, acc.: 73.44%] [G loss: 0.495639]\n",
      "epoch:3 step:3271 [D loss: 0.497989, acc.: 75.00%] [G loss: 0.561227]\n",
      "epoch:3 step:3272 [D loss: 0.463318, acc.: 77.34%] [G loss: 0.607827]\n",
      "epoch:3 step:3273 [D loss: 0.520018, acc.: 75.00%] [G loss: 0.520016]\n",
      "epoch:3 step:3274 [D loss: 0.549603, acc.: 69.53%] [G loss: 0.494343]\n",
      "epoch:3 step:3275 [D loss: 0.550460, acc.: 71.88%] [G loss: 0.598589]\n",
      "epoch:3 step:3276 [D loss: 0.631332, acc.: 65.62%] [G loss: 0.429869]\n",
      "epoch:3 step:3277 [D loss: 0.523117, acc.: 71.09%] [G loss: 0.633913]\n",
      "epoch:3 step:3278 [D loss: 0.552754, acc.: 67.97%] [G loss: 0.583943]\n",
      "epoch:3 step:3279 [D loss: 0.533725, acc.: 75.78%] [G loss: 0.605269]\n",
      "epoch:3 step:3280 [D loss: 0.530942, acc.: 77.34%] [G loss: 0.625240]\n",
      "epoch:3 step:3281 [D loss: 0.574470, acc.: 69.53%] [G loss: 0.409174]\n",
      "epoch:3 step:3282 [D loss: 0.520513, acc.: 75.78%] [G loss: 0.544238]\n",
      "epoch:3 step:3283 [D loss: 0.421513, acc.: 83.59%] [G loss: 0.785231]\n",
      "epoch:3 step:3284 [D loss: 0.619466, acc.: 67.19%] [G loss: 0.637050]\n",
      "epoch:3 step:3285 [D loss: 0.464017, acc.: 78.91%] [G loss: 0.742161]\n",
      "epoch:3 step:3286 [D loss: 0.424181, acc.: 82.81%] [G loss: 0.757780]\n",
      "epoch:3 step:3287 [D loss: 0.525600, acc.: 74.22%] [G loss: 0.567768]\n",
      "epoch:3 step:3288 [D loss: 0.673376, acc.: 62.50%] [G loss: 0.368368]\n",
      "epoch:3 step:3289 [D loss: 0.535139, acc.: 71.09%] [G loss: 0.388244]\n",
      "epoch:3 step:3290 [D loss: 0.563098, acc.: 71.09%] [G loss: 0.394695]\n",
      "epoch:3 step:3291 [D loss: 0.575890, acc.: 74.22%] [G loss: 0.459609]\n",
      "epoch:3 step:3292 [D loss: 0.556610, acc.: 68.75%] [G loss: 0.541553]\n",
      "epoch:3 step:3293 [D loss: 0.555771, acc.: 71.88%] [G loss: 0.500456]\n",
      "epoch:3 step:3294 [D loss: 0.529279, acc.: 71.09%] [G loss: 0.558662]\n",
      "epoch:3 step:3295 [D loss: 0.487075, acc.: 80.47%] [G loss: 0.589746]\n",
      "epoch:3 step:3296 [D loss: 0.508378, acc.: 72.66%] [G loss: 0.538743]\n",
      "epoch:3 step:3297 [D loss: 0.523394, acc.: 73.44%] [G loss: 0.530663]\n",
      "epoch:3 step:3298 [D loss: 0.540189, acc.: 78.12%] [G loss: 0.480935]\n",
      "epoch:3 step:3299 [D loss: 0.513552, acc.: 73.44%] [G loss: 0.497886]\n",
      "epoch:3 step:3300 [D loss: 0.550262, acc.: 76.56%] [G loss: 0.467304]\n",
      "epoch:3 step:3301 [D loss: 0.603394, acc.: 64.84%] [G loss: 0.523564]\n",
      "epoch:3 step:3302 [D loss: 0.492230, acc.: 72.66%] [G loss: 0.508381]\n",
      "epoch:3 step:3303 [D loss: 0.544101, acc.: 75.00%] [G loss: 0.442753]\n",
      "epoch:3 step:3304 [D loss: 0.570008, acc.: 67.97%] [G loss: 0.431518]\n",
      "epoch:3 step:3305 [D loss: 0.545506, acc.: 76.56%] [G loss: 0.452126]\n",
      "epoch:3 step:3306 [D loss: 0.532590, acc.: 71.88%] [G loss: 0.589306]\n",
      "epoch:3 step:3307 [D loss: 0.492779, acc.: 78.12%] [G loss: 0.585703]\n",
      "epoch:3 step:3308 [D loss: 0.501736, acc.: 75.00%] [G loss: 0.563522]\n",
      "epoch:3 step:3309 [D loss: 0.482728, acc.: 79.69%] [G loss: 0.527479]\n",
      "epoch:3 step:3310 [D loss: 0.416188, acc.: 83.59%] [G loss: 0.850271]\n",
      "epoch:3 step:3311 [D loss: 0.613867, acc.: 67.19%] [G loss: 0.568607]\n",
      "epoch:3 step:3312 [D loss: 0.653553, acc.: 60.94%] [G loss: 0.406846]\n",
      "epoch:3 step:3313 [D loss: 0.628798, acc.: 63.28%] [G loss: 0.377939]\n",
      "epoch:3 step:3314 [D loss: 0.479894, acc.: 78.12%] [G loss: 0.514289]\n",
      "epoch:3 step:3315 [D loss: 0.461169, acc.: 79.69%] [G loss: 0.665614]\n",
      "epoch:3 step:3316 [D loss: 0.548857, acc.: 73.44%] [G loss: 0.598255]\n",
      "epoch:3 step:3317 [D loss: 0.455897, acc.: 80.47%] [G loss: 0.597215]\n",
      "epoch:3 step:3318 [D loss: 0.522544, acc.: 75.78%] [G loss: 0.521581]\n",
      "epoch:3 step:3319 [D loss: 0.446121, acc.: 83.59%] [G loss: 0.716663]\n",
      "epoch:3 step:3320 [D loss: 0.499609, acc.: 79.69%] [G loss: 0.571256]\n",
      "epoch:3 step:3321 [D loss: 0.556954, acc.: 72.66%] [G loss: 0.542742]\n",
      "epoch:3 step:3322 [D loss: 0.599644, acc.: 66.41%] [G loss: 0.466126]\n",
      "epoch:3 step:3323 [D loss: 0.557702, acc.: 71.09%] [G loss: 0.550053]\n",
      "epoch:3 step:3324 [D loss: 0.514484, acc.: 75.00%] [G loss: 0.575714]\n",
      "epoch:3 step:3325 [D loss: 0.427027, acc.: 82.03%] [G loss: 0.718012]\n",
      "epoch:3 step:3326 [D loss: 0.507741, acc.: 73.44%] [G loss: 0.642481]\n",
      "epoch:3 step:3327 [D loss: 0.511438, acc.: 77.34%] [G loss: 0.545022]\n",
      "epoch:3 step:3328 [D loss: 0.540595, acc.: 72.66%] [G loss: 0.518213]\n",
      "epoch:3 step:3329 [D loss: 0.472447, acc.: 81.25%] [G loss: 0.538417]\n",
      "epoch:3 step:3330 [D loss: 0.544830, acc.: 75.00%] [G loss: 0.447796]\n",
      "epoch:3 step:3331 [D loss: 0.495511, acc.: 75.78%] [G loss: 0.549404]\n",
      "epoch:3 step:3332 [D loss: 0.488632, acc.: 82.81%] [G loss: 0.577774]\n",
      "epoch:3 step:3333 [D loss: 0.513730, acc.: 72.66%] [G loss: 0.637468]\n",
      "epoch:3 step:3334 [D loss: 0.464234, acc.: 82.03%] [G loss: 0.760403]\n",
      "epoch:3 step:3335 [D loss: 0.553319, acc.: 69.53%] [G loss: 0.506521]\n",
      "epoch:3 step:3336 [D loss: 0.582592, acc.: 72.66%] [G loss: 0.481105]\n",
      "epoch:3 step:3337 [D loss: 0.522805, acc.: 75.00%] [G loss: 0.451916]\n",
      "epoch:3 step:3338 [D loss: 0.594042, acc.: 69.53%] [G loss: 0.449821]\n",
      "epoch:3 step:3339 [D loss: 0.595798, acc.: 66.41%] [G loss: 0.389548]\n",
      "epoch:3 step:3340 [D loss: 0.561898, acc.: 71.09%] [G loss: 0.330460]\n",
      "epoch:3 step:3341 [D loss: 0.498842, acc.: 75.78%] [G loss: 0.507745]\n",
      "epoch:3 step:3342 [D loss: 0.573024, acc.: 70.31%] [G loss: 0.499142]\n",
      "epoch:3 step:3343 [D loss: 0.508827, acc.: 76.56%] [G loss: 0.568631]\n",
      "epoch:3 step:3344 [D loss: 0.535498, acc.: 74.22%] [G loss: 0.592206]\n",
      "epoch:3 step:3345 [D loss: 0.468540, acc.: 82.81%] [G loss: 0.492342]\n",
      "epoch:3 step:3346 [D loss: 0.516264, acc.: 72.66%] [G loss: 0.439275]\n",
      "epoch:3 step:3347 [D loss: 0.473149, acc.: 74.22%] [G loss: 0.539805]\n",
      "epoch:3 step:3348 [D loss: 0.543260, acc.: 71.88%] [G loss: 0.546271]\n",
      "epoch:3 step:3349 [D loss: 0.507716, acc.: 76.56%] [G loss: 0.560225]\n",
      "epoch:3 step:3350 [D loss: 0.561547, acc.: 70.31%] [G loss: 0.527233]\n",
      "epoch:3 step:3351 [D loss: 0.527479, acc.: 73.44%] [G loss: 0.525566]\n",
      "epoch:3 step:3352 [D loss: 0.497879, acc.: 77.34%] [G loss: 0.551581]\n",
      "epoch:3 step:3353 [D loss: 0.635545, acc.: 64.06%] [G loss: 0.413073]\n",
      "epoch:3 step:3354 [D loss: 0.584611, acc.: 72.66%] [G loss: 0.467430]\n",
      "epoch:3 step:3355 [D loss: 0.552580, acc.: 71.09%] [G loss: 0.526742]\n",
      "epoch:3 step:3356 [D loss: 0.529687, acc.: 75.00%] [G loss: 0.482563]\n",
      "epoch:3 step:3357 [D loss: 0.476600, acc.: 76.56%] [G loss: 0.513662]\n",
      "epoch:3 step:3358 [D loss: 0.464824, acc.: 78.91%] [G loss: 0.477084]\n",
      "epoch:3 step:3359 [D loss: 0.490696, acc.: 76.56%] [G loss: 0.487404]\n",
      "epoch:3 step:3360 [D loss: 0.481667, acc.: 80.47%] [G loss: 0.654519]\n",
      "epoch:3 step:3361 [D loss: 0.550429, acc.: 75.00%] [G loss: 0.501877]\n",
      "epoch:3 step:3362 [D loss: 0.516112, acc.: 75.00%] [G loss: 0.618514]\n",
      "epoch:3 step:3363 [D loss: 0.449839, acc.: 84.38%] [G loss: 0.557398]\n",
      "epoch:3 step:3364 [D loss: 0.529087, acc.: 75.00%] [G loss: 0.467701]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:3 step:3365 [D loss: 0.434655, acc.: 79.69%] [G loss: 0.538632]\n",
      "epoch:3 step:3366 [D loss: 0.473359, acc.: 82.81%] [G loss: 0.533889]\n",
      "epoch:3 step:3367 [D loss: 0.466061, acc.: 82.81%] [G loss: 0.677814]\n",
      "epoch:3 step:3368 [D loss: 0.491611, acc.: 80.47%] [G loss: 0.558905]\n",
      "epoch:3 step:3369 [D loss: 0.462023, acc.: 79.69%] [G loss: 0.628803]\n",
      "epoch:3 step:3370 [D loss: 0.536740, acc.: 74.22%] [G loss: 0.500385]\n",
      "epoch:3 step:3371 [D loss: 0.522301, acc.: 74.22%] [G loss: 0.527629]\n",
      "epoch:3 step:3372 [D loss: 0.506502, acc.: 77.34%] [G loss: 0.504029]\n",
      "epoch:3 step:3373 [D loss: 0.589706, acc.: 65.62%] [G loss: 0.464000]\n",
      "epoch:3 step:3374 [D loss: 0.543661, acc.: 71.09%] [G loss: 0.547929]\n",
      "epoch:3 step:3375 [D loss: 0.534892, acc.: 74.22%] [G loss: 0.519693]\n",
      "epoch:3 step:3376 [D loss: 0.503916, acc.: 78.91%] [G loss: 0.669414]\n",
      "epoch:3 step:3377 [D loss: 0.548378, acc.: 74.22%] [G loss: 0.499916]\n",
      "epoch:3 step:3378 [D loss: 0.466241, acc.: 75.78%] [G loss: 0.678588]\n",
      "epoch:3 step:3379 [D loss: 0.495067, acc.: 73.44%] [G loss: 0.601885]\n",
      "epoch:3 step:3380 [D loss: 0.544837, acc.: 70.31%] [G loss: 0.556459]\n",
      "epoch:3 step:3381 [D loss: 0.496528, acc.: 78.91%] [G loss: 0.587645]\n",
      "epoch:3 step:3382 [D loss: 0.499772, acc.: 75.78%] [G loss: 0.506203]\n",
      "epoch:3 step:3383 [D loss: 0.569623, acc.: 64.84%] [G loss: 0.512221]\n",
      "epoch:3 step:3384 [D loss: 0.491319, acc.: 79.69%] [G loss: 0.567249]\n",
      "epoch:3 step:3385 [D loss: 0.460817, acc.: 78.91%] [G loss: 0.555512]\n",
      "epoch:3 step:3386 [D loss: 0.461241, acc.: 81.25%] [G loss: 0.512285]\n",
      "epoch:3 step:3387 [D loss: 0.497903, acc.: 76.56%] [G loss: 0.562456]\n",
      "epoch:3 step:3388 [D loss: 0.519605, acc.: 69.53%] [G loss: 0.607189]\n",
      "epoch:3 step:3389 [D loss: 0.482870, acc.: 77.34%] [G loss: 0.585380]\n",
      "epoch:3 step:3390 [D loss: 0.487507, acc.: 78.12%] [G loss: 0.700965]\n",
      "epoch:3 step:3391 [D loss: 0.557319, acc.: 71.88%] [G loss: 0.621138]\n",
      "epoch:3 step:3392 [D loss: 0.518280, acc.: 71.09%] [G loss: 0.631936]\n",
      "epoch:3 step:3393 [D loss: 0.500745, acc.: 75.00%] [G loss: 0.661119]\n",
      "epoch:3 step:3394 [D loss: 0.520864, acc.: 77.34%] [G loss: 0.529418]\n",
      "epoch:3 step:3395 [D loss: 0.541182, acc.: 75.78%] [G loss: 0.561457]\n",
      "epoch:3 step:3396 [D loss: 0.508340, acc.: 74.22%] [G loss: 0.492159]\n",
      "epoch:3 step:3397 [D loss: 0.589068, acc.: 70.31%] [G loss: 0.522823]\n",
      "epoch:3 step:3398 [D loss: 0.549536, acc.: 71.09%] [G loss: 0.613504]\n",
      "epoch:3 step:3399 [D loss: 0.550446, acc.: 73.44%] [G loss: 0.609405]\n",
      "epoch:3 step:3400 [D loss: 0.470286, acc.: 79.69%] [G loss: 0.611632]\n",
      "##############\n",
      "[3.88822532 1.56874507 7.44317179 5.492647   4.76110902 6.21297226\n",
      " 5.46928951 5.47007444 5.46505057 4.0172858 ]\n",
      "##########\n",
      "epoch:3 step:3401 [D loss: 0.572848, acc.: 70.31%] [G loss: 0.541143]\n",
      "epoch:3 step:3402 [D loss: 0.580688, acc.: 67.97%] [G loss: 0.522362]\n",
      "epoch:3 step:3403 [D loss: 0.514272, acc.: 75.78%] [G loss: 0.498690]\n",
      "epoch:3 step:3404 [D loss: 0.563246, acc.: 67.97%] [G loss: 0.574374]\n",
      "epoch:3 step:3405 [D loss: 0.507629, acc.: 71.88%] [G loss: 0.582878]\n",
      "epoch:3 step:3406 [D loss: 0.549478, acc.: 71.09%] [G loss: 0.471395]\n",
      "epoch:3 step:3407 [D loss: 0.536414, acc.: 71.88%] [G loss: 0.483335]\n",
      "epoch:3 step:3408 [D loss: 0.511657, acc.: 75.00%] [G loss: 0.510204]\n",
      "epoch:3 step:3409 [D loss: 0.521891, acc.: 78.12%] [G loss: 0.542816]\n",
      "epoch:3 step:3410 [D loss: 0.532281, acc.: 74.22%] [G loss: 0.457977]\n",
      "epoch:3 step:3411 [D loss: 0.558683, acc.: 72.66%] [G loss: 0.475292]\n",
      "epoch:3 step:3412 [D loss: 0.506711, acc.: 73.44%] [G loss: 0.588069]\n",
      "epoch:3 step:3413 [D loss: 0.480777, acc.: 78.12%] [G loss: 0.604738]\n",
      "epoch:3 step:3414 [D loss: 0.516812, acc.: 74.22%] [G loss: 0.540828]\n",
      "epoch:3 step:3415 [D loss: 0.556051, acc.: 69.53%] [G loss: 0.494671]\n",
      "epoch:3 step:3416 [D loss: 0.445048, acc.: 78.12%] [G loss: 0.565988]\n",
      "epoch:3 step:3417 [D loss: 0.516737, acc.: 75.00%] [G loss: 0.425054]\n",
      "epoch:3 step:3418 [D loss: 0.535519, acc.: 70.31%] [G loss: 0.354357]\n",
      "epoch:3 step:3419 [D loss: 0.536054, acc.: 75.00%] [G loss: 0.484533]\n",
      "epoch:3 step:3420 [D loss: 0.449371, acc.: 78.91%] [G loss: 0.600415]\n",
      "epoch:3 step:3421 [D loss: 0.563926, acc.: 67.19%] [G loss: 0.509952]\n",
      "epoch:3 step:3422 [D loss: 0.505646, acc.: 78.91%] [G loss: 0.506575]\n",
      "epoch:3 step:3423 [D loss: 0.487097, acc.: 75.78%] [G loss: 0.496615]\n",
      "epoch:3 step:3424 [D loss: 0.474952, acc.: 81.25%] [G loss: 0.545255]\n",
      "epoch:3 step:3425 [D loss: 0.561706, acc.: 64.06%] [G loss: 0.435878]\n",
      "epoch:3 step:3426 [D loss: 0.565734, acc.: 64.84%] [G loss: 0.627456]\n",
      "epoch:3 step:3427 [D loss: 0.565876, acc.: 68.75%] [G loss: 0.534680]\n",
      "epoch:3 step:3428 [D loss: 0.536062, acc.: 71.88%] [G loss: 0.511662]\n",
      "epoch:3 step:3429 [D loss: 0.538792, acc.: 71.88%] [G loss: 0.488959]\n",
      "epoch:3 step:3430 [D loss: 0.542549, acc.: 73.44%] [G loss: 0.509174]\n",
      "epoch:3 step:3431 [D loss: 0.487566, acc.: 77.34%] [G loss: 0.599765]\n",
      "epoch:3 step:3432 [D loss: 0.540907, acc.: 71.09%] [G loss: 0.636272]\n",
      "epoch:3 step:3433 [D loss: 0.637159, acc.: 65.62%] [G loss: 0.462122]\n",
      "epoch:3 step:3434 [D loss: 0.492657, acc.: 78.12%] [G loss: 0.535926]\n",
      "epoch:3 step:3435 [D loss: 0.528828, acc.: 68.75%] [G loss: 0.481414]\n",
      "epoch:3 step:3436 [D loss: 0.522518, acc.: 71.09%] [G loss: 0.486720]\n",
      "epoch:3 step:3437 [D loss: 0.505883, acc.: 71.88%] [G loss: 0.473716]\n",
      "epoch:3 step:3438 [D loss: 0.490257, acc.: 79.69%] [G loss: 0.538360]\n",
      "epoch:3 step:3439 [D loss: 0.506845, acc.: 74.22%] [G loss: 0.421505]\n",
      "epoch:3 step:3440 [D loss: 0.528127, acc.: 76.56%] [G loss: 0.516955]\n",
      "epoch:3 step:3441 [D loss: 0.499112, acc.: 77.34%] [G loss: 0.563560]\n",
      "epoch:3 step:3442 [D loss: 0.504999, acc.: 78.12%] [G loss: 0.549083]\n",
      "epoch:3 step:3443 [D loss: 0.486894, acc.: 78.91%] [G loss: 0.563069]\n",
      "epoch:3 step:3444 [D loss: 0.499515, acc.: 80.47%] [G loss: 0.549974]\n",
      "epoch:3 step:3445 [D loss: 0.503985, acc.: 75.00%] [G loss: 0.627234]\n",
      "epoch:3 step:3446 [D loss: 0.514359, acc.: 73.44%] [G loss: 0.578207]\n",
      "epoch:3 step:3447 [D loss: 0.574637, acc.: 71.09%] [G loss: 0.425890]\n",
      "epoch:3 step:3448 [D loss: 0.508639, acc.: 81.25%] [G loss: 0.462739]\n",
      "epoch:3 step:3449 [D loss: 0.535943, acc.: 71.88%] [G loss: 0.485413]\n",
      "epoch:3 step:3450 [D loss: 0.479120, acc.: 75.78%] [G loss: 0.548186]\n",
      "epoch:3 step:3451 [D loss: 0.512999, acc.: 78.12%] [G loss: 0.550603]\n",
      "epoch:3 step:3452 [D loss: 0.488646, acc.: 79.69%] [G loss: 0.561309]\n",
      "epoch:3 step:3453 [D loss: 0.508629, acc.: 73.44%] [G loss: 0.571059]\n",
      "epoch:3 step:3454 [D loss: 0.540478, acc.: 73.44%] [G loss: 0.550992]\n",
      "epoch:3 step:3455 [D loss: 0.525291, acc.: 74.22%] [G loss: 0.546693]\n",
      "epoch:3 step:3456 [D loss: 0.546814, acc.: 74.22%] [G loss: 0.456104]\n",
      "epoch:3 step:3457 [D loss: 0.551730, acc.: 71.09%] [G loss: 0.562499]\n",
      "epoch:3 step:3458 [D loss: 0.582593, acc.: 67.19%] [G loss: 0.486029]\n",
      "epoch:3 step:3459 [D loss: 0.511455, acc.: 78.91%] [G loss: 0.766856]\n",
      "epoch:3 step:3460 [D loss: 0.497727, acc.: 78.91%] [G loss: 0.694984]\n",
      "epoch:3 step:3461 [D loss: 0.536326, acc.: 78.91%] [G loss: 0.581781]\n",
      "epoch:3 step:3462 [D loss: 0.510799, acc.: 74.22%] [G loss: 0.539485]\n",
      "epoch:3 step:3463 [D loss: 0.594479, acc.: 66.41%] [G loss: 0.467244]\n",
      "epoch:3 step:3464 [D loss: 0.567547, acc.: 71.09%] [G loss: 0.419586]\n",
      "epoch:3 step:3465 [D loss: 0.502024, acc.: 77.34%] [G loss: 0.436087]\n",
      "epoch:3 step:3466 [D loss: 0.527317, acc.: 80.47%] [G loss: 0.374931]\n",
      "epoch:3 step:3467 [D loss: 0.519159, acc.: 75.00%] [G loss: 0.449826]\n",
      "epoch:3 step:3468 [D loss: 0.545496, acc.: 69.53%] [G loss: 0.464411]\n",
      "epoch:3 step:3469 [D loss: 0.585513, acc.: 69.53%] [G loss: 0.404407]\n",
      "epoch:3 step:3470 [D loss: 0.552613, acc.: 70.31%] [G loss: 0.471689]\n",
      "epoch:3 step:3471 [D loss: 0.495397, acc.: 75.00%] [G loss: 0.543827]\n",
      "epoch:3 step:3472 [D loss: 0.491930, acc.: 80.47%] [G loss: 0.550471]\n",
      "epoch:3 step:3473 [D loss: 0.540099, acc.: 71.09%] [G loss: 0.548300]\n",
      "epoch:3 step:3474 [D loss: 0.437205, acc.: 85.16%] [G loss: 0.619036]\n",
      "epoch:3 step:3475 [D loss: 0.533152, acc.: 71.09%] [G loss: 0.673359]\n",
      "epoch:3 step:3476 [D loss: 0.504435, acc.: 75.00%] [G loss: 0.593904]\n",
      "epoch:3 step:3477 [D loss: 0.524017, acc.: 75.78%] [G loss: 0.599775]\n",
      "epoch:3 step:3478 [D loss: 0.518054, acc.: 78.12%] [G loss: 0.595228]\n",
      "epoch:3 step:3479 [D loss: 0.552310, acc.: 69.53%] [G loss: 0.546111]\n",
      "epoch:3 step:3480 [D loss: 0.511513, acc.: 73.44%] [G loss: 0.498631]\n",
      "epoch:3 step:3481 [D loss: 0.448054, acc.: 82.81%] [G loss: 0.545987]\n",
      "epoch:3 step:3482 [D loss: 0.509786, acc.: 75.00%] [G loss: 0.543212]\n",
      "epoch:3 step:3483 [D loss: 0.594001, acc.: 64.06%] [G loss: 0.473279]\n",
      "epoch:3 step:3484 [D loss: 0.523332, acc.: 77.34%] [G loss: 0.460848]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:3 step:3485 [D loss: 0.521586, acc.: 80.47%] [G loss: 0.523338]\n",
      "epoch:3 step:3486 [D loss: 0.538928, acc.: 71.09%] [G loss: 0.579988]\n",
      "epoch:3 step:3487 [D loss: 0.464484, acc.: 78.12%] [G loss: 0.543600]\n",
      "epoch:3 step:3488 [D loss: 0.506943, acc.: 74.22%] [G loss: 0.469649]\n",
      "epoch:3 step:3489 [D loss: 0.457148, acc.: 81.25%] [G loss: 0.577808]\n",
      "epoch:3 step:3490 [D loss: 0.544143, acc.: 73.44%] [G loss: 0.517424]\n",
      "epoch:3 step:3491 [D loss: 0.433115, acc.: 85.16%] [G loss: 0.627724]\n",
      "epoch:3 step:3492 [D loss: 0.533329, acc.: 75.00%] [G loss: 0.520307]\n",
      "epoch:3 step:3493 [D loss: 0.475373, acc.: 80.47%] [G loss: 0.630028]\n",
      "epoch:3 step:3494 [D loss: 0.572008, acc.: 66.41%] [G loss: 0.420988]\n",
      "epoch:3 step:3495 [D loss: 0.545826, acc.: 71.09%] [G loss: 0.453297]\n",
      "epoch:3 step:3496 [D loss: 0.557124, acc.: 66.41%] [G loss: 0.527507]\n",
      "epoch:3 step:3497 [D loss: 0.507534, acc.: 78.91%] [G loss: 0.552375]\n",
      "epoch:3 step:3498 [D loss: 0.505363, acc.: 78.12%] [G loss: 0.566741]\n",
      "epoch:3 step:3499 [D loss: 0.558314, acc.: 72.66%] [G loss: 0.577988]\n",
      "epoch:3 step:3500 [D loss: 0.565711, acc.: 69.53%] [G loss: 0.527453]\n",
      "epoch:3 step:3501 [D loss: 0.513842, acc.: 72.66%] [G loss: 0.616328]\n",
      "epoch:3 step:3502 [D loss: 0.490719, acc.: 77.34%] [G loss: 0.638219]\n",
      "epoch:3 step:3503 [D loss: 0.527848, acc.: 73.44%] [G loss: 0.528575]\n",
      "epoch:3 step:3504 [D loss: 0.472860, acc.: 79.69%] [G loss: 0.580399]\n",
      "epoch:3 step:3505 [D loss: 0.510639, acc.: 75.78%] [G loss: 0.607158]\n",
      "epoch:3 step:3506 [D loss: 0.510482, acc.: 75.78%] [G loss: 0.531470]\n",
      "epoch:3 step:3507 [D loss: 0.584029, acc.: 66.41%] [G loss: 0.524633]\n",
      "epoch:3 step:3508 [D loss: 0.465157, acc.: 81.25%] [G loss: 0.661829]\n",
      "epoch:3 step:3509 [D loss: 0.545624, acc.: 71.88%] [G loss: 0.477404]\n",
      "epoch:3 step:3510 [D loss: 0.507068, acc.: 76.56%] [G loss: 0.626602]\n",
      "epoch:3 step:3511 [D loss: 0.526165, acc.: 78.91%] [G loss: 0.454801]\n",
      "epoch:3 step:3512 [D loss: 0.474878, acc.: 75.78%] [G loss: 0.593906]\n",
      "epoch:3 step:3513 [D loss: 0.549872, acc.: 67.97%] [G loss: 0.599626]\n",
      "epoch:3 step:3514 [D loss: 0.558491, acc.: 70.31%] [G loss: 0.529122]\n",
      "epoch:3 step:3515 [D loss: 0.590448, acc.: 68.75%] [G loss: 0.514535]\n",
      "epoch:3 step:3516 [D loss: 0.498437, acc.: 78.91%] [G loss: 0.474584]\n",
      "epoch:3 step:3517 [D loss: 0.480428, acc.: 78.12%] [G loss: 0.592005]\n",
      "epoch:3 step:3518 [D loss: 0.415799, acc.: 88.28%] [G loss: 0.660740]\n",
      "epoch:3 step:3519 [D loss: 0.474408, acc.: 80.47%] [G loss: 0.704224]\n",
      "epoch:3 step:3520 [D loss: 0.477270, acc.: 80.47%] [G loss: 0.857055]\n",
      "epoch:3 step:3521 [D loss: 0.623524, acc.: 66.41%] [G loss: 0.475609]\n",
      "epoch:3 step:3522 [D loss: 0.541989, acc.: 72.66%] [G loss: 0.538270]\n",
      "epoch:3 step:3523 [D loss: 0.505023, acc.: 75.00%] [G loss: 0.443843]\n",
      "epoch:3 step:3524 [D loss: 0.549367, acc.: 74.22%] [G loss: 0.453635]\n",
      "epoch:3 step:3525 [D loss: 0.475278, acc.: 78.91%] [G loss: 0.516499]\n",
      "epoch:3 step:3526 [D loss: 0.597451, acc.: 64.84%] [G loss: 0.477194]\n",
      "epoch:3 step:3527 [D loss: 0.643300, acc.: 65.62%] [G loss: 0.451984]\n",
      "epoch:3 step:3528 [D loss: 0.580956, acc.: 66.41%] [G loss: 0.420673]\n",
      "epoch:3 step:3529 [D loss: 0.562975, acc.: 70.31%] [G loss: 0.455371]\n",
      "epoch:3 step:3530 [D loss: 0.512054, acc.: 73.44%] [G loss: 0.494563]\n",
      "epoch:3 step:3531 [D loss: 0.594128, acc.: 69.53%] [G loss: 0.518805]\n",
      "epoch:3 step:3532 [D loss: 0.545476, acc.: 71.88%] [G loss: 0.461958]\n",
      "epoch:3 step:3533 [D loss: 0.502505, acc.: 75.78%] [G loss: 0.410325]\n",
      "epoch:3 step:3534 [D loss: 0.595236, acc.: 73.44%] [G loss: 0.458510]\n",
      "epoch:3 step:3535 [D loss: 0.547306, acc.: 71.88%] [G loss: 0.430886]\n",
      "epoch:3 step:3536 [D loss: 0.535216, acc.: 75.78%] [G loss: 0.590241]\n",
      "epoch:3 step:3537 [D loss: 0.527236, acc.: 71.88%] [G loss: 0.541571]\n",
      "epoch:3 step:3538 [D loss: 0.606395, acc.: 65.62%] [G loss: 0.437719]\n",
      "epoch:3 step:3539 [D loss: 0.506417, acc.: 77.34%] [G loss: 0.435936]\n",
      "epoch:3 step:3540 [D loss: 0.573222, acc.: 72.66%] [G loss: 0.441420]\n",
      "epoch:3 step:3541 [D loss: 0.496602, acc.: 81.25%] [G loss: 0.424596]\n",
      "epoch:3 step:3542 [D loss: 0.500202, acc.: 80.47%] [G loss: 0.693346]\n",
      "epoch:3 step:3543 [D loss: 0.498387, acc.: 73.44%] [G loss: 0.582892]\n",
      "epoch:3 step:3544 [D loss: 0.461210, acc.: 80.47%] [G loss: 0.689493]\n",
      "epoch:3 step:3545 [D loss: 0.573230, acc.: 71.09%] [G loss: 0.500752]\n",
      "epoch:3 step:3546 [D loss: 0.576089, acc.: 71.09%] [G loss: 0.525492]\n",
      "epoch:3 step:3547 [D loss: 0.452009, acc.: 78.91%] [G loss: 0.588857]\n",
      "epoch:3 step:3548 [D loss: 0.512756, acc.: 71.09%] [G loss: 0.594611]\n",
      "epoch:3 step:3549 [D loss: 0.576729, acc.: 66.41%] [G loss: 0.433658]\n",
      "epoch:3 step:3550 [D loss: 0.554029, acc.: 71.88%] [G loss: 0.464962]\n",
      "epoch:3 step:3551 [D loss: 0.611942, acc.: 61.72%] [G loss: 0.357005]\n",
      "epoch:3 step:3552 [D loss: 0.577846, acc.: 68.75%] [G loss: 0.469120]\n",
      "epoch:3 step:3553 [D loss: 0.530223, acc.: 76.56%] [G loss: 0.472277]\n",
      "epoch:3 step:3554 [D loss: 0.529801, acc.: 74.22%] [G loss: 0.499011]\n",
      "epoch:3 step:3555 [D loss: 0.494435, acc.: 82.03%] [G loss: 0.519576]\n",
      "epoch:3 step:3556 [D loss: 0.521967, acc.: 73.44%] [G loss: 0.504120]\n",
      "epoch:3 step:3557 [D loss: 0.476237, acc.: 78.12%] [G loss: 0.607196]\n",
      "epoch:3 step:3558 [D loss: 0.489211, acc.: 76.56%] [G loss: 0.741485]\n",
      "epoch:3 step:3559 [D loss: 0.484561, acc.: 80.47%] [G loss: 0.678925]\n",
      "epoch:3 step:3560 [D loss: 0.541189, acc.: 67.19%] [G loss: 0.534056]\n",
      "epoch:3 step:3561 [D loss: 0.531080, acc.: 76.56%] [G loss: 0.478713]\n",
      "epoch:3 step:3562 [D loss: 0.478169, acc.: 79.69%] [G loss: 0.628005]\n",
      "epoch:3 step:3563 [D loss: 0.499641, acc.: 77.34%] [G loss: 0.620630]\n",
      "epoch:3 step:3564 [D loss: 0.490318, acc.: 77.34%] [G loss: 0.599025]\n",
      "epoch:3 step:3565 [D loss: 0.479765, acc.: 78.91%] [G loss: 0.707249]\n",
      "epoch:3 step:3566 [D loss: 0.514171, acc.: 72.66%] [G loss: 0.671226]\n",
      "epoch:3 step:3567 [D loss: 0.548455, acc.: 69.53%] [G loss: 0.600146]\n",
      "epoch:3 step:3568 [D loss: 0.518410, acc.: 71.88%] [G loss: 0.720197]\n",
      "epoch:3 step:3569 [D loss: 0.518592, acc.: 75.00%] [G loss: 0.508381]\n",
      "epoch:3 step:3570 [D loss: 0.532262, acc.: 75.00%] [G loss: 0.565490]\n",
      "epoch:3 step:3571 [D loss: 0.523140, acc.: 75.00%] [G loss: 0.499402]\n",
      "epoch:3 step:3572 [D loss: 0.482010, acc.: 77.34%] [G loss: 0.575009]\n",
      "epoch:3 step:3573 [D loss: 0.579036, acc.: 64.84%] [G loss: 0.399526]\n",
      "epoch:3 step:3574 [D loss: 0.519713, acc.: 75.78%] [G loss: 0.500412]\n",
      "epoch:3 step:3575 [D loss: 0.537635, acc.: 71.88%] [G loss: 0.635766]\n",
      "epoch:3 step:3576 [D loss: 0.627491, acc.: 67.97%] [G loss: 0.474732]\n",
      "epoch:3 step:3577 [D loss: 0.691373, acc.: 59.38%] [G loss: 0.366017]\n",
      "epoch:3 step:3578 [D loss: 0.547691, acc.: 74.22%] [G loss: 0.473992]\n",
      "epoch:3 step:3579 [D loss: 0.569012, acc.: 67.19%] [G loss: 0.506617]\n",
      "epoch:3 step:3580 [D loss: 0.485534, acc.: 80.47%] [G loss: 0.655680]\n",
      "epoch:3 step:3581 [D loss: 0.548709, acc.: 68.75%] [G loss: 0.558170]\n",
      "epoch:3 step:3582 [D loss: 0.515960, acc.: 73.44%] [G loss: 0.567995]\n",
      "epoch:3 step:3583 [D loss: 0.566709, acc.: 70.31%] [G loss: 0.457663]\n",
      "epoch:3 step:3584 [D loss: 0.525084, acc.: 71.88%] [G loss: 0.485394]\n",
      "epoch:3 step:3585 [D loss: 0.550795, acc.: 71.88%] [G loss: 0.519069]\n",
      "epoch:3 step:3586 [D loss: 0.540890, acc.: 76.56%] [G loss: 0.573785]\n",
      "epoch:3 step:3587 [D loss: 0.562508, acc.: 69.53%] [G loss: 0.483922]\n",
      "epoch:3 step:3588 [D loss: 0.510453, acc.: 78.12%] [G loss: 0.428605]\n",
      "epoch:3 step:3589 [D loss: 0.586013, acc.: 71.88%] [G loss: 0.451461]\n",
      "epoch:3 step:3590 [D loss: 0.489505, acc.: 80.47%] [G loss: 0.571274]\n",
      "epoch:3 step:3591 [D loss: 0.505136, acc.: 77.34%] [G loss: 0.493681]\n",
      "epoch:3 step:3592 [D loss: 0.469021, acc.: 78.12%] [G loss: 0.698645]\n",
      "epoch:3 step:3593 [D loss: 0.522144, acc.: 75.78%] [G loss: 0.739658]\n",
      "epoch:3 step:3594 [D loss: 0.504793, acc.: 74.22%] [G loss: 0.592205]\n",
      "epoch:3 step:3595 [D loss: 0.586620, acc.: 69.53%] [G loss: 0.456391]\n",
      "epoch:3 step:3596 [D loss: 0.526477, acc.: 71.09%] [G loss: 0.547028]\n",
      "epoch:3 step:3597 [D loss: 0.511312, acc.: 74.22%] [G loss: 0.692226]\n",
      "epoch:3 step:3598 [D loss: 0.540195, acc.: 75.00%] [G loss: 0.501593]\n",
      "epoch:3 step:3599 [D loss: 0.612315, acc.: 67.19%] [G loss: 0.492510]\n",
      "epoch:3 step:3600 [D loss: 0.538431, acc.: 78.91%] [G loss: 0.390466]\n",
      "##############\n",
      "[3.71725262 2.00151828 7.23664709 5.27436949 4.61182367 6.32013343\n",
      " 5.83977978 5.27999357 5.32607883 4.12594877]\n",
      "##########\n",
      "epoch:3 step:3601 [D loss: 0.505387, acc.: 76.56%] [G loss: 0.508034]\n",
      "epoch:3 step:3602 [D loss: 0.529016, acc.: 71.88%] [G loss: 0.567892]\n",
      "epoch:3 step:3603 [D loss: 0.425587, acc.: 84.38%] [G loss: 0.681367]\n",
      "epoch:3 step:3604 [D loss: 0.560991, acc.: 67.97%] [G loss: 0.594022]\n",
      "epoch:3 step:3605 [D loss: 0.566434, acc.: 68.75%] [G loss: 0.514612]\n",
      "epoch:3 step:3606 [D loss: 0.469687, acc.: 78.12%] [G loss: 0.567549]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:3 step:3607 [D loss: 0.538239, acc.: 71.88%] [G loss: 0.564317]\n",
      "epoch:3 step:3608 [D loss: 0.486592, acc.: 80.47%] [G loss: 0.587986]\n",
      "epoch:3 step:3609 [D loss: 0.496732, acc.: 75.78%] [G loss: 0.586328]\n",
      "epoch:3 step:3610 [D loss: 0.564042, acc.: 73.44%] [G loss: 0.510772]\n",
      "epoch:3 step:3611 [D loss: 0.591103, acc.: 70.31%] [G loss: 0.526498]\n",
      "epoch:3 step:3612 [D loss: 0.513630, acc.: 75.00%] [G loss: 0.492723]\n",
      "epoch:3 step:3613 [D loss: 0.537447, acc.: 71.09%] [G loss: 0.579123]\n",
      "epoch:3 step:3614 [D loss: 0.482901, acc.: 76.56%] [G loss: 0.618795]\n",
      "epoch:3 step:3615 [D loss: 0.509100, acc.: 71.88%] [G loss: 0.516576]\n",
      "epoch:3 step:3616 [D loss: 0.467143, acc.: 80.47%] [G loss: 0.662646]\n",
      "epoch:3 step:3617 [D loss: 0.472169, acc.: 76.56%] [G loss: 0.583795]\n",
      "epoch:3 step:3618 [D loss: 0.473321, acc.: 77.34%] [G loss: 0.603151]\n",
      "epoch:3 step:3619 [D loss: 0.589311, acc.: 67.19%] [G loss: 0.406357]\n",
      "epoch:3 step:3620 [D loss: 0.544577, acc.: 79.69%] [G loss: 0.471549]\n",
      "epoch:3 step:3621 [D loss: 0.525184, acc.: 71.88%] [G loss: 0.441213]\n",
      "epoch:3 step:3622 [D loss: 0.543644, acc.: 72.66%] [G loss: 0.482541]\n",
      "epoch:3 step:3623 [D loss: 0.601439, acc.: 71.09%] [G loss: 0.422468]\n",
      "epoch:3 step:3624 [D loss: 0.527702, acc.: 76.56%] [G loss: 0.493395]\n",
      "epoch:3 step:3625 [D loss: 0.552874, acc.: 75.00%] [G loss: 0.618952]\n",
      "epoch:3 step:3626 [D loss: 0.561234, acc.: 72.66%] [G loss: 0.604552]\n",
      "epoch:3 step:3627 [D loss: 0.551962, acc.: 75.00%] [G loss: 0.766905]\n",
      "epoch:3 step:3628 [D loss: 0.577919, acc.: 72.66%] [G loss: 0.557781]\n",
      "epoch:3 step:3629 [D loss: 0.582104, acc.: 69.53%] [G loss: 0.480725]\n",
      "epoch:3 step:3630 [D loss: 0.484797, acc.: 77.34%] [G loss: 0.484827]\n",
      "epoch:3 step:3631 [D loss: 0.545816, acc.: 71.88%] [G loss: 0.486230]\n",
      "epoch:3 step:3632 [D loss: 0.481023, acc.: 78.12%] [G loss: 0.474902]\n",
      "epoch:3 step:3633 [D loss: 0.477875, acc.: 80.47%] [G loss: 0.592413]\n",
      "epoch:3 step:3634 [D loss: 0.462046, acc.: 82.03%] [G loss: 0.558252]\n",
      "epoch:3 step:3635 [D loss: 0.603323, acc.: 64.84%] [G loss: 0.402256]\n",
      "epoch:3 step:3636 [D loss: 0.580429, acc.: 70.31%] [G loss: 0.457173]\n",
      "epoch:3 step:3637 [D loss: 0.563126, acc.: 69.53%] [G loss: 0.447245]\n",
      "epoch:3 step:3638 [D loss: 0.584437, acc.: 62.50%] [G loss: 0.436954]\n",
      "epoch:3 step:3639 [D loss: 0.591885, acc.: 66.41%] [G loss: 0.483727]\n",
      "epoch:3 step:3640 [D loss: 0.515244, acc.: 78.12%] [G loss: 0.469425]\n",
      "epoch:3 step:3641 [D loss: 0.527436, acc.: 75.78%] [G loss: 0.528698]\n",
      "epoch:3 step:3642 [D loss: 0.564554, acc.: 71.09%] [G loss: 0.369657]\n",
      "epoch:3 step:3643 [D loss: 0.557118, acc.: 67.97%] [G loss: 0.481860]\n",
      "epoch:3 step:3644 [D loss: 0.482959, acc.: 78.91%] [G loss: 0.538358]\n",
      "epoch:3 step:3645 [D loss: 0.488421, acc.: 80.47%] [G loss: 0.577472]\n",
      "epoch:3 step:3646 [D loss: 0.534468, acc.: 72.66%] [G loss: 0.507137]\n",
      "epoch:3 step:3647 [D loss: 0.528937, acc.: 73.44%] [G loss: 0.603223]\n",
      "epoch:3 step:3648 [D loss: 0.511966, acc.: 76.56%] [G loss: 0.622420]\n",
      "epoch:3 step:3649 [D loss: 0.548755, acc.: 70.31%] [G loss: 0.576568]\n",
      "epoch:3 step:3650 [D loss: 0.539748, acc.: 74.22%] [G loss: 0.448837]\n",
      "epoch:3 step:3651 [D loss: 0.566057, acc.: 71.09%] [G loss: 0.438749]\n",
      "epoch:3 step:3652 [D loss: 0.527349, acc.: 71.88%] [G loss: 0.475383]\n",
      "epoch:3 step:3653 [D loss: 0.481782, acc.: 75.78%] [G loss: 0.539397]\n",
      "epoch:3 step:3654 [D loss: 0.506742, acc.: 76.56%] [G loss: 0.520686]\n",
      "epoch:3 step:3655 [D loss: 0.582194, acc.: 70.31%] [G loss: 0.522046]\n",
      "epoch:3 step:3656 [D loss: 0.562113, acc.: 69.53%] [G loss: 0.472396]\n",
      "epoch:3 step:3657 [D loss: 0.559545, acc.: 67.97%] [G loss: 0.371204]\n",
      "epoch:3 step:3658 [D loss: 0.524616, acc.: 75.78%] [G loss: 0.426988]\n",
      "epoch:3 step:3659 [D loss: 0.486057, acc.: 72.66%] [G loss: 0.462413]\n",
      "epoch:3 step:3660 [D loss: 0.533658, acc.: 74.22%] [G loss: 0.482524]\n",
      "epoch:3 step:3661 [D loss: 0.520128, acc.: 73.44%] [G loss: 0.486440]\n",
      "epoch:3 step:3662 [D loss: 0.538432, acc.: 73.44%] [G loss: 0.417924]\n",
      "epoch:3 step:3663 [D loss: 0.470474, acc.: 78.91%] [G loss: 0.610655]\n",
      "epoch:3 step:3664 [D loss: 0.481663, acc.: 78.12%] [G loss: 0.690666]\n",
      "epoch:3 step:3665 [D loss: 0.444393, acc.: 81.25%] [G loss: 0.606560]\n",
      "epoch:3 step:3666 [D loss: 0.524908, acc.: 75.78%] [G loss: 0.779369]\n",
      "epoch:3 step:3667 [D loss: 0.532710, acc.: 75.78%] [G loss: 0.574737]\n",
      "epoch:3 step:3668 [D loss: 0.513224, acc.: 77.34%] [G loss: 0.572366]\n",
      "epoch:3 step:3669 [D loss: 0.669272, acc.: 59.38%] [G loss: 0.444900]\n",
      "epoch:3 step:3670 [D loss: 0.553343, acc.: 71.88%] [G loss: 0.490309]\n",
      "epoch:3 step:3671 [D loss: 0.457537, acc.: 78.91%] [G loss: 0.534232]\n",
      "epoch:3 step:3672 [D loss: 0.607579, acc.: 64.84%] [G loss: 0.518654]\n",
      "epoch:3 step:3673 [D loss: 0.580070, acc.: 73.44%] [G loss: 0.444273]\n",
      "epoch:3 step:3674 [D loss: 0.515642, acc.: 78.91%] [G loss: 0.529705]\n",
      "epoch:3 step:3675 [D loss: 0.503390, acc.: 76.56%] [G loss: 0.481936]\n",
      "epoch:3 step:3676 [D loss: 0.496433, acc.: 77.34%] [G loss: 0.492726]\n",
      "epoch:3 step:3677 [D loss: 0.501374, acc.: 73.44%] [G loss: 0.474254]\n",
      "epoch:3 step:3678 [D loss: 0.583274, acc.: 71.09%] [G loss: 0.423587]\n",
      "epoch:3 step:3679 [D loss: 0.523932, acc.: 74.22%] [G loss: 0.491360]\n",
      "epoch:3 step:3680 [D loss: 0.538236, acc.: 71.09%] [G loss: 0.429701]\n",
      "epoch:3 step:3681 [D loss: 0.490093, acc.: 77.34%] [G loss: 0.435686]\n",
      "epoch:3 step:3682 [D loss: 0.485590, acc.: 75.78%] [G loss: 0.558310]\n",
      "epoch:3 step:3683 [D loss: 0.496083, acc.: 78.91%] [G loss: 0.553541]\n",
      "epoch:3 step:3684 [D loss: 0.551749, acc.: 71.88%] [G loss: 0.471145]\n",
      "epoch:3 step:3685 [D loss: 0.526256, acc.: 77.34%] [G loss: 0.501429]\n",
      "epoch:3 step:3686 [D loss: 0.475679, acc.: 76.56%] [G loss: 0.550190]\n",
      "epoch:3 step:3687 [D loss: 0.550766, acc.: 74.22%] [G loss: 0.605458]\n",
      "epoch:3 step:3688 [D loss: 0.520893, acc.: 75.00%] [G loss: 0.530131]\n",
      "epoch:3 step:3689 [D loss: 0.496946, acc.: 73.44%] [G loss: 0.705619]\n",
      "epoch:3 step:3690 [D loss: 0.564040, acc.: 69.53%] [G loss: 0.462460]\n",
      "epoch:3 step:3691 [D loss: 0.607427, acc.: 66.41%] [G loss: 0.445953]\n",
      "epoch:3 step:3692 [D loss: 0.524525, acc.: 71.88%] [G loss: 0.425418]\n",
      "epoch:3 step:3693 [D loss: 0.565568, acc.: 67.97%] [G loss: 0.433633]\n",
      "epoch:3 step:3694 [D loss: 0.554565, acc.: 69.53%] [G loss: 0.485849]\n",
      "epoch:3 step:3695 [D loss: 0.521788, acc.: 72.66%] [G loss: 0.513344]\n",
      "epoch:3 step:3696 [D loss: 0.477977, acc.: 74.22%] [G loss: 0.696123]\n",
      "epoch:3 step:3697 [D loss: 0.464554, acc.: 80.47%] [G loss: 0.675305]\n",
      "epoch:3 step:3698 [D loss: 0.494818, acc.: 76.56%] [G loss: 0.698782]\n",
      "epoch:3 step:3699 [D loss: 0.487500, acc.: 76.56%] [G loss: 0.569227]\n",
      "epoch:3 step:3700 [D loss: 0.509681, acc.: 74.22%] [G loss: 0.630307]\n",
      "epoch:3 step:3701 [D loss: 0.424677, acc.: 82.03%] [G loss: 0.595213]\n",
      "epoch:3 step:3702 [D loss: 0.579791, acc.: 64.06%] [G loss: 0.444926]\n",
      "epoch:3 step:3703 [D loss: 0.593424, acc.: 69.53%] [G loss: 0.502098]\n",
      "epoch:3 step:3704 [D loss: 0.576123, acc.: 66.41%] [G loss: 0.482965]\n",
      "epoch:3 step:3705 [D loss: 0.488969, acc.: 71.88%] [G loss: 0.756687]\n",
      "epoch:3 step:3706 [D loss: 0.503707, acc.: 75.00%] [G loss: 0.608127]\n",
      "epoch:3 step:3707 [D loss: 0.576339, acc.: 70.31%] [G loss: 0.637175]\n",
      "epoch:3 step:3708 [D loss: 0.478063, acc.: 78.91%] [G loss: 0.516144]\n",
      "epoch:3 step:3709 [D loss: 0.477167, acc.: 79.69%] [G loss: 0.592420]\n",
      "epoch:3 step:3710 [D loss: 0.536893, acc.: 73.44%] [G loss: 0.603880]\n",
      "epoch:3 step:3711 [D loss: 0.487240, acc.: 79.69%] [G loss: 0.606944]\n",
      "epoch:3 step:3712 [D loss: 0.518011, acc.: 69.53%] [G loss: 0.507730]\n",
      "epoch:3 step:3713 [D loss: 0.531910, acc.: 77.34%] [G loss: 0.467223]\n",
      "epoch:3 step:3714 [D loss: 0.533808, acc.: 73.44%] [G loss: 0.448239]\n",
      "epoch:3 step:3715 [D loss: 0.482737, acc.: 79.69%] [G loss: 0.556139]\n",
      "epoch:3 step:3716 [D loss: 0.525866, acc.: 77.34%] [G loss: 0.461924]\n",
      "epoch:3 step:3717 [D loss: 0.486831, acc.: 74.22%] [G loss: 0.591802]\n",
      "epoch:3 step:3718 [D loss: 0.545743, acc.: 71.88%] [G loss: 0.526551]\n",
      "epoch:3 step:3719 [D loss: 0.537010, acc.: 67.19%] [G loss: 0.583792]\n",
      "epoch:3 step:3720 [D loss: 0.492897, acc.: 73.44%] [G loss: 0.596840]\n",
      "epoch:3 step:3721 [D loss: 0.435650, acc.: 82.03%] [G loss: 0.671807]\n",
      "epoch:3 step:3722 [D loss: 0.456262, acc.: 83.59%] [G loss: 0.618229]\n",
      "epoch:3 step:3723 [D loss: 0.467287, acc.: 78.91%] [G loss: 0.722351]\n",
      "epoch:3 step:3724 [D loss: 0.599150, acc.: 65.62%] [G loss: 0.570905]\n",
      "epoch:3 step:3725 [D loss: 0.510338, acc.: 77.34%] [G loss: 0.557039]\n",
      "epoch:3 step:3726 [D loss: 0.605163, acc.: 68.75%] [G loss: 0.525839]\n",
      "epoch:3 step:3727 [D loss: 0.525758, acc.: 77.34%] [G loss: 0.416340]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:3 step:3728 [D loss: 0.504246, acc.: 79.69%] [G loss: 0.558027]\n",
      "epoch:3 step:3729 [D loss: 0.477105, acc.: 78.91%] [G loss: 0.620487]\n",
      "epoch:3 step:3730 [D loss: 0.556620, acc.: 69.53%] [G loss: 0.725842]\n",
      "epoch:3 step:3731 [D loss: 0.679891, acc.: 63.28%] [G loss: 0.577929]\n",
      "epoch:3 step:3732 [D loss: 0.448613, acc.: 81.25%] [G loss: 0.727069]\n",
      "epoch:3 step:3733 [D loss: 0.491663, acc.: 80.47%] [G loss: 0.492805]\n",
      "epoch:3 step:3734 [D loss: 0.466784, acc.: 79.69%] [G loss: 0.626947]\n",
      "epoch:3 step:3735 [D loss: 0.432884, acc.: 83.59%] [G loss: 0.627561]\n",
      "epoch:3 step:3736 [D loss: 0.494043, acc.: 75.78%] [G loss: 0.775027]\n",
      "epoch:3 step:3737 [D loss: 0.478309, acc.: 82.03%] [G loss: 0.907816]\n",
      "epoch:3 step:3738 [D loss: 0.447368, acc.: 78.91%] [G loss: 1.074438]\n",
      "epoch:3 step:3739 [D loss: 0.773140, acc.: 60.16%] [G loss: 0.830333]\n",
      "epoch:3 step:3740 [D loss: 0.477843, acc.: 76.56%] [G loss: 0.945169]\n",
      "epoch:3 step:3741 [D loss: 0.442774, acc.: 76.56%] [G loss: 0.889331]\n",
      "epoch:3 step:3742 [D loss: 0.533657, acc.: 69.53%] [G loss: 0.581816]\n",
      "epoch:3 step:3743 [D loss: 0.589999, acc.: 64.06%] [G loss: 0.532070]\n",
      "epoch:3 step:3744 [D loss: 0.452801, acc.: 82.81%] [G loss: 0.571186]\n",
      "epoch:3 step:3745 [D loss: 0.498110, acc.: 75.78%] [G loss: 0.668341]\n",
      "epoch:3 step:3746 [D loss: 0.538234, acc.: 73.44%] [G loss: 0.675845]\n",
      "epoch:3 step:3747 [D loss: 0.344621, acc.: 88.28%] [G loss: 0.843801]\n",
      "epoch:3 step:3748 [D loss: 0.475062, acc.: 78.91%] [G loss: 0.964617]\n",
      "epoch:4 step:3749 [D loss: 0.541345, acc.: 74.22%] [G loss: 0.705599]\n",
      "epoch:4 step:3750 [D loss: 0.467834, acc.: 79.69%] [G loss: 0.803675]\n",
      "epoch:4 step:3751 [D loss: 0.543608, acc.: 70.31%] [G loss: 0.627265]\n",
      "epoch:4 step:3752 [D loss: 0.511435, acc.: 72.66%] [G loss: 0.641385]\n",
      "epoch:4 step:3753 [D loss: 0.524683, acc.: 73.44%] [G loss: 0.687108]\n",
      "epoch:4 step:3754 [D loss: 0.514336, acc.: 71.88%] [G loss: 0.510681]\n",
      "epoch:4 step:3755 [D loss: 0.441039, acc.: 80.47%] [G loss: 0.693641]\n",
      "epoch:4 step:3756 [D loss: 0.522420, acc.: 75.78%] [G loss: 0.573460]\n",
      "epoch:4 step:3757 [D loss: 0.493192, acc.: 74.22%] [G loss: 0.652406]\n",
      "epoch:4 step:3758 [D loss: 0.558024, acc.: 70.31%] [G loss: 0.549533]\n",
      "epoch:4 step:3759 [D loss: 0.462131, acc.: 79.69%] [G loss: 0.657628]\n",
      "epoch:4 step:3760 [D loss: 0.567701, acc.: 68.75%] [G loss: 0.454913]\n",
      "epoch:4 step:3761 [D loss: 0.494294, acc.: 79.69%] [G loss: 0.582227]\n",
      "epoch:4 step:3762 [D loss: 0.522204, acc.: 75.78%] [G loss: 0.448398]\n",
      "epoch:4 step:3763 [D loss: 0.501785, acc.: 79.69%] [G loss: 0.406622]\n",
      "epoch:4 step:3764 [D loss: 0.474920, acc.: 75.78%] [G loss: 0.517482]\n",
      "epoch:4 step:3765 [D loss: 0.541672, acc.: 77.34%] [G loss: 0.495355]\n",
      "epoch:4 step:3766 [D loss: 0.570611, acc.: 72.66%] [G loss: 0.465164]\n",
      "epoch:4 step:3767 [D loss: 0.528383, acc.: 75.78%] [G loss: 0.429198]\n",
      "epoch:4 step:3768 [D loss: 0.574959, acc.: 70.31%] [G loss: 0.443039]\n",
      "epoch:4 step:3769 [D loss: 0.533802, acc.: 75.78%] [G loss: 0.425506]\n",
      "epoch:4 step:3770 [D loss: 0.428875, acc.: 82.81%] [G loss: 0.642005]\n",
      "epoch:4 step:3771 [D loss: 0.587827, acc.: 64.84%] [G loss: 0.566117]\n",
      "epoch:4 step:3772 [D loss: 0.482911, acc.: 78.12%] [G loss: 0.629507]\n",
      "epoch:4 step:3773 [D loss: 0.470868, acc.: 80.47%] [G loss: 0.643094]\n",
      "epoch:4 step:3774 [D loss: 0.514151, acc.: 75.78%] [G loss: 0.507809]\n",
      "epoch:4 step:3775 [D loss: 0.478986, acc.: 75.78%] [G loss: 0.580914]\n",
      "epoch:4 step:3776 [D loss: 0.515978, acc.: 73.44%] [G loss: 0.518635]\n",
      "epoch:4 step:3777 [D loss: 0.477565, acc.: 78.91%] [G loss: 0.465970]\n",
      "epoch:4 step:3778 [D loss: 0.539380, acc.: 75.00%] [G loss: 0.409277]\n",
      "epoch:4 step:3779 [D loss: 0.487199, acc.: 80.47%] [G loss: 0.570037]\n",
      "epoch:4 step:3780 [D loss: 0.472283, acc.: 79.69%] [G loss: 0.636387]\n",
      "epoch:4 step:3781 [D loss: 0.491817, acc.: 75.78%] [G loss: 0.534624]\n",
      "epoch:4 step:3782 [D loss: 0.466201, acc.: 78.12%] [G loss: 0.509108]\n",
      "epoch:4 step:3783 [D loss: 0.516410, acc.: 74.22%] [G loss: 0.589152]\n",
      "epoch:4 step:3784 [D loss: 0.447126, acc.: 78.12%] [G loss: 0.700268]\n",
      "epoch:4 step:3785 [D loss: 0.483144, acc.: 78.91%] [G loss: 0.597382]\n",
      "epoch:4 step:3786 [D loss: 0.581689, acc.: 71.88%] [G loss: 0.505563]\n",
      "epoch:4 step:3787 [D loss: 0.477672, acc.: 78.12%] [G loss: 0.574760]\n",
      "epoch:4 step:3788 [D loss: 0.425495, acc.: 85.94%] [G loss: 0.708139]\n",
      "epoch:4 step:3789 [D loss: 0.532248, acc.: 75.00%] [G loss: 0.577540]\n",
      "epoch:4 step:3790 [D loss: 0.476838, acc.: 81.25%] [G loss: 0.584462]\n",
      "epoch:4 step:3791 [D loss: 0.465278, acc.: 75.78%] [G loss: 0.518237]\n",
      "epoch:4 step:3792 [D loss: 0.591072, acc.: 64.84%] [G loss: 0.470809]\n",
      "epoch:4 step:3793 [D loss: 0.487582, acc.: 82.03%] [G loss: 0.600141]\n",
      "epoch:4 step:3794 [D loss: 0.516286, acc.: 75.78%] [G loss: 0.592883]\n",
      "epoch:4 step:3795 [D loss: 0.512997, acc.: 75.00%] [G loss: 0.515311]\n",
      "epoch:4 step:3796 [D loss: 0.510669, acc.: 78.91%] [G loss: 0.539906]\n",
      "epoch:4 step:3797 [D loss: 0.483551, acc.: 84.38%] [G loss: 0.496922]\n",
      "epoch:4 step:3798 [D loss: 0.536416, acc.: 78.12%] [G loss: 0.412772]\n",
      "epoch:4 step:3799 [D loss: 0.529828, acc.: 77.34%] [G loss: 0.427701]\n",
      "epoch:4 step:3800 [D loss: 0.528689, acc.: 72.66%] [G loss: 0.549425]\n",
      "##############\n",
      "[3.43306261 1.89676416 7.09546214 5.34098028 4.48457588 6.41365665\n",
      " 5.5923407  5.31706763 5.31485754 3.9021089 ]\n",
      "##########\n",
      "epoch:4 step:3801 [D loss: 0.520922, acc.: 74.22%] [G loss: 0.593373]\n",
      "epoch:4 step:3802 [D loss: 0.479487, acc.: 80.47%] [G loss: 0.662886]\n",
      "epoch:4 step:3803 [D loss: 0.502815, acc.: 75.78%] [G loss: 0.660823]\n",
      "epoch:4 step:3804 [D loss: 0.526375, acc.: 75.00%] [G loss: 0.674307]\n",
      "epoch:4 step:3805 [D loss: 0.508850, acc.: 76.56%] [G loss: 0.513843]\n",
      "epoch:4 step:3806 [D loss: 0.531051, acc.: 72.66%] [G loss: 0.622281]\n",
      "epoch:4 step:3807 [D loss: 0.498587, acc.: 76.56%] [G loss: 0.682150]\n",
      "epoch:4 step:3808 [D loss: 0.517194, acc.: 75.78%] [G loss: 0.624609]\n",
      "epoch:4 step:3809 [D loss: 0.508662, acc.: 74.22%] [G loss: 0.627266]\n",
      "epoch:4 step:3810 [D loss: 0.605066, acc.: 71.09%] [G loss: 0.568950]\n",
      "epoch:4 step:3811 [D loss: 0.552945, acc.: 75.00%] [G loss: 0.427062]\n",
      "epoch:4 step:3812 [D loss: 0.531787, acc.: 77.34%] [G loss: 0.552079]\n",
      "epoch:4 step:3813 [D loss: 0.537215, acc.: 78.12%] [G loss: 0.524547]\n",
      "epoch:4 step:3814 [D loss: 0.548093, acc.: 76.56%] [G loss: 0.506823]\n",
      "epoch:4 step:3815 [D loss: 0.521033, acc.: 78.12%] [G loss: 0.428985]\n",
      "epoch:4 step:3816 [D loss: 0.559397, acc.: 71.09%] [G loss: 0.480487]\n",
      "epoch:4 step:3817 [D loss: 0.546915, acc.: 74.22%] [G loss: 0.611174]\n",
      "epoch:4 step:3818 [D loss: 0.522339, acc.: 70.31%] [G loss: 0.533175]\n",
      "epoch:4 step:3819 [D loss: 0.500218, acc.: 75.78%] [G loss: 0.439207]\n",
      "epoch:4 step:3820 [D loss: 0.472690, acc.: 80.47%] [G loss: 0.558913]\n",
      "epoch:4 step:3821 [D loss: 0.472272, acc.: 77.34%] [G loss: 0.498347]\n",
      "epoch:4 step:3822 [D loss: 0.474657, acc.: 78.91%] [G loss: 0.657780]\n",
      "epoch:4 step:3823 [D loss: 0.488469, acc.: 70.31%] [G loss: 0.696379]\n",
      "epoch:4 step:3824 [D loss: 0.483968, acc.: 75.00%] [G loss: 0.709063]\n",
      "epoch:4 step:3825 [D loss: 0.391477, acc.: 83.59%] [G loss: 0.742506]\n",
      "epoch:4 step:3826 [D loss: 0.581703, acc.: 73.44%] [G loss: 0.496578]\n",
      "epoch:4 step:3827 [D loss: 0.526175, acc.: 71.09%] [G loss: 0.494505]\n",
      "epoch:4 step:3828 [D loss: 0.538354, acc.: 71.88%] [G loss: 0.516989]\n",
      "epoch:4 step:3829 [D loss: 0.543600, acc.: 73.44%] [G loss: 0.463109]\n",
      "epoch:4 step:3830 [D loss: 0.471116, acc.: 79.69%] [G loss: 0.491120]\n",
      "epoch:4 step:3831 [D loss: 0.434978, acc.: 80.47%] [G loss: 0.605304]\n",
      "epoch:4 step:3832 [D loss: 0.532733, acc.: 74.22%] [G loss: 0.537936]\n",
      "epoch:4 step:3833 [D loss: 0.551612, acc.: 69.53%] [G loss: 0.488571]\n",
      "epoch:4 step:3834 [D loss: 0.523703, acc.: 75.78%] [G loss: 0.529137]\n",
      "epoch:4 step:3835 [D loss: 0.459914, acc.: 80.47%] [G loss: 0.665395]\n",
      "epoch:4 step:3836 [D loss: 0.485781, acc.: 78.91%] [G loss: 0.495062]\n",
      "epoch:4 step:3837 [D loss: 0.474224, acc.: 79.69%] [G loss: 0.660335]\n",
      "epoch:4 step:3838 [D loss: 0.509263, acc.: 74.22%] [G loss: 0.494726]\n",
      "epoch:4 step:3839 [D loss: 0.525961, acc.: 73.44%] [G loss: 0.614038]\n",
      "epoch:4 step:3840 [D loss: 0.479613, acc.: 81.25%] [G loss: 0.638884]\n",
      "epoch:4 step:3841 [D loss: 0.511499, acc.: 75.78%] [G loss: 0.557628]\n",
      "epoch:4 step:3842 [D loss: 0.470776, acc.: 77.34%] [G loss: 0.680783]\n",
      "epoch:4 step:3843 [D loss: 0.506751, acc.: 77.34%] [G loss: 0.535512]\n",
      "epoch:4 step:3844 [D loss: 0.436156, acc.: 81.25%] [G loss: 0.633019]\n",
      "epoch:4 step:3845 [D loss: 0.553486, acc.: 68.75%] [G loss: 0.642349]\n",
      "epoch:4 step:3846 [D loss: 0.554773, acc.: 75.00%] [G loss: 0.672733]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:4 step:3847 [D loss: 0.492153, acc.: 77.34%] [G loss: 0.568283]\n",
      "epoch:4 step:3848 [D loss: 0.433539, acc.: 78.91%] [G loss: 0.803422]\n",
      "epoch:4 step:3849 [D loss: 0.501081, acc.: 78.12%] [G loss: 0.718575]\n",
      "epoch:4 step:3850 [D loss: 0.595613, acc.: 67.97%] [G loss: 0.475825]\n",
      "epoch:4 step:3851 [D loss: 0.492924, acc.: 80.47%] [G loss: 0.548062]\n",
      "epoch:4 step:3852 [D loss: 0.475849, acc.: 72.66%] [G loss: 0.625690]\n",
      "epoch:4 step:3853 [D loss: 0.549622, acc.: 71.09%] [G loss: 0.518609]\n",
      "epoch:4 step:3854 [D loss: 0.534022, acc.: 75.78%] [G loss: 0.501119]\n",
      "epoch:4 step:3855 [D loss: 0.573823, acc.: 68.75%] [G loss: 0.554233]\n",
      "epoch:4 step:3856 [D loss: 0.534725, acc.: 73.44%] [G loss: 0.488826]\n",
      "epoch:4 step:3857 [D loss: 0.564634, acc.: 66.41%] [G loss: 0.530745]\n",
      "epoch:4 step:3858 [D loss: 0.552393, acc.: 74.22%] [G loss: 0.432320]\n",
      "epoch:4 step:3859 [D loss: 0.566602, acc.: 74.22%] [G loss: 0.489055]\n",
      "epoch:4 step:3860 [D loss: 0.518012, acc.: 78.12%] [G loss: 0.505318]\n",
      "epoch:4 step:3861 [D loss: 0.560958, acc.: 67.97%] [G loss: 0.462556]\n",
      "epoch:4 step:3862 [D loss: 0.576561, acc.: 68.75%] [G loss: 0.515894]\n",
      "epoch:4 step:3863 [D loss: 0.547726, acc.: 74.22%] [G loss: 0.543956]\n",
      "epoch:4 step:3864 [D loss: 0.557971, acc.: 73.44%] [G loss: 0.525321]\n",
      "epoch:4 step:3865 [D loss: 0.538924, acc.: 70.31%] [G loss: 0.577067]\n",
      "epoch:4 step:3866 [D loss: 0.534343, acc.: 74.22%] [G loss: 0.634483]\n",
      "epoch:4 step:3867 [D loss: 0.475147, acc.: 78.91%] [G loss: 0.623658]\n",
      "epoch:4 step:3868 [D loss: 0.606385, acc.: 69.53%] [G loss: 0.556155]\n",
      "epoch:4 step:3869 [D loss: 0.559832, acc.: 72.66%] [G loss: 0.467289]\n",
      "epoch:4 step:3870 [D loss: 0.600652, acc.: 64.06%] [G loss: 0.407128]\n",
      "epoch:4 step:3871 [D loss: 0.512664, acc.: 75.78%] [G loss: 0.569207]\n",
      "epoch:4 step:3872 [D loss: 0.554388, acc.: 72.66%] [G loss: 0.427351]\n",
      "epoch:4 step:3873 [D loss: 0.531161, acc.: 72.66%] [G loss: 0.421669]\n",
      "epoch:4 step:3874 [D loss: 0.504126, acc.: 77.34%] [G loss: 0.501657]\n",
      "epoch:4 step:3875 [D loss: 0.496871, acc.: 75.78%] [G loss: 0.562117]\n",
      "epoch:4 step:3876 [D loss: 0.518571, acc.: 72.66%] [G loss: 0.426543]\n",
      "epoch:4 step:3877 [D loss: 0.570466, acc.: 68.75%] [G loss: 0.450590]\n",
      "epoch:4 step:3878 [D loss: 0.488146, acc.: 80.47%] [G loss: 0.551594]\n",
      "epoch:4 step:3879 [D loss: 0.443430, acc.: 78.12%] [G loss: 0.547337]\n",
      "epoch:4 step:3880 [D loss: 0.503573, acc.: 76.56%] [G loss: 0.538367]\n",
      "epoch:4 step:3881 [D loss: 0.576136, acc.: 67.19%] [G loss: 0.541291]\n",
      "epoch:4 step:3882 [D loss: 0.502855, acc.: 71.09%] [G loss: 0.486525]\n",
      "epoch:4 step:3883 [D loss: 0.482543, acc.: 77.34%] [G loss: 0.573541]\n",
      "epoch:4 step:3884 [D loss: 0.583120, acc.: 68.75%] [G loss: 0.639036]\n",
      "epoch:4 step:3885 [D loss: 0.588920, acc.: 69.53%] [G loss: 0.461873]\n",
      "epoch:4 step:3886 [D loss: 0.519964, acc.: 75.78%] [G loss: 0.386619]\n",
      "epoch:4 step:3887 [D loss: 0.572870, acc.: 66.41%] [G loss: 0.453847]\n",
      "epoch:4 step:3888 [D loss: 0.583479, acc.: 64.84%] [G loss: 0.467855]\n",
      "epoch:4 step:3889 [D loss: 0.500261, acc.: 79.69%] [G loss: 0.513383]\n",
      "epoch:4 step:3890 [D loss: 0.509982, acc.: 71.88%] [G loss: 0.559956]\n",
      "epoch:4 step:3891 [D loss: 0.572128, acc.: 71.09%] [G loss: 0.628057]\n",
      "epoch:4 step:3892 [D loss: 0.496805, acc.: 78.91%] [G loss: 0.562530]\n",
      "epoch:4 step:3893 [D loss: 0.537908, acc.: 71.09%] [G loss: 0.592933]\n",
      "epoch:4 step:3894 [D loss: 0.524159, acc.: 73.44%] [G loss: 0.605740]\n",
      "epoch:4 step:3895 [D loss: 0.614419, acc.: 69.53%] [G loss: 0.390739]\n",
      "epoch:4 step:3896 [D loss: 0.578839, acc.: 66.41%] [G loss: 0.433867]\n",
      "epoch:4 step:3897 [D loss: 0.482697, acc.: 78.12%] [G loss: 0.529227]\n",
      "epoch:4 step:3898 [D loss: 0.546947, acc.: 77.34%] [G loss: 0.436412]\n",
      "epoch:4 step:3899 [D loss: 0.496863, acc.: 75.78%] [G loss: 0.584951]\n",
      "epoch:4 step:3900 [D loss: 0.504315, acc.: 76.56%] [G loss: 0.596100]\n",
      "epoch:4 step:3901 [D loss: 0.555363, acc.: 71.88%] [G loss: 0.559807]\n",
      "epoch:4 step:3902 [D loss: 0.521633, acc.: 73.44%] [G loss: 0.489125]\n",
      "epoch:4 step:3903 [D loss: 0.458385, acc.: 80.47%] [G loss: 0.583299]\n",
      "epoch:4 step:3904 [D loss: 0.541131, acc.: 75.00%] [G loss: 0.608874]\n",
      "epoch:4 step:3905 [D loss: 0.530854, acc.: 76.56%] [G loss: 0.506531]\n",
      "epoch:4 step:3906 [D loss: 0.533686, acc.: 75.78%] [G loss: 0.442424]\n",
      "epoch:4 step:3907 [D loss: 0.559801, acc.: 67.19%] [G loss: 0.523432]\n",
      "epoch:4 step:3908 [D loss: 0.556908, acc.: 72.66%] [G loss: 0.592249]\n",
      "epoch:4 step:3909 [D loss: 0.508403, acc.: 74.22%] [G loss: 0.499826]\n",
      "epoch:4 step:3910 [D loss: 0.466594, acc.: 75.00%] [G loss: 0.590954]\n",
      "epoch:4 step:3911 [D loss: 0.491860, acc.: 73.44%] [G loss: 0.661082]\n",
      "epoch:4 step:3912 [D loss: 0.484680, acc.: 78.12%] [G loss: 0.635251]\n",
      "epoch:4 step:3913 [D loss: 0.488563, acc.: 81.25%] [G loss: 0.532308]\n",
      "epoch:4 step:3914 [D loss: 0.512325, acc.: 75.78%] [G loss: 0.594993]\n",
      "epoch:4 step:3915 [D loss: 0.549378, acc.: 68.75%] [G loss: 0.470158]\n",
      "epoch:4 step:3916 [D loss: 0.519036, acc.: 72.66%] [G loss: 0.612307]\n",
      "epoch:4 step:3917 [D loss: 0.633592, acc.: 63.28%] [G loss: 0.454350]\n",
      "epoch:4 step:3918 [D loss: 0.492093, acc.: 78.91%] [G loss: 0.517771]\n",
      "epoch:4 step:3919 [D loss: 0.471991, acc.: 79.69%] [G loss: 0.486366]\n",
      "epoch:4 step:3920 [D loss: 0.470930, acc.: 82.03%] [G loss: 0.499633]\n",
      "epoch:4 step:3921 [D loss: 0.503498, acc.: 73.44%] [G loss: 0.497593]\n",
      "epoch:4 step:3922 [D loss: 0.525120, acc.: 68.75%] [G loss: 0.496262]\n",
      "epoch:4 step:3923 [D loss: 0.512904, acc.: 71.88%] [G loss: 0.566758]\n",
      "epoch:4 step:3924 [D loss: 0.487781, acc.: 78.91%] [G loss: 0.624122]\n",
      "epoch:4 step:3925 [D loss: 0.489439, acc.: 79.69%] [G loss: 0.539044]\n",
      "epoch:4 step:3926 [D loss: 0.508681, acc.: 74.22%] [G loss: 0.600148]\n",
      "epoch:4 step:3927 [D loss: 0.538907, acc.: 71.88%] [G loss: 0.645950]\n",
      "epoch:4 step:3928 [D loss: 0.553456, acc.: 77.34%] [G loss: 0.390304]\n",
      "epoch:4 step:3929 [D loss: 0.544097, acc.: 72.66%] [G loss: 0.495265]\n",
      "epoch:4 step:3930 [D loss: 0.536828, acc.: 72.66%] [G loss: 0.611625]\n",
      "epoch:4 step:3931 [D loss: 0.534229, acc.: 70.31%] [G loss: 0.540690]\n",
      "epoch:4 step:3932 [D loss: 0.573573, acc.: 69.53%] [G loss: 0.677889]\n",
      "epoch:4 step:3933 [D loss: 0.580127, acc.: 67.97%] [G loss: 0.635294]\n",
      "epoch:4 step:3934 [D loss: 0.530819, acc.: 78.12%] [G loss: 0.509088]\n",
      "epoch:4 step:3935 [D loss: 0.571580, acc.: 71.09%] [G loss: 0.416977]\n",
      "epoch:4 step:3936 [D loss: 0.519386, acc.: 75.78%] [G loss: 0.499521]\n",
      "epoch:4 step:3937 [D loss: 0.531991, acc.: 73.44%] [G loss: 0.489624]\n",
      "epoch:4 step:3938 [D loss: 0.431396, acc.: 77.34%] [G loss: 0.594244]\n",
      "epoch:4 step:3939 [D loss: 0.500979, acc.: 76.56%] [G loss: 0.537399]\n",
      "epoch:4 step:3940 [D loss: 0.473530, acc.: 80.47%] [G loss: 0.667342]\n",
      "epoch:4 step:3941 [D loss: 0.510603, acc.: 76.56%] [G loss: 0.545011]\n",
      "epoch:4 step:3942 [D loss: 0.484337, acc.: 76.56%] [G loss: 0.610276]\n",
      "epoch:4 step:3943 [D loss: 0.539951, acc.: 72.66%] [G loss: 0.596570]\n",
      "epoch:4 step:3944 [D loss: 0.553944, acc.: 70.31%] [G loss: 0.563106]\n",
      "epoch:4 step:3945 [D loss: 0.535761, acc.: 74.22%] [G loss: 0.478078]\n",
      "epoch:4 step:3946 [D loss: 0.469789, acc.: 81.25%] [G loss: 0.637620]\n",
      "epoch:4 step:3947 [D loss: 0.521453, acc.: 75.78%] [G loss: 0.579722]\n",
      "epoch:4 step:3948 [D loss: 0.597735, acc.: 70.31%] [G loss: 0.498474]\n",
      "epoch:4 step:3949 [D loss: 0.525279, acc.: 75.78%] [G loss: 0.527760]\n",
      "epoch:4 step:3950 [D loss: 0.531465, acc.: 75.00%] [G loss: 0.436776]\n",
      "epoch:4 step:3951 [D loss: 0.587836, acc.: 69.53%] [G loss: 0.376646]\n",
      "epoch:4 step:3952 [D loss: 0.549130, acc.: 71.09%] [G loss: 0.599028]\n",
      "epoch:4 step:3953 [D loss: 0.492616, acc.: 73.44%] [G loss: 0.540658]\n",
      "epoch:4 step:3954 [D loss: 0.465498, acc.: 79.69%] [G loss: 0.710113]\n",
      "epoch:4 step:3955 [D loss: 0.401943, acc.: 85.94%] [G loss: 0.713295]\n",
      "epoch:4 step:3956 [D loss: 0.500222, acc.: 78.91%] [G loss: 0.559688]\n",
      "epoch:4 step:3957 [D loss: 0.496179, acc.: 77.34%] [G loss: 0.663905]\n",
      "epoch:4 step:3958 [D loss: 0.574857, acc.: 67.19%] [G loss: 0.508881]\n",
      "epoch:4 step:3959 [D loss: 0.547300, acc.: 73.44%] [G loss: 0.505456]\n",
      "epoch:4 step:3960 [D loss: 0.539721, acc.: 72.66%] [G loss: 0.457865]\n",
      "epoch:4 step:3961 [D loss: 0.493430, acc.: 73.44%] [G loss: 0.612039]\n",
      "epoch:4 step:3962 [D loss: 0.673907, acc.: 55.47%] [G loss: 0.422783]\n",
      "epoch:4 step:3963 [D loss: 0.545531, acc.: 71.09%] [G loss: 0.440603]\n",
      "epoch:4 step:3964 [D loss: 0.545716, acc.: 71.09%] [G loss: 0.482152]\n",
      "epoch:4 step:3965 [D loss: 0.482151, acc.: 78.12%] [G loss: 0.541308]\n",
      "epoch:4 step:3966 [D loss: 0.526657, acc.: 73.44%] [G loss: 0.474983]\n",
      "epoch:4 step:3967 [D loss: 0.503444, acc.: 76.56%] [G loss: 0.453161]\n",
      "epoch:4 step:3968 [D loss: 0.588138, acc.: 65.62%] [G loss: 0.413214]\n",
      "epoch:4 step:3969 [D loss: 0.488647, acc.: 78.91%] [G loss: 0.575040]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:4 step:3970 [D loss: 0.487934, acc.: 76.56%] [G loss: 0.691315]\n",
      "epoch:4 step:3971 [D loss: 0.440104, acc.: 84.38%] [G loss: 0.689289]\n",
      "epoch:4 step:3972 [D loss: 0.586995, acc.: 63.28%] [G loss: 0.483983]\n",
      "epoch:4 step:3973 [D loss: 0.587898, acc.: 66.41%] [G loss: 0.589171]\n",
      "epoch:4 step:3974 [D loss: 0.514410, acc.: 70.31%] [G loss: 0.450075]\n",
      "epoch:4 step:3975 [D loss: 0.561657, acc.: 71.88%] [G loss: 0.337361]\n",
      "epoch:4 step:3976 [D loss: 0.566332, acc.: 68.75%] [G loss: 0.468121]\n",
      "epoch:4 step:3977 [D loss: 0.501114, acc.: 72.66%] [G loss: 0.518881]\n",
      "epoch:4 step:3978 [D loss: 0.452097, acc.: 82.03%] [G loss: 0.585021]\n",
      "epoch:4 step:3979 [D loss: 0.488925, acc.: 78.91%] [G loss: 0.811876]\n",
      "epoch:4 step:3980 [D loss: 0.414887, acc.: 84.38%] [G loss: 0.911313]\n",
      "epoch:4 step:3981 [D loss: 0.517045, acc.: 78.91%] [G loss: 0.580496]\n",
      "epoch:4 step:3982 [D loss: 0.451327, acc.: 79.69%] [G loss: 0.699434]\n",
      "epoch:4 step:3983 [D loss: 0.547494, acc.: 71.88%] [G loss: 0.670015]\n",
      "epoch:4 step:3984 [D loss: 0.494097, acc.: 80.47%] [G loss: 0.629606]\n",
      "epoch:4 step:3985 [D loss: 0.554772, acc.: 72.66%] [G loss: 0.491865]\n",
      "epoch:4 step:3986 [D loss: 0.573036, acc.: 68.75%] [G loss: 0.409191]\n",
      "epoch:4 step:3987 [D loss: 0.505104, acc.: 76.56%] [G loss: 0.553546]\n",
      "epoch:4 step:3988 [D loss: 0.515984, acc.: 74.22%] [G loss: 0.534480]\n",
      "epoch:4 step:3989 [D loss: 0.549057, acc.: 75.78%] [G loss: 0.499754]\n",
      "epoch:4 step:3990 [D loss: 0.504107, acc.: 77.34%] [G loss: 0.572644]\n",
      "epoch:4 step:3991 [D loss: 0.508649, acc.: 78.12%] [G loss: 0.555741]\n",
      "epoch:4 step:3992 [D loss: 0.502479, acc.: 76.56%] [G loss: 0.629211]\n",
      "epoch:4 step:3993 [D loss: 0.495442, acc.: 78.91%] [G loss: 0.615775]\n",
      "epoch:4 step:3994 [D loss: 0.526802, acc.: 71.88%] [G loss: 0.523021]\n",
      "epoch:4 step:3995 [D loss: 0.613958, acc.: 63.28%] [G loss: 0.495308]\n",
      "epoch:4 step:3996 [D loss: 0.544307, acc.: 71.09%] [G loss: 0.511252]\n",
      "epoch:4 step:3997 [D loss: 0.569809, acc.: 69.53%] [G loss: 0.518413]\n",
      "epoch:4 step:3998 [D loss: 0.579344, acc.: 64.84%] [G loss: 0.557480]\n",
      "epoch:4 step:3999 [D loss: 0.605985, acc.: 65.62%] [G loss: 0.574320]\n",
      "epoch:4 step:4000 [D loss: 0.518826, acc.: 74.22%] [G loss: 0.493977]\n",
      "##############\n",
      "[3.84922137 1.62716232 7.25234941 5.20824901 4.58915057 6.30283938\n",
      " 5.55247318 5.42448942 5.44529428 3.81655638]\n",
      "##########\n",
      "epoch:4 step:4001 [D loss: 0.495060, acc.: 78.12%] [G loss: 0.484633]\n",
      "epoch:4 step:4002 [D loss: 0.489193, acc.: 73.44%] [G loss: 0.508834]\n",
      "epoch:4 step:4003 [D loss: 0.466382, acc.: 81.25%] [G loss: 0.549197]\n",
      "epoch:4 step:4004 [D loss: 0.526903, acc.: 74.22%] [G loss: 0.574525]\n",
      "epoch:4 step:4005 [D loss: 0.574348, acc.: 65.62%] [G loss: 0.431418]\n",
      "epoch:4 step:4006 [D loss: 0.493006, acc.: 75.00%] [G loss: 0.554098]\n",
      "epoch:4 step:4007 [D loss: 0.489632, acc.: 75.78%] [G loss: 0.520201]\n",
      "epoch:4 step:4008 [D loss: 0.552149, acc.: 71.09%] [G loss: 0.503340]\n",
      "epoch:4 step:4009 [D loss: 0.476506, acc.: 78.91%] [G loss: 0.610057]\n",
      "epoch:4 step:4010 [D loss: 0.496876, acc.: 78.91%] [G loss: 0.514737]\n",
      "epoch:4 step:4011 [D loss: 0.665828, acc.: 61.72%] [G loss: 0.466881]\n",
      "epoch:4 step:4012 [D loss: 0.496574, acc.: 78.12%] [G loss: 0.503380]\n",
      "epoch:4 step:4013 [D loss: 0.529833, acc.: 75.00%] [G loss: 0.450366]\n",
      "epoch:4 step:4014 [D loss: 0.499676, acc.: 79.69%] [G loss: 0.597238]\n",
      "epoch:4 step:4015 [D loss: 0.566620, acc.: 69.53%] [G loss: 0.519919]\n",
      "epoch:4 step:4016 [D loss: 0.502178, acc.: 76.56%] [G loss: 0.474369]\n",
      "epoch:4 step:4017 [D loss: 0.514638, acc.: 75.00%] [G loss: 0.504653]\n",
      "epoch:4 step:4018 [D loss: 0.503214, acc.: 77.34%] [G loss: 0.594989]\n",
      "epoch:4 step:4019 [D loss: 0.521405, acc.: 76.56%] [G loss: 0.546735]\n",
      "epoch:4 step:4020 [D loss: 0.557699, acc.: 72.66%] [G loss: 0.565317]\n",
      "epoch:4 step:4021 [D loss: 0.494817, acc.: 74.22%] [G loss: 0.562458]\n",
      "epoch:4 step:4022 [D loss: 0.521599, acc.: 75.78%] [G loss: 0.529429]\n",
      "epoch:4 step:4023 [D loss: 0.575308, acc.: 64.84%] [G loss: 0.420411]\n",
      "epoch:4 step:4024 [D loss: 0.544624, acc.: 70.31%] [G loss: 0.463580]\n",
      "epoch:4 step:4025 [D loss: 0.607708, acc.: 64.84%] [G loss: 0.503926]\n",
      "epoch:4 step:4026 [D loss: 0.569352, acc.: 71.88%] [G loss: 0.430910]\n",
      "epoch:4 step:4027 [D loss: 0.489160, acc.: 80.47%] [G loss: 0.629573]\n",
      "epoch:4 step:4028 [D loss: 0.566712, acc.: 67.97%] [G loss: 0.552991]\n",
      "epoch:4 step:4029 [D loss: 0.654143, acc.: 62.50%] [G loss: 0.334236]\n",
      "epoch:4 step:4030 [D loss: 0.579720, acc.: 68.75%] [G loss: 0.491610]\n",
      "epoch:4 step:4031 [D loss: 0.488989, acc.: 80.47%] [G loss: 0.439824]\n",
      "epoch:4 step:4032 [D loss: 0.500552, acc.: 77.34%] [G loss: 0.469854]\n",
      "epoch:4 step:4033 [D loss: 0.515137, acc.: 75.00%] [G loss: 0.531999]\n",
      "epoch:4 step:4034 [D loss: 0.446569, acc.: 84.38%] [G loss: 0.628367]\n",
      "epoch:4 step:4035 [D loss: 0.545690, acc.: 70.31%] [G loss: 0.546344]\n",
      "epoch:4 step:4036 [D loss: 0.557882, acc.: 71.88%] [G loss: 0.517266]\n",
      "epoch:4 step:4037 [D loss: 0.504420, acc.: 78.12%] [G loss: 0.432879]\n",
      "epoch:4 step:4038 [D loss: 0.498793, acc.: 77.34%] [G loss: 0.486352]\n",
      "epoch:4 step:4039 [D loss: 0.529833, acc.: 74.22%] [G loss: 0.536325]\n",
      "epoch:4 step:4040 [D loss: 0.563353, acc.: 70.31%] [G loss: 0.533009]\n",
      "epoch:4 step:4041 [D loss: 0.512037, acc.: 74.22%] [G loss: 0.565776]\n",
      "epoch:4 step:4042 [D loss: 0.529519, acc.: 75.00%] [G loss: 0.473051]\n",
      "epoch:4 step:4043 [D loss: 0.511047, acc.: 75.78%] [G loss: 0.573502]\n",
      "epoch:4 step:4044 [D loss: 0.437438, acc.: 80.47%] [G loss: 0.537948]\n",
      "epoch:4 step:4045 [D loss: 0.548742, acc.: 72.66%] [G loss: 0.504923]\n",
      "epoch:4 step:4046 [D loss: 0.522776, acc.: 72.66%] [G loss: 0.571198]\n",
      "epoch:4 step:4047 [D loss: 0.472322, acc.: 78.12%] [G loss: 0.595317]\n",
      "epoch:4 step:4048 [D loss: 0.505573, acc.: 73.44%] [G loss: 0.592527]\n",
      "epoch:4 step:4049 [D loss: 0.583696, acc.: 67.19%] [G loss: 0.547853]\n",
      "epoch:4 step:4050 [D loss: 0.497846, acc.: 75.00%] [G loss: 0.547773]\n",
      "epoch:4 step:4051 [D loss: 0.488483, acc.: 75.78%] [G loss: 0.658020]\n",
      "epoch:4 step:4052 [D loss: 0.443399, acc.: 78.91%] [G loss: 0.518191]\n",
      "epoch:4 step:4053 [D loss: 0.464594, acc.: 78.91%] [G loss: 0.591189]\n",
      "epoch:4 step:4054 [D loss: 0.507628, acc.: 74.22%] [G loss: 0.523583]\n",
      "epoch:4 step:4055 [D loss: 0.451823, acc.: 85.16%] [G loss: 0.517717]\n",
      "epoch:4 step:4056 [D loss: 0.463041, acc.: 79.69%] [G loss: 0.641670]\n",
      "epoch:4 step:4057 [D loss: 0.493989, acc.: 79.69%] [G loss: 0.662188]\n",
      "epoch:4 step:4058 [D loss: 0.486499, acc.: 74.22%] [G loss: 0.640947]\n",
      "epoch:4 step:4059 [D loss: 0.459895, acc.: 78.12%] [G loss: 0.668804]\n",
      "epoch:4 step:4060 [D loss: 0.487686, acc.: 74.22%] [G loss: 0.698169]\n",
      "epoch:4 step:4061 [D loss: 0.467265, acc.: 82.03%] [G loss: 0.848698]\n",
      "epoch:4 step:4062 [D loss: 0.474192, acc.: 75.78%] [G loss: 0.791830]\n",
      "epoch:4 step:4063 [D loss: 0.445945, acc.: 80.47%] [G loss: 1.032876]\n",
      "epoch:4 step:4064 [D loss: 0.704076, acc.: 55.47%] [G loss: 0.565331]\n",
      "epoch:4 step:4065 [D loss: 0.619597, acc.: 64.84%] [G loss: 0.426671]\n",
      "epoch:4 step:4066 [D loss: 0.466996, acc.: 82.03%] [G loss: 0.630106]\n",
      "epoch:4 step:4067 [D loss: 0.545372, acc.: 71.09%] [G loss: 0.602920]\n",
      "epoch:4 step:4068 [D loss: 0.496164, acc.: 77.34%] [G loss: 0.570980]\n",
      "epoch:4 step:4069 [D loss: 0.473423, acc.: 81.25%] [G loss: 0.621144]\n",
      "epoch:4 step:4070 [D loss: 0.550997, acc.: 72.66%] [G loss: 0.560274]\n",
      "epoch:4 step:4071 [D loss: 0.563341, acc.: 67.97%] [G loss: 0.517725]\n",
      "epoch:4 step:4072 [D loss: 0.546817, acc.: 71.88%] [G loss: 0.525387]\n",
      "epoch:4 step:4073 [D loss: 0.499415, acc.: 78.91%] [G loss: 0.455866]\n",
      "epoch:4 step:4074 [D loss: 0.495270, acc.: 71.09%] [G loss: 0.546371]\n",
      "epoch:4 step:4075 [D loss: 0.501721, acc.: 75.00%] [G loss: 0.621319]\n",
      "epoch:4 step:4076 [D loss: 0.510389, acc.: 75.78%] [G loss: 0.603918]\n",
      "epoch:4 step:4077 [D loss: 0.502477, acc.: 77.34%] [G loss: 0.641624]\n",
      "epoch:4 step:4078 [D loss: 0.527229, acc.: 75.00%] [G loss: 0.529090]\n",
      "epoch:4 step:4079 [D loss: 0.568730, acc.: 74.22%] [G loss: 0.478742]\n",
      "epoch:4 step:4080 [D loss: 0.526066, acc.: 71.09%] [G loss: 0.498472]\n",
      "epoch:4 step:4081 [D loss: 0.471817, acc.: 75.00%] [G loss: 0.589597]\n",
      "epoch:4 step:4082 [D loss: 0.523143, acc.: 74.22%] [G loss: 0.609447]\n",
      "epoch:4 step:4083 [D loss: 0.450624, acc.: 76.56%] [G loss: 0.816007]\n",
      "epoch:4 step:4084 [D loss: 0.498232, acc.: 75.00%] [G loss: 0.653349]\n",
      "epoch:4 step:4085 [D loss: 0.493175, acc.: 78.12%] [G loss: 0.660881]\n",
      "epoch:4 step:4086 [D loss: 0.553843, acc.: 67.97%] [G loss: 0.504066]\n",
      "epoch:4 step:4087 [D loss: 0.523997, acc.: 78.12%] [G loss: 0.527302]\n",
      "epoch:4 step:4088 [D loss: 0.476695, acc.: 78.12%] [G loss: 0.632734]\n",
      "epoch:4 step:4089 [D loss: 0.599152, acc.: 68.75%] [G loss: 0.391541]\n",
      "epoch:4 step:4090 [D loss: 0.609162, acc.: 63.28%] [G loss: 0.551177]\n",
      "epoch:4 step:4091 [D loss: 0.474813, acc.: 76.56%] [G loss: 0.649642]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:4 step:4092 [D loss: 0.424297, acc.: 85.16%] [G loss: 0.663027]\n",
      "epoch:4 step:4093 [D loss: 0.512998, acc.: 75.78%] [G loss: 0.650278]\n",
      "epoch:4 step:4094 [D loss: 0.507435, acc.: 74.22%] [G loss: 0.810626]\n",
      "epoch:4 step:4095 [D loss: 0.460255, acc.: 77.34%] [G loss: 0.795550]\n",
      "epoch:4 step:4096 [D loss: 0.633279, acc.: 71.09%] [G loss: 0.543570]\n",
      "epoch:4 step:4097 [D loss: 0.653346, acc.: 59.38%] [G loss: 0.390967]\n",
      "epoch:4 step:4098 [D loss: 0.496644, acc.: 78.91%] [G loss: 0.400699]\n",
      "epoch:4 step:4099 [D loss: 0.520722, acc.: 76.56%] [G loss: 0.537127]\n",
      "epoch:4 step:4100 [D loss: 0.541039, acc.: 72.66%] [G loss: 0.532196]\n",
      "epoch:4 step:4101 [D loss: 0.528231, acc.: 70.31%] [G loss: 0.540948]\n",
      "epoch:4 step:4102 [D loss: 0.476857, acc.: 79.69%] [G loss: 0.638546]\n",
      "epoch:4 step:4103 [D loss: 0.563789, acc.: 71.09%] [G loss: 0.626132]\n",
      "epoch:4 step:4104 [D loss: 0.557547, acc.: 71.09%] [G loss: 0.597776]\n",
      "epoch:4 step:4105 [D loss: 0.471108, acc.: 82.03%] [G loss: 0.574999]\n",
      "epoch:4 step:4106 [D loss: 0.493602, acc.: 74.22%] [G loss: 0.662592]\n",
      "epoch:4 step:4107 [D loss: 0.460505, acc.: 78.91%] [G loss: 0.803503]\n",
      "epoch:4 step:4108 [D loss: 0.518077, acc.: 76.56%] [G loss: 0.702407]\n",
      "epoch:4 step:4109 [D loss: 0.484397, acc.: 81.25%] [G loss: 0.570246]\n",
      "epoch:4 step:4110 [D loss: 0.543152, acc.: 75.78%] [G loss: 0.590405]\n",
      "epoch:4 step:4111 [D loss: 0.502812, acc.: 77.34%] [G loss: 0.537290]\n",
      "epoch:4 step:4112 [D loss: 0.496264, acc.: 74.22%] [G loss: 0.635246]\n",
      "epoch:4 step:4113 [D loss: 0.505704, acc.: 74.22%] [G loss: 0.579824]\n",
      "epoch:4 step:4114 [D loss: 0.460013, acc.: 78.91%] [G loss: 0.571943]\n",
      "epoch:4 step:4115 [D loss: 0.549178, acc.: 72.66%] [G loss: 0.712231]\n",
      "epoch:4 step:4116 [D loss: 0.517993, acc.: 71.09%] [G loss: 0.651997]\n",
      "epoch:4 step:4117 [D loss: 0.572365, acc.: 68.75%] [G loss: 0.486406]\n",
      "epoch:4 step:4118 [D loss: 0.549112, acc.: 72.66%] [G loss: 0.512438]\n",
      "epoch:4 step:4119 [D loss: 0.513529, acc.: 76.56%] [G loss: 0.677898]\n",
      "epoch:4 step:4120 [D loss: 0.500441, acc.: 79.69%] [G loss: 0.633388]\n",
      "epoch:4 step:4121 [D loss: 0.555413, acc.: 72.66%] [G loss: 0.463795]\n",
      "epoch:4 step:4122 [D loss: 0.425122, acc.: 82.03%] [G loss: 0.607383]\n",
      "epoch:4 step:4123 [D loss: 0.499450, acc.: 75.00%] [G loss: 0.620696]\n",
      "epoch:4 step:4124 [D loss: 0.688926, acc.: 60.16%] [G loss: 0.470916]\n",
      "epoch:4 step:4125 [D loss: 0.526264, acc.: 73.44%] [G loss: 0.584583]\n",
      "epoch:4 step:4126 [D loss: 0.534847, acc.: 71.88%] [G loss: 0.614877]\n",
      "epoch:4 step:4127 [D loss: 0.579194, acc.: 71.09%] [G loss: 0.523908]\n",
      "epoch:4 step:4128 [D loss: 0.533455, acc.: 75.00%] [G loss: 0.607985]\n",
      "epoch:4 step:4129 [D loss: 0.475645, acc.: 78.91%] [G loss: 0.532193]\n",
      "epoch:4 step:4130 [D loss: 0.481973, acc.: 80.47%] [G loss: 0.635028]\n",
      "epoch:4 step:4131 [D loss: 0.539639, acc.: 74.22%] [G loss: 0.542406]\n",
      "epoch:4 step:4132 [D loss: 0.548022, acc.: 75.00%] [G loss: 0.603801]\n",
      "epoch:4 step:4133 [D loss: 0.520525, acc.: 71.88%] [G loss: 0.584963]\n",
      "epoch:4 step:4134 [D loss: 0.520371, acc.: 71.88%] [G loss: 0.513701]\n",
      "epoch:4 step:4135 [D loss: 0.552060, acc.: 71.88%] [G loss: 0.412897]\n",
      "epoch:4 step:4136 [D loss: 0.519886, acc.: 76.56%] [G loss: 0.461472]\n",
      "epoch:4 step:4137 [D loss: 0.510357, acc.: 77.34%] [G loss: 0.551358]\n",
      "epoch:4 step:4138 [D loss: 0.540191, acc.: 73.44%] [G loss: 0.475407]\n",
      "epoch:4 step:4139 [D loss: 0.475017, acc.: 78.91%] [G loss: 0.605308]\n",
      "epoch:4 step:4140 [D loss: 0.452480, acc.: 79.69%] [G loss: 0.678918]\n",
      "epoch:4 step:4141 [D loss: 0.527587, acc.: 74.22%] [G loss: 0.545411]\n",
      "epoch:4 step:4142 [D loss: 0.506452, acc.: 75.00%] [G loss: 0.518357]\n",
      "epoch:4 step:4143 [D loss: 0.460490, acc.: 78.12%] [G loss: 0.531667]\n",
      "epoch:4 step:4144 [D loss: 0.575241, acc.: 68.75%] [G loss: 0.531620]\n",
      "epoch:4 step:4145 [D loss: 0.533576, acc.: 74.22%] [G loss: 0.571808]\n",
      "epoch:4 step:4146 [D loss: 0.456644, acc.: 75.00%] [G loss: 0.756364]\n",
      "epoch:4 step:4147 [D loss: 0.506094, acc.: 77.34%] [G loss: 0.748791]\n",
      "epoch:4 step:4148 [D loss: 0.624427, acc.: 62.50%] [G loss: 0.561212]\n",
      "epoch:4 step:4149 [D loss: 0.555099, acc.: 71.09%] [G loss: 0.485107]\n",
      "epoch:4 step:4150 [D loss: 0.472583, acc.: 76.56%] [G loss: 0.536623]\n",
      "epoch:4 step:4151 [D loss: 0.509604, acc.: 74.22%] [G loss: 0.584454]\n",
      "epoch:4 step:4152 [D loss: 0.601113, acc.: 64.06%] [G loss: 0.520901]\n",
      "epoch:4 step:4153 [D loss: 0.558074, acc.: 66.41%] [G loss: 0.522403]\n",
      "epoch:4 step:4154 [D loss: 0.502584, acc.: 76.56%] [G loss: 0.605076]\n",
      "epoch:4 step:4155 [D loss: 0.521362, acc.: 75.00%] [G loss: 0.499224]\n",
      "epoch:4 step:4156 [D loss: 0.565664, acc.: 71.09%] [G loss: 0.669725]\n",
      "epoch:4 step:4157 [D loss: 0.513979, acc.: 78.12%] [G loss: 0.676557]\n",
      "epoch:4 step:4158 [D loss: 0.541371, acc.: 72.66%] [G loss: 0.613300]\n",
      "epoch:4 step:4159 [D loss: 0.556396, acc.: 69.53%] [G loss: 0.414690]\n",
      "epoch:4 step:4160 [D loss: 0.584344, acc.: 67.19%] [G loss: 0.536108]\n",
      "epoch:4 step:4161 [D loss: 0.526875, acc.: 73.44%] [G loss: 0.469294]\n",
      "epoch:4 step:4162 [D loss: 0.569142, acc.: 71.09%] [G loss: 0.493176]\n",
      "epoch:4 step:4163 [D loss: 0.568240, acc.: 69.53%] [G loss: 0.553524]\n",
      "epoch:4 step:4164 [D loss: 0.525339, acc.: 74.22%] [G loss: 0.535496]\n",
      "epoch:4 step:4165 [D loss: 0.596126, acc.: 69.53%] [G loss: 0.432184]\n",
      "epoch:4 step:4166 [D loss: 0.593902, acc.: 62.50%] [G loss: 0.383385]\n",
      "epoch:4 step:4167 [D loss: 0.502821, acc.: 75.78%] [G loss: 0.458104]\n",
      "epoch:4 step:4168 [D loss: 0.587722, acc.: 67.19%] [G loss: 0.463912]\n",
      "epoch:4 step:4169 [D loss: 0.568303, acc.: 69.53%] [G loss: 0.469994]\n",
      "epoch:4 step:4170 [D loss: 0.557691, acc.: 69.53%] [G loss: 0.430226]\n",
      "epoch:4 step:4171 [D loss: 0.557215, acc.: 66.41%] [G loss: 0.478286]\n",
      "epoch:4 step:4172 [D loss: 0.613317, acc.: 64.06%] [G loss: 0.473514]\n",
      "epoch:4 step:4173 [D loss: 0.565150, acc.: 75.78%] [G loss: 0.523518]\n",
      "epoch:4 step:4174 [D loss: 0.478798, acc.: 77.34%] [G loss: 0.682196]\n",
      "epoch:4 step:4175 [D loss: 0.509089, acc.: 74.22%] [G loss: 0.632918]\n",
      "epoch:4 step:4176 [D loss: 0.431992, acc.: 83.59%] [G loss: 0.697661]\n",
      "epoch:4 step:4177 [D loss: 0.397957, acc.: 82.81%] [G loss: 0.823830]\n",
      "epoch:4 step:4178 [D loss: 0.511451, acc.: 77.34%] [G loss: 0.636614]\n",
      "epoch:4 step:4179 [D loss: 0.505761, acc.: 76.56%] [G loss: 0.659466]\n",
      "epoch:4 step:4180 [D loss: 0.587795, acc.: 71.09%] [G loss: 0.465949]\n",
      "epoch:4 step:4181 [D loss: 0.583323, acc.: 70.31%] [G loss: 0.479572]\n",
      "epoch:4 step:4182 [D loss: 0.489017, acc.: 77.34%] [G loss: 0.463788]\n",
      "epoch:4 step:4183 [D loss: 0.564579, acc.: 70.31%] [G loss: 0.455432]\n",
      "epoch:4 step:4184 [D loss: 0.490665, acc.: 78.12%] [G loss: 0.640986]\n",
      "epoch:4 step:4185 [D loss: 0.655055, acc.: 61.72%] [G loss: 0.489354]\n",
      "epoch:4 step:4186 [D loss: 0.596874, acc.: 64.84%] [G loss: 0.470995]\n",
      "epoch:4 step:4187 [D loss: 0.526100, acc.: 72.66%] [G loss: 0.561853]\n",
      "epoch:4 step:4188 [D loss: 0.544924, acc.: 75.00%] [G loss: 0.565319]\n",
      "epoch:4 step:4189 [D loss: 0.577890, acc.: 74.22%] [G loss: 0.480125]\n",
      "epoch:4 step:4190 [D loss: 0.569283, acc.: 71.09%] [G loss: 0.446081]\n",
      "epoch:4 step:4191 [D loss: 0.514923, acc.: 79.69%] [G loss: 0.467039]\n",
      "epoch:4 step:4192 [D loss: 0.466070, acc.: 78.91%] [G loss: 0.576887]\n",
      "epoch:4 step:4193 [D loss: 0.501660, acc.: 75.00%] [G loss: 0.597269]\n",
      "epoch:4 step:4194 [D loss: 0.485434, acc.: 75.78%] [G loss: 0.527844]\n",
      "epoch:4 step:4195 [D loss: 0.504661, acc.: 72.66%] [G loss: 0.663559]\n",
      "epoch:4 step:4196 [D loss: 0.491719, acc.: 82.03%] [G loss: 0.563804]\n",
      "epoch:4 step:4197 [D loss: 0.490311, acc.: 78.12%] [G loss: 0.728593]\n",
      "epoch:4 step:4198 [D loss: 0.473349, acc.: 79.69%] [G loss: 0.609369]\n",
      "epoch:4 step:4199 [D loss: 0.443304, acc.: 82.03%] [G loss: 0.625966]\n",
      "epoch:4 step:4200 [D loss: 0.512442, acc.: 74.22%] [G loss: 0.684851]\n",
      "##############\n",
      "[3.32835537 1.96642078 6.94198542 5.30860902 4.47693408 6.22997779\n",
      " 5.44838855 5.19169952 5.18042533 3.937379  ]\n",
      "##########\n",
      "epoch:4 step:4201 [D loss: 0.553024, acc.: 67.97%] [G loss: 0.582649]\n",
      "epoch:4 step:4202 [D loss: 0.527860, acc.: 74.22%] [G loss: 0.601914]\n",
      "epoch:4 step:4203 [D loss: 0.611160, acc.: 62.50%] [G loss: 0.550798]\n",
      "epoch:4 step:4204 [D loss: 0.610306, acc.: 64.84%] [G loss: 0.506779]\n",
      "epoch:4 step:4205 [D loss: 0.533803, acc.: 74.22%] [G loss: 0.504885]\n",
      "epoch:4 step:4206 [D loss: 0.549702, acc.: 75.78%] [G loss: 0.594424]\n",
      "epoch:4 step:4207 [D loss: 0.520260, acc.: 74.22%] [G loss: 0.479845]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:4 step:4208 [D loss: 0.500391, acc.: 76.56%] [G loss: 0.466461]\n",
      "epoch:4 step:4209 [D loss: 0.500910, acc.: 74.22%] [G loss: 0.544299]\n",
      "epoch:4 step:4210 [D loss: 0.553419, acc.: 72.66%] [G loss: 0.477883]\n",
      "epoch:4 step:4211 [D loss: 0.537660, acc.: 72.66%] [G loss: 0.557274]\n",
      "epoch:4 step:4212 [D loss: 0.523486, acc.: 74.22%] [G loss: 0.560853]\n",
      "epoch:4 step:4213 [D loss: 0.626310, acc.: 64.84%] [G loss: 0.581423]\n",
      "epoch:4 step:4214 [D loss: 0.540702, acc.: 75.00%] [G loss: 0.570451]\n",
      "epoch:4 step:4215 [D loss: 0.525683, acc.: 73.44%] [G loss: 0.640891]\n",
      "epoch:4 step:4216 [D loss: 0.517497, acc.: 73.44%] [G loss: 0.611977]\n",
      "epoch:4 step:4217 [D loss: 0.572666, acc.: 67.97%] [G loss: 0.568528]\n",
      "epoch:4 step:4218 [D loss: 0.516042, acc.: 71.88%] [G loss: 0.626847]\n",
      "epoch:4 step:4219 [D loss: 0.466303, acc.: 77.34%] [G loss: 0.750090]\n",
      "epoch:4 step:4220 [D loss: 0.465532, acc.: 79.69%] [G loss: 0.750105]\n",
      "epoch:4 step:4221 [D loss: 0.601886, acc.: 68.75%] [G loss: 0.651468]\n",
      "epoch:4 step:4222 [D loss: 0.506216, acc.: 78.91%] [G loss: 0.626922]\n",
      "epoch:4 step:4223 [D loss: 0.474064, acc.: 80.47%] [G loss: 0.788281]\n",
      "epoch:4 step:4224 [D loss: 0.552509, acc.: 74.22%] [G loss: 0.642619]\n",
      "epoch:4 step:4225 [D loss: 0.718401, acc.: 60.94%] [G loss: 0.441763]\n",
      "epoch:4 step:4226 [D loss: 0.547403, acc.: 69.53%] [G loss: 0.391607]\n",
      "epoch:4 step:4227 [D loss: 0.568504, acc.: 71.09%] [G loss: 0.376917]\n",
      "epoch:4 step:4228 [D loss: 0.598719, acc.: 71.88%] [G loss: 0.477331]\n",
      "epoch:4 step:4229 [D loss: 0.518745, acc.: 77.34%] [G loss: 0.470562]\n",
      "epoch:4 step:4230 [D loss: 0.584188, acc.: 67.19%] [G loss: 0.437173]\n",
      "epoch:4 step:4231 [D loss: 0.509788, acc.: 75.78%] [G loss: 0.520619]\n",
      "epoch:4 step:4232 [D loss: 0.522575, acc.: 79.69%] [G loss: 0.558156]\n",
      "epoch:4 step:4233 [D loss: 0.566232, acc.: 67.97%] [G loss: 0.509117]\n",
      "epoch:4 step:4234 [D loss: 0.572410, acc.: 67.97%] [G loss: 0.565703]\n",
      "epoch:4 step:4235 [D loss: 0.470580, acc.: 78.91%] [G loss: 0.607446]\n",
      "epoch:4 step:4236 [D loss: 0.475339, acc.: 76.56%] [G loss: 0.514202]\n",
      "epoch:4 step:4237 [D loss: 0.624664, acc.: 67.19%] [G loss: 0.446495]\n",
      "epoch:4 step:4238 [D loss: 0.568057, acc.: 73.44%] [G loss: 0.447705]\n",
      "epoch:4 step:4239 [D loss: 0.529438, acc.: 70.31%] [G loss: 0.490509]\n",
      "epoch:4 step:4240 [D loss: 0.547569, acc.: 75.78%] [G loss: 0.496787]\n",
      "epoch:4 step:4241 [D loss: 0.576939, acc.: 67.19%] [G loss: 0.462667]\n",
      "epoch:4 step:4242 [D loss: 0.535543, acc.: 74.22%] [G loss: 0.514378]\n",
      "epoch:4 step:4243 [D loss: 0.470404, acc.: 82.81%] [G loss: 0.496673]\n",
      "epoch:4 step:4244 [D loss: 0.512350, acc.: 74.22%] [G loss: 0.557086]\n",
      "epoch:4 step:4245 [D loss: 0.520606, acc.: 75.78%] [G loss: 0.526706]\n",
      "epoch:4 step:4246 [D loss: 0.463184, acc.: 79.69%] [G loss: 0.701814]\n",
      "epoch:4 step:4247 [D loss: 0.431978, acc.: 82.03%] [G loss: 0.808262]\n",
      "epoch:4 step:4248 [D loss: 0.614564, acc.: 66.41%] [G loss: 0.457840]\n",
      "epoch:4 step:4249 [D loss: 0.639128, acc.: 64.06%] [G loss: 0.414556]\n",
      "epoch:4 step:4250 [D loss: 0.517672, acc.: 80.47%] [G loss: 0.485335]\n",
      "epoch:4 step:4251 [D loss: 0.460838, acc.: 78.12%] [G loss: 0.571154]\n",
      "epoch:4 step:4252 [D loss: 0.482640, acc.: 77.34%] [G loss: 0.664194]\n",
      "epoch:4 step:4253 [D loss: 0.526900, acc.: 75.78%] [G loss: 0.551921]\n",
      "epoch:4 step:4254 [D loss: 0.504598, acc.: 74.22%] [G loss: 0.502061]\n",
      "epoch:4 step:4255 [D loss: 0.513441, acc.: 78.12%] [G loss: 0.527907]\n",
      "epoch:4 step:4256 [D loss: 0.448001, acc.: 82.81%] [G loss: 0.614648]\n",
      "epoch:4 step:4257 [D loss: 0.506180, acc.: 74.22%] [G loss: 0.596487]\n",
      "epoch:4 step:4258 [D loss: 0.519890, acc.: 71.09%] [G loss: 0.632976]\n",
      "epoch:4 step:4259 [D loss: 0.598167, acc.: 63.28%] [G loss: 0.478841]\n",
      "epoch:4 step:4260 [D loss: 0.571247, acc.: 73.44%] [G loss: 0.505331]\n",
      "epoch:4 step:4261 [D loss: 0.511208, acc.: 75.00%] [G loss: 0.520900]\n",
      "epoch:4 step:4262 [D loss: 0.508303, acc.: 76.56%] [G loss: 0.725424]\n",
      "epoch:4 step:4263 [D loss: 0.505320, acc.: 75.78%] [G loss: 0.598284]\n",
      "epoch:4 step:4264 [D loss: 0.493006, acc.: 82.81%] [G loss: 0.637383]\n",
      "epoch:4 step:4265 [D loss: 0.568335, acc.: 71.09%] [G loss: 0.510003]\n",
      "epoch:4 step:4266 [D loss: 0.495011, acc.: 77.34%] [G loss: 0.517154]\n",
      "epoch:4 step:4267 [D loss: 0.541861, acc.: 71.88%] [G loss: 0.501110]\n",
      "epoch:4 step:4268 [D loss: 0.455842, acc.: 82.81%] [G loss: 0.624977]\n",
      "epoch:4 step:4269 [D loss: 0.502222, acc.: 76.56%] [G loss: 0.614379]\n",
      "epoch:4 step:4270 [D loss: 0.484874, acc.: 77.34%] [G loss: 0.647457]\n",
      "epoch:4 step:4271 [D loss: 0.542907, acc.: 67.19%] [G loss: 0.655772]\n",
      "epoch:4 step:4272 [D loss: 0.617497, acc.: 61.72%] [G loss: 0.438536]\n",
      "epoch:4 step:4273 [D loss: 0.558812, acc.: 70.31%] [G loss: 0.483423]\n",
      "epoch:4 step:4274 [D loss: 0.522108, acc.: 75.00%] [G loss: 0.516349]\n",
      "epoch:4 step:4275 [D loss: 0.511470, acc.: 77.34%] [G loss: 0.623840]\n",
      "epoch:4 step:4276 [D loss: 0.617710, acc.: 64.84%] [G loss: 0.471469]\n",
      "epoch:4 step:4277 [D loss: 0.535399, acc.: 73.44%] [G loss: 0.513092]\n",
      "epoch:4 step:4278 [D loss: 0.487965, acc.: 75.78%] [G loss: 0.573776]\n",
      "epoch:4 step:4279 [D loss: 0.561841, acc.: 71.88%] [G loss: 0.450135]\n",
      "epoch:4 step:4280 [D loss: 0.553669, acc.: 73.44%] [G loss: 0.539491]\n",
      "epoch:4 step:4281 [D loss: 0.507523, acc.: 72.66%] [G loss: 0.595456]\n",
      "epoch:4 step:4282 [D loss: 0.458597, acc.: 82.03%] [G loss: 0.676550]\n",
      "epoch:4 step:4283 [D loss: 0.619430, acc.: 63.28%] [G loss: 0.438842]\n",
      "epoch:4 step:4284 [D loss: 0.487790, acc.: 78.91%] [G loss: 0.572145]\n",
      "epoch:4 step:4285 [D loss: 0.586928, acc.: 66.41%] [G loss: 0.568920]\n",
      "epoch:4 step:4286 [D loss: 0.586153, acc.: 66.41%] [G loss: 0.530543]\n",
      "epoch:4 step:4287 [D loss: 0.512201, acc.: 78.12%] [G loss: 0.540492]\n",
      "epoch:4 step:4288 [D loss: 0.512902, acc.: 76.56%] [G loss: 0.478729]\n",
      "epoch:4 step:4289 [D loss: 0.545127, acc.: 72.66%] [G loss: 0.496807]\n",
      "epoch:4 step:4290 [D loss: 0.565114, acc.: 74.22%] [G loss: 0.500130]\n",
      "epoch:4 step:4291 [D loss: 0.553698, acc.: 71.09%] [G loss: 0.634069]\n",
      "epoch:4 step:4292 [D loss: 0.520126, acc.: 74.22%] [G loss: 0.439807]\n",
      "epoch:4 step:4293 [D loss: 0.553724, acc.: 71.09%] [G loss: 0.510454]\n",
      "epoch:4 step:4294 [D loss: 0.468727, acc.: 75.00%] [G loss: 0.648329]\n",
      "epoch:4 step:4295 [D loss: 0.430528, acc.: 82.03%] [G loss: 0.625552]\n",
      "epoch:4 step:4296 [D loss: 0.527279, acc.: 72.66%] [G loss: 0.498819]\n",
      "epoch:4 step:4297 [D loss: 0.516098, acc.: 75.00%] [G loss: 0.527574]\n",
      "epoch:4 step:4298 [D loss: 0.541533, acc.: 74.22%] [G loss: 0.478319]\n",
      "epoch:4 step:4299 [D loss: 0.509411, acc.: 75.00%] [G loss: 0.546557]\n",
      "epoch:4 step:4300 [D loss: 0.461573, acc.: 79.69%] [G loss: 0.591286]\n",
      "epoch:4 step:4301 [D loss: 0.520852, acc.: 77.34%] [G loss: 0.526830]\n",
      "epoch:4 step:4302 [D loss: 0.448152, acc.: 80.47%] [G loss: 0.645989]\n",
      "epoch:4 step:4303 [D loss: 0.503536, acc.: 75.78%] [G loss: 0.541726]\n",
      "epoch:4 step:4304 [D loss: 0.469969, acc.: 80.47%] [G loss: 0.569029]\n",
      "epoch:4 step:4305 [D loss: 0.435741, acc.: 84.38%] [G loss: 0.587621]\n",
      "epoch:4 step:4306 [D loss: 0.474506, acc.: 78.12%] [G loss: 0.596952]\n",
      "epoch:4 step:4307 [D loss: 0.523034, acc.: 72.66%] [G loss: 0.563424]\n",
      "epoch:4 step:4308 [D loss: 0.569604, acc.: 70.31%] [G loss: 0.564759]\n",
      "epoch:4 step:4309 [D loss: 0.489430, acc.: 78.12%] [G loss: 0.472097]\n",
      "epoch:4 step:4310 [D loss: 0.542001, acc.: 72.66%] [G loss: 0.486460]\n",
      "epoch:4 step:4311 [D loss: 0.571081, acc.: 67.19%] [G loss: 0.429020]\n",
      "epoch:4 step:4312 [D loss: 0.527760, acc.: 71.09%] [G loss: 0.550388]\n",
      "epoch:4 step:4313 [D loss: 0.443048, acc.: 82.03%] [G loss: 0.655851]\n",
      "epoch:4 step:4314 [D loss: 0.615003, acc.: 71.88%] [G loss: 0.505400]\n",
      "epoch:4 step:4315 [D loss: 0.468738, acc.: 78.12%] [G loss: 0.452593]\n",
      "epoch:4 step:4316 [D loss: 0.484947, acc.: 75.78%] [G loss: 0.821632]\n",
      "epoch:4 step:4317 [D loss: 0.546735, acc.: 68.75%] [G loss: 0.636780]\n",
      "epoch:4 step:4318 [D loss: 0.511681, acc.: 76.56%] [G loss: 0.613509]\n",
      "epoch:4 step:4319 [D loss: 0.535596, acc.: 74.22%] [G loss: 0.537331]\n",
      "epoch:4 step:4320 [D loss: 0.535068, acc.: 71.09%] [G loss: 0.614098]\n",
      "epoch:4 step:4321 [D loss: 0.535140, acc.: 72.66%] [G loss: 0.621745]\n",
      "epoch:4 step:4322 [D loss: 0.508378, acc.: 76.56%] [G loss: 0.685606]\n",
      "epoch:4 step:4323 [D loss: 0.485548, acc.: 74.22%] [G loss: 0.586432]\n",
      "epoch:4 step:4324 [D loss: 0.559203, acc.: 71.88%] [G loss: 0.463009]\n",
      "epoch:4 step:4325 [D loss: 0.596777, acc.: 60.16%] [G loss: 0.444363]\n",
      "epoch:4 step:4326 [D loss: 0.531522, acc.: 72.66%] [G loss: 0.554990]\n",
      "epoch:4 step:4327 [D loss: 0.513479, acc.: 75.78%] [G loss: 0.594054]\n",
      "epoch:4 step:4328 [D loss: 0.546571, acc.: 75.78%] [G loss: 0.827146]\n",
      "epoch:4 step:4329 [D loss: 0.531567, acc.: 71.88%] [G loss: 0.671221]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:4 step:4330 [D loss: 0.453351, acc.: 78.12%] [G loss: 0.626346]\n",
      "epoch:4 step:4331 [D loss: 0.583629, acc.: 70.31%] [G loss: 0.545664]\n",
      "epoch:4 step:4332 [D loss: 0.562417, acc.: 68.75%] [G loss: 0.656402]\n",
      "epoch:4 step:4333 [D loss: 0.555462, acc.: 68.75%] [G loss: 0.531994]\n",
      "epoch:4 step:4334 [D loss: 0.558440, acc.: 70.31%] [G loss: 0.532260]\n",
      "epoch:4 step:4335 [D loss: 0.542649, acc.: 68.75%] [G loss: 0.553670]\n",
      "epoch:4 step:4336 [D loss: 0.583444, acc.: 69.53%] [G loss: 0.670575]\n",
      "epoch:4 step:4337 [D loss: 0.499242, acc.: 73.44%] [G loss: 0.694594]\n",
      "epoch:4 step:4338 [D loss: 0.565902, acc.: 67.97%] [G loss: 0.491986]\n",
      "epoch:4 step:4339 [D loss: 0.570689, acc.: 75.00%] [G loss: 0.523579]\n",
      "epoch:4 step:4340 [D loss: 0.417719, acc.: 84.38%] [G loss: 0.501149]\n",
      "epoch:4 step:4341 [D loss: 0.555801, acc.: 70.31%] [G loss: 0.524540]\n",
      "epoch:4 step:4342 [D loss: 0.581520, acc.: 70.31%] [G loss: 0.451742]\n",
      "epoch:4 step:4343 [D loss: 0.538811, acc.: 69.53%] [G loss: 0.543161]\n",
      "epoch:4 step:4344 [D loss: 0.534560, acc.: 68.75%] [G loss: 0.489870]\n",
      "epoch:4 step:4345 [D loss: 0.562983, acc.: 70.31%] [G loss: 0.536288]\n",
      "epoch:4 step:4346 [D loss: 0.522864, acc.: 75.78%] [G loss: 0.561192]\n",
      "epoch:4 step:4347 [D loss: 0.538730, acc.: 73.44%] [G loss: 0.482698]\n",
      "epoch:4 step:4348 [D loss: 0.569507, acc.: 68.75%] [G loss: 0.504914]\n",
      "epoch:4 step:4349 [D loss: 0.506793, acc.: 76.56%] [G loss: 0.426732]\n",
      "epoch:4 step:4350 [D loss: 0.449665, acc.: 83.59%] [G loss: 0.612272]\n",
      "epoch:4 step:4351 [D loss: 0.480062, acc.: 78.91%] [G loss: 0.502240]\n",
      "epoch:4 step:4352 [D loss: 0.548047, acc.: 73.44%] [G loss: 0.517720]\n",
      "epoch:4 step:4353 [D loss: 0.514925, acc.: 76.56%] [G loss: 0.528600]\n",
      "epoch:4 step:4354 [D loss: 0.525534, acc.: 74.22%] [G loss: 0.530193]\n",
      "epoch:4 step:4355 [D loss: 0.561108, acc.: 68.75%] [G loss: 0.623952]\n",
      "epoch:4 step:4356 [D loss: 0.529276, acc.: 76.56%] [G loss: 0.621571]\n",
      "epoch:4 step:4357 [D loss: 0.488430, acc.: 77.34%] [G loss: 0.587004]\n",
      "epoch:4 step:4358 [D loss: 0.555113, acc.: 68.75%] [G loss: 0.529723]\n",
      "epoch:4 step:4359 [D loss: 0.517851, acc.: 73.44%] [G loss: 0.389524]\n",
      "epoch:4 step:4360 [D loss: 0.483059, acc.: 78.12%] [G loss: 0.550139]\n",
      "epoch:4 step:4361 [D loss: 0.468663, acc.: 80.47%] [G loss: 0.586585]\n",
      "epoch:4 step:4362 [D loss: 0.538625, acc.: 75.78%] [G loss: 0.547102]\n",
      "epoch:4 step:4363 [D loss: 0.616165, acc.: 60.94%] [G loss: 0.509501]\n",
      "epoch:4 step:4364 [D loss: 0.572315, acc.: 67.97%] [G loss: 0.539030]\n",
      "epoch:4 step:4365 [D loss: 0.532137, acc.: 69.53%] [G loss: 0.621066]\n",
      "epoch:4 step:4366 [D loss: 0.542902, acc.: 71.88%] [G loss: 0.510950]\n",
      "epoch:4 step:4367 [D loss: 0.518009, acc.: 74.22%] [G loss: 0.642807]\n",
      "epoch:4 step:4368 [D loss: 0.528330, acc.: 75.00%] [G loss: 0.576877]\n",
      "epoch:4 step:4369 [D loss: 0.513876, acc.: 76.56%] [G loss: 0.588753]\n",
      "epoch:4 step:4370 [D loss: 0.618459, acc.: 65.62%] [G loss: 0.463854]\n",
      "epoch:4 step:4371 [D loss: 0.522611, acc.: 73.44%] [G loss: 0.503331]\n",
      "epoch:4 step:4372 [D loss: 0.506575, acc.: 75.78%] [G loss: 0.653602]\n",
      "epoch:4 step:4373 [D loss: 0.502475, acc.: 76.56%] [G loss: 0.583622]\n",
      "epoch:4 step:4374 [D loss: 0.504320, acc.: 75.78%] [G loss: 0.562866]\n",
      "epoch:4 step:4375 [D loss: 0.490087, acc.: 78.91%] [G loss: 0.570990]\n",
      "epoch:4 step:4376 [D loss: 0.541350, acc.: 71.88%] [G loss: 0.544759]\n",
      "epoch:4 step:4377 [D loss: 0.494417, acc.: 75.78%] [G loss: 0.566675]\n",
      "epoch:4 step:4378 [D loss: 0.531389, acc.: 75.78%] [G loss: 0.540220]\n",
      "epoch:4 step:4379 [D loss: 0.484407, acc.: 74.22%] [G loss: 0.599310]\n",
      "epoch:4 step:4380 [D loss: 0.484885, acc.: 80.47%] [G loss: 0.502663]\n",
      "epoch:4 step:4381 [D loss: 0.509256, acc.: 74.22%] [G loss: 0.645938]\n",
      "epoch:4 step:4382 [D loss: 0.513813, acc.: 78.12%] [G loss: 0.605502]\n",
      "epoch:4 step:4383 [D loss: 0.499075, acc.: 75.78%] [G loss: 0.597549]\n",
      "epoch:4 step:4384 [D loss: 0.597840, acc.: 67.19%] [G loss: 0.473843]\n",
      "epoch:4 step:4385 [D loss: 0.532008, acc.: 70.31%] [G loss: 0.511135]\n",
      "epoch:4 step:4386 [D loss: 0.566365, acc.: 74.22%] [G loss: 0.498017]\n",
      "epoch:4 step:4387 [D loss: 0.456197, acc.: 82.81%] [G loss: 0.662240]\n",
      "epoch:4 step:4388 [D loss: 0.509499, acc.: 74.22%] [G loss: 0.622250]\n",
      "epoch:4 step:4389 [D loss: 0.460151, acc.: 81.25%] [G loss: 0.770822]\n",
      "epoch:4 step:4390 [D loss: 0.487096, acc.: 76.56%] [G loss: 0.763709]\n",
      "epoch:4 step:4391 [D loss: 0.538621, acc.: 71.09%] [G loss: 0.684865]\n",
      "epoch:4 step:4392 [D loss: 0.601121, acc.: 69.53%] [G loss: 0.537372]\n",
      "epoch:4 step:4393 [D loss: 0.604916, acc.: 70.31%] [G loss: 0.424005]\n",
      "epoch:4 step:4394 [D loss: 0.539729, acc.: 73.44%] [G loss: 0.563877]\n",
      "epoch:4 step:4395 [D loss: 0.479741, acc.: 77.34%] [G loss: 0.555691]\n",
      "epoch:4 step:4396 [D loss: 0.405362, acc.: 80.47%] [G loss: 0.734044]\n",
      "epoch:4 step:4397 [D loss: 0.551295, acc.: 72.66%] [G loss: 0.723087]\n",
      "epoch:4 step:4398 [D loss: 0.552895, acc.: 71.09%] [G loss: 0.767881]\n",
      "epoch:4 step:4399 [D loss: 0.461153, acc.: 74.22%] [G loss: 0.703648]\n",
      "epoch:4 step:4400 [D loss: 0.586395, acc.: 68.75%] [G loss: 0.486825]\n",
      "##############\n",
      "[3.47399702 1.75883017 6.87232063 5.00843193 4.6546927  6.29525317\n",
      " 5.45786173 5.27883302 5.12613368 4.08335965]\n",
      "##########\n",
      "epoch:4 step:4401 [D loss: 0.602801, acc.: 67.19%] [G loss: 0.466661]\n",
      "epoch:4 step:4402 [D loss: 0.496450, acc.: 75.78%] [G loss: 0.504673]\n",
      "epoch:4 step:4403 [D loss: 0.545797, acc.: 72.66%] [G loss: 0.477822]\n",
      "epoch:4 step:4404 [D loss: 0.540362, acc.: 72.66%] [G loss: 0.463417]\n",
      "epoch:4 step:4405 [D loss: 0.576818, acc.: 67.97%] [G loss: 0.455399]\n",
      "epoch:4 step:4406 [D loss: 0.579819, acc.: 67.19%] [G loss: 0.644945]\n",
      "epoch:4 step:4407 [D loss: 0.550929, acc.: 75.78%] [G loss: 0.445285]\n",
      "epoch:4 step:4408 [D loss: 0.486388, acc.: 77.34%] [G loss: 0.557350]\n",
      "epoch:4 step:4409 [D loss: 0.485938, acc.: 75.00%] [G loss: 0.557472]\n",
      "epoch:4 step:4410 [D loss: 0.547958, acc.: 67.97%] [G loss: 0.603342]\n",
      "epoch:4 step:4411 [D loss: 0.515967, acc.: 74.22%] [G loss: 0.701955]\n",
      "epoch:4 step:4412 [D loss: 0.548155, acc.: 71.88%] [G loss: 0.613717]\n",
      "epoch:4 step:4413 [D loss: 0.502981, acc.: 74.22%] [G loss: 0.703337]\n",
      "epoch:4 step:4414 [D loss: 0.494357, acc.: 82.81%] [G loss: 0.546277]\n",
      "epoch:4 step:4415 [D loss: 0.615394, acc.: 67.19%] [G loss: 0.565148]\n",
      "epoch:4 step:4416 [D loss: 0.541226, acc.: 74.22%] [G loss: 0.514066]\n",
      "epoch:4 step:4417 [D loss: 0.510890, acc.: 70.31%] [G loss: 0.477886]\n",
      "epoch:4 step:4418 [D loss: 0.523548, acc.: 68.75%] [G loss: 0.527105]\n",
      "epoch:4 step:4419 [D loss: 0.552305, acc.: 71.88%] [G loss: 0.578249]\n",
      "epoch:4 step:4420 [D loss: 0.581043, acc.: 69.53%] [G loss: 0.566157]\n",
      "epoch:4 step:4421 [D loss: 0.589903, acc.: 68.75%] [G loss: 0.494260]\n",
      "epoch:4 step:4422 [D loss: 0.497563, acc.: 78.91%] [G loss: 0.548695]\n",
      "epoch:4 step:4423 [D loss: 0.537100, acc.: 77.34%] [G loss: 0.651682]\n",
      "epoch:4 step:4424 [D loss: 0.546249, acc.: 71.88%] [G loss: 0.596430]\n",
      "epoch:4 step:4425 [D loss: 0.517885, acc.: 75.00%] [G loss: 0.619537]\n",
      "epoch:4 step:4426 [D loss: 0.495718, acc.: 81.25%] [G loss: 0.575206]\n",
      "epoch:4 step:4427 [D loss: 0.520365, acc.: 71.09%] [G loss: 0.553439]\n",
      "epoch:4 step:4428 [D loss: 0.421750, acc.: 86.72%] [G loss: 0.660118]\n",
      "epoch:4 step:4429 [D loss: 0.482799, acc.: 79.69%] [G loss: 0.695723]\n",
      "epoch:4 step:4430 [D loss: 0.522230, acc.: 77.34%] [G loss: 0.618482]\n",
      "epoch:4 step:4431 [D loss: 0.556543, acc.: 70.31%] [G loss: 0.551148]\n",
      "epoch:4 step:4432 [D loss: 0.504382, acc.: 71.88%] [G loss: 0.529860]\n",
      "epoch:4 step:4433 [D loss: 0.536381, acc.: 69.53%] [G loss: 0.510610]\n",
      "epoch:4 step:4434 [D loss: 0.542636, acc.: 73.44%] [G loss: 0.546202]\n",
      "epoch:4 step:4435 [D loss: 0.553924, acc.: 73.44%] [G loss: 0.467553]\n",
      "epoch:4 step:4436 [D loss: 0.571699, acc.: 71.09%] [G loss: 0.544410]\n",
      "epoch:4 step:4437 [D loss: 0.513396, acc.: 78.12%] [G loss: 0.615839]\n",
      "epoch:4 step:4438 [D loss: 0.483850, acc.: 78.91%] [G loss: 0.715914]\n",
      "epoch:4 step:4439 [D loss: 0.514667, acc.: 75.00%] [G loss: 0.615453]\n",
      "epoch:4 step:4440 [D loss: 0.514128, acc.: 75.00%] [G loss: 0.574501]\n",
      "epoch:4 step:4441 [D loss: 0.453836, acc.: 82.03%] [G loss: 0.555562]\n",
      "epoch:4 step:4442 [D loss: 0.521407, acc.: 71.09%] [G loss: 0.661666]\n",
      "epoch:4 step:4443 [D loss: 0.518416, acc.: 73.44%] [G loss: 0.600521]\n",
      "epoch:4 step:4444 [D loss: 0.624174, acc.: 59.38%] [G loss: 0.438951]\n",
      "epoch:4 step:4445 [D loss: 0.465424, acc.: 82.03%] [G loss: 0.429055]\n",
      "epoch:4 step:4446 [D loss: 0.513861, acc.: 73.44%] [G loss: 0.620778]\n",
      "epoch:4 step:4447 [D loss: 0.508697, acc.: 72.66%] [G loss: 0.533236]\n",
      "epoch:4 step:4448 [D loss: 0.532779, acc.: 74.22%] [G loss: 0.576640]\n",
      "epoch:4 step:4449 [D loss: 0.502457, acc.: 71.09%] [G loss: 0.622278]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:4 step:4450 [D loss: 0.562273, acc.: 66.41%] [G loss: 0.561403]\n",
      "epoch:4 step:4451 [D loss: 0.599148, acc.: 67.97%] [G loss: 0.526377]\n",
      "epoch:4 step:4452 [D loss: 0.621993, acc.: 69.53%] [G loss: 0.447376]\n",
      "epoch:4 step:4453 [D loss: 0.550688, acc.: 70.31%] [G loss: 0.565606]\n",
      "epoch:4 step:4454 [D loss: 0.519429, acc.: 73.44%] [G loss: 0.551656]\n",
      "epoch:4 step:4455 [D loss: 0.502954, acc.: 70.31%] [G loss: 0.580034]\n",
      "epoch:4 step:4456 [D loss: 0.491528, acc.: 78.91%] [G loss: 0.671766]\n",
      "epoch:4 step:4457 [D loss: 0.510348, acc.: 76.56%] [G loss: 0.620628]\n",
      "epoch:4 step:4458 [D loss: 0.601159, acc.: 65.62%] [G loss: 0.481237]\n",
      "epoch:4 step:4459 [D loss: 0.556969, acc.: 69.53%] [G loss: 0.564025]\n",
      "epoch:4 step:4460 [D loss: 0.550613, acc.: 69.53%] [G loss: 0.532593]\n",
      "epoch:4 step:4461 [D loss: 0.530225, acc.: 77.34%] [G loss: 0.551176]\n",
      "epoch:4 step:4462 [D loss: 0.499143, acc.: 78.12%] [G loss: 0.612029]\n",
      "epoch:4 step:4463 [D loss: 0.540879, acc.: 72.66%] [G loss: 0.553773]\n",
      "epoch:4 step:4464 [D loss: 0.620986, acc.: 65.62%] [G loss: 0.449158]\n",
      "epoch:4 step:4465 [D loss: 0.595178, acc.: 74.22%] [G loss: 0.490450]\n",
      "epoch:4 step:4466 [D loss: 0.589694, acc.: 67.19%] [G loss: 0.431476]\n",
      "epoch:4 step:4467 [D loss: 0.496110, acc.: 78.12%] [G loss: 0.562536]\n",
      "epoch:4 step:4468 [D loss: 0.618918, acc.: 70.31%] [G loss: 0.449128]\n",
      "epoch:4 step:4469 [D loss: 0.601096, acc.: 67.19%] [G loss: 0.500343]\n",
      "epoch:4 step:4470 [D loss: 0.522411, acc.: 74.22%] [G loss: 0.514527]\n",
      "epoch:4 step:4471 [D loss: 0.550909, acc.: 75.78%] [G loss: 0.510828]\n",
      "epoch:4 step:4472 [D loss: 0.568132, acc.: 70.31%] [G loss: 0.512950]\n",
      "epoch:4 step:4473 [D loss: 0.526939, acc.: 75.78%] [G loss: 0.637193]\n",
      "epoch:4 step:4474 [D loss: 0.503039, acc.: 75.00%] [G loss: 0.554798]\n",
      "epoch:4 step:4475 [D loss: 0.574004, acc.: 68.75%] [G loss: 0.490096]\n",
      "epoch:4 step:4476 [D loss: 0.505363, acc.: 71.09%] [G loss: 0.510063]\n",
      "epoch:4 step:4477 [D loss: 0.569895, acc.: 71.09%] [G loss: 0.443030]\n",
      "epoch:4 step:4478 [D loss: 0.569793, acc.: 70.31%] [G loss: 0.504413]\n",
      "epoch:4 step:4479 [D loss: 0.532268, acc.: 67.97%] [G loss: 0.524898]\n",
      "epoch:4 step:4480 [D loss: 0.486907, acc.: 74.22%] [G loss: 0.566237]\n",
      "epoch:4 step:4481 [D loss: 0.541239, acc.: 71.09%] [G loss: 0.595491]\n",
      "epoch:4 step:4482 [D loss: 0.568128, acc.: 67.19%] [G loss: 0.572393]\n",
      "epoch:4 step:4483 [D loss: 0.511398, acc.: 74.22%] [G loss: 0.524361]\n",
      "epoch:4 step:4484 [D loss: 0.502278, acc.: 78.91%] [G loss: 0.601610]\n",
      "epoch:4 step:4485 [D loss: 0.516474, acc.: 75.00%] [G loss: 0.470922]\n",
      "epoch:4 step:4486 [D loss: 0.509058, acc.: 78.91%] [G loss: 0.563329]\n",
      "epoch:4 step:4487 [D loss: 0.552778, acc.: 69.53%] [G loss: 0.561029]\n",
      "epoch:4 step:4488 [D loss: 0.591150, acc.: 64.06%] [G loss: 0.396931]\n",
      "epoch:4 step:4489 [D loss: 0.570115, acc.: 67.97%] [G loss: 0.461423]\n",
      "epoch:4 step:4490 [D loss: 0.568521, acc.: 69.53%] [G loss: 0.439249]\n",
      "epoch:4 step:4491 [D loss: 0.508359, acc.: 76.56%] [G loss: 0.623936]\n",
      "epoch:4 step:4492 [D loss: 0.543480, acc.: 75.78%] [G loss: 0.530200]\n",
      "epoch:4 step:4493 [D loss: 0.504664, acc.: 77.34%] [G loss: 0.506004]\n",
      "epoch:4 step:4494 [D loss: 0.484738, acc.: 77.34%] [G loss: 0.670866]\n",
      "epoch:4 step:4495 [D loss: 0.421537, acc.: 81.25%] [G loss: 0.711814]\n",
      "epoch:4 step:4496 [D loss: 0.549881, acc.: 70.31%] [G loss: 0.501496]\n",
      "epoch:4 step:4497 [D loss: 0.537331, acc.: 71.09%] [G loss: 0.482426]\n",
      "epoch:4 step:4498 [D loss: 0.526370, acc.: 76.56%] [G loss: 0.615426]\n",
      "epoch:4 step:4499 [D loss: 0.517489, acc.: 73.44%] [G loss: 0.536467]\n",
      "epoch:4 step:4500 [D loss: 0.474569, acc.: 81.25%] [G loss: 0.687775]\n",
      "epoch:4 step:4501 [D loss: 0.525119, acc.: 73.44%] [G loss: 0.681323]\n",
      "epoch:4 step:4502 [D loss: 0.461741, acc.: 76.56%] [G loss: 0.730260]\n",
      "epoch:4 step:4503 [D loss: 0.500939, acc.: 71.09%] [G loss: 0.764427]\n",
      "epoch:4 step:4504 [D loss: 0.510693, acc.: 75.00%] [G loss: 0.659895]\n",
      "epoch:4 step:4505 [D loss: 0.583048, acc.: 67.19%] [G loss: 0.614666]\n",
      "epoch:4 step:4506 [D loss: 0.491856, acc.: 74.22%] [G loss: 0.782715]\n",
      "epoch:4 step:4507 [D loss: 0.598078, acc.: 65.62%] [G loss: 0.590442]\n",
      "epoch:4 step:4508 [D loss: 0.529507, acc.: 72.66%] [G loss: 0.614997]\n",
      "epoch:4 step:4509 [D loss: 0.475350, acc.: 78.91%] [G loss: 0.633471]\n",
      "epoch:4 step:4510 [D loss: 0.529953, acc.: 73.44%] [G loss: 0.529231]\n",
      "epoch:4 step:4511 [D loss: 0.494661, acc.: 78.12%] [G loss: 0.533993]\n",
      "epoch:4 step:4512 [D loss: 0.542215, acc.: 73.44%] [G loss: 0.473538]\n",
      "epoch:4 step:4513 [D loss: 0.644392, acc.: 63.28%] [G loss: 0.632865]\n",
      "epoch:4 step:4514 [D loss: 0.612590, acc.: 63.28%] [G loss: 0.581186]\n",
      "epoch:4 step:4515 [D loss: 0.535924, acc.: 72.66%] [G loss: 0.622335]\n",
      "epoch:4 step:4516 [D loss: 0.532867, acc.: 74.22%] [G loss: 0.519242]\n",
      "epoch:4 step:4517 [D loss: 0.450087, acc.: 79.69%] [G loss: 0.790274]\n",
      "epoch:4 step:4518 [D loss: 0.528770, acc.: 75.78%] [G loss: 0.609833]\n",
      "epoch:4 step:4519 [D loss: 0.452199, acc.: 77.34%] [G loss: 0.590806]\n",
      "epoch:4 step:4520 [D loss: 0.514693, acc.: 71.88%] [G loss: 0.530088]\n",
      "epoch:4 step:4521 [D loss: 0.531600, acc.: 75.00%] [G loss: 0.676749]\n",
      "epoch:4 step:4522 [D loss: 0.565139, acc.: 70.31%] [G loss: 0.509287]\n",
      "epoch:4 step:4523 [D loss: 0.510958, acc.: 76.56%] [G loss: 0.546028]\n",
      "epoch:4 step:4524 [D loss: 0.542672, acc.: 69.53%] [G loss: 0.659858]\n",
      "epoch:4 step:4525 [D loss: 0.542922, acc.: 69.53%] [G loss: 0.564608]\n",
      "epoch:4 step:4526 [D loss: 0.533194, acc.: 78.91%] [G loss: 0.469534]\n",
      "epoch:4 step:4527 [D loss: 0.550798, acc.: 68.75%] [G loss: 0.562923]\n",
      "epoch:4 step:4528 [D loss: 0.515481, acc.: 76.56%] [G loss: 0.622671]\n",
      "epoch:4 step:4529 [D loss: 0.478741, acc.: 80.47%] [G loss: 0.791620]\n",
      "epoch:4 step:4530 [D loss: 0.481060, acc.: 78.91%] [G loss: 0.752432]\n",
      "epoch:4 step:4531 [D loss: 0.563890, acc.: 68.75%] [G loss: 0.637831]\n",
      "epoch:4 step:4532 [D loss: 0.569630, acc.: 71.09%] [G loss: 0.558826]\n",
      "epoch:4 step:4533 [D loss: 0.552250, acc.: 77.34%] [G loss: 0.512680]\n",
      "epoch:4 step:4534 [D loss: 0.496289, acc.: 74.22%] [G loss: 0.523892]\n",
      "epoch:4 step:4535 [D loss: 0.558383, acc.: 70.31%] [G loss: 0.567313]\n",
      "epoch:4 step:4536 [D loss: 0.661115, acc.: 64.06%] [G loss: 0.382738]\n",
      "epoch:4 step:4537 [D loss: 0.565769, acc.: 71.88%] [G loss: 0.455050]\n",
      "epoch:4 step:4538 [D loss: 0.519449, acc.: 75.00%] [G loss: 0.466421]\n",
      "epoch:4 step:4539 [D loss: 0.508344, acc.: 76.56%] [G loss: 0.516315]\n",
      "epoch:4 step:4540 [D loss: 0.396776, acc.: 85.16%] [G loss: 0.836785]\n",
      "epoch:4 step:4541 [D loss: 0.575410, acc.: 69.53%] [G loss: 0.708711]\n",
      "epoch:4 step:4542 [D loss: 0.600695, acc.: 67.19%] [G loss: 0.677877]\n",
      "epoch:4 step:4543 [D loss: 0.546877, acc.: 74.22%] [G loss: 0.496900]\n",
      "epoch:4 step:4544 [D loss: 0.461822, acc.: 76.56%] [G loss: 0.687991]\n",
      "epoch:4 step:4545 [D loss: 0.541463, acc.: 77.34%] [G loss: 0.512446]\n",
      "epoch:4 step:4546 [D loss: 0.494022, acc.: 74.22%] [G loss: 0.637027]\n",
      "epoch:4 step:4547 [D loss: 0.524190, acc.: 75.00%] [G loss: 0.599534]\n",
      "epoch:4 step:4548 [D loss: 0.538948, acc.: 69.53%] [G loss: 0.534302]\n",
      "epoch:4 step:4549 [D loss: 0.489071, acc.: 76.56%] [G loss: 0.595071]\n",
      "epoch:4 step:4550 [D loss: 0.494748, acc.: 75.00%] [G loss: 0.675587]\n",
      "epoch:4 step:4551 [D loss: 0.433971, acc.: 81.25%] [G loss: 0.802882]\n",
      "epoch:4 step:4552 [D loss: 0.523368, acc.: 72.66%] [G loss: 0.531434]\n",
      "epoch:4 step:4553 [D loss: 0.498005, acc.: 73.44%] [G loss: 0.476760]\n",
      "epoch:4 step:4554 [D loss: 0.479245, acc.: 72.66%] [G loss: 0.657972]\n",
      "epoch:4 step:4555 [D loss: 0.503020, acc.: 73.44%] [G loss: 0.689480]\n",
      "epoch:4 step:4556 [D loss: 0.509633, acc.: 74.22%] [G loss: 0.673592]\n",
      "epoch:4 step:4557 [D loss: 0.551319, acc.: 71.88%] [G loss: 0.580622]\n",
      "epoch:4 step:4558 [D loss: 0.545001, acc.: 73.44%] [G loss: 0.630289]\n",
      "epoch:4 step:4559 [D loss: 0.584248, acc.: 69.53%] [G loss: 0.513067]\n",
      "epoch:4 step:4560 [D loss: 0.632873, acc.: 64.84%] [G loss: 0.399720]\n",
      "epoch:4 step:4561 [D loss: 0.559534, acc.: 71.88%] [G loss: 0.480260]\n",
      "epoch:4 step:4562 [D loss: 0.535283, acc.: 72.66%] [G loss: 0.498126]\n",
      "epoch:4 step:4563 [D loss: 0.541789, acc.: 74.22%] [G loss: 0.616316]\n",
      "epoch:4 step:4564 [D loss: 0.538240, acc.: 70.31%] [G loss: 0.686133]\n",
      "epoch:4 step:4565 [D loss: 0.574265, acc.: 68.75%] [G loss: 0.688999]\n",
      "epoch:4 step:4566 [D loss: 0.542080, acc.: 65.62%] [G loss: 0.506946]\n",
      "epoch:4 step:4567 [D loss: 0.531386, acc.: 75.78%] [G loss: 0.473367]\n",
      "epoch:4 step:4568 [D loss: 0.544119, acc.: 74.22%] [G loss: 0.564917]\n",
      "epoch:4 step:4569 [D loss: 0.578755, acc.: 64.84%] [G loss: 0.436788]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:4 step:4570 [D loss: 0.476779, acc.: 80.47%] [G loss: 0.522996]\n",
      "epoch:4 step:4571 [D loss: 0.468478, acc.: 82.03%] [G loss: 0.650233]\n",
      "epoch:4 step:4572 [D loss: 0.629868, acc.: 70.31%] [G loss: 0.488352]\n",
      "epoch:4 step:4573 [D loss: 0.526427, acc.: 74.22%] [G loss: 0.466946]\n",
      "epoch:4 step:4574 [D loss: 0.605833, acc.: 60.94%] [G loss: 0.471121]\n",
      "epoch:4 step:4575 [D loss: 0.563649, acc.: 72.66%] [G loss: 0.536364]\n",
      "epoch:4 step:4576 [D loss: 0.602284, acc.: 60.94%] [G loss: 0.487190]\n",
      "epoch:4 step:4577 [D loss: 0.546464, acc.: 65.62%] [G loss: 0.463617]\n",
      "epoch:4 step:4578 [D loss: 0.556902, acc.: 70.31%] [G loss: 0.557117]\n",
      "epoch:4 step:4579 [D loss: 0.523297, acc.: 76.56%] [G loss: 0.417756]\n",
      "epoch:4 step:4580 [D loss: 0.479138, acc.: 78.91%] [G loss: 0.549869]\n",
      "epoch:4 step:4581 [D loss: 0.509347, acc.: 76.56%] [G loss: 0.470614]\n",
      "epoch:4 step:4582 [D loss: 0.517660, acc.: 72.66%] [G loss: 0.527428]\n",
      "epoch:4 step:4583 [D loss: 0.526832, acc.: 74.22%] [G loss: 0.481598]\n",
      "epoch:4 step:4584 [D loss: 0.507555, acc.: 75.00%] [G loss: 0.542986]\n",
      "epoch:4 step:4585 [D loss: 0.529775, acc.: 74.22%] [G loss: 0.578330]\n",
      "epoch:4 step:4586 [D loss: 0.500470, acc.: 76.56%] [G loss: 0.569972]\n",
      "epoch:4 step:4587 [D loss: 0.525478, acc.: 70.31%] [G loss: 0.525277]\n",
      "epoch:4 step:4588 [D loss: 0.579250, acc.: 68.75%] [G loss: 0.564872]\n",
      "epoch:4 step:4589 [D loss: 0.543662, acc.: 75.00%] [G loss: 0.479719]\n",
      "epoch:4 step:4590 [D loss: 0.538261, acc.: 73.44%] [G loss: 0.458820]\n",
      "epoch:4 step:4591 [D loss: 0.511032, acc.: 77.34%] [G loss: 0.499796]\n",
      "epoch:4 step:4592 [D loss: 0.559350, acc.: 74.22%] [G loss: 0.503257]\n",
      "epoch:4 step:4593 [D loss: 0.547686, acc.: 71.88%] [G loss: 0.553520]\n",
      "epoch:4 step:4594 [D loss: 0.558129, acc.: 72.66%] [G loss: 0.507114]\n",
      "epoch:4 step:4595 [D loss: 0.557666, acc.: 71.09%] [G loss: 0.413783]\n",
      "epoch:4 step:4596 [D loss: 0.505464, acc.: 75.78%] [G loss: 0.424879]\n",
      "epoch:4 step:4597 [D loss: 0.525031, acc.: 73.44%] [G loss: 0.437782]\n",
      "epoch:4 step:4598 [D loss: 0.553034, acc.: 68.75%] [G loss: 0.421442]\n",
      "epoch:4 step:4599 [D loss: 0.530668, acc.: 78.12%] [G loss: 0.450588]\n",
      "epoch:4 step:4600 [D loss: 0.461684, acc.: 77.34%] [G loss: 0.524290]\n",
      "##############\n",
      "[3.36453108 1.99047755 7.21545748 5.08568189 4.27556426 5.84673949\n",
      " 5.49297426 5.08359722 5.33973536 3.97013854]\n",
      "##########\n",
      "epoch:4 step:4601 [D loss: 0.509213, acc.: 74.22%] [G loss: 0.532398]\n",
      "epoch:4 step:4602 [D loss: 0.457252, acc.: 82.81%] [G loss: 0.602008]\n",
      "epoch:4 step:4603 [D loss: 0.555186, acc.: 71.09%] [G loss: 0.563694]\n",
      "epoch:4 step:4604 [D loss: 0.647133, acc.: 58.59%] [G loss: 0.471356]\n",
      "epoch:4 step:4605 [D loss: 0.495520, acc.: 75.78%] [G loss: 0.661612]\n",
      "epoch:4 step:4606 [D loss: 0.661887, acc.: 56.25%] [G loss: 0.530076]\n",
      "epoch:4 step:4607 [D loss: 0.564677, acc.: 70.31%] [G loss: 0.499150]\n",
      "epoch:4 step:4608 [D loss: 0.461688, acc.: 78.12%] [G loss: 0.604179]\n",
      "epoch:4 step:4609 [D loss: 0.621508, acc.: 64.06%] [G loss: 0.510393]\n",
      "epoch:4 step:4610 [D loss: 0.560084, acc.: 73.44%] [G loss: 0.412969]\n",
      "epoch:4 step:4611 [D loss: 0.513218, acc.: 72.66%] [G loss: 0.557495]\n",
      "epoch:4 step:4612 [D loss: 0.549086, acc.: 71.88%] [G loss: 0.531011]\n",
      "epoch:4 step:4613 [D loss: 0.552037, acc.: 68.75%] [G loss: 0.604816]\n",
      "epoch:4 step:4614 [D loss: 0.524010, acc.: 71.09%] [G loss: 0.594638]\n",
      "epoch:4 step:4615 [D loss: 0.619698, acc.: 67.97%] [G loss: 0.474517]\n",
      "epoch:4 step:4616 [D loss: 0.540270, acc.: 74.22%] [G loss: 0.479425]\n",
      "epoch:4 step:4617 [D loss: 0.533565, acc.: 75.78%] [G loss: 0.447779]\n",
      "epoch:4 step:4618 [D loss: 0.474784, acc.: 77.34%] [G loss: 0.499474]\n",
      "epoch:4 step:4619 [D loss: 0.495024, acc.: 82.03%] [G loss: 0.633478]\n",
      "epoch:4 step:4620 [D loss: 0.540110, acc.: 73.44%] [G loss: 0.462127]\n",
      "epoch:4 step:4621 [D loss: 0.556880, acc.: 70.31%] [G loss: 0.576424]\n",
      "epoch:4 step:4622 [D loss: 0.550598, acc.: 72.66%] [G loss: 0.474776]\n",
      "epoch:4 step:4623 [D loss: 0.498035, acc.: 75.00%] [G loss: 0.513928]\n",
      "epoch:4 step:4624 [D loss: 0.522097, acc.: 75.78%] [G loss: 0.478309]\n",
      "epoch:4 step:4625 [D loss: 0.525895, acc.: 72.66%] [G loss: 0.506773]\n",
      "epoch:4 step:4626 [D loss: 0.518961, acc.: 77.34%] [G loss: 0.596175]\n",
      "epoch:4 step:4627 [D loss: 0.548196, acc.: 71.88%] [G loss: 0.515474]\n",
      "epoch:4 step:4628 [D loss: 0.595312, acc.: 65.62%] [G loss: 0.406836]\n",
      "epoch:4 step:4629 [D loss: 0.576600, acc.: 64.06%] [G loss: 0.380129]\n",
      "epoch:4 step:4630 [D loss: 0.569391, acc.: 68.75%] [G loss: 0.451251]\n",
      "epoch:4 step:4631 [D loss: 0.530259, acc.: 73.44%] [G loss: 0.536463]\n",
      "epoch:4 step:4632 [D loss: 0.469790, acc.: 75.00%] [G loss: 0.569991]\n",
      "epoch:4 step:4633 [D loss: 0.474947, acc.: 78.91%] [G loss: 0.694187]\n",
      "epoch:4 step:4634 [D loss: 0.495880, acc.: 78.12%] [G loss: 0.615397]\n",
      "epoch:4 step:4635 [D loss: 0.509472, acc.: 76.56%] [G loss: 0.749951]\n",
      "epoch:4 step:4636 [D loss: 0.526783, acc.: 71.09%] [G loss: 0.650107]\n",
      "epoch:4 step:4637 [D loss: 0.545974, acc.: 69.53%] [G loss: 0.579487]\n",
      "epoch:4 step:4638 [D loss: 0.444129, acc.: 78.12%] [G loss: 0.557261]\n",
      "epoch:4 step:4639 [D loss: 0.576847, acc.: 63.28%] [G loss: 0.575119]\n",
      "epoch:4 step:4640 [D loss: 0.624868, acc.: 64.06%] [G loss: 0.489462]\n",
      "epoch:4 step:4641 [D loss: 0.534273, acc.: 75.78%] [G loss: 0.565746]\n",
      "epoch:4 step:4642 [D loss: 0.502059, acc.: 75.00%] [G loss: 0.483489]\n",
      "epoch:4 step:4643 [D loss: 0.495003, acc.: 75.78%] [G loss: 0.671039]\n",
      "epoch:4 step:4644 [D loss: 0.552122, acc.: 71.09%] [G loss: 0.618176]\n",
      "epoch:4 step:4645 [D loss: 0.490126, acc.: 76.56%] [G loss: 0.585822]\n",
      "epoch:4 step:4646 [D loss: 0.463771, acc.: 79.69%] [G loss: 0.670531]\n",
      "epoch:4 step:4647 [D loss: 0.503655, acc.: 76.56%] [G loss: 0.630862]\n",
      "epoch:4 step:4648 [D loss: 0.539396, acc.: 71.88%] [G loss: 0.599744]\n",
      "epoch:4 step:4649 [D loss: 0.492817, acc.: 76.56%] [G loss: 0.594304]\n",
      "epoch:4 step:4650 [D loss: 0.572876, acc.: 66.41%] [G loss: 0.504110]\n",
      "epoch:4 step:4651 [D loss: 0.513124, acc.: 76.56%] [G loss: 0.578256]\n",
      "epoch:4 step:4652 [D loss: 0.529670, acc.: 73.44%] [G loss: 0.632752]\n",
      "epoch:4 step:4653 [D loss: 0.533513, acc.: 71.88%] [G loss: 0.589339]\n",
      "epoch:4 step:4654 [D loss: 0.496231, acc.: 80.47%] [G loss: 0.677083]\n",
      "epoch:4 step:4655 [D loss: 0.582062, acc.: 62.50%] [G loss: 0.548271]\n",
      "epoch:4 step:4656 [D loss: 0.509131, acc.: 72.66%] [G loss: 0.629593]\n",
      "epoch:4 step:4657 [D loss: 0.503531, acc.: 78.12%] [G loss: 0.760779]\n",
      "epoch:4 step:4658 [D loss: 0.501992, acc.: 77.34%] [G loss: 0.596310]\n",
      "epoch:4 step:4659 [D loss: 0.499909, acc.: 76.56%] [G loss: 0.555541]\n",
      "epoch:4 step:4660 [D loss: 0.467097, acc.: 76.56%] [G loss: 0.816163]\n",
      "epoch:4 step:4661 [D loss: 0.580305, acc.: 69.53%] [G loss: 0.589749]\n",
      "epoch:4 step:4662 [D loss: 0.482632, acc.: 80.47%] [G loss: 0.552647]\n",
      "epoch:4 step:4663 [D loss: 0.600950, acc.: 72.66%] [G loss: 0.619120]\n",
      "epoch:4 step:4664 [D loss: 0.521629, acc.: 71.09%] [G loss: 0.625586]\n",
      "epoch:4 step:4665 [D loss: 0.580708, acc.: 68.75%] [G loss: 0.534161]\n",
      "epoch:4 step:4666 [D loss: 0.466073, acc.: 79.69%] [G loss: 0.570657]\n",
      "epoch:4 step:4667 [D loss: 0.512752, acc.: 74.22%] [G loss: 0.602400]\n",
      "epoch:4 step:4668 [D loss: 0.646336, acc.: 64.84%] [G loss: 0.587859]\n",
      "epoch:4 step:4669 [D loss: 0.495750, acc.: 79.69%] [G loss: 0.666040]\n",
      "epoch:4 step:4670 [D loss: 0.576073, acc.: 71.88%] [G loss: 0.507331]\n",
      "epoch:4 step:4671 [D loss: 0.463547, acc.: 78.91%] [G loss: 0.578917]\n",
      "epoch:4 step:4672 [D loss: 0.501840, acc.: 75.00%] [G loss: 0.690423]\n",
      "epoch:4 step:4673 [D loss: 0.421216, acc.: 81.25%] [G loss: 0.797211]\n",
      "epoch:4 step:4674 [D loss: 0.474771, acc.: 78.91%] [G loss: 0.781410]\n",
      "epoch:4 step:4675 [D loss: 0.474740, acc.: 76.56%] [G loss: 1.046716]\n",
      "epoch:4 step:4676 [D loss: 0.842879, acc.: 59.38%] [G loss: 0.687044]\n",
      "epoch:4 step:4677 [D loss: 0.463380, acc.: 80.47%] [G loss: 0.814874]\n",
      "epoch:4 step:4678 [D loss: 0.428105, acc.: 81.25%] [G loss: 1.068978]\n",
      "epoch:4 step:4679 [D loss: 0.556582, acc.: 70.31%] [G loss: 0.616596]\n",
      "epoch:4 step:4680 [D loss: 0.581621, acc.: 66.41%] [G loss: 0.595238]\n",
      "epoch:4 step:4681 [D loss: 0.496620, acc.: 76.56%] [G loss: 0.634798]\n",
      "epoch:4 step:4682 [D loss: 0.495471, acc.: 78.12%] [G loss: 0.832541]\n",
      "epoch:4 step:4683 [D loss: 0.537694, acc.: 67.97%] [G loss: 0.763112]\n",
      "epoch:4 step:4684 [D loss: 0.413921, acc.: 80.47%] [G loss: 0.789730]\n",
      "epoch:4 step:4685 [D loss: 0.453888, acc.: 82.81%] [G loss: 1.019277]\n",
      "epoch:5 step:4686 [D loss: 0.563302, acc.: 72.66%] [G loss: 0.928619]\n",
      "epoch:5 step:4687 [D loss: 0.503786, acc.: 74.22%] [G loss: 0.706405]\n",
      "epoch:5 step:4688 [D loss: 0.615262, acc.: 71.88%] [G loss: 0.622872]\n",
      "epoch:5 step:4689 [D loss: 0.489530, acc.: 79.69%] [G loss: 0.671456]\n",
      "epoch:5 step:4690 [D loss: 0.532966, acc.: 71.88%] [G loss: 0.552535]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:5 step:4691 [D loss: 0.476337, acc.: 76.56%] [G loss: 0.562424]\n",
      "epoch:5 step:4692 [D loss: 0.509226, acc.: 78.12%] [G loss: 0.711469]\n",
      "epoch:5 step:4693 [D loss: 0.579054, acc.: 66.41%] [G loss: 0.519894]\n",
      "epoch:5 step:4694 [D loss: 0.510431, acc.: 77.34%] [G loss: 0.599848]\n",
      "epoch:5 step:4695 [D loss: 0.547993, acc.: 71.88%] [G loss: 0.586438]\n",
      "epoch:5 step:4696 [D loss: 0.458438, acc.: 82.81%] [G loss: 0.608548]\n",
      "epoch:5 step:4697 [D loss: 0.564703, acc.: 70.31%] [G loss: 0.549586]\n",
      "epoch:5 step:4698 [D loss: 0.567519, acc.: 67.19%] [G loss: 0.392126]\n",
      "epoch:5 step:4699 [D loss: 0.572040, acc.: 67.97%] [G loss: 0.440175]\n",
      "epoch:5 step:4700 [D loss: 0.545305, acc.: 71.09%] [G loss: 0.495990]\n",
      "epoch:5 step:4701 [D loss: 0.498359, acc.: 76.56%] [G loss: 0.552563]\n",
      "epoch:5 step:4702 [D loss: 0.572117, acc.: 70.31%] [G loss: 0.581387]\n",
      "epoch:5 step:4703 [D loss: 0.635358, acc.: 65.62%] [G loss: 0.565021]\n",
      "epoch:5 step:4704 [D loss: 0.584959, acc.: 67.97%] [G loss: 0.437730]\n",
      "epoch:5 step:4705 [D loss: 0.586485, acc.: 66.41%] [G loss: 0.490150]\n",
      "epoch:5 step:4706 [D loss: 0.571477, acc.: 67.97%] [G loss: 0.558998]\n",
      "epoch:5 step:4707 [D loss: 0.475912, acc.: 81.25%] [G loss: 0.591285]\n",
      "epoch:5 step:4708 [D loss: 0.520865, acc.: 74.22%] [G loss: 0.693173]\n",
      "epoch:5 step:4709 [D loss: 0.540801, acc.: 73.44%] [G loss: 0.585387]\n",
      "epoch:5 step:4710 [D loss: 0.499589, acc.: 75.00%] [G loss: 0.588577]\n",
      "epoch:5 step:4711 [D loss: 0.528703, acc.: 71.88%] [G loss: 0.547864]\n",
      "epoch:5 step:4712 [D loss: 0.463322, acc.: 78.12%] [G loss: 0.640739]\n",
      "epoch:5 step:4713 [D loss: 0.537082, acc.: 71.88%] [G loss: 0.546069]\n",
      "epoch:5 step:4714 [D loss: 0.459228, acc.: 81.25%] [G loss: 0.614894]\n",
      "epoch:5 step:4715 [D loss: 0.507930, acc.: 80.47%] [G loss: 0.511773]\n",
      "epoch:5 step:4716 [D loss: 0.545333, acc.: 67.19%] [G loss: 0.471849]\n",
      "epoch:5 step:4717 [D loss: 0.487796, acc.: 77.34%] [G loss: 0.649273]\n",
      "epoch:5 step:4718 [D loss: 0.512495, acc.: 74.22%] [G loss: 0.593201]\n",
      "epoch:5 step:4719 [D loss: 0.468301, acc.: 78.12%] [G loss: 0.765666]\n",
      "epoch:5 step:4720 [D loss: 0.585634, acc.: 67.19%] [G loss: 0.633796]\n",
      "epoch:5 step:4721 [D loss: 0.475901, acc.: 77.34%] [G loss: 0.765826]\n",
      "epoch:5 step:4722 [D loss: 0.495852, acc.: 79.69%] [G loss: 0.612576]\n",
      "epoch:5 step:4723 [D loss: 0.658255, acc.: 64.06%] [G loss: 0.563730]\n",
      "epoch:5 step:4724 [D loss: 0.476948, acc.: 83.59%] [G loss: 0.615163]\n",
      "epoch:5 step:4725 [D loss: 0.460044, acc.: 80.47%] [G loss: 0.638299]\n",
      "epoch:5 step:4726 [D loss: 0.533114, acc.: 72.66%] [G loss: 0.660298]\n",
      "epoch:5 step:4727 [D loss: 0.539145, acc.: 73.44%] [G loss: 0.595544]\n",
      "epoch:5 step:4728 [D loss: 0.476251, acc.: 78.12%] [G loss: 0.659678]\n",
      "epoch:5 step:4729 [D loss: 0.585620, acc.: 69.53%] [G loss: 0.461847]\n",
      "epoch:5 step:4730 [D loss: 0.480543, acc.: 74.22%] [G loss: 0.612172]\n",
      "epoch:5 step:4731 [D loss: 0.475504, acc.: 78.91%] [G loss: 0.550256]\n",
      "epoch:5 step:4732 [D loss: 0.472857, acc.: 78.91%] [G loss: 0.629854]\n",
      "epoch:5 step:4733 [D loss: 0.564135, acc.: 70.31%] [G loss: 0.460037]\n",
      "epoch:5 step:4734 [D loss: 0.500487, acc.: 75.00%] [G loss: 0.605457]\n",
      "epoch:5 step:4735 [D loss: 0.552457, acc.: 72.66%] [G loss: 0.531033]\n",
      "epoch:5 step:4736 [D loss: 0.531947, acc.: 75.00%] [G loss: 0.569503]\n",
      "epoch:5 step:4737 [D loss: 0.483900, acc.: 78.12%] [G loss: 0.594504]\n",
      "epoch:5 step:4738 [D loss: 0.547183, acc.: 76.56%] [G loss: 0.658525]\n",
      "epoch:5 step:4739 [D loss: 0.494294, acc.: 74.22%] [G loss: 0.706911]\n",
      "epoch:5 step:4740 [D loss: 0.535181, acc.: 69.53%] [G loss: 0.684645]\n",
      "epoch:5 step:4741 [D loss: 0.480397, acc.: 75.78%] [G loss: 0.684573]\n",
      "epoch:5 step:4742 [D loss: 0.507826, acc.: 76.56%] [G loss: 0.533623]\n",
      "epoch:5 step:4743 [D loss: 0.565464, acc.: 69.53%] [G loss: 0.507153]\n",
      "epoch:5 step:4744 [D loss: 0.543925, acc.: 66.41%] [G loss: 0.547152]\n",
      "epoch:5 step:4745 [D loss: 0.520034, acc.: 74.22%] [G loss: 0.663881]\n",
      "epoch:5 step:4746 [D loss: 0.494649, acc.: 73.44%] [G loss: 0.650164]\n",
      "epoch:5 step:4747 [D loss: 0.538924, acc.: 74.22%] [G loss: 0.550809]\n",
      "epoch:5 step:4748 [D loss: 0.557429, acc.: 68.75%] [G loss: 0.426332]\n",
      "epoch:5 step:4749 [D loss: 0.552383, acc.: 70.31%] [G loss: 0.388043]\n",
      "epoch:5 step:4750 [D loss: 0.463629, acc.: 81.25%] [G loss: 0.594813]\n",
      "epoch:5 step:4751 [D loss: 0.525227, acc.: 75.00%] [G loss: 0.444688]\n",
      "epoch:5 step:4752 [D loss: 0.555575, acc.: 72.66%] [G loss: 0.408275]\n",
      "epoch:5 step:4753 [D loss: 0.567430, acc.: 70.31%] [G loss: 0.518711]\n",
      "epoch:5 step:4754 [D loss: 0.554412, acc.: 71.88%] [G loss: 0.442136]\n",
      "epoch:5 step:4755 [D loss: 0.477915, acc.: 75.78%] [G loss: 0.583024]\n",
      "epoch:5 step:4756 [D loss: 0.521270, acc.: 71.88%] [G loss: 0.531525]\n",
      "epoch:5 step:4757 [D loss: 0.484589, acc.: 78.12%] [G loss: 0.587296]\n",
      "epoch:5 step:4758 [D loss: 0.514088, acc.: 71.09%] [G loss: 0.456755]\n",
      "epoch:5 step:4759 [D loss: 0.445741, acc.: 82.81%] [G loss: 0.675969]\n",
      "epoch:5 step:4760 [D loss: 0.514061, acc.: 72.66%] [G loss: 0.544062]\n",
      "epoch:5 step:4761 [D loss: 0.499680, acc.: 75.00%] [G loss: 0.700112]\n",
      "epoch:5 step:4762 [D loss: 0.436840, acc.: 82.03%] [G loss: 0.799514]\n",
      "epoch:5 step:4763 [D loss: 0.642533, acc.: 68.75%] [G loss: 0.559373]\n",
      "epoch:5 step:4764 [D loss: 0.558778, acc.: 73.44%] [G loss: 0.454135]\n",
      "epoch:5 step:4765 [D loss: 0.502111, acc.: 78.12%] [G loss: 0.507082]\n",
      "epoch:5 step:4766 [D loss: 0.597356, acc.: 67.19%] [G loss: 0.556419]\n",
      "epoch:5 step:4767 [D loss: 0.480751, acc.: 77.34%] [G loss: 0.544919]\n",
      "epoch:5 step:4768 [D loss: 0.513117, acc.: 75.78%] [G loss: 0.508656]\n",
      "epoch:5 step:4769 [D loss: 0.539026, acc.: 68.75%] [G loss: 0.530412]\n",
      "epoch:5 step:4770 [D loss: 0.519393, acc.: 70.31%] [G loss: 0.676824]\n",
      "epoch:5 step:4771 [D loss: 0.546460, acc.: 74.22%] [G loss: 0.460884]\n",
      "epoch:5 step:4772 [D loss: 0.530073, acc.: 73.44%] [G loss: 0.552923]\n",
      "epoch:5 step:4773 [D loss: 0.539834, acc.: 75.78%] [G loss: 0.525141]\n",
      "epoch:5 step:4774 [D loss: 0.470245, acc.: 78.91%] [G loss: 0.687967]\n",
      "epoch:5 step:4775 [D loss: 0.486603, acc.: 73.44%] [G loss: 0.657606]\n",
      "epoch:5 step:4776 [D loss: 0.537250, acc.: 72.66%] [G loss: 0.658832]\n",
      "epoch:5 step:4777 [D loss: 0.513245, acc.: 75.78%] [G loss: 0.576747]\n",
      "epoch:5 step:4778 [D loss: 0.539234, acc.: 73.44%] [G loss: 0.721622]\n",
      "epoch:5 step:4779 [D loss: 0.576025, acc.: 69.53%] [G loss: 0.524310]\n",
      "epoch:5 step:4780 [D loss: 0.566206, acc.: 64.06%] [G loss: 0.491099]\n",
      "epoch:5 step:4781 [D loss: 0.426045, acc.: 82.03%] [G loss: 0.693142]\n",
      "epoch:5 step:4782 [D loss: 0.528879, acc.: 75.78%] [G loss: 0.691062]\n",
      "epoch:5 step:4783 [D loss: 0.560159, acc.: 72.66%] [G loss: 0.648616]\n",
      "epoch:5 step:4784 [D loss: 0.538753, acc.: 71.09%] [G loss: 0.545943]\n",
      "epoch:5 step:4785 [D loss: 0.447781, acc.: 79.69%] [G loss: 0.694593]\n",
      "epoch:5 step:4786 [D loss: 0.516575, acc.: 77.34%] [G loss: 0.592071]\n",
      "epoch:5 step:4787 [D loss: 0.568598, acc.: 71.88%] [G loss: 0.540016]\n",
      "epoch:5 step:4788 [D loss: 0.517756, acc.: 75.78%] [G loss: 0.448690]\n",
      "epoch:5 step:4789 [D loss: 0.548065, acc.: 68.75%] [G loss: 0.545432]\n",
      "epoch:5 step:4790 [D loss: 0.598388, acc.: 69.53%] [G loss: 0.504401]\n",
      "epoch:5 step:4791 [D loss: 0.553960, acc.: 70.31%] [G loss: 0.607921]\n",
      "epoch:5 step:4792 [D loss: 0.602509, acc.: 64.06%] [G loss: 0.547454]\n",
      "epoch:5 step:4793 [D loss: 0.579307, acc.: 66.41%] [G loss: 0.552848]\n",
      "epoch:5 step:4794 [D loss: 0.561625, acc.: 71.09%] [G loss: 0.511656]\n",
      "epoch:5 step:4795 [D loss: 0.534277, acc.: 73.44%] [G loss: 0.479240]\n",
      "epoch:5 step:4796 [D loss: 0.587513, acc.: 69.53%] [G loss: 0.414576]\n",
      "epoch:5 step:4797 [D loss: 0.528769, acc.: 71.09%] [G loss: 0.502695]\n",
      "epoch:5 step:4798 [D loss: 0.620897, acc.: 61.72%] [G loss: 0.456168]\n",
      "epoch:5 step:4799 [D loss: 0.575050, acc.: 61.72%] [G loss: 0.537501]\n",
      "epoch:5 step:4800 [D loss: 0.563607, acc.: 69.53%] [G loss: 0.523501]\n",
      "##############\n",
      "[3.37909512 1.95701331 7.01916467 5.31327296 4.30219671 6.18212446\n",
      " 5.37688687 5.03594502 5.15195167 3.84756841]\n",
      "##########\n",
      "epoch:5 step:4801 [D loss: 0.541440, acc.: 74.22%] [G loss: 0.520084]\n",
      "epoch:5 step:4802 [D loss: 0.528296, acc.: 74.22%] [G loss: 0.659139]\n",
      "epoch:5 step:4803 [D loss: 0.632755, acc.: 69.53%] [G loss: 0.614609]\n",
      "epoch:5 step:4804 [D loss: 0.426585, acc.: 87.50%] [G loss: 0.765308]\n",
      "epoch:5 step:4805 [D loss: 0.571448, acc.: 73.44%] [G loss: 0.582718]\n",
      "epoch:5 step:4806 [D loss: 0.547051, acc.: 78.12%] [G loss: 0.543302]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:5 step:4807 [D loss: 0.540522, acc.: 75.78%] [G loss: 0.620485]\n",
      "epoch:5 step:4808 [D loss: 0.506637, acc.: 75.78%] [G loss: 0.532598]\n",
      "epoch:5 step:4809 [D loss: 0.619322, acc.: 63.28%] [G loss: 0.436042]\n",
      "epoch:5 step:4810 [D loss: 0.581854, acc.: 66.41%] [G loss: 0.420290]\n",
      "epoch:5 step:4811 [D loss: 0.514030, acc.: 76.56%] [G loss: 0.513649]\n",
      "epoch:5 step:4812 [D loss: 0.521491, acc.: 75.00%] [G loss: 0.456979]\n",
      "epoch:5 step:4813 [D loss: 0.479876, acc.: 77.34%] [G loss: 0.469584]\n",
      "epoch:5 step:4814 [D loss: 0.605296, acc.: 68.75%] [G loss: 0.441137]\n",
      "epoch:5 step:4815 [D loss: 0.493209, acc.: 72.66%] [G loss: 0.601751]\n",
      "epoch:5 step:4816 [D loss: 0.534163, acc.: 73.44%] [G loss: 0.657153]\n",
      "epoch:5 step:4817 [D loss: 0.560689, acc.: 68.75%] [G loss: 0.546013]\n",
      "epoch:5 step:4818 [D loss: 0.596360, acc.: 74.22%] [G loss: 0.517106]\n",
      "epoch:5 step:4819 [D loss: 0.499673, acc.: 74.22%] [G loss: 0.496912]\n",
      "epoch:5 step:4820 [D loss: 0.508519, acc.: 73.44%] [G loss: 0.563320]\n",
      "epoch:5 step:4821 [D loss: 0.473211, acc.: 81.25%] [G loss: 0.562524]\n",
      "epoch:5 step:4822 [D loss: 0.600862, acc.: 62.50%] [G loss: 0.570324]\n",
      "epoch:5 step:4823 [D loss: 0.530755, acc.: 71.09%] [G loss: 0.555094]\n",
      "epoch:5 step:4824 [D loss: 0.624034, acc.: 63.28%] [G loss: 0.460779]\n",
      "epoch:5 step:4825 [D loss: 0.553878, acc.: 67.97%] [G loss: 0.571241]\n",
      "epoch:5 step:4826 [D loss: 0.476123, acc.: 74.22%] [G loss: 0.692519]\n",
      "epoch:5 step:4827 [D loss: 0.507448, acc.: 76.56%] [G loss: 0.663314]\n",
      "epoch:5 step:4828 [D loss: 0.565908, acc.: 69.53%] [G loss: 0.566884]\n",
      "epoch:5 step:4829 [D loss: 0.522801, acc.: 71.09%] [G loss: 0.475139]\n",
      "epoch:5 step:4830 [D loss: 0.533763, acc.: 78.12%] [G loss: 0.523248]\n",
      "epoch:5 step:4831 [D loss: 0.483092, acc.: 78.12%] [G loss: 0.504206]\n",
      "epoch:5 step:4832 [D loss: 0.553031, acc.: 75.00%] [G loss: 0.584321]\n",
      "epoch:5 step:4833 [D loss: 0.538069, acc.: 71.09%] [G loss: 0.532482]\n",
      "epoch:5 step:4834 [D loss: 0.465619, acc.: 81.25%] [G loss: 0.546582]\n",
      "epoch:5 step:4835 [D loss: 0.589831, acc.: 71.88%] [G loss: 0.577857]\n",
      "epoch:5 step:4836 [D loss: 0.519351, acc.: 72.66%] [G loss: 0.532665]\n",
      "epoch:5 step:4837 [D loss: 0.490035, acc.: 74.22%] [G loss: 0.753669]\n",
      "epoch:5 step:4838 [D loss: 0.553927, acc.: 71.09%] [G loss: 0.497793]\n",
      "epoch:5 step:4839 [D loss: 0.509384, acc.: 71.88%] [G loss: 0.674353]\n",
      "epoch:5 step:4840 [D loss: 0.471313, acc.: 78.12%] [G loss: 0.605856]\n",
      "epoch:5 step:4841 [D loss: 0.518069, acc.: 71.09%] [G loss: 0.682568]\n",
      "epoch:5 step:4842 [D loss: 0.560210, acc.: 69.53%] [G loss: 0.564607]\n",
      "epoch:5 step:4843 [D loss: 0.548432, acc.: 75.78%] [G loss: 0.426821]\n",
      "epoch:5 step:4844 [D loss: 0.508558, acc.: 71.88%] [G loss: 0.531671]\n",
      "epoch:5 step:4845 [D loss: 0.604982, acc.: 67.97%] [G loss: 0.578950]\n",
      "epoch:5 step:4846 [D loss: 0.540122, acc.: 74.22%] [G loss: 0.548159]\n",
      "epoch:5 step:4847 [D loss: 0.452357, acc.: 79.69%] [G loss: 0.705190]\n",
      "epoch:5 step:4848 [D loss: 0.460506, acc.: 79.69%] [G loss: 0.558306]\n",
      "epoch:5 step:4849 [D loss: 0.567792, acc.: 68.75%] [G loss: 0.469278]\n",
      "epoch:5 step:4850 [D loss: 0.516672, acc.: 74.22%] [G loss: 0.703151]\n",
      "epoch:5 step:4851 [D loss: 0.502755, acc.: 75.00%] [G loss: 0.559536]\n",
      "epoch:5 step:4852 [D loss: 0.553668, acc.: 65.62%] [G loss: 0.570958]\n",
      "epoch:5 step:4853 [D loss: 0.545763, acc.: 75.00%] [G loss: 0.480601]\n",
      "epoch:5 step:4854 [D loss: 0.585859, acc.: 61.72%] [G loss: 0.407532]\n",
      "epoch:5 step:4855 [D loss: 0.515039, acc.: 73.44%] [G loss: 0.548937]\n",
      "epoch:5 step:4856 [D loss: 0.465796, acc.: 79.69%] [G loss: 0.457682]\n",
      "epoch:5 step:4857 [D loss: 0.531780, acc.: 74.22%] [G loss: 0.545526]\n",
      "epoch:5 step:4858 [D loss: 0.502939, acc.: 76.56%] [G loss: 0.554778]\n",
      "epoch:5 step:4859 [D loss: 0.555890, acc.: 68.75%] [G loss: 0.598442]\n",
      "epoch:5 step:4860 [D loss: 0.544546, acc.: 69.53%] [G loss: 0.567043]\n",
      "epoch:5 step:4861 [D loss: 0.526037, acc.: 71.09%] [G loss: 0.535290]\n",
      "epoch:5 step:4862 [D loss: 0.481233, acc.: 78.91%] [G loss: 0.579365]\n",
      "epoch:5 step:4863 [D loss: 0.490265, acc.: 80.47%] [G loss: 0.676685]\n",
      "epoch:5 step:4864 [D loss: 0.542116, acc.: 73.44%] [G loss: 0.551853]\n",
      "epoch:5 step:4865 [D loss: 0.575487, acc.: 65.62%] [G loss: 0.515025]\n",
      "epoch:5 step:4866 [D loss: 0.539251, acc.: 71.88%] [G loss: 0.458045]\n",
      "epoch:5 step:4867 [D loss: 0.580462, acc.: 68.75%] [G loss: 0.643745]\n",
      "epoch:5 step:4868 [D loss: 0.562419, acc.: 68.75%] [G loss: 0.619065]\n",
      "epoch:5 step:4869 [D loss: 0.539687, acc.: 74.22%] [G loss: 0.601580]\n",
      "epoch:5 step:4870 [D loss: 0.513396, acc.: 74.22%] [G loss: 0.618734]\n",
      "epoch:5 step:4871 [D loss: 0.526545, acc.: 75.00%] [G loss: 0.570935]\n",
      "epoch:5 step:4872 [D loss: 0.604732, acc.: 69.53%] [G loss: 0.484347]\n",
      "epoch:5 step:4873 [D loss: 0.546217, acc.: 65.62%] [G loss: 0.506859]\n",
      "epoch:5 step:4874 [D loss: 0.533703, acc.: 72.66%] [G loss: 0.507530]\n",
      "epoch:5 step:4875 [D loss: 0.482151, acc.: 74.22%] [G loss: 0.598476]\n",
      "epoch:5 step:4876 [D loss: 0.524134, acc.: 71.88%] [G loss: 0.559892]\n",
      "epoch:5 step:4877 [D loss: 0.574319, acc.: 69.53%] [G loss: 0.519154]\n",
      "epoch:5 step:4878 [D loss: 0.545016, acc.: 70.31%] [G loss: 0.602903]\n",
      "epoch:5 step:4879 [D loss: 0.455490, acc.: 79.69%] [G loss: 0.711282]\n",
      "epoch:5 step:4880 [D loss: 0.570018, acc.: 68.75%] [G loss: 0.579565]\n",
      "epoch:5 step:4881 [D loss: 0.591998, acc.: 65.62%] [G loss: 0.512437]\n",
      "epoch:5 step:4882 [D loss: 0.527292, acc.: 77.34%] [G loss: 0.636223]\n",
      "epoch:5 step:4883 [D loss: 0.486952, acc.: 78.12%] [G loss: 0.672013]\n",
      "epoch:5 step:4884 [D loss: 0.532424, acc.: 70.31%] [G loss: 0.591246]\n",
      "epoch:5 step:4885 [D loss: 0.628110, acc.: 60.94%] [G loss: 0.445908]\n",
      "epoch:5 step:4886 [D loss: 0.546369, acc.: 70.31%] [G loss: 0.556464]\n",
      "epoch:5 step:4887 [D loss: 0.487412, acc.: 78.12%] [G loss: 0.589301]\n",
      "epoch:5 step:4888 [D loss: 0.600257, acc.: 68.75%] [G loss: 0.390341]\n",
      "epoch:5 step:4889 [D loss: 0.568674, acc.: 67.19%] [G loss: 0.354530]\n",
      "epoch:5 step:4890 [D loss: 0.535861, acc.: 71.09%] [G loss: 0.590276]\n",
      "epoch:5 step:4891 [D loss: 0.476840, acc.: 72.66%] [G loss: 0.564584]\n",
      "epoch:5 step:4892 [D loss: 0.426386, acc.: 81.25%] [G loss: 0.703633]\n",
      "epoch:5 step:4893 [D loss: 0.436340, acc.: 82.03%] [G loss: 0.619360]\n",
      "epoch:5 step:4894 [D loss: 0.505215, acc.: 75.78%] [G loss: 0.588942]\n",
      "epoch:5 step:4895 [D loss: 0.558470, acc.: 70.31%] [G loss: 0.558519]\n",
      "epoch:5 step:4896 [D loss: 0.554761, acc.: 74.22%] [G loss: 0.507841]\n",
      "epoch:5 step:4897 [D loss: 0.490857, acc.: 77.34%] [G loss: 0.489880]\n",
      "epoch:5 step:4898 [D loss: 0.483310, acc.: 71.88%] [G loss: 0.507761]\n",
      "epoch:5 step:4899 [D loss: 0.648313, acc.: 59.38%] [G loss: 0.398334]\n",
      "epoch:5 step:4900 [D loss: 0.569928, acc.: 67.97%] [G loss: 0.443000]\n",
      "epoch:5 step:4901 [D loss: 0.555612, acc.: 75.00%] [G loss: 0.581578]\n",
      "epoch:5 step:4902 [D loss: 0.487591, acc.: 75.78%] [G loss: 0.560567]\n",
      "epoch:5 step:4903 [D loss: 0.520046, acc.: 78.91%] [G loss: 0.576477]\n",
      "epoch:5 step:4904 [D loss: 0.512219, acc.: 82.03%] [G loss: 0.544142]\n",
      "epoch:5 step:4905 [D loss: 0.605188, acc.: 64.06%] [G loss: 0.461597]\n",
      "epoch:5 step:4906 [D loss: 0.511654, acc.: 76.56%] [G loss: 0.699395]\n",
      "epoch:5 step:4907 [D loss: 0.419897, acc.: 84.38%] [G loss: 0.881841]\n",
      "epoch:5 step:4908 [D loss: 0.483948, acc.: 79.69%] [G loss: 0.746417]\n",
      "epoch:5 step:4909 [D loss: 0.620967, acc.: 60.94%] [G loss: 0.552865]\n",
      "epoch:5 step:4910 [D loss: 0.563905, acc.: 74.22%] [G loss: 0.428160]\n",
      "epoch:5 step:4911 [D loss: 0.596043, acc.: 67.19%] [G loss: 0.429404]\n",
      "epoch:5 step:4912 [D loss: 0.506304, acc.: 75.78%] [G loss: 0.524399]\n",
      "epoch:5 step:4913 [D loss: 0.569815, acc.: 69.53%] [G loss: 0.491167]\n",
      "epoch:5 step:4914 [D loss: 0.499118, acc.: 78.91%] [G loss: 0.421095]\n",
      "epoch:5 step:4915 [D loss: 0.490690, acc.: 70.31%] [G loss: 0.710233]\n",
      "epoch:5 step:4916 [D loss: 0.474778, acc.: 78.91%] [G loss: 0.802932]\n",
      "epoch:5 step:4917 [D loss: 0.423378, acc.: 82.03%] [G loss: 0.816504]\n",
      "epoch:5 step:4918 [D loss: 0.519121, acc.: 76.56%] [G loss: 0.728853]\n",
      "epoch:5 step:4919 [D loss: 0.536039, acc.: 72.66%] [G loss: 0.667730]\n",
      "epoch:5 step:4920 [D loss: 0.509031, acc.: 73.44%] [G loss: 0.758671]\n",
      "epoch:5 step:4921 [D loss: 0.538296, acc.: 71.88%] [G loss: 0.476703]\n",
      "epoch:5 step:4922 [D loss: 0.541871, acc.: 71.09%] [G loss: 0.692399]\n",
      "epoch:5 step:4923 [D loss: 0.530254, acc.: 74.22%] [G loss: 0.527282]\n",
      "epoch:5 step:4924 [D loss: 0.513596, acc.: 73.44%] [G loss: 0.469396]\n",
      "epoch:5 step:4925 [D loss: 0.516870, acc.: 73.44%] [G loss: 0.507439]\n",
      "epoch:5 step:4926 [D loss: 0.565061, acc.: 73.44%] [G loss: 0.542568]\n",
      "epoch:5 step:4927 [D loss: 0.543080, acc.: 71.09%] [G loss: 0.616649]\n",
      "epoch:5 step:4928 [D loss: 0.530566, acc.: 72.66%] [G loss: 0.473339]\n",
      "epoch:5 step:4929 [D loss: 0.494847, acc.: 79.69%] [G loss: 0.701334]\n",
      "epoch:5 step:4930 [D loss: 0.526455, acc.: 74.22%] [G loss: 0.555642]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:5 step:4931 [D loss: 0.592022, acc.: 68.75%] [G loss: 0.528186]\n",
      "epoch:5 step:4932 [D loss: 0.558811, acc.: 74.22%] [G loss: 0.665172]\n",
      "epoch:5 step:4933 [D loss: 0.595999, acc.: 67.97%] [G loss: 0.629736]\n",
      "epoch:5 step:4934 [D loss: 0.566152, acc.: 74.22%] [G loss: 0.550774]\n",
      "epoch:5 step:4935 [D loss: 0.563975, acc.: 67.97%] [G loss: 0.637238]\n",
      "epoch:5 step:4936 [D loss: 0.652863, acc.: 57.81%] [G loss: 0.561893]\n",
      "epoch:5 step:4937 [D loss: 0.572230, acc.: 71.09%] [G loss: 0.598352]\n",
      "epoch:5 step:4938 [D loss: 0.511312, acc.: 75.00%] [G loss: 0.519499]\n",
      "epoch:5 step:4939 [D loss: 0.507472, acc.: 75.00%] [G loss: 0.466271]\n",
      "epoch:5 step:4940 [D loss: 0.507304, acc.: 75.78%] [G loss: 0.530056]\n",
      "epoch:5 step:4941 [D loss: 0.504281, acc.: 77.34%] [G loss: 0.444589]\n",
      "epoch:5 step:4942 [D loss: 0.554993, acc.: 67.97%] [G loss: 0.446028]\n",
      "epoch:5 step:4943 [D loss: 0.475898, acc.: 80.47%] [G loss: 0.499472]\n",
      "epoch:5 step:4944 [D loss: 0.473564, acc.: 79.69%] [G loss: 0.649873]\n",
      "epoch:5 step:4945 [D loss: 0.599464, acc.: 66.41%] [G loss: 0.540876]\n",
      "epoch:5 step:4946 [D loss: 0.518345, acc.: 75.00%] [G loss: 0.554379]\n",
      "epoch:5 step:4947 [D loss: 0.473818, acc.: 82.03%] [G loss: 0.630400]\n",
      "epoch:5 step:4948 [D loss: 0.597931, acc.: 64.84%] [G loss: 0.561837]\n",
      "epoch:5 step:4949 [D loss: 0.513733, acc.: 77.34%] [G loss: 0.616520]\n",
      "epoch:5 step:4950 [D loss: 0.611406, acc.: 67.19%] [G loss: 0.521302]\n",
      "epoch:5 step:4951 [D loss: 0.552916, acc.: 74.22%] [G loss: 0.452982]\n",
      "epoch:5 step:4952 [D loss: 0.554757, acc.: 72.66%] [G loss: 0.473094]\n",
      "epoch:5 step:4953 [D loss: 0.542179, acc.: 73.44%] [G loss: 0.567491]\n",
      "epoch:5 step:4954 [D loss: 0.558039, acc.: 69.53%] [G loss: 0.456435]\n",
      "epoch:5 step:4955 [D loss: 0.541728, acc.: 72.66%] [G loss: 0.514530]\n",
      "epoch:5 step:4956 [D loss: 0.483098, acc.: 77.34%] [G loss: 0.595212]\n",
      "epoch:5 step:4957 [D loss: 0.521547, acc.: 73.44%] [G loss: 0.557944]\n",
      "epoch:5 step:4958 [D loss: 0.582713, acc.: 67.97%] [G loss: 0.418732]\n",
      "epoch:5 step:4959 [D loss: 0.529084, acc.: 70.31%] [G loss: 0.525680]\n",
      "epoch:5 step:4960 [D loss: 0.584588, acc.: 64.84%] [G loss: 0.468424]\n",
      "epoch:5 step:4961 [D loss: 0.516483, acc.: 78.12%] [G loss: 0.502808]\n",
      "epoch:5 step:4962 [D loss: 0.629590, acc.: 62.50%] [G loss: 0.513003]\n",
      "epoch:5 step:4963 [D loss: 0.611329, acc.: 67.19%] [G loss: 0.481773]\n",
      "epoch:5 step:4964 [D loss: 0.560329, acc.: 70.31%] [G loss: 0.579004]\n",
      "epoch:5 step:4965 [D loss: 0.557776, acc.: 67.97%] [G loss: 0.686867]\n",
      "epoch:5 step:4966 [D loss: 0.642885, acc.: 64.06%] [G loss: 0.419894]\n",
      "epoch:5 step:4967 [D loss: 0.579211, acc.: 73.44%] [G loss: 0.328173]\n",
      "epoch:5 step:4968 [D loss: 0.542925, acc.: 72.66%] [G loss: 0.423866]\n",
      "epoch:5 step:4969 [D loss: 0.501818, acc.: 77.34%] [G loss: 0.561244]\n",
      "epoch:5 step:4970 [D loss: 0.527814, acc.: 71.88%] [G loss: 0.472758]\n",
      "epoch:5 step:4971 [D loss: 0.503639, acc.: 75.78%] [G loss: 0.564774]\n",
      "epoch:5 step:4972 [D loss: 0.563756, acc.: 69.53%] [G loss: 0.563859]\n",
      "epoch:5 step:4973 [D loss: 0.581816, acc.: 74.22%] [G loss: 0.515638]\n",
      "epoch:5 step:4974 [D loss: 0.545611, acc.: 71.88%] [G loss: 0.512082]\n",
      "epoch:5 step:4975 [D loss: 0.569143, acc.: 69.53%] [G loss: 0.472097]\n",
      "epoch:5 step:4976 [D loss: 0.526226, acc.: 78.91%] [G loss: 0.496353]\n",
      "epoch:5 step:4977 [D loss: 0.550888, acc.: 68.75%] [G loss: 0.487340]\n",
      "epoch:5 step:4978 [D loss: 0.514584, acc.: 70.31%] [G loss: 0.493784]\n",
      "epoch:5 step:4979 [D loss: 0.582201, acc.: 69.53%] [G loss: 0.451912]\n",
      "epoch:5 step:4980 [D loss: 0.563166, acc.: 75.00%] [G loss: 0.400685]\n",
      "epoch:5 step:4981 [D loss: 0.488966, acc.: 76.56%] [G loss: 0.481518]\n",
      "epoch:5 step:4982 [D loss: 0.549329, acc.: 76.56%] [G loss: 0.498771]\n",
      "epoch:5 step:4983 [D loss: 0.454628, acc.: 80.47%] [G loss: 0.617236]\n",
      "epoch:5 step:4984 [D loss: 0.486893, acc.: 78.91%] [G loss: 0.673386]\n",
      "epoch:5 step:4985 [D loss: 0.532446, acc.: 74.22%] [G loss: 0.473728]\n",
      "epoch:5 step:4986 [D loss: 0.573365, acc.: 68.75%] [G loss: 0.521953]\n",
      "epoch:5 step:4987 [D loss: 0.508421, acc.: 74.22%] [G loss: 0.551792]\n",
      "epoch:5 step:4988 [D loss: 0.545727, acc.: 70.31%] [G loss: 0.638600]\n",
      "epoch:5 step:4989 [D loss: 0.498743, acc.: 71.88%] [G loss: 0.390086]\n",
      "epoch:5 step:4990 [D loss: 0.506982, acc.: 74.22%] [G loss: 0.599710]\n",
      "epoch:5 step:4991 [D loss: 0.515627, acc.: 73.44%] [G loss: 0.598500]\n",
      "epoch:5 step:4992 [D loss: 0.449261, acc.: 77.34%] [G loss: 0.670002]\n",
      "epoch:5 step:4993 [D loss: 0.577876, acc.: 66.41%] [G loss: 0.541218]\n",
      "epoch:5 step:4994 [D loss: 0.442918, acc.: 78.91%] [G loss: 0.660119]\n",
      "epoch:5 step:4995 [D loss: 0.501285, acc.: 74.22%] [G loss: 0.701330]\n",
      "epoch:5 step:4996 [D loss: 0.478461, acc.: 79.69%] [G loss: 0.737250]\n",
      "epoch:5 step:4997 [D loss: 0.445617, acc.: 81.25%] [G loss: 0.779054]\n",
      "epoch:5 step:4998 [D loss: 0.458424, acc.: 80.47%] [G loss: 0.831539]\n",
      "epoch:5 step:4999 [D loss: 0.437211, acc.: 81.25%] [G loss: 0.896450]\n",
      "epoch:5 step:5000 [D loss: 0.424810, acc.: 78.91%] [G loss: 0.882144]\n",
      "##############\n",
      "[3.48077984 1.98824728 7.00242448 5.15670636 4.52409637 6.19998223\n",
      " 5.15097593 5.01955049 5.24724427 3.7272729 ]\n",
      "##########\n",
      "epoch:5 step:5001 [D loss: 0.716741, acc.: 60.16%] [G loss: 0.567180]\n",
      "epoch:5 step:5002 [D loss: 0.610180, acc.: 66.41%] [G loss: 0.538652]\n",
      "epoch:5 step:5003 [D loss: 0.528838, acc.: 71.09%] [G loss: 0.606006]\n",
      "epoch:5 step:5004 [D loss: 0.549996, acc.: 71.09%] [G loss: 0.551949]\n",
      "epoch:5 step:5005 [D loss: 0.482280, acc.: 77.34%] [G loss: 0.675052]\n",
      "epoch:5 step:5006 [D loss: 0.484529, acc.: 81.25%] [G loss: 0.575158]\n",
      "epoch:5 step:5007 [D loss: 0.601493, acc.: 63.28%] [G loss: 0.533243]\n",
      "epoch:5 step:5008 [D loss: 0.599687, acc.: 67.19%] [G loss: 0.507348]\n",
      "epoch:5 step:5009 [D loss: 0.573233, acc.: 67.97%] [G loss: 0.501038]\n",
      "epoch:5 step:5010 [D loss: 0.511441, acc.: 71.88%] [G loss: 0.505318]\n",
      "epoch:5 step:5011 [D loss: 0.503205, acc.: 71.09%] [G loss: 0.486697]\n",
      "epoch:5 step:5012 [D loss: 0.515576, acc.: 77.34%] [G loss: 0.651008]\n",
      "epoch:5 step:5013 [D loss: 0.463054, acc.: 79.69%] [G loss: 0.633224]\n",
      "epoch:5 step:5014 [D loss: 0.601915, acc.: 64.84%] [G loss: 0.604832]\n",
      "epoch:5 step:5015 [D loss: 0.530738, acc.: 72.66%] [G loss: 0.544745]\n",
      "epoch:5 step:5016 [D loss: 0.539670, acc.: 75.00%] [G loss: 0.502676]\n",
      "epoch:5 step:5017 [D loss: 0.511345, acc.: 76.56%] [G loss: 0.567640]\n",
      "epoch:5 step:5018 [D loss: 0.478802, acc.: 77.34%] [G loss: 0.514834]\n",
      "epoch:5 step:5019 [D loss: 0.556945, acc.: 72.66%] [G loss: 0.624148]\n",
      "epoch:5 step:5020 [D loss: 0.514879, acc.: 71.88%] [G loss: 0.509911]\n",
      "epoch:5 step:5021 [D loss: 0.484223, acc.: 75.78%] [G loss: 0.661031]\n",
      "epoch:5 step:5022 [D loss: 0.470862, acc.: 79.69%] [G loss: 0.697571]\n",
      "epoch:5 step:5023 [D loss: 0.547509, acc.: 67.97%] [G loss: 0.650267]\n",
      "epoch:5 step:5024 [D loss: 0.490063, acc.: 78.91%] [G loss: 0.724556]\n",
      "epoch:5 step:5025 [D loss: 0.558024, acc.: 68.75%] [G loss: 0.519592]\n",
      "epoch:5 step:5026 [D loss: 0.590390, acc.: 67.19%] [G loss: 0.552936]\n",
      "epoch:5 step:5027 [D loss: 0.601210, acc.: 70.31%] [G loss: 0.514920]\n",
      "epoch:5 step:5028 [D loss: 0.457745, acc.: 78.12%] [G loss: 0.557109]\n",
      "epoch:5 step:5029 [D loss: 0.414739, acc.: 82.81%] [G loss: 0.724056]\n",
      "epoch:5 step:5030 [D loss: 0.541953, acc.: 74.22%] [G loss: 0.606801]\n",
      "epoch:5 step:5031 [D loss: 0.511699, acc.: 73.44%] [G loss: 0.734325]\n",
      "epoch:5 step:5032 [D loss: 0.490166, acc.: 72.66%] [G loss: 0.791399]\n",
      "epoch:5 step:5033 [D loss: 0.646987, acc.: 65.62%] [G loss: 0.538028]\n",
      "epoch:5 step:5034 [D loss: 0.701364, acc.: 59.38%] [G loss: 0.500088]\n",
      "epoch:5 step:5035 [D loss: 0.500740, acc.: 75.78%] [G loss: 0.737609]\n",
      "epoch:5 step:5036 [D loss: 0.538043, acc.: 74.22%] [G loss: 0.647817]\n",
      "epoch:5 step:5037 [D loss: 0.612622, acc.: 64.06%] [G loss: 0.609453]\n",
      "epoch:5 step:5038 [D loss: 0.579581, acc.: 65.62%] [G loss: 0.696495]\n",
      "epoch:5 step:5039 [D loss: 0.408811, acc.: 84.38%] [G loss: 0.746858]\n",
      "epoch:5 step:5040 [D loss: 0.544679, acc.: 71.09%] [G loss: 0.742567]\n",
      "epoch:5 step:5041 [D loss: 0.583644, acc.: 68.75%] [G loss: 0.580959]\n",
      "epoch:5 step:5042 [D loss: 0.453461, acc.: 82.81%] [G loss: 0.589948]\n",
      "epoch:5 step:5043 [D loss: 0.450239, acc.: 79.69%] [G loss: 0.690608]\n",
      "epoch:5 step:5044 [D loss: 0.505640, acc.: 76.56%] [G loss: 0.629701]\n",
      "epoch:5 step:5045 [D loss: 0.513780, acc.: 77.34%] [G loss: 0.654826]\n",
      "epoch:5 step:5046 [D loss: 0.509171, acc.: 76.56%] [G loss: 0.625302]\n",
      "epoch:5 step:5047 [D loss: 0.532605, acc.: 75.00%] [G loss: 0.610945]\n",
      "epoch:5 step:5048 [D loss: 0.474216, acc.: 77.34%] [G loss: 0.624828]\n",
      "epoch:5 step:5049 [D loss: 0.510980, acc.: 75.00%] [G loss: 0.521715]\n",
      "epoch:5 step:5050 [D loss: 0.496161, acc.: 76.56%] [G loss: 0.661129]\n",
      "epoch:5 step:5051 [D loss: 0.519034, acc.: 73.44%] [G loss: 0.673498]\n",
      "epoch:5 step:5052 [D loss: 0.572469, acc.: 71.88%] [G loss: 0.461168]\n",
      "epoch:5 step:5053 [D loss: 0.546983, acc.: 74.22%] [G loss: 0.568851]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:5 step:5054 [D loss: 0.528166, acc.: 76.56%] [G loss: 0.658627]\n",
      "epoch:5 step:5055 [D loss: 0.545205, acc.: 77.34%] [G loss: 0.496684]\n",
      "epoch:5 step:5056 [D loss: 0.549579, acc.: 74.22%] [G loss: 0.549306]\n",
      "epoch:5 step:5057 [D loss: 0.484572, acc.: 77.34%] [G loss: 0.610916]\n",
      "epoch:5 step:5058 [D loss: 0.552481, acc.: 71.09%] [G loss: 0.522145]\n",
      "epoch:5 step:5059 [D loss: 0.442076, acc.: 82.81%] [G loss: 0.606325]\n",
      "epoch:5 step:5060 [D loss: 0.530846, acc.: 74.22%] [G loss: 0.599516]\n",
      "epoch:5 step:5061 [D loss: 0.713013, acc.: 53.91%] [G loss: 0.387256]\n",
      "epoch:5 step:5062 [D loss: 0.557055, acc.: 69.53%] [G loss: 0.520787]\n",
      "epoch:5 step:5063 [D loss: 0.497986, acc.: 76.56%] [G loss: 0.708601]\n",
      "epoch:5 step:5064 [D loss: 0.624715, acc.: 66.41%] [G loss: 0.444273]\n",
      "epoch:5 step:5065 [D loss: 0.593520, acc.: 70.31%] [G loss: 0.457474]\n",
      "epoch:5 step:5066 [D loss: 0.472383, acc.: 78.12%] [G loss: 0.549846]\n",
      "epoch:5 step:5067 [D loss: 0.526523, acc.: 71.88%] [G loss: 0.588904]\n",
      "epoch:5 step:5068 [D loss: 0.576424, acc.: 67.97%] [G loss: 0.644888]\n",
      "epoch:5 step:5069 [D loss: 0.529632, acc.: 72.66%] [G loss: 0.694595]\n",
      "epoch:5 step:5070 [D loss: 0.561156, acc.: 70.31%] [G loss: 0.623869]\n",
      "epoch:5 step:5071 [D loss: 0.564215, acc.: 69.53%] [G loss: 0.447266]\n",
      "epoch:5 step:5072 [D loss: 0.602203, acc.: 62.50%] [G loss: 0.491509]\n",
      "epoch:5 step:5073 [D loss: 0.544050, acc.: 67.97%] [G loss: 0.566288]\n",
      "epoch:5 step:5074 [D loss: 0.527682, acc.: 75.00%] [G loss: 0.672528]\n",
      "epoch:5 step:5075 [D loss: 0.557669, acc.: 71.88%] [G loss: 0.619426]\n",
      "epoch:5 step:5076 [D loss: 0.540135, acc.: 71.09%] [G loss: 0.459211]\n",
      "epoch:5 step:5077 [D loss: 0.491264, acc.: 74.22%] [G loss: 0.560932]\n",
      "epoch:5 step:5078 [D loss: 0.576026, acc.: 63.28%] [G loss: 0.578000]\n",
      "epoch:5 step:5079 [D loss: 0.531091, acc.: 75.78%] [G loss: 0.472305]\n",
      "epoch:5 step:5080 [D loss: 0.521364, acc.: 72.66%] [G loss: 0.589734]\n",
      "epoch:5 step:5081 [D loss: 0.604869, acc.: 64.84%] [G loss: 0.463022]\n",
      "epoch:5 step:5082 [D loss: 0.531558, acc.: 69.53%] [G loss: 0.487247]\n",
      "epoch:5 step:5083 [D loss: 0.475600, acc.: 78.12%] [G loss: 0.618898]\n",
      "epoch:5 step:5084 [D loss: 0.502275, acc.: 76.56%] [G loss: 0.851571]\n",
      "epoch:5 step:5085 [D loss: 0.675566, acc.: 60.94%] [G loss: 0.595946]\n",
      "epoch:5 step:5086 [D loss: 0.579045, acc.: 65.62%] [G loss: 0.443290]\n",
      "epoch:5 step:5087 [D loss: 0.454278, acc.: 80.47%] [G loss: 0.685042]\n",
      "epoch:5 step:5088 [D loss: 0.487327, acc.: 73.44%] [G loss: 0.626602]\n",
      "epoch:5 step:5089 [D loss: 0.587504, acc.: 66.41%] [G loss: 0.464553]\n",
      "epoch:5 step:5090 [D loss: 0.536585, acc.: 68.75%] [G loss: 0.482594]\n",
      "epoch:5 step:5091 [D loss: 0.454222, acc.: 82.81%] [G loss: 0.640897]\n",
      "epoch:5 step:5092 [D loss: 0.518657, acc.: 73.44%] [G loss: 0.486719]\n",
      "epoch:5 step:5093 [D loss: 0.575296, acc.: 72.66%] [G loss: 0.482505]\n",
      "epoch:5 step:5094 [D loss: 0.547656, acc.: 72.66%] [G loss: 0.478056]\n",
      "epoch:5 step:5095 [D loss: 0.585699, acc.: 66.41%] [G loss: 0.567936]\n",
      "epoch:5 step:5096 [D loss: 0.592586, acc.: 66.41%] [G loss: 0.501409]\n",
      "epoch:5 step:5097 [D loss: 0.554209, acc.: 71.88%] [G loss: 0.522027]\n",
      "epoch:5 step:5098 [D loss: 0.533837, acc.: 68.75%] [G loss: 0.429447]\n",
      "epoch:5 step:5099 [D loss: 0.542734, acc.: 72.66%] [G loss: 0.485694]\n",
      "epoch:5 step:5100 [D loss: 0.581968, acc.: 67.19%] [G loss: 0.541885]\n",
      "epoch:5 step:5101 [D loss: 0.545036, acc.: 71.88%] [G loss: 0.575466]\n",
      "epoch:5 step:5102 [D loss: 0.609103, acc.: 65.62%] [G loss: 0.623558]\n",
      "epoch:5 step:5103 [D loss: 0.589728, acc.: 59.38%] [G loss: 0.443212]\n",
      "epoch:5 step:5104 [D loss: 0.573854, acc.: 73.44%] [G loss: 0.584030]\n",
      "epoch:5 step:5105 [D loss: 0.586847, acc.: 62.50%] [G loss: 0.529766]\n",
      "epoch:5 step:5106 [D loss: 0.552718, acc.: 73.44%] [G loss: 0.508917]\n",
      "epoch:5 step:5107 [D loss: 0.533491, acc.: 75.00%] [G loss: 0.446683]\n",
      "epoch:5 step:5108 [D loss: 0.495658, acc.: 75.00%] [G loss: 0.634549]\n",
      "epoch:5 step:5109 [D loss: 0.623786, acc.: 58.59%] [G loss: 0.389170]\n",
      "epoch:5 step:5110 [D loss: 0.520984, acc.: 78.12%] [G loss: 0.487154]\n",
      "epoch:5 step:5111 [D loss: 0.475769, acc.: 76.56%] [G loss: 0.555789]\n",
      "epoch:5 step:5112 [D loss: 0.512625, acc.: 74.22%] [G loss: 0.613459]\n",
      "epoch:5 step:5113 [D loss: 0.521437, acc.: 74.22%] [G loss: 0.535991]\n",
      "epoch:5 step:5114 [D loss: 0.424790, acc.: 82.03%] [G loss: 0.696359]\n",
      "epoch:5 step:5115 [D loss: 0.538784, acc.: 75.00%] [G loss: 0.625751]\n",
      "epoch:5 step:5116 [D loss: 0.496911, acc.: 75.78%] [G loss: 0.584115]\n",
      "epoch:5 step:5117 [D loss: 0.560491, acc.: 67.19%] [G loss: 0.601765]\n",
      "epoch:5 step:5118 [D loss: 0.624474, acc.: 64.84%] [G loss: 0.434247]\n",
      "epoch:5 step:5119 [D loss: 0.501739, acc.: 76.56%] [G loss: 0.457221]\n",
      "epoch:5 step:5120 [D loss: 0.544081, acc.: 74.22%] [G loss: 0.529519]\n",
      "epoch:5 step:5121 [D loss: 0.488714, acc.: 77.34%] [G loss: 0.628471]\n",
      "epoch:5 step:5122 [D loss: 0.633762, acc.: 66.41%] [G loss: 0.509270]\n",
      "epoch:5 step:5123 [D loss: 0.541642, acc.: 68.75%] [G loss: 0.422316]\n",
      "epoch:5 step:5124 [D loss: 0.470365, acc.: 83.59%] [G loss: 0.477705]\n",
      "epoch:5 step:5125 [D loss: 0.519449, acc.: 74.22%] [G loss: 0.565135]\n",
      "epoch:5 step:5126 [D loss: 0.572722, acc.: 70.31%] [G loss: 0.540241]\n",
      "epoch:5 step:5127 [D loss: 0.553774, acc.: 67.97%] [G loss: 0.503460]\n",
      "epoch:5 step:5128 [D loss: 0.515712, acc.: 75.78%] [G loss: 0.504127]\n",
      "epoch:5 step:5129 [D loss: 0.514466, acc.: 75.00%] [G loss: 0.651340]\n",
      "epoch:5 step:5130 [D loss: 0.550591, acc.: 71.88%] [G loss: 0.565585]\n",
      "epoch:5 step:5131 [D loss: 0.519268, acc.: 73.44%] [G loss: 0.544713]\n",
      "epoch:5 step:5132 [D loss: 0.521442, acc.: 74.22%] [G loss: 0.580716]\n",
      "epoch:5 step:5133 [D loss: 0.537895, acc.: 74.22%] [G loss: 0.581194]\n",
      "epoch:5 step:5134 [D loss: 0.544396, acc.: 68.75%] [G loss: 0.567151]\n",
      "epoch:5 step:5135 [D loss: 0.514002, acc.: 77.34%] [G loss: 0.610009]\n",
      "epoch:5 step:5136 [D loss: 0.467012, acc.: 78.12%] [G loss: 0.679733]\n",
      "epoch:5 step:5137 [D loss: 0.483622, acc.: 80.47%] [G loss: 0.683946]\n",
      "epoch:5 step:5138 [D loss: 0.507470, acc.: 72.66%] [G loss: 0.593408]\n",
      "epoch:5 step:5139 [D loss: 0.553616, acc.: 67.97%] [G loss: 0.533097]\n",
      "epoch:5 step:5140 [D loss: 0.545566, acc.: 75.78%] [G loss: 0.507579]\n",
      "epoch:5 step:5141 [D loss: 0.647337, acc.: 64.06%] [G loss: 0.466735]\n",
      "epoch:5 step:5142 [D loss: 0.464492, acc.: 79.69%] [G loss: 0.610223]\n",
      "epoch:5 step:5143 [D loss: 0.612509, acc.: 64.06%] [G loss: 0.480471]\n",
      "epoch:5 step:5144 [D loss: 0.581342, acc.: 66.41%] [G loss: 0.386738]\n",
      "epoch:5 step:5145 [D loss: 0.522006, acc.: 72.66%] [G loss: 0.609831]\n",
      "epoch:5 step:5146 [D loss: 0.508597, acc.: 75.78%] [G loss: 0.512753]\n",
      "epoch:5 step:5147 [D loss: 0.579598, acc.: 65.62%] [G loss: 0.522313]\n",
      "epoch:5 step:5148 [D loss: 0.538816, acc.: 74.22%] [G loss: 0.449695]\n",
      "epoch:5 step:5149 [D loss: 0.529773, acc.: 73.44%] [G loss: 0.497478]\n",
      "epoch:5 step:5150 [D loss: 0.643716, acc.: 62.50%] [G loss: 0.510899]\n",
      "epoch:5 step:5151 [D loss: 0.511372, acc.: 78.12%] [G loss: 0.549716]\n",
      "epoch:5 step:5152 [D loss: 0.498030, acc.: 82.03%] [G loss: 0.600165]\n",
      "epoch:5 step:5153 [D loss: 0.517599, acc.: 74.22%] [G loss: 0.570028]\n",
      "epoch:5 step:5154 [D loss: 0.523740, acc.: 72.66%] [G loss: 0.574320]\n",
      "epoch:5 step:5155 [D loss: 0.503060, acc.: 76.56%] [G loss: 0.604934]\n",
      "epoch:5 step:5156 [D loss: 0.439534, acc.: 82.03%] [G loss: 0.804695]\n",
      "epoch:5 step:5157 [D loss: 0.410247, acc.: 83.59%] [G loss: 0.754855]\n",
      "epoch:5 step:5158 [D loss: 0.614476, acc.: 62.50%] [G loss: 0.509763]\n",
      "epoch:5 step:5159 [D loss: 0.583780, acc.: 69.53%] [G loss: 0.444476]\n",
      "epoch:5 step:5160 [D loss: 0.474900, acc.: 75.78%] [G loss: 0.592289]\n",
      "epoch:5 step:5161 [D loss: 0.505094, acc.: 71.88%] [G loss: 0.632336]\n",
      "epoch:5 step:5162 [D loss: 0.669932, acc.: 61.72%] [G loss: 0.466684]\n",
      "epoch:5 step:5163 [D loss: 0.613213, acc.: 69.53%] [G loss: 0.361999]\n",
      "epoch:5 step:5164 [D loss: 0.566640, acc.: 68.75%] [G loss: 0.541826]\n",
      "epoch:5 step:5165 [D loss: 0.561050, acc.: 67.97%] [G loss: 0.531353]\n",
      "epoch:5 step:5166 [D loss: 0.560782, acc.: 70.31%] [G loss: 0.574271]\n",
      "epoch:5 step:5167 [D loss: 0.633731, acc.: 64.06%] [G loss: 0.463491]\n",
      "epoch:5 step:5168 [D loss: 0.537198, acc.: 73.44%] [G loss: 0.495204]\n",
      "epoch:5 step:5169 [D loss: 0.493190, acc.: 75.78%] [G loss: 0.555948]\n",
      "epoch:5 step:5170 [D loss: 0.524285, acc.: 71.88%] [G loss: 0.620729]\n",
      "epoch:5 step:5171 [D loss: 0.589135, acc.: 66.41%] [G loss: 0.451306]\n",
      "epoch:5 step:5172 [D loss: 0.574611, acc.: 69.53%] [G loss: 0.514646]\n",
      "epoch:5 step:5173 [D loss: 0.497029, acc.: 70.31%] [G loss: 0.597417]\n",
      "epoch:5 step:5174 [D loss: 0.526119, acc.: 72.66%] [G loss: 0.624469]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:5 step:5175 [D loss: 0.570801, acc.: 71.09%] [G loss: 0.502283]\n",
      "epoch:5 step:5176 [D loss: 0.499510, acc.: 76.56%] [G loss: 0.569480]\n",
      "epoch:5 step:5177 [D loss: 0.577340, acc.: 67.97%] [G loss: 0.576461]\n",
      "epoch:5 step:5178 [D loss: 0.549388, acc.: 70.31%] [G loss: 0.473663]\n",
      "epoch:5 step:5179 [D loss: 0.536608, acc.: 78.12%] [G loss: 0.632283]\n",
      "epoch:5 step:5180 [D loss: 0.485563, acc.: 84.38%] [G loss: 0.592067]\n",
      "epoch:5 step:5181 [D loss: 0.589035, acc.: 70.31%] [G loss: 0.496905]\n",
      "epoch:5 step:5182 [D loss: 0.497775, acc.: 77.34%] [G loss: 0.558327]\n",
      "epoch:5 step:5183 [D loss: 0.493755, acc.: 77.34%] [G loss: 0.601733]\n",
      "epoch:5 step:5184 [D loss: 0.431220, acc.: 88.28%] [G loss: 0.685124]\n",
      "epoch:5 step:5185 [D loss: 0.599596, acc.: 63.28%] [G loss: 0.508311]\n",
      "epoch:5 step:5186 [D loss: 0.625653, acc.: 68.75%] [G loss: 0.427144]\n",
      "epoch:5 step:5187 [D loss: 0.602125, acc.: 67.97%] [G loss: 0.444957]\n",
      "epoch:5 step:5188 [D loss: 0.499393, acc.: 78.91%] [G loss: 0.430811]\n",
      "epoch:5 step:5189 [D loss: 0.437236, acc.: 86.72%] [G loss: 0.814259]\n",
      "epoch:5 step:5190 [D loss: 0.505141, acc.: 75.00%] [G loss: 0.581442]\n",
      "epoch:5 step:5191 [D loss: 0.520768, acc.: 74.22%] [G loss: 0.598656]\n",
      "epoch:5 step:5192 [D loss: 0.467873, acc.: 78.91%] [G loss: 0.659693]\n",
      "epoch:5 step:5193 [D loss: 0.468950, acc.: 75.00%] [G loss: 0.645967]\n",
      "epoch:5 step:5194 [D loss: 0.547958, acc.: 69.53%] [G loss: 0.620166]\n",
      "epoch:5 step:5195 [D loss: 0.574509, acc.: 67.19%] [G loss: 0.618133]\n",
      "epoch:5 step:5196 [D loss: 0.690873, acc.: 57.81%] [G loss: 0.464745]\n",
      "epoch:5 step:5197 [D loss: 0.541386, acc.: 71.88%] [G loss: 0.483602]\n",
      "epoch:5 step:5198 [D loss: 0.500292, acc.: 76.56%] [G loss: 0.751221]\n",
      "epoch:5 step:5199 [D loss: 0.499445, acc.: 71.88%] [G loss: 0.597581]\n",
      "epoch:5 step:5200 [D loss: 0.504137, acc.: 76.56%] [G loss: 0.660136]\n",
      "##############\n",
      "[3.362472   2.13796626 6.8579625  4.91396993 4.35749027 5.97783952\n",
      " 4.97864904 5.16335706 5.05038827 3.95815915]\n",
      "##########\n",
      "epoch:5 step:5201 [D loss: 0.490131, acc.: 77.34%] [G loss: 0.681120]\n",
      "epoch:5 step:5202 [D loss: 0.553898, acc.: 72.66%] [G loss: 0.565804]\n",
      "epoch:5 step:5203 [D loss: 0.503784, acc.: 75.00%] [G loss: 0.554026]\n",
      "epoch:5 step:5204 [D loss: 0.559217, acc.: 72.66%] [G loss: 0.510200]\n",
      "epoch:5 step:5205 [D loss: 0.477571, acc.: 75.78%] [G loss: 0.545363]\n",
      "epoch:5 step:5206 [D loss: 0.458784, acc.: 77.34%] [G loss: 0.609068]\n",
      "epoch:5 step:5207 [D loss: 0.467921, acc.: 75.00%] [G loss: 0.604534]\n",
      "epoch:5 step:5208 [D loss: 0.498109, acc.: 75.78%] [G loss: 0.647451]\n",
      "epoch:5 step:5209 [D loss: 0.535146, acc.: 71.88%] [G loss: 0.554350]\n",
      "epoch:5 step:5210 [D loss: 0.587405, acc.: 64.06%] [G loss: 0.492806]\n",
      "epoch:5 step:5211 [D loss: 0.513129, acc.: 72.66%] [G loss: 0.637774]\n",
      "epoch:5 step:5212 [D loss: 0.593671, acc.: 66.41%] [G loss: 0.514059]\n",
      "epoch:5 step:5213 [D loss: 0.640844, acc.: 66.41%] [G loss: 0.447897]\n",
      "epoch:5 step:5214 [D loss: 0.583724, acc.: 69.53%] [G loss: 0.526455]\n",
      "epoch:5 step:5215 [D loss: 0.457357, acc.: 81.25%] [G loss: 0.505161]\n",
      "epoch:5 step:5216 [D loss: 0.558352, acc.: 71.88%] [G loss: 0.528711]\n",
      "epoch:5 step:5217 [D loss: 0.509150, acc.: 79.69%] [G loss: 0.580760]\n",
      "epoch:5 step:5218 [D loss: 0.525253, acc.: 71.88%] [G loss: 0.702566]\n",
      "epoch:5 step:5219 [D loss: 0.504455, acc.: 71.09%] [G loss: 0.621433]\n",
      "epoch:5 step:5220 [D loss: 0.576877, acc.: 71.88%] [G loss: 0.568609]\n",
      "epoch:5 step:5221 [D loss: 0.534001, acc.: 71.88%] [G loss: 0.570243]\n",
      "epoch:5 step:5222 [D loss: 0.541778, acc.: 71.09%] [G loss: 0.555538]\n",
      "epoch:5 step:5223 [D loss: 0.574744, acc.: 67.19%] [G loss: 0.419349]\n",
      "epoch:5 step:5224 [D loss: 0.553108, acc.: 70.31%] [G loss: 0.608836]\n",
      "epoch:5 step:5225 [D loss: 0.586720, acc.: 66.41%] [G loss: 0.548978]\n",
      "epoch:5 step:5226 [D loss: 0.515649, acc.: 71.09%] [G loss: 0.606566]\n",
      "epoch:5 step:5227 [D loss: 0.628056, acc.: 67.19%] [G loss: 0.468902]\n",
      "epoch:5 step:5228 [D loss: 0.590544, acc.: 64.84%] [G loss: 0.576516]\n",
      "epoch:5 step:5229 [D loss: 0.604163, acc.: 65.62%] [G loss: 0.484591]\n",
      "epoch:5 step:5230 [D loss: 0.562450, acc.: 67.19%] [G loss: 0.537414]\n",
      "epoch:5 step:5231 [D loss: 0.499501, acc.: 75.00%] [G loss: 0.547292]\n",
      "epoch:5 step:5232 [D loss: 0.486738, acc.: 78.91%] [G loss: 0.625124]\n",
      "epoch:5 step:5233 [D loss: 0.520852, acc.: 70.31%] [G loss: 0.559853]\n",
      "epoch:5 step:5234 [D loss: 0.531692, acc.: 75.00%] [G loss: 0.561810]\n",
      "epoch:5 step:5235 [D loss: 0.564161, acc.: 67.97%] [G loss: 0.488362]\n",
      "epoch:5 step:5236 [D loss: 0.541849, acc.: 74.22%] [G loss: 0.493643]\n",
      "epoch:5 step:5237 [D loss: 0.461277, acc.: 77.34%] [G loss: 0.690272]\n",
      "epoch:5 step:5238 [D loss: 0.519807, acc.: 71.09%] [G loss: 0.523498]\n",
      "epoch:5 step:5239 [D loss: 0.458135, acc.: 75.78%] [G loss: 0.614500]\n",
      "epoch:5 step:5240 [D loss: 0.502221, acc.: 76.56%] [G loss: 0.661339]\n",
      "epoch:5 step:5241 [D loss: 0.454472, acc.: 81.25%] [G loss: 0.800785]\n",
      "epoch:5 step:5242 [D loss: 0.523012, acc.: 71.88%] [G loss: 0.580293]\n",
      "epoch:5 step:5243 [D loss: 0.462303, acc.: 75.78%] [G loss: 0.633435]\n",
      "epoch:5 step:5244 [D loss: 0.541441, acc.: 69.53%] [G loss: 0.469454]\n",
      "epoch:5 step:5245 [D loss: 0.540321, acc.: 71.88%] [G loss: 0.608814]\n",
      "epoch:5 step:5246 [D loss: 0.507497, acc.: 78.91%] [G loss: 0.624798]\n",
      "epoch:5 step:5247 [D loss: 0.619683, acc.: 60.16%] [G loss: 0.451143]\n",
      "epoch:5 step:5248 [D loss: 0.528852, acc.: 78.12%] [G loss: 0.547296]\n",
      "epoch:5 step:5249 [D loss: 0.526060, acc.: 71.88%] [G loss: 0.669189]\n",
      "epoch:5 step:5250 [D loss: 0.545013, acc.: 72.66%] [G loss: 0.617474]\n",
      "epoch:5 step:5251 [D loss: 0.655440, acc.: 59.38%] [G loss: 0.517338]\n",
      "epoch:5 step:5252 [D loss: 0.481324, acc.: 73.44%] [G loss: 0.632301]\n",
      "epoch:5 step:5253 [D loss: 0.519866, acc.: 72.66%] [G loss: 0.547192]\n",
      "epoch:5 step:5254 [D loss: 0.504186, acc.: 76.56%] [G loss: 0.552939]\n",
      "epoch:5 step:5255 [D loss: 0.516608, acc.: 71.09%] [G loss: 0.533931]\n",
      "epoch:5 step:5256 [D loss: 0.495744, acc.: 75.00%] [G loss: 0.613916]\n",
      "epoch:5 step:5257 [D loss: 0.566911, acc.: 73.44%] [G loss: 0.656275]\n",
      "epoch:5 step:5258 [D loss: 0.558275, acc.: 70.31%] [G loss: 0.545052]\n",
      "epoch:5 step:5259 [D loss: 0.494299, acc.: 78.91%] [G loss: 0.589957]\n",
      "epoch:5 step:5260 [D loss: 0.515548, acc.: 75.78%] [G loss: 0.766606]\n",
      "epoch:5 step:5261 [D loss: 0.606268, acc.: 62.50%] [G loss: 0.680664]\n",
      "epoch:5 step:5262 [D loss: 0.575233, acc.: 65.62%] [G loss: 0.468092]\n",
      "epoch:5 step:5263 [D loss: 0.576772, acc.: 64.06%] [G loss: 0.538909]\n",
      "epoch:5 step:5264 [D loss: 0.517452, acc.: 71.09%] [G loss: 0.560996]\n",
      "epoch:5 step:5265 [D loss: 0.529142, acc.: 73.44%] [G loss: 0.551034]\n",
      "epoch:5 step:5266 [D loss: 0.587880, acc.: 61.72%] [G loss: 0.483472]\n",
      "epoch:5 step:5267 [D loss: 0.513913, acc.: 78.12%] [G loss: 0.688623]\n",
      "epoch:5 step:5268 [D loss: 0.569550, acc.: 70.31%] [G loss: 0.572778]\n",
      "epoch:5 step:5269 [D loss: 0.636609, acc.: 61.72%] [G loss: 0.502677]\n",
      "epoch:5 step:5270 [D loss: 0.527776, acc.: 71.09%] [G loss: 0.523164]\n",
      "epoch:5 step:5271 [D loss: 0.616004, acc.: 66.41%] [G loss: 0.489072]\n",
      "epoch:5 step:5272 [D loss: 0.532552, acc.: 69.53%] [G loss: 0.504175]\n",
      "epoch:5 step:5273 [D loss: 0.645670, acc.: 60.94%] [G loss: 0.602514]\n",
      "epoch:5 step:5274 [D loss: 0.532326, acc.: 72.66%] [G loss: 0.671070]\n",
      "epoch:5 step:5275 [D loss: 0.537082, acc.: 67.19%] [G loss: 0.741898]\n",
      "epoch:5 step:5276 [D loss: 0.566387, acc.: 72.66%] [G loss: 0.513908]\n",
      "epoch:5 step:5277 [D loss: 0.521606, acc.: 78.91%] [G loss: 0.623314]\n",
      "epoch:5 step:5278 [D loss: 0.575350, acc.: 68.75%] [G loss: 0.543155]\n",
      "epoch:5 step:5279 [D loss: 0.543376, acc.: 71.88%] [G loss: 0.616100]\n",
      "epoch:5 step:5280 [D loss: 0.583477, acc.: 64.84%] [G loss: 0.522746]\n",
      "epoch:5 step:5281 [D loss: 0.589302, acc.: 67.19%] [G loss: 0.506292]\n",
      "epoch:5 step:5282 [D loss: 0.507237, acc.: 72.66%] [G loss: 0.565897]\n",
      "epoch:5 step:5283 [D loss: 0.517897, acc.: 75.00%] [G loss: 0.759802]\n",
      "epoch:5 step:5284 [D loss: 0.561450, acc.: 69.53%] [G loss: 0.548263]\n",
      "epoch:5 step:5285 [D loss: 0.623797, acc.: 66.41%] [G loss: 0.381437]\n",
      "epoch:5 step:5286 [D loss: 0.494551, acc.: 72.66%] [G loss: 0.450269]\n",
      "epoch:5 step:5287 [D loss: 0.504331, acc.: 69.53%] [G loss: 0.539781]\n",
      "epoch:5 step:5288 [D loss: 0.500543, acc.: 75.00%] [G loss: 0.679592]\n",
      "epoch:5 step:5289 [D loss: 0.630905, acc.: 65.62%] [G loss: 0.555529]\n",
      "epoch:5 step:5290 [D loss: 0.505721, acc.: 72.66%] [G loss: 0.618831]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:5 step:5291 [D loss: 0.541979, acc.: 71.09%] [G loss: 0.478066]\n",
      "epoch:5 step:5292 [D loss: 0.538926, acc.: 71.09%] [G loss: 0.446547]\n",
      "epoch:5 step:5293 [D loss: 0.524740, acc.: 73.44%] [G loss: 0.638786]\n",
      "epoch:5 step:5294 [D loss: 0.516180, acc.: 72.66%] [G loss: 0.550947]\n",
      "epoch:5 step:5295 [D loss: 0.581789, acc.: 68.75%] [G loss: 0.477858]\n",
      "epoch:5 step:5296 [D loss: 0.536202, acc.: 70.31%] [G loss: 0.518904]\n",
      "epoch:5 step:5297 [D loss: 0.513896, acc.: 75.00%] [G loss: 0.530137]\n",
      "epoch:5 step:5298 [D loss: 0.478076, acc.: 79.69%] [G loss: 0.495958]\n",
      "epoch:5 step:5299 [D loss: 0.547711, acc.: 73.44%] [G loss: 0.465094]\n",
      "epoch:5 step:5300 [D loss: 0.589971, acc.: 63.28%] [G loss: 0.423642]\n",
      "epoch:5 step:5301 [D loss: 0.583605, acc.: 66.41%] [G loss: 0.497886]\n",
      "epoch:5 step:5302 [D loss: 0.564774, acc.: 68.75%] [G loss: 0.607971]\n",
      "epoch:5 step:5303 [D loss: 0.525116, acc.: 72.66%] [G loss: 0.539719]\n",
      "epoch:5 step:5304 [D loss: 0.526316, acc.: 74.22%] [G loss: 0.622833]\n",
      "epoch:5 step:5305 [D loss: 0.518945, acc.: 72.66%] [G loss: 0.531480]\n",
      "epoch:5 step:5306 [D loss: 0.562702, acc.: 70.31%] [G loss: 0.636466]\n",
      "epoch:5 step:5307 [D loss: 0.586244, acc.: 69.53%] [G loss: 0.450622]\n",
      "epoch:5 step:5308 [D loss: 0.567997, acc.: 69.53%] [G loss: 0.465178]\n",
      "epoch:5 step:5309 [D loss: 0.554502, acc.: 71.88%] [G loss: 0.627244]\n",
      "epoch:5 step:5310 [D loss: 0.559846, acc.: 68.75%] [G loss: 0.580537]\n",
      "epoch:5 step:5311 [D loss: 0.524034, acc.: 71.88%] [G loss: 0.540149]\n",
      "epoch:5 step:5312 [D loss: 0.531422, acc.: 70.31%] [G loss: 0.691108]\n",
      "epoch:5 step:5313 [D loss: 0.531353, acc.: 69.53%] [G loss: 0.515499]\n",
      "epoch:5 step:5314 [D loss: 0.484274, acc.: 79.69%] [G loss: 0.610925]\n",
      "epoch:5 step:5315 [D loss: 0.527236, acc.: 74.22%] [G loss: 0.481116]\n",
      "epoch:5 step:5316 [D loss: 0.475833, acc.: 75.78%] [G loss: 0.662940]\n",
      "epoch:5 step:5317 [D loss: 0.537210, acc.: 67.97%] [G loss: 0.535635]\n",
      "epoch:5 step:5318 [D loss: 0.523702, acc.: 74.22%] [G loss: 0.545703]\n",
      "epoch:5 step:5319 [D loss: 0.507212, acc.: 75.78%] [G loss: 0.550533]\n",
      "epoch:5 step:5320 [D loss: 0.470915, acc.: 78.12%] [G loss: 0.628170]\n",
      "epoch:5 step:5321 [D loss: 0.575331, acc.: 71.09%] [G loss: 0.502250]\n",
      "epoch:5 step:5322 [D loss: 0.579905, acc.: 69.53%] [G loss: 0.458805]\n",
      "epoch:5 step:5323 [D loss: 0.528730, acc.: 75.78%] [G loss: 0.459926]\n",
      "epoch:5 step:5324 [D loss: 0.495571, acc.: 80.47%] [G loss: 0.528381]\n",
      "epoch:5 step:5325 [D loss: 0.530903, acc.: 73.44%] [G loss: 0.569455]\n",
      "epoch:5 step:5326 [D loss: 0.449414, acc.: 81.25%] [G loss: 0.758048]\n",
      "epoch:5 step:5327 [D loss: 0.482220, acc.: 78.12%] [G loss: 0.755285]\n",
      "epoch:5 step:5328 [D loss: 0.521166, acc.: 75.78%] [G loss: 0.640177]\n",
      "epoch:5 step:5329 [D loss: 0.590629, acc.: 71.09%] [G loss: 0.500312]\n",
      "epoch:5 step:5330 [D loss: 0.524297, acc.: 75.78%] [G loss: 0.449219]\n",
      "epoch:5 step:5331 [D loss: 0.575548, acc.: 67.97%] [G loss: 0.574538]\n",
      "epoch:5 step:5332 [D loss: 0.480593, acc.: 80.47%] [G loss: 0.702098]\n",
      "epoch:5 step:5333 [D loss: 0.396684, acc.: 83.59%] [G loss: 0.883526]\n",
      "epoch:5 step:5334 [D loss: 0.575496, acc.: 69.53%] [G loss: 0.648615]\n",
      "epoch:5 step:5335 [D loss: 0.498552, acc.: 75.78%] [G loss: 0.724988]\n",
      "epoch:5 step:5336 [D loss: 0.476754, acc.: 77.34%] [G loss: 0.785792]\n",
      "epoch:5 step:5337 [D loss: 0.641149, acc.: 63.28%] [G loss: 0.486310]\n",
      "epoch:5 step:5338 [D loss: 0.609828, acc.: 62.50%] [G loss: 0.477613]\n",
      "epoch:5 step:5339 [D loss: 0.476835, acc.: 82.03%] [G loss: 0.503912]\n",
      "epoch:5 step:5340 [D loss: 0.530389, acc.: 75.78%] [G loss: 0.523687]\n",
      "epoch:5 step:5341 [D loss: 0.565905, acc.: 69.53%] [G loss: 0.550554]\n",
      "epoch:5 step:5342 [D loss: 0.516718, acc.: 74.22%] [G loss: 0.558227]\n",
      "epoch:5 step:5343 [D loss: 0.565117, acc.: 67.97%] [G loss: 0.557707]\n",
      "epoch:5 step:5344 [D loss: 0.558365, acc.: 68.75%] [G loss: 0.412539]\n",
      "epoch:5 step:5345 [D loss: 0.504934, acc.: 75.78%] [G loss: 0.502270]\n",
      "epoch:5 step:5346 [D loss: 0.457724, acc.: 82.03%] [G loss: 0.609896]\n",
      "epoch:5 step:5347 [D loss: 0.592692, acc.: 67.19%] [G loss: 0.530163]\n",
      "epoch:5 step:5348 [D loss: 0.548543, acc.: 71.09%] [G loss: 0.536978]\n",
      "epoch:5 step:5349 [D loss: 0.560070, acc.: 71.88%] [G loss: 0.557568]\n",
      "epoch:5 step:5350 [D loss: 0.579134, acc.: 64.84%] [G loss: 0.709000]\n",
      "epoch:5 step:5351 [D loss: 0.541988, acc.: 67.97%] [G loss: 0.690942]\n",
      "epoch:5 step:5352 [D loss: 0.622160, acc.: 60.94%] [G loss: 0.617948]\n",
      "epoch:5 step:5353 [D loss: 0.580789, acc.: 73.44%] [G loss: 0.510527]\n",
      "epoch:5 step:5354 [D loss: 0.530300, acc.: 72.66%] [G loss: 0.483771]\n",
      "epoch:5 step:5355 [D loss: 0.546835, acc.: 68.75%] [G loss: 0.473874]\n",
      "epoch:5 step:5356 [D loss: 0.561406, acc.: 69.53%] [G loss: 0.497673]\n",
      "epoch:5 step:5357 [D loss: 0.588623, acc.: 70.31%] [G loss: 0.650664]\n",
      "epoch:5 step:5358 [D loss: 0.586340, acc.: 65.62%] [G loss: 0.558939]\n",
      "epoch:5 step:5359 [D loss: 0.558981, acc.: 69.53%] [G loss: 0.526897]\n",
      "epoch:5 step:5360 [D loss: 0.566690, acc.: 67.97%] [G loss: 0.397015]\n",
      "epoch:5 step:5361 [D loss: 0.515052, acc.: 74.22%] [G loss: 0.591175]\n",
      "epoch:5 step:5362 [D loss: 0.478717, acc.: 78.91%] [G loss: 0.567696]\n",
      "epoch:5 step:5363 [D loss: 0.520763, acc.: 75.00%] [G loss: 0.566229]\n",
      "epoch:5 step:5364 [D loss: 0.527021, acc.: 73.44%] [G loss: 0.619438]\n",
      "epoch:5 step:5365 [D loss: 0.480177, acc.: 75.78%] [G loss: 0.520202]\n",
      "epoch:5 step:5366 [D loss: 0.555670, acc.: 71.88%] [G loss: 0.566966]\n",
      "epoch:5 step:5367 [D loss: 0.503309, acc.: 78.91%] [G loss: 0.663568]\n",
      "epoch:5 step:5368 [D loss: 0.584724, acc.: 68.75%] [G loss: 0.481657]\n",
      "epoch:5 step:5369 [D loss: 0.540221, acc.: 71.09%] [G loss: 0.705183]\n",
      "epoch:5 step:5370 [D loss: 0.520263, acc.: 75.00%] [G loss: 0.572326]\n",
      "epoch:5 step:5371 [D loss: 0.559227, acc.: 75.00%] [G loss: 0.454213]\n",
      "epoch:5 step:5372 [D loss: 0.573201, acc.: 67.19%] [G loss: 0.439532]\n",
      "epoch:5 step:5373 [D loss: 0.610177, acc.: 68.75%] [G loss: 0.444091]\n",
      "epoch:5 step:5374 [D loss: 0.535841, acc.: 76.56%] [G loss: 0.501121]\n",
      "epoch:5 step:5375 [D loss: 0.486322, acc.: 77.34%] [G loss: 0.680998]\n",
      "epoch:5 step:5376 [D loss: 0.475754, acc.: 82.03%] [G loss: 0.718572]\n",
      "epoch:5 step:5377 [D loss: 0.565607, acc.: 71.09%] [G loss: 0.531511]\n",
      "epoch:5 step:5378 [D loss: 0.465416, acc.: 78.91%] [G loss: 0.601383]\n",
      "epoch:5 step:5379 [D loss: 0.482721, acc.: 73.44%] [G loss: 0.741012]\n",
      "epoch:5 step:5380 [D loss: 0.493276, acc.: 80.47%] [G loss: 0.645320]\n",
      "epoch:5 step:5381 [D loss: 0.621977, acc.: 65.62%] [G loss: 0.449191]\n",
      "epoch:5 step:5382 [D loss: 0.544946, acc.: 68.75%] [G loss: 0.611852]\n",
      "epoch:5 step:5383 [D loss: 0.501240, acc.: 76.56%] [G loss: 0.707173]\n",
      "epoch:5 step:5384 [D loss: 0.524900, acc.: 74.22%] [G loss: 0.628772]\n",
      "epoch:5 step:5385 [D loss: 0.551634, acc.: 75.00%] [G loss: 0.618538]\n",
      "epoch:5 step:5386 [D loss: 0.520180, acc.: 73.44%] [G loss: 0.567197]\n",
      "epoch:5 step:5387 [D loss: 0.562703, acc.: 70.31%] [G loss: 0.588782]\n",
      "epoch:5 step:5388 [D loss: 0.620832, acc.: 64.84%] [G loss: 0.678547]\n",
      "epoch:5 step:5389 [D loss: 0.620216, acc.: 64.84%] [G loss: 0.502426]\n",
      "epoch:5 step:5390 [D loss: 0.624589, acc.: 64.06%] [G loss: 0.492171]\n",
      "epoch:5 step:5391 [D loss: 0.560767, acc.: 69.53%] [G loss: 0.453292]\n",
      "epoch:5 step:5392 [D loss: 0.470546, acc.: 81.25%] [G loss: 0.622422]\n",
      "epoch:5 step:5393 [D loss: 0.470325, acc.: 78.91%] [G loss: 0.804366]\n",
      "epoch:5 step:5394 [D loss: 0.531537, acc.: 74.22%] [G loss: 0.626009]\n",
      "epoch:5 step:5395 [D loss: 0.616868, acc.: 70.31%] [G loss: 0.522352]\n",
      "epoch:5 step:5396 [D loss: 0.526362, acc.: 74.22%] [G loss: 0.456329]\n",
      "epoch:5 step:5397 [D loss: 0.557707, acc.: 69.53%] [G loss: 0.533317]\n",
      "epoch:5 step:5398 [D loss: 0.538375, acc.: 71.09%] [G loss: 0.488007]\n",
      "epoch:5 step:5399 [D loss: 0.529680, acc.: 78.12%] [G loss: 0.527620]\n",
      "epoch:5 step:5400 [D loss: 0.540739, acc.: 74.22%] [G loss: 0.523578]\n",
      "##############\n",
      "[3.615729   1.68011747 6.80035543 4.92189074 4.38416437 6.09251698\n",
      " 5.08058376 5.08887199 4.87066229 4.00697756]\n",
      "##########\n",
      "epoch:5 step:5401 [D loss: 0.601185, acc.: 66.41%] [G loss: 0.470466]\n",
      "epoch:5 step:5402 [D loss: 0.648920, acc.: 60.16%] [G loss: 0.438381]\n",
      "epoch:5 step:5403 [D loss: 0.600848, acc.: 67.19%] [G loss: 0.404392]\n",
      "epoch:5 step:5404 [D loss: 0.503079, acc.: 74.22%] [G loss: 0.509050]\n",
      "epoch:5 step:5405 [D loss: 0.600014, acc.: 66.41%] [G loss: 0.554541]\n",
      "epoch:5 step:5406 [D loss: 0.594719, acc.: 63.28%] [G loss: 0.499004]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:5 step:5407 [D loss: 0.542327, acc.: 71.09%] [G loss: 0.610238]\n",
      "epoch:5 step:5408 [D loss: 0.576560, acc.: 69.53%] [G loss: 0.526112]\n",
      "epoch:5 step:5409 [D loss: 0.511053, acc.: 75.00%] [G loss: 0.500705]\n",
      "epoch:5 step:5410 [D loss: 0.473941, acc.: 80.47%] [G loss: 0.657283]\n",
      "epoch:5 step:5411 [D loss: 0.534655, acc.: 73.44%] [G loss: 0.620749]\n",
      "epoch:5 step:5412 [D loss: 0.590035, acc.: 69.53%] [G loss: 0.463279]\n",
      "epoch:5 step:5413 [D loss: 0.538445, acc.: 71.09%] [G loss: 0.418158]\n",
      "epoch:5 step:5414 [D loss: 0.559356, acc.: 75.78%] [G loss: 0.557966]\n",
      "epoch:5 step:5415 [D loss: 0.507286, acc.: 75.00%] [G loss: 0.603591]\n",
      "epoch:5 step:5416 [D loss: 0.568468, acc.: 68.75%] [G loss: 0.474929]\n",
      "epoch:5 step:5417 [D loss: 0.498541, acc.: 76.56%] [G loss: 0.656535]\n",
      "epoch:5 step:5418 [D loss: 0.487028, acc.: 76.56%] [G loss: 0.770949]\n",
      "epoch:5 step:5419 [D loss: 0.523867, acc.: 75.00%] [G loss: 0.628553]\n",
      "epoch:5 step:5420 [D loss: 0.586944, acc.: 66.41%] [G loss: 0.660857]\n",
      "epoch:5 step:5421 [D loss: 0.456456, acc.: 76.56%] [G loss: 0.641873]\n",
      "epoch:5 step:5422 [D loss: 0.468062, acc.: 78.91%] [G loss: 0.566933]\n",
      "epoch:5 step:5423 [D loss: 0.642818, acc.: 62.50%] [G loss: 0.512619]\n",
      "epoch:5 step:5424 [D loss: 0.614597, acc.: 62.50%] [G loss: 0.496175]\n",
      "epoch:5 step:5425 [D loss: 0.620384, acc.: 61.72%] [G loss: 0.441274]\n",
      "epoch:5 step:5426 [D loss: 0.549976, acc.: 77.34%] [G loss: 0.441138]\n",
      "epoch:5 step:5427 [D loss: 0.566289, acc.: 70.31%] [G loss: 0.571492]\n",
      "epoch:5 step:5428 [D loss: 0.485006, acc.: 74.22%] [G loss: 0.563376]\n",
      "epoch:5 step:5429 [D loss: 0.522540, acc.: 74.22%] [G loss: 0.603456]\n",
      "epoch:5 step:5430 [D loss: 0.576029, acc.: 67.97%] [G loss: 0.517207]\n",
      "epoch:5 step:5431 [D loss: 0.471986, acc.: 80.47%] [G loss: 0.566777]\n",
      "epoch:5 step:5432 [D loss: 0.420753, acc.: 83.59%] [G loss: 0.731383]\n",
      "epoch:5 step:5433 [D loss: 0.538108, acc.: 68.75%] [G loss: 0.648461]\n",
      "epoch:5 step:5434 [D loss: 0.579110, acc.: 63.28%] [G loss: 0.572086]\n",
      "epoch:5 step:5435 [D loss: 0.516299, acc.: 71.88%] [G loss: 0.693299]\n",
      "epoch:5 step:5436 [D loss: 0.510798, acc.: 77.34%] [G loss: 0.659312]\n",
      "epoch:5 step:5437 [D loss: 0.534874, acc.: 73.44%] [G loss: 0.561667]\n",
      "epoch:5 step:5438 [D loss: 0.538766, acc.: 66.41%] [G loss: 0.561269]\n",
      "epoch:5 step:5439 [D loss: 0.500069, acc.: 72.66%] [G loss: 0.683029]\n",
      "epoch:5 step:5440 [D loss: 0.538080, acc.: 75.00%] [G loss: 0.600019]\n",
      "epoch:5 step:5441 [D loss: 0.528114, acc.: 74.22%] [G loss: 0.515593]\n",
      "epoch:5 step:5442 [D loss: 0.579070, acc.: 67.19%] [G loss: 0.765870]\n",
      "epoch:5 step:5443 [D loss: 0.511447, acc.: 71.88%] [G loss: 0.671407]\n",
      "epoch:5 step:5444 [D loss: 0.534718, acc.: 74.22%] [G loss: 0.657758]\n",
      "epoch:5 step:5445 [D loss: 0.568138, acc.: 66.41%] [G loss: 0.479071]\n",
      "epoch:5 step:5446 [D loss: 0.570718, acc.: 71.88%] [G loss: 0.592483]\n",
      "epoch:5 step:5447 [D loss: 0.540285, acc.: 70.31%] [G loss: 0.637388]\n",
      "epoch:5 step:5448 [D loss: 0.554718, acc.: 72.66%] [G loss: 0.379807]\n",
      "epoch:5 step:5449 [D loss: 0.504147, acc.: 73.44%] [G loss: 0.573751]\n",
      "epoch:5 step:5450 [D loss: 0.586897, acc.: 69.53%] [G loss: 0.492587]\n",
      "epoch:5 step:5451 [D loss: 0.682017, acc.: 63.28%] [G loss: 0.385550]\n",
      "epoch:5 step:5452 [D loss: 0.495141, acc.: 77.34%] [G loss: 0.517446]\n",
      "epoch:5 step:5453 [D loss: 0.528353, acc.: 70.31%] [G loss: 0.706247]\n",
      "epoch:5 step:5454 [D loss: 0.493926, acc.: 76.56%] [G loss: 0.635999]\n",
      "epoch:5 step:5455 [D loss: 0.484870, acc.: 75.78%] [G loss: 0.485998]\n",
      "epoch:5 step:5456 [D loss: 0.523179, acc.: 69.53%] [G loss: 0.701662]\n",
      "epoch:5 step:5457 [D loss: 0.524326, acc.: 71.88%] [G loss: 0.594745]\n",
      "epoch:5 step:5458 [D loss: 0.543917, acc.: 67.97%] [G loss: 0.477897]\n",
      "epoch:5 step:5459 [D loss: 0.603123, acc.: 67.19%] [G loss: 0.493310]\n",
      "epoch:5 step:5460 [D loss: 0.517250, acc.: 73.44%] [G loss: 0.592751]\n",
      "epoch:5 step:5461 [D loss: 0.571102, acc.: 71.09%] [G loss: 0.498595]\n",
      "epoch:5 step:5462 [D loss: 0.514675, acc.: 74.22%] [G loss: 0.500543]\n",
      "epoch:5 step:5463 [D loss: 0.507622, acc.: 78.91%] [G loss: 0.474900]\n",
      "epoch:5 step:5464 [D loss: 0.575961, acc.: 67.97%] [G loss: 0.558609]\n",
      "epoch:5 step:5465 [D loss: 0.447234, acc.: 82.03%] [G loss: 0.735288]\n",
      "epoch:5 step:5466 [D loss: 0.486805, acc.: 73.44%] [G loss: 0.668626]\n",
      "epoch:5 step:5467 [D loss: 0.508540, acc.: 74.22%] [G loss: 0.754565]\n",
      "epoch:5 step:5468 [D loss: 0.527314, acc.: 73.44%] [G loss: 0.657316]\n",
      "epoch:5 step:5469 [D loss: 0.563384, acc.: 67.97%] [G loss: 0.492117]\n",
      "epoch:5 step:5470 [D loss: 0.521407, acc.: 71.09%] [G loss: 0.499802]\n",
      "epoch:5 step:5471 [D loss: 0.514355, acc.: 75.00%] [G loss: 0.494952]\n",
      "epoch:5 step:5472 [D loss: 0.592379, acc.: 67.97%] [G loss: 0.537189]\n",
      "epoch:5 step:5473 [D loss: 0.633092, acc.: 64.06%] [G loss: 0.378898]\n",
      "epoch:5 step:5474 [D loss: 0.513531, acc.: 74.22%] [G loss: 0.467298]\n",
      "epoch:5 step:5475 [D loss: 0.619397, acc.: 64.84%] [G loss: 0.431890]\n",
      "epoch:5 step:5476 [D loss: 0.541428, acc.: 68.75%] [G loss: 0.558591]\n",
      "epoch:5 step:5477 [D loss: 0.470397, acc.: 79.69%] [G loss: 0.592452]\n",
      "epoch:5 step:5478 [D loss: 0.610129, acc.: 67.97%] [G loss: 0.566356]\n",
      "epoch:5 step:5479 [D loss: 0.560880, acc.: 71.09%] [G loss: 0.683662]\n",
      "epoch:5 step:5480 [D loss: 0.539184, acc.: 73.44%] [G loss: 0.653211]\n",
      "epoch:5 step:5481 [D loss: 0.476094, acc.: 75.78%] [G loss: 0.563295]\n",
      "epoch:5 step:5482 [D loss: 0.541880, acc.: 71.09%] [G loss: 0.550629]\n",
      "epoch:5 step:5483 [D loss: 0.494699, acc.: 72.66%] [G loss: 0.492049]\n",
      "epoch:5 step:5484 [D loss: 0.572382, acc.: 67.19%] [G loss: 0.521165]\n",
      "epoch:5 step:5485 [D loss: 0.506679, acc.: 75.00%] [G loss: 0.630956]\n",
      "epoch:5 step:5486 [D loss: 0.511603, acc.: 78.12%] [G loss: 0.596202]\n",
      "epoch:5 step:5487 [D loss: 0.494485, acc.: 74.22%] [G loss: 0.618378]\n",
      "epoch:5 step:5488 [D loss: 0.498067, acc.: 75.78%] [G loss: 0.703488]\n",
      "epoch:5 step:5489 [D loss: 0.515730, acc.: 69.53%] [G loss: 0.561236]\n",
      "epoch:5 step:5490 [D loss: 0.501748, acc.: 74.22%] [G loss: 0.505211]\n",
      "epoch:5 step:5491 [D loss: 0.521175, acc.: 72.66%] [G loss: 0.582444]\n",
      "epoch:5 step:5492 [D loss: 0.496364, acc.: 78.12%] [G loss: 0.643908]\n",
      "epoch:5 step:5493 [D loss: 0.620905, acc.: 67.19%] [G loss: 0.483222]\n",
      "epoch:5 step:5494 [D loss: 0.543436, acc.: 72.66%] [G loss: 0.498731]\n",
      "epoch:5 step:5495 [D loss: 0.519650, acc.: 74.22%] [G loss: 0.570762]\n",
      "epoch:5 step:5496 [D loss: 0.516822, acc.: 75.78%] [G loss: 0.551303]\n",
      "epoch:5 step:5497 [D loss: 0.636344, acc.: 64.84%] [G loss: 0.425540]\n",
      "epoch:5 step:5498 [D loss: 0.514609, acc.: 74.22%] [G loss: 0.519841]\n",
      "epoch:5 step:5499 [D loss: 0.515423, acc.: 69.53%] [G loss: 0.515155]\n",
      "epoch:5 step:5500 [D loss: 0.510021, acc.: 78.91%] [G loss: 0.682316]\n",
      "epoch:5 step:5501 [D loss: 0.539914, acc.: 68.75%] [G loss: 0.753293]\n",
      "epoch:5 step:5502 [D loss: 0.619363, acc.: 65.62%] [G loss: 0.537838]\n",
      "epoch:5 step:5503 [D loss: 0.551282, acc.: 75.00%] [G loss: 0.551069]\n",
      "epoch:5 step:5504 [D loss: 0.537796, acc.: 75.00%] [G loss: 0.461706]\n",
      "epoch:5 step:5505 [D loss: 0.606787, acc.: 67.19%] [G loss: 0.566814]\n",
      "epoch:5 step:5506 [D loss: 0.512772, acc.: 75.78%] [G loss: 0.482636]\n",
      "epoch:5 step:5507 [D loss: 0.486085, acc.: 76.56%] [G loss: 0.612507]\n",
      "epoch:5 step:5508 [D loss: 0.470462, acc.: 75.00%] [G loss: 0.556200]\n",
      "epoch:5 step:5509 [D loss: 0.639531, acc.: 64.84%] [G loss: 0.572203]\n",
      "epoch:5 step:5510 [D loss: 0.566556, acc.: 66.41%] [G loss: 0.480850]\n",
      "epoch:5 step:5511 [D loss: 0.564914, acc.: 68.75%] [G loss: 0.525026]\n",
      "epoch:5 step:5512 [D loss: 0.594881, acc.: 65.62%] [G loss: 0.458790]\n",
      "epoch:5 step:5513 [D loss: 0.609835, acc.: 67.19%] [G loss: 0.491512]\n",
      "epoch:5 step:5514 [D loss: 0.549394, acc.: 70.31%] [G loss: 0.468277]\n",
      "epoch:5 step:5515 [D loss: 0.543513, acc.: 72.66%] [G loss: 0.543083]\n",
      "epoch:5 step:5516 [D loss: 0.519481, acc.: 71.09%] [G loss: 0.551909]\n",
      "epoch:5 step:5517 [D loss: 0.518438, acc.: 75.00%] [G loss: 0.501978]\n",
      "epoch:5 step:5518 [D loss: 0.479401, acc.: 82.03%] [G loss: 0.681539]\n",
      "epoch:5 step:5519 [D loss: 0.531718, acc.: 68.75%] [G loss: 0.513657]\n",
      "epoch:5 step:5520 [D loss: 0.516979, acc.: 77.34%] [G loss: 0.489067]\n",
      "epoch:5 step:5521 [D loss: 0.582905, acc.: 66.41%] [G loss: 0.460177]\n",
      "epoch:5 step:5522 [D loss: 0.516102, acc.: 73.44%] [G loss: 0.592574]\n",
      "epoch:5 step:5523 [D loss: 0.497535, acc.: 75.78%] [G loss: 0.504384]\n",
      "epoch:5 step:5524 [D loss: 0.590262, acc.: 64.06%] [G loss: 0.491321]\n",
      "epoch:5 step:5525 [D loss: 0.572375, acc.: 68.75%] [G loss: 0.462466]\n",
      "epoch:5 step:5526 [D loss: 0.535240, acc.: 73.44%] [G loss: 0.582273]\n",
      "epoch:5 step:5527 [D loss: 0.507847, acc.: 72.66%] [G loss: 0.597341]\n",
      "epoch:5 step:5528 [D loss: 0.517331, acc.: 71.88%] [G loss: 0.536643]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:5 step:5529 [D loss: 0.590559, acc.: 66.41%] [G loss: 0.563916]\n",
      "epoch:5 step:5530 [D loss: 0.606408, acc.: 59.38%] [G loss: 0.494091]\n",
      "epoch:5 step:5531 [D loss: 0.568520, acc.: 68.75%] [G loss: 0.504452]\n",
      "epoch:5 step:5532 [D loss: 0.577900, acc.: 67.19%] [G loss: 0.395358]\n",
      "epoch:5 step:5533 [D loss: 0.508381, acc.: 71.09%] [G loss: 0.461211]\n",
      "epoch:5 step:5534 [D loss: 0.515879, acc.: 76.56%] [G loss: 0.488333]\n",
      "epoch:5 step:5535 [D loss: 0.527680, acc.: 69.53%] [G loss: 0.405495]\n",
      "epoch:5 step:5536 [D loss: 0.553238, acc.: 67.19%] [G loss: 0.516230]\n",
      "epoch:5 step:5537 [D loss: 0.476413, acc.: 77.34%] [G loss: 0.549899]\n",
      "epoch:5 step:5538 [D loss: 0.506260, acc.: 73.44%] [G loss: 0.641182]\n",
      "epoch:5 step:5539 [D loss: 0.475937, acc.: 82.03%] [G loss: 0.657570]\n",
      "epoch:5 step:5540 [D loss: 0.486023, acc.: 76.56%] [G loss: 0.679856]\n",
      "epoch:5 step:5541 [D loss: 0.658433, acc.: 61.72%] [G loss: 0.608985]\n",
      "epoch:5 step:5542 [D loss: 0.512126, acc.: 75.78%] [G loss: 0.691742]\n",
      "epoch:5 step:5543 [D loss: 0.726343, acc.: 56.25%] [G loss: 0.571991]\n",
      "epoch:5 step:5544 [D loss: 0.547803, acc.: 71.09%] [G loss: 0.708247]\n",
      "epoch:5 step:5545 [D loss: 0.441339, acc.: 78.91%] [G loss: 0.785947]\n",
      "epoch:5 step:5546 [D loss: 0.666329, acc.: 62.50%] [G loss: 0.524370]\n",
      "epoch:5 step:5547 [D loss: 0.641433, acc.: 63.28%] [G loss: 0.505321]\n",
      "epoch:5 step:5548 [D loss: 0.538068, acc.: 69.53%] [G loss: 0.477052]\n",
      "epoch:5 step:5549 [D loss: 0.549629, acc.: 70.31%] [G loss: 0.401259]\n",
      "epoch:5 step:5550 [D loss: 0.537182, acc.: 67.97%] [G loss: 0.543112]\n",
      "epoch:5 step:5551 [D loss: 0.557555, acc.: 70.31%] [G loss: 0.624058]\n",
      "epoch:5 step:5552 [D loss: 0.646380, acc.: 67.19%] [G loss: 0.419716]\n",
      "epoch:5 step:5553 [D loss: 0.556496, acc.: 75.00%] [G loss: 0.424387]\n",
      "epoch:5 step:5554 [D loss: 0.579137, acc.: 69.53%] [G loss: 0.442174]\n",
      "epoch:5 step:5555 [D loss: 0.505494, acc.: 71.09%] [G loss: 0.471942]\n",
      "epoch:5 step:5556 [D loss: 0.473315, acc.: 76.56%] [G loss: 0.710320]\n",
      "epoch:5 step:5557 [D loss: 0.530902, acc.: 71.88%] [G loss: 0.579647]\n",
      "epoch:5 step:5558 [D loss: 0.599951, acc.: 64.84%] [G loss: 0.518174]\n",
      "epoch:5 step:5559 [D loss: 0.559579, acc.: 70.31%] [G loss: 0.568468]\n",
      "epoch:5 step:5560 [D loss: 0.484678, acc.: 75.00%] [G loss: 0.583244]\n",
      "epoch:5 step:5561 [D loss: 0.497420, acc.: 75.78%] [G loss: 0.577635]\n",
      "epoch:5 step:5562 [D loss: 0.536480, acc.: 72.66%] [G loss: 0.453272]\n",
      "epoch:5 step:5563 [D loss: 0.566185, acc.: 67.97%] [G loss: 0.572144]\n",
      "epoch:5 step:5564 [D loss: 0.562232, acc.: 70.31%] [G loss: 0.514143]\n",
      "epoch:5 step:5565 [D loss: 0.633154, acc.: 60.94%] [G loss: 0.348567]\n",
      "epoch:5 step:5566 [D loss: 0.569352, acc.: 65.62%] [G loss: 0.374890]\n",
      "epoch:5 step:5567 [D loss: 0.533085, acc.: 73.44%] [G loss: 0.482217]\n",
      "epoch:5 step:5568 [D loss: 0.592400, acc.: 67.19%] [G loss: 0.476153]\n",
      "epoch:5 step:5569 [D loss: 0.507911, acc.: 76.56%] [G loss: 0.532697]\n",
      "epoch:5 step:5570 [D loss: 0.541049, acc.: 71.09%] [G loss: 0.542686]\n",
      "epoch:5 step:5571 [D loss: 0.450186, acc.: 78.12%] [G loss: 0.631609]\n",
      "epoch:5 step:5572 [D loss: 0.508805, acc.: 73.44%] [G loss: 0.656633]\n",
      "epoch:5 step:5573 [D loss: 0.546292, acc.: 71.09%] [G loss: 0.612712]\n",
      "epoch:5 step:5574 [D loss: 0.515992, acc.: 72.66%] [G loss: 0.498998]\n",
      "epoch:5 step:5575 [D loss: 0.453621, acc.: 82.03%] [G loss: 0.665891]\n",
      "epoch:5 step:5576 [D loss: 0.633978, acc.: 66.41%] [G loss: 0.592649]\n",
      "epoch:5 step:5577 [D loss: 0.609527, acc.: 67.97%] [G loss: 0.628858]\n",
      "epoch:5 step:5578 [D loss: 0.571007, acc.: 68.75%] [G loss: 0.542123]\n",
      "epoch:5 step:5579 [D loss: 0.509591, acc.: 76.56%] [G loss: 0.643591]\n",
      "epoch:5 step:5580 [D loss: 0.506231, acc.: 80.47%] [G loss: 0.557807]\n",
      "epoch:5 step:5581 [D loss: 0.545480, acc.: 71.09%] [G loss: 0.689539]\n",
      "epoch:5 step:5582 [D loss: 0.505197, acc.: 76.56%] [G loss: 0.544553]\n",
      "epoch:5 step:5583 [D loss: 0.476601, acc.: 79.69%] [G loss: 0.663265]\n",
      "epoch:5 step:5584 [D loss: 0.527950, acc.: 72.66%] [G loss: 0.622246]\n",
      "epoch:5 step:5585 [D loss: 0.495389, acc.: 82.03%] [G loss: 0.641073]\n",
      "epoch:5 step:5586 [D loss: 0.552570, acc.: 69.53%] [G loss: 0.535934]\n",
      "epoch:5 step:5587 [D loss: 0.598444, acc.: 63.28%] [G loss: 0.496789]\n",
      "epoch:5 step:5588 [D loss: 0.523127, acc.: 69.53%] [G loss: 0.449417]\n",
      "epoch:5 step:5589 [D loss: 0.511913, acc.: 77.34%] [G loss: 0.532584]\n",
      "epoch:5 step:5590 [D loss: 0.612486, acc.: 64.84%] [G loss: 0.620126]\n",
      "epoch:5 step:5591 [D loss: 0.503934, acc.: 75.78%] [G loss: 0.674670]\n",
      "epoch:5 step:5592 [D loss: 0.565518, acc.: 67.97%] [G loss: 0.580673]\n",
      "epoch:5 step:5593 [D loss: 0.550179, acc.: 67.19%] [G loss: 0.591002]\n",
      "epoch:5 step:5594 [D loss: 0.483931, acc.: 78.91%] [G loss: 0.667438]\n",
      "epoch:5 step:5595 [D loss: 0.475217, acc.: 76.56%] [G loss: 0.592670]\n",
      "epoch:5 step:5596 [D loss: 0.497252, acc.: 74.22%] [G loss: 0.743348]\n",
      "epoch:5 step:5597 [D loss: 0.461036, acc.: 78.12%] [G loss: 0.826787]\n",
      "epoch:5 step:5598 [D loss: 0.562889, acc.: 68.75%] [G loss: 0.859519]\n",
      "epoch:5 step:5599 [D loss: 0.519304, acc.: 73.44%] [G loss: 0.759162]\n",
      "epoch:5 step:5600 [D loss: 0.636409, acc.: 62.50%] [G loss: 0.507061]\n",
      "##############\n",
      "[3.36963337 2.08894592 6.88708103 5.04864554 3.96906926 5.98958378\n",
      " 5.03423761 4.88760855 4.9006284  3.72777262]\n",
      "##########\n",
      "epoch:5 step:5601 [D loss: 0.498958, acc.: 75.78%] [G loss: 0.605425]\n",
      "epoch:5 step:5602 [D loss: 0.634893, acc.: 64.06%] [G loss: 0.614462]\n",
      "epoch:5 step:5603 [D loss: 0.522860, acc.: 72.66%] [G loss: 0.634781]\n",
      "epoch:5 step:5604 [D loss: 0.515761, acc.: 72.66%] [G loss: 0.664920]\n",
      "epoch:5 step:5605 [D loss: 0.656777, acc.: 62.50%] [G loss: 0.546808]\n",
      "epoch:5 step:5606 [D loss: 0.415702, acc.: 84.38%] [G loss: 0.852950]\n",
      "epoch:5 step:5607 [D loss: 0.549209, acc.: 67.19%] [G loss: 0.752247]\n",
      "epoch:5 step:5608 [D loss: 0.452217, acc.: 79.69%] [G loss: 0.648681]\n",
      "epoch:5 step:5609 [D loss: 0.435001, acc.: 78.91%] [G loss: 0.720584]\n",
      "epoch:5 step:5610 [D loss: 0.381528, acc.: 83.59%] [G loss: 0.837337]\n",
      "epoch:5 step:5611 [D loss: 0.465029, acc.: 82.03%] [G loss: 1.121246]\n",
      "epoch:5 step:5612 [D loss: 0.446087, acc.: 76.56%] [G loss: 1.026949]\n",
      "epoch:5 step:5613 [D loss: 0.775692, acc.: 59.38%] [G loss: 0.850749]\n",
      "epoch:5 step:5614 [D loss: 0.455863, acc.: 80.47%] [G loss: 0.993232]\n",
      "epoch:5 step:5615 [D loss: 0.492078, acc.: 74.22%] [G loss: 1.035298]\n",
      "epoch:5 step:5616 [D loss: 0.542393, acc.: 68.75%] [G loss: 0.750560]\n",
      "epoch:5 step:5617 [D loss: 0.576834, acc.: 68.75%] [G loss: 0.760713]\n",
      "epoch:5 step:5618 [D loss: 0.475304, acc.: 78.91%] [G loss: 0.698813]\n",
      "epoch:5 step:5619 [D loss: 0.544091, acc.: 68.75%] [G loss: 0.733605]\n",
      "epoch:5 step:5620 [D loss: 0.467703, acc.: 77.34%] [G loss: 0.820565]\n",
      "epoch:5 step:5621 [D loss: 0.389625, acc.: 84.38%] [G loss: 0.928218]\n",
      "epoch:5 step:5622 [D loss: 0.412402, acc.: 85.94%] [G loss: 0.751737]\n",
      "epoch:6 step:5623 [D loss: 0.600243, acc.: 68.75%] [G loss: 0.784218]\n",
      "epoch:6 step:5624 [D loss: 0.564708, acc.: 67.19%] [G loss: 0.784131]\n",
      "epoch:6 step:5625 [D loss: 0.550952, acc.: 73.44%] [G loss: 0.782413]\n",
      "epoch:6 step:5626 [D loss: 0.599752, acc.: 64.06%] [G loss: 0.560321]\n",
      "epoch:6 step:5627 [D loss: 0.550057, acc.: 67.19%] [G loss: 0.531908]\n",
      "epoch:6 step:5628 [D loss: 0.520466, acc.: 72.66%] [G loss: 0.585584]\n",
      "epoch:6 step:5629 [D loss: 0.497598, acc.: 77.34%] [G loss: 0.703468]\n",
      "epoch:6 step:5630 [D loss: 0.557580, acc.: 69.53%] [G loss: 0.691777]\n",
      "epoch:6 step:5631 [D loss: 0.555836, acc.: 69.53%] [G loss: 0.657053]\n",
      "epoch:6 step:5632 [D loss: 0.535806, acc.: 72.66%] [G loss: 0.562385]\n",
      "epoch:6 step:5633 [D loss: 0.487389, acc.: 77.34%] [G loss: 0.722745]\n",
      "epoch:6 step:5634 [D loss: 0.561168, acc.: 67.97%] [G loss: 0.593669]\n",
      "epoch:6 step:5635 [D loss: 0.545411, acc.: 71.09%] [G loss: 0.399790]\n",
      "epoch:6 step:5636 [D loss: 0.519841, acc.: 75.00%] [G loss: 0.622302]\n",
      "epoch:6 step:5637 [D loss: 0.528097, acc.: 74.22%] [G loss: 0.476480]\n",
      "epoch:6 step:5638 [D loss: 0.486944, acc.: 77.34%] [G loss: 0.606484]\n",
      "epoch:6 step:5639 [D loss: 0.624147, acc.: 64.06%] [G loss: 0.550062]\n",
      "epoch:6 step:5640 [D loss: 0.580973, acc.: 68.75%] [G loss: 0.559080]\n",
      "epoch:6 step:5641 [D loss: 0.606833, acc.: 63.28%] [G loss: 0.491221]\n",
      "epoch:6 step:5642 [D loss: 0.552420, acc.: 71.88%] [G loss: 0.619269]\n",
      "epoch:6 step:5643 [D loss: 0.558030, acc.: 74.22%] [G loss: 0.653390]\n",
      "epoch:6 step:5644 [D loss: 0.466903, acc.: 81.25%] [G loss: 0.540067]\n",
      "epoch:6 step:5645 [D loss: 0.506340, acc.: 75.78%] [G loss: 0.615866]\n",
      "epoch:6 step:5646 [D loss: 0.523676, acc.: 75.78%] [G loss: 0.654526]\n",
      "epoch:6 step:5647 [D loss: 0.478900, acc.: 76.56%] [G loss: 0.669046]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:6 step:5648 [D loss: 0.546373, acc.: 69.53%] [G loss: 0.485553]\n",
      "epoch:6 step:5649 [D loss: 0.527984, acc.: 69.53%] [G loss: 0.494642]\n",
      "epoch:6 step:5650 [D loss: 0.536188, acc.: 68.75%] [G loss: 0.636783]\n",
      "epoch:6 step:5651 [D loss: 0.537009, acc.: 70.31%] [G loss: 0.568489]\n",
      "epoch:6 step:5652 [D loss: 0.549930, acc.: 75.78%] [G loss: 0.533155]\n",
      "epoch:6 step:5653 [D loss: 0.542551, acc.: 72.66%] [G loss: 0.509502]\n",
      "epoch:6 step:5654 [D loss: 0.523151, acc.: 69.53%] [G loss: 0.739719]\n",
      "epoch:6 step:5655 [D loss: 0.498892, acc.: 76.56%] [G loss: 0.483529]\n",
      "epoch:6 step:5656 [D loss: 0.488995, acc.: 73.44%] [G loss: 0.527268]\n",
      "epoch:6 step:5657 [D loss: 0.566346, acc.: 67.97%] [G loss: 0.643834]\n",
      "epoch:6 step:5658 [D loss: 0.522381, acc.: 76.56%] [G loss: 0.575387]\n",
      "epoch:6 step:5659 [D loss: 0.509707, acc.: 75.00%] [G loss: 0.606662]\n",
      "epoch:6 step:5660 [D loss: 0.606245, acc.: 70.31%] [G loss: 0.400935]\n",
      "epoch:6 step:5661 [D loss: 0.489694, acc.: 75.00%] [G loss: 0.460159]\n",
      "epoch:6 step:5662 [D loss: 0.415335, acc.: 79.69%] [G loss: 0.692690]\n",
      "epoch:6 step:5663 [D loss: 0.507259, acc.: 77.34%] [G loss: 0.569167]\n",
      "epoch:6 step:5664 [D loss: 0.538339, acc.: 71.09%] [G loss: 0.590749]\n",
      "epoch:6 step:5665 [D loss: 0.529167, acc.: 73.44%] [G loss: 0.562727]\n",
      "epoch:6 step:5666 [D loss: 0.567625, acc.: 67.97%] [G loss: 0.598990]\n",
      "epoch:6 step:5667 [D loss: 0.493487, acc.: 75.00%] [G loss: 0.529358]\n",
      "epoch:6 step:5668 [D loss: 0.509859, acc.: 74.22%] [G loss: 0.478079]\n",
      "epoch:6 step:5669 [D loss: 0.546208, acc.: 73.44%] [G loss: 0.545335]\n",
      "epoch:6 step:5670 [D loss: 0.546296, acc.: 71.88%] [G loss: 0.560271]\n",
      "epoch:6 step:5671 [D loss: 0.525895, acc.: 71.09%] [G loss: 0.584022]\n",
      "epoch:6 step:5672 [D loss: 0.546575, acc.: 70.31%] [G loss: 0.560203]\n",
      "epoch:6 step:5673 [D loss: 0.586768, acc.: 71.09%] [G loss: 0.386185]\n",
      "epoch:6 step:5674 [D loss: 0.600373, acc.: 63.28%] [G loss: 0.489855]\n",
      "epoch:6 step:5675 [D loss: 0.516891, acc.: 78.91%] [G loss: 0.574604]\n",
      "epoch:6 step:5676 [D loss: 0.478741, acc.: 78.91%] [G loss: 0.650380]\n",
      "epoch:6 step:5677 [D loss: 0.508559, acc.: 77.34%] [G loss: 0.543698]\n",
      "epoch:6 step:5678 [D loss: 0.488850, acc.: 80.47%] [G loss: 0.496533]\n",
      "epoch:6 step:5679 [D loss: 0.494305, acc.: 78.91%] [G loss: 0.484037]\n",
      "epoch:6 step:5680 [D loss: 0.576391, acc.: 66.41%] [G loss: 0.561275]\n",
      "epoch:6 step:5681 [D loss: 0.510316, acc.: 74.22%] [G loss: 0.715582]\n",
      "epoch:6 step:5682 [D loss: 0.544328, acc.: 66.41%] [G loss: 0.731233]\n",
      "epoch:6 step:5683 [D loss: 0.539865, acc.: 68.75%] [G loss: 0.583169]\n",
      "epoch:6 step:5684 [D loss: 0.553120, acc.: 69.53%] [G loss: 0.578738]\n",
      "epoch:6 step:5685 [D loss: 0.547945, acc.: 67.19%] [G loss: 0.537418]\n",
      "epoch:6 step:5686 [D loss: 0.520028, acc.: 69.53%] [G loss: 0.524445]\n",
      "epoch:6 step:5687 [D loss: 0.571262, acc.: 71.88%] [G loss: 0.447584]\n",
      "epoch:6 step:5688 [D loss: 0.501056, acc.: 75.00%] [G loss: 0.620842]\n",
      "epoch:6 step:5689 [D loss: 0.571485, acc.: 70.31%] [G loss: 0.498100]\n",
      "epoch:6 step:5690 [D loss: 0.555286, acc.: 67.19%] [G loss: 0.475216]\n",
      "epoch:6 step:5691 [D loss: 0.589230, acc.: 69.53%] [G loss: 0.484934]\n",
      "epoch:6 step:5692 [D loss: 0.505845, acc.: 76.56%] [G loss: 0.682878]\n",
      "epoch:6 step:5693 [D loss: 0.500875, acc.: 75.00%] [G loss: 0.511214]\n",
      "epoch:6 step:5694 [D loss: 0.471297, acc.: 79.69%] [G loss: 0.614515]\n",
      "epoch:6 step:5695 [D loss: 0.533719, acc.: 67.97%] [G loss: 0.531016]\n",
      "epoch:6 step:5696 [D loss: 0.502050, acc.: 75.00%] [G loss: 0.500546]\n",
      "epoch:6 step:5697 [D loss: 0.498217, acc.: 76.56%] [G loss: 0.676326]\n",
      "epoch:6 step:5698 [D loss: 0.519263, acc.: 69.53%] [G loss: 0.845562]\n",
      "epoch:6 step:5699 [D loss: 0.444592, acc.: 76.56%] [G loss: 0.773205]\n",
      "epoch:6 step:5700 [D loss: 0.598314, acc.: 65.62%] [G loss: 0.494124]\n",
      "epoch:6 step:5701 [D loss: 0.555339, acc.: 67.97%] [G loss: 0.535745]\n",
      "epoch:6 step:5702 [D loss: 0.575119, acc.: 68.75%] [G loss: 0.515077]\n",
      "epoch:6 step:5703 [D loss: 0.540700, acc.: 71.09%] [G loss: 0.558243]\n",
      "epoch:6 step:5704 [D loss: 0.501906, acc.: 78.12%] [G loss: 0.521299]\n",
      "epoch:6 step:5705 [D loss: 0.527461, acc.: 73.44%] [G loss: 0.528287]\n",
      "epoch:6 step:5706 [D loss: 0.525777, acc.: 71.09%] [G loss: 0.626710]\n",
      "epoch:6 step:5707 [D loss: 0.555422, acc.: 73.44%] [G loss: 0.562747]\n",
      "epoch:6 step:5708 [D loss: 0.540623, acc.: 75.78%] [G loss: 0.486589]\n",
      "epoch:6 step:5709 [D loss: 0.528226, acc.: 73.44%] [G loss: 0.500704]\n",
      "epoch:6 step:5710 [D loss: 0.511202, acc.: 74.22%] [G loss: 0.431640]\n",
      "epoch:6 step:5711 [D loss: 0.496874, acc.: 73.44%] [G loss: 0.627443]\n",
      "epoch:6 step:5712 [D loss: 0.495435, acc.: 78.12%] [G loss: 0.610997]\n",
      "epoch:6 step:5713 [D loss: 0.527355, acc.: 71.88%] [G loss: 0.679013]\n",
      "epoch:6 step:5714 [D loss: 0.486039, acc.: 81.25%] [G loss: 0.583778]\n",
      "epoch:6 step:5715 [D loss: 0.524216, acc.: 75.78%] [G loss: 0.539127]\n",
      "epoch:6 step:5716 [D loss: 0.501575, acc.: 75.00%] [G loss: 0.637764]\n",
      "epoch:6 step:5717 [D loss: 0.571455, acc.: 68.75%] [G loss: 0.493321]\n",
      "epoch:6 step:5718 [D loss: 0.438913, acc.: 81.25%] [G loss: 0.555262]\n",
      "epoch:6 step:5719 [D loss: 0.552724, acc.: 71.88%] [G loss: 0.597986]\n",
      "epoch:6 step:5720 [D loss: 0.511150, acc.: 76.56%] [G loss: 0.692776]\n",
      "epoch:6 step:5721 [D loss: 0.540520, acc.: 72.66%] [G loss: 0.572692]\n",
      "epoch:6 step:5722 [D loss: 0.449240, acc.: 80.47%] [G loss: 0.756597]\n",
      "epoch:6 step:5723 [D loss: 0.514325, acc.: 74.22%] [G loss: 0.597450]\n",
      "epoch:6 step:5724 [D loss: 0.612703, acc.: 62.50%] [G loss: 0.684386]\n",
      "epoch:6 step:5725 [D loss: 0.557462, acc.: 67.97%] [G loss: 0.451933]\n",
      "epoch:6 step:5726 [D loss: 0.490223, acc.: 74.22%] [G loss: 0.516633]\n",
      "epoch:6 step:5727 [D loss: 0.600746, acc.: 62.50%] [G loss: 0.453930]\n",
      "epoch:6 step:5728 [D loss: 0.547957, acc.: 67.97%] [G loss: 0.542378]\n",
      "epoch:6 step:5729 [D loss: 0.601478, acc.: 62.50%] [G loss: 0.499783]\n",
      "epoch:6 step:5730 [D loss: 0.612018, acc.: 64.84%] [G loss: 0.565287]\n",
      "epoch:6 step:5731 [D loss: 0.570518, acc.: 66.41%] [G loss: 0.569222]\n",
      "epoch:6 step:5732 [D loss: 0.549222, acc.: 71.09%] [G loss: 0.494891]\n",
      "epoch:6 step:5733 [D loss: 0.480976, acc.: 75.78%] [G loss: 0.561302]\n",
      "epoch:6 step:5734 [D loss: 0.533660, acc.: 67.97%] [G loss: 0.573253]\n",
      "epoch:6 step:5735 [D loss: 0.566248, acc.: 69.53%] [G loss: 0.540703]\n",
      "epoch:6 step:5736 [D loss: 0.565863, acc.: 72.66%] [G loss: 0.498372]\n",
      "epoch:6 step:5737 [D loss: 0.552549, acc.: 71.09%] [G loss: 0.645578]\n",
      "epoch:6 step:5738 [D loss: 0.508670, acc.: 72.66%] [G loss: 0.562844]\n",
      "epoch:6 step:5739 [D loss: 0.517380, acc.: 71.88%] [G loss: 0.538040]\n",
      "epoch:6 step:5740 [D loss: 0.527570, acc.: 75.00%] [G loss: 0.639947]\n",
      "epoch:6 step:5741 [D loss: 0.426230, acc.: 82.81%] [G loss: 0.859901]\n",
      "epoch:6 step:5742 [D loss: 0.641949, acc.: 66.41%] [G loss: 0.643165]\n",
      "epoch:6 step:5743 [D loss: 0.552544, acc.: 73.44%] [G loss: 0.604610]\n",
      "epoch:6 step:5744 [D loss: 0.531487, acc.: 75.00%] [G loss: 0.649142]\n",
      "epoch:6 step:5745 [D loss: 0.536615, acc.: 73.44%] [G loss: 0.656915]\n",
      "epoch:6 step:5746 [D loss: 0.526246, acc.: 75.00%] [G loss: 0.522992]\n",
      "epoch:6 step:5747 [D loss: 0.568232, acc.: 70.31%] [G loss: 0.590600]\n",
      "epoch:6 step:5748 [D loss: 0.530979, acc.: 71.88%] [G loss: 0.563900]\n",
      "epoch:6 step:5749 [D loss: 0.500498, acc.: 75.00%] [G loss: 0.578591]\n",
      "epoch:6 step:5750 [D loss: 0.480837, acc.: 75.00%] [G loss: 0.438259]\n",
      "epoch:6 step:5751 [D loss: 0.573978, acc.: 66.41%] [G loss: 0.491000]\n",
      "epoch:6 step:5752 [D loss: 0.422384, acc.: 82.03%] [G loss: 0.634493]\n",
      "epoch:6 step:5753 [D loss: 0.510921, acc.: 71.88%] [G loss: 0.612764]\n",
      "epoch:6 step:5754 [D loss: 0.550704, acc.: 74.22%] [G loss: 0.611648]\n",
      "epoch:6 step:5755 [D loss: 0.548207, acc.: 70.31%] [G loss: 0.607218]\n",
      "epoch:6 step:5756 [D loss: 0.558221, acc.: 67.19%] [G loss: 0.589889]\n",
      "epoch:6 step:5757 [D loss: 0.483828, acc.: 78.12%] [G loss: 0.538813]\n",
      "epoch:6 step:5758 [D loss: 0.550969, acc.: 70.31%] [G loss: 0.636172]\n",
      "epoch:6 step:5759 [D loss: 0.626617, acc.: 67.19%] [G loss: 0.542236]\n",
      "epoch:6 step:5760 [D loss: 0.574253, acc.: 70.31%] [G loss: 0.479474]\n",
      "epoch:6 step:5761 [D loss: 0.511351, acc.: 72.66%] [G loss: 0.630984]\n",
      "epoch:6 step:5762 [D loss: 0.532549, acc.: 68.75%] [G loss: 0.595716]\n",
      "epoch:6 step:5763 [D loss: 0.522092, acc.: 67.97%] [G loss: 0.417419]\n",
      "epoch:6 step:5764 [D loss: 0.559068, acc.: 71.09%] [G loss: 0.497164]\n",
      "epoch:6 step:5765 [D loss: 0.637963, acc.: 56.25%] [G loss: 0.519384]\n",
      "epoch:6 step:5766 [D loss: 0.467177, acc.: 77.34%] [G loss: 0.646852]\n",
      "epoch:6 step:5767 [D loss: 0.550986, acc.: 72.66%] [G loss: 0.498760]\n",
      "epoch:6 step:5768 [D loss: 0.499517, acc.: 72.66%] [G loss: 0.549263]\n",
      "epoch:6 step:5769 [D loss: 0.607150, acc.: 72.66%] [G loss: 0.484244]\n",
      "epoch:6 step:5770 [D loss: 0.555627, acc.: 69.53%] [G loss: 0.573264]\n",
      "epoch:6 step:5771 [D loss: 0.479269, acc.: 80.47%] [G loss: 0.577951]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:6 step:5772 [D loss: 0.654747, acc.: 64.84%] [G loss: 0.592368]\n",
      "epoch:6 step:5773 [D loss: 0.560153, acc.: 69.53%] [G loss: 0.468607]\n",
      "epoch:6 step:5774 [D loss: 0.448816, acc.: 80.47%] [G loss: 0.736276]\n",
      "epoch:6 step:5775 [D loss: 0.580618, acc.: 71.88%] [G loss: 0.665078]\n",
      "epoch:6 step:5776 [D loss: 0.529139, acc.: 74.22%] [G loss: 0.578290]\n",
      "epoch:6 step:5777 [D loss: 0.481179, acc.: 78.12%] [G loss: 0.622310]\n",
      "epoch:6 step:5778 [D loss: 0.513967, acc.: 76.56%] [G loss: 0.735418]\n",
      "epoch:6 step:5779 [D loss: 0.599855, acc.: 66.41%] [G loss: 0.618791]\n",
      "epoch:6 step:5780 [D loss: 0.522225, acc.: 78.12%] [G loss: 0.666026]\n",
      "epoch:6 step:5781 [D loss: 0.526661, acc.: 76.56%] [G loss: 0.501397]\n",
      "epoch:6 step:5782 [D loss: 0.600547, acc.: 65.62%] [G loss: 0.485155]\n",
      "epoch:6 step:5783 [D loss: 0.510317, acc.: 75.00%] [G loss: 0.618418]\n",
      "epoch:6 step:5784 [D loss: 0.464115, acc.: 81.25%] [G loss: 0.690024]\n",
      "epoch:6 step:5785 [D loss: 0.489342, acc.: 75.00%] [G loss: 0.712663]\n",
      "epoch:6 step:5786 [D loss: 0.539022, acc.: 71.09%] [G loss: 0.597020]\n",
      "epoch:6 step:5787 [D loss: 0.492093, acc.: 75.00%] [G loss: 0.685556]\n",
      "epoch:6 step:5788 [D loss: 0.536947, acc.: 71.09%] [G loss: 0.608309]\n",
      "epoch:6 step:5789 [D loss: 0.565859, acc.: 65.62%] [G loss: 0.525207]\n",
      "epoch:6 step:5790 [D loss: 0.565763, acc.: 69.53%] [G loss: 0.483826]\n",
      "epoch:6 step:5791 [D loss: 0.581071, acc.: 68.75%] [G loss: 0.457669]\n",
      "epoch:6 step:5792 [D loss: 0.513925, acc.: 71.88%] [G loss: 0.465371]\n",
      "epoch:6 step:5793 [D loss: 0.507015, acc.: 72.66%] [G loss: 0.489495]\n",
      "epoch:6 step:5794 [D loss: 0.509177, acc.: 74.22%] [G loss: 0.590329]\n",
      "epoch:6 step:5795 [D loss: 0.506193, acc.: 77.34%] [G loss: 0.563000]\n",
      "epoch:6 step:5796 [D loss: 0.546518, acc.: 68.75%] [G loss: 0.600186]\n",
      "epoch:6 step:5797 [D loss: 0.546135, acc.: 72.66%] [G loss: 0.558027]\n",
      "epoch:6 step:5798 [D loss: 0.489036, acc.: 77.34%] [G loss: 0.480812]\n",
      "epoch:6 step:5799 [D loss: 0.489222, acc.: 74.22%] [G loss: 0.603168]\n",
      "epoch:6 step:5800 [D loss: 0.547232, acc.: 73.44%] [G loss: 0.625175]\n",
      "##############\n",
      "[3.13602223 2.22854341 6.8290013  4.91875316 4.15302997 6.07509578\n",
      " 5.03465241 5.16759651 4.82146379 3.71967394]\n",
      "##########\n",
      "epoch:6 step:5801 [D loss: 0.536099, acc.: 73.44%] [G loss: 0.486608]\n",
      "epoch:6 step:5802 [D loss: 0.580623, acc.: 69.53%] [G loss: 0.482105]\n",
      "epoch:6 step:5803 [D loss: 0.574200, acc.: 71.09%] [G loss: 0.509763]\n",
      "epoch:6 step:5804 [D loss: 0.517241, acc.: 75.78%] [G loss: 0.754414]\n",
      "epoch:6 step:5805 [D loss: 0.602409, acc.: 63.28%] [G loss: 0.548496]\n",
      "epoch:6 step:5806 [D loss: 0.540039, acc.: 72.66%] [G loss: 0.605101]\n",
      "epoch:6 step:5807 [D loss: 0.554706, acc.: 72.66%] [G loss: 0.581144]\n",
      "epoch:6 step:5808 [D loss: 0.586174, acc.: 67.97%] [G loss: 0.470379]\n",
      "epoch:6 step:5809 [D loss: 0.603271, acc.: 65.62%] [G loss: 0.535211]\n",
      "epoch:6 step:5810 [D loss: 0.517643, acc.: 75.00%] [G loss: 0.490344]\n",
      "epoch:6 step:5811 [D loss: 0.562022, acc.: 70.31%] [G loss: 0.492963]\n",
      "epoch:6 step:5812 [D loss: 0.497281, acc.: 74.22%] [G loss: 0.562644]\n",
      "epoch:6 step:5813 [D loss: 0.557120, acc.: 68.75%] [G loss: 0.494718]\n",
      "epoch:6 step:5814 [D loss: 0.564187, acc.: 70.31%] [G loss: 0.513878]\n",
      "epoch:6 step:5815 [D loss: 0.528270, acc.: 75.78%] [G loss: 0.569302]\n",
      "epoch:6 step:5816 [D loss: 0.432864, acc.: 80.47%] [G loss: 0.609402]\n",
      "epoch:6 step:5817 [D loss: 0.561241, acc.: 67.97%] [G loss: 0.639775]\n",
      "epoch:6 step:5818 [D loss: 0.572463, acc.: 67.97%] [G loss: 0.462651]\n",
      "epoch:6 step:5819 [D loss: 0.523553, acc.: 73.44%] [G loss: 0.456980]\n",
      "epoch:6 step:5820 [D loss: 0.483394, acc.: 73.44%] [G loss: 0.669220]\n",
      "epoch:6 step:5821 [D loss: 0.552244, acc.: 69.53%] [G loss: 0.732317]\n",
      "epoch:6 step:5822 [D loss: 0.612180, acc.: 64.06%] [G loss: 0.592420]\n",
      "epoch:6 step:5823 [D loss: 0.574520, acc.: 67.19%] [G loss: 0.498693]\n",
      "epoch:6 step:5824 [D loss: 0.498414, acc.: 75.00%] [G loss: 0.581083]\n",
      "epoch:6 step:5825 [D loss: 0.625877, acc.: 67.97%] [G loss: 0.393042]\n",
      "epoch:6 step:5826 [D loss: 0.550909, acc.: 65.62%] [G loss: 0.467161]\n",
      "epoch:6 step:5827 [D loss: 0.508246, acc.: 73.44%] [G loss: 0.515021]\n",
      "epoch:6 step:5828 [D loss: 0.527213, acc.: 69.53%] [G loss: 0.613775]\n",
      "epoch:6 step:5829 [D loss: 0.423926, acc.: 81.25%] [G loss: 0.603502]\n",
      "epoch:6 step:5830 [D loss: 0.416579, acc.: 79.69%] [G loss: 0.745823]\n",
      "epoch:6 step:5831 [D loss: 0.571949, acc.: 68.75%] [G loss: 0.634518]\n",
      "epoch:6 step:5832 [D loss: 0.593458, acc.: 64.06%] [G loss: 0.557906]\n",
      "epoch:6 step:5833 [D loss: 0.601518, acc.: 65.62%] [G loss: 0.509832]\n",
      "epoch:6 step:5834 [D loss: 0.564674, acc.: 68.75%] [G loss: 0.496589]\n",
      "epoch:6 step:5835 [D loss: 0.521917, acc.: 72.66%] [G loss: 0.489009]\n",
      "epoch:6 step:5836 [D loss: 0.700148, acc.: 57.81%] [G loss: 0.456460]\n",
      "epoch:6 step:5837 [D loss: 0.595497, acc.: 67.19%] [G loss: 0.424259]\n",
      "epoch:6 step:5838 [D loss: 0.503066, acc.: 75.78%] [G loss: 0.505976]\n",
      "epoch:6 step:5839 [D loss: 0.516251, acc.: 78.12%] [G loss: 0.559592]\n",
      "epoch:6 step:5840 [D loss: 0.502332, acc.: 81.25%] [G loss: 0.492794]\n",
      "epoch:6 step:5841 [D loss: 0.498059, acc.: 76.56%] [G loss: 0.640124]\n",
      "epoch:6 step:5842 [D loss: 0.650449, acc.: 58.59%] [G loss: 0.472736]\n",
      "epoch:6 step:5843 [D loss: 0.505985, acc.: 74.22%] [G loss: 0.620255]\n",
      "epoch:6 step:5844 [D loss: 0.461957, acc.: 78.12%] [G loss: 0.693179]\n",
      "epoch:6 step:5845 [D loss: 0.466589, acc.: 82.81%] [G loss: 0.702299]\n",
      "epoch:6 step:5846 [D loss: 0.632502, acc.: 67.19%] [G loss: 0.562308]\n",
      "epoch:6 step:5847 [D loss: 0.590959, acc.: 67.19%] [G loss: 0.618859]\n",
      "epoch:6 step:5848 [D loss: 0.544568, acc.: 69.53%] [G loss: 0.424596]\n",
      "epoch:6 step:5849 [D loss: 0.551947, acc.: 71.09%] [G loss: 0.519241]\n",
      "epoch:6 step:5850 [D loss: 0.592621, acc.: 71.88%] [G loss: 0.393053]\n",
      "epoch:6 step:5851 [D loss: 0.501528, acc.: 78.12%] [G loss: 0.423854]\n",
      "epoch:6 step:5852 [D loss: 0.502813, acc.: 77.34%] [G loss: 0.565348]\n",
      "epoch:6 step:5853 [D loss: 0.477165, acc.: 70.31%] [G loss: 0.599674]\n",
      "epoch:6 step:5854 [D loss: 0.460712, acc.: 74.22%] [G loss: 0.729350]\n",
      "epoch:6 step:5855 [D loss: 0.555714, acc.: 75.00%] [G loss: 0.681472]\n",
      "epoch:6 step:5856 [D loss: 0.543069, acc.: 70.31%] [G loss: 0.650969]\n",
      "epoch:6 step:5857 [D loss: 0.590559, acc.: 66.41%] [G loss: 0.551339]\n",
      "epoch:6 step:5858 [D loss: 0.500310, acc.: 75.78%] [G loss: 0.578923]\n",
      "epoch:6 step:5859 [D loss: 0.566594, acc.: 70.31%] [G loss: 0.588242]\n",
      "epoch:6 step:5860 [D loss: 0.588570, acc.: 61.72%] [G loss: 0.517350]\n",
      "epoch:6 step:5861 [D loss: 0.564442, acc.: 68.75%] [G loss: 0.522173]\n",
      "epoch:6 step:5862 [D loss: 0.568888, acc.: 71.09%] [G loss: 0.480510]\n",
      "epoch:6 step:5863 [D loss: 0.542153, acc.: 71.09%] [G loss: 0.465800]\n",
      "epoch:6 step:5864 [D loss: 0.510862, acc.: 77.34%] [G loss: 0.624013]\n",
      "epoch:6 step:5865 [D loss: 0.541036, acc.: 74.22%] [G loss: 0.470383]\n",
      "epoch:6 step:5866 [D loss: 0.542043, acc.: 72.66%] [G loss: 0.456137]\n",
      "epoch:6 step:5867 [D loss: 0.523279, acc.: 75.00%] [G loss: 0.578028]\n",
      "epoch:6 step:5868 [D loss: 0.583049, acc.: 68.75%] [G loss: 0.601096]\n",
      "epoch:6 step:5869 [D loss: 0.550975, acc.: 67.19%] [G loss: 0.570590]\n",
      "epoch:6 step:5870 [D loss: 0.593083, acc.: 65.62%] [G loss: 0.582968]\n",
      "epoch:6 step:5871 [D loss: 0.594540, acc.: 67.19%] [G loss: 0.437953]\n",
      "epoch:6 step:5872 [D loss: 0.570890, acc.: 67.97%] [G loss: 0.587102]\n",
      "epoch:6 step:5873 [D loss: 0.639228, acc.: 56.25%] [G loss: 0.546780]\n",
      "epoch:6 step:5874 [D loss: 0.551495, acc.: 67.97%] [G loss: 0.469809]\n",
      "epoch:6 step:5875 [D loss: 0.526775, acc.: 71.88%] [G loss: 0.662282]\n",
      "epoch:6 step:5876 [D loss: 0.466803, acc.: 79.69%] [G loss: 0.594094]\n",
      "epoch:6 step:5877 [D loss: 0.524185, acc.: 71.88%] [G loss: 0.589279]\n",
      "epoch:6 step:5878 [D loss: 0.518836, acc.: 73.44%] [G loss: 0.559291]\n",
      "epoch:6 step:5879 [D loss: 0.617505, acc.: 63.28%] [G loss: 0.468164]\n",
      "epoch:6 step:5880 [D loss: 0.492467, acc.: 78.12%] [G loss: 0.474110]\n",
      "epoch:6 step:5881 [D loss: 0.467116, acc.: 75.00%] [G loss: 0.698033]\n",
      "epoch:6 step:5882 [D loss: 0.595291, acc.: 64.84%] [G loss: 0.507754]\n",
      "epoch:6 step:5883 [D loss: 0.533885, acc.: 73.44%] [G loss: 0.473355]\n",
      "epoch:6 step:5884 [D loss: 0.505162, acc.: 75.78%] [G loss: 0.493678]\n",
      "epoch:6 step:5885 [D loss: 0.598395, acc.: 69.53%] [G loss: 0.595519]\n",
      "epoch:6 step:5886 [D loss: 0.488526, acc.: 78.91%] [G loss: 0.645134]\n",
      "epoch:6 step:5887 [D loss: 0.609659, acc.: 65.62%] [G loss: 0.491484]\n",
      "epoch:6 step:5888 [D loss: 0.507233, acc.: 75.78%] [G loss: 0.510060]\n",
      "epoch:6 step:5889 [D loss: 0.580610, acc.: 65.62%] [G loss: 0.530513]\n",
      "epoch:6 step:5890 [D loss: 0.537218, acc.: 73.44%] [G loss: 0.440843]\n",
      "epoch:6 step:5891 [D loss: 0.530266, acc.: 71.88%] [G loss: 0.585064]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:6 step:5892 [D loss: 0.516603, acc.: 74.22%] [G loss: 0.534886]\n",
      "epoch:6 step:5893 [D loss: 0.515485, acc.: 79.69%] [G loss: 0.557601]\n",
      "epoch:6 step:5894 [D loss: 0.541241, acc.: 72.66%] [G loss: 0.545171]\n",
      "epoch:6 step:5895 [D loss: 0.524839, acc.: 71.09%] [G loss: 0.435954]\n",
      "epoch:6 step:5896 [D loss: 0.554227, acc.: 70.31%] [G loss: 0.588003]\n",
      "epoch:6 step:5897 [D loss: 0.577231, acc.: 71.88%] [G loss: 0.503772]\n",
      "epoch:6 step:5898 [D loss: 0.520764, acc.: 74.22%] [G loss: 0.615428]\n",
      "epoch:6 step:5899 [D loss: 0.604825, acc.: 70.31%] [G loss: 0.476732]\n",
      "epoch:6 step:5900 [D loss: 0.640703, acc.: 58.59%] [G loss: 0.371036]\n",
      "epoch:6 step:5901 [D loss: 0.512744, acc.: 71.09%] [G loss: 0.678839]\n",
      "epoch:6 step:5902 [D loss: 0.565578, acc.: 67.19%] [G loss: 0.574266]\n",
      "epoch:6 step:5903 [D loss: 0.569793, acc.: 67.97%] [G loss: 0.451897]\n",
      "epoch:6 step:5904 [D loss: 0.577007, acc.: 68.75%] [G loss: 0.502048]\n",
      "epoch:6 step:5905 [D loss: 0.497314, acc.: 76.56%] [G loss: 0.535276]\n",
      "epoch:6 step:5906 [D loss: 0.527566, acc.: 74.22%] [G loss: 0.508218]\n",
      "epoch:6 step:5907 [D loss: 0.482943, acc.: 75.78%] [G loss: 0.558183]\n",
      "epoch:6 step:5908 [D loss: 0.468135, acc.: 76.56%] [G loss: 0.533464]\n",
      "epoch:6 step:5909 [D loss: 0.619563, acc.: 65.62%] [G loss: 0.509634]\n",
      "epoch:6 step:5910 [D loss: 0.624487, acc.: 60.94%] [G loss: 0.689438]\n",
      "epoch:6 step:5911 [D loss: 0.567388, acc.: 65.62%] [G loss: 0.499436]\n",
      "epoch:6 step:5912 [D loss: 0.547269, acc.: 71.09%] [G loss: 0.673662]\n",
      "epoch:6 step:5913 [D loss: 0.541696, acc.: 74.22%] [G loss: 0.528322]\n",
      "epoch:6 step:5914 [D loss: 0.516481, acc.: 71.88%] [G loss: 0.577865]\n",
      "epoch:6 step:5915 [D loss: 0.528401, acc.: 71.09%] [G loss: 0.619224]\n",
      "epoch:6 step:5916 [D loss: 0.553840, acc.: 72.66%] [G loss: 0.475606]\n",
      "epoch:6 step:5917 [D loss: 0.584613, acc.: 70.31%] [G loss: 0.401484]\n",
      "epoch:6 step:5918 [D loss: 0.439173, acc.: 85.94%] [G loss: 0.519083]\n",
      "epoch:6 step:5919 [D loss: 0.573659, acc.: 70.31%] [G loss: 0.452749]\n",
      "epoch:6 step:5920 [D loss: 0.464089, acc.: 80.47%] [G loss: 0.606686]\n",
      "epoch:6 step:5921 [D loss: 0.473700, acc.: 78.12%] [G loss: 0.719948]\n",
      "epoch:6 step:5922 [D loss: 0.479250, acc.: 78.12%] [G loss: 0.774128]\n",
      "epoch:6 step:5923 [D loss: 0.620529, acc.: 68.75%] [G loss: 0.584102]\n",
      "epoch:6 step:5924 [D loss: 0.510207, acc.: 76.56%] [G loss: 0.418933]\n",
      "epoch:6 step:5925 [D loss: 0.533689, acc.: 72.66%] [G loss: 0.559439]\n",
      "epoch:6 step:5926 [D loss: 0.517963, acc.: 73.44%] [G loss: 0.527178]\n",
      "epoch:6 step:5927 [D loss: 0.492476, acc.: 77.34%] [G loss: 0.692381]\n",
      "epoch:6 step:5928 [D loss: 0.575708, acc.: 66.41%] [G loss: 0.651234]\n",
      "epoch:6 step:5929 [D loss: 0.509755, acc.: 71.88%] [G loss: 0.617478]\n",
      "epoch:6 step:5930 [D loss: 0.559520, acc.: 70.31%] [G loss: 0.574456]\n",
      "epoch:6 step:5931 [D loss: 0.450278, acc.: 78.91%] [G loss: 0.667478]\n",
      "epoch:6 step:5932 [D loss: 0.507653, acc.: 75.00%] [G loss: 0.726933]\n",
      "epoch:6 step:5933 [D loss: 0.494233, acc.: 71.88%] [G loss: 0.800179]\n",
      "epoch:6 step:5934 [D loss: 0.497033, acc.: 75.78%] [G loss: 0.703768]\n",
      "epoch:6 step:5935 [D loss: 0.495754, acc.: 78.12%] [G loss: 0.819514]\n",
      "epoch:6 step:5936 [D loss: 0.412944, acc.: 84.38%] [G loss: 0.893717]\n",
      "epoch:6 step:5937 [D loss: 0.475082, acc.: 78.12%] [G loss: 1.003879]\n",
      "epoch:6 step:5938 [D loss: 0.726454, acc.: 57.03%] [G loss: 0.574862]\n",
      "epoch:6 step:5939 [D loss: 0.568129, acc.: 67.97%] [G loss: 0.541011]\n",
      "epoch:6 step:5940 [D loss: 0.517289, acc.: 75.00%] [G loss: 0.622415]\n",
      "epoch:6 step:5941 [D loss: 0.558890, acc.: 67.97%] [G loss: 0.571708]\n",
      "epoch:6 step:5942 [D loss: 0.570816, acc.: 67.97%] [G loss: 0.703965]\n",
      "epoch:6 step:5943 [D loss: 0.442314, acc.: 80.47%] [G loss: 0.570964]\n",
      "epoch:6 step:5944 [D loss: 0.575056, acc.: 67.97%] [G loss: 0.516081]\n",
      "epoch:6 step:5945 [D loss: 0.637884, acc.: 62.50%] [G loss: 0.500545]\n",
      "epoch:6 step:5946 [D loss: 0.592654, acc.: 66.41%] [G loss: 0.477605]\n",
      "epoch:6 step:5947 [D loss: 0.526440, acc.: 77.34%] [G loss: 0.590993]\n",
      "epoch:6 step:5948 [D loss: 0.504841, acc.: 74.22%] [G loss: 0.654793]\n",
      "epoch:6 step:5949 [D loss: 0.544445, acc.: 75.00%] [G loss: 0.594136]\n",
      "epoch:6 step:5950 [D loss: 0.498597, acc.: 77.34%] [G loss: 0.702453]\n",
      "epoch:6 step:5951 [D loss: 0.536385, acc.: 71.09%] [G loss: 0.669598]\n",
      "epoch:6 step:5952 [D loss: 0.528278, acc.: 71.09%] [G loss: 0.565605]\n",
      "epoch:6 step:5953 [D loss: 0.519658, acc.: 73.44%] [G loss: 0.537577]\n",
      "epoch:6 step:5954 [D loss: 0.484773, acc.: 73.44%] [G loss: 0.616404]\n",
      "epoch:6 step:5955 [D loss: 0.485809, acc.: 77.34%] [G loss: 0.518129]\n",
      "epoch:6 step:5956 [D loss: 0.517831, acc.: 71.09%] [G loss: 0.537160]\n",
      "epoch:6 step:5957 [D loss: 0.484099, acc.: 74.22%] [G loss: 0.618578]\n",
      "epoch:6 step:5958 [D loss: 0.600159, acc.: 67.19%] [G loss: 0.751575]\n",
      "epoch:6 step:5959 [D loss: 0.530522, acc.: 75.00%] [G loss: 0.628880]\n",
      "epoch:6 step:5960 [D loss: 0.541951, acc.: 71.88%] [G loss: 0.642554]\n",
      "epoch:6 step:5961 [D loss: 0.490803, acc.: 78.91%] [G loss: 0.545065]\n",
      "epoch:6 step:5962 [D loss: 0.513760, acc.: 71.88%] [G loss: 0.600629]\n",
      "epoch:6 step:5963 [D loss: 0.569470, acc.: 70.31%] [G loss: 0.612931]\n",
      "epoch:6 step:5964 [D loss: 0.616505, acc.: 65.62%] [G loss: 0.461973]\n",
      "epoch:6 step:5965 [D loss: 0.512628, acc.: 76.56%] [G loss: 0.619399]\n",
      "epoch:6 step:5966 [D loss: 0.460875, acc.: 79.69%] [G loss: 0.793393]\n",
      "epoch:6 step:5967 [D loss: 0.502512, acc.: 73.44%] [G loss: 0.711080]\n",
      "epoch:6 step:5968 [D loss: 0.538557, acc.: 71.09%] [G loss: 0.696697]\n",
      "epoch:6 step:5969 [D loss: 0.451966, acc.: 82.03%] [G loss: 0.822908]\n",
      "epoch:6 step:5970 [D loss: 0.645204, acc.: 60.16%] [G loss: 0.663610]\n",
      "epoch:6 step:5971 [D loss: 0.779441, acc.: 52.34%] [G loss: 0.415370]\n",
      "epoch:6 step:5972 [D loss: 0.503653, acc.: 75.00%] [G loss: 0.582360]\n",
      "epoch:6 step:5973 [D loss: 0.545249, acc.: 73.44%] [G loss: 0.543103]\n",
      "epoch:6 step:5974 [D loss: 0.566552, acc.: 67.97%] [G loss: 0.657203]\n",
      "epoch:6 step:5975 [D loss: 0.530491, acc.: 71.09%] [G loss: 0.596055]\n",
      "epoch:6 step:5976 [D loss: 0.459188, acc.: 78.91%] [G loss: 0.705170]\n",
      "epoch:6 step:5977 [D loss: 0.591967, acc.: 68.75%] [G loss: 0.624077]\n",
      "epoch:6 step:5978 [D loss: 0.574167, acc.: 70.31%] [G loss: 0.599443]\n",
      "epoch:6 step:5979 [D loss: 0.474719, acc.: 77.34%] [G loss: 0.672188]\n",
      "epoch:6 step:5980 [D loss: 0.470589, acc.: 76.56%] [G loss: 0.722580]\n",
      "epoch:6 step:5981 [D loss: 0.467379, acc.: 76.56%] [G loss: 0.561346]\n",
      "epoch:6 step:5982 [D loss: 0.504329, acc.: 75.00%] [G loss: 0.684803]\n",
      "epoch:6 step:5983 [D loss: 0.583263, acc.: 71.88%] [G loss: 0.699227]\n",
      "epoch:6 step:5984 [D loss: 0.567339, acc.: 68.75%] [G loss: 0.598484]\n",
      "epoch:6 step:5985 [D loss: 0.494837, acc.: 75.78%] [G loss: 0.554864]\n",
      "epoch:6 step:5986 [D loss: 0.569013, acc.: 71.88%] [G loss: 0.525817]\n",
      "epoch:6 step:5987 [D loss: 0.541605, acc.: 71.09%] [G loss: 0.673152]\n",
      "epoch:6 step:5988 [D loss: 0.510659, acc.: 68.75%] [G loss: 0.725682]\n",
      "epoch:6 step:5989 [D loss: 0.560902, acc.: 72.66%] [G loss: 0.699796]\n",
      "epoch:6 step:5990 [D loss: 0.546160, acc.: 72.66%] [G loss: 0.611289]\n",
      "epoch:6 step:5991 [D loss: 0.586307, acc.: 73.44%] [G loss: 0.619609]\n",
      "epoch:6 step:5992 [D loss: 0.571061, acc.: 76.56%] [G loss: 0.679114]\n",
      "epoch:6 step:5993 [D loss: 0.492679, acc.: 77.34%] [G loss: 0.656179]\n",
      "epoch:6 step:5994 [D loss: 0.571494, acc.: 64.84%] [G loss: 0.615586]\n",
      "epoch:6 step:5995 [D loss: 0.567985, acc.: 70.31%] [G loss: 0.550272]\n",
      "epoch:6 step:5996 [D loss: 0.486353, acc.: 76.56%] [G loss: 0.790256]\n",
      "epoch:6 step:5997 [D loss: 0.575721, acc.: 69.53%] [G loss: 0.609415]\n",
      "epoch:6 step:5998 [D loss: 0.695419, acc.: 59.38%] [G loss: 0.428782]\n",
      "epoch:6 step:5999 [D loss: 0.588049, acc.: 63.28%] [G loss: 0.456183]\n",
      "epoch:6 step:6000 [D loss: 0.554896, acc.: 63.28%] [G loss: 0.540893]\n",
      "##############\n",
      "[3.55393575 1.23841976 6.93838908 4.97769768 4.14051706 5.78221084\n",
      " 5.19554001 5.10440238 4.62479333 3.79967714]\n",
      "##########\n",
      "epoch:6 step:6001 [D loss: 0.610256, acc.: 69.53%] [G loss: 0.534264]\n",
      "epoch:6 step:6002 [D loss: 0.613056, acc.: 64.84%] [G loss: 0.409642]\n",
      "epoch:6 step:6003 [D loss: 0.494533, acc.: 74.22%] [G loss: 0.518320]\n",
      "epoch:6 step:6004 [D loss: 0.540574, acc.: 73.44%] [G loss: 0.523429]\n",
      "epoch:6 step:6005 [D loss: 0.614565, acc.: 59.38%] [G loss: 0.487061]\n",
      "epoch:6 step:6006 [D loss: 0.548843, acc.: 74.22%] [G loss: 0.439229]\n",
      "epoch:6 step:6007 [D loss: 0.486899, acc.: 75.78%] [G loss: 0.602782]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:6 step:6008 [D loss: 0.573480, acc.: 67.19%] [G loss: 0.575192]\n",
      "epoch:6 step:6009 [D loss: 0.557697, acc.: 71.09%] [G loss: 0.521129]\n",
      "epoch:6 step:6010 [D loss: 0.564011, acc.: 69.53%] [G loss: 0.466483]\n",
      "epoch:6 step:6011 [D loss: 0.544985, acc.: 72.66%] [G loss: 0.586482]\n",
      "epoch:6 step:6012 [D loss: 0.570216, acc.: 69.53%] [G loss: 0.633937]\n",
      "epoch:6 step:6013 [D loss: 0.551819, acc.: 74.22%] [G loss: 0.476618]\n",
      "epoch:6 step:6014 [D loss: 0.481203, acc.: 73.44%] [G loss: 0.493082]\n",
      "epoch:6 step:6015 [D loss: 0.611889, acc.: 66.41%] [G loss: 0.529173]\n",
      "epoch:6 step:6016 [D loss: 0.550916, acc.: 71.88%] [G loss: 0.469151]\n",
      "epoch:6 step:6017 [D loss: 0.504730, acc.: 75.00%] [G loss: 0.530526]\n",
      "epoch:6 step:6018 [D loss: 0.577660, acc.: 67.19%] [G loss: 0.451568]\n",
      "epoch:6 step:6019 [D loss: 0.497902, acc.: 77.34%] [G loss: 0.610700]\n",
      "epoch:6 step:6020 [D loss: 0.533112, acc.: 71.09%] [G loss: 0.692501]\n",
      "epoch:6 step:6021 [D loss: 0.528442, acc.: 71.09%] [G loss: 0.721503]\n",
      "epoch:6 step:6022 [D loss: 0.647803, acc.: 62.50%] [G loss: 0.406695]\n",
      "epoch:6 step:6023 [D loss: 0.639262, acc.: 59.38%] [G loss: 0.456138]\n",
      "epoch:6 step:6024 [D loss: 0.489708, acc.: 72.66%] [G loss: 0.591106]\n",
      "epoch:6 step:6025 [D loss: 0.505979, acc.: 72.66%] [G loss: 0.606210]\n",
      "epoch:6 step:6026 [D loss: 0.568853, acc.: 65.62%] [G loss: 0.641709]\n",
      "epoch:6 step:6027 [D loss: 0.534364, acc.: 70.31%] [G loss: 0.570813]\n",
      "epoch:6 step:6028 [D loss: 0.517744, acc.: 73.44%] [G loss: 0.720558]\n",
      "epoch:6 step:6029 [D loss: 0.558929, acc.: 68.75%] [G loss: 0.627901]\n",
      "epoch:6 step:6030 [D loss: 0.585439, acc.: 72.66%] [G loss: 0.541931]\n",
      "epoch:6 step:6031 [D loss: 0.549825, acc.: 64.84%] [G loss: 0.755115]\n",
      "epoch:6 step:6032 [D loss: 0.568382, acc.: 71.88%] [G loss: 0.574581]\n",
      "epoch:6 step:6033 [D loss: 0.591807, acc.: 66.41%] [G loss: 0.468440]\n",
      "epoch:6 step:6034 [D loss: 0.609428, acc.: 63.28%] [G loss: 0.421231]\n",
      "epoch:6 step:6035 [D loss: 0.540042, acc.: 75.00%] [G loss: 0.651082]\n",
      "epoch:6 step:6036 [D loss: 0.567305, acc.: 66.41%] [G loss: 0.440055]\n",
      "epoch:6 step:6037 [D loss: 0.546118, acc.: 67.19%] [G loss: 0.628305]\n",
      "epoch:6 step:6038 [D loss: 0.529956, acc.: 71.88%] [G loss: 0.595615]\n",
      "epoch:6 step:6039 [D loss: 0.586601, acc.: 69.53%] [G loss: 0.589748]\n",
      "epoch:6 step:6040 [D loss: 0.610235, acc.: 60.94%] [G loss: 0.402168]\n",
      "epoch:6 step:6041 [D loss: 0.519639, acc.: 77.34%] [G loss: 0.459037]\n",
      "epoch:6 step:6042 [D loss: 0.531745, acc.: 75.00%] [G loss: 0.493250]\n",
      "epoch:6 step:6043 [D loss: 0.535917, acc.: 73.44%] [G loss: 0.445845]\n",
      "epoch:6 step:6044 [D loss: 0.562012, acc.: 69.53%] [G loss: 0.597737]\n",
      "epoch:6 step:6045 [D loss: 0.580155, acc.: 67.19%] [G loss: 0.513273]\n",
      "epoch:6 step:6046 [D loss: 0.628160, acc.: 64.84%] [G loss: 0.611139]\n",
      "epoch:6 step:6047 [D loss: 0.564914, acc.: 67.97%] [G loss: 0.610808]\n",
      "epoch:6 step:6048 [D loss: 0.464304, acc.: 74.22%] [G loss: 0.779984]\n",
      "epoch:6 step:6049 [D loss: 0.486425, acc.: 74.22%] [G loss: 0.839781]\n",
      "epoch:6 step:6050 [D loss: 0.504282, acc.: 76.56%] [G loss: 0.648466]\n",
      "epoch:6 step:6051 [D loss: 0.446151, acc.: 81.25%] [G loss: 0.681447]\n",
      "epoch:6 step:6052 [D loss: 0.523626, acc.: 75.00%] [G loss: 0.788491]\n",
      "epoch:6 step:6053 [D loss: 0.510626, acc.: 75.00%] [G loss: 0.703964]\n",
      "epoch:6 step:6054 [D loss: 0.599480, acc.: 64.84%] [G loss: 0.573307]\n",
      "epoch:6 step:6055 [D loss: 0.602367, acc.: 64.84%] [G loss: 0.504281]\n",
      "epoch:6 step:6056 [D loss: 0.504213, acc.: 76.56%] [G loss: 0.519323]\n",
      "epoch:6 step:6057 [D loss: 0.578095, acc.: 67.97%] [G loss: 0.522691]\n",
      "epoch:6 step:6058 [D loss: 0.493420, acc.: 78.12%] [G loss: 0.603381]\n",
      "epoch:6 step:6059 [D loss: 0.681792, acc.: 66.41%] [G loss: 0.479124]\n",
      "epoch:6 step:6060 [D loss: 0.539356, acc.: 69.53%] [G loss: 0.546381]\n",
      "epoch:6 step:6061 [D loss: 0.459961, acc.: 78.91%] [G loss: 0.640040]\n",
      "epoch:6 step:6062 [D loss: 0.516438, acc.: 71.88%] [G loss: 0.516304]\n",
      "epoch:6 step:6063 [D loss: 0.570341, acc.: 67.19%] [G loss: 0.565327]\n",
      "epoch:6 step:6064 [D loss: 0.585310, acc.: 68.75%] [G loss: 0.653089]\n",
      "epoch:6 step:6065 [D loss: 0.497656, acc.: 78.12%] [G loss: 0.558456]\n",
      "epoch:6 step:6066 [D loss: 0.581140, acc.: 65.62%] [G loss: 0.656308]\n",
      "epoch:6 step:6067 [D loss: 0.526385, acc.: 73.44%] [G loss: 0.528921]\n",
      "epoch:6 step:6068 [D loss: 0.566789, acc.: 66.41%] [G loss: 0.637805]\n",
      "epoch:6 step:6069 [D loss: 0.538908, acc.: 72.66%] [G loss: 0.702917]\n",
      "epoch:6 step:6070 [D loss: 0.575191, acc.: 67.97%] [G loss: 0.630411]\n",
      "epoch:6 step:6071 [D loss: 0.532988, acc.: 70.31%] [G loss: 0.721841]\n",
      "epoch:6 step:6072 [D loss: 0.536258, acc.: 71.09%] [G loss: 0.549152]\n",
      "epoch:6 step:6073 [D loss: 0.432112, acc.: 82.81%] [G loss: 0.732440]\n",
      "epoch:6 step:6074 [D loss: 0.481581, acc.: 77.34%] [G loss: 0.709349]\n",
      "epoch:6 step:6075 [D loss: 0.506274, acc.: 73.44%] [G loss: 0.769255]\n",
      "epoch:6 step:6076 [D loss: 0.567199, acc.: 71.88%] [G loss: 0.726705]\n",
      "epoch:6 step:6077 [D loss: 0.567345, acc.: 71.09%] [G loss: 0.531157]\n",
      "epoch:6 step:6078 [D loss: 0.657597, acc.: 62.50%] [G loss: 0.539677]\n",
      "epoch:6 step:6079 [D loss: 0.506099, acc.: 77.34%] [G loss: 0.614372]\n",
      "epoch:6 step:6080 [D loss: 0.645347, acc.: 59.38%] [G loss: 0.472218]\n",
      "epoch:6 step:6081 [D loss: 0.553291, acc.: 70.31%] [G loss: 0.581778]\n",
      "epoch:6 step:6082 [D loss: 0.480977, acc.: 78.12%] [G loss: 0.581451]\n",
      "epoch:6 step:6083 [D loss: 0.533589, acc.: 69.53%] [G loss: 0.706207]\n",
      "epoch:6 step:6084 [D loss: 0.561555, acc.: 68.75%] [G loss: 0.581914]\n",
      "epoch:6 step:6085 [D loss: 0.562027, acc.: 73.44%] [G loss: 0.534639]\n",
      "epoch:6 step:6086 [D loss: 0.528615, acc.: 75.78%] [G loss: 0.521030]\n",
      "epoch:6 step:6087 [D loss: 0.651689, acc.: 58.59%] [G loss: 0.535627]\n",
      "epoch:6 step:6088 [D loss: 0.578657, acc.: 66.41%] [G loss: 0.639059]\n",
      "epoch:6 step:6089 [D loss: 0.521750, acc.: 77.34%] [G loss: 0.820095]\n",
      "epoch:6 step:6090 [D loss: 0.517996, acc.: 77.34%] [G loss: 0.732692]\n",
      "epoch:6 step:6091 [D loss: 0.601408, acc.: 67.97%] [G loss: 0.587126]\n",
      "epoch:6 step:6092 [D loss: 0.598986, acc.: 71.88%] [G loss: 0.684168]\n",
      "epoch:6 step:6093 [D loss: 0.461559, acc.: 76.56%] [G loss: 0.790978]\n",
      "epoch:6 step:6094 [D loss: 0.472498, acc.: 79.69%] [G loss: 0.867511]\n",
      "epoch:6 step:6095 [D loss: 0.658036, acc.: 62.50%] [G loss: 0.624774]\n",
      "epoch:6 step:6096 [D loss: 0.567633, acc.: 67.97%] [G loss: 0.528392]\n",
      "epoch:6 step:6097 [D loss: 0.477772, acc.: 78.91%] [G loss: 0.638705]\n",
      "epoch:6 step:6098 [D loss: 0.561955, acc.: 71.09%] [G loss: 0.627934]\n",
      "epoch:6 step:6099 [D loss: 0.703267, acc.: 60.16%] [G loss: 0.511327]\n",
      "epoch:6 step:6100 [D loss: 0.598854, acc.: 67.97%] [G loss: 0.484007]\n",
      "epoch:6 step:6101 [D loss: 0.530434, acc.: 73.44%] [G loss: 0.488152]\n",
      "epoch:6 step:6102 [D loss: 0.628110, acc.: 67.19%] [G loss: 0.532359]\n",
      "epoch:6 step:6103 [D loss: 0.596988, acc.: 71.09%] [G loss: 0.450782]\n",
      "epoch:6 step:6104 [D loss: 0.597094, acc.: 66.41%] [G loss: 0.403142]\n",
      "epoch:6 step:6105 [D loss: 0.552126, acc.: 67.19%] [G loss: 0.525160]\n",
      "epoch:6 step:6106 [D loss: 0.470001, acc.: 75.78%] [G loss: 0.558347]\n",
      "epoch:6 step:6107 [D loss: 0.511519, acc.: 72.66%] [G loss: 0.704286]\n",
      "epoch:6 step:6108 [D loss: 0.536121, acc.: 72.66%] [G loss: 0.643289]\n",
      "epoch:6 step:6109 [D loss: 0.554622, acc.: 67.19%] [G loss: 0.592438]\n",
      "epoch:6 step:6110 [D loss: 0.500265, acc.: 71.88%] [G loss: 0.593385]\n",
      "epoch:6 step:6111 [D loss: 0.586082, acc.: 62.50%] [G loss: 0.629404]\n",
      "epoch:6 step:6112 [D loss: 0.597958, acc.: 63.28%] [G loss: 0.533121]\n",
      "epoch:6 step:6113 [D loss: 0.536872, acc.: 71.09%] [G loss: 0.640779]\n",
      "epoch:6 step:6114 [D loss: 0.557674, acc.: 72.66%] [G loss: 0.496231]\n",
      "epoch:6 step:6115 [D loss: 0.552692, acc.: 71.88%] [G loss: 0.465722]\n",
      "epoch:6 step:6116 [D loss: 0.574411, acc.: 66.41%] [G loss: 0.381199]\n",
      "epoch:6 step:6117 [D loss: 0.523851, acc.: 71.88%] [G loss: 0.554387]\n",
      "epoch:6 step:6118 [D loss: 0.591644, acc.: 69.53%] [G loss: 0.465621]\n",
      "epoch:6 step:6119 [D loss: 0.597757, acc.: 62.50%] [G loss: 0.490094]\n",
      "epoch:6 step:6120 [D loss: 0.503354, acc.: 75.00%] [G loss: 0.576840]\n",
      "epoch:6 step:6121 [D loss: 0.420155, acc.: 82.81%] [G loss: 0.736222]\n",
      "epoch:6 step:6122 [D loss: 0.665734, acc.: 59.38%] [G loss: 0.454738]\n",
      "epoch:6 step:6123 [D loss: 0.614915, acc.: 69.53%] [G loss: 0.429352]\n",
      "epoch:6 step:6124 [D loss: 0.596420, acc.: 68.75%] [G loss: 0.383878]\n",
      "epoch:6 step:6125 [D loss: 0.489032, acc.: 81.25%] [G loss: 0.481396]\n",
      "epoch:6 step:6126 [D loss: 0.528900, acc.: 77.34%] [G loss: 0.621609]\n",
      "epoch:6 step:6127 [D loss: 0.538017, acc.: 71.88%] [G loss: 0.566715]\n",
      "epoch:6 step:6128 [D loss: 0.530112, acc.: 71.09%] [G loss: 0.701171]\n",
      "epoch:6 step:6129 [D loss: 0.555436, acc.: 69.53%] [G loss: 0.618078]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:6 step:6130 [D loss: 0.433375, acc.: 82.03%] [G loss: 0.718566]\n",
      "epoch:6 step:6131 [D loss: 0.524128, acc.: 70.31%] [G loss: 0.685346]\n",
      "epoch:6 step:6132 [D loss: 0.575690, acc.: 70.31%] [G loss: 0.503136]\n",
      "epoch:6 step:6133 [D loss: 0.665995, acc.: 59.38%] [G loss: 0.357789]\n",
      "epoch:6 step:6134 [D loss: 0.545553, acc.: 71.09%] [G loss: 0.501608]\n",
      "epoch:6 step:6135 [D loss: 0.511107, acc.: 75.00%] [G loss: 0.556388]\n",
      "epoch:6 step:6136 [D loss: 0.509820, acc.: 74.22%] [G loss: 0.625029]\n",
      "epoch:6 step:6137 [D loss: 0.499788, acc.: 77.34%] [G loss: 0.491219]\n",
      "epoch:6 step:6138 [D loss: 0.480970, acc.: 78.12%] [G loss: 0.601566]\n",
      "epoch:6 step:6139 [D loss: 0.548924, acc.: 76.56%] [G loss: 0.594129]\n",
      "epoch:6 step:6140 [D loss: 0.530749, acc.: 76.56%] [G loss: 0.486025]\n",
      "epoch:6 step:6141 [D loss: 0.497978, acc.: 78.12%] [G loss: 0.623496]\n",
      "epoch:6 step:6142 [D loss: 0.482646, acc.: 75.78%] [G loss: 0.632935]\n",
      "epoch:6 step:6143 [D loss: 0.510266, acc.: 77.34%] [G loss: 0.589870]\n",
      "epoch:6 step:6144 [D loss: 0.532771, acc.: 71.88%] [G loss: 0.611240]\n",
      "epoch:6 step:6145 [D loss: 0.513138, acc.: 76.56%] [G loss: 0.788200]\n",
      "epoch:6 step:6146 [D loss: 0.556490, acc.: 70.31%] [G loss: 0.591548]\n",
      "epoch:6 step:6147 [D loss: 0.616171, acc.: 67.19%] [G loss: 0.532053]\n",
      "epoch:6 step:6148 [D loss: 0.545169, acc.: 68.75%] [G loss: 0.463792]\n",
      "epoch:6 step:6149 [D loss: 0.536991, acc.: 71.88%] [G loss: 0.576139]\n",
      "epoch:6 step:6150 [D loss: 0.680383, acc.: 56.25%] [G loss: 0.462764]\n",
      "epoch:6 step:6151 [D loss: 0.599111, acc.: 67.97%] [G loss: 0.590226]\n",
      "epoch:6 step:6152 [D loss: 0.486904, acc.: 78.12%] [G loss: 0.524842]\n",
      "epoch:6 step:6153 [D loss: 0.556839, acc.: 66.41%] [G loss: 0.569563]\n",
      "epoch:6 step:6154 [D loss: 0.565715, acc.: 70.31%] [G loss: 0.465359]\n",
      "epoch:6 step:6155 [D loss: 0.568205, acc.: 64.84%] [G loss: 0.376061]\n",
      "epoch:6 step:6156 [D loss: 0.481380, acc.: 78.12%] [G loss: 0.579864]\n",
      "epoch:6 step:6157 [D loss: 0.545709, acc.: 70.31%] [G loss: 0.463546]\n",
      "epoch:6 step:6158 [D loss: 0.466993, acc.: 77.34%] [G loss: 0.616352]\n",
      "epoch:6 step:6159 [D loss: 0.545232, acc.: 70.31%] [G loss: 0.451102]\n",
      "epoch:6 step:6160 [D loss: 0.563806, acc.: 68.75%] [G loss: 0.484175]\n",
      "epoch:6 step:6161 [D loss: 0.565963, acc.: 71.09%] [G loss: 0.559715]\n",
      "epoch:6 step:6162 [D loss: 0.574670, acc.: 61.72%] [G loss: 0.516758]\n",
      "epoch:6 step:6163 [D loss: 0.518985, acc.: 71.09%] [G loss: 0.554692]\n",
      "epoch:6 step:6164 [D loss: 0.566724, acc.: 71.88%] [G loss: 0.489931]\n",
      "epoch:6 step:6165 [D loss: 0.602459, acc.: 68.75%] [G loss: 0.412204]\n",
      "epoch:6 step:6166 [D loss: 0.568714, acc.: 69.53%] [G loss: 0.433868]\n",
      "epoch:6 step:6167 [D loss: 0.532661, acc.: 74.22%] [G loss: 0.507667]\n",
      "epoch:6 step:6168 [D loss: 0.494145, acc.: 73.44%] [G loss: 0.613618]\n",
      "epoch:6 step:6169 [D loss: 0.494849, acc.: 71.88%] [G loss: 0.670923]\n",
      "epoch:6 step:6170 [D loss: 0.553452, acc.: 71.09%] [G loss: 0.742536]\n",
      "epoch:6 step:6171 [D loss: 0.546209, acc.: 74.22%] [G loss: 0.605439]\n",
      "epoch:6 step:6172 [D loss: 0.613219, acc.: 62.50%] [G loss: 0.568600]\n",
      "epoch:6 step:6173 [D loss: 0.502877, acc.: 77.34%] [G loss: 0.735513]\n",
      "epoch:6 step:6174 [D loss: 0.485947, acc.: 77.34%] [G loss: 0.522181]\n",
      "epoch:6 step:6175 [D loss: 0.509037, acc.: 73.44%] [G loss: 0.675154]\n",
      "epoch:6 step:6176 [D loss: 0.468429, acc.: 73.44%] [G loss: 0.554149]\n",
      "epoch:6 step:6177 [D loss: 0.487084, acc.: 74.22%] [G loss: 0.667219]\n",
      "epoch:6 step:6178 [D loss: 0.474058, acc.: 82.03%] [G loss: 0.498179]\n",
      "epoch:6 step:6179 [D loss: 0.533924, acc.: 71.09%] [G loss: 0.667091]\n",
      "epoch:6 step:6180 [D loss: 0.520465, acc.: 71.09%] [G loss: 0.629275]\n",
      "epoch:6 step:6181 [D loss: 0.555157, acc.: 71.88%] [G loss: 0.678252]\n",
      "epoch:6 step:6182 [D loss: 0.552981, acc.: 70.31%] [G loss: 0.553886]\n",
      "epoch:6 step:6183 [D loss: 0.537470, acc.: 71.09%] [G loss: 0.583171]\n",
      "epoch:6 step:6184 [D loss: 0.629840, acc.: 62.50%] [G loss: 0.551236]\n",
      "epoch:6 step:6185 [D loss: 0.611007, acc.: 64.06%] [G loss: 0.465480]\n",
      "epoch:6 step:6186 [D loss: 0.524756, acc.: 73.44%] [G loss: 0.677442]\n",
      "epoch:6 step:6187 [D loss: 0.588410, acc.: 68.75%] [G loss: 0.652778]\n",
      "epoch:6 step:6188 [D loss: 0.638646, acc.: 66.41%] [G loss: 0.423756]\n",
      "epoch:6 step:6189 [D loss: 0.513978, acc.: 72.66%] [G loss: 0.417053]\n",
      "epoch:6 step:6190 [D loss: 0.521235, acc.: 74.22%] [G loss: 0.589262]\n",
      "epoch:6 step:6191 [D loss: 0.522021, acc.: 72.66%] [G loss: 0.641390]\n",
      "epoch:6 step:6192 [D loss: 0.537089, acc.: 72.66%] [G loss: 0.614640]\n",
      "epoch:6 step:6193 [D loss: 0.508520, acc.: 71.88%] [G loss: 0.562415]\n",
      "epoch:6 step:6194 [D loss: 0.556810, acc.: 71.88%] [G loss: 0.562486]\n",
      "epoch:6 step:6195 [D loss: 0.543253, acc.: 73.44%] [G loss: 0.623169]\n",
      "epoch:6 step:6196 [D loss: 0.486398, acc.: 79.69%] [G loss: 0.570020]\n",
      "epoch:6 step:6197 [D loss: 0.539275, acc.: 74.22%] [G loss: 0.711379]\n",
      "epoch:6 step:6198 [D loss: 0.606193, acc.: 64.84%] [G loss: 0.519798]\n",
      "epoch:6 step:6199 [D loss: 0.555093, acc.: 67.97%] [G loss: 0.529858]\n",
      "epoch:6 step:6200 [D loss: 0.548263, acc.: 69.53%] [G loss: 0.548894]\n",
      "##############\n",
      "[3.34352947 1.50525972 6.90818148 4.73140324 4.2171396  5.96030967\n",
      " 4.79252987 5.04002724 4.7479868  3.70926736]\n",
      "##########\n",
      "epoch:6 step:6201 [D loss: 0.571968, acc.: 67.97%] [G loss: 0.519839]\n",
      "epoch:6 step:6202 [D loss: 0.581799, acc.: 67.97%] [G loss: 0.511821]\n",
      "epoch:6 step:6203 [D loss: 0.539938, acc.: 67.97%] [G loss: 0.565354]\n",
      "epoch:6 step:6204 [D loss: 0.463588, acc.: 77.34%] [G loss: 0.700874]\n",
      "epoch:6 step:6205 [D loss: 0.498296, acc.: 72.66%] [G loss: 0.672027]\n",
      "epoch:6 step:6206 [D loss: 0.610709, acc.: 69.53%] [G loss: 0.669844]\n",
      "epoch:6 step:6207 [D loss: 0.543246, acc.: 67.97%] [G loss: 0.546542]\n",
      "epoch:6 step:6208 [D loss: 0.592001, acc.: 67.19%] [G loss: 0.520230]\n",
      "epoch:6 step:6209 [D loss: 0.569633, acc.: 62.50%] [G loss: 0.521880]\n",
      "epoch:6 step:6210 [D loss: 0.613801, acc.: 64.06%] [G loss: 0.605362]\n",
      "epoch:6 step:6211 [D loss: 0.537147, acc.: 70.31%] [G loss: 0.708514]\n",
      "epoch:6 step:6212 [D loss: 0.637930, acc.: 63.28%] [G loss: 0.476192]\n",
      "epoch:6 step:6213 [D loss: 0.604102, acc.: 69.53%] [G loss: 0.375148]\n",
      "epoch:6 step:6214 [D loss: 0.499596, acc.: 74.22%] [G loss: 0.597358]\n",
      "epoch:6 step:6215 [D loss: 0.535771, acc.: 71.88%] [G loss: 0.509321]\n",
      "epoch:6 step:6216 [D loss: 0.545076, acc.: 70.31%] [G loss: 0.536470]\n",
      "epoch:6 step:6217 [D loss: 0.570855, acc.: 64.84%] [G loss: 0.509350]\n",
      "epoch:6 step:6218 [D loss: 0.573746, acc.: 67.19%] [G loss: 0.534898]\n",
      "epoch:6 step:6219 [D loss: 0.525665, acc.: 70.31%] [G loss: 0.614576]\n",
      "epoch:6 step:6220 [D loss: 0.481456, acc.: 80.47%] [G loss: 0.549666]\n",
      "epoch:6 step:6221 [D loss: 0.561817, acc.: 70.31%] [G loss: 0.575265]\n",
      "epoch:6 step:6222 [D loss: 0.578242, acc.: 68.75%] [G loss: 0.503203]\n",
      "epoch:6 step:6223 [D loss: 0.551087, acc.: 67.97%] [G loss: 0.503809]\n",
      "epoch:6 step:6224 [D loss: 0.531361, acc.: 71.88%] [G loss: 0.537598]\n",
      "epoch:6 step:6225 [D loss: 0.443918, acc.: 80.47%] [G loss: 0.653548]\n",
      "epoch:6 step:6226 [D loss: 0.564839, acc.: 71.09%] [G loss: 0.643048]\n",
      "epoch:6 step:6227 [D loss: 0.462892, acc.: 78.12%] [G loss: 0.621271]\n",
      "epoch:6 step:6228 [D loss: 0.608517, acc.: 63.28%] [G loss: 0.532868]\n",
      "epoch:6 step:6229 [D loss: 0.501916, acc.: 76.56%] [G loss: 0.599994]\n",
      "epoch:6 step:6230 [D loss: 0.512132, acc.: 71.88%] [G loss: 0.433909]\n",
      "epoch:6 step:6231 [D loss: 0.530980, acc.: 72.66%] [G loss: 0.504450]\n",
      "epoch:6 step:6232 [D loss: 0.599571, acc.: 70.31%] [G loss: 0.470146]\n",
      "epoch:6 step:6233 [D loss: 0.467428, acc.: 77.34%] [G loss: 0.585729]\n",
      "epoch:6 step:6234 [D loss: 0.550543, acc.: 67.97%] [G loss: 0.508605]\n",
      "epoch:6 step:6235 [D loss: 0.493454, acc.: 75.78%] [G loss: 0.548520]\n",
      "epoch:6 step:6236 [D loss: 0.619716, acc.: 64.06%] [G loss: 0.463891]\n",
      "epoch:6 step:6237 [D loss: 0.671842, acc.: 59.38%] [G loss: 0.441306]\n",
      "epoch:6 step:6238 [D loss: 0.548703, acc.: 67.19%] [G loss: 0.608585]\n",
      "epoch:6 step:6239 [D loss: 0.519627, acc.: 72.66%] [G loss: 0.531405]\n",
      "epoch:6 step:6240 [D loss: 0.655343, acc.: 65.62%] [G loss: 0.560934]\n",
      "epoch:6 step:6241 [D loss: 0.515312, acc.: 72.66%] [G loss: 0.663077]\n",
      "epoch:6 step:6242 [D loss: 0.558364, acc.: 71.09%] [G loss: 0.544046]\n",
      "epoch:6 step:6243 [D loss: 0.578598, acc.: 67.97%] [G loss: 0.487941]\n",
      "epoch:6 step:6244 [D loss: 0.635186, acc.: 61.72%] [G loss: 0.405852]\n",
      "epoch:6 step:6245 [D loss: 0.477316, acc.: 80.47%] [G loss: 0.528614]\n",
      "epoch:6 step:6246 [D loss: 0.507046, acc.: 77.34%] [G loss: 0.603439]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:6 step:6247 [D loss: 0.565494, acc.: 63.28%] [G loss: 0.473665]\n",
      "epoch:6 step:6248 [D loss: 0.522597, acc.: 71.09%] [G loss: 0.473794]\n",
      "epoch:6 step:6249 [D loss: 0.526441, acc.: 73.44%] [G loss: 0.581216]\n",
      "epoch:6 step:6250 [D loss: 0.590367, acc.: 66.41%] [G loss: 0.493514]\n",
      "epoch:6 step:6251 [D loss: 0.489858, acc.: 75.00%] [G loss: 0.601355]\n",
      "epoch:6 step:6252 [D loss: 0.522722, acc.: 73.44%] [G loss: 0.531268]\n",
      "epoch:6 step:6253 [D loss: 0.499060, acc.: 75.78%] [G loss: 0.623144]\n",
      "epoch:6 step:6254 [D loss: 0.556121, acc.: 72.66%] [G loss: 0.676460]\n",
      "epoch:6 step:6255 [D loss: 0.529003, acc.: 73.44%] [G loss: 0.482692]\n",
      "epoch:6 step:6256 [D loss: 0.522423, acc.: 74.22%] [G loss: 0.569847]\n",
      "epoch:6 step:6257 [D loss: 0.533886, acc.: 71.88%] [G loss: 0.531706]\n",
      "epoch:6 step:6258 [D loss: 0.591141, acc.: 65.62%] [G loss: 0.524214]\n",
      "epoch:6 step:6259 [D loss: 0.510074, acc.: 73.44%] [G loss: 0.524761]\n",
      "epoch:6 step:6260 [D loss: 0.543126, acc.: 73.44%] [G loss: 0.526767]\n",
      "epoch:6 step:6261 [D loss: 0.517151, acc.: 72.66%] [G loss: 0.531076]\n",
      "epoch:6 step:6262 [D loss: 0.541093, acc.: 71.88%] [G loss: 0.459682]\n",
      "epoch:6 step:6263 [D loss: 0.456995, acc.: 82.81%] [G loss: 0.623964]\n",
      "epoch:6 step:6264 [D loss: 0.484881, acc.: 75.78%] [G loss: 0.653819]\n",
      "epoch:6 step:6265 [D loss: 0.522350, acc.: 71.88%] [G loss: 0.755438]\n",
      "epoch:6 step:6266 [D loss: 0.571933, acc.: 66.41%] [G loss: 0.571958]\n",
      "epoch:6 step:6267 [D loss: 0.553466, acc.: 73.44%] [G loss: 0.622950]\n",
      "epoch:6 step:6268 [D loss: 0.567284, acc.: 67.97%] [G loss: 0.474755]\n",
      "epoch:6 step:6269 [D loss: 0.464320, acc.: 84.38%] [G loss: 0.533577]\n",
      "epoch:6 step:6270 [D loss: 0.385453, acc.: 82.81%] [G loss: 0.737640]\n",
      "epoch:6 step:6271 [D loss: 0.521954, acc.: 73.44%] [G loss: 0.698861]\n",
      "epoch:6 step:6272 [D loss: 0.496763, acc.: 77.34%] [G loss: 0.789707]\n",
      "epoch:6 step:6273 [D loss: 0.496424, acc.: 76.56%] [G loss: 0.677677]\n",
      "epoch:6 step:6274 [D loss: 0.632013, acc.: 66.41%] [G loss: 0.589077]\n",
      "epoch:6 step:6275 [D loss: 0.640371, acc.: 61.72%] [G loss: 0.432523]\n",
      "epoch:6 step:6276 [D loss: 0.517744, acc.: 68.75%] [G loss: 0.454056]\n",
      "epoch:6 step:6277 [D loss: 0.524652, acc.: 72.66%] [G loss: 0.494147]\n",
      "epoch:6 step:6278 [D loss: 0.525019, acc.: 72.66%] [G loss: 0.530040]\n",
      "epoch:6 step:6279 [D loss: 0.530491, acc.: 68.75%] [G loss: 0.528548]\n",
      "epoch:6 step:6280 [D loss: 0.567392, acc.: 68.75%] [G loss: 0.593464]\n",
      "epoch:6 step:6281 [D loss: 0.546398, acc.: 67.97%] [G loss: 0.564113]\n",
      "epoch:6 step:6282 [D loss: 0.528453, acc.: 78.91%] [G loss: 0.505960]\n",
      "epoch:6 step:6283 [D loss: 0.535811, acc.: 74.22%] [G loss: 0.583651]\n",
      "epoch:6 step:6284 [D loss: 0.569952, acc.: 67.97%] [G loss: 0.578371]\n",
      "epoch:6 step:6285 [D loss: 0.484359, acc.: 75.00%] [G loss: 0.654959]\n",
      "epoch:6 step:6286 [D loss: 0.601503, acc.: 64.84%] [G loss: 0.621466]\n",
      "epoch:6 step:6287 [D loss: 0.584552, acc.: 68.75%] [G loss: 0.724104]\n",
      "epoch:6 step:6288 [D loss: 0.558272, acc.: 68.75%] [G loss: 0.628068]\n",
      "epoch:6 step:6289 [D loss: 0.580019, acc.: 67.97%] [G loss: 0.555040]\n",
      "epoch:6 step:6290 [D loss: 0.546064, acc.: 77.34%] [G loss: 0.494266]\n",
      "epoch:6 step:6291 [D loss: 0.533015, acc.: 71.09%] [G loss: 0.529712]\n",
      "epoch:6 step:6292 [D loss: 0.545608, acc.: 69.53%] [G loss: 0.491357]\n",
      "epoch:6 step:6293 [D loss: 0.585666, acc.: 67.97%] [G loss: 0.533445]\n",
      "epoch:6 step:6294 [D loss: 0.532281, acc.: 70.31%] [G loss: 0.752887]\n",
      "epoch:6 step:6295 [D loss: 0.572105, acc.: 69.53%] [G loss: 0.602883]\n",
      "epoch:6 step:6296 [D loss: 0.554319, acc.: 72.66%] [G loss: 0.470041]\n",
      "epoch:6 step:6297 [D loss: 0.578331, acc.: 67.19%] [G loss: 0.637597]\n",
      "epoch:6 step:6298 [D loss: 0.528285, acc.: 75.78%] [G loss: 0.591448]\n",
      "epoch:6 step:6299 [D loss: 0.654622, acc.: 62.50%] [G loss: 0.413207]\n",
      "epoch:6 step:6300 [D loss: 0.554748, acc.: 75.00%] [G loss: 0.494746]\n",
      "epoch:6 step:6301 [D loss: 0.558380, acc.: 67.97%] [G loss: 0.472330]\n",
      "epoch:6 step:6302 [D loss: 0.478490, acc.: 79.69%] [G loss: 0.702340]\n",
      "epoch:6 step:6303 [D loss: 0.504751, acc.: 76.56%] [G loss: 0.653732]\n",
      "epoch:6 step:6304 [D loss: 0.538656, acc.: 75.78%] [G loss: 0.653370]\n",
      "epoch:6 step:6305 [D loss: 0.525090, acc.: 77.34%] [G loss: 0.631207]\n",
      "epoch:6 step:6306 [D loss: 0.573257, acc.: 67.97%] [G loss: 0.538817]\n",
      "epoch:6 step:6307 [D loss: 0.525125, acc.: 73.44%] [G loss: 0.480993]\n",
      "epoch:6 step:6308 [D loss: 0.568941, acc.: 71.88%] [G loss: 0.472140]\n",
      "epoch:6 step:6309 [D loss: 0.563937, acc.: 67.97%] [G loss: 0.425693]\n",
      "epoch:6 step:6310 [D loss: 0.569844, acc.: 68.75%] [G loss: 0.494464]\n",
      "epoch:6 step:6311 [D loss: 0.560028, acc.: 66.41%] [G loss: 0.504040]\n",
      "epoch:6 step:6312 [D loss: 0.477361, acc.: 77.34%] [G loss: 0.629327]\n",
      "epoch:6 step:6313 [D loss: 0.496059, acc.: 76.56%] [G loss: 0.634171]\n",
      "epoch:6 step:6314 [D loss: 0.536796, acc.: 71.09%] [G loss: 0.721690]\n",
      "epoch:6 step:6315 [D loss: 0.468757, acc.: 77.34%] [G loss: 0.595672]\n",
      "epoch:6 step:6316 [D loss: 0.536927, acc.: 74.22%] [G loss: 0.738004]\n",
      "epoch:6 step:6317 [D loss: 0.510313, acc.: 72.66%] [G loss: 0.628148]\n",
      "epoch:6 step:6318 [D loss: 0.623188, acc.: 62.50%] [G loss: 0.482713]\n",
      "epoch:6 step:6319 [D loss: 0.536434, acc.: 66.41%] [G loss: 0.562860]\n",
      "epoch:6 step:6320 [D loss: 0.524522, acc.: 71.88%] [G loss: 0.621634]\n",
      "epoch:6 step:6321 [D loss: 0.538318, acc.: 70.31%] [G loss: 0.590995]\n",
      "epoch:6 step:6322 [D loss: 0.574019, acc.: 63.28%] [G loss: 0.569017]\n",
      "epoch:6 step:6323 [D loss: 0.521663, acc.: 78.12%] [G loss: 0.771853]\n",
      "epoch:6 step:6324 [D loss: 0.576171, acc.: 66.41%] [G loss: 0.543930]\n",
      "epoch:6 step:6325 [D loss: 0.597381, acc.: 62.50%] [G loss: 0.548018]\n",
      "epoch:6 step:6326 [D loss: 0.648345, acc.: 57.81%] [G loss: 0.432509]\n",
      "epoch:6 step:6327 [D loss: 0.540627, acc.: 74.22%] [G loss: 0.610416]\n",
      "epoch:6 step:6328 [D loss: 0.501498, acc.: 71.88%] [G loss: 0.521265]\n",
      "epoch:6 step:6329 [D loss: 0.482951, acc.: 75.78%] [G loss: 0.526510]\n",
      "epoch:6 step:6330 [D loss: 0.476454, acc.: 78.12%] [G loss: 0.589693]\n",
      "epoch:6 step:6331 [D loss: 0.516808, acc.: 74.22%] [G loss: 0.660881]\n",
      "epoch:6 step:6332 [D loss: 0.637454, acc.: 63.28%] [G loss: 0.557752]\n",
      "epoch:6 step:6333 [D loss: 0.588103, acc.: 67.97%] [G loss: 0.498430]\n",
      "epoch:6 step:6334 [D loss: 0.513056, acc.: 74.22%] [G loss: 0.568967]\n",
      "epoch:6 step:6335 [D loss: 0.626707, acc.: 65.62%] [G loss: 0.488059]\n",
      "epoch:6 step:6336 [D loss: 0.546421, acc.: 70.31%] [G loss: 0.473533]\n",
      "epoch:6 step:6337 [D loss: 0.538688, acc.: 72.66%] [G loss: 0.573620]\n",
      "epoch:6 step:6338 [D loss: 0.595919, acc.: 67.97%] [G loss: 0.452536]\n",
      "epoch:6 step:6339 [D loss: 0.631266, acc.: 66.41%] [G loss: 0.580453]\n",
      "epoch:6 step:6340 [D loss: 0.617200, acc.: 63.28%] [G loss: 0.443831]\n",
      "epoch:6 step:6341 [D loss: 0.488646, acc.: 78.91%] [G loss: 0.625700]\n",
      "epoch:6 step:6342 [D loss: 0.685331, acc.: 61.72%] [G loss: 0.356785]\n",
      "epoch:6 step:6343 [D loss: 0.550853, acc.: 73.44%] [G loss: 0.475157]\n",
      "epoch:6 step:6344 [D loss: 0.551308, acc.: 67.97%] [G loss: 0.535611]\n",
      "epoch:6 step:6345 [D loss: 0.545901, acc.: 72.66%] [G loss: 0.505563]\n",
      "epoch:6 step:6346 [D loss: 0.538070, acc.: 70.31%] [G loss: 0.415878]\n",
      "epoch:6 step:6347 [D loss: 0.492212, acc.: 79.69%] [G loss: 0.670364]\n",
      "epoch:6 step:6348 [D loss: 0.476951, acc.: 77.34%] [G loss: 0.720754]\n",
      "epoch:6 step:6349 [D loss: 0.608365, acc.: 65.62%] [G loss: 0.524976]\n",
      "epoch:6 step:6350 [D loss: 0.550596, acc.: 70.31%] [G loss: 0.453413]\n",
      "epoch:6 step:6351 [D loss: 0.613641, acc.: 64.84%] [G loss: 0.403556]\n",
      "epoch:6 step:6352 [D loss: 0.517919, acc.: 73.44%] [G loss: 0.537299]\n",
      "epoch:6 step:6353 [D loss: 0.566011, acc.: 68.75%] [G loss: 0.547908]\n",
      "epoch:6 step:6354 [D loss: 0.527402, acc.: 70.31%] [G loss: 0.534671]\n",
      "epoch:6 step:6355 [D loss: 0.548121, acc.: 67.97%] [G loss: 0.629720]\n",
      "epoch:6 step:6356 [D loss: 0.473228, acc.: 78.12%] [G loss: 0.632182]\n",
      "epoch:6 step:6357 [D loss: 0.591135, acc.: 68.75%] [G loss: 0.524167]\n",
      "epoch:6 step:6358 [D loss: 0.510822, acc.: 76.56%] [G loss: 0.483161]\n",
      "epoch:6 step:6359 [D loss: 0.508270, acc.: 75.78%] [G loss: 0.518568]\n",
      "epoch:6 step:6360 [D loss: 0.526523, acc.: 71.09%] [G loss: 0.590588]\n",
      "epoch:6 step:6361 [D loss: 0.605968, acc.: 67.19%] [G loss: 0.473232]\n",
      "epoch:6 step:6362 [D loss: 0.659884, acc.: 55.47%] [G loss: 0.404761]\n",
      "epoch:6 step:6363 [D loss: 0.599736, acc.: 65.62%] [G loss: 0.440967]\n",
      "epoch:6 step:6364 [D loss: 0.565042, acc.: 69.53%] [G loss: 0.430147]\n",
      "epoch:6 step:6365 [D loss: 0.522404, acc.: 71.88%] [G loss: 0.586697]\n",
      "epoch:6 step:6366 [D loss: 0.542561, acc.: 67.97%] [G loss: 0.600334]\n",
      "epoch:6 step:6367 [D loss: 0.597620, acc.: 65.62%] [G loss: 0.514389]\n",
      "epoch:6 step:6368 [D loss: 0.470442, acc.: 77.34%] [G loss: 0.574632]\n",
      "epoch:6 step:6369 [D loss: 0.446905, acc.: 81.25%] [G loss: 0.621849]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:6 step:6370 [D loss: 0.525225, acc.: 73.44%] [G loss: 0.568358]\n",
      "epoch:6 step:6371 [D loss: 0.514828, acc.: 75.78%] [G loss: 0.593443]\n",
      "epoch:6 step:6372 [D loss: 0.491842, acc.: 74.22%] [G loss: 0.677209]\n",
      "epoch:6 step:6373 [D loss: 0.498117, acc.: 75.78%] [G loss: 0.650767]\n",
      "epoch:6 step:6374 [D loss: 0.581789, acc.: 67.19%] [G loss: 0.471733]\n",
      "epoch:6 step:6375 [D loss: 0.459795, acc.: 78.12%] [G loss: 0.557005]\n",
      "epoch:6 step:6376 [D loss: 0.511740, acc.: 72.66%] [G loss: 0.608869]\n",
      "epoch:6 step:6377 [D loss: 0.557911, acc.: 70.31%] [G loss: 0.507548]\n",
      "epoch:6 step:6378 [D loss: 0.574552, acc.: 65.62%] [G loss: 0.700448]\n",
      "epoch:6 step:6379 [D loss: 0.549766, acc.: 70.31%] [G loss: 0.655196]\n",
      "epoch:6 step:6380 [D loss: 0.514418, acc.: 76.56%] [G loss: 0.559412]\n",
      "epoch:6 step:6381 [D loss: 0.568436, acc.: 68.75%] [G loss: 0.567477]\n",
      "epoch:6 step:6382 [D loss: 0.514595, acc.: 73.44%] [G loss: 0.479838]\n",
      "epoch:6 step:6383 [D loss: 0.507413, acc.: 73.44%] [G loss: 0.484243]\n",
      "epoch:6 step:6384 [D loss: 0.587462, acc.: 68.75%] [G loss: 0.502093]\n",
      "epoch:6 step:6385 [D loss: 0.615004, acc.: 65.62%] [G loss: 0.587566]\n",
      "epoch:6 step:6386 [D loss: 0.531500, acc.: 71.88%] [G loss: 0.563647]\n",
      "epoch:6 step:6387 [D loss: 0.675328, acc.: 59.38%] [G loss: 0.416322]\n",
      "epoch:6 step:6388 [D loss: 0.675207, acc.: 57.03%] [G loss: 0.449682]\n",
      "epoch:6 step:6389 [D loss: 0.579480, acc.: 71.09%] [G loss: 0.492466]\n",
      "epoch:6 step:6390 [D loss: 0.581779, acc.: 68.75%] [G loss: 0.609827]\n",
      "epoch:6 step:6391 [D loss: 0.530139, acc.: 71.09%] [G loss: 0.680081]\n",
      "epoch:6 step:6392 [D loss: 0.524429, acc.: 73.44%] [G loss: 0.649135]\n",
      "epoch:6 step:6393 [D loss: 0.553715, acc.: 68.75%] [G loss: 0.574594]\n",
      "epoch:6 step:6394 [D loss: 0.531893, acc.: 70.31%] [G loss: 0.587408]\n",
      "epoch:6 step:6395 [D loss: 0.546440, acc.: 70.31%] [G loss: 0.510561]\n",
      "epoch:6 step:6396 [D loss: 0.596189, acc.: 68.75%] [G loss: 0.511480]\n",
      "epoch:6 step:6397 [D loss: 0.511384, acc.: 71.88%] [G loss: 0.614864]\n",
      "epoch:6 step:6398 [D loss: 0.638264, acc.: 63.28%] [G loss: 0.584915]\n",
      "epoch:6 step:6399 [D loss: 0.540866, acc.: 71.88%] [G loss: 0.482506]\n",
      "epoch:6 step:6400 [D loss: 0.523611, acc.: 75.00%] [G loss: 0.517417]\n",
      "##############\n",
      "[3.30483371 1.53279652 6.65584639 5.03072141 4.1307842  6.18179859\n",
      " 5.0704004  4.68673808 4.92867325 3.8681102 ]\n",
      "##########\n",
      "epoch:6 step:6401 [D loss: 0.557956, acc.: 71.88%] [G loss: 0.495133]\n",
      "epoch:6 step:6402 [D loss: 0.522973, acc.: 76.56%] [G loss: 0.562685]\n",
      "epoch:6 step:6403 [D loss: 0.505992, acc.: 75.78%] [G loss: 0.791283]\n",
      "epoch:6 step:6404 [D loss: 0.477181, acc.: 75.00%] [G loss: 0.714112]\n",
      "epoch:6 step:6405 [D loss: 0.517088, acc.: 71.09%] [G loss: 0.612168]\n",
      "epoch:6 step:6406 [D loss: 0.609100, acc.: 63.28%] [G loss: 0.596937]\n",
      "epoch:6 step:6407 [D loss: 0.597252, acc.: 68.75%] [G loss: 0.442275]\n",
      "epoch:6 step:6408 [D loss: 0.519995, acc.: 71.88%] [G loss: 0.605441]\n",
      "epoch:6 step:6409 [D loss: 0.573448, acc.: 69.53%] [G loss: 0.536872]\n",
      "epoch:6 step:6410 [D loss: 0.670456, acc.: 59.38%] [G loss: 0.449167]\n",
      "epoch:6 step:6411 [D loss: 0.549707, acc.: 68.75%] [G loss: 0.357804]\n",
      "epoch:6 step:6412 [D loss: 0.528210, acc.: 76.56%] [G loss: 0.463597]\n",
      "epoch:6 step:6413 [D loss: 0.566584, acc.: 70.31%] [G loss: 0.534223]\n",
      "epoch:6 step:6414 [D loss: 0.455490, acc.: 79.69%] [G loss: 0.584059]\n",
      "epoch:6 step:6415 [D loss: 0.618090, acc.: 68.75%] [G loss: 0.624053]\n",
      "epoch:6 step:6416 [D loss: 0.657356, acc.: 59.38%] [G loss: 0.529413]\n",
      "epoch:6 step:6417 [D loss: 0.557101, acc.: 71.09%] [G loss: 0.561081]\n",
      "epoch:6 step:6418 [D loss: 0.480963, acc.: 75.00%] [G loss: 0.550664]\n",
      "epoch:6 step:6419 [D loss: 0.519956, acc.: 70.31%] [G loss: 0.590387]\n",
      "epoch:6 step:6420 [D loss: 0.489714, acc.: 70.31%] [G loss: 0.677016]\n",
      "epoch:6 step:6421 [D loss: 0.587368, acc.: 71.09%] [G loss: 0.458482]\n",
      "epoch:6 step:6422 [D loss: 0.545660, acc.: 68.75%] [G loss: 0.651430]\n",
      "epoch:6 step:6423 [D loss: 0.514514, acc.: 75.00%] [G loss: 0.587326]\n",
      "epoch:6 step:6424 [D loss: 0.451843, acc.: 81.25%] [G loss: 0.584944]\n",
      "epoch:6 step:6425 [D loss: 0.556577, acc.: 73.44%] [G loss: 0.561567]\n",
      "epoch:6 step:6426 [D loss: 0.577531, acc.: 64.06%] [G loss: 0.479357]\n",
      "epoch:6 step:6427 [D loss: 0.550389, acc.: 69.53%] [G loss: 0.456529]\n",
      "epoch:6 step:6428 [D loss: 0.522699, acc.: 72.66%] [G loss: 0.600833]\n",
      "epoch:6 step:6429 [D loss: 0.500422, acc.: 75.78%] [G loss: 0.792258]\n",
      "epoch:6 step:6430 [D loss: 0.551201, acc.: 74.22%] [G loss: 0.486654]\n",
      "epoch:6 step:6431 [D loss: 0.503881, acc.: 73.44%] [G loss: 0.513941]\n",
      "epoch:6 step:6432 [D loss: 0.498725, acc.: 75.00%] [G loss: 0.552635]\n",
      "epoch:6 step:6433 [D loss: 0.551314, acc.: 67.19%] [G loss: 0.561508]\n",
      "epoch:6 step:6434 [D loss: 0.598296, acc.: 67.19%] [G loss: 0.510536]\n",
      "epoch:6 step:6435 [D loss: 0.555487, acc.: 69.53%] [G loss: 0.425564]\n",
      "epoch:6 step:6436 [D loss: 0.509151, acc.: 75.00%] [G loss: 0.484673]\n",
      "epoch:6 step:6437 [D loss: 0.531413, acc.: 73.44%] [G loss: 0.706477]\n",
      "epoch:6 step:6438 [D loss: 0.586848, acc.: 65.62%] [G loss: 0.736678]\n",
      "epoch:6 step:6439 [D loss: 0.581188, acc.: 70.31%] [G loss: 0.591367]\n",
      "epoch:6 step:6440 [D loss: 0.633997, acc.: 60.94%] [G loss: 0.460299]\n",
      "epoch:6 step:6441 [D loss: 0.524633, acc.: 73.44%] [G loss: 0.543029]\n",
      "epoch:6 step:6442 [D loss: 0.599617, acc.: 67.19%] [G loss: 0.528994]\n",
      "epoch:6 step:6443 [D loss: 0.533826, acc.: 73.44%] [G loss: 0.502501]\n",
      "epoch:6 step:6444 [D loss: 0.490704, acc.: 72.66%] [G loss: 0.622811]\n",
      "epoch:6 step:6445 [D loss: 0.467937, acc.: 78.12%] [G loss: 0.470673]\n",
      "epoch:6 step:6446 [D loss: 0.634721, acc.: 64.84%] [G loss: 0.459394]\n",
      "epoch:6 step:6447 [D loss: 0.521806, acc.: 71.88%] [G loss: 0.542244]\n",
      "epoch:6 step:6448 [D loss: 0.619033, acc.: 61.72%] [G loss: 0.621551]\n",
      "epoch:6 step:6449 [D loss: 0.582612, acc.: 64.84%] [G loss: 0.485672]\n",
      "epoch:6 step:6450 [D loss: 0.636789, acc.: 60.16%] [G loss: 0.492967]\n",
      "epoch:6 step:6451 [D loss: 0.541978, acc.: 67.19%] [G loss: 0.562947]\n",
      "epoch:6 step:6452 [D loss: 0.563058, acc.: 72.66%] [G loss: 0.512565]\n",
      "epoch:6 step:6453 [D loss: 0.544751, acc.: 71.88%] [G loss: 0.557238]\n",
      "epoch:6 step:6454 [D loss: 0.512086, acc.: 71.88%] [G loss: 0.570355]\n",
      "epoch:6 step:6455 [D loss: 0.519071, acc.: 73.44%] [G loss: 0.646239]\n",
      "epoch:6 step:6456 [D loss: 0.511662, acc.: 75.00%] [G loss: 0.598030]\n",
      "epoch:6 step:6457 [D loss: 0.559148, acc.: 75.78%] [G loss: 0.443291]\n",
      "epoch:6 step:6458 [D loss: 0.529959, acc.: 73.44%] [G loss: 0.499696]\n",
      "epoch:6 step:6459 [D loss: 0.547921, acc.: 74.22%] [G loss: 0.515872]\n",
      "epoch:6 step:6460 [D loss: 0.526607, acc.: 75.78%] [G loss: 0.520694]\n",
      "epoch:6 step:6461 [D loss: 0.603273, acc.: 65.62%] [G loss: 0.491344]\n",
      "epoch:6 step:6462 [D loss: 0.572356, acc.: 67.19%] [G loss: 0.528131]\n",
      "epoch:6 step:6463 [D loss: 0.540054, acc.: 67.19%] [G loss: 0.537736]\n",
      "epoch:6 step:6464 [D loss: 0.528370, acc.: 70.31%] [G loss: 0.380542]\n",
      "epoch:6 step:6465 [D loss: 0.520948, acc.: 74.22%] [G loss: 0.437130]\n",
      "epoch:6 step:6466 [D loss: 0.586110, acc.: 67.97%] [G loss: 0.539864]\n",
      "epoch:6 step:6467 [D loss: 0.574921, acc.: 70.31%] [G loss: 0.591790]\n",
      "epoch:6 step:6468 [D loss: 0.550633, acc.: 71.88%] [G loss: 0.353550]\n",
      "epoch:6 step:6469 [D loss: 0.578283, acc.: 64.84%] [G loss: 0.425728]\n",
      "epoch:6 step:6470 [D loss: 0.529547, acc.: 70.31%] [G loss: 0.462094]\n",
      "epoch:6 step:6471 [D loss: 0.568384, acc.: 70.31%] [G loss: 0.402449]\n",
      "epoch:6 step:6472 [D loss: 0.556270, acc.: 67.19%] [G loss: 0.536412]\n",
      "epoch:6 step:6473 [D loss: 0.562243, acc.: 66.41%] [G loss: 0.492412]\n",
      "epoch:6 step:6474 [D loss: 0.516050, acc.: 74.22%] [G loss: 0.607814]\n",
      "epoch:6 step:6475 [D loss: 0.527256, acc.: 71.88%] [G loss: 0.656762]\n",
      "epoch:6 step:6476 [D loss: 0.480996, acc.: 77.34%] [G loss: 0.673143]\n",
      "epoch:6 step:6477 [D loss: 0.530627, acc.: 74.22%] [G loss: 0.544187]\n",
      "epoch:6 step:6478 [D loss: 0.574789, acc.: 74.22%] [G loss: 0.537084]\n",
      "epoch:6 step:6479 [D loss: 0.505766, acc.: 75.00%] [G loss: 0.560960]\n",
      "epoch:6 step:6480 [D loss: 0.677544, acc.: 60.16%] [G loss: 0.525661]\n",
      "epoch:6 step:6481 [D loss: 0.564870, acc.: 71.88%] [G loss: 0.550662]\n",
      "epoch:6 step:6482 [D loss: 0.468398, acc.: 79.69%] [G loss: 0.762951]\n",
      "epoch:6 step:6483 [D loss: 0.588669, acc.: 68.75%] [G loss: 0.602022]\n",
      "epoch:6 step:6484 [D loss: 0.563750, acc.: 69.53%] [G loss: 0.375149]\n",
      "epoch:6 step:6485 [D loss: 0.615931, acc.: 57.03%] [G loss: 0.372040]\n",
      "epoch:6 step:6486 [D loss: 0.512768, acc.: 72.66%] [G loss: 0.529675]\n",
      "epoch:6 step:6487 [D loss: 0.546392, acc.: 71.88%] [G loss: 0.491683]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:6 step:6488 [D loss: 0.530352, acc.: 71.09%] [G loss: 0.560782]\n",
      "epoch:6 step:6489 [D loss: 0.665740, acc.: 61.72%] [G loss: 0.447078]\n",
      "epoch:6 step:6490 [D loss: 0.520236, acc.: 78.12%] [G loss: 0.534840]\n",
      "epoch:6 step:6491 [D loss: 0.582608, acc.: 65.62%] [G loss: 0.387628]\n",
      "epoch:6 step:6492 [D loss: 0.459336, acc.: 80.47%] [G loss: 0.531081]\n",
      "epoch:6 step:6493 [D loss: 0.499490, acc.: 70.31%] [G loss: 0.684736]\n",
      "epoch:6 step:6494 [D loss: 0.502801, acc.: 71.88%] [G loss: 0.609333]\n",
      "epoch:6 step:6495 [D loss: 0.528968, acc.: 72.66%] [G loss: 0.507790]\n",
      "epoch:6 step:6496 [D loss: 0.580656, acc.: 68.75%] [G loss: 0.519751]\n",
      "epoch:6 step:6497 [D loss: 0.498110, acc.: 81.25%] [G loss: 0.531011]\n",
      "epoch:6 step:6498 [D loss: 0.522139, acc.: 71.88%] [G loss: 0.506869]\n",
      "epoch:6 step:6499 [D loss: 0.534714, acc.: 70.31%] [G loss: 0.485477]\n",
      "epoch:6 step:6500 [D loss: 0.515565, acc.: 72.66%] [G loss: 0.663800]\n",
      "epoch:6 step:6501 [D loss: 0.594855, acc.: 65.62%] [G loss: 0.579860]\n",
      "epoch:6 step:6502 [D loss: 0.690387, acc.: 58.59%] [G loss: 0.511866]\n",
      "epoch:6 step:6503 [D loss: 0.527298, acc.: 72.66%] [G loss: 0.404537]\n",
      "epoch:6 step:6504 [D loss: 0.572579, acc.: 70.31%] [G loss: 0.515130]\n",
      "epoch:6 step:6505 [D loss: 0.594098, acc.: 67.97%] [G loss: 0.428351]\n",
      "epoch:6 step:6506 [D loss: 0.509943, acc.: 71.88%] [G loss: 0.628572]\n",
      "epoch:6 step:6507 [D loss: 0.508185, acc.: 71.88%] [G loss: 0.655291]\n",
      "epoch:6 step:6508 [D loss: 0.544187, acc.: 67.97%] [G loss: 0.774195]\n",
      "epoch:6 step:6509 [D loss: 0.549813, acc.: 75.00%] [G loss: 0.660440]\n",
      "epoch:6 step:6510 [D loss: 0.580835, acc.: 64.84%] [G loss: 0.647878]\n",
      "epoch:6 step:6511 [D loss: 0.569693, acc.: 70.31%] [G loss: 0.605703]\n",
      "epoch:6 step:6512 [D loss: 0.499892, acc.: 78.12%] [G loss: 0.629726]\n",
      "epoch:6 step:6513 [D loss: 0.616668, acc.: 66.41%] [G loss: 0.522201]\n",
      "epoch:6 step:6514 [D loss: 0.651701, acc.: 63.28%] [G loss: 0.472516]\n",
      "epoch:6 step:6515 [D loss: 0.544688, acc.: 74.22%] [G loss: 0.638876]\n",
      "epoch:6 step:6516 [D loss: 0.486169, acc.: 78.12%] [G loss: 0.577521]\n",
      "epoch:6 step:6517 [D loss: 0.529216, acc.: 74.22%] [G loss: 0.617484]\n",
      "epoch:6 step:6518 [D loss: 0.458399, acc.: 75.78%] [G loss: 0.726195]\n",
      "epoch:6 step:6519 [D loss: 0.482910, acc.: 78.12%] [G loss: 0.662680]\n",
      "epoch:6 step:6520 [D loss: 0.509495, acc.: 78.91%] [G loss: 0.675851]\n",
      "epoch:6 step:6521 [D loss: 0.500108, acc.: 76.56%] [G loss: 0.686509]\n",
      "epoch:6 step:6522 [D loss: 0.500958, acc.: 75.00%] [G loss: 0.659881]\n",
      "epoch:6 step:6523 [D loss: 0.582424, acc.: 65.62%] [G loss: 0.665969]\n",
      "epoch:6 step:6524 [D loss: 0.578731, acc.: 67.19%] [G loss: 0.508177]\n",
      "epoch:6 step:6525 [D loss: 0.599680, acc.: 64.06%] [G loss: 0.454813]\n",
      "epoch:6 step:6526 [D loss: 0.560904, acc.: 67.97%] [G loss: 0.509434]\n",
      "epoch:6 step:6527 [D loss: 0.542909, acc.: 73.44%] [G loss: 0.633530]\n",
      "epoch:6 step:6528 [D loss: 0.458853, acc.: 82.81%] [G loss: 0.541884]\n",
      "epoch:6 step:6529 [D loss: 0.552379, acc.: 70.31%] [G loss: 0.645286]\n",
      "epoch:6 step:6530 [D loss: 0.535068, acc.: 73.44%] [G loss: 0.600192]\n",
      "epoch:6 step:6531 [D loss: 0.525726, acc.: 68.75%] [G loss: 0.583312]\n",
      "epoch:6 step:6532 [D loss: 0.495451, acc.: 75.78%] [G loss: 0.646874]\n",
      "epoch:6 step:6533 [D loss: 0.480025, acc.: 79.69%] [G loss: 0.617501]\n",
      "epoch:6 step:6534 [D loss: 0.429297, acc.: 81.25%] [G loss: 0.782105]\n",
      "epoch:6 step:6535 [D loss: 0.571693, acc.: 67.97%] [G loss: 0.781449]\n",
      "epoch:6 step:6536 [D loss: 0.504139, acc.: 78.91%] [G loss: 0.530958]\n",
      "epoch:6 step:6537 [D loss: 0.573539, acc.: 65.62%] [G loss: 0.652670]\n",
      "epoch:6 step:6538 [D loss: 0.512058, acc.: 78.12%] [G loss: 0.563411]\n",
      "epoch:6 step:6539 [D loss: 0.606740, acc.: 64.06%] [G loss: 0.490534]\n",
      "epoch:6 step:6540 [D loss: 0.493410, acc.: 78.12%] [G loss: 0.587247]\n",
      "epoch:6 step:6541 [D loss: 0.467303, acc.: 82.81%] [G loss: 0.641533]\n",
      "epoch:6 step:6542 [D loss: 0.744249, acc.: 57.03%] [G loss: 0.534160]\n",
      "epoch:6 step:6543 [D loss: 0.460875, acc.: 78.12%] [G loss: 0.723996]\n",
      "epoch:6 step:6544 [D loss: 0.508918, acc.: 75.78%] [G loss: 0.573462]\n",
      "epoch:6 step:6545 [D loss: 0.484203, acc.: 71.88%] [G loss: 0.731701]\n",
      "epoch:6 step:6546 [D loss: 0.464311, acc.: 75.00%] [G loss: 0.757437]\n",
      "epoch:6 step:6547 [D loss: 0.431450, acc.: 78.91%] [G loss: 0.852808]\n",
      "epoch:6 step:6548 [D loss: 0.428509, acc.: 78.91%] [G loss: 0.969684]\n",
      "epoch:6 step:6549 [D loss: 0.503191, acc.: 74.22%] [G loss: 1.116604]\n",
      "epoch:6 step:6550 [D loss: 0.813589, acc.: 57.03%] [G loss: 0.836909]\n",
      "epoch:6 step:6551 [D loss: 0.480435, acc.: 74.22%] [G loss: 0.929250]\n",
      "epoch:6 step:6552 [D loss: 0.509624, acc.: 70.31%] [G loss: 0.961538]\n",
      "epoch:6 step:6553 [D loss: 0.534750, acc.: 67.19%] [G loss: 0.984486]\n",
      "epoch:6 step:6554 [D loss: 0.611973, acc.: 70.31%] [G loss: 0.629336]\n",
      "epoch:6 step:6555 [D loss: 0.530174, acc.: 74.22%] [G loss: 0.630262]\n",
      "epoch:6 step:6556 [D loss: 0.582420, acc.: 69.53%] [G loss: 0.682431]\n",
      "epoch:6 step:6557 [D loss: 0.458698, acc.: 80.47%] [G loss: 0.901554]\n",
      "epoch:6 step:6558 [D loss: 0.334772, acc.: 86.72%] [G loss: 1.081172]\n",
      "epoch:6 step:6559 [D loss: 0.476753, acc.: 76.56%] [G loss: 1.335577]\n",
      "epoch:7 step:6560 [D loss: 0.607012, acc.: 68.75%] [G loss: 0.878915]\n",
      "epoch:7 step:6561 [D loss: 0.529932, acc.: 71.88%] [G loss: 0.774244]\n",
      "epoch:7 step:6562 [D loss: 0.608384, acc.: 66.41%] [G loss: 0.789199]\n",
      "epoch:7 step:6563 [D loss: 0.544151, acc.: 72.66%] [G loss: 0.671790]\n",
      "epoch:7 step:6564 [D loss: 0.551602, acc.: 72.66%] [G loss: 0.602098]\n",
      "epoch:7 step:6565 [D loss: 0.533530, acc.: 72.66%] [G loss: 0.586900]\n",
      "epoch:7 step:6566 [D loss: 0.482770, acc.: 79.69%] [G loss: 0.754596]\n",
      "epoch:7 step:6567 [D loss: 0.558815, acc.: 73.44%] [G loss: 0.638027]\n",
      "epoch:7 step:6568 [D loss: 0.493369, acc.: 71.88%] [G loss: 0.774020]\n",
      "epoch:7 step:6569 [D loss: 0.564839, acc.: 71.09%] [G loss: 0.660629]\n",
      "epoch:7 step:6570 [D loss: 0.450321, acc.: 78.12%] [G loss: 0.845715]\n",
      "epoch:7 step:6571 [D loss: 0.572761, acc.: 66.41%] [G loss: 0.487182]\n",
      "epoch:7 step:6572 [D loss: 0.544522, acc.: 69.53%] [G loss: 0.625202]\n",
      "epoch:7 step:6573 [D loss: 0.544655, acc.: 73.44%] [G loss: 0.539623]\n",
      "epoch:7 step:6574 [D loss: 0.451953, acc.: 82.81%] [G loss: 0.501090]\n",
      "epoch:7 step:6575 [D loss: 0.507278, acc.: 74.22%] [G loss: 0.693089]\n",
      "epoch:7 step:6576 [D loss: 0.541250, acc.: 71.88%] [G loss: 0.528988]\n",
      "epoch:7 step:6577 [D loss: 0.627118, acc.: 65.62%] [G loss: 0.496299]\n",
      "epoch:7 step:6578 [D loss: 0.537636, acc.: 73.44%] [G loss: 0.472945]\n",
      "epoch:7 step:6579 [D loss: 0.598858, acc.: 65.62%] [G loss: 0.568711]\n",
      "epoch:7 step:6580 [D loss: 0.588766, acc.: 64.06%] [G loss: 0.483504]\n",
      "epoch:7 step:6581 [D loss: 0.509804, acc.: 74.22%] [G loss: 0.606696]\n",
      "epoch:7 step:6582 [D loss: 0.491733, acc.: 77.34%] [G loss: 0.598225]\n",
      "epoch:7 step:6583 [D loss: 0.482329, acc.: 77.34%] [G loss: 0.677422]\n",
      "epoch:7 step:6584 [D loss: 0.501144, acc.: 80.47%] [G loss: 0.633657]\n",
      "epoch:7 step:6585 [D loss: 0.618282, acc.: 64.06%] [G loss: 0.444377]\n",
      "epoch:7 step:6586 [D loss: 0.481693, acc.: 76.56%] [G loss: 0.456347]\n",
      "epoch:7 step:6587 [D loss: 0.529531, acc.: 73.44%] [G loss: 0.590143]\n",
      "epoch:7 step:6588 [D loss: 0.551818, acc.: 74.22%] [G loss: 0.622924]\n",
      "epoch:7 step:6589 [D loss: 0.518125, acc.: 76.56%] [G loss: 0.651268]\n",
      "epoch:7 step:6590 [D loss: 0.567073, acc.: 73.44%] [G loss: 0.526531]\n",
      "epoch:7 step:6591 [D loss: 0.590994, acc.: 64.84%] [G loss: 0.492840]\n",
      "epoch:7 step:6592 [D loss: 0.490865, acc.: 75.78%] [G loss: 0.689998]\n",
      "epoch:7 step:6593 [D loss: 0.513460, acc.: 74.22%] [G loss: 0.600349]\n",
      "epoch:7 step:6594 [D loss: 0.579468, acc.: 71.88%] [G loss: 0.584141]\n",
      "epoch:7 step:6595 [D loss: 0.492645, acc.: 74.22%] [G loss: 0.762000]\n",
      "epoch:7 step:6596 [D loss: 0.491053, acc.: 81.25%] [G loss: 0.613577]\n",
      "epoch:7 step:6597 [D loss: 0.650436, acc.: 65.62%] [G loss: 0.534479]\n",
      "epoch:7 step:6598 [D loss: 0.505447, acc.: 75.00%] [G loss: 0.574000]\n",
      "epoch:7 step:6599 [D loss: 0.436971, acc.: 81.25%] [G loss: 0.695109]\n",
      "epoch:7 step:6600 [D loss: 0.521635, acc.: 72.66%] [G loss: 0.590605]\n",
      "##############\n",
      "[3.37935597 1.45367795 6.81985543 4.96021955 4.20091927 5.54794168\n",
      " 5.06125868 4.93622463 4.75384472 3.86840945]\n",
      "##########\n",
      "epoch:7 step:6601 [D loss: 0.576181, acc.: 72.66%] [G loss: 0.645880]\n",
      "epoch:7 step:6602 [D loss: 0.526473, acc.: 72.66%] [G loss: 0.659693]\n",
      "epoch:7 step:6603 [D loss: 0.562678, acc.: 70.31%] [G loss: 0.515020]\n",
      "epoch:7 step:6604 [D loss: 0.504606, acc.: 76.56%] [G loss: 0.519212]\n",
      "epoch:7 step:6605 [D loss: 0.484175, acc.: 73.44%] [G loss: 0.566993]\n",
      "epoch:7 step:6606 [D loss: 0.567618, acc.: 70.31%] [G loss: 0.605209]\n",
      "epoch:7 step:6607 [D loss: 0.506634, acc.: 74.22%] [G loss: 0.571012]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:7 step:6608 [D loss: 0.537794, acc.: 71.88%] [G loss: 0.592007]\n",
      "epoch:7 step:6609 [D loss: 0.548800, acc.: 71.88%] [G loss: 0.473851]\n",
      "epoch:7 step:6610 [D loss: 0.639374, acc.: 60.94%] [G loss: 0.611916]\n",
      "epoch:7 step:6611 [D loss: 0.599628, acc.: 62.50%] [G loss: 0.486411]\n",
      "epoch:7 step:6612 [D loss: 0.502970, acc.: 77.34%] [G loss: 0.615222]\n",
      "epoch:7 step:6613 [D loss: 0.496630, acc.: 77.34%] [G loss: 0.603025]\n",
      "epoch:7 step:6614 [D loss: 0.536501, acc.: 71.88%] [G loss: 0.638866]\n",
      "epoch:7 step:6615 [D loss: 0.525689, acc.: 74.22%] [G loss: 0.625113]\n",
      "epoch:7 step:6616 [D loss: 0.527297, acc.: 68.75%] [G loss: 0.566761]\n",
      "epoch:7 step:6617 [D loss: 0.598827, acc.: 64.84%] [G loss: 0.573491]\n",
      "epoch:7 step:6618 [D loss: 0.474929, acc.: 78.12%] [G loss: 0.692947]\n",
      "epoch:7 step:6619 [D loss: 0.531812, acc.: 71.09%] [G loss: 0.550363]\n",
      "epoch:7 step:6620 [D loss: 0.521585, acc.: 66.41%] [G loss: 0.616381]\n",
      "epoch:7 step:6621 [D loss: 0.577009, acc.: 69.53%] [G loss: 0.572883]\n",
      "epoch:7 step:6622 [D loss: 0.576051, acc.: 70.31%] [G loss: 0.466116]\n",
      "epoch:7 step:6623 [D loss: 0.562414, acc.: 68.75%] [G loss: 0.479208]\n",
      "epoch:7 step:6624 [D loss: 0.519997, acc.: 71.88%] [G loss: 0.545894]\n",
      "epoch:7 step:6625 [D loss: 0.519150, acc.: 78.12%] [G loss: 0.543532]\n",
      "epoch:7 step:6626 [D loss: 0.591071, acc.: 68.75%] [G loss: 0.526602]\n",
      "epoch:7 step:6627 [D loss: 0.525922, acc.: 72.66%] [G loss: 0.530453]\n",
      "epoch:7 step:6628 [D loss: 0.494475, acc.: 81.25%] [G loss: 0.581511]\n",
      "epoch:7 step:6629 [D loss: 0.525103, acc.: 72.66%] [G loss: 0.583812]\n",
      "epoch:7 step:6630 [D loss: 0.541267, acc.: 71.88%] [G loss: 0.473028]\n",
      "epoch:7 step:6631 [D loss: 0.499673, acc.: 73.44%] [G loss: 0.469790]\n",
      "epoch:7 step:6632 [D loss: 0.551086, acc.: 67.19%] [G loss: 0.477406]\n",
      "epoch:7 step:6633 [D loss: 0.493955, acc.: 76.56%] [G loss: 0.504458]\n",
      "epoch:7 step:6634 [D loss: 0.580982, acc.: 71.88%] [G loss: 0.729087]\n",
      "epoch:7 step:6635 [D loss: 0.580976, acc.: 68.75%] [G loss: 0.612379]\n",
      "epoch:7 step:6636 [D loss: 0.444505, acc.: 79.69%] [G loss: 0.759159]\n",
      "epoch:7 step:6637 [D loss: 0.601923, acc.: 69.53%] [G loss: 0.567601]\n",
      "epoch:7 step:6638 [D loss: 0.612131, acc.: 64.06%] [G loss: 0.466931]\n",
      "epoch:7 step:6639 [D loss: 0.539038, acc.: 70.31%] [G loss: 0.597749]\n",
      "epoch:7 step:6640 [D loss: 0.590165, acc.: 68.75%] [G loss: 0.464915]\n",
      "epoch:7 step:6641 [D loss: 0.511099, acc.: 72.66%] [G loss: 0.573291]\n",
      "epoch:7 step:6642 [D loss: 0.480257, acc.: 77.34%] [G loss: 0.565475]\n",
      "epoch:7 step:6643 [D loss: 0.512198, acc.: 72.66%] [G loss: 0.636121]\n",
      "epoch:7 step:6644 [D loss: 0.567682, acc.: 65.62%] [G loss: 0.474553]\n",
      "epoch:7 step:6645 [D loss: 0.514530, acc.: 75.00%] [G loss: 0.625531]\n",
      "epoch:7 step:6646 [D loss: 0.528501, acc.: 73.44%] [G loss: 0.555527]\n",
      "epoch:7 step:6647 [D loss: 0.546952, acc.: 74.22%] [G loss: 0.665785]\n",
      "epoch:7 step:6648 [D loss: 0.531999, acc.: 75.00%] [G loss: 0.701704]\n",
      "epoch:7 step:6649 [D loss: 0.483680, acc.: 77.34%] [G loss: 0.703163]\n",
      "epoch:7 step:6650 [D loss: 0.550373, acc.: 69.53%] [G loss: 0.600071]\n",
      "epoch:7 step:6651 [D loss: 0.499441, acc.: 74.22%] [G loss: 0.602090]\n",
      "epoch:7 step:6652 [D loss: 0.532277, acc.: 75.00%] [G loss: 0.615254]\n",
      "epoch:7 step:6653 [D loss: 0.609321, acc.: 60.94%] [G loss: 0.534488]\n",
      "epoch:7 step:6654 [D loss: 0.553308, acc.: 71.09%] [G loss: 0.611527]\n",
      "epoch:7 step:6655 [D loss: 0.520041, acc.: 77.34%] [G loss: 0.574196]\n",
      "epoch:7 step:6656 [D loss: 0.526570, acc.: 72.66%] [G loss: 0.606384]\n",
      "epoch:7 step:6657 [D loss: 0.552811, acc.: 68.75%] [G loss: 0.546645]\n",
      "epoch:7 step:6658 [D loss: 0.522004, acc.: 72.66%] [G loss: 0.530035]\n",
      "epoch:7 step:6659 [D loss: 0.458254, acc.: 75.00%] [G loss: 0.777453]\n",
      "epoch:7 step:6660 [D loss: 0.528426, acc.: 70.31%] [G loss: 0.591113]\n",
      "epoch:7 step:6661 [D loss: 0.603839, acc.: 65.62%] [G loss: 0.682972]\n",
      "epoch:7 step:6662 [D loss: 0.494807, acc.: 73.44%] [G loss: 0.553040]\n",
      "epoch:7 step:6663 [D loss: 0.538590, acc.: 69.53%] [G loss: 0.528400]\n",
      "epoch:7 step:6664 [D loss: 0.584443, acc.: 64.06%] [G loss: 0.483869]\n",
      "epoch:7 step:6665 [D loss: 0.528428, acc.: 72.66%] [G loss: 0.612393]\n",
      "epoch:7 step:6666 [D loss: 0.626393, acc.: 62.50%] [G loss: 0.524117]\n",
      "epoch:7 step:6667 [D loss: 0.652830, acc.: 62.50%] [G loss: 0.611664]\n",
      "epoch:7 step:6668 [D loss: 0.581774, acc.: 70.31%] [G loss: 0.477652]\n",
      "epoch:7 step:6669 [D loss: 0.603650, acc.: 63.28%] [G loss: 0.462934]\n",
      "epoch:7 step:6670 [D loss: 0.507434, acc.: 74.22%] [G loss: 0.496965]\n",
      "epoch:7 step:6671 [D loss: 0.535684, acc.: 73.44%] [G loss: 0.653105]\n",
      "epoch:7 step:6672 [D loss: 0.609701, acc.: 62.50%] [G loss: 0.492161]\n",
      "epoch:7 step:6673 [D loss: 0.542048, acc.: 75.00%] [G loss: 0.631513]\n",
      "epoch:7 step:6674 [D loss: 0.522574, acc.: 77.34%] [G loss: 0.503437]\n",
      "epoch:7 step:6675 [D loss: 0.546189, acc.: 72.66%] [G loss: 0.725610]\n",
      "epoch:7 step:6676 [D loss: 0.532759, acc.: 74.22%] [G loss: 0.643819]\n",
      "epoch:7 step:6677 [D loss: 0.509369, acc.: 79.69%] [G loss: 0.793006]\n",
      "epoch:7 step:6678 [D loss: 0.440811, acc.: 82.03%] [G loss: 0.794363]\n",
      "epoch:7 step:6679 [D loss: 0.590468, acc.: 71.09%] [G loss: 0.645831]\n",
      "epoch:7 step:6680 [D loss: 0.556684, acc.: 69.53%] [G loss: 0.589469]\n",
      "epoch:7 step:6681 [D loss: 0.578923, acc.: 73.44%] [G loss: 0.623969]\n",
      "epoch:7 step:6682 [D loss: 0.483305, acc.: 73.44%] [G loss: 0.726058]\n",
      "epoch:7 step:6683 [D loss: 0.579398, acc.: 67.19%] [G loss: 0.534632]\n",
      "epoch:7 step:6684 [D loss: 0.559357, acc.: 71.09%] [G loss: 0.465719]\n",
      "epoch:7 step:6685 [D loss: 0.493273, acc.: 76.56%] [G loss: 0.545649]\n",
      "epoch:7 step:6686 [D loss: 0.526601, acc.: 76.56%] [G loss: 0.386265]\n",
      "epoch:7 step:6687 [D loss: 0.490760, acc.: 75.78%] [G loss: 0.550912]\n",
      "epoch:7 step:6688 [D loss: 0.544682, acc.: 70.31%] [G loss: 0.473177]\n",
      "epoch:7 step:6689 [D loss: 0.481868, acc.: 75.78%] [G loss: 0.574311]\n",
      "epoch:7 step:6690 [D loss: 0.488272, acc.: 73.44%] [G loss: 0.489501]\n",
      "epoch:7 step:6691 [D loss: 0.549436, acc.: 74.22%] [G loss: 0.432075]\n",
      "epoch:7 step:6692 [D loss: 0.562953, acc.: 63.28%] [G loss: 0.452462]\n",
      "epoch:7 step:6693 [D loss: 0.577205, acc.: 68.75%] [G loss: 0.432621]\n",
      "epoch:7 step:6694 [D loss: 0.523383, acc.: 77.34%] [G loss: 0.572582]\n",
      "epoch:7 step:6695 [D loss: 0.529531, acc.: 75.00%] [G loss: 0.621911]\n",
      "epoch:7 step:6696 [D loss: 0.641644, acc.: 64.84%] [G loss: 0.506375]\n",
      "epoch:7 step:6697 [D loss: 0.571548, acc.: 72.66%] [G loss: 0.533283]\n",
      "epoch:7 step:6698 [D loss: 0.578086, acc.: 64.06%] [G loss: 0.518500]\n",
      "epoch:7 step:6699 [D loss: 0.566876, acc.: 67.19%] [G loss: 0.495385]\n",
      "epoch:7 step:6700 [D loss: 0.537220, acc.: 67.97%] [G loss: 0.582128]\n",
      "epoch:7 step:6701 [D loss: 0.516698, acc.: 74.22%] [G loss: 0.606266]\n",
      "epoch:7 step:6702 [D loss: 0.599283, acc.: 64.84%] [G loss: 0.471533]\n",
      "epoch:7 step:6703 [D loss: 0.498215, acc.: 75.78%] [G loss: 0.550527]\n",
      "epoch:7 step:6704 [D loss: 0.573830, acc.: 64.84%] [G loss: 0.554832]\n",
      "epoch:7 step:6705 [D loss: 0.472631, acc.: 75.78%] [G loss: 0.688948]\n",
      "epoch:7 step:6706 [D loss: 0.628721, acc.: 64.06%] [G loss: 0.505273]\n",
      "epoch:7 step:6707 [D loss: 0.536775, acc.: 71.88%] [G loss: 0.677434]\n",
      "epoch:7 step:6708 [D loss: 0.502948, acc.: 76.56%] [G loss: 0.492251]\n",
      "epoch:7 step:6709 [D loss: 0.609946, acc.: 66.41%] [G loss: 0.539196]\n",
      "epoch:7 step:6710 [D loss: 0.545834, acc.: 74.22%] [G loss: 0.682593]\n",
      "epoch:7 step:6711 [D loss: 0.453627, acc.: 80.47%] [G loss: 0.754841]\n",
      "epoch:7 step:6712 [D loss: 0.621920, acc.: 63.28%] [G loss: 0.607061]\n",
      "epoch:7 step:6713 [D loss: 0.556363, acc.: 67.19%] [G loss: 0.518790]\n",
      "epoch:7 step:6714 [D loss: 0.492940, acc.: 81.25%] [G loss: 0.542179]\n",
      "epoch:7 step:6715 [D loss: 0.530747, acc.: 74.22%] [G loss: 0.588818]\n",
      "epoch:7 step:6716 [D loss: 0.584123, acc.: 66.41%] [G loss: 0.597339]\n",
      "epoch:7 step:6717 [D loss: 0.612543, acc.: 64.84%] [G loss: 0.627337]\n",
      "epoch:7 step:6718 [D loss: 0.553521, acc.: 71.88%] [G loss: 0.500784]\n",
      "epoch:7 step:6719 [D loss: 0.596758, acc.: 68.75%] [G loss: 0.650603]\n",
      "epoch:7 step:6720 [D loss: 0.489324, acc.: 78.91%] [G loss: 0.642719]\n",
      "epoch:7 step:6721 [D loss: 0.447542, acc.: 75.78%] [G loss: 0.729013]\n",
      "epoch:7 step:6722 [D loss: 0.552878, acc.: 67.97%] [G loss: 0.574636]\n",
      "epoch:7 step:6723 [D loss: 0.558698, acc.: 72.66%] [G loss: 0.610826]\n",
      "epoch:7 step:6724 [D loss: 0.510218, acc.: 77.34%] [G loss: 0.560988]\n",
      "epoch:7 step:6725 [D loss: 0.537869, acc.: 71.88%] [G loss: 0.525073]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:7 step:6726 [D loss: 0.544951, acc.: 70.31%] [G loss: 0.499580]\n",
      "epoch:7 step:6727 [D loss: 0.541673, acc.: 74.22%] [G loss: 0.481489]\n",
      "epoch:7 step:6728 [D loss: 0.603793, acc.: 70.31%] [G loss: 0.355691]\n",
      "epoch:7 step:6729 [D loss: 0.532402, acc.: 71.88%] [G loss: 0.566147]\n",
      "epoch:7 step:6730 [D loss: 0.544476, acc.: 74.22%] [G loss: 0.518321]\n",
      "epoch:7 step:6731 [D loss: 0.570126, acc.: 68.75%] [G loss: 0.578747]\n",
      "epoch:7 step:6732 [D loss: 0.553810, acc.: 68.75%] [G loss: 0.719848]\n",
      "epoch:7 step:6733 [D loss: 0.572106, acc.: 67.97%] [G loss: 0.551356]\n",
      "epoch:7 step:6734 [D loss: 0.557849, acc.: 64.84%] [G loss: 0.578247]\n",
      "epoch:7 step:6735 [D loss: 0.490393, acc.: 78.91%] [G loss: 0.518365]\n",
      "epoch:7 step:6736 [D loss: 0.549714, acc.: 71.88%] [G loss: 0.502555]\n",
      "epoch:7 step:6737 [D loss: 0.578453, acc.: 64.84%] [G loss: 0.542007]\n",
      "epoch:7 step:6738 [D loss: 0.536724, acc.: 72.66%] [G loss: 0.556282]\n",
      "epoch:7 step:6739 [D loss: 0.621192, acc.: 67.19%] [G loss: 0.481759]\n",
      "epoch:7 step:6740 [D loss: 0.539315, acc.: 68.75%] [G loss: 0.533846]\n",
      "epoch:7 step:6741 [D loss: 0.524779, acc.: 79.69%] [G loss: 0.538234]\n",
      "epoch:7 step:6742 [D loss: 0.585055, acc.: 67.97%] [G loss: 0.598002]\n",
      "epoch:7 step:6743 [D loss: 0.578030, acc.: 66.41%] [G loss: 0.595091]\n",
      "epoch:7 step:6744 [D loss: 0.561925, acc.: 68.75%] [G loss: 0.583387]\n",
      "epoch:7 step:6745 [D loss: 0.552857, acc.: 73.44%] [G loss: 0.688841]\n",
      "epoch:7 step:6746 [D loss: 0.622405, acc.: 64.84%] [G loss: 0.569695]\n",
      "epoch:7 step:6747 [D loss: 0.573713, acc.: 67.97%] [G loss: 0.446033]\n",
      "epoch:7 step:6748 [D loss: 0.536449, acc.: 71.88%] [G loss: 0.546421]\n",
      "epoch:7 step:6749 [D loss: 0.500114, acc.: 74.22%] [G loss: 0.661246]\n",
      "epoch:7 step:6750 [D loss: 0.467931, acc.: 76.56%] [G loss: 0.750666]\n",
      "epoch:7 step:6751 [D loss: 0.600443, acc.: 65.62%] [G loss: 0.557153]\n",
      "epoch:7 step:6752 [D loss: 0.528478, acc.: 78.91%] [G loss: 0.622672]\n",
      "epoch:7 step:6753 [D loss: 0.441220, acc.: 81.25%] [G loss: 0.645504]\n",
      "epoch:7 step:6754 [D loss: 0.557203, acc.: 68.75%] [G loss: 0.643025]\n",
      "epoch:7 step:6755 [D loss: 0.518464, acc.: 70.31%] [G loss: 0.638189]\n",
      "epoch:7 step:6756 [D loss: 0.542397, acc.: 73.44%] [G loss: 0.556292]\n",
      "epoch:7 step:6757 [D loss: 0.471348, acc.: 79.69%] [G loss: 0.767404]\n",
      "epoch:7 step:6758 [D loss: 0.512118, acc.: 71.88%] [G loss: 0.638209]\n",
      "epoch:7 step:6759 [D loss: 0.598947, acc.: 66.41%] [G loss: 0.610041]\n",
      "epoch:7 step:6760 [D loss: 0.570607, acc.: 67.97%] [G loss: 0.539799]\n",
      "epoch:7 step:6761 [D loss: 0.509239, acc.: 76.56%] [G loss: 0.605497]\n",
      "epoch:7 step:6762 [D loss: 0.623743, acc.: 61.72%] [G loss: 0.586431]\n",
      "epoch:7 step:6763 [D loss: 0.536353, acc.: 72.66%] [G loss: 0.589329]\n",
      "epoch:7 step:6764 [D loss: 0.529864, acc.: 71.09%] [G loss: 0.599309]\n",
      "epoch:7 step:6765 [D loss: 0.551490, acc.: 71.88%] [G loss: 0.708257]\n",
      "epoch:7 step:6766 [D loss: 0.462374, acc.: 79.69%] [G loss: 0.743463]\n",
      "epoch:7 step:6767 [D loss: 0.412331, acc.: 82.03%] [G loss: 0.826959]\n",
      "epoch:7 step:6768 [D loss: 0.512439, acc.: 74.22%] [G loss: 0.681209]\n",
      "epoch:7 step:6769 [D loss: 0.581841, acc.: 67.19%] [G loss: 0.470578]\n",
      "epoch:7 step:6770 [D loss: 0.554277, acc.: 70.31%] [G loss: 0.514687]\n",
      "epoch:7 step:6771 [D loss: 0.515318, acc.: 74.22%] [G loss: 0.481869]\n",
      "epoch:7 step:6772 [D loss: 0.493176, acc.: 72.66%] [G loss: 0.530260]\n",
      "epoch:7 step:6773 [D loss: 0.694307, acc.: 60.94%] [G loss: 0.508508]\n",
      "epoch:7 step:6774 [D loss: 0.603164, acc.: 61.72%] [G loss: 0.484336]\n",
      "epoch:7 step:6775 [D loss: 0.564592, acc.: 73.44%] [G loss: 0.622222]\n",
      "epoch:7 step:6776 [D loss: 0.503683, acc.: 76.56%] [G loss: 0.652250]\n",
      "epoch:7 step:6777 [D loss: 0.523391, acc.: 75.00%] [G loss: 0.478574]\n",
      "epoch:7 step:6778 [D loss: 0.513317, acc.: 75.78%] [G loss: 0.644803]\n",
      "epoch:7 step:6779 [D loss: 0.609972, acc.: 63.28%] [G loss: 0.724068]\n",
      "epoch:7 step:6780 [D loss: 0.485441, acc.: 75.78%] [G loss: 0.661543]\n",
      "epoch:7 step:6781 [D loss: 0.467851, acc.: 77.34%] [G loss: 0.616246]\n",
      "epoch:7 step:6782 [D loss: 0.499324, acc.: 77.34%] [G loss: 0.604953]\n",
      "epoch:7 step:6783 [D loss: 0.591921, acc.: 70.31%] [G loss: 0.585650]\n",
      "epoch:7 step:6784 [D loss: 0.607835, acc.: 62.50%] [G loss: 0.498151]\n",
      "epoch:7 step:6785 [D loss: 0.604824, acc.: 63.28%] [G loss: 0.470807]\n",
      "epoch:7 step:6786 [D loss: 0.550622, acc.: 71.88%] [G loss: 0.549474]\n",
      "epoch:7 step:6787 [D loss: 0.608775, acc.: 67.97%] [G loss: 0.402620]\n",
      "epoch:7 step:6788 [D loss: 0.508843, acc.: 75.78%] [G loss: 0.573313]\n",
      "epoch:7 step:6789 [D loss: 0.535689, acc.: 74.22%] [G loss: 0.549568]\n",
      "epoch:7 step:6790 [D loss: 0.453721, acc.: 76.56%] [G loss: 0.757872]\n",
      "epoch:7 step:6791 [D loss: 0.441755, acc.: 78.91%] [G loss: 0.920768]\n",
      "epoch:7 step:6792 [D loss: 0.597046, acc.: 71.09%] [G loss: 0.726512]\n",
      "epoch:7 step:6793 [D loss: 0.504312, acc.: 76.56%] [G loss: 0.655092]\n",
      "epoch:7 step:6794 [D loss: 0.599487, acc.: 66.41%] [G loss: 0.672451]\n",
      "epoch:7 step:6795 [D loss: 0.530294, acc.: 73.44%] [G loss: 0.446355]\n",
      "epoch:7 step:6796 [D loss: 0.551154, acc.: 74.22%] [G loss: 0.544365]\n",
      "epoch:7 step:6797 [D loss: 0.555308, acc.: 68.75%] [G loss: 0.537683]\n",
      "epoch:7 step:6798 [D loss: 0.531529, acc.: 69.53%] [G loss: 0.484928]\n",
      "epoch:7 step:6799 [D loss: 0.529984, acc.: 70.31%] [G loss: 0.466700]\n",
      "epoch:7 step:6800 [D loss: 0.538067, acc.: 69.53%] [G loss: 0.532395]\n",
      "##############\n",
      "[3.55222673 1.56804477 6.7217105  4.8955468  4.1444885  5.90708777\n",
      " 5.00906685 5.14945551 5.10555391 3.90069302]\n",
      "##########\n",
      "epoch:7 step:6801 [D loss: 0.524692, acc.: 74.22%] [G loss: 0.646772]\n",
      "epoch:7 step:6802 [D loss: 0.538544, acc.: 71.09%] [G loss: 0.547451]\n",
      "epoch:7 step:6803 [D loss: 0.506929, acc.: 75.00%] [G loss: 0.694100]\n",
      "epoch:7 step:6804 [D loss: 0.549044, acc.: 72.66%] [G loss: 0.530459]\n",
      "epoch:7 step:6805 [D loss: 0.527053, acc.: 75.00%] [G loss: 0.595317]\n",
      "epoch:7 step:6806 [D loss: 0.592601, acc.: 63.28%] [G loss: 0.497342]\n",
      "epoch:7 step:6807 [D loss: 0.565467, acc.: 71.88%] [G loss: 0.657974]\n",
      "epoch:7 step:6808 [D loss: 0.534979, acc.: 74.22%] [G loss: 0.687350]\n",
      "epoch:7 step:6809 [D loss: 0.606582, acc.: 65.62%] [G loss: 0.780513]\n",
      "epoch:7 step:6810 [D loss: 0.598817, acc.: 67.19%] [G loss: 0.579604]\n",
      "epoch:7 step:6811 [D loss: 0.536688, acc.: 74.22%] [G loss: 0.521857]\n",
      "epoch:7 step:6812 [D loss: 0.504479, acc.: 75.78%] [G loss: 0.607876]\n",
      "epoch:7 step:6813 [D loss: 0.509841, acc.: 72.66%] [G loss: 0.642337]\n",
      "epoch:7 step:6814 [D loss: 0.524316, acc.: 73.44%] [G loss: 0.606335]\n",
      "epoch:7 step:6815 [D loss: 0.556553, acc.: 67.97%] [G loss: 0.506457]\n",
      "epoch:7 step:6816 [D loss: 0.643719, acc.: 61.72%] [G loss: 0.434488]\n",
      "epoch:7 step:6817 [D loss: 0.523057, acc.: 77.34%] [G loss: 0.450844]\n",
      "epoch:7 step:6818 [D loss: 0.543904, acc.: 67.19%] [G loss: 0.514094]\n",
      "epoch:7 step:6819 [D loss: 0.545544, acc.: 70.31%] [G loss: 0.576459]\n",
      "epoch:7 step:6820 [D loss: 0.541748, acc.: 72.66%] [G loss: 0.528093]\n",
      "epoch:7 step:6821 [D loss: 0.507557, acc.: 76.56%] [G loss: 0.594115]\n",
      "epoch:7 step:6822 [D loss: 0.619678, acc.: 66.41%] [G loss: 0.503277]\n",
      "epoch:7 step:6823 [D loss: 0.500119, acc.: 74.22%] [G loss: 0.642183]\n",
      "epoch:7 step:6824 [D loss: 0.588625, acc.: 67.19%] [G loss: 0.491480]\n",
      "epoch:7 step:6825 [D loss: 0.531272, acc.: 73.44%] [G loss: 0.454419]\n",
      "epoch:7 step:6826 [D loss: 0.551979, acc.: 65.62%] [G loss: 0.528196]\n",
      "epoch:7 step:6827 [D loss: 0.577355, acc.: 68.75%] [G loss: 0.470392]\n",
      "epoch:7 step:6828 [D loss: 0.545811, acc.: 70.31%] [G loss: 0.512286]\n",
      "epoch:7 step:6829 [D loss: 0.533398, acc.: 73.44%] [G loss: 0.575137]\n",
      "epoch:7 step:6830 [D loss: 0.502875, acc.: 76.56%] [G loss: 0.649403]\n",
      "epoch:7 step:6831 [D loss: 0.534159, acc.: 71.88%] [G loss: 0.616742]\n",
      "epoch:7 step:6832 [D loss: 0.517500, acc.: 70.31%] [G loss: 0.562868]\n",
      "epoch:7 step:6833 [D loss: 0.510695, acc.: 75.00%] [G loss: 0.551130]\n",
      "epoch:7 step:6834 [D loss: 0.592627, acc.: 66.41%] [G loss: 0.442675]\n",
      "epoch:7 step:6835 [D loss: 0.518361, acc.: 76.56%] [G loss: 0.523546]\n",
      "epoch:7 step:6836 [D loss: 0.681800, acc.: 62.50%] [G loss: 0.428225]\n",
      "epoch:7 step:6837 [D loss: 0.560872, acc.: 72.66%] [G loss: 0.605914]\n",
      "epoch:7 step:6838 [D loss: 0.494266, acc.: 76.56%] [G loss: 0.720586]\n",
      "epoch:7 step:6839 [D loss: 0.557128, acc.: 68.75%] [G loss: 0.603120]\n",
      "epoch:7 step:6840 [D loss: 0.633726, acc.: 62.50%] [G loss: 0.475896]\n",
      "epoch:7 step:6841 [D loss: 0.528975, acc.: 76.56%] [G loss: 0.548351]\n",
      "epoch:7 step:6842 [D loss: 0.463649, acc.: 78.12%] [G loss: 0.610570]\n",
      "epoch:7 step:6843 [D loss: 0.499322, acc.: 74.22%] [G loss: 0.611789]\n",
      "epoch:7 step:6844 [D loss: 0.496154, acc.: 73.44%] [G loss: 0.528421]\n",
      "epoch:7 step:6845 [D loss: 0.463633, acc.: 77.34%] [G loss: 0.622474]\n",
      "epoch:7 step:6846 [D loss: 0.592722, acc.: 63.28%] [G loss: 0.665979]\n",
      "epoch:7 step:6847 [D loss: 0.658322, acc.: 57.03%] [G loss: 0.540817]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:7 step:6848 [D loss: 0.537790, acc.: 71.09%] [G loss: 0.515330]\n",
      "epoch:7 step:6849 [D loss: 0.540908, acc.: 67.97%] [G loss: 0.553101]\n",
      "epoch:7 step:6850 [D loss: 0.576528, acc.: 67.97%] [G loss: 0.322659]\n",
      "epoch:7 step:6851 [D loss: 0.524931, acc.: 75.00%] [G loss: 0.534959]\n",
      "epoch:7 step:6852 [D loss: 0.604458, acc.: 67.97%] [G loss: 0.546908]\n",
      "epoch:7 step:6853 [D loss: 0.581485, acc.: 66.41%] [G loss: 0.494408]\n",
      "epoch:7 step:6854 [D loss: 0.557259, acc.: 68.75%] [G loss: 0.562354]\n",
      "epoch:7 step:6855 [D loss: 0.454888, acc.: 79.69%] [G loss: 0.669461]\n",
      "epoch:7 step:6856 [D loss: 0.591524, acc.: 65.62%] [G loss: 0.614779]\n",
      "epoch:7 step:6857 [D loss: 0.485667, acc.: 79.69%] [G loss: 0.631925]\n",
      "epoch:7 step:6858 [D loss: 0.447061, acc.: 82.81%] [G loss: 0.753187]\n",
      "epoch:7 step:6859 [D loss: 0.541896, acc.: 75.00%] [G loss: 0.733271]\n",
      "epoch:7 step:6860 [D loss: 0.623712, acc.: 66.41%] [G loss: 0.550446]\n",
      "epoch:7 step:6861 [D loss: 0.484464, acc.: 76.56%] [G loss: 0.626257]\n",
      "epoch:7 step:6862 [D loss: 0.494401, acc.: 75.78%] [G loss: 0.569946]\n",
      "epoch:7 step:6863 [D loss: 0.480573, acc.: 77.34%] [G loss: 0.741005]\n",
      "epoch:7 step:6864 [D loss: 0.536267, acc.: 69.53%] [G loss: 0.716738]\n",
      "epoch:7 step:6865 [D loss: 0.542754, acc.: 71.09%] [G loss: 0.585624]\n",
      "epoch:7 step:6866 [D loss: 0.481885, acc.: 75.78%] [G loss: 0.695755]\n",
      "epoch:7 step:6867 [D loss: 0.544547, acc.: 68.75%] [G loss: 0.567321]\n",
      "epoch:7 step:6868 [D loss: 0.492971, acc.: 73.44%] [G loss: 0.725673]\n",
      "epoch:7 step:6869 [D loss: 0.524568, acc.: 72.66%] [G loss: 0.705127]\n",
      "epoch:7 step:6870 [D loss: 0.456482, acc.: 77.34%] [G loss: 0.784022]\n",
      "epoch:7 step:6871 [D loss: 0.525436, acc.: 75.78%] [G loss: 0.725836]\n",
      "epoch:7 step:6872 [D loss: 0.518477, acc.: 72.66%] [G loss: 0.817524]\n",
      "epoch:7 step:6873 [D loss: 0.424279, acc.: 82.03%] [G loss: 0.921396]\n",
      "epoch:7 step:6874 [D loss: 0.528118, acc.: 72.66%] [G loss: 0.881101]\n",
      "epoch:7 step:6875 [D loss: 0.746890, acc.: 60.16%] [G loss: 0.507528]\n",
      "epoch:7 step:6876 [D loss: 0.594177, acc.: 63.28%] [G loss: 0.548211]\n",
      "epoch:7 step:6877 [D loss: 0.513503, acc.: 75.00%] [G loss: 0.622902]\n",
      "epoch:7 step:6878 [D loss: 0.533018, acc.: 70.31%] [G loss: 0.595543]\n",
      "epoch:7 step:6879 [D loss: 0.550627, acc.: 73.44%] [G loss: 0.542919]\n",
      "epoch:7 step:6880 [D loss: 0.463158, acc.: 81.25%] [G loss: 0.672493]\n",
      "epoch:7 step:6881 [D loss: 0.563155, acc.: 67.97%] [G loss: 0.760198]\n",
      "epoch:7 step:6882 [D loss: 0.545918, acc.: 74.22%] [G loss: 0.564835]\n",
      "epoch:7 step:6883 [D loss: 0.610493, acc.: 65.62%] [G loss: 0.526919]\n",
      "epoch:7 step:6884 [D loss: 0.551824, acc.: 69.53%] [G loss: 0.572191]\n",
      "epoch:7 step:6885 [D loss: 0.496541, acc.: 78.91%] [G loss: 0.702679]\n",
      "epoch:7 step:6886 [D loss: 0.585575, acc.: 69.53%] [G loss: 0.484096]\n",
      "epoch:7 step:6887 [D loss: 0.512684, acc.: 75.00%] [G loss: 0.592712]\n",
      "epoch:7 step:6888 [D loss: 0.549333, acc.: 72.66%] [G loss: 0.562525]\n",
      "epoch:7 step:6889 [D loss: 0.562583, acc.: 66.41%] [G loss: 0.545048]\n",
      "epoch:7 step:6890 [D loss: 0.535076, acc.: 74.22%] [G loss: 0.502631]\n",
      "epoch:7 step:6891 [D loss: 0.524948, acc.: 68.75%] [G loss: 0.475407]\n",
      "epoch:7 step:6892 [D loss: 0.469573, acc.: 77.34%] [G loss: 0.611150]\n",
      "epoch:7 step:6893 [D loss: 0.533591, acc.: 69.53%] [G loss: 0.667931]\n",
      "epoch:7 step:6894 [D loss: 0.528916, acc.: 71.88%] [G loss: 0.730954]\n",
      "epoch:7 step:6895 [D loss: 0.527381, acc.: 75.78%] [G loss: 0.626994]\n",
      "epoch:7 step:6896 [D loss: 0.531884, acc.: 72.66%] [G loss: 0.647534]\n",
      "epoch:7 step:6897 [D loss: 0.541121, acc.: 72.66%] [G loss: 0.566615]\n",
      "epoch:7 step:6898 [D loss: 0.519237, acc.: 75.00%] [G loss: 0.575709]\n",
      "epoch:7 step:6899 [D loss: 0.497075, acc.: 75.78%] [G loss: 0.594455]\n",
      "epoch:7 step:6900 [D loss: 0.552007, acc.: 71.09%] [G loss: 0.545412]\n",
      "epoch:7 step:6901 [D loss: 0.605900, acc.: 65.62%] [G loss: 0.605283]\n",
      "epoch:7 step:6902 [D loss: 0.473609, acc.: 79.69%] [G loss: 0.676236]\n",
      "epoch:7 step:6903 [D loss: 0.454538, acc.: 79.69%] [G loss: 0.935884]\n",
      "epoch:7 step:6904 [D loss: 0.592883, acc.: 65.62%] [G loss: 0.861655]\n",
      "epoch:7 step:6905 [D loss: 0.532137, acc.: 74.22%] [G loss: 0.771359]\n",
      "epoch:7 step:6906 [D loss: 0.440991, acc.: 85.94%] [G loss: 0.916146]\n",
      "epoch:7 step:6907 [D loss: 0.669203, acc.: 64.06%] [G loss: 0.495456]\n",
      "epoch:7 step:6908 [D loss: 0.737038, acc.: 47.66%] [G loss: 0.425708]\n",
      "epoch:7 step:6909 [D loss: 0.495110, acc.: 77.34%] [G loss: 0.595995]\n",
      "epoch:7 step:6910 [D loss: 0.481944, acc.: 77.34%] [G loss: 0.822856]\n",
      "epoch:7 step:6911 [D loss: 0.613021, acc.: 67.97%] [G loss: 0.571083]\n",
      "epoch:7 step:6912 [D loss: 0.576383, acc.: 68.75%] [G loss: 0.510630]\n",
      "epoch:7 step:6913 [D loss: 0.454841, acc.: 78.91%] [G loss: 0.685313]\n",
      "epoch:7 step:6914 [D loss: 0.577194, acc.: 67.97%] [G loss: 0.722876]\n",
      "epoch:7 step:6915 [D loss: 0.565591, acc.: 68.75%] [G loss: 0.672446]\n",
      "epoch:7 step:6916 [D loss: 0.463986, acc.: 76.56%] [G loss: 0.674272]\n",
      "epoch:7 step:6917 [D loss: 0.442812, acc.: 78.12%] [G loss: 0.819188]\n",
      "epoch:7 step:6918 [D loss: 0.525196, acc.: 67.97%] [G loss: 0.652991]\n",
      "epoch:7 step:6919 [D loss: 0.487070, acc.: 73.44%] [G loss: 0.750753]\n",
      "epoch:7 step:6920 [D loss: 0.558820, acc.: 71.88%] [G loss: 0.564858]\n",
      "epoch:7 step:6921 [D loss: 0.560309, acc.: 65.62%] [G loss: 0.696457]\n",
      "epoch:7 step:6922 [D loss: 0.520418, acc.: 75.78%] [G loss: 0.649794]\n",
      "epoch:7 step:6923 [D loss: 0.529855, acc.: 71.88%] [G loss: 0.459138]\n",
      "epoch:7 step:6924 [D loss: 0.530911, acc.: 74.22%] [G loss: 0.692467]\n",
      "epoch:7 step:6925 [D loss: 0.518118, acc.: 74.22%] [G loss: 0.644577]\n",
      "epoch:7 step:6926 [D loss: 0.565924, acc.: 66.41%] [G loss: 0.713882]\n",
      "epoch:7 step:6927 [D loss: 0.501297, acc.: 71.09%] [G loss: 0.718855]\n",
      "epoch:7 step:6928 [D loss: 0.602067, acc.: 66.41%] [G loss: 0.704231]\n",
      "epoch:7 step:6929 [D loss: 0.504432, acc.: 73.44%] [G loss: 0.710652]\n",
      "epoch:7 step:6930 [D loss: 0.560045, acc.: 73.44%] [G loss: 0.497609]\n",
      "epoch:7 step:6931 [D loss: 0.525509, acc.: 74.22%] [G loss: 0.618507]\n",
      "epoch:7 step:6932 [D loss: 0.549056, acc.: 69.53%] [G loss: 0.619026]\n",
      "epoch:7 step:6933 [D loss: 0.537874, acc.: 74.22%] [G loss: 0.599325]\n",
      "epoch:7 step:6934 [D loss: 0.587232, acc.: 70.31%] [G loss: 0.645700]\n",
      "epoch:7 step:6935 [D loss: 0.713107, acc.: 59.38%] [G loss: 0.450811]\n",
      "epoch:7 step:6936 [D loss: 0.604735, acc.: 67.19%] [G loss: 0.514220]\n",
      "epoch:7 step:6937 [D loss: 0.531091, acc.: 71.09%] [G loss: 0.547290]\n",
      "epoch:7 step:6938 [D loss: 0.603042, acc.: 67.19%] [G loss: 0.537317]\n",
      "epoch:7 step:6939 [D loss: 0.597273, acc.: 65.62%] [G loss: 0.462223]\n",
      "epoch:7 step:6940 [D loss: 0.513873, acc.: 75.78%] [G loss: 0.548364]\n",
      "epoch:7 step:6941 [D loss: 0.553947, acc.: 70.31%] [G loss: 0.522852]\n",
      "epoch:7 step:6942 [D loss: 0.554887, acc.: 68.75%] [G loss: 0.510972]\n",
      "epoch:7 step:6943 [D loss: 0.580841, acc.: 64.84%] [G loss: 0.528095]\n",
      "epoch:7 step:6944 [D loss: 0.539152, acc.: 73.44%] [G loss: 0.558566]\n",
      "epoch:7 step:6945 [D loss: 0.624006, acc.: 58.59%] [G loss: 0.476901]\n",
      "epoch:7 step:6946 [D loss: 0.576084, acc.: 67.19%] [G loss: 0.517291]\n",
      "epoch:7 step:6947 [D loss: 0.566159, acc.: 67.97%] [G loss: 0.517007]\n",
      "epoch:7 step:6948 [D loss: 0.511122, acc.: 71.88%] [G loss: 0.659244]\n",
      "epoch:7 step:6949 [D loss: 0.580606, acc.: 67.19%] [G loss: 0.445393]\n",
      "epoch:7 step:6950 [D loss: 0.549181, acc.: 68.75%] [G loss: 0.471511]\n",
      "epoch:7 step:6951 [D loss: 0.497501, acc.: 75.00%] [G loss: 0.643742]\n",
      "epoch:7 step:6952 [D loss: 0.594521, acc.: 66.41%] [G loss: 0.578915]\n",
      "epoch:7 step:6953 [D loss: 0.564621, acc.: 69.53%] [G loss: 0.483458]\n",
      "epoch:7 step:6954 [D loss: 0.568662, acc.: 63.28%] [G loss: 0.515458]\n",
      "epoch:7 step:6955 [D loss: 0.546023, acc.: 70.31%] [G loss: 0.553049]\n",
      "epoch:7 step:6956 [D loss: 0.481597, acc.: 79.69%] [G loss: 0.623375]\n",
      "epoch:7 step:6957 [D loss: 0.479699, acc.: 75.00%] [G loss: 0.608065]\n",
      "epoch:7 step:6958 [D loss: 0.524873, acc.: 73.44%] [G loss: 0.647889]\n",
      "epoch:7 step:6959 [D loss: 0.597515, acc.: 60.94%] [G loss: 0.553388]\n",
      "epoch:7 step:6960 [D loss: 0.581628, acc.: 63.28%] [G loss: 0.543176]\n",
      "epoch:7 step:6961 [D loss: 0.474314, acc.: 75.00%] [G loss: 0.641766]\n",
      "epoch:7 step:6962 [D loss: 0.483595, acc.: 76.56%] [G loss: 0.733073]\n",
      "epoch:7 step:6963 [D loss: 0.613169, acc.: 64.84%] [G loss: 0.573597]\n",
      "epoch:7 step:6964 [D loss: 0.524882, acc.: 71.09%] [G loss: 0.483372]\n",
      "epoch:7 step:6965 [D loss: 0.523415, acc.: 74.22%] [G loss: 0.595511]\n",
      "epoch:7 step:6966 [D loss: 0.614551, acc.: 67.97%] [G loss: 0.641107]\n",
      "epoch:7 step:6967 [D loss: 0.607417, acc.: 63.28%] [G loss: 0.550197]\n",
      "epoch:7 step:6968 [D loss: 0.569913, acc.: 64.06%] [G loss: 0.539021]\n",
      "epoch:7 step:6969 [D loss: 0.583741, acc.: 68.75%] [G loss: 0.592682]\n",
      "epoch:7 step:6970 [D loss: 0.597843, acc.: 60.94%] [G loss: 0.551137]\n",
      "epoch:7 step:6971 [D loss: 0.590620, acc.: 64.84%] [G loss: 0.519843]\n",
      "epoch:7 step:6972 [D loss: 0.610711, acc.: 65.62%] [G loss: 0.514971]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:7 step:6973 [D loss: 0.533536, acc.: 71.88%] [G loss: 0.651438]\n",
      "epoch:7 step:6974 [D loss: 0.591862, acc.: 67.19%] [G loss: 0.572101]\n",
      "epoch:7 step:6975 [D loss: 0.501703, acc.: 77.34%] [G loss: 0.817868]\n",
      "epoch:7 step:6976 [D loss: 0.635398, acc.: 68.75%] [G loss: 0.543068]\n",
      "epoch:7 step:6977 [D loss: 0.606804, acc.: 67.97%] [G loss: 0.512952]\n",
      "epoch:7 step:6978 [D loss: 0.541523, acc.: 74.22%] [G loss: 0.488282]\n",
      "epoch:7 step:6979 [D loss: 0.575278, acc.: 66.41%] [G loss: 0.453448]\n",
      "epoch:7 step:6980 [D loss: 0.560499, acc.: 71.88%] [G loss: 0.559601]\n",
      "epoch:7 step:6981 [D loss: 0.583740, acc.: 63.28%] [G loss: 0.599034]\n",
      "epoch:7 step:6982 [D loss: 0.538815, acc.: 71.09%] [G loss: 0.539305]\n",
      "epoch:7 step:6983 [D loss: 0.599466, acc.: 68.75%] [G loss: 0.560155]\n",
      "epoch:7 step:6984 [D loss: 0.547175, acc.: 70.31%] [G loss: 0.528567]\n",
      "epoch:7 step:6985 [D loss: 0.513427, acc.: 72.66%] [G loss: 0.607904]\n",
      "epoch:7 step:6986 [D loss: 0.548603, acc.: 72.66%] [G loss: 0.756858]\n",
      "epoch:7 step:6987 [D loss: 0.517023, acc.: 75.00%] [G loss: 0.651673]\n",
      "epoch:7 step:6988 [D loss: 0.456173, acc.: 81.25%] [G loss: 0.652694]\n",
      "epoch:7 step:6989 [D loss: 0.514093, acc.: 76.56%] [G loss: 0.529394]\n",
      "epoch:7 step:6990 [D loss: 0.505358, acc.: 73.44%] [G loss: 0.606497]\n",
      "epoch:7 step:6991 [D loss: 0.572419, acc.: 66.41%] [G loss: 0.491869]\n",
      "epoch:7 step:6992 [D loss: 0.622028, acc.: 70.31%] [G loss: 0.443659]\n",
      "epoch:7 step:6993 [D loss: 0.556602, acc.: 74.22%] [G loss: 0.460992]\n",
      "epoch:7 step:6994 [D loss: 0.537876, acc.: 75.78%] [G loss: 0.458567]\n",
      "epoch:7 step:6995 [D loss: 0.521251, acc.: 75.00%] [G loss: 0.637091]\n",
      "epoch:7 step:6996 [D loss: 0.624280, acc.: 70.31%] [G loss: 0.545865]\n",
      "epoch:7 step:6997 [D loss: 0.548616, acc.: 68.75%] [G loss: 0.456247]\n",
      "epoch:7 step:6998 [D loss: 0.493827, acc.: 79.69%] [G loss: 0.641162]\n",
      "epoch:7 step:6999 [D loss: 0.495729, acc.: 72.66%] [G loss: 0.651146]\n",
      "epoch:7 step:7000 [D loss: 0.585510, acc.: 65.62%] [G loss: 0.698662]\n",
      "##############\n",
      "[3.20964584 1.78619505 6.69064733 5.02939609 4.14750562 5.64398064\n",
      " 4.88766451 4.95685426 4.9863405  3.84110116]\n",
      "##########\n",
      "epoch:7 step:7001 [D loss: 0.552922, acc.: 63.28%] [G loss: 0.605460]\n",
      "epoch:7 step:7002 [D loss: 0.531796, acc.: 75.00%] [G loss: 0.482178]\n",
      "epoch:7 step:7003 [D loss: 0.532770, acc.: 70.31%] [G loss: 0.727888]\n",
      "epoch:7 step:7004 [D loss: 0.538043, acc.: 71.88%] [G loss: 0.635386]\n",
      "epoch:7 step:7005 [D loss: 0.519286, acc.: 71.09%] [G loss: 0.716904]\n",
      "epoch:7 step:7006 [D loss: 0.484492, acc.: 72.66%] [G loss: 0.940266]\n",
      "epoch:7 step:7007 [D loss: 0.592654, acc.: 69.53%] [G loss: 0.641870]\n",
      "epoch:7 step:7008 [D loss: 0.531561, acc.: 73.44%] [G loss: 0.638524]\n",
      "epoch:7 step:7009 [D loss: 0.508363, acc.: 71.88%] [G loss: 0.622931]\n",
      "epoch:7 step:7010 [D loss: 0.426194, acc.: 81.25%] [G loss: 0.817723]\n",
      "epoch:7 step:7011 [D loss: 0.513057, acc.: 71.09%] [G loss: 0.678962]\n",
      "epoch:7 step:7012 [D loss: 0.483842, acc.: 72.66%] [G loss: 0.827687]\n",
      "epoch:7 step:7013 [D loss: 0.611618, acc.: 64.06%] [G loss: 0.599649]\n",
      "epoch:7 step:7014 [D loss: 0.566902, acc.: 72.66%] [G loss: 0.590456]\n",
      "epoch:7 step:7015 [D loss: 0.641177, acc.: 62.50%] [G loss: 0.567326]\n",
      "epoch:7 step:7016 [D loss: 0.508680, acc.: 75.00%] [G loss: 0.470351]\n",
      "epoch:7 step:7017 [D loss: 0.660844, acc.: 64.84%] [G loss: 0.510684]\n",
      "epoch:7 step:7018 [D loss: 0.567375, acc.: 71.09%] [G loss: 0.548877]\n",
      "epoch:7 step:7019 [D loss: 0.580013, acc.: 70.31%] [G loss: 0.602139]\n",
      "epoch:7 step:7020 [D loss: 0.488485, acc.: 75.00%] [G loss: 0.648389]\n",
      "epoch:7 step:7021 [D loss: 0.614079, acc.: 65.62%] [G loss: 0.595823]\n",
      "epoch:7 step:7022 [D loss: 0.539740, acc.: 73.44%] [G loss: 0.557295]\n",
      "epoch:7 step:7023 [D loss: 0.525322, acc.: 70.31%] [G loss: 0.554752]\n",
      "epoch:7 step:7024 [D loss: 0.659802, acc.: 63.28%] [G loss: 0.490596]\n",
      "epoch:7 step:7025 [D loss: 0.541036, acc.: 70.31%] [G loss: 0.468206]\n",
      "epoch:7 step:7026 [D loss: 0.513770, acc.: 73.44%] [G loss: 0.670470]\n",
      "epoch:7 step:7027 [D loss: 0.530290, acc.: 74.22%] [G loss: 0.609658]\n",
      "epoch:7 step:7028 [D loss: 0.531874, acc.: 75.00%] [G loss: 0.587510]\n",
      "epoch:7 step:7029 [D loss: 0.537795, acc.: 70.31%] [G loss: 0.697043]\n",
      "epoch:7 step:7030 [D loss: 0.446663, acc.: 82.03%] [G loss: 0.740674]\n",
      "epoch:7 step:7031 [D loss: 0.484636, acc.: 78.12%] [G loss: 1.076171]\n",
      "epoch:7 step:7032 [D loss: 0.668913, acc.: 62.50%] [G loss: 0.532816]\n",
      "epoch:7 step:7033 [D loss: 0.572819, acc.: 64.06%] [G loss: 0.555352]\n",
      "epoch:7 step:7034 [D loss: 0.477745, acc.: 75.78%] [G loss: 0.758155]\n",
      "epoch:7 step:7035 [D loss: 0.610715, acc.: 70.31%] [G loss: 0.634987]\n",
      "epoch:7 step:7036 [D loss: 0.703108, acc.: 57.81%] [G loss: 0.437472]\n",
      "epoch:7 step:7037 [D loss: 0.618764, acc.: 62.50%] [G loss: 0.317292]\n",
      "epoch:7 step:7038 [D loss: 0.496554, acc.: 81.25%] [G loss: 0.478116]\n",
      "epoch:7 step:7039 [D loss: 0.609918, acc.: 64.84%] [G loss: 0.496945]\n",
      "epoch:7 step:7040 [D loss: 0.505224, acc.: 78.12%] [G loss: 0.473588]\n",
      "epoch:7 step:7041 [D loss: 0.690805, acc.: 58.59%] [G loss: 0.456660]\n",
      "epoch:7 step:7042 [D loss: 0.553267, acc.: 69.53%] [G loss: 0.528067]\n",
      "epoch:7 step:7043 [D loss: 0.491265, acc.: 76.56%] [G loss: 0.594790]\n",
      "epoch:7 step:7044 [D loss: 0.545413, acc.: 71.09%] [G loss: 0.514133]\n",
      "epoch:7 step:7045 [D loss: 0.641147, acc.: 64.06%] [G loss: 0.593882]\n",
      "epoch:7 step:7046 [D loss: 0.545243, acc.: 68.75%] [G loss: 0.503067]\n",
      "epoch:7 step:7047 [D loss: 0.494854, acc.: 75.78%] [G loss: 0.660339]\n",
      "epoch:7 step:7048 [D loss: 0.559525, acc.: 64.06%] [G loss: 0.536386]\n",
      "epoch:7 step:7049 [D loss: 0.554356, acc.: 70.31%] [G loss: 0.612913]\n",
      "epoch:7 step:7050 [D loss: 0.509757, acc.: 73.44%] [G loss: 0.574940]\n",
      "epoch:7 step:7051 [D loss: 0.633485, acc.: 63.28%] [G loss: 0.511196]\n",
      "epoch:7 step:7052 [D loss: 0.573750, acc.: 66.41%] [G loss: 0.486135]\n",
      "epoch:7 step:7053 [D loss: 0.536583, acc.: 75.78%] [G loss: 0.499488]\n",
      "epoch:7 step:7054 [D loss: 0.540069, acc.: 74.22%] [G loss: 0.555319]\n",
      "epoch:7 step:7055 [D loss: 0.574537, acc.: 69.53%] [G loss: 0.459330]\n",
      "epoch:7 step:7056 [D loss: 0.572630, acc.: 74.22%] [G loss: 0.600559]\n",
      "epoch:7 step:7057 [D loss: 0.551583, acc.: 71.88%] [G loss: 0.615897]\n",
      "epoch:7 step:7058 [D loss: 0.454764, acc.: 80.47%] [G loss: 0.708178]\n",
      "epoch:7 step:7059 [D loss: 0.644899, acc.: 63.28%] [G loss: 0.552425]\n",
      "epoch:7 step:7060 [D loss: 0.632724, acc.: 67.19%] [G loss: 0.458384]\n",
      "epoch:7 step:7061 [D loss: 0.609763, acc.: 67.19%] [G loss: 0.387015]\n",
      "epoch:7 step:7062 [D loss: 0.517779, acc.: 77.34%] [G loss: 0.511864]\n",
      "epoch:7 step:7063 [D loss: 0.477002, acc.: 74.22%] [G loss: 0.667221]\n",
      "epoch:7 step:7064 [D loss: 0.546466, acc.: 71.09%] [G loss: 0.658520]\n",
      "epoch:7 step:7065 [D loss: 0.516401, acc.: 74.22%] [G loss: 0.669227]\n",
      "epoch:7 step:7066 [D loss: 0.506642, acc.: 74.22%] [G loss: 0.662096]\n",
      "epoch:7 step:7067 [D loss: 0.415744, acc.: 85.16%] [G loss: 0.753300]\n",
      "epoch:7 step:7068 [D loss: 0.530288, acc.: 71.88%] [G loss: 0.648977]\n",
      "epoch:7 step:7069 [D loss: 0.572654, acc.: 67.97%] [G loss: 0.629380]\n",
      "epoch:7 step:7070 [D loss: 0.682242, acc.: 57.81%] [G loss: 0.431694]\n",
      "epoch:7 step:7071 [D loss: 0.602762, acc.: 67.97%] [G loss: 0.465996]\n",
      "epoch:7 step:7072 [D loss: 0.494876, acc.: 79.69%] [G loss: 0.522188]\n",
      "epoch:7 step:7073 [D loss: 0.548737, acc.: 69.53%] [G loss: 0.527494]\n",
      "epoch:7 step:7074 [D loss: 0.523403, acc.: 74.22%] [G loss: 0.751013]\n",
      "epoch:7 step:7075 [D loss: 0.509357, acc.: 71.88%] [G loss: 0.622766]\n",
      "epoch:7 step:7076 [D loss: 0.559481, acc.: 68.75%] [G loss: 0.662731]\n",
      "epoch:7 step:7077 [D loss: 0.507429, acc.: 75.78%] [G loss: 0.566427]\n",
      "epoch:7 step:7078 [D loss: 0.491385, acc.: 75.78%] [G loss: 0.692464]\n",
      "epoch:7 step:7079 [D loss: 0.500479, acc.: 72.66%] [G loss: 0.531600]\n",
      "epoch:7 step:7080 [D loss: 0.518116, acc.: 75.00%] [G loss: 0.608733]\n",
      "epoch:7 step:7081 [D loss: 0.484504, acc.: 76.56%] [G loss: 0.538056]\n",
      "epoch:7 step:7082 [D loss: 0.580427, acc.: 70.31%] [G loss: 0.528244]\n",
      "epoch:7 step:7083 [D loss: 0.522451, acc.: 73.44%] [G loss: 0.609473]\n",
      "epoch:7 step:7084 [D loss: 0.558898, acc.: 69.53%] [G loss: 0.555289]\n",
      "epoch:7 step:7085 [D loss: 0.559265, acc.: 69.53%] [G loss: 0.588728]\n",
      "epoch:7 step:7086 [D loss: 0.576141, acc.: 69.53%] [G loss: 0.541928]\n",
      "epoch:7 step:7087 [D loss: 0.675679, acc.: 59.38%] [G loss: 0.504752]\n",
      "epoch:7 step:7088 [D loss: 0.623137, acc.: 62.50%] [G loss: 0.572456]\n",
      "epoch:7 step:7089 [D loss: 0.496577, acc.: 70.31%] [G loss: 0.788589]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:7 step:7090 [D loss: 0.571349, acc.: 71.09%] [G loss: 0.589922]\n",
      "epoch:7 step:7091 [D loss: 0.560384, acc.: 69.53%] [G loss: 0.526418]\n",
      "epoch:7 step:7092 [D loss: 0.536266, acc.: 71.09%] [G loss: 0.554851]\n",
      "epoch:7 step:7093 [D loss: 0.496636, acc.: 72.66%] [G loss: 0.521265]\n",
      "epoch:7 step:7094 [D loss: 0.652507, acc.: 64.06%] [G loss: 0.440583]\n",
      "epoch:7 step:7095 [D loss: 0.519053, acc.: 73.44%] [G loss: 0.526259]\n",
      "epoch:7 step:7096 [D loss: 0.592186, acc.: 69.53%] [G loss: 0.538354]\n",
      "epoch:7 step:7097 [D loss: 0.549312, acc.: 67.97%] [G loss: 0.530859]\n",
      "epoch:7 step:7098 [D loss: 0.584702, acc.: 60.16%] [G loss: 0.452988]\n",
      "epoch:7 step:7099 [D loss: 0.500906, acc.: 71.88%] [G loss: 0.531230]\n",
      "epoch:7 step:7100 [D loss: 0.521729, acc.: 74.22%] [G loss: 0.558227]\n",
      "epoch:7 step:7101 [D loss: 0.573663, acc.: 67.19%] [G loss: 0.510293]\n",
      "epoch:7 step:7102 [D loss: 0.595109, acc.: 68.75%] [G loss: 0.522745]\n",
      "epoch:7 step:7103 [D loss: 0.588130, acc.: 64.84%] [G loss: 0.523533]\n",
      "epoch:7 step:7104 [D loss: 0.554139, acc.: 73.44%] [G loss: 0.602095]\n",
      "epoch:7 step:7105 [D loss: 0.483838, acc.: 78.12%] [G loss: 0.674804]\n",
      "epoch:7 step:7106 [D loss: 0.550482, acc.: 67.97%] [G loss: 0.665683]\n",
      "epoch:7 step:7107 [D loss: 0.529503, acc.: 71.88%] [G loss: 0.501249]\n",
      "epoch:7 step:7108 [D loss: 0.535293, acc.: 67.97%] [G loss: 0.611036]\n",
      "epoch:7 step:7109 [D loss: 0.617003, acc.: 60.94%] [G loss: 0.609776]\n",
      "epoch:7 step:7110 [D loss: 0.545172, acc.: 71.09%] [G loss: 0.513766]\n",
      "epoch:7 step:7111 [D loss: 0.512899, acc.: 73.44%] [G loss: 0.579083]\n",
      "epoch:7 step:7112 [D loss: 0.542321, acc.: 73.44%] [G loss: 0.536001]\n",
      "epoch:7 step:7113 [D loss: 0.450890, acc.: 75.78%] [G loss: 0.686534]\n",
      "epoch:7 step:7114 [D loss: 0.505180, acc.: 78.12%] [G loss: 0.523050]\n",
      "epoch:7 step:7115 [D loss: 0.508290, acc.: 74.22%] [G loss: 0.555851]\n",
      "epoch:7 step:7116 [D loss: 0.504514, acc.: 75.00%] [G loss: 0.639963]\n",
      "epoch:7 step:7117 [D loss: 0.463514, acc.: 78.12%] [G loss: 0.656565]\n",
      "epoch:7 step:7118 [D loss: 0.561837, acc.: 70.31%] [G loss: 0.508495]\n",
      "epoch:7 step:7119 [D loss: 0.551446, acc.: 70.31%] [G loss: 0.511226]\n",
      "epoch:7 step:7120 [D loss: 0.478397, acc.: 78.91%] [G loss: 0.603353]\n",
      "epoch:7 step:7121 [D loss: 0.627122, acc.: 60.94%] [G loss: 0.518556]\n",
      "epoch:7 step:7122 [D loss: 0.568912, acc.: 69.53%] [G loss: 0.568537]\n",
      "epoch:7 step:7123 [D loss: 0.539596, acc.: 67.97%] [G loss: 0.491005]\n",
      "epoch:7 step:7124 [D loss: 0.610126, acc.: 67.97%] [G loss: 0.532856]\n",
      "epoch:7 step:7125 [D loss: 0.664758, acc.: 60.94%] [G loss: 0.491402]\n",
      "epoch:7 step:7126 [D loss: 0.507451, acc.: 75.00%] [G loss: 0.549493]\n",
      "epoch:7 step:7127 [D loss: 0.533718, acc.: 74.22%] [G loss: 0.677696]\n",
      "epoch:7 step:7128 [D loss: 0.507320, acc.: 73.44%] [G loss: 0.669260]\n",
      "epoch:7 step:7129 [D loss: 0.568980, acc.: 66.41%] [G loss: 0.485738]\n",
      "epoch:7 step:7130 [D loss: 0.518254, acc.: 75.00%] [G loss: 0.567339]\n",
      "epoch:7 step:7131 [D loss: 0.579529, acc.: 69.53%] [G loss: 0.522578]\n",
      "epoch:7 step:7132 [D loss: 0.545710, acc.: 73.44%] [G loss: 0.622865]\n",
      "epoch:7 step:7133 [D loss: 0.535427, acc.: 71.09%] [G loss: 0.740690]\n",
      "epoch:7 step:7134 [D loss: 0.524271, acc.: 75.78%] [G loss: 0.645680]\n",
      "epoch:7 step:7135 [D loss: 0.626393, acc.: 64.06%] [G loss: 0.579529]\n",
      "epoch:7 step:7136 [D loss: 0.618561, acc.: 61.72%] [G loss: 0.532146]\n",
      "epoch:7 step:7137 [D loss: 0.539993, acc.: 67.19%] [G loss: 0.681052]\n",
      "epoch:7 step:7138 [D loss: 0.558007, acc.: 66.41%] [G loss: 0.605954]\n",
      "epoch:7 step:7139 [D loss: 0.604391, acc.: 63.28%] [G loss: 0.527016]\n",
      "epoch:7 step:7140 [D loss: 0.555722, acc.: 69.53%] [G loss: 0.522007]\n",
      "epoch:7 step:7141 [D loss: 0.509184, acc.: 75.00%] [G loss: 0.749205]\n",
      "epoch:7 step:7142 [D loss: 0.574575, acc.: 65.62%] [G loss: 0.574439]\n",
      "epoch:7 step:7143 [D loss: 0.669357, acc.: 59.38%] [G loss: 0.628686]\n",
      "epoch:7 step:7144 [D loss: 0.532731, acc.: 72.66%] [G loss: 0.492050]\n",
      "epoch:7 step:7145 [D loss: 0.577404, acc.: 67.19%] [G loss: 0.447225]\n",
      "epoch:7 step:7146 [D loss: 0.574106, acc.: 64.06%] [G loss: 0.417646]\n",
      "epoch:7 step:7147 [D loss: 0.636286, acc.: 57.81%] [G loss: 0.587649]\n",
      "epoch:7 step:7148 [D loss: 0.520141, acc.: 70.31%] [G loss: 0.600958]\n",
      "epoch:7 step:7149 [D loss: 0.549242, acc.: 73.44%] [G loss: 0.580216]\n",
      "epoch:7 step:7150 [D loss: 0.568546, acc.: 64.06%] [G loss: 0.494537]\n",
      "epoch:7 step:7151 [D loss: 0.521304, acc.: 73.44%] [G loss: 0.546565]\n",
      "epoch:7 step:7152 [D loss: 0.531320, acc.: 71.88%] [G loss: 0.681793]\n",
      "epoch:7 step:7153 [D loss: 0.564389, acc.: 71.09%] [G loss: 0.577125]\n",
      "epoch:7 step:7154 [D loss: 0.625132, acc.: 64.84%] [G loss: 0.550718]\n",
      "epoch:7 step:7155 [D loss: 0.554679, acc.: 68.75%] [G loss: 0.535247]\n",
      "epoch:7 step:7156 [D loss: 0.529369, acc.: 71.88%] [G loss: 0.484131]\n",
      "epoch:7 step:7157 [D loss: 0.518867, acc.: 73.44%] [G loss: 0.491302]\n",
      "epoch:7 step:7158 [D loss: 0.629928, acc.: 64.84%] [G loss: 0.500632]\n",
      "epoch:7 step:7159 [D loss: 0.636806, acc.: 63.28%] [G loss: 0.609328]\n",
      "epoch:7 step:7160 [D loss: 0.534801, acc.: 67.97%] [G loss: 0.530442]\n",
      "epoch:7 step:7161 [D loss: 0.533761, acc.: 67.19%] [G loss: 0.553471]\n",
      "epoch:7 step:7162 [D loss: 0.504557, acc.: 76.56%] [G loss: 0.620685]\n",
      "epoch:7 step:7163 [D loss: 0.591579, acc.: 71.09%] [G loss: 0.491690]\n",
      "epoch:7 step:7164 [D loss: 0.513456, acc.: 76.56%] [G loss: 0.551918]\n",
      "epoch:7 step:7165 [D loss: 0.614384, acc.: 66.41%] [G loss: 0.576795]\n",
      "epoch:7 step:7166 [D loss: 0.556131, acc.: 65.62%] [G loss: 0.476775]\n",
      "epoch:7 step:7167 [D loss: 0.517823, acc.: 76.56%] [G loss: 0.564407]\n",
      "epoch:7 step:7168 [D loss: 0.508209, acc.: 75.00%] [G loss: 0.498153]\n",
      "epoch:7 step:7169 [D loss: 0.565696, acc.: 69.53%] [G loss: 0.434942]\n",
      "epoch:7 step:7170 [D loss: 0.538494, acc.: 70.31%] [G loss: 0.381358]\n",
      "epoch:7 step:7171 [D loss: 0.534430, acc.: 71.09%] [G loss: 0.496301]\n",
      "epoch:7 step:7172 [D loss: 0.461612, acc.: 77.34%] [G loss: 0.612344]\n",
      "epoch:7 step:7173 [D loss: 0.554465, acc.: 70.31%] [G loss: 0.492163]\n",
      "epoch:7 step:7174 [D loss: 0.608608, acc.: 64.06%] [G loss: 0.515011]\n",
      "epoch:7 step:7175 [D loss: 0.495875, acc.: 75.00%] [G loss: 0.601097]\n",
      "epoch:7 step:7176 [D loss: 0.604497, acc.: 64.06%] [G loss: 0.432216]\n",
      "epoch:7 step:7177 [D loss: 0.519002, acc.: 72.66%] [G loss: 0.650408]\n",
      "epoch:7 step:7178 [D loss: 0.518745, acc.: 76.56%] [G loss: 0.650140]\n",
      "epoch:7 step:7179 [D loss: 0.541956, acc.: 72.66%] [G loss: 0.560986]\n",
      "epoch:7 step:7180 [D loss: 0.575283, acc.: 67.19%] [G loss: 0.508935]\n",
      "epoch:7 step:7181 [D loss: 0.672613, acc.: 66.41%] [G loss: 0.446834]\n",
      "epoch:7 step:7182 [D loss: 0.498891, acc.: 75.00%] [G loss: 0.521006]\n",
      "epoch:7 step:7183 [D loss: 0.490083, acc.: 75.00%] [G loss: 0.590508]\n",
      "epoch:7 step:7184 [D loss: 0.575560, acc.: 67.19%] [G loss: 0.455741]\n",
      "epoch:7 step:7185 [D loss: 0.525633, acc.: 74.22%] [G loss: 0.512746]\n",
      "epoch:7 step:7186 [D loss: 0.557591, acc.: 67.19%] [G loss: 0.507600]\n",
      "epoch:7 step:7187 [D loss: 0.556570, acc.: 71.09%] [G loss: 0.508479]\n",
      "epoch:7 step:7188 [D loss: 0.499683, acc.: 77.34%] [G loss: 0.569400]\n",
      "epoch:7 step:7189 [D loss: 0.516624, acc.: 71.88%] [G loss: 0.568420]\n",
      "epoch:7 step:7190 [D loss: 0.469478, acc.: 78.12%] [G loss: 0.573915]\n",
      "epoch:7 step:7191 [D loss: 0.514353, acc.: 73.44%] [G loss: 0.629262]\n",
      "epoch:7 step:7192 [D loss: 0.529484, acc.: 71.09%] [G loss: 0.611472]\n",
      "epoch:7 step:7193 [D loss: 0.496900, acc.: 79.69%] [G loss: 0.647952]\n",
      "epoch:7 step:7194 [D loss: 0.517612, acc.: 68.75%] [G loss: 0.725873]\n",
      "epoch:7 step:7195 [D loss: 0.578830, acc.: 68.75%] [G loss: 0.553990]\n",
      "epoch:7 step:7196 [D loss: 0.526527, acc.: 75.00%] [G loss: 0.467156]\n",
      "epoch:7 step:7197 [D loss: 0.545963, acc.: 73.44%] [G loss: 0.471486]\n",
      "epoch:7 step:7198 [D loss: 0.505926, acc.: 71.88%] [G loss: 0.557696]\n",
      "epoch:7 step:7199 [D loss: 0.538640, acc.: 70.31%] [G loss: 0.612873]\n",
      "epoch:7 step:7200 [D loss: 0.472220, acc.: 78.91%] [G loss: 0.727055]\n",
      "##############\n",
      "[2.96541112 1.60400746 6.62867494 4.88839076 3.99721809 5.84005433\n",
      " 4.85887455 4.71356479 4.72067193 3.72728728]\n",
      "##########\n",
      "epoch:7 step:7201 [D loss: 0.422770, acc.: 82.81%] [G loss: 0.804553]\n",
      "epoch:7 step:7202 [D loss: 0.533115, acc.: 73.44%] [G loss: 0.571961]\n",
      "epoch:7 step:7203 [D loss: 0.578123, acc.: 67.97%] [G loss: 0.582690]\n",
      "epoch:7 step:7204 [D loss: 0.564094, acc.: 67.97%] [G loss: 0.412237]\n",
      "epoch:7 step:7205 [D loss: 0.570236, acc.: 71.09%] [G loss: 0.571120]\n",
      "epoch:7 step:7206 [D loss: 0.495651, acc.: 78.91%] [G loss: 0.670689]\n",
      "epoch:7 step:7207 [D loss: 0.421555, acc.: 83.59%] [G loss: 0.767647]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:7 step:7208 [D loss: 0.451235, acc.: 82.81%] [G loss: 0.810601]\n",
      "epoch:7 step:7209 [D loss: 0.533414, acc.: 77.34%] [G loss: 0.776515]\n",
      "epoch:7 step:7210 [D loss: 0.514128, acc.: 76.56%] [G loss: 0.712759]\n",
      "epoch:7 step:7211 [D loss: 0.633772, acc.: 61.72%] [G loss: 0.560356]\n",
      "epoch:7 step:7212 [D loss: 0.623234, acc.: 62.50%] [G loss: 0.540972]\n",
      "epoch:7 step:7213 [D loss: 0.481779, acc.: 73.44%] [G loss: 0.647532]\n",
      "epoch:7 step:7214 [D loss: 0.590719, acc.: 66.41%] [G loss: 0.538940]\n",
      "epoch:7 step:7215 [D loss: 0.564957, acc.: 72.66%] [G loss: 0.577404]\n",
      "epoch:7 step:7216 [D loss: 0.514987, acc.: 73.44%] [G loss: 0.591739]\n",
      "epoch:7 step:7217 [D loss: 0.583939, acc.: 66.41%] [G loss: 0.586756]\n",
      "epoch:7 step:7218 [D loss: 0.533641, acc.: 74.22%] [G loss: 0.699416]\n",
      "epoch:7 step:7219 [D loss: 0.506278, acc.: 78.91%] [G loss: 0.655264]\n",
      "epoch:7 step:7220 [D loss: 0.520871, acc.: 71.09%] [G loss: 0.612822]\n",
      "epoch:7 step:7221 [D loss: 0.557752, acc.: 67.19%] [G loss: 0.618436]\n",
      "epoch:7 step:7222 [D loss: 0.554327, acc.: 67.19%] [G loss: 0.577970]\n",
      "epoch:7 step:7223 [D loss: 0.546655, acc.: 67.97%] [G loss: 0.817826]\n",
      "epoch:7 step:7224 [D loss: 0.664941, acc.: 60.16%] [G loss: 0.611625]\n",
      "epoch:7 step:7225 [D loss: 0.513567, acc.: 77.34%] [G loss: 0.566531]\n",
      "epoch:7 step:7226 [D loss: 0.618064, acc.: 64.06%] [G loss: 0.529374]\n",
      "epoch:7 step:7227 [D loss: 0.548891, acc.: 71.88%] [G loss: 0.609725]\n",
      "epoch:7 step:7228 [D loss: 0.517108, acc.: 72.66%] [G loss: 0.545662]\n",
      "epoch:7 step:7229 [D loss: 0.546503, acc.: 68.75%] [G loss: 0.511108]\n",
      "epoch:7 step:7230 [D loss: 0.587315, acc.: 64.06%] [G loss: 0.536975]\n",
      "epoch:7 step:7231 [D loss: 0.555577, acc.: 72.66%] [G loss: 0.507096]\n",
      "epoch:7 step:7232 [D loss: 0.542566, acc.: 73.44%] [G loss: 0.508817]\n",
      "epoch:7 step:7233 [D loss: 0.557262, acc.: 71.09%] [G loss: 0.584135]\n",
      "epoch:7 step:7234 [D loss: 0.579570, acc.: 62.50%] [G loss: 0.491578]\n",
      "epoch:7 step:7235 [D loss: 0.547032, acc.: 69.53%] [G loss: 0.645409]\n",
      "epoch:7 step:7236 [D loss: 0.495701, acc.: 75.00%] [G loss: 0.661313]\n",
      "epoch:7 step:7237 [D loss: 0.574275, acc.: 66.41%] [G loss: 0.573536]\n",
      "epoch:7 step:7238 [D loss: 0.538484, acc.: 68.75%] [G loss: 0.557309]\n",
      "epoch:7 step:7239 [D loss: 0.475648, acc.: 75.78%] [G loss: 0.670337]\n",
      "epoch:7 step:7240 [D loss: 0.499179, acc.: 75.78%] [G loss: 0.709448]\n",
      "epoch:7 step:7241 [D loss: 0.617712, acc.: 63.28%] [G loss: 0.520457]\n",
      "epoch:7 step:7242 [D loss: 0.567737, acc.: 70.31%] [G loss: 0.593019]\n",
      "epoch:7 step:7243 [D loss: 0.664008, acc.: 60.16%] [G loss: 0.445923]\n",
      "epoch:7 step:7244 [D loss: 0.543417, acc.: 68.75%] [G loss: 0.506071]\n",
      "epoch:7 step:7245 [D loss: 0.642427, acc.: 65.62%] [G loss: 0.471983]\n",
      "epoch:7 step:7246 [D loss: 0.553190, acc.: 74.22%] [G loss: 0.484472]\n",
      "epoch:7 step:7247 [D loss: 0.581922, acc.: 67.19%] [G loss: 0.555833]\n",
      "epoch:7 step:7248 [D loss: 0.528076, acc.: 74.22%] [G loss: 0.664665]\n",
      "epoch:7 step:7249 [D loss: 0.483731, acc.: 78.91%] [G loss: 0.721471]\n",
      "epoch:7 step:7250 [D loss: 0.508205, acc.: 76.56%] [G loss: 0.644410]\n",
      "epoch:7 step:7251 [D loss: 0.510408, acc.: 73.44%] [G loss: 0.614908]\n",
      "epoch:7 step:7252 [D loss: 0.507864, acc.: 78.91%] [G loss: 0.670672]\n",
      "epoch:7 step:7253 [D loss: 0.486467, acc.: 79.69%] [G loss: 0.657543]\n",
      "epoch:7 step:7254 [D loss: 0.532577, acc.: 74.22%] [G loss: 0.596024]\n",
      "epoch:7 step:7255 [D loss: 0.656287, acc.: 57.03%] [G loss: 0.446977]\n",
      "epoch:7 step:7256 [D loss: 0.556681, acc.: 67.19%] [G loss: 0.514340]\n",
      "epoch:7 step:7257 [D loss: 0.520114, acc.: 74.22%] [G loss: 0.586455]\n",
      "epoch:7 step:7258 [D loss: 0.529647, acc.: 70.31%] [G loss: 0.687878]\n",
      "epoch:7 step:7259 [D loss: 0.540268, acc.: 74.22%] [G loss: 0.792176]\n",
      "epoch:7 step:7260 [D loss: 0.547985, acc.: 71.09%] [G loss: 0.753662]\n",
      "epoch:7 step:7261 [D loss: 0.569600, acc.: 69.53%] [G loss: 0.598127]\n",
      "epoch:7 step:7262 [D loss: 0.576683, acc.: 67.19%] [G loss: 0.589211]\n",
      "epoch:7 step:7263 [D loss: 0.655469, acc.: 60.16%] [G loss: 0.558001]\n",
      "epoch:7 step:7264 [D loss: 0.554734, acc.: 66.41%] [G loss: 0.558596]\n",
      "epoch:7 step:7265 [D loss: 0.572361, acc.: 70.31%] [G loss: 0.676646]\n",
      "epoch:7 step:7266 [D loss: 0.490998, acc.: 80.47%] [G loss: 0.655488]\n",
      "epoch:7 step:7267 [D loss: 0.472127, acc.: 80.47%] [G loss: 0.614452]\n",
      "epoch:7 step:7268 [D loss: 0.500549, acc.: 68.75%] [G loss: 0.659021]\n",
      "epoch:7 step:7269 [D loss: 0.608906, acc.: 67.97%] [G loss: 0.462879]\n",
      "epoch:7 step:7270 [D loss: 0.552161, acc.: 68.75%] [G loss: 0.636588]\n",
      "epoch:7 step:7271 [D loss: 0.504546, acc.: 73.44%] [G loss: 0.651581]\n",
      "epoch:7 step:7272 [D loss: 0.595000, acc.: 65.62%] [G loss: 0.436249]\n",
      "epoch:7 step:7273 [D loss: 0.511863, acc.: 74.22%] [G loss: 0.563210]\n",
      "epoch:7 step:7274 [D loss: 0.581311, acc.: 67.97%] [G loss: 0.615663]\n",
      "epoch:7 step:7275 [D loss: 0.641713, acc.: 64.06%] [G loss: 0.438270]\n",
      "epoch:7 step:7276 [D loss: 0.626529, acc.: 60.16%] [G loss: 0.427035]\n",
      "epoch:7 step:7277 [D loss: 0.650096, acc.: 59.38%] [G loss: 0.303061]\n",
      "epoch:7 step:7278 [D loss: 0.574046, acc.: 69.53%] [G loss: 0.445390]\n",
      "epoch:7 step:7279 [D loss: 0.621083, acc.: 67.97%] [G loss: 0.556512]\n",
      "epoch:7 step:7280 [D loss: 0.600287, acc.: 65.62%] [G loss: 0.556759]\n",
      "epoch:7 step:7281 [D loss: 0.542627, acc.: 67.97%] [G loss: 0.585142]\n",
      "epoch:7 step:7282 [D loss: 0.583539, acc.: 66.41%] [G loss: 0.481554]\n",
      "epoch:7 step:7283 [D loss: 0.539961, acc.: 68.75%] [G loss: 0.574036]\n",
      "epoch:7 step:7284 [D loss: 0.471581, acc.: 80.47%] [G loss: 0.697574]\n",
      "epoch:7 step:7285 [D loss: 0.482725, acc.: 79.69%] [G loss: 0.760947]\n",
      "epoch:7 step:7286 [D loss: 0.583063, acc.: 68.75%] [G loss: 0.471207]\n",
      "epoch:7 step:7287 [D loss: 0.519291, acc.: 72.66%] [G loss: 0.466448]\n",
      "epoch:7 step:7288 [D loss: 0.650497, acc.: 60.16%] [G loss: 0.384309]\n",
      "epoch:7 step:7289 [D loss: 0.568051, acc.: 64.84%] [G loss: 0.451105]\n",
      "epoch:7 step:7290 [D loss: 0.566465, acc.: 66.41%] [G loss: 0.594395]\n",
      "epoch:7 step:7291 [D loss: 0.523400, acc.: 75.78%] [G loss: 0.594262]\n",
      "epoch:7 step:7292 [D loss: 0.581269, acc.: 66.41%] [G loss: 0.595376]\n",
      "epoch:7 step:7293 [D loss: 0.539674, acc.: 70.31%] [G loss: 0.624054]\n",
      "epoch:7 step:7294 [D loss: 0.514402, acc.: 75.00%] [G loss: 0.590827]\n",
      "epoch:7 step:7295 [D loss: 0.494721, acc.: 75.00%] [G loss: 0.704174]\n",
      "epoch:7 step:7296 [D loss: 0.483864, acc.: 78.91%] [G loss: 0.723169]\n",
      "epoch:7 step:7297 [D loss: 0.605059, acc.: 65.62%] [G loss: 0.420191]\n",
      "epoch:7 step:7298 [D loss: 0.589440, acc.: 67.19%] [G loss: 0.511505]\n",
      "epoch:7 step:7299 [D loss: 0.642926, acc.: 59.38%] [G loss: 0.471548]\n",
      "epoch:7 step:7300 [D loss: 0.535477, acc.: 75.00%] [G loss: 0.414675]\n",
      "epoch:7 step:7301 [D loss: 0.574912, acc.: 67.97%] [G loss: 0.460586]\n",
      "epoch:7 step:7302 [D loss: 0.504069, acc.: 77.34%] [G loss: 0.680989]\n",
      "epoch:7 step:7303 [D loss: 0.594626, acc.: 71.09%] [G loss: 0.575576]\n",
      "epoch:7 step:7304 [D loss: 0.634314, acc.: 60.94%] [G loss: 0.550991]\n",
      "epoch:7 step:7305 [D loss: 0.494986, acc.: 74.22%] [G loss: 0.644264]\n",
      "epoch:7 step:7306 [D loss: 0.426776, acc.: 76.56%] [G loss: 0.642895]\n",
      "epoch:7 step:7307 [D loss: 0.565817, acc.: 65.62%] [G loss: 0.629310]\n",
      "epoch:7 step:7308 [D loss: 0.527459, acc.: 74.22%] [G loss: 0.511032]\n",
      "epoch:7 step:7309 [D loss: 0.506694, acc.: 72.66%] [G loss: 0.545443]\n",
      "epoch:7 step:7310 [D loss: 0.518658, acc.: 71.09%] [G loss: 0.636538]\n",
      "epoch:7 step:7311 [D loss: 0.577356, acc.: 64.06%] [G loss: 0.636334]\n",
      "epoch:7 step:7312 [D loss: 0.500135, acc.: 74.22%] [G loss: 0.591038]\n",
      "epoch:7 step:7313 [D loss: 0.498780, acc.: 78.91%] [G loss: 0.668938]\n",
      "epoch:7 step:7314 [D loss: 0.562516, acc.: 68.75%] [G loss: 0.625715]\n",
      "epoch:7 step:7315 [D loss: 0.505677, acc.: 78.12%] [G loss: 0.643779]\n",
      "epoch:7 step:7316 [D loss: 0.522429, acc.: 71.09%] [G loss: 0.663133]\n",
      "epoch:7 step:7317 [D loss: 0.503222, acc.: 76.56%] [G loss: 0.588988]\n",
      "epoch:7 step:7318 [D loss: 0.567195, acc.: 69.53%] [G loss: 0.519522]\n",
      "epoch:7 step:7319 [D loss: 0.527436, acc.: 72.66%] [G loss: 0.551958]\n",
      "epoch:7 step:7320 [D loss: 0.577207, acc.: 71.09%] [G loss: 0.479177]\n",
      "epoch:7 step:7321 [D loss: 0.581395, acc.: 64.06%] [G loss: 0.539651]\n",
      "epoch:7 step:7322 [D loss: 0.584877, acc.: 64.84%] [G loss: 0.435400]\n",
      "epoch:7 step:7323 [D loss: 0.563594, acc.: 68.75%] [G loss: 0.445082]\n",
      "epoch:7 step:7324 [D loss: 0.665880, acc.: 61.72%] [G loss: 0.580616]\n",
      "epoch:7 step:7325 [D loss: 0.679963, acc.: 61.72%] [G loss: 0.472073]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:7 step:7326 [D loss: 0.520521, acc.: 75.00%] [G loss: 0.577464]\n",
      "epoch:7 step:7327 [D loss: 0.494729, acc.: 78.12%] [G loss: 0.542388]\n",
      "epoch:7 step:7328 [D loss: 0.513154, acc.: 71.09%] [G loss: 0.551958]\n",
      "epoch:7 step:7329 [D loss: 0.533774, acc.: 73.44%] [G loss: 0.769342]\n",
      "epoch:7 step:7330 [D loss: 0.479858, acc.: 78.91%] [G loss: 0.691305]\n",
      "epoch:7 step:7331 [D loss: 0.528243, acc.: 70.31%] [G loss: 0.557085]\n",
      "epoch:7 step:7332 [D loss: 0.557221, acc.: 66.41%] [G loss: 0.634029]\n",
      "epoch:7 step:7333 [D loss: 0.536067, acc.: 77.34%] [G loss: 0.623708]\n",
      "epoch:7 step:7334 [D loss: 0.530463, acc.: 69.53%] [G loss: 0.644008]\n",
      "epoch:7 step:7335 [D loss: 0.569224, acc.: 66.41%] [G loss: 0.472022]\n",
      "epoch:7 step:7336 [D loss: 0.534016, acc.: 71.09%] [G loss: 0.537741]\n",
      "epoch:7 step:7337 [D loss: 0.502067, acc.: 75.78%] [G loss: 0.536429]\n",
      "epoch:7 step:7338 [D loss: 0.589873, acc.: 66.41%] [G loss: 0.576574]\n",
      "epoch:7 step:7339 [D loss: 0.562939, acc.: 63.28%] [G loss: 0.663062]\n",
      "epoch:7 step:7340 [D loss: 0.575300, acc.: 67.97%] [G loss: 0.796305]\n",
      "epoch:7 step:7341 [D loss: 0.520106, acc.: 69.53%] [G loss: 0.700017]\n",
      "epoch:7 step:7342 [D loss: 0.538491, acc.: 73.44%] [G loss: 0.717546]\n",
      "epoch:7 step:7343 [D loss: 0.632070, acc.: 61.72%] [G loss: 0.465151]\n",
      "epoch:7 step:7344 [D loss: 0.562000, acc.: 70.31%] [G loss: 0.507090]\n",
      "epoch:7 step:7345 [D loss: 0.559392, acc.: 68.75%] [G loss: 0.661285]\n",
      "epoch:7 step:7346 [D loss: 0.600550, acc.: 64.84%] [G loss: 0.601029]\n",
      "epoch:7 step:7347 [D loss: 0.666410, acc.: 60.94%] [G loss: 0.491468]\n",
      "epoch:7 step:7348 [D loss: 0.587784, acc.: 66.41%] [G loss: 0.392824]\n",
      "epoch:7 step:7349 [D loss: 0.581315, acc.: 66.41%] [G loss: 0.489111]\n",
      "epoch:7 step:7350 [D loss: 0.527558, acc.: 76.56%] [G loss: 0.595405]\n",
      "epoch:7 step:7351 [D loss: 0.479687, acc.: 75.78%] [G loss: 0.638815]\n",
      "epoch:7 step:7352 [D loss: 0.560747, acc.: 69.53%] [G loss: 0.617262]\n",
      "epoch:7 step:7353 [D loss: 0.559603, acc.: 67.97%] [G loss: 0.578473]\n",
      "epoch:7 step:7354 [D loss: 0.565964, acc.: 65.62%] [G loss: 0.703672]\n",
      "epoch:7 step:7355 [D loss: 0.462170, acc.: 80.47%] [G loss: 0.687467]\n",
      "epoch:7 step:7356 [D loss: 0.567800, acc.: 64.84%] [G loss: 0.563535]\n",
      "epoch:7 step:7357 [D loss: 0.485509, acc.: 71.09%] [G loss: 0.627285]\n",
      "epoch:7 step:7358 [D loss: 0.619724, acc.: 67.97%] [G loss: 0.523340]\n",
      "epoch:7 step:7359 [D loss: 0.559277, acc.: 68.75%] [G loss: 0.553423]\n",
      "epoch:7 step:7360 [D loss: 0.528951, acc.: 71.09%] [G loss: 0.590872]\n",
      "epoch:7 step:7361 [D loss: 0.502451, acc.: 71.88%] [G loss: 0.656469]\n",
      "epoch:7 step:7362 [D loss: 0.545848, acc.: 71.88%] [G loss: 0.683110]\n",
      "epoch:7 step:7363 [D loss: 0.549103, acc.: 75.00%] [G loss: 0.419180]\n",
      "epoch:7 step:7364 [D loss: 0.550712, acc.: 66.41%] [G loss: 0.519524]\n",
      "epoch:7 step:7365 [D loss: 0.543612, acc.: 69.53%] [G loss: 0.456364]\n",
      "epoch:7 step:7366 [D loss: 0.506063, acc.: 78.91%] [G loss: 0.570450]\n",
      "epoch:7 step:7367 [D loss: 0.557521, acc.: 70.31%] [G loss: 0.562679]\n",
      "epoch:7 step:7368 [D loss: 0.556289, acc.: 70.31%] [G loss: 0.586724]\n",
      "epoch:7 step:7369 [D loss: 0.523519, acc.: 71.09%] [G loss: 0.603844]\n",
      "epoch:7 step:7370 [D loss: 0.519483, acc.: 75.78%] [G loss: 0.472639]\n",
      "epoch:7 step:7371 [D loss: 0.622073, acc.: 66.41%] [G loss: 0.413315]\n",
      "epoch:7 step:7372 [D loss: 0.548021, acc.: 73.44%] [G loss: 0.491458]\n",
      "epoch:7 step:7373 [D loss: 0.507667, acc.: 74.22%] [G loss: 0.639597]\n",
      "epoch:7 step:7374 [D loss: 0.531484, acc.: 73.44%] [G loss: 0.672160]\n",
      "epoch:7 step:7375 [D loss: 0.548246, acc.: 71.88%] [G loss: 0.616329]\n",
      "epoch:7 step:7376 [D loss: 0.629469, acc.: 66.41%] [G loss: 0.515673]\n",
      "epoch:7 step:7377 [D loss: 0.565132, acc.: 69.53%] [G loss: 0.561684]\n",
      "epoch:7 step:7378 [D loss: 0.519732, acc.: 71.88%] [G loss: 0.584302]\n",
      "epoch:7 step:7379 [D loss: 0.615042, acc.: 64.84%] [G loss: 0.496305]\n",
      "epoch:7 step:7380 [D loss: 0.502711, acc.: 73.44%] [G loss: 0.586558]\n",
      "epoch:7 step:7381 [D loss: 0.564208, acc.: 66.41%] [G loss: 0.575021]\n",
      "epoch:7 step:7382 [D loss: 0.461992, acc.: 78.12%] [G loss: 0.517878]\n",
      "epoch:7 step:7383 [D loss: 0.578705, acc.: 67.19%] [G loss: 0.524004]\n",
      "epoch:7 step:7384 [D loss: 0.557740, acc.: 69.53%] [G loss: 0.559650]\n",
      "epoch:7 step:7385 [D loss: 0.542664, acc.: 74.22%] [G loss: 0.538655]\n",
      "epoch:7 step:7386 [D loss: 0.539359, acc.: 68.75%] [G loss: 0.637840]\n",
      "epoch:7 step:7387 [D loss: 0.600302, acc.: 66.41%] [G loss: 0.442998]\n",
      "epoch:7 step:7388 [D loss: 0.531969, acc.: 70.31%] [G loss: 0.555727]\n",
      "epoch:7 step:7389 [D loss: 0.577212, acc.: 71.09%] [G loss: 0.639883]\n",
      "epoch:7 step:7390 [D loss: 0.588246, acc.: 68.75%] [G loss: 0.529221]\n",
      "epoch:7 step:7391 [D loss: 0.580251, acc.: 68.75%] [G loss: 0.482692]\n",
      "epoch:7 step:7392 [D loss: 0.479549, acc.: 78.12%] [G loss: 0.642794]\n",
      "epoch:7 step:7393 [D loss: 0.543023, acc.: 71.09%] [G loss: 0.543249]\n",
      "epoch:7 step:7394 [D loss: 0.548082, acc.: 75.00%] [G loss: 0.552526]\n",
      "epoch:7 step:7395 [D loss: 0.538358, acc.: 74.22%] [G loss: 0.475495]\n",
      "epoch:7 step:7396 [D loss: 0.533898, acc.: 71.88%] [G loss: 0.482441]\n",
      "epoch:7 step:7397 [D loss: 0.556618, acc.: 67.97%] [G loss: 0.521665]\n",
      "epoch:7 step:7398 [D loss: 0.594238, acc.: 64.06%] [G loss: 0.505927]\n",
      "epoch:7 step:7399 [D loss: 0.574790, acc.: 68.75%] [G loss: 0.499428]\n",
      "epoch:7 step:7400 [D loss: 0.555670, acc.: 67.97%] [G loss: 0.374978]\n",
      "##############\n",
      "[3.17865056 1.37489688 6.52006075 4.99876861 3.88597254 5.62028702\n",
      " 4.86108474 4.83101634 4.82710699 3.65979357]\n",
      "##########\n",
      "epoch:7 step:7401 [D loss: 0.520596, acc.: 71.09%] [G loss: 0.524370]\n",
      "epoch:7 step:7402 [D loss: 0.494572, acc.: 78.12%] [G loss: 0.661430]\n",
      "epoch:7 step:7403 [D loss: 0.538243, acc.: 71.88%] [G loss: 0.614374]\n",
      "epoch:7 step:7404 [D loss: 0.620056, acc.: 67.19%] [G loss: 0.464777]\n",
      "epoch:7 step:7405 [D loss: 0.518504, acc.: 71.88%] [G loss: 0.537685]\n",
      "epoch:7 step:7406 [D loss: 0.584262, acc.: 67.97%] [G loss: 0.423940]\n",
      "epoch:7 step:7407 [D loss: 0.577250, acc.: 65.62%] [G loss: 0.476767]\n",
      "epoch:7 step:7408 [D loss: 0.595504, acc.: 64.84%] [G loss: 0.304847]\n",
      "epoch:7 step:7409 [D loss: 0.553940, acc.: 67.19%] [G loss: 0.488863]\n",
      "epoch:7 step:7410 [D loss: 0.599693, acc.: 65.62%] [G loss: 0.436249]\n",
      "epoch:7 step:7411 [D loss: 0.483491, acc.: 78.12%] [G loss: 0.509047]\n",
      "epoch:7 step:7412 [D loss: 0.510195, acc.: 70.31%] [G loss: 0.630382]\n",
      "epoch:7 step:7413 [D loss: 0.489690, acc.: 77.34%] [G loss: 0.541939]\n",
      "epoch:7 step:7414 [D loss: 0.548553, acc.: 65.62%] [G loss: 0.625942]\n",
      "epoch:7 step:7415 [D loss: 0.585671, acc.: 67.97%] [G loss: 0.584346]\n",
      "epoch:7 step:7416 [D loss: 0.494375, acc.: 77.34%] [G loss: 0.638948]\n",
      "epoch:7 step:7417 [D loss: 0.697259, acc.: 56.25%] [G loss: 0.609962]\n",
      "epoch:7 step:7418 [D loss: 0.546756, acc.: 73.44%] [G loss: 0.590965]\n",
      "epoch:7 step:7419 [D loss: 0.506217, acc.: 72.66%] [G loss: 0.680153]\n",
      "epoch:7 step:7420 [D loss: 0.632001, acc.: 64.84%] [G loss: 0.579305]\n",
      "epoch:7 step:7421 [D loss: 0.542945, acc.: 69.53%] [G loss: 0.640891]\n",
      "epoch:7 step:7422 [D loss: 0.585359, acc.: 63.28%] [G loss: 0.454516]\n",
      "epoch:7 step:7423 [D loss: 0.572499, acc.: 69.53%] [G loss: 0.428657]\n",
      "epoch:7 step:7424 [D loss: 0.572435, acc.: 70.31%] [G loss: 0.466917]\n",
      "epoch:7 step:7425 [D loss: 0.545110, acc.: 71.88%] [G loss: 0.464009]\n",
      "epoch:7 step:7426 [D loss: 0.699783, acc.: 55.47%] [G loss: 0.409227]\n",
      "epoch:7 step:7427 [D loss: 0.571566, acc.: 67.97%] [G loss: 0.464417]\n",
      "epoch:7 step:7428 [D loss: 0.557773, acc.: 67.97%] [G loss: 0.502838]\n",
      "epoch:7 step:7429 [D loss: 0.481587, acc.: 78.12%] [G loss: 0.641414]\n",
      "epoch:7 step:7430 [D loss: 0.496535, acc.: 73.44%] [G loss: 0.581456]\n",
      "epoch:7 step:7431 [D loss: 0.558502, acc.: 67.97%] [G loss: 0.586659]\n",
      "epoch:7 step:7432 [D loss: 0.662714, acc.: 61.72%] [G loss: 0.490641]\n",
      "epoch:7 step:7433 [D loss: 0.526033, acc.: 75.78%] [G loss: 0.465689]\n",
      "epoch:7 step:7434 [D loss: 0.500643, acc.: 74.22%] [G loss: 0.518142]\n",
      "epoch:7 step:7435 [D loss: 0.565874, acc.: 70.31%] [G loss: 0.581958]\n",
      "epoch:7 step:7436 [D loss: 0.609745, acc.: 66.41%] [G loss: 0.536329]\n",
      "epoch:7 step:7437 [D loss: 0.536894, acc.: 73.44%] [G loss: 0.626587]\n",
      "epoch:7 step:7438 [D loss: 0.545985, acc.: 70.31%] [G loss: 0.429638]\n",
      "epoch:7 step:7439 [D loss: 0.657263, acc.: 62.50%] [G loss: 0.379152]\n",
      "epoch:7 step:7440 [D loss: 0.536813, acc.: 70.31%] [G loss: 0.442356]\n",
      "epoch:7 step:7441 [D loss: 0.543224, acc.: 74.22%] [G loss: 0.430300]\n",
      "epoch:7 step:7442 [D loss: 0.564088, acc.: 69.53%] [G loss: 0.405181]\n",
      "epoch:7 step:7443 [D loss: 0.499490, acc.: 78.91%] [G loss: 0.695850]\n",
      "epoch:7 step:7444 [D loss: 0.544363, acc.: 70.31%] [G loss: 0.556050]\n",
      "epoch:7 step:7445 [D loss: 0.493668, acc.: 74.22%] [G loss: 0.801656]\n",
      "epoch:7 step:7446 [D loss: 0.580914, acc.: 70.31%] [G loss: 0.677835]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:7 step:7447 [D loss: 0.503362, acc.: 72.66%] [G loss: 0.795015]\n",
      "epoch:7 step:7448 [D loss: 0.583969, acc.: 68.75%] [G loss: 0.641462]\n",
      "epoch:7 step:7449 [D loss: 0.502304, acc.: 76.56%] [G loss: 0.665409]\n",
      "epoch:7 step:7450 [D loss: 0.648154, acc.: 64.06%] [G loss: 0.721638]\n",
      "epoch:7 step:7451 [D loss: 0.627242, acc.: 63.28%] [G loss: 0.460396]\n",
      "epoch:7 step:7452 [D loss: 0.538968, acc.: 71.09%] [G loss: 0.688877]\n",
      "epoch:7 step:7453 [D loss: 0.508154, acc.: 75.00%] [G loss: 0.524309]\n",
      "epoch:7 step:7454 [D loss: 0.519073, acc.: 73.44%] [G loss: 0.641355]\n",
      "epoch:7 step:7455 [D loss: 0.522820, acc.: 75.00%] [G loss: 0.641230]\n",
      "epoch:7 step:7456 [D loss: 0.528090, acc.: 74.22%] [G loss: 0.587250]\n",
      "epoch:7 step:7457 [D loss: 0.483531, acc.: 78.91%] [G loss: 0.610547]\n",
      "epoch:7 step:7458 [D loss: 0.511011, acc.: 76.56%] [G loss: 0.682741]\n",
      "epoch:7 step:7459 [D loss: 0.546996, acc.: 75.78%] [G loss: 0.565655]\n",
      "epoch:7 step:7460 [D loss: 0.530804, acc.: 71.09%] [G loss: 0.631287]\n",
      "epoch:7 step:7461 [D loss: 0.554070, acc.: 67.97%] [G loss: 0.519261]\n",
      "epoch:7 step:7462 [D loss: 0.543360, acc.: 71.09%] [G loss: 0.471289]\n",
      "epoch:7 step:7463 [D loss: 0.562436, acc.: 70.31%] [G loss: 0.512149]\n",
      "epoch:7 step:7464 [D loss: 0.600529, acc.: 67.97%] [G loss: 0.488183]\n",
      "epoch:7 step:7465 [D loss: 0.503134, acc.: 73.44%] [G loss: 0.652253]\n",
      "epoch:7 step:7466 [D loss: 0.542910, acc.: 71.88%] [G loss: 0.647720]\n",
      "epoch:7 step:7467 [D loss: 0.582120, acc.: 67.97%] [G loss: 0.565774]\n",
      "epoch:7 step:7468 [D loss: 0.510394, acc.: 76.56%] [G loss: 0.635526]\n",
      "epoch:7 step:7469 [D loss: 0.523057, acc.: 70.31%] [G loss: 0.549665]\n",
      "epoch:7 step:7470 [D loss: 0.482093, acc.: 82.03%] [G loss: 0.699560]\n",
      "epoch:7 step:7471 [D loss: 0.457497, acc.: 78.12%] [G loss: 0.681361]\n",
      "epoch:7 step:7472 [D loss: 0.552409, acc.: 67.97%] [G loss: 0.670900]\n",
      "epoch:7 step:7473 [D loss: 0.549664, acc.: 70.31%] [G loss: 0.571571]\n",
      "epoch:7 step:7474 [D loss: 0.574108, acc.: 62.50%] [G loss: 0.628934]\n",
      "epoch:7 step:7475 [D loss: 0.504445, acc.: 78.12%] [G loss: 0.643812]\n",
      "epoch:7 step:7476 [D loss: 0.609081, acc.: 64.06%] [G loss: 0.517439]\n",
      "epoch:7 step:7477 [D loss: 0.568554, acc.: 65.62%] [G loss: 0.704565]\n",
      "epoch:7 step:7478 [D loss: 0.525141, acc.: 73.44%] [G loss: 0.736932]\n",
      "epoch:7 step:7479 [D loss: 0.706180, acc.: 55.47%] [G loss: 0.613930]\n",
      "epoch:7 step:7480 [D loss: 0.508151, acc.: 67.97%] [G loss: 0.599777]\n",
      "epoch:7 step:7481 [D loss: 0.574989, acc.: 67.19%] [G loss: 0.485650]\n",
      "epoch:7 step:7482 [D loss: 0.492483, acc.: 75.00%] [G loss: 0.743097]\n",
      "epoch:7 step:7483 [D loss: 0.443907, acc.: 81.25%] [G loss: 0.862449]\n",
      "epoch:7 step:7484 [D loss: 0.425920, acc.: 79.69%] [G loss: 0.885524]\n",
      "epoch:7 step:7485 [D loss: 0.427784, acc.: 82.81%] [G loss: 1.106674]\n",
      "epoch:7 step:7486 [D loss: 0.501677, acc.: 73.44%] [G loss: 0.976825]\n",
      "epoch:7 step:7487 [D loss: 0.778218, acc.: 60.94%] [G loss: 0.899890]\n",
      "epoch:7 step:7488 [D loss: 0.401626, acc.: 85.94%] [G loss: 1.540811]\n",
      "epoch:7 step:7489 [D loss: 0.448000, acc.: 78.12%] [G loss: 1.170032]\n",
      "epoch:7 step:7490 [D loss: 0.624359, acc.: 61.72%] [G loss: 0.708235]\n",
      "epoch:7 step:7491 [D loss: 0.725067, acc.: 60.16%] [G loss: 0.618777]\n",
      "epoch:7 step:7492 [D loss: 0.502861, acc.: 75.00%] [G loss: 0.845936]\n",
      "epoch:7 step:7493 [D loss: 0.518574, acc.: 72.66%] [G loss: 0.830824]\n",
      "epoch:7 step:7494 [D loss: 0.520466, acc.: 71.88%] [G loss: 0.829189]\n",
      "epoch:7 step:7495 [D loss: 0.389972, acc.: 82.81%] [G loss: 1.228324]\n",
      "epoch:7 step:7496 [D loss: 0.411332, acc.: 82.03%] [G loss: 1.228851]\n",
      "epoch:8 step:7497 [D loss: 0.628971, acc.: 67.19%] [G loss: 0.890974]\n",
      "epoch:8 step:7498 [D loss: 0.486537, acc.: 75.78%] [G loss: 0.822199]\n",
      "epoch:8 step:7499 [D loss: 0.586963, acc.: 67.19%] [G loss: 0.667226]\n",
      "epoch:8 step:7500 [D loss: 0.490758, acc.: 75.00%] [G loss: 0.628543]\n",
      "epoch:8 step:7501 [D loss: 0.589332, acc.: 68.75%] [G loss: 0.543359]\n",
      "epoch:8 step:7502 [D loss: 0.555338, acc.: 67.19%] [G loss: 0.656867]\n",
      "epoch:8 step:7503 [D loss: 0.481904, acc.: 78.12%] [G loss: 0.582120]\n",
      "epoch:8 step:7504 [D loss: 0.554133, acc.: 71.09%] [G loss: 0.753720]\n",
      "epoch:8 step:7505 [D loss: 0.539945, acc.: 73.44%] [G loss: 0.736783]\n",
      "epoch:8 step:7506 [D loss: 0.516750, acc.: 75.00%] [G loss: 0.673791]\n",
      "epoch:8 step:7507 [D loss: 0.514545, acc.: 75.00%] [G loss: 0.677972]\n",
      "epoch:8 step:7508 [D loss: 0.569790, acc.: 70.31%] [G loss: 0.546750]\n",
      "epoch:8 step:7509 [D loss: 0.591036, acc.: 67.19%] [G loss: 0.467549]\n",
      "epoch:8 step:7510 [D loss: 0.511281, acc.: 78.12%] [G loss: 0.459913]\n",
      "epoch:8 step:7511 [D loss: 0.517551, acc.: 80.47%] [G loss: 0.533545]\n",
      "epoch:8 step:7512 [D loss: 0.537986, acc.: 73.44%] [G loss: 0.547556]\n",
      "epoch:8 step:7513 [D loss: 0.546724, acc.: 75.78%] [G loss: 0.555365]\n",
      "epoch:8 step:7514 [D loss: 0.579733, acc.: 66.41%] [G loss: 0.607937]\n",
      "epoch:8 step:7515 [D loss: 0.563504, acc.: 67.97%] [G loss: 0.491138]\n",
      "epoch:8 step:7516 [D loss: 0.667244, acc.: 59.38%] [G loss: 0.439056]\n",
      "epoch:8 step:7517 [D loss: 0.538644, acc.: 71.09%] [G loss: 0.541287]\n",
      "epoch:8 step:7518 [D loss: 0.505645, acc.: 75.00%] [G loss: 0.650272]\n",
      "epoch:8 step:7519 [D loss: 0.552226, acc.: 70.31%] [G loss: 0.511336]\n",
      "epoch:8 step:7520 [D loss: 0.543562, acc.: 74.22%] [G loss: 0.523376]\n",
      "epoch:8 step:7521 [D loss: 0.501985, acc.: 78.91%] [G loss: 0.669991]\n",
      "epoch:8 step:7522 [D loss: 0.579150, acc.: 65.62%] [G loss: 0.466261]\n",
      "epoch:8 step:7523 [D loss: 0.493612, acc.: 72.66%] [G loss: 0.549523]\n",
      "epoch:8 step:7524 [D loss: 0.532658, acc.: 73.44%] [G loss: 0.547659]\n",
      "epoch:8 step:7525 [D loss: 0.505280, acc.: 78.12%] [G loss: 0.477980]\n",
      "epoch:8 step:7526 [D loss: 0.587370, acc.: 69.53%] [G loss: 0.427757]\n",
      "epoch:8 step:7527 [D loss: 0.536785, acc.: 71.88%] [G loss: 0.637755]\n",
      "epoch:8 step:7528 [D loss: 0.564727, acc.: 70.31%] [G loss: 0.606752]\n",
      "epoch:8 step:7529 [D loss: 0.557819, acc.: 69.53%] [G loss: 0.657183]\n",
      "epoch:8 step:7530 [D loss: 0.486597, acc.: 73.44%] [G loss: 0.597443]\n",
      "epoch:8 step:7531 [D loss: 0.577868, acc.: 66.41%] [G loss: 0.653290]\n",
      "epoch:8 step:7532 [D loss: 0.522970, acc.: 73.44%] [G loss: 0.611277]\n",
      "epoch:8 step:7533 [D loss: 0.523358, acc.: 75.00%] [G loss: 0.601622]\n",
      "epoch:8 step:7534 [D loss: 0.610153, acc.: 66.41%] [G loss: 0.506292]\n",
      "epoch:8 step:7535 [D loss: 0.534847, acc.: 73.44%] [G loss: 0.476808]\n",
      "epoch:8 step:7536 [D loss: 0.458214, acc.: 77.34%] [G loss: 0.717868]\n",
      "epoch:8 step:7537 [D loss: 0.559637, acc.: 71.09%] [G loss: 0.624266]\n",
      "epoch:8 step:7538 [D loss: 0.573109, acc.: 68.75%] [G loss: 0.625606]\n",
      "epoch:8 step:7539 [D loss: 0.492708, acc.: 78.12%] [G loss: 0.625580]\n",
      "epoch:8 step:7540 [D loss: 0.565482, acc.: 67.97%] [G loss: 0.551221]\n",
      "epoch:8 step:7541 [D loss: 0.494807, acc.: 75.00%] [G loss: 0.591178]\n",
      "epoch:8 step:7542 [D loss: 0.526452, acc.: 71.88%] [G loss: 0.530712]\n",
      "epoch:8 step:7543 [D loss: 0.589824, acc.: 71.09%] [G loss: 0.554230]\n",
      "epoch:8 step:7544 [D loss: 0.549006, acc.: 73.44%] [G loss: 0.585872]\n",
      "epoch:8 step:7545 [D loss: 0.531946, acc.: 74.22%] [G loss: 0.599791]\n",
      "epoch:8 step:7546 [D loss: 0.559587, acc.: 74.22%] [G loss: 0.499823]\n",
      "epoch:8 step:7547 [D loss: 0.598804, acc.: 67.97%] [G loss: 0.398919]\n",
      "epoch:8 step:7548 [D loss: 0.587803, acc.: 72.66%] [G loss: 0.524418]\n",
      "epoch:8 step:7549 [D loss: 0.562741, acc.: 72.66%] [G loss: 0.714074]\n",
      "epoch:8 step:7550 [D loss: 0.432438, acc.: 81.25%] [G loss: 0.638572]\n",
      "epoch:8 step:7551 [D loss: 0.557267, acc.: 74.22%] [G loss: 0.575939]\n",
      "epoch:8 step:7552 [D loss: 0.497766, acc.: 77.34%] [G loss: 0.609217]\n",
      "epoch:8 step:7553 [D loss: 0.524210, acc.: 70.31%] [G loss: 0.537466]\n",
      "epoch:8 step:7554 [D loss: 0.576703, acc.: 71.09%] [G loss: 0.617217]\n",
      "epoch:8 step:7555 [D loss: 0.510019, acc.: 72.66%] [G loss: 0.683423]\n",
      "epoch:8 step:7556 [D loss: 0.558355, acc.: 70.31%] [G loss: 0.515559]\n",
      "epoch:8 step:7557 [D loss: 0.556970, acc.: 67.19%] [G loss: 0.602717]\n",
      "epoch:8 step:7558 [D loss: 0.556734, acc.: 70.31%] [G loss: 0.548094]\n",
      "epoch:8 step:7559 [D loss: 0.563274, acc.: 66.41%] [G loss: 0.528075]\n",
      "epoch:8 step:7560 [D loss: 0.605318, acc.: 67.19%] [G loss: 0.402380]\n",
      "epoch:8 step:7561 [D loss: 0.526607, acc.: 70.31%] [G loss: 0.586962]\n",
      "epoch:8 step:7562 [D loss: 0.479440, acc.: 79.69%] [G loss: 0.593795]\n",
      "epoch:8 step:7563 [D loss: 0.528409, acc.: 74.22%] [G loss: 0.532125]\n",
      "epoch:8 step:7564 [D loss: 0.520666, acc.: 70.31%] [G loss: 0.556674]\n",
      "epoch:8 step:7565 [D loss: 0.496177, acc.: 75.00%] [G loss: 0.657150]\n",
      "epoch:8 step:7566 [D loss: 0.470694, acc.: 78.91%] [G loss: 0.693998]\n",
      "epoch:8 step:7567 [D loss: 0.550946, acc.: 65.62%] [G loss: 0.491324]\n",
      "epoch:8 step:7568 [D loss: 0.516555, acc.: 71.09%] [G loss: 0.622492]\n",
      "epoch:8 step:7569 [D loss: 0.559384, acc.: 65.62%] [G loss: 0.549746]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:8 step:7570 [D loss: 0.479487, acc.: 76.56%] [G loss: 0.681690]\n",
      "epoch:8 step:7571 [D loss: 0.575740, acc.: 67.97%] [G loss: 0.737447]\n",
      "epoch:8 step:7572 [D loss: 0.502184, acc.: 72.66%] [G loss: 0.665999]\n",
      "epoch:8 step:7573 [D loss: 0.524325, acc.: 76.56%] [G loss: 0.845375]\n",
      "epoch:8 step:7574 [D loss: 0.617862, acc.: 64.06%] [G loss: 0.708465]\n",
      "epoch:8 step:7575 [D loss: 0.567798, acc.: 62.50%] [G loss: 0.487100]\n",
      "epoch:8 step:7576 [D loss: 0.551799, acc.: 75.00%] [G loss: 0.590048]\n",
      "epoch:8 step:7577 [D loss: 0.590487, acc.: 65.62%] [G loss: 0.646003]\n",
      "epoch:8 step:7578 [D loss: 0.483324, acc.: 71.09%] [G loss: 0.650267]\n",
      "epoch:8 step:7579 [D loss: 0.504668, acc.: 75.78%] [G loss: 0.588830]\n",
      "epoch:8 step:7580 [D loss: 0.573176, acc.: 68.75%] [G loss: 0.429531]\n",
      "epoch:8 step:7581 [D loss: 0.590810, acc.: 67.97%] [G loss: 0.503031]\n",
      "epoch:8 step:7582 [D loss: 0.565378, acc.: 67.19%] [G loss: 0.469440]\n",
      "epoch:8 step:7583 [D loss: 0.521234, acc.: 75.78%] [G loss: 0.508757]\n",
      "epoch:8 step:7584 [D loss: 0.485649, acc.: 79.69%] [G loss: 0.475737]\n",
      "epoch:8 step:7585 [D loss: 0.527412, acc.: 73.44%] [G loss: 0.555840]\n",
      "epoch:8 step:7586 [D loss: 0.498786, acc.: 74.22%] [G loss: 0.743206]\n",
      "epoch:8 step:7587 [D loss: 0.574685, acc.: 67.97%] [G loss: 0.581258]\n",
      "epoch:8 step:7588 [D loss: 0.474859, acc.: 78.12%] [G loss: 0.546216]\n",
      "epoch:8 step:7589 [D loss: 0.504875, acc.: 78.12%] [G loss: 0.468032]\n",
      "epoch:8 step:7590 [D loss: 0.519895, acc.: 74.22%] [G loss: 0.658673]\n",
      "epoch:8 step:7591 [D loss: 0.537457, acc.: 71.09%] [G loss: 0.530837]\n",
      "epoch:8 step:7592 [D loss: 0.500218, acc.: 77.34%] [G loss: 0.571639]\n",
      "epoch:8 step:7593 [D loss: 0.592680, acc.: 64.06%] [G loss: 0.622972]\n",
      "epoch:8 step:7594 [D loss: 0.581363, acc.: 66.41%] [G loss: 0.657296]\n",
      "epoch:8 step:7595 [D loss: 0.543434, acc.: 75.00%] [G loss: 0.787198]\n",
      "epoch:8 step:7596 [D loss: 0.470999, acc.: 77.34%] [G loss: 0.729633]\n",
      "epoch:8 step:7597 [D loss: 0.517800, acc.: 72.66%] [G loss: 0.632424]\n",
      "epoch:8 step:7598 [D loss: 0.536905, acc.: 71.88%] [G loss: 0.612990]\n",
      "epoch:8 step:7599 [D loss: 0.494890, acc.: 75.00%] [G loss: 0.507095]\n",
      "epoch:8 step:7600 [D loss: 0.533546, acc.: 67.97%] [G loss: 0.586633]\n",
      "##############\n",
      "[3.16444996 1.60138313 6.35121564 4.84231578 3.89521337 5.89814234\n",
      " 4.62088866 4.81393956 4.81458846 3.77498977]\n",
      "##########\n",
      "epoch:8 step:7601 [D loss: 0.581407, acc.: 67.19%] [G loss: 0.527453]\n",
      "epoch:8 step:7602 [D loss: 0.587214, acc.: 69.53%] [G loss: 0.559880]\n",
      "epoch:8 step:7603 [D loss: 0.585023, acc.: 69.53%] [G loss: 0.562275]\n",
      "epoch:8 step:7604 [D loss: 0.633642, acc.: 61.72%] [G loss: 0.535110]\n",
      "epoch:8 step:7605 [D loss: 0.589980, acc.: 65.62%] [G loss: 0.490843]\n",
      "epoch:8 step:7606 [D loss: 0.582501, acc.: 70.31%] [G loss: 0.504036]\n",
      "epoch:8 step:7607 [D loss: 0.509523, acc.: 80.47%] [G loss: 0.588714]\n",
      "epoch:8 step:7608 [D loss: 0.524790, acc.: 75.78%] [G loss: 0.605023]\n",
      "epoch:8 step:7609 [D loss: 0.616061, acc.: 63.28%] [G loss: 0.538345]\n",
      "epoch:8 step:7610 [D loss: 0.549363, acc.: 71.88%] [G loss: 0.554309]\n",
      "epoch:8 step:7611 [D loss: 0.551613, acc.: 69.53%] [G loss: 0.567628]\n",
      "epoch:8 step:7612 [D loss: 0.539549, acc.: 71.09%] [G loss: 0.547728]\n",
      "epoch:8 step:7613 [D loss: 0.566558, acc.: 69.53%] [G loss: 0.566285]\n",
      "epoch:8 step:7614 [D loss: 0.610976, acc.: 63.28%] [G loss: 0.731334]\n",
      "epoch:8 step:7615 [D loss: 0.501274, acc.: 78.91%] [G loss: 0.758756]\n",
      "epoch:8 step:7616 [D loss: 0.570546, acc.: 69.53%] [G loss: 0.681754]\n",
      "epoch:8 step:7617 [D loss: 0.534576, acc.: 73.44%] [G loss: 0.636555]\n",
      "epoch:8 step:7618 [D loss: 0.497974, acc.: 80.47%] [G loss: 0.706547]\n",
      "epoch:8 step:7619 [D loss: 0.528271, acc.: 72.66%] [G loss: 0.795588]\n",
      "epoch:8 step:7620 [D loss: 0.603669, acc.: 66.41%] [G loss: 0.699375]\n",
      "epoch:8 step:7621 [D loss: 0.584910, acc.: 65.62%] [G loss: 0.552081]\n",
      "epoch:8 step:7622 [D loss: 0.507771, acc.: 73.44%] [G loss: 0.501607]\n",
      "epoch:8 step:7623 [D loss: 0.537799, acc.: 71.88%] [G loss: 0.578275]\n",
      "epoch:8 step:7624 [D loss: 0.492496, acc.: 74.22%] [G loss: 0.508489]\n",
      "epoch:8 step:7625 [D loss: 0.591059, acc.: 61.72%] [G loss: 0.507486]\n",
      "epoch:8 step:7626 [D loss: 0.504645, acc.: 80.47%] [G loss: 0.660160]\n",
      "epoch:8 step:7627 [D loss: 0.464408, acc.: 78.91%] [G loss: 0.682064]\n",
      "epoch:8 step:7628 [D loss: 0.537083, acc.: 71.09%] [G loss: 0.528836]\n",
      "epoch:8 step:7629 [D loss: 0.500021, acc.: 74.22%] [G loss: 0.564761]\n",
      "epoch:8 step:7630 [D loss: 0.548404, acc.: 71.09%] [G loss: 0.580547]\n",
      "epoch:8 step:7631 [D loss: 0.524435, acc.: 72.66%] [G loss: 0.685782]\n",
      "epoch:8 step:7632 [D loss: 0.530351, acc.: 75.00%] [G loss: 0.664524]\n",
      "epoch:8 step:7633 [D loss: 0.664260, acc.: 62.50%] [G loss: 0.487936]\n",
      "epoch:8 step:7634 [D loss: 0.586662, acc.: 70.31%] [G loss: 0.502607]\n",
      "epoch:8 step:7635 [D loss: 0.557747, acc.: 64.84%] [G loss: 0.524070]\n",
      "epoch:8 step:7636 [D loss: 0.585144, acc.: 67.97%] [G loss: 0.526046]\n",
      "epoch:8 step:7637 [D loss: 0.523014, acc.: 67.97%] [G loss: 0.564369]\n",
      "epoch:8 step:7638 [D loss: 0.529496, acc.: 71.09%] [G loss: 0.632614]\n",
      "epoch:8 step:7639 [D loss: 0.631194, acc.: 61.72%] [G loss: 0.487852]\n",
      "epoch:8 step:7640 [D loss: 0.505449, acc.: 78.12%] [G loss: 0.508415]\n",
      "epoch:8 step:7641 [D loss: 0.532867, acc.: 70.31%] [G loss: 0.533796]\n",
      "epoch:8 step:7642 [D loss: 0.487097, acc.: 73.44%] [G loss: 0.576632]\n",
      "epoch:8 step:7643 [D loss: 0.641441, acc.: 64.06%] [G loss: 0.489778]\n",
      "epoch:8 step:7644 [D loss: 0.572474, acc.: 65.62%] [G loss: 0.530396]\n",
      "epoch:8 step:7645 [D loss: 0.511161, acc.: 73.44%] [G loss: 0.563953]\n",
      "epoch:8 step:7646 [D loss: 0.625356, acc.: 70.31%] [G loss: 0.528659]\n",
      "epoch:8 step:7647 [D loss: 0.560066, acc.: 73.44%] [G loss: 0.500903]\n",
      "epoch:8 step:7648 [D loss: 0.471640, acc.: 78.12%] [G loss: 0.596722]\n",
      "epoch:8 step:7649 [D loss: 0.553405, acc.: 69.53%] [G loss: 0.641043]\n",
      "epoch:8 step:7650 [D loss: 0.599081, acc.: 64.84%] [G loss: 0.567137]\n",
      "epoch:8 step:7651 [D loss: 0.422668, acc.: 83.59%] [G loss: 0.561597]\n",
      "epoch:8 step:7652 [D loss: 0.514721, acc.: 71.09%] [G loss: 0.657296]\n",
      "epoch:8 step:7653 [D loss: 0.529213, acc.: 71.09%] [G loss: 0.555166]\n",
      "epoch:8 step:7654 [D loss: 0.615872, acc.: 67.97%] [G loss: 0.409427]\n",
      "epoch:8 step:7655 [D loss: 0.520368, acc.: 68.75%] [G loss: 0.557721]\n",
      "epoch:8 step:7656 [D loss: 0.635968, acc.: 67.19%] [G loss: 0.673727]\n",
      "epoch:8 step:7657 [D loss: 0.484310, acc.: 73.44%] [G loss: 0.631184]\n",
      "epoch:8 step:7658 [D loss: 0.499024, acc.: 76.56%] [G loss: 0.767304]\n",
      "epoch:8 step:7659 [D loss: 0.562496, acc.: 72.66%] [G loss: 0.671712]\n",
      "epoch:8 step:7660 [D loss: 0.560465, acc.: 68.75%] [G loss: 0.617648]\n",
      "epoch:8 step:7661 [D loss: 0.511883, acc.: 75.00%] [G loss: 0.721704]\n",
      "epoch:8 step:7662 [D loss: 0.581047, acc.: 68.75%] [G loss: 0.533910]\n",
      "epoch:8 step:7663 [D loss: 0.534317, acc.: 71.88%] [G loss: 0.487483]\n",
      "epoch:8 step:7664 [D loss: 0.553571, acc.: 70.31%] [G loss: 0.499958]\n",
      "epoch:8 step:7665 [D loss: 0.627480, acc.: 62.50%] [G loss: 0.469959]\n",
      "epoch:8 step:7666 [D loss: 0.579923, acc.: 66.41%] [G loss: 0.477835]\n",
      "epoch:8 step:7667 [D loss: 0.561817, acc.: 71.09%] [G loss: 0.554119]\n",
      "epoch:8 step:7668 [D loss: 0.518961, acc.: 70.31%] [G loss: 0.775026]\n",
      "epoch:8 step:7669 [D loss: 0.498414, acc.: 77.34%] [G loss: 0.500038]\n",
      "epoch:8 step:7670 [D loss: 0.597926, acc.: 64.84%] [G loss: 0.595678]\n",
      "epoch:8 step:7671 [D loss: 0.590368, acc.: 62.50%] [G loss: 0.514891]\n",
      "epoch:8 step:7672 [D loss: 0.564044, acc.: 67.97%] [G loss: 0.558039]\n",
      "epoch:8 step:7673 [D loss: 0.513983, acc.: 72.66%] [G loss: 0.594197]\n",
      "epoch:8 step:7674 [D loss: 0.587028, acc.: 70.31%] [G loss: 0.479403]\n",
      "epoch:8 step:7675 [D loss: 0.508987, acc.: 75.78%] [G loss: 0.677735]\n",
      "epoch:8 step:7676 [D loss: 0.663302, acc.: 60.16%] [G loss: 0.604619]\n",
      "epoch:8 step:7677 [D loss: 0.564240, acc.: 67.97%] [G loss: 0.566486]\n",
      "epoch:8 step:7678 [D loss: 0.537756, acc.: 78.91%] [G loss: 0.692529]\n",
      "epoch:8 step:7679 [D loss: 0.566849, acc.: 69.53%] [G loss: 0.698434]\n",
      "epoch:8 step:7680 [D loss: 0.583723, acc.: 66.41%] [G loss: 0.553448]\n",
      "epoch:8 step:7681 [D loss: 0.614904, acc.: 61.72%] [G loss: 0.592497]\n",
      "epoch:8 step:7682 [D loss: 0.583947, acc.: 64.84%] [G loss: 0.590388]\n",
      "epoch:8 step:7683 [D loss: 0.612997, acc.: 62.50%] [G loss: 0.438260]\n",
      "epoch:8 step:7684 [D loss: 0.526385, acc.: 73.44%] [G loss: 0.533762]\n",
      "epoch:8 step:7685 [D loss: 0.551122, acc.: 67.19%] [G loss: 0.499754]\n",
      "epoch:8 step:7686 [D loss: 0.515994, acc.: 74.22%] [G loss: 0.584637]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:8 step:7687 [D loss: 0.497374, acc.: 71.88%] [G loss: 0.644587]\n",
      "epoch:8 step:7688 [D loss: 0.531147, acc.: 73.44%] [G loss: 0.625743]\n",
      "epoch:8 step:7689 [D loss: 0.577036, acc.: 69.53%] [G loss: 0.653456]\n",
      "epoch:8 step:7690 [D loss: 0.463088, acc.: 75.78%] [G loss: 0.660497]\n",
      "epoch:8 step:7691 [D loss: 0.597869, acc.: 64.84%] [G loss: 0.610105]\n",
      "epoch:8 step:7692 [D loss: 0.594919, acc.: 66.41%] [G loss: 0.646972]\n",
      "epoch:8 step:7693 [D loss: 0.552729, acc.: 74.22%] [G loss: 0.689857]\n",
      "epoch:8 step:7694 [D loss: 0.494696, acc.: 72.66%] [G loss: 0.651333]\n",
      "epoch:8 step:7695 [D loss: 0.541576, acc.: 67.97%] [G loss: 0.710698]\n",
      "epoch:8 step:7696 [D loss: 0.645127, acc.: 62.50%] [G loss: 0.444865]\n",
      "epoch:8 step:7697 [D loss: 0.581728, acc.: 67.97%] [G loss: 0.573492]\n",
      "epoch:8 step:7698 [D loss: 0.526862, acc.: 75.78%] [G loss: 0.594678]\n",
      "epoch:8 step:7699 [D loss: 0.600229, acc.: 67.97%] [G loss: 0.449686]\n",
      "epoch:8 step:7700 [D loss: 0.609092, acc.: 68.75%] [G loss: 0.496054]\n",
      "epoch:8 step:7701 [D loss: 0.483164, acc.: 75.00%] [G loss: 0.578908]\n",
      "epoch:8 step:7702 [D loss: 0.514360, acc.: 72.66%] [G loss: 0.693496]\n",
      "epoch:8 step:7703 [D loss: 0.446424, acc.: 78.91%] [G loss: 0.633021]\n",
      "epoch:8 step:7704 [D loss: 0.438375, acc.: 80.47%] [G loss: 0.777359]\n",
      "epoch:8 step:7705 [D loss: 0.486946, acc.: 76.56%] [G loss: 0.677403]\n",
      "epoch:8 step:7706 [D loss: 0.645858, acc.: 60.94%] [G loss: 0.522194]\n",
      "epoch:8 step:7707 [D loss: 0.531563, acc.: 74.22%] [G loss: 0.579282]\n",
      "epoch:8 step:7708 [D loss: 0.544842, acc.: 70.31%] [G loss: 0.516302]\n",
      "epoch:8 step:7709 [D loss: 0.534328, acc.: 69.53%] [G loss: 0.506861]\n",
      "epoch:8 step:7710 [D loss: 0.605370, acc.: 67.19%] [G loss: 0.418762]\n",
      "epoch:8 step:7711 [D loss: 0.569695, acc.: 65.62%] [G loss: 0.428515]\n",
      "epoch:8 step:7712 [D loss: 0.584964, acc.: 68.75%] [G loss: 0.588064]\n",
      "epoch:8 step:7713 [D loss: 0.528401, acc.: 74.22%] [G loss: 0.727557]\n",
      "epoch:8 step:7714 [D loss: 0.528897, acc.: 72.66%] [G loss: 0.573387]\n",
      "epoch:8 step:7715 [D loss: 0.510497, acc.: 75.78%] [G loss: 0.605325]\n",
      "epoch:8 step:7716 [D loss: 0.626200, acc.: 64.06%] [G loss: 0.519469]\n",
      "epoch:8 step:7717 [D loss: 0.518234, acc.: 69.53%] [G loss: 0.527237]\n",
      "epoch:8 step:7718 [D loss: 0.494438, acc.: 76.56%] [G loss: 0.773300]\n",
      "epoch:8 step:7719 [D loss: 0.481359, acc.: 75.00%] [G loss: 0.656296]\n",
      "epoch:8 step:7720 [D loss: 0.573227, acc.: 70.31%] [G loss: 0.576077]\n",
      "epoch:8 step:7721 [D loss: 0.591847, acc.: 65.62%] [G loss: 0.562598]\n",
      "epoch:8 step:7722 [D loss: 0.619160, acc.: 60.16%] [G loss: 0.474611]\n",
      "epoch:8 step:7723 [D loss: 0.565505, acc.: 73.44%] [G loss: 0.509120]\n",
      "epoch:8 step:7724 [D loss: 0.589435, acc.: 66.41%] [G loss: 0.439069]\n",
      "epoch:8 step:7725 [D loss: 0.581628, acc.: 72.66%] [G loss: 0.527658]\n",
      "epoch:8 step:7726 [D loss: 0.540663, acc.: 71.09%] [G loss: 0.585040]\n",
      "epoch:8 step:7727 [D loss: 0.504755, acc.: 71.09%] [G loss: 0.741921]\n",
      "epoch:8 step:7728 [D loss: 0.435604, acc.: 82.81%] [G loss: 0.745655]\n",
      "epoch:8 step:7729 [D loss: 0.545870, acc.: 71.88%] [G loss: 0.647061]\n",
      "epoch:8 step:7730 [D loss: 0.579691, acc.: 66.41%] [G loss: 0.581005]\n",
      "epoch:8 step:7731 [D loss: 0.582399, acc.: 66.41%] [G loss: 0.709436]\n",
      "epoch:8 step:7732 [D loss: 0.558307, acc.: 67.97%] [G loss: 0.550412]\n",
      "epoch:8 step:7733 [D loss: 0.552193, acc.: 67.97%] [G loss: 0.555212]\n",
      "epoch:8 step:7734 [D loss: 0.597382, acc.: 67.97%] [G loss: 0.425501]\n",
      "epoch:8 step:7735 [D loss: 0.517322, acc.: 71.09%] [G loss: 0.480184]\n",
      "epoch:8 step:7736 [D loss: 0.492858, acc.: 75.78%] [G loss: 0.488516]\n",
      "epoch:8 step:7737 [D loss: 0.570811, acc.: 71.88%] [G loss: 0.606463]\n",
      "epoch:8 step:7738 [D loss: 0.526665, acc.: 71.88%] [G loss: 0.676216]\n",
      "epoch:8 step:7739 [D loss: 0.572508, acc.: 67.19%] [G loss: 0.466604]\n",
      "epoch:8 step:7740 [D loss: 0.485232, acc.: 77.34%] [G loss: 0.694229]\n",
      "epoch:8 step:7741 [D loss: 0.544084, acc.: 68.75%] [G loss: 0.608255]\n",
      "epoch:8 step:7742 [D loss: 0.584590, acc.: 68.75%] [G loss: 0.633806]\n",
      "epoch:8 step:7743 [D loss: 0.581006, acc.: 66.41%] [G loss: 0.641078]\n",
      "epoch:8 step:7744 [D loss: 0.538029, acc.: 70.31%] [G loss: 0.624689]\n",
      "epoch:8 step:7745 [D loss: 0.532725, acc.: 72.66%] [G loss: 0.673481]\n",
      "epoch:8 step:7746 [D loss: 0.663949, acc.: 60.16%] [G loss: 0.575455]\n",
      "epoch:8 step:7747 [D loss: 0.642014, acc.: 59.38%] [G loss: 0.517148]\n",
      "epoch:8 step:7748 [D loss: 0.609325, acc.: 64.84%] [G loss: 0.428072]\n",
      "epoch:8 step:7749 [D loss: 0.553808, acc.: 76.56%] [G loss: 0.478915]\n",
      "epoch:8 step:7750 [D loss: 0.485225, acc.: 75.78%] [G loss: 0.598508]\n",
      "epoch:8 step:7751 [D loss: 0.519045, acc.: 75.00%] [G loss: 0.600901]\n",
      "epoch:8 step:7752 [D loss: 0.541433, acc.: 70.31%] [G loss: 0.784232]\n",
      "epoch:8 step:7753 [D loss: 0.601229, acc.: 64.84%] [G loss: 0.547266]\n",
      "epoch:8 step:7754 [D loss: 0.533697, acc.: 68.75%] [G loss: 0.498414]\n",
      "epoch:8 step:7755 [D loss: 0.584543, acc.: 67.19%] [G loss: 0.498044]\n",
      "epoch:8 step:7756 [D loss: 0.559378, acc.: 69.53%] [G loss: 0.556442]\n",
      "epoch:8 step:7757 [D loss: 0.550277, acc.: 71.88%] [G loss: 0.417794]\n",
      "epoch:8 step:7758 [D loss: 0.493291, acc.: 77.34%] [G loss: 0.579214]\n",
      "epoch:8 step:7759 [D loss: 0.577082, acc.: 66.41%] [G loss: 0.562299]\n",
      "epoch:8 step:7760 [D loss: 0.520990, acc.: 72.66%] [G loss: 0.590586]\n",
      "epoch:8 step:7761 [D loss: 0.637761, acc.: 67.19%] [G loss: 0.495629]\n",
      "epoch:8 step:7762 [D loss: 0.539489, acc.: 73.44%] [G loss: 0.512375]\n",
      "epoch:8 step:7763 [D loss: 0.511165, acc.: 70.31%] [G loss: 0.432323]\n",
      "epoch:8 step:7764 [D loss: 0.611555, acc.: 63.28%] [G loss: 0.398727]\n",
      "epoch:8 step:7765 [D loss: 0.563989, acc.: 71.09%] [G loss: 0.701005]\n",
      "epoch:8 step:7766 [D loss: 0.531300, acc.: 73.44%] [G loss: 0.657900]\n",
      "epoch:8 step:7767 [D loss: 0.526308, acc.: 71.88%] [G loss: 0.606809]\n",
      "epoch:8 step:7768 [D loss: 0.547373, acc.: 70.31%] [G loss: 0.623155]\n",
      "epoch:8 step:7769 [D loss: 0.548173, acc.: 72.66%] [G loss: 0.520650]\n",
      "epoch:8 step:7770 [D loss: 0.523936, acc.: 72.66%] [G loss: 0.537366]\n",
      "epoch:8 step:7771 [D loss: 0.589413, acc.: 65.62%] [G loss: 0.427126]\n",
      "epoch:8 step:7772 [D loss: 0.527071, acc.: 71.88%] [G loss: 0.484333]\n",
      "epoch:8 step:7773 [D loss: 0.675293, acc.: 61.72%] [G loss: 0.364626]\n",
      "epoch:8 step:7774 [D loss: 0.606706, acc.: 61.72%] [G loss: 0.366038]\n",
      "epoch:8 step:7775 [D loss: 0.565301, acc.: 69.53%] [G loss: 0.471998]\n",
      "epoch:8 step:7776 [D loss: 0.518076, acc.: 78.12%] [G loss: 0.630338]\n",
      "epoch:8 step:7777 [D loss: 0.544261, acc.: 71.88%] [G loss: 0.425031]\n",
      "epoch:8 step:7778 [D loss: 0.565016, acc.: 71.09%] [G loss: 0.395880]\n",
      "epoch:8 step:7779 [D loss: 0.475172, acc.: 80.47%] [G loss: 0.598732]\n",
      "epoch:8 step:7780 [D loss: 0.526672, acc.: 71.09%] [G loss: 0.599182]\n",
      "epoch:8 step:7781 [D loss: 0.481616, acc.: 77.34%] [G loss: 0.641514]\n",
      "epoch:8 step:7782 [D loss: 0.492114, acc.: 76.56%] [G loss: 0.654154]\n",
      "epoch:8 step:7783 [D loss: 0.567956, acc.: 68.75%] [G loss: 0.626000]\n",
      "epoch:8 step:7784 [D loss: 0.584020, acc.: 67.19%] [G loss: 0.640680]\n",
      "epoch:8 step:7785 [D loss: 0.538954, acc.: 72.66%] [G loss: 0.577416]\n",
      "epoch:8 step:7786 [D loss: 0.546739, acc.: 69.53%] [G loss: 0.641248]\n",
      "epoch:8 step:7787 [D loss: 0.578876, acc.: 69.53%] [G loss: 0.504857]\n",
      "epoch:8 step:7788 [D loss: 0.533565, acc.: 71.09%] [G loss: 0.505839]\n",
      "epoch:8 step:7789 [D loss: 0.631001, acc.: 61.72%] [G loss: 0.510464]\n",
      "epoch:8 step:7790 [D loss: 0.573879, acc.: 70.31%] [G loss: 0.459656]\n",
      "epoch:8 step:7791 [D loss: 0.559512, acc.: 67.19%] [G loss: 0.488273]\n",
      "epoch:8 step:7792 [D loss: 0.483891, acc.: 79.69%] [G loss: 0.567841]\n",
      "epoch:8 step:7793 [D loss: 0.549098, acc.: 74.22%] [G loss: 0.432298]\n",
      "epoch:8 step:7794 [D loss: 0.490943, acc.: 76.56%] [G loss: 0.521167]\n",
      "epoch:8 step:7795 [D loss: 0.536033, acc.: 75.78%] [G loss: 0.575866]\n",
      "epoch:8 step:7796 [D loss: 0.535233, acc.: 69.53%] [G loss: 0.584393]\n",
      "epoch:8 step:7797 [D loss: 0.618982, acc.: 70.31%] [G loss: 0.514087]\n",
      "epoch:8 step:7798 [D loss: 0.564359, acc.: 71.09%] [G loss: 0.477175]\n",
      "epoch:8 step:7799 [D loss: 0.605008, acc.: 67.19%] [G loss: 0.586070]\n",
      "epoch:8 step:7800 [D loss: 0.494734, acc.: 78.12%] [G loss: 0.663844]\n",
      "##############\n",
      "[3.30251624 1.14012634 6.69578793 4.8868584  3.98253617 5.70606093\n",
      " 4.83420145 4.98464351 4.71026603 3.97533691]\n",
      "##########\n",
      "epoch:8 step:7801 [D loss: 0.527928, acc.: 71.88%] [G loss: 0.623815]\n",
      "epoch:8 step:7802 [D loss: 0.599963, acc.: 65.62%] [G loss: 0.619581]\n",
      "epoch:8 step:7803 [D loss: 0.492096, acc.: 75.78%] [G loss: 0.731509]\n",
      "epoch:8 step:7804 [D loss: 0.617770, acc.: 62.50%] [G loss: 0.441789]\n",
      "epoch:8 step:7805 [D loss: 0.491937, acc.: 69.53%] [G loss: 0.736267]\n",
      "epoch:8 step:7806 [D loss: 0.505310, acc.: 75.78%] [G loss: 0.646354]\n",
      "epoch:8 step:7807 [D loss: 0.485074, acc.: 74.22%] [G loss: 0.723801]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:8 step:7808 [D loss: 0.474815, acc.: 78.12%] [G loss: 0.816465]\n",
      "epoch:8 step:7809 [D loss: 0.499374, acc.: 76.56%] [G loss: 0.762496]\n",
      "epoch:8 step:7810 [D loss: 0.467949, acc.: 75.78%] [G loss: 0.875302]\n",
      "epoch:8 step:7811 [D loss: 0.501738, acc.: 75.78%] [G loss: 0.876153]\n",
      "epoch:8 step:7812 [D loss: 0.722262, acc.: 63.28%] [G loss: 0.571910]\n",
      "epoch:8 step:7813 [D loss: 0.570637, acc.: 68.75%] [G loss: 0.589249]\n",
      "epoch:8 step:7814 [D loss: 0.537044, acc.: 73.44%] [G loss: 0.510850]\n",
      "epoch:8 step:7815 [D loss: 0.554159, acc.: 72.66%] [G loss: 0.552251]\n",
      "epoch:8 step:7816 [D loss: 0.543156, acc.: 71.88%] [G loss: 0.546715]\n",
      "epoch:8 step:7817 [D loss: 0.473676, acc.: 78.12%] [G loss: 0.605805]\n",
      "epoch:8 step:7818 [D loss: 0.561548, acc.: 68.75%] [G loss: 0.563309]\n",
      "epoch:8 step:7819 [D loss: 0.581806, acc.: 68.75%] [G loss: 0.557020]\n",
      "epoch:8 step:7820 [D loss: 0.578410, acc.: 69.53%] [G loss: 0.477300]\n",
      "epoch:8 step:7821 [D loss: 0.563016, acc.: 69.53%] [G loss: 0.445914]\n",
      "epoch:8 step:7822 [D loss: 0.512061, acc.: 76.56%] [G loss: 0.675716]\n",
      "epoch:8 step:7823 [D loss: 0.528907, acc.: 71.88%] [G loss: 0.568770]\n",
      "epoch:8 step:7824 [D loss: 0.486730, acc.: 72.66%] [G loss: 0.714595]\n",
      "epoch:8 step:7825 [D loss: 0.504925, acc.: 73.44%] [G loss: 0.712552]\n",
      "epoch:8 step:7826 [D loss: 0.601991, acc.: 64.84%] [G loss: 0.458929]\n",
      "epoch:8 step:7827 [D loss: 0.540501, acc.: 71.09%] [G loss: 0.511875]\n",
      "epoch:8 step:7828 [D loss: 0.519615, acc.: 74.22%] [G loss: 0.523991]\n",
      "epoch:8 step:7829 [D loss: 0.485617, acc.: 75.00%] [G loss: 0.562161]\n",
      "epoch:8 step:7830 [D loss: 0.531346, acc.: 69.53%] [G loss: 0.848118]\n",
      "epoch:8 step:7831 [D loss: 0.487990, acc.: 75.00%] [G loss: 0.680856]\n",
      "epoch:8 step:7832 [D loss: 0.499107, acc.: 74.22%] [G loss: 0.800039]\n",
      "epoch:8 step:7833 [D loss: 0.534632, acc.: 71.88%] [G loss: 0.656963]\n",
      "epoch:8 step:7834 [D loss: 0.554981, acc.: 67.97%] [G loss: 0.642641]\n",
      "epoch:8 step:7835 [D loss: 0.559070, acc.: 71.09%] [G loss: 0.676219]\n",
      "epoch:8 step:7836 [D loss: 0.511430, acc.: 72.66%] [G loss: 0.643193]\n",
      "epoch:8 step:7837 [D loss: 0.671521, acc.: 64.06%] [G loss: 0.450840]\n",
      "epoch:8 step:7838 [D loss: 0.633792, acc.: 62.50%] [G loss: 0.505363]\n",
      "epoch:8 step:7839 [D loss: 0.552922, acc.: 71.09%] [G loss: 0.549388]\n",
      "epoch:8 step:7840 [D loss: 0.490601, acc.: 79.69%] [G loss: 0.653193]\n",
      "epoch:8 step:7841 [D loss: 0.555065, acc.: 71.09%] [G loss: 0.709403]\n",
      "epoch:8 step:7842 [D loss: 0.501864, acc.: 77.34%] [G loss: 0.687476]\n",
      "epoch:8 step:7843 [D loss: 0.503500, acc.: 75.78%] [G loss: 0.891262]\n",
      "epoch:8 step:7844 [D loss: 0.604198, acc.: 65.62%] [G loss: 0.670659]\n",
      "epoch:8 step:7845 [D loss: 0.686153, acc.: 62.50%] [G loss: 0.443484]\n",
      "epoch:8 step:7846 [D loss: 0.456964, acc.: 81.25%] [G loss: 0.659286]\n",
      "epoch:8 step:7847 [D loss: 0.511582, acc.: 75.00%] [G loss: 0.565722]\n",
      "epoch:8 step:7848 [D loss: 0.575095, acc.: 67.19%] [G loss: 0.598470]\n",
      "epoch:8 step:7849 [D loss: 0.596316, acc.: 66.41%] [G loss: 0.579239]\n",
      "epoch:8 step:7850 [D loss: 0.463021, acc.: 78.91%] [G loss: 0.699525]\n",
      "epoch:8 step:7851 [D loss: 0.599308, acc.: 67.97%] [G loss: 0.703406]\n",
      "epoch:8 step:7852 [D loss: 0.567176, acc.: 65.62%] [G loss: 0.451479]\n",
      "epoch:8 step:7853 [D loss: 0.465059, acc.: 78.91%] [G loss: 0.549045]\n",
      "epoch:8 step:7854 [D loss: 0.404177, acc.: 82.03%] [G loss: 0.790045]\n",
      "epoch:8 step:7855 [D loss: 0.446187, acc.: 79.69%] [G loss: 0.684025]\n",
      "epoch:8 step:7856 [D loss: 0.474953, acc.: 78.12%] [G loss: 0.709647]\n",
      "epoch:8 step:7857 [D loss: 0.517424, acc.: 73.44%] [G loss: 0.752208]\n",
      "epoch:8 step:7858 [D loss: 0.584216, acc.: 67.19%] [G loss: 0.547242]\n",
      "epoch:8 step:7859 [D loss: 0.527370, acc.: 71.88%] [G loss: 0.658874]\n",
      "epoch:8 step:7860 [D loss: 0.552315, acc.: 72.66%] [G loss: 0.555674]\n",
      "epoch:8 step:7861 [D loss: 0.557456, acc.: 70.31%] [G loss: 0.477255]\n",
      "epoch:8 step:7862 [D loss: 0.530461, acc.: 71.09%] [G loss: 0.739708]\n",
      "epoch:8 step:7863 [D loss: 0.646856, acc.: 63.28%] [G loss: 0.570064]\n",
      "epoch:8 step:7864 [D loss: 0.556950, acc.: 72.66%] [G loss: 0.553445]\n",
      "epoch:8 step:7865 [D loss: 0.548008, acc.: 73.44%] [G loss: 0.463961]\n",
      "epoch:8 step:7866 [D loss: 0.586543, acc.: 69.53%] [G loss: 0.487512]\n",
      "epoch:8 step:7867 [D loss: 0.521667, acc.: 75.00%] [G loss: 0.622373]\n",
      "epoch:8 step:7868 [D loss: 0.553703, acc.: 68.75%] [G loss: 0.604389]\n",
      "epoch:8 step:7869 [D loss: 0.556423, acc.: 70.31%] [G loss: 0.512583]\n",
      "epoch:8 step:7870 [D loss: 0.477421, acc.: 75.78%] [G loss: 0.713601]\n",
      "epoch:8 step:7871 [D loss: 0.596017, acc.: 71.09%] [G loss: 0.656140]\n",
      "epoch:8 step:7872 [D loss: 0.690426, acc.: 59.38%] [G loss: 0.499500]\n",
      "epoch:8 step:7873 [D loss: 0.583808, acc.: 67.97%] [G loss: 0.409478]\n",
      "epoch:8 step:7874 [D loss: 0.582727, acc.: 68.75%] [G loss: 0.584290]\n",
      "epoch:8 step:7875 [D loss: 0.633939, acc.: 67.97%] [G loss: 0.482413]\n",
      "epoch:8 step:7876 [D loss: 0.597514, acc.: 66.41%] [G loss: 0.429410]\n",
      "epoch:8 step:7877 [D loss: 0.450150, acc.: 78.91%] [G loss: 0.553765]\n",
      "epoch:8 step:7878 [D loss: 0.547464, acc.: 75.00%] [G loss: 0.528572]\n",
      "epoch:8 step:7879 [D loss: 0.527541, acc.: 73.44%] [G loss: 0.591867]\n",
      "epoch:8 step:7880 [D loss: 0.560565, acc.: 70.31%] [G loss: 0.582337]\n",
      "epoch:8 step:7881 [D loss: 0.461335, acc.: 76.56%] [G loss: 0.582753]\n",
      "epoch:8 step:7882 [D loss: 0.631110, acc.: 60.94%] [G loss: 0.515138]\n",
      "epoch:8 step:7883 [D loss: 0.562126, acc.: 64.84%] [G loss: 0.497416]\n",
      "epoch:8 step:7884 [D loss: 0.590749, acc.: 67.97%] [G loss: 0.496671]\n",
      "epoch:8 step:7885 [D loss: 0.538882, acc.: 72.66%] [G loss: 0.517010]\n",
      "epoch:8 step:7886 [D loss: 0.662813, acc.: 59.38%] [G loss: 0.476095]\n",
      "epoch:8 step:7887 [D loss: 0.541904, acc.: 68.75%] [G loss: 0.448541]\n",
      "epoch:8 step:7888 [D loss: 0.468976, acc.: 79.69%] [G loss: 0.659594]\n",
      "epoch:8 step:7889 [D loss: 0.614549, acc.: 60.94%] [G loss: 0.600139]\n",
      "epoch:8 step:7890 [D loss: 0.572466, acc.: 67.19%] [G loss: 0.513879]\n",
      "epoch:8 step:7891 [D loss: 0.513771, acc.: 73.44%] [G loss: 0.491589]\n",
      "epoch:8 step:7892 [D loss: 0.620844, acc.: 60.94%] [G loss: 0.528757]\n",
      "epoch:8 step:7893 [D loss: 0.573619, acc.: 69.53%] [G loss: 0.580085]\n",
      "epoch:8 step:7894 [D loss: 0.552840, acc.: 69.53%] [G loss: 0.759975]\n",
      "epoch:8 step:7895 [D loss: 0.507870, acc.: 77.34%] [G loss: 0.644835]\n",
      "epoch:8 step:7896 [D loss: 0.659560, acc.: 58.59%] [G loss: 0.725497]\n",
      "epoch:8 step:7897 [D loss: 0.667190, acc.: 57.81%] [G loss: 0.395224]\n",
      "epoch:8 step:7898 [D loss: 0.493724, acc.: 76.56%] [G loss: 0.479718]\n",
      "epoch:8 step:7899 [D loss: 0.498484, acc.: 75.00%] [G loss: 0.567204]\n",
      "epoch:8 step:7900 [D loss: 0.631713, acc.: 60.16%] [G loss: 0.465777]\n",
      "epoch:8 step:7901 [D loss: 0.559243, acc.: 69.53%] [G loss: 0.599270]\n",
      "epoch:8 step:7902 [D loss: 0.511562, acc.: 73.44%] [G loss: 0.613934]\n",
      "epoch:8 step:7903 [D loss: 0.571963, acc.: 71.88%] [G loss: 0.596331]\n",
      "epoch:8 step:7904 [D loss: 0.620037, acc.: 64.06%] [G loss: 0.430640]\n",
      "epoch:8 step:7905 [D loss: 0.553052, acc.: 70.31%] [G loss: 0.519777]\n",
      "epoch:8 step:7906 [D loss: 0.539926, acc.: 72.66%] [G loss: 0.514271]\n",
      "epoch:8 step:7907 [D loss: 0.657007, acc.: 56.25%] [G loss: 0.435291]\n",
      "epoch:8 step:7908 [D loss: 0.577239, acc.: 66.41%] [G loss: 0.475215]\n",
      "epoch:8 step:7909 [D loss: 0.576857, acc.: 68.75%] [G loss: 0.477568]\n",
      "epoch:8 step:7910 [D loss: 0.546925, acc.: 69.53%] [G loss: 0.522336]\n",
      "epoch:8 step:7911 [D loss: 0.552336, acc.: 72.66%] [G loss: 0.541345]\n",
      "epoch:8 step:7912 [D loss: 0.542913, acc.: 67.19%] [G loss: 0.525539]\n",
      "epoch:8 step:7913 [D loss: 0.633328, acc.: 64.84%] [G loss: 0.393627]\n",
      "epoch:8 step:7914 [D loss: 0.622528, acc.: 61.72%] [G loss: 0.540789]\n",
      "epoch:8 step:7915 [D loss: 0.583015, acc.: 61.72%] [G loss: 0.409233]\n",
      "epoch:8 step:7916 [D loss: 0.540354, acc.: 73.44%] [G loss: 0.631820]\n",
      "epoch:8 step:7917 [D loss: 0.656286, acc.: 61.72%] [G loss: 0.535335]\n",
      "epoch:8 step:7918 [D loss: 0.593586, acc.: 69.53%] [G loss: 0.450603]\n",
      "epoch:8 step:7919 [D loss: 0.570382, acc.: 71.09%] [G loss: 0.487279]\n",
      "epoch:8 step:7920 [D loss: 0.547915, acc.: 70.31%] [G loss: 0.542303]\n",
      "epoch:8 step:7921 [D loss: 0.560626, acc.: 64.84%] [G loss: 0.636184]\n",
      "epoch:8 step:7922 [D loss: 0.479679, acc.: 76.56%] [G loss: 0.558768]\n",
      "epoch:8 step:7923 [D loss: 0.538553, acc.: 71.88%] [G loss: 0.633835]\n",
      "epoch:8 step:7924 [D loss: 0.520010, acc.: 72.66%] [G loss: 0.717508]\n",
      "epoch:8 step:7925 [D loss: 0.475266, acc.: 78.91%] [G loss: 0.644456]\n",
      "epoch:8 step:7926 [D loss: 0.481554, acc.: 78.91%] [G loss: 0.683489]\n",
      "epoch:8 step:7927 [D loss: 0.530944, acc.: 68.75%] [G loss: 0.589013]\n",
      "epoch:8 step:7928 [D loss: 0.545793, acc.: 67.97%] [G loss: 0.620885]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:8 step:7929 [D loss: 0.644379, acc.: 60.16%] [G loss: 0.548255]\n",
      "epoch:8 step:7930 [D loss: 0.511085, acc.: 77.34%] [G loss: 0.656043]\n",
      "epoch:8 step:7931 [D loss: 0.529691, acc.: 75.00%] [G loss: 0.641926]\n",
      "epoch:8 step:7932 [D loss: 0.481295, acc.: 77.34%] [G loss: 0.671479]\n",
      "epoch:8 step:7933 [D loss: 0.668560, acc.: 58.59%] [G loss: 0.430627]\n",
      "epoch:8 step:7934 [D loss: 0.576105, acc.: 64.06%] [G loss: 0.501093]\n",
      "epoch:8 step:7935 [D loss: 0.514329, acc.: 74.22%] [G loss: 0.504202]\n",
      "epoch:8 step:7936 [D loss: 0.474364, acc.: 80.47%] [G loss: 0.582229]\n",
      "epoch:8 step:7937 [D loss: 0.607867, acc.: 64.06%] [G loss: 0.581493]\n",
      "epoch:8 step:7938 [D loss: 0.550147, acc.: 68.75%] [G loss: 0.582623]\n",
      "epoch:8 step:7939 [D loss: 0.495898, acc.: 78.12%] [G loss: 0.535651]\n",
      "epoch:8 step:7940 [D loss: 0.528709, acc.: 69.53%] [G loss: 0.471624]\n",
      "epoch:8 step:7941 [D loss: 0.555552, acc.: 67.19%] [G loss: 0.558839]\n",
      "epoch:8 step:7942 [D loss: 0.548963, acc.: 66.41%] [G loss: 0.603538]\n",
      "epoch:8 step:7943 [D loss: 0.504618, acc.: 72.66%] [G loss: 0.601440]\n",
      "epoch:8 step:7944 [D loss: 0.510753, acc.: 78.12%] [G loss: 0.494487]\n",
      "epoch:8 step:7945 [D loss: 0.564711, acc.: 69.53%] [G loss: 0.695777]\n",
      "epoch:8 step:7946 [D loss: 0.509414, acc.: 75.00%] [G loss: 0.668060]\n",
      "epoch:8 step:7947 [D loss: 0.462910, acc.: 80.47%] [G loss: 0.980312]\n",
      "epoch:8 step:7948 [D loss: 0.520549, acc.: 74.22%] [G loss: 0.825433]\n",
      "epoch:8 step:7949 [D loss: 0.495546, acc.: 72.66%] [G loss: 0.821630]\n",
      "epoch:8 step:7950 [D loss: 0.593340, acc.: 70.31%] [G loss: 0.537360]\n",
      "epoch:8 step:7951 [D loss: 0.545584, acc.: 72.66%] [G loss: 0.632200]\n",
      "epoch:8 step:7952 [D loss: 0.631755, acc.: 60.94%] [G loss: 0.471795]\n",
      "epoch:8 step:7953 [D loss: 0.534046, acc.: 70.31%] [G loss: 0.584828]\n",
      "epoch:8 step:7954 [D loss: 0.582302, acc.: 67.97%] [G loss: 0.573726]\n",
      "epoch:8 step:7955 [D loss: 0.531379, acc.: 77.34%] [G loss: 0.515916]\n",
      "epoch:8 step:7956 [D loss: 0.538474, acc.: 68.75%] [G loss: 0.647588]\n",
      "epoch:8 step:7957 [D loss: 0.535716, acc.: 73.44%] [G loss: 0.517118]\n",
      "epoch:8 step:7958 [D loss: 0.564184, acc.: 65.62%] [G loss: 0.600329]\n",
      "epoch:8 step:7959 [D loss: 0.526371, acc.: 73.44%] [G loss: 0.450169]\n",
      "epoch:8 step:7960 [D loss: 0.527882, acc.: 74.22%] [G loss: 0.637527]\n",
      "epoch:8 step:7961 [D loss: 0.629353, acc.: 64.84%] [G loss: 0.476466]\n",
      "epoch:8 step:7962 [D loss: 0.550870, acc.: 72.66%] [G loss: 0.541866]\n",
      "epoch:8 step:7963 [D loss: 0.481174, acc.: 76.56%] [G loss: 0.680297]\n",
      "epoch:8 step:7964 [D loss: 0.553865, acc.: 73.44%] [G loss: 0.667629]\n",
      "epoch:8 step:7965 [D loss: 0.539293, acc.: 70.31%] [G loss: 0.711412]\n",
      "epoch:8 step:7966 [D loss: 0.513662, acc.: 75.00%] [G loss: 0.696999]\n",
      "epoch:8 step:7967 [D loss: 0.410822, acc.: 82.81%] [G loss: 0.786004]\n",
      "epoch:8 step:7968 [D loss: 0.450031, acc.: 81.25%] [G loss: 0.928971]\n",
      "epoch:8 step:7969 [D loss: 0.653121, acc.: 60.94%] [G loss: 0.785149]\n",
      "epoch:8 step:7970 [D loss: 0.547808, acc.: 67.97%] [G loss: 0.620294]\n",
      "epoch:8 step:7971 [D loss: 0.521717, acc.: 75.78%] [G loss: 0.546807]\n",
      "epoch:8 step:7972 [D loss: 0.568817, acc.: 71.09%] [G loss: 0.687771]\n",
      "epoch:8 step:7973 [D loss: 0.714769, acc.: 54.69%] [G loss: 0.393952]\n",
      "epoch:8 step:7974 [D loss: 0.587642, acc.: 66.41%] [G loss: 0.439896]\n",
      "epoch:8 step:7975 [D loss: 0.546701, acc.: 72.66%] [G loss: 0.524129]\n",
      "epoch:8 step:7976 [D loss: 0.663373, acc.: 68.75%] [G loss: 0.518027]\n",
      "epoch:8 step:7977 [D loss: 0.539794, acc.: 76.56%] [G loss: 0.521562]\n",
      "epoch:8 step:7978 [D loss: 0.602505, acc.: 66.41%] [G loss: 0.466095]\n",
      "epoch:8 step:7979 [D loss: 0.505372, acc.: 71.88%] [G loss: 0.504151]\n",
      "epoch:8 step:7980 [D loss: 0.526791, acc.: 75.00%] [G loss: 0.620700]\n",
      "epoch:8 step:7981 [D loss: 0.547417, acc.: 75.00%] [G loss: 0.550966]\n",
      "epoch:8 step:7982 [D loss: 0.539750, acc.: 75.00%] [G loss: 0.552598]\n",
      "epoch:8 step:7983 [D loss: 0.542666, acc.: 70.31%] [G loss: 0.462987]\n",
      "epoch:8 step:7984 [D loss: 0.533608, acc.: 71.09%] [G loss: 0.425146]\n",
      "epoch:8 step:7985 [D loss: 0.545850, acc.: 70.31%] [G loss: 0.566828]\n",
      "epoch:8 step:7986 [D loss: 0.520421, acc.: 75.00%] [G loss: 0.696585]\n",
      "epoch:8 step:7987 [D loss: 0.584328, acc.: 68.75%] [G loss: 0.655930]\n",
      "epoch:8 step:7988 [D loss: 0.603099, acc.: 62.50%] [G loss: 0.436452]\n",
      "epoch:8 step:7989 [D loss: 0.572681, acc.: 67.97%] [G loss: 0.578459]\n",
      "epoch:8 step:7990 [D loss: 0.623558, acc.: 57.81%] [G loss: 0.431219]\n",
      "epoch:8 step:7991 [D loss: 0.516915, acc.: 76.56%] [G loss: 0.457940]\n",
      "epoch:8 step:7992 [D loss: 0.548110, acc.: 74.22%] [G loss: 0.449099]\n",
      "epoch:8 step:7993 [D loss: 0.572531, acc.: 71.09%] [G loss: 0.553728]\n",
      "epoch:8 step:7994 [D loss: 0.530327, acc.: 72.66%] [G loss: 0.608054]\n",
      "epoch:8 step:7995 [D loss: 0.484974, acc.: 75.78%] [G loss: 0.724023]\n",
      "epoch:8 step:7996 [D loss: 0.578249, acc.: 65.62%] [G loss: 0.670989]\n",
      "epoch:8 step:7997 [D loss: 0.663396, acc.: 57.03%] [G loss: 0.420322]\n",
      "epoch:8 step:7998 [D loss: 0.603595, acc.: 65.62%] [G loss: 0.437716]\n",
      "epoch:8 step:7999 [D loss: 0.510570, acc.: 75.00%] [G loss: 0.506189]\n",
      "epoch:8 step:8000 [D loss: 0.444035, acc.: 78.91%] [G loss: 0.788099]\n",
      "##############\n",
      "[3.29109586 1.77295359 6.47332811 5.11775627 4.10944913 6.04061923\n",
      " 4.67713911 5.08075199 4.92971611 3.93371388]\n",
      "##########\n",
      "epoch:8 step:8001 [D loss: 0.571897, acc.: 69.53%] [G loss: 0.747961]\n",
      "epoch:8 step:8002 [D loss: 0.497625, acc.: 75.00%] [G loss: 0.621164]\n",
      "epoch:8 step:8003 [D loss: 0.519445, acc.: 74.22%] [G loss: 0.717209]\n",
      "epoch:8 step:8004 [D loss: 0.439502, acc.: 82.03%] [G loss: 0.722139]\n",
      "epoch:8 step:8005 [D loss: 0.522272, acc.: 75.00%] [G loss: 0.609090]\n",
      "epoch:8 step:8006 [D loss: 0.544341, acc.: 67.97%] [G loss: 0.588226]\n",
      "epoch:8 step:8007 [D loss: 0.643833, acc.: 63.28%] [G loss: 0.292483]\n",
      "epoch:8 step:8008 [D loss: 0.594959, acc.: 71.09%] [G loss: 0.398700]\n",
      "epoch:8 step:8009 [D loss: 0.527067, acc.: 71.88%] [G loss: 0.580732]\n",
      "epoch:8 step:8010 [D loss: 0.477715, acc.: 78.12%] [G loss: 0.590166]\n",
      "epoch:8 step:8011 [D loss: 0.523432, acc.: 71.88%] [G loss: 0.547986]\n",
      "epoch:8 step:8012 [D loss: 0.496039, acc.: 75.00%] [G loss: 0.596443]\n",
      "epoch:8 step:8013 [D loss: 0.603628, acc.: 66.41%] [G loss: 0.631602]\n",
      "epoch:8 step:8014 [D loss: 0.542142, acc.: 68.75%] [G loss: 0.679919]\n",
      "epoch:8 step:8015 [D loss: 0.504169, acc.: 77.34%] [G loss: 0.595113]\n",
      "epoch:8 step:8016 [D loss: 0.471032, acc.: 75.78%] [G loss: 0.670048]\n",
      "epoch:8 step:8017 [D loss: 0.515356, acc.: 72.66%] [G loss: 0.600915]\n",
      "epoch:8 step:8018 [D loss: 0.487570, acc.: 77.34%] [G loss: 0.616401]\n",
      "epoch:8 step:8019 [D loss: 0.502248, acc.: 75.78%] [G loss: 0.612534]\n",
      "epoch:8 step:8020 [D loss: 0.584886, acc.: 67.19%] [G loss: 0.444438]\n",
      "epoch:8 step:8021 [D loss: 0.573438, acc.: 66.41%] [G loss: 0.550728]\n",
      "epoch:8 step:8022 [D loss: 0.546739, acc.: 69.53%] [G loss: 0.494511]\n",
      "epoch:8 step:8023 [D loss: 0.591626, acc.: 68.75%] [G loss: 0.528110]\n",
      "epoch:8 step:8024 [D loss: 0.647366, acc.: 64.06%] [G loss: 0.520230]\n",
      "epoch:8 step:8025 [D loss: 0.595371, acc.: 62.50%] [G loss: 0.506658]\n",
      "epoch:8 step:8026 [D loss: 0.492395, acc.: 73.44%] [G loss: 0.578751]\n",
      "epoch:8 step:8027 [D loss: 0.554861, acc.: 71.09%] [G loss: 0.669260]\n",
      "epoch:8 step:8028 [D loss: 0.577731, acc.: 65.62%] [G loss: 0.590809]\n",
      "epoch:8 step:8029 [D loss: 0.609575, acc.: 66.41%] [G loss: 0.544160]\n",
      "epoch:8 step:8030 [D loss: 0.529215, acc.: 71.88%] [G loss: 0.582031]\n",
      "epoch:8 step:8031 [D loss: 0.580711, acc.: 68.75%] [G loss: 0.452313]\n",
      "epoch:8 step:8032 [D loss: 0.502323, acc.: 80.47%] [G loss: 0.514952]\n",
      "epoch:8 step:8033 [D loss: 0.557732, acc.: 69.53%] [G loss: 0.526512]\n",
      "epoch:8 step:8034 [D loss: 0.563491, acc.: 65.62%] [G loss: 0.389191]\n",
      "epoch:8 step:8035 [D loss: 0.550070, acc.: 71.88%] [G loss: 0.600316]\n",
      "epoch:8 step:8036 [D loss: 0.534924, acc.: 74.22%] [G loss: 0.601725]\n",
      "epoch:8 step:8037 [D loss: 0.585436, acc.: 64.06%] [G loss: 0.478756]\n",
      "epoch:8 step:8038 [D loss: 0.626335, acc.: 59.38%] [G loss: 0.411324]\n",
      "epoch:8 step:8039 [D loss: 0.611877, acc.: 70.31%] [G loss: 0.534190]\n",
      "epoch:8 step:8040 [D loss: 0.561019, acc.: 70.31%] [G loss: 0.541784]\n",
      "epoch:8 step:8041 [D loss: 0.533093, acc.: 71.88%] [G loss: 0.567631]\n",
      "epoch:8 step:8042 [D loss: 0.502589, acc.: 74.22%] [G loss: 0.609178]\n",
      "epoch:8 step:8043 [D loss: 0.501971, acc.: 75.00%] [G loss: 0.640474]\n",
      "epoch:8 step:8044 [D loss: 0.534192, acc.: 71.09%] [G loss: 0.681179]\n",
      "epoch:8 step:8045 [D loss: 0.572912, acc.: 64.84%] [G loss: 0.655106]\n",
      "epoch:8 step:8046 [D loss: 0.555878, acc.: 71.88%] [G loss: 0.491915]\n",
      "epoch:8 step:8047 [D loss: 0.564870, acc.: 70.31%] [G loss: 0.597400]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:8 step:8048 [D loss: 0.532295, acc.: 72.66%] [G loss: 0.492445]\n",
      "epoch:8 step:8049 [D loss: 0.549794, acc.: 70.31%] [G loss: 0.514578]\n",
      "epoch:8 step:8050 [D loss: 0.491328, acc.: 76.56%] [G loss: 0.573082]\n",
      "epoch:8 step:8051 [D loss: 0.486383, acc.: 76.56%] [G loss: 0.623361]\n",
      "epoch:8 step:8052 [D loss: 0.525432, acc.: 73.44%] [G loss: 0.587619]\n",
      "epoch:8 step:8053 [D loss: 0.527338, acc.: 74.22%] [G loss: 0.593962]\n",
      "epoch:8 step:8054 [D loss: 0.482274, acc.: 77.34%] [G loss: 0.583757]\n",
      "epoch:8 step:8055 [D loss: 0.572519, acc.: 64.06%] [G loss: 0.560907]\n",
      "epoch:8 step:8056 [D loss: 0.577129, acc.: 63.28%] [G loss: 0.563265]\n",
      "epoch:8 step:8057 [D loss: 0.565140, acc.: 66.41%] [G loss: 0.643124]\n",
      "epoch:8 step:8058 [D loss: 0.621330, acc.: 61.72%] [G loss: 0.568567]\n",
      "epoch:8 step:8059 [D loss: 0.586084, acc.: 66.41%] [G loss: 0.534627]\n",
      "epoch:8 step:8060 [D loss: 0.535954, acc.: 71.88%] [G loss: 0.666057]\n",
      "epoch:8 step:8061 [D loss: 0.590146, acc.: 68.75%] [G loss: 0.596105]\n",
      "epoch:8 step:8062 [D loss: 0.666064, acc.: 57.81%] [G loss: 0.462929]\n",
      "epoch:8 step:8063 [D loss: 0.542709, acc.: 71.88%] [G loss: 0.501442]\n",
      "epoch:8 step:8064 [D loss: 0.534316, acc.: 75.78%] [G loss: 0.536273]\n",
      "epoch:8 step:8065 [D loss: 0.517961, acc.: 72.66%] [G loss: 0.613783]\n",
      "epoch:8 step:8066 [D loss: 0.539348, acc.: 73.44%] [G loss: 0.553222]\n",
      "epoch:8 step:8067 [D loss: 0.565127, acc.: 70.31%] [G loss: 0.498071]\n",
      "epoch:8 step:8068 [D loss: 0.547292, acc.: 70.31%] [G loss: 0.656828]\n",
      "epoch:8 step:8069 [D loss: 0.565179, acc.: 67.19%] [G loss: 0.488916]\n",
      "epoch:8 step:8070 [D loss: 0.497725, acc.: 74.22%] [G loss: 0.727007]\n",
      "epoch:8 step:8071 [D loss: 0.513505, acc.: 75.78%] [G loss: 0.695266]\n",
      "epoch:8 step:8072 [D loss: 0.618594, acc.: 63.28%] [G loss: 0.595295]\n",
      "epoch:8 step:8073 [D loss: 0.602364, acc.: 65.62%] [G loss: 0.589541]\n",
      "epoch:8 step:8074 [D loss: 0.524155, acc.: 70.31%] [G loss: 0.637505]\n",
      "epoch:8 step:8075 [D loss: 0.593676, acc.: 65.62%] [G loss: 0.639941]\n",
      "epoch:8 step:8076 [D loss: 0.577681, acc.: 66.41%] [G loss: 0.549924]\n",
      "epoch:8 step:8077 [D loss: 0.573571, acc.: 70.31%] [G loss: 0.682132]\n",
      "epoch:8 step:8078 [D loss: 0.496125, acc.: 76.56%] [G loss: 0.837641]\n",
      "epoch:8 step:8079 [D loss: 0.604987, acc.: 66.41%] [G loss: 0.657123]\n",
      "epoch:8 step:8080 [D loss: 0.656182, acc.: 57.81%] [G loss: 0.446334]\n",
      "epoch:8 step:8081 [D loss: 0.556516, acc.: 71.88%] [G loss: 0.495722]\n",
      "epoch:8 step:8082 [D loss: 0.581513, acc.: 66.41%] [G loss: 0.560062]\n",
      "epoch:8 step:8083 [D loss: 0.571720, acc.: 66.41%] [G loss: 0.470412]\n",
      "epoch:8 step:8084 [D loss: 0.561220, acc.: 66.41%] [G loss: 0.645018]\n",
      "epoch:8 step:8085 [D loss: 0.549322, acc.: 68.75%] [G loss: 0.740421]\n",
      "epoch:8 step:8086 [D loss: 0.596156, acc.: 68.75%] [G loss: 0.509374]\n",
      "epoch:8 step:8087 [D loss: 0.624444, acc.: 60.16%] [G loss: 0.517573]\n",
      "epoch:8 step:8088 [D loss: 0.518235, acc.: 73.44%] [G loss: 0.640149]\n",
      "epoch:8 step:8089 [D loss: 0.552611, acc.: 74.22%] [G loss: 0.508945]\n",
      "epoch:8 step:8090 [D loss: 0.546573, acc.: 71.88%] [G loss: 0.469735]\n",
      "epoch:8 step:8091 [D loss: 0.571165, acc.: 69.53%] [G loss: 0.458117]\n",
      "epoch:8 step:8092 [D loss: 0.522945, acc.: 73.44%] [G loss: 0.598861]\n",
      "epoch:8 step:8093 [D loss: 0.536713, acc.: 67.19%] [G loss: 0.476858]\n",
      "epoch:8 step:8094 [D loss: 0.528023, acc.: 75.78%] [G loss: 0.623734]\n",
      "epoch:8 step:8095 [D loss: 0.548297, acc.: 72.66%] [G loss: 0.571682]\n",
      "epoch:8 step:8096 [D loss: 0.649025, acc.: 62.50%] [G loss: 0.463639]\n",
      "epoch:8 step:8097 [D loss: 0.537237, acc.: 71.09%] [G loss: 0.563856]\n",
      "epoch:8 step:8098 [D loss: 0.470727, acc.: 77.34%] [G loss: 0.653786]\n",
      "epoch:8 step:8099 [D loss: 0.476481, acc.: 78.12%] [G loss: 0.672733]\n",
      "epoch:8 step:8100 [D loss: 0.610934, acc.: 65.62%] [G loss: 0.591563]\n",
      "epoch:8 step:8101 [D loss: 0.509561, acc.: 73.44%] [G loss: 0.601553]\n",
      "epoch:8 step:8102 [D loss: 0.577763, acc.: 68.75%] [G loss: 0.482694]\n",
      "epoch:8 step:8103 [D loss: 0.556532, acc.: 64.84%] [G loss: 0.518012]\n",
      "epoch:8 step:8104 [D loss: 0.509347, acc.: 74.22%] [G loss: 0.502274]\n",
      "epoch:8 step:8105 [D loss: 0.513099, acc.: 73.44%] [G loss: 0.508533]\n",
      "epoch:8 step:8106 [D loss: 0.577322, acc.: 70.31%] [G loss: 0.496567]\n",
      "epoch:8 step:8107 [D loss: 0.516396, acc.: 70.31%] [G loss: 0.495286]\n",
      "epoch:8 step:8108 [D loss: 0.571007, acc.: 66.41%] [G loss: 0.503577]\n",
      "epoch:8 step:8109 [D loss: 0.534291, acc.: 70.31%] [G loss: 0.502231]\n",
      "epoch:8 step:8110 [D loss: 0.578719, acc.: 69.53%] [G loss: 0.567887]\n",
      "epoch:8 step:8111 [D loss: 0.607918, acc.: 63.28%] [G loss: 0.569924]\n",
      "epoch:8 step:8112 [D loss: 0.625280, acc.: 64.06%] [G loss: 0.558433]\n",
      "epoch:8 step:8113 [D loss: 0.556078, acc.: 71.09%] [G loss: 0.565830]\n",
      "epoch:8 step:8114 [D loss: 0.563398, acc.: 73.44%] [G loss: 0.596389]\n",
      "epoch:8 step:8115 [D loss: 0.512290, acc.: 72.66%] [G loss: 0.621834]\n",
      "epoch:8 step:8116 [D loss: 0.523966, acc.: 73.44%] [G loss: 0.641083]\n",
      "epoch:8 step:8117 [D loss: 0.596376, acc.: 68.75%] [G loss: 0.519701]\n",
      "epoch:8 step:8118 [D loss: 0.597218, acc.: 69.53%] [G loss: 0.406724]\n",
      "epoch:8 step:8119 [D loss: 0.489331, acc.: 78.91%] [G loss: 0.618294]\n",
      "epoch:8 step:8120 [D loss: 0.476811, acc.: 80.47%] [G loss: 0.712647]\n",
      "epoch:8 step:8121 [D loss: 0.579543, acc.: 66.41%] [G loss: 0.410238]\n",
      "epoch:8 step:8122 [D loss: 0.507892, acc.: 79.69%] [G loss: 0.534869]\n",
      "epoch:8 step:8123 [D loss: 0.564694, acc.: 69.53%] [G loss: 0.500968]\n",
      "epoch:8 step:8124 [D loss: 0.596311, acc.: 61.72%] [G loss: 0.461431]\n",
      "epoch:8 step:8125 [D loss: 0.503005, acc.: 77.34%] [G loss: 0.572007]\n",
      "epoch:8 step:8126 [D loss: 0.517952, acc.: 78.12%] [G loss: 0.615206]\n",
      "epoch:8 step:8127 [D loss: 0.488019, acc.: 81.25%] [G loss: 0.625784]\n",
      "epoch:8 step:8128 [D loss: 0.543514, acc.: 75.00%] [G loss: 0.672043]\n",
      "epoch:8 step:8129 [D loss: 0.521163, acc.: 74.22%] [G loss: 0.710620]\n",
      "epoch:8 step:8130 [D loss: 0.489943, acc.: 75.00%] [G loss: 0.713625]\n",
      "epoch:8 step:8131 [D loss: 0.480567, acc.: 75.00%] [G loss: 0.733286]\n",
      "epoch:8 step:8132 [D loss: 0.631104, acc.: 60.16%] [G loss: 0.445222]\n",
      "epoch:8 step:8133 [D loss: 0.536557, acc.: 73.44%] [G loss: 0.557847]\n",
      "epoch:8 step:8134 [D loss: 0.526123, acc.: 73.44%] [G loss: 0.445221]\n",
      "epoch:8 step:8135 [D loss: 0.482381, acc.: 76.56%] [G loss: 0.573430]\n",
      "epoch:8 step:8136 [D loss: 0.580368, acc.: 71.88%] [G loss: 0.599915]\n",
      "epoch:8 step:8137 [D loss: 0.492418, acc.: 76.56%] [G loss: 0.787386]\n",
      "epoch:8 step:8138 [D loss: 0.494161, acc.: 77.34%] [G loss: 0.958464]\n",
      "epoch:8 step:8139 [D loss: 0.533588, acc.: 67.97%] [G loss: 0.847714]\n",
      "epoch:8 step:8140 [D loss: 0.568291, acc.: 68.75%] [G loss: 0.636204]\n",
      "epoch:8 step:8141 [D loss: 0.543073, acc.: 74.22%] [G loss: 0.544916]\n",
      "epoch:8 step:8142 [D loss: 0.565021, acc.: 71.09%] [G loss: 0.505543]\n",
      "epoch:8 step:8143 [D loss: 0.465558, acc.: 82.81%] [G loss: 0.591011]\n",
      "epoch:8 step:8144 [D loss: 0.431975, acc.: 78.12%] [G loss: 0.706366]\n",
      "epoch:8 step:8145 [D loss: 0.516698, acc.: 75.78%] [G loss: 0.756188]\n",
      "epoch:8 step:8146 [D loss: 0.475213, acc.: 82.81%] [G loss: 0.636429]\n",
      "epoch:8 step:8147 [D loss: 0.543200, acc.: 72.66%] [G loss: 0.674298]\n",
      "epoch:8 step:8148 [D loss: 0.591288, acc.: 70.31%] [G loss: 0.428532]\n",
      "epoch:8 step:8149 [D loss: 0.632716, acc.: 62.50%] [G loss: 0.430981]\n",
      "epoch:8 step:8150 [D loss: 0.525677, acc.: 71.88%] [G loss: 0.439088]\n",
      "epoch:8 step:8151 [D loss: 0.547371, acc.: 70.31%] [G loss: 0.523147]\n",
      "epoch:8 step:8152 [D loss: 0.501172, acc.: 74.22%] [G loss: 0.501619]\n",
      "epoch:8 step:8153 [D loss: 0.528914, acc.: 73.44%] [G loss: 0.571634]\n",
      "epoch:8 step:8154 [D loss: 0.553820, acc.: 67.19%] [G loss: 0.610926]\n",
      "epoch:8 step:8155 [D loss: 0.524960, acc.: 70.31%] [G loss: 0.675622]\n",
      "epoch:8 step:8156 [D loss: 0.530911, acc.: 74.22%] [G loss: 0.523286]\n",
      "epoch:8 step:8157 [D loss: 0.478563, acc.: 76.56%] [G loss: 0.686157]\n",
      "epoch:8 step:8158 [D loss: 0.608935, acc.: 64.06%] [G loss: 0.506131]\n",
      "epoch:8 step:8159 [D loss: 0.526709, acc.: 71.88%] [G loss: 0.633699]\n",
      "epoch:8 step:8160 [D loss: 0.608361, acc.: 64.06%] [G loss: 0.584113]\n",
      "epoch:8 step:8161 [D loss: 0.539071, acc.: 69.53%] [G loss: 0.674490]\n",
      "epoch:8 step:8162 [D loss: 0.563668, acc.: 71.09%] [G loss: 0.594224]\n",
      "epoch:8 step:8163 [D loss: 0.568043, acc.: 67.97%] [G loss: 0.611614]\n",
      "epoch:8 step:8164 [D loss: 0.594087, acc.: 70.31%] [G loss: 0.544821]\n",
      "epoch:8 step:8165 [D loss: 0.575506, acc.: 68.75%] [G loss: 0.428934]\n",
      "epoch:8 step:8166 [D loss: 0.531314, acc.: 74.22%] [G loss: 0.560089]\n",
      "epoch:8 step:8167 [D loss: 0.549179, acc.: 68.75%] [G loss: 0.633652]\n",
      "epoch:8 step:8168 [D loss: 0.600481, acc.: 68.75%] [G loss: 0.550332]\n",
      "epoch:8 step:8169 [D loss: 0.568924, acc.: 72.66%] [G loss: 0.535219]\n",
      "epoch:8 step:8170 [D loss: 0.499550, acc.: 78.12%] [G loss: 0.568237]\n",
      "epoch:8 step:8171 [D loss: 0.609680, acc.: 62.50%] [G loss: 0.485572]\n",
      "epoch:8 step:8172 [D loss: 0.554729, acc.: 71.88%] [G loss: 0.575504]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:8 step:8173 [D loss: 0.558856, acc.: 72.66%] [G loss: 0.628000]\n",
      "epoch:8 step:8174 [D loss: 0.591655, acc.: 67.19%] [G loss: 0.453613]\n",
      "epoch:8 step:8175 [D loss: 0.496992, acc.: 75.78%] [G loss: 0.591668]\n",
      "epoch:8 step:8176 [D loss: 0.540732, acc.: 74.22%] [G loss: 0.626484]\n",
      "epoch:8 step:8177 [D loss: 0.528582, acc.: 72.66%] [G loss: 0.602463]\n",
      "epoch:8 step:8178 [D loss: 0.544533, acc.: 73.44%] [G loss: 0.568039]\n",
      "epoch:8 step:8179 [D loss: 0.558364, acc.: 72.66%] [G loss: 0.478498]\n",
      "epoch:8 step:8180 [D loss: 0.561655, acc.: 65.62%] [G loss: 0.569545]\n",
      "epoch:8 step:8181 [D loss: 0.525094, acc.: 71.88%] [G loss: 0.535518]\n",
      "epoch:8 step:8182 [D loss: 0.544472, acc.: 73.44%] [G loss: 0.410066]\n",
      "epoch:8 step:8183 [D loss: 0.600150, acc.: 63.28%] [G loss: 0.547972]\n",
      "epoch:8 step:8184 [D loss: 0.576333, acc.: 65.62%] [G loss: 0.544644]\n",
      "epoch:8 step:8185 [D loss: 0.547973, acc.: 73.44%] [G loss: 0.564680]\n",
      "epoch:8 step:8186 [D loss: 0.506427, acc.: 74.22%] [G loss: 0.746700]\n",
      "epoch:8 step:8187 [D loss: 0.551894, acc.: 69.53%] [G loss: 0.480662]\n",
      "epoch:8 step:8188 [D loss: 0.528119, acc.: 76.56%] [G loss: 0.545625]\n",
      "epoch:8 step:8189 [D loss: 0.478735, acc.: 77.34%] [G loss: 0.685171]\n",
      "epoch:8 step:8190 [D loss: 0.544051, acc.: 71.09%] [G loss: 0.776044]\n",
      "epoch:8 step:8191 [D loss: 0.542462, acc.: 72.66%] [G loss: 0.632642]\n",
      "epoch:8 step:8192 [D loss: 0.633441, acc.: 60.16%] [G loss: 0.428472]\n",
      "epoch:8 step:8193 [D loss: 0.534922, acc.: 67.19%] [G loss: 0.555029]\n",
      "epoch:8 step:8194 [D loss: 0.558501, acc.: 71.88%] [G loss: 0.499857]\n",
      "epoch:8 step:8195 [D loss: 0.554198, acc.: 70.31%] [G loss: 0.544713]\n",
      "epoch:8 step:8196 [D loss: 0.531923, acc.: 75.00%] [G loss: 0.495534]\n",
      "epoch:8 step:8197 [D loss: 0.547160, acc.: 68.75%] [G loss: 0.722886]\n",
      "epoch:8 step:8198 [D loss: 0.569589, acc.: 67.19%] [G loss: 0.683502]\n",
      "epoch:8 step:8199 [D loss: 0.604113, acc.: 67.19%] [G loss: 0.592321]\n",
      "epoch:8 step:8200 [D loss: 0.617597, acc.: 64.06%] [G loss: 0.431549]\n",
      "##############\n",
      "[2.84989596 1.66769628 6.72251584 4.75614159 4.05182834 5.75304611\n",
      " 4.74948238 5.17402416 4.45114674 3.94887568]\n",
      "##########\n",
      "epoch:8 step:8201 [D loss: 0.547575, acc.: 75.00%] [G loss: 0.516891]\n",
      "epoch:8 step:8202 [D loss: 0.544932, acc.: 66.41%] [G loss: 0.548205]\n",
      "epoch:8 step:8203 [D loss: 0.514637, acc.: 77.34%] [G loss: 0.602702]\n",
      "epoch:8 step:8204 [D loss: 0.465621, acc.: 78.91%] [G loss: 0.815191]\n",
      "epoch:8 step:8205 [D loss: 0.534471, acc.: 71.09%] [G loss: 0.682822]\n",
      "epoch:8 step:8206 [D loss: 0.681281, acc.: 62.50%] [G loss: 0.475035]\n",
      "epoch:8 step:8207 [D loss: 0.562942, acc.: 70.31%] [G loss: 0.542921]\n",
      "epoch:8 step:8208 [D loss: 0.524308, acc.: 75.78%] [G loss: 0.623403]\n",
      "epoch:8 step:8209 [D loss: 0.570701, acc.: 69.53%] [G loss: 0.585593]\n",
      "epoch:8 step:8210 [D loss: 0.529337, acc.: 70.31%] [G loss: 0.645327]\n",
      "epoch:8 step:8211 [D loss: 0.557144, acc.: 70.31%] [G loss: 0.686940]\n",
      "epoch:8 step:8212 [D loss: 0.615803, acc.: 64.84%] [G loss: 0.557490]\n",
      "epoch:8 step:8213 [D loss: 0.653463, acc.: 60.16%] [G loss: 0.370246]\n",
      "epoch:8 step:8214 [D loss: 0.600780, acc.: 68.75%] [G loss: 0.451583]\n",
      "epoch:8 step:8215 [D loss: 0.550417, acc.: 69.53%] [G loss: 0.548223]\n",
      "epoch:8 step:8216 [D loss: 0.694258, acc.: 61.72%] [G loss: 0.481264]\n",
      "epoch:8 step:8217 [D loss: 0.609370, acc.: 61.72%] [G loss: 0.426943]\n",
      "epoch:8 step:8218 [D loss: 0.575434, acc.: 64.84%] [G loss: 0.418005]\n",
      "epoch:8 step:8219 [D loss: 0.552982, acc.: 67.97%] [G loss: 0.550892]\n",
      "epoch:8 step:8220 [D loss: 0.525405, acc.: 78.12%] [G loss: 0.520011]\n",
      "epoch:8 step:8221 [D loss: 0.508364, acc.: 78.12%] [G loss: 0.727031]\n",
      "epoch:8 step:8222 [D loss: 0.554359, acc.: 67.19%] [G loss: 0.596718]\n",
      "epoch:8 step:8223 [D loss: 0.618394, acc.: 63.28%] [G loss: 0.387568]\n",
      "epoch:8 step:8224 [D loss: 0.569923, acc.: 68.75%] [G loss: 0.397320]\n",
      "epoch:8 step:8225 [D loss: 0.574951, acc.: 70.31%] [G loss: 0.532197]\n",
      "epoch:8 step:8226 [D loss: 0.566342, acc.: 65.62%] [G loss: 0.478857]\n",
      "epoch:8 step:8227 [D loss: 0.595218, acc.: 65.62%] [G loss: 0.616342]\n",
      "epoch:8 step:8228 [D loss: 0.508211, acc.: 75.00%] [G loss: 0.558970]\n",
      "epoch:8 step:8229 [D loss: 0.528389, acc.: 71.09%] [G loss: 0.608421]\n",
      "epoch:8 step:8230 [D loss: 0.569712, acc.: 64.06%] [G loss: 0.542044]\n",
      "epoch:8 step:8231 [D loss: 0.569948, acc.: 71.09%] [G loss: 0.589895]\n",
      "epoch:8 step:8232 [D loss: 0.497457, acc.: 76.56%] [G loss: 0.582504]\n",
      "epoch:8 step:8233 [D loss: 0.516135, acc.: 70.31%] [G loss: 0.575440]\n",
      "epoch:8 step:8234 [D loss: 0.658941, acc.: 55.47%] [G loss: 0.491126]\n",
      "epoch:8 step:8235 [D loss: 0.619042, acc.: 69.53%] [G loss: 0.622608]\n",
      "epoch:8 step:8236 [D loss: 0.603083, acc.: 61.72%] [G loss: 0.545040]\n",
      "epoch:8 step:8237 [D loss: 0.592938, acc.: 67.97%] [G loss: 0.518511]\n",
      "epoch:8 step:8238 [D loss: 0.573810, acc.: 61.72%] [G loss: 0.456626]\n",
      "epoch:8 step:8239 [D loss: 0.522016, acc.: 72.66%] [G loss: 0.584346]\n",
      "epoch:8 step:8240 [D loss: 0.494014, acc.: 74.22%] [G loss: 0.689071]\n",
      "epoch:8 step:8241 [D loss: 0.660242, acc.: 54.69%] [G loss: 0.488191]\n",
      "epoch:8 step:8242 [D loss: 0.469338, acc.: 77.34%] [G loss: 0.647153]\n",
      "epoch:8 step:8243 [D loss: 0.438728, acc.: 79.69%] [G loss: 0.691632]\n",
      "epoch:8 step:8244 [D loss: 0.570992, acc.: 68.75%] [G loss: 0.596346]\n",
      "epoch:8 step:8245 [D loss: 0.559882, acc.: 69.53%] [G loss: 0.536192]\n",
      "epoch:8 step:8246 [D loss: 0.516513, acc.: 75.78%] [G loss: 0.583922]\n",
      "epoch:8 step:8247 [D loss: 0.555939, acc.: 72.66%] [G loss: 0.514167]\n",
      "epoch:8 step:8248 [D loss: 0.625798, acc.: 64.84%] [G loss: 0.687190]\n",
      "epoch:8 step:8249 [D loss: 0.529746, acc.: 75.00%] [G loss: 0.568696]\n",
      "epoch:8 step:8250 [D loss: 0.589153, acc.: 66.41%] [G loss: 0.591687]\n",
      "epoch:8 step:8251 [D loss: 0.555256, acc.: 65.62%] [G loss: 0.480862]\n",
      "epoch:8 step:8252 [D loss: 0.566388, acc.: 69.53%] [G loss: 0.517325]\n",
      "epoch:8 step:8253 [D loss: 0.573410, acc.: 67.19%] [G loss: 0.497928]\n",
      "epoch:8 step:8254 [D loss: 0.544045, acc.: 72.66%] [G loss: 0.489830]\n",
      "epoch:8 step:8255 [D loss: 0.529927, acc.: 77.34%] [G loss: 0.429824]\n",
      "epoch:8 step:8256 [D loss: 0.543789, acc.: 67.19%] [G loss: 0.513073]\n",
      "epoch:8 step:8257 [D loss: 0.545439, acc.: 71.88%] [G loss: 0.566805]\n",
      "epoch:8 step:8258 [D loss: 0.607066, acc.: 65.62%] [G loss: 0.549968]\n",
      "epoch:8 step:8259 [D loss: 0.537305, acc.: 71.88%] [G loss: 0.423447]\n",
      "epoch:8 step:8260 [D loss: 0.607100, acc.: 67.19%] [G loss: 0.576494]\n",
      "epoch:8 step:8261 [D loss: 0.670116, acc.: 61.72%] [G loss: 0.464630]\n",
      "epoch:8 step:8262 [D loss: 0.652700, acc.: 62.50%] [G loss: 0.473271]\n",
      "epoch:8 step:8263 [D loss: 0.577061, acc.: 67.97%] [G loss: 0.429947]\n",
      "epoch:8 step:8264 [D loss: 0.542638, acc.: 68.75%] [G loss: 0.573627]\n",
      "epoch:8 step:8265 [D loss: 0.551479, acc.: 68.75%] [G loss: 0.608928]\n",
      "epoch:8 step:8266 [D loss: 0.527004, acc.: 69.53%] [G loss: 0.583552]\n",
      "epoch:8 step:8267 [D loss: 0.543111, acc.: 69.53%] [G loss: 0.500367]\n",
      "epoch:8 step:8268 [D loss: 0.546754, acc.: 67.97%] [G loss: 0.530377]\n",
      "epoch:8 step:8269 [D loss: 0.569133, acc.: 67.19%] [G loss: 0.567999]\n",
      "epoch:8 step:8270 [D loss: 0.570540, acc.: 69.53%] [G loss: 0.481342]\n",
      "epoch:8 step:8271 [D loss: 0.555710, acc.: 71.09%] [G loss: 0.756553]\n",
      "epoch:8 step:8272 [D loss: 0.626290, acc.: 64.84%] [G loss: 0.690661]\n",
      "epoch:8 step:8273 [D loss: 0.592309, acc.: 69.53%] [G loss: 0.499537]\n",
      "epoch:8 step:8274 [D loss: 0.542386, acc.: 67.19%] [G loss: 0.488258]\n",
      "epoch:8 step:8275 [D loss: 0.552601, acc.: 71.88%] [G loss: 0.472569]\n",
      "epoch:8 step:8276 [D loss: 0.575286, acc.: 71.88%] [G loss: 0.564392]\n",
      "epoch:8 step:8277 [D loss: 0.460864, acc.: 78.91%] [G loss: 0.638614]\n",
      "epoch:8 step:8278 [D loss: 0.508484, acc.: 78.12%] [G loss: 0.640783]\n",
      "epoch:8 step:8279 [D loss: 0.612694, acc.: 61.72%] [G loss: 0.606129]\n",
      "epoch:8 step:8280 [D loss: 0.645558, acc.: 62.50%] [G loss: 0.740286]\n",
      "epoch:8 step:8281 [D loss: 0.538466, acc.: 71.09%] [G loss: 0.549418]\n",
      "epoch:8 step:8282 [D loss: 0.519716, acc.: 69.53%] [G loss: 0.517717]\n",
      "epoch:8 step:8283 [D loss: 0.615611, acc.: 67.97%] [G loss: 0.509805]\n",
      "epoch:8 step:8284 [D loss: 0.629804, acc.: 64.84%] [G loss: 0.571810]\n",
      "epoch:8 step:8285 [D loss: 0.541406, acc.: 77.34%] [G loss: 0.449288]\n",
      "epoch:8 step:8286 [D loss: 0.644703, acc.: 59.38%] [G loss: 0.509760]\n",
      "epoch:8 step:8287 [D loss: 0.535005, acc.: 71.88%] [G loss: 0.542334]\n",
      "epoch:8 step:8288 [D loss: 0.493676, acc.: 75.78%] [G loss: 0.597319]\n",
      "epoch:8 step:8289 [D loss: 0.577045, acc.: 69.53%] [G loss: 0.590027]\n",
      "epoch:8 step:8290 [D loss: 0.627790, acc.: 64.06%] [G loss: 0.605360]\n",
      "epoch:8 step:8291 [D loss: 0.513859, acc.: 71.09%] [G loss: 0.671567]\n",
      "epoch:8 step:8292 [D loss: 0.527576, acc.: 71.88%] [G loss: 0.669294]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:8 step:8293 [D loss: 0.576600, acc.: 71.09%] [G loss: 0.572451]\n",
      "epoch:8 step:8294 [D loss: 0.521711, acc.: 69.53%] [G loss: 0.584683]\n",
      "epoch:8 step:8295 [D loss: 0.575654, acc.: 72.66%] [G loss: 0.619801]\n",
      "epoch:8 step:8296 [D loss: 0.583279, acc.: 64.06%] [G loss: 0.475635]\n",
      "epoch:8 step:8297 [D loss: 0.491501, acc.: 80.47%] [G loss: 0.589337]\n",
      "epoch:8 step:8298 [D loss: 0.452142, acc.: 81.25%] [G loss: 0.678367]\n",
      "epoch:8 step:8299 [D loss: 0.482183, acc.: 75.78%] [G loss: 0.650337]\n",
      "epoch:8 step:8300 [D loss: 0.618242, acc.: 64.06%] [G loss: 0.483905]\n",
      "epoch:8 step:8301 [D loss: 0.541723, acc.: 69.53%] [G loss: 0.511746]\n",
      "epoch:8 step:8302 [D loss: 0.554044, acc.: 65.62%] [G loss: 0.586782]\n",
      "epoch:8 step:8303 [D loss: 0.512767, acc.: 77.34%] [G loss: 0.649636]\n",
      "epoch:8 step:8304 [D loss: 0.576595, acc.: 71.88%] [G loss: 0.555843]\n",
      "epoch:8 step:8305 [D loss: 0.553405, acc.: 67.19%] [G loss: 0.586830]\n",
      "epoch:8 step:8306 [D loss: 0.543183, acc.: 70.31%] [G loss: 0.529643]\n",
      "epoch:8 step:8307 [D loss: 0.570348, acc.: 69.53%] [G loss: 0.490494]\n",
      "epoch:8 step:8308 [D loss: 0.642783, acc.: 61.72%] [G loss: 0.433815]\n",
      "epoch:8 step:8309 [D loss: 0.521308, acc.: 71.09%] [G loss: 0.466667]\n",
      "epoch:8 step:8310 [D loss: 0.523990, acc.: 74.22%] [G loss: 0.609251]\n",
      "epoch:8 step:8311 [D loss: 0.564134, acc.: 72.66%] [G loss: 0.797821]\n",
      "epoch:8 step:8312 [D loss: 0.518651, acc.: 78.91%] [G loss: 0.657256]\n",
      "epoch:8 step:8313 [D loss: 0.612718, acc.: 67.97%] [G loss: 0.612025]\n",
      "epoch:8 step:8314 [D loss: 0.642581, acc.: 60.94%] [G loss: 0.693795]\n",
      "epoch:8 step:8315 [D loss: 0.502767, acc.: 77.34%] [G loss: 0.653278]\n",
      "epoch:8 step:8316 [D loss: 0.607481, acc.: 66.41%] [G loss: 0.578778]\n",
      "epoch:8 step:8317 [D loss: 0.552563, acc.: 66.41%] [G loss: 0.434378]\n",
      "epoch:8 step:8318 [D loss: 0.499205, acc.: 71.88%] [G loss: 0.554035]\n",
      "epoch:8 step:8319 [D loss: 0.484402, acc.: 73.44%] [G loss: 0.573039]\n",
      "epoch:8 step:8320 [D loss: 0.572151, acc.: 70.31%] [G loss: 0.585178]\n",
      "epoch:8 step:8321 [D loss: 0.521367, acc.: 74.22%] [G loss: 0.446198]\n",
      "epoch:8 step:8322 [D loss: 0.533336, acc.: 70.31%] [G loss: 0.562840]\n",
      "epoch:8 step:8323 [D loss: 0.603691, acc.: 61.72%] [G loss: 0.571968]\n",
      "epoch:8 step:8324 [D loss: 0.604826, acc.: 62.50%] [G loss: 0.701039]\n",
      "epoch:8 step:8325 [D loss: 0.537284, acc.: 71.09%] [G loss: 0.594685]\n",
      "epoch:8 step:8326 [D loss: 0.514025, acc.: 75.78%] [G loss: 0.643326]\n",
      "epoch:8 step:8327 [D loss: 0.641620, acc.: 63.28%] [G loss: 0.440952]\n",
      "epoch:8 step:8328 [D loss: 0.543752, acc.: 71.88%] [G loss: 0.452407]\n",
      "epoch:8 step:8329 [D loss: 0.526015, acc.: 74.22%] [G loss: 0.548745]\n",
      "epoch:8 step:8330 [D loss: 0.508860, acc.: 74.22%] [G loss: 0.583747]\n",
      "epoch:8 step:8331 [D loss: 0.523515, acc.: 72.66%] [G loss: 0.446122]\n",
      "epoch:8 step:8332 [D loss: 0.551067, acc.: 70.31%] [G loss: 0.466630]\n",
      "epoch:8 step:8333 [D loss: 0.507762, acc.: 75.00%] [G loss: 0.487704]\n",
      "epoch:8 step:8334 [D loss: 0.515681, acc.: 74.22%] [G loss: 0.525557]\n",
      "epoch:8 step:8335 [D loss: 0.570769, acc.: 67.97%] [G loss: 0.478727]\n",
      "epoch:8 step:8336 [D loss: 0.553776, acc.: 69.53%] [G loss: 0.488034]\n",
      "epoch:8 step:8337 [D loss: 0.533784, acc.: 68.75%] [G loss: 0.499225]\n",
      "epoch:8 step:8338 [D loss: 0.502488, acc.: 73.44%] [G loss: 0.515258]\n",
      "epoch:8 step:8339 [D loss: 0.501498, acc.: 74.22%] [G loss: 0.549952]\n",
      "epoch:8 step:8340 [D loss: 0.550606, acc.: 63.28%] [G loss: 0.604288]\n",
      "epoch:8 step:8341 [D loss: 0.556081, acc.: 66.41%] [G loss: 0.580312]\n",
      "epoch:8 step:8342 [D loss: 0.593052, acc.: 62.50%] [G loss: 0.536790]\n",
      "epoch:8 step:8343 [D loss: 0.580574, acc.: 67.19%] [G loss: 0.474236]\n",
      "epoch:8 step:8344 [D loss: 0.552052, acc.: 72.66%] [G loss: 0.540623]\n",
      "epoch:8 step:8345 [D loss: 0.601299, acc.: 64.84%] [G loss: 0.562363]\n",
      "epoch:8 step:8346 [D loss: 0.565834, acc.: 66.41%] [G loss: 0.467703]\n",
      "epoch:8 step:8347 [D loss: 0.602019, acc.: 61.72%] [G loss: 0.555661]\n",
      "epoch:8 step:8348 [D loss: 0.533450, acc.: 68.75%] [G loss: 0.622683]\n",
      "epoch:8 step:8349 [D loss: 0.550704, acc.: 72.66%] [G loss: 0.554542]\n",
      "epoch:8 step:8350 [D loss: 0.487418, acc.: 72.66%] [G loss: 0.771540]\n",
      "epoch:8 step:8351 [D loss: 0.532257, acc.: 72.66%] [G loss: 0.644510]\n",
      "epoch:8 step:8352 [D loss: 0.643055, acc.: 64.84%] [G loss: 0.666641]\n",
      "epoch:8 step:8353 [D loss: 0.477057, acc.: 78.91%] [G loss: 0.560190]\n",
      "epoch:8 step:8354 [D loss: 0.677264, acc.: 58.59%] [G loss: 0.621875]\n",
      "epoch:8 step:8355 [D loss: 0.606413, acc.: 64.84%] [G loss: 0.497228]\n",
      "epoch:8 step:8356 [D loss: 0.499693, acc.: 74.22%] [G loss: 0.636544]\n",
      "epoch:8 step:8357 [D loss: 0.610119, acc.: 65.62%] [G loss: 0.571855]\n",
      "epoch:8 step:8358 [D loss: 0.567422, acc.: 65.62%] [G loss: 0.485859]\n",
      "epoch:8 step:8359 [D loss: 0.574565, acc.: 69.53%] [G loss: 0.434151]\n",
      "epoch:8 step:8360 [D loss: 0.556592, acc.: 69.53%] [G loss: 0.461807]\n",
      "epoch:8 step:8361 [D loss: 0.560532, acc.: 66.41%] [G loss: 0.475706]\n",
      "epoch:8 step:8362 [D loss: 0.537230, acc.: 71.88%] [G loss: 0.607825]\n",
      "epoch:8 step:8363 [D loss: 0.663475, acc.: 60.16%] [G loss: 0.437448]\n",
      "epoch:8 step:8364 [D loss: 0.524075, acc.: 71.09%] [G loss: 0.480328]\n",
      "epoch:8 step:8365 [D loss: 0.567840, acc.: 68.75%] [G loss: 0.412748]\n",
      "epoch:8 step:8366 [D loss: 0.499440, acc.: 72.66%] [G loss: 0.523934]\n",
      "epoch:8 step:8367 [D loss: 0.479464, acc.: 75.78%] [G loss: 0.684811]\n",
      "epoch:8 step:8368 [D loss: 0.544576, acc.: 68.75%] [G loss: 0.546596]\n",
      "epoch:8 step:8369 [D loss: 0.598439, acc.: 65.62%] [G loss: 0.720870]\n",
      "epoch:8 step:8370 [D loss: 0.567774, acc.: 69.53%] [G loss: 0.515671]\n",
      "epoch:8 step:8371 [D loss: 0.527219, acc.: 74.22%] [G loss: 0.504643]\n",
      "epoch:8 step:8372 [D loss: 0.565919, acc.: 67.19%] [G loss: 0.596865]\n",
      "epoch:8 step:8373 [D loss: 0.595719, acc.: 67.19%] [G loss: 0.445919]\n",
      "epoch:8 step:8374 [D loss: 0.516392, acc.: 73.44%] [G loss: 0.490565]\n",
      "epoch:8 step:8375 [D loss: 0.563516, acc.: 72.66%] [G loss: 0.377386]\n",
      "epoch:8 step:8376 [D loss: 0.650230, acc.: 63.28%] [G loss: 0.450175]\n",
      "epoch:8 step:8377 [D loss: 0.577718, acc.: 64.06%] [G loss: 0.490094]\n",
      "epoch:8 step:8378 [D loss: 0.589608, acc.: 65.62%] [G loss: 0.481267]\n",
      "epoch:8 step:8379 [D loss: 0.583422, acc.: 69.53%] [G loss: 0.560506]\n",
      "epoch:8 step:8380 [D loss: 0.469148, acc.: 78.12%] [G loss: 0.694263]\n",
      "epoch:8 step:8381 [D loss: 0.483396, acc.: 76.56%] [G loss: 0.688523]\n",
      "epoch:8 step:8382 [D loss: 0.497048, acc.: 68.75%] [G loss: 0.937412]\n",
      "epoch:8 step:8383 [D loss: 0.539513, acc.: 73.44%] [G loss: 0.611860]\n",
      "epoch:8 step:8384 [D loss: 0.576565, acc.: 71.09%] [G loss: 0.586445]\n",
      "epoch:8 step:8385 [D loss: 0.547652, acc.: 67.97%] [G loss: 0.526735]\n",
      "epoch:8 step:8386 [D loss: 0.492821, acc.: 75.78%] [G loss: 0.595225]\n",
      "epoch:8 step:8387 [D loss: 0.614266, acc.: 66.41%] [G loss: 0.547344]\n",
      "epoch:8 step:8388 [D loss: 0.594528, acc.: 66.41%] [G loss: 0.482440]\n",
      "epoch:8 step:8389 [D loss: 0.540021, acc.: 72.66%] [G loss: 0.558187]\n",
      "epoch:8 step:8390 [D loss: 0.479660, acc.: 78.91%] [G loss: 0.599424]\n",
      "epoch:8 step:8391 [D loss: 0.556958, acc.: 70.31%] [G loss: 0.661605]\n",
      "epoch:8 step:8392 [D loss: 0.509979, acc.: 78.12%] [G loss: 0.559645]\n",
      "epoch:8 step:8393 [D loss: 0.542244, acc.: 72.66%] [G loss: 0.670275]\n",
      "epoch:8 step:8394 [D loss: 0.505224, acc.: 75.00%] [G loss: 0.687926]\n",
      "epoch:8 step:8395 [D loss: 0.486995, acc.: 76.56%] [G loss: 0.791920]\n",
      "epoch:8 step:8396 [D loss: 0.508062, acc.: 76.56%] [G loss: 0.765496]\n",
      "epoch:8 step:8397 [D loss: 0.555861, acc.: 67.97%] [G loss: 0.626178]\n",
      "epoch:8 step:8398 [D loss: 0.571928, acc.: 68.75%] [G loss: 0.471563]\n",
      "epoch:8 step:8399 [D loss: 0.549566, acc.: 71.09%] [G loss: 0.714996]\n",
      "epoch:8 step:8400 [D loss: 0.556553, acc.: 69.53%] [G loss: 0.704846]\n",
      "##############\n",
      "[3.25307023 1.40802392 6.22161388 5.04813315 4.08933581 5.92371237\n",
      " 4.77383581 4.90291612 4.68157077 4.00383544]\n",
      "##########\n",
      "epoch:8 step:8401 [D loss: 0.574775, acc.: 70.31%] [G loss: 0.461499]\n",
      "epoch:8 step:8402 [D loss: 0.519032, acc.: 71.88%] [G loss: 0.750013]\n",
      "epoch:8 step:8403 [D loss: 0.566408, acc.: 71.09%] [G loss: 0.663526]\n",
      "epoch:8 step:8404 [D loss: 0.578126, acc.: 64.84%] [G loss: 0.590173]\n",
      "epoch:8 step:8405 [D loss: 0.511946, acc.: 73.44%] [G loss: 0.548295]\n",
      "epoch:8 step:8406 [D loss: 0.545146, acc.: 71.09%] [G loss: 0.520031]\n",
      "epoch:8 step:8407 [D loss: 0.504261, acc.: 74.22%] [G loss: 0.714834]\n",
      "epoch:8 step:8408 [D loss: 0.440565, acc.: 82.03%] [G loss: 0.888678]\n",
      "epoch:8 step:8409 [D loss: 0.590523, acc.: 69.53%] [G loss: 0.767633]\n",
      "epoch:8 step:8410 [D loss: 0.533118, acc.: 77.34%] [G loss: 0.628372]\n",
      "epoch:8 step:8411 [D loss: 0.660164, acc.: 56.25%] [G loss: 0.560932]\n",
      "epoch:8 step:8412 [D loss: 0.537020, acc.: 75.78%] [G loss: 0.477461]\n",
      "epoch:8 step:8413 [D loss: 0.602201, acc.: 64.06%] [G loss: 0.498027]\n",
      "epoch:8 step:8414 [D loss: 0.555890, acc.: 67.19%] [G loss: 0.573563]\n",
      "epoch:8 step:8415 [D loss: 0.512879, acc.: 73.44%] [G loss: 0.709421]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:8 step:8416 [D loss: 0.774472, acc.: 56.25%] [G loss: 0.574598]\n",
      "epoch:8 step:8417 [D loss: 0.456729, acc.: 82.03%] [G loss: 0.629291]\n",
      "epoch:8 step:8418 [D loss: 0.517594, acc.: 71.09%] [G loss: 0.563227]\n",
      "epoch:8 step:8419 [D loss: 0.516317, acc.: 71.88%] [G loss: 0.668165]\n",
      "epoch:8 step:8420 [D loss: 0.493437, acc.: 71.09%] [G loss: 0.772420]\n",
      "epoch:8 step:8421 [D loss: 0.473089, acc.: 78.91%] [G loss: 0.692602]\n",
      "epoch:8 step:8422 [D loss: 0.485074, acc.: 75.78%] [G loss: 0.954286]\n",
      "epoch:8 step:8423 [D loss: 0.551404, acc.: 67.97%] [G loss: 0.861293]\n",
      "epoch:8 step:8424 [D loss: 0.678804, acc.: 65.62%] [G loss: 0.804673]\n",
      "epoch:8 step:8425 [D loss: 0.438760, acc.: 82.03%] [G loss: 0.968021]\n",
      "epoch:8 step:8426 [D loss: 0.524964, acc.: 71.88%] [G loss: 0.935172]\n",
      "epoch:8 step:8427 [D loss: 0.586539, acc.: 64.06%] [G loss: 0.983903]\n",
      "epoch:8 step:8428 [D loss: 0.620113, acc.: 69.53%] [G loss: 0.653656]\n",
      "epoch:8 step:8429 [D loss: 0.521870, acc.: 73.44%] [G loss: 0.708384]\n",
      "epoch:8 step:8430 [D loss: 0.581458, acc.: 63.28%] [G loss: 0.684559]\n",
      "epoch:8 step:8431 [D loss: 0.483698, acc.: 78.91%] [G loss: 0.708393]\n",
      "epoch:8 step:8432 [D loss: 0.386275, acc.: 85.94%] [G loss: 0.925144]\n",
      "epoch:8 step:8433 [D loss: 0.432346, acc.: 82.03%] [G loss: 0.974175]\n",
      "epoch:9 step:8434 [D loss: 0.549245, acc.: 71.88%] [G loss: 1.065365]\n",
      "epoch:9 step:8435 [D loss: 0.501398, acc.: 74.22%] [G loss: 0.979689]\n",
      "epoch:9 step:8436 [D loss: 0.607233, acc.: 67.97%] [G loss: 0.694592]\n",
      "epoch:9 step:8437 [D loss: 0.490088, acc.: 80.47%] [G loss: 0.750875]\n",
      "epoch:9 step:8438 [D loss: 0.647829, acc.: 63.28%] [G loss: 0.630979]\n",
      "epoch:9 step:8439 [D loss: 0.521926, acc.: 71.88%] [G loss: 0.807372]\n",
      "epoch:9 step:8440 [D loss: 0.534317, acc.: 71.88%] [G loss: 0.676447]\n",
      "epoch:9 step:8441 [D loss: 0.575258, acc.: 71.88%] [G loss: 0.672575]\n",
      "epoch:9 step:8442 [D loss: 0.526170, acc.: 74.22%] [G loss: 0.884907]\n",
      "epoch:9 step:8443 [D loss: 0.527610, acc.: 72.66%] [G loss: 0.670638]\n",
      "epoch:9 step:8444 [D loss: 0.471165, acc.: 75.78%] [G loss: 0.736022]\n",
      "epoch:9 step:8445 [D loss: 0.607143, acc.: 65.62%] [G loss: 0.621364]\n",
      "epoch:9 step:8446 [D loss: 0.573985, acc.: 72.66%] [G loss: 0.509676]\n",
      "epoch:9 step:8447 [D loss: 0.524517, acc.: 76.56%] [G loss: 0.546387]\n",
      "epoch:9 step:8448 [D loss: 0.470304, acc.: 81.25%] [G loss: 0.533758]\n",
      "epoch:9 step:8449 [D loss: 0.519089, acc.: 74.22%] [G loss: 0.536718]\n",
      "epoch:9 step:8450 [D loss: 0.583482, acc.: 70.31%] [G loss: 0.626252]\n",
      "epoch:9 step:8451 [D loss: 0.670167, acc.: 60.16%] [G loss: 0.784449]\n",
      "epoch:9 step:8452 [D loss: 0.552545, acc.: 69.53%] [G loss: 0.643993]\n",
      "epoch:9 step:8453 [D loss: 0.634690, acc.: 67.97%] [G loss: 0.483490]\n",
      "epoch:9 step:8454 [D loss: 0.536403, acc.: 68.75%] [G loss: 0.480532]\n",
      "epoch:9 step:8455 [D loss: 0.456160, acc.: 79.69%] [G loss: 0.573188]\n",
      "epoch:9 step:8456 [D loss: 0.534648, acc.: 69.53%] [G loss: 0.614442]\n",
      "epoch:9 step:8457 [D loss: 0.485695, acc.: 74.22%] [G loss: 0.605407]\n",
      "epoch:9 step:8458 [D loss: 0.517893, acc.: 75.00%] [G loss: 0.529230]\n",
      "epoch:9 step:8459 [D loss: 0.617042, acc.: 64.84%] [G loss: 0.373664]\n",
      "epoch:9 step:8460 [D loss: 0.505424, acc.: 74.22%] [G loss: 0.458283]\n",
      "epoch:9 step:8461 [D loss: 0.588210, acc.: 60.94%] [G loss: 0.493102]\n",
      "epoch:9 step:8462 [D loss: 0.505209, acc.: 75.78%] [G loss: 0.484388]\n",
      "epoch:9 step:8463 [D loss: 0.570356, acc.: 67.19%] [G loss: 0.483738]\n",
      "epoch:9 step:8464 [D loss: 0.575459, acc.: 68.75%] [G loss: 0.534717]\n",
      "epoch:9 step:8465 [D loss: 0.526045, acc.: 67.97%] [G loss: 0.623749]\n",
      "epoch:9 step:8466 [D loss: 0.527472, acc.: 70.31%] [G loss: 0.565717]\n",
      "epoch:9 step:8467 [D loss: 0.510970, acc.: 72.66%] [G loss: 0.610401]\n",
      "epoch:9 step:8468 [D loss: 0.635950, acc.: 63.28%] [G loss: 0.571671]\n",
      "epoch:9 step:8469 [D loss: 0.513730, acc.: 76.56%] [G loss: 0.795126]\n",
      "epoch:9 step:8470 [D loss: 0.495641, acc.: 77.34%] [G loss: 0.657033]\n",
      "epoch:9 step:8471 [D loss: 0.627782, acc.: 64.84%] [G loss: 0.461438]\n",
      "epoch:9 step:8472 [D loss: 0.523245, acc.: 70.31%] [G loss: 0.596781]\n",
      "epoch:9 step:8473 [D loss: 0.429310, acc.: 83.59%] [G loss: 0.823799]\n",
      "epoch:9 step:8474 [D loss: 0.528167, acc.: 73.44%] [G loss: 0.495345]\n",
      "epoch:9 step:8475 [D loss: 0.546758, acc.: 71.88%] [G loss: 0.545839]\n",
      "epoch:9 step:8476 [D loss: 0.582067, acc.: 64.84%] [G loss: 0.732040]\n",
      "epoch:9 step:8477 [D loss: 0.580383, acc.: 67.97%] [G loss: 0.622763]\n",
      "epoch:9 step:8478 [D loss: 0.528348, acc.: 75.78%] [G loss: 0.615808]\n",
      "epoch:9 step:8479 [D loss: 0.510367, acc.: 76.56%] [G loss: 0.586568]\n",
      "epoch:9 step:8480 [D loss: 0.541698, acc.: 75.00%] [G loss: 0.505255]\n",
      "epoch:9 step:8481 [D loss: 0.523849, acc.: 75.78%] [G loss: 0.457244]\n",
      "epoch:9 step:8482 [D loss: 0.556262, acc.: 72.66%] [G loss: 0.509269]\n",
      "epoch:9 step:8483 [D loss: 0.599225, acc.: 62.50%] [G loss: 0.588835]\n",
      "epoch:9 step:8484 [D loss: 0.663986, acc.: 62.50%] [G loss: 0.524634]\n",
      "epoch:9 step:8485 [D loss: 0.577050, acc.: 69.53%] [G loss: 0.493090]\n",
      "epoch:9 step:8486 [D loss: 0.517914, acc.: 71.09%] [G loss: 0.523072]\n",
      "epoch:9 step:8487 [D loss: 0.495225, acc.: 72.66%] [G loss: 0.727062]\n",
      "epoch:9 step:8488 [D loss: 0.548403, acc.: 71.88%] [G loss: 0.671495]\n",
      "epoch:9 step:8489 [D loss: 0.533778, acc.: 74.22%] [G loss: 0.514547]\n",
      "epoch:9 step:8490 [D loss: 0.526945, acc.: 67.97%] [G loss: 0.555477]\n",
      "epoch:9 step:8491 [D loss: 0.530760, acc.: 74.22%] [G loss: 0.610556]\n",
      "epoch:9 step:8492 [D loss: 0.506967, acc.: 72.66%] [G loss: 0.522776]\n",
      "epoch:9 step:8493 [D loss: 0.567152, acc.: 70.31%] [G loss: 0.599014]\n",
      "epoch:9 step:8494 [D loss: 0.524089, acc.: 71.09%] [G loss: 0.643637]\n",
      "epoch:9 step:8495 [D loss: 0.579076, acc.: 71.88%] [G loss: 0.559695]\n",
      "epoch:9 step:8496 [D loss: 0.587068, acc.: 67.19%] [G loss: 0.430541]\n",
      "epoch:9 step:8497 [D loss: 0.537248, acc.: 71.88%] [G loss: 0.558073]\n",
      "epoch:9 step:8498 [D loss: 0.551790, acc.: 75.00%] [G loss: 0.590743]\n",
      "epoch:9 step:8499 [D loss: 0.496747, acc.: 77.34%] [G loss: 0.625646]\n",
      "epoch:9 step:8500 [D loss: 0.524490, acc.: 71.88%] [G loss: 0.548429]\n",
      "epoch:9 step:8501 [D loss: 0.544456, acc.: 70.31%] [G loss: 0.514266]\n",
      "epoch:9 step:8502 [D loss: 0.467826, acc.: 80.47%] [G loss: 0.480351]\n",
      "epoch:9 step:8503 [D loss: 0.536525, acc.: 74.22%] [G loss: 0.516602]\n",
      "epoch:9 step:8504 [D loss: 0.538628, acc.: 69.53%] [G loss: 0.530732]\n",
      "epoch:9 step:8505 [D loss: 0.519183, acc.: 74.22%] [G loss: 0.560554]\n",
      "epoch:9 step:8506 [D loss: 0.563575, acc.: 67.97%] [G loss: 0.498432]\n",
      "epoch:9 step:8507 [D loss: 0.521725, acc.: 72.66%] [G loss: 0.533724]\n",
      "epoch:9 step:8508 [D loss: 0.577434, acc.: 67.19%] [G loss: 0.541151]\n",
      "epoch:9 step:8509 [D loss: 0.536062, acc.: 70.31%] [G loss: 0.901390]\n",
      "epoch:9 step:8510 [D loss: 0.450643, acc.: 81.25%] [G loss: 0.763093]\n",
      "epoch:9 step:8511 [D loss: 0.575502, acc.: 74.22%] [G loss: 0.632592]\n",
      "epoch:9 step:8512 [D loss: 0.617817, acc.: 64.06%] [G loss: 0.525045]\n",
      "epoch:9 step:8513 [D loss: 0.544919, acc.: 69.53%] [G loss: 0.510471]\n",
      "epoch:9 step:8514 [D loss: 0.543375, acc.: 67.19%] [G loss: 0.650026]\n",
      "epoch:9 step:8515 [D loss: 0.508892, acc.: 74.22%] [G loss: 0.491850]\n",
      "epoch:9 step:8516 [D loss: 0.494722, acc.: 75.00%] [G loss: 0.638130]\n",
      "epoch:9 step:8517 [D loss: 0.561132, acc.: 68.75%] [G loss: 0.574982]\n",
      "epoch:9 step:8518 [D loss: 0.571422, acc.: 64.84%] [G loss: 0.615179]\n",
      "epoch:9 step:8519 [D loss: 0.561936, acc.: 70.31%] [G loss: 0.520135]\n",
      "epoch:9 step:8520 [D loss: 0.541476, acc.: 68.75%] [G loss: 0.474586]\n",
      "epoch:9 step:8521 [D loss: 0.477730, acc.: 75.78%] [G loss: 0.655175]\n",
      "epoch:9 step:8522 [D loss: 0.552253, acc.: 69.53%] [G loss: 0.658894]\n",
      "epoch:9 step:8523 [D loss: 0.507559, acc.: 71.88%] [G loss: 0.544972]\n",
      "epoch:9 step:8524 [D loss: 0.568335, acc.: 64.84%] [G loss: 0.556109]\n",
      "epoch:9 step:8525 [D loss: 0.487021, acc.: 75.00%] [G loss: 0.598439]\n",
      "epoch:9 step:8526 [D loss: 0.482882, acc.: 75.00%] [G loss: 0.642538]\n",
      "epoch:9 step:8527 [D loss: 0.504654, acc.: 71.88%] [G loss: 0.590220]\n",
      "epoch:9 step:8528 [D loss: 0.532338, acc.: 72.66%] [G loss: 0.627508]\n",
      "epoch:9 step:8529 [D loss: 0.505359, acc.: 75.00%] [G loss: 0.631192]\n",
      "epoch:9 step:8530 [D loss: 0.571998, acc.: 64.06%] [G loss: 0.589948]\n",
      "epoch:9 step:8531 [D loss: 0.545472, acc.: 65.62%] [G loss: 0.619081]\n",
      "epoch:9 step:8532 [D loss: 0.551207, acc.: 68.75%] [G loss: 0.631557]\n",
      "epoch:9 step:8533 [D loss: 0.484428, acc.: 76.56%] [G loss: 0.588030]\n",
      "epoch:9 step:8534 [D loss: 0.595961, acc.: 64.06%] [G loss: 0.545232]\n",
      "epoch:9 step:8535 [D loss: 0.590523, acc.: 68.75%] [G loss: 0.537558]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:9 step:8536 [D loss: 0.525475, acc.: 72.66%] [G loss: 0.533317]\n",
      "epoch:9 step:8537 [D loss: 0.513718, acc.: 71.88%] [G loss: 0.650928]\n",
      "epoch:9 step:8538 [D loss: 0.585782, acc.: 65.62%] [G loss: 0.515659]\n",
      "epoch:9 step:8539 [D loss: 0.581930, acc.: 67.19%] [G loss: 0.518665]\n",
      "epoch:9 step:8540 [D loss: 0.549449, acc.: 70.31%] [G loss: 0.647770]\n",
      "epoch:9 step:8541 [D loss: 0.693723, acc.: 60.94%] [G loss: 0.477715]\n",
      "epoch:9 step:8542 [D loss: 0.605806, acc.: 63.28%] [G loss: 0.466967]\n",
      "epoch:9 step:8543 [D loss: 0.542006, acc.: 69.53%] [G loss: 0.447581]\n",
      "epoch:9 step:8544 [D loss: 0.507270, acc.: 73.44%] [G loss: 0.615174]\n",
      "epoch:9 step:8545 [D loss: 0.545469, acc.: 71.88%] [G loss: 0.526607]\n",
      "epoch:9 step:8546 [D loss: 0.565200, acc.: 68.75%] [G loss: 0.682979]\n",
      "epoch:9 step:8547 [D loss: 0.497614, acc.: 76.56%] [G loss: 0.640389]\n",
      "epoch:9 step:8548 [D loss: 0.528175, acc.: 73.44%] [G loss: 0.561306]\n",
      "epoch:9 step:8549 [D loss: 0.541753, acc.: 73.44%] [G loss: 0.630311]\n",
      "epoch:9 step:8550 [D loss: 0.582300, acc.: 65.62%] [G loss: 0.486272]\n",
      "epoch:9 step:8551 [D loss: 0.577262, acc.: 69.53%] [G loss: 0.561933]\n",
      "epoch:9 step:8552 [D loss: 0.494784, acc.: 78.12%] [G loss: 0.683635]\n",
      "epoch:9 step:8553 [D loss: 0.562675, acc.: 70.31%] [G loss: 0.722279]\n",
      "epoch:9 step:8554 [D loss: 0.582746, acc.: 71.09%] [G loss: 0.657741]\n",
      "epoch:9 step:8555 [D loss: 0.542007, acc.: 75.00%] [G loss: 0.801188]\n",
      "epoch:9 step:8556 [D loss: 0.507160, acc.: 74.22%] [G loss: 0.686060]\n",
      "epoch:9 step:8557 [D loss: 0.580402, acc.: 67.97%] [G loss: 0.574841]\n",
      "epoch:9 step:8558 [D loss: 0.555365, acc.: 67.19%] [G loss: 0.489601]\n",
      "epoch:9 step:8559 [D loss: 0.529178, acc.: 71.88%] [G loss: 0.601326]\n",
      "epoch:9 step:8560 [D loss: 0.488060, acc.: 73.44%] [G loss: 0.583488]\n",
      "epoch:9 step:8561 [D loss: 0.472976, acc.: 78.91%] [G loss: 0.567322]\n",
      "epoch:9 step:8562 [D loss: 0.586337, acc.: 67.19%] [G loss: 0.576523]\n",
      "epoch:9 step:8563 [D loss: 0.450072, acc.: 79.69%] [G loss: 0.571117]\n",
      "epoch:9 step:8564 [D loss: 0.524386, acc.: 70.31%] [G loss: 0.591969]\n",
      "epoch:9 step:8565 [D loss: 0.566588, acc.: 71.88%] [G loss: 0.713176]\n",
      "epoch:9 step:8566 [D loss: 0.584663, acc.: 66.41%] [G loss: 0.520527]\n",
      "epoch:9 step:8567 [D loss: 0.522239, acc.: 71.88%] [G loss: 0.587687]\n",
      "epoch:9 step:8568 [D loss: 0.539630, acc.: 71.09%] [G loss: 0.575122]\n",
      "epoch:9 step:8569 [D loss: 0.528527, acc.: 75.00%] [G loss: 0.480773]\n",
      "epoch:9 step:8570 [D loss: 0.639542, acc.: 60.16%] [G loss: 0.492357]\n",
      "epoch:9 step:8571 [D loss: 0.606503, acc.: 66.41%] [G loss: 0.480619]\n",
      "epoch:9 step:8572 [D loss: 0.627162, acc.: 64.84%] [G loss: 0.578320]\n",
      "epoch:9 step:8573 [D loss: 0.644080, acc.: 60.16%] [G loss: 0.523038]\n",
      "epoch:9 step:8574 [D loss: 0.590265, acc.: 62.50%] [G loss: 0.461242]\n",
      "epoch:9 step:8575 [D loss: 0.529998, acc.: 69.53%] [G loss: 0.574754]\n",
      "epoch:9 step:8576 [D loss: 0.624877, acc.: 60.94%] [G loss: 0.486305]\n",
      "epoch:9 step:8577 [D loss: 0.507048, acc.: 73.44%] [G loss: 0.517879]\n",
      "epoch:9 step:8578 [D loss: 0.559323, acc.: 65.62%] [G loss: 0.641948]\n",
      "epoch:9 step:8579 [D loss: 0.473250, acc.: 78.12%] [G loss: 0.628872]\n",
      "epoch:9 step:8580 [D loss: 0.667514, acc.: 60.16%] [G loss: 0.409584]\n",
      "epoch:9 step:8581 [D loss: 0.535201, acc.: 75.00%] [G loss: 0.407726]\n",
      "epoch:9 step:8582 [D loss: 0.481695, acc.: 75.78%] [G loss: 0.594471]\n",
      "epoch:9 step:8583 [D loss: 0.602316, acc.: 69.53%] [G loss: 0.567365]\n",
      "epoch:9 step:8584 [D loss: 0.557416, acc.: 67.97%] [G loss: 0.521348]\n",
      "epoch:9 step:8585 [D loss: 0.500174, acc.: 78.12%] [G loss: 0.633113]\n",
      "epoch:9 step:8586 [D loss: 0.595715, acc.: 67.19%] [G loss: 0.624235]\n",
      "epoch:9 step:8587 [D loss: 0.545880, acc.: 71.09%] [G loss: 0.511679]\n",
      "epoch:9 step:8588 [D loss: 0.489562, acc.: 73.44%] [G loss: 0.578006]\n",
      "epoch:9 step:8589 [D loss: 0.552261, acc.: 71.09%] [G loss: 0.633390]\n",
      "epoch:9 step:8590 [D loss: 0.616504, acc.: 63.28%] [G loss: 0.556067]\n",
      "epoch:9 step:8591 [D loss: 0.574423, acc.: 67.97%] [G loss: 0.432692]\n",
      "epoch:9 step:8592 [D loss: 0.511898, acc.: 75.78%] [G loss: 0.571080]\n",
      "epoch:9 step:8593 [D loss: 0.597108, acc.: 64.84%] [G loss: 0.799396]\n",
      "epoch:9 step:8594 [D loss: 0.542407, acc.: 71.88%] [G loss: 0.603885]\n",
      "epoch:9 step:8595 [D loss: 0.470118, acc.: 77.34%] [G loss: 0.692032]\n",
      "epoch:9 step:8596 [D loss: 0.541785, acc.: 73.44%] [G loss: 0.749317]\n",
      "epoch:9 step:8597 [D loss: 0.578812, acc.: 65.62%] [G loss: 0.627370]\n",
      "epoch:9 step:8598 [D loss: 0.532458, acc.: 71.88%] [G loss: 0.485566]\n",
      "epoch:9 step:8599 [D loss: 0.599900, acc.: 64.84%] [G loss: 0.573160]\n",
      "epoch:9 step:8600 [D loss: 0.522424, acc.: 70.31%] [G loss: 0.434036]\n",
      "##############\n",
      "[2.88013521 1.15704411 6.58154042 5.04781074 4.00792851 5.77809792\n",
      " 4.72355845 4.86440444 4.70095106 4.10242372]\n",
      "##########\n",
      "epoch:9 step:8601 [D loss: 0.528179, acc.: 67.19%] [G loss: 0.626962]\n",
      "epoch:9 step:8602 [D loss: 0.552976, acc.: 70.31%] [G loss: 0.447779]\n",
      "epoch:9 step:8603 [D loss: 0.546736, acc.: 67.19%] [G loss: 0.471397]\n",
      "epoch:9 step:8604 [D loss: 0.544933, acc.: 70.31%] [G loss: 0.473846]\n",
      "epoch:9 step:8605 [D loss: 0.516631, acc.: 75.00%] [G loss: 0.527184]\n",
      "epoch:9 step:8606 [D loss: 0.483719, acc.: 71.88%] [G loss: 0.662886]\n",
      "epoch:9 step:8607 [D loss: 0.612907, acc.: 64.84%] [G loss: 0.410711]\n",
      "epoch:9 step:8608 [D loss: 0.567401, acc.: 65.62%] [G loss: 0.489767]\n",
      "epoch:9 step:8609 [D loss: 0.527793, acc.: 75.78%] [G loss: 0.481034]\n",
      "epoch:9 step:8610 [D loss: 0.488332, acc.: 75.00%] [G loss: 0.593405]\n",
      "epoch:9 step:8611 [D loss: 0.595723, acc.: 66.41%] [G loss: 0.591315]\n",
      "epoch:9 step:8612 [D loss: 0.515053, acc.: 72.66%] [G loss: 0.553760]\n",
      "epoch:9 step:8613 [D loss: 0.648669, acc.: 64.06%] [G loss: 0.455219]\n",
      "epoch:9 step:8614 [D loss: 0.560964, acc.: 71.09%] [G loss: 0.513986]\n",
      "epoch:9 step:8615 [D loss: 0.553240, acc.: 71.09%] [G loss: 0.524336]\n",
      "epoch:9 step:8616 [D loss: 0.573172, acc.: 69.53%] [G loss: 0.596958]\n",
      "epoch:9 step:8617 [D loss: 0.605382, acc.: 64.84%] [G loss: 0.594616]\n",
      "epoch:9 step:8618 [D loss: 0.567858, acc.: 69.53%] [G loss: 0.575083]\n",
      "epoch:9 step:8619 [D loss: 0.566285, acc.: 68.75%] [G loss: 0.711421]\n",
      "epoch:9 step:8620 [D loss: 0.552772, acc.: 69.53%] [G loss: 0.598551]\n",
      "epoch:9 step:8621 [D loss: 0.583544, acc.: 69.53%] [G loss: 0.516036]\n",
      "epoch:9 step:8622 [D loss: 0.578744, acc.: 68.75%] [G loss: 0.404927]\n",
      "epoch:9 step:8623 [D loss: 0.475181, acc.: 77.34%] [G loss: 0.615433]\n",
      "epoch:9 step:8624 [D loss: 0.465703, acc.: 78.91%] [G loss: 0.656428]\n",
      "epoch:9 step:8625 [D loss: 0.536464, acc.: 71.09%] [G loss: 0.690597]\n",
      "epoch:9 step:8626 [D loss: 0.578755, acc.: 67.97%] [G loss: 0.533108]\n",
      "epoch:9 step:8627 [D loss: 0.480531, acc.: 78.91%] [G loss: 0.648216]\n",
      "epoch:9 step:8628 [D loss: 0.579409, acc.: 64.06%] [G loss: 0.558268]\n",
      "epoch:9 step:8629 [D loss: 0.599667, acc.: 64.06%] [G loss: 0.525616]\n",
      "epoch:9 step:8630 [D loss: 0.493326, acc.: 75.78%] [G loss: 0.704030]\n",
      "epoch:9 step:8631 [D loss: 0.515594, acc.: 70.31%] [G loss: 0.517135]\n",
      "epoch:9 step:8632 [D loss: 0.567149, acc.: 66.41%] [G loss: 0.551481]\n",
      "epoch:9 step:8633 [D loss: 0.597661, acc.: 64.84%] [G loss: 0.579506]\n",
      "epoch:9 step:8634 [D loss: 0.572709, acc.: 70.31%] [G loss: 0.581357]\n",
      "epoch:9 step:8635 [D loss: 0.509088, acc.: 71.88%] [G loss: 0.507356]\n",
      "epoch:9 step:8636 [D loss: 0.579396, acc.: 68.75%] [G loss: 0.495624]\n",
      "epoch:9 step:8637 [D loss: 0.511233, acc.: 75.78%] [G loss: 0.410928]\n",
      "epoch:9 step:8638 [D loss: 0.501353, acc.: 76.56%] [G loss: 0.514271]\n",
      "epoch:9 step:8639 [D loss: 0.523804, acc.: 74.22%] [G loss: 0.775373]\n",
      "epoch:9 step:8640 [D loss: 0.455123, acc.: 74.22%] [G loss: 0.790864]\n",
      "epoch:9 step:8641 [D loss: 0.448197, acc.: 79.69%] [G loss: 0.702102]\n",
      "epoch:9 step:8642 [D loss: 0.497203, acc.: 72.66%] [G loss: 0.567369]\n",
      "epoch:9 step:8643 [D loss: 0.580978, acc.: 66.41%] [G loss: 0.518156]\n",
      "epoch:9 step:8644 [D loss: 0.590809, acc.: 63.28%] [G loss: 0.481672]\n",
      "epoch:9 step:8645 [D loss: 0.562228, acc.: 67.97%] [G loss: 0.516341]\n",
      "epoch:9 step:8646 [D loss: 0.502415, acc.: 70.31%] [G loss: 0.624132]\n",
      "epoch:9 step:8647 [D loss: 0.637338, acc.: 62.50%] [G loss: 0.468839]\n",
      "epoch:9 step:8648 [D loss: 0.593043, acc.: 64.06%] [G loss: 0.377715]\n",
      "epoch:9 step:8649 [D loss: 0.546238, acc.: 71.09%] [G loss: 0.517993]\n",
      "epoch:9 step:8650 [D loss: 0.545907, acc.: 70.31%] [G loss: 0.604052]\n",
      "epoch:9 step:8651 [D loss: 0.528282, acc.: 71.09%] [G loss: 0.578281]\n",
      "epoch:9 step:8652 [D loss: 0.538280, acc.: 71.09%] [G loss: 0.645127]\n",
      "epoch:9 step:8653 [D loss: 0.610594, acc.: 66.41%] [G loss: 0.539595]\n",
      "epoch:9 step:8654 [D loss: 0.517422, acc.: 71.09%] [G loss: 0.632770]\n",
      "epoch:9 step:8655 [D loss: 0.482529, acc.: 77.34%] [G loss: 0.704217]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:9 step:8656 [D loss: 0.477253, acc.: 75.00%] [G loss: 0.848279]\n",
      "epoch:9 step:8657 [D loss: 0.550990, acc.: 74.22%] [G loss: 0.651000]\n",
      "epoch:9 step:8658 [D loss: 0.583126, acc.: 71.09%] [G loss: 0.538662]\n",
      "epoch:9 step:8659 [D loss: 0.604455, acc.: 66.41%] [G loss: 0.554682]\n",
      "epoch:9 step:8660 [D loss: 0.548579, acc.: 71.09%] [G loss: 0.571917]\n",
      "epoch:9 step:8661 [D loss: 0.604519, acc.: 58.59%] [G loss: 0.520274]\n",
      "epoch:9 step:8662 [D loss: 0.533035, acc.: 74.22%] [G loss: 0.411826]\n",
      "epoch:9 step:8663 [D loss: 0.575668, acc.: 67.97%] [G loss: 0.561971]\n",
      "epoch:9 step:8664 [D loss: 0.514520, acc.: 72.66%] [G loss: 0.638372]\n",
      "epoch:9 step:8665 [D loss: 0.440939, acc.: 81.25%] [G loss: 0.978330]\n",
      "epoch:9 step:8666 [D loss: 0.510568, acc.: 74.22%] [G loss: 0.730296]\n",
      "epoch:9 step:8667 [D loss: 0.561519, acc.: 71.88%] [G loss: 0.570299]\n",
      "epoch:9 step:8668 [D loss: 0.582410, acc.: 64.84%] [G loss: 0.463103]\n",
      "epoch:9 step:8669 [D loss: 0.528011, acc.: 77.34%] [G loss: 0.546566]\n",
      "epoch:9 step:8670 [D loss: 0.552416, acc.: 68.75%] [G loss: 0.643026]\n",
      "epoch:9 step:8671 [D loss: 0.509007, acc.: 76.56%] [G loss: 0.552658]\n",
      "epoch:9 step:8672 [D loss: 0.519694, acc.: 73.44%] [G loss: 0.570457]\n",
      "epoch:9 step:8673 [D loss: 0.533392, acc.: 69.53%] [G loss: 0.585771]\n",
      "epoch:9 step:8674 [D loss: 0.523388, acc.: 75.00%] [G loss: 0.661017]\n",
      "epoch:9 step:8675 [D loss: 0.526697, acc.: 70.31%] [G loss: 0.553357]\n",
      "epoch:9 step:8676 [D loss: 0.532654, acc.: 67.97%] [G loss: 0.546157]\n",
      "epoch:9 step:8677 [D loss: 0.485842, acc.: 71.88%] [G loss: 0.566140]\n",
      "epoch:9 step:8678 [D loss: 0.514461, acc.: 73.44%] [G loss: 0.609004]\n",
      "epoch:9 step:8679 [D loss: 0.562351, acc.: 67.19%] [G loss: 0.685613]\n",
      "epoch:9 step:8680 [D loss: 0.550846, acc.: 72.66%] [G loss: 0.657434]\n",
      "epoch:9 step:8681 [D loss: 0.531428, acc.: 71.09%] [G loss: 0.701453]\n",
      "epoch:9 step:8682 [D loss: 0.538130, acc.: 70.31%] [G loss: 0.621144]\n",
      "epoch:9 step:8683 [D loss: 0.644876, acc.: 61.72%] [G loss: 0.618617]\n",
      "epoch:9 step:8684 [D loss: 0.644572, acc.: 62.50%] [G loss: 0.617364]\n",
      "epoch:9 step:8685 [D loss: 0.587845, acc.: 67.97%] [G loss: 0.603325]\n",
      "epoch:9 step:8686 [D loss: 0.558550, acc.: 72.66%] [G loss: 0.563012]\n",
      "epoch:9 step:8687 [D loss: 0.518228, acc.: 67.97%] [G loss: 0.543334]\n",
      "epoch:9 step:8688 [D loss: 0.498961, acc.: 75.00%] [G loss: 0.611631]\n",
      "epoch:9 step:8689 [D loss: 0.560756, acc.: 61.72%] [G loss: 0.581333]\n",
      "epoch:9 step:8690 [D loss: 0.603209, acc.: 60.94%] [G loss: 0.469045]\n",
      "epoch:9 step:8691 [D loss: 0.517801, acc.: 72.66%] [G loss: 0.634565]\n",
      "epoch:9 step:8692 [D loss: 0.543934, acc.: 69.53%] [G loss: 0.562356]\n",
      "epoch:9 step:8693 [D loss: 0.592115, acc.: 64.06%] [G loss: 0.438747]\n",
      "epoch:9 step:8694 [D loss: 0.515609, acc.: 76.56%] [G loss: 0.462233]\n",
      "epoch:9 step:8695 [D loss: 0.536586, acc.: 73.44%] [G loss: 0.456548]\n",
      "epoch:9 step:8696 [D loss: 0.599643, acc.: 68.75%] [G loss: 0.516514]\n",
      "epoch:9 step:8697 [D loss: 0.498189, acc.: 76.56%] [G loss: 0.638520]\n",
      "epoch:9 step:8698 [D loss: 0.607542, acc.: 64.84%] [G loss: 0.514018]\n",
      "epoch:9 step:8699 [D loss: 0.548500, acc.: 71.09%] [G loss: 0.527370]\n",
      "epoch:9 step:8700 [D loss: 0.561215, acc.: 69.53%] [G loss: 0.452138]\n",
      "epoch:9 step:8701 [D loss: 0.582853, acc.: 66.41%] [G loss: 0.469087]\n",
      "epoch:9 step:8702 [D loss: 0.567533, acc.: 67.97%] [G loss: 0.487834]\n",
      "epoch:9 step:8703 [D loss: 0.512023, acc.: 75.78%] [G loss: 0.510457]\n",
      "epoch:9 step:8704 [D loss: 0.520175, acc.: 69.53%] [G loss: 0.653679]\n",
      "epoch:9 step:8705 [D loss: 0.580489, acc.: 67.97%] [G loss: 0.613301]\n",
      "epoch:9 step:8706 [D loss: 0.533801, acc.: 70.31%] [G loss: 0.509673]\n",
      "epoch:9 step:8707 [D loss: 0.526450, acc.: 75.00%] [G loss: 0.580010]\n",
      "epoch:9 step:8708 [D loss: 0.574674, acc.: 71.88%] [G loss: 0.521881]\n",
      "epoch:9 step:8709 [D loss: 0.507349, acc.: 78.12%] [G loss: 0.519779]\n",
      "epoch:9 step:8710 [D loss: 0.637633, acc.: 64.84%] [G loss: 0.469480]\n",
      "epoch:9 step:8711 [D loss: 0.644670, acc.: 60.94%] [G loss: 0.434113]\n",
      "epoch:9 step:8712 [D loss: 0.543990, acc.: 70.31%] [G loss: 0.661994]\n",
      "epoch:9 step:8713 [D loss: 0.593249, acc.: 60.16%] [G loss: 0.473310]\n",
      "epoch:9 step:8714 [D loss: 0.583517, acc.: 70.31%] [G loss: 0.484725]\n",
      "epoch:9 step:8715 [D loss: 0.561638, acc.: 71.09%] [G loss: 0.513415]\n",
      "epoch:9 step:8716 [D loss: 0.504416, acc.: 75.00%] [G loss: 0.554110]\n",
      "epoch:9 step:8717 [D loss: 0.553832, acc.: 66.41%] [G loss: 0.564009]\n",
      "epoch:9 step:8718 [D loss: 0.508487, acc.: 69.53%] [G loss: 0.568858]\n",
      "epoch:9 step:8719 [D loss: 0.534038, acc.: 71.88%] [G loss: 0.639566]\n",
      "epoch:9 step:8720 [D loss: 0.578225, acc.: 62.50%] [G loss: 0.476800]\n",
      "epoch:9 step:8721 [D loss: 0.596037, acc.: 67.19%] [G loss: 0.527183]\n",
      "epoch:9 step:8722 [D loss: 0.600028, acc.: 63.28%] [G loss: 0.541405]\n",
      "epoch:9 step:8723 [D loss: 0.579434, acc.: 69.53%] [G loss: 0.427332]\n",
      "epoch:9 step:8724 [D loss: 0.564553, acc.: 70.31%] [G loss: 0.489717]\n",
      "epoch:9 step:8725 [D loss: 0.531252, acc.: 71.09%] [G loss: 0.493570]\n",
      "epoch:9 step:8726 [D loss: 0.554884, acc.: 65.62%] [G loss: 0.462946]\n",
      "epoch:9 step:8727 [D loss: 0.604608, acc.: 65.62%] [G loss: 0.391337]\n",
      "epoch:9 step:8728 [D loss: 0.554619, acc.: 65.62%] [G loss: 0.453678]\n",
      "epoch:9 step:8729 [D loss: 0.504128, acc.: 75.00%] [G loss: 0.540354]\n",
      "epoch:9 step:8730 [D loss: 0.545505, acc.: 67.97%] [G loss: 0.579937]\n",
      "epoch:9 step:8731 [D loss: 0.474598, acc.: 81.25%] [G loss: 0.647985]\n",
      "epoch:9 step:8732 [D loss: 0.493460, acc.: 74.22%] [G loss: 0.693404]\n",
      "epoch:9 step:8733 [D loss: 0.517826, acc.: 74.22%] [G loss: 0.648204]\n",
      "epoch:9 step:8734 [D loss: 0.615426, acc.: 63.28%] [G loss: 0.514760]\n",
      "epoch:9 step:8735 [D loss: 0.470389, acc.: 75.78%] [G loss: 0.534629]\n",
      "epoch:9 step:8736 [D loss: 0.532601, acc.: 74.22%] [G loss: 0.600878]\n",
      "epoch:9 step:8737 [D loss: 0.481062, acc.: 75.78%] [G loss: 0.610511]\n",
      "epoch:9 step:8738 [D loss: 0.500937, acc.: 74.22%] [G loss: 0.516785]\n",
      "epoch:9 step:8739 [D loss: 0.550477, acc.: 71.88%] [G loss: 0.769329]\n",
      "epoch:9 step:8740 [D loss: 0.461082, acc.: 78.12%] [G loss: 0.672119]\n",
      "epoch:9 step:8741 [D loss: 0.564536, acc.: 67.97%] [G loss: 0.521429]\n",
      "epoch:9 step:8742 [D loss: 0.494477, acc.: 71.88%] [G loss: 0.690847]\n",
      "epoch:9 step:8743 [D loss: 0.514135, acc.: 71.09%] [G loss: 0.610632]\n",
      "epoch:9 step:8744 [D loss: 0.521030, acc.: 69.53%] [G loss: 0.750445]\n",
      "epoch:9 step:8745 [D loss: 0.459798, acc.: 78.91%] [G loss: 0.774929]\n",
      "epoch:9 step:8746 [D loss: 0.536355, acc.: 75.78%] [G loss: 0.903450]\n",
      "epoch:9 step:8747 [D loss: 0.439681, acc.: 78.12%] [G loss: 0.860122]\n",
      "epoch:9 step:8748 [D loss: 0.472483, acc.: 76.56%] [G loss: 0.848001]\n",
      "epoch:9 step:8749 [D loss: 0.742902, acc.: 63.28%] [G loss: 0.680889]\n",
      "epoch:9 step:8750 [D loss: 0.615544, acc.: 61.72%] [G loss: 0.558000]\n",
      "epoch:9 step:8751 [D loss: 0.507014, acc.: 73.44%] [G loss: 0.655424]\n",
      "epoch:9 step:8752 [D loss: 0.539197, acc.: 71.09%] [G loss: 0.603697]\n",
      "epoch:9 step:8753 [D loss: 0.528874, acc.: 79.69%] [G loss: 0.534024]\n",
      "epoch:9 step:8754 [D loss: 0.487735, acc.: 81.25%] [G loss: 0.663674]\n",
      "epoch:9 step:8755 [D loss: 0.575687, acc.: 64.06%] [G loss: 0.507983]\n",
      "epoch:9 step:8756 [D loss: 0.576311, acc.: 67.97%] [G loss: 0.479560]\n",
      "epoch:9 step:8757 [D loss: 0.554378, acc.: 73.44%] [G loss: 0.493367]\n",
      "epoch:9 step:8758 [D loss: 0.561049, acc.: 72.66%] [G loss: 0.610807]\n",
      "epoch:9 step:8759 [D loss: 0.470143, acc.: 77.34%] [G loss: 0.633798]\n",
      "epoch:9 step:8760 [D loss: 0.547518, acc.: 70.31%] [G loss: 0.557124]\n",
      "epoch:9 step:8761 [D loss: 0.443424, acc.: 82.03%] [G loss: 0.768494]\n",
      "epoch:9 step:8762 [D loss: 0.501341, acc.: 75.78%] [G loss: 0.666183]\n",
      "epoch:9 step:8763 [D loss: 0.585742, acc.: 68.75%] [G loss: 0.423393]\n",
      "epoch:9 step:8764 [D loss: 0.589341, acc.: 64.84%] [G loss: 0.410095]\n",
      "epoch:9 step:8765 [D loss: 0.517715, acc.: 74.22%] [G loss: 0.578531]\n",
      "epoch:9 step:8766 [D loss: 0.490280, acc.: 73.44%] [G loss: 0.593233]\n",
      "epoch:9 step:8767 [D loss: 0.538816, acc.: 72.66%] [G loss: 0.683925]\n",
      "epoch:9 step:8768 [D loss: 0.509284, acc.: 71.88%] [G loss: 0.648960]\n",
      "epoch:9 step:8769 [D loss: 0.563667, acc.: 71.09%] [G loss: 0.599007]\n",
      "epoch:9 step:8770 [D loss: 0.462508, acc.: 78.91%] [G loss: 0.614042]\n",
      "epoch:9 step:8771 [D loss: 0.551305, acc.: 70.31%] [G loss: 0.553441]\n",
      "epoch:9 step:8772 [D loss: 0.528830, acc.: 75.78%] [G loss: 0.717412]\n",
      "epoch:9 step:8773 [D loss: 0.512785, acc.: 73.44%] [G loss: 0.598115]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:9 step:8774 [D loss: 0.600493, acc.: 68.75%] [G loss: 0.430196]\n",
      "epoch:9 step:8775 [D loss: 0.668629, acc.: 53.12%] [G loss: 0.549720]\n",
      "epoch:9 step:8776 [D loss: 0.480988, acc.: 78.12%] [G loss: 0.693733]\n",
      "epoch:9 step:8777 [D loss: 0.523902, acc.: 69.53%] [G loss: 0.672387]\n",
      "epoch:9 step:8778 [D loss: 0.559278, acc.: 68.75%] [G loss: 0.649641]\n",
      "epoch:9 step:8779 [D loss: 0.553007, acc.: 71.88%] [G loss: 0.747863]\n",
      "epoch:9 step:8780 [D loss: 0.432941, acc.: 85.94%] [G loss: 0.869034]\n",
      "epoch:9 step:8781 [D loss: 0.599082, acc.: 67.97%] [G loss: 0.671478]\n",
      "epoch:9 step:8782 [D loss: 0.751570, acc.: 55.47%] [G loss: 0.488689]\n",
      "epoch:9 step:8783 [D loss: 0.512559, acc.: 72.66%] [G loss: 0.530540]\n",
      "epoch:9 step:8784 [D loss: 0.504407, acc.: 79.69%] [G loss: 0.499974]\n",
      "epoch:9 step:8785 [D loss: 0.582959, acc.: 64.06%] [G loss: 0.644533]\n",
      "epoch:9 step:8786 [D loss: 0.616453, acc.: 63.28%] [G loss: 0.577970]\n",
      "epoch:9 step:8787 [D loss: 0.416091, acc.: 82.81%] [G loss: 0.899947]\n",
      "epoch:9 step:8788 [D loss: 0.567947, acc.: 69.53%] [G loss: 0.674629]\n",
      "epoch:9 step:8789 [D loss: 0.654871, acc.: 64.06%] [G loss: 0.577805]\n",
      "epoch:9 step:8790 [D loss: 0.509629, acc.: 69.53%] [G loss: 0.516504]\n",
      "epoch:9 step:8791 [D loss: 0.503386, acc.: 74.22%] [G loss: 0.780176]\n",
      "epoch:9 step:8792 [D loss: 0.502976, acc.: 75.00%] [G loss: 0.783183]\n",
      "epoch:9 step:8793 [D loss: 0.479922, acc.: 76.56%] [G loss: 0.769693]\n",
      "epoch:9 step:8794 [D loss: 0.519519, acc.: 74.22%] [G loss: 0.687195]\n",
      "epoch:9 step:8795 [D loss: 0.560926, acc.: 73.44%] [G loss: 0.495227]\n",
      "epoch:9 step:8796 [D loss: 0.515927, acc.: 79.69%] [G loss: 0.545876]\n",
      "epoch:9 step:8797 [D loss: 0.538790, acc.: 67.19%] [G loss: 0.556029]\n",
      "epoch:9 step:8798 [D loss: 0.604201, acc.: 65.62%] [G loss: 0.651855]\n",
      "epoch:9 step:8799 [D loss: 0.535404, acc.: 70.31%] [G loss: 0.752881]\n",
      "epoch:9 step:8800 [D loss: 0.618901, acc.: 65.62%] [G loss: 0.647388]\n",
      "##############\n",
      "[3.15775608 1.68834528 6.5421312  5.10005873 3.90585344 5.75322696\n",
      " 4.80249456 4.77861494 4.69166821 3.85012449]\n",
      "##########\n",
      "epoch:9 step:8801 [D loss: 0.591277, acc.: 63.28%] [G loss: 0.538371]\n",
      "epoch:9 step:8802 [D loss: 0.531409, acc.: 73.44%] [G loss: 0.484201]\n",
      "epoch:9 step:8803 [D loss: 0.521746, acc.: 75.00%] [G loss: 0.563194]\n",
      "epoch:9 step:8804 [D loss: 0.550449, acc.: 73.44%] [G loss: 0.638543]\n",
      "epoch:9 step:8805 [D loss: 0.535603, acc.: 69.53%] [G loss: 0.675763]\n",
      "epoch:9 step:8806 [D loss: 0.572077, acc.: 65.62%] [G loss: 0.502363]\n",
      "epoch:9 step:8807 [D loss: 0.479520, acc.: 74.22%] [G loss: 0.567851]\n",
      "epoch:9 step:8808 [D loss: 0.560973, acc.: 72.66%] [G loss: 0.647931]\n",
      "epoch:9 step:8809 [D loss: 0.799858, acc.: 53.91%] [G loss: 0.398102]\n",
      "epoch:9 step:8810 [D loss: 0.570522, acc.: 67.19%] [G loss: 0.388785]\n",
      "epoch:9 step:8811 [D loss: 0.520345, acc.: 72.66%] [G loss: 0.593438]\n",
      "epoch:9 step:8812 [D loss: 0.623994, acc.: 62.50%] [G loss: 0.512802]\n",
      "epoch:9 step:8813 [D loss: 0.577970, acc.: 65.62%] [G loss: 0.432641]\n",
      "epoch:9 step:8814 [D loss: 0.488146, acc.: 74.22%] [G loss: 0.552870]\n",
      "epoch:9 step:8815 [D loss: 0.536956, acc.: 69.53%] [G loss: 0.593527]\n",
      "epoch:9 step:8816 [D loss: 0.580397, acc.: 64.84%] [G loss: 0.548977]\n",
      "epoch:9 step:8817 [D loss: 0.573221, acc.: 68.75%] [G loss: 0.573363]\n",
      "epoch:9 step:8818 [D loss: 0.493155, acc.: 78.91%] [G loss: 0.588810]\n",
      "epoch:9 step:8819 [D loss: 0.586694, acc.: 67.97%] [G loss: 0.507974]\n",
      "epoch:9 step:8820 [D loss: 0.558378, acc.: 64.84%] [G loss: 0.521977]\n",
      "epoch:9 step:8821 [D loss: 0.652765, acc.: 59.38%] [G loss: 0.372464]\n",
      "epoch:9 step:8822 [D loss: 0.542385, acc.: 71.09%] [G loss: 0.504804]\n",
      "epoch:9 step:8823 [D loss: 0.546767, acc.: 68.75%] [G loss: 0.521380]\n",
      "epoch:9 step:8824 [D loss: 0.557060, acc.: 68.75%] [G loss: 0.464244]\n",
      "epoch:9 step:8825 [D loss: 0.518977, acc.: 69.53%] [G loss: 0.515764]\n",
      "epoch:9 step:8826 [D loss: 0.580953, acc.: 67.19%] [G loss: 0.426988]\n",
      "epoch:9 step:8827 [D loss: 0.557106, acc.: 69.53%] [G loss: 0.391258]\n",
      "epoch:9 step:8828 [D loss: 0.484747, acc.: 77.34%] [G loss: 0.574599]\n",
      "epoch:9 step:8829 [D loss: 0.641732, acc.: 64.06%] [G loss: 0.576805]\n",
      "epoch:9 step:8830 [D loss: 0.553724, acc.: 66.41%] [G loss: 0.614616]\n",
      "epoch:9 step:8831 [D loss: 0.527710, acc.: 69.53%] [G loss: 0.697571]\n",
      "epoch:9 step:8832 [D loss: 0.491633, acc.: 77.34%] [G loss: 0.644711]\n",
      "epoch:9 step:8833 [D loss: 0.623578, acc.: 60.94%] [G loss: 0.669825]\n",
      "epoch:9 step:8834 [D loss: 0.631617, acc.: 65.62%] [G loss: 0.543558]\n",
      "epoch:9 step:8835 [D loss: 0.616367, acc.: 60.94%] [G loss: 0.697980]\n",
      "epoch:9 step:8836 [D loss: 0.464189, acc.: 82.03%] [G loss: 0.785778]\n",
      "epoch:9 step:8837 [D loss: 0.562443, acc.: 69.53%] [G loss: 0.652930]\n",
      "epoch:9 step:8838 [D loss: 0.611009, acc.: 61.72%] [G loss: 0.524522]\n",
      "epoch:9 step:8839 [D loss: 0.542642, acc.: 71.88%] [G loss: 0.612832]\n",
      "epoch:9 step:8840 [D loss: 0.550567, acc.: 68.75%] [G loss: 0.731132]\n",
      "epoch:9 step:8841 [D loss: 0.572901, acc.: 71.09%] [G loss: 0.579898]\n",
      "epoch:9 step:8842 [D loss: 0.570741, acc.: 67.97%] [G loss: 0.566285]\n",
      "epoch:9 step:8843 [D loss: 0.619469, acc.: 63.28%] [G loss: 0.611689]\n",
      "epoch:9 step:8844 [D loss: 0.553417, acc.: 65.62%] [G loss: 0.636113]\n",
      "epoch:9 step:8845 [D loss: 0.628868, acc.: 62.50%] [G loss: 0.500489]\n",
      "epoch:9 step:8846 [D loss: 0.557894, acc.: 66.41%] [G loss: 0.475904]\n",
      "epoch:9 step:8847 [D loss: 0.504125, acc.: 71.88%] [G loss: 0.513812]\n",
      "epoch:9 step:8848 [D loss: 0.549999, acc.: 69.53%] [G loss: 0.641737]\n",
      "epoch:9 step:8849 [D loss: 0.522261, acc.: 71.88%] [G loss: 0.703107]\n",
      "epoch:9 step:8850 [D loss: 0.590860, acc.: 67.97%] [G loss: 0.551079]\n",
      "epoch:9 step:8851 [D loss: 0.621623, acc.: 64.84%] [G loss: 0.403407]\n",
      "epoch:9 step:8852 [D loss: 0.614446, acc.: 60.94%] [G loss: 0.520320]\n",
      "epoch:9 step:8853 [D loss: 0.558431, acc.: 66.41%] [G loss: 0.645053]\n",
      "epoch:9 step:8854 [D loss: 0.585197, acc.: 65.62%] [G loss: 0.580946]\n",
      "epoch:9 step:8855 [D loss: 0.603907, acc.: 65.62%] [G loss: 0.496017]\n",
      "epoch:9 step:8856 [D loss: 0.563683, acc.: 71.88%] [G loss: 0.572524]\n",
      "epoch:9 step:8857 [D loss: 0.570639, acc.: 71.09%] [G loss: 0.562560]\n",
      "epoch:9 step:8858 [D loss: 0.549193, acc.: 69.53%] [G loss: 0.681544]\n",
      "epoch:9 step:8859 [D loss: 0.488955, acc.: 76.56%] [G loss: 0.652462]\n",
      "epoch:9 step:8860 [D loss: 0.453106, acc.: 79.69%] [G loss: 0.796118]\n",
      "epoch:9 step:8861 [D loss: 0.536489, acc.: 70.31%] [G loss: 0.679359]\n",
      "epoch:9 step:8862 [D loss: 0.450274, acc.: 78.91%] [G loss: 0.706496]\n",
      "epoch:9 step:8863 [D loss: 0.533025, acc.: 73.44%] [G loss: 0.700123]\n",
      "epoch:9 step:8864 [D loss: 0.544670, acc.: 71.09%] [G loss: 0.632152]\n",
      "epoch:9 step:8865 [D loss: 0.606792, acc.: 66.41%] [G loss: 0.610517]\n",
      "epoch:9 step:8866 [D loss: 0.581089, acc.: 67.97%] [G loss: 0.405623]\n",
      "epoch:9 step:8867 [D loss: 0.502496, acc.: 77.34%] [G loss: 0.593758]\n",
      "epoch:9 step:8868 [D loss: 0.596168, acc.: 71.88%] [G loss: 0.560324]\n",
      "epoch:9 step:8869 [D loss: 0.498734, acc.: 72.66%] [G loss: 0.572142]\n",
      "epoch:9 step:8870 [D loss: 0.629987, acc.: 69.53%] [G loss: 0.504892]\n",
      "epoch:9 step:8871 [D loss: 0.558793, acc.: 66.41%] [G loss: 0.657362]\n",
      "epoch:9 step:8872 [D loss: 0.482998, acc.: 76.56%] [G loss: 0.735448]\n",
      "epoch:9 step:8873 [D loss: 0.513556, acc.: 74.22%] [G loss: 0.785972]\n",
      "epoch:9 step:8874 [D loss: 0.574733, acc.: 67.97%] [G loss: 0.581575]\n",
      "epoch:9 step:8875 [D loss: 0.530336, acc.: 71.09%] [G loss: 0.569861]\n",
      "epoch:9 step:8876 [D loss: 0.524538, acc.: 75.78%] [G loss: 0.523030]\n",
      "epoch:9 step:8877 [D loss: 0.532209, acc.: 74.22%] [G loss: 0.667702]\n",
      "epoch:9 step:8878 [D loss: 0.538831, acc.: 71.09%] [G loss: 0.714849]\n",
      "epoch:9 step:8879 [D loss: 0.589417, acc.: 66.41%] [G loss: 0.619032]\n",
      "epoch:9 step:8880 [D loss: 0.532071, acc.: 67.97%] [G loss: 0.728231]\n",
      "epoch:9 step:8881 [D loss: 0.602609, acc.: 65.62%] [G loss: 0.645332]\n",
      "epoch:9 step:8882 [D loss: 0.501606, acc.: 75.78%] [G loss: 0.740325]\n",
      "epoch:9 step:8883 [D loss: 0.497577, acc.: 72.66%] [G loss: 0.641755]\n",
      "epoch:9 step:8884 [D loss: 0.420956, acc.: 82.03%] [G loss: 0.933090]\n",
      "epoch:9 step:8885 [D loss: 0.514847, acc.: 78.12%] [G loss: 0.795580]\n",
      "epoch:9 step:8886 [D loss: 0.603694, acc.: 67.19%] [G loss: 0.733145]\n",
      "epoch:9 step:8887 [D loss: 0.588296, acc.: 70.31%] [G loss: 0.594266]\n",
      "epoch:9 step:8888 [D loss: 0.552382, acc.: 67.19%] [G loss: 0.581618]\n",
      "epoch:9 step:8889 [D loss: 0.662640, acc.: 58.59%] [G loss: 0.497077]\n",
      "epoch:9 step:8890 [D loss: 0.522055, acc.: 73.44%] [G loss: 0.579306]\n",
      "epoch:9 step:8891 [D loss: 0.712370, acc.: 57.81%] [G loss: 0.445799]\n",
      "epoch:9 step:8892 [D loss: 0.543901, acc.: 71.88%] [G loss: 0.544144]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:9 step:8893 [D loss: 0.527371, acc.: 71.09%] [G loss: 0.591606]\n",
      "epoch:9 step:8894 [D loss: 0.535864, acc.: 71.88%] [G loss: 0.689176]\n",
      "epoch:9 step:8895 [D loss: 0.593805, acc.: 67.19%] [G loss: 0.499524]\n",
      "epoch:9 step:8896 [D loss: 0.563180, acc.: 70.31%] [G loss: 0.543261]\n",
      "epoch:9 step:8897 [D loss: 0.518058, acc.: 76.56%] [G loss: 0.513301]\n",
      "epoch:9 step:8898 [D loss: 0.644936, acc.: 60.94%] [G loss: 0.577358]\n",
      "epoch:9 step:8899 [D loss: 0.584203, acc.: 68.75%] [G loss: 0.501694]\n",
      "epoch:9 step:8900 [D loss: 0.488642, acc.: 78.12%] [G loss: 0.601220]\n",
      "epoch:9 step:8901 [D loss: 0.587988, acc.: 67.97%] [G loss: 0.524427]\n",
      "epoch:9 step:8902 [D loss: 0.528482, acc.: 74.22%] [G loss: 0.700985]\n",
      "epoch:9 step:8903 [D loss: 0.581336, acc.: 68.75%] [G loss: 0.539386]\n",
      "epoch:9 step:8904 [D loss: 0.455743, acc.: 76.56%] [G loss: 0.678655]\n",
      "epoch:9 step:8905 [D loss: 0.416355, acc.: 87.50%] [G loss: 0.856037]\n",
      "epoch:9 step:8906 [D loss: 0.666001, acc.: 58.59%] [G loss: 0.627561]\n",
      "epoch:9 step:8907 [D loss: 0.568174, acc.: 64.06%] [G loss: 0.667516]\n",
      "epoch:9 step:8908 [D loss: 0.545742, acc.: 71.88%] [G loss: 0.738945]\n",
      "epoch:9 step:8909 [D loss: 0.547608, acc.: 71.09%] [G loss: 0.721325]\n",
      "epoch:9 step:8910 [D loss: 0.631825, acc.: 64.06%] [G loss: 0.444733]\n",
      "epoch:9 step:8911 [D loss: 0.580642, acc.: 64.84%] [G loss: 0.360204]\n",
      "epoch:9 step:8912 [D loss: 0.523051, acc.: 72.66%] [G loss: 0.463366]\n",
      "epoch:9 step:8913 [D loss: 0.591635, acc.: 69.53%] [G loss: 0.471961]\n",
      "epoch:9 step:8914 [D loss: 0.506017, acc.: 78.12%] [G loss: 0.481573]\n",
      "epoch:9 step:8915 [D loss: 0.630315, acc.: 58.59%] [G loss: 0.459174]\n",
      "epoch:9 step:8916 [D loss: 0.572355, acc.: 66.41%] [G loss: 0.385253]\n",
      "epoch:9 step:8917 [D loss: 0.494400, acc.: 78.12%] [G loss: 0.528944]\n",
      "epoch:9 step:8918 [D loss: 0.521358, acc.: 73.44%] [G loss: 0.552682]\n",
      "epoch:9 step:8919 [D loss: 0.561005, acc.: 68.75%] [G loss: 0.616563]\n",
      "epoch:9 step:8920 [D loss: 0.525976, acc.: 72.66%] [G loss: 0.585553]\n",
      "epoch:9 step:8921 [D loss: 0.520742, acc.: 67.97%] [G loss: 0.581788]\n",
      "epoch:9 step:8922 [D loss: 0.578873, acc.: 67.97%] [G loss: 0.682880]\n",
      "epoch:9 step:8923 [D loss: 0.592611, acc.: 67.19%] [G loss: 0.550098]\n",
      "epoch:9 step:8924 [D loss: 0.523921, acc.: 76.56%] [G loss: 0.631209]\n",
      "epoch:9 step:8925 [D loss: 0.577177, acc.: 66.41%] [G loss: 0.529743]\n",
      "epoch:9 step:8926 [D loss: 0.585576, acc.: 65.62%] [G loss: 0.418588]\n",
      "epoch:9 step:8927 [D loss: 0.581658, acc.: 71.09%] [G loss: 0.520979]\n",
      "epoch:9 step:8928 [D loss: 0.528956, acc.: 75.78%] [G loss: 0.603240]\n",
      "epoch:9 step:8929 [D loss: 0.578179, acc.: 71.09%] [G loss: 0.494841]\n",
      "epoch:9 step:8930 [D loss: 0.586132, acc.: 68.75%] [G loss: 0.468011]\n",
      "epoch:9 step:8931 [D loss: 0.475516, acc.: 78.12%] [G loss: 0.603891]\n",
      "epoch:9 step:8932 [D loss: 0.470991, acc.: 82.03%] [G loss: 0.710061]\n",
      "epoch:9 step:8933 [D loss: 0.580034, acc.: 64.84%] [G loss: 0.597469]\n",
      "epoch:9 step:8934 [D loss: 0.667774, acc.: 63.28%] [G loss: 0.584258]\n",
      "epoch:9 step:8935 [D loss: 0.657656, acc.: 56.25%] [G loss: 0.386586]\n",
      "epoch:9 step:8936 [D loss: 0.492498, acc.: 82.03%] [G loss: 0.480197]\n",
      "epoch:9 step:8937 [D loss: 0.494993, acc.: 78.91%] [G loss: 0.594450]\n",
      "epoch:9 step:8938 [D loss: 0.477246, acc.: 77.34%] [G loss: 0.675653]\n",
      "epoch:9 step:8939 [D loss: 0.538598, acc.: 72.66%] [G loss: 0.691775]\n",
      "epoch:9 step:8940 [D loss: 0.537278, acc.: 69.53%] [G loss: 0.743048]\n",
      "epoch:9 step:8941 [D loss: 0.419171, acc.: 83.59%] [G loss: 0.699118]\n",
      "epoch:9 step:8942 [D loss: 0.545259, acc.: 71.88%] [G loss: 0.686933]\n",
      "epoch:9 step:8943 [D loss: 0.621308, acc.: 63.28%] [G loss: 0.534917]\n",
      "epoch:9 step:8944 [D loss: 0.608396, acc.: 62.50%] [G loss: 0.476757]\n",
      "epoch:9 step:8945 [D loss: 0.572709, acc.: 69.53%] [G loss: 0.571250]\n",
      "epoch:9 step:8946 [D loss: 0.566226, acc.: 66.41%] [G loss: 0.566205]\n",
      "epoch:9 step:8947 [D loss: 0.458261, acc.: 79.69%] [G loss: 0.608079]\n",
      "epoch:9 step:8948 [D loss: 0.503639, acc.: 72.66%] [G loss: 0.658153]\n",
      "epoch:9 step:8949 [D loss: 0.492856, acc.: 75.00%] [G loss: 0.732031]\n",
      "epoch:9 step:8950 [D loss: 0.519022, acc.: 71.88%] [G loss: 0.653245]\n",
      "epoch:9 step:8951 [D loss: 0.520672, acc.: 72.66%] [G loss: 0.729883]\n",
      "epoch:9 step:8952 [D loss: 0.535583, acc.: 71.88%] [G loss: 0.623172]\n",
      "epoch:9 step:8953 [D loss: 0.481727, acc.: 75.00%] [G loss: 0.570377]\n",
      "epoch:9 step:8954 [D loss: 0.557848, acc.: 70.31%] [G loss: 0.656906]\n",
      "epoch:9 step:8955 [D loss: 0.483812, acc.: 78.91%] [G loss: 0.605194]\n",
      "epoch:9 step:8956 [D loss: 0.525462, acc.: 71.88%] [G loss: 0.616159]\n",
      "epoch:9 step:8957 [D loss: 0.509906, acc.: 70.31%] [G loss: 0.625295]\n",
      "epoch:9 step:8958 [D loss: 0.562644, acc.: 70.31%] [G loss: 0.540466]\n",
      "epoch:9 step:8959 [D loss: 0.541863, acc.: 71.88%] [G loss: 0.697338]\n",
      "epoch:9 step:8960 [D loss: 0.607875, acc.: 68.75%] [G loss: 0.587300]\n",
      "epoch:9 step:8961 [D loss: 0.660321, acc.: 60.16%] [G loss: 0.586072]\n",
      "epoch:9 step:8962 [D loss: 0.573839, acc.: 67.97%] [G loss: 0.486544]\n",
      "epoch:9 step:8963 [D loss: 0.527926, acc.: 71.88%] [G loss: 0.767889]\n",
      "epoch:9 step:8964 [D loss: 0.544643, acc.: 71.88%] [G loss: 0.535529]\n",
      "epoch:9 step:8965 [D loss: 0.582125, acc.: 66.41%] [G loss: 0.478997]\n",
      "epoch:9 step:8966 [D loss: 0.597892, acc.: 67.97%] [G loss: 0.611775]\n",
      "epoch:9 step:8967 [D loss: 0.488333, acc.: 77.34%] [G loss: 0.663465]\n",
      "epoch:9 step:8968 [D loss: 0.606196, acc.: 66.41%] [G loss: 0.560476]\n",
      "epoch:9 step:8969 [D loss: 0.532491, acc.: 72.66%] [G loss: 0.509794]\n",
      "epoch:9 step:8970 [D loss: 0.573543, acc.: 70.31%] [G loss: 0.596357]\n",
      "epoch:9 step:8971 [D loss: 0.622982, acc.: 60.94%] [G loss: 0.448351]\n",
      "epoch:9 step:8972 [D loss: 0.564208, acc.: 67.19%] [G loss: 0.493574]\n",
      "epoch:9 step:8973 [D loss: 0.545135, acc.: 69.53%] [G loss: 0.432031]\n",
      "epoch:9 step:8974 [D loss: 0.518245, acc.: 71.88%] [G loss: 0.495906]\n",
      "epoch:9 step:8975 [D loss: 0.630946, acc.: 64.84%] [G loss: 0.470544]\n",
      "epoch:9 step:8976 [D loss: 0.618094, acc.: 63.28%] [G loss: 0.595188]\n",
      "epoch:9 step:8977 [D loss: 0.586823, acc.: 72.66%] [G loss: 0.597282]\n",
      "epoch:9 step:8978 [D loss: 0.560792, acc.: 73.44%] [G loss: 0.584402]\n",
      "epoch:9 step:8979 [D loss: 0.518049, acc.: 72.66%] [G loss: 0.588435]\n",
      "epoch:9 step:8980 [D loss: 0.549844, acc.: 70.31%] [G loss: 0.510507]\n",
      "epoch:9 step:8981 [D loss: 0.520686, acc.: 69.53%] [G loss: 0.641697]\n",
      "epoch:9 step:8982 [D loss: 0.539660, acc.: 70.31%] [G loss: 0.718270]\n",
      "epoch:9 step:8983 [D loss: 0.562446, acc.: 71.09%] [G loss: 0.629394]\n",
      "epoch:9 step:8984 [D loss: 0.550624, acc.: 70.31%] [G loss: 0.512811]\n",
      "epoch:9 step:8985 [D loss: 0.533015, acc.: 72.66%] [G loss: 0.471127]\n",
      "epoch:9 step:8986 [D loss: 0.565554, acc.: 71.09%] [G loss: 0.512349]\n",
      "epoch:9 step:8987 [D loss: 0.450489, acc.: 81.25%] [G loss: 0.655770]\n",
      "epoch:9 step:8988 [D loss: 0.515443, acc.: 72.66%] [G loss: 0.702018]\n",
      "epoch:9 step:8989 [D loss: 0.521598, acc.: 75.00%] [G loss: 0.594302]\n",
      "epoch:9 step:8990 [D loss: 0.506859, acc.: 74.22%] [G loss: 0.597314]\n",
      "epoch:9 step:8991 [D loss: 0.483660, acc.: 75.00%] [G loss: 0.546964]\n",
      "epoch:9 step:8992 [D loss: 0.604270, acc.: 62.50%] [G loss: 0.549353]\n",
      "epoch:9 step:8993 [D loss: 0.561995, acc.: 66.41%] [G loss: 0.455373]\n",
      "epoch:9 step:8994 [D loss: 0.518992, acc.: 75.78%] [G loss: 0.540411]\n",
      "epoch:9 step:8995 [D loss: 0.615535, acc.: 64.84%] [G loss: 0.524357]\n",
      "epoch:9 step:8996 [D loss: 0.515859, acc.: 71.09%] [G loss: 0.494687]\n",
      "epoch:9 step:8997 [D loss: 0.545120, acc.: 72.66%] [G loss: 0.689000]\n",
      "epoch:9 step:8998 [D loss: 0.545805, acc.: 68.75%] [G loss: 0.568311]\n",
      "epoch:9 step:8999 [D loss: 0.709406, acc.: 60.16%] [G loss: 0.593626]\n",
      "epoch:9 step:9000 [D loss: 0.511325, acc.: 76.56%] [G loss: 0.609985]\n",
      "##############\n",
      "[2.93596009 1.38251703 6.15560557 4.68298992 4.18481677 5.53759094\n",
      " 4.69296854 5.20803148 4.65794772 3.98609443]\n",
      "##########\n",
      "epoch:9 step:9001 [D loss: 0.501556, acc.: 76.56%] [G loss: 0.517587]\n",
      "epoch:9 step:9002 [D loss: 0.559274, acc.: 72.66%] [G loss: 0.597683]\n",
      "epoch:9 step:9003 [D loss: 0.533253, acc.: 75.00%] [G loss: 0.564630]\n",
      "epoch:9 step:9004 [D loss: 0.520034, acc.: 75.00%] [G loss: 0.839552]\n",
      "epoch:9 step:9005 [D loss: 0.575070, acc.: 68.75%] [G loss: 0.520277]\n",
      "epoch:9 step:9006 [D loss: 0.575662, acc.: 67.97%] [G loss: 0.661970]\n",
      "epoch:9 step:9007 [D loss: 0.472961, acc.: 75.00%] [G loss: 0.676032]\n",
      "epoch:9 step:9008 [D loss: 0.528137, acc.: 75.00%] [G loss: 0.630070]\n",
      "epoch:9 step:9009 [D loss: 0.621647, acc.: 64.06%] [G loss: 0.596842]\n",
      "epoch:9 step:9010 [D loss: 0.562677, acc.: 70.31%] [G loss: 0.499031]\n",
      "epoch:9 step:9011 [D loss: 0.548184, acc.: 70.31%] [G loss: 0.464745]\n",
      "epoch:9 step:9012 [D loss: 0.527530, acc.: 75.78%] [G loss: 0.538016]\n",
      "epoch:9 step:9013 [D loss: 0.580787, acc.: 64.06%] [G loss: 0.599540]\n",
      "epoch:9 step:9014 [D loss: 0.622331, acc.: 62.50%] [G loss: 0.575434]\n",
      "epoch:9 step:9015 [D loss: 0.450048, acc.: 80.47%] [G loss: 0.879794]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:9 step:9016 [D loss: 0.612163, acc.: 67.19%] [G loss: 0.757759]\n",
      "epoch:9 step:9017 [D loss: 0.661781, acc.: 62.50%] [G loss: 0.511735]\n",
      "epoch:9 step:9018 [D loss: 0.585004, acc.: 68.75%] [G loss: 0.562229]\n",
      "epoch:9 step:9019 [D loss: 0.613692, acc.: 67.97%] [G loss: 0.454776]\n",
      "epoch:9 step:9020 [D loss: 0.549136, acc.: 71.09%] [G loss: 0.550581]\n",
      "epoch:9 step:9021 [D loss: 0.585201, acc.: 62.50%] [G loss: 0.544400]\n",
      "epoch:9 step:9022 [D loss: 0.514707, acc.: 72.66%] [G loss: 0.725490]\n",
      "epoch:9 step:9023 [D loss: 0.556238, acc.: 70.31%] [G loss: 0.595492]\n",
      "epoch:9 step:9024 [D loss: 0.640610, acc.: 60.94%] [G loss: 0.399422]\n",
      "epoch:9 step:9025 [D loss: 0.450678, acc.: 81.25%] [G loss: 0.683403]\n",
      "epoch:9 step:9026 [D loss: 0.497688, acc.: 70.31%] [G loss: 0.718164]\n",
      "epoch:9 step:9027 [D loss: 0.600844, acc.: 68.75%] [G loss: 0.548253]\n",
      "epoch:9 step:9028 [D loss: 0.558931, acc.: 67.19%] [G loss: 0.560886]\n",
      "epoch:9 step:9029 [D loss: 0.557202, acc.: 72.66%] [G loss: 0.470857]\n",
      "epoch:9 step:9030 [D loss: 0.582046, acc.: 70.31%] [G loss: 0.568466]\n",
      "epoch:9 step:9031 [D loss: 0.468535, acc.: 78.91%] [G loss: 0.658463]\n",
      "epoch:9 step:9032 [D loss: 0.584099, acc.: 67.97%] [G loss: 0.618167]\n",
      "epoch:9 step:9033 [D loss: 0.645454, acc.: 63.28%] [G loss: 0.509692]\n",
      "epoch:9 step:9034 [D loss: 0.525345, acc.: 73.44%] [G loss: 0.527349]\n",
      "epoch:9 step:9035 [D loss: 0.511324, acc.: 72.66%] [G loss: 0.616703]\n",
      "epoch:9 step:9036 [D loss: 0.485919, acc.: 78.91%] [G loss: 0.810452]\n",
      "epoch:9 step:9037 [D loss: 0.578216, acc.: 68.75%] [G loss: 0.518388]\n",
      "epoch:9 step:9038 [D loss: 0.464319, acc.: 78.12%] [G loss: 0.656298]\n",
      "epoch:9 step:9039 [D loss: 0.679805, acc.: 55.47%] [G loss: 0.382283]\n",
      "epoch:9 step:9040 [D loss: 0.549124, acc.: 65.62%] [G loss: 0.524773]\n",
      "epoch:9 step:9041 [D loss: 0.548831, acc.: 70.31%] [G loss: 0.549196]\n",
      "epoch:9 step:9042 [D loss: 0.530788, acc.: 71.09%] [G loss: 0.561099]\n",
      "epoch:9 step:9043 [D loss: 0.645975, acc.: 64.84%] [G loss: 0.448616]\n",
      "epoch:9 step:9044 [D loss: 0.487596, acc.: 78.12%] [G loss: 0.506973]\n",
      "epoch:9 step:9045 [D loss: 0.544915, acc.: 71.88%] [G loss: 0.532896]\n",
      "epoch:9 step:9046 [D loss: 0.484177, acc.: 76.56%] [G loss: 0.521827]\n",
      "epoch:9 step:9047 [D loss: 0.595080, acc.: 64.84%] [G loss: 0.475472]\n",
      "epoch:9 step:9048 [D loss: 0.626006, acc.: 60.94%] [G loss: 0.529309]\n",
      "epoch:9 step:9049 [D loss: 0.582443, acc.: 64.84%] [G loss: 0.513563]\n",
      "epoch:9 step:9050 [D loss: 0.600967, acc.: 64.84%] [G loss: 0.587510]\n",
      "epoch:9 step:9051 [D loss: 0.530855, acc.: 71.09%] [G loss: 0.578910]\n",
      "epoch:9 step:9052 [D loss: 0.521733, acc.: 76.56%] [G loss: 0.515185]\n",
      "epoch:9 step:9053 [D loss: 0.501199, acc.: 76.56%] [G loss: 0.629573]\n",
      "epoch:9 step:9054 [D loss: 0.563248, acc.: 69.53%] [G loss: 0.413826]\n",
      "epoch:9 step:9055 [D loss: 0.578283, acc.: 69.53%] [G loss: 0.532780]\n",
      "epoch:9 step:9056 [D loss: 0.553098, acc.: 69.53%] [G loss: 0.570574]\n",
      "epoch:9 step:9057 [D loss: 0.486763, acc.: 75.78%] [G loss: 0.510929]\n",
      "epoch:9 step:9058 [D loss: 0.570312, acc.: 63.28%] [G loss: 0.575400]\n",
      "epoch:9 step:9059 [D loss: 0.524535, acc.: 71.09%] [G loss: 0.495808]\n",
      "epoch:9 step:9060 [D loss: 0.552209, acc.: 70.31%] [G loss: 0.583049]\n",
      "epoch:9 step:9061 [D loss: 0.611085, acc.: 65.62%] [G loss: 0.542756]\n",
      "epoch:9 step:9062 [D loss: 0.510434, acc.: 71.88%] [G loss: 0.633954]\n",
      "epoch:9 step:9063 [D loss: 0.581282, acc.: 67.19%] [G loss: 0.604479]\n",
      "epoch:9 step:9064 [D loss: 0.540540, acc.: 71.09%] [G loss: 0.522634]\n",
      "epoch:9 step:9065 [D loss: 0.532213, acc.: 76.56%] [G loss: 0.576057]\n",
      "epoch:9 step:9066 [D loss: 0.547488, acc.: 70.31%] [G loss: 0.489344]\n",
      "epoch:9 step:9067 [D loss: 0.492690, acc.: 78.12%] [G loss: 0.642405]\n",
      "epoch:9 step:9068 [D loss: 0.483791, acc.: 79.69%] [G loss: 0.628575]\n",
      "epoch:9 step:9069 [D loss: 0.597003, acc.: 69.53%] [G loss: 0.612025]\n",
      "epoch:9 step:9070 [D loss: 0.532436, acc.: 73.44%] [G loss: 0.514720]\n",
      "epoch:9 step:9071 [D loss: 0.507255, acc.: 72.66%] [G loss: 0.504383]\n",
      "epoch:9 step:9072 [D loss: 0.517070, acc.: 74.22%] [G loss: 0.512173]\n",
      "epoch:9 step:9073 [D loss: 0.506447, acc.: 75.00%] [G loss: 0.792959]\n",
      "epoch:9 step:9074 [D loss: 0.500034, acc.: 75.00%] [G loss: 0.679997]\n",
      "epoch:9 step:9075 [D loss: 0.467034, acc.: 78.12%] [G loss: 0.778029]\n",
      "epoch:9 step:9076 [D loss: 0.548754, acc.: 71.09%] [G loss: 0.558666]\n",
      "epoch:9 step:9077 [D loss: 0.567593, acc.: 73.44%] [G loss: 0.586368]\n",
      "epoch:9 step:9078 [D loss: 0.552585, acc.: 73.44%] [G loss: 0.613140]\n",
      "epoch:9 step:9079 [D loss: 0.496412, acc.: 78.12%] [G loss: 0.549220]\n",
      "epoch:9 step:9080 [D loss: 0.457736, acc.: 85.16%] [G loss: 0.631896]\n",
      "epoch:9 step:9081 [D loss: 0.458823, acc.: 78.12%] [G loss: 1.002890]\n",
      "epoch:9 step:9082 [D loss: 0.465333, acc.: 77.34%] [G loss: 0.850976]\n",
      "epoch:9 step:9083 [D loss: 0.551008, acc.: 73.44%] [G loss: 0.789266]\n",
      "epoch:9 step:9084 [D loss: 0.562767, acc.: 70.31%] [G loss: 0.568416]\n",
      "epoch:9 step:9085 [D loss: 0.644308, acc.: 64.84%] [G loss: 0.575293]\n",
      "epoch:9 step:9086 [D loss: 0.609372, acc.: 64.84%] [G loss: 0.563219]\n",
      "epoch:9 step:9087 [D loss: 0.508861, acc.: 71.09%] [G loss: 0.538804]\n",
      "epoch:9 step:9088 [D loss: 0.594797, acc.: 64.84%] [G loss: 0.691233]\n",
      "epoch:9 step:9089 [D loss: 0.539917, acc.: 71.09%] [G loss: 0.573349]\n",
      "epoch:9 step:9090 [D loss: 0.522620, acc.: 69.53%] [G loss: 0.469829]\n",
      "epoch:9 step:9091 [D loss: 0.572025, acc.: 65.62%] [G loss: 0.621812]\n",
      "epoch:9 step:9092 [D loss: 0.534674, acc.: 74.22%] [G loss: 0.622657]\n",
      "epoch:9 step:9093 [D loss: 0.526548, acc.: 74.22%] [G loss: 0.522095]\n",
      "epoch:9 step:9094 [D loss: 0.493631, acc.: 74.22%] [G loss: 0.573952]\n",
      "epoch:9 step:9095 [D loss: 0.516115, acc.: 73.44%] [G loss: 0.631560]\n",
      "epoch:9 step:9096 [D loss: 0.523062, acc.: 73.44%] [G loss: 0.626986]\n",
      "epoch:9 step:9097 [D loss: 0.566378, acc.: 67.97%] [G loss: 0.674351]\n",
      "epoch:9 step:9098 [D loss: 0.573519, acc.: 66.41%] [G loss: 0.644423]\n",
      "epoch:9 step:9099 [D loss: 0.542096, acc.: 67.97%] [G loss: 0.635260]\n",
      "epoch:9 step:9100 [D loss: 0.585151, acc.: 67.19%] [G loss: 0.624628]\n",
      "epoch:9 step:9101 [D loss: 0.542103, acc.: 74.22%] [G loss: 0.624258]\n",
      "epoch:9 step:9102 [D loss: 0.531150, acc.: 69.53%] [G loss: 0.583746]\n",
      "epoch:9 step:9103 [D loss: 0.575134, acc.: 67.97%] [G loss: 0.568196]\n",
      "epoch:9 step:9104 [D loss: 0.583385, acc.: 65.62%] [G loss: 0.580753]\n",
      "epoch:9 step:9105 [D loss: 0.595218, acc.: 66.41%] [G loss: 0.657288]\n",
      "epoch:9 step:9106 [D loss: 0.590555, acc.: 64.06%] [G loss: 0.569635]\n",
      "epoch:9 step:9107 [D loss: 0.520569, acc.: 71.09%] [G loss: 0.587572]\n",
      "epoch:9 step:9108 [D loss: 0.563370, acc.: 67.97%] [G loss: 0.630843]\n",
      "epoch:9 step:9109 [D loss: 0.640409, acc.: 62.50%] [G loss: 0.574109]\n",
      "epoch:9 step:9110 [D loss: 0.484257, acc.: 77.34%] [G loss: 0.696163]\n",
      "epoch:9 step:9111 [D loss: 0.550649, acc.: 70.31%] [G loss: 0.595198]\n",
      "epoch:9 step:9112 [D loss: 0.552820, acc.: 67.97%] [G loss: 0.564435]\n",
      "epoch:9 step:9113 [D loss: 0.478777, acc.: 81.25%] [G loss: 0.597696]\n",
      "epoch:9 step:9114 [D loss: 0.504893, acc.: 73.44%] [G loss: 0.607125]\n",
      "epoch:9 step:9115 [D loss: 0.557333, acc.: 69.53%] [G loss: 0.495710]\n",
      "epoch:9 step:9116 [D loss: 0.555242, acc.: 70.31%] [G loss: 0.494545]\n",
      "epoch:9 step:9117 [D loss: 0.561347, acc.: 69.53%] [G loss: 0.493353]\n",
      "epoch:9 step:9118 [D loss: 0.554047, acc.: 68.75%] [G loss: 0.626860]\n",
      "epoch:9 step:9119 [D loss: 0.569223, acc.: 67.19%] [G loss: 0.555979]\n",
      "epoch:9 step:9120 [D loss: 0.567497, acc.: 62.50%] [G loss: 0.553402]\n",
      "epoch:9 step:9121 [D loss: 0.564155, acc.: 64.84%] [G loss: 0.458479]\n",
      "epoch:9 step:9122 [D loss: 0.579046, acc.: 71.09%] [G loss: 0.603861]\n",
      "epoch:9 step:9123 [D loss: 0.507423, acc.: 77.34%] [G loss: 0.657634]\n",
      "epoch:9 step:9124 [D loss: 0.564765, acc.: 69.53%] [G loss: 0.662139]\n",
      "epoch:9 step:9125 [D loss: 0.531324, acc.: 71.09%] [G loss: 0.639478]\n",
      "epoch:9 step:9126 [D loss: 0.454870, acc.: 78.12%] [G loss: 0.701671]\n",
      "epoch:9 step:9127 [D loss: 0.515382, acc.: 74.22%] [G loss: 0.581230]\n",
      "epoch:9 step:9128 [D loss: 0.516426, acc.: 74.22%] [G loss: 0.684337]\n",
      "epoch:9 step:9129 [D loss: 0.640453, acc.: 59.38%] [G loss: 0.559521]\n",
      "epoch:9 step:9130 [D loss: 0.517282, acc.: 73.44%] [G loss: 0.592171]\n",
      "epoch:9 step:9131 [D loss: 0.577365, acc.: 68.75%] [G loss: 0.577802]\n",
      "epoch:9 step:9132 [D loss: 0.512133, acc.: 71.88%] [G loss: 0.560858]\n",
      "epoch:9 step:9133 [D loss: 0.517143, acc.: 75.00%] [G loss: 0.670387]\n",
      "epoch:9 step:9134 [D loss: 0.561691, acc.: 71.09%] [G loss: 0.515513]\n",
      "epoch:9 step:9135 [D loss: 0.537410, acc.: 74.22%] [G loss: 0.684753]\n",
      "epoch:9 step:9136 [D loss: 0.582127, acc.: 67.19%] [G loss: 0.632666]\n",
      "epoch:9 step:9137 [D loss: 0.665573, acc.: 56.25%] [G loss: 0.479312]\n",
      "epoch:9 step:9138 [D loss: 0.522978, acc.: 71.09%] [G loss: 0.523238]\n",
      "epoch:9 step:9139 [D loss: 0.580912, acc.: 68.75%] [G loss: 0.466537]\n",
      "epoch:9 step:9140 [D loss: 0.506672, acc.: 75.78%] [G loss: 0.580912]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:9 step:9141 [D loss: 0.539753, acc.: 73.44%] [G loss: 0.787871]\n",
      "epoch:9 step:9142 [D loss: 0.536409, acc.: 68.75%] [G loss: 0.660561]\n",
      "epoch:9 step:9143 [D loss: 0.601791, acc.: 64.06%] [G loss: 0.545230]\n",
      "epoch:9 step:9144 [D loss: 0.551395, acc.: 70.31%] [G loss: 0.613383]\n",
      "epoch:9 step:9145 [D loss: 0.545290, acc.: 69.53%] [G loss: 0.653328]\n",
      "epoch:9 step:9146 [D loss: 0.614724, acc.: 62.50%] [G loss: 0.490638]\n",
      "epoch:9 step:9147 [D loss: 0.566147, acc.: 65.62%] [G loss: 0.483454]\n",
      "epoch:9 step:9148 [D loss: 0.546297, acc.: 72.66%] [G loss: 0.472533]\n",
      "epoch:9 step:9149 [D loss: 0.586955, acc.: 65.62%] [G loss: 0.512101]\n",
      "epoch:9 step:9150 [D loss: 0.617536, acc.: 62.50%] [G loss: 0.410575]\n",
      "epoch:9 step:9151 [D loss: 0.613771, acc.: 64.06%] [G loss: 0.365742]\n",
      "epoch:9 step:9152 [D loss: 0.558428, acc.: 68.75%] [G loss: 0.539832]\n",
      "epoch:9 step:9153 [D loss: 0.607213, acc.: 60.94%] [G loss: 0.498819]\n",
      "epoch:9 step:9154 [D loss: 0.567630, acc.: 71.09%] [G loss: 0.679620]\n",
      "epoch:9 step:9155 [D loss: 0.529633, acc.: 75.00%] [G loss: 0.543740]\n",
      "epoch:9 step:9156 [D loss: 0.611387, acc.: 64.06%] [G loss: 0.481446]\n",
      "epoch:9 step:9157 [D loss: 0.533413, acc.: 72.66%] [G loss: 0.579403]\n",
      "epoch:9 step:9158 [D loss: 0.503860, acc.: 75.78%] [G loss: 0.700476]\n",
      "epoch:9 step:9159 [D loss: 0.501592, acc.: 78.12%] [G loss: 0.623395]\n",
      "epoch:9 step:9160 [D loss: 0.610879, acc.: 62.50%] [G loss: 0.493642]\n",
      "epoch:9 step:9161 [D loss: 0.535476, acc.: 72.66%] [G loss: 0.554134]\n",
      "epoch:9 step:9162 [D loss: 0.619181, acc.: 64.84%] [G loss: 0.547230]\n",
      "epoch:9 step:9163 [D loss: 0.510615, acc.: 78.91%] [G loss: 0.531016]\n",
      "epoch:9 step:9164 [D loss: 0.551322, acc.: 71.09%] [G loss: 0.413832]\n",
      "epoch:9 step:9165 [D loss: 0.562167, acc.: 68.75%] [G loss: 0.550818]\n",
      "epoch:9 step:9166 [D loss: 0.531334, acc.: 71.09%] [G loss: 0.655234]\n",
      "epoch:9 step:9167 [D loss: 0.540679, acc.: 67.19%] [G loss: 0.555705]\n",
      "epoch:9 step:9168 [D loss: 0.544726, acc.: 69.53%] [G loss: 0.602605]\n",
      "epoch:9 step:9169 [D loss: 0.460144, acc.: 78.91%] [G loss: 0.591892]\n",
      "epoch:9 step:9170 [D loss: 0.542089, acc.: 71.88%] [G loss: 0.607376]\n",
      "epoch:9 step:9171 [D loss: 0.563275, acc.: 66.41%] [G loss: 0.633996]\n",
      "epoch:9 step:9172 [D loss: 0.614670, acc.: 67.97%] [G loss: 0.456517]\n",
      "epoch:9 step:9173 [D loss: 0.700230, acc.: 49.22%] [G loss: 0.404852]\n",
      "epoch:9 step:9174 [D loss: 0.571652, acc.: 69.53%] [G loss: 0.515221]\n",
      "epoch:9 step:9175 [D loss: 0.547844, acc.: 73.44%] [G loss: 0.578224]\n",
      "epoch:9 step:9176 [D loss: 0.526762, acc.: 73.44%] [G loss: 0.720019]\n",
      "epoch:9 step:9177 [D loss: 0.583810, acc.: 71.09%] [G loss: 0.673998]\n",
      "epoch:9 step:9178 [D loss: 0.633627, acc.: 64.84%] [G loss: 0.623022]\n",
      "epoch:9 step:9179 [D loss: 0.482501, acc.: 72.66%] [G loss: 0.657453]\n",
      "epoch:9 step:9180 [D loss: 0.491462, acc.: 74.22%] [G loss: 0.664574]\n",
      "epoch:9 step:9181 [D loss: 0.530855, acc.: 73.44%] [G loss: 0.700586]\n",
      "epoch:9 step:9182 [D loss: 0.577150, acc.: 67.19%] [G loss: 0.465495]\n",
      "epoch:9 step:9183 [D loss: 0.504154, acc.: 76.56%] [G loss: 0.705374]\n",
      "epoch:9 step:9184 [D loss: 0.500592, acc.: 75.78%] [G loss: 0.645999]\n",
      "epoch:9 step:9185 [D loss: 0.562934, acc.: 65.62%] [G loss: 0.537957]\n",
      "epoch:9 step:9186 [D loss: 0.497378, acc.: 75.00%] [G loss: 0.572444]\n",
      "epoch:9 step:9187 [D loss: 0.531853, acc.: 72.66%] [G loss: 0.653661]\n",
      "epoch:9 step:9188 [D loss: 0.509644, acc.: 74.22%] [G loss: 0.690551]\n",
      "epoch:9 step:9189 [D loss: 0.590557, acc.: 67.97%] [G loss: 0.541496]\n",
      "epoch:9 step:9190 [D loss: 0.552152, acc.: 67.97%] [G loss: 0.625780]\n",
      "epoch:9 step:9191 [D loss: 0.555943, acc.: 71.09%] [G loss: 0.643004]\n",
      "epoch:9 step:9192 [D loss: 0.624569, acc.: 69.53%] [G loss: 0.634430]\n",
      "epoch:9 step:9193 [D loss: 0.528255, acc.: 70.31%] [G loss: 0.501245]\n",
      "epoch:9 step:9194 [D loss: 0.600824, acc.: 65.62%] [G loss: 0.488044]\n",
      "epoch:9 step:9195 [D loss: 0.596315, acc.: 62.50%] [G loss: 0.467287]\n",
      "epoch:9 step:9196 [D loss: 0.596616, acc.: 65.62%] [G loss: 0.644558]\n",
      "epoch:9 step:9197 [D loss: 0.578467, acc.: 66.41%] [G loss: 0.593010]\n",
      "epoch:9 step:9198 [D loss: 0.659380, acc.: 61.72%] [G loss: 0.461495]\n",
      "epoch:9 step:9199 [D loss: 0.670436, acc.: 59.38%] [G loss: 0.540388]\n",
      "epoch:9 step:9200 [D loss: 0.551926, acc.: 69.53%] [G loss: 0.385346]\n",
      "##############\n",
      "[2.91939855 0.99286169 6.57443747 5.08420505 3.85378348 5.50734133\n",
      " 4.60466627 4.85066042 4.69968632 3.98600563]\n",
      "##########\n",
      "epoch:9 step:9201 [D loss: 0.539158, acc.: 73.44%] [G loss: 0.612125]\n",
      "epoch:9 step:9202 [D loss: 0.600462, acc.: 67.19%] [G loss: 0.705192]\n",
      "epoch:9 step:9203 [D loss: 0.529726, acc.: 75.00%] [G loss: 0.569857]\n",
      "epoch:9 step:9204 [D loss: 0.536594, acc.: 68.75%] [G loss: 0.656647]\n",
      "epoch:9 step:9205 [D loss: 0.536132, acc.: 71.09%] [G loss: 0.546244]\n",
      "epoch:9 step:9206 [D loss: 0.557348, acc.: 69.53%] [G loss: 0.520872]\n",
      "epoch:9 step:9207 [D loss: 0.591364, acc.: 70.31%] [G loss: 0.616750]\n",
      "epoch:9 step:9208 [D loss: 0.522857, acc.: 76.56%] [G loss: 0.558045]\n",
      "epoch:9 step:9209 [D loss: 0.612711, acc.: 65.62%] [G loss: 0.432490]\n",
      "epoch:9 step:9210 [D loss: 0.573867, acc.: 67.19%] [G loss: 0.512452]\n",
      "epoch:9 step:9211 [D loss: 0.541213, acc.: 75.78%] [G loss: 0.507186]\n",
      "epoch:9 step:9212 [D loss: 0.592081, acc.: 67.97%] [G loss: 0.479420]\n",
      "epoch:9 step:9213 [D loss: 0.609168, acc.: 63.28%] [G loss: 0.699369]\n",
      "epoch:9 step:9214 [D loss: 0.490969, acc.: 75.78%] [G loss: 0.752974]\n",
      "epoch:9 step:9215 [D loss: 0.573809, acc.: 64.84%] [G loss: 0.655046]\n",
      "epoch:9 step:9216 [D loss: 0.568686, acc.: 67.97%] [G loss: 0.493425]\n",
      "epoch:9 step:9217 [D loss: 0.645693, acc.: 63.28%] [G loss: 0.542116]\n",
      "epoch:9 step:9218 [D loss: 0.595205, acc.: 67.97%] [G loss: 0.462991]\n",
      "epoch:9 step:9219 [D loss: 0.506134, acc.: 72.66%] [G loss: 0.611552]\n",
      "epoch:9 step:9220 [D loss: 0.565316, acc.: 70.31%] [G loss: 0.571518]\n",
      "epoch:9 step:9221 [D loss: 0.691109, acc.: 53.12%] [G loss: 0.443252]\n",
      "epoch:9 step:9222 [D loss: 0.542678, acc.: 74.22%] [G loss: 0.427792]\n",
      "epoch:9 step:9223 [D loss: 0.524559, acc.: 67.97%] [G loss: 0.538783]\n",
      "epoch:9 step:9224 [D loss: 0.557811, acc.: 64.06%] [G loss: 0.548070]\n",
      "epoch:9 step:9225 [D loss: 0.468799, acc.: 74.22%] [G loss: 0.783497]\n",
      "epoch:9 step:9226 [D loss: 0.585597, acc.: 66.41%] [G loss: 0.669171]\n",
      "epoch:9 step:9227 [D loss: 0.675902, acc.: 57.03%] [G loss: 0.567719]\n",
      "epoch:9 step:9228 [D loss: 0.557721, acc.: 67.97%] [G loss: 0.541899]\n",
      "epoch:9 step:9229 [D loss: 0.536512, acc.: 65.62%] [G loss: 0.691831]\n",
      "epoch:9 step:9230 [D loss: 0.504855, acc.: 75.00%] [G loss: 0.750040]\n",
      "epoch:9 step:9231 [D loss: 0.534393, acc.: 71.09%] [G loss: 0.557262]\n",
      "epoch:9 step:9232 [D loss: 0.545379, acc.: 71.88%] [G loss: 0.545673]\n",
      "epoch:9 step:9233 [D loss: 0.558441, acc.: 69.53%] [G loss: 0.547945]\n",
      "epoch:9 step:9234 [D loss: 0.481491, acc.: 75.00%] [G loss: 0.511993]\n",
      "epoch:9 step:9235 [D loss: 0.531250, acc.: 69.53%] [G loss: 0.785534]\n",
      "epoch:9 step:9236 [D loss: 0.500660, acc.: 77.34%] [G loss: 0.694909]\n",
      "epoch:9 step:9237 [D loss: 0.560871, acc.: 67.97%] [G loss: 0.562573]\n",
      "epoch:9 step:9238 [D loss: 0.574917, acc.: 67.19%] [G loss: 0.430278]\n",
      "epoch:9 step:9239 [D loss: 0.554054, acc.: 66.41%] [G loss: 0.446592]\n",
      "epoch:9 step:9240 [D loss: 0.529470, acc.: 70.31%] [G loss: 0.387033]\n",
      "epoch:9 step:9241 [D loss: 0.534348, acc.: 75.00%] [G loss: 0.532964]\n",
      "epoch:9 step:9242 [D loss: 0.506628, acc.: 76.56%] [G loss: 0.556927]\n",
      "epoch:9 step:9243 [D loss: 0.533195, acc.: 70.31%] [G loss: 0.525194]\n",
      "epoch:9 step:9244 [D loss: 0.530932, acc.: 75.00%] [G loss: 0.577794]\n",
      "epoch:9 step:9245 [D loss: 0.642052, acc.: 63.28%] [G loss: 0.440841]\n",
      "epoch:9 step:9246 [D loss: 0.555019, acc.: 72.66%] [G loss: 0.463982]\n",
      "epoch:9 step:9247 [D loss: 0.484991, acc.: 74.22%] [G loss: 0.609810]\n",
      "epoch:9 step:9248 [D loss: 0.484148, acc.: 78.12%] [G loss: 0.798877]\n",
      "epoch:9 step:9249 [D loss: 0.524691, acc.: 71.88%] [G loss: 0.883868]\n",
      "epoch:9 step:9250 [D loss: 0.593245, acc.: 68.75%] [G loss: 0.652779]\n",
      "epoch:9 step:9251 [D loss: 0.565309, acc.: 70.31%] [G loss: 0.554137]\n",
      "epoch:9 step:9252 [D loss: 0.540101, acc.: 72.66%] [G loss: 0.586816]\n",
      "epoch:9 step:9253 [D loss: 0.634237, acc.: 66.41%] [G loss: 0.423925]\n",
      "epoch:9 step:9254 [D loss: 0.583687, acc.: 70.31%] [G loss: 0.420471]\n",
      "epoch:9 step:9255 [D loss: 0.525385, acc.: 69.53%] [G loss: 0.640262]\n",
      "epoch:9 step:9256 [D loss: 0.512914, acc.: 67.19%] [G loss: 0.655123]\n",
      "epoch:9 step:9257 [D loss: 0.591487, acc.: 67.97%] [G loss: 0.583553]\n",
      "epoch:9 step:9258 [D loss: 0.526661, acc.: 74.22%] [G loss: 0.571292]\n",
      "epoch:9 step:9259 [D loss: 0.537835, acc.: 73.44%] [G loss: 0.539605]\n",
      "epoch:9 step:9260 [D loss: 0.542978, acc.: 69.53%] [G loss: 0.523999]\n",
      "epoch:9 step:9261 [D loss: 0.630738, acc.: 55.47%] [G loss: 0.418962]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:9 step:9262 [D loss: 0.585360, acc.: 69.53%] [G loss: 0.602498]\n",
      "epoch:9 step:9263 [D loss: 0.554318, acc.: 73.44%] [G loss: 0.624719]\n",
      "epoch:9 step:9264 [D loss: 0.539632, acc.: 75.78%] [G loss: 0.408337]\n",
      "epoch:9 step:9265 [D loss: 0.550157, acc.: 67.97%] [G loss: 0.345908]\n",
      "epoch:9 step:9266 [D loss: 0.516432, acc.: 75.00%] [G loss: 0.537607]\n",
      "epoch:9 step:9267 [D loss: 0.510528, acc.: 74.22%] [G loss: 0.438381]\n",
      "epoch:9 step:9268 [D loss: 0.543972, acc.: 73.44%] [G loss: 0.708983]\n",
      "epoch:9 step:9269 [D loss: 0.555707, acc.: 72.66%] [G loss: 0.461734]\n",
      "epoch:9 step:9270 [D loss: 0.538909, acc.: 70.31%] [G loss: 0.544255]\n",
      "epoch:9 step:9271 [D loss: 0.532305, acc.: 71.09%] [G loss: 0.528572]\n",
      "epoch:9 step:9272 [D loss: 0.623943, acc.: 61.72%] [G loss: 0.489626]\n",
      "epoch:9 step:9273 [D loss: 0.632245, acc.: 60.16%] [G loss: 0.456209]\n",
      "epoch:9 step:9274 [D loss: 0.568235, acc.: 65.62%] [G loss: 0.479749]\n",
      "epoch:9 step:9275 [D loss: 0.521954, acc.: 68.75%] [G loss: 0.466909]\n",
      "epoch:9 step:9276 [D loss: 0.540492, acc.: 71.88%] [G loss: 0.508788]\n",
      "epoch:9 step:9277 [D loss: 0.571744, acc.: 69.53%] [G loss: 0.576424]\n",
      "epoch:9 step:9278 [D loss: 0.622819, acc.: 60.94%] [G loss: 0.479155]\n",
      "epoch:9 step:9279 [D loss: 0.578042, acc.: 67.19%] [G loss: 0.578259]\n",
      "epoch:9 step:9280 [D loss: 0.619425, acc.: 64.84%] [G loss: 0.421501]\n",
      "epoch:9 step:9281 [D loss: 0.527966, acc.: 71.88%] [G loss: 0.411057]\n",
      "epoch:9 step:9282 [D loss: 0.510411, acc.: 74.22%] [G loss: 0.504566]\n",
      "epoch:9 step:9283 [D loss: 0.557087, acc.: 69.53%] [G loss: 0.542816]\n",
      "epoch:9 step:9284 [D loss: 0.561903, acc.: 69.53%] [G loss: 0.469430]\n",
      "epoch:9 step:9285 [D loss: 0.523194, acc.: 69.53%] [G loss: 0.454893]\n",
      "epoch:9 step:9286 [D loss: 0.555597, acc.: 73.44%] [G loss: 0.652598]\n",
      "epoch:9 step:9287 [D loss: 0.518692, acc.: 73.44%] [G loss: 0.535269]\n",
      "epoch:9 step:9288 [D loss: 0.521588, acc.: 74.22%] [G loss: 0.637043]\n",
      "epoch:9 step:9289 [D loss: 0.663837, acc.: 58.59%] [G loss: 0.633216]\n",
      "epoch:9 step:9290 [D loss: 0.488992, acc.: 74.22%] [G loss: 0.745768]\n",
      "epoch:9 step:9291 [D loss: 0.655346, acc.: 60.94%] [G loss: 0.535346]\n",
      "epoch:9 step:9292 [D loss: 0.549075, acc.: 70.31%] [G loss: 0.587717]\n",
      "epoch:9 step:9293 [D loss: 0.458685, acc.: 78.12%] [G loss: 0.582826]\n",
      "epoch:9 step:9294 [D loss: 0.602796, acc.: 70.31%] [G loss: 0.563058]\n",
      "epoch:9 step:9295 [D loss: 0.545532, acc.: 65.62%] [G loss: 0.491598]\n",
      "epoch:9 step:9296 [D loss: 0.619159, acc.: 61.72%] [G loss: 0.434763]\n",
      "epoch:9 step:9297 [D loss: 0.558602, acc.: 71.09%] [G loss: 0.480620]\n",
      "epoch:9 step:9298 [D loss: 0.551322, acc.: 68.75%] [G loss: 0.597505]\n",
      "epoch:9 step:9299 [D loss: 0.527718, acc.: 75.00%] [G loss: 0.586322]\n",
      "epoch:9 step:9300 [D loss: 0.662860, acc.: 59.38%] [G loss: 0.489826]\n",
      "epoch:9 step:9301 [D loss: 0.538292, acc.: 71.88%] [G loss: 0.477851]\n",
      "epoch:9 step:9302 [D loss: 0.554947, acc.: 65.62%] [G loss: 0.445722]\n",
      "epoch:9 step:9303 [D loss: 0.483692, acc.: 78.12%] [G loss: 0.563876]\n",
      "epoch:9 step:9304 [D loss: 0.501870, acc.: 75.78%] [G loss: 0.621315]\n",
      "epoch:9 step:9305 [D loss: 0.502391, acc.: 77.34%] [G loss: 0.471500]\n",
      "epoch:9 step:9306 [D loss: 0.570579, acc.: 67.19%] [G loss: 0.590746]\n",
      "epoch:9 step:9307 [D loss: 0.547480, acc.: 69.53%] [G loss: 0.520290]\n",
      "epoch:9 step:9308 [D loss: 0.501796, acc.: 74.22%] [G loss: 0.521651]\n",
      "epoch:9 step:9309 [D loss: 0.573162, acc.: 69.53%] [G loss: 0.629089]\n",
      "epoch:9 step:9310 [D loss: 0.573207, acc.: 71.88%] [G loss: 0.492872]\n",
      "epoch:9 step:9311 [D loss: 0.579467, acc.: 67.97%] [G loss: 0.418548]\n",
      "epoch:9 step:9312 [D loss: 0.583775, acc.: 64.84%] [G loss: 0.506473]\n",
      "epoch:9 step:9313 [D loss: 0.708243, acc.: 55.47%] [G loss: 0.515550]\n",
      "epoch:9 step:9314 [D loss: 0.549017, acc.: 67.97%] [G loss: 0.401512]\n",
      "epoch:9 step:9315 [D loss: 0.594696, acc.: 67.97%] [G loss: 0.385927]\n",
      "epoch:9 step:9316 [D loss: 0.601400, acc.: 65.62%] [G loss: 0.567567]\n",
      "epoch:9 step:9317 [D loss: 0.498365, acc.: 75.00%] [G loss: 0.534501]\n",
      "epoch:9 step:9318 [D loss: 0.512502, acc.: 73.44%] [G loss: 0.667458]\n",
      "epoch:9 step:9319 [D loss: 0.495197, acc.: 72.66%] [G loss: 0.714720]\n",
      "epoch:9 step:9320 [D loss: 0.582329, acc.: 67.97%] [G loss: 0.630079]\n",
      "epoch:9 step:9321 [D loss: 0.603644, acc.: 61.72%] [G loss: 0.572589]\n",
      "epoch:9 step:9322 [D loss: 0.589130, acc.: 66.41%] [G loss: 0.478525]\n",
      "epoch:9 step:9323 [D loss: 0.506536, acc.: 75.78%] [G loss: 0.527869]\n",
      "epoch:9 step:9324 [D loss: 0.580442, acc.: 65.62%] [G loss: 0.553324]\n",
      "epoch:9 step:9325 [D loss: 0.566862, acc.: 62.50%] [G loss: 0.612487]\n",
      "epoch:9 step:9326 [D loss: 0.580469, acc.: 68.75%] [G loss: 0.587357]\n",
      "epoch:9 step:9327 [D loss: 0.477595, acc.: 79.69%] [G loss: 0.739545]\n",
      "epoch:9 step:9328 [D loss: 0.523306, acc.: 75.78%] [G loss: 0.853209]\n",
      "epoch:9 step:9329 [D loss: 0.498333, acc.: 77.34%] [G loss: 0.646826]\n",
      "epoch:9 step:9330 [D loss: 0.484964, acc.: 75.78%] [G loss: 0.681044]\n",
      "epoch:9 step:9331 [D loss: 0.550490, acc.: 71.09%] [G loss: 0.677167]\n",
      "epoch:9 step:9332 [D loss: 0.506871, acc.: 78.12%] [G loss: 0.596668]\n",
      "epoch:9 step:9333 [D loss: 0.527939, acc.: 75.00%] [G loss: 0.755712]\n",
      "epoch:9 step:9334 [D loss: 0.557349, acc.: 67.97%] [G loss: 0.552538]\n",
      "epoch:9 step:9335 [D loss: 0.593415, acc.: 66.41%] [G loss: 0.434649]\n",
      "epoch:9 step:9336 [D loss: 0.574523, acc.: 64.84%] [G loss: 0.530189]\n",
      "epoch:9 step:9337 [D loss: 0.539935, acc.: 71.88%] [G loss: 0.533062]\n",
      "epoch:9 step:9338 [D loss: 0.592876, acc.: 71.09%] [G loss: 0.702098]\n",
      "epoch:9 step:9339 [D loss: 0.497809, acc.: 78.91%] [G loss: 0.635280]\n",
      "epoch:9 step:9340 [D loss: 0.575046, acc.: 69.53%] [G loss: 0.557877]\n",
      "epoch:9 step:9341 [D loss: 0.550414, acc.: 71.09%] [G loss: 0.578569]\n",
      "epoch:9 step:9342 [D loss: 0.503748, acc.: 75.78%] [G loss: 0.597146]\n",
      "epoch:9 step:9343 [D loss: 0.504288, acc.: 71.88%] [G loss: 0.704465]\n",
      "epoch:9 step:9344 [D loss: 0.484849, acc.: 77.34%] [G loss: 0.652282]\n",
      "epoch:9 step:9345 [D loss: 0.457526, acc.: 78.91%] [G loss: 0.736514]\n",
      "epoch:9 step:9346 [D loss: 0.559684, acc.: 73.44%] [G loss: 0.697130]\n",
      "epoch:9 step:9347 [D loss: 0.585616, acc.: 65.62%] [G loss: 0.890943]\n",
      "epoch:9 step:9348 [D loss: 0.606789, acc.: 60.94%] [G loss: 0.640346]\n",
      "epoch:9 step:9349 [D loss: 0.495800, acc.: 74.22%] [G loss: 0.558041]\n",
      "epoch:9 step:9350 [D loss: 0.646439, acc.: 58.59%] [G loss: 0.482495]\n",
      "epoch:9 step:9351 [D loss: 0.487658, acc.: 80.47%] [G loss: 0.714212]\n",
      "epoch:9 step:9352 [D loss: 0.509326, acc.: 75.00%] [G loss: 0.744619]\n",
      "epoch:9 step:9353 [D loss: 0.781530, acc.: 51.56%] [G loss: 0.650411]\n",
      "epoch:9 step:9354 [D loss: 0.483466, acc.: 77.34%] [G loss: 0.737552]\n",
      "epoch:9 step:9355 [D loss: 0.573899, acc.: 67.19%] [G loss: 0.630467]\n",
      "epoch:9 step:9356 [D loss: 0.446537, acc.: 78.91%] [G loss: 0.657524]\n",
      "epoch:9 step:9357 [D loss: 0.444615, acc.: 75.00%] [G loss: 0.673674]\n",
      "epoch:9 step:9358 [D loss: 0.415873, acc.: 80.47%] [G loss: 0.876966]\n",
      "epoch:9 step:9359 [D loss: 0.451726, acc.: 75.00%] [G loss: 0.859979]\n",
      "epoch:9 step:9360 [D loss: 0.541327, acc.: 67.97%] [G loss: 1.144267]\n",
      "epoch:9 step:9361 [D loss: 0.700920, acc.: 64.84%] [G loss: 1.017925]\n",
      "epoch:9 step:9362 [D loss: 0.396276, acc.: 84.38%] [G loss: 1.456591]\n",
      "epoch:9 step:9363 [D loss: 0.496391, acc.: 71.09%] [G loss: 1.209716]\n",
      "epoch:9 step:9364 [D loss: 0.588517, acc.: 69.53%] [G loss: 0.772985]\n",
      "epoch:9 step:9365 [D loss: 0.620393, acc.: 64.06%] [G loss: 0.610996]\n",
      "epoch:9 step:9366 [D loss: 0.507531, acc.: 75.78%] [G loss: 0.730584]\n",
      "epoch:9 step:9367 [D loss: 0.597803, acc.: 64.84%] [G loss: 0.943938]\n",
      "epoch:9 step:9368 [D loss: 0.481506, acc.: 73.44%] [G loss: 0.861827]\n",
      "epoch:9 step:9369 [D loss: 0.408227, acc.: 80.47%] [G loss: 1.193392]\n",
      "epoch:9 step:9370 [D loss: 0.478755, acc.: 77.34%] [G loss: 1.339375]\n",
      "epoch:10 step:9371 [D loss: 0.564789, acc.: 75.78%] [G loss: 1.030172]\n",
      "epoch:10 step:9372 [D loss: 0.503114, acc.: 74.22%] [G loss: 0.880461]\n",
      "epoch:10 step:9373 [D loss: 0.636168, acc.: 66.41%] [G loss: 0.727416]\n",
      "epoch:10 step:9374 [D loss: 0.547478, acc.: 71.09%] [G loss: 0.585233]\n",
      "epoch:10 step:9375 [D loss: 0.552018, acc.: 73.44%] [G loss: 0.787668]\n",
      "epoch:10 step:9376 [D loss: 0.541218, acc.: 72.66%] [G loss: 0.658683]\n",
      "epoch:10 step:9377 [D loss: 0.506902, acc.: 75.78%] [G loss: 0.654918]\n",
      "epoch:10 step:9378 [D loss: 0.524870, acc.: 75.78%] [G loss: 0.630880]\n",
      "epoch:10 step:9379 [D loss: 0.498836, acc.: 71.88%] [G loss: 0.679528]\n",
      "epoch:10 step:9380 [D loss: 0.505173, acc.: 75.78%] [G loss: 0.666979]\n",
      "epoch:10 step:9381 [D loss: 0.512314, acc.: 77.34%] [G loss: 0.751969]\n",
      "epoch:10 step:9382 [D loss: 0.576474, acc.: 68.75%] [G loss: 0.619800]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:10 step:9383 [D loss: 0.557020, acc.: 69.53%] [G loss: 0.595128]\n",
      "epoch:10 step:9384 [D loss: 0.569032, acc.: 67.97%] [G loss: 0.494678]\n",
      "epoch:10 step:9385 [D loss: 0.501740, acc.: 76.56%] [G loss: 0.593214]\n",
      "epoch:10 step:9386 [D loss: 0.490597, acc.: 75.78%] [G loss: 0.712321]\n",
      "epoch:10 step:9387 [D loss: 0.525282, acc.: 70.31%] [G loss: 0.706263]\n",
      "epoch:10 step:9388 [D loss: 0.637963, acc.: 58.59%] [G loss: 0.473990]\n",
      "epoch:10 step:9389 [D loss: 0.593669, acc.: 65.62%] [G loss: 0.486167]\n",
      "epoch:10 step:9390 [D loss: 0.618671, acc.: 65.62%] [G loss: 0.468053]\n",
      "epoch:10 step:9391 [D loss: 0.600824, acc.: 59.38%] [G loss: 0.498635]\n",
      "epoch:10 step:9392 [D loss: 0.464886, acc.: 80.47%] [G loss: 0.689110]\n",
      "epoch:10 step:9393 [D loss: 0.554791, acc.: 71.88%] [G loss: 0.655889]\n",
      "epoch:10 step:9394 [D loss: 0.464773, acc.: 75.00%] [G loss: 0.650995]\n",
      "epoch:10 step:9395 [D loss: 0.494697, acc.: 75.00%] [G loss: 0.516932]\n",
      "epoch:10 step:9396 [D loss: 0.648317, acc.: 67.97%] [G loss: 0.566792]\n",
      "epoch:10 step:9397 [D loss: 0.480332, acc.: 71.09%] [G loss: 0.616781]\n",
      "epoch:10 step:9398 [D loss: 0.598062, acc.: 68.75%] [G loss: 0.700781]\n",
      "epoch:10 step:9399 [D loss: 0.515125, acc.: 74.22%] [G loss: 0.636060]\n",
      "epoch:10 step:9400 [D loss: 0.555546, acc.: 71.88%] [G loss: 0.492120]\n",
      "##############\n",
      "[3.16435437 1.14871095 6.34922137 5.08007336 3.85369541 5.76967422\n",
      " 4.43202421 5.0751202  4.54943057 3.96280559]\n",
      "##########\n",
      "epoch:10 step:9401 [D loss: 0.607229, acc.: 64.84%] [G loss: 0.417823]\n",
      "epoch:10 step:9402 [D loss: 0.556847, acc.: 68.75%] [G loss: 0.605477]\n",
      "epoch:10 step:9403 [D loss: 0.529750, acc.: 67.97%] [G loss: 0.538536]\n",
      "epoch:10 step:9404 [D loss: 0.505011, acc.: 78.91%] [G loss: 0.637911]\n",
      "epoch:10 step:9405 [D loss: 0.602622, acc.: 69.53%] [G loss: 0.556465]\n",
      "epoch:10 step:9406 [D loss: 0.523796, acc.: 67.97%] [G loss: 0.591307]\n",
      "epoch:10 step:9407 [D loss: 0.537619, acc.: 70.31%] [G loss: 0.471655]\n",
      "epoch:10 step:9408 [D loss: 0.602200, acc.: 67.19%] [G loss: 0.553215]\n",
      "epoch:10 step:9409 [D loss: 0.583866, acc.: 68.75%] [G loss: 0.597358]\n",
      "epoch:10 step:9410 [D loss: 0.483963, acc.: 75.00%] [G loss: 0.559969]\n",
      "epoch:10 step:9411 [D loss: 0.514321, acc.: 77.34%] [G loss: 0.588991]\n",
      "epoch:10 step:9412 [D loss: 0.525544, acc.: 73.44%] [G loss: 0.614251]\n",
      "epoch:10 step:9413 [D loss: 0.524897, acc.: 73.44%] [G loss: 0.706712]\n",
      "epoch:10 step:9414 [D loss: 0.608582, acc.: 65.62%] [G loss: 0.526193]\n",
      "epoch:10 step:9415 [D loss: 0.529783, acc.: 74.22%] [G loss: 0.558181]\n",
      "epoch:10 step:9416 [D loss: 0.526563, acc.: 77.34%] [G loss: 0.565507]\n",
      "epoch:10 step:9417 [D loss: 0.544034, acc.: 74.22%] [G loss: 0.493872]\n",
      "epoch:10 step:9418 [D loss: 0.571523, acc.: 68.75%] [G loss: 0.542805]\n",
      "epoch:10 step:9419 [D loss: 0.488450, acc.: 75.78%] [G loss: 0.624057]\n",
      "epoch:10 step:9420 [D loss: 0.535389, acc.: 75.00%] [G loss: 0.640943]\n",
      "epoch:10 step:9421 [D loss: 0.650749, acc.: 62.50%] [G loss: 0.399989]\n",
      "epoch:10 step:9422 [D loss: 0.651080, acc.: 66.41%] [G loss: 0.493924]\n",
      "epoch:10 step:9423 [D loss: 0.522835, acc.: 75.00%] [G loss: 0.680155]\n",
      "epoch:10 step:9424 [D loss: 0.518928, acc.: 75.00%] [G loss: 0.776917]\n",
      "epoch:10 step:9425 [D loss: 0.569696, acc.: 69.53%] [G loss: 0.674826]\n",
      "epoch:10 step:9426 [D loss: 0.538673, acc.: 71.88%] [G loss: 0.547535]\n",
      "epoch:10 step:9427 [D loss: 0.523723, acc.: 68.75%] [G loss: 0.650169]\n",
      "epoch:10 step:9428 [D loss: 0.571082, acc.: 69.53%] [G loss: 0.490059]\n",
      "epoch:10 step:9429 [D loss: 0.557406, acc.: 74.22%] [G loss: 0.502024]\n",
      "epoch:10 step:9430 [D loss: 0.561138, acc.: 64.84%] [G loss: 0.576829]\n",
      "epoch:10 step:9431 [D loss: 0.503983, acc.: 72.66%] [G loss: 0.777855]\n",
      "epoch:10 step:9432 [D loss: 0.606876, acc.: 70.31%] [G loss: 0.507615]\n",
      "epoch:10 step:9433 [D loss: 0.584111, acc.: 67.97%] [G loss: 0.549871]\n",
      "epoch:10 step:9434 [D loss: 0.596853, acc.: 64.06%] [G loss: 0.498144]\n",
      "epoch:10 step:9435 [D loss: 0.506216, acc.: 80.47%] [G loss: 0.454299]\n",
      "epoch:10 step:9436 [D loss: 0.568519, acc.: 72.66%] [G loss: 0.539712]\n",
      "epoch:10 step:9437 [D loss: 0.565316, acc.: 72.66%] [G loss: 0.570157]\n",
      "epoch:10 step:9438 [D loss: 0.549502, acc.: 70.31%] [G loss: 0.413967]\n",
      "epoch:10 step:9439 [D loss: 0.552459, acc.: 67.97%] [G loss: 0.501675]\n",
      "epoch:10 step:9440 [D loss: 0.531485, acc.: 76.56%] [G loss: 0.653233]\n",
      "epoch:10 step:9441 [D loss: 0.563969, acc.: 68.75%] [G loss: 0.499297]\n",
      "epoch:10 step:9442 [D loss: 0.515647, acc.: 73.44%] [G loss: 0.629209]\n",
      "epoch:10 step:9443 [D loss: 0.571776, acc.: 68.75%] [G loss: 0.574113]\n",
      "epoch:10 step:9444 [D loss: 0.488568, acc.: 78.12%] [G loss: 0.666353]\n",
      "epoch:10 step:9445 [D loss: 0.569457, acc.: 69.53%] [G loss: 0.598528]\n",
      "epoch:10 step:9446 [D loss: 0.558280, acc.: 68.75%] [G loss: 0.591475]\n",
      "epoch:10 step:9447 [D loss: 0.440702, acc.: 76.56%] [G loss: 0.820969]\n",
      "epoch:10 step:9448 [D loss: 0.666762, acc.: 60.94%] [G loss: 0.477070]\n",
      "epoch:10 step:9449 [D loss: 0.554121, acc.: 66.41%] [G loss: 0.494735]\n",
      "epoch:10 step:9450 [D loss: 0.508285, acc.: 73.44%] [G loss: 0.509483]\n",
      "epoch:10 step:9451 [D loss: 0.521208, acc.: 71.09%] [G loss: 0.839724]\n",
      "epoch:10 step:9452 [D loss: 0.538310, acc.: 73.44%] [G loss: 0.603596]\n",
      "epoch:10 step:9453 [D loss: 0.548675, acc.: 72.66%] [G loss: 0.647857]\n",
      "epoch:10 step:9454 [D loss: 0.582593, acc.: 67.97%] [G loss: 0.528963]\n",
      "epoch:10 step:9455 [D loss: 0.585534, acc.: 67.19%] [G loss: 0.620252]\n",
      "epoch:10 step:9456 [D loss: 0.546149, acc.: 70.31%] [G loss: 0.482919]\n",
      "epoch:10 step:9457 [D loss: 0.514209, acc.: 75.78%] [G loss: 0.522933]\n",
      "epoch:10 step:9458 [D loss: 0.491904, acc.: 75.00%] [G loss: 0.514279]\n",
      "epoch:10 step:9459 [D loss: 0.510667, acc.: 75.00%] [G loss: 0.620407]\n",
      "epoch:10 step:9460 [D loss: 0.497778, acc.: 78.91%] [G loss: 0.570338]\n",
      "epoch:10 step:9461 [D loss: 0.584053, acc.: 67.97%] [G loss: 0.524031]\n",
      "epoch:10 step:9462 [D loss: 0.449708, acc.: 77.34%] [G loss: 0.601416]\n",
      "epoch:10 step:9463 [D loss: 0.487164, acc.: 76.56%] [G loss: 0.729363]\n",
      "epoch:10 step:9464 [D loss: 0.529940, acc.: 73.44%] [G loss: 0.687001]\n",
      "epoch:10 step:9465 [D loss: 0.585661, acc.: 70.31%] [G loss: 0.578685]\n",
      "epoch:10 step:9466 [D loss: 0.491014, acc.: 76.56%] [G loss: 0.650115]\n",
      "epoch:10 step:9467 [D loss: 0.525073, acc.: 71.88%] [G loss: 0.636224]\n",
      "epoch:10 step:9468 [D loss: 0.570210, acc.: 70.31%] [G loss: 0.613343]\n",
      "epoch:10 step:9469 [D loss: 0.555474, acc.: 71.09%] [G loss: 0.692862]\n",
      "epoch:10 step:9470 [D loss: 0.474161, acc.: 76.56%] [G loss: 0.751758]\n",
      "epoch:10 step:9471 [D loss: 0.558772, acc.: 68.75%] [G loss: 0.551132]\n",
      "epoch:10 step:9472 [D loss: 0.615340, acc.: 68.75%] [G loss: 0.636245]\n",
      "epoch:10 step:9473 [D loss: 0.514480, acc.: 73.44%] [G loss: 0.489276]\n",
      "epoch:10 step:9474 [D loss: 0.564375, acc.: 67.97%] [G loss: 0.499032]\n",
      "epoch:10 step:9475 [D loss: 0.583433, acc.: 65.62%] [G loss: 0.512271]\n",
      "epoch:10 step:9476 [D loss: 0.535991, acc.: 72.66%] [G loss: 0.491336]\n",
      "epoch:10 step:9477 [D loss: 0.620208, acc.: 64.84%] [G loss: 0.624418]\n",
      "epoch:10 step:9478 [D loss: 0.671187, acc.: 64.06%] [G loss: 0.470399]\n",
      "epoch:10 step:9479 [D loss: 0.587383, acc.: 70.31%] [G loss: 0.507151]\n",
      "epoch:10 step:9480 [D loss: 0.536945, acc.: 70.31%] [G loss: 0.551675]\n",
      "epoch:10 step:9481 [D loss: 0.519845, acc.: 71.88%] [G loss: 0.584904]\n",
      "epoch:10 step:9482 [D loss: 0.516301, acc.: 75.78%] [G loss: 0.718710]\n",
      "epoch:10 step:9483 [D loss: 0.555403, acc.: 72.66%] [G loss: 0.595596]\n",
      "epoch:10 step:9484 [D loss: 0.550653, acc.: 65.62%] [G loss: 0.542629]\n",
      "epoch:10 step:9485 [D loss: 0.544691, acc.: 70.31%] [G loss: 0.659386]\n",
      "epoch:10 step:9486 [D loss: 0.541882, acc.: 71.09%] [G loss: 0.690072]\n",
      "epoch:10 step:9487 [D loss: 0.524124, acc.: 75.00%] [G loss: 0.691273]\n",
      "epoch:10 step:9488 [D loss: 0.533622, acc.: 70.31%] [G loss: 0.570770]\n",
      "epoch:10 step:9489 [D loss: 0.472731, acc.: 75.00%] [G loss: 0.712291]\n",
      "epoch:10 step:9490 [D loss: 0.581411, acc.: 67.97%] [G loss: 0.633141]\n",
      "epoch:10 step:9491 [D loss: 0.531894, acc.: 71.88%] [G loss: 0.586812]\n",
      "epoch:10 step:9492 [D loss: 0.518353, acc.: 78.91%] [G loss: 0.895302]\n",
      "epoch:10 step:9493 [D loss: 0.518287, acc.: 74.22%] [G loss: 0.703856]\n",
      "epoch:10 step:9494 [D loss: 0.592394, acc.: 67.97%] [G loss: 0.598842]\n",
      "epoch:10 step:9495 [D loss: 0.580366, acc.: 64.06%] [G loss: 0.526732]\n",
      "epoch:10 step:9496 [D loss: 0.551123, acc.: 73.44%] [G loss: 0.615793]\n",
      "epoch:10 step:9497 [D loss: 0.538445, acc.: 71.88%] [G loss: 0.536227]\n",
      "epoch:10 step:9498 [D loss: 0.499377, acc.: 75.00%] [G loss: 0.477325]\n",
      "epoch:10 step:9499 [D loss: 0.622038, acc.: 63.28%] [G loss: 0.489932]\n",
      "epoch:10 step:9500 [D loss: 0.519924, acc.: 72.66%] [G loss: 0.573571]\n",
      "epoch:10 step:9501 [D loss: 0.539419, acc.: 67.19%] [G loss: 0.629162]\n",
      "epoch:10 step:9502 [D loss: 0.583772, acc.: 67.97%] [G loss: 0.501598]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:10 step:9503 [D loss: 0.568513, acc.: 65.62%] [G loss: 0.641973]\n",
      "epoch:10 step:9504 [D loss: 0.523174, acc.: 70.31%] [G loss: 0.621113]\n",
      "epoch:10 step:9505 [D loss: 0.512594, acc.: 77.34%] [G loss: 0.767999]\n",
      "epoch:10 step:9506 [D loss: 0.560393, acc.: 69.53%] [G loss: 0.726742]\n",
      "epoch:10 step:9507 [D loss: 0.646301, acc.: 65.62%] [G loss: 0.626903]\n",
      "epoch:10 step:9508 [D loss: 0.648953, acc.: 60.94%] [G loss: 0.478739]\n",
      "epoch:10 step:9509 [D loss: 0.543699, acc.: 69.53%] [G loss: 0.708679]\n",
      "epoch:10 step:9510 [D loss: 0.553407, acc.: 67.97%] [G loss: 0.558419]\n",
      "epoch:10 step:9511 [D loss: 0.529199, acc.: 67.97%] [G loss: 0.574363]\n",
      "epoch:10 step:9512 [D loss: 0.567664, acc.: 65.62%] [G loss: 0.449920]\n",
      "epoch:10 step:9513 [D loss: 0.590395, acc.: 69.53%] [G loss: 0.497677]\n",
      "epoch:10 step:9514 [D loss: 0.534679, acc.: 73.44%] [G loss: 0.665940]\n",
      "epoch:10 step:9515 [D loss: 0.571992, acc.: 67.19%] [G loss: 0.631578]\n",
      "epoch:10 step:9516 [D loss: 0.508781, acc.: 70.31%] [G loss: 0.537861]\n",
      "epoch:10 step:9517 [D loss: 0.642910, acc.: 62.50%] [G loss: 0.388568]\n",
      "epoch:10 step:9518 [D loss: 0.603799, acc.: 63.28%] [G loss: 0.408194]\n",
      "epoch:10 step:9519 [D loss: 0.488774, acc.: 77.34%] [G loss: 0.549481]\n",
      "epoch:10 step:9520 [D loss: 0.583112, acc.: 66.41%] [G loss: 0.649942]\n",
      "epoch:10 step:9521 [D loss: 0.585286, acc.: 66.41%] [G loss: 0.487397]\n",
      "epoch:10 step:9522 [D loss: 0.494642, acc.: 76.56%] [G loss: 0.678825]\n",
      "epoch:10 step:9523 [D loss: 0.590507, acc.: 66.41%] [G loss: 0.589857]\n",
      "epoch:10 step:9524 [D loss: 0.537809, acc.: 69.53%] [G loss: 0.567588]\n",
      "epoch:10 step:9525 [D loss: 0.448291, acc.: 81.25%] [G loss: 0.547504]\n",
      "epoch:10 step:9526 [D loss: 0.502911, acc.: 72.66%] [G loss: 0.661779]\n",
      "epoch:10 step:9527 [D loss: 0.566376, acc.: 66.41%] [G loss: 0.488499]\n",
      "epoch:10 step:9528 [D loss: 0.568364, acc.: 69.53%] [G loss: 0.643042]\n",
      "epoch:10 step:9529 [D loss: 0.521133, acc.: 75.78%] [G loss: 0.515495]\n",
      "epoch:10 step:9530 [D loss: 0.619260, acc.: 66.41%] [G loss: 0.612030]\n",
      "epoch:10 step:9531 [D loss: 0.524964, acc.: 71.09%] [G loss: 0.549231]\n",
      "epoch:10 step:9532 [D loss: 0.470855, acc.: 78.12%] [G loss: 0.702015]\n",
      "epoch:10 step:9533 [D loss: 0.561574, acc.: 71.09%] [G loss: 0.734360]\n",
      "epoch:10 step:9534 [D loss: 0.549509, acc.: 71.09%] [G loss: 0.723201]\n",
      "epoch:10 step:9535 [D loss: 0.540772, acc.: 67.97%] [G loss: 0.535241]\n",
      "epoch:10 step:9536 [D loss: 0.598265, acc.: 65.62%] [G loss: 0.483484]\n",
      "epoch:10 step:9537 [D loss: 0.548904, acc.: 70.31%] [G loss: 0.535689]\n",
      "epoch:10 step:9538 [D loss: 0.604330, acc.: 59.38%] [G loss: 0.557914]\n",
      "epoch:10 step:9539 [D loss: 0.637940, acc.: 62.50%] [G loss: 0.617220]\n",
      "epoch:10 step:9540 [D loss: 0.530085, acc.: 70.31%] [G loss: 0.476439]\n",
      "epoch:10 step:9541 [D loss: 0.498860, acc.: 73.44%] [G loss: 0.517486]\n",
      "epoch:10 step:9542 [D loss: 0.538790, acc.: 71.09%] [G loss: 0.660094]\n",
      "epoch:10 step:9543 [D loss: 0.461424, acc.: 78.91%] [G loss: 0.583417]\n",
      "epoch:10 step:9544 [D loss: 0.625421, acc.: 64.84%] [G loss: 0.449066]\n",
      "epoch:10 step:9545 [D loss: 0.579178, acc.: 63.28%] [G loss: 0.486051]\n",
      "epoch:10 step:9546 [D loss: 0.508240, acc.: 70.31%] [G loss: 0.514119]\n",
      "epoch:10 step:9547 [D loss: 0.518774, acc.: 73.44%] [G loss: 0.485602]\n",
      "epoch:10 step:9548 [D loss: 0.567658, acc.: 65.62%] [G loss: 0.580228]\n",
      "epoch:10 step:9549 [D loss: 0.607777, acc.: 60.16%] [G loss: 0.451365]\n",
      "epoch:10 step:9550 [D loss: 0.560455, acc.: 68.75%] [G loss: 0.447952]\n",
      "epoch:10 step:9551 [D loss: 0.575198, acc.: 71.88%] [G loss: 0.474128]\n",
      "epoch:10 step:9552 [D loss: 0.589977, acc.: 67.97%] [G loss: 0.483972]\n",
      "epoch:10 step:9553 [D loss: 0.645803, acc.: 64.84%] [G loss: 0.599664]\n",
      "epoch:10 step:9554 [D loss: 0.569876, acc.: 67.97%] [G loss: 0.832799]\n",
      "epoch:10 step:9555 [D loss: 0.628259, acc.: 63.28%] [G loss: 0.532683]\n",
      "epoch:10 step:9556 [D loss: 0.612066, acc.: 66.41%] [G loss: 0.589265]\n",
      "epoch:10 step:9557 [D loss: 0.587005, acc.: 66.41%] [G loss: 0.463202]\n",
      "epoch:10 step:9558 [D loss: 0.524436, acc.: 71.88%] [G loss: 0.432022]\n",
      "epoch:10 step:9559 [D loss: 0.600128, acc.: 64.84%] [G loss: 0.374099]\n",
      "epoch:10 step:9560 [D loss: 0.483107, acc.: 77.34%] [G loss: 0.554089]\n",
      "epoch:10 step:9561 [D loss: 0.538801, acc.: 71.88%] [G loss: 0.576295]\n",
      "epoch:10 step:9562 [D loss: 0.524553, acc.: 74.22%] [G loss: 0.543957]\n",
      "epoch:10 step:9563 [D loss: 0.565213, acc.: 69.53%] [G loss: 0.535495]\n",
      "epoch:10 step:9564 [D loss: 0.520377, acc.: 74.22%] [G loss: 0.627328]\n",
      "epoch:10 step:9565 [D loss: 0.558517, acc.: 71.09%] [G loss: 0.618250]\n",
      "epoch:10 step:9566 [D loss: 0.583281, acc.: 67.19%] [G loss: 0.493216]\n",
      "epoch:10 step:9567 [D loss: 0.505268, acc.: 71.09%] [G loss: 0.439811]\n",
      "epoch:10 step:9568 [D loss: 0.480423, acc.: 77.34%] [G loss: 0.608839]\n",
      "epoch:10 step:9569 [D loss: 0.584511, acc.: 66.41%] [G loss: 0.553500]\n",
      "epoch:10 step:9570 [D loss: 0.565119, acc.: 72.66%] [G loss: 0.597777]\n",
      "epoch:10 step:9571 [D loss: 0.585650, acc.: 68.75%] [G loss: 0.560283]\n",
      "epoch:10 step:9572 [D loss: 0.497301, acc.: 74.22%] [G loss: 0.684144]\n",
      "epoch:10 step:9573 [D loss: 0.611583, acc.: 64.06%] [G loss: 0.567634]\n",
      "epoch:10 step:9574 [D loss: 0.607298, acc.: 65.62%] [G loss: 0.553751]\n",
      "epoch:10 step:9575 [D loss: 0.532888, acc.: 75.78%] [G loss: 0.613438]\n",
      "epoch:10 step:9576 [D loss: 0.551990, acc.: 73.44%] [G loss: 0.619279]\n",
      "epoch:10 step:9577 [D loss: 0.456771, acc.: 78.12%] [G loss: 0.622709]\n",
      "epoch:10 step:9578 [D loss: 0.424153, acc.: 78.91%] [G loss: 0.582384]\n",
      "epoch:10 step:9579 [D loss: 0.516406, acc.: 74.22%] [G loss: 0.544700]\n",
      "epoch:10 step:9580 [D loss: 0.599643, acc.: 67.97%] [G loss: 0.563646]\n",
      "epoch:10 step:9581 [D loss: 0.582621, acc.: 64.84%] [G loss: 0.550902]\n",
      "epoch:10 step:9582 [D loss: 0.580786, acc.: 66.41%] [G loss: 0.457468]\n",
      "epoch:10 step:9583 [D loss: 0.558083, acc.: 71.88%] [G loss: 0.574929]\n",
      "epoch:10 step:9584 [D loss: 0.661443, acc.: 62.50%] [G loss: 0.510208]\n",
      "epoch:10 step:9585 [D loss: 0.568593, acc.: 65.62%] [G loss: 0.530897]\n",
      "epoch:10 step:9586 [D loss: 0.525747, acc.: 71.88%] [G loss: 0.700653]\n",
      "epoch:10 step:9587 [D loss: 0.505611, acc.: 77.34%] [G loss: 0.603817]\n",
      "epoch:10 step:9588 [D loss: 0.536236, acc.: 71.88%] [G loss: 0.576599]\n",
      "epoch:10 step:9589 [D loss: 0.516760, acc.: 75.00%] [G loss: 0.662808]\n",
      "epoch:10 step:9590 [D loss: 0.632133, acc.: 64.06%] [G loss: 0.568612]\n",
      "epoch:10 step:9591 [D loss: 0.496701, acc.: 71.88%] [G loss: 0.718004]\n",
      "epoch:10 step:9592 [D loss: 0.472577, acc.: 77.34%] [G loss: 0.714168]\n",
      "epoch:10 step:9593 [D loss: 0.484294, acc.: 78.12%] [G loss: 0.765839]\n",
      "epoch:10 step:9594 [D loss: 0.562523, acc.: 69.53%] [G loss: 0.743925]\n",
      "epoch:10 step:9595 [D loss: 0.608806, acc.: 61.72%] [G loss: 0.692984]\n",
      "epoch:10 step:9596 [D loss: 0.611682, acc.: 60.94%] [G loss: 0.621915]\n",
      "epoch:10 step:9597 [D loss: 0.520098, acc.: 73.44%] [G loss: 0.553540]\n",
      "epoch:10 step:9598 [D loss: 0.584944, acc.: 68.75%] [G loss: 0.370378]\n",
      "epoch:10 step:9599 [D loss: 0.578707, acc.: 72.66%] [G loss: 0.548449]\n",
      "epoch:10 step:9600 [D loss: 0.484052, acc.: 77.34%] [G loss: 0.776875]\n",
      "##############\n",
      "[3.3860589  1.56517724 6.38015375 4.8389092  3.82036951 6.02361\n",
      " 4.72875673 4.76195938 4.66101045 3.89847213]\n",
      "##########\n",
      "epoch:10 step:9601 [D loss: 0.440483, acc.: 80.47%] [G loss: 0.835002]\n",
      "epoch:10 step:9602 [D loss: 0.465069, acc.: 74.22%] [G loss: 0.697660]\n",
      "epoch:10 step:9603 [D loss: 0.595276, acc.: 65.62%] [G loss: 0.671701]\n",
      "epoch:10 step:9604 [D loss: 0.471656, acc.: 78.91%] [G loss: 0.739218]\n",
      "epoch:10 step:9605 [D loss: 0.573468, acc.: 62.50%] [G loss: 0.566634]\n",
      "epoch:10 step:9606 [D loss: 0.504464, acc.: 72.66%] [G loss: 0.642677]\n",
      "epoch:10 step:9607 [D loss: 0.527902, acc.: 69.53%] [G loss: 0.448319]\n",
      "epoch:10 step:9608 [D loss: 0.540730, acc.: 71.09%] [G loss: 0.651972]\n",
      "epoch:10 step:9609 [D loss: 0.543933, acc.: 67.19%] [G loss: 0.686392]\n",
      "epoch:10 step:9610 [D loss: 0.582653, acc.: 63.28%] [G loss: 0.618734]\n",
      "epoch:10 step:9611 [D loss: 0.525918, acc.: 72.66%] [G loss: 0.638780]\n",
      "epoch:10 step:9612 [D loss: 0.499546, acc.: 71.09%] [G loss: 0.622754]\n",
      "epoch:10 step:9613 [D loss: 0.511410, acc.: 70.31%] [G loss: 0.569397]\n",
      "epoch:10 step:9614 [D loss: 0.483876, acc.: 75.78%] [G loss: 0.700412]\n",
      "epoch:10 step:9615 [D loss: 0.552742, acc.: 68.75%] [G loss: 0.581734]\n",
      "epoch:10 step:9616 [D loss: 0.592653, acc.: 64.84%] [G loss: 0.537545]\n",
      "epoch:10 step:9617 [D loss: 0.585822, acc.: 71.09%] [G loss: 0.586557]\n",
      "epoch:10 step:9618 [D loss: 0.493051, acc.: 78.91%] [G loss: 0.695959]\n",
      "epoch:10 step:9619 [D loss: 0.565710, acc.: 71.88%] [G loss: 0.707212]\n",
      "epoch:10 step:9620 [D loss: 0.620340, acc.: 64.06%] [G loss: 0.642269]\n",
      "epoch:10 step:9621 [D loss: 0.702403, acc.: 56.25%] [G loss: 0.515226]\n",
      "epoch:10 step:9622 [D loss: 0.545237, acc.: 71.09%] [G loss: 0.649878]\n",
      "epoch:10 step:9623 [D loss: 0.569337, acc.: 71.88%] [G loss: 0.501195]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:10 step:9624 [D loss: 0.494446, acc.: 73.44%] [G loss: 0.564567]\n",
      "epoch:10 step:9625 [D loss: 0.515771, acc.: 73.44%] [G loss: 0.548159]\n",
      "epoch:10 step:9626 [D loss: 0.534849, acc.: 69.53%] [G loss: 0.607463]\n",
      "epoch:10 step:9627 [D loss: 0.573331, acc.: 65.62%] [G loss: 0.506600]\n",
      "epoch:10 step:9628 [D loss: 0.522475, acc.: 70.31%] [G loss: 0.556792]\n",
      "epoch:10 step:9629 [D loss: 0.568693, acc.: 64.84%] [G loss: 0.495948]\n",
      "epoch:10 step:9630 [D loss: 0.592720, acc.: 61.72%] [G loss: 0.560988]\n",
      "epoch:10 step:9631 [D loss: 0.553140, acc.: 72.66%] [G loss: 0.609966]\n",
      "epoch:10 step:9632 [D loss: 0.511838, acc.: 76.56%] [G loss: 0.617787]\n",
      "epoch:10 step:9633 [D loss: 0.567055, acc.: 67.19%] [G loss: 0.568198]\n",
      "epoch:10 step:9634 [D loss: 0.523778, acc.: 74.22%] [G loss: 0.575780]\n",
      "epoch:10 step:9635 [D loss: 0.556954, acc.: 71.88%] [G loss: 0.551729]\n",
      "epoch:10 step:9636 [D loss: 0.580005, acc.: 66.41%] [G loss: 0.467208]\n",
      "epoch:10 step:9637 [D loss: 0.617391, acc.: 65.62%] [G loss: 0.561414]\n",
      "epoch:10 step:9638 [D loss: 0.516217, acc.: 78.91%] [G loss: 0.575257]\n",
      "epoch:10 step:9639 [D loss: 0.563801, acc.: 71.09%] [G loss: 0.584068]\n",
      "epoch:10 step:9640 [D loss: 0.497937, acc.: 77.34%] [G loss: 0.712357]\n",
      "epoch:10 step:9641 [D loss: 0.497697, acc.: 71.88%] [G loss: 0.599926]\n",
      "epoch:10 step:9642 [D loss: 0.555657, acc.: 69.53%] [G loss: 0.695070]\n",
      "epoch:10 step:9643 [D loss: 0.606253, acc.: 63.28%] [G loss: 0.539141]\n",
      "epoch:10 step:9644 [D loss: 0.538553, acc.: 73.44%] [G loss: 0.560822]\n",
      "epoch:10 step:9645 [D loss: 0.565399, acc.: 69.53%] [G loss: 0.572256]\n",
      "epoch:10 step:9646 [D loss: 0.544391, acc.: 75.00%] [G loss: 0.594651]\n",
      "epoch:10 step:9647 [D loss: 0.670135, acc.: 58.59%] [G loss: 0.369926]\n",
      "epoch:10 step:9648 [D loss: 0.658576, acc.: 61.72%] [G loss: 0.363947]\n",
      "epoch:10 step:9649 [D loss: 0.593619, acc.: 63.28%] [G loss: 0.470257]\n",
      "epoch:10 step:9650 [D loss: 0.581943, acc.: 69.53%] [G loss: 0.535114]\n",
      "epoch:10 step:9651 [D loss: 0.572042, acc.: 68.75%] [G loss: 0.532262]\n",
      "epoch:10 step:9652 [D loss: 0.576936, acc.: 66.41%] [G loss: 0.563751]\n",
      "epoch:10 step:9653 [D loss: 0.490198, acc.: 78.12%] [G loss: 0.646455]\n",
      "epoch:10 step:9654 [D loss: 0.532442, acc.: 74.22%] [G loss: 0.638236]\n",
      "epoch:10 step:9655 [D loss: 0.522569, acc.: 72.66%] [G loss: 0.612195]\n",
      "epoch:10 step:9656 [D loss: 0.490093, acc.: 75.78%] [G loss: 0.597237]\n",
      "epoch:10 step:9657 [D loss: 0.563508, acc.: 69.53%] [G loss: 0.549537]\n",
      "epoch:10 step:9658 [D loss: 0.528982, acc.: 72.66%] [G loss: 0.627838]\n",
      "epoch:10 step:9659 [D loss: 0.543893, acc.: 67.19%] [G loss: 0.537081]\n",
      "epoch:10 step:9660 [D loss: 0.619897, acc.: 61.72%] [G loss: 0.570557]\n",
      "epoch:10 step:9661 [D loss: 0.587433, acc.: 68.75%] [G loss: 0.608397]\n",
      "epoch:10 step:9662 [D loss: 0.539381, acc.: 69.53%] [G loss: 0.547193]\n",
      "epoch:10 step:9663 [D loss: 0.575890, acc.: 64.06%] [G loss: 0.502231]\n",
      "epoch:10 step:9664 [D loss: 0.624986, acc.: 64.84%] [G loss: 0.363334]\n",
      "epoch:10 step:9665 [D loss: 0.538113, acc.: 69.53%] [G loss: 0.537511]\n",
      "epoch:10 step:9666 [D loss: 0.514520, acc.: 68.75%] [G loss: 0.385338]\n",
      "epoch:10 step:9667 [D loss: 0.522137, acc.: 76.56%] [G loss: 0.510856]\n",
      "epoch:10 step:9668 [D loss: 0.482169, acc.: 78.12%] [G loss: 0.526999]\n",
      "epoch:10 step:9669 [D loss: 0.529640, acc.: 71.09%] [G loss: 0.630636]\n",
      "epoch:10 step:9670 [D loss: 0.476138, acc.: 78.12%] [G loss: 0.723629]\n",
      "epoch:10 step:9671 [D loss: 0.647511, acc.: 66.41%] [G loss: 0.567949]\n",
      "epoch:10 step:9672 [D loss: 0.541391, acc.: 71.09%] [G loss: 0.502217]\n",
      "epoch:10 step:9673 [D loss: 0.557373, acc.: 68.75%] [G loss: 0.570155]\n",
      "epoch:10 step:9674 [D loss: 0.526306, acc.: 69.53%] [G loss: 0.652774]\n",
      "epoch:10 step:9675 [D loss: 0.557778, acc.: 71.09%] [G loss: 0.669054]\n",
      "epoch:10 step:9676 [D loss: 0.538578, acc.: 73.44%] [G loss: 0.709442]\n",
      "epoch:10 step:9677 [D loss: 0.481820, acc.: 78.91%] [G loss: 0.621850]\n",
      "epoch:10 step:9678 [D loss: 0.589421, acc.: 68.75%] [G loss: 0.608397]\n",
      "epoch:10 step:9679 [D loss: 0.523775, acc.: 68.75%] [G loss: 0.595393]\n",
      "epoch:10 step:9680 [D loss: 0.553261, acc.: 68.75%] [G loss: 0.727922]\n",
      "epoch:10 step:9681 [D loss: 0.575595, acc.: 67.97%] [G loss: 0.725615]\n",
      "epoch:10 step:9682 [D loss: 0.479347, acc.: 75.78%] [G loss: 0.733058]\n",
      "epoch:10 step:9683 [D loss: 0.478275, acc.: 79.69%] [G loss: 0.963502]\n",
      "epoch:10 step:9684 [D loss: 0.479564, acc.: 76.56%] [G loss: 0.746347]\n",
      "epoch:10 step:9685 [D loss: 0.475629, acc.: 78.91%] [G loss: 1.004283]\n",
      "epoch:10 step:9686 [D loss: 0.719908, acc.: 62.50%] [G loss: 0.691453]\n",
      "epoch:10 step:9687 [D loss: 0.554524, acc.: 67.19%] [G loss: 0.616165]\n",
      "epoch:10 step:9688 [D loss: 0.515102, acc.: 75.78%] [G loss: 0.657540]\n",
      "epoch:10 step:9689 [D loss: 0.560395, acc.: 67.19%] [G loss: 0.551925]\n",
      "epoch:10 step:9690 [D loss: 0.567218, acc.: 67.19%] [G loss: 0.491547]\n",
      "epoch:10 step:9691 [D loss: 0.457624, acc.: 81.25%] [G loss: 0.803913]\n",
      "epoch:10 step:9692 [D loss: 0.579804, acc.: 71.09%] [G loss: 0.652214]\n",
      "epoch:10 step:9693 [D loss: 0.572692, acc.: 71.09%] [G loss: 0.710483]\n",
      "epoch:10 step:9694 [D loss: 0.603029, acc.: 64.84%] [G loss: 0.492489]\n",
      "epoch:10 step:9695 [D loss: 0.565245, acc.: 66.41%] [G loss: 0.458785]\n",
      "epoch:10 step:9696 [D loss: 0.512971, acc.: 76.56%] [G loss: 0.607939]\n",
      "epoch:10 step:9697 [D loss: 0.513289, acc.: 72.66%] [G loss: 0.582325]\n",
      "epoch:10 step:9698 [D loss: 0.501226, acc.: 75.00%] [G loss: 0.640937]\n",
      "epoch:10 step:9699 [D loss: 0.557788, acc.: 66.41%] [G loss: 0.674836]\n",
      "epoch:10 step:9700 [D loss: 0.547042, acc.: 67.97%] [G loss: 0.486549]\n",
      "epoch:10 step:9701 [D loss: 0.566669, acc.: 67.97%] [G loss: 0.496246]\n",
      "epoch:10 step:9702 [D loss: 0.500973, acc.: 71.09%] [G loss: 0.741461]\n",
      "epoch:10 step:9703 [D loss: 0.506432, acc.: 78.12%] [G loss: 0.532876]\n",
      "epoch:10 step:9704 [D loss: 0.549316, acc.: 67.19%] [G loss: 0.579874]\n",
      "epoch:10 step:9705 [D loss: 0.522173, acc.: 73.44%] [G loss: 0.591865]\n",
      "epoch:10 step:9706 [D loss: 0.549122, acc.: 71.09%] [G loss: 0.581193]\n",
      "epoch:10 step:9707 [D loss: 0.566194, acc.: 71.09%] [G loss: 0.479755]\n",
      "epoch:10 step:9708 [D loss: 0.540381, acc.: 69.53%] [G loss: 0.699212]\n",
      "epoch:10 step:9709 [D loss: 0.550050, acc.: 71.88%] [G loss: 0.630966]\n",
      "epoch:10 step:9710 [D loss: 0.522211, acc.: 73.44%] [G loss: 0.617010]\n",
      "epoch:10 step:9711 [D loss: 0.633374, acc.: 64.06%] [G loss: 0.633656]\n",
      "epoch:10 step:9712 [D loss: 0.616429, acc.: 64.84%] [G loss: 0.659593]\n",
      "epoch:10 step:9713 [D loss: 0.517103, acc.: 75.78%] [G loss: 0.593673]\n",
      "epoch:10 step:9714 [D loss: 0.481833, acc.: 75.00%] [G loss: 0.563111]\n",
      "epoch:10 step:9715 [D loss: 0.597046, acc.: 67.97%] [G loss: 0.653863]\n",
      "epoch:10 step:9716 [D loss: 0.523290, acc.: 71.09%] [G loss: 0.889068]\n",
      "epoch:10 step:9717 [D loss: 0.436669, acc.: 80.47%] [G loss: 0.950145]\n",
      "epoch:10 step:9718 [D loss: 0.639660, acc.: 65.62%] [G loss: 0.494944]\n",
      "epoch:10 step:9719 [D loss: 0.721515, acc.: 56.25%] [G loss: 0.423805]\n",
      "epoch:10 step:9720 [D loss: 0.503577, acc.: 71.88%] [G loss: 0.503667]\n",
      "epoch:10 step:9721 [D loss: 0.539317, acc.: 74.22%] [G loss: 0.526124]\n",
      "epoch:10 step:9722 [D loss: 0.602924, acc.: 63.28%] [G loss: 0.680801]\n",
      "epoch:10 step:9723 [D loss: 0.580590, acc.: 65.62%] [G loss: 0.657499]\n",
      "epoch:10 step:9724 [D loss: 0.404031, acc.: 86.72%] [G loss: 0.795074]\n",
      "epoch:10 step:9725 [D loss: 0.511702, acc.: 77.34%] [G loss: 0.735044]\n",
      "epoch:10 step:9726 [D loss: 0.572912, acc.: 66.41%] [G loss: 0.660185]\n",
      "epoch:10 step:9727 [D loss: 0.457348, acc.: 78.12%] [G loss: 0.724599]\n",
      "epoch:10 step:9728 [D loss: 0.446686, acc.: 73.44%] [G loss: 0.762909]\n",
      "epoch:10 step:9729 [D loss: 0.474733, acc.: 77.34%] [G loss: 0.694646]\n",
      "epoch:10 step:9730 [D loss: 0.519648, acc.: 69.53%] [G loss: 0.771277]\n",
      "epoch:10 step:9731 [D loss: 0.517939, acc.: 74.22%] [G loss: 0.755727]\n",
      "epoch:10 step:9732 [D loss: 0.582083, acc.: 69.53%] [G loss: 0.668196]\n",
      "epoch:10 step:9733 [D loss: 0.534764, acc.: 74.22%] [G loss: 0.526441]\n",
      "epoch:10 step:9734 [D loss: 0.517984, acc.: 72.66%] [G loss: 0.691023]\n",
      "epoch:10 step:9735 [D loss: 0.549703, acc.: 70.31%] [G loss: 0.545259]\n",
      "epoch:10 step:9736 [D loss: 0.497715, acc.: 72.66%] [G loss: 0.633458]\n",
      "epoch:10 step:9737 [D loss: 0.663087, acc.: 61.72%] [G loss: 0.473714]\n",
      "epoch:10 step:9738 [D loss: 0.568230, acc.: 68.75%] [G loss: 0.520833]\n",
      "epoch:10 step:9739 [D loss: 0.552173, acc.: 73.44%] [G loss: 0.609561]\n",
      "epoch:10 step:9740 [D loss: 0.526121, acc.: 73.44%] [G loss: 0.577736]\n",
      "epoch:10 step:9741 [D loss: 0.612339, acc.: 68.75%] [G loss: 0.735763]\n",
      "epoch:10 step:9742 [D loss: 0.533987, acc.: 69.53%] [G loss: 0.667886]\n",
      "epoch:10 step:9743 [D loss: 0.568547, acc.: 64.84%] [G loss: 0.637971]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:10 step:9744 [D loss: 0.540088, acc.: 74.22%] [G loss: 0.663624]\n",
      "epoch:10 step:9745 [D loss: 0.560596, acc.: 70.31%] [G loss: 0.636992]\n",
      "epoch:10 step:9746 [D loss: 0.743338, acc.: 50.78%] [G loss: 0.391538]\n",
      "epoch:10 step:9747 [D loss: 0.574889, acc.: 63.28%] [G loss: 0.531285]\n",
      "epoch:10 step:9748 [D loss: 0.540373, acc.: 67.19%] [G loss: 0.624029]\n",
      "epoch:10 step:9749 [D loss: 0.602849, acc.: 67.19%] [G loss: 0.524550]\n",
      "epoch:10 step:9750 [D loss: 0.583213, acc.: 69.53%] [G loss: 0.541253]\n",
      "epoch:10 step:9751 [D loss: 0.480562, acc.: 78.12%] [G loss: 0.674081]\n",
      "epoch:10 step:9752 [D loss: 0.513093, acc.: 75.78%] [G loss: 0.676026]\n",
      "epoch:10 step:9753 [D loss: 0.598641, acc.: 64.84%] [G loss: 0.587234]\n",
      "epoch:10 step:9754 [D loss: 0.593349, acc.: 67.19%] [G loss: 0.526597]\n",
      "epoch:10 step:9755 [D loss: 0.479141, acc.: 76.56%] [G loss: 0.726590]\n",
      "epoch:10 step:9756 [D loss: 0.584532, acc.: 67.19%] [G loss: 0.621611]\n",
      "epoch:10 step:9757 [D loss: 0.550430, acc.: 69.53%] [G loss: 0.498955]\n",
      "epoch:10 step:9758 [D loss: 0.510162, acc.: 75.78%] [G loss: 0.672653]\n",
      "epoch:10 step:9759 [D loss: 0.547868, acc.: 72.66%] [G loss: 0.623752]\n",
      "epoch:10 step:9760 [D loss: 0.597862, acc.: 66.41%] [G loss: 0.483010]\n",
      "epoch:10 step:9761 [D loss: 0.534303, acc.: 72.66%] [G loss: 0.596410]\n",
      "epoch:10 step:9762 [D loss: 0.469493, acc.: 73.44%] [G loss: 0.579303]\n",
      "epoch:10 step:9763 [D loss: 0.608144, acc.: 68.75%] [G loss: 0.635358]\n",
      "epoch:10 step:9764 [D loss: 0.508050, acc.: 75.00%] [G loss: 0.553232]\n",
      "epoch:10 step:9765 [D loss: 0.508059, acc.: 71.88%] [G loss: 0.691007]\n",
      "epoch:10 step:9766 [D loss: 0.606233, acc.: 66.41%] [G loss: 0.676822]\n",
      "epoch:10 step:9767 [D loss: 0.565575, acc.: 69.53%] [G loss: 0.470527]\n",
      "epoch:10 step:9768 [D loss: 0.522974, acc.: 71.09%] [G loss: 0.818943]\n",
      "epoch:10 step:9769 [D loss: 0.561306, acc.: 67.97%] [G loss: 0.607642]\n",
      "epoch:10 step:9770 [D loss: 0.645410, acc.: 57.03%] [G loss: 0.449182]\n",
      "epoch:10 step:9771 [D loss: 0.613770, acc.: 60.16%] [G loss: 0.462180]\n",
      "epoch:10 step:9772 [D loss: 0.520637, acc.: 75.00%] [G loss: 0.615442]\n",
      "epoch:10 step:9773 [D loss: 0.515825, acc.: 72.66%] [G loss: 0.716806]\n",
      "epoch:10 step:9774 [D loss: 0.552948, acc.: 68.75%] [G loss: 0.577939]\n",
      "epoch:10 step:9775 [D loss: 0.534358, acc.: 66.41%] [G loss: 0.615285]\n",
      "epoch:10 step:9776 [D loss: 0.526792, acc.: 72.66%] [G loss: 0.674184]\n",
      "epoch:10 step:9777 [D loss: 0.572951, acc.: 67.19%] [G loss: 0.601755]\n",
      "epoch:10 step:9778 [D loss: 0.561809, acc.: 68.75%] [G loss: 0.688461]\n",
      "epoch:10 step:9779 [D loss: 0.604164, acc.: 63.28%] [G loss: 0.580090]\n",
      "epoch:10 step:9780 [D loss: 0.548475, acc.: 71.09%] [G loss: 0.504283]\n",
      "epoch:10 step:9781 [D loss: 0.599669, acc.: 61.72%] [G loss: 0.618403]\n",
      "epoch:10 step:9782 [D loss: 0.571560, acc.: 67.19%] [G loss: 0.445552]\n",
      "epoch:10 step:9783 [D loss: 0.556236, acc.: 67.97%] [G loss: 0.555122]\n",
      "epoch:10 step:9784 [D loss: 0.485828, acc.: 75.78%] [G loss: 0.638762]\n",
      "epoch:10 step:9785 [D loss: 0.554213, acc.: 66.41%] [G loss: 0.516526]\n",
      "epoch:10 step:9786 [D loss: 0.531429, acc.: 68.75%] [G loss: 0.738351]\n",
      "epoch:10 step:9787 [D loss: 0.557829, acc.: 72.66%] [G loss: 0.584124]\n",
      "epoch:10 step:9788 [D loss: 0.597701, acc.: 67.19%] [G loss: 0.452342]\n",
      "epoch:10 step:9789 [D loss: 0.568475, acc.: 70.31%] [G loss: 0.538824]\n",
      "epoch:10 step:9790 [D loss: 0.552836, acc.: 67.97%] [G loss: 0.713854]\n",
      "epoch:10 step:9791 [D loss: 0.551766, acc.: 66.41%] [G loss: 0.602227]\n",
      "epoch:10 step:9792 [D loss: 0.615688, acc.: 64.06%] [G loss: 0.533533]\n",
      "epoch:10 step:9793 [D loss: 0.558514, acc.: 67.19%] [G loss: 0.578750]\n",
      "epoch:10 step:9794 [D loss: 0.619420, acc.: 60.94%] [G loss: 0.559308]\n",
      "epoch:10 step:9795 [D loss: 0.576692, acc.: 67.19%] [G loss: 0.599905]\n",
      "epoch:10 step:9796 [D loss: 0.519760, acc.: 72.66%] [G loss: 0.642767]\n",
      "epoch:10 step:9797 [D loss: 0.494658, acc.: 76.56%] [G loss: 0.830213]\n",
      "epoch:10 step:9798 [D loss: 0.536380, acc.: 67.19%] [G loss: 0.609452]\n",
      "epoch:10 step:9799 [D loss: 0.471410, acc.: 76.56%] [G loss: 0.732327]\n",
      "epoch:10 step:9800 [D loss: 0.541201, acc.: 74.22%] [G loss: 0.572635]\n",
      "##############\n",
      "[3.20916621 1.28965675 6.34685268 4.96193272 3.82906203 5.72075341\n",
      " 4.66738149 4.91400493 4.50620761 4.14843169]\n",
      "##########\n",
      "epoch:10 step:9801 [D loss: 0.527344, acc.: 73.44%] [G loss: 0.605100]\n",
      "epoch:10 step:9802 [D loss: 0.582747, acc.: 66.41%] [G loss: 0.508740]\n",
      "epoch:10 step:9803 [D loss: 0.584064, acc.: 72.66%] [G loss: 0.475186]\n",
      "epoch:10 step:9804 [D loss: 0.506402, acc.: 78.91%] [G loss: 0.524509]\n",
      "epoch:10 step:9805 [D loss: 0.539483, acc.: 73.44%] [G loss: 0.596752]\n",
      "epoch:10 step:9806 [D loss: 0.475119, acc.: 78.91%] [G loss: 0.810682]\n",
      "epoch:10 step:9807 [D loss: 0.623771, acc.: 69.53%] [G loss: 0.610203]\n",
      "epoch:10 step:9808 [D loss: 0.591797, acc.: 64.06%] [G loss: 0.472760]\n",
      "epoch:10 step:9809 [D loss: 0.487604, acc.: 78.12%] [G loss: 0.579822]\n",
      "epoch:10 step:9810 [D loss: 0.538833, acc.: 71.09%] [G loss: 0.771460]\n",
      "epoch:10 step:9811 [D loss: 0.628223, acc.: 57.81%] [G loss: 0.620945]\n",
      "epoch:10 step:9812 [D loss: 0.529946, acc.: 72.66%] [G loss: 0.667723]\n",
      "epoch:10 step:9813 [D loss: 0.557570, acc.: 67.97%] [G loss: 0.492218]\n",
      "epoch:10 step:9814 [D loss: 0.518368, acc.: 67.19%] [G loss: 0.655107]\n",
      "epoch:10 step:9815 [D loss: 0.597180, acc.: 68.75%] [G loss: 0.640306]\n",
      "epoch:10 step:9816 [D loss: 0.525041, acc.: 70.31%] [G loss: 0.568689]\n",
      "epoch:10 step:9817 [D loss: 0.517231, acc.: 70.31%] [G loss: 0.687431]\n",
      "epoch:10 step:9818 [D loss: 0.505794, acc.: 75.00%] [G loss: 0.570829]\n",
      "epoch:10 step:9819 [D loss: 0.487782, acc.: 74.22%] [G loss: 0.670146]\n",
      "epoch:10 step:9820 [D loss: 0.508416, acc.: 74.22%] [G loss: 0.532296]\n",
      "epoch:10 step:9821 [D loss: 0.449174, acc.: 81.25%] [G loss: 0.868027]\n",
      "epoch:10 step:9822 [D loss: 0.460997, acc.: 75.00%] [G loss: 0.805946]\n",
      "epoch:10 step:9823 [D loss: 0.555837, acc.: 71.09%] [G loss: 0.647956]\n",
      "epoch:10 step:9824 [D loss: 0.549153, acc.: 71.88%] [G loss: 0.626809]\n",
      "epoch:10 step:9825 [D loss: 0.557588, acc.: 67.97%] [G loss: 0.434999]\n",
      "epoch:10 step:9826 [D loss: 0.658328, acc.: 62.50%] [G loss: 0.651639]\n",
      "epoch:10 step:9827 [D loss: 0.452929, acc.: 83.59%] [G loss: 0.613652]\n",
      "epoch:10 step:9828 [D loss: 0.696346, acc.: 59.38%] [G loss: 0.600490]\n",
      "epoch:10 step:9829 [D loss: 0.554524, acc.: 71.09%] [G loss: 0.579665]\n",
      "epoch:10 step:9830 [D loss: 0.526203, acc.: 74.22%] [G loss: 0.584020]\n",
      "epoch:10 step:9831 [D loss: 0.543053, acc.: 68.75%] [G loss: 0.576384]\n",
      "epoch:10 step:9832 [D loss: 0.565099, acc.: 66.41%] [G loss: 0.519123]\n",
      "epoch:10 step:9833 [D loss: 0.583659, acc.: 64.06%] [G loss: 0.522585]\n",
      "epoch:10 step:9834 [D loss: 0.513500, acc.: 71.88%] [G loss: 0.541651]\n",
      "epoch:10 step:9835 [D loss: 0.663633, acc.: 57.03%] [G loss: 0.587075]\n",
      "epoch:10 step:9836 [D loss: 0.525263, acc.: 71.09%] [G loss: 0.527014]\n",
      "epoch:10 step:9837 [D loss: 0.502209, acc.: 72.66%] [G loss: 0.511203]\n",
      "epoch:10 step:9838 [D loss: 0.609034, acc.: 68.75%] [G loss: 0.668571]\n",
      "epoch:10 step:9839 [D loss: 0.534305, acc.: 70.31%] [G loss: 0.759166]\n",
      "epoch:10 step:9840 [D loss: 0.599213, acc.: 67.97%] [G loss: 0.659259]\n",
      "epoch:10 step:9841 [D loss: 0.471733, acc.: 78.12%] [G loss: 0.722654]\n",
      "epoch:10 step:9842 [D loss: 0.454544, acc.: 80.47%] [G loss: 1.002456]\n",
      "epoch:10 step:9843 [D loss: 0.723446, acc.: 57.81%] [G loss: 0.631651]\n",
      "epoch:10 step:9844 [D loss: 0.572723, acc.: 64.84%] [G loss: 0.628968]\n",
      "epoch:10 step:9845 [D loss: 0.557089, acc.: 68.75%] [G loss: 0.608171]\n",
      "epoch:10 step:9846 [D loss: 0.539196, acc.: 77.34%] [G loss: 0.648833]\n",
      "epoch:10 step:9847 [D loss: 0.647865, acc.: 64.84%] [G loss: 0.506052]\n",
      "epoch:10 step:9848 [D loss: 0.621758, acc.: 61.72%] [G loss: 0.400135]\n",
      "epoch:10 step:9849 [D loss: 0.600267, acc.: 66.41%] [G loss: 0.373462]\n",
      "epoch:10 step:9850 [D loss: 0.636964, acc.: 58.59%] [G loss: 0.578364]\n",
      "epoch:10 step:9851 [D loss: 0.532526, acc.: 71.88%] [G loss: 0.721560]\n",
      "epoch:10 step:9852 [D loss: 0.618355, acc.: 65.62%] [G loss: 0.533226]\n",
      "epoch:10 step:9853 [D loss: 0.559597, acc.: 68.75%] [G loss: 0.540496]\n",
      "epoch:10 step:9854 [D loss: 0.536963, acc.: 67.97%] [G loss: 0.489863]\n",
      "epoch:10 step:9855 [D loss: 0.551014, acc.: 69.53%] [G loss: 0.505826]\n",
      "epoch:10 step:9856 [D loss: 0.552357, acc.: 67.19%] [G loss: 0.571271]\n",
      "epoch:10 step:9857 [D loss: 0.530625, acc.: 71.88%] [G loss: 0.625888]\n",
      "epoch:10 step:9858 [D loss: 0.447998, acc.: 81.25%] [G loss: 0.649223]\n",
      "epoch:10 step:9859 [D loss: 0.583304, acc.: 74.22%] [G loss: 0.496131]\n",
      "epoch:10 step:9860 [D loss: 0.568929, acc.: 70.31%] [G loss: 0.520210]\n",
      "epoch:10 step:9861 [D loss: 0.562974, acc.: 70.31%] [G loss: 0.579541]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:10 step:9862 [D loss: 0.650270, acc.: 60.16%] [G loss: 0.534477]\n",
      "epoch:10 step:9863 [D loss: 0.561955, acc.: 70.31%] [G loss: 0.414208]\n",
      "epoch:10 step:9864 [D loss: 0.557019, acc.: 70.31%] [G loss: 0.474576]\n",
      "epoch:10 step:9865 [D loss: 0.562938, acc.: 67.19%] [G loss: 0.506627]\n",
      "epoch:10 step:9866 [D loss: 0.568929, acc.: 69.53%] [G loss: 0.539754]\n",
      "epoch:10 step:9867 [D loss: 0.532075, acc.: 74.22%] [G loss: 0.591194]\n",
      "epoch:10 step:9868 [D loss: 0.465711, acc.: 78.91%] [G loss: 0.759213]\n",
      "epoch:10 step:9869 [D loss: 0.479952, acc.: 76.56%] [G loss: 0.774274]\n",
      "epoch:10 step:9870 [D loss: 0.590447, acc.: 70.31%] [G loss: 0.401508]\n",
      "epoch:10 step:9871 [D loss: 0.674700, acc.: 63.28%] [G loss: 0.414161]\n",
      "epoch:10 step:9872 [D loss: 0.589791, acc.: 66.41%] [G loss: 0.540440]\n",
      "epoch:10 step:9873 [D loss: 0.538901, acc.: 71.88%] [G loss: 0.474919]\n",
      "epoch:10 step:9874 [D loss: 0.472436, acc.: 81.25%] [G loss: 0.576702]\n",
      "epoch:10 step:9875 [D loss: 0.542341, acc.: 70.31%] [G loss: 0.598895]\n",
      "epoch:10 step:9876 [D loss: 0.502261, acc.: 76.56%] [G loss: 0.629215]\n",
      "epoch:10 step:9877 [D loss: 0.543911, acc.: 72.66%] [G loss: 0.836923]\n",
      "epoch:10 step:9878 [D loss: 0.410372, acc.: 83.59%] [G loss: 0.799581]\n",
      "epoch:10 step:9879 [D loss: 0.511133, acc.: 72.66%] [G loss: 0.815850]\n",
      "epoch:10 step:9880 [D loss: 0.592577, acc.: 64.84%] [G loss: 0.687344]\n",
      "epoch:10 step:9881 [D loss: 0.638533, acc.: 64.06%] [G loss: 0.493422]\n",
      "epoch:10 step:9882 [D loss: 0.608266, acc.: 64.06%] [G loss: 0.462029]\n",
      "epoch:10 step:9883 [D loss: 0.554143, acc.: 70.31%] [G loss: 0.522266]\n",
      "epoch:10 step:9884 [D loss: 0.499038, acc.: 75.00%] [G loss: 0.604868]\n",
      "epoch:10 step:9885 [D loss: 0.556215, acc.: 70.31%] [G loss: 0.608785]\n",
      "epoch:10 step:9886 [D loss: 0.523717, acc.: 78.12%] [G loss: 0.581651]\n",
      "epoch:10 step:9887 [D loss: 0.588608, acc.: 71.88%] [G loss: 0.484751]\n",
      "epoch:10 step:9888 [D loss: 0.571156, acc.: 64.84%] [G loss: 0.576282]\n",
      "epoch:10 step:9889 [D loss: 0.512013, acc.: 71.09%] [G loss: 0.519734]\n",
      "epoch:10 step:9890 [D loss: 0.517971, acc.: 75.00%] [G loss: 0.527712]\n",
      "epoch:10 step:9891 [D loss: 0.513880, acc.: 71.88%] [G loss: 0.596530]\n",
      "epoch:10 step:9892 [D loss: 0.546498, acc.: 75.78%] [G loss: 0.573907]\n",
      "epoch:10 step:9893 [D loss: 0.493705, acc.: 73.44%] [G loss: 0.609162]\n",
      "epoch:10 step:9894 [D loss: 0.578865, acc.: 65.62%] [G loss: 0.562599]\n",
      "epoch:10 step:9895 [D loss: 0.551047, acc.: 71.09%] [G loss: 0.611041]\n",
      "epoch:10 step:9896 [D loss: 0.570118, acc.: 64.06%] [G loss: 0.533299]\n",
      "epoch:10 step:9897 [D loss: 0.535155, acc.: 73.44%] [G loss: 0.677646]\n",
      "epoch:10 step:9898 [D loss: 0.683943, acc.: 60.94%] [G loss: 0.496711]\n",
      "epoch:10 step:9899 [D loss: 0.622314, acc.: 61.72%] [G loss: 0.506512]\n",
      "epoch:10 step:9900 [D loss: 0.569343, acc.: 69.53%] [G loss: 0.516094]\n",
      "epoch:10 step:9901 [D loss: 0.556436, acc.: 68.75%] [G loss: 0.595620]\n",
      "epoch:10 step:9902 [D loss: 0.537091, acc.: 73.44%] [G loss: 0.544999]\n",
      "epoch:10 step:9903 [D loss: 0.608648, acc.: 65.62%] [G loss: 0.640638]\n",
      "epoch:10 step:9904 [D loss: 0.509141, acc.: 75.00%] [G loss: 0.561675]\n",
      "epoch:10 step:9905 [D loss: 0.624640, acc.: 65.62%] [G loss: 0.511247]\n",
      "epoch:10 step:9906 [D loss: 0.546956, acc.: 69.53%] [G loss: 0.396936]\n",
      "epoch:10 step:9907 [D loss: 0.630223, acc.: 61.72%] [G loss: 0.493316]\n",
      "epoch:10 step:9908 [D loss: 0.609124, acc.: 64.84%] [G loss: 0.487270]\n",
      "epoch:10 step:9909 [D loss: 0.567203, acc.: 65.62%] [G loss: 0.413301]\n",
      "epoch:10 step:9910 [D loss: 0.491650, acc.: 75.00%] [G loss: 0.483909]\n",
      "epoch:10 step:9911 [D loss: 0.501760, acc.: 75.78%] [G loss: 0.519784]\n",
      "epoch:10 step:9912 [D loss: 0.602620, acc.: 67.97%] [G loss: 0.466533]\n",
      "epoch:10 step:9913 [D loss: 0.617582, acc.: 69.53%] [G loss: 0.470769]\n",
      "epoch:10 step:9914 [D loss: 0.536976, acc.: 72.66%] [G loss: 0.520772]\n",
      "epoch:10 step:9915 [D loss: 0.537812, acc.: 69.53%] [G loss: 0.564405]\n",
      "epoch:10 step:9916 [D loss: 0.610280, acc.: 66.41%] [G loss: 0.567987]\n",
      "epoch:10 step:9917 [D loss: 0.552321, acc.: 71.88%] [G loss: 0.578081]\n",
      "epoch:10 step:9918 [D loss: 0.535824, acc.: 72.66%] [G loss: 0.572664]\n",
      "epoch:10 step:9919 [D loss: 0.564654, acc.: 71.09%] [G loss: 0.644345]\n",
      "epoch:10 step:9920 [D loss: 0.561638, acc.: 70.31%] [G loss: 0.459883]\n",
      "epoch:10 step:9921 [D loss: 0.529508, acc.: 73.44%] [G loss: 0.618053]\n",
      "epoch:10 step:9922 [D loss: 0.534294, acc.: 73.44%] [G loss: 0.568855]\n",
      "epoch:10 step:9923 [D loss: 0.585048, acc.: 66.41%] [G loss: 0.503282]\n",
      "epoch:10 step:9924 [D loss: 0.466709, acc.: 81.25%] [G loss: 0.617156]\n",
      "epoch:10 step:9925 [D loss: 0.490725, acc.: 77.34%] [G loss: 0.605577]\n",
      "epoch:10 step:9926 [D loss: 0.514064, acc.: 75.78%] [G loss: 0.640530]\n",
      "epoch:10 step:9927 [D loss: 0.499828, acc.: 75.78%] [G loss: 0.670352]\n",
      "epoch:10 step:9928 [D loss: 0.537610, acc.: 68.75%] [G loss: 0.611505]\n",
      "epoch:10 step:9929 [D loss: 0.594043, acc.: 66.41%] [G loss: 0.560919]\n",
      "epoch:10 step:9930 [D loss: 0.549291, acc.: 71.09%] [G loss: 0.502990]\n",
      "epoch:10 step:9931 [D loss: 0.568338, acc.: 67.19%] [G loss: 0.424132]\n",
      "epoch:10 step:9932 [D loss: 0.619504, acc.: 64.84%] [G loss: 0.502690]\n",
      "epoch:10 step:9933 [D loss: 0.501280, acc.: 75.78%] [G loss: 0.577213]\n",
      "epoch:10 step:9934 [D loss: 0.504544, acc.: 74.22%] [G loss: 0.575051]\n",
      "epoch:10 step:9935 [D loss: 0.584438, acc.: 71.09%] [G loss: 0.495701]\n",
      "epoch:10 step:9936 [D loss: 0.716594, acc.: 57.03%] [G loss: 0.434108]\n",
      "epoch:10 step:9937 [D loss: 0.541835, acc.: 67.97%] [G loss: 0.492123]\n",
      "epoch:10 step:9938 [D loss: 0.527873, acc.: 75.78%] [G loss: 0.551078]\n",
      "epoch:10 step:9939 [D loss: 0.503511, acc.: 74.22%] [G loss: 0.682378]\n",
      "epoch:10 step:9940 [D loss: 0.523977, acc.: 74.22%] [G loss: 0.511536]\n",
      "epoch:10 step:9941 [D loss: 0.525172, acc.: 68.75%] [G loss: 0.635918]\n",
      "epoch:10 step:9942 [D loss: 0.567684, acc.: 69.53%] [G loss: 0.492783]\n",
      "epoch:10 step:9943 [D loss: 0.557127, acc.: 67.19%] [G loss: 0.539602]\n",
      "epoch:10 step:9944 [D loss: 0.493820, acc.: 75.00%] [G loss: 0.635581]\n",
      "epoch:10 step:9945 [D loss: 0.511004, acc.: 72.66%] [G loss: 0.787499]\n",
      "epoch:10 step:9946 [D loss: 0.613428, acc.: 61.72%] [G loss: 0.554506]\n",
      "epoch:10 step:9947 [D loss: 0.564298, acc.: 71.09%] [G loss: 0.508526]\n",
      "epoch:10 step:9948 [D loss: 0.534620, acc.: 71.09%] [G loss: 0.486860]\n",
      "epoch:10 step:9949 [D loss: 0.496492, acc.: 76.56%] [G loss: 0.594946]\n",
      "epoch:10 step:9950 [D loss: 0.578414, acc.: 71.88%] [G loss: 0.516284]\n",
      "epoch:10 step:9951 [D loss: 0.614971, acc.: 65.62%] [G loss: 0.517734]\n",
      "epoch:10 step:9952 [D loss: 0.476741, acc.: 81.25%] [G loss: 0.797567]\n",
      "epoch:10 step:9953 [D loss: 0.608553, acc.: 64.84%] [G loss: 0.770596]\n",
      "epoch:10 step:9954 [D loss: 0.635677, acc.: 60.94%] [G loss: 0.488101]\n",
      "epoch:10 step:9955 [D loss: 0.495713, acc.: 76.56%] [G loss: 0.375679]\n",
      "epoch:10 step:9956 [D loss: 0.589818, acc.: 66.41%] [G loss: 0.496840]\n",
      "epoch:10 step:9957 [D loss: 0.577734, acc.: 63.28%] [G loss: 0.502760]\n",
      "epoch:10 step:9958 [D loss: 0.565322, acc.: 65.62%] [G loss: 0.578233]\n",
      "epoch:10 step:9959 [D loss: 0.580422, acc.: 69.53%] [G loss: 0.594984]\n",
      "epoch:10 step:9960 [D loss: 0.548361, acc.: 67.19%] [G loss: 0.577572]\n",
      "epoch:10 step:9961 [D loss: 0.581142, acc.: 71.09%] [G loss: 0.527339]\n",
      "epoch:10 step:9962 [D loss: 0.489801, acc.: 78.91%] [G loss: 0.601478]\n",
      "epoch:10 step:9963 [D loss: 0.580052, acc.: 70.31%] [G loss: 0.575964]\n",
      "epoch:10 step:9964 [D loss: 0.549295, acc.: 71.09%] [G loss: 0.614887]\n",
      "epoch:10 step:9965 [D loss: 0.536054, acc.: 71.88%] [G loss: 0.549693]\n",
      "epoch:10 step:9966 [D loss: 0.561701, acc.: 69.53%] [G loss: 0.643180]\n",
      "epoch:10 step:9967 [D loss: 0.589266, acc.: 69.53%] [G loss: 0.489910]\n",
      "epoch:10 step:9968 [D loss: 0.510876, acc.: 78.12%] [G loss: 0.711448]\n",
      "epoch:10 step:9969 [D loss: 0.509512, acc.: 74.22%] [G loss: 0.584226]\n",
      "epoch:10 step:9970 [D loss: 0.615329, acc.: 65.62%] [G loss: 0.501312]\n",
      "epoch:10 step:9971 [D loss: 0.539189, acc.: 70.31%] [G loss: 0.518999]\n",
      "epoch:10 step:9972 [D loss: 0.476596, acc.: 78.12%] [G loss: 0.618340]\n",
      "epoch:10 step:9973 [D loss: 0.495877, acc.: 74.22%] [G loss: 0.658414]\n",
      "epoch:10 step:9974 [D loss: 0.631373, acc.: 64.84%] [G loss: 0.540065]\n",
      "epoch:10 step:9975 [D loss: 0.458074, acc.: 80.47%] [G loss: 0.559893]\n",
      "epoch:10 step:9976 [D loss: 0.610536, acc.: 67.19%] [G loss: 0.529868]\n",
      "epoch:10 step:9977 [D loss: 0.525812, acc.: 73.44%] [G loss: 0.465931]\n",
      "epoch:10 step:9978 [D loss: 0.594986, acc.: 64.06%] [G loss: 0.493067]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:10 step:9979 [D loss: 0.535745, acc.: 72.66%] [G loss: 0.563766]\n",
      "epoch:10 step:9980 [D loss: 0.582579, acc.: 66.41%] [G loss: 0.504661]\n",
      "epoch:10 step:9981 [D loss: 0.538252, acc.: 69.53%] [G loss: 0.536977]\n",
      "epoch:10 step:9982 [D loss: 0.573037, acc.: 61.72%] [G loss: 0.433849]\n",
      "epoch:10 step:9983 [D loss: 0.532484, acc.: 70.31%] [G loss: 0.557702]\n",
      "epoch:10 step:9984 [D loss: 0.546902, acc.: 69.53%] [G loss: 0.588156]\n",
      "epoch:10 step:9985 [D loss: 0.619517, acc.: 63.28%] [G loss: 0.488201]\n",
      "epoch:10 step:9986 [D loss: 0.605958, acc.: 66.41%] [G loss: 0.629489]\n",
      "epoch:10 step:9987 [D loss: 0.581314, acc.: 64.06%] [G loss: 0.551604]\n",
      "epoch:10 step:9988 [D loss: 0.538074, acc.: 71.88%] [G loss: 0.561595]\n",
      "epoch:10 step:9989 [D loss: 0.535642, acc.: 68.75%] [G loss: 0.562672]\n",
      "epoch:10 step:9990 [D loss: 0.506530, acc.: 73.44%] [G loss: 0.572560]\n",
      "epoch:10 step:9991 [D loss: 0.533966, acc.: 71.09%] [G loss: 0.635257]\n",
      "epoch:10 step:9992 [D loss: 0.595339, acc.: 69.53%] [G loss: 0.437224]\n",
      "epoch:10 step:9993 [D loss: 0.496126, acc.: 76.56%] [G loss: 0.714947]\n",
      "epoch:10 step:9994 [D loss: 0.503981, acc.: 75.00%] [G loss: 0.725038]\n",
      "epoch:10 step:9995 [D loss: 0.579637, acc.: 67.97%] [G loss: 0.697715]\n",
      "epoch:10 step:9996 [D loss: 0.535876, acc.: 71.88%] [G loss: 0.594622]\n",
      "epoch:10 step:9997 [D loss: 0.583995, acc.: 61.72%] [G loss: 0.571416]\n",
      "epoch:10 step:9998 [D loss: 0.583061, acc.: 67.97%] [G loss: 0.526488]\n",
      "epoch:10 step:9999 [D loss: 0.496067, acc.: 75.00%] [G loss: 0.544179]\n",
      "epoch:10 step:10000 [D loss: 0.560686, acc.: 67.97%] [G loss: 0.491016]\n",
      "##############\n",
      "[3.11121602 1.24054132 6.45378481 4.79753425 3.95240298 5.65758512\n",
      " 4.97315255 4.85764066 4.41971673 3.96174495]\n",
      "##########\n",
      "epoch:10 step:10001 [D loss: 0.504324, acc.: 78.91%] [G loss: 0.523762]\n",
      "epoch:10 step:10002 [D loss: 0.514846, acc.: 73.44%] [G loss: 0.719804]\n",
      "epoch:10 step:10003 [D loss: 0.588163, acc.: 69.53%] [G loss: 0.617786]\n",
      "epoch:10 step:10004 [D loss: 0.502716, acc.: 78.91%] [G loss: 0.565720]\n",
      "epoch:10 step:10005 [D loss: 0.506276, acc.: 75.78%] [G loss: 0.599849]\n",
      "epoch:10 step:10006 [D loss: 0.582872, acc.: 67.97%] [G loss: 0.567037]\n",
      "epoch:10 step:10007 [D loss: 0.519654, acc.: 75.78%] [G loss: 0.511805]\n",
      "epoch:10 step:10008 [D loss: 0.518296, acc.: 73.44%] [G loss: 0.446931]\n",
      "epoch:10 step:10009 [D loss: 0.481378, acc.: 74.22%] [G loss: 0.685408]\n",
      "epoch:10 step:10010 [D loss: 0.542245, acc.: 71.88%] [G loss: 0.677334]\n",
      "epoch:10 step:10011 [D loss: 0.550277, acc.: 68.75%] [G loss: 0.689943]\n",
      "epoch:10 step:10012 [D loss: 0.496699, acc.: 77.34%] [G loss: 0.738980]\n",
      "epoch:10 step:10013 [D loss: 0.571591, acc.: 67.19%] [G loss: 0.667616]\n",
      "epoch:10 step:10014 [D loss: 0.560848, acc.: 69.53%] [G loss: 0.596563]\n",
      "epoch:10 step:10015 [D loss: 0.557482, acc.: 71.88%] [G loss: 0.637495]\n",
      "epoch:10 step:10016 [D loss: 0.581258, acc.: 66.41%] [G loss: 0.518618]\n",
      "epoch:10 step:10017 [D loss: 0.463556, acc.: 80.47%] [G loss: 0.671317]\n",
      "epoch:10 step:10018 [D loss: 0.465748, acc.: 77.34%] [G loss: 0.771191]\n",
      "epoch:10 step:10019 [D loss: 0.538399, acc.: 69.53%] [G loss: 0.687457]\n",
      "epoch:10 step:10020 [D loss: 0.523477, acc.: 75.00%] [G loss: 0.578101]\n",
      "epoch:10 step:10021 [D loss: 0.521929, acc.: 74.22%] [G loss: 0.728185]\n",
      "epoch:10 step:10022 [D loss: 0.631292, acc.: 65.62%] [G loss: 0.464569]\n",
      "epoch:10 step:10023 [D loss: 0.619602, acc.: 63.28%] [G loss: 0.404383]\n",
      "epoch:10 step:10024 [D loss: 0.519008, acc.: 75.00%] [G loss: 0.568953]\n",
      "epoch:10 step:10025 [D loss: 0.572634, acc.: 66.41%] [G loss: 0.531518]\n",
      "epoch:10 step:10026 [D loss: 0.588329, acc.: 67.97%] [G loss: 0.473078]\n",
      "epoch:10 step:10027 [D loss: 0.546743, acc.: 71.88%] [G loss: 0.489444]\n",
      "epoch:10 step:10028 [D loss: 0.530910, acc.: 71.09%] [G loss: 0.576424]\n",
      "epoch:10 step:10029 [D loss: 0.568381, acc.: 66.41%] [G loss: 0.549609]\n",
      "epoch:10 step:10030 [D loss: 0.514317, acc.: 74.22%] [G loss: 0.518702]\n",
      "epoch:10 step:10031 [D loss: 0.469477, acc.: 76.56%] [G loss: 0.673124]\n",
      "epoch:10 step:10032 [D loss: 0.514027, acc.: 71.88%] [G loss: 0.669118]\n",
      "epoch:10 step:10033 [D loss: 0.533345, acc.: 74.22%] [G loss: 0.608073]\n",
      "epoch:10 step:10034 [D loss: 0.567506, acc.: 63.28%] [G loss: 0.571913]\n",
      "epoch:10 step:10035 [D loss: 0.568273, acc.: 68.75%] [G loss: 0.499443]\n",
      "epoch:10 step:10036 [D loss: 0.507075, acc.: 76.56%] [G loss: 0.784891]\n",
      "epoch:10 step:10037 [D loss: 0.570417, acc.: 67.19%] [G loss: 0.590193]\n",
      "epoch:10 step:10038 [D loss: 0.549251, acc.: 74.22%] [G loss: 0.644846]\n",
      "epoch:10 step:10039 [D loss: 0.518805, acc.: 75.00%] [G loss: 0.497427]\n",
      "epoch:10 step:10040 [D loss: 0.568647, acc.: 66.41%] [G loss: 0.559339]\n",
      "epoch:10 step:10041 [D loss: 0.578230, acc.: 71.88%] [G loss: 0.743594]\n",
      "epoch:10 step:10042 [D loss: 0.562386, acc.: 67.19%] [G loss: 0.796121]\n",
      "epoch:10 step:10043 [D loss: 0.616989, acc.: 60.16%] [G loss: 0.632277]\n",
      "epoch:10 step:10044 [D loss: 0.574564, acc.: 68.75%] [G loss: 0.641943]\n",
      "epoch:10 step:10045 [D loss: 0.549330, acc.: 71.88%] [G loss: 0.489202]\n",
      "epoch:10 step:10046 [D loss: 0.531835, acc.: 71.09%] [G loss: 0.578455]\n",
      "epoch:10 step:10047 [D loss: 0.486344, acc.: 75.00%] [G loss: 0.616638]\n",
      "epoch:10 step:10048 [D loss: 0.536927, acc.: 70.31%] [G loss: 0.577748]\n",
      "epoch:10 step:10049 [D loss: 0.553897, acc.: 71.88%] [G loss: 0.630821]\n",
      "epoch:10 step:10050 [D loss: 0.530994, acc.: 75.00%] [G loss: 0.679129]\n",
      "epoch:10 step:10051 [D loss: 0.519165, acc.: 76.56%] [G loss: 0.649621]\n",
      "epoch:10 step:10052 [D loss: 0.518640, acc.: 75.78%] [G loss: 0.717123]\n",
      "epoch:10 step:10053 [D loss: 0.542683, acc.: 71.09%] [G loss: 0.680054]\n",
      "epoch:10 step:10054 [D loss: 0.598936, acc.: 65.62%] [G loss: 0.423026]\n",
      "epoch:10 step:10055 [D loss: 0.561079, acc.: 68.75%] [G loss: 0.450511]\n",
      "epoch:10 step:10056 [D loss: 0.593570, acc.: 66.41%] [G loss: 0.440030]\n",
      "epoch:10 step:10057 [D loss: 0.547267, acc.: 68.75%] [G loss: 0.581529]\n",
      "epoch:10 step:10058 [D loss: 0.569275, acc.: 67.19%] [G loss: 0.486121]\n",
      "epoch:10 step:10059 [D loss: 0.566737, acc.: 66.41%] [G loss: 0.617992]\n",
      "epoch:10 step:10060 [D loss: 0.537919, acc.: 74.22%] [G loss: 0.669811]\n",
      "epoch:10 step:10061 [D loss: 0.513194, acc.: 74.22%] [G loss: 0.592425]\n",
      "epoch:10 step:10062 [D loss: 0.559212, acc.: 70.31%] [G loss: 0.503796]\n",
      "epoch:10 step:10063 [D loss: 0.499930, acc.: 74.22%] [G loss: 0.726194]\n",
      "epoch:10 step:10064 [D loss: 0.504751, acc.: 75.78%] [G loss: 0.632372]\n",
      "epoch:10 step:10065 [D loss: 0.505364, acc.: 75.78%] [G loss: 0.567548]\n",
      "epoch:10 step:10066 [D loss: 0.631566, acc.: 63.28%] [G loss: 0.438046]\n",
      "epoch:10 step:10067 [D loss: 0.568793, acc.: 62.50%] [G loss: 0.528157]\n",
      "epoch:10 step:10068 [D loss: 0.512071, acc.: 75.78%] [G loss: 0.654270]\n",
      "epoch:10 step:10069 [D loss: 0.535193, acc.: 67.19%] [G loss: 0.540250]\n",
      "epoch:10 step:10070 [D loss: 0.533814, acc.: 71.88%] [G loss: 0.787050]\n",
      "epoch:10 step:10071 [D loss: 0.556697, acc.: 73.44%] [G loss: 0.604955]\n",
      "epoch:10 step:10072 [D loss: 0.590728, acc.: 63.28%] [G loss: 0.642647]\n",
      "epoch:10 step:10073 [D loss: 0.534447, acc.: 71.09%] [G loss: 0.515938]\n",
      "epoch:10 step:10074 [D loss: 0.661129, acc.: 57.03%] [G loss: 0.518032]\n",
      "epoch:10 step:10075 [D loss: 0.527819, acc.: 75.00%] [G loss: 0.592700]\n",
      "epoch:10 step:10076 [D loss: 0.551597, acc.: 67.97%] [G loss: 0.530668]\n",
      "epoch:10 step:10077 [D loss: 0.516751, acc.: 76.56%] [G loss: 0.557325]\n",
      "epoch:10 step:10078 [D loss: 0.480551, acc.: 79.69%] [G loss: 0.718306]\n",
      "epoch:10 step:10079 [D loss: 0.560516, acc.: 63.28%] [G loss: 0.664001]\n",
      "epoch:10 step:10080 [D loss: 0.572679, acc.: 71.88%] [G loss: 0.637642]\n",
      "epoch:10 step:10081 [D loss: 0.583215, acc.: 65.62%] [G loss: 0.666634]\n",
      "epoch:10 step:10082 [D loss: 0.554416, acc.: 66.41%] [G loss: 0.654526]\n",
      "epoch:10 step:10083 [D loss: 0.631046, acc.: 62.50%] [G loss: 0.628443]\n",
      "epoch:10 step:10084 [D loss: 0.519271, acc.: 74.22%] [G loss: 0.750135]\n",
      "epoch:10 step:10085 [D loss: 0.561195, acc.: 67.97%] [G loss: 0.534654]\n",
      "epoch:10 step:10086 [D loss: 0.680748, acc.: 60.16%] [G loss: 0.567107]\n",
      "epoch:10 step:10087 [D loss: 0.593835, acc.: 67.19%] [G loss: 0.549285]\n",
      "epoch:10 step:10088 [D loss: 0.600806, acc.: 64.06%] [G loss: 0.548148]\n",
      "epoch:10 step:10089 [D loss: 0.520347, acc.: 77.34%] [G loss: 0.686749]\n",
      "epoch:10 step:10090 [D loss: 0.648715, acc.: 70.31%] [G loss: 0.425650]\n",
      "epoch:10 step:10091 [D loss: 0.561935, acc.: 67.97%] [G loss: 0.542502]\n",
      "epoch:10 step:10092 [D loss: 0.593559, acc.: 65.62%] [G loss: 0.493655]\n",
      "epoch:10 step:10093 [D loss: 0.567405, acc.: 67.19%] [G loss: 0.472882]\n",
      "epoch:10 step:10094 [D loss: 0.486063, acc.: 74.22%] [G loss: 0.568920]\n",
      "epoch:10 step:10095 [D loss: 0.490177, acc.: 77.34%] [G loss: 0.593394]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:10 step:10096 [D loss: 0.518814, acc.: 72.66%] [G loss: 0.529392]\n",
      "epoch:10 step:10097 [D loss: 0.546301, acc.: 68.75%] [G loss: 0.551396]\n",
      "epoch:10 step:10098 [D loss: 0.507655, acc.: 77.34%] [G loss: 0.571222]\n",
      "epoch:10 step:10099 [D loss: 0.612654, acc.: 62.50%] [G loss: 0.529894]\n",
      "epoch:10 step:10100 [D loss: 0.527985, acc.: 76.56%] [G loss: 0.539882]\n",
      "epoch:10 step:10101 [D loss: 0.553666, acc.: 67.97%] [G loss: 0.570418]\n",
      "epoch:10 step:10102 [D loss: 0.529172, acc.: 71.09%] [G loss: 0.521574]\n",
      "epoch:10 step:10103 [D loss: 0.554533, acc.: 67.19%] [G loss: 0.681471]\n",
      "epoch:10 step:10104 [D loss: 0.516141, acc.: 74.22%] [G loss: 0.595169]\n",
      "epoch:10 step:10105 [D loss: 0.565774, acc.: 69.53%] [G loss: 0.521003]\n",
      "epoch:10 step:10106 [D loss: 0.469960, acc.: 75.00%] [G loss: 0.670185]\n",
      "epoch:10 step:10107 [D loss: 0.574463, acc.: 64.06%] [G loss: 0.538159]\n",
      "epoch:10 step:10108 [D loss: 0.554704, acc.: 65.62%] [G loss: 0.546099]\n",
      "epoch:10 step:10109 [D loss: 0.615915, acc.: 66.41%] [G loss: 0.475496]\n",
      "epoch:10 step:10110 [D loss: 0.651213, acc.: 60.94%] [G loss: 0.404979]\n",
      "epoch:10 step:10111 [D loss: 0.584196, acc.: 71.09%] [G loss: 0.360856]\n",
      "epoch:10 step:10112 [D loss: 0.533340, acc.: 67.97%] [G loss: 0.503627]\n",
      "epoch:10 step:10113 [D loss: 0.543489, acc.: 71.09%] [G loss: 0.677480]\n",
      "epoch:10 step:10114 [D loss: 0.543676, acc.: 71.09%] [G loss: 0.517886]\n",
      "epoch:10 step:10115 [D loss: 0.579356, acc.: 66.41%] [G loss: 0.607913]\n",
      "epoch:10 step:10116 [D loss: 0.477660, acc.: 75.00%] [G loss: 0.635530]\n",
      "epoch:10 step:10117 [D loss: 0.444979, acc.: 77.34%] [G loss: 0.635139]\n",
      "epoch:10 step:10118 [D loss: 0.550295, acc.: 68.75%] [G loss: 0.632142]\n",
      "epoch:10 step:10119 [D loss: 0.541608, acc.: 71.09%] [G loss: 0.633865]\n",
      "epoch:10 step:10120 [D loss: 0.508248, acc.: 78.12%] [G loss: 0.628286]\n",
      "epoch:10 step:10121 [D loss: 0.530916, acc.: 71.88%] [G loss: 0.581805]\n",
      "epoch:10 step:10122 [D loss: 0.577747, acc.: 66.41%] [G loss: 0.569429]\n",
      "epoch:10 step:10123 [D loss: 0.510576, acc.: 72.66%] [G loss: 0.632203]\n",
      "epoch:10 step:10124 [D loss: 0.532028, acc.: 74.22%] [G loss: 0.630338]\n",
      "epoch:10 step:10125 [D loss: 0.548746, acc.: 66.41%] [G loss: 0.619198]\n",
      "epoch:10 step:10126 [D loss: 0.531711, acc.: 73.44%] [G loss: 0.596823]\n",
      "epoch:10 step:10127 [D loss: 0.588475, acc.: 67.19%] [G loss: 0.587949]\n",
      "epoch:10 step:10128 [D loss: 0.564256, acc.: 67.19%] [G loss: 0.601639]\n",
      "epoch:10 step:10129 [D loss: 0.645922, acc.: 66.41%] [G loss: 0.558491]\n",
      "epoch:10 step:10130 [D loss: 0.571933, acc.: 68.75%] [G loss: 0.490250]\n",
      "epoch:10 step:10131 [D loss: 0.540660, acc.: 70.31%] [G loss: 0.594770]\n",
      "epoch:10 step:10132 [D loss: 0.571965, acc.: 64.06%] [G loss: 0.556274]\n",
      "epoch:10 step:10133 [D loss: 0.540754, acc.: 70.31%] [G loss: 0.542998]\n",
      "epoch:10 step:10134 [D loss: 0.555783, acc.: 69.53%] [G loss: 0.538601]\n",
      "epoch:10 step:10135 [D loss: 0.634691, acc.: 64.06%] [G loss: 0.563768]\n",
      "epoch:10 step:10136 [D loss: 0.656349, acc.: 57.81%] [G loss: 0.431338]\n",
      "epoch:10 step:10137 [D loss: 0.533522, acc.: 71.09%] [G loss: 0.514283]\n",
      "epoch:10 step:10138 [D loss: 0.616242, acc.: 69.53%] [G loss: 0.662530]\n",
      "epoch:10 step:10139 [D loss: 0.490872, acc.: 75.00%] [G loss: 0.776463]\n",
      "epoch:10 step:10140 [D loss: 0.568930, acc.: 69.53%] [G loss: 0.653801]\n",
      "epoch:10 step:10141 [D loss: 0.545951, acc.: 70.31%] [G loss: 0.579033]\n",
      "epoch:10 step:10142 [D loss: 0.564462, acc.: 69.53%] [G loss: 0.559709]\n",
      "epoch:10 step:10143 [D loss: 0.543368, acc.: 70.31%] [G loss: 0.544991]\n",
      "epoch:10 step:10144 [D loss: 0.629322, acc.: 64.84%] [G loss: 0.465199]\n",
      "epoch:10 step:10145 [D loss: 0.546905, acc.: 69.53%] [G loss: 0.455479]\n",
      "epoch:10 step:10146 [D loss: 0.566092, acc.: 72.66%] [G loss: 0.563513]\n",
      "epoch:10 step:10147 [D loss: 0.559795, acc.: 69.53%] [G loss: 0.534658]\n",
      "epoch:10 step:10148 [D loss: 0.555097, acc.: 73.44%] [G loss: 0.591211]\n",
      "epoch:10 step:10149 [D loss: 0.574286, acc.: 68.75%] [G loss: 0.488643]\n",
      "epoch:10 step:10150 [D loss: 0.570478, acc.: 62.50%] [G loss: 0.644062]\n",
      "epoch:10 step:10151 [D loss: 0.566123, acc.: 71.88%] [G loss: 0.650545]\n",
      "epoch:10 step:10152 [D loss: 0.491594, acc.: 77.34%] [G loss: 0.804360]\n",
      "epoch:10 step:10153 [D loss: 0.544076, acc.: 68.75%] [G loss: 0.710846]\n",
      "epoch:10 step:10154 [D loss: 0.672885, acc.: 57.03%] [G loss: 0.390992]\n",
      "epoch:10 step:10155 [D loss: 0.561230, acc.: 69.53%] [G loss: 0.614561]\n",
      "epoch:10 step:10156 [D loss: 0.530105, acc.: 67.19%] [G loss: 0.636705]\n",
      "epoch:10 step:10157 [D loss: 0.552917, acc.: 67.97%] [G loss: 0.582822]\n",
      "epoch:10 step:10158 [D loss: 0.708609, acc.: 57.81%] [G loss: 0.474890]\n",
      "epoch:10 step:10159 [D loss: 0.593090, acc.: 65.62%] [G loss: 0.468571]\n",
      "epoch:10 step:10160 [D loss: 0.539433, acc.: 72.66%] [G loss: 0.536349]\n",
      "epoch:10 step:10161 [D loss: 0.601462, acc.: 64.06%] [G loss: 0.509548]\n",
      "epoch:10 step:10162 [D loss: 0.465704, acc.: 78.12%] [G loss: 0.590479]\n",
      "epoch:10 step:10163 [D loss: 0.578092, acc.: 66.41%] [G loss: 0.597842]\n",
      "epoch:10 step:10164 [D loss: 0.598307, acc.: 65.62%] [G loss: 0.619919]\n",
      "epoch:10 step:10165 [D loss: 0.528623, acc.: 73.44%] [G loss: 0.608420]\n",
      "epoch:10 step:10166 [D loss: 0.493475, acc.: 78.12%] [G loss: 0.611344]\n",
      "epoch:10 step:10167 [D loss: 0.543857, acc.: 71.09%] [G loss: 0.642362]\n",
      "epoch:10 step:10168 [D loss: 0.535490, acc.: 70.31%] [G loss: 0.620068]\n",
      "epoch:10 step:10169 [D loss: 0.572539, acc.: 75.00%] [G loss: 0.500599]\n",
      "epoch:10 step:10170 [D loss: 0.569914, acc.: 63.28%] [G loss: 0.617924]\n",
      "epoch:10 step:10171 [D loss: 0.541319, acc.: 71.88%] [G loss: 0.571654]\n",
      "epoch:10 step:10172 [D loss: 0.515051, acc.: 68.75%] [G loss: 0.739711]\n",
      "epoch:10 step:10173 [D loss: 0.528203, acc.: 79.69%] [G loss: 0.618901]\n",
      "epoch:10 step:10174 [D loss: 0.536165, acc.: 70.31%] [G loss: 0.738670]\n",
      "epoch:10 step:10175 [D loss: 0.589134, acc.: 67.19%] [G loss: 0.386167]\n",
      "epoch:10 step:10176 [D loss: 0.542023, acc.: 69.53%] [G loss: 0.533183]\n",
      "epoch:10 step:10177 [D loss: 0.528976, acc.: 72.66%] [G loss: 0.503997]\n",
      "epoch:10 step:10178 [D loss: 0.539607, acc.: 75.78%] [G loss: 0.572047]\n",
      "epoch:10 step:10179 [D loss: 0.500868, acc.: 78.91%] [G loss: 0.537291]\n",
      "epoch:10 step:10180 [D loss: 0.485128, acc.: 75.78%] [G loss: 0.572909]\n",
      "epoch:10 step:10181 [D loss: 0.563648, acc.: 71.88%] [G loss: 0.513774]\n",
      "epoch:10 step:10182 [D loss: 0.629009, acc.: 63.28%] [G loss: 0.419335]\n",
      "epoch:10 step:10183 [D loss: 0.538540, acc.: 69.53%] [G loss: 0.454115]\n",
      "epoch:10 step:10184 [D loss: 0.590264, acc.: 65.62%] [G loss: 0.675086]\n",
      "epoch:10 step:10185 [D loss: 0.546252, acc.: 75.00%] [G loss: 0.681014]\n",
      "epoch:10 step:10186 [D loss: 0.540580, acc.: 64.84%] [G loss: 0.750966]\n",
      "epoch:10 step:10187 [D loss: 0.621634, acc.: 64.06%] [G loss: 0.671166]\n",
      "epoch:10 step:10188 [D loss: 0.573451, acc.: 67.19%] [G loss: 0.577672]\n",
      "epoch:10 step:10189 [D loss: 0.546288, acc.: 75.78%] [G loss: 0.489488]\n",
      "epoch:10 step:10190 [D loss: 0.627804, acc.: 64.84%] [G loss: 0.480372]\n",
      "epoch:10 step:10191 [D loss: 0.550525, acc.: 68.75%] [G loss: 0.429955]\n",
      "epoch:10 step:10192 [D loss: 0.507062, acc.: 76.56%] [G loss: 0.603763]\n",
      "epoch:10 step:10193 [D loss: 0.430448, acc.: 80.47%] [G loss: 0.604562]\n",
      "epoch:10 step:10194 [D loss: 0.594141, acc.: 64.84%] [G loss: 0.546841]\n",
      "epoch:10 step:10195 [D loss: 0.569009, acc.: 64.84%] [G loss: 0.500534]\n",
      "epoch:10 step:10196 [D loss: 0.580373, acc.: 65.62%] [G loss: 0.471859]\n",
      "epoch:10 step:10197 [D loss: 0.584826, acc.: 70.31%] [G loss: 0.473946]\n",
      "epoch:10 step:10198 [D loss: 0.644434, acc.: 64.06%] [G loss: 0.489022]\n",
      "epoch:10 step:10199 [D loss: 0.518758, acc.: 75.00%] [G loss: 0.522844]\n",
      "epoch:10 step:10200 [D loss: 0.558702, acc.: 70.31%] [G loss: 0.560307]\n",
      "##############\n",
      "[3.42921022 1.32212698 6.46307712 5.06103759 3.82182861 5.70986963\n",
      " 4.63796196 4.78170054 4.50921041 4.02842631]\n",
      "##########\n",
      "epoch:10 step:10201 [D loss: 0.604137, acc.: 67.19%] [G loss: 0.400942]\n",
      "epoch:10 step:10202 [D loss: 0.565762, acc.: 67.97%] [G loss: 0.465719]\n",
      "epoch:10 step:10203 [D loss: 0.498825, acc.: 72.66%] [G loss: 0.592184]\n",
      "epoch:10 step:10204 [D loss: 0.523707, acc.: 67.97%] [G loss: 0.592614]\n",
      "epoch:10 step:10205 [D loss: 0.576888, acc.: 68.75%] [G loss: 0.477052]\n",
      "epoch:10 step:10206 [D loss: 0.526011, acc.: 71.09%] [G loss: 0.594991]\n",
      "epoch:10 step:10207 [D loss: 0.540963, acc.: 71.09%] [G loss: 0.553409]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:10 step:10208 [D loss: 0.546061, acc.: 68.75%] [G loss: 0.512651]\n",
      "epoch:10 step:10209 [D loss: 0.582000, acc.: 70.31%] [G loss: 0.670432]\n",
      "epoch:10 step:10210 [D loss: 0.602429, acc.: 64.06%] [G loss: 0.416265]\n",
      "epoch:10 step:10211 [D loss: 0.561529, acc.: 74.22%] [G loss: 0.492922]\n",
      "epoch:10 step:10212 [D loss: 0.555852, acc.: 70.31%] [G loss: 0.427497]\n",
      "epoch:10 step:10213 [D loss: 0.507032, acc.: 75.78%] [G loss: 0.534271]\n",
      "epoch:10 step:10214 [D loss: 0.545714, acc.: 71.09%] [G loss: 0.510474]\n",
      "epoch:10 step:10215 [D loss: 0.562713, acc.: 65.62%] [G loss: 0.571408]\n",
      "epoch:10 step:10216 [D loss: 0.557757, acc.: 67.97%] [G loss: 0.515486]\n",
      "epoch:10 step:10217 [D loss: 0.587266, acc.: 70.31%] [G loss: 0.367869]\n",
      "epoch:10 step:10218 [D loss: 0.536242, acc.: 68.75%] [G loss: 0.516709]\n",
      "epoch:10 step:10219 [D loss: 0.579908, acc.: 68.75%] [G loss: 0.469335]\n",
      "epoch:10 step:10220 [D loss: 0.541322, acc.: 66.41%] [G loss: 0.471798]\n",
      "epoch:10 step:10221 [D loss: 0.573442, acc.: 70.31%] [G loss: 0.582147]\n",
      "epoch:10 step:10222 [D loss: 0.556920, acc.: 71.09%] [G loss: 0.511785]\n",
      "epoch:10 step:10223 [D loss: 0.562485, acc.: 62.50%] [G loss: 0.597578]\n",
      "epoch:10 step:10224 [D loss: 0.576977, acc.: 67.19%] [G loss: 0.628271]\n",
      "epoch:10 step:10225 [D loss: 0.527658, acc.: 70.31%] [G loss: 0.585014]\n",
      "epoch:10 step:10226 [D loss: 0.596987, acc.: 67.19%] [G loss: 0.594080]\n",
      "epoch:10 step:10227 [D loss: 0.568859, acc.: 66.41%] [G loss: 0.616889]\n",
      "epoch:10 step:10228 [D loss: 0.669910, acc.: 63.28%] [G loss: 0.533930]\n",
      "epoch:10 step:10229 [D loss: 0.564330, acc.: 69.53%] [G loss: 0.633180]\n",
      "epoch:10 step:10230 [D loss: 0.564641, acc.: 71.88%] [G loss: 0.689032]\n",
      "epoch:10 step:10231 [D loss: 0.600298, acc.: 67.19%] [G loss: 0.593258]\n",
      "epoch:10 step:10232 [D loss: 0.576881, acc.: 65.62%] [G loss: 0.409437]\n",
      "epoch:10 step:10233 [D loss: 0.602293, acc.: 67.19%] [G loss: 0.439898]\n",
      "epoch:10 step:10234 [D loss: 0.546813, acc.: 64.84%] [G loss: 0.531381]\n",
      "epoch:10 step:10235 [D loss: 0.567663, acc.: 68.75%] [G loss: 0.531407]\n",
      "epoch:10 step:10236 [D loss: 0.521609, acc.: 73.44%] [G loss: 0.496731]\n",
      "epoch:10 step:10237 [D loss: 0.652167, acc.: 61.72%] [G loss: 0.358703]\n",
      "epoch:10 step:10238 [D loss: 0.550359, acc.: 72.66%] [G loss: 0.554205]\n",
      "epoch:10 step:10239 [D loss: 0.599204, acc.: 64.06%] [G loss: 0.431885]\n",
      "epoch:10 step:10240 [D loss: 0.432910, acc.: 80.47%] [G loss: 0.793342]\n",
      "epoch:10 step:10241 [D loss: 0.517523, acc.: 72.66%] [G loss: 0.710498]\n",
      "epoch:10 step:10242 [D loss: 0.502722, acc.: 74.22%] [G loss: 0.721908]\n",
      "epoch:10 step:10243 [D loss: 0.655411, acc.: 61.72%] [G loss: 0.494701]\n",
      "epoch:10 step:10244 [D loss: 0.579186, acc.: 63.28%] [G loss: 0.513766]\n",
      "epoch:10 step:10245 [D loss: 0.505488, acc.: 73.44%] [G loss: 0.597010]\n",
      "epoch:10 step:10246 [D loss: 0.534472, acc.: 67.97%] [G loss: 0.516300]\n",
      "epoch:10 step:10247 [D loss: 0.604386, acc.: 62.50%] [G loss: 0.425183]\n",
      "epoch:10 step:10248 [D loss: 0.582072, acc.: 64.06%] [G loss: 0.507962]\n",
      "epoch:10 step:10249 [D loss: 0.541548, acc.: 67.97%] [G loss: 0.528852]\n",
      "epoch:10 step:10250 [D loss: 0.640511, acc.: 60.16%] [G loss: 0.487157]\n",
      "epoch:10 step:10251 [D loss: 0.592344, acc.: 64.06%] [G loss: 0.424284]\n",
      "epoch:10 step:10252 [D loss: 0.541316, acc.: 69.53%] [G loss: 0.470479]\n",
      "epoch:10 step:10253 [D loss: 0.608858, acc.: 64.84%] [G loss: 0.499900]\n",
      "epoch:10 step:10254 [D loss: 0.497816, acc.: 77.34%] [G loss: 0.630236]\n",
      "epoch:10 step:10255 [D loss: 0.540737, acc.: 73.44%] [G loss: 0.754124]\n",
      "epoch:10 step:10256 [D loss: 0.580495, acc.: 65.62%] [G loss: 0.590563]\n",
      "epoch:10 step:10257 [D loss: 0.585565, acc.: 67.19%] [G loss: 0.756118]\n",
      "epoch:10 step:10258 [D loss: 0.561242, acc.: 67.97%] [G loss: 0.633055]\n",
      "epoch:10 step:10259 [D loss: 0.562000, acc.: 66.41%] [G loss: 0.610924]\n",
      "epoch:10 step:10260 [D loss: 0.482711, acc.: 78.12%] [G loss: 0.654080]\n",
      "epoch:10 step:10261 [D loss: 0.623815, acc.: 61.72%] [G loss: 0.494844]\n",
      "epoch:10 step:10262 [D loss: 0.641891, acc.: 61.72%] [G loss: 0.485138]\n",
      "epoch:10 step:10263 [D loss: 0.593385, acc.: 68.75%] [G loss: 0.481778]\n",
      "epoch:10 step:10264 [D loss: 0.455018, acc.: 77.34%] [G loss: 0.602208]\n",
      "epoch:10 step:10265 [D loss: 0.547161, acc.: 75.78%] [G loss: 0.658704]\n",
      "epoch:10 step:10266 [D loss: 0.499348, acc.: 73.44%] [G loss: 0.699287]\n",
      "epoch:10 step:10267 [D loss: 0.546713, acc.: 71.88%] [G loss: 0.639010]\n",
      "epoch:10 step:10268 [D loss: 0.509967, acc.: 75.00%] [G loss: 0.591842]\n",
      "epoch:10 step:10269 [D loss: 0.471230, acc.: 81.25%] [G loss: 0.744543]\n",
      "epoch:10 step:10270 [D loss: 0.558053, acc.: 69.53%] [G loss: 0.730852]\n",
      "epoch:10 step:10271 [D loss: 0.560660, acc.: 62.50%] [G loss: 0.699435]\n",
      "epoch:10 step:10272 [D loss: 0.586873, acc.: 65.62%] [G loss: 0.537844]\n",
      "epoch:10 step:10273 [D loss: 0.567532, acc.: 67.97%] [G loss: 0.488705]\n",
      "epoch:10 step:10274 [D loss: 0.592906, acc.: 65.62%] [G loss: 0.633944]\n",
      "epoch:10 step:10275 [D loss: 0.592950, acc.: 67.19%] [G loss: 0.548241]\n",
      "epoch:10 step:10276 [D loss: 0.473690, acc.: 82.03%] [G loss: 0.717164]\n",
      "epoch:10 step:10277 [D loss: 0.599747, acc.: 64.84%] [G loss: 0.661436]\n",
      "epoch:10 step:10278 [D loss: 0.540895, acc.: 72.66%] [G loss: 0.571771]\n",
      "epoch:10 step:10279 [D loss: 0.490659, acc.: 78.12%] [G loss: 0.572326]\n",
      "epoch:10 step:10280 [D loss: 0.520154, acc.: 69.53%] [G loss: 0.753759]\n",
      "epoch:10 step:10281 [D loss: 0.485123, acc.: 78.12%] [G loss: 0.714578]\n",
      "epoch:10 step:10282 [D loss: 0.497341, acc.: 76.56%] [G loss: 0.785325]\n",
      "epoch:10 step:10283 [D loss: 0.569035, acc.: 71.88%] [G loss: 0.719913]\n",
      "epoch:10 step:10284 [D loss: 0.537865, acc.: 73.44%] [G loss: 0.712592]\n",
      "epoch:10 step:10285 [D loss: 0.639305, acc.: 58.59%] [G loss: 0.540585]\n",
      "epoch:10 step:10286 [D loss: 0.511868, acc.: 75.78%] [G loss: 0.666796]\n",
      "epoch:10 step:10287 [D loss: 0.622339, acc.: 64.06%] [G loss: 0.559904]\n",
      "epoch:10 step:10288 [D loss: 0.492420, acc.: 75.78%] [G loss: 0.662620]\n",
      "epoch:10 step:10289 [D loss: 0.484921, acc.: 77.34%] [G loss: 0.665580]\n",
      "epoch:10 step:10290 [D loss: 0.743512, acc.: 58.59%] [G loss: 0.455956]\n",
      "epoch:10 step:10291 [D loss: 0.501824, acc.: 74.22%] [G loss: 0.629286]\n",
      "epoch:10 step:10292 [D loss: 0.493846, acc.: 75.78%] [G loss: 0.593763]\n",
      "epoch:10 step:10293 [D loss: 0.464155, acc.: 75.78%] [G loss: 0.626705]\n",
      "epoch:10 step:10294 [D loss: 0.476514, acc.: 77.34%] [G loss: 0.754127]\n",
      "epoch:10 step:10295 [D loss: 0.455033, acc.: 76.56%] [G loss: 0.800095]\n",
      "epoch:10 step:10296 [D loss: 0.467972, acc.: 74.22%] [G loss: 0.978368]\n",
      "epoch:10 step:10297 [D loss: 0.441841, acc.: 80.47%] [G loss: 0.977750]\n",
      "epoch:10 step:10298 [D loss: 0.647949, acc.: 66.41%] [G loss: 0.944680]\n",
      "epoch:10 step:10299 [D loss: 0.483328, acc.: 78.12%] [G loss: 1.021313]\n",
      "epoch:10 step:10300 [D loss: 0.491539, acc.: 76.56%] [G loss: 1.054121]\n",
      "epoch:10 step:10301 [D loss: 0.597284, acc.: 64.06%] [G loss: 0.762987]\n",
      "epoch:10 step:10302 [D loss: 0.599165, acc.: 63.28%] [G loss: 0.668210]\n",
      "epoch:10 step:10303 [D loss: 0.556718, acc.: 75.78%] [G loss: 0.812346]\n",
      "epoch:10 step:10304 [D loss: 0.518892, acc.: 70.31%] [G loss: 0.950286]\n",
      "epoch:10 step:10305 [D loss: 0.513248, acc.: 74.22%] [G loss: 0.854718]\n",
      "epoch:10 step:10306 [D loss: 0.400826, acc.: 79.69%] [G loss: 1.167241]\n",
      "epoch:10 step:10307 [D loss: 0.412950, acc.: 83.59%] [G loss: 1.222807]\n",
      "epoch:11 step:10308 [D loss: 0.645161, acc.: 67.19%] [G loss: 1.046453]\n",
      "epoch:11 step:10309 [D loss: 0.466482, acc.: 78.12%] [G loss: 1.002545]\n",
      "epoch:11 step:10310 [D loss: 0.602893, acc.: 66.41%] [G loss: 0.877242]\n",
      "epoch:11 step:10311 [D loss: 0.515369, acc.: 73.44%] [G loss: 0.857786]\n",
      "epoch:11 step:10312 [D loss: 0.645393, acc.: 65.62%] [G loss: 0.724976]\n",
      "epoch:11 step:10313 [D loss: 0.531138, acc.: 70.31%] [G loss: 0.802942]\n",
      "epoch:11 step:10314 [D loss: 0.535545, acc.: 77.34%] [G loss: 0.540972]\n",
      "epoch:11 step:10315 [D loss: 0.581938, acc.: 71.09%] [G loss: 0.622960]\n",
      "epoch:11 step:10316 [D loss: 0.508307, acc.: 71.09%] [G loss: 0.658812]\n",
      "epoch:11 step:10317 [D loss: 0.538653, acc.: 71.88%] [G loss: 0.733658]\n",
      "epoch:11 step:10318 [D loss: 0.506391, acc.: 75.00%] [G loss: 0.716410]\n",
      "epoch:11 step:10319 [D loss: 0.617443, acc.: 64.06%] [G loss: 0.638451]\n",
      "epoch:11 step:10320 [D loss: 0.536199, acc.: 74.22%] [G loss: 0.489926]\n",
      "epoch:11 step:10321 [D loss: 0.521897, acc.: 75.00%] [G loss: 0.572941]\n",
      "epoch:11 step:10322 [D loss: 0.522870, acc.: 76.56%] [G loss: 0.579634]\n",
      "epoch:11 step:10323 [D loss: 0.500330, acc.: 74.22%] [G loss: 0.837753]\n",
      "epoch:11 step:10324 [D loss: 0.561467, acc.: 72.66%] [G loss: 0.583736]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:11 step:10325 [D loss: 0.630772, acc.: 63.28%] [G loss: 0.427355]\n",
      "epoch:11 step:10326 [D loss: 0.564610, acc.: 71.09%] [G loss: 0.589171]\n",
      "epoch:11 step:10327 [D loss: 0.662644, acc.: 64.06%] [G loss: 0.552616]\n",
      "epoch:11 step:10328 [D loss: 0.593965, acc.: 64.06%] [G loss: 0.528053]\n",
      "epoch:11 step:10329 [D loss: 0.489280, acc.: 80.47%] [G loss: 0.565556]\n",
      "epoch:11 step:10330 [D loss: 0.529914, acc.: 70.31%] [G loss: 0.594396]\n",
      "epoch:11 step:10331 [D loss: 0.496274, acc.: 75.00%] [G loss: 0.694751]\n",
      "epoch:11 step:10332 [D loss: 0.531590, acc.: 72.66%] [G loss: 0.648986]\n",
      "epoch:11 step:10333 [D loss: 0.578335, acc.: 69.53%] [G loss: 0.553812]\n",
      "epoch:11 step:10334 [D loss: 0.491455, acc.: 75.78%] [G loss: 0.552323]\n",
      "epoch:11 step:10335 [D loss: 0.551614, acc.: 66.41%] [G loss: 0.547371]\n",
      "epoch:11 step:10336 [D loss: 0.513804, acc.: 75.00%] [G loss: 0.500644]\n",
      "epoch:11 step:10337 [D loss: 0.577186, acc.: 67.19%] [G loss: 0.602017]\n",
      "epoch:11 step:10338 [D loss: 0.603951, acc.: 66.41%] [G loss: 0.479143]\n",
      "epoch:11 step:10339 [D loss: 0.545118, acc.: 72.66%] [G loss: 0.529402]\n",
      "epoch:11 step:10340 [D loss: 0.504198, acc.: 74.22%] [G loss: 0.565988]\n",
      "epoch:11 step:10341 [D loss: 0.553228, acc.: 66.41%] [G loss: 0.609712]\n",
      "epoch:11 step:10342 [D loss: 0.617480, acc.: 64.84%] [G loss: 0.543785]\n",
      "epoch:11 step:10343 [D loss: 0.516258, acc.: 71.09%] [G loss: 0.636311]\n",
      "epoch:11 step:10344 [D loss: 0.481166, acc.: 78.12%] [G loss: 0.556477]\n",
      "epoch:11 step:10345 [D loss: 0.629009, acc.: 60.94%] [G loss: 0.592888]\n",
      "epoch:11 step:10346 [D loss: 0.564070, acc.: 67.19%] [G loss: 0.527713]\n",
      "epoch:11 step:10347 [D loss: 0.447704, acc.: 75.78%] [G loss: 0.708127]\n",
      "epoch:11 step:10348 [D loss: 0.515568, acc.: 75.00%] [G loss: 0.677834]\n",
      "epoch:11 step:10349 [D loss: 0.535623, acc.: 71.88%] [G loss: 0.575496]\n",
      "epoch:11 step:10350 [D loss: 0.523722, acc.: 75.78%] [G loss: 0.469754]\n",
      "epoch:11 step:10351 [D loss: 0.578042, acc.: 69.53%] [G loss: 0.518787]\n",
      "epoch:11 step:10352 [D loss: 0.489566, acc.: 72.66%] [G loss: 0.662145]\n",
      "epoch:11 step:10353 [D loss: 0.501937, acc.: 76.56%] [G loss: 0.646317]\n",
      "epoch:11 step:10354 [D loss: 0.524774, acc.: 68.75%] [G loss: 0.640983]\n",
      "epoch:11 step:10355 [D loss: 0.563218, acc.: 67.19%] [G loss: 0.575138]\n",
      "epoch:11 step:10356 [D loss: 0.527332, acc.: 72.66%] [G loss: 0.667458]\n",
      "epoch:11 step:10357 [D loss: 0.552242, acc.: 71.09%] [G loss: 0.659006]\n",
      "epoch:11 step:10358 [D loss: 0.648249, acc.: 64.84%] [G loss: 0.434672]\n",
      "epoch:11 step:10359 [D loss: 0.586697, acc.: 73.44%] [G loss: 0.463997]\n",
      "epoch:11 step:10360 [D loss: 0.516858, acc.: 71.88%] [G loss: 0.639307]\n",
      "epoch:11 step:10361 [D loss: 0.455383, acc.: 79.69%] [G loss: 0.572674]\n",
      "epoch:11 step:10362 [D loss: 0.545689, acc.: 71.88%] [G loss: 0.579710]\n",
      "epoch:11 step:10363 [D loss: 0.552653, acc.: 72.66%] [G loss: 0.762525]\n",
      "epoch:11 step:10364 [D loss: 0.527184, acc.: 72.66%] [G loss: 0.551395]\n",
      "epoch:11 step:10365 [D loss: 0.523271, acc.: 70.31%] [G loss: 0.650334]\n",
      "epoch:11 step:10366 [D loss: 0.580708, acc.: 71.09%] [G loss: 0.624085]\n",
      "epoch:11 step:10367 [D loss: 0.546328, acc.: 72.66%] [G loss: 0.666111]\n",
      "epoch:11 step:10368 [D loss: 0.558441, acc.: 67.97%] [G loss: 0.514504]\n",
      "epoch:11 step:10369 [D loss: 0.566319, acc.: 73.44%] [G loss: 0.550106]\n",
      "epoch:11 step:10370 [D loss: 0.604292, acc.: 67.19%] [G loss: 0.439120]\n",
      "epoch:11 step:10371 [D loss: 0.541932, acc.: 75.78%] [G loss: 0.620239]\n",
      "epoch:11 step:10372 [D loss: 0.507142, acc.: 76.56%] [G loss: 0.579824]\n",
      "epoch:11 step:10373 [D loss: 0.602721, acc.: 67.19%] [G loss: 0.644424]\n",
      "epoch:11 step:10374 [D loss: 0.521615, acc.: 74.22%] [G loss: 0.597750]\n",
      "epoch:11 step:10375 [D loss: 0.521922, acc.: 73.44%] [G loss: 0.595142]\n",
      "epoch:11 step:10376 [D loss: 0.478791, acc.: 81.25%] [G loss: 0.606883]\n",
      "epoch:11 step:10377 [D loss: 0.501262, acc.: 77.34%] [G loss: 0.562601]\n",
      "epoch:11 step:10378 [D loss: 0.556710, acc.: 71.09%] [G loss: 0.529169]\n",
      "epoch:11 step:10379 [D loss: 0.508313, acc.: 71.88%] [G loss: 0.660486]\n",
      "epoch:11 step:10380 [D loss: 0.573251, acc.: 68.75%] [G loss: 0.426497]\n",
      "epoch:11 step:10381 [D loss: 0.521278, acc.: 75.00%] [G loss: 0.694028]\n",
      "epoch:11 step:10382 [D loss: 0.521590, acc.: 73.44%] [G loss: 0.760795]\n",
      "epoch:11 step:10383 [D loss: 0.560675, acc.: 68.75%] [G loss: 0.915075]\n",
      "epoch:11 step:10384 [D loss: 0.420650, acc.: 78.91%] [G loss: 0.835896]\n",
      "epoch:11 step:10385 [D loss: 0.589196, acc.: 68.75%] [G loss: 0.562780]\n",
      "epoch:11 step:10386 [D loss: 0.571968, acc.: 66.41%] [G loss: 0.522922]\n",
      "epoch:11 step:10387 [D loss: 0.528004, acc.: 69.53%] [G loss: 0.516192]\n",
      "epoch:11 step:10388 [D loss: 0.543261, acc.: 69.53%] [G loss: 0.541984]\n",
      "epoch:11 step:10389 [D loss: 0.518831, acc.: 72.66%] [G loss: 0.622501]\n",
      "epoch:11 step:10390 [D loss: 0.526564, acc.: 71.88%] [G loss: 0.572865]\n",
      "epoch:11 step:10391 [D loss: 0.561340, acc.: 68.75%] [G loss: 0.682351]\n",
      "epoch:11 step:10392 [D loss: 0.610276, acc.: 64.06%] [G loss: 0.500281]\n",
      "epoch:11 step:10393 [D loss: 0.559858, acc.: 71.09%] [G loss: 0.505879]\n",
      "epoch:11 step:10394 [D loss: 0.540466, acc.: 64.84%] [G loss: 0.569436]\n",
      "epoch:11 step:10395 [D loss: 0.530144, acc.: 75.00%] [G loss: 0.514340]\n",
      "epoch:11 step:10396 [D loss: 0.551165, acc.: 67.19%] [G loss: 0.564790]\n",
      "epoch:11 step:10397 [D loss: 0.500395, acc.: 75.00%] [G loss: 0.538970]\n",
      "epoch:11 step:10398 [D loss: 0.572420, acc.: 65.62%] [G loss: 0.439718]\n",
      "epoch:11 step:10399 [D loss: 0.473173, acc.: 78.91%] [G loss: 0.509291]\n",
      "epoch:11 step:10400 [D loss: 0.555215, acc.: 70.31%] [G loss: 0.726300]\n",
      "##############\n",
      "[3.15230152 0.96622883 6.24512203 4.84300267 3.89160201 5.71224479\n",
      " 4.70133191 5.12838278 4.35440769 3.78212731]\n",
      "##########\n",
      "epoch:11 step:10401 [D loss: 0.467944, acc.: 73.44%] [G loss: 0.740974]\n",
      "epoch:11 step:10402 [D loss: 0.534281, acc.: 74.22%] [G loss: 0.587029]\n",
      "epoch:11 step:10403 [D loss: 0.519819, acc.: 76.56%] [G loss: 0.575838]\n",
      "epoch:11 step:10404 [D loss: 0.530939, acc.: 68.75%] [G loss: 0.634766]\n",
      "epoch:11 step:10405 [D loss: 0.545431, acc.: 70.31%] [G loss: 0.466141]\n",
      "epoch:11 step:10406 [D loss: 0.533251, acc.: 71.09%] [G loss: 0.762385]\n",
      "epoch:11 step:10407 [D loss: 0.458299, acc.: 77.34%] [G loss: 0.626082]\n",
      "epoch:11 step:10408 [D loss: 0.525930, acc.: 74.22%] [G loss: 0.653595]\n",
      "epoch:11 step:10409 [D loss: 0.658280, acc.: 60.16%] [G loss: 0.581838]\n",
      "epoch:11 step:10410 [D loss: 0.571680, acc.: 66.41%] [G loss: 0.516550]\n",
      "epoch:11 step:10411 [D loss: 0.541588, acc.: 69.53%] [G loss: 0.577969]\n",
      "epoch:11 step:10412 [D loss: 0.579633, acc.: 63.28%] [G loss: 0.592232]\n",
      "epoch:11 step:10413 [D loss: 0.573631, acc.: 68.75%] [G loss: 0.510020]\n",
      "epoch:11 step:10414 [D loss: 0.580499, acc.: 68.75%] [G loss: 0.498538]\n",
      "epoch:11 step:10415 [D loss: 0.692485, acc.: 59.38%] [G loss: 0.484014]\n",
      "epoch:11 step:10416 [D loss: 0.661848, acc.: 64.84%] [G loss: 0.533364]\n",
      "epoch:11 step:10417 [D loss: 0.540403, acc.: 75.78%] [G loss: 0.423524]\n",
      "epoch:11 step:10418 [D loss: 0.530315, acc.: 72.66%] [G loss: 0.419542]\n",
      "epoch:11 step:10419 [D loss: 0.530196, acc.: 75.00%] [G loss: 0.555813]\n",
      "epoch:11 step:10420 [D loss: 0.592145, acc.: 65.62%] [G loss: 0.521443]\n",
      "epoch:11 step:10421 [D loss: 0.521450, acc.: 77.34%] [G loss: 0.609034]\n",
      "epoch:11 step:10422 [D loss: 0.592741, acc.: 71.09%] [G loss: 0.571424]\n",
      "epoch:11 step:10423 [D loss: 0.509124, acc.: 71.88%] [G loss: 0.616483]\n",
      "epoch:11 step:10424 [D loss: 0.529916, acc.: 67.97%] [G loss: 0.688699]\n",
      "epoch:11 step:10425 [D loss: 0.517253, acc.: 75.00%] [G loss: 0.647325]\n",
      "epoch:11 step:10426 [D loss: 0.474418, acc.: 79.69%] [G loss: 0.683333]\n",
      "epoch:11 step:10427 [D loss: 0.529884, acc.: 75.00%] [G loss: 0.741947]\n",
      "epoch:11 step:10428 [D loss: 0.562499, acc.: 71.09%] [G loss: 0.646351]\n",
      "epoch:11 step:10429 [D loss: 0.504208, acc.: 76.56%] [G loss: 0.660747]\n",
      "epoch:11 step:10430 [D loss: 0.507980, acc.: 75.78%] [G loss: 0.739070]\n",
      "epoch:11 step:10431 [D loss: 0.594333, acc.: 67.97%] [G loss: 0.657045]\n",
      "epoch:11 step:10432 [D loss: 0.570807, acc.: 70.31%] [G loss: 0.560668]\n",
      "epoch:11 step:10433 [D loss: 0.496078, acc.: 75.78%] [G loss: 0.510124]\n",
      "epoch:11 step:10434 [D loss: 0.520179, acc.: 75.00%] [G loss: 0.557499]\n",
      "epoch:11 step:10435 [D loss: 0.531971, acc.: 72.66%] [G loss: 0.635471]\n",
      "epoch:11 step:10436 [D loss: 0.615568, acc.: 60.16%] [G loss: 0.427783]\n",
      "epoch:11 step:10437 [D loss: 0.525336, acc.: 73.44%] [G loss: 0.469416]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:11 step:10438 [D loss: 0.504176, acc.: 72.66%] [G loss: 0.679046]\n",
      "epoch:11 step:10439 [D loss: 0.569377, acc.: 68.75%] [G loss: 0.549313]\n",
      "epoch:11 step:10440 [D loss: 0.611756, acc.: 64.84%] [G loss: 0.568036]\n",
      "epoch:11 step:10441 [D loss: 0.537964, acc.: 70.31%] [G loss: 0.584589]\n",
      "epoch:11 step:10442 [D loss: 0.555414, acc.: 68.75%] [G loss: 0.643091]\n",
      "epoch:11 step:10443 [D loss: 0.508545, acc.: 76.56%] [G loss: 0.635697]\n",
      "epoch:11 step:10444 [D loss: 0.653950, acc.: 60.16%] [G loss: 0.498759]\n",
      "epoch:11 step:10445 [D loss: 0.552875, acc.: 69.53%] [G loss: 0.493975]\n",
      "epoch:11 step:10446 [D loss: 0.579016, acc.: 66.41%] [G loss: 0.544158]\n",
      "epoch:11 step:10447 [D loss: 0.578157, acc.: 66.41%] [G loss: 0.471886]\n",
      "epoch:11 step:10448 [D loss: 0.574342, acc.: 67.97%] [G loss: 0.423133]\n",
      "epoch:11 step:10449 [D loss: 0.550304, acc.: 65.62%] [G loss: 0.542462]\n",
      "epoch:11 step:10450 [D loss: 0.612525, acc.: 60.94%] [G loss: 0.583309]\n",
      "epoch:11 step:10451 [D loss: 0.478038, acc.: 75.78%] [G loss: 0.656395]\n",
      "epoch:11 step:10452 [D loss: 0.612923, acc.: 61.72%] [G loss: 0.621368]\n",
      "epoch:11 step:10453 [D loss: 0.502566, acc.: 74.22%] [G loss: 0.635607]\n",
      "epoch:11 step:10454 [D loss: 0.620626, acc.: 60.16%] [G loss: 0.536590]\n",
      "epoch:11 step:10455 [D loss: 0.643697, acc.: 54.69%] [G loss: 0.600764]\n",
      "epoch:11 step:10456 [D loss: 0.508272, acc.: 74.22%] [G loss: 0.495779]\n",
      "epoch:11 step:10457 [D loss: 0.556344, acc.: 67.97%] [G loss: 0.522920]\n",
      "epoch:11 step:10458 [D loss: 0.517705, acc.: 77.34%] [G loss: 0.585958]\n",
      "epoch:11 step:10459 [D loss: 0.517705, acc.: 71.09%] [G loss: 0.692406]\n",
      "epoch:11 step:10460 [D loss: 0.612872, acc.: 64.84%] [G loss: 0.580732]\n",
      "epoch:11 step:10461 [D loss: 0.543925, acc.: 71.09%] [G loss: 0.635639]\n",
      "epoch:11 step:10462 [D loss: 0.478270, acc.: 81.25%] [G loss: 0.611825]\n",
      "epoch:11 step:10463 [D loss: 0.528738, acc.: 70.31%] [G loss: 0.663992]\n",
      "epoch:11 step:10464 [D loss: 0.607724, acc.: 62.50%] [G loss: 0.476566]\n",
      "epoch:11 step:10465 [D loss: 0.638145, acc.: 65.62%] [G loss: 0.518571]\n",
      "epoch:11 step:10466 [D loss: 0.482573, acc.: 78.91%] [G loss: 0.698844]\n",
      "epoch:11 step:10467 [D loss: 0.587438, acc.: 67.19%] [G loss: 0.575186]\n",
      "epoch:11 step:10468 [D loss: 0.546641, acc.: 68.75%] [G loss: 0.529863]\n",
      "epoch:11 step:10469 [D loss: 0.509832, acc.: 72.66%] [G loss: 0.741171]\n",
      "epoch:11 step:10470 [D loss: 0.555949, acc.: 68.75%] [G loss: 0.704573]\n",
      "epoch:11 step:10471 [D loss: 0.562895, acc.: 65.62%] [G loss: 0.627370]\n",
      "epoch:11 step:10472 [D loss: 0.495974, acc.: 78.12%] [G loss: 0.512434]\n",
      "epoch:11 step:10473 [D loss: 0.628277, acc.: 62.50%] [G loss: 0.421552]\n",
      "epoch:11 step:10474 [D loss: 0.516130, acc.: 74.22%] [G loss: 0.509909]\n",
      "epoch:11 step:10475 [D loss: 0.583840, acc.: 69.53%] [G loss: 0.463211]\n",
      "epoch:11 step:10476 [D loss: 0.592406, acc.: 64.84%] [G loss: 0.441412]\n",
      "epoch:11 step:10477 [D loss: 0.535208, acc.: 67.19%] [G loss: 0.456610]\n",
      "epoch:11 step:10478 [D loss: 0.531900, acc.: 70.31%] [G loss: 0.563356]\n",
      "epoch:11 step:10479 [D loss: 0.537839, acc.: 73.44%] [G loss: 0.604295]\n",
      "epoch:11 step:10480 [D loss: 0.510159, acc.: 75.00%] [G loss: 0.558752]\n",
      "epoch:11 step:10481 [D loss: 0.605059, acc.: 67.97%] [G loss: 0.559136]\n",
      "epoch:11 step:10482 [D loss: 0.615933, acc.: 67.19%] [G loss: 0.593629]\n",
      "epoch:11 step:10483 [D loss: 0.513494, acc.: 74.22%] [G loss: 0.613125]\n",
      "epoch:11 step:10484 [D loss: 0.532895, acc.: 71.09%] [G loss: 0.528636]\n",
      "epoch:11 step:10485 [D loss: 0.567806, acc.: 68.75%] [G loss: 0.583360]\n",
      "epoch:11 step:10486 [D loss: 0.566066, acc.: 70.31%] [G loss: 0.476877]\n",
      "epoch:11 step:10487 [D loss: 0.599305, acc.: 64.06%] [G loss: 0.443832]\n",
      "epoch:11 step:10488 [D loss: 0.543001, acc.: 71.88%] [G loss: 0.514899]\n",
      "epoch:11 step:10489 [D loss: 0.580673, acc.: 63.28%] [G loss: 0.427551]\n",
      "epoch:11 step:10490 [D loss: 0.617676, acc.: 67.19%] [G loss: 0.551677]\n",
      "epoch:11 step:10491 [D loss: 0.504586, acc.: 74.22%] [G loss: 0.575572]\n",
      "epoch:11 step:10492 [D loss: 0.646150, acc.: 60.94%] [G loss: 0.594087]\n",
      "epoch:11 step:10493 [D loss: 0.526842, acc.: 71.09%] [G loss: 0.551431]\n",
      "epoch:11 step:10494 [D loss: 0.620772, acc.: 63.28%] [G loss: 0.416669]\n",
      "epoch:11 step:10495 [D loss: 0.551428, acc.: 70.31%] [G loss: 0.465134]\n",
      "epoch:11 step:10496 [D loss: 0.597612, acc.: 62.50%] [G loss: 0.425162]\n",
      "epoch:11 step:10497 [D loss: 0.535487, acc.: 71.09%] [G loss: 0.540678]\n",
      "epoch:11 step:10498 [D loss: 0.526671, acc.: 75.00%] [G loss: 0.532903]\n",
      "epoch:11 step:10499 [D loss: 0.502814, acc.: 75.78%] [G loss: 0.483416]\n",
      "epoch:11 step:10500 [D loss: 0.583320, acc.: 66.41%] [G loss: 0.526775]\n",
      "epoch:11 step:10501 [D loss: 0.469984, acc.: 78.12%] [G loss: 0.572677]\n",
      "epoch:11 step:10502 [D loss: 0.579051, acc.: 71.09%] [G loss: 0.680635]\n",
      "epoch:11 step:10503 [D loss: 0.650028, acc.: 61.72%] [G loss: 0.638772]\n",
      "epoch:11 step:10504 [D loss: 0.560072, acc.: 71.88%] [G loss: 0.513432]\n",
      "epoch:11 step:10505 [D loss: 0.526612, acc.: 71.09%] [G loss: 0.708188]\n",
      "epoch:11 step:10506 [D loss: 0.526291, acc.: 72.66%] [G loss: 0.687371]\n",
      "epoch:11 step:10507 [D loss: 0.595742, acc.: 67.19%] [G loss: 0.582803]\n",
      "epoch:11 step:10508 [D loss: 0.551441, acc.: 70.31%] [G loss: 0.521503]\n",
      "epoch:11 step:10509 [D loss: 0.458313, acc.: 81.25%] [G loss: 0.719233]\n",
      "epoch:11 step:10510 [D loss: 0.608869, acc.: 64.06%] [G loss: 0.579121]\n",
      "epoch:11 step:10511 [D loss: 0.555249, acc.: 69.53%] [G loss: 0.696323]\n",
      "epoch:11 step:10512 [D loss: 0.529241, acc.: 70.31%] [G loss: 0.450163]\n",
      "epoch:11 step:10513 [D loss: 0.527668, acc.: 72.66%] [G loss: 0.508471]\n",
      "epoch:11 step:10514 [D loss: 0.485141, acc.: 78.91%] [G loss: 0.608853]\n",
      "epoch:11 step:10515 [D loss: 0.456022, acc.: 79.69%] [G loss: 0.620609]\n",
      "epoch:11 step:10516 [D loss: 0.526121, acc.: 76.56%] [G loss: 0.699764]\n",
      "epoch:11 step:10517 [D loss: 0.600658, acc.: 64.06%] [G loss: 0.478948]\n",
      "epoch:11 step:10518 [D loss: 0.637133, acc.: 63.28%] [G loss: 0.502285]\n",
      "epoch:11 step:10519 [D loss: 0.575457, acc.: 73.44%] [G loss: 0.418786]\n",
      "epoch:11 step:10520 [D loss: 0.519606, acc.: 71.09%] [G loss: 0.595568]\n",
      "epoch:11 step:10521 [D loss: 0.669271, acc.: 60.94%] [G loss: 0.415260]\n",
      "epoch:11 step:10522 [D loss: 0.605403, acc.: 65.62%] [G loss: 0.600928]\n",
      "epoch:11 step:10523 [D loss: 0.555003, acc.: 61.72%] [G loss: 0.617729]\n",
      "epoch:11 step:10524 [D loss: 0.519031, acc.: 71.88%] [G loss: 0.674248]\n",
      "epoch:11 step:10525 [D loss: 0.505597, acc.: 76.56%] [G loss: 0.548618]\n",
      "epoch:11 step:10526 [D loss: 0.475502, acc.: 78.12%] [G loss: 0.644429]\n",
      "epoch:11 step:10527 [D loss: 0.619418, acc.: 63.28%] [G loss: 0.528550]\n",
      "epoch:11 step:10528 [D loss: 0.513233, acc.: 75.00%] [G loss: 0.609946]\n",
      "epoch:11 step:10529 [D loss: 0.442022, acc.: 85.94%] [G loss: 0.795607]\n",
      "epoch:11 step:10530 [D loss: 0.519963, acc.: 75.00%] [G loss: 0.770788]\n",
      "epoch:11 step:10531 [D loss: 0.568618, acc.: 72.66%] [G loss: 0.642231]\n",
      "epoch:11 step:10532 [D loss: 0.610480, acc.: 71.09%] [G loss: 0.639693]\n",
      "epoch:11 step:10533 [D loss: 0.544399, acc.: 74.22%] [G loss: 0.561108]\n",
      "epoch:11 step:10534 [D loss: 0.581438, acc.: 63.28%] [G loss: 0.410027]\n",
      "epoch:11 step:10535 [D loss: 0.575109, acc.: 66.41%] [G loss: 0.478662]\n",
      "epoch:11 step:10536 [D loss: 0.566013, acc.: 71.88%] [G loss: 0.511809]\n",
      "epoch:11 step:10537 [D loss: 0.515137, acc.: 76.56%] [G loss: 0.626136]\n",
      "epoch:11 step:10538 [D loss: 0.517202, acc.: 71.88%] [G loss: 0.703377]\n",
      "epoch:11 step:10539 [D loss: 0.444305, acc.: 80.47%] [G loss: 0.903702]\n",
      "epoch:11 step:10540 [D loss: 0.568587, acc.: 71.88%] [G loss: 0.619791]\n",
      "epoch:11 step:10541 [D loss: 0.579434, acc.: 72.66%] [G loss: 0.545965]\n",
      "epoch:11 step:10542 [D loss: 0.585969, acc.: 64.06%] [G loss: 0.595980]\n",
      "epoch:11 step:10543 [D loss: 0.512832, acc.: 71.88%] [G loss: 0.670752]\n",
      "epoch:11 step:10544 [D loss: 0.526660, acc.: 71.09%] [G loss: 0.578569]\n",
      "epoch:11 step:10545 [D loss: 0.569112, acc.: 63.28%] [G loss: 0.539310]\n",
      "epoch:11 step:10546 [D loss: 0.525323, acc.: 72.66%] [G loss: 0.470293]\n",
      "epoch:11 step:10547 [D loss: 0.547959, acc.: 67.19%] [G loss: 0.580555]\n",
      "epoch:11 step:10548 [D loss: 0.534886, acc.: 75.00%] [G loss: 0.611300]\n",
      "epoch:11 step:10549 [D loss: 0.503122, acc.: 78.91%] [G loss: 0.529280]\n",
      "epoch:11 step:10550 [D loss: 0.551461, acc.: 67.19%] [G loss: 0.683630]\n",
      "epoch:11 step:10551 [D loss: 0.484763, acc.: 77.34%] [G loss: 0.673723]\n",
      "epoch:11 step:10552 [D loss: 0.524612, acc.: 74.22%] [G loss: 0.477614]\n",
      "epoch:11 step:10553 [D loss: 0.524751, acc.: 74.22%] [G loss: 0.638528]\n",
      "epoch:11 step:10554 [D loss: 0.576284, acc.: 63.28%] [G loss: 0.542251]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:11 step:10555 [D loss: 0.537599, acc.: 71.09%] [G loss: 0.593218]\n",
      "epoch:11 step:10556 [D loss: 0.628980, acc.: 63.28%] [G loss: 0.571231]\n",
      "epoch:11 step:10557 [D loss: 0.631759, acc.: 60.94%] [G loss: 0.659001]\n",
      "epoch:11 step:10558 [D loss: 0.604151, acc.: 64.06%] [G loss: 0.714986]\n",
      "epoch:11 step:10559 [D loss: 0.587455, acc.: 67.97%] [G loss: 0.619193]\n",
      "epoch:11 step:10560 [D loss: 0.568492, acc.: 69.53%] [G loss: 0.513633]\n",
      "epoch:11 step:10561 [D loss: 0.506840, acc.: 71.88%] [G loss: 0.505170]\n",
      "epoch:11 step:10562 [D loss: 0.525498, acc.: 70.31%] [G loss: 0.584611]\n",
      "epoch:11 step:10563 [D loss: 0.554528, acc.: 68.75%] [G loss: 0.555462]\n",
      "epoch:11 step:10564 [D loss: 0.602193, acc.: 63.28%] [G loss: 0.565145]\n",
      "epoch:11 step:10565 [D loss: 0.553300, acc.: 69.53%] [G loss: 0.697037]\n",
      "epoch:11 step:10566 [D loss: 0.522526, acc.: 71.09%] [G loss: 0.616569]\n",
      "epoch:11 step:10567 [D loss: 0.556025, acc.: 67.97%] [G loss: 0.686279]\n",
      "epoch:11 step:10568 [D loss: 0.552370, acc.: 67.19%] [G loss: 0.499770]\n",
      "epoch:11 step:10569 [D loss: 0.564151, acc.: 69.53%] [G loss: 0.439483]\n",
      "epoch:11 step:10570 [D loss: 0.573986, acc.: 68.75%] [G loss: 0.537152]\n",
      "epoch:11 step:10571 [D loss: 0.562489, acc.: 70.31%] [G loss: 0.516269]\n",
      "epoch:11 step:10572 [D loss: 0.571490, acc.: 71.09%] [G loss: 0.637155]\n",
      "epoch:11 step:10573 [D loss: 0.563921, acc.: 66.41%] [G loss: 0.554899]\n",
      "epoch:11 step:10574 [D loss: 0.575824, acc.: 65.62%] [G loss: 0.645019]\n",
      "epoch:11 step:10575 [D loss: 0.526849, acc.: 71.88%] [G loss: 0.592592]\n",
      "epoch:11 step:10576 [D loss: 0.538690, acc.: 72.66%] [G loss: 0.544138]\n",
      "epoch:11 step:10577 [D loss: 0.491881, acc.: 76.56%] [G loss: 0.750550]\n",
      "epoch:11 step:10578 [D loss: 0.536461, acc.: 71.09%] [G loss: 0.755393]\n",
      "epoch:11 step:10579 [D loss: 0.498407, acc.: 74.22%] [G loss: 0.645538]\n",
      "epoch:11 step:10580 [D loss: 0.549363, acc.: 68.75%] [G loss: 0.660393]\n",
      "epoch:11 step:10581 [D loss: 0.513924, acc.: 75.00%] [G loss: 0.654802]\n",
      "epoch:11 step:10582 [D loss: 0.592013, acc.: 71.88%] [G loss: 0.460741]\n",
      "epoch:11 step:10583 [D loss: 0.569027, acc.: 67.97%] [G loss: 0.516607]\n",
      "epoch:11 step:10584 [D loss: 0.683146, acc.: 64.06%] [G loss: 0.436761]\n",
      "epoch:11 step:10585 [D loss: 0.677109, acc.: 55.47%] [G loss: 0.397735]\n",
      "epoch:11 step:10586 [D loss: 0.587600, acc.: 65.62%] [G loss: 0.449075]\n",
      "epoch:11 step:10587 [D loss: 0.540830, acc.: 70.31%] [G loss: 0.642735]\n",
      "epoch:11 step:10588 [D loss: 0.592282, acc.: 67.97%] [G loss: 0.557289]\n",
      "epoch:11 step:10589 [D loss: 0.578408, acc.: 65.62%] [G loss: 0.481059]\n",
      "epoch:11 step:10590 [D loss: 0.521879, acc.: 74.22%] [G loss: 0.656788]\n",
      "epoch:11 step:10591 [D loss: 0.489530, acc.: 73.44%] [G loss: 0.602164]\n",
      "epoch:11 step:10592 [D loss: 0.505655, acc.: 78.91%] [G loss: 0.436366]\n",
      "epoch:11 step:10593 [D loss: 0.482414, acc.: 76.56%] [G loss: 0.651755]\n",
      "epoch:11 step:10594 [D loss: 0.603177, acc.: 63.28%] [G loss: 0.603854]\n",
      "epoch:11 step:10595 [D loss: 0.569382, acc.: 67.97%] [G loss: 0.532819]\n",
      "epoch:11 step:10596 [D loss: 0.597229, acc.: 62.50%] [G loss: 0.550255]\n",
      "epoch:11 step:10597 [D loss: 0.583394, acc.: 63.28%] [G loss: 0.626760]\n",
      "epoch:11 step:10598 [D loss: 0.556579, acc.: 71.09%] [G loss: 0.688802]\n",
      "epoch:11 step:10599 [D loss: 0.512412, acc.: 74.22%] [G loss: 0.536874]\n",
      "epoch:11 step:10600 [D loss: 0.574870, acc.: 66.41%] [G loss: 0.449944]\n",
      "##############\n",
      "[3.27261177 1.19245459 6.37024106 4.88255442 3.87733344 5.76398418\n",
      " 4.51117584 4.89446981 4.45553203 3.93608147]\n",
      "##########\n",
      "epoch:11 step:10601 [D loss: 0.587533, acc.: 66.41%] [G loss: 0.490537]\n",
      "epoch:11 step:10602 [D loss: 0.609109, acc.: 64.06%] [G loss: 0.488543]\n",
      "epoch:11 step:10603 [D loss: 0.474032, acc.: 78.91%] [G loss: 0.576960]\n",
      "epoch:11 step:10604 [D loss: 0.568714, acc.: 68.75%] [G loss: 0.555409]\n",
      "epoch:11 step:10605 [D loss: 0.475230, acc.: 75.78%] [G loss: 0.671548]\n",
      "epoch:11 step:10606 [D loss: 0.474958, acc.: 76.56%] [G loss: 0.688337]\n",
      "epoch:11 step:10607 [D loss: 0.513130, acc.: 73.44%] [G loss: 0.618014]\n",
      "epoch:11 step:10608 [D loss: 0.662501, acc.: 63.28%] [G loss: 0.580576]\n",
      "epoch:11 step:10609 [D loss: 0.552575, acc.: 69.53%] [G loss: 0.525497]\n",
      "epoch:11 step:10610 [D loss: 0.550693, acc.: 71.09%] [G loss: 0.684361]\n",
      "epoch:11 step:10611 [D loss: 0.506693, acc.: 72.66%] [G loss: 0.560875]\n",
      "epoch:11 step:10612 [D loss: 0.533311, acc.: 73.44%] [G loss: 0.585470]\n",
      "epoch:11 step:10613 [D loss: 0.595771, acc.: 67.19%] [G loss: 0.684125]\n",
      "epoch:11 step:10614 [D loss: 0.492308, acc.: 75.78%] [G loss: 0.703351]\n",
      "epoch:11 step:10615 [D loss: 0.572432, acc.: 67.19%] [G loss: 0.549513]\n",
      "epoch:11 step:10616 [D loss: 0.539718, acc.: 66.41%] [G loss: 0.634998]\n",
      "epoch:11 step:10617 [D loss: 0.573248, acc.: 65.62%] [G loss: 0.671447]\n",
      "epoch:11 step:10618 [D loss: 0.459250, acc.: 76.56%] [G loss: 0.682953]\n",
      "epoch:11 step:10619 [D loss: 0.496261, acc.: 78.12%] [G loss: 0.661246]\n",
      "epoch:11 step:10620 [D loss: 0.540744, acc.: 71.88%] [G loss: 0.822943]\n",
      "epoch:11 step:10621 [D loss: 0.473801, acc.: 75.00%] [G loss: 0.947687]\n",
      "epoch:11 step:10622 [D loss: 0.481844, acc.: 78.12%] [G loss: 0.827436]\n",
      "epoch:11 step:10623 [D loss: 0.763104, acc.: 56.25%] [G loss: 0.544439]\n",
      "epoch:11 step:10624 [D loss: 0.611698, acc.: 60.94%] [G loss: 0.428407]\n",
      "epoch:11 step:10625 [D loss: 0.523633, acc.: 71.09%] [G loss: 0.577572]\n",
      "epoch:11 step:10626 [D loss: 0.599462, acc.: 70.31%] [G loss: 0.580309]\n",
      "epoch:11 step:10627 [D loss: 0.506685, acc.: 76.56%] [G loss: 0.576381]\n",
      "epoch:11 step:10628 [D loss: 0.470218, acc.: 82.03%] [G loss: 0.705671]\n",
      "epoch:11 step:10629 [D loss: 0.587493, acc.: 67.19%] [G loss: 0.608525]\n",
      "epoch:11 step:10630 [D loss: 0.600715, acc.: 67.19%] [G loss: 0.430906]\n",
      "epoch:11 step:10631 [D loss: 0.575649, acc.: 63.28%] [G loss: 0.434430]\n",
      "epoch:11 step:10632 [D loss: 0.553831, acc.: 73.44%] [G loss: 0.570822]\n",
      "epoch:11 step:10633 [D loss: 0.512371, acc.: 74.22%] [G loss: 0.600690]\n",
      "epoch:11 step:10634 [D loss: 0.545537, acc.: 70.31%] [G loss: 0.601382]\n",
      "epoch:11 step:10635 [D loss: 0.503825, acc.: 75.78%] [G loss: 0.527448]\n",
      "epoch:11 step:10636 [D loss: 0.540723, acc.: 69.53%] [G loss: 0.612072]\n",
      "epoch:11 step:10637 [D loss: 0.559642, acc.: 68.75%] [G loss: 0.567458]\n",
      "epoch:11 step:10638 [D loss: 0.579329, acc.: 67.19%] [G loss: 0.593014]\n",
      "epoch:11 step:10639 [D loss: 0.565049, acc.: 71.09%] [G loss: 0.553307]\n",
      "epoch:11 step:10640 [D loss: 0.506542, acc.: 72.66%] [G loss: 0.557329]\n",
      "epoch:11 step:10641 [D loss: 0.495240, acc.: 77.34%] [G loss: 0.610237]\n",
      "epoch:11 step:10642 [D loss: 0.557981, acc.: 68.75%] [G loss: 0.818255]\n",
      "epoch:11 step:10643 [D loss: 0.527276, acc.: 74.22%] [G loss: 0.738583]\n",
      "epoch:11 step:10644 [D loss: 0.515509, acc.: 75.00%] [G loss: 0.611841]\n",
      "epoch:11 step:10645 [D loss: 0.535116, acc.: 72.66%] [G loss: 0.528666]\n",
      "epoch:11 step:10646 [D loss: 0.516274, acc.: 75.78%] [G loss: 0.600979]\n",
      "epoch:11 step:10647 [D loss: 0.549783, acc.: 70.31%] [G loss: 0.625165]\n",
      "epoch:11 step:10648 [D loss: 0.597043, acc.: 70.31%] [G loss: 0.517015]\n",
      "epoch:11 step:10649 [D loss: 0.598606, acc.: 68.75%] [G loss: 0.723637]\n",
      "epoch:11 step:10650 [D loss: 0.482772, acc.: 82.03%] [G loss: 0.767265]\n",
      "epoch:11 step:10651 [D loss: 0.509833, acc.: 71.88%] [G loss: 0.805144]\n",
      "epoch:11 step:10652 [D loss: 0.573518, acc.: 64.84%] [G loss: 0.763413]\n",
      "epoch:11 step:10653 [D loss: 0.498087, acc.: 74.22%] [G loss: 0.946419]\n",
      "epoch:11 step:10654 [D loss: 0.475017, acc.: 76.56%] [G loss: 0.726352]\n",
      "epoch:11 step:10655 [D loss: 0.585415, acc.: 68.75%] [G loss: 0.668416]\n",
      "epoch:11 step:10656 [D loss: 0.696762, acc.: 55.47%] [G loss: 0.429116]\n",
      "epoch:11 step:10657 [D loss: 0.499723, acc.: 74.22%] [G loss: 0.551547]\n",
      "epoch:11 step:10658 [D loss: 0.502541, acc.: 74.22%] [G loss: 0.689124]\n",
      "epoch:11 step:10659 [D loss: 0.621328, acc.: 63.28%] [G loss: 0.615712]\n",
      "epoch:11 step:10660 [D loss: 0.547355, acc.: 70.31%] [G loss: 0.653280]\n",
      "epoch:11 step:10661 [D loss: 0.454309, acc.: 78.91%] [G loss: 0.783161]\n",
      "epoch:11 step:10662 [D loss: 0.546050, acc.: 76.56%] [G loss: 0.832425]\n",
      "epoch:11 step:10663 [D loss: 0.554913, acc.: 70.31%] [G loss: 0.554715]\n",
      "epoch:11 step:10664 [D loss: 0.511012, acc.: 75.00%] [G loss: 0.648414]\n",
      "epoch:11 step:10665 [D loss: 0.506962, acc.: 73.44%] [G loss: 0.695496]\n",
      "epoch:11 step:10666 [D loss: 0.478418, acc.: 78.91%] [G loss: 0.857279]\n",
      "epoch:11 step:10667 [D loss: 0.517047, acc.: 72.66%] [G loss: 0.834116]\n",
      "epoch:11 step:10668 [D loss: 0.468205, acc.: 78.12%] [G loss: 0.741979]\n",
      "epoch:11 step:10669 [D loss: 0.580352, acc.: 68.75%] [G loss: 0.669285]\n",
      "epoch:11 step:10670 [D loss: 0.568470, acc.: 71.09%] [G loss: 0.560702]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:11 step:10671 [D loss: 0.522292, acc.: 74.22%] [G loss: 0.424005]\n",
      "epoch:11 step:10672 [D loss: 0.575023, acc.: 65.62%] [G loss: 0.500634]\n",
      "epoch:11 step:10673 [D loss: 0.568566, acc.: 67.97%] [G loss: 0.704014]\n",
      "epoch:11 step:10674 [D loss: 0.557045, acc.: 72.66%] [G loss: 0.669257]\n",
      "epoch:11 step:10675 [D loss: 0.564498, acc.: 71.88%] [G loss: 0.557737]\n",
      "epoch:11 step:10676 [D loss: 0.563656, acc.: 71.09%] [G loss: 0.614476]\n",
      "epoch:11 step:10677 [D loss: 0.546073, acc.: 71.09%] [G loss: 0.550135]\n",
      "epoch:11 step:10678 [D loss: 0.580749, acc.: 69.53%] [G loss: 0.594663]\n",
      "epoch:11 step:10679 [D loss: 0.563928, acc.: 67.19%] [G loss: 0.552713]\n",
      "epoch:11 step:10680 [D loss: 0.570387, acc.: 70.31%] [G loss: 0.504665]\n",
      "epoch:11 step:10681 [D loss: 0.504665, acc.: 76.56%] [G loss: 0.632995]\n",
      "epoch:11 step:10682 [D loss: 0.549645, acc.: 65.62%] [G loss: 0.606161]\n",
      "epoch:11 step:10683 [D loss: 0.685603, acc.: 59.38%] [G loss: 0.492703]\n",
      "epoch:11 step:10684 [D loss: 0.590518, acc.: 67.97%] [G loss: 0.610667]\n",
      "epoch:11 step:10685 [D loss: 0.562598, acc.: 69.53%] [G loss: 0.718686]\n",
      "epoch:11 step:10686 [D loss: 0.576317, acc.: 69.53%] [G loss: 0.513491]\n",
      "epoch:11 step:10687 [D loss: 0.648159, acc.: 61.72%] [G loss: 0.401748]\n",
      "epoch:11 step:10688 [D loss: 0.509869, acc.: 69.53%] [G loss: 0.514514]\n",
      "epoch:11 step:10689 [D loss: 0.565191, acc.: 74.22%] [G loss: 0.566974]\n",
      "epoch:11 step:10690 [D loss: 0.583738, acc.: 67.97%] [G loss: 0.651721]\n",
      "epoch:11 step:10691 [D loss: 0.545761, acc.: 68.75%] [G loss: 0.655635]\n",
      "epoch:11 step:10692 [D loss: 0.454525, acc.: 77.34%] [G loss: 0.593309]\n",
      "epoch:11 step:10693 [D loss: 0.604958, acc.: 65.62%] [G loss: 0.545973]\n",
      "epoch:11 step:10694 [D loss: 0.568442, acc.: 67.97%] [G loss: 0.493216]\n",
      "epoch:11 step:10695 [D loss: 0.530148, acc.: 73.44%] [G loss: 0.637289]\n",
      "epoch:11 step:10696 [D loss: 0.544301, acc.: 71.09%] [G loss: 0.520057]\n",
      "epoch:11 step:10697 [D loss: 0.572518, acc.: 68.75%] [G loss: 0.484203]\n",
      "epoch:11 step:10698 [D loss: 0.558934, acc.: 67.19%] [G loss: 0.410719]\n",
      "epoch:11 step:10699 [D loss: 0.502218, acc.: 67.97%] [G loss: 0.567780]\n",
      "epoch:11 step:10700 [D loss: 0.606453, acc.: 61.72%] [G loss: 0.521696]\n",
      "epoch:11 step:10701 [D loss: 0.531769, acc.: 70.31%] [G loss: 0.519617]\n",
      "epoch:11 step:10702 [D loss: 0.558304, acc.: 67.19%] [G loss: 0.467475]\n",
      "epoch:11 step:10703 [D loss: 0.611653, acc.: 64.84%] [G loss: 0.537488]\n",
      "epoch:11 step:10704 [D loss: 0.560627, acc.: 69.53%] [G loss: 0.639280]\n",
      "epoch:11 step:10705 [D loss: 0.493441, acc.: 75.78%] [G loss: 0.808350]\n",
      "epoch:11 step:10706 [D loss: 0.513004, acc.: 75.78%] [G loss: 0.845980]\n",
      "epoch:11 step:10707 [D loss: 0.632143, acc.: 58.59%] [G loss: 0.679107]\n",
      "epoch:11 step:10708 [D loss: 0.640090, acc.: 58.59%] [G loss: 0.327204]\n",
      "epoch:11 step:10709 [D loss: 0.516256, acc.: 75.00%] [G loss: 0.644020]\n",
      "epoch:11 step:10710 [D loss: 0.535170, acc.: 72.66%] [G loss: 0.502945]\n",
      "epoch:11 step:10711 [D loss: 0.598451, acc.: 64.84%] [G loss: 0.571742]\n",
      "epoch:11 step:10712 [D loss: 0.540851, acc.: 71.09%] [G loss: 0.688148]\n",
      "epoch:11 step:10713 [D loss: 0.537348, acc.: 70.31%] [G loss: 0.724178]\n",
      "epoch:11 step:10714 [D loss: 0.562558, acc.: 68.75%] [G loss: 0.635513]\n",
      "epoch:11 step:10715 [D loss: 0.553727, acc.: 72.66%] [G loss: 0.644621]\n",
      "epoch:11 step:10716 [D loss: 0.620475, acc.: 64.06%] [G loss: 0.528045]\n",
      "epoch:11 step:10717 [D loss: 0.586596, acc.: 67.97%] [G loss: 0.712035]\n",
      "epoch:11 step:10718 [D loss: 0.547098, acc.: 67.19%] [G loss: 0.659709]\n",
      "epoch:11 step:10719 [D loss: 0.655685, acc.: 57.03%] [G loss: 0.435338]\n",
      "epoch:11 step:10720 [D loss: 0.558519, acc.: 70.31%] [G loss: 0.605882]\n",
      "epoch:11 step:10721 [D loss: 0.538273, acc.: 70.31%] [G loss: 0.605070]\n",
      "epoch:11 step:10722 [D loss: 0.504249, acc.: 75.00%] [G loss: 0.586485]\n",
      "epoch:11 step:10723 [D loss: 0.501729, acc.: 75.00%] [G loss: 0.563697]\n",
      "epoch:11 step:10724 [D loss: 0.611322, acc.: 67.19%] [G loss: 0.626700]\n",
      "epoch:11 step:10725 [D loss: 0.629598, acc.: 65.62%] [G loss: 0.603705]\n",
      "epoch:11 step:10726 [D loss: 0.591353, acc.: 69.53%] [G loss: 0.527736]\n",
      "epoch:11 step:10727 [D loss: 0.570875, acc.: 67.19%] [G loss: 0.574890]\n",
      "epoch:11 step:10728 [D loss: 0.606025, acc.: 60.94%] [G loss: 0.510171]\n",
      "epoch:11 step:10729 [D loss: 0.587033, acc.: 67.97%] [G loss: 0.462256]\n",
      "epoch:11 step:10730 [D loss: 0.550586, acc.: 71.09%] [G loss: 0.609355]\n",
      "epoch:11 step:10731 [D loss: 0.586588, acc.: 64.06%] [G loss: 0.533044]\n",
      "epoch:11 step:10732 [D loss: 0.538427, acc.: 74.22%] [G loss: 0.648527]\n",
      "epoch:11 step:10733 [D loss: 0.529276, acc.: 67.97%] [G loss: 0.614248]\n",
      "epoch:11 step:10734 [D loss: 0.478056, acc.: 81.25%] [G loss: 0.748518]\n",
      "epoch:11 step:10735 [D loss: 0.484030, acc.: 75.78%] [G loss: 0.777207]\n",
      "epoch:11 step:10736 [D loss: 0.540000, acc.: 72.66%] [G loss: 0.740291]\n",
      "epoch:11 step:10737 [D loss: 0.486023, acc.: 77.34%] [G loss: 0.600715]\n",
      "epoch:11 step:10738 [D loss: 0.513879, acc.: 70.31%] [G loss: 0.733843]\n",
      "epoch:11 step:10739 [D loss: 0.565930, acc.: 68.75%] [G loss: 0.573692]\n",
      "epoch:11 step:10740 [D loss: 0.560169, acc.: 72.66%] [G loss: 0.583920]\n",
      "epoch:11 step:10741 [D loss: 0.512217, acc.: 75.00%] [G loss: 0.501211]\n",
      "epoch:11 step:10742 [D loss: 0.571095, acc.: 67.19%] [G loss: 0.556141]\n",
      "epoch:11 step:10743 [D loss: 0.486425, acc.: 75.00%] [G loss: 0.685833]\n",
      "epoch:11 step:10744 [D loss: 0.652240, acc.: 64.06%] [G loss: 0.577983]\n",
      "epoch:11 step:10745 [D loss: 0.553871, acc.: 68.75%] [G loss: 0.677729]\n",
      "epoch:11 step:10746 [D loss: 0.498456, acc.: 74.22%] [G loss: 0.658310]\n",
      "epoch:11 step:10747 [D loss: 0.511683, acc.: 69.53%] [G loss: 0.574887]\n",
      "epoch:11 step:10748 [D loss: 0.539085, acc.: 71.09%] [G loss: 0.719431]\n",
      "epoch:11 step:10749 [D loss: 0.634130, acc.: 58.59%] [G loss: 0.656699]\n",
      "epoch:11 step:10750 [D loss: 0.531260, acc.: 71.88%] [G loss: 0.577884]\n",
      "epoch:11 step:10751 [D loss: 0.525350, acc.: 73.44%] [G loss: 0.615910]\n",
      "epoch:11 step:10752 [D loss: 0.591108, acc.: 63.28%] [G loss: 0.422349]\n",
      "epoch:11 step:10753 [D loss: 0.483725, acc.: 76.56%] [G loss: 0.589662]\n",
      "epoch:11 step:10754 [D loss: 0.506009, acc.: 75.00%] [G loss: 0.681513]\n",
      "epoch:11 step:10755 [D loss: 0.560325, acc.: 72.66%] [G loss: 0.742984]\n",
      "epoch:11 step:10756 [D loss: 0.516638, acc.: 74.22%] [G loss: 0.863643]\n",
      "epoch:11 step:10757 [D loss: 0.574299, acc.: 70.31%] [G loss: 0.744579]\n",
      "epoch:11 step:10758 [D loss: 0.429139, acc.: 83.59%] [G loss: 0.592681]\n",
      "epoch:11 step:10759 [D loss: 0.495842, acc.: 75.00%] [G loss: 0.758495]\n",
      "epoch:11 step:10760 [D loss: 0.531751, acc.: 75.78%] [G loss: 0.859257]\n",
      "epoch:11 step:10761 [D loss: 0.638626, acc.: 63.28%] [G loss: 0.581536]\n",
      "epoch:11 step:10762 [D loss: 0.573493, acc.: 67.97%] [G loss: 0.605678]\n",
      "epoch:11 step:10763 [D loss: 0.693181, acc.: 59.38%] [G loss: 0.402250]\n",
      "epoch:11 step:10764 [D loss: 0.522831, acc.: 71.88%] [G loss: 0.574180]\n",
      "epoch:11 step:10765 [D loss: 0.611865, acc.: 66.41%] [G loss: 0.508839]\n",
      "epoch:11 step:10766 [D loss: 0.545036, acc.: 74.22%] [G loss: 0.476246]\n",
      "epoch:11 step:10767 [D loss: 0.560771, acc.: 70.31%] [G loss: 0.510168]\n",
      "epoch:11 step:10768 [D loss: 0.526115, acc.: 70.31%] [G loss: 0.602736]\n",
      "epoch:11 step:10769 [D loss: 0.572133, acc.: 65.62%] [G loss: 0.567474]\n",
      "epoch:11 step:10770 [D loss: 0.572618, acc.: 70.31%] [G loss: 0.571908]\n",
      "epoch:11 step:10771 [D loss: 0.543898, acc.: 71.09%] [G loss: 0.600738]\n",
      "epoch:11 step:10772 [D loss: 0.619089, acc.: 60.94%] [G loss: 0.531696]\n",
      "epoch:11 step:10773 [D loss: 0.580084, acc.: 68.75%] [G loss: 0.579140]\n",
      "epoch:11 step:10774 [D loss: 0.565083, acc.: 67.97%] [G loss: 0.547546]\n",
      "epoch:11 step:10775 [D loss: 0.565651, acc.: 68.75%] [G loss: 0.582621]\n",
      "epoch:11 step:10776 [D loss: 0.531044, acc.: 68.75%] [G loss: 0.648121]\n",
      "epoch:11 step:10777 [D loss: 0.636307, acc.: 61.72%] [G loss: 0.559673]\n",
      "epoch:11 step:10778 [D loss: 0.424412, acc.: 81.25%] [G loss: 0.764117]\n",
      "epoch:11 step:10779 [D loss: 0.399037, acc.: 82.81%] [G loss: 0.853875]\n",
      "epoch:11 step:10780 [D loss: 0.666045, acc.: 62.50%] [G loss: 0.601648]\n",
      "epoch:11 step:10781 [D loss: 0.537253, acc.: 71.09%] [G loss: 0.649218]\n",
      "epoch:11 step:10782 [D loss: 0.518642, acc.: 72.66%] [G loss: 0.732889]\n",
      "epoch:11 step:10783 [D loss: 0.556646, acc.: 71.88%] [G loss: 0.651962]\n",
      "epoch:11 step:10784 [D loss: 0.697038, acc.: 60.94%] [G loss: 0.624975]\n",
      "epoch:11 step:10785 [D loss: 0.587363, acc.: 68.75%] [G loss: 0.520047]\n",
      "epoch:11 step:10786 [D loss: 0.591723, acc.: 66.41%] [G loss: 0.627353]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:11 step:10787 [D loss: 0.584960, acc.: 68.75%] [G loss: 0.580568]\n",
      "epoch:11 step:10788 [D loss: 0.471187, acc.: 82.03%] [G loss: 0.552434]\n",
      "epoch:11 step:10789 [D loss: 0.634852, acc.: 63.28%] [G loss: 0.436444]\n",
      "epoch:11 step:10790 [D loss: 0.553053, acc.: 70.31%] [G loss: 0.558112]\n",
      "epoch:11 step:10791 [D loss: 0.541676, acc.: 70.31%] [G loss: 0.534259]\n",
      "epoch:11 step:10792 [D loss: 0.550686, acc.: 67.19%] [G loss: 0.654773]\n",
      "epoch:11 step:10793 [D loss: 0.604398, acc.: 63.28%] [G loss: 0.543200]\n",
      "epoch:11 step:10794 [D loss: 0.542910, acc.: 66.41%] [G loss: 0.692925]\n",
      "epoch:11 step:10795 [D loss: 0.487481, acc.: 75.78%] [G loss: 0.475936]\n",
      "epoch:11 step:10796 [D loss: 0.560671, acc.: 71.88%] [G loss: 0.584849]\n",
      "epoch:11 step:10797 [D loss: 0.577576, acc.: 67.97%] [G loss: 0.559276]\n",
      "epoch:11 step:10798 [D loss: 0.516883, acc.: 71.09%] [G loss: 0.603129]\n",
      "epoch:11 step:10799 [D loss: 0.646886, acc.: 62.50%] [G loss: 0.438599]\n",
      "epoch:11 step:10800 [D loss: 0.603775, acc.: 67.19%] [G loss: 0.473367]\n",
      "##############\n",
      "[3.50395401 1.26763652 6.33663206 4.91947448 3.78726672 5.45660258\n",
      " 4.6792186  4.8053021  4.62654328 4.04596948]\n",
      "##########\n",
      "epoch:11 step:10801 [D loss: 0.593369, acc.: 64.06%] [G loss: 0.503611]\n",
      "epoch:11 step:10802 [D loss: 0.506190, acc.: 72.66%] [G loss: 0.619259]\n",
      "epoch:11 step:10803 [D loss: 0.573346, acc.: 69.53%] [G loss: 0.569271]\n",
      "epoch:11 step:10804 [D loss: 0.549217, acc.: 66.41%] [G loss: 0.562690]\n",
      "epoch:11 step:10805 [D loss: 0.567618, acc.: 68.75%] [G loss: 0.524536]\n",
      "epoch:11 step:10806 [D loss: 0.498938, acc.: 77.34%] [G loss: 0.570148]\n",
      "epoch:11 step:10807 [D loss: 0.560696, acc.: 69.53%] [G loss: 0.569680]\n",
      "epoch:11 step:10808 [D loss: 0.671932, acc.: 66.41%] [G loss: 0.558715]\n",
      "epoch:11 step:10809 [D loss: 0.619760, acc.: 62.50%] [G loss: 0.453797]\n",
      "epoch:11 step:10810 [D loss: 0.486741, acc.: 77.34%] [G loss: 0.570467]\n",
      "epoch:11 step:10811 [D loss: 0.462760, acc.: 82.81%] [G loss: 0.567033]\n",
      "epoch:11 step:10812 [D loss: 0.527613, acc.: 76.56%] [G loss: 0.701038]\n",
      "epoch:11 step:10813 [D loss: 0.544021, acc.: 75.00%] [G loss: 0.744179]\n",
      "epoch:11 step:10814 [D loss: 0.556559, acc.: 67.19%] [G loss: 0.680406]\n",
      "epoch:11 step:10815 [D loss: 0.456185, acc.: 79.69%] [G loss: 0.811475]\n",
      "epoch:11 step:10816 [D loss: 0.512543, acc.: 75.00%] [G loss: 0.730573]\n",
      "epoch:11 step:10817 [D loss: 0.623913, acc.: 66.41%] [G loss: 0.596228]\n",
      "epoch:11 step:10818 [D loss: 0.688723, acc.: 53.91%] [G loss: 0.327182]\n",
      "epoch:11 step:10819 [D loss: 0.569601, acc.: 65.62%] [G loss: 0.398916]\n",
      "epoch:11 step:10820 [D loss: 0.512686, acc.: 76.56%] [G loss: 0.533046]\n",
      "epoch:11 step:10821 [D loss: 0.569244, acc.: 65.62%] [G loss: 0.621470]\n",
      "epoch:11 step:10822 [D loss: 0.568480, acc.: 65.62%] [G loss: 0.722517]\n",
      "epoch:11 step:10823 [D loss: 0.489162, acc.: 75.78%] [G loss: 0.660713]\n",
      "epoch:11 step:10824 [D loss: 0.546539, acc.: 75.00%] [G loss: 0.539125]\n",
      "epoch:11 step:10825 [D loss: 0.562603, acc.: 67.97%] [G loss: 0.546619]\n",
      "epoch:11 step:10826 [D loss: 0.520444, acc.: 75.00%] [G loss: 0.592365]\n",
      "epoch:11 step:10827 [D loss: 0.484235, acc.: 73.44%] [G loss: 0.679992]\n",
      "epoch:11 step:10828 [D loss: 0.563802, acc.: 68.75%] [G loss: 0.554765]\n",
      "epoch:11 step:10829 [D loss: 0.535165, acc.: 70.31%] [G loss: 0.522940]\n",
      "epoch:11 step:10830 [D loss: 0.507319, acc.: 73.44%] [G loss: 0.567310]\n",
      "epoch:11 step:10831 [D loss: 0.589606, acc.: 68.75%] [G loss: 0.531458]\n",
      "epoch:11 step:10832 [D loss: 0.542754, acc.: 74.22%] [G loss: 0.611726]\n",
      "epoch:11 step:10833 [D loss: 0.498651, acc.: 72.66%] [G loss: 0.631500]\n",
      "epoch:11 step:10834 [D loss: 0.544394, acc.: 68.75%] [G loss: 0.641373]\n",
      "epoch:11 step:10835 [D loss: 0.676138, acc.: 61.72%] [G loss: 0.546635]\n",
      "epoch:11 step:10836 [D loss: 0.583606, acc.: 64.06%] [G loss: 0.375081]\n",
      "epoch:11 step:10837 [D loss: 0.553968, acc.: 68.75%] [G loss: 0.493254]\n",
      "epoch:11 step:10838 [D loss: 0.582862, acc.: 65.62%] [G loss: 0.517317]\n",
      "epoch:11 step:10839 [D loss: 0.530952, acc.: 72.66%] [G loss: 0.701306]\n",
      "epoch:11 step:10840 [D loss: 0.549918, acc.: 67.97%] [G loss: 0.619574]\n",
      "epoch:11 step:10841 [D loss: 0.520840, acc.: 75.00%] [G loss: 0.483529]\n",
      "epoch:11 step:10842 [D loss: 0.616914, acc.: 60.16%] [G loss: 0.495247]\n",
      "epoch:11 step:10843 [D loss: 0.500851, acc.: 78.91%] [G loss: 0.483546]\n",
      "epoch:11 step:10844 [D loss: 0.586660, acc.: 67.19%] [G loss: 0.521953]\n",
      "epoch:11 step:10845 [D loss: 0.566260, acc.: 66.41%] [G loss: 0.525032]\n",
      "epoch:11 step:10846 [D loss: 0.530838, acc.: 72.66%] [G loss: 0.511088]\n",
      "epoch:11 step:10847 [D loss: 0.552915, acc.: 70.31%] [G loss: 0.606106]\n",
      "epoch:11 step:10848 [D loss: 0.554114, acc.: 68.75%] [G loss: 0.474583]\n",
      "epoch:11 step:10849 [D loss: 0.600762, acc.: 65.62%] [G loss: 0.457434]\n",
      "epoch:11 step:10850 [D loss: 0.624870, acc.: 64.84%] [G loss: 0.456776]\n",
      "epoch:11 step:10851 [D loss: 0.523450, acc.: 74.22%] [G loss: 0.453772]\n",
      "epoch:11 step:10852 [D loss: 0.570650, acc.: 70.31%] [G loss: 0.611318]\n",
      "epoch:11 step:10853 [D loss: 0.524575, acc.: 74.22%] [G loss: 0.598436]\n",
      "epoch:11 step:10854 [D loss: 0.509699, acc.: 74.22%] [G loss: 0.596324]\n",
      "epoch:11 step:10855 [D loss: 0.483305, acc.: 77.34%] [G loss: 0.663466]\n",
      "epoch:11 step:10856 [D loss: 0.540162, acc.: 71.09%] [G loss: 0.684304]\n",
      "epoch:11 step:10857 [D loss: 0.570898, acc.: 71.88%] [G loss: 0.502815]\n",
      "epoch:11 step:10858 [D loss: 0.511053, acc.: 72.66%] [G loss: 0.609719]\n",
      "epoch:11 step:10859 [D loss: 0.494755, acc.: 79.69%] [G loss: 0.620700]\n",
      "epoch:11 step:10860 [D loss: 0.598923, acc.: 65.62%] [G loss: 0.483383]\n",
      "epoch:11 step:10861 [D loss: 0.536808, acc.: 69.53%] [G loss: 0.508540]\n",
      "epoch:11 step:10862 [D loss: 0.458525, acc.: 79.69%] [G loss: 0.672174]\n",
      "epoch:11 step:10863 [D loss: 0.534012, acc.: 71.88%] [G loss: 0.639404]\n",
      "epoch:11 step:10864 [D loss: 0.498252, acc.: 75.78%] [G loss: 0.571307]\n",
      "epoch:11 step:10865 [D loss: 0.546131, acc.: 72.66%] [G loss: 0.610110]\n",
      "epoch:11 step:10866 [D loss: 0.646585, acc.: 55.47%] [G loss: 0.753594]\n",
      "epoch:11 step:10867 [D loss: 0.500248, acc.: 73.44%] [G loss: 0.713454]\n",
      "epoch:11 step:10868 [D loss: 0.558304, acc.: 71.09%] [G loss: 0.683595]\n",
      "epoch:11 step:10869 [D loss: 0.632876, acc.: 61.72%] [G loss: 0.508536]\n",
      "epoch:11 step:10870 [D loss: 0.573073, acc.: 70.31%] [G loss: 0.644137]\n",
      "epoch:11 step:10871 [D loss: 0.540229, acc.: 71.88%] [G loss: 0.690389]\n",
      "epoch:11 step:10872 [D loss: 0.563002, acc.: 70.31%] [G loss: 0.773902]\n",
      "epoch:11 step:10873 [D loss: 0.712971, acc.: 60.16%] [G loss: 0.421887]\n",
      "epoch:11 step:10874 [D loss: 0.513769, acc.: 75.00%] [G loss: 0.509425]\n",
      "epoch:11 step:10875 [D loss: 0.519732, acc.: 70.31%] [G loss: 0.545900]\n",
      "epoch:11 step:10876 [D loss: 0.588017, acc.: 63.28%] [G loss: 0.590384]\n",
      "epoch:11 step:10877 [D loss: 0.557950, acc.: 71.09%] [G loss: 0.559703]\n",
      "epoch:11 step:10878 [D loss: 0.548886, acc.: 72.66%] [G loss: 0.527236]\n",
      "epoch:11 step:10879 [D loss: 0.520381, acc.: 72.66%] [G loss: 0.621599]\n",
      "epoch:11 step:10880 [D loss: 0.517549, acc.: 72.66%] [G loss: 0.586298]\n",
      "epoch:11 step:10881 [D loss: 0.481306, acc.: 78.12%] [G loss: 0.585624]\n",
      "epoch:11 step:10882 [D loss: 0.554475, acc.: 68.75%] [G loss: 0.540309]\n",
      "epoch:11 step:10883 [D loss: 0.594629, acc.: 63.28%] [G loss: 0.594075]\n",
      "epoch:11 step:10884 [D loss: 0.610096, acc.: 67.97%] [G loss: 0.471614]\n",
      "epoch:11 step:10885 [D loss: 0.541798, acc.: 67.19%] [G loss: 0.569617]\n",
      "epoch:11 step:10886 [D loss: 0.527157, acc.: 74.22%] [G loss: 0.549458]\n",
      "epoch:11 step:10887 [D loss: 0.555487, acc.: 71.88%] [G loss: 0.579500]\n",
      "epoch:11 step:10888 [D loss: 0.535002, acc.: 71.09%] [G loss: 0.640338]\n",
      "epoch:11 step:10889 [D loss: 0.451487, acc.: 79.69%] [G loss: 0.698519]\n",
      "epoch:11 step:10890 [D loss: 0.589666, acc.: 67.97%] [G loss: 0.692363]\n",
      "epoch:11 step:10891 [D loss: 0.633846, acc.: 61.72%] [G loss: 0.628900]\n",
      "epoch:11 step:10892 [D loss: 0.589806, acc.: 63.28%] [G loss: 0.527382]\n",
      "epoch:11 step:10893 [D loss: 0.632120, acc.: 61.72%] [G loss: 0.411516]\n",
      "epoch:11 step:10894 [D loss: 0.553944, acc.: 68.75%] [G loss: 0.649098]\n",
      "epoch:11 step:10895 [D loss: 0.654689, acc.: 60.94%] [G loss: 0.507103]\n",
      "epoch:11 step:10896 [D loss: 0.519747, acc.: 70.31%] [G loss: 0.683537]\n",
      "epoch:11 step:10897 [D loss: 0.634813, acc.: 61.72%] [G loss: 0.539867]\n",
      "epoch:11 step:10898 [D loss: 0.644186, acc.: 63.28%] [G loss: 0.521860]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:11 step:10899 [D loss: 0.506162, acc.: 74.22%] [G loss: 0.572545]\n",
      "epoch:11 step:10900 [D loss: 0.510635, acc.: 74.22%] [G loss: 0.675254]\n",
      "epoch:11 step:10901 [D loss: 0.616880, acc.: 70.31%] [G loss: 0.568669]\n",
      "epoch:11 step:10902 [D loss: 0.543521, acc.: 70.31%] [G loss: 0.636166]\n",
      "epoch:11 step:10903 [D loss: 0.519010, acc.: 72.66%] [G loss: 0.558634]\n",
      "epoch:11 step:10904 [D loss: 0.564182, acc.: 71.88%] [G loss: 0.565913]\n",
      "epoch:11 step:10905 [D loss: 0.530404, acc.: 74.22%] [G loss: 0.667271]\n",
      "epoch:11 step:10906 [D loss: 0.535208, acc.: 74.22%] [G loss: 0.676040]\n",
      "epoch:11 step:10907 [D loss: 0.614105, acc.: 64.06%] [G loss: 0.505300]\n",
      "epoch:11 step:10908 [D loss: 0.528155, acc.: 73.44%] [G loss: 0.521438]\n",
      "epoch:11 step:10909 [D loss: 0.463016, acc.: 78.91%] [G loss: 0.591078]\n",
      "epoch:11 step:10910 [D loss: 0.515149, acc.: 80.47%] [G loss: 0.581771]\n",
      "epoch:11 step:10911 [D loss: 0.538609, acc.: 66.41%] [G loss: 0.782825]\n",
      "epoch:11 step:10912 [D loss: 0.484586, acc.: 75.00%] [G loss: 0.733733]\n",
      "epoch:11 step:10913 [D loss: 0.638414, acc.: 60.94%] [G loss: 0.597534]\n",
      "epoch:11 step:10914 [D loss: 0.518559, acc.: 71.88%] [G loss: 0.571470]\n",
      "epoch:11 step:10915 [D loss: 0.545435, acc.: 75.78%] [G loss: 0.504450]\n",
      "epoch:11 step:10916 [D loss: 0.513966, acc.: 72.66%] [G loss: 0.601765]\n",
      "epoch:11 step:10917 [D loss: 0.563984, acc.: 65.62%] [G loss: 0.463635]\n",
      "epoch:11 step:10918 [D loss: 0.513711, acc.: 72.66%] [G loss: 0.488049]\n",
      "epoch:11 step:10919 [D loss: 0.519345, acc.: 77.34%] [G loss: 0.469872]\n",
      "epoch:11 step:10920 [D loss: 0.517181, acc.: 69.53%] [G loss: 0.508091]\n",
      "epoch:11 step:10921 [D loss: 0.582432, acc.: 67.97%] [G loss: 0.546916]\n",
      "epoch:11 step:10922 [D loss: 0.597035, acc.: 67.97%] [G loss: 0.578852]\n",
      "epoch:11 step:10923 [D loss: 0.586846, acc.: 68.75%] [G loss: 0.696660]\n",
      "epoch:11 step:10924 [D loss: 0.563253, acc.: 66.41%] [G loss: 0.515925]\n",
      "epoch:11 step:10925 [D loss: 0.518875, acc.: 71.09%] [G loss: 0.629089]\n",
      "epoch:11 step:10926 [D loss: 0.589366, acc.: 66.41%] [G loss: 0.468031]\n",
      "epoch:11 step:10927 [D loss: 0.557272, acc.: 71.09%] [G loss: 0.789001]\n",
      "epoch:11 step:10928 [D loss: 0.553738, acc.: 70.31%] [G loss: 0.514395]\n",
      "epoch:11 step:10929 [D loss: 0.661784, acc.: 62.50%] [G loss: 0.503825]\n",
      "epoch:11 step:10930 [D loss: 0.509618, acc.: 73.44%] [G loss: 0.627746]\n",
      "epoch:11 step:10931 [D loss: 0.474369, acc.: 75.00%] [G loss: 0.580641]\n",
      "epoch:11 step:10932 [D loss: 0.540001, acc.: 70.31%] [G loss: 0.685676]\n",
      "epoch:11 step:10933 [D loss: 0.599705, acc.: 66.41%] [G loss: 0.570214]\n",
      "epoch:11 step:10934 [D loss: 0.529723, acc.: 68.75%] [G loss: 0.518023]\n",
      "epoch:11 step:10935 [D loss: 0.554414, acc.: 67.97%] [G loss: 0.514353]\n",
      "epoch:11 step:10936 [D loss: 0.513741, acc.: 74.22%] [G loss: 0.521190]\n",
      "epoch:11 step:10937 [D loss: 0.554898, acc.: 72.66%] [G loss: 0.529516]\n",
      "epoch:11 step:10938 [D loss: 0.504306, acc.: 80.47%] [G loss: 0.651632]\n",
      "epoch:11 step:10939 [D loss: 0.515510, acc.: 75.78%] [G loss: 0.609895]\n",
      "epoch:11 step:10940 [D loss: 0.505068, acc.: 76.56%] [G loss: 0.639341]\n",
      "epoch:11 step:10941 [D loss: 0.501799, acc.: 73.44%] [G loss: 0.536827]\n",
      "epoch:11 step:10942 [D loss: 0.469733, acc.: 75.78%] [G loss: 0.588830]\n",
      "epoch:11 step:10943 [D loss: 0.635405, acc.: 65.62%] [G loss: 0.478235]\n",
      "epoch:11 step:10944 [D loss: 0.550408, acc.: 71.88%] [G loss: 0.635180]\n",
      "epoch:11 step:10945 [D loss: 0.527625, acc.: 73.44%] [G loss: 0.486504]\n",
      "epoch:11 step:10946 [D loss: 0.507790, acc.: 71.88%] [G loss: 0.568179]\n",
      "epoch:11 step:10947 [D loss: 0.556565, acc.: 69.53%] [G loss: 0.537788]\n",
      "epoch:11 step:10948 [D loss: 0.519137, acc.: 71.09%] [G loss: 0.554988]\n",
      "epoch:11 step:10949 [D loss: 0.482227, acc.: 76.56%] [G loss: 0.835812]\n",
      "epoch:11 step:10950 [D loss: 0.484254, acc.: 74.22%] [G loss: 0.618316]\n",
      "epoch:11 step:10951 [D loss: 0.575091, acc.: 64.06%] [G loss: 0.562773]\n",
      "epoch:11 step:10952 [D loss: 0.563276, acc.: 71.09%] [G loss: 0.500093]\n",
      "epoch:11 step:10953 [D loss: 0.572540, acc.: 66.41%] [G loss: 0.418071]\n",
      "epoch:11 step:10954 [D loss: 0.449703, acc.: 81.25%] [G loss: 0.673798]\n",
      "epoch:11 step:10955 [D loss: 0.380748, acc.: 86.72%] [G loss: 0.973033]\n",
      "epoch:11 step:10956 [D loss: 0.532582, acc.: 69.53%] [G loss: 0.726261]\n",
      "epoch:11 step:10957 [D loss: 0.533640, acc.: 72.66%] [G loss: 0.774977]\n",
      "epoch:11 step:10958 [D loss: 0.588824, acc.: 66.41%] [G loss: 0.626338]\n",
      "epoch:11 step:10959 [D loss: 0.654334, acc.: 65.62%] [G loss: 0.588327]\n",
      "epoch:11 step:10960 [D loss: 0.617834, acc.: 60.94%] [G loss: 0.527459]\n",
      "epoch:11 step:10961 [D loss: 0.504512, acc.: 71.88%] [G loss: 0.555306]\n",
      "epoch:11 step:10962 [D loss: 0.644642, acc.: 63.28%] [G loss: 0.530797]\n",
      "epoch:11 step:10963 [D loss: 0.558459, acc.: 70.31%] [G loss: 0.576229]\n",
      "epoch:11 step:10964 [D loss: 0.557301, acc.: 68.75%] [G loss: 0.619933]\n",
      "epoch:11 step:10965 [D loss: 0.561283, acc.: 70.31%] [G loss: 0.598314]\n",
      "epoch:11 step:10966 [D loss: 0.548394, acc.: 72.66%] [G loss: 0.522739]\n",
      "epoch:11 step:10967 [D loss: 0.520871, acc.: 76.56%] [G loss: 0.561923]\n",
      "epoch:11 step:10968 [D loss: 0.514267, acc.: 67.97%] [G loss: 0.565329]\n",
      "epoch:11 step:10969 [D loss: 0.549642, acc.: 68.75%] [G loss: 0.565390]\n",
      "epoch:11 step:10970 [D loss: 0.538329, acc.: 71.88%] [G loss: 0.600781]\n",
      "epoch:11 step:10971 [D loss: 0.573008, acc.: 65.62%] [G loss: 0.705882]\n",
      "epoch:11 step:10972 [D loss: 0.553581, acc.: 66.41%] [G loss: 0.616599]\n",
      "epoch:11 step:10973 [D loss: 0.572488, acc.: 68.75%] [G loss: 0.533333]\n",
      "epoch:11 step:10974 [D loss: 0.585763, acc.: 68.75%] [G loss: 0.632619]\n",
      "epoch:11 step:10975 [D loss: 0.565564, acc.: 69.53%] [G loss: 0.565404]\n",
      "epoch:11 step:10976 [D loss: 0.515466, acc.: 74.22%] [G loss: 0.483812]\n",
      "epoch:11 step:10977 [D loss: 0.527671, acc.: 71.09%] [G loss: 0.825691]\n",
      "epoch:11 step:10978 [D loss: 0.609356, acc.: 63.28%] [G loss: 0.741135]\n",
      "epoch:11 step:10979 [D loss: 0.571880, acc.: 65.62%] [G loss: 0.755021]\n",
      "epoch:11 step:10980 [D loss: 0.644252, acc.: 61.72%] [G loss: 0.641826]\n",
      "epoch:11 step:10981 [D loss: 0.542897, acc.: 71.09%] [G loss: 0.556765]\n",
      "epoch:11 step:10982 [D loss: 0.590442, acc.: 68.75%] [G loss: 0.515303]\n",
      "epoch:11 step:10983 [D loss: 0.562673, acc.: 71.09%] [G loss: 0.593788]\n",
      "epoch:11 step:10984 [D loss: 0.487172, acc.: 79.69%] [G loss: 0.603574]\n",
      "epoch:11 step:10985 [D loss: 0.546266, acc.: 72.66%] [G loss: 0.517445]\n",
      "epoch:11 step:10986 [D loss: 0.505982, acc.: 76.56%] [G loss: 0.624225]\n",
      "epoch:11 step:10987 [D loss: 0.509686, acc.: 75.78%] [G loss: 0.556787]\n",
      "epoch:11 step:10988 [D loss: 0.485232, acc.: 78.12%] [G loss: 0.681694]\n",
      "epoch:11 step:10989 [D loss: 0.529838, acc.: 75.00%] [G loss: 0.518178]\n",
      "epoch:11 step:10990 [D loss: 0.519918, acc.: 73.44%] [G loss: 0.434719]\n",
      "epoch:11 step:10991 [D loss: 0.671130, acc.: 58.59%] [G loss: 0.408352]\n",
      "epoch:11 step:10992 [D loss: 0.524582, acc.: 74.22%] [G loss: 0.484752]\n",
      "epoch:11 step:10993 [D loss: 0.638189, acc.: 60.94%] [G loss: 0.392415]\n",
      "epoch:11 step:10994 [D loss: 0.565309, acc.: 68.75%] [G loss: 0.526415]\n",
      "epoch:11 step:10995 [D loss: 0.577283, acc.: 67.19%] [G loss: 0.506869]\n",
      "epoch:11 step:10996 [D loss: 0.588777, acc.: 64.84%] [G loss: 0.499077]\n",
      "epoch:11 step:10997 [D loss: 0.503721, acc.: 76.56%] [G loss: 0.613272]\n",
      "epoch:11 step:10998 [D loss: 0.531850, acc.: 75.78%] [G loss: 0.623844]\n",
      "epoch:11 step:10999 [D loss: 0.502798, acc.: 75.78%] [G loss: 0.778814]\n",
      "epoch:11 step:11000 [D loss: 0.468436, acc.: 77.34%] [G loss: 0.643090]\n",
      "##############\n",
      "[3.28940461 1.32001394 6.27080359 5.04125363 3.74849437 5.68920341\n",
      " 4.62129809 5.04304972 4.74268335 4.13336105]\n",
      "##########\n",
      "epoch:11 step:11001 [D loss: 0.552750, acc.: 73.44%] [G loss: 0.615015]\n",
      "epoch:11 step:11002 [D loss: 0.527160, acc.: 72.66%] [G loss: 0.703655]\n",
      "epoch:11 step:11003 [D loss: 0.590071, acc.: 65.62%] [G loss: 0.560529]\n",
      "epoch:11 step:11004 [D loss: 0.545405, acc.: 66.41%] [G loss: 0.490218]\n",
      "epoch:11 step:11005 [D loss: 0.527581, acc.: 72.66%] [G loss: 0.511617]\n",
      "epoch:11 step:11006 [D loss: 0.535346, acc.: 66.41%] [G loss: 0.585569]\n",
      "epoch:11 step:11007 [D loss: 0.545618, acc.: 73.44%] [G loss: 0.550596]\n",
      "epoch:11 step:11008 [D loss: 0.558691, acc.: 71.88%] [G loss: 0.463438]\n",
      "epoch:11 step:11009 [D loss: 0.547788, acc.: 65.62%] [G loss: 0.661083]\n",
      "epoch:11 step:11010 [D loss: 0.586713, acc.: 66.41%] [G loss: 0.491361]\n",
      "epoch:11 step:11011 [D loss: 0.604220, acc.: 68.75%] [G loss: 0.550508]\n",
      "epoch:11 step:11012 [D loss: 0.499449, acc.: 78.91%] [G loss: 0.545817]\n",
      "epoch:11 step:11013 [D loss: 0.572869, acc.: 67.19%] [G loss: 0.422591]\n",
      "epoch:11 step:11014 [D loss: 0.543812, acc.: 72.66%] [G loss: 0.628549]\n",
      "epoch:11 step:11015 [D loss: 0.541889, acc.: 71.88%] [G loss: 0.632851]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:11 step:11016 [D loss: 0.505053, acc.: 75.00%] [G loss: 0.613857]\n",
      "epoch:11 step:11017 [D loss: 0.568812, acc.: 72.66%] [G loss: 0.542969]\n",
      "epoch:11 step:11018 [D loss: 0.568538, acc.: 67.19%] [G loss: 0.523868]\n",
      "epoch:11 step:11019 [D loss: 0.531109, acc.: 71.09%] [G loss: 0.593815]\n",
      "epoch:11 step:11020 [D loss: 0.559605, acc.: 64.06%] [G loss: 0.629326]\n",
      "epoch:11 step:11021 [D loss: 0.560470, acc.: 68.75%] [G loss: 0.654853]\n",
      "epoch:11 step:11022 [D loss: 0.517695, acc.: 71.09%] [G loss: 0.509099]\n",
      "epoch:11 step:11023 [D loss: 0.604713, acc.: 62.50%] [G loss: 0.517572]\n",
      "epoch:11 step:11024 [D loss: 0.601771, acc.: 63.28%] [G loss: 0.532883]\n",
      "epoch:11 step:11025 [D loss: 0.600843, acc.: 67.19%] [G loss: 0.434914]\n",
      "epoch:11 step:11026 [D loss: 0.553861, acc.: 67.97%] [G loss: 0.471310]\n",
      "epoch:11 step:11027 [D loss: 0.600604, acc.: 67.19%] [G loss: 0.596879]\n",
      "epoch:11 step:11028 [D loss: 0.570860, acc.: 65.62%] [G loss: 0.501157]\n",
      "epoch:11 step:11029 [D loss: 0.563445, acc.: 71.09%] [G loss: 0.491511]\n",
      "epoch:11 step:11030 [D loss: 0.636058, acc.: 60.16%] [G loss: 0.638385]\n",
      "epoch:11 step:11031 [D loss: 0.546822, acc.: 67.97%] [G loss: 0.583317]\n",
      "epoch:11 step:11032 [D loss: 0.525093, acc.: 73.44%] [G loss: 0.705884]\n",
      "epoch:11 step:11033 [D loss: 0.506851, acc.: 73.44%] [G loss: 0.768899]\n",
      "epoch:11 step:11034 [D loss: 0.572817, acc.: 72.66%] [G loss: 0.521873]\n",
      "epoch:11 step:11035 [D loss: 0.544469, acc.: 69.53%] [G loss: 0.624731]\n",
      "epoch:11 step:11036 [D loss: 0.596886, acc.: 67.19%] [G loss: 0.556244]\n",
      "epoch:11 step:11037 [D loss: 0.532337, acc.: 71.88%] [G loss: 0.624245]\n",
      "epoch:11 step:11038 [D loss: 0.543196, acc.: 73.44%] [G loss: 0.518788]\n",
      "epoch:11 step:11039 [D loss: 0.496051, acc.: 70.31%] [G loss: 0.630629]\n",
      "epoch:11 step:11040 [D loss: 0.534594, acc.: 70.31%] [G loss: 0.617623]\n",
      "epoch:11 step:11041 [D loss: 0.561058, acc.: 68.75%] [G loss: 0.519998]\n",
      "epoch:11 step:11042 [D loss: 0.577959, acc.: 68.75%] [G loss: 0.464910]\n",
      "epoch:11 step:11043 [D loss: 0.497477, acc.: 73.44%] [G loss: 0.600404]\n",
      "epoch:11 step:11044 [D loss: 0.487845, acc.: 76.56%] [G loss: 0.702284]\n",
      "epoch:11 step:11045 [D loss: 0.588738, acc.: 67.19%] [G loss: 0.692842]\n",
      "epoch:11 step:11046 [D loss: 0.597215, acc.: 64.84%] [G loss: 0.504741]\n",
      "epoch:11 step:11047 [D loss: 0.703715, acc.: 53.12%] [G loss: 0.470209]\n",
      "epoch:11 step:11048 [D loss: 0.552721, acc.: 73.44%] [G loss: 0.533583]\n",
      "epoch:11 step:11049 [D loss: 0.550550, acc.: 71.88%] [G loss: 0.550715]\n",
      "epoch:11 step:11050 [D loss: 0.561041, acc.: 67.19%] [G loss: 0.544051]\n",
      "epoch:11 step:11051 [D loss: 0.574139, acc.: 74.22%] [G loss: 0.639580]\n",
      "epoch:11 step:11052 [D loss: 0.590923, acc.: 63.28%] [G loss: 0.482628]\n",
      "epoch:11 step:11053 [D loss: 0.496954, acc.: 71.88%] [G loss: 0.645191]\n",
      "epoch:11 step:11054 [D loss: 0.423155, acc.: 80.47%] [G loss: 0.760499]\n",
      "epoch:11 step:11055 [D loss: 0.539130, acc.: 71.88%] [G loss: 0.577569]\n",
      "epoch:11 step:11056 [D loss: 0.517327, acc.: 72.66%] [G loss: 0.620828]\n",
      "epoch:11 step:11057 [D loss: 0.511011, acc.: 71.88%] [G loss: 0.701171]\n",
      "epoch:11 step:11058 [D loss: 0.520047, acc.: 71.88%] [G loss: 0.622641]\n",
      "epoch:11 step:11059 [D loss: 0.595335, acc.: 62.50%] [G loss: 0.547900]\n",
      "epoch:11 step:11060 [D loss: 0.485925, acc.: 73.44%] [G loss: 0.645195]\n",
      "epoch:11 step:11061 [D loss: 0.556106, acc.: 67.19%] [G loss: 0.590468]\n",
      "epoch:11 step:11062 [D loss: 0.539705, acc.: 68.75%] [G loss: 0.514824]\n",
      "epoch:11 step:11063 [D loss: 0.600362, acc.: 65.62%] [G loss: 0.486577]\n",
      "epoch:11 step:11064 [D loss: 0.518141, acc.: 71.88%] [G loss: 0.469003]\n",
      "epoch:11 step:11065 [D loss: 0.605305, acc.: 66.41%] [G loss: 0.591282]\n",
      "epoch:11 step:11066 [D loss: 0.555014, acc.: 67.97%] [G loss: 0.562934]\n",
      "epoch:11 step:11067 [D loss: 0.538540, acc.: 70.31%] [G loss: 0.542009]\n",
      "epoch:11 step:11068 [D loss: 0.532077, acc.: 71.09%] [G loss: 0.579002]\n",
      "epoch:11 step:11069 [D loss: 0.623506, acc.: 58.59%] [G loss: 0.481765]\n",
      "epoch:11 step:11070 [D loss: 0.543649, acc.: 72.66%] [G loss: 0.517668]\n",
      "epoch:11 step:11071 [D loss: 0.552753, acc.: 71.09%] [G loss: 0.575826]\n",
      "epoch:11 step:11072 [D loss: 0.629158, acc.: 61.72%] [G loss: 0.494848]\n",
      "epoch:11 step:11073 [D loss: 0.636630, acc.: 63.28%] [G loss: 0.382838]\n",
      "epoch:11 step:11074 [D loss: 0.541482, acc.: 70.31%] [G loss: 0.463869]\n",
      "epoch:11 step:11075 [D loss: 0.483951, acc.: 78.12%] [G loss: 0.573240]\n",
      "epoch:11 step:11076 [D loss: 0.542820, acc.: 71.88%] [G loss: 0.766298]\n",
      "epoch:11 step:11077 [D loss: 0.527856, acc.: 76.56%] [G loss: 0.671109]\n",
      "epoch:11 step:11078 [D loss: 0.524265, acc.: 71.09%] [G loss: 0.748947]\n",
      "epoch:11 step:11079 [D loss: 0.567103, acc.: 68.75%] [G loss: 0.570727]\n",
      "epoch:11 step:11080 [D loss: 0.550529, acc.: 67.97%] [G loss: 0.506223]\n",
      "epoch:11 step:11081 [D loss: 0.612205, acc.: 67.19%] [G loss: 0.537258]\n",
      "epoch:11 step:11082 [D loss: 0.525120, acc.: 74.22%] [G loss: 0.578813]\n",
      "epoch:11 step:11083 [D loss: 0.576133, acc.: 68.75%] [G loss: 0.620716]\n",
      "epoch:11 step:11084 [D loss: 0.508650, acc.: 75.00%] [G loss: 0.523260]\n",
      "epoch:11 step:11085 [D loss: 0.534405, acc.: 71.88%] [G loss: 0.507430]\n",
      "epoch:11 step:11086 [D loss: 0.576562, acc.: 65.62%] [G loss: 0.670746]\n",
      "epoch:11 step:11087 [D loss: 0.533909, acc.: 74.22%] [G loss: 0.575201]\n",
      "epoch:11 step:11088 [D loss: 0.511523, acc.: 71.09%] [G loss: 0.736803]\n",
      "epoch:11 step:11089 [D loss: 0.500681, acc.: 73.44%] [G loss: 0.818229]\n",
      "epoch:11 step:11090 [D loss: 0.568448, acc.: 69.53%] [G loss: 0.723958]\n",
      "epoch:11 step:11091 [D loss: 0.607464, acc.: 64.84%] [G loss: 0.557345]\n",
      "epoch:11 step:11092 [D loss: 0.543338, acc.: 69.53%] [G loss: 0.439505]\n",
      "epoch:11 step:11093 [D loss: 0.565056, acc.: 66.41%] [G loss: 0.552857]\n",
      "epoch:11 step:11094 [D loss: 0.578009, acc.: 73.44%] [G loss: 0.521850]\n",
      "epoch:11 step:11095 [D loss: 0.632684, acc.: 64.84%] [G loss: 0.503260]\n",
      "epoch:11 step:11096 [D loss: 0.547587, acc.: 71.88%] [G loss: 0.612526]\n",
      "epoch:11 step:11097 [D loss: 0.524086, acc.: 71.88%] [G loss: 0.627141]\n",
      "epoch:11 step:11098 [D loss: 0.538095, acc.: 67.97%] [G loss: 0.570654]\n",
      "epoch:11 step:11099 [D loss: 0.453784, acc.: 75.00%] [G loss: 0.786553]\n",
      "epoch:11 step:11100 [D loss: 0.579693, acc.: 66.41%] [G loss: 0.595207]\n",
      "epoch:11 step:11101 [D loss: 0.668355, acc.: 59.38%] [G loss: 0.582845]\n",
      "epoch:11 step:11102 [D loss: 0.570575, acc.: 66.41%] [G loss: 0.635587]\n",
      "epoch:11 step:11103 [D loss: 0.522381, acc.: 72.66%] [G loss: 0.849840]\n",
      "epoch:11 step:11104 [D loss: 0.538309, acc.: 69.53%] [G loss: 0.579753]\n",
      "epoch:11 step:11105 [D loss: 0.516142, acc.: 69.53%] [G loss: 0.610794]\n",
      "epoch:11 step:11106 [D loss: 0.550313, acc.: 72.66%] [G loss: 0.610434]\n",
      "epoch:11 step:11107 [D loss: 0.565184, acc.: 67.97%] [G loss: 0.543578]\n",
      "epoch:11 step:11108 [D loss: 0.507084, acc.: 72.66%] [G loss: 0.801928]\n",
      "epoch:11 step:11109 [D loss: 0.510531, acc.: 70.31%] [G loss: 0.715490]\n",
      "epoch:11 step:11110 [D loss: 0.499215, acc.: 76.56%] [G loss: 0.789797]\n",
      "epoch:11 step:11111 [D loss: 0.500750, acc.: 75.00%] [G loss: 0.631618]\n",
      "epoch:11 step:11112 [D loss: 0.523272, acc.: 67.97%] [G loss: 0.463874]\n",
      "epoch:11 step:11113 [D loss: 0.575960, acc.: 67.97%] [G loss: 0.538957]\n",
      "epoch:11 step:11114 [D loss: 0.465706, acc.: 79.69%] [G loss: 0.605882]\n",
      "epoch:11 step:11115 [D loss: 0.570067, acc.: 67.97%] [G loss: 0.578278]\n",
      "epoch:11 step:11116 [D loss: 0.520245, acc.: 73.44%] [G loss: 0.607798]\n",
      "epoch:11 step:11117 [D loss: 0.551790, acc.: 68.75%] [G loss: 0.591018]\n",
      "epoch:11 step:11118 [D loss: 0.539391, acc.: 71.09%] [G loss: 0.522637]\n",
      "epoch:11 step:11119 [D loss: 0.653773, acc.: 61.72%] [G loss: 0.517597]\n",
      "epoch:11 step:11120 [D loss: 0.565436, acc.: 69.53%] [G loss: 0.482927]\n",
      "epoch:11 step:11121 [D loss: 0.516705, acc.: 71.09%] [G loss: 0.624861]\n",
      "epoch:11 step:11122 [D loss: 0.520048, acc.: 75.78%] [G loss: 0.664428]\n",
      "epoch:11 step:11123 [D loss: 0.573580, acc.: 66.41%] [G loss: 0.698922]\n",
      "epoch:11 step:11124 [D loss: 0.635399, acc.: 64.84%] [G loss: 0.737530]\n",
      "epoch:11 step:11125 [D loss: 0.594894, acc.: 64.84%] [G loss: 0.580970]\n",
      "epoch:11 step:11126 [D loss: 0.510385, acc.: 74.22%] [G loss: 0.567716]\n",
      "epoch:11 step:11127 [D loss: 0.688913, acc.: 57.81%] [G loss: 0.496724]\n",
      "epoch:11 step:11128 [D loss: 0.522601, acc.: 71.88%] [G loss: 0.554159]\n",
      "epoch:11 step:11129 [D loss: 0.520080, acc.: 74.22%] [G loss: 0.609978]\n",
      "epoch:11 step:11130 [D loss: 0.445507, acc.: 81.25%] [G loss: 0.681957]\n",
      "epoch:11 step:11131 [D loss: 0.564462, acc.: 68.75%] [G loss: 0.556923]\n",
      "epoch:11 step:11132 [D loss: 0.601246, acc.: 61.72%] [G loss: 0.600084]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:11 step:11133 [D loss: 0.521360, acc.: 77.34%] [G loss: 0.572273]\n",
      "epoch:11 step:11134 [D loss: 0.533728, acc.: 70.31%] [G loss: 0.513128]\n",
      "epoch:11 step:11135 [D loss: 0.582216, acc.: 66.41%] [G loss: 0.618156]\n",
      "epoch:11 step:11136 [D loss: 0.550144, acc.: 71.88%] [G loss: 0.545418]\n",
      "epoch:11 step:11137 [D loss: 0.593693, acc.: 67.97%] [G loss: 0.541727]\n",
      "epoch:11 step:11138 [D loss: 0.591683, acc.: 64.06%] [G loss: 0.493382]\n",
      "epoch:11 step:11139 [D loss: 0.583262, acc.: 67.97%] [G loss: 0.514135]\n",
      "epoch:11 step:11140 [D loss: 0.516907, acc.: 75.78%] [G loss: 0.585766]\n",
      "epoch:11 step:11141 [D loss: 0.541987, acc.: 64.84%] [G loss: 0.568569]\n",
      "epoch:11 step:11142 [D loss: 0.574759, acc.: 67.97%] [G loss: 0.573126]\n",
      "epoch:11 step:11143 [D loss: 0.549670, acc.: 71.88%] [G loss: 0.527347]\n",
      "epoch:11 step:11144 [D loss: 0.537332, acc.: 71.88%] [G loss: 0.513854]\n",
      "epoch:11 step:11145 [D loss: 0.549025, acc.: 74.22%] [G loss: 0.503782]\n",
      "epoch:11 step:11146 [D loss: 0.630810, acc.: 57.03%] [G loss: 0.480900]\n",
      "epoch:11 step:11147 [D loss: 0.617264, acc.: 60.94%] [G loss: 0.413488]\n",
      "epoch:11 step:11148 [D loss: 0.584178, acc.: 62.50%] [G loss: 0.444047]\n",
      "epoch:11 step:11149 [D loss: 0.523548, acc.: 74.22%] [G loss: 0.614204]\n",
      "epoch:11 step:11150 [D loss: 0.567582, acc.: 70.31%] [G loss: 0.515999]\n",
      "epoch:11 step:11151 [D loss: 0.550115, acc.: 71.09%] [G loss: 0.596365]\n",
      "epoch:11 step:11152 [D loss: 0.539730, acc.: 71.88%] [G loss: 0.575607]\n",
      "epoch:11 step:11153 [D loss: 0.599380, acc.: 68.75%] [G loss: 0.352087]\n",
      "epoch:11 step:11154 [D loss: 0.624385, acc.: 60.94%] [G loss: 0.342803]\n",
      "epoch:11 step:11155 [D loss: 0.535504, acc.: 71.88%] [G loss: 0.443684]\n",
      "epoch:11 step:11156 [D loss: 0.597453, acc.: 64.84%] [G loss: 0.424787]\n",
      "epoch:11 step:11157 [D loss: 0.540474, acc.: 71.09%] [G loss: 0.476436]\n",
      "epoch:11 step:11158 [D loss: 0.577646, acc.: 64.06%] [G loss: 0.525811]\n",
      "epoch:11 step:11159 [D loss: 0.564057, acc.: 67.19%] [G loss: 0.496820]\n",
      "epoch:11 step:11160 [D loss: 0.549036, acc.: 67.19%] [G loss: 0.496882]\n",
      "epoch:11 step:11161 [D loss: 0.547319, acc.: 71.88%] [G loss: 0.457312]\n",
      "epoch:11 step:11162 [D loss: 0.534862, acc.: 72.66%] [G loss: 0.678498]\n",
      "epoch:11 step:11163 [D loss: 0.584279, acc.: 69.53%] [G loss: 0.525445]\n",
      "epoch:11 step:11164 [D loss: 0.510775, acc.: 70.31%] [G loss: 0.511558]\n",
      "epoch:11 step:11165 [D loss: 0.618159, acc.: 62.50%] [G loss: 0.557954]\n",
      "epoch:11 step:11166 [D loss: 0.604271, acc.: 66.41%] [G loss: 0.668075]\n",
      "epoch:11 step:11167 [D loss: 0.489501, acc.: 76.56%] [G loss: 0.717257]\n",
      "epoch:11 step:11168 [D loss: 0.634643, acc.: 64.84%] [G loss: 0.529990]\n",
      "epoch:11 step:11169 [D loss: 0.566121, acc.: 67.97%] [G loss: 0.499302]\n",
      "epoch:11 step:11170 [D loss: 0.545057, acc.: 68.75%] [G loss: 0.389704]\n",
      "epoch:11 step:11171 [D loss: 0.587333, acc.: 61.72%] [G loss: 0.419877]\n",
      "epoch:11 step:11172 [D loss: 0.609655, acc.: 62.50%] [G loss: 0.492814]\n",
      "epoch:11 step:11173 [D loss: 0.556442, acc.: 66.41%] [G loss: 0.587636]\n",
      "epoch:11 step:11174 [D loss: 0.678908, acc.: 55.47%] [G loss: 0.486992]\n",
      "epoch:11 step:11175 [D loss: 0.550003, acc.: 70.31%] [G loss: 0.472908]\n",
      "epoch:11 step:11176 [D loss: 0.587947, acc.: 65.62%] [G loss: 0.444141]\n",
      "epoch:11 step:11177 [D loss: 0.505702, acc.: 74.22%] [G loss: 0.451850]\n",
      "epoch:11 step:11178 [D loss: 0.511220, acc.: 75.00%] [G loss: 0.558419]\n",
      "epoch:11 step:11179 [D loss: 0.552948, acc.: 68.75%] [G loss: 0.493292]\n",
      "epoch:11 step:11180 [D loss: 0.612702, acc.: 64.84%] [G loss: 0.551334]\n",
      "epoch:11 step:11181 [D loss: 0.615286, acc.: 67.19%] [G loss: 0.388703]\n",
      "epoch:11 step:11182 [D loss: 0.543031, acc.: 75.00%] [G loss: 0.575345]\n",
      "epoch:11 step:11183 [D loss: 0.507381, acc.: 72.66%] [G loss: 0.576718]\n",
      "epoch:11 step:11184 [D loss: 0.562780, acc.: 67.97%] [G loss: 0.547426]\n",
      "epoch:11 step:11185 [D loss: 0.547841, acc.: 71.09%] [G loss: 0.544714]\n",
      "epoch:11 step:11186 [D loss: 0.562119, acc.: 67.97%] [G loss: 0.541229]\n",
      "epoch:11 step:11187 [D loss: 0.621313, acc.: 65.62%] [G loss: 0.451372]\n",
      "epoch:11 step:11188 [D loss: 0.606546, acc.: 60.94%] [G loss: 0.428076]\n",
      "epoch:11 step:11189 [D loss: 0.551679, acc.: 65.62%] [G loss: 0.532656]\n",
      "epoch:11 step:11190 [D loss: 0.550284, acc.: 71.88%] [G loss: 0.489916]\n",
      "epoch:11 step:11191 [D loss: 0.506776, acc.: 75.78%] [G loss: 0.510223]\n",
      "epoch:11 step:11192 [D loss: 0.517519, acc.: 70.31%] [G loss: 0.587384]\n",
      "epoch:11 step:11193 [D loss: 0.518666, acc.: 71.09%] [G loss: 0.717183]\n",
      "epoch:11 step:11194 [D loss: 0.517268, acc.: 71.09%] [G loss: 0.691970]\n",
      "epoch:11 step:11195 [D loss: 0.603907, acc.: 65.62%] [G loss: 0.772340]\n",
      "epoch:11 step:11196 [D loss: 0.558901, acc.: 67.19%] [G loss: 0.551405]\n",
      "epoch:11 step:11197 [D loss: 0.483043, acc.: 80.47%] [G loss: 0.631421]\n",
      "epoch:11 step:11198 [D loss: 0.615705, acc.: 67.19%] [G loss: 0.616298]\n",
      "epoch:11 step:11199 [D loss: 0.579438, acc.: 68.75%] [G loss: 0.541004]\n",
      "epoch:11 step:11200 [D loss: 0.580910, acc.: 66.41%] [G loss: 0.412248]\n",
      "##############\n",
      "[3.20209453 1.24832807 6.08827022 4.73051423 4.00341967 5.8348355\n",
      " 4.67339452 4.81173129 4.59762309 3.85526263]\n",
      "##########\n",
      "epoch:11 step:11201 [D loss: 0.477881, acc.: 75.78%] [G loss: 0.638381]\n",
      "epoch:11 step:11202 [D loss: 0.502848, acc.: 71.88%] [G loss: 0.753937]\n",
      "epoch:11 step:11203 [D loss: 0.490845, acc.: 75.00%] [G loss: 0.789519]\n",
      "epoch:11 step:11204 [D loss: 0.532786, acc.: 71.88%] [G loss: 0.799114]\n",
      "epoch:11 step:11205 [D loss: 0.476744, acc.: 78.91%] [G loss: 0.655816]\n",
      "epoch:11 step:11206 [D loss: 0.522643, acc.: 75.00%] [G loss: 0.719033]\n",
      "epoch:11 step:11207 [D loss: 0.524688, acc.: 75.78%] [G loss: 0.977393]\n",
      "epoch:11 step:11208 [D loss: 0.592580, acc.: 62.50%] [G loss: 0.691493]\n",
      "epoch:11 step:11209 [D loss: 0.636122, acc.: 61.72%] [G loss: 0.509355]\n",
      "epoch:11 step:11210 [D loss: 0.553963, acc.: 65.62%] [G loss: 0.483889]\n",
      "epoch:11 step:11211 [D loss: 0.572310, acc.: 66.41%] [G loss: 0.601346]\n",
      "epoch:11 step:11212 [D loss: 0.583224, acc.: 68.75%] [G loss: 0.598052]\n",
      "epoch:11 step:11213 [D loss: 0.503966, acc.: 75.00%] [G loss: 0.665790]\n",
      "epoch:11 step:11214 [D loss: 0.538596, acc.: 71.09%] [G loss: 0.558475]\n",
      "epoch:11 step:11215 [D loss: 0.610772, acc.: 62.50%] [G loss: 0.582073]\n",
      "epoch:11 step:11216 [D loss: 0.520895, acc.: 72.66%] [G loss: 0.599893]\n",
      "epoch:11 step:11217 [D loss: 0.561987, acc.: 67.19%] [G loss: 0.587480]\n",
      "epoch:11 step:11218 [D loss: 0.505301, acc.: 75.00%] [G loss: 0.725112]\n",
      "epoch:11 step:11219 [D loss: 0.436897, acc.: 82.03%] [G loss: 0.783884]\n",
      "epoch:11 step:11220 [D loss: 0.521007, acc.: 73.44%] [G loss: 0.877852]\n",
      "epoch:11 step:11221 [D loss: 0.492012, acc.: 72.66%] [G loss: 0.816522]\n",
      "epoch:11 step:11222 [D loss: 0.593502, acc.: 61.72%] [G loss: 0.706998]\n",
      "epoch:11 step:11223 [D loss: 0.520378, acc.: 77.34%] [G loss: 0.684420]\n",
      "epoch:11 step:11224 [D loss: 0.649298, acc.: 62.50%] [G loss: 0.528072]\n",
      "epoch:11 step:11225 [D loss: 0.511495, acc.: 75.00%] [G loss: 0.553685]\n",
      "epoch:11 step:11226 [D loss: 0.468941, acc.: 81.25%] [G loss: 0.907027]\n",
      "epoch:11 step:11227 [D loss: 0.806590, acc.: 54.69%] [G loss: 0.658570]\n",
      "epoch:11 step:11228 [D loss: 0.520743, acc.: 72.66%] [G loss: 0.733775]\n",
      "epoch:11 step:11229 [D loss: 0.524907, acc.: 73.44%] [G loss: 0.606623]\n",
      "epoch:11 step:11230 [D loss: 0.467574, acc.: 76.56%] [G loss: 0.599399]\n",
      "epoch:11 step:11231 [D loss: 0.417703, acc.: 81.25%] [G loss: 0.759180]\n",
      "epoch:11 step:11232 [D loss: 0.448005, acc.: 76.56%] [G loss: 0.996703]\n",
      "epoch:11 step:11233 [D loss: 0.487917, acc.: 75.00%] [G loss: 1.004768]\n",
      "epoch:11 step:11234 [D loss: 0.531283, acc.: 71.09%] [G loss: 1.077283]\n",
      "epoch:11 step:11235 [D loss: 0.716715, acc.: 60.94%] [G loss: 0.889463]\n",
      "epoch:11 step:11236 [D loss: 0.450978, acc.: 79.69%] [G loss: 1.169054]\n",
      "epoch:11 step:11237 [D loss: 0.444312, acc.: 76.56%] [G loss: 1.013758]\n",
      "epoch:11 step:11238 [D loss: 0.548667, acc.: 71.09%] [G loss: 0.774461]\n",
      "epoch:11 step:11239 [D loss: 0.654747, acc.: 63.28%] [G loss: 0.571256]\n",
      "epoch:11 step:11240 [D loss: 0.556209, acc.: 70.31%] [G loss: 0.750976]\n",
      "epoch:11 step:11241 [D loss: 0.513724, acc.: 71.09%] [G loss: 0.704688]\n",
      "epoch:11 step:11242 [D loss: 0.469366, acc.: 74.22%] [G loss: 0.929986]\n",
      "epoch:11 step:11243 [D loss: 0.432883, acc.: 82.81%] [G loss: 1.189253]\n",
      "epoch:11 step:11244 [D loss: 0.414550, acc.: 82.81%] [G loss: 1.150848]\n",
      "epoch:12 step:11245 [D loss: 0.614806, acc.: 66.41%] [G loss: 0.871327]\n",
      "epoch:12 step:11246 [D loss: 0.494303, acc.: 75.00%] [G loss: 0.859998]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:12 step:11247 [D loss: 0.553772, acc.: 70.31%] [G loss: 0.765759]\n",
      "epoch:12 step:11248 [D loss: 0.601799, acc.: 66.41%] [G loss: 0.641120]\n",
      "epoch:12 step:11249 [D loss: 0.559789, acc.: 68.75%] [G loss: 0.681159]\n",
      "epoch:12 step:11250 [D loss: 0.600271, acc.: 65.62%] [G loss: 0.617325]\n",
      "epoch:12 step:11251 [D loss: 0.484057, acc.: 76.56%] [G loss: 0.728565]\n",
      "epoch:12 step:11252 [D loss: 0.562509, acc.: 74.22%] [G loss: 0.678910]\n",
      "epoch:12 step:11253 [D loss: 0.475274, acc.: 78.12%] [G loss: 0.792221]\n",
      "epoch:12 step:11254 [D loss: 0.505836, acc.: 76.56%] [G loss: 0.883638]\n",
      "epoch:12 step:11255 [D loss: 0.481376, acc.: 76.56%] [G loss: 0.636222]\n",
      "epoch:12 step:11256 [D loss: 0.608878, acc.: 69.53%] [G loss: 0.669412]\n",
      "epoch:12 step:11257 [D loss: 0.581560, acc.: 71.09%] [G loss: 0.577066]\n",
      "epoch:12 step:11258 [D loss: 0.578933, acc.: 68.75%] [G loss: 0.622135]\n",
      "epoch:12 step:11259 [D loss: 0.527853, acc.: 74.22%] [G loss: 0.617905]\n",
      "epoch:12 step:11260 [D loss: 0.530303, acc.: 72.66%] [G loss: 0.716361]\n",
      "epoch:12 step:11261 [D loss: 0.526898, acc.: 75.78%] [G loss: 0.701705]\n",
      "epoch:12 step:11262 [D loss: 0.568194, acc.: 69.53%] [G loss: 0.505320]\n",
      "epoch:12 step:11263 [D loss: 0.574041, acc.: 65.62%] [G loss: 0.495863]\n",
      "epoch:12 step:11264 [D loss: 0.754475, acc.: 49.22%] [G loss: 0.531251]\n",
      "epoch:12 step:11265 [D loss: 0.570531, acc.: 70.31%] [G loss: 0.479275]\n",
      "epoch:12 step:11266 [D loss: 0.460901, acc.: 81.25%] [G loss: 0.753162]\n",
      "epoch:12 step:11267 [D loss: 0.590008, acc.: 67.97%] [G loss: 0.477160]\n",
      "epoch:12 step:11268 [D loss: 0.512022, acc.: 71.09%] [G loss: 0.576740]\n",
      "epoch:12 step:11269 [D loss: 0.482640, acc.: 74.22%] [G loss: 0.694635]\n",
      "epoch:12 step:11270 [D loss: 0.615823, acc.: 64.06%] [G loss: 0.557403]\n",
      "epoch:12 step:11271 [D loss: 0.503177, acc.: 75.00%] [G loss: 0.690188]\n",
      "epoch:12 step:11272 [D loss: 0.547667, acc.: 73.44%] [G loss: 0.649734]\n",
      "epoch:12 step:11273 [D loss: 0.516186, acc.: 69.53%] [G loss: 0.623263]\n",
      "epoch:12 step:11274 [D loss: 0.545106, acc.: 67.19%] [G loss: 0.643331]\n",
      "epoch:12 step:11275 [D loss: 0.622967, acc.: 60.16%] [G loss: 0.509509]\n",
      "epoch:12 step:11276 [D loss: 0.600700, acc.: 67.97%] [G loss: 0.620399]\n",
      "epoch:12 step:11277 [D loss: 0.517021, acc.: 75.78%] [G loss: 0.568764]\n",
      "epoch:12 step:11278 [D loss: 0.514953, acc.: 70.31%] [G loss: 0.664362]\n",
      "epoch:12 step:11279 [D loss: 0.547200, acc.: 72.66%] [G loss: 0.469685]\n",
      "epoch:12 step:11280 [D loss: 0.551419, acc.: 70.31%] [G loss: 0.653970]\n",
      "epoch:12 step:11281 [D loss: 0.572870, acc.: 70.31%] [G loss: 0.734728]\n",
      "epoch:12 step:11282 [D loss: 0.593674, acc.: 67.97%] [G loss: 0.589546]\n",
      "epoch:12 step:11283 [D loss: 0.530529, acc.: 73.44%] [G loss: 0.661334]\n",
      "epoch:12 step:11284 [D loss: 0.418750, acc.: 85.16%] [G loss: 0.799453]\n",
      "epoch:12 step:11285 [D loss: 0.593404, acc.: 64.84%] [G loss: 0.620925]\n",
      "epoch:12 step:11286 [D loss: 0.526302, acc.: 68.75%] [G loss: 0.743931]\n",
      "epoch:12 step:11287 [D loss: 0.505629, acc.: 75.00%] [G loss: 0.664138]\n",
      "epoch:12 step:11288 [D loss: 0.602232, acc.: 64.84%] [G loss: 0.636507]\n",
      "epoch:12 step:11289 [D loss: 0.489992, acc.: 76.56%] [G loss: 0.689311]\n",
      "epoch:12 step:11290 [D loss: 0.463736, acc.: 77.34%] [G loss: 0.615011]\n",
      "epoch:12 step:11291 [D loss: 0.551968, acc.: 70.31%] [G loss: 0.773103]\n",
      "epoch:12 step:11292 [D loss: 0.587816, acc.: 68.75%] [G loss: 0.581972]\n",
      "epoch:12 step:11293 [D loss: 0.513706, acc.: 76.56%] [G loss: 0.606289]\n",
      "epoch:12 step:11294 [D loss: 0.580134, acc.: 71.09%] [G loss: 0.484000]\n",
      "epoch:12 step:11295 [D loss: 0.597129, acc.: 65.62%] [G loss: 0.446175]\n",
      "epoch:12 step:11296 [D loss: 0.624928, acc.: 63.28%] [G loss: 0.548542]\n",
      "epoch:12 step:11297 [D loss: 0.478705, acc.: 75.00%] [G loss: 0.641533]\n",
      "epoch:12 step:11298 [D loss: 0.488897, acc.: 75.00%] [G loss: 0.661203]\n",
      "epoch:12 step:11299 [D loss: 0.573490, acc.: 70.31%] [G loss: 0.699078]\n",
      "epoch:12 step:11300 [D loss: 0.518021, acc.: 72.66%] [G loss: 0.727539]\n",
      "epoch:12 step:11301 [D loss: 0.543788, acc.: 73.44%] [G loss: 0.680098]\n",
      "epoch:12 step:11302 [D loss: 0.555655, acc.: 66.41%] [G loss: 0.673570]\n",
      "epoch:12 step:11303 [D loss: 0.492824, acc.: 77.34%] [G loss: 0.618322]\n",
      "epoch:12 step:11304 [D loss: 0.529638, acc.: 75.78%] [G loss: 0.729062]\n",
      "epoch:12 step:11305 [D loss: 0.584973, acc.: 71.09%] [G loss: 0.583378]\n",
      "epoch:12 step:11306 [D loss: 0.587533, acc.: 69.53%] [G loss: 0.544672]\n",
      "epoch:12 step:11307 [D loss: 0.567262, acc.: 71.09%] [G loss: 0.531116]\n",
      "epoch:12 step:11308 [D loss: 0.564695, acc.: 71.09%] [G loss: 0.532938]\n",
      "epoch:12 step:11309 [D loss: 0.543806, acc.: 75.00%] [G loss: 0.592608]\n",
      "epoch:12 step:11310 [D loss: 0.530564, acc.: 72.66%] [G loss: 0.581063]\n",
      "epoch:12 step:11311 [D loss: 0.539771, acc.: 72.66%] [G loss: 0.489315]\n",
      "epoch:12 step:11312 [D loss: 0.556420, acc.: 72.66%] [G loss: 0.572115]\n",
      "epoch:12 step:11313 [D loss: 0.484420, acc.: 74.22%] [G loss: 0.556135]\n",
      "epoch:12 step:11314 [D loss: 0.496223, acc.: 81.25%] [G loss: 0.635277]\n",
      "epoch:12 step:11315 [D loss: 0.551397, acc.: 70.31%] [G loss: 0.602534]\n",
      "epoch:12 step:11316 [D loss: 0.550001, acc.: 64.06%] [G loss: 0.567469]\n",
      "epoch:12 step:11317 [D loss: 0.578036, acc.: 70.31%] [G loss: 0.586963]\n",
      "epoch:12 step:11318 [D loss: 0.471680, acc.: 75.00%] [G loss: 0.687106]\n",
      "epoch:12 step:11319 [D loss: 0.511397, acc.: 76.56%] [G loss: 0.610165]\n",
      "epoch:12 step:11320 [D loss: 0.575989, acc.: 67.19%] [G loss: 0.688492]\n",
      "epoch:12 step:11321 [D loss: 0.418044, acc.: 84.38%] [G loss: 0.856458]\n",
      "epoch:12 step:11322 [D loss: 0.630435, acc.: 65.62%] [G loss: 0.593960]\n",
      "epoch:12 step:11323 [D loss: 0.539901, acc.: 71.09%] [G loss: 0.552301]\n",
      "epoch:12 step:11324 [D loss: 0.523924, acc.: 71.09%] [G loss: 0.583840]\n",
      "epoch:12 step:11325 [D loss: 0.538549, acc.: 70.31%] [G loss: 0.580955]\n",
      "epoch:12 step:11326 [D loss: 0.509995, acc.: 72.66%] [G loss: 0.558811]\n",
      "epoch:12 step:11327 [D loss: 0.529709, acc.: 73.44%] [G loss: 0.618033]\n",
      "epoch:12 step:11328 [D loss: 0.533543, acc.: 69.53%] [G loss: 0.565104]\n",
      "epoch:12 step:11329 [D loss: 0.575709, acc.: 64.06%] [G loss: 0.623793]\n",
      "epoch:12 step:11330 [D loss: 0.543251, acc.: 70.31%] [G loss: 0.451905]\n",
      "epoch:12 step:11331 [D loss: 0.537517, acc.: 71.88%] [G loss: 0.522979]\n",
      "epoch:12 step:11332 [D loss: 0.514135, acc.: 74.22%] [G loss: 0.570022]\n",
      "epoch:12 step:11333 [D loss: 0.568183, acc.: 66.41%] [G loss: 0.554260]\n",
      "epoch:12 step:11334 [D loss: 0.555205, acc.: 72.66%] [G loss: 0.678284]\n",
      "epoch:12 step:11335 [D loss: 0.577194, acc.: 71.09%] [G loss: 0.488003]\n",
      "epoch:12 step:11336 [D loss: 0.434988, acc.: 81.25%] [G loss: 0.626013]\n",
      "epoch:12 step:11337 [D loss: 0.513538, acc.: 77.34%] [G loss: 0.706646]\n",
      "epoch:12 step:11338 [D loss: 0.519914, acc.: 73.44%] [G loss: 0.697877]\n",
      "epoch:12 step:11339 [D loss: 0.479810, acc.: 74.22%] [G loss: 0.706429]\n",
      "epoch:12 step:11340 [D loss: 0.515608, acc.: 74.22%] [G loss: 0.685086]\n",
      "epoch:12 step:11341 [D loss: 0.527148, acc.: 72.66%] [G loss: 0.702294]\n",
      "epoch:12 step:11342 [D loss: 0.553797, acc.: 67.19%] [G loss: 0.687081]\n",
      "epoch:12 step:11343 [D loss: 0.555622, acc.: 69.53%] [G loss: 0.571398]\n",
      "epoch:12 step:11344 [D loss: 0.476179, acc.: 79.69%] [G loss: 0.702749]\n",
      "epoch:12 step:11345 [D loss: 0.475965, acc.: 74.22%] [G loss: 0.803921]\n",
      "epoch:12 step:11346 [D loss: 0.618389, acc.: 64.84%] [G loss: 0.645571]\n",
      "epoch:12 step:11347 [D loss: 0.517125, acc.: 68.75%] [G loss: 0.618081]\n",
      "epoch:12 step:11348 [D loss: 0.526610, acc.: 71.88%] [G loss: 0.651807]\n",
      "epoch:12 step:11349 [D loss: 0.591228, acc.: 63.28%] [G loss: 0.507371]\n",
      "epoch:12 step:11350 [D loss: 0.546765, acc.: 71.09%] [G loss: 0.638361]\n",
      "epoch:12 step:11351 [D loss: 0.604032, acc.: 67.19%] [G loss: 0.665208]\n",
      "epoch:12 step:11352 [D loss: 0.616804, acc.: 67.19%] [G loss: 0.468316]\n",
      "epoch:12 step:11353 [D loss: 0.615819, acc.: 64.06%] [G loss: 0.471954]\n",
      "epoch:12 step:11354 [D loss: 0.518757, acc.: 73.44%] [G loss: 0.506298]\n",
      "epoch:12 step:11355 [D loss: 0.536395, acc.: 70.31%] [G loss: 0.560287]\n",
      "epoch:12 step:11356 [D loss: 0.517896, acc.: 71.88%] [G loss: 0.539611]\n",
      "epoch:12 step:11357 [D loss: 0.585310, acc.: 65.62%] [G loss: 0.630196]\n",
      "epoch:12 step:11358 [D loss: 0.529239, acc.: 74.22%] [G loss: 0.598417]\n",
      "epoch:12 step:11359 [D loss: 0.551641, acc.: 71.88%] [G loss: 0.694136]\n",
      "epoch:12 step:11360 [D loss: 0.525895, acc.: 75.78%] [G loss: 0.765506]\n",
      "epoch:12 step:11361 [D loss: 0.544715, acc.: 70.31%] [G loss: 0.744344]\n",
      "epoch:12 step:11362 [D loss: 0.525585, acc.: 72.66%] [G loss: 0.733152]\n",
      "epoch:12 step:11363 [D loss: 0.486991, acc.: 81.25%] [G loss: 0.747746]\n",
      "epoch:12 step:11364 [D loss: 0.571033, acc.: 75.00%] [G loss: 0.783182]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:12 step:11365 [D loss: 0.531177, acc.: 71.88%] [G loss: 0.727380]\n",
      "epoch:12 step:11366 [D loss: 0.489585, acc.: 77.34%] [G loss: 0.760461]\n",
      "epoch:12 step:11367 [D loss: 0.489777, acc.: 77.34%] [G loss: 0.735550]\n",
      "epoch:12 step:11368 [D loss: 0.563450, acc.: 68.75%] [G loss: 0.595896]\n",
      "epoch:12 step:11369 [D loss: 0.615014, acc.: 64.06%] [G loss: 0.554066]\n",
      "epoch:12 step:11370 [D loss: 0.519070, acc.: 70.31%] [G loss: 0.455979]\n",
      "epoch:12 step:11371 [D loss: 0.465345, acc.: 79.69%] [G loss: 0.676846]\n",
      "epoch:12 step:11372 [D loss: 0.478630, acc.: 79.69%] [G loss: 0.572473]\n",
      "epoch:12 step:11373 [D loss: 0.544099, acc.: 71.88%] [G loss: 0.502447]\n",
      "epoch:12 step:11374 [D loss: 0.480836, acc.: 77.34%] [G loss: 0.527756]\n",
      "epoch:12 step:11375 [D loss: 0.462250, acc.: 73.44%] [G loss: 0.596490]\n",
      "epoch:12 step:11376 [D loss: 0.543383, acc.: 71.88%] [G loss: 0.517844]\n",
      "epoch:12 step:11377 [D loss: 0.528391, acc.: 70.31%] [G loss: 0.542910]\n",
      "epoch:12 step:11378 [D loss: 0.526281, acc.: 69.53%] [G loss: 0.543506]\n",
      "epoch:12 step:11379 [D loss: 0.510257, acc.: 79.69%] [G loss: 0.704779]\n",
      "epoch:12 step:11380 [D loss: 0.576293, acc.: 71.09%] [G loss: 0.742104]\n",
      "epoch:12 step:11381 [D loss: 0.550397, acc.: 74.22%] [G loss: 0.510689]\n",
      "epoch:12 step:11382 [D loss: 0.560057, acc.: 72.66%] [G loss: 0.542536]\n",
      "epoch:12 step:11383 [D loss: 0.536280, acc.: 71.09%] [G loss: 0.551878]\n",
      "epoch:12 step:11384 [D loss: 0.613373, acc.: 60.94%] [G loss: 0.446188]\n",
      "epoch:12 step:11385 [D loss: 0.506169, acc.: 74.22%] [G loss: 0.707693]\n",
      "epoch:12 step:11386 [D loss: 0.522674, acc.: 71.88%] [G loss: 0.561281]\n",
      "epoch:12 step:11387 [D loss: 0.570641, acc.: 62.50%] [G loss: 0.596620]\n",
      "epoch:12 step:11388 [D loss: 0.548245, acc.: 71.88%] [G loss: 0.561865]\n",
      "epoch:12 step:11389 [D loss: 0.533924, acc.: 71.09%] [G loss: 0.680928]\n",
      "epoch:12 step:11390 [D loss: 0.459359, acc.: 76.56%] [G loss: 0.619732]\n",
      "epoch:12 step:11391 [D loss: 0.630247, acc.: 62.50%] [G loss: 0.466140]\n",
      "epoch:12 step:11392 [D loss: 0.615832, acc.: 62.50%] [G loss: 0.499193]\n",
      "epoch:12 step:11393 [D loss: 0.486549, acc.: 75.78%] [G loss: 0.615837]\n",
      "epoch:12 step:11394 [D loss: 0.581012, acc.: 72.66%] [G loss: 0.476346]\n",
      "epoch:12 step:11395 [D loss: 0.542996, acc.: 73.44%] [G loss: 0.607901]\n",
      "epoch:12 step:11396 [D loss: 0.471099, acc.: 80.47%] [G loss: 0.716678]\n",
      "epoch:12 step:11397 [D loss: 0.640355, acc.: 58.59%] [G loss: 0.457642]\n",
      "epoch:12 step:11398 [D loss: 0.565454, acc.: 69.53%] [G loss: 0.536530]\n",
      "epoch:12 step:11399 [D loss: 0.488468, acc.: 72.66%] [G loss: 0.675547]\n",
      "epoch:12 step:11400 [D loss: 0.540972, acc.: 68.75%] [G loss: 0.705747]\n",
      "##############\n",
      "[3.00188392 0.82973991 6.30429505 4.65024661 3.69018238 5.65693301\n",
      " 4.38740283 4.70971308 4.35645074 3.94315855]\n",
      "##########\n",
      "epoch:12 step:11401 [D loss: 0.565989, acc.: 73.44%] [G loss: 0.609607]\n",
      "epoch:12 step:11402 [D loss: 0.601806, acc.: 70.31%] [G loss: 0.486940]\n",
      "epoch:12 step:11403 [D loss: 0.518298, acc.: 74.22%] [G loss: 0.506900]\n",
      "epoch:12 step:11404 [D loss: 0.584738, acc.: 67.97%] [G loss: 0.576229]\n",
      "epoch:12 step:11405 [D loss: 0.570602, acc.: 72.66%] [G loss: 0.676233]\n",
      "epoch:12 step:11406 [D loss: 0.466994, acc.: 76.56%] [G loss: 0.789526]\n",
      "epoch:12 step:11407 [D loss: 0.583405, acc.: 64.06%] [G loss: 0.790540]\n",
      "epoch:12 step:11408 [D loss: 0.543606, acc.: 69.53%] [G loss: 0.813776]\n",
      "epoch:12 step:11409 [D loss: 0.527145, acc.: 74.22%] [G loss: 0.500598]\n",
      "epoch:12 step:11410 [D loss: 0.526936, acc.: 69.53%] [G loss: 0.607822]\n",
      "epoch:12 step:11411 [D loss: 0.590382, acc.: 66.41%] [G loss: 0.442421]\n",
      "epoch:12 step:11412 [D loss: 0.563930, acc.: 68.75%] [G loss: 0.529616]\n",
      "epoch:12 step:11413 [D loss: 0.613574, acc.: 67.19%] [G loss: 0.448713]\n",
      "epoch:12 step:11414 [D loss: 0.558277, acc.: 66.41%] [G loss: 0.509159]\n",
      "epoch:12 step:11415 [D loss: 0.551204, acc.: 67.19%] [G loss: 0.414767]\n",
      "epoch:12 step:11416 [D loss: 0.564246, acc.: 73.44%] [G loss: 0.556290]\n",
      "epoch:12 step:11417 [D loss: 0.489019, acc.: 75.00%] [G loss: 0.731352]\n",
      "epoch:12 step:11418 [D loss: 0.607881, acc.: 64.06%] [G loss: 0.621282]\n",
      "epoch:12 step:11419 [D loss: 0.643275, acc.: 58.59%] [G loss: 0.484836]\n",
      "epoch:12 step:11420 [D loss: 0.522866, acc.: 75.00%] [G loss: 0.510419]\n",
      "epoch:12 step:11421 [D loss: 0.492418, acc.: 75.78%] [G loss: 0.482547]\n",
      "epoch:12 step:11422 [D loss: 0.600119, acc.: 57.03%] [G loss: 0.472431]\n",
      "epoch:12 step:11423 [D loss: 0.494902, acc.: 75.78%] [G loss: 0.636048]\n",
      "epoch:12 step:11424 [D loss: 0.683923, acc.: 54.69%] [G loss: 0.455020]\n",
      "epoch:12 step:11425 [D loss: 0.578907, acc.: 66.41%] [G loss: 0.465247]\n",
      "epoch:12 step:11426 [D loss: 0.601216, acc.: 70.31%] [G loss: 0.482648]\n",
      "epoch:12 step:11427 [D loss: 0.579211, acc.: 67.97%] [G loss: 0.534063]\n",
      "epoch:12 step:11428 [D loss: 0.550912, acc.: 68.75%] [G loss: 0.510432]\n",
      "epoch:12 step:11429 [D loss: 0.582481, acc.: 61.72%] [G loss: 0.517453]\n",
      "epoch:12 step:11430 [D loss: 0.567094, acc.: 71.09%] [G loss: 0.490921]\n",
      "epoch:12 step:11431 [D loss: 0.645601, acc.: 59.38%] [G loss: 0.543719]\n",
      "epoch:12 step:11432 [D loss: 0.587053, acc.: 63.28%] [G loss: 0.490120]\n",
      "epoch:12 step:11433 [D loss: 0.574982, acc.: 68.75%] [G loss: 0.526490]\n",
      "epoch:12 step:11434 [D loss: 0.465018, acc.: 78.12%] [G loss: 0.582360]\n",
      "epoch:12 step:11435 [D loss: 0.546856, acc.: 71.88%] [G loss: 0.584684]\n",
      "epoch:12 step:11436 [D loss: 0.493429, acc.: 78.91%] [G loss: 0.543358]\n",
      "epoch:12 step:11437 [D loss: 0.578925, acc.: 64.06%] [G loss: 0.605290]\n",
      "epoch:12 step:11438 [D loss: 0.535537, acc.: 74.22%] [G loss: 0.757558]\n",
      "epoch:12 step:11439 [D loss: 0.587282, acc.: 68.75%] [G loss: 0.658541]\n",
      "epoch:12 step:11440 [D loss: 0.579418, acc.: 67.19%] [G loss: 0.705614]\n",
      "epoch:12 step:11441 [D loss: 0.600802, acc.: 63.28%] [G loss: 0.517446]\n",
      "epoch:12 step:11442 [D loss: 0.441030, acc.: 81.25%] [G loss: 0.629401]\n",
      "epoch:12 step:11443 [D loss: 0.590862, acc.: 65.62%] [G loss: 0.700133]\n",
      "epoch:12 step:11444 [D loss: 0.618763, acc.: 66.41%] [G loss: 0.595238]\n",
      "epoch:12 step:11445 [D loss: 0.589960, acc.: 67.97%] [G loss: 0.534674]\n",
      "epoch:12 step:11446 [D loss: 0.542682, acc.: 71.88%] [G loss: 0.680351]\n",
      "epoch:12 step:11447 [D loss: 0.636842, acc.: 63.28%] [G loss: 0.561204]\n",
      "epoch:12 step:11448 [D loss: 0.562250, acc.: 68.75%] [G loss: 0.554673]\n",
      "epoch:12 step:11449 [D loss: 0.547127, acc.: 70.31%] [G loss: 0.622457]\n",
      "epoch:12 step:11450 [D loss: 0.548551, acc.: 69.53%] [G loss: 0.546824]\n",
      "epoch:12 step:11451 [D loss: 0.423089, acc.: 82.03%] [G loss: 0.764636]\n",
      "epoch:12 step:11452 [D loss: 0.458269, acc.: 75.78%] [G loss: 0.753460]\n",
      "epoch:12 step:11453 [D loss: 0.516056, acc.: 75.78%] [G loss: 0.755725]\n",
      "epoch:12 step:11454 [D loss: 0.624013, acc.: 66.41%] [G loss: 0.518101]\n",
      "epoch:12 step:11455 [D loss: 0.561105, acc.: 63.28%] [G loss: 0.498353]\n",
      "epoch:12 step:11456 [D loss: 0.599700, acc.: 68.75%] [G loss: 0.381161]\n",
      "epoch:12 step:11457 [D loss: 0.578834, acc.: 67.97%] [G loss: 0.557661]\n",
      "epoch:12 step:11458 [D loss: 0.659485, acc.: 64.06%] [G loss: 0.529991]\n",
      "epoch:12 step:11459 [D loss: 0.578758, acc.: 70.31%] [G loss: 0.530560]\n",
      "epoch:12 step:11460 [D loss: 0.538048, acc.: 72.66%] [G loss: 0.561566]\n",
      "epoch:12 step:11461 [D loss: 0.554468, acc.: 68.75%] [G loss: 0.582350]\n",
      "epoch:12 step:11462 [D loss: 0.535129, acc.: 76.56%] [G loss: 0.678155]\n",
      "epoch:12 step:11463 [D loss: 0.504545, acc.: 79.69%] [G loss: 0.693865]\n",
      "epoch:12 step:11464 [D loss: 0.651538, acc.: 67.19%] [G loss: 0.564077]\n",
      "epoch:12 step:11465 [D loss: 0.550364, acc.: 68.75%] [G loss: 0.532157]\n",
      "epoch:12 step:11466 [D loss: 0.495648, acc.: 73.44%] [G loss: 0.681243]\n",
      "epoch:12 step:11467 [D loss: 0.496527, acc.: 73.44%] [G loss: 0.807172]\n",
      "epoch:12 step:11468 [D loss: 0.589935, acc.: 70.31%] [G loss: 0.626984]\n",
      "epoch:12 step:11469 [D loss: 0.541798, acc.: 69.53%] [G loss: 0.695505]\n",
      "epoch:12 step:11470 [D loss: 0.606808, acc.: 60.16%] [G loss: 0.457488]\n",
      "epoch:12 step:11471 [D loss: 0.589154, acc.: 65.62%] [G loss: 0.555927]\n",
      "epoch:12 step:11472 [D loss: 0.565091, acc.: 68.75%] [G loss: 0.563662]\n",
      "epoch:12 step:11473 [D loss: 0.558228, acc.: 69.53%] [G loss: 0.602030]\n",
      "epoch:12 step:11474 [D loss: 0.557608, acc.: 67.19%] [G loss: 0.614088]\n",
      "epoch:12 step:11475 [D loss: 0.449254, acc.: 79.69%] [G loss: 0.760649]\n",
      "epoch:12 step:11476 [D loss: 0.464111, acc.: 77.34%] [G loss: 0.802932]\n",
      "epoch:12 step:11477 [D loss: 0.578438, acc.: 64.06%] [G loss: 0.781509]\n",
      "epoch:12 step:11478 [D loss: 0.545217, acc.: 75.00%] [G loss: 0.671573]\n",
      "epoch:12 step:11479 [D loss: 0.557155, acc.: 66.41%] [G loss: 0.764899]\n",
      "epoch:12 step:11480 [D loss: 0.525639, acc.: 71.88%] [G loss: 0.607983]\n",
      "epoch:12 step:11481 [D loss: 0.548301, acc.: 68.75%] [G loss: 0.581445]\n",
      "epoch:12 step:11482 [D loss: 0.577043, acc.: 65.62%] [G loss: 0.606760]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:12 step:11483 [D loss: 0.509576, acc.: 72.66%] [G loss: 0.599545]\n",
      "epoch:12 step:11484 [D loss: 0.534663, acc.: 71.09%] [G loss: 0.629567]\n",
      "epoch:12 step:11485 [D loss: 0.535654, acc.: 73.44%] [G loss: 0.575997]\n",
      "epoch:12 step:11486 [D loss: 0.508452, acc.: 75.00%] [G loss: 0.608438]\n",
      "epoch:12 step:11487 [D loss: 0.559260, acc.: 68.75%] [G loss: 0.621544]\n",
      "epoch:12 step:11488 [D loss: 0.462530, acc.: 76.56%] [G loss: 0.650043]\n",
      "epoch:12 step:11489 [D loss: 0.533034, acc.: 69.53%] [G loss: 0.598103]\n",
      "epoch:12 step:11490 [D loss: 0.528666, acc.: 74.22%] [G loss: 0.615871]\n",
      "epoch:12 step:11491 [D loss: 0.551830, acc.: 67.19%] [G loss: 0.796525]\n",
      "epoch:12 step:11492 [D loss: 0.561334, acc.: 71.88%] [G loss: 0.625588]\n",
      "epoch:12 step:11493 [D loss: 0.582301, acc.: 69.53%] [G loss: 0.731382]\n",
      "epoch:12 step:11494 [D loss: 0.605437, acc.: 59.38%] [G loss: 0.547927]\n",
      "epoch:12 step:11495 [D loss: 0.616806, acc.: 67.19%] [G loss: 0.580372]\n",
      "epoch:12 step:11496 [D loss: 0.580759, acc.: 71.88%] [G loss: 0.667156]\n",
      "epoch:12 step:11497 [D loss: 0.590932, acc.: 63.28%] [G loss: 0.698797]\n",
      "epoch:12 step:11498 [D loss: 0.494597, acc.: 75.78%] [G loss: 0.456392]\n",
      "epoch:12 step:11499 [D loss: 0.519967, acc.: 72.66%] [G loss: 0.668471]\n",
      "epoch:12 step:11500 [D loss: 0.538478, acc.: 71.88%] [G loss: 0.712132]\n",
      "epoch:12 step:11501 [D loss: 0.586717, acc.: 60.94%] [G loss: 0.516589]\n",
      "epoch:12 step:11502 [D loss: 0.526939, acc.: 71.09%] [G loss: 0.536836]\n",
      "epoch:12 step:11503 [D loss: 0.546759, acc.: 63.28%] [G loss: 0.664759]\n",
      "epoch:12 step:11504 [D loss: 0.588096, acc.: 64.06%] [G loss: 0.484644]\n",
      "epoch:12 step:11505 [D loss: 0.529193, acc.: 72.66%] [G loss: 0.618138]\n",
      "epoch:12 step:11506 [D loss: 0.536198, acc.: 71.88%] [G loss: 0.471334]\n",
      "epoch:12 step:11507 [D loss: 0.592863, acc.: 71.88%] [G loss: 0.516119]\n",
      "epoch:12 step:11508 [D loss: 0.574651, acc.: 67.97%] [G loss: 0.560834]\n",
      "epoch:12 step:11509 [D loss: 0.551389, acc.: 67.97%] [G loss: 0.636428]\n",
      "epoch:12 step:11510 [D loss: 0.554796, acc.: 67.97%] [G loss: 0.617255]\n",
      "epoch:12 step:11511 [D loss: 0.581205, acc.: 67.97%] [G loss: 0.568118]\n",
      "epoch:12 step:11512 [D loss: 0.525523, acc.: 71.88%] [G loss: 0.703809]\n",
      "epoch:12 step:11513 [D loss: 0.537385, acc.: 73.44%] [G loss: 0.563483]\n",
      "epoch:12 step:11514 [D loss: 0.521629, acc.: 71.88%] [G loss: 0.623029]\n",
      "epoch:12 step:11515 [D loss: 0.507307, acc.: 75.00%] [G loss: 0.594277]\n",
      "epoch:12 step:11516 [D loss: 0.560287, acc.: 69.53%] [G loss: 0.670669]\n",
      "epoch:12 step:11517 [D loss: 0.591318, acc.: 63.28%] [G loss: 0.626245]\n",
      "epoch:12 step:11518 [D loss: 0.503704, acc.: 75.00%] [G loss: 0.658088]\n",
      "epoch:12 step:11519 [D loss: 0.572500, acc.: 71.88%] [G loss: 0.453965]\n",
      "epoch:12 step:11520 [D loss: 0.503552, acc.: 76.56%] [G loss: 0.557804]\n",
      "epoch:12 step:11521 [D loss: 0.651911, acc.: 60.94%] [G loss: 0.410351]\n",
      "epoch:12 step:11522 [D loss: 0.633512, acc.: 63.28%] [G loss: 0.489930]\n",
      "epoch:12 step:11523 [D loss: 0.564638, acc.: 72.66%] [G loss: 0.473658]\n",
      "epoch:12 step:11524 [D loss: 0.593693, acc.: 66.41%] [G loss: 0.498533]\n",
      "epoch:12 step:11525 [D loss: 0.556289, acc.: 68.75%] [G loss: 0.456266]\n",
      "epoch:12 step:11526 [D loss: 0.576239, acc.: 66.41%] [G loss: 0.470718]\n",
      "epoch:12 step:11527 [D loss: 0.505969, acc.: 76.56%] [G loss: 0.667304]\n",
      "epoch:12 step:11528 [D loss: 0.519579, acc.: 71.09%] [G loss: 0.592197]\n",
      "epoch:12 step:11529 [D loss: 0.558877, acc.: 73.44%] [G loss: 0.595948]\n",
      "epoch:12 step:11530 [D loss: 0.517797, acc.: 75.78%] [G loss: 0.703725]\n",
      "epoch:12 step:11531 [D loss: 0.625540, acc.: 61.72%] [G loss: 0.464191]\n",
      "epoch:12 step:11532 [D loss: 0.634848, acc.: 61.72%] [G loss: 0.502485]\n",
      "epoch:12 step:11533 [D loss: 0.578342, acc.: 61.72%] [G loss: 0.616039]\n",
      "epoch:12 step:11534 [D loss: 0.556348, acc.: 68.75%] [G loss: 0.577705]\n",
      "epoch:12 step:11535 [D loss: 0.596584, acc.: 67.97%] [G loss: 0.479945]\n",
      "epoch:12 step:11536 [D loss: 0.530645, acc.: 69.53%] [G loss: 0.598416]\n",
      "epoch:12 step:11537 [D loss: 0.619120, acc.: 64.84%] [G loss: 0.593141]\n",
      "epoch:12 step:11538 [D loss: 0.586506, acc.: 64.06%] [G loss: 0.480562]\n",
      "epoch:12 step:11539 [D loss: 0.544226, acc.: 66.41%] [G loss: 0.529339]\n",
      "epoch:12 step:11540 [D loss: 0.475316, acc.: 74.22%] [G loss: 0.475099]\n",
      "epoch:12 step:11541 [D loss: 0.519760, acc.: 71.88%] [G loss: 0.540389]\n",
      "epoch:12 step:11542 [D loss: 0.478604, acc.: 80.47%] [G loss: 0.480341]\n",
      "epoch:12 step:11543 [D loss: 0.591070, acc.: 67.97%] [G loss: 0.628141]\n",
      "epoch:12 step:11544 [D loss: 0.552223, acc.: 73.44%] [G loss: 0.649191]\n",
      "epoch:12 step:11545 [D loss: 0.603885, acc.: 71.09%] [G loss: 0.607006]\n",
      "epoch:12 step:11546 [D loss: 0.601584, acc.: 67.97%] [G loss: 0.506231]\n",
      "epoch:12 step:11547 [D loss: 0.565008, acc.: 67.97%] [G loss: 0.586513]\n",
      "epoch:12 step:11548 [D loss: 0.508421, acc.: 75.78%] [G loss: 0.595825]\n",
      "epoch:12 step:11549 [D loss: 0.538564, acc.: 71.09%] [G loss: 0.578743]\n",
      "epoch:12 step:11550 [D loss: 0.522738, acc.: 75.78%] [G loss: 0.600893]\n",
      "epoch:12 step:11551 [D loss: 0.444483, acc.: 77.34%] [G loss: 0.627297]\n",
      "epoch:12 step:11552 [D loss: 0.542846, acc.: 75.00%] [G loss: 0.647345]\n",
      "epoch:12 step:11553 [D loss: 0.497224, acc.: 72.66%] [G loss: 0.703408]\n",
      "epoch:12 step:11554 [D loss: 0.534297, acc.: 70.31%] [G loss: 0.725428]\n",
      "epoch:12 step:11555 [D loss: 0.526295, acc.: 72.66%] [G loss: 0.666681]\n",
      "epoch:12 step:11556 [D loss: 0.425139, acc.: 88.28%] [G loss: 0.758154]\n",
      "epoch:12 step:11557 [D loss: 0.555348, acc.: 68.75%] [G loss: 0.859649]\n",
      "epoch:12 step:11558 [D loss: 0.477793, acc.: 76.56%] [G loss: 0.809142]\n",
      "epoch:12 step:11559 [D loss: 0.477885, acc.: 76.56%] [G loss: 0.785585]\n",
      "epoch:12 step:11560 [D loss: 0.731275, acc.: 58.59%] [G loss: 0.655028]\n",
      "epoch:12 step:11561 [D loss: 0.622175, acc.: 63.28%] [G loss: 0.512045]\n",
      "epoch:12 step:11562 [D loss: 0.540267, acc.: 69.53%] [G loss: 0.609918]\n",
      "epoch:12 step:11563 [D loss: 0.560954, acc.: 70.31%] [G loss: 0.529631]\n",
      "epoch:12 step:11564 [D loss: 0.556791, acc.: 67.19%] [G loss: 0.495442]\n",
      "epoch:12 step:11565 [D loss: 0.480854, acc.: 76.56%] [G loss: 0.698144]\n",
      "epoch:12 step:11566 [D loss: 0.551506, acc.: 70.31%] [G loss: 0.791743]\n",
      "epoch:12 step:11567 [D loss: 0.602776, acc.: 64.84%] [G loss: 0.655420]\n",
      "epoch:12 step:11568 [D loss: 0.608613, acc.: 66.41%] [G loss: 0.459761]\n",
      "epoch:12 step:11569 [D loss: 0.519024, acc.: 74.22%] [G loss: 0.524406]\n",
      "epoch:12 step:11570 [D loss: 0.470402, acc.: 77.34%] [G loss: 0.737968]\n",
      "epoch:12 step:11571 [D loss: 0.556629, acc.: 75.78%] [G loss: 0.635393]\n",
      "epoch:12 step:11572 [D loss: 0.462342, acc.: 78.91%] [G loss: 0.769354]\n",
      "epoch:12 step:11573 [D loss: 0.527189, acc.: 72.66%] [G loss: 0.612423]\n",
      "epoch:12 step:11574 [D loss: 0.629314, acc.: 60.16%] [G loss: 0.521950]\n",
      "epoch:12 step:11575 [D loss: 0.539448, acc.: 71.88%] [G loss: 0.489417]\n",
      "epoch:12 step:11576 [D loss: 0.522819, acc.: 71.88%] [G loss: 0.474397]\n",
      "epoch:12 step:11577 [D loss: 0.472929, acc.: 78.12%] [G loss: 0.502931]\n",
      "epoch:12 step:11578 [D loss: 0.513786, acc.: 72.66%] [G loss: 0.552179]\n",
      "epoch:12 step:11579 [D loss: 0.500967, acc.: 75.78%] [G loss: 0.641278]\n",
      "epoch:12 step:11580 [D loss: 0.513339, acc.: 75.78%] [G loss: 0.701940]\n",
      "epoch:12 step:11581 [D loss: 0.534695, acc.: 71.88%] [G loss: 0.586426]\n",
      "epoch:12 step:11582 [D loss: 0.533072, acc.: 71.88%] [G loss: 0.672058]\n",
      "epoch:12 step:11583 [D loss: 0.568723, acc.: 71.09%] [G loss: 0.519552]\n",
      "epoch:12 step:11584 [D loss: 0.464480, acc.: 78.12%] [G loss: 0.657564]\n",
      "epoch:12 step:11585 [D loss: 0.598032, acc.: 67.97%] [G loss: 0.612934]\n",
      "epoch:12 step:11586 [D loss: 0.640441, acc.: 64.84%] [G loss: 0.530105]\n",
      "epoch:12 step:11587 [D loss: 0.460960, acc.: 82.03%] [G loss: 0.549615]\n",
      "epoch:12 step:11588 [D loss: 0.441452, acc.: 82.81%] [G loss: 0.703355]\n",
      "epoch:12 step:11589 [D loss: 0.581172, acc.: 67.19%] [G loss: 0.831250]\n",
      "epoch:12 step:11590 [D loss: 0.512798, acc.: 71.88%] [G loss: 0.979964]\n",
      "epoch:12 step:11591 [D loss: 0.438109, acc.: 83.59%] [G loss: 1.040238]\n",
      "epoch:12 step:11592 [D loss: 0.652744, acc.: 65.62%] [G loss: 0.632241]\n",
      "epoch:12 step:11593 [D loss: 0.744238, acc.: 53.12%] [G loss: 0.439340]\n",
      "epoch:12 step:11594 [D loss: 0.461147, acc.: 79.69%] [G loss: 0.646423]\n",
      "epoch:12 step:11595 [D loss: 0.554648, acc.: 73.44%] [G loss: 0.743187]\n",
      "epoch:12 step:11596 [D loss: 0.620874, acc.: 66.41%] [G loss: 0.802752]\n",
      "epoch:12 step:11597 [D loss: 0.602491, acc.: 62.50%] [G loss: 0.731291]\n",
      "epoch:12 step:11598 [D loss: 0.411312, acc.: 78.91%] [G loss: 0.980319]\n",
      "epoch:12 step:11599 [D loss: 0.611269, acc.: 70.31%] [G loss: 0.708558]\n",
      "epoch:12 step:11600 [D loss: 0.594475, acc.: 67.19%] [G loss: 0.619334]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##############\n",
      "[3.10838169 1.19640367 6.22595128 5.01885004 3.69163365 5.69974076\n",
      " 4.51788912 4.89597383 4.61437346 4.08535171]\n",
      "##########\n",
      "epoch:12 step:11601 [D loss: 0.525550, acc.: 70.31%] [G loss: 0.682295]\n",
      "epoch:12 step:11602 [D loss: 0.453734, acc.: 78.12%] [G loss: 0.827535]\n",
      "epoch:12 step:11603 [D loss: 0.497070, acc.: 74.22%] [G loss: 0.730082]\n",
      "epoch:12 step:11604 [D loss: 0.528227, acc.: 73.44%] [G loss: 0.707977]\n",
      "epoch:12 step:11605 [D loss: 0.514978, acc.: 73.44%] [G loss: 0.804159]\n",
      "epoch:12 step:11606 [D loss: 0.583153, acc.: 64.06%] [G loss: 0.604599]\n",
      "epoch:12 step:11607 [D loss: 0.580375, acc.: 67.19%] [G loss: 0.566826]\n",
      "epoch:12 step:11608 [D loss: 0.539601, acc.: 72.66%] [G loss: 0.621984]\n",
      "epoch:12 step:11609 [D loss: 0.605174, acc.: 61.72%] [G loss: 0.658653]\n",
      "epoch:12 step:11610 [D loss: 0.516832, acc.: 68.75%] [G loss: 0.628825]\n",
      "epoch:12 step:11611 [D loss: 0.620770, acc.: 65.62%] [G loss: 0.557765]\n",
      "epoch:12 step:11612 [D loss: 0.533677, acc.: 71.09%] [G loss: 0.628706]\n",
      "epoch:12 step:11613 [D loss: 0.523269, acc.: 72.66%] [G loss: 0.589894]\n",
      "epoch:12 step:11614 [D loss: 0.511319, acc.: 77.34%] [G loss: 0.573538]\n",
      "epoch:12 step:11615 [D loss: 0.489771, acc.: 75.00%] [G loss: 0.689344]\n",
      "epoch:12 step:11616 [D loss: 0.530793, acc.: 75.00%] [G loss: 0.747152]\n",
      "epoch:12 step:11617 [D loss: 0.572311, acc.: 67.19%] [G loss: 0.617807]\n",
      "epoch:12 step:11618 [D loss: 0.489078, acc.: 74.22%] [G loss: 0.695620]\n",
      "epoch:12 step:11619 [D loss: 0.601196, acc.: 64.84%] [G loss: 0.748038]\n",
      "epoch:12 step:11620 [D loss: 0.711545, acc.: 59.38%] [G loss: 0.474608]\n",
      "epoch:12 step:11621 [D loss: 0.595376, acc.: 67.19%] [G loss: 0.546644]\n",
      "epoch:12 step:11622 [D loss: 0.585721, acc.: 63.28%] [G loss: 0.545650]\n",
      "epoch:12 step:11623 [D loss: 0.555367, acc.: 69.53%] [G loss: 0.604955]\n",
      "epoch:12 step:11624 [D loss: 0.579810, acc.: 68.75%] [G loss: 0.466889]\n",
      "epoch:12 step:11625 [D loss: 0.475246, acc.: 78.91%] [G loss: 0.529303]\n",
      "epoch:12 step:11626 [D loss: 0.534158, acc.: 71.88%] [G loss: 0.568845]\n",
      "epoch:12 step:11627 [D loss: 0.548362, acc.: 70.31%] [G loss: 0.509843]\n",
      "epoch:12 step:11628 [D loss: 0.579165, acc.: 67.19%] [G loss: 0.565285]\n",
      "epoch:12 step:11629 [D loss: 0.469513, acc.: 78.91%] [G loss: 0.541446]\n",
      "epoch:12 step:11630 [D loss: 0.590556, acc.: 67.97%] [G loss: 0.509256]\n",
      "epoch:12 step:11631 [D loss: 0.498951, acc.: 70.31%] [G loss: 0.734666]\n",
      "epoch:12 step:11632 [D loss: 0.577031, acc.: 71.09%] [G loss: 0.689136]\n",
      "epoch:12 step:11633 [D loss: 0.606844, acc.: 64.84%] [G loss: 0.668775]\n",
      "epoch:12 step:11634 [D loss: 0.602146, acc.: 66.41%] [G loss: 0.645890]\n",
      "epoch:12 step:11635 [D loss: 0.572770, acc.: 68.75%] [G loss: 0.525030]\n",
      "epoch:12 step:11636 [D loss: 0.532401, acc.: 71.88%] [G loss: 0.513189]\n",
      "epoch:12 step:11637 [D loss: 0.583421, acc.: 71.09%] [G loss: 0.533582]\n",
      "epoch:12 step:11638 [D loss: 0.531574, acc.: 71.88%] [G loss: 0.494015]\n",
      "epoch:12 step:11639 [D loss: 0.537218, acc.: 69.53%] [G loss: 0.592738]\n",
      "epoch:12 step:11640 [D loss: 0.488876, acc.: 78.91%] [G loss: 0.566996]\n",
      "epoch:12 step:11641 [D loss: 0.545335, acc.: 68.75%] [G loss: 0.574420]\n",
      "epoch:12 step:11642 [D loss: 0.440433, acc.: 82.81%] [G loss: 0.829569]\n",
      "epoch:12 step:11643 [D loss: 0.543158, acc.: 70.31%] [G loss: 0.802039]\n",
      "epoch:12 step:11644 [D loss: 0.625338, acc.: 58.59%] [G loss: 0.527002]\n",
      "epoch:12 step:11645 [D loss: 0.635951, acc.: 60.16%] [G loss: 0.505123]\n",
      "epoch:12 step:11646 [D loss: 0.503644, acc.: 75.00%] [G loss: 0.635675]\n",
      "epoch:12 step:11647 [D loss: 0.483128, acc.: 71.09%] [G loss: 0.651133]\n",
      "epoch:12 step:11648 [D loss: 0.597579, acc.: 63.28%] [G loss: 0.615226]\n",
      "epoch:12 step:11649 [D loss: 0.566582, acc.: 67.19%] [G loss: 0.642957]\n",
      "epoch:12 step:11650 [D loss: 0.573672, acc.: 69.53%] [G loss: 0.625332]\n",
      "epoch:12 step:11651 [D loss: 0.626033, acc.: 64.84%] [G loss: 0.641329]\n",
      "epoch:12 step:11652 [D loss: 0.583868, acc.: 66.41%] [G loss: 0.587819]\n",
      "epoch:12 step:11653 [D loss: 0.566302, acc.: 65.62%] [G loss: 0.648277]\n",
      "epoch:12 step:11654 [D loss: 0.577578, acc.: 69.53%] [G loss: 0.582569]\n",
      "epoch:12 step:11655 [D loss: 0.588347, acc.: 65.62%] [G loss: 0.525391]\n",
      "epoch:12 step:11656 [D loss: 0.565943, acc.: 67.19%] [G loss: 0.500174]\n",
      "epoch:12 step:11657 [D loss: 0.546812, acc.: 67.97%] [G loss: 0.594399]\n",
      "epoch:12 step:11658 [D loss: 0.525813, acc.: 69.53%] [G loss: 0.806066]\n",
      "epoch:12 step:11659 [D loss: 0.575594, acc.: 66.41%] [G loss: 0.627592]\n",
      "epoch:12 step:11660 [D loss: 0.516016, acc.: 75.00%] [G loss: 0.799857]\n",
      "epoch:12 step:11661 [D loss: 0.582129, acc.: 65.62%] [G loss: 0.675291]\n",
      "epoch:12 step:11662 [D loss: 0.616615, acc.: 65.62%] [G loss: 0.630245]\n",
      "epoch:12 step:11663 [D loss: 0.565214, acc.: 65.62%] [G loss: 0.626042]\n",
      "epoch:12 step:11664 [D loss: 0.595277, acc.: 64.84%] [G loss: 0.614780]\n",
      "epoch:12 step:11665 [D loss: 0.590137, acc.: 66.41%] [G loss: 0.541656]\n",
      "epoch:12 step:11666 [D loss: 0.620979, acc.: 68.75%] [G loss: 0.494590]\n",
      "epoch:12 step:11667 [D loss: 0.557725, acc.: 66.41%] [G loss: 0.457725]\n",
      "epoch:12 step:11668 [D loss: 0.548277, acc.: 67.97%] [G loss: 0.646942]\n",
      "epoch:12 step:11669 [D loss: 0.558013, acc.: 73.44%] [G loss: 0.553593]\n",
      "epoch:12 step:11670 [D loss: 0.503529, acc.: 72.66%] [G loss: 0.789475]\n",
      "epoch:12 step:11671 [D loss: 0.440209, acc.: 84.38%] [G loss: 0.708233]\n",
      "epoch:12 step:11672 [D loss: 0.540271, acc.: 72.66%] [G loss: 0.803000]\n",
      "epoch:12 step:11673 [D loss: 0.501727, acc.: 75.78%] [G loss: 0.693968]\n",
      "epoch:12 step:11674 [D loss: 0.570370, acc.: 71.09%] [G loss: 0.694093]\n",
      "epoch:12 step:11675 [D loss: 0.522414, acc.: 70.31%] [G loss: 0.696214]\n",
      "epoch:12 step:11676 [D loss: 0.567685, acc.: 71.09%] [G loss: 0.526315]\n",
      "epoch:12 step:11677 [D loss: 0.568199, acc.: 68.75%] [G loss: 0.589458]\n",
      "epoch:12 step:11678 [D loss: 0.544808, acc.: 74.22%] [G loss: 0.551800]\n",
      "epoch:12 step:11679 [D loss: 0.548345, acc.: 72.66%] [G loss: 0.570996]\n",
      "epoch:12 step:11680 [D loss: 0.484847, acc.: 78.12%] [G loss: 0.596317]\n",
      "epoch:12 step:11681 [D loss: 0.666754, acc.: 60.94%] [G loss: 0.624410]\n",
      "epoch:12 step:11682 [D loss: 0.603631, acc.: 60.94%] [G loss: 0.682876]\n",
      "epoch:12 step:11683 [D loss: 0.534092, acc.: 71.88%] [G loss: 0.822518]\n",
      "epoch:12 step:11684 [D loss: 0.563221, acc.: 62.50%] [G loss: 0.778396]\n",
      "epoch:12 step:11685 [D loss: 0.544363, acc.: 69.53%] [G loss: 0.622464]\n",
      "epoch:12 step:11686 [D loss: 0.585255, acc.: 64.84%] [G loss: 0.377528]\n",
      "epoch:12 step:11687 [D loss: 0.592321, acc.: 68.75%] [G loss: 0.487070]\n",
      "epoch:12 step:11688 [D loss: 0.556362, acc.: 71.09%] [G loss: 0.613405]\n",
      "epoch:12 step:11689 [D loss: 0.545140, acc.: 68.75%] [G loss: 0.717841]\n",
      "epoch:12 step:11690 [D loss: 0.517517, acc.: 73.44%] [G loss: 0.699442]\n",
      "epoch:12 step:11691 [D loss: 0.592079, acc.: 67.97%] [G loss: 0.592212]\n",
      "epoch:12 step:11692 [D loss: 0.552286, acc.: 70.31%] [G loss: 0.677787]\n",
      "epoch:12 step:11693 [D loss: 0.509641, acc.: 75.78%] [G loss: 0.727950]\n",
      "epoch:12 step:11694 [D loss: 0.523714, acc.: 71.88%] [G loss: 0.613842]\n",
      "epoch:12 step:11695 [D loss: 0.439021, acc.: 78.12%] [G loss: 0.712537]\n",
      "epoch:12 step:11696 [D loss: 0.483159, acc.: 75.78%] [G loss: 0.808068]\n",
      "epoch:12 step:11697 [D loss: 0.596620, acc.: 70.31%] [G loss: 0.656853]\n",
      "epoch:12 step:11698 [D loss: 0.566333, acc.: 72.66%] [G loss: 0.478995]\n",
      "epoch:12 step:11699 [D loss: 0.603866, acc.: 64.06%] [G loss: 0.579858]\n",
      "epoch:12 step:11700 [D loss: 0.688108, acc.: 60.16%] [G loss: 0.608057]\n",
      "epoch:12 step:11701 [D loss: 0.474095, acc.: 77.34%] [G loss: 0.708558]\n",
      "epoch:12 step:11702 [D loss: 0.685348, acc.: 60.94%] [G loss: 0.601961]\n",
      "epoch:12 step:11703 [D loss: 0.544743, acc.: 73.44%] [G loss: 0.675390]\n",
      "epoch:12 step:11704 [D loss: 0.504535, acc.: 69.53%] [G loss: 0.678088]\n",
      "epoch:12 step:11705 [D loss: 0.509451, acc.: 72.66%] [G loss: 0.595544]\n",
      "epoch:12 step:11706 [D loss: 0.565768, acc.: 66.41%] [G loss: 0.576140]\n",
      "epoch:12 step:11707 [D loss: 0.589453, acc.: 70.31%] [G loss: 0.558448]\n",
      "epoch:12 step:11708 [D loss: 0.514093, acc.: 75.00%] [G loss: 0.606365]\n",
      "epoch:12 step:11709 [D loss: 0.613635, acc.: 57.81%] [G loss: 0.484167]\n",
      "epoch:12 step:11710 [D loss: 0.581795, acc.: 64.06%] [G loss: 0.463164]\n",
      "epoch:12 step:11711 [D loss: 0.520791, acc.: 71.09%] [G loss: 0.544558]\n",
      "epoch:12 step:11712 [D loss: 0.649532, acc.: 63.28%] [G loss: 0.545578]\n",
      "epoch:12 step:11713 [D loss: 0.500358, acc.: 78.91%] [G loss: 0.621585]\n",
      "epoch:12 step:11714 [D loss: 0.552359, acc.: 75.78%] [G loss: 0.601918]\n",
      "epoch:12 step:11715 [D loss: 0.448326, acc.: 78.12%] [G loss: 0.704463]\n",
      "epoch:12 step:11716 [D loss: 0.440078, acc.: 81.25%] [G loss: 0.774336]\n",
      "epoch:12 step:11717 [D loss: 0.690711, acc.: 61.72%] [G loss: 0.600932]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:12 step:11718 [D loss: 0.651115, acc.: 60.16%] [G loss: 0.491669]\n",
      "epoch:12 step:11719 [D loss: 0.521226, acc.: 75.00%] [G loss: 0.731606]\n",
      "epoch:12 step:11720 [D loss: 0.583462, acc.: 73.44%] [G loss: 0.683098]\n",
      "epoch:12 step:11721 [D loss: 0.659234, acc.: 64.06%] [G loss: 0.531911]\n",
      "epoch:12 step:11722 [D loss: 0.621634, acc.: 65.62%] [G loss: 0.399244]\n",
      "epoch:12 step:11723 [D loss: 0.538642, acc.: 71.88%] [G loss: 0.449861]\n",
      "epoch:12 step:11724 [D loss: 0.590437, acc.: 67.19%] [G loss: 0.481125]\n",
      "epoch:12 step:11725 [D loss: 0.506206, acc.: 78.91%] [G loss: 0.589469]\n",
      "epoch:12 step:11726 [D loss: 0.614912, acc.: 67.19%] [G loss: 0.658430]\n",
      "epoch:12 step:11727 [D loss: 0.596308, acc.: 69.53%] [G loss: 0.548116]\n",
      "epoch:12 step:11728 [D loss: 0.564755, acc.: 66.41%] [G loss: 0.591778]\n",
      "epoch:12 step:11729 [D loss: 0.542072, acc.: 74.22%] [G loss: 0.633725]\n",
      "epoch:12 step:11730 [D loss: 0.598948, acc.: 67.19%] [G loss: 0.548725]\n",
      "epoch:12 step:11731 [D loss: 0.554064, acc.: 68.75%] [G loss: 0.572565]\n",
      "epoch:12 step:11732 [D loss: 0.497820, acc.: 72.66%] [G loss: 0.434311]\n",
      "epoch:12 step:11733 [D loss: 0.563817, acc.: 70.31%] [G loss: 0.440455]\n",
      "epoch:12 step:11734 [D loss: 0.588019, acc.: 69.53%] [G loss: 0.424896]\n",
      "epoch:12 step:11735 [D loss: 0.538321, acc.: 74.22%] [G loss: 0.642743]\n",
      "epoch:12 step:11736 [D loss: 0.575782, acc.: 71.09%] [G loss: 0.498358]\n",
      "epoch:12 step:11737 [D loss: 0.537023, acc.: 71.09%] [G loss: 0.402478]\n",
      "epoch:12 step:11738 [D loss: 0.574634, acc.: 67.97%] [G loss: 0.509080]\n",
      "epoch:12 step:11739 [D loss: 0.508168, acc.: 78.91%] [G loss: 0.470856]\n",
      "epoch:12 step:11740 [D loss: 0.601890, acc.: 67.19%] [G loss: 0.527145]\n",
      "epoch:12 step:11741 [D loss: 0.528941, acc.: 74.22%] [G loss: 0.585045]\n",
      "epoch:12 step:11742 [D loss: 0.557564, acc.: 67.97%] [G loss: 0.620944]\n",
      "epoch:12 step:11743 [D loss: 0.569433, acc.: 64.84%] [G loss: 0.626195]\n",
      "epoch:12 step:11744 [D loss: 0.591382, acc.: 68.75%] [G loss: 0.533737]\n",
      "epoch:12 step:11745 [D loss: 0.642791, acc.: 67.19%] [G loss: 0.447856]\n",
      "epoch:12 step:11746 [D loss: 0.595422, acc.: 67.97%] [G loss: 0.557884]\n",
      "epoch:12 step:11747 [D loss: 0.499979, acc.: 75.78%] [G loss: 0.649929]\n",
      "epoch:12 step:11748 [D loss: 0.522861, acc.: 75.00%] [G loss: 0.718261]\n",
      "epoch:12 step:11749 [D loss: 0.559799, acc.: 72.66%] [G loss: 0.637250]\n",
      "epoch:12 step:11750 [D loss: 0.572117, acc.: 71.88%] [G loss: 0.638548]\n",
      "epoch:12 step:11751 [D loss: 0.524487, acc.: 69.53%] [G loss: 0.806076]\n",
      "epoch:12 step:11752 [D loss: 0.453775, acc.: 75.78%] [G loss: 0.752660]\n",
      "epoch:12 step:11753 [D loss: 0.532762, acc.: 75.00%] [G loss: 0.826254]\n",
      "epoch:12 step:11754 [D loss: 0.615283, acc.: 65.62%] [G loss: 0.553805]\n",
      "epoch:12 step:11755 [D loss: 0.646987, acc.: 61.72%] [G loss: 0.474664]\n",
      "epoch:12 step:11756 [D loss: 0.633981, acc.: 60.94%] [G loss: 0.592865]\n",
      "epoch:12 step:11757 [D loss: 0.510637, acc.: 71.88%] [G loss: 0.499441]\n",
      "epoch:12 step:11758 [D loss: 0.490897, acc.: 74.22%] [G loss: 0.542658]\n",
      "epoch:12 step:11759 [D loss: 0.544011, acc.: 68.75%] [G loss: 0.584824]\n",
      "epoch:12 step:11760 [D loss: 0.484763, acc.: 75.78%] [G loss: 0.686949]\n",
      "epoch:12 step:11761 [D loss: 0.531007, acc.: 74.22%] [G loss: 0.580443]\n",
      "epoch:12 step:11762 [D loss: 0.525994, acc.: 73.44%] [G loss: 0.618465]\n",
      "epoch:12 step:11763 [D loss: 0.467525, acc.: 75.78%] [G loss: 0.681695]\n",
      "epoch:12 step:11764 [D loss: 0.564468, acc.: 69.53%] [G loss: 0.573279]\n",
      "epoch:12 step:11765 [D loss: 0.530852, acc.: 75.00%] [G loss: 0.618217]\n",
      "epoch:12 step:11766 [D loss: 0.569477, acc.: 67.97%] [G loss: 0.674491]\n",
      "epoch:12 step:11767 [D loss: 0.490368, acc.: 77.34%] [G loss: 0.693900]\n",
      "epoch:12 step:11768 [D loss: 0.553181, acc.: 73.44%] [G loss: 0.627474]\n",
      "epoch:12 step:11769 [D loss: 0.604827, acc.: 64.06%] [G loss: 0.543325]\n",
      "epoch:12 step:11770 [D loss: 0.524374, acc.: 74.22%] [G loss: 0.640289]\n",
      "epoch:12 step:11771 [D loss: 0.556387, acc.: 69.53%] [G loss: 0.550102]\n",
      "epoch:12 step:11772 [D loss: 0.647085, acc.: 61.72%] [G loss: 0.489853]\n",
      "epoch:12 step:11773 [D loss: 0.570478, acc.: 69.53%] [G loss: 0.567225]\n",
      "epoch:12 step:11774 [D loss: 0.541216, acc.: 71.88%] [G loss: 0.588384]\n",
      "epoch:12 step:11775 [D loss: 0.564380, acc.: 67.97%] [G loss: 0.722941]\n",
      "epoch:12 step:11776 [D loss: 0.607554, acc.: 64.06%] [G loss: 0.663308]\n",
      "epoch:12 step:11777 [D loss: 0.533892, acc.: 71.88%] [G loss: 0.571940]\n",
      "epoch:12 step:11778 [D loss: 0.473799, acc.: 73.44%] [G loss: 0.656786]\n",
      "epoch:12 step:11779 [D loss: 0.588476, acc.: 64.06%] [G loss: 0.546582]\n",
      "epoch:12 step:11780 [D loss: 0.498224, acc.: 73.44%] [G loss: 0.569461]\n",
      "epoch:12 step:11781 [D loss: 0.594765, acc.: 67.97%] [G loss: 0.535411]\n",
      "epoch:12 step:11782 [D loss: 0.530791, acc.: 75.00%] [G loss: 0.477913]\n",
      "epoch:12 step:11783 [D loss: 0.559711, acc.: 70.31%] [G loss: 0.472514]\n",
      "epoch:12 step:11784 [D loss: 0.564209, acc.: 67.97%] [G loss: 0.541362]\n",
      "epoch:12 step:11785 [D loss: 0.552331, acc.: 67.97%] [G loss: 0.510641]\n",
      "epoch:12 step:11786 [D loss: 0.615477, acc.: 60.16%] [G loss: 0.465433]\n",
      "epoch:12 step:11787 [D loss: 0.585719, acc.: 67.97%] [G loss: 0.602227]\n",
      "epoch:12 step:11788 [D loss: 0.552447, acc.: 69.53%] [G loss: 0.618037]\n",
      "epoch:12 step:11789 [D loss: 0.573049, acc.: 70.31%] [G loss: 0.553224]\n",
      "epoch:12 step:11790 [D loss: 0.538218, acc.: 67.19%] [G loss: 0.618164]\n",
      "epoch:12 step:11791 [D loss: 0.555070, acc.: 71.88%] [G loss: 0.626532]\n",
      "epoch:12 step:11792 [D loss: 0.506895, acc.: 75.00%] [G loss: 0.606976]\n",
      "epoch:12 step:11793 [D loss: 0.523466, acc.: 79.69%] [G loss: 0.615683]\n",
      "epoch:12 step:11794 [D loss: 0.538716, acc.: 75.00%] [G loss: 0.539668]\n",
      "epoch:12 step:11795 [D loss: 0.516691, acc.: 75.78%] [G loss: 0.515494]\n",
      "epoch:12 step:11796 [D loss: 0.491382, acc.: 77.34%] [G loss: 0.596216]\n",
      "epoch:12 step:11797 [D loss: 0.563025, acc.: 67.19%] [G loss: 0.574150]\n",
      "epoch:12 step:11798 [D loss: 0.482194, acc.: 74.22%] [G loss: 0.735594]\n",
      "epoch:12 step:11799 [D loss: 0.485740, acc.: 76.56%] [G loss: 0.674798]\n",
      "epoch:12 step:11800 [D loss: 0.548679, acc.: 67.97%] [G loss: 0.610720]\n",
      "##############\n",
      "[3.14383485 1.24891065 6.29456146 4.76454714 3.72841762 5.83103146\n",
      " 4.56546696 4.66873613 4.4917711  3.90871104]\n",
      "##########\n",
      "epoch:12 step:11801 [D loss: 0.494490, acc.: 75.00%] [G loss: 0.639010]\n",
      "epoch:12 step:11802 [D loss: 0.501988, acc.: 73.44%] [G loss: 0.592588]\n",
      "epoch:12 step:11803 [D loss: 0.652891, acc.: 59.38%] [G loss: 0.585882]\n",
      "epoch:12 step:11804 [D loss: 0.529565, acc.: 71.88%] [G loss: 0.586413]\n",
      "epoch:12 step:11805 [D loss: 0.592165, acc.: 64.06%] [G loss: 0.503389]\n",
      "epoch:12 step:11806 [D loss: 0.556047, acc.: 69.53%] [G loss: 0.623829]\n",
      "epoch:12 step:11807 [D loss: 0.565105, acc.: 65.62%] [G loss: 0.510455]\n",
      "epoch:12 step:11808 [D loss: 0.548789, acc.: 72.66%] [G loss: 0.563087]\n",
      "epoch:12 step:11809 [D loss: 0.585587, acc.: 70.31%] [G loss: 0.719630]\n",
      "epoch:12 step:11810 [D loss: 0.655600, acc.: 62.50%] [G loss: 0.548792]\n",
      "epoch:12 step:11811 [D loss: 0.521959, acc.: 71.88%] [G loss: 0.481840]\n",
      "epoch:12 step:11812 [D loss: 0.559047, acc.: 70.31%] [G loss: 0.598547]\n",
      "epoch:12 step:11813 [D loss: 0.513819, acc.: 70.31%] [G loss: 0.704794]\n",
      "epoch:12 step:11814 [D loss: 0.534357, acc.: 71.88%] [G loss: 0.560585]\n",
      "epoch:12 step:11815 [D loss: 0.548568, acc.: 71.09%] [G loss: 0.622647]\n",
      "epoch:12 step:11816 [D loss: 0.565118, acc.: 68.75%] [G loss: 0.641440]\n",
      "epoch:12 step:11817 [D loss: 0.545580, acc.: 68.75%] [G loss: 0.525986]\n",
      "epoch:12 step:11818 [D loss: 0.481203, acc.: 71.88%] [G loss: 0.688529]\n",
      "epoch:12 step:11819 [D loss: 0.491970, acc.: 74.22%] [G loss: 0.830405]\n",
      "epoch:12 step:11820 [D loss: 0.641445, acc.: 65.62%] [G loss: 0.731297]\n",
      "epoch:12 step:11821 [D loss: 0.566334, acc.: 70.31%] [G loss: 0.740767]\n",
      "epoch:12 step:11822 [D loss: 0.521586, acc.: 72.66%] [G loss: 0.555723]\n",
      "epoch:12 step:11823 [D loss: 0.539397, acc.: 67.19%] [G loss: 0.470092]\n",
      "epoch:12 step:11824 [D loss: 0.644900, acc.: 58.59%] [G loss: 0.531242]\n",
      "epoch:12 step:11825 [D loss: 0.522798, acc.: 75.00%] [G loss: 0.640930]\n",
      "epoch:12 step:11826 [D loss: 0.452071, acc.: 80.47%] [G loss: 0.742570]\n",
      "epoch:12 step:11827 [D loss: 0.542063, acc.: 73.44%] [G loss: 0.672320]\n",
      "epoch:12 step:11828 [D loss: 0.614787, acc.: 62.50%] [G loss: 0.594438]\n",
      "epoch:12 step:11829 [D loss: 0.478922, acc.: 74.22%] [G loss: 0.655925]\n",
      "epoch:12 step:11830 [D loss: 0.574231, acc.: 67.19%] [G loss: 0.608347]\n",
      "epoch:12 step:11831 [D loss: 0.585250, acc.: 67.19%] [G loss: 0.467829]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:12 step:11832 [D loss: 0.573298, acc.: 63.28%] [G loss: 0.501082]\n",
      "epoch:12 step:11833 [D loss: 0.514295, acc.: 69.53%] [G loss: 0.695980]\n",
      "epoch:12 step:11834 [D loss: 0.559215, acc.: 65.62%] [G loss: 0.665593]\n",
      "epoch:12 step:11835 [D loss: 0.578169, acc.: 69.53%] [G loss: 0.529354]\n",
      "epoch:12 step:11836 [D loss: 0.531577, acc.: 71.88%] [G loss: 0.482358]\n",
      "epoch:12 step:11837 [D loss: 0.558992, acc.: 70.31%] [G loss: 0.520169]\n",
      "epoch:12 step:11838 [D loss: 0.569975, acc.: 67.19%] [G loss: 0.553810]\n",
      "epoch:12 step:11839 [D loss: 0.561314, acc.: 71.88%] [G loss: 0.554988]\n",
      "epoch:12 step:11840 [D loss: 0.581939, acc.: 69.53%] [G loss: 0.657933]\n",
      "epoch:12 step:11841 [D loss: 0.564387, acc.: 68.75%] [G loss: 0.477872]\n",
      "epoch:12 step:11842 [D loss: 0.535606, acc.: 72.66%] [G loss: 0.594248]\n",
      "epoch:12 step:11843 [D loss: 0.547689, acc.: 71.09%] [G loss: 0.551832]\n",
      "epoch:12 step:11844 [D loss: 0.560453, acc.: 71.88%] [G loss: 0.544205]\n",
      "epoch:12 step:11845 [D loss: 0.509141, acc.: 73.44%] [G loss: 0.567211]\n",
      "epoch:12 step:11846 [D loss: 0.474292, acc.: 77.34%] [G loss: 0.580328]\n",
      "epoch:12 step:11847 [D loss: 0.508380, acc.: 72.66%] [G loss: 0.726926]\n",
      "epoch:12 step:11848 [D loss: 0.580554, acc.: 70.31%] [G loss: 0.639261]\n",
      "epoch:12 step:11849 [D loss: 0.459871, acc.: 78.12%] [G loss: 0.786712]\n",
      "epoch:12 step:11850 [D loss: 0.609363, acc.: 65.62%] [G loss: 0.481347]\n",
      "epoch:12 step:11851 [D loss: 0.529813, acc.: 71.09%] [G loss: 0.465478]\n",
      "epoch:12 step:11852 [D loss: 0.530166, acc.: 75.78%] [G loss: 0.497585]\n",
      "epoch:12 step:11853 [D loss: 0.529001, acc.: 71.09%] [G loss: 0.429722]\n",
      "epoch:12 step:11854 [D loss: 0.560231, acc.: 72.66%] [G loss: 0.501826]\n",
      "epoch:12 step:11855 [D loss: 0.511635, acc.: 69.53%] [G loss: 0.565970]\n",
      "epoch:12 step:11856 [D loss: 0.570302, acc.: 67.19%] [G loss: 0.575401]\n",
      "epoch:12 step:11857 [D loss: 0.510614, acc.: 65.62%] [G loss: 0.549033]\n",
      "epoch:12 step:11858 [D loss: 0.578778, acc.: 66.41%] [G loss: 0.506330]\n",
      "epoch:12 step:11859 [D loss: 0.606983, acc.: 69.53%] [G loss: 0.480378]\n",
      "epoch:12 step:11860 [D loss: 0.600378, acc.: 61.72%] [G loss: 0.615254]\n",
      "epoch:12 step:11861 [D loss: 0.585682, acc.: 67.97%] [G loss: 0.633430]\n",
      "epoch:12 step:11862 [D loss: 0.544047, acc.: 73.44%] [G loss: 0.602449]\n",
      "epoch:12 step:11863 [D loss: 0.593488, acc.: 64.84%] [G loss: 0.663095]\n",
      "epoch:12 step:11864 [D loss: 0.535093, acc.: 67.97%] [G loss: 0.577627]\n",
      "epoch:12 step:11865 [D loss: 0.576816, acc.: 70.31%] [G loss: 0.509816]\n",
      "epoch:12 step:11866 [D loss: 0.596045, acc.: 67.19%] [G loss: 0.555998]\n",
      "epoch:12 step:11867 [D loss: 0.533461, acc.: 71.88%] [G loss: 0.511412]\n",
      "epoch:12 step:11868 [D loss: 0.486812, acc.: 76.56%] [G loss: 0.710457]\n",
      "epoch:12 step:11869 [D loss: 0.616311, acc.: 64.84%] [G loss: 0.662398]\n",
      "epoch:12 step:11870 [D loss: 0.562869, acc.: 63.28%] [G loss: 0.517635]\n",
      "epoch:12 step:11871 [D loss: 0.587091, acc.: 64.06%] [G loss: 0.540817]\n",
      "epoch:12 step:11872 [D loss: 0.585308, acc.: 67.19%] [G loss: 0.491330]\n",
      "epoch:12 step:11873 [D loss: 0.512366, acc.: 77.34%] [G loss: 0.571276]\n",
      "epoch:12 step:11874 [D loss: 0.575413, acc.: 67.19%] [G loss: 0.478512]\n",
      "epoch:12 step:11875 [D loss: 0.493098, acc.: 81.25%] [G loss: 0.602824]\n",
      "epoch:12 step:11876 [D loss: 0.512877, acc.: 75.78%] [G loss: 0.577658]\n",
      "epoch:12 step:11877 [D loss: 0.554459, acc.: 71.09%] [G loss: 0.643233]\n",
      "epoch:12 step:11878 [D loss: 0.441983, acc.: 82.03%] [G loss: 0.614941]\n",
      "epoch:12 step:11879 [D loss: 0.474356, acc.: 75.78%] [G loss: 0.672671]\n",
      "epoch:12 step:11880 [D loss: 0.617796, acc.: 64.84%] [G loss: 0.509166]\n",
      "epoch:12 step:11881 [D loss: 0.575271, acc.: 67.97%] [G loss: 0.477669]\n",
      "epoch:12 step:11882 [D loss: 0.534777, acc.: 69.53%] [G loss: 0.539686]\n",
      "epoch:12 step:11883 [D loss: 0.516411, acc.: 69.53%] [G loss: 0.606950]\n",
      "epoch:12 step:11884 [D loss: 0.567239, acc.: 71.88%] [G loss: 0.631647]\n",
      "epoch:12 step:11885 [D loss: 0.478515, acc.: 78.12%] [G loss: 0.651632]\n",
      "epoch:12 step:11886 [D loss: 0.497228, acc.: 75.78%] [G loss: 0.852387]\n",
      "epoch:12 step:11887 [D loss: 0.493028, acc.: 72.66%] [G loss: 0.689933]\n",
      "epoch:12 step:11888 [D loss: 0.603581, acc.: 63.28%] [G loss: 0.653886]\n",
      "epoch:12 step:11889 [D loss: 0.587967, acc.: 64.84%] [G loss: 0.653161]\n",
      "epoch:12 step:11890 [D loss: 0.567932, acc.: 69.53%] [G loss: 0.516037]\n",
      "epoch:12 step:11891 [D loss: 0.505677, acc.: 75.00%] [G loss: 0.671991]\n",
      "epoch:12 step:11892 [D loss: 0.433085, acc.: 81.25%] [G loss: 0.690198]\n",
      "epoch:12 step:11893 [D loss: 0.488553, acc.: 76.56%] [G loss: 0.748757]\n",
      "epoch:12 step:11894 [D loss: 0.539032, acc.: 69.53%] [G loss: 0.604958]\n",
      "epoch:12 step:11895 [D loss: 0.551165, acc.: 71.88%] [G loss: 0.757678]\n",
      "epoch:12 step:11896 [D loss: 0.635687, acc.: 64.84%] [G loss: 0.637720]\n",
      "epoch:12 step:11897 [D loss: 0.596331, acc.: 68.75%] [G loss: 0.516599]\n",
      "epoch:12 step:11898 [D loss: 0.493706, acc.: 78.12%] [G loss: 0.449234]\n",
      "epoch:12 step:11899 [D loss: 0.572148, acc.: 70.31%] [G loss: 0.473274]\n",
      "epoch:12 step:11900 [D loss: 0.562955, acc.: 70.31%] [G loss: 0.597412]\n",
      "epoch:12 step:11901 [D loss: 0.515343, acc.: 71.09%] [G loss: 0.561789]\n",
      "epoch:12 step:11902 [D loss: 0.607901, acc.: 64.84%] [G loss: 0.754980]\n",
      "epoch:12 step:11903 [D loss: 0.513740, acc.: 72.66%] [G loss: 0.634486]\n",
      "epoch:12 step:11904 [D loss: 0.525124, acc.: 74.22%] [G loss: 0.587084]\n",
      "epoch:12 step:11905 [D loss: 0.499987, acc.: 73.44%] [G loss: 0.635034]\n",
      "epoch:12 step:11906 [D loss: 0.547190, acc.: 71.88%] [G loss: 0.672097]\n",
      "epoch:12 step:11907 [D loss: 0.584064, acc.: 63.28%] [G loss: 0.463879]\n",
      "epoch:12 step:11908 [D loss: 0.507266, acc.: 72.66%] [G loss: 0.916442]\n",
      "epoch:12 step:11909 [D loss: 0.546566, acc.: 66.41%] [G loss: 0.706423]\n",
      "epoch:12 step:11910 [D loss: 0.555083, acc.: 71.88%] [G loss: 0.654891]\n",
      "epoch:12 step:11911 [D loss: 0.615413, acc.: 62.50%] [G loss: 0.494330]\n",
      "epoch:12 step:11912 [D loss: 0.574709, acc.: 70.31%] [G loss: 0.606234]\n",
      "epoch:12 step:11913 [D loss: 0.534468, acc.: 70.31%] [G loss: 0.511868]\n",
      "epoch:12 step:11914 [D loss: 0.555488, acc.: 65.62%] [G loss: 0.581206]\n",
      "epoch:12 step:11915 [D loss: 0.562832, acc.: 67.97%] [G loss: 0.679128]\n",
      "epoch:12 step:11916 [D loss: 0.566398, acc.: 68.75%] [G loss: 0.627898]\n",
      "epoch:12 step:11917 [D loss: 0.564822, acc.: 64.84%] [G loss: 0.570576]\n",
      "epoch:12 step:11918 [D loss: 0.558850, acc.: 66.41%] [G loss: 0.631232]\n",
      "epoch:12 step:11919 [D loss: 0.599594, acc.: 65.62%] [G loss: 0.607653]\n",
      "epoch:12 step:11920 [D loss: 0.588618, acc.: 68.75%] [G loss: 0.505956]\n",
      "epoch:12 step:11921 [D loss: 0.481799, acc.: 78.12%] [G loss: 0.582486]\n",
      "epoch:12 step:11922 [D loss: 0.564770, acc.: 67.97%] [G loss: 0.669492]\n",
      "epoch:12 step:11923 [D loss: 0.531186, acc.: 73.44%] [G loss: 0.657552]\n",
      "epoch:12 step:11924 [D loss: 0.527373, acc.: 75.78%] [G loss: 0.571387]\n",
      "epoch:12 step:11925 [D loss: 0.504967, acc.: 74.22%] [G loss: 0.539461]\n",
      "epoch:12 step:11926 [D loss: 0.558013, acc.: 70.31%] [G loss: 0.447954]\n",
      "epoch:12 step:11927 [D loss: 0.546062, acc.: 69.53%] [G loss: 0.606137]\n",
      "epoch:12 step:11928 [D loss: 0.610771, acc.: 66.41%] [G loss: 0.465956]\n",
      "epoch:12 step:11929 [D loss: 0.510399, acc.: 75.78%] [G loss: 0.510564]\n",
      "epoch:12 step:11930 [D loss: 0.624575, acc.: 61.72%] [G loss: 0.461799]\n",
      "epoch:12 step:11931 [D loss: 0.542815, acc.: 72.66%] [G loss: 0.458801]\n",
      "epoch:12 step:11932 [D loss: 0.590702, acc.: 60.94%] [G loss: 0.482532]\n",
      "epoch:12 step:11933 [D loss: 0.614014, acc.: 64.84%] [G loss: 0.409678]\n",
      "epoch:12 step:11934 [D loss: 0.462714, acc.: 82.81%] [G loss: 0.644862]\n",
      "epoch:12 step:11935 [D loss: 0.541426, acc.: 71.09%] [G loss: 0.543095]\n",
      "epoch:12 step:11936 [D loss: 0.548855, acc.: 70.31%] [G loss: 0.673766]\n",
      "epoch:12 step:11937 [D loss: 0.518752, acc.: 77.34%] [G loss: 0.769685]\n",
      "epoch:12 step:11938 [D loss: 0.503566, acc.: 71.88%] [G loss: 0.617314]\n",
      "epoch:12 step:11939 [D loss: 0.551230, acc.: 73.44%] [G loss: 0.648989]\n",
      "epoch:12 step:11940 [D loss: 0.609234, acc.: 63.28%] [G loss: 0.571936]\n",
      "epoch:12 step:11941 [D loss: 0.576543, acc.: 69.53%] [G loss: 0.634607]\n",
      "epoch:12 step:11942 [D loss: 0.582850, acc.: 62.50%] [G loss: 0.477671]\n",
      "epoch:12 step:11943 [D loss: 0.505420, acc.: 74.22%] [G loss: 0.641786]\n",
      "epoch:12 step:11944 [D loss: 0.516807, acc.: 70.31%] [G loss: 0.745520]\n",
      "epoch:12 step:11945 [D loss: 0.503774, acc.: 78.12%] [G loss: 0.718100]\n",
      "epoch:12 step:11946 [D loss: 0.556149, acc.: 75.00%] [G loss: 0.555995]\n",
      "epoch:12 step:11947 [D loss: 0.597340, acc.: 66.41%] [G loss: 0.483541]\n",
      "epoch:12 step:11948 [D loss: 0.663952, acc.: 62.50%] [G loss: 0.542773]\n",
      "epoch:12 step:11949 [D loss: 0.546528, acc.: 67.19%] [G loss: 0.420392]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:12 step:11950 [D loss: 0.640150, acc.: 63.28%] [G loss: 0.521473]\n",
      "epoch:12 step:11951 [D loss: 0.477342, acc.: 77.34%] [G loss: 0.794811]\n",
      "epoch:12 step:11952 [D loss: 0.508779, acc.: 74.22%] [G loss: 0.609839]\n",
      "epoch:12 step:11953 [D loss: 0.554942, acc.: 70.31%] [G loss: 0.648438]\n",
      "epoch:12 step:11954 [D loss: 0.564270, acc.: 67.97%] [G loss: 0.620879]\n",
      "epoch:12 step:11955 [D loss: 0.573623, acc.: 67.97%] [G loss: 0.493911]\n",
      "epoch:12 step:11956 [D loss: 0.577259, acc.: 67.19%] [G loss: 0.546689]\n",
      "epoch:12 step:11957 [D loss: 0.608318, acc.: 58.59%] [G loss: 0.516933]\n",
      "epoch:12 step:11958 [D loss: 0.545953, acc.: 73.44%] [G loss: 0.722681]\n",
      "epoch:12 step:11959 [D loss: 0.573654, acc.: 68.75%] [G loss: 0.541376]\n",
      "epoch:12 step:11960 [D loss: 0.590103, acc.: 67.19%] [G loss: 0.459780]\n",
      "epoch:12 step:11961 [D loss: 0.597669, acc.: 62.50%] [G loss: 0.428084]\n",
      "epoch:12 step:11962 [D loss: 0.585871, acc.: 64.06%] [G loss: 0.415914]\n",
      "epoch:12 step:11963 [D loss: 0.512524, acc.: 73.44%] [G loss: 0.590111]\n",
      "epoch:12 step:11964 [D loss: 0.656586, acc.: 62.50%] [G loss: 0.485240]\n",
      "epoch:12 step:11965 [D loss: 0.593274, acc.: 61.72%] [G loss: 0.582041]\n",
      "epoch:12 step:11966 [D loss: 0.587601, acc.: 64.84%] [G loss: 0.469189]\n",
      "epoch:12 step:11967 [D loss: 0.608568, acc.: 67.97%] [G loss: 0.504449]\n",
      "epoch:12 step:11968 [D loss: 0.506517, acc.: 79.69%] [G loss: 0.584545]\n",
      "epoch:12 step:11969 [D loss: 0.474960, acc.: 77.34%] [G loss: 0.771620]\n",
      "epoch:12 step:11970 [D loss: 0.518455, acc.: 71.88%] [G loss: 0.799772]\n",
      "epoch:12 step:11971 [D loss: 0.599946, acc.: 65.62%] [G loss: 0.576246]\n",
      "epoch:12 step:11972 [D loss: 0.543648, acc.: 70.31%] [G loss: 0.609235]\n",
      "epoch:12 step:11973 [D loss: 0.581175, acc.: 66.41%] [G loss: 0.495127]\n",
      "epoch:12 step:11974 [D loss: 0.513733, acc.: 75.00%] [G loss: 0.522291]\n",
      "epoch:12 step:11975 [D loss: 0.539314, acc.: 77.34%] [G loss: 0.469813]\n",
      "epoch:12 step:11976 [D loss: 0.503510, acc.: 76.56%] [G loss: 0.641244]\n",
      "epoch:12 step:11977 [D loss: 0.524294, acc.: 71.09%] [G loss: 0.660222]\n",
      "epoch:12 step:11978 [D loss: 0.530101, acc.: 69.53%] [G loss: 0.554085]\n",
      "epoch:12 step:11979 [D loss: 0.587586, acc.: 64.84%] [G loss: 0.676555]\n",
      "epoch:12 step:11980 [D loss: 0.521442, acc.: 73.44%] [G loss: 0.759263]\n",
      "epoch:12 step:11981 [D loss: 0.536544, acc.: 72.66%] [G loss: 0.564621]\n",
      "epoch:12 step:11982 [D loss: 0.565404, acc.: 67.19%] [G loss: 0.513995]\n",
      "epoch:12 step:11983 [D loss: 0.592422, acc.: 69.53%] [G loss: 0.555522]\n",
      "epoch:12 step:11984 [D loss: 0.643785, acc.: 57.81%] [G loss: 0.445813]\n",
      "epoch:12 step:11985 [D loss: 0.542362, acc.: 71.88%] [G loss: 0.467280]\n",
      "epoch:12 step:11986 [D loss: 0.541912, acc.: 67.19%] [G loss: 0.528410]\n",
      "epoch:12 step:11987 [D loss: 0.475846, acc.: 79.69%] [G loss: 0.685327]\n",
      "epoch:12 step:11988 [D loss: 0.565156, acc.: 73.44%] [G loss: 0.706551]\n",
      "epoch:12 step:11989 [D loss: 0.641413, acc.: 60.94%] [G loss: 0.612966]\n",
      "epoch:12 step:11990 [D loss: 0.487345, acc.: 73.44%] [G loss: 0.662690]\n",
      "epoch:12 step:11991 [D loss: 0.487482, acc.: 74.22%] [G loss: 0.714331]\n",
      "epoch:12 step:11992 [D loss: 0.530539, acc.: 72.66%] [G loss: 0.689917]\n",
      "epoch:12 step:11993 [D loss: 0.544009, acc.: 74.22%] [G loss: 0.667768]\n",
      "epoch:12 step:11994 [D loss: 0.541248, acc.: 70.31%] [G loss: 0.661005]\n",
      "epoch:12 step:11995 [D loss: 0.493627, acc.: 76.56%] [G loss: 0.790873]\n",
      "epoch:12 step:11996 [D loss: 0.618219, acc.: 64.06%] [G loss: 0.501995]\n",
      "epoch:12 step:11997 [D loss: 0.480962, acc.: 78.12%] [G loss: 0.553819]\n",
      "epoch:12 step:11998 [D loss: 0.545450, acc.: 68.75%] [G loss: 0.614708]\n",
      "epoch:12 step:11999 [D loss: 0.548355, acc.: 71.09%] [G loss: 0.603411]\n",
      "epoch:12 step:12000 [D loss: 0.628924, acc.: 62.50%] [G loss: 0.499662]\n",
      "##############\n",
      "[3.38515989 1.28888722 6.25768402 4.70608575 3.70870848 5.64713627\n",
      " 4.58138114 4.80149059 4.4207075  3.92152046]\n",
      "##########\n",
      "epoch:12 step:12001 [D loss: 0.545297, acc.: 69.53%] [G loss: 0.532626]\n",
      "epoch:12 step:12002 [D loss: 0.578218, acc.: 68.75%] [G loss: 0.551648]\n",
      "epoch:12 step:12003 [D loss: 0.547206, acc.: 71.88%] [G loss: 0.484492]\n",
      "epoch:12 step:12004 [D loss: 0.559724, acc.: 67.19%] [G loss: 0.556611]\n",
      "epoch:12 step:12005 [D loss: 0.538420, acc.: 75.78%] [G loss: 0.657546]\n",
      "epoch:12 step:12006 [D loss: 0.584090, acc.: 67.97%] [G loss: 0.508361]\n",
      "epoch:12 step:12007 [D loss: 0.564050, acc.: 70.31%] [G loss: 0.549165]\n",
      "epoch:12 step:12008 [D loss: 0.576006, acc.: 64.06%] [G loss: 0.607528]\n",
      "epoch:12 step:12009 [D loss: 0.640211, acc.: 60.94%] [G loss: 0.504313]\n",
      "epoch:12 step:12010 [D loss: 0.659058, acc.: 53.12%] [G loss: 0.496577]\n",
      "epoch:12 step:12011 [D loss: 0.546368, acc.: 74.22%] [G loss: 0.484982]\n",
      "epoch:12 step:12012 [D loss: 0.551726, acc.: 69.53%] [G loss: 0.536983]\n",
      "epoch:12 step:12013 [D loss: 0.508257, acc.: 76.56%] [G loss: 0.756343]\n",
      "epoch:12 step:12014 [D loss: 0.582888, acc.: 67.97%] [G loss: 0.688344]\n",
      "epoch:12 step:12015 [D loss: 0.511779, acc.: 75.00%] [G loss: 0.641963]\n",
      "epoch:12 step:12016 [D loss: 0.563040, acc.: 66.41%] [G loss: 0.554185]\n",
      "epoch:12 step:12017 [D loss: 0.534775, acc.: 71.88%] [G loss: 0.611698]\n",
      "epoch:12 step:12018 [D loss: 0.598253, acc.: 70.31%] [G loss: 0.525654]\n",
      "epoch:12 step:12019 [D loss: 0.512248, acc.: 72.66%] [G loss: 0.615269]\n",
      "epoch:12 step:12020 [D loss: 0.571411, acc.: 66.41%] [G loss: 0.673683]\n",
      "epoch:12 step:12021 [D loss: 0.589852, acc.: 67.97%] [G loss: 0.505574]\n",
      "epoch:12 step:12022 [D loss: 0.579239, acc.: 71.09%] [G loss: 0.550290]\n",
      "epoch:12 step:12023 [D loss: 0.595312, acc.: 68.75%] [G loss: 0.435976]\n",
      "epoch:12 step:12024 [D loss: 0.519631, acc.: 72.66%] [G loss: 0.562637]\n",
      "epoch:12 step:12025 [D loss: 0.518603, acc.: 74.22%] [G loss: 0.828307]\n",
      "epoch:12 step:12026 [D loss: 0.492711, acc.: 77.34%] [G loss: 0.755274]\n",
      "epoch:12 step:12027 [D loss: 0.572380, acc.: 67.19%] [G loss: 0.625847]\n",
      "epoch:12 step:12028 [D loss: 0.631710, acc.: 64.84%] [G loss: 0.502315]\n",
      "epoch:12 step:12029 [D loss: 0.568238, acc.: 71.09%] [G loss: 0.471484]\n",
      "epoch:12 step:12030 [D loss: 0.551515, acc.: 64.06%] [G loss: 0.617681]\n",
      "epoch:12 step:12031 [D loss: 0.590367, acc.: 64.06%] [G loss: 0.690575]\n",
      "epoch:12 step:12032 [D loss: 0.659050, acc.: 60.16%] [G loss: 0.556190]\n",
      "epoch:12 step:12033 [D loss: 0.515468, acc.: 71.88%] [G loss: 0.564885]\n",
      "epoch:12 step:12034 [D loss: 0.524693, acc.: 71.09%] [G loss: 0.596783]\n",
      "epoch:12 step:12035 [D loss: 0.557626, acc.: 70.31%] [G loss: 0.585056]\n",
      "epoch:12 step:12036 [D loss: 0.433029, acc.: 79.69%] [G loss: 0.663937]\n",
      "epoch:12 step:12037 [D loss: 0.653718, acc.: 61.72%] [G loss: 0.559625]\n",
      "epoch:12 step:12038 [D loss: 0.681269, acc.: 57.81%] [G loss: 0.567762]\n",
      "epoch:12 step:12039 [D loss: 0.603715, acc.: 60.94%] [G loss: 0.477711]\n",
      "epoch:12 step:12040 [D loss: 0.525517, acc.: 70.31%] [G loss: 0.715769]\n",
      "epoch:12 step:12041 [D loss: 0.531646, acc.: 75.00%] [G loss: 0.673170]\n",
      "epoch:12 step:12042 [D loss: 0.555896, acc.: 65.62%] [G loss: 0.578040]\n",
      "epoch:12 step:12043 [D loss: 0.572086, acc.: 71.09%] [G loss: 0.721725]\n",
      "epoch:12 step:12044 [D loss: 0.569061, acc.: 64.06%] [G loss: 0.652592]\n",
      "epoch:12 step:12045 [D loss: 0.555827, acc.: 65.62%] [G loss: 0.634948]\n",
      "epoch:12 step:12046 [D loss: 0.491937, acc.: 75.00%] [G loss: 0.721825]\n",
      "epoch:12 step:12047 [D loss: 0.490141, acc.: 78.91%] [G loss: 0.867526]\n",
      "epoch:12 step:12048 [D loss: 0.520839, acc.: 75.78%] [G loss: 0.682298]\n",
      "epoch:12 step:12049 [D loss: 0.593800, acc.: 66.41%] [G loss: 0.376016]\n",
      "epoch:12 step:12050 [D loss: 0.507319, acc.: 75.00%] [G loss: 0.553372]\n",
      "epoch:12 step:12051 [D loss: 0.499641, acc.: 78.91%] [G loss: 0.547082]\n",
      "epoch:12 step:12052 [D loss: 0.591516, acc.: 71.88%] [G loss: 0.601408]\n",
      "epoch:12 step:12053 [D loss: 0.560884, acc.: 69.53%] [G loss: 0.562341]\n",
      "epoch:12 step:12054 [D loss: 0.502267, acc.: 77.34%] [G loss: 0.538559]\n",
      "epoch:12 step:12055 [D loss: 0.536593, acc.: 72.66%] [G loss: 0.695997]\n",
      "epoch:12 step:12056 [D loss: 0.625111, acc.: 60.94%] [G loss: 0.496480]\n",
      "epoch:12 step:12057 [D loss: 0.564184, acc.: 67.19%] [G loss: 0.390682]\n",
      "epoch:12 step:12058 [D loss: 0.487652, acc.: 75.00%] [G loss: 0.579911]\n",
      "epoch:12 step:12059 [D loss: 0.484518, acc.: 75.00%] [G loss: 0.739547]\n",
      "epoch:12 step:12060 [D loss: 0.537657, acc.: 74.22%] [G loss: 0.805499]\n",
      "epoch:12 step:12061 [D loss: 0.688540, acc.: 64.84%] [G loss: 0.512636]\n",
      "epoch:12 step:12062 [D loss: 0.561802, acc.: 70.31%] [G loss: 0.546299]\n",
      "epoch:12 step:12063 [D loss: 0.533759, acc.: 69.53%] [G loss: 0.582839]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:12 step:12064 [D loss: 0.618464, acc.: 63.28%] [G loss: 0.534743]\n",
      "epoch:12 step:12065 [D loss: 0.535855, acc.: 69.53%] [G loss: 0.432404]\n",
      "epoch:12 step:12066 [D loss: 0.542309, acc.: 69.53%] [G loss: 0.671257]\n",
      "epoch:12 step:12067 [D loss: 0.412893, acc.: 82.03%] [G loss: 0.534831]\n",
      "epoch:12 step:12068 [D loss: 0.594806, acc.: 67.19%] [G loss: 0.499270]\n",
      "epoch:12 step:12069 [D loss: 0.536095, acc.: 73.44%] [G loss: 0.475199]\n",
      "epoch:12 step:12070 [D loss: 0.550291, acc.: 73.44%] [G loss: 0.502044]\n",
      "epoch:12 step:12071 [D loss: 0.524308, acc.: 71.09%] [G loss: 0.622604]\n",
      "epoch:12 step:12072 [D loss: 0.636825, acc.: 60.94%] [G loss: 0.557145]\n",
      "epoch:12 step:12073 [D loss: 0.526455, acc.: 74.22%] [G loss: 0.614735]\n",
      "epoch:12 step:12074 [D loss: 0.596342, acc.: 65.62%] [G loss: 0.631674]\n",
      "epoch:12 step:12075 [D loss: 0.574352, acc.: 66.41%] [G loss: 0.480476]\n",
      "epoch:12 step:12076 [D loss: 0.564300, acc.: 72.66%] [G loss: 0.501381]\n",
      "epoch:12 step:12077 [D loss: 0.519237, acc.: 69.53%] [G loss: 0.650630]\n",
      "epoch:12 step:12078 [D loss: 0.518275, acc.: 74.22%] [G loss: 0.532417]\n",
      "epoch:12 step:12079 [D loss: 0.578132, acc.: 70.31%] [G loss: 0.482810]\n",
      "epoch:12 step:12080 [D loss: 0.545504, acc.: 69.53%] [G loss: 0.634213]\n",
      "epoch:12 step:12081 [D loss: 0.511025, acc.: 71.09%] [G loss: 0.717073]\n",
      "epoch:12 step:12082 [D loss: 0.559233, acc.: 69.53%] [G loss: 0.489567]\n",
      "epoch:12 step:12083 [D loss: 0.585410, acc.: 66.41%] [G loss: 0.407102]\n",
      "epoch:12 step:12084 [D loss: 0.643118, acc.: 61.72%] [G loss: 0.513822]\n",
      "epoch:12 step:12085 [D loss: 0.541771, acc.: 68.75%] [G loss: 0.510556]\n",
      "epoch:12 step:12086 [D loss: 0.517289, acc.: 73.44%] [G loss: 0.502346]\n",
      "epoch:12 step:12087 [D loss: 0.497979, acc.: 72.66%] [G loss: 0.561282]\n",
      "epoch:12 step:12088 [D loss: 0.545518, acc.: 72.66%] [G loss: 0.498144]\n",
      "epoch:12 step:12089 [D loss: 0.597572, acc.: 63.28%] [G loss: 0.417689]\n",
      "epoch:12 step:12090 [D loss: 0.544399, acc.: 68.75%] [G loss: 0.509449]\n",
      "epoch:12 step:12091 [D loss: 0.635938, acc.: 62.50%] [G loss: 0.438075]\n",
      "epoch:12 step:12092 [D loss: 0.538949, acc.: 70.31%] [G loss: 0.500044]\n",
      "epoch:12 step:12093 [D loss: 0.550257, acc.: 70.31%] [G loss: 0.498447]\n",
      "epoch:12 step:12094 [D loss: 0.574835, acc.: 67.19%] [G loss: 0.445196]\n",
      "epoch:12 step:12095 [D loss: 0.596495, acc.: 67.97%] [G loss: 0.400809]\n",
      "epoch:12 step:12096 [D loss: 0.573236, acc.: 67.97%] [G loss: 0.461506]\n",
      "epoch:12 step:12097 [D loss: 0.567671, acc.: 64.06%] [G loss: 0.565911]\n",
      "epoch:12 step:12098 [D loss: 0.509237, acc.: 71.09%] [G loss: 0.672813]\n",
      "epoch:12 step:12099 [D loss: 0.528730, acc.: 67.19%] [G loss: 0.709591]\n",
      "epoch:12 step:12100 [D loss: 0.563676, acc.: 71.88%] [G loss: 0.608546]\n",
      "epoch:12 step:12101 [D loss: 0.480744, acc.: 76.56%] [G loss: 0.635781]\n",
      "epoch:12 step:12102 [D loss: 0.632474, acc.: 66.41%] [G loss: 0.495106]\n",
      "epoch:12 step:12103 [D loss: 0.555886, acc.: 71.09%] [G loss: 0.570342]\n",
      "epoch:12 step:12104 [D loss: 0.467011, acc.: 76.56%] [G loss: 0.670712]\n",
      "epoch:12 step:12105 [D loss: 0.620871, acc.: 66.41%] [G loss: 0.588461]\n",
      "epoch:12 step:12106 [D loss: 0.559835, acc.: 68.75%] [G loss: 0.444059]\n",
      "epoch:12 step:12107 [D loss: 0.611387, acc.: 66.41%] [G loss: 0.534099]\n",
      "epoch:12 step:12108 [D loss: 0.521851, acc.: 71.88%] [G loss: 0.582752]\n",
      "epoch:12 step:12109 [D loss: 0.577992, acc.: 66.41%] [G loss: 0.548375]\n",
      "epoch:12 step:12110 [D loss: 0.558723, acc.: 67.19%] [G loss: 0.525297]\n",
      "epoch:12 step:12111 [D loss: 0.648399, acc.: 61.72%] [G loss: 0.465888]\n",
      "epoch:12 step:12112 [D loss: 0.538295, acc.: 71.88%] [G loss: 0.510458]\n",
      "epoch:12 step:12113 [D loss: 0.620023, acc.: 63.28%] [G loss: 0.565322]\n",
      "epoch:12 step:12114 [D loss: 0.481207, acc.: 73.44%] [G loss: 0.633978]\n",
      "epoch:12 step:12115 [D loss: 0.519378, acc.: 71.88%] [G loss: 0.725870]\n",
      "epoch:12 step:12116 [D loss: 0.534378, acc.: 71.09%] [G loss: 0.654866]\n",
      "epoch:12 step:12117 [D loss: 0.569387, acc.: 71.09%] [G loss: 0.594109]\n",
      "epoch:12 step:12118 [D loss: 0.675081, acc.: 60.16%] [G loss: 0.454733]\n",
      "epoch:12 step:12119 [D loss: 0.494007, acc.: 78.12%] [G loss: 0.618554]\n",
      "epoch:12 step:12120 [D loss: 0.535362, acc.: 68.75%] [G loss: 0.476605]\n",
      "epoch:12 step:12121 [D loss: 0.566343, acc.: 70.31%] [G loss: 0.524066]\n",
      "epoch:12 step:12122 [D loss: 0.545921, acc.: 68.75%] [G loss: 0.491440]\n",
      "epoch:12 step:12123 [D loss: 0.534256, acc.: 67.97%] [G loss: 0.387256]\n",
      "epoch:12 step:12124 [D loss: 0.593231, acc.: 67.19%] [G loss: 0.417130]\n",
      "epoch:12 step:12125 [D loss: 0.584424, acc.: 68.75%] [G loss: 0.358310]\n",
      "epoch:12 step:12126 [D loss: 0.608020, acc.: 64.06%] [G loss: 0.418870]\n",
      "epoch:12 step:12127 [D loss: 0.565275, acc.: 66.41%] [G loss: 0.576869]\n",
      "epoch:12 step:12128 [D loss: 0.493071, acc.: 70.31%] [G loss: 0.575610]\n",
      "epoch:12 step:12129 [D loss: 0.516446, acc.: 78.12%] [G loss: 0.508348]\n",
      "epoch:12 step:12130 [D loss: 0.477126, acc.: 78.91%] [G loss: 0.647751]\n",
      "epoch:12 step:12131 [D loss: 0.502610, acc.: 77.34%] [G loss: 0.632396]\n",
      "epoch:12 step:12132 [D loss: 0.551523, acc.: 67.97%] [G loss: 0.648665]\n",
      "epoch:12 step:12133 [D loss: 0.566673, acc.: 67.19%] [G loss: 0.607670]\n",
      "epoch:12 step:12134 [D loss: 0.492080, acc.: 77.34%] [G loss: 0.749448]\n",
      "epoch:12 step:12135 [D loss: 0.618809, acc.: 64.84%] [G loss: 0.506384]\n",
      "epoch:12 step:12136 [D loss: 0.582481, acc.: 66.41%] [G loss: 0.422174]\n",
      "epoch:12 step:12137 [D loss: 0.558530, acc.: 71.09%] [G loss: 0.493165]\n",
      "epoch:12 step:12138 [D loss: 0.485742, acc.: 76.56%] [G loss: 0.622265]\n",
      "epoch:12 step:12139 [D loss: 0.477795, acc.: 75.78%] [G loss: 0.755504]\n",
      "epoch:12 step:12140 [D loss: 0.492915, acc.: 78.12%] [G loss: 0.582694]\n",
      "epoch:12 step:12141 [D loss: 0.538967, acc.: 74.22%] [G loss: 0.602385]\n",
      "epoch:12 step:12142 [D loss: 0.447985, acc.: 78.91%] [G loss: 0.835693]\n",
      "epoch:12 step:12143 [D loss: 0.501370, acc.: 71.09%] [G loss: 0.703327]\n",
      "epoch:12 step:12144 [D loss: 0.504593, acc.: 73.44%] [G loss: 0.791256]\n",
      "epoch:12 step:12145 [D loss: 0.533921, acc.: 71.09%] [G loss: 0.773189]\n",
      "epoch:12 step:12146 [D loss: 0.572824, acc.: 69.53%] [G loss: 0.541304]\n",
      "epoch:12 step:12147 [D loss: 0.586246, acc.: 70.31%] [G loss: 0.763091]\n",
      "epoch:12 step:12148 [D loss: 0.589830, acc.: 68.75%] [G loss: 0.504352]\n",
      "epoch:12 step:12149 [D loss: 0.620859, acc.: 64.84%] [G loss: 0.657085]\n",
      "epoch:12 step:12150 [D loss: 0.485515, acc.: 80.47%] [G loss: 0.756088]\n",
      "epoch:12 step:12151 [D loss: 0.537286, acc.: 72.66%] [G loss: 0.581942]\n",
      "epoch:12 step:12152 [D loss: 0.580652, acc.: 71.09%] [G loss: 0.590592]\n",
      "epoch:12 step:12153 [D loss: 0.546345, acc.: 74.22%] [G loss: 0.633431]\n",
      "epoch:12 step:12154 [D loss: 0.501622, acc.: 73.44%] [G loss: 0.607438]\n",
      "epoch:12 step:12155 [D loss: 0.454696, acc.: 83.59%] [G loss: 0.738354]\n",
      "epoch:12 step:12156 [D loss: 0.489262, acc.: 77.34%] [G loss: 0.873836]\n",
      "epoch:12 step:12157 [D loss: 0.616649, acc.: 67.19%] [G loss: 0.815617]\n",
      "epoch:12 step:12158 [D loss: 0.451296, acc.: 76.56%] [G loss: 0.901903]\n",
      "epoch:12 step:12159 [D loss: 0.608763, acc.: 64.06%] [G loss: 0.741345]\n",
      "epoch:12 step:12160 [D loss: 0.538714, acc.: 69.53%] [G loss: 0.622915]\n",
      "epoch:12 step:12161 [D loss: 0.663577, acc.: 57.03%] [G loss: 0.446930]\n",
      "epoch:12 step:12162 [D loss: 0.534915, acc.: 71.09%] [G loss: 0.610850]\n",
      "epoch:12 step:12163 [D loss: 0.439103, acc.: 82.81%] [G loss: 0.757998]\n",
      "epoch:12 step:12164 [D loss: 0.785381, acc.: 51.56%] [G loss: 0.476200]\n",
      "epoch:12 step:12165 [D loss: 0.526489, acc.: 75.00%] [G loss: 0.774957]\n",
      "epoch:12 step:12166 [D loss: 0.576729, acc.: 64.84%] [G loss: 0.579845]\n",
      "epoch:12 step:12167 [D loss: 0.465875, acc.: 78.12%] [G loss: 0.681273]\n",
      "epoch:12 step:12168 [D loss: 0.482796, acc.: 76.56%] [G loss: 0.842076]\n",
      "epoch:12 step:12169 [D loss: 0.441798, acc.: 82.81%] [G loss: 0.755157]\n",
      "epoch:12 step:12170 [D loss: 0.419969, acc.: 80.47%] [G loss: 1.083222]\n",
      "epoch:12 step:12171 [D loss: 0.497024, acc.: 73.44%] [G loss: 1.226891]\n",
      "epoch:12 step:12172 [D loss: 0.758400, acc.: 58.59%] [G loss: 0.919287]\n",
      "epoch:12 step:12173 [D loss: 0.425447, acc.: 83.59%] [G loss: 0.936559]\n",
      "epoch:12 step:12174 [D loss: 0.462901, acc.: 78.12%] [G loss: 1.040016]\n",
      "epoch:12 step:12175 [D loss: 0.658714, acc.: 60.16%] [G loss: 0.828629]\n",
      "epoch:12 step:12176 [D loss: 0.707332, acc.: 52.34%] [G loss: 0.600635]\n",
      "epoch:12 step:12177 [D loss: 0.423994, acc.: 80.47%] [G loss: 0.673071]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:12 step:12178 [D loss: 0.521486, acc.: 74.22%] [G loss: 0.752371]\n",
      "epoch:12 step:12179 [D loss: 0.465756, acc.: 76.56%] [G loss: 0.856127]\n",
      "epoch:12 step:12180 [D loss: 0.407051, acc.: 82.81%] [G loss: 0.918607]\n",
      "epoch:12 step:12181 [D loss: 0.479567, acc.: 75.00%] [G loss: 1.042638]\n",
      "epoch:13 step:12182 [D loss: 0.534516, acc.: 72.66%] [G loss: 0.852868]\n",
      "epoch:13 step:12183 [D loss: 0.491228, acc.: 75.78%] [G loss: 0.792356]\n",
      "epoch:13 step:12184 [D loss: 0.624665, acc.: 61.72%] [G loss: 0.836750]\n",
      "epoch:13 step:12185 [D loss: 0.508477, acc.: 73.44%] [G loss: 0.810598]\n",
      "epoch:13 step:12186 [D loss: 0.565975, acc.: 69.53%] [G loss: 0.642124]\n",
      "epoch:13 step:12187 [D loss: 0.599283, acc.: 63.28%] [G loss: 0.634904]\n",
      "epoch:13 step:12188 [D loss: 0.512465, acc.: 76.56%] [G loss: 0.669595]\n",
      "epoch:13 step:12189 [D loss: 0.518234, acc.: 75.00%] [G loss: 0.673404]\n",
      "epoch:13 step:12190 [D loss: 0.477600, acc.: 75.78%] [G loss: 0.749983]\n",
      "epoch:13 step:12191 [D loss: 0.527686, acc.: 73.44%] [G loss: 0.747663]\n",
      "epoch:13 step:12192 [D loss: 0.460049, acc.: 82.03%] [G loss: 0.727312]\n",
      "epoch:13 step:12193 [D loss: 0.572491, acc.: 71.09%] [G loss: 0.695377]\n",
      "epoch:13 step:12194 [D loss: 0.528748, acc.: 72.66%] [G loss: 0.631090]\n",
      "epoch:13 step:12195 [D loss: 0.559889, acc.: 67.19%] [G loss: 0.509176]\n",
      "epoch:13 step:12196 [D loss: 0.507221, acc.: 78.12%] [G loss: 0.648385]\n",
      "epoch:13 step:12197 [D loss: 0.496264, acc.: 74.22%] [G loss: 0.638410]\n",
      "epoch:13 step:12198 [D loss: 0.528175, acc.: 78.12%] [G loss: 0.493412]\n",
      "epoch:13 step:12199 [D loss: 0.576893, acc.: 65.62%] [G loss: 0.601846]\n",
      "epoch:13 step:12200 [D loss: 0.565286, acc.: 64.84%] [G loss: 0.582697]\n",
      "##############\n",
      "[2.77975431 1.20525061 6.32332203 4.59581085 3.80480434 5.99595228\n",
      " 4.48981247 4.79592675 4.55967296 3.98101638]\n",
      "##########\n",
      "epoch:13 step:12201 [D loss: 0.587161, acc.: 69.53%] [G loss: 0.466960]\n",
      "epoch:13 step:12202 [D loss: 0.622997, acc.: 62.50%] [G loss: 0.593746]\n",
      "epoch:13 step:12203 [D loss: 0.536724, acc.: 70.31%] [G loss: 0.529337]\n",
      "epoch:13 step:12204 [D loss: 0.539624, acc.: 71.88%] [G loss: 0.643752]\n",
      "epoch:13 step:12205 [D loss: 0.487586, acc.: 71.88%] [G loss: 0.618614]\n",
      "epoch:13 step:12206 [D loss: 0.491493, acc.: 73.44%] [G loss: 0.698666]\n",
      "epoch:13 step:12207 [D loss: 0.567117, acc.: 69.53%] [G loss: 0.454867]\n",
      "epoch:13 step:12208 [D loss: 0.502856, acc.: 76.56%] [G loss: 0.677441]\n",
      "epoch:13 step:12209 [D loss: 0.564526, acc.: 70.31%] [G loss: 0.594644]\n",
      "epoch:13 step:12210 [D loss: 0.549626, acc.: 71.88%] [G loss: 0.515986]\n",
      "epoch:13 step:12211 [D loss: 0.551243, acc.: 72.66%] [G loss: 0.532394]\n",
      "epoch:13 step:12212 [D loss: 0.600665, acc.: 64.06%] [G loss: 0.528138]\n",
      "epoch:13 step:12213 [D loss: 0.620712, acc.: 64.84%] [G loss: 0.709028]\n",
      "epoch:13 step:12214 [D loss: 0.539250, acc.: 70.31%] [G loss: 0.685532]\n",
      "epoch:13 step:12215 [D loss: 0.510385, acc.: 72.66%] [G loss: 0.704710]\n",
      "epoch:13 step:12216 [D loss: 0.627187, acc.: 60.16%] [G loss: 0.579369]\n",
      "epoch:13 step:12217 [D loss: 0.530256, acc.: 71.88%] [G loss: 0.533648]\n",
      "epoch:13 step:12218 [D loss: 0.507045, acc.: 82.03%] [G loss: 0.674714]\n",
      "epoch:13 step:12219 [D loss: 0.629015, acc.: 61.72%] [G loss: 0.511780]\n",
      "epoch:13 step:12220 [D loss: 0.547187, acc.: 72.66%] [G loss: 0.495260]\n",
      "epoch:13 step:12221 [D loss: 0.470861, acc.: 75.00%] [G loss: 0.780629]\n",
      "epoch:13 step:12222 [D loss: 0.552014, acc.: 71.09%] [G loss: 0.701411]\n",
      "epoch:13 step:12223 [D loss: 0.527090, acc.: 74.22%] [G loss: 0.692464]\n",
      "epoch:13 step:12224 [D loss: 0.556595, acc.: 69.53%] [G loss: 0.519466]\n",
      "epoch:13 step:12225 [D loss: 0.590095, acc.: 64.06%] [G loss: 0.560451]\n",
      "epoch:13 step:12226 [D loss: 0.468215, acc.: 80.47%] [G loss: 0.646692]\n",
      "epoch:13 step:12227 [D loss: 0.545339, acc.: 71.09%] [G loss: 0.490468]\n",
      "epoch:13 step:12228 [D loss: 0.514462, acc.: 77.34%] [G loss: 0.572472]\n",
      "epoch:13 step:12229 [D loss: 0.518215, acc.: 73.44%] [G loss: 0.709889]\n",
      "epoch:13 step:12230 [D loss: 0.514865, acc.: 71.09%] [G loss: 0.729601]\n",
      "epoch:13 step:12231 [D loss: 0.558867, acc.: 71.09%] [G loss: 0.685271]\n",
      "epoch:13 step:12232 [D loss: 0.650403, acc.: 61.72%] [G loss: 0.485208]\n",
      "epoch:13 step:12233 [D loss: 0.651972, acc.: 59.38%] [G loss: 0.404044]\n",
      "epoch:13 step:12234 [D loss: 0.492700, acc.: 75.00%] [G loss: 0.830564]\n",
      "epoch:13 step:12235 [D loss: 0.557340, acc.: 67.97%] [G loss: 0.531780]\n",
      "epoch:13 step:12236 [D loss: 0.532537, acc.: 74.22%] [G loss: 0.626998]\n",
      "epoch:13 step:12237 [D loss: 0.523733, acc.: 75.78%] [G loss: 0.578851]\n",
      "epoch:13 step:12238 [D loss: 0.481951, acc.: 77.34%] [G loss: 0.689822]\n",
      "epoch:13 step:12239 [D loss: 0.535103, acc.: 71.88%] [G loss: 0.711593]\n",
      "epoch:13 step:12240 [D loss: 0.576210, acc.: 69.53%] [G loss: 0.652584]\n",
      "epoch:13 step:12241 [D loss: 0.544471, acc.: 72.66%] [G loss: 0.661464]\n",
      "epoch:13 step:12242 [D loss: 0.588592, acc.: 67.19%] [G loss: 0.608765]\n",
      "epoch:13 step:12243 [D loss: 0.560822, acc.: 74.22%] [G loss: 0.538335]\n",
      "epoch:13 step:12244 [D loss: 0.543687, acc.: 71.09%] [G loss: 0.543148]\n",
      "epoch:13 step:12245 [D loss: 0.581240, acc.: 67.97%] [G loss: 0.540617]\n",
      "epoch:13 step:12246 [D loss: 0.515685, acc.: 71.09%] [G loss: 0.509932]\n",
      "epoch:13 step:12247 [D loss: 0.536491, acc.: 71.88%] [G loss: 0.556129]\n",
      "epoch:13 step:12248 [D loss: 0.523224, acc.: 74.22%] [G loss: 0.707855]\n",
      "epoch:13 step:12249 [D loss: 0.561928, acc.: 67.19%] [G loss: 0.625175]\n",
      "epoch:13 step:12250 [D loss: 0.470011, acc.: 74.22%] [G loss: 0.652485]\n",
      "epoch:13 step:12251 [D loss: 0.546100, acc.: 71.09%] [G loss: 0.677638]\n",
      "epoch:13 step:12252 [D loss: 0.522315, acc.: 72.66%] [G loss: 0.644725]\n",
      "epoch:13 step:12253 [D loss: 0.534187, acc.: 68.75%] [G loss: 0.572019]\n",
      "epoch:13 step:12254 [D loss: 0.569329, acc.: 67.97%] [G loss: 0.493491]\n",
      "epoch:13 step:12255 [D loss: 0.505368, acc.: 73.44%] [G loss: 0.624249]\n",
      "epoch:13 step:12256 [D loss: 0.510714, acc.: 74.22%] [G loss: 0.850993]\n",
      "epoch:13 step:12257 [D loss: 0.575074, acc.: 67.97%] [G loss: 0.754570]\n",
      "epoch:13 step:12258 [D loss: 0.433828, acc.: 78.91%] [G loss: 0.960850]\n",
      "epoch:13 step:12259 [D loss: 0.634142, acc.: 63.28%] [G loss: 0.608837]\n",
      "epoch:13 step:12260 [D loss: 0.543977, acc.: 67.97%] [G loss: 0.569354]\n",
      "epoch:13 step:12261 [D loss: 0.510205, acc.: 72.66%] [G loss: 0.596908]\n",
      "epoch:13 step:12262 [D loss: 0.573405, acc.: 68.75%] [G loss: 0.553078]\n",
      "epoch:13 step:12263 [D loss: 0.531713, acc.: 68.75%] [G loss: 0.627117]\n",
      "epoch:13 step:12264 [D loss: 0.500978, acc.: 75.78%] [G loss: 0.651640]\n",
      "epoch:13 step:12265 [D loss: 0.526602, acc.: 65.62%] [G loss: 0.703198]\n",
      "epoch:13 step:12266 [D loss: 0.671954, acc.: 60.94%] [G loss: 0.616915]\n",
      "epoch:13 step:12267 [D loss: 0.573183, acc.: 66.41%] [G loss: 0.589780]\n",
      "epoch:13 step:12268 [D loss: 0.499644, acc.: 73.44%] [G loss: 0.512313]\n",
      "epoch:13 step:12269 [D loss: 0.560004, acc.: 68.75%] [G loss: 0.604274]\n",
      "epoch:13 step:12270 [D loss: 0.574310, acc.: 66.41%] [G loss: 0.575576]\n",
      "epoch:13 step:12271 [D loss: 0.502316, acc.: 75.00%] [G loss: 0.573345]\n",
      "epoch:13 step:12272 [D loss: 0.602060, acc.: 67.19%] [G loss: 0.619572]\n",
      "epoch:13 step:12273 [D loss: 0.509422, acc.: 71.09%] [G loss: 0.705529]\n",
      "epoch:13 step:12274 [D loss: 0.511853, acc.: 74.22%] [G loss: 0.687679]\n",
      "epoch:13 step:12275 [D loss: 0.537201, acc.: 72.66%] [G loss: 0.634660]\n",
      "epoch:13 step:12276 [D loss: 0.532347, acc.: 70.31%] [G loss: 0.609775]\n",
      "epoch:13 step:12277 [D loss: 0.491427, acc.: 75.00%] [G loss: 0.599015]\n",
      "epoch:13 step:12278 [D loss: 0.536082, acc.: 73.44%] [G loss: 0.643001]\n",
      "epoch:13 step:12279 [D loss: 0.571774, acc.: 68.75%] [G loss: 0.661984]\n",
      "epoch:13 step:12280 [D loss: 0.523071, acc.: 74.22%] [G loss: 0.688734]\n",
      "epoch:13 step:12281 [D loss: 0.444661, acc.: 78.91%] [G loss: 0.646226]\n",
      "epoch:13 step:12282 [D loss: 0.534703, acc.: 72.66%] [G loss: 0.573173]\n",
      "epoch:13 step:12283 [D loss: 0.613083, acc.: 67.19%] [G loss: 0.649410]\n",
      "epoch:13 step:12284 [D loss: 0.598450, acc.: 64.84%] [G loss: 0.473596]\n",
      "epoch:13 step:12285 [D loss: 0.536868, acc.: 71.88%] [G loss: 0.499394]\n",
      "epoch:13 step:12286 [D loss: 0.644377, acc.: 60.16%] [G loss: 0.466466]\n",
      "epoch:13 step:12287 [D loss: 0.509338, acc.: 73.44%] [G loss: 0.543827]\n",
      "epoch:13 step:12288 [D loss: 0.587855, acc.: 66.41%] [G loss: 0.555235]\n",
      "epoch:13 step:12289 [D loss: 0.659072, acc.: 59.38%] [G loss: 0.465663]\n",
      "epoch:13 step:12290 [D loss: 0.612241, acc.: 66.41%] [G loss: 0.419660]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:13 step:12291 [D loss: 0.528339, acc.: 72.66%] [G loss: 0.468546]\n",
      "epoch:13 step:12292 [D loss: 0.503301, acc.: 75.00%] [G loss: 0.612447]\n",
      "epoch:13 step:12293 [D loss: 0.498394, acc.: 71.09%] [G loss: 0.651972]\n",
      "epoch:13 step:12294 [D loss: 0.540695, acc.: 72.66%] [G loss: 0.605566]\n",
      "epoch:13 step:12295 [D loss: 0.494012, acc.: 73.44%] [G loss: 0.704682]\n",
      "epoch:13 step:12296 [D loss: 0.567123, acc.: 72.66%] [G loss: 0.700485]\n",
      "epoch:13 step:12297 [D loss: 0.543016, acc.: 68.75%] [G loss: 0.648020]\n",
      "epoch:13 step:12298 [D loss: 0.588478, acc.: 64.06%] [G loss: 0.624054]\n",
      "epoch:13 step:12299 [D loss: 0.566022, acc.: 67.19%] [G loss: 0.737956]\n",
      "epoch:13 step:12300 [D loss: 0.510937, acc.: 75.78%] [G loss: 0.764413]\n",
      "epoch:13 step:12301 [D loss: 0.597217, acc.: 62.50%] [G loss: 0.778616]\n",
      "epoch:13 step:12302 [D loss: 0.579482, acc.: 70.31%] [G loss: 0.579351]\n",
      "epoch:13 step:12303 [D loss: 0.535066, acc.: 76.56%] [G loss: 0.725619]\n",
      "epoch:13 step:12304 [D loss: 0.484482, acc.: 74.22%] [G loss: 0.738870]\n",
      "epoch:13 step:12305 [D loss: 0.600360, acc.: 67.97%] [G loss: 0.619775]\n",
      "epoch:13 step:12306 [D loss: 0.569844, acc.: 67.97%] [G loss: 0.564935]\n",
      "epoch:13 step:12307 [D loss: 0.500221, acc.: 76.56%] [G loss: 0.530113]\n",
      "epoch:13 step:12308 [D loss: 0.505330, acc.: 78.91%] [G loss: 0.522928]\n",
      "epoch:13 step:12309 [D loss: 0.491137, acc.: 76.56%] [G loss: 0.591097]\n",
      "epoch:13 step:12310 [D loss: 0.579144, acc.: 67.19%] [G loss: 0.670613]\n",
      "epoch:13 step:12311 [D loss: 0.456593, acc.: 81.25%] [G loss: 0.613251]\n",
      "epoch:13 step:12312 [D loss: 0.489787, acc.: 71.88%] [G loss: 0.630244]\n",
      "epoch:13 step:12313 [D loss: 0.571355, acc.: 71.88%] [G loss: 0.614758]\n",
      "epoch:13 step:12314 [D loss: 0.536008, acc.: 70.31%] [G loss: 0.562922]\n",
      "epoch:13 step:12315 [D loss: 0.547933, acc.: 71.88%] [G loss: 0.639942]\n",
      "epoch:13 step:12316 [D loss: 0.521822, acc.: 75.78%] [G loss: 0.642859]\n",
      "epoch:13 step:12317 [D loss: 0.496477, acc.: 75.78%] [G loss: 0.617254]\n",
      "epoch:13 step:12318 [D loss: 0.611612, acc.: 67.19%] [G loss: 0.591007]\n",
      "epoch:13 step:12319 [D loss: 0.612271, acc.: 60.94%] [G loss: 0.497181]\n",
      "epoch:13 step:12320 [D loss: 0.537513, acc.: 74.22%] [G loss: 0.449350]\n",
      "epoch:13 step:12321 [D loss: 0.594509, acc.: 64.84%] [G loss: 0.473592]\n",
      "epoch:13 step:12322 [D loss: 0.540595, acc.: 65.62%] [G loss: 0.394018]\n",
      "epoch:13 step:12323 [D loss: 0.555391, acc.: 68.75%] [G loss: 0.436958]\n",
      "epoch:13 step:12324 [D loss: 0.615774, acc.: 60.16%] [G loss: 0.530784]\n",
      "epoch:13 step:12325 [D loss: 0.544232, acc.: 71.88%] [G loss: 0.445194]\n",
      "epoch:13 step:12326 [D loss: 0.580228, acc.: 64.06%] [G loss: 0.527580]\n",
      "epoch:13 step:12327 [D loss: 0.528597, acc.: 72.66%] [G loss: 0.721191]\n",
      "epoch:13 step:12328 [D loss: 0.632526, acc.: 61.72%] [G loss: 0.667580]\n",
      "epoch:13 step:12329 [D loss: 0.601807, acc.: 62.50%] [G loss: 0.524207]\n",
      "epoch:13 step:12330 [D loss: 0.471967, acc.: 75.00%] [G loss: 0.663059]\n",
      "epoch:13 step:12331 [D loss: 0.551838, acc.: 71.09%] [G loss: 0.566403]\n",
      "epoch:13 step:12332 [D loss: 0.529206, acc.: 74.22%] [G loss: 0.532794]\n",
      "epoch:13 step:12333 [D loss: 0.507457, acc.: 76.56%] [G loss: 0.655816]\n",
      "epoch:13 step:12334 [D loss: 0.630625, acc.: 60.94%] [G loss: 0.571803]\n",
      "epoch:13 step:12335 [D loss: 0.538990, acc.: 70.31%] [G loss: 0.577472]\n",
      "epoch:13 step:12336 [D loss: 0.488661, acc.: 74.22%] [G loss: 0.696643]\n",
      "epoch:13 step:12337 [D loss: 0.538736, acc.: 75.00%] [G loss: 0.618347]\n",
      "epoch:13 step:12338 [D loss: 0.552583, acc.: 71.88%] [G loss: 0.505994]\n",
      "epoch:13 step:12339 [D loss: 0.590260, acc.: 71.09%] [G loss: 0.473086]\n",
      "epoch:13 step:12340 [D loss: 0.505933, acc.: 76.56%] [G loss: 0.615246]\n",
      "epoch:13 step:12341 [D loss: 0.675957, acc.: 60.94%] [G loss: 0.488015]\n",
      "epoch:13 step:12342 [D loss: 0.558972, acc.: 72.66%] [G loss: 0.598326]\n",
      "epoch:13 step:12343 [D loss: 0.503222, acc.: 78.12%] [G loss: 0.697844]\n",
      "epoch:13 step:12344 [D loss: 0.555108, acc.: 71.09%] [G loss: 0.850346]\n",
      "epoch:13 step:12345 [D loss: 0.593127, acc.: 65.62%] [G loss: 0.577882]\n",
      "epoch:13 step:12346 [D loss: 0.514364, acc.: 74.22%] [G loss: 0.612354]\n",
      "epoch:13 step:12347 [D loss: 0.554169, acc.: 69.53%] [G loss: 0.597636]\n",
      "epoch:13 step:12348 [D loss: 0.584413, acc.: 68.75%] [G loss: 0.557170]\n",
      "epoch:13 step:12349 [D loss: 0.571788, acc.: 65.62%] [G loss: 0.426693]\n",
      "epoch:13 step:12350 [D loss: 0.610689, acc.: 63.28%] [G loss: 0.441523]\n",
      "epoch:13 step:12351 [D loss: 0.563926, acc.: 69.53%] [G loss: 0.513264]\n",
      "epoch:13 step:12352 [D loss: 0.548533, acc.: 70.31%] [G loss: 0.571440]\n",
      "epoch:13 step:12353 [D loss: 0.538323, acc.: 73.44%] [G loss: 0.729857]\n",
      "epoch:13 step:12354 [D loss: 0.501982, acc.: 75.78%] [G loss: 0.608834]\n",
      "epoch:13 step:12355 [D loss: 0.600284, acc.: 63.28%] [G loss: 0.631276]\n",
      "epoch:13 step:12356 [D loss: 0.604000, acc.: 62.50%] [G loss: 0.523860]\n",
      "epoch:13 step:12357 [D loss: 0.517283, acc.: 77.34%] [G loss: 0.475504]\n",
      "epoch:13 step:12358 [D loss: 0.541507, acc.: 71.88%] [G loss: 0.558627]\n",
      "epoch:13 step:12359 [D loss: 0.603643, acc.: 58.59%] [G loss: 0.500538]\n",
      "epoch:13 step:12360 [D loss: 0.577934, acc.: 66.41%] [G loss: 0.457807]\n",
      "epoch:13 step:12361 [D loss: 0.627804, acc.: 61.72%] [G loss: 0.469269]\n",
      "epoch:13 step:12362 [D loss: 0.593002, acc.: 67.97%] [G loss: 0.617324]\n",
      "epoch:13 step:12363 [D loss: 0.522921, acc.: 73.44%] [G loss: 0.645811]\n",
      "epoch:13 step:12364 [D loss: 0.516376, acc.: 72.66%] [G loss: 0.567734]\n",
      "epoch:13 step:12365 [D loss: 0.557793, acc.: 70.31%] [G loss: 0.517701]\n",
      "epoch:13 step:12366 [D loss: 0.569182, acc.: 68.75%] [G loss: 0.441196]\n",
      "epoch:13 step:12367 [D loss: 0.532276, acc.: 68.75%] [G loss: 0.594511]\n",
      "epoch:13 step:12368 [D loss: 0.634872, acc.: 57.81%] [G loss: 0.460206]\n",
      "epoch:13 step:12369 [D loss: 0.559281, acc.: 70.31%] [G loss: 0.555166]\n",
      "epoch:13 step:12370 [D loss: 0.590266, acc.: 65.62%] [G loss: 0.539062]\n",
      "epoch:13 step:12371 [D loss: 0.512149, acc.: 77.34%] [G loss: 0.576146]\n",
      "epoch:13 step:12372 [D loss: 0.537291, acc.: 74.22%] [G loss: 0.572319]\n",
      "epoch:13 step:12373 [D loss: 0.511552, acc.: 75.78%] [G loss: 0.690697]\n",
      "epoch:13 step:12374 [D loss: 0.535113, acc.: 76.56%] [G loss: 0.493578]\n",
      "epoch:13 step:12375 [D loss: 0.465364, acc.: 80.47%] [G loss: 0.659240]\n",
      "epoch:13 step:12376 [D loss: 0.608049, acc.: 64.84%] [G loss: 0.573109]\n",
      "epoch:13 step:12377 [D loss: 0.535914, acc.: 71.88%] [G loss: 0.512135]\n",
      "epoch:13 step:12378 [D loss: 0.516167, acc.: 73.44%] [G loss: 0.627878]\n",
      "epoch:13 step:12379 [D loss: 0.476585, acc.: 75.00%] [G loss: 0.560694]\n",
      "epoch:13 step:12380 [D loss: 0.552205, acc.: 67.97%] [G loss: 0.746693]\n",
      "epoch:13 step:12381 [D loss: 0.630298, acc.: 61.72%] [G loss: 0.557623]\n",
      "epoch:13 step:12382 [D loss: 0.581161, acc.: 66.41%] [G loss: 0.620604]\n",
      "epoch:13 step:12383 [D loss: 0.518716, acc.: 75.00%] [G loss: 0.634287]\n",
      "epoch:13 step:12384 [D loss: 0.560634, acc.: 73.44%] [G loss: 0.571643]\n",
      "epoch:13 step:12385 [D loss: 0.533550, acc.: 73.44%] [G loss: 0.636462]\n",
      "epoch:13 step:12386 [D loss: 0.540547, acc.: 70.31%] [G loss: 0.708569]\n",
      "epoch:13 step:12387 [D loss: 0.544033, acc.: 70.31%] [G loss: 0.643868]\n",
      "epoch:13 step:12388 [D loss: 0.418034, acc.: 81.25%] [G loss: 0.794696]\n",
      "epoch:13 step:12389 [D loss: 0.459710, acc.: 78.91%] [G loss: 0.757589]\n",
      "epoch:13 step:12390 [D loss: 0.581580, acc.: 64.06%] [G loss: 0.771195]\n",
      "epoch:13 step:12391 [D loss: 0.598669, acc.: 67.19%] [G loss: 0.609722]\n",
      "epoch:13 step:12392 [D loss: 0.642309, acc.: 59.38%] [G loss: 0.441974]\n",
      "epoch:13 step:12393 [D loss: 0.567140, acc.: 70.31%] [G loss: 0.649570]\n",
      "epoch:13 step:12394 [D loss: 0.600310, acc.: 67.97%] [G loss: 0.558682]\n",
      "epoch:13 step:12395 [D loss: 0.641651, acc.: 65.62%] [G loss: 0.596386]\n",
      "epoch:13 step:12396 [D loss: 0.584124, acc.: 63.28%] [G loss: 0.594351]\n",
      "epoch:13 step:12397 [D loss: 0.562423, acc.: 65.62%] [G loss: 0.523743]\n",
      "epoch:13 step:12398 [D loss: 0.571482, acc.: 65.62%] [G loss: 0.590483]\n",
      "epoch:13 step:12399 [D loss: 0.504147, acc.: 75.00%] [G loss: 0.713991]\n",
      "epoch:13 step:12400 [D loss: 0.530974, acc.: 75.78%] [G loss: 0.691305]\n",
      "##############\n",
      "[3.06294919 0.90541438 6.48408794 4.87207981 3.73383545 5.74342698\n",
      " 4.46471453 5.04117232 4.62939347 4.0550703 ]\n",
      "##########\n",
      "epoch:13 step:12401 [D loss: 0.664493, acc.: 63.28%] [G loss: 0.653970]\n",
      "epoch:13 step:12402 [D loss: 0.496901, acc.: 70.31%] [G loss: 0.620834]\n",
      "epoch:13 step:12403 [D loss: 0.492933, acc.: 75.00%] [G loss: 0.688253]\n",
      "epoch:13 step:12404 [D loss: 0.467392, acc.: 78.12%] [G loss: 0.956127]\n",
      "epoch:13 step:12405 [D loss: 0.661424, acc.: 66.41%] [G loss: 0.702452]\n",
      "epoch:13 step:12406 [D loss: 0.569402, acc.: 71.09%] [G loss: 0.605744]\n",
      "epoch:13 step:12407 [D loss: 0.666812, acc.: 60.94%] [G loss: 0.624065]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:13 step:12408 [D loss: 0.528284, acc.: 69.53%] [G loss: 0.603350]\n",
      "epoch:13 step:12409 [D loss: 0.639372, acc.: 57.81%] [G loss: 0.440391]\n",
      "epoch:13 step:12410 [D loss: 0.548259, acc.: 75.00%] [G loss: 0.555948]\n",
      "epoch:13 step:12411 [D loss: 0.525317, acc.: 72.66%] [G loss: 0.656380]\n",
      "epoch:13 step:12412 [D loss: 0.483962, acc.: 77.34%] [G loss: 0.773387]\n",
      "epoch:13 step:12413 [D loss: 0.467876, acc.: 78.12%] [G loss: 0.771996]\n",
      "epoch:13 step:12414 [D loss: 0.508883, acc.: 76.56%] [G loss: 0.779770]\n",
      "epoch:13 step:12415 [D loss: 0.566041, acc.: 70.31%] [G loss: 0.648404]\n",
      "epoch:13 step:12416 [D loss: 0.559954, acc.: 65.62%] [G loss: 0.651045]\n",
      "epoch:13 step:12417 [D loss: 0.567948, acc.: 65.62%] [G loss: 0.498655]\n",
      "epoch:13 step:12418 [D loss: 0.569618, acc.: 71.88%] [G loss: 0.502318]\n",
      "epoch:13 step:12419 [D loss: 0.559757, acc.: 75.00%] [G loss: 0.450119]\n",
      "epoch:13 step:12420 [D loss: 0.594856, acc.: 62.50%] [G loss: 0.490995]\n",
      "epoch:13 step:12421 [D loss: 0.535647, acc.: 67.19%] [G loss: 0.722813]\n",
      "epoch:13 step:12422 [D loss: 0.513479, acc.: 78.12%] [G loss: 0.553083]\n",
      "epoch:13 step:12423 [D loss: 0.501481, acc.: 76.56%] [G loss: 0.614982]\n",
      "epoch:13 step:12424 [D loss: 0.555627, acc.: 65.62%] [G loss: 0.595425]\n",
      "epoch:13 step:12425 [D loss: 0.526364, acc.: 71.09%] [G loss: 0.515672]\n",
      "epoch:13 step:12426 [D loss: 0.551019, acc.: 73.44%] [G loss: 0.725815]\n",
      "epoch:13 step:12427 [D loss: 0.603715, acc.: 66.41%] [G loss: 0.527582]\n",
      "epoch:13 step:12428 [D loss: 0.573625, acc.: 67.19%] [G loss: 0.753345]\n",
      "epoch:13 step:12429 [D loss: 0.542925, acc.: 73.44%] [G loss: 0.695733]\n",
      "epoch:13 step:12430 [D loss: 0.554753, acc.: 67.97%] [G loss: 0.499199]\n",
      "epoch:13 step:12431 [D loss: 0.606336, acc.: 60.94%] [G loss: 0.585979]\n",
      "epoch:13 step:12432 [D loss: 0.652713, acc.: 60.94%] [G loss: 0.599579]\n",
      "epoch:13 step:12433 [D loss: 0.528432, acc.: 72.66%] [G loss: 0.598378]\n",
      "epoch:13 step:12434 [D loss: 0.595196, acc.: 67.19%] [G loss: 0.507704]\n",
      "epoch:13 step:12435 [D loss: 0.561976, acc.: 70.31%] [G loss: 0.518866]\n",
      "epoch:13 step:12436 [D loss: 0.523130, acc.: 71.88%] [G loss: 0.613161]\n",
      "epoch:13 step:12437 [D loss: 0.535874, acc.: 74.22%] [G loss: 0.536924]\n",
      "epoch:13 step:12438 [D loss: 0.552619, acc.: 68.75%] [G loss: 0.568155]\n",
      "epoch:13 step:12439 [D loss: 0.567762, acc.: 70.31%] [G loss: 0.561606]\n",
      "epoch:13 step:12440 [D loss: 0.486075, acc.: 71.88%] [G loss: 0.624759]\n",
      "epoch:13 step:12441 [D loss: 0.565694, acc.: 63.28%] [G loss: 0.622457]\n",
      "epoch:13 step:12442 [D loss: 0.547732, acc.: 67.19%] [G loss: 0.603179]\n",
      "epoch:13 step:12443 [D loss: 0.543894, acc.: 71.88%] [G loss: 0.540133]\n",
      "epoch:13 step:12444 [D loss: 0.620606, acc.: 68.75%] [G loss: 0.522388]\n",
      "epoch:13 step:12445 [D loss: 0.521281, acc.: 72.66%] [G loss: 0.564494]\n",
      "epoch:13 step:12446 [D loss: 0.572300, acc.: 67.97%] [G loss: 0.613402]\n",
      "epoch:13 step:12447 [D loss: 0.590138, acc.: 64.06%] [G loss: 0.511068]\n",
      "epoch:13 step:12448 [D loss: 0.578990, acc.: 67.97%] [G loss: 0.468952]\n",
      "epoch:13 step:12449 [D loss: 0.561126, acc.: 67.97%] [G loss: 0.623956]\n",
      "epoch:13 step:12450 [D loss: 0.528648, acc.: 70.31%] [G loss: 0.533497]\n",
      "epoch:13 step:12451 [D loss: 0.476984, acc.: 78.91%] [G loss: 0.641351]\n",
      "epoch:13 step:12452 [D loss: 0.483419, acc.: 72.66%] [G loss: 0.687344]\n",
      "epoch:13 step:12453 [D loss: 0.533981, acc.: 74.22%] [G loss: 0.695712]\n",
      "epoch:13 step:12454 [D loss: 0.571779, acc.: 66.41%] [G loss: 0.520996]\n",
      "epoch:13 step:12455 [D loss: 0.520697, acc.: 75.00%] [G loss: 0.618768]\n",
      "epoch:13 step:12456 [D loss: 0.580090, acc.: 67.19%] [G loss: 0.609628]\n",
      "epoch:13 step:12457 [D loss: 0.496369, acc.: 77.34%] [G loss: 0.635586]\n",
      "epoch:13 step:12458 [D loss: 0.687070, acc.: 58.59%] [G loss: 0.443515]\n",
      "epoch:13 step:12459 [D loss: 0.624343, acc.: 64.84%] [G loss: 0.528781]\n",
      "epoch:13 step:12460 [D loss: 0.597771, acc.: 60.94%] [G loss: 0.476267]\n",
      "epoch:13 step:12461 [D loss: 0.533742, acc.: 68.75%] [G loss: 0.574565]\n",
      "epoch:13 step:12462 [D loss: 0.617820, acc.: 63.28%] [G loss: 0.527906]\n",
      "epoch:13 step:12463 [D loss: 0.583112, acc.: 62.50%] [G loss: 0.502969]\n",
      "epoch:13 step:12464 [D loss: 0.521444, acc.: 70.31%] [G loss: 0.621027]\n",
      "epoch:13 step:12465 [D loss: 0.548311, acc.: 65.62%] [G loss: 0.606821]\n",
      "epoch:13 step:12466 [D loss: 0.525167, acc.: 74.22%] [G loss: 0.507994]\n",
      "epoch:13 step:12467 [D loss: 0.560352, acc.: 70.31%] [G loss: 0.670287]\n",
      "epoch:13 step:12468 [D loss: 0.563983, acc.: 69.53%] [G loss: 0.557740]\n",
      "epoch:13 step:12469 [D loss: 0.575590, acc.: 68.75%] [G loss: 0.501219]\n",
      "epoch:13 step:12470 [D loss: 0.589986, acc.: 65.62%] [G loss: 0.751965]\n",
      "epoch:13 step:12471 [D loss: 0.551720, acc.: 64.84%] [G loss: 0.649706]\n",
      "epoch:13 step:12472 [D loss: 0.610433, acc.: 68.75%] [G loss: 0.497328]\n",
      "epoch:13 step:12473 [D loss: 0.523483, acc.: 75.00%] [G loss: 0.558374]\n",
      "epoch:13 step:12474 [D loss: 0.601472, acc.: 64.84%] [G loss: 0.463428]\n",
      "epoch:13 step:12475 [D loss: 0.564482, acc.: 65.62%] [G loss: 0.604601]\n",
      "epoch:13 step:12476 [D loss: 0.587136, acc.: 66.41%] [G loss: 0.554298]\n",
      "epoch:13 step:12477 [D loss: 0.484369, acc.: 72.66%] [G loss: 0.549666]\n",
      "epoch:13 step:12478 [D loss: 0.558725, acc.: 71.09%] [G loss: 0.523708]\n",
      "epoch:13 step:12479 [D loss: 0.455634, acc.: 83.59%] [G loss: 0.704493]\n",
      "epoch:13 step:12480 [D loss: 0.455734, acc.: 79.69%] [G loss: 0.584250]\n",
      "epoch:13 step:12481 [D loss: 0.502158, acc.: 75.00%] [G loss: 0.720345]\n",
      "epoch:13 step:12482 [D loss: 0.689724, acc.: 56.25%] [G loss: 0.518760]\n",
      "epoch:13 step:12483 [D loss: 0.541949, acc.: 74.22%] [G loss: 0.556906]\n",
      "epoch:13 step:12484 [D loss: 0.538348, acc.: 72.66%] [G loss: 0.687475]\n",
      "epoch:13 step:12485 [D loss: 0.482737, acc.: 75.00%] [G loss: 0.653558]\n",
      "epoch:13 step:12486 [D loss: 0.524698, acc.: 70.31%] [G loss: 0.680401]\n",
      "epoch:13 step:12487 [D loss: 0.519747, acc.: 73.44%] [G loss: 0.725211]\n",
      "epoch:13 step:12488 [D loss: 0.488664, acc.: 74.22%] [G loss: 0.628147]\n",
      "epoch:13 step:12489 [D loss: 0.558576, acc.: 71.09%] [G loss: 0.528514]\n",
      "epoch:13 step:12490 [D loss: 0.537152, acc.: 68.75%] [G loss: 0.649804]\n",
      "epoch:13 step:12491 [D loss: 0.504418, acc.: 71.09%] [G loss: 0.615142]\n",
      "epoch:13 step:12492 [D loss: 0.479512, acc.: 73.44%] [G loss: 0.586849]\n",
      "epoch:13 step:12493 [D loss: 0.491308, acc.: 78.12%] [G loss: 0.702042]\n",
      "epoch:13 step:12494 [D loss: 0.503998, acc.: 74.22%] [G loss: 0.899901]\n",
      "epoch:13 step:12495 [D loss: 0.435430, acc.: 82.81%] [G loss: 0.933277]\n",
      "epoch:13 step:12496 [D loss: 0.492037, acc.: 76.56%] [G loss: 0.990815]\n",
      "epoch:13 step:12497 [D loss: 0.740478, acc.: 59.38%] [G loss: 0.642970]\n",
      "epoch:13 step:12498 [D loss: 0.584448, acc.: 65.62%] [G loss: 0.656552]\n",
      "epoch:13 step:12499 [D loss: 0.589699, acc.: 66.41%] [G loss: 0.639922]\n",
      "epoch:13 step:12500 [D loss: 0.552047, acc.: 71.88%] [G loss: 0.574540]\n",
      "epoch:13 step:12501 [D loss: 0.522866, acc.: 75.78%] [G loss: 0.673560]\n",
      "epoch:13 step:12502 [D loss: 0.428925, acc.: 84.38%] [G loss: 0.754300]\n",
      "epoch:13 step:12503 [D loss: 0.587745, acc.: 64.84%] [G loss: 0.605871]\n",
      "epoch:13 step:12504 [D loss: 0.587553, acc.: 64.84%] [G loss: 0.656632]\n",
      "epoch:13 step:12505 [D loss: 0.566962, acc.: 73.44%] [G loss: 0.432857]\n",
      "epoch:13 step:12506 [D loss: 0.518996, acc.: 74.22%] [G loss: 0.633849]\n",
      "epoch:13 step:12507 [D loss: 0.569263, acc.: 66.41%] [G loss: 0.677925]\n",
      "epoch:13 step:12508 [D loss: 0.564390, acc.: 69.53%] [G loss: 0.613761]\n",
      "epoch:13 step:12509 [D loss: 0.487871, acc.: 76.56%] [G loss: 0.627282]\n",
      "epoch:13 step:12510 [D loss: 0.501155, acc.: 75.00%] [G loss: 0.675060]\n",
      "epoch:13 step:12511 [D loss: 0.574879, acc.: 71.09%] [G loss: 0.567574]\n",
      "epoch:13 step:12512 [D loss: 0.565039, acc.: 67.19%] [G loss: 0.445758]\n",
      "epoch:13 step:12513 [D loss: 0.559012, acc.: 64.84%] [G loss: 0.583302]\n",
      "epoch:13 step:12514 [D loss: 0.531312, acc.: 69.53%] [G loss: 0.517266]\n",
      "epoch:13 step:12515 [D loss: 0.539229, acc.: 75.00%] [G loss: 0.550196]\n",
      "epoch:13 step:12516 [D loss: 0.492267, acc.: 76.56%] [G loss: 0.597077]\n",
      "epoch:13 step:12517 [D loss: 0.534580, acc.: 76.56%] [G loss: 0.631721]\n",
      "epoch:13 step:12518 [D loss: 0.543736, acc.: 69.53%] [G loss: 0.475328]\n",
      "epoch:13 step:12519 [D loss: 0.552744, acc.: 70.31%] [G loss: 0.527087]\n",
      "epoch:13 step:12520 [D loss: 0.511220, acc.: 75.00%] [G loss: 0.616552]\n",
      "epoch:13 step:12521 [D loss: 0.476163, acc.: 77.34%] [G loss: 0.770974]\n",
      "epoch:13 step:12522 [D loss: 0.580290, acc.: 70.31%] [G loss: 0.607037]\n",
      "epoch:13 step:12523 [D loss: 0.651355, acc.: 60.94%] [G loss: 0.510173]\n",
      "epoch:13 step:12524 [D loss: 0.539584, acc.: 71.88%] [G loss: 0.691359]\n",
      "epoch:13 step:12525 [D loss: 0.429334, acc.: 79.69%] [G loss: 0.887447]\n",
      "epoch:13 step:12526 [D loss: 0.553815, acc.: 68.75%] [G loss: 0.877481]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:13 step:12527 [D loss: 0.520733, acc.: 73.44%] [G loss: 0.974184]\n",
      "epoch:13 step:12528 [D loss: 0.484739, acc.: 76.56%] [G loss: 0.967237]\n",
      "epoch:13 step:12529 [D loss: 0.668674, acc.: 60.16%] [G loss: 0.623465]\n",
      "epoch:13 step:12530 [D loss: 0.702230, acc.: 57.81%] [G loss: 0.521272]\n",
      "epoch:13 step:12531 [D loss: 0.471784, acc.: 79.69%] [G loss: 0.589749]\n",
      "epoch:13 step:12532 [D loss: 0.535756, acc.: 71.09%] [G loss: 0.653549]\n",
      "epoch:13 step:12533 [D loss: 0.560785, acc.: 67.19%] [G loss: 0.711538]\n",
      "epoch:13 step:12534 [D loss: 0.560355, acc.: 66.41%] [G loss: 0.736678]\n",
      "epoch:13 step:12535 [D loss: 0.432590, acc.: 78.12%] [G loss: 0.847792]\n",
      "epoch:13 step:12536 [D loss: 0.597966, acc.: 68.75%] [G loss: 0.973513]\n",
      "epoch:13 step:12537 [D loss: 0.583854, acc.: 63.28%] [G loss: 0.596748]\n",
      "epoch:13 step:12538 [D loss: 0.483279, acc.: 73.44%] [G loss: 0.728167]\n",
      "epoch:13 step:12539 [D loss: 0.474060, acc.: 78.12%] [G loss: 0.751539]\n",
      "epoch:13 step:12540 [D loss: 0.491287, acc.: 77.34%] [G loss: 0.708105]\n",
      "epoch:13 step:12541 [D loss: 0.506850, acc.: 70.31%] [G loss: 0.786830]\n",
      "epoch:13 step:12542 [D loss: 0.542743, acc.: 73.44%] [G loss: 0.667528]\n",
      "epoch:13 step:12543 [D loss: 0.620916, acc.: 65.62%] [G loss: 0.688454]\n",
      "epoch:13 step:12544 [D loss: 0.576273, acc.: 66.41%] [G loss: 0.513632]\n",
      "epoch:13 step:12545 [D loss: 0.514758, acc.: 75.00%] [G loss: 0.649728]\n",
      "epoch:13 step:12546 [D loss: 0.589249, acc.: 65.62%] [G loss: 0.554845]\n",
      "epoch:13 step:12547 [D loss: 0.537912, acc.: 67.97%] [G loss: 0.540721]\n",
      "epoch:13 step:12548 [D loss: 0.569706, acc.: 68.75%] [G loss: 0.538791]\n",
      "epoch:13 step:12549 [D loss: 0.552432, acc.: 70.31%] [G loss: 0.604502]\n",
      "epoch:13 step:12550 [D loss: 0.462612, acc.: 78.12%] [G loss: 0.771809]\n",
      "epoch:13 step:12551 [D loss: 0.548811, acc.: 70.31%] [G loss: 0.635984]\n",
      "epoch:13 step:12552 [D loss: 0.561387, acc.: 66.41%] [G loss: 0.591378]\n",
      "epoch:13 step:12553 [D loss: 0.569135, acc.: 68.75%] [G loss: 0.596810]\n",
      "epoch:13 step:12554 [D loss: 0.579342, acc.: 64.84%] [G loss: 0.495815]\n",
      "epoch:13 step:12555 [D loss: 0.438593, acc.: 81.25%] [G loss: 0.645365]\n",
      "epoch:13 step:12556 [D loss: 0.623516, acc.: 64.06%] [G loss: 0.541526]\n",
      "epoch:13 step:12557 [D loss: 0.706013, acc.: 56.25%] [G loss: 0.469681]\n",
      "epoch:13 step:12558 [D loss: 0.598781, acc.: 64.84%] [G loss: 0.426205]\n",
      "epoch:13 step:12559 [D loss: 0.520701, acc.: 74.22%] [G loss: 0.573395]\n",
      "epoch:13 step:12560 [D loss: 0.597093, acc.: 64.06%] [G loss: 0.535957]\n",
      "epoch:13 step:12561 [D loss: 0.565257, acc.: 69.53%] [G loss: 0.502498]\n",
      "epoch:13 step:12562 [D loss: 0.484907, acc.: 74.22%] [G loss: 0.618956]\n",
      "epoch:13 step:12563 [D loss: 0.538975, acc.: 71.09%] [G loss: 0.593756]\n",
      "epoch:13 step:12564 [D loss: 0.567769, acc.: 71.09%] [G loss: 0.530475]\n",
      "epoch:13 step:12565 [D loss: 0.556891, acc.: 66.41%] [G loss: 0.474559]\n",
      "epoch:13 step:12566 [D loss: 0.493211, acc.: 74.22%] [G loss: 0.540701]\n",
      "epoch:13 step:12567 [D loss: 0.621645, acc.: 63.28%] [G loss: 0.520886]\n",
      "epoch:13 step:12568 [D loss: 0.550228, acc.: 69.53%] [G loss: 0.573556]\n",
      "epoch:13 step:12569 [D loss: 0.526416, acc.: 73.44%] [G loss: 0.669807]\n",
      "epoch:13 step:12570 [D loss: 0.637270, acc.: 67.19%] [G loss: 0.777728]\n",
      "epoch:13 step:12571 [D loss: 0.592200, acc.: 65.62%] [G loss: 0.488621]\n",
      "epoch:13 step:12572 [D loss: 0.542038, acc.: 70.31%] [G loss: 0.623801]\n",
      "epoch:13 step:12573 [D loss: 0.479547, acc.: 76.56%] [G loss: 0.632966]\n",
      "epoch:13 step:12574 [D loss: 0.594476, acc.: 68.75%] [G loss: 0.488406]\n",
      "epoch:13 step:12575 [D loss: 0.542302, acc.: 71.88%] [G loss: 0.455259]\n",
      "epoch:13 step:12576 [D loss: 0.548137, acc.: 70.31%] [G loss: 0.508314]\n",
      "epoch:13 step:12577 [D loss: 0.567150, acc.: 70.31%] [G loss: 0.582950]\n",
      "epoch:13 step:12578 [D loss: 0.543801, acc.: 69.53%] [G loss: 0.571259]\n",
      "epoch:13 step:12579 [D loss: 0.522626, acc.: 67.97%] [G loss: 0.560569]\n",
      "epoch:13 step:12580 [D loss: 0.542146, acc.: 75.00%] [G loss: 0.739827]\n",
      "epoch:13 step:12581 [D loss: 0.631129, acc.: 56.25%] [G loss: 0.478241]\n",
      "epoch:13 step:12582 [D loss: 0.656844, acc.: 55.47%] [G loss: 0.418163]\n",
      "epoch:13 step:12583 [D loss: 0.486469, acc.: 76.56%] [G loss: 0.738746]\n",
      "epoch:13 step:12584 [D loss: 0.505375, acc.: 72.66%] [G loss: 0.842803]\n",
      "epoch:13 step:12585 [D loss: 0.622666, acc.: 65.62%] [G loss: 0.625797]\n",
      "epoch:13 step:12586 [D loss: 0.530435, acc.: 71.09%] [G loss: 0.587139]\n",
      "epoch:13 step:12587 [D loss: 0.504278, acc.: 73.44%] [G loss: 0.742361]\n",
      "epoch:13 step:12588 [D loss: 0.635105, acc.: 60.94%] [G loss: 0.837457]\n",
      "epoch:13 step:12589 [D loss: 0.590476, acc.: 71.09%] [G loss: 0.727107]\n",
      "epoch:13 step:12590 [D loss: 0.558817, acc.: 66.41%] [G loss: 0.563230]\n",
      "epoch:13 step:12591 [D loss: 0.565876, acc.: 67.97%] [G loss: 0.572132]\n",
      "epoch:13 step:12592 [D loss: 0.620201, acc.: 64.06%] [G loss: 0.562778]\n",
      "epoch:13 step:12593 [D loss: 0.587387, acc.: 64.06%] [G loss: 0.461887]\n",
      "epoch:13 step:12594 [D loss: 0.513167, acc.: 73.44%] [G loss: 0.679985]\n",
      "epoch:13 step:12595 [D loss: 0.552660, acc.: 67.97%] [G loss: 0.619141]\n",
      "epoch:13 step:12596 [D loss: 0.571440, acc.: 68.75%] [G loss: 0.649989]\n",
      "epoch:13 step:12597 [D loss: 0.515522, acc.: 78.12%] [G loss: 0.758254]\n",
      "epoch:13 step:12598 [D loss: 0.619388, acc.: 66.41%] [G loss: 0.703251]\n",
      "epoch:13 step:12599 [D loss: 0.698779, acc.: 58.59%] [G loss: 0.470654]\n",
      "epoch:13 step:12600 [D loss: 0.582627, acc.: 64.06%] [G loss: 0.671507]\n",
      "##############\n",
      "[3.11704773 1.61876258 6.29294424 4.82346666 3.90247425 5.72220061\n",
      " 4.50665818 4.86411333 4.58010043 3.95136435]\n",
      "##########\n",
      "epoch:13 step:12601 [D loss: 0.604422, acc.: 61.72%] [G loss: 0.639781]\n",
      "epoch:13 step:12602 [D loss: 0.570753, acc.: 65.62%] [G loss: 0.690140]\n",
      "epoch:13 step:12603 [D loss: 0.544342, acc.: 76.56%] [G loss: 0.576761]\n",
      "epoch:13 step:12604 [D loss: 0.632016, acc.: 64.84%] [G loss: 0.526996]\n",
      "epoch:13 step:12605 [D loss: 0.566565, acc.: 64.06%] [G loss: 0.628271]\n",
      "epoch:13 step:12606 [D loss: 0.533394, acc.: 75.00%] [G loss: 0.694297]\n",
      "epoch:13 step:12607 [D loss: 0.498382, acc.: 72.66%] [G loss: 0.693087]\n",
      "epoch:13 step:12608 [D loss: 0.487338, acc.: 77.34%] [G loss: 0.802478]\n",
      "epoch:13 step:12609 [D loss: 0.565381, acc.: 64.06%] [G loss: 0.728398]\n",
      "epoch:13 step:12610 [D loss: 0.492369, acc.: 74.22%] [G loss: 0.764185]\n",
      "epoch:13 step:12611 [D loss: 0.533666, acc.: 70.31%] [G loss: 0.466433]\n",
      "epoch:13 step:12612 [D loss: 0.564579, acc.: 70.31%] [G loss: 0.726296]\n",
      "epoch:13 step:12613 [D loss: 0.598833, acc.: 65.62%] [G loss: 0.516355]\n",
      "epoch:13 step:12614 [D loss: 0.577757, acc.: 67.19%] [G loss: 0.569325]\n",
      "epoch:13 step:12615 [D loss: 0.538236, acc.: 73.44%] [G loss: 0.602157]\n",
      "epoch:13 step:12616 [D loss: 0.530050, acc.: 74.22%] [G loss: 0.625512]\n",
      "epoch:13 step:12617 [D loss: 0.502457, acc.: 74.22%] [G loss: 0.632179]\n",
      "epoch:13 step:12618 [D loss: 0.646868, acc.: 69.53%] [G loss: 0.737080]\n",
      "epoch:13 step:12619 [D loss: 0.570569, acc.: 67.19%] [G loss: 0.540532]\n",
      "epoch:13 step:12620 [D loss: 0.514158, acc.: 79.69%] [G loss: 0.608773]\n",
      "epoch:13 step:12621 [D loss: 0.508778, acc.: 72.66%] [G loss: 0.617276]\n",
      "epoch:13 step:12622 [D loss: 0.519754, acc.: 71.88%] [G loss: 0.592597]\n",
      "epoch:13 step:12623 [D loss: 0.611737, acc.: 68.75%] [G loss: 0.662554]\n",
      "epoch:13 step:12624 [D loss: 0.518845, acc.: 75.00%] [G loss: 0.634881]\n",
      "epoch:13 step:12625 [D loss: 0.501860, acc.: 74.22%] [G loss: 0.774156]\n",
      "epoch:13 step:12626 [D loss: 0.566381, acc.: 69.53%] [G loss: 0.721067]\n",
      "epoch:13 step:12627 [D loss: 0.509123, acc.: 75.78%] [G loss: 0.691340]\n",
      "epoch:13 step:12628 [D loss: 0.545703, acc.: 67.97%] [G loss: 0.714975]\n",
      "epoch:13 step:12629 [D loss: 0.538758, acc.: 75.78%] [G loss: 0.802760]\n",
      "epoch:13 step:12630 [D loss: 0.527578, acc.: 71.88%] [G loss: 0.853656]\n",
      "epoch:13 step:12631 [D loss: 0.556876, acc.: 73.44%] [G loss: 0.665461]\n",
      "epoch:13 step:12632 [D loss: 0.466032, acc.: 74.22%] [G loss: 0.905369]\n",
      "epoch:13 step:12633 [D loss: 0.508476, acc.: 75.00%] [G loss: 0.885545]\n",
      "epoch:13 step:12634 [D loss: 0.540110, acc.: 71.09%] [G loss: 0.738205]\n",
      "epoch:13 step:12635 [D loss: 0.595981, acc.: 68.75%] [G loss: 0.660641]\n",
      "epoch:13 step:12636 [D loss: 0.604852, acc.: 67.19%] [G loss: 0.513697]\n",
      "epoch:13 step:12637 [D loss: 0.648302, acc.: 61.72%] [G loss: 0.571622]\n",
      "epoch:13 step:12638 [D loss: 0.506031, acc.: 74.22%] [G loss: 0.676280]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:13 step:12639 [D loss: 0.649371, acc.: 63.28%] [G loss: 0.583537]\n",
      "epoch:13 step:12640 [D loss: 0.537815, acc.: 69.53%] [G loss: 0.624218]\n",
      "epoch:13 step:12641 [D loss: 0.532068, acc.: 69.53%] [G loss: 0.653696]\n",
      "epoch:13 step:12642 [D loss: 0.531658, acc.: 72.66%] [G loss: 0.747893]\n",
      "epoch:13 step:12643 [D loss: 0.593585, acc.: 63.28%] [G loss: 0.649572]\n",
      "epoch:13 step:12644 [D loss: 0.566372, acc.: 67.97%] [G loss: 0.684827]\n",
      "epoch:13 step:12645 [D loss: 0.550734, acc.: 69.53%] [G loss: 0.604351]\n",
      "epoch:13 step:12646 [D loss: 0.608272, acc.: 66.41%] [G loss: 0.629018]\n",
      "epoch:13 step:12647 [D loss: 0.555171, acc.: 68.75%] [G loss: 0.546804]\n",
      "epoch:13 step:12648 [D loss: 0.561020, acc.: 71.09%] [G loss: 0.675665]\n",
      "epoch:13 step:12649 [D loss: 0.556024, acc.: 67.97%] [G loss: 0.615229]\n",
      "epoch:13 step:12650 [D loss: 0.544760, acc.: 74.22%] [G loss: 0.565246]\n",
      "epoch:13 step:12651 [D loss: 0.555550, acc.: 73.44%] [G loss: 0.694799]\n",
      "epoch:13 step:12652 [D loss: 0.468184, acc.: 77.34%] [G loss: 0.745181]\n",
      "epoch:13 step:12653 [D loss: 0.532049, acc.: 71.88%] [G loss: 0.860964]\n",
      "epoch:13 step:12654 [D loss: 0.676797, acc.: 59.38%] [G loss: 0.755209]\n",
      "epoch:13 step:12655 [D loss: 0.556562, acc.: 66.41%] [G loss: 0.623128]\n",
      "epoch:13 step:12656 [D loss: 0.484095, acc.: 71.88%] [G loss: 0.664665]\n",
      "epoch:13 step:12657 [D loss: 0.520275, acc.: 75.78%] [G loss: 0.547761]\n",
      "epoch:13 step:12658 [D loss: 0.675318, acc.: 57.81%] [G loss: 0.514523]\n",
      "epoch:13 step:12659 [D loss: 0.550906, acc.: 70.31%] [G loss: 0.492834]\n",
      "epoch:13 step:12660 [D loss: 0.519393, acc.: 78.12%] [G loss: 0.498042]\n",
      "epoch:13 step:12661 [D loss: 0.671543, acc.: 62.50%] [G loss: 0.557172]\n",
      "epoch:13 step:12662 [D loss: 0.537553, acc.: 73.44%] [G loss: 0.446422]\n",
      "epoch:13 step:12663 [D loss: 0.626939, acc.: 63.28%] [G loss: 0.354338]\n",
      "epoch:13 step:12664 [D loss: 0.517004, acc.: 74.22%] [G loss: 0.559999]\n",
      "epoch:13 step:12665 [D loss: 0.504712, acc.: 71.09%] [G loss: 0.604367]\n",
      "epoch:13 step:12666 [D loss: 0.592939, acc.: 66.41%] [G loss: 0.776402]\n",
      "epoch:13 step:12667 [D loss: 0.579077, acc.: 64.84%] [G loss: 0.682261]\n",
      "epoch:13 step:12668 [D loss: 0.556810, acc.: 68.75%] [G loss: 0.496992]\n",
      "epoch:13 step:12669 [D loss: 0.475914, acc.: 74.22%] [G loss: 0.719058]\n",
      "epoch:13 step:12670 [D loss: 0.572507, acc.: 67.19%] [G loss: 0.587526]\n",
      "epoch:13 step:12671 [D loss: 0.526732, acc.: 73.44%] [G loss: 0.555992]\n",
      "epoch:13 step:12672 [D loss: 0.583986, acc.: 70.31%] [G loss: 0.556953]\n",
      "epoch:13 step:12673 [D loss: 0.625378, acc.: 64.06%] [G loss: 0.523161]\n",
      "epoch:13 step:12674 [D loss: 0.584369, acc.: 71.88%] [G loss: 0.474874]\n",
      "epoch:13 step:12675 [D loss: 0.582813, acc.: 68.75%] [G loss: 0.453585]\n",
      "epoch:13 step:12676 [D loss: 0.528537, acc.: 71.09%] [G loss: 0.461384]\n",
      "epoch:13 step:12677 [D loss: 0.623350, acc.: 63.28%] [G loss: 0.510204]\n",
      "epoch:13 step:12678 [D loss: 0.558009, acc.: 74.22%] [G loss: 0.689200]\n",
      "epoch:13 step:12679 [D loss: 0.522069, acc.: 73.44%] [G loss: 0.578168]\n",
      "epoch:13 step:12680 [D loss: 0.499559, acc.: 75.78%] [G loss: 0.596048]\n",
      "epoch:13 step:12681 [D loss: 0.631629, acc.: 66.41%] [G loss: 0.461146]\n",
      "epoch:13 step:12682 [D loss: 0.635790, acc.: 62.50%] [G loss: 0.439002]\n",
      "epoch:13 step:12683 [D loss: 0.620492, acc.: 64.84%] [G loss: 0.445434]\n",
      "epoch:13 step:12684 [D loss: 0.513336, acc.: 71.88%] [G loss: 0.579262]\n",
      "epoch:13 step:12685 [D loss: 0.490104, acc.: 78.12%] [G loss: 0.643827]\n",
      "epoch:13 step:12686 [D loss: 0.537583, acc.: 73.44%] [G loss: 0.643575]\n",
      "epoch:13 step:12687 [D loss: 0.560906, acc.: 72.66%] [G loss: 0.641305]\n",
      "epoch:13 step:12688 [D loss: 0.483642, acc.: 76.56%] [G loss: 0.842877]\n",
      "epoch:13 step:12689 [D loss: 0.407695, acc.: 80.47%] [G loss: 0.942539]\n",
      "epoch:13 step:12690 [D loss: 0.554649, acc.: 74.22%] [G loss: 0.688257]\n",
      "epoch:13 step:12691 [D loss: 0.588362, acc.: 68.75%] [G loss: 0.659879]\n",
      "epoch:13 step:12692 [D loss: 0.662277, acc.: 56.25%] [G loss: 0.469410]\n",
      "epoch:13 step:12693 [D loss: 0.624622, acc.: 60.94%] [G loss: 0.428954]\n",
      "epoch:13 step:12694 [D loss: 0.541422, acc.: 71.09%] [G loss: 0.581732]\n",
      "epoch:13 step:12695 [D loss: 0.454361, acc.: 79.69%] [G loss: 0.725001]\n",
      "epoch:13 step:12696 [D loss: 0.504273, acc.: 75.78%] [G loss: 0.633025]\n",
      "epoch:13 step:12697 [D loss: 0.448147, acc.: 83.59%] [G loss: 0.648934]\n",
      "epoch:13 step:12698 [D loss: 0.499128, acc.: 75.78%] [G loss: 0.651272]\n",
      "epoch:13 step:12699 [D loss: 0.587483, acc.: 65.62%] [G loss: 0.571873]\n",
      "epoch:13 step:12700 [D loss: 0.492278, acc.: 75.78%] [G loss: 0.634347]\n",
      "epoch:13 step:12701 [D loss: 0.459327, acc.: 75.78%] [G loss: 0.900294]\n",
      "epoch:13 step:12702 [D loss: 0.543461, acc.: 67.19%] [G loss: 0.538649]\n",
      "epoch:13 step:12703 [D loss: 0.596094, acc.: 67.97%] [G loss: 0.597359]\n",
      "epoch:13 step:12704 [D loss: 0.490868, acc.: 77.34%] [G loss: 0.734349]\n",
      "epoch:13 step:12705 [D loss: 0.544754, acc.: 73.44%] [G loss: 0.630771]\n",
      "epoch:13 step:12706 [D loss: 0.569894, acc.: 70.31%] [G loss: 0.677414]\n",
      "epoch:13 step:12707 [D loss: 0.552634, acc.: 69.53%] [G loss: 0.506432]\n",
      "epoch:13 step:12708 [D loss: 0.523834, acc.: 71.88%] [G loss: 0.617476]\n",
      "epoch:13 step:12709 [D loss: 0.658343, acc.: 58.59%] [G loss: 0.425130]\n",
      "epoch:13 step:12710 [D loss: 0.600790, acc.: 68.75%] [G loss: 0.615248]\n",
      "epoch:13 step:12711 [D loss: 0.555111, acc.: 68.75%] [G loss: 0.730334]\n",
      "epoch:13 step:12712 [D loss: 0.586030, acc.: 65.62%] [G loss: 0.555023]\n",
      "epoch:13 step:12713 [D loss: 0.562499, acc.: 65.62%] [G loss: 0.487380]\n",
      "epoch:13 step:12714 [D loss: 0.503365, acc.: 75.00%] [G loss: 0.513491]\n",
      "epoch:13 step:12715 [D loss: 0.492873, acc.: 77.34%] [G loss: 0.701879]\n",
      "epoch:13 step:12716 [D loss: 0.622218, acc.: 62.50%] [G loss: 0.615093]\n",
      "epoch:13 step:12717 [D loss: 0.523328, acc.: 72.66%] [G loss: 0.470716]\n",
      "epoch:13 step:12718 [D loss: 0.588084, acc.: 66.41%] [G loss: 0.573568]\n",
      "epoch:13 step:12719 [D loss: 0.522615, acc.: 71.88%] [G loss: 0.607494]\n",
      "epoch:13 step:12720 [D loss: 0.500898, acc.: 73.44%] [G loss: 0.506910]\n",
      "epoch:13 step:12721 [D loss: 0.599891, acc.: 65.62%] [G loss: 0.479245]\n",
      "epoch:13 step:12722 [D loss: 0.579829, acc.: 66.41%] [G loss: 0.555791]\n",
      "epoch:13 step:12723 [D loss: 0.636654, acc.: 64.84%] [G loss: 0.561548]\n",
      "epoch:13 step:12724 [D loss: 0.654767, acc.: 59.38%] [G loss: 0.614724]\n",
      "epoch:13 step:12725 [D loss: 0.564253, acc.: 67.19%] [G loss: 0.627239]\n",
      "epoch:13 step:12726 [D loss: 0.554881, acc.: 70.31%] [G loss: 0.795511]\n",
      "epoch:13 step:12727 [D loss: 0.528203, acc.: 74.22%] [G loss: 0.618691]\n",
      "epoch:13 step:12728 [D loss: 0.571656, acc.: 65.62%] [G loss: 0.682046]\n",
      "epoch:13 step:12729 [D loss: 0.509475, acc.: 69.53%] [G loss: 0.594054]\n",
      "epoch:13 step:12730 [D loss: 0.515386, acc.: 74.22%] [G loss: 0.573245]\n",
      "epoch:13 step:12731 [D loss: 0.563668, acc.: 67.19%] [G loss: 0.577284]\n",
      "epoch:13 step:12732 [D loss: 0.509851, acc.: 75.00%] [G loss: 0.563538]\n",
      "epoch:13 step:12733 [D loss: 0.493614, acc.: 75.00%] [G loss: 0.528723]\n",
      "epoch:13 step:12734 [D loss: 0.576355, acc.: 67.19%] [G loss: 0.591568]\n",
      "epoch:13 step:12735 [D loss: 0.462779, acc.: 78.12%] [G loss: 0.565062]\n",
      "epoch:13 step:12736 [D loss: 0.474586, acc.: 75.00%] [G loss: 0.680862]\n",
      "epoch:13 step:12737 [D loss: 0.592822, acc.: 64.06%] [G loss: 0.686852]\n",
      "epoch:13 step:12738 [D loss: 0.508083, acc.: 74.22%] [G loss: 0.617076]\n",
      "epoch:13 step:12739 [D loss: 0.508809, acc.: 72.66%] [G loss: 0.575518]\n",
      "epoch:13 step:12740 [D loss: 0.590069, acc.: 62.50%] [G loss: 0.727217]\n",
      "epoch:13 step:12741 [D loss: 0.542696, acc.: 70.31%] [G loss: 0.548548]\n",
      "epoch:13 step:12742 [D loss: 0.571288, acc.: 69.53%] [G loss: 0.602411]\n",
      "epoch:13 step:12743 [D loss: 0.588182, acc.: 67.97%] [G loss: 0.464462]\n",
      "epoch:13 step:12744 [D loss: 0.591933, acc.: 67.97%] [G loss: 0.541337]\n",
      "epoch:13 step:12745 [D loss: 0.524081, acc.: 69.53%] [G loss: 0.677444]\n",
      "epoch:13 step:12746 [D loss: 0.532900, acc.: 75.00%] [G loss: 0.659305]\n",
      "epoch:13 step:12747 [D loss: 0.677931, acc.: 57.03%] [G loss: 0.593570]\n",
      "epoch:13 step:12748 [D loss: 0.534389, acc.: 71.88%] [G loss: 0.702698]\n",
      "epoch:13 step:12749 [D loss: 0.545603, acc.: 71.09%] [G loss: 0.702545]\n",
      "epoch:13 step:12750 [D loss: 0.562097, acc.: 75.78%] [G loss: 0.537021]\n",
      "epoch:13 step:12751 [D loss: 0.471365, acc.: 78.91%] [G loss: 0.637491]\n",
      "epoch:13 step:12752 [D loss: 0.586323, acc.: 65.62%] [G loss: 0.563668]\n",
      "epoch:13 step:12753 [D loss: 0.591018, acc.: 68.75%] [G loss: 0.649030]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:13 step:12754 [D loss: 0.568250, acc.: 69.53%] [G loss: 0.544540]\n",
      "epoch:13 step:12755 [D loss: 0.480014, acc.: 74.22%] [G loss: 0.777573]\n",
      "epoch:13 step:12756 [D loss: 0.467449, acc.: 77.34%] [G loss: 0.918653]\n",
      "epoch:13 step:12757 [D loss: 0.591777, acc.: 69.53%] [G loss: 0.642038]\n",
      "epoch:13 step:12758 [D loss: 0.585229, acc.: 64.84%] [G loss: 0.613504]\n",
      "epoch:13 step:12759 [D loss: 0.526723, acc.: 70.31%] [G loss: 0.750875]\n",
      "epoch:13 step:12760 [D loss: 0.513302, acc.: 73.44%] [G loss: 0.608348]\n",
      "epoch:13 step:12761 [D loss: 0.573912, acc.: 64.84%] [G loss: 0.798790]\n",
      "epoch:13 step:12762 [D loss: 0.520166, acc.: 73.44%] [G loss: 0.598588]\n",
      "epoch:13 step:12763 [D loss: 0.452444, acc.: 78.12%] [G loss: 0.739397]\n",
      "epoch:13 step:12764 [D loss: 0.543504, acc.: 68.75%] [G loss: 0.767900]\n",
      "epoch:13 step:12765 [D loss: 0.625447, acc.: 62.50%] [G loss: 0.549978]\n",
      "epoch:13 step:12766 [D loss: 0.529560, acc.: 68.75%] [G loss: 0.723370]\n",
      "epoch:13 step:12767 [D loss: 0.605243, acc.: 64.84%] [G loss: 0.599769]\n",
      "epoch:13 step:12768 [D loss: 0.579700, acc.: 64.84%] [G loss: 0.520748]\n",
      "epoch:13 step:12769 [D loss: 0.580881, acc.: 69.53%] [G loss: 0.681707]\n",
      "epoch:13 step:12770 [D loss: 0.549531, acc.: 68.75%] [G loss: 0.531634]\n",
      "epoch:13 step:12771 [D loss: 0.610541, acc.: 61.72%] [G loss: 0.589696]\n",
      "epoch:13 step:12772 [D loss: 0.606999, acc.: 67.19%] [G loss: 0.532298]\n",
      "epoch:13 step:12773 [D loss: 0.544644, acc.: 71.88%] [G loss: 0.617549]\n",
      "epoch:13 step:12774 [D loss: 0.539261, acc.: 69.53%] [G loss: 0.527264]\n",
      "epoch:13 step:12775 [D loss: 0.593571, acc.: 69.53%] [G loss: 0.457719]\n",
      "epoch:13 step:12776 [D loss: 0.523473, acc.: 77.34%] [G loss: 0.476011]\n",
      "epoch:13 step:12777 [D loss: 0.586982, acc.: 67.19%] [G loss: 0.543827]\n",
      "epoch:13 step:12778 [D loss: 0.588598, acc.: 65.62%] [G loss: 0.559081]\n",
      "epoch:13 step:12779 [D loss: 0.512329, acc.: 74.22%] [G loss: 0.614462]\n",
      "epoch:13 step:12780 [D loss: 0.544796, acc.: 71.88%] [G loss: 0.549575]\n",
      "epoch:13 step:12781 [D loss: 0.582949, acc.: 67.19%] [G loss: 0.553497]\n",
      "epoch:13 step:12782 [D loss: 0.541392, acc.: 71.88%] [G loss: 0.601428]\n",
      "epoch:13 step:12783 [D loss: 0.481993, acc.: 75.00%] [G loss: 0.737588]\n",
      "epoch:13 step:12784 [D loss: 0.534449, acc.: 72.66%] [G loss: 0.641446]\n",
      "epoch:13 step:12785 [D loss: 0.590356, acc.: 66.41%] [G loss: 0.558191]\n",
      "epoch:13 step:12786 [D loss: 0.462852, acc.: 79.69%] [G loss: 0.598605]\n",
      "epoch:13 step:12787 [D loss: 0.630746, acc.: 64.06%] [G loss: 0.479784]\n",
      "epoch:13 step:12788 [D loss: 0.514879, acc.: 77.34%] [G loss: 0.451184]\n",
      "epoch:13 step:12789 [D loss: 0.569849, acc.: 67.97%] [G loss: 0.579445]\n",
      "epoch:13 step:12790 [D loss: 0.592528, acc.: 65.62%] [G loss: 0.371847]\n",
      "epoch:13 step:12791 [D loss: 0.607004, acc.: 64.84%] [G loss: 0.510525]\n",
      "epoch:13 step:12792 [D loss: 0.504816, acc.: 73.44%] [G loss: 0.502241]\n",
      "epoch:13 step:12793 [D loss: 0.542280, acc.: 70.31%] [G loss: 0.564368]\n",
      "epoch:13 step:12794 [D loss: 0.556387, acc.: 67.97%] [G loss: 0.530126]\n",
      "epoch:13 step:12795 [D loss: 0.578134, acc.: 65.62%] [G loss: 0.671636]\n",
      "epoch:13 step:12796 [D loss: 0.622237, acc.: 68.75%] [G loss: 0.681480]\n",
      "epoch:13 step:12797 [D loss: 0.592930, acc.: 64.06%] [G loss: 0.612078]\n",
      "epoch:13 step:12798 [D loss: 0.556187, acc.: 67.97%] [G loss: 0.494754]\n",
      "epoch:13 step:12799 [D loss: 0.552335, acc.: 68.75%] [G loss: 0.623612]\n",
      "epoch:13 step:12800 [D loss: 0.550366, acc.: 69.53%] [G loss: 0.547587]\n",
      "##############\n",
      "[3.30633311 0.86302406 6.40864745 5.0169805  4.01216086 5.6976419\n",
      " 4.60506324 4.78836962 4.65958869 4.26235381]\n",
      "##########\n",
      "epoch:13 step:12801 [D loss: 0.522259, acc.: 67.19%] [G loss: 0.557859]\n",
      "epoch:13 step:12802 [D loss: 0.579894, acc.: 67.97%] [G loss: 0.543625]\n",
      "epoch:13 step:12803 [D loss: 0.542283, acc.: 72.66%] [G loss: 0.640380]\n",
      "epoch:13 step:12804 [D loss: 0.484407, acc.: 75.78%] [G loss: 0.663843]\n",
      "epoch:13 step:12805 [D loss: 0.526163, acc.: 71.88%] [G loss: 0.706011]\n",
      "epoch:13 step:12806 [D loss: 0.601882, acc.: 65.62%] [G loss: 0.627599]\n",
      "epoch:13 step:12807 [D loss: 0.533458, acc.: 67.97%] [G loss: 0.615035]\n",
      "epoch:13 step:12808 [D loss: 0.547848, acc.: 69.53%] [G loss: 0.596818]\n",
      "epoch:13 step:12809 [D loss: 0.560981, acc.: 64.06%] [G loss: 0.643425]\n",
      "epoch:13 step:12810 [D loss: 0.537982, acc.: 69.53%] [G loss: 0.646465]\n",
      "epoch:13 step:12811 [D loss: 0.529485, acc.: 71.88%] [G loss: 0.508865]\n",
      "epoch:13 step:12812 [D loss: 0.483815, acc.: 78.12%] [G loss: 0.584449]\n",
      "epoch:13 step:12813 [D loss: 0.502105, acc.: 75.00%] [G loss: 0.613851]\n",
      "epoch:13 step:12814 [D loss: 0.530518, acc.: 74.22%] [G loss: 0.657699]\n",
      "epoch:13 step:12815 [D loss: 0.492725, acc.: 76.56%] [G loss: 0.651432]\n",
      "epoch:13 step:12816 [D loss: 0.515943, acc.: 68.75%] [G loss: 0.688852]\n",
      "epoch:13 step:12817 [D loss: 0.593450, acc.: 71.09%] [G loss: 0.556186]\n",
      "epoch:13 step:12818 [D loss: 0.504107, acc.: 74.22%] [G loss: 0.567447]\n",
      "epoch:13 step:12819 [D loss: 0.511356, acc.: 73.44%] [G loss: 0.550845]\n",
      "epoch:13 step:12820 [D loss: 0.564267, acc.: 67.97%] [G loss: 0.588550]\n",
      "epoch:13 step:12821 [D loss: 0.567642, acc.: 67.97%] [G loss: 0.557799]\n",
      "epoch:13 step:12822 [D loss: 0.500652, acc.: 75.00%] [G loss: 0.909118]\n",
      "epoch:13 step:12823 [D loss: 0.456113, acc.: 75.78%] [G loss: 0.734280]\n",
      "epoch:13 step:12824 [D loss: 0.562877, acc.: 69.53%] [G loss: 0.627830]\n",
      "epoch:13 step:12825 [D loss: 0.549887, acc.: 70.31%] [G loss: 0.586382]\n",
      "epoch:13 step:12826 [D loss: 0.556892, acc.: 68.75%] [G loss: 0.512113]\n",
      "epoch:13 step:12827 [D loss: 0.582346, acc.: 64.06%] [G loss: 0.533554]\n",
      "epoch:13 step:12828 [D loss: 0.456590, acc.: 78.91%] [G loss: 0.857311]\n",
      "epoch:13 step:12829 [D loss: 0.421754, acc.: 79.69%] [G loss: 0.992968]\n",
      "epoch:13 step:12830 [D loss: 0.513113, acc.: 69.53%] [G loss: 0.797927]\n",
      "epoch:13 step:12831 [D loss: 0.519688, acc.: 75.00%] [G loss: 0.849338]\n",
      "epoch:13 step:12832 [D loss: 0.511649, acc.: 73.44%] [G loss: 0.701910]\n",
      "epoch:13 step:12833 [D loss: 0.656477, acc.: 64.84%] [G loss: 0.445972]\n",
      "epoch:13 step:12834 [D loss: 0.597300, acc.: 65.62%] [G loss: 0.526001]\n",
      "epoch:13 step:12835 [D loss: 0.498650, acc.: 75.00%] [G loss: 0.605130]\n",
      "epoch:13 step:12836 [D loss: 0.560566, acc.: 70.31%] [G loss: 0.576260]\n",
      "epoch:13 step:12837 [D loss: 0.613714, acc.: 68.75%] [G loss: 0.581500]\n",
      "epoch:13 step:12838 [D loss: 0.497068, acc.: 76.56%] [G loss: 0.811658]\n",
      "epoch:13 step:12839 [D loss: 0.564030, acc.: 65.62%] [G loss: 0.625363]\n",
      "epoch:13 step:12840 [D loss: 0.579836, acc.: 67.97%] [G loss: 0.511402]\n",
      "epoch:13 step:12841 [D loss: 0.478728, acc.: 79.69%] [G loss: 0.657860]\n",
      "epoch:13 step:12842 [D loss: 0.511810, acc.: 73.44%] [G loss: 0.666394]\n",
      "epoch:13 step:12843 [D loss: 0.555020, acc.: 69.53%] [G loss: 0.609717]\n",
      "epoch:13 step:12844 [D loss: 0.535793, acc.: 70.31%] [G loss: 0.555906]\n",
      "epoch:13 step:12845 [D loss: 0.569618, acc.: 65.62%] [G loss: 0.637773]\n",
      "epoch:13 step:12846 [D loss: 0.544258, acc.: 72.66%] [G loss: 0.657540]\n",
      "epoch:13 step:12847 [D loss: 0.538583, acc.: 70.31%] [G loss: 0.653360]\n",
      "epoch:13 step:12848 [D loss: 0.572747, acc.: 70.31%] [G loss: 0.695434]\n",
      "epoch:13 step:12849 [D loss: 0.566983, acc.: 71.88%] [G loss: 0.564376]\n",
      "epoch:13 step:12850 [D loss: 0.539973, acc.: 71.09%] [G loss: 0.572331]\n",
      "epoch:13 step:12851 [D loss: 0.540509, acc.: 73.44%] [G loss: 0.528987]\n",
      "epoch:13 step:12852 [D loss: 0.600305, acc.: 66.41%] [G loss: 0.508043]\n",
      "epoch:13 step:12853 [D loss: 0.619592, acc.: 64.84%] [G loss: 0.635943]\n",
      "epoch:13 step:12854 [D loss: 0.556830, acc.: 71.09%] [G loss: 0.563397]\n",
      "epoch:13 step:12855 [D loss: 0.510586, acc.: 71.09%] [G loss: 0.662597]\n",
      "epoch:13 step:12856 [D loss: 0.598229, acc.: 64.84%] [G loss: 0.508682]\n",
      "epoch:13 step:12857 [D loss: 0.505993, acc.: 76.56%] [G loss: 0.570581]\n",
      "epoch:13 step:12858 [D loss: 0.541635, acc.: 71.88%] [G loss: 0.979337]\n",
      "epoch:13 step:12859 [D loss: 0.594948, acc.: 67.19%] [G loss: 0.664881]\n",
      "epoch:13 step:12860 [D loss: 0.480114, acc.: 76.56%] [G loss: 0.614773]\n",
      "epoch:13 step:12861 [D loss: 0.511567, acc.: 73.44%] [G loss: 0.620354]\n",
      "epoch:13 step:12862 [D loss: 0.490574, acc.: 77.34%] [G loss: 0.638636]\n",
      "epoch:13 step:12863 [D loss: 0.567796, acc.: 67.97%] [G loss: 0.610448]\n",
      "epoch:13 step:12864 [D loss: 0.533899, acc.: 70.31%] [G loss: 0.750937]\n",
      "epoch:13 step:12865 [D loss: 0.584305, acc.: 67.19%] [G loss: 0.488496]\n",
      "epoch:13 step:12866 [D loss: 0.524168, acc.: 73.44%] [G loss: 0.650601]\n",
      "epoch:13 step:12867 [D loss: 0.599998, acc.: 69.53%] [G loss: 0.600406]\n",
      "epoch:13 step:12868 [D loss: 0.585690, acc.: 64.84%] [G loss: 0.509892]\n",
      "epoch:13 step:12869 [D loss: 0.552190, acc.: 71.09%] [G loss: 0.523331]\n",
      "epoch:13 step:12870 [D loss: 0.577088, acc.: 68.75%] [G loss: 0.547672]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:13 step:12871 [D loss: 0.518609, acc.: 80.47%] [G loss: 0.653272]\n",
      "epoch:13 step:12872 [D loss: 0.567351, acc.: 70.31%] [G loss: 0.610481]\n",
      "epoch:13 step:12873 [D loss: 0.534194, acc.: 74.22%] [G loss: 0.585535]\n",
      "epoch:13 step:12874 [D loss: 0.466510, acc.: 78.91%] [G loss: 0.666914]\n",
      "epoch:13 step:12875 [D loss: 0.461966, acc.: 77.34%] [G loss: 0.704527]\n",
      "epoch:13 step:12876 [D loss: 0.537924, acc.: 75.78%] [G loss: 0.572186]\n",
      "epoch:13 step:12877 [D loss: 0.600870, acc.: 65.62%] [G loss: 0.533955]\n",
      "epoch:13 step:12878 [D loss: 0.546270, acc.: 67.97%] [G loss: 0.474088]\n",
      "epoch:13 step:12879 [D loss: 0.602055, acc.: 57.81%] [G loss: 0.477848]\n",
      "epoch:13 step:12880 [D loss: 0.531828, acc.: 64.84%] [G loss: 0.511405]\n",
      "epoch:13 step:12881 [D loss: 0.562879, acc.: 68.75%] [G loss: 0.633913]\n",
      "epoch:13 step:12882 [D loss: 0.527548, acc.: 72.66%] [G loss: 0.644590]\n",
      "epoch:13 step:12883 [D loss: 0.548673, acc.: 69.53%] [G loss: 0.672634]\n",
      "epoch:13 step:12884 [D loss: 0.568955, acc.: 67.19%] [G loss: 0.662767]\n",
      "epoch:13 step:12885 [D loss: 0.610628, acc.: 65.62%] [G loss: 0.586894]\n",
      "epoch:13 step:12886 [D loss: 0.512260, acc.: 75.00%] [G loss: 0.506195]\n",
      "epoch:13 step:12887 [D loss: 0.530244, acc.: 74.22%] [G loss: 0.560727]\n",
      "epoch:13 step:12888 [D loss: 0.538195, acc.: 74.22%] [G loss: 0.662118]\n",
      "epoch:13 step:12889 [D loss: 0.538661, acc.: 71.09%] [G loss: 0.546837]\n",
      "epoch:13 step:12890 [D loss: 0.506681, acc.: 70.31%] [G loss: 0.602493]\n",
      "epoch:13 step:12891 [D loss: 0.641432, acc.: 64.84%] [G loss: 0.527689]\n",
      "epoch:13 step:12892 [D loss: 0.517119, acc.: 71.09%] [G loss: 0.548183]\n",
      "epoch:13 step:12893 [D loss: 0.556735, acc.: 72.66%] [G loss: 0.532765]\n",
      "epoch:13 step:12894 [D loss: 0.568643, acc.: 63.28%] [G loss: 0.609321]\n",
      "epoch:13 step:12895 [D loss: 0.549535, acc.: 64.06%] [G loss: 0.581697]\n",
      "epoch:13 step:12896 [D loss: 0.545076, acc.: 69.53%] [G loss: 0.535121]\n",
      "epoch:13 step:12897 [D loss: 0.608146, acc.: 65.62%] [G loss: 0.482086]\n",
      "epoch:13 step:12898 [D loss: 0.563786, acc.: 71.88%] [G loss: 0.513200]\n",
      "epoch:13 step:12899 [D loss: 0.553420, acc.: 72.66%] [G loss: 0.575985]\n",
      "epoch:13 step:12900 [D loss: 0.491862, acc.: 76.56%] [G loss: 0.551469]\n",
      "epoch:13 step:12901 [D loss: 0.659200, acc.: 60.94%] [G loss: 0.517869]\n",
      "epoch:13 step:12902 [D loss: 0.601190, acc.: 63.28%] [G loss: 0.510422]\n",
      "epoch:13 step:12903 [D loss: 0.529364, acc.: 73.44%] [G loss: 0.608601]\n",
      "epoch:13 step:12904 [D loss: 0.599514, acc.: 67.19%] [G loss: 0.435687]\n",
      "epoch:13 step:12905 [D loss: 0.518593, acc.: 78.12%] [G loss: 0.543180]\n",
      "epoch:13 step:12906 [D loss: 0.535016, acc.: 74.22%] [G loss: 0.560490]\n",
      "epoch:13 step:12907 [D loss: 0.510510, acc.: 72.66%] [G loss: 0.556166]\n",
      "epoch:13 step:12908 [D loss: 0.541722, acc.: 70.31%] [G loss: 0.575059]\n",
      "epoch:13 step:12909 [D loss: 0.568520, acc.: 71.88%] [G loss: 0.653586]\n",
      "epoch:13 step:12910 [D loss: 0.601860, acc.: 62.50%] [G loss: 0.573511]\n",
      "epoch:13 step:12911 [D loss: 0.490788, acc.: 78.91%] [G loss: 0.425064]\n",
      "epoch:13 step:12912 [D loss: 0.562409, acc.: 67.19%] [G loss: 0.550614]\n",
      "epoch:13 step:12913 [D loss: 0.495884, acc.: 70.31%] [G loss: 0.646934]\n",
      "epoch:13 step:12914 [D loss: 0.543173, acc.: 72.66%] [G loss: 0.588656]\n",
      "epoch:13 step:12915 [D loss: 0.593736, acc.: 63.28%] [G loss: 0.585124]\n",
      "epoch:13 step:12916 [D loss: 0.581251, acc.: 67.19%] [G loss: 0.548684]\n",
      "epoch:13 step:12917 [D loss: 0.512242, acc.: 71.88%] [G loss: 0.602621]\n",
      "epoch:13 step:12918 [D loss: 0.486702, acc.: 75.78%] [G loss: 0.613233]\n",
      "epoch:13 step:12919 [D loss: 0.573461, acc.: 61.72%] [G loss: 0.632388]\n",
      "epoch:13 step:12920 [D loss: 0.622463, acc.: 63.28%] [G loss: 0.497312]\n",
      "epoch:13 step:12921 [D loss: 0.634230, acc.: 60.94%] [G loss: 0.433625]\n",
      "epoch:13 step:12922 [D loss: 0.546801, acc.: 66.41%] [G loss: 0.427591]\n",
      "epoch:13 step:12923 [D loss: 0.512513, acc.: 71.09%] [G loss: 0.683292]\n",
      "epoch:13 step:12924 [D loss: 0.538890, acc.: 71.09%] [G loss: 0.651985]\n",
      "epoch:13 step:12925 [D loss: 0.593326, acc.: 66.41%] [G loss: 0.678256]\n",
      "epoch:13 step:12926 [D loss: 0.598163, acc.: 65.62%] [G loss: 0.509703]\n",
      "epoch:13 step:12927 [D loss: 0.481771, acc.: 75.78%] [G loss: 0.569934]\n",
      "epoch:13 step:12928 [D loss: 0.423751, acc.: 81.25%] [G loss: 0.700143]\n",
      "epoch:13 step:12929 [D loss: 0.530317, acc.: 69.53%] [G loss: 0.758825]\n",
      "epoch:13 step:12930 [D loss: 0.525972, acc.: 74.22%] [G loss: 0.646522]\n",
      "epoch:13 step:12931 [D loss: 0.506410, acc.: 74.22%] [G loss: 0.747957]\n",
      "epoch:13 step:12932 [D loss: 0.487857, acc.: 78.12%] [G loss: 0.687088]\n",
      "epoch:13 step:12933 [D loss: 0.633570, acc.: 59.38%] [G loss: 0.548262]\n",
      "epoch:13 step:12934 [D loss: 0.486604, acc.: 77.34%] [G loss: 0.727026]\n",
      "epoch:13 step:12935 [D loss: 0.564819, acc.: 65.62%] [G loss: 0.625115]\n",
      "epoch:13 step:12936 [D loss: 0.536639, acc.: 71.88%] [G loss: 0.508281]\n",
      "epoch:13 step:12937 [D loss: 0.534757, acc.: 71.88%] [G loss: 0.714440]\n",
      "epoch:13 step:12938 [D loss: 0.568634, acc.: 67.97%] [G loss: 0.703554]\n",
      "epoch:13 step:12939 [D loss: 0.584606, acc.: 64.84%] [G loss: 0.524946]\n",
      "epoch:13 step:12940 [D loss: 0.570040, acc.: 68.75%] [G loss: 0.613411]\n",
      "epoch:13 step:12941 [D loss: 0.528673, acc.: 69.53%] [G loss: 0.465886]\n",
      "epoch:13 step:12942 [D loss: 0.540061, acc.: 70.31%] [G loss: 0.574933]\n",
      "epoch:13 step:12943 [D loss: 0.585041, acc.: 62.50%] [G loss: 0.580796]\n",
      "epoch:13 step:12944 [D loss: 0.514968, acc.: 76.56%] [G loss: 0.652608]\n",
      "epoch:13 step:12945 [D loss: 0.563286, acc.: 68.75%] [G loss: 0.599688]\n",
      "epoch:13 step:12946 [D loss: 0.625508, acc.: 64.06%] [G loss: 0.524777]\n",
      "epoch:13 step:12947 [D loss: 0.624987, acc.: 60.94%] [G loss: 0.526614]\n",
      "epoch:13 step:12948 [D loss: 0.572373, acc.: 70.31%] [G loss: 0.449155]\n",
      "epoch:13 step:12949 [D loss: 0.557077, acc.: 69.53%] [G loss: 0.544119]\n",
      "epoch:13 step:12950 [D loss: 0.516528, acc.: 75.00%] [G loss: 0.759319]\n",
      "epoch:13 step:12951 [D loss: 0.581540, acc.: 71.88%] [G loss: 0.608113]\n",
      "epoch:13 step:12952 [D loss: 0.532631, acc.: 70.31%] [G loss: 0.614685]\n",
      "epoch:13 step:12953 [D loss: 0.556404, acc.: 67.97%] [G loss: 0.563726]\n",
      "epoch:13 step:12954 [D loss: 0.533836, acc.: 73.44%] [G loss: 0.616436]\n",
      "epoch:13 step:12955 [D loss: 0.563959, acc.: 70.31%] [G loss: 0.476988]\n",
      "epoch:13 step:12956 [D loss: 0.540863, acc.: 71.09%] [G loss: 0.688964]\n",
      "epoch:13 step:12957 [D loss: 0.567804, acc.: 69.53%] [G loss: 0.592458]\n",
      "epoch:13 step:12958 [D loss: 0.582775, acc.: 67.19%] [G loss: 0.630983]\n",
      "epoch:13 step:12959 [D loss: 0.576557, acc.: 67.19%] [G loss: 0.486656]\n",
      "epoch:13 step:12960 [D loss: 0.592249, acc.: 64.84%] [G loss: 0.452552]\n",
      "epoch:13 step:12961 [D loss: 0.545601, acc.: 72.66%] [G loss: 0.584700]\n",
      "epoch:13 step:12962 [D loss: 0.513114, acc.: 72.66%] [G loss: 0.722386]\n",
      "epoch:13 step:12963 [D loss: 0.473792, acc.: 78.12%] [G loss: 0.908686]\n",
      "epoch:13 step:12964 [D loss: 0.613412, acc.: 64.06%] [G loss: 0.686045]\n",
      "epoch:13 step:12965 [D loss: 0.628811, acc.: 61.72%] [G loss: 0.546154]\n",
      "epoch:13 step:12966 [D loss: 0.611878, acc.: 60.16%] [G loss: 0.439527]\n",
      "epoch:13 step:12967 [D loss: 0.543059, acc.: 68.75%] [G loss: 0.594885]\n",
      "epoch:13 step:12968 [D loss: 0.585737, acc.: 69.53%] [G loss: 0.556191]\n",
      "epoch:13 step:12969 [D loss: 0.655946, acc.: 64.84%] [G loss: 0.416297]\n",
      "epoch:13 step:12970 [D loss: 0.512888, acc.: 74.22%] [G loss: 0.617139]\n",
      "epoch:13 step:12971 [D loss: 0.527181, acc.: 74.22%] [G loss: 0.575464]\n",
      "epoch:13 step:12972 [D loss: 0.557408, acc.: 68.75%] [G loss: 0.616946]\n",
      "epoch:13 step:12973 [D loss: 0.464951, acc.: 76.56%] [G loss: 0.675289]\n",
      "epoch:13 step:12974 [D loss: 0.581938, acc.: 67.97%] [G loss: 0.600650]\n",
      "epoch:13 step:12975 [D loss: 0.683294, acc.: 59.38%] [G loss: 0.469440]\n",
      "epoch:13 step:12976 [D loss: 0.526597, acc.: 69.53%] [G loss: 0.517118]\n",
      "epoch:13 step:12977 [D loss: 0.542159, acc.: 68.75%] [G loss: 0.679648]\n",
      "epoch:13 step:12978 [D loss: 0.521433, acc.: 76.56%] [G loss: 0.613847]\n",
      "epoch:13 step:12979 [D loss: 0.556846, acc.: 69.53%] [G loss: 0.716550]\n",
      "epoch:13 step:12980 [D loss: 0.549614, acc.: 70.31%] [G loss: 0.572154]\n",
      "epoch:13 step:12981 [D loss: 0.586850, acc.: 64.84%] [G loss: 0.648951]\n",
      "epoch:13 step:12982 [D loss: 0.552979, acc.: 67.19%] [G loss: 0.669137]\n",
      "epoch:13 step:12983 [D loss: 0.541588, acc.: 67.97%] [G loss: 0.710014]\n",
      "epoch:13 step:12984 [D loss: 0.534411, acc.: 75.00%] [G loss: 0.784679]\n",
      "epoch:13 step:12985 [D loss: 0.500704, acc.: 73.44%] [G loss: 0.614015]\n",
      "epoch:13 step:12986 [D loss: 0.595898, acc.: 61.72%] [G loss: 0.496393]\n",
      "epoch:13 step:12987 [D loss: 0.543780, acc.: 67.97%] [G loss: 0.477575]\n",
      "epoch:13 step:12988 [D loss: 0.512286, acc.: 71.09%] [G loss: 0.504956]\n",
      "epoch:13 step:12989 [D loss: 0.595104, acc.: 64.06%] [G loss: 0.506249]\n",
      "epoch:13 step:12990 [D loss: 0.559352, acc.: 75.00%] [G loss: 0.476690]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:13 step:12991 [D loss: 0.522434, acc.: 76.56%] [G loss: 0.535301]\n",
      "epoch:13 step:12992 [D loss: 0.504929, acc.: 75.78%] [G loss: 0.583906]\n",
      "epoch:13 step:12993 [D loss: 0.612473, acc.: 64.06%] [G loss: 0.461441]\n",
      "epoch:13 step:12994 [D loss: 0.547067, acc.: 66.41%] [G loss: 0.448846]\n",
      "epoch:13 step:12995 [D loss: 0.516193, acc.: 71.09%] [G loss: 0.632767]\n",
      "epoch:13 step:12996 [D loss: 0.534489, acc.: 71.09%] [G loss: 0.726185]\n",
      "epoch:13 step:12997 [D loss: 0.600603, acc.: 67.97%] [G loss: 0.830292]\n",
      "epoch:13 step:12998 [D loss: 0.601741, acc.: 64.84%] [G loss: 0.559833]\n",
      "epoch:13 step:12999 [D loss: 0.581094, acc.: 65.62%] [G loss: 0.513286]\n",
      "epoch:13 step:13000 [D loss: 0.503306, acc.: 78.12%] [G loss: 0.516847]\n",
      "##############\n",
      "[3.34070644 1.4244964  6.40103467 5.02825598 3.64527953 5.6460734\n",
      " 4.5359253  4.96029961 4.51482763 4.14136659]\n",
      "##########\n",
      "epoch:13 step:13001 [D loss: 0.614855, acc.: 62.50%] [G loss: 0.518146]\n",
      "epoch:13 step:13002 [D loss: 0.535937, acc.: 69.53%] [G loss: 0.534368]\n",
      "epoch:13 step:13003 [D loss: 0.537393, acc.: 69.53%] [G loss: 0.542078]\n",
      "epoch:13 step:13004 [D loss: 0.455140, acc.: 78.91%] [G loss: 0.709996]\n",
      "epoch:13 step:13005 [D loss: 0.592674, acc.: 71.88%] [G loss: 0.566297]\n",
      "epoch:13 step:13006 [D loss: 0.542635, acc.: 74.22%] [G loss: 0.493708]\n",
      "epoch:13 step:13007 [D loss: 0.573042, acc.: 69.53%] [G loss: 0.510963]\n",
      "epoch:13 step:13008 [D loss: 0.509535, acc.: 76.56%] [G loss: 0.553519]\n",
      "epoch:13 step:13009 [D loss: 0.652161, acc.: 59.38%] [G loss: 0.481123]\n",
      "epoch:13 step:13010 [D loss: 0.548419, acc.: 66.41%] [G loss: 0.569303]\n",
      "epoch:13 step:13011 [D loss: 0.556376, acc.: 67.19%] [G loss: 0.639543]\n",
      "epoch:13 step:13012 [D loss: 0.508304, acc.: 75.00%] [G loss: 0.552774]\n",
      "epoch:13 step:13013 [D loss: 0.545143, acc.: 73.44%] [G loss: 0.531034]\n",
      "epoch:13 step:13014 [D loss: 0.521508, acc.: 75.78%] [G loss: 0.571040]\n",
      "epoch:13 step:13015 [D loss: 0.510450, acc.: 72.66%] [G loss: 0.632112]\n",
      "epoch:13 step:13016 [D loss: 0.568232, acc.: 74.22%] [G loss: 0.490871]\n",
      "epoch:13 step:13017 [D loss: 0.507603, acc.: 78.91%] [G loss: 0.600320]\n",
      "epoch:13 step:13018 [D loss: 0.567742, acc.: 67.97%] [G loss: 0.656793]\n",
      "epoch:13 step:13019 [D loss: 0.554588, acc.: 71.88%] [G loss: 0.504514]\n",
      "epoch:13 step:13020 [D loss: 0.585280, acc.: 65.62%] [G loss: 0.396120]\n",
      "epoch:13 step:13021 [D loss: 0.571286, acc.: 67.97%] [G loss: 0.367468]\n",
      "epoch:13 step:13022 [D loss: 0.557036, acc.: 60.94%] [G loss: 0.393158]\n",
      "epoch:13 step:13023 [D loss: 0.537316, acc.: 71.88%] [G loss: 0.515638]\n",
      "epoch:13 step:13024 [D loss: 0.542137, acc.: 71.88%] [G loss: 0.658972]\n",
      "epoch:13 step:13025 [D loss: 0.614703, acc.: 64.84%] [G loss: 0.521143]\n",
      "epoch:13 step:13026 [D loss: 0.569764, acc.: 68.75%] [G loss: 0.658574]\n",
      "epoch:13 step:13027 [D loss: 0.578034, acc.: 63.28%] [G loss: 0.572399]\n",
      "epoch:13 step:13028 [D loss: 0.602957, acc.: 62.50%] [G loss: 0.513271]\n",
      "epoch:13 step:13029 [D loss: 0.526128, acc.: 70.31%] [G loss: 0.439677]\n",
      "epoch:13 step:13030 [D loss: 0.559592, acc.: 71.09%] [G loss: 0.400561]\n",
      "epoch:13 step:13031 [D loss: 0.575034, acc.: 64.06%] [G loss: 0.463538]\n",
      "epoch:13 step:13032 [D loss: 0.596635, acc.: 69.53%] [G loss: 0.444201]\n",
      "epoch:13 step:13033 [D loss: 0.531572, acc.: 67.19%] [G loss: 0.579246]\n",
      "epoch:13 step:13034 [D loss: 0.559958, acc.: 69.53%] [G loss: 0.589086]\n",
      "epoch:13 step:13035 [D loss: 0.493325, acc.: 74.22%] [G loss: 0.665450]\n",
      "epoch:13 step:13036 [D loss: 0.535690, acc.: 69.53%] [G loss: 0.666050]\n",
      "epoch:13 step:13037 [D loss: 0.577140, acc.: 71.09%] [G loss: 0.542207]\n",
      "epoch:13 step:13038 [D loss: 0.472794, acc.: 77.34%] [G loss: 0.611535]\n",
      "epoch:13 step:13039 [D loss: 0.773639, acc.: 52.34%] [G loss: 0.508178]\n",
      "epoch:13 step:13040 [D loss: 0.586067, acc.: 68.75%] [G loss: 0.691206]\n",
      "epoch:13 step:13041 [D loss: 0.459378, acc.: 77.34%] [G loss: 0.827606]\n",
      "epoch:13 step:13042 [D loss: 0.676710, acc.: 58.59%] [G loss: 0.656946]\n",
      "epoch:13 step:13043 [D loss: 0.564184, acc.: 66.41%] [G loss: 0.609504]\n",
      "epoch:13 step:13044 [D loss: 0.530475, acc.: 69.53%] [G loss: 0.551629]\n",
      "epoch:13 step:13045 [D loss: 0.577906, acc.: 67.97%] [G loss: 0.535785]\n",
      "epoch:13 step:13046 [D loss: 0.593841, acc.: 66.41%] [G loss: 0.532727]\n",
      "epoch:13 step:13047 [D loss: 0.542010, acc.: 67.19%] [G loss: 0.507514]\n",
      "epoch:13 step:13048 [D loss: 0.664764, acc.: 60.94%] [G loss: 0.338142]\n",
      "epoch:13 step:13049 [D loss: 0.590850, acc.: 65.62%] [G loss: 0.421481]\n",
      "epoch:13 step:13050 [D loss: 0.595133, acc.: 71.88%] [G loss: 0.513463]\n",
      "epoch:13 step:13051 [D loss: 0.481973, acc.: 76.56%] [G loss: 0.577931]\n",
      "epoch:13 step:13052 [D loss: 0.504661, acc.: 75.00%] [G loss: 0.687281]\n",
      "epoch:13 step:13053 [D loss: 0.567999, acc.: 66.41%] [G loss: 0.489475]\n",
      "epoch:13 step:13054 [D loss: 0.589271, acc.: 67.19%] [G loss: 0.597053]\n",
      "epoch:13 step:13055 [D loss: 0.596446, acc.: 64.06%] [G loss: 0.511399]\n",
      "epoch:13 step:13056 [D loss: 0.491843, acc.: 75.00%] [G loss: 0.657442]\n",
      "epoch:13 step:13057 [D loss: 0.549785, acc.: 70.31%] [G loss: 0.539763]\n",
      "epoch:13 step:13058 [D loss: 0.585158, acc.: 70.31%] [G loss: 0.609295]\n",
      "epoch:13 step:13059 [D loss: 0.592858, acc.: 68.75%] [G loss: 0.592222]\n",
      "epoch:13 step:13060 [D loss: 0.569391, acc.: 71.88%] [G loss: 0.584193]\n",
      "epoch:13 step:13061 [D loss: 0.676365, acc.: 60.16%] [G loss: 0.446399]\n",
      "epoch:13 step:13062 [D loss: 0.592303, acc.: 66.41%] [G loss: 0.323247]\n",
      "epoch:13 step:13063 [D loss: 0.598146, acc.: 60.94%] [G loss: 0.362138]\n",
      "epoch:13 step:13064 [D loss: 0.555745, acc.: 74.22%] [G loss: 0.441304]\n",
      "epoch:13 step:13065 [D loss: 0.522518, acc.: 72.66%] [G loss: 0.433007]\n",
      "epoch:13 step:13066 [D loss: 0.528432, acc.: 73.44%] [G loss: 0.631583]\n",
      "epoch:13 step:13067 [D loss: 0.537937, acc.: 73.44%] [G loss: 0.650885]\n",
      "epoch:13 step:13068 [D loss: 0.540510, acc.: 70.31%] [G loss: 0.643926]\n",
      "epoch:13 step:13069 [D loss: 0.512590, acc.: 72.66%] [G loss: 0.783480]\n",
      "epoch:13 step:13070 [D loss: 0.535557, acc.: 68.75%] [G loss: 0.651391]\n",
      "epoch:13 step:13071 [D loss: 0.460889, acc.: 76.56%] [G loss: 0.722160]\n",
      "epoch:13 step:13072 [D loss: 0.653812, acc.: 64.84%] [G loss: 0.629655]\n",
      "epoch:13 step:13073 [D loss: 0.619020, acc.: 66.41%] [G loss: 0.648091]\n",
      "epoch:13 step:13074 [D loss: 0.558539, acc.: 68.75%] [G loss: 0.582536]\n",
      "epoch:13 step:13075 [D loss: 0.484275, acc.: 73.44%] [G loss: 0.765475]\n",
      "epoch:13 step:13076 [D loss: 0.515658, acc.: 71.88%] [G loss: 0.829546]\n",
      "epoch:13 step:13077 [D loss: 0.477548, acc.: 77.34%] [G loss: 0.732126]\n",
      "epoch:13 step:13078 [D loss: 0.514884, acc.: 73.44%] [G loss: 0.769496]\n",
      "epoch:13 step:13079 [D loss: 0.493043, acc.: 74.22%] [G loss: 0.770277]\n",
      "epoch:13 step:13080 [D loss: 0.502562, acc.: 73.44%] [G loss: 0.672685]\n",
      "epoch:13 step:13081 [D loss: 0.542235, acc.: 73.44%] [G loss: 0.644808]\n",
      "epoch:13 step:13082 [D loss: 0.492648, acc.: 72.66%] [G loss: 0.703784]\n",
      "epoch:13 step:13083 [D loss: 0.639995, acc.: 60.16%] [G loss: 0.526644]\n",
      "epoch:13 step:13084 [D loss: 0.605705, acc.: 64.06%] [G loss: 0.535203]\n",
      "epoch:13 step:13085 [D loss: 0.554038, acc.: 69.53%] [G loss: 0.483266]\n",
      "epoch:13 step:13086 [D loss: 0.578878, acc.: 66.41%] [G loss: 0.678911]\n",
      "epoch:13 step:13087 [D loss: 0.458434, acc.: 80.47%] [G loss: 0.766868]\n",
      "epoch:13 step:13088 [D loss: 0.556227, acc.: 68.75%] [G loss: 0.474756]\n",
      "epoch:13 step:13089 [D loss: 0.551117, acc.: 74.22%] [G loss: 0.549969]\n",
      "epoch:13 step:13090 [D loss: 0.497363, acc.: 76.56%] [G loss: 0.585076]\n",
      "epoch:13 step:13091 [D loss: 0.569056, acc.: 67.97%] [G loss: 0.741067]\n",
      "epoch:13 step:13092 [D loss: 0.453627, acc.: 78.91%] [G loss: 0.856544]\n",
      "epoch:13 step:13093 [D loss: 0.444871, acc.: 79.69%] [G loss: 0.930091]\n",
      "epoch:13 step:13094 [D loss: 0.574295, acc.: 69.53%] [G loss: 0.843536]\n",
      "epoch:13 step:13095 [D loss: 0.491739, acc.: 76.56%] [G loss: 0.986565]\n",
      "epoch:13 step:13096 [D loss: 0.659583, acc.: 59.38%] [G loss: 0.607558]\n",
      "epoch:13 step:13097 [D loss: 0.527545, acc.: 73.44%] [G loss: 0.614147]\n",
      "epoch:13 step:13098 [D loss: 0.656031, acc.: 60.16%] [G loss: 0.589434]\n",
      "epoch:13 step:13099 [D loss: 0.549865, acc.: 63.28%] [G loss: 0.660658]\n",
      "epoch:13 step:13100 [D loss: 0.459783, acc.: 81.25%] [G loss: 0.758843]\n",
      "epoch:13 step:13101 [D loss: 0.682819, acc.: 57.03%] [G loss: 0.700636]\n",
      "epoch:13 step:13102 [D loss: 0.468500, acc.: 75.78%] [G loss: 0.825736]\n",
      "epoch:13 step:13103 [D loss: 0.579974, acc.: 65.62%] [G loss: 0.541620]\n",
      "epoch:13 step:13104 [D loss: 0.448771, acc.: 78.91%] [G loss: 0.733038]\n",
      "epoch:13 step:13105 [D loss: 0.479590, acc.: 74.22%] [G loss: 0.806441]\n",
      "epoch:13 step:13106 [D loss: 0.413367, acc.: 80.47%] [G loss: 0.867342]\n",
      "epoch:13 step:13107 [D loss: 0.461964, acc.: 74.22%] [G loss: 1.036263]\n",
      "epoch:13 step:13108 [D loss: 0.514647, acc.: 74.22%] [G loss: 0.996125]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:13 step:13109 [D loss: 0.794181, acc.: 57.03%] [G loss: 0.906780]\n",
      "epoch:13 step:13110 [D loss: 0.434214, acc.: 84.38%] [G loss: 1.056509]\n",
      "epoch:13 step:13111 [D loss: 0.524188, acc.: 74.22%] [G loss: 1.153571]\n",
      "epoch:13 step:13112 [D loss: 0.565712, acc.: 71.88%] [G loss: 1.041700]\n",
      "epoch:13 step:13113 [D loss: 0.640049, acc.: 61.72%] [G loss: 0.619596]\n",
      "epoch:13 step:13114 [D loss: 0.468494, acc.: 75.78%] [G loss: 0.683433]\n",
      "epoch:13 step:13115 [D loss: 0.565435, acc.: 70.31%] [G loss: 0.691133]\n",
      "epoch:13 step:13116 [D loss: 0.518949, acc.: 71.09%] [G loss: 0.929677]\n",
      "epoch:13 step:13117 [D loss: 0.361566, acc.: 84.38%] [G loss: 1.073347]\n",
      "epoch:13 step:13118 [D loss: 0.507916, acc.: 71.88%] [G loss: 1.147244]\n",
      "epoch:14 step:13119 [D loss: 0.603969, acc.: 68.75%] [G loss: 1.193434]\n",
      "epoch:14 step:13120 [D loss: 0.531052, acc.: 71.88%] [G loss: 1.000281]\n",
      "epoch:14 step:13121 [D loss: 0.567162, acc.: 69.53%] [G loss: 0.776413]\n",
      "epoch:14 step:13122 [D loss: 0.567911, acc.: 71.09%] [G loss: 0.729452]\n",
      "epoch:14 step:13123 [D loss: 0.578437, acc.: 70.31%] [G loss: 0.725204]\n",
      "epoch:14 step:13124 [D loss: 0.557970, acc.: 70.31%] [G loss: 0.736923]\n",
      "epoch:14 step:13125 [D loss: 0.510904, acc.: 77.34%] [G loss: 0.716172]\n",
      "epoch:14 step:13126 [D loss: 0.573000, acc.: 68.75%] [G loss: 0.724345]\n",
      "epoch:14 step:13127 [D loss: 0.511640, acc.: 74.22%] [G loss: 0.739534]\n",
      "epoch:14 step:13128 [D loss: 0.541651, acc.: 76.56%] [G loss: 1.038514]\n",
      "epoch:14 step:13129 [D loss: 0.499451, acc.: 75.78%] [G loss: 0.705068]\n",
      "epoch:14 step:13130 [D loss: 0.581639, acc.: 67.97%] [G loss: 0.644735]\n",
      "epoch:14 step:13131 [D loss: 0.578596, acc.: 65.62%] [G loss: 0.518196]\n",
      "epoch:14 step:13132 [D loss: 0.495348, acc.: 74.22%] [G loss: 0.757938]\n",
      "epoch:14 step:13133 [D loss: 0.494596, acc.: 73.44%] [G loss: 0.751069]\n",
      "epoch:14 step:13134 [D loss: 0.497428, acc.: 75.78%] [G loss: 0.744609]\n",
      "epoch:14 step:13135 [D loss: 0.549603, acc.: 71.88%] [G loss: 0.694264]\n",
      "epoch:14 step:13136 [D loss: 0.586626, acc.: 68.75%] [G loss: 0.609008]\n",
      "epoch:14 step:13137 [D loss: 0.583844, acc.: 66.41%] [G loss: 0.587395]\n",
      "epoch:14 step:13138 [D loss: 0.597744, acc.: 66.41%] [G loss: 0.601422]\n",
      "epoch:14 step:13139 [D loss: 0.620474, acc.: 63.28%] [G loss: 0.576545]\n",
      "epoch:14 step:13140 [D loss: 0.457892, acc.: 81.25%] [G loss: 0.648939]\n",
      "epoch:14 step:13141 [D loss: 0.549641, acc.: 73.44%] [G loss: 0.525204]\n",
      "epoch:14 step:13142 [D loss: 0.517571, acc.: 75.78%] [G loss: 0.524859]\n",
      "epoch:14 step:13143 [D loss: 0.534905, acc.: 76.56%] [G loss: 0.683330]\n",
      "epoch:14 step:13144 [D loss: 0.548130, acc.: 70.31%] [G loss: 0.582902]\n",
      "epoch:14 step:13145 [D loss: 0.500356, acc.: 73.44%] [G loss: 0.572655]\n",
      "epoch:14 step:13146 [D loss: 0.578246, acc.: 71.88%] [G loss: 0.556434]\n",
      "epoch:14 step:13147 [D loss: 0.516209, acc.: 70.31%] [G loss: 0.648901]\n",
      "epoch:14 step:13148 [D loss: 0.574218, acc.: 71.88%] [G loss: 0.665071]\n",
      "epoch:14 step:13149 [D loss: 0.598649, acc.: 64.06%] [G loss: 0.631806]\n",
      "epoch:14 step:13150 [D loss: 0.630915, acc.: 62.50%] [G loss: 0.408809]\n",
      "epoch:14 step:13151 [D loss: 0.554155, acc.: 71.09%] [G loss: 0.660887]\n",
      "epoch:14 step:13152 [D loss: 0.587809, acc.: 59.38%] [G loss: 0.636255]\n",
      "epoch:14 step:13153 [D loss: 0.637662, acc.: 64.84%] [G loss: 0.585278]\n",
      "epoch:14 step:13154 [D loss: 0.510419, acc.: 73.44%] [G loss: 0.765817]\n",
      "epoch:14 step:13155 [D loss: 0.511217, acc.: 75.78%] [G loss: 0.696341]\n",
      "epoch:14 step:13156 [D loss: 0.619984, acc.: 66.41%] [G loss: 0.616835]\n",
      "epoch:14 step:13157 [D loss: 0.555519, acc.: 72.66%] [G loss: 0.434390]\n",
      "epoch:14 step:13158 [D loss: 0.427023, acc.: 80.47%] [G loss: 0.754172]\n",
      "epoch:14 step:13159 [D loss: 0.554510, acc.: 70.31%] [G loss: 0.700581]\n",
      "epoch:14 step:13160 [D loss: 0.544583, acc.: 67.19%] [G loss: 0.557144]\n",
      "epoch:14 step:13161 [D loss: 0.525957, acc.: 74.22%] [G loss: 0.602144]\n",
      "epoch:14 step:13162 [D loss: 0.567504, acc.: 65.62%] [G loss: 0.625993]\n",
      "epoch:14 step:13163 [D loss: 0.488806, acc.: 75.00%] [G loss: 0.634362]\n",
      "epoch:14 step:13164 [D loss: 0.529451, acc.: 75.78%] [G loss: 0.648515]\n",
      "epoch:14 step:13165 [D loss: 0.535840, acc.: 74.22%] [G loss: 0.615258]\n",
      "epoch:14 step:13166 [D loss: 0.529030, acc.: 74.22%] [G loss: 0.645534]\n",
      "epoch:14 step:13167 [D loss: 0.504320, acc.: 75.00%] [G loss: 0.623853]\n",
      "epoch:14 step:13168 [D loss: 0.599925, acc.: 63.28%] [G loss: 0.644036]\n",
      "epoch:14 step:13169 [D loss: 0.686338, acc.: 54.69%] [G loss: 0.543965]\n",
      "epoch:14 step:13170 [D loss: 0.616794, acc.: 63.28%] [G loss: 0.648288]\n",
      "epoch:14 step:13171 [D loss: 0.527245, acc.: 73.44%] [G loss: 0.718614]\n",
      "epoch:14 step:13172 [D loss: 0.454479, acc.: 81.25%] [G loss: 0.733788]\n",
      "epoch:14 step:13173 [D loss: 0.569865, acc.: 62.50%] [G loss: 0.642441]\n",
      "epoch:14 step:13174 [D loss: 0.489496, acc.: 71.88%] [G loss: 0.671719]\n",
      "epoch:14 step:13175 [D loss: 0.521876, acc.: 67.97%] [G loss: 0.747483]\n",
      "epoch:14 step:13176 [D loss: 0.564577, acc.: 68.75%] [G loss: 0.615818]\n",
      "epoch:14 step:13177 [D loss: 0.491131, acc.: 75.78%] [G loss: 0.799688]\n",
      "epoch:14 step:13178 [D loss: 0.539307, acc.: 71.09%] [G loss: 0.605309]\n",
      "epoch:14 step:13179 [D loss: 0.578498, acc.: 66.41%] [G loss: 0.582948]\n",
      "epoch:14 step:13180 [D loss: 0.568493, acc.: 70.31%] [G loss: 0.542276]\n",
      "epoch:14 step:13181 [D loss: 0.538768, acc.: 73.44%] [G loss: 0.548005]\n",
      "epoch:14 step:13182 [D loss: 0.646967, acc.: 60.94%] [G loss: 0.445083]\n",
      "epoch:14 step:13183 [D loss: 0.482152, acc.: 84.38%] [G loss: 0.528003]\n",
      "epoch:14 step:13184 [D loss: 0.569216, acc.: 68.75%] [G loss: 0.623174]\n",
      "epoch:14 step:13185 [D loss: 0.573331, acc.: 67.97%] [G loss: 0.516265]\n",
      "epoch:14 step:13186 [D loss: 0.565307, acc.: 65.62%] [G loss: 0.543802]\n",
      "epoch:14 step:13187 [D loss: 0.459540, acc.: 79.69%] [G loss: 0.590613]\n",
      "epoch:14 step:13188 [D loss: 0.531645, acc.: 72.66%] [G loss: 0.568469]\n",
      "epoch:14 step:13189 [D loss: 0.517607, acc.: 75.78%] [G loss: 0.527061]\n",
      "epoch:14 step:13190 [D loss: 0.531641, acc.: 71.88%] [G loss: 0.607671]\n",
      "epoch:14 step:13191 [D loss: 0.573658, acc.: 69.53%] [G loss: 0.466506]\n",
      "epoch:14 step:13192 [D loss: 0.459754, acc.: 75.78%] [G loss: 0.792819]\n",
      "epoch:14 step:13193 [D loss: 0.560582, acc.: 67.97%] [G loss: 0.740750]\n",
      "epoch:14 step:13194 [D loss: 0.532975, acc.: 75.78%] [G loss: 0.701963]\n",
      "epoch:14 step:13195 [D loss: 0.508529, acc.: 70.31%] [G loss: 0.884523]\n",
      "epoch:14 step:13196 [D loss: 0.604878, acc.: 66.41%] [G loss: 0.622817]\n",
      "epoch:14 step:13197 [D loss: 0.545411, acc.: 71.09%] [G loss: 0.609056]\n",
      "epoch:14 step:13198 [D loss: 0.520718, acc.: 73.44%] [G loss: 0.599031]\n",
      "epoch:14 step:13199 [D loss: 0.530796, acc.: 70.31%] [G loss: 0.664694]\n",
      "epoch:14 step:13200 [D loss: 0.533030, acc.: 69.53%] [G loss: 0.654638]\n",
      "##############\n",
      "[2.96252497 1.13277421 6.41066721 4.758681   3.88601088 5.49414638\n",
      " 4.61044884 5.07033022 4.49384285 4.16642123]\n",
      "##########\n",
      "epoch:14 step:13201 [D loss: 0.514748, acc.: 72.66%] [G loss: 0.539994]\n",
      "epoch:14 step:13202 [D loss: 0.579169, acc.: 66.41%] [G loss: 0.530779]\n",
      "epoch:14 step:13203 [D loss: 0.594602, acc.: 66.41%] [G loss: 0.597666]\n",
      "epoch:14 step:13204 [D loss: 0.545122, acc.: 72.66%] [G loss: 0.737811]\n",
      "epoch:14 step:13205 [D loss: 0.529667, acc.: 70.31%] [G loss: 0.599521]\n",
      "epoch:14 step:13206 [D loss: 0.529715, acc.: 73.44%] [G loss: 0.538477]\n",
      "epoch:14 step:13207 [D loss: 0.541953, acc.: 74.22%] [G loss: 0.655420]\n",
      "epoch:14 step:13208 [D loss: 0.509210, acc.: 71.88%] [G loss: 0.669735]\n",
      "epoch:14 step:13209 [D loss: 0.569254, acc.: 69.53%] [G loss: 0.725138]\n",
      "epoch:14 step:13210 [D loss: 0.457994, acc.: 82.03%] [G loss: 0.596134]\n",
      "epoch:14 step:13211 [D loss: 0.459119, acc.: 79.69%] [G loss: 0.755395]\n",
      "epoch:14 step:13212 [D loss: 0.543674, acc.: 73.44%] [G loss: 0.822684]\n",
      "epoch:14 step:13213 [D loss: 0.521966, acc.: 71.88%] [G loss: 0.600076]\n",
      "epoch:14 step:13214 [D loss: 0.504879, acc.: 72.66%] [G loss: 0.641467]\n",
      "epoch:14 step:13215 [D loss: 0.542489, acc.: 72.66%] [G loss: 0.713068]\n",
      "epoch:14 step:13216 [D loss: 0.517441, acc.: 70.31%] [G loss: 0.676026]\n",
      "epoch:14 step:13217 [D loss: 0.514185, acc.: 71.88%] [G loss: 0.618634]\n",
      "epoch:14 step:13218 [D loss: 0.442660, acc.: 79.69%] [G loss: 0.791941]\n",
      "epoch:14 step:13219 [D loss: 0.482605, acc.: 75.78%] [G loss: 0.701895]\n",
      "epoch:14 step:13220 [D loss: 0.604235, acc.: 66.41%] [G loss: 0.539613]\n",
      "epoch:14 step:13221 [D loss: 0.531636, acc.: 69.53%] [G loss: 0.477786]\n",
      "epoch:14 step:13222 [D loss: 0.526589, acc.: 75.78%] [G loss: 0.594223]\n",
      "epoch:14 step:13223 [D loss: 0.607229, acc.: 63.28%] [G loss: 0.563829]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:14 step:13224 [D loss: 0.567883, acc.: 68.75%] [G loss: 0.439403]\n",
      "epoch:14 step:13225 [D loss: 0.573306, acc.: 67.97%] [G loss: 0.671685]\n",
      "epoch:14 step:13226 [D loss: 0.612946, acc.: 68.75%] [G loss: 0.528867]\n",
      "epoch:14 step:13227 [D loss: 0.643625, acc.: 61.72%] [G loss: 0.504517]\n",
      "epoch:14 step:13228 [D loss: 0.589048, acc.: 65.62%] [G loss: 0.637629]\n",
      "epoch:14 step:13229 [D loss: 0.541640, acc.: 70.31%] [G loss: 0.525233]\n",
      "epoch:14 step:13230 [D loss: 0.504577, acc.: 75.00%] [G loss: 0.656855]\n",
      "epoch:14 step:13231 [D loss: 0.525531, acc.: 69.53%] [G loss: 0.604376]\n",
      "epoch:14 step:13232 [D loss: 0.538130, acc.: 70.31%] [G loss: 0.733078]\n",
      "epoch:14 step:13233 [D loss: 0.522476, acc.: 78.91%] [G loss: 0.791567]\n",
      "epoch:14 step:13234 [D loss: 0.502027, acc.: 75.00%] [G loss: 0.642293]\n",
      "epoch:14 step:13235 [D loss: 0.569401, acc.: 64.84%] [G loss: 0.628426]\n",
      "epoch:14 step:13236 [D loss: 0.519639, acc.: 72.66%] [G loss: 0.696384]\n",
      "epoch:14 step:13237 [D loss: 0.485321, acc.: 76.56%] [G loss: 0.877332]\n",
      "epoch:14 step:13238 [D loss: 0.547854, acc.: 75.78%] [G loss: 0.777123]\n",
      "epoch:14 step:13239 [D loss: 0.549643, acc.: 70.31%] [G loss: 0.647702]\n",
      "epoch:14 step:13240 [D loss: 0.543108, acc.: 74.22%] [G loss: 0.951315]\n",
      "epoch:14 step:13241 [D loss: 0.538482, acc.: 71.09%] [G loss: 0.757102]\n",
      "epoch:14 step:13242 [D loss: 0.634428, acc.: 67.19%] [G loss: 0.703110]\n",
      "epoch:14 step:13243 [D loss: 0.598108, acc.: 67.19%] [G loss: 0.621090]\n",
      "epoch:14 step:13244 [D loss: 0.504049, acc.: 72.66%] [G loss: 0.607017]\n",
      "epoch:14 step:13245 [D loss: 0.517445, acc.: 72.66%] [G loss: 0.496523]\n",
      "epoch:14 step:13246 [D loss: 0.518457, acc.: 72.66%] [G loss: 0.674514]\n",
      "epoch:14 step:13247 [D loss: 0.541441, acc.: 75.00%] [G loss: 0.479241]\n",
      "epoch:14 step:13248 [D loss: 0.581336, acc.: 67.97%] [G loss: 0.477450]\n",
      "epoch:14 step:13249 [D loss: 0.500078, acc.: 71.88%] [G loss: 0.573027]\n",
      "epoch:14 step:13250 [D loss: 0.634220, acc.: 64.84%] [G loss: 0.528461]\n",
      "epoch:14 step:13251 [D loss: 0.562032, acc.: 71.09%] [G loss: 0.689407]\n",
      "epoch:14 step:13252 [D loss: 0.554868, acc.: 69.53%] [G loss: 0.621627]\n",
      "epoch:14 step:13253 [D loss: 0.483086, acc.: 76.56%] [G loss: 0.871591]\n",
      "epoch:14 step:13254 [D loss: 0.538253, acc.: 72.66%] [G loss: 0.855369]\n",
      "epoch:14 step:13255 [D loss: 0.626067, acc.: 68.75%] [G loss: 0.531858]\n",
      "epoch:14 step:13256 [D loss: 0.595044, acc.: 66.41%] [G loss: 0.581105]\n",
      "epoch:14 step:13257 [D loss: 0.557211, acc.: 67.19%] [G loss: 0.535002]\n",
      "epoch:14 step:13258 [D loss: 0.573019, acc.: 67.97%] [G loss: 0.564827]\n",
      "epoch:14 step:13259 [D loss: 0.598642, acc.: 62.50%] [G loss: 0.545382]\n",
      "epoch:14 step:13260 [D loss: 0.586707, acc.: 61.72%] [G loss: 0.630737]\n",
      "epoch:14 step:13261 [D loss: 0.567300, acc.: 69.53%] [G loss: 0.596613]\n",
      "epoch:14 step:13262 [D loss: 0.535721, acc.: 70.31%] [G loss: 0.532847]\n",
      "epoch:14 step:13263 [D loss: 0.560930, acc.: 69.53%] [G loss: 0.641190]\n",
      "epoch:14 step:13264 [D loss: 0.491952, acc.: 77.34%] [G loss: 0.637264]\n",
      "epoch:14 step:13265 [D loss: 0.624633, acc.: 63.28%] [G loss: 0.483075]\n",
      "epoch:14 step:13266 [D loss: 0.634823, acc.: 62.50%] [G loss: 0.531599]\n",
      "epoch:14 step:13267 [D loss: 0.534361, acc.: 71.88%] [G loss: 0.487135]\n",
      "epoch:14 step:13268 [D loss: 0.547371, acc.: 71.88%] [G loss: 0.498376]\n",
      "epoch:14 step:13269 [D loss: 0.573699, acc.: 64.84%] [G loss: 0.531239]\n",
      "epoch:14 step:13270 [D loss: 0.495511, acc.: 75.00%] [G loss: 0.612947]\n",
      "epoch:14 step:13271 [D loss: 0.572867, acc.: 70.31%] [G loss: 0.622401]\n",
      "epoch:14 step:13272 [D loss: 0.548692, acc.: 71.09%] [G loss: 0.603685]\n",
      "epoch:14 step:13273 [D loss: 0.471258, acc.: 77.34%] [G loss: 0.630058]\n",
      "epoch:14 step:13274 [D loss: 0.535760, acc.: 66.41%] [G loss: 0.708732]\n",
      "epoch:14 step:13275 [D loss: 0.553898, acc.: 65.62%] [G loss: 0.586895]\n",
      "epoch:14 step:13276 [D loss: 0.579730, acc.: 67.97%] [G loss: 0.524617]\n",
      "epoch:14 step:13277 [D loss: 0.473674, acc.: 78.12%] [G loss: 0.590186]\n",
      "epoch:14 step:13278 [D loss: 0.630085, acc.: 66.41%] [G loss: 0.640962]\n",
      "epoch:14 step:13279 [D loss: 0.543617, acc.: 68.75%] [G loss: 0.636559]\n",
      "epoch:14 step:13280 [D loss: 0.506645, acc.: 72.66%] [G loss: 0.761031]\n",
      "epoch:14 step:13281 [D loss: 0.606970, acc.: 66.41%] [G loss: 0.569023]\n",
      "epoch:14 step:13282 [D loss: 0.532116, acc.: 72.66%] [G loss: 0.742514]\n",
      "epoch:14 step:13283 [D loss: 0.535017, acc.: 71.88%] [G loss: 0.541471]\n",
      "epoch:14 step:13284 [D loss: 0.615839, acc.: 65.62%] [G loss: 0.620129]\n",
      "epoch:14 step:13285 [D loss: 0.573905, acc.: 66.41%] [G loss: 0.581327]\n",
      "epoch:14 step:13286 [D loss: 0.567694, acc.: 71.88%] [G loss: 0.427074]\n",
      "epoch:14 step:13287 [D loss: 0.608734, acc.: 68.75%] [G loss: 0.404942]\n",
      "epoch:14 step:13288 [D loss: 0.552343, acc.: 69.53%] [G loss: 0.444997]\n",
      "epoch:14 step:13289 [D loss: 0.512883, acc.: 73.44%] [G loss: 0.530736]\n",
      "epoch:14 step:13290 [D loss: 0.502716, acc.: 74.22%] [G loss: 0.519124]\n",
      "epoch:14 step:13291 [D loss: 0.490457, acc.: 75.78%] [G loss: 0.667438]\n",
      "epoch:14 step:13292 [D loss: 0.558713, acc.: 69.53%] [G loss: 0.557883]\n",
      "epoch:14 step:13293 [D loss: 0.613833, acc.: 64.84%] [G loss: 0.361817]\n",
      "epoch:14 step:13294 [D loss: 0.548389, acc.: 71.88%] [G loss: 0.556725]\n",
      "epoch:14 step:13295 [D loss: 0.521111, acc.: 71.88%] [G loss: 0.679058]\n",
      "epoch:14 step:13296 [D loss: 0.620824, acc.: 64.84%] [G loss: 0.457475]\n",
      "epoch:14 step:13297 [D loss: 0.565751, acc.: 67.19%] [G loss: 0.640651]\n",
      "epoch:14 step:13298 [D loss: 0.622549, acc.: 66.41%] [G loss: 0.502320]\n",
      "epoch:14 step:13299 [D loss: 0.595384, acc.: 62.50%] [G loss: 0.468408]\n",
      "epoch:14 step:13300 [D loss: 0.583510, acc.: 68.75%] [G loss: 0.553561]\n",
      "epoch:14 step:13301 [D loss: 0.582259, acc.: 69.53%] [G loss: 0.611982]\n",
      "epoch:14 step:13302 [D loss: 0.505509, acc.: 73.44%] [G loss: 0.585328]\n",
      "epoch:14 step:13303 [D loss: 0.571876, acc.: 67.97%] [G loss: 0.557166]\n",
      "epoch:14 step:13304 [D loss: 0.528180, acc.: 72.66%] [G loss: 0.672300]\n",
      "epoch:14 step:13305 [D loss: 0.615781, acc.: 64.84%] [G loss: 0.510241]\n",
      "epoch:14 step:13306 [D loss: 0.572770, acc.: 74.22%] [G loss: 0.594667]\n",
      "epoch:14 step:13307 [D loss: 0.548549, acc.: 67.19%] [G loss: 0.554474]\n",
      "epoch:14 step:13308 [D loss: 0.501364, acc.: 78.12%] [G loss: 0.524380]\n",
      "epoch:14 step:13309 [D loss: 0.498210, acc.: 72.66%] [G loss: 0.708042]\n",
      "epoch:14 step:13310 [D loss: 0.536474, acc.: 73.44%] [G loss: 0.627323]\n",
      "epoch:14 step:13311 [D loss: 0.576013, acc.: 67.19%] [G loss: 0.544454]\n",
      "epoch:14 step:13312 [D loss: 0.480650, acc.: 77.34%] [G loss: 0.618706]\n",
      "epoch:14 step:13313 [D loss: 0.585548, acc.: 67.97%] [G loss: 0.643389]\n",
      "epoch:14 step:13314 [D loss: 0.546929, acc.: 69.53%] [G loss: 0.663155]\n",
      "epoch:14 step:13315 [D loss: 0.513554, acc.: 71.88%] [G loss: 0.524357]\n",
      "epoch:14 step:13316 [D loss: 0.498318, acc.: 75.78%] [G loss: 0.729054]\n",
      "epoch:14 step:13317 [D loss: 0.467982, acc.: 75.00%] [G loss: 0.756156]\n",
      "epoch:14 step:13318 [D loss: 0.611543, acc.: 66.41%] [G loss: 0.465854]\n",
      "epoch:14 step:13319 [D loss: 0.597697, acc.: 62.50%] [G loss: 0.495682]\n",
      "epoch:14 step:13320 [D loss: 0.521529, acc.: 69.53%] [G loss: 0.589080]\n",
      "epoch:14 step:13321 [D loss: 0.577694, acc.: 64.84%] [G loss: 0.611827]\n",
      "epoch:14 step:13322 [D loss: 0.542718, acc.: 75.00%] [G loss: 0.600665]\n",
      "epoch:14 step:13323 [D loss: 0.557723, acc.: 72.66%] [G loss: 0.855923]\n",
      "epoch:14 step:13324 [D loss: 0.558073, acc.: 72.66%] [G loss: 0.654306]\n",
      "epoch:14 step:13325 [D loss: 0.466003, acc.: 78.12%] [G loss: 0.674812]\n",
      "epoch:14 step:13326 [D loss: 0.447265, acc.: 78.91%] [G loss: 0.685825]\n",
      "epoch:14 step:13327 [D loss: 0.489870, acc.: 75.00%] [G loss: 0.833357]\n",
      "epoch:14 step:13328 [D loss: 0.591405, acc.: 67.19%] [G loss: 0.598836]\n",
      "epoch:14 step:13329 [D loss: 0.598474, acc.: 61.72%] [G loss: 0.495665]\n",
      "epoch:14 step:13330 [D loss: 0.589927, acc.: 71.88%] [G loss: 0.644224]\n",
      "epoch:14 step:13331 [D loss: 0.574317, acc.: 67.19%] [G loss: 0.542541]\n",
      "epoch:14 step:13332 [D loss: 0.681578, acc.: 62.50%] [G loss: 0.589670]\n",
      "epoch:14 step:13333 [D loss: 0.534867, acc.: 71.09%] [G loss: 0.543351]\n",
      "epoch:14 step:13334 [D loss: 0.569829, acc.: 67.19%] [G loss: 0.527326]\n",
      "epoch:14 step:13335 [D loss: 0.504080, acc.: 71.09%] [G loss: 0.654684]\n",
      "epoch:14 step:13336 [D loss: 0.528259, acc.: 75.78%] [G loss: 0.627028]\n",
      "epoch:14 step:13337 [D loss: 0.491577, acc.: 78.91%] [G loss: 0.715702]\n",
      "epoch:14 step:13338 [D loss: 0.697765, acc.: 61.72%] [G loss: 0.544167]\n",
      "epoch:14 step:13339 [D loss: 0.490513, acc.: 77.34%] [G loss: 0.575511]\n",
      "epoch:14 step:13340 [D loss: 0.487835, acc.: 75.78%] [G loss: 0.763567]\n",
      "epoch:14 step:13341 [D loss: 0.490837, acc.: 75.78%] [G loss: 0.726664]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:14 step:13342 [D loss: 0.569982, acc.: 71.09%] [G loss: 0.731602]\n",
      "epoch:14 step:13343 [D loss: 0.517472, acc.: 74.22%] [G loss: 0.755064]\n",
      "epoch:14 step:13344 [D loss: 0.583099, acc.: 64.84%] [G loss: 0.637641]\n",
      "epoch:14 step:13345 [D loss: 0.557600, acc.: 70.31%] [G loss: 0.569945]\n",
      "epoch:14 step:13346 [D loss: 0.613749, acc.: 65.62%] [G loss: 0.654084]\n",
      "epoch:14 step:13347 [D loss: 0.498168, acc.: 79.69%] [G loss: 0.570487]\n",
      "epoch:14 step:13348 [D loss: 0.552111, acc.: 71.09%] [G loss: 0.750414]\n",
      "epoch:14 step:13349 [D loss: 0.445397, acc.: 79.69%] [G loss: 0.885706]\n",
      "epoch:14 step:13350 [D loss: 0.458024, acc.: 80.47%] [G loss: 1.097662]\n",
      "epoch:14 step:13351 [D loss: 0.600772, acc.: 68.75%] [G loss: 0.626813]\n",
      "epoch:14 step:13352 [D loss: 0.627784, acc.: 67.19%] [G loss: 0.691546]\n",
      "epoch:14 step:13353 [D loss: 0.600332, acc.: 65.62%] [G loss: 0.625772]\n",
      "epoch:14 step:13354 [D loss: 0.556569, acc.: 71.09%] [G loss: 0.455694]\n",
      "epoch:14 step:13355 [D loss: 0.547681, acc.: 67.97%] [G loss: 0.441558]\n",
      "epoch:14 step:13356 [D loss: 0.577615, acc.: 68.75%] [G loss: 0.457153]\n",
      "epoch:14 step:13357 [D loss: 0.538575, acc.: 71.88%] [G loss: 0.615927]\n",
      "epoch:14 step:13358 [D loss: 0.552948, acc.: 74.22%] [G loss: 0.482263]\n",
      "epoch:14 step:13359 [D loss: 0.549212, acc.: 73.44%] [G loss: 0.469027]\n",
      "epoch:14 step:13360 [D loss: 0.523589, acc.: 71.88%] [G loss: 0.520823]\n",
      "epoch:14 step:13361 [D loss: 0.531986, acc.: 69.53%] [G loss: 0.612509]\n",
      "epoch:14 step:13362 [D loss: 0.477749, acc.: 75.78%] [G loss: 0.659456]\n",
      "epoch:14 step:13363 [D loss: 0.548803, acc.: 72.66%] [G loss: 0.523095]\n",
      "epoch:14 step:13364 [D loss: 0.502681, acc.: 69.53%] [G loss: 0.775161]\n",
      "epoch:14 step:13365 [D loss: 0.539976, acc.: 67.97%] [G loss: 0.746509]\n",
      "epoch:14 step:13366 [D loss: 0.579178, acc.: 69.53%] [G loss: 0.656185]\n",
      "epoch:14 step:13367 [D loss: 0.549944, acc.: 67.97%] [G loss: 0.761044]\n",
      "epoch:14 step:13368 [D loss: 0.644346, acc.: 60.94%] [G loss: 0.594471]\n",
      "epoch:14 step:13369 [D loss: 0.590987, acc.: 67.19%] [G loss: 0.648090]\n",
      "epoch:14 step:13370 [D loss: 0.558449, acc.: 74.22%] [G loss: 0.563038]\n",
      "epoch:14 step:13371 [D loss: 0.572996, acc.: 68.75%] [G loss: 0.646112]\n",
      "epoch:14 step:13372 [D loss: 0.523819, acc.: 75.78%] [G loss: 0.554153]\n",
      "epoch:14 step:13373 [D loss: 0.566453, acc.: 68.75%] [G loss: 0.584533]\n",
      "epoch:14 step:13374 [D loss: 0.550653, acc.: 69.53%] [G loss: 0.650192]\n",
      "epoch:14 step:13375 [D loss: 0.573535, acc.: 60.94%] [G loss: 0.520302]\n",
      "epoch:14 step:13376 [D loss: 0.531048, acc.: 71.09%] [G loss: 0.610874]\n",
      "epoch:14 step:13377 [D loss: 0.559397, acc.: 63.28%] [G loss: 0.617344]\n",
      "epoch:14 step:13378 [D loss: 0.585582, acc.: 66.41%] [G loss: 0.598184]\n",
      "epoch:14 step:13379 [D loss: 0.552020, acc.: 70.31%] [G loss: 0.534161]\n",
      "epoch:14 step:13380 [D loss: 0.485267, acc.: 75.78%] [G loss: 0.555641]\n",
      "epoch:14 step:13381 [D loss: 0.619230, acc.: 71.09%] [G loss: 0.478158]\n",
      "epoch:14 step:13382 [D loss: 0.537645, acc.: 68.75%] [G loss: 0.586310]\n",
      "epoch:14 step:13383 [D loss: 0.562927, acc.: 67.19%] [G loss: 0.564626]\n",
      "epoch:14 step:13384 [D loss: 0.511451, acc.: 72.66%] [G loss: 0.568942]\n",
      "epoch:14 step:13385 [D loss: 0.578017, acc.: 66.41%] [G loss: 0.593381]\n",
      "epoch:14 step:13386 [D loss: 0.580281, acc.: 62.50%] [G loss: 0.515554]\n",
      "epoch:14 step:13387 [D loss: 0.506843, acc.: 76.56%] [G loss: 0.635275]\n",
      "epoch:14 step:13388 [D loss: 0.506544, acc.: 73.44%] [G loss: 0.583959]\n",
      "epoch:14 step:13389 [D loss: 0.520635, acc.: 72.66%] [G loss: 0.670035]\n",
      "epoch:14 step:13390 [D loss: 0.522485, acc.: 72.66%] [G loss: 0.626301]\n",
      "epoch:14 step:13391 [D loss: 0.584316, acc.: 67.19%] [G loss: 0.576499]\n",
      "epoch:14 step:13392 [D loss: 0.508978, acc.: 73.44%] [G loss: 0.572800]\n",
      "epoch:14 step:13393 [D loss: 0.565340, acc.: 67.97%] [G loss: 0.523642]\n",
      "epoch:14 step:13394 [D loss: 0.502778, acc.: 78.12%] [G loss: 0.580031]\n",
      "epoch:14 step:13395 [D loss: 0.682617, acc.: 61.72%] [G loss: 0.373022]\n",
      "epoch:14 step:13396 [D loss: 0.615936, acc.: 71.09%] [G loss: 0.443741]\n",
      "epoch:14 step:13397 [D loss: 0.582121, acc.: 67.19%] [G loss: 0.460977]\n",
      "epoch:14 step:13398 [D loss: 0.607385, acc.: 70.31%] [G loss: 0.570695]\n",
      "epoch:14 step:13399 [D loss: 0.560180, acc.: 70.31%] [G loss: 0.515172]\n",
      "epoch:14 step:13400 [D loss: 0.575352, acc.: 71.09%] [G loss: 0.481324]\n",
      "##############\n",
      "[3.07711773 1.25865614 6.34007842 4.7633596  3.79660466 5.65030656\n",
      " 4.50582288 5.02554558 4.70427585 4.04246482]\n",
      "##########\n",
      "epoch:14 step:13401 [D loss: 0.550946, acc.: 75.00%] [G loss: 0.682982]\n",
      "epoch:14 step:13402 [D loss: 0.596506, acc.: 71.09%] [G loss: 0.583118]\n",
      "epoch:14 step:13403 [D loss: 0.532418, acc.: 74.22%] [G loss: 0.537896]\n",
      "epoch:14 step:13404 [D loss: 0.488097, acc.: 75.00%] [G loss: 0.716324]\n",
      "epoch:14 step:13405 [D loss: 0.557093, acc.: 69.53%] [G loss: 0.550578]\n",
      "epoch:14 step:13406 [D loss: 0.628846, acc.: 64.06%] [G loss: 0.620220]\n",
      "epoch:14 step:13407 [D loss: 0.506313, acc.: 74.22%] [G loss: 0.557310]\n",
      "epoch:14 step:13408 [D loss: 0.534979, acc.: 71.09%] [G loss: 0.545448]\n",
      "epoch:14 step:13409 [D loss: 0.584853, acc.: 66.41%] [G loss: 0.585009]\n",
      "epoch:14 step:13410 [D loss: 0.564523, acc.: 70.31%] [G loss: 0.571215]\n",
      "epoch:14 step:13411 [D loss: 0.593951, acc.: 63.28%] [G loss: 0.546220]\n",
      "epoch:14 step:13412 [D loss: 0.585883, acc.: 67.19%] [G loss: 0.516896]\n",
      "epoch:14 step:13413 [D loss: 0.579318, acc.: 63.28%] [G loss: 0.670850]\n",
      "epoch:14 step:13414 [D loss: 0.470615, acc.: 80.47%] [G loss: 0.514000]\n",
      "epoch:14 step:13415 [D loss: 0.596064, acc.: 67.19%] [G loss: 0.509384]\n",
      "epoch:14 step:13416 [D loss: 0.455930, acc.: 79.69%] [G loss: 0.587488]\n",
      "epoch:14 step:13417 [D loss: 0.524195, acc.: 77.34%] [G loss: 0.703742]\n",
      "epoch:14 step:13418 [D loss: 0.501827, acc.: 73.44%] [G loss: 0.702424]\n",
      "epoch:14 step:13419 [D loss: 0.610323, acc.: 63.28%] [G loss: 0.691823]\n",
      "epoch:14 step:13420 [D loss: 0.567784, acc.: 67.19%] [G loss: 0.477334]\n",
      "epoch:14 step:13421 [D loss: 0.574890, acc.: 71.09%] [G loss: 0.645576]\n",
      "epoch:14 step:13422 [D loss: 0.491680, acc.: 73.44%] [G loss: 0.774414]\n",
      "epoch:14 step:13423 [D loss: 0.518581, acc.: 74.22%] [G loss: 0.602007]\n",
      "epoch:14 step:13424 [D loss: 0.539665, acc.: 73.44%] [G loss: 0.726105]\n",
      "epoch:14 step:13425 [D loss: 0.470159, acc.: 77.34%] [G loss: 0.615431]\n",
      "epoch:14 step:13426 [D loss: 0.583072, acc.: 67.97%] [G loss: 0.610865]\n",
      "epoch:14 step:13427 [D loss: 0.530544, acc.: 67.97%] [G loss: 0.712494]\n",
      "epoch:14 step:13428 [D loss: 0.543762, acc.: 68.75%] [G loss: 0.562384]\n",
      "epoch:14 step:13429 [D loss: 0.514139, acc.: 72.66%] [G loss: 0.841002]\n",
      "epoch:14 step:13430 [D loss: 0.462130, acc.: 81.25%] [G loss: 0.840304]\n",
      "epoch:14 step:13431 [D loss: 0.481903, acc.: 78.91%] [G loss: 1.003895]\n",
      "epoch:14 step:13432 [D loss: 0.447333, acc.: 78.12%] [G loss: 1.063563]\n",
      "epoch:14 step:13433 [D loss: 0.461562, acc.: 80.47%] [G loss: 0.982243]\n",
      "epoch:14 step:13434 [D loss: 0.742596, acc.: 57.81%] [G loss: 0.687802]\n",
      "epoch:14 step:13435 [D loss: 0.566339, acc.: 67.97%] [G loss: 0.652218]\n",
      "epoch:14 step:13436 [D loss: 0.538449, acc.: 72.66%] [G loss: 0.708304]\n",
      "epoch:14 step:13437 [D loss: 0.541367, acc.: 67.97%] [G loss: 0.559016]\n",
      "epoch:14 step:13438 [D loss: 0.547966, acc.: 68.75%] [G loss: 0.563735]\n",
      "epoch:14 step:13439 [D loss: 0.482970, acc.: 76.56%] [G loss: 0.809605]\n",
      "epoch:14 step:13440 [D loss: 0.559029, acc.: 65.62%] [G loss: 0.744852]\n",
      "epoch:14 step:13441 [D loss: 0.604650, acc.: 64.06%] [G loss: 0.624780]\n",
      "epoch:14 step:13442 [D loss: 0.560081, acc.: 67.97%] [G loss: 0.427405]\n",
      "epoch:14 step:13443 [D loss: 0.525865, acc.: 68.75%] [G loss: 0.516427]\n",
      "epoch:14 step:13444 [D loss: 0.492357, acc.: 74.22%] [G loss: 0.577890]\n",
      "epoch:14 step:13445 [D loss: 0.544588, acc.: 73.44%] [G loss: 0.659818]\n",
      "epoch:14 step:13446 [D loss: 0.504742, acc.: 75.78%] [G loss: 0.717301]\n",
      "epoch:14 step:13447 [D loss: 0.516855, acc.: 75.78%] [G loss: 0.625208]\n",
      "epoch:14 step:13448 [D loss: 0.560111, acc.: 67.97%] [G loss: 0.677046]\n",
      "epoch:14 step:13449 [D loss: 0.581479, acc.: 66.41%] [G loss: 0.466753]\n",
      "epoch:14 step:13450 [D loss: 0.500254, acc.: 66.41%] [G loss: 0.532731]\n",
      "epoch:14 step:13451 [D loss: 0.493894, acc.: 74.22%] [G loss: 0.456957]\n",
      "epoch:14 step:13452 [D loss: 0.532273, acc.: 75.00%] [G loss: 0.633941]\n",
      "epoch:14 step:13453 [D loss: 0.549787, acc.: 69.53%] [G loss: 0.708477]\n",
      "epoch:14 step:13454 [D loss: 0.490694, acc.: 74.22%] [G loss: 0.620901]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:14 step:13455 [D loss: 0.540252, acc.: 73.44%] [G loss: 0.720653]\n",
      "epoch:14 step:13456 [D loss: 0.591488, acc.: 64.84%] [G loss: 0.510806]\n",
      "epoch:14 step:13457 [D loss: 0.556782, acc.: 68.75%] [G loss: 0.541849]\n",
      "epoch:14 step:13458 [D loss: 0.479388, acc.: 77.34%] [G loss: 0.754770]\n",
      "epoch:14 step:13459 [D loss: 0.583395, acc.: 72.66%] [G loss: 0.535358]\n",
      "epoch:14 step:13460 [D loss: 0.580084, acc.: 67.19%] [G loss: 0.530730]\n",
      "epoch:14 step:13461 [D loss: 0.494300, acc.: 72.66%] [G loss: 0.611181]\n",
      "epoch:14 step:13462 [D loss: 0.483182, acc.: 73.44%] [G loss: 0.880630]\n",
      "epoch:14 step:13463 [D loss: 0.610415, acc.: 60.16%] [G loss: 0.832859]\n",
      "epoch:14 step:13464 [D loss: 0.531848, acc.: 74.22%] [G loss: 0.874756]\n",
      "epoch:14 step:13465 [D loss: 0.496698, acc.: 77.34%] [G loss: 1.153995]\n",
      "epoch:14 step:13466 [D loss: 0.660156, acc.: 63.28%] [G loss: 0.699606]\n",
      "epoch:14 step:13467 [D loss: 0.684469, acc.: 61.72%] [G loss: 0.573205]\n",
      "epoch:14 step:13468 [D loss: 0.493452, acc.: 75.78%] [G loss: 0.593790]\n",
      "epoch:14 step:13469 [D loss: 0.557244, acc.: 71.09%] [G loss: 0.654124]\n",
      "epoch:14 step:13470 [D loss: 0.582053, acc.: 67.97%] [G loss: 0.751343]\n",
      "epoch:14 step:13471 [D loss: 0.598011, acc.: 71.09%] [G loss: 0.742820]\n",
      "epoch:14 step:13472 [D loss: 0.407458, acc.: 84.38%] [G loss: 0.869913]\n",
      "epoch:14 step:13473 [D loss: 0.516208, acc.: 71.09%] [G loss: 0.882466]\n",
      "epoch:14 step:13474 [D loss: 0.551914, acc.: 71.88%] [G loss: 0.637149]\n",
      "epoch:14 step:13475 [D loss: 0.457121, acc.: 75.78%] [G loss: 0.667270]\n",
      "epoch:14 step:13476 [D loss: 0.470505, acc.: 75.78%] [G loss: 0.915298]\n",
      "epoch:14 step:13477 [D loss: 0.500379, acc.: 73.44%] [G loss: 0.828886]\n",
      "epoch:14 step:13478 [D loss: 0.486563, acc.: 74.22%] [G loss: 0.825675]\n",
      "epoch:14 step:13479 [D loss: 0.511625, acc.: 74.22%] [G loss: 0.949370]\n",
      "epoch:14 step:13480 [D loss: 0.526812, acc.: 73.44%] [G loss: 0.792166]\n",
      "epoch:14 step:13481 [D loss: 0.517111, acc.: 72.66%] [G loss: 0.642954]\n",
      "epoch:14 step:13482 [D loss: 0.574822, acc.: 66.41%] [G loss: 0.579516]\n",
      "epoch:14 step:13483 [D loss: 0.598904, acc.: 64.84%] [G loss: 0.641221]\n",
      "epoch:14 step:13484 [D loss: 0.537001, acc.: 71.09%] [G loss: 0.671434]\n",
      "epoch:14 step:13485 [D loss: 0.577559, acc.: 68.75%] [G loss: 0.806645]\n",
      "epoch:14 step:13486 [D loss: 0.517695, acc.: 74.22%] [G loss: 0.583582]\n",
      "epoch:14 step:13487 [D loss: 0.539767, acc.: 70.31%] [G loss: 0.563495]\n",
      "epoch:14 step:13488 [D loss: 0.565185, acc.: 68.75%] [G loss: 0.574404]\n",
      "epoch:14 step:13489 [D loss: 0.539075, acc.: 71.09%] [G loss: 0.658126]\n",
      "epoch:14 step:13490 [D loss: 0.558252, acc.: 65.62%] [G loss: 0.646447]\n",
      "epoch:14 step:13491 [D loss: 0.575662, acc.: 64.06%] [G loss: 0.682479]\n",
      "epoch:14 step:13492 [D loss: 0.456999, acc.: 75.00%] [G loss: 0.753581]\n",
      "epoch:14 step:13493 [D loss: 0.598280, acc.: 67.19%] [G loss: 0.592607]\n",
      "epoch:14 step:13494 [D loss: 0.724333, acc.: 57.03%] [G loss: 0.458072]\n",
      "epoch:14 step:13495 [D loss: 0.582317, acc.: 63.28%] [G loss: 0.569672]\n",
      "epoch:14 step:13496 [D loss: 0.642289, acc.: 63.28%] [G loss: 0.670780]\n",
      "epoch:14 step:13497 [D loss: 0.596785, acc.: 70.31%] [G loss: 0.571881]\n",
      "epoch:14 step:13498 [D loss: 0.583640, acc.: 65.62%] [G loss: 0.474419]\n",
      "epoch:14 step:13499 [D loss: 0.503932, acc.: 74.22%] [G loss: 0.567070]\n",
      "epoch:14 step:13500 [D loss: 0.539337, acc.: 72.66%] [G loss: 0.532416]\n",
      "epoch:14 step:13501 [D loss: 0.556630, acc.: 70.31%] [G loss: 0.609723]\n",
      "epoch:14 step:13502 [D loss: 0.587096, acc.: 66.41%] [G loss: 0.475727]\n",
      "epoch:14 step:13503 [D loss: 0.481958, acc.: 77.34%] [G loss: 0.690869]\n",
      "epoch:14 step:13504 [D loss: 0.556395, acc.: 70.31%] [G loss: 0.622559]\n",
      "epoch:14 step:13505 [D loss: 0.503851, acc.: 74.22%] [G loss: 0.586562]\n",
      "epoch:14 step:13506 [D loss: 0.495815, acc.: 76.56%] [G loss: 0.606695]\n",
      "epoch:14 step:13507 [D loss: 0.550593, acc.: 67.19%] [G loss: 0.632531]\n",
      "epoch:14 step:13508 [D loss: 0.582675, acc.: 63.28%] [G loss: 0.519589]\n",
      "epoch:14 step:13509 [D loss: 0.553909, acc.: 71.09%] [G loss: 0.565287]\n",
      "epoch:14 step:13510 [D loss: 0.483359, acc.: 79.69%] [G loss: 0.709897]\n",
      "epoch:14 step:13511 [D loss: 0.651416, acc.: 60.94%] [G loss: 0.737096]\n",
      "epoch:14 step:13512 [D loss: 0.497952, acc.: 75.78%] [G loss: 0.555347]\n",
      "epoch:14 step:13513 [D loss: 0.513722, acc.: 74.22%] [G loss: 0.545854]\n",
      "epoch:14 step:13514 [D loss: 0.565493, acc.: 72.66%] [G loss: 0.418735]\n",
      "epoch:14 step:13515 [D loss: 0.538609, acc.: 70.31%] [G loss: 0.542291]\n",
      "epoch:14 step:13516 [D loss: 0.471300, acc.: 78.91%] [G loss: 0.729559]\n",
      "epoch:14 step:13517 [D loss: 0.505669, acc.: 78.12%] [G loss: 0.792651]\n",
      "epoch:14 step:13518 [D loss: 0.632480, acc.: 63.28%] [G loss: 0.681974]\n",
      "epoch:14 step:13519 [D loss: 0.672566, acc.: 56.25%] [G loss: 0.477803]\n",
      "epoch:14 step:13520 [D loss: 0.495393, acc.: 77.34%] [G loss: 0.657536]\n",
      "epoch:14 step:13521 [D loss: 0.474134, acc.: 74.22%] [G loss: 0.729419]\n",
      "epoch:14 step:13522 [D loss: 0.574950, acc.: 65.62%] [G loss: 0.608842]\n",
      "epoch:14 step:13523 [D loss: 0.516552, acc.: 75.00%] [G loss: 0.869876]\n",
      "epoch:14 step:13524 [D loss: 0.536109, acc.: 68.75%] [G loss: 0.577638]\n",
      "epoch:14 step:13525 [D loss: 0.535734, acc.: 74.22%] [G loss: 0.540676]\n",
      "epoch:14 step:13526 [D loss: 0.621444, acc.: 64.06%] [G loss: 0.550154]\n",
      "epoch:14 step:13527 [D loss: 0.600895, acc.: 61.72%] [G loss: 0.591171]\n",
      "epoch:14 step:13528 [D loss: 0.611209, acc.: 66.41%] [G loss: 0.557991]\n",
      "epoch:14 step:13529 [D loss: 0.602782, acc.: 64.84%] [G loss: 0.544551]\n",
      "epoch:14 step:13530 [D loss: 0.592846, acc.: 64.84%] [G loss: 0.453551]\n",
      "epoch:14 step:13531 [D loss: 0.544050, acc.: 68.75%] [G loss: 0.549695]\n",
      "epoch:14 step:13532 [D loss: 0.546695, acc.: 67.19%] [G loss: 0.547137]\n",
      "epoch:14 step:13533 [D loss: 0.552993, acc.: 68.75%] [G loss: 0.641043]\n",
      "epoch:14 step:13534 [D loss: 0.480255, acc.: 81.25%] [G loss: 0.728096]\n",
      "epoch:14 step:13535 [D loss: 0.612846, acc.: 64.84%] [G loss: 0.742764]\n",
      "epoch:14 step:13536 [D loss: 0.603140, acc.: 67.97%] [G loss: 0.612979]\n",
      "epoch:14 step:13537 [D loss: 0.599296, acc.: 67.19%] [G loss: 0.583597]\n",
      "epoch:14 step:13538 [D loss: 0.574807, acc.: 60.94%] [G loss: 0.694997]\n",
      "epoch:14 step:13539 [D loss: 0.579792, acc.: 65.62%] [G loss: 0.534899]\n",
      "epoch:14 step:13540 [D loss: 0.552715, acc.: 64.84%] [G loss: 0.514288]\n",
      "epoch:14 step:13541 [D loss: 0.531695, acc.: 75.00%] [G loss: 0.664303]\n",
      "epoch:14 step:13542 [D loss: 0.570355, acc.: 65.62%] [G loss: 0.692533]\n",
      "epoch:14 step:13543 [D loss: 0.586589, acc.: 64.06%] [G loss: 0.558948]\n",
      "epoch:14 step:13544 [D loss: 0.504018, acc.: 72.66%] [G loss: 0.718497]\n",
      "epoch:14 step:13545 [D loss: 0.472110, acc.: 73.44%] [G loss: 0.901550]\n",
      "epoch:14 step:13546 [D loss: 0.516219, acc.: 71.88%] [G loss: 0.676320]\n",
      "epoch:14 step:13547 [D loss: 0.499222, acc.: 78.12%] [G loss: 0.821952]\n",
      "epoch:14 step:13548 [D loss: 0.571036, acc.: 66.41%] [G loss: 0.684212]\n",
      "epoch:14 step:13549 [D loss: 0.538870, acc.: 70.31%] [G loss: 0.551041]\n",
      "epoch:14 step:13550 [D loss: 0.550038, acc.: 69.53%] [G loss: 0.600860]\n",
      "epoch:14 step:13551 [D loss: 0.570388, acc.: 69.53%] [G loss: 0.565041]\n",
      "epoch:14 step:13552 [D loss: 0.545837, acc.: 72.66%] [G loss: 0.459010]\n",
      "epoch:14 step:13553 [D loss: 0.509206, acc.: 76.56%] [G loss: 0.585479]\n",
      "epoch:14 step:13554 [D loss: 0.509702, acc.: 73.44%] [G loss: 0.763885]\n",
      "epoch:14 step:13555 [D loss: 0.656427, acc.: 63.28%] [G loss: 0.536437]\n",
      "epoch:14 step:13556 [D loss: 0.534173, acc.: 69.53%] [G loss: 0.604151]\n",
      "epoch:14 step:13557 [D loss: 0.527754, acc.: 69.53%] [G loss: 0.796050]\n",
      "epoch:14 step:13558 [D loss: 0.483650, acc.: 75.78%] [G loss: 0.658492]\n",
      "epoch:14 step:13559 [D loss: 0.519798, acc.: 74.22%] [G loss: 0.787614]\n",
      "epoch:14 step:13560 [D loss: 0.569121, acc.: 70.31%] [G loss: 0.783806]\n",
      "epoch:14 step:13561 [D loss: 0.533647, acc.: 74.22%] [G loss: 0.664277]\n",
      "epoch:14 step:13562 [D loss: 0.497080, acc.: 73.44%] [G loss: 0.660069]\n",
      "epoch:14 step:13563 [D loss: 0.613002, acc.: 61.72%] [G loss: 0.595842]\n",
      "epoch:14 step:13564 [D loss: 0.516252, acc.: 74.22%] [G loss: 0.799509]\n",
      "epoch:14 step:13565 [D loss: 0.548100, acc.: 72.66%] [G loss: 0.608349]\n",
      "epoch:14 step:13566 [D loss: 0.517298, acc.: 76.56%] [G loss: 0.683752]\n",
      "epoch:14 step:13567 [D loss: 0.506581, acc.: 72.66%] [G loss: 0.747572]\n",
      "epoch:14 step:13568 [D loss: 0.514098, acc.: 73.44%] [G loss: 0.839953]\n",
      "epoch:14 step:13569 [D loss: 0.429497, acc.: 82.03%] [G loss: 0.840711]\n",
      "epoch:14 step:13570 [D loss: 0.475958, acc.: 78.12%] [G loss: 0.659705]\n",
      "epoch:14 step:13571 [D loss: 0.539626, acc.: 71.88%] [G loss: 0.818719]\n",
      "epoch:14 step:13572 [D loss: 0.593846, acc.: 70.31%] [G loss: 0.675362]\n",
      "epoch:14 step:13573 [D loss: 0.562842, acc.: 69.53%] [G loss: 0.555574]\n",
      "epoch:14 step:13574 [D loss: 0.668151, acc.: 62.50%] [G loss: 0.541583]\n",
      "epoch:14 step:13575 [D loss: 0.453842, acc.: 82.81%] [G loss: 0.755780]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:14 step:13576 [D loss: 0.689744, acc.: 62.50%] [G loss: 0.477818]\n",
      "epoch:14 step:13577 [D loss: 0.606761, acc.: 67.97%] [G loss: 0.535823]\n",
      "epoch:14 step:13578 [D loss: 0.566542, acc.: 72.66%] [G loss: 0.624499]\n",
      "epoch:14 step:13579 [D loss: 0.498148, acc.: 74.22%] [G loss: 0.713064]\n",
      "epoch:14 step:13580 [D loss: 0.561403, acc.: 67.97%] [G loss: 0.604965]\n",
      "epoch:14 step:13581 [D loss: 0.602359, acc.: 65.62%] [G loss: 0.432919]\n",
      "epoch:14 step:13582 [D loss: 0.490754, acc.: 75.78%] [G loss: 0.663630]\n",
      "epoch:14 step:13583 [D loss: 0.583988, acc.: 62.50%] [G loss: 0.566318]\n",
      "epoch:14 step:13584 [D loss: 0.560011, acc.: 64.84%] [G loss: 0.609959]\n",
      "epoch:14 step:13585 [D loss: 0.511943, acc.: 71.88%] [G loss: 0.742628]\n",
      "epoch:14 step:13586 [D loss: 0.582314, acc.: 66.41%] [G loss: 0.564479]\n",
      "epoch:14 step:13587 [D loss: 0.543116, acc.: 69.53%] [G loss: 0.691715]\n",
      "epoch:14 step:13588 [D loss: 0.553166, acc.: 75.00%] [G loss: 0.666859]\n",
      "epoch:14 step:13589 [D loss: 0.446104, acc.: 78.91%] [G loss: 0.684376]\n",
      "epoch:14 step:13590 [D loss: 0.417843, acc.: 82.81%] [G loss: 0.934259]\n",
      "epoch:14 step:13591 [D loss: 0.657878, acc.: 60.16%] [G loss: 0.822792]\n",
      "epoch:14 step:13592 [D loss: 0.553252, acc.: 67.97%] [G loss: 0.708631]\n",
      "epoch:14 step:13593 [D loss: 0.472661, acc.: 77.34%] [G loss: 0.919234]\n",
      "epoch:14 step:13594 [D loss: 0.513084, acc.: 72.66%] [G loss: 0.860934]\n",
      "epoch:14 step:13595 [D loss: 0.680610, acc.: 57.81%] [G loss: 0.543299]\n",
      "epoch:14 step:13596 [D loss: 0.564657, acc.: 67.97%] [G loss: 0.475123]\n",
      "epoch:14 step:13597 [D loss: 0.503669, acc.: 73.44%] [G loss: 0.626773]\n",
      "epoch:14 step:13598 [D loss: 0.610962, acc.: 66.41%] [G loss: 0.498229]\n",
      "epoch:14 step:13599 [D loss: 0.577634, acc.: 73.44%] [G loss: 0.704573]\n",
      "epoch:14 step:13600 [D loss: 0.568311, acc.: 68.75%] [G loss: 0.648153]\n",
      "##############\n",
      "[3.00287732 1.34232521 6.18010191 5.14687166 3.78393521 5.79447999\n",
      " 4.56517145 4.70215177 4.75782506 4.33172267]\n",
      "##########\n",
      "epoch:14 step:13601 [D loss: 0.522556, acc.: 76.56%] [G loss: 0.630904]\n",
      "epoch:14 step:13602 [D loss: 0.531581, acc.: 71.88%] [G loss: 0.587482]\n",
      "epoch:14 step:13603 [D loss: 0.488425, acc.: 71.09%] [G loss: 0.672787]\n",
      "epoch:14 step:13604 [D loss: 0.564718, acc.: 64.06%] [G loss: 0.636089]\n",
      "epoch:14 step:13605 [D loss: 0.534030, acc.: 73.44%] [G loss: 0.580634]\n",
      "epoch:14 step:13606 [D loss: 0.458955, acc.: 78.12%] [G loss: 0.487211]\n",
      "epoch:14 step:13607 [D loss: 0.491978, acc.: 71.88%] [G loss: 0.527092]\n",
      "epoch:14 step:13608 [D loss: 0.580086, acc.: 71.88%] [G loss: 0.561453]\n",
      "epoch:14 step:13609 [D loss: 0.586990, acc.: 70.31%] [G loss: 0.578412]\n",
      "epoch:14 step:13610 [D loss: 0.607514, acc.: 64.06%] [G loss: 0.509222]\n",
      "epoch:14 step:13611 [D loss: 0.554397, acc.: 74.22%] [G loss: 0.542733]\n",
      "epoch:14 step:13612 [D loss: 0.558574, acc.: 71.88%] [G loss: 0.550118]\n",
      "epoch:14 step:13613 [D loss: 0.478867, acc.: 77.34%] [G loss: 0.593640]\n",
      "epoch:14 step:13614 [D loss: 0.608209, acc.: 67.19%] [G loss: 0.443472]\n",
      "epoch:14 step:13615 [D loss: 0.589558, acc.: 64.84%] [G loss: 0.488464]\n",
      "epoch:14 step:13616 [D loss: 0.516456, acc.: 72.66%] [G loss: 0.504541]\n",
      "epoch:14 step:13617 [D loss: 0.477419, acc.: 78.12%] [G loss: 0.586283]\n",
      "epoch:14 step:13618 [D loss: 0.554122, acc.: 75.00%] [G loss: 0.557594]\n",
      "epoch:14 step:13619 [D loss: 0.666027, acc.: 62.50%] [G loss: 0.520397]\n",
      "epoch:14 step:13620 [D loss: 0.577756, acc.: 70.31%] [G loss: 0.486750]\n",
      "epoch:14 step:13621 [D loss: 0.491433, acc.: 78.12%] [G loss: 0.541811]\n",
      "epoch:14 step:13622 [D loss: 0.492542, acc.: 77.34%] [G loss: 0.626208]\n",
      "epoch:14 step:13623 [D loss: 0.558363, acc.: 70.31%] [G loss: 0.700512]\n",
      "epoch:14 step:13624 [D loss: 0.525255, acc.: 71.88%] [G loss: 0.739194]\n",
      "epoch:14 step:13625 [D loss: 0.514493, acc.: 71.88%] [G loss: 0.756229]\n",
      "epoch:14 step:13626 [D loss: 0.393482, acc.: 83.59%] [G loss: 0.942868]\n",
      "epoch:14 step:13627 [D loss: 0.531599, acc.: 70.31%] [G loss: 0.748032]\n",
      "epoch:14 step:13628 [D loss: 0.592494, acc.: 64.84%] [G loss: 0.662292]\n",
      "epoch:14 step:13629 [D loss: 0.632880, acc.: 62.50%] [G loss: 0.424946]\n",
      "epoch:14 step:13630 [D loss: 0.594100, acc.: 67.19%] [G loss: 0.505605]\n",
      "epoch:14 step:13631 [D loss: 0.508303, acc.: 76.56%] [G loss: 0.582061]\n",
      "epoch:14 step:13632 [D loss: 0.530551, acc.: 68.75%] [G loss: 0.635402]\n",
      "epoch:14 step:13633 [D loss: 0.529314, acc.: 71.09%] [G loss: 0.559425]\n",
      "epoch:14 step:13634 [D loss: 0.505870, acc.: 73.44%] [G loss: 0.636920]\n",
      "epoch:14 step:13635 [D loss: 0.535213, acc.: 72.66%] [G loss: 0.602713]\n",
      "epoch:14 step:13636 [D loss: 0.547492, acc.: 68.75%] [G loss: 0.637288]\n",
      "epoch:14 step:13637 [D loss: 0.522514, acc.: 71.09%] [G loss: 0.596189]\n",
      "epoch:14 step:13638 [D loss: 0.491781, acc.: 74.22%] [G loss: 0.573980]\n",
      "epoch:14 step:13639 [D loss: 0.571234, acc.: 71.88%] [G loss: 0.536249]\n",
      "epoch:14 step:13640 [D loss: 0.534157, acc.: 70.31%] [G loss: 0.575683]\n",
      "epoch:14 step:13641 [D loss: 0.541030, acc.: 69.53%] [G loss: 0.522877]\n",
      "epoch:14 step:13642 [D loss: 0.531731, acc.: 73.44%] [G loss: 0.638489]\n",
      "epoch:14 step:13643 [D loss: 0.564163, acc.: 68.75%] [G loss: 0.532796]\n",
      "epoch:14 step:13644 [D loss: 0.521342, acc.: 69.53%] [G loss: 0.592775]\n",
      "epoch:14 step:13645 [D loss: 0.584810, acc.: 66.41%] [G loss: 0.742850]\n",
      "epoch:14 step:13646 [D loss: 0.726965, acc.: 51.56%] [G loss: 0.546411]\n",
      "epoch:14 step:13647 [D loss: 0.567201, acc.: 63.28%] [G loss: 0.550295]\n",
      "epoch:14 step:13648 [D loss: 0.559211, acc.: 67.19%] [G loss: 0.631312]\n",
      "epoch:14 step:13649 [D loss: 0.519559, acc.: 78.12%] [G loss: 0.633833]\n",
      "epoch:14 step:13650 [D loss: 0.589076, acc.: 67.97%] [G loss: 0.562602]\n",
      "epoch:14 step:13651 [D loss: 0.533512, acc.: 71.09%] [G loss: 0.710885]\n",
      "epoch:14 step:13652 [D loss: 0.518457, acc.: 71.88%] [G loss: 0.672565]\n",
      "epoch:14 step:13653 [D loss: 0.634541, acc.: 61.72%] [G loss: 0.527453]\n",
      "epoch:14 step:13654 [D loss: 0.494232, acc.: 71.88%] [G loss: 0.576062]\n",
      "epoch:14 step:13655 [D loss: 0.563735, acc.: 67.19%] [G loss: 0.703993]\n",
      "epoch:14 step:13656 [D loss: 0.620829, acc.: 60.16%] [G loss: 0.633029]\n",
      "epoch:14 step:13657 [D loss: 0.558820, acc.: 70.31%] [G loss: 0.468968]\n",
      "epoch:14 step:13658 [D loss: 0.555827, acc.: 68.75%] [G loss: 0.663415]\n",
      "epoch:14 step:13659 [D loss: 0.551024, acc.: 67.19%] [G loss: 0.474784]\n",
      "epoch:14 step:13660 [D loss: 0.624498, acc.: 60.16%] [G loss: 0.575808]\n",
      "epoch:14 step:13661 [D loss: 0.574453, acc.: 65.62%] [G loss: 0.556206]\n",
      "epoch:14 step:13662 [D loss: 0.500105, acc.: 74.22%] [G loss: 0.652202]\n",
      "epoch:14 step:13663 [D loss: 0.509770, acc.: 72.66%] [G loss: 0.756729]\n",
      "epoch:14 step:13664 [D loss: 0.522557, acc.: 71.88%] [G loss: 0.733130]\n",
      "epoch:14 step:13665 [D loss: 0.590287, acc.: 71.09%] [G loss: 0.689352]\n",
      "epoch:14 step:13666 [D loss: 0.484432, acc.: 71.88%] [G loss: 0.694441]\n",
      "epoch:14 step:13667 [D loss: 0.529930, acc.: 71.88%] [G loss: 0.757070]\n",
      "epoch:14 step:13668 [D loss: 0.498559, acc.: 75.78%] [G loss: 0.592260]\n",
      "epoch:14 step:13669 [D loss: 0.530446, acc.: 74.22%] [G loss: 0.692971]\n",
      "epoch:14 step:13670 [D loss: 0.557370, acc.: 67.19%] [G loss: 0.697689]\n",
      "epoch:14 step:13671 [D loss: 0.567127, acc.: 66.41%] [G loss: 0.623999]\n",
      "epoch:14 step:13672 [D loss: 0.517934, acc.: 70.31%] [G loss: 0.656438]\n",
      "epoch:14 step:13673 [D loss: 0.501364, acc.: 77.34%] [G loss: 0.613548]\n",
      "epoch:14 step:13674 [D loss: 0.525412, acc.: 76.56%] [G loss: 0.572432]\n",
      "epoch:14 step:13675 [D loss: 0.492339, acc.: 78.91%] [G loss: 0.679391]\n",
      "epoch:14 step:13676 [D loss: 0.448628, acc.: 76.56%] [G loss: 0.740602]\n",
      "epoch:14 step:13677 [D loss: 0.583369, acc.: 65.62%] [G loss: 0.731853]\n",
      "epoch:14 step:13678 [D loss: 0.581948, acc.: 63.28%] [G loss: 0.633191]\n",
      "epoch:14 step:13679 [D loss: 0.560855, acc.: 66.41%] [G loss: 0.531942]\n",
      "epoch:14 step:13680 [D loss: 0.542203, acc.: 71.88%] [G loss: 0.501362]\n",
      "epoch:14 step:13681 [D loss: 0.538662, acc.: 71.88%] [G loss: 0.536977]\n",
      "epoch:14 step:13682 [D loss: 0.529676, acc.: 74.22%] [G loss: 0.665945]\n",
      "epoch:14 step:13683 [D loss: 0.595930, acc.: 68.75%] [G loss: 0.884841]\n",
      "epoch:14 step:13684 [D loss: 0.693627, acc.: 64.06%] [G loss: 0.597037]\n",
      "epoch:14 step:13685 [D loss: 0.522789, acc.: 72.66%] [G loss: 0.640674]\n",
      "epoch:14 step:13686 [D loss: 0.536649, acc.: 72.66%] [G loss: 0.670771]\n",
      "epoch:14 step:13687 [D loss: 0.524659, acc.: 73.44%] [G loss: 0.775526]\n",
      "epoch:14 step:13688 [D loss: 0.539768, acc.: 68.75%] [G loss: 0.605280]\n",
      "epoch:14 step:13689 [D loss: 0.552056, acc.: 71.09%] [G loss: 0.554449]\n",
      "epoch:14 step:13690 [D loss: 0.548956, acc.: 72.66%] [G loss: 0.512519]\n",
      "epoch:14 step:13691 [D loss: 0.562530, acc.: 67.97%] [G loss: 0.642485]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:14 step:13692 [D loss: 0.455614, acc.: 80.47%] [G loss: 0.740079]\n",
      "epoch:14 step:13693 [D loss: 0.550740, acc.: 67.97%] [G loss: 0.645845]\n",
      "epoch:14 step:13694 [D loss: 0.626757, acc.: 64.84%] [G loss: 0.621195]\n",
      "epoch:14 step:13695 [D loss: 0.549761, acc.: 69.53%] [G loss: 0.711754]\n",
      "epoch:14 step:13696 [D loss: 0.519746, acc.: 74.22%] [G loss: 0.492942]\n",
      "epoch:14 step:13697 [D loss: 0.556396, acc.: 67.97%] [G loss: 0.511579]\n",
      "epoch:14 step:13698 [D loss: 0.547439, acc.: 71.09%] [G loss: 0.547501]\n",
      "epoch:14 step:13699 [D loss: 0.528479, acc.: 72.66%] [G loss: 0.567546]\n",
      "epoch:14 step:13700 [D loss: 0.482408, acc.: 76.56%] [G loss: 0.678836]\n",
      "epoch:14 step:13701 [D loss: 0.570135, acc.: 68.75%] [G loss: 0.744032]\n",
      "epoch:14 step:13702 [D loss: 0.595653, acc.: 64.84%] [G loss: 0.638398]\n",
      "epoch:14 step:13703 [D loss: 0.549474, acc.: 69.53%] [G loss: 0.605582]\n",
      "epoch:14 step:13704 [D loss: 0.578614, acc.: 67.19%] [G loss: 0.598353]\n",
      "epoch:14 step:13705 [D loss: 0.576746, acc.: 62.50%] [G loss: 0.481078]\n",
      "epoch:14 step:13706 [D loss: 0.580447, acc.: 64.84%] [G loss: 0.609356]\n",
      "epoch:14 step:13707 [D loss: 0.539896, acc.: 67.97%] [G loss: 0.674860]\n",
      "epoch:14 step:13708 [D loss: 0.562683, acc.: 70.31%] [G loss: 0.496065]\n",
      "epoch:14 step:13709 [D loss: 0.570500, acc.: 73.44%] [G loss: 0.623715]\n",
      "epoch:14 step:13710 [D loss: 0.545017, acc.: 72.66%] [G loss: 0.541943]\n",
      "epoch:14 step:13711 [D loss: 0.499032, acc.: 75.00%] [G loss: 0.743050]\n",
      "epoch:14 step:13712 [D loss: 0.587626, acc.: 71.88%] [G loss: 0.530244]\n",
      "epoch:14 step:13713 [D loss: 0.574951, acc.: 69.53%] [G loss: 0.579599]\n",
      "epoch:14 step:13714 [D loss: 0.548692, acc.: 66.41%] [G loss: 0.620940]\n",
      "epoch:14 step:13715 [D loss: 0.576619, acc.: 73.44%] [G loss: 0.530717]\n",
      "epoch:14 step:13716 [D loss: 0.491143, acc.: 73.44%] [G loss: 0.765768]\n",
      "epoch:14 step:13717 [D loss: 0.616055, acc.: 65.62%] [G loss: 0.711650]\n",
      "epoch:14 step:13718 [D loss: 0.585984, acc.: 74.22%] [G loss: 0.564149]\n",
      "epoch:14 step:13719 [D loss: 0.521704, acc.: 73.44%] [G loss: 0.722088]\n",
      "epoch:14 step:13720 [D loss: 0.573010, acc.: 67.97%] [G loss: 0.756313]\n",
      "epoch:14 step:13721 [D loss: 0.490901, acc.: 77.34%] [G loss: 0.855541]\n",
      "epoch:14 step:13722 [D loss: 0.574449, acc.: 69.53%] [G loss: 0.729482]\n",
      "epoch:14 step:13723 [D loss: 0.445925, acc.: 80.47%] [G loss: 0.823544]\n",
      "epoch:14 step:13724 [D loss: 0.637983, acc.: 64.06%] [G loss: 0.651456]\n",
      "epoch:14 step:13725 [D loss: 0.565937, acc.: 69.53%] [G loss: 0.487152]\n",
      "epoch:14 step:13726 [D loss: 0.563457, acc.: 66.41%] [G loss: 0.540474]\n",
      "epoch:14 step:13727 [D loss: 0.521317, acc.: 75.00%] [G loss: 0.537747]\n",
      "epoch:14 step:13728 [D loss: 0.591083, acc.: 64.06%] [G loss: 0.481678]\n",
      "epoch:14 step:13729 [D loss: 0.495486, acc.: 71.09%] [G loss: 0.514439]\n",
      "epoch:14 step:13730 [D loss: 0.566485, acc.: 65.62%] [G loss: 0.506757]\n",
      "epoch:14 step:13731 [D loss: 0.485701, acc.: 73.44%] [G loss: 0.669426]\n",
      "epoch:14 step:13732 [D loss: 0.628381, acc.: 63.28%] [G loss: 0.527538]\n",
      "epoch:14 step:13733 [D loss: 0.603827, acc.: 62.50%] [G loss: 0.632889]\n",
      "epoch:14 step:13734 [D loss: 0.557511, acc.: 70.31%] [G loss: 0.528844]\n",
      "epoch:14 step:13735 [D loss: 0.574696, acc.: 69.53%] [G loss: 0.516514]\n",
      "epoch:14 step:13736 [D loss: 0.496049, acc.: 75.78%] [G loss: 0.546014]\n",
      "epoch:14 step:13737 [D loss: 0.563232, acc.: 68.75%] [G loss: 0.546088]\n",
      "epoch:14 step:13738 [D loss: 0.505318, acc.: 71.09%] [G loss: 0.765507]\n",
      "epoch:14 step:13739 [D loss: 0.572859, acc.: 67.19%] [G loss: 0.479264]\n",
      "epoch:14 step:13740 [D loss: 0.535374, acc.: 71.09%] [G loss: 0.486092]\n",
      "epoch:14 step:13741 [D loss: 0.472099, acc.: 74.22%] [G loss: 0.650724]\n",
      "epoch:14 step:13742 [D loss: 0.486463, acc.: 77.34%] [G loss: 0.741362]\n",
      "epoch:14 step:13743 [D loss: 0.614716, acc.: 64.06%] [G loss: 0.619058]\n",
      "epoch:14 step:13744 [D loss: 0.589807, acc.: 66.41%] [G loss: 0.588544]\n",
      "epoch:14 step:13745 [D loss: 0.568968, acc.: 65.62%] [G loss: 0.665591]\n",
      "epoch:14 step:13746 [D loss: 0.586790, acc.: 67.97%] [G loss: 0.482538]\n",
      "epoch:14 step:13747 [D loss: 0.524997, acc.: 71.09%] [G loss: 0.497912]\n",
      "epoch:14 step:13748 [D loss: 0.555813, acc.: 68.75%] [G loss: 0.460143]\n",
      "epoch:14 step:13749 [D loss: 0.506291, acc.: 77.34%] [G loss: 0.638483]\n",
      "epoch:14 step:13750 [D loss: 0.486837, acc.: 75.78%] [G loss: 0.508509]\n",
      "epoch:14 step:13751 [D loss: 0.572402, acc.: 64.84%] [G loss: 0.716026]\n",
      "epoch:14 step:13752 [D loss: 0.491978, acc.: 75.78%] [G loss: 0.674999]\n",
      "epoch:14 step:13753 [D loss: 0.465982, acc.: 76.56%] [G loss: 0.595629]\n",
      "epoch:14 step:13754 [D loss: 0.578880, acc.: 71.09%] [G loss: 0.605859]\n",
      "epoch:14 step:13755 [D loss: 0.541167, acc.: 69.53%] [G loss: 0.527932]\n",
      "epoch:14 step:13756 [D loss: 0.518814, acc.: 71.88%] [G loss: 0.703735]\n",
      "epoch:14 step:13757 [D loss: 0.494657, acc.: 76.56%] [G loss: 0.695799]\n",
      "epoch:14 step:13758 [D loss: 0.597825, acc.: 64.84%] [G loss: 0.554471]\n",
      "epoch:14 step:13759 [D loss: 0.480267, acc.: 75.00%] [G loss: 0.820997]\n",
      "epoch:14 step:13760 [D loss: 0.508321, acc.: 75.00%] [G loss: 0.905019]\n",
      "epoch:14 step:13761 [D loss: 0.524096, acc.: 71.09%] [G loss: 0.729631]\n",
      "epoch:14 step:13762 [D loss: 0.562814, acc.: 68.75%] [G loss: 0.694952]\n",
      "epoch:14 step:13763 [D loss: 0.574781, acc.: 66.41%] [G loss: 0.544482]\n",
      "epoch:14 step:13764 [D loss: 0.522199, acc.: 71.88%] [G loss: 0.537075]\n",
      "epoch:14 step:13765 [D loss: 0.421734, acc.: 84.38%] [G loss: 0.698850]\n",
      "epoch:14 step:13766 [D loss: 0.416647, acc.: 81.25%] [G loss: 0.857433]\n",
      "epoch:14 step:13767 [D loss: 0.468736, acc.: 75.00%] [G loss: 0.969470]\n",
      "epoch:14 step:13768 [D loss: 0.489634, acc.: 77.34%] [G loss: 0.688073]\n",
      "epoch:14 step:13769 [D loss: 0.519186, acc.: 75.78%] [G loss: 0.800661]\n",
      "epoch:14 step:13770 [D loss: 0.687937, acc.: 58.59%] [G loss: 0.538454]\n",
      "epoch:14 step:13771 [D loss: 0.582783, acc.: 69.53%] [G loss: 0.465558]\n",
      "epoch:14 step:13772 [D loss: 0.512043, acc.: 74.22%] [G loss: 0.637717]\n",
      "epoch:14 step:13773 [D loss: 0.605189, acc.: 67.97%] [G loss: 0.559874]\n",
      "epoch:14 step:13774 [D loss: 0.554169, acc.: 75.00%] [G loss: 0.443945]\n",
      "epoch:14 step:13775 [D loss: 0.487563, acc.: 74.22%] [G loss: 0.644808]\n",
      "epoch:14 step:13776 [D loss: 0.566228, acc.: 67.19%] [G loss: 0.547358]\n",
      "epoch:14 step:13777 [D loss: 0.518735, acc.: 71.88%] [G loss: 0.731454]\n",
      "epoch:14 step:13778 [D loss: 0.494753, acc.: 75.00%] [G loss: 0.548991]\n",
      "epoch:14 step:13779 [D loss: 0.545506, acc.: 71.88%] [G loss: 0.683252]\n",
      "epoch:14 step:13780 [D loss: 0.473037, acc.: 74.22%] [G loss: 0.818149]\n",
      "epoch:14 step:13781 [D loss: 0.500532, acc.: 71.09%] [G loss: 0.688036]\n",
      "epoch:14 step:13782 [D loss: 0.556256, acc.: 69.53%] [G loss: 0.500692]\n",
      "epoch:14 step:13783 [D loss: 0.571443, acc.: 67.19%] [G loss: 0.577610]\n",
      "epoch:14 step:13784 [D loss: 0.545660, acc.: 71.09%] [G loss: 0.611072]\n",
      "epoch:14 step:13785 [D loss: 0.570395, acc.: 67.19%] [G loss: 0.721362]\n",
      "epoch:14 step:13786 [D loss: 0.540303, acc.: 72.66%] [G loss: 0.548093]\n",
      "epoch:14 step:13787 [D loss: 0.582856, acc.: 66.41%] [G loss: 0.658471]\n",
      "epoch:14 step:13788 [D loss: 0.539274, acc.: 68.75%] [G loss: 0.728399]\n",
      "epoch:14 step:13789 [D loss: 0.595475, acc.: 68.75%] [G loss: 0.727431]\n",
      "epoch:14 step:13790 [D loss: 0.595692, acc.: 64.84%] [G loss: 0.651923]\n",
      "epoch:14 step:13791 [D loss: 0.599132, acc.: 62.50%] [G loss: 0.598019]\n",
      "epoch:14 step:13792 [D loss: 0.563656, acc.: 71.09%] [G loss: 0.685638]\n",
      "epoch:14 step:13793 [D loss: 0.583811, acc.: 67.19%] [G loss: 0.560638]\n",
      "epoch:14 step:13794 [D loss: 0.587287, acc.: 67.19%] [G loss: 0.572010]\n",
      "epoch:14 step:13795 [D loss: 0.500719, acc.: 74.22%] [G loss: 0.595914]\n",
      "epoch:14 step:13796 [D loss: 0.568877, acc.: 69.53%] [G loss: 0.709641]\n",
      "epoch:14 step:13797 [D loss: 0.574893, acc.: 70.31%] [G loss: 0.649389]\n",
      "epoch:14 step:13798 [D loss: 0.565820, acc.: 75.78%] [G loss: 0.528374]\n",
      "epoch:14 step:13799 [D loss: 0.482062, acc.: 76.56%] [G loss: 0.683049]\n",
      "epoch:14 step:13800 [D loss: 0.517297, acc.: 74.22%] [G loss: 0.530539]\n",
      "##############\n",
      "[3.13220104 0.92336507 6.29863427 4.80546311 3.84175397 5.78151169\n",
      " 4.72960381 4.60651349 4.55211147 4.11155173]\n",
      "##########\n",
      "epoch:14 step:13801 [D loss: 0.556287, acc.: 67.97%] [G loss: 0.601157]\n",
      "epoch:14 step:13802 [D loss: 0.557677, acc.: 71.88%] [G loss: 0.544627]\n",
      "epoch:14 step:13803 [D loss: 0.542354, acc.: 71.88%] [G loss: 0.525920]\n",
      "epoch:14 step:13804 [D loss: 0.598333, acc.: 66.41%] [G loss: 0.405178]\n",
      "epoch:14 step:13805 [D loss: 0.553847, acc.: 69.53%] [G loss: 0.467641]\n",
      "epoch:14 step:13806 [D loss: 0.584383, acc.: 68.75%] [G loss: 0.432552]\n",
      "epoch:14 step:13807 [D loss: 0.539001, acc.: 75.00%] [G loss: 0.561297]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:14 step:13808 [D loss: 0.523009, acc.: 76.56%] [G loss: 0.780436]\n",
      "epoch:14 step:13809 [D loss: 0.509572, acc.: 77.34%] [G loss: 0.702257]\n",
      "epoch:14 step:13810 [D loss: 0.542329, acc.: 71.09%] [G loss: 0.576973]\n",
      "epoch:14 step:13811 [D loss: 0.482556, acc.: 78.12%] [G loss: 0.658296]\n",
      "epoch:14 step:13812 [D loss: 0.507474, acc.: 73.44%] [G loss: 0.647490]\n",
      "epoch:14 step:13813 [D loss: 0.558308, acc.: 71.09%] [G loss: 0.718178]\n",
      "epoch:14 step:13814 [D loss: 0.654394, acc.: 60.94%] [G loss: 0.564287]\n",
      "epoch:14 step:13815 [D loss: 0.552270, acc.: 62.50%] [G loss: 0.570537]\n",
      "epoch:14 step:13816 [D loss: 0.566615, acc.: 62.50%] [G loss: 0.567842]\n",
      "epoch:14 step:13817 [D loss: 0.535889, acc.: 70.31%] [G loss: 0.510041]\n",
      "epoch:14 step:13818 [D loss: 0.544676, acc.: 68.75%] [G loss: 0.701286]\n",
      "epoch:14 step:13819 [D loss: 0.528964, acc.: 71.88%] [G loss: 0.799668]\n",
      "epoch:14 step:13820 [D loss: 0.565345, acc.: 73.44%] [G loss: 0.687589]\n",
      "epoch:14 step:13821 [D loss: 0.572442, acc.: 69.53%] [G loss: 0.609403]\n",
      "epoch:14 step:13822 [D loss: 0.654971, acc.: 63.28%] [G loss: 0.502727]\n",
      "epoch:14 step:13823 [D loss: 0.525908, acc.: 73.44%] [G loss: 0.526965]\n",
      "epoch:14 step:13824 [D loss: 0.552017, acc.: 71.09%] [G loss: 0.521548]\n",
      "epoch:14 step:13825 [D loss: 0.502931, acc.: 73.44%] [G loss: 0.672399]\n",
      "epoch:14 step:13826 [D loss: 0.505808, acc.: 75.78%] [G loss: 0.629858]\n",
      "epoch:14 step:13827 [D loss: 0.542391, acc.: 69.53%] [G loss: 0.686327]\n",
      "epoch:14 step:13828 [D loss: 0.576804, acc.: 67.97%] [G loss: 0.609661]\n",
      "epoch:14 step:13829 [D loss: 0.625816, acc.: 62.50%] [G loss: 0.527155]\n",
      "epoch:14 step:13830 [D loss: 0.549290, acc.: 71.09%] [G loss: 0.522231]\n",
      "epoch:14 step:13831 [D loss: 0.552544, acc.: 66.41%] [G loss: 0.649885]\n",
      "epoch:14 step:13832 [D loss: 0.541064, acc.: 69.53%] [G loss: 0.581938]\n",
      "epoch:14 step:13833 [D loss: 0.526562, acc.: 71.09%] [G loss: 0.576503]\n",
      "epoch:14 step:13834 [D loss: 0.619078, acc.: 64.84%] [G loss: 0.422838]\n",
      "epoch:14 step:13835 [D loss: 0.575194, acc.: 71.09%] [G loss: 0.520106]\n",
      "epoch:14 step:13836 [D loss: 0.552932, acc.: 67.97%] [G loss: 0.445792]\n",
      "epoch:14 step:13837 [D loss: 0.515996, acc.: 75.78%] [G loss: 0.591209]\n",
      "epoch:14 step:13838 [D loss: 0.605861, acc.: 67.97%] [G loss: 0.417374]\n",
      "epoch:14 step:13839 [D loss: 0.587665, acc.: 67.19%] [G loss: 0.459994]\n",
      "epoch:14 step:13840 [D loss: 0.537242, acc.: 72.66%] [G loss: 0.553998]\n",
      "epoch:14 step:13841 [D loss: 0.597879, acc.: 69.53%] [G loss: 0.522340]\n",
      "epoch:14 step:13842 [D loss: 0.535781, acc.: 74.22%] [G loss: 0.591034]\n",
      "epoch:14 step:13843 [D loss: 0.531197, acc.: 76.56%] [G loss: 0.635595]\n",
      "epoch:14 step:13844 [D loss: 0.560815, acc.: 72.66%] [G loss: 0.758785]\n",
      "epoch:14 step:13845 [D loss: 0.528024, acc.: 71.88%] [G loss: 0.622657]\n",
      "epoch:14 step:13846 [D loss: 0.572877, acc.: 71.88%] [G loss: 0.539279]\n",
      "epoch:14 step:13847 [D loss: 0.606834, acc.: 64.84%] [G loss: 0.535190]\n",
      "epoch:14 step:13848 [D loss: 0.534002, acc.: 72.66%] [G loss: 0.495845]\n",
      "epoch:14 step:13849 [D loss: 0.617761, acc.: 57.03%] [G loss: 0.498483]\n",
      "epoch:14 step:13850 [D loss: 0.534161, acc.: 70.31%] [G loss: 0.559922]\n",
      "epoch:14 step:13851 [D loss: 0.550759, acc.: 66.41%] [G loss: 0.626992]\n",
      "epoch:14 step:13852 [D loss: 0.512623, acc.: 71.09%] [G loss: 0.577704]\n",
      "epoch:14 step:13853 [D loss: 0.611906, acc.: 60.94%] [G loss: 0.619082]\n",
      "epoch:14 step:13854 [D loss: 0.490772, acc.: 75.00%] [G loss: 0.679977]\n",
      "epoch:14 step:13855 [D loss: 0.548293, acc.: 70.31%] [G loss: 0.613637]\n",
      "epoch:14 step:13856 [D loss: 0.575570, acc.: 69.53%] [G loss: 0.541131]\n",
      "epoch:14 step:13857 [D loss: 0.599794, acc.: 65.62%] [G loss: 0.572350]\n",
      "epoch:14 step:13858 [D loss: 0.625140, acc.: 63.28%] [G loss: 0.477690]\n",
      "epoch:14 step:13859 [D loss: 0.542661, acc.: 66.41%] [G loss: 0.537230]\n",
      "epoch:14 step:13860 [D loss: 0.541522, acc.: 72.66%] [G loss: 0.611456]\n",
      "epoch:14 step:13861 [D loss: 0.571713, acc.: 73.44%] [G loss: 0.699699]\n",
      "epoch:14 step:13862 [D loss: 0.545222, acc.: 74.22%] [G loss: 0.602389]\n",
      "epoch:14 step:13863 [D loss: 0.580575, acc.: 63.28%] [G loss: 0.590459]\n",
      "epoch:14 step:13864 [D loss: 0.474243, acc.: 77.34%] [G loss: 0.664912]\n",
      "epoch:14 step:13865 [D loss: 0.438744, acc.: 84.38%] [G loss: 0.631129]\n",
      "epoch:14 step:13866 [D loss: 0.543078, acc.: 68.75%] [G loss: 0.551190]\n",
      "epoch:14 step:13867 [D loss: 0.527246, acc.: 72.66%] [G loss: 0.567184]\n",
      "epoch:14 step:13868 [D loss: 0.525179, acc.: 73.44%] [G loss: 0.621254]\n",
      "epoch:14 step:13869 [D loss: 0.536534, acc.: 70.31%] [G loss: 0.731454]\n",
      "epoch:14 step:13870 [D loss: 0.625663, acc.: 59.38%] [G loss: 0.690846]\n",
      "epoch:14 step:13871 [D loss: 0.573984, acc.: 63.28%] [G loss: 0.597054]\n",
      "epoch:14 step:13872 [D loss: 0.541877, acc.: 71.09%] [G loss: 0.711222]\n",
      "epoch:14 step:13873 [D loss: 0.553825, acc.: 67.97%] [G loss: 0.553917]\n",
      "epoch:14 step:13874 [D loss: 0.571779, acc.: 69.53%] [G loss: 0.535561]\n",
      "epoch:14 step:13875 [D loss: 0.574261, acc.: 67.97%] [G loss: 0.569566]\n",
      "epoch:14 step:13876 [D loss: 0.546825, acc.: 69.53%] [G loss: 0.569499]\n",
      "epoch:14 step:13877 [D loss: 0.603657, acc.: 65.62%] [G loss: 0.596670]\n",
      "epoch:14 step:13878 [D loss: 0.527764, acc.: 71.88%] [G loss: 0.514072]\n",
      "epoch:14 step:13879 [D loss: 0.552842, acc.: 71.88%] [G loss: 0.403027]\n",
      "epoch:14 step:13880 [D loss: 0.557832, acc.: 67.97%] [G loss: 0.512757]\n",
      "epoch:14 step:13881 [D loss: 0.562089, acc.: 65.62%] [G loss: 0.500194]\n",
      "epoch:14 step:13882 [D loss: 0.596228, acc.: 68.75%] [G loss: 0.515318]\n",
      "epoch:14 step:13883 [D loss: 0.655079, acc.: 62.50%] [G loss: 0.467126]\n",
      "epoch:14 step:13884 [D loss: 0.689289, acc.: 53.91%] [G loss: 0.416229]\n",
      "epoch:14 step:13885 [D loss: 0.537829, acc.: 70.31%] [G loss: 0.363430]\n",
      "epoch:14 step:13886 [D loss: 0.542140, acc.: 71.88%] [G loss: 0.641738]\n",
      "epoch:14 step:13887 [D loss: 0.496089, acc.: 76.56%] [G loss: 0.735982]\n",
      "epoch:14 step:13888 [D loss: 0.556202, acc.: 70.31%] [G loss: 0.691748]\n",
      "epoch:14 step:13889 [D loss: 0.502535, acc.: 73.44%] [G loss: 0.651324]\n",
      "epoch:14 step:13890 [D loss: 0.536151, acc.: 71.88%] [G loss: 0.624259]\n",
      "epoch:14 step:13891 [D loss: 0.571417, acc.: 66.41%] [G loss: 0.620501]\n",
      "epoch:14 step:13892 [D loss: 0.621900, acc.: 64.06%] [G loss: 0.628847]\n",
      "epoch:14 step:13893 [D loss: 0.512740, acc.: 75.00%] [G loss: 0.514038]\n",
      "epoch:14 step:13894 [D loss: 0.546952, acc.: 70.31%] [G loss: 0.653350]\n",
      "epoch:14 step:13895 [D loss: 0.568570, acc.: 71.88%] [G loss: 0.730932]\n",
      "epoch:14 step:13896 [D loss: 0.524600, acc.: 75.00%] [G loss: 0.509741]\n",
      "epoch:14 step:13897 [D loss: 0.581468, acc.: 65.62%] [G loss: 0.559724]\n",
      "epoch:14 step:13898 [D loss: 0.608321, acc.: 62.50%] [G loss: 0.642798]\n",
      "epoch:14 step:13899 [D loss: 0.515183, acc.: 75.78%] [G loss: 0.618209]\n",
      "epoch:14 step:13900 [D loss: 0.557515, acc.: 68.75%] [G loss: 0.631996]\n",
      "epoch:14 step:13901 [D loss: 0.615805, acc.: 64.06%] [G loss: 0.655201]\n",
      "epoch:14 step:13902 [D loss: 0.613883, acc.: 67.97%] [G loss: 0.503433]\n",
      "epoch:14 step:13903 [D loss: 0.562517, acc.: 67.97%] [G loss: 0.477919]\n",
      "epoch:14 step:13904 [D loss: 0.520509, acc.: 72.66%] [G loss: 0.539282]\n",
      "epoch:14 step:13905 [D loss: 0.588572, acc.: 67.19%] [G loss: 0.541564]\n",
      "epoch:14 step:13906 [D loss: 0.585729, acc.: 64.84%] [G loss: 0.627995]\n",
      "epoch:14 step:13907 [D loss: 0.524264, acc.: 74.22%] [G loss: 0.609399]\n",
      "epoch:14 step:13908 [D loss: 0.560664, acc.: 70.31%] [G loss: 0.405997]\n",
      "epoch:14 step:13909 [D loss: 0.564682, acc.: 68.75%] [G loss: 0.585935]\n",
      "epoch:14 step:13910 [D loss: 0.465569, acc.: 75.78%] [G loss: 0.846706]\n",
      "epoch:14 step:13911 [D loss: 0.601497, acc.: 68.75%] [G loss: 0.649674]\n",
      "epoch:14 step:13912 [D loss: 0.654728, acc.: 62.50%] [G loss: 0.566290]\n",
      "epoch:14 step:13913 [D loss: 0.606235, acc.: 57.03%] [G loss: 0.654647]\n",
      "epoch:14 step:13914 [D loss: 0.495200, acc.: 75.00%] [G loss: 0.597463]\n",
      "epoch:14 step:13915 [D loss: 0.510903, acc.: 71.88%] [G loss: 0.645479]\n",
      "epoch:14 step:13916 [D loss: 0.489551, acc.: 74.22%] [G loss: 0.580127]\n",
      "epoch:14 step:13917 [D loss: 0.550460, acc.: 75.00%] [G loss: 0.586744]\n",
      "epoch:14 step:13918 [D loss: 0.567476, acc.: 65.62%] [G loss: 0.527864]\n",
      "epoch:14 step:13919 [D loss: 0.552343, acc.: 71.88%] [G loss: 0.564504]\n",
      "epoch:14 step:13920 [D loss: 0.469369, acc.: 75.78%] [G loss: 0.706346]\n",
      "epoch:14 step:13921 [D loss: 0.487739, acc.: 78.91%] [G loss: 0.724885]\n",
      "epoch:14 step:13922 [D loss: 0.560804, acc.: 66.41%] [G loss: 0.582099]\n",
      "epoch:14 step:13923 [D loss: 0.580504, acc.: 71.09%] [G loss: 0.543184]\n",
      "epoch:14 step:13924 [D loss: 0.603306, acc.: 64.84%] [G loss: 0.444638]\n",
      "epoch:14 step:13925 [D loss: 0.514094, acc.: 75.78%] [G loss: 0.538076]\n",
      "epoch:14 step:13926 [D loss: 0.586425, acc.: 66.41%] [G loss: 0.634382]\n",
      "epoch:14 step:13927 [D loss: 0.561062, acc.: 70.31%] [G loss: 0.625693]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:14 step:13928 [D loss: 0.561297, acc.: 68.75%] [G loss: 0.558725]\n",
      "epoch:14 step:13929 [D loss: 0.545977, acc.: 71.88%] [G loss: 0.642879]\n",
      "epoch:14 step:13930 [D loss: 0.681566, acc.: 59.38%] [G loss: 0.517206]\n",
      "epoch:14 step:13931 [D loss: 0.544865, acc.: 67.97%] [G loss: 0.522859]\n",
      "epoch:14 step:13932 [D loss: 0.462496, acc.: 77.34%] [G loss: 0.549879]\n",
      "epoch:14 step:13933 [D loss: 0.499855, acc.: 75.78%] [G loss: 0.748251]\n",
      "epoch:14 step:13934 [D loss: 0.620976, acc.: 68.75%] [G loss: 0.787020]\n",
      "epoch:14 step:13935 [D loss: 0.592686, acc.: 67.97%] [G loss: 0.645415]\n",
      "epoch:14 step:13936 [D loss: 0.602025, acc.: 68.75%] [G loss: 0.524175]\n",
      "epoch:14 step:13937 [D loss: 0.524309, acc.: 71.88%] [G loss: 0.658741]\n",
      "epoch:14 step:13938 [D loss: 0.594557, acc.: 61.72%] [G loss: 0.739782]\n",
      "epoch:14 step:13939 [D loss: 0.574937, acc.: 69.53%] [G loss: 0.507206]\n",
      "epoch:14 step:13940 [D loss: 0.544772, acc.: 68.75%] [G loss: 0.500875]\n",
      "epoch:14 step:13941 [D loss: 0.453901, acc.: 82.03%] [G loss: 0.621255]\n",
      "epoch:14 step:13942 [D loss: 0.609175, acc.: 66.41%] [G loss: 0.598680]\n",
      "epoch:14 step:13943 [D loss: 0.614754, acc.: 65.62%] [G loss: 0.513932]\n",
      "epoch:14 step:13944 [D loss: 0.586100, acc.: 64.84%] [G loss: 0.564389]\n",
      "epoch:14 step:13945 [D loss: 0.539424, acc.: 71.09%] [G loss: 0.649123]\n",
      "epoch:14 step:13946 [D loss: 0.676653, acc.: 61.72%] [G loss: 0.531019]\n",
      "epoch:14 step:13947 [D loss: 0.576631, acc.: 65.62%] [G loss: 0.557983]\n",
      "epoch:14 step:13948 [D loss: 0.569653, acc.: 70.31%] [G loss: 0.549528]\n",
      "epoch:14 step:13949 [D loss: 0.550923, acc.: 68.75%] [G loss: 0.561129]\n",
      "epoch:14 step:13950 [D loss: 0.545116, acc.: 72.66%] [G loss: 0.645826]\n",
      "epoch:14 step:13951 [D loss: 0.509717, acc.: 68.75%] [G loss: 0.663027]\n",
      "epoch:14 step:13952 [D loss: 0.532413, acc.: 71.88%] [G loss: 0.524341]\n",
      "epoch:14 step:13953 [D loss: 0.548961, acc.: 73.44%] [G loss: 0.600530]\n",
      "epoch:14 step:13954 [D loss: 0.524878, acc.: 78.12%] [G loss: 0.577095]\n",
      "epoch:14 step:13955 [D loss: 0.544821, acc.: 72.66%] [G loss: 0.573041]\n",
      "epoch:14 step:13956 [D loss: 0.525296, acc.: 72.66%] [G loss: 0.483232]\n",
      "epoch:14 step:13957 [D loss: 0.559530, acc.: 69.53%] [G loss: 0.418178]\n",
      "epoch:14 step:13958 [D loss: 0.588015, acc.: 74.22%] [G loss: 0.476908]\n",
      "epoch:14 step:13959 [D loss: 0.513421, acc.: 72.66%] [G loss: 0.521415]\n",
      "epoch:14 step:13960 [D loss: 0.505902, acc.: 77.34%] [G loss: 0.506861]\n",
      "epoch:14 step:13961 [D loss: 0.557595, acc.: 67.19%] [G loss: 0.477485]\n",
      "epoch:14 step:13962 [D loss: 0.597828, acc.: 67.19%] [G loss: 0.556841]\n",
      "epoch:14 step:13963 [D loss: 0.532717, acc.: 76.56%] [G loss: 0.682114]\n",
      "epoch:14 step:13964 [D loss: 0.607662, acc.: 63.28%] [G loss: 0.509328]\n",
      "epoch:14 step:13965 [D loss: 0.617370, acc.: 67.97%] [G loss: 0.468942]\n",
      "epoch:14 step:13966 [D loss: 0.548084, acc.: 69.53%] [G loss: 0.473628]\n",
      "epoch:14 step:13967 [D loss: 0.542174, acc.: 70.31%] [G loss: 0.432615]\n",
      "epoch:14 step:13968 [D loss: 0.589697, acc.: 64.06%] [G loss: 0.493363]\n",
      "epoch:14 step:13969 [D loss: 0.600081, acc.: 64.84%] [G loss: 0.469824]\n",
      "epoch:14 step:13970 [D loss: 0.552697, acc.: 71.88%] [G loss: 0.569659]\n",
      "epoch:14 step:13971 [D loss: 0.584813, acc.: 64.06%] [G loss: 0.760029]\n",
      "epoch:14 step:13972 [D loss: 0.531075, acc.: 70.31%] [G loss: 0.526960]\n",
      "epoch:14 step:13973 [D loss: 0.546214, acc.: 67.97%] [G loss: 0.656321]\n",
      "epoch:14 step:13974 [D loss: 0.547303, acc.: 73.44%] [G loss: 0.594008]\n",
      "epoch:14 step:13975 [D loss: 0.491852, acc.: 80.47%] [G loss: 0.606308]\n",
      "epoch:14 step:13976 [D loss: 0.646088, acc.: 66.41%] [G loss: 0.627754]\n",
      "epoch:14 step:13977 [D loss: 0.597711, acc.: 67.19%] [G loss: 0.620467]\n",
      "epoch:14 step:13978 [D loss: 0.437668, acc.: 79.69%] [G loss: 0.764698]\n",
      "epoch:14 step:13979 [D loss: 0.679955, acc.: 64.06%] [G loss: 0.642904]\n",
      "epoch:14 step:13980 [D loss: 0.582476, acc.: 72.66%] [G loss: 0.468835]\n",
      "epoch:14 step:13981 [D loss: 0.564983, acc.: 71.88%] [G loss: 0.462044]\n",
      "epoch:14 step:13982 [D loss: 0.530481, acc.: 67.19%] [G loss: 0.640929]\n",
      "epoch:14 step:13983 [D loss: 0.604490, acc.: 64.84%] [G loss: 0.381285]\n",
      "epoch:14 step:13984 [D loss: 0.537608, acc.: 70.31%] [G loss: 0.544882]\n",
      "epoch:14 step:13985 [D loss: 0.670701, acc.: 63.28%] [G loss: 0.487339]\n",
      "epoch:14 step:13986 [D loss: 0.540892, acc.: 73.44%] [G loss: 0.470790]\n",
      "epoch:14 step:13987 [D loss: 0.547401, acc.: 71.09%] [G loss: 0.512168]\n",
      "epoch:14 step:13988 [D loss: 0.491199, acc.: 75.00%] [G loss: 0.663247]\n",
      "epoch:14 step:13989 [D loss: 0.523681, acc.: 72.66%] [G loss: 0.642224]\n",
      "epoch:14 step:13990 [D loss: 0.560640, acc.: 71.88%] [G loss: 0.782977]\n",
      "epoch:14 step:13991 [D loss: 0.588062, acc.: 64.84%] [G loss: 0.577961]\n",
      "epoch:14 step:13992 [D loss: 0.551078, acc.: 72.66%] [G loss: 0.618049]\n",
      "epoch:14 step:13993 [D loss: 0.481739, acc.: 76.56%] [G loss: 0.631912]\n",
      "epoch:14 step:13994 [D loss: 0.592761, acc.: 67.97%] [G loss: 0.688128]\n",
      "epoch:14 step:13995 [D loss: 0.606900, acc.: 63.28%] [G loss: 0.546595]\n",
      "epoch:14 step:13996 [D loss: 0.607915, acc.: 67.97%] [G loss: 0.634698]\n",
      "epoch:14 step:13997 [D loss: 0.568889, acc.: 67.97%] [G loss: 0.494899]\n",
      "epoch:14 step:13998 [D loss: 0.627620, acc.: 60.94%] [G loss: 0.471603]\n",
      "epoch:14 step:13999 [D loss: 0.544199, acc.: 70.31%] [G loss: 0.461269]\n",
      "epoch:14 step:14000 [D loss: 0.578184, acc.: 61.72%] [G loss: 0.414439]\n",
      "##############\n",
      "[3.37711974 0.71885634 6.05535517 4.87357252 3.70001512 5.81666923\n",
      " 4.50588039 4.8464849  4.77633379 4.0577653 ]\n",
      "##########\n",
      "epoch:14 step:14001 [D loss: 0.572655, acc.: 70.31%] [G loss: 0.442846]\n",
      "epoch:14 step:14002 [D loss: 0.540927, acc.: 70.31%] [G loss: 0.543305]\n",
      "epoch:14 step:14003 [D loss: 0.521749, acc.: 72.66%] [G loss: 0.548014]\n",
      "epoch:14 step:14004 [D loss: 0.546753, acc.: 70.31%] [G loss: 0.538724]\n",
      "epoch:14 step:14005 [D loss: 0.490056, acc.: 73.44%] [G loss: 0.637277]\n",
      "epoch:14 step:14006 [D loss: 0.555812, acc.: 67.19%] [G loss: 0.620117]\n",
      "epoch:14 step:14007 [D loss: 0.567835, acc.: 70.31%] [G loss: 0.581146]\n",
      "epoch:14 step:14008 [D loss: 0.497275, acc.: 80.47%] [G loss: 0.531288]\n",
      "epoch:14 step:14009 [D loss: 0.638088, acc.: 64.06%] [G loss: 0.505756]\n",
      "epoch:14 step:14010 [D loss: 0.609190, acc.: 61.72%] [G loss: 0.513953]\n",
      "epoch:14 step:14011 [D loss: 0.521121, acc.: 75.78%] [G loss: 0.634190]\n",
      "epoch:14 step:14012 [D loss: 0.450163, acc.: 75.00%] [G loss: 0.643879]\n",
      "epoch:14 step:14013 [D loss: 0.549593, acc.: 65.62%] [G loss: 0.790569]\n",
      "epoch:14 step:14014 [D loss: 0.523300, acc.: 71.09%] [G loss: 0.670383]\n",
      "epoch:14 step:14015 [D loss: 0.507701, acc.: 74.22%] [G loss: 0.646888]\n",
      "epoch:14 step:14016 [D loss: 0.528190, acc.: 69.53%] [G loss: 0.661311]\n",
      "epoch:14 step:14017 [D loss: 0.506662, acc.: 77.34%] [G loss: 0.660781]\n",
      "epoch:14 step:14018 [D loss: 0.524145, acc.: 73.44%] [G loss: 0.602829]\n",
      "epoch:14 step:14019 [D loss: 0.520106, acc.: 70.31%] [G loss: 0.664798]\n",
      "epoch:14 step:14020 [D loss: 0.563247, acc.: 66.41%] [G loss: 0.586517]\n",
      "epoch:14 step:14021 [D loss: 0.526100, acc.: 73.44%] [G loss: 0.584562]\n",
      "epoch:14 step:14022 [D loss: 0.590460, acc.: 67.19%] [G loss: 0.489407]\n",
      "epoch:14 step:14023 [D loss: 0.589124, acc.: 65.62%] [G loss: 0.525207]\n",
      "epoch:14 step:14024 [D loss: 0.508868, acc.: 77.34%] [G loss: 0.742782]\n",
      "epoch:14 step:14025 [D loss: 0.583390, acc.: 65.62%] [G loss: 0.833547]\n",
      "epoch:14 step:14026 [D loss: 0.525945, acc.: 66.41%] [G loss: 0.682815]\n",
      "epoch:14 step:14027 [D loss: 0.487894, acc.: 78.12%] [G loss: 0.498235]\n",
      "epoch:14 step:14028 [D loss: 0.529605, acc.: 70.31%] [G loss: 0.640921]\n",
      "epoch:14 step:14029 [D loss: 0.463311, acc.: 80.47%] [G loss: 0.743469]\n",
      "epoch:14 step:14030 [D loss: 0.476646, acc.: 78.91%] [G loss: 0.717328]\n",
      "epoch:14 step:14031 [D loss: 0.568201, acc.: 71.09%] [G loss: 0.789430]\n",
      "epoch:14 step:14032 [D loss: 0.587243, acc.: 67.19%] [G loss: 0.713894]\n",
      "epoch:14 step:14033 [D loss: 0.627844, acc.: 65.62%] [G loss: 0.692363]\n",
      "epoch:14 step:14034 [D loss: 0.560972, acc.: 71.88%] [G loss: 0.611990]\n",
      "epoch:14 step:14035 [D loss: 0.605840, acc.: 58.59%] [G loss: 0.564144]\n",
      "epoch:14 step:14036 [D loss: 0.443890, acc.: 80.47%] [G loss: 0.764315]\n",
      "epoch:14 step:14037 [D loss: 0.489022, acc.: 75.78%] [G loss: 0.812421]\n",
      "epoch:14 step:14038 [D loss: 0.723239, acc.: 58.59%] [G loss: 0.599916]\n",
      "epoch:14 step:14039 [D loss: 0.509480, acc.: 75.78%] [G loss: 0.791826]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:14 step:14040 [D loss: 0.572450, acc.: 68.75%] [G loss: 0.663561]\n",
      "epoch:14 step:14041 [D loss: 0.453034, acc.: 78.91%] [G loss: 0.847544]\n",
      "epoch:14 step:14042 [D loss: 0.459231, acc.: 78.12%] [G loss: 0.812836]\n",
      "epoch:14 step:14043 [D loss: 0.410579, acc.: 79.69%] [G loss: 0.967150]\n",
      "epoch:14 step:14044 [D loss: 0.404223, acc.: 82.03%] [G loss: 0.943551]\n",
      "epoch:14 step:14045 [D loss: 0.530419, acc.: 73.44%] [G loss: 0.985478]\n",
      "epoch:14 step:14046 [D loss: 0.756206, acc.: 59.38%] [G loss: 1.044633]\n",
      "epoch:14 step:14047 [D loss: 0.438118, acc.: 79.69%] [G loss: 1.135012]\n",
      "epoch:14 step:14048 [D loss: 0.459934, acc.: 74.22%] [G loss: 1.219527]\n",
      "epoch:14 step:14049 [D loss: 0.574688, acc.: 64.84%] [G loss: 0.903458]\n",
      "epoch:14 step:14050 [D loss: 0.623715, acc.: 63.28%] [G loss: 0.865995]\n",
      "epoch:14 step:14051 [D loss: 0.521582, acc.: 73.44%] [G loss: 0.774084]\n",
      "epoch:14 step:14052 [D loss: 0.544799, acc.: 70.31%] [G loss: 0.865387]\n",
      "epoch:14 step:14053 [D loss: 0.462445, acc.: 77.34%] [G loss: 0.999657]\n",
      "epoch:14 step:14054 [D loss: 0.380330, acc.: 84.38%] [G loss: 1.366980]\n",
      "epoch:14 step:14055 [D loss: 0.384959, acc.: 85.94%] [G loss: 1.505251]\n",
      "epoch:15 step:14056 [D loss: 0.663455, acc.: 66.41%] [G loss: 1.204963]\n",
      "epoch:15 step:14057 [D loss: 0.495891, acc.: 75.00%] [G loss: 0.999092]\n",
      "epoch:15 step:14058 [D loss: 0.552479, acc.: 71.09%] [G loss: 0.793027]\n",
      "epoch:15 step:14059 [D loss: 0.550725, acc.: 72.66%] [G loss: 0.783773]\n",
      "epoch:15 step:14060 [D loss: 0.584192, acc.: 69.53%] [G loss: 0.715284]\n",
      "epoch:15 step:14061 [D loss: 0.614188, acc.: 66.41%] [G loss: 0.761824]\n",
      "epoch:15 step:14062 [D loss: 0.532266, acc.: 74.22%] [G loss: 0.698436]\n",
      "epoch:15 step:14063 [D loss: 0.513703, acc.: 73.44%] [G loss: 0.807653]\n",
      "epoch:15 step:14064 [D loss: 0.472319, acc.: 80.47%] [G loss: 0.732482]\n",
      "epoch:15 step:14065 [D loss: 0.542263, acc.: 77.34%] [G loss: 0.707162]\n",
      "epoch:15 step:14066 [D loss: 0.495523, acc.: 76.56%] [G loss: 0.625252]\n",
      "epoch:15 step:14067 [D loss: 0.577410, acc.: 68.75%] [G loss: 0.566800]\n",
      "epoch:15 step:14068 [D loss: 0.574367, acc.: 65.62%] [G loss: 0.507086]\n",
      "epoch:15 step:14069 [D loss: 0.567629, acc.: 69.53%] [G loss: 0.618364]\n",
      "epoch:15 step:14070 [D loss: 0.525713, acc.: 75.78%] [G loss: 0.682528]\n",
      "epoch:15 step:14071 [D loss: 0.473150, acc.: 78.91%] [G loss: 0.811707]\n",
      "epoch:15 step:14072 [D loss: 0.575588, acc.: 73.44%] [G loss: 0.645471]\n",
      "epoch:15 step:14073 [D loss: 0.633556, acc.: 57.81%] [G loss: 0.647188]\n",
      "epoch:15 step:14074 [D loss: 0.599782, acc.: 63.28%] [G loss: 0.595105]\n",
      "epoch:15 step:14075 [D loss: 0.599004, acc.: 67.97%] [G loss: 0.635894]\n",
      "epoch:15 step:14076 [D loss: 0.587642, acc.: 64.84%] [G loss: 0.531857]\n",
      "epoch:15 step:14077 [D loss: 0.467464, acc.: 80.47%] [G loss: 0.762785]\n",
      "epoch:15 step:14078 [D loss: 0.522262, acc.: 74.22%] [G loss: 0.711827]\n",
      "epoch:15 step:14079 [D loss: 0.479781, acc.: 76.56%] [G loss: 0.553513]\n",
      "epoch:15 step:14080 [D loss: 0.490446, acc.: 77.34%] [G loss: 0.667808]\n",
      "epoch:15 step:14081 [D loss: 0.521616, acc.: 73.44%] [G loss: 0.615977]\n",
      "epoch:15 step:14082 [D loss: 0.507012, acc.: 74.22%] [G loss: 0.645472]\n",
      "epoch:15 step:14083 [D loss: 0.550783, acc.: 70.31%] [G loss: 0.626858]\n",
      "epoch:15 step:14084 [D loss: 0.495028, acc.: 78.91%] [G loss: 0.574117]\n",
      "epoch:15 step:14085 [D loss: 0.572764, acc.: 69.53%] [G loss: 0.604151]\n",
      "epoch:15 step:14086 [D loss: 0.562976, acc.: 67.97%] [G loss: 0.584958]\n",
      "epoch:15 step:14087 [D loss: 0.489679, acc.: 75.78%] [G loss: 0.500785]\n",
      "epoch:15 step:14088 [D loss: 0.574096, acc.: 67.97%] [G loss: 0.631048]\n",
      "epoch:15 step:14089 [D loss: 0.559301, acc.: 69.53%] [G loss: 0.639036]\n",
      "epoch:15 step:14090 [D loss: 0.551381, acc.: 74.22%] [G loss: 0.533897]\n",
      "epoch:15 step:14091 [D loss: 0.501605, acc.: 75.00%] [G loss: 0.667234]\n",
      "epoch:15 step:14092 [D loss: 0.515644, acc.: 69.53%] [G loss: 0.634879]\n",
      "epoch:15 step:14093 [D loss: 0.578783, acc.: 72.66%] [G loss: 0.566429]\n",
      "epoch:15 step:14094 [D loss: 0.608000, acc.: 61.72%] [G loss: 0.560145]\n",
      "epoch:15 step:14095 [D loss: 0.433921, acc.: 78.91%] [G loss: 0.839216]\n",
      "epoch:15 step:14096 [D loss: 0.571094, acc.: 69.53%] [G loss: 0.859738]\n",
      "epoch:15 step:14097 [D loss: 0.513443, acc.: 72.66%] [G loss: 0.742725]\n",
      "epoch:15 step:14098 [D loss: 0.554208, acc.: 68.75%] [G loss: 0.545155]\n",
      "epoch:15 step:14099 [D loss: 0.539704, acc.: 71.09%] [G loss: 0.676838]\n",
      "epoch:15 step:14100 [D loss: 0.483119, acc.: 78.12%] [G loss: 0.622978]\n",
      "epoch:15 step:14101 [D loss: 0.509130, acc.: 75.00%] [G loss: 0.669337]\n",
      "epoch:15 step:14102 [D loss: 0.552865, acc.: 69.53%] [G loss: 0.615736]\n",
      "epoch:15 step:14103 [D loss: 0.519091, acc.: 75.00%] [G loss: 0.663694]\n",
      "epoch:15 step:14104 [D loss: 0.533986, acc.: 68.75%] [G loss: 0.857980]\n",
      "epoch:15 step:14105 [D loss: 0.591227, acc.: 67.19%] [G loss: 0.716519]\n",
      "epoch:15 step:14106 [D loss: 0.674101, acc.: 60.16%] [G loss: 0.717533]\n",
      "epoch:15 step:14107 [D loss: 0.593623, acc.: 67.19%] [G loss: 0.590355]\n",
      "epoch:15 step:14108 [D loss: 0.539158, acc.: 74.22%] [G loss: 0.586657]\n",
      "epoch:15 step:14109 [D loss: 0.504432, acc.: 75.78%] [G loss: 0.675191]\n",
      "epoch:15 step:14110 [D loss: 0.550783, acc.: 71.09%] [G loss: 0.752183]\n",
      "epoch:15 step:14111 [D loss: 0.517620, acc.: 72.66%] [G loss: 0.689258]\n",
      "epoch:15 step:14112 [D loss: 0.526635, acc.: 70.31%] [G loss: 0.607028]\n",
      "epoch:15 step:14113 [D loss: 0.545735, acc.: 70.31%] [G loss: 0.622047]\n",
      "epoch:15 step:14114 [D loss: 0.484186, acc.: 75.78%] [G loss: 0.692806]\n",
      "epoch:15 step:14115 [D loss: 0.623379, acc.: 60.94%] [G loss: 0.516123]\n",
      "epoch:15 step:14116 [D loss: 0.561842, acc.: 66.41%] [G loss: 0.637368]\n",
      "epoch:15 step:14117 [D loss: 0.550538, acc.: 71.88%] [G loss: 0.527813]\n",
      "epoch:15 step:14118 [D loss: 0.583465, acc.: 67.19%] [G loss: 0.667170]\n",
      "epoch:15 step:14119 [D loss: 0.614887, acc.: 67.19%] [G loss: 0.650693]\n",
      "epoch:15 step:14120 [D loss: 0.516797, acc.: 74.22%] [G loss: 0.645927]\n",
      "epoch:15 step:14121 [D loss: 0.568132, acc.: 65.62%] [G loss: 0.661218]\n",
      "epoch:15 step:14122 [D loss: 0.531056, acc.: 72.66%] [G loss: 0.602277]\n",
      "epoch:15 step:14123 [D loss: 0.515149, acc.: 72.66%] [G loss: 0.605960]\n",
      "epoch:15 step:14124 [D loss: 0.473612, acc.: 78.91%] [G loss: 0.554999]\n",
      "epoch:15 step:14125 [D loss: 0.522873, acc.: 75.78%] [G loss: 0.481656]\n",
      "epoch:15 step:14126 [D loss: 0.537878, acc.: 72.66%] [G loss: 0.550049]\n",
      "epoch:15 step:14127 [D loss: 0.552049, acc.: 71.09%] [G loss: 0.519163]\n",
      "epoch:15 step:14128 [D loss: 0.572984, acc.: 65.62%] [G loss: 0.561869]\n",
      "epoch:15 step:14129 [D loss: 0.467943, acc.: 78.91%] [G loss: 0.594490]\n",
      "epoch:15 step:14130 [D loss: 0.532344, acc.: 71.09%] [G loss: 0.727613]\n",
      "epoch:15 step:14131 [D loss: 0.527817, acc.: 72.66%] [G loss: 0.826408]\n",
      "epoch:15 step:14132 [D loss: 0.466842, acc.: 76.56%] [G loss: 0.721860]\n",
      "epoch:15 step:14133 [D loss: 0.588418, acc.: 67.97%] [G loss: 0.605835]\n",
      "epoch:15 step:14134 [D loss: 0.599755, acc.: 68.75%] [G loss: 0.493081]\n",
      "epoch:15 step:14135 [D loss: 0.462364, acc.: 76.56%] [G loss: 0.724107]\n",
      "epoch:15 step:14136 [D loss: 0.537708, acc.: 68.75%] [G loss: 0.586120]\n",
      "epoch:15 step:14137 [D loss: 0.559205, acc.: 69.53%] [G loss: 0.715859]\n",
      "epoch:15 step:14138 [D loss: 0.520553, acc.: 71.88%] [G loss: 0.593664]\n",
      "epoch:15 step:14139 [D loss: 0.524945, acc.: 66.41%] [G loss: 0.637204]\n",
      "epoch:15 step:14140 [D loss: 0.594804, acc.: 64.84%] [G loss: 0.674714]\n",
      "epoch:15 step:14141 [D loss: 0.525640, acc.: 72.66%] [G loss: 0.547123]\n",
      "epoch:15 step:14142 [D loss: 0.507080, acc.: 75.00%] [G loss: 0.582186]\n",
      "epoch:15 step:14143 [D loss: 0.478136, acc.: 77.34%] [G loss: 0.679487]\n",
      "epoch:15 step:14144 [D loss: 0.536036, acc.: 70.31%] [G loss: 0.700567]\n",
      "epoch:15 step:14145 [D loss: 0.541192, acc.: 67.97%] [G loss: 0.830402]\n",
      "epoch:15 step:14146 [D loss: 0.523321, acc.: 69.53%] [G loss: 0.929161]\n",
      "epoch:15 step:14147 [D loss: 0.489430, acc.: 75.00%] [G loss: 0.782281]\n",
      "epoch:15 step:14148 [D loss: 0.489326, acc.: 78.12%] [G loss: 0.815734]\n",
      "epoch:15 step:14149 [D loss: 0.548394, acc.: 74.22%] [G loss: 0.709001]\n",
      "epoch:15 step:14150 [D loss: 0.529268, acc.: 73.44%] [G loss: 0.824667]\n",
      "epoch:15 step:14151 [D loss: 0.519679, acc.: 73.44%] [G loss: 0.697647]\n",
      "epoch:15 step:14152 [D loss: 0.543817, acc.: 73.44%] [G loss: 0.636539]\n",
      "epoch:15 step:14153 [D loss: 0.534181, acc.: 75.00%] [G loss: 0.720383]\n",
      "epoch:15 step:14154 [D loss: 0.523228, acc.: 75.78%] [G loss: 0.739139]\n",
      "epoch:15 step:14155 [D loss: 0.470151, acc.: 77.34%] [G loss: 0.817165]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:15 step:14156 [D loss: 0.532321, acc.: 72.66%] [G loss: 0.573866]\n",
      "epoch:15 step:14157 [D loss: 0.628680, acc.: 62.50%] [G loss: 0.585726]\n",
      "epoch:15 step:14158 [D loss: 0.535720, acc.: 67.19%] [G loss: 0.556541]\n",
      "epoch:15 step:14159 [D loss: 0.469064, acc.: 75.00%] [G loss: 0.654621]\n",
      "epoch:15 step:14160 [D loss: 0.580410, acc.: 65.62%] [G loss: 0.558945]\n",
      "epoch:15 step:14161 [D loss: 0.540472, acc.: 71.88%] [G loss: 0.614898]\n",
      "epoch:15 step:14162 [D loss: 0.535114, acc.: 71.88%] [G loss: 0.646670]\n",
      "epoch:15 step:14163 [D loss: 0.641625, acc.: 60.94%] [G loss: 0.506037]\n",
      "epoch:15 step:14164 [D loss: 0.617840, acc.: 63.28%] [G loss: 0.608686]\n",
      "epoch:15 step:14165 [D loss: 0.535519, acc.: 73.44%] [G loss: 0.702834]\n",
      "epoch:15 step:14166 [D loss: 0.533795, acc.: 69.53%] [G loss: 0.569312]\n",
      "epoch:15 step:14167 [D loss: 0.543927, acc.: 71.88%] [G loss: 0.568209]\n",
      "epoch:15 step:14168 [D loss: 0.603926, acc.: 63.28%] [G loss: 0.525608]\n",
      "epoch:15 step:14169 [D loss: 0.561472, acc.: 75.00%] [G loss: 0.508924]\n",
      "epoch:15 step:14170 [D loss: 0.516539, acc.: 77.34%] [G loss: 0.601419]\n",
      "epoch:15 step:14171 [D loss: 0.490818, acc.: 76.56%] [G loss: 0.672065]\n",
      "epoch:15 step:14172 [D loss: 0.536266, acc.: 73.44%] [G loss: 0.661242]\n",
      "epoch:15 step:14173 [D loss: 0.517723, acc.: 70.31%] [G loss: 0.758939]\n",
      "epoch:15 step:14174 [D loss: 0.462482, acc.: 75.78%] [G loss: 0.868040]\n",
      "epoch:15 step:14175 [D loss: 0.555471, acc.: 71.09%] [G loss: 0.640377]\n",
      "epoch:15 step:14176 [D loss: 0.487507, acc.: 75.00%] [G loss: 0.601433]\n",
      "epoch:15 step:14177 [D loss: 0.539345, acc.: 77.34%] [G loss: 0.636335]\n",
      "epoch:15 step:14178 [D loss: 0.490414, acc.: 74.22%] [G loss: 0.932589]\n",
      "epoch:15 step:14179 [D loss: 0.621182, acc.: 64.84%] [G loss: 0.733828]\n",
      "epoch:15 step:14180 [D loss: 0.606986, acc.: 66.41%] [G loss: 0.656680]\n",
      "epoch:15 step:14181 [D loss: 0.487681, acc.: 75.00%] [G loss: 0.638639]\n",
      "epoch:15 step:14182 [D loss: 0.488984, acc.: 74.22%] [G loss: 0.619592]\n",
      "epoch:15 step:14183 [D loss: 0.516034, acc.: 75.00%] [G loss: 0.482713]\n",
      "epoch:15 step:14184 [D loss: 0.542111, acc.: 71.88%] [G loss: 0.638995]\n",
      "epoch:15 step:14185 [D loss: 0.471058, acc.: 77.34%] [G loss: 0.755388]\n",
      "epoch:15 step:14186 [D loss: 0.522095, acc.: 69.53%] [G loss: 0.675874]\n",
      "epoch:15 step:14187 [D loss: 0.604788, acc.: 64.06%] [G loss: 0.639306]\n",
      "epoch:15 step:14188 [D loss: 0.585409, acc.: 67.97%] [G loss: 0.680762]\n",
      "epoch:15 step:14189 [D loss: 0.528116, acc.: 71.09%] [G loss: 0.594799]\n",
      "epoch:15 step:14190 [D loss: 0.560847, acc.: 69.53%] [G loss: 0.686859]\n",
      "epoch:15 step:14191 [D loss: 0.535202, acc.: 72.66%] [G loss: 0.786364]\n",
      "epoch:15 step:14192 [D loss: 0.611007, acc.: 71.09%] [G loss: 0.707232]\n",
      "epoch:15 step:14193 [D loss: 0.520607, acc.: 77.34%] [G loss: 0.546937]\n",
      "epoch:15 step:14194 [D loss: 0.564233, acc.: 65.62%] [G loss: 0.482270]\n",
      "epoch:15 step:14195 [D loss: 0.568874, acc.: 61.72%] [G loss: 0.604813]\n",
      "epoch:15 step:14196 [D loss: 0.499717, acc.: 70.31%] [G loss: 0.584431]\n",
      "epoch:15 step:14197 [D loss: 0.502050, acc.: 71.88%] [G loss: 0.549313]\n",
      "epoch:15 step:14198 [D loss: 0.585321, acc.: 64.84%] [G loss: 0.543651]\n",
      "epoch:15 step:14199 [D loss: 0.505914, acc.: 72.66%] [G loss: 0.516284]\n",
      "epoch:15 step:14200 [D loss: 0.592374, acc.: 65.62%] [G loss: 0.496022]\n",
      "##############\n",
      "[2.84045527 1.18987097 6.15808573 4.71568448 4.04197645 5.86031658\n",
      " 4.85474081 4.74827481 4.61521666 4.13210442]\n",
      "##########\n",
      "epoch:15 step:14201 [D loss: 0.458656, acc.: 78.91%] [G loss: 0.607615]\n",
      "epoch:15 step:14202 [D loss: 0.633374, acc.: 62.50%] [G loss: 0.553593]\n",
      "epoch:15 step:14203 [D loss: 0.562746, acc.: 62.50%] [G loss: 0.510407]\n",
      "epoch:15 step:14204 [D loss: 0.514243, acc.: 77.34%] [G loss: 0.612830]\n",
      "epoch:15 step:14205 [D loss: 0.662624, acc.: 62.50%] [G loss: 0.624363]\n",
      "epoch:15 step:14206 [D loss: 0.535773, acc.: 72.66%] [G loss: 0.729098]\n",
      "epoch:15 step:14207 [D loss: 0.464177, acc.: 80.47%] [G loss: 0.803950]\n",
      "epoch:15 step:14208 [D loss: 0.548589, acc.: 75.00%] [G loss: 0.554709]\n",
      "epoch:15 step:14209 [D loss: 0.578472, acc.: 64.06%] [G loss: 0.555007]\n",
      "epoch:15 step:14210 [D loss: 0.446448, acc.: 78.12%] [G loss: 0.676439]\n",
      "epoch:15 step:14211 [D loss: 0.546952, acc.: 69.53%] [G loss: 0.652138]\n",
      "epoch:15 step:14212 [D loss: 0.589323, acc.: 67.97%] [G loss: 0.773292]\n",
      "epoch:15 step:14213 [D loss: 0.580625, acc.: 65.62%] [G loss: 0.509106]\n",
      "epoch:15 step:14214 [D loss: 0.525233, acc.: 75.78%] [G loss: 0.617256]\n",
      "epoch:15 step:14215 [D loss: 0.610469, acc.: 64.06%] [G loss: 0.552201]\n",
      "epoch:15 step:14216 [D loss: 0.513444, acc.: 75.00%] [G loss: 0.671498]\n",
      "epoch:15 step:14217 [D loss: 0.468182, acc.: 74.22%] [G loss: 0.985287]\n",
      "epoch:15 step:14218 [D loss: 0.581160, acc.: 65.62%] [G loss: 0.687141]\n",
      "epoch:15 step:14219 [D loss: 0.519062, acc.: 72.66%] [G loss: 0.627918]\n",
      "epoch:15 step:14220 [D loss: 0.477782, acc.: 77.34%] [G loss: 0.627759]\n",
      "epoch:15 step:14221 [D loss: 0.583264, acc.: 67.19%] [G loss: 0.531470]\n",
      "epoch:15 step:14222 [D loss: 0.518038, acc.: 72.66%] [G loss: 0.635999]\n",
      "epoch:15 step:14223 [D loss: 0.591960, acc.: 63.28%] [G loss: 0.487161]\n",
      "epoch:15 step:14224 [D loss: 0.634854, acc.: 62.50%] [G loss: 0.542148]\n",
      "epoch:15 step:14225 [D loss: 0.549888, acc.: 64.84%] [G loss: 0.541577]\n",
      "epoch:15 step:14226 [D loss: 0.533355, acc.: 68.75%] [G loss: 0.636122]\n",
      "epoch:15 step:14227 [D loss: 0.497010, acc.: 74.22%] [G loss: 0.532178]\n",
      "epoch:15 step:14228 [D loss: 0.515425, acc.: 71.09%] [G loss: 0.709829]\n",
      "epoch:15 step:14229 [D loss: 0.610986, acc.: 63.28%] [G loss: 0.683850]\n",
      "epoch:15 step:14230 [D loss: 0.589572, acc.: 67.19%] [G loss: 0.519776]\n",
      "epoch:15 step:14231 [D loss: 0.485079, acc.: 72.66%] [G loss: 0.731979]\n",
      "epoch:15 step:14232 [D loss: 0.507306, acc.: 75.00%] [G loss: 0.659737]\n",
      "epoch:15 step:14233 [D loss: 0.605999, acc.: 64.84%] [G loss: 0.612120]\n",
      "epoch:15 step:14234 [D loss: 0.558481, acc.: 70.31%] [G loss: 0.595337]\n",
      "epoch:15 step:14235 [D loss: 0.600582, acc.: 65.62%] [G loss: 0.385068]\n",
      "epoch:15 step:14236 [D loss: 0.582413, acc.: 69.53%] [G loss: 0.546250]\n",
      "epoch:15 step:14237 [D loss: 0.508702, acc.: 71.88%] [G loss: 0.763642]\n",
      "epoch:15 step:14238 [D loss: 0.552473, acc.: 72.66%] [G loss: 0.741392]\n",
      "epoch:15 step:14239 [D loss: 0.535757, acc.: 70.31%] [G loss: 0.731652]\n",
      "epoch:15 step:14240 [D loss: 0.582124, acc.: 68.75%] [G loss: 0.636232]\n",
      "epoch:15 step:14241 [D loss: 0.526010, acc.: 75.00%] [G loss: 0.684911]\n",
      "epoch:15 step:14242 [D loss: 0.584677, acc.: 69.53%] [G loss: 0.700911]\n",
      "epoch:15 step:14243 [D loss: 0.533344, acc.: 67.97%] [G loss: 0.511749]\n",
      "epoch:15 step:14244 [D loss: 0.615803, acc.: 65.62%] [G loss: 0.553481]\n",
      "epoch:15 step:14245 [D loss: 0.496381, acc.: 76.56%] [G loss: 0.616144]\n",
      "epoch:15 step:14246 [D loss: 0.521737, acc.: 73.44%] [G loss: 0.683629]\n",
      "epoch:15 step:14247 [D loss: 0.509945, acc.: 74.22%] [G loss: 0.666391]\n",
      "epoch:15 step:14248 [D loss: 0.529575, acc.: 69.53%] [G loss: 0.664990]\n",
      "epoch:15 step:14249 [D loss: 0.484577, acc.: 73.44%] [G loss: 0.672526]\n",
      "epoch:15 step:14250 [D loss: 0.574381, acc.: 70.31%] [G loss: 0.621654]\n",
      "epoch:15 step:14251 [D loss: 0.630610, acc.: 63.28%] [G loss: 0.485602]\n",
      "epoch:15 step:14252 [D loss: 0.517354, acc.: 75.00%] [G loss: 0.659032]\n",
      "epoch:15 step:14253 [D loss: 0.456410, acc.: 77.34%] [G loss: 0.839858]\n",
      "epoch:15 step:14254 [D loss: 0.572240, acc.: 68.75%] [G loss: 0.708334]\n",
      "epoch:15 step:14255 [D loss: 0.602432, acc.: 65.62%] [G loss: 0.568468]\n",
      "epoch:15 step:14256 [D loss: 0.584918, acc.: 66.41%] [G loss: 0.616370]\n",
      "epoch:15 step:14257 [D loss: 0.501685, acc.: 75.00%] [G loss: 0.644294]\n",
      "epoch:15 step:14258 [D loss: 0.642050, acc.: 62.50%] [G loss: 0.701424]\n",
      "epoch:15 step:14259 [D loss: 0.561254, acc.: 70.31%] [G loss: 0.599412]\n",
      "epoch:15 step:14260 [D loss: 0.483424, acc.: 78.12%] [G loss: 0.743892]\n",
      "epoch:15 step:14261 [D loss: 0.523532, acc.: 68.75%] [G loss: 0.669884]\n",
      "epoch:15 step:14262 [D loss: 0.465207, acc.: 78.12%] [G loss: 0.810947]\n",
      "epoch:15 step:14263 [D loss: 0.467070, acc.: 76.56%] [G loss: 0.785414]\n",
      "epoch:15 step:14264 [D loss: 0.516098, acc.: 70.31%] [G loss: 0.879020]\n",
      "epoch:15 step:14265 [D loss: 0.676273, acc.: 60.94%] [G loss: 0.480590]\n",
      "epoch:15 step:14266 [D loss: 0.608806, acc.: 65.62%] [G loss: 0.399379]\n",
      "epoch:15 step:14267 [D loss: 0.502406, acc.: 77.34%] [G loss: 0.583753]\n",
      "epoch:15 step:14268 [D loss: 0.582901, acc.: 67.19%] [G loss: 0.512205]\n",
      "epoch:15 step:14269 [D loss: 0.629504, acc.: 57.81%] [G loss: 0.542938]\n",
      "epoch:15 step:14270 [D loss: 0.613478, acc.: 58.59%] [G loss: 0.514829]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:15 step:14271 [D loss: 0.544240, acc.: 68.75%] [G loss: 0.502972]\n",
      "epoch:15 step:14272 [D loss: 0.527199, acc.: 73.44%] [G loss: 0.573575]\n",
      "epoch:15 step:14273 [D loss: 0.530242, acc.: 73.44%] [G loss: 0.612952]\n",
      "epoch:15 step:14274 [D loss: 0.495420, acc.: 78.91%] [G loss: 0.567651]\n",
      "epoch:15 step:14275 [D loss: 0.639993, acc.: 67.97%] [G loss: 0.501850]\n",
      "epoch:15 step:14276 [D loss: 0.513178, acc.: 75.00%] [G loss: 0.531366]\n",
      "epoch:15 step:14277 [D loss: 0.477112, acc.: 74.22%] [G loss: 0.623681]\n",
      "epoch:15 step:14278 [D loss: 0.468295, acc.: 78.91%] [G loss: 0.925727]\n",
      "epoch:15 step:14279 [D loss: 0.582738, acc.: 67.97%] [G loss: 0.779030]\n",
      "epoch:15 step:14280 [D loss: 0.563178, acc.: 70.31%] [G loss: 0.645787]\n",
      "epoch:15 step:14281 [D loss: 0.609321, acc.: 64.06%] [G loss: 0.479016]\n",
      "epoch:15 step:14282 [D loss: 0.528225, acc.: 74.22%] [G loss: 0.514830]\n",
      "epoch:15 step:14283 [D loss: 0.609843, acc.: 64.06%] [G loss: 0.464637]\n",
      "epoch:15 step:14284 [D loss: 0.480215, acc.: 78.12%] [G loss: 0.588494]\n",
      "epoch:15 step:14285 [D loss: 0.571925, acc.: 69.53%] [G loss: 0.576173]\n",
      "epoch:15 step:14286 [D loss: 0.511209, acc.: 71.09%] [G loss: 0.733600]\n",
      "epoch:15 step:14287 [D loss: 0.462277, acc.: 80.47%] [G loss: 1.005091]\n",
      "epoch:15 step:14288 [D loss: 0.532618, acc.: 72.66%] [G loss: 0.677791]\n",
      "epoch:15 step:14289 [D loss: 0.569963, acc.: 74.22%] [G loss: 0.720048]\n",
      "epoch:15 step:14290 [D loss: 0.540606, acc.: 68.75%] [G loss: 0.691632]\n",
      "epoch:15 step:14291 [D loss: 0.561483, acc.: 70.31%] [G loss: 0.812915]\n",
      "epoch:15 step:14292 [D loss: 0.553673, acc.: 70.31%] [G loss: 0.677204]\n",
      "epoch:15 step:14293 [D loss: 0.570363, acc.: 71.88%] [G loss: 0.552798]\n",
      "epoch:15 step:14294 [D loss: 0.518950, acc.: 72.66%] [G loss: 0.559090]\n",
      "epoch:15 step:14295 [D loss: 0.561919, acc.: 65.62%] [G loss: 0.516489]\n",
      "epoch:15 step:14296 [D loss: 0.506961, acc.: 76.56%] [G loss: 0.631598]\n",
      "epoch:15 step:14297 [D loss: 0.544915, acc.: 68.75%] [G loss: 0.556404]\n",
      "epoch:15 step:14298 [D loss: 0.596488, acc.: 65.62%] [G loss: 0.575505]\n",
      "epoch:15 step:14299 [D loss: 0.492253, acc.: 71.09%] [G loss: 0.566602]\n",
      "epoch:15 step:14300 [D loss: 0.524451, acc.: 71.09%] [G loss: 0.589835]\n",
      "epoch:15 step:14301 [D loss: 0.508635, acc.: 73.44%] [G loss: 0.634558]\n",
      "epoch:15 step:14302 [D loss: 0.514373, acc.: 73.44%] [G loss: 0.845916]\n",
      "epoch:15 step:14303 [D loss: 0.516143, acc.: 72.66%] [G loss: 0.673291]\n",
      "epoch:15 step:14304 [D loss: 0.652589, acc.: 64.06%] [G loss: 0.763549]\n",
      "epoch:15 step:14305 [D loss: 0.612160, acc.: 64.06%] [G loss: 0.717791]\n",
      "epoch:15 step:14306 [D loss: 0.686405, acc.: 56.25%] [G loss: 0.535557]\n",
      "epoch:15 step:14307 [D loss: 0.522464, acc.: 75.00%] [G loss: 0.663296]\n",
      "epoch:15 step:14308 [D loss: 0.572443, acc.: 68.75%] [G loss: 0.563138]\n",
      "epoch:15 step:14309 [D loss: 0.503040, acc.: 71.88%] [G loss: 0.550546]\n",
      "epoch:15 step:14310 [D loss: 0.505089, acc.: 72.66%] [G loss: 0.684906]\n",
      "epoch:15 step:14311 [D loss: 0.523792, acc.: 71.09%] [G loss: 0.611612]\n",
      "epoch:15 step:14312 [D loss: 0.616074, acc.: 62.50%] [G loss: 0.573050]\n",
      "epoch:15 step:14313 [D loss: 0.539164, acc.: 70.31%] [G loss: 0.571472]\n",
      "epoch:15 step:14314 [D loss: 0.522904, acc.: 70.31%] [G loss: 0.598743]\n",
      "epoch:15 step:14315 [D loss: 0.567229, acc.: 64.84%] [G loss: 0.529716]\n",
      "epoch:15 step:14316 [D loss: 0.542293, acc.: 64.84%] [G loss: 0.575211]\n",
      "epoch:15 step:14317 [D loss: 0.458380, acc.: 77.34%] [G loss: 0.717402]\n",
      "epoch:15 step:14318 [D loss: 0.582824, acc.: 70.31%] [G loss: 0.531592]\n",
      "epoch:15 step:14319 [D loss: 0.511444, acc.: 67.97%] [G loss: 0.619228]\n",
      "epoch:15 step:14320 [D loss: 0.559833, acc.: 71.09%] [G loss: 0.575848]\n",
      "epoch:15 step:14321 [D loss: 0.541330, acc.: 71.09%] [G loss: 0.542290]\n",
      "epoch:15 step:14322 [D loss: 0.583930, acc.: 67.97%] [G loss: 0.536466]\n",
      "epoch:15 step:14323 [D loss: 0.530386, acc.: 70.31%] [G loss: 0.462878]\n",
      "epoch:15 step:14324 [D loss: 0.538304, acc.: 70.31%] [G loss: 0.580127]\n",
      "epoch:15 step:14325 [D loss: 0.525159, acc.: 71.88%] [G loss: 0.607069]\n",
      "epoch:15 step:14326 [D loss: 0.525104, acc.: 73.44%] [G loss: 0.545716]\n",
      "epoch:15 step:14327 [D loss: 0.556857, acc.: 71.09%] [G loss: 0.626536]\n",
      "epoch:15 step:14328 [D loss: 0.495432, acc.: 71.88%] [G loss: 0.631472]\n",
      "epoch:15 step:14329 [D loss: 0.510792, acc.: 73.44%] [G loss: 0.666906]\n",
      "epoch:15 step:14330 [D loss: 0.586275, acc.: 68.75%] [G loss: 0.532931]\n",
      "epoch:15 step:14331 [D loss: 0.484287, acc.: 76.56%] [G loss: 0.628641]\n",
      "epoch:15 step:14332 [D loss: 0.623846, acc.: 68.75%] [G loss: 0.475859]\n",
      "epoch:15 step:14333 [D loss: 0.642470, acc.: 60.16%] [G loss: 0.405748]\n",
      "epoch:15 step:14334 [D loss: 0.656217, acc.: 57.81%] [G loss: 0.421406]\n",
      "epoch:15 step:14335 [D loss: 0.511372, acc.: 73.44%] [G loss: 0.596007]\n",
      "epoch:15 step:14336 [D loss: 0.547097, acc.: 72.66%] [G loss: 0.707026]\n",
      "epoch:15 step:14337 [D loss: 0.603019, acc.: 64.84%] [G loss: 0.460054]\n",
      "epoch:15 step:14338 [D loss: 0.499007, acc.: 79.69%] [G loss: 0.624041]\n",
      "epoch:15 step:14339 [D loss: 0.476655, acc.: 76.56%] [G loss: 0.577536]\n",
      "epoch:15 step:14340 [D loss: 0.540051, acc.: 69.53%] [G loss: 0.575511]\n",
      "epoch:15 step:14341 [D loss: 0.487946, acc.: 78.91%] [G loss: 0.623488]\n",
      "epoch:15 step:14342 [D loss: 0.562746, acc.: 67.97%] [G loss: 0.584813]\n",
      "epoch:15 step:14343 [D loss: 0.546254, acc.: 70.31%] [G loss: 0.625340]\n",
      "epoch:15 step:14344 [D loss: 0.554157, acc.: 68.75%] [G loss: 0.669018]\n",
      "epoch:15 step:14345 [D loss: 0.593234, acc.: 64.84%] [G loss: 0.540774]\n",
      "epoch:15 step:14346 [D loss: 0.608292, acc.: 67.19%] [G loss: 0.605176]\n",
      "epoch:15 step:14347 [D loss: 0.522374, acc.: 69.53%] [G loss: 0.626269]\n",
      "epoch:15 step:14348 [D loss: 0.574663, acc.: 65.62%] [G loss: 0.480913]\n",
      "epoch:15 step:14349 [D loss: 0.565192, acc.: 69.53%] [G loss: 0.524136]\n",
      "epoch:15 step:14350 [D loss: 0.578241, acc.: 67.19%] [G loss: 0.393096]\n",
      "epoch:15 step:14351 [D loss: 0.486804, acc.: 75.00%] [G loss: 0.564428]\n",
      "epoch:15 step:14352 [D loss: 0.553167, acc.: 67.19%] [G loss: 0.545546]\n",
      "epoch:15 step:14353 [D loss: 0.473823, acc.: 81.25%] [G loss: 0.597631]\n",
      "epoch:15 step:14354 [D loss: 0.498776, acc.: 75.78%] [G loss: 0.609257]\n",
      "epoch:15 step:14355 [D loss: 0.536414, acc.: 71.09%] [G loss: 0.679245]\n",
      "epoch:15 step:14356 [D loss: 0.625449, acc.: 64.84%] [G loss: 0.492855]\n",
      "epoch:15 step:14357 [D loss: 0.562780, acc.: 68.75%] [G loss: 0.603186]\n",
      "epoch:15 step:14358 [D loss: 0.544985, acc.: 74.22%] [G loss: 0.561580]\n",
      "epoch:15 step:14359 [D loss: 0.507258, acc.: 73.44%] [G loss: 0.616909]\n",
      "epoch:15 step:14360 [D loss: 0.546636, acc.: 71.88%] [G loss: 0.643818]\n",
      "epoch:15 step:14361 [D loss: 0.484120, acc.: 72.66%] [G loss: 0.752153]\n",
      "epoch:15 step:14362 [D loss: 0.499202, acc.: 74.22%] [G loss: 0.791753]\n",
      "epoch:15 step:14363 [D loss: 0.585751, acc.: 69.53%] [G loss: 0.607666]\n",
      "epoch:15 step:14364 [D loss: 0.512881, acc.: 72.66%] [G loss: 0.626972]\n",
      "epoch:15 step:14365 [D loss: 0.527883, acc.: 71.88%] [G loss: 0.810233]\n",
      "epoch:15 step:14366 [D loss: 0.465665, acc.: 76.56%] [G loss: 0.704647]\n",
      "epoch:15 step:14367 [D loss: 0.436309, acc.: 82.03%] [G loss: 0.889465]\n",
      "epoch:15 step:14368 [D loss: 0.520357, acc.: 72.66%] [G loss: 0.994685]\n",
      "epoch:15 step:14369 [D loss: 0.447008, acc.: 80.47%] [G loss: 1.093516]\n",
      "epoch:15 step:14370 [D loss: 0.506336, acc.: 72.66%] [G loss: 0.937487]\n",
      "epoch:15 step:14371 [D loss: 0.755607, acc.: 58.59%] [G loss: 0.502131]\n",
      "epoch:15 step:14372 [D loss: 0.582186, acc.: 67.19%] [G loss: 0.533228]\n",
      "epoch:15 step:14373 [D loss: 0.509911, acc.: 71.09%] [G loss: 0.683757]\n",
      "epoch:15 step:14374 [D loss: 0.551982, acc.: 68.75%] [G loss: 0.567150]\n",
      "epoch:15 step:14375 [D loss: 0.568480, acc.: 69.53%] [G loss: 0.514445]\n",
      "epoch:15 step:14376 [D loss: 0.484969, acc.: 75.78%] [G loss: 0.669873]\n",
      "epoch:15 step:14377 [D loss: 0.569505, acc.: 68.75%] [G loss: 0.649852]\n",
      "epoch:15 step:14378 [D loss: 0.624141, acc.: 64.84%] [G loss: 0.464350]\n",
      "epoch:15 step:14379 [D loss: 0.594439, acc.: 65.62%] [G loss: 0.503979]\n",
      "epoch:15 step:14380 [D loss: 0.546824, acc.: 75.00%] [G loss: 0.501632]\n",
      "epoch:15 step:14381 [D loss: 0.462674, acc.: 78.91%] [G loss: 0.779181]\n",
      "epoch:15 step:14382 [D loss: 0.555612, acc.: 71.88%] [G loss: 0.690390]\n",
      "epoch:15 step:14383 [D loss: 0.492006, acc.: 75.00%] [G loss: 0.677569]\n",
      "epoch:15 step:14384 [D loss: 0.499197, acc.: 72.66%] [G loss: 0.826375]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:15 step:14385 [D loss: 0.630156, acc.: 64.84%] [G loss: 0.403663]\n",
      "epoch:15 step:14386 [D loss: 0.529134, acc.: 71.09%] [G loss: 0.548797]\n",
      "epoch:15 step:14387 [D loss: 0.545650, acc.: 69.53%] [G loss: 0.438761]\n",
      "epoch:15 step:14388 [D loss: 0.561473, acc.: 74.22%] [G loss: 0.660913]\n",
      "epoch:15 step:14389 [D loss: 0.544917, acc.: 72.66%] [G loss: 0.731311]\n",
      "epoch:15 step:14390 [D loss: 0.557581, acc.: 69.53%] [G loss: 0.585027]\n",
      "epoch:15 step:14391 [D loss: 0.514699, acc.: 78.12%] [G loss: 0.564070]\n",
      "epoch:15 step:14392 [D loss: 0.539112, acc.: 73.44%] [G loss: 0.659576]\n",
      "epoch:15 step:14393 [D loss: 0.582260, acc.: 65.62%] [G loss: 0.633014]\n",
      "epoch:15 step:14394 [D loss: 0.509278, acc.: 72.66%] [G loss: 0.599540]\n",
      "epoch:15 step:14395 [D loss: 0.459023, acc.: 82.03%] [G loss: 0.609481]\n",
      "epoch:15 step:14396 [D loss: 0.590260, acc.: 68.75%] [G loss: 0.585225]\n",
      "epoch:15 step:14397 [D loss: 0.629777, acc.: 65.62%] [G loss: 0.527151]\n",
      "epoch:15 step:14398 [D loss: 0.512022, acc.: 70.31%] [G loss: 0.650372]\n",
      "epoch:15 step:14399 [D loss: 0.516675, acc.: 69.53%] [G loss: 0.771670]\n",
      "epoch:15 step:14400 [D loss: 0.535319, acc.: 71.09%] [G loss: 0.764606]\n",
      "##############\n",
      "[3.04855119 0.69391449 6.00674427 4.6844499  4.05775329 5.78022028\n",
      " 4.48090021 5.1378113  4.61218724 4.02869944]\n",
      "##########\n",
      "epoch:15 step:14401 [D loss: 0.567192, acc.: 65.62%] [G loss: 0.917461]\n",
      "epoch:15 step:14402 [D loss: 0.513358, acc.: 75.78%] [G loss: 1.012174]\n",
      "epoch:15 step:14403 [D loss: 0.649017, acc.: 64.06%] [G loss: 0.628821]\n",
      "epoch:15 step:14404 [D loss: 0.661063, acc.: 60.16%] [G loss: 0.564590]\n",
      "epoch:15 step:14405 [D loss: 0.531151, acc.: 71.09%] [G loss: 0.504288]\n",
      "epoch:15 step:14406 [D loss: 0.508977, acc.: 77.34%] [G loss: 0.709122]\n",
      "epoch:15 step:14407 [D loss: 0.631100, acc.: 60.94%] [G loss: 0.658982]\n",
      "epoch:15 step:14408 [D loss: 0.549586, acc.: 71.09%] [G loss: 0.674726]\n",
      "epoch:15 step:14409 [D loss: 0.364705, acc.: 86.72%] [G loss: 0.842316]\n",
      "epoch:15 step:14410 [D loss: 0.613117, acc.: 63.28%] [G loss: 0.731310]\n",
      "epoch:15 step:14411 [D loss: 0.542975, acc.: 68.75%] [G loss: 0.771266]\n",
      "epoch:15 step:14412 [D loss: 0.479463, acc.: 72.66%] [G loss: 0.702811]\n",
      "epoch:15 step:14413 [D loss: 0.506151, acc.: 72.66%] [G loss: 0.884563]\n",
      "epoch:15 step:14414 [D loss: 0.493210, acc.: 75.78%] [G loss: 0.851646]\n",
      "epoch:15 step:14415 [D loss: 0.526238, acc.: 71.09%] [G loss: 0.874160]\n",
      "epoch:15 step:14416 [D loss: 0.461159, acc.: 81.25%] [G loss: 0.926353]\n",
      "epoch:15 step:14417 [D loss: 0.573057, acc.: 67.97%] [G loss: 0.678733]\n",
      "epoch:15 step:14418 [D loss: 0.589254, acc.: 65.62%] [G loss: 0.632006]\n",
      "epoch:15 step:14419 [D loss: 0.497281, acc.: 72.66%] [G loss: 0.652624]\n",
      "epoch:15 step:14420 [D loss: 0.570095, acc.: 67.97%] [G loss: 0.641502]\n",
      "epoch:15 step:14421 [D loss: 0.574794, acc.: 67.19%] [G loss: 0.613342]\n",
      "epoch:15 step:14422 [D loss: 0.607004, acc.: 64.06%] [G loss: 0.490216]\n",
      "epoch:15 step:14423 [D loss: 0.549335, acc.: 68.75%] [G loss: 0.647220]\n",
      "epoch:15 step:14424 [D loss: 0.538894, acc.: 70.31%] [G loss: 0.538615]\n",
      "epoch:15 step:14425 [D loss: 0.569175, acc.: 70.31%] [G loss: 0.641035]\n",
      "epoch:15 step:14426 [D loss: 0.553379, acc.: 71.88%] [G loss: 0.736041]\n",
      "epoch:15 step:14427 [D loss: 0.558942, acc.: 71.88%] [G loss: 0.571661]\n",
      "epoch:15 step:14428 [D loss: 0.562653, acc.: 69.53%] [G loss: 0.570226]\n",
      "epoch:15 step:14429 [D loss: 0.474393, acc.: 70.31%] [G loss: 0.677640]\n",
      "epoch:15 step:14430 [D loss: 0.631183, acc.: 60.16%] [G loss: 0.558572]\n",
      "epoch:15 step:14431 [D loss: 0.696508, acc.: 57.81%] [G loss: 0.575072]\n",
      "epoch:15 step:14432 [D loss: 0.551604, acc.: 66.41%] [G loss: 0.525949]\n",
      "epoch:15 step:14433 [D loss: 0.575150, acc.: 67.19%] [G loss: 0.565160]\n",
      "epoch:15 step:14434 [D loss: 0.608987, acc.: 64.84%] [G loss: 0.602566]\n",
      "epoch:15 step:14435 [D loss: 0.599903, acc.: 65.62%] [G loss: 0.563616]\n",
      "epoch:15 step:14436 [D loss: 0.504613, acc.: 75.78%] [G loss: 0.549439]\n",
      "epoch:15 step:14437 [D loss: 0.550496, acc.: 75.00%] [G loss: 0.595077]\n",
      "epoch:15 step:14438 [D loss: 0.569161, acc.: 67.19%] [G loss: 0.577222]\n",
      "epoch:15 step:14439 [D loss: 0.529920, acc.: 69.53%] [G loss: 0.619196]\n",
      "epoch:15 step:14440 [D loss: 0.487353, acc.: 75.78%] [G loss: 0.632245]\n",
      "epoch:15 step:14441 [D loss: 0.615474, acc.: 64.84%] [G loss: 0.645034]\n",
      "epoch:15 step:14442 [D loss: 0.526150, acc.: 67.97%] [G loss: 0.476706]\n",
      "epoch:15 step:14443 [D loss: 0.498435, acc.: 78.91%] [G loss: 0.684737]\n",
      "epoch:15 step:14444 [D loss: 0.522439, acc.: 73.44%] [G loss: 0.559656]\n",
      "epoch:15 step:14445 [D loss: 0.625401, acc.: 63.28%] [G loss: 0.467774]\n",
      "epoch:15 step:14446 [D loss: 0.596062, acc.: 63.28%] [G loss: 0.574313]\n",
      "epoch:15 step:14447 [D loss: 0.524614, acc.: 71.09%] [G loss: 0.529746]\n",
      "epoch:15 step:14448 [D loss: 0.620444, acc.: 64.84%] [G loss: 0.589832]\n",
      "epoch:15 step:14449 [D loss: 0.527908, acc.: 72.66%] [G loss: 0.680474]\n",
      "epoch:15 step:14450 [D loss: 0.564278, acc.: 70.31%] [G loss: 0.487266]\n",
      "epoch:15 step:14451 [D loss: 0.550088, acc.: 69.53%] [G loss: 0.662079]\n",
      "epoch:15 step:14452 [D loss: 0.562485, acc.: 64.06%] [G loss: 0.617111]\n",
      "epoch:15 step:14453 [D loss: 0.509058, acc.: 73.44%] [G loss: 0.450046]\n",
      "epoch:15 step:14454 [D loss: 0.535017, acc.: 71.88%] [G loss: 0.694052]\n",
      "epoch:15 step:14455 [D loss: 0.656179, acc.: 57.03%] [G loss: 0.514117]\n",
      "epoch:15 step:14456 [D loss: 0.652633, acc.: 55.47%] [G loss: 0.476297]\n",
      "epoch:15 step:14457 [D loss: 0.505905, acc.: 71.88%] [G loss: 0.769229]\n",
      "epoch:15 step:14458 [D loss: 0.470986, acc.: 71.88%] [G loss: 0.730181]\n",
      "epoch:15 step:14459 [D loss: 0.584347, acc.: 66.41%] [G loss: 0.538407]\n",
      "epoch:15 step:14460 [D loss: 0.530231, acc.: 71.09%] [G loss: 0.825530]\n",
      "epoch:15 step:14461 [D loss: 0.506591, acc.: 72.66%] [G loss: 0.853867]\n",
      "epoch:15 step:14462 [D loss: 0.568329, acc.: 65.62%] [G loss: 0.687937]\n",
      "epoch:15 step:14463 [D loss: 0.599979, acc.: 67.97%] [G loss: 0.740027]\n",
      "epoch:15 step:14464 [D loss: 0.538878, acc.: 67.19%] [G loss: 0.644292]\n",
      "epoch:15 step:14465 [D loss: 0.630573, acc.: 57.81%] [G loss: 0.584241]\n",
      "epoch:15 step:14466 [D loss: 0.569950, acc.: 68.75%] [G loss: 0.670470]\n",
      "epoch:15 step:14467 [D loss: 0.628823, acc.: 60.16%] [G loss: 0.530188]\n",
      "epoch:15 step:14468 [D loss: 0.575698, acc.: 71.09%] [G loss: 0.680091]\n",
      "epoch:15 step:14469 [D loss: 0.545889, acc.: 67.97%] [G loss: 0.560000]\n",
      "epoch:15 step:14470 [D loss: 0.564607, acc.: 67.19%] [G loss: 0.693998]\n",
      "epoch:15 step:14471 [D loss: 0.495952, acc.: 79.69%] [G loss: 0.661070]\n",
      "epoch:15 step:14472 [D loss: 0.570856, acc.: 70.31%] [G loss: 0.738216]\n",
      "epoch:15 step:14473 [D loss: 0.607919, acc.: 66.41%] [G loss: 0.504799]\n",
      "epoch:15 step:14474 [D loss: 0.553597, acc.: 71.88%] [G loss: 0.536879]\n",
      "epoch:15 step:14475 [D loss: 0.603485, acc.: 62.50%] [G loss: 0.615653]\n",
      "epoch:15 step:14476 [D loss: 0.567352, acc.: 72.66%] [G loss: 0.730479]\n",
      "epoch:15 step:14477 [D loss: 0.604578, acc.: 67.19%] [G loss: 0.609693]\n",
      "epoch:15 step:14478 [D loss: 0.568631, acc.: 68.75%] [G loss: 0.487833]\n",
      "epoch:15 step:14479 [D loss: 0.558221, acc.: 71.88%] [G loss: 0.668894]\n",
      "epoch:15 step:14480 [D loss: 0.539557, acc.: 72.66%] [G loss: 0.622007]\n",
      "epoch:15 step:14481 [D loss: 0.494067, acc.: 74.22%] [G loss: 0.668710]\n",
      "epoch:15 step:14482 [D loss: 0.487876, acc.: 75.00%] [G loss: 0.815936]\n",
      "epoch:15 step:14483 [D loss: 0.536525, acc.: 71.09%] [G loss: 0.783741]\n",
      "epoch:15 step:14484 [D loss: 0.516233, acc.: 73.44%] [G loss: 0.802839]\n",
      "epoch:15 step:14485 [D loss: 0.524544, acc.: 75.00%] [G loss: 0.749340]\n",
      "epoch:15 step:14486 [D loss: 0.519972, acc.: 69.53%] [G loss: 0.739915]\n",
      "epoch:15 step:14487 [D loss: 0.574694, acc.: 64.06%] [G loss: 0.732045]\n",
      "epoch:15 step:14488 [D loss: 0.589446, acc.: 68.75%] [G loss: 0.701111]\n",
      "epoch:15 step:14489 [D loss: 0.529859, acc.: 67.97%] [G loss: 0.544641]\n",
      "epoch:15 step:14490 [D loss: 0.581843, acc.: 69.53%] [G loss: 0.647916]\n",
      "epoch:15 step:14491 [D loss: 0.519548, acc.: 75.78%] [G loss: 0.783416]\n",
      "epoch:15 step:14492 [D loss: 0.654320, acc.: 63.28%] [G loss: 0.511994]\n",
      "epoch:15 step:14493 [D loss: 0.540704, acc.: 71.09%] [G loss: 0.674592]\n",
      "epoch:15 step:14494 [D loss: 0.486766, acc.: 78.91%] [G loss: 0.739845]\n",
      "epoch:15 step:14495 [D loss: 0.518301, acc.: 73.44%] [G loss: 0.713706]\n",
      "epoch:15 step:14496 [D loss: 0.631166, acc.: 66.41%] [G loss: 0.878849]\n",
      "epoch:15 step:14497 [D loss: 0.576449, acc.: 66.41%] [G loss: 0.692082]\n",
      "epoch:15 step:14498 [D loss: 0.520766, acc.: 74.22%] [G loss: 0.643569]\n",
      "epoch:15 step:14499 [D loss: 0.542849, acc.: 75.78%] [G loss: 0.632937]\n",
      "epoch:15 step:14500 [D loss: 0.546146, acc.: 70.31%] [G loss: 0.740824]\n",
      "epoch:15 step:14501 [D loss: 0.507325, acc.: 69.53%] [G loss: 0.693781]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:15 step:14502 [D loss: 0.534207, acc.: 70.31%] [G loss: 0.787303]\n",
      "epoch:15 step:14503 [D loss: 0.581950, acc.: 68.75%] [G loss: 0.827813]\n",
      "epoch:15 step:14504 [D loss: 0.497572, acc.: 76.56%] [G loss: 0.748057]\n",
      "epoch:15 step:14505 [D loss: 0.475258, acc.: 78.91%] [G loss: 0.745495]\n",
      "epoch:15 step:14506 [D loss: 0.497970, acc.: 78.12%] [G loss: 0.755832]\n",
      "epoch:15 step:14507 [D loss: 0.478504, acc.: 76.56%] [G loss: 0.707723]\n",
      "epoch:15 step:14508 [D loss: 0.560800, acc.: 69.53%] [G loss: 0.886038]\n",
      "epoch:15 step:14509 [D loss: 0.566295, acc.: 70.31%] [G loss: 0.570474]\n",
      "epoch:15 step:14510 [D loss: 0.550313, acc.: 71.09%] [G loss: 0.685262]\n",
      "epoch:15 step:14511 [D loss: 0.600822, acc.: 64.06%] [G loss: 0.605983]\n",
      "epoch:15 step:14512 [D loss: 0.459711, acc.: 77.34%] [G loss: 0.757044]\n",
      "epoch:15 step:14513 [D loss: 0.672511, acc.: 62.50%] [G loss: 0.532557]\n",
      "epoch:15 step:14514 [D loss: 0.576212, acc.: 67.97%] [G loss: 0.729265]\n",
      "epoch:15 step:14515 [D loss: 0.491275, acc.: 75.78%] [G loss: 0.645834]\n",
      "epoch:15 step:14516 [D loss: 0.552955, acc.: 68.75%] [G loss: 0.828066]\n",
      "epoch:15 step:14517 [D loss: 0.558849, acc.: 65.62%] [G loss: 0.562571]\n",
      "epoch:15 step:14518 [D loss: 0.551430, acc.: 70.31%] [G loss: 0.604488]\n",
      "epoch:15 step:14519 [D loss: 0.502467, acc.: 75.00%] [G loss: 0.588462]\n",
      "epoch:15 step:14520 [D loss: 0.607937, acc.: 64.06%] [G loss: 0.575268]\n",
      "epoch:15 step:14521 [D loss: 0.521284, acc.: 71.09%] [G loss: 0.596031]\n",
      "epoch:15 step:14522 [D loss: 0.477624, acc.: 82.03%] [G loss: 0.716960]\n",
      "epoch:15 step:14523 [D loss: 0.548551, acc.: 67.97%] [G loss: 0.767329]\n",
      "epoch:15 step:14524 [D loss: 0.559315, acc.: 71.09%] [G loss: 0.763786]\n",
      "epoch:15 step:14525 [D loss: 0.568873, acc.: 68.75%] [G loss: 0.696060]\n",
      "epoch:15 step:14526 [D loss: 0.447858, acc.: 81.25%] [G loss: 0.827971]\n",
      "epoch:15 step:14527 [D loss: 0.443753, acc.: 82.03%] [G loss: 0.845757]\n",
      "epoch:15 step:14528 [D loss: 0.708751, acc.: 58.59%] [G loss: 0.526892]\n",
      "epoch:15 step:14529 [D loss: 0.579592, acc.: 67.97%] [G loss: 0.448951]\n",
      "epoch:15 step:14530 [D loss: 0.462250, acc.: 78.12%] [G loss: 0.777384]\n",
      "epoch:15 step:14531 [D loss: 0.475930, acc.: 80.47%] [G loss: 0.764081]\n",
      "epoch:15 step:14532 [D loss: 0.666370, acc.: 64.06%] [G loss: 0.540100]\n",
      "epoch:15 step:14533 [D loss: 0.600040, acc.: 68.75%] [G loss: 0.568728]\n",
      "epoch:15 step:14534 [D loss: 0.504255, acc.: 77.34%] [G loss: 0.625375]\n",
      "epoch:15 step:14535 [D loss: 0.608367, acc.: 67.19%] [G loss: 0.559646]\n",
      "epoch:15 step:14536 [D loss: 0.500378, acc.: 77.34%] [G loss: 0.713674]\n",
      "epoch:15 step:14537 [D loss: 0.589150, acc.: 68.75%] [G loss: 0.534773]\n",
      "epoch:15 step:14538 [D loss: 0.537656, acc.: 69.53%] [G loss: 0.549309]\n",
      "epoch:15 step:14539 [D loss: 0.506046, acc.: 69.53%] [G loss: 0.674347]\n",
      "epoch:15 step:14540 [D loss: 0.475681, acc.: 78.91%] [G loss: 0.738944]\n",
      "epoch:15 step:14541 [D loss: 0.549428, acc.: 72.66%] [G loss: 0.621954]\n",
      "epoch:15 step:14542 [D loss: 0.542248, acc.: 68.75%] [G loss: 0.724069]\n",
      "epoch:15 step:14543 [D loss: 0.511304, acc.: 73.44%] [G loss: 0.668996]\n",
      "epoch:15 step:14544 [D loss: 0.548016, acc.: 69.53%] [G loss: 0.714244]\n",
      "epoch:15 step:14545 [D loss: 0.517487, acc.: 76.56%] [G loss: 0.578554]\n",
      "epoch:15 step:14546 [D loss: 0.605910, acc.: 60.94%] [G loss: 0.608621]\n",
      "epoch:15 step:14547 [D loss: 0.591321, acc.: 65.62%] [G loss: 0.469406]\n",
      "epoch:15 step:14548 [D loss: 0.554925, acc.: 69.53%] [G loss: 0.605244]\n",
      "epoch:15 step:14549 [D loss: 0.614731, acc.: 66.41%] [G loss: 0.390954]\n",
      "epoch:15 step:14550 [D loss: 0.534177, acc.: 75.00%] [G loss: 0.571278]\n",
      "epoch:15 step:14551 [D loss: 0.569752, acc.: 70.31%] [G loss: 0.685006]\n",
      "epoch:15 step:14552 [D loss: 0.526749, acc.: 73.44%] [G loss: 0.646445]\n",
      "epoch:15 step:14553 [D loss: 0.538208, acc.: 71.09%] [G loss: 0.660032]\n",
      "epoch:15 step:14554 [D loss: 0.497293, acc.: 75.78%] [G loss: 0.759253]\n",
      "epoch:15 step:14555 [D loss: 0.582444, acc.: 74.22%] [G loss: 0.564737]\n",
      "epoch:15 step:14556 [D loss: 0.622452, acc.: 63.28%] [G loss: 0.573864]\n",
      "epoch:15 step:14557 [D loss: 0.629807, acc.: 63.28%] [G loss: 0.483128]\n",
      "epoch:15 step:14558 [D loss: 0.483227, acc.: 75.78%] [G loss: 0.629632]\n",
      "epoch:15 step:14559 [D loss: 0.495109, acc.: 75.00%] [G loss: 0.824627]\n",
      "epoch:15 step:14560 [D loss: 0.547270, acc.: 71.88%] [G loss: 0.726725]\n",
      "epoch:15 step:14561 [D loss: 0.522801, acc.: 74.22%] [G loss: 0.654329]\n",
      "epoch:15 step:14562 [D loss: 0.579317, acc.: 70.31%] [G loss: 0.629738]\n",
      "epoch:15 step:14563 [D loss: 0.424029, acc.: 80.47%] [G loss: 0.837674]\n",
      "epoch:15 step:14564 [D loss: 0.527969, acc.: 72.66%] [G loss: 0.812337]\n",
      "epoch:15 step:14565 [D loss: 0.589499, acc.: 72.66%] [G loss: 0.730360]\n",
      "epoch:15 step:14566 [D loss: 0.670069, acc.: 57.03%] [G loss: 0.531374]\n",
      "epoch:15 step:14567 [D loss: 0.608331, acc.: 65.62%] [G loss: 0.331468]\n",
      "epoch:15 step:14568 [D loss: 0.500717, acc.: 75.78%] [G loss: 0.571684]\n",
      "epoch:15 step:14569 [D loss: 0.522096, acc.: 71.09%] [G loss: 0.609732]\n",
      "epoch:15 step:14570 [D loss: 0.519213, acc.: 75.00%] [G loss: 0.796892]\n",
      "epoch:15 step:14571 [D loss: 0.496375, acc.: 78.12%] [G loss: 0.737735]\n",
      "epoch:15 step:14572 [D loss: 0.545633, acc.: 74.22%] [G loss: 0.681366]\n",
      "epoch:15 step:14573 [D loss: 0.579100, acc.: 70.31%] [G loss: 0.742105]\n",
      "epoch:15 step:14574 [D loss: 0.520375, acc.: 75.78%] [G loss: 0.714971]\n",
      "epoch:15 step:14575 [D loss: 0.474592, acc.: 75.00%] [G loss: 0.777901]\n",
      "epoch:15 step:14576 [D loss: 0.555726, acc.: 71.88%] [G loss: 0.642273]\n",
      "epoch:15 step:14577 [D loss: 0.519690, acc.: 69.53%] [G loss: 0.733276]\n",
      "epoch:15 step:14578 [D loss: 0.496700, acc.: 70.31%] [G loss: 0.659361]\n",
      "epoch:15 step:14579 [D loss: 0.500728, acc.: 74.22%] [G loss: 0.702993]\n",
      "epoch:15 step:14580 [D loss: 0.592700, acc.: 69.53%] [G loss: 0.484369]\n",
      "epoch:15 step:14581 [D loss: 0.510442, acc.: 70.31%] [G loss: 0.571654]\n",
      "epoch:15 step:14582 [D loss: 0.579231, acc.: 68.75%] [G loss: 0.647000]\n",
      "epoch:15 step:14583 [D loss: 0.712708, acc.: 55.47%] [G loss: 0.438576]\n",
      "epoch:15 step:14584 [D loss: 0.589652, acc.: 66.41%] [G loss: 0.686989]\n",
      "epoch:15 step:14585 [D loss: 0.556785, acc.: 71.88%] [G loss: 0.586520]\n",
      "epoch:15 step:14586 [D loss: 0.582324, acc.: 66.41%] [G loss: 0.664526]\n",
      "epoch:15 step:14587 [D loss: 0.583270, acc.: 67.97%] [G loss: 0.528618]\n",
      "epoch:15 step:14588 [D loss: 0.560504, acc.: 67.97%] [G loss: 0.637354]\n",
      "epoch:15 step:14589 [D loss: 0.475180, acc.: 75.78%] [G loss: 0.649588]\n",
      "epoch:15 step:14590 [D loss: 0.613804, acc.: 67.19%] [G loss: 0.562650]\n",
      "epoch:15 step:14591 [D loss: 0.552949, acc.: 72.66%] [G loss: 0.633628]\n",
      "epoch:15 step:14592 [D loss: 0.554788, acc.: 70.31%] [G loss: 0.642195]\n",
      "epoch:15 step:14593 [D loss: 0.611879, acc.: 61.72%] [G loss: 0.558662]\n",
      "epoch:15 step:14594 [D loss: 0.539515, acc.: 73.44%] [G loss: 0.602203]\n",
      "epoch:15 step:14595 [D loss: 0.542592, acc.: 71.88%] [G loss: 0.653828]\n",
      "epoch:15 step:14596 [D loss: 0.560964, acc.: 67.19%] [G loss: 0.565574]\n",
      "epoch:15 step:14597 [D loss: 0.592912, acc.: 67.97%] [G loss: 0.584228]\n",
      "epoch:15 step:14598 [D loss: 0.588988, acc.: 67.97%] [G loss: 0.533197]\n",
      "epoch:15 step:14599 [D loss: 0.522779, acc.: 74.22%] [G loss: 0.589773]\n",
      "epoch:15 step:14600 [D loss: 0.503058, acc.: 78.12%] [G loss: 0.626140]\n",
      "##############\n",
      "[3.17021279 1.15767519 5.9712342  5.04169679 3.77909641 5.64512351\n",
      " 4.50827673 4.64757864 4.48630685 3.97018666]\n",
      "##########\n",
      "epoch:15 step:14601 [D loss: 0.489374, acc.: 71.88%] [G loss: 0.693424]\n",
      "epoch:15 step:14602 [D loss: 0.552694, acc.: 71.88%] [G loss: 0.593053]\n",
      "epoch:15 step:14603 [D loss: 0.439267, acc.: 79.69%] [G loss: 0.634002]\n",
      "epoch:15 step:14604 [D loss: 0.537658, acc.: 74.22%] [G loss: 0.662426]\n",
      "epoch:15 step:14605 [D loss: 0.563226, acc.: 71.88%] [G loss: 0.651277]\n",
      "epoch:15 step:14606 [D loss: 0.524010, acc.: 69.53%] [G loss: 0.607551]\n",
      "epoch:15 step:14607 [D loss: 0.461328, acc.: 78.12%] [G loss: 0.669868]\n",
      "epoch:15 step:14608 [D loss: 0.624773, acc.: 66.41%] [G loss: 0.631359]\n",
      "epoch:15 step:14609 [D loss: 0.462082, acc.: 78.12%] [G loss: 0.715793]\n",
      "epoch:15 step:14610 [D loss: 0.500152, acc.: 75.00%] [G loss: 0.537786]\n",
      "epoch:15 step:14611 [D loss: 0.530306, acc.: 72.66%] [G loss: 0.755798]\n",
      "epoch:15 step:14612 [D loss: 0.514109, acc.: 73.44%] [G loss: 0.565624]\n",
      "epoch:15 step:14613 [D loss: 0.457708, acc.: 75.78%] [G loss: 0.749216]\n",
      "epoch:15 step:14614 [D loss: 0.636662, acc.: 60.16%] [G loss: 0.502384]\n",
      "epoch:15 step:14615 [D loss: 0.561887, acc.: 70.31%] [G loss: 0.464325]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:15 step:14616 [D loss: 0.536203, acc.: 72.66%] [G loss: 0.484702]\n",
      "epoch:15 step:14617 [D loss: 0.562627, acc.: 70.31%] [G loss: 0.689552]\n",
      "epoch:15 step:14618 [D loss: 0.551044, acc.: 72.66%] [G loss: 0.533604]\n",
      "epoch:15 step:14619 [D loss: 0.479062, acc.: 75.78%] [G loss: 0.617445]\n",
      "epoch:15 step:14620 [D loss: 0.541542, acc.: 71.88%] [G loss: 0.774045]\n",
      "epoch:15 step:14621 [D loss: 0.654685, acc.: 60.16%] [G loss: 0.625727]\n",
      "epoch:15 step:14622 [D loss: 0.507797, acc.: 72.66%] [G loss: 0.645584]\n",
      "epoch:15 step:14623 [D loss: 0.510756, acc.: 71.88%] [G loss: 0.654341]\n",
      "epoch:15 step:14624 [D loss: 0.565319, acc.: 67.19%] [G loss: 0.685100]\n",
      "epoch:15 step:14625 [D loss: 0.554184, acc.: 71.09%] [G loss: 0.739165]\n",
      "epoch:15 step:14626 [D loss: 0.501834, acc.: 75.00%] [G loss: 0.636129]\n",
      "epoch:15 step:14627 [D loss: 0.568062, acc.: 64.84%] [G loss: 0.479624]\n",
      "epoch:15 step:14628 [D loss: 0.549750, acc.: 69.53%] [G loss: 0.682516]\n",
      "epoch:15 step:14629 [D loss: 0.577373, acc.: 74.22%] [G loss: 0.767975]\n",
      "epoch:15 step:14630 [D loss: 0.465373, acc.: 80.47%] [G loss: 0.743365]\n",
      "epoch:15 step:14631 [D loss: 0.616588, acc.: 63.28%] [G loss: 0.555301]\n",
      "epoch:15 step:14632 [D loss: 0.588136, acc.: 61.72%] [G loss: 0.612441]\n",
      "epoch:15 step:14633 [D loss: 0.579553, acc.: 64.84%] [G loss: 0.616007]\n",
      "epoch:15 step:14634 [D loss: 0.514747, acc.: 75.00%] [G loss: 0.613813]\n",
      "epoch:15 step:14635 [D loss: 0.578447, acc.: 67.19%] [G loss: 0.555180]\n",
      "epoch:15 step:14636 [D loss: 0.569743, acc.: 74.22%] [G loss: 0.758385]\n",
      "epoch:15 step:14637 [D loss: 0.468085, acc.: 80.47%] [G loss: 0.695895]\n",
      "epoch:15 step:14638 [D loss: 0.569837, acc.: 64.06%] [G loss: 0.653647]\n",
      "epoch:15 step:14639 [D loss: 0.601258, acc.: 68.75%] [G loss: 0.798523]\n",
      "epoch:15 step:14640 [D loss: 0.542081, acc.: 71.09%] [G loss: 0.555936]\n",
      "epoch:15 step:14641 [D loss: 0.583915, acc.: 68.75%] [G loss: 0.575362]\n",
      "epoch:15 step:14642 [D loss: 0.591389, acc.: 63.28%] [G loss: 0.694416]\n",
      "epoch:15 step:14643 [D loss: 0.571445, acc.: 67.97%] [G loss: 0.654563]\n",
      "epoch:15 step:14644 [D loss: 0.567938, acc.: 64.06%] [G loss: 0.666383]\n",
      "epoch:15 step:14645 [D loss: 0.608936, acc.: 61.72%] [G loss: 0.452617]\n",
      "epoch:15 step:14646 [D loss: 0.602448, acc.: 68.75%] [G loss: 0.478672]\n",
      "epoch:15 step:14647 [D loss: 0.530702, acc.: 73.44%] [G loss: 0.469921]\n",
      "epoch:15 step:14648 [D loss: 0.467015, acc.: 79.69%] [G loss: 0.538919]\n",
      "epoch:15 step:14649 [D loss: 0.559601, acc.: 71.88%] [G loss: 0.504686]\n",
      "epoch:15 step:14650 [D loss: 0.567442, acc.: 66.41%] [G loss: 0.481111]\n",
      "epoch:15 step:14651 [D loss: 0.552728, acc.: 71.09%] [G loss: 0.504886]\n",
      "epoch:15 step:14652 [D loss: 0.544203, acc.: 72.66%] [G loss: 0.574182]\n",
      "epoch:15 step:14653 [D loss: 0.532774, acc.: 71.88%] [G loss: 0.718810]\n",
      "epoch:15 step:14654 [D loss: 0.599916, acc.: 63.28%] [G loss: 0.743668]\n",
      "epoch:15 step:14655 [D loss: 0.645280, acc.: 61.72%] [G loss: 0.505727]\n",
      "epoch:15 step:14656 [D loss: 0.531082, acc.: 68.75%] [G loss: 0.617680]\n",
      "epoch:15 step:14657 [D loss: 0.498465, acc.: 76.56%] [G loss: 0.622638]\n",
      "epoch:15 step:14658 [D loss: 0.527427, acc.: 70.31%] [G loss: 0.571616]\n",
      "epoch:15 step:14659 [D loss: 0.542545, acc.: 74.22%] [G loss: 0.751980]\n",
      "epoch:15 step:14660 [D loss: 0.470850, acc.: 77.34%] [G loss: 0.634229]\n",
      "epoch:15 step:14661 [D loss: 0.617500, acc.: 64.06%] [G loss: 0.713522]\n",
      "epoch:15 step:14662 [D loss: 0.538179, acc.: 71.09%] [G loss: 0.514429]\n",
      "epoch:15 step:14663 [D loss: 0.532744, acc.: 70.31%] [G loss: 0.536746]\n",
      "epoch:15 step:14664 [D loss: 0.570311, acc.: 66.41%] [G loss: 0.399875]\n",
      "epoch:15 step:14665 [D loss: 0.573482, acc.: 69.53%] [G loss: 0.470485]\n",
      "epoch:15 step:14666 [D loss: 0.493051, acc.: 74.22%] [G loss: 0.470861]\n",
      "epoch:15 step:14667 [D loss: 0.542723, acc.: 72.66%] [G loss: 0.517932]\n",
      "epoch:15 step:14668 [D loss: 0.457891, acc.: 75.78%] [G loss: 0.497240]\n",
      "epoch:15 step:14669 [D loss: 0.580057, acc.: 66.41%] [G loss: 0.549317]\n",
      "epoch:15 step:14670 [D loss: 0.617131, acc.: 64.06%] [G loss: 0.637491]\n",
      "epoch:15 step:14671 [D loss: 0.565097, acc.: 68.75%] [G loss: 0.561244]\n",
      "epoch:15 step:14672 [D loss: 0.518142, acc.: 73.44%] [G loss: 0.604082]\n",
      "epoch:15 step:14673 [D loss: 0.586949, acc.: 64.84%] [G loss: 0.695103]\n",
      "epoch:15 step:14674 [D loss: 0.576586, acc.: 68.75%] [G loss: 0.674403]\n",
      "epoch:15 step:14675 [D loss: 0.506638, acc.: 74.22%] [G loss: 0.626643]\n",
      "epoch:15 step:14676 [D loss: 0.569399, acc.: 71.09%] [G loss: 0.551812]\n",
      "epoch:15 step:14677 [D loss: 0.585779, acc.: 70.31%] [G loss: 0.690309]\n",
      "epoch:15 step:14678 [D loss: 0.530009, acc.: 67.97%] [G loss: 0.662829]\n",
      "epoch:15 step:14679 [D loss: 0.463989, acc.: 78.12%] [G loss: 0.672849]\n",
      "epoch:15 step:14680 [D loss: 0.578350, acc.: 65.62%] [G loss: 0.587725]\n",
      "epoch:15 step:14681 [D loss: 0.548036, acc.: 69.53%] [G loss: 0.549785]\n",
      "epoch:15 step:14682 [D loss: 0.548164, acc.: 68.75%] [G loss: 0.493678]\n",
      "epoch:15 step:14683 [D loss: 0.602140, acc.: 65.62%] [G loss: 0.466935]\n",
      "epoch:15 step:14684 [D loss: 0.493571, acc.: 78.12%] [G loss: 0.631290]\n",
      "epoch:15 step:14685 [D loss: 0.515454, acc.: 76.56%] [G loss: 0.667581]\n",
      "epoch:15 step:14686 [D loss: 0.531875, acc.: 81.25%] [G loss: 0.779122]\n",
      "epoch:15 step:14687 [D loss: 0.529604, acc.: 71.09%] [G loss: 0.702109]\n",
      "epoch:15 step:14688 [D loss: 0.521259, acc.: 71.09%] [G loss: 0.644367]\n",
      "epoch:15 step:14689 [D loss: 0.543157, acc.: 73.44%] [G loss: 0.685681]\n",
      "epoch:15 step:14690 [D loss: 0.546404, acc.: 68.75%] [G loss: 0.607901]\n",
      "epoch:15 step:14691 [D loss: 0.605780, acc.: 70.31%] [G loss: 0.619044]\n",
      "epoch:15 step:14692 [D loss: 0.521187, acc.: 71.88%] [G loss: 0.504954]\n",
      "epoch:15 step:14693 [D loss: 0.536600, acc.: 68.75%] [G loss: 0.516235]\n",
      "epoch:15 step:14694 [D loss: 0.507260, acc.: 72.66%] [G loss: 0.642385]\n",
      "epoch:15 step:14695 [D loss: 0.545717, acc.: 69.53%] [G loss: 0.727214]\n",
      "epoch:15 step:14696 [D loss: 0.457848, acc.: 77.34%] [G loss: 0.727028]\n",
      "epoch:15 step:14697 [D loss: 0.534454, acc.: 68.75%] [G loss: 0.720938]\n",
      "epoch:15 step:14698 [D loss: 0.516298, acc.: 67.97%] [G loss: 0.731304]\n",
      "epoch:15 step:14699 [D loss: 0.584879, acc.: 66.41%] [G loss: 0.664297]\n",
      "epoch:15 step:14700 [D loss: 0.573181, acc.: 66.41%] [G loss: 0.583933]\n",
      "epoch:15 step:14701 [D loss: 0.553147, acc.: 73.44%] [G loss: 0.612758]\n",
      "epoch:15 step:14702 [D loss: 0.447265, acc.: 79.69%] [G loss: 0.701721]\n",
      "epoch:15 step:14703 [D loss: 0.410740, acc.: 82.81%] [G loss: 0.934128]\n",
      "epoch:15 step:14704 [D loss: 0.574049, acc.: 67.19%] [G loss: 0.872906]\n",
      "epoch:15 step:14705 [D loss: 0.535033, acc.: 74.22%] [G loss: 0.875829]\n",
      "epoch:15 step:14706 [D loss: 0.528130, acc.: 78.91%] [G loss: 0.658540]\n",
      "epoch:15 step:14707 [D loss: 0.676406, acc.: 57.81%] [G loss: 0.596466]\n",
      "epoch:15 step:14708 [D loss: 0.548518, acc.: 70.31%] [G loss: 0.742076]\n",
      "epoch:15 step:14709 [D loss: 0.513148, acc.: 70.31%] [G loss: 0.626110]\n",
      "epoch:15 step:14710 [D loss: 0.577542, acc.: 71.09%] [G loss: 0.606836]\n",
      "epoch:15 step:14711 [D loss: 0.557129, acc.: 73.44%] [G loss: 0.517442]\n",
      "epoch:15 step:14712 [D loss: 0.503670, acc.: 71.09%] [G loss: 0.634356]\n",
      "epoch:15 step:14713 [D loss: 0.612211, acc.: 65.62%] [G loss: 0.587991]\n",
      "epoch:15 step:14714 [D loss: 0.533554, acc.: 71.88%] [G loss: 0.599361]\n",
      "epoch:15 step:14715 [D loss: 0.585126, acc.: 67.97%] [G loss: 0.652447]\n",
      "epoch:15 step:14716 [D loss: 0.470626, acc.: 77.34%] [G loss: 0.653411]\n",
      "epoch:15 step:14717 [D loss: 0.566985, acc.: 65.62%] [G loss: 0.621486]\n",
      "epoch:15 step:14718 [D loss: 0.499929, acc.: 74.22%] [G loss: 0.595566]\n",
      "epoch:15 step:14719 [D loss: 0.591135, acc.: 67.97%] [G loss: 0.568284]\n",
      "epoch:15 step:14720 [D loss: 0.554850, acc.: 69.53%] [G loss: 0.728574]\n",
      "epoch:15 step:14721 [D loss: 0.570987, acc.: 69.53%] [G loss: 0.521752]\n",
      "epoch:15 step:14722 [D loss: 0.540005, acc.: 70.31%] [G loss: 0.723289]\n",
      "epoch:15 step:14723 [D loss: 0.581985, acc.: 71.88%] [G loss: 0.538625]\n",
      "epoch:15 step:14724 [D loss: 0.563058, acc.: 65.62%] [G loss: 0.525283]\n",
      "epoch:15 step:14725 [D loss: 0.530322, acc.: 71.09%] [G loss: 0.870448]\n",
      "epoch:15 step:14726 [D loss: 0.586644, acc.: 67.19%] [G loss: 0.622566]\n",
      "epoch:15 step:14727 [D loss: 0.606998, acc.: 67.97%] [G loss: 0.629309]\n",
      "epoch:15 step:14728 [D loss: 0.598493, acc.: 63.28%] [G loss: 0.632962]\n",
      "epoch:15 step:14729 [D loss: 0.555691, acc.: 67.97%] [G loss: 0.669767]\n",
      "epoch:15 step:14730 [D loss: 0.554176, acc.: 68.75%] [G loss: 0.573892]\n",
      "epoch:15 step:14731 [D loss: 0.535077, acc.: 72.66%] [G loss: 0.663947]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:15 step:14732 [D loss: 0.449695, acc.: 78.91%] [G loss: 0.618465]\n",
      "epoch:15 step:14733 [D loss: 0.568908, acc.: 70.31%] [G loss: 0.660318]\n",
      "epoch:15 step:14734 [D loss: 0.504710, acc.: 74.22%] [G loss: 0.620133]\n",
      "epoch:15 step:14735 [D loss: 0.605976, acc.: 67.97%] [G loss: 0.564967]\n",
      "epoch:15 step:14736 [D loss: 0.534417, acc.: 70.31%] [G loss: 0.585847]\n",
      "epoch:15 step:14737 [D loss: 0.543021, acc.: 71.09%] [G loss: 0.668093]\n",
      "epoch:15 step:14738 [D loss: 0.632673, acc.: 63.28%] [G loss: 0.524961]\n",
      "epoch:15 step:14739 [D loss: 0.590879, acc.: 67.19%] [G loss: 0.578938]\n",
      "epoch:15 step:14740 [D loss: 0.502577, acc.: 77.34%] [G loss: 0.612520]\n",
      "epoch:15 step:14741 [D loss: 0.640384, acc.: 64.06%] [G loss: 0.531118]\n",
      "epoch:15 step:14742 [D loss: 0.552004, acc.: 71.88%] [G loss: 0.568357]\n",
      "epoch:15 step:14743 [D loss: 0.597461, acc.: 66.41%] [G loss: 0.495087]\n",
      "epoch:15 step:14744 [D loss: 0.567678, acc.: 70.31%] [G loss: 0.624984]\n",
      "epoch:15 step:14745 [D loss: 0.479399, acc.: 77.34%] [G loss: 0.734889]\n",
      "epoch:15 step:14746 [D loss: 0.551772, acc.: 71.88%] [G loss: 0.729456]\n",
      "epoch:15 step:14747 [D loss: 0.548137, acc.: 71.88%] [G loss: 0.649712]\n",
      "epoch:15 step:14748 [D loss: 0.487477, acc.: 82.81%] [G loss: 0.833692]\n",
      "epoch:15 step:14749 [D loss: 0.484436, acc.: 77.34%] [G loss: 0.584394]\n",
      "epoch:15 step:14750 [D loss: 0.506809, acc.: 71.88%] [G loss: 0.644669]\n",
      "epoch:15 step:14751 [D loss: 0.595907, acc.: 63.28%] [G loss: 0.578596]\n",
      "epoch:15 step:14752 [D loss: 0.540188, acc.: 64.84%] [G loss: 0.554078]\n",
      "epoch:15 step:14753 [D loss: 0.613505, acc.: 59.38%] [G loss: 0.597928]\n",
      "epoch:15 step:14754 [D loss: 0.512915, acc.: 71.09%] [G loss: 0.588871]\n",
      "epoch:15 step:14755 [D loss: 0.577509, acc.: 67.19%] [G loss: 0.533211]\n",
      "epoch:15 step:14756 [D loss: 0.534792, acc.: 74.22%] [G loss: 0.659580]\n",
      "epoch:15 step:14757 [D loss: 0.572994, acc.: 66.41%] [G loss: 0.565181]\n",
      "epoch:15 step:14758 [D loss: 0.590754, acc.: 64.06%] [G loss: 0.459928]\n",
      "epoch:15 step:14759 [D loss: 0.640501, acc.: 61.72%] [G loss: 0.483433]\n",
      "epoch:15 step:14760 [D loss: 0.497116, acc.: 74.22%] [G loss: 0.649551]\n",
      "epoch:15 step:14761 [D loss: 0.529645, acc.: 75.78%] [G loss: 0.515316]\n",
      "epoch:15 step:14762 [D loss: 0.453523, acc.: 75.78%] [G loss: 0.690191]\n",
      "epoch:15 step:14763 [D loss: 0.583101, acc.: 72.66%] [G loss: 0.745718]\n",
      "epoch:15 step:14764 [D loss: 0.539679, acc.: 71.09%] [G loss: 0.799519]\n",
      "epoch:15 step:14765 [D loss: 0.599580, acc.: 64.84%] [G loss: 0.563224]\n",
      "epoch:15 step:14766 [D loss: 0.542289, acc.: 75.00%] [G loss: 0.626983]\n",
      "epoch:15 step:14767 [D loss: 0.483645, acc.: 77.34%] [G loss: 0.620578]\n",
      "epoch:15 step:14768 [D loss: 0.587148, acc.: 66.41%] [G loss: 0.669685]\n",
      "epoch:15 step:14769 [D loss: 0.498150, acc.: 76.56%] [G loss: 0.662785]\n",
      "epoch:15 step:14770 [D loss: 0.584208, acc.: 65.62%] [G loss: 0.506814]\n",
      "epoch:15 step:14771 [D loss: 0.599691, acc.: 64.06%] [G loss: 0.463058]\n",
      "epoch:15 step:14772 [D loss: 0.607888, acc.: 61.72%] [G loss: 0.577866]\n",
      "epoch:15 step:14773 [D loss: 0.600732, acc.: 64.84%] [G loss: 0.482551]\n",
      "epoch:15 step:14774 [D loss: 0.557883, acc.: 73.44%] [G loss: 0.558509]\n",
      "epoch:15 step:14775 [D loss: 0.577257, acc.: 66.41%] [G loss: 0.427801]\n",
      "epoch:15 step:14776 [D loss: 0.577034, acc.: 64.84%] [G loss: 0.568971]\n",
      "epoch:15 step:14777 [D loss: 0.534554, acc.: 75.00%] [G loss: 0.530059]\n",
      "epoch:15 step:14778 [D loss: 0.609825, acc.: 65.62%] [G loss: 0.532878]\n",
      "epoch:15 step:14779 [D loss: 0.543196, acc.: 74.22%] [G loss: 0.587881]\n",
      "epoch:15 step:14780 [D loss: 0.525727, acc.: 72.66%] [G loss: 0.622355]\n",
      "epoch:15 step:14781 [D loss: 0.507730, acc.: 73.44%] [G loss: 0.693851]\n",
      "epoch:15 step:14782 [D loss: 0.542874, acc.: 71.09%] [G loss: 0.593231]\n",
      "epoch:15 step:14783 [D loss: 0.562113, acc.: 71.88%] [G loss: 0.552829]\n",
      "epoch:15 step:14784 [D loss: 0.634432, acc.: 60.16%] [G loss: 0.445953]\n",
      "epoch:15 step:14785 [D loss: 0.517384, acc.: 71.88%] [G loss: 0.482963]\n",
      "epoch:15 step:14786 [D loss: 0.559989, acc.: 69.53%] [G loss: 0.511772]\n",
      "epoch:15 step:14787 [D loss: 0.509436, acc.: 69.53%] [G loss: 0.546324]\n",
      "epoch:15 step:14788 [D loss: 0.564024, acc.: 68.75%] [G loss: 0.682685]\n",
      "epoch:15 step:14789 [D loss: 0.547559, acc.: 69.53%] [G loss: 0.560835]\n",
      "epoch:15 step:14790 [D loss: 0.605432, acc.: 61.72%] [G loss: 0.504128]\n",
      "epoch:15 step:14791 [D loss: 0.547369, acc.: 71.88%] [G loss: 0.576257]\n",
      "epoch:15 step:14792 [D loss: 0.515818, acc.: 75.00%] [G loss: 0.640733]\n",
      "epoch:15 step:14793 [D loss: 0.530710, acc.: 70.31%] [G loss: 0.600976]\n",
      "epoch:15 step:14794 [D loss: 0.574709, acc.: 71.88%] [G loss: 0.624516]\n",
      "epoch:15 step:14795 [D loss: 0.674034, acc.: 57.81%] [G loss: 0.354091]\n",
      "epoch:15 step:14796 [D loss: 0.565964, acc.: 68.75%] [G loss: 0.519988]\n",
      "epoch:15 step:14797 [D loss: 0.519219, acc.: 68.75%] [G loss: 0.576924]\n",
      "epoch:15 step:14798 [D loss: 0.518685, acc.: 71.09%] [G loss: 0.680266]\n",
      "epoch:15 step:14799 [D loss: 0.551433, acc.: 72.66%] [G loss: 0.640875]\n",
      "epoch:15 step:14800 [D loss: 0.545097, acc.: 69.53%] [G loss: 0.574304]\n",
      "##############\n",
      "[3.22027666 1.13190668 6.2978458  4.8107177  3.89917987 5.81101672\n",
      " 4.66671073 4.8880451  4.50054988 4.22560973]\n",
      "##########\n",
      "epoch:15 step:14801 [D loss: 0.466180, acc.: 73.44%] [G loss: 0.700192]\n",
      "epoch:15 step:14802 [D loss: 0.424922, acc.: 82.03%] [G loss: 0.789095]\n",
      "epoch:15 step:14803 [D loss: 0.533958, acc.: 67.97%] [G loss: 0.772251]\n",
      "epoch:15 step:14804 [D loss: 0.522980, acc.: 75.78%] [G loss: 0.711106]\n",
      "epoch:15 step:14805 [D loss: 0.536122, acc.: 72.66%] [G loss: 0.759449]\n",
      "epoch:15 step:14806 [D loss: 0.529796, acc.: 73.44%] [G loss: 0.662382]\n",
      "epoch:15 step:14807 [D loss: 0.585968, acc.: 63.28%] [G loss: 0.648617]\n",
      "epoch:15 step:14808 [D loss: 0.568237, acc.: 66.41%] [G loss: 0.594156]\n",
      "epoch:15 step:14809 [D loss: 0.500721, acc.: 71.88%] [G loss: 0.554198]\n",
      "epoch:15 step:14810 [D loss: 0.572028, acc.: 68.75%] [G loss: 0.663659]\n",
      "epoch:15 step:14811 [D loss: 0.549761, acc.: 71.88%] [G loss: 0.734229]\n",
      "epoch:15 step:14812 [D loss: 0.527565, acc.: 70.31%] [G loss: 0.574925]\n",
      "epoch:15 step:14813 [D loss: 0.497268, acc.: 73.44%] [G loss: 0.636314]\n",
      "epoch:15 step:14814 [D loss: 0.589288, acc.: 70.31%] [G loss: 0.562539]\n",
      "epoch:15 step:14815 [D loss: 0.503492, acc.: 72.66%] [G loss: 0.672481]\n",
      "epoch:15 step:14816 [D loss: 0.571241, acc.: 71.09%] [G loss: 0.557023]\n",
      "epoch:15 step:14817 [D loss: 0.582630, acc.: 64.06%] [G loss: 0.521871]\n",
      "epoch:15 step:14818 [D loss: 0.549264, acc.: 75.00%] [G loss: 0.591616]\n",
      "epoch:15 step:14819 [D loss: 0.548153, acc.: 73.44%] [G loss: 0.528843]\n",
      "epoch:15 step:14820 [D loss: 0.605789, acc.: 64.84%] [G loss: 0.625132]\n",
      "epoch:15 step:14821 [D loss: 0.639646, acc.: 58.59%] [G loss: 0.506483]\n",
      "epoch:15 step:14822 [D loss: 0.559638, acc.: 70.31%] [G loss: 0.647132]\n",
      "epoch:15 step:14823 [D loss: 0.547760, acc.: 67.19%] [G loss: 0.654663]\n",
      "epoch:15 step:14824 [D loss: 0.541764, acc.: 70.31%] [G loss: 0.800430]\n",
      "epoch:15 step:14825 [D loss: 0.536652, acc.: 73.44%] [G loss: 0.652700]\n",
      "epoch:15 step:14826 [D loss: 0.602594, acc.: 68.75%] [G loss: 0.735919]\n",
      "epoch:15 step:14827 [D loss: 0.563880, acc.: 70.31%] [G loss: 0.484941]\n",
      "epoch:15 step:14828 [D loss: 0.560739, acc.: 72.66%] [G loss: 0.584881]\n",
      "epoch:15 step:14829 [D loss: 0.545558, acc.: 67.19%] [G loss: 0.521585]\n",
      "epoch:15 step:14830 [D loss: 0.532426, acc.: 72.66%] [G loss: 0.625975]\n",
      "epoch:15 step:14831 [D loss: 0.589393, acc.: 65.62%] [G loss: 0.618754]\n",
      "epoch:15 step:14832 [D loss: 0.529221, acc.: 72.66%] [G loss: 0.656868]\n",
      "epoch:15 step:14833 [D loss: 0.554918, acc.: 75.00%] [G loss: 0.660738]\n",
      "epoch:15 step:14834 [D loss: 0.523309, acc.: 73.44%] [G loss: 0.708028]\n",
      "epoch:15 step:14835 [D loss: 0.559539, acc.: 63.28%] [G loss: 0.707727]\n",
      "epoch:15 step:14836 [D loss: 0.526624, acc.: 70.31%] [G loss: 0.758426]\n",
      "epoch:15 step:14837 [D loss: 0.546972, acc.: 72.66%] [G loss: 0.719189]\n",
      "epoch:15 step:14838 [D loss: 0.551120, acc.: 68.75%] [G loss: 0.665828]\n",
      "epoch:15 step:14839 [D loss: 0.639332, acc.: 63.28%] [G loss: 0.436171]\n",
      "epoch:15 step:14840 [D loss: 0.526891, acc.: 71.09%] [G loss: 0.602659]\n",
      "epoch:15 step:14841 [D loss: 0.571827, acc.: 65.62%] [G loss: 0.530842]\n",
      "epoch:15 step:14842 [D loss: 0.561110, acc.: 71.09%] [G loss: 0.498106]\n",
      "epoch:15 step:14843 [D loss: 0.655219, acc.: 64.06%] [G loss: 0.614639]\n",
      "epoch:15 step:14844 [D loss: 0.495314, acc.: 75.00%] [G loss: 0.638322]\n",
      "epoch:15 step:14845 [D loss: 0.510949, acc.: 77.34%] [G loss: 0.608985]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:15 step:14846 [D loss: 0.536527, acc.: 71.88%] [G loss: 0.602088]\n",
      "epoch:15 step:14847 [D loss: 0.479653, acc.: 75.78%] [G loss: 0.730243]\n",
      "epoch:15 step:14848 [D loss: 0.624415, acc.: 65.62%] [G loss: 0.642511]\n",
      "epoch:15 step:14849 [D loss: 0.662461, acc.: 64.06%] [G loss: 0.587851]\n",
      "epoch:15 step:14850 [D loss: 0.516970, acc.: 67.97%] [G loss: 0.741729]\n",
      "epoch:15 step:14851 [D loss: 0.508527, acc.: 74.22%] [G loss: 0.704248]\n",
      "epoch:15 step:14852 [D loss: 0.566494, acc.: 64.06%] [G loss: 0.682312]\n",
      "epoch:15 step:14853 [D loss: 0.518118, acc.: 70.31%] [G loss: 0.683461]\n",
      "epoch:15 step:14854 [D loss: 0.568406, acc.: 71.09%] [G loss: 0.606824]\n",
      "epoch:15 step:14855 [D loss: 0.545285, acc.: 66.41%] [G loss: 0.625641]\n",
      "epoch:15 step:14856 [D loss: 0.516283, acc.: 74.22%] [G loss: 0.699492]\n",
      "epoch:15 step:14857 [D loss: 0.502551, acc.: 70.31%] [G loss: 0.713290]\n",
      "epoch:15 step:14858 [D loss: 0.500420, acc.: 73.44%] [G loss: 0.618704]\n",
      "epoch:15 step:14859 [D loss: 0.535523, acc.: 67.19%] [G loss: 0.593267]\n",
      "epoch:15 step:14860 [D loss: 0.535823, acc.: 69.53%] [G loss: 0.595448]\n",
      "epoch:15 step:14861 [D loss: 0.611110, acc.: 59.38%] [G loss: 0.576573]\n",
      "epoch:15 step:14862 [D loss: 0.581767, acc.: 64.06%] [G loss: 0.509027]\n",
      "epoch:15 step:14863 [D loss: 0.560858, acc.: 67.97%] [G loss: 0.543098]\n",
      "epoch:15 step:14864 [D loss: 0.535159, acc.: 69.53%] [G loss: 0.609119]\n",
      "epoch:15 step:14865 [D loss: 0.520726, acc.: 75.00%] [G loss: 0.613101]\n",
      "epoch:15 step:14866 [D loss: 0.527401, acc.: 72.66%] [G loss: 0.588463]\n",
      "epoch:15 step:14867 [D loss: 0.616023, acc.: 65.62%] [G loss: 0.517149]\n",
      "epoch:15 step:14868 [D loss: 0.641778, acc.: 61.72%] [G loss: 0.427025]\n",
      "epoch:15 step:14869 [D loss: 0.554995, acc.: 68.75%] [G loss: 0.412712]\n",
      "epoch:15 step:14870 [D loss: 0.526641, acc.: 75.00%] [G loss: 0.686955]\n",
      "epoch:15 step:14871 [D loss: 0.508229, acc.: 74.22%] [G loss: 0.807361]\n",
      "epoch:15 step:14872 [D loss: 0.601063, acc.: 63.28%] [G loss: 0.523939]\n",
      "epoch:15 step:14873 [D loss: 0.554354, acc.: 68.75%] [G loss: 0.694334]\n",
      "epoch:15 step:14874 [D loss: 0.542458, acc.: 67.97%] [G loss: 0.483190]\n",
      "epoch:15 step:14875 [D loss: 0.633808, acc.: 66.41%] [G loss: 0.533744]\n",
      "epoch:15 step:14876 [D loss: 0.545226, acc.: 68.75%] [G loss: 0.660139]\n",
      "epoch:15 step:14877 [D loss: 0.507577, acc.: 75.78%] [G loss: 0.508243]\n",
      "epoch:15 step:14878 [D loss: 0.444295, acc.: 82.03%] [G loss: 0.594966]\n",
      "epoch:15 step:14879 [D loss: 0.586216, acc.: 67.19%] [G loss: 0.649585]\n",
      "epoch:15 step:14880 [D loss: 0.534051, acc.: 71.09%] [G loss: 0.606437]\n",
      "epoch:15 step:14881 [D loss: 0.525117, acc.: 69.53%] [G loss: 0.638551]\n",
      "epoch:15 step:14882 [D loss: 0.511894, acc.: 72.66%] [G loss: 0.540682]\n",
      "epoch:15 step:14883 [D loss: 0.608518, acc.: 64.84%] [G loss: 0.537616]\n",
      "epoch:15 step:14884 [D loss: 0.523967, acc.: 71.09%] [G loss: 0.661617]\n",
      "epoch:15 step:14885 [D loss: 0.566190, acc.: 67.97%] [G loss: 0.720565]\n",
      "epoch:15 step:14886 [D loss: 0.547520, acc.: 71.88%] [G loss: 0.519517]\n",
      "epoch:15 step:14887 [D loss: 0.553520, acc.: 75.00%] [G loss: 0.545378]\n",
      "epoch:15 step:14888 [D loss: 0.512133, acc.: 72.66%] [G loss: 0.589218]\n",
      "epoch:15 step:14889 [D loss: 0.528070, acc.: 68.75%] [G loss: 0.618368]\n",
      "epoch:15 step:14890 [D loss: 0.586204, acc.: 69.53%] [G loss: 0.474005]\n",
      "epoch:15 step:14891 [D loss: 0.537891, acc.: 72.66%] [G loss: 0.478285]\n",
      "epoch:15 step:14892 [D loss: 0.571107, acc.: 68.75%] [G loss: 0.487332]\n",
      "epoch:15 step:14893 [D loss: 0.581205, acc.: 66.41%] [G loss: 0.477455]\n",
      "epoch:15 step:14894 [D loss: 0.597855, acc.: 64.06%] [G loss: 0.506730]\n",
      "epoch:15 step:14895 [D loss: 0.567103, acc.: 71.88%] [G loss: 0.501621]\n",
      "epoch:15 step:14896 [D loss: 0.540661, acc.: 67.97%] [G loss: 0.480374]\n",
      "epoch:15 step:14897 [D loss: 0.548057, acc.: 67.19%] [G loss: 0.483873]\n",
      "epoch:15 step:14898 [D loss: 0.562914, acc.: 71.09%] [G loss: 0.597753]\n",
      "epoch:15 step:14899 [D loss: 0.607628, acc.: 61.72%] [G loss: 0.570850]\n",
      "epoch:15 step:14900 [D loss: 0.570615, acc.: 70.31%] [G loss: 0.526057]\n",
      "epoch:15 step:14901 [D loss: 0.585199, acc.: 64.84%] [G loss: 0.579661]\n",
      "epoch:15 step:14902 [D loss: 0.572192, acc.: 66.41%] [G loss: 0.514394]\n",
      "epoch:15 step:14903 [D loss: 0.609780, acc.: 63.28%] [G loss: 0.446443]\n",
      "epoch:15 step:14904 [D loss: 0.523073, acc.: 71.88%] [G loss: 0.640070]\n",
      "epoch:15 step:14905 [D loss: 0.581756, acc.: 66.41%] [G loss: 0.441637]\n",
      "epoch:15 step:14906 [D loss: 0.563016, acc.: 68.75%] [G loss: 0.577739]\n",
      "epoch:15 step:14907 [D loss: 0.557465, acc.: 68.75%] [G loss: 0.615560]\n",
      "epoch:15 step:14908 [D loss: 0.548923, acc.: 71.09%] [G loss: 0.586101]\n",
      "epoch:15 step:14909 [D loss: 0.533884, acc.: 71.88%] [G loss: 0.609445]\n",
      "epoch:15 step:14910 [D loss: 0.548217, acc.: 71.09%] [G loss: 0.592930]\n",
      "epoch:15 step:14911 [D loss: 0.616014, acc.: 62.50%] [G loss: 0.491413]\n",
      "epoch:15 step:14912 [D loss: 0.486536, acc.: 76.56%] [G loss: 0.643573]\n",
      "epoch:15 step:14913 [D loss: 0.594580, acc.: 66.41%] [G loss: 0.656428]\n",
      "epoch:15 step:14914 [D loss: 0.539278, acc.: 70.31%] [G loss: 0.690340]\n",
      "epoch:15 step:14915 [D loss: 0.433995, acc.: 82.03%] [G loss: 0.734660]\n",
      "epoch:15 step:14916 [D loss: 0.675689, acc.: 62.50%] [G loss: 0.600201]\n",
      "epoch:15 step:14917 [D loss: 0.549684, acc.: 72.66%] [G loss: 0.515172]\n",
      "epoch:15 step:14918 [D loss: 0.550406, acc.: 69.53%] [G loss: 0.487745]\n",
      "epoch:15 step:14919 [D loss: 0.498385, acc.: 71.09%] [G loss: 0.555437]\n",
      "epoch:15 step:14920 [D loss: 0.589643, acc.: 64.84%] [G loss: 0.615076]\n",
      "epoch:15 step:14921 [D loss: 0.498194, acc.: 71.09%] [G loss: 0.584733]\n",
      "epoch:15 step:14922 [D loss: 0.624142, acc.: 64.06%] [G loss: 0.459142]\n",
      "epoch:15 step:14923 [D loss: 0.554468, acc.: 71.09%] [G loss: 0.629067]\n",
      "epoch:15 step:14924 [D loss: 0.538421, acc.: 71.88%] [G loss: 0.584012]\n",
      "epoch:15 step:14925 [D loss: 0.500931, acc.: 71.09%] [G loss: 0.545069]\n",
      "epoch:15 step:14926 [D loss: 0.490984, acc.: 74.22%] [G loss: 0.692925]\n",
      "epoch:15 step:14927 [D loss: 0.535888, acc.: 67.19%] [G loss: 0.781136]\n",
      "epoch:15 step:14928 [D loss: 0.598999, acc.: 65.62%] [G loss: 0.657870]\n",
      "epoch:15 step:14929 [D loss: 0.610725, acc.: 64.06%] [G loss: 0.532274]\n",
      "epoch:15 step:14930 [D loss: 0.481266, acc.: 78.91%] [G loss: 0.551772]\n",
      "epoch:15 step:14931 [D loss: 0.614252, acc.: 66.41%] [G loss: 0.541262]\n",
      "epoch:15 step:14932 [D loss: 0.575030, acc.: 69.53%] [G loss: 0.683049]\n",
      "epoch:15 step:14933 [D loss: 0.541248, acc.: 68.75%] [G loss: 0.570268]\n",
      "epoch:15 step:14934 [D loss: 0.623340, acc.: 64.06%] [G loss: 0.503747]\n",
      "epoch:15 step:14935 [D loss: 0.626374, acc.: 65.62%] [G loss: 0.444380]\n",
      "epoch:15 step:14936 [D loss: 0.569612, acc.: 65.62%] [G loss: 0.430992]\n",
      "epoch:15 step:14937 [D loss: 0.576409, acc.: 70.31%] [G loss: 0.523249]\n",
      "epoch:15 step:14938 [D loss: 0.581827, acc.: 70.31%] [G loss: 0.459586]\n",
      "epoch:15 step:14939 [D loss: 0.499799, acc.: 72.66%] [G loss: 0.601399]\n",
      "epoch:15 step:14940 [D loss: 0.529839, acc.: 71.88%] [G loss: 0.685135]\n",
      "epoch:15 step:14941 [D loss: 0.525183, acc.: 71.88%] [G loss: 0.738728]\n",
      "epoch:15 step:14942 [D loss: 0.538170, acc.: 72.66%] [G loss: 0.624886]\n",
      "epoch:15 step:14943 [D loss: 0.555373, acc.: 67.19%] [G loss: 0.722824]\n",
      "epoch:15 step:14944 [D loss: 0.607635, acc.: 61.72%] [G loss: 0.627844]\n",
      "epoch:15 step:14945 [D loss: 0.533036, acc.: 67.97%] [G loss: 0.730951]\n",
      "epoch:15 step:14946 [D loss: 0.655678, acc.: 57.03%] [G loss: 0.581897]\n",
      "epoch:15 step:14947 [D loss: 0.649832, acc.: 61.72%] [G loss: 0.544742]\n",
      "epoch:15 step:14948 [D loss: 0.509602, acc.: 75.00%] [G loss: 0.560856]\n",
      "epoch:15 step:14949 [D loss: 0.461749, acc.: 78.12%] [G loss: 0.757603]\n",
      "epoch:15 step:14950 [D loss: 0.552992, acc.: 68.75%] [G loss: 0.730826]\n",
      "epoch:15 step:14951 [D loss: 0.512799, acc.: 75.78%] [G loss: 0.758189]\n",
      "epoch:15 step:14952 [D loss: 0.528209, acc.: 70.31%] [G loss: 0.679283]\n",
      "epoch:15 step:14953 [D loss: 0.511409, acc.: 75.78%] [G loss: 0.671320]\n",
      "epoch:15 step:14954 [D loss: 0.510264, acc.: 75.78%] [G loss: 0.724569]\n",
      "epoch:15 step:14955 [D loss: 0.520829, acc.: 76.56%] [G loss: 0.746781]\n",
      "epoch:15 step:14956 [D loss: 0.531031, acc.: 72.66%] [G loss: 0.688834]\n",
      "epoch:15 step:14957 [D loss: 0.602368, acc.: 67.19%] [G loss: 0.659178]\n",
      "epoch:15 step:14958 [D loss: 0.552814, acc.: 71.09%] [G loss: 0.453322]\n",
      "epoch:15 step:14959 [D loss: 0.521767, acc.: 71.88%] [G loss: 0.644812]\n",
      "epoch:15 step:14960 [D loss: 0.581940, acc.: 64.84%] [G loss: 0.645513]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:15 step:14961 [D loss: 0.481238, acc.: 74.22%] [G loss: 0.832373]\n",
      "epoch:15 step:14962 [D loss: 0.597972, acc.: 64.06%] [G loss: 0.616421]\n",
      "epoch:15 step:14963 [D loss: 0.610838, acc.: 60.94%] [G loss: 0.617922]\n",
      "epoch:15 step:14964 [D loss: 0.468318, acc.: 77.34%] [G loss: 0.728379]\n",
      "epoch:15 step:14965 [D loss: 0.553653, acc.: 69.53%] [G loss: 0.670321]\n",
      "epoch:15 step:14966 [D loss: 0.443973, acc.: 79.69%] [G loss: 0.729704]\n",
      "epoch:15 step:14967 [D loss: 0.506296, acc.: 76.56%] [G loss: 0.821163]\n",
      "epoch:15 step:14968 [D loss: 0.552921, acc.: 71.88%] [G loss: 0.778055]\n",
      "epoch:15 step:14969 [D loss: 0.514812, acc.: 73.44%] [G loss: 0.659362]\n",
      "epoch:15 step:14970 [D loss: 0.614034, acc.: 64.84%] [G loss: 0.706118]\n",
      "epoch:15 step:14971 [D loss: 0.510453, acc.: 72.66%] [G loss: 0.677306]\n",
      "epoch:15 step:14972 [D loss: 0.643966, acc.: 60.16%] [G loss: 0.693780]\n",
      "epoch:15 step:14973 [D loss: 0.538159, acc.: 70.31%] [G loss: 0.719159]\n",
      "epoch:15 step:14974 [D loss: 0.443102, acc.: 81.25%] [G loss: 0.826164]\n",
      "epoch:15 step:14975 [D loss: 0.741513, acc.: 55.47%] [G loss: 0.450764]\n",
      "epoch:15 step:14976 [D loss: 0.467482, acc.: 75.78%] [G loss: 0.725767]\n",
      "epoch:15 step:14977 [D loss: 0.569301, acc.: 67.19%] [G loss: 0.706759]\n",
      "epoch:15 step:14978 [D loss: 0.475926, acc.: 73.44%] [G loss: 0.582719]\n",
      "epoch:15 step:14979 [D loss: 0.471680, acc.: 75.78%] [G loss: 0.726959]\n",
      "epoch:15 step:14980 [D loss: 0.463916, acc.: 77.34%] [G loss: 0.932950]\n",
      "epoch:15 step:14981 [D loss: 0.422061, acc.: 78.12%] [G loss: 1.084175]\n",
      "epoch:15 step:14982 [D loss: 0.510876, acc.: 71.09%] [G loss: 0.997762]\n",
      "epoch:15 step:14983 [D loss: 0.737522, acc.: 63.28%] [G loss: 0.846145]\n",
      "epoch:15 step:14984 [D loss: 0.541329, acc.: 73.44%] [G loss: 1.216729]\n",
      "epoch:15 step:14985 [D loss: 0.422451, acc.: 78.91%] [G loss: 1.079680]\n",
      "epoch:15 step:14986 [D loss: 0.550732, acc.: 75.78%] [G loss: 1.029859]\n",
      "epoch:15 step:14987 [D loss: 0.574162, acc.: 67.97%] [G loss: 0.706816]\n",
      "epoch:15 step:14988 [D loss: 0.520712, acc.: 72.66%] [G loss: 0.787536]\n",
      "epoch:15 step:14989 [D loss: 0.594120, acc.: 69.53%] [G loss: 0.803210]\n",
      "epoch:15 step:14990 [D loss: 0.456668, acc.: 78.91%] [G loss: 0.729638]\n",
      "epoch:15 step:14991 [D loss: 0.387991, acc.: 83.59%] [G loss: 1.158483]\n",
      "epoch:15 step:14992 [D loss: 0.465516, acc.: 78.91%] [G loss: 1.473790]\n",
      "epoch:16 step:14993 [D loss: 0.621430, acc.: 67.97%] [G loss: 0.888085]\n",
      "epoch:16 step:14994 [D loss: 0.507708, acc.: 74.22%] [G loss: 1.015975]\n",
      "epoch:16 step:14995 [D loss: 0.612327, acc.: 68.75%] [G loss: 0.859048]\n",
      "epoch:16 step:14996 [D loss: 0.569131, acc.: 68.75%] [G loss: 0.705200]\n",
      "epoch:16 step:14997 [D loss: 0.575553, acc.: 72.66%] [G loss: 0.792302]\n",
      "epoch:16 step:14998 [D loss: 0.579768, acc.: 67.19%] [G loss: 0.876238]\n",
      "epoch:16 step:14999 [D loss: 0.452619, acc.: 79.69%] [G loss: 0.816872]\n",
      "epoch:16 step:15000 [D loss: 0.532098, acc.: 74.22%] [G loss: 0.730286]\n",
      "##############\n",
      "[2.81599659 0.95636224 6.20142848 4.58931513 3.61999312 5.79321725\n",
      " 4.42677966 4.78930392 4.48503341 4.20984155]\n",
      "##########\n",
      "epoch:16 step:15001 [D loss: 0.489862, acc.: 77.34%] [G loss: 0.706635]\n",
      "epoch:16 step:15002 [D loss: 0.520853, acc.: 75.00%] [G loss: 0.549208]\n",
      "epoch:16 step:15003 [D loss: 0.497252, acc.: 75.00%] [G loss: 0.740793]\n",
      "epoch:16 step:15004 [D loss: 0.585339, acc.: 67.19%] [G loss: 0.668992]\n",
      "epoch:16 step:15005 [D loss: 0.567501, acc.: 69.53%] [G loss: 0.663272]\n",
      "epoch:16 step:15006 [D loss: 0.536487, acc.: 71.88%] [G loss: 0.756978]\n",
      "epoch:16 step:15007 [D loss: 0.584217, acc.: 68.75%] [G loss: 0.535905]\n",
      "epoch:16 step:15008 [D loss: 0.486265, acc.: 77.34%] [G loss: 0.771365]\n",
      "epoch:16 step:15009 [D loss: 0.546762, acc.: 72.66%] [G loss: 0.619414]\n",
      "epoch:16 step:15010 [D loss: 0.603136, acc.: 66.41%] [G loss: 0.706589]\n",
      "epoch:16 step:15011 [D loss: 0.550218, acc.: 71.09%] [G loss: 0.555570]\n",
      "epoch:16 step:15012 [D loss: 0.636718, acc.: 66.41%] [G loss: 0.668784]\n",
      "epoch:16 step:15013 [D loss: 0.582430, acc.: 73.44%] [G loss: 0.671746]\n",
      "epoch:16 step:15014 [D loss: 0.464869, acc.: 82.03%] [G loss: 0.694773]\n",
      "epoch:16 step:15015 [D loss: 0.513746, acc.: 72.66%] [G loss: 0.591551]\n",
      "epoch:16 step:15016 [D loss: 0.491000, acc.: 73.44%] [G loss: 0.725006]\n",
      "epoch:16 step:15017 [D loss: 0.484821, acc.: 74.22%] [G loss: 0.585332]\n",
      "epoch:16 step:15018 [D loss: 0.642494, acc.: 60.94%] [G loss: 0.618029]\n",
      "epoch:16 step:15019 [D loss: 0.461881, acc.: 76.56%] [G loss: 0.581109]\n",
      "epoch:16 step:15020 [D loss: 0.554472, acc.: 69.53%] [G loss: 0.665113]\n",
      "epoch:16 step:15021 [D loss: 0.505720, acc.: 73.44%] [G loss: 0.700778]\n",
      "epoch:16 step:15022 [D loss: 0.540257, acc.: 71.88%] [G loss: 0.584979]\n",
      "epoch:16 step:15023 [D loss: 0.617104, acc.: 62.50%] [G loss: 0.567124]\n",
      "epoch:16 step:15024 [D loss: 0.530331, acc.: 70.31%] [G loss: 0.565342]\n",
      "epoch:16 step:15025 [D loss: 0.534082, acc.: 67.97%] [G loss: 0.688106]\n",
      "epoch:16 step:15026 [D loss: 0.526891, acc.: 69.53%] [G loss: 0.699412]\n",
      "epoch:16 step:15027 [D loss: 0.568135, acc.: 67.97%] [G loss: 0.595157]\n",
      "epoch:16 step:15028 [D loss: 0.584030, acc.: 69.53%] [G loss: 0.636816]\n",
      "epoch:16 step:15029 [D loss: 0.495684, acc.: 76.56%] [G loss: 0.629353]\n",
      "epoch:16 step:15030 [D loss: 0.557087, acc.: 70.31%] [G loss: 0.725026]\n",
      "epoch:16 step:15031 [D loss: 0.548517, acc.: 75.00%] [G loss: 0.670158]\n",
      "epoch:16 step:15032 [D loss: 0.420396, acc.: 84.38%] [G loss: 0.764361]\n",
      "epoch:16 step:15033 [D loss: 0.538252, acc.: 67.97%] [G loss: 0.757488]\n",
      "epoch:16 step:15034 [D loss: 0.539215, acc.: 71.88%] [G loss: 0.665593]\n",
      "epoch:16 step:15035 [D loss: 0.521898, acc.: 73.44%] [G loss: 0.652095]\n",
      "epoch:16 step:15036 [D loss: 0.520098, acc.: 73.44%] [G loss: 0.783482]\n",
      "epoch:16 step:15037 [D loss: 0.517803, acc.: 71.88%] [G loss: 0.720354]\n",
      "epoch:16 step:15038 [D loss: 0.460376, acc.: 78.12%] [G loss: 0.726519]\n",
      "epoch:16 step:15039 [D loss: 0.535344, acc.: 73.44%] [G loss: 0.634468]\n",
      "epoch:16 step:15040 [D loss: 0.550046, acc.: 75.78%] [G loss: 0.593145]\n",
      "epoch:16 step:15041 [D loss: 0.525100, acc.: 71.88%] [G loss: 0.679908]\n",
      "epoch:16 step:15042 [D loss: 0.578678, acc.: 69.53%] [G loss: 0.650946]\n",
      "epoch:16 step:15043 [D loss: 0.687235, acc.: 62.50%] [G loss: 0.509531]\n",
      "epoch:16 step:15044 [D loss: 0.592124, acc.: 65.62%] [G loss: 0.519198]\n",
      "epoch:16 step:15045 [D loss: 0.542160, acc.: 71.09%] [G loss: 0.611005]\n",
      "epoch:16 step:15046 [D loss: 0.491267, acc.: 74.22%] [G loss: 0.811885]\n",
      "epoch:16 step:15047 [D loss: 0.502177, acc.: 74.22%] [G loss: 0.964013]\n",
      "epoch:16 step:15048 [D loss: 0.522685, acc.: 72.66%] [G loss: 0.695881]\n",
      "epoch:16 step:15049 [D loss: 0.533874, acc.: 72.66%] [G loss: 0.611955]\n",
      "epoch:16 step:15050 [D loss: 0.580682, acc.: 66.41%] [G loss: 0.635728]\n",
      "epoch:16 step:15051 [D loss: 0.521507, acc.: 70.31%] [G loss: 0.818254]\n",
      "epoch:16 step:15052 [D loss: 0.533132, acc.: 71.09%] [G loss: 0.607380]\n",
      "epoch:16 step:15053 [D loss: 0.544558, acc.: 67.19%] [G loss: 0.634422]\n",
      "epoch:16 step:15054 [D loss: 0.531762, acc.: 76.56%] [G loss: 0.567987]\n",
      "epoch:16 step:15055 [D loss: 0.592413, acc.: 73.44%] [G loss: 0.502293]\n",
      "epoch:16 step:15056 [D loss: 0.582758, acc.: 71.09%] [G loss: 0.632344]\n",
      "epoch:16 step:15057 [D loss: 0.522743, acc.: 71.88%] [G loss: 0.626314]\n",
      "epoch:16 step:15058 [D loss: 0.565556, acc.: 67.97%] [G loss: 0.645520]\n",
      "epoch:16 step:15059 [D loss: 0.523142, acc.: 72.66%] [G loss: 0.556429]\n",
      "epoch:16 step:15060 [D loss: 0.527235, acc.: 74.22%] [G loss: 0.533556]\n",
      "epoch:16 step:15061 [D loss: 0.468576, acc.: 78.12%] [G loss: 0.706670]\n",
      "epoch:16 step:15062 [D loss: 0.515598, acc.: 75.00%] [G loss: 0.637313]\n",
      "epoch:16 step:15063 [D loss: 0.563541, acc.: 71.88%] [G loss: 0.626580]\n",
      "epoch:16 step:15064 [D loss: 0.506202, acc.: 71.09%] [G loss: 0.713984]\n",
      "epoch:16 step:15065 [D loss: 0.543378, acc.: 72.66%] [G loss: 0.651464]\n",
      "epoch:16 step:15066 [D loss: 0.521921, acc.: 74.22%] [G loss: 0.825511]\n",
      "epoch:16 step:15067 [D loss: 0.512364, acc.: 75.00%] [G loss: 0.679128]\n",
      "epoch:16 step:15068 [D loss: 0.525775, acc.: 72.66%] [G loss: 0.786225]\n",
      "epoch:16 step:15069 [D loss: 0.479478, acc.: 78.12%] [G loss: 0.809511]\n",
      "epoch:16 step:15070 [D loss: 0.666133, acc.: 64.84%] [G loss: 0.505101]\n",
      "epoch:16 step:15071 [D loss: 0.519013, acc.: 67.19%] [G loss: 0.724917]\n",
      "epoch:16 step:15072 [D loss: 0.518218, acc.: 70.31%] [G loss: 0.617686]\n",
      "epoch:16 step:15073 [D loss: 0.552687, acc.: 67.97%] [G loss: 0.595291]\n",
      "epoch:16 step:15074 [D loss: 0.516767, acc.: 65.62%] [G loss: 0.606120]\n",
      "epoch:16 step:15075 [D loss: 0.485035, acc.: 76.56%] [G loss: 0.878753]\n",
      "epoch:16 step:15076 [D loss: 0.547111, acc.: 69.53%] [G loss: 0.690361]\n",
      "epoch:16 step:15077 [D loss: 0.616422, acc.: 62.50%] [G loss: 0.622044]\n",
      "epoch:16 step:15078 [D loss: 0.524471, acc.: 76.56%] [G loss: 0.607288]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:16 step:15079 [D loss: 0.522811, acc.: 73.44%] [G loss: 0.592687]\n",
      "epoch:16 step:15080 [D loss: 0.523166, acc.: 73.44%] [G loss: 0.605634]\n",
      "epoch:16 step:15081 [D loss: 0.509770, acc.: 71.09%] [G loss: 0.661219]\n",
      "epoch:16 step:15082 [D loss: 0.503131, acc.: 70.31%] [G loss: 0.751691]\n",
      "epoch:16 step:15083 [D loss: 0.603192, acc.: 67.19%] [G loss: 0.685573]\n",
      "epoch:16 step:15084 [D loss: 0.442882, acc.: 76.56%] [G loss: 0.695059]\n",
      "epoch:16 step:15085 [D loss: 0.523175, acc.: 70.31%] [G loss: 0.875911]\n",
      "epoch:16 step:15086 [D loss: 0.501336, acc.: 76.56%] [G loss: 0.753151]\n",
      "epoch:16 step:15087 [D loss: 0.564950, acc.: 67.97%] [G loss: 0.728082]\n",
      "epoch:16 step:15088 [D loss: 0.487729, acc.: 74.22%] [G loss: 0.847855]\n",
      "epoch:16 step:15089 [D loss: 0.544815, acc.: 76.56%] [G loss: 0.759565]\n",
      "epoch:16 step:15090 [D loss: 0.539538, acc.: 71.88%] [G loss: 0.677560]\n",
      "epoch:16 step:15091 [D loss: 0.505032, acc.: 72.66%] [G loss: 0.634574]\n",
      "epoch:16 step:15092 [D loss: 0.448884, acc.: 78.12%] [G loss: 0.861432]\n",
      "epoch:16 step:15093 [D loss: 0.508194, acc.: 72.66%] [G loss: 0.953138]\n",
      "epoch:16 step:15094 [D loss: 0.697898, acc.: 63.28%] [G loss: 0.655076]\n",
      "epoch:16 step:15095 [D loss: 0.527510, acc.: 74.22%] [G loss: 0.533629]\n",
      "epoch:16 step:15096 [D loss: 0.495731, acc.: 75.00%] [G loss: 0.833441]\n",
      "epoch:16 step:15097 [D loss: 0.634213, acc.: 62.50%] [G loss: 0.643582]\n",
      "epoch:16 step:15098 [D loss: 0.551390, acc.: 67.19%] [G loss: 0.542835]\n",
      "epoch:16 step:15099 [D loss: 0.566191, acc.: 68.75%] [G loss: 0.617471]\n",
      "epoch:16 step:15100 [D loss: 0.643366, acc.: 60.94%] [G loss: 0.563221]\n",
      "epoch:16 step:15101 [D loss: 0.611363, acc.: 67.19%] [G loss: 0.628708]\n",
      "epoch:16 step:15102 [D loss: 0.527482, acc.: 70.31%] [G loss: 0.534648]\n",
      "epoch:16 step:15103 [D loss: 0.472747, acc.: 79.69%] [G loss: 0.524030]\n",
      "epoch:16 step:15104 [D loss: 0.527154, acc.: 71.88%] [G loss: 0.554003]\n",
      "epoch:16 step:15105 [D loss: 0.548853, acc.: 67.19%] [G loss: 0.588831]\n",
      "epoch:16 step:15106 [D loss: 0.546177, acc.: 73.44%] [G loss: 0.597586]\n",
      "epoch:16 step:15107 [D loss: 0.533154, acc.: 73.44%] [G loss: 0.944132]\n",
      "epoch:16 step:15108 [D loss: 0.585044, acc.: 65.62%] [G loss: 0.787812]\n",
      "epoch:16 step:15109 [D loss: 0.584319, acc.: 67.19%] [G loss: 0.622453]\n",
      "epoch:16 step:15110 [D loss: 0.548027, acc.: 68.75%] [G loss: 0.868902]\n",
      "epoch:16 step:15111 [D loss: 0.485646, acc.: 76.56%] [G loss: 0.764340]\n",
      "epoch:16 step:15112 [D loss: 0.544957, acc.: 73.44%] [G loss: 0.781685]\n",
      "epoch:16 step:15113 [D loss: 0.532560, acc.: 73.44%] [G loss: 0.731202]\n",
      "epoch:16 step:15114 [D loss: 0.498823, acc.: 78.12%] [G loss: 0.757476]\n",
      "epoch:16 step:15115 [D loss: 0.498480, acc.: 71.09%] [G loss: 0.847760]\n",
      "epoch:16 step:15116 [D loss: 0.572008, acc.: 67.97%] [G loss: 0.756242]\n",
      "epoch:16 step:15117 [D loss: 0.600345, acc.: 70.31%] [G loss: 0.631989]\n",
      "epoch:16 step:15118 [D loss: 0.471919, acc.: 77.34%] [G loss: 0.654364]\n",
      "epoch:16 step:15119 [D loss: 0.467842, acc.: 78.91%] [G loss: 0.576165]\n",
      "epoch:16 step:15120 [D loss: 0.511817, acc.: 75.00%] [G loss: 0.711912]\n",
      "epoch:16 step:15121 [D loss: 0.525705, acc.: 74.22%] [G loss: 0.639153]\n",
      "epoch:16 step:15122 [D loss: 0.481772, acc.: 75.00%] [G loss: 0.667226]\n",
      "epoch:16 step:15123 [D loss: 0.492681, acc.: 74.22%] [G loss: 0.754056]\n",
      "epoch:16 step:15124 [D loss: 0.535090, acc.: 71.09%] [G loss: 0.646502]\n",
      "epoch:16 step:15125 [D loss: 0.569930, acc.: 72.66%] [G loss: 0.665152]\n",
      "epoch:16 step:15126 [D loss: 0.517070, acc.: 74.22%] [G loss: 0.700890]\n",
      "epoch:16 step:15127 [D loss: 0.491999, acc.: 78.91%] [G loss: 0.735415]\n",
      "epoch:16 step:15128 [D loss: 0.526541, acc.: 71.88%] [G loss: 0.663365]\n",
      "epoch:16 step:15129 [D loss: 0.640385, acc.: 64.06%] [G loss: 0.660678]\n",
      "epoch:16 step:15130 [D loss: 0.582305, acc.: 64.84%] [G loss: 0.529581]\n",
      "epoch:16 step:15131 [D loss: 0.508049, acc.: 78.12%] [G loss: 0.565863]\n",
      "epoch:16 step:15132 [D loss: 0.578709, acc.: 67.19%] [G loss: 0.550017]\n",
      "epoch:16 step:15133 [D loss: 0.514281, acc.: 70.31%] [G loss: 0.535273]\n",
      "epoch:16 step:15134 [D loss: 0.571498, acc.: 66.41%] [G loss: 0.487543]\n",
      "epoch:16 step:15135 [D loss: 0.588425, acc.: 64.84%] [G loss: 0.480689]\n",
      "epoch:16 step:15136 [D loss: 0.543142, acc.: 67.19%] [G loss: 0.612592]\n",
      "epoch:16 step:15137 [D loss: 0.577536, acc.: 62.50%] [G loss: 0.460978]\n",
      "epoch:16 step:15138 [D loss: 0.533711, acc.: 73.44%] [G loss: 0.607968]\n",
      "epoch:16 step:15139 [D loss: 0.629907, acc.: 64.06%] [G loss: 0.519677]\n",
      "epoch:16 step:15140 [D loss: 0.592763, acc.: 62.50%] [G loss: 0.574168]\n",
      "epoch:16 step:15141 [D loss: 0.497088, acc.: 73.44%] [G loss: 0.519319]\n",
      "epoch:16 step:15142 [D loss: 0.574478, acc.: 66.41%] [G loss: 0.554637]\n",
      "epoch:16 step:15143 [D loss: 0.503121, acc.: 75.78%] [G loss: 0.566982]\n",
      "epoch:16 step:15144 [D loss: 0.463920, acc.: 82.81%] [G loss: 0.795312]\n",
      "epoch:16 step:15145 [D loss: 0.573588, acc.: 66.41%] [G loss: 0.584257]\n",
      "epoch:16 step:15146 [D loss: 0.597916, acc.: 63.28%] [G loss: 0.559092]\n",
      "epoch:16 step:15147 [D loss: 0.484865, acc.: 75.78%] [G loss: 0.681980]\n",
      "epoch:16 step:15148 [D loss: 0.500437, acc.: 72.66%] [G loss: 0.714524]\n",
      "epoch:16 step:15149 [D loss: 0.598832, acc.: 67.19%] [G loss: 0.600345]\n",
      "epoch:16 step:15150 [D loss: 0.588983, acc.: 64.84%] [G loss: 0.486058]\n",
      "epoch:16 step:15151 [D loss: 0.507068, acc.: 72.66%] [G loss: 0.523034]\n",
      "epoch:16 step:15152 [D loss: 0.594827, acc.: 65.62%] [G loss: 0.482957]\n",
      "epoch:16 step:15153 [D loss: 0.494898, acc.: 71.88%] [G loss: 0.681820]\n",
      "epoch:16 step:15154 [D loss: 0.456464, acc.: 75.78%] [G loss: 0.584915]\n",
      "epoch:16 step:15155 [D loss: 0.587590, acc.: 62.50%] [G loss: 0.620067]\n",
      "epoch:16 step:15156 [D loss: 0.524267, acc.: 71.88%] [G loss: 0.524543]\n",
      "epoch:16 step:15157 [D loss: 0.547148, acc.: 67.97%] [G loss: 0.685975]\n",
      "epoch:16 step:15158 [D loss: 0.553612, acc.: 69.53%] [G loss: 0.602698]\n",
      "epoch:16 step:15159 [D loss: 0.572686, acc.: 67.97%] [G loss: 0.698616]\n",
      "epoch:16 step:15160 [D loss: 0.594755, acc.: 68.75%] [G loss: 0.632804]\n",
      "epoch:16 step:15161 [D loss: 0.642819, acc.: 61.72%] [G loss: 0.523637]\n",
      "epoch:16 step:15162 [D loss: 0.522634, acc.: 71.09%] [G loss: 0.525381]\n",
      "epoch:16 step:15163 [D loss: 0.575810, acc.: 63.28%] [G loss: 0.504409]\n",
      "epoch:16 step:15164 [D loss: 0.541582, acc.: 68.75%] [G loss: 0.543006]\n",
      "epoch:16 step:15165 [D loss: 0.506382, acc.: 71.09%] [G loss: 0.610846]\n",
      "epoch:16 step:15166 [D loss: 0.575512, acc.: 68.75%] [G loss: 0.604229]\n",
      "epoch:16 step:15167 [D loss: 0.582797, acc.: 63.28%] [G loss: 0.505148]\n",
      "epoch:16 step:15168 [D loss: 0.544899, acc.: 69.53%] [G loss: 0.651948]\n",
      "epoch:16 step:15169 [D loss: 0.501552, acc.: 77.34%] [G loss: 0.596445]\n",
      "epoch:16 step:15170 [D loss: 0.586652, acc.: 65.62%] [G loss: 0.422994]\n",
      "epoch:16 step:15171 [D loss: 0.535356, acc.: 75.00%] [G loss: 0.416686]\n",
      "epoch:16 step:15172 [D loss: 0.602864, acc.: 64.84%] [G loss: 0.447405]\n",
      "epoch:16 step:15173 [D loss: 0.572873, acc.: 69.53%] [G loss: 0.575249]\n",
      "epoch:16 step:15174 [D loss: 0.534325, acc.: 67.19%] [G loss: 0.705676]\n",
      "epoch:16 step:15175 [D loss: 0.581150, acc.: 69.53%] [G loss: 0.570937]\n",
      "epoch:16 step:15176 [D loss: 0.514819, acc.: 73.44%] [G loss: 0.731929]\n",
      "epoch:16 step:15177 [D loss: 0.551671, acc.: 69.53%] [G loss: 0.657873]\n",
      "epoch:16 step:15178 [D loss: 0.560500, acc.: 66.41%] [G loss: 0.588623]\n",
      "epoch:16 step:15179 [D loss: 0.617591, acc.: 64.06%] [G loss: 0.680786]\n",
      "epoch:16 step:15180 [D loss: 0.551680, acc.: 71.88%] [G loss: 0.549107]\n",
      "epoch:16 step:15181 [D loss: 0.556757, acc.: 70.31%] [G loss: 0.673015]\n",
      "epoch:16 step:15182 [D loss: 0.487655, acc.: 75.78%] [G loss: 0.634807]\n",
      "epoch:16 step:15183 [D loss: 0.526718, acc.: 72.66%] [G loss: 0.558769]\n",
      "epoch:16 step:15184 [D loss: 0.531986, acc.: 73.44%] [G loss: 0.604766]\n",
      "epoch:16 step:15185 [D loss: 0.537893, acc.: 70.31%] [G loss: 0.461999]\n",
      "epoch:16 step:15186 [D loss: 0.492258, acc.: 76.56%] [G loss: 0.779325]\n",
      "epoch:16 step:15187 [D loss: 0.513542, acc.: 75.00%] [G loss: 0.665404]\n",
      "epoch:16 step:15188 [D loss: 0.566711, acc.: 67.97%] [G loss: 0.646658]\n",
      "epoch:16 step:15189 [D loss: 0.589129, acc.: 65.62%] [G loss: 0.542141]\n",
      "epoch:16 step:15190 [D loss: 0.414090, acc.: 82.81%] [G loss: 0.796887]\n",
      "epoch:16 step:15191 [D loss: 0.523306, acc.: 73.44%] [G loss: 0.772903]\n",
      "epoch:16 step:15192 [D loss: 0.635223, acc.: 61.72%] [G loss: 0.459071]\n",
      "epoch:16 step:15193 [D loss: 0.629605, acc.: 60.16%] [G loss: 0.676679]\n",
      "epoch:16 step:15194 [D loss: 0.558424, acc.: 67.19%] [G loss: 0.633165]\n",
      "epoch:16 step:15195 [D loss: 0.553837, acc.: 73.44%] [G loss: 0.574671]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:16 step:15196 [D loss: 0.548113, acc.: 68.75%] [G loss: 0.679440]\n",
      "epoch:16 step:15197 [D loss: 0.492961, acc.: 75.78%] [G loss: 0.710775]\n",
      "epoch:16 step:15198 [D loss: 0.538711, acc.: 71.88%] [G loss: 0.718868]\n",
      "epoch:16 step:15199 [D loss: 0.456504, acc.: 80.47%] [G loss: 0.909910]\n",
      "epoch:16 step:15200 [D loss: 0.419170, acc.: 82.81%] [G loss: 0.852690]\n",
      "##############\n",
      "[2.9409827  1.17031234 6.43489381 4.80026616 3.94091719 5.99397683\n",
      " 4.46257363 4.79592115 4.68092357 3.99343367]\n",
      "##########\n",
      "epoch:16 step:15201 [D loss: 0.524789, acc.: 74.22%] [G loss: 0.718630]\n",
      "epoch:16 step:15202 [D loss: 0.649590, acc.: 67.19%] [G loss: 0.558695]\n",
      "epoch:16 step:15203 [D loss: 0.598071, acc.: 68.75%] [G loss: 0.518245]\n",
      "epoch:16 step:15204 [D loss: 0.563920, acc.: 72.66%] [G loss: 0.608419]\n",
      "epoch:16 step:15205 [D loss: 0.573555, acc.: 68.75%] [G loss: 0.612728]\n",
      "epoch:16 step:15206 [D loss: 0.653071, acc.: 63.28%] [G loss: 0.479865]\n",
      "epoch:16 step:15207 [D loss: 0.559146, acc.: 74.22%] [G loss: 0.641632]\n",
      "epoch:16 step:15208 [D loss: 0.530670, acc.: 67.97%] [G loss: 0.590319]\n",
      "epoch:16 step:15209 [D loss: 0.506353, acc.: 73.44%] [G loss: 0.665158]\n",
      "epoch:16 step:15210 [D loss: 0.540297, acc.: 70.31%] [G loss: 0.594680]\n",
      "epoch:16 step:15211 [D loss: 0.480092, acc.: 79.69%] [G loss: 0.910891]\n",
      "epoch:16 step:15212 [D loss: 0.641989, acc.: 64.84%] [G loss: 0.806266]\n",
      "epoch:16 step:15213 [D loss: 0.552579, acc.: 71.09%] [G loss: 0.560789]\n",
      "epoch:16 step:15214 [D loss: 0.457748, acc.: 79.69%] [G loss: 0.588272]\n",
      "epoch:16 step:15215 [D loss: 0.489518, acc.: 75.78%] [G loss: 0.804217]\n",
      "epoch:16 step:15216 [D loss: 0.584145, acc.: 67.97%] [G loss: 0.733536]\n",
      "epoch:16 step:15217 [D loss: 0.560861, acc.: 73.44%] [G loss: 0.826565]\n",
      "epoch:16 step:15218 [D loss: 0.583416, acc.: 64.84%] [G loss: 0.533744]\n",
      "epoch:16 step:15219 [D loss: 0.562318, acc.: 69.53%] [G loss: 0.587575]\n",
      "epoch:16 step:15220 [D loss: 0.639814, acc.: 66.41%] [G loss: 0.784356]\n",
      "epoch:16 step:15221 [D loss: 0.522259, acc.: 74.22%] [G loss: 0.678275]\n",
      "epoch:16 step:15222 [D loss: 0.527015, acc.: 71.88%] [G loss: 0.583534]\n",
      "epoch:16 step:15223 [D loss: 0.477044, acc.: 78.12%] [G loss: 0.875161]\n",
      "epoch:16 step:15224 [D loss: 0.490641, acc.: 74.22%] [G loss: 1.060339]\n",
      "epoch:16 step:15225 [D loss: 0.527336, acc.: 73.44%] [G loss: 0.853314]\n",
      "epoch:16 step:15226 [D loss: 0.535734, acc.: 71.88%] [G loss: 0.679109]\n",
      "epoch:16 step:15227 [D loss: 0.595368, acc.: 64.06%] [G loss: 0.637357]\n",
      "epoch:16 step:15228 [D loss: 0.542392, acc.: 67.97%] [G loss: 0.701913]\n",
      "epoch:16 step:15229 [D loss: 0.514356, acc.: 76.56%] [G loss: 0.686398]\n",
      "epoch:16 step:15230 [D loss: 0.594105, acc.: 67.19%] [G loss: 0.527965]\n",
      "epoch:16 step:15231 [D loss: 0.517972, acc.: 76.56%] [G loss: 0.699957]\n",
      "epoch:16 step:15232 [D loss: 0.591766, acc.: 66.41%] [G loss: 0.590364]\n",
      "epoch:16 step:15233 [D loss: 0.504918, acc.: 75.78%] [G loss: 0.655732]\n",
      "epoch:16 step:15234 [D loss: 0.527629, acc.: 73.44%] [G loss: 0.556879]\n",
      "epoch:16 step:15235 [D loss: 0.480114, acc.: 76.56%] [G loss: 0.719771]\n",
      "epoch:16 step:15236 [D loss: 0.523195, acc.: 71.88%] [G loss: 0.686512]\n",
      "epoch:16 step:15237 [D loss: 0.541149, acc.: 70.31%] [G loss: 0.731386]\n",
      "epoch:16 step:15238 [D loss: 0.503030, acc.: 72.66%] [G loss: 0.745728]\n",
      "epoch:16 step:15239 [D loss: 0.534222, acc.: 71.88%] [G loss: 0.780376]\n",
      "epoch:16 step:15240 [D loss: 0.537060, acc.: 76.56%] [G loss: 0.649105]\n",
      "epoch:16 step:15241 [D loss: 0.601024, acc.: 67.97%] [G loss: 0.595177]\n",
      "epoch:16 step:15242 [D loss: 0.668945, acc.: 61.72%] [G loss: 0.632613]\n",
      "epoch:16 step:15243 [D loss: 0.663594, acc.: 60.94%] [G loss: 0.536216]\n",
      "epoch:16 step:15244 [D loss: 0.536275, acc.: 72.66%] [G loss: 0.665434]\n",
      "epoch:16 step:15245 [D loss: 0.602539, acc.: 64.84%] [G loss: 0.592196]\n",
      "epoch:16 step:15246 [D loss: 0.495030, acc.: 77.34%] [G loss: 0.717053]\n",
      "epoch:16 step:15247 [D loss: 0.513749, acc.: 72.66%] [G loss: 0.744327]\n",
      "epoch:16 step:15248 [D loss: 0.546912, acc.: 67.97%] [G loss: 0.623554]\n",
      "epoch:16 step:15249 [D loss: 0.623339, acc.: 59.38%] [G loss: 0.596323]\n",
      "epoch:16 step:15250 [D loss: 0.560667, acc.: 66.41%] [G loss: 0.483670]\n",
      "epoch:16 step:15251 [D loss: 0.524801, acc.: 70.31%] [G loss: 0.462463]\n",
      "epoch:16 step:15252 [D loss: 0.540362, acc.: 73.44%] [G loss: 0.458556]\n",
      "epoch:16 step:15253 [D loss: 0.580169, acc.: 67.19%] [G loss: 0.524275]\n",
      "epoch:16 step:15254 [D loss: 0.513164, acc.: 75.00%] [G loss: 0.552532]\n",
      "epoch:16 step:15255 [D loss: 0.578549, acc.: 68.75%] [G loss: 0.505750]\n",
      "epoch:16 step:15256 [D loss: 0.537047, acc.: 67.19%] [G loss: 0.598068]\n",
      "epoch:16 step:15257 [D loss: 0.519899, acc.: 73.44%] [G loss: 0.606396]\n",
      "epoch:16 step:15258 [D loss: 0.607562, acc.: 64.06%] [G loss: 0.493990]\n",
      "epoch:16 step:15259 [D loss: 0.580872, acc.: 65.62%] [G loss: 0.502902]\n",
      "epoch:16 step:15260 [D loss: 0.548183, acc.: 64.84%] [G loss: 0.476405]\n",
      "epoch:16 step:15261 [D loss: 0.504141, acc.: 74.22%] [G loss: 0.611048]\n",
      "epoch:16 step:15262 [D loss: 0.532742, acc.: 74.22%] [G loss: 0.604592]\n",
      "epoch:16 step:15263 [D loss: 0.493708, acc.: 78.12%] [G loss: 0.559774]\n",
      "epoch:16 step:15264 [D loss: 0.528927, acc.: 74.22%] [G loss: 0.656066]\n",
      "epoch:16 step:15265 [D loss: 0.509811, acc.: 74.22%] [G loss: 0.633058]\n",
      "epoch:16 step:15266 [D loss: 0.488699, acc.: 77.34%] [G loss: 0.608846]\n",
      "epoch:16 step:15267 [D loss: 0.638692, acc.: 69.53%] [G loss: 0.524548]\n",
      "epoch:16 step:15268 [D loss: 0.457654, acc.: 80.47%] [G loss: 0.753356]\n",
      "epoch:16 step:15269 [D loss: 0.641426, acc.: 67.97%] [G loss: 0.475051]\n",
      "epoch:16 step:15270 [D loss: 0.606686, acc.: 65.62%] [G loss: 0.568175]\n",
      "epoch:16 step:15271 [D loss: 0.639225, acc.: 62.50%] [G loss: 0.433594]\n",
      "epoch:16 step:15272 [D loss: 0.553873, acc.: 68.75%] [G loss: 0.543201]\n",
      "epoch:16 step:15273 [D loss: 0.564863, acc.: 66.41%] [G loss: 0.531641]\n",
      "epoch:16 step:15274 [D loss: 0.558252, acc.: 71.88%] [G loss: 0.552431]\n",
      "epoch:16 step:15275 [D loss: 0.499096, acc.: 77.34%] [G loss: 0.492128]\n",
      "epoch:16 step:15276 [D loss: 0.500059, acc.: 73.44%] [G loss: 0.535541]\n",
      "epoch:16 step:15277 [D loss: 0.512585, acc.: 70.31%] [G loss: 0.593504]\n",
      "epoch:16 step:15278 [D loss: 0.518087, acc.: 71.88%] [G loss: 0.825006]\n",
      "epoch:16 step:15279 [D loss: 0.576924, acc.: 66.41%] [G loss: 0.533875]\n",
      "epoch:16 step:15280 [D loss: 0.595547, acc.: 65.62%] [G loss: 0.558528]\n",
      "epoch:16 step:15281 [D loss: 0.566434, acc.: 66.41%] [G loss: 0.481122]\n",
      "epoch:16 step:15282 [D loss: 0.586686, acc.: 63.28%] [G loss: 0.622131]\n",
      "epoch:16 step:15283 [D loss: 0.597784, acc.: 67.97%] [G loss: 0.551455]\n",
      "epoch:16 step:15284 [D loss: 0.532871, acc.: 69.53%] [G loss: 0.741429]\n",
      "epoch:16 step:15285 [D loss: 0.598536, acc.: 65.62%] [G loss: 0.549228]\n",
      "epoch:16 step:15286 [D loss: 0.607923, acc.: 65.62%] [G loss: 0.618834]\n",
      "epoch:16 step:15287 [D loss: 0.585416, acc.: 67.97%] [G loss: 0.482191]\n",
      "epoch:16 step:15288 [D loss: 0.476165, acc.: 72.66%] [G loss: 0.668754]\n",
      "epoch:16 step:15289 [D loss: 0.546003, acc.: 71.09%] [G loss: 0.588896]\n",
      "epoch:16 step:15290 [D loss: 0.485593, acc.: 78.91%] [G loss: 0.598070]\n",
      "epoch:16 step:15291 [D loss: 0.479274, acc.: 77.34%] [G loss: 0.660049]\n",
      "epoch:16 step:15292 [D loss: 0.539994, acc.: 76.56%] [G loss: 0.702726]\n",
      "epoch:16 step:15293 [D loss: 0.619055, acc.: 64.84%] [G loss: 0.610899]\n",
      "epoch:16 step:15294 [D loss: 0.536574, acc.: 71.09%] [G loss: 0.502308]\n",
      "epoch:16 step:15295 [D loss: 0.498979, acc.: 76.56%] [G loss: 0.575551]\n",
      "epoch:16 step:15296 [D loss: 0.491234, acc.: 72.66%] [G loss: 0.678833]\n",
      "epoch:16 step:15297 [D loss: 0.581770, acc.: 67.97%] [G loss: 0.600196]\n",
      "epoch:16 step:15298 [D loss: 0.517577, acc.: 71.09%] [G loss: 0.720677]\n",
      "epoch:16 step:15299 [D loss: 0.476871, acc.: 77.34%] [G loss: 0.684329]\n",
      "epoch:16 step:15300 [D loss: 0.533942, acc.: 72.66%] [G loss: 0.625976]\n",
      "epoch:16 step:15301 [D loss: 0.532609, acc.: 66.41%] [G loss: 0.643540]\n",
      "epoch:16 step:15302 [D loss: 0.558392, acc.: 68.75%] [G loss: 0.765378]\n",
      "epoch:16 step:15303 [D loss: 0.525493, acc.: 71.09%] [G loss: 0.756307]\n",
      "epoch:16 step:15304 [D loss: 0.454208, acc.: 81.25%] [G loss: 0.823710]\n",
      "epoch:16 step:15305 [D loss: 0.479324, acc.: 76.56%] [G loss: 0.958450]\n",
      "epoch:16 step:15306 [D loss: 0.507239, acc.: 70.31%] [G loss: 0.899617]\n",
      "epoch:16 step:15307 [D loss: 0.496400, acc.: 74.22%] [G loss: 1.004280]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:16 step:15308 [D loss: 0.710068, acc.: 64.06%] [G loss: 0.755161]\n",
      "epoch:16 step:15309 [D loss: 0.575446, acc.: 67.19%] [G loss: 0.514967]\n",
      "epoch:16 step:15310 [D loss: 0.508024, acc.: 72.66%] [G loss: 0.560742]\n",
      "epoch:16 step:15311 [D loss: 0.569430, acc.: 71.88%] [G loss: 0.580992]\n",
      "epoch:16 step:15312 [D loss: 0.554987, acc.: 70.31%] [G loss: 0.516336]\n",
      "epoch:16 step:15313 [D loss: 0.477132, acc.: 78.91%] [G loss: 0.611327]\n",
      "epoch:16 step:15314 [D loss: 0.588897, acc.: 69.53%] [G loss: 0.688083]\n",
      "epoch:16 step:15315 [D loss: 0.597475, acc.: 67.97%] [G loss: 0.490940]\n",
      "epoch:16 step:15316 [D loss: 0.593803, acc.: 66.41%] [G loss: 0.575126]\n",
      "epoch:16 step:15317 [D loss: 0.559617, acc.: 68.75%] [G loss: 0.512125]\n",
      "epoch:16 step:15318 [D loss: 0.485788, acc.: 75.78%] [G loss: 0.646103]\n",
      "epoch:16 step:15319 [D loss: 0.506092, acc.: 75.00%] [G loss: 0.874260]\n",
      "epoch:16 step:15320 [D loss: 0.443906, acc.: 84.38%] [G loss: 0.837533]\n",
      "epoch:16 step:15321 [D loss: 0.509780, acc.: 71.09%] [G loss: 0.881064]\n",
      "epoch:16 step:15322 [D loss: 0.604306, acc.: 64.84%] [G loss: 0.564183]\n",
      "epoch:16 step:15323 [D loss: 0.540913, acc.: 69.53%] [G loss: 0.481484]\n",
      "epoch:16 step:15324 [D loss: 0.494342, acc.: 73.44%] [G loss: 0.587854]\n",
      "epoch:16 step:15325 [D loss: 0.501025, acc.: 75.00%] [G loss: 0.618115]\n",
      "epoch:16 step:15326 [D loss: 0.518366, acc.: 75.00%] [G loss: 0.744846]\n",
      "epoch:16 step:15327 [D loss: 0.500610, acc.: 76.56%] [G loss: 0.801037]\n",
      "epoch:16 step:15328 [D loss: 0.528171, acc.: 73.44%] [G loss: 0.738917]\n",
      "epoch:16 step:15329 [D loss: 0.590142, acc.: 66.41%] [G loss: 0.714244]\n",
      "epoch:16 step:15330 [D loss: 0.573060, acc.: 66.41%] [G loss: 0.724876]\n",
      "epoch:16 step:15331 [D loss: 0.550826, acc.: 67.97%] [G loss: 0.678100]\n",
      "epoch:16 step:15332 [D loss: 0.510089, acc.: 74.22%] [G loss: 0.551250]\n",
      "epoch:16 step:15333 [D loss: 0.592791, acc.: 65.62%] [G loss: 0.754386]\n",
      "epoch:16 step:15334 [D loss: 0.633618, acc.: 61.72%] [G loss: 0.471414]\n",
      "epoch:16 step:15335 [D loss: 0.510582, acc.: 75.78%] [G loss: 0.486711]\n",
      "epoch:16 step:15336 [D loss: 0.485597, acc.: 74.22%] [G loss: 0.865057]\n",
      "epoch:16 step:15337 [D loss: 0.559469, acc.: 71.09%] [G loss: 0.765306]\n",
      "epoch:16 step:15338 [D loss: 0.526142, acc.: 69.53%] [G loss: 0.729198]\n",
      "epoch:16 step:15339 [D loss: 0.448300, acc.: 83.59%] [G loss: 0.872528]\n",
      "epoch:16 step:15340 [D loss: 0.604463, acc.: 70.31%] [G loss: 0.738656]\n",
      "epoch:16 step:15341 [D loss: 0.679126, acc.: 61.72%] [G loss: 0.567770]\n",
      "epoch:16 step:15342 [D loss: 0.511662, acc.: 73.44%] [G loss: 0.541587]\n",
      "epoch:16 step:15343 [D loss: 0.552976, acc.: 67.97%] [G loss: 0.619913]\n",
      "epoch:16 step:15344 [D loss: 0.547708, acc.: 69.53%] [G loss: 0.810174]\n",
      "epoch:16 step:15345 [D loss: 0.597312, acc.: 61.72%] [G loss: 0.751951]\n",
      "epoch:16 step:15346 [D loss: 0.414830, acc.: 78.91%] [G loss: 0.949051]\n",
      "epoch:16 step:15347 [D loss: 0.530446, acc.: 68.75%] [G loss: 0.809507]\n",
      "epoch:16 step:15348 [D loss: 0.633266, acc.: 64.06%] [G loss: 0.705909]\n",
      "epoch:16 step:15349 [D loss: 0.431751, acc.: 82.81%] [G loss: 0.744897]\n",
      "epoch:16 step:15350 [D loss: 0.479619, acc.: 72.66%] [G loss: 0.663096]\n",
      "epoch:16 step:15351 [D loss: 0.523337, acc.: 72.66%] [G loss: 0.777177]\n",
      "epoch:16 step:15352 [D loss: 0.484250, acc.: 75.00%] [G loss: 0.772141]\n",
      "epoch:16 step:15353 [D loss: 0.528458, acc.: 72.66%] [G loss: 0.722189]\n",
      "epoch:16 step:15354 [D loss: 0.547100, acc.: 72.66%] [G loss: 0.628670]\n",
      "epoch:16 step:15355 [D loss: 0.517469, acc.: 72.66%] [G loss: 0.589695]\n",
      "epoch:16 step:15356 [D loss: 0.521895, acc.: 67.97%] [G loss: 0.577881]\n",
      "epoch:16 step:15357 [D loss: 0.579710, acc.: 69.53%] [G loss: 0.508842]\n",
      "epoch:16 step:15358 [D loss: 0.510466, acc.: 74.22%] [G loss: 0.644044]\n",
      "epoch:16 step:15359 [D loss: 0.601216, acc.: 60.94%] [G loss: 0.603016]\n",
      "epoch:16 step:15360 [D loss: 0.548458, acc.: 69.53%] [G loss: 0.641385]\n",
      "epoch:16 step:15361 [D loss: 0.531021, acc.: 75.00%] [G loss: 0.582114]\n",
      "epoch:16 step:15362 [D loss: 0.492156, acc.: 74.22%] [G loss: 0.747448]\n",
      "epoch:16 step:15363 [D loss: 0.525072, acc.: 75.78%] [G loss: 0.738582]\n",
      "epoch:16 step:15364 [D loss: 0.598077, acc.: 62.50%] [G loss: 0.777727]\n",
      "epoch:16 step:15365 [D loss: 0.560760, acc.: 70.31%] [G loss: 0.687084]\n",
      "epoch:16 step:15366 [D loss: 0.471531, acc.: 74.22%] [G loss: 0.803150]\n",
      "epoch:16 step:15367 [D loss: 0.630580, acc.: 65.62%] [G loss: 0.803743]\n",
      "epoch:16 step:15368 [D loss: 0.748420, acc.: 53.12%] [G loss: 0.399212]\n",
      "epoch:16 step:15369 [D loss: 0.569468, acc.: 64.06%] [G loss: 0.524447]\n",
      "epoch:16 step:15370 [D loss: 0.533249, acc.: 72.66%] [G loss: 0.720574]\n",
      "epoch:16 step:15371 [D loss: 0.585767, acc.: 66.41%] [G loss: 0.690844]\n",
      "epoch:16 step:15372 [D loss: 0.603073, acc.: 70.31%] [G loss: 0.477136]\n",
      "epoch:16 step:15373 [D loss: 0.493905, acc.: 73.44%] [G loss: 0.676583]\n",
      "epoch:16 step:15374 [D loss: 0.523179, acc.: 73.44%] [G loss: 0.576341]\n",
      "epoch:16 step:15375 [D loss: 0.519858, acc.: 71.88%] [G loss: 0.580897]\n",
      "epoch:16 step:15376 [D loss: 0.544871, acc.: 66.41%] [G loss: 0.549978]\n",
      "epoch:16 step:15377 [D loss: 0.540614, acc.: 68.75%] [G loss: 0.574164]\n",
      "epoch:16 step:15378 [D loss: 0.608093, acc.: 64.06%] [G loss: 0.640517]\n",
      "epoch:16 step:15379 [D loss: 0.526128, acc.: 73.44%] [G loss: 0.668947]\n",
      "epoch:16 step:15380 [D loss: 0.519429, acc.: 71.88%] [G loss: 0.688816]\n",
      "epoch:16 step:15381 [D loss: 0.494427, acc.: 75.78%] [G loss: 0.653111]\n",
      "epoch:16 step:15382 [D loss: 0.594300, acc.: 67.19%] [G loss: 0.475387]\n",
      "epoch:16 step:15383 [D loss: 0.582534, acc.: 63.28%] [G loss: 0.445925]\n",
      "epoch:16 step:15384 [D loss: 0.528382, acc.: 68.75%] [G loss: 0.588970]\n",
      "epoch:16 step:15385 [D loss: 0.560902, acc.: 67.97%] [G loss: 0.581423]\n",
      "epoch:16 step:15386 [D loss: 0.565491, acc.: 66.41%] [G loss: 0.449834]\n",
      "epoch:16 step:15387 [D loss: 0.532897, acc.: 71.88%] [G loss: 0.498816]\n",
      "epoch:16 step:15388 [D loss: 0.551053, acc.: 69.53%] [G loss: 0.648687]\n",
      "epoch:16 step:15389 [D loss: 0.579625, acc.: 62.50%] [G loss: 0.635660]\n",
      "epoch:16 step:15390 [D loss: 0.470768, acc.: 75.78%] [G loss: 0.804410]\n",
      "epoch:16 step:15391 [D loss: 0.506751, acc.: 76.56%] [G loss: 0.599279]\n",
      "epoch:16 step:15392 [D loss: 0.633247, acc.: 57.81%] [G loss: 0.582643]\n",
      "epoch:16 step:15393 [D loss: 0.650650, acc.: 57.81%] [G loss: 0.434297]\n",
      "epoch:16 step:15394 [D loss: 0.469658, acc.: 73.44%] [G loss: 0.611008]\n",
      "epoch:16 step:15395 [D loss: 0.485102, acc.: 69.53%] [G loss: 0.730730]\n",
      "epoch:16 step:15396 [D loss: 0.550197, acc.: 69.53%] [G loss: 0.699225]\n",
      "epoch:16 step:15397 [D loss: 0.528032, acc.: 73.44%] [G loss: 0.571562]\n",
      "epoch:16 step:15398 [D loss: 0.586585, acc.: 62.50%] [G loss: 0.595458]\n",
      "epoch:16 step:15399 [D loss: 0.587322, acc.: 65.62%] [G loss: 0.714148]\n",
      "epoch:16 step:15400 [D loss: 0.605688, acc.: 64.06%] [G loss: 0.636068]\n",
      "##############\n",
      "[2.9309572  1.24915157 6.04301959 4.60464731 3.68169786 5.75945126\n",
      " 4.59173017 4.69827112 4.60616924 4.15509055]\n",
      "##########\n",
      "epoch:16 step:15401 [D loss: 0.573202, acc.: 67.97%] [G loss: 0.562174]\n",
      "epoch:16 step:15402 [D loss: 0.577868, acc.: 65.62%] [G loss: 0.730660]\n",
      "epoch:16 step:15403 [D loss: 0.566189, acc.: 67.19%] [G loss: 0.637979]\n",
      "epoch:16 step:15404 [D loss: 0.602771, acc.: 63.28%] [G loss: 0.485446]\n",
      "epoch:16 step:15405 [D loss: 0.589122, acc.: 70.31%] [G loss: 0.619030]\n",
      "epoch:16 step:15406 [D loss: 0.510597, acc.: 73.44%] [G loss: 0.746775]\n",
      "epoch:16 step:15407 [D loss: 0.592595, acc.: 66.41%] [G loss: 0.782289]\n",
      "epoch:16 step:15408 [D loss: 0.469817, acc.: 79.69%] [G loss: 0.840429]\n",
      "epoch:16 step:15409 [D loss: 0.599471, acc.: 68.75%] [G loss: 0.797795]\n",
      "epoch:16 step:15410 [D loss: 0.693833, acc.: 58.59%] [G loss: 0.434124]\n",
      "epoch:16 step:15411 [D loss: 0.514078, acc.: 75.78%] [G loss: 0.620062]\n",
      "epoch:16 step:15412 [D loss: 0.607210, acc.: 63.28%] [G loss: 0.459382]\n",
      "epoch:16 step:15413 [D loss: 0.583119, acc.: 65.62%] [G loss: 0.541074]\n",
      "epoch:16 step:15414 [D loss: 0.563392, acc.: 71.09%] [G loss: 0.578869]\n",
      "epoch:16 step:15415 [D loss: 0.516057, acc.: 70.31%] [G loss: 0.672535]\n",
      "epoch:16 step:15416 [D loss: 0.559510, acc.: 66.41%] [G loss: 0.621607]\n",
      "epoch:16 step:15417 [D loss: 0.514938, acc.: 72.66%] [G loss: 0.571848]\n",
      "epoch:16 step:15418 [D loss: 0.510277, acc.: 71.09%] [G loss: 0.764778]\n",
      "epoch:16 step:15419 [D loss: 0.506524, acc.: 73.44%] [G loss: 0.844882]\n",
      "epoch:16 step:15420 [D loss: 0.510412, acc.: 75.78%] [G loss: 0.753753]\n",
      "epoch:16 step:15421 [D loss: 0.451205, acc.: 82.03%] [G loss: 0.857035]\n",
      "epoch:16 step:15422 [D loss: 0.530005, acc.: 74.22%] [G loss: 0.802509]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:16 step:15423 [D loss: 0.546966, acc.: 68.75%] [G loss: 0.743065]\n",
      "epoch:16 step:15424 [D loss: 0.569377, acc.: 67.97%] [G loss: 0.639595]\n",
      "epoch:16 step:15425 [D loss: 0.630279, acc.: 67.19%] [G loss: 0.648935]\n",
      "epoch:16 step:15426 [D loss: 0.554721, acc.: 67.97%] [G loss: 0.645328]\n",
      "epoch:16 step:15427 [D loss: 0.539291, acc.: 72.66%] [G loss: 0.714801]\n",
      "epoch:16 step:15428 [D loss: 0.457610, acc.: 78.91%] [G loss: 0.718568]\n",
      "epoch:16 step:15429 [D loss: 0.651394, acc.: 63.28%] [G loss: 0.625039]\n",
      "epoch:16 step:15430 [D loss: 0.529769, acc.: 75.78%] [G loss: 0.629667]\n",
      "epoch:16 step:15431 [D loss: 0.475048, acc.: 80.47%] [G loss: 0.763616]\n",
      "epoch:16 step:15432 [D loss: 0.516161, acc.: 69.53%] [G loss: 0.743584]\n",
      "epoch:16 step:15433 [D loss: 0.526046, acc.: 73.44%] [G loss: 0.790042]\n",
      "epoch:16 step:15434 [D loss: 0.551711, acc.: 67.19%] [G loss: 0.620814]\n",
      "epoch:16 step:15435 [D loss: 0.535309, acc.: 71.88%] [G loss: 0.668890]\n",
      "epoch:16 step:15436 [D loss: 0.491344, acc.: 75.00%] [G loss: 0.692650]\n",
      "epoch:16 step:15437 [D loss: 0.539755, acc.: 71.09%] [G loss: 0.716267]\n",
      "epoch:16 step:15438 [D loss: 0.551424, acc.: 68.75%] [G loss: 0.804804]\n",
      "epoch:16 step:15439 [D loss: 0.541840, acc.: 72.66%] [G loss: 0.848258]\n",
      "epoch:16 step:15440 [D loss: 0.564273, acc.: 67.97%] [G loss: 0.645844]\n",
      "epoch:16 step:15441 [D loss: 0.498810, acc.: 72.66%] [G loss: 0.769824]\n",
      "epoch:16 step:15442 [D loss: 0.502310, acc.: 75.00%] [G loss: 0.600055]\n",
      "epoch:16 step:15443 [D loss: 0.408710, acc.: 82.81%] [G loss: 0.789973]\n",
      "epoch:16 step:15444 [D loss: 0.456020, acc.: 78.12%] [G loss: 0.858573]\n",
      "epoch:16 step:15445 [D loss: 0.514821, acc.: 73.44%] [G loss: 0.689227]\n",
      "epoch:16 step:15446 [D loss: 0.620106, acc.: 64.06%] [G loss: 0.672087]\n",
      "epoch:16 step:15447 [D loss: 0.608038, acc.: 60.94%] [G loss: 0.463037]\n",
      "epoch:16 step:15448 [D loss: 0.634245, acc.: 64.84%] [G loss: 0.420315]\n",
      "epoch:16 step:15449 [D loss: 0.554066, acc.: 71.88%] [G loss: 0.584147]\n",
      "epoch:16 step:15450 [D loss: 0.656434, acc.: 64.06%] [G loss: 0.536400]\n",
      "epoch:16 step:15451 [D loss: 0.533400, acc.: 71.09%] [G loss: 0.525007]\n",
      "epoch:16 step:15452 [D loss: 0.518248, acc.: 78.12%] [G loss: 0.709895]\n",
      "epoch:16 step:15453 [D loss: 0.511861, acc.: 70.31%] [G loss: 0.665060]\n",
      "epoch:16 step:15454 [D loss: 0.577377, acc.: 66.41%] [G loss: 0.582386]\n",
      "epoch:16 step:15455 [D loss: 0.515533, acc.: 69.53%] [G loss: 0.502413]\n",
      "epoch:16 step:15456 [D loss: 0.524750, acc.: 72.66%] [G loss: 0.793417]\n",
      "epoch:16 step:15457 [D loss: 0.594427, acc.: 62.50%] [G loss: 0.588637]\n",
      "epoch:16 step:15458 [D loss: 0.594837, acc.: 64.06%] [G loss: 0.565583]\n",
      "epoch:16 step:15459 [D loss: 0.517006, acc.: 72.66%] [G loss: 0.650765]\n",
      "epoch:16 step:15460 [D loss: 0.567750, acc.: 70.31%] [G loss: 0.776564]\n",
      "epoch:16 step:15461 [D loss: 0.520318, acc.: 72.66%] [G loss: 0.671235]\n",
      "epoch:16 step:15462 [D loss: 0.572201, acc.: 67.97%] [G loss: 0.592110]\n",
      "epoch:16 step:15463 [D loss: 0.448254, acc.: 79.69%] [G loss: 0.834379]\n",
      "epoch:16 step:15464 [D loss: 0.459423, acc.: 80.47%] [G loss: 0.935511]\n",
      "epoch:16 step:15465 [D loss: 0.681852, acc.: 54.69%] [G loss: 0.689283]\n",
      "epoch:16 step:15466 [D loss: 0.518331, acc.: 68.75%] [G loss: 0.756327]\n",
      "epoch:16 step:15467 [D loss: 0.493490, acc.: 75.00%] [G loss: 0.909275]\n",
      "epoch:16 step:15468 [D loss: 0.536308, acc.: 74.22%] [G loss: 0.708393]\n",
      "epoch:16 step:15469 [D loss: 0.721141, acc.: 59.38%] [G loss: 0.476742]\n",
      "epoch:16 step:15470 [D loss: 0.578246, acc.: 68.75%] [G loss: 0.515581]\n",
      "epoch:16 step:15471 [D loss: 0.522684, acc.: 75.00%] [G loss: 0.540338]\n",
      "epoch:16 step:15472 [D loss: 0.601187, acc.: 69.53%] [G loss: 0.529516]\n",
      "epoch:16 step:15473 [D loss: 0.514582, acc.: 72.66%] [G loss: 0.486808]\n",
      "epoch:16 step:15474 [D loss: 0.600490, acc.: 66.41%] [G loss: 0.614027]\n",
      "epoch:16 step:15475 [D loss: 0.525627, acc.: 71.88%] [G loss: 0.623166]\n",
      "epoch:16 step:15476 [D loss: 0.523212, acc.: 67.97%] [G loss: 0.576374]\n",
      "epoch:16 step:15477 [D loss: 0.557448, acc.: 70.31%] [G loss: 0.573488]\n",
      "epoch:16 step:15478 [D loss: 0.553020, acc.: 69.53%] [G loss: 0.543598]\n",
      "epoch:16 step:15479 [D loss: 0.559124, acc.: 67.97%] [G loss: 0.537280]\n",
      "epoch:16 step:15480 [D loss: 0.491084, acc.: 78.91%] [G loss: 0.509278]\n",
      "epoch:16 step:15481 [D loss: 0.502445, acc.: 71.09%] [G loss: 0.687459]\n",
      "epoch:16 step:15482 [D loss: 0.574890, acc.: 66.41%] [G loss: 0.585161]\n",
      "epoch:16 step:15483 [D loss: 0.520404, acc.: 74.22%] [G loss: 0.554085]\n",
      "epoch:16 step:15484 [D loss: 0.577168, acc.: 66.41%] [G loss: 0.512049]\n",
      "epoch:16 step:15485 [D loss: 0.546635, acc.: 70.31%] [G loss: 0.526519]\n",
      "epoch:16 step:15486 [D loss: 0.593917, acc.: 68.75%] [G loss: 0.467250]\n",
      "epoch:16 step:15487 [D loss: 0.481191, acc.: 80.47%] [G loss: 0.461053]\n",
      "epoch:16 step:15488 [D loss: 0.589094, acc.: 64.06%] [G loss: 0.644106]\n",
      "epoch:16 step:15489 [D loss: 0.554936, acc.: 67.19%] [G loss: 0.535569]\n",
      "epoch:16 step:15490 [D loss: 0.523759, acc.: 73.44%] [G loss: 0.679608]\n",
      "epoch:16 step:15491 [D loss: 0.490776, acc.: 75.00%] [G loss: 0.709842]\n",
      "epoch:16 step:15492 [D loss: 0.525117, acc.: 71.88%] [G loss: 0.622342]\n",
      "epoch:16 step:15493 [D loss: 0.664963, acc.: 62.50%] [G loss: 0.455938]\n",
      "epoch:16 step:15494 [D loss: 0.599898, acc.: 67.19%] [G loss: 0.442212]\n",
      "epoch:16 step:15495 [D loss: 0.505237, acc.: 76.56%] [G loss: 0.573100]\n",
      "epoch:16 step:15496 [D loss: 0.523743, acc.: 76.56%] [G loss: 0.676186]\n",
      "epoch:16 step:15497 [D loss: 0.528368, acc.: 72.66%] [G loss: 0.686908]\n",
      "epoch:16 step:15498 [D loss: 0.500989, acc.: 75.00%] [G loss: 0.656635]\n",
      "epoch:16 step:15499 [D loss: 0.570627, acc.: 70.31%] [G loss: 0.623866]\n",
      "epoch:16 step:15500 [D loss: 0.474148, acc.: 76.56%] [G loss: 0.831440]\n",
      "epoch:16 step:15501 [D loss: 0.551166, acc.: 71.88%] [G loss: 0.874204]\n",
      "epoch:16 step:15502 [D loss: 0.646361, acc.: 63.28%] [G loss: 0.576707]\n",
      "epoch:16 step:15503 [D loss: 0.644595, acc.: 61.72%] [G loss: 0.527324]\n",
      "epoch:16 step:15504 [D loss: 0.554842, acc.: 66.41%] [G loss: 0.581934]\n",
      "epoch:16 step:15505 [D loss: 0.506746, acc.: 72.66%] [G loss: 0.634986]\n",
      "epoch:16 step:15506 [D loss: 0.472207, acc.: 78.12%] [G loss: 0.623457]\n",
      "epoch:16 step:15507 [D loss: 0.484579, acc.: 78.91%] [G loss: 0.729356]\n",
      "epoch:16 step:15508 [D loss: 0.484051, acc.: 79.69%] [G loss: 0.832572]\n",
      "epoch:16 step:15509 [D loss: 0.579269, acc.: 69.53%] [G loss: 0.585325]\n",
      "epoch:16 step:15510 [D loss: 0.588093, acc.: 66.41%] [G loss: 0.518784]\n",
      "epoch:16 step:15511 [D loss: 0.482799, acc.: 75.78%] [G loss: 0.766484]\n",
      "epoch:16 step:15512 [D loss: 0.471150, acc.: 75.00%] [G loss: 0.698527]\n",
      "epoch:16 step:15513 [D loss: 0.481745, acc.: 74.22%] [G loss: 0.797020]\n",
      "epoch:16 step:15514 [D loss: 0.497337, acc.: 74.22%] [G loss: 0.798692]\n",
      "epoch:16 step:15515 [D loss: 0.462959, acc.: 80.47%] [G loss: 0.746764]\n",
      "epoch:16 step:15516 [D loss: 0.503551, acc.: 72.66%] [G loss: 0.757465]\n",
      "epoch:16 step:15517 [D loss: 0.593221, acc.: 64.84%] [G loss: 0.510013]\n",
      "epoch:16 step:15518 [D loss: 0.516599, acc.: 67.97%] [G loss: 0.572479]\n",
      "epoch:16 step:15519 [D loss: 0.584844, acc.: 65.62%] [G loss: 0.667769]\n",
      "epoch:16 step:15520 [D loss: 0.637332, acc.: 61.72%] [G loss: 0.578215]\n",
      "epoch:16 step:15521 [D loss: 0.595140, acc.: 69.53%] [G loss: 0.619052]\n",
      "epoch:16 step:15522 [D loss: 0.552753, acc.: 67.19%] [G loss: 0.627579]\n",
      "epoch:16 step:15523 [D loss: 0.600422, acc.: 63.28%] [G loss: 0.594162]\n",
      "epoch:16 step:15524 [D loss: 0.564613, acc.: 65.62%] [G loss: 0.603374]\n",
      "epoch:16 step:15525 [D loss: 0.638676, acc.: 60.94%] [G loss: 0.548020]\n",
      "epoch:16 step:15526 [D loss: 0.533480, acc.: 72.66%] [G loss: 0.837296]\n",
      "epoch:16 step:15527 [D loss: 0.658153, acc.: 64.06%] [G loss: 0.561951]\n",
      "epoch:16 step:15528 [D loss: 0.537866, acc.: 70.31%] [G loss: 0.610335]\n",
      "epoch:16 step:15529 [D loss: 0.585194, acc.: 66.41%] [G loss: 0.557280]\n",
      "epoch:16 step:15530 [D loss: 0.594424, acc.: 62.50%] [G loss: 0.506212]\n",
      "epoch:16 step:15531 [D loss: 0.534127, acc.: 72.66%] [G loss: 0.497380]\n",
      "epoch:16 step:15532 [D loss: 0.561332, acc.: 68.75%] [G loss: 0.553471]\n",
      "epoch:16 step:15533 [D loss: 0.541042, acc.: 67.97%] [G loss: 0.506999]\n",
      "epoch:16 step:15534 [D loss: 0.601157, acc.: 67.97%] [G loss: 0.584232]\n",
      "epoch:16 step:15535 [D loss: 0.558671, acc.: 67.97%] [G loss: 0.507785]\n",
      "epoch:16 step:15536 [D loss: 0.509924, acc.: 73.44%] [G loss: 0.488770]\n",
      "epoch:16 step:15537 [D loss: 0.488077, acc.: 74.22%] [G loss: 0.566563]\n",
      "epoch:16 step:15538 [D loss: 0.484618, acc.: 77.34%] [G loss: 0.664005]\n",
      "epoch:16 step:15539 [D loss: 0.577220, acc.: 71.09%] [G loss: 0.647378]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:16 step:15540 [D loss: 0.465899, acc.: 79.69%] [G loss: 0.671796]\n",
      "epoch:16 step:15541 [D loss: 0.502467, acc.: 71.88%] [G loss: 0.753876]\n",
      "epoch:16 step:15542 [D loss: 0.541172, acc.: 68.75%] [G loss: 0.627334]\n",
      "epoch:16 step:15543 [D loss: 0.500244, acc.: 78.12%] [G loss: 0.669723]\n",
      "epoch:16 step:15544 [D loss: 0.470984, acc.: 81.25%] [G loss: 0.676283]\n",
      "epoch:16 step:15545 [D loss: 0.563649, acc.: 71.88%] [G loss: 0.602496]\n",
      "epoch:16 step:15546 [D loss: 0.497512, acc.: 71.88%] [G loss: 0.626495]\n",
      "epoch:16 step:15547 [D loss: 0.464578, acc.: 78.91%] [G loss: 0.723414]\n",
      "epoch:16 step:15548 [D loss: 0.525676, acc.: 76.56%] [G loss: 0.703497]\n",
      "epoch:16 step:15549 [D loss: 0.522215, acc.: 72.66%] [G loss: 0.703909]\n",
      "epoch:16 step:15550 [D loss: 0.495506, acc.: 74.22%] [G loss: 0.731981]\n",
      "epoch:16 step:15551 [D loss: 0.573335, acc.: 66.41%] [G loss: 0.568205]\n",
      "epoch:16 step:15552 [D loss: 0.540970, acc.: 71.88%] [G loss: 0.548722]\n",
      "epoch:16 step:15553 [D loss: 0.566382, acc.: 65.62%] [G loss: 0.540254]\n",
      "epoch:16 step:15554 [D loss: 0.547630, acc.: 64.84%] [G loss: 0.533973]\n",
      "epoch:16 step:15555 [D loss: 0.565049, acc.: 66.41%] [G loss: 0.623792]\n",
      "epoch:16 step:15556 [D loss: 0.531034, acc.: 72.66%] [G loss: 0.814416]\n",
      "epoch:16 step:15557 [D loss: 0.571018, acc.: 71.88%] [G loss: 0.739888]\n",
      "epoch:16 step:15558 [D loss: 0.709253, acc.: 57.03%] [G loss: 0.427360]\n",
      "epoch:16 step:15559 [D loss: 0.467354, acc.: 78.12%] [G loss: 0.632819]\n",
      "epoch:16 step:15560 [D loss: 0.495680, acc.: 78.91%] [G loss: 0.632783]\n",
      "epoch:16 step:15561 [D loss: 0.554594, acc.: 71.09%] [G loss: 0.646023]\n",
      "epoch:16 step:15562 [D loss: 0.497666, acc.: 76.56%] [G loss: 0.674072]\n",
      "epoch:16 step:15563 [D loss: 0.552670, acc.: 71.09%] [G loss: 0.674741]\n",
      "epoch:16 step:15564 [D loss: 0.529006, acc.: 74.22%] [G loss: 0.757277]\n",
      "epoch:16 step:15565 [D loss: 0.553944, acc.: 71.88%] [G loss: 0.640274]\n",
      "epoch:16 step:15566 [D loss: 0.495111, acc.: 75.00%] [G loss: 0.717277]\n",
      "epoch:16 step:15567 [D loss: 0.505850, acc.: 71.09%] [G loss: 0.749780]\n",
      "epoch:16 step:15568 [D loss: 0.677296, acc.: 57.03%] [G loss: 0.583931]\n",
      "epoch:16 step:15569 [D loss: 0.539216, acc.: 71.88%] [G loss: 0.483401]\n",
      "epoch:16 step:15570 [D loss: 0.601600, acc.: 65.62%] [G loss: 0.539704]\n",
      "epoch:16 step:15571 [D loss: 0.580003, acc.: 66.41%] [G loss: 0.660424]\n",
      "epoch:16 step:15572 [D loss: 0.621459, acc.: 60.94%] [G loss: 0.618655]\n",
      "epoch:16 step:15573 [D loss: 0.515925, acc.: 75.00%] [G loss: 0.803867]\n",
      "epoch:16 step:15574 [D loss: 0.482669, acc.: 80.47%] [G loss: 0.780744]\n",
      "epoch:16 step:15575 [D loss: 0.639198, acc.: 61.72%] [G loss: 0.753532]\n",
      "epoch:16 step:15576 [D loss: 0.664454, acc.: 60.16%] [G loss: 0.640195]\n",
      "epoch:16 step:15577 [D loss: 0.542533, acc.: 74.22%] [G loss: 0.692957]\n",
      "epoch:16 step:15578 [D loss: 0.597970, acc.: 64.84%] [G loss: 0.520654]\n",
      "epoch:16 step:15579 [D loss: 0.605944, acc.: 61.72%] [G loss: 0.441234]\n",
      "epoch:16 step:15580 [D loss: 0.552463, acc.: 71.09%] [G loss: 0.558297]\n",
      "epoch:16 step:15581 [D loss: 0.510580, acc.: 75.00%] [G loss: 0.918716]\n",
      "epoch:16 step:15582 [D loss: 0.576163, acc.: 70.31%] [G loss: 0.629947]\n",
      "epoch:16 step:15583 [D loss: 0.553019, acc.: 67.97%] [G loss: 0.569843]\n",
      "epoch:16 step:15584 [D loss: 0.503158, acc.: 75.00%] [G loss: 0.651844]\n",
      "epoch:16 step:15585 [D loss: 0.466154, acc.: 78.91%] [G loss: 0.697313]\n",
      "epoch:16 step:15586 [D loss: 0.592321, acc.: 69.53%] [G loss: 0.695582]\n",
      "epoch:16 step:15587 [D loss: 0.519885, acc.: 75.78%] [G loss: 0.637768]\n",
      "epoch:16 step:15588 [D loss: 0.582975, acc.: 64.84%] [G loss: 0.461915]\n",
      "epoch:16 step:15589 [D loss: 0.572121, acc.: 70.31%] [G loss: 0.497645]\n",
      "epoch:16 step:15590 [D loss: 0.517568, acc.: 76.56%] [G loss: 0.707767]\n",
      "epoch:16 step:15591 [D loss: 0.549471, acc.: 68.75%] [G loss: 0.751740]\n",
      "epoch:16 step:15592 [D loss: 0.577774, acc.: 67.97%] [G loss: 0.620877]\n",
      "epoch:16 step:15593 [D loss: 0.569390, acc.: 67.97%] [G loss: 0.505624]\n",
      "epoch:16 step:15594 [D loss: 0.487023, acc.: 74.22%] [G loss: 0.737591]\n",
      "epoch:16 step:15595 [D loss: 0.483743, acc.: 79.69%] [G loss: 0.714704]\n",
      "epoch:16 step:15596 [D loss: 0.603814, acc.: 71.88%] [G loss: 0.734562]\n",
      "epoch:16 step:15597 [D loss: 0.428077, acc.: 75.00%] [G loss: 0.759399]\n",
      "epoch:16 step:15598 [D loss: 0.654474, acc.: 64.06%] [G loss: 0.508068]\n",
      "epoch:16 step:15599 [D loss: 0.485780, acc.: 72.66%] [G loss: 0.592808]\n",
      "epoch:16 step:15600 [D loss: 0.578667, acc.: 64.84%] [G loss: 0.496345]\n",
      "##############\n",
      "[3.1124931  1.59981466 6.11915749 4.97633047 3.78836295 5.70246362\n",
      " 4.58856191 4.73220721 4.48042816 4.19476341]\n",
      "##########\n",
      "epoch:16 step:15601 [D loss: 0.547599, acc.: 71.09%] [G loss: 0.446699]\n",
      "epoch:16 step:15602 [D loss: 0.561055, acc.: 70.31%] [G loss: 0.539928]\n",
      "epoch:16 step:15603 [D loss: 0.491380, acc.: 78.12%] [G loss: 0.584491]\n",
      "epoch:16 step:15604 [D loss: 0.522048, acc.: 71.09%] [G loss: 0.513371]\n",
      "epoch:16 step:15605 [D loss: 0.479333, acc.: 71.09%] [G loss: 0.539055]\n",
      "epoch:16 step:15606 [D loss: 0.572512, acc.: 65.62%] [G loss: 0.583385]\n",
      "epoch:16 step:15607 [D loss: 0.581448, acc.: 69.53%] [G loss: 0.518693]\n",
      "epoch:16 step:15608 [D loss: 0.622355, acc.: 63.28%] [G loss: 0.710860]\n",
      "epoch:16 step:15609 [D loss: 0.587687, acc.: 66.41%] [G loss: 0.644473]\n",
      "epoch:16 step:15610 [D loss: 0.554483, acc.: 65.62%] [G loss: 0.663281]\n",
      "epoch:16 step:15611 [D loss: 0.559965, acc.: 67.97%] [G loss: 0.656334]\n",
      "epoch:16 step:15612 [D loss: 0.481966, acc.: 77.34%] [G loss: 0.590295]\n",
      "epoch:16 step:15613 [D loss: 0.534189, acc.: 71.09%] [G loss: 0.560772]\n",
      "epoch:16 step:15614 [D loss: 0.537858, acc.: 70.31%] [G loss: 0.504385]\n",
      "epoch:16 step:15615 [D loss: 0.489002, acc.: 73.44%] [G loss: 0.623270]\n",
      "epoch:16 step:15616 [D loss: 0.468420, acc.: 79.69%] [G loss: 0.674418]\n",
      "epoch:16 step:15617 [D loss: 0.606385, acc.: 63.28%] [G loss: 0.552152]\n",
      "epoch:16 step:15618 [D loss: 0.507244, acc.: 71.88%] [G loss: 0.554371]\n",
      "epoch:16 step:15619 [D loss: 0.509565, acc.: 72.66%] [G loss: 0.673815]\n",
      "epoch:16 step:15620 [D loss: 0.571522, acc.: 69.53%] [G loss: 0.565565]\n",
      "epoch:16 step:15621 [D loss: 0.550286, acc.: 70.31%] [G loss: 0.721059]\n",
      "epoch:16 step:15622 [D loss: 0.555679, acc.: 72.66%] [G loss: 0.549054]\n",
      "epoch:16 step:15623 [D loss: 0.495532, acc.: 77.34%] [G loss: 0.645317]\n",
      "epoch:16 step:15624 [D loss: 0.518599, acc.: 75.00%] [G loss: 0.648917]\n",
      "epoch:16 step:15625 [D loss: 0.544584, acc.: 69.53%] [G loss: 0.672066]\n",
      "epoch:16 step:15626 [D loss: 0.473640, acc.: 78.91%] [G loss: 0.847208]\n",
      "epoch:16 step:15627 [D loss: 0.510447, acc.: 71.09%] [G loss: 0.794823]\n",
      "epoch:16 step:15628 [D loss: 0.610859, acc.: 66.41%] [G loss: 0.693517]\n",
      "epoch:16 step:15629 [D loss: 0.562389, acc.: 70.31%] [G loss: 0.530996]\n",
      "epoch:16 step:15630 [D loss: 0.497024, acc.: 78.91%] [G loss: 0.710660]\n",
      "epoch:16 step:15631 [D loss: 0.515465, acc.: 72.66%] [G loss: 0.603162]\n",
      "epoch:16 step:15632 [D loss: 0.530363, acc.: 72.66%] [G loss: 0.583455]\n",
      "epoch:16 step:15633 [D loss: 0.508420, acc.: 73.44%] [G loss: 0.609367]\n",
      "epoch:16 step:15634 [D loss: 0.532674, acc.: 67.97%] [G loss: 0.723582]\n",
      "epoch:16 step:15635 [D loss: 0.507020, acc.: 70.31%] [G loss: 0.828143]\n",
      "epoch:16 step:15636 [D loss: 0.568837, acc.: 67.19%] [G loss: 0.704806]\n",
      "epoch:16 step:15637 [D loss: 0.544893, acc.: 67.19%] [G loss: 0.572767]\n",
      "epoch:16 step:15638 [D loss: 0.570374, acc.: 68.75%] [G loss: 0.577927]\n",
      "epoch:16 step:15639 [D loss: 0.477890, acc.: 77.34%] [G loss: 0.696835]\n",
      "epoch:16 step:15640 [D loss: 0.389177, acc.: 84.38%] [G loss: 0.922979]\n",
      "epoch:16 step:15641 [D loss: 0.512438, acc.: 68.75%] [G loss: 0.653720]\n",
      "epoch:16 step:15642 [D loss: 0.489112, acc.: 75.78%] [G loss: 0.791089]\n",
      "epoch:16 step:15643 [D loss: 0.489632, acc.: 78.12%] [G loss: 0.628082]\n",
      "epoch:16 step:15644 [D loss: 0.685581, acc.: 61.72%] [G loss: 0.466311]\n",
      "epoch:16 step:15645 [D loss: 0.533241, acc.: 70.31%] [G loss: 0.534789]\n",
      "epoch:16 step:15646 [D loss: 0.569551, acc.: 69.53%] [G loss: 0.606838]\n",
      "epoch:16 step:15647 [D loss: 0.587908, acc.: 67.19%] [G loss: 0.704015]\n",
      "epoch:16 step:15648 [D loss: 0.516627, acc.: 75.78%] [G loss: 0.596423]\n",
      "epoch:16 step:15649 [D loss: 0.552761, acc.: 69.53%] [G loss: 0.664116]\n",
      "epoch:16 step:15650 [D loss: 0.583565, acc.: 66.41%] [G loss: 0.593988]\n",
      "epoch:16 step:15651 [D loss: 0.544585, acc.: 72.66%] [G loss: 0.607473]\n",
      "epoch:16 step:15652 [D loss: 0.505244, acc.: 75.00%] [G loss: 0.710368]\n",
      "epoch:16 step:15653 [D loss: 0.528250, acc.: 68.75%] [G loss: 0.633759]\n",
      "epoch:16 step:15654 [D loss: 0.501572, acc.: 74.22%] [G loss: 0.693306]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:16 step:15655 [D loss: 0.519155, acc.: 73.44%] [G loss: 0.691586]\n",
      "epoch:16 step:15656 [D loss: 0.528336, acc.: 69.53%] [G loss: 0.715635]\n",
      "epoch:16 step:15657 [D loss: 0.545363, acc.: 71.09%] [G loss: 0.514659]\n",
      "epoch:16 step:15658 [D loss: 0.538755, acc.: 72.66%] [G loss: 0.580055]\n",
      "epoch:16 step:15659 [D loss: 0.551257, acc.: 67.97%] [G loss: 0.715713]\n",
      "epoch:16 step:15660 [D loss: 0.569052, acc.: 68.75%] [G loss: 0.625512]\n",
      "epoch:16 step:15661 [D loss: 0.550692, acc.: 67.97%] [G loss: 0.559426]\n",
      "epoch:16 step:15662 [D loss: 0.530335, acc.: 68.75%] [G loss: 0.554616]\n",
      "epoch:16 step:15663 [D loss: 0.545961, acc.: 69.53%] [G loss: 0.625592]\n",
      "epoch:16 step:15664 [D loss: 0.611240, acc.: 72.66%] [G loss: 0.827448]\n",
      "epoch:16 step:15665 [D loss: 0.518597, acc.: 72.66%] [G loss: 0.642708]\n",
      "epoch:16 step:15666 [D loss: 0.621465, acc.: 66.41%] [G loss: 0.600433]\n",
      "epoch:16 step:15667 [D loss: 0.578736, acc.: 65.62%] [G loss: 0.579806]\n",
      "epoch:16 step:15668 [D loss: 0.520243, acc.: 74.22%] [G loss: 0.705090]\n",
      "epoch:16 step:15669 [D loss: 0.464275, acc.: 77.34%] [G loss: 0.657095]\n",
      "epoch:16 step:15670 [D loss: 0.571986, acc.: 67.19%] [G loss: 0.625473]\n",
      "epoch:16 step:15671 [D loss: 0.512349, acc.: 75.78%] [G loss: 0.723312]\n",
      "epoch:16 step:15672 [D loss: 0.546833, acc.: 75.78%] [G loss: 0.721438]\n",
      "epoch:16 step:15673 [D loss: 0.521268, acc.: 72.66%] [G loss: 0.741280]\n",
      "epoch:16 step:15674 [D loss: 0.538871, acc.: 73.44%] [G loss: 0.660278]\n",
      "epoch:16 step:15675 [D loss: 0.554445, acc.: 71.88%] [G loss: 0.600596]\n",
      "epoch:16 step:15676 [D loss: 0.596157, acc.: 67.19%] [G loss: 0.534505]\n",
      "epoch:16 step:15677 [D loss: 0.506754, acc.: 75.00%] [G loss: 0.617186]\n",
      "epoch:16 step:15678 [D loss: 0.609198, acc.: 67.19%] [G loss: 0.468507]\n",
      "epoch:16 step:15679 [D loss: 0.553485, acc.: 68.75%] [G loss: 0.545509]\n",
      "epoch:16 step:15680 [D loss: 0.667829, acc.: 58.59%] [G loss: 0.408041]\n",
      "epoch:16 step:15681 [D loss: 0.601803, acc.: 67.97%] [G loss: 0.541116]\n",
      "epoch:16 step:15682 [D loss: 0.498093, acc.: 78.12%] [G loss: 0.651248]\n",
      "epoch:16 step:15683 [D loss: 0.509099, acc.: 75.78%] [G loss: 0.609366]\n",
      "epoch:16 step:15684 [D loss: 0.535028, acc.: 69.53%] [G loss: 0.724885]\n",
      "epoch:16 step:15685 [D loss: 0.508029, acc.: 75.00%] [G loss: 0.703372]\n",
      "epoch:16 step:15686 [D loss: 0.486583, acc.: 75.78%] [G loss: 0.788082]\n",
      "epoch:16 step:15687 [D loss: 0.525447, acc.: 71.88%] [G loss: 0.597114]\n",
      "epoch:16 step:15688 [D loss: 0.641784, acc.: 62.50%] [G loss: 0.446484]\n",
      "epoch:16 step:15689 [D loss: 0.545385, acc.: 66.41%] [G loss: 0.492084]\n",
      "epoch:16 step:15690 [D loss: 0.554588, acc.: 68.75%] [G loss: 0.603398]\n",
      "epoch:16 step:15691 [D loss: 0.533726, acc.: 71.88%] [G loss: 0.560273]\n",
      "epoch:16 step:15692 [D loss: 0.498189, acc.: 69.53%] [G loss: 0.797319]\n",
      "epoch:16 step:15693 [D loss: 0.515422, acc.: 73.44%] [G loss: 0.627015]\n",
      "epoch:16 step:15694 [D loss: 0.544723, acc.: 68.75%] [G loss: 0.621236]\n",
      "epoch:16 step:15695 [D loss: 0.533730, acc.: 70.31%] [G loss: 0.644091]\n",
      "epoch:16 step:15696 [D loss: 0.617350, acc.: 62.50%] [G loss: 0.570618]\n",
      "epoch:16 step:15697 [D loss: 0.518069, acc.: 71.88%] [G loss: 0.550828]\n",
      "epoch:16 step:15698 [D loss: 0.523054, acc.: 77.34%] [G loss: 0.724984]\n",
      "epoch:16 step:15699 [D loss: 0.468739, acc.: 77.34%] [G loss: 0.888617]\n",
      "epoch:16 step:15700 [D loss: 0.533243, acc.: 76.56%] [G loss: 0.802263]\n",
      "epoch:16 step:15701 [D loss: 0.522471, acc.: 72.66%] [G loss: 0.713546]\n",
      "epoch:16 step:15702 [D loss: 0.588442, acc.: 68.75%] [G loss: 0.634070]\n",
      "epoch:16 step:15703 [D loss: 0.594083, acc.: 64.84%] [G loss: 0.558585]\n",
      "epoch:16 step:15704 [D loss: 0.516914, acc.: 71.88%] [G loss: 0.786144]\n",
      "epoch:16 step:15705 [D loss: 0.633865, acc.: 60.94%] [G loss: 0.655693]\n",
      "epoch:16 step:15706 [D loss: 0.544518, acc.: 71.09%] [G loss: 0.571558]\n",
      "epoch:16 step:15707 [D loss: 0.548894, acc.: 68.75%] [G loss: 0.638085]\n",
      "epoch:16 step:15708 [D loss: 0.596250, acc.: 66.41%] [G loss: 0.460000]\n",
      "epoch:16 step:15709 [D loss: 0.559991, acc.: 68.75%] [G loss: 0.551881]\n",
      "epoch:16 step:15710 [D loss: 0.625301, acc.: 64.84%] [G loss: 0.521201]\n",
      "epoch:16 step:15711 [D loss: 0.492331, acc.: 75.78%] [G loss: 0.667562]\n",
      "epoch:16 step:15712 [D loss: 0.614651, acc.: 67.97%] [G loss: 0.614133]\n",
      "epoch:16 step:15713 [D loss: 0.590177, acc.: 66.41%] [G loss: 0.534033]\n",
      "epoch:16 step:15714 [D loss: 0.561842, acc.: 71.09%] [G loss: 0.664123]\n",
      "epoch:16 step:15715 [D loss: 0.582937, acc.: 67.19%] [G loss: 0.531930]\n",
      "epoch:16 step:15716 [D loss: 0.478439, acc.: 78.12%] [G loss: 0.647648]\n",
      "epoch:16 step:15717 [D loss: 0.487923, acc.: 77.34%] [G loss: 0.711962]\n",
      "epoch:16 step:15718 [D loss: 0.566885, acc.: 71.09%] [G loss: 0.588492]\n",
      "epoch:16 step:15719 [D loss: 0.564101, acc.: 67.97%] [G loss: 0.654797]\n",
      "epoch:16 step:15720 [D loss: 0.537621, acc.: 70.31%] [G loss: 0.660049]\n",
      "epoch:16 step:15721 [D loss: 0.573771, acc.: 67.19%] [G loss: 0.645526]\n",
      "epoch:16 step:15722 [D loss: 0.494995, acc.: 72.66%] [G loss: 0.585308]\n",
      "epoch:16 step:15723 [D loss: 0.569016, acc.: 64.06%] [G loss: 0.620352]\n",
      "epoch:16 step:15724 [D loss: 0.514831, acc.: 74.22%] [G loss: 0.587784]\n",
      "epoch:16 step:15725 [D loss: 0.558301, acc.: 66.41%] [G loss: 0.657487]\n",
      "epoch:16 step:15726 [D loss: 0.591132, acc.: 65.62%] [G loss: 0.633878]\n",
      "epoch:16 step:15727 [D loss: 0.524638, acc.: 70.31%] [G loss: 0.686236]\n",
      "epoch:16 step:15728 [D loss: 0.502438, acc.: 75.00%] [G loss: 0.809077]\n",
      "epoch:16 step:15729 [D loss: 0.477425, acc.: 78.12%] [G loss: 0.733892]\n",
      "epoch:16 step:15730 [D loss: 0.544796, acc.: 67.19%] [G loss: 0.587674]\n",
      "epoch:16 step:15731 [D loss: 0.629134, acc.: 65.62%] [G loss: 0.533144]\n",
      "epoch:16 step:15732 [D loss: 0.629224, acc.: 58.59%] [G loss: 0.345538]\n",
      "epoch:16 step:15733 [D loss: 0.602032, acc.: 67.19%] [G loss: 0.549206]\n",
      "epoch:16 step:15734 [D loss: 0.582055, acc.: 73.44%] [G loss: 0.616147]\n",
      "epoch:16 step:15735 [D loss: 0.505634, acc.: 79.69%] [G loss: 0.689721]\n",
      "epoch:16 step:15736 [D loss: 0.606084, acc.: 70.31%] [G loss: 0.493644]\n",
      "epoch:16 step:15737 [D loss: 0.567174, acc.: 67.19%] [G loss: 0.661459]\n",
      "epoch:16 step:15738 [D loss: 0.450098, acc.: 74.22%] [G loss: 0.676852]\n",
      "epoch:16 step:15739 [D loss: 0.451690, acc.: 77.34%] [G loss: 0.791914]\n",
      "epoch:16 step:15740 [D loss: 0.518466, acc.: 71.09%] [G loss: 0.844856]\n",
      "epoch:16 step:15741 [D loss: 0.536288, acc.: 75.78%] [G loss: 0.713431]\n",
      "epoch:16 step:15742 [D loss: 0.504370, acc.: 75.78%] [G loss: 0.789585]\n",
      "epoch:16 step:15743 [D loss: 0.524391, acc.: 74.22%] [G loss: 0.832064]\n",
      "epoch:16 step:15744 [D loss: 0.605936, acc.: 64.06%] [G loss: 0.796042]\n",
      "epoch:16 step:15745 [D loss: 0.549867, acc.: 73.44%] [G loss: 0.786311]\n",
      "epoch:16 step:15746 [D loss: 0.558465, acc.: 67.19%] [G loss: 0.731858]\n",
      "epoch:16 step:15747 [D loss: 0.582410, acc.: 67.19%] [G loss: 0.569540]\n",
      "epoch:16 step:15748 [D loss: 0.595533, acc.: 70.31%] [G loss: 0.627557]\n",
      "epoch:16 step:15749 [D loss: 0.541671, acc.: 69.53%] [G loss: 0.642426]\n",
      "epoch:16 step:15750 [D loss: 0.529414, acc.: 72.66%] [G loss: 0.757172]\n",
      "epoch:16 step:15751 [D loss: 0.573220, acc.: 64.84%] [G loss: 0.567551]\n",
      "epoch:16 step:15752 [D loss: 0.524890, acc.: 69.53%] [G loss: 0.564657]\n",
      "epoch:16 step:15753 [D loss: 0.501828, acc.: 75.78%] [G loss: 0.753269]\n",
      "epoch:16 step:15754 [D loss: 0.558248, acc.: 69.53%] [G loss: 0.598341]\n",
      "epoch:16 step:15755 [D loss: 0.513433, acc.: 71.88%] [G loss: 0.505973]\n",
      "epoch:16 step:15756 [D loss: 0.581504, acc.: 65.62%] [G loss: 0.656099]\n",
      "epoch:16 step:15757 [D loss: 0.576026, acc.: 68.75%] [G loss: 0.522020]\n",
      "epoch:16 step:15758 [D loss: 0.658401, acc.: 58.59%] [G loss: 0.436060]\n",
      "epoch:16 step:15759 [D loss: 0.544115, acc.: 75.78%] [G loss: 0.488942]\n",
      "epoch:16 step:15760 [D loss: 0.555012, acc.: 67.19%] [G loss: 0.728720]\n",
      "epoch:16 step:15761 [D loss: 0.522183, acc.: 71.88%] [G loss: 0.884359]\n",
      "epoch:16 step:15762 [D loss: 0.572859, acc.: 73.44%] [G loss: 0.882406]\n",
      "epoch:16 step:15763 [D loss: 0.530903, acc.: 74.22%] [G loss: 0.881819]\n",
      "epoch:16 step:15764 [D loss: 0.548675, acc.: 70.31%] [G loss: 0.628703]\n",
      "epoch:16 step:15765 [D loss: 0.561450, acc.: 70.31%] [G loss: 0.525630]\n",
      "epoch:16 step:15766 [D loss: 0.531701, acc.: 70.31%] [G loss: 0.601062]\n",
      "epoch:16 step:15767 [D loss: 0.498779, acc.: 74.22%] [G loss: 0.626515]\n",
      "epoch:16 step:15768 [D loss: 0.589163, acc.: 67.97%] [G loss: 0.549257]\n",
      "epoch:16 step:15769 [D loss: 0.557719, acc.: 71.09%] [G loss: 0.646249]\n",
      "epoch:16 step:15770 [D loss: 0.554812, acc.: 67.97%] [G loss: 0.601088]\n",
      "epoch:16 step:15771 [D loss: 0.559884, acc.: 67.19%] [G loss: 0.635059]\n",
      "epoch:16 step:15772 [D loss: 0.549733, acc.: 71.88%] [G loss: 0.704851]\n",
      "epoch:16 step:15773 [D loss: 0.496364, acc.: 71.88%] [G loss: 0.756320]\n",
      "epoch:16 step:15774 [D loss: 0.548921, acc.: 72.66%] [G loss: 0.638906]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:16 step:15775 [D loss: 0.563328, acc.: 64.84%] [G loss: 0.771979]\n",
      "epoch:16 step:15776 [D loss: 0.632542, acc.: 64.06%] [G loss: 0.528167]\n",
      "epoch:16 step:15777 [D loss: 0.512772, acc.: 75.78%] [G loss: 0.620133]\n",
      "epoch:16 step:15778 [D loss: 0.541050, acc.: 71.88%] [G loss: 0.662758]\n",
      "epoch:16 step:15779 [D loss: 0.583539, acc.: 68.75%] [G loss: 0.507719]\n",
      "epoch:16 step:15780 [D loss: 0.680986, acc.: 54.69%] [G loss: 0.543908]\n",
      "epoch:16 step:15781 [D loss: 0.547985, acc.: 64.84%] [G loss: 0.538888]\n",
      "epoch:16 step:15782 [D loss: 0.548015, acc.: 67.97%] [G loss: 0.549917]\n",
      "epoch:16 step:15783 [D loss: 0.504649, acc.: 74.22%] [G loss: 0.696958]\n",
      "epoch:16 step:15784 [D loss: 0.465416, acc.: 75.78%] [G loss: 0.547099]\n",
      "epoch:16 step:15785 [D loss: 0.605751, acc.: 70.31%] [G loss: 0.697367]\n",
      "epoch:16 step:15786 [D loss: 0.675000, acc.: 61.72%] [G loss: 0.574984]\n",
      "epoch:16 step:15787 [D loss: 0.536325, acc.: 64.84%] [G loss: 0.673544]\n",
      "epoch:16 step:15788 [D loss: 0.539510, acc.: 67.19%] [G loss: 0.793528]\n",
      "epoch:16 step:15789 [D loss: 0.536729, acc.: 69.53%] [G loss: 0.602204]\n",
      "epoch:16 step:15790 [D loss: 0.531929, acc.: 70.31%] [G loss: 0.528890]\n",
      "epoch:16 step:15791 [D loss: 0.564535, acc.: 67.97%] [G loss: 0.628428]\n",
      "epoch:16 step:15792 [D loss: 0.589597, acc.: 66.41%] [G loss: 0.421067]\n",
      "epoch:16 step:15793 [D loss: 0.526747, acc.: 74.22%] [G loss: 0.712277]\n",
      "epoch:16 step:15794 [D loss: 0.478692, acc.: 74.22%] [G loss: 0.649718]\n",
      "epoch:16 step:15795 [D loss: 0.484908, acc.: 72.66%] [G loss: 0.592340]\n",
      "epoch:16 step:15796 [D loss: 0.531339, acc.: 70.31%] [G loss: 0.739807]\n",
      "epoch:16 step:15797 [D loss: 0.525725, acc.: 69.53%] [G loss: 0.647206]\n",
      "epoch:16 step:15798 [D loss: 0.503865, acc.: 76.56%] [G loss: 0.615034]\n",
      "epoch:16 step:15799 [D loss: 0.507174, acc.: 71.88%] [G loss: 0.543567]\n",
      "epoch:16 step:15800 [D loss: 0.598494, acc.: 66.41%] [G loss: 0.528868]\n",
      "##############\n",
      "[3.13629878 0.88797483 6.12651864 4.63174313 3.66308845 5.72271283\n",
      " 4.5312203  4.96134279 4.5572887  3.97040795]\n",
      "##########\n",
      "epoch:16 step:15801 [D loss: 0.577724, acc.: 68.75%] [G loss: 0.598186]\n",
      "epoch:16 step:15802 [D loss: 0.512809, acc.: 72.66%] [G loss: 0.623998]\n",
      "epoch:16 step:15803 [D loss: 0.566981, acc.: 66.41%] [G loss: 0.576042]\n",
      "epoch:16 step:15804 [D loss: 0.634677, acc.: 64.06%] [G loss: 0.470585]\n",
      "epoch:16 step:15805 [D loss: 0.516763, acc.: 71.88%] [G loss: 0.559653]\n",
      "epoch:16 step:15806 [D loss: 0.478736, acc.: 73.44%] [G loss: 0.783053]\n",
      "epoch:16 step:15807 [D loss: 0.465864, acc.: 78.91%] [G loss: 0.735302]\n",
      "epoch:16 step:15808 [D loss: 0.532391, acc.: 73.44%] [G loss: 0.834651]\n",
      "epoch:16 step:15809 [D loss: 0.703811, acc.: 61.72%] [G loss: 0.710829]\n",
      "epoch:16 step:15810 [D loss: 0.589648, acc.: 64.84%] [G loss: 0.630495]\n",
      "epoch:16 step:15811 [D loss: 0.563778, acc.: 65.62%] [G loss: 0.549924]\n",
      "epoch:16 step:15812 [D loss: 0.627720, acc.: 67.97%] [G loss: 0.532178]\n",
      "epoch:16 step:15813 [D loss: 0.542003, acc.: 67.19%] [G loss: 0.570612]\n",
      "epoch:16 step:15814 [D loss: 0.550418, acc.: 67.97%] [G loss: 0.552535]\n",
      "epoch:16 step:15815 [D loss: 0.440181, acc.: 78.12%] [G loss: 0.563138]\n",
      "epoch:16 step:15816 [D loss: 0.562335, acc.: 71.88%] [G loss: 0.613518]\n",
      "epoch:16 step:15817 [D loss: 0.529266, acc.: 71.88%] [G loss: 0.588516]\n",
      "epoch:16 step:15818 [D loss: 0.530454, acc.: 67.19%] [G loss: 0.563193]\n",
      "epoch:16 step:15819 [D loss: 0.554951, acc.: 67.19%] [G loss: 0.511070]\n",
      "epoch:16 step:15820 [D loss: 0.596908, acc.: 67.19%] [G loss: 0.495358]\n",
      "epoch:16 step:15821 [D loss: 0.585135, acc.: 62.50%] [G loss: 0.557509]\n",
      "epoch:16 step:15822 [D loss: 0.575990, acc.: 67.19%] [G loss: 0.663868]\n",
      "epoch:16 step:15823 [D loss: 0.543549, acc.: 71.09%] [G loss: 0.622811]\n",
      "epoch:16 step:15824 [D loss: 0.555100, acc.: 68.75%] [G loss: 0.604030]\n",
      "epoch:16 step:15825 [D loss: 0.558027, acc.: 71.09%] [G loss: 0.662768]\n",
      "epoch:16 step:15826 [D loss: 0.553986, acc.: 67.19%] [G loss: 0.507607]\n",
      "epoch:16 step:15827 [D loss: 0.546816, acc.: 66.41%] [G loss: 0.487236]\n",
      "epoch:16 step:15828 [D loss: 0.557910, acc.: 70.31%] [G loss: 0.604788]\n",
      "epoch:16 step:15829 [D loss: 0.532410, acc.: 70.31%] [G loss: 0.683297]\n",
      "epoch:16 step:15830 [D loss: 0.540359, acc.: 70.31%] [G loss: 0.561157]\n",
      "epoch:16 step:15831 [D loss: 0.592010, acc.: 62.50%] [G loss: 0.628847]\n",
      "epoch:16 step:15832 [D loss: 0.569941, acc.: 67.19%] [G loss: 0.555427]\n",
      "epoch:16 step:15833 [D loss: 0.518718, acc.: 71.88%] [G loss: 0.528269]\n",
      "epoch:16 step:15834 [D loss: 0.492818, acc.: 75.78%] [G loss: 0.589440]\n",
      "epoch:16 step:15835 [D loss: 0.515727, acc.: 75.78%] [G loss: 0.501091]\n",
      "epoch:16 step:15836 [D loss: 0.563003, acc.: 67.19%] [G loss: 0.498860]\n",
      "epoch:16 step:15837 [D loss: 0.510700, acc.: 73.44%] [G loss: 0.487876]\n",
      "epoch:16 step:15838 [D loss: 0.619333, acc.: 62.50%] [G loss: 0.508142]\n",
      "epoch:16 step:15839 [D loss: 0.658659, acc.: 59.38%] [G loss: 0.442137]\n",
      "epoch:16 step:15840 [D loss: 0.506126, acc.: 71.88%] [G loss: 0.585844]\n",
      "epoch:16 step:15841 [D loss: 0.601239, acc.: 64.06%] [G loss: 0.523611]\n",
      "epoch:16 step:15842 [D loss: 0.569659, acc.: 71.88%] [G loss: 0.547790]\n",
      "epoch:16 step:15843 [D loss: 0.571773, acc.: 67.19%] [G loss: 0.484421]\n",
      "epoch:16 step:15844 [D loss: 0.538645, acc.: 72.66%] [G loss: 0.537089]\n",
      "epoch:16 step:15845 [D loss: 0.625246, acc.: 64.06%] [G loss: 0.531925]\n",
      "epoch:16 step:15846 [D loss: 0.504804, acc.: 74.22%] [G loss: 0.722212]\n",
      "epoch:16 step:15847 [D loss: 0.507603, acc.: 73.44%] [G loss: 0.692812]\n",
      "epoch:16 step:15848 [D loss: 0.594738, acc.: 64.06%] [G loss: 0.551034]\n",
      "epoch:16 step:15849 [D loss: 0.452039, acc.: 79.69%] [G loss: 0.634728]\n",
      "epoch:16 step:15850 [D loss: 0.670287, acc.: 60.94%] [G loss: 0.395967]\n",
      "epoch:16 step:15851 [D loss: 0.620461, acc.: 67.19%] [G loss: 0.634238]\n",
      "epoch:16 step:15852 [D loss: 0.445969, acc.: 75.78%] [G loss: 0.683026]\n",
      "epoch:16 step:15853 [D loss: 0.633938, acc.: 65.62%] [G loss: 0.775648]\n",
      "epoch:16 step:15854 [D loss: 0.562720, acc.: 65.62%] [G loss: 0.688225]\n",
      "epoch:16 step:15855 [D loss: 0.583002, acc.: 70.31%] [G loss: 0.521673]\n",
      "epoch:16 step:15856 [D loss: 0.505268, acc.: 73.44%] [G loss: 0.722001]\n",
      "epoch:16 step:15857 [D loss: 0.611601, acc.: 60.16%] [G loss: 0.541721]\n",
      "epoch:16 step:15858 [D loss: 0.561630, acc.: 68.75%] [G loss: 0.518328]\n",
      "epoch:16 step:15859 [D loss: 0.654979, acc.: 60.94%] [G loss: 0.516257]\n",
      "epoch:16 step:15860 [D loss: 0.563279, acc.: 66.41%] [G loss: 0.556128]\n",
      "epoch:16 step:15861 [D loss: 0.559343, acc.: 68.75%] [G loss: 0.587589]\n",
      "epoch:16 step:15862 [D loss: 0.463958, acc.: 72.66%] [G loss: 0.654116]\n",
      "epoch:16 step:15863 [D loss: 0.489824, acc.: 74.22%] [G loss: 0.700290]\n",
      "epoch:16 step:15864 [D loss: 0.501586, acc.: 75.00%] [G loss: 0.708301]\n",
      "epoch:16 step:15865 [D loss: 0.591768, acc.: 65.62%] [G loss: 0.632871]\n",
      "epoch:16 step:15866 [D loss: 0.558080, acc.: 65.62%] [G loss: 0.679081]\n",
      "epoch:16 step:15867 [D loss: 0.482736, acc.: 76.56%] [G loss: 0.686907]\n",
      "epoch:16 step:15868 [D loss: 0.609230, acc.: 67.19%] [G loss: 0.473785]\n",
      "epoch:16 step:15869 [D loss: 0.592693, acc.: 67.19%] [G loss: 0.546143]\n",
      "epoch:16 step:15870 [D loss: 0.564444, acc.: 67.19%] [G loss: 0.483913]\n",
      "epoch:16 step:15871 [D loss: 0.565684, acc.: 68.75%] [G loss: 0.555394]\n",
      "epoch:16 step:15872 [D loss: 0.669676, acc.: 56.25%] [G loss: 0.454507]\n",
      "epoch:16 step:15873 [D loss: 0.573027, acc.: 71.09%] [G loss: 0.398741]\n",
      "epoch:16 step:15874 [D loss: 0.545731, acc.: 71.09%] [G loss: 0.538153]\n",
      "epoch:16 step:15875 [D loss: 0.615012, acc.: 70.31%] [G loss: 0.447964]\n",
      "epoch:16 step:15876 [D loss: 0.477633, acc.: 75.78%] [G loss: 0.566302]\n",
      "epoch:16 step:15877 [D loss: 0.549098, acc.: 66.41%] [G loss: 0.711859]\n",
      "epoch:16 step:15878 [D loss: 0.520121, acc.: 71.09%] [G loss: 0.792347]\n",
      "epoch:16 step:15879 [D loss: 0.503316, acc.: 75.78%] [G loss: 0.708619]\n",
      "epoch:16 step:15880 [D loss: 0.531220, acc.: 74.22%] [G loss: 0.637204]\n",
      "epoch:16 step:15881 [D loss: 0.515755, acc.: 69.53%] [G loss: 0.935091]\n",
      "epoch:16 step:15882 [D loss: 0.480335, acc.: 77.34%] [G loss: 0.578115]\n",
      "epoch:16 step:15883 [D loss: 0.608650, acc.: 63.28%] [G loss: 0.575984]\n",
      "epoch:16 step:15884 [D loss: 0.658777, acc.: 62.50%] [G loss: 0.514950]\n",
      "epoch:16 step:15885 [D loss: 0.568883, acc.: 69.53%] [G loss: 0.626916]\n",
      "epoch:16 step:15886 [D loss: 0.479286, acc.: 75.00%] [G loss: 0.762615]\n",
      "epoch:16 step:15887 [D loss: 0.554477, acc.: 74.22%] [G loss: 0.654035]\n",
      "epoch:16 step:15888 [D loss: 0.498382, acc.: 74.22%] [G loss: 0.755403]\n",
      "epoch:16 step:15889 [D loss: 0.524055, acc.: 72.66%] [G loss: 0.762529]\n",
      "epoch:16 step:15890 [D loss: 0.464502, acc.: 75.78%] [G loss: 0.711207]\n",
      "epoch:16 step:15891 [D loss: 0.485995, acc.: 78.12%] [G loss: 0.884890]\n",
      "epoch:16 step:15892 [D loss: 0.514265, acc.: 75.00%] [G loss: 0.982129]\n",
      "epoch:16 step:15893 [D loss: 0.462853, acc.: 78.91%] [G loss: 0.740204]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:16 step:15894 [D loss: 0.593278, acc.: 64.84%] [G loss: 0.631032]\n",
      "epoch:16 step:15895 [D loss: 0.560892, acc.: 67.97%] [G loss: 0.669645]\n",
      "epoch:16 step:15896 [D loss: 0.585078, acc.: 67.97%] [G loss: 0.600244]\n",
      "epoch:16 step:15897 [D loss: 0.640331, acc.: 66.41%] [G loss: 0.500252]\n",
      "epoch:16 step:15898 [D loss: 0.476178, acc.: 77.34%] [G loss: 0.701768]\n",
      "epoch:16 step:15899 [D loss: 0.588479, acc.: 63.28%] [G loss: 0.729969]\n",
      "epoch:16 step:15900 [D loss: 0.472978, acc.: 82.03%] [G loss: 0.786336]\n",
      "epoch:16 step:15901 [D loss: 0.519691, acc.: 67.97%] [G loss: 0.729285]\n",
      "epoch:16 step:15902 [D loss: 0.592238, acc.: 69.53%] [G loss: 0.704416]\n",
      "epoch:16 step:15903 [D loss: 0.459576, acc.: 78.91%] [G loss: 0.575537]\n",
      "epoch:16 step:15904 [D loss: 0.513501, acc.: 73.44%] [G loss: 0.882305]\n",
      "epoch:16 step:15905 [D loss: 0.506887, acc.: 73.44%] [G loss: 0.835883]\n",
      "epoch:16 step:15906 [D loss: 0.483167, acc.: 75.00%] [G loss: 0.931077]\n",
      "epoch:16 step:15907 [D loss: 0.663324, acc.: 61.72%] [G loss: 0.646213]\n",
      "epoch:16 step:15908 [D loss: 0.520677, acc.: 75.00%] [G loss: 0.608436]\n",
      "epoch:16 step:15909 [D loss: 0.611031, acc.: 64.84%] [G loss: 0.586835]\n",
      "epoch:16 step:15910 [D loss: 0.516530, acc.: 71.88%] [G loss: 0.710060]\n",
      "epoch:16 step:15911 [D loss: 0.482575, acc.: 75.78%] [G loss: 0.830096]\n",
      "epoch:16 step:15912 [D loss: 0.718119, acc.: 64.06%] [G loss: 0.618322]\n",
      "epoch:16 step:15913 [D loss: 0.497224, acc.: 73.44%] [G loss: 0.639917]\n",
      "epoch:16 step:15914 [D loss: 0.559567, acc.: 71.88%] [G loss: 0.663812]\n",
      "epoch:16 step:15915 [D loss: 0.452480, acc.: 79.69%] [G loss: 0.762744]\n",
      "epoch:16 step:15916 [D loss: 0.497566, acc.: 75.00%] [G loss: 0.812674]\n",
      "epoch:16 step:15917 [D loss: 0.378880, acc.: 85.94%] [G loss: 0.999922]\n",
      "epoch:16 step:15918 [D loss: 0.410023, acc.: 82.03%] [G loss: 1.162022]\n",
      "epoch:16 step:15919 [D loss: 0.475271, acc.: 75.78%] [G loss: 1.084917]\n",
      "epoch:16 step:15920 [D loss: 0.648719, acc.: 64.84%] [G loss: 0.962524]\n",
      "epoch:16 step:15921 [D loss: 0.399794, acc.: 82.03%] [G loss: 1.368760]\n",
      "epoch:16 step:15922 [D loss: 0.492415, acc.: 71.88%] [G loss: 1.099271]\n",
      "epoch:16 step:15923 [D loss: 0.565188, acc.: 68.75%] [G loss: 1.047671]\n",
      "epoch:16 step:15924 [D loss: 0.586691, acc.: 67.19%] [G loss: 0.715570]\n",
      "epoch:16 step:15925 [D loss: 0.520292, acc.: 74.22%] [G loss: 0.858159]\n",
      "epoch:16 step:15926 [D loss: 0.664100, acc.: 65.62%] [G loss: 1.018948]\n",
      "epoch:16 step:15927 [D loss: 0.443112, acc.: 79.69%] [G loss: 1.091045]\n",
      "epoch:16 step:15928 [D loss: 0.337580, acc.: 89.06%] [G loss: 1.395557]\n",
      "epoch:16 step:15929 [D loss: 0.416876, acc.: 80.47%] [G loss: 1.517591]\n",
      "epoch:17 step:15930 [D loss: 0.610541, acc.: 67.19%] [G loss: 0.916082]\n",
      "epoch:17 step:15931 [D loss: 0.498298, acc.: 74.22%] [G loss: 0.985433]\n",
      "epoch:17 step:15932 [D loss: 0.532811, acc.: 76.56%] [G loss: 0.973881]\n",
      "epoch:17 step:15933 [D loss: 0.517867, acc.: 73.44%] [G loss: 0.734805]\n",
      "epoch:17 step:15934 [D loss: 0.590478, acc.: 70.31%] [G loss: 0.617331]\n",
      "epoch:17 step:15935 [D loss: 0.629461, acc.: 66.41%] [G loss: 0.728773]\n",
      "epoch:17 step:15936 [D loss: 0.501910, acc.: 73.44%] [G loss: 0.735145]\n",
      "epoch:17 step:15937 [D loss: 0.513869, acc.: 76.56%] [G loss: 0.646909]\n",
      "epoch:17 step:15938 [D loss: 0.499533, acc.: 75.00%] [G loss: 0.753676]\n",
      "epoch:17 step:15939 [D loss: 0.545769, acc.: 72.66%] [G loss: 0.837171]\n",
      "epoch:17 step:15940 [D loss: 0.447563, acc.: 81.25%] [G loss: 0.808082]\n",
      "epoch:17 step:15941 [D loss: 0.605434, acc.: 64.84%] [G loss: 0.648531]\n",
      "epoch:17 step:15942 [D loss: 0.556862, acc.: 71.88%] [G loss: 0.573638]\n",
      "epoch:17 step:15943 [D loss: 0.530484, acc.: 69.53%] [G loss: 0.730141]\n",
      "epoch:17 step:15944 [D loss: 0.506582, acc.: 77.34%] [G loss: 0.605283]\n",
      "epoch:17 step:15945 [D loss: 0.472115, acc.: 74.22%] [G loss: 0.804312]\n",
      "epoch:17 step:15946 [D loss: 0.588152, acc.: 67.97%] [G loss: 0.686621]\n",
      "epoch:17 step:15947 [D loss: 0.556808, acc.: 70.31%] [G loss: 0.602369]\n",
      "epoch:17 step:15948 [D loss: 0.555200, acc.: 70.31%] [G loss: 0.638932]\n",
      "epoch:17 step:15949 [D loss: 0.616362, acc.: 69.53%] [G loss: 0.667591]\n",
      "epoch:17 step:15950 [D loss: 0.598587, acc.: 64.06%] [G loss: 0.688927]\n",
      "epoch:17 step:15951 [D loss: 0.511772, acc.: 71.09%] [G loss: 0.851625]\n",
      "epoch:17 step:15952 [D loss: 0.578937, acc.: 64.84%] [G loss: 0.634159]\n",
      "epoch:17 step:15953 [D loss: 0.517264, acc.: 73.44%] [G loss: 0.673659]\n",
      "epoch:17 step:15954 [D loss: 0.507740, acc.: 75.78%] [G loss: 0.598135]\n",
      "epoch:17 step:15955 [D loss: 0.626591, acc.: 63.28%] [G loss: 0.609060]\n",
      "epoch:17 step:15956 [D loss: 0.453860, acc.: 75.00%] [G loss: 0.627175]\n",
      "epoch:17 step:15957 [D loss: 0.530735, acc.: 71.09%] [G loss: 0.667582]\n",
      "epoch:17 step:15958 [D loss: 0.505707, acc.: 76.56%] [G loss: 0.600510]\n",
      "epoch:17 step:15959 [D loss: 0.532102, acc.: 71.88%] [G loss: 0.740368]\n",
      "epoch:17 step:15960 [D loss: 0.562740, acc.: 67.19%] [G loss: 0.638462]\n",
      "epoch:17 step:15961 [D loss: 0.556487, acc.: 67.19%] [G loss: 0.644053]\n",
      "epoch:17 step:15962 [D loss: 0.495980, acc.: 77.34%] [G loss: 0.683097]\n",
      "epoch:17 step:15963 [D loss: 0.505608, acc.: 76.56%] [G loss: 0.617972]\n",
      "epoch:17 step:15964 [D loss: 0.543065, acc.: 71.88%] [G loss: 0.832286]\n",
      "epoch:17 step:15965 [D loss: 0.529066, acc.: 68.75%] [G loss: 0.622214]\n",
      "epoch:17 step:15966 [D loss: 0.502657, acc.: 73.44%] [G loss: 0.736710]\n",
      "epoch:17 step:15967 [D loss: 0.627448, acc.: 65.62%] [G loss: 0.528854]\n",
      "epoch:17 step:15968 [D loss: 0.504023, acc.: 77.34%] [G loss: 0.545793]\n",
      "epoch:17 step:15969 [D loss: 0.436021, acc.: 78.91%] [G loss: 0.784200]\n",
      "epoch:17 step:15970 [D loss: 0.586904, acc.: 65.62%] [G loss: 0.705895]\n",
      "epoch:17 step:15971 [D loss: 0.501648, acc.: 78.91%] [G loss: 0.767797]\n",
      "epoch:17 step:15972 [D loss: 0.564650, acc.: 67.97%] [G loss: 0.830560]\n",
      "epoch:17 step:15973 [D loss: 0.609976, acc.: 64.06%] [G loss: 0.564337]\n",
      "epoch:17 step:15974 [D loss: 0.490751, acc.: 75.78%] [G loss: 0.948587]\n",
      "epoch:17 step:15975 [D loss: 0.511282, acc.: 75.00%] [G loss: 0.769701]\n",
      "epoch:17 step:15976 [D loss: 0.595608, acc.: 69.53%] [G loss: 0.701173]\n",
      "epoch:17 step:15977 [D loss: 0.498077, acc.: 78.12%] [G loss: 0.678460]\n",
      "epoch:17 step:15978 [D loss: 0.494558, acc.: 75.78%] [G loss: 0.715248]\n",
      "epoch:17 step:15979 [D loss: 0.563717, acc.: 65.62%] [G loss: 0.611102]\n",
      "epoch:17 step:15980 [D loss: 0.668815, acc.: 62.50%] [G loss: 0.429749]\n",
      "epoch:17 step:15981 [D loss: 0.593193, acc.: 70.31%] [G loss: 0.557839]\n",
      "epoch:17 step:15982 [D loss: 0.534955, acc.: 70.31%] [G loss: 0.677829]\n",
      "epoch:17 step:15983 [D loss: 0.454746, acc.: 82.03%] [G loss: 0.816052]\n",
      "epoch:17 step:15984 [D loss: 0.530785, acc.: 73.44%] [G loss: 0.773173]\n",
      "epoch:17 step:15985 [D loss: 0.520900, acc.: 74.22%] [G loss: 0.735587]\n",
      "epoch:17 step:15986 [D loss: 0.488451, acc.: 76.56%] [G loss: 0.765668]\n",
      "epoch:17 step:15987 [D loss: 0.558961, acc.: 69.53%] [G loss: 0.519251]\n",
      "epoch:17 step:15988 [D loss: 0.479440, acc.: 75.78%] [G loss: 0.713566]\n",
      "epoch:17 step:15989 [D loss: 0.541355, acc.: 71.88%] [G loss: 0.659500]\n",
      "epoch:17 step:15990 [D loss: 0.569513, acc.: 66.41%] [G loss: 0.685320]\n",
      "epoch:17 step:15991 [D loss: 0.563384, acc.: 75.00%] [G loss: 0.560330]\n",
      "epoch:17 step:15992 [D loss: 0.588853, acc.: 66.41%] [G loss: 0.544037]\n",
      "epoch:17 step:15993 [D loss: 0.564949, acc.: 71.88%] [G loss: 0.527548]\n",
      "epoch:17 step:15994 [D loss: 0.510802, acc.: 75.78%] [G loss: 0.545492]\n",
      "epoch:17 step:15995 [D loss: 0.547897, acc.: 70.31%] [G loss: 0.537991]\n",
      "epoch:17 step:15996 [D loss: 0.575759, acc.: 66.41%] [G loss: 0.549922]\n",
      "epoch:17 step:15997 [D loss: 0.534280, acc.: 70.31%] [G loss: 0.609530]\n",
      "epoch:17 step:15998 [D loss: 0.509616, acc.: 74.22%] [G loss: 0.669079]\n",
      "epoch:17 step:15999 [D loss: 0.503383, acc.: 77.34%] [G loss: 0.655962]\n",
      "epoch:17 step:16000 [D loss: 0.542809, acc.: 74.22%] [G loss: 0.498995]\n",
      "##############\n",
      "[2.71037991 1.43147533 6.0022217  4.74531076 3.90944365 5.80248816\n",
      " 4.55188549 4.85906443 4.66621917 4.09880605]\n",
      "##########\n",
      "epoch:17 step:16001 [D loss: 0.546150, acc.: 69.53%] [G loss: 0.654567]\n",
      "epoch:17 step:16002 [D loss: 0.534600, acc.: 73.44%] [G loss: 0.572219]\n",
      "epoch:17 step:16003 [D loss: 0.503339, acc.: 74.22%] [G loss: 0.622551]\n",
      "epoch:17 step:16004 [D loss: 0.486615, acc.: 73.44%] [G loss: 0.713390]\n",
      "epoch:17 step:16005 [D loss: 0.541729, acc.: 70.31%] [G loss: 0.722905]\n",
      "epoch:17 step:16006 [D loss: 0.492284, acc.: 71.88%] [G loss: 0.652804]\n",
      "epoch:17 step:16007 [D loss: 0.575494, acc.: 68.75%] [G loss: 0.539610]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:17 step:16008 [D loss: 0.567174, acc.: 66.41%] [G loss: 0.666123]\n",
      "epoch:17 step:16009 [D loss: 0.497438, acc.: 75.78%] [G loss: 0.630172]\n",
      "epoch:17 step:16010 [D loss: 0.534733, acc.: 71.09%] [G loss: 0.727061]\n",
      "epoch:17 step:16011 [D loss: 0.506375, acc.: 71.88%] [G loss: 0.729934]\n",
      "epoch:17 step:16012 [D loss: 0.507534, acc.: 73.44%] [G loss: 0.743925]\n",
      "epoch:17 step:16013 [D loss: 0.501127, acc.: 74.22%] [G loss: 0.799919]\n",
      "epoch:17 step:16014 [D loss: 0.547433, acc.: 68.75%] [G loss: 0.613762]\n",
      "epoch:17 step:16015 [D loss: 0.600906, acc.: 67.19%] [G loss: 0.528147]\n",
      "epoch:17 step:16016 [D loss: 0.562783, acc.: 70.31%] [G loss: 0.513702]\n",
      "epoch:17 step:16017 [D loss: 0.499179, acc.: 74.22%] [G loss: 0.696191]\n",
      "epoch:17 step:16018 [D loss: 0.467346, acc.: 77.34%] [G loss: 0.801669]\n",
      "epoch:17 step:16019 [D loss: 0.547397, acc.: 67.97%] [G loss: 0.744095]\n",
      "epoch:17 step:16020 [D loss: 0.585869, acc.: 67.19%] [G loss: 0.703658]\n",
      "epoch:17 step:16021 [D loss: 0.445325, acc.: 79.69%] [G loss: 0.705486]\n",
      "epoch:17 step:16022 [D loss: 0.497619, acc.: 72.66%] [G loss: 0.750512]\n",
      "epoch:17 step:16023 [D loss: 0.463309, acc.: 74.22%] [G loss: 0.751299]\n",
      "epoch:17 step:16024 [D loss: 0.526136, acc.: 71.88%] [G loss: 0.715299]\n",
      "epoch:17 step:16025 [D loss: 0.495307, acc.: 71.88%] [G loss: 0.758345]\n",
      "epoch:17 step:16026 [D loss: 0.494366, acc.: 77.34%] [G loss: 0.735765]\n",
      "epoch:17 step:16027 [D loss: 0.519684, acc.: 73.44%] [G loss: 0.736800]\n",
      "epoch:17 step:16028 [D loss: 0.567231, acc.: 68.75%] [G loss: 0.642580]\n",
      "epoch:17 step:16029 [D loss: 0.540192, acc.: 75.00%] [G loss: 0.944877]\n",
      "epoch:17 step:16030 [D loss: 0.513951, acc.: 75.00%] [G loss: 0.705953]\n",
      "epoch:17 step:16031 [D loss: 0.633757, acc.: 62.50%] [G loss: 0.584309]\n",
      "epoch:17 step:16032 [D loss: 0.521276, acc.: 71.09%] [G loss: 0.540790]\n",
      "epoch:17 step:16033 [D loss: 0.486308, acc.: 73.44%] [G loss: 0.687345]\n",
      "epoch:17 step:16034 [D loss: 0.636808, acc.: 64.06%] [G loss: 0.502386]\n",
      "epoch:17 step:16035 [D loss: 0.550096, acc.: 67.97%] [G loss: 0.522241]\n",
      "epoch:17 step:16036 [D loss: 0.634092, acc.: 66.41%] [G loss: 0.636319]\n",
      "epoch:17 step:16037 [D loss: 0.682977, acc.: 54.69%] [G loss: 0.584187]\n",
      "epoch:17 step:16038 [D loss: 0.642128, acc.: 62.50%] [G loss: 0.600436]\n",
      "epoch:17 step:16039 [D loss: 0.514361, acc.: 75.00%] [G loss: 0.537320]\n",
      "epoch:17 step:16040 [D loss: 0.484324, acc.: 74.22%] [G loss: 0.681196]\n",
      "epoch:17 step:16041 [D loss: 0.547536, acc.: 72.66%] [G loss: 0.534550]\n",
      "epoch:17 step:16042 [D loss: 0.534634, acc.: 75.00%] [G loss: 0.575410]\n",
      "epoch:17 step:16043 [D loss: 0.507218, acc.: 73.44%] [G loss: 0.648579]\n",
      "epoch:17 step:16044 [D loss: 0.570769, acc.: 67.19%] [G loss: 0.524202]\n",
      "epoch:17 step:16045 [D loss: 0.519632, acc.: 70.31%] [G loss: 0.710548]\n",
      "epoch:17 step:16046 [D loss: 0.538665, acc.: 70.31%] [G loss: 0.539642]\n",
      "epoch:17 step:16047 [D loss: 0.548659, acc.: 70.31%] [G loss: 0.769230]\n",
      "epoch:17 step:16048 [D loss: 0.491643, acc.: 72.66%] [G loss: 0.592736]\n",
      "epoch:17 step:16049 [D loss: 0.552811, acc.: 71.09%] [G loss: 0.799587]\n",
      "epoch:17 step:16050 [D loss: 0.534925, acc.: 70.31%] [G loss: 0.678704]\n",
      "epoch:17 step:16051 [D loss: 0.464257, acc.: 79.69%] [G loss: 0.962350]\n",
      "epoch:17 step:16052 [D loss: 0.495710, acc.: 77.34%] [G loss: 0.749879]\n",
      "epoch:17 step:16053 [D loss: 0.611672, acc.: 67.19%] [G loss: 0.793152]\n",
      "epoch:17 step:16054 [D loss: 0.583727, acc.: 64.84%] [G loss: 0.630924]\n",
      "epoch:17 step:16055 [D loss: 0.488692, acc.: 74.22%] [G loss: 0.658203]\n",
      "epoch:17 step:16056 [D loss: 0.532378, acc.: 67.19%] [G loss: 0.635683]\n",
      "epoch:17 step:16057 [D loss: 0.517593, acc.: 70.31%] [G loss: 0.712384]\n",
      "epoch:17 step:16058 [D loss: 0.549158, acc.: 67.97%] [G loss: 0.597438]\n",
      "epoch:17 step:16059 [D loss: 0.497996, acc.: 75.78%] [G loss: 0.725412]\n",
      "epoch:17 step:16060 [D loss: 0.463095, acc.: 73.44%] [G loss: 0.645456]\n",
      "epoch:17 step:16061 [D loss: 0.575717, acc.: 67.97%] [G loss: 0.845365]\n",
      "epoch:17 step:16062 [D loss: 0.526894, acc.: 71.09%] [G loss: 0.652261]\n",
      "epoch:17 step:16063 [D loss: 0.551810, acc.: 71.88%] [G loss: 0.711920]\n",
      "epoch:17 step:16064 [D loss: 0.546206, acc.: 71.88%] [G loss: 0.662068]\n",
      "epoch:17 step:16065 [D loss: 0.519169, acc.: 72.66%] [G loss: 0.691795]\n",
      "epoch:17 step:16066 [D loss: 0.645304, acc.: 64.84%] [G loss: 0.665092]\n",
      "epoch:17 step:16067 [D loss: 0.587394, acc.: 69.53%] [G loss: 0.604024]\n",
      "epoch:17 step:16068 [D loss: 0.545068, acc.: 67.19%] [G loss: 0.709608]\n",
      "epoch:17 step:16069 [D loss: 0.606994, acc.: 63.28%] [G loss: 0.584996]\n",
      "epoch:17 step:16070 [D loss: 0.576899, acc.: 68.75%] [G loss: 0.633028]\n",
      "epoch:17 step:16071 [D loss: 0.545152, acc.: 67.19%] [G loss: 0.580523]\n",
      "epoch:17 step:16072 [D loss: 0.557770, acc.: 67.19%] [G loss: 0.670033]\n",
      "epoch:17 step:16073 [D loss: 0.541522, acc.: 72.66%] [G loss: 0.529487]\n",
      "epoch:17 step:16074 [D loss: 0.579602, acc.: 65.62%] [G loss: 0.737183]\n",
      "epoch:17 step:16075 [D loss: 0.529327, acc.: 76.56%] [G loss: 0.673284]\n",
      "epoch:17 step:16076 [D loss: 0.659740, acc.: 58.59%] [G loss: 0.476101]\n",
      "epoch:17 step:16077 [D loss: 0.593883, acc.: 66.41%] [G loss: 0.472175]\n",
      "epoch:17 step:16078 [D loss: 0.521006, acc.: 75.00%] [G loss: 0.568264]\n",
      "epoch:17 step:16079 [D loss: 0.596479, acc.: 67.97%] [G loss: 0.528438]\n",
      "epoch:17 step:16080 [D loss: 0.564004, acc.: 73.44%] [G loss: 0.619365]\n",
      "epoch:17 step:16081 [D loss: 0.432864, acc.: 82.03%] [G loss: 0.616809]\n",
      "epoch:17 step:16082 [D loss: 0.613111, acc.: 64.06%] [G loss: 0.611047]\n",
      "epoch:17 step:16083 [D loss: 0.526914, acc.: 68.75%] [G loss: 0.649445]\n",
      "epoch:17 step:16084 [D loss: 0.489163, acc.: 73.44%] [G loss: 0.760495]\n",
      "epoch:17 step:16085 [D loss: 0.496526, acc.: 72.66%] [G loss: 0.780142]\n",
      "epoch:17 step:16086 [D loss: 0.564179, acc.: 71.88%] [G loss: 0.684756]\n",
      "epoch:17 step:16087 [D loss: 0.582919, acc.: 68.75%] [G loss: 0.615248]\n",
      "epoch:17 step:16088 [D loss: 0.549705, acc.: 75.78%] [G loss: 0.548027]\n",
      "epoch:17 step:16089 [D loss: 0.608683, acc.: 64.06%] [G loss: 0.694575]\n",
      "epoch:17 step:16090 [D loss: 0.511257, acc.: 72.66%] [G loss: 0.881654]\n",
      "epoch:17 step:16091 [D loss: 0.458114, acc.: 77.34%] [G loss: 0.707670]\n",
      "epoch:17 step:16092 [D loss: 0.533790, acc.: 71.09%] [G loss: 0.861053]\n",
      "epoch:17 step:16093 [D loss: 0.569423, acc.: 67.97%] [G loss: 0.690607]\n",
      "epoch:17 step:16094 [D loss: 0.481589, acc.: 74.22%] [G loss: 0.757925]\n",
      "epoch:17 step:16095 [D loss: 0.563971, acc.: 64.06%] [G loss: 0.544841]\n",
      "epoch:17 step:16096 [D loss: 0.540595, acc.: 70.31%] [G loss: 0.563097]\n",
      "epoch:17 step:16097 [D loss: 0.513750, acc.: 77.34%] [G loss: 0.526878]\n",
      "epoch:17 step:16098 [D loss: 0.600020, acc.: 65.62%] [G loss: 0.574868]\n",
      "epoch:17 step:16099 [D loss: 0.569336, acc.: 66.41%] [G loss: 0.443030]\n",
      "epoch:17 step:16100 [D loss: 0.516778, acc.: 71.88%] [G loss: 0.560810]\n",
      "epoch:17 step:16101 [D loss: 0.506987, acc.: 71.88%] [G loss: 0.501802]\n",
      "epoch:17 step:16102 [D loss: 0.481304, acc.: 73.44%] [G loss: 0.743142]\n",
      "epoch:17 step:16103 [D loss: 0.600224, acc.: 58.59%] [G loss: 0.641014]\n",
      "epoch:17 step:16104 [D loss: 0.596466, acc.: 64.06%] [G loss: 0.581271]\n",
      "epoch:17 step:16105 [D loss: 0.495432, acc.: 75.00%] [G loss: 0.709651]\n",
      "epoch:17 step:16106 [D loss: 0.555941, acc.: 71.88%] [G loss: 0.544414]\n",
      "epoch:17 step:16107 [D loss: 0.557236, acc.: 65.62%] [G loss: 0.664042]\n",
      "epoch:17 step:16108 [D loss: 0.565132, acc.: 65.62%] [G loss: 0.467246]\n",
      "epoch:17 step:16109 [D loss: 0.624953, acc.: 60.94%] [G loss: 0.455924]\n",
      "epoch:17 step:16110 [D loss: 0.579370, acc.: 69.53%] [G loss: 0.631740]\n",
      "epoch:17 step:16111 [D loss: 0.562280, acc.: 72.66%] [G loss: 0.670099]\n",
      "epoch:17 step:16112 [D loss: 0.543096, acc.: 72.66%] [G loss: 0.689944]\n",
      "epoch:17 step:16113 [D loss: 0.568799, acc.: 67.97%] [G loss: 0.675314]\n",
      "epoch:17 step:16114 [D loss: 0.592179, acc.: 68.75%] [G loss: 0.660856]\n",
      "epoch:17 step:16115 [D loss: 0.560228, acc.: 69.53%] [G loss: 0.589925]\n",
      "epoch:17 step:16116 [D loss: 0.576907, acc.: 66.41%] [G loss: 0.639694]\n",
      "epoch:17 step:16117 [D loss: 0.561284, acc.: 66.41%] [G loss: 0.536962]\n",
      "epoch:17 step:16118 [D loss: 0.594311, acc.: 65.62%] [G loss: 0.480978]\n",
      "epoch:17 step:16119 [D loss: 0.456427, acc.: 77.34%] [G loss: 0.656277]\n",
      "epoch:17 step:16120 [D loss: 0.510400, acc.: 79.69%] [G loss: 0.595734]\n",
      "epoch:17 step:16121 [D loss: 0.509888, acc.: 80.47%] [G loss: 0.623265]\n",
      "epoch:17 step:16122 [D loss: 0.550377, acc.: 73.44%] [G loss: 0.665621]\n",
      "epoch:17 step:16123 [D loss: 0.455223, acc.: 77.34%] [G loss: 0.755933]\n",
      "epoch:17 step:16124 [D loss: 0.559920, acc.: 71.09%] [G loss: 0.519440]\n",
      "epoch:17 step:16125 [D loss: 0.558039, acc.: 67.19%] [G loss: 0.646448]\n",
      "epoch:17 step:16126 [D loss: 0.534699, acc.: 70.31%] [G loss: 0.636944]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:17 step:16127 [D loss: 0.544416, acc.: 71.88%] [G loss: 0.716087]\n",
      "epoch:17 step:16128 [D loss: 0.524316, acc.: 70.31%] [G loss: 0.736617]\n",
      "epoch:17 step:16129 [D loss: 0.586535, acc.: 71.09%] [G loss: 0.670942]\n",
      "epoch:17 step:16130 [D loss: 0.552008, acc.: 68.75%] [G loss: 0.519281]\n",
      "epoch:17 step:16131 [D loss: 0.559127, acc.: 71.88%] [G loss: 0.584737]\n",
      "epoch:17 step:16132 [D loss: 0.660111, acc.: 60.94%] [G loss: 0.541710]\n",
      "epoch:17 step:16133 [D loss: 0.572765, acc.: 66.41%] [G loss: 0.667307]\n",
      "epoch:17 step:16134 [D loss: 0.510959, acc.: 74.22%] [G loss: 0.815670]\n",
      "epoch:17 step:16135 [D loss: 0.485512, acc.: 75.78%] [G loss: 0.837664]\n",
      "epoch:17 step:16136 [D loss: 0.493041, acc.: 72.66%] [G loss: 0.770301]\n",
      "epoch:17 step:16137 [D loss: 0.448538, acc.: 75.78%] [G loss: 0.976007]\n",
      "epoch:17 step:16138 [D loss: 0.592366, acc.: 71.88%] [G loss: 0.882812]\n",
      "epoch:17 step:16139 [D loss: 0.602211, acc.: 70.31%] [G loss: 0.591757]\n",
      "epoch:17 step:16140 [D loss: 0.585730, acc.: 66.41%] [G loss: 0.559862]\n",
      "epoch:17 step:16141 [D loss: 0.531211, acc.: 76.56%] [G loss: 0.448929]\n",
      "epoch:17 step:16142 [D loss: 0.531160, acc.: 71.88%] [G loss: 0.642729]\n",
      "epoch:17 step:16143 [D loss: 0.637453, acc.: 64.06%] [G loss: 0.489639]\n",
      "epoch:17 step:16144 [D loss: 0.535185, acc.: 66.41%] [G loss: 0.718904]\n",
      "epoch:17 step:16145 [D loss: 0.539291, acc.: 71.88%] [G loss: 0.638144]\n",
      "epoch:17 step:16146 [D loss: 0.518864, acc.: 72.66%] [G loss: 0.723994]\n",
      "epoch:17 step:16147 [D loss: 0.496328, acc.: 76.56%] [G loss: 0.820451]\n",
      "epoch:17 step:16148 [D loss: 0.477308, acc.: 78.91%] [G loss: 0.762322]\n",
      "epoch:17 step:16149 [D loss: 0.591439, acc.: 67.19%] [G loss: 0.691887]\n",
      "epoch:17 step:16150 [D loss: 0.525441, acc.: 70.31%] [G loss: 0.547156]\n",
      "epoch:17 step:16151 [D loss: 0.475368, acc.: 77.34%] [G loss: 0.769187]\n",
      "epoch:17 step:16152 [D loss: 0.487776, acc.: 78.91%] [G loss: 0.808328]\n",
      "epoch:17 step:16153 [D loss: 0.542308, acc.: 71.88%] [G loss: 0.661204]\n",
      "epoch:17 step:16154 [D loss: 0.569528, acc.: 68.75%] [G loss: 0.710954]\n",
      "epoch:17 step:16155 [D loss: 0.553353, acc.: 64.06%] [G loss: 0.635485]\n",
      "epoch:17 step:16156 [D loss: 0.566360, acc.: 67.19%] [G loss: 0.599218]\n",
      "epoch:17 step:16157 [D loss: 0.591210, acc.: 64.84%] [G loss: 0.528095]\n",
      "epoch:17 step:16158 [D loss: 0.485192, acc.: 79.69%] [G loss: 0.674487]\n",
      "epoch:17 step:16159 [D loss: 0.502647, acc.: 76.56%] [G loss: 0.681456]\n",
      "epoch:17 step:16160 [D loss: 0.489886, acc.: 78.91%] [G loss: 0.678136]\n",
      "epoch:17 step:16161 [D loss: 0.462089, acc.: 78.12%] [G loss: 0.801591]\n",
      "epoch:17 step:16162 [D loss: 0.511541, acc.: 76.56%] [G loss: 0.772248]\n",
      "epoch:17 step:16163 [D loss: 0.516916, acc.: 75.00%] [G loss: 0.675151]\n",
      "epoch:17 step:16164 [D loss: 0.601171, acc.: 64.84%] [G loss: 0.629602]\n",
      "epoch:17 step:16165 [D loss: 0.515967, acc.: 70.31%] [G loss: 0.623292]\n",
      "epoch:17 step:16166 [D loss: 0.547276, acc.: 66.41%] [G loss: 0.534473]\n",
      "epoch:17 step:16167 [D loss: 0.564626, acc.: 72.66%] [G loss: 0.475876]\n",
      "epoch:17 step:16168 [D loss: 0.545095, acc.: 71.09%] [G loss: 0.504613]\n",
      "epoch:17 step:16169 [D loss: 0.552008, acc.: 71.88%] [G loss: 0.741212]\n",
      "epoch:17 step:16170 [D loss: 0.518884, acc.: 75.78%] [G loss: 0.634551]\n",
      "epoch:17 step:16171 [D loss: 0.574026, acc.: 67.19%] [G loss: 0.623695]\n",
      "epoch:17 step:16172 [D loss: 0.598164, acc.: 66.41%] [G loss: 0.777066]\n",
      "epoch:17 step:16173 [D loss: 0.464323, acc.: 79.69%] [G loss: 0.582972]\n",
      "epoch:17 step:16174 [D loss: 0.548751, acc.: 71.09%] [G loss: 0.515930]\n",
      "epoch:17 step:16175 [D loss: 0.536277, acc.: 66.41%] [G loss: 0.568879]\n",
      "epoch:17 step:16176 [D loss: 0.566063, acc.: 67.97%] [G loss: 0.545984]\n",
      "epoch:17 step:16177 [D loss: 0.512801, acc.: 72.66%] [G loss: 0.716906]\n",
      "epoch:17 step:16178 [D loss: 0.561025, acc.: 69.53%] [G loss: 0.681822]\n",
      "epoch:17 step:16179 [D loss: 0.588943, acc.: 65.62%] [G loss: 0.548226]\n",
      "epoch:17 step:16180 [D loss: 0.571169, acc.: 64.84%] [G loss: 0.669047]\n",
      "epoch:17 step:16181 [D loss: 0.554822, acc.: 71.88%] [G loss: 0.696929]\n",
      "epoch:17 step:16182 [D loss: 0.592298, acc.: 62.50%] [G loss: 0.564686]\n",
      "epoch:17 step:16183 [D loss: 0.499579, acc.: 75.78%] [G loss: 0.775719]\n",
      "epoch:17 step:16184 [D loss: 0.520302, acc.: 72.66%] [G loss: 0.636220]\n",
      "epoch:17 step:16185 [D loss: 0.554121, acc.: 69.53%] [G loss: 0.642813]\n",
      "epoch:17 step:16186 [D loss: 0.593235, acc.: 62.50%] [G loss: 0.680739]\n",
      "epoch:17 step:16187 [D loss: 0.521163, acc.: 76.56%] [G loss: 0.515923]\n",
      "epoch:17 step:16188 [D loss: 0.511540, acc.: 70.31%] [G loss: 0.796304]\n",
      "epoch:17 step:16189 [D loss: 0.610515, acc.: 60.16%] [G loss: 0.472671]\n",
      "epoch:17 step:16190 [D loss: 0.559364, acc.: 67.97%] [G loss: 0.497199]\n",
      "epoch:17 step:16191 [D loss: 0.502411, acc.: 75.78%] [G loss: 0.547533]\n",
      "epoch:17 step:16192 [D loss: 0.625505, acc.: 65.62%] [G loss: 0.555065]\n",
      "epoch:17 step:16193 [D loss: 0.524971, acc.: 73.44%] [G loss: 0.654633]\n",
      "epoch:17 step:16194 [D loss: 0.554593, acc.: 70.31%] [G loss: 0.720502]\n",
      "epoch:17 step:16195 [D loss: 0.581252, acc.: 67.97%] [G loss: 0.536553]\n",
      "epoch:17 step:16196 [D loss: 0.580971, acc.: 69.53%] [G loss: 0.485694]\n",
      "epoch:17 step:16197 [D loss: 0.530611, acc.: 75.00%] [G loss: 0.502704]\n",
      "epoch:17 step:16198 [D loss: 0.535875, acc.: 70.31%] [G loss: 0.784192]\n",
      "epoch:17 step:16199 [D loss: 0.513995, acc.: 78.12%] [G loss: 0.612622]\n",
      "epoch:17 step:16200 [D loss: 0.484600, acc.: 75.78%] [G loss: 0.713805]\n",
      "##############\n",
      "[3.08639314 1.19803436 6.25509013 4.94274015 3.97870542 5.583502\n",
      " 4.58283124 5.18579496 4.52191936 4.1053955 ]\n",
      "##########\n",
      "epoch:17 step:16201 [D loss: 0.534041, acc.: 69.53%] [G loss: 0.798842]\n",
      "epoch:17 step:16202 [D loss: 0.512431, acc.: 72.66%] [G loss: 0.629388]\n",
      "epoch:17 step:16203 [D loss: 0.506894, acc.: 78.91%] [G loss: 0.709810]\n",
      "epoch:17 step:16204 [D loss: 0.548976, acc.: 71.88%] [G loss: 0.564118]\n",
      "epoch:17 step:16205 [D loss: 0.539266, acc.: 75.78%] [G loss: 0.552760]\n",
      "epoch:17 step:16206 [D loss: 0.622311, acc.: 68.75%] [G loss: 0.609665]\n",
      "epoch:17 step:16207 [D loss: 0.599218, acc.: 65.62%] [G loss: 0.515096]\n",
      "epoch:17 step:16208 [D loss: 0.532110, acc.: 71.88%] [G loss: 0.617749]\n",
      "epoch:17 step:16209 [D loss: 0.566600, acc.: 60.94%] [G loss: 0.539785]\n",
      "epoch:17 step:16210 [D loss: 0.574782, acc.: 67.97%] [G loss: 0.626054]\n",
      "epoch:17 step:16211 [D loss: 0.562048, acc.: 66.41%] [G loss: 0.452501]\n",
      "epoch:17 step:16212 [D loss: 0.490099, acc.: 75.00%] [G loss: 0.709365]\n",
      "epoch:17 step:16213 [D loss: 0.521096, acc.: 71.88%] [G loss: 0.512914]\n",
      "epoch:17 step:16214 [D loss: 0.505615, acc.: 74.22%] [G loss: 0.570290]\n",
      "epoch:17 step:16215 [D loss: 0.543765, acc.: 71.88%] [G loss: 0.685256]\n",
      "epoch:17 step:16216 [D loss: 0.572590, acc.: 68.75%] [G loss: 0.612993]\n",
      "epoch:17 step:16217 [D loss: 0.550661, acc.: 72.66%] [G loss: 0.640314]\n",
      "epoch:17 step:16218 [D loss: 0.522637, acc.: 70.31%] [G loss: 0.613228]\n",
      "epoch:17 step:16219 [D loss: 0.575517, acc.: 66.41%] [G loss: 0.638901]\n",
      "epoch:17 step:16220 [D loss: 0.583121, acc.: 68.75%] [G loss: 0.573177]\n",
      "epoch:17 step:16221 [D loss: 0.500245, acc.: 75.00%] [G loss: 0.570865]\n",
      "epoch:17 step:16222 [D loss: 0.544533, acc.: 68.75%] [G loss: 0.502088]\n",
      "epoch:17 step:16223 [D loss: 0.580616, acc.: 67.97%] [G loss: 0.555061]\n",
      "epoch:17 step:16224 [D loss: 0.641593, acc.: 61.72%] [G loss: 0.552748]\n",
      "epoch:17 step:16225 [D loss: 0.461767, acc.: 80.47%] [G loss: 0.807530]\n",
      "epoch:17 step:16226 [D loss: 0.591405, acc.: 67.97%] [G loss: 0.490531]\n",
      "epoch:17 step:16227 [D loss: 0.507213, acc.: 77.34%] [G loss: 0.514305]\n",
      "epoch:17 step:16228 [D loss: 0.468158, acc.: 74.22%] [G loss: 0.701003]\n",
      "epoch:17 step:16229 [D loss: 0.455675, acc.: 80.47%] [G loss: 0.598438]\n",
      "epoch:17 step:16230 [D loss: 0.631987, acc.: 65.62%] [G loss: 0.586582]\n",
      "epoch:17 step:16231 [D loss: 0.507724, acc.: 72.66%] [G loss: 0.637199]\n",
      "epoch:17 step:16232 [D loss: 0.568044, acc.: 70.31%] [G loss: 0.678127]\n",
      "epoch:17 step:16233 [D loss: 0.514054, acc.: 73.44%] [G loss: 0.730780]\n",
      "epoch:17 step:16234 [D loss: 0.534619, acc.: 71.88%] [G loss: 0.674493]\n",
      "epoch:17 step:16235 [D loss: 0.496333, acc.: 76.56%] [G loss: 0.599867]\n",
      "epoch:17 step:16236 [D loss: 0.527487, acc.: 75.00%] [G loss: 0.730902]\n",
      "epoch:17 step:16237 [D loss: 0.567703, acc.: 64.84%] [G loss: 0.618728]\n",
      "epoch:17 step:16238 [D loss: 0.485834, acc.: 71.88%] [G loss: 0.588145]\n",
      "epoch:17 step:16239 [D loss: 0.554025, acc.: 71.88%] [G loss: 0.704883]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:17 step:16240 [D loss: 0.505534, acc.: 76.56%] [G loss: 0.661653]\n",
      "epoch:17 step:16241 [D loss: 0.463723, acc.: 82.81%] [G loss: 0.807939]\n",
      "epoch:17 step:16242 [D loss: 0.497627, acc.: 74.22%] [G loss: 0.788591]\n",
      "epoch:17 step:16243 [D loss: 0.455098, acc.: 79.69%] [G loss: 0.906403]\n",
      "epoch:17 step:16244 [D loss: 0.447399, acc.: 82.03%] [G loss: 0.977597]\n",
      "epoch:17 step:16245 [D loss: 0.711883, acc.: 64.06%] [G loss: 0.587113]\n",
      "epoch:17 step:16246 [D loss: 0.593552, acc.: 64.06%] [G loss: 0.595090]\n",
      "epoch:17 step:16247 [D loss: 0.558736, acc.: 69.53%] [G loss: 0.661962]\n",
      "epoch:17 step:16248 [D loss: 0.526219, acc.: 71.88%] [G loss: 0.711239]\n",
      "epoch:17 step:16249 [D loss: 0.563514, acc.: 69.53%] [G loss: 0.563902]\n",
      "epoch:17 step:16250 [D loss: 0.525352, acc.: 77.34%] [G loss: 0.640188]\n",
      "epoch:17 step:16251 [D loss: 0.564788, acc.: 70.31%] [G loss: 0.570725]\n",
      "epoch:17 step:16252 [D loss: 0.592318, acc.: 66.41%] [G loss: 0.494638]\n",
      "epoch:17 step:16253 [D loss: 0.556191, acc.: 69.53%] [G loss: 0.498112]\n",
      "epoch:17 step:16254 [D loss: 0.595711, acc.: 67.97%] [G loss: 0.583390]\n",
      "epoch:17 step:16255 [D loss: 0.475021, acc.: 77.34%] [G loss: 0.591596]\n",
      "epoch:17 step:16256 [D loss: 0.584955, acc.: 73.44%] [G loss: 0.612201]\n",
      "epoch:17 step:16257 [D loss: 0.458656, acc.: 74.22%] [G loss: 0.787215]\n",
      "epoch:17 step:16258 [D loss: 0.502306, acc.: 75.00%] [G loss: 0.682631]\n",
      "epoch:17 step:16259 [D loss: 0.588859, acc.: 66.41%] [G loss: 0.593412]\n",
      "epoch:17 step:16260 [D loss: 0.575288, acc.: 68.75%] [G loss: 0.562803]\n",
      "epoch:17 step:16261 [D loss: 0.544320, acc.: 70.31%] [G loss: 0.755416]\n",
      "epoch:17 step:16262 [D loss: 0.492176, acc.: 74.22%] [G loss: 0.601652]\n",
      "epoch:17 step:16263 [D loss: 0.504265, acc.: 75.00%] [G loss: 0.639873]\n",
      "epoch:17 step:16264 [D loss: 0.525744, acc.: 73.44%] [G loss: 0.703954]\n",
      "epoch:17 step:16265 [D loss: 0.463636, acc.: 77.34%] [G loss: 0.743769]\n",
      "epoch:17 step:16266 [D loss: 0.546111, acc.: 74.22%] [G loss: 0.801939]\n",
      "epoch:17 step:16267 [D loss: 0.573094, acc.: 67.97%] [G loss: 0.525622]\n",
      "epoch:17 step:16268 [D loss: 0.514244, acc.: 75.78%] [G loss: 0.673612]\n",
      "epoch:17 step:16269 [D loss: 0.530971, acc.: 70.31%] [G loss: 0.644445]\n",
      "epoch:17 step:16270 [D loss: 0.596586, acc.: 70.31%] [G loss: 0.710884]\n",
      "epoch:17 step:16271 [D loss: 0.641280, acc.: 61.72%] [G loss: 0.577264]\n",
      "epoch:17 step:16272 [D loss: 0.480405, acc.: 78.91%] [G loss: 0.869233]\n",
      "epoch:17 step:16273 [D loss: 0.486462, acc.: 78.12%] [G loss: 0.870680]\n",
      "epoch:17 step:16274 [D loss: 0.572176, acc.: 65.62%] [G loss: 0.864152]\n",
      "epoch:17 step:16275 [D loss: 0.561862, acc.: 66.41%] [G loss: 0.779971]\n",
      "epoch:17 step:16276 [D loss: 0.461754, acc.: 77.34%] [G loss: 1.067682]\n",
      "epoch:17 step:16277 [D loss: 0.648611, acc.: 64.06%] [G loss: 0.808626]\n",
      "epoch:17 step:16278 [D loss: 0.742136, acc.: 55.47%] [G loss: 0.460264]\n",
      "epoch:17 step:16279 [D loss: 0.425899, acc.: 78.91%] [G loss: 0.624297]\n",
      "epoch:17 step:16280 [D loss: 0.524848, acc.: 75.00%] [G loss: 0.629335]\n",
      "epoch:17 step:16281 [D loss: 0.595081, acc.: 63.28%] [G loss: 0.517201]\n",
      "epoch:17 step:16282 [D loss: 0.555030, acc.: 64.06%] [G loss: 0.647455]\n",
      "epoch:17 step:16283 [D loss: 0.423431, acc.: 82.81%] [G loss: 0.991120]\n",
      "epoch:17 step:16284 [D loss: 0.612614, acc.: 64.84%] [G loss: 0.727371]\n",
      "epoch:17 step:16285 [D loss: 0.541681, acc.: 71.88%] [G loss: 0.798644]\n",
      "epoch:17 step:16286 [D loss: 0.442155, acc.: 78.12%] [G loss: 0.627071]\n",
      "epoch:17 step:16287 [D loss: 0.462947, acc.: 76.56%] [G loss: 0.716498]\n",
      "epoch:17 step:16288 [D loss: 0.457707, acc.: 74.22%] [G loss: 0.917646]\n",
      "epoch:17 step:16289 [D loss: 0.521269, acc.: 71.88%] [G loss: 0.790371]\n",
      "epoch:17 step:16290 [D loss: 0.506608, acc.: 77.34%] [G loss: 0.824310]\n",
      "epoch:17 step:16291 [D loss: 0.575889, acc.: 67.97%] [G loss: 0.665320]\n",
      "epoch:17 step:16292 [D loss: 0.521713, acc.: 72.66%] [G loss: 0.675036]\n",
      "epoch:17 step:16293 [D loss: 0.516664, acc.: 74.22%] [G loss: 0.689794]\n",
      "epoch:17 step:16294 [D loss: 0.563217, acc.: 67.19%] [G loss: 0.561973]\n",
      "epoch:17 step:16295 [D loss: 0.561061, acc.: 67.97%] [G loss: 0.566540]\n",
      "epoch:17 step:16296 [D loss: 0.628469, acc.: 64.06%] [G loss: 0.637371]\n",
      "epoch:17 step:16297 [D loss: 0.563964, acc.: 71.09%] [G loss: 0.627352]\n",
      "epoch:17 step:16298 [D loss: 0.506013, acc.: 75.78%] [G loss: 0.611309]\n",
      "epoch:17 step:16299 [D loss: 0.540042, acc.: 70.31%] [G loss: 0.787845]\n",
      "epoch:17 step:16300 [D loss: 0.506675, acc.: 75.78%] [G loss: 0.640641]\n",
      "epoch:17 step:16301 [D loss: 0.596180, acc.: 67.19%] [G loss: 0.544601]\n",
      "epoch:17 step:16302 [D loss: 0.560219, acc.: 71.09%] [G loss: 0.645260]\n",
      "epoch:17 step:16303 [D loss: 0.440856, acc.: 80.47%] [G loss: 0.803017]\n",
      "epoch:17 step:16304 [D loss: 0.568071, acc.: 69.53%] [G loss: 0.595726]\n",
      "epoch:17 step:16305 [D loss: 0.672915, acc.: 57.81%] [G loss: 0.391577]\n",
      "epoch:17 step:16306 [D loss: 0.578024, acc.: 67.19%] [G loss: 0.462055]\n",
      "epoch:17 step:16307 [D loss: 0.544189, acc.: 71.09%] [G loss: 0.685173]\n",
      "epoch:17 step:16308 [D loss: 0.561740, acc.: 69.53%] [G loss: 0.508665]\n",
      "epoch:17 step:16309 [D loss: 0.635108, acc.: 61.72%] [G loss: 0.495348]\n",
      "epoch:17 step:16310 [D loss: 0.487086, acc.: 77.34%] [G loss: 0.680367]\n",
      "epoch:17 step:16311 [D loss: 0.557584, acc.: 69.53%] [G loss: 0.548481]\n",
      "epoch:17 step:16312 [D loss: 0.606320, acc.: 67.19%] [G loss: 0.537671]\n",
      "epoch:17 step:16313 [D loss: 0.525036, acc.: 73.44%] [G loss: 0.527769]\n",
      "epoch:17 step:16314 [D loss: 0.495594, acc.: 73.44%] [G loss: 0.676928]\n",
      "epoch:17 step:16315 [D loss: 0.608936, acc.: 64.06%] [G loss: 0.486258]\n",
      "epoch:17 step:16316 [D loss: 0.552902, acc.: 66.41%] [G loss: 0.628962]\n",
      "epoch:17 step:16317 [D loss: 0.579347, acc.: 66.41%] [G loss: 0.582323]\n",
      "epoch:17 step:16318 [D loss: 0.523999, acc.: 71.09%] [G loss: 0.593519]\n",
      "epoch:17 step:16319 [D loss: 0.565363, acc.: 69.53%] [G loss: 0.534414]\n",
      "epoch:17 step:16320 [D loss: 0.585220, acc.: 63.28%] [G loss: 0.617568]\n",
      "epoch:17 step:16321 [D loss: 0.467773, acc.: 77.34%] [G loss: 0.567838]\n",
      "epoch:17 step:16322 [D loss: 0.590808, acc.: 68.75%] [G loss: 0.598052]\n",
      "epoch:17 step:16323 [D loss: 0.540815, acc.: 70.31%] [G loss: 0.473315]\n",
      "epoch:17 step:16324 [D loss: 0.536013, acc.: 71.09%] [G loss: 0.583626]\n",
      "epoch:17 step:16325 [D loss: 0.556799, acc.: 69.53%] [G loss: 0.535917]\n",
      "epoch:17 step:16326 [D loss: 0.512109, acc.: 72.66%] [G loss: 0.737305]\n",
      "epoch:17 step:16327 [D loss: 0.496160, acc.: 71.88%] [G loss: 0.604599]\n",
      "epoch:17 step:16328 [D loss: 0.494770, acc.: 75.00%] [G loss: 0.740484]\n",
      "epoch:17 step:16329 [D loss: 0.635153, acc.: 58.59%] [G loss: 0.536787]\n",
      "epoch:17 step:16330 [D loss: 0.666539, acc.: 57.81%] [G loss: 0.566888]\n",
      "epoch:17 step:16331 [D loss: 0.448563, acc.: 76.56%] [G loss: 0.681887]\n",
      "epoch:17 step:16332 [D loss: 0.476075, acc.: 78.12%] [G loss: 0.782486]\n",
      "epoch:17 step:16333 [D loss: 0.593167, acc.: 68.75%] [G loss: 0.621730]\n",
      "epoch:17 step:16334 [D loss: 0.508895, acc.: 71.88%] [G loss: 0.908797]\n",
      "epoch:17 step:16335 [D loss: 0.552449, acc.: 68.75%] [G loss: 0.775375]\n",
      "epoch:17 step:16336 [D loss: 0.531918, acc.: 73.44%] [G loss: 0.727402]\n",
      "epoch:17 step:16337 [D loss: 0.675974, acc.: 57.03%] [G loss: 0.548789]\n",
      "epoch:17 step:16338 [D loss: 0.545096, acc.: 65.62%] [G loss: 0.630719]\n",
      "epoch:17 step:16339 [D loss: 0.574640, acc.: 63.28%] [G loss: 0.646944]\n",
      "epoch:17 step:16340 [D loss: 0.609002, acc.: 59.38%] [G loss: 0.613707]\n",
      "epoch:17 step:16341 [D loss: 0.609078, acc.: 64.06%] [G loss: 0.458853]\n",
      "epoch:17 step:16342 [D loss: 0.593476, acc.: 65.62%] [G loss: 0.610550]\n",
      "epoch:17 step:16343 [D loss: 0.541901, acc.: 71.88%] [G loss: 0.596838]\n",
      "epoch:17 step:16344 [D loss: 0.571908, acc.: 66.41%] [G loss: 0.714011]\n",
      "epoch:17 step:16345 [D loss: 0.487957, acc.: 78.12%] [G loss: 0.706553]\n",
      "epoch:17 step:16346 [D loss: 0.558002, acc.: 68.75%] [G loss: 0.751871]\n",
      "epoch:17 step:16347 [D loss: 0.605193, acc.: 67.19%] [G loss: 0.615482]\n",
      "epoch:17 step:16348 [D loss: 0.523385, acc.: 71.09%] [G loss: 0.654398]\n",
      "epoch:17 step:16349 [D loss: 0.587887, acc.: 62.50%] [G loss: 0.715564]\n",
      "epoch:17 step:16350 [D loss: 0.595507, acc.: 66.41%] [G loss: 0.652522]\n",
      "epoch:17 step:16351 [D loss: 0.560673, acc.: 67.19%] [G loss: 0.665121]\n",
      "epoch:17 step:16352 [D loss: 0.543549, acc.: 68.75%] [G loss: 0.672196]\n",
      "epoch:17 step:16353 [D loss: 0.558733, acc.: 71.88%] [G loss: 0.710978]\n",
      "epoch:17 step:16354 [D loss: 0.502524, acc.: 73.44%] [G loss: 0.924391]\n",
      "epoch:17 step:16355 [D loss: 0.522197, acc.: 67.97%] [G loss: 0.690927]\n",
      "epoch:17 step:16356 [D loss: 0.505946, acc.: 72.66%] [G loss: 0.947545]\n",
      "epoch:17 step:16357 [D loss: 0.520546, acc.: 73.44%] [G loss: 0.851396]\n",
      "epoch:17 step:16358 [D loss: 0.508002, acc.: 76.56%] [G loss: 0.729549]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:17 step:16359 [D loss: 0.497871, acc.: 77.34%] [G loss: 0.864496]\n",
      "epoch:17 step:16360 [D loss: 0.546203, acc.: 68.75%] [G loss: 0.750700]\n",
      "epoch:17 step:16361 [D loss: 0.565343, acc.: 68.75%] [G loss: 0.618987]\n",
      "epoch:17 step:16362 [D loss: 0.638697, acc.: 66.41%] [G loss: 0.634135]\n",
      "epoch:17 step:16363 [D loss: 0.557418, acc.: 73.44%] [G loss: 0.621819]\n",
      "epoch:17 step:16364 [D loss: 0.542800, acc.: 66.41%] [G loss: 0.552231]\n",
      "epoch:17 step:16365 [D loss: 0.500713, acc.: 75.78%] [G loss: 0.648229]\n",
      "epoch:17 step:16366 [D loss: 0.628410, acc.: 67.19%] [G loss: 0.636344]\n",
      "epoch:17 step:16367 [D loss: 0.548239, acc.: 72.66%] [G loss: 0.662593]\n",
      "epoch:17 step:16368 [D loss: 0.488753, acc.: 75.00%] [G loss: 0.672351]\n",
      "epoch:17 step:16369 [D loss: 0.492665, acc.: 75.00%] [G loss: 0.707114]\n",
      "epoch:17 step:16370 [D loss: 0.532232, acc.: 69.53%] [G loss: 0.659312]\n",
      "epoch:17 step:16371 [D loss: 0.585102, acc.: 69.53%] [G loss: 0.708264]\n",
      "epoch:17 step:16372 [D loss: 0.544937, acc.: 72.66%] [G loss: 0.613683]\n",
      "epoch:17 step:16373 [D loss: 0.563768, acc.: 71.88%] [G loss: 0.873833]\n",
      "epoch:17 step:16374 [D loss: 0.544204, acc.: 71.88%] [G loss: 0.685010]\n",
      "epoch:17 step:16375 [D loss: 0.536676, acc.: 71.09%] [G loss: 0.791162]\n",
      "epoch:17 step:16376 [D loss: 0.497042, acc.: 72.66%] [G loss: 0.639821]\n",
      "epoch:17 step:16377 [D loss: 0.625256, acc.: 62.50%] [G loss: 0.633133]\n",
      "epoch:17 step:16378 [D loss: 0.482210, acc.: 78.91%] [G loss: 0.728782]\n",
      "epoch:17 step:16379 [D loss: 0.518434, acc.: 70.31%] [G loss: 0.753024]\n",
      "epoch:17 step:16380 [D loss: 0.439675, acc.: 75.78%] [G loss: 0.951041]\n",
      "epoch:17 step:16381 [D loss: 0.497487, acc.: 71.88%] [G loss: 0.837865]\n",
      "epoch:17 step:16382 [D loss: 0.516138, acc.: 70.31%] [G loss: 0.858404]\n",
      "epoch:17 step:16383 [D loss: 0.593823, acc.: 71.09%] [G loss: 0.782109]\n",
      "epoch:17 step:16384 [D loss: 0.555814, acc.: 70.31%] [G loss: 0.667699]\n",
      "epoch:17 step:16385 [D loss: 0.651393, acc.: 67.19%] [G loss: 0.520151]\n",
      "epoch:17 step:16386 [D loss: 0.490371, acc.: 76.56%] [G loss: 0.649587]\n",
      "epoch:17 step:16387 [D loss: 0.647057, acc.: 65.62%] [G loss: 0.543770]\n",
      "epoch:17 step:16388 [D loss: 0.580776, acc.: 67.97%] [G loss: 0.497173]\n",
      "epoch:17 step:16389 [D loss: 0.455565, acc.: 80.47%] [G loss: 0.760375]\n",
      "epoch:17 step:16390 [D loss: 0.503917, acc.: 71.88%] [G loss: 0.731297]\n",
      "epoch:17 step:16391 [D loss: 0.584806, acc.: 63.28%] [G loss: 0.619742]\n",
      "epoch:17 step:16392 [D loss: 0.555405, acc.: 67.97%] [G loss: 0.578970]\n",
      "epoch:17 step:16393 [D loss: 0.501630, acc.: 73.44%] [G loss: 0.657982]\n",
      "epoch:17 step:16394 [D loss: 0.603561, acc.: 64.06%] [G loss: 0.549043]\n",
      "epoch:17 step:16395 [D loss: 0.569918, acc.: 67.19%] [G loss: 0.496771]\n",
      "epoch:17 step:16396 [D loss: 0.538118, acc.: 68.75%] [G loss: 0.580900]\n",
      "epoch:17 step:16397 [D loss: 0.575146, acc.: 66.41%] [G loss: 0.672223]\n",
      "epoch:17 step:16398 [D loss: 0.543332, acc.: 70.31%] [G loss: 0.686146]\n",
      "epoch:17 step:16399 [D loss: 0.560996, acc.: 71.09%] [G loss: 0.665726]\n",
      "epoch:17 step:16400 [D loss: 0.484736, acc.: 77.34%] [G loss: 0.843600]\n",
      "##############\n",
      "[3.19487517 0.99550148 5.88669735 4.90131448 4.08197361 5.76134982\n",
      " 4.20134925 4.78282067 4.55529261 4.24965385]\n",
      "##########\n",
      "epoch:17 step:16401 [D loss: 0.439001, acc.: 82.81%] [G loss: 0.851073]\n",
      "epoch:17 step:16402 [D loss: 0.711022, acc.: 59.38%] [G loss: 0.737753]\n",
      "epoch:17 step:16403 [D loss: 0.573079, acc.: 65.62%] [G loss: 0.691343]\n",
      "epoch:17 step:16404 [D loss: 0.513607, acc.: 74.22%] [G loss: 0.715380]\n",
      "epoch:17 step:16405 [D loss: 0.487482, acc.: 79.69%] [G loss: 0.776317]\n",
      "epoch:17 step:16406 [D loss: 0.674105, acc.: 58.59%] [G loss: 0.479508]\n",
      "epoch:17 step:16407 [D loss: 0.509212, acc.: 75.78%] [G loss: 0.556183]\n",
      "epoch:17 step:16408 [D loss: 0.522709, acc.: 76.56%] [G loss: 0.715383]\n",
      "epoch:17 step:16409 [D loss: 0.591927, acc.: 69.53%] [G loss: 0.539115]\n",
      "epoch:17 step:16410 [D loss: 0.503764, acc.: 75.78%] [G loss: 0.631183]\n",
      "epoch:17 step:16411 [D loss: 0.649036, acc.: 65.62%] [G loss: 0.600611]\n",
      "epoch:17 step:16412 [D loss: 0.557219, acc.: 70.31%] [G loss: 0.637710]\n",
      "epoch:17 step:16413 [D loss: 0.523676, acc.: 75.78%] [G loss: 0.650913]\n",
      "epoch:17 step:16414 [D loss: 0.507239, acc.: 74.22%] [G loss: 0.678344]\n",
      "epoch:17 step:16415 [D loss: 0.551787, acc.: 70.31%] [G loss: 0.588146]\n",
      "epoch:17 step:16416 [D loss: 0.567646, acc.: 65.62%] [G loss: 0.574754]\n",
      "epoch:17 step:16417 [D loss: 0.493411, acc.: 77.34%] [G loss: 0.571252]\n",
      "epoch:17 step:16418 [D loss: 0.560249, acc.: 70.31%] [G loss: 0.606180]\n",
      "epoch:17 step:16419 [D loss: 0.598996, acc.: 65.62%] [G loss: 0.674710]\n",
      "epoch:17 step:16420 [D loss: 0.562353, acc.: 67.19%] [G loss: 0.676704]\n",
      "epoch:17 step:16421 [D loss: 0.568837, acc.: 66.41%] [G loss: 0.558284]\n",
      "epoch:17 step:16422 [D loss: 0.590171, acc.: 67.97%] [G loss: 0.455439]\n",
      "epoch:17 step:16423 [D loss: 0.600852, acc.: 68.75%] [G loss: 0.463069]\n",
      "epoch:17 step:16424 [D loss: 0.511905, acc.: 72.66%] [G loss: 0.471096]\n",
      "epoch:17 step:16425 [D loss: 0.569925, acc.: 71.09%] [G loss: 0.537249]\n",
      "epoch:17 step:16426 [D loss: 0.488536, acc.: 76.56%] [G loss: 0.720526]\n",
      "epoch:17 step:16427 [D loss: 0.521916, acc.: 73.44%] [G loss: 0.753300]\n",
      "epoch:17 step:16428 [D loss: 0.494305, acc.: 78.12%] [G loss: 0.890923]\n",
      "epoch:17 step:16429 [D loss: 0.614197, acc.: 64.06%] [G loss: 0.517811]\n",
      "epoch:17 step:16430 [D loss: 0.617319, acc.: 64.06%] [G loss: 0.624828]\n",
      "epoch:17 step:16431 [D loss: 0.606510, acc.: 62.50%] [G loss: 0.565135]\n",
      "epoch:17 step:16432 [D loss: 0.552011, acc.: 70.31%] [G loss: 0.573713]\n",
      "epoch:17 step:16433 [D loss: 0.500430, acc.: 75.78%] [G loss: 0.510118]\n",
      "epoch:17 step:16434 [D loss: 0.502752, acc.: 74.22%] [G loss: 0.756127]\n",
      "epoch:17 step:16435 [D loss: 0.524479, acc.: 73.44%] [G loss: 0.616446]\n",
      "epoch:17 step:16436 [D loss: 0.506243, acc.: 75.00%] [G loss: 0.751769]\n",
      "epoch:17 step:16437 [D loss: 0.390525, acc.: 86.72%] [G loss: 0.971122]\n",
      "epoch:17 step:16438 [D loss: 0.491136, acc.: 74.22%] [G loss: 0.844779]\n",
      "epoch:17 step:16439 [D loss: 0.624103, acc.: 63.28%] [G loss: 0.602503]\n",
      "epoch:17 step:16440 [D loss: 0.703018, acc.: 57.03%] [G loss: 0.557396]\n",
      "epoch:17 step:16441 [D loss: 0.561991, acc.: 67.97%] [G loss: 0.521617]\n",
      "epoch:17 step:16442 [D loss: 0.515803, acc.: 76.56%] [G loss: 0.570652]\n",
      "epoch:17 step:16443 [D loss: 0.468604, acc.: 73.44%] [G loss: 0.654569]\n",
      "epoch:17 step:16444 [D loss: 0.524899, acc.: 71.09%] [G loss: 0.553401]\n",
      "epoch:17 step:16445 [D loss: 0.468238, acc.: 79.69%] [G loss: 0.868182]\n",
      "epoch:17 step:16446 [D loss: 0.562698, acc.: 69.53%] [G loss: 0.569385]\n",
      "epoch:17 step:16447 [D loss: 0.521481, acc.: 71.88%] [G loss: 0.635745]\n",
      "epoch:17 step:16448 [D loss: 0.433269, acc.: 78.91%] [G loss: 0.671242]\n",
      "epoch:17 step:16449 [D loss: 0.454316, acc.: 82.81%] [G loss: 0.770873]\n",
      "epoch:17 step:16450 [D loss: 0.472655, acc.: 78.12%] [G loss: 0.771938]\n",
      "epoch:17 step:16451 [D loss: 0.528399, acc.: 66.41%] [G loss: 0.625114]\n",
      "epoch:17 step:16452 [D loss: 0.486593, acc.: 77.34%] [G loss: 0.574690]\n",
      "epoch:17 step:16453 [D loss: 0.579229, acc.: 67.19%] [G loss: 0.720764]\n",
      "epoch:17 step:16454 [D loss: 0.614017, acc.: 64.06%] [G loss: 0.622924]\n",
      "epoch:17 step:16455 [D loss: 0.517646, acc.: 73.44%] [G loss: 0.759436]\n",
      "epoch:17 step:16456 [D loss: 0.569972, acc.: 65.62%] [G loss: 0.617380]\n",
      "epoch:17 step:16457 [D loss: 0.657348, acc.: 64.06%] [G loss: 0.521564]\n",
      "epoch:17 step:16458 [D loss: 0.575431, acc.: 68.75%] [G loss: 0.543596]\n",
      "epoch:17 step:16459 [D loss: 0.483995, acc.: 75.78%] [G loss: 0.513753]\n",
      "epoch:17 step:16460 [D loss: 0.531835, acc.: 71.88%] [G loss: 0.697108]\n",
      "epoch:17 step:16461 [D loss: 0.563545, acc.: 68.75%] [G loss: 0.615741]\n",
      "epoch:17 step:16462 [D loss: 0.535903, acc.: 69.53%] [G loss: 0.668434]\n",
      "epoch:17 step:16463 [D loss: 0.499185, acc.: 70.31%] [G loss: 0.671231]\n",
      "epoch:17 step:16464 [D loss: 0.635764, acc.: 58.59%] [G loss: 0.521819]\n",
      "epoch:17 step:16465 [D loss: 0.522112, acc.: 71.88%] [G loss: 0.623614]\n",
      "epoch:17 step:16466 [D loss: 0.555371, acc.: 67.19%] [G loss: 0.688174]\n",
      "epoch:17 step:16467 [D loss: 0.557978, acc.: 66.41%] [G loss: 0.528434]\n",
      "epoch:17 step:16468 [D loss: 0.552817, acc.: 66.41%] [G loss: 0.666183]\n",
      "epoch:17 step:16469 [D loss: 0.546765, acc.: 68.75%] [G loss: 0.457920]\n",
      "epoch:17 step:16470 [D loss: 0.566089, acc.: 66.41%] [G loss: 0.511728]\n",
      "epoch:17 step:16471 [D loss: 0.655092, acc.: 63.28%] [G loss: 0.582913]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:17 step:16472 [D loss: 0.565435, acc.: 70.31%] [G loss: 0.663243]\n",
      "epoch:17 step:16473 [D loss: 0.536269, acc.: 75.00%] [G loss: 0.618245]\n",
      "epoch:17 step:16474 [D loss: 0.546429, acc.: 74.22%] [G loss: 0.533740]\n",
      "epoch:17 step:16475 [D loss: 0.521512, acc.: 73.44%] [G loss: 0.737817]\n",
      "epoch:17 step:16476 [D loss: 0.526145, acc.: 72.66%] [G loss: 0.679584]\n",
      "epoch:17 step:16477 [D loss: 0.492177, acc.: 75.00%] [G loss: 0.907340]\n",
      "epoch:17 step:16478 [D loss: 0.539360, acc.: 71.09%] [G loss: 0.639293]\n",
      "epoch:17 step:16479 [D loss: 0.566853, acc.: 67.19%] [G loss: 0.583330]\n",
      "epoch:17 step:16480 [D loss: 0.517590, acc.: 71.88%] [G loss: 0.607779]\n",
      "epoch:17 step:16481 [D loss: 0.491621, acc.: 78.12%] [G loss: 0.693120]\n",
      "epoch:17 step:16482 [D loss: 0.605866, acc.: 68.75%] [G loss: 0.758209]\n",
      "epoch:17 step:16483 [D loss: 0.477180, acc.: 78.12%] [G loss: 0.712025]\n",
      "epoch:17 step:16484 [D loss: 0.474623, acc.: 74.22%] [G loss: 0.742404]\n",
      "epoch:17 step:16485 [D loss: 0.502524, acc.: 73.44%] [G loss: 0.846178]\n",
      "epoch:17 step:16486 [D loss: 0.538044, acc.: 72.66%] [G loss: 0.624125]\n",
      "epoch:17 step:16487 [D loss: 0.473623, acc.: 74.22%] [G loss: 0.588783]\n",
      "epoch:17 step:16488 [D loss: 0.633425, acc.: 65.62%] [G loss: 0.481111]\n",
      "epoch:17 step:16489 [D loss: 0.550362, acc.: 69.53%] [G loss: 0.491409]\n",
      "epoch:17 step:16490 [D loss: 0.552397, acc.: 67.19%] [G loss: 0.471911]\n",
      "epoch:17 step:16491 [D loss: 0.574296, acc.: 66.41%] [G loss: 0.558764]\n",
      "epoch:17 step:16492 [D loss: 0.568099, acc.: 67.97%] [G loss: 0.777543]\n",
      "epoch:17 step:16493 [D loss: 0.519800, acc.: 71.88%] [G loss: 0.785446]\n",
      "epoch:17 step:16494 [D loss: 0.554198, acc.: 71.09%] [G loss: 0.716271]\n",
      "epoch:17 step:16495 [D loss: 0.654053, acc.: 64.06%] [G loss: 0.585726]\n",
      "epoch:17 step:16496 [D loss: 0.475728, acc.: 77.34%] [G loss: 0.700320]\n",
      "epoch:17 step:16497 [D loss: 0.502585, acc.: 80.47%] [G loss: 0.689765]\n",
      "epoch:17 step:16498 [D loss: 0.545974, acc.: 72.66%] [G loss: 0.739532]\n",
      "epoch:17 step:16499 [D loss: 0.512113, acc.: 73.44%] [G loss: 0.685719]\n",
      "epoch:17 step:16500 [D loss: 0.567684, acc.: 70.31%] [G loss: 0.753865]\n",
      "epoch:17 step:16501 [D loss: 0.539749, acc.: 71.09%] [G loss: 0.695791]\n",
      "epoch:17 step:16502 [D loss: 0.543329, acc.: 71.09%] [G loss: 0.671647]\n",
      "epoch:17 step:16503 [D loss: 0.468529, acc.: 78.91%] [G loss: 0.840297]\n",
      "epoch:17 step:16504 [D loss: 0.471895, acc.: 76.56%] [G loss: 0.758548]\n",
      "epoch:17 step:16505 [D loss: 0.682448, acc.: 53.12%] [G loss: 0.677932]\n",
      "epoch:17 step:16506 [D loss: 0.555352, acc.: 71.09%] [G loss: 0.587714]\n",
      "epoch:17 step:16507 [D loss: 0.563551, acc.: 67.19%] [G loss: 0.431500]\n",
      "epoch:17 step:16508 [D loss: 0.523586, acc.: 71.88%] [G loss: 0.603559]\n",
      "epoch:17 step:16509 [D loss: 0.537699, acc.: 71.88%] [G loss: 0.800956]\n",
      "epoch:17 step:16510 [D loss: 0.503648, acc.: 75.78%] [G loss: 0.701838]\n",
      "epoch:17 step:16511 [D loss: 0.462866, acc.: 82.03%] [G loss: 0.772923]\n",
      "epoch:17 step:16512 [D loss: 0.590262, acc.: 66.41%] [G loss: 0.618815]\n",
      "epoch:17 step:16513 [D loss: 0.598016, acc.: 65.62%] [G loss: 0.616654]\n",
      "epoch:17 step:16514 [D loss: 0.513522, acc.: 72.66%] [G loss: 0.520433]\n",
      "epoch:17 step:16515 [D loss: 0.603778, acc.: 64.84%] [G loss: 0.557043]\n",
      "epoch:17 step:16516 [D loss: 0.613873, acc.: 61.72%] [G loss: 0.542639]\n",
      "epoch:17 step:16517 [D loss: 0.595315, acc.: 64.06%] [G loss: 0.576034]\n",
      "epoch:17 step:16518 [D loss: 0.519065, acc.: 71.09%] [G loss: 0.732073]\n",
      "epoch:17 step:16519 [D loss: 0.575782, acc.: 64.84%] [G loss: 0.590753]\n",
      "epoch:17 step:16520 [D loss: 0.577826, acc.: 70.31%] [G loss: 0.597547]\n",
      "epoch:17 step:16521 [D loss: 0.511264, acc.: 75.78%] [G loss: 0.524750]\n",
      "epoch:17 step:16522 [D loss: 0.496442, acc.: 79.69%] [G loss: 0.465319]\n",
      "epoch:17 step:16523 [D loss: 0.587864, acc.: 66.41%] [G loss: 0.576041]\n",
      "epoch:17 step:16524 [D loss: 0.561205, acc.: 71.09%] [G loss: 0.545782]\n",
      "epoch:17 step:16525 [D loss: 0.542925, acc.: 70.31%] [G loss: 0.561230]\n",
      "epoch:17 step:16526 [D loss: 0.579380, acc.: 67.97%] [G loss: 0.554847]\n",
      "epoch:17 step:16527 [D loss: 0.500835, acc.: 72.66%] [G loss: 0.752123]\n",
      "epoch:17 step:16528 [D loss: 0.572316, acc.: 70.31%] [G loss: 0.676653]\n",
      "epoch:17 step:16529 [D loss: 0.629696, acc.: 65.62%] [G loss: 0.608774]\n",
      "epoch:17 step:16530 [D loss: 0.536941, acc.: 71.88%] [G loss: 0.520670]\n",
      "epoch:17 step:16531 [D loss: 0.531338, acc.: 70.31%] [G loss: 0.649274]\n",
      "epoch:17 step:16532 [D loss: 0.481938, acc.: 78.91%] [G loss: 0.671361]\n",
      "epoch:17 step:16533 [D loss: 0.545940, acc.: 70.31%] [G loss: 0.592719]\n",
      "epoch:17 step:16534 [D loss: 0.480675, acc.: 79.69%] [G loss: 0.703082]\n",
      "epoch:17 step:16535 [D loss: 0.578722, acc.: 67.97%] [G loss: 0.629334]\n",
      "epoch:17 step:16536 [D loss: 0.536736, acc.: 73.44%] [G loss: 0.469344]\n",
      "epoch:17 step:16537 [D loss: 0.574362, acc.: 68.75%] [G loss: 0.563458]\n",
      "epoch:17 step:16538 [D loss: 0.549447, acc.: 71.88%] [G loss: 0.451556]\n",
      "epoch:17 step:16539 [D loss: 0.596816, acc.: 65.62%] [G loss: 0.602325]\n",
      "epoch:17 step:16540 [D loss: 0.496052, acc.: 78.12%] [G loss: 0.534867]\n",
      "epoch:17 step:16541 [D loss: 0.568117, acc.: 69.53%] [G loss: 0.537457]\n",
      "epoch:17 step:16542 [D loss: 0.480762, acc.: 71.09%] [G loss: 0.578192]\n",
      "epoch:17 step:16543 [D loss: 0.542245, acc.: 67.97%] [G loss: 0.597023]\n",
      "epoch:17 step:16544 [D loss: 0.614632, acc.: 63.28%] [G loss: 0.568220]\n",
      "epoch:17 step:16545 [D loss: 0.529239, acc.: 70.31%] [G loss: 0.543344]\n",
      "epoch:17 step:16546 [D loss: 0.510604, acc.: 72.66%] [G loss: 0.686317]\n",
      "epoch:17 step:16547 [D loss: 0.514900, acc.: 72.66%] [G loss: 0.737155]\n",
      "epoch:17 step:16548 [D loss: 0.592118, acc.: 67.97%] [G loss: 0.675563]\n",
      "epoch:17 step:16549 [D loss: 0.542980, acc.: 64.84%] [G loss: 0.419038]\n",
      "epoch:17 step:16550 [D loss: 0.534365, acc.: 70.31%] [G loss: 0.665129]\n",
      "epoch:17 step:16551 [D loss: 0.557867, acc.: 69.53%] [G loss: 0.571978]\n",
      "epoch:17 step:16552 [D loss: 0.525631, acc.: 68.75%] [G loss: 0.663247]\n",
      "epoch:17 step:16553 [D loss: 0.463413, acc.: 79.69%] [G loss: 0.724964]\n",
      "epoch:17 step:16554 [D loss: 0.590665, acc.: 64.06%] [G loss: 0.697552]\n",
      "epoch:17 step:16555 [D loss: 0.495254, acc.: 77.34%] [G loss: 0.684098]\n",
      "epoch:17 step:16556 [D loss: 0.553253, acc.: 66.41%] [G loss: 0.560046]\n",
      "epoch:17 step:16557 [D loss: 0.533357, acc.: 75.00%] [G loss: 0.567408]\n",
      "epoch:17 step:16558 [D loss: 0.531360, acc.: 71.09%] [G loss: 0.646512]\n",
      "epoch:17 step:16559 [D loss: 0.530032, acc.: 75.78%] [G loss: 0.503120]\n",
      "epoch:17 step:16560 [D loss: 0.503953, acc.: 77.34%] [G loss: 0.600097]\n",
      "epoch:17 step:16561 [D loss: 0.492451, acc.: 78.12%] [G loss: 0.725945]\n",
      "epoch:17 step:16562 [D loss: 0.520848, acc.: 72.66%] [G loss: 0.710106]\n",
      "epoch:17 step:16563 [D loss: 0.455679, acc.: 82.81%] [G loss: 0.785932]\n",
      "epoch:17 step:16564 [D loss: 0.481229, acc.: 74.22%] [G loss: 0.770412]\n",
      "epoch:17 step:16565 [D loss: 0.673741, acc.: 62.50%] [G loss: 0.561950]\n",
      "epoch:17 step:16566 [D loss: 0.570312, acc.: 64.06%] [G loss: 0.521122]\n",
      "epoch:17 step:16567 [D loss: 0.522930, acc.: 71.88%] [G loss: 0.599362]\n",
      "epoch:17 step:16568 [D loss: 0.543343, acc.: 68.75%] [G loss: 0.542650]\n",
      "epoch:17 step:16569 [D loss: 0.547495, acc.: 68.75%] [G loss: 0.732210]\n",
      "epoch:17 step:16570 [D loss: 0.487345, acc.: 78.91%] [G loss: 0.908760]\n",
      "epoch:17 step:16571 [D loss: 0.507306, acc.: 70.31%] [G loss: 0.877932]\n",
      "epoch:17 step:16572 [D loss: 0.509364, acc.: 72.66%] [G loss: 0.656043]\n",
      "epoch:17 step:16573 [D loss: 0.555526, acc.: 72.66%] [G loss: 0.648203]\n",
      "epoch:17 step:16574 [D loss: 0.540355, acc.: 71.88%] [G loss: 0.567085]\n",
      "epoch:17 step:16575 [D loss: 0.552634, acc.: 69.53%] [G loss: 0.618665]\n",
      "epoch:17 step:16576 [D loss: 0.471142, acc.: 78.91%] [G loss: 0.876808]\n",
      "epoch:17 step:16577 [D loss: 0.437542, acc.: 77.34%] [G loss: 0.842200]\n",
      "epoch:17 step:16578 [D loss: 0.539392, acc.: 71.88%] [G loss: 0.774010]\n",
      "epoch:17 step:16579 [D loss: 0.597010, acc.: 68.75%] [G loss: 0.717906]\n",
      "epoch:17 step:16580 [D loss: 0.465726, acc.: 78.12%] [G loss: 0.726621]\n",
      "epoch:17 step:16581 [D loss: 0.652853, acc.: 60.16%] [G loss: 0.530745]\n",
      "epoch:17 step:16582 [D loss: 0.528923, acc.: 78.91%] [G loss: 0.487266]\n",
      "epoch:17 step:16583 [D loss: 0.537657, acc.: 69.53%] [G loss: 0.570005]\n",
      "epoch:17 step:16584 [D loss: 0.527025, acc.: 76.56%] [G loss: 0.685117]\n",
      "epoch:17 step:16585 [D loss: 0.532299, acc.: 71.09%] [G loss: 0.559600]\n",
      "epoch:17 step:16586 [D loss: 0.474199, acc.: 77.34%] [G loss: 0.565342]\n",
      "epoch:17 step:16587 [D loss: 0.618206, acc.: 61.72%] [G loss: 0.607302]\n",
      "epoch:17 step:16588 [D loss: 0.533985, acc.: 71.09%] [G loss: 0.789401]\n",
      "epoch:17 step:16589 [D loss: 0.536775, acc.: 72.66%] [G loss: 0.692454]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:17 step:16590 [D loss: 0.520418, acc.: 73.44%] [G loss: 0.622928]\n",
      "epoch:17 step:16591 [D loss: 0.472667, acc.: 78.12%] [G loss: 0.740867]\n",
      "epoch:17 step:16592 [D loss: 0.607128, acc.: 62.50%] [G loss: 0.555576]\n",
      "epoch:17 step:16593 [D loss: 0.547818, acc.: 68.75%] [G loss: 0.768127]\n",
      "epoch:17 step:16594 [D loss: 0.555835, acc.: 71.09%] [G loss: 0.664723]\n",
      "epoch:17 step:16595 [D loss: 0.526700, acc.: 67.97%] [G loss: 0.674141]\n",
      "epoch:17 step:16596 [D loss: 0.534175, acc.: 75.78%] [G loss: 0.697121]\n",
      "epoch:17 step:16597 [D loss: 0.524879, acc.: 75.78%] [G loss: 0.522293]\n",
      "epoch:17 step:16598 [D loss: 0.565322, acc.: 68.75%] [G loss: 0.582574]\n",
      "epoch:17 step:16599 [D loss: 0.598311, acc.: 69.53%] [G loss: 0.562864]\n",
      "epoch:17 step:16600 [D loss: 0.527851, acc.: 71.88%] [G loss: 0.586600]\n",
      "##############\n",
      "[3.1200088  1.07436821 6.03735239 4.78729327 3.84973499 5.78908985\n",
      " 4.30712254 4.82188395 4.57053239 4.22864717]\n",
      "##########\n",
      "epoch:17 step:16601 [D loss: 0.571783, acc.: 66.41%] [G loss: 0.666721]\n",
      "epoch:17 step:16602 [D loss: 0.585060, acc.: 64.84%] [G loss: 0.659098]\n",
      "epoch:17 step:16603 [D loss: 0.533020, acc.: 69.53%] [G loss: 0.563683]\n",
      "epoch:17 step:16604 [D loss: 0.656451, acc.: 64.06%] [G loss: 0.609923]\n",
      "epoch:17 step:16605 [D loss: 0.476410, acc.: 78.91%] [G loss: 0.586299]\n",
      "epoch:17 step:16606 [D loss: 0.517852, acc.: 75.78%] [G loss: 0.509861]\n",
      "epoch:17 step:16607 [D loss: 0.579025, acc.: 68.75%] [G loss: 0.568386]\n",
      "epoch:17 step:16608 [D loss: 0.504226, acc.: 78.12%] [G loss: 0.633148]\n",
      "epoch:17 step:16609 [D loss: 0.567378, acc.: 68.75%] [G loss: 0.584312]\n",
      "epoch:17 step:16610 [D loss: 0.474677, acc.: 79.69%] [G loss: 0.683331]\n",
      "epoch:17 step:16611 [D loss: 0.538810, acc.: 72.66%] [G loss: 0.628084]\n",
      "epoch:17 step:16612 [D loss: 0.531624, acc.: 71.09%] [G loss: 0.511044]\n",
      "epoch:17 step:16613 [D loss: 0.619606, acc.: 66.41%] [G loss: 0.475362]\n",
      "epoch:17 step:16614 [D loss: 0.497991, acc.: 75.00%] [G loss: 0.595442]\n",
      "epoch:17 step:16615 [D loss: 0.575894, acc.: 67.19%] [G loss: 0.494296]\n",
      "epoch:17 step:16616 [D loss: 0.605533, acc.: 65.62%] [G loss: 0.565011]\n",
      "epoch:17 step:16617 [D loss: 0.554999, acc.: 73.44%] [G loss: 0.589122]\n",
      "epoch:17 step:16618 [D loss: 0.538038, acc.: 68.75%] [G loss: 0.610616]\n",
      "epoch:17 step:16619 [D loss: 0.501859, acc.: 72.66%] [G loss: 0.685314]\n",
      "epoch:17 step:16620 [D loss: 0.525884, acc.: 70.31%] [G loss: 0.717849]\n",
      "epoch:17 step:16621 [D loss: 0.510384, acc.: 75.78%] [G loss: 0.555791]\n",
      "epoch:17 step:16622 [D loss: 0.517028, acc.: 75.00%] [G loss: 0.612155]\n",
      "epoch:17 step:16623 [D loss: 0.481377, acc.: 78.12%] [G loss: 0.773793]\n",
      "epoch:17 step:16624 [D loss: 0.519384, acc.: 74.22%] [G loss: 0.758899]\n",
      "epoch:17 step:16625 [D loss: 0.604131, acc.: 65.62%] [G loss: 0.584087]\n",
      "epoch:17 step:16626 [D loss: 0.588840, acc.: 61.72%] [G loss: 0.630684]\n",
      "epoch:17 step:16627 [D loss: 0.592646, acc.: 61.72%] [G loss: 0.617736]\n",
      "epoch:17 step:16628 [D loss: 0.525477, acc.: 71.88%] [G loss: 0.552115]\n",
      "epoch:17 step:16629 [D loss: 0.522499, acc.: 71.88%] [G loss: 0.773721]\n",
      "epoch:17 step:16630 [D loss: 0.574194, acc.: 71.09%] [G loss: 0.692808]\n",
      "epoch:17 step:16631 [D loss: 0.560881, acc.: 71.88%] [G loss: 0.712492]\n",
      "epoch:17 step:16632 [D loss: 0.628050, acc.: 64.84%] [G loss: 0.558024]\n",
      "epoch:17 step:16633 [D loss: 0.633457, acc.: 63.28%] [G loss: 0.600593]\n",
      "epoch:17 step:16634 [D loss: 0.522215, acc.: 74.22%] [G loss: 0.677269]\n",
      "epoch:17 step:16635 [D loss: 0.524142, acc.: 75.78%] [G loss: 0.628483]\n",
      "epoch:17 step:16636 [D loss: 0.453841, acc.: 78.12%] [G loss: 0.613565]\n",
      "epoch:17 step:16637 [D loss: 0.552932, acc.: 71.09%] [G loss: 0.577714]\n",
      "epoch:17 step:16638 [D loss: 0.514366, acc.: 70.31%] [G loss: 0.837717]\n",
      "epoch:17 step:16639 [D loss: 0.545045, acc.: 71.88%] [G loss: 0.552213]\n",
      "epoch:17 step:16640 [D loss: 0.564475, acc.: 73.44%] [G loss: 0.599385]\n",
      "epoch:17 step:16641 [D loss: 0.537131, acc.: 70.31%] [G loss: 0.575400]\n",
      "epoch:17 step:16642 [D loss: 0.546121, acc.: 66.41%] [G loss: 0.703025]\n",
      "epoch:17 step:16643 [D loss: 0.533097, acc.: 66.41%] [G loss: 0.678724]\n",
      "epoch:17 step:16644 [D loss: 0.578783, acc.: 67.19%] [G loss: 0.579980]\n",
      "epoch:17 step:16645 [D loss: 0.622022, acc.: 63.28%] [G loss: 0.438566]\n",
      "epoch:17 step:16646 [D loss: 0.567930, acc.: 67.97%] [G loss: 0.573185]\n",
      "epoch:17 step:16647 [D loss: 0.548550, acc.: 67.19%] [G loss: 0.398002]\n",
      "epoch:17 step:16648 [D loss: 0.514409, acc.: 75.00%] [G loss: 0.685912]\n",
      "epoch:17 step:16649 [D loss: 0.597103, acc.: 68.75%] [G loss: 0.573247]\n",
      "epoch:17 step:16650 [D loss: 0.591560, acc.: 71.88%] [G loss: 0.544490]\n",
      "epoch:17 step:16651 [D loss: 0.551599, acc.: 74.22%] [G loss: 0.637028]\n",
      "epoch:17 step:16652 [D loss: 0.600800, acc.: 63.28%] [G loss: 0.554634]\n",
      "epoch:17 step:16653 [D loss: 0.488246, acc.: 75.00%] [G loss: 0.580805]\n",
      "epoch:17 step:16654 [D loss: 0.484399, acc.: 79.69%] [G loss: 0.763311]\n",
      "epoch:17 step:16655 [D loss: 0.527301, acc.: 74.22%] [G loss: 0.724794]\n",
      "epoch:17 step:16656 [D loss: 0.553576, acc.: 66.41%] [G loss: 0.602227]\n",
      "epoch:17 step:16657 [D loss: 0.546849, acc.: 72.66%] [G loss: 0.626315]\n",
      "epoch:17 step:16658 [D loss: 0.585758, acc.: 66.41%] [G loss: 0.631087]\n",
      "epoch:17 step:16659 [D loss: 0.542853, acc.: 69.53%] [G loss: 0.497430]\n",
      "epoch:17 step:16660 [D loss: 0.633628, acc.: 64.06%] [G loss: 0.524191]\n",
      "epoch:17 step:16661 [D loss: 0.544715, acc.: 71.88%] [G loss: 0.591914]\n",
      "epoch:17 step:16662 [D loss: 0.528134, acc.: 71.09%] [G loss: 0.624930]\n",
      "epoch:17 step:16663 [D loss: 0.534254, acc.: 65.62%] [G loss: 0.579604]\n",
      "epoch:17 step:16664 [D loss: 0.528982, acc.: 70.31%] [G loss: 0.560936]\n",
      "epoch:17 step:16665 [D loss: 0.478703, acc.: 75.00%] [G loss: 0.599752]\n",
      "epoch:17 step:16666 [D loss: 0.526797, acc.: 75.00%] [G loss: 0.524425]\n",
      "epoch:17 step:16667 [D loss: 0.556815, acc.: 67.19%] [G loss: 0.525076]\n",
      "epoch:17 step:16668 [D loss: 0.552244, acc.: 75.00%] [G loss: 0.521613]\n",
      "epoch:17 step:16669 [D loss: 0.626338, acc.: 60.94%] [G loss: 0.468363]\n",
      "epoch:17 step:16670 [D loss: 0.556958, acc.: 67.19%] [G loss: 0.478241]\n",
      "epoch:17 step:16671 [D loss: 0.492936, acc.: 74.22%] [G loss: 0.631912]\n",
      "epoch:17 step:16672 [D loss: 0.531260, acc.: 71.88%] [G loss: 0.782556]\n",
      "epoch:17 step:16673 [D loss: 0.561980, acc.: 70.31%] [G loss: 0.740650]\n",
      "epoch:17 step:16674 [D loss: 0.580137, acc.: 67.19%] [G loss: 0.419847]\n",
      "epoch:17 step:16675 [D loss: 0.474946, acc.: 76.56%] [G loss: 0.742535]\n",
      "epoch:17 step:16676 [D loss: 0.413254, acc.: 82.03%] [G loss: 0.843487]\n",
      "epoch:17 step:16677 [D loss: 0.529883, acc.: 71.09%] [G loss: 0.701216]\n",
      "epoch:17 step:16678 [D loss: 0.553569, acc.: 70.31%] [G loss: 0.653263]\n",
      "epoch:17 step:16679 [D loss: 0.501860, acc.: 73.44%] [G loss: 0.682324]\n",
      "epoch:17 step:16680 [D loss: 0.482335, acc.: 75.78%] [G loss: 0.620305]\n",
      "epoch:17 step:16681 [D loss: 0.571858, acc.: 71.09%] [G loss: 0.585690]\n",
      "epoch:17 step:16682 [D loss: 0.530437, acc.: 74.22%] [G loss: 0.591083]\n",
      "epoch:17 step:16683 [D loss: 0.567701, acc.: 71.88%] [G loss: 0.722320]\n",
      "epoch:17 step:16684 [D loss: 0.575405, acc.: 65.62%] [G loss: 0.724094]\n",
      "epoch:17 step:16685 [D loss: 0.581183, acc.: 70.31%] [G loss: 0.711757]\n",
      "epoch:17 step:16686 [D loss: 0.519785, acc.: 74.22%] [G loss: 0.656052]\n",
      "epoch:17 step:16687 [D loss: 0.516098, acc.: 74.22%] [G loss: 0.593609]\n",
      "epoch:17 step:16688 [D loss: 0.561018, acc.: 72.66%] [G loss: 0.615454]\n",
      "epoch:17 step:16689 [D loss: 0.517823, acc.: 68.75%] [G loss: 0.634759]\n",
      "epoch:17 step:16690 [D loss: 0.546779, acc.: 69.53%] [G loss: 0.639473]\n",
      "epoch:17 step:16691 [D loss: 0.641267, acc.: 60.94%] [G loss: 0.575915]\n",
      "epoch:17 step:16692 [D loss: 0.565859, acc.: 70.31%] [G loss: 0.619051]\n",
      "epoch:17 step:16693 [D loss: 0.605501, acc.: 65.62%] [G loss: 0.627829]\n",
      "epoch:17 step:16694 [D loss: 0.594259, acc.: 67.19%] [G loss: 0.569831]\n",
      "epoch:17 step:16695 [D loss: 0.708521, acc.: 55.47%] [G loss: 0.667062]\n",
      "epoch:17 step:16696 [D loss: 0.522682, acc.: 77.34%] [G loss: 0.583761]\n",
      "epoch:17 step:16697 [D loss: 0.570074, acc.: 70.31%] [G loss: 0.814915]\n",
      "epoch:17 step:16698 [D loss: 0.490751, acc.: 75.00%] [G loss: 0.816590]\n",
      "epoch:17 step:16699 [D loss: 0.523472, acc.: 72.66%] [G loss: 0.961881]\n",
      "epoch:17 step:16700 [D loss: 0.534065, acc.: 67.97%] [G loss: 0.815423]\n",
      "epoch:17 step:16701 [D loss: 0.545062, acc.: 70.31%] [G loss: 0.681125]\n",
      "epoch:17 step:16702 [D loss: 0.546513, acc.: 68.75%] [G loss: 0.637385]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:17 step:16703 [D loss: 0.506881, acc.: 75.00%] [G loss: 0.653340]\n",
      "epoch:17 step:16704 [D loss: 0.527684, acc.: 72.66%] [G loss: 0.680626]\n",
      "epoch:17 step:16705 [D loss: 0.545497, acc.: 68.75%] [G loss: 0.599094]\n",
      "epoch:17 step:16706 [D loss: 0.540455, acc.: 72.66%] [G loss: 0.717636]\n",
      "epoch:17 step:16707 [D loss: 0.571560, acc.: 71.09%] [G loss: 0.467787]\n",
      "epoch:17 step:16708 [D loss: 0.535513, acc.: 70.31%] [G loss: 0.545194]\n",
      "epoch:17 step:16709 [D loss: 0.555494, acc.: 69.53%] [G loss: 0.625236]\n",
      "epoch:17 step:16710 [D loss: 0.470419, acc.: 75.78%] [G loss: 0.808037]\n",
      "epoch:17 step:16711 [D loss: 0.521465, acc.: 77.34%] [G loss: 0.773773]\n",
      "epoch:17 step:16712 [D loss: 0.587873, acc.: 65.62%] [G loss: 0.691378]\n",
      "epoch:17 step:16713 [D loss: 0.605909, acc.: 65.62%] [G loss: 0.532575]\n",
      "epoch:17 step:16714 [D loss: 0.543004, acc.: 68.75%] [G loss: 0.507486]\n",
      "epoch:17 step:16715 [D loss: 0.525061, acc.: 74.22%] [G loss: 0.597807]\n",
      "epoch:17 step:16716 [D loss: 0.577971, acc.: 70.31%] [G loss: 0.613017]\n",
      "epoch:17 step:16717 [D loss: 0.653175, acc.: 56.25%] [G loss: 0.491391]\n",
      "epoch:17 step:16718 [D loss: 0.545713, acc.: 67.97%] [G loss: 0.565759]\n",
      "epoch:17 step:16719 [D loss: 0.483971, acc.: 76.56%] [G loss: 0.592976]\n",
      "epoch:17 step:16720 [D loss: 0.508395, acc.: 75.78%] [G loss: 0.598774]\n",
      "epoch:17 step:16721 [D loss: 0.498757, acc.: 76.56%] [G loss: 0.536919]\n",
      "epoch:17 step:16722 [D loss: 0.600105, acc.: 72.66%] [G loss: 0.760328]\n",
      "epoch:17 step:16723 [D loss: 0.677362, acc.: 62.50%] [G loss: 0.635650]\n",
      "epoch:17 step:16724 [D loss: 0.597085, acc.: 63.28%] [G loss: 0.559633]\n",
      "epoch:17 step:16725 [D loss: 0.517083, acc.: 74.22%] [G loss: 0.695755]\n",
      "epoch:17 step:16726 [D loss: 0.497815, acc.: 80.47%] [G loss: 0.727213]\n",
      "epoch:17 step:16727 [D loss: 0.497940, acc.: 67.97%] [G loss: 0.721435]\n",
      "epoch:17 step:16728 [D loss: 0.580816, acc.: 64.06%] [G loss: 0.630195]\n",
      "epoch:17 step:16729 [D loss: 0.555662, acc.: 71.88%] [G loss: 0.733989]\n",
      "epoch:17 step:16730 [D loss: 0.508176, acc.: 73.44%] [G loss: 0.749996]\n",
      "epoch:17 step:16731 [D loss: 0.505866, acc.: 71.88%] [G loss: 0.830107]\n",
      "epoch:17 step:16732 [D loss: 0.512995, acc.: 75.00%] [G loss: 0.721426]\n",
      "epoch:17 step:16733 [D loss: 0.520251, acc.: 69.53%] [G loss: 0.627088]\n",
      "epoch:17 step:16734 [D loss: 0.581314, acc.: 65.62%] [G loss: 0.718943]\n",
      "epoch:17 step:16735 [D loss: 0.614771, acc.: 65.62%] [G loss: 0.690879]\n",
      "epoch:17 step:16736 [D loss: 0.550674, acc.: 68.75%] [G loss: 0.695023]\n",
      "epoch:17 step:16737 [D loss: 0.555901, acc.: 71.09%] [G loss: 0.622212]\n",
      "epoch:17 step:16738 [D loss: 0.527757, acc.: 71.09%] [G loss: 0.567535]\n",
      "epoch:17 step:16739 [D loss: 0.511271, acc.: 71.09%] [G loss: 0.693002]\n",
      "epoch:17 step:16740 [D loss: 0.589302, acc.: 67.97%] [G loss: 0.700974]\n",
      "epoch:17 step:16741 [D loss: 0.636128, acc.: 61.72%] [G loss: 0.450544]\n",
      "epoch:17 step:16742 [D loss: 0.527207, acc.: 71.09%] [G loss: 0.531311]\n",
      "epoch:17 step:16743 [D loss: 0.496149, acc.: 73.44%] [G loss: 0.605463]\n",
      "epoch:17 step:16744 [D loss: 0.493857, acc.: 74.22%] [G loss: 0.685563]\n",
      "epoch:17 step:16745 [D loss: 0.517761, acc.: 70.31%] [G loss: 0.728881]\n",
      "epoch:17 step:16746 [D loss: 0.653524, acc.: 61.72%] [G loss: 0.564955]\n",
      "epoch:17 step:16747 [D loss: 0.559982, acc.: 71.09%] [G loss: 0.628061]\n",
      "epoch:17 step:16748 [D loss: 0.542769, acc.: 70.31%] [G loss: 0.617089]\n",
      "epoch:17 step:16749 [D loss: 0.619261, acc.: 62.50%] [G loss: 0.570090]\n",
      "epoch:17 step:16750 [D loss: 0.556351, acc.: 64.06%] [G loss: 0.496342]\n",
      "epoch:17 step:16751 [D loss: 0.563130, acc.: 67.19%] [G loss: 0.514044]\n",
      "epoch:17 step:16752 [D loss: 0.439013, acc.: 78.91%] [G loss: 0.719938]\n",
      "epoch:17 step:16753 [D loss: 0.585437, acc.: 68.75%] [G loss: 0.634693]\n",
      "epoch:17 step:16754 [D loss: 0.566753, acc.: 67.97%] [G loss: 0.559575]\n",
      "epoch:17 step:16755 [D loss: 0.552085, acc.: 68.75%] [G loss: 0.603841]\n",
      "epoch:17 step:16756 [D loss: 0.576724, acc.: 67.97%] [G loss: 0.533334]\n",
      "epoch:17 step:16757 [D loss: 0.609793, acc.: 61.72%] [G loss: 0.579222]\n",
      "epoch:17 step:16758 [D loss: 0.535564, acc.: 66.41%] [G loss: 0.537586]\n",
      "epoch:17 step:16759 [D loss: 0.563188, acc.: 69.53%] [G loss: 0.569830]\n",
      "epoch:17 step:16760 [D loss: 0.511622, acc.: 74.22%] [G loss: 0.631776]\n",
      "epoch:17 step:16761 [D loss: 0.530339, acc.: 70.31%] [G loss: 0.583772]\n",
      "epoch:17 step:16762 [D loss: 0.550181, acc.: 71.88%] [G loss: 0.616107]\n",
      "epoch:17 step:16763 [D loss: 0.543072, acc.: 70.31%] [G loss: 0.516162]\n",
      "epoch:17 step:16764 [D loss: 0.576290, acc.: 70.31%] [G loss: 0.623796]\n",
      "epoch:17 step:16765 [D loss: 0.579438, acc.: 66.41%] [G loss: 0.541593]\n",
      "epoch:17 step:16766 [D loss: 0.524893, acc.: 73.44%] [G loss: 0.751465]\n",
      "epoch:17 step:16767 [D loss: 0.530806, acc.: 70.31%] [G loss: 0.626389]\n",
      "epoch:17 step:16768 [D loss: 0.555172, acc.: 71.09%] [G loss: 0.481962]\n",
      "epoch:17 step:16769 [D loss: 0.636553, acc.: 67.97%] [G loss: 0.515543]\n",
      "epoch:17 step:16770 [D loss: 0.551428, acc.: 67.97%] [G loss: 0.614674]\n",
      "epoch:17 step:16771 [D loss: 0.532970, acc.: 66.41%] [G loss: 0.526685]\n",
      "epoch:17 step:16772 [D loss: 0.535520, acc.: 74.22%] [G loss: 0.631647]\n",
      "epoch:17 step:16773 [D loss: 0.532027, acc.: 69.53%] [G loss: 0.590782]\n",
      "epoch:17 step:16774 [D loss: 0.570638, acc.: 66.41%] [G loss: 0.666254]\n",
      "epoch:17 step:16775 [D loss: 0.609495, acc.: 60.16%] [G loss: 0.565701]\n",
      "epoch:17 step:16776 [D loss: 0.614096, acc.: 65.62%] [G loss: 0.500691]\n",
      "epoch:17 step:16777 [D loss: 0.554547, acc.: 66.41%] [G loss: 0.473346]\n",
      "epoch:17 step:16778 [D loss: 0.536880, acc.: 68.75%] [G loss: 0.550428]\n",
      "epoch:17 step:16779 [D loss: 0.548888, acc.: 72.66%] [G loss: 0.593398]\n",
      "epoch:17 step:16780 [D loss: 0.562165, acc.: 63.28%] [G loss: 0.611749]\n",
      "epoch:17 step:16781 [D loss: 0.591382, acc.: 60.94%] [G loss: 0.600161]\n",
      "epoch:17 step:16782 [D loss: 0.523525, acc.: 71.88%] [G loss: 0.672983]\n",
      "epoch:17 step:16783 [D loss: 0.498623, acc.: 71.88%] [G loss: 0.671410]\n",
      "epoch:17 step:16784 [D loss: 0.585673, acc.: 64.06%] [G loss: 0.692264]\n",
      "epoch:17 step:16785 [D loss: 0.581202, acc.: 70.31%] [G loss: 0.684530]\n",
      "epoch:17 step:16786 [D loss: 0.474094, acc.: 82.81%] [G loss: 0.709358]\n",
      "epoch:17 step:16787 [D loss: 0.653588, acc.: 59.38%] [G loss: 0.707589]\n",
      "epoch:17 step:16788 [D loss: 0.599812, acc.: 66.41%] [G loss: 0.679890]\n",
      "epoch:17 step:16789 [D loss: 0.455777, acc.: 78.12%] [G loss: 0.772122]\n",
      "epoch:17 step:16790 [D loss: 0.649763, acc.: 65.62%] [G loss: 0.582134]\n",
      "epoch:17 step:16791 [D loss: 0.627023, acc.: 65.62%] [G loss: 0.614606]\n",
      "epoch:17 step:16792 [D loss: 0.570355, acc.: 69.53%] [G loss: 0.551135]\n",
      "epoch:17 step:16793 [D loss: 0.543912, acc.: 71.09%] [G loss: 0.574072]\n",
      "epoch:17 step:16794 [D loss: 0.544131, acc.: 74.22%] [G loss: 0.522090]\n",
      "epoch:17 step:16795 [D loss: 0.573866, acc.: 67.19%] [G loss: 0.465648]\n",
      "epoch:17 step:16796 [D loss: 0.654691, acc.: 57.03%] [G loss: 0.544741]\n",
      "epoch:17 step:16797 [D loss: 0.477708, acc.: 78.12%] [G loss: 0.623221]\n",
      "epoch:17 step:16798 [D loss: 0.561548, acc.: 67.19%] [G loss: 0.559561]\n",
      "epoch:17 step:16799 [D loss: 0.428109, acc.: 78.91%] [G loss: 0.680415]\n",
      "epoch:17 step:16800 [D loss: 0.497283, acc.: 75.00%] [G loss: 0.727640]\n",
      "##############\n",
      "[3.08313795 1.03680151 6.2409813  4.90434302 3.87262787 5.89116768\n",
      " 4.31872791 4.75733317 4.7888862  4.10988898]\n",
      "##########\n",
      "epoch:17 step:16801 [D loss: 0.545534, acc.: 71.09%] [G loss: 0.692526]\n",
      "epoch:17 step:16802 [D loss: 0.607534, acc.: 67.19%] [G loss: 0.623675]\n",
      "epoch:17 step:16803 [D loss: 0.546127, acc.: 65.62%] [G loss: 0.611894]\n",
      "epoch:17 step:16804 [D loss: 0.488293, acc.: 75.00%] [G loss: 0.656696]\n",
      "epoch:17 step:16805 [D loss: 0.538147, acc.: 69.53%] [G loss: 0.701371]\n",
      "epoch:17 step:16806 [D loss: 0.593778, acc.: 64.84%] [G loss: 0.536108]\n",
      "epoch:17 step:16807 [D loss: 0.519759, acc.: 74.22%] [G loss: 0.551581]\n",
      "epoch:17 step:16808 [D loss: 0.543076, acc.: 71.09%] [G loss: 0.574023]\n",
      "epoch:17 step:16809 [D loss: 0.642287, acc.: 57.81%] [G loss: 0.509333]\n",
      "epoch:17 step:16810 [D loss: 0.603135, acc.: 67.19%] [G loss: 0.466438]\n",
      "epoch:17 step:16811 [D loss: 0.591603, acc.: 60.94%] [G loss: 0.448620]\n",
      "epoch:17 step:16812 [D loss: 0.537633, acc.: 71.88%] [G loss: 0.659386]\n",
      "epoch:17 step:16813 [D loss: 0.446044, acc.: 81.25%] [G loss: 0.727720]\n",
      "epoch:17 step:16814 [D loss: 0.491959, acc.: 75.00%] [G loss: 0.654150]\n",
      "epoch:17 step:16815 [D loss: 0.511918, acc.: 75.78%] [G loss: 0.771794]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:17 step:16816 [D loss: 0.565712, acc.: 71.88%] [G loss: 0.772078]\n",
      "epoch:17 step:16817 [D loss: 0.524246, acc.: 68.75%] [G loss: 0.798789]\n",
      "epoch:17 step:16818 [D loss: 0.572265, acc.: 70.31%] [G loss: 0.735702]\n",
      "epoch:17 step:16819 [D loss: 0.493313, acc.: 74.22%] [G loss: 0.693578]\n",
      "epoch:17 step:16820 [D loss: 0.641293, acc.: 66.41%] [G loss: 0.676457]\n",
      "epoch:17 step:16821 [D loss: 0.649627, acc.: 60.94%] [G loss: 0.547793]\n",
      "epoch:17 step:16822 [D loss: 0.520963, acc.: 76.56%] [G loss: 0.772739]\n",
      "epoch:17 step:16823 [D loss: 0.425759, acc.: 81.25%] [G loss: 0.742332]\n",
      "epoch:17 step:16824 [D loss: 0.513119, acc.: 73.44%] [G loss: 0.665099]\n",
      "epoch:17 step:16825 [D loss: 0.484952, acc.: 76.56%] [G loss: 0.764067]\n",
      "epoch:17 step:16826 [D loss: 0.493458, acc.: 72.66%] [G loss: 0.726867]\n",
      "epoch:17 step:16827 [D loss: 0.454082, acc.: 78.91%] [G loss: 0.767996]\n",
      "epoch:17 step:16828 [D loss: 0.479778, acc.: 78.12%] [G loss: 0.762221]\n",
      "epoch:17 step:16829 [D loss: 0.492635, acc.: 78.12%] [G loss: 0.800164]\n",
      "epoch:17 step:16830 [D loss: 0.526414, acc.: 70.31%] [G loss: 0.733537]\n",
      "epoch:17 step:16831 [D loss: 0.604286, acc.: 67.97%] [G loss: 0.752727]\n",
      "epoch:17 step:16832 [D loss: 0.563036, acc.: 70.31%] [G loss: 0.641642]\n",
      "epoch:17 step:16833 [D loss: 0.504129, acc.: 77.34%] [G loss: 0.636112]\n",
      "epoch:17 step:16834 [D loss: 0.566235, acc.: 70.31%] [G loss: 0.687157]\n",
      "epoch:17 step:16835 [D loss: 0.504312, acc.: 73.44%] [G loss: 0.774043]\n",
      "epoch:17 step:16836 [D loss: 0.623499, acc.: 68.75%] [G loss: 0.623428]\n",
      "epoch:17 step:16837 [D loss: 0.565558, acc.: 69.53%] [G loss: 0.655218]\n",
      "epoch:17 step:16838 [D loss: 0.505038, acc.: 75.78%] [G loss: 0.662948]\n",
      "epoch:17 step:16839 [D loss: 0.536515, acc.: 71.09%] [G loss: 0.711354]\n",
      "epoch:17 step:16840 [D loss: 0.469741, acc.: 81.25%] [G loss: 0.903087]\n",
      "epoch:17 step:16841 [D loss: 0.466376, acc.: 79.69%] [G loss: 0.973398]\n",
      "epoch:17 step:16842 [D loss: 0.590014, acc.: 69.53%] [G loss: 0.870705]\n",
      "epoch:17 step:16843 [D loss: 0.543588, acc.: 68.75%] [G loss: 0.864387]\n",
      "epoch:17 step:16844 [D loss: 0.582660, acc.: 67.19%] [G loss: 0.724368]\n",
      "epoch:17 step:16845 [D loss: 0.561450, acc.: 67.19%] [G loss: 0.599183]\n",
      "epoch:17 step:16846 [D loss: 0.612095, acc.: 57.03%] [G loss: 0.576940]\n",
      "epoch:17 step:16847 [D loss: 0.568335, acc.: 71.88%] [G loss: 0.724983]\n",
      "epoch:17 step:16848 [D loss: 0.495316, acc.: 77.34%] [G loss: 0.733664]\n",
      "epoch:17 step:16849 [D loss: 0.714941, acc.: 55.47%] [G loss: 0.605901]\n",
      "epoch:17 step:16850 [D loss: 0.562472, acc.: 69.53%] [G loss: 0.728378]\n",
      "epoch:17 step:16851 [D loss: 0.589316, acc.: 66.41%] [G loss: 0.641496]\n",
      "epoch:17 step:16852 [D loss: 0.430292, acc.: 81.25%] [G loss: 0.746973]\n",
      "epoch:17 step:16853 [D loss: 0.483658, acc.: 73.44%] [G loss: 0.824965]\n",
      "epoch:17 step:16854 [D loss: 0.458723, acc.: 73.44%] [G loss: 0.923593]\n",
      "epoch:17 step:16855 [D loss: 0.435980, acc.: 76.56%] [G loss: 0.996685]\n",
      "epoch:17 step:16856 [D loss: 0.453534, acc.: 79.69%] [G loss: 1.209102]\n",
      "epoch:17 step:16857 [D loss: 0.664687, acc.: 67.19%] [G loss: 1.224346]\n",
      "epoch:17 step:16858 [D loss: 0.516987, acc.: 75.00%] [G loss: 1.244147]\n",
      "epoch:17 step:16859 [D loss: 0.507348, acc.: 77.34%] [G loss: 1.193244]\n",
      "epoch:17 step:16860 [D loss: 0.608707, acc.: 67.19%] [G loss: 1.070381]\n",
      "epoch:17 step:16861 [D loss: 0.642773, acc.: 61.72%] [G loss: 0.671029]\n",
      "epoch:17 step:16862 [D loss: 0.442611, acc.: 78.12%] [G loss: 0.975263]\n",
      "epoch:17 step:16863 [D loss: 0.595369, acc.: 67.97%] [G loss: 0.853639]\n",
      "epoch:17 step:16864 [D loss: 0.504061, acc.: 76.56%] [G loss: 0.891466]\n",
      "epoch:17 step:16865 [D loss: 0.433236, acc.: 75.78%] [G loss: 1.024676]\n",
      "epoch:17 step:16866 [D loss: 0.409217, acc.: 86.72%] [G loss: 1.309596]\n",
      "epoch:18 step:16867 [D loss: 0.555312, acc.: 71.09%] [G loss: 1.133018]\n",
      "epoch:18 step:16868 [D loss: 0.433930, acc.: 79.69%] [G loss: 1.006626]\n",
      "epoch:18 step:16869 [D loss: 0.603310, acc.: 67.19%] [G loss: 1.018216]\n",
      "epoch:18 step:16870 [D loss: 0.530157, acc.: 75.78%] [G loss: 0.861151]\n",
      "epoch:18 step:16871 [D loss: 0.566911, acc.: 70.31%] [G loss: 0.754623]\n",
      "epoch:18 step:16872 [D loss: 0.524800, acc.: 73.44%] [G loss: 0.753272]\n",
      "epoch:18 step:16873 [D loss: 0.540203, acc.: 74.22%] [G loss: 0.793691]\n",
      "epoch:18 step:16874 [D loss: 0.483843, acc.: 78.91%] [G loss: 0.762344]\n",
      "epoch:18 step:16875 [D loss: 0.491003, acc.: 79.69%] [G loss: 0.852153]\n",
      "epoch:18 step:16876 [D loss: 0.492289, acc.: 77.34%] [G loss: 0.860724]\n",
      "epoch:18 step:16877 [D loss: 0.481415, acc.: 75.78%] [G loss: 0.632922]\n",
      "epoch:18 step:16878 [D loss: 0.598197, acc.: 68.75%] [G loss: 0.738562]\n",
      "epoch:18 step:16879 [D loss: 0.548857, acc.: 72.66%] [G loss: 0.610019]\n",
      "epoch:18 step:16880 [D loss: 0.556932, acc.: 65.62%] [G loss: 0.469889]\n",
      "epoch:18 step:16881 [D loss: 0.469901, acc.: 78.12%] [G loss: 0.689742]\n",
      "epoch:18 step:16882 [D loss: 0.465071, acc.: 78.91%] [G loss: 0.626479]\n",
      "epoch:18 step:16883 [D loss: 0.532437, acc.: 70.31%] [G loss: 0.553465]\n",
      "epoch:18 step:16884 [D loss: 0.617036, acc.: 63.28%] [G loss: 0.916879]\n",
      "epoch:18 step:16885 [D loss: 0.605477, acc.: 64.84%] [G loss: 0.701148]\n",
      "epoch:18 step:16886 [D loss: 0.571171, acc.: 71.88%] [G loss: 0.546936]\n",
      "epoch:18 step:16887 [D loss: 0.544844, acc.: 72.66%] [G loss: 0.610892]\n",
      "epoch:18 step:16888 [D loss: 0.501721, acc.: 76.56%] [G loss: 0.879705]\n",
      "epoch:18 step:16889 [D loss: 0.547558, acc.: 68.75%] [G loss: 0.680972]\n",
      "epoch:18 step:16890 [D loss: 0.526813, acc.: 70.31%] [G loss: 0.637627]\n",
      "epoch:18 step:16891 [D loss: 0.459201, acc.: 80.47%] [G loss: 0.799015]\n",
      "epoch:18 step:16892 [D loss: 0.567354, acc.: 71.88%] [G loss: 0.695006]\n",
      "epoch:18 step:16893 [D loss: 0.482089, acc.: 72.66%] [G loss: 0.751953]\n",
      "epoch:18 step:16894 [D loss: 0.608336, acc.: 64.06%] [G loss: 0.514099]\n",
      "epoch:18 step:16895 [D loss: 0.526858, acc.: 71.09%] [G loss: 0.668325]\n",
      "epoch:18 step:16896 [D loss: 0.545959, acc.: 70.31%] [G loss: 0.618104]\n",
      "epoch:18 step:16897 [D loss: 0.615803, acc.: 61.72%] [G loss: 0.690484]\n",
      "epoch:18 step:16898 [D loss: 0.512304, acc.: 74.22%] [G loss: 0.659389]\n",
      "epoch:18 step:16899 [D loss: 0.527681, acc.: 71.09%] [G loss: 0.753656]\n",
      "epoch:18 step:16900 [D loss: 0.581971, acc.: 64.06%] [G loss: 0.585731]\n",
      "epoch:18 step:16901 [D loss: 0.577930, acc.: 70.31%] [G loss: 0.745089]\n",
      "epoch:18 step:16902 [D loss: 0.522848, acc.: 70.31%] [G loss: 0.602669]\n",
      "epoch:18 step:16903 [D loss: 0.521518, acc.: 75.00%] [G loss: 0.877175]\n",
      "epoch:18 step:16904 [D loss: 0.616735, acc.: 61.72%] [G loss: 0.601221]\n",
      "epoch:18 step:16905 [D loss: 0.567787, acc.: 70.31%] [G loss: 0.540500]\n",
      "epoch:18 step:16906 [D loss: 0.422518, acc.: 80.47%] [G loss: 0.817184]\n",
      "epoch:18 step:16907 [D loss: 0.562356, acc.: 66.41%] [G loss: 0.833797]\n",
      "epoch:18 step:16908 [D loss: 0.535121, acc.: 68.75%] [G loss: 0.617628]\n",
      "epoch:18 step:16909 [D loss: 0.545397, acc.: 70.31%] [G loss: 0.554445]\n",
      "epoch:18 step:16910 [D loss: 0.564680, acc.: 67.97%] [G loss: 0.599039]\n",
      "epoch:18 step:16911 [D loss: 0.477767, acc.: 75.78%] [G loss: 0.694634]\n",
      "epoch:18 step:16912 [D loss: 0.495062, acc.: 73.44%] [G loss: 0.749481]\n",
      "epoch:18 step:16913 [D loss: 0.549359, acc.: 68.75%] [G loss: 0.578656]\n",
      "epoch:18 step:16914 [D loss: 0.548575, acc.: 69.53%] [G loss: 0.667826]\n",
      "epoch:18 step:16915 [D loss: 0.480621, acc.: 75.00%] [G loss: 0.880497]\n",
      "epoch:18 step:16916 [D loss: 0.568796, acc.: 68.75%] [G loss: 0.571664]\n",
      "epoch:18 step:16917 [D loss: 0.654552, acc.: 60.94%] [G loss: 0.496676]\n",
      "epoch:18 step:16918 [D loss: 0.634251, acc.: 61.72%] [G loss: 0.548151]\n",
      "epoch:18 step:16919 [D loss: 0.536654, acc.: 71.88%] [G loss: 0.580436]\n",
      "epoch:18 step:16920 [D loss: 0.477121, acc.: 71.88%] [G loss: 0.701011]\n",
      "epoch:18 step:16921 [D loss: 0.566623, acc.: 67.19%] [G loss: 0.642970]\n",
      "epoch:18 step:16922 [D loss: 0.479828, acc.: 77.34%] [G loss: 0.687993]\n",
      "epoch:18 step:16923 [D loss: 0.488151, acc.: 75.78%] [G loss: 0.784360]\n",
      "epoch:18 step:16924 [D loss: 0.548595, acc.: 70.31%] [G loss: 0.586519]\n",
      "epoch:18 step:16925 [D loss: 0.499073, acc.: 75.78%] [G loss: 0.752210]\n",
      "epoch:18 step:16926 [D loss: 0.547843, acc.: 68.75%] [G loss: 0.565094]\n",
      "epoch:18 step:16927 [D loss: 0.557610, acc.: 71.09%] [G loss: 0.622437]\n",
      "epoch:18 step:16928 [D loss: 0.581671, acc.: 67.97%] [G loss: 0.646713]\n",
      "epoch:18 step:16929 [D loss: 0.525220, acc.: 71.88%] [G loss: 0.497733]\n",
      "epoch:18 step:16930 [D loss: 0.578459, acc.: 67.97%] [G loss: 0.586023]\n",
      "epoch:18 step:16931 [D loss: 0.520483, acc.: 75.78%] [G loss: 0.616083]\n",
      "epoch:18 step:16932 [D loss: 0.550432, acc.: 68.75%] [G loss: 0.623673]\n",
      "epoch:18 step:16933 [D loss: 0.521412, acc.: 74.22%] [G loss: 0.588432]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:18 step:16934 [D loss: 0.543584, acc.: 67.97%] [G loss: 0.571506]\n",
      "epoch:18 step:16935 [D loss: 0.486236, acc.: 77.34%] [G loss: 0.574707]\n",
      "epoch:18 step:16936 [D loss: 0.533299, acc.: 75.00%] [G loss: 0.598656]\n",
      "epoch:18 step:16937 [D loss: 0.522238, acc.: 72.66%] [G loss: 0.514952]\n",
      "epoch:18 step:16938 [D loss: 0.567724, acc.: 72.66%] [G loss: 0.594604]\n",
      "epoch:18 step:16939 [D loss: 0.527678, acc.: 72.66%] [G loss: 0.738668]\n",
      "epoch:18 step:16940 [D loss: 0.490041, acc.: 73.44%] [G loss: 0.767537]\n",
      "epoch:18 step:16941 [D loss: 0.556485, acc.: 70.31%] [G loss: 0.786053]\n",
      "epoch:18 step:16942 [D loss: 0.535789, acc.: 71.09%] [G loss: 0.688527]\n",
      "epoch:18 step:16943 [D loss: 0.491475, acc.: 71.88%] [G loss: 0.676011]\n",
      "epoch:18 step:16944 [D loss: 0.597463, acc.: 70.31%] [G loss: 0.685245]\n",
      "epoch:18 step:16945 [D loss: 0.591754, acc.: 68.75%] [G loss: 0.576094]\n",
      "epoch:18 step:16946 [D loss: 0.505393, acc.: 72.66%] [G loss: 0.676860]\n",
      "epoch:18 step:16947 [D loss: 0.511186, acc.: 75.78%] [G loss: 0.697517]\n",
      "epoch:18 step:16948 [D loss: 0.511915, acc.: 73.44%] [G loss: 0.683570]\n",
      "epoch:18 step:16949 [D loss: 0.495221, acc.: 75.78%] [G loss: 0.678920]\n",
      "epoch:18 step:16950 [D loss: 0.508427, acc.: 71.88%] [G loss: 0.713811]\n",
      "epoch:18 step:16951 [D loss: 0.590819, acc.: 68.75%] [G loss: 0.560188]\n",
      "epoch:18 step:16952 [D loss: 0.566963, acc.: 66.41%] [G loss: 0.538990]\n",
      "epoch:18 step:16953 [D loss: 0.537817, acc.: 70.31%] [G loss: 0.603313]\n",
      "epoch:18 step:16954 [D loss: 0.532297, acc.: 75.00%] [G loss: 0.793982]\n",
      "epoch:18 step:16955 [D loss: 0.513705, acc.: 73.44%] [G loss: 0.672789]\n",
      "epoch:18 step:16956 [D loss: 0.500182, acc.: 75.78%] [G loss: 0.720569]\n",
      "epoch:18 step:16957 [D loss: 0.548846, acc.: 70.31%] [G loss: 0.698153]\n",
      "epoch:18 step:16958 [D loss: 0.488989, acc.: 76.56%] [G loss: 0.716914]\n",
      "epoch:18 step:16959 [D loss: 0.504356, acc.: 71.09%] [G loss: 0.679391]\n",
      "epoch:18 step:16960 [D loss: 0.535943, acc.: 72.66%] [G loss: 0.775561]\n",
      "epoch:18 step:16961 [D loss: 0.496320, acc.: 71.88%] [G loss: 0.694102]\n",
      "epoch:18 step:16962 [D loss: 0.554375, acc.: 67.97%] [G loss: 0.619339]\n",
      "epoch:18 step:16963 [D loss: 0.471216, acc.: 78.12%] [G loss: 0.636737]\n",
      "epoch:18 step:16964 [D loss: 0.570707, acc.: 69.53%] [G loss: 0.702953]\n",
      "epoch:18 step:16965 [D loss: 0.560241, acc.: 74.22%] [G loss: 0.601373]\n",
      "epoch:18 step:16966 [D loss: 0.462129, acc.: 76.56%] [G loss: 0.790209]\n",
      "epoch:18 step:16967 [D loss: 0.504222, acc.: 71.88%] [G loss: 0.749044]\n",
      "epoch:18 step:16968 [D loss: 0.622245, acc.: 67.97%] [G loss: 0.596726]\n",
      "epoch:18 step:16969 [D loss: 0.532677, acc.: 69.53%] [G loss: 0.554069]\n",
      "epoch:18 step:16970 [D loss: 0.562146, acc.: 70.31%] [G loss: 0.730560]\n",
      "epoch:18 step:16971 [D loss: 0.612125, acc.: 63.28%] [G loss: 0.729453]\n",
      "epoch:18 step:16972 [D loss: 0.557054, acc.: 71.09%] [G loss: 0.713027]\n",
      "epoch:18 step:16973 [D loss: 0.552343, acc.: 67.97%] [G loss: 0.615381]\n",
      "epoch:18 step:16974 [D loss: 0.662414, acc.: 63.28%] [G loss: 0.489926]\n",
      "epoch:18 step:16975 [D loss: 0.556321, acc.: 71.09%] [G loss: 0.545658]\n",
      "epoch:18 step:16976 [D loss: 0.525567, acc.: 71.88%] [G loss: 0.662609]\n",
      "epoch:18 step:16977 [D loss: 0.524118, acc.: 71.88%] [G loss: 0.515029]\n",
      "epoch:18 step:16978 [D loss: 0.535932, acc.: 76.56%] [G loss: 0.682903]\n",
      "epoch:18 step:16979 [D loss: 0.516050, acc.: 75.00%] [G loss: 0.622571]\n",
      "epoch:18 step:16980 [D loss: 0.517278, acc.: 74.22%] [G loss: 0.769091]\n",
      "epoch:18 step:16981 [D loss: 0.487392, acc.: 78.91%] [G loss: 0.675087]\n",
      "epoch:18 step:16982 [D loss: 0.575023, acc.: 66.41%] [G loss: 0.661723]\n",
      "epoch:18 step:16983 [D loss: 0.562274, acc.: 67.97%] [G loss: 0.667395]\n",
      "epoch:18 step:16984 [D loss: 0.501918, acc.: 69.53%] [G loss: 0.712270]\n",
      "epoch:18 step:16985 [D loss: 0.489401, acc.: 79.69%] [G loss: 0.746948]\n",
      "epoch:18 step:16986 [D loss: 0.589637, acc.: 64.84%] [G loss: 0.703572]\n",
      "epoch:18 step:16987 [D loss: 0.492759, acc.: 76.56%] [G loss: 0.777604]\n",
      "epoch:18 step:16988 [D loss: 0.494022, acc.: 78.91%] [G loss: 0.871207]\n",
      "epoch:18 step:16989 [D loss: 0.541046, acc.: 75.00%] [G loss: 1.010554]\n",
      "epoch:18 step:16990 [D loss: 0.587680, acc.: 67.97%] [G loss: 0.728511]\n",
      "epoch:18 step:16991 [D loss: 0.585159, acc.: 64.06%] [G loss: 0.680087]\n",
      "epoch:18 step:16992 [D loss: 0.516509, acc.: 73.44%] [G loss: 0.568337]\n",
      "epoch:18 step:16993 [D loss: 0.525756, acc.: 73.44%] [G loss: 0.686538]\n",
      "epoch:18 step:16994 [D loss: 0.507144, acc.: 71.09%] [G loss: 0.638890]\n",
      "epoch:18 step:16995 [D loss: 0.584118, acc.: 63.28%] [G loss: 0.635928]\n",
      "epoch:18 step:16996 [D loss: 0.482027, acc.: 75.78%] [G loss: 0.543329]\n",
      "epoch:18 step:16997 [D loss: 0.493106, acc.: 69.53%] [G loss: 0.618505]\n",
      "epoch:18 step:16998 [D loss: 0.540329, acc.: 72.66%] [G loss: 0.640356]\n",
      "epoch:18 step:16999 [D loss: 0.583942, acc.: 64.84%] [G loss: 0.742299]\n",
      "epoch:18 step:17000 [D loss: 0.526845, acc.: 71.88%] [G loss: 0.620345]\n",
      "##############\n",
      "[2.80255631 0.9864154  6.22347198 4.66302328 3.81570979 5.70954803\n",
      " 4.61589977 4.77155701 4.69416084 4.17629036]\n",
      "##########\n",
      "epoch:18 step:17001 [D loss: 0.490649, acc.: 76.56%] [G loss: 0.759869]\n",
      "epoch:18 step:17002 [D loss: 0.530659, acc.: 72.66%] [G loss: 0.702145]\n",
      "epoch:18 step:17003 [D loss: 0.652646, acc.: 64.06%] [G loss: 0.574736]\n",
      "epoch:18 step:17004 [D loss: 0.576913, acc.: 68.75%] [G loss: 0.667603]\n",
      "epoch:18 step:17005 [D loss: 0.525336, acc.: 71.09%] [G loss: 0.525396]\n",
      "epoch:18 step:17006 [D loss: 0.570183, acc.: 66.41%] [G loss: 0.569922]\n",
      "epoch:18 step:17007 [D loss: 0.534218, acc.: 69.53%] [G loss: 0.476063]\n",
      "epoch:18 step:17008 [D loss: 0.576010, acc.: 59.38%] [G loss: 0.477346]\n",
      "epoch:18 step:17009 [D loss: 0.610296, acc.: 58.59%] [G loss: 0.513117]\n",
      "epoch:18 step:17010 [D loss: 0.495170, acc.: 72.66%] [G loss: 0.613866]\n",
      "epoch:18 step:17011 [D loss: 0.587884, acc.: 66.41%] [G loss: 0.484402]\n",
      "epoch:18 step:17012 [D loss: 0.507623, acc.: 72.66%] [G loss: 0.616688]\n",
      "epoch:18 step:17013 [D loss: 0.590392, acc.: 67.97%] [G loss: 0.490807]\n",
      "epoch:18 step:17014 [D loss: 0.628372, acc.: 64.06%] [G loss: 0.518069]\n",
      "epoch:18 step:17015 [D loss: 0.510647, acc.: 71.09%] [G loss: 0.617868]\n",
      "epoch:18 step:17016 [D loss: 0.580005, acc.: 70.31%] [G loss: 0.510506]\n",
      "epoch:18 step:17017 [D loss: 0.577355, acc.: 67.19%] [G loss: 0.512400]\n",
      "epoch:18 step:17018 [D loss: 0.484797, acc.: 76.56%] [G loss: 0.861146]\n",
      "epoch:18 step:17019 [D loss: 0.632009, acc.: 61.72%] [G loss: 0.680525]\n",
      "epoch:18 step:17020 [D loss: 0.543869, acc.: 69.53%] [G loss: 0.689425]\n",
      "epoch:18 step:17021 [D loss: 0.506034, acc.: 71.09%] [G loss: 0.648519]\n",
      "epoch:18 step:17022 [D loss: 0.545265, acc.: 72.66%] [G loss: 0.588290]\n",
      "epoch:18 step:17023 [D loss: 0.577258, acc.: 67.97%] [G loss: 0.622235]\n",
      "epoch:18 step:17024 [D loss: 0.569615, acc.: 67.97%] [G loss: 0.578796]\n",
      "epoch:18 step:17025 [D loss: 0.482303, acc.: 77.34%] [G loss: 0.617333]\n",
      "epoch:18 step:17026 [D loss: 0.665542, acc.: 61.72%] [G loss: 0.598046]\n",
      "epoch:18 step:17027 [D loss: 0.543895, acc.: 69.53%] [G loss: 0.741938]\n",
      "epoch:18 step:17028 [D loss: 0.497462, acc.: 75.78%] [G loss: 0.903593]\n",
      "epoch:18 step:17029 [D loss: 0.582683, acc.: 65.62%] [G loss: 0.788692]\n",
      "epoch:18 step:17030 [D loss: 0.540051, acc.: 71.09%] [G loss: 0.686593]\n",
      "epoch:18 step:17031 [D loss: 0.504818, acc.: 72.66%] [G loss: 0.655250]\n",
      "epoch:18 step:17032 [D loss: 0.545525, acc.: 73.44%] [G loss: 0.584707]\n",
      "epoch:18 step:17033 [D loss: 0.498904, acc.: 74.22%] [G loss: 0.749700]\n",
      "epoch:18 step:17034 [D loss: 0.551334, acc.: 70.31%] [G loss: 0.561973]\n",
      "epoch:18 step:17035 [D loss: 0.595070, acc.: 64.06%] [G loss: 0.467934]\n",
      "epoch:18 step:17036 [D loss: 0.555315, acc.: 66.41%] [G loss: 0.511611]\n",
      "epoch:18 step:17037 [D loss: 0.549659, acc.: 67.97%] [G loss: 0.551981]\n",
      "epoch:18 step:17038 [D loss: 0.529737, acc.: 72.66%] [G loss: 0.693348]\n",
      "epoch:18 step:17039 [D loss: 0.480822, acc.: 80.47%] [G loss: 0.601155]\n",
      "epoch:18 step:17040 [D loss: 0.600958, acc.: 64.84%] [G loss: 0.539810]\n",
      "epoch:18 step:17041 [D loss: 0.593641, acc.: 64.06%] [G loss: 0.480913]\n",
      "epoch:18 step:17042 [D loss: 0.504974, acc.: 75.00%] [G loss: 0.661760]\n",
      "epoch:18 step:17043 [D loss: 0.481478, acc.: 79.69%] [G loss: 0.666972]\n",
      "epoch:18 step:17044 [D loss: 0.539144, acc.: 71.09%] [G loss: 0.540335]\n",
      "epoch:18 step:17045 [D loss: 0.526609, acc.: 73.44%] [G loss: 0.640814]\n",
      "epoch:18 step:17046 [D loss: 0.657062, acc.: 60.94%] [G loss: 0.448583]\n",
      "epoch:18 step:17047 [D loss: 0.554135, acc.: 69.53%] [G loss: 0.480863]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:18 step:17048 [D loss: 0.542479, acc.: 70.31%] [G loss: 0.653595]\n",
      "epoch:18 step:17049 [D loss: 0.555380, acc.: 67.97%] [G loss: 0.676732]\n",
      "epoch:18 step:17050 [D loss: 0.554000, acc.: 67.19%] [G loss: 0.617226]\n",
      "epoch:18 step:17051 [D loss: 0.611933, acc.: 65.62%] [G loss: 0.642736]\n",
      "epoch:18 step:17052 [D loss: 0.550695, acc.: 67.97%] [G loss: 0.569560]\n",
      "epoch:18 step:17053 [D loss: 0.611468, acc.: 66.41%] [G loss: 0.541609]\n",
      "epoch:18 step:17054 [D loss: 0.570297, acc.: 68.75%] [G loss: 0.583637]\n",
      "epoch:18 step:17055 [D loss: 0.551357, acc.: 70.31%] [G loss: 0.611305]\n",
      "epoch:18 step:17056 [D loss: 0.493613, acc.: 77.34%] [G loss: 0.624333]\n",
      "epoch:18 step:17057 [D loss: 0.492434, acc.: 78.12%] [G loss: 0.679373]\n",
      "epoch:18 step:17058 [D loss: 0.525198, acc.: 73.44%] [G loss: 0.623942]\n",
      "epoch:18 step:17059 [D loss: 0.567190, acc.: 71.09%] [G loss: 0.837860]\n",
      "epoch:18 step:17060 [D loss: 0.463707, acc.: 78.91%] [G loss: 0.789768]\n",
      "epoch:18 step:17061 [D loss: 0.550194, acc.: 74.22%] [G loss: 0.652964]\n",
      "epoch:18 step:17062 [D loss: 0.518848, acc.: 72.66%] [G loss: 0.658819]\n",
      "epoch:18 step:17063 [D loss: 0.502758, acc.: 75.00%] [G loss: 0.787065]\n",
      "epoch:18 step:17064 [D loss: 0.475656, acc.: 76.56%] [G loss: 0.688895]\n",
      "epoch:18 step:17065 [D loss: 0.467701, acc.: 75.78%] [G loss: 0.887527]\n",
      "epoch:18 step:17066 [D loss: 0.699487, acc.: 61.72%] [G loss: 0.618797]\n",
      "epoch:18 step:17067 [D loss: 0.584341, acc.: 69.53%] [G loss: 0.626792]\n",
      "epoch:18 step:17068 [D loss: 0.567493, acc.: 67.19%] [G loss: 0.672493]\n",
      "epoch:18 step:17069 [D loss: 0.644102, acc.: 64.06%] [G loss: 0.632094]\n",
      "epoch:18 step:17070 [D loss: 0.582553, acc.: 64.84%] [G loss: 0.576583]\n",
      "epoch:18 step:17071 [D loss: 0.494539, acc.: 75.00%] [G loss: 0.885123]\n",
      "epoch:18 step:17072 [D loss: 0.525526, acc.: 71.09%] [G loss: 0.796212]\n",
      "epoch:18 step:17073 [D loss: 0.432009, acc.: 82.03%] [G loss: 0.771006]\n",
      "epoch:18 step:17074 [D loss: 0.446900, acc.: 75.00%] [G loss: 0.892753]\n",
      "epoch:18 step:17075 [D loss: 0.496905, acc.: 76.56%] [G loss: 0.779793]\n",
      "epoch:18 step:17076 [D loss: 0.627908, acc.: 64.06%] [G loss: 0.574366]\n",
      "epoch:18 step:17077 [D loss: 0.615847, acc.: 65.62%] [G loss: 0.585149]\n",
      "epoch:18 step:17078 [D loss: 0.528280, acc.: 75.78%] [G loss: 0.546305]\n",
      "epoch:18 step:17079 [D loss: 0.552711, acc.: 69.53%] [G loss: 0.684863]\n",
      "epoch:18 step:17080 [D loss: 0.613006, acc.: 62.50%] [G loss: 0.536701]\n",
      "epoch:18 step:17081 [D loss: 0.544408, acc.: 72.66%] [G loss: 0.531522]\n",
      "epoch:18 step:17082 [D loss: 0.499130, acc.: 71.88%] [G loss: 0.770614]\n",
      "epoch:18 step:17083 [D loss: 0.493942, acc.: 73.44%] [G loss: 0.573909]\n",
      "epoch:18 step:17084 [D loss: 0.553729, acc.: 71.88%] [G loss: 0.768706]\n",
      "epoch:18 step:17085 [D loss: 0.485553, acc.: 78.12%] [G loss: 0.903447]\n",
      "epoch:18 step:17086 [D loss: 0.679956, acc.: 64.06%] [G loss: 0.740697]\n",
      "epoch:18 step:17087 [D loss: 0.533560, acc.: 72.66%] [G loss: 0.737994]\n",
      "epoch:18 step:17088 [D loss: 0.502653, acc.: 71.09%] [G loss: 0.753320]\n",
      "epoch:18 step:17089 [D loss: 0.554092, acc.: 71.09%] [G loss: 0.778590]\n",
      "epoch:18 step:17090 [D loss: 0.550896, acc.: 76.56%] [G loss: 0.650927]\n",
      "epoch:18 step:17091 [D loss: 0.569672, acc.: 69.53%] [G loss: 0.684341]\n",
      "epoch:18 step:17092 [D loss: 0.558962, acc.: 64.84%] [G loss: 0.665270]\n",
      "epoch:18 step:17093 [D loss: 0.499794, acc.: 74.22%] [G loss: 0.750472]\n",
      "epoch:18 step:17094 [D loss: 0.579579, acc.: 68.75%] [G loss: 0.681698]\n",
      "epoch:18 step:17095 [D loss: 0.513471, acc.: 71.09%] [G loss: 0.805654]\n",
      "epoch:18 step:17096 [D loss: 0.502540, acc.: 71.88%] [G loss: 0.691297]\n",
      "epoch:18 step:17097 [D loss: 0.534211, acc.: 70.31%] [G loss: 0.770645]\n",
      "epoch:18 step:17098 [D loss: 0.479246, acc.: 75.00%] [G loss: 0.868795]\n",
      "epoch:18 step:17099 [D loss: 0.555572, acc.: 68.75%] [G loss: 0.875400]\n",
      "epoch:18 step:17100 [D loss: 0.582773, acc.: 70.31%] [G loss: 0.701068]\n",
      "epoch:18 step:17101 [D loss: 0.565020, acc.: 69.53%] [G loss: 0.524774]\n",
      "epoch:18 step:17102 [D loss: 0.471553, acc.: 75.00%] [G loss: 0.727124]\n",
      "epoch:18 step:17103 [D loss: 0.556764, acc.: 67.97%] [G loss: 0.558810]\n",
      "epoch:18 step:17104 [D loss: 0.564915, acc.: 70.31%] [G loss: 0.587930]\n",
      "epoch:18 step:17105 [D loss: 0.545101, acc.: 71.09%] [G loss: 0.572765]\n",
      "epoch:18 step:17106 [D loss: 0.539629, acc.: 72.66%] [G loss: 0.604584]\n",
      "epoch:18 step:17107 [D loss: 0.517557, acc.: 73.44%] [G loss: 0.517967]\n",
      "epoch:18 step:17108 [D loss: 0.550259, acc.: 70.31%] [G loss: 0.651831]\n",
      "epoch:18 step:17109 [D loss: 0.555715, acc.: 70.31%] [G loss: 0.609477]\n",
      "epoch:18 step:17110 [D loss: 0.488782, acc.: 75.00%] [G loss: 0.793948]\n",
      "epoch:18 step:17111 [D loss: 0.514406, acc.: 74.22%] [G loss: 0.654449]\n",
      "epoch:18 step:17112 [D loss: 0.481620, acc.: 75.00%] [G loss: 0.708514]\n",
      "epoch:18 step:17113 [D loss: 0.541460, acc.: 66.41%] [G loss: 0.773945]\n",
      "epoch:18 step:17114 [D loss: 0.542423, acc.: 71.88%] [G loss: 0.748513]\n",
      "epoch:18 step:17115 [D loss: 0.588590, acc.: 64.84%] [G loss: 0.704000]\n",
      "epoch:18 step:17116 [D loss: 0.641891, acc.: 61.72%] [G loss: 0.943437]\n",
      "epoch:18 step:17117 [D loss: 0.583711, acc.: 67.97%] [G loss: 0.645164]\n",
      "epoch:18 step:17118 [D loss: 0.557149, acc.: 67.97%] [G loss: 0.558249]\n",
      "epoch:18 step:17119 [D loss: 0.555096, acc.: 69.53%] [G loss: 0.679327]\n",
      "epoch:18 step:17120 [D loss: 0.522309, acc.: 71.88%] [G loss: 0.592566]\n",
      "epoch:18 step:17121 [D loss: 0.544035, acc.: 67.19%] [G loss: 0.686935]\n",
      "epoch:18 step:17122 [D loss: 0.531587, acc.: 72.66%] [G loss: 0.635600]\n",
      "epoch:18 step:17123 [D loss: 0.597227, acc.: 61.72%] [G loss: 0.520402]\n",
      "epoch:18 step:17124 [D loss: 0.496513, acc.: 75.00%] [G loss: 0.525823]\n",
      "epoch:18 step:17125 [D loss: 0.542109, acc.: 70.31%] [G loss: 0.683659]\n",
      "epoch:18 step:17126 [D loss: 0.572356, acc.: 66.41%] [G loss: 0.685175]\n",
      "epoch:18 step:17127 [D loss: 0.516607, acc.: 76.56%] [G loss: 0.592928]\n",
      "epoch:18 step:17128 [D loss: 0.531582, acc.: 71.09%] [G loss: 0.521949]\n",
      "epoch:18 step:17129 [D loss: 0.563877, acc.: 74.22%] [G loss: 0.652356]\n",
      "epoch:18 step:17130 [D loss: 0.541727, acc.: 70.31%] [G loss: 0.659507]\n",
      "epoch:18 step:17131 [D loss: 0.520143, acc.: 71.09%] [G loss: 0.724595]\n",
      "epoch:18 step:17132 [D loss: 0.566070, acc.: 71.09%] [G loss: 0.562106]\n",
      "epoch:18 step:17133 [D loss: 0.557832, acc.: 68.75%] [G loss: 0.562475]\n",
      "epoch:18 step:17134 [D loss: 0.500025, acc.: 78.91%] [G loss: 0.668935]\n",
      "epoch:18 step:17135 [D loss: 0.565393, acc.: 66.41%] [G loss: 0.504440]\n",
      "epoch:18 step:17136 [D loss: 0.496085, acc.: 77.34%] [G loss: 0.813419]\n",
      "epoch:18 step:17137 [D loss: 0.534424, acc.: 75.78%] [G loss: 0.749504]\n",
      "epoch:18 step:17138 [D loss: 0.581695, acc.: 64.84%] [G loss: 0.600588]\n",
      "epoch:18 step:17139 [D loss: 0.504328, acc.: 70.31%] [G loss: 0.822542]\n",
      "epoch:18 step:17140 [D loss: 0.489961, acc.: 78.12%] [G loss: 0.616834]\n",
      "epoch:18 step:17141 [D loss: 0.673183, acc.: 65.62%] [G loss: 0.559783]\n",
      "epoch:18 step:17142 [D loss: 0.483801, acc.: 76.56%] [G loss: 0.687470]\n",
      "epoch:18 step:17143 [D loss: 0.648902, acc.: 66.41%] [G loss: 0.564644]\n",
      "epoch:18 step:17144 [D loss: 0.655309, acc.: 60.16%] [G loss: 0.442628]\n",
      "epoch:18 step:17145 [D loss: 0.563516, acc.: 65.62%] [G loss: 0.485523]\n",
      "epoch:18 step:17146 [D loss: 0.520007, acc.: 72.66%] [G loss: 0.609507]\n",
      "epoch:18 step:17147 [D loss: 0.586313, acc.: 66.41%] [G loss: 0.602842]\n",
      "epoch:18 step:17148 [D loss: 0.589426, acc.: 66.41%] [G loss: 0.614663]\n",
      "epoch:18 step:17149 [D loss: 0.546029, acc.: 71.88%] [G loss: 0.660838]\n",
      "epoch:18 step:17150 [D loss: 0.556263, acc.: 65.62%] [G loss: 0.642488]\n",
      "epoch:18 step:17151 [D loss: 0.560900, acc.: 74.22%] [G loss: 0.673648]\n",
      "epoch:18 step:17152 [D loss: 0.541170, acc.: 72.66%] [G loss: 0.712979]\n",
      "epoch:18 step:17153 [D loss: 0.601433, acc.: 64.84%] [G loss: 0.626312]\n",
      "epoch:18 step:17154 [D loss: 0.567620, acc.: 72.66%] [G loss: 0.614603]\n",
      "epoch:18 step:17155 [D loss: 0.548541, acc.: 71.09%] [G loss: 0.536822]\n",
      "epoch:18 step:17156 [D loss: 0.562707, acc.: 70.31%] [G loss: 0.552383]\n",
      "epoch:18 step:17157 [D loss: 0.604470, acc.: 62.50%] [G loss: 0.472171]\n",
      "epoch:18 step:17158 [D loss: 0.513172, acc.: 71.88%] [G loss: 0.613612]\n",
      "epoch:18 step:17159 [D loss: 0.538822, acc.: 73.44%] [G loss: 0.608976]\n",
      "epoch:18 step:17160 [D loss: 0.600149, acc.: 64.06%] [G loss: 0.513381]\n",
      "epoch:18 step:17161 [D loss: 0.629827, acc.: 62.50%] [G loss: 0.555779]\n",
      "epoch:18 step:17162 [D loss: 0.469941, acc.: 78.91%] [G loss: 0.678195]\n",
      "epoch:18 step:17163 [D loss: 0.608129, acc.: 62.50%] [G loss: 0.623837]\n",
      "epoch:18 step:17164 [D loss: 0.444247, acc.: 80.47%] [G loss: 0.559697]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:18 step:17165 [D loss: 0.467192, acc.: 77.34%] [G loss: 0.702987]\n",
      "epoch:18 step:17166 [D loss: 0.490014, acc.: 72.66%] [G loss: 0.688856]\n",
      "epoch:18 step:17167 [D loss: 0.678095, acc.: 59.38%] [G loss: 0.562073]\n",
      "epoch:18 step:17168 [D loss: 0.549478, acc.: 72.66%] [G loss: 0.682585]\n",
      "epoch:18 step:17169 [D loss: 0.606310, acc.: 67.19%] [G loss: 0.537603]\n",
      "epoch:18 step:17170 [D loss: 0.431816, acc.: 84.38%] [G loss: 0.630549]\n",
      "epoch:18 step:17171 [D loss: 0.515547, acc.: 71.09%] [G loss: 0.591084]\n",
      "epoch:18 step:17172 [D loss: 0.548860, acc.: 71.09%] [G loss: 0.516731]\n",
      "epoch:18 step:17173 [D loss: 0.475268, acc.: 75.78%] [G loss: 0.689749]\n",
      "epoch:18 step:17174 [D loss: 0.512448, acc.: 75.00%] [G loss: 0.706647]\n",
      "epoch:18 step:17175 [D loss: 0.532622, acc.: 67.97%] [G loss: 0.656668]\n",
      "epoch:18 step:17176 [D loss: 0.519247, acc.: 68.75%] [G loss: 0.703475]\n",
      "epoch:18 step:17177 [D loss: 0.506912, acc.: 74.22%] [G loss: 0.723054]\n",
      "epoch:18 step:17178 [D loss: 0.461062, acc.: 81.25%] [G loss: 0.820156]\n",
      "epoch:18 step:17179 [D loss: 0.499582, acc.: 70.31%] [G loss: 0.923588]\n",
      "epoch:18 step:17180 [D loss: 0.487381, acc.: 73.44%] [G loss: 0.892682]\n",
      "epoch:18 step:17181 [D loss: 0.515857, acc.: 70.31%] [G loss: 0.888738]\n",
      "epoch:18 step:17182 [D loss: 0.653381, acc.: 65.62%] [G loss: 0.747429]\n",
      "epoch:18 step:17183 [D loss: 0.620882, acc.: 64.84%] [G loss: 0.519557]\n",
      "epoch:18 step:17184 [D loss: 0.508064, acc.: 72.66%] [G loss: 0.689331]\n",
      "epoch:18 step:17185 [D loss: 0.569093, acc.: 65.62%] [G loss: 0.639369]\n",
      "epoch:18 step:17186 [D loss: 0.569906, acc.: 67.97%] [G loss: 0.577383]\n",
      "epoch:18 step:17187 [D loss: 0.436290, acc.: 82.03%] [G loss: 0.676306]\n",
      "epoch:18 step:17188 [D loss: 0.507434, acc.: 72.66%] [G loss: 0.799163]\n",
      "epoch:18 step:17189 [D loss: 0.643664, acc.: 64.06%] [G loss: 0.477290]\n",
      "epoch:18 step:17190 [D loss: 0.585455, acc.: 66.41%] [G loss: 0.584971]\n",
      "epoch:18 step:17191 [D loss: 0.609434, acc.: 64.84%] [G loss: 0.607961]\n",
      "epoch:18 step:17192 [D loss: 0.424811, acc.: 78.12%] [G loss: 0.629084]\n",
      "epoch:18 step:17193 [D loss: 0.514128, acc.: 73.44%] [G loss: 0.835448]\n",
      "epoch:18 step:17194 [D loss: 0.490734, acc.: 78.12%] [G loss: 0.676808]\n",
      "epoch:18 step:17195 [D loss: 0.546169, acc.: 74.22%] [G loss: 0.627018]\n",
      "epoch:18 step:17196 [D loss: 0.589139, acc.: 66.41%] [G loss: 0.584112]\n",
      "epoch:18 step:17197 [D loss: 0.519946, acc.: 71.09%] [G loss: 0.531930]\n",
      "epoch:18 step:17198 [D loss: 0.501674, acc.: 72.66%] [G loss: 0.569821]\n",
      "epoch:18 step:17199 [D loss: 0.479426, acc.: 73.44%] [G loss: 0.692581]\n",
      "epoch:18 step:17200 [D loss: 0.490146, acc.: 75.78%] [G loss: 0.711382]\n",
      "##############\n",
      "[2.86836275 1.09052883 6.04096512 4.87393296 3.94498171 5.66394761\n",
      " 4.53597255 5.2020599  4.44686561 4.20494326]\n",
      "##########\n",
      "epoch:18 step:17201 [D loss: 0.514976, acc.: 71.09%] [G loss: 0.708237]\n",
      "epoch:18 step:17202 [D loss: 0.503694, acc.: 78.12%] [G loss: 0.740281]\n",
      "epoch:18 step:17203 [D loss: 0.535392, acc.: 72.66%] [G loss: 0.618205]\n",
      "epoch:18 step:17204 [D loss: 0.514333, acc.: 73.44%] [G loss: 0.672349]\n",
      "epoch:18 step:17205 [D loss: 0.524834, acc.: 78.12%] [G loss: 0.662776]\n",
      "epoch:18 step:17206 [D loss: 0.484011, acc.: 75.78%] [G loss: 0.611552]\n",
      "epoch:18 step:17207 [D loss: 0.562175, acc.: 72.66%] [G loss: 0.608060]\n",
      "epoch:18 step:17208 [D loss: 0.602912, acc.: 66.41%] [G loss: 0.698842]\n",
      "epoch:18 step:17209 [D loss: 0.487642, acc.: 74.22%] [G loss: 0.815846]\n",
      "epoch:18 step:17210 [D loss: 0.438748, acc.: 79.69%] [G loss: 0.894172]\n",
      "epoch:18 step:17211 [D loss: 0.567682, acc.: 67.97%] [G loss: 0.742775]\n",
      "epoch:18 step:17212 [D loss: 0.584060, acc.: 64.84%] [G loss: 0.672798]\n",
      "epoch:18 step:17213 [D loss: 0.429444, acc.: 80.47%] [G loss: 1.133563]\n",
      "epoch:18 step:17214 [D loss: 0.617564, acc.: 65.62%] [G loss: 0.648500]\n",
      "epoch:18 step:17215 [D loss: 0.725335, acc.: 54.69%] [G loss: 0.491463]\n",
      "epoch:18 step:17216 [D loss: 0.461605, acc.: 76.56%] [G loss: 0.636317]\n",
      "epoch:18 step:17217 [D loss: 0.529140, acc.: 73.44%] [G loss: 0.697776]\n",
      "epoch:18 step:17218 [D loss: 0.618719, acc.: 64.06%] [G loss: 0.668790]\n",
      "epoch:18 step:17219 [D loss: 0.563854, acc.: 70.31%] [G loss: 0.625747]\n",
      "epoch:18 step:17220 [D loss: 0.401706, acc.: 83.59%] [G loss: 0.852693]\n",
      "epoch:18 step:17221 [D loss: 0.540846, acc.: 72.66%] [G loss: 0.694062]\n",
      "epoch:18 step:17222 [D loss: 0.495989, acc.: 77.34%] [G loss: 0.662760]\n",
      "epoch:18 step:17223 [D loss: 0.436849, acc.: 78.91%] [G loss: 0.789248]\n",
      "epoch:18 step:17224 [D loss: 0.479513, acc.: 75.00%] [G loss: 0.712136]\n",
      "epoch:18 step:17225 [D loss: 0.466602, acc.: 76.56%] [G loss: 0.919677]\n",
      "epoch:18 step:17226 [D loss: 0.490455, acc.: 78.91%] [G loss: 0.899714]\n",
      "epoch:18 step:17227 [D loss: 0.481121, acc.: 76.56%] [G loss: 0.762981]\n",
      "epoch:18 step:17228 [D loss: 0.527322, acc.: 74.22%] [G loss: 0.777637]\n",
      "epoch:18 step:17229 [D loss: 0.613701, acc.: 64.06%] [G loss: 0.760775]\n",
      "epoch:18 step:17230 [D loss: 0.500184, acc.: 75.78%] [G loss: 0.759528]\n",
      "epoch:18 step:17231 [D loss: 0.576588, acc.: 69.53%] [G loss: 0.534397]\n",
      "epoch:18 step:17232 [D loss: 0.564725, acc.: 71.88%] [G loss: 0.599493]\n",
      "epoch:18 step:17233 [D loss: 0.615972, acc.: 62.50%] [G loss: 0.645426]\n",
      "epoch:18 step:17234 [D loss: 0.515020, acc.: 74.22%] [G loss: 0.639366]\n",
      "epoch:18 step:17235 [D loss: 0.534564, acc.: 68.75%] [G loss: 0.615031]\n",
      "epoch:18 step:17236 [D loss: 0.547113, acc.: 71.88%] [G loss: 0.668347]\n",
      "epoch:18 step:17237 [D loss: 0.499211, acc.: 75.00%] [G loss: 0.795917]\n",
      "epoch:18 step:17238 [D loss: 0.531818, acc.: 74.22%] [G loss: 0.780199]\n",
      "epoch:18 step:17239 [D loss: 0.508706, acc.: 72.66%] [G loss: 0.701009]\n",
      "epoch:18 step:17240 [D loss: 0.469154, acc.: 78.91%] [G loss: 0.762475]\n",
      "epoch:18 step:17241 [D loss: 0.612730, acc.: 64.06%] [G loss: 0.562431]\n",
      "epoch:18 step:17242 [D loss: 0.697157, acc.: 59.38%] [G loss: 0.600454]\n",
      "epoch:18 step:17243 [D loss: 0.558603, acc.: 74.22%] [G loss: 0.491421]\n",
      "epoch:18 step:17244 [D loss: 0.559825, acc.: 65.62%] [G loss: 0.520116]\n",
      "epoch:18 step:17245 [D loss: 0.553957, acc.: 72.66%] [G loss: 0.606424]\n",
      "epoch:18 step:17246 [D loss: 0.580013, acc.: 65.62%] [G loss: 0.466744]\n",
      "epoch:18 step:17247 [D loss: 0.469442, acc.: 77.34%] [G loss: 0.547997]\n",
      "epoch:18 step:17248 [D loss: 0.566006, acc.: 72.66%] [G loss: 0.666794]\n",
      "epoch:18 step:17249 [D loss: 0.558427, acc.: 69.53%] [G loss: 0.702112]\n",
      "epoch:18 step:17250 [D loss: 0.553100, acc.: 71.88%] [G loss: 0.493620]\n",
      "epoch:18 step:17251 [D loss: 0.431605, acc.: 81.25%] [G loss: 0.661306]\n",
      "epoch:18 step:17252 [D loss: 0.624277, acc.: 66.41%] [G loss: 0.674909]\n",
      "epoch:18 step:17253 [D loss: 0.521024, acc.: 73.44%] [G loss: 0.598124]\n",
      "epoch:18 step:17254 [D loss: 0.537876, acc.: 70.31%] [G loss: 0.898394]\n",
      "epoch:18 step:17255 [D loss: 0.514886, acc.: 69.53%] [G loss: 0.723570]\n",
      "epoch:18 step:17256 [D loss: 0.584363, acc.: 67.97%] [G loss: 0.596650]\n",
      "epoch:18 step:17257 [D loss: 0.604355, acc.: 64.06%] [G loss: 0.725839]\n",
      "epoch:18 step:17258 [D loss: 0.560017, acc.: 67.97%] [G loss: 0.552953]\n",
      "epoch:18 step:17259 [D loss: 0.577271, acc.: 67.97%] [G loss: 0.614989]\n",
      "epoch:18 step:17260 [D loss: 0.527413, acc.: 71.88%] [G loss: 0.574717]\n",
      "epoch:18 step:17261 [D loss: 0.552786, acc.: 73.44%] [G loss: 0.594208]\n",
      "epoch:18 step:17262 [D loss: 0.507257, acc.: 75.78%] [G loss: 0.663604]\n",
      "epoch:18 step:17263 [D loss: 0.502296, acc.: 73.44%] [G loss: 0.658012]\n",
      "epoch:18 step:17264 [D loss: 0.506512, acc.: 70.31%] [G loss: 0.755899]\n",
      "epoch:18 step:17265 [D loss: 0.487074, acc.: 74.22%] [G loss: 0.731326]\n",
      "epoch:18 step:17266 [D loss: 0.695023, acc.: 57.03%] [G loss: 0.589511]\n",
      "epoch:18 step:17267 [D loss: 0.686807, acc.: 57.03%] [G loss: 0.509827]\n",
      "epoch:18 step:17268 [D loss: 0.478879, acc.: 75.00%] [G loss: 0.676628]\n",
      "epoch:18 step:17269 [D loss: 0.553839, acc.: 75.00%] [G loss: 0.792691]\n",
      "epoch:18 step:17270 [D loss: 0.598661, acc.: 65.62%] [G loss: 0.630509]\n",
      "epoch:18 step:17271 [D loss: 0.524779, acc.: 71.88%] [G loss: 0.695247]\n",
      "epoch:18 step:17272 [D loss: 0.551404, acc.: 69.53%] [G loss: 0.664942]\n",
      "epoch:18 step:17273 [D loss: 0.501676, acc.: 71.88%] [G loss: 0.644726]\n",
      "epoch:18 step:17274 [D loss: 0.580618, acc.: 66.41%] [G loss: 0.445519]\n",
      "epoch:18 step:17275 [D loss: 0.565172, acc.: 67.97%] [G loss: 0.699617]\n",
      "epoch:18 step:17276 [D loss: 0.567817, acc.: 68.75%] [G loss: 0.587959]\n",
      "epoch:18 step:17277 [D loss: 0.575380, acc.: 68.75%] [G loss: 0.673696]\n",
      "epoch:18 step:17278 [D loss: 0.622385, acc.: 63.28%] [G loss: 0.599124]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:18 step:17279 [D loss: 0.561797, acc.: 72.66%] [G loss: 0.568782]\n",
      "epoch:18 step:17280 [D loss: 0.538232, acc.: 72.66%] [G loss: 0.682326]\n",
      "epoch:18 step:17281 [D loss: 0.524180, acc.: 71.09%] [G loss: 0.860485]\n",
      "epoch:18 step:17282 [D loss: 0.477719, acc.: 79.69%] [G loss: 0.669709]\n",
      "epoch:18 step:17283 [D loss: 0.535265, acc.: 70.31%] [G loss: 0.810240]\n",
      "epoch:18 step:17284 [D loss: 0.670716, acc.: 60.94%] [G loss: 0.499482]\n",
      "epoch:18 step:17285 [D loss: 0.552345, acc.: 70.31%] [G loss: 0.791143]\n",
      "epoch:18 step:17286 [D loss: 0.576013, acc.: 64.06%] [G loss: 0.776315]\n",
      "epoch:18 step:17287 [D loss: 0.592947, acc.: 66.41%] [G loss: 0.609924]\n",
      "epoch:18 step:17288 [D loss: 0.563473, acc.: 69.53%] [G loss: 0.514215]\n",
      "epoch:18 step:17289 [D loss: 0.539690, acc.: 72.66%] [G loss: 0.488745]\n",
      "epoch:18 step:17290 [D loss: 0.585216, acc.: 67.19%] [G loss: 0.494995]\n",
      "epoch:18 step:17291 [D loss: 0.480641, acc.: 76.56%] [G loss: 0.767520]\n",
      "epoch:18 step:17292 [D loss: 0.513860, acc.: 71.88%] [G loss: 0.723477]\n",
      "epoch:18 step:17293 [D loss: 0.457916, acc.: 77.34%] [G loss: 0.858249]\n",
      "epoch:18 step:17294 [D loss: 0.479372, acc.: 80.47%] [G loss: 0.886798]\n",
      "epoch:18 step:17295 [D loss: 0.476110, acc.: 78.12%] [G loss: 0.824811]\n",
      "epoch:18 step:17296 [D loss: 0.507621, acc.: 75.00%] [G loss: 0.956300]\n",
      "epoch:18 step:17297 [D loss: 0.569614, acc.: 66.41%] [G loss: 0.607858]\n",
      "epoch:18 step:17298 [D loss: 0.530896, acc.: 75.00%] [G loss: 0.702901]\n",
      "epoch:18 step:17299 [D loss: 0.595060, acc.: 70.31%] [G loss: 0.643388]\n",
      "epoch:18 step:17300 [D loss: 0.555982, acc.: 74.22%] [G loss: 0.601047]\n",
      "epoch:18 step:17301 [D loss: 0.521829, acc.: 72.66%] [G loss: 0.626978]\n",
      "epoch:18 step:17302 [D loss: 0.501700, acc.: 77.34%] [G loss: 0.781694]\n",
      "epoch:18 step:17303 [D loss: 0.615302, acc.: 74.22%] [G loss: 0.647948]\n",
      "epoch:18 step:17304 [D loss: 0.559710, acc.: 65.62%] [G loss: 0.660560]\n",
      "epoch:18 step:17305 [D loss: 0.545053, acc.: 71.88%] [G loss: 0.886437]\n",
      "epoch:18 step:17306 [D loss: 0.458072, acc.: 80.47%] [G loss: 0.835722]\n",
      "epoch:18 step:17307 [D loss: 0.538553, acc.: 67.19%] [G loss: 0.786071]\n",
      "epoch:18 step:17308 [D loss: 0.547975, acc.: 68.75%] [G loss: 0.701670]\n",
      "epoch:18 step:17309 [D loss: 0.510716, acc.: 74.22%] [G loss: 0.758819]\n",
      "epoch:18 step:17310 [D loss: 0.470155, acc.: 78.91%] [G loss: 0.697070]\n",
      "epoch:18 step:17311 [D loss: 0.591138, acc.: 67.19%] [G loss: 0.807068]\n",
      "epoch:18 step:17312 [D loss: 0.501515, acc.: 71.88%] [G loss: 0.754416]\n",
      "epoch:18 step:17313 [D loss: 0.620143, acc.: 64.06%] [G loss: 0.682726]\n",
      "epoch:18 step:17314 [D loss: 0.544760, acc.: 73.44%] [G loss: 0.753339]\n",
      "epoch:18 step:17315 [D loss: 0.498187, acc.: 74.22%] [G loss: 0.786409]\n",
      "epoch:18 step:17316 [D loss: 0.526132, acc.: 71.88%] [G loss: 0.775768]\n",
      "epoch:18 step:17317 [D loss: 0.374995, acc.: 83.59%] [G loss: 0.974237]\n",
      "epoch:18 step:17318 [D loss: 0.468190, acc.: 72.66%] [G loss: 0.855762]\n",
      "epoch:18 step:17319 [D loss: 0.538364, acc.: 72.66%] [G loss: 0.702093]\n",
      "epoch:18 step:17320 [D loss: 0.594981, acc.: 70.31%] [G loss: 0.638615]\n",
      "epoch:18 step:17321 [D loss: 0.514373, acc.: 72.66%] [G loss: 0.663936]\n",
      "epoch:18 step:17322 [D loss: 0.612004, acc.: 66.41%] [G loss: 0.585653]\n",
      "epoch:18 step:17323 [D loss: 0.540828, acc.: 67.19%] [G loss: 0.647720]\n",
      "epoch:18 step:17324 [D loss: 0.647485, acc.: 63.28%] [G loss: 0.632022]\n",
      "epoch:18 step:17325 [D loss: 0.566837, acc.: 68.75%] [G loss: 0.524315]\n",
      "epoch:18 step:17326 [D loss: 0.500303, acc.: 75.00%] [G loss: 0.581692]\n",
      "epoch:18 step:17327 [D loss: 0.534539, acc.: 67.19%] [G loss: 0.693298]\n",
      "epoch:18 step:17328 [D loss: 0.547630, acc.: 68.75%] [G loss: 0.732292]\n",
      "epoch:18 step:17329 [D loss: 0.535703, acc.: 68.75%] [G loss: 0.620536]\n",
      "epoch:18 step:17330 [D loss: 0.519612, acc.: 69.53%] [G loss: 0.614866]\n",
      "epoch:18 step:17331 [D loss: 0.599877, acc.: 65.62%] [G loss: 0.562207]\n",
      "epoch:18 step:17332 [D loss: 0.563821, acc.: 66.41%] [G loss: 0.620371]\n",
      "epoch:18 step:17333 [D loss: 0.517566, acc.: 75.00%] [G loss: 0.704604]\n",
      "epoch:18 step:17334 [D loss: 0.530514, acc.: 73.44%] [G loss: 0.719970]\n",
      "epoch:18 step:17335 [D loss: 0.534768, acc.: 71.09%] [G loss: 0.825387]\n",
      "epoch:18 step:17336 [D loss: 0.544085, acc.: 71.88%] [G loss: 0.677451]\n",
      "epoch:18 step:17337 [D loss: 0.436613, acc.: 79.69%] [G loss: 0.823991]\n",
      "epoch:18 step:17338 [D loss: 0.455721, acc.: 77.34%] [G loss: 0.856031]\n",
      "epoch:18 step:17339 [D loss: 0.672461, acc.: 56.25%] [G loss: 0.747093]\n",
      "epoch:18 step:17340 [D loss: 0.476884, acc.: 75.78%] [G loss: 0.936955]\n",
      "epoch:18 step:17341 [D loss: 0.445709, acc.: 78.12%] [G loss: 0.908089]\n",
      "epoch:18 step:17342 [D loss: 0.497598, acc.: 76.56%] [G loss: 0.701789]\n",
      "epoch:18 step:17343 [D loss: 0.650737, acc.: 63.28%] [G loss: 0.593761]\n",
      "epoch:18 step:17344 [D loss: 0.539398, acc.: 68.75%] [G loss: 0.487242]\n",
      "epoch:18 step:17345 [D loss: 0.454548, acc.: 82.81%] [G loss: 0.629256]\n",
      "epoch:18 step:17346 [D loss: 0.645146, acc.: 63.28%] [G loss: 0.536358]\n",
      "epoch:18 step:17347 [D loss: 0.471879, acc.: 82.81%] [G loss: 0.656343]\n",
      "epoch:18 step:17348 [D loss: 0.600872, acc.: 67.97%] [G loss: 0.594534]\n",
      "epoch:18 step:17349 [D loss: 0.512438, acc.: 69.53%] [G loss: 0.624345]\n",
      "epoch:18 step:17350 [D loss: 0.506800, acc.: 75.00%] [G loss: 0.665725]\n",
      "epoch:18 step:17351 [D loss: 0.549119, acc.: 75.78%] [G loss: 0.683583]\n",
      "epoch:18 step:17352 [D loss: 0.536945, acc.: 70.31%] [G loss: 0.675587]\n",
      "epoch:18 step:17353 [D loss: 0.575523, acc.: 67.19%] [G loss: 0.504741]\n",
      "epoch:18 step:17354 [D loss: 0.485883, acc.: 74.22%] [G loss: 0.627693]\n",
      "epoch:18 step:17355 [D loss: 0.516878, acc.: 67.19%] [G loss: 0.602235]\n",
      "epoch:18 step:17356 [D loss: 0.586689, acc.: 67.97%] [G loss: 0.606344]\n",
      "epoch:18 step:17357 [D loss: 0.521540, acc.: 67.97%] [G loss: 0.750119]\n",
      "epoch:18 step:17358 [D loss: 0.597014, acc.: 65.62%] [G loss: 0.469684]\n",
      "epoch:18 step:17359 [D loss: 0.564001, acc.: 69.53%] [G loss: 0.512238]\n",
      "epoch:18 step:17360 [D loss: 0.567550, acc.: 69.53%] [G loss: 0.444290]\n",
      "epoch:18 step:17361 [D loss: 0.472413, acc.: 79.69%] [G loss: 0.674619]\n",
      "epoch:18 step:17362 [D loss: 0.548682, acc.: 74.22%] [G loss: 0.516965]\n",
      "epoch:18 step:17363 [D loss: 0.548088, acc.: 70.31%] [G loss: 0.549092]\n",
      "epoch:18 step:17364 [D loss: 0.518328, acc.: 75.78%] [G loss: 0.811509]\n",
      "epoch:18 step:17365 [D loss: 0.490759, acc.: 75.78%] [G loss: 0.727675]\n",
      "epoch:18 step:17366 [D loss: 0.569095, acc.: 72.66%] [G loss: 0.557400]\n",
      "epoch:18 step:17367 [D loss: 0.621172, acc.: 65.62%] [G loss: 0.580333]\n",
      "epoch:18 step:17368 [D loss: 0.623731, acc.: 61.72%] [G loss: 0.526363]\n",
      "epoch:18 step:17369 [D loss: 0.545080, acc.: 70.31%] [G loss: 0.583500]\n",
      "epoch:18 step:17370 [D loss: 0.504326, acc.: 78.91%] [G loss: 0.749833]\n",
      "epoch:18 step:17371 [D loss: 0.472490, acc.: 76.56%] [G loss: 0.841480]\n",
      "epoch:18 step:17372 [D loss: 0.522971, acc.: 71.88%] [G loss: 0.730769]\n",
      "epoch:18 step:17373 [D loss: 0.550566, acc.: 71.88%] [G loss: 0.590578]\n",
      "epoch:18 step:17374 [D loss: 0.426011, acc.: 83.59%] [G loss: 0.818560]\n",
      "epoch:18 step:17375 [D loss: 0.515352, acc.: 72.66%] [G loss: 0.711685]\n",
      "epoch:18 step:17376 [D loss: 0.565800, acc.: 71.88%] [G loss: 0.710059]\n",
      "epoch:18 step:17377 [D loss: 0.706613, acc.: 57.03%] [G loss: 0.404116]\n",
      "epoch:18 step:17378 [D loss: 0.578311, acc.: 68.75%] [G loss: 0.546286]\n",
      "epoch:18 step:17379 [D loss: 0.530313, acc.: 67.97%] [G loss: 0.694740]\n",
      "epoch:18 step:17380 [D loss: 0.471873, acc.: 78.91%] [G loss: 0.714678]\n",
      "epoch:18 step:17381 [D loss: 0.546231, acc.: 71.88%] [G loss: 0.677450]\n",
      "epoch:18 step:17382 [D loss: 0.511556, acc.: 73.44%] [G loss: 0.868226]\n",
      "epoch:18 step:17383 [D loss: 0.519640, acc.: 70.31%] [G loss: 0.728856]\n",
      "epoch:18 step:17384 [D loss: 0.538416, acc.: 70.31%] [G loss: 0.667374]\n",
      "epoch:18 step:17385 [D loss: 0.493857, acc.: 73.44%] [G loss: 0.705078]\n",
      "epoch:18 step:17386 [D loss: 0.490962, acc.: 79.69%] [G loss: 0.745591]\n",
      "epoch:18 step:17387 [D loss: 0.543443, acc.: 73.44%] [G loss: 0.668159]\n",
      "epoch:18 step:17388 [D loss: 0.476741, acc.: 76.56%] [G loss: 0.831296]\n",
      "epoch:18 step:17389 [D loss: 0.488872, acc.: 78.91%] [G loss: 0.745013]\n",
      "epoch:18 step:17390 [D loss: 0.552426, acc.: 71.09%] [G loss: 0.642493]\n",
      "epoch:18 step:17391 [D loss: 0.581338, acc.: 69.53%] [G loss: 0.721658]\n",
      "epoch:18 step:17392 [D loss: 0.542439, acc.: 69.53%] [G loss: 0.713694]\n",
      "epoch:18 step:17393 [D loss: 0.546783, acc.: 70.31%] [G loss: 0.658684]\n",
      "epoch:18 step:17394 [D loss: 0.636222, acc.: 62.50%] [G loss: 0.550259]\n",
      "epoch:18 step:17395 [D loss: 0.609153, acc.: 60.94%] [G loss: 0.617085]\n",
      "epoch:18 step:17396 [D loss: 0.556131, acc.: 67.97%] [G loss: 0.591866]\n",
      "epoch:18 step:17397 [D loss: 0.562361, acc.: 73.44%] [G loss: 0.584885]\n",
      "epoch:18 step:17398 [D loss: 0.600509, acc.: 64.06%] [G loss: 0.585295]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:18 step:17399 [D loss: 0.551195, acc.: 68.75%] [G loss: 0.624277]\n",
      "epoch:18 step:17400 [D loss: 0.509052, acc.: 73.44%] [G loss: 0.722279]\n",
      "##############\n",
      "[2.95315334 0.98407297 6.05844847 4.78044459 3.86723592 5.58849933\n",
      " 4.47527313 4.68954923 4.47766341 4.04287888]\n",
      "##########\n",
      "epoch:18 step:17401 [D loss: 0.623616, acc.: 59.38%] [G loss: 0.528612]\n",
      "epoch:18 step:17402 [D loss: 0.515795, acc.: 71.09%] [G loss: 0.599190]\n",
      "epoch:18 step:17403 [D loss: 0.594899, acc.: 67.19%] [G loss: 0.803136]\n",
      "epoch:18 step:17404 [D loss: 0.545202, acc.: 69.53%] [G loss: 0.692042]\n",
      "epoch:18 step:17405 [D loss: 0.556835, acc.: 70.31%] [G loss: 0.626498]\n",
      "epoch:18 step:17406 [D loss: 0.602706, acc.: 64.84%] [G loss: 0.557973]\n",
      "epoch:18 step:17407 [D loss: 0.581421, acc.: 67.19%] [G loss: 0.465079]\n",
      "epoch:18 step:17408 [D loss: 0.573150, acc.: 67.19%] [G loss: 0.565334]\n",
      "epoch:18 step:17409 [D loss: 0.546324, acc.: 71.88%] [G loss: 0.622477]\n",
      "epoch:18 step:17410 [D loss: 0.535858, acc.: 71.09%] [G loss: 0.621943]\n",
      "epoch:18 step:17411 [D loss: 0.498251, acc.: 72.66%] [G loss: 0.822026]\n",
      "epoch:18 step:17412 [D loss: 0.481211, acc.: 78.12%] [G loss: 0.733966]\n",
      "epoch:18 step:17413 [D loss: 0.544522, acc.: 75.00%] [G loss: 0.791399]\n",
      "epoch:18 step:17414 [D loss: 0.454778, acc.: 77.34%] [G loss: 0.744579]\n",
      "epoch:18 step:17415 [D loss: 0.491852, acc.: 78.91%] [G loss: 0.740885]\n",
      "epoch:18 step:17416 [D loss: 0.555559, acc.: 70.31%] [G loss: 0.645826]\n",
      "epoch:18 step:17417 [D loss: 0.577924, acc.: 70.31%] [G loss: 0.649874]\n",
      "epoch:18 step:17418 [D loss: 0.509421, acc.: 76.56%] [G loss: 0.581511]\n",
      "epoch:18 step:17419 [D loss: 0.576329, acc.: 67.97%] [G loss: 0.678035]\n",
      "epoch:18 step:17420 [D loss: 0.483137, acc.: 77.34%] [G loss: 0.778232]\n",
      "epoch:18 step:17421 [D loss: 0.481303, acc.: 78.91%] [G loss: 0.777814]\n",
      "epoch:18 step:17422 [D loss: 0.548443, acc.: 75.00%] [G loss: 0.748950]\n",
      "epoch:18 step:17423 [D loss: 0.516234, acc.: 75.78%] [G loss: 0.727436]\n",
      "epoch:18 step:17424 [D loss: 0.484967, acc.: 75.78%] [G loss: 0.705011]\n",
      "epoch:18 step:17425 [D loss: 0.577012, acc.: 70.31%] [G loss: 0.574952]\n",
      "epoch:18 step:17426 [D loss: 0.545888, acc.: 68.75%] [G loss: 0.613067]\n",
      "epoch:18 step:17427 [D loss: 0.631989, acc.: 60.16%] [G loss: 0.504258]\n",
      "epoch:18 step:17428 [D loss: 0.503409, acc.: 73.44%] [G loss: 0.567232]\n",
      "epoch:18 step:17429 [D loss: 0.508511, acc.: 74.22%] [G loss: 0.682083]\n",
      "epoch:18 step:17430 [D loss: 0.473703, acc.: 76.56%] [G loss: 0.674296]\n",
      "epoch:18 step:17431 [D loss: 0.551627, acc.: 72.66%] [G loss: 0.760413]\n",
      "epoch:18 step:17432 [D loss: 0.670940, acc.: 67.19%] [G loss: 0.692874]\n",
      "epoch:18 step:17433 [D loss: 0.494219, acc.: 74.22%] [G loss: 0.673576]\n",
      "epoch:18 step:17434 [D loss: 0.486720, acc.: 78.91%] [G loss: 0.855360]\n",
      "epoch:18 step:17435 [D loss: 0.532055, acc.: 74.22%] [G loss: 0.690314]\n",
      "epoch:18 step:17436 [D loss: 0.541717, acc.: 75.78%] [G loss: 0.809082]\n",
      "epoch:18 step:17437 [D loss: 0.555911, acc.: 67.97%] [G loss: 0.724314]\n",
      "epoch:18 step:17438 [D loss: 0.519089, acc.: 72.66%] [G loss: 0.574727]\n",
      "epoch:18 step:17439 [D loss: 0.551331, acc.: 71.09%] [G loss: 0.747094]\n",
      "epoch:18 step:17440 [D loss: 0.488346, acc.: 75.00%] [G loss: 0.732774]\n",
      "epoch:18 step:17441 [D loss: 0.473570, acc.: 77.34%] [G loss: 0.914179]\n",
      "epoch:18 step:17442 [D loss: 0.579094, acc.: 67.19%] [G loss: 0.741036]\n",
      "epoch:18 step:17443 [D loss: 0.524645, acc.: 71.88%] [G loss: 0.805041]\n",
      "epoch:18 step:17444 [D loss: 0.573527, acc.: 66.41%] [G loss: 0.507300]\n",
      "epoch:18 step:17445 [D loss: 0.484519, acc.: 74.22%] [G loss: 0.742793]\n",
      "epoch:18 step:17446 [D loss: 0.568245, acc.: 67.19%] [G loss: 0.801175]\n",
      "epoch:18 step:17447 [D loss: 0.537180, acc.: 75.00%] [G loss: 0.806118]\n",
      "epoch:18 step:17448 [D loss: 0.457198, acc.: 84.38%] [G loss: 0.826494]\n",
      "epoch:18 step:17449 [D loss: 0.545420, acc.: 75.00%] [G loss: 0.810155]\n",
      "epoch:18 step:17450 [D loss: 0.637786, acc.: 65.62%] [G loss: 0.653608]\n",
      "epoch:18 step:17451 [D loss: 0.540665, acc.: 69.53%] [G loss: 0.545006]\n",
      "epoch:18 step:17452 [D loss: 0.568686, acc.: 71.88%] [G loss: 0.524957]\n",
      "epoch:18 step:17453 [D loss: 0.597963, acc.: 63.28%] [G loss: 0.556103]\n",
      "epoch:18 step:17454 [D loss: 0.594384, acc.: 67.97%] [G loss: 0.615119]\n",
      "epoch:18 step:17455 [D loss: 0.561343, acc.: 65.62%] [G loss: 0.605913]\n",
      "epoch:18 step:17456 [D loss: 0.542262, acc.: 64.06%] [G loss: 0.701491]\n",
      "epoch:18 step:17457 [D loss: 0.569779, acc.: 70.31%] [G loss: 0.729825]\n",
      "epoch:18 step:17458 [D loss: 0.489287, acc.: 76.56%] [G loss: 0.715942]\n",
      "epoch:18 step:17459 [D loss: 0.476217, acc.: 74.22%] [G loss: 0.825350]\n",
      "epoch:18 step:17460 [D loss: 0.576531, acc.: 71.09%] [G loss: 0.638971]\n",
      "epoch:18 step:17461 [D loss: 0.570359, acc.: 67.19%] [G loss: 0.640572]\n",
      "epoch:18 step:17462 [D loss: 0.545891, acc.: 68.75%] [G loss: 0.638258]\n",
      "epoch:18 step:17463 [D loss: 0.530525, acc.: 71.88%] [G loss: 0.669461]\n",
      "epoch:18 step:17464 [D loss: 0.517860, acc.: 74.22%] [G loss: 0.649873]\n",
      "epoch:18 step:17465 [D loss: 0.525024, acc.: 72.66%] [G loss: 0.839462]\n",
      "epoch:18 step:17466 [D loss: 0.575280, acc.: 66.41%] [G loss: 0.747172]\n",
      "epoch:18 step:17467 [D loss: 0.523897, acc.: 74.22%] [G loss: 0.739668]\n",
      "epoch:18 step:17468 [D loss: 0.508173, acc.: 75.00%] [G loss: 0.753485]\n",
      "epoch:18 step:17469 [D loss: 0.504311, acc.: 76.56%] [G loss: 0.775227]\n",
      "epoch:18 step:17470 [D loss: 0.570906, acc.: 71.09%] [G loss: 0.694480]\n",
      "epoch:18 step:17471 [D loss: 0.473789, acc.: 72.66%] [G loss: 0.713290]\n",
      "epoch:18 step:17472 [D loss: 0.646365, acc.: 65.62%] [G loss: 0.805412]\n",
      "epoch:18 step:17473 [D loss: 0.537651, acc.: 67.97%] [G loss: 0.552694]\n",
      "epoch:18 step:17474 [D loss: 0.541875, acc.: 73.44%] [G loss: 0.654881]\n",
      "epoch:18 step:17475 [D loss: 0.605522, acc.: 67.19%] [G loss: 0.451843]\n",
      "epoch:18 step:17476 [D loss: 0.558619, acc.: 68.75%] [G loss: 0.544364]\n",
      "epoch:18 step:17477 [D loss: 0.542043, acc.: 70.31%] [G loss: 0.459267]\n",
      "epoch:18 step:17478 [D loss: 0.574560, acc.: 68.75%] [G loss: 0.491601]\n",
      "epoch:18 step:17479 [D loss: 0.493336, acc.: 73.44%] [G loss: 0.658068]\n",
      "epoch:18 step:17480 [D loss: 0.610539, acc.: 64.06%] [G loss: 0.598857]\n",
      "epoch:18 step:17481 [D loss: 0.676448, acc.: 54.69%] [G loss: 0.622960]\n",
      "epoch:18 step:17482 [D loss: 0.607219, acc.: 62.50%] [G loss: 0.688844]\n",
      "epoch:18 step:17483 [D loss: 0.540894, acc.: 70.31%] [G loss: 0.735458]\n",
      "epoch:18 step:17484 [D loss: 0.612437, acc.: 63.28%] [G loss: 0.650810]\n",
      "epoch:18 step:17485 [D loss: 0.559715, acc.: 69.53%] [G loss: 0.654162]\n",
      "epoch:18 step:17486 [D loss: 0.575098, acc.: 65.62%] [G loss: 0.654801]\n",
      "epoch:18 step:17487 [D loss: 0.528702, acc.: 71.88%] [G loss: 0.508071]\n",
      "epoch:18 step:17488 [D loss: 0.612211, acc.: 64.84%] [G loss: 0.489917]\n",
      "epoch:18 step:17489 [D loss: 0.487074, acc.: 75.78%] [G loss: 0.547474]\n",
      "epoch:18 step:17490 [D loss: 0.486764, acc.: 75.78%] [G loss: 0.587200]\n",
      "epoch:18 step:17491 [D loss: 0.562209, acc.: 66.41%] [G loss: 0.603513]\n",
      "epoch:18 step:17492 [D loss: 0.497618, acc.: 78.12%] [G loss: 0.719427]\n",
      "epoch:18 step:17493 [D loss: 0.601538, acc.: 61.72%] [G loss: 0.530702]\n",
      "epoch:18 step:17494 [D loss: 0.567263, acc.: 69.53%] [G loss: 0.603761]\n",
      "epoch:18 step:17495 [D loss: 0.493167, acc.: 72.66%] [G loss: 0.737468]\n",
      "epoch:18 step:17496 [D loss: 0.551617, acc.: 68.75%] [G loss: 0.638956]\n",
      "epoch:18 step:17497 [D loss: 0.525157, acc.: 75.00%] [G loss: 0.691199]\n",
      "epoch:18 step:17498 [D loss: 0.522034, acc.: 74.22%] [G loss: 0.634229]\n",
      "epoch:18 step:17499 [D loss: 0.552989, acc.: 66.41%] [G loss: 0.610032]\n",
      "epoch:18 step:17500 [D loss: 0.461204, acc.: 77.34%] [G loss: 0.700891]\n",
      "epoch:18 step:17501 [D loss: 0.526371, acc.: 70.31%] [G loss: 0.795784]\n",
      "epoch:18 step:17502 [D loss: 0.602778, acc.: 69.53%] [G loss: 0.774989]\n",
      "epoch:18 step:17503 [D loss: 0.608799, acc.: 66.41%] [G loss: 0.527712]\n",
      "epoch:18 step:17504 [D loss: 0.522368, acc.: 73.44%] [G loss: 0.667182]\n",
      "epoch:18 step:17505 [D loss: 0.513211, acc.: 73.44%] [G loss: 0.744730]\n",
      "epoch:18 step:17506 [D loss: 0.548862, acc.: 71.09%] [G loss: 0.864769]\n",
      "epoch:18 step:17507 [D loss: 0.458788, acc.: 80.47%] [G loss: 0.724992]\n",
      "epoch:18 step:17508 [D loss: 0.460551, acc.: 78.91%] [G loss: 0.881325]\n",
      "epoch:18 step:17509 [D loss: 0.482535, acc.: 75.00%] [G loss: 0.826760]\n",
      "epoch:18 step:17510 [D loss: 0.618685, acc.: 60.94%] [G loss: 0.630970]\n",
      "epoch:18 step:17511 [D loss: 0.523310, acc.: 71.09%] [G loss: 0.606058]\n",
      "epoch:18 step:17512 [D loss: 0.587594, acc.: 70.31%] [G loss: 0.568478]\n",
      "epoch:18 step:17513 [D loss: 0.464247, acc.: 78.91%] [G loss: 0.728782]\n",
      "epoch:18 step:17514 [D loss: 0.395128, acc.: 82.03%] [G loss: 1.153770]\n",
      "epoch:18 step:17515 [D loss: 0.493418, acc.: 73.44%] [G loss: 0.954765]\n",
      "epoch:18 step:17516 [D loss: 0.512761, acc.: 74.22%] [G loss: 0.851758]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:18 step:17517 [D loss: 0.511207, acc.: 75.78%] [G loss: 1.015857]\n",
      "epoch:18 step:17518 [D loss: 0.631413, acc.: 61.72%] [G loss: 0.527535]\n",
      "epoch:18 step:17519 [D loss: 0.609189, acc.: 64.84%] [G loss: 0.396778]\n",
      "epoch:18 step:17520 [D loss: 0.475757, acc.: 76.56%] [G loss: 0.547136]\n",
      "epoch:18 step:17521 [D loss: 0.557620, acc.: 72.66%] [G loss: 0.638032]\n",
      "epoch:18 step:17522 [D loss: 0.550565, acc.: 71.09%] [G loss: 0.607581]\n",
      "epoch:18 step:17523 [D loss: 0.488885, acc.: 71.88%] [G loss: 0.718908]\n",
      "epoch:18 step:17524 [D loss: 0.540025, acc.: 69.53%] [G loss: 0.745684]\n",
      "epoch:18 step:17525 [D loss: 0.514970, acc.: 73.44%] [G loss: 0.692861]\n",
      "epoch:18 step:17526 [D loss: 0.517667, acc.: 72.66%] [G loss: 0.675802]\n",
      "epoch:18 step:17527 [D loss: 0.496822, acc.: 71.09%] [G loss: 0.736997]\n",
      "epoch:18 step:17528 [D loss: 0.533936, acc.: 71.88%] [G loss: 0.786633]\n",
      "epoch:18 step:17529 [D loss: 0.541498, acc.: 71.09%] [G loss: 0.582468]\n",
      "epoch:18 step:17530 [D loss: 0.589506, acc.: 64.84%] [G loss: 0.612900]\n",
      "epoch:18 step:17531 [D loss: 0.566218, acc.: 67.97%] [G loss: 0.568433]\n",
      "epoch:18 step:17532 [D loss: 0.537598, acc.: 71.88%] [G loss: 0.698077]\n",
      "epoch:18 step:17533 [D loss: 0.604677, acc.: 59.38%] [G loss: 0.711152]\n",
      "epoch:18 step:17534 [D loss: 0.574737, acc.: 69.53%] [G loss: 0.687079]\n",
      "epoch:18 step:17535 [D loss: 0.562827, acc.: 70.31%] [G loss: 0.529720]\n",
      "epoch:18 step:17536 [D loss: 0.559656, acc.: 70.31%] [G loss: 0.518555]\n",
      "epoch:18 step:17537 [D loss: 0.557689, acc.: 70.31%] [G loss: 0.590763]\n",
      "epoch:18 step:17538 [D loss: 0.546579, acc.: 71.88%] [G loss: 0.546023]\n",
      "epoch:18 step:17539 [D loss: 0.559508, acc.: 67.19%] [G loss: 0.681588]\n",
      "epoch:18 step:17540 [D loss: 0.565251, acc.: 64.84%] [G loss: 0.685123]\n",
      "epoch:18 step:17541 [D loss: 0.604382, acc.: 65.62%] [G loss: 0.574547]\n",
      "epoch:18 step:17542 [D loss: 0.501998, acc.: 76.56%] [G loss: 0.562693]\n",
      "epoch:18 step:17543 [D loss: 0.533376, acc.: 72.66%] [G loss: 0.540219]\n",
      "epoch:18 step:17544 [D loss: 0.579111, acc.: 67.97%] [G loss: 0.579403]\n",
      "epoch:18 step:17545 [D loss: 0.501941, acc.: 74.22%] [G loss: 0.666941]\n",
      "epoch:18 step:17546 [D loss: 0.517219, acc.: 72.66%] [G loss: 0.635863]\n",
      "epoch:18 step:17547 [D loss: 0.500767, acc.: 74.22%] [G loss: 0.701643]\n",
      "epoch:18 step:17548 [D loss: 0.570198, acc.: 72.66%] [G loss: 0.718623]\n",
      "epoch:18 step:17549 [D loss: 0.541708, acc.: 70.31%] [G loss: 0.626668]\n",
      "epoch:18 step:17550 [D loss: 0.588840, acc.: 67.97%] [G loss: 0.686332]\n",
      "epoch:18 step:17551 [D loss: 0.531782, acc.: 73.44%] [G loss: 0.576682]\n",
      "epoch:18 step:17552 [D loss: 0.579157, acc.: 70.31%] [G loss: 0.664587]\n",
      "epoch:18 step:17553 [D loss: 0.554281, acc.: 69.53%] [G loss: 0.557908]\n",
      "epoch:18 step:17554 [D loss: 0.558535, acc.: 68.75%] [G loss: 0.612458]\n",
      "epoch:18 step:17555 [D loss: 0.542926, acc.: 71.09%] [G loss: 0.619751]\n",
      "epoch:18 step:17556 [D loss: 0.543326, acc.: 71.09%] [G loss: 0.594502]\n",
      "epoch:18 step:17557 [D loss: 0.512443, acc.: 72.66%] [G loss: 0.627632]\n",
      "epoch:18 step:17558 [D loss: 0.549721, acc.: 69.53%] [G loss: 0.679381]\n",
      "epoch:18 step:17559 [D loss: 0.454052, acc.: 80.47%] [G loss: 0.704472]\n",
      "epoch:18 step:17560 [D loss: 0.493235, acc.: 71.88%] [G loss: 0.775170]\n",
      "epoch:18 step:17561 [D loss: 0.483089, acc.: 77.34%] [G loss: 0.725213]\n",
      "epoch:18 step:17562 [D loss: 0.643851, acc.: 62.50%] [G loss: 0.515192]\n",
      "epoch:18 step:17563 [D loss: 0.572875, acc.: 63.28%] [G loss: 0.733972]\n",
      "epoch:18 step:17564 [D loss: 0.622857, acc.: 61.72%] [G loss: 0.529707]\n",
      "epoch:18 step:17565 [D loss: 0.526599, acc.: 69.53%] [G loss: 0.685338]\n",
      "epoch:18 step:17566 [D loss: 0.516818, acc.: 74.22%] [G loss: 0.641048]\n",
      "epoch:18 step:17567 [D loss: 0.513950, acc.: 73.44%] [G loss: 0.698928]\n",
      "epoch:18 step:17568 [D loss: 0.583458, acc.: 69.53%] [G loss: 0.644782]\n",
      "epoch:18 step:17569 [D loss: 0.636645, acc.: 61.72%] [G loss: 0.620594]\n",
      "epoch:18 step:17570 [D loss: 0.576404, acc.: 72.66%] [G loss: 0.586910]\n",
      "epoch:18 step:17571 [D loss: 0.537228, acc.: 72.66%] [G loss: 0.495705]\n",
      "epoch:18 step:17572 [D loss: 0.566489, acc.: 68.75%] [G loss: 0.546151]\n",
      "epoch:18 step:17573 [D loss: 0.515000, acc.: 69.53%] [G loss: 0.727664]\n",
      "epoch:18 step:17574 [D loss: 0.532905, acc.: 71.09%] [G loss: 0.824471]\n",
      "epoch:18 step:17575 [D loss: 0.587402, acc.: 68.75%] [G loss: 0.768081]\n",
      "epoch:18 step:17576 [D loss: 0.506915, acc.: 75.00%] [G loss: 0.795219]\n",
      "epoch:18 step:17577 [D loss: 0.549918, acc.: 71.88%] [G loss: 0.574437]\n",
      "epoch:18 step:17578 [D loss: 0.517542, acc.: 69.53%] [G loss: 0.595744]\n",
      "epoch:18 step:17579 [D loss: 0.584648, acc.: 61.72%] [G loss: 0.552326]\n",
      "epoch:18 step:17580 [D loss: 0.520947, acc.: 73.44%] [G loss: 0.583407]\n",
      "epoch:18 step:17581 [D loss: 0.559645, acc.: 71.09%] [G loss: 0.773805]\n",
      "epoch:18 step:17582 [D loss: 0.574642, acc.: 68.75%] [G loss: 0.551726]\n",
      "epoch:18 step:17583 [D loss: 0.577639, acc.: 72.66%] [G loss: 0.476007]\n",
      "epoch:18 step:17584 [D loss: 0.570722, acc.: 64.06%] [G loss: 0.425876]\n",
      "epoch:18 step:17585 [D loss: 0.524188, acc.: 67.19%] [G loss: 0.604672]\n",
      "epoch:18 step:17586 [D loss: 0.604107, acc.: 67.19%] [G loss: 0.650928]\n",
      "epoch:18 step:17587 [D loss: 0.626088, acc.: 62.50%] [G loss: 0.578386]\n",
      "epoch:18 step:17588 [D loss: 0.550884, acc.: 75.00%] [G loss: 0.552456]\n",
      "epoch:18 step:17589 [D loss: 0.615795, acc.: 60.16%] [G loss: 0.439526]\n",
      "epoch:18 step:17590 [D loss: 0.523919, acc.: 72.66%] [G loss: 0.622344]\n",
      "epoch:18 step:17591 [D loss: 0.487006, acc.: 80.47%] [G loss: 0.698693]\n",
      "epoch:18 step:17592 [D loss: 0.556486, acc.: 71.88%] [G loss: 0.653016]\n",
      "epoch:18 step:17593 [D loss: 0.557358, acc.: 67.19%] [G loss: 0.639579]\n",
      "epoch:18 step:17594 [D loss: 0.543729, acc.: 71.09%] [G loss: 0.601836]\n",
      "epoch:18 step:17595 [D loss: 0.609815, acc.: 64.06%] [G loss: 0.536889]\n",
      "epoch:18 step:17596 [D loss: 0.517524, acc.: 73.44%] [G loss: 0.562732]\n",
      "epoch:18 step:17597 [D loss: 0.604391, acc.: 65.62%] [G loss: 0.544896]\n",
      "epoch:18 step:17598 [D loss: 0.553939, acc.: 67.97%] [G loss: 0.575817]\n",
      "epoch:18 step:17599 [D loss: 0.559850, acc.: 67.19%] [G loss: 0.570586]\n",
      "epoch:18 step:17600 [D loss: 0.589616, acc.: 66.41%] [G loss: 0.513788]\n",
      "##############\n",
      "[3.18235215 1.45633213 6.58695738 4.88835144 4.22088807 5.56943945\n",
      " 4.61461363 5.08227249 4.57130828 4.35398286]\n",
      "##########\n",
      "epoch:18 step:17601 [D loss: 0.596097, acc.: 60.16%] [G loss: 0.535846]\n",
      "epoch:18 step:17602 [D loss: 0.521594, acc.: 73.44%] [G loss: 0.662951]\n",
      "epoch:18 step:17603 [D loss: 0.532727, acc.: 71.09%] [G loss: 0.535310]\n",
      "epoch:18 step:17604 [D loss: 0.525877, acc.: 71.88%] [G loss: 0.482586]\n",
      "epoch:18 step:17605 [D loss: 0.557742, acc.: 72.66%] [G loss: 0.469339]\n",
      "epoch:18 step:17606 [D loss: 0.624092, acc.: 63.28%] [G loss: 0.430965]\n",
      "epoch:18 step:17607 [D loss: 0.575378, acc.: 69.53%] [G loss: 0.455763]\n",
      "epoch:18 step:17608 [D loss: 0.538137, acc.: 68.75%] [G loss: 0.561535]\n",
      "epoch:18 step:17609 [D loss: 0.548297, acc.: 66.41%] [G loss: 0.622080]\n",
      "epoch:18 step:17610 [D loss: 0.568091, acc.: 71.88%] [G loss: 0.544248]\n",
      "epoch:18 step:17611 [D loss: 0.572004, acc.: 60.94%] [G loss: 0.563972]\n",
      "epoch:18 step:17612 [D loss: 0.417408, acc.: 77.34%] [G loss: 0.754628]\n",
      "epoch:18 step:17613 [D loss: 0.429085, acc.: 79.69%] [G loss: 0.778861]\n",
      "epoch:18 step:17614 [D loss: 0.481231, acc.: 75.00%] [G loss: 0.673643]\n",
      "epoch:18 step:17615 [D loss: 0.525070, acc.: 74.22%] [G loss: 0.740150]\n",
      "epoch:18 step:17616 [D loss: 0.466216, acc.: 79.69%] [G loss: 0.724702]\n",
      "epoch:18 step:17617 [D loss: 0.495607, acc.: 77.34%] [G loss: 0.784057]\n",
      "epoch:18 step:17618 [D loss: 0.603474, acc.: 61.72%] [G loss: 0.679483]\n",
      "epoch:18 step:17619 [D loss: 0.517440, acc.: 75.00%] [G loss: 0.566443]\n",
      "epoch:18 step:17620 [D loss: 0.527701, acc.: 74.22%] [G loss: 0.596383]\n",
      "epoch:18 step:17621 [D loss: 0.522577, acc.: 75.78%] [G loss: 0.652079]\n",
      "epoch:18 step:17622 [D loss: 0.594659, acc.: 64.84%] [G loss: 0.555756]\n",
      "epoch:18 step:17623 [D loss: 0.554793, acc.: 69.53%] [G loss: 0.690271]\n",
      "epoch:18 step:17624 [D loss: 0.541203, acc.: 73.44%] [G loss: 0.705109]\n",
      "epoch:18 step:17625 [D loss: 0.539376, acc.: 70.31%] [G loss: 0.554774]\n",
      "epoch:18 step:17626 [D loss: 0.502548, acc.: 69.53%] [G loss: 0.691257]\n",
      "epoch:18 step:17627 [D loss: 0.587640, acc.: 67.19%] [G loss: 0.558883]\n",
      "epoch:18 step:17628 [D loss: 0.577424, acc.: 67.97%] [G loss: 0.693001]\n",
      "epoch:18 step:17629 [D loss: 0.585646, acc.: 63.28%] [G loss: 0.594786]\n",
      "epoch:18 step:17630 [D loss: 0.581416, acc.: 67.97%] [G loss: 0.530399]\n",
      "epoch:18 step:17631 [D loss: 0.566126, acc.: 70.31%] [G loss: 0.585185]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:18 step:17632 [D loss: 0.695886, acc.: 55.47%] [G loss: 0.491523]\n",
      "epoch:18 step:17633 [D loss: 0.517382, acc.: 70.31%] [G loss: 0.565576]\n",
      "epoch:18 step:17634 [D loss: 0.529185, acc.: 70.31%] [G loss: 0.616460]\n",
      "epoch:18 step:17635 [D loss: 0.495743, acc.: 76.56%] [G loss: 0.744914]\n",
      "epoch:18 step:17636 [D loss: 0.511212, acc.: 71.09%] [G loss: 0.695078]\n",
      "epoch:18 step:17637 [D loss: 0.524752, acc.: 74.22%] [G loss: 0.730135]\n",
      "epoch:18 step:17638 [D loss: 0.536456, acc.: 71.88%] [G loss: 0.642130]\n",
      "epoch:18 step:17639 [D loss: 0.564581, acc.: 66.41%] [G loss: 0.564997]\n",
      "epoch:18 step:17640 [D loss: 0.562808, acc.: 70.31%] [G loss: 0.547078]\n",
      "epoch:18 step:17641 [D loss: 0.532315, acc.: 74.22%] [G loss: 0.563381]\n",
      "epoch:18 step:17642 [D loss: 0.566401, acc.: 67.97%] [G loss: 0.643635]\n",
      "epoch:18 step:17643 [D loss: 0.541773, acc.: 71.88%] [G loss: 0.642929]\n",
      "epoch:18 step:17644 [D loss: 0.598116, acc.: 62.50%] [G loss: 0.599618]\n",
      "epoch:18 step:17645 [D loss: 0.527443, acc.: 71.09%] [G loss: 0.626179]\n",
      "epoch:18 step:17646 [D loss: 0.506240, acc.: 77.34%] [G loss: 0.701539]\n",
      "epoch:18 step:17647 [D loss: 0.510321, acc.: 78.12%] [G loss: 0.866170]\n",
      "epoch:18 step:17648 [D loss: 0.572080, acc.: 68.75%] [G loss: 1.078391]\n",
      "epoch:18 step:17649 [D loss: 0.561290, acc.: 69.53%] [G loss: 0.663141]\n",
      "epoch:18 step:17650 [D loss: 0.662757, acc.: 60.94%] [G loss: 0.476256]\n",
      "epoch:18 step:17651 [D loss: 0.528966, acc.: 75.00%] [G loss: 0.627511]\n",
      "epoch:18 step:17652 [D loss: 0.503651, acc.: 71.09%] [G loss: 0.825908]\n",
      "epoch:18 step:17653 [D loss: 0.528644, acc.: 72.66%] [G loss: 0.607455]\n",
      "epoch:18 step:17654 [D loss: 0.654284, acc.: 62.50%] [G loss: 0.590005]\n",
      "epoch:18 step:17655 [D loss: 0.537380, acc.: 73.44%] [G loss: 0.634452]\n",
      "epoch:18 step:17656 [D loss: 0.617752, acc.: 65.62%] [G loss: 0.590666]\n",
      "epoch:18 step:17657 [D loss: 0.559404, acc.: 67.19%] [G loss: 0.730108]\n",
      "epoch:18 step:17658 [D loss: 0.458462, acc.: 77.34%] [G loss: 0.781578]\n",
      "epoch:18 step:17659 [D loss: 0.591386, acc.: 69.53%] [G loss: 0.607700]\n",
      "epoch:18 step:17660 [D loss: 0.686777, acc.: 60.94%] [G loss: 0.503183]\n",
      "epoch:18 step:17661 [D loss: 0.577024, acc.: 65.62%] [G loss: 0.486719]\n",
      "epoch:18 step:17662 [D loss: 0.528267, acc.: 71.88%] [G loss: 0.606601]\n",
      "epoch:18 step:17663 [D loss: 0.488861, acc.: 75.78%] [G loss: 0.813431]\n",
      "epoch:18 step:17664 [D loss: 0.524103, acc.: 70.31%] [G loss: 0.638929]\n",
      "epoch:18 step:17665 [D loss: 0.606206, acc.: 69.53%] [G loss: 0.635301]\n",
      "epoch:18 step:17666 [D loss: 0.575542, acc.: 64.06%] [G loss: 0.702066]\n",
      "epoch:18 step:17667 [D loss: 0.536485, acc.: 71.09%] [G loss: 0.737395]\n",
      "epoch:18 step:17668 [D loss: 0.489536, acc.: 78.12%] [G loss: 0.774779]\n",
      "epoch:18 step:17669 [D loss: 0.518110, acc.: 75.00%] [G loss: 0.711285]\n",
      "epoch:18 step:17670 [D loss: 0.544889, acc.: 70.31%] [G loss: 0.664401]\n",
      "epoch:18 step:17671 [D loss: 0.535480, acc.: 70.31%] [G loss: 0.694572]\n",
      "epoch:18 step:17672 [D loss: 0.587054, acc.: 65.62%] [G loss: 0.374697]\n",
      "epoch:18 step:17673 [D loss: 0.523301, acc.: 71.88%] [G loss: 0.471271]\n",
      "epoch:18 step:17674 [D loss: 0.581711, acc.: 66.41%] [G loss: 0.662735]\n",
      "epoch:18 step:17675 [D loss: 0.511752, acc.: 72.66%] [G loss: 0.650974]\n",
      "epoch:18 step:17676 [D loss: 0.521327, acc.: 72.66%] [G loss: 0.751439]\n",
      "epoch:18 step:17677 [D loss: 0.534558, acc.: 72.66%] [G loss: 0.708960]\n",
      "epoch:18 step:17678 [D loss: 0.643278, acc.: 61.72%] [G loss: 0.505651]\n",
      "epoch:18 step:17679 [D loss: 0.576113, acc.: 67.97%] [G loss: 0.467360]\n",
      "epoch:18 step:17680 [D loss: 0.465978, acc.: 76.56%] [G loss: 0.688693]\n",
      "epoch:18 step:17681 [D loss: 0.486901, acc.: 76.56%] [G loss: 0.643265]\n",
      "epoch:18 step:17682 [D loss: 0.499028, acc.: 73.44%] [G loss: 0.890177]\n",
      "epoch:18 step:17683 [D loss: 0.588107, acc.: 71.88%] [G loss: 0.723087]\n",
      "epoch:18 step:17684 [D loss: 0.504608, acc.: 71.09%] [G loss: 0.624824]\n",
      "epoch:18 step:17685 [D loss: 0.513863, acc.: 70.31%] [G loss: 0.664186]\n",
      "epoch:18 step:17686 [D loss: 0.703875, acc.: 64.84%] [G loss: 0.464685]\n",
      "epoch:18 step:17687 [D loss: 0.546500, acc.: 69.53%] [G loss: 0.472175]\n",
      "epoch:18 step:17688 [D loss: 0.511273, acc.: 72.66%] [G loss: 0.587026]\n",
      "epoch:18 step:17689 [D loss: 0.420119, acc.: 83.59%] [G loss: 0.756490]\n",
      "epoch:18 step:17690 [D loss: 0.548808, acc.: 70.31%] [G loss: 0.710299]\n",
      "epoch:18 step:17691 [D loss: 0.542789, acc.: 68.75%] [G loss: 0.524275]\n",
      "epoch:18 step:17692 [D loss: 0.534226, acc.: 69.53%] [G loss: 0.554649]\n",
      "epoch:18 step:17693 [D loss: 0.564169, acc.: 64.84%] [G loss: 0.552654]\n",
      "epoch:18 step:17694 [D loss: 0.607084, acc.: 64.84%] [G loss: 0.497744]\n",
      "epoch:18 step:17695 [D loss: 0.554714, acc.: 67.97%] [G loss: 0.561940]\n",
      "epoch:18 step:17696 [D loss: 0.520361, acc.: 71.88%] [G loss: 0.599667]\n",
      "epoch:18 step:17697 [D loss: 0.548706, acc.: 66.41%] [G loss: 0.542085]\n",
      "epoch:18 step:17698 [D loss: 0.514658, acc.: 74.22%] [G loss: 0.629210]\n",
      "epoch:18 step:17699 [D loss: 0.550132, acc.: 68.75%] [G loss: 0.521879]\n",
      "epoch:18 step:17700 [D loss: 0.501617, acc.: 74.22%] [G loss: 0.477240]\n",
      "epoch:18 step:17701 [D loss: 0.568344, acc.: 69.53%] [G loss: 0.611152]\n",
      "epoch:18 step:17702 [D loss: 0.502719, acc.: 75.00%] [G loss: 0.551322]\n",
      "epoch:18 step:17703 [D loss: 0.575413, acc.: 69.53%] [G loss: 0.503975]\n",
      "epoch:18 step:17704 [D loss: 0.554845, acc.: 65.62%] [G loss: 0.583332]\n",
      "epoch:18 step:17705 [D loss: 0.564371, acc.: 64.84%] [G loss: 0.556030]\n",
      "epoch:18 step:17706 [D loss: 0.569815, acc.: 68.75%] [G loss: 0.422066]\n",
      "epoch:18 step:17707 [D loss: 0.517344, acc.: 70.31%] [G loss: 0.394347]\n",
      "epoch:18 step:17708 [D loss: 0.484257, acc.: 76.56%] [G loss: 0.594827]\n",
      "epoch:18 step:17709 [D loss: 0.505785, acc.: 75.00%] [G loss: 0.624154]\n",
      "epoch:18 step:17710 [D loss: 0.534078, acc.: 73.44%] [G loss: 0.711086]\n",
      "epoch:18 step:17711 [D loss: 0.575712, acc.: 65.62%] [G loss: 0.585191]\n",
      "epoch:18 step:17712 [D loss: 0.572118, acc.: 68.75%] [G loss: 0.651579]\n",
      "epoch:18 step:17713 [D loss: 0.633016, acc.: 61.72%] [G loss: 0.514172]\n",
      "epoch:18 step:17714 [D loss: 0.514905, acc.: 73.44%] [G loss: 0.525927]\n",
      "epoch:18 step:17715 [D loss: 0.551960, acc.: 66.41%] [G loss: 0.432982]\n",
      "epoch:18 step:17716 [D loss: 0.555870, acc.: 70.31%] [G loss: 0.533670]\n",
      "epoch:18 step:17717 [D loss: 0.610120, acc.: 64.84%] [G loss: 0.388287]\n",
      "epoch:18 step:17718 [D loss: 0.565651, acc.: 65.62%] [G loss: 0.560110]\n",
      "epoch:18 step:17719 [D loss: 0.514410, acc.: 70.31%] [G loss: 0.644277]\n",
      "epoch:18 step:17720 [D loss: 0.529589, acc.: 66.41%] [G loss: 0.611503]\n",
      "epoch:18 step:17721 [D loss: 0.515153, acc.: 72.66%] [G loss: 0.742439]\n",
      "epoch:18 step:17722 [D loss: 0.632958, acc.: 66.41%] [G loss: 0.586153]\n",
      "epoch:18 step:17723 [D loss: 0.492081, acc.: 77.34%] [G loss: 0.629367]\n",
      "epoch:18 step:17724 [D loss: 0.587139, acc.: 64.84%] [G loss: 0.710343]\n",
      "epoch:18 step:17725 [D loss: 0.546597, acc.: 73.44%] [G loss: 0.703232]\n",
      "epoch:18 step:17726 [D loss: 0.484457, acc.: 74.22%] [G loss: 0.701399]\n",
      "epoch:18 step:17727 [D loss: 0.668700, acc.: 60.16%] [G loss: 0.563480]\n",
      "epoch:18 step:17728 [D loss: 0.592135, acc.: 67.19%] [G loss: 0.546604]\n",
      "epoch:18 step:17729 [D loss: 0.574323, acc.: 64.06%] [G loss: 0.535053]\n",
      "epoch:18 step:17730 [D loss: 0.533833, acc.: 71.88%] [G loss: 0.679895]\n",
      "epoch:18 step:17731 [D loss: 0.567522, acc.: 65.62%] [G loss: 0.626817]\n",
      "epoch:18 step:17732 [D loss: 0.520218, acc.: 71.88%] [G loss: 0.660833]\n",
      "epoch:18 step:17733 [D loss: 0.652110, acc.: 62.50%] [G loss: 0.439370]\n",
      "epoch:18 step:17734 [D loss: 0.537543, acc.: 71.09%] [G loss: 0.708242]\n",
      "epoch:18 step:17735 [D loss: 0.559549, acc.: 65.62%] [G loss: 0.559253]\n",
      "epoch:18 step:17736 [D loss: 0.458818, acc.: 74.22%] [G loss: 0.575074]\n",
      "epoch:18 step:17737 [D loss: 0.479270, acc.: 76.56%] [G loss: 0.546781]\n",
      "epoch:18 step:17738 [D loss: 0.532948, acc.: 71.09%] [G loss: 0.778609]\n",
      "epoch:18 step:17739 [D loss: 0.613834, acc.: 63.28%] [G loss: 0.634871]\n",
      "epoch:18 step:17740 [D loss: 0.589850, acc.: 65.62%] [G loss: 0.614514]\n",
      "epoch:18 step:17741 [D loss: 0.481295, acc.: 72.66%] [G loss: 0.793458]\n",
      "epoch:18 step:17742 [D loss: 0.546254, acc.: 69.53%] [G loss: 0.832342]\n",
      "epoch:18 step:17743 [D loss: 0.594362, acc.: 62.50%] [G loss: 0.574500]\n",
      "epoch:18 step:17744 [D loss: 0.514516, acc.: 72.66%] [G loss: 0.662777]\n",
      "epoch:18 step:17745 [D loss: 0.528492, acc.: 72.66%] [G loss: 0.600103]\n",
      "epoch:18 step:17746 [D loss: 0.656541, acc.: 57.81%] [G loss: 0.518016]\n",
      "epoch:18 step:17747 [D loss: 0.574391, acc.: 64.06%] [G loss: 0.487979]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:18 step:17748 [D loss: 0.644630, acc.: 61.72%] [G loss: 0.587750]\n",
      "epoch:18 step:17749 [D loss: 0.587328, acc.: 68.75%] [G loss: 0.520820]\n",
      "epoch:18 step:17750 [D loss: 0.523274, acc.: 75.78%] [G loss: 0.626264]\n",
      "epoch:18 step:17751 [D loss: 0.521824, acc.: 70.31%] [G loss: 0.738758]\n",
      "epoch:18 step:17752 [D loss: 0.541409, acc.: 74.22%] [G loss: 0.637057]\n",
      "epoch:18 step:17753 [D loss: 0.569013, acc.: 66.41%] [G loss: 0.666478]\n",
      "epoch:18 step:17754 [D loss: 0.574013, acc.: 64.84%] [G loss: 0.774301]\n",
      "epoch:18 step:17755 [D loss: 0.532179, acc.: 69.53%] [G loss: 0.711664]\n",
      "epoch:18 step:17756 [D loss: 0.496220, acc.: 75.78%] [G loss: 0.824848]\n",
      "epoch:18 step:17757 [D loss: 0.588506, acc.: 67.19%] [G loss: 0.529244]\n",
      "epoch:18 step:17758 [D loss: 0.667004, acc.: 58.59%] [G loss: 0.570301]\n",
      "epoch:18 step:17759 [D loss: 0.547912, acc.: 71.09%] [G loss: 0.644750]\n",
      "epoch:18 step:17760 [D loss: 0.461467, acc.: 78.91%] [G loss: 0.666133]\n",
      "epoch:18 step:17761 [D loss: 0.535055, acc.: 73.44%] [G loss: 0.791908]\n",
      "epoch:18 step:17762 [D loss: 0.494540, acc.: 75.00%] [G loss: 0.804092]\n",
      "epoch:18 step:17763 [D loss: 0.513495, acc.: 73.44%] [G loss: 0.831613]\n",
      "epoch:18 step:17764 [D loss: 0.483179, acc.: 79.69%] [G loss: 0.830194]\n",
      "epoch:18 step:17765 [D loss: 0.517143, acc.: 76.56%] [G loss: 0.927078]\n",
      "epoch:18 step:17766 [D loss: 0.537560, acc.: 73.44%] [G loss: 0.893806]\n",
      "epoch:18 step:17767 [D loss: 0.538821, acc.: 70.31%] [G loss: 0.777368]\n",
      "epoch:18 step:17768 [D loss: 0.552916, acc.: 63.28%] [G loss: 0.723853]\n",
      "epoch:18 step:17769 [D loss: 0.579969, acc.: 66.41%] [G loss: 0.659840]\n",
      "epoch:18 step:17770 [D loss: 0.524731, acc.: 74.22%] [G loss: 0.748224]\n",
      "epoch:18 step:17771 [D loss: 0.571372, acc.: 71.09%] [G loss: 0.563217]\n",
      "epoch:18 step:17772 [D loss: 0.509399, acc.: 73.44%] [G loss: 0.727993]\n",
      "epoch:18 step:17773 [D loss: 0.583712, acc.: 67.19%] [G loss: 0.850216]\n",
      "epoch:18 step:17774 [D loss: 0.550946, acc.: 71.88%] [G loss: 0.740147]\n",
      "epoch:18 step:17775 [D loss: 0.493859, acc.: 75.00%] [G loss: 0.734116]\n",
      "epoch:18 step:17776 [D loss: 0.582342, acc.: 66.41%] [G loss: 0.800669]\n",
      "epoch:18 step:17777 [D loss: 0.514269, acc.: 72.66%] [G loss: 0.835979]\n",
      "epoch:18 step:17778 [D loss: 0.511669, acc.: 73.44%] [G loss: 0.804767]\n",
      "epoch:18 step:17779 [D loss: 0.534071, acc.: 73.44%] [G loss: 0.852410]\n",
      "epoch:18 step:17780 [D loss: 0.472409, acc.: 76.56%] [G loss: 0.767139]\n",
      "epoch:18 step:17781 [D loss: 0.648528, acc.: 61.72%] [G loss: 0.708002]\n",
      "epoch:18 step:17782 [D loss: 0.496455, acc.: 76.56%] [G loss: 0.699195]\n",
      "epoch:18 step:17783 [D loss: 0.675444, acc.: 55.47%] [G loss: 0.607221]\n",
      "epoch:18 step:17784 [D loss: 0.523352, acc.: 69.53%] [G loss: 0.730288]\n",
      "epoch:18 step:17785 [D loss: 0.438455, acc.: 80.47%] [G loss: 0.928891]\n",
      "epoch:18 step:17786 [D loss: 0.753534, acc.: 57.03%] [G loss: 0.665963]\n",
      "epoch:18 step:17787 [D loss: 0.507921, acc.: 74.22%] [G loss: 0.641826]\n",
      "epoch:18 step:17788 [D loss: 0.519459, acc.: 70.31%] [G loss: 0.875204]\n",
      "epoch:18 step:17789 [D loss: 0.449169, acc.: 72.66%] [G loss: 0.696026]\n",
      "epoch:18 step:17790 [D loss: 0.477767, acc.: 77.34%] [G loss: 0.624061]\n",
      "epoch:18 step:17791 [D loss: 0.377233, acc.: 86.72%] [G loss: 0.838087]\n",
      "epoch:18 step:17792 [D loss: 0.456178, acc.: 71.88%] [G loss: 1.088993]\n",
      "epoch:18 step:17793 [D loss: 0.540088, acc.: 72.66%] [G loss: 0.923264]\n",
      "epoch:18 step:17794 [D loss: 0.660572, acc.: 63.28%] [G loss: 1.314747]\n",
      "epoch:18 step:17795 [D loss: 0.409147, acc.: 81.25%] [G loss: 1.567988]\n",
      "epoch:18 step:17796 [D loss: 0.499740, acc.: 73.44%] [G loss: 1.440933]\n",
      "epoch:18 step:17797 [D loss: 0.588390, acc.: 69.53%] [G loss: 1.062904]\n",
      "epoch:18 step:17798 [D loss: 0.606251, acc.: 61.72%] [G loss: 0.718917]\n",
      "epoch:18 step:17799 [D loss: 0.576049, acc.: 68.75%] [G loss: 0.811618]\n",
      "epoch:18 step:17800 [D loss: 0.540257, acc.: 69.53%] [G loss: 1.020402]\n",
      "##############\n",
      "[3.08517139 1.05793761 6.33079007 4.87142949 3.49814404 5.54901298\n",
      " 4.1968677  4.63969613 4.46480029 4.2363947 ]\n",
      "##########\n",
      "epoch:18 step:17801 [D loss: 0.487285, acc.: 75.00%] [G loss: 1.076784]\n",
      "epoch:18 step:17802 [D loss: 0.430248, acc.: 82.81%] [G loss: 1.141350]\n",
      "epoch:18 step:17803 [D loss: 0.390198, acc.: 86.72%] [G loss: 1.220357]\n",
      "epoch:19 step:17804 [D loss: 0.526064, acc.: 78.12%] [G loss: 0.979963]\n",
      "epoch:19 step:17805 [D loss: 0.465804, acc.: 76.56%] [G loss: 0.928325]\n",
      "epoch:19 step:17806 [D loss: 0.515524, acc.: 75.00%] [G loss: 0.986155]\n",
      "epoch:19 step:17807 [D loss: 0.513709, acc.: 71.88%] [G loss: 0.980801]\n",
      "epoch:19 step:17808 [D loss: 0.541602, acc.: 67.97%] [G loss: 0.925060]\n",
      "epoch:19 step:17809 [D loss: 0.563809, acc.: 71.88%] [G loss: 0.869816]\n",
      "epoch:19 step:17810 [D loss: 0.499330, acc.: 78.91%] [G loss: 0.843523]\n",
      "epoch:19 step:17811 [D loss: 0.466284, acc.: 79.69%] [G loss: 0.771608]\n",
      "epoch:19 step:17812 [D loss: 0.470327, acc.: 78.91%] [G loss: 0.823703]\n",
      "epoch:19 step:17813 [D loss: 0.520313, acc.: 75.78%] [G loss: 0.896569]\n",
      "epoch:19 step:17814 [D loss: 0.477418, acc.: 77.34%] [G loss: 0.964847]\n",
      "epoch:19 step:17815 [D loss: 0.596205, acc.: 68.75%] [G loss: 0.783432]\n",
      "epoch:19 step:17816 [D loss: 0.567855, acc.: 68.75%] [G loss: 0.657702]\n",
      "epoch:19 step:17817 [D loss: 0.528321, acc.: 70.31%] [G loss: 0.457533]\n",
      "epoch:19 step:17818 [D loss: 0.509739, acc.: 76.56%] [G loss: 0.623904]\n",
      "epoch:19 step:17819 [D loss: 0.489821, acc.: 75.78%] [G loss: 0.812429]\n",
      "epoch:19 step:17820 [D loss: 0.541012, acc.: 72.66%] [G loss: 0.824866]\n",
      "epoch:19 step:17821 [D loss: 0.592289, acc.: 67.19%] [G loss: 0.723000]\n",
      "epoch:19 step:17822 [D loss: 0.537734, acc.: 71.88%] [G loss: 0.675788]\n",
      "epoch:19 step:17823 [D loss: 0.624442, acc.: 67.19%] [G loss: 0.671288]\n",
      "epoch:19 step:17824 [D loss: 0.615404, acc.: 63.28%] [G loss: 0.604898]\n",
      "epoch:19 step:17825 [D loss: 0.467090, acc.: 77.34%] [G loss: 0.996286]\n",
      "epoch:19 step:17826 [D loss: 0.533435, acc.: 69.53%] [G loss: 0.762015]\n",
      "epoch:19 step:17827 [D loss: 0.483658, acc.: 76.56%] [G loss: 0.769936]\n",
      "epoch:19 step:17828 [D loss: 0.452247, acc.: 78.91%] [G loss: 0.616469]\n",
      "epoch:19 step:17829 [D loss: 0.570938, acc.: 67.19%] [G loss: 0.653342]\n",
      "epoch:19 step:17830 [D loss: 0.506595, acc.: 73.44%] [G loss: 0.626429]\n",
      "epoch:19 step:17831 [D loss: 0.559499, acc.: 65.62%] [G loss: 0.785432]\n",
      "epoch:19 step:17832 [D loss: 0.526460, acc.: 71.88%] [G loss: 0.643950]\n",
      "epoch:19 step:17833 [D loss: 0.540707, acc.: 71.09%] [G loss: 0.540071]\n",
      "epoch:19 step:17834 [D loss: 0.623000, acc.: 61.72%] [G loss: 0.646272]\n",
      "epoch:19 step:17835 [D loss: 0.534716, acc.: 69.53%] [G loss: 0.630149]\n",
      "epoch:19 step:17836 [D loss: 0.470550, acc.: 77.34%] [G loss: 0.673909]\n",
      "epoch:19 step:17837 [D loss: 0.601621, acc.: 67.97%] [G loss: 0.548461]\n",
      "epoch:19 step:17838 [D loss: 0.595647, acc.: 65.62%] [G loss: 0.517276]\n",
      "epoch:19 step:17839 [D loss: 0.518508, acc.: 74.22%] [G loss: 0.713156]\n",
      "epoch:19 step:17840 [D loss: 0.557709, acc.: 70.31%] [G loss: 0.602534]\n",
      "epoch:19 step:17841 [D loss: 0.567676, acc.: 71.09%] [G loss: 0.603968]\n",
      "epoch:19 step:17842 [D loss: 0.496700, acc.: 74.22%] [G loss: 0.659411]\n",
      "epoch:19 step:17843 [D loss: 0.440413, acc.: 78.91%] [G loss: 0.770798]\n",
      "epoch:19 step:17844 [D loss: 0.540008, acc.: 70.31%] [G loss: 0.778796]\n",
      "epoch:19 step:17845 [D loss: 0.502099, acc.: 75.00%] [G loss: 0.772004]\n",
      "epoch:19 step:17846 [D loss: 0.518542, acc.: 71.88%] [G loss: 0.564040]\n",
      "epoch:19 step:17847 [D loss: 0.562166, acc.: 64.84%] [G loss: 0.562443]\n",
      "epoch:19 step:17848 [D loss: 0.471105, acc.: 75.00%] [G loss: 0.782421]\n",
      "epoch:19 step:17849 [D loss: 0.552983, acc.: 70.31%] [G loss: 0.761444]\n",
      "epoch:19 step:17850 [D loss: 0.514142, acc.: 78.91%] [G loss: 0.767222]\n",
      "epoch:19 step:17851 [D loss: 0.523117, acc.: 74.22%] [G loss: 0.683434]\n",
      "epoch:19 step:17852 [D loss: 0.538918, acc.: 69.53%] [G loss: 0.881278]\n",
      "epoch:19 step:17853 [D loss: 0.556920, acc.: 67.97%] [G loss: 0.773336]\n",
      "epoch:19 step:17854 [D loss: 0.658455, acc.: 64.84%] [G loss: 0.757055]\n",
      "epoch:19 step:17855 [D loss: 0.563195, acc.: 68.75%] [G loss: 0.646235]\n",
      "epoch:19 step:17856 [D loss: 0.527026, acc.: 74.22%] [G loss: 0.584266]\n",
      "epoch:19 step:17857 [D loss: 0.445308, acc.: 78.91%] [G loss: 0.872244]\n",
      "epoch:19 step:17858 [D loss: 0.579020, acc.: 67.19%] [G loss: 0.662974]\n",
      "epoch:19 step:17859 [D loss: 0.514352, acc.: 71.88%] [G loss: 0.756329]\n",
      "epoch:19 step:17860 [D loss: 0.500037, acc.: 71.09%] [G loss: 0.723175]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:19 step:17861 [D loss: 0.595854, acc.: 62.50%] [G loss: 0.775268]\n",
      "epoch:19 step:17862 [D loss: 0.478006, acc.: 76.56%] [G loss: 0.721823]\n",
      "epoch:19 step:17863 [D loss: 0.598849, acc.: 66.41%] [G loss: 0.758637]\n",
      "epoch:19 step:17864 [D loss: 0.547745, acc.: 68.75%] [G loss: 0.683107]\n",
      "epoch:19 step:17865 [D loss: 0.574327, acc.: 67.97%] [G loss: 0.579681]\n",
      "epoch:19 step:17866 [D loss: 0.536551, acc.: 72.66%] [G loss: 0.671122]\n",
      "epoch:19 step:17867 [D loss: 0.587669, acc.: 71.88%] [G loss: 0.578213]\n",
      "epoch:19 step:17868 [D loss: 0.491211, acc.: 78.12%] [G loss: 0.464058]\n",
      "epoch:19 step:17869 [D loss: 0.592857, acc.: 63.28%] [G loss: 0.672344]\n",
      "epoch:19 step:17870 [D loss: 0.539719, acc.: 73.44%] [G loss: 0.744259]\n",
      "epoch:19 step:17871 [D loss: 0.563786, acc.: 71.88%] [G loss: 0.473514]\n",
      "epoch:19 step:17872 [D loss: 0.472332, acc.: 79.69%] [G loss: 0.608283]\n",
      "epoch:19 step:17873 [D loss: 0.469538, acc.: 80.47%] [G loss: 0.789841]\n",
      "epoch:19 step:17874 [D loss: 0.541830, acc.: 71.88%] [G loss: 0.607545]\n",
      "epoch:19 step:17875 [D loss: 0.556377, acc.: 67.19%] [G loss: 0.739920]\n",
      "epoch:19 step:17876 [D loss: 0.568730, acc.: 64.06%] [G loss: 0.643275]\n",
      "epoch:19 step:17877 [D loss: 0.467180, acc.: 80.47%] [G loss: 0.629785]\n",
      "epoch:19 step:17878 [D loss: 0.548778, acc.: 71.09%] [G loss: 0.684116]\n",
      "epoch:19 step:17879 [D loss: 0.532983, acc.: 75.00%] [G loss: 0.788211]\n",
      "epoch:19 step:17880 [D loss: 0.463678, acc.: 76.56%] [G loss: 0.921357]\n",
      "epoch:19 step:17881 [D loss: 0.686895, acc.: 63.28%] [G loss: 0.586443]\n",
      "epoch:19 step:17882 [D loss: 0.600489, acc.: 65.62%] [G loss: 0.508396]\n",
      "epoch:19 step:17883 [D loss: 0.462214, acc.: 77.34%] [G loss: 0.686737]\n",
      "epoch:19 step:17884 [D loss: 0.557363, acc.: 64.06%] [G loss: 0.598773]\n",
      "epoch:19 step:17885 [D loss: 0.514676, acc.: 71.09%] [G loss: 0.605382]\n",
      "epoch:19 step:17886 [D loss: 0.444969, acc.: 82.03%] [G loss: 0.590439]\n",
      "epoch:19 step:17887 [D loss: 0.530391, acc.: 71.88%] [G loss: 0.613308]\n",
      "epoch:19 step:17888 [D loss: 0.569414, acc.: 68.75%] [G loss: 0.738669]\n",
      "epoch:19 step:17889 [D loss: 0.525514, acc.: 75.78%] [G loss: 0.644257]\n",
      "epoch:19 step:17890 [D loss: 0.559967, acc.: 69.53%] [G loss: 0.665876]\n",
      "epoch:19 step:17891 [D loss: 0.505481, acc.: 76.56%] [G loss: 0.801552]\n",
      "epoch:19 step:17892 [D loss: 0.512444, acc.: 75.00%] [G loss: 0.778260]\n",
      "epoch:19 step:17893 [D loss: 0.500346, acc.: 75.78%] [G loss: 0.661899]\n",
      "epoch:19 step:17894 [D loss: 0.551966, acc.: 69.53%] [G loss: 0.846895]\n",
      "epoch:19 step:17895 [D loss: 0.534552, acc.: 75.00%] [G loss: 0.669515]\n",
      "epoch:19 step:17896 [D loss: 0.474207, acc.: 75.78%] [G loss: 0.849580]\n",
      "epoch:19 step:17897 [D loss: 0.496961, acc.: 75.78%] [G loss: 0.807621]\n",
      "epoch:19 step:17898 [D loss: 0.566079, acc.: 67.97%] [G loss: 0.723976]\n",
      "epoch:19 step:17899 [D loss: 0.510958, acc.: 69.53%] [G loss: 0.722490]\n",
      "epoch:19 step:17900 [D loss: 0.577090, acc.: 61.72%] [G loss: 0.889610]\n",
      "epoch:19 step:17901 [D loss: 0.499869, acc.: 74.22%] [G loss: 0.702278]\n",
      "epoch:19 step:17902 [D loss: 0.535565, acc.: 71.09%] [G loss: 0.730192]\n",
      "epoch:19 step:17903 [D loss: 0.480975, acc.: 75.78%] [G loss: 0.761133]\n",
      "epoch:19 step:17904 [D loss: 0.567055, acc.: 71.09%] [G loss: 0.818337]\n",
      "epoch:19 step:17905 [D loss: 0.655323, acc.: 67.19%] [G loss: 0.483134]\n",
      "epoch:19 step:17906 [D loss: 0.536598, acc.: 71.09%] [G loss: 0.570842]\n",
      "epoch:19 step:17907 [D loss: 0.510721, acc.: 68.75%] [G loss: 0.531467]\n",
      "epoch:19 step:17908 [D loss: 0.608123, acc.: 66.41%] [G loss: 0.525889]\n",
      "epoch:19 step:17909 [D loss: 0.599162, acc.: 68.75%] [G loss: 0.563017]\n",
      "epoch:19 step:17910 [D loss: 0.579564, acc.: 67.19%] [G loss: 0.667858]\n",
      "epoch:19 step:17911 [D loss: 0.600142, acc.: 67.97%] [G loss: 0.539832]\n",
      "epoch:19 step:17912 [D loss: 0.624714, acc.: 62.50%] [G loss: 0.728622]\n",
      "epoch:19 step:17913 [D loss: 0.562033, acc.: 67.19%] [G loss: 0.594926]\n",
      "epoch:19 step:17914 [D loss: 0.510316, acc.: 75.78%] [G loss: 0.570734]\n",
      "epoch:19 step:17915 [D loss: 0.514706, acc.: 73.44%] [G loss: 0.576921]\n",
      "epoch:19 step:17916 [D loss: 0.597486, acc.: 67.19%] [G loss: 0.559890]\n",
      "epoch:19 step:17917 [D loss: 0.569867, acc.: 71.88%] [G loss: 0.556459]\n",
      "epoch:19 step:17918 [D loss: 0.526973, acc.: 72.66%] [G loss: 0.672657]\n",
      "epoch:19 step:17919 [D loss: 0.463477, acc.: 78.91%] [G loss: 0.638713]\n",
      "epoch:19 step:17920 [D loss: 0.599413, acc.: 64.84%] [G loss: 0.725119]\n",
      "epoch:19 step:17921 [D loss: 0.495298, acc.: 75.00%] [G loss: 0.877928]\n",
      "epoch:19 step:17922 [D loss: 0.491506, acc.: 77.34%] [G loss: 0.801704]\n",
      "epoch:19 step:17923 [D loss: 0.580265, acc.: 69.53%] [G loss: 0.758547]\n",
      "epoch:19 step:17924 [D loss: 0.559154, acc.: 68.75%] [G loss: 0.649865]\n",
      "epoch:19 step:17925 [D loss: 0.509618, acc.: 75.78%] [G loss: 0.714749]\n",
      "epoch:19 step:17926 [D loss: 0.486944, acc.: 75.78%] [G loss: 0.817404]\n",
      "epoch:19 step:17927 [D loss: 0.589063, acc.: 67.97%] [G loss: 0.756253]\n",
      "epoch:19 step:17928 [D loss: 0.586899, acc.: 69.53%] [G loss: 0.548381]\n",
      "epoch:19 step:17929 [D loss: 0.478457, acc.: 76.56%] [G loss: 0.579517]\n",
      "epoch:19 step:17930 [D loss: 0.483069, acc.: 75.78%] [G loss: 0.716511]\n",
      "epoch:19 step:17931 [D loss: 0.534567, acc.: 71.88%] [G loss: 0.663359]\n",
      "epoch:19 step:17932 [D loss: 0.630525, acc.: 60.94%] [G loss: 0.593742]\n",
      "epoch:19 step:17933 [D loss: 0.472117, acc.: 77.34%] [G loss: 0.611968]\n",
      "epoch:19 step:17934 [D loss: 0.463620, acc.: 76.56%] [G loss: 0.760486]\n",
      "epoch:19 step:17935 [D loss: 0.571840, acc.: 70.31%] [G loss: 0.555107]\n",
      "epoch:19 step:17936 [D loss: 0.514420, acc.: 69.53%] [G loss: 0.638052]\n",
      "epoch:19 step:17937 [D loss: 0.549819, acc.: 68.75%] [G loss: 0.629291]\n",
      "epoch:19 step:17938 [D loss: 0.528421, acc.: 72.66%] [G loss: 0.623013]\n",
      "epoch:19 step:17939 [D loss: 0.509744, acc.: 77.34%] [G loss: 0.705544]\n",
      "epoch:19 step:17940 [D loss: 0.617427, acc.: 68.75%] [G loss: 0.545806]\n",
      "epoch:19 step:17941 [D loss: 0.593304, acc.: 68.75%] [G loss: 0.547752]\n",
      "epoch:19 step:17942 [D loss: 0.541111, acc.: 68.75%] [G loss: 0.599063]\n",
      "epoch:19 step:17943 [D loss: 0.567240, acc.: 69.53%] [G loss: 0.610196]\n",
      "epoch:19 step:17944 [D loss: 0.558688, acc.: 69.53%] [G loss: 0.498794]\n",
      "epoch:19 step:17945 [D loss: 0.568926, acc.: 71.09%] [G loss: 0.611780]\n",
      "epoch:19 step:17946 [D loss: 0.618456, acc.: 67.19%] [G loss: 0.567282]\n",
      "epoch:19 step:17947 [D loss: 0.489295, acc.: 71.09%] [G loss: 0.615815]\n",
      "epoch:19 step:17948 [D loss: 0.551860, acc.: 68.75%] [G loss: 0.600641]\n",
      "epoch:19 step:17949 [D loss: 0.494638, acc.: 76.56%] [G loss: 0.676854]\n",
      "epoch:19 step:17950 [D loss: 0.624133, acc.: 62.50%] [G loss: 0.479875]\n",
      "epoch:19 step:17951 [D loss: 0.595900, acc.: 65.62%] [G loss: 0.477718]\n",
      "epoch:19 step:17952 [D loss: 0.495429, acc.: 72.66%] [G loss: 0.655061]\n",
      "epoch:19 step:17953 [D loss: 0.560663, acc.: 66.41%] [G loss: 0.574324]\n",
      "epoch:19 step:17954 [D loss: 0.545704, acc.: 71.88%] [G loss: 0.546013]\n",
      "epoch:19 step:17955 [D loss: 0.436906, acc.: 78.12%] [G loss: 0.848156]\n",
      "epoch:19 step:17956 [D loss: 0.588185, acc.: 66.41%] [G loss: 0.649855]\n",
      "epoch:19 step:17957 [D loss: 0.582401, acc.: 65.62%] [G loss: 0.685223]\n",
      "epoch:19 step:17958 [D loss: 0.481647, acc.: 76.56%] [G loss: 0.689559]\n",
      "epoch:19 step:17959 [D loss: 0.506117, acc.: 75.78%] [G loss: 0.647039]\n",
      "epoch:19 step:17960 [D loss: 0.536556, acc.: 75.00%] [G loss: 0.698658]\n",
      "epoch:19 step:17961 [D loss: 0.565893, acc.: 71.09%] [G loss: 0.569824]\n",
      "epoch:19 step:17962 [D loss: 0.564005, acc.: 73.44%] [G loss: 0.667584]\n",
      "epoch:19 step:17963 [D loss: 0.635604, acc.: 64.84%] [G loss: 0.574132]\n",
      "epoch:19 step:17964 [D loss: 0.536054, acc.: 72.66%] [G loss: 0.585260]\n",
      "epoch:19 step:17965 [D loss: 0.449503, acc.: 76.56%] [G loss: 0.794428]\n",
      "epoch:19 step:17966 [D loss: 0.505447, acc.: 75.00%] [G loss: 0.822934]\n",
      "epoch:19 step:17967 [D loss: 0.628034, acc.: 67.97%] [G loss: 0.656827]\n",
      "epoch:19 step:17968 [D loss: 0.534047, acc.: 67.97%] [G loss: 0.525938]\n",
      "epoch:19 step:17969 [D loss: 0.508999, acc.: 77.34%] [G loss: 0.578662]\n",
      "epoch:19 step:17970 [D loss: 0.572152, acc.: 65.62%] [G loss: 0.618679]\n",
      "epoch:19 step:17971 [D loss: 0.547882, acc.: 67.97%] [G loss: 0.489987]\n",
      "epoch:19 step:17972 [D loss: 0.628926, acc.: 61.72%] [G loss: 0.613040]\n",
      "epoch:19 step:17973 [D loss: 0.556485, acc.: 67.19%] [G loss: 0.431227]\n",
      "epoch:19 step:17974 [D loss: 0.505364, acc.: 77.34%] [G loss: 0.685915]\n",
      "epoch:19 step:17975 [D loss: 0.551479, acc.: 70.31%] [G loss: 0.731693]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:19 step:17976 [D loss: 0.456385, acc.: 78.12%] [G loss: 0.727841]\n",
      "epoch:19 step:17977 [D loss: 0.587739, acc.: 70.31%] [G loss: 0.703859]\n",
      "epoch:19 step:17978 [D loss: 0.578671, acc.: 66.41%] [G loss: 0.575688]\n",
      "epoch:19 step:17979 [D loss: 0.583797, acc.: 65.62%] [G loss: 0.468271]\n",
      "epoch:19 step:17980 [D loss: 0.520299, acc.: 71.88%] [G loss: 0.479250]\n",
      "epoch:19 step:17981 [D loss: 0.577662, acc.: 66.41%] [G loss: 0.589538]\n",
      "epoch:19 step:17982 [D loss: 0.553407, acc.: 69.53%] [G loss: 0.538805]\n",
      "epoch:19 step:17983 [D loss: 0.625351, acc.: 63.28%] [G loss: 0.574340]\n",
      "epoch:19 step:17984 [D loss: 0.621399, acc.: 61.72%] [G loss: 0.335757]\n",
      "epoch:19 step:17985 [D loss: 0.524665, acc.: 72.66%] [G loss: 0.617281]\n",
      "epoch:19 step:17986 [D loss: 0.611675, acc.: 67.19%] [G loss: 0.758757]\n",
      "epoch:19 step:17987 [D loss: 0.567239, acc.: 69.53%] [G loss: 0.712426]\n",
      "epoch:19 step:17988 [D loss: 0.584033, acc.: 63.28%] [G loss: 0.722186]\n",
      "epoch:19 step:17989 [D loss: 0.531838, acc.: 70.31%] [G loss: 0.785125]\n",
      "epoch:19 step:17990 [D loss: 0.620455, acc.: 64.84%] [G loss: 0.551049]\n",
      "epoch:19 step:17991 [D loss: 0.537480, acc.: 73.44%] [G loss: 0.610657]\n",
      "epoch:19 step:17992 [D loss: 0.581701, acc.: 69.53%] [G loss: 0.628505]\n",
      "epoch:19 step:17993 [D loss: 0.458224, acc.: 76.56%] [G loss: 0.666273]\n",
      "epoch:19 step:17994 [D loss: 0.523840, acc.: 74.22%] [G loss: 0.635585]\n",
      "epoch:19 step:17995 [D loss: 0.552899, acc.: 75.78%] [G loss: 0.641107]\n",
      "epoch:19 step:17996 [D loss: 0.579835, acc.: 66.41%] [G loss: 0.564552]\n",
      "epoch:19 step:17997 [D loss: 0.460749, acc.: 80.47%] [G loss: 0.680190]\n",
      "epoch:19 step:17998 [D loss: 0.540749, acc.: 73.44%] [G loss: 0.744648]\n",
      "epoch:19 step:17999 [D loss: 0.541371, acc.: 68.75%] [G loss: 0.623593]\n",
      "epoch:19 step:18000 [D loss: 0.566493, acc.: 68.75%] [G loss: 0.661227]\n",
      "##############\n",
      "[3.04082736 1.39840628 6.52491038 4.94708321 3.66485476 5.95664551\n",
      " 4.37590924 4.67543246 4.6360684  4.40911496]\n",
      "##########\n",
      "epoch:19 step:18001 [D loss: 0.477558, acc.: 74.22%] [G loss: 0.761355]\n",
      "epoch:19 step:18002 [D loss: 0.508796, acc.: 71.88%] [G loss: 0.921378]\n",
      "epoch:19 step:18003 [D loss: 0.651844, acc.: 60.16%] [G loss: 0.603549]\n",
      "epoch:19 step:18004 [D loss: 0.557669, acc.: 70.31%] [G loss: 0.616011]\n",
      "epoch:19 step:18005 [D loss: 0.506808, acc.: 74.22%] [G loss: 0.542345]\n",
      "epoch:19 step:18006 [D loss: 0.647337, acc.: 64.06%] [G loss: 0.468512]\n",
      "epoch:19 step:18007 [D loss: 0.547232, acc.: 70.31%] [G loss: 0.645329]\n",
      "epoch:19 step:18008 [D loss: 0.487069, acc.: 78.91%] [G loss: 0.713584]\n",
      "epoch:19 step:18009 [D loss: 0.506451, acc.: 72.66%] [G loss: 0.633100]\n",
      "epoch:19 step:18010 [D loss: 0.515673, acc.: 71.88%] [G loss: 0.742737]\n",
      "epoch:19 step:18011 [D loss: 0.465191, acc.: 78.12%] [G loss: 0.929215]\n",
      "epoch:19 step:18012 [D loss: 0.509118, acc.: 77.34%] [G loss: 0.855674]\n",
      "epoch:19 step:18013 [D loss: 0.636692, acc.: 63.28%] [G loss: 0.595109]\n",
      "epoch:19 step:18014 [D loss: 0.587336, acc.: 67.97%] [G loss: 0.595773]\n",
      "epoch:19 step:18015 [D loss: 0.540311, acc.: 67.97%] [G loss: 0.607778]\n",
      "epoch:19 step:18016 [D loss: 0.520743, acc.: 71.88%] [G loss: 0.543324]\n",
      "epoch:19 step:18017 [D loss: 0.633612, acc.: 64.06%] [G loss: 0.522013]\n",
      "epoch:19 step:18018 [D loss: 0.543454, acc.: 67.19%] [G loss: 0.516133]\n",
      "epoch:19 step:18019 [D loss: 0.529732, acc.: 71.09%] [G loss: 0.756634]\n",
      "epoch:19 step:18020 [D loss: 0.492520, acc.: 74.22%] [G loss: 0.736742]\n",
      "epoch:19 step:18021 [D loss: 0.505364, acc.: 75.00%] [G loss: 0.627660]\n",
      "epoch:19 step:18022 [D loss: 0.455964, acc.: 78.12%] [G loss: 0.826096]\n",
      "epoch:19 step:18023 [D loss: 0.654433, acc.: 67.97%] [G loss: 0.654048]\n",
      "epoch:19 step:18024 [D loss: 0.561031, acc.: 66.41%] [G loss: 0.588409]\n",
      "epoch:19 step:18025 [D loss: 0.424593, acc.: 81.25%] [G loss: 0.980067]\n",
      "epoch:19 step:18026 [D loss: 0.480161, acc.: 76.56%] [G loss: 0.828129]\n",
      "epoch:19 step:18027 [D loss: 0.579361, acc.: 71.09%] [G loss: 0.632415]\n",
      "epoch:19 step:18028 [D loss: 0.560046, acc.: 67.19%] [G loss: 0.604786]\n",
      "epoch:19 step:18029 [D loss: 0.581333, acc.: 63.28%] [G loss: 0.496834]\n",
      "epoch:19 step:18030 [D loss: 0.553558, acc.: 67.97%] [G loss: 0.532690]\n",
      "epoch:19 step:18031 [D loss: 0.674194, acc.: 58.59%] [G loss: 0.448988]\n",
      "epoch:19 step:18032 [D loss: 0.503355, acc.: 76.56%] [G loss: 0.582775]\n",
      "epoch:19 step:18033 [D loss: 0.506863, acc.: 76.56%] [G loss: 0.722111]\n",
      "epoch:19 step:18034 [D loss: 0.458359, acc.: 77.34%] [G loss: 0.813158]\n",
      "epoch:19 step:18035 [D loss: 0.457762, acc.: 78.91%] [G loss: 0.912104]\n",
      "epoch:19 step:18036 [D loss: 0.536296, acc.: 71.88%] [G loss: 0.867197]\n",
      "epoch:19 step:18037 [D loss: 0.567979, acc.: 69.53%] [G loss: 0.677827]\n",
      "epoch:19 step:18038 [D loss: 0.561673, acc.: 69.53%] [G loss: 0.712193]\n",
      "epoch:19 step:18039 [D loss: 0.549462, acc.: 69.53%] [G loss: 0.603772]\n",
      "epoch:19 step:18040 [D loss: 0.549946, acc.: 70.31%] [G loss: 0.668327]\n",
      "epoch:19 step:18041 [D loss: 0.627112, acc.: 64.84%] [G loss: 0.494884]\n",
      "epoch:19 step:18042 [D loss: 0.523908, acc.: 73.44%] [G loss: 0.549150]\n",
      "epoch:19 step:18043 [D loss: 0.565979, acc.: 67.19%] [G loss: 0.611325]\n",
      "epoch:19 step:18044 [D loss: 0.484551, acc.: 76.56%] [G loss: 0.642619]\n",
      "epoch:19 step:18045 [D loss: 0.576860, acc.: 69.53%] [G loss: 0.696298]\n",
      "epoch:19 step:18046 [D loss: 0.525936, acc.: 69.53%] [G loss: 0.631775]\n",
      "epoch:19 step:18047 [D loss: 0.522019, acc.: 74.22%] [G loss: 0.575889]\n",
      "epoch:19 step:18048 [D loss: 0.510011, acc.: 76.56%] [G loss: 0.654656]\n",
      "epoch:19 step:18049 [D loss: 0.501931, acc.: 74.22%] [G loss: 0.731980]\n",
      "epoch:19 step:18050 [D loss: 0.513019, acc.: 72.66%] [G loss: 0.684540]\n",
      "epoch:19 step:18051 [D loss: 0.528290, acc.: 71.88%] [G loss: 0.578506]\n",
      "epoch:19 step:18052 [D loss: 0.548914, acc.: 69.53%] [G loss: 0.758631]\n",
      "epoch:19 step:18053 [D loss: 0.548494, acc.: 70.31%] [G loss: 0.682947]\n",
      "epoch:19 step:18054 [D loss: 0.622415, acc.: 60.16%] [G loss: 0.635133]\n",
      "epoch:19 step:18055 [D loss: 0.630156, acc.: 64.06%] [G loss: 0.788426]\n",
      "epoch:19 step:18056 [D loss: 0.562765, acc.: 71.09%] [G loss: 0.654250]\n",
      "epoch:19 step:18057 [D loss: 0.541598, acc.: 72.66%] [G loss: 0.625400]\n",
      "epoch:19 step:18058 [D loss: 0.530118, acc.: 71.88%] [G loss: 0.607159]\n",
      "epoch:19 step:18059 [D loss: 0.550835, acc.: 72.66%] [G loss: 0.695572]\n",
      "epoch:19 step:18060 [D loss: 0.632163, acc.: 60.16%] [G loss: 0.561071]\n",
      "epoch:19 step:18061 [D loss: 0.538149, acc.: 72.66%] [G loss: 0.634183]\n",
      "epoch:19 step:18062 [D loss: 0.538069, acc.: 70.31%] [G loss: 0.572104]\n",
      "epoch:19 step:18063 [D loss: 0.579540, acc.: 65.62%] [G loss: 0.566867]\n",
      "epoch:19 step:18064 [D loss: 0.571269, acc.: 67.19%] [G loss: 0.533117]\n",
      "epoch:19 step:18065 [D loss: 0.529415, acc.: 71.88%] [G loss: 0.563757]\n",
      "epoch:19 step:18066 [D loss: 0.591996, acc.: 67.19%] [G loss: 0.470283]\n",
      "epoch:19 step:18067 [D loss: 0.546066, acc.: 69.53%] [G loss: 0.548050]\n",
      "epoch:19 step:18068 [D loss: 0.586419, acc.: 67.97%] [G loss: 0.519751]\n",
      "epoch:19 step:18069 [D loss: 0.617360, acc.: 64.06%] [G loss: 0.508144]\n",
      "epoch:19 step:18070 [D loss: 0.571080, acc.: 69.53%] [G loss: 0.612749]\n",
      "epoch:19 step:18071 [D loss: 0.522057, acc.: 70.31%] [G loss: 0.721377]\n",
      "epoch:19 step:18072 [D loss: 0.541584, acc.: 70.31%] [G loss: 0.604637]\n",
      "epoch:19 step:18073 [D loss: 0.465456, acc.: 75.78%] [G loss: 0.654011]\n",
      "epoch:19 step:18074 [D loss: 0.541175, acc.: 70.31%] [G loss: 0.727640]\n",
      "epoch:19 step:18075 [D loss: 0.576282, acc.: 70.31%] [G loss: 0.667096]\n",
      "epoch:19 step:18076 [D loss: 0.565998, acc.: 64.84%] [G loss: 0.610949]\n",
      "epoch:19 step:18077 [D loss: 0.536306, acc.: 68.75%] [G loss: 0.629987]\n",
      "epoch:19 step:18078 [D loss: 0.604304, acc.: 67.97%] [G loss: 0.545457]\n",
      "epoch:19 step:18079 [D loss: 0.533935, acc.: 77.34%] [G loss: 0.663651]\n",
      "epoch:19 step:18080 [D loss: 0.694332, acc.: 62.50%] [G loss: 0.438907]\n",
      "epoch:19 step:18081 [D loss: 0.636252, acc.: 67.97%] [G loss: 0.503224]\n",
      "epoch:19 step:18082 [D loss: 0.558308, acc.: 71.88%] [G loss: 0.365694]\n",
      "epoch:19 step:18083 [D loss: 0.527583, acc.: 71.88%] [G loss: 0.581270]\n",
      "epoch:19 step:18084 [D loss: 0.606749, acc.: 64.06%] [G loss: 0.470064]\n",
      "epoch:19 step:18085 [D loss: 0.588975, acc.: 67.97%] [G loss: 0.536508]\n",
      "epoch:19 step:18086 [D loss: 0.509991, acc.: 69.53%] [G loss: 0.629220]\n",
      "epoch:19 step:18087 [D loss: 0.557956, acc.: 68.75%] [G loss: 0.477841]\n",
      "epoch:19 step:18088 [D loss: 0.527659, acc.: 71.09%] [G loss: 0.523271]\n",
      "epoch:19 step:18089 [D loss: 0.513107, acc.: 75.00%] [G loss: 0.666824]\n",
      "epoch:19 step:18090 [D loss: 0.569861, acc.: 70.31%] [G loss: 0.640032]\n",
      "epoch:19 step:18091 [D loss: 0.583466, acc.: 67.19%] [G loss: 0.581977]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:19 step:18092 [D loss: 0.581503, acc.: 68.75%] [G loss: 0.623218]\n",
      "epoch:19 step:18093 [D loss: 0.601685, acc.: 64.06%] [G loss: 0.619777]\n",
      "epoch:19 step:18094 [D loss: 0.630831, acc.: 65.62%] [G loss: 0.489892]\n",
      "epoch:19 step:18095 [D loss: 0.481319, acc.: 75.00%] [G loss: 0.596772]\n",
      "epoch:19 step:18096 [D loss: 0.568414, acc.: 65.62%] [G loss: 0.641958]\n",
      "epoch:19 step:18097 [D loss: 0.592594, acc.: 60.16%] [G loss: 0.617432]\n",
      "epoch:19 step:18098 [D loss: 0.559993, acc.: 71.09%] [G loss: 0.515349]\n",
      "epoch:19 step:18099 [D loss: 0.497444, acc.: 75.00%] [G loss: 0.573951]\n",
      "epoch:19 step:18100 [D loss: 0.580161, acc.: 64.06%] [G loss: 0.477635]\n",
      "epoch:19 step:18101 [D loss: 0.488024, acc.: 78.91%] [G loss: 0.659798]\n",
      "epoch:19 step:18102 [D loss: 0.467190, acc.: 76.56%] [G loss: 0.738531]\n",
      "epoch:19 step:18103 [D loss: 0.531432, acc.: 74.22%] [G loss: 0.642974]\n",
      "epoch:19 step:18104 [D loss: 0.613960, acc.: 68.75%] [G loss: 0.545793]\n",
      "epoch:19 step:18105 [D loss: 0.508894, acc.: 73.44%] [G loss: 0.566298]\n",
      "epoch:19 step:18106 [D loss: 0.540116, acc.: 67.97%] [G loss: 0.613196]\n",
      "epoch:19 step:18107 [D loss: 0.452131, acc.: 80.47%] [G loss: 0.532974]\n",
      "epoch:19 step:18108 [D loss: 0.543261, acc.: 69.53%] [G loss: 0.699952]\n",
      "epoch:19 step:18109 [D loss: 0.484667, acc.: 76.56%] [G loss: 0.900004]\n",
      "epoch:19 step:18110 [D loss: 0.508338, acc.: 75.78%] [G loss: 0.714774]\n",
      "epoch:19 step:18111 [D loss: 0.616300, acc.: 66.41%] [G loss: 0.771158]\n",
      "epoch:19 step:18112 [D loss: 0.559284, acc.: 67.97%] [G loss: 0.773156]\n",
      "epoch:19 step:18113 [D loss: 0.531050, acc.: 69.53%] [G loss: 0.765599]\n",
      "epoch:19 step:18114 [D loss: 0.565492, acc.: 67.97%] [G loss: 0.668371]\n",
      "epoch:19 step:18115 [D loss: 0.479276, acc.: 79.69%] [G loss: 0.896461]\n",
      "epoch:19 step:18116 [D loss: 0.533010, acc.: 71.88%] [G loss: 0.916359]\n",
      "epoch:19 step:18117 [D loss: 0.432246, acc.: 80.47%] [G loss: 0.842747]\n",
      "epoch:19 step:18118 [D loss: 0.500905, acc.: 73.44%] [G loss: 0.948897]\n",
      "epoch:19 step:18119 [D loss: 0.636507, acc.: 67.97%] [G loss: 0.586410]\n",
      "epoch:19 step:18120 [D loss: 0.593927, acc.: 66.41%] [G loss: 0.523093]\n",
      "epoch:19 step:18121 [D loss: 0.516822, acc.: 69.53%] [G loss: 0.479871]\n",
      "epoch:19 step:18122 [D loss: 0.563296, acc.: 70.31%] [G loss: 0.426895]\n",
      "epoch:19 step:18123 [D loss: 0.578799, acc.: 67.19%] [G loss: 0.627577]\n",
      "epoch:19 step:18124 [D loss: 0.447131, acc.: 80.47%] [G loss: 0.896260]\n",
      "epoch:19 step:18125 [D loss: 0.567825, acc.: 69.53%] [G loss: 0.673817]\n",
      "epoch:19 step:18126 [D loss: 0.603544, acc.: 68.75%] [G loss: 0.683728]\n",
      "epoch:19 step:18127 [D loss: 0.588764, acc.: 66.41%] [G loss: 0.398965]\n",
      "epoch:19 step:18128 [D loss: 0.545854, acc.: 71.09%] [G loss: 0.600553]\n",
      "epoch:19 step:18129 [D loss: 0.487663, acc.: 75.00%] [G loss: 0.698229]\n",
      "epoch:19 step:18130 [D loss: 0.508387, acc.: 71.09%] [G loss: 0.651979]\n",
      "epoch:19 step:18131 [D loss: 0.504846, acc.: 75.00%] [G loss: 0.793190]\n",
      "epoch:19 step:18132 [D loss: 0.524422, acc.: 74.22%] [G loss: 0.727599]\n",
      "epoch:19 step:18133 [D loss: 0.589583, acc.: 61.72%] [G loss: 0.571388]\n",
      "epoch:19 step:18134 [D loss: 0.578976, acc.: 67.19%] [G loss: 0.517304]\n",
      "epoch:19 step:18135 [D loss: 0.521503, acc.: 73.44%] [G loss: 0.562780]\n",
      "epoch:19 step:18136 [D loss: 0.464055, acc.: 80.47%] [G loss: 0.609502]\n",
      "epoch:19 step:18137 [D loss: 0.492456, acc.: 75.78%] [G loss: 0.802859]\n",
      "epoch:19 step:18138 [D loss: 0.501210, acc.: 78.12%] [G loss: 0.740743]\n",
      "epoch:19 step:18139 [D loss: 0.457554, acc.: 77.34%] [G loss: 0.738949]\n",
      "epoch:19 step:18140 [D loss: 0.533009, acc.: 69.53%] [G loss: 0.862635]\n",
      "epoch:19 step:18141 [D loss: 0.574505, acc.: 63.28%] [G loss: 0.663566]\n",
      "epoch:19 step:18142 [D loss: 0.576133, acc.: 68.75%] [G loss: 0.628044]\n",
      "epoch:19 step:18143 [D loss: 0.456211, acc.: 81.25%] [G loss: 0.603872]\n",
      "epoch:19 step:18144 [D loss: 0.672199, acc.: 63.28%] [G loss: 0.520191]\n",
      "epoch:19 step:18145 [D loss: 0.634193, acc.: 62.50%] [G loss: 0.507951]\n",
      "epoch:19 step:18146 [D loss: 0.493805, acc.: 74.22%] [G loss: 0.627574]\n",
      "epoch:19 step:18147 [D loss: 0.490083, acc.: 74.22%] [G loss: 0.901994]\n",
      "epoch:19 step:18148 [D loss: 0.558380, acc.: 64.84%] [G loss: 0.873568]\n",
      "epoch:19 step:18149 [D loss: 0.562423, acc.: 64.06%] [G loss: 0.875222]\n",
      "epoch:19 step:18150 [D loss: 0.463829, acc.: 80.47%] [G loss: 1.009093]\n",
      "epoch:19 step:18151 [D loss: 0.641191, acc.: 67.19%] [G loss: 0.799536]\n",
      "epoch:19 step:18152 [D loss: 0.778267, acc.: 53.12%] [G loss: 0.541178]\n",
      "epoch:19 step:18153 [D loss: 0.467630, acc.: 74.22%] [G loss: 0.698616]\n",
      "epoch:19 step:18154 [D loss: 0.527366, acc.: 71.09%] [G loss: 0.506962]\n",
      "epoch:19 step:18155 [D loss: 0.643021, acc.: 60.16%] [G loss: 0.617738]\n",
      "epoch:19 step:18156 [D loss: 0.544918, acc.: 71.09%] [G loss: 0.747756]\n",
      "epoch:19 step:18157 [D loss: 0.402498, acc.: 81.25%] [G loss: 1.001853]\n",
      "epoch:19 step:18158 [D loss: 0.515208, acc.: 67.97%] [G loss: 0.819846]\n",
      "epoch:19 step:18159 [D loss: 0.531288, acc.: 78.12%] [G loss: 0.694330]\n",
      "epoch:19 step:18160 [D loss: 0.497880, acc.: 74.22%] [G loss: 0.715938]\n",
      "epoch:19 step:18161 [D loss: 0.477338, acc.: 76.56%] [G loss: 0.762390]\n",
      "epoch:19 step:18162 [D loss: 0.497759, acc.: 74.22%] [G loss: 0.833222]\n",
      "epoch:19 step:18163 [D loss: 0.510786, acc.: 71.88%] [G loss: 0.897637]\n",
      "epoch:19 step:18164 [D loss: 0.501174, acc.: 75.78%] [G loss: 0.786882]\n",
      "epoch:19 step:18165 [D loss: 0.551335, acc.: 68.75%] [G loss: 0.708501]\n",
      "epoch:19 step:18166 [D loss: 0.600144, acc.: 64.84%] [G loss: 0.733625]\n",
      "epoch:19 step:18167 [D loss: 0.496258, acc.: 78.91%] [G loss: 0.684014]\n",
      "epoch:19 step:18168 [D loss: 0.591309, acc.: 65.62%] [G loss: 0.573972]\n",
      "epoch:19 step:18169 [D loss: 0.565380, acc.: 69.53%] [G loss: 0.552665]\n",
      "epoch:19 step:18170 [D loss: 0.583012, acc.: 64.84%] [G loss: 0.659476]\n",
      "epoch:19 step:18171 [D loss: 0.611174, acc.: 61.72%] [G loss: 0.727073]\n",
      "epoch:19 step:18172 [D loss: 0.528041, acc.: 69.53%] [G loss: 0.726084]\n",
      "epoch:19 step:18173 [D loss: 0.557677, acc.: 71.09%] [G loss: 0.698304]\n",
      "epoch:19 step:18174 [D loss: 0.499438, acc.: 76.56%] [G loss: 0.744273]\n",
      "epoch:19 step:18175 [D loss: 0.525881, acc.: 75.78%] [G loss: 0.908323]\n",
      "epoch:19 step:18176 [D loss: 0.555601, acc.: 71.09%] [G loss: 0.727677]\n",
      "epoch:19 step:18177 [D loss: 0.446361, acc.: 82.03%] [G loss: 0.797092]\n",
      "epoch:19 step:18178 [D loss: 0.575343, acc.: 71.88%] [G loss: 0.581824]\n",
      "epoch:19 step:18179 [D loss: 0.741315, acc.: 50.78%] [G loss: 0.348387]\n",
      "epoch:19 step:18180 [D loss: 0.591563, acc.: 63.28%] [G loss: 0.460908]\n",
      "epoch:19 step:18181 [D loss: 0.532198, acc.: 71.09%] [G loss: 0.598351]\n",
      "epoch:19 step:18182 [D loss: 0.581028, acc.: 66.41%] [G loss: 0.526175]\n",
      "epoch:19 step:18183 [D loss: 0.570372, acc.: 68.75%] [G loss: 0.526010]\n",
      "epoch:19 step:18184 [D loss: 0.465847, acc.: 78.91%] [G loss: 0.561348]\n",
      "epoch:19 step:18185 [D loss: 0.544194, acc.: 71.88%] [G loss: 0.571187]\n",
      "epoch:19 step:18186 [D loss: 0.533356, acc.: 71.88%] [G loss: 0.656886]\n",
      "epoch:19 step:18187 [D loss: 0.570676, acc.: 70.31%] [G loss: 0.555356]\n",
      "epoch:19 step:18188 [D loss: 0.495750, acc.: 75.00%] [G loss: 0.686075]\n",
      "epoch:19 step:18189 [D loss: 0.584683, acc.: 67.19%] [G loss: 0.607214]\n",
      "epoch:19 step:18190 [D loss: 0.524661, acc.: 71.88%] [G loss: 0.638241]\n",
      "epoch:19 step:18191 [D loss: 0.568543, acc.: 72.66%] [G loss: 0.592872]\n",
      "epoch:19 step:18192 [D loss: 0.558103, acc.: 69.53%] [G loss: 0.655847]\n",
      "epoch:19 step:18193 [D loss: 0.612028, acc.: 65.62%] [G loss: 0.585084]\n",
      "epoch:19 step:18194 [D loss: 0.557895, acc.: 67.19%] [G loss: 0.629137]\n",
      "epoch:19 step:18195 [D loss: 0.495932, acc.: 75.78%] [G loss: 0.683613]\n",
      "epoch:19 step:18196 [D loss: 0.586673, acc.: 66.41%] [G loss: 0.509654]\n",
      "epoch:19 step:18197 [D loss: 0.549759, acc.: 66.41%] [G loss: 0.422807]\n",
      "epoch:19 step:18198 [D loss: 0.524655, acc.: 70.31%] [G loss: 0.646023]\n",
      "epoch:19 step:18199 [D loss: 0.559874, acc.: 67.19%] [G loss: 0.568945]\n",
      "epoch:19 step:18200 [D loss: 0.601003, acc.: 66.41%] [G loss: 0.591764]\n",
      "##############\n",
      "[3.06625606 0.92254707 6.23660753 4.91329774 3.65864862 5.71428077\n",
      " 4.40365457 4.80810604 4.73706761 4.17438952]\n",
      "##########\n",
      "epoch:19 step:18201 [D loss: 0.476369, acc.: 75.00%] [G loss: 0.537934]\n",
      "epoch:19 step:18202 [D loss: 0.552566, acc.: 70.31%] [G loss: 0.798282]\n",
      "epoch:19 step:18203 [D loss: 0.580572, acc.: 63.28%] [G loss: 0.605474]\n",
      "epoch:19 step:18204 [D loss: 0.607843, acc.: 61.72%] [G loss: 0.513602]\n",
      "epoch:19 step:18205 [D loss: 0.497381, acc.: 74.22%] [G loss: 0.665141]\n",
      "epoch:19 step:18206 [D loss: 0.494905, acc.: 70.31%] [G loss: 0.711884]\n",
      "epoch:19 step:18207 [D loss: 0.586057, acc.: 71.88%] [G loss: 0.552684]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:19 step:18208 [D loss: 0.511140, acc.: 76.56%] [G loss: 0.646701]\n",
      "epoch:19 step:18209 [D loss: 0.546082, acc.: 73.44%] [G loss: 0.713907]\n",
      "epoch:19 step:18210 [D loss: 0.582617, acc.: 67.97%] [G loss: 0.732982]\n",
      "epoch:19 step:18211 [D loss: 0.567297, acc.: 71.88%] [G loss: 0.586608]\n",
      "epoch:19 step:18212 [D loss: 0.589564, acc.: 64.06%] [G loss: 0.656917]\n",
      "epoch:19 step:18213 [D loss: 0.557372, acc.: 68.75%] [G loss: 0.616527]\n",
      "epoch:19 step:18214 [D loss: 0.573270, acc.: 67.19%] [G loss: 0.703125]\n",
      "epoch:19 step:18215 [D loss: 0.627411, acc.: 61.72%] [G loss: 0.494204]\n",
      "epoch:19 step:18216 [D loss: 0.575244, acc.: 72.66%] [G loss: 0.452654]\n",
      "epoch:19 step:18217 [D loss: 0.537240, acc.: 70.31%] [G loss: 0.774152]\n",
      "epoch:19 step:18218 [D loss: 0.532879, acc.: 73.44%] [G loss: 0.833901]\n",
      "epoch:19 step:18219 [D loss: 0.506272, acc.: 71.09%] [G loss: 0.833622]\n",
      "epoch:19 step:18220 [D loss: 0.557271, acc.: 68.75%] [G loss: 0.798592]\n",
      "epoch:19 step:18221 [D loss: 0.643195, acc.: 67.19%] [G loss: 0.618149]\n",
      "epoch:19 step:18222 [D loss: 0.556905, acc.: 67.19%] [G loss: 0.590341]\n",
      "epoch:19 step:18223 [D loss: 0.612781, acc.: 60.94%] [G loss: 0.743401]\n",
      "epoch:19 step:18224 [D loss: 0.574172, acc.: 71.88%] [G loss: 0.629549]\n",
      "epoch:19 step:18225 [D loss: 0.598211, acc.: 69.53%] [G loss: 0.560191]\n",
      "epoch:19 step:18226 [D loss: 0.557347, acc.: 64.06%] [G loss: 0.570273]\n",
      "epoch:19 step:18227 [D loss: 0.563500, acc.: 65.62%] [G loss: 0.629672]\n",
      "epoch:19 step:18228 [D loss: 0.519584, acc.: 76.56%] [G loss: 0.762966]\n",
      "epoch:19 step:18229 [D loss: 0.518541, acc.: 71.09%] [G loss: 0.754419]\n",
      "epoch:19 step:18230 [D loss: 0.430338, acc.: 79.69%] [G loss: 0.827658]\n",
      "epoch:19 step:18231 [D loss: 0.606750, acc.: 65.62%] [G loss: 0.772389]\n",
      "epoch:19 step:18232 [D loss: 0.483223, acc.: 77.34%] [G loss: 0.659899]\n",
      "epoch:19 step:18233 [D loss: 0.589857, acc.: 67.19%] [G loss: 0.699649]\n",
      "epoch:19 step:18234 [D loss: 0.518942, acc.: 69.53%] [G loss: 0.666402]\n",
      "epoch:19 step:18235 [D loss: 0.587133, acc.: 62.50%] [G loss: 0.592456]\n",
      "epoch:19 step:18236 [D loss: 0.563180, acc.: 69.53%] [G loss: 0.636659]\n",
      "epoch:19 step:18237 [D loss: 0.508051, acc.: 75.78%] [G loss: 0.595593]\n",
      "epoch:19 step:18238 [D loss: 0.526663, acc.: 67.97%] [G loss: 0.615903]\n",
      "epoch:19 step:18239 [D loss: 0.441899, acc.: 77.34%] [G loss: 0.770712]\n",
      "epoch:19 step:18240 [D loss: 0.664684, acc.: 64.06%] [G loss: 0.623121]\n",
      "epoch:19 step:18241 [D loss: 0.611613, acc.: 64.84%] [G loss: 0.456736]\n",
      "epoch:19 step:18242 [D loss: 0.565582, acc.: 74.22%] [G loss: 0.761300]\n",
      "epoch:19 step:18243 [D loss: 0.535371, acc.: 69.53%] [G loss: 0.869301]\n",
      "epoch:19 step:18244 [D loss: 0.525763, acc.: 71.88%] [G loss: 0.797335]\n",
      "epoch:19 step:18245 [D loss: 0.571572, acc.: 66.41%] [G loss: 0.716177]\n",
      "epoch:19 step:18246 [D loss: 0.508761, acc.: 76.56%] [G loss: 0.909974]\n",
      "epoch:19 step:18247 [D loss: 0.516432, acc.: 73.44%] [G loss: 0.890467]\n",
      "epoch:19 step:18248 [D loss: 0.535395, acc.: 72.66%] [G loss: 0.729138]\n",
      "epoch:19 step:18249 [D loss: 0.527183, acc.: 67.97%] [G loss: 0.807388]\n",
      "epoch:19 step:18250 [D loss: 0.545432, acc.: 73.44%] [G loss: 0.921737]\n",
      "epoch:19 step:18251 [D loss: 0.570125, acc.: 70.31%] [G loss: 0.738531]\n",
      "epoch:19 step:18252 [D loss: 0.482244, acc.: 75.78%] [G loss: 0.823784]\n",
      "epoch:19 step:18253 [D loss: 0.513200, acc.: 71.88%] [G loss: 0.854452]\n",
      "epoch:19 step:18254 [D loss: 0.496829, acc.: 74.22%] [G loss: 0.793482]\n",
      "epoch:19 step:18255 [D loss: 0.492380, acc.: 76.56%] [G loss: 0.915531]\n",
      "epoch:19 step:18256 [D loss: 0.566490, acc.: 71.88%] [G loss: 0.718582]\n",
      "epoch:19 step:18257 [D loss: 0.576467, acc.: 67.19%] [G loss: 0.777268]\n",
      "epoch:19 step:18258 [D loss: 0.589210, acc.: 65.62%] [G loss: 0.600474]\n",
      "epoch:19 step:18259 [D loss: 0.665221, acc.: 58.59%] [G loss: 0.575816]\n",
      "epoch:19 step:18260 [D loss: 0.518506, acc.: 70.31%] [G loss: 0.671269]\n",
      "epoch:19 step:18261 [D loss: 0.651417, acc.: 63.28%] [G loss: 0.464646]\n",
      "epoch:19 step:18262 [D loss: 0.543586, acc.: 70.31%] [G loss: 0.541127]\n",
      "epoch:19 step:18263 [D loss: 0.516509, acc.: 74.22%] [G loss: 0.603434]\n",
      "epoch:19 step:18264 [D loss: 0.553718, acc.: 68.75%] [G loss: 0.648024]\n",
      "epoch:19 step:18265 [D loss: 0.574586, acc.: 65.62%] [G loss: 0.763966]\n",
      "epoch:19 step:18266 [D loss: 0.549333, acc.: 71.88%] [G loss: 0.508783]\n",
      "epoch:19 step:18267 [D loss: 0.532288, acc.: 72.66%] [G loss: 0.697993]\n",
      "epoch:19 step:18268 [D loss: 0.586545, acc.: 68.75%] [G loss: 0.576371]\n",
      "epoch:19 step:18269 [D loss: 0.533506, acc.: 71.88%] [G loss: 0.687754]\n",
      "epoch:19 step:18270 [D loss: 0.513570, acc.: 70.31%] [G loss: 0.742332]\n",
      "epoch:19 step:18271 [D loss: 0.554298, acc.: 70.31%] [G loss: 0.722609]\n",
      "epoch:19 step:18272 [D loss: 0.528301, acc.: 71.88%] [G loss: 0.591051]\n",
      "epoch:19 step:18273 [D loss: 0.567985, acc.: 71.09%] [G loss: 0.721041]\n",
      "epoch:19 step:18274 [D loss: 0.412216, acc.: 82.03%] [G loss: 0.715606]\n",
      "epoch:19 step:18275 [D loss: 0.443837, acc.: 78.12%] [G loss: 0.886132]\n",
      "epoch:19 step:18276 [D loss: 0.645665, acc.: 59.38%] [G loss: 0.626218]\n",
      "epoch:19 step:18277 [D loss: 0.600517, acc.: 60.16%] [G loss: 0.775155]\n",
      "epoch:19 step:18278 [D loss: 0.493208, acc.: 75.00%] [G loss: 0.912189]\n",
      "epoch:19 step:18279 [D loss: 0.509465, acc.: 73.44%] [G loss: 0.852680]\n",
      "epoch:19 step:18280 [D loss: 0.653133, acc.: 64.06%] [G loss: 0.548506]\n",
      "epoch:19 step:18281 [D loss: 0.587586, acc.: 68.75%] [G loss: 0.588573]\n",
      "epoch:19 step:18282 [D loss: 0.541062, acc.: 70.31%] [G loss: 0.571530]\n",
      "epoch:19 step:18283 [D loss: 0.629201, acc.: 62.50%] [G loss: 0.484736]\n",
      "epoch:19 step:18284 [D loss: 0.507629, acc.: 78.12%] [G loss: 0.659375]\n",
      "epoch:19 step:18285 [D loss: 0.602797, acc.: 65.62%] [G loss: 0.507967]\n",
      "epoch:19 step:18286 [D loss: 0.585884, acc.: 73.44%] [G loss: 0.529140]\n",
      "epoch:19 step:18287 [D loss: 0.483029, acc.: 74.22%] [G loss: 0.846415]\n",
      "epoch:19 step:18288 [D loss: 0.546576, acc.: 67.97%] [G loss: 0.834905]\n",
      "epoch:19 step:18289 [D loss: 0.577134, acc.: 65.62%] [G loss: 0.703531]\n",
      "epoch:19 step:18290 [D loss: 0.644336, acc.: 60.16%] [G loss: 0.526988]\n",
      "epoch:19 step:18291 [D loss: 0.496775, acc.: 76.56%] [G loss: 0.635630]\n",
      "epoch:19 step:18292 [D loss: 0.557671, acc.: 71.88%] [G loss: 0.590665]\n",
      "epoch:19 step:18293 [D loss: 0.571375, acc.: 70.31%] [G loss: 0.725320]\n",
      "epoch:19 step:18294 [D loss: 0.547390, acc.: 71.88%] [G loss: 0.661596]\n",
      "epoch:19 step:18295 [D loss: 0.626669, acc.: 64.06%] [G loss: 0.551474]\n",
      "epoch:19 step:18296 [D loss: 0.530275, acc.: 69.53%] [G loss: 0.547778]\n",
      "epoch:19 step:18297 [D loss: 0.549903, acc.: 70.31%] [G loss: 0.526363]\n",
      "epoch:19 step:18298 [D loss: 0.512530, acc.: 75.00%] [G loss: 0.655065]\n",
      "epoch:19 step:18299 [D loss: 0.586920, acc.: 71.09%] [G loss: 0.683732]\n",
      "epoch:19 step:18300 [D loss: 0.570280, acc.: 74.22%] [G loss: 0.697603]\n",
      "epoch:19 step:18301 [D loss: 0.522205, acc.: 68.75%] [G loss: 0.803731]\n",
      "epoch:19 step:18302 [D loss: 0.477010, acc.: 77.34%] [G loss: 0.634793]\n",
      "epoch:19 step:18303 [D loss: 0.611343, acc.: 69.53%] [G loss: 0.460356]\n",
      "epoch:19 step:18304 [D loss: 0.643437, acc.: 67.19%] [G loss: 0.543807]\n",
      "epoch:19 step:18305 [D loss: 0.603268, acc.: 67.97%] [G loss: 0.594313]\n",
      "epoch:19 step:18306 [D loss: 0.518640, acc.: 74.22%] [G loss: 0.755843]\n",
      "epoch:19 step:18307 [D loss: 0.432168, acc.: 82.03%] [G loss: 0.823649]\n",
      "epoch:19 step:18308 [D loss: 0.464039, acc.: 79.69%] [G loss: 0.681836]\n",
      "epoch:19 step:18309 [D loss: 0.491370, acc.: 76.56%] [G loss: 0.763962]\n",
      "epoch:19 step:18310 [D loss: 0.527703, acc.: 73.44%] [G loss: 0.826376]\n",
      "epoch:19 step:18311 [D loss: 0.435185, acc.: 79.69%] [G loss: 0.873175]\n",
      "epoch:19 step:18312 [D loss: 0.544402, acc.: 73.44%] [G loss: 0.782621]\n",
      "epoch:19 step:18313 [D loss: 0.603844, acc.: 65.62%] [G loss: 0.567572]\n",
      "epoch:19 step:18314 [D loss: 0.642353, acc.: 60.16%] [G loss: 0.515576]\n",
      "epoch:19 step:18315 [D loss: 0.612393, acc.: 64.84%] [G loss: 0.494511]\n",
      "epoch:19 step:18316 [D loss: 0.514662, acc.: 75.78%] [G loss: 0.636389]\n",
      "epoch:19 step:18317 [D loss: 0.478835, acc.: 77.34%] [G loss: 0.593683]\n",
      "epoch:19 step:18318 [D loss: 0.537229, acc.: 72.66%] [G loss: 0.774451]\n",
      "epoch:19 step:18319 [D loss: 0.450642, acc.: 79.69%] [G loss: 0.864650]\n",
      "epoch:19 step:18320 [D loss: 0.448721, acc.: 79.69%] [G loss: 0.710281]\n",
      "epoch:19 step:18321 [D loss: 0.588515, acc.: 65.62%] [G loss: 0.767943]\n",
      "epoch:19 step:18322 [D loss: 0.507981, acc.: 75.00%] [G loss: 0.879474]\n",
      "epoch:19 step:18323 [D loss: 0.501232, acc.: 74.22%] [G loss: 0.937154]\n",
      "epoch:19 step:18324 [D loss: 0.567201, acc.: 63.28%] [G loss: 0.789571]\n",
      "epoch:19 step:18325 [D loss: 0.516827, acc.: 74.22%] [G loss: 0.821259]\n",
      "epoch:19 step:18326 [D loss: 0.480762, acc.: 72.66%] [G loss: 0.693861]\n",
      "epoch:19 step:18327 [D loss: 0.605350, acc.: 60.16%] [G loss: 0.647566]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:19 step:18328 [D loss: 0.571095, acc.: 68.75%] [G loss: 0.777969]\n",
      "epoch:19 step:18329 [D loss: 0.559826, acc.: 65.62%] [G loss: 0.481627]\n",
      "epoch:19 step:18330 [D loss: 0.535952, acc.: 67.97%] [G loss: 0.781807]\n",
      "epoch:19 step:18331 [D loss: 0.665913, acc.: 54.69%] [G loss: 0.659916]\n",
      "epoch:19 step:18332 [D loss: 0.602374, acc.: 63.28%] [G loss: 0.456895]\n",
      "epoch:19 step:18333 [D loss: 0.546406, acc.: 71.88%] [G loss: 0.841266]\n",
      "epoch:19 step:18334 [D loss: 0.538490, acc.: 72.66%] [G loss: 0.715444]\n",
      "epoch:19 step:18335 [D loss: 0.542702, acc.: 70.31%] [G loss: 0.664349]\n",
      "epoch:19 step:18336 [D loss: 0.555363, acc.: 68.75%] [G loss: 0.732967]\n",
      "epoch:19 step:18337 [D loss: 0.520994, acc.: 74.22%] [G loss: 0.758337]\n",
      "epoch:19 step:18338 [D loss: 0.588759, acc.: 67.19%] [G loss: 0.572121]\n",
      "epoch:19 step:18339 [D loss: 0.514262, acc.: 75.00%] [G loss: 0.489252]\n",
      "epoch:19 step:18340 [D loss: 0.592070, acc.: 70.31%] [G loss: 0.568669]\n",
      "epoch:19 step:18341 [D loss: 0.559965, acc.: 67.97%] [G loss: 0.459500]\n",
      "epoch:19 step:18342 [D loss: 0.527040, acc.: 74.22%] [G loss: 0.668700]\n",
      "epoch:19 step:18343 [D loss: 0.536354, acc.: 67.19%] [G loss: 0.695220]\n",
      "epoch:19 step:18344 [D loss: 0.511137, acc.: 69.53%] [G loss: 0.656790]\n",
      "epoch:19 step:18345 [D loss: 0.600460, acc.: 67.19%] [G loss: 0.570042]\n",
      "epoch:19 step:18346 [D loss: 0.566443, acc.: 67.97%] [G loss: 0.503263]\n",
      "epoch:19 step:18347 [D loss: 0.511540, acc.: 72.66%] [G loss: 0.645021]\n",
      "epoch:19 step:18348 [D loss: 0.527312, acc.: 73.44%] [G loss: 0.680111]\n",
      "epoch:19 step:18349 [D loss: 0.505709, acc.: 71.09%] [G loss: 0.714326]\n",
      "epoch:19 step:18350 [D loss: 0.546572, acc.: 72.66%] [G loss: 0.577103]\n",
      "epoch:19 step:18351 [D loss: 0.515804, acc.: 70.31%] [G loss: 0.692906]\n",
      "epoch:19 step:18352 [D loss: 0.547966, acc.: 70.31%] [G loss: 0.744903]\n",
      "epoch:19 step:18353 [D loss: 0.542296, acc.: 71.09%] [G loss: 0.631540]\n",
      "epoch:19 step:18354 [D loss: 0.493668, acc.: 75.78%] [G loss: 0.600353]\n",
      "epoch:19 step:18355 [D loss: 0.460547, acc.: 78.12%] [G loss: 0.670859]\n",
      "epoch:19 step:18356 [D loss: 0.565136, acc.: 71.88%] [G loss: 0.586569]\n",
      "epoch:19 step:18357 [D loss: 0.490096, acc.: 72.66%] [G loss: 0.612671]\n",
      "epoch:19 step:18358 [D loss: 0.470952, acc.: 74.22%] [G loss: 0.668972]\n",
      "epoch:19 step:18359 [D loss: 0.551152, acc.: 71.88%] [G loss: 0.675180]\n",
      "epoch:19 step:18360 [D loss: 0.496653, acc.: 76.56%] [G loss: 0.707678]\n",
      "epoch:19 step:18361 [D loss: 0.475940, acc.: 76.56%] [G loss: 0.795622]\n",
      "epoch:19 step:18362 [D loss: 0.579263, acc.: 66.41%] [G loss: 0.654528]\n",
      "epoch:19 step:18363 [D loss: 0.542813, acc.: 69.53%] [G loss: 0.619364]\n",
      "epoch:19 step:18364 [D loss: 0.587286, acc.: 61.72%] [G loss: 0.591648]\n",
      "epoch:19 step:18365 [D loss: 0.539640, acc.: 75.78%] [G loss: 0.668740]\n",
      "epoch:19 step:18366 [D loss: 0.547708, acc.: 67.97%] [G loss: 0.674749]\n",
      "epoch:19 step:18367 [D loss: 0.513762, acc.: 75.00%] [G loss: 0.722479]\n",
      "epoch:19 step:18368 [D loss: 0.579875, acc.: 67.97%] [G loss: 0.557852]\n",
      "epoch:19 step:18369 [D loss: 0.749912, acc.: 59.38%] [G loss: 0.535388]\n",
      "epoch:19 step:18370 [D loss: 0.537464, acc.: 71.88%] [G loss: 0.590243]\n",
      "epoch:19 step:18371 [D loss: 0.496170, acc.: 75.00%] [G loss: 0.838375]\n",
      "epoch:19 step:18372 [D loss: 0.564556, acc.: 67.19%] [G loss: 0.602055]\n",
      "epoch:19 step:18373 [D loss: 0.532463, acc.: 73.44%] [G loss: 0.563749]\n",
      "epoch:19 step:18374 [D loss: 0.546988, acc.: 70.31%] [G loss: 0.557251]\n",
      "epoch:19 step:18375 [D loss: 0.518166, acc.: 73.44%] [G loss: 0.632326]\n",
      "epoch:19 step:18376 [D loss: 0.545249, acc.: 70.31%] [G loss: 0.635431]\n",
      "epoch:19 step:18377 [D loss: 0.451541, acc.: 78.12%] [G loss: 0.680912]\n",
      "epoch:19 step:18378 [D loss: 0.467687, acc.: 74.22%] [G loss: 0.796645]\n",
      "epoch:19 step:18379 [D loss: 0.665869, acc.: 64.06%] [G loss: 0.596764]\n",
      "epoch:19 step:18380 [D loss: 0.583936, acc.: 65.62%] [G loss: 0.618811]\n",
      "epoch:19 step:18381 [D loss: 0.587695, acc.: 66.41%] [G loss: 0.618881]\n",
      "epoch:19 step:18382 [D loss: 0.548615, acc.: 69.53%] [G loss: 0.742769]\n",
      "epoch:19 step:18383 [D loss: 0.522956, acc.: 73.44%] [G loss: 0.703379]\n",
      "epoch:19 step:18384 [D loss: 0.575350, acc.: 67.97%] [G loss: 0.642780]\n",
      "epoch:19 step:18385 [D loss: 0.419546, acc.: 85.94%] [G loss: 0.694946]\n",
      "epoch:19 step:18386 [D loss: 0.557933, acc.: 67.97%] [G loss: 0.744430]\n",
      "epoch:19 step:18387 [D loss: 0.636785, acc.: 64.06%] [G loss: 0.521241]\n",
      "epoch:19 step:18388 [D loss: 0.558613, acc.: 71.09%] [G loss: 0.575432]\n",
      "epoch:19 step:18389 [D loss: 0.567591, acc.: 64.84%] [G loss: 0.598495]\n",
      "epoch:19 step:18390 [D loss: 0.575064, acc.: 67.19%] [G loss: 0.548200]\n",
      "epoch:19 step:18391 [D loss: 0.567788, acc.: 71.09%] [G loss: 0.698812]\n",
      "epoch:19 step:18392 [D loss: 0.540638, acc.: 70.31%] [G loss: 0.772246]\n",
      "epoch:19 step:18393 [D loss: 0.599741, acc.: 65.62%] [G loss: 0.506862]\n",
      "epoch:19 step:18394 [D loss: 0.610213, acc.: 65.62%] [G loss: 0.514769]\n",
      "epoch:19 step:18395 [D loss: 0.491973, acc.: 74.22%] [G loss: 0.529228]\n",
      "epoch:19 step:18396 [D loss: 0.485691, acc.: 77.34%] [G loss: 0.628565]\n",
      "epoch:19 step:18397 [D loss: 0.573368, acc.: 69.53%] [G loss: 0.650031]\n",
      "epoch:19 step:18398 [D loss: 0.541341, acc.: 72.66%] [G loss: 0.633347]\n",
      "epoch:19 step:18399 [D loss: 0.500015, acc.: 72.66%] [G loss: 0.645333]\n",
      "epoch:19 step:18400 [D loss: 0.558091, acc.: 70.31%] [G loss: 0.634274]\n",
      "##############\n",
      "[2.73893406 0.38534967 5.97145784 4.78674504 3.64283862 5.75338428\n",
      " 4.47243708 4.8343978  4.62207113 4.10824864]\n",
      "##########\n",
      "epoch:19 step:18401 [D loss: 0.508176, acc.: 71.09%] [G loss: 0.642039]\n",
      "epoch:19 step:18402 [D loss: 0.488821, acc.: 78.12%] [G loss: 0.643262]\n",
      "epoch:19 step:18403 [D loss: 0.583856, acc.: 70.31%] [G loss: 0.712190]\n",
      "epoch:19 step:18404 [D loss: 0.538362, acc.: 71.88%] [G loss: 0.669365]\n",
      "epoch:19 step:18405 [D loss: 0.514619, acc.: 69.53%] [G loss: 0.549505]\n",
      "epoch:19 step:18406 [D loss: 0.481381, acc.: 75.78%] [G loss: 0.851255]\n",
      "epoch:19 step:18407 [D loss: 0.604404, acc.: 60.16%] [G loss: 0.618291]\n",
      "epoch:19 step:18408 [D loss: 0.492473, acc.: 76.56%] [G loss: 0.742455]\n",
      "epoch:19 step:18409 [D loss: 0.608883, acc.: 64.84%] [G loss: 0.693518]\n",
      "epoch:19 step:18410 [D loss: 0.523371, acc.: 71.88%] [G loss: 0.584313]\n",
      "epoch:19 step:18411 [D loss: 0.548256, acc.: 71.88%] [G loss: 0.568653]\n",
      "epoch:19 step:18412 [D loss: 0.620304, acc.: 64.84%] [G loss: 0.525836]\n",
      "epoch:19 step:18413 [D loss: 0.558361, acc.: 71.88%] [G loss: 0.468585]\n",
      "epoch:19 step:18414 [D loss: 0.510757, acc.: 75.00%] [G loss: 0.447249]\n",
      "epoch:19 step:18415 [D loss: 0.531653, acc.: 71.09%] [G loss: 0.637978]\n",
      "epoch:19 step:18416 [D loss: 0.489950, acc.: 73.44%] [G loss: 0.567202]\n",
      "epoch:19 step:18417 [D loss: 0.585147, acc.: 66.41%] [G loss: 0.568829]\n",
      "epoch:19 step:18418 [D loss: 0.596725, acc.: 65.62%] [G loss: 0.680950]\n",
      "epoch:19 step:18419 [D loss: 0.573143, acc.: 64.06%] [G loss: 0.646882]\n",
      "epoch:19 step:18420 [D loss: 0.585565, acc.: 71.09%] [G loss: 0.735857]\n",
      "epoch:19 step:18421 [D loss: 0.556954, acc.: 67.97%] [G loss: 0.776674]\n",
      "epoch:19 step:18422 [D loss: 0.584513, acc.: 67.19%] [G loss: 0.695032]\n",
      "epoch:19 step:18423 [D loss: 0.554217, acc.: 67.19%] [G loss: 0.774411]\n",
      "epoch:19 step:18424 [D loss: 0.528590, acc.: 75.00%] [G loss: 0.652771]\n",
      "epoch:19 step:18425 [D loss: 0.577303, acc.: 74.22%] [G loss: 0.561736]\n",
      "epoch:19 step:18426 [D loss: 0.464923, acc.: 77.34%] [G loss: 0.791309]\n",
      "epoch:19 step:18427 [D loss: 0.474054, acc.: 75.78%] [G loss: 0.652976]\n",
      "epoch:19 step:18428 [D loss: 0.579569, acc.: 63.28%] [G loss: 0.666142]\n",
      "epoch:19 step:18429 [D loss: 0.565618, acc.: 67.19%] [G loss: 0.601258]\n",
      "epoch:19 step:18430 [D loss: 0.616566, acc.: 61.72%] [G loss: 0.668556]\n",
      "epoch:19 step:18431 [D loss: 0.555491, acc.: 71.09%] [G loss: 0.575111]\n",
      "epoch:19 step:18432 [D loss: 0.493916, acc.: 71.09%] [G loss: 0.629172]\n",
      "epoch:19 step:18433 [D loss: 0.534119, acc.: 72.66%] [G loss: 0.696680]\n",
      "epoch:19 step:18434 [D loss: 0.492432, acc.: 77.34%] [G loss: 0.704490]\n",
      "epoch:19 step:18435 [D loss: 0.499404, acc.: 78.91%] [G loss: 0.695047]\n",
      "epoch:19 step:18436 [D loss: 0.518260, acc.: 68.75%] [G loss: 0.736391]\n",
      "epoch:19 step:18437 [D loss: 0.463668, acc.: 81.25%] [G loss: 0.702995]\n",
      "epoch:19 step:18438 [D loss: 0.507718, acc.: 74.22%] [G loss: 0.886569]\n",
      "epoch:19 step:18439 [D loss: 0.590632, acc.: 67.19%] [G loss: 0.749276]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:19 step:18440 [D loss: 0.565857, acc.: 67.97%] [G loss: 0.495272]\n",
      "epoch:19 step:18441 [D loss: 0.498188, acc.: 75.00%] [G loss: 0.607008]\n",
      "epoch:19 step:18442 [D loss: 0.551697, acc.: 69.53%] [G loss: 0.520510]\n",
      "epoch:19 step:18443 [D loss: 0.598923, acc.: 64.06%] [G loss: 0.568565]\n",
      "epoch:19 step:18444 [D loss: 0.529122, acc.: 69.53%] [G loss: 0.581947]\n",
      "epoch:19 step:18445 [D loss: 0.467448, acc.: 78.12%] [G loss: 0.716171]\n",
      "epoch:19 step:18446 [D loss: 0.506787, acc.: 73.44%] [G loss: 0.692742]\n",
      "epoch:19 step:18447 [D loss: 0.565121, acc.: 67.97%] [G loss: 0.673547]\n",
      "epoch:19 step:18448 [D loss: 0.532300, acc.: 66.41%] [G loss: 0.613330]\n",
      "epoch:19 step:18449 [D loss: 0.568302, acc.: 67.19%] [G loss: 0.484901]\n",
      "epoch:19 step:18450 [D loss: 0.467325, acc.: 82.03%] [G loss: 0.696891]\n",
      "epoch:19 step:18451 [D loss: 0.373999, acc.: 89.06%] [G loss: 0.943600]\n",
      "epoch:19 step:18452 [D loss: 0.481253, acc.: 72.66%] [G loss: 0.942838]\n",
      "epoch:19 step:18453 [D loss: 0.486810, acc.: 75.78%] [G loss: 0.907531]\n",
      "epoch:19 step:18454 [D loss: 0.582013, acc.: 71.09%] [G loss: 0.756249]\n",
      "epoch:19 step:18455 [D loss: 0.649095, acc.: 59.38%] [G loss: 0.736688]\n",
      "epoch:19 step:18456 [D loss: 0.578102, acc.: 64.06%] [G loss: 0.509893]\n",
      "epoch:19 step:18457 [D loss: 0.456047, acc.: 81.25%] [G loss: 0.728616]\n",
      "epoch:19 step:18458 [D loss: 0.578101, acc.: 71.88%] [G loss: 0.515762]\n",
      "epoch:19 step:18459 [D loss: 0.545241, acc.: 73.44%] [G loss: 0.573692]\n",
      "epoch:19 step:18460 [D loss: 0.513265, acc.: 68.75%] [G loss: 0.636656]\n",
      "epoch:19 step:18461 [D loss: 0.538233, acc.: 67.97%] [G loss: 0.754930]\n",
      "epoch:19 step:18462 [D loss: 0.554072, acc.: 70.31%] [G loss: 0.675012]\n",
      "epoch:19 step:18463 [D loss: 0.537971, acc.: 72.66%] [G loss: 0.723055]\n",
      "epoch:19 step:18464 [D loss: 0.502700, acc.: 71.09%] [G loss: 0.576146]\n",
      "epoch:19 step:18465 [D loss: 0.491661, acc.: 72.66%] [G loss: 0.595657]\n",
      "epoch:19 step:18466 [D loss: 0.525225, acc.: 73.44%] [G loss: 0.608875]\n",
      "epoch:19 step:18467 [D loss: 0.572361, acc.: 69.53%] [G loss: 0.643061]\n",
      "epoch:19 step:18468 [D loss: 0.558387, acc.: 69.53%] [G loss: 0.601760]\n",
      "epoch:19 step:18469 [D loss: 0.455244, acc.: 77.34%] [G loss: 0.737229]\n",
      "epoch:19 step:18470 [D loss: 0.593535, acc.: 63.28%] [G loss: 0.667661]\n",
      "epoch:19 step:18471 [D loss: 0.542815, acc.: 71.09%] [G loss: 0.759474]\n",
      "epoch:19 step:18472 [D loss: 0.504280, acc.: 73.44%] [G loss: 0.755255]\n",
      "epoch:19 step:18473 [D loss: 0.557896, acc.: 67.19%] [G loss: 0.531749]\n",
      "epoch:19 step:18474 [D loss: 0.581623, acc.: 67.19%] [G loss: 0.661603]\n",
      "epoch:19 step:18475 [D loss: 0.530264, acc.: 71.88%] [G loss: 0.678736]\n",
      "epoch:19 step:18476 [D loss: 0.704902, acc.: 58.59%] [G loss: 0.734632]\n",
      "epoch:19 step:18477 [D loss: 0.561433, acc.: 66.41%] [G loss: 0.667852]\n",
      "epoch:19 step:18478 [D loss: 0.601424, acc.: 69.53%] [G loss: 0.588852]\n",
      "epoch:19 step:18479 [D loss: 0.499107, acc.: 74.22%] [G loss: 0.727288]\n",
      "epoch:19 step:18480 [D loss: 0.496466, acc.: 73.44%] [G loss: 0.767856]\n",
      "epoch:19 step:18481 [D loss: 0.602560, acc.: 62.50%] [G loss: 0.689632]\n",
      "epoch:19 step:18482 [D loss: 0.499448, acc.: 71.88%] [G loss: 0.689064]\n",
      "epoch:19 step:18483 [D loss: 0.519003, acc.: 75.00%] [G loss: 0.782065]\n",
      "epoch:19 step:18484 [D loss: 0.466033, acc.: 78.12%] [G loss: 0.708097]\n",
      "epoch:19 step:18485 [D loss: 0.601384, acc.: 66.41%] [G loss: 0.394771]\n",
      "epoch:19 step:18486 [D loss: 0.535708, acc.: 69.53%] [G loss: 0.648168]\n",
      "epoch:19 step:18487 [D loss: 0.565666, acc.: 69.53%] [G loss: 0.603228]\n",
      "epoch:19 step:18488 [D loss: 0.536161, acc.: 68.75%] [G loss: 0.584720]\n",
      "epoch:19 step:18489 [D loss: 0.591673, acc.: 66.41%] [G loss: 0.501046]\n",
      "epoch:19 step:18490 [D loss: 0.559281, acc.: 70.31%] [G loss: 0.469022]\n",
      "epoch:19 step:18491 [D loss: 0.535087, acc.: 72.66%] [G loss: 0.452959]\n",
      "epoch:19 step:18492 [D loss: 0.507367, acc.: 75.78%] [G loss: 0.497290]\n",
      "epoch:19 step:18493 [D loss: 0.507463, acc.: 74.22%] [G loss: 0.811798]\n",
      "epoch:19 step:18494 [D loss: 0.500304, acc.: 73.44%] [G loss: 0.710119]\n",
      "epoch:19 step:18495 [D loss: 0.584408, acc.: 66.41%] [G loss: 0.556082]\n",
      "epoch:19 step:18496 [D loss: 0.497056, acc.: 74.22%] [G loss: 0.731288]\n",
      "epoch:19 step:18497 [D loss: 0.485318, acc.: 75.78%] [G loss: 0.789723]\n",
      "epoch:19 step:18498 [D loss: 0.468774, acc.: 75.78%] [G loss: 0.718618]\n",
      "epoch:19 step:18499 [D loss: 0.676079, acc.: 53.91%] [G loss: 0.517357]\n",
      "epoch:19 step:18500 [D loss: 0.550729, acc.: 68.75%] [G loss: 0.582514]\n",
      "epoch:19 step:18501 [D loss: 0.544266, acc.: 71.09%] [G loss: 0.442893]\n",
      "epoch:19 step:18502 [D loss: 0.517933, acc.: 73.44%] [G loss: 0.602190]\n",
      "epoch:19 step:18503 [D loss: 0.513644, acc.: 74.22%] [G loss: 0.614151]\n",
      "epoch:19 step:18504 [D loss: 0.523722, acc.: 71.09%] [G loss: 0.716738]\n",
      "epoch:19 step:18505 [D loss: 0.554431, acc.: 70.31%] [G loss: 0.610113]\n",
      "epoch:19 step:18506 [D loss: 0.596374, acc.: 68.75%] [G loss: 0.503945]\n",
      "epoch:19 step:18507 [D loss: 0.564752, acc.: 67.97%] [G loss: 0.483660]\n",
      "epoch:19 step:18508 [D loss: 0.520837, acc.: 72.66%] [G loss: 0.840675]\n",
      "epoch:19 step:18509 [D loss: 0.506011, acc.: 75.78%] [G loss: 0.687820]\n",
      "epoch:19 step:18510 [D loss: 0.472723, acc.: 77.34%] [G loss: 0.891061]\n",
      "epoch:19 step:18511 [D loss: 0.505618, acc.: 73.44%] [G loss: 0.803515]\n",
      "epoch:19 step:18512 [D loss: 0.516282, acc.: 68.75%] [G loss: 0.806170]\n",
      "epoch:19 step:18513 [D loss: 0.577529, acc.: 67.97%] [G loss: 0.559658]\n",
      "epoch:19 step:18514 [D loss: 0.565403, acc.: 67.19%] [G loss: 0.659613]\n",
      "epoch:19 step:18515 [D loss: 0.518411, acc.: 70.31%] [G loss: 0.723737]\n",
      "epoch:19 step:18516 [D loss: 0.550167, acc.: 67.19%] [G loss: 0.624106]\n",
      "epoch:19 step:18517 [D loss: 0.547811, acc.: 71.09%] [G loss: 0.678874]\n",
      "epoch:19 step:18518 [D loss: 0.510083, acc.: 77.34%] [G loss: 0.520768]\n",
      "epoch:19 step:18519 [D loss: 0.582169, acc.: 66.41%] [G loss: 0.531113]\n",
      "epoch:19 step:18520 [D loss: 0.552667, acc.: 72.66%] [G loss: 0.459474]\n",
      "epoch:19 step:18521 [D loss: 0.563152, acc.: 64.06%] [G loss: 0.492648]\n",
      "epoch:19 step:18522 [D loss: 0.488799, acc.: 76.56%] [G loss: 0.764697]\n",
      "epoch:19 step:18523 [D loss: 0.554421, acc.: 66.41%] [G loss: 0.687313]\n",
      "epoch:19 step:18524 [D loss: 0.605452, acc.: 64.06%] [G loss: 0.614070]\n",
      "epoch:19 step:18525 [D loss: 0.544971, acc.: 68.75%] [G loss: 0.803281]\n",
      "epoch:19 step:18526 [D loss: 0.629979, acc.: 63.28%] [G loss: 0.614431]\n",
      "epoch:19 step:18527 [D loss: 0.468498, acc.: 76.56%] [G loss: 0.644812]\n",
      "epoch:19 step:18528 [D loss: 0.475046, acc.: 82.81%] [G loss: 0.620109]\n",
      "epoch:19 step:18529 [D loss: 0.559281, acc.: 69.53%] [G loss: 0.708709]\n",
      "epoch:19 step:18530 [D loss: 0.566875, acc.: 70.31%] [G loss: 0.638478]\n",
      "epoch:19 step:18531 [D loss: 0.557792, acc.: 70.31%] [G loss: 0.533048]\n",
      "epoch:19 step:18532 [D loss: 0.599720, acc.: 63.28%] [G loss: 0.619815]\n",
      "epoch:19 step:18533 [D loss: 0.543463, acc.: 71.09%] [G loss: 0.521131]\n",
      "epoch:19 step:18534 [D loss: 0.582883, acc.: 64.84%] [G loss: 0.668293]\n",
      "epoch:19 step:18535 [D loss: 0.586249, acc.: 65.62%] [G loss: 0.703958]\n",
      "epoch:19 step:18536 [D loss: 0.526008, acc.: 75.78%] [G loss: 0.583796]\n",
      "epoch:19 step:18537 [D loss: 0.569121, acc.: 67.19%] [G loss: 0.612829]\n",
      "epoch:19 step:18538 [D loss: 0.545864, acc.: 65.62%] [G loss: 0.602894]\n",
      "epoch:19 step:18539 [D loss: 0.487423, acc.: 73.44%] [G loss: 0.660114]\n",
      "epoch:19 step:18540 [D loss: 0.525983, acc.: 71.09%] [G loss: 0.653613]\n",
      "epoch:19 step:18541 [D loss: 0.571806, acc.: 71.09%] [G loss: 0.662017]\n",
      "epoch:19 step:18542 [D loss: 0.564971, acc.: 68.75%] [G loss: 0.539904]\n",
      "epoch:19 step:18543 [D loss: 0.639317, acc.: 59.38%] [G loss: 0.469665]\n",
      "epoch:19 step:18544 [D loss: 0.544246, acc.: 67.19%] [G loss: 0.555964]\n",
      "epoch:19 step:18545 [D loss: 0.538854, acc.: 70.31%] [G loss: 0.720108]\n",
      "epoch:19 step:18546 [D loss: 0.545119, acc.: 71.09%] [G loss: 0.618562]\n",
      "epoch:19 step:18547 [D loss: 0.500526, acc.: 78.12%] [G loss: 0.829141]\n",
      "epoch:19 step:18548 [D loss: 0.613475, acc.: 64.84%] [G loss: 0.581618]\n",
      "epoch:19 step:18549 [D loss: 0.466871, acc.: 78.12%] [G loss: 0.828873]\n",
      "epoch:19 step:18550 [D loss: 0.411884, acc.: 80.47%] [G loss: 0.762143]\n",
      "epoch:19 step:18551 [D loss: 0.585601, acc.: 66.41%] [G loss: 0.645616]\n",
      "epoch:19 step:18552 [D loss: 0.539555, acc.: 71.88%] [G loss: 0.615010]\n",
      "epoch:19 step:18553 [D loss: 0.482272, acc.: 73.44%] [G loss: 0.751537]\n",
      "epoch:19 step:18554 [D loss: 0.557927, acc.: 69.53%] [G loss: 0.782747]\n",
      "epoch:19 step:18555 [D loss: 0.610288, acc.: 63.28%] [G loss: 0.662938]\n",
      "epoch:19 step:18556 [D loss: 0.502494, acc.: 76.56%] [G loss: 0.745922]\n",
      "epoch:19 step:18557 [D loss: 0.533054, acc.: 67.97%] [G loss: 0.640658]\n",
      "epoch:19 step:18558 [D loss: 0.548184, acc.: 67.97%] [G loss: 0.597720]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:19 step:18559 [D loss: 0.544462, acc.: 75.00%] [G loss: 0.649576]\n",
      "epoch:19 step:18560 [D loss: 0.598860, acc.: 61.72%] [G loss: 0.722594]\n",
      "epoch:19 step:18561 [D loss: 0.499324, acc.: 74.22%] [G loss: 0.632154]\n",
      "epoch:19 step:18562 [D loss: 0.510664, acc.: 73.44%] [G loss: 0.589377]\n",
      "epoch:19 step:18563 [D loss: 0.532606, acc.: 69.53%] [G loss: 0.743652]\n",
      "epoch:19 step:18564 [D loss: 0.528244, acc.: 75.00%] [G loss: 0.566778]\n",
      "epoch:19 step:18565 [D loss: 0.594997, acc.: 64.84%] [G loss: 0.513207]\n",
      "epoch:19 step:18566 [D loss: 0.573136, acc.: 67.19%] [G loss: 0.576503]\n",
      "epoch:19 step:18567 [D loss: 0.548168, acc.: 69.53%] [G loss: 0.639627]\n",
      "epoch:19 step:18568 [D loss: 0.592210, acc.: 67.97%] [G loss: 0.690899]\n",
      "epoch:19 step:18569 [D loss: 0.619196, acc.: 62.50%] [G loss: 0.568758]\n",
      "epoch:19 step:18570 [D loss: 0.572761, acc.: 67.19%] [G loss: 0.623263]\n",
      "epoch:19 step:18571 [D loss: 0.565516, acc.: 67.97%] [G loss: 0.672600]\n",
      "epoch:19 step:18572 [D loss: 0.502156, acc.: 78.91%] [G loss: 1.017943]\n",
      "epoch:19 step:18573 [D loss: 0.518190, acc.: 73.44%] [G loss: 0.807655]\n",
      "epoch:19 step:18574 [D loss: 0.552248, acc.: 70.31%] [G loss: 0.916553]\n",
      "epoch:19 step:18575 [D loss: 0.568534, acc.: 68.75%] [G loss: 0.654231]\n",
      "epoch:19 step:18576 [D loss: 0.563571, acc.: 68.75%] [G loss: 0.674852]\n",
      "epoch:19 step:18577 [D loss: 0.571763, acc.: 71.88%] [G loss: 0.632546]\n",
      "epoch:19 step:18578 [D loss: 0.494269, acc.: 74.22%] [G loss: 0.720232]\n",
      "epoch:19 step:18579 [D loss: 0.576607, acc.: 67.19%] [G loss: 0.739129]\n",
      "epoch:19 step:18580 [D loss: 0.531998, acc.: 71.88%] [G loss: 0.565395]\n",
      "epoch:19 step:18581 [D loss: 0.568925, acc.: 68.75%] [G loss: 0.476721]\n",
      "epoch:19 step:18582 [D loss: 0.566332, acc.: 65.62%] [G loss: 0.635717]\n",
      "epoch:19 step:18583 [D loss: 0.566093, acc.: 68.75%] [G loss: 0.777806]\n",
      "epoch:19 step:18584 [D loss: 0.533070, acc.: 75.78%] [G loss: 0.640853]\n",
      "epoch:19 step:18585 [D loss: 0.528986, acc.: 76.56%] [G loss: 0.859010]\n",
      "epoch:19 step:18586 [D loss: 0.565156, acc.: 67.97%] [G loss: 0.690869]\n",
      "epoch:19 step:18587 [D loss: 0.650904, acc.: 62.50%] [G loss: 0.646917]\n",
      "epoch:19 step:18588 [D loss: 0.540454, acc.: 64.84%] [G loss: 0.696459]\n",
      "epoch:19 step:18589 [D loss: 0.498753, acc.: 75.78%] [G loss: 0.672298]\n",
      "epoch:19 step:18590 [D loss: 0.549161, acc.: 67.19%] [G loss: 0.672961]\n",
      "epoch:19 step:18591 [D loss: 0.647761, acc.: 62.50%] [G loss: 0.499960]\n",
      "epoch:19 step:18592 [D loss: 0.542119, acc.: 73.44%] [G loss: 0.559235]\n",
      "epoch:19 step:18593 [D loss: 0.503752, acc.: 75.00%] [G loss: 0.566599]\n",
      "epoch:19 step:18594 [D loss: 0.534360, acc.: 72.66%] [G loss: 0.537012]\n",
      "epoch:19 step:18595 [D loss: 0.471478, acc.: 75.00%] [G loss: 0.595740]\n",
      "epoch:19 step:18596 [D loss: 0.603288, acc.: 64.84%] [G loss: 0.600465]\n",
      "epoch:19 step:18597 [D loss: 0.610660, acc.: 64.06%] [G loss: 0.584587]\n",
      "epoch:19 step:18598 [D loss: 0.619776, acc.: 57.03%] [G loss: 0.667606]\n",
      "epoch:19 step:18599 [D loss: 0.536090, acc.: 75.00%] [G loss: 0.931594]\n",
      "epoch:19 step:18600 [D loss: 0.528268, acc.: 72.66%] [G loss: 0.685650]\n",
      "##############\n",
      "[3.21989916 0.88360156 6.25351527 5.03238033 3.77036864 5.65688624\n",
      " 4.66609889 4.8015757  4.61404575 4.12633535]\n",
      "##########\n",
      "epoch:19 step:18601 [D loss: 0.531921, acc.: 68.75%] [G loss: 0.784040]\n",
      "epoch:19 step:18602 [D loss: 0.575341, acc.: 70.31%] [G loss: 0.722879]\n",
      "epoch:19 step:18603 [D loss: 0.590462, acc.: 64.06%] [G loss: 0.670545]\n",
      "epoch:19 step:18604 [D loss: 0.517922, acc.: 74.22%] [G loss: 0.667046]\n",
      "epoch:19 step:18605 [D loss: 0.505568, acc.: 70.31%] [G loss: 0.743015]\n",
      "epoch:19 step:18606 [D loss: 0.481312, acc.: 75.78%] [G loss: 0.859586]\n",
      "epoch:19 step:18607 [D loss: 0.557620, acc.: 67.97%] [G loss: 0.644552]\n",
      "epoch:19 step:18608 [D loss: 0.554764, acc.: 67.19%] [G loss: 0.489274]\n",
      "epoch:19 step:18609 [D loss: 0.528952, acc.: 70.31%] [G loss: 0.447570]\n",
      "epoch:19 step:18610 [D loss: 0.518882, acc.: 71.88%] [G loss: 0.718981]\n",
      "epoch:19 step:18611 [D loss: 0.591793, acc.: 68.75%] [G loss: 0.525324]\n",
      "epoch:19 step:18612 [D loss: 0.529718, acc.: 71.88%] [G loss: 0.670214]\n",
      "epoch:19 step:18613 [D loss: 0.550908, acc.: 73.44%] [G loss: 0.579507]\n",
      "epoch:19 step:18614 [D loss: 0.524246, acc.: 75.00%] [G loss: 0.617535]\n",
      "epoch:19 step:18615 [D loss: 0.646394, acc.: 56.25%] [G loss: 0.554788]\n",
      "epoch:19 step:18616 [D loss: 0.545417, acc.: 71.09%] [G loss: 0.640429]\n",
      "epoch:19 step:18617 [D loss: 0.476484, acc.: 76.56%] [G loss: 0.607621]\n",
      "epoch:19 step:18618 [D loss: 0.489114, acc.: 77.34%] [G loss: 0.691646]\n",
      "epoch:19 step:18619 [D loss: 0.543477, acc.: 69.53%] [G loss: 0.722316]\n",
      "epoch:19 step:18620 [D loss: 0.605731, acc.: 67.97%] [G loss: 0.693981]\n",
      "epoch:19 step:18621 [D loss: 0.605480, acc.: 65.62%] [G loss: 0.730094]\n",
      "epoch:19 step:18622 [D loss: 0.516649, acc.: 71.88%] [G loss: 0.668683]\n",
      "epoch:19 step:18623 [D loss: 0.705712, acc.: 60.16%] [G loss: 0.578957]\n",
      "epoch:19 step:18624 [D loss: 0.540089, acc.: 69.53%] [G loss: 0.567279]\n",
      "epoch:19 step:18625 [D loss: 0.577047, acc.: 70.31%] [G loss: 0.578947]\n",
      "epoch:19 step:18626 [D loss: 0.437301, acc.: 79.69%] [G loss: 0.760304]\n",
      "epoch:19 step:18627 [D loss: 0.560845, acc.: 70.31%] [G loss: 0.525269]\n",
      "epoch:19 step:18628 [D loss: 0.563640, acc.: 65.62%] [G loss: 0.612406]\n",
      "epoch:19 step:18629 [D loss: 0.531950, acc.: 69.53%] [G loss: 0.621135]\n",
      "epoch:19 step:18630 [D loss: 0.566568, acc.: 65.62%] [G loss: 0.662006]\n",
      "epoch:19 step:18631 [D loss: 0.631494, acc.: 64.84%] [G loss: 0.704793]\n",
      "epoch:19 step:18632 [D loss: 0.516903, acc.: 69.53%] [G loss: 0.746867]\n",
      "epoch:19 step:18633 [D loss: 0.564153, acc.: 71.09%] [G loss: 0.557597]\n",
      "epoch:19 step:18634 [D loss: 0.512069, acc.: 73.44%] [G loss: 0.671027]\n",
      "epoch:19 step:18635 [D loss: 0.521229, acc.: 74.22%] [G loss: 0.636990]\n",
      "epoch:19 step:18636 [D loss: 0.546127, acc.: 70.31%] [G loss: 0.540200]\n",
      "epoch:19 step:18637 [D loss: 0.505201, acc.: 73.44%] [G loss: 0.567727]\n",
      "epoch:19 step:18638 [D loss: 0.585253, acc.: 68.75%] [G loss: 0.363265]\n",
      "epoch:19 step:18639 [D loss: 0.545672, acc.: 63.28%] [G loss: 0.608787]\n",
      "epoch:19 step:18640 [D loss: 0.531749, acc.: 69.53%] [G loss: 0.532325]\n",
      "epoch:19 step:18641 [D loss: 0.541914, acc.: 70.31%] [G loss: 0.643968]\n",
      "epoch:19 step:18642 [D loss: 0.604601, acc.: 66.41%] [G loss: 0.478174]\n",
      "epoch:19 step:18643 [D loss: 0.588942, acc.: 69.53%] [G loss: 0.576716]\n",
      "epoch:19 step:18644 [D loss: 0.529925, acc.: 69.53%] [G loss: 0.521593]\n",
      "epoch:19 step:18645 [D loss: 0.488945, acc.: 79.69%] [G loss: 0.554345]\n",
      "epoch:19 step:18646 [D loss: 0.507709, acc.: 75.78%] [G loss: 0.628039]\n",
      "epoch:19 step:18647 [D loss: 0.568788, acc.: 67.19%] [G loss: 0.540494]\n",
      "epoch:19 step:18648 [D loss: 0.516608, acc.: 75.78%] [G loss: 0.641836]\n",
      "epoch:19 step:18649 [D loss: 0.558835, acc.: 69.53%] [G loss: 0.438971]\n",
      "epoch:19 step:18650 [D loss: 0.649260, acc.: 60.94%] [G loss: 0.361987]\n",
      "epoch:19 step:18651 [D loss: 0.554849, acc.: 67.97%] [G loss: 0.513784]\n",
      "epoch:19 step:18652 [D loss: 0.558673, acc.: 71.09%] [G loss: 0.657880]\n",
      "epoch:19 step:18653 [D loss: 0.554812, acc.: 67.19%] [G loss: 0.509337]\n",
      "epoch:19 step:18654 [D loss: 0.553189, acc.: 67.97%] [G loss: 0.547245]\n",
      "epoch:19 step:18655 [D loss: 0.561073, acc.: 74.22%] [G loss: 0.540341]\n",
      "epoch:19 step:18656 [D loss: 0.547588, acc.: 68.75%] [G loss: 0.569725]\n",
      "epoch:19 step:18657 [D loss: 0.541602, acc.: 67.97%] [G loss: 0.699968]\n",
      "epoch:19 step:18658 [D loss: 0.586561, acc.: 67.97%] [G loss: 0.501399]\n",
      "epoch:19 step:18659 [D loss: 0.618045, acc.: 62.50%] [G loss: 0.606968]\n",
      "epoch:19 step:18660 [D loss: 0.472916, acc.: 76.56%] [G loss: 0.647620]\n",
      "epoch:19 step:18661 [D loss: 0.623851, acc.: 64.84%] [G loss: 0.540780]\n",
      "epoch:19 step:18662 [D loss: 0.582045, acc.: 66.41%] [G loss: 0.572811]\n",
      "epoch:19 step:18663 [D loss: 0.446952, acc.: 79.69%] [G loss: 0.687261]\n",
      "epoch:19 step:18664 [D loss: 0.646530, acc.: 65.62%] [G loss: 0.613040]\n",
      "epoch:19 step:18665 [D loss: 0.579786, acc.: 65.62%] [G loss: 0.519767]\n",
      "epoch:19 step:18666 [D loss: 0.547863, acc.: 71.09%] [G loss: 0.520892]\n",
      "epoch:19 step:18667 [D loss: 0.550771, acc.: 66.41%] [G loss: 0.575224]\n",
      "epoch:19 step:18668 [D loss: 0.583968, acc.: 64.06%] [G loss: 0.535336]\n",
      "epoch:19 step:18669 [D loss: 0.536225, acc.: 68.75%] [G loss: 0.627115]\n",
      "epoch:19 step:18670 [D loss: 0.673827, acc.: 58.59%] [G loss: 0.518292]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:19 step:18671 [D loss: 0.532912, acc.: 71.09%] [G loss: 0.474147]\n",
      "epoch:19 step:18672 [D loss: 0.545756, acc.: 65.62%] [G loss: 0.731074]\n",
      "epoch:19 step:18673 [D loss: 0.437381, acc.: 78.91%] [G loss: 0.678275]\n",
      "epoch:19 step:18674 [D loss: 0.473041, acc.: 75.00%] [G loss: 0.849866]\n",
      "epoch:19 step:18675 [D loss: 0.527693, acc.: 75.00%] [G loss: 0.766705]\n",
      "epoch:19 step:18676 [D loss: 0.677375, acc.: 67.19%] [G loss: 0.798145]\n",
      "epoch:19 step:18677 [D loss: 0.526875, acc.: 67.97%] [G loss: 0.647724]\n",
      "epoch:19 step:18678 [D loss: 0.546778, acc.: 74.22%] [G loss: 0.741053]\n",
      "epoch:19 step:18679 [D loss: 0.559349, acc.: 67.97%] [G loss: 0.637396]\n",
      "epoch:19 step:18680 [D loss: 0.649852, acc.: 60.16%] [G loss: 0.486642]\n",
      "epoch:19 step:18681 [D loss: 0.547153, acc.: 72.66%] [G loss: 0.622368]\n",
      "epoch:19 step:18682 [D loss: 0.541153, acc.: 68.75%] [G loss: 0.444246]\n",
      "epoch:19 step:18683 [D loss: 0.635993, acc.: 62.50%] [G loss: 0.494240]\n",
      "epoch:19 step:18684 [D loss: 0.535348, acc.: 70.31%] [G loss: 0.397740]\n",
      "epoch:19 step:18685 [D loss: 0.600644, acc.: 61.72%] [G loss: 0.482612]\n",
      "epoch:19 step:18686 [D loss: 0.621243, acc.: 63.28%] [G loss: 0.468399]\n",
      "epoch:19 step:18687 [D loss: 0.504336, acc.: 73.44%] [G loss: 0.611961]\n",
      "epoch:19 step:18688 [D loss: 0.611192, acc.: 70.31%] [G loss: 0.892737]\n",
      "epoch:19 step:18689 [D loss: 0.534376, acc.: 72.66%] [G loss: 0.723708]\n",
      "epoch:19 step:18690 [D loss: 0.546692, acc.: 67.97%] [G loss: 0.586089]\n",
      "epoch:19 step:18691 [D loss: 0.523034, acc.: 71.09%] [G loss: 0.642572]\n",
      "epoch:19 step:18692 [D loss: 0.507211, acc.: 72.66%] [G loss: 0.622263]\n",
      "epoch:19 step:18693 [D loss: 0.519419, acc.: 72.66%] [G loss: 0.862057]\n",
      "epoch:19 step:18694 [D loss: 0.640515, acc.: 65.62%] [G loss: 0.553165]\n",
      "epoch:19 step:18695 [D loss: 0.675939, acc.: 57.81%] [G loss: 0.560290]\n",
      "epoch:19 step:18696 [D loss: 0.566903, acc.: 69.53%] [G loss: 0.682851]\n",
      "epoch:19 step:18697 [D loss: 0.492165, acc.: 73.44%] [G loss: 0.755813]\n",
      "epoch:19 step:18698 [D loss: 0.524499, acc.: 72.66%] [G loss: 0.798244]\n",
      "epoch:19 step:18699 [D loss: 0.485934, acc.: 76.56%] [G loss: 0.902354]\n",
      "epoch:19 step:18700 [D loss: 0.501060, acc.: 76.56%] [G loss: 0.824843]\n",
      "epoch:19 step:18701 [D loss: 0.460079, acc.: 79.69%] [G loss: 0.839908]\n",
      "epoch:19 step:18702 [D loss: 0.495149, acc.: 76.56%] [G loss: 0.753396]\n",
      "epoch:19 step:18703 [D loss: 0.484309, acc.: 77.34%] [G loss: 0.827029]\n",
      "epoch:19 step:18704 [D loss: 0.503172, acc.: 69.53%] [G loss: 0.716266]\n",
      "epoch:19 step:18705 [D loss: 0.557924, acc.: 69.53%] [G loss: 0.644258]\n",
      "epoch:19 step:18706 [D loss: 0.571160, acc.: 71.88%] [G loss: 0.641327]\n",
      "epoch:19 step:18707 [D loss: 0.550802, acc.: 73.44%] [G loss: 0.638805]\n",
      "epoch:19 step:18708 [D loss: 0.574323, acc.: 69.53%] [G loss: 0.675101]\n",
      "epoch:19 step:18709 [D loss: 0.515312, acc.: 71.88%] [G loss: 0.660416]\n",
      "epoch:19 step:18710 [D loss: 0.552947, acc.: 70.31%] [G loss: 0.700148]\n",
      "epoch:19 step:18711 [D loss: 0.586490, acc.: 63.28%] [G loss: 0.650473]\n",
      "epoch:19 step:18712 [D loss: 0.538633, acc.: 67.97%] [G loss: 0.625296]\n",
      "epoch:19 step:18713 [D loss: 0.522651, acc.: 71.09%] [G loss: 0.596191]\n",
      "epoch:19 step:18714 [D loss: 0.512491, acc.: 75.00%] [G loss: 0.797636]\n",
      "epoch:19 step:18715 [D loss: 0.520048, acc.: 75.78%] [G loss: 0.797074]\n",
      "epoch:19 step:18716 [D loss: 0.546614, acc.: 71.88%] [G loss: 0.807406]\n",
      "epoch:19 step:18717 [D loss: 0.462390, acc.: 76.56%] [G loss: 0.872879]\n",
      "epoch:19 step:18718 [D loss: 0.624198, acc.: 64.06%] [G loss: 0.547898]\n",
      "epoch:19 step:18719 [D loss: 0.495847, acc.: 75.00%] [G loss: 0.617916]\n",
      "epoch:19 step:18720 [D loss: 0.708014, acc.: 54.69%] [G loss: 0.569885]\n",
      "epoch:19 step:18721 [D loss: 0.529076, acc.: 67.97%] [G loss: 0.680691]\n",
      "epoch:19 step:18722 [D loss: 0.460081, acc.: 78.12%] [G loss: 0.946904]\n",
      "epoch:19 step:18723 [D loss: 0.692036, acc.: 61.72%] [G loss: 0.757587]\n",
      "epoch:19 step:18724 [D loss: 0.436296, acc.: 82.03%] [G loss: 0.717087]\n",
      "epoch:19 step:18725 [D loss: 0.607489, acc.: 64.06%] [G loss: 0.666422]\n",
      "epoch:19 step:18726 [D loss: 0.511785, acc.: 71.88%] [G loss: 0.550585]\n",
      "epoch:19 step:18727 [D loss: 0.498960, acc.: 69.53%] [G loss: 0.764209]\n",
      "epoch:19 step:18728 [D loss: 0.427185, acc.: 79.69%] [G loss: 0.916247]\n",
      "epoch:19 step:18729 [D loss: 0.469552, acc.: 74.22%] [G loss: 0.973603]\n",
      "epoch:19 step:18730 [D loss: 0.516712, acc.: 75.78%] [G loss: 0.926268]\n",
      "epoch:19 step:18731 [D loss: 0.723048, acc.: 60.94%] [G loss: 0.892436]\n",
      "epoch:19 step:18732 [D loss: 0.377672, acc.: 80.47%] [G loss: 1.195849]\n",
      "epoch:19 step:18733 [D loss: 0.462641, acc.: 78.12%] [G loss: 1.142742]\n",
      "epoch:19 step:18734 [D loss: 0.563989, acc.: 71.88%] [G loss: 0.966711]\n",
      "epoch:19 step:18735 [D loss: 0.632946, acc.: 63.28%] [G loss: 0.794375]\n",
      "epoch:19 step:18736 [D loss: 0.500056, acc.: 74.22%] [G loss: 0.865349]\n",
      "epoch:19 step:18737 [D loss: 0.503842, acc.: 76.56%] [G loss: 1.013444]\n",
      "epoch:19 step:18738 [D loss: 0.475019, acc.: 75.00%] [G loss: 0.894040]\n",
      "epoch:19 step:18739 [D loss: 0.403990, acc.: 85.94%] [G loss: 1.236754]\n",
      "epoch:19 step:18740 [D loss: 0.469003, acc.: 75.78%] [G loss: 1.482333]\n",
      "epoch:20 step:18741 [D loss: 0.607652, acc.: 70.31%] [G loss: 1.006310]\n",
      "epoch:20 step:18742 [D loss: 0.440504, acc.: 76.56%] [G loss: 1.117394]\n",
      "epoch:20 step:18743 [D loss: 0.586958, acc.: 67.19%] [G loss: 1.004416]\n",
      "epoch:20 step:18744 [D loss: 0.518148, acc.: 75.78%] [G loss: 0.810247]\n",
      "epoch:20 step:18745 [D loss: 0.563256, acc.: 71.88%] [G loss: 0.694039]\n",
      "epoch:20 step:18746 [D loss: 0.586186, acc.: 63.28%] [G loss: 0.675055]\n",
      "epoch:20 step:18747 [D loss: 0.471139, acc.: 79.69%] [G loss: 0.762036]\n",
      "epoch:20 step:18748 [D loss: 0.540633, acc.: 71.09%] [G loss: 0.635505]\n",
      "epoch:20 step:18749 [D loss: 0.495639, acc.: 75.78%] [G loss: 0.895232]\n",
      "epoch:20 step:18750 [D loss: 0.509193, acc.: 74.22%] [G loss: 0.938971]\n",
      "epoch:20 step:18751 [D loss: 0.437957, acc.: 82.81%] [G loss: 0.755390]\n",
      "epoch:20 step:18752 [D loss: 0.571766, acc.: 69.53%] [G loss: 0.800503]\n",
      "epoch:20 step:18753 [D loss: 0.538753, acc.: 72.66%] [G loss: 0.723020]\n",
      "epoch:20 step:18754 [D loss: 0.503998, acc.: 75.00%] [G loss: 0.659365]\n",
      "epoch:20 step:18755 [D loss: 0.460728, acc.: 78.91%] [G loss: 0.719402]\n",
      "epoch:20 step:18756 [D loss: 0.516237, acc.: 75.78%] [G loss: 0.554769]\n",
      "epoch:20 step:18757 [D loss: 0.523834, acc.: 73.44%] [G loss: 0.838640]\n",
      "epoch:20 step:18758 [D loss: 0.553984, acc.: 71.09%] [G loss: 0.646555]\n",
      "epoch:20 step:18759 [D loss: 0.562598, acc.: 71.09%] [G loss: 0.809681]\n",
      "epoch:20 step:18760 [D loss: 0.606947, acc.: 66.41%] [G loss: 0.715383]\n",
      "epoch:20 step:18761 [D loss: 0.556350, acc.: 71.88%] [G loss: 0.633750]\n",
      "epoch:20 step:18762 [D loss: 0.429458, acc.: 82.03%] [G loss: 0.961018]\n",
      "epoch:20 step:18763 [D loss: 0.544624, acc.: 71.09%] [G loss: 0.732043]\n",
      "epoch:20 step:18764 [D loss: 0.554713, acc.: 69.53%] [G loss: 0.566858]\n",
      "epoch:20 step:18765 [D loss: 0.511049, acc.: 75.78%] [G loss: 0.651610]\n",
      "epoch:20 step:18766 [D loss: 0.579247, acc.: 68.75%] [G loss: 0.538449]\n",
      "epoch:20 step:18767 [D loss: 0.458989, acc.: 78.91%] [G loss: 0.600563]\n",
      "epoch:20 step:18768 [D loss: 0.525195, acc.: 68.75%] [G loss: 0.623714]\n",
      "epoch:20 step:18769 [D loss: 0.580406, acc.: 69.53%] [G loss: 0.644561]\n",
      "epoch:20 step:18770 [D loss: 0.530607, acc.: 74.22%] [G loss: 0.612202]\n",
      "epoch:20 step:18771 [D loss: 0.663115, acc.: 64.06%] [G loss: 0.448764]\n",
      "epoch:20 step:18772 [D loss: 0.548388, acc.: 72.66%] [G loss: 0.535809]\n",
      "epoch:20 step:18773 [D loss: 0.502423, acc.: 73.44%] [G loss: 0.730969]\n",
      "epoch:20 step:18774 [D loss: 0.513819, acc.: 70.31%] [G loss: 0.625836]\n",
      "epoch:20 step:18775 [D loss: 0.569981, acc.: 64.84%] [G loss: 0.549302]\n",
      "epoch:20 step:18776 [D loss: 0.534583, acc.: 67.19%] [G loss: 0.732479]\n",
      "epoch:20 step:18777 [D loss: 0.508883, acc.: 77.34%] [G loss: 0.703900]\n",
      "epoch:20 step:18778 [D loss: 0.614615, acc.: 67.19%] [G loss: 0.601275]\n",
      "epoch:20 step:18779 [D loss: 0.537408, acc.: 70.31%] [G loss: 0.512190]\n",
      "epoch:20 step:18780 [D loss: 0.502709, acc.: 75.00%] [G loss: 0.770454]\n",
      "epoch:20 step:18781 [D loss: 0.523584, acc.: 73.44%] [G loss: 0.808386]\n",
      "epoch:20 step:18782 [D loss: 0.548203, acc.: 72.66%] [G loss: 0.661252]\n",
      "epoch:20 step:18783 [D loss: 0.571318, acc.: 70.31%] [G loss: 0.564058]\n",
      "epoch:20 step:18784 [D loss: 0.591190, acc.: 65.62%] [G loss: 0.739907]\n",
      "epoch:20 step:18785 [D loss: 0.498525, acc.: 71.88%] [G loss: 0.471243]\n",
      "epoch:20 step:18786 [D loss: 0.487797, acc.: 71.88%] [G loss: 0.739859]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:20 step:18787 [D loss: 0.625163, acc.: 60.94%] [G loss: 0.553676]\n",
      "epoch:20 step:18788 [D loss: 0.520953, acc.: 72.66%] [G loss: 0.719863]\n",
      "epoch:20 step:18789 [D loss: 0.457854, acc.: 78.91%] [G loss: 0.813906]\n",
      "epoch:20 step:18790 [D loss: 0.572016, acc.: 69.53%] [G loss: 0.560440]\n",
      "epoch:20 step:18791 [D loss: 0.676682, acc.: 57.81%] [G loss: 0.544693]\n",
      "epoch:20 step:18792 [D loss: 0.584131, acc.: 65.62%] [G loss: 0.566395]\n",
      "epoch:20 step:18793 [D loss: 0.530558, acc.: 76.56%] [G loss: 0.841895]\n",
      "epoch:20 step:18794 [D loss: 0.495893, acc.: 71.88%] [G loss: 0.657878]\n",
      "epoch:20 step:18795 [D loss: 0.610235, acc.: 66.41%] [G loss: 0.784686]\n",
      "epoch:20 step:18796 [D loss: 0.485301, acc.: 76.56%] [G loss: 0.778449]\n",
      "epoch:20 step:18797 [D loss: 0.493331, acc.: 70.31%] [G loss: 0.803748]\n",
      "epoch:20 step:18798 [D loss: 0.593329, acc.: 64.84%] [G loss: 0.641475]\n",
      "epoch:20 step:18799 [D loss: 0.529082, acc.: 71.09%] [G loss: 0.758362]\n",
      "epoch:20 step:18800 [D loss: 0.574197, acc.: 70.31%] [G loss: 0.842774]\n",
      "##############\n",
      "[3.00740509 1.2722268  6.3285051  5.02767506 4.04012555 5.67457081\n",
      " 4.54659459 5.14869929 4.65779392 4.29920263]\n",
      "##########\n",
      "epoch:20 step:18801 [D loss: 0.627859, acc.: 65.62%] [G loss: 0.709782]\n",
      "epoch:20 step:18802 [D loss: 0.544967, acc.: 71.88%] [G loss: 0.794343]\n",
      "epoch:20 step:18803 [D loss: 0.578774, acc.: 72.66%] [G loss: 0.522590]\n",
      "epoch:20 step:18804 [D loss: 0.561571, acc.: 66.41%] [G loss: 0.508737]\n",
      "epoch:20 step:18805 [D loss: 0.535344, acc.: 71.09%] [G loss: 0.544251]\n",
      "epoch:20 step:18806 [D loss: 0.503019, acc.: 75.00%] [G loss: 0.755559]\n",
      "epoch:20 step:18807 [D loss: 0.547482, acc.: 67.19%] [G loss: 0.633790]\n",
      "epoch:20 step:18808 [D loss: 0.509244, acc.: 70.31%] [G loss: 0.600826]\n",
      "epoch:20 step:18809 [D loss: 0.547022, acc.: 67.19%] [G loss: 0.551514]\n",
      "epoch:20 step:18810 [D loss: 0.528811, acc.: 76.56%] [G loss: 0.670654]\n",
      "epoch:20 step:18811 [D loss: 0.541270, acc.: 71.88%] [G loss: 0.701813]\n",
      "epoch:20 step:18812 [D loss: 0.522417, acc.: 71.09%] [G loss: 0.589868]\n",
      "epoch:20 step:18813 [D loss: 0.574050, acc.: 65.62%] [G loss: 0.652555]\n",
      "epoch:20 step:18814 [D loss: 0.485244, acc.: 77.34%] [G loss: 0.803590]\n",
      "epoch:20 step:18815 [D loss: 0.535378, acc.: 71.88%] [G loss: 0.714952]\n",
      "epoch:20 step:18816 [D loss: 0.566538, acc.: 71.88%] [G loss: 1.030287]\n",
      "epoch:20 step:18817 [D loss: 0.471871, acc.: 74.22%] [G loss: 0.882385]\n",
      "epoch:20 step:18818 [D loss: 0.623885, acc.: 70.31%] [G loss: 0.541189]\n",
      "epoch:20 step:18819 [D loss: 0.558288, acc.: 69.53%] [G loss: 0.524364]\n",
      "epoch:20 step:18820 [D loss: 0.503400, acc.: 77.34%] [G loss: 0.595015]\n",
      "epoch:20 step:18821 [D loss: 0.554570, acc.: 67.19%] [G loss: 0.637147]\n",
      "epoch:20 step:18822 [D loss: 0.528425, acc.: 69.53%] [G loss: 0.613830]\n",
      "epoch:20 step:18823 [D loss: 0.480966, acc.: 79.69%] [G loss: 0.640877]\n",
      "epoch:20 step:18824 [D loss: 0.604246, acc.: 65.62%] [G loss: 0.717986]\n",
      "epoch:20 step:18825 [D loss: 0.579547, acc.: 62.50%] [G loss: 0.557605]\n",
      "epoch:20 step:18826 [D loss: 0.523208, acc.: 71.88%] [G loss: 0.556901]\n",
      "epoch:20 step:18827 [D loss: 0.558809, acc.: 69.53%] [G loss: 0.598996]\n",
      "epoch:20 step:18828 [D loss: 0.530905, acc.: 71.88%] [G loss: 0.557149]\n",
      "epoch:20 step:18829 [D loss: 0.505413, acc.: 71.88%] [G loss: 0.716345]\n",
      "epoch:20 step:18830 [D loss: 0.515962, acc.: 72.66%] [G loss: 0.747517]\n",
      "epoch:20 step:18831 [D loss: 0.558885, acc.: 70.31%] [G loss: 0.652374]\n",
      "epoch:20 step:18832 [D loss: 0.495644, acc.: 74.22%] [G loss: 0.801024]\n",
      "epoch:20 step:18833 [D loss: 0.497629, acc.: 75.00%] [G loss: 0.742070]\n",
      "epoch:20 step:18834 [D loss: 0.470329, acc.: 78.91%] [G loss: 0.751983]\n",
      "epoch:20 step:18835 [D loss: 0.561588, acc.: 73.44%] [G loss: 0.796555]\n",
      "epoch:20 step:18836 [D loss: 0.491301, acc.: 77.34%] [G loss: 0.684188]\n",
      "epoch:20 step:18837 [D loss: 0.492541, acc.: 74.22%] [G loss: 0.686244]\n",
      "epoch:20 step:18838 [D loss: 0.565962, acc.: 69.53%] [G loss: 0.701571]\n",
      "epoch:20 step:18839 [D loss: 0.530604, acc.: 75.78%] [G loss: 0.622307]\n",
      "epoch:20 step:18840 [D loss: 0.461235, acc.: 80.47%] [G loss: 0.818655]\n",
      "epoch:20 step:18841 [D loss: 0.520174, acc.: 75.00%] [G loss: 0.817788]\n",
      "epoch:20 step:18842 [D loss: 0.620817, acc.: 67.19%] [G loss: 0.536907]\n",
      "epoch:20 step:18843 [D loss: 0.560007, acc.: 63.28%] [G loss: 0.487419]\n",
      "epoch:20 step:18844 [D loss: 0.546925, acc.: 69.53%] [G loss: 0.545866]\n",
      "epoch:20 step:18845 [D loss: 0.590094, acc.: 63.28%] [G loss: 0.478407]\n",
      "epoch:20 step:18846 [D loss: 0.578815, acc.: 64.84%] [G loss: 0.584472]\n",
      "epoch:20 step:18847 [D loss: 0.562307, acc.: 71.09%] [G loss: 0.640966]\n",
      "epoch:20 step:18848 [D loss: 0.625822, acc.: 67.19%] [G loss: 0.621306]\n",
      "epoch:20 step:18849 [D loss: 0.536508, acc.: 70.31%] [G loss: 0.539727]\n",
      "epoch:20 step:18850 [D loss: 0.595676, acc.: 64.84%] [G loss: 0.539853]\n",
      "epoch:20 step:18851 [D loss: 0.495729, acc.: 80.47%] [G loss: 0.586846]\n",
      "epoch:20 step:18852 [D loss: 0.533747, acc.: 74.22%] [G loss: 0.643971]\n",
      "epoch:20 step:18853 [D loss: 0.529097, acc.: 69.53%] [G loss: 0.689000]\n",
      "epoch:20 step:18854 [D loss: 0.540985, acc.: 73.44%] [G loss: 0.686853]\n",
      "epoch:20 step:18855 [D loss: 0.498220, acc.: 75.78%] [G loss: 0.643800]\n",
      "epoch:20 step:18856 [D loss: 0.517847, acc.: 74.22%] [G loss: 0.620551]\n",
      "epoch:20 step:18857 [D loss: 0.502893, acc.: 75.78%] [G loss: 0.771848]\n",
      "epoch:20 step:18858 [D loss: 0.514418, acc.: 77.34%] [G loss: 0.751824]\n",
      "epoch:20 step:18859 [D loss: 0.472076, acc.: 82.03%] [G loss: 0.713647]\n",
      "epoch:20 step:18860 [D loss: 0.513473, acc.: 72.66%] [G loss: 0.695502]\n",
      "epoch:20 step:18861 [D loss: 0.556563, acc.: 67.97%] [G loss: 0.546556]\n",
      "epoch:20 step:18862 [D loss: 0.495700, acc.: 81.25%] [G loss: 0.801264]\n",
      "epoch:20 step:18863 [D loss: 0.535485, acc.: 72.66%] [G loss: 0.729174]\n",
      "epoch:20 step:18864 [D loss: 0.559348, acc.: 72.66%] [G loss: 0.638933]\n",
      "epoch:20 step:18865 [D loss: 0.624211, acc.: 67.97%] [G loss: 0.588590]\n",
      "epoch:20 step:18866 [D loss: 0.497538, acc.: 77.34%] [G loss: 0.585837]\n",
      "epoch:20 step:18867 [D loss: 0.462044, acc.: 78.91%] [G loss: 0.707022]\n",
      "epoch:20 step:18868 [D loss: 0.516802, acc.: 74.22%] [G loss: 0.715814]\n",
      "epoch:20 step:18869 [D loss: 0.554166, acc.: 68.75%] [G loss: 0.590971]\n",
      "epoch:20 step:18870 [D loss: 0.480973, acc.: 75.00%] [G loss: 0.672141]\n",
      "epoch:20 step:18871 [D loss: 0.492990, acc.: 69.53%] [G loss: 0.779365]\n",
      "epoch:20 step:18872 [D loss: 0.556815, acc.: 70.31%] [G loss: 0.672921]\n",
      "epoch:20 step:18873 [D loss: 0.530524, acc.: 67.97%] [G loss: 0.783763]\n",
      "epoch:20 step:18874 [D loss: 0.474574, acc.: 76.56%] [G loss: 0.822792]\n",
      "epoch:20 step:18875 [D loss: 0.533601, acc.: 74.22%] [G loss: 0.471250]\n",
      "epoch:20 step:18876 [D loss: 0.545413, acc.: 71.88%] [G loss: 0.812393]\n",
      "epoch:20 step:18877 [D loss: 0.675896, acc.: 64.06%] [G loss: 0.656158]\n",
      "epoch:20 step:18878 [D loss: 0.522110, acc.: 71.09%] [G loss: 0.572213]\n",
      "epoch:20 step:18879 [D loss: 0.499280, acc.: 72.66%] [G loss: 0.645992]\n",
      "epoch:20 step:18880 [D loss: 0.573060, acc.: 67.19%] [G loss: 0.627605]\n",
      "epoch:20 step:18881 [D loss: 0.556069, acc.: 68.75%] [G loss: 0.587293]\n",
      "epoch:20 step:18882 [D loss: 0.541792, acc.: 66.41%] [G loss: 0.654190]\n",
      "epoch:20 step:18883 [D loss: 0.621035, acc.: 64.84%] [G loss: 0.565583]\n",
      "epoch:20 step:18884 [D loss: 0.524467, acc.: 70.31%] [G loss: 0.525930]\n",
      "epoch:20 step:18885 [D loss: 0.575700, acc.: 66.41%] [G loss: 0.576428]\n",
      "epoch:20 step:18886 [D loss: 0.503668, acc.: 71.88%] [G loss: 0.717155]\n",
      "epoch:20 step:18887 [D loss: 0.645789, acc.: 60.94%] [G loss: 0.615211]\n",
      "epoch:20 step:18888 [D loss: 0.568280, acc.: 66.41%] [G loss: 0.590743]\n",
      "epoch:20 step:18889 [D loss: 0.464354, acc.: 77.34%] [G loss: 0.645042]\n",
      "epoch:20 step:18890 [D loss: 0.577168, acc.: 62.50%] [G loss: 0.533026]\n",
      "epoch:20 step:18891 [D loss: 0.607613, acc.: 65.62%] [G loss: 0.592526]\n",
      "epoch:20 step:18892 [D loss: 0.468519, acc.: 81.25%] [G loss: 0.709973]\n",
      "epoch:20 step:18893 [D loss: 0.570073, acc.: 71.09%] [G loss: 0.752738]\n",
      "epoch:20 step:18894 [D loss: 0.564742, acc.: 68.75%] [G loss: 0.702039]\n",
      "epoch:20 step:18895 [D loss: 0.559390, acc.: 64.06%] [G loss: 0.652637]\n",
      "epoch:20 step:18896 [D loss: 0.575617, acc.: 67.19%] [G loss: 0.836389]\n",
      "epoch:20 step:18897 [D loss: 0.557364, acc.: 71.88%] [G loss: 0.624391]\n",
      "epoch:20 step:18898 [D loss: 0.586700, acc.: 69.53%] [G loss: 0.567872]\n",
      "epoch:20 step:18899 [D loss: 0.495458, acc.: 78.91%] [G loss: 0.595178]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:20 step:18900 [D loss: 0.571422, acc.: 66.41%] [G loss: 0.636117]\n",
      "epoch:20 step:18901 [D loss: 0.549288, acc.: 71.88%] [G loss: 0.680629]\n",
      "epoch:20 step:18902 [D loss: 0.474811, acc.: 76.56%] [G loss: 0.626731]\n",
      "epoch:20 step:18903 [D loss: 0.528302, acc.: 72.66%] [G loss: 0.826459]\n",
      "epoch:20 step:18904 [D loss: 0.662592, acc.: 61.72%] [G loss: 0.584697]\n",
      "epoch:20 step:18905 [D loss: 0.486411, acc.: 71.88%] [G loss: 0.728414]\n",
      "epoch:20 step:18906 [D loss: 0.570742, acc.: 67.97%] [G loss: 0.698224]\n",
      "epoch:20 step:18907 [D loss: 0.542699, acc.: 69.53%] [G loss: 0.557501]\n",
      "epoch:20 step:18908 [D loss: 0.554269, acc.: 72.66%] [G loss: 0.609778]\n",
      "epoch:20 step:18909 [D loss: 0.616186, acc.: 59.38%] [G loss: 0.485388]\n",
      "epoch:20 step:18910 [D loss: 0.565521, acc.: 70.31%] [G loss: 0.470824]\n",
      "epoch:20 step:18911 [D loss: 0.512722, acc.: 73.44%] [G loss: 0.582988]\n",
      "epoch:20 step:18912 [D loss: 0.480893, acc.: 79.69%] [G loss: 0.573325]\n",
      "epoch:20 step:18913 [D loss: 0.492189, acc.: 77.34%] [G loss: 0.650612]\n",
      "epoch:20 step:18914 [D loss: 0.563309, acc.: 71.09%] [G loss: 0.695987]\n",
      "epoch:20 step:18915 [D loss: 0.604297, acc.: 60.94%] [G loss: 0.559484]\n",
      "epoch:20 step:18916 [D loss: 0.508553, acc.: 75.00%] [G loss: 0.665583]\n",
      "epoch:20 step:18917 [D loss: 0.520304, acc.: 71.88%] [G loss: 0.527790]\n",
      "epoch:20 step:18918 [D loss: 0.567073, acc.: 65.62%] [G loss: 0.650990]\n",
      "epoch:20 step:18919 [D loss: 0.568853, acc.: 68.75%] [G loss: 0.678230]\n",
      "epoch:20 step:18920 [D loss: 0.628641, acc.: 60.16%] [G loss: 0.446036]\n",
      "epoch:20 step:18921 [D loss: 0.582294, acc.: 62.50%] [G loss: 0.417996]\n",
      "epoch:20 step:18922 [D loss: 0.527794, acc.: 71.09%] [G loss: 0.655214]\n",
      "epoch:20 step:18923 [D loss: 0.577626, acc.: 70.31%] [G loss: 0.718619]\n",
      "epoch:20 step:18924 [D loss: 0.492300, acc.: 71.09%] [G loss: 0.623784]\n",
      "epoch:20 step:18925 [D loss: 0.547915, acc.: 67.97%] [G loss: 0.588817]\n",
      "epoch:20 step:18926 [D loss: 0.526565, acc.: 68.75%] [G loss: 0.694228]\n",
      "epoch:20 step:18927 [D loss: 0.612651, acc.: 65.62%] [G loss: 0.713290]\n",
      "epoch:20 step:18928 [D loss: 0.569685, acc.: 67.19%] [G loss: 0.702600]\n",
      "epoch:20 step:18929 [D loss: 0.569276, acc.: 67.97%] [G loss: 0.517864]\n",
      "epoch:20 step:18930 [D loss: 0.505626, acc.: 75.00%] [G loss: 0.644497]\n",
      "epoch:20 step:18931 [D loss: 0.507751, acc.: 76.56%] [G loss: 0.617874]\n",
      "epoch:20 step:18932 [D loss: 0.513565, acc.: 77.34%] [G loss: 0.661071]\n",
      "epoch:20 step:18933 [D loss: 0.563662, acc.: 68.75%] [G loss: 0.572093]\n",
      "epoch:20 step:18934 [D loss: 0.486451, acc.: 77.34%] [G loss: 0.727989]\n",
      "epoch:20 step:18935 [D loss: 0.535612, acc.: 77.34%] [G loss: 0.692445]\n",
      "epoch:20 step:18936 [D loss: 0.533660, acc.: 69.53%] [G loss: 0.653757]\n",
      "epoch:20 step:18937 [D loss: 0.523666, acc.: 72.66%] [G loss: 0.710740]\n",
      "epoch:20 step:18938 [D loss: 0.484066, acc.: 75.78%] [G loss: 0.823594]\n",
      "epoch:20 step:18939 [D loss: 0.522153, acc.: 73.44%] [G loss: 0.725960]\n",
      "epoch:20 step:18940 [D loss: 0.664257, acc.: 62.50%] [G loss: 0.658270]\n",
      "epoch:20 step:18941 [D loss: 0.580509, acc.: 70.31%] [G loss: 0.510519]\n",
      "epoch:20 step:18942 [D loss: 0.556252, acc.: 67.97%] [G loss: 0.773651]\n",
      "epoch:20 step:18943 [D loss: 0.651213, acc.: 65.62%] [G loss: 0.567234]\n",
      "epoch:20 step:18944 [D loss: 0.566813, acc.: 68.75%] [G loss: 0.592670]\n",
      "epoch:20 step:18945 [D loss: 0.558273, acc.: 72.66%] [G loss: 0.958730]\n",
      "epoch:20 step:18946 [D loss: 0.519101, acc.: 71.09%] [G loss: 0.615422]\n",
      "epoch:20 step:18947 [D loss: 0.469075, acc.: 75.78%] [G loss: 0.790739]\n",
      "epoch:20 step:18948 [D loss: 0.457924, acc.: 81.25%] [G loss: 0.986476]\n",
      "epoch:20 step:18949 [D loss: 0.558769, acc.: 71.09%] [G loss: 0.820533]\n",
      "epoch:20 step:18950 [D loss: 0.635357, acc.: 65.62%] [G loss: 0.606560]\n",
      "epoch:20 step:18951 [D loss: 0.613495, acc.: 67.19%] [G loss: 0.624605]\n",
      "epoch:20 step:18952 [D loss: 0.529845, acc.: 75.00%] [G loss: 0.679841]\n",
      "epoch:20 step:18953 [D loss: 0.567855, acc.: 66.41%] [G loss: 0.722238]\n",
      "epoch:20 step:18954 [D loss: 0.600062, acc.: 66.41%] [G loss: 0.576366]\n",
      "epoch:20 step:18955 [D loss: 0.598308, acc.: 65.62%] [G loss: 0.559561]\n",
      "epoch:20 step:18956 [D loss: 0.510924, acc.: 67.19%] [G loss: 0.582764]\n",
      "epoch:20 step:18957 [D loss: 0.538423, acc.: 71.88%] [G loss: 0.557207]\n",
      "epoch:20 step:18958 [D loss: 0.477581, acc.: 78.91%] [G loss: 0.665923]\n",
      "epoch:20 step:18959 [D loss: 0.495824, acc.: 75.78%] [G loss: 0.740538]\n",
      "epoch:20 step:18960 [D loss: 0.613942, acc.: 68.75%] [G loss: 0.674569]\n",
      "epoch:20 step:18961 [D loss: 0.523785, acc.: 71.88%] [G loss: 0.656529]\n",
      "epoch:20 step:18962 [D loss: 0.501373, acc.: 78.91%] [G loss: 0.691110]\n",
      "epoch:20 step:18963 [D loss: 0.424244, acc.: 82.81%] [G loss: 0.982200]\n",
      "epoch:20 step:18964 [D loss: 0.626112, acc.: 64.06%] [G loss: 0.800853]\n",
      "epoch:20 step:18965 [D loss: 0.531272, acc.: 72.66%] [G loss: 0.741879]\n",
      "epoch:20 step:18966 [D loss: 0.580313, acc.: 61.72%] [G loss: 0.663772]\n",
      "epoch:20 step:18967 [D loss: 0.538908, acc.: 78.12%] [G loss: 0.765678]\n",
      "epoch:20 step:18968 [D loss: 0.608302, acc.: 67.97%] [G loss: 0.858641]\n",
      "epoch:20 step:18969 [D loss: 0.580254, acc.: 66.41%] [G loss: 0.682853]\n",
      "epoch:20 step:18970 [D loss: 0.525931, acc.: 74.22%] [G loss: 0.604267]\n",
      "epoch:20 step:18971 [D loss: 0.489389, acc.: 76.56%] [G loss: 0.889587]\n",
      "epoch:20 step:18972 [D loss: 0.461775, acc.: 82.03%] [G loss: 1.097439]\n",
      "epoch:20 step:18973 [D loss: 0.493591, acc.: 76.56%] [G loss: 0.803765]\n",
      "epoch:20 step:18974 [D loss: 0.562182, acc.: 70.31%] [G loss: 0.775846]\n",
      "epoch:20 step:18975 [D loss: 0.578551, acc.: 70.31%] [G loss: 0.645050]\n",
      "epoch:20 step:18976 [D loss: 0.539246, acc.: 69.53%] [G loss: 0.571985]\n",
      "epoch:20 step:18977 [D loss: 0.570875, acc.: 64.06%] [G loss: 0.735687]\n",
      "epoch:20 step:18978 [D loss: 0.593785, acc.: 71.09%] [G loss: 0.609023]\n",
      "epoch:20 step:18979 [D loss: 0.517517, acc.: 70.31%] [G loss: 0.521546]\n",
      "epoch:20 step:18980 [D loss: 0.584414, acc.: 65.62%] [G loss: 0.568464]\n",
      "epoch:20 step:18981 [D loss: 0.527452, acc.: 67.97%] [G loss: 0.606187]\n",
      "epoch:20 step:18982 [D loss: 0.538213, acc.: 72.66%] [G loss: 0.629599]\n",
      "epoch:20 step:18983 [D loss: 0.513556, acc.: 72.66%] [G loss: 0.612328]\n",
      "epoch:20 step:18984 [D loss: 0.502368, acc.: 76.56%] [G loss: 0.703364]\n",
      "epoch:20 step:18985 [D loss: 0.473033, acc.: 82.03%] [G loss: 0.744195]\n",
      "epoch:20 step:18986 [D loss: 0.575143, acc.: 67.97%] [G loss: 0.637069]\n",
      "epoch:20 step:18987 [D loss: 0.520526, acc.: 72.66%] [G loss: 0.739327]\n",
      "epoch:20 step:18988 [D loss: 0.507758, acc.: 75.00%] [G loss: 0.820238]\n",
      "epoch:20 step:18989 [D loss: 0.537981, acc.: 71.09%] [G loss: 0.746442]\n",
      "epoch:20 step:18990 [D loss: 0.587033, acc.: 67.97%] [G loss: 0.719603]\n",
      "epoch:20 step:18991 [D loss: 0.617492, acc.: 63.28%] [G loss: 0.655303]\n",
      "epoch:20 step:18992 [D loss: 0.508210, acc.: 73.44%] [G loss: 0.808415]\n",
      "epoch:20 step:18993 [D loss: 0.592076, acc.: 67.97%] [G loss: 0.740567]\n",
      "epoch:20 step:18994 [D loss: 0.544201, acc.: 71.09%] [G loss: 0.692879]\n",
      "epoch:20 step:18995 [D loss: 0.502242, acc.: 78.91%] [G loss: 0.726808]\n",
      "epoch:20 step:18996 [D loss: 0.553115, acc.: 67.97%] [G loss: 0.643099]\n",
      "epoch:20 step:18997 [D loss: 0.599652, acc.: 66.41%] [G loss: 0.535966]\n",
      "epoch:20 step:18998 [D loss: 0.516235, acc.: 75.00%] [G loss: 0.605650]\n",
      "epoch:20 step:18999 [D loss: 0.514927, acc.: 73.44%] [G loss: 0.743485]\n",
      "epoch:20 step:19000 [D loss: 0.579188, acc.: 64.06%] [G loss: 0.606361]\n",
      "##############\n",
      "[2.96018041 0.78619977 6.12185551 4.85933159 3.95105166 5.61445589\n",
      " 4.49481639 5.08340759 4.63471178 4.1535344 ]\n",
      "##########\n",
      "epoch:20 step:19001 [D loss: 0.514050, acc.: 71.88%] [G loss: 0.612824]\n",
      "epoch:20 step:19002 [D loss: 0.503596, acc.: 76.56%] [G loss: 0.638016]\n",
      "epoch:20 step:19003 [D loss: 0.575833, acc.: 68.75%] [G loss: 0.492842]\n",
      "epoch:20 step:19004 [D loss: 0.537434, acc.: 67.97%] [G loss: 0.658550]\n",
      "epoch:20 step:19005 [D loss: 0.587507, acc.: 65.62%] [G loss: 0.618811]\n",
      "epoch:20 step:19006 [D loss: 0.546668, acc.: 71.09%] [G loss: 0.548117]\n",
      "epoch:20 step:19007 [D loss: 0.553226, acc.: 73.44%] [G loss: 0.628688]\n",
      "epoch:20 step:19008 [D loss: 0.514752, acc.: 71.88%] [G loss: 0.632055]\n",
      "epoch:20 step:19009 [D loss: 0.543273, acc.: 71.88%] [G loss: 0.580735]\n",
      "epoch:20 step:19010 [D loss: 0.506052, acc.: 75.00%] [G loss: 0.648510]\n",
      "epoch:20 step:19011 [D loss: 0.483884, acc.: 78.12%] [G loss: 0.767444]\n",
      "epoch:20 step:19012 [D loss: 0.571374, acc.: 66.41%] [G loss: 0.717076]\n",
      "epoch:20 step:19013 [D loss: 0.549495, acc.: 68.75%] [G loss: 0.723144]\n",
      "epoch:20 step:19014 [D loss: 0.516801, acc.: 69.53%] [G loss: 0.619807]\n",
      "epoch:20 step:19015 [D loss: 0.572448, acc.: 67.97%] [G loss: 0.753009]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:20 step:19016 [D loss: 0.506678, acc.: 73.44%] [G loss: 0.662807]\n",
      "epoch:20 step:19017 [D loss: 0.660270, acc.: 59.38%] [G loss: 0.638237]\n",
      "epoch:20 step:19018 [D loss: 0.621990, acc.: 67.19%] [G loss: 0.490239]\n",
      "epoch:20 step:19019 [D loss: 0.557127, acc.: 71.09%] [G loss: 0.529006]\n",
      "epoch:20 step:19020 [D loss: 0.542622, acc.: 71.09%] [G loss: 0.502835]\n",
      "epoch:20 step:19021 [D loss: 0.538137, acc.: 69.53%] [G loss: 0.641559]\n",
      "epoch:20 step:19022 [D loss: 0.554484, acc.: 71.88%] [G loss: 0.571694]\n",
      "epoch:20 step:19023 [D loss: 0.486840, acc.: 78.91%] [G loss: 0.597620]\n",
      "epoch:20 step:19024 [D loss: 0.550239, acc.: 66.41%] [G loss: 0.477698]\n",
      "epoch:20 step:19025 [D loss: 0.515656, acc.: 70.31%] [G loss: 0.785777]\n",
      "epoch:20 step:19026 [D loss: 0.517620, acc.: 68.75%] [G loss: 0.560000]\n",
      "epoch:20 step:19027 [D loss: 0.594514, acc.: 65.62%] [G loss: 0.535835]\n",
      "epoch:20 step:19028 [D loss: 0.602744, acc.: 69.53%] [G loss: 0.699847]\n",
      "epoch:20 step:19029 [D loss: 0.504171, acc.: 78.91%] [G loss: 0.604128]\n",
      "epoch:20 step:19030 [D loss: 0.545878, acc.: 70.31%] [G loss: 0.661309]\n",
      "epoch:20 step:19031 [D loss: 0.581630, acc.: 70.31%] [G loss: 0.532261]\n",
      "epoch:20 step:19032 [D loss: 0.490661, acc.: 75.00%] [G loss: 0.750268]\n",
      "epoch:20 step:19033 [D loss: 0.539488, acc.: 66.41%] [G loss: 0.661524]\n",
      "epoch:20 step:19034 [D loss: 0.634385, acc.: 64.84%] [G loss: 0.447787]\n",
      "epoch:20 step:19035 [D loss: 0.595658, acc.: 67.19%] [G loss: 0.513794]\n",
      "epoch:20 step:19036 [D loss: 0.466341, acc.: 75.78%] [G loss: 0.605313]\n",
      "epoch:20 step:19037 [D loss: 0.570211, acc.: 66.41%] [G loss: 0.513885]\n",
      "epoch:20 step:19038 [D loss: 0.512306, acc.: 78.12%] [G loss: 0.645768]\n",
      "epoch:20 step:19039 [D loss: 0.430256, acc.: 80.47%] [G loss: 0.822835]\n",
      "epoch:20 step:19040 [D loss: 0.528011, acc.: 69.53%] [G loss: 0.623022]\n",
      "epoch:20 step:19041 [D loss: 0.624288, acc.: 63.28%] [G loss: 0.597820]\n",
      "epoch:20 step:19042 [D loss: 0.541766, acc.: 73.44%] [G loss: 0.548361]\n",
      "epoch:20 step:19043 [D loss: 0.529026, acc.: 73.44%] [G loss: 0.470530]\n",
      "epoch:20 step:19044 [D loss: 0.465904, acc.: 75.78%] [G loss: 0.609078]\n",
      "epoch:20 step:19045 [D loss: 0.518104, acc.: 71.88%] [G loss: 0.539153]\n",
      "epoch:20 step:19046 [D loss: 0.543405, acc.: 73.44%] [G loss: 0.695815]\n",
      "epoch:20 step:19047 [D loss: 0.500865, acc.: 74.22%] [G loss: 0.769929]\n",
      "epoch:20 step:19048 [D loss: 0.554395, acc.: 69.53%] [G loss: 0.755718]\n",
      "epoch:20 step:19049 [D loss: 0.558362, acc.: 64.84%] [G loss: 0.678289]\n",
      "epoch:20 step:19050 [D loss: 0.576824, acc.: 68.75%] [G loss: 0.679562]\n",
      "epoch:20 step:19051 [D loss: 0.432048, acc.: 79.69%] [G loss: 0.750754]\n",
      "epoch:20 step:19052 [D loss: 0.456438, acc.: 78.91%] [G loss: 0.811687]\n",
      "epoch:20 step:19053 [D loss: 0.510334, acc.: 71.88%] [G loss: 0.885507]\n",
      "epoch:20 step:19054 [D loss: 0.482427, acc.: 73.44%] [G loss: 0.858029]\n",
      "epoch:20 step:19055 [D loss: 0.502041, acc.: 76.56%] [G loss: 1.161446]\n",
      "epoch:20 step:19056 [D loss: 0.696064, acc.: 66.41%] [G loss: 0.697636]\n",
      "epoch:20 step:19057 [D loss: 0.559294, acc.: 68.75%] [G loss: 0.666420]\n",
      "epoch:20 step:19058 [D loss: 0.513465, acc.: 71.88%] [G loss: 0.543852]\n",
      "epoch:20 step:19059 [D loss: 0.538894, acc.: 70.31%] [G loss: 0.628529]\n",
      "epoch:20 step:19060 [D loss: 0.539327, acc.: 71.09%] [G loss: 0.737060]\n",
      "epoch:20 step:19061 [D loss: 0.454742, acc.: 81.25%] [G loss: 0.624460]\n",
      "epoch:20 step:19062 [D loss: 0.562134, acc.: 65.62%] [G loss: 0.652052]\n",
      "epoch:20 step:19063 [D loss: 0.615343, acc.: 66.41%] [G loss: 0.632403]\n",
      "epoch:20 step:19064 [D loss: 0.564041, acc.: 63.28%] [G loss: 0.521190]\n",
      "epoch:20 step:19065 [D loss: 0.536805, acc.: 69.53%] [G loss: 0.561753]\n",
      "epoch:20 step:19066 [D loss: 0.475323, acc.: 74.22%] [G loss: 0.610904]\n",
      "epoch:20 step:19067 [D loss: 0.549564, acc.: 69.53%] [G loss: 0.739727]\n",
      "epoch:20 step:19068 [D loss: 0.443914, acc.: 81.25%] [G loss: 0.720472]\n",
      "epoch:20 step:19069 [D loss: 0.565038, acc.: 70.31%] [G loss: 0.629253]\n",
      "epoch:20 step:19070 [D loss: 0.585364, acc.: 64.84%] [G loss: 0.558779]\n",
      "epoch:20 step:19071 [D loss: 0.508649, acc.: 73.44%] [G loss: 0.555116]\n",
      "epoch:20 step:19072 [D loss: 0.529869, acc.: 65.62%] [G loss: 0.558013]\n",
      "epoch:20 step:19073 [D loss: 0.515099, acc.: 72.66%] [G loss: 0.503728]\n",
      "epoch:20 step:19074 [D loss: 0.502272, acc.: 73.44%] [G loss: 0.684106]\n",
      "epoch:20 step:19075 [D loss: 0.475598, acc.: 78.91%] [G loss: 0.773117]\n",
      "epoch:20 step:19076 [D loss: 0.490367, acc.: 78.12%] [G loss: 0.745268]\n",
      "epoch:20 step:19077 [D loss: 0.476385, acc.: 75.00%] [G loss: 0.723503]\n",
      "epoch:20 step:19078 [D loss: 0.528000, acc.: 69.53%] [G loss: 0.656364]\n",
      "epoch:20 step:19079 [D loss: 0.548873, acc.: 71.09%] [G loss: 0.580879]\n",
      "epoch:20 step:19080 [D loss: 0.456781, acc.: 78.12%] [G loss: 0.734088]\n",
      "epoch:20 step:19081 [D loss: 0.647520, acc.: 67.19%] [G loss: 0.608758]\n",
      "epoch:20 step:19082 [D loss: 0.649001, acc.: 57.03%] [G loss: 0.551828]\n",
      "epoch:20 step:19083 [D loss: 0.549467, acc.: 74.22%] [G loss: 0.650277]\n",
      "epoch:20 step:19084 [D loss: 0.467957, acc.: 79.69%] [G loss: 0.806277]\n",
      "epoch:20 step:19085 [D loss: 0.587157, acc.: 65.62%] [G loss: 0.736799]\n",
      "epoch:20 step:19086 [D loss: 0.537301, acc.: 73.44%] [G loss: 0.918168]\n",
      "epoch:20 step:19087 [D loss: 0.464657, acc.: 77.34%] [G loss: 0.921146]\n",
      "epoch:20 step:19088 [D loss: 0.591599, acc.: 65.62%] [G loss: 0.733980]\n",
      "epoch:20 step:19089 [D loss: 0.776359, acc.: 54.69%] [G loss: 0.409599]\n",
      "epoch:20 step:19090 [D loss: 0.477769, acc.: 74.22%] [G loss: 0.681673]\n",
      "epoch:20 step:19091 [D loss: 0.526224, acc.: 74.22%] [G loss: 0.875492]\n",
      "epoch:20 step:19092 [D loss: 0.569512, acc.: 74.22%] [G loss: 0.823278]\n",
      "epoch:20 step:19093 [D loss: 0.558620, acc.: 68.75%] [G loss: 0.594286]\n",
      "epoch:20 step:19094 [D loss: 0.413801, acc.: 79.69%] [G loss: 0.940783]\n",
      "epoch:20 step:19095 [D loss: 0.538454, acc.: 74.22%] [G loss: 0.841792]\n",
      "epoch:20 step:19096 [D loss: 0.585621, acc.: 67.19%] [G loss: 0.632129]\n",
      "epoch:20 step:19097 [D loss: 0.457269, acc.: 78.91%] [G loss: 0.806136]\n",
      "epoch:20 step:19098 [D loss: 0.457102, acc.: 76.56%] [G loss: 0.773302]\n",
      "epoch:20 step:19099 [D loss: 0.464922, acc.: 75.78%] [G loss: 0.796151]\n",
      "epoch:20 step:19100 [D loss: 0.530581, acc.: 71.88%] [G loss: 0.975663]\n",
      "epoch:20 step:19101 [D loss: 0.474312, acc.: 78.12%] [G loss: 0.851657]\n",
      "epoch:20 step:19102 [D loss: 0.530875, acc.: 72.66%] [G loss: 0.704229]\n",
      "epoch:20 step:19103 [D loss: 0.588008, acc.: 66.41%] [G loss: 0.676646]\n",
      "epoch:20 step:19104 [D loss: 0.516811, acc.: 71.88%] [G loss: 0.740880]\n",
      "epoch:20 step:19105 [D loss: 0.561508, acc.: 70.31%] [G loss: 0.706106]\n",
      "epoch:20 step:19106 [D loss: 0.494492, acc.: 74.22%] [G loss: 0.558254]\n",
      "epoch:20 step:19107 [D loss: 0.580228, acc.: 67.97%] [G loss: 0.793547]\n",
      "epoch:20 step:19108 [D loss: 0.581368, acc.: 64.06%] [G loss: 0.778896]\n",
      "epoch:20 step:19109 [D loss: 0.526862, acc.: 67.97%] [G loss: 0.735893]\n",
      "epoch:20 step:19110 [D loss: 0.548004, acc.: 68.75%] [G loss: 0.711383]\n",
      "epoch:20 step:19111 [D loss: 0.466202, acc.: 77.34%] [G loss: 0.712004]\n",
      "epoch:20 step:19112 [D loss: 0.529684, acc.: 69.53%] [G loss: 0.775475]\n",
      "epoch:20 step:19113 [D loss: 0.511288, acc.: 73.44%] [G loss: 0.740379]\n",
      "epoch:20 step:19114 [D loss: 0.391965, acc.: 85.16%] [G loss: 0.933868]\n",
      "epoch:20 step:19115 [D loss: 0.629844, acc.: 66.41%] [G loss: 0.732403]\n",
      "epoch:20 step:19116 [D loss: 0.709887, acc.: 61.72%] [G loss: 0.609864]\n",
      "epoch:20 step:19117 [D loss: 0.548999, acc.: 70.31%] [G loss: 0.544909]\n",
      "epoch:20 step:19118 [D loss: 0.638219, acc.: 59.38%] [G loss: 0.454596]\n",
      "epoch:20 step:19119 [D loss: 0.601151, acc.: 67.19%] [G loss: 0.609978]\n",
      "epoch:20 step:19120 [D loss: 0.614457, acc.: 66.41%] [G loss: 0.524920]\n",
      "epoch:20 step:19121 [D loss: 0.477841, acc.: 77.34%] [G loss: 0.640974]\n",
      "epoch:20 step:19122 [D loss: 0.544033, acc.: 73.44%] [G loss: 0.740193]\n",
      "epoch:20 step:19123 [D loss: 0.541065, acc.: 70.31%] [G loss: 0.567067]\n",
      "epoch:20 step:19124 [D loss: 0.564560, acc.: 70.31%] [G loss: 0.656286]\n",
      "epoch:20 step:19125 [D loss: 0.468794, acc.: 79.69%] [G loss: 0.804609]\n",
      "epoch:20 step:19126 [D loss: 0.583692, acc.: 67.97%] [G loss: 0.681556]\n",
      "epoch:20 step:19127 [D loss: 0.542059, acc.: 67.97%] [G loss: 0.614357]\n",
      "epoch:20 step:19128 [D loss: 0.524047, acc.: 74.22%] [G loss: 0.646306]\n",
      "epoch:20 step:19129 [D loss: 0.530030, acc.: 67.19%] [G loss: 0.690554]\n",
      "epoch:20 step:19130 [D loss: 0.585433, acc.: 66.41%] [G loss: 0.624191]\n",
      "epoch:20 step:19131 [D loss: 0.542965, acc.: 74.22%] [G loss: 0.580695]\n",
      "epoch:20 step:19132 [D loss: 0.542333, acc.: 71.88%] [G loss: 0.746325]\n",
      "epoch:20 step:19133 [D loss: 0.555573, acc.: 70.31%] [G loss: 0.525966]\n",
      "epoch:20 step:19134 [D loss: 0.547744, acc.: 71.88%] [G loss: 0.613753]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:20 step:19135 [D loss: 0.526009, acc.: 72.66%] [G loss: 0.478078]\n",
      "epoch:20 step:19136 [D loss: 0.538613, acc.: 71.88%] [G loss: 0.671985]\n",
      "epoch:20 step:19137 [D loss: 0.549899, acc.: 70.31%] [G loss: 0.728861]\n",
      "epoch:20 step:19138 [D loss: 0.523989, acc.: 68.75%] [G loss: 0.753356]\n",
      "epoch:20 step:19139 [D loss: 0.459077, acc.: 78.12%] [G loss: 0.882511]\n",
      "epoch:20 step:19140 [D loss: 0.624405, acc.: 60.16%] [G loss: 0.701716]\n",
      "epoch:20 step:19141 [D loss: 0.666639, acc.: 59.38%] [G loss: 0.709158]\n",
      "epoch:20 step:19142 [D loss: 0.510844, acc.: 75.78%] [G loss: 0.662251]\n",
      "epoch:20 step:19143 [D loss: 0.486928, acc.: 75.00%] [G loss: 0.988782]\n",
      "epoch:20 step:19144 [D loss: 0.592245, acc.: 66.41%] [G loss: 0.690775]\n",
      "epoch:20 step:19145 [D loss: 0.547783, acc.: 67.19%] [G loss: 0.801335]\n",
      "epoch:20 step:19146 [D loss: 0.508189, acc.: 69.53%] [G loss: 0.761156]\n",
      "epoch:20 step:19147 [D loss: 0.548792, acc.: 67.19%] [G loss: 0.684479]\n",
      "epoch:20 step:19148 [D loss: 0.594274, acc.: 66.41%] [G loss: 0.610092]\n",
      "epoch:20 step:19149 [D loss: 0.562075, acc.: 67.19%] [G loss: 0.812093]\n",
      "epoch:20 step:19150 [D loss: 0.559633, acc.: 67.19%] [G loss: 0.762248]\n",
      "epoch:20 step:19151 [D loss: 0.550248, acc.: 67.19%] [G loss: 0.564088]\n",
      "epoch:20 step:19152 [D loss: 0.598007, acc.: 60.94%] [G loss: 0.640397]\n",
      "epoch:20 step:19153 [D loss: 0.575781, acc.: 70.31%] [G loss: 0.720180]\n",
      "epoch:20 step:19154 [D loss: 0.491724, acc.: 76.56%] [G loss: 0.645467]\n",
      "epoch:20 step:19155 [D loss: 0.531790, acc.: 69.53%] [G loss: 0.864469]\n",
      "epoch:20 step:19156 [D loss: 0.522434, acc.: 71.88%] [G loss: 0.890942]\n",
      "epoch:20 step:19157 [D loss: 0.577819, acc.: 68.75%] [G loss: 0.749620]\n",
      "epoch:20 step:19158 [D loss: 0.618531, acc.: 69.53%] [G loss: 0.646067]\n",
      "epoch:20 step:19159 [D loss: 0.525312, acc.: 75.00%] [G loss: 0.663584]\n",
      "epoch:20 step:19160 [D loss: 0.580585, acc.: 67.97%] [G loss: 0.747198]\n",
      "epoch:20 step:19161 [D loss: 0.545823, acc.: 71.88%] [G loss: 0.763880]\n",
      "epoch:20 step:19162 [D loss: 0.639238, acc.: 64.06%] [G loss: 0.593174]\n",
      "epoch:20 step:19163 [D loss: 0.593074, acc.: 63.28%] [G loss: 0.477507]\n",
      "epoch:20 step:19164 [D loss: 0.570009, acc.: 65.62%] [G loss: 0.601661]\n",
      "epoch:20 step:19165 [D loss: 0.564298, acc.: 70.31%] [G loss: 0.774121]\n",
      "epoch:20 step:19166 [D loss: 0.529582, acc.: 68.75%] [G loss: 0.735430]\n",
      "epoch:20 step:19167 [D loss: 0.515151, acc.: 73.44%] [G loss: 0.738607]\n",
      "epoch:20 step:19168 [D loss: 0.502764, acc.: 75.00%] [G loss: 0.886995]\n",
      "epoch:20 step:19169 [D loss: 0.462441, acc.: 80.47%] [G loss: 0.763769]\n",
      "epoch:20 step:19170 [D loss: 0.509221, acc.: 75.78%] [G loss: 0.897179]\n",
      "epoch:20 step:19171 [D loss: 0.613852, acc.: 66.41%] [G loss: 0.672993]\n",
      "epoch:20 step:19172 [D loss: 0.567518, acc.: 72.66%] [G loss: 0.692847]\n",
      "epoch:20 step:19173 [D loss: 0.595548, acc.: 60.16%] [G loss: 0.604140]\n",
      "epoch:20 step:19174 [D loss: 0.502633, acc.: 75.00%] [G loss: 0.612319]\n",
      "epoch:20 step:19175 [D loss: 0.555595, acc.: 61.72%] [G loss: 0.744888]\n",
      "epoch:20 step:19176 [D loss: 0.492241, acc.: 75.00%] [G loss: 0.829682]\n",
      "epoch:20 step:19177 [D loss: 0.692072, acc.: 63.28%] [G loss: 0.589250]\n",
      "epoch:20 step:19178 [D loss: 0.553043, acc.: 68.75%] [G loss: 0.558756]\n",
      "epoch:20 step:19179 [D loss: 0.525351, acc.: 72.66%] [G loss: 0.567180]\n",
      "epoch:20 step:19180 [D loss: 0.462003, acc.: 77.34%] [G loss: 0.814892]\n",
      "epoch:20 step:19181 [D loss: 0.514786, acc.: 72.66%] [G loss: 0.838082]\n",
      "epoch:20 step:19182 [D loss: 0.563765, acc.: 69.53%] [G loss: 0.777708]\n",
      "epoch:20 step:19183 [D loss: 0.520874, acc.: 77.34%] [G loss: 0.708963]\n",
      "epoch:20 step:19184 [D loss: 0.472344, acc.: 77.34%] [G loss: 0.768314]\n",
      "epoch:20 step:19185 [D loss: 0.561198, acc.: 67.97%] [G loss: 0.845972]\n",
      "epoch:20 step:19186 [D loss: 0.523829, acc.: 70.31%] [G loss: 0.747109]\n",
      "epoch:20 step:19187 [D loss: 0.513434, acc.: 74.22%] [G loss: 0.692498]\n",
      "epoch:20 step:19188 [D loss: 0.501931, acc.: 72.66%] [G loss: 0.644171]\n",
      "epoch:20 step:19189 [D loss: 0.448260, acc.: 79.69%] [G loss: 0.808779]\n",
      "epoch:20 step:19190 [D loss: 0.537906, acc.: 73.44%] [G loss: 0.627247]\n",
      "epoch:20 step:19191 [D loss: 0.428645, acc.: 84.38%] [G loss: 0.911153]\n",
      "epoch:20 step:19192 [D loss: 0.504624, acc.: 71.88%] [G loss: 0.949382]\n",
      "epoch:20 step:19193 [D loss: 0.562831, acc.: 69.53%] [G loss: 0.821364]\n",
      "epoch:20 step:19194 [D loss: 0.549699, acc.: 70.31%] [G loss: 0.606920]\n",
      "epoch:20 step:19195 [D loss: 0.568122, acc.: 68.75%] [G loss: 0.618996]\n",
      "epoch:20 step:19196 [D loss: 0.637372, acc.: 66.41%] [G loss: 0.680922]\n",
      "epoch:20 step:19197 [D loss: 0.540901, acc.: 71.09%] [G loss: 0.688779]\n",
      "epoch:20 step:19198 [D loss: 0.618905, acc.: 67.97%] [G loss: 0.691888]\n",
      "epoch:20 step:19199 [D loss: 0.560871, acc.: 69.53%] [G loss: 0.572477]\n",
      "epoch:20 step:19200 [D loss: 0.483159, acc.: 77.34%] [G loss: 0.765820]\n",
      "##############\n",
      "[2.7929039  1.01376078 6.37588896 4.77577323 3.88091031 5.57982146\n",
      " 4.55834795 4.6727699  4.72073395 4.06053581]\n",
      "##########\n",
      "epoch:20 step:19201 [D loss: 0.510851, acc.: 75.00%] [G loss: 0.733077]\n",
      "epoch:20 step:19202 [D loss: 0.545572, acc.: 69.53%] [G loss: 0.570932]\n",
      "epoch:20 step:19203 [D loss: 0.514150, acc.: 71.88%] [G loss: 0.605361]\n",
      "epoch:20 step:19204 [D loss: 0.536594, acc.: 70.31%] [G loss: 0.741575]\n",
      "epoch:20 step:19205 [D loss: 0.635543, acc.: 64.84%] [G loss: 0.723920]\n",
      "epoch:20 step:19206 [D loss: 0.510165, acc.: 71.88%] [G loss: 0.595878]\n",
      "epoch:20 step:19207 [D loss: 0.513189, acc.: 70.31%] [G loss: 0.626129]\n",
      "epoch:20 step:19208 [D loss: 0.528855, acc.: 71.88%] [G loss: 0.742347]\n",
      "epoch:20 step:19209 [D loss: 0.514930, acc.: 74.22%] [G loss: 0.677533]\n",
      "epoch:20 step:19210 [D loss: 0.511145, acc.: 74.22%] [G loss: 0.786834]\n",
      "epoch:20 step:19211 [D loss: 0.419061, acc.: 80.47%] [G loss: 0.700968]\n",
      "epoch:20 step:19212 [D loss: 0.488072, acc.: 77.34%] [G loss: 0.990640]\n",
      "epoch:20 step:19213 [D loss: 0.681854, acc.: 56.25%] [G loss: 0.761674]\n",
      "epoch:20 step:19214 [D loss: 0.577677, acc.: 67.19%] [G loss: 0.665170]\n",
      "epoch:20 step:19215 [D loss: 0.472861, acc.: 79.69%] [G loss: 1.069477]\n",
      "epoch:20 step:19216 [D loss: 0.523841, acc.: 72.66%] [G loss: 0.946577]\n",
      "epoch:20 step:19217 [D loss: 0.686545, acc.: 63.28%] [G loss: 0.488459]\n",
      "epoch:20 step:19218 [D loss: 0.573528, acc.: 69.53%] [G loss: 0.513252]\n",
      "epoch:20 step:19219 [D loss: 0.520026, acc.: 74.22%] [G loss: 0.614141]\n",
      "epoch:20 step:19220 [D loss: 0.587629, acc.: 70.31%] [G loss: 0.657573]\n",
      "epoch:20 step:19221 [D loss: 0.503734, acc.: 76.56%] [G loss: 0.590135]\n",
      "epoch:20 step:19222 [D loss: 0.611139, acc.: 63.28%] [G loss: 0.543854]\n",
      "epoch:20 step:19223 [D loss: 0.536107, acc.: 71.88%] [G loss: 0.562701]\n",
      "epoch:20 step:19224 [D loss: 0.534174, acc.: 72.66%] [G loss: 0.706852]\n",
      "epoch:20 step:19225 [D loss: 0.498795, acc.: 73.44%] [G loss: 0.716358]\n",
      "epoch:20 step:19226 [D loss: 0.601046, acc.: 66.41%] [G loss: 0.620084]\n",
      "epoch:20 step:19227 [D loss: 0.543326, acc.: 70.31%] [G loss: 0.665767]\n",
      "epoch:20 step:19228 [D loss: 0.519646, acc.: 68.75%] [G loss: 0.720004]\n",
      "epoch:20 step:19229 [D loss: 0.522866, acc.: 70.31%] [G loss: 0.767058]\n",
      "epoch:20 step:19230 [D loss: 0.600652, acc.: 65.62%] [G loss: 0.600311]\n",
      "epoch:20 step:19231 [D loss: 0.556892, acc.: 67.97%] [G loss: 0.671020]\n",
      "epoch:20 step:19232 [D loss: 0.551944, acc.: 74.22%] [G loss: 0.746123]\n",
      "epoch:20 step:19233 [D loss: 0.584931, acc.: 62.50%] [G loss: 0.541397]\n",
      "epoch:20 step:19234 [D loss: 0.670417, acc.: 65.62%] [G loss: 0.509229]\n",
      "epoch:20 step:19235 [D loss: 0.496693, acc.: 78.12%] [G loss: 0.636375]\n",
      "epoch:20 step:19236 [D loss: 0.551284, acc.: 72.66%] [G loss: 0.664303]\n",
      "epoch:20 step:19237 [D loss: 0.548926, acc.: 75.00%] [G loss: 0.564636]\n",
      "epoch:20 step:19238 [D loss: 0.521432, acc.: 71.09%] [G loss: 0.739872]\n",
      "epoch:20 step:19239 [D loss: 0.473909, acc.: 81.25%] [G loss: 0.628211]\n",
      "epoch:20 step:19240 [D loss: 0.581247, acc.: 67.97%] [G loss: 0.620756]\n",
      "epoch:20 step:19241 [D loss: 0.584328, acc.: 67.19%] [G loss: 0.606716]\n",
      "epoch:20 step:19242 [D loss: 0.623774, acc.: 60.94%] [G loss: 0.569217]\n",
      "epoch:20 step:19243 [D loss: 0.487275, acc.: 77.34%] [G loss: 0.728240]\n",
      "epoch:20 step:19244 [D loss: 0.522683, acc.: 71.88%] [G loss: 0.671185]\n",
      "epoch:20 step:19245 [D loss: 0.504923, acc.: 75.78%] [G loss: 0.773789]\n",
      "epoch:20 step:19246 [D loss: 0.504500, acc.: 77.34%] [G loss: 0.650979]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:20 step:19247 [D loss: 0.496423, acc.: 72.66%] [G loss: 0.853210]\n",
      "epoch:20 step:19248 [D loss: 0.463022, acc.: 82.03%] [G loss: 0.919919]\n",
      "epoch:20 step:19249 [D loss: 0.561443, acc.: 72.66%] [G loss: 0.797161]\n",
      "epoch:20 step:19250 [D loss: 0.611116, acc.: 68.75%] [G loss: 0.703064]\n",
      "epoch:20 step:19251 [D loss: 0.659349, acc.: 59.38%] [G loss: 0.567213]\n",
      "epoch:20 step:19252 [D loss: 0.550094, acc.: 68.75%] [G loss: 0.564864]\n",
      "epoch:20 step:19253 [D loss: 0.540499, acc.: 71.09%] [G loss: 0.529511]\n",
      "epoch:20 step:19254 [D loss: 0.445846, acc.: 79.69%] [G loss: 0.697883]\n",
      "epoch:20 step:19255 [D loss: 0.515875, acc.: 71.88%] [G loss: 0.669998]\n",
      "epoch:20 step:19256 [D loss: 0.480944, acc.: 75.78%] [G loss: 0.686910]\n",
      "epoch:20 step:19257 [D loss: 0.456379, acc.: 81.25%] [G loss: 0.713519]\n",
      "epoch:20 step:19258 [D loss: 0.563380, acc.: 71.88%] [G loss: 0.670329]\n",
      "epoch:20 step:19259 [D loss: 0.529646, acc.: 72.66%] [G loss: 0.703823]\n",
      "epoch:20 step:19260 [D loss: 0.538165, acc.: 70.31%] [G loss: 0.694826]\n",
      "epoch:20 step:19261 [D loss: 0.505645, acc.: 74.22%] [G loss: 0.795665]\n",
      "epoch:20 step:19262 [D loss: 0.485620, acc.: 74.22%] [G loss: 0.807501]\n",
      "epoch:20 step:19263 [D loss: 0.503075, acc.: 71.88%] [G loss: 0.756256]\n",
      "epoch:20 step:19264 [D loss: 0.551838, acc.: 67.97%] [G loss: 0.790740]\n",
      "epoch:20 step:19265 [D loss: 0.546583, acc.: 73.44%] [G loss: 0.656244]\n",
      "epoch:20 step:19266 [D loss: 0.486488, acc.: 78.12%] [G loss: 0.734088]\n",
      "epoch:20 step:19267 [D loss: 0.574454, acc.: 69.53%] [G loss: 0.654116]\n",
      "epoch:20 step:19268 [D loss: 0.682357, acc.: 64.06%] [G loss: 0.619745]\n",
      "epoch:20 step:19269 [D loss: 0.585920, acc.: 64.06%] [G loss: 0.573893]\n",
      "epoch:20 step:19270 [D loss: 0.536567, acc.: 68.75%] [G loss: 0.635802]\n",
      "epoch:20 step:19271 [D loss: 0.579795, acc.: 65.62%] [G loss: 0.599688]\n",
      "epoch:20 step:19272 [D loss: 0.581688, acc.: 63.28%] [G loss: 0.503134]\n",
      "epoch:20 step:19273 [D loss: 0.531379, acc.: 67.97%] [G loss: 0.729923]\n",
      "epoch:20 step:19274 [D loss: 0.511313, acc.: 71.09%] [G loss: 0.727945]\n",
      "epoch:20 step:19275 [D loss: 0.624853, acc.: 58.59%] [G loss: 0.609700]\n",
      "epoch:20 step:19276 [D loss: 0.499547, acc.: 71.09%] [G loss: 0.699837]\n",
      "epoch:20 step:19277 [D loss: 0.562547, acc.: 64.84%] [G loss: 0.510295]\n",
      "epoch:20 step:19278 [D loss: 0.529007, acc.: 70.31%] [G loss: 0.797228]\n",
      "epoch:20 step:19279 [D loss: 0.553294, acc.: 67.19%] [G loss: 0.685224]\n",
      "epoch:20 step:19280 [D loss: 0.526568, acc.: 71.09%] [G loss: 0.774061]\n",
      "epoch:20 step:19281 [D loss: 0.524411, acc.: 76.56%] [G loss: 0.616780]\n",
      "epoch:20 step:19282 [D loss: 0.645845, acc.: 63.28%] [G loss: 0.488111]\n",
      "epoch:20 step:19283 [D loss: 0.560337, acc.: 67.97%] [G loss: 0.608269]\n",
      "epoch:20 step:19284 [D loss: 0.611790, acc.: 64.06%] [G loss: 0.580199]\n",
      "epoch:20 step:19285 [D loss: 0.558221, acc.: 71.88%] [G loss: 0.741041]\n",
      "epoch:20 step:19286 [D loss: 0.502405, acc.: 73.44%] [G loss: 0.923891]\n",
      "epoch:20 step:19287 [D loss: 0.553474, acc.: 75.00%] [G loss: 0.758837]\n",
      "epoch:20 step:19288 [D loss: 0.471423, acc.: 76.56%] [G loss: 0.758879]\n",
      "epoch:20 step:19289 [D loss: 0.516758, acc.: 75.78%] [G loss: 0.778880]\n",
      "epoch:20 step:19290 [D loss: 0.492541, acc.: 77.34%] [G loss: 0.712690]\n",
      "epoch:20 step:19291 [D loss: 0.518174, acc.: 74.22%] [G loss: 0.787738]\n",
      "epoch:20 step:19292 [D loss: 0.492392, acc.: 72.66%] [G loss: 0.677605]\n",
      "epoch:20 step:19293 [D loss: 0.558787, acc.: 69.53%] [G loss: 0.615724]\n",
      "epoch:20 step:19294 [D loss: 0.470258, acc.: 76.56%] [G loss: 0.670886]\n",
      "epoch:20 step:19295 [D loss: 0.489824, acc.: 75.00%] [G loss: 0.757985]\n",
      "epoch:20 step:19296 [D loss: 0.580160, acc.: 65.62%] [G loss: 0.758998]\n",
      "epoch:20 step:19297 [D loss: 0.521151, acc.: 74.22%] [G loss: 0.712974]\n",
      "epoch:20 step:19298 [D loss: 0.452087, acc.: 77.34%] [G loss: 0.706391]\n",
      "epoch:20 step:19299 [D loss: 0.553781, acc.: 67.97%] [G loss: 0.678339]\n",
      "epoch:20 step:19300 [D loss: 0.605331, acc.: 68.75%] [G loss: 0.493667]\n",
      "epoch:20 step:19301 [D loss: 0.517372, acc.: 73.44%] [G loss: 0.742949]\n",
      "epoch:20 step:19302 [D loss: 0.552130, acc.: 67.97%] [G loss: 0.817049]\n",
      "epoch:20 step:19303 [D loss: 0.535471, acc.: 71.88%] [G loss: 0.595720]\n",
      "epoch:20 step:19304 [D loss: 0.505163, acc.: 74.22%] [G loss: 0.618099]\n",
      "epoch:20 step:19305 [D loss: 0.539108, acc.: 76.56%] [G loss: 0.761948]\n",
      "epoch:20 step:19306 [D loss: 0.668819, acc.: 63.28%] [G loss: 0.512639]\n",
      "epoch:20 step:19307 [D loss: 0.480306, acc.: 73.44%] [G loss: 0.693735]\n",
      "epoch:20 step:19308 [D loss: 0.526308, acc.: 81.25%] [G loss: 0.689759]\n",
      "epoch:20 step:19309 [D loss: 0.566469, acc.: 74.22%] [G loss: 0.610881]\n",
      "epoch:20 step:19310 [D loss: 0.505165, acc.: 72.66%] [G loss: 0.589821]\n",
      "epoch:20 step:19311 [D loss: 0.533880, acc.: 71.09%] [G loss: 0.709797]\n",
      "epoch:20 step:19312 [D loss: 0.509375, acc.: 74.22%] [G loss: 0.651012]\n",
      "epoch:20 step:19313 [D loss: 0.594454, acc.: 67.97%] [G loss: 0.792104]\n",
      "epoch:20 step:19314 [D loss: 0.489976, acc.: 76.56%] [G loss: 0.687684]\n",
      "epoch:20 step:19315 [D loss: 0.497253, acc.: 73.44%] [G loss: 0.749673]\n",
      "epoch:20 step:19316 [D loss: 0.609978, acc.: 64.06%] [G loss: 0.561671]\n",
      "epoch:20 step:19317 [D loss: 0.537354, acc.: 71.88%] [G loss: 0.625103]\n",
      "epoch:20 step:19318 [D loss: 0.564206, acc.: 65.62%] [G loss: 0.657454]\n",
      "epoch:20 step:19319 [D loss: 0.550252, acc.: 65.62%] [G loss: 0.655787]\n",
      "epoch:20 step:19320 [D loss: 0.531762, acc.: 74.22%] [G loss: 0.509104]\n",
      "epoch:20 step:19321 [D loss: 0.506450, acc.: 72.66%] [G loss: 0.750858]\n",
      "epoch:20 step:19322 [D loss: 0.498695, acc.: 75.78%] [G loss: 0.570589]\n",
      "epoch:20 step:19323 [D loss: 0.540831, acc.: 67.97%] [G loss: 0.655845]\n",
      "epoch:20 step:19324 [D loss: 0.594203, acc.: 64.06%] [G loss: 0.566431]\n",
      "epoch:20 step:19325 [D loss: 0.533502, acc.: 71.09%] [G loss: 0.516369]\n",
      "epoch:20 step:19326 [D loss: 0.573106, acc.: 65.62%] [G loss: 0.515733]\n",
      "epoch:20 step:19327 [D loss: 0.581513, acc.: 66.41%] [G loss: 0.497138]\n",
      "epoch:20 step:19328 [D loss: 0.571290, acc.: 67.19%] [G loss: 0.612562]\n",
      "epoch:20 step:19329 [D loss: 0.562033, acc.: 64.06%] [G loss: 0.673756]\n",
      "epoch:20 step:19330 [D loss: 0.544397, acc.: 68.75%] [G loss: 0.634137]\n",
      "epoch:20 step:19331 [D loss: 0.560945, acc.: 74.22%] [G loss: 0.710502]\n",
      "epoch:20 step:19332 [D loss: 0.478483, acc.: 78.12%] [G loss: 0.692556]\n",
      "epoch:20 step:19333 [D loss: 0.520805, acc.: 72.66%] [G loss: 0.678948]\n",
      "epoch:20 step:19334 [D loss: 0.599754, acc.: 69.53%] [G loss: 0.632745]\n",
      "epoch:20 step:19335 [D loss: 0.514272, acc.: 76.56%] [G loss: 0.616043]\n",
      "epoch:20 step:19336 [D loss: 0.564346, acc.: 67.19%] [G loss: 0.708832]\n",
      "epoch:20 step:19337 [D loss: 0.560756, acc.: 70.31%] [G loss: 0.547280]\n",
      "epoch:20 step:19338 [D loss: 0.474075, acc.: 79.69%] [G loss: 0.682404]\n",
      "epoch:20 step:19339 [D loss: 0.562407, acc.: 70.31%] [G loss: 0.589117]\n",
      "epoch:20 step:19340 [D loss: 0.568483, acc.: 69.53%] [G loss: 0.622130]\n",
      "epoch:20 step:19341 [D loss: 0.538390, acc.: 74.22%] [G loss: 0.650852]\n",
      "epoch:20 step:19342 [D loss: 0.558769, acc.: 67.97%] [G loss: 0.853710]\n",
      "epoch:20 step:19343 [D loss: 0.505762, acc.: 73.44%] [G loss: 0.694858]\n",
      "epoch:20 step:19344 [D loss: 0.545791, acc.: 67.97%] [G loss: 0.667989]\n",
      "epoch:20 step:19345 [D loss: 0.433456, acc.: 80.47%] [G loss: 0.630818]\n",
      "epoch:20 step:19346 [D loss: 0.587697, acc.: 66.41%] [G loss: 0.501800]\n",
      "epoch:20 step:19347 [D loss: 0.521320, acc.: 69.53%] [G loss: 0.668560]\n",
      "epoch:20 step:19348 [D loss: 0.578376, acc.: 65.62%] [G loss: 0.622889]\n",
      "epoch:20 step:19349 [D loss: 0.546942, acc.: 70.31%] [G loss: 0.522887]\n",
      "epoch:20 step:19350 [D loss: 0.574724, acc.: 66.41%] [G loss: 0.480477]\n",
      "epoch:20 step:19351 [D loss: 0.527980, acc.: 71.88%] [G loss: 0.491190]\n",
      "epoch:20 step:19352 [D loss: 0.548554, acc.: 70.31%] [G loss: 0.490156]\n",
      "epoch:20 step:19353 [D loss: 0.485037, acc.: 74.22%] [G loss: 0.559903]\n",
      "epoch:20 step:19354 [D loss: 0.559717, acc.: 67.97%] [G loss: 0.560366]\n",
      "epoch:20 step:19355 [D loss: 0.581360, acc.: 67.97%] [G loss: 0.690328]\n",
      "epoch:20 step:19356 [D loss: 0.598472, acc.: 67.97%] [G loss: 0.582584]\n",
      "epoch:20 step:19357 [D loss: 0.528572, acc.: 71.88%] [G loss: 0.682561]\n",
      "epoch:20 step:19358 [D loss: 0.587344, acc.: 67.19%] [G loss: 0.687566]\n",
      "epoch:20 step:19359 [D loss: 0.600026, acc.: 64.06%] [G loss: 0.689440]\n",
      "epoch:20 step:19360 [D loss: 0.525903, acc.: 69.53%] [G loss: 0.776771]\n",
      "epoch:20 step:19361 [D loss: 0.572694, acc.: 67.19%] [G loss: 0.577312]\n",
      "epoch:20 step:19362 [D loss: 0.541707, acc.: 71.09%] [G loss: 0.601260]\n",
      "epoch:20 step:19363 [D loss: 0.504259, acc.: 74.22%] [G loss: 0.641359]\n",
      "epoch:20 step:19364 [D loss: 0.520355, acc.: 74.22%] [G loss: 0.881764]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:20 step:19365 [D loss: 0.601595, acc.: 64.84%] [G loss: 0.737266]\n",
      "epoch:20 step:19366 [D loss: 0.561614, acc.: 69.53%] [G loss: 0.643758]\n",
      "epoch:20 step:19367 [D loss: 0.561791, acc.: 67.97%] [G loss: 0.543858]\n",
      "epoch:20 step:19368 [D loss: 0.574776, acc.: 67.97%] [G loss: 0.516636]\n",
      "epoch:20 step:19369 [D loss: 0.507855, acc.: 70.31%] [G loss: 0.605318]\n",
      "epoch:20 step:19370 [D loss: 0.541427, acc.: 67.97%] [G loss: 0.474290]\n",
      "epoch:20 step:19371 [D loss: 0.471304, acc.: 72.66%] [G loss: 0.655746]\n",
      "epoch:20 step:19372 [D loss: 0.476914, acc.: 78.91%] [G loss: 0.639186]\n",
      "epoch:20 step:19373 [D loss: 0.514081, acc.: 70.31%] [G loss: 0.730085]\n",
      "epoch:20 step:19374 [D loss: 0.480773, acc.: 78.12%] [G loss: 0.717520]\n",
      "epoch:20 step:19375 [D loss: 0.496484, acc.: 73.44%] [G loss: 0.721405]\n",
      "epoch:20 step:19376 [D loss: 0.601159, acc.: 71.09%] [G loss: 0.480403]\n",
      "epoch:20 step:19377 [D loss: 0.547994, acc.: 69.53%] [G loss: 0.467542]\n",
      "epoch:20 step:19378 [D loss: 0.525957, acc.: 71.88%] [G loss: 0.557799]\n",
      "epoch:20 step:19379 [D loss: 0.510216, acc.: 69.53%] [G loss: 0.668661]\n",
      "epoch:20 step:19380 [D loss: 0.570487, acc.: 64.06%] [G loss: 0.682067]\n",
      "epoch:20 step:19381 [D loss: 0.500955, acc.: 73.44%] [G loss: 0.844938]\n",
      "epoch:20 step:19382 [D loss: 0.475937, acc.: 73.44%] [G loss: 1.041593]\n",
      "epoch:20 step:19383 [D loss: 0.528753, acc.: 70.31%] [G loss: 0.767599]\n",
      "epoch:20 step:19384 [D loss: 0.550370, acc.: 70.31%] [G loss: 0.683373]\n",
      "epoch:20 step:19385 [D loss: 0.570275, acc.: 66.41%] [G loss: 0.656900]\n",
      "epoch:20 step:19386 [D loss: 0.534087, acc.: 71.88%] [G loss: 0.737169]\n",
      "epoch:20 step:19387 [D loss: 0.448635, acc.: 78.91%] [G loss: 0.901671]\n",
      "epoch:20 step:19388 [D loss: 0.381829, acc.: 87.50%] [G loss: 0.922579]\n",
      "epoch:20 step:19389 [D loss: 0.520636, acc.: 74.22%] [G loss: 0.863209]\n",
      "epoch:20 step:19390 [D loss: 0.483090, acc.: 74.22%] [G loss: 0.748653]\n",
      "epoch:20 step:19391 [D loss: 0.502814, acc.: 76.56%] [G loss: 0.753902]\n",
      "epoch:20 step:19392 [D loss: 0.658515, acc.: 65.62%] [G loss: 0.771330]\n",
      "epoch:20 step:19393 [D loss: 0.609299, acc.: 64.06%] [G loss: 0.579914]\n",
      "epoch:20 step:19394 [D loss: 0.488930, acc.: 72.66%] [G loss: 0.686247]\n",
      "epoch:20 step:19395 [D loss: 0.544104, acc.: 70.31%] [G loss: 0.717110]\n",
      "epoch:20 step:19396 [D loss: 0.535295, acc.: 74.22%] [G loss: 0.692122]\n",
      "epoch:20 step:19397 [D loss: 0.501828, acc.: 71.09%] [G loss: 0.720088]\n",
      "epoch:20 step:19398 [D loss: 0.568874, acc.: 69.53%] [G loss: 0.694407]\n",
      "epoch:20 step:19399 [D loss: 0.563944, acc.: 73.44%] [G loss: 0.703209]\n",
      "epoch:20 step:19400 [D loss: 0.504736, acc.: 72.66%] [G loss: 0.635508]\n",
      "##############\n",
      "[2.98572903 1.2075902  6.45881409 4.98335605 3.9494644  5.86761191\n",
      " 4.46466329 4.77856924 4.82311323 4.26656954]\n",
      "##########\n",
      "epoch:20 step:19401 [D loss: 0.469362, acc.: 75.00%] [G loss: 0.704483]\n",
      "epoch:20 step:19402 [D loss: 0.575948, acc.: 70.31%] [G loss: 0.643372]\n",
      "epoch:20 step:19403 [D loss: 0.518912, acc.: 71.88%] [G loss: 0.705417]\n",
      "epoch:20 step:19404 [D loss: 0.577082, acc.: 67.97%] [G loss: 0.665843]\n",
      "epoch:20 step:19405 [D loss: 0.526992, acc.: 69.53%] [G loss: 0.632299]\n",
      "epoch:20 step:19406 [D loss: 0.491284, acc.: 74.22%] [G loss: 0.693351]\n",
      "epoch:20 step:19407 [D loss: 0.537791, acc.: 75.00%] [G loss: 0.685982]\n",
      "epoch:20 step:19408 [D loss: 0.559272, acc.: 75.00%] [G loss: 0.658498]\n",
      "epoch:20 step:19409 [D loss: 0.492309, acc.: 75.00%] [G loss: 0.655537]\n",
      "epoch:20 step:19410 [D loss: 0.505782, acc.: 72.66%] [G loss: 0.628896]\n",
      "epoch:20 step:19411 [D loss: 0.523547, acc.: 74.22%] [G loss: 0.806356]\n",
      "epoch:20 step:19412 [D loss: 0.599782, acc.: 64.84%] [G loss: 0.596331]\n",
      "epoch:20 step:19413 [D loss: 0.534269, acc.: 71.09%] [G loss: 0.668887]\n",
      "epoch:20 step:19414 [D loss: 0.587510, acc.: 67.19%] [G loss: 0.754784]\n",
      "epoch:20 step:19415 [D loss: 0.635354, acc.: 66.41%] [G loss: 0.742969]\n",
      "epoch:20 step:19416 [D loss: 0.533394, acc.: 70.31%] [G loss: 0.765996]\n",
      "epoch:20 step:19417 [D loss: 0.511247, acc.: 73.44%] [G loss: 0.754799]\n",
      "epoch:20 step:19418 [D loss: 0.554900, acc.: 69.53%] [G loss: 0.580590]\n",
      "epoch:20 step:19419 [D loss: 0.497912, acc.: 77.34%] [G loss: 0.620852]\n",
      "epoch:20 step:19420 [D loss: 0.529848, acc.: 72.66%] [G loss: 0.500330]\n",
      "epoch:20 step:19421 [D loss: 0.467841, acc.: 78.91%] [G loss: 0.713702]\n",
      "epoch:20 step:19422 [D loss: 0.561535, acc.: 67.19%] [G loss: 0.559467]\n",
      "epoch:20 step:19423 [D loss: 0.528765, acc.: 71.09%] [G loss: 0.584851]\n",
      "epoch:20 step:19424 [D loss: 0.613243, acc.: 67.19%] [G loss: 0.503076]\n",
      "epoch:20 step:19425 [D loss: 0.522490, acc.: 70.31%] [G loss: 0.594468]\n",
      "epoch:20 step:19426 [D loss: 0.640399, acc.: 63.28%] [G loss: 0.432862]\n",
      "epoch:20 step:19427 [D loss: 0.567835, acc.: 64.84%] [G loss: 0.577292]\n",
      "epoch:20 step:19428 [D loss: 0.572331, acc.: 67.97%] [G loss: 0.431732]\n",
      "epoch:20 step:19429 [D loss: 0.571977, acc.: 67.97%] [G loss: 0.661159]\n",
      "epoch:20 step:19430 [D loss: 0.478335, acc.: 78.91%] [G loss: 0.791483]\n",
      "epoch:20 step:19431 [D loss: 0.545748, acc.: 70.31%] [G loss: 0.646215]\n",
      "epoch:20 step:19432 [D loss: 0.547204, acc.: 73.44%] [G loss: 0.624141]\n",
      "epoch:20 step:19433 [D loss: 0.502873, acc.: 77.34%] [G loss: 0.712147]\n",
      "epoch:20 step:19434 [D loss: 0.527978, acc.: 75.00%] [G loss: 0.752647]\n",
      "epoch:20 step:19435 [D loss: 0.501473, acc.: 78.12%] [G loss: 0.806098]\n",
      "epoch:20 step:19436 [D loss: 0.587915, acc.: 63.28%] [G loss: 0.672394]\n",
      "epoch:20 step:19437 [D loss: 0.516555, acc.: 71.88%] [G loss: 0.644656]\n",
      "epoch:20 step:19438 [D loss: 0.603727, acc.: 64.06%] [G loss: 0.565287]\n",
      "epoch:20 step:19439 [D loss: 0.507748, acc.: 74.22%] [G loss: 0.585908]\n",
      "epoch:20 step:19440 [D loss: 0.490039, acc.: 78.91%] [G loss: 0.702750]\n",
      "epoch:20 step:19441 [D loss: 0.490840, acc.: 77.34%] [G loss: 0.904296]\n",
      "epoch:20 step:19442 [D loss: 0.535125, acc.: 71.88%] [G loss: 0.563089]\n",
      "epoch:20 step:19443 [D loss: 0.602109, acc.: 66.41%] [G loss: 0.613933]\n",
      "epoch:20 step:19444 [D loss: 0.561774, acc.: 67.19%] [G loss: 0.525282]\n",
      "epoch:20 step:19445 [D loss: 0.529601, acc.: 71.88%] [G loss: 0.493212]\n",
      "epoch:20 step:19446 [D loss: 0.566543, acc.: 71.09%] [G loss: 0.685426]\n",
      "epoch:20 step:19447 [D loss: 0.505071, acc.: 69.53%] [G loss: 0.731284]\n",
      "epoch:20 step:19448 [D loss: 0.519929, acc.: 75.00%] [G loss: 0.692570]\n",
      "epoch:20 step:19449 [D loss: 0.551236, acc.: 67.97%] [G loss: 0.735612]\n",
      "epoch:20 step:19450 [D loss: 0.584199, acc.: 64.06%] [G loss: 0.609023]\n",
      "epoch:20 step:19451 [D loss: 0.610416, acc.: 64.06%] [G loss: 0.612027]\n",
      "epoch:20 step:19452 [D loss: 0.539892, acc.: 71.09%] [G loss: 0.636303]\n",
      "epoch:20 step:19453 [D loss: 0.556301, acc.: 70.31%] [G loss: 0.637401]\n",
      "epoch:20 step:19454 [D loss: 0.513134, acc.: 70.31%] [G loss: 0.587176]\n",
      "epoch:20 step:19455 [D loss: 0.546747, acc.: 73.44%] [G loss: 0.614822]\n",
      "epoch:20 step:19456 [D loss: 0.551116, acc.: 71.09%] [G loss: 0.594597]\n",
      "epoch:20 step:19457 [D loss: 0.564871, acc.: 70.31%] [G loss: 0.562240]\n",
      "epoch:20 step:19458 [D loss: 0.594053, acc.: 62.50%] [G loss: 0.455844]\n",
      "epoch:20 step:19459 [D loss: 0.466976, acc.: 77.34%] [G loss: 0.728761]\n",
      "epoch:20 step:19460 [D loss: 0.605883, acc.: 65.62%] [G loss: 0.525388]\n",
      "epoch:20 step:19461 [D loss: 0.526115, acc.: 72.66%] [G loss: 0.593802]\n",
      "epoch:20 step:19462 [D loss: 0.585311, acc.: 68.75%] [G loss: 0.574073]\n",
      "epoch:20 step:19463 [D loss: 0.586476, acc.: 67.97%] [G loss: 0.684736]\n",
      "epoch:20 step:19464 [D loss: 0.495548, acc.: 74.22%] [G loss: 0.581248]\n",
      "epoch:20 step:19465 [D loss: 0.487635, acc.: 76.56%] [G loss: 0.680057]\n",
      "epoch:20 step:19466 [D loss: 0.534225, acc.: 73.44%] [G loss: 0.610018]\n",
      "epoch:20 step:19467 [D loss: 0.565797, acc.: 71.88%] [G loss: 0.704243]\n",
      "epoch:20 step:19468 [D loss: 0.569525, acc.: 65.62%] [G loss: 0.541641]\n",
      "epoch:20 step:19469 [D loss: 0.604920, acc.: 64.06%] [G loss: 0.623753]\n",
      "epoch:20 step:19470 [D loss: 0.536722, acc.: 70.31%] [G loss: 0.607659]\n",
      "epoch:20 step:19471 [D loss: 0.584518, acc.: 65.62%] [G loss: 0.514384]\n",
      "epoch:20 step:19472 [D loss: 0.491929, acc.: 74.22%] [G loss: 0.537378]\n",
      "epoch:20 step:19473 [D loss: 0.571921, acc.: 70.31%] [G loss: 0.443529]\n",
      "epoch:20 step:19474 [D loss: 0.525559, acc.: 71.88%] [G loss: 0.558643]\n",
      "epoch:20 step:19475 [D loss: 0.561181, acc.: 66.41%] [G loss: 0.673097]\n",
      "epoch:20 step:19476 [D loss: 0.493766, acc.: 74.22%] [G loss: 0.712042]\n",
      "epoch:20 step:19477 [D loss: 0.534827, acc.: 75.00%] [G loss: 0.540477]\n",
      "epoch:20 step:19478 [D loss: 0.559895, acc.: 64.06%] [G loss: 0.681014]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:20 step:19479 [D loss: 0.551550, acc.: 71.09%] [G loss: 0.592676]\n",
      "epoch:20 step:19480 [D loss: 0.671318, acc.: 60.16%] [G loss: 0.449802]\n",
      "epoch:20 step:19481 [D loss: 0.548197, acc.: 70.31%] [G loss: 0.630578]\n",
      "epoch:20 step:19482 [D loss: 0.555578, acc.: 68.75%] [G loss: 0.711168]\n",
      "epoch:20 step:19483 [D loss: 0.549588, acc.: 69.53%] [G loss: 0.712334]\n",
      "epoch:20 step:19484 [D loss: 0.615302, acc.: 68.75%] [G loss: 0.706986]\n",
      "epoch:20 step:19485 [D loss: 0.572904, acc.: 65.62%] [G loss: 0.717657]\n",
      "epoch:20 step:19486 [D loss: 0.491806, acc.: 75.00%] [G loss: 0.717191]\n",
      "epoch:20 step:19487 [D loss: 0.406562, acc.: 81.25%] [G loss: 0.748535]\n",
      "epoch:20 step:19488 [D loss: 0.506917, acc.: 71.88%] [G loss: 0.728443]\n",
      "epoch:20 step:19489 [D loss: 0.539950, acc.: 69.53%] [G loss: 0.681679]\n",
      "epoch:20 step:19490 [D loss: 0.486479, acc.: 78.12%] [G loss: 0.512353]\n",
      "epoch:20 step:19491 [D loss: 0.520495, acc.: 71.88%] [G loss: 0.653750]\n",
      "epoch:20 step:19492 [D loss: 0.570903, acc.: 67.97%] [G loss: 0.681981]\n",
      "epoch:20 step:19493 [D loss: 0.456501, acc.: 80.47%] [G loss: 0.618871]\n",
      "epoch:20 step:19494 [D loss: 0.541805, acc.: 67.97%] [G loss: 0.794822]\n",
      "epoch:20 step:19495 [D loss: 0.561866, acc.: 69.53%] [G loss: 0.704510]\n",
      "epoch:20 step:19496 [D loss: 0.560531, acc.: 67.97%] [G loss: 0.652289]\n",
      "epoch:20 step:19497 [D loss: 0.526516, acc.: 68.75%] [G loss: 0.648712]\n",
      "epoch:20 step:19498 [D loss: 0.549152, acc.: 71.09%] [G loss: 0.598935]\n",
      "epoch:20 step:19499 [D loss: 0.526650, acc.: 72.66%] [G loss: 0.651291]\n",
      "epoch:20 step:19500 [D loss: 0.542798, acc.: 69.53%] [G loss: 0.787263]\n",
      "epoch:20 step:19501 [D loss: 0.529891, acc.: 71.88%] [G loss: 0.687037]\n",
      "epoch:20 step:19502 [D loss: 0.640237, acc.: 64.84%] [G loss: 0.628445]\n",
      "epoch:20 step:19503 [D loss: 0.550542, acc.: 75.00%] [G loss: 0.656449]\n",
      "epoch:20 step:19504 [D loss: 0.588682, acc.: 65.62%] [G loss: 0.601572]\n",
      "epoch:20 step:19505 [D loss: 0.585796, acc.: 63.28%] [G loss: 0.652204]\n",
      "epoch:20 step:19506 [D loss: 0.604163, acc.: 69.53%] [G loss: 0.492252]\n",
      "epoch:20 step:19507 [D loss: 0.513676, acc.: 73.44%] [G loss: 0.519843]\n",
      "epoch:20 step:19508 [D loss: 0.580045, acc.: 65.62%] [G loss: 0.645133]\n",
      "epoch:20 step:19509 [D loss: 0.511795, acc.: 68.75%] [G loss: 0.720332]\n",
      "epoch:20 step:19510 [D loss: 0.508415, acc.: 72.66%] [G loss: 0.834466]\n",
      "epoch:20 step:19511 [D loss: 0.547872, acc.: 71.09%] [G loss: 0.975010]\n",
      "epoch:20 step:19512 [D loss: 0.531495, acc.: 72.66%] [G loss: 0.661816]\n",
      "epoch:20 step:19513 [D loss: 0.543501, acc.: 67.97%] [G loss: 0.642914]\n",
      "epoch:20 step:19514 [D loss: 0.516150, acc.: 74.22%] [G loss: 0.666936]\n",
      "epoch:20 step:19515 [D loss: 0.546832, acc.: 70.31%] [G loss: 0.652208]\n",
      "epoch:20 step:19516 [D loss: 0.538262, acc.: 71.88%] [G loss: 0.594326]\n",
      "epoch:20 step:19517 [D loss: 0.546347, acc.: 69.53%] [G loss: 0.556440]\n",
      "epoch:20 step:19518 [D loss: 0.576355, acc.: 68.75%] [G loss: 0.490502]\n",
      "epoch:20 step:19519 [D loss: 0.550034, acc.: 69.53%] [G loss: 0.624882]\n",
      "epoch:20 step:19520 [D loss: 0.566996, acc.: 69.53%] [G loss: 0.715535]\n",
      "epoch:20 step:19521 [D loss: 0.528565, acc.: 76.56%] [G loss: 0.799642]\n",
      "epoch:20 step:19522 [D loss: 0.549769, acc.: 71.88%] [G loss: 0.948479]\n",
      "epoch:20 step:19523 [D loss: 0.573989, acc.: 66.41%] [G loss: 0.973458]\n",
      "epoch:20 step:19524 [D loss: 0.632718, acc.: 60.94%] [G loss: 0.645901]\n",
      "epoch:20 step:19525 [D loss: 0.524804, acc.: 72.66%] [G loss: 0.542565]\n",
      "epoch:20 step:19526 [D loss: 0.507209, acc.: 73.44%] [G loss: 0.613920]\n",
      "epoch:20 step:19527 [D loss: 0.602951, acc.: 64.84%] [G loss: 0.628754]\n",
      "epoch:20 step:19528 [D loss: 0.634908, acc.: 66.41%] [G loss: 0.576378]\n",
      "epoch:20 step:19529 [D loss: 0.505715, acc.: 72.66%] [G loss: 0.795926]\n",
      "epoch:20 step:19530 [D loss: 0.508737, acc.: 72.66%] [G loss: 0.684965]\n",
      "epoch:20 step:19531 [D loss: 0.539302, acc.: 74.22%] [G loss: 0.597982]\n",
      "epoch:20 step:19532 [D loss: 0.464190, acc.: 78.91%] [G loss: 0.735864]\n",
      "epoch:20 step:19533 [D loss: 0.606479, acc.: 64.06%] [G loss: 0.613332]\n",
      "epoch:20 step:19534 [D loss: 0.620697, acc.: 63.28%] [G loss: 0.625880]\n",
      "epoch:20 step:19535 [D loss: 0.509327, acc.: 74.22%] [G loss: 0.764163]\n",
      "epoch:20 step:19536 [D loss: 0.529444, acc.: 72.66%] [G loss: 0.574971]\n",
      "epoch:20 step:19537 [D loss: 0.568680, acc.: 70.31%] [G loss: 0.786241]\n",
      "epoch:20 step:19538 [D loss: 0.519104, acc.: 71.09%] [G loss: 0.595627]\n",
      "epoch:20 step:19539 [D loss: 0.580593, acc.: 69.53%] [G loss: 0.534335]\n",
      "epoch:20 step:19540 [D loss: 0.550929, acc.: 66.41%] [G loss: 0.534180]\n",
      "epoch:20 step:19541 [D loss: 0.506943, acc.: 76.56%] [G loss: 0.670515]\n",
      "epoch:20 step:19542 [D loss: 0.480049, acc.: 75.00%] [G loss: 0.806768]\n",
      "epoch:20 step:19543 [D loss: 0.550404, acc.: 71.88%] [G loss: 0.710323]\n",
      "epoch:20 step:19544 [D loss: 0.530436, acc.: 69.53%] [G loss: 0.627536]\n",
      "epoch:20 step:19545 [D loss: 0.573977, acc.: 64.84%] [G loss: 0.552750]\n",
      "epoch:20 step:19546 [D loss: 0.523384, acc.: 75.00%] [G loss: 0.604773]\n",
      "epoch:20 step:19547 [D loss: 0.493068, acc.: 78.91%] [G loss: 0.706899]\n",
      "epoch:20 step:19548 [D loss: 0.590500, acc.: 67.97%] [G loss: 0.530408]\n",
      "epoch:20 step:19549 [D loss: 0.572537, acc.: 68.75%] [G loss: 0.513736]\n",
      "epoch:20 step:19550 [D loss: 0.538065, acc.: 67.97%] [G loss: 0.636474]\n",
      "epoch:20 step:19551 [D loss: 0.546149, acc.: 69.53%] [G loss: 0.597678]\n",
      "epoch:20 step:19552 [D loss: 0.590586, acc.: 68.75%] [G loss: 0.528625]\n",
      "epoch:20 step:19553 [D loss: 0.554541, acc.: 65.62%] [G loss: 0.493244]\n",
      "epoch:20 step:19554 [D loss: 0.534052, acc.: 68.75%] [G loss: 0.627991]\n",
      "epoch:20 step:19555 [D loss: 0.502668, acc.: 73.44%] [G loss: 0.766107]\n",
      "epoch:20 step:19556 [D loss: 0.549253, acc.: 73.44%] [G loss: 0.734947]\n",
      "epoch:20 step:19557 [D loss: 0.627930, acc.: 71.09%] [G loss: 0.664782]\n",
      "epoch:20 step:19558 [D loss: 0.579233, acc.: 65.62%] [G loss: 0.656702]\n",
      "epoch:20 step:19559 [D loss: 0.495737, acc.: 73.44%] [G loss: 0.769237]\n",
      "epoch:20 step:19560 [D loss: 0.618939, acc.: 67.97%] [G loss: 0.611221]\n",
      "epoch:20 step:19561 [D loss: 0.534167, acc.: 68.75%] [G loss: 0.509938]\n",
      "epoch:20 step:19562 [D loss: 0.604957, acc.: 61.72%] [G loss: 0.534791]\n",
      "epoch:20 step:19563 [D loss: 0.436480, acc.: 77.34%] [G loss: 0.757377]\n",
      "epoch:20 step:19564 [D loss: 0.588630, acc.: 69.53%] [G loss: 0.650515]\n",
      "epoch:20 step:19565 [D loss: 0.501546, acc.: 72.66%] [G loss: 0.669435]\n",
      "epoch:20 step:19566 [D loss: 0.541934, acc.: 67.19%] [G loss: 0.699130]\n",
      "epoch:20 step:19567 [D loss: 0.572353, acc.: 67.19%] [G loss: 0.701566]\n",
      "epoch:20 step:19568 [D loss: 0.648541, acc.: 60.94%] [G loss: 0.630350]\n",
      "epoch:20 step:19569 [D loss: 0.529696, acc.: 67.19%] [G loss: 0.673679]\n",
      "epoch:20 step:19570 [D loss: 0.559372, acc.: 67.19%] [G loss: 0.754785]\n",
      "epoch:20 step:19571 [D loss: 0.540977, acc.: 74.22%] [G loss: 0.559861]\n",
      "epoch:20 step:19572 [D loss: 0.528357, acc.: 75.78%] [G loss: 0.596984]\n",
      "epoch:20 step:19573 [D loss: 0.512838, acc.: 70.31%] [G loss: 0.760100]\n",
      "epoch:20 step:19574 [D loss: 0.575868, acc.: 64.06%] [G loss: 0.538747]\n",
      "epoch:20 step:19575 [D loss: 0.568941, acc.: 65.62%] [G loss: 0.592035]\n",
      "epoch:20 step:19576 [D loss: 0.525521, acc.: 73.44%] [G loss: 0.565474]\n",
      "epoch:20 step:19577 [D loss: 0.578049, acc.: 67.97%] [G loss: 0.558879]\n",
      "epoch:20 step:19578 [D loss: 0.500080, acc.: 77.34%] [G loss: 0.592797]\n",
      "epoch:20 step:19579 [D loss: 0.551347, acc.: 63.28%] [G loss: 0.663390]\n",
      "epoch:20 step:19580 [D loss: 0.588848, acc.: 69.53%] [G loss: 0.620479]\n",
      "epoch:20 step:19581 [D loss: 0.502911, acc.: 75.78%] [G loss: 0.621326]\n",
      "epoch:20 step:19582 [D loss: 0.529564, acc.: 71.88%] [G loss: 0.695631]\n",
      "epoch:20 step:19583 [D loss: 0.538324, acc.: 74.22%] [G loss: 0.565116]\n",
      "epoch:20 step:19584 [D loss: 0.556927, acc.: 72.66%] [G loss: 0.687046]\n",
      "epoch:20 step:19585 [D loss: 0.594058, acc.: 66.41%] [G loss: 0.633034]\n",
      "epoch:20 step:19586 [D loss: 0.578000, acc.: 61.72%] [G loss: 0.573703]\n",
      "epoch:20 step:19587 [D loss: 0.592617, acc.: 67.19%] [G loss: 0.433632]\n",
      "epoch:20 step:19588 [D loss: 0.545581, acc.: 67.19%] [G loss: 0.462633]\n",
      "epoch:20 step:19589 [D loss: 0.544996, acc.: 67.97%] [G loss: 0.473499]\n",
      "epoch:20 step:19590 [D loss: 0.536382, acc.: 73.44%] [G loss: 0.638063]\n",
      "epoch:20 step:19591 [D loss: 0.546422, acc.: 67.19%] [G loss: 0.473394]\n",
      "epoch:20 step:19592 [D loss: 0.547747, acc.: 68.75%] [G loss: 0.483786]\n",
      "epoch:20 step:19593 [D loss: 0.556101, acc.: 68.75%] [G loss: 0.603118]\n",
      "epoch:20 step:19594 [D loss: 0.492489, acc.: 70.31%] [G loss: 0.592415]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:20 step:19595 [D loss: 0.541591, acc.: 67.19%] [G loss: 0.637329]\n",
      "epoch:20 step:19596 [D loss: 0.555090, acc.: 69.53%] [G loss: 0.536105]\n",
      "epoch:20 step:19597 [D loss: 0.469464, acc.: 76.56%] [G loss: 0.659512]\n",
      "epoch:20 step:19598 [D loss: 0.620401, acc.: 70.31%] [G loss: 0.611289]\n",
      "epoch:20 step:19599 [D loss: 0.594550, acc.: 65.62%] [G loss: 0.662409]\n",
      "epoch:20 step:19600 [D loss: 0.473053, acc.: 76.56%] [G loss: 0.813362]\n",
      "##############\n",
      "[2.97689946 1.77890557 6.13762804 4.79538266 3.81880403 5.5996443\n",
      " 4.40967072 5.06486875 4.78719478 4.24135261]\n",
      "##########\n",
      "epoch:20 step:19601 [D loss: 0.641924, acc.: 67.19%] [G loss: 0.503938]\n",
      "epoch:20 step:19602 [D loss: 0.560313, acc.: 67.19%] [G loss: 0.521863]\n",
      "epoch:20 step:19603 [D loss: 0.558656, acc.: 67.97%] [G loss: 0.471550]\n",
      "epoch:20 step:19604 [D loss: 0.568198, acc.: 68.75%] [G loss: 0.625059]\n",
      "epoch:20 step:19605 [D loss: 0.604437, acc.: 60.94%] [G loss: 0.643383]\n",
      "epoch:20 step:19606 [D loss: 0.560334, acc.: 68.75%] [G loss: 0.528761]\n",
      "epoch:20 step:19607 [D loss: 0.645914, acc.: 57.81%] [G loss: 0.566912]\n",
      "epoch:20 step:19608 [D loss: 0.545133, acc.: 71.88%] [G loss: 0.475865]\n",
      "epoch:20 step:19609 [D loss: 0.616064, acc.: 60.16%] [G loss: 0.557760]\n",
      "epoch:20 step:19610 [D loss: 0.494785, acc.: 71.88%] [G loss: 0.628206]\n",
      "epoch:20 step:19611 [D loss: 0.473066, acc.: 75.78%] [G loss: 0.863193]\n",
      "epoch:20 step:19612 [D loss: 0.550542, acc.: 68.75%] [G loss: 0.713896]\n",
      "epoch:20 step:19613 [D loss: 0.602713, acc.: 66.41%] [G loss: 0.640501]\n",
      "epoch:20 step:19614 [D loss: 0.546189, acc.: 67.97%] [G loss: 0.576759]\n",
      "epoch:20 step:19615 [D loss: 0.449880, acc.: 80.47%] [G loss: 0.743736]\n",
      "epoch:20 step:19616 [D loss: 0.545992, acc.: 71.09%] [G loss: 0.674494]\n",
      "epoch:20 step:19617 [D loss: 0.606499, acc.: 61.72%] [G loss: 0.450682]\n",
      "epoch:20 step:19618 [D loss: 0.528499, acc.: 71.88%] [G loss: 0.468013]\n",
      "epoch:20 step:19619 [D loss: 0.552438, acc.: 72.66%] [G loss: 0.643067]\n",
      "epoch:20 step:19620 [D loss: 0.679845, acc.: 57.03%] [G loss: 0.491871]\n",
      "epoch:20 step:19621 [D loss: 0.606736, acc.: 60.16%] [G loss: 0.452218]\n",
      "epoch:20 step:19622 [D loss: 0.629560, acc.: 64.84%] [G loss: 0.484744]\n",
      "epoch:20 step:19623 [D loss: 0.603884, acc.: 63.28%] [G loss: 0.548495]\n",
      "epoch:20 step:19624 [D loss: 0.519072, acc.: 74.22%] [G loss: 0.505307]\n",
      "epoch:20 step:19625 [D loss: 0.512998, acc.: 71.09%] [G loss: 0.608624]\n",
      "epoch:20 step:19626 [D loss: 0.502621, acc.: 73.44%] [G loss: 0.551558]\n",
      "epoch:20 step:19627 [D loss: 0.535751, acc.: 71.88%] [G loss: 0.611529]\n",
      "epoch:20 step:19628 [D loss: 0.575084, acc.: 67.19%] [G loss: 0.667669]\n",
      "epoch:20 step:19629 [D loss: 0.572896, acc.: 65.62%] [G loss: 0.601809]\n",
      "epoch:20 step:19630 [D loss: 0.527150, acc.: 69.53%] [G loss: 0.605242]\n",
      "epoch:20 step:19631 [D loss: 0.590978, acc.: 62.50%] [G loss: 0.630620]\n",
      "epoch:20 step:19632 [D loss: 0.643199, acc.: 62.50%] [G loss: 0.646202]\n",
      "epoch:20 step:19633 [D loss: 0.499334, acc.: 76.56%] [G loss: 0.677738]\n",
      "epoch:20 step:19634 [D loss: 0.490807, acc.: 73.44%] [G loss: 0.663801]\n",
      "epoch:20 step:19635 [D loss: 0.549306, acc.: 69.53%] [G loss: 0.758145]\n",
      "epoch:20 step:19636 [D loss: 0.555085, acc.: 74.22%] [G loss: 0.721295]\n",
      "epoch:20 step:19637 [D loss: 0.479322, acc.: 76.56%] [G loss: 0.715380]\n",
      "epoch:20 step:19638 [D loss: 0.494796, acc.: 74.22%] [G loss: 0.681251]\n",
      "epoch:20 step:19639 [D loss: 0.488383, acc.: 74.22%] [G loss: 0.817031]\n",
      "epoch:20 step:19640 [D loss: 0.487424, acc.: 75.00%] [G loss: 0.835365]\n",
      "epoch:20 step:19641 [D loss: 0.528406, acc.: 75.00%] [G loss: 0.655343]\n",
      "epoch:20 step:19642 [D loss: 0.609505, acc.: 64.06%] [G loss: 0.643670]\n",
      "epoch:20 step:19643 [D loss: 0.550185, acc.: 71.88%] [G loss: 0.599726]\n",
      "epoch:20 step:19644 [D loss: 0.535682, acc.: 75.00%] [G loss: 0.542093]\n",
      "epoch:20 step:19645 [D loss: 0.588402, acc.: 67.97%] [G loss: 0.720817]\n",
      "epoch:20 step:19646 [D loss: 0.543549, acc.: 74.22%] [G loss: 0.712710]\n",
      "epoch:20 step:19647 [D loss: 0.528040, acc.: 72.66%] [G loss: 0.674180]\n",
      "epoch:20 step:19648 [D loss: 0.534726, acc.: 77.34%] [G loss: 0.711696]\n",
      "epoch:20 step:19649 [D loss: 0.473956, acc.: 77.34%] [G loss: 0.725269]\n",
      "epoch:20 step:19650 [D loss: 0.505358, acc.: 76.56%] [G loss: 0.828493]\n",
      "epoch:20 step:19651 [D loss: 0.499255, acc.: 75.00%] [G loss: 0.674998]\n",
      "epoch:20 step:19652 [D loss: 0.554278, acc.: 74.22%] [G loss: 0.761300]\n",
      "epoch:20 step:19653 [D loss: 0.576491, acc.: 68.75%] [G loss: 0.699341]\n",
      "epoch:20 step:19654 [D loss: 0.487431, acc.: 75.00%] [G loss: 0.815404]\n",
      "epoch:20 step:19655 [D loss: 0.576621, acc.: 70.31%] [G loss: 0.644421]\n",
      "epoch:20 step:19656 [D loss: 0.501332, acc.: 77.34%] [G loss: 0.606001]\n",
      "epoch:20 step:19657 [D loss: 0.615955, acc.: 64.06%] [G loss: 0.579453]\n",
      "epoch:20 step:19658 [D loss: 0.509534, acc.: 75.00%] [G loss: 0.879134]\n",
      "epoch:20 step:19659 [D loss: 0.429617, acc.: 85.16%] [G loss: 0.783094]\n",
      "epoch:20 step:19660 [D loss: 0.747634, acc.: 50.78%] [G loss: 0.603379]\n",
      "epoch:20 step:19661 [D loss: 0.508713, acc.: 78.91%] [G loss: 0.780024]\n",
      "epoch:20 step:19662 [D loss: 0.545503, acc.: 70.31%] [G loss: 0.657822]\n",
      "epoch:20 step:19663 [D loss: 0.432941, acc.: 76.56%] [G loss: 0.733401]\n",
      "epoch:20 step:19664 [D loss: 0.505680, acc.: 76.56%] [G loss: 0.935815]\n",
      "epoch:20 step:19665 [D loss: 0.410579, acc.: 81.25%] [G loss: 1.061352]\n",
      "epoch:20 step:19666 [D loss: 0.421676, acc.: 77.34%] [G loss: 1.170464]\n",
      "epoch:20 step:19667 [D loss: 0.532447, acc.: 67.97%] [G loss: 1.119812]\n",
      "epoch:20 step:19668 [D loss: 0.670180, acc.: 66.41%] [G loss: 1.087736]\n",
      "epoch:20 step:19669 [D loss: 0.503568, acc.: 71.88%] [G loss: 1.347229]\n",
      "epoch:20 step:19670 [D loss: 0.496226, acc.: 74.22%] [G loss: 1.336353]\n",
      "epoch:20 step:19671 [D loss: 0.568914, acc.: 67.19%] [G loss: 0.990087]\n",
      "epoch:20 step:19672 [D loss: 0.667940, acc.: 59.38%] [G loss: 0.761607]\n",
      "epoch:20 step:19673 [D loss: 0.477321, acc.: 75.78%] [G loss: 0.760989]\n",
      "epoch:20 step:19674 [D loss: 0.511877, acc.: 75.00%] [G loss: 0.884058]\n",
      "epoch:20 step:19675 [D loss: 0.511866, acc.: 76.56%] [G loss: 1.006101]\n",
      "epoch:20 step:19676 [D loss: 0.386435, acc.: 82.81%] [G loss: 1.278023]\n",
      "epoch:20 step:19677 [D loss: 0.460263, acc.: 79.69%] [G loss: 1.230773]\n",
      "epoch:21 step:19678 [D loss: 0.549930, acc.: 74.22%] [G loss: 1.067622]\n",
      "epoch:21 step:19679 [D loss: 0.446501, acc.: 75.78%] [G loss: 1.112847]\n",
      "epoch:21 step:19680 [D loss: 0.538581, acc.: 71.09%] [G loss: 0.968012]\n",
      "epoch:21 step:19681 [D loss: 0.484114, acc.: 78.12%] [G loss: 0.953142]\n",
      "epoch:21 step:19682 [D loss: 0.550138, acc.: 69.53%] [G loss: 1.041976]\n",
      "epoch:21 step:19683 [D loss: 0.573142, acc.: 71.88%] [G loss: 0.651240]\n",
      "epoch:21 step:19684 [D loss: 0.545503, acc.: 73.44%] [G loss: 0.836265]\n",
      "epoch:21 step:19685 [D loss: 0.482104, acc.: 81.25%] [G loss: 0.895445]\n",
      "epoch:21 step:19686 [D loss: 0.452003, acc.: 79.69%] [G loss: 0.847683]\n",
      "epoch:21 step:19687 [D loss: 0.492319, acc.: 79.69%] [G loss: 0.740474]\n",
      "epoch:21 step:19688 [D loss: 0.439209, acc.: 82.03%] [G loss: 0.722510]\n",
      "epoch:21 step:19689 [D loss: 0.569778, acc.: 72.66%] [G loss: 0.646556]\n",
      "epoch:21 step:19690 [D loss: 0.568146, acc.: 68.75%] [G loss: 0.710792]\n",
      "epoch:21 step:19691 [D loss: 0.540910, acc.: 73.44%] [G loss: 0.756450]\n",
      "epoch:21 step:19692 [D loss: 0.462612, acc.: 75.00%] [G loss: 0.777696]\n",
      "epoch:21 step:19693 [D loss: 0.473891, acc.: 76.56%] [G loss: 0.718102]\n",
      "epoch:21 step:19694 [D loss: 0.552126, acc.: 75.00%] [G loss: 0.582343]\n",
      "epoch:21 step:19695 [D loss: 0.548381, acc.: 69.53%] [G loss: 0.737450]\n",
      "epoch:21 step:19696 [D loss: 0.588297, acc.: 64.84%] [G loss: 0.628126]\n",
      "epoch:21 step:19697 [D loss: 0.582275, acc.: 66.41%] [G loss: 0.623129]\n",
      "epoch:21 step:19698 [D loss: 0.555402, acc.: 66.41%] [G loss: 0.736165]\n",
      "epoch:21 step:19699 [D loss: 0.423093, acc.: 82.81%] [G loss: 0.833405]\n",
      "epoch:21 step:19700 [D loss: 0.559860, acc.: 70.31%] [G loss: 0.624425]\n",
      "epoch:21 step:19701 [D loss: 0.495189, acc.: 73.44%] [G loss: 0.648633]\n",
      "epoch:21 step:19702 [D loss: 0.449699, acc.: 78.91%] [G loss: 0.625140]\n",
      "epoch:21 step:19703 [D loss: 0.592819, acc.: 67.19%] [G loss: 0.643422]\n",
      "epoch:21 step:19704 [D loss: 0.449371, acc.: 77.34%] [G loss: 0.730698]\n",
      "epoch:21 step:19705 [D loss: 0.544037, acc.: 68.75%] [G loss: 0.784452]\n",
      "epoch:21 step:19706 [D loss: 0.522159, acc.: 73.44%] [G loss: 0.795238]\n",
      "epoch:21 step:19707 [D loss: 0.528295, acc.: 72.66%] [G loss: 0.611596]\n",
      "epoch:21 step:19708 [D loss: 0.607497, acc.: 64.06%] [G loss: 0.614246]\n",
      "epoch:21 step:19709 [D loss: 0.552628, acc.: 67.97%] [G loss: 0.646428]\n",
      "epoch:21 step:19710 [D loss: 0.534868, acc.: 67.97%] [G loss: 0.728723]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:21 step:19711 [D loss: 0.541690, acc.: 70.31%] [G loss: 0.742622]\n",
      "epoch:21 step:19712 [D loss: 0.578126, acc.: 66.41%] [G loss: 0.760030]\n",
      "epoch:21 step:19713 [D loss: 0.539609, acc.: 67.97%] [G loss: 0.694972]\n",
      "epoch:21 step:19714 [D loss: 0.490251, acc.: 77.34%] [G loss: 0.674204]\n",
      "epoch:21 step:19715 [D loss: 0.562081, acc.: 68.75%] [G loss: 0.647902]\n",
      "epoch:21 step:19716 [D loss: 0.558901, acc.: 67.97%] [G loss: 0.606996]\n",
      "epoch:21 step:19717 [D loss: 0.432938, acc.: 78.91%] [G loss: 0.567650]\n",
      "epoch:21 step:19718 [D loss: 0.526499, acc.: 72.66%] [G loss: 0.710295]\n",
      "epoch:21 step:19719 [D loss: 0.527160, acc.: 68.75%] [G loss: 0.654474]\n",
      "epoch:21 step:19720 [D loss: 0.514162, acc.: 72.66%] [G loss: 0.734118]\n",
      "epoch:21 step:19721 [D loss: 0.575197, acc.: 69.53%] [G loss: 0.646382]\n",
      "epoch:21 step:19722 [D loss: 0.497198, acc.: 72.66%] [G loss: 0.623885]\n",
      "epoch:21 step:19723 [D loss: 0.547198, acc.: 72.66%] [G loss: 0.772866]\n",
      "epoch:21 step:19724 [D loss: 0.502928, acc.: 72.66%] [G loss: 0.840317]\n",
      "epoch:21 step:19725 [D loss: 0.597105, acc.: 63.28%] [G loss: 0.593802]\n",
      "epoch:21 step:19726 [D loss: 0.445747, acc.: 77.34%] [G loss: 0.903899]\n",
      "epoch:21 step:19727 [D loss: 0.599918, acc.: 65.62%] [G loss: 0.752653]\n",
      "epoch:21 step:19728 [D loss: 0.599129, acc.: 67.97%] [G loss: 0.653139]\n",
      "epoch:21 step:19729 [D loss: 0.616522, acc.: 63.28%] [G loss: 0.663629]\n",
      "epoch:21 step:19730 [D loss: 0.545260, acc.: 70.31%] [G loss: 0.742053]\n",
      "epoch:21 step:19731 [D loss: 0.461585, acc.: 75.00%] [G loss: 0.845341]\n",
      "epoch:21 step:19732 [D loss: 0.521858, acc.: 71.09%] [G loss: 0.907622]\n",
      "epoch:21 step:19733 [D loss: 0.497310, acc.: 75.00%] [G loss: 0.745950]\n",
      "epoch:21 step:19734 [D loss: 0.573489, acc.: 67.19%] [G loss: 0.864813]\n",
      "epoch:21 step:19735 [D loss: 0.581602, acc.: 63.28%] [G loss: 0.848108]\n",
      "epoch:21 step:19736 [D loss: 0.542984, acc.: 67.97%] [G loss: 0.794596]\n",
      "epoch:21 step:19737 [D loss: 0.570989, acc.: 67.19%] [G loss: 0.728310]\n",
      "epoch:21 step:19738 [D loss: 0.576949, acc.: 60.94%] [G loss: 0.665395]\n",
      "epoch:21 step:19739 [D loss: 0.580521, acc.: 66.41%] [G loss: 0.608642]\n",
      "epoch:21 step:19740 [D loss: 0.524038, acc.: 73.44%] [G loss: 0.608432]\n",
      "epoch:21 step:19741 [D loss: 0.585245, acc.: 70.31%] [G loss: 0.580612]\n",
      "epoch:21 step:19742 [D loss: 0.501366, acc.: 72.66%] [G loss: 0.564944]\n",
      "epoch:21 step:19743 [D loss: 0.517194, acc.: 72.66%] [G loss: 0.743555]\n",
      "epoch:21 step:19744 [D loss: 0.609174, acc.: 63.28%] [G loss: 0.666909]\n",
      "epoch:21 step:19745 [D loss: 0.512505, acc.: 75.00%] [G loss: 0.631490]\n",
      "epoch:21 step:19746 [D loss: 0.504999, acc.: 71.09%] [G loss: 0.651711]\n",
      "epoch:21 step:19747 [D loss: 0.534216, acc.: 72.66%] [G loss: 0.695034]\n",
      "epoch:21 step:19748 [D loss: 0.536000, acc.: 68.75%] [G loss: 0.587242]\n",
      "epoch:21 step:19749 [D loss: 0.561742, acc.: 65.62%] [G loss: 0.548828]\n",
      "epoch:21 step:19750 [D loss: 0.591203, acc.: 64.06%] [G loss: 0.494208]\n",
      "epoch:21 step:19751 [D loss: 0.501667, acc.: 72.66%] [G loss: 0.593377]\n",
      "epoch:21 step:19752 [D loss: 0.559890, acc.: 66.41%] [G loss: 0.614541]\n",
      "epoch:21 step:19753 [D loss: 0.510512, acc.: 75.78%] [G loss: 0.587800]\n",
      "epoch:21 step:19754 [D loss: 0.483381, acc.: 72.66%] [G loss: 0.697086]\n",
      "epoch:21 step:19755 [D loss: 0.592636, acc.: 71.09%] [G loss: 0.700248]\n",
      "epoch:21 step:19756 [D loss: 0.567949, acc.: 65.62%] [G loss: 0.699995]\n",
      "epoch:21 step:19757 [D loss: 0.485239, acc.: 73.44%] [G loss: 0.688685]\n",
      "epoch:21 step:19758 [D loss: 0.531123, acc.: 71.09%] [G loss: 0.595247]\n",
      "epoch:21 step:19759 [D loss: 0.530118, acc.: 70.31%] [G loss: 0.710442]\n",
      "epoch:21 step:19760 [D loss: 0.484915, acc.: 77.34%] [G loss: 0.831075]\n",
      "epoch:21 step:19761 [D loss: 0.498043, acc.: 71.88%] [G loss: 0.743119]\n",
      "epoch:21 step:19762 [D loss: 0.564518, acc.: 67.19%] [G loss: 0.539568]\n",
      "epoch:21 step:19763 [D loss: 0.540519, acc.: 68.75%] [G loss: 0.723565]\n",
      "epoch:21 step:19764 [D loss: 0.540336, acc.: 71.88%] [G loss: 0.626155]\n",
      "epoch:21 step:19765 [D loss: 0.505633, acc.: 72.66%] [G loss: 0.606092]\n",
      "epoch:21 step:19766 [D loss: 0.509009, acc.: 78.12%] [G loss: 0.598446]\n",
      "epoch:21 step:19767 [D loss: 0.525431, acc.: 68.75%] [G loss: 0.718779]\n",
      "epoch:21 step:19768 [D loss: 0.535254, acc.: 73.44%] [G loss: 0.673649]\n",
      "epoch:21 step:19769 [D loss: 0.439744, acc.: 76.56%] [G loss: 0.819991]\n",
      "epoch:21 step:19770 [D loss: 0.491480, acc.: 75.78%] [G loss: 0.802859]\n",
      "epoch:21 step:19771 [D loss: 0.468050, acc.: 77.34%] [G loss: 0.751671]\n",
      "epoch:21 step:19772 [D loss: 0.477267, acc.: 77.34%] [G loss: 0.745622]\n",
      "epoch:21 step:19773 [D loss: 0.514560, acc.: 71.88%] [G loss: 0.712791]\n",
      "epoch:21 step:19774 [D loss: 0.501307, acc.: 70.31%] [G loss: 0.708140]\n",
      "epoch:21 step:19775 [D loss: 0.537398, acc.: 70.31%] [G loss: 0.852554]\n",
      "epoch:21 step:19776 [D loss: 0.550724, acc.: 71.88%] [G loss: 0.705913]\n",
      "epoch:21 step:19777 [D loss: 0.471114, acc.: 75.78%] [G loss: 0.912245]\n",
      "epoch:21 step:19778 [D loss: 0.554164, acc.: 72.66%] [G loss: 0.816653]\n",
      "epoch:21 step:19779 [D loss: 0.639993, acc.: 57.03%] [G loss: 0.592948]\n",
      "epoch:21 step:19780 [D loss: 0.511954, acc.: 69.53%] [G loss: 0.515499]\n",
      "epoch:21 step:19781 [D loss: 0.498371, acc.: 75.78%] [G loss: 0.611132]\n",
      "epoch:21 step:19782 [D loss: 0.639531, acc.: 61.72%] [G loss: 0.719905]\n",
      "epoch:21 step:19783 [D loss: 0.484832, acc.: 78.12%] [G loss: 0.620605]\n",
      "epoch:21 step:19784 [D loss: 0.582377, acc.: 67.19%] [G loss: 0.678454]\n",
      "epoch:21 step:19785 [D loss: 0.652155, acc.: 60.94%] [G loss: 0.490752]\n",
      "epoch:21 step:19786 [D loss: 0.595665, acc.: 68.75%] [G loss: 0.596068]\n",
      "epoch:21 step:19787 [D loss: 0.554859, acc.: 67.19%] [G loss: 0.534520]\n",
      "epoch:21 step:19788 [D loss: 0.478947, acc.: 74.22%] [G loss: 0.545423]\n",
      "epoch:21 step:19789 [D loss: 0.509838, acc.: 75.00%] [G loss: 0.671470]\n",
      "epoch:21 step:19790 [D loss: 0.538529, acc.: 71.09%] [G loss: 0.654461]\n",
      "epoch:21 step:19791 [D loss: 0.528314, acc.: 73.44%] [G loss: 0.648966]\n",
      "epoch:21 step:19792 [D loss: 0.581441, acc.: 71.09%] [G loss: 0.663948]\n",
      "epoch:21 step:19793 [D loss: 0.553241, acc.: 67.97%] [G loss: 0.635024]\n",
      "epoch:21 step:19794 [D loss: 0.488432, acc.: 81.25%] [G loss: 0.756728]\n",
      "epoch:21 step:19795 [D loss: 0.483959, acc.: 76.56%] [G loss: 0.695789]\n",
      "epoch:21 step:19796 [D loss: 0.451950, acc.: 76.56%] [G loss: 1.065204]\n",
      "epoch:21 step:19797 [D loss: 0.521303, acc.: 72.66%] [G loss: 0.836982]\n",
      "epoch:21 step:19798 [D loss: 0.520290, acc.: 71.88%] [G loss: 0.699937]\n",
      "epoch:21 step:19799 [D loss: 0.498101, acc.: 76.56%] [G loss: 0.877339]\n",
      "epoch:21 step:19800 [D loss: 0.496168, acc.: 75.00%] [G loss: 0.770151]\n",
      "##############\n",
      "[3.04318315 1.41079672 6.02705976 4.84887251 3.87079417 5.70077516\n",
      " 4.37960879 4.83911283 4.7332099  4.4040793 ]\n",
      "##########\n",
      "epoch:21 step:19801 [D loss: 0.529209, acc.: 74.22%] [G loss: 0.676333]\n",
      "epoch:21 step:19802 [D loss: 0.559870, acc.: 71.09%] [G loss: 0.624214]\n",
      "epoch:21 step:19803 [D loss: 0.482708, acc.: 74.22%] [G loss: 0.700493]\n",
      "epoch:21 step:19804 [D loss: 0.533233, acc.: 73.44%] [G loss: 0.614986]\n",
      "epoch:21 step:19805 [D loss: 0.487401, acc.: 74.22%] [G loss: 0.728144]\n",
      "epoch:21 step:19806 [D loss: 0.537357, acc.: 72.66%] [G loss: 0.669468]\n",
      "epoch:21 step:19807 [D loss: 0.493867, acc.: 72.66%] [G loss: 0.713051]\n",
      "epoch:21 step:19808 [D loss: 0.466394, acc.: 74.22%] [G loss: 0.721777]\n",
      "epoch:21 step:19809 [D loss: 0.531948, acc.: 75.78%] [G loss: 0.740122]\n",
      "epoch:21 step:19810 [D loss: 0.553587, acc.: 71.09%] [G loss: 0.825295]\n",
      "epoch:21 step:19811 [D loss: 0.524640, acc.: 67.97%] [G loss: 0.786205]\n",
      "epoch:21 step:19812 [D loss: 0.522318, acc.: 73.44%] [G loss: 0.668820]\n",
      "epoch:21 step:19813 [D loss: 0.516665, acc.: 73.44%] [G loss: 0.765563]\n",
      "epoch:21 step:19814 [D loss: 0.611418, acc.: 64.84%] [G loss: 0.687385]\n",
      "epoch:21 step:19815 [D loss: 0.623616, acc.: 64.84%] [G loss: 0.621849]\n",
      "epoch:21 step:19816 [D loss: 0.566553, acc.: 68.75%] [G loss: 0.581543]\n",
      "epoch:21 step:19817 [D loss: 0.610190, acc.: 64.84%] [G loss: 0.504645]\n",
      "epoch:21 step:19818 [D loss: 0.498589, acc.: 71.88%] [G loss: 0.613204]\n",
      "epoch:21 step:19819 [D loss: 0.530714, acc.: 66.41%] [G loss: 0.677234]\n",
      "epoch:21 step:19820 [D loss: 0.624227, acc.: 65.62%] [G loss: 0.606624]\n",
      "epoch:21 step:19821 [D loss: 0.510772, acc.: 74.22%] [G loss: 0.545087]\n",
      "epoch:21 step:19822 [D loss: 0.531462, acc.: 70.31%] [G loss: 0.640448]\n",
      "epoch:21 step:19823 [D loss: 0.535658, acc.: 75.78%] [G loss: 0.727648]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:21 step:19824 [D loss: 0.607283, acc.: 65.62%] [G loss: 0.601068]\n",
      "epoch:21 step:19825 [D loss: 0.643509, acc.: 60.94%] [G loss: 0.688059]\n",
      "epoch:21 step:19826 [D loss: 0.515499, acc.: 72.66%] [G loss: 0.567443]\n",
      "epoch:21 step:19827 [D loss: 0.590135, acc.: 69.53%] [G loss: 0.540760]\n",
      "epoch:21 step:19828 [D loss: 0.529900, acc.: 71.88%] [G loss: 0.604578]\n",
      "epoch:21 step:19829 [D loss: 0.489242, acc.: 77.34%] [G loss: 0.683028]\n",
      "epoch:21 step:19830 [D loss: 0.579378, acc.: 67.97%] [G loss: 0.808211]\n",
      "epoch:21 step:19831 [D loss: 0.575359, acc.: 67.97%] [G loss: 0.606642]\n",
      "epoch:21 step:19832 [D loss: 0.511011, acc.: 69.53%] [G loss: 0.555359]\n",
      "epoch:21 step:19833 [D loss: 0.515655, acc.: 70.31%] [G loss: 0.582401]\n",
      "epoch:21 step:19834 [D loss: 0.551627, acc.: 68.75%] [G loss: 0.609422]\n",
      "epoch:21 step:19835 [D loss: 0.540937, acc.: 69.53%] [G loss: 0.563143]\n",
      "epoch:21 step:19836 [D loss: 0.509505, acc.: 75.00%] [G loss: 0.655751]\n",
      "epoch:21 step:19837 [D loss: 0.621126, acc.: 69.53%] [G loss: 0.597641]\n",
      "epoch:21 step:19838 [D loss: 0.523050, acc.: 75.00%] [G loss: 0.711993]\n",
      "epoch:21 step:19839 [D loss: 0.515872, acc.: 70.31%] [G loss: 0.850652]\n",
      "epoch:21 step:19840 [D loss: 0.580154, acc.: 68.75%] [G loss: 0.924924]\n",
      "epoch:21 step:19841 [D loss: 0.602758, acc.: 62.50%] [G loss: 0.803436]\n",
      "epoch:21 step:19842 [D loss: 0.567710, acc.: 69.53%] [G loss: 0.671230]\n",
      "epoch:21 step:19843 [D loss: 0.547458, acc.: 67.19%] [G loss: 0.527385]\n",
      "epoch:21 step:19844 [D loss: 0.498139, acc.: 77.34%] [G loss: 0.523350]\n",
      "epoch:21 step:19845 [D loss: 0.568992, acc.: 65.62%] [G loss: 0.560779]\n",
      "epoch:21 step:19846 [D loss: 0.665428, acc.: 56.25%] [G loss: 0.540340]\n",
      "epoch:21 step:19847 [D loss: 0.552836, acc.: 70.31%] [G loss: 0.526401]\n",
      "epoch:21 step:19848 [D loss: 0.541772, acc.: 70.31%] [G loss: 0.579649]\n",
      "epoch:21 step:19849 [D loss: 0.541509, acc.: 70.31%] [G loss: 0.649387]\n",
      "epoch:21 step:19850 [D loss: 0.473025, acc.: 75.78%] [G loss: 0.793795]\n",
      "epoch:21 step:19851 [D loss: 0.574654, acc.: 66.41%] [G loss: 0.646923]\n",
      "epoch:21 step:19852 [D loss: 0.602078, acc.: 64.84%] [G loss: 0.491105]\n",
      "epoch:21 step:19853 [D loss: 0.515170, acc.: 72.66%] [G loss: 0.643041]\n",
      "epoch:21 step:19854 [D loss: 0.511103, acc.: 77.34%] [G loss: 0.639656]\n",
      "epoch:21 step:19855 [D loss: 0.544319, acc.: 71.09%] [G loss: 0.678540]\n",
      "epoch:21 step:19856 [D loss: 0.561192, acc.: 64.84%] [G loss: 0.546116]\n",
      "epoch:21 step:19857 [D loss: 0.618880, acc.: 65.62%] [G loss: 0.536926]\n",
      "epoch:21 step:19858 [D loss: 0.606158, acc.: 64.84%] [G loss: 0.489122]\n",
      "epoch:21 step:19859 [D loss: 0.560491, acc.: 67.19%] [G loss: 0.608646]\n",
      "epoch:21 step:19860 [D loss: 0.616300, acc.: 66.41%] [G loss: 0.682015]\n",
      "epoch:21 step:19861 [D loss: 0.487982, acc.: 73.44%] [G loss: 0.685678]\n",
      "epoch:21 step:19862 [D loss: 0.584762, acc.: 63.28%] [G loss: 0.820132]\n",
      "epoch:21 step:19863 [D loss: 0.555854, acc.: 72.66%] [G loss: 0.653435]\n",
      "epoch:21 step:19864 [D loss: 0.597005, acc.: 60.94%] [G loss: 0.588685]\n",
      "epoch:21 step:19865 [D loss: 0.558804, acc.: 70.31%] [G loss: 0.544136]\n",
      "epoch:21 step:19866 [D loss: 0.577122, acc.: 70.31%] [G loss: 0.611923]\n",
      "epoch:21 step:19867 [D loss: 0.495371, acc.: 73.44%] [G loss: 0.662515]\n",
      "epoch:21 step:19868 [D loss: 0.540972, acc.: 71.09%] [G loss: 0.729500]\n",
      "epoch:21 step:19869 [D loss: 0.529751, acc.: 75.78%] [G loss: 0.711465]\n",
      "epoch:21 step:19870 [D loss: 0.541391, acc.: 71.09%] [G loss: 0.612656]\n",
      "epoch:21 step:19871 [D loss: 0.465425, acc.: 76.56%] [G loss: 0.791764]\n",
      "epoch:21 step:19872 [D loss: 0.603066, acc.: 64.84%] [G loss: 0.520281]\n",
      "epoch:21 step:19873 [D loss: 0.538840, acc.: 70.31%] [G loss: 0.613347]\n",
      "epoch:21 step:19874 [D loss: 0.496741, acc.: 76.56%] [G loss: 0.802047]\n",
      "epoch:21 step:19875 [D loss: 0.464277, acc.: 77.34%] [G loss: 0.847471]\n",
      "epoch:21 step:19876 [D loss: 0.536725, acc.: 70.31%] [G loss: 0.844162]\n",
      "epoch:21 step:19877 [D loss: 0.590187, acc.: 64.06%] [G loss: 0.661457]\n",
      "epoch:21 step:19878 [D loss: 0.545987, acc.: 71.09%] [G loss: 0.646618]\n",
      "epoch:21 step:19879 [D loss: 0.535296, acc.: 69.53%] [G loss: 0.714202]\n",
      "epoch:21 step:19880 [D loss: 0.559400, acc.: 71.09%] [G loss: 0.680750]\n",
      "epoch:21 step:19881 [D loss: 0.563421, acc.: 69.53%] [G loss: 0.807924]\n",
      "epoch:21 step:19882 [D loss: 0.510098, acc.: 71.88%] [G loss: 0.791961]\n",
      "epoch:21 step:19883 [D loss: 0.549664, acc.: 71.09%] [G loss: 0.664576]\n",
      "epoch:21 step:19884 [D loss: 0.461803, acc.: 76.56%] [G loss: 0.945840]\n",
      "epoch:21 step:19885 [D loss: 0.456556, acc.: 78.12%] [G loss: 0.979033]\n",
      "epoch:21 step:19886 [D loss: 0.492742, acc.: 77.34%] [G loss: 0.958640]\n",
      "epoch:21 step:19887 [D loss: 0.632346, acc.: 64.06%] [G loss: 0.694725]\n",
      "epoch:21 step:19888 [D loss: 0.631975, acc.: 64.84%] [G loss: 0.611869]\n",
      "epoch:21 step:19889 [D loss: 0.513539, acc.: 71.09%] [G loss: 0.736376]\n",
      "epoch:21 step:19890 [D loss: 0.533740, acc.: 70.31%] [G loss: 0.478122]\n",
      "epoch:21 step:19891 [D loss: 0.682572, acc.: 60.94%] [G loss: 0.602883]\n",
      "epoch:21 step:19892 [D loss: 0.599113, acc.: 64.06%] [G loss: 0.597956]\n",
      "epoch:21 step:19893 [D loss: 0.519584, acc.: 71.88%] [G loss: 0.748987]\n",
      "epoch:21 step:19894 [D loss: 0.519740, acc.: 74.22%] [G loss: 0.573895]\n",
      "epoch:21 step:19895 [D loss: 0.517654, acc.: 72.66%] [G loss: 0.777797]\n",
      "epoch:21 step:19896 [D loss: 0.475591, acc.: 75.00%] [G loss: 0.708462]\n",
      "epoch:21 step:19897 [D loss: 0.600020, acc.: 69.53%] [G loss: 0.798962]\n",
      "epoch:21 step:19898 [D loss: 0.525547, acc.: 71.09%] [G loss: 0.734171]\n",
      "epoch:21 step:19899 [D loss: 0.489249, acc.: 79.69%] [G loss: 0.815239]\n",
      "epoch:21 step:19900 [D loss: 0.472975, acc.: 78.12%] [G loss: 0.927952]\n",
      "epoch:21 step:19901 [D loss: 0.591896, acc.: 67.19%] [G loss: 0.737562]\n",
      "epoch:21 step:19902 [D loss: 0.527209, acc.: 73.44%] [G loss: 0.767105]\n",
      "epoch:21 step:19903 [D loss: 0.548201, acc.: 66.41%] [G loss: 0.731918]\n",
      "epoch:21 step:19904 [D loss: 0.516729, acc.: 73.44%] [G loss: 0.724781]\n",
      "epoch:21 step:19905 [D loss: 0.579739, acc.: 64.84%] [G loss: 0.561190]\n",
      "epoch:21 step:19906 [D loss: 0.495254, acc.: 78.12%] [G loss: 0.714789]\n",
      "epoch:21 step:19907 [D loss: 0.551760, acc.: 75.00%] [G loss: 0.729804]\n",
      "epoch:21 step:19908 [D loss: 0.478802, acc.: 78.12%] [G loss: 0.898839]\n",
      "epoch:21 step:19909 [D loss: 0.441899, acc.: 82.81%] [G loss: 0.973924]\n",
      "epoch:21 step:19910 [D loss: 0.532745, acc.: 74.22%] [G loss: 0.756499]\n",
      "epoch:21 step:19911 [D loss: 0.606242, acc.: 66.41%] [G loss: 0.693930]\n",
      "epoch:21 step:19912 [D loss: 0.561542, acc.: 67.97%] [G loss: 0.632008]\n",
      "epoch:21 step:19913 [D loss: 0.491972, acc.: 75.00%] [G loss: 0.711792]\n",
      "epoch:21 step:19914 [D loss: 0.485891, acc.: 72.66%] [G loss: 0.596294]\n",
      "epoch:21 step:19915 [D loss: 0.596870, acc.: 64.84%] [G loss: 0.575865]\n",
      "epoch:21 step:19916 [D loss: 0.534990, acc.: 71.88%] [G loss: 0.638815]\n",
      "epoch:21 step:19917 [D loss: 0.540724, acc.: 71.09%] [G loss: 0.655316]\n",
      "epoch:21 step:19918 [D loss: 0.493212, acc.: 75.78%] [G loss: 0.689371]\n",
      "epoch:21 step:19919 [D loss: 0.516984, acc.: 72.66%] [G loss: 0.666235]\n",
      "epoch:21 step:19920 [D loss: 0.540940, acc.: 70.31%] [G loss: 0.664258]\n",
      "epoch:21 step:19921 [D loss: 0.501539, acc.: 75.00%] [G loss: 0.708791]\n",
      "epoch:21 step:19922 [D loss: 0.492904, acc.: 75.00%] [G loss: 0.656717]\n",
      "epoch:21 step:19923 [D loss: 0.503108, acc.: 72.66%] [G loss: 0.706892]\n",
      "epoch:21 step:19924 [D loss: 0.557823, acc.: 67.97%] [G loss: 0.604770]\n",
      "epoch:21 step:19925 [D loss: 0.485857, acc.: 75.00%] [G loss: 0.752340]\n",
      "epoch:21 step:19926 [D loss: 0.547300, acc.: 73.44%] [G loss: 0.771675]\n",
      "epoch:21 step:19927 [D loss: 0.614234, acc.: 58.59%] [G loss: 0.581654]\n",
      "epoch:21 step:19928 [D loss: 0.625014, acc.: 66.41%] [G loss: 0.619194]\n",
      "epoch:21 step:19929 [D loss: 0.563636, acc.: 68.75%] [G loss: 0.590284]\n",
      "epoch:21 step:19930 [D loss: 0.608042, acc.: 67.97%] [G loss: 0.582922]\n",
      "epoch:21 step:19931 [D loss: 0.531673, acc.: 71.88%] [G loss: 0.499126]\n",
      "epoch:21 step:19932 [D loss: 0.523448, acc.: 67.19%] [G loss: 0.569985]\n",
      "epoch:21 step:19933 [D loss: 0.583387, acc.: 64.84%] [G loss: 0.645164]\n",
      "epoch:21 step:19934 [D loss: 0.649346, acc.: 57.03%] [G loss: 0.474590]\n",
      "epoch:21 step:19935 [D loss: 0.498817, acc.: 77.34%] [G loss: 0.588643]\n",
      "epoch:21 step:19936 [D loss: 0.527067, acc.: 70.31%] [G loss: 0.579508]\n",
      "epoch:21 step:19937 [D loss: 0.541034, acc.: 65.62%] [G loss: 0.467567]\n",
      "epoch:21 step:19938 [D loss: 0.616065, acc.: 64.84%] [G loss: 0.639110]\n",
      "epoch:21 step:19939 [D loss: 0.533994, acc.: 72.66%] [G loss: 0.714197]\n",
      "epoch:21 step:19940 [D loss: 0.568948, acc.: 69.53%] [G loss: 0.707534]\n",
      "epoch:21 step:19941 [D loss: 0.596093, acc.: 72.66%] [G loss: 0.544765]\n",
      "epoch:21 step:19942 [D loss: 0.530315, acc.: 75.00%] [G loss: 0.556931]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:21 step:19943 [D loss: 0.514874, acc.: 73.44%] [G loss: 0.645555]\n",
      "epoch:21 step:19944 [D loss: 0.584444, acc.: 64.84%] [G loss: 0.529627]\n",
      "epoch:21 step:19945 [D loss: 0.515602, acc.: 75.00%] [G loss: 0.690339]\n",
      "epoch:21 step:19946 [D loss: 0.534592, acc.: 75.78%] [G loss: 0.603133]\n",
      "epoch:21 step:19947 [D loss: 0.521990, acc.: 75.00%] [G loss: 0.816978]\n",
      "epoch:21 step:19948 [D loss: 0.520363, acc.: 73.44%] [G loss: 0.705097]\n",
      "epoch:21 step:19949 [D loss: 0.568858, acc.: 62.50%] [G loss: 0.760541]\n",
      "epoch:21 step:19950 [D loss: 0.488099, acc.: 75.00%] [G loss: 0.732717]\n",
      "epoch:21 step:19951 [D loss: 0.506902, acc.: 70.31%] [G loss: 0.680131]\n",
      "epoch:21 step:19952 [D loss: 0.600562, acc.: 73.44%] [G loss: 0.571752]\n",
      "epoch:21 step:19953 [D loss: 0.455532, acc.: 79.69%] [G loss: 0.831219]\n",
      "epoch:21 step:19954 [D loss: 0.688517, acc.: 59.38%] [G loss: 0.506491]\n",
      "epoch:21 step:19955 [D loss: 0.594383, acc.: 67.97%] [G loss: 0.461588]\n",
      "epoch:21 step:19956 [D loss: 0.567748, acc.: 65.62%] [G loss: 0.566055]\n",
      "epoch:21 step:19957 [D loss: 0.532792, acc.: 69.53%] [G loss: 0.658943]\n",
      "epoch:21 step:19958 [D loss: 0.536603, acc.: 71.88%] [G loss: 0.657761]\n",
      "epoch:21 step:19959 [D loss: 0.557766, acc.: 67.97%] [G loss: 0.555918]\n",
      "epoch:21 step:19960 [D loss: 0.513959, acc.: 71.88%] [G loss: 0.679947]\n",
      "epoch:21 step:19961 [D loss: 0.536072, acc.: 67.97%] [G loss: 0.654878]\n",
      "epoch:21 step:19962 [D loss: 0.480033, acc.: 77.34%] [G loss: 0.617127]\n",
      "epoch:21 step:19963 [D loss: 0.458725, acc.: 78.91%] [G loss: 0.876043]\n",
      "epoch:21 step:19964 [D loss: 0.575363, acc.: 66.41%] [G loss: 0.778425]\n",
      "epoch:21 step:19965 [D loss: 0.584735, acc.: 68.75%] [G loss: 0.644245]\n",
      "epoch:21 step:19966 [D loss: 0.498989, acc.: 72.66%] [G loss: 0.590096]\n",
      "epoch:21 step:19967 [D loss: 0.580317, acc.: 68.75%] [G loss: 0.669954]\n",
      "epoch:21 step:19968 [D loss: 0.576568, acc.: 69.53%] [G loss: 0.665255]\n",
      "epoch:21 step:19969 [D loss: 0.550720, acc.: 71.09%] [G loss: 0.512238]\n",
      "epoch:21 step:19970 [D loss: 0.537353, acc.: 67.19%] [G loss: 0.629827]\n",
      "epoch:21 step:19971 [D loss: 0.600376, acc.: 62.50%] [G loss: 0.568813]\n",
      "epoch:21 step:19972 [D loss: 0.540720, acc.: 71.09%] [G loss: 0.519499]\n",
      "epoch:21 step:19973 [D loss: 0.480678, acc.: 75.78%] [G loss: 0.619312]\n",
      "epoch:21 step:19974 [D loss: 0.574416, acc.: 65.62%] [G loss: 0.556704]\n",
      "epoch:21 step:19975 [D loss: 0.441111, acc.: 79.69%] [G loss: 0.704230]\n",
      "epoch:21 step:19976 [D loss: 0.506105, acc.: 73.44%] [G loss: 0.796794]\n",
      "epoch:21 step:19977 [D loss: 0.493127, acc.: 75.00%] [G loss: 0.627661]\n",
      "epoch:21 step:19978 [D loss: 0.626890, acc.: 62.50%] [G loss: 0.665995]\n",
      "epoch:21 step:19979 [D loss: 0.551291, acc.: 70.31%] [G loss: 0.582876]\n",
      "epoch:21 step:19980 [D loss: 0.530018, acc.: 76.56%] [G loss: 0.554811]\n",
      "epoch:21 step:19981 [D loss: 0.505634, acc.: 72.66%] [G loss: 0.816685]\n",
      "epoch:21 step:19982 [D loss: 0.494731, acc.: 76.56%] [G loss: 0.844396]\n",
      "epoch:21 step:19983 [D loss: 0.500701, acc.: 75.00%] [G loss: 1.006695]\n",
      "epoch:21 step:19984 [D loss: 0.458960, acc.: 76.56%] [G loss: 0.867694]\n",
      "epoch:21 step:19985 [D loss: 0.529302, acc.: 75.78%] [G loss: 0.705044]\n",
      "epoch:21 step:19986 [D loss: 0.567178, acc.: 65.62%] [G loss: 0.629324]\n",
      "epoch:21 step:19987 [D loss: 0.529087, acc.: 71.09%] [G loss: 0.731407]\n",
      "epoch:21 step:19988 [D loss: 0.508519, acc.: 71.88%] [G loss: 0.620947]\n",
      "epoch:21 step:19989 [D loss: 0.474057, acc.: 76.56%] [G loss: 0.907066]\n",
      "epoch:21 step:19990 [D loss: 0.464168, acc.: 76.56%] [G loss: 0.928086]\n",
      "epoch:21 step:19991 [D loss: 0.473004, acc.: 78.91%] [G loss: 0.835359]\n",
      "epoch:21 step:19992 [D loss: 0.444865, acc.: 80.47%] [G loss: 1.002951]\n",
      "epoch:21 step:19993 [D loss: 0.636184, acc.: 63.28%] [G loss: 0.706789]\n",
      "epoch:21 step:19994 [D loss: 0.599988, acc.: 67.19%] [G loss: 0.527966]\n",
      "epoch:21 step:19995 [D loss: 0.530610, acc.: 71.88%] [G loss: 0.464479]\n",
      "epoch:21 step:19996 [D loss: 0.576286, acc.: 67.97%] [G loss: 0.551264]\n",
      "epoch:21 step:19997 [D loss: 0.578750, acc.: 67.97%] [G loss: 0.743629]\n",
      "epoch:21 step:19998 [D loss: 0.497132, acc.: 72.66%] [G loss: 0.809344]\n",
      "epoch:21 step:19999 [D loss: 0.536429, acc.: 71.88%] [G loss: 0.696862]\n",
      "epoch:21 step:20000 [D loss: 0.601713, acc.: 67.19%] [G loss: 0.672219]\n",
      "##############\n",
      "[3.15864532 1.18017579 6.1355776  4.76037562 3.75415895 5.76713632\n",
      " 4.53595759 4.89067991 4.5196776  4.17996191]\n",
      "##########\n",
      "epoch:21 step:20001 [D loss: 0.599906, acc.: 63.28%] [G loss: 0.598846]\n",
      "epoch:21 step:20002 [D loss: 0.584095, acc.: 66.41%] [G loss: 0.648671]\n",
      "epoch:21 step:20003 [D loss: 0.440186, acc.: 78.91%] [G loss: 0.798726]\n",
      "epoch:21 step:20004 [D loss: 0.484089, acc.: 73.44%] [G loss: 0.739476]\n",
      "epoch:21 step:20005 [D loss: 0.488120, acc.: 78.91%] [G loss: 0.772683]\n",
      "epoch:21 step:20006 [D loss: 0.528788, acc.: 75.00%] [G loss: 0.867962]\n",
      "epoch:21 step:20007 [D loss: 0.582245, acc.: 66.41%] [G loss: 0.573260]\n",
      "epoch:21 step:20008 [D loss: 0.521845, acc.: 77.34%] [G loss: 0.659486]\n",
      "epoch:21 step:20009 [D loss: 0.536135, acc.: 70.31%] [G loss: 0.604789]\n",
      "epoch:21 step:20010 [D loss: 0.527834, acc.: 75.78%] [G loss: 0.711414]\n",
      "epoch:21 step:20011 [D loss: 0.484465, acc.: 75.00%] [G loss: 0.749859]\n",
      "epoch:21 step:20012 [D loss: 0.545601, acc.: 71.88%] [G loss: 0.558466]\n",
      "epoch:21 step:20013 [D loss: 0.502417, acc.: 77.34%] [G loss: 0.701771]\n",
      "epoch:21 step:20014 [D loss: 0.539240, acc.: 71.88%] [G loss: 0.813709]\n",
      "epoch:21 step:20015 [D loss: 0.536427, acc.: 68.75%] [G loss: 0.766478]\n",
      "epoch:21 step:20016 [D loss: 0.549287, acc.: 70.31%] [G loss: 0.638915]\n",
      "epoch:21 step:20017 [D loss: 0.484464, acc.: 74.22%] [G loss: 0.737352]\n",
      "epoch:21 step:20018 [D loss: 0.509242, acc.: 76.56%] [G loss: 0.801211]\n",
      "epoch:21 step:20019 [D loss: 0.627367, acc.: 61.72%] [G loss: 0.557015]\n",
      "epoch:21 step:20020 [D loss: 0.494298, acc.: 77.34%] [G loss: 0.725661]\n",
      "epoch:21 step:20021 [D loss: 0.468810, acc.: 76.56%] [G loss: 0.802478]\n",
      "epoch:21 step:20022 [D loss: 0.597280, acc.: 66.41%] [G loss: 0.736645]\n",
      "epoch:21 step:20023 [D loss: 0.548665, acc.: 67.19%] [G loss: 0.793839]\n",
      "epoch:21 step:20024 [D loss: 0.475470, acc.: 80.47%] [G loss: 0.949393]\n",
      "epoch:21 step:20025 [D loss: 0.671056, acc.: 60.16%] [G loss: 0.722711]\n",
      "epoch:21 step:20026 [D loss: 0.706468, acc.: 56.25%] [G loss: 0.578064]\n",
      "epoch:21 step:20027 [D loss: 0.489476, acc.: 74.22%] [G loss: 0.714173]\n",
      "epoch:21 step:20028 [D loss: 0.481337, acc.: 75.00%] [G loss: 0.768165]\n",
      "epoch:21 step:20029 [D loss: 0.535255, acc.: 70.31%] [G loss: 0.689434]\n",
      "epoch:21 step:20030 [D loss: 0.529615, acc.: 67.97%] [G loss: 0.750679]\n",
      "epoch:21 step:20031 [D loss: 0.379489, acc.: 86.72%] [G loss: 0.790071]\n",
      "epoch:21 step:20032 [D loss: 0.551701, acc.: 67.97%] [G loss: 0.727339]\n",
      "epoch:21 step:20033 [D loss: 0.549263, acc.: 70.31%] [G loss: 0.858716]\n",
      "epoch:21 step:20034 [D loss: 0.482828, acc.: 72.66%] [G loss: 0.807376]\n",
      "epoch:21 step:20035 [D loss: 0.451769, acc.: 77.34%] [G loss: 0.910377]\n",
      "epoch:21 step:20036 [D loss: 0.493582, acc.: 72.66%] [G loss: 0.808718]\n",
      "epoch:21 step:20037 [D loss: 0.487292, acc.: 71.88%] [G loss: 0.770021]\n",
      "epoch:21 step:20038 [D loss: 0.477111, acc.: 75.00%] [G loss: 0.870591]\n",
      "epoch:21 step:20039 [D loss: 0.560177, acc.: 67.97%] [G loss: 0.875007]\n",
      "epoch:21 step:20040 [D loss: 0.564750, acc.: 67.97%] [G loss: 0.659371]\n",
      "epoch:21 step:20041 [D loss: 0.519895, acc.: 72.66%] [G loss: 0.762817]\n",
      "epoch:21 step:20042 [D loss: 0.562880, acc.: 66.41%] [G loss: 0.615574]\n",
      "epoch:21 step:20043 [D loss: 0.509900, acc.: 72.66%] [G loss: 0.698440]\n",
      "epoch:21 step:20044 [D loss: 0.589354, acc.: 68.75%] [G loss: 0.769754]\n",
      "epoch:21 step:20045 [D loss: 0.584950, acc.: 66.41%] [G loss: 0.575834]\n",
      "epoch:21 step:20046 [D loss: 0.483556, acc.: 78.12%] [G loss: 0.755342]\n",
      "epoch:21 step:20047 [D loss: 0.526854, acc.: 73.44%] [G loss: 0.667260]\n",
      "epoch:21 step:20048 [D loss: 0.495007, acc.: 75.78%] [G loss: 0.700496]\n",
      "epoch:21 step:20049 [D loss: 0.532911, acc.: 73.44%] [G loss: 0.658158]\n",
      "epoch:21 step:20050 [D loss: 0.539766, acc.: 72.66%] [G loss: 0.597373]\n",
      "epoch:21 step:20051 [D loss: 0.406383, acc.: 81.25%] [G loss: 0.739173]\n",
      "epoch:21 step:20052 [D loss: 0.557368, acc.: 70.31%] [G loss: 0.727345]\n",
      "epoch:21 step:20053 [D loss: 0.662992, acc.: 61.72%] [G loss: 0.697152]\n",
      "epoch:21 step:20054 [D loss: 0.578613, acc.: 66.41%] [G loss: 0.559077]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:21 step:20055 [D loss: 0.574262, acc.: 68.75%] [G loss: 0.800778]\n",
      "epoch:21 step:20056 [D loss: 0.569052, acc.: 70.31%] [G loss: 0.665655]\n",
      "epoch:21 step:20057 [D loss: 0.604605, acc.: 69.53%] [G loss: 0.458957]\n",
      "epoch:21 step:20058 [D loss: 0.450979, acc.: 78.12%] [G loss: 0.693407]\n",
      "epoch:21 step:20059 [D loss: 0.509814, acc.: 77.34%] [G loss: 0.726149]\n",
      "epoch:21 step:20060 [D loss: 0.578601, acc.: 66.41%] [G loss: 0.683737]\n",
      "epoch:21 step:20061 [D loss: 0.616687, acc.: 60.94%] [G loss: 0.710143]\n",
      "epoch:21 step:20062 [D loss: 0.468934, acc.: 78.12%] [G loss: 0.766220]\n",
      "epoch:21 step:20063 [D loss: 0.574297, acc.: 67.19%] [G loss: 0.700991]\n",
      "epoch:21 step:20064 [D loss: 0.528993, acc.: 69.53%] [G loss: 0.753616]\n",
      "epoch:21 step:20065 [D loss: 0.529020, acc.: 74.22%] [G loss: 0.626348]\n",
      "epoch:21 step:20066 [D loss: 0.524436, acc.: 74.22%] [G loss: 0.629882]\n",
      "epoch:21 step:20067 [D loss: 0.558144, acc.: 71.09%] [G loss: 0.611987]\n",
      "epoch:21 step:20068 [D loss: 0.532574, acc.: 72.66%] [G loss: 0.500926]\n",
      "epoch:21 step:20069 [D loss: 0.477112, acc.: 73.44%] [G loss: 0.653863]\n",
      "epoch:21 step:20070 [D loss: 0.563903, acc.: 72.66%] [G loss: 0.584362]\n",
      "epoch:21 step:20071 [D loss: 0.557621, acc.: 67.97%] [G loss: 0.626636]\n",
      "epoch:21 step:20072 [D loss: 0.502703, acc.: 73.44%] [G loss: 0.625164]\n",
      "epoch:21 step:20073 [D loss: 0.515460, acc.: 73.44%] [G loss: 0.653051]\n",
      "epoch:21 step:20074 [D loss: 0.544958, acc.: 71.09%] [G loss: 0.642523]\n",
      "epoch:21 step:20075 [D loss: 0.494374, acc.: 71.88%] [G loss: 0.687710]\n",
      "epoch:21 step:20076 [D loss: 0.491593, acc.: 78.12%] [G loss: 0.986059]\n",
      "epoch:21 step:20077 [D loss: 0.669342, acc.: 57.03%] [G loss: 0.701938]\n",
      "epoch:21 step:20078 [D loss: 0.724346, acc.: 54.69%] [G loss: 0.667028]\n",
      "epoch:21 step:20079 [D loss: 0.476581, acc.: 75.78%] [G loss: 0.822697]\n",
      "epoch:21 step:20080 [D loss: 0.479798, acc.: 76.56%] [G loss: 0.737160]\n",
      "epoch:21 step:20081 [D loss: 0.601114, acc.: 64.06%] [G loss: 0.756035]\n",
      "epoch:21 step:20082 [D loss: 0.543002, acc.: 71.09%] [G loss: 0.643511]\n",
      "epoch:21 step:20083 [D loss: 0.483448, acc.: 79.69%] [G loss: 0.832965]\n",
      "epoch:21 step:20084 [D loss: 0.590603, acc.: 67.97%] [G loss: 0.767204]\n",
      "epoch:21 step:20085 [D loss: 0.551228, acc.: 74.22%] [G loss: 0.783512]\n",
      "epoch:21 step:20086 [D loss: 0.581122, acc.: 69.53%] [G loss: 0.666195]\n",
      "epoch:21 step:20087 [D loss: 0.566651, acc.: 71.09%] [G loss: 0.698311]\n",
      "epoch:21 step:20088 [D loss: 0.622841, acc.: 64.06%] [G loss: 0.643870]\n",
      "epoch:21 step:20089 [D loss: 0.593001, acc.: 62.50%] [G loss: 0.524318]\n",
      "epoch:21 step:20090 [D loss: 0.564244, acc.: 69.53%] [G loss: 0.593290]\n",
      "epoch:21 step:20091 [D loss: 0.556606, acc.: 68.75%] [G loss: 0.607998]\n",
      "epoch:21 step:20092 [D loss: 0.514944, acc.: 72.66%] [G loss: 0.821767]\n",
      "epoch:21 step:20093 [D loss: 0.509220, acc.: 72.66%] [G loss: 0.877687]\n",
      "epoch:21 step:20094 [D loss: 0.655760, acc.: 61.72%] [G loss: 0.748970]\n",
      "epoch:21 step:20095 [D loss: 0.638860, acc.: 60.94%] [G loss: 0.613147]\n",
      "epoch:21 step:20096 [D loss: 0.572890, acc.: 69.53%] [G loss: 0.770734]\n",
      "epoch:21 step:20097 [D loss: 0.557619, acc.: 64.84%] [G loss: 0.803225]\n",
      "epoch:21 step:20098 [D loss: 0.576152, acc.: 64.84%] [G loss: 0.686582]\n",
      "epoch:21 step:20099 [D loss: 0.640568, acc.: 61.72%] [G loss: 0.539847]\n",
      "epoch:21 step:20100 [D loss: 0.537862, acc.: 74.22%] [G loss: 0.614560]\n",
      "epoch:21 step:20101 [D loss: 0.525162, acc.: 71.88%] [G loss: 0.636417]\n",
      "epoch:21 step:20102 [D loss: 0.515468, acc.: 77.34%] [G loss: 0.758079]\n",
      "epoch:21 step:20103 [D loss: 0.492527, acc.: 75.00%] [G loss: 0.650524]\n",
      "epoch:21 step:20104 [D loss: 0.448905, acc.: 78.12%] [G loss: 1.056734]\n",
      "epoch:21 step:20105 [D loss: 0.508139, acc.: 73.44%] [G loss: 0.770778]\n",
      "epoch:21 step:20106 [D loss: 0.421806, acc.: 80.47%] [G loss: 0.910710]\n",
      "epoch:21 step:20107 [D loss: 0.540331, acc.: 72.66%] [G loss: 0.805648]\n",
      "epoch:21 step:20108 [D loss: 0.504675, acc.: 71.09%] [G loss: 0.892616]\n",
      "epoch:21 step:20109 [D loss: 0.581703, acc.: 70.31%] [G loss: 0.757625]\n",
      "epoch:21 step:20110 [D loss: 0.549757, acc.: 70.31%] [G loss: 0.621820]\n",
      "epoch:21 step:20111 [D loss: 0.475435, acc.: 76.56%] [G loss: 0.725049]\n",
      "epoch:21 step:20112 [D loss: 0.537271, acc.: 67.97%] [G loss: 0.775973]\n",
      "epoch:21 step:20113 [D loss: 0.505201, acc.: 73.44%] [G loss: 0.802137]\n",
      "epoch:21 step:20114 [D loss: 0.685117, acc.: 65.62%] [G loss: 0.612819]\n",
      "epoch:21 step:20115 [D loss: 0.572990, acc.: 64.84%] [G loss: 0.712225]\n",
      "epoch:21 step:20116 [D loss: 0.553930, acc.: 75.00%] [G loss: 0.665911]\n",
      "epoch:21 step:20117 [D loss: 0.478541, acc.: 75.00%] [G loss: 1.055807]\n",
      "epoch:21 step:20118 [D loss: 0.524748, acc.: 69.53%] [G loss: 1.063613]\n",
      "epoch:21 step:20119 [D loss: 0.594282, acc.: 62.50%] [G loss: 0.508252]\n",
      "epoch:21 step:20120 [D loss: 0.497352, acc.: 76.56%] [G loss: 0.818108]\n",
      "epoch:21 step:20121 [D loss: 0.541949, acc.: 73.44%] [G loss: 0.747587]\n",
      "epoch:21 step:20122 [D loss: 0.565951, acc.: 71.09%] [G loss: 0.783964]\n",
      "epoch:21 step:20123 [D loss: 0.598589, acc.: 62.50%] [G loss: 0.789978]\n",
      "epoch:21 step:20124 [D loss: 0.540169, acc.: 69.53%] [G loss: 0.860671]\n",
      "epoch:21 step:20125 [D loss: 0.529680, acc.: 72.66%] [G loss: 0.617703]\n",
      "epoch:21 step:20126 [D loss: 0.503703, acc.: 75.78%] [G loss: 0.670180]\n",
      "epoch:21 step:20127 [D loss: 0.478379, acc.: 79.69%] [G loss: 0.720351]\n",
      "epoch:21 step:20128 [D loss: 0.422797, acc.: 79.69%] [G loss: 0.776482]\n",
      "epoch:21 step:20129 [D loss: 0.458126, acc.: 80.47%] [G loss: 0.812050]\n",
      "epoch:21 step:20130 [D loss: 0.535889, acc.: 70.31%] [G loss: 0.930478]\n",
      "epoch:21 step:20131 [D loss: 0.559151, acc.: 71.09%] [G loss: 0.783057]\n",
      "epoch:21 step:20132 [D loss: 0.539619, acc.: 70.31%] [G loss: 0.658823]\n",
      "epoch:21 step:20133 [D loss: 0.611223, acc.: 62.50%] [G loss: 0.594177]\n",
      "epoch:21 step:20134 [D loss: 0.478892, acc.: 78.12%] [G loss: 0.771445]\n",
      "epoch:21 step:20135 [D loss: 0.611896, acc.: 66.41%] [G loss: 0.672291]\n",
      "epoch:21 step:20136 [D loss: 0.510320, acc.: 76.56%] [G loss: 0.660204]\n",
      "epoch:21 step:20137 [D loss: 0.522685, acc.: 72.66%] [G loss: 0.697253]\n",
      "epoch:21 step:20138 [D loss: 0.508593, acc.: 74.22%] [G loss: 0.741972]\n",
      "epoch:21 step:20139 [D loss: 0.564183, acc.: 70.31%] [G loss: 0.791527]\n",
      "epoch:21 step:20140 [D loss: 0.544960, acc.: 69.53%] [G loss: 0.677051]\n",
      "epoch:21 step:20141 [D loss: 0.552833, acc.: 73.44%] [G loss: 0.534731]\n",
      "epoch:21 step:20142 [D loss: 0.576442, acc.: 65.62%] [G loss: 0.661488]\n",
      "epoch:21 step:20143 [D loss: 0.515592, acc.: 73.44%] [G loss: 0.670162]\n",
      "epoch:21 step:20144 [D loss: 0.505274, acc.: 71.88%] [G loss: 0.743502]\n",
      "epoch:21 step:20145 [D loss: 0.551442, acc.: 65.62%] [G loss: 0.744772]\n",
      "epoch:21 step:20146 [D loss: 0.521494, acc.: 71.88%] [G loss: 0.883035]\n",
      "epoch:21 step:20147 [D loss: 0.556876, acc.: 70.31%] [G loss: 0.847536]\n",
      "epoch:21 step:20148 [D loss: 0.411497, acc.: 82.81%] [G loss: 0.939526]\n",
      "epoch:21 step:20149 [D loss: 0.468759, acc.: 79.69%] [G loss: 1.051698]\n",
      "epoch:21 step:20150 [D loss: 0.747542, acc.: 54.69%] [G loss: 0.630264]\n",
      "epoch:21 step:20151 [D loss: 0.543625, acc.: 65.62%] [G loss: 0.737143]\n",
      "epoch:21 step:20152 [D loss: 0.467993, acc.: 77.34%] [G loss: 0.911534]\n",
      "epoch:21 step:20153 [D loss: 0.559568, acc.: 71.88%] [G loss: 0.829660]\n",
      "epoch:21 step:20154 [D loss: 0.683479, acc.: 62.50%] [G loss: 0.563873]\n",
      "epoch:21 step:20155 [D loss: 0.576993, acc.: 71.09%] [G loss: 0.576836]\n",
      "epoch:21 step:20156 [D loss: 0.467675, acc.: 81.25%] [G loss: 0.637993]\n",
      "epoch:21 step:20157 [D loss: 0.599087, acc.: 71.88%] [G loss: 0.606577]\n",
      "epoch:21 step:20158 [D loss: 0.486102, acc.: 77.34%] [G loss: 0.779680]\n",
      "epoch:21 step:20159 [D loss: 0.589193, acc.: 67.97%] [G loss: 0.571072]\n",
      "epoch:21 step:20160 [D loss: 0.512334, acc.: 78.12%] [G loss: 0.669688]\n",
      "epoch:21 step:20161 [D loss: 0.521522, acc.: 73.44%] [G loss: 0.725778]\n",
      "epoch:21 step:20162 [D loss: 0.516374, acc.: 70.31%] [G loss: 0.782017]\n",
      "epoch:21 step:20163 [D loss: 0.536796, acc.: 70.31%] [G loss: 0.656161]\n",
      "epoch:21 step:20164 [D loss: 0.584828, acc.: 67.19%] [G loss: 0.543939]\n",
      "epoch:21 step:20165 [D loss: 0.524884, acc.: 74.22%] [G loss: 0.532525]\n",
      "epoch:21 step:20166 [D loss: 0.550918, acc.: 67.97%] [G loss: 0.626427]\n",
      "epoch:21 step:20167 [D loss: 0.570119, acc.: 65.62%] [G loss: 0.647930]\n",
      "epoch:21 step:20168 [D loss: 0.554644, acc.: 67.97%] [G loss: 0.695646]\n",
      "epoch:21 step:20169 [D loss: 0.556007, acc.: 68.75%] [G loss: 0.645049]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:21 step:20170 [D loss: 0.595939, acc.: 64.84%] [G loss: 0.530599]\n",
      "epoch:21 step:20171 [D loss: 0.569052, acc.: 69.53%] [G loss: 0.517911]\n",
      "epoch:21 step:20172 [D loss: 0.518114, acc.: 71.88%] [G loss: 0.525022]\n",
      "epoch:21 step:20173 [D loss: 0.554114, acc.: 74.22%] [G loss: 0.645166]\n",
      "epoch:21 step:20174 [D loss: 0.563370, acc.: 75.00%] [G loss: 0.742373]\n",
      "epoch:21 step:20175 [D loss: 0.500648, acc.: 74.22%] [G loss: 0.775346]\n",
      "epoch:21 step:20176 [D loss: 0.527113, acc.: 75.78%] [G loss: 0.734952]\n",
      "epoch:21 step:20177 [D loss: 0.580116, acc.: 69.53%] [G loss: 0.681102]\n",
      "epoch:21 step:20178 [D loss: 0.669110, acc.: 58.59%] [G loss: 0.470081]\n",
      "epoch:21 step:20179 [D loss: 0.612404, acc.: 62.50%] [G loss: 0.564003]\n",
      "epoch:21 step:20180 [D loss: 0.499689, acc.: 75.78%] [G loss: 0.541715]\n",
      "epoch:21 step:20181 [D loss: 0.470910, acc.: 78.91%] [G loss: 0.895025]\n",
      "epoch:21 step:20182 [D loss: 0.485696, acc.: 78.91%] [G loss: 0.884579]\n",
      "epoch:21 step:20183 [D loss: 0.560565, acc.: 71.09%] [G loss: 0.893495]\n",
      "epoch:21 step:20184 [D loss: 0.489921, acc.: 76.56%] [G loss: 0.872158]\n",
      "epoch:21 step:20185 [D loss: 0.464841, acc.: 78.12%] [G loss: 1.056452]\n",
      "epoch:21 step:20186 [D loss: 0.509994, acc.: 73.44%] [G loss: 0.939569]\n",
      "epoch:21 step:20187 [D loss: 0.600017, acc.: 69.53%] [G loss: 0.715643]\n",
      "epoch:21 step:20188 [D loss: 0.641255, acc.: 56.25%] [G loss: 0.577886]\n",
      "epoch:21 step:20189 [D loss: 0.588325, acc.: 68.75%] [G loss: 0.562454]\n",
      "epoch:21 step:20190 [D loss: 0.558158, acc.: 68.75%] [G loss: 0.520621]\n",
      "epoch:21 step:20191 [D loss: 0.478732, acc.: 77.34%] [G loss: 0.659947]\n",
      "epoch:21 step:20192 [D loss: 0.497747, acc.: 77.34%] [G loss: 0.634910]\n",
      "epoch:21 step:20193 [D loss: 0.542435, acc.: 69.53%] [G loss: 0.616949]\n",
      "epoch:21 step:20194 [D loss: 0.500358, acc.: 71.09%] [G loss: 0.789166]\n",
      "epoch:21 step:20195 [D loss: 0.542858, acc.: 72.66%] [G loss: 0.662247]\n",
      "epoch:21 step:20196 [D loss: 0.512791, acc.: 71.09%] [G loss: 0.795931]\n",
      "epoch:21 step:20197 [D loss: 0.473495, acc.: 77.34%] [G loss: 0.745397]\n",
      "epoch:21 step:20198 [D loss: 0.490725, acc.: 74.22%] [G loss: 0.749186]\n",
      "epoch:21 step:20199 [D loss: 0.533757, acc.: 69.53%] [G loss: 0.683582]\n",
      "epoch:21 step:20200 [D loss: 0.503582, acc.: 73.44%] [G loss: 0.694993]\n",
      "##############\n",
      "[2.98715353 1.03585435 6.0631479  4.87199834 4.23775195 5.76292323\n",
      " 4.47619861 4.82209186 4.69559154 4.11914462]\n",
      "##########\n",
      "epoch:21 step:20201 [D loss: 0.558901, acc.: 68.75%] [G loss: 0.682480]\n",
      "epoch:21 step:20202 [D loss: 0.601792, acc.: 65.62%] [G loss: 0.806205]\n",
      "epoch:21 step:20203 [D loss: 0.486584, acc.: 77.34%] [G loss: 0.624198]\n",
      "epoch:21 step:20204 [D loss: 0.555522, acc.: 71.88%] [G loss: 0.644964]\n",
      "epoch:21 step:20205 [D loss: 0.604883, acc.: 64.06%] [G loss: 0.584553]\n",
      "epoch:21 step:20206 [D loss: 0.578930, acc.: 63.28%] [G loss: 0.578522]\n",
      "epoch:21 step:20207 [D loss: 0.542844, acc.: 65.62%] [G loss: 0.826963]\n",
      "epoch:21 step:20208 [D loss: 0.509552, acc.: 76.56%] [G loss: 0.772100]\n",
      "epoch:21 step:20209 [D loss: 0.591476, acc.: 64.06%] [G loss: 0.631808]\n",
      "epoch:21 step:20210 [D loss: 0.521958, acc.: 72.66%] [G loss: 0.719071]\n",
      "epoch:21 step:20211 [D loss: 0.492864, acc.: 72.66%] [G loss: 0.814749]\n",
      "epoch:21 step:20212 [D loss: 0.659118, acc.: 63.28%] [G loss: 0.669174]\n",
      "epoch:21 step:20213 [D loss: 0.470073, acc.: 76.56%] [G loss: 0.744331]\n",
      "epoch:21 step:20214 [D loss: 0.563838, acc.: 69.53%] [G loss: 0.648654]\n",
      "epoch:21 step:20215 [D loss: 0.526556, acc.: 71.88%] [G loss: 0.671351]\n",
      "epoch:21 step:20216 [D loss: 0.567461, acc.: 64.06%] [G loss: 0.476839]\n",
      "epoch:21 step:20217 [D loss: 0.514187, acc.: 66.41%] [G loss: 0.743621]\n",
      "epoch:21 step:20218 [D loss: 0.552131, acc.: 69.53%] [G loss: 0.629092]\n",
      "epoch:21 step:20219 [D loss: 0.640416, acc.: 64.84%] [G loss: 0.539841]\n",
      "epoch:21 step:20220 [D loss: 0.603485, acc.: 65.62%] [G loss: 0.594177]\n",
      "epoch:21 step:20221 [D loss: 0.517755, acc.: 74.22%] [G loss: 0.656775]\n",
      "epoch:21 step:20222 [D loss: 0.518478, acc.: 72.66%] [G loss: 0.689935]\n",
      "epoch:21 step:20223 [D loss: 0.511380, acc.: 75.00%] [G loss: 0.840431]\n",
      "epoch:21 step:20224 [D loss: 0.559659, acc.: 67.97%] [G loss: 0.670816]\n",
      "epoch:21 step:20225 [D loss: 0.493048, acc.: 76.56%] [G loss: 0.593627]\n",
      "epoch:21 step:20226 [D loss: 0.536790, acc.: 71.09%] [G loss: 0.749180]\n",
      "epoch:21 step:20227 [D loss: 0.533519, acc.: 73.44%] [G loss: 0.543070]\n",
      "epoch:21 step:20228 [D loss: 0.480480, acc.: 75.00%] [G loss: 0.751454]\n",
      "epoch:21 step:20229 [D loss: 0.486482, acc.: 76.56%] [G loss: 0.900546]\n",
      "epoch:21 step:20230 [D loss: 0.625939, acc.: 64.06%] [G loss: 0.663753]\n",
      "epoch:21 step:20231 [D loss: 0.466899, acc.: 76.56%] [G loss: 0.692943]\n",
      "epoch:21 step:20232 [D loss: 0.472647, acc.: 74.22%] [G loss: 0.726685]\n",
      "epoch:21 step:20233 [D loss: 0.584056, acc.: 68.75%] [G loss: 0.619099]\n",
      "epoch:21 step:20234 [D loss: 0.547923, acc.: 71.88%] [G loss: 0.711552]\n",
      "epoch:21 step:20235 [D loss: 0.474531, acc.: 78.91%] [G loss: 0.785827]\n",
      "epoch:21 step:20236 [D loss: 0.552966, acc.: 71.88%] [G loss: 0.667605]\n",
      "epoch:21 step:20237 [D loss: 0.564520, acc.: 66.41%] [G loss: 0.506185]\n",
      "epoch:21 step:20238 [D loss: 0.575804, acc.: 65.62%] [G loss: 0.620755]\n",
      "epoch:21 step:20239 [D loss: 0.557963, acc.: 66.41%] [G loss: 0.582084]\n",
      "epoch:21 step:20240 [D loss: 0.543308, acc.: 69.53%] [G loss: 0.638675]\n",
      "epoch:21 step:20241 [D loss: 0.505251, acc.: 82.03%] [G loss: 0.767374]\n",
      "epoch:21 step:20242 [D loss: 0.567753, acc.: 70.31%] [G loss: 0.745096]\n",
      "epoch:21 step:20243 [D loss: 0.726977, acc.: 60.16%] [G loss: 0.561880]\n",
      "epoch:21 step:20244 [D loss: 0.497457, acc.: 76.56%] [G loss: 0.446807]\n",
      "epoch:21 step:20245 [D loss: 0.524129, acc.: 71.88%] [G loss: 0.763941]\n",
      "epoch:21 step:20246 [D loss: 0.502896, acc.: 73.44%] [G loss: 0.814509]\n",
      "epoch:21 step:20247 [D loss: 0.508651, acc.: 73.44%] [G loss: 0.831853]\n",
      "epoch:21 step:20248 [D loss: 0.568028, acc.: 74.22%] [G loss: 0.776407]\n",
      "epoch:21 step:20249 [D loss: 0.528768, acc.: 75.78%] [G loss: 0.543682]\n",
      "epoch:21 step:20250 [D loss: 0.549819, acc.: 74.22%] [G loss: 0.852309]\n",
      "epoch:21 step:20251 [D loss: 0.459056, acc.: 82.81%] [G loss: 0.814764]\n",
      "epoch:21 step:20252 [D loss: 0.518720, acc.: 75.00%] [G loss: 0.816571]\n",
      "epoch:21 step:20253 [D loss: 0.598273, acc.: 68.75%] [G loss: 0.646753]\n",
      "epoch:21 step:20254 [D loss: 0.549811, acc.: 71.09%] [G loss: 0.906888]\n",
      "epoch:21 step:20255 [D loss: 0.580239, acc.: 64.84%] [G loss: 0.474379]\n",
      "epoch:21 step:20256 [D loss: 0.522976, acc.: 71.88%] [G loss: 0.483232]\n",
      "epoch:21 step:20257 [D loss: 0.549531, acc.: 67.97%] [G loss: 0.645705]\n",
      "epoch:21 step:20258 [D loss: 0.548552, acc.: 73.44%] [G loss: 0.647716]\n",
      "epoch:21 step:20259 [D loss: 0.440975, acc.: 84.38%] [G loss: 0.889855]\n",
      "epoch:21 step:20260 [D loss: 0.596179, acc.: 70.31%] [G loss: 0.944572]\n",
      "epoch:21 step:20261 [D loss: 0.553861, acc.: 68.75%] [G loss: 0.755393]\n",
      "epoch:21 step:20262 [D loss: 0.540829, acc.: 71.88%] [G loss: 0.650210]\n",
      "epoch:21 step:20263 [D loss: 0.569070, acc.: 64.84%] [G loss: 0.487760]\n",
      "epoch:21 step:20264 [D loss: 0.555238, acc.: 71.09%] [G loss: 0.544713]\n",
      "epoch:21 step:20265 [D loss: 0.572359, acc.: 67.97%] [G loss: 0.622674]\n",
      "epoch:21 step:20266 [D loss: 0.512852, acc.: 72.66%] [G loss: 0.757274]\n",
      "epoch:21 step:20267 [D loss: 0.608490, acc.: 70.31%] [G loss: 0.742757]\n",
      "epoch:21 step:20268 [D loss: 0.571971, acc.: 71.09%] [G loss: 0.636160]\n",
      "epoch:21 step:20269 [D loss: 0.486820, acc.: 78.91%] [G loss: 0.765410]\n",
      "epoch:21 step:20270 [D loss: 0.521931, acc.: 73.44%] [G loss: 0.627394]\n",
      "epoch:21 step:20271 [D loss: 0.547271, acc.: 70.31%] [G loss: 0.639490]\n",
      "epoch:21 step:20272 [D loss: 0.556453, acc.: 68.75%] [G loss: 0.608407]\n",
      "epoch:21 step:20273 [D loss: 0.565852, acc.: 67.97%] [G loss: 0.574858]\n",
      "epoch:21 step:20274 [D loss: 0.540078, acc.: 68.75%] [G loss: 0.618554]\n",
      "epoch:21 step:20275 [D loss: 0.480659, acc.: 77.34%] [G loss: 0.848689]\n",
      "epoch:21 step:20276 [D loss: 0.542593, acc.: 71.09%] [G loss: 0.673659]\n",
      "epoch:21 step:20277 [D loss: 0.591242, acc.: 67.97%] [G loss: 0.699793]\n",
      "epoch:21 step:20278 [D loss: 0.526984, acc.: 71.09%] [G loss: 0.730736]\n",
      "epoch:21 step:20279 [D loss: 0.556396, acc.: 67.97%] [G loss: 0.658759]\n",
      "epoch:21 step:20280 [D loss: 0.504246, acc.: 70.31%] [G loss: 0.812952]\n",
      "epoch:21 step:20281 [D loss: 0.589715, acc.: 66.41%] [G loss: 0.613352]\n",
      "epoch:21 step:20282 [D loss: 0.432853, acc.: 82.03%] [G loss: 0.683383]\n",
      "epoch:21 step:20283 [D loss: 0.612675, acc.: 63.28%] [G loss: 0.750280]\n",
      "epoch:21 step:20284 [D loss: 0.529233, acc.: 71.09%] [G loss: 0.549568]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:21 step:20285 [D loss: 0.531332, acc.: 69.53%] [G loss: 0.641492]\n",
      "epoch:21 step:20286 [D loss: 0.539398, acc.: 67.19%] [G loss: 0.587916]\n",
      "epoch:21 step:20287 [D loss: 0.557977, acc.: 70.31%] [G loss: 0.508294]\n",
      "epoch:21 step:20288 [D loss: 0.478741, acc.: 78.91%] [G loss: 0.628136]\n",
      "epoch:21 step:20289 [D loss: 0.553805, acc.: 68.75%] [G loss: 0.671278]\n",
      "epoch:21 step:20290 [D loss: 0.466981, acc.: 77.34%] [G loss: 0.731235]\n",
      "epoch:21 step:20291 [D loss: 0.578872, acc.: 64.06%] [G loss: 0.622851]\n",
      "epoch:21 step:20292 [D loss: 0.576242, acc.: 64.06%] [G loss: 0.543605]\n",
      "epoch:21 step:20293 [D loss: 0.621315, acc.: 58.59%] [G loss: 0.684327]\n",
      "epoch:21 step:20294 [D loss: 0.562005, acc.: 67.97%] [G loss: 0.860098]\n",
      "epoch:21 step:20295 [D loss: 0.538186, acc.: 72.66%] [G loss: 0.670730]\n",
      "epoch:21 step:20296 [D loss: 0.612953, acc.: 64.84%] [G loss: 0.563729]\n",
      "epoch:21 step:20297 [D loss: 0.523644, acc.: 70.31%] [G loss: 0.625357]\n",
      "epoch:21 step:20298 [D loss: 0.502292, acc.: 73.44%] [G loss: 0.693178]\n",
      "epoch:21 step:20299 [D loss: 0.540866, acc.: 74.22%] [G loss: 0.586654]\n",
      "epoch:21 step:20300 [D loss: 0.476750, acc.: 78.12%] [G loss: 0.717922]\n",
      "epoch:21 step:20301 [D loss: 0.502141, acc.: 77.34%] [G loss: 0.726864]\n",
      "epoch:21 step:20302 [D loss: 0.575122, acc.: 68.75%] [G loss: 0.709838]\n",
      "epoch:21 step:20303 [D loss: 0.578652, acc.: 66.41%] [G loss: 0.683703]\n",
      "epoch:21 step:20304 [D loss: 0.579659, acc.: 66.41%] [G loss: 0.624255]\n",
      "epoch:21 step:20305 [D loss: 0.601095, acc.: 68.75%] [G loss: 0.502645]\n",
      "epoch:21 step:20306 [D loss: 0.475236, acc.: 78.12%] [G loss: 0.631666]\n",
      "epoch:21 step:20307 [D loss: 0.560071, acc.: 67.97%] [G loss: 0.740061]\n",
      "epoch:21 step:20308 [D loss: 0.524024, acc.: 77.34%] [G loss: 0.660373]\n",
      "epoch:21 step:20309 [D loss: 0.486339, acc.: 74.22%] [G loss: 0.790364]\n",
      "epoch:21 step:20310 [D loss: 0.529325, acc.: 71.09%] [G loss: 0.742178]\n",
      "epoch:21 step:20311 [D loss: 0.418054, acc.: 84.38%] [G loss: 0.697754]\n",
      "epoch:21 step:20312 [D loss: 0.495152, acc.: 74.22%] [G loss: 0.813761]\n",
      "epoch:21 step:20313 [D loss: 0.584321, acc.: 66.41%] [G loss: 0.761351]\n",
      "epoch:21 step:20314 [D loss: 0.585381, acc.: 65.62%] [G loss: 0.579449]\n",
      "epoch:21 step:20315 [D loss: 0.582730, acc.: 60.94%] [G loss: 0.669823]\n",
      "epoch:21 step:20316 [D loss: 0.546010, acc.: 68.75%] [G loss: 0.628543]\n",
      "epoch:21 step:20317 [D loss: 0.575282, acc.: 68.75%] [G loss: 0.809293]\n",
      "epoch:21 step:20318 [D loss: 0.508742, acc.: 75.78%] [G loss: 0.831442]\n",
      "epoch:21 step:20319 [D loss: 0.500374, acc.: 72.66%] [G loss: 1.032313]\n",
      "epoch:21 step:20320 [D loss: 0.503819, acc.: 69.53%] [G loss: 1.054485]\n",
      "epoch:21 step:20321 [D loss: 0.523630, acc.: 72.66%] [G loss: 0.804760]\n",
      "epoch:21 step:20322 [D loss: 0.577115, acc.: 65.62%] [G loss: 0.611858]\n",
      "epoch:21 step:20323 [D loss: 0.498406, acc.: 75.78%] [G loss: 0.639723]\n",
      "epoch:21 step:20324 [D loss: 0.443226, acc.: 82.03%] [G loss: 0.764581]\n",
      "epoch:21 step:20325 [D loss: 0.412227, acc.: 85.16%] [G loss: 0.915352]\n",
      "epoch:21 step:20326 [D loss: 0.475546, acc.: 75.00%] [G loss: 0.888329]\n",
      "epoch:21 step:20327 [D loss: 0.474995, acc.: 78.12%] [G loss: 0.947904]\n",
      "epoch:21 step:20328 [D loss: 0.513554, acc.: 78.12%] [G loss: 0.853948]\n",
      "epoch:21 step:20329 [D loss: 0.644661, acc.: 61.72%] [G loss: 0.632686]\n",
      "epoch:21 step:20330 [D loss: 0.527008, acc.: 72.66%] [G loss: 0.692016]\n",
      "epoch:21 step:20331 [D loss: 0.505658, acc.: 75.78%] [G loss: 0.823389]\n",
      "epoch:21 step:20332 [D loss: 0.607630, acc.: 67.97%] [G loss: 0.596261]\n",
      "epoch:21 step:20333 [D loss: 0.514460, acc.: 75.78%] [G loss: 0.640843]\n",
      "epoch:21 step:20334 [D loss: 0.478233, acc.: 73.44%] [G loss: 0.776028]\n",
      "epoch:21 step:20335 [D loss: 0.568536, acc.: 68.75%] [G loss: 0.726463]\n",
      "epoch:21 step:20336 [D loss: 0.518190, acc.: 74.22%] [G loss: 0.797955]\n",
      "epoch:21 step:20337 [D loss: 0.542551, acc.: 71.88%] [G loss: 0.793343]\n",
      "epoch:21 step:20338 [D loss: 0.452166, acc.: 77.34%] [G loss: 0.711284]\n",
      "epoch:21 step:20339 [D loss: 0.606930, acc.: 67.19%] [G loss: 0.595009]\n",
      "epoch:21 step:20340 [D loss: 0.571958, acc.: 68.75%] [G loss: 0.641914]\n",
      "epoch:21 step:20341 [D loss: 0.577192, acc.: 61.72%] [G loss: 0.591093]\n",
      "epoch:21 step:20342 [D loss: 0.529015, acc.: 72.66%] [G loss: 0.556417]\n",
      "epoch:21 step:20343 [D loss: 0.508894, acc.: 74.22%] [G loss: 0.586795]\n",
      "epoch:21 step:20344 [D loss: 0.534467, acc.: 70.31%] [G loss: 0.659617]\n",
      "epoch:21 step:20345 [D loss: 0.552115, acc.: 72.66%] [G loss: 0.742887]\n",
      "epoch:21 step:20346 [D loss: 0.511498, acc.: 76.56%] [G loss: 0.677686]\n",
      "epoch:21 step:20347 [D loss: 0.515533, acc.: 68.75%] [G loss: 0.637646]\n",
      "epoch:21 step:20348 [D loss: 0.567645, acc.: 71.09%] [G loss: 0.824097]\n",
      "epoch:21 step:20349 [D loss: 0.565083, acc.: 67.19%] [G loss: 0.765107]\n",
      "epoch:21 step:20350 [D loss: 0.604496, acc.: 64.06%] [G loss: 0.693726]\n",
      "epoch:21 step:20351 [D loss: 0.536808, acc.: 68.75%] [G loss: 0.696747]\n",
      "epoch:21 step:20352 [D loss: 0.569912, acc.: 69.53%] [G loss: 0.620296]\n",
      "epoch:21 step:20353 [D loss: 0.510423, acc.: 71.09%] [G loss: 0.702522]\n",
      "epoch:21 step:20354 [D loss: 0.516025, acc.: 71.88%] [G loss: 0.644827]\n",
      "epoch:21 step:20355 [D loss: 0.555543, acc.: 70.31%] [G loss: 0.708249]\n",
      "epoch:21 step:20356 [D loss: 0.462737, acc.: 76.56%] [G loss: 0.590884]\n",
      "epoch:21 step:20357 [D loss: 0.541680, acc.: 71.09%] [G loss: 0.721872]\n",
      "epoch:21 step:20358 [D loss: 0.527690, acc.: 71.09%] [G loss: 0.724034]\n",
      "epoch:21 step:20359 [D loss: 0.538391, acc.: 71.88%] [G loss: 0.739442]\n",
      "epoch:21 step:20360 [D loss: 0.545818, acc.: 67.97%] [G loss: 0.756570]\n",
      "epoch:21 step:20361 [D loss: 0.585395, acc.: 71.09%] [G loss: 0.501294]\n",
      "epoch:21 step:20362 [D loss: 0.530097, acc.: 76.56%] [G loss: 0.490566]\n",
      "epoch:21 step:20363 [D loss: 0.573812, acc.: 64.06%] [G loss: 0.542207]\n",
      "epoch:21 step:20364 [D loss: 0.603747, acc.: 64.06%] [G loss: 0.550505]\n",
      "epoch:21 step:20365 [D loss: 0.546726, acc.: 67.97%] [G loss: 0.624143]\n",
      "epoch:21 step:20366 [D loss: 0.597828, acc.: 62.50%] [G loss: 0.591487]\n",
      "epoch:21 step:20367 [D loss: 0.498445, acc.: 75.00%] [G loss: 0.626427]\n",
      "epoch:21 step:20368 [D loss: 0.584982, acc.: 67.19%] [G loss: 0.563577]\n",
      "epoch:21 step:20369 [D loss: 0.498871, acc.: 75.00%] [G loss: 0.603520]\n",
      "epoch:21 step:20370 [D loss: 0.484646, acc.: 78.91%] [G loss: 0.748067]\n",
      "epoch:21 step:20371 [D loss: 0.438392, acc.: 81.25%] [G loss: 0.741651]\n",
      "epoch:21 step:20372 [D loss: 0.526783, acc.: 75.00%] [G loss: 0.823090]\n",
      "epoch:21 step:20373 [D loss: 0.643246, acc.: 59.38%] [G loss: 0.700709]\n",
      "epoch:21 step:20374 [D loss: 0.541664, acc.: 67.97%] [G loss: 0.540553]\n",
      "epoch:21 step:20375 [D loss: 0.545749, acc.: 67.97%] [G loss: 0.471495]\n",
      "epoch:21 step:20376 [D loss: 0.563557, acc.: 69.53%] [G loss: 0.603030]\n",
      "epoch:21 step:20377 [D loss: 0.542706, acc.: 73.44%] [G loss: 0.641982]\n",
      "epoch:21 step:20378 [D loss: 0.540178, acc.: 74.22%] [G loss: 0.636698]\n",
      "epoch:21 step:20379 [D loss: 0.566014, acc.: 71.09%] [G loss: 0.609417]\n",
      "epoch:21 step:20380 [D loss: 0.631674, acc.: 64.06%] [G loss: 0.582119]\n",
      "epoch:21 step:20381 [D loss: 0.594402, acc.: 64.06%] [G loss: 0.547770]\n",
      "epoch:21 step:20382 [D loss: 0.497374, acc.: 75.00%] [G loss: 0.678405]\n",
      "epoch:21 step:20383 [D loss: 0.560171, acc.: 67.97%] [G loss: 0.519731]\n",
      "epoch:21 step:20384 [D loss: 0.513559, acc.: 71.88%] [G loss: 0.681705]\n",
      "epoch:21 step:20385 [D loss: 0.513220, acc.: 75.00%] [G loss: 0.788970]\n",
      "epoch:21 step:20386 [D loss: 0.526650, acc.: 77.34%] [G loss: 0.712454]\n",
      "epoch:21 step:20387 [D loss: 0.544758, acc.: 68.75%] [G loss: 0.637858]\n",
      "epoch:21 step:20388 [D loss: 0.586876, acc.: 65.62%] [G loss: 0.635974]\n",
      "epoch:21 step:20389 [D loss: 0.533815, acc.: 69.53%] [G loss: 0.646571]\n",
      "epoch:21 step:20390 [D loss: 0.570950, acc.: 67.97%] [G loss: 0.682627]\n",
      "epoch:21 step:20391 [D loss: 0.485713, acc.: 78.12%] [G loss: 0.671322]\n",
      "epoch:21 step:20392 [D loss: 0.580330, acc.: 69.53%] [G loss: 0.636737]\n",
      "epoch:21 step:20393 [D loss: 0.586115, acc.: 60.94%] [G loss: 0.607575]\n",
      "epoch:21 step:20394 [D loss: 0.562440, acc.: 71.09%] [G loss: 0.524640]\n",
      "epoch:21 step:20395 [D loss: 0.598609, acc.: 62.50%] [G loss: 0.489201]\n",
      "epoch:21 step:20396 [D loss: 0.469395, acc.: 78.91%] [G loss: 0.663708]\n",
      "epoch:21 step:20397 [D loss: 0.565890, acc.: 66.41%] [G loss: 0.647047]\n",
      "epoch:21 step:20398 [D loss: 0.556280, acc.: 70.31%] [G loss: 0.559688]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:21 step:20399 [D loss: 0.541360, acc.: 75.00%] [G loss: 0.618988]\n",
      "epoch:21 step:20400 [D loss: 0.567781, acc.: 70.31%] [G loss: 0.461754]\n",
      "##############\n",
      "[3.08318829 1.30314965 6.59262789 4.8929882  3.85438557 5.57964908\n",
      " 4.49880984 4.92629153 4.6736929  4.31244794]\n",
      "##########\n",
      "epoch:21 step:20401 [D loss: 0.438413, acc.: 83.59%] [G loss: 0.645883]\n",
      "epoch:21 step:20402 [D loss: 0.478816, acc.: 80.47%] [G loss: 0.720870]\n",
      "epoch:21 step:20403 [D loss: 0.534818, acc.: 71.88%] [G loss: 0.799366]\n",
      "epoch:21 step:20404 [D loss: 0.533370, acc.: 73.44%] [G loss: 0.723805]\n",
      "epoch:21 step:20405 [D loss: 0.556991, acc.: 68.75%] [G loss: 0.699828]\n",
      "epoch:21 step:20406 [D loss: 0.552255, acc.: 71.88%] [G loss: 0.672025]\n",
      "epoch:21 step:20407 [D loss: 0.539903, acc.: 73.44%] [G loss: 0.639329]\n",
      "epoch:21 step:20408 [D loss: 0.581641, acc.: 68.75%] [G loss: 0.695367]\n",
      "epoch:21 step:20409 [D loss: 0.538390, acc.: 71.09%] [G loss: 0.530665]\n",
      "epoch:21 step:20410 [D loss: 0.538249, acc.: 71.09%] [G loss: 0.655456]\n",
      "epoch:21 step:20411 [D loss: 0.564194, acc.: 71.88%] [G loss: 0.525132]\n",
      "epoch:21 step:20412 [D loss: 0.628625, acc.: 63.28%] [G loss: 0.464908]\n",
      "epoch:21 step:20413 [D loss: 0.509509, acc.: 71.88%] [G loss: 0.664245]\n",
      "epoch:21 step:20414 [D loss: 0.514843, acc.: 76.56%] [G loss: 0.706674]\n",
      "epoch:21 step:20415 [D loss: 0.497448, acc.: 68.75%] [G loss: 0.781687]\n",
      "epoch:21 step:20416 [D loss: 0.545862, acc.: 71.88%] [G loss: 0.628650]\n",
      "epoch:21 step:20417 [D loss: 0.599559, acc.: 62.50%] [G loss: 0.481817]\n",
      "epoch:21 step:20418 [D loss: 0.521726, acc.: 68.75%] [G loss: 0.539931]\n",
      "epoch:21 step:20419 [D loss: 0.554882, acc.: 72.66%] [G loss: 0.675947]\n",
      "epoch:21 step:20420 [D loss: 0.528571, acc.: 73.44%] [G loss: 0.682679]\n",
      "epoch:21 step:20421 [D loss: 0.511943, acc.: 78.91%] [G loss: 0.653839]\n",
      "epoch:21 step:20422 [D loss: 0.558547, acc.: 62.50%] [G loss: 0.636497]\n",
      "epoch:21 step:20423 [D loss: 0.427758, acc.: 78.12%] [G loss: 0.613855]\n",
      "epoch:21 step:20424 [D loss: 0.472050, acc.: 77.34%] [G loss: 0.706835]\n",
      "epoch:21 step:20425 [D loss: 0.518862, acc.: 74.22%] [G loss: 0.620871]\n",
      "epoch:21 step:20426 [D loss: 0.543882, acc.: 73.44%] [G loss: 0.598434]\n",
      "epoch:21 step:20427 [D loss: 0.479018, acc.: 77.34%] [G loss: 0.605629]\n",
      "epoch:21 step:20428 [D loss: 0.489637, acc.: 75.78%] [G loss: 0.729020]\n",
      "epoch:21 step:20429 [D loss: 0.609237, acc.: 65.62%] [G loss: 0.795804]\n",
      "epoch:21 step:20430 [D loss: 0.524311, acc.: 76.56%] [G loss: 0.663671]\n",
      "epoch:21 step:20431 [D loss: 0.531391, acc.: 73.44%] [G loss: 0.729387]\n",
      "epoch:21 step:20432 [D loss: 0.544507, acc.: 71.09%] [G loss: 0.678006]\n",
      "epoch:21 step:20433 [D loss: 0.581220, acc.: 64.84%] [G loss: 0.732828]\n",
      "epoch:21 step:20434 [D loss: 0.516268, acc.: 74.22%] [G loss: 0.751057]\n",
      "epoch:21 step:20435 [D loss: 0.542208, acc.: 75.00%] [G loss: 0.515129]\n",
      "epoch:21 step:20436 [D loss: 0.554026, acc.: 71.88%] [G loss: 0.574394]\n",
      "epoch:21 step:20437 [D loss: 0.567495, acc.: 71.09%] [G loss: 0.699128]\n",
      "epoch:21 step:20438 [D loss: 0.572218, acc.: 66.41%] [G loss: 0.639763]\n",
      "epoch:21 step:20439 [D loss: 0.580455, acc.: 67.19%] [G loss: 0.603529]\n",
      "epoch:21 step:20440 [D loss: 0.572152, acc.: 68.75%] [G loss: 0.578997]\n",
      "epoch:21 step:20441 [D loss: 0.532669, acc.: 71.09%] [G loss: 0.551394]\n",
      "epoch:21 step:20442 [D loss: 0.582892, acc.: 67.97%] [G loss: 0.549335]\n",
      "epoch:21 step:20443 [D loss: 0.651460, acc.: 57.81%] [G loss: 0.438335]\n",
      "epoch:21 step:20444 [D loss: 0.496011, acc.: 77.34%] [G loss: 0.697525]\n",
      "epoch:21 step:20445 [D loss: 0.596723, acc.: 68.75%] [G loss: 0.681833]\n",
      "epoch:21 step:20446 [D loss: 0.474114, acc.: 77.34%] [G loss: 0.914104]\n",
      "epoch:21 step:20447 [D loss: 0.507546, acc.: 72.66%] [G loss: 0.899002]\n",
      "epoch:21 step:20448 [D loss: 0.525162, acc.: 74.22%] [G loss: 0.975570]\n",
      "epoch:21 step:20449 [D loss: 0.568002, acc.: 70.31%] [G loss: 0.679299]\n",
      "epoch:21 step:20450 [D loss: 0.543280, acc.: 71.09%] [G loss: 0.676982]\n",
      "epoch:21 step:20451 [D loss: 0.522262, acc.: 74.22%] [G loss: 0.574878]\n",
      "epoch:21 step:20452 [D loss: 0.512403, acc.: 75.00%] [G loss: 0.759933]\n",
      "epoch:21 step:20453 [D loss: 0.575075, acc.: 65.62%] [G loss: 0.678702]\n",
      "epoch:21 step:20454 [D loss: 0.598928, acc.: 67.97%] [G loss: 0.692756]\n",
      "epoch:21 step:20455 [D loss: 0.519616, acc.: 74.22%] [G loss: 0.718921]\n",
      "epoch:21 step:20456 [D loss: 0.547049, acc.: 71.09%] [G loss: 0.610473]\n",
      "epoch:21 step:20457 [D loss: 0.530919, acc.: 72.66%] [G loss: 0.595024]\n",
      "epoch:21 step:20458 [D loss: 0.546761, acc.: 66.41%] [G loss: 0.888417]\n",
      "epoch:21 step:20459 [D loss: 0.484506, acc.: 74.22%] [G loss: 0.892229]\n",
      "epoch:21 step:20460 [D loss: 0.561981, acc.: 68.75%] [G loss: 0.640257]\n",
      "epoch:21 step:20461 [D loss: 0.591026, acc.: 64.84%] [G loss: 0.471455]\n",
      "epoch:21 step:20462 [D loss: 0.502047, acc.: 75.78%] [G loss: 0.553603]\n",
      "epoch:21 step:20463 [D loss: 0.518417, acc.: 73.44%] [G loss: 0.621237]\n",
      "epoch:21 step:20464 [D loss: 0.523209, acc.: 72.66%] [G loss: 0.829725]\n",
      "epoch:21 step:20465 [D loss: 0.631892, acc.: 67.19%] [G loss: 0.580022]\n",
      "epoch:21 step:20466 [D loss: 0.505320, acc.: 71.88%] [G loss: 0.757420]\n",
      "epoch:21 step:20467 [D loss: 0.546427, acc.: 67.97%] [G loss: 0.740494]\n",
      "epoch:21 step:20468 [D loss: 0.543357, acc.: 75.00%] [G loss: 0.699894]\n",
      "epoch:21 step:20469 [D loss: 0.485473, acc.: 75.00%] [G loss: 0.819608]\n",
      "epoch:21 step:20470 [D loss: 0.578567, acc.: 72.66%] [G loss: 0.750093]\n",
      "epoch:21 step:20471 [D loss: 0.655894, acc.: 64.84%] [G loss: 0.517932]\n",
      "epoch:21 step:20472 [D loss: 0.572447, acc.: 65.62%] [G loss: 0.674745]\n",
      "epoch:21 step:20473 [D loss: 0.506156, acc.: 77.34%] [G loss: 0.861187]\n",
      "epoch:21 step:20474 [D loss: 0.540929, acc.: 71.88%] [G loss: 0.816829]\n",
      "epoch:21 step:20475 [D loss: 0.541627, acc.: 69.53%] [G loss: 0.573927]\n",
      "epoch:21 step:20476 [D loss: 0.523019, acc.: 75.78%] [G loss: 0.692159]\n",
      "epoch:21 step:20477 [D loss: 0.589757, acc.: 68.75%] [G loss: 0.532379]\n",
      "epoch:21 step:20478 [D loss: 0.550618, acc.: 70.31%] [G loss: 0.611387]\n",
      "epoch:21 step:20479 [D loss: 0.449663, acc.: 78.12%] [G loss: 0.786477]\n",
      "epoch:21 step:20480 [D loss: 0.526582, acc.: 77.34%] [G loss: 0.708559]\n",
      "epoch:21 step:20481 [D loss: 0.550418, acc.: 71.09%] [G loss: 0.579132]\n",
      "epoch:21 step:20482 [D loss: 0.565613, acc.: 69.53%] [G loss: 0.423977]\n",
      "epoch:21 step:20483 [D loss: 0.537254, acc.: 73.44%] [G loss: 0.476981]\n",
      "epoch:21 step:20484 [D loss: 0.488048, acc.: 79.69%] [G loss: 0.551473]\n",
      "epoch:21 step:20485 [D loss: 0.538512, acc.: 71.09%] [G loss: 0.551193]\n",
      "epoch:21 step:20486 [D loss: 0.478265, acc.: 78.91%] [G loss: 0.683674]\n",
      "epoch:21 step:20487 [D loss: 0.487992, acc.: 74.22%] [G loss: 0.614316]\n",
      "epoch:21 step:20488 [D loss: 0.523615, acc.: 71.88%] [G loss: 0.644644]\n",
      "epoch:21 step:20489 [D loss: 0.585747, acc.: 67.19%] [G loss: 0.498458]\n",
      "epoch:21 step:20490 [D loss: 0.569277, acc.: 67.97%] [G loss: 0.481242]\n",
      "epoch:21 step:20491 [D loss: 0.531028, acc.: 68.75%] [G loss: 0.741238]\n",
      "epoch:21 step:20492 [D loss: 0.511459, acc.: 73.44%] [G loss: 0.816975]\n",
      "epoch:21 step:20493 [D loss: 0.534843, acc.: 72.66%] [G loss: 0.786758]\n",
      "epoch:21 step:20494 [D loss: 0.618106, acc.: 68.75%] [G loss: 0.685611]\n",
      "epoch:21 step:20495 [D loss: 0.567089, acc.: 67.97%] [G loss: 0.495120]\n",
      "epoch:21 step:20496 [D loss: 0.546908, acc.: 71.09%] [G loss: 0.726227]\n",
      "epoch:21 step:20497 [D loss: 0.648792, acc.: 66.41%] [G loss: 0.610214]\n",
      "epoch:21 step:20498 [D loss: 0.562004, acc.: 65.62%] [G loss: 0.573239]\n",
      "epoch:21 step:20499 [D loss: 0.526681, acc.: 72.66%] [G loss: 0.495347]\n",
      "epoch:21 step:20500 [D loss: 0.443679, acc.: 78.91%] [G loss: 0.677971]\n",
      "epoch:21 step:20501 [D loss: 0.548933, acc.: 68.75%] [G loss: 0.776783]\n",
      "epoch:21 step:20502 [D loss: 0.581977, acc.: 68.75%] [G loss: 0.539129]\n",
      "epoch:21 step:20503 [D loss: 0.519973, acc.: 71.88%] [G loss: 0.765281]\n",
      "epoch:21 step:20504 [D loss: 0.504297, acc.: 68.75%] [G loss: 0.651089]\n",
      "epoch:21 step:20505 [D loss: 0.607027, acc.: 64.06%] [G loss: 0.591855]\n",
      "epoch:21 step:20506 [D loss: 0.539650, acc.: 70.31%] [G loss: 0.683021]\n",
      "epoch:21 step:20507 [D loss: 0.550705, acc.: 70.31%] [G loss: 0.680078]\n",
      "epoch:21 step:20508 [D loss: 0.592689, acc.: 63.28%] [G loss: 0.635100]\n",
      "epoch:21 step:20509 [D loss: 0.541207, acc.: 74.22%] [G loss: 0.647817]\n",
      "epoch:21 step:20510 [D loss: 0.560318, acc.: 71.88%] [G loss: 0.722815]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:21 step:20511 [D loss: 0.523011, acc.: 71.09%] [G loss: 0.661331]\n",
      "epoch:21 step:20512 [D loss: 0.532945, acc.: 71.09%] [G loss: 0.676107]\n",
      "epoch:21 step:20513 [D loss: 0.548423, acc.: 67.19%] [G loss: 0.598092]\n",
      "epoch:21 step:20514 [D loss: 0.593332, acc.: 64.06%] [G loss: 0.578164]\n",
      "epoch:21 step:20515 [D loss: 0.529783, acc.: 75.78%] [G loss: 0.647151]\n",
      "epoch:21 step:20516 [D loss: 0.592217, acc.: 62.50%] [G loss: 0.570177]\n",
      "epoch:21 step:20517 [D loss: 0.546454, acc.: 71.88%] [G loss: 0.638999]\n",
      "epoch:21 step:20518 [D loss: 0.576005, acc.: 70.31%] [G loss: 0.516035]\n",
      "epoch:21 step:20519 [D loss: 0.505683, acc.: 67.97%] [G loss: 0.648865]\n",
      "epoch:21 step:20520 [D loss: 0.551480, acc.: 73.44%] [G loss: 0.671892]\n",
      "epoch:21 step:20521 [D loss: 0.538807, acc.: 76.56%] [G loss: 0.565581]\n",
      "epoch:21 step:20522 [D loss: 0.575005, acc.: 68.75%] [G loss: 0.583844]\n",
      "epoch:21 step:20523 [D loss: 0.586229, acc.: 63.28%] [G loss: 0.648838]\n",
      "epoch:21 step:20524 [D loss: 0.671119, acc.: 59.38%] [G loss: 0.465779]\n",
      "epoch:21 step:20525 [D loss: 0.496783, acc.: 72.66%] [G loss: 0.491581]\n",
      "epoch:21 step:20526 [D loss: 0.516041, acc.: 72.66%] [G loss: 0.574943]\n",
      "epoch:21 step:20527 [D loss: 0.577803, acc.: 67.97%] [G loss: 0.512894]\n",
      "epoch:21 step:20528 [D loss: 0.567131, acc.: 67.97%] [G loss: 0.637674]\n",
      "epoch:21 step:20529 [D loss: 0.525492, acc.: 70.31%] [G loss: 0.604529]\n",
      "epoch:21 step:20530 [D loss: 0.580845, acc.: 67.19%] [G loss: 0.533037]\n",
      "epoch:21 step:20531 [D loss: 0.518510, acc.: 72.66%] [G loss: 0.687152]\n",
      "epoch:21 step:20532 [D loss: 0.553202, acc.: 67.19%] [G loss: 0.657284]\n",
      "epoch:21 step:20533 [D loss: 0.574186, acc.: 67.19%] [G loss: 0.556086]\n",
      "epoch:21 step:20534 [D loss: 0.473251, acc.: 80.47%] [G loss: 0.742391]\n",
      "epoch:21 step:20535 [D loss: 0.601468, acc.: 71.09%] [G loss: 0.548519]\n",
      "epoch:21 step:20536 [D loss: 0.580869, acc.: 68.75%] [G loss: 0.751997]\n",
      "epoch:21 step:20537 [D loss: 0.444000, acc.: 83.59%] [G loss: 0.854578]\n",
      "epoch:21 step:20538 [D loss: 0.624685, acc.: 67.97%] [G loss: 0.641306]\n",
      "epoch:21 step:20539 [D loss: 0.533082, acc.: 70.31%] [G loss: 0.458875]\n",
      "epoch:21 step:20540 [D loss: 0.584633, acc.: 67.19%] [G loss: 0.576852]\n",
      "epoch:21 step:20541 [D loss: 0.538700, acc.: 69.53%] [G loss: 0.450165]\n",
      "epoch:21 step:20542 [D loss: 0.588519, acc.: 64.06%] [G loss: 0.552774]\n",
      "epoch:21 step:20543 [D loss: 0.531690, acc.: 67.97%] [G loss: 0.600890]\n",
      "epoch:21 step:20544 [D loss: 0.632514, acc.: 61.72%] [G loss: 0.624980]\n",
      "epoch:21 step:20545 [D loss: 0.553810, acc.: 68.75%] [G loss: 0.544310]\n",
      "epoch:21 step:20546 [D loss: 0.587054, acc.: 67.97%] [G loss: 0.533432]\n",
      "epoch:21 step:20547 [D loss: 0.546804, acc.: 71.09%] [G loss: 0.607613]\n",
      "epoch:21 step:20548 [D loss: 0.476394, acc.: 75.00%] [G loss: 0.803397]\n",
      "epoch:21 step:20549 [D loss: 0.535487, acc.: 73.44%] [G loss: 0.678533]\n",
      "epoch:21 step:20550 [D loss: 0.594948, acc.: 63.28%] [G loss: 0.695211]\n",
      "epoch:21 step:20551 [D loss: 0.597504, acc.: 65.62%] [G loss: 0.612854]\n",
      "epoch:21 step:20552 [D loss: 0.463831, acc.: 78.12%] [G loss: 0.635825]\n",
      "epoch:21 step:20553 [D loss: 0.512929, acc.: 75.00%] [G loss: 0.557338]\n",
      "epoch:21 step:20554 [D loss: 0.582099, acc.: 62.50%] [G loss: 0.636985]\n",
      "epoch:21 step:20555 [D loss: 0.546153, acc.: 68.75%] [G loss: 0.555111]\n",
      "epoch:21 step:20556 [D loss: 0.584862, acc.: 64.06%] [G loss: 0.460669]\n",
      "epoch:21 step:20557 [D loss: 0.662696, acc.: 54.69%] [G loss: 0.516732]\n",
      "epoch:21 step:20558 [D loss: 0.566389, acc.: 67.97%] [G loss: 0.511046]\n",
      "epoch:21 step:20559 [D loss: 0.621176, acc.: 61.72%] [G loss: 0.516876]\n",
      "epoch:21 step:20560 [D loss: 0.569876, acc.: 65.62%] [G loss: 0.519891]\n",
      "epoch:21 step:20561 [D loss: 0.503073, acc.: 74.22%] [G loss: 0.688499]\n",
      "epoch:21 step:20562 [D loss: 0.559969, acc.: 71.09%] [G loss: 0.731326]\n",
      "epoch:21 step:20563 [D loss: 0.490759, acc.: 74.22%] [G loss: 0.874619]\n",
      "epoch:21 step:20564 [D loss: 0.594239, acc.: 71.09%] [G loss: 0.684658]\n",
      "epoch:21 step:20565 [D loss: 0.519482, acc.: 68.75%] [G loss: 0.700329]\n",
      "epoch:21 step:20566 [D loss: 0.575010, acc.: 65.62%] [G loss: 0.661860]\n",
      "epoch:21 step:20567 [D loss: 0.478096, acc.: 76.56%] [G loss: 0.762664]\n",
      "epoch:21 step:20568 [D loss: 0.572632, acc.: 67.19%] [G loss: 0.703974]\n",
      "epoch:21 step:20569 [D loss: 0.595048, acc.: 68.75%] [G loss: 0.489721]\n",
      "epoch:21 step:20570 [D loss: 0.552959, acc.: 69.53%] [G loss: 0.627100]\n",
      "epoch:21 step:20571 [D loss: 0.457412, acc.: 74.22%] [G loss: 0.700080]\n",
      "epoch:21 step:20572 [D loss: 0.532917, acc.: 72.66%] [G loss: 0.703866]\n",
      "epoch:21 step:20573 [D loss: 0.477693, acc.: 78.12%] [G loss: 0.721873]\n",
      "epoch:21 step:20574 [D loss: 0.498891, acc.: 74.22%] [G loss: 0.772442]\n",
      "epoch:21 step:20575 [D loss: 0.492554, acc.: 78.91%] [G loss: 0.826067]\n",
      "epoch:21 step:20576 [D loss: 0.466196, acc.: 78.12%] [G loss: 0.872910]\n",
      "epoch:21 step:20577 [D loss: 0.504548, acc.: 76.56%] [G loss: 0.713292]\n",
      "epoch:21 step:20578 [D loss: 0.574471, acc.: 67.97%] [G loss: 0.711115]\n",
      "epoch:21 step:20579 [D loss: 0.576304, acc.: 64.06%] [G loss: 0.626261]\n",
      "epoch:21 step:20580 [D loss: 0.524686, acc.: 74.22%] [G loss: 0.647167]\n",
      "epoch:21 step:20581 [D loss: 0.527970, acc.: 77.34%] [G loss: 0.583963]\n",
      "epoch:21 step:20582 [D loss: 0.568973, acc.: 70.31%] [G loss: 0.597298]\n",
      "epoch:21 step:20583 [D loss: 0.474593, acc.: 78.12%] [G loss: 0.776461]\n",
      "epoch:21 step:20584 [D loss: 0.593606, acc.: 67.19%] [G loss: 0.687585]\n",
      "epoch:21 step:20585 [D loss: 0.505991, acc.: 75.78%] [G loss: 0.819540]\n",
      "epoch:21 step:20586 [D loss: 0.501839, acc.: 75.00%] [G loss: 0.628978]\n",
      "epoch:21 step:20587 [D loss: 0.602798, acc.: 63.28%] [G loss: 0.676798]\n",
      "epoch:21 step:20588 [D loss: 0.462089, acc.: 78.12%] [G loss: 0.744127]\n",
      "epoch:21 step:20589 [D loss: 0.481018, acc.: 78.12%] [G loss: 0.742305]\n",
      "epoch:21 step:20590 [D loss: 0.539481, acc.: 72.66%] [G loss: 0.922575]\n",
      "epoch:21 step:20591 [D loss: 0.486892, acc.: 72.66%] [G loss: 0.908916]\n",
      "epoch:21 step:20592 [D loss: 0.624910, acc.: 64.06%] [G loss: 0.591842]\n",
      "epoch:21 step:20593 [D loss: 0.486187, acc.: 76.56%] [G loss: 0.668468]\n",
      "epoch:21 step:20594 [D loss: 0.600884, acc.: 65.62%] [G loss: 0.707905]\n",
      "epoch:21 step:20595 [D loss: 0.515772, acc.: 71.88%] [G loss: 0.749561]\n",
      "epoch:21 step:20596 [D loss: 0.480203, acc.: 74.22%] [G loss: 0.966256]\n",
      "epoch:21 step:20597 [D loss: 0.712155, acc.: 61.72%] [G loss: 0.718945]\n",
      "epoch:21 step:20598 [D loss: 0.460314, acc.: 75.78%] [G loss: 0.752592]\n",
      "epoch:21 step:20599 [D loss: 0.597501, acc.: 61.72%] [G loss: 0.685535]\n",
      "epoch:21 step:20600 [D loss: 0.451585, acc.: 75.00%] [G loss: 0.805332]\n",
      "##############\n",
      "[3.05479415 0.95974633 5.89643266 4.82788051 3.81980445 5.62364084\n",
      " 4.68782536 4.87683887 4.77579248 4.39554205]\n",
      "##########\n",
      "epoch:21 step:20601 [D loss: 0.466061, acc.: 75.00%] [G loss: 0.897670]\n",
      "epoch:21 step:20602 [D loss: 0.412392, acc.: 77.34%] [G loss: 1.044089]\n",
      "epoch:21 step:20603 [D loss: 0.390249, acc.: 78.12%] [G loss: 1.091788]\n",
      "epoch:21 step:20604 [D loss: 0.484447, acc.: 75.00%] [G loss: 1.215133]\n",
      "epoch:21 step:20605 [D loss: 0.661581, acc.: 65.62%] [G loss: 1.012587]\n",
      "epoch:21 step:20606 [D loss: 0.520557, acc.: 72.66%] [G loss: 1.442166]\n",
      "epoch:21 step:20607 [D loss: 0.485388, acc.: 74.22%] [G loss: 1.579582]\n",
      "epoch:21 step:20608 [D loss: 0.599655, acc.: 70.31%] [G loss: 1.038909]\n",
      "epoch:21 step:20609 [D loss: 0.622315, acc.: 65.62%] [G loss: 0.897396]\n",
      "epoch:21 step:20610 [D loss: 0.455502, acc.: 77.34%] [G loss: 1.066671]\n",
      "epoch:21 step:20611 [D loss: 0.553890, acc.: 68.75%] [G loss: 0.997888]\n",
      "epoch:21 step:20612 [D loss: 0.454592, acc.: 77.34%] [G loss: 0.891424]\n",
      "epoch:21 step:20613 [D loss: 0.434909, acc.: 79.69%] [G loss: 1.158243]\n",
      "epoch:21 step:20614 [D loss: 0.441630, acc.: 83.59%] [G loss: 1.433430]\n",
      "epoch:22 step:20615 [D loss: 0.593711, acc.: 70.31%] [G loss: 1.113937]\n",
      "epoch:22 step:20616 [D loss: 0.433312, acc.: 78.91%] [G loss: 1.203909]\n",
      "epoch:22 step:20617 [D loss: 0.535899, acc.: 73.44%] [G loss: 0.946824]\n",
      "epoch:22 step:20618 [D loss: 0.513900, acc.: 73.44%] [G loss: 0.958212]\n",
      "epoch:22 step:20619 [D loss: 0.558100, acc.: 70.31%] [G loss: 0.871088]\n",
      "epoch:22 step:20620 [D loss: 0.547611, acc.: 72.66%] [G loss: 0.732350]\n",
      "epoch:22 step:20621 [D loss: 0.491154, acc.: 74.22%] [G loss: 0.814256]\n",
      "epoch:22 step:20622 [D loss: 0.520330, acc.: 71.88%] [G loss: 0.701970]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:22 step:20623 [D loss: 0.493554, acc.: 76.56%] [G loss: 0.918936]\n",
      "epoch:22 step:20624 [D loss: 0.484034, acc.: 76.56%] [G loss: 1.139342]\n",
      "epoch:22 step:20625 [D loss: 0.427962, acc.: 80.47%] [G loss: 0.988496]\n",
      "epoch:22 step:20626 [D loss: 0.622935, acc.: 64.06%] [G loss: 0.594729]\n",
      "epoch:22 step:20627 [D loss: 0.577993, acc.: 63.28%] [G loss: 0.730535]\n",
      "epoch:22 step:20628 [D loss: 0.539551, acc.: 74.22%] [G loss: 0.713000]\n",
      "epoch:22 step:20629 [D loss: 0.457909, acc.: 79.69%] [G loss: 0.804463]\n",
      "epoch:22 step:20630 [D loss: 0.487894, acc.: 77.34%] [G loss: 0.740657]\n",
      "epoch:22 step:20631 [D loss: 0.614976, acc.: 64.84%] [G loss: 0.702004]\n",
      "epoch:22 step:20632 [D loss: 0.643687, acc.: 64.06%] [G loss: 0.702324]\n",
      "epoch:22 step:20633 [D loss: 0.566256, acc.: 65.62%] [G loss: 0.788542]\n",
      "epoch:22 step:20634 [D loss: 0.608812, acc.: 68.75%] [G loss: 0.746532]\n",
      "epoch:22 step:20635 [D loss: 0.564726, acc.: 66.41%] [G loss: 0.586919]\n",
      "epoch:22 step:20636 [D loss: 0.457191, acc.: 73.44%] [G loss: 0.789149]\n",
      "epoch:22 step:20637 [D loss: 0.525271, acc.: 71.09%] [G loss: 0.778008]\n",
      "epoch:22 step:20638 [D loss: 0.477787, acc.: 76.56%] [G loss: 0.616266]\n",
      "epoch:22 step:20639 [D loss: 0.453532, acc.: 76.56%] [G loss: 0.692414]\n",
      "epoch:22 step:20640 [D loss: 0.595467, acc.: 65.62%] [G loss: 0.610615]\n",
      "epoch:22 step:20641 [D loss: 0.479054, acc.: 73.44%] [G loss: 0.801063]\n",
      "epoch:22 step:20642 [D loss: 0.566945, acc.: 68.75%] [G loss: 0.652587]\n",
      "epoch:22 step:20643 [D loss: 0.538747, acc.: 71.09%] [G loss: 0.626637]\n",
      "epoch:22 step:20644 [D loss: 0.565135, acc.: 69.53%] [G loss: 0.622657]\n",
      "epoch:22 step:20645 [D loss: 0.644589, acc.: 63.28%] [G loss: 0.682534]\n",
      "epoch:22 step:20646 [D loss: 0.502110, acc.: 76.56%] [G loss: 0.755662]\n",
      "epoch:22 step:20647 [D loss: 0.523112, acc.: 70.31%] [G loss: 0.664029]\n",
      "epoch:22 step:20648 [D loss: 0.529312, acc.: 73.44%] [G loss: 0.512678]\n",
      "epoch:22 step:20649 [D loss: 0.575982, acc.: 68.75%] [G loss: 0.591393]\n",
      "epoch:22 step:20650 [D loss: 0.526719, acc.: 71.09%] [G loss: 0.703526]\n",
      "epoch:22 step:20651 [D loss: 0.474318, acc.: 72.66%] [G loss: 0.763787]\n",
      "epoch:22 step:20652 [D loss: 0.586910, acc.: 70.31%] [G loss: 0.600010]\n",
      "epoch:22 step:20653 [D loss: 0.533293, acc.: 73.44%] [G loss: 0.615232]\n",
      "epoch:22 step:20654 [D loss: 0.439114, acc.: 82.81%] [G loss: 0.772681]\n",
      "epoch:22 step:20655 [D loss: 0.543029, acc.: 73.44%] [G loss: 0.830773]\n",
      "epoch:22 step:20656 [D loss: 0.520311, acc.: 71.88%] [G loss: 0.738984]\n",
      "epoch:22 step:20657 [D loss: 0.544084, acc.: 70.31%] [G loss: 0.616172]\n",
      "epoch:22 step:20658 [D loss: 0.591269, acc.: 64.84%] [G loss: 0.601048]\n",
      "epoch:22 step:20659 [D loss: 0.492635, acc.: 75.78%] [G loss: 0.725943]\n",
      "epoch:22 step:20660 [D loss: 0.533170, acc.: 71.09%] [G loss: 0.759243]\n",
      "epoch:22 step:20661 [D loss: 0.511285, acc.: 73.44%] [G loss: 0.821638]\n",
      "epoch:22 step:20662 [D loss: 0.566499, acc.: 71.88%] [G loss: 0.644894]\n",
      "epoch:22 step:20663 [D loss: 0.486575, acc.: 75.00%] [G loss: 0.844260]\n",
      "epoch:22 step:20664 [D loss: 0.555468, acc.: 70.31%] [G loss: 0.689437]\n",
      "epoch:22 step:20665 [D loss: 0.628954, acc.: 64.06%] [G loss: 0.549314]\n",
      "epoch:22 step:20666 [D loss: 0.578424, acc.: 65.62%] [G loss: 0.619271]\n",
      "epoch:22 step:20667 [D loss: 0.540784, acc.: 72.66%] [G loss: 0.631462]\n",
      "epoch:22 step:20668 [D loss: 0.452822, acc.: 76.56%] [G loss: 0.910712]\n",
      "epoch:22 step:20669 [D loss: 0.623658, acc.: 60.94%] [G loss: 0.649212]\n",
      "epoch:22 step:20670 [D loss: 0.431499, acc.: 82.81%] [G loss: 0.804650]\n",
      "epoch:22 step:20671 [D loss: 0.508766, acc.: 69.53%] [G loss: 0.661986]\n",
      "epoch:22 step:20672 [D loss: 0.543206, acc.: 71.09%] [G loss: 0.890067]\n",
      "epoch:22 step:20673 [D loss: 0.493301, acc.: 72.66%] [G loss: 0.725586]\n",
      "epoch:22 step:20674 [D loss: 0.595006, acc.: 64.84%] [G loss: 0.832045]\n",
      "epoch:22 step:20675 [D loss: 0.581279, acc.: 70.31%] [G loss: 0.861163]\n",
      "epoch:22 step:20676 [D loss: 0.572738, acc.: 70.31%] [G loss: 0.537135]\n",
      "epoch:22 step:20677 [D loss: 0.570258, acc.: 64.84%] [G loss: 0.552343]\n",
      "epoch:22 step:20678 [D loss: 0.548366, acc.: 73.44%] [G loss: 0.736307]\n",
      "epoch:22 step:20679 [D loss: 0.552523, acc.: 69.53%] [G loss: 0.575181]\n",
      "epoch:22 step:20680 [D loss: 0.613770, acc.: 71.09%] [G loss: 0.550907]\n",
      "epoch:22 step:20681 [D loss: 0.585193, acc.: 66.41%] [G loss: 0.547858]\n",
      "epoch:22 step:20682 [D loss: 0.525362, acc.: 72.66%] [G loss: 0.648818]\n",
      "epoch:22 step:20683 [D loss: 0.454411, acc.: 77.34%] [G loss: 0.819834]\n",
      "epoch:22 step:20684 [D loss: 0.542258, acc.: 74.22%] [G loss: 0.680060]\n",
      "epoch:22 step:20685 [D loss: 0.532071, acc.: 75.00%] [G loss: 0.548250]\n",
      "epoch:22 step:20686 [D loss: 0.525294, acc.: 69.53%] [G loss: 0.803447]\n",
      "epoch:22 step:20687 [D loss: 0.602712, acc.: 64.06%] [G loss: 0.667311]\n",
      "epoch:22 step:20688 [D loss: 0.442002, acc.: 78.91%] [G loss: 0.830636]\n",
      "epoch:22 step:20689 [D loss: 0.543114, acc.: 70.31%] [G loss: 0.807681]\n",
      "epoch:22 step:20690 [D loss: 0.497705, acc.: 77.34%] [G loss: 1.008593]\n",
      "epoch:22 step:20691 [D loss: 0.433725, acc.: 79.69%] [G loss: 0.972245]\n",
      "epoch:22 step:20692 [D loss: 0.611607, acc.: 69.53%] [G loss: 0.638042]\n",
      "epoch:22 step:20693 [D loss: 0.577847, acc.: 67.19%] [G loss: 0.670346]\n",
      "epoch:22 step:20694 [D loss: 0.454870, acc.: 78.12%] [G loss: 0.850697]\n",
      "epoch:22 step:20695 [D loss: 0.554578, acc.: 66.41%] [G loss: 0.657594]\n",
      "epoch:22 step:20696 [D loss: 0.530613, acc.: 74.22%] [G loss: 0.716242]\n",
      "epoch:22 step:20697 [D loss: 0.461628, acc.: 81.25%] [G loss: 0.836086]\n",
      "epoch:22 step:20698 [D loss: 0.509252, acc.: 71.09%] [G loss: 0.883610]\n",
      "epoch:22 step:20699 [D loss: 0.547132, acc.: 68.75%] [G loss: 0.737947]\n",
      "epoch:22 step:20700 [D loss: 0.528115, acc.: 75.00%] [G loss: 0.773690]\n",
      "epoch:22 step:20701 [D loss: 0.544241, acc.: 70.31%] [G loss: 0.640294]\n",
      "epoch:22 step:20702 [D loss: 0.529557, acc.: 71.88%] [G loss: 0.638817]\n",
      "epoch:22 step:20703 [D loss: 0.520264, acc.: 77.34%] [G loss: 0.746641]\n",
      "epoch:22 step:20704 [D loss: 0.495969, acc.: 74.22%] [G loss: 0.783822]\n",
      "epoch:22 step:20705 [D loss: 0.630843, acc.: 59.38%] [G loss: 0.656090]\n",
      "epoch:22 step:20706 [D loss: 0.441561, acc.: 78.12%] [G loss: 0.886460]\n",
      "epoch:22 step:20707 [D loss: 0.476956, acc.: 76.56%] [G loss: 0.853437]\n",
      "epoch:22 step:20708 [D loss: 0.493067, acc.: 78.12%] [G loss: 0.805670]\n",
      "epoch:22 step:20709 [D loss: 0.517696, acc.: 75.00%] [G loss: 0.733275]\n",
      "epoch:22 step:20710 [D loss: 0.501631, acc.: 73.44%] [G loss: 0.712067]\n",
      "epoch:22 step:20711 [D loss: 0.506992, acc.: 71.09%] [G loss: 0.989644]\n",
      "epoch:22 step:20712 [D loss: 0.541353, acc.: 67.97%] [G loss: 0.794912]\n",
      "epoch:22 step:20713 [D loss: 0.542978, acc.: 73.44%] [G loss: 0.635568]\n",
      "epoch:22 step:20714 [D loss: 0.503917, acc.: 75.78%] [G loss: 0.760583]\n",
      "epoch:22 step:20715 [D loss: 0.458903, acc.: 79.69%] [G loss: 1.011655]\n",
      "epoch:22 step:20716 [D loss: 0.617716, acc.: 65.62%] [G loss: 0.700977]\n",
      "epoch:22 step:20717 [D loss: 0.500421, acc.: 71.09%] [G loss: 0.559839]\n",
      "epoch:22 step:20718 [D loss: 0.506887, acc.: 73.44%] [G loss: 0.631107]\n",
      "epoch:22 step:20719 [D loss: 0.611282, acc.: 62.50%] [G loss: 0.728681]\n",
      "epoch:22 step:20720 [D loss: 0.491064, acc.: 76.56%] [G loss: 0.650495]\n",
      "epoch:22 step:20721 [D loss: 0.576574, acc.: 64.06%] [G loss: 0.501302]\n",
      "epoch:22 step:20722 [D loss: 0.628170, acc.: 66.41%] [G loss: 0.560717]\n",
      "epoch:22 step:20723 [D loss: 0.543999, acc.: 71.88%] [G loss: 0.623244]\n",
      "epoch:22 step:20724 [D loss: 0.546254, acc.: 74.22%] [G loss: 0.579434]\n",
      "epoch:22 step:20725 [D loss: 0.510395, acc.: 71.88%] [G loss: 0.613190]\n",
      "epoch:22 step:20726 [D loss: 0.499216, acc.: 75.78%] [G loss: 0.608760]\n",
      "epoch:22 step:20727 [D loss: 0.556984, acc.: 69.53%] [G loss: 0.622571]\n",
      "epoch:22 step:20728 [D loss: 0.532677, acc.: 68.75%] [G loss: 0.498975]\n",
      "epoch:22 step:20729 [D loss: 0.558781, acc.: 72.66%] [G loss: 0.638992]\n",
      "epoch:22 step:20730 [D loss: 0.536232, acc.: 71.09%] [G loss: 0.766335]\n",
      "epoch:22 step:20731 [D loss: 0.505548, acc.: 71.88%] [G loss: 0.706010]\n",
      "epoch:22 step:20732 [D loss: 0.516437, acc.: 70.31%] [G loss: 0.699884]\n",
      "epoch:22 step:20733 [D loss: 0.451243, acc.: 77.34%] [G loss: 0.738721]\n",
      "epoch:22 step:20734 [D loss: 0.503783, acc.: 73.44%] [G loss: 0.777594]\n",
      "epoch:22 step:20735 [D loss: 0.547488, acc.: 66.41%] [G loss: 0.738819]\n",
      "epoch:22 step:20736 [D loss: 0.481515, acc.: 79.69%] [G loss: 0.741488]\n",
      "epoch:22 step:20737 [D loss: 0.521157, acc.: 72.66%] [G loss: 0.917830]\n",
      "epoch:22 step:20738 [D loss: 0.574995, acc.: 71.09%] [G loss: 0.685827]\n",
      "epoch:22 step:20739 [D loss: 0.622190, acc.: 67.97%] [G loss: 0.683192]\n",
      "epoch:22 step:20740 [D loss: 0.518047, acc.: 73.44%] [G loss: 0.542157]\n",
      "epoch:22 step:20741 [D loss: 0.517100, acc.: 71.09%] [G loss: 0.582960]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:22 step:20742 [D loss: 0.515342, acc.: 72.66%] [G loss: 0.574186]\n",
      "epoch:22 step:20743 [D loss: 0.571881, acc.: 64.84%] [G loss: 0.669921]\n",
      "epoch:22 step:20744 [D loss: 0.475014, acc.: 73.44%] [G loss: 0.657264]\n",
      "epoch:22 step:20745 [D loss: 0.473389, acc.: 75.78%] [G loss: 0.865483]\n",
      "epoch:22 step:20746 [D loss: 0.557512, acc.: 67.19%] [G loss: 0.709073]\n",
      "epoch:22 step:20747 [D loss: 0.510509, acc.: 71.88%] [G loss: 0.801656]\n",
      "epoch:22 step:20748 [D loss: 0.527135, acc.: 72.66%] [G loss: 0.767541]\n",
      "epoch:22 step:20749 [D loss: 0.492137, acc.: 79.69%] [G loss: 0.682678]\n",
      "epoch:22 step:20750 [D loss: 0.541582, acc.: 72.66%] [G loss: 0.916776]\n",
      "epoch:22 step:20751 [D loss: 0.599515, acc.: 64.84%] [G loss: 0.602145]\n",
      "epoch:22 step:20752 [D loss: 0.542437, acc.: 75.00%] [G loss: 0.612358]\n",
      "epoch:22 step:20753 [D loss: 0.584604, acc.: 66.41%] [G loss: 0.641826]\n",
      "epoch:22 step:20754 [D loss: 0.551148, acc.: 67.97%] [G loss: 0.589973]\n",
      "epoch:22 step:20755 [D loss: 0.562860, acc.: 69.53%] [G loss: 0.632668]\n",
      "epoch:22 step:20756 [D loss: 0.558724, acc.: 64.84%] [G loss: 0.559523]\n",
      "epoch:22 step:20757 [D loss: 0.562373, acc.: 68.75%] [G loss: 0.611189]\n",
      "epoch:22 step:20758 [D loss: 0.483612, acc.: 71.88%] [G loss: 0.511530]\n",
      "epoch:22 step:20759 [D loss: 0.543094, acc.: 70.31%] [G loss: 0.663528]\n",
      "epoch:22 step:20760 [D loss: 0.513575, acc.: 74.22%] [G loss: 0.719733]\n",
      "epoch:22 step:20761 [D loss: 0.569714, acc.: 69.53%] [G loss: 0.691060]\n",
      "epoch:22 step:20762 [D loss: 0.528957, acc.: 73.44%] [G loss: 0.617782]\n",
      "epoch:22 step:20763 [D loss: 0.536136, acc.: 70.31%] [G loss: 0.645211]\n",
      "epoch:22 step:20764 [D loss: 0.574542, acc.: 69.53%] [G loss: 0.772229]\n",
      "epoch:22 step:20765 [D loss: 0.605326, acc.: 64.06%] [G loss: 0.777889]\n",
      "epoch:22 step:20766 [D loss: 0.483576, acc.: 74.22%] [G loss: 0.793337]\n",
      "epoch:22 step:20767 [D loss: 0.551874, acc.: 73.44%] [G loss: 0.715997]\n",
      "epoch:22 step:20768 [D loss: 0.595909, acc.: 67.97%] [G loss: 0.682469]\n",
      "epoch:22 step:20769 [D loss: 0.469219, acc.: 76.56%] [G loss: 0.746876]\n",
      "epoch:22 step:20770 [D loss: 0.569868, acc.: 65.62%] [G loss: 0.666052]\n",
      "epoch:22 step:20771 [D loss: 0.559840, acc.: 65.62%] [G loss: 0.702787]\n",
      "epoch:22 step:20772 [D loss: 0.517012, acc.: 69.53%] [G loss: 0.591598]\n",
      "epoch:22 step:20773 [D loss: 0.486907, acc.: 78.12%] [G loss: 0.602991]\n",
      "epoch:22 step:20774 [D loss: 0.598505, acc.: 67.97%] [G loss: 0.701917]\n",
      "epoch:22 step:20775 [D loss: 0.473772, acc.: 74.22%] [G loss: 0.693706]\n",
      "epoch:22 step:20776 [D loss: 0.467952, acc.: 73.44%] [G loss: 0.837447]\n",
      "epoch:22 step:20777 [D loss: 0.561017, acc.: 63.28%] [G loss: 0.998406]\n",
      "epoch:22 step:20778 [D loss: 0.581179, acc.: 66.41%] [G loss: 0.752490]\n",
      "epoch:22 step:20779 [D loss: 0.485044, acc.: 74.22%] [G loss: 0.686864]\n",
      "epoch:22 step:20780 [D loss: 0.536136, acc.: 67.97%] [G loss: 0.558717]\n",
      "epoch:22 step:20781 [D loss: 0.528831, acc.: 71.88%] [G loss: 0.503243]\n",
      "epoch:22 step:20782 [D loss: 0.530590, acc.: 72.66%] [G loss: 0.632465]\n",
      "epoch:22 step:20783 [D loss: 0.619446, acc.: 62.50%] [G loss: 0.460767]\n",
      "epoch:22 step:20784 [D loss: 0.551409, acc.: 64.06%] [G loss: 0.539651]\n",
      "epoch:22 step:20785 [D loss: 0.539613, acc.: 74.22%] [G loss: 0.595671]\n",
      "epoch:22 step:20786 [D loss: 0.534567, acc.: 71.88%] [G loss: 0.568958]\n",
      "epoch:22 step:20787 [D loss: 0.460758, acc.: 78.12%] [G loss: 0.771061]\n",
      "epoch:22 step:20788 [D loss: 0.571418, acc.: 63.28%] [G loss: 0.745075]\n",
      "epoch:22 step:20789 [D loss: 0.572417, acc.: 64.06%] [G loss: 0.500697]\n",
      "epoch:22 step:20790 [D loss: 0.540275, acc.: 69.53%] [G loss: 0.516607]\n",
      "epoch:22 step:20791 [D loss: 0.501859, acc.: 72.66%] [G loss: 0.524905]\n",
      "epoch:22 step:20792 [D loss: 0.538049, acc.: 68.75%] [G loss: 0.574615]\n",
      "epoch:22 step:20793 [D loss: 0.591580, acc.: 61.72%] [G loss: 0.488661]\n",
      "epoch:22 step:20794 [D loss: 0.609726, acc.: 62.50%] [G loss: 0.490901]\n",
      "epoch:22 step:20795 [D loss: 0.542784, acc.: 67.97%] [G loss: 0.663771]\n",
      "epoch:22 step:20796 [D loss: 0.588121, acc.: 66.41%] [G loss: 0.644772]\n",
      "epoch:22 step:20797 [D loss: 0.527814, acc.: 74.22%] [G loss: 0.820034]\n",
      "epoch:22 step:20798 [D loss: 0.585383, acc.: 65.62%] [G loss: 0.543107]\n",
      "epoch:22 step:20799 [D loss: 0.587690, acc.: 64.84%] [G loss: 0.673154]\n",
      "epoch:22 step:20800 [D loss: 0.576903, acc.: 64.84%] [G loss: 0.674767]\n",
      "##############\n",
      "[3.01149153 1.24777272 6.36910241 4.79669354 3.86340506 5.47938816\n",
      " 4.37885682 5.00336218 4.48874511 4.36713674]\n",
      "##########\n",
      "epoch:22 step:20801 [D loss: 0.576025, acc.: 67.19%] [G loss: 0.601676]\n",
      "epoch:22 step:20802 [D loss: 0.540600, acc.: 72.66%] [G loss: 0.493763]\n",
      "epoch:22 step:20803 [D loss: 0.564111, acc.: 68.75%] [G loss: 0.506084]\n",
      "epoch:22 step:20804 [D loss: 0.481242, acc.: 77.34%] [G loss: 0.651043]\n",
      "epoch:22 step:20805 [D loss: 0.469001, acc.: 77.34%] [G loss: 0.838877]\n",
      "epoch:22 step:20806 [D loss: 0.569487, acc.: 67.97%] [G loss: 0.777580]\n",
      "epoch:22 step:20807 [D loss: 0.611891, acc.: 67.97%] [G loss: 0.772737]\n",
      "epoch:22 step:20808 [D loss: 0.423481, acc.: 80.47%] [G loss: 0.783260]\n",
      "epoch:22 step:20809 [D loss: 0.624271, acc.: 68.75%] [G loss: 0.740494]\n",
      "epoch:22 step:20810 [D loss: 0.548492, acc.: 67.19%] [G loss: 0.689994]\n",
      "epoch:22 step:20811 [D loss: 0.483509, acc.: 78.91%] [G loss: 0.742585]\n",
      "epoch:22 step:20812 [D loss: 0.469403, acc.: 78.91%] [G loss: 0.747007]\n",
      "epoch:22 step:20813 [D loss: 0.551546, acc.: 68.75%] [G loss: 0.720057]\n",
      "epoch:22 step:20814 [D loss: 0.645871, acc.: 65.62%] [G loss: 0.735160]\n",
      "epoch:22 step:20815 [D loss: 0.554909, acc.: 70.31%] [G loss: 0.595741]\n",
      "epoch:22 step:20816 [D loss: 0.536338, acc.: 70.31%] [G loss: 0.770072]\n",
      "epoch:22 step:20817 [D loss: 0.587130, acc.: 67.97%] [G loss: 0.599068]\n",
      "epoch:22 step:20818 [D loss: 0.512579, acc.: 77.34%] [G loss: 0.589529]\n",
      "epoch:22 step:20819 [D loss: 0.511745, acc.: 72.66%] [G loss: 0.776669]\n",
      "epoch:22 step:20820 [D loss: 0.528401, acc.: 70.31%] [G loss: 0.704135]\n",
      "epoch:22 step:20821 [D loss: 0.479647, acc.: 75.78%] [G loss: 0.561800]\n",
      "epoch:22 step:20822 [D loss: 0.462484, acc.: 79.69%] [G loss: 0.739728]\n",
      "epoch:22 step:20823 [D loss: 0.529995, acc.: 68.75%] [G loss: 0.925640]\n",
      "epoch:22 step:20824 [D loss: 0.602091, acc.: 64.84%] [G loss: 0.724954]\n",
      "epoch:22 step:20825 [D loss: 0.596776, acc.: 67.19%] [G loss: 0.528754]\n",
      "epoch:22 step:20826 [D loss: 0.528827, acc.: 71.09%] [G loss: 0.635975]\n",
      "epoch:22 step:20827 [D loss: 0.540533, acc.: 71.09%] [G loss: 0.563518]\n",
      "epoch:22 step:20828 [D loss: 0.635557, acc.: 58.59%] [G loss: 0.409081]\n",
      "epoch:22 step:20829 [D loss: 0.581461, acc.: 64.06%] [G loss: 0.544666]\n",
      "epoch:22 step:20830 [D loss: 0.554377, acc.: 68.75%] [G loss: 0.676780]\n",
      "epoch:22 step:20831 [D loss: 0.459159, acc.: 77.34%] [G loss: 0.707834]\n",
      "epoch:22 step:20832 [D loss: 0.511586, acc.: 74.22%] [G loss: 0.678190]\n",
      "epoch:22 step:20833 [D loss: 0.481933, acc.: 79.69%] [G loss: 0.840606]\n",
      "epoch:22 step:20834 [D loss: 0.672336, acc.: 63.28%] [G loss: 0.790632]\n",
      "epoch:22 step:20835 [D loss: 0.534826, acc.: 72.66%] [G loss: 0.879198]\n",
      "epoch:22 step:20836 [D loss: 0.469544, acc.: 78.91%] [G loss: 0.733357]\n",
      "epoch:22 step:20837 [D loss: 0.497508, acc.: 75.78%] [G loss: 0.860151]\n",
      "epoch:22 step:20838 [D loss: 0.595893, acc.: 67.97%] [G loss: 0.730701]\n",
      "epoch:22 step:20839 [D loss: 0.544686, acc.: 70.31%] [G loss: 0.696311]\n",
      "epoch:22 step:20840 [D loss: 0.560261, acc.: 64.84%] [G loss: 0.684402]\n",
      "epoch:22 step:20841 [D loss: 0.558917, acc.: 67.97%] [G loss: 0.637684]\n",
      "epoch:22 step:20842 [D loss: 0.578857, acc.: 67.19%] [G loss: 0.527587]\n",
      "epoch:22 step:20843 [D loss: 0.597753, acc.: 70.31%] [G loss: 0.656449]\n",
      "epoch:22 step:20844 [D loss: 0.538500, acc.: 71.88%] [G loss: 0.774116]\n",
      "epoch:22 step:20845 [D loss: 0.466861, acc.: 76.56%] [G loss: 0.885513]\n",
      "epoch:22 step:20846 [D loss: 0.413637, acc.: 79.69%] [G loss: 1.100668]\n",
      "epoch:22 step:20847 [D loss: 0.495194, acc.: 75.00%] [G loss: 0.898403]\n",
      "epoch:22 step:20848 [D loss: 0.577923, acc.: 70.31%] [G loss: 0.703960]\n",
      "epoch:22 step:20849 [D loss: 0.558986, acc.: 70.31%] [G loss: 0.697236]\n",
      "epoch:22 step:20850 [D loss: 0.547277, acc.: 71.88%] [G loss: 0.562313]\n",
      "epoch:22 step:20851 [D loss: 0.556353, acc.: 70.31%] [G loss: 0.686730]\n",
      "epoch:22 step:20852 [D loss: 0.587319, acc.: 71.88%] [G loss: 0.605523]\n",
      "epoch:22 step:20853 [D loss: 0.519610, acc.: 72.66%] [G loss: 0.743557]\n",
      "epoch:22 step:20854 [D loss: 0.573767, acc.: 69.53%] [G loss: 0.631994]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:22 step:20855 [D loss: 0.480023, acc.: 75.78%] [G loss: 0.726469]\n",
      "epoch:22 step:20856 [D loss: 0.542179, acc.: 67.97%] [G loss: 0.638989]\n",
      "epoch:22 step:20857 [D loss: 0.544052, acc.: 71.88%] [G loss: 0.666046]\n",
      "epoch:22 step:20858 [D loss: 0.451191, acc.: 81.25%] [G loss: 0.653203]\n",
      "epoch:22 step:20859 [D loss: 0.507886, acc.: 72.66%] [G loss: 0.652329]\n",
      "epoch:22 step:20860 [D loss: 0.471390, acc.: 78.91%] [G loss: 0.584784]\n",
      "epoch:22 step:20861 [D loss: 0.506034, acc.: 73.44%] [G loss: 0.770841]\n",
      "epoch:22 step:20862 [D loss: 0.465423, acc.: 76.56%] [G loss: 0.785349]\n",
      "epoch:22 step:20863 [D loss: 0.589110, acc.: 69.53%] [G loss: 0.719763]\n",
      "epoch:22 step:20864 [D loss: 0.650558, acc.: 61.72%] [G loss: 0.842136]\n",
      "epoch:22 step:20865 [D loss: 0.589663, acc.: 66.41%] [G loss: 0.684624]\n",
      "epoch:22 step:20866 [D loss: 0.555923, acc.: 71.88%] [G loss: 0.771097]\n",
      "epoch:22 step:20867 [D loss: 0.631784, acc.: 65.62%] [G loss: 0.734281]\n",
      "epoch:22 step:20868 [D loss: 0.521380, acc.: 74.22%] [G loss: 0.721515]\n",
      "epoch:22 step:20869 [D loss: 0.531288, acc.: 72.66%] [G loss: 0.697598]\n",
      "epoch:22 step:20870 [D loss: 0.518636, acc.: 75.00%] [G loss: 0.793517]\n",
      "epoch:22 step:20871 [D loss: 0.564035, acc.: 66.41%] [G loss: 0.701063]\n",
      "epoch:22 step:20872 [D loss: 0.473296, acc.: 77.34%] [G loss: 0.709023]\n",
      "epoch:22 step:20873 [D loss: 0.520504, acc.: 71.88%] [G loss: 0.827071]\n",
      "epoch:22 step:20874 [D loss: 0.553302, acc.: 70.31%] [G loss: 0.692302]\n",
      "epoch:22 step:20875 [D loss: 0.592841, acc.: 67.97%] [G loss: 0.727849]\n",
      "epoch:22 step:20876 [D loss: 0.509434, acc.: 74.22%] [G loss: 0.767203]\n",
      "epoch:22 step:20877 [D loss: 0.620348, acc.: 64.84%] [G loss: 0.711322]\n",
      "epoch:22 step:20878 [D loss: 0.512679, acc.: 75.78%] [G loss: 0.621993]\n",
      "epoch:22 step:20879 [D loss: 0.586271, acc.: 68.75%] [G loss: 0.567217]\n",
      "epoch:22 step:20880 [D loss: 0.580602, acc.: 66.41%] [G loss: 0.664587]\n",
      "epoch:22 step:20881 [D loss: 0.550261, acc.: 65.62%] [G loss: 0.636832]\n",
      "epoch:22 step:20882 [D loss: 0.519411, acc.: 73.44%] [G loss: 0.556478]\n",
      "epoch:22 step:20883 [D loss: 0.479772, acc.: 77.34%] [G loss: 0.559108]\n",
      "epoch:22 step:20884 [D loss: 0.505545, acc.: 75.78%] [G loss: 0.774385]\n",
      "epoch:22 step:20885 [D loss: 0.501808, acc.: 77.34%] [G loss: 0.701626]\n",
      "epoch:22 step:20886 [D loss: 0.538302, acc.: 74.22%] [G loss: 0.732167]\n",
      "epoch:22 step:20887 [D loss: 0.527786, acc.: 74.22%] [G loss: 0.624977]\n",
      "epoch:22 step:20888 [D loss: 0.495726, acc.: 75.78%] [G loss: 0.707834]\n",
      "epoch:22 step:20889 [D loss: 0.566613, acc.: 70.31%] [G loss: 0.597466]\n",
      "epoch:22 step:20890 [D loss: 0.497586, acc.: 72.66%] [G loss: 0.724666]\n",
      "epoch:22 step:20891 [D loss: 0.641634, acc.: 65.62%] [G loss: 0.658817]\n",
      "epoch:22 step:20892 [D loss: 0.640256, acc.: 64.84%] [G loss: 0.460195]\n",
      "epoch:22 step:20893 [D loss: 0.557542, acc.: 71.88%] [G loss: 0.690676]\n",
      "epoch:22 step:20894 [D loss: 0.483603, acc.: 75.78%] [G loss: 0.656529]\n",
      "epoch:22 step:20895 [D loss: 0.567591, acc.: 71.88%] [G loss: 0.636993]\n",
      "epoch:22 step:20896 [D loss: 0.565118, acc.: 65.62%] [G loss: 0.516497]\n",
      "epoch:22 step:20897 [D loss: 0.505351, acc.: 75.78%] [G loss: 0.619085]\n",
      "epoch:22 step:20898 [D loss: 0.515250, acc.: 71.88%] [G loss: 0.675905]\n",
      "epoch:22 step:20899 [D loss: 0.564169, acc.: 65.62%] [G loss: 0.616493]\n",
      "epoch:22 step:20900 [D loss: 0.517434, acc.: 75.00%] [G loss: 0.817962]\n",
      "epoch:22 step:20901 [D loss: 0.568804, acc.: 73.44%] [G loss: 0.730141]\n",
      "epoch:22 step:20902 [D loss: 0.615364, acc.: 64.06%] [G loss: 0.519789]\n",
      "epoch:22 step:20903 [D loss: 0.537546, acc.: 69.53%] [G loss: 0.756810]\n",
      "epoch:22 step:20904 [D loss: 0.573096, acc.: 68.75%] [G loss: 0.625747]\n",
      "epoch:22 step:20905 [D loss: 0.557396, acc.: 68.75%] [G loss: 0.667071]\n",
      "epoch:22 step:20906 [D loss: 0.488789, acc.: 78.91%] [G loss: 0.688001]\n",
      "epoch:22 step:20907 [D loss: 0.595512, acc.: 67.19%] [G loss: 0.548195]\n",
      "epoch:22 step:20908 [D loss: 0.607025, acc.: 62.50%] [G loss: 0.566595]\n",
      "epoch:22 step:20909 [D loss: 0.545116, acc.: 68.75%] [G loss: 0.575238]\n",
      "epoch:22 step:20910 [D loss: 0.497700, acc.: 72.66%] [G loss: 0.550126]\n",
      "epoch:22 step:20911 [D loss: 0.595224, acc.: 67.97%] [G loss: 0.471090]\n",
      "epoch:22 step:20912 [D loss: 0.443260, acc.: 76.56%] [G loss: 0.849532]\n",
      "epoch:22 step:20913 [D loss: 0.459379, acc.: 77.34%] [G loss: 0.733524]\n",
      "epoch:22 step:20914 [D loss: 0.519330, acc.: 73.44%] [G loss: 0.690474]\n",
      "epoch:22 step:20915 [D loss: 0.582804, acc.: 64.84%] [G loss: 0.731139]\n",
      "epoch:22 step:20916 [D loss: 0.514187, acc.: 77.34%] [G loss: 0.591873]\n",
      "epoch:22 step:20917 [D loss: 0.501532, acc.: 77.34%] [G loss: 0.634354]\n",
      "epoch:22 step:20918 [D loss: 0.489454, acc.: 82.03%] [G loss: 0.665911]\n",
      "epoch:22 step:20919 [D loss: 0.515666, acc.: 71.88%] [G loss: 0.704117]\n",
      "epoch:22 step:20920 [D loss: 0.496174, acc.: 77.34%] [G loss: 0.756286]\n",
      "epoch:22 step:20921 [D loss: 0.485972, acc.: 72.66%] [G loss: 0.845856]\n",
      "epoch:22 step:20922 [D loss: 0.558834, acc.: 69.53%] [G loss: 0.647997]\n",
      "epoch:22 step:20923 [D loss: 0.539888, acc.: 67.19%] [G loss: 0.702504]\n",
      "epoch:22 step:20924 [D loss: 0.548881, acc.: 70.31%] [G loss: 0.710917]\n",
      "epoch:22 step:20925 [D loss: 0.483934, acc.: 77.34%] [G loss: 0.891317]\n",
      "epoch:22 step:20926 [D loss: 0.447615, acc.: 80.47%] [G loss: 0.935378]\n",
      "epoch:22 step:20927 [D loss: 0.498260, acc.: 74.22%] [G loss: 0.954775]\n",
      "epoch:22 step:20928 [D loss: 0.413344, acc.: 81.25%] [G loss: 1.089640]\n",
      "epoch:22 step:20929 [D loss: 0.481440, acc.: 77.34%] [G loss: 1.004664]\n",
      "epoch:22 step:20930 [D loss: 0.704767, acc.: 59.38%] [G loss: 0.734471]\n",
      "epoch:22 step:20931 [D loss: 0.576329, acc.: 68.75%] [G loss: 0.534482]\n",
      "epoch:22 step:20932 [D loss: 0.546769, acc.: 71.09%] [G loss: 0.556209]\n",
      "epoch:22 step:20933 [D loss: 0.524824, acc.: 70.31%] [G loss: 0.640628]\n",
      "epoch:22 step:20934 [D loss: 0.601656, acc.: 58.59%] [G loss: 0.570317]\n",
      "epoch:22 step:20935 [D loss: 0.492851, acc.: 75.78%] [G loss: 0.653007]\n",
      "epoch:22 step:20936 [D loss: 0.543377, acc.: 71.88%] [G loss: 0.661030]\n",
      "epoch:22 step:20937 [D loss: 0.584217, acc.: 66.41%] [G loss: 0.535123]\n",
      "epoch:22 step:20938 [D loss: 0.592987, acc.: 65.62%] [G loss: 0.521504]\n",
      "epoch:22 step:20939 [D loss: 0.548871, acc.: 71.09%] [G loss: 0.608268]\n",
      "epoch:22 step:20940 [D loss: 0.446487, acc.: 80.47%] [G loss: 0.763377]\n",
      "epoch:22 step:20941 [D loss: 0.533098, acc.: 71.09%] [G loss: 0.801715]\n",
      "epoch:22 step:20942 [D loss: 0.442889, acc.: 82.03%] [G loss: 0.855322]\n",
      "epoch:22 step:20943 [D loss: 0.548355, acc.: 75.00%] [G loss: 0.739993]\n",
      "epoch:22 step:20944 [D loss: 0.596318, acc.: 64.84%] [G loss: 0.653170]\n",
      "epoch:22 step:20945 [D loss: 0.552646, acc.: 68.75%] [G loss: 0.518316]\n",
      "epoch:22 step:20946 [D loss: 0.522601, acc.: 70.31%] [G loss: 0.609895]\n",
      "epoch:22 step:20947 [D loss: 0.491875, acc.: 76.56%] [G loss: 0.697129]\n",
      "epoch:22 step:20948 [D loss: 0.493804, acc.: 74.22%] [G loss: 0.760537]\n",
      "epoch:22 step:20949 [D loss: 0.547167, acc.: 71.88%] [G loss: 0.720074]\n",
      "epoch:22 step:20950 [D loss: 0.509043, acc.: 70.31%] [G loss: 0.775337]\n",
      "epoch:22 step:20951 [D loss: 0.488924, acc.: 71.88%] [G loss: 0.720337]\n",
      "epoch:22 step:20952 [D loss: 0.512961, acc.: 72.66%] [G loss: 0.816691]\n",
      "epoch:22 step:20953 [D loss: 0.562074, acc.: 69.53%] [G loss: 0.656489]\n",
      "epoch:22 step:20954 [D loss: 0.456884, acc.: 78.12%] [G loss: 0.803228]\n",
      "epoch:22 step:20955 [D loss: 0.562476, acc.: 69.53%] [G loss: 0.751362]\n",
      "epoch:22 step:20956 [D loss: 0.657670, acc.: 64.06%] [G loss: 0.538842]\n",
      "epoch:22 step:20957 [D loss: 0.450820, acc.: 82.03%] [G loss: 0.824187]\n",
      "epoch:22 step:20958 [D loss: 0.425485, acc.: 81.25%] [G loss: 0.756315]\n",
      "epoch:22 step:20959 [D loss: 0.520843, acc.: 69.53%] [G loss: 0.882815]\n",
      "epoch:22 step:20960 [D loss: 0.500619, acc.: 68.75%] [G loss: 0.978602]\n",
      "epoch:22 step:20961 [D loss: 0.483916, acc.: 74.22%] [G loss: 0.869413]\n",
      "epoch:22 step:20962 [D loss: 0.640579, acc.: 65.62%] [G loss: 0.779330]\n",
      "epoch:22 step:20963 [D loss: 0.719617, acc.: 55.47%] [G loss: 0.569116]\n",
      "epoch:22 step:20964 [D loss: 0.474489, acc.: 77.34%] [G loss: 0.570300]\n",
      "epoch:22 step:20965 [D loss: 0.574964, acc.: 71.09%] [G loss: 0.547560]\n",
      "epoch:22 step:20966 [D loss: 0.529315, acc.: 72.66%] [G loss: 0.797380]\n",
      "epoch:22 step:20967 [D loss: 0.558599, acc.: 71.09%] [G loss: 0.704404]\n",
      "epoch:22 step:20968 [D loss: 0.391304, acc.: 82.81%] [G loss: 0.795634]\n",
      "epoch:22 step:20969 [D loss: 0.503559, acc.: 74.22%] [G loss: 0.774349]\n",
      "epoch:22 step:20970 [D loss: 0.565854, acc.: 68.75%] [G loss: 0.772423]\n",
      "epoch:22 step:20971 [D loss: 0.411997, acc.: 80.47%] [G loss: 0.741679]\n",
      "epoch:22 step:20972 [D loss: 0.438129, acc.: 81.25%] [G loss: 0.795083]\n",
      "epoch:22 step:20973 [D loss: 0.462866, acc.: 80.47%] [G loss: 0.895480]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:22 step:20974 [D loss: 0.496369, acc.: 71.88%] [G loss: 0.889329]\n",
      "epoch:22 step:20975 [D loss: 0.468002, acc.: 77.34%] [G loss: 0.877418]\n",
      "epoch:22 step:20976 [D loss: 0.500761, acc.: 78.12%] [G loss: 0.778422]\n",
      "epoch:22 step:20977 [D loss: 0.552824, acc.: 72.66%] [G loss: 0.655925]\n",
      "epoch:22 step:20978 [D loss: 0.535510, acc.: 71.09%] [G loss: 0.732932]\n",
      "epoch:22 step:20979 [D loss: 0.566839, acc.: 66.41%] [G loss: 0.703525]\n",
      "epoch:22 step:20980 [D loss: 0.567070, acc.: 61.72%] [G loss: 0.572512]\n",
      "epoch:22 step:20981 [D loss: 0.554347, acc.: 71.09%] [G loss: 0.828097]\n",
      "epoch:22 step:20982 [D loss: 0.572550, acc.: 61.72%] [G loss: 0.870374]\n",
      "epoch:22 step:20983 [D loss: 0.502458, acc.: 75.78%] [G loss: 0.833162]\n",
      "epoch:22 step:20984 [D loss: 0.546400, acc.: 71.88%] [G loss: 0.796891]\n",
      "epoch:22 step:20985 [D loss: 0.458865, acc.: 75.78%] [G loss: 0.800865]\n",
      "epoch:22 step:20986 [D loss: 0.551006, acc.: 70.31%] [G loss: 0.693050]\n",
      "epoch:22 step:20987 [D loss: 0.548637, acc.: 71.88%] [G loss: 0.606082]\n",
      "epoch:22 step:20988 [D loss: 0.485570, acc.: 73.44%] [G loss: 0.752862]\n",
      "epoch:22 step:20989 [D loss: 0.596375, acc.: 67.97%] [G loss: 0.702112]\n",
      "epoch:22 step:20990 [D loss: 0.669200, acc.: 58.59%] [G loss: 0.538608]\n",
      "epoch:22 step:20991 [D loss: 0.576886, acc.: 66.41%] [G loss: 0.570798]\n",
      "epoch:22 step:20992 [D loss: 0.592452, acc.: 64.06%] [G loss: 0.471547]\n",
      "epoch:22 step:20993 [D loss: 0.598895, acc.: 67.97%] [G loss: 0.544784]\n",
      "epoch:22 step:20994 [D loss: 0.578695, acc.: 67.97%] [G loss: 0.644898]\n",
      "epoch:22 step:20995 [D loss: 0.467872, acc.: 79.69%] [G loss: 0.763783]\n",
      "epoch:22 step:20996 [D loss: 0.524312, acc.: 73.44%] [G loss: 0.739611]\n",
      "epoch:22 step:20997 [D loss: 0.552380, acc.: 67.97%] [G loss: 0.631718]\n",
      "epoch:22 step:20998 [D loss: 0.559189, acc.: 69.53%] [G loss: 0.620349]\n",
      "epoch:22 step:20999 [D loss: 0.510558, acc.: 74.22%] [G loss: 0.655747]\n",
      "epoch:22 step:21000 [D loss: 0.614397, acc.: 60.16%] [G loss: 0.575268]\n",
      "##############\n",
      "[2.61443573 1.33345931 6.19129628 4.6916283  3.39635158 5.4673075\n",
      " 4.63128204 4.84749631 4.42618569 4.16433132]\n",
      "##########\n",
      "epoch:22 step:21001 [D loss: 0.529921, acc.: 71.09%] [G loss: 0.675433]\n",
      "epoch:22 step:21002 [D loss: 0.532550, acc.: 71.88%] [G loss: 0.581689]\n",
      "epoch:22 step:21003 [D loss: 0.552985, acc.: 70.31%] [G loss: 0.793847]\n",
      "epoch:22 step:21004 [D loss: 0.566942, acc.: 67.97%] [G loss: 0.485104]\n",
      "epoch:22 step:21005 [D loss: 0.549148, acc.: 68.75%] [G loss: 0.543871]\n",
      "epoch:22 step:21006 [D loss: 0.499775, acc.: 75.00%] [G loss: 0.537002]\n",
      "epoch:22 step:21007 [D loss: 0.591201, acc.: 65.62%] [G loss: 0.503909]\n",
      "epoch:22 step:21008 [D loss: 0.561689, acc.: 70.31%] [G loss: 0.554434]\n",
      "epoch:22 step:21009 [D loss: 0.558556, acc.: 74.22%] [G loss: 0.584094]\n",
      "epoch:22 step:21010 [D loss: 0.602034, acc.: 64.84%] [G loss: 0.620476]\n",
      "epoch:22 step:21011 [D loss: 0.564750, acc.: 67.97%] [G loss: 0.797589]\n",
      "epoch:22 step:21012 [D loss: 0.475618, acc.: 75.00%] [G loss: 0.724575]\n",
      "epoch:22 step:21013 [D loss: 0.546167, acc.: 68.75%] [G loss: 0.699939]\n",
      "epoch:22 step:21014 [D loss: 0.638902, acc.: 57.03%] [G loss: 0.581517]\n",
      "epoch:22 step:21015 [D loss: 0.602344, acc.: 65.62%] [G loss: 0.593176]\n",
      "epoch:22 step:21016 [D loss: 0.500224, acc.: 72.66%] [G loss: 0.915647]\n",
      "epoch:22 step:21017 [D loss: 0.469872, acc.: 73.44%] [G loss: 0.828723]\n",
      "epoch:22 step:21018 [D loss: 0.568894, acc.: 68.75%] [G loss: 0.664339]\n",
      "epoch:22 step:21019 [D loss: 0.496436, acc.: 75.78%] [G loss: 0.702849]\n",
      "epoch:22 step:21020 [D loss: 0.474328, acc.: 75.78%] [G loss: 0.720986]\n",
      "epoch:22 step:21021 [D loss: 0.547366, acc.: 71.88%] [G loss: 0.751014]\n",
      "epoch:22 step:21022 [D loss: 0.566046, acc.: 66.41%] [G loss: 0.802586]\n",
      "epoch:22 step:21023 [D loss: 0.588172, acc.: 66.41%] [G loss: 0.762129]\n",
      "epoch:22 step:21024 [D loss: 0.528978, acc.: 75.00%] [G loss: 0.681122]\n",
      "epoch:22 step:21025 [D loss: 0.615090, acc.: 61.72%] [G loss: 0.526345]\n",
      "epoch:22 step:21026 [D loss: 0.602035, acc.: 66.41%] [G loss: 0.559891]\n",
      "epoch:22 step:21027 [D loss: 0.562172, acc.: 70.31%] [G loss: 0.664522]\n",
      "epoch:22 step:21028 [D loss: 0.492550, acc.: 75.00%] [G loss: 0.740268]\n",
      "epoch:22 step:21029 [D loss: 0.527601, acc.: 71.88%] [G loss: 0.748060]\n",
      "epoch:22 step:21030 [D loss: 0.499676, acc.: 76.56%] [G loss: 0.950488]\n",
      "epoch:22 step:21031 [D loss: 0.619879, acc.: 67.97%] [G loss: 0.872683]\n",
      "epoch:22 step:21032 [D loss: 0.596338, acc.: 69.53%] [G loss: 0.654514]\n",
      "epoch:22 step:21033 [D loss: 0.514503, acc.: 73.44%] [G loss: 0.732251]\n",
      "epoch:22 step:21034 [D loss: 0.546020, acc.: 66.41%] [G loss: 0.642971]\n",
      "epoch:22 step:21035 [D loss: 0.561903, acc.: 69.53%] [G loss: 0.583473]\n",
      "epoch:22 step:21036 [D loss: 0.651298, acc.: 61.72%] [G loss: 0.586065]\n",
      "epoch:22 step:21037 [D loss: 0.524169, acc.: 68.75%] [G loss: 0.641218]\n",
      "epoch:22 step:21038 [D loss: 0.556980, acc.: 67.19%] [G loss: 0.719544]\n",
      "epoch:22 step:21039 [D loss: 0.568472, acc.: 68.75%] [G loss: 0.625448]\n",
      "epoch:22 step:21040 [D loss: 0.481107, acc.: 71.88%] [G loss: 0.696798]\n",
      "epoch:22 step:21041 [D loss: 0.426052, acc.: 83.59%] [G loss: 0.872781]\n",
      "epoch:22 step:21042 [D loss: 0.518723, acc.: 71.09%] [G loss: 0.741940]\n",
      "epoch:22 step:21043 [D loss: 0.480534, acc.: 76.56%] [G loss: 0.774085]\n",
      "epoch:22 step:21044 [D loss: 0.569826, acc.: 72.66%] [G loss: 0.835272]\n",
      "epoch:22 step:21045 [D loss: 0.547607, acc.: 68.75%] [G loss: 0.841848]\n",
      "epoch:22 step:21046 [D loss: 0.578913, acc.: 66.41%] [G loss: 0.585450]\n",
      "epoch:22 step:21047 [D loss: 0.596325, acc.: 68.75%] [G loss: 0.566574]\n",
      "epoch:22 step:21048 [D loss: 0.562512, acc.: 70.31%] [G loss: 0.914414]\n",
      "epoch:22 step:21049 [D loss: 0.557090, acc.: 68.75%] [G loss: 0.715871]\n",
      "epoch:22 step:21050 [D loss: 0.479731, acc.: 73.44%] [G loss: 0.787285]\n",
      "epoch:22 step:21051 [D loss: 0.672597, acc.: 65.62%] [G loss: 0.781821]\n",
      "epoch:22 step:21052 [D loss: 0.558908, acc.: 64.84%] [G loss: 0.604049]\n",
      "epoch:22 step:21053 [D loss: 0.519269, acc.: 75.78%] [G loss: 0.752015]\n",
      "epoch:22 step:21054 [D loss: 0.470895, acc.: 77.34%] [G loss: 0.821675]\n",
      "epoch:22 step:21055 [D loss: 0.479248, acc.: 75.00%] [G loss: 0.762711]\n",
      "epoch:22 step:21056 [D loss: 0.574691, acc.: 68.75%] [G loss: 0.687207]\n",
      "epoch:22 step:21057 [D loss: 0.509918, acc.: 77.34%] [G loss: 0.737528]\n",
      "epoch:22 step:21058 [D loss: 0.529423, acc.: 73.44%] [G loss: 0.942130]\n",
      "epoch:22 step:21059 [D loss: 0.542794, acc.: 68.75%] [G loss: 0.865217]\n",
      "epoch:22 step:21060 [D loss: 0.523980, acc.: 69.53%] [G loss: 1.032581]\n",
      "epoch:22 step:21061 [D loss: 0.608011, acc.: 63.28%] [G loss: 0.785163]\n",
      "epoch:22 step:21062 [D loss: 0.502645, acc.: 73.44%] [G loss: 0.990948]\n",
      "epoch:22 step:21063 [D loss: 0.517924, acc.: 72.66%] [G loss: 0.847536]\n",
      "epoch:22 step:21064 [D loss: 0.537111, acc.: 75.78%] [G loss: 0.797619]\n",
      "epoch:22 step:21065 [D loss: 0.451667, acc.: 75.00%] [G loss: 0.881276]\n",
      "epoch:22 step:21066 [D loss: 0.461219, acc.: 76.56%] [G loss: 1.008251]\n",
      "epoch:22 step:21067 [D loss: 0.557960, acc.: 69.53%] [G loss: 0.719683]\n",
      "epoch:22 step:21068 [D loss: 0.603682, acc.: 64.06%] [G loss: 0.694190]\n",
      "epoch:22 step:21069 [D loss: 0.599117, acc.: 67.97%] [G loss: 0.709585]\n",
      "epoch:22 step:21070 [D loss: 0.653447, acc.: 61.72%] [G loss: 0.634841]\n",
      "epoch:22 step:21071 [D loss: 0.456909, acc.: 82.03%] [G loss: 0.787207]\n",
      "epoch:22 step:21072 [D loss: 0.638258, acc.: 65.62%] [G loss: 0.614130]\n",
      "epoch:22 step:21073 [D loss: 0.507810, acc.: 75.00%] [G loss: 0.611197]\n",
      "epoch:22 step:21074 [D loss: 0.483762, acc.: 76.56%] [G loss: 0.528862]\n",
      "epoch:22 step:21075 [D loss: 0.478841, acc.: 76.56%] [G loss: 0.757903]\n",
      "epoch:22 step:21076 [D loss: 0.567964, acc.: 63.28%] [G loss: 0.767705]\n",
      "epoch:22 step:21077 [D loss: 0.566833, acc.: 65.62%] [G loss: 0.682982]\n",
      "epoch:22 step:21078 [D loss: 0.518702, acc.: 75.00%] [G loss: 0.845887]\n",
      "epoch:22 step:21079 [D loss: 0.638646, acc.: 63.28%] [G loss: 0.665697]\n",
      "epoch:22 step:21080 [D loss: 0.563872, acc.: 66.41%] [G loss: 0.746190]\n",
      "epoch:22 step:21081 [D loss: 0.578699, acc.: 66.41%] [G loss: 0.649125]\n",
      "epoch:22 step:21082 [D loss: 0.533886, acc.: 69.53%] [G loss: 0.874357]\n",
      "epoch:22 step:21083 [D loss: 0.563915, acc.: 67.97%] [G loss: 0.797127]\n",
      "epoch:22 step:21084 [D loss: 0.519393, acc.: 78.12%] [G loss: 0.717027]\n",
      "epoch:22 step:21085 [D loss: 0.448107, acc.: 77.34%] [G loss: 0.895189]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:22 step:21086 [D loss: 0.440596, acc.: 82.81%] [G loss: 1.059970]\n",
      "epoch:22 step:21087 [D loss: 0.659755, acc.: 60.16%] [G loss: 0.739811]\n",
      "epoch:22 step:21088 [D loss: 0.567636, acc.: 65.62%] [G loss: 0.871417]\n",
      "epoch:22 step:21089 [D loss: 0.475834, acc.: 75.00%] [G loss: 0.996206]\n",
      "epoch:22 step:21090 [D loss: 0.534326, acc.: 72.66%] [G loss: 0.741505]\n",
      "epoch:22 step:21091 [D loss: 0.656859, acc.: 64.84%] [G loss: 0.517881]\n",
      "epoch:22 step:21092 [D loss: 0.575918, acc.: 67.97%] [G loss: 0.543646]\n",
      "epoch:22 step:21093 [D loss: 0.521313, acc.: 75.00%] [G loss: 0.617985]\n",
      "epoch:22 step:21094 [D loss: 0.565717, acc.: 71.09%] [G loss: 0.566116]\n",
      "epoch:22 step:21095 [D loss: 0.493293, acc.: 75.00%] [G loss: 0.635784]\n",
      "epoch:22 step:21096 [D loss: 0.611768, acc.: 67.19%] [G loss: 0.575202]\n",
      "epoch:22 step:21097 [D loss: 0.517424, acc.: 70.31%] [G loss: 0.584376]\n",
      "epoch:22 step:21098 [D loss: 0.492415, acc.: 73.44%] [G loss: 0.634287]\n",
      "epoch:22 step:21099 [D loss: 0.495158, acc.: 77.34%] [G loss: 0.680131]\n",
      "epoch:22 step:21100 [D loss: 0.591995, acc.: 66.41%] [G loss: 0.910105]\n",
      "epoch:22 step:21101 [D loss: 0.547189, acc.: 66.41%] [G loss: 0.756765]\n",
      "epoch:22 step:21102 [D loss: 0.511861, acc.: 68.75%] [G loss: 0.782942]\n",
      "epoch:22 step:21103 [D loss: 0.542557, acc.: 71.88%] [G loss: 0.743775]\n",
      "epoch:22 step:21104 [D loss: 0.568800, acc.: 65.62%] [G loss: 0.570951]\n",
      "epoch:22 step:21105 [D loss: 0.564382, acc.: 73.44%] [G loss: 0.592646]\n",
      "epoch:22 step:21106 [D loss: 0.592568, acc.: 67.97%] [G loss: 0.514921]\n",
      "epoch:22 step:21107 [D loss: 0.542321, acc.: 71.09%] [G loss: 0.591453]\n",
      "epoch:22 step:21108 [D loss: 0.613706, acc.: 64.84%] [G loss: 0.667387]\n",
      "epoch:22 step:21109 [D loss: 0.513371, acc.: 74.22%] [G loss: 0.668738]\n",
      "epoch:22 step:21110 [D loss: 0.524752, acc.: 73.44%] [G loss: 0.784130]\n",
      "epoch:22 step:21111 [D loss: 0.562282, acc.: 76.56%] [G loss: 0.700102]\n",
      "epoch:22 step:21112 [D loss: 0.541845, acc.: 67.97%] [G loss: 0.693008]\n",
      "epoch:22 step:21113 [D loss: 0.532799, acc.: 70.31%] [G loss: 0.722816]\n",
      "epoch:22 step:21114 [D loss: 0.559382, acc.: 67.97%] [G loss: 0.773646]\n",
      "epoch:22 step:21115 [D loss: 0.576867, acc.: 72.66%] [G loss: 0.607635]\n",
      "epoch:22 step:21116 [D loss: 0.589069, acc.: 65.62%] [G loss: 0.549657]\n",
      "epoch:22 step:21117 [D loss: 0.520208, acc.: 74.22%] [G loss: 0.663049]\n",
      "epoch:22 step:21118 [D loss: 0.472440, acc.: 75.78%] [G loss: 0.824620]\n",
      "epoch:22 step:21119 [D loss: 0.492440, acc.: 75.78%] [G loss: 0.684534]\n",
      "epoch:22 step:21120 [D loss: 0.497969, acc.: 75.00%] [G loss: 0.676533]\n",
      "epoch:22 step:21121 [D loss: 0.575051, acc.: 70.31%] [G loss: 0.687356]\n",
      "epoch:22 step:21122 [D loss: 0.425142, acc.: 81.25%] [G loss: 0.870180]\n",
      "epoch:22 step:21123 [D loss: 0.502765, acc.: 74.22%] [G loss: 1.092178]\n",
      "epoch:22 step:21124 [D loss: 0.545541, acc.: 71.88%] [G loss: 0.892601]\n",
      "epoch:22 step:21125 [D loss: 0.626684, acc.: 57.81%] [G loss: 0.611848]\n",
      "epoch:22 step:21126 [D loss: 0.558581, acc.: 69.53%] [G loss: 0.564126]\n",
      "epoch:22 step:21127 [D loss: 0.510156, acc.: 71.09%] [G loss: 0.675856]\n",
      "epoch:22 step:21128 [D loss: 0.530097, acc.: 70.31%] [G loss: 0.691467]\n",
      "epoch:22 step:21129 [D loss: 0.502681, acc.: 73.44%] [G loss: 0.874483]\n",
      "epoch:22 step:21130 [D loss: 0.467328, acc.: 76.56%] [G loss: 1.045257]\n",
      "epoch:22 step:21131 [D loss: 0.536527, acc.: 71.88%] [G loss: 0.763470]\n",
      "epoch:22 step:21132 [D loss: 0.540967, acc.: 67.97%] [G loss: 0.691181]\n",
      "epoch:22 step:21133 [D loss: 0.520135, acc.: 75.78%] [G loss: 0.620528]\n",
      "epoch:22 step:21134 [D loss: 0.473728, acc.: 75.78%] [G loss: 0.695185]\n",
      "epoch:22 step:21135 [D loss: 0.531306, acc.: 70.31%] [G loss: 0.659564]\n",
      "epoch:22 step:21136 [D loss: 0.507274, acc.: 71.88%] [G loss: 0.702756]\n",
      "epoch:22 step:21137 [D loss: 0.481770, acc.: 74.22%] [G loss: 0.835327]\n",
      "epoch:22 step:21138 [D loss: 0.545592, acc.: 70.31%] [G loss: 0.819285]\n",
      "epoch:22 step:21139 [D loss: 0.593790, acc.: 73.44%] [G loss: 0.730462]\n",
      "epoch:22 step:21140 [D loss: 0.477575, acc.: 77.34%] [G loss: 0.737849]\n",
      "epoch:22 step:21141 [D loss: 0.599431, acc.: 67.19%] [G loss: 0.872181]\n",
      "epoch:22 step:21142 [D loss: 0.664603, acc.: 60.16%] [G loss: 0.610550]\n",
      "epoch:22 step:21143 [D loss: 0.616821, acc.: 60.16%] [G loss: 0.589312]\n",
      "epoch:22 step:21144 [D loss: 0.534518, acc.: 71.09%] [G loss: 0.826138]\n",
      "epoch:22 step:21145 [D loss: 0.593578, acc.: 71.09%] [G loss: 0.713798]\n",
      "epoch:22 step:21146 [D loss: 0.633665, acc.: 63.28%] [G loss: 0.622517]\n",
      "epoch:22 step:21147 [D loss: 0.543365, acc.: 70.31%] [G loss: 0.591148]\n",
      "epoch:22 step:21148 [D loss: 0.475932, acc.: 78.91%] [G loss: 0.676733]\n",
      "epoch:22 step:21149 [D loss: 0.579163, acc.: 67.19%] [G loss: 0.567353]\n",
      "epoch:22 step:21150 [D loss: 0.519646, acc.: 76.56%] [G loss: 0.597366]\n",
      "epoch:22 step:21151 [D loss: 0.555153, acc.: 69.53%] [G loss: 0.609962]\n",
      "epoch:22 step:21152 [D loss: 0.562262, acc.: 68.75%] [G loss: 0.560602]\n",
      "epoch:22 step:21153 [D loss: 0.546185, acc.: 70.31%] [G loss: 0.623530]\n",
      "epoch:22 step:21154 [D loss: 0.505687, acc.: 68.75%] [G loss: 0.626270]\n",
      "epoch:22 step:21155 [D loss: 0.514495, acc.: 74.22%] [G loss: 0.657001]\n",
      "epoch:22 step:21156 [D loss: 0.636583, acc.: 61.72%] [G loss: 0.487904]\n",
      "epoch:22 step:21157 [D loss: 0.590004, acc.: 65.62%] [G loss: 0.596564]\n",
      "epoch:22 step:21158 [D loss: 0.599798, acc.: 66.41%] [G loss: 0.703151]\n",
      "epoch:22 step:21159 [D loss: 0.562231, acc.: 71.09%] [G loss: 0.688877]\n",
      "epoch:22 step:21160 [D loss: 0.535715, acc.: 71.09%] [G loss: 0.599019]\n",
      "epoch:22 step:21161 [D loss: 0.510880, acc.: 77.34%] [G loss: 0.839476]\n",
      "epoch:22 step:21162 [D loss: 0.486447, acc.: 74.22%] [G loss: 0.681934]\n",
      "epoch:22 step:21163 [D loss: 0.527704, acc.: 71.88%] [G loss: 1.050276]\n",
      "epoch:22 step:21164 [D loss: 0.533433, acc.: 71.88%] [G loss: 0.881101]\n",
      "epoch:22 step:21165 [D loss: 0.506824, acc.: 75.00%] [G loss: 0.718469]\n",
      "epoch:22 step:21166 [D loss: 0.512967, acc.: 75.78%] [G loss: 0.674491]\n",
      "epoch:22 step:21167 [D loss: 0.605816, acc.: 69.53%] [G loss: 0.576585]\n",
      "epoch:22 step:21168 [D loss: 0.475153, acc.: 80.47%] [G loss: 0.706640]\n",
      "epoch:22 step:21169 [D loss: 0.481154, acc.: 77.34%] [G loss: 0.733732]\n",
      "epoch:22 step:21170 [D loss: 0.574022, acc.: 68.75%] [G loss: 0.814648]\n",
      "epoch:22 step:21171 [D loss: 0.554286, acc.: 70.31%] [G loss: 0.642584]\n",
      "epoch:22 step:21172 [D loss: 0.450291, acc.: 82.03%] [G loss: 0.670870]\n",
      "epoch:22 step:21173 [D loss: 0.621567, acc.: 61.72%] [G loss: 0.774194]\n",
      "epoch:22 step:21174 [D loss: 0.591375, acc.: 65.62%] [G loss: 0.584478]\n",
      "epoch:22 step:21175 [D loss: 0.538874, acc.: 68.75%] [G loss: 0.626734]\n",
      "epoch:22 step:21176 [D loss: 0.602448, acc.: 63.28%] [G loss: 0.539109]\n",
      "epoch:22 step:21177 [D loss: 0.530064, acc.: 73.44%] [G loss: 0.593287]\n",
      "epoch:22 step:21178 [D loss: 0.474487, acc.: 76.56%] [G loss: 0.833703]\n",
      "epoch:22 step:21179 [D loss: 0.554709, acc.: 72.66%] [G loss: 0.846804]\n",
      "epoch:22 step:21180 [D loss: 0.668340, acc.: 66.41%] [G loss: 0.567626]\n",
      "epoch:22 step:21181 [D loss: 0.487493, acc.: 75.00%] [G loss: 0.604562]\n",
      "epoch:22 step:21182 [D loss: 0.500525, acc.: 76.56%] [G loss: 0.773360]\n",
      "epoch:22 step:21183 [D loss: 0.485549, acc.: 76.56%] [G loss: 0.706132]\n",
      "epoch:22 step:21184 [D loss: 0.524686, acc.: 75.78%] [G loss: 0.840820]\n",
      "epoch:22 step:21185 [D loss: 0.533689, acc.: 71.88%] [G loss: 0.861156]\n",
      "epoch:22 step:21186 [D loss: 0.547306, acc.: 71.88%] [G loss: 0.784750]\n",
      "epoch:22 step:21187 [D loss: 0.550262, acc.: 67.19%] [G loss: 0.607866]\n",
      "epoch:22 step:21188 [D loss: 0.459233, acc.: 78.12%] [G loss: 0.745561]\n",
      "epoch:22 step:21189 [D loss: 0.510034, acc.: 71.09%] [G loss: 0.873189]\n",
      "epoch:22 step:21190 [D loss: 0.606800, acc.: 62.50%] [G loss: 0.613910]\n",
      "epoch:22 step:21191 [D loss: 0.573924, acc.: 67.97%] [G loss: 0.758187]\n",
      "epoch:22 step:21192 [D loss: 0.540176, acc.: 70.31%] [G loss: 0.751990]\n",
      "epoch:22 step:21193 [D loss: 0.527901, acc.: 69.53%] [G loss: 0.585376]\n",
      "epoch:22 step:21194 [D loss: 0.569376, acc.: 69.53%] [G loss: 0.670608]\n",
      "epoch:22 step:21195 [D loss: 0.528202, acc.: 74.22%] [G loss: 0.697032]\n",
      "epoch:22 step:21196 [D loss: 0.430592, acc.: 84.38%] [G loss: 0.820563]\n",
      "epoch:22 step:21197 [D loss: 0.543979, acc.: 74.22%] [G loss: 0.906578]\n",
      "epoch:22 step:21198 [D loss: 0.659188, acc.: 60.94%] [G loss: 0.661316]\n",
      "epoch:22 step:21199 [D loss: 0.557671, acc.: 68.75%] [G loss: 0.563782]\n",
      "epoch:22 step:21200 [D loss: 0.523150, acc.: 70.31%] [G loss: 0.588882]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##############\n",
      "[2.82191792 0.9886889  6.18349123 4.97453857 3.93727667 5.81697759\n",
      " 4.40245163 5.03267743 4.71571787 4.28434699]\n",
      "##########\n",
      "epoch:22 step:21201 [D loss: 0.556503, acc.: 63.28%] [G loss: 0.476470]\n",
      "epoch:22 step:21202 [D loss: 0.586287, acc.: 57.81%] [G loss: 0.582746]\n",
      "epoch:22 step:21203 [D loss: 0.517390, acc.: 71.09%] [G loss: 0.619385]\n",
      "epoch:22 step:21204 [D loss: 0.542623, acc.: 67.19%] [G loss: 0.659464]\n",
      "epoch:22 step:21205 [D loss: 0.554296, acc.: 71.09%] [G loss: 0.698997]\n",
      "epoch:22 step:21206 [D loss: 0.483730, acc.: 79.69%] [G loss: 0.695118]\n",
      "epoch:22 step:21207 [D loss: 0.477577, acc.: 73.44%] [G loss: 0.677505]\n",
      "epoch:22 step:21208 [D loss: 0.574641, acc.: 67.19%] [G loss: 0.663356]\n",
      "epoch:22 step:21209 [D loss: 0.569811, acc.: 69.53%] [G loss: 0.652594]\n",
      "epoch:22 step:21210 [D loss: 0.532590, acc.: 68.75%] [G loss: 0.656087]\n",
      "epoch:22 step:21211 [D loss: 0.557509, acc.: 67.19%] [G loss: 0.606339]\n",
      "epoch:22 step:21212 [D loss: 0.495769, acc.: 75.00%] [G loss: 0.641140]\n",
      "epoch:22 step:21213 [D loss: 0.519628, acc.: 68.75%] [G loss: 0.729658]\n",
      "epoch:22 step:21214 [D loss: 0.570178, acc.: 70.31%] [G loss: 0.687609]\n",
      "epoch:22 step:21215 [D loss: 0.519710, acc.: 73.44%] [G loss: 0.885528]\n",
      "epoch:22 step:21216 [D loss: 0.494899, acc.: 76.56%] [G loss: 0.904167]\n",
      "epoch:22 step:21217 [D loss: 0.504599, acc.: 74.22%] [G loss: 0.864286]\n",
      "epoch:22 step:21218 [D loss: 0.573778, acc.: 68.75%] [G loss: 0.874192]\n",
      "epoch:22 step:21219 [D loss: 0.479098, acc.: 73.44%] [G loss: 0.911883]\n",
      "epoch:22 step:21220 [D loss: 0.607937, acc.: 73.44%] [G loss: 0.911793]\n",
      "epoch:22 step:21221 [D loss: 0.492297, acc.: 75.78%] [G loss: 0.719962]\n",
      "epoch:22 step:21222 [D loss: 0.554056, acc.: 68.75%] [G loss: 0.610554]\n",
      "epoch:22 step:21223 [D loss: 0.582999, acc.: 64.84%] [G loss: 0.614310]\n",
      "epoch:22 step:21224 [D loss: 0.588954, acc.: 67.19%] [G loss: 0.515899]\n",
      "epoch:22 step:21225 [D loss: 0.495831, acc.: 75.78%] [G loss: 0.554815]\n",
      "epoch:22 step:21226 [D loss: 0.546371, acc.: 71.88%] [G loss: 0.651559]\n",
      "epoch:22 step:21227 [D loss: 0.449752, acc.: 77.34%] [G loss: 0.776724]\n",
      "epoch:22 step:21228 [D loss: 0.574280, acc.: 62.50%] [G loss: 0.528306]\n",
      "epoch:22 step:21229 [D loss: 0.609015, acc.: 64.06%] [G loss: 0.659168]\n",
      "epoch:22 step:21230 [D loss: 0.543422, acc.: 71.09%] [G loss: 0.756830]\n",
      "epoch:22 step:21231 [D loss: 0.534094, acc.: 75.00%] [G loss: 0.671850]\n",
      "epoch:22 step:21232 [D loss: 0.559232, acc.: 67.97%] [G loss: 0.610031]\n",
      "epoch:22 step:21233 [D loss: 0.513482, acc.: 71.88%] [G loss: 0.772253]\n",
      "epoch:22 step:21234 [D loss: 0.527622, acc.: 74.22%] [G loss: 0.652604]\n",
      "epoch:22 step:21235 [D loss: 0.546107, acc.: 67.97%] [G loss: 0.591632]\n",
      "epoch:22 step:21236 [D loss: 0.590377, acc.: 67.97%] [G loss: 0.650306]\n",
      "epoch:22 step:21237 [D loss: 0.477820, acc.: 76.56%] [G loss: 0.685952]\n",
      "epoch:22 step:21238 [D loss: 0.458509, acc.: 78.91%] [G loss: 0.718024]\n",
      "epoch:22 step:21239 [D loss: 0.607008, acc.: 61.72%] [G loss: 0.713890]\n",
      "epoch:22 step:21240 [D loss: 0.528764, acc.: 69.53%] [G loss: 0.639614]\n",
      "epoch:22 step:21241 [D loss: 0.557907, acc.: 69.53%] [G loss: 0.642365]\n",
      "epoch:22 step:21242 [D loss: 0.656091, acc.: 60.94%] [G loss: 0.629555]\n",
      "epoch:22 step:21243 [D loss: 0.471733, acc.: 73.44%] [G loss: 0.658157]\n",
      "epoch:22 step:21244 [D loss: 0.589346, acc.: 65.62%] [G loss: 0.618089]\n",
      "epoch:22 step:21245 [D loss: 0.541099, acc.: 73.44%] [G loss: 0.726216]\n",
      "epoch:22 step:21246 [D loss: 0.497477, acc.: 71.09%] [G loss: 0.759380]\n",
      "epoch:22 step:21247 [D loss: 0.526819, acc.: 69.53%] [G loss: 0.722319]\n",
      "epoch:22 step:21248 [D loss: 0.478276, acc.: 80.47%] [G loss: 0.646847]\n",
      "epoch:22 step:21249 [D loss: 0.461517, acc.: 78.12%] [G loss: 0.789171]\n",
      "epoch:22 step:21250 [D loss: 0.620959, acc.: 64.06%] [G loss: 0.645353]\n",
      "epoch:22 step:21251 [D loss: 0.538911, acc.: 70.31%] [G loss: 0.653404]\n",
      "epoch:22 step:21252 [D loss: 0.548372, acc.: 67.19%] [G loss: 0.685867]\n",
      "epoch:22 step:21253 [D loss: 0.523400, acc.: 73.44%] [G loss: 0.714962]\n",
      "epoch:22 step:21254 [D loss: 0.541589, acc.: 67.97%] [G loss: 0.764980]\n",
      "epoch:22 step:21255 [D loss: 0.470326, acc.: 78.12%] [G loss: 0.957273]\n",
      "epoch:22 step:21256 [D loss: 0.467515, acc.: 80.47%] [G loss: 0.824439]\n",
      "epoch:22 step:21257 [D loss: 0.483570, acc.: 77.34%] [G loss: 0.823882]\n",
      "epoch:22 step:21258 [D loss: 0.562344, acc.: 67.97%] [G loss: 0.549048]\n",
      "epoch:22 step:21259 [D loss: 0.544940, acc.: 68.75%] [G loss: 0.607484]\n",
      "epoch:22 step:21260 [D loss: 0.565284, acc.: 69.53%] [G loss: 0.628790]\n",
      "epoch:22 step:21261 [D loss: 0.414798, acc.: 81.25%] [G loss: 0.791142]\n",
      "epoch:22 step:21262 [D loss: 0.397077, acc.: 85.94%] [G loss: 0.808663]\n",
      "epoch:22 step:21263 [D loss: 0.509405, acc.: 71.09%] [G loss: 0.850538]\n",
      "epoch:22 step:21264 [D loss: 0.518724, acc.: 76.56%] [G loss: 1.091227]\n",
      "epoch:22 step:21265 [D loss: 0.531641, acc.: 72.66%] [G loss: 0.831035]\n",
      "epoch:22 step:21266 [D loss: 0.648516, acc.: 64.06%] [G loss: 0.690643]\n",
      "epoch:22 step:21267 [D loss: 0.527166, acc.: 78.12%] [G loss: 0.635225]\n",
      "epoch:22 step:21268 [D loss: 0.538453, acc.: 73.44%] [G loss: 0.712778]\n",
      "epoch:22 step:21269 [D loss: 0.521373, acc.: 71.09%] [G loss: 0.864335]\n",
      "epoch:22 step:21270 [D loss: 0.528444, acc.: 67.97%] [G loss: 0.750794]\n",
      "epoch:22 step:21271 [D loss: 0.500072, acc.: 69.53%] [G loss: 0.675132]\n",
      "epoch:22 step:21272 [D loss: 0.557497, acc.: 67.19%] [G loss: 0.790216]\n",
      "epoch:22 step:21273 [D loss: 0.556620, acc.: 71.09%] [G loss: 0.522180]\n",
      "epoch:22 step:21274 [D loss: 0.485436, acc.: 76.56%] [G loss: 0.607666]\n",
      "epoch:22 step:21275 [D loss: 0.474549, acc.: 76.56%] [G loss: 0.749374]\n",
      "epoch:22 step:21276 [D loss: 0.570830, acc.: 71.09%] [G loss: 0.628469]\n",
      "epoch:22 step:21277 [D loss: 0.585460, acc.: 63.28%] [G loss: 0.755137]\n",
      "epoch:22 step:21278 [D loss: 0.530613, acc.: 69.53%] [G loss: 0.904528]\n",
      "epoch:22 step:21279 [D loss: 0.551847, acc.: 69.53%] [G loss: 0.683322]\n",
      "epoch:22 step:21280 [D loss: 0.506296, acc.: 71.88%] [G loss: 0.721055]\n",
      "epoch:22 step:21281 [D loss: 0.605196, acc.: 61.72%] [G loss: 0.639383]\n",
      "epoch:22 step:21282 [D loss: 0.528557, acc.: 75.78%] [G loss: 0.789855]\n",
      "epoch:22 step:21283 [D loss: 0.531590, acc.: 71.09%] [G loss: 0.731146]\n",
      "epoch:22 step:21284 [D loss: 0.492284, acc.: 73.44%] [G loss: 0.616235]\n",
      "epoch:22 step:21285 [D loss: 0.545028, acc.: 71.88%] [G loss: 0.655973]\n",
      "epoch:22 step:21286 [D loss: 0.550246, acc.: 67.19%] [G loss: 0.590811]\n",
      "epoch:22 step:21287 [D loss: 0.547046, acc.: 66.41%] [G loss: 0.729051]\n",
      "epoch:22 step:21288 [D loss: 0.524277, acc.: 68.75%] [G loss: 0.706449]\n",
      "epoch:22 step:21289 [D loss: 0.595106, acc.: 67.19%] [G loss: 0.604675]\n",
      "epoch:22 step:21290 [D loss: 0.544503, acc.: 74.22%] [G loss: 0.699154]\n",
      "epoch:22 step:21291 [D loss: 0.463376, acc.: 80.47%] [G loss: 0.600169]\n",
      "epoch:22 step:21292 [D loss: 0.607076, acc.: 68.75%] [G loss: 0.589505]\n",
      "epoch:22 step:21293 [D loss: 0.503991, acc.: 75.78%] [G loss: 0.738595]\n",
      "epoch:22 step:21294 [D loss: 0.550782, acc.: 75.00%] [G loss: 0.576861]\n",
      "epoch:22 step:21295 [D loss: 0.470800, acc.: 80.47%] [G loss: 0.646622]\n",
      "epoch:22 step:21296 [D loss: 0.511316, acc.: 73.44%] [G loss: 0.761443]\n",
      "epoch:22 step:21297 [D loss: 0.535077, acc.: 70.31%] [G loss: 0.741489]\n",
      "epoch:22 step:21298 [D loss: 0.566862, acc.: 71.88%] [G loss: 0.485132]\n",
      "epoch:22 step:21299 [D loss: 0.549806, acc.: 69.53%] [G loss: 0.538896]\n",
      "epoch:22 step:21300 [D loss: 0.577970, acc.: 65.62%] [G loss: 0.555076]\n",
      "epoch:22 step:21301 [D loss: 0.551440, acc.: 73.44%] [G loss: 0.550454]\n",
      "epoch:22 step:21302 [D loss: 0.545044, acc.: 70.31%] [G loss: 0.612144]\n",
      "epoch:22 step:21303 [D loss: 0.493063, acc.: 74.22%] [G loss: 0.704021]\n",
      "epoch:22 step:21304 [D loss: 0.491819, acc.: 75.78%] [G loss: 0.721411]\n",
      "epoch:22 step:21305 [D loss: 0.510956, acc.: 76.56%] [G loss: 0.565127]\n",
      "epoch:22 step:21306 [D loss: 0.560340, acc.: 70.31%] [G loss: 0.522619]\n",
      "epoch:22 step:21307 [D loss: 0.441222, acc.: 85.16%] [G loss: 0.812200]\n",
      "epoch:22 step:21308 [D loss: 0.431378, acc.: 78.91%] [G loss: 0.863311]\n",
      "epoch:22 step:21309 [D loss: 0.481328, acc.: 76.56%] [G loss: 0.825312]\n",
      "epoch:22 step:21310 [D loss: 0.618987, acc.: 61.72%] [G loss: 0.763627]\n",
      "epoch:22 step:21311 [D loss: 0.559977, acc.: 69.53%] [G loss: 0.594170]\n",
      "epoch:22 step:21312 [D loss: 0.534917, acc.: 68.75%] [G loss: 0.529525]\n",
      "epoch:22 step:21313 [D loss: 0.504841, acc.: 73.44%] [G loss: 0.711230]\n",
      "epoch:22 step:21314 [D loss: 0.548453, acc.: 70.31%] [G loss: 0.820731]\n",
      "epoch:22 step:21315 [D loss: 0.540775, acc.: 70.31%] [G loss: 0.675665]\n",
      "epoch:22 step:21316 [D loss: 0.536006, acc.: 71.88%] [G loss: 0.732285]\n",
      "epoch:22 step:21317 [D loss: 0.645677, acc.: 60.94%] [G loss: 0.687809]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:22 step:21318 [D loss: 0.600616, acc.: 67.19%] [G loss: 0.616174]\n",
      "epoch:22 step:21319 [D loss: 0.512278, acc.: 72.66%] [G loss: 0.564761]\n",
      "epoch:22 step:21320 [D loss: 0.536491, acc.: 72.66%] [G loss: 0.690381]\n",
      "epoch:22 step:21321 [D loss: 0.480136, acc.: 78.12%] [G loss: 0.651753]\n",
      "epoch:22 step:21322 [D loss: 0.513656, acc.: 75.78%] [G loss: 0.811569]\n",
      "epoch:22 step:21323 [D loss: 0.538197, acc.: 70.31%] [G loss: 0.847382]\n",
      "epoch:22 step:21324 [D loss: 0.590873, acc.: 71.09%] [G loss: 0.721486]\n",
      "epoch:22 step:21325 [D loss: 0.589184, acc.: 67.19%] [G loss: 0.903851]\n",
      "epoch:22 step:21326 [D loss: 0.558494, acc.: 69.53%] [G loss: 0.821137]\n",
      "epoch:22 step:21327 [D loss: 0.617402, acc.: 66.41%] [G loss: 0.618026]\n",
      "epoch:22 step:21328 [D loss: 0.497138, acc.: 73.44%] [G loss: 0.761046]\n",
      "epoch:22 step:21329 [D loss: 0.528416, acc.: 73.44%] [G loss: 0.627855]\n",
      "epoch:22 step:21330 [D loss: 0.624322, acc.: 69.53%] [G loss: 0.487626]\n",
      "epoch:22 step:21331 [D loss: 0.596767, acc.: 67.97%] [G loss: 0.598870]\n",
      "epoch:22 step:21332 [D loss: 0.524537, acc.: 72.66%] [G loss: 0.708481]\n",
      "epoch:22 step:21333 [D loss: 0.533628, acc.: 67.97%] [G loss: 0.769924]\n",
      "epoch:22 step:21334 [D loss: 0.552055, acc.: 74.22%] [G loss: 0.599833]\n",
      "epoch:22 step:21335 [D loss: 0.560558, acc.: 68.75%] [G loss: 0.764227]\n",
      "epoch:22 step:21336 [D loss: 0.535806, acc.: 71.09%] [G loss: 0.561083]\n",
      "epoch:22 step:21337 [D loss: 0.560623, acc.: 68.75%] [G loss: 0.625591]\n",
      "epoch:22 step:21338 [D loss: 0.472661, acc.: 78.91%] [G loss: 0.684846]\n",
      "epoch:22 step:21339 [D loss: 0.470661, acc.: 78.12%] [G loss: 0.776770]\n",
      "epoch:22 step:21340 [D loss: 0.503961, acc.: 78.12%] [G loss: 0.832861]\n",
      "epoch:22 step:21341 [D loss: 0.531313, acc.: 71.88%] [G loss: 0.768793]\n",
      "epoch:22 step:21342 [D loss: 0.538539, acc.: 74.22%] [G loss: 0.773746]\n",
      "epoch:22 step:21343 [D loss: 0.566743, acc.: 68.75%] [G loss: 0.650720]\n",
      "epoch:22 step:21344 [D loss: 0.539837, acc.: 73.44%] [G loss: 0.579240]\n",
      "epoch:22 step:21345 [D loss: 0.568899, acc.: 67.97%] [G loss: 0.689228]\n",
      "epoch:22 step:21346 [D loss: 0.598738, acc.: 66.41%] [G loss: 0.595230]\n",
      "epoch:22 step:21347 [D loss: 0.517210, acc.: 73.44%] [G loss: 0.455195]\n",
      "epoch:22 step:21348 [D loss: 0.548544, acc.: 71.88%] [G loss: 0.548915]\n",
      "epoch:22 step:21349 [D loss: 0.591109, acc.: 65.62%] [G loss: 0.568911]\n",
      "epoch:22 step:21350 [D loss: 0.476505, acc.: 75.78%] [G loss: 0.761721]\n",
      "epoch:22 step:21351 [D loss: 0.514918, acc.: 71.09%] [G loss: 0.609699]\n",
      "epoch:22 step:21352 [D loss: 0.567086, acc.: 64.06%] [G loss: 0.581167]\n",
      "epoch:22 step:21353 [D loss: 0.543575, acc.: 71.09%] [G loss: 0.676545]\n",
      "epoch:22 step:21354 [D loss: 0.606049, acc.: 64.84%] [G loss: 0.540169]\n",
      "epoch:22 step:21355 [D loss: 0.535662, acc.: 71.09%] [G loss: 0.579247]\n",
      "epoch:22 step:21356 [D loss: 0.502910, acc.: 75.00%] [G loss: 0.723977]\n",
      "epoch:22 step:21357 [D loss: 0.523046, acc.: 68.75%] [G loss: 0.693665]\n",
      "epoch:22 step:21358 [D loss: 0.520987, acc.: 78.91%] [G loss: 0.961384]\n",
      "epoch:22 step:21359 [D loss: 0.564504, acc.: 70.31%] [G loss: 0.732436]\n",
      "epoch:22 step:21360 [D loss: 0.479145, acc.: 75.78%] [G loss: 0.704376]\n",
      "epoch:22 step:21361 [D loss: 0.435705, acc.: 82.03%] [G loss: 0.917103]\n",
      "epoch:22 step:21362 [D loss: 0.504668, acc.: 74.22%] [G loss: 0.782511]\n",
      "epoch:22 step:21363 [D loss: 0.538730, acc.: 71.09%] [G loss: 0.564843]\n",
      "epoch:22 step:21364 [D loss: 0.486977, acc.: 73.44%] [G loss: 0.669900]\n",
      "epoch:22 step:21365 [D loss: 0.480813, acc.: 78.91%] [G loss: 0.761288]\n",
      "epoch:22 step:21366 [D loss: 0.659884, acc.: 61.72%] [G loss: 0.786913]\n",
      "epoch:22 step:21367 [D loss: 0.510593, acc.: 72.66%] [G loss: 0.589726]\n",
      "epoch:22 step:21368 [D loss: 0.529885, acc.: 74.22%] [G loss: 0.679817]\n",
      "epoch:22 step:21369 [D loss: 0.547317, acc.: 67.19%] [G loss: 0.982723]\n",
      "epoch:22 step:21370 [D loss: 0.580354, acc.: 67.97%] [G loss: 0.716516]\n",
      "epoch:22 step:21371 [D loss: 0.559074, acc.: 66.41%] [G loss: 0.629611]\n",
      "epoch:22 step:21372 [D loss: 0.550449, acc.: 72.66%] [G loss: 0.609467]\n",
      "epoch:22 step:21373 [D loss: 0.547640, acc.: 71.88%] [G loss: 0.569731]\n",
      "epoch:22 step:21374 [D loss: 0.527796, acc.: 70.31%] [G loss: 0.671919]\n",
      "epoch:22 step:21375 [D loss: 0.516988, acc.: 70.31%] [G loss: 0.697548]\n",
      "epoch:22 step:21376 [D loss: 0.619494, acc.: 67.97%] [G loss: 0.700210]\n",
      "epoch:22 step:21377 [D loss: 0.573147, acc.: 64.06%] [G loss: 0.592290]\n",
      "epoch:22 step:21378 [D loss: 0.563427, acc.: 67.19%] [G loss: 0.710092]\n",
      "epoch:22 step:21379 [D loss: 0.560509, acc.: 67.19%] [G loss: 0.710111]\n",
      "epoch:22 step:21380 [D loss: 0.652002, acc.: 63.28%] [G loss: 0.613324]\n",
      "epoch:22 step:21381 [D loss: 0.539294, acc.: 71.88%] [G loss: 0.583302]\n",
      "epoch:22 step:21382 [D loss: 0.553969, acc.: 71.88%] [G loss: 0.990597]\n",
      "epoch:22 step:21383 [D loss: 0.540055, acc.: 71.09%] [G loss: 0.976379]\n",
      "epoch:22 step:21384 [D loss: 0.487895, acc.: 76.56%] [G loss: 0.936748]\n",
      "epoch:22 step:21385 [D loss: 0.518546, acc.: 73.44%] [G loss: 0.724419]\n",
      "epoch:22 step:21386 [D loss: 0.564665, acc.: 69.53%] [G loss: 0.719306]\n",
      "epoch:22 step:21387 [D loss: 0.569729, acc.: 69.53%] [G loss: 0.606105]\n",
      "epoch:22 step:21388 [D loss: 0.550757, acc.: 73.44%] [G loss: 0.734927]\n",
      "epoch:22 step:21389 [D loss: 0.508955, acc.: 76.56%] [G loss: 0.708194]\n",
      "epoch:22 step:21390 [D loss: 0.554562, acc.: 71.09%] [G loss: 0.669407]\n",
      "epoch:22 step:21391 [D loss: 0.518201, acc.: 73.44%] [G loss: 0.656050]\n",
      "epoch:22 step:21392 [D loss: 0.536029, acc.: 68.75%] [G loss: 0.618025]\n",
      "epoch:22 step:21393 [D loss: 0.563123, acc.: 70.31%] [G loss: 0.622823]\n",
      "epoch:22 step:21394 [D loss: 0.523354, acc.: 71.88%] [G loss: 0.730353]\n",
      "epoch:22 step:21395 [D loss: 0.462556, acc.: 76.56%] [G loss: 0.802128]\n",
      "epoch:22 step:21396 [D loss: 0.527822, acc.: 70.31%] [G loss: 0.929309]\n",
      "epoch:22 step:21397 [D loss: 0.577465, acc.: 68.75%] [G loss: 0.791947]\n",
      "epoch:22 step:21398 [D loss: 0.611858, acc.: 67.97%] [G loss: 0.637884]\n",
      "epoch:22 step:21399 [D loss: 0.509659, acc.: 71.88%] [G loss: 0.743425]\n",
      "epoch:22 step:21400 [D loss: 0.491725, acc.: 77.34%] [G loss: 0.677435]\n",
      "##############\n",
      "[3.21726444 1.43696555 6.30621088 4.82936544 4.05418291 5.54155913\n",
      " 4.58848714 5.00774977 4.6379465  4.23272189]\n",
      "##########\n",
      "epoch:22 step:21401 [D loss: 0.563342, acc.: 71.09%] [G loss: 0.660565]\n",
      "epoch:22 step:21402 [D loss: 0.619804, acc.: 66.41%] [G loss: 0.541896]\n",
      "epoch:22 step:21403 [D loss: 0.466185, acc.: 77.34%] [G loss: 0.616949]\n",
      "epoch:22 step:21404 [D loss: 0.526288, acc.: 71.09%] [G loss: 0.597566]\n",
      "epoch:22 step:21405 [D loss: 0.528499, acc.: 76.56%] [G loss: 0.645823]\n",
      "epoch:22 step:21406 [D loss: 0.446918, acc.: 77.34%] [G loss: 0.708392]\n",
      "epoch:22 step:21407 [D loss: 0.561626, acc.: 71.09%] [G loss: 0.668084]\n",
      "epoch:22 step:21408 [D loss: 0.642757, acc.: 60.94%] [G loss: 0.594664]\n",
      "epoch:22 step:21409 [D loss: 0.536997, acc.: 67.97%] [G loss: 0.713904]\n",
      "epoch:22 step:21410 [D loss: 0.486884, acc.: 79.69%] [G loss: 0.727464]\n",
      "epoch:22 step:21411 [D loss: 0.558902, acc.: 68.75%] [G loss: 0.997078]\n",
      "epoch:22 step:21412 [D loss: 0.523605, acc.: 67.97%] [G loss: 0.738083]\n",
      "epoch:22 step:21413 [D loss: 0.535462, acc.: 71.09%] [G loss: 0.893022]\n",
      "epoch:22 step:21414 [D loss: 0.600447, acc.: 62.50%] [G loss: 0.712084]\n",
      "epoch:22 step:21415 [D loss: 0.492342, acc.: 78.12%] [G loss: 0.812853]\n",
      "epoch:22 step:21416 [D loss: 0.466492, acc.: 76.56%] [G loss: 0.982665]\n",
      "epoch:22 step:21417 [D loss: 0.544362, acc.: 74.22%] [G loss: 0.774448]\n",
      "epoch:22 step:21418 [D loss: 0.534176, acc.: 69.53%] [G loss: 0.713704]\n",
      "epoch:22 step:21419 [D loss: 0.549961, acc.: 70.31%] [G loss: 0.660307]\n",
      "epoch:22 step:21420 [D loss: 0.552042, acc.: 70.31%] [G loss: 0.541718]\n",
      "epoch:22 step:21421 [D loss: 0.523326, acc.: 74.22%] [G loss: 0.491517]\n",
      "epoch:22 step:21422 [D loss: 0.553615, acc.: 67.97%] [G loss: 0.569367]\n",
      "epoch:22 step:21423 [D loss: 0.529771, acc.: 69.53%] [G loss: 0.632348]\n",
      "epoch:22 step:21424 [D loss: 0.475093, acc.: 78.91%] [G loss: 0.675671]\n",
      "epoch:22 step:21425 [D loss: 0.565821, acc.: 71.88%] [G loss: 0.511204]\n",
      "epoch:22 step:21426 [D loss: 0.586472, acc.: 67.97%] [G loss: 0.479477]\n",
      "epoch:22 step:21427 [D loss: 0.560944, acc.: 67.97%] [G loss: 0.568123]\n",
      "epoch:22 step:21428 [D loss: 0.440270, acc.: 76.56%] [G loss: 0.623711]\n",
      "epoch:22 step:21429 [D loss: 0.497462, acc.: 74.22%] [G loss: 0.982396]\n",
      "epoch:22 step:21430 [D loss: 0.475936, acc.: 75.78%] [G loss: 0.973846]\n",
      "epoch:22 step:21431 [D loss: 0.625325, acc.: 60.94%] [G loss: 0.769526]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:22 step:21432 [D loss: 0.537283, acc.: 68.75%] [G loss: 0.559812]\n",
      "epoch:22 step:21433 [D loss: 0.520582, acc.: 75.78%] [G loss: 0.632637]\n",
      "epoch:22 step:21434 [D loss: 0.649235, acc.: 62.50%] [G loss: 0.553991]\n",
      "epoch:22 step:21435 [D loss: 0.539548, acc.: 67.19%] [G loss: 0.568581]\n",
      "epoch:22 step:21436 [D loss: 0.528238, acc.: 70.31%] [G loss: 0.523026]\n",
      "epoch:22 step:21437 [D loss: 0.442762, acc.: 79.69%] [G loss: 0.702024]\n",
      "epoch:22 step:21438 [D loss: 0.550322, acc.: 66.41%] [G loss: 0.645169]\n",
      "epoch:22 step:21439 [D loss: 0.502158, acc.: 75.00%] [G loss: 0.696752]\n",
      "epoch:22 step:21440 [D loss: 0.497407, acc.: 75.78%] [G loss: 0.747838]\n",
      "epoch:22 step:21441 [D loss: 0.522268, acc.: 69.53%] [G loss: 0.756225]\n",
      "epoch:22 step:21442 [D loss: 0.589957, acc.: 67.19%] [G loss: 0.732139]\n",
      "epoch:22 step:21443 [D loss: 0.580586, acc.: 67.19%] [G loss: 0.781273]\n",
      "epoch:22 step:21444 [D loss: 0.556372, acc.: 65.62%] [G loss: 0.631247]\n",
      "epoch:22 step:21445 [D loss: 0.553041, acc.: 71.09%] [G loss: 0.628497]\n",
      "epoch:22 step:21446 [D loss: 0.534695, acc.: 71.88%] [G loss: 0.735007]\n",
      "epoch:22 step:21447 [D loss: 0.475979, acc.: 72.66%] [G loss: 0.741905]\n",
      "epoch:22 step:21448 [D loss: 0.515773, acc.: 72.66%] [G loss: 0.623002]\n",
      "epoch:22 step:21449 [D loss: 0.534243, acc.: 71.88%] [G loss: 0.603303]\n",
      "epoch:22 step:21450 [D loss: 0.498839, acc.: 71.88%] [G loss: 0.523740]\n",
      "epoch:22 step:21451 [D loss: 0.537680, acc.: 68.75%] [G loss: 0.655103]\n",
      "epoch:22 step:21452 [D loss: 0.525956, acc.: 72.66%] [G loss: 0.739789]\n",
      "epoch:22 step:21453 [D loss: 0.557479, acc.: 67.19%] [G loss: 0.656053]\n",
      "epoch:22 step:21454 [D loss: 0.562867, acc.: 68.75%] [G loss: 0.535101]\n",
      "epoch:22 step:21455 [D loss: 0.543397, acc.: 68.75%] [G loss: 0.595276]\n",
      "epoch:22 step:21456 [D loss: 0.553531, acc.: 70.31%] [G loss: 0.513328]\n",
      "epoch:22 step:21457 [D loss: 0.487587, acc.: 76.56%] [G loss: 0.801309]\n",
      "epoch:22 step:21458 [D loss: 0.537903, acc.: 71.09%] [G loss: 0.552999]\n",
      "epoch:22 step:21459 [D loss: 0.567536, acc.: 66.41%] [G loss: 0.721353]\n",
      "epoch:22 step:21460 [D loss: 0.578671, acc.: 62.50%] [G loss: 0.541333]\n",
      "epoch:22 step:21461 [D loss: 0.629529, acc.: 66.41%] [G loss: 0.522625]\n",
      "epoch:22 step:21462 [D loss: 0.541436, acc.: 63.28%] [G loss: 0.476179]\n",
      "epoch:22 step:21463 [D loss: 0.495658, acc.: 75.78%] [G loss: 0.709743]\n",
      "epoch:22 step:21464 [D loss: 0.517249, acc.: 73.44%] [G loss: 0.545458]\n",
      "epoch:22 step:21465 [D loss: 0.622304, acc.: 59.38%] [G loss: 0.564934]\n",
      "epoch:22 step:21466 [D loss: 0.568122, acc.: 67.19%] [G loss: 0.656689]\n",
      "epoch:22 step:21467 [D loss: 0.566606, acc.: 68.75%] [G loss: 0.614411]\n",
      "epoch:22 step:21468 [D loss: 0.543951, acc.: 71.09%] [G loss: 0.551166]\n",
      "epoch:22 step:21469 [D loss: 0.545193, acc.: 70.31%] [G loss: 0.647932]\n",
      "epoch:22 step:21470 [D loss: 0.530032, acc.: 71.88%] [G loss: 0.530650]\n",
      "epoch:22 step:21471 [D loss: 0.446105, acc.: 83.59%] [G loss: 0.726464]\n",
      "epoch:22 step:21472 [D loss: 0.604697, acc.: 68.75%] [G loss: 0.803481]\n",
      "epoch:22 step:21473 [D loss: 0.569091, acc.: 68.75%] [G loss: 0.723622]\n",
      "epoch:22 step:21474 [D loss: 0.447723, acc.: 80.47%] [G loss: 0.898450]\n",
      "epoch:22 step:21475 [D loss: 0.625861, acc.: 64.06%] [G loss: 0.561796]\n",
      "epoch:22 step:21476 [D loss: 0.541090, acc.: 71.09%] [G loss: 0.611918]\n",
      "epoch:22 step:21477 [D loss: 0.533549, acc.: 70.31%] [G loss: 0.549891]\n",
      "epoch:22 step:21478 [D loss: 0.608894, acc.: 63.28%] [G loss: 0.485555]\n",
      "epoch:22 step:21479 [D loss: 0.553777, acc.: 67.19%] [G loss: 0.632136]\n",
      "epoch:22 step:21480 [D loss: 0.554031, acc.: 71.09%] [G loss: 0.525579]\n",
      "epoch:22 step:21481 [D loss: 0.683297, acc.: 57.03%] [G loss: 0.462764]\n",
      "epoch:22 step:21482 [D loss: 0.468978, acc.: 74.22%] [G loss: 0.461035]\n",
      "epoch:22 step:21483 [D loss: 0.545617, acc.: 70.31%] [G loss: 0.539892]\n",
      "epoch:22 step:21484 [D loss: 0.455600, acc.: 78.12%] [G loss: 0.590075]\n",
      "epoch:22 step:21485 [D loss: 0.445244, acc.: 78.12%] [G loss: 0.616988]\n",
      "epoch:22 step:21486 [D loss: 0.500183, acc.: 77.34%] [G loss: 0.865651]\n",
      "epoch:22 step:21487 [D loss: 0.570590, acc.: 67.97%] [G loss: 0.515668]\n",
      "epoch:22 step:21488 [D loss: 0.595999, acc.: 64.06%] [G loss: 0.625087]\n",
      "epoch:22 step:21489 [D loss: 0.483105, acc.: 72.66%] [G loss: 0.738630]\n",
      "epoch:22 step:21490 [D loss: 0.531783, acc.: 70.31%] [G loss: 0.612451]\n",
      "epoch:22 step:21491 [D loss: 0.615146, acc.: 65.62%] [G loss: 0.540354]\n",
      "epoch:22 step:21492 [D loss: 0.564679, acc.: 64.06%] [G loss: 0.614309]\n",
      "epoch:22 step:21493 [D loss: 0.549979, acc.: 68.75%] [G loss: 0.843616]\n",
      "epoch:22 step:21494 [D loss: 0.632055, acc.: 62.50%] [G loss: 0.605814]\n",
      "epoch:22 step:21495 [D loss: 0.557063, acc.: 69.53%] [G loss: 0.562122]\n",
      "epoch:22 step:21496 [D loss: 0.533071, acc.: 71.88%] [G loss: 0.516927]\n",
      "epoch:22 step:21497 [D loss: 0.596153, acc.: 64.84%] [G loss: 0.591107]\n",
      "epoch:22 step:21498 [D loss: 0.451759, acc.: 78.12%] [G loss: 0.849890]\n",
      "epoch:22 step:21499 [D loss: 0.498876, acc.: 70.31%] [G loss: 0.893435]\n",
      "epoch:22 step:21500 [D loss: 0.497822, acc.: 75.78%] [G loss: 0.778752]\n",
      "epoch:22 step:21501 [D loss: 0.540613, acc.: 73.44%] [G loss: 0.776775]\n",
      "epoch:22 step:21502 [D loss: 0.590196, acc.: 60.94%] [G loss: 0.709211]\n",
      "epoch:22 step:21503 [D loss: 0.543860, acc.: 71.88%] [G loss: 0.702744]\n",
      "epoch:22 step:21504 [D loss: 0.490764, acc.: 73.44%] [G loss: 0.815268]\n",
      "epoch:22 step:21505 [D loss: 0.582961, acc.: 69.53%] [G loss: 0.752911]\n",
      "epoch:22 step:21506 [D loss: 0.656316, acc.: 59.38%] [G loss: 0.515247]\n",
      "epoch:22 step:21507 [D loss: 0.510373, acc.: 75.00%] [G loss: 0.515987]\n",
      "epoch:22 step:21508 [D loss: 0.473646, acc.: 77.34%] [G loss: 0.573606]\n",
      "epoch:22 step:21509 [D loss: 0.529311, acc.: 71.09%] [G loss: 0.726679]\n",
      "epoch:22 step:21510 [D loss: 0.466937, acc.: 80.47%] [G loss: 0.769810]\n",
      "epoch:22 step:21511 [D loss: 0.495866, acc.: 73.44%] [G loss: 0.691202]\n",
      "epoch:22 step:21512 [D loss: 0.549588, acc.: 67.19%] [G loss: 0.907314]\n",
      "epoch:22 step:21513 [D loss: 0.503610, acc.: 74.22%] [G loss: 0.876902]\n",
      "epoch:22 step:21514 [D loss: 0.548932, acc.: 71.09%] [G loss: 0.762376]\n",
      "epoch:22 step:21515 [D loss: 0.490828, acc.: 76.56%] [G loss: 0.857492]\n",
      "epoch:22 step:21516 [D loss: 0.604226, acc.: 66.41%] [G loss: 0.574313]\n",
      "epoch:22 step:21517 [D loss: 0.527933, acc.: 74.22%] [G loss: 0.571193]\n",
      "epoch:22 step:21518 [D loss: 0.581482, acc.: 67.19%] [G loss: 0.813819]\n",
      "epoch:22 step:21519 [D loss: 0.539123, acc.: 72.66%] [G loss: 0.625607]\n",
      "epoch:22 step:21520 [D loss: 0.553841, acc.: 75.78%] [G loss: 0.700264]\n",
      "epoch:22 step:21521 [D loss: 0.539695, acc.: 75.00%] [G loss: 0.718876]\n",
      "epoch:22 step:21522 [D loss: 0.520314, acc.: 75.00%] [G loss: 0.749602]\n",
      "epoch:22 step:21523 [D loss: 0.455264, acc.: 78.91%] [G loss: 0.750314]\n",
      "epoch:22 step:21524 [D loss: 0.591673, acc.: 63.28%] [G loss: 0.714715]\n",
      "epoch:22 step:21525 [D loss: 0.485994, acc.: 76.56%] [G loss: 0.787527]\n",
      "epoch:22 step:21526 [D loss: 0.574666, acc.: 70.31%] [G loss: 0.716858]\n",
      "epoch:22 step:21527 [D loss: 0.569375, acc.: 69.53%] [G loss: 0.840778]\n",
      "epoch:22 step:21528 [D loss: 0.566666, acc.: 71.09%] [G loss: 0.918563]\n",
      "epoch:22 step:21529 [D loss: 0.608559, acc.: 64.06%] [G loss: 0.617067]\n",
      "epoch:22 step:21530 [D loss: 0.530885, acc.: 74.22%] [G loss: 0.782356]\n",
      "epoch:22 step:21531 [D loss: 0.557514, acc.: 69.53%] [G loss: 0.727385]\n",
      "epoch:22 step:21532 [D loss: 0.499473, acc.: 71.88%] [G loss: 0.744384]\n",
      "epoch:22 step:21533 [D loss: 0.417898, acc.: 82.03%] [G loss: 1.025530]\n",
      "epoch:22 step:21534 [D loss: 0.793336, acc.: 59.38%] [G loss: 0.571328]\n",
      "epoch:22 step:21535 [D loss: 0.471578, acc.: 79.69%] [G loss: 0.768131]\n",
      "epoch:22 step:21536 [D loss: 0.528336, acc.: 71.88%] [G loss: 0.825771]\n",
      "epoch:22 step:21537 [D loss: 0.436467, acc.: 78.91%] [G loss: 0.757590]\n",
      "epoch:22 step:21538 [D loss: 0.486950, acc.: 74.22%] [G loss: 0.838479]\n",
      "epoch:22 step:21539 [D loss: 0.416202, acc.: 81.25%] [G loss: 0.998385]\n",
      "epoch:22 step:21540 [D loss: 0.460222, acc.: 80.47%] [G loss: 1.079981]\n",
      "epoch:22 step:21541 [D loss: 0.505731, acc.: 73.44%] [G loss: 1.044077]\n",
      "epoch:22 step:21542 [D loss: 0.630874, acc.: 63.28%] [G loss: 1.325257]\n",
      "epoch:22 step:21543 [D loss: 0.459716, acc.: 78.91%] [G loss: 1.580737]\n",
      "epoch:22 step:21544 [D loss: 0.419008, acc.: 78.12%] [G loss: 1.297957]\n",
      "epoch:22 step:21545 [D loss: 0.575235, acc.: 70.31%] [G loss: 1.168707]\n",
      "epoch:22 step:21546 [D loss: 0.597873, acc.: 64.06%] [G loss: 0.711047]\n",
      "epoch:22 step:21547 [D loss: 0.569580, acc.: 70.31%] [G loss: 0.922657]\n",
      "epoch:22 step:21548 [D loss: 0.550712, acc.: 70.31%] [G loss: 0.938239]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:22 step:21549 [D loss: 0.455092, acc.: 76.56%] [G loss: 0.944982]\n",
      "epoch:22 step:21550 [D loss: 0.441239, acc.: 76.56%] [G loss: 1.091658]\n",
      "epoch:22 step:21551 [D loss: 0.485445, acc.: 79.69%] [G loss: 1.299804]\n",
      "epoch:23 step:21552 [D loss: 0.546519, acc.: 74.22%] [G loss: 1.118688]\n",
      "epoch:23 step:21553 [D loss: 0.415047, acc.: 77.34%] [G loss: 1.002480]\n",
      "epoch:23 step:21554 [D loss: 0.519512, acc.: 71.88%] [G loss: 1.076760]\n",
      "epoch:23 step:21555 [D loss: 0.522492, acc.: 70.31%] [G loss: 0.764427]\n",
      "epoch:23 step:21556 [D loss: 0.579136, acc.: 65.62%] [G loss: 0.933664]\n",
      "epoch:23 step:21557 [D loss: 0.602509, acc.: 72.66%] [G loss: 0.936355]\n",
      "epoch:23 step:21558 [D loss: 0.487364, acc.: 81.25%] [G loss: 0.854666]\n",
      "epoch:23 step:21559 [D loss: 0.559952, acc.: 71.88%] [G loss: 0.804536]\n",
      "epoch:23 step:21560 [D loss: 0.481406, acc.: 74.22%] [G loss: 0.873338]\n",
      "epoch:23 step:21561 [D loss: 0.557628, acc.: 75.00%] [G loss: 0.916744]\n",
      "epoch:23 step:21562 [D loss: 0.453746, acc.: 80.47%] [G loss: 0.987144]\n",
      "epoch:23 step:21563 [D loss: 0.611905, acc.: 65.62%] [G loss: 0.675119]\n",
      "epoch:23 step:21564 [D loss: 0.587934, acc.: 66.41%] [G loss: 0.482273]\n",
      "epoch:23 step:21565 [D loss: 0.516604, acc.: 72.66%] [G loss: 0.745732]\n",
      "epoch:23 step:21566 [D loss: 0.516885, acc.: 69.53%] [G loss: 0.626450]\n",
      "epoch:23 step:21567 [D loss: 0.487090, acc.: 78.12%] [G loss: 0.810097]\n",
      "epoch:23 step:21568 [D loss: 0.523473, acc.: 71.88%] [G loss: 0.635978]\n",
      "epoch:23 step:21569 [D loss: 0.581990, acc.: 67.19%] [G loss: 0.671062]\n",
      "epoch:23 step:21570 [D loss: 0.547773, acc.: 71.88%] [G loss: 0.737700]\n",
      "epoch:23 step:21571 [D loss: 0.658155, acc.: 61.72%] [G loss: 0.688923]\n",
      "epoch:23 step:21572 [D loss: 0.606189, acc.: 65.62%] [G loss: 0.788215]\n",
      "epoch:23 step:21573 [D loss: 0.480911, acc.: 75.00%] [G loss: 1.002729]\n",
      "epoch:23 step:21574 [D loss: 0.555852, acc.: 68.75%] [G loss: 0.841248]\n",
      "epoch:23 step:21575 [D loss: 0.472802, acc.: 77.34%] [G loss: 0.682603]\n",
      "epoch:23 step:21576 [D loss: 0.489009, acc.: 74.22%] [G loss: 0.613654]\n",
      "epoch:23 step:21577 [D loss: 0.568817, acc.: 65.62%] [G loss: 0.691709]\n",
      "epoch:23 step:21578 [D loss: 0.435523, acc.: 78.91%] [G loss: 0.703047]\n",
      "epoch:23 step:21579 [D loss: 0.538679, acc.: 71.09%] [G loss: 0.674317]\n",
      "epoch:23 step:21580 [D loss: 0.572161, acc.: 67.19%] [G loss: 0.795102]\n",
      "epoch:23 step:21581 [D loss: 0.562774, acc.: 71.88%] [G loss: 0.681516]\n",
      "epoch:23 step:21582 [D loss: 0.601608, acc.: 65.62%] [G loss: 0.726217]\n",
      "epoch:23 step:21583 [D loss: 0.510327, acc.: 76.56%] [G loss: 0.663990]\n",
      "epoch:23 step:21584 [D loss: 0.559859, acc.: 70.31%] [G loss: 0.747963]\n",
      "epoch:23 step:21585 [D loss: 0.552913, acc.: 69.53%] [G loss: 0.815819]\n",
      "epoch:23 step:21586 [D loss: 0.616287, acc.: 64.84%] [G loss: 0.595028]\n",
      "epoch:23 step:21587 [D loss: 0.542248, acc.: 67.97%] [G loss: 0.831137]\n",
      "epoch:23 step:21588 [D loss: 0.521206, acc.: 77.34%] [G loss: 0.669897]\n",
      "epoch:23 step:21589 [D loss: 0.594698, acc.: 67.97%] [G loss: 0.635195]\n",
      "epoch:23 step:21590 [D loss: 0.547802, acc.: 68.75%] [G loss: 0.644990]\n",
      "epoch:23 step:21591 [D loss: 0.409636, acc.: 81.25%] [G loss: 0.838483]\n",
      "epoch:23 step:21592 [D loss: 0.534563, acc.: 73.44%] [G loss: 0.703652]\n",
      "epoch:23 step:21593 [D loss: 0.500506, acc.: 76.56%] [G loss: 0.557886]\n",
      "epoch:23 step:21594 [D loss: 0.511392, acc.: 74.22%] [G loss: 0.604457]\n",
      "epoch:23 step:21595 [D loss: 0.610208, acc.: 66.41%] [G loss: 0.557305]\n",
      "epoch:23 step:21596 [D loss: 0.484371, acc.: 78.12%] [G loss: 0.737556]\n",
      "epoch:23 step:21597 [D loss: 0.516697, acc.: 70.31%] [G loss: 0.683191]\n",
      "epoch:23 step:21598 [D loss: 0.502612, acc.: 74.22%] [G loss: 0.833965]\n",
      "epoch:23 step:21599 [D loss: 0.479015, acc.: 80.47%] [G loss: 0.744171]\n",
      "epoch:23 step:21600 [D loss: 0.445574, acc.: 82.03%] [G loss: 0.864649]\n",
      "##############\n",
      "[2.58804462 1.3121519  6.18797383 5.15081664 3.84264983 5.80017585\n",
      " 4.71178504 4.98832456 4.70885445 4.33562817]\n",
      "##########\n",
      "epoch:23 step:21601 [D loss: 0.541193, acc.: 67.97%] [G loss: 0.825089]\n",
      "epoch:23 step:21602 [D loss: 0.625068, acc.: 69.53%] [G loss: 0.642413]\n",
      "epoch:23 step:21603 [D loss: 0.606836, acc.: 66.41%] [G loss: 0.638778]\n",
      "epoch:23 step:21604 [D loss: 0.572085, acc.: 67.97%] [G loss: 0.706042]\n",
      "epoch:23 step:21605 [D loss: 0.444656, acc.: 79.69%] [G loss: 0.695392]\n",
      "epoch:23 step:21606 [D loss: 0.530620, acc.: 71.09%] [G loss: 0.678321]\n",
      "epoch:23 step:21607 [D loss: 0.546296, acc.: 75.00%] [G loss: 0.787849]\n",
      "epoch:23 step:21608 [D loss: 0.500076, acc.: 71.88%] [G loss: 0.637689]\n",
      "epoch:23 step:21609 [D loss: 0.533475, acc.: 71.88%] [G loss: 0.720524]\n",
      "epoch:23 step:21610 [D loss: 0.458738, acc.: 80.47%] [G loss: 0.805502]\n",
      "epoch:23 step:21611 [D loss: 0.597554, acc.: 61.72%] [G loss: 0.867307]\n",
      "epoch:23 step:21612 [D loss: 0.597497, acc.: 60.16%] [G loss: 0.745994]\n",
      "epoch:23 step:21613 [D loss: 0.512902, acc.: 75.78%] [G loss: 0.682515]\n",
      "epoch:23 step:21614 [D loss: 0.576472, acc.: 64.84%] [G loss: 0.642208]\n",
      "epoch:23 step:21615 [D loss: 0.548074, acc.: 70.31%] [G loss: 0.655217]\n",
      "epoch:23 step:21616 [D loss: 0.492813, acc.: 75.00%] [G loss: 0.760522]\n",
      "epoch:23 step:21617 [D loss: 0.543259, acc.: 71.09%] [G loss: 0.572218]\n",
      "epoch:23 step:21618 [D loss: 0.555814, acc.: 73.44%] [G loss: 0.532574]\n",
      "epoch:23 step:21619 [D loss: 0.567470, acc.: 65.62%] [G loss: 0.633932]\n",
      "epoch:23 step:21620 [D loss: 0.473718, acc.: 76.56%] [G loss: 0.702713]\n",
      "epoch:23 step:21621 [D loss: 0.542295, acc.: 68.75%] [G loss: 0.614001]\n",
      "epoch:23 step:21622 [D loss: 0.539551, acc.: 72.66%] [G loss: 0.640166]\n",
      "epoch:23 step:21623 [D loss: 0.495409, acc.: 74.22%] [G loss: 0.744395]\n",
      "epoch:23 step:21624 [D loss: 0.563811, acc.: 64.84%] [G loss: 0.601810]\n",
      "epoch:23 step:21625 [D loss: 0.470231, acc.: 75.00%] [G loss: 0.685621]\n",
      "epoch:23 step:21626 [D loss: 0.471639, acc.: 78.91%] [G loss: 0.750168]\n",
      "epoch:23 step:21627 [D loss: 0.545026, acc.: 72.66%] [G loss: 0.733809]\n",
      "epoch:23 step:21628 [D loss: 0.467203, acc.: 76.56%] [G loss: 0.894745]\n",
      "epoch:23 step:21629 [D loss: 0.604364, acc.: 68.75%] [G loss: 0.653402]\n",
      "epoch:23 step:21630 [D loss: 0.535121, acc.: 67.97%] [G loss: 0.682042]\n",
      "epoch:23 step:21631 [D loss: 0.489810, acc.: 76.56%] [G loss: 0.526587]\n",
      "epoch:23 step:21632 [D loss: 0.527079, acc.: 69.53%] [G loss: 0.619217]\n",
      "epoch:23 step:21633 [D loss: 0.565353, acc.: 60.94%] [G loss: 0.622630]\n",
      "epoch:23 step:21634 [D loss: 0.468726, acc.: 75.78%] [G loss: 0.732474]\n",
      "epoch:23 step:21635 [D loss: 0.525835, acc.: 75.00%] [G loss: 0.734194]\n",
      "epoch:23 step:21636 [D loss: 0.601091, acc.: 65.62%] [G loss: 0.687039]\n",
      "epoch:23 step:21637 [D loss: 0.538620, acc.: 71.09%] [G loss: 0.613391]\n",
      "epoch:23 step:21638 [D loss: 0.539528, acc.: 74.22%] [G loss: 0.655815]\n",
      "epoch:23 step:21639 [D loss: 0.540038, acc.: 69.53%] [G loss: 0.620787]\n",
      "epoch:23 step:21640 [D loss: 0.519070, acc.: 71.88%] [G loss: 0.558391]\n",
      "epoch:23 step:21641 [D loss: 0.528065, acc.: 71.09%] [G loss: 0.764443]\n",
      "epoch:23 step:21642 [D loss: 0.539558, acc.: 72.66%] [G loss: 0.780837]\n",
      "epoch:23 step:21643 [D loss: 0.454772, acc.: 80.47%] [G loss: 0.735953]\n",
      "epoch:23 step:21644 [D loss: 0.513982, acc.: 75.00%] [G loss: 1.056883]\n",
      "epoch:23 step:21645 [D loss: 0.490939, acc.: 75.00%] [G loss: 0.834052]\n",
      "epoch:23 step:21646 [D loss: 0.501602, acc.: 76.56%] [G loss: 0.915816]\n",
      "epoch:23 step:21647 [D loss: 0.527932, acc.: 71.88%] [G loss: 0.939024]\n",
      "epoch:23 step:21648 [D loss: 0.503872, acc.: 71.88%] [G loss: 0.694897]\n",
      "epoch:23 step:21649 [D loss: 0.544662, acc.: 67.97%] [G loss: 0.675889]\n",
      "epoch:23 step:21650 [D loss: 0.537604, acc.: 75.00%] [G loss: 0.880438]\n",
      "epoch:23 step:21651 [D loss: 0.445833, acc.: 77.34%] [G loss: 0.986452]\n",
      "epoch:23 step:21652 [D loss: 0.517716, acc.: 77.34%] [G loss: 0.924603]\n",
      "epoch:23 step:21653 [D loss: 0.662223, acc.: 62.50%] [G loss: 0.706042]\n",
      "epoch:23 step:21654 [D loss: 0.509644, acc.: 70.31%] [G loss: 0.746669]\n",
      "epoch:23 step:21655 [D loss: 0.513437, acc.: 72.66%] [G loss: 0.638130]\n",
      "epoch:23 step:21656 [D loss: 0.571683, acc.: 67.19%] [G loss: 0.563737]\n",
      "epoch:23 step:21657 [D loss: 0.547765, acc.: 70.31%] [G loss: 0.589515]\n",
      "epoch:23 step:21658 [D loss: 0.555977, acc.: 69.53%] [G loss: 0.878670]\n",
      "epoch:23 step:21659 [D loss: 0.646993, acc.: 59.38%] [G loss: 0.628512]\n",
      "epoch:23 step:21660 [D loss: 0.544815, acc.: 70.31%] [G loss: 0.680078]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:23 step:21661 [D loss: 0.545913, acc.: 67.97%] [G loss: 0.537123]\n",
      "epoch:23 step:21662 [D loss: 0.494376, acc.: 75.78%] [G loss: 0.651199]\n",
      "epoch:23 step:21663 [D loss: 0.539228, acc.: 72.66%] [G loss: 0.597969]\n",
      "epoch:23 step:21664 [D loss: 0.533681, acc.: 71.09%] [G loss: 0.680930]\n",
      "epoch:23 step:21665 [D loss: 0.484411, acc.: 78.91%] [G loss: 0.650026]\n",
      "epoch:23 step:21666 [D loss: 0.554651, acc.: 72.66%] [G loss: 0.710267]\n",
      "epoch:23 step:21667 [D loss: 0.502473, acc.: 74.22%] [G loss: 0.562195]\n",
      "epoch:23 step:21668 [D loss: 0.560523, acc.: 67.97%] [G loss: 0.674839]\n",
      "epoch:23 step:21669 [D loss: 0.524181, acc.: 71.09%] [G loss: 0.788109]\n",
      "epoch:23 step:21670 [D loss: 0.395753, acc.: 82.81%] [G loss: 0.745534]\n",
      "epoch:23 step:21671 [D loss: 0.532092, acc.: 73.44%] [G loss: 0.881253]\n",
      "epoch:23 step:21672 [D loss: 0.513561, acc.: 73.44%] [G loss: 0.662696]\n",
      "epoch:23 step:21673 [D loss: 0.479133, acc.: 78.91%] [G loss: 0.866424]\n",
      "epoch:23 step:21674 [D loss: 0.508242, acc.: 73.44%] [G loss: 0.919582]\n",
      "epoch:23 step:21675 [D loss: 0.534402, acc.: 72.66%] [G loss: 0.897079]\n",
      "epoch:23 step:21676 [D loss: 0.572207, acc.: 69.53%] [G loss: 0.744768]\n",
      "epoch:23 step:21677 [D loss: 0.529004, acc.: 71.09%] [G loss: 0.655630]\n",
      "epoch:23 step:21678 [D loss: 0.456640, acc.: 78.12%] [G loss: 0.756625]\n",
      "epoch:23 step:21679 [D loss: 0.514818, acc.: 75.00%] [G loss: 0.592241]\n",
      "epoch:23 step:21680 [D loss: 0.598619, acc.: 64.84%] [G loss: 0.662961]\n",
      "epoch:23 step:21681 [D loss: 0.520054, acc.: 69.53%] [G loss: 0.604287]\n",
      "epoch:23 step:21682 [D loss: 0.458102, acc.: 74.22%] [G loss: 0.723453]\n",
      "epoch:23 step:21683 [D loss: 0.580660, acc.: 70.31%] [G loss: 0.686791]\n",
      "epoch:23 step:21684 [D loss: 0.582947, acc.: 66.41%] [G loss: 0.727139]\n",
      "epoch:23 step:21685 [D loss: 0.529515, acc.: 71.09%] [G loss: 0.716268]\n",
      "epoch:23 step:21686 [D loss: 0.517604, acc.: 72.66%] [G loss: 0.626682]\n",
      "epoch:23 step:21687 [D loss: 0.521869, acc.: 75.00%] [G loss: 0.693551]\n",
      "epoch:23 step:21688 [D loss: 0.663078, acc.: 64.06%] [G loss: 0.791567]\n",
      "epoch:23 step:21689 [D loss: 0.573684, acc.: 64.84%] [G loss: 0.570431]\n",
      "epoch:23 step:21690 [D loss: 0.519966, acc.: 71.09%] [G loss: 0.745169]\n",
      "epoch:23 step:21691 [D loss: 0.630517, acc.: 61.72%] [G loss: 0.581720]\n",
      "epoch:23 step:21692 [D loss: 0.508638, acc.: 69.53%] [G loss: 0.558279]\n",
      "epoch:23 step:21693 [D loss: 0.568620, acc.: 65.62%] [G loss: 0.439490]\n",
      "epoch:23 step:21694 [D loss: 0.594469, acc.: 65.62%] [G loss: 0.617694]\n",
      "epoch:23 step:21695 [D loss: 0.545801, acc.: 71.09%] [G loss: 0.593782]\n",
      "epoch:23 step:21696 [D loss: 0.558778, acc.: 67.97%] [G loss: 0.672511]\n",
      "epoch:23 step:21697 [D loss: 0.483738, acc.: 78.91%] [G loss: 0.748783]\n",
      "epoch:23 step:21698 [D loss: 0.601265, acc.: 69.53%] [G loss: 0.670615]\n",
      "epoch:23 step:21699 [D loss: 0.563741, acc.: 69.53%] [G loss: 0.626279]\n",
      "epoch:23 step:21700 [D loss: 0.494617, acc.: 73.44%] [G loss: 0.595124]\n",
      "epoch:23 step:21701 [D loss: 0.586142, acc.: 67.19%] [G loss: 0.632175]\n",
      "epoch:23 step:21702 [D loss: 0.552627, acc.: 67.19%] [G loss: 0.658381]\n",
      "epoch:23 step:21703 [D loss: 0.494499, acc.: 77.34%] [G loss: 0.863110]\n",
      "epoch:23 step:21704 [D loss: 0.564630, acc.: 66.41%] [G loss: 0.787892]\n",
      "epoch:23 step:21705 [D loss: 0.575892, acc.: 67.19%] [G loss: 0.697585]\n",
      "epoch:23 step:21706 [D loss: 0.470086, acc.: 75.00%] [G loss: 0.646480]\n",
      "epoch:23 step:21707 [D loss: 0.477991, acc.: 78.12%] [G loss: 0.836725]\n",
      "epoch:23 step:21708 [D loss: 0.537049, acc.: 70.31%] [G loss: 0.577954]\n",
      "epoch:23 step:21709 [D loss: 0.615021, acc.: 63.28%] [G loss: 0.488120]\n",
      "epoch:23 step:21710 [D loss: 0.489953, acc.: 78.12%] [G loss: 0.673620]\n",
      "epoch:23 step:21711 [D loss: 0.653606, acc.: 64.84%] [G loss: 0.634268]\n",
      "epoch:23 step:21712 [D loss: 0.535404, acc.: 70.31%] [G loss: 0.666801]\n",
      "epoch:23 step:21713 [D loss: 0.464691, acc.: 76.56%] [G loss: 0.862324]\n",
      "epoch:23 step:21714 [D loss: 0.539007, acc.: 70.31%] [G loss: 0.886967]\n",
      "epoch:23 step:21715 [D loss: 0.599927, acc.: 67.97%] [G loss: 0.643027]\n",
      "epoch:23 step:21716 [D loss: 0.502929, acc.: 75.00%] [G loss: 0.667650]\n",
      "epoch:23 step:21717 [D loss: 0.560915, acc.: 67.97%] [G loss: 0.745094]\n",
      "epoch:23 step:21718 [D loss: 0.496964, acc.: 75.00%] [G loss: 0.683334]\n",
      "epoch:23 step:21719 [D loss: 0.564740, acc.: 68.75%] [G loss: 0.624105]\n",
      "epoch:23 step:21720 [D loss: 0.579116, acc.: 67.19%] [G loss: 0.528941]\n",
      "epoch:23 step:21721 [D loss: 0.512556, acc.: 70.31%] [G loss: 0.580095]\n",
      "epoch:23 step:21722 [D loss: 0.524450, acc.: 75.00%] [G loss: 0.660375]\n",
      "epoch:23 step:21723 [D loss: 0.518643, acc.: 73.44%] [G loss: 0.559216]\n",
      "epoch:23 step:21724 [D loss: 0.469668, acc.: 75.78%] [G loss: 0.660322]\n",
      "epoch:23 step:21725 [D loss: 0.598588, acc.: 62.50%] [G loss: 0.636158]\n",
      "epoch:23 step:21726 [D loss: 0.562928, acc.: 67.19%] [G loss: 0.664512]\n",
      "epoch:23 step:21727 [D loss: 0.495025, acc.: 75.78%] [G loss: 0.638513]\n",
      "epoch:23 step:21728 [D loss: 0.474461, acc.: 79.69%] [G loss: 0.673927]\n",
      "epoch:23 step:21729 [D loss: 0.605085, acc.: 64.84%] [G loss: 0.506222]\n",
      "epoch:23 step:21730 [D loss: 0.520666, acc.: 73.44%] [G loss: 0.536454]\n",
      "epoch:23 step:21731 [D loss: 0.637263, acc.: 56.25%] [G loss: 0.601336]\n",
      "epoch:23 step:21732 [D loss: 0.523570, acc.: 73.44%] [G loss: 0.581408]\n",
      "epoch:23 step:21733 [D loss: 0.567967, acc.: 73.44%] [G loss: 0.750753]\n",
      "epoch:23 step:21734 [D loss: 0.584429, acc.: 67.19%] [G loss: 0.624800]\n",
      "epoch:23 step:21735 [D loss: 0.548014, acc.: 71.09%] [G loss: 0.982941]\n",
      "epoch:23 step:21736 [D loss: 0.578987, acc.: 64.84%] [G loss: 0.646139]\n",
      "epoch:23 step:21737 [D loss: 0.521212, acc.: 73.44%] [G loss: 0.765244]\n",
      "epoch:23 step:21738 [D loss: 0.572028, acc.: 67.97%] [G loss: 0.601024]\n",
      "epoch:23 step:21739 [D loss: 0.531881, acc.: 74.22%] [G loss: 0.669736]\n",
      "epoch:23 step:21740 [D loss: 0.565754, acc.: 70.31%] [G loss: 0.499150]\n",
      "epoch:23 step:21741 [D loss: 0.471089, acc.: 81.25%] [G loss: 0.711035]\n",
      "epoch:23 step:21742 [D loss: 0.497428, acc.: 75.78%] [G loss: 0.738720]\n",
      "epoch:23 step:21743 [D loss: 0.535671, acc.: 70.31%] [G loss: 0.698342]\n",
      "epoch:23 step:21744 [D loss: 0.593221, acc.: 67.19%] [G loss: 0.673445]\n",
      "epoch:23 step:21745 [D loss: 0.452878, acc.: 80.47%] [G loss: 0.948894]\n",
      "epoch:23 step:21746 [D loss: 0.534818, acc.: 72.66%] [G loss: 0.681434]\n",
      "epoch:23 step:21747 [D loss: 0.490595, acc.: 74.22%] [G loss: 0.789332]\n",
      "epoch:23 step:21748 [D loss: 0.484398, acc.: 77.34%] [G loss: 0.745713]\n",
      "epoch:23 step:21749 [D loss: 0.460815, acc.: 77.34%] [G loss: 0.731671]\n",
      "epoch:23 step:21750 [D loss: 0.496105, acc.: 75.00%] [G loss: 0.831800]\n",
      "epoch:23 step:21751 [D loss: 0.608399, acc.: 64.06%] [G loss: 0.783948]\n",
      "epoch:23 step:21752 [D loss: 0.546934, acc.: 71.88%] [G loss: 0.571420]\n",
      "epoch:23 step:21753 [D loss: 0.499865, acc.: 73.44%] [G loss: 0.629781]\n",
      "epoch:23 step:21754 [D loss: 0.610117, acc.: 64.06%] [G loss: 0.729278]\n",
      "epoch:23 step:21755 [D loss: 0.525414, acc.: 74.22%] [G loss: 0.660837]\n",
      "epoch:23 step:21756 [D loss: 0.537224, acc.: 71.09%] [G loss: 0.777909]\n",
      "epoch:23 step:21757 [D loss: 0.527575, acc.: 71.88%] [G loss: 0.877833]\n",
      "epoch:23 step:21758 [D loss: 0.497828, acc.: 78.12%] [G loss: 0.908479]\n",
      "epoch:23 step:21759 [D loss: 0.434944, acc.: 79.69%] [G loss: 1.147353]\n",
      "epoch:23 step:21760 [D loss: 0.526188, acc.: 73.44%] [G loss: 0.912523]\n",
      "epoch:23 step:21761 [D loss: 0.665122, acc.: 57.03%] [G loss: 0.541743]\n",
      "epoch:23 step:21762 [D loss: 0.633686, acc.: 67.97%] [G loss: 0.589626]\n",
      "epoch:23 step:21763 [D loss: 0.542964, acc.: 74.22%] [G loss: 0.577484]\n",
      "epoch:23 step:21764 [D loss: 0.501137, acc.: 70.31%] [G loss: 0.807716]\n",
      "epoch:23 step:21765 [D loss: 0.601514, acc.: 68.75%] [G loss: 0.585191]\n",
      "epoch:23 step:21766 [D loss: 0.530847, acc.: 73.44%] [G loss: 0.683519]\n",
      "epoch:23 step:21767 [D loss: 0.548780, acc.: 70.31%] [G loss: 0.569674]\n",
      "epoch:23 step:21768 [D loss: 0.491013, acc.: 74.22%] [G loss: 0.633124]\n",
      "epoch:23 step:21769 [D loss: 0.515806, acc.: 69.53%] [G loss: 0.594845]\n",
      "epoch:23 step:21770 [D loss: 0.504634, acc.: 74.22%] [G loss: 0.759565]\n",
      "epoch:23 step:21771 [D loss: 0.646563, acc.: 61.72%] [G loss: 0.775712]\n",
      "epoch:23 step:21772 [D loss: 0.604082, acc.: 65.62%] [G loss: 0.602901]\n",
      "epoch:23 step:21773 [D loss: 0.506555, acc.: 75.00%] [G loss: 1.023140]\n",
      "epoch:23 step:21774 [D loss: 0.514950, acc.: 75.78%] [G loss: 0.884728]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:23 step:21775 [D loss: 0.533215, acc.: 70.31%] [G loss: 0.813675]\n",
      "epoch:23 step:21776 [D loss: 0.515032, acc.: 73.44%] [G loss: 0.707966]\n",
      "epoch:23 step:21777 [D loss: 0.580659, acc.: 65.62%] [G loss: 0.733807]\n",
      "epoch:23 step:21778 [D loss: 0.505040, acc.: 77.34%] [G loss: 0.737481]\n",
      "epoch:23 step:21779 [D loss: 0.567387, acc.: 71.88%] [G loss: 0.617676]\n",
      "epoch:23 step:21780 [D loss: 0.531650, acc.: 75.00%] [G loss: 0.608599]\n",
      "epoch:23 step:21781 [D loss: 0.525243, acc.: 74.22%] [G loss: 0.756021]\n",
      "epoch:23 step:21782 [D loss: 0.473638, acc.: 78.12%] [G loss: 0.894126]\n",
      "epoch:23 step:21783 [D loss: 0.439890, acc.: 78.91%] [G loss: 0.918788]\n",
      "epoch:23 step:21784 [D loss: 0.525668, acc.: 74.22%] [G loss: 0.923496]\n",
      "epoch:23 step:21785 [D loss: 0.550108, acc.: 72.66%] [G loss: 0.917718]\n",
      "epoch:23 step:21786 [D loss: 0.599723, acc.: 62.50%] [G loss: 0.627028]\n",
      "epoch:23 step:21787 [D loss: 0.485490, acc.: 75.78%] [G loss: 0.628423]\n",
      "epoch:23 step:21788 [D loss: 0.518396, acc.: 71.88%] [G loss: 0.767163]\n",
      "epoch:23 step:21789 [D loss: 0.539762, acc.: 72.66%] [G loss: 0.534390]\n",
      "epoch:23 step:21790 [D loss: 0.530109, acc.: 67.19%] [G loss: 0.566321]\n",
      "epoch:23 step:21791 [D loss: 0.554898, acc.: 68.75%] [G loss: 0.625417]\n",
      "epoch:23 step:21792 [D loss: 0.503463, acc.: 72.66%] [G loss: 0.659341]\n",
      "epoch:23 step:21793 [D loss: 0.475794, acc.: 76.56%] [G loss: 0.770577]\n",
      "epoch:23 step:21794 [D loss: 0.534277, acc.: 70.31%] [G loss: 0.620594]\n",
      "epoch:23 step:21795 [D loss: 0.442389, acc.: 82.81%] [G loss: 0.868431]\n",
      "epoch:23 step:21796 [D loss: 0.502740, acc.: 77.34%] [G loss: 0.673570]\n",
      "epoch:23 step:21797 [D loss: 0.500498, acc.: 75.00%] [G loss: 0.751709]\n",
      "epoch:23 step:21798 [D loss: 0.556132, acc.: 70.31%] [G loss: 0.679255]\n",
      "epoch:23 step:21799 [D loss: 0.483106, acc.: 76.56%] [G loss: 0.832428]\n",
      "epoch:23 step:21800 [D loss: 0.571401, acc.: 70.31%] [G loss: 0.712853]\n",
      "##############\n",
      "[3.35463646 1.34192702 6.11393423 4.5858855  3.6557732  5.69776289\n",
      " 4.6348844  4.93363081 4.75579272 4.19382043]\n",
      "##########\n",
      "epoch:23 step:21801 [D loss: 0.591604, acc.: 64.06%] [G loss: 0.586713]\n",
      "epoch:23 step:21802 [D loss: 0.629104, acc.: 65.62%] [G loss: 0.791768]\n",
      "epoch:23 step:21803 [D loss: 0.548413, acc.: 67.19%] [G loss: 0.875859]\n",
      "epoch:23 step:21804 [D loss: 0.585192, acc.: 66.41%] [G loss: 0.626054]\n",
      "epoch:23 step:21805 [D loss: 0.510256, acc.: 73.44%] [G loss: 0.617274]\n",
      "epoch:23 step:21806 [D loss: 0.538410, acc.: 71.88%] [G loss: 0.808471]\n",
      "epoch:23 step:21807 [D loss: 0.550765, acc.: 68.75%] [G loss: 0.629256]\n",
      "epoch:23 step:21808 [D loss: 0.614895, acc.: 58.59%] [G loss: 0.681657]\n",
      "epoch:23 step:21809 [D loss: 0.525405, acc.: 71.88%] [G loss: 0.614654]\n",
      "epoch:23 step:21810 [D loss: 0.532389, acc.: 71.09%] [G loss: 0.793546]\n",
      "epoch:23 step:21811 [D loss: 0.569451, acc.: 65.62%] [G loss: 0.873092]\n",
      "epoch:23 step:21812 [D loss: 0.517693, acc.: 74.22%] [G loss: 0.694965]\n",
      "epoch:23 step:21813 [D loss: 0.531498, acc.: 69.53%] [G loss: 0.566600]\n",
      "epoch:23 step:21814 [D loss: 0.582026, acc.: 70.31%] [G loss: 0.647893]\n",
      "epoch:23 step:21815 [D loss: 0.566316, acc.: 71.09%] [G loss: 0.665656]\n",
      "epoch:23 step:21816 [D loss: 0.523383, acc.: 67.19%] [G loss: 0.736428]\n",
      "epoch:23 step:21817 [D loss: 0.546867, acc.: 71.09%] [G loss: 0.674575]\n",
      "epoch:23 step:21818 [D loss: 0.583539, acc.: 70.31%] [G loss: 0.565645]\n",
      "epoch:23 step:21819 [D loss: 0.528199, acc.: 71.88%] [G loss: 0.686587]\n",
      "epoch:23 step:21820 [D loss: 0.518866, acc.: 74.22%] [G loss: 0.565992]\n",
      "epoch:23 step:21821 [D loss: 0.504139, acc.: 76.56%] [G loss: 0.702218]\n",
      "epoch:23 step:21822 [D loss: 0.501337, acc.: 74.22%] [G loss: 0.794761]\n",
      "epoch:23 step:21823 [D loss: 0.547954, acc.: 69.53%] [G loss: 0.682111]\n",
      "epoch:23 step:21824 [D loss: 0.513397, acc.: 71.88%] [G loss: 0.543470]\n",
      "epoch:23 step:21825 [D loss: 0.468470, acc.: 78.12%] [G loss: 0.718966]\n",
      "epoch:23 step:21826 [D loss: 0.523643, acc.: 71.88%] [G loss: 0.648857]\n",
      "epoch:23 step:21827 [D loss: 0.464643, acc.: 78.91%] [G loss: 0.790030]\n",
      "epoch:23 step:21828 [D loss: 0.671924, acc.: 62.50%] [G loss: 0.435352]\n",
      "epoch:23 step:21829 [D loss: 0.666652, acc.: 62.50%] [G loss: 0.437541]\n",
      "epoch:23 step:21830 [D loss: 0.528173, acc.: 66.41%] [G loss: 0.604279]\n",
      "epoch:23 step:21831 [D loss: 0.555042, acc.: 67.97%] [G loss: 0.663692]\n",
      "epoch:23 step:21832 [D loss: 0.551209, acc.: 67.19%] [G loss: 0.683211]\n",
      "epoch:23 step:21833 [D loss: 0.557014, acc.: 70.31%] [G loss: 0.515971]\n",
      "epoch:23 step:21834 [D loss: 0.513703, acc.: 74.22%] [G loss: 0.700553]\n",
      "epoch:23 step:21835 [D loss: 0.484693, acc.: 75.00%] [G loss: 0.725445]\n",
      "epoch:23 step:21836 [D loss: 0.513617, acc.: 74.22%] [G loss: 0.625018]\n",
      "epoch:23 step:21837 [D loss: 0.530042, acc.: 71.09%] [G loss: 0.706713]\n",
      "epoch:23 step:21838 [D loss: 0.554415, acc.: 71.88%] [G loss: 0.759109]\n",
      "epoch:23 step:21839 [D loss: 0.558283, acc.: 71.88%] [G loss: 0.713367]\n",
      "epoch:23 step:21840 [D loss: 0.548397, acc.: 72.66%] [G loss: 0.509539]\n",
      "epoch:23 step:21841 [D loss: 0.560775, acc.: 70.31%] [G loss: 0.590090]\n",
      "epoch:23 step:21842 [D loss: 0.613734, acc.: 67.97%] [G loss: 0.564159]\n",
      "epoch:23 step:21843 [D loss: 0.526839, acc.: 74.22%] [G loss: 0.616734]\n",
      "epoch:23 step:21844 [D loss: 0.589138, acc.: 67.19%] [G loss: 0.604108]\n",
      "epoch:23 step:21845 [D loss: 0.561658, acc.: 69.53%] [G loss: 0.700005]\n",
      "epoch:23 step:21846 [D loss: 0.552122, acc.: 71.88%] [G loss: 0.625619]\n",
      "epoch:23 step:21847 [D loss: 0.565282, acc.: 63.28%] [G loss: 0.462633]\n",
      "epoch:23 step:21848 [D loss: 0.544455, acc.: 70.31%] [G loss: 0.489869]\n",
      "epoch:23 step:21849 [D loss: 0.470265, acc.: 75.78%] [G loss: 0.618228]\n",
      "epoch:23 step:21850 [D loss: 0.464024, acc.: 80.47%] [G loss: 0.680903]\n",
      "epoch:23 step:21851 [D loss: 0.489404, acc.: 75.78%] [G loss: 0.700355]\n",
      "epoch:23 step:21852 [D loss: 0.614443, acc.: 66.41%] [G loss: 0.642506]\n",
      "epoch:23 step:21853 [D loss: 0.537602, acc.: 71.09%] [G loss: 0.536173]\n",
      "epoch:23 step:21854 [D loss: 0.575322, acc.: 67.19%] [G loss: 0.541298]\n",
      "epoch:23 step:21855 [D loss: 0.475080, acc.: 82.03%] [G loss: 0.813992]\n",
      "epoch:23 step:21856 [D loss: 0.474197, acc.: 76.56%] [G loss: 0.734093]\n",
      "epoch:23 step:21857 [D loss: 0.475236, acc.: 74.22%] [G loss: 0.899470]\n",
      "epoch:23 step:21858 [D loss: 0.483699, acc.: 75.78%] [G loss: 0.780967]\n",
      "epoch:23 step:21859 [D loss: 0.602394, acc.: 65.62%] [G loss: 0.738999]\n",
      "epoch:23 step:21860 [D loss: 0.508331, acc.: 75.00%] [G loss: 0.727681]\n",
      "epoch:23 step:21861 [D loss: 0.563787, acc.: 67.97%] [G loss: 0.699732]\n",
      "epoch:23 step:21862 [D loss: 0.542691, acc.: 67.97%] [G loss: 0.640023]\n",
      "epoch:23 step:21863 [D loss: 0.472409, acc.: 75.00%] [G loss: 0.927121]\n",
      "epoch:23 step:21864 [D loss: 0.486841, acc.: 77.34%] [G loss: 0.985740]\n",
      "epoch:23 step:21865 [D loss: 0.435513, acc.: 78.91%] [G loss: 0.870823]\n",
      "epoch:23 step:21866 [D loss: 0.445736, acc.: 82.03%] [G loss: 1.075409]\n",
      "epoch:23 step:21867 [D loss: 0.720897, acc.: 61.72%] [G loss: 0.669268]\n",
      "epoch:23 step:21868 [D loss: 0.564725, acc.: 70.31%] [G loss: 0.616251]\n",
      "epoch:23 step:21869 [D loss: 0.510447, acc.: 72.66%] [G loss: 0.596135]\n",
      "epoch:23 step:21870 [D loss: 0.553533, acc.: 71.09%] [G loss: 0.569768]\n",
      "epoch:23 step:21871 [D loss: 0.559854, acc.: 67.19%] [G loss: 0.731263]\n",
      "epoch:23 step:21872 [D loss: 0.480141, acc.: 82.03%] [G loss: 0.770613]\n",
      "epoch:23 step:21873 [D loss: 0.557061, acc.: 67.19%] [G loss: 0.772466]\n",
      "epoch:23 step:21874 [D loss: 0.542618, acc.: 66.41%] [G loss: 0.714075]\n",
      "epoch:23 step:21875 [D loss: 0.517871, acc.: 74.22%] [G loss: 0.778687]\n",
      "epoch:23 step:21876 [D loss: 0.594210, acc.: 66.41%] [G loss: 0.481179]\n",
      "epoch:23 step:21877 [D loss: 0.459174, acc.: 79.69%] [G loss: 0.559927]\n",
      "epoch:23 step:21878 [D loss: 0.563918, acc.: 68.75%] [G loss: 0.760362]\n",
      "epoch:23 step:21879 [D loss: 0.464365, acc.: 77.34%] [G loss: 0.794698]\n",
      "epoch:23 step:21880 [D loss: 0.517441, acc.: 72.66%] [G loss: 0.843032]\n",
      "epoch:23 step:21881 [D loss: 0.590296, acc.: 67.19%] [G loss: 0.568010]\n",
      "epoch:23 step:21882 [D loss: 0.547075, acc.: 70.31%] [G loss: 0.578166]\n",
      "epoch:23 step:21883 [D loss: 0.506246, acc.: 71.88%] [G loss: 0.525273]\n",
      "epoch:23 step:21884 [D loss: 0.484056, acc.: 76.56%] [G loss: 0.631852]\n",
      "epoch:23 step:21885 [D loss: 0.469631, acc.: 75.78%] [G loss: 0.845420]\n",
      "epoch:23 step:21886 [D loss: 0.478849, acc.: 78.12%] [G loss: 0.854584]\n",
      "epoch:23 step:21887 [D loss: 0.503575, acc.: 75.78%] [G loss: 0.747613]\n",
      "epoch:23 step:21888 [D loss: 0.521374, acc.: 72.66%] [G loss: 0.814337]\n",
      "epoch:23 step:21889 [D loss: 0.546113, acc.: 68.75%] [G loss: 0.731081]\n",
      "epoch:23 step:21890 [D loss: 0.580529, acc.: 68.75%] [G loss: 0.724144]\n",
      "epoch:23 step:21891 [D loss: 0.512308, acc.: 71.09%] [G loss: 0.777616]\n",
      "epoch:23 step:21892 [D loss: 0.551278, acc.: 77.34%] [G loss: 0.728202]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:23 step:21893 [D loss: 0.611476, acc.: 64.84%] [G loss: 0.828963]\n",
      "epoch:23 step:21894 [D loss: 0.528277, acc.: 69.53%] [G loss: 0.636462]\n",
      "epoch:23 step:21895 [D loss: 0.495468, acc.: 75.78%] [G loss: 0.840221]\n",
      "epoch:23 step:21896 [D loss: 0.550295, acc.: 65.62%] [G loss: 0.852292]\n",
      "epoch:23 step:21897 [D loss: 0.480972, acc.: 75.78%] [G loss: 0.782836]\n",
      "epoch:23 step:21898 [D loss: 0.464824, acc.: 75.00%] [G loss: 0.971097]\n",
      "epoch:23 step:21899 [D loss: 0.607975, acc.: 65.62%] [G loss: 0.778482]\n",
      "epoch:23 step:21900 [D loss: 0.685275, acc.: 62.50%] [G loss: 0.634521]\n",
      "epoch:23 step:21901 [D loss: 0.468657, acc.: 76.56%] [G loss: 0.571203]\n",
      "epoch:23 step:21902 [D loss: 0.522899, acc.: 74.22%] [G loss: 0.784464]\n",
      "epoch:23 step:21903 [D loss: 0.590659, acc.: 67.19%] [G loss: 0.638355]\n",
      "epoch:23 step:21904 [D loss: 0.548182, acc.: 70.31%] [G loss: 0.616888]\n",
      "epoch:23 step:21905 [D loss: 0.369740, acc.: 84.38%] [G loss: 0.848539]\n",
      "epoch:23 step:21906 [D loss: 0.540501, acc.: 71.88%] [G loss: 0.892233]\n",
      "epoch:23 step:21907 [D loss: 0.575927, acc.: 67.19%] [G loss: 0.621158]\n",
      "epoch:23 step:21908 [D loss: 0.456958, acc.: 78.91%] [G loss: 0.838590]\n",
      "epoch:23 step:21909 [D loss: 0.455509, acc.: 75.78%] [G loss: 0.791567]\n",
      "epoch:23 step:21910 [D loss: 0.486249, acc.: 76.56%] [G loss: 0.930643]\n",
      "epoch:23 step:21911 [D loss: 0.490874, acc.: 78.12%] [G loss: 0.938121]\n",
      "epoch:23 step:21912 [D loss: 0.500438, acc.: 73.44%] [G loss: 0.862991]\n",
      "epoch:23 step:21913 [D loss: 0.509033, acc.: 71.09%] [G loss: 0.827351]\n",
      "epoch:23 step:21914 [D loss: 0.547918, acc.: 71.09%] [G loss: 0.686916]\n",
      "epoch:23 step:21915 [D loss: 0.575958, acc.: 68.75%] [G loss: 0.771364]\n",
      "epoch:23 step:21916 [D loss: 0.600366, acc.: 64.84%] [G loss: 0.641153]\n",
      "epoch:23 step:21917 [D loss: 0.562310, acc.: 64.06%] [G loss: 0.770800]\n",
      "epoch:23 step:21918 [D loss: 0.560744, acc.: 68.75%] [G loss: 0.727749]\n",
      "epoch:23 step:21919 [D loss: 0.546028, acc.: 67.97%] [G loss: 0.731738]\n",
      "epoch:23 step:21920 [D loss: 0.497813, acc.: 71.09%] [G loss: 0.781384]\n",
      "epoch:23 step:21921 [D loss: 0.530602, acc.: 71.09%] [G loss: 0.784415]\n",
      "epoch:23 step:21922 [D loss: 0.488344, acc.: 80.47%] [G loss: 0.802354]\n",
      "epoch:23 step:21923 [D loss: 0.539099, acc.: 67.19%] [G loss: 0.644138]\n",
      "epoch:23 step:21924 [D loss: 0.542265, acc.: 70.31%] [G loss: 0.764546]\n",
      "epoch:23 step:21925 [D loss: 0.405549, acc.: 80.47%] [G loss: 0.980204]\n",
      "epoch:23 step:21926 [D loss: 0.626460, acc.: 62.50%] [G loss: 0.620206]\n",
      "epoch:23 step:21927 [D loss: 0.702842, acc.: 57.03%] [G loss: 0.494217]\n",
      "epoch:23 step:21928 [D loss: 0.537715, acc.: 67.97%] [G loss: 0.721908]\n",
      "epoch:23 step:21929 [D loss: 0.521793, acc.: 74.22%] [G loss: 0.775541]\n",
      "epoch:23 step:21930 [D loss: 0.561736, acc.: 71.88%] [G loss: 0.576864]\n",
      "epoch:23 step:21931 [D loss: 0.600974, acc.: 67.19%] [G loss: 0.514226]\n",
      "epoch:23 step:21932 [D loss: 0.472116, acc.: 74.22%] [G loss: 0.654235]\n",
      "epoch:23 step:21933 [D loss: 0.527976, acc.: 72.66%] [G loss: 0.714139]\n",
      "epoch:23 step:21934 [D loss: 0.516257, acc.: 72.66%] [G loss: 0.620780]\n",
      "epoch:23 step:21935 [D loss: 0.550104, acc.: 71.88%] [G loss: 0.608230]\n",
      "epoch:23 step:21936 [D loss: 0.462827, acc.: 79.69%] [G loss: 0.762392]\n",
      "epoch:23 step:21937 [D loss: 0.550762, acc.: 71.09%] [G loss: 0.636797]\n",
      "epoch:23 step:21938 [D loss: 0.583959, acc.: 67.97%] [G loss: 0.707326]\n",
      "epoch:23 step:21939 [D loss: 0.502935, acc.: 74.22%] [G loss: 0.698095]\n",
      "epoch:23 step:21940 [D loss: 0.526491, acc.: 73.44%] [G loss: 0.878950]\n",
      "epoch:23 step:21941 [D loss: 0.547079, acc.: 73.44%] [G loss: 0.721434]\n",
      "epoch:23 step:21942 [D loss: 0.553667, acc.: 68.75%] [G loss: 0.598424]\n",
      "epoch:23 step:21943 [D loss: 0.471369, acc.: 76.56%] [G loss: 0.893918]\n",
      "epoch:23 step:21944 [D loss: 0.584913, acc.: 65.62%] [G loss: 0.568066]\n",
      "epoch:23 step:21945 [D loss: 0.598598, acc.: 69.53%] [G loss: 0.586556]\n",
      "epoch:23 step:21946 [D loss: 0.518631, acc.: 73.44%] [G loss: 0.627822]\n",
      "epoch:23 step:21947 [D loss: 0.581327, acc.: 69.53%] [G loss: 0.589353]\n",
      "epoch:23 step:21948 [D loss: 0.625030, acc.: 60.16%] [G loss: 0.826156]\n",
      "epoch:23 step:21949 [D loss: 0.495510, acc.: 71.88%] [G loss: 0.749271]\n",
      "epoch:23 step:21950 [D loss: 0.514158, acc.: 72.66%] [G loss: 0.741870]\n",
      "epoch:23 step:21951 [D loss: 0.633245, acc.: 62.50%] [G loss: 0.659769]\n",
      "epoch:23 step:21952 [D loss: 0.647721, acc.: 57.03%] [G loss: 0.466093]\n",
      "epoch:23 step:21953 [D loss: 0.497255, acc.: 77.34%] [G loss: 0.669661]\n",
      "epoch:23 step:21954 [D loss: 0.506900, acc.: 71.88%] [G loss: 0.590013]\n",
      "epoch:23 step:21955 [D loss: 0.581963, acc.: 69.53%] [G loss: 0.849791]\n",
      "epoch:23 step:21956 [D loss: 0.562878, acc.: 69.53%] [G loss: 0.900083]\n",
      "epoch:23 step:21957 [D loss: 0.482302, acc.: 73.44%] [G loss: 0.839724]\n",
      "epoch:23 step:21958 [D loss: 0.616014, acc.: 60.94%] [G loss: 0.799673]\n",
      "epoch:23 step:21959 [D loss: 0.579251, acc.: 68.75%] [G loss: 0.659819]\n",
      "epoch:23 step:21960 [D loss: 0.562590, acc.: 69.53%] [G loss: 0.777113]\n",
      "epoch:23 step:21961 [D loss: 0.571957, acc.: 64.06%] [G loss: 0.714623]\n",
      "epoch:23 step:21962 [D loss: 0.608231, acc.: 60.94%] [G loss: 0.570697]\n",
      "epoch:23 step:21963 [D loss: 0.586579, acc.: 65.62%] [G loss: 0.501108]\n",
      "epoch:23 step:21964 [D loss: 0.548420, acc.: 75.00%] [G loss: 0.742135]\n",
      "epoch:23 step:21965 [D loss: 0.492015, acc.: 75.78%] [G loss: 0.702328]\n",
      "epoch:23 step:21966 [D loss: 0.572833, acc.: 65.62%] [G loss: 0.743323]\n",
      "epoch:23 step:21967 [D loss: 0.475747, acc.: 77.34%] [G loss: 0.984254]\n",
      "epoch:23 step:21968 [D loss: 0.552195, acc.: 70.31%] [G loss: 0.761165]\n",
      "epoch:23 step:21969 [D loss: 0.593975, acc.: 71.09%] [G loss: 0.624246]\n",
      "epoch:23 step:21970 [D loss: 0.599074, acc.: 62.50%] [G loss: 0.732095]\n",
      "epoch:23 step:21971 [D loss: 0.577470, acc.: 64.06%] [G loss: 0.808525]\n",
      "epoch:23 step:21972 [D loss: 0.514418, acc.: 74.22%] [G loss: 0.785870]\n",
      "epoch:23 step:21973 [D loss: 0.625277, acc.: 67.97%] [G loss: 0.599470]\n",
      "epoch:23 step:21974 [D loss: 0.520498, acc.: 71.88%] [G loss: 0.687289]\n",
      "epoch:23 step:21975 [D loss: 0.549704, acc.: 71.09%] [G loss: 0.683293]\n",
      "epoch:23 step:21976 [D loss: 0.523589, acc.: 72.66%] [G loss: 0.708698]\n",
      "epoch:23 step:21977 [D loss: 0.447735, acc.: 75.78%] [G loss: 0.911946]\n",
      "epoch:23 step:21978 [D loss: 0.464811, acc.: 79.69%] [G loss: 0.772876]\n",
      "epoch:23 step:21979 [D loss: 0.512254, acc.: 72.66%] [G loss: 0.944010]\n",
      "epoch:23 step:21980 [D loss: 0.472301, acc.: 78.12%] [G loss: 0.963565]\n",
      "epoch:23 step:21981 [D loss: 0.532496, acc.: 71.09%] [G loss: 0.885289]\n",
      "epoch:23 step:21982 [D loss: 0.520787, acc.: 67.19%] [G loss: 0.818708]\n",
      "epoch:23 step:21983 [D loss: 0.590424, acc.: 64.06%] [G loss: 0.807708]\n",
      "epoch:23 step:21984 [D loss: 0.568915, acc.: 75.00%] [G loss: 0.715014]\n",
      "epoch:23 step:21985 [D loss: 0.576966, acc.: 66.41%] [G loss: 0.717957]\n",
      "epoch:23 step:21986 [D loss: 0.495204, acc.: 75.78%] [G loss: 0.745189]\n",
      "epoch:23 step:21987 [D loss: 0.543995, acc.: 67.97%] [G loss: 0.700123]\n",
      "epoch:23 step:21988 [D loss: 0.658288, acc.: 64.06%] [G loss: 0.803079]\n",
      "epoch:23 step:21989 [D loss: 0.516171, acc.: 71.09%] [G loss: 0.703775]\n",
      "epoch:23 step:21990 [D loss: 0.476130, acc.: 75.00%] [G loss: 0.846084]\n",
      "epoch:23 step:21991 [D loss: 0.505637, acc.: 72.66%] [G loss: 0.927163]\n",
      "epoch:23 step:21992 [D loss: 0.537613, acc.: 70.31%] [G loss: 0.796002]\n",
      "epoch:23 step:21993 [D loss: 0.562762, acc.: 69.53%] [G loss: 0.817170]\n",
      "epoch:23 step:21994 [D loss: 0.504458, acc.: 78.12%] [G loss: 0.738899]\n",
      "epoch:23 step:21995 [D loss: 0.508783, acc.: 75.00%] [G loss: 0.833858]\n",
      "epoch:23 step:21996 [D loss: 0.555718, acc.: 72.66%] [G loss: 0.761922]\n",
      "epoch:23 step:21997 [D loss: 0.518143, acc.: 73.44%] [G loss: 0.801178]\n",
      "epoch:23 step:21998 [D loss: 0.567488, acc.: 71.09%] [G loss: 0.864132]\n",
      "epoch:23 step:21999 [D loss: 0.542252, acc.: 65.62%] [G loss: 0.953004]\n",
      "epoch:23 step:22000 [D loss: 0.484218, acc.: 77.34%] [G loss: 0.798765]\n",
      "##############\n",
      "[2.8706419  1.41906081 5.94114776 4.98008574 4.00362891 5.49302648\n",
      " 4.40099991 5.03989695 4.76796044 4.05611962]\n",
      "##########\n",
      "epoch:23 step:22001 [D loss: 0.485294, acc.: 72.66%] [G loss: 0.753726]\n",
      "epoch:23 step:22002 [D loss: 0.434755, acc.: 76.56%] [G loss: 0.998685]\n",
      "epoch:23 step:22003 [D loss: 0.461149, acc.: 77.34%] [G loss: 0.844025]\n",
      "epoch:23 step:22004 [D loss: 0.539630, acc.: 71.09%] [G loss: 0.808967]\n",
      "epoch:23 step:22005 [D loss: 0.525575, acc.: 71.88%] [G loss: 0.834867]\n",
      "epoch:23 step:22006 [D loss: 0.593185, acc.: 68.75%] [G loss: 0.590418]\n",
      "epoch:23 step:22007 [D loss: 0.553268, acc.: 73.44%] [G loss: 0.879426]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:23 step:22008 [D loss: 0.464382, acc.: 79.69%] [G loss: 0.724259]\n",
      "epoch:23 step:22009 [D loss: 0.678378, acc.: 63.28%] [G loss: 0.685114]\n",
      "epoch:23 step:22010 [D loss: 0.485921, acc.: 79.69%] [G loss: 0.725995]\n",
      "epoch:23 step:22011 [D loss: 0.508211, acc.: 76.56%] [G loss: 0.727442]\n",
      "epoch:23 step:22012 [D loss: 0.523254, acc.: 71.09%] [G loss: 0.818452]\n",
      "epoch:23 step:22013 [D loss: 0.612334, acc.: 64.84%] [G loss: 0.779021]\n",
      "epoch:23 step:22014 [D loss: 0.533768, acc.: 69.53%] [G loss: 0.623573]\n",
      "epoch:23 step:22015 [D loss: 0.531785, acc.: 70.31%] [G loss: 0.687566]\n",
      "epoch:23 step:22016 [D loss: 0.593015, acc.: 69.53%] [G loss: 0.554274]\n",
      "epoch:23 step:22017 [D loss: 0.576592, acc.: 60.16%] [G loss: 0.656049]\n",
      "epoch:23 step:22018 [D loss: 0.529997, acc.: 71.88%] [G loss: 0.638960]\n",
      "epoch:23 step:22019 [D loss: 0.602501, acc.: 63.28%] [G loss: 0.596291]\n",
      "epoch:23 step:22020 [D loss: 0.502453, acc.: 73.44%] [G loss: 0.868557]\n",
      "epoch:23 step:22021 [D loss: 0.531717, acc.: 74.22%] [G loss: 0.704735]\n",
      "epoch:23 step:22022 [D loss: 0.441632, acc.: 78.12%] [G loss: 0.813228]\n",
      "epoch:23 step:22023 [D loss: 0.450875, acc.: 77.34%] [G loss: 0.706692]\n",
      "epoch:23 step:22024 [D loss: 0.611540, acc.: 61.72%] [G loss: 0.737821]\n",
      "epoch:23 step:22025 [D loss: 0.566091, acc.: 64.06%] [G loss: 0.566744]\n",
      "epoch:23 step:22026 [D loss: 0.473808, acc.: 75.00%] [G loss: 0.894122]\n",
      "epoch:23 step:22027 [D loss: 0.522657, acc.: 72.66%] [G loss: 0.758384]\n",
      "epoch:23 step:22028 [D loss: 0.627870, acc.: 63.28%] [G loss: 0.707027]\n",
      "epoch:23 step:22029 [D loss: 0.597414, acc.: 66.41%] [G loss: 0.539309]\n",
      "epoch:23 step:22030 [D loss: 0.453123, acc.: 79.69%] [G loss: 0.772972]\n",
      "epoch:23 step:22031 [D loss: 0.622203, acc.: 64.06%] [G loss: 0.548051]\n",
      "epoch:23 step:22032 [D loss: 0.462755, acc.: 81.25%] [G loss: 0.745643]\n",
      "epoch:23 step:22033 [D loss: 0.661582, acc.: 60.16%] [G loss: 0.529379]\n",
      "epoch:23 step:22034 [D loss: 0.485355, acc.: 77.34%] [G loss: 0.661084]\n",
      "epoch:23 step:22035 [D loss: 0.473219, acc.: 77.34%] [G loss: 0.653848]\n",
      "epoch:23 step:22036 [D loss: 0.509454, acc.: 67.97%] [G loss: 0.738090]\n",
      "epoch:23 step:22037 [D loss: 0.545468, acc.: 64.06%] [G loss: 0.708534]\n",
      "epoch:23 step:22038 [D loss: 0.583767, acc.: 67.19%] [G loss: 0.550284]\n",
      "epoch:23 step:22039 [D loss: 0.465034, acc.: 75.78%] [G loss: 0.756881]\n",
      "epoch:23 step:22040 [D loss: 0.514763, acc.: 70.31%] [G loss: 0.717454]\n",
      "epoch:23 step:22041 [D loss: 0.558302, acc.: 70.31%] [G loss: 0.788422]\n",
      "epoch:23 step:22042 [D loss: 0.542542, acc.: 70.31%] [G loss: 0.795504]\n",
      "epoch:23 step:22043 [D loss: 0.605931, acc.: 67.97%] [G loss: 0.710570]\n",
      "epoch:23 step:22044 [D loss: 0.532481, acc.: 72.66%] [G loss: 0.519223]\n",
      "epoch:23 step:22045 [D loss: 0.577447, acc.: 66.41%] [G loss: 0.646866]\n",
      "epoch:23 step:22046 [D loss: 0.504996, acc.: 71.09%] [G loss: 0.652218]\n",
      "epoch:23 step:22047 [D loss: 0.539157, acc.: 72.66%] [G loss: 0.617441]\n",
      "epoch:23 step:22048 [D loss: 0.552355, acc.: 73.44%] [G loss: 0.691787]\n",
      "epoch:23 step:22049 [D loss: 0.551693, acc.: 68.75%] [G loss: 0.599414]\n",
      "epoch:23 step:22050 [D loss: 0.500720, acc.: 76.56%] [G loss: 0.741975]\n",
      "epoch:23 step:22051 [D loss: 0.545973, acc.: 68.75%] [G loss: 0.736680]\n",
      "epoch:23 step:22052 [D loss: 0.648852, acc.: 65.62%] [G loss: 0.477153]\n",
      "epoch:23 step:22053 [D loss: 0.653981, acc.: 62.50%] [G loss: 0.554371]\n",
      "epoch:23 step:22054 [D loss: 0.540486, acc.: 70.31%] [G loss: 0.574114]\n",
      "epoch:23 step:22055 [D loss: 0.483194, acc.: 77.34%] [G loss: 0.684215]\n",
      "epoch:23 step:22056 [D loss: 0.493977, acc.: 78.12%] [G loss: 0.721130]\n",
      "epoch:23 step:22057 [D loss: 0.511483, acc.: 72.66%] [G loss: 0.808571]\n",
      "epoch:23 step:22058 [D loss: 0.519963, acc.: 76.56%] [G loss: 0.989447]\n",
      "epoch:23 step:22059 [D loss: 0.437314, acc.: 78.12%] [G loss: 0.968351]\n",
      "epoch:23 step:22060 [D loss: 0.476667, acc.: 76.56%] [G loss: 0.900224]\n",
      "epoch:23 step:22061 [D loss: 0.653622, acc.: 65.62%] [G loss: 0.586721]\n",
      "epoch:23 step:22062 [D loss: 0.632582, acc.: 63.28%] [G loss: 0.648800]\n",
      "epoch:23 step:22063 [D loss: 0.601009, acc.: 62.50%] [G loss: 0.484633]\n",
      "epoch:23 step:22064 [D loss: 0.509676, acc.: 74.22%] [G loss: 0.588407]\n",
      "epoch:23 step:22065 [D loss: 0.510831, acc.: 71.88%] [G loss: 0.632075]\n",
      "epoch:23 step:22066 [D loss: 0.521832, acc.: 72.66%] [G loss: 0.686149]\n",
      "epoch:23 step:22067 [D loss: 0.506475, acc.: 74.22%] [G loss: 0.813802]\n",
      "epoch:23 step:22068 [D loss: 0.516614, acc.: 74.22%] [G loss: 0.717337]\n",
      "epoch:23 step:22069 [D loss: 0.514458, acc.: 75.00%] [G loss: 0.777252]\n",
      "epoch:23 step:22070 [D loss: 0.423412, acc.: 82.03%] [G loss: 0.878257]\n",
      "epoch:23 step:22071 [D loss: 0.529409, acc.: 69.53%] [G loss: 0.718294]\n",
      "epoch:23 step:22072 [D loss: 0.535622, acc.: 72.66%] [G loss: 0.850290]\n",
      "epoch:23 step:22073 [D loss: 0.514454, acc.: 72.66%] [G loss: 0.774393]\n",
      "epoch:23 step:22074 [D loss: 0.466733, acc.: 75.78%] [G loss: 0.850751]\n",
      "epoch:23 step:22075 [D loss: 0.553559, acc.: 70.31%] [G loss: 0.772995]\n",
      "epoch:23 step:22076 [D loss: 0.555403, acc.: 74.22%] [G loss: 0.645870]\n",
      "epoch:23 step:22077 [D loss: 0.491136, acc.: 75.78%] [G loss: 0.659852]\n",
      "epoch:23 step:22078 [D loss: 0.535150, acc.: 67.97%] [G loss: 0.631404]\n",
      "epoch:23 step:22079 [D loss: 0.660962, acc.: 60.94%] [G loss: 0.609539]\n",
      "epoch:23 step:22080 [D loss: 0.584173, acc.: 71.88%] [G loss: 0.559826]\n",
      "epoch:23 step:22081 [D loss: 0.509244, acc.: 71.88%] [G loss: 0.820434]\n",
      "epoch:23 step:22082 [D loss: 0.593456, acc.: 67.97%] [G loss: 0.721414]\n",
      "epoch:23 step:22083 [D loss: 0.556560, acc.: 70.31%] [G loss: 0.864518]\n",
      "epoch:23 step:22084 [D loss: 0.525065, acc.: 71.09%] [G loss: 0.725184]\n",
      "epoch:23 step:22085 [D loss: 0.475526, acc.: 77.34%] [G loss: 0.736184]\n",
      "epoch:23 step:22086 [D loss: 0.605322, acc.: 65.62%] [G loss: 0.540206]\n",
      "epoch:23 step:22087 [D loss: 0.528301, acc.: 70.31%] [G loss: 0.392166]\n",
      "epoch:23 step:22088 [D loss: 0.567924, acc.: 68.75%] [G loss: 0.750212]\n",
      "epoch:23 step:22089 [D loss: 0.590460, acc.: 67.97%] [G loss: 0.607014]\n",
      "epoch:23 step:22090 [D loss: 0.547014, acc.: 72.66%] [G loss: 0.636775]\n",
      "epoch:23 step:22091 [D loss: 0.524840, acc.: 71.88%] [G loss: 0.649714]\n",
      "epoch:23 step:22092 [D loss: 0.560532, acc.: 66.41%] [G loss: 0.683115]\n",
      "epoch:23 step:22093 [D loss: 0.611439, acc.: 60.94%] [G loss: 0.557041]\n",
      "epoch:23 step:22094 [D loss: 0.568600, acc.: 67.97%] [G loss: 0.654226]\n",
      "epoch:23 step:22095 [D loss: 0.559183, acc.: 73.44%] [G loss: 0.566980]\n",
      "epoch:23 step:22096 [D loss: 0.487196, acc.: 75.78%] [G loss: 0.650929]\n",
      "epoch:23 step:22097 [D loss: 0.464222, acc.: 77.34%] [G loss: 0.786272]\n",
      "epoch:23 step:22098 [D loss: 0.566456, acc.: 72.66%] [G loss: 0.707254]\n",
      "epoch:23 step:22099 [D loss: 0.473028, acc.: 75.00%] [G loss: 0.756883]\n",
      "epoch:23 step:22100 [D loss: 0.531649, acc.: 76.56%] [G loss: 0.934009]\n",
      "epoch:23 step:22101 [D loss: 0.517592, acc.: 76.56%] [G loss: 0.852289]\n",
      "epoch:23 step:22102 [D loss: 0.504128, acc.: 74.22%] [G loss: 0.672766]\n",
      "epoch:23 step:22103 [D loss: 0.447663, acc.: 78.91%] [G loss: 0.814280]\n",
      "epoch:23 step:22104 [D loss: 0.584017, acc.: 63.28%] [G loss: 0.742628]\n",
      "epoch:23 step:22105 [D loss: 0.466386, acc.: 75.78%] [G loss: 0.883156]\n",
      "epoch:23 step:22106 [D loss: 0.472280, acc.: 76.56%] [G loss: 0.785514]\n",
      "epoch:23 step:22107 [D loss: 0.480982, acc.: 78.12%] [G loss: 0.802871]\n",
      "epoch:23 step:22108 [D loss: 0.476902, acc.: 81.25%] [G loss: 0.699944]\n",
      "epoch:23 step:22109 [D loss: 0.455403, acc.: 75.00%] [G loss: 0.804261]\n",
      "epoch:23 step:22110 [D loss: 0.569505, acc.: 71.09%] [G loss: 0.635844]\n",
      "epoch:23 step:22111 [D loss: 0.558873, acc.: 67.97%] [G loss: 0.643519]\n",
      "epoch:23 step:22112 [D loss: 0.543638, acc.: 68.75%] [G loss: 0.690604]\n",
      "epoch:23 step:22113 [D loss: 0.588924, acc.: 67.19%] [G loss: 0.546715]\n",
      "epoch:23 step:22114 [D loss: 0.558599, acc.: 66.41%] [G loss: 0.770125]\n",
      "epoch:23 step:22115 [D loss: 0.478410, acc.: 76.56%] [G loss: 0.805896]\n",
      "epoch:23 step:22116 [D loss: 0.536676, acc.: 77.34%] [G loss: 0.683659]\n",
      "epoch:23 step:22117 [D loss: 0.674989, acc.: 63.28%] [G loss: 0.713593]\n",
      "epoch:23 step:22118 [D loss: 0.493249, acc.: 73.44%] [G loss: 0.742626]\n",
      "epoch:23 step:22119 [D loss: 0.553873, acc.: 71.09%] [G loss: 0.739750]\n",
      "epoch:23 step:22120 [D loss: 0.567095, acc.: 70.31%] [G loss: 0.471143]\n",
      "epoch:23 step:22121 [D loss: 0.513209, acc.: 71.09%] [G loss: 0.674800]\n",
      "epoch:23 step:22122 [D loss: 0.541232, acc.: 71.09%] [G loss: 0.579737]\n",
      "epoch:23 step:22123 [D loss: 0.586734, acc.: 68.75%] [G loss: 0.626704]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:23 step:22124 [D loss: 0.535857, acc.: 70.31%] [G loss: 0.753682]\n",
      "epoch:23 step:22125 [D loss: 0.538849, acc.: 75.78%] [G loss: 0.787672]\n",
      "epoch:23 step:22126 [D loss: 0.524026, acc.: 72.66%] [G loss: 0.928869]\n",
      "epoch:23 step:22127 [D loss: 0.585742, acc.: 67.19%] [G loss: 0.759122]\n",
      "epoch:23 step:22128 [D loss: 0.546272, acc.: 68.75%] [G loss: 0.723125]\n",
      "epoch:23 step:22129 [D loss: 0.583901, acc.: 63.28%] [G loss: 0.545866]\n",
      "epoch:23 step:22130 [D loss: 0.466788, acc.: 75.78%] [G loss: 0.634129]\n",
      "epoch:23 step:22131 [D loss: 0.572639, acc.: 68.75%] [G loss: 0.623129]\n",
      "epoch:23 step:22132 [D loss: 0.522141, acc.: 77.34%] [G loss: 0.564554]\n",
      "epoch:23 step:22133 [D loss: 0.431218, acc.: 82.03%] [G loss: 0.707550]\n",
      "epoch:23 step:22134 [D loss: 0.544847, acc.: 75.00%] [G loss: 0.866852]\n",
      "epoch:23 step:22135 [D loss: 0.604042, acc.: 65.62%] [G loss: 0.604892]\n",
      "epoch:23 step:22136 [D loss: 0.551535, acc.: 67.19%] [G loss: 0.661676]\n",
      "epoch:23 step:22137 [D loss: 0.600319, acc.: 66.41%] [G loss: 0.595329]\n",
      "epoch:23 step:22138 [D loss: 0.544951, acc.: 69.53%] [G loss: 0.683637]\n",
      "epoch:23 step:22139 [D loss: 0.555887, acc.: 67.97%] [G loss: 0.568975]\n",
      "epoch:23 step:22140 [D loss: 0.549953, acc.: 64.84%] [G loss: 0.738086]\n",
      "epoch:23 step:22141 [D loss: 0.500787, acc.: 73.44%] [G loss: 0.605257]\n",
      "epoch:23 step:22142 [D loss: 0.576356, acc.: 70.31%] [G loss: 0.650856]\n",
      "epoch:23 step:22143 [D loss: 0.500198, acc.: 78.91%] [G loss: 0.788298]\n",
      "epoch:23 step:22144 [D loss: 0.548969, acc.: 68.75%] [G loss: 0.591322]\n",
      "epoch:23 step:22145 [D loss: 0.545318, acc.: 73.44%] [G loss: 0.675849]\n",
      "epoch:23 step:22146 [D loss: 0.545824, acc.: 72.66%] [G loss: 0.666826]\n",
      "epoch:23 step:22147 [D loss: 0.507145, acc.: 70.31%] [G loss: 0.667490]\n",
      "epoch:23 step:22148 [D loss: 0.565454, acc.: 70.31%] [G loss: 0.548598]\n",
      "epoch:23 step:22149 [D loss: 0.483839, acc.: 80.47%] [G loss: 0.589410]\n",
      "epoch:23 step:22150 [D loss: 0.458128, acc.: 80.47%] [G loss: 0.693322]\n",
      "epoch:23 step:22151 [D loss: 0.646846, acc.: 61.72%] [G loss: 0.708231]\n",
      "epoch:23 step:22152 [D loss: 0.511262, acc.: 72.66%] [G loss: 0.723890]\n",
      "epoch:23 step:22153 [D loss: 0.519348, acc.: 68.75%] [G loss: 0.850368]\n",
      "epoch:23 step:22154 [D loss: 0.466326, acc.: 78.12%] [G loss: 0.806241]\n",
      "epoch:23 step:22155 [D loss: 0.564288, acc.: 70.31%] [G loss: 0.777816]\n",
      "epoch:23 step:22156 [D loss: 0.440534, acc.: 78.12%] [G loss: 0.787704]\n",
      "epoch:23 step:22157 [D loss: 0.590557, acc.: 69.53%] [G loss: 0.530645]\n",
      "epoch:23 step:22158 [D loss: 0.537610, acc.: 70.31%] [G loss: 0.600591]\n",
      "epoch:23 step:22159 [D loss: 0.560455, acc.: 68.75%] [G loss: 0.688741]\n",
      "epoch:23 step:22160 [D loss: 0.548719, acc.: 68.75%] [G loss: 0.452326]\n",
      "epoch:23 step:22161 [D loss: 0.568588, acc.: 67.19%] [G loss: 0.548751]\n",
      "epoch:23 step:22162 [D loss: 0.534760, acc.: 71.09%] [G loss: 0.588531]\n",
      "epoch:23 step:22163 [D loss: 0.564682, acc.: 67.97%] [G loss: 0.657984]\n",
      "epoch:23 step:22164 [D loss: 0.480492, acc.: 79.69%] [G loss: 0.696052]\n",
      "epoch:23 step:22165 [D loss: 0.565677, acc.: 65.62%] [G loss: 0.645411]\n",
      "epoch:23 step:22166 [D loss: 0.580050, acc.: 64.06%] [G loss: 0.553909]\n",
      "epoch:23 step:22167 [D loss: 0.599112, acc.: 63.28%] [G loss: 0.689404]\n",
      "epoch:23 step:22168 [D loss: 0.571506, acc.: 60.94%] [G loss: 0.634627]\n",
      "epoch:23 step:22169 [D loss: 0.542746, acc.: 68.75%] [G loss: 0.659605]\n",
      "epoch:23 step:22170 [D loss: 0.548444, acc.: 71.88%] [G loss: 0.678149]\n",
      "epoch:23 step:22171 [D loss: 0.529071, acc.: 69.53%] [G loss: 0.800406]\n",
      "epoch:23 step:22172 [D loss: 0.547260, acc.: 69.53%] [G loss: 0.657496]\n",
      "epoch:23 step:22173 [D loss: 0.551806, acc.: 69.53%] [G loss: 0.598793]\n",
      "epoch:23 step:22174 [D loss: 0.495036, acc.: 75.78%] [G loss: 0.875703]\n",
      "epoch:23 step:22175 [D loss: 0.448521, acc.: 79.69%] [G loss: 0.875007]\n",
      "epoch:23 step:22176 [D loss: 0.655955, acc.: 64.84%] [G loss: 0.548158]\n",
      "epoch:23 step:22177 [D loss: 0.532789, acc.: 70.31%] [G loss: 0.754840]\n",
      "epoch:23 step:22178 [D loss: 0.543155, acc.: 70.31%] [G loss: 0.538386]\n",
      "epoch:23 step:22179 [D loss: 0.569982, acc.: 67.19%] [G loss: 0.710886]\n",
      "epoch:23 step:22180 [D loss: 0.497900, acc.: 75.00%] [G loss: 0.702500]\n",
      "epoch:23 step:22181 [D loss: 0.563442, acc.: 71.88%] [G loss: 0.630216]\n",
      "epoch:23 step:22182 [D loss: 0.498749, acc.: 71.09%] [G loss: 0.713191]\n",
      "epoch:23 step:22183 [D loss: 0.489697, acc.: 75.78%] [G loss: 0.773849]\n",
      "epoch:23 step:22184 [D loss: 0.542169, acc.: 71.09%] [G loss: 0.922760]\n",
      "epoch:23 step:22185 [D loss: 0.440290, acc.: 82.81%] [G loss: 0.855505]\n",
      "epoch:23 step:22186 [D loss: 0.493724, acc.: 75.78%] [G loss: 0.715650]\n",
      "epoch:23 step:22187 [D loss: 0.581841, acc.: 68.75%] [G loss: 0.766423]\n",
      "epoch:23 step:22188 [D loss: 0.550306, acc.: 67.19%] [G loss: 0.461015]\n",
      "epoch:23 step:22189 [D loss: 0.503210, acc.: 74.22%] [G loss: 0.669692]\n",
      "epoch:23 step:22190 [D loss: 0.502339, acc.: 71.88%] [G loss: 0.774545]\n",
      "epoch:23 step:22191 [D loss: 0.565176, acc.: 68.75%] [G loss: 0.673179]\n",
      "epoch:23 step:22192 [D loss: 0.487881, acc.: 76.56%] [G loss: 0.829460]\n",
      "epoch:23 step:22193 [D loss: 0.516464, acc.: 68.75%] [G loss: 0.750113]\n",
      "epoch:23 step:22194 [D loss: 0.547807, acc.: 67.97%] [G loss: 0.814620]\n",
      "epoch:23 step:22195 [D loss: 0.557465, acc.: 70.31%] [G loss: 0.780601]\n",
      "epoch:23 step:22196 [D loss: 0.558099, acc.: 64.84%] [G loss: 0.613591]\n",
      "epoch:23 step:22197 [D loss: 0.534122, acc.: 71.88%] [G loss: 0.658699]\n",
      "epoch:23 step:22198 [D loss: 0.452339, acc.: 81.25%] [G loss: 0.799838]\n",
      "epoch:23 step:22199 [D loss: 0.421261, acc.: 84.38%] [G loss: 1.404521]\n",
      "epoch:23 step:22200 [D loss: 0.481148, acc.: 74.22%] [G loss: 0.885114]\n",
      "##############\n",
      "[3.13992165 1.22980507 6.08637646 5.03983904 3.93089688 5.53903771\n",
      " 4.46920597 4.91788033 4.75336902 4.17093897]\n",
      "##########\n",
      "epoch:23 step:22201 [D loss: 0.497740, acc.: 76.56%] [G loss: 0.730215]\n",
      "epoch:23 step:22202 [D loss: 0.536789, acc.: 76.56%] [G loss: 0.778446]\n",
      "epoch:23 step:22203 [D loss: 0.644660, acc.: 67.97%] [G loss: 0.768403]\n",
      "epoch:23 step:22204 [D loss: 0.590647, acc.: 64.06%] [G loss: 0.675949]\n",
      "epoch:23 step:22205 [D loss: 0.470404, acc.: 75.78%] [G loss: 0.742188]\n",
      "epoch:23 step:22206 [D loss: 0.602026, acc.: 69.53%] [G loss: 0.732406]\n",
      "epoch:23 step:22207 [D loss: 0.536157, acc.: 73.44%] [G loss: 0.729025]\n",
      "epoch:23 step:22208 [D loss: 0.466601, acc.: 75.00%] [G loss: 0.800300]\n",
      "epoch:23 step:22209 [D loss: 0.542668, acc.: 70.31%] [G loss: 0.752519]\n",
      "epoch:23 step:22210 [D loss: 0.500040, acc.: 74.22%] [G loss: 0.755890]\n",
      "epoch:23 step:22211 [D loss: 0.559611, acc.: 71.88%] [G loss: 0.722351]\n",
      "epoch:23 step:22212 [D loss: 0.481611, acc.: 75.78%] [G loss: 0.782901]\n",
      "epoch:23 step:22213 [D loss: 0.516609, acc.: 75.00%] [G loss: 0.703009]\n",
      "epoch:23 step:22214 [D loss: 0.564604, acc.: 64.84%] [G loss: 0.839503]\n",
      "epoch:23 step:22215 [D loss: 0.501956, acc.: 71.88%] [G loss: 0.768735]\n",
      "epoch:23 step:22216 [D loss: 0.574295, acc.: 67.19%] [G loss: 0.781867]\n",
      "epoch:23 step:22217 [D loss: 0.514404, acc.: 70.31%] [G loss: 0.727000]\n",
      "epoch:23 step:22218 [D loss: 0.509707, acc.: 71.09%] [G loss: 0.779888]\n",
      "epoch:23 step:22219 [D loss: 0.553151, acc.: 72.66%] [G loss: 0.630605]\n",
      "epoch:23 step:22220 [D loss: 0.548015, acc.: 68.75%] [G loss: 0.771337]\n",
      "epoch:23 step:22221 [D loss: 0.535246, acc.: 67.19%] [G loss: 0.627239]\n",
      "epoch:23 step:22222 [D loss: 0.581833, acc.: 68.75%] [G loss: 0.672310]\n",
      "epoch:23 step:22223 [D loss: 0.531474, acc.: 69.53%] [G loss: 0.782583]\n",
      "epoch:23 step:22224 [D loss: 0.548977, acc.: 70.31%] [G loss: 0.639870]\n",
      "epoch:23 step:22225 [D loss: 0.491914, acc.: 75.78%] [G loss: 0.645748]\n",
      "epoch:23 step:22226 [D loss: 0.571941, acc.: 71.88%] [G loss: 0.701081]\n",
      "epoch:23 step:22227 [D loss: 0.527669, acc.: 71.09%] [G loss: 0.597875]\n",
      "epoch:23 step:22228 [D loss: 0.488749, acc.: 75.78%] [G loss: 0.675204]\n",
      "epoch:23 step:22229 [D loss: 0.580808, acc.: 64.84%] [G loss: 0.676996]\n",
      "epoch:23 step:22230 [D loss: 0.513456, acc.: 74.22%] [G loss: 0.565511]\n",
      "epoch:23 step:22231 [D loss: 0.496248, acc.: 77.34%] [G loss: 0.797792]\n",
      "epoch:23 step:22232 [D loss: 0.515424, acc.: 75.00%] [G loss: 0.731009]\n",
      "epoch:23 step:22233 [D loss: 0.593266, acc.: 68.75%] [G loss: 0.562763]\n",
      "epoch:23 step:22234 [D loss: 0.509566, acc.: 72.66%] [G loss: 0.590204]\n",
      "epoch:23 step:22235 [D loss: 0.605822, acc.: 67.19%] [G loss: 0.508042]\n",
      "epoch:23 step:22236 [D loss: 0.509289, acc.: 78.12%] [G loss: 0.583975]\n",
      "epoch:23 step:22237 [D loss: 0.591838, acc.: 67.97%] [G loss: 0.556385]\n",
      "epoch:23 step:22238 [D loss: 0.585845, acc.: 67.19%] [G loss: 0.684528]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:23 step:22239 [D loss: 0.526377, acc.: 73.44%] [G loss: 0.605332]\n",
      "epoch:23 step:22240 [D loss: 0.558976, acc.: 73.44%] [G loss: 0.574374]\n",
      "epoch:23 step:22241 [D loss: 0.415922, acc.: 81.25%] [G loss: 0.840851]\n",
      "epoch:23 step:22242 [D loss: 0.543536, acc.: 74.22%] [G loss: 0.561183]\n",
      "epoch:23 step:22243 [D loss: 0.524819, acc.: 69.53%] [G loss: 0.692396]\n",
      "epoch:23 step:22244 [D loss: 0.500644, acc.: 75.00%] [G loss: 0.709073]\n",
      "epoch:23 step:22245 [D loss: 0.483313, acc.: 74.22%] [G loss: 0.797495]\n",
      "epoch:23 step:22246 [D loss: 0.480203, acc.: 79.69%] [G loss: 0.697017]\n",
      "epoch:23 step:22247 [D loss: 0.577140, acc.: 63.28%] [G loss: 0.682650]\n",
      "epoch:23 step:22248 [D loss: 0.581257, acc.: 65.62%] [G loss: 0.656622]\n",
      "epoch:23 step:22249 [D loss: 0.578825, acc.: 66.41%] [G loss: 0.608554]\n",
      "epoch:23 step:22250 [D loss: 0.506926, acc.: 73.44%] [G loss: 0.810535]\n",
      "epoch:23 step:22251 [D loss: 0.532571, acc.: 74.22%] [G loss: 0.873907]\n",
      "epoch:23 step:22252 [D loss: 0.527577, acc.: 71.09%] [G loss: 0.880491]\n",
      "epoch:23 step:22253 [D loss: 0.581074, acc.: 65.62%] [G loss: 0.735059]\n",
      "epoch:23 step:22254 [D loss: 0.594449, acc.: 64.06%] [G loss: 0.716525]\n",
      "epoch:23 step:22255 [D loss: 0.637388, acc.: 63.28%] [G loss: 0.568210]\n",
      "epoch:23 step:22256 [D loss: 0.528677, acc.: 68.75%] [G loss: 0.575719]\n",
      "epoch:23 step:22257 [D loss: 0.534600, acc.: 75.00%] [G loss: 0.920429]\n",
      "epoch:23 step:22258 [D loss: 0.509765, acc.: 67.97%] [G loss: 0.824097]\n",
      "epoch:23 step:22259 [D loss: 0.487593, acc.: 75.78%] [G loss: 0.802563]\n",
      "epoch:23 step:22260 [D loss: 0.547385, acc.: 68.75%] [G loss: 0.667812]\n",
      "epoch:23 step:22261 [D loss: 0.546471, acc.: 72.66%] [G loss: 0.701098]\n",
      "epoch:23 step:22262 [D loss: 0.581992, acc.: 67.19%] [G loss: 0.655805]\n",
      "epoch:23 step:22263 [D loss: 0.512203, acc.: 72.66%] [G loss: 0.680100]\n",
      "epoch:23 step:22264 [D loss: 0.556051, acc.: 67.19%] [G loss: 0.786978]\n",
      "epoch:23 step:22265 [D loss: 0.509242, acc.: 73.44%] [G loss: 0.491402]\n",
      "epoch:23 step:22266 [D loss: 0.551232, acc.: 73.44%] [G loss: 0.715831]\n",
      "epoch:23 step:22267 [D loss: 0.565783, acc.: 67.97%] [G loss: 0.621499]\n",
      "epoch:23 step:22268 [D loss: 0.551040, acc.: 74.22%] [G loss: 0.491553]\n",
      "epoch:23 step:22269 [D loss: 0.520033, acc.: 71.09%] [G loss: 0.552166]\n",
      "epoch:23 step:22270 [D loss: 0.449623, acc.: 78.12%] [G loss: 0.761352]\n",
      "epoch:23 step:22271 [D loss: 0.600676, acc.: 69.53%] [G loss: 0.823815]\n",
      "epoch:23 step:22272 [D loss: 0.565497, acc.: 67.97%] [G loss: 0.622002]\n",
      "epoch:23 step:22273 [D loss: 0.522763, acc.: 75.00%] [G loss: 0.690996]\n",
      "epoch:23 step:22274 [D loss: 0.551586, acc.: 71.88%] [G loss: 0.747654]\n",
      "epoch:23 step:22275 [D loss: 0.481275, acc.: 77.34%] [G loss: 0.732952]\n",
      "epoch:23 step:22276 [D loss: 0.504058, acc.: 78.91%] [G loss: 0.794597]\n",
      "epoch:23 step:22277 [D loss: 0.524236, acc.: 72.66%] [G loss: 0.717957]\n",
      "epoch:23 step:22278 [D loss: 0.604684, acc.: 64.06%] [G loss: 0.569441]\n",
      "epoch:23 step:22279 [D loss: 0.578251, acc.: 67.97%] [G loss: 0.648092]\n",
      "epoch:23 step:22280 [D loss: 0.567511, acc.: 68.75%] [G loss: 0.407900]\n",
      "epoch:23 step:22281 [D loss: 0.518768, acc.: 74.22%] [G loss: 0.570901]\n",
      "epoch:23 step:22282 [D loss: 0.566583, acc.: 71.09%] [G loss: 0.678072]\n",
      "epoch:23 step:22283 [D loss: 0.517017, acc.: 72.66%] [G loss: 0.500934]\n",
      "epoch:23 step:22284 [D loss: 0.535477, acc.: 71.88%] [G loss: 0.652387]\n",
      "epoch:23 step:22285 [D loss: 0.567696, acc.: 67.97%] [G loss: 0.629248]\n",
      "epoch:23 step:22286 [D loss: 0.574017, acc.: 65.62%] [G loss: 0.725425]\n",
      "epoch:23 step:22287 [D loss: 0.491386, acc.: 78.12%] [G loss: 0.604929]\n",
      "epoch:23 step:22288 [D loss: 0.558463, acc.: 68.75%] [G loss: 0.863163]\n",
      "epoch:23 step:22289 [D loss: 0.531752, acc.: 71.09%] [G loss: 0.534456]\n",
      "epoch:23 step:22290 [D loss: 0.550651, acc.: 67.97%] [G loss: 0.543754]\n",
      "epoch:23 step:22291 [D loss: 0.563456, acc.: 66.41%] [G loss: 0.626992]\n",
      "epoch:23 step:22292 [D loss: 0.578327, acc.: 64.84%] [G loss: 0.720859]\n",
      "epoch:23 step:22293 [D loss: 0.505214, acc.: 77.34%] [G loss: 0.736618]\n",
      "epoch:23 step:22294 [D loss: 0.501751, acc.: 74.22%] [G loss: 0.764949]\n",
      "epoch:23 step:22295 [D loss: 0.512985, acc.: 78.91%] [G loss: 0.846269]\n",
      "epoch:23 step:22296 [D loss: 0.531962, acc.: 70.31%] [G loss: 0.725162]\n",
      "epoch:23 step:22297 [D loss: 0.420820, acc.: 80.47%] [G loss: 0.732071]\n",
      "epoch:23 step:22298 [D loss: 0.486247, acc.: 78.12%] [G loss: 0.878565]\n",
      "epoch:23 step:22299 [D loss: 0.544380, acc.: 70.31%] [G loss: 0.798084]\n",
      "epoch:23 step:22300 [D loss: 0.585571, acc.: 68.75%] [G loss: 0.558192]\n",
      "epoch:23 step:22301 [D loss: 0.503483, acc.: 71.88%] [G loss: 0.864160]\n",
      "epoch:23 step:22302 [D loss: 0.539636, acc.: 74.22%] [G loss: 0.754363]\n",
      "epoch:23 step:22303 [D loss: 0.586361, acc.: 64.84%] [G loss: 0.621050]\n",
      "epoch:23 step:22304 [D loss: 0.511932, acc.: 72.66%] [G loss: 0.674122]\n",
      "epoch:23 step:22305 [D loss: 0.547832, acc.: 69.53%] [G loss: 0.780075]\n",
      "epoch:23 step:22306 [D loss: 0.487407, acc.: 75.00%] [G loss: 0.702841]\n",
      "epoch:23 step:22307 [D loss: 0.509448, acc.: 75.78%] [G loss: 0.673508]\n",
      "epoch:23 step:22308 [D loss: 0.536597, acc.: 71.88%] [G loss: 0.776412]\n",
      "epoch:23 step:22309 [D loss: 0.556823, acc.: 71.88%] [G loss: 0.695388]\n",
      "epoch:23 step:22310 [D loss: 0.560006, acc.: 70.31%] [G loss: 0.664493]\n",
      "epoch:23 step:22311 [D loss: 0.510057, acc.: 70.31%] [G loss: 0.666033]\n",
      "epoch:23 step:22312 [D loss: 0.543152, acc.: 67.19%] [G loss: 0.657013]\n",
      "epoch:23 step:22313 [D loss: 0.579120, acc.: 66.41%] [G loss: 0.740669]\n",
      "epoch:23 step:22314 [D loss: 0.509431, acc.: 73.44%] [G loss: 0.744426]\n",
      "epoch:23 step:22315 [D loss: 0.552935, acc.: 70.31%] [G loss: 0.697330]\n",
      "epoch:23 step:22316 [D loss: 0.535434, acc.: 73.44%] [G loss: 0.636529]\n",
      "epoch:23 step:22317 [D loss: 0.594378, acc.: 64.06%] [G loss: 0.733325]\n",
      "epoch:23 step:22318 [D loss: 0.549734, acc.: 71.88%] [G loss: 0.614569]\n",
      "epoch:23 step:22319 [D loss: 0.590416, acc.: 69.53%] [G loss: 0.858431]\n",
      "epoch:23 step:22320 [D loss: 0.522051, acc.: 73.44%] [G loss: 0.755854]\n",
      "epoch:23 step:22321 [D loss: 0.498973, acc.: 80.47%] [G loss: 0.943873]\n",
      "epoch:23 step:22322 [D loss: 0.502402, acc.: 71.88%] [G loss: 0.736027]\n",
      "epoch:23 step:22323 [D loss: 0.552337, acc.: 66.41%] [G loss: 0.786443]\n",
      "epoch:23 step:22324 [D loss: 0.534909, acc.: 72.66%] [G loss: 0.716498]\n",
      "epoch:23 step:22325 [D loss: 0.520978, acc.: 71.88%] [G loss: 0.735695]\n",
      "epoch:23 step:22326 [D loss: 0.524352, acc.: 71.88%] [G loss: 0.670142]\n",
      "epoch:23 step:22327 [D loss: 0.538412, acc.: 68.75%] [G loss: 0.735312]\n",
      "epoch:23 step:22328 [D loss: 0.594161, acc.: 69.53%] [G loss: 0.772117]\n",
      "epoch:23 step:22329 [D loss: 0.531438, acc.: 73.44%] [G loss: 0.629708]\n",
      "epoch:23 step:22330 [D loss: 0.547659, acc.: 66.41%] [G loss: 0.571201]\n",
      "epoch:23 step:22331 [D loss: 0.574286, acc.: 72.66%] [G loss: 0.673829]\n",
      "epoch:23 step:22332 [D loss: 0.465097, acc.: 76.56%] [G loss: 0.923150]\n",
      "epoch:23 step:22333 [D loss: 0.505620, acc.: 71.09%] [G loss: 0.876472]\n",
      "epoch:23 step:22334 [D loss: 0.542386, acc.: 69.53%] [G loss: 0.865974]\n",
      "epoch:23 step:22335 [D loss: 0.646626, acc.: 68.75%] [G loss: 0.564737]\n",
      "epoch:23 step:22336 [D loss: 0.546086, acc.: 71.09%] [G loss: 0.533356]\n",
      "epoch:23 step:22337 [D loss: 0.515393, acc.: 75.00%] [G loss: 0.725121]\n",
      "epoch:23 step:22338 [D loss: 0.601214, acc.: 70.31%] [G loss: 0.530116]\n",
      "epoch:23 step:22339 [D loss: 0.625534, acc.: 67.97%] [G loss: 0.496430]\n",
      "epoch:23 step:22340 [D loss: 0.499949, acc.: 78.91%] [G loss: 0.683260]\n",
      "epoch:23 step:22341 [D loss: 0.511811, acc.: 71.88%] [G loss: 0.669219]\n",
      "epoch:23 step:22342 [D loss: 0.507781, acc.: 74.22%] [G loss: 0.708369]\n",
      "epoch:23 step:22343 [D loss: 0.446655, acc.: 78.12%] [G loss: 0.789966]\n",
      "epoch:23 step:22344 [D loss: 0.569665, acc.: 71.88%] [G loss: 0.691518]\n",
      "epoch:23 step:22345 [D loss: 0.604942, acc.: 64.84%] [G loss: 0.566762]\n",
      "epoch:23 step:22346 [D loss: 0.544359, acc.: 73.44%] [G loss: 0.815511]\n",
      "epoch:23 step:22347 [D loss: 0.541558, acc.: 69.53%] [G loss: 0.857428]\n",
      "epoch:23 step:22348 [D loss: 0.467483, acc.: 75.78%] [G loss: 0.929293]\n",
      "epoch:23 step:22349 [D loss: 0.539128, acc.: 70.31%] [G loss: 0.668301]\n",
      "epoch:23 step:22350 [D loss: 0.559658, acc.: 67.19%] [G loss: 0.620612]\n",
      "epoch:23 step:22351 [D loss: 0.553508, acc.: 68.75%] [G loss: 0.589417]\n",
      "epoch:23 step:22352 [D loss: 0.530309, acc.: 75.00%] [G loss: 0.985710]\n",
      "epoch:23 step:22353 [D loss: 0.460587, acc.: 75.78%] [G loss: 0.903764]\n",
      "epoch:23 step:22354 [D loss: 0.502336, acc.: 78.12%] [G loss: 0.615450]\n",
      "epoch:23 step:22355 [D loss: 0.530453, acc.: 71.88%] [G loss: 0.714838]\n",
      "epoch:23 step:22356 [D loss: 0.558532, acc.: 67.97%] [G loss: 0.640182]\n",
      "epoch:23 step:22357 [D loss: 0.545986, acc.: 69.53%] [G loss: 0.567626]\n",
      "epoch:23 step:22358 [D loss: 0.498420, acc.: 74.22%] [G loss: 0.694292]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:23 step:22359 [D loss: 0.550093, acc.: 67.19%] [G loss: 0.652741]\n",
      "epoch:23 step:22360 [D loss: 0.558608, acc.: 67.19%] [G loss: 0.497791]\n",
      "epoch:23 step:22361 [D loss: 0.515132, acc.: 71.88%] [G loss: 0.643002]\n",
      "epoch:23 step:22362 [D loss: 0.537096, acc.: 76.56%] [G loss: 0.631587]\n",
      "epoch:23 step:22363 [D loss: 0.653442, acc.: 62.50%] [G loss: 0.498181]\n",
      "epoch:23 step:22364 [D loss: 0.527013, acc.: 72.66%] [G loss: 0.581681]\n",
      "epoch:23 step:22365 [D loss: 0.479864, acc.: 76.56%] [G loss: 0.727083]\n",
      "epoch:23 step:22366 [D loss: 0.515997, acc.: 75.00%] [G loss: 0.846246]\n",
      "epoch:23 step:22367 [D loss: 0.569406, acc.: 69.53%] [G loss: 0.890126]\n",
      "epoch:23 step:22368 [D loss: 0.586508, acc.: 68.75%] [G loss: 0.754428]\n",
      "epoch:23 step:22369 [D loss: 0.601655, acc.: 67.19%] [G loss: 0.604959]\n",
      "epoch:23 step:22370 [D loss: 0.523941, acc.: 72.66%] [G loss: 0.715785]\n",
      "epoch:23 step:22371 [D loss: 0.652042, acc.: 64.84%] [G loss: 0.515679]\n",
      "epoch:23 step:22372 [D loss: 0.543078, acc.: 71.88%] [G loss: 0.518000]\n",
      "epoch:23 step:22373 [D loss: 0.561718, acc.: 63.28%] [G loss: 0.669819]\n",
      "epoch:23 step:22374 [D loss: 0.435213, acc.: 79.69%] [G loss: 0.849213]\n",
      "epoch:23 step:22375 [D loss: 0.551283, acc.: 68.75%] [G loss: 0.722893]\n",
      "epoch:23 step:22376 [D loss: 0.550299, acc.: 69.53%] [G loss: 0.739596]\n",
      "epoch:23 step:22377 [D loss: 0.548158, acc.: 68.75%] [G loss: 0.859417]\n",
      "epoch:23 step:22378 [D loss: 0.534735, acc.: 72.66%] [G loss: 0.729729]\n",
      "epoch:23 step:22379 [D loss: 0.610153, acc.: 64.06%] [G loss: 0.552463]\n",
      "epoch:23 step:22380 [D loss: 0.484382, acc.: 73.44%] [G loss: 0.747546]\n",
      "epoch:23 step:22381 [D loss: 0.538769, acc.: 70.31%] [G loss: 0.838355]\n",
      "epoch:23 step:22382 [D loss: 0.541305, acc.: 67.97%] [G loss: 0.692223]\n",
      "epoch:23 step:22383 [D loss: 0.539299, acc.: 71.88%] [G loss: 0.651795]\n",
      "epoch:23 step:22384 [D loss: 0.533374, acc.: 70.31%] [G loss: 0.724311]\n",
      "epoch:23 step:22385 [D loss: 0.500741, acc.: 71.09%] [G loss: 0.823732]\n",
      "epoch:23 step:22386 [D loss: 0.546366, acc.: 72.66%] [G loss: 0.565007]\n",
      "epoch:23 step:22387 [D loss: 0.505229, acc.: 71.09%] [G loss: 0.622886]\n",
      "epoch:23 step:22388 [D loss: 0.569643, acc.: 71.09%] [G loss: 0.568849]\n",
      "epoch:23 step:22389 [D loss: 0.541799, acc.: 68.75%] [G loss: 0.686900]\n",
      "epoch:23 step:22390 [D loss: 0.551827, acc.: 70.31%] [G loss: 0.552728]\n",
      "epoch:23 step:22391 [D loss: 0.554266, acc.: 75.00%] [G loss: 0.472061]\n",
      "epoch:23 step:22392 [D loss: 0.535423, acc.: 71.88%] [G loss: 0.522841]\n",
      "epoch:23 step:22393 [D loss: 0.528961, acc.: 71.88%] [G loss: 0.515508]\n",
      "epoch:23 step:22394 [D loss: 0.526315, acc.: 70.31%] [G loss: 0.733320]\n",
      "epoch:23 step:22395 [D loss: 0.545503, acc.: 75.00%] [G loss: 0.644428]\n",
      "epoch:23 step:22396 [D loss: 0.556837, acc.: 69.53%] [G loss: 0.563492]\n",
      "epoch:23 step:22397 [D loss: 0.548173, acc.: 69.53%] [G loss: 0.640893]\n",
      "epoch:23 step:22398 [D loss: 0.637825, acc.: 60.94%] [G loss: 0.428514]\n",
      "epoch:23 step:22399 [D loss: 0.538599, acc.: 66.41%] [G loss: 0.515564]\n",
      "epoch:23 step:22400 [D loss: 0.520791, acc.: 71.88%] [G loss: 0.793723]\n",
      "##############\n",
      "[3.1230394  1.61344408 6.29901584 4.91942564 3.93644481 5.59633296\n",
      " 4.62615014 5.03382981 4.84894651 4.26007985]\n",
      "##########\n",
      "epoch:23 step:22401 [D loss: 0.558921, acc.: 74.22%] [G loss: 0.563151]\n",
      "epoch:23 step:22402 [D loss: 0.530937, acc.: 68.75%] [G loss: 0.616918]\n",
      "epoch:23 step:22403 [D loss: 0.548316, acc.: 69.53%] [G loss: 0.640860]\n",
      "epoch:23 step:22404 [D loss: 0.551747, acc.: 67.19%] [G loss: 0.744989]\n",
      "epoch:23 step:22405 [D loss: 0.510597, acc.: 70.31%] [G loss: 0.619598]\n",
      "epoch:23 step:22406 [D loss: 0.527456, acc.: 71.09%] [G loss: 0.763535]\n",
      "epoch:23 step:22407 [D loss: 0.577496, acc.: 67.97%] [G loss: 0.659453]\n",
      "epoch:23 step:22408 [D loss: 0.468468, acc.: 78.12%] [G loss: 0.718961]\n",
      "epoch:23 step:22409 [D loss: 0.574124, acc.: 65.62%] [G loss: 0.582510]\n",
      "epoch:23 step:22410 [D loss: 0.596493, acc.: 65.62%] [G loss: 0.745261]\n",
      "epoch:23 step:22411 [D loss: 0.440645, acc.: 79.69%] [G loss: 0.987820]\n",
      "epoch:23 step:22412 [D loss: 0.581527, acc.: 67.97%] [G loss: 0.711131]\n",
      "epoch:23 step:22413 [D loss: 0.588291, acc.: 66.41%] [G loss: 0.503028]\n",
      "epoch:23 step:22414 [D loss: 0.534962, acc.: 71.09%] [G loss: 0.575774]\n",
      "epoch:23 step:22415 [D loss: 0.609835, acc.: 65.62%] [G loss: 0.535226]\n",
      "epoch:23 step:22416 [D loss: 0.574686, acc.: 66.41%] [G loss: 0.475865]\n",
      "epoch:23 step:22417 [D loss: 0.542013, acc.: 71.88%] [G loss: 0.537326]\n",
      "epoch:23 step:22418 [D loss: 0.639907, acc.: 60.16%] [G loss: 0.448517]\n",
      "epoch:23 step:22419 [D loss: 0.532774, acc.: 71.09%] [G loss: 0.511234]\n",
      "epoch:23 step:22420 [D loss: 0.555733, acc.: 70.31%] [G loss: 0.533068]\n",
      "epoch:23 step:22421 [D loss: 0.482766, acc.: 75.78%] [G loss: 0.634029]\n",
      "epoch:23 step:22422 [D loss: 0.463708, acc.: 78.91%] [G loss: 0.727461]\n",
      "epoch:23 step:22423 [D loss: 0.546949, acc.: 70.31%] [G loss: 0.711602]\n",
      "epoch:23 step:22424 [D loss: 0.597744, acc.: 68.75%] [G loss: 0.579206]\n",
      "epoch:23 step:22425 [D loss: 0.517605, acc.: 69.53%] [G loss: 0.627533]\n",
      "epoch:23 step:22426 [D loss: 0.464808, acc.: 78.91%] [G loss: 0.652664]\n",
      "epoch:23 step:22427 [D loss: 0.552652, acc.: 69.53%] [G loss: 0.591387]\n",
      "epoch:23 step:22428 [D loss: 0.571741, acc.: 66.41%] [G loss: 0.547846]\n",
      "epoch:23 step:22429 [D loss: 0.558982, acc.: 75.78%] [G loss: 0.621692]\n",
      "epoch:23 step:22430 [D loss: 0.582881, acc.: 65.62%] [G loss: 0.757086]\n",
      "epoch:23 step:22431 [D loss: 0.655862, acc.: 57.03%] [G loss: 0.626333]\n",
      "epoch:23 step:22432 [D loss: 0.603537, acc.: 68.75%] [G loss: 0.458463]\n",
      "epoch:23 step:22433 [D loss: 0.605410, acc.: 62.50%] [G loss: 0.479681]\n",
      "epoch:23 step:22434 [D loss: 0.555111, acc.: 67.19%] [G loss: 0.692606]\n",
      "epoch:23 step:22435 [D loss: 0.476636, acc.: 79.69%] [G loss: 0.872938]\n",
      "epoch:23 step:22436 [D loss: 0.469666, acc.: 74.22%] [G loss: 0.906497]\n",
      "epoch:23 step:22437 [D loss: 0.492432, acc.: 75.78%] [G loss: 0.954104]\n",
      "epoch:23 step:22438 [D loss: 0.516367, acc.: 74.22%] [G loss: 0.805149]\n",
      "epoch:23 step:22439 [D loss: 0.575364, acc.: 65.62%] [G loss: 0.707326]\n",
      "epoch:23 step:22440 [D loss: 0.505877, acc.: 74.22%] [G loss: 0.762935]\n",
      "epoch:23 step:22441 [D loss: 0.470278, acc.: 78.91%] [G loss: 0.795975]\n",
      "epoch:23 step:22442 [D loss: 0.585623, acc.: 70.31%] [G loss: 0.684646]\n",
      "epoch:23 step:22443 [D loss: 0.631206, acc.: 64.06%] [G loss: 0.649840]\n",
      "epoch:23 step:22444 [D loss: 0.597266, acc.: 62.50%] [G loss: 0.488527]\n",
      "epoch:23 step:22445 [D loss: 0.479825, acc.: 73.44%] [G loss: 0.632203]\n",
      "epoch:23 step:22446 [D loss: 0.519675, acc.: 71.09%] [G loss: 0.738771]\n",
      "epoch:23 step:22447 [D loss: 0.500974, acc.: 75.00%] [G loss: 0.810466]\n",
      "epoch:23 step:22448 [D loss: 0.486520, acc.: 75.00%] [G loss: 0.938855]\n",
      "epoch:23 step:22449 [D loss: 0.463844, acc.: 79.69%] [G loss: 0.802635]\n",
      "epoch:23 step:22450 [D loss: 0.485612, acc.: 78.91%] [G loss: 0.667701]\n",
      "epoch:23 step:22451 [D loss: 0.510037, acc.: 76.56%] [G loss: 0.739835]\n",
      "epoch:23 step:22452 [D loss: 0.549034, acc.: 71.09%] [G loss: 0.672868]\n",
      "epoch:23 step:22453 [D loss: 0.545376, acc.: 68.75%] [G loss: 0.765584]\n",
      "epoch:23 step:22454 [D loss: 0.586561, acc.: 64.84%] [G loss: 0.639844]\n",
      "epoch:23 step:22455 [D loss: 0.566551, acc.: 70.31%] [G loss: 0.539729]\n",
      "epoch:23 step:22456 [D loss: 0.583114, acc.: 71.88%] [G loss: 0.879424]\n",
      "epoch:23 step:22457 [D loss: 0.518349, acc.: 73.44%] [G loss: 0.766075]\n",
      "epoch:23 step:22458 [D loss: 0.586435, acc.: 64.84%] [G loss: 0.707195]\n",
      "epoch:23 step:22459 [D loss: 0.535465, acc.: 75.78%] [G loss: 0.740354]\n",
      "epoch:23 step:22460 [D loss: 0.490807, acc.: 76.56%] [G loss: 0.661276]\n",
      "epoch:23 step:22461 [D loss: 0.574351, acc.: 64.84%] [G loss: 0.653314]\n",
      "epoch:23 step:22462 [D loss: 0.478945, acc.: 75.78%] [G loss: 0.760587]\n",
      "epoch:23 step:22463 [D loss: 0.483190, acc.: 72.66%] [G loss: 0.931719]\n",
      "epoch:23 step:22464 [D loss: 0.516212, acc.: 74.22%] [G loss: 0.984107]\n",
      "epoch:23 step:22465 [D loss: 0.513249, acc.: 71.88%] [G loss: 0.802034]\n",
      "epoch:23 step:22466 [D loss: 0.652879, acc.: 62.50%] [G loss: 0.694437]\n",
      "epoch:23 step:22467 [D loss: 0.474705, acc.: 75.78%] [G loss: 0.756662]\n",
      "epoch:23 step:22468 [D loss: 0.591975, acc.: 61.72%] [G loss: 0.624131]\n",
      "epoch:23 step:22469 [D loss: 0.494705, acc.: 73.44%] [G loss: 0.965212]\n",
      "epoch:23 step:22470 [D loss: 0.479581, acc.: 80.47%] [G loss: 0.966904]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:23 step:22471 [D loss: 0.763702, acc.: 58.59%] [G loss: 0.802374]\n",
      "epoch:23 step:22472 [D loss: 0.466387, acc.: 76.56%] [G loss: 0.642363]\n",
      "epoch:23 step:22473 [D loss: 0.587188, acc.: 64.84%] [G loss: 0.696874]\n",
      "epoch:23 step:22474 [D loss: 0.447469, acc.: 74.22%] [G loss: 0.759238]\n",
      "epoch:23 step:22475 [D loss: 0.481753, acc.: 75.00%] [G loss: 0.823134]\n",
      "epoch:23 step:22476 [D loss: 0.434941, acc.: 77.34%] [G loss: 0.902884]\n",
      "epoch:23 step:22477 [D loss: 0.454769, acc.: 75.00%] [G loss: 1.280196]\n",
      "epoch:23 step:22478 [D loss: 0.531923, acc.: 71.09%] [G loss: 1.368062]\n",
      "epoch:23 step:22479 [D loss: 0.632638, acc.: 70.31%] [G loss: 0.893113]\n",
      "epoch:23 step:22480 [D loss: 0.458462, acc.: 78.91%] [G loss: 1.302067]\n",
      "epoch:23 step:22481 [D loss: 0.477232, acc.: 75.00%] [G loss: 1.258499]\n",
      "epoch:23 step:22482 [D loss: 0.623579, acc.: 66.41%] [G loss: 0.969683]\n",
      "epoch:23 step:22483 [D loss: 0.635946, acc.: 65.62%] [G loss: 0.808754]\n",
      "epoch:23 step:22484 [D loss: 0.515398, acc.: 74.22%] [G loss: 0.920647]\n",
      "epoch:23 step:22485 [D loss: 0.628419, acc.: 63.28%] [G loss: 0.917707]\n",
      "epoch:23 step:22486 [D loss: 0.437247, acc.: 81.25%] [G loss: 0.954082]\n",
      "epoch:23 step:22487 [D loss: 0.367129, acc.: 85.16%] [G loss: 1.096607]\n",
      "epoch:23 step:22488 [D loss: 0.453731, acc.: 82.03%] [G loss: 1.172485]\n",
      "epoch:24 step:22489 [D loss: 0.556581, acc.: 72.66%] [G loss: 1.131800]\n",
      "epoch:24 step:22490 [D loss: 0.493312, acc.: 78.12%] [G loss: 0.999377]\n",
      "epoch:24 step:22491 [D loss: 0.545024, acc.: 75.00%] [G loss: 1.172024]\n",
      "epoch:24 step:22492 [D loss: 0.516916, acc.: 75.00%] [G loss: 0.994676]\n",
      "epoch:24 step:22493 [D loss: 0.581808, acc.: 69.53%] [G loss: 0.866949]\n",
      "epoch:24 step:22494 [D loss: 0.549821, acc.: 71.88%] [G loss: 0.763628]\n",
      "epoch:24 step:22495 [D loss: 0.505397, acc.: 77.34%] [G loss: 0.807687]\n",
      "epoch:24 step:22496 [D loss: 0.534536, acc.: 72.66%] [G loss: 1.008247]\n",
      "epoch:24 step:22497 [D loss: 0.480231, acc.: 75.78%] [G loss: 0.717471]\n",
      "epoch:24 step:22498 [D loss: 0.494921, acc.: 76.56%] [G loss: 0.656570]\n",
      "epoch:24 step:22499 [D loss: 0.427339, acc.: 80.47%] [G loss: 0.695794]\n",
      "epoch:24 step:22500 [D loss: 0.607481, acc.: 63.28%] [G loss: 0.658161]\n",
      "epoch:24 step:22501 [D loss: 0.526026, acc.: 71.09%] [G loss: 0.631887]\n",
      "epoch:24 step:22502 [D loss: 0.543984, acc.: 71.09%] [G loss: 0.589692]\n",
      "epoch:24 step:22503 [D loss: 0.511312, acc.: 76.56%] [G loss: 0.702731]\n",
      "epoch:24 step:22504 [D loss: 0.510963, acc.: 71.88%] [G loss: 0.861863]\n",
      "epoch:24 step:22505 [D loss: 0.506061, acc.: 75.00%] [G loss: 0.877451]\n",
      "epoch:24 step:22506 [D loss: 0.572106, acc.: 66.41%] [G loss: 0.615545]\n",
      "epoch:24 step:22507 [D loss: 0.595925, acc.: 64.06%] [G loss: 0.614720]\n",
      "epoch:24 step:22508 [D loss: 0.601168, acc.: 65.62%] [G loss: 0.593260]\n",
      "epoch:24 step:22509 [D loss: 0.584637, acc.: 71.09%] [G loss: 0.699949]\n",
      "epoch:24 step:22510 [D loss: 0.508661, acc.: 73.44%] [G loss: 0.818402]\n",
      "epoch:24 step:22511 [D loss: 0.538061, acc.: 74.22%] [G loss: 0.781934]\n",
      "epoch:24 step:22512 [D loss: 0.525420, acc.: 67.97%] [G loss: 0.634081]\n",
      "epoch:24 step:22513 [D loss: 0.505213, acc.: 72.66%] [G loss: 0.682908]\n",
      "epoch:24 step:22514 [D loss: 0.570490, acc.: 67.19%] [G loss: 0.606088]\n",
      "epoch:24 step:22515 [D loss: 0.438852, acc.: 78.91%] [G loss: 0.597736]\n",
      "epoch:24 step:22516 [D loss: 0.566266, acc.: 68.75%] [G loss: 0.694541]\n",
      "epoch:24 step:22517 [D loss: 0.561516, acc.: 68.75%] [G loss: 0.657813]\n",
      "epoch:24 step:22518 [D loss: 0.555058, acc.: 69.53%] [G loss: 0.806746]\n",
      "epoch:24 step:22519 [D loss: 0.584112, acc.: 67.19%] [G loss: 0.671348]\n",
      "epoch:24 step:22520 [D loss: 0.577543, acc.: 68.75%] [G loss: 0.648363]\n",
      "epoch:24 step:22521 [D loss: 0.518119, acc.: 70.31%] [G loss: 0.746673]\n",
      "epoch:24 step:22522 [D loss: 0.529036, acc.: 71.09%] [G loss: 0.592866]\n",
      "epoch:24 step:22523 [D loss: 0.590132, acc.: 69.53%] [G loss: 0.754874]\n",
      "epoch:24 step:22524 [D loss: 0.496555, acc.: 74.22%] [G loss: 0.793270]\n",
      "epoch:24 step:22525 [D loss: 0.492747, acc.: 75.00%] [G loss: 0.745840]\n",
      "epoch:24 step:22526 [D loss: 0.608785, acc.: 67.97%] [G loss: 0.553477]\n",
      "epoch:24 step:22527 [D loss: 0.528370, acc.: 75.00%] [G loss: 0.629151]\n",
      "epoch:24 step:22528 [D loss: 0.445143, acc.: 81.25%] [G loss: 0.932709]\n",
      "epoch:24 step:22529 [D loss: 0.586403, acc.: 69.53%] [G loss: 0.732941]\n",
      "epoch:24 step:22530 [D loss: 0.487271, acc.: 78.91%] [G loss: 0.706048]\n",
      "epoch:24 step:22531 [D loss: 0.565016, acc.: 65.62%] [G loss: 0.687369]\n",
      "epoch:24 step:22532 [D loss: 0.594527, acc.: 71.09%] [G loss: 0.771912]\n",
      "epoch:24 step:22533 [D loss: 0.518038, acc.: 75.78%] [G loss: 0.824767]\n",
      "epoch:24 step:22534 [D loss: 0.532201, acc.: 73.44%] [G loss: 0.692219]\n",
      "epoch:24 step:22535 [D loss: 0.498202, acc.: 72.66%] [G loss: 0.767197]\n",
      "epoch:24 step:22536 [D loss: 0.550118, acc.: 71.09%] [G loss: 0.697791]\n",
      "epoch:24 step:22537 [D loss: 0.475014, acc.: 74.22%] [G loss: 0.786936]\n",
      "epoch:24 step:22538 [D loss: 0.524635, acc.: 71.09%] [G loss: 0.781631]\n",
      "epoch:24 step:22539 [D loss: 0.681185, acc.: 57.03%] [G loss: 0.604855]\n",
      "epoch:24 step:22540 [D loss: 0.602374, acc.: 61.72%] [G loss: 0.494604]\n",
      "epoch:24 step:22541 [D loss: 0.507245, acc.: 78.12%] [G loss: 0.771116]\n",
      "epoch:24 step:22542 [D loss: 0.500597, acc.: 71.09%] [G loss: 0.815166]\n",
      "epoch:24 step:22543 [D loss: 0.570472, acc.: 64.84%] [G loss: 0.812306]\n",
      "epoch:24 step:22544 [D loss: 0.508007, acc.: 76.56%] [G loss: 0.548892]\n",
      "epoch:24 step:22545 [D loss: 0.478541, acc.: 74.22%] [G loss: 0.803441]\n",
      "epoch:24 step:22546 [D loss: 0.545141, acc.: 67.97%] [G loss: 0.842304]\n",
      "epoch:24 step:22547 [D loss: 0.505740, acc.: 75.00%] [G loss: 0.767388]\n",
      "epoch:24 step:22548 [D loss: 0.589838, acc.: 68.75%] [G loss: 0.722830]\n",
      "epoch:24 step:22549 [D loss: 0.555847, acc.: 74.22%] [G loss: 0.678604]\n",
      "epoch:24 step:22550 [D loss: 0.563332, acc.: 69.53%] [G loss: 0.672711]\n",
      "epoch:24 step:22551 [D loss: 0.537825, acc.: 73.44%] [G loss: 0.580957]\n",
      "epoch:24 step:22552 [D loss: 0.600342, acc.: 65.62%] [G loss: 0.632924]\n",
      "epoch:24 step:22553 [D loss: 0.555799, acc.: 67.97%] [G loss: 0.681614]\n",
      "epoch:24 step:22554 [D loss: 0.528871, acc.: 75.78%] [G loss: 0.612869]\n",
      "epoch:24 step:22555 [D loss: 0.615489, acc.: 64.06%] [G loss: 0.687344]\n",
      "epoch:24 step:22556 [D loss: 0.530249, acc.: 70.31%] [G loss: 0.650842]\n",
      "epoch:24 step:22557 [D loss: 0.477383, acc.: 75.00%] [G loss: 0.766704]\n",
      "epoch:24 step:22558 [D loss: 0.511966, acc.: 76.56%] [G loss: 0.632675]\n",
      "epoch:24 step:22559 [D loss: 0.515908, acc.: 73.44%] [G loss: 0.679864]\n",
      "epoch:24 step:22560 [D loss: 0.516893, acc.: 73.44%] [G loss: 0.606115]\n",
      "epoch:24 step:22561 [D loss: 0.555142, acc.: 67.19%] [G loss: 0.576380]\n",
      "epoch:24 step:22562 [D loss: 0.455676, acc.: 81.25%] [G loss: 0.713102]\n",
      "epoch:24 step:22563 [D loss: 0.514616, acc.: 75.78%] [G loss: 0.652453]\n",
      "epoch:24 step:22564 [D loss: 0.544169, acc.: 72.66%] [G loss: 0.813085]\n",
      "epoch:24 step:22565 [D loss: 0.495727, acc.: 77.34%] [G loss: 0.797538]\n",
      "epoch:24 step:22566 [D loss: 0.552489, acc.: 70.31%] [G loss: 0.822189]\n",
      "epoch:24 step:22567 [D loss: 0.548119, acc.: 67.97%] [G loss: 0.498664]\n",
      "epoch:24 step:22568 [D loss: 0.498603, acc.: 75.78%] [G loss: 0.653963]\n",
      "epoch:24 step:22569 [D loss: 0.540140, acc.: 67.19%] [G loss: 0.757627]\n",
      "epoch:24 step:22570 [D loss: 0.562315, acc.: 67.19%] [G loss: 0.717380]\n",
      "epoch:24 step:22571 [D loss: 0.439709, acc.: 82.81%] [G loss: 0.761094]\n",
      "epoch:24 step:22572 [D loss: 0.563185, acc.: 70.31%] [G loss: 0.812199]\n",
      "epoch:24 step:22573 [D loss: 0.588932, acc.: 64.84%] [G loss: 0.527871]\n",
      "epoch:24 step:22574 [D loss: 0.492364, acc.: 76.56%] [G loss: 0.689444]\n",
      "epoch:24 step:22575 [D loss: 0.506851, acc.: 75.00%] [G loss: 0.600027]\n",
      "epoch:24 step:22576 [D loss: 0.518779, acc.: 74.22%] [G loss: 0.685855]\n",
      "epoch:24 step:22577 [D loss: 0.514884, acc.: 74.22%] [G loss: 0.793020]\n",
      "epoch:24 step:22578 [D loss: 0.469883, acc.: 75.78%] [G loss: 0.807909]\n",
      "epoch:24 step:22579 [D loss: 0.584127, acc.: 69.53%] [G loss: 0.714206]\n",
      "epoch:24 step:22580 [D loss: 0.434890, acc.: 79.69%] [G loss: 0.758233]\n",
      "epoch:24 step:22581 [D loss: 0.493031, acc.: 75.78%] [G loss: 0.662270]\n",
      "epoch:24 step:22582 [D loss: 0.483840, acc.: 75.78%] [G loss: 0.848084]\n",
      "epoch:24 step:22583 [D loss: 0.490244, acc.: 74.22%] [G loss: 0.834124]\n",
      "epoch:24 step:22584 [D loss: 0.477911, acc.: 74.22%] [G loss: 0.755973]\n",
      "epoch:24 step:22585 [D loss: 0.477176, acc.: 75.00%] [G loss: 0.840251]\n",
      "epoch:24 step:22586 [D loss: 0.554393, acc.: 71.88%] [G loss: 0.775308]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:24 step:22587 [D loss: 0.617535, acc.: 66.41%] [G loss: 0.839715]\n",
      "epoch:24 step:22588 [D loss: 0.480021, acc.: 76.56%] [G loss: 0.952729]\n",
      "epoch:24 step:22589 [D loss: 0.577847, acc.: 73.44%] [G loss: 0.780767]\n",
      "epoch:24 step:22590 [D loss: 0.601901, acc.: 63.28%] [G loss: 0.744791]\n",
      "epoch:24 step:22591 [D loss: 0.565324, acc.: 70.31%] [G loss: 0.641683]\n",
      "epoch:24 step:22592 [D loss: 0.510542, acc.: 71.09%] [G loss: 0.612639]\n",
      "epoch:24 step:22593 [D loss: 0.650454, acc.: 60.16%] [G loss: 0.557732]\n",
      "epoch:24 step:22594 [D loss: 0.501026, acc.: 74.22%] [G loss: 0.582115]\n",
      "epoch:24 step:22595 [D loss: 0.558383, acc.: 75.00%] [G loss: 0.846894]\n",
      "epoch:24 step:22596 [D loss: 0.627576, acc.: 67.19%] [G loss: 0.672240]\n",
      "epoch:24 step:22597 [D loss: 0.623187, acc.: 67.19%] [G loss: 0.785140]\n",
      "epoch:24 step:22598 [D loss: 0.539038, acc.: 71.09%] [G loss: 0.562207]\n",
      "epoch:24 step:22599 [D loss: 0.480089, acc.: 75.00%] [G loss: 0.521091]\n",
      "epoch:24 step:22600 [D loss: 0.541530, acc.: 69.53%] [G loss: 0.605397]\n",
      "##############\n",
      "[3.2730167  1.12728444 5.86769197 4.7973239  4.04022977 5.51081761\n",
      " 4.45088283 4.70886667 4.62103553 4.33418408]\n",
      "##########\n",
      "epoch:24 step:22601 [D loss: 0.563510, acc.: 67.19%] [G loss: 0.452272]\n",
      "epoch:24 step:22602 [D loss: 0.558487, acc.: 71.09%] [G loss: 0.603378]\n",
      "epoch:24 step:22603 [D loss: 0.536229, acc.: 76.56%] [G loss: 0.665539]\n",
      "epoch:24 step:22604 [D loss: 0.509992, acc.: 72.66%] [G loss: 0.820635]\n",
      "epoch:24 step:22605 [D loss: 0.539313, acc.: 67.19%] [G loss: 0.557691]\n",
      "epoch:24 step:22606 [D loss: 0.505114, acc.: 74.22%] [G loss: 0.612918]\n",
      "epoch:24 step:22607 [D loss: 0.454730, acc.: 77.34%] [G loss: 0.760335]\n",
      "epoch:24 step:22608 [D loss: 0.503032, acc.: 74.22%] [G loss: 0.855606]\n",
      "epoch:24 step:22609 [D loss: 0.457086, acc.: 73.44%] [G loss: 0.731242]\n",
      "epoch:24 step:22610 [D loss: 0.504485, acc.: 76.56%] [G loss: 0.881994]\n",
      "epoch:24 step:22611 [D loss: 0.529391, acc.: 72.66%] [G loss: 0.948278]\n",
      "epoch:24 step:22612 [D loss: 0.576061, acc.: 68.75%] [G loss: 0.712670]\n",
      "epoch:24 step:22613 [D loss: 0.521538, acc.: 72.66%] [G loss: 0.741240]\n",
      "epoch:24 step:22614 [D loss: 0.484382, acc.: 76.56%] [G loss: 0.687353]\n",
      "epoch:24 step:22615 [D loss: 0.421304, acc.: 80.47%] [G loss: 0.867552]\n",
      "epoch:24 step:22616 [D loss: 0.549718, acc.: 71.88%] [G loss: 0.862948]\n",
      "epoch:24 step:22617 [D loss: 0.577118, acc.: 64.84%] [G loss: 0.553479]\n",
      "epoch:24 step:22618 [D loss: 0.477784, acc.: 78.91%] [G loss: 0.567470]\n",
      "epoch:24 step:22619 [D loss: 0.475311, acc.: 75.00%] [G loss: 0.774987]\n",
      "epoch:24 step:22620 [D loss: 0.521853, acc.: 73.44%] [G loss: 0.772990]\n",
      "epoch:24 step:22621 [D loss: 0.568455, acc.: 72.66%] [G loss: 0.885180]\n",
      "epoch:24 step:22622 [D loss: 0.523528, acc.: 72.66%] [G loss: 0.749489]\n",
      "epoch:24 step:22623 [D loss: 0.588115, acc.: 70.31%] [G loss: 0.814156]\n",
      "epoch:24 step:22624 [D loss: 0.496750, acc.: 78.91%] [G loss: 0.895485]\n",
      "epoch:24 step:22625 [D loss: 0.634739, acc.: 64.06%] [G loss: 0.721859]\n",
      "epoch:24 step:22626 [D loss: 0.612518, acc.: 65.62%] [G loss: 0.570046]\n",
      "epoch:24 step:22627 [D loss: 0.565467, acc.: 67.97%] [G loss: 0.689762]\n",
      "epoch:24 step:22628 [D loss: 0.598290, acc.: 66.41%] [G loss: 0.594230]\n",
      "epoch:24 step:22629 [D loss: 0.494445, acc.: 74.22%] [G loss: 0.607374]\n",
      "epoch:24 step:22630 [D loss: 0.584977, acc.: 61.72%] [G loss: 0.601343]\n",
      "epoch:24 step:22631 [D loss: 0.598850, acc.: 69.53%] [G loss: 0.486740]\n",
      "epoch:24 step:22632 [D loss: 0.540078, acc.: 70.31%] [G loss: 0.550312]\n",
      "epoch:24 step:22633 [D loss: 0.566186, acc.: 65.62%] [G loss: 0.620170]\n",
      "epoch:24 step:22634 [D loss: 0.478221, acc.: 81.25%] [G loss: 0.757866]\n",
      "epoch:24 step:22635 [D loss: 0.579408, acc.: 66.41%] [G loss: 0.659790]\n",
      "epoch:24 step:22636 [D loss: 0.549194, acc.: 66.41%] [G loss: 0.551139]\n",
      "epoch:24 step:22637 [D loss: 0.501110, acc.: 71.88%] [G loss: 0.655422]\n",
      "epoch:24 step:22638 [D loss: 0.525892, acc.: 70.31%] [G loss: 0.681724]\n",
      "epoch:24 step:22639 [D loss: 0.540416, acc.: 71.09%] [G loss: 0.827482]\n",
      "epoch:24 step:22640 [D loss: 0.486686, acc.: 74.22%] [G loss: 0.953883]\n",
      "epoch:24 step:22641 [D loss: 0.615780, acc.: 64.06%] [G loss: 0.670390]\n",
      "epoch:24 step:22642 [D loss: 0.550730, acc.: 68.75%] [G loss: 0.725671]\n",
      "epoch:24 step:22643 [D loss: 0.446954, acc.: 80.47%] [G loss: 0.599472]\n",
      "epoch:24 step:22644 [D loss: 0.516598, acc.: 75.00%] [G loss: 0.564197]\n",
      "epoch:24 step:22645 [D loss: 0.600780, acc.: 63.28%] [G loss: 0.604812]\n",
      "epoch:24 step:22646 [D loss: 0.512718, acc.: 71.09%] [G loss: 0.585763]\n",
      "epoch:24 step:22647 [D loss: 0.485179, acc.: 75.00%] [G loss: 0.814166]\n",
      "epoch:24 step:22648 [D loss: 0.574936, acc.: 67.19%] [G loss: 0.720973]\n",
      "epoch:24 step:22649 [D loss: 0.578272, acc.: 67.19%] [G loss: 0.829294]\n",
      "epoch:24 step:22650 [D loss: 0.478931, acc.: 75.00%] [G loss: 1.163971]\n",
      "epoch:24 step:22651 [D loss: 0.632665, acc.: 65.62%] [G loss: 0.899243]\n",
      "epoch:24 step:22652 [D loss: 0.580997, acc.: 69.53%] [G loss: 0.624396]\n",
      "epoch:24 step:22653 [D loss: 0.534309, acc.: 72.66%] [G loss: 0.562563]\n",
      "epoch:24 step:22654 [D loss: 0.577393, acc.: 63.28%] [G loss: 0.516461]\n",
      "epoch:24 step:22655 [D loss: 0.531684, acc.: 75.00%] [G loss: 0.523129]\n",
      "epoch:24 step:22656 [D loss: 0.506676, acc.: 74.22%] [G loss: 0.582001]\n",
      "epoch:24 step:22657 [D loss: 0.597013, acc.: 63.28%] [G loss: 0.587038]\n",
      "epoch:24 step:22658 [D loss: 0.561661, acc.: 70.31%] [G loss: 0.604238]\n",
      "epoch:24 step:22659 [D loss: 0.524662, acc.: 73.44%] [G loss: 0.654473]\n",
      "epoch:24 step:22660 [D loss: 0.581007, acc.: 71.88%] [G loss: 0.605088]\n",
      "epoch:24 step:22661 [D loss: 0.441662, acc.: 76.56%] [G loss: 0.804178]\n",
      "epoch:24 step:22662 [D loss: 0.535361, acc.: 70.31%] [G loss: 0.710712]\n",
      "epoch:24 step:22663 [D loss: 0.607765, acc.: 65.62%] [G loss: 0.595001]\n",
      "epoch:24 step:22664 [D loss: 0.521625, acc.: 73.44%] [G loss: 0.666934]\n",
      "epoch:24 step:22665 [D loss: 0.516631, acc.: 72.66%] [G loss: 0.735729]\n",
      "epoch:24 step:22666 [D loss: 0.620065, acc.: 62.50%] [G loss: 0.589952]\n",
      "epoch:24 step:22667 [D loss: 0.540122, acc.: 70.31%] [G loss: 0.720115]\n",
      "epoch:24 step:22668 [D loss: 0.591911, acc.: 64.84%] [G loss: 0.463956]\n",
      "epoch:24 step:22669 [D loss: 0.583705, acc.: 67.19%] [G loss: 0.532935]\n",
      "epoch:24 step:22670 [D loss: 0.510331, acc.: 77.34%] [G loss: 0.783359]\n",
      "epoch:24 step:22671 [D loss: 0.584524, acc.: 69.53%] [G loss: 0.726376]\n",
      "epoch:24 step:22672 [D loss: 0.579912, acc.: 67.97%] [G loss: 0.671120]\n",
      "epoch:24 step:22673 [D loss: 0.569795, acc.: 66.41%] [G loss: 0.603961]\n",
      "epoch:24 step:22674 [D loss: 0.566369, acc.: 64.84%] [G loss: 0.649052]\n",
      "epoch:24 step:22675 [D loss: 0.589350, acc.: 66.41%] [G loss: 0.570934]\n",
      "epoch:24 step:22676 [D loss: 0.554023, acc.: 68.75%] [G loss: 0.567110]\n",
      "epoch:24 step:22677 [D loss: 0.560014, acc.: 70.31%] [G loss: 0.493578]\n",
      "epoch:24 step:22678 [D loss: 0.457999, acc.: 78.12%] [G loss: 0.803741]\n",
      "epoch:24 step:22679 [D loss: 0.477713, acc.: 79.69%] [G loss: 0.686997]\n",
      "epoch:24 step:22680 [D loss: 0.557787, acc.: 69.53%] [G loss: 0.753323]\n",
      "epoch:24 step:22681 [D loss: 0.570843, acc.: 73.44%] [G loss: 0.734143]\n",
      "epoch:24 step:22682 [D loss: 0.434854, acc.: 80.47%] [G loss: 0.792610]\n",
      "epoch:24 step:22683 [D loss: 0.555534, acc.: 71.09%] [G loss: 0.637481]\n",
      "epoch:24 step:22684 [D loss: 0.544967, acc.: 69.53%] [G loss: 0.649302]\n",
      "epoch:24 step:22685 [D loss: 0.500316, acc.: 74.22%] [G loss: 0.755109]\n",
      "epoch:24 step:22686 [D loss: 0.554839, acc.: 69.53%] [G loss: 0.676207]\n",
      "epoch:24 step:22687 [D loss: 0.516057, acc.: 75.00%] [G loss: 0.782024]\n",
      "epoch:24 step:22688 [D loss: 0.627006, acc.: 67.97%] [G loss: 0.547301]\n",
      "epoch:24 step:22689 [D loss: 0.522594, acc.: 74.22%] [G loss: 0.776026]\n",
      "epoch:24 step:22690 [D loss: 0.569700, acc.: 66.41%] [G loss: 0.792053]\n",
      "epoch:24 step:22691 [D loss: 0.600987, acc.: 67.97%] [G loss: 0.718522]\n",
      "epoch:24 step:22692 [D loss: 0.487308, acc.: 75.78%] [G loss: 0.822442]\n",
      "epoch:24 step:22693 [D loss: 0.540512, acc.: 67.97%] [G loss: 0.703226]\n",
      "epoch:24 step:22694 [D loss: 0.507013, acc.: 75.00%] [G loss: 0.808698]\n",
      "epoch:24 step:22695 [D loss: 0.498487, acc.: 77.34%] [G loss: 0.807736]\n",
      "epoch:24 step:22696 [D loss: 0.439141, acc.: 81.25%] [G loss: 0.977118]\n",
      "epoch:24 step:22697 [D loss: 0.490765, acc.: 71.88%] [G loss: 1.021392]\n",
      "epoch:24 step:22698 [D loss: 0.676289, acc.: 58.59%] [G loss: 0.567469]\n",
      "epoch:24 step:22699 [D loss: 0.604245, acc.: 64.06%] [G loss: 0.559585]\n",
      "epoch:24 step:22700 [D loss: 0.471787, acc.: 77.34%] [G loss: 0.776730]\n",
      "epoch:24 step:22701 [D loss: 0.516448, acc.: 71.88%] [G loss: 0.639917]\n",
      "epoch:24 step:22702 [D loss: 0.616497, acc.: 68.75%] [G loss: 0.637446]\n",
      "epoch:24 step:22703 [D loss: 0.533184, acc.: 68.75%] [G loss: 0.559970]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:24 step:22704 [D loss: 0.530147, acc.: 71.09%] [G loss: 0.653820]\n",
      "epoch:24 step:22705 [D loss: 0.506088, acc.: 72.66%] [G loss: 0.689084]\n",
      "epoch:24 step:22706 [D loss: 0.494261, acc.: 75.78%] [G loss: 0.783798]\n",
      "epoch:24 step:22707 [D loss: 0.436056, acc.: 80.47%] [G loss: 0.887399]\n",
      "epoch:24 step:22708 [D loss: 0.721296, acc.: 60.94%] [G loss: 0.791757]\n",
      "epoch:24 step:22709 [D loss: 0.515859, acc.: 73.44%] [G loss: 0.717648]\n",
      "epoch:24 step:22710 [D loss: 0.485479, acc.: 76.56%] [G loss: 0.784307]\n",
      "epoch:24 step:22711 [D loss: 0.507865, acc.: 75.00%] [G loss: 0.723163]\n",
      "epoch:24 step:22712 [D loss: 0.577844, acc.: 70.31%] [G loss: 0.662899]\n",
      "epoch:24 step:22713 [D loss: 0.504623, acc.: 73.44%] [G loss: 0.757313]\n",
      "epoch:24 step:22714 [D loss: 0.611260, acc.: 59.38%] [G loss: 0.597365]\n",
      "epoch:24 step:22715 [D loss: 0.590628, acc.: 67.19%] [G loss: 0.711416]\n",
      "epoch:24 step:22716 [D loss: 0.571065, acc.: 64.84%] [G loss: 0.591134]\n",
      "epoch:24 step:22717 [D loss: 0.514233, acc.: 71.88%] [G loss: 0.722327]\n",
      "epoch:24 step:22718 [D loss: 0.536242, acc.: 74.22%] [G loss: 0.805692]\n",
      "epoch:24 step:22719 [D loss: 0.481914, acc.: 78.91%] [G loss: 1.025740]\n",
      "epoch:24 step:22720 [D loss: 0.447216, acc.: 81.25%] [G loss: 1.148004]\n",
      "epoch:24 step:22721 [D loss: 0.521837, acc.: 71.09%] [G loss: 0.839022]\n",
      "epoch:24 step:22722 [D loss: 0.627198, acc.: 65.62%] [G loss: 0.729537]\n",
      "epoch:24 step:22723 [D loss: 0.572255, acc.: 70.31%] [G loss: 0.689132]\n",
      "epoch:24 step:22724 [D loss: 0.542834, acc.: 66.41%] [G loss: 0.530558]\n",
      "epoch:24 step:22725 [D loss: 0.568360, acc.: 65.62%] [G loss: 0.650392]\n",
      "epoch:24 step:22726 [D loss: 0.612228, acc.: 63.28%] [G loss: 0.474785]\n",
      "epoch:24 step:22727 [D loss: 0.543484, acc.: 71.88%] [G loss: 0.753692]\n",
      "epoch:24 step:22728 [D loss: 0.603096, acc.: 66.41%] [G loss: 0.673655]\n",
      "epoch:24 step:22729 [D loss: 0.508877, acc.: 71.09%] [G loss: 0.725945]\n",
      "epoch:24 step:22730 [D loss: 0.537766, acc.: 70.31%] [G loss: 0.949714]\n",
      "epoch:24 step:22731 [D loss: 0.554298, acc.: 67.19%] [G loss: 0.813850]\n",
      "epoch:24 step:22732 [D loss: 0.499233, acc.: 72.66%] [G loss: 0.659981]\n",
      "epoch:24 step:22733 [D loss: 0.501213, acc.: 75.00%] [G loss: 0.745293]\n",
      "epoch:24 step:22734 [D loss: 0.516343, acc.: 69.53%] [G loss: 0.802392]\n",
      "epoch:24 step:22735 [D loss: 0.503766, acc.: 71.09%] [G loss: 0.784202]\n",
      "epoch:24 step:22736 [D loss: 0.465674, acc.: 78.12%] [G loss: 0.783543]\n",
      "epoch:24 step:22737 [D loss: 0.609077, acc.: 64.84%] [G loss: 0.762668]\n",
      "epoch:24 step:22738 [D loss: 0.588532, acc.: 63.28%] [G loss: 0.754926]\n",
      "epoch:24 step:22739 [D loss: 0.629972, acc.: 61.72%] [G loss: 0.542541]\n",
      "epoch:24 step:22740 [D loss: 0.575600, acc.: 67.97%] [G loss: 0.620399]\n",
      "epoch:24 step:22741 [D loss: 0.577570, acc.: 64.06%] [G loss: 0.732826]\n",
      "epoch:24 step:22742 [D loss: 0.510406, acc.: 71.88%] [G loss: 0.624799]\n",
      "epoch:24 step:22743 [D loss: 0.520679, acc.: 67.97%] [G loss: 0.531375]\n",
      "epoch:24 step:22744 [D loss: 0.555458, acc.: 66.41%] [G loss: 0.480962]\n",
      "epoch:24 step:22745 [D loss: 0.560967, acc.: 66.41%] [G loss: 0.675486]\n",
      "epoch:24 step:22746 [D loss: 0.484812, acc.: 75.00%] [G loss: 0.650028]\n",
      "epoch:24 step:22747 [D loss: 0.541135, acc.: 68.75%] [G loss: 0.637832]\n",
      "epoch:24 step:22748 [D loss: 0.537920, acc.: 66.41%] [G loss: 0.558736]\n",
      "epoch:24 step:22749 [D loss: 0.524213, acc.: 73.44%] [G loss: 0.715345]\n",
      "epoch:24 step:22750 [D loss: 0.510062, acc.: 71.09%] [G loss: 0.750359]\n",
      "epoch:24 step:22751 [D loss: 0.560672, acc.: 71.88%] [G loss: 0.691004]\n",
      "epoch:24 step:22752 [D loss: 0.490939, acc.: 75.78%] [G loss: 0.638548]\n",
      "epoch:24 step:22753 [D loss: 0.525105, acc.: 71.88%] [G loss: 0.803329]\n",
      "epoch:24 step:22754 [D loss: 0.557224, acc.: 68.75%] [G loss: 0.581869]\n",
      "epoch:24 step:22755 [D loss: 0.556635, acc.: 68.75%] [G loss: 0.664198]\n",
      "epoch:24 step:22756 [D loss: 0.541984, acc.: 71.09%] [G loss: 0.607993]\n",
      "epoch:24 step:22757 [D loss: 0.552121, acc.: 70.31%] [G loss: 0.466342]\n",
      "epoch:24 step:22758 [D loss: 0.502787, acc.: 74.22%] [G loss: 0.584014]\n",
      "epoch:24 step:22759 [D loss: 0.501930, acc.: 76.56%] [G loss: 0.654282]\n",
      "epoch:24 step:22760 [D loss: 0.573904, acc.: 68.75%] [G loss: 0.752234]\n",
      "epoch:24 step:22761 [D loss: 0.536478, acc.: 71.09%] [G loss: 0.667638]\n",
      "epoch:24 step:22762 [D loss: 0.505090, acc.: 75.00%] [G loss: 0.618887]\n",
      "epoch:24 step:22763 [D loss: 0.521342, acc.: 74.22%] [G loss: 0.668269]\n",
      "epoch:24 step:22764 [D loss: 0.479596, acc.: 79.69%] [G loss: 0.669144]\n",
      "epoch:24 step:22765 [D loss: 0.646771, acc.: 61.72%] [G loss: 0.657092]\n",
      "epoch:24 step:22766 [D loss: 0.683659, acc.: 60.16%] [G loss: 0.571802]\n",
      "epoch:24 step:22767 [D loss: 0.569595, acc.: 68.75%] [G loss: 0.565883]\n",
      "epoch:24 step:22768 [D loss: 0.505748, acc.: 71.88%] [G loss: 0.685606]\n",
      "epoch:24 step:22769 [D loss: 0.585386, acc.: 68.75%] [G loss: 0.553467]\n",
      "epoch:24 step:22770 [D loss: 0.529515, acc.: 71.88%] [G loss: 0.655989]\n",
      "epoch:24 step:22771 [D loss: 0.573243, acc.: 68.75%] [G loss: 0.500380]\n",
      "epoch:24 step:22772 [D loss: 0.522711, acc.: 70.31%] [G loss: 0.776270]\n",
      "epoch:24 step:22773 [D loss: 0.526018, acc.: 70.31%] [G loss: 0.741754]\n",
      "epoch:24 step:22774 [D loss: 0.517619, acc.: 72.66%] [G loss: 0.697010]\n",
      "epoch:24 step:22775 [D loss: 0.569422, acc.: 67.19%] [G loss: 0.632572]\n",
      "epoch:24 step:22776 [D loss: 0.510534, acc.: 73.44%] [G loss: 0.706911]\n",
      "epoch:24 step:22777 [D loss: 0.542724, acc.: 69.53%] [G loss: 0.789011]\n",
      "epoch:24 step:22778 [D loss: 0.510842, acc.: 73.44%] [G loss: 0.706459]\n",
      "epoch:24 step:22779 [D loss: 0.597523, acc.: 70.31%] [G loss: 0.645381]\n",
      "epoch:24 step:22780 [D loss: 0.492302, acc.: 76.56%] [G loss: 0.657748]\n",
      "epoch:24 step:22781 [D loss: 0.611919, acc.: 67.19%] [G loss: 0.521140]\n",
      "epoch:24 step:22782 [D loss: 0.589558, acc.: 67.19%] [G loss: 0.446978]\n",
      "epoch:24 step:22783 [D loss: 0.572353, acc.: 67.97%] [G loss: 0.540129]\n",
      "epoch:24 step:22784 [D loss: 0.454231, acc.: 78.91%] [G loss: 0.663838]\n",
      "epoch:24 step:22785 [D loss: 0.526179, acc.: 72.66%] [G loss: 0.534202]\n",
      "epoch:24 step:22786 [D loss: 0.456901, acc.: 76.56%] [G loss: 0.613914]\n",
      "epoch:24 step:22787 [D loss: 0.486247, acc.: 75.78%] [G loss: 0.754564]\n",
      "epoch:24 step:22788 [D loss: 0.487028, acc.: 76.56%] [G loss: 0.734121]\n",
      "epoch:24 step:22789 [D loss: 0.616679, acc.: 64.06%] [G loss: 0.673586]\n",
      "epoch:24 step:22790 [D loss: 0.569478, acc.: 67.19%] [G loss: 0.547218]\n",
      "epoch:24 step:22791 [D loss: 0.550426, acc.: 69.53%] [G loss: 0.550738]\n",
      "epoch:24 step:22792 [D loss: 0.511921, acc.: 72.66%] [G loss: 0.693671]\n",
      "epoch:24 step:22793 [D loss: 0.513725, acc.: 72.66%] [G loss: 0.724420]\n",
      "epoch:24 step:22794 [D loss: 0.505359, acc.: 77.34%] [G loss: 0.651937]\n",
      "epoch:24 step:22795 [D loss: 0.505861, acc.: 70.31%] [G loss: 0.859539]\n",
      "epoch:24 step:22796 [D loss: 0.598026, acc.: 65.62%] [G loss: 0.523999]\n",
      "epoch:24 step:22797 [D loss: 0.473048, acc.: 77.34%] [G loss: 0.676988]\n",
      "epoch:24 step:22798 [D loss: 0.538155, acc.: 69.53%] [G loss: 0.574079]\n",
      "epoch:24 step:22799 [D loss: 0.512449, acc.: 71.09%] [G loss: 0.756629]\n",
      "epoch:24 step:22800 [D loss: 0.475756, acc.: 80.47%] [G loss: 0.975792]\n",
      "##############\n",
      "[2.85907472 0.91270084 6.19120878 4.82025587 3.73545207 5.67317218\n",
      " 4.46169172 4.89233521 4.80303851 4.30693356]\n",
      "##########\n",
      "epoch:24 step:22801 [D loss: 0.487359, acc.: 73.44%] [G loss: 0.931455]\n",
      "epoch:24 step:22802 [D loss: 0.479392, acc.: 75.78%] [G loss: 0.967903]\n",
      "epoch:24 step:22803 [D loss: 0.437514, acc.: 82.03%] [G loss: 0.997593]\n",
      "epoch:24 step:22804 [D loss: 0.671685, acc.: 67.97%] [G loss: 0.746141]\n",
      "epoch:24 step:22805 [D loss: 0.550830, acc.: 67.97%] [G loss: 0.480661]\n",
      "epoch:24 step:22806 [D loss: 0.531008, acc.: 70.31%] [G loss: 0.658920]\n",
      "epoch:24 step:22807 [D loss: 0.551337, acc.: 74.22%] [G loss: 0.690204]\n",
      "epoch:24 step:22808 [D loss: 0.542098, acc.: 73.44%] [G loss: 0.610891]\n",
      "epoch:24 step:22809 [D loss: 0.484515, acc.: 75.78%] [G loss: 0.682964]\n",
      "epoch:24 step:22810 [D loss: 0.631880, acc.: 64.84%] [G loss: 0.607133]\n",
      "epoch:24 step:22811 [D loss: 0.559972, acc.: 70.31%] [G loss: 0.607296]\n",
      "epoch:24 step:22812 [D loss: 0.579517, acc.: 64.84%] [G loss: 0.537141]\n",
      "epoch:24 step:22813 [D loss: 0.561165, acc.: 73.44%] [G loss: 0.615598]\n",
      "epoch:24 step:22814 [D loss: 0.464757, acc.: 78.12%] [G loss: 0.614436]\n",
      "epoch:24 step:22815 [D loss: 0.527017, acc.: 66.41%] [G loss: 0.748713]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:24 step:22816 [D loss: 0.426224, acc.: 75.78%] [G loss: 0.853870]\n",
      "epoch:24 step:22817 [D loss: 0.529806, acc.: 72.66%] [G loss: 0.697422]\n",
      "epoch:24 step:22818 [D loss: 0.607543, acc.: 62.50%] [G loss: 0.560546]\n",
      "epoch:24 step:22819 [D loss: 0.545503, acc.: 71.88%] [G loss: 0.563465]\n",
      "epoch:24 step:22820 [D loss: 0.490640, acc.: 75.00%] [G loss: 0.595195]\n",
      "epoch:24 step:22821 [D loss: 0.532658, acc.: 72.66%] [G loss: 0.583246]\n",
      "epoch:24 step:22822 [D loss: 0.461763, acc.: 75.00%] [G loss: 0.623164]\n",
      "epoch:24 step:22823 [D loss: 0.521297, acc.: 75.78%] [G loss: 1.081447]\n",
      "epoch:24 step:22824 [D loss: 0.495593, acc.: 77.34%] [G loss: 0.729282]\n",
      "epoch:24 step:22825 [D loss: 0.503423, acc.: 75.78%] [G loss: 0.665608]\n",
      "epoch:24 step:22826 [D loss: 0.544831, acc.: 70.31%] [G loss: 0.722960]\n",
      "epoch:24 step:22827 [D loss: 0.528352, acc.: 69.53%] [G loss: 0.932746]\n",
      "epoch:24 step:22828 [D loss: 0.460801, acc.: 77.34%] [G loss: 1.091343]\n",
      "epoch:24 step:22829 [D loss: 0.592129, acc.: 71.09%] [G loss: 0.756231]\n",
      "epoch:24 step:22830 [D loss: 0.625355, acc.: 64.84%] [G loss: 0.607425]\n",
      "epoch:24 step:22831 [D loss: 0.490812, acc.: 75.78%] [G loss: 0.802266]\n",
      "epoch:24 step:22832 [D loss: 0.461320, acc.: 75.78%] [G loss: 0.939666]\n",
      "epoch:24 step:22833 [D loss: 0.585133, acc.: 68.75%] [G loss: 0.686991]\n",
      "epoch:24 step:22834 [D loss: 0.478425, acc.: 75.78%] [G loss: 0.940870]\n",
      "epoch:24 step:22835 [D loss: 0.454010, acc.: 75.78%] [G loss: 1.063942]\n",
      "epoch:24 step:22836 [D loss: 0.636516, acc.: 64.84%] [G loss: 0.686243]\n",
      "epoch:24 step:22837 [D loss: 0.769666, acc.: 54.69%] [G loss: 0.510639]\n",
      "epoch:24 step:22838 [D loss: 0.462197, acc.: 78.91%] [G loss: 0.555830]\n",
      "epoch:24 step:22839 [D loss: 0.533637, acc.: 70.31%] [G loss: 0.594447]\n",
      "epoch:24 step:22840 [D loss: 0.537222, acc.: 74.22%] [G loss: 0.714659]\n",
      "epoch:24 step:22841 [D loss: 0.590657, acc.: 64.84%] [G loss: 0.672409]\n",
      "epoch:24 step:22842 [D loss: 0.384474, acc.: 84.38%] [G loss: 0.866825]\n",
      "epoch:24 step:22843 [D loss: 0.511058, acc.: 70.31%] [G loss: 0.842671]\n",
      "epoch:24 step:22844 [D loss: 0.563629, acc.: 71.09%] [G loss: 0.719774]\n",
      "epoch:24 step:22845 [D loss: 0.428061, acc.: 77.34%] [G loss: 0.823975]\n",
      "epoch:24 step:22846 [D loss: 0.478944, acc.: 76.56%] [G loss: 0.901894]\n",
      "epoch:24 step:22847 [D loss: 0.434819, acc.: 79.69%] [G loss: 1.052471]\n",
      "epoch:24 step:22848 [D loss: 0.535597, acc.: 69.53%] [G loss: 0.829419]\n",
      "epoch:24 step:22849 [D loss: 0.474846, acc.: 75.78%] [G loss: 0.976569]\n",
      "epoch:24 step:22850 [D loss: 0.534285, acc.: 75.00%] [G loss: 0.880958]\n",
      "epoch:24 step:22851 [D loss: 0.563737, acc.: 70.31%] [G loss: 0.797793]\n",
      "epoch:24 step:22852 [D loss: 0.538947, acc.: 69.53%] [G loss: 0.650663]\n",
      "epoch:24 step:22853 [D loss: 0.551259, acc.: 69.53%] [G loss: 0.630861]\n",
      "epoch:24 step:22854 [D loss: 0.561359, acc.: 65.62%] [G loss: 0.627598]\n",
      "epoch:24 step:22855 [D loss: 0.545090, acc.: 73.44%] [G loss: 0.654759]\n",
      "epoch:24 step:22856 [D loss: 0.522794, acc.: 77.34%] [G loss: 0.580547]\n",
      "epoch:24 step:22857 [D loss: 0.460169, acc.: 76.56%] [G loss: 0.804032]\n",
      "epoch:24 step:22858 [D loss: 0.508641, acc.: 74.22%] [G loss: 0.584562]\n",
      "epoch:24 step:22859 [D loss: 0.482274, acc.: 78.91%] [G loss: 0.767673]\n",
      "epoch:24 step:22860 [D loss: 0.604992, acc.: 67.97%] [G loss: 0.755646]\n",
      "epoch:24 step:22861 [D loss: 0.505917, acc.: 75.78%] [G loss: 0.836834]\n",
      "epoch:24 step:22862 [D loss: 0.478539, acc.: 80.47%] [G loss: 0.789456]\n",
      "epoch:24 step:22863 [D loss: 0.599789, acc.: 67.97%] [G loss: 0.752818]\n",
      "epoch:24 step:22864 [D loss: 0.667490, acc.: 62.50%] [G loss: 0.520709]\n",
      "epoch:24 step:22865 [D loss: 0.555933, acc.: 69.53%] [G loss: 0.536205]\n",
      "epoch:24 step:22866 [D loss: 0.529107, acc.: 72.66%] [G loss: 0.653159]\n",
      "epoch:24 step:22867 [D loss: 0.570158, acc.: 72.66%] [G loss: 0.575966]\n",
      "epoch:24 step:22868 [D loss: 0.599928, acc.: 68.75%] [G loss: 0.610718]\n",
      "epoch:24 step:22869 [D loss: 0.453041, acc.: 75.78%] [G loss: 0.634459]\n",
      "epoch:24 step:22870 [D loss: 0.523200, acc.: 75.00%] [G loss: 0.692631]\n",
      "epoch:24 step:22871 [D loss: 0.526089, acc.: 75.00%] [G loss: 0.772199]\n",
      "epoch:24 step:22872 [D loss: 0.531988, acc.: 71.09%] [G loss: 0.659200]\n",
      "epoch:24 step:22873 [D loss: 0.435912, acc.: 82.03%] [G loss: 0.664201]\n",
      "epoch:24 step:22874 [D loss: 0.592824, acc.: 64.84%] [G loss: 0.648325]\n",
      "epoch:24 step:22875 [D loss: 0.538179, acc.: 70.31%] [G loss: 0.700395]\n",
      "epoch:24 step:22876 [D loss: 0.523968, acc.: 74.22%] [G loss: 0.820177]\n",
      "epoch:24 step:22877 [D loss: 0.513412, acc.: 72.66%] [G loss: 0.658375]\n",
      "epoch:24 step:22878 [D loss: 0.585810, acc.: 64.06%] [G loss: 0.763874]\n",
      "epoch:24 step:22879 [D loss: 0.531973, acc.: 70.31%] [G loss: 0.696645]\n",
      "epoch:24 step:22880 [D loss: 0.473015, acc.: 76.56%] [G loss: 0.835503]\n",
      "epoch:24 step:22881 [D loss: 0.567829, acc.: 72.66%] [G loss: 0.586311]\n",
      "epoch:24 step:22882 [D loss: 0.550316, acc.: 70.31%] [G loss: 0.467532]\n",
      "epoch:24 step:22883 [D loss: 0.524858, acc.: 74.22%] [G loss: 0.464930]\n",
      "epoch:24 step:22884 [D loss: 0.557978, acc.: 71.88%] [G loss: 0.516214]\n",
      "epoch:24 step:22885 [D loss: 0.551112, acc.: 69.53%] [G loss: 0.818575]\n",
      "epoch:24 step:22886 [D loss: 0.481299, acc.: 71.88%] [G loss: 0.800909]\n",
      "epoch:24 step:22887 [D loss: 0.495964, acc.: 78.91%] [G loss: 0.952353]\n",
      "epoch:24 step:22888 [D loss: 0.613938, acc.: 63.28%] [G loss: 0.596856]\n",
      "epoch:24 step:22889 [D loss: 0.751568, acc.: 54.69%] [G loss: 0.423447]\n",
      "epoch:24 step:22890 [D loss: 0.484876, acc.: 77.34%] [G loss: 0.754804]\n",
      "epoch:24 step:22891 [D loss: 0.470487, acc.: 74.22%] [G loss: 0.745524]\n",
      "epoch:24 step:22892 [D loss: 0.569624, acc.: 67.97%] [G loss: 0.687493]\n",
      "epoch:24 step:22893 [D loss: 0.525368, acc.: 69.53%] [G loss: 0.665816]\n",
      "epoch:24 step:22894 [D loss: 0.483524, acc.: 73.44%] [G loss: 0.791803]\n",
      "epoch:24 step:22895 [D loss: 0.591361, acc.: 66.41%] [G loss: 0.738806]\n",
      "epoch:24 step:22896 [D loss: 0.551890, acc.: 66.41%] [G loss: 0.839958]\n",
      "epoch:24 step:22897 [D loss: 0.534539, acc.: 75.00%] [G loss: 0.658883]\n",
      "epoch:24 step:22898 [D loss: 0.547203, acc.: 67.19%] [G loss: 0.633617]\n",
      "epoch:24 step:22899 [D loss: 0.599822, acc.: 66.41%] [G loss: 0.499666]\n",
      "epoch:24 step:22900 [D loss: 0.612377, acc.: 65.62%] [G loss: 0.635525]\n",
      "epoch:24 step:22901 [D loss: 0.548296, acc.: 75.78%] [G loss: 0.682471]\n",
      "epoch:24 step:22902 [D loss: 0.493320, acc.: 75.00%] [G loss: 0.904242]\n",
      "epoch:24 step:22903 [D loss: 0.502472, acc.: 68.75%] [G loss: 0.895989]\n",
      "epoch:24 step:22904 [D loss: 0.468516, acc.: 78.91%] [G loss: 0.715985]\n",
      "epoch:24 step:22905 [D loss: 0.564132, acc.: 67.19%] [G loss: 0.737727]\n",
      "epoch:24 step:22906 [D loss: 0.646160, acc.: 67.19%] [G loss: 0.854652]\n",
      "epoch:24 step:22907 [D loss: 0.562666, acc.: 68.75%] [G loss: 0.737981]\n",
      "epoch:24 step:22908 [D loss: 0.610629, acc.: 61.72%] [G loss: 0.770929]\n",
      "epoch:24 step:22909 [D loss: 0.537858, acc.: 71.88%] [G loss: 0.623360]\n",
      "epoch:24 step:22910 [D loss: 0.608989, acc.: 65.62%] [G loss: 0.416829]\n",
      "epoch:24 step:22911 [D loss: 0.570496, acc.: 68.75%] [G loss: 0.636010]\n",
      "epoch:24 step:22912 [D loss: 0.562745, acc.: 67.97%] [G loss: 0.581395]\n",
      "epoch:24 step:22913 [D loss: 0.553735, acc.: 69.53%] [G loss: 0.855717]\n",
      "epoch:24 step:22914 [D loss: 0.517705, acc.: 75.00%] [G loss: 0.806780]\n",
      "epoch:24 step:22915 [D loss: 0.474475, acc.: 75.00%] [G loss: 1.004743]\n",
      "epoch:24 step:22916 [D loss: 0.533202, acc.: 69.53%] [G loss: 0.889932]\n",
      "epoch:24 step:22917 [D loss: 0.411253, acc.: 83.59%] [G loss: 0.958067]\n",
      "epoch:24 step:22918 [D loss: 0.529131, acc.: 75.00%] [G loss: 0.816995]\n",
      "epoch:24 step:22919 [D loss: 0.528970, acc.: 75.00%] [G loss: 0.970522]\n",
      "epoch:24 step:22920 [D loss: 0.563777, acc.: 69.53%] [G loss: 0.661719]\n",
      "epoch:24 step:22921 [D loss: 0.545315, acc.: 70.31%] [G loss: 0.521879]\n",
      "epoch:24 step:22922 [D loss: 0.526765, acc.: 71.88%] [G loss: 0.631712]\n",
      "epoch:24 step:22923 [D loss: 0.497651, acc.: 70.31%] [G loss: 0.909299]\n",
      "epoch:24 step:22924 [D loss: 0.462628, acc.: 77.34%] [G loss: 0.690295]\n",
      "epoch:24 step:22925 [D loss: 0.636809, acc.: 70.31%] [G loss: 0.647541]\n",
      "epoch:24 step:22926 [D loss: 0.533856, acc.: 71.88%] [G loss: 0.627494]\n",
      "epoch:24 step:22927 [D loss: 0.505639, acc.: 73.44%] [G loss: 0.638466]\n",
      "epoch:24 step:22928 [D loss: 0.480869, acc.: 75.78%] [G loss: 0.732100]\n",
      "epoch:24 step:22929 [D loss: 0.560553, acc.: 67.97%] [G loss: 0.767809]\n",
      "epoch:24 step:22930 [D loss: 0.587674, acc.: 67.97%] [G loss: 0.880727]\n",
      "epoch:24 step:22931 [D loss: 0.547285, acc.: 68.75%] [G loss: 0.767463]\n",
      "epoch:24 step:22932 [D loss: 0.501133, acc.: 75.00%] [G loss: 0.820399]\n",
      "epoch:24 step:22933 [D loss: 0.571274, acc.: 65.62%] [G loss: 0.969144]\n",
      "epoch:24 step:22934 [D loss: 0.493823, acc.: 75.78%] [G loss: 0.774123]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:24 step:22935 [D loss: 0.517719, acc.: 69.53%] [G loss: 0.691390]\n",
      "epoch:24 step:22936 [D loss: 0.496813, acc.: 71.09%] [G loss: 0.794519]\n",
      "epoch:24 step:22937 [D loss: 0.534027, acc.: 71.88%] [G loss: 0.756533]\n",
      "epoch:24 step:22938 [D loss: 0.514619, acc.: 74.22%] [G loss: 0.749474]\n",
      "epoch:24 step:22939 [D loss: 0.417965, acc.: 83.59%] [G loss: 0.765627]\n",
      "epoch:24 step:22940 [D loss: 0.482496, acc.: 77.34%] [G loss: 0.878136]\n",
      "epoch:24 step:22941 [D loss: 0.528793, acc.: 70.31%] [G loss: 0.832406]\n",
      "epoch:24 step:22942 [D loss: 0.536654, acc.: 70.31%] [G loss: 0.767720]\n",
      "epoch:24 step:22943 [D loss: 0.503312, acc.: 73.44%] [G loss: 0.623245]\n",
      "epoch:24 step:22944 [D loss: 0.649634, acc.: 64.06%] [G loss: 0.683801]\n",
      "epoch:24 step:22945 [D loss: 0.491616, acc.: 74.22%] [G loss: 0.816339]\n",
      "epoch:24 step:22946 [D loss: 0.632113, acc.: 66.41%] [G loss: 0.577400]\n",
      "epoch:24 step:22947 [D loss: 0.500165, acc.: 74.22%] [G loss: 0.685353]\n",
      "epoch:24 step:22948 [D loss: 0.476078, acc.: 82.81%] [G loss: 0.679417]\n",
      "epoch:24 step:22949 [D loss: 0.489403, acc.: 77.34%] [G loss: 0.868840]\n",
      "epoch:24 step:22950 [D loss: 0.550939, acc.: 67.97%] [G loss: 0.594231]\n",
      "epoch:24 step:22951 [D loss: 0.544507, acc.: 66.41%] [G loss: 0.623965]\n",
      "epoch:24 step:22952 [D loss: 0.561383, acc.: 67.19%] [G loss: 0.619903]\n",
      "epoch:24 step:22953 [D loss: 0.556814, acc.: 75.78%] [G loss: 0.740241]\n",
      "epoch:24 step:22954 [D loss: 0.591724, acc.: 66.41%] [G loss: 0.617466]\n",
      "epoch:24 step:22955 [D loss: 0.532006, acc.: 69.53%] [G loss: 0.736045]\n",
      "epoch:24 step:22956 [D loss: 0.547457, acc.: 67.19%] [G loss: 0.856040]\n",
      "epoch:24 step:22957 [D loss: 0.525289, acc.: 67.97%] [G loss: 0.726110]\n",
      "epoch:24 step:22958 [D loss: 0.490991, acc.: 76.56%] [G loss: 0.980464]\n",
      "epoch:24 step:22959 [D loss: 0.463198, acc.: 76.56%] [G loss: 0.846406]\n",
      "epoch:24 step:22960 [D loss: 0.428517, acc.: 83.59%] [G loss: 0.892051]\n",
      "epoch:24 step:22961 [D loss: 0.630913, acc.: 62.50%] [G loss: 0.622606]\n",
      "epoch:24 step:22962 [D loss: 0.523607, acc.: 66.41%] [G loss: 0.766990]\n",
      "epoch:24 step:22963 [D loss: 0.478442, acc.: 75.78%] [G loss: 0.801824]\n",
      "epoch:24 step:22964 [D loss: 0.465321, acc.: 82.81%] [G loss: 0.831108]\n",
      "epoch:24 step:22965 [D loss: 0.720704, acc.: 63.28%] [G loss: 0.601410]\n",
      "epoch:24 step:22966 [D loss: 0.563948, acc.: 70.31%] [G loss: 0.609668]\n",
      "epoch:24 step:22967 [D loss: 0.522690, acc.: 75.00%] [G loss: 0.651625]\n",
      "epoch:24 step:22968 [D loss: 0.623598, acc.: 64.84%] [G loss: 0.565205]\n",
      "epoch:24 step:22969 [D loss: 0.523281, acc.: 71.09%] [G loss: 0.569419]\n",
      "epoch:24 step:22970 [D loss: 0.591265, acc.: 69.53%] [G loss: 0.598159]\n",
      "epoch:24 step:22971 [D loss: 0.542366, acc.: 70.31%] [G loss: 0.738041]\n",
      "epoch:24 step:22972 [D loss: 0.503459, acc.: 73.44%] [G loss: 0.612081]\n",
      "epoch:24 step:22973 [D loss: 0.508012, acc.: 76.56%] [G loss: 0.780046]\n",
      "epoch:24 step:22974 [D loss: 0.542399, acc.: 68.75%] [G loss: 0.650072]\n",
      "epoch:24 step:22975 [D loss: 0.546142, acc.: 73.44%] [G loss: 0.555367]\n",
      "epoch:24 step:22976 [D loss: 0.488481, acc.: 74.22%] [G loss: 0.606406]\n",
      "epoch:24 step:22977 [D loss: 0.527000, acc.: 71.09%] [G loss: 0.789608]\n",
      "epoch:24 step:22978 [D loss: 0.590279, acc.: 69.53%] [G loss: 0.708112]\n",
      "epoch:24 step:22979 [D loss: 0.514952, acc.: 74.22%] [G loss: 0.625788]\n",
      "epoch:24 step:22980 [D loss: 0.607254, acc.: 66.41%] [G loss: 0.758607]\n",
      "epoch:24 step:22981 [D loss: 0.530475, acc.: 75.78%] [G loss: 0.595400]\n",
      "epoch:24 step:22982 [D loss: 0.592378, acc.: 64.06%] [G loss: 0.741899]\n",
      "epoch:24 step:22983 [D loss: 0.528754, acc.: 71.09%] [G loss: 0.605529]\n",
      "epoch:24 step:22984 [D loss: 0.552708, acc.: 64.84%] [G loss: 0.681422]\n",
      "epoch:24 step:22985 [D loss: 0.558613, acc.: 72.66%] [G loss: 0.731493]\n",
      "epoch:24 step:22986 [D loss: 0.584331, acc.: 67.19%] [G loss: 0.828689]\n",
      "epoch:24 step:22987 [D loss: 0.514833, acc.: 74.22%] [G loss: 0.750268]\n",
      "epoch:24 step:22988 [D loss: 0.530368, acc.: 74.22%] [G loss: 0.626523]\n",
      "epoch:24 step:22989 [D loss: 0.600235, acc.: 64.06%] [G loss: 0.663705]\n",
      "epoch:24 step:22990 [D loss: 0.619598, acc.: 61.72%] [G loss: 0.527341]\n",
      "epoch:24 step:22991 [D loss: 0.514144, acc.: 72.66%] [G loss: 0.643048]\n",
      "epoch:24 step:22992 [D loss: 0.430844, acc.: 82.03%] [G loss: 0.774147]\n",
      "epoch:24 step:22993 [D loss: 0.453872, acc.: 79.69%] [G loss: 0.942250]\n",
      "epoch:24 step:22994 [D loss: 0.539322, acc.: 71.88%] [G loss: 0.848835]\n",
      "epoch:24 step:22995 [D loss: 0.504952, acc.: 78.91%] [G loss: 0.763495]\n",
      "epoch:24 step:22996 [D loss: 0.414979, acc.: 82.81%] [G loss: 0.846883]\n",
      "epoch:24 step:22997 [D loss: 0.547650, acc.: 67.19%] [G loss: 0.797575]\n",
      "epoch:24 step:22998 [D loss: 0.574378, acc.: 68.75%] [G loss: 0.667236]\n",
      "epoch:24 step:22999 [D loss: 0.678670, acc.: 54.69%] [G loss: 0.550994]\n",
      "epoch:24 step:23000 [D loss: 0.587034, acc.: 62.50%] [G loss: 0.507999]\n",
      "##############\n",
      "[3.02776337 1.21104833 6.17237278 4.89728708 4.02156167 5.56953122\n",
      " 4.44961244 4.9250907  4.71211319 4.2172358 ]\n",
      "##########\n",
      "epoch:24 step:23001 [D loss: 0.512239, acc.: 71.09%] [G loss: 0.549147]\n",
      "epoch:24 step:23002 [D loss: 0.495736, acc.: 72.66%] [G loss: 0.700565]\n",
      "epoch:24 step:23003 [D loss: 0.505328, acc.: 75.78%] [G loss: 0.729578]\n",
      "epoch:24 step:23004 [D loss: 0.461882, acc.: 79.69%] [G loss: 0.769382]\n",
      "epoch:24 step:23005 [D loss: 0.535681, acc.: 73.44%] [G loss: 0.744363]\n",
      "epoch:24 step:23006 [D loss: 0.515496, acc.: 72.66%] [G loss: 0.663167]\n",
      "epoch:24 step:23007 [D loss: 0.477245, acc.: 80.47%] [G loss: 0.706411]\n",
      "epoch:24 step:23008 [D loss: 0.505406, acc.: 76.56%] [G loss: 0.810947]\n",
      "epoch:24 step:23009 [D loss: 0.534499, acc.: 72.66%] [G loss: 0.811084]\n",
      "epoch:24 step:23010 [D loss: 0.494614, acc.: 75.00%] [G loss: 0.680728]\n",
      "epoch:24 step:23011 [D loss: 0.431245, acc.: 80.47%] [G loss: 0.851752]\n",
      "epoch:24 step:23012 [D loss: 0.566490, acc.: 72.66%] [G loss: 0.787040]\n",
      "epoch:24 step:23013 [D loss: 0.619347, acc.: 65.62%] [G loss: 0.614229]\n",
      "epoch:24 step:23014 [D loss: 0.457797, acc.: 79.69%] [G loss: 0.632973]\n",
      "epoch:24 step:23015 [D loss: 0.581020, acc.: 65.62%] [G loss: 0.706055]\n",
      "epoch:24 step:23016 [D loss: 0.660640, acc.: 66.41%] [G loss: 0.562219]\n",
      "epoch:24 step:23017 [D loss: 0.549855, acc.: 64.06%] [G loss: 0.504627]\n",
      "epoch:24 step:23018 [D loss: 0.539467, acc.: 71.09%] [G loss: 0.510970]\n",
      "epoch:24 step:23019 [D loss: 0.520268, acc.: 74.22%] [G loss: 0.625192]\n",
      "epoch:24 step:23020 [D loss: 0.617142, acc.: 67.19%] [G loss: 0.849042]\n",
      "epoch:24 step:23021 [D loss: 0.535449, acc.: 70.31%] [G loss: 0.705893]\n",
      "epoch:24 step:23022 [D loss: 0.476990, acc.: 78.12%] [G loss: 0.743175]\n",
      "epoch:24 step:23023 [D loss: 0.549592, acc.: 71.88%] [G loss: 0.601941]\n",
      "epoch:24 step:23024 [D loss: 0.506061, acc.: 69.53%] [G loss: 0.540101]\n",
      "epoch:24 step:23025 [D loss: 0.570977, acc.: 73.44%] [G loss: 0.834331]\n",
      "epoch:24 step:23026 [D loss: 0.495378, acc.: 75.78%] [G loss: 0.655887]\n",
      "epoch:24 step:23027 [D loss: 0.566928, acc.: 66.41%] [G loss: 0.695479]\n",
      "epoch:24 step:23028 [D loss: 0.520918, acc.: 67.97%] [G loss: 0.680353]\n",
      "epoch:24 step:23029 [D loss: 0.547714, acc.: 73.44%] [G loss: 0.685021]\n",
      "epoch:24 step:23030 [D loss: 0.605630, acc.: 64.84%] [G loss: 0.479477]\n",
      "epoch:24 step:23031 [D loss: 0.567121, acc.: 70.31%] [G loss: 0.637319]\n",
      "epoch:24 step:23032 [D loss: 0.564416, acc.: 72.66%] [G loss: 0.698059]\n",
      "epoch:24 step:23033 [D loss: 0.498936, acc.: 71.88%] [G loss: 0.757853]\n",
      "epoch:24 step:23034 [D loss: 0.475631, acc.: 80.47%] [G loss: 0.781074]\n",
      "epoch:24 step:23035 [D loss: 0.606790, acc.: 70.31%] [G loss: 0.777207]\n",
      "epoch:24 step:23036 [D loss: 0.483770, acc.: 77.34%] [G loss: 0.596317]\n",
      "epoch:24 step:23037 [D loss: 0.495322, acc.: 75.78%] [G loss: 1.023061]\n",
      "epoch:24 step:23038 [D loss: 0.510062, acc.: 77.34%] [G loss: 0.866956]\n",
      "epoch:24 step:23039 [D loss: 0.555599, acc.: 71.09%] [G loss: 0.690745]\n",
      "epoch:24 step:23040 [D loss: 0.461615, acc.: 78.91%] [G loss: 0.802085]\n",
      "epoch:24 step:23041 [D loss: 0.596377, acc.: 68.75%] [G loss: 0.668100]\n",
      "epoch:24 step:23042 [D loss: 0.450059, acc.: 78.12%] [G loss: 0.733157]\n",
      "epoch:24 step:23043 [D loss: 0.482827, acc.: 78.91%] [G loss: 0.801656]\n",
      "epoch:24 step:23044 [D loss: 0.554947, acc.: 71.09%] [G loss: 0.727410]\n",
      "epoch:24 step:23045 [D loss: 0.532058, acc.: 74.22%] [G loss: 0.628637]\n",
      "epoch:24 step:23046 [D loss: 0.488793, acc.: 78.91%] [G loss: 0.620530]\n",
      "epoch:24 step:23047 [D loss: 0.594831, acc.: 66.41%] [G loss: 0.628839]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:24 step:23048 [D loss: 0.537572, acc.: 71.88%] [G loss: 0.644677]\n",
      "epoch:24 step:23049 [D loss: 0.646021, acc.: 63.28%] [G loss: 0.704582]\n",
      "epoch:24 step:23050 [D loss: 0.543771, acc.: 68.75%] [G loss: 0.652941]\n",
      "epoch:24 step:23051 [D loss: 0.595250, acc.: 65.62%] [G loss: 0.567859]\n",
      "epoch:24 step:23052 [D loss: 0.467647, acc.: 81.25%] [G loss: 0.766502]\n",
      "epoch:24 step:23053 [D loss: 0.516298, acc.: 74.22%] [G loss: 0.874403]\n",
      "epoch:24 step:23054 [D loss: 0.726791, acc.: 62.50%] [G loss: 0.722787]\n",
      "epoch:24 step:23055 [D loss: 0.539079, acc.: 75.00%] [G loss: 0.554112]\n",
      "epoch:24 step:23056 [D loss: 0.530866, acc.: 74.22%] [G loss: 0.759420]\n",
      "epoch:24 step:23057 [D loss: 0.523183, acc.: 76.56%] [G loss: 0.622441]\n",
      "epoch:24 step:23058 [D loss: 0.510146, acc.: 75.78%] [G loss: 0.712651]\n",
      "epoch:24 step:23059 [D loss: 0.524672, acc.: 73.44%] [G loss: 0.636900]\n",
      "epoch:24 step:23060 [D loss: 0.521745, acc.: 74.22%] [G loss: 0.807145]\n",
      "epoch:24 step:23061 [D loss: 0.527641, acc.: 72.66%] [G loss: 0.900804]\n",
      "epoch:24 step:23062 [D loss: 0.439121, acc.: 82.03%] [G loss: 0.935446]\n",
      "epoch:24 step:23063 [D loss: 0.449536, acc.: 77.34%] [G loss: 0.899773]\n",
      "epoch:24 step:23064 [D loss: 0.636716, acc.: 63.28%] [G loss: 0.798264]\n",
      "epoch:24 step:23065 [D loss: 0.597015, acc.: 66.41%] [G loss: 0.833371]\n",
      "epoch:24 step:23066 [D loss: 0.578055, acc.: 66.41%] [G loss: 0.690936]\n",
      "epoch:24 step:23067 [D loss: 0.541391, acc.: 69.53%] [G loss: 0.625395]\n",
      "epoch:24 step:23068 [D loss: 0.544579, acc.: 65.62%] [G loss: 0.804020]\n",
      "epoch:24 step:23069 [D loss: 0.504436, acc.: 80.47%] [G loss: 0.829352]\n",
      "epoch:24 step:23070 [D loss: 0.400269, acc.: 80.47%] [G loss: 1.011525]\n",
      "epoch:24 step:23071 [D loss: 0.515146, acc.: 72.66%] [G loss: 0.680224]\n",
      "epoch:24 step:23072 [D loss: 0.610624, acc.: 67.19%] [G loss: 0.682247]\n",
      "epoch:24 step:23073 [D loss: 0.601872, acc.: 66.41%] [G loss: 0.786568]\n",
      "epoch:24 step:23074 [D loss: 0.557468, acc.: 67.97%] [G loss: 0.675410]\n",
      "epoch:24 step:23075 [D loss: 0.531098, acc.: 67.97%] [G loss: 0.825742]\n",
      "epoch:24 step:23076 [D loss: 0.556695, acc.: 72.66%] [G loss: 0.573219]\n",
      "epoch:24 step:23077 [D loss: 0.594646, acc.: 67.97%] [G loss: 0.758355]\n",
      "epoch:24 step:23078 [D loss: 0.514018, acc.: 67.97%] [G loss: 0.726400]\n",
      "epoch:24 step:23079 [D loss: 0.588875, acc.: 70.31%] [G loss: 0.587275]\n",
      "epoch:24 step:23080 [D loss: 0.462982, acc.: 75.78%] [G loss: 0.731823]\n",
      "epoch:24 step:23081 [D loss: 0.524598, acc.: 73.44%] [G loss: 0.764985]\n",
      "epoch:24 step:23082 [D loss: 0.564084, acc.: 68.75%] [G loss: 0.822916]\n",
      "epoch:24 step:23083 [D loss: 0.573288, acc.: 66.41%] [G loss: 0.684839]\n",
      "epoch:24 step:23084 [D loss: 0.512198, acc.: 73.44%] [G loss: 0.725617]\n",
      "epoch:24 step:23085 [D loss: 0.565504, acc.: 68.75%] [G loss: 0.618689]\n",
      "epoch:24 step:23086 [D loss: 0.487204, acc.: 75.78%] [G loss: 0.697634]\n",
      "epoch:24 step:23087 [D loss: 0.481583, acc.: 78.91%] [G loss: 0.771931]\n",
      "epoch:24 step:23088 [D loss: 0.636750, acc.: 63.28%] [G loss: 0.766570]\n",
      "epoch:24 step:23089 [D loss: 0.472598, acc.: 75.78%] [G loss: 0.770446]\n",
      "epoch:24 step:23090 [D loss: 0.531248, acc.: 75.78%] [G loss: 0.781366]\n",
      "epoch:24 step:23091 [D loss: 0.482891, acc.: 75.00%] [G loss: 0.879836]\n",
      "epoch:24 step:23092 [D loss: 0.576498, acc.: 69.53%] [G loss: 0.701361]\n",
      "epoch:24 step:23093 [D loss: 0.427169, acc.: 77.34%] [G loss: 0.870481]\n",
      "epoch:24 step:23094 [D loss: 0.552104, acc.: 72.66%] [G loss: 0.721999]\n",
      "epoch:24 step:23095 [D loss: 0.559560, acc.: 70.31%] [G loss: 0.579084]\n",
      "epoch:24 step:23096 [D loss: 0.542211, acc.: 67.97%] [G loss: 0.803257]\n",
      "epoch:24 step:23097 [D loss: 0.562534, acc.: 65.62%] [G loss: 0.539730]\n",
      "epoch:24 step:23098 [D loss: 0.580330, acc.: 66.41%] [G loss: 0.461312]\n",
      "epoch:24 step:23099 [D loss: 0.496929, acc.: 74.22%] [G loss: 0.565596]\n",
      "epoch:24 step:23100 [D loss: 0.571441, acc.: 68.75%] [G loss: 0.697605]\n",
      "epoch:24 step:23101 [D loss: 0.532207, acc.: 71.09%] [G loss: 0.694770]\n",
      "epoch:24 step:23102 [D loss: 0.547198, acc.: 69.53%] [G loss: 0.769591]\n",
      "epoch:24 step:23103 [D loss: 0.583282, acc.: 65.62%] [G loss: 0.586450]\n",
      "epoch:24 step:23104 [D loss: 0.531466, acc.: 69.53%] [G loss: 0.679211]\n",
      "epoch:24 step:23105 [D loss: 0.484272, acc.: 77.34%] [G loss: 0.843294]\n",
      "epoch:24 step:23106 [D loss: 0.585954, acc.: 63.28%] [G loss: 0.843616]\n",
      "epoch:24 step:23107 [D loss: 0.637485, acc.: 64.06%] [G loss: 0.618505]\n",
      "epoch:24 step:23108 [D loss: 0.529226, acc.: 68.75%] [G loss: 0.670822]\n",
      "epoch:24 step:23109 [D loss: 0.516172, acc.: 75.78%] [G loss: 0.559617]\n",
      "epoch:24 step:23110 [D loss: 0.546596, acc.: 67.97%] [G loss: 0.634534]\n",
      "epoch:24 step:23111 [D loss: 0.442462, acc.: 78.91%] [G loss: 0.770666]\n",
      "epoch:24 step:23112 [D loss: 0.493652, acc.: 77.34%] [G loss: 0.865778]\n",
      "epoch:24 step:23113 [D loss: 0.605984, acc.: 66.41%] [G loss: 0.827738]\n",
      "epoch:24 step:23114 [D loss: 0.510154, acc.: 73.44%] [G loss: 0.649003]\n",
      "epoch:24 step:23115 [D loss: 0.536451, acc.: 71.09%] [G loss: 0.767570]\n",
      "epoch:24 step:23116 [D loss: 0.564042, acc.: 66.41%] [G loss: 0.569419]\n",
      "epoch:24 step:23117 [D loss: 0.508065, acc.: 72.66%] [G loss: 0.706121]\n",
      "epoch:24 step:23118 [D loss: 0.505713, acc.: 76.56%] [G loss: 0.611167]\n",
      "epoch:24 step:23119 [D loss: 0.499093, acc.: 75.78%] [G loss: 0.746271]\n",
      "epoch:24 step:23120 [D loss: 0.454502, acc.: 82.81%] [G loss: 0.741223]\n",
      "epoch:24 step:23121 [D loss: 0.520109, acc.: 74.22%] [G loss: 0.760727]\n",
      "epoch:24 step:23122 [D loss: 0.471261, acc.: 79.69%] [G loss: 0.950903]\n",
      "epoch:24 step:23123 [D loss: 0.467520, acc.: 78.12%] [G loss: 0.887751]\n",
      "epoch:24 step:23124 [D loss: 0.559820, acc.: 67.97%] [G loss: 0.701309]\n",
      "epoch:24 step:23125 [D loss: 0.534210, acc.: 74.22%] [G loss: 0.611768]\n",
      "epoch:24 step:23126 [D loss: 0.539367, acc.: 71.09%] [G loss: 0.582449]\n",
      "epoch:24 step:23127 [D loss: 0.507863, acc.: 70.31%] [G loss: 0.656649]\n",
      "epoch:24 step:23128 [D loss: 0.571565, acc.: 67.19%] [G loss: 0.751354]\n",
      "epoch:24 step:23129 [D loss: 0.473056, acc.: 75.00%] [G loss: 0.618735]\n",
      "epoch:24 step:23130 [D loss: 0.491493, acc.: 75.78%] [G loss: 0.877149]\n",
      "epoch:24 step:23131 [D loss: 0.538048, acc.: 67.19%] [G loss: 0.856491]\n",
      "epoch:24 step:23132 [D loss: 0.517940, acc.: 71.88%] [G loss: 0.850448]\n",
      "epoch:24 step:23133 [D loss: 0.558481, acc.: 66.41%] [G loss: 0.644084]\n",
      "epoch:24 step:23134 [D loss: 0.531538, acc.: 71.88%] [G loss: 0.642198]\n",
      "epoch:24 step:23135 [D loss: 0.460746, acc.: 80.47%] [G loss: 0.731868]\n",
      "epoch:24 step:23136 [D loss: 0.416609, acc.: 82.03%] [G loss: 0.804317]\n",
      "epoch:24 step:23137 [D loss: 0.472599, acc.: 78.12%] [G loss: 0.922831]\n",
      "epoch:24 step:23138 [D loss: 0.560295, acc.: 75.00%] [G loss: 0.981353]\n",
      "epoch:24 step:23139 [D loss: 0.498340, acc.: 74.22%] [G loss: 0.806819]\n",
      "epoch:24 step:23140 [D loss: 0.583999, acc.: 69.53%] [G loss: 0.729172]\n",
      "epoch:24 step:23141 [D loss: 0.555767, acc.: 67.97%] [G loss: 0.541902]\n",
      "epoch:24 step:23142 [D loss: 0.490045, acc.: 75.00%] [G loss: 1.069844]\n",
      "epoch:24 step:23143 [D loss: 0.549599, acc.: 71.88%] [G loss: 0.642333]\n",
      "epoch:24 step:23144 [D loss: 0.528435, acc.: 71.88%] [G loss: 0.561088]\n",
      "epoch:24 step:23145 [D loss: 0.521879, acc.: 69.53%] [G loss: 0.809737]\n",
      "epoch:24 step:23146 [D loss: 0.579082, acc.: 69.53%] [G loss: 0.778663]\n",
      "epoch:24 step:23147 [D loss: 0.558726, acc.: 71.09%] [G loss: 0.660696]\n",
      "epoch:24 step:23148 [D loss: 0.553545, acc.: 77.34%] [G loss: 0.816790]\n",
      "epoch:24 step:23149 [D loss: 0.482570, acc.: 75.00%] [G loss: 0.651453]\n",
      "epoch:24 step:23150 [D loss: 0.518706, acc.: 71.09%] [G loss: 0.685119]\n",
      "epoch:24 step:23151 [D loss: 0.540041, acc.: 71.88%] [G loss: 0.759592]\n",
      "epoch:24 step:23152 [D loss: 0.541481, acc.: 69.53%] [G loss: 0.953251]\n",
      "epoch:24 step:23153 [D loss: 0.557219, acc.: 65.62%] [G loss: 0.751633]\n",
      "epoch:24 step:23154 [D loss: 0.546650, acc.: 74.22%] [G loss: 0.671028]\n",
      "epoch:24 step:23155 [D loss: 0.573642, acc.: 64.84%] [G loss: 0.718159]\n",
      "epoch:24 step:23156 [D loss: 0.568049, acc.: 68.75%] [G loss: 0.742829]\n",
      "epoch:24 step:23157 [D loss: 0.560652, acc.: 68.75%] [G loss: 0.663802]\n",
      "epoch:24 step:23158 [D loss: 0.544800, acc.: 71.88%] [G loss: 0.678059]\n",
      "epoch:24 step:23159 [D loss: 0.547669, acc.: 69.53%] [G loss: 0.766805]\n",
      "epoch:24 step:23160 [D loss: 0.554008, acc.: 71.09%] [G loss: 0.977970]\n",
      "epoch:24 step:23161 [D loss: 0.673623, acc.: 60.16%] [G loss: 0.630977]\n",
      "epoch:24 step:23162 [D loss: 0.532987, acc.: 72.66%] [G loss: 0.625910]\n",
      "epoch:24 step:23163 [D loss: 0.620968, acc.: 64.06%] [G loss: 0.655652]\n",
      "epoch:24 step:23164 [D loss: 0.560226, acc.: 67.97%] [G loss: 0.644100]\n",
      "epoch:24 step:23165 [D loss: 0.504970, acc.: 73.44%] [G loss: 0.760112]\n",
      "epoch:24 step:23166 [D loss: 0.595442, acc.: 66.41%] [G loss: 0.743565]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:24 step:23167 [D loss: 0.488627, acc.: 80.47%] [G loss: 0.721431]\n",
      "epoch:24 step:23168 [D loss: 0.488368, acc.: 77.34%] [G loss: 0.689236]\n",
      "epoch:24 step:23169 [D loss: 0.489800, acc.: 76.56%] [G loss: 0.612002]\n",
      "epoch:24 step:23170 [D loss: 0.541693, acc.: 69.53%] [G loss: 0.558467]\n",
      "epoch:24 step:23171 [D loss: 0.575571, acc.: 67.97%] [G loss: 0.585637]\n",
      "epoch:24 step:23172 [D loss: 0.591687, acc.: 65.62%] [G loss: 0.603848]\n",
      "epoch:24 step:23173 [D loss: 0.539002, acc.: 71.88%] [G loss: 0.660299]\n",
      "epoch:24 step:23174 [D loss: 0.568804, acc.: 67.97%] [G loss: 0.630829]\n",
      "epoch:24 step:23175 [D loss: 0.524266, acc.: 72.66%] [G loss: 0.614769]\n",
      "epoch:24 step:23176 [D loss: 0.567282, acc.: 71.09%] [G loss: 0.549144]\n",
      "epoch:24 step:23177 [D loss: 0.570864, acc.: 68.75%] [G loss: 0.664089]\n",
      "epoch:24 step:23178 [D loss: 0.445574, acc.: 78.12%] [G loss: 0.724015]\n",
      "epoch:24 step:23179 [D loss: 0.554061, acc.: 71.88%] [G loss: 0.804843]\n",
      "epoch:24 step:23180 [D loss: 0.527183, acc.: 74.22%] [G loss: 0.577704]\n",
      "epoch:24 step:23181 [D loss: 0.502961, acc.: 72.66%] [G loss: 0.724896]\n",
      "epoch:24 step:23182 [D loss: 0.495705, acc.: 72.66%] [G loss: 0.848526]\n",
      "epoch:24 step:23183 [D loss: 0.523092, acc.: 75.00%] [G loss: 0.683455]\n",
      "epoch:24 step:23184 [D loss: 0.591752, acc.: 64.06%] [G loss: 0.783063]\n",
      "epoch:24 step:23185 [D loss: 0.556616, acc.: 65.62%] [G loss: 0.693376]\n",
      "epoch:24 step:23186 [D loss: 0.552869, acc.: 69.53%] [G loss: 0.816972]\n",
      "epoch:24 step:23187 [D loss: 0.521138, acc.: 75.00%] [G loss: 0.576919]\n",
      "epoch:24 step:23188 [D loss: 0.567543, acc.: 67.97%] [G loss: 0.721596]\n",
      "epoch:24 step:23189 [D loss: 0.515244, acc.: 69.53%] [G loss: 0.900969]\n",
      "epoch:24 step:23190 [D loss: 0.564488, acc.: 68.75%] [G loss: 0.841020]\n",
      "epoch:24 step:23191 [D loss: 0.604550, acc.: 60.94%] [G loss: 0.497014]\n",
      "epoch:24 step:23192 [D loss: 0.621020, acc.: 60.94%] [G loss: 0.602839]\n",
      "epoch:24 step:23193 [D loss: 0.520377, acc.: 67.97%] [G loss: 0.717787]\n",
      "epoch:24 step:23194 [D loss: 0.532268, acc.: 69.53%] [G loss: 0.794146]\n",
      "epoch:24 step:23195 [D loss: 0.486974, acc.: 75.00%] [G loss: 0.740045]\n",
      "epoch:24 step:23196 [D loss: 0.516115, acc.: 71.88%] [G loss: 0.694620]\n",
      "epoch:24 step:23197 [D loss: 0.591147, acc.: 67.19%] [G loss: 0.880135]\n",
      "epoch:24 step:23198 [D loss: 0.578592, acc.: 69.53%] [G loss: 0.631289]\n",
      "epoch:24 step:23199 [D loss: 0.592572, acc.: 64.84%] [G loss: 0.704519]\n",
      "epoch:24 step:23200 [D loss: 0.509924, acc.: 74.22%] [G loss: 0.910929]\n",
      "##############\n",
      "[2.98805946 0.87025348 6.09779463 4.77712881 4.04788142 5.65715918\n",
      " 4.54697934 4.88011719 4.81983169 4.39957212]\n",
      "##########\n",
      "epoch:24 step:23201 [D loss: 0.634490, acc.: 64.06%] [G loss: 0.536030]\n",
      "epoch:24 step:23202 [D loss: 0.513945, acc.: 71.09%] [G loss: 0.697755]\n",
      "epoch:24 step:23203 [D loss: 0.545876, acc.: 71.88%] [G loss: 0.639590]\n",
      "epoch:24 step:23204 [D loss: 0.599777, acc.: 63.28%] [G loss: 0.575455]\n",
      "epoch:24 step:23205 [D loss: 0.529787, acc.: 70.31%] [G loss: 0.680035]\n",
      "epoch:24 step:23206 [D loss: 0.562966, acc.: 67.19%] [G loss: 0.661797]\n",
      "epoch:24 step:23207 [D loss: 0.483974, acc.: 75.78%] [G loss: 0.776934]\n",
      "epoch:24 step:23208 [D loss: 0.564240, acc.: 70.31%] [G loss: 0.633179]\n",
      "epoch:24 step:23209 [D loss: 0.586986, acc.: 63.28%] [G loss: 0.511833]\n",
      "epoch:24 step:23210 [D loss: 0.531686, acc.: 71.88%] [G loss: 0.639959]\n",
      "epoch:24 step:23211 [D loss: 0.564179, acc.: 74.22%] [G loss: 0.576783]\n",
      "epoch:24 step:23212 [D loss: 0.489161, acc.: 75.78%] [G loss: 0.704732]\n",
      "epoch:24 step:23213 [D loss: 0.536897, acc.: 67.97%] [G loss: 0.709480]\n",
      "epoch:24 step:23214 [D loss: 0.496366, acc.: 77.34%] [G loss: 0.843159]\n",
      "epoch:24 step:23215 [D loss: 0.548136, acc.: 71.88%] [G loss: 0.706429]\n",
      "epoch:24 step:23216 [D loss: 0.553708, acc.: 68.75%] [G loss: 0.678033]\n",
      "epoch:24 step:23217 [D loss: 0.564029, acc.: 66.41%] [G loss: 0.603086]\n",
      "epoch:24 step:23218 [D loss: 0.505640, acc.: 71.88%] [G loss: 0.590523]\n",
      "epoch:24 step:23219 [D loss: 0.586403, acc.: 68.75%] [G loss: 0.737762]\n",
      "epoch:24 step:23220 [D loss: 0.524156, acc.: 70.31%] [G loss: 0.556631]\n",
      "epoch:24 step:23221 [D loss: 0.534706, acc.: 74.22%] [G loss: 0.648289]\n",
      "epoch:24 step:23222 [D loss: 0.498835, acc.: 76.56%] [G loss: 0.638807]\n",
      "epoch:24 step:23223 [D loss: 0.551507, acc.: 69.53%] [G loss: 0.878104]\n",
      "epoch:24 step:23224 [D loss: 0.556205, acc.: 73.44%] [G loss: 0.771966]\n",
      "epoch:24 step:23225 [D loss: 0.579780, acc.: 66.41%] [G loss: 0.670511]\n",
      "epoch:24 step:23226 [D loss: 0.572686, acc.: 68.75%] [G loss: 0.492339]\n",
      "epoch:24 step:23227 [D loss: 0.553744, acc.: 70.31%] [G loss: 0.537202]\n",
      "epoch:24 step:23228 [D loss: 0.568401, acc.: 64.06%] [G loss: 0.503628]\n",
      "epoch:24 step:23229 [D loss: 0.565624, acc.: 70.31%] [G loss: 0.590950]\n",
      "epoch:24 step:23230 [D loss: 0.511426, acc.: 74.22%] [G loss: 0.620453]\n",
      "epoch:24 step:23231 [D loss: 0.523201, acc.: 72.66%] [G loss: 0.754982]\n",
      "epoch:24 step:23232 [D loss: 0.542769, acc.: 73.44%] [G loss: 0.867570]\n",
      "epoch:24 step:23233 [D loss: 0.590283, acc.: 67.97%] [G loss: 0.742184]\n",
      "epoch:24 step:23234 [D loss: 0.394114, acc.: 82.81%] [G loss: 0.918322]\n",
      "epoch:24 step:23235 [D loss: 0.446199, acc.: 75.78%] [G loss: 0.758986]\n",
      "epoch:24 step:23236 [D loss: 0.528718, acc.: 75.00%] [G loss: 0.772662]\n",
      "epoch:24 step:23237 [D loss: 0.472998, acc.: 77.34%] [G loss: 0.670406]\n",
      "epoch:24 step:23238 [D loss: 0.454033, acc.: 76.56%] [G loss: 0.900055]\n",
      "epoch:24 step:23239 [D loss: 0.507370, acc.: 71.88%] [G loss: 0.948886]\n",
      "epoch:24 step:23240 [D loss: 0.591392, acc.: 71.09%] [G loss: 0.801958]\n",
      "epoch:24 step:23241 [D loss: 0.495230, acc.: 74.22%] [G loss: 0.684115]\n",
      "epoch:24 step:23242 [D loss: 0.552496, acc.: 66.41%] [G loss: 0.808741]\n",
      "epoch:24 step:23243 [D loss: 0.542808, acc.: 65.62%] [G loss: 0.748620]\n",
      "epoch:24 step:23244 [D loss: 0.517739, acc.: 76.56%] [G loss: 0.596284]\n",
      "epoch:24 step:23245 [D loss: 0.542472, acc.: 70.31%] [G loss: 0.658882]\n",
      "epoch:24 step:23246 [D loss: 0.469589, acc.: 77.34%] [G loss: 0.600272]\n",
      "epoch:24 step:23247 [D loss: 0.576855, acc.: 70.31%] [G loss: 0.608671]\n",
      "epoch:24 step:23248 [D loss: 0.536509, acc.: 71.09%] [G loss: 0.684569]\n",
      "epoch:24 step:23249 [D loss: 0.544157, acc.: 71.88%] [G loss: 0.589915]\n",
      "epoch:24 step:23250 [D loss: 0.574211, acc.: 68.75%] [G loss: 0.682140]\n",
      "epoch:24 step:23251 [D loss: 0.558976, acc.: 66.41%] [G loss: 0.683542]\n",
      "epoch:24 step:23252 [D loss: 0.524884, acc.: 72.66%] [G loss: 0.585676]\n",
      "epoch:24 step:23253 [D loss: 0.632204, acc.: 64.06%] [G loss: 0.666469]\n",
      "epoch:24 step:23254 [D loss: 0.610564, acc.: 66.41%] [G loss: 0.535383]\n",
      "epoch:24 step:23255 [D loss: 0.541825, acc.: 77.34%] [G loss: 0.674468]\n",
      "epoch:24 step:23256 [D loss: 0.529934, acc.: 72.66%] [G loss: 0.708405]\n",
      "epoch:24 step:23257 [D loss: 0.489663, acc.: 74.22%] [G loss: 0.924016]\n",
      "epoch:24 step:23258 [D loss: 0.510566, acc.: 71.88%] [G loss: 0.902359]\n",
      "epoch:24 step:23259 [D loss: 0.495862, acc.: 72.66%] [G loss: 0.960071]\n",
      "epoch:24 step:23260 [D loss: 0.577397, acc.: 66.41%] [G loss: 0.763708]\n",
      "epoch:24 step:23261 [D loss: 0.482284, acc.: 78.12%] [G loss: 0.815528]\n",
      "epoch:24 step:23262 [D loss: 0.530179, acc.: 71.09%] [G loss: 0.640449]\n",
      "epoch:24 step:23263 [D loss: 0.509914, acc.: 75.00%] [G loss: 0.734043]\n",
      "epoch:24 step:23264 [D loss: 0.502719, acc.: 73.44%] [G loss: 0.585379]\n",
      "epoch:24 step:23265 [D loss: 0.550361, acc.: 70.31%] [G loss: 0.672520]\n",
      "epoch:24 step:23266 [D loss: 0.557171, acc.: 69.53%] [G loss: 0.730738]\n",
      "epoch:24 step:23267 [D loss: 0.526661, acc.: 71.88%] [G loss: 0.644305]\n",
      "epoch:24 step:23268 [D loss: 0.457203, acc.: 82.81%] [G loss: 0.917167]\n",
      "epoch:24 step:23269 [D loss: 0.507642, acc.: 74.22%] [G loss: 0.697606]\n",
      "epoch:24 step:23270 [D loss: 0.470514, acc.: 75.78%] [G loss: 0.826553]\n",
      "epoch:24 step:23271 [D loss: 0.550524, acc.: 66.41%] [G loss: 0.865772]\n",
      "epoch:24 step:23272 [D loss: 0.610940, acc.: 65.62%] [G loss: 0.854008]\n",
      "epoch:24 step:23273 [D loss: 0.494209, acc.: 75.78%] [G loss: 0.632649]\n",
      "epoch:24 step:23274 [D loss: 0.544141, acc.: 72.66%] [G loss: 0.593335]\n",
      "epoch:24 step:23275 [D loss: 0.561720, acc.: 72.66%] [G loss: 0.692392]\n",
      "epoch:24 step:23276 [D loss: 0.666186, acc.: 58.59%] [G loss: 0.534745]\n",
      "epoch:24 step:23277 [D loss: 0.508092, acc.: 68.75%] [G loss: 0.762973]\n",
      "epoch:24 step:23278 [D loss: 0.494303, acc.: 69.53%] [G loss: 0.727368]\n",
      "epoch:24 step:23279 [D loss: 0.550574, acc.: 71.09%] [G loss: 0.657798]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:24 step:23280 [D loss: 0.427817, acc.: 83.59%] [G loss: 0.701264]\n",
      "epoch:24 step:23281 [D loss: 0.562262, acc.: 66.41%] [G loss: 0.677290]\n",
      "epoch:24 step:23282 [D loss: 0.652891, acc.: 60.16%] [G loss: 0.717002]\n",
      "epoch:24 step:23283 [D loss: 0.501857, acc.: 72.66%] [G loss: 0.579244]\n",
      "epoch:24 step:23284 [D loss: 0.515558, acc.: 73.44%] [G loss: 0.805194]\n",
      "epoch:24 step:23285 [D loss: 0.539386, acc.: 68.75%] [G loss: 0.762816]\n",
      "epoch:24 step:23286 [D loss: 0.541396, acc.: 72.66%] [G loss: 0.582375]\n",
      "epoch:24 step:23287 [D loss: 0.554680, acc.: 70.31%] [G loss: 0.900994]\n",
      "epoch:24 step:23288 [D loss: 0.600430, acc.: 65.62%] [G loss: 0.647290]\n",
      "epoch:24 step:23289 [D loss: 0.489812, acc.: 78.91%] [G loss: 0.622602]\n",
      "epoch:24 step:23290 [D loss: 0.461117, acc.: 76.56%] [G loss: 0.896320]\n",
      "epoch:24 step:23291 [D loss: 0.530009, acc.: 74.22%] [G loss: 0.791374]\n",
      "epoch:24 step:23292 [D loss: 0.510714, acc.: 71.88%] [G loss: 0.599006]\n",
      "epoch:24 step:23293 [D loss: 0.545765, acc.: 74.22%] [G loss: 0.495565]\n",
      "epoch:24 step:23294 [D loss: 0.559248, acc.: 71.09%] [G loss: 0.545593]\n",
      "epoch:24 step:23295 [D loss: 0.524837, acc.: 70.31%] [G loss: 0.557482]\n",
      "epoch:24 step:23296 [D loss: 0.590231, acc.: 65.62%] [G loss: 0.559121]\n",
      "epoch:24 step:23297 [D loss: 0.547526, acc.: 70.31%] [G loss: 0.559597]\n",
      "epoch:24 step:23298 [D loss: 0.512655, acc.: 71.09%] [G loss: 0.678224]\n",
      "epoch:24 step:23299 [D loss: 0.588865, acc.: 61.72%] [G loss: 0.638612]\n",
      "epoch:24 step:23300 [D loss: 0.603491, acc.: 67.97%] [G loss: 0.625691]\n",
      "epoch:24 step:23301 [D loss: 0.520187, acc.: 70.31%] [G loss: 0.561173]\n",
      "epoch:24 step:23302 [D loss: 0.483196, acc.: 78.12%] [G loss: 0.635834]\n",
      "epoch:24 step:23303 [D loss: 0.541109, acc.: 68.75%] [G loss: 0.767286]\n",
      "epoch:24 step:23304 [D loss: 0.520400, acc.: 75.00%] [G loss: 0.827321]\n",
      "epoch:24 step:23305 [D loss: 0.660756, acc.: 67.97%] [G loss: 0.735275]\n",
      "epoch:24 step:23306 [D loss: 0.525899, acc.: 70.31%] [G loss: 0.722790]\n",
      "epoch:24 step:23307 [D loss: 0.493235, acc.: 75.78%] [G loss: 0.776656]\n",
      "epoch:24 step:23308 [D loss: 0.628940, acc.: 66.41%] [G loss: 0.618432]\n",
      "epoch:24 step:23309 [D loss: 0.543894, acc.: 67.19%] [G loss: 0.493071]\n",
      "epoch:24 step:23310 [D loss: 0.592557, acc.: 66.41%] [G loss: 0.537831]\n",
      "epoch:24 step:23311 [D loss: 0.451213, acc.: 80.47%] [G loss: 0.652244]\n",
      "epoch:24 step:23312 [D loss: 0.538149, acc.: 71.09%] [G loss: 0.786360]\n",
      "epoch:24 step:23313 [D loss: 0.519133, acc.: 72.66%] [G loss: 0.738118]\n",
      "epoch:24 step:23314 [D loss: 0.552244, acc.: 69.53%] [G loss: 0.665905]\n",
      "epoch:24 step:23315 [D loss: 0.552298, acc.: 65.62%] [G loss: 0.727635]\n",
      "epoch:24 step:23316 [D loss: 0.618067, acc.: 60.16%] [G loss: 0.710113]\n",
      "epoch:24 step:23317 [D loss: 0.541245, acc.: 66.41%] [G loss: 0.592370]\n",
      "epoch:24 step:23318 [D loss: 0.495178, acc.: 70.31%] [G loss: 0.613425]\n",
      "epoch:24 step:23319 [D loss: 0.547551, acc.: 66.41%] [G loss: 0.612192]\n",
      "epoch:24 step:23320 [D loss: 0.599774, acc.: 68.75%] [G loss: 0.686432]\n",
      "epoch:24 step:23321 [D loss: 0.546878, acc.: 72.66%] [G loss: 0.663271]\n",
      "epoch:24 step:23322 [D loss: 0.535096, acc.: 67.19%] [G loss: 0.628780]\n",
      "epoch:24 step:23323 [D loss: 0.557010, acc.: 69.53%] [G loss: 0.601248]\n",
      "epoch:24 step:23324 [D loss: 0.562592, acc.: 68.75%] [G loss: 0.624817]\n",
      "epoch:24 step:23325 [D loss: 0.531795, acc.: 71.88%] [G loss: 0.721035]\n",
      "epoch:24 step:23326 [D loss: 0.543314, acc.: 71.88%] [G loss: 0.610854]\n",
      "epoch:24 step:23327 [D loss: 0.556614, acc.: 66.41%] [G loss: 0.723952]\n",
      "epoch:24 step:23328 [D loss: 0.542091, acc.: 75.00%] [G loss: 0.557281]\n",
      "epoch:24 step:23329 [D loss: 0.539900, acc.: 72.66%] [G loss: 0.521640]\n",
      "epoch:24 step:23330 [D loss: 0.496329, acc.: 78.91%] [G loss: 0.638443]\n",
      "epoch:24 step:23331 [D loss: 0.522933, acc.: 72.66%] [G loss: 0.722956]\n",
      "epoch:24 step:23332 [D loss: 0.526665, acc.: 72.66%] [G loss: 0.711818]\n",
      "epoch:24 step:23333 [D loss: 0.552457, acc.: 72.66%] [G loss: 0.676249]\n",
      "epoch:24 step:23334 [D loss: 0.571749, acc.: 64.84%] [G loss: 0.613900]\n",
      "epoch:24 step:23335 [D loss: 0.607425, acc.: 67.19%] [G loss: 0.393693]\n",
      "epoch:24 step:23336 [D loss: 0.573860, acc.: 64.84%] [G loss: 0.491943]\n",
      "epoch:24 step:23337 [D loss: 0.549724, acc.: 68.75%] [G loss: 0.637756]\n",
      "epoch:24 step:23338 [D loss: 0.565299, acc.: 71.09%] [G loss: 0.552289]\n",
      "epoch:24 step:23339 [D loss: 0.601839, acc.: 62.50%] [G loss: 0.623897]\n",
      "epoch:24 step:23340 [D loss: 0.591564, acc.: 62.50%] [G loss: 0.585592]\n",
      "epoch:24 step:23341 [D loss: 0.557380, acc.: 71.09%] [G loss: 0.811629]\n",
      "epoch:24 step:23342 [D loss: 0.555011, acc.: 67.97%] [G loss: 0.635705]\n",
      "epoch:24 step:23343 [D loss: 0.601108, acc.: 70.31%] [G loss: 0.713676]\n",
      "epoch:24 step:23344 [D loss: 0.527617, acc.: 74.22%] [G loss: 0.655224]\n",
      "epoch:24 step:23345 [D loss: 0.530444, acc.: 77.34%] [G loss: 0.669318]\n",
      "epoch:24 step:23346 [D loss: 0.621543, acc.: 65.62%] [G loss: 0.745086]\n",
      "epoch:24 step:23347 [D loss: 0.561979, acc.: 68.75%] [G loss: 0.806212]\n",
      "epoch:24 step:23348 [D loss: 0.464067, acc.: 78.91%] [G loss: 0.863592]\n",
      "epoch:24 step:23349 [D loss: 0.611493, acc.: 67.97%] [G loss: 0.543772]\n",
      "epoch:24 step:23350 [D loss: 0.521588, acc.: 74.22%] [G loss: 0.593606]\n",
      "epoch:24 step:23351 [D loss: 0.582862, acc.: 69.53%] [G loss: 0.531786]\n",
      "epoch:24 step:23352 [D loss: 0.527959, acc.: 72.66%] [G loss: 0.536221]\n",
      "epoch:24 step:23353 [D loss: 0.603798, acc.: 61.72%] [G loss: 0.459560]\n",
      "epoch:24 step:23354 [D loss: 0.541550, acc.: 72.66%] [G loss: 0.654140]\n",
      "epoch:24 step:23355 [D loss: 0.648484, acc.: 64.06%] [G loss: 0.443531]\n",
      "epoch:24 step:23356 [D loss: 0.562162, acc.: 65.62%] [G loss: 0.450265]\n",
      "epoch:24 step:23357 [D loss: 0.528513, acc.: 68.75%] [G loss: 0.784704]\n",
      "epoch:24 step:23358 [D loss: 0.473788, acc.: 74.22%] [G loss: 0.823433]\n",
      "epoch:24 step:23359 [D loss: 0.492015, acc.: 72.66%] [G loss: 0.723840]\n",
      "epoch:24 step:23360 [D loss: 0.551221, acc.: 71.09%] [G loss: 0.802286]\n",
      "epoch:24 step:23361 [D loss: 0.566447, acc.: 70.31%] [G loss: 0.689051]\n",
      "epoch:24 step:23362 [D loss: 0.580928, acc.: 65.62%] [G loss: 0.596685]\n",
      "epoch:24 step:23363 [D loss: 0.524427, acc.: 75.78%] [G loss: 0.841871]\n",
      "epoch:24 step:23364 [D loss: 0.542425, acc.: 72.66%] [G loss: 0.570490]\n",
      "epoch:24 step:23365 [D loss: 0.576946, acc.: 68.75%] [G loss: 0.546731]\n",
      "epoch:24 step:23366 [D loss: 0.511713, acc.: 75.00%] [G loss: 0.626472]\n",
      "epoch:24 step:23367 [D loss: 0.552451, acc.: 67.19%] [G loss: 0.605947]\n",
      "epoch:24 step:23368 [D loss: 0.651580, acc.: 56.25%] [G loss: 0.589944]\n",
      "epoch:24 step:23369 [D loss: 0.599114, acc.: 69.53%] [G loss: 0.489750]\n",
      "epoch:24 step:23370 [D loss: 0.551926, acc.: 67.19%] [G loss: 0.470668]\n",
      "epoch:24 step:23371 [D loss: 0.552979, acc.: 67.97%] [G loss: 0.613005]\n",
      "epoch:24 step:23372 [D loss: 0.460709, acc.: 75.00%] [G loss: 0.726711]\n",
      "epoch:24 step:23373 [D loss: 0.534955, acc.: 70.31%] [G loss: 0.683115]\n",
      "epoch:24 step:23374 [D loss: 0.498234, acc.: 74.22%] [G loss: 0.830174]\n",
      "epoch:24 step:23375 [D loss: 0.512122, acc.: 75.78%] [G loss: 0.746960]\n",
      "epoch:24 step:23376 [D loss: 0.535714, acc.: 67.19%] [G loss: 0.779039]\n",
      "epoch:24 step:23377 [D loss: 0.585104, acc.: 67.97%] [G loss: 0.703526]\n",
      "epoch:24 step:23378 [D loss: 0.512128, acc.: 70.31%] [G loss: 0.705327]\n",
      "epoch:24 step:23379 [D loss: 0.575934, acc.: 68.75%] [G loss: 0.713478]\n",
      "epoch:24 step:23380 [D loss: 0.658073, acc.: 61.72%] [G loss: 0.512475]\n",
      "epoch:24 step:23381 [D loss: 0.555747, acc.: 75.00%] [G loss: 0.476189]\n",
      "epoch:24 step:23382 [D loss: 0.440973, acc.: 82.03%] [G loss: 0.630836]\n",
      "epoch:24 step:23383 [D loss: 0.447999, acc.: 78.12%] [G loss: 0.967110]\n",
      "epoch:24 step:23384 [D loss: 0.524443, acc.: 74.22%] [G loss: 0.859662]\n",
      "epoch:24 step:23385 [D loss: 0.530124, acc.: 69.53%] [G loss: 0.795973]\n",
      "epoch:24 step:23386 [D loss: 0.467724, acc.: 76.56%] [G loss: 0.756639]\n",
      "epoch:24 step:23387 [D loss: 0.446174, acc.: 80.47%] [G loss: 0.917881]\n",
      "epoch:24 step:23388 [D loss: 0.482119, acc.: 78.91%] [G loss: 0.724608]\n",
      "epoch:24 step:23389 [D loss: 0.504110, acc.: 70.31%] [G loss: 0.742971]\n",
      "epoch:24 step:23390 [D loss: 0.562626, acc.: 64.84%] [G loss: 0.744020]\n",
      "epoch:24 step:23391 [D loss: 0.516573, acc.: 70.31%] [G loss: 0.772836]\n",
      "epoch:24 step:23392 [D loss: 0.514483, acc.: 75.00%] [G loss: 0.758461]\n",
      "epoch:24 step:23393 [D loss: 0.601233, acc.: 65.62%] [G loss: 0.790003]\n",
      "epoch:24 step:23394 [D loss: 0.514998, acc.: 78.12%] [G loss: 0.783693]\n",
      "epoch:24 step:23395 [D loss: 0.590534, acc.: 64.06%] [G loss: 0.798167]\n",
      "epoch:24 step:23396 [D loss: 0.538196, acc.: 71.88%] [G loss: 0.721280]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:24 step:23397 [D loss: 0.435667, acc.: 83.59%] [G loss: 0.732641]\n",
      "epoch:24 step:23398 [D loss: 0.556724, acc.: 70.31%] [G loss: 0.840621]\n",
      "epoch:24 step:23399 [D loss: 0.506682, acc.: 74.22%] [G loss: 0.725699]\n",
      "epoch:24 step:23400 [D loss: 0.547693, acc.: 67.19%] [G loss: 0.776167]\n",
      "##############\n",
      "[3.56274106 1.40433113 6.12550499 4.98505779 4.08989377 5.49336031\n",
      " 4.70159763 5.00146988 4.83179293 4.33546677]\n",
      "##########\n",
      "epoch:24 step:23401 [D loss: 0.567689, acc.: 67.97%] [G loss: 0.683806]\n",
      "epoch:24 step:23402 [D loss: 0.580940, acc.: 64.84%] [G loss: 0.846600]\n",
      "epoch:24 step:23403 [D loss: 0.632177, acc.: 65.62%] [G loss: 0.748970]\n",
      "epoch:24 step:23404 [D loss: 0.548458, acc.: 72.66%] [G loss: 0.668638]\n",
      "epoch:24 step:23405 [D loss: 0.646622, acc.: 61.72%] [G loss: 0.619095]\n",
      "epoch:24 step:23406 [D loss: 0.509360, acc.: 75.00%] [G loss: 0.624335]\n",
      "epoch:24 step:23407 [D loss: 0.469079, acc.: 78.91%] [G loss: 0.807722]\n",
      "epoch:24 step:23408 [D loss: 0.634766, acc.: 67.19%] [G loss: 0.696481]\n",
      "epoch:24 step:23409 [D loss: 0.581942, acc.: 68.75%] [G loss: 0.735855]\n",
      "epoch:24 step:23410 [D loss: 0.542323, acc.: 72.66%] [G loss: 0.657673]\n",
      "epoch:24 step:23411 [D loss: 0.460009, acc.: 75.78%] [G loss: 0.779572]\n",
      "epoch:24 step:23412 [D loss: 0.432881, acc.: 81.25%] [G loss: 0.851736]\n",
      "epoch:24 step:23413 [D loss: 0.395899, acc.: 80.47%] [G loss: 1.011141]\n",
      "epoch:24 step:23414 [D loss: 0.395315, acc.: 82.81%] [G loss: 0.988905]\n",
      "epoch:24 step:23415 [D loss: 0.451491, acc.: 75.78%] [G loss: 1.406058]\n",
      "epoch:24 step:23416 [D loss: 0.703583, acc.: 62.50%] [G loss: 1.198045]\n",
      "epoch:24 step:23417 [D loss: 0.445050, acc.: 76.56%] [G loss: 1.596576]\n",
      "epoch:24 step:23418 [D loss: 0.480176, acc.: 75.00%] [G loss: 1.142072]\n",
      "epoch:24 step:23419 [D loss: 0.566964, acc.: 67.97%] [G loss: 1.298952]\n",
      "epoch:24 step:23420 [D loss: 0.631662, acc.: 61.72%] [G loss: 0.943635]\n",
      "epoch:24 step:23421 [D loss: 0.477158, acc.: 73.44%] [G loss: 0.809062]\n",
      "epoch:24 step:23422 [D loss: 0.528026, acc.: 71.09%] [G loss: 0.958312]\n",
      "epoch:24 step:23423 [D loss: 0.460632, acc.: 73.44%] [G loss: 1.047086]\n",
      "epoch:24 step:23424 [D loss: 0.427237, acc.: 78.91%] [G loss: 1.157760]\n",
      "epoch:24 step:23425 [D loss: 0.415268, acc.: 79.69%] [G loss: 1.250324]\n",
      "epoch:25 step:23426 [D loss: 0.582642, acc.: 71.09%] [G loss: 1.299987]\n",
      "epoch:25 step:23427 [D loss: 0.449309, acc.: 78.12%] [G loss: 1.225091]\n",
      "epoch:25 step:23428 [D loss: 0.599980, acc.: 66.41%] [G loss: 1.036962]\n",
      "epoch:25 step:23429 [D loss: 0.519605, acc.: 72.66%] [G loss: 0.934860]\n",
      "epoch:25 step:23430 [D loss: 0.553410, acc.: 68.75%] [G loss: 0.909324]\n",
      "epoch:25 step:23431 [D loss: 0.626374, acc.: 67.19%] [G loss: 0.769313]\n",
      "epoch:25 step:23432 [D loss: 0.454044, acc.: 79.69%] [G loss: 0.885844]\n",
      "epoch:25 step:23433 [D loss: 0.490247, acc.: 75.78%] [G loss: 0.791966]\n",
      "epoch:25 step:23434 [D loss: 0.485057, acc.: 76.56%] [G loss: 0.857108]\n",
      "epoch:25 step:23435 [D loss: 0.518634, acc.: 75.00%] [G loss: 0.738861]\n",
      "epoch:25 step:23436 [D loss: 0.433794, acc.: 83.59%] [G loss: 0.848796]\n",
      "epoch:25 step:23437 [D loss: 0.646753, acc.: 63.28%] [G loss: 0.665972]\n",
      "epoch:25 step:23438 [D loss: 0.545691, acc.: 71.09%] [G loss: 0.568081]\n",
      "epoch:25 step:23439 [D loss: 0.498376, acc.: 82.03%] [G loss: 0.601364]\n",
      "epoch:25 step:23440 [D loss: 0.569510, acc.: 68.75%] [G loss: 0.738600]\n",
      "epoch:25 step:23441 [D loss: 0.456440, acc.: 77.34%] [G loss: 0.912535]\n",
      "epoch:25 step:23442 [D loss: 0.546895, acc.: 70.31%] [G loss: 0.756372]\n",
      "epoch:25 step:23443 [D loss: 0.502991, acc.: 74.22%] [G loss: 0.776480]\n",
      "epoch:25 step:23444 [D loss: 0.598964, acc.: 67.97%] [G loss: 0.650269]\n",
      "epoch:25 step:23445 [D loss: 0.544163, acc.: 67.19%] [G loss: 0.802043]\n",
      "epoch:25 step:23446 [D loss: 0.576359, acc.: 66.41%] [G loss: 0.651924]\n",
      "epoch:25 step:23447 [D loss: 0.482273, acc.: 78.91%] [G loss: 1.114156]\n",
      "epoch:25 step:23448 [D loss: 0.558748, acc.: 74.22%] [G loss: 0.884016]\n",
      "epoch:25 step:23449 [D loss: 0.546800, acc.: 71.88%] [G loss: 0.598019]\n",
      "epoch:25 step:23450 [D loss: 0.489017, acc.: 77.34%] [G loss: 0.754891]\n",
      "epoch:25 step:23451 [D loss: 0.578894, acc.: 67.97%] [G loss: 0.656670]\n",
      "epoch:25 step:23452 [D loss: 0.472218, acc.: 79.69%] [G loss: 0.758599]\n",
      "epoch:25 step:23453 [D loss: 0.532290, acc.: 67.97%] [G loss: 0.805632]\n",
      "epoch:25 step:23454 [D loss: 0.508077, acc.: 71.09%] [G loss: 0.614920]\n",
      "epoch:25 step:23455 [D loss: 0.591426, acc.: 65.62%] [G loss: 0.587546]\n",
      "epoch:25 step:23456 [D loss: 0.615532, acc.: 64.84%] [G loss: 0.631533]\n",
      "epoch:25 step:23457 [D loss: 0.543218, acc.: 67.97%] [G loss: 0.617264]\n",
      "epoch:25 step:23458 [D loss: 0.507744, acc.: 72.66%] [G loss: 0.569211]\n",
      "epoch:25 step:23459 [D loss: 0.607638, acc.: 62.50%] [G loss: 0.714571]\n",
      "epoch:25 step:23460 [D loss: 0.575446, acc.: 65.62%] [G loss: 0.715690]\n",
      "epoch:25 step:23461 [D loss: 0.537203, acc.: 69.53%] [G loss: 0.689636]\n",
      "epoch:25 step:23462 [D loss: 0.521741, acc.: 71.09%] [G loss: 0.717531]\n",
      "epoch:25 step:23463 [D loss: 0.540380, acc.: 76.56%] [G loss: 0.714919]\n",
      "epoch:25 step:23464 [D loss: 0.515615, acc.: 69.53%] [G loss: 0.870555]\n",
      "epoch:25 step:23465 [D loss: 0.438290, acc.: 78.91%] [G loss: 0.822131]\n",
      "epoch:25 step:23466 [D loss: 0.553425, acc.: 71.88%] [G loss: 0.650433]\n",
      "epoch:25 step:23467 [D loss: 0.561860, acc.: 65.62%] [G loss: 0.586267]\n",
      "epoch:25 step:23468 [D loss: 0.511884, acc.: 74.22%] [G loss: 0.640186]\n",
      "epoch:25 step:23469 [D loss: 0.591361, acc.: 64.84%] [G loss: 0.606546]\n",
      "epoch:25 step:23470 [D loss: 0.514956, acc.: 75.78%] [G loss: 0.653028]\n",
      "epoch:25 step:23471 [D loss: 0.469638, acc.: 73.44%] [G loss: 0.747321]\n",
      "epoch:25 step:23472 [D loss: 0.534331, acc.: 71.88%] [G loss: 0.750780]\n",
      "epoch:25 step:23473 [D loss: 0.548294, acc.: 70.31%] [G loss: 0.746794]\n",
      "epoch:25 step:23474 [D loss: 0.516749, acc.: 72.66%] [G loss: 0.828005]\n",
      "epoch:25 step:23475 [D loss: 0.496559, acc.: 75.78%] [G loss: 1.109441]\n",
      "epoch:25 step:23476 [D loss: 0.580279, acc.: 64.84%] [G loss: 0.757075]\n",
      "epoch:25 step:23477 [D loss: 0.550559, acc.: 67.97%] [G loss: 0.583184]\n",
      "epoch:25 step:23478 [D loss: 0.532960, acc.: 76.56%] [G loss: 0.879624]\n",
      "epoch:25 step:23479 [D loss: 0.483628, acc.: 75.00%] [G loss: 0.927488]\n",
      "epoch:25 step:23480 [D loss: 0.609776, acc.: 72.66%] [G loss: 0.861747]\n",
      "epoch:25 step:23481 [D loss: 0.508771, acc.: 75.78%] [G loss: 0.624162]\n",
      "epoch:25 step:23482 [D loss: 0.522213, acc.: 76.56%] [G loss: 0.818514]\n",
      "epoch:25 step:23483 [D loss: 0.566537, acc.: 67.97%] [G loss: 0.805685]\n",
      "epoch:25 step:23484 [D loss: 0.465975, acc.: 75.00%] [G loss: 0.752517]\n",
      "epoch:25 step:23485 [D loss: 0.574658, acc.: 72.66%] [G loss: 0.717184]\n",
      "epoch:25 step:23486 [D loss: 0.543974, acc.: 68.75%] [G loss: 0.869135]\n",
      "epoch:25 step:23487 [D loss: 0.584586, acc.: 71.88%] [G loss: 0.748929]\n",
      "epoch:25 step:23488 [D loss: 0.560308, acc.: 67.97%] [G loss: 0.628575]\n",
      "epoch:25 step:23489 [D loss: 0.567363, acc.: 69.53%] [G loss: 0.577095]\n",
      "epoch:25 step:23490 [D loss: 0.517523, acc.: 69.53%] [G loss: 0.715265]\n",
      "epoch:25 step:23491 [D loss: 0.572433, acc.: 72.66%] [G loss: 0.756567]\n",
      "epoch:25 step:23492 [D loss: 0.532395, acc.: 71.09%] [G loss: 0.663548]\n",
      "epoch:25 step:23493 [D loss: 0.528047, acc.: 69.53%] [G loss: 0.619305]\n",
      "epoch:25 step:23494 [D loss: 0.476194, acc.: 76.56%] [G loss: 0.618666]\n",
      "epoch:25 step:23495 [D loss: 0.524123, acc.: 72.66%] [G loss: 0.683385]\n",
      "epoch:25 step:23496 [D loss: 0.519255, acc.: 74.22%] [G loss: 0.633242]\n",
      "epoch:25 step:23497 [D loss: 0.508036, acc.: 75.78%] [G loss: 0.707918]\n",
      "epoch:25 step:23498 [D loss: 0.531549, acc.: 71.09%] [G loss: 0.598074]\n",
      "epoch:25 step:23499 [D loss: 0.436653, acc.: 81.25%] [G loss: 0.781614]\n",
      "epoch:25 step:23500 [D loss: 0.560276, acc.: 67.19%] [G loss: 0.914542]\n",
      "epoch:25 step:23501 [D loss: 0.482903, acc.: 79.69%] [G loss: 0.893731]\n",
      "epoch:25 step:23502 [D loss: 0.432188, acc.: 78.91%] [G loss: 1.077778]\n",
      "epoch:25 step:23503 [D loss: 0.588166, acc.: 68.75%] [G loss: 0.717627]\n",
      "epoch:25 step:23504 [D loss: 0.562035, acc.: 69.53%] [G loss: 0.580122]\n",
      "epoch:25 step:23505 [D loss: 0.505570, acc.: 78.12%] [G loss: 0.578083]\n",
      "epoch:25 step:23506 [D loss: 0.466137, acc.: 75.78%] [G loss: 0.867679]\n",
      "epoch:25 step:23507 [D loss: 0.501822, acc.: 72.66%] [G loss: 0.749727]\n",
      "epoch:25 step:23508 [D loss: 0.499276, acc.: 73.44%] [G loss: 0.695260]\n",
      "epoch:25 step:23509 [D loss: 0.493528, acc.: 78.91%] [G loss: 0.699564]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:25 step:23510 [D loss: 0.579250, acc.: 64.84%] [G loss: 0.706672]\n",
      "epoch:25 step:23511 [D loss: 0.545256, acc.: 68.75%] [G loss: 0.822269]\n",
      "epoch:25 step:23512 [D loss: 0.499143, acc.: 72.66%] [G loss: 0.903949]\n",
      "epoch:25 step:23513 [D loss: 0.475391, acc.: 76.56%] [G loss: 0.646182]\n",
      "epoch:25 step:23514 [D loss: 0.544865, acc.: 69.53%] [G loss: 0.708272]\n",
      "epoch:25 step:23515 [D loss: 0.463690, acc.: 78.91%] [G loss: 0.809395]\n",
      "epoch:25 step:23516 [D loss: 0.642618, acc.: 61.72%] [G loss: 0.647213]\n",
      "epoch:25 step:23517 [D loss: 0.450488, acc.: 78.91%] [G loss: 0.773915]\n",
      "epoch:25 step:23518 [D loss: 0.509280, acc.: 74.22%] [G loss: 0.739686]\n",
      "epoch:25 step:23519 [D loss: 0.494723, acc.: 75.78%] [G loss: 0.875310]\n",
      "epoch:25 step:23520 [D loss: 0.472862, acc.: 78.12%] [G loss: 0.730953]\n",
      "epoch:25 step:23521 [D loss: 0.516744, acc.: 71.88%] [G loss: 0.647229]\n",
      "epoch:25 step:23522 [D loss: 0.526281, acc.: 68.75%] [G loss: 0.819764]\n",
      "epoch:25 step:23523 [D loss: 0.524960, acc.: 72.66%] [G loss: 0.748298]\n",
      "epoch:25 step:23524 [D loss: 0.598340, acc.: 67.97%] [G loss: 0.859611]\n",
      "epoch:25 step:23525 [D loss: 0.459638, acc.: 76.56%] [G loss: 0.972339]\n",
      "epoch:25 step:23526 [D loss: 0.548008, acc.: 75.78%] [G loss: 0.915939]\n",
      "epoch:25 step:23527 [D loss: 0.611568, acc.: 67.97%] [G loss: 0.695962]\n",
      "epoch:25 step:23528 [D loss: 0.515825, acc.: 69.53%] [G loss: 0.646713]\n",
      "epoch:25 step:23529 [D loss: 0.502848, acc.: 75.78%] [G loss: 0.549002]\n",
      "epoch:25 step:23530 [D loss: 0.599590, acc.: 66.41%] [G loss: 0.515855]\n",
      "epoch:25 step:23531 [D loss: 0.539443, acc.: 67.97%] [G loss: 0.579836]\n",
      "epoch:25 step:23532 [D loss: 0.583170, acc.: 67.19%] [G loss: 0.797990]\n",
      "epoch:25 step:23533 [D loss: 0.667022, acc.: 64.84%] [G loss: 0.758639]\n",
      "epoch:25 step:23534 [D loss: 0.527088, acc.: 72.66%] [G loss: 0.592033]\n",
      "epoch:25 step:23535 [D loss: 0.517139, acc.: 71.88%] [G loss: 0.672045]\n",
      "epoch:25 step:23536 [D loss: 0.470559, acc.: 73.44%] [G loss: 0.623889]\n",
      "epoch:25 step:23537 [D loss: 0.543015, acc.: 71.09%] [G loss: 0.585591]\n",
      "epoch:25 step:23538 [D loss: 0.518019, acc.: 73.44%] [G loss: 0.676935]\n",
      "epoch:25 step:23539 [D loss: 0.536012, acc.: 77.34%] [G loss: 0.675985]\n",
      "epoch:25 step:23540 [D loss: 0.531399, acc.: 74.22%] [G loss: 0.649203]\n",
      "epoch:25 step:23541 [D loss: 0.496610, acc.: 74.22%] [G loss: 0.760382]\n",
      "epoch:25 step:23542 [D loss: 0.507228, acc.: 74.22%] [G loss: 0.713435]\n",
      "epoch:25 step:23543 [D loss: 0.519294, acc.: 69.53%] [G loss: 0.811284]\n",
      "epoch:25 step:23544 [D loss: 0.444432, acc.: 82.03%] [G loss: 0.964113]\n",
      "epoch:25 step:23545 [D loss: 0.505906, acc.: 73.44%] [G loss: 1.094287]\n",
      "epoch:25 step:23546 [D loss: 0.518217, acc.: 75.00%] [G loss: 0.908210]\n",
      "epoch:25 step:23547 [D loss: 0.531782, acc.: 72.66%] [G loss: 0.862450]\n",
      "epoch:25 step:23548 [D loss: 0.457236, acc.: 76.56%] [G loss: 0.848218]\n",
      "epoch:25 step:23549 [D loss: 0.557362, acc.: 67.97%] [G loss: 0.693571]\n",
      "epoch:25 step:23550 [D loss: 0.575910, acc.: 71.88%] [G loss: 0.610555]\n",
      "epoch:25 step:23551 [D loss: 0.551538, acc.: 67.97%] [G loss: 0.640562]\n",
      "epoch:25 step:23552 [D loss: 0.484998, acc.: 73.44%] [G loss: 0.596406]\n",
      "epoch:25 step:23553 [D loss: 0.471169, acc.: 72.66%] [G loss: 0.721047]\n",
      "epoch:25 step:23554 [D loss: 0.572603, acc.: 71.09%] [G loss: 0.579422]\n",
      "epoch:25 step:23555 [D loss: 0.438758, acc.: 84.38%] [G loss: 0.766464]\n",
      "epoch:25 step:23556 [D loss: 0.484049, acc.: 73.44%] [G loss: 0.909461]\n",
      "epoch:25 step:23557 [D loss: 0.493552, acc.: 75.00%] [G loss: 0.709249]\n",
      "epoch:25 step:23558 [D loss: 0.523358, acc.: 71.09%] [G loss: 0.762506]\n",
      "epoch:25 step:23559 [D loss: 0.533896, acc.: 68.75%] [G loss: 1.101605]\n",
      "epoch:25 step:23560 [D loss: 0.528539, acc.: 71.09%] [G loss: 0.828933]\n",
      "epoch:25 step:23561 [D loss: 0.509093, acc.: 75.00%] [G loss: 0.953719]\n",
      "epoch:25 step:23562 [D loss: 0.604532, acc.: 64.06%] [G loss: 0.636262]\n",
      "epoch:25 step:23563 [D loss: 0.563999, acc.: 71.88%] [G loss: 0.618261]\n",
      "epoch:25 step:23564 [D loss: 0.565237, acc.: 67.97%] [G loss: 0.733628]\n",
      "epoch:25 step:23565 [D loss: 0.576631, acc.: 66.41%] [G loss: 0.620711]\n",
      "epoch:25 step:23566 [D loss: 0.542508, acc.: 67.97%] [G loss: 0.658489]\n",
      "epoch:25 step:23567 [D loss: 0.565710, acc.: 65.62%] [G loss: 0.634126]\n",
      "epoch:25 step:23568 [D loss: 0.598384, acc.: 64.06%] [G loss: 0.520887]\n",
      "epoch:25 step:23569 [D loss: 0.476103, acc.: 77.34%] [G loss: 0.697204]\n",
      "epoch:25 step:23570 [D loss: 0.534998, acc.: 71.09%] [G loss: 0.626043]\n",
      "epoch:25 step:23571 [D loss: 0.500374, acc.: 74.22%] [G loss: 0.718333]\n",
      "epoch:25 step:23572 [D loss: 0.604997, acc.: 67.19%] [G loss: 0.522484]\n",
      "epoch:25 step:23573 [D loss: 0.565158, acc.: 66.41%] [G loss: 0.658727]\n",
      "epoch:25 step:23574 [D loss: 0.558727, acc.: 72.66%] [G loss: 0.654151]\n",
      "epoch:25 step:23575 [D loss: 0.588837, acc.: 71.88%] [G loss: 0.732957]\n",
      "epoch:25 step:23576 [D loss: 0.554791, acc.: 67.19%] [G loss: 0.693386]\n",
      "epoch:25 step:23577 [D loss: 0.420195, acc.: 78.91%] [G loss: 0.836840]\n",
      "epoch:25 step:23578 [D loss: 0.588847, acc.: 70.31%] [G loss: 0.705288]\n",
      "epoch:25 step:23579 [D loss: 0.534309, acc.: 70.31%] [G loss: 0.681841]\n",
      "epoch:25 step:23580 [D loss: 0.493300, acc.: 78.12%] [G loss: 0.728025]\n",
      "epoch:25 step:23581 [D loss: 0.512200, acc.: 71.88%] [G loss: 0.784928]\n",
      "epoch:25 step:23582 [D loss: 0.570982, acc.: 67.97%] [G loss: 0.768740]\n",
      "epoch:25 step:23583 [D loss: 0.585609, acc.: 64.84%] [G loss: 0.536528]\n",
      "epoch:25 step:23584 [D loss: 0.472334, acc.: 79.69%] [G loss: 0.786387]\n",
      "epoch:25 step:23585 [D loss: 0.635038, acc.: 64.84%] [G loss: 0.556842]\n",
      "epoch:25 step:23586 [D loss: 0.480184, acc.: 69.53%] [G loss: 0.750892]\n",
      "epoch:25 step:23587 [D loss: 0.477529, acc.: 75.78%] [G loss: 0.896866]\n",
      "epoch:25 step:23588 [D loss: 0.522469, acc.: 66.41%] [G loss: 0.834678]\n",
      "epoch:25 step:23589 [D loss: 0.475098, acc.: 74.22%] [G loss: 0.700075]\n",
      "epoch:25 step:23590 [D loss: 0.514925, acc.: 71.88%] [G loss: 0.679024]\n",
      "epoch:25 step:23591 [D loss: 0.538130, acc.: 70.31%] [G loss: 0.558852]\n",
      "epoch:25 step:23592 [D loss: 0.498640, acc.: 73.44%] [G loss: 0.643380]\n",
      "epoch:25 step:23593 [D loss: 0.561641, acc.: 73.44%] [G loss: 0.536826]\n",
      "epoch:25 step:23594 [D loss: 0.592710, acc.: 64.06%] [G loss: 0.413450]\n",
      "epoch:25 step:23595 [D loss: 0.486012, acc.: 73.44%] [G loss: 0.693226]\n",
      "epoch:25 step:23596 [D loss: 0.550600, acc.: 69.53%] [G loss: 0.586176]\n",
      "epoch:25 step:23597 [D loss: 0.523841, acc.: 69.53%] [G loss: 0.682968]\n",
      "epoch:25 step:23598 [D loss: 0.484520, acc.: 71.88%] [G loss: 0.783437]\n",
      "epoch:25 step:23599 [D loss: 0.652529, acc.: 60.16%] [G loss: 0.557402]\n",
      "epoch:25 step:23600 [D loss: 0.574416, acc.: 64.06%] [G loss: 0.639320]\n",
      "##############\n",
      "[2.58871258 1.25824689 6.33612062 4.91662224 3.70558417 5.58828003\n",
      " 4.48909621 4.95132762 4.60120888 4.27822295]\n",
      "##########\n",
      "epoch:25 step:23601 [D loss: 0.482026, acc.: 71.88%] [G loss: 0.643476]\n",
      "epoch:25 step:23602 [D loss: 0.509471, acc.: 69.53%] [G loss: 0.846760]\n",
      "epoch:25 step:23603 [D loss: 0.558143, acc.: 67.19%] [G loss: 0.733572]\n",
      "epoch:25 step:23604 [D loss: 0.592033, acc.: 65.62%] [G loss: 0.690052]\n",
      "epoch:25 step:23605 [D loss: 0.602506, acc.: 63.28%] [G loss: 0.521896]\n",
      "epoch:25 step:23606 [D loss: 0.557192, acc.: 70.31%] [G loss: 0.624721]\n",
      "epoch:25 step:23607 [D loss: 0.537979, acc.: 67.97%] [G loss: 0.672363]\n",
      "epoch:25 step:23608 [D loss: 0.553050, acc.: 70.31%] [G loss: 0.794060]\n",
      "epoch:25 step:23609 [D loss: 0.496405, acc.: 75.78%] [G loss: 0.852342]\n",
      "epoch:25 step:23610 [D loss: 0.652355, acc.: 59.38%] [G loss: 0.484808]\n",
      "epoch:25 step:23611 [D loss: 0.504598, acc.: 75.78%] [G loss: 0.844287]\n",
      "epoch:25 step:23612 [D loss: 0.652618, acc.: 57.03%] [G loss: 0.572730]\n",
      "epoch:25 step:23613 [D loss: 0.558522, acc.: 67.19%] [G loss: 0.726315]\n",
      "epoch:25 step:23614 [D loss: 0.531097, acc.: 71.88%] [G loss: 0.582836]\n",
      "epoch:25 step:23615 [D loss: 0.462005, acc.: 75.78%] [G loss: 0.646653]\n",
      "epoch:25 step:23616 [D loss: 0.495362, acc.: 77.34%] [G loss: 0.675246]\n",
      "epoch:25 step:23617 [D loss: 0.524297, acc.: 72.66%] [G loss: 0.683226]\n",
      "epoch:25 step:23618 [D loss: 0.525187, acc.: 75.00%] [G loss: 0.682344]\n",
      "epoch:25 step:23619 [D loss: 0.449234, acc.: 74.22%] [G loss: 0.705955]\n",
      "epoch:25 step:23620 [D loss: 0.587847, acc.: 66.41%] [G loss: 0.753727]\n",
      "epoch:25 step:23621 [D loss: 0.536070, acc.: 70.31%] [G loss: 0.623051]\n",
      "epoch:25 step:23622 [D loss: 0.535864, acc.: 70.31%] [G loss: 0.757692]\n",
      "epoch:25 step:23623 [D loss: 0.472052, acc.: 78.12%] [G loss: 0.758444]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:25 step:23624 [D loss: 0.508563, acc.: 73.44%] [G loss: 1.232972]\n",
      "epoch:25 step:23625 [D loss: 0.659581, acc.: 59.38%] [G loss: 0.567087]\n",
      "epoch:25 step:23626 [D loss: 0.595081, acc.: 67.19%] [G loss: 0.567585]\n",
      "epoch:25 step:23627 [D loss: 0.510707, acc.: 75.78%] [G loss: 0.696710]\n",
      "epoch:25 step:23628 [D loss: 0.587653, acc.: 66.41%] [G loss: 0.682603]\n",
      "epoch:25 step:23629 [D loss: 0.581545, acc.: 67.97%] [G loss: 0.625806]\n",
      "epoch:25 step:23630 [D loss: 0.466091, acc.: 74.22%] [G loss: 0.898668]\n",
      "epoch:25 step:23631 [D loss: 0.492789, acc.: 74.22%] [G loss: 0.780640]\n",
      "epoch:25 step:23632 [D loss: 0.438851, acc.: 77.34%] [G loss: 0.905837]\n",
      "epoch:25 step:23633 [D loss: 0.436719, acc.: 78.12%] [G loss: 0.806276]\n",
      "epoch:25 step:23634 [D loss: 0.501997, acc.: 71.88%] [G loss: 0.906966]\n",
      "epoch:25 step:23635 [D loss: 0.641409, acc.: 63.28%] [G loss: 0.680179]\n",
      "epoch:25 step:23636 [D loss: 0.540933, acc.: 74.22%] [G loss: 0.632654]\n",
      "epoch:25 step:23637 [D loss: 0.518860, acc.: 78.12%] [G loss: 0.627428]\n",
      "epoch:25 step:23638 [D loss: 0.572259, acc.: 68.75%] [G loss: 0.719532]\n",
      "epoch:25 step:23639 [D loss: 0.597440, acc.: 66.41%] [G loss: 0.483081]\n",
      "epoch:25 step:23640 [D loss: 0.578390, acc.: 65.62%] [G loss: 0.612483]\n",
      "epoch:25 step:23641 [D loss: 0.517398, acc.: 75.00%] [G loss: 0.627242]\n",
      "epoch:25 step:23642 [D loss: 0.494374, acc.: 75.78%] [G loss: 0.688807]\n",
      "epoch:25 step:23643 [D loss: 0.508673, acc.: 72.66%] [G loss: 0.679601]\n",
      "epoch:25 step:23644 [D loss: 0.455056, acc.: 82.03%] [G loss: 0.773135]\n",
      "epoch:25 step:23645 [D loss: 0.608383, acc.: 67.19%] [G loss: 0.772631]\n",
      "epoch:25 step:23646 [D loss: 0.538108, acc.: 72.66%] [G loss: 0.907387]\n",
      "epoch:25 step:23647 [D loss: 0.492491, acc.: 77.34%] [G loss: 0.964170]\n",
      "epoch:25 step:23648 [D loss: 0.483007, acc.: 79.69%] [G loss: 0.677166]\n",
      "epoch:25 step:23649 [D loss: 0.564801, acc.: 71.09%] [G loss: 0.705110]\n",
      "epoch:25 step:23650 [D loss: 0.569665, acc.: 63.28%] [G loss: 0.821695]\n",
      "epoch:25 step:23651 [D loss: 0.548945, acc.: 66.41%] [G loss: 0.659322]\n",
      "epoch:25 step:23652 [D loss: 0.572901, acc.: 72.66%] [G loss: 0.545831]\n",
      "epoch:25 step:23653 [D loss: 0.586863, acc.: 64.06%] [G loss: 0.603513]\n",
      "epoch:25 step:23654 [D loss: 0.528835, acc.: 76.56%] [G loss: 0.758631]\n",
      "epoch:25 step:23655 [D loss: 0.498074, acc.: 75.00%] [G loss: 0.841206]\n",
      "epoch:25 step:23656 [D loss: 0.425090, acc.: 82.81%] [G loss: 1.092149]\n",
      "epoch:25 step:23657 [D loss: 0.541691, acc.: 73.44%] [G loss: 1.148193]\n",
      "epoch:25 step:23658 [D loss: 0.507409, acc.: 74.22%] [G loss: 0.860003]\n",
      "epoch:25 step:23659 [D loss: 0.608247, acc.: 67.97%] [G loss: 0.635138]\n",
      "epoch:25 step:23660 [D loss: 0.585916, acc.: 64.06%] [G loss: 0.617471]\n",
      "epoch:25 step:23661 [D loss: 0.510159, acc.: 70.31%] [G loss: 0.496265]\n",
      "epoch:25 step:23662 [D loss: 0.530377, acc.: 71.09%] [G loss: 0.554750]\n",
      "epoch:25 step:23663 [D loss: 0.588022, acc.: 64.06%] [G loss: 0.695045]\n",
      "epoch:25 step:23664 [D loss: 0.481377, acc.: 73.44%] [G loss: 0.617513]\n",
      "epoch:25 step:23665 [D loss: 0.607591, acc.: 68.75%] [G loss: 0.502807]\n",
      "epoch:25 step:23666 [D loss: 0.455816, acc.: 78.91%] [G loss: 0.669749]\n",
      "epoch:25 step:23667 [D loss: 0.495058, acc.: 75.00%] [G loss: 0.631061]\n",
      "epoch:25 step:23668 [D loss: 0.556280, acc.: 69.53%] [G loss: 0.618808]\n",
      "epoch:25 step:23669 [D loss: 0.467316, acc.: 78.12%] [G loss: 0.851034]\n",
      "epoch:25 step:23670 [D loss: 0.496762, acc.: 75.00%] [G loss: 0.767268]\n",
      "epoch:25 step:23671 [D loss: 0.467351, acc.: 76.56%] [G loss: 0.957125]\n",
      "epoch:25 step:23672 [D loss: 0.488264, acc.: 75.00%] [G loss: 0.876754]\n",
      "epoch:25 step:23673 [D loss: 0.513780, acc.: 78.12%] [G loss: 0.935504]\n",
      "epoch:25 step:23674 [D loss: 0.550699, acc.: 71.09%] [G loss: 0.737729]\n",
      "epoch:25 step:23675 [D loss: 0.639737, acc.: 66.41%] [G loss: 0.921252]\n",
      "epoch:25 step:23676 [D loss: 0.605595, acc.: 60.94%] [G loss: 0.816333]\n",
      "epoch:25 step:23677 [D loss: 0.597410, acc.: 64.84%] [G loss: 0.670123]\n",
      "epoch:25 step:23678 [D loss: 0.571734, acc.: 64.06%] [G loss: 0.671318]\n",
      "epoch:25 step:23679 [D loss: 0.528870, acc.: 69.53%] [G loss: 0.601265]\n",
      "epoch:25 step:23680 [D loss: 0.550209, acc.: 71.09%] [G loss: 0.709011]\n",
      "epoch:25 step:23681 [D loss: 0.595320, acc.: 66.41%] [G loss: 0.691589]\n",
      "epoch:25 step:23682 [D loss: 0.579355, acc.: 60.94%] [G loss: 0.664457]\n",
      "epoch:25 step:23683 [D loss: 0.486648, acc.: 75.00%] [G loss: 0.654525]\n",
      "epoch:25 step:23684 [D loss: 0.523120, acc.: 71.09%] [G loss: 0.557257]\n",
      "epoch:25 step:23685 [D loss: 0.567091, acc.: 64.84%] [G loss: 0.574441]\n",
      "epoch:25 step:23686 [D loss: 0.504274, acc.: 75.00%] [G loss: 0.653654]\n",
      "epoch:25 step:23687 [D loss: 0.509840, acc.: 72.66%] [G loss: 0.754574]\n",
      "epoch:25 step:23688 [D loss: 0.582103, acc.: 70.31%] [G loss: 0.571203]\n",
      "epoch:25 step:23689 [D loss: 0.545950, acc.: 74.22%] [G loss: 0.585398]\n",
      "epoch:25 step:23690 [D loss: 0.577924, acc.: 69.53%] [G loss: 0.762986]\n",
      "epoch:25 step:23691 [D loss: 0.569718, acc.: 66.41%] [G loss: 0.603558]\n",
      "epoch:25 step:23692 [D loss: 0.490466, acc.: 75.00%] [G loss: 0.819399]\n",
      "epoch:25 step:23693 [D loss: 0.527742, acc.: 71.09%] [G loss: 0.654284]\n",
      "epoch:25 step:23694 [D loss: 0.521020, acc.: 72.66%] [G loss: 0.734612]\n",
      "epoch:25 step:23695 [D loss: 0.483654, acc.: 76.56%] [G loss: 0.794383]\n",
      "epoch:25 step:23696 [D loss: 0.557378, acc.: 68.75%] [G loss: 0.797081]\n",
      "epoch:25 step:23697 [D loss: 0.562183, acc.: 68.75%] [G loss: 0.718998]\n",
      "epoch:25 step:23698 [D loss: 0.498034, acc.: 76.56%] [G loss: 0.683602]\n",
      "epoch:25 step:23699 [D loss: 0.459670, acc.: 78.12%] [G loss: 0.747061]\n",
      "epoch:25 step:23700 [D loss: 0.549381, acc.: 65.62%] [G loss: 0.629021]\n",
      "epoch:25 step:23701 [D loss: 0.476492, acc.: 78.91%] [G loss: 0.852179]\n",
      "epoch:25 step:23702 [D loss: 0.657531, acc.: 63.28%] [G loss: 0.572219]\n",
      "epoch:25 step:23703 [D loss: 0.626146, acc.: 67.97%] [G loss: 0.482394]\n",
      "epoch:25 step:23704 [D loss: 0.546001, acc.: 71.09%] [G loss: 0.521653]\n",
      "epoch:25 step:23705 [D loss: 0.487049, acc.: 76.56%] [G loss: 0.647467]\n",
      "epoch:25 step:23706 [D loss: 0.584680, acc.: 65.62%] [G loss: 0.604176]\n",
      "epoch:25 step:23707 [D loss: 0.522487, acc.: 70.31%] [G loss: 0.720459]\n",
      "epoch:25 step:23708 [D loss: 0.505763, acc.: 72.66%] [G loss: 0.596405]\n",
      "epoch:25 step:23709 [D loss: 0.573712, acc.: 68.75%] [G loss: 0.537763]\n",
      "epoch:25 step:23710 [D loss: 0.531036, acc.: 72.66%] [G loss: 0.739095]\n",
      "epoch:25 step:23711 [D loss: 0.547754, acc.: 71.88%] [G loss: 0.806775]\n",
      "epoch:25 step:23712 [D loss: 0.531655, acc.: 72.66%] [G loss: 0.708130]\n",
      "epoch:25 step:23713 [D loss: 0.597923, acc.: 63.28%] [G loss: 0.688932]\n",
      "epoch:25 step:23714 [D loss: 0.532714, acc.: 70.31%] [G loss: 0.557356]\n",
      "epoch:25 step:23715 [D loss: 0.536118, acc.: 74.22%] [G loss: 0.684792]\n",
      "epoch:25 step:23716 [D loss: 0.586177, acc.: 72.66%] [G loss: 0.688239]\n",
      "epoch:25 step:23717 [D loss: 0.463238, acc.: 76.56%] [G loss: 0.684969]\n",
      "epoch:25 step:23718 [D loss: 0.577293, acc.: 66.41%] [G loss: 0.658371]\n",
      "epoch:25 step:23719 [D loss: 0.585429, acc.: 65.62%] [G loss: 0.582421]\n",
      "epoch:25 step:23720 [D loss: 0.590904, acc.: 61.72%] [G loss: 0.489614]\n",
      "epoch:25 step:23721 [D loss: 0.463992, acc.: 78.12%] [G loss: 0.607271]\n",
      "epoch:25 step:23722 [D loss: 0.592684, acc.: 65.62%] [G loss: 0.546785]\n",
      "epoch:25 step:23723 [D loss: 0.437945, acc.: 81.25%] [G loss: 0.699073]\n",
      "epoch:25 step:23724 [D loss: 0.464243, acc.: 75.00%] [G loss: 0.786442]\n",
      "epoch:25 step:23725 [D loss: 0.513054, acc.: 76.56%] [G loss: 0.608848]\n",
      "epoch:25 step:23726 [D loss: 0.635540, acc.: 66.41%] [G loss: 0.507039]\n",
      "epoch:25 step:23727 [D loss: 0.530107, acc.: 67.19%] [G loss: 0.587628]\n",
      "epoch:25 step:23728 [D loss: 0.483078, acc.: 74.22%] [G loss: 0.665853]\n",
      "epoch:25 step:23729 [D loss: 0.518787, acc.: 72.66%] [G loss: 0.670300]\n",
      "epoch:25 step:23730 [D loss: 0.557053, acc.: 68.75%] [G loss: 0.745760]\n",
      "epoch:25 step:23731 [D loss: 0.503009, acc.: 75.78%] [G loss: 0.700760]\n",
      "epoch:25 step:23732 [D loss: 0.473826, acc.: 77.34%] [G loss: 0.807891]\n",
      "epoch:25 step:23733 [D loss: 0.593521, acc.: 63.28%] [G loss: 0.728909]\n",
      "epoch:25 step:23734 [D loss: 0.488551, acc.: 73.44%] [G loss: 0.879117]\n",
      "epoch:25 step:23735 [D loss: 0.499957, acc.: 75.00%] [G loss: 0.792084]\n",
      "epoch:25 step:23736 [D loss: 0.462778, acc.: 78.12%] [G loss: 0.689662]\n",
      "epoch:25 step:23737 [D loss: 0.439738, acc.: 82.03%] [G loss: 0.937477]\n",
      "epoch:25 step:23738 [D loss: 0.536166, acc.: 71.09%] [G loss: 0.880637]\n",
      "epoch:25 step:23739 [D loss: 0.467278, acc.: 80.47%] [G loss: 1.047492]\n",
      "epoch:25 step:23740 [D loss: 0.426660, acc.: 79.69%] [G loss: 0.945720]\n",
      "epoch:25 step:23741 [D loss: 0.659690, acc.: 64.06%] [G loss: 1.033133]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:25 step:23742 [D loss: 0.546366, acc.: 71.09%] [G loss: 0.606260]\n",
      "epoch:25 step:23743 [D loss: 0.544228, acc.: 70.31%] [G loss: 0.684959]\n",
      "epoch:25 step:23744 [D loss: 0.550064, acc.: 71.09%] [G loss: 0.775103]\n",
      "epoch:25 step:23745 [D loss: 0.524986, acc.: 71.88%] [G loss: 0.780682]\n",
      "epoch:25 step:23746 [D loss: 0.472322, acc.: 80.47%] [G loss: 0.636226]\n",
      "epoch:25 step:23747 [D loss: 0.585660, acc.: 65.62%] [G loss: 0.760998]\n",
      "epoch:25 step:23748 [D loss: 0.552653, acc.: 72.66%] [G loss: 0.569762]\n",
      "epoch:25 step:23749 [D loss: 0.545107, acc.: 73.44%] [G loss: 0.647500]\n",
      "epoch:25 step:23750 [D loss: 0.534277, acc.: 71.88%] [G loss: 0.555431]\n",
      "epoch:25 step:23751 [D loss: 0.449839, acc.: 75.78%] [G loss: 0.707155]\n",
      "epoch:25 step:23752 [D loss: 0.521588, acc.: 67.97%] [G loss: 0.642892]\n",
      "epoch:25 step:23753 [D loss: 0.458428, acc.: 75.00%] [G loss: 0.835443]\n",
      "epoch:25 step:23754 [D loss: 0.491655, acc.: 77.34%] [G loss: 0.877187]\n",
      "epoch:25 step:23755 [D loss: 0.610584, acc.: 68.75%] [G loss: 0.765545]\n",
      "epoch:25 step:23756 [D loss: 0.571534, acc.: 71.09%] [G loss: 0.558911]\n",
      "epoch:25 step:23757 [D loss: 0.526920, acc.: 71.09%] [G loss: 0.724350]\n",
      "epoch:25 step:23758 [D loss: 0.508033, acc.: 75.00%] [G loss: 0.758627]\n",
      "epoch:25 step:23759 [D loss: 0.427014, acc.: 84.38%] [G loss: 0.957852]\n",
      "epoch:25 step:23760 [D loss: 0.523953, acc.: 73.44%] [G loss: 0.752601]\n",
      "epoch:25 step:23761 [D loss: 0.496501, acc.: 74.22%] [G loss: 0.744315]\n",
      "epoch:25 step:23762 [D loss: 0.533603, acc.: 67.97%] [G loss: 0.763576]\n",
      "epoch:25 step:23763 [D loss: 0.538695, acc.: 68.75%] [G loss: 0.754445]\n",
      "epoch:25 step:23764 [D loss: 0.537922, acc.: 66.41%] [G loss: 0.806663]\n",
      "epoch:25 step:23765 [D loss: 0.446162, acc.: 81.25%] [G loss: 0.862636]\n",
      "epoch:25 step:23766 [D loss: 0.600424, acc.: 65.62%] [G loss: 0.674113]\n",
      "epoch:25 step:23767 [D loss: 0.584589, acc.: 66.41%] [G loss: 0.735861]\n",
      "epoch:25 step:23768 [D loss: 0.476731, acc.: 77.34%] [G loss: 1.000269]\n",
      "epoch:25 step:23769 [D loss: 0.474363, acc.: 73.44%] [G loss: 0.901381]\n",
      "epoch:25 step:23770 [D loss: 0.536930, acc.: 69.53%] [G loss: 0.740653]\n",
      "epoch:25 step:23771 [D loss: 0.551358, acc.: 68.75%] [G loss: 0.899003]\n",
      "epoch:25 step:23772 [D loss: 0.447142, acc.: 78.91%] [G loss: 1.197814]\n",
      "epoch:25 step:23773 [D loss: 0.590963, acc.: 68.75%] [G loss: 0.733293]\n",
      "epoch:25 step:23774 [D loss: 0.689833, acc.: 57.81%] [G loss: 0.473557]\n",
      "epoch:25 step:23775 [D loss: 0.545186, acc.: 69.53%] [G loss: 0.560641]\n",
      "epoch:25 step:23776 [D loss: 0.535607, acc.: 70.31%] [G loss: 0.665359]\n",
      "epoch:25 step:23777 [D loss: 0.540764, acc.: 68.75%] [G loss: 0.717909]\n",
      "epoch:25 step:23778 [D loss: 0.561863, acc.: 70.31%] [G loss: 0.763557]\n",
      "epoch:25 step:23779 [D loss: 0.388583, acc.: 85.94%] [G loss: 0.981315]\n",
      "epoch:25 step:23780 [D loss: 0.497778, acc.: 74.22%] [G loss: 0.966843]\n",
      "epoch:25 step:23781 [D loss: 0.607487, acc.: 60.16%] [G loss: 0.768139]\n",
      "epoch:25 step:23782 [D loss: 0.398239, acc.: 83.59%] [G loss: 0.827795]\n",
      "epoch:25 step:23783 [D loss: 0.470755, acc.: 76.56%] [G loss: 0.923101]\n",
      "epoch:25 step:23784 [D loss: 0.487622, acc.: 75.00%] [G loss: 0.889375]\n",
      "epoch:25 step:23785 [D loss: 0.463225, acc.: 78.12%] [G loss: 0.911525]\n",
      "epoch:25 step:23786 [D loss: 0.474692, acc.: 75.00%] [G loss: 0.827187]\n",
      "epoch:25 step:23787 [D loss: 0.552465, acc.: 69.53%] [G loss: 0.665385]\n",
      "epoch:25 step:23788 [D loss: 0.522965, acc.: 72.66%] [G loss: 0.794837]\n",
      "epoch:25 step:23789 [D loss: 0.543532, acc.: 67.19%] [G loss: 0.544827]\n",
      "epoch:25 step:23790 [D loss: 0.608394, acc.: 64.06%] [G loss: 0.648620]\n",
      "epoch:25 step:23791 [D loss: 0.535760, acc.: 70.31%] [G loss: 0.673207]\n",
      "epoch:25 step:23792 [D loss: 0.584762, acc.: 63.28%] [G loss: 0.586904]\n",
      "epoch:25 step:23793 [D loss: 0.564070, acc.: 64.06%] [G loss: 0.690814]\n",
      "epoch:25 step:23794 [D loss: 0.520889, acc.: 74.22%] [G loss: 0.783949]\n",
      "epoch:25 step:23795 [D loss: 0.496154, acc.: 72.66%] [G loss: 0.852173]\n",
      "epoch:25 step:23796 [D loss: 0.527764, acc.: 75.00%] [G loss: 0.731663]\n",
      "epoch:25 step:23797 [D loss: 0.584235, acc.: 68.75%] [G loss: 0.714467]\n",
      "epoch:25 step:23798 [D loss: 0.551309, acc.: 68.75%] [G loss: 0.702543]\n",
      "epoch:25 step:23799 [D loss: 0.418065, acc.: 82.03%] [G loss: 0.852907]\n",
      "epoch:25 step:23800 [D loss: 0.579214, acc.: 69.53%] [G loss: 0.680563]\n",
      "##############\n",
      "[3.03965546 0.84449766 6.10914395 4.94783748 3.71764977 5.77242901\n",
      " 4.38835449 5.10797037 4.63760917 4.28498323]\n",
      "##########\n",
      "epoch:25 step:23801 [D loss: 0.698373, acc.: 61.72%] [G loss: 0.554415]\n",
      "epoch:25 step:23802 [D loss: 0.553095, acc.: 61.72%] [G loss: 0.576740]\n",
      "epoch:25 step:23803 [D loss: 0.533472, acc.: 70.31%] [G loss: 0.653772]\n",
      "epoch:25 step:23804 [D loss: 0.505736, acc.: 74.22%] [G loss: 0.856168]\n",
      "epoch:25 step:23805 [D loss: 0.611272, acc.: 64.84%] [G loss: 0.633286]\n",
      "epoch:25 step:23806 [D loss: 0.473431, acc.: 76.56%] [G loss: 0.567963]\n",
      "epoch:25 step:23807 [D loss: 0.515874, acc.: 72.66%] [G loss: 0.629948]\n",
      "epoch:25 step:23808 [D loss: 0.564606, acc.: 65.62%] [G loss: 0.670968]\n",
      "epoch:25 step:23809 [D loss: 0.527680, acc.: 71.88%] [G loss: 0.672315]\n",
      "epoch:25 step:23810 [D loss: 0.486313, acc.: 75.00%] [G loss: 0.721838]\n",
      "epoch:25 step:23811 [D loss: 0.571082, acc.: 65.62%] [G loss: 0.679020]\n",
      "epoch:25 step:23812 [D loss: 0.522511, acc.: 72.66%] [G loss: 0.662399]\n",
      "epoch:25 step:23813 [D loss: 0.534773, acc.: 69.53%] [G loss: 0.683161]\n",
      "epoch:25 step:23814 [D loss: 0.585072, acc.: 64.06%] [G loss: 0.641898]\n",
      "epoch:25 step:23815 [D loss: 0.566877, acc.: 71.09%] [G loss: 0.630067]\n",
      "epoch:25 step:23816 [D loss: 0.555332, acc.: 67.19%] [G loss: 0.683958]\n",
      "epoch:25 step:23817 [D loss: 0.499459, acc.: 72.66%] [G loss: 0.760496]\n",
      "epoch:25 step:23818 [D loss: 0.641185, acc.: 64.84%] [G loss: 0.803025]\n",
      "epoch:25 step:23819 [D loss: 0.530551, acc.: 71.88%] [G loss: 0.467601]\n",
      "epoch:25 step:23820 [D loss: 0.563018, acc.: 71.09%] [G loss: 0.559840]\n",
      "epoch:25 step:23821 [D loss: 0.546646, acc.: 68.75%] [G loss: 0.589567]\n",
      "epoch:25 step:23822 [D loss: 0.538535, acc.: 73.44%] [G loss: 0.668573]\n",
      "epoch:25 step:23823 [D loss: 0.445130, acc.: 78.91%] [G loss: 0.843019]\n",
      "epoch:25 step:23824 [D loss: 0.497380, acc.: 76.56%] [G loss: 0.696672]\n",
      "epoch:25 step:23825 [D loss: 0.638753, acc.: 59.38%] [G loss: 0.660921]\n",
      "epoch:25 step:23826 [D loss: 0.652792, acc.: 55.47%] [G loss: 0.501101]\n",
      "epoch:25 step:23827 [D loss: 0.506682, acc.: 66.41%] [G loss: 0.687016]\n",
      "epoch:25 step:23828 [D loss: 0.525072, acc.: 69.53%] [G loss: 0.714593]\n",
      "epoch:25 step:23829 [D loss: 0.585567, acc.: 66.41%] [G loss: 0.703137]\n",
      "epoch:25 step:23830 [D loss: 0.559413, acc.: 73.44%] [G loss: 0.712857]\n",
      "epoch:25 step:23831 [D loss: 0.466567, acc.: 76.56%] [G loss: 0.989072]\n",
      "epoch:25 step:23832 [D loss: 0.607900, acc.: 63.28%] [G loss: 0.719450]\n",
      "epoch:25 step:23833 [D loss: 0.572194, acc.: 64.84%] [G loss: 0.793240]\n",
      "epoch:25 step:23834 [D loss: 0.570462, acc.: 67.97%] [G loss: 0.731472]\n",
      "epoch:25 step:23835 [D loss: 0.584163, acc.: 62.50%] [G loss: 0.732042]\n",
      "epoch:25 step:23836 [D loss: 0.597748, acc.: 60.94%] [G loss: 0.633533]\n",
      "epoch:25 step:23837 [D loss: 0.595067, acc.: 67.97%] [G loss: 0.518019]\n",
      "epoch:25 step:23838 [D loss: 0.501102, acc.: 74.22%] [G loss: 0.770102]\n",
      "epoch:25 step:23839 [D loss: 0.547145, acc.: 63.28%] [G loss: 0.683636]\n",
      "epoch:25 step:23840 [D loss: 0.523161, acc.: 68.75%] [G loss: 0.802089]\n",
      "epoch:25 step:23841 [D loss: 0.476483, acc.: 80.47%] [G loss: 0.882097]\n",
      "epoch:25 step:23842 [D loss: 0.574061, acc.: 68.75%] [G loss: 0.669692]\n",
      "epoch:25 step:23843 [D loss: 0.635115, acc.: 60.16%] [G loss: 0.600978]\n",
      "epoch:25 step:23844 [D loss: 0.544110, acc.: 74.22%] [G loss: 0.749053]\n",
      "epoch:25 step:23845 [D loss: 0.540107, acc.: 71.88%] [G loss: 0.761686]\n",
      "epoch:25 step:23846 [D loss: 0.592274, acc.: 64.84%] [G loss: 0.636484]\n",
      "epoch:25 step:23847 [D loss: 0.633596, acc.: 58.59%] [G loss: 0.523739]\n",
      "epoch:25 step:23848 [D loss: 0.523638, acc.: 73.44%] [G loss: 0.658692]\n",
      "epoch:25 step:23849 [D loss: 0.532945, acc.: 71.88%] [G loss: 0.613837]\n",
      "epoch:25 step:23850 [D loss: 0.502348, acc.: 75.78%] [G loss: 0.740947]\n",
      "epoch:25 step:23851 [D loss: 0.450294, acc.: 77.34%] [G loss: 0.920034]\n",
      "epoch:25 step:23852 [D loss: 0.417296, acc.: 78.91%] [G loss: 1.040519]\n",
      "epoch:25 step:23853 [D loss: 0.541034, acc.: 70.31%] [G loss: 0.876925]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:25 step:23854 [D loss: 0.460813, acc.: 80.47%] [G loss: 0.860611]\n",
      "epoch:25 step:23855 [D loss: 0.536449, acc.: 72.66%] [G loss: 0.995316]\n",
      "epoch:25 step:23856 [D loss: 0.557786, acc.: 67.19%] [G loss: 0.843174]\n",
      "epoch:25 step:23857 [D loss: 0.565753, acc.: 69.53%] [G loss: 0.617566]\n",
      "epoch:25 step:23858 [D loss: 0.535563, acc.: 70.31%] [G loss: 0.692145]\n",
      "epoch:25 step:23859 [D loss: 0.505032, acc.: 73.44%] [G loss: 0.612590]\n",
      "epoch:25 step:23860 [D loss: 0.570141, acc.: 68.75%] [G loss: 0.675508]\n",
      "epoch:25 step:23861 [D loss: 0.444110, acc.: 76.56%] [G loss: 0.736331]\n",
      "epoch:25 step:23862 [D loss: 0.650083, acc.: 67.97%] [G loss: 0.659126]\n",
      "epoch:25 step:23863 [D loss: 0.548421, acc.: 69.53%] [G loss: 0.559571]\n",
      "epoch:25 step:23864 [D loss: 0.475570, acc.: 78.12%] [G loss: 0.693492]\n",
      "epoch:25 step:23865 [D loss: 0.459697, acc.: 77.34%] [G loss: 0.858389]\n",
      "epoch:25 step:23866 [D loss: 0.551274, acc.: 66.41%] [G loss: 0.818722]\n",
      "epoch:25 step:23867 [D loss: 0.578648, acc.: 66.41%] [G loss: 0.932035]\n",
      "epoch:25 step:23868 [D loss: 0.524387, acc.: 70.31%] [G loss: 0.807005]\n",
      "epoch:25 step:23869 [D loss: 0.505551, acc.: 74.22%] [G loss: 0.944460]\n",
      "epoch:25 step:23870 [D loss: 0.521132, acc.: 70.31%] [G loss: 0.970772]\n",
      "epoch:25 step:23871 [D loss: 0.524415, acc.: 71.88%] [G loss: 0.773088]\n",
      "epoch:25 step:23872 [D loss: 0.543188, acc.: 68.75%] [G loss: 0.786483]\n",
      "epoch:25 step:23873 [D loss: 0.576378, acc.: 70.31%] [G loss: 0.720309]\n",
      "epoch:25 step:23874 [D loss: 0.497916, acc.: 77.34%] [G loss: 0.994742]\n",
      "epoch:25 step:23875 [D loss: 0.536763, acc.: 72.66%] [G loss: 0.599363]\n",
      "epoch:25 step:23876 [D loss: 0.425597, acc.: 80.47%] [G loss: 0.832383]\n",
      "epoch:25 step:23877 [D loss: 0.451582, acc.: 78.91%] [G loss: 0.782175]\n",
      "epoch:25 step:23878 [D loss: 0.522001, acc.: 75.00%] [G loss: 0.900512]\n",
      "epoch:25 step:23879 [D loss: 0.509933, acc.: 75.78%] [G loss: 0.869148]\n",
      "epoch:25 step:23880 [D loss: 0.540132, acc.: 73.44%] [G loss: 0.826460]\n",
      "epoch:25 step:23881 [D loss: 0.617757, acc.: 62.50%] [G loss: 0.634202]\n",
      "epoch:25 step:23882 [D loss: 0.475028, acc.: 75.78%] [G loss: 0.882824]\n",
      "epoch:25 step:23883 [D loss: 0.605093, acc.: 67.97%] [G loss: 0.707134]\n",
      "epoch:25 step:23884 [D loss: 0.542310, acc.: 70.31%] [G loss: 0.782112]\n",
      "epoch:25 step:23885 [D loss: 0.499766, acc.: 79.69%] [G loss: 0.694550]\n",
      "epoch:25 step:23886 [D loss: 0.532064, acc.: 71.88%] [G loss: 0.864101]\n",
      "epoch:25 step:23887 [D loss: 0.543136, acc.: 69.53%] [G loss: 0.777188]\n",
      "epoch:25 step:23888 [D loss: 0.534568, acc.: 71.88%] [G loss: 0.716536]\n",
      "epoch:25 step:23889 [D loss: 0.489179, acc.: 75.00%] [G loss: 0.776423]\n",
      "epoch:25 step:23890 [D loss: 0.601039, acc.: 67.19%] [G loss: 0.632084]\n",
      "epoch:25 step:23891 [D loss: 0.556055, acc.: 67.97%] [G loss: 0.694255]\n",
      "epoch:25 step:23892 [D loss: 0.579918, acc.: 62.50%] [G loss: 0.708663]\n",
      "epoch:25 step:23893 [D loss: 0.547510, acc.: 70.31%] [G loss: 0.703046]\n",
      "epoch:25 step:23894 [D loss: 0.573314, acc.: 67.97%] [G loss: 0.629551]\n",
      "epoch:25 step:23895 [D loss: 0.547564, acc.: 71.88%] [G loss: 0.651573]\n",
      "epoch:25 step:23896 [D loss: 0.442962, acc.: 79.69%] [G loss: 0.762393]\n",
      "epoch:25 step:23897 [D loss: 0.436970, acc.: 79.69%] [G loss: 1.076098]\n",
      "epoch:25 step:23898 [D loss: 0.640969, acc.: 61.72%] [G loss: 0.812729]\n",
      "epoch:25 step:23899 [D loss: 0.550630, acc.: 68.75%] [G loss: 0.595451]\n",
      "epoch:25 step:23900 [D loss: 0.466273, acc.: 73.44%] [G loss: 0.828551]\n",
      "epoch:25 step:23901 [D loss: 0.520446, acc.: 74.22%] [G loss: 0.837887]\n",
      "epoch:25 step:23902 [D loss: 0.648536, acc.: 63.28%] [G loss: 0.626613]\n",
      "epoch:25 step:23903 [D loss: 0.579922, acc.: 72.66%] [G loss: 0.583453]\n",
      "epoch:25 step:23904 [D loss: 0.495521, acc.: 75.78%] [G loss: 0.563944]\n",
      "epoch:25 step:23905 [D loss: 0.615778, acc.: 63.28%] [G loss: 0.595686]\n",
      "epoch:25 step:23906 [D loss: 0.520789, acc.: 76.56%] [G loss: 0.610865]\n",
      "epoch:25 step:23907 [D loss: 0.615058, acc.: 65.62%] [G loss: 0.536558]\n",
      "epoch:25 step:23908 [D loss: 0.513668, acc.: 73.44%] [G loss: 0.700490]\n",
      "epoch:25 step:23909 [D loss: 0.513897, acc.: 73.44%] [G loss: 0.626323]\n",
      "epoch:25 step:23910 [D loss: 0.500556, acc.: 75.00%] [G loss: 0.804653]\n",
      "epoch:25 step:23911 [D loss: 0.558717, acc.: 67.97%] [G loss: 0.633211]\n",
      "epoch:25 step:23912 [D loss: 0.619355, acc.: 64.84%] [G loss: 0.751038]\n",
      "epoch:25 step:23913 [D loss: 0.459071, acc.: 80.47%] [G loss: 0.685769]\n",
      "epoch:25 step:23914 [D loss: 0.533035, acc.: 73.44%] [G loss: 0.562362]\n",
      "epoch:25 step:23915 [D loss: 0.568012, acc.: 71.09%] [G loss: 0.654720]\n",
      "epoch:25 step:23916 [D loss: 0.532959, acc.: 70.31%] [G loss: 0.610203]\n",
      "epoch:25 step:23917 [D loss: 0.609559, acc.: 64.84%] [G loss: 0.528346]\n",
      "epoch:25 step:23918 [D loss: 0.616383, acc.: 68.75%] [G loss: 0.565078]\n",
      "epoch:25 step:23919 [D loss: 0.582635, acc.: 73.44%] [G loss: 0.530538]\n",
      "epoch:25 step:23920 [D loss: 0.472667, acc.: 77.34%] [G loss: 0.686958]\n",
      "epoch:25 step:23921 [D loss: 0.517113, acc.: 75.78%] [G loss: 0.573249]\n",
      "epoch:25 step:23922 [D loss: 0.571968, acc.: 71.88%] [G loss: 0.677226]\n",
      "epoch:25 step:23923 [D loss: 0.515928, acc.: 73.44%] [G loss: 0.772769]\n",
      "epoch:25 step:23924 [D loss: 0.454191, acc.: 77.34%] [G loss: 0.834598]\n",
      "epoch:25 step:23925 [D loss: 0.582668, acc.: 67.19%] [G loss: 0.713753]\n",
      "epoch:25 step:23926 [D loss: 0.611834, acc.: 64.06%] [G loss: 0.590472]\n",
      "epoch:25 step:23927 [D loss: 0.573095, acc.: 63.28%] [G loss: 0.580021]\n",
      "epoch:25 step:23928 [D loss: 0.510284, acc.: 76.56%] [G loss: 0.654266]\n",
      "epoch:25 step:23929 [D loss: 0.486545, acc.: 78.12%] [G loss: 0.927134]\n",
      "epoch:25 step:23930 [D loss: 0.514455, acc.: 73.44%] [G loss: 0.743707]\n",
      "epoch:25 step:23931 [D loss: 0.478512, acc.: 76.56%] [G loss: 0.663135]\n",
      "epoch:25 step:23932 [D loss: 0.481290, acc.: 77.34%] [G loss: 0.846907]\n",
      "epoch:25 step:23933 [D loss: 0.397056, acc.: 85.16%] [G loss: 0.948205]\n",
      "epoch:25 step:23934 [D loss: 0.558614, acc.: 72.66%] [G loss: 0.992833]\n",
      "epoch:25 step:23935 [D loss: 0.536889, acc.: 74.22%] [G loss: 0.864549]\n",
      "epoch:25 step:23936 [D loss: 0.597708, acc.: 65.62%] [G loss: 0.613816]\n",
      "epoch:25 step:23937 [D loss: 0.603025, acc.: 63.28%] [G loss: 0.594544]\n",
      "epoch:25 step:23938 [D loss: 0.500424, acc.: 79.69%] [G loss: 0.789189]\n",
      "epoch:25 step:23939 [D loss: 0.511096, acc.: 69.53%] [G loss: 0.767062]\n",
      "epoch:25 step:23940 [D loss: 0.476756, acc.: 75.78%] [G loss: 0.873309]\n",
      "epoch:25 step:23941 [D loss: 0.441934, acc.: 78.12%] [G loss: 0.766039]\n",
      "epoch:25 step:23942 [D loss: 0.496855, acc.: 75.78%] [G loss: 0.707896]\n",
      "epoch:25 step:23943 [D loss: 0.553615, acc.: 69.53%] [G loss: 0.696989]\n",
      "epoch:25 step:23944 [D loss: 0.489387, acc.: 71.88%] [G loss: 0.793212]\n",
      "epoch:25 step:23945 [D loss: 0.480540, acc.: 77.34%] [G loss: 0.823007]\n",
      "epoch:25 step:23946 [D loss: 0.512623, acc.: 71.88%] [G loss: 0.970142]\n",
      "epoch:25 step:23947 [D loss: 0.446757, acc.: 80.47%] [G loss: 0.876618]\n",
      "epoch:25 step:23948 [D loss: 0.496557, acc.: 75.00%] [G loss: 0.816131]\n",
      "epoch:25 step:23949 [D loss: 0.558676, acc.: 66.41%] [G loss: 0.666060]\n",
      "epoch:25 step:23950 [D loss: 0.555110, acc.: 72.66%] [G loss: 0.586994]\n",
      "epoch:25 step:23951 [D loss: 0.456980, acc.: 76.56%] [G loss: 0.723016]\n",
      "epoch:25 step:23952 [D loss: 0.507443, acc.: 77.34%] [G loss: 0.658268]\n",
      "epoch:25 step:23953 [D loss: 0.629164, acc.: 65.62%] [G loss: 0.708844]\n",
      "epoch:25 step:23954 [D loss: 0.595161, acc.: 60.94%] [G loss: 0.607137]\n",
      "epoch:25 step:23955 [D loss: 0.566139, acc.: 65.62%] [G loss: 0.753168]\n",
      "epoch:25 step:23956 [D loss: 0.536646, acc.: 70.31%] [G loss: 0.779572]\n",
      "epoch:25 step:23957 [D loss: 0.494560, acc.: 77.34%] [G loss: 0.732430]\n",
      "epoch:25 step:23958 [D loss: 0.577916, acc.: 68.75%] [G loss: 0.780931]\n",
      "epoch:25 step:23959 [D loss: 0.484223, acc.: 76.56%] [G loss: 0.919152]\n",
      "epoch:25 step:23960 [D loss: 0.674365, acc.: 62.50%] [G loss: 0.485953]\n",
      "epoch:25 step:23961 [D loss: 0.460223, acc.: 75.78%] [G loss: 0.623280]\n",
      "epoch:25 step:23962 [D loss: 0.538773, acc.: 70.31%] [G loss: 0.668463]\n",
      "epoch:25 step:23963 [D loss: 0.547758, acc.: 71.88%] [G loss: 0.628906]\n",
      "epoch:25 step:23964 [D loss: 0.544247, acc.: 68.75%] [G loss: 0.692194]\n",
      "epoch:25 step:23965 [D loss: 0.506430, acc.: 74.22%] [G loss: 0.823205]\n",
      "epoch:25 step:23966 [D loss: 0.542925, acc.: 66.41%] [G loss: 0.707045]\n",
      "epoch:25 step:23967 [D loss: 0.615659, acc.: 64.06%] [G loss: 0.625122]\n",
      "epoch:25 step:23968 [D loss: 0.585088, acc.: 71.88%] [G loss: 0.630726]\n",
      "epoch:25 step:23969 [D loss: 0.529513, acc.: 71.09%] [G loss: 0.673493]\n",
      "epoch:25 step:23970 [D loss: 0.522768, acc.: 71.09%] [G loss: 0.585904]\n",
      "epoch:25 step:23971 [D loss: 0.534609, acc.: 78.12%] [G loss: 0.914789]\n",
      "epoch:25 step:23972 [D loss: 0.597566, acc.: 70.31%] [G loss: 0.669624]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:25 step:23973 [D loss: 0.458154, acc.: 78.12%] [G loss: 0.888838]\n",
      "epoch:25 step:23974 [D loss: 0.533061, acc.: 78.12%] [G loss: 0.804039]\n",
      "epoch:25 step:23975 [D loss: 0.553392, acc.: 72.66%] [G loss: 0.720417]\n",
      "epoch:25 step:23976 [D loss: 0.524843, acc.: 68.75%] [G loss: 0.896620]\n",
      "epoch:25 step:23977 [D loss: 0.487077, acc.: 76.56%] [G loss: 0.775262]\n",
      "epoch:25 step:23978 [D loss: 0.595611, acc.: 70.31%] [G loss: 0.761565]\n",
      "epoch:25 step:23979 [D loss: 0.432076, acc.: 84.38%] [G loss: 0.862186]\n",
      "epoch:25 step:23980 [D loss: 0.480045, acc.: 77.34%] [G loss: 0.881166]\n",
      "epoch:25 step:23981 [D loss: 0.536831, acc.: 71.09%] [G loss: 0.837840]\n",
      "epoch:25 step:23982 [D loss: 0.554958, acc.: 70.31%] [G loss: 0.861556]\n",
      "epoch:25 step:23983 [D loss: 0.493039, acc.: 75.78%] [G loss: 0.904553]\n",
      "epoch:25 step:23984 [D loss: 0.584376, acc.: 68.75%] [G loss: 0.849760]\n",
      "epoch:25 step:23985 [D loss: 0.590180, acc.: 71.09%] [G loss: 0.601798]\n",
      "epoch:25 step:23986 [D loss: 0.552785, acc.: 68.75%] [G loss: 0.679156]\n",
      "epoch:25 step:23987 [D loss: 0.570547, acc.: 71.88%] [G loss: 0.630301]\n",
      "epoch:25 step:23988 [D loss: 0.544501, acc.: 71.88%] [G loss: 0.573173]\n",
      "epoch:25 step:23989 [D loss: 0.506528, acc.: 71.88%] [G loss: 0.697533]\n",
      "epoch:25 step:23990 [D loss: 0.544481, acc.: 71.09%] [G loss: 0.821759]\n",
      "epoch:25 step:23991 [D loss: 0.676943, acc.: 60.94%] [G loss: 0.567089]\n",
      "epoch:25 step:23992 [D loss: 0.505740, acc.: 71.88%] [G loss: 0.717151]\n",
      "epoch:25 step:23993 [D loss: 0.463719, acc.: 75.78%] [G loss: 0.714767]\n",
      "epoch:25 step:23994 [D loss: 0.505048, acc.: 75.78%] [G loss: 0.689308]\n",
      "epoch:25 step:23995 [D loss: 0.539106, acc.: 73.44%] [G loss: 0.851375]\n",
      "epoch:25 step:23996 [D loss: 0.553616, acc.: 71.09%] [G loss: 0.871012]\n",
      "epoch:25 step:23997 [D loss: 0.535266, acc.: 71.88%] [G loss: 0.717452]\n",
      "epoch:25 step:23998 [D loss: 0.556673, acc.: 71.88%] [G loss: 0.704386]\n",
      "epoch:25 step:23999 [D loss: 0.456133, acc.: 80.47%] [G loss: 1.057559]\n",
      "epoch:25 step:24000 [D loss: 0.481334, acc.: 75.78%] [G loss: 0.804132]\n",
      "##############\n",
      "[3.10774592 1.005141   6.28002261 4.74728152 3.82809097 5.69378923\n",
      " 4.75561128 4.74455412 4.73518791 4.26335203]\n",
      "##########\n",
      "epoch:25 step:24001 [D loss: 0.616609, acc.: 61.72%] [G loss: 0.602572]\n",
      "epoch:25 step:24002 [D loss: 0.588868, acc.: 66.41%] [G loss: 0.592121]\n",
      "epoch:25 step:24003 [D loss: 0.570057, acc.: 66.41%] [G loss: 0.651260]\n",
      "epoch:25 step:24004 [D loss: 0.496361, acc.: 75.00%] [G loss: 0.699280]\n",
      "epoch:25 step:24005 [D loss: 0.563791, acc.: 73.44%] [G loss: 0.609763]\n",
      "epoch:25 step:24006 [D loss: 0.535081, acc.: 72.66%] [G loss: 0.706403]\n",
      "epoch:25 step:24007 [D loss: 0.417266, acc.: 83.59%] [G loss: 0.866841]\n",
      "epoch:25 step:24008 [D loss: 0.561988, acc.: 72.66%] [G loss: 0.661609]\n",
      "epoch:25 step:24009 [D loss: 0.607038, acc.: 64.84%] [G loss: 0.815412]\n",
      "epoch:25 step:24010 [D loss: 0.567183, acc.: 68.75%] [G loss: 0.678228]\n",
      "epoch:25 step:24011 [D loss: 0.561950, acc.: 68.75%] [G loss: 0.528872]\n",
      "epoch:25 step:24012 [D loss: 0.585758, acc.: 63.28%] [G loss: 0.637330]\n",
      "epoch:25 step:24013 [D loss: 0.569195, acc.: 67.19%] [G loss: 0.593187]\n",
      "epoch:25 step:24014 [D loss: 0.492391, acc.: 71.88%] [G loss: 0.723655]\n",
      "epoch:25 step:24015 [D loss: 0.562445, acc.: 70.31%] [G loss: 0.650441]\n",
      "epoch:25 step:24016 [D loss: 0.594645, acc.: 71.09%] [G loss: 0.508886]\n",
      "epoch:25 step:24017 [D loss: 0.500150, acc.: 77.34%] [G loss: 0.562147]\n",
      "epoch:25 step:24018 [D loss: 0.476313, acc.: 75.00%] [G loss: 0.729982]\n",
      "epoch:25 step:24019 [D loss: 0.576893, acc.: 66.41%] [G loss: 0.715822]\n",
      "epoch:25 step:24020 [D loss: 0.539833, acc.: 73.44%] [G loss: 0.637986]\n",
      "epoch:25 step:24021 [D loss: 0.599278, acc.: 65.62%] [G loss: 0.691275]\n",
      "epoch:25 step:24022 [D loss: 0.504396, acc.: 75.00%] [G loss: 0.667185]\n",
      "epoch:25 step:24023 [D loss: 0.480424, acc.: 78.91%] [G loss: 0.754804]\n",
      "epoch:25 step:24024 [D loss: 0.465163, acc.: 78.12%] [G loss: 0.776484]\n",
      "epoch:25 step:24025 [D loss: 0.568820, acc.: 65.62%] [G loss: 0.633202]\n",
      "epoch:25 step:24026 [D loss: 0.486184, acc.: 71.88%] [G loss: 0.663027]\n",
      "epoch:25 step:24027 [D loss: 0.483254, acc.: 78.12%] [G loss: 0.934892]\n",
      "epoch:25 step:24028 [D loss: 0.485905, acc.: 78.12%] [G loss: 0.986602]\n",
      "epoch:25 step:24029 [D loss: 0.582656, acc.: 65.62%] [G loss: 1.002578]\n",
      "epoch:25 step:24030 [D loss: 0.454152, acc.: 78.12%] [G loss: 0.874631]\n",
      "epoch:25 step:24031 [D loss: 0.589460, acc.: 69.53%] [G loss: 0.647018]\n",
      "epoch:25 step:24032 [D loss: 0.571432, acc.: 71.88%] [G loss: 0.684952]\n",
      "epoch:25 step:24033 [D loss: 0.554758, acc.: 68.75%] [G loss: 0.577033]\n",
      "epoch:25 step:24034 [D loss: 0.523886, acc.: 75.78%] [G loss: 0.464489]\n",
      "epoch:25 step:24035 [D loss: 0.593601, acc.: 64.06%] [G loss: 0.554233]\n",
      "epoch:25 step:24036 [D loss: 0.504156, acc.: 72.66%] [G loss: 0.509868]\n",
      "epoch:25 step:24037 [D loss: 0.544799, acc.: 73.44%] [G loss: 0.732068]\n",
      "epoch:25 step:24038 [D loss: 0.465872, acc.: 77.34%] [G loss: 0.679634]\n",
      "epoch:25 step:24039 [D loss: 0.595898, acc.: 63.28%] [G loss: 0.617135]\n",
      "epoch:25 step:24040 [D loss: 0.554013, acc.: 69.53%] [G loss: 0.735222]\n",
      "epoch:25 step:24041 [D loss: 0.540133, acc.: 70.31%] [G loss: 0.722454]\n",
      "epoch:25 step:24042 [D loss: 0.526760, acc.: 73.44%] [G loss: 0.793236]\n",
      "epoch:25 step:24043 [D loss: 0.580920, acc.: 67.97%] [G loss: 0.747494]\n",
      "epoch:25 step:24044 [D loss: 0.518616, acc.: 71.88%] [G loss: 0.621220]\n",
      "epoch:25 step:24045 [D loss: 0.495421, acc.: 73.44%] [G loss: 0.695046]\n",
      "epoch:25 step:24046 [D loss: 0.527245, acc.: 75.00%] [G loss: 0.760700]\n",
      "epoch:25 step:24047 [D loss: 0.557936, acc.: 68.75%] [G loss: 0.637577]\n",
      "epoch:25 step:24048 [D loss: 0.467871, acc.: 77.34%] [G loss: 0.718902]\n",
      "epoch:25 step:24049 [D loss: 0.472802, acc.: 74.22%] [G loss: 0.845865]\n",
      "epoch:25 step:24050 [D loss: 0.607406, acc.: 63.28%] [G loss: 0.612971]\n",
      "epoch:25 step:24051 [D loss: 0.561824, acc.: 68.75%] [G loss: 0.702659]\n",
      "epoch:25 step:24052 [D loss: 0.601281, acc.: 66.41%] [G loss: 0.728474]\n",
      "epoch:25 step:24053 [D loss: 0.609473, acc.: 61.72%] [G loss: 0.559892]\n",
      "epoch:25 step:24054 [D loss: 0.487787, acc.: 74.22%] [G loss: 0.576290]\n",
      "epoch:25 step:24055 [D loss: 0.570327, acc.: 66.41%] [G loss: 0.796349]\n",
      "epoch:25 step:24056 [D loss: 0.460792, acc.: 76.56%] [G loss: 0.926249]\n",
      "epoch:25 step:24057 [D loss: 0.496412, acc.: 76.56%] [G loss: 0.678201]\n",
      "epoch:25 step:24058 [D loss: 0.549885, acc.: 67.97%] [G loss: 0.612837]\n",
      "epoch:25 step:24059 [D loss: 0.478284, acc.: 78.91%] [G loss: 0.765168]\n",
      "epoch:25 step:24060 [D loss: 0.532922, acc.: 69.53%] [G loss: 0.737506]\n",
      "epoch:25 step:24061 [D loss: 0.577021, acc.: 70.31%] [G loss: 0.592331]\n",
      "epoch:25 step:24062 [D loss: 0.557909, acc.: 69.53%] [G loss: 0.626239]\n",
      "epoch:25 step:24063 [D loss: 0.496753, acc.: 71.88%] [G loss: 0.617246]\n",
      "epoch:25 step:24064 [D loss: 0.484058, acc.: 75.00%] [G loss: 0.721415]\n",
      "epoch:25 step:24065 [D loss: 0.553636, acc.: 70.31%] [G loss: 0.876920]\n",
      "epoch:25 step:24066 [D loss: 0.495729, acc.: 76.56%] [G loss: 1.015292]\n",
      "epoch:25 step:24067 [D loss: 0.471605, acc.: 78.12%] [G loss: 0.980632]\n",
      "epoch:25 step:24068 [D loss: 0.495497, acc.: 71.88%] [G loss: 0.877736]\n",
      "epoch:25 step:24069 [D loss: 0.613128, acc.: 58.59%] [G loss: 0.745164]\n",
      "epoch:25 step:24070 [D loss: 0.538040, acc.: 71.09%] [G loss: 0.733524]\n",
      "epoch:25 step:24071 [D loss: 0.541398, acc.: 71.09%] [G loss: 0.635876]\n",
      "epoch:25 step:24072 [D loss: 0.391991, acc.: 85.16%] [G loss: 0.772791]\n",
      "epoch:25 step:24073 [D loss: 0.383176, acc.: 82.03%] [G loss: 0.947757]\n",
      "epoch:25 step:24074 [D loss: 0.568191, acc.: 72.66%] [G loss: 0.861482]\n",
      "epoch:25 step:24075 [D loss: 0.524212, acc.: 70.31%] [G loss: 0.869078]\n",
      "epoch:25 step:24076 [D loss: 0.517658, acc.: 74.22%] [G loss: 0.754628]\n",
      "epoch:25 step:24077 [D loss: 0.592478, acc.: 69.53%] [G loss: 0.638517]\n",
      "epoch:25 step:24078 [D loss: 0.576383, acc.: 65.62%] [G loss: 0.616247]\n",
      "epoch:25 step:24079 [D loss: 0.473255, acc.: 75.00%] [G loss: 0.837505]\n",
      "epoch:25 step:24080 [D loss: 0.535578, acc.: 70.31%] [G loss: 0.638001]\n",
      "epoch:25 step:24081 [D loss: 0.519861, acc.: 73.44%] [G loss: 0.959061]\n",
      "epoch:25 step:24082 [D loss: 0.502231, acc.: 74.22%] [G loss: 0.806305]\n",
      "epoch:25 step:24083 [D loss: 0.553824, acc.: 71.88%] [G loss: 0.783035]\n",
      "epoch:25 step:24084 [D loss: 0.531060, acc.: 70.31%] [G loss: 0.806884]\n",
      "epoch:25 step:24085 [D loss: 0.502486, acc.: 76.56%] [G loss: 0.708960]\n",
      "epoch:25 step:24086 [D loss: 0.459659, acc.: 75.00%] [G loss: 0.817860]\n",
      "epoch:25 step:24087 [D loss: 0.527797, acc.: 71.88%] [G loss: 0.774254]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:25 step:24088 [D loss: 0.521555, acc.: 71.88%] [G loss: 0.726975]\n",
      "epoch:25 step:24089 [D loss: 0.504777, acc.: 71.88%] [G loss: 0.868422]\n",
      "epoch:25 step:24090 [D loss: 0.608220, acc.: 67.97%] [G loss: 0.719023]\n",
      "epoch:25 step:24091 [D loss: 0.508321, acc.: 71.09%] [G loss: 0.759495]\n",
      "epoch:25 step:24092 [D loss: 0.512300, acc.: 71.88%] [G loss: 0.702162]\n",
      "epoch:25 step:24093 [D loss: 0.521969, acc.: 75.78%] [G loss: 0.566967]\n",
      "epoch:25 step:24094 [D loss: 0.511161, acc.: 73.44%] [G loss: 0.576703]\n",
      "epoch:25 step:24095 [D loss: 0.468266, acc.: 75.00%] [G loss: 0.726524]\n",
      "epoch:25 step:24096 [D loss: 0.549527, acc.: 70.31%] [G loss: 0.672188]\n",
      "epoch:25 step:24097 [D loss: 0.512290, acc.: 74.22%] [G loss: 0.893760]\n",
      "epoch:25 step:24098 [D loss: 0.596366, acc.: 60.16%] [G loss: 0.682896]\n",
      "epoch:25 step:24099 [D loss: 0.562934, acc.: 72.66%] [G loss: 0.656972]\n",
      "epoch:25 step:24100 [D loss: 0.556859, acc.: 73.44%] [G loss: 0.617564]\n",
      "epoch:25 step:24101 [D loss: 0.527336, acc.: 72.66%] [G loss: 0.595191]\n",
      "epoch:25 step:24102 [D loss: 0.479167, acc.: 74.22%] [G loss: 0.725136]\n",
      "epoch:25 step:24103 [D loss: 0.594418, acc.: 69.53%] [G loss: 0.612379]\n",
      "epoch:25 step:24104 [D loss: 0.532472, acc.: 73.44%] [G loss: 0.672666]\n",
      "epoch:25 step:24105 [D loss: 0.505841, acc.: 73.44%] [G loss: 0.665226]\n",
      "epoch:25 step:24106 [D loss: 0.465195, acc.: 76.56%] [G loss: 0.715526]\n",
      "epoch:25 step:24107 [D loss: 0.601712, acc.: 60.94%] [G loss: 0.768127]\n",
      "epoch:25 step:24108 [D loss: 0.526339, acc.: 73.44%] [G loss: 0.863216]\n",
      "epoch:25 step:24109 [D loss: 0.576246, acc.: 71.09%] [G loss: 0.623926]\n",
      "epoch:25 step:24110 [D loss: 0.499307, acc.: 77.34%] [G loss: 0.540484]\n",
      "epoch:25 step:24111 [D loss: 0.552514, acc.: 69.53%] [G loss: 0.641431]\n",
      "epoch:25 step:24112 [D loss: 0.575678, acc.: 69.53%] [G loss: 0.614233]\n",
      "epoch:25 step:24113 [D loss: 0.545809, acc.: 71.88%] [G loss: 0.636286]\n",
      "epoch:25 step:24114 [D loss: 0.598217, acc.: 65.62%] [G loss: 0.568891]\n",
      "epoch:25 step:24115 [D loss: 0.484370, acc.: 76.56%] [G loss: 0.679095]\n",
      "epoch:25 step:24116 [D loss: 0.531970, acc.: 74.22%] [G loss: 0.753088]\n",
      "epoch:25 step:24117 [D loss: 0.525608, acc.: 71.09%] [G loss: 0.715091]\n",
      "epoch:25 step:24118 [D loss: 0.461253, acc.: 77.34%] [G loss: 0.773390]\n",
      "epoch:25 step:24119 [D loss: 0.440768, acc.: 81.25%] [G loss: 0.821198]\n",
      "epoch:25 step:24120 [D loss: 0.531579, acc.: 71.88%] [G loss: 0.734190]\n",
      "epoch:25 step:24121 [D loss: 0.649599, acc.: 62.50%] [G loss: 0.710189]\n",
      "epoch:25 step:24122 [D loss: 0.564400, acc.: 65.62%] [G loss: 0.711012]\n",
      "epoch:25 step:24123 [D loss: 0.568588, acc.: 65.62%] [G loss: 0.542268]\n",
      "epoch:25 step:24124 [D loss: 0.504605, acc.: 67.19%] [G loss: 0.707944]\n",
      "epoch:25 step:24125 [D loss: 0.524208, acc.: 73.44%] [G loss: 0.719475]\n",
      "epoch:25 step:24126 [D loss: 0.493569, acc.: 75.78%] [G loss: 0.830892]\n",
      "epoch:25 step:24127 [D loss: 0.525577, acc.: 74.22%] [G loss: 0.613239]\n",
      "epoch:25 step:24128 [D loss: 0.596135, acc.: 65.62%] [G loss: 0.670390]\n",
      "epoch:25 step:24129 [D loss: 0.600721, acc.: 64.84%] [G loss: 0.634788]\n",
      "epoch:25 step:24130 [D loss: 0.517711, acc.: 75.00%] [G loss: 0.546410]\n",
      "epoch:25 step:24131 [D loss: 0.529722, acc.: 75.00%] [G loss: 0.562054]\n",
      "epoch:25 step:24132 [D loss: 0.496311, acc.: 71.88%] [G loss: 0.897742]\n",
      "epoch:25 step:24133 [D loss: 0.461047, acc.: 76.56%] [G loss: 0.704211]\n",
      "epoch:25 step:24134 [D loss: 0.532015, acc.: 74.22%] [G loss: 0.663005]\n",
      "epoch:25 step:24135 [D loss: 0.571897, acc.: 63.28%] [G loss: 0.621438]\n",
      "epoch:25 step:24136 [D loss: 0.521529, acc.: 67.97%] [G loss: 0.685507]\n",
      "epoch:25 step:24137 [D loss: 0.501200, acc.: 72.66%] [G loss: 0.786979]\n",
      "epoch:25 step:24138 [D loss: 0.568144, acc.: 68.75%] [G loss: 0.784740]\n",
      "epoch:25 step:24139 [D loss: 0.542033, acc.: 70.31%] [G loss: 0.703763]\n",
      "epoch:25 step:24140 [D loss: 0.502028, acc.: 75.78%] [G loss: 0.624646]\n",
      "epoch:25 step:24141 [D loss: 0.533964, acc.: 71.09%] [G loss: 0.670065]\n",
      "epoch:25 step:24142 [D loss: 0.541317, acc.: 68.75%] [G loss: 0.635482]\n",
      "epoch:25 step:24143 [D loss: 0.531010, acc.: 71.88%] [G loss: 0.673075]\n",
      "epoch:25 step:24144 [D loss: 0.435660, acc.: 78.12%] [G loss: 0.708132]\n",
      "epoch:25 step:24145 [D loss: 0.581263, acc.: 72.66%] [G loss: 0.755482]\n",
      "epoch:25 step:24146 [D loss: 0.554288, acc.: 71.88%] [G loss: 0.658498]\n",
      "epoch:25 step:24147 [D loss: 0.559416, acc.: 69.53%] [G loss: 0.687226]\n",
      "epoch:25 step:24148 [D loss: 0.559994, acc.: 72.66%] [G loss: 0.700529]\n",
      "epoch:25 step:24149 [D loss: 0.466589, acc.: 77.34%] [G loss: 0.785480]\n",
      "epoch:25 step:24150 [D loss: 0.475163, acc.: 74.22%] [G loss: 0.945629]\n",
      "epoch:25 step:24151 [D loss: 0.535947, acc.: 72.66%] [G loss: 0.856463]\n",
      "epoch:25 step:24152 [D loss: 0.541687, acc.: 71.88%] [G loss: 0.872673]\n",
      "epoch:25 step:24153 [D loss: 0.482395, acc.: 78.12%] [G loss: 0.934462]\n",
      "epoch:25 step:24154 [D loss: 0.517564, acc.: 72.66%] [G loss: 0.774400]\n",
      "epoch:25 step:24155 [D loss: 0.537236, acc.: 71.09%] [G loss: 0.673417]\n",
      "epoch:25 step:24156 [D loss: 0.655380, acc.: 57.81%] [G loss: 0.792802]\n",
      "epoch:25 step:24157 [D loss: 0.521497, acc.: 70.31%] [G loss: 0.679552]\n",
      "epoch:25 step:24158 [D loss: 0.592922, acc.: 64.06%] [G loss: 0.611286]\n",
      "epoch:25 step:24159 [D loss: 0.527311, acc.: 72.66%] [G loss: 0.581975]\n",
      "epoch:25 step:24160 [D loss: 0.554779, acc.: 70.31%] [G loss: 0.735286]\n",
      "epoch:25 step:24161 [D loss: 0.479475, acc.: 77.34%] [G loss: 0.738335]\n",
      "epoch:25 step:24162 [D loss: 0.490941, acc.: 77.34%] [G loss: 0.749838]\n",
      "epoch:25 step:24163 [D loss: 0.536268, acc.: 71.88%] [G loss: 0.714195]\n",
      "epoch:25 step:24164 [D loss: 0.598176, acc.: 68.75%] [G loss: 0.595514]\n",
      "epoch:25 step:24165 [D loss: 0.632020, acc.: 63.28%] [G loss: 0.732914]\n",
      "epoch:25 step:24166 [D loss: 0.521579, acc.: 74.22%] [G loss: 0.640213]\n",
      "epoch:25 step:24167 [D loss: 0.503094, acc.: 73.44%] [G loss: 0.747260]\n",
      "epoch:25 step:24168 [D loss: 0.503594, acc.: 75.00%] [G loss: 0.676784]\n",
      "epoch:25 step:24169 [D loss: 0.506740, acc.: 79.69%] [G loss: 0.787567]\n",
      "epoch:25 step:24170 [D loss: 0.595678, acc.: 67.19%] [G loss: 0.680647]\n",
      "epoch:25 step:24171 [D loss: 0.421053, acc.: 79.69%] [G loss: 0.896909]\n",
      "epoch:25 step:24172 [D loss: 0.444661, acc.: 81.25%] [G loss: 0.883933]\n",
      "epoch:25 step:24173 [D loss: 0.548201, acc.: 74.22%] [G loss: 0.753516]\n",
      "epoch:25 step:24174 [D loss: 0.512125, acc.: 73.44%] [G loss: 0.760475]\n",
      "epoch:25 step:24175 [D loss: 0.490621, acc.: 72.66%] [G loss: 0.594547]\n",
      "epoch:25 step:24176 [D loss: 0.510670, acc.: 68.75%] [G loss: 0.839754]\n",
      "epoch:25 step:24177 [D loss: 0.589837, acc.: 70.31%] [G loss: 0.716922]\n",
      "epoch:25 step:24178 [D loss: 0.557280, acc.: 69.53%] [G loss: 0.797599]\n",
      "epoch:25 step:24179 [D loss: 0.533799, acc.: 73.44%] [G loss: 0.679208]\n",
      "epoch:25 step:24180 [D loss: 0.570844, acc.: 69.53%] [G loss: 0.694314]\n",
      "epoch:25 step:24181 [D loss: 0.584897, acc.: 69.53%] [G loss: 0.733903]\n",
      "epoch:25 step:24182 [D loss: 0.583207, acc.: 71.09%] [G loss: 0.721709]\n",
      "epoch:25 step:24183 [D loss: 0.541507, acc.: 70.31%] [G loss: 0.689871]\n",
      "epoch:25 step:24184 [D loss: 0.555085, acc.: 71.09%] [G loss: 0.578623]\n",
      "epoch:25 step:24185 [D loss: 0.471658, acc.: 74.22%] [G loss: 0.712157]\n",
      "epoch:25 step:24186 [D loss: 0.530499, acc.: 75.00%] [G loss: 0.565556]\n",
      "epoch:25 step:24187 [D loss: 0.592522, acc.: 65.62%] [G loss: 0.572634]\n",
      "epoch:25 step:24188 [D loss: 0.557538, acc.: 68.75%] [G loss: 0.529775]\n",
      "epoch:25 step:24189 [D loss: 0.547489, acc.: 73.44%] [G loss: 0.565200]\n",
      "epoch:25 step:24190 [D loss: 0.544055, acc.: 70.31%] [G loss: 0.695881]\n",
      "epoch:25 step:24191 [D loss: 0.651060, acc.: 53.91%] [G loss: 0.462984]\n",
      "epoch:25 step:24192 [D loss: 0.524447, acc.: 69.53%] [G loss: 0.599719]\n",
      "epoch:25 step:24193 [D loss: 0.554009, acc.: 67.19%] [G loss: 0.878420]\n",
      "epoch:25 step:24194 [D loss: 0.468612, acc.: 78.91%] [G loss: 0.831834]\n",
      "epoch:25 step:24195 [D loss: 0.546081, acc.: 66.41%] [G loss: 0.837359]\n",
      "epoch:25 step:24196 [D loss: 0.499994, acc.: 71.88%] [G loss: 0.979999]\n",
      "epoch:25 step:24197 [D loss: 0.552460, acc.: 69.53%] [G loss: 0.725905]\n",
      "epoch:25 step:24198 [D loss: 0.558059, acc.: 72.66%] [G loss: 0.699503]\n",
      "epoch:25 step:24199 [D loss: 0.555191, acc.: 71.09%] [G loss: 0.656135]\n",
      "epoch:25 step:24200 [D loss: 0.511742, acc.: 73.44%] [G loss: 0.780955]\n",
      "##############\n",
      "[2.86661846 0.9010708  6.13122838 4.87390032 3.73756237 5.61688254\n",
      " 4.36960974 4.76916412 4.63261879 4.31222324]\n",
      "##########\n",
      "epoch:25 step:24201 [D loss: 0.544498, acc.: 68.75%] [G loss: 0.640610]\n",
      "epoch:25 step:24202 [D loss: 0.550283, acc.: 73.44%] [G loss: 0.814481]\n",
      "epoch:25 step:24203 [D loss: 0.533616, acc.: 68.75%] [G loss: 0.671960]\n",
      "epoch:25 step:24204 [D loss: 0.511576, acc.: 72.66%] [G loss: 0.569384]\n",
      "epoch:25 step:24205 [D loss: 0.492245, acc.: 75.00%] [G loss: 0.712393]\n",
      "epoch:25 step:24206 [D loss: 0.480211, acc.: 75.78%] [G loss: 1.104292]\n",
      "epoch:25 step:24207 [D loss: 0.485499, acc.: 78.12%] [G loss: 1.020900]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:25 step:24208 [D loss: 0.561133, acc.: 67.19%] [G loss: 0.988895]\n",
      "epoch:25 step:24209 [D loss: 0.628020, acc.: 66.41%] [G loss: 0.532092]\n",
      "epoch:25 step:24210 [D loss: 0.533719, acc.: 70.31%] [G loss: 0.778571]\n",
      "epoch:25 step:24211 [D loss: 0.508488, acc.: 76.56%] [G loss: 0.664304]\n",
      "epoch:25 step:24212 [D loss: 0.546102, acc.: 73.44%] [G loss: 0.692411]\n",
      "epoch:25 step:24213 [D loss: 0.661346, acc.: 58.59%] [G loss: 0.519227]\n",
      "epoch:25 step:24214 [D loss: 0.576902, acc.: 68.75%] [G loss: 0.752770]\n",
      "epoch:25 step:24215 [D loss: 0.545575, acc.: 67.97%] [G loss: 0.594773]\n",
      "epoch:25 step:24216 [D loss: 0.519165, acc.: 75.00%] [G loss: 0.824868]\n",
      "epoch:25 step:24217 [D loss: 0.454135, acc.: 77.34%] [G loss: 0.794039]\n",
      "epoch:25 step:24218 [D loss: 0.616893, acc.: 64.06%] [G loss: 0.768601]\n",
      "epoch:25 step:24219 [D loss: 0.589525, acc.: 68.75%] [G loss: 0.819930]\n",
      "epoch:25 step:24220 [D loss: 0.521473, acc.: 76.56%] [G loss: 0.667041]\n",
      "epoch:25 step:24221 [D loss: 0.523668, acc.: 72.66%] [G loss: 0.863012]\n",
      "epoch:25 step:24222 [D loss: 0.634799, acc.: 64.06%] [G loss: 0.637122]\n",
      "epoch:25 step:24223 [D loss: 0.504824, acc.: 71.88%] [G loss: 0.742710]\n",
      "epoch:25 step:24224 [D loss: 0.595313, acc.: 68.75%] [G loss: 0.712789]\n",
      "epoch:25 step:24225 [D loss: 0.584198, acc.: 67.97%] [G loss: 0.558652]\n",
      "epoch:25 step:24226 [D loss: 0.466133, acc.: 78.12%] [G loss: 0.732765]\n",
      "epoch:25 step:24227 [D loss: 0.480872, acc.: 71.88%] [G loss: 0.800630]\n",
      "epoch:25 step:24228 [D loss: 0.537208, acc.: 74.22%] [G loss: 0.728318]\n",
      "epoch:25 step:24229 [D loss: 0.537341, acc.: 67.97%] [G loss: 0.638751]\n",
      "epoch:25 step:24230 [D loss: 0.541489, acc.: 71.88%] [G loss: 0.590577]\n",
      "epoch:25 step:24231 [D loss: 0.556486, acc.: 68.75%] [G loss: 0.628691]\n",
      "epoch:25 step:24232 [D loss: 0.503935, acc.: 75.78%] [G loss: 0.581743]\n",
      "epoch:25 step:24233 [D loss: 0.548016, acc.: 69.53%] [G loss: 0.580216]\n",
      "epoch:25 step:24234 [D loss: 0.528495, acc.: 67.97%] [G loss: 0.546023]\n",
      "epoch:25 step:24235 [D loss: 0.508525, acc.: 73.44%] [G loss: 0.748753]\n",
      "epoch:25 step:24236 [D loss: 0.562982, acc.: 67.19%] [G loss: 0.696371]\n",
      "epoch:25 step:24237 [D loss: 0.572308, acc.: 67.97%] [G loss: 0.615796]\n",
      "epoch:25 step:24238 [D loss: 0.533051, acc.: 71.88%] [G loss: 0.604272]\n",
      "epoch:25 step:24239 [D loss: 0.459267, acc.: 78.91%] [G loss: 0.622030]\n",
      "epoch:25 step:24240 [D loss: 0.453356, acc.: 75.78%] [G loss: 0.806356]\n",
      "epoch:25 step:24241 [D loss: 0.551176, acc.: 69.53%] [G loss: 0.653134]\n",
      "epoch:25 step:24242 [D loss: 0.575230, acc.: 71.09%] [G loss: 0.777409]\n",
      "epoch:25 step:24243 [D loss: 0.521227, acc.: 72.66%] [G loss: 0.715001]\n",
      "epoch:25 step:24244 [D loss: 0.495670, acc.: 78.91%] [G loss: 0.628923]\n",
      "epoch:25 step:24245 [D loss: 0.645436, acc.: 63.28%] [G loss: 0.583750]\n",
      "epoch:25 step:24246 [D loss: 0.531110, acc.: 71.09%] [G loss: 0.697043]\n",
      "epoch:25 step:24247 [D loss: 0.536767, acc.: 69.53%] [G loss: 0.505343]\n",
      "epoch:25 step:24248 [D loss: 0.432974, acc.: 78.91%] [G loss: 0.956002]\n",
      "epoch:25 step:24249 [D loss: 0.588575, acc.: 67.97%] [G loss: 0.679465]\n",
      "epoch:25 step:24250 [D loss: 0.532865, acc.: 71.88%] [G loss: 0.737745]\n",
      "epoch:25 step:24251 [D loss: 0.594396, acc.: 67.97%] [G loss: 0.700394]\n",
      "epoch:25 step:24252 [D loss: 0.556263, acc.: 66.41%] [G loss: 0.729213]\n",
      "epoch:25 step:24253 [D loss: 0.635161, acc.: 62.50%] [G loss: 0.669762]\n",
      "epoch:25 step:24254 [D loss: 0.550392, acc.: 64.06%] [G loss: 0.806458]\n",
      "epoch:25 step:24255 [D loss: 0.545494, acc.: 71.88%] [G loss: 0.703565]\n",
      "epoch:25 step:24256 [D loss: 0.526114, acc.: 68.75%] [G loss: 0.914288]\n",
      "epoch:25 step:24257 [D loss: 0.512139, acc.: 75.78%] [G loss: 0.681580]\n",
      "epoch:25 step:24258 [D loss: 0.497747, acc.: 75.00%] [G loss: 0.614894]\n",
      "epoch:25 step:24259 [D loss: 0.537174, acc.: 67.19%] [G loss: 0.557587]\n",
      "epoch:25 step:24260 [D loss: 0.528901, acc.: 67.97%] [G loss: 0.643264]\n",
      "epoch:25 step:24261 [D loss: 0.539434, acc.: 73.44%] [G loss: 0.605416]\n",
      "epoch:25 step:24262 [D loss: 0.520957, acc.: 70.31%] [G loss: 0.536111]\n",
      "epoch:25 step:24263 [D loss: 0.606719, acc.: 60.16%] [G loss: 0.654419]\n",
      "epoch:25 step:24264 [D loss: 0.568907, acc.: 67.97%] [G loss: 0.694527]\n",
      "epoch:25 step:24265 [D loss: 0.548291, acc.: 73.44%] [G loss: 0.608132]\n",
      "epoch:25 step:24266 [D loss: 0.534592, acc.: 69.53%] [G loss: 0.413483]\n",
      "epoch:25 step:24267 [D loss: 0.519369, acc.: 72.66%] [G loss: 0.451051]\n",
      "epoch:25 step:24268 [D loss: 0.486435, acc.: 75.78%] [G loss: 0.727635]\n",
      "epoch:25 step:24269 [D loss: 0.540412, acc.: 71.09%] [G loss: 0.727232]\n",
      "epoch:25 step:24270 [D loss: 0.549443, acc.: 69.53%] [G loss: 0.700199]\n",
      "epoch:25 step:24271 [D loss: 0.541616, acc.: 65.62%] [G loss: 0.521302]\n",
      "epoch:25 step:24272 [D loss: 0.623319, acc.: 63.28%] [G loss: 0.513070]\n",
      "epoch:25 step:24273 [D loss: 0.521135, acc.: 69.53%] [G loss: 0.563882]\n",
      "epoch:25 step:24274 [D loss: 0.558848, acc.: 67.19%] [G loss: 0.596946]\n",
      "epoch:25 step:24275 [D loss: 0.554282, acc.: 66.41%] [G loss: 0.567499]\n",
      "epoch:25 step:24276 [D loss: 0.572297, acc.: 67.19%] [G loss: 0.639818]\n",
      "epoch:25 step:24277 [D loss: 0.545175, acc.: 68.75%] [G loss: 0.615869]\n",
      "epoch:25 step:24278 [D loss: 0.533407, acc.: 73.44%] [G loss: 0.646081]\n",
      "epoch:25 step:24279 [D loss: 0.570050, acc.: 58.59%] [G loss: 0.582975]\n",
      "epoch:25 step:24280 [D loss: 0.553271, acc.: 68.75%] [G loss: 0.751747]\n",
      "epoch:25 step:24281 [D loss: 0.638900, acc.: 64.06%] [G loss: 0.619907]\n",
      "epoch:25 step:24282 [D loss: 0.487901, acc.: 79.69%] [G loss: 0.703661]\n",
      "epoch:25 step:24283 [D loss: 0.609838, acc.: 65.62%] [G loss: 0.697362]\n",
      "epoch:25 step:24284 [D loss: 0.583000, acc.: 69.53%] [G loss: 0.751024]\n",
      "epoch:25 step:24285 [D loss: 0.447150, acc.: 78.12%] [G loss: 0.724510]\n",
      "epoch:25 step:24286 [D loss: 0.634822, acc.: 62.50%] [G loss: 0.739375]\n",
      "epoch:25 step:24287 [D loss: 0.543529, acc.: 67.19%] [G loss: 0.685947]\n",
      "epoch:25 step:24288 [D loss: 0.555036, acc.: 69.53%] [G loss: 0.611215]\n",
      "epoch:25 step:24289 [D loss: 0.548829, acc.: 65.62%] [G loss: 0.529098]\n",
      "epoch:25 step:24290 [D loss: 0.556884, acc.: 68.75%] [G loss: 0.574187]\n",
      "epoch:25 step:24291 [D loss: 0.568672, acc.: 63.28%] [G loss: 0.382947]\n",
      "epoch:25 step:24292 [D loss: 0.657812, acc.: 60.16%] [G loss: 0.487622]\n",
      "epoch:25 step:24293 [D loss: 0.563404, acc.: 71.09%] [G loss: 0.526714]\n",
      "epoch:25 step:24294 [D loss: 0.567488, acc.: 64.06%] [G loss: 0.550020]\n",
      "epoch:25 step:24295 [D loss: 0.455128, acc.: 75.78%] [G loss: 0.689972]\n",
      "epoch:25 step:24296 [D loss: 0.474443, acc.: 76.56%] [G loss: 0.702289]\n",
      "epoch:25 step:24297 [D loss: 0.517918, acc.: 75.00%] [G loss: 0.720306]\n",
      "epoch:25 step:24298 [D loss: 0.565345, acc.: 74.22%] [G loss: 0.706808]\n",
      "epoch:25 step:24299 [D loss: 0.597241, acc.: 60.94%] [G loss: 0.680045]\n",
      "epoch:25 step:24300 [D loss: 0.473009, acc.: 79.69%] [G loss: 0.669437]\n",
      "epoch:25 step:24301 [D loss: 0.586840, acc.: 70.31%] [G loss: 0.635357]\n",
      "epoch:25 step:24302 [D loss: 0.639660, acc.: 63.28%] [G loss: 0.569209]\n",
      "epoch:25 step:24303 [D loss: 0.530563, acc.: 71.09%] [G loss: 0.550871]\n",
      "epoch:25 step:24304 [D loss: 0.622234, acc.: 60.94%] [G loss: 0.709223]\n",
      "epoch:25 step:24305 [D loss: 0.675359, acc.: 57.81%] [G loss: 0.540770]\n",
      "epoch:25 step:24306 [D loss: 0.573708, acc.: 66.41%] [G loss: 0.477573]\n",
      "epoch:25 step:24307 [D loss: 0.636453, acc.: 62.50%] [G loss: 0.487294]\n",
      "epoch:25 step:24308 [D loss: 0.564571, acc.: 66.41%] [G loss: 0.688715]\n",
      "epoch:25 step:24309 [D loss: 0.461920, acc.: 78.12%] [G loss: 0.742625]\n",
      "epoch:25 step:24310 [D loss: 0.538924, acc.: 68.75%] [G loss: 0.779329]\n",
      "epoch:25 step:24311 [D loss: 0.507372, acc.: 73.44%] [G loss: 0.752443]\n",
      "epoch:25 step:24312 [D loss: 0.518064, acc.: 71.88%] [G loss: 0.975448]\n",
      "epoch:25 step:24313 [D loss: 0.534807, acc.: 72.66%] [G loss: 0.803851]\n",
      "epoch:25 step:24314 [D loss: 0.529009, acc.: 71.09%] [G loss: 0.672266]\n",
      "epoch:25 step:24315 [D loss: 0.521302, acc.: 69.53%] [G loss: 0.809912]\n",
      "epoch:25 step:24316 [D loss: 0.594672, acc.: 67.97%] [G loss: 0.824837]\n",
      "epoch:25 step:24317 [D loss: 0.653842, acc.: 61.72%] [G loss: 0.624519]\n",
      "epoch:25 step:24318 [D loss: 0.555895, acc.: 69.53%] [G loss: 0.787374]\n",
      "epoch:25 step:24319 [D loss: 0.442187, acc.: 78.12%] [G loss: 0.732724]\n",
      "epoch:25 step:24320 [D loss: 0.479821, acc.: 78.91%] [G loss: 0.624910]\n",
      "epoch:25 step:24321 [D loss: 0.458008, acc.: 80.47%] [G loss: 0.848573]\n",
      "epoch:25 step:24322 [D loss: 0.478722, acc.: 75.78%] [G loss: 0.736986]\n",
      "epoch:25 step:24323 [D loss: 0.463428, acc.: 76.56%] [G loss: 0.895605]\n",
      "epoch:25 step:24324 [D loss: 0.456796, acc.: 80.47%] [G loss: 0.880683]\n",
      "epoch:25 step:24325 [D loss: 0.519640, acc.: 74.22%] [G loss: 0.732515]\n",
      "epoch:25 step:24326 [D loss: 0.488610, acc.: 74.22%] [G loss: 0.893800]\n",
      "epoch:25 step:24327 [D loss: 0.561028, acc.: 64.84%] [G loss: 0.778645]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:25 step:24328 [D loss: 0.541909, acc.: 71.09%] [G loss: 0.809701]\n",
      "epoch:25 step:24329 [D loss: 0.599159, acc.: 69.53%] [G loss: 0.656789]\n",
      "epoch:25 step:24330 [D loss: 0.537280, acc.: 71.88%] [G loss: 0.843306]\n",
      "epoch:25 step:24331 [D loss: 0.481160, acc.: 81.25%] [G loss: 0.720475]\n",
      "epoch:25 step:24332 [D loss: 0.512395, acc.: 71.88%] [G loss: 0.848937]\n",
      "epoch:25 step:24333 [D loss: 0.519883, acc.: 71.09%] [G loss: 0.822342]\n",
      "epoch:25 step:24334 [D loss: 0.513965, acc.: 78.12%] [G loss: 0.869918]\n",
      "epoch:25 step:24335 [D loss: 0.583546, acc.: 71.09%] [G loss: 0.727578]\n",
      "epoch:25 step:24336 [D loss: 0.492900, acc.: 71.09%] [G loss: 0.826675]\n",
      "epoch:25 step:24337 [D loss: 0.500011, acc.: 75.00%] [G loss: 0.856630]\n",
      "epoch:25 step:24338 [D loss: 0.551104, acc.: 70.31%] [G loss: 0.869444]\n",
      "epoch:25 step:24339 [D loss: 0.516393, acc.: 71.09%] [G loss: 0.818741]\n",
      "epoch:25 step:24340 [D loss: 0.609927, acc.: 60.16%] [G loss: 0.663851]\n",
      "epoch:25 step:24341 [D loss: 0.489145, acc.: 75.78%] [G loss: 0.827422]\n",
      "epoch:25 step:24342 [D loss: 0.619509, acc.: 64.06%] [G loss: 0.611236]\n",
      "epoch:25 step:24343 [D loss: 0.443702, acc.: 82.81%] [G loss: 0.829204]\n",
      "epoch:25 step:24344 [D loss: 0.426252, acc.: 81.25%] [G loss: 0.981880]\n",
      "epoch:25 step:24345 [D loss: 0.637079, acc.: 69.53%] [G loss: 0.719663]\n",
      "epoch:25 step:24346 [D loss: 0.529440, acc.: 67.97%] [G loss: 0.815362]\n",
      "epoch:25 step:24347 [D loss: 0.542720, acc.: 70.31%] [G loss: 0.670289]\n",
      "epoch:25 step:24348 [D loss: 0.421943, acc.: 81.25%] [G loss: 0.768238]\n",
      "epoch:25 step:24349 [D loss: 0.417168, acc.: 82.81%] [G loss: 0.931949]\n",
      "epoch:25 step:24350 [D loss: 0.464546, acc.: 83.59%] [G loss: 1.032128]\n",
      "epoch:25 step:24351 [D loss: 0.451318, acc.: 74.22%] [G loss: 1.187019]\n",
      "epoch:25 step:24352 [D loss: 0.488623, acc.: 75.00%] [G loss: 1.252830]\n",
      "epoch:25 step:24353 [D loss: 0.642333, acc.: 63.28%] [G loss: 1.287615]\n",
      "epoch:25 step:24354 [D loss: 0.451115, acc.: 76.56%] [G loss: 1.321142]\n",
      "epoch:25 step:24355 [D loss: 0.503006, acc.: 73.44%] [G loss: 1.446293]\n",
      "epoch:25 step:24356 [D loss: 0.500289, acc.: 71.09%] [G loss: 0.867366]\n",
      "epoch:25 step:24357 [D loss: 0.596278, acc.: 71.88%] [G loss: 0.971823]\n",
      "epoch:25 step:24358 [D loss: 0.544190, acc.: 72.66%] [G loss: 1.221218]\n",
      "epoch:25 step:24359 [D loss: 0.505516, acc.: 68.75%] [G loss: 0.935876]\n",
      "epoch:25 step:24360 [D loss: 0.456783, acc.: 78.12%] [G loss: 1.050259]\n",
      "epoch:25 step:24361 [D loss: 0.375425, acc.: 82.81%] [G loss: 1.333870]\n",
      "epoch:25 step:24362 [D loss: 0.446981, acc.: 82.81%] [G loss: 1.451600]\n",
      "epoch:26 step:24363 [D loss: 0.585279, acc.: 72.66%] [G loss: 1.227208]\n",
      "epoch:26 step:24364 [D loss: 0.455656, acc.: 73.44%] [G loss: 1.028437]\n",
      "epoch:26 step:24365 [D loss: 0.568834, acc.: 67.97%] [G loss: 0.897887]\n",
      "epoch:26 step:24366 [D loss: 0.489240, acc.: 79.69%] [G loss: 1.041860]\n",
      "epoch:26 step:24367 [D loss: 0.590777, acc.: 70.31%] [G loss: 0.954981]\n",
      "epoch:26 step:24368 [D loss: 0.593090, acc.: 70.31%] [G loss: 0.864523]\n",
      "epoch:26 step:24369 [D loss: 0.458076, acc.: 82.81%] [G loss: 0.942876]\n",
      "epoch:26 step:24370 [D loss: 0.539494, acc.: 77.34%] [G loss: 0.865513]\n",
      "epoch:26 step:24371 [D loss: 0.447070, acc.: 77.34%] [G loss: 0.852758]\n",
      "epoch:26 step:24372 [D loss: 0.463591, acc.: 81.25%] [G loss: 0.745941]\n",
      "epoch:26 step:24373 [D loss: 0.474834, acc.: 78.91%] [G loss: 0.937030]\n",
      "epoch:26 step:24374 [D loss: 0.568109, acc.: 67.97%] [G loss: 0.664109]\n",
      "epoch:26 step:24375 [D loss: 0.523800, acc.: 78.91%] [G loss: 0.630017]\n",
      "epoch:26 step:24376 [D loss: 0.511627, acc.: 70.31%] [G loss: 0.769013]\n",
      "epoch:26 step:24377 [D loss: 0.523420, acc.: 71.09%] [G loss: 0.680521]\n",
      "epoch:26 step:24378 [D loss: 0.456075, acc.: 78.91%] [G loss: 1.041908]\n",
      "epoch:26 step:24379 [D loss: 0.590540, acc.: 70.31%] [G loss: 0.816876]\n",
      "epoch:26 step:24380 [D loss: 0.528331, acc.: 77.34%] [G loss: 0.809434]\n",
      "epoch:26 step:24381 [D loss: 0.528879, acc.: 74.22%] [G loss: 0.819031]\n",
      "epoch:26 step:24382 [D loss: 0.637267, acc.: 58.59%] [G loss: 0.696777]\n",
      "epoch:26 step:24383 [D loss: 0.523227, acc.: 74.22%] [G loss: 0.781815]\n",
      "epoch:26 step:24384 [D loss: 0.461512, acc.: 80.47%] [G loss: 0.898835]\n",
      "epoch:26 step:24385 [D loss: 0.632126, acc.: 65.62%] [G loss: 0.760190]\n",
      "epoch:26 step:24386 [D loss: 0.534614, acc.: 70.31%] [G loss: 0.695868]\n",
      "epoch:26 step:24387 [D loss: 0.521108, acc.: 73.44%] [G loss: 0.721770]\n",
      "epoch:26 step:24388 [D loss: 0.587102, acc.: 69.53%] [G loss: 0.624496]\n",
      "epoch:26 step:24389 [D loss: 0.450790, acc.: 78.12%] [G loss: 0.777563]\n",
      "epoch:26 step:24390 [D loss: 0.529957, acc.: 67.97%] [G loss: 0.930668]\n",
      "epoch:26 step:24391 [D loss: 0.549512, acc.: 66.41%] [G loss: 0.582411]\n",
      "epoch:26 step:24392 [D loss: 0.515784, acc.: 74.22%] [G loss: 0.793593]\n",
      "epoch:26 step:24393 [D loss: 0.618508, acc.: 64.84%] [G loss: 0.609183]\n",
      "epoch:26 step:24394 [D loss: 0.523502, acc.: 73.44%] [G loss: 0.661432]\n",
      "epoch:26 step:24395 [D loss: 0.525739, acc.: 72.66%] [G loss: 0.813369]\n",
      "epoch:26 step:24396 [D loss: 0.553905, acc.: 67.19%] [G loss: 0.687405]\n",
      "epoch:26 step:24397 [D loss: 0.571045, acc.: 67.19%] [G loss: 0.613407]\n",
      "epoch:26 step:24398 [D loss: 0.490601, acc.: 75.78%] [G loss: 0.833306]\n",
      "epoch:26 step:24399 [D loss: 0.456678, acc.: 75.78%] [G loss: 0.648760]\n",
      "epoch:26 step:24400 [D loss: 0.525282, acc.: 75.00%] [G loss: 0.649739]\n",
      "##############\n",
      "[3.17978011 0.81870883 6.19829003 4.9332241  3.86979929 5.71175547\n",
      " 4.52810434 4.94081429 4.67073413 4.16453597]\n",
      "##########\n",
      "epoch:26 step:24401 [D loss: 0.499012, acc.: 74.22%] [G loss: 0.644206]\n",
      "epoch:26 step:24402 [D loss: 0.434792, acc.: 82.03%] [G loss: 0.730089]\n",
      "epoch:26 step:24403 [D loss: 0.498470, acc.: 76.56%] [G loss: 0.684650]\n",
      "epoch:26 step:24404 [D loss: 0.514277, acc.: 70.31%] [G loss: 0.612117]\n",
      "epoch:26 step:24405 [D loss: 0.512774, acc.: 69.53%] [G loss: 0.709369]\n",
      "epoch:26 step:24406 [D loss: 0.580556, acc.: 67.19%] [G loss: 0.771236]\n",
      "epoch:26 step:24407 [D loss: 0.470215, acc.: 76.56%] [G loss: 0.656061]\n",
      "epoch:26 step:24408 [D loss: 0.515247, acc.: 75.78%] [G loss: 0.678804]\n",
      "epoch:26 step:24409 [D loss: 0.502308, acc.: 69.53%] [G loss: 0.827401]\n",
      "epoch:26 step:24410 [D loss: 0.514379, acc.: 70.31%] [G loss: 0.651687]\n",
      "epoch:26 step:24411 [D loss: 0.468099, acc.: 77.34%] [G loss: 0.876801]\n",
      "epoch:26 step:24412 [D loss: 0.527100, acc.: 72.66%] [G loss: 0.800048]\n",
      "epoch:26 step:24413 [D loss: 0.603941, acc.: 67.19%] [G loss: 0.773454]\n",
      "epoch:26 step:24414 [D loss: 0.584125, acc.: 64.84%] [G loss: 0.626304]\n",
      "epoch:26 step:24415 [D loss: 0.566851, acc.: 71.09%] [G loss: 0.844519]\n",
      "epoch:26 step:24416 [D loss: 0.483783, acc.: 71.09%] [G loss: 1.033064]\n",
      "epoch:26 step:24417 [D loss: 0.580101, acc.: 69.53%] [G loss: 0.829823]\n",
      "epoch:26 step:24418 [D loss: 0.456243, acc.: 80.47%] [G loss: 0.854713]\n",
      "epoch:26 step:24419 [D loss: 0.513688, acc.: 71.88%] [G loss: 0.721241]\n",
      "epoch:26 step:24420 [D loss: 0.592205, acc.: 67.97%] [G loss: 0.717930]\n",
      "epoch:26 step:24421 [D loss: 0.482744, acc.: 73.44%] [G loss: 1.022634]\n",
      "epoch:26 step:24422 [D loss: 0.557926, acc.: 68.75%] [G loss: 0.743052]\n",
      "epoch:26 step:24423 [D loss: 0.515428, acc.: 73.44%] [G loss: 0.830615]\n",
      "epoch:26 step:24424 [D loss: 0.531859, acc.: 75.00%] [G loss: 0.521927]\n",
      "epoch:26 step:24425 [D loss: 0.545400, acc.: 69.53%] [G loss: 0.697396]\n",
      "epoch:26 step:24426 [D loss: 0.579990, acc.: 68.75%] [G loss: 0.669034]\n",
      "epoch:26 step:24427 [D loss: 0.511679, acc.: 71.88%] [G loss: 0.531208]\n",
      "epoch:26 step:24428 [D loss: 0.587808, acc.: 66.41%] [G loss: 0.485481]\n",
      "epoch:26 step:24429 [D loss: 0.550918, acc.: 68.75%] [G loss: 0.611997]\n",
      "epoch:26 step:24430 [D loss: 0.526965, acc.: 73.44%] [G loss: 0.701817]\n",
      "epoch:26 step:24431 [D loss: 0.521623, acc.: 72.66%] [G loss: 0.605250]\n",
      "epoch:26 step:24432 [D loss: 0.476534, acc.: 76.56%] [G loss: 0.838847]\n",
      "epoch:26 step:24433 [D loss: 0.502634, acc.: 75.00%] [G loss: 0.684257]\n",
      "epoch:26 step:24434 [D loss: 0.512773, acc.: 75.78%] [G loss: 0.649422]\n",
      "epoch:26 step:24435 [D loss: 0.560440, acc.: 64.06%] [G loss: 0.590851]\n",
      "epoch:26 step:24436 [D loss: 0.466096, acc.: 79.69%] [G loss: 0.714985]\n",
      "epoch:26 step:24437 [D loss: 0.553449, acc.: 71.09%] [G loss: 0.740747]\n",
      "epoch:26 step:24438 [D loss: 0.475293, acc.: 74.22%] [G loss: 0.868168]\n",
      "epoch:26 step:24439 [D loss: 0.488083, acc.: 77.34%] [G loss: 1.011406]\n",
      "epoch:26 step:24440 [D loss: 0.564189, acc.: 70.31%] [G loss: 0.672323]\n",
      "epoch:26 step:24441 [D loss: 0.532227, acc.: 74.22%] [G loss: 0.665206]\n",
      "epoch:26 step:24442 [D loss: 0.474762, acc.: 75.00%] [G loss: 0.699162]\n",
      "epoch:26 step:24443 [D loss: 0.491360, acc.: 71.88%] [G loss: 0.777109]\n",
      "epoch:26 step:24444 [D loss: 0.482043, acc.: 74.22%] [G loss: 0.612338]\n",
      "epoch:26 step:24445 [D loss: 0.475925, acc.: 77.34%] [G loss: 0.667505]\n",
      "epoch:26 step:24446 [D loss: 0.536253, acc.: 71.09%] [G loss: 0.865625]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:26 step:24447 [D loss: 0.619457, acc.: 64.06%] [G loss: 0.731165]\n",
      "epoch:26 step:24448 [D loss: 0.539136, acc.: 71.09%] [G loss: 0.732320]\n",
      "epoch:26 step:24449 [D loss: 0.493344, acc.: 75.78%] [G loss: 0.829285]\n",
      "epoch:26 step:24450 [D loss: 0.463072, acc.: 76.56%] [G loss: 0.838882]\n",
      "epoch:26 step:24451 [D loss: 0.511489, acc.: 70.31%] [G loss: 0.623918]\n",
      "epoch:26 step:24452 [D loss: 0.483837, acc.: 73.44%] [G loss: 0.782881]\n",
      "epoch:26 step:24453 [D loss: 0.539770, acc.: 70.31%] [G loss: 0.704188]\n",
      "epoch:26 step:24454 [D loss: 0.506544, acc.: 76.56%] [G loss: 0.887431]\n",
      "epoch:26 step:24455 [D loss: 0.516315, acc.: 77.34%] [G loss: 0.840953]\n",
      "epoch:26 step:24456 [D loss: 0.545285, acc.: 71.09%] [G loss: 0.790999]\n",
      "epoch:26 step:24457 [D loss: 0.514847, acc.: 77.34%] [G loss: 0.781940]\n",
      "epoch:26 step:24458 [D loss: 0.459676, acc.: 74.22%] [G loss: 0.762176]\n",
      "epoch:26 step:24459 [D loss: 0.466640, acc.: 76.56%] [G loss: 0.901225]\n",
      "epoch:26 step:24460 [D loss: 0.620216, acc.: 64.06%] [G loss: 0.741959]\n",
      "epoch:26 step:24461 [D loss: 0.565392, acc.: 70.31%] [G loss: 0.682397]\n",
      "epoch:26 step:24462 [D loss: 0.468753, acc.: 79.69%] [G loss: 0.936223]\n",
      "epoch:26 step:24463 [D loss: 0.519033, acc.: 73.44%] [G loss: 0.793558]\n",
      "epoch:26 step:24464 [D loss: 0.610705, acc.: 66.41%] [G loss: 0.796615]\n",
      "epoch:26 step:24465 [D loss: 0.532161, acc.: 65.62%] [G loss: 0.666092]\n",
      "epoch:26 step:24466 [D loss: 0.517225, acc.: 69.53%] [G loss: 0.631850]\n",
      "epoch:26 step:24467 [D loss: 0.595867, acc.: 60.16%] [G loss: 0.589731]\n",
      "epoch:26 step:24468 [D loss: 0.474789, acc.: 81.25%] [G loss: 0.644751]\n",
      "epoch:26 step:24469 [D loss: 0.558844, acc.: 66.41%] [G loss: 0.755956]\n",
      "epoch:26 step:24470 [D loss: 0.622802, acc.: 67.97%] [G loss: 0.666332]\n",
      "epoch:26 step:24471 [D loss: 0.591606, acc.: 64.84%] [G loss: 0.712218]\n",
      "epoch:26 step:24472 [D loss: 0.522530, acc.: 69.53%] [G loss: 0.650891]\n",
      "epoch:26 step:24473 [D loss: 0.512348, acc.: 72.66%] [G loss: 0.728709]\n",
      "epoch:26 step:24474 [D loss: 0.504402, acc.: 73.44%] [G loss: 0.574478]\n",
      "epoch:26 step:24475 [D loss: 0.491769, acc.: 76.56%] [G loss: 0.903817]\n",
      "epoch:26 step:24476 [D loss: 0.558407, acc.: 75.78%] [G loss: 0.662871]\n",
      "epoch:26 step:24477 [D loss: 0.506594, acc.: 78.12%] [G loss: 0.712226]\n",
      "epoch:26 step:24478 [D loss: 0.520734, acc.: 69.53%] [G loss: 0.771952]\n",
      "epoch:26 step:24479 [D loss: 0.499280, acc.: 75.78%] [G loss: 1.041302]\n",
      "epoch:26 step:24480 [D loss: 0.528636, acc.: 72.66%] [G loss: 0.810750]\n",
      "epoch:26 step:24481 [D loss: 0.435950, acc.: 78.91%] [G loss: 1.020113]\n",
      "epoch:26 step:24482 [D loss: 0.530202, acc.: 72.66%] [G loss: 0.823985]\n",
      "epoch:26 step:24483 [D loss: 0.467863, acc.: 74.22%] [G loss: 0.936744]\n",
      "epoch:26 step:24484 [D loss: 0.491450, acc.: 75.78%] [G loss: 0.757251]\n",
      "epoch:26 step:24485 [D loss: 0.496949, acc.: 75.00%] [G loss: 0.742063]\n",
      "epoch:26 step:24486 [D loss: 0.535037, acc.: 69.53%] [G loss: 0.812439]\n",
      "epoch:26 step:24487 [D loss: 0.540663, acc.: 73.44%] [G loss: 0.633035]\n",
      "epoch:26 step:24488 [D loss: 0.478201, acc.: 74.22%] [G loss: 0.741674]\n",
      "epoch:26 step:24489 [D loss: 0.476500, acc.: 73.44%] [G loss: 0.786429]\n",
      "epoch:26 step:24490 [D loss: 0.509651, acc.: 74.22%] [G loss: 0.901806]\n",
      "epoch:26 step:24491 [D loss: 0.576161, acc.: 69.53%] [G loss: 0.741063]\n",
      "epoch:26 step:24492 [D loss: 0.474715, acc.: 75.78%] [G loss: 0.677658]\n",
      "epoch:26 step:24493 [D loss: 0.483083, acc.: 74.22%] [G loss: 0.635631]\n",
      "epoch:26 step:24494 [D loss: 0.488438, acc.: 71.88%] [G loss: 0.708755]\n",
      "epoch:26 step:24495 [D loss: 0.525910, acc.: 70.31%] [G loss: 0.819469]\n",
      "epoch:26 step:24496 [D loss: 0.514865, acc.: 72.66%] [G loss: 0.903211]\n",
      "epoch:26 step:24497 [D loss: 0.465352, acc.: 78.91%] [G loss: 0.716661]\n",
      "epoch:26 step:24498 [D loss: 0.487808, acc.: 79.69%] [G loss: 0.880591]\n",
      "epoch:26 step:24499 [D loss: 0.600701, acc.: 65.62%] [G loss: 0.763577]\n",
      "epoch:26 step:24500 [D loss: 0.577791, acc.: 68.75%] [G loss: 0.644815]\n",
      "epoch:26 step:24501 [D loss: 0.541511, acc.: 68.75%] [G loss: 0.570005]\n",
      "epoch:26 step:24502 [D loss: 0.574757, acc.: 67.97%] [G loss: 0.707807]\n",
      "epoch:26 step:24503 [D loss: 0.514193, acc.: 68.75%] [G loss: 0.648806]\n",
      "epoch:26 step:24504 [D loss: 0.535884, acc.: 69.53%] [G loss: 0.704888]\n",
      "epoch:26 step:24505 [D loss: 0.566764, acc.: 71.88%] [G loss: 0.625236]\n",
      "epoch:26 step:24506 [D loss: 0.545494, acc.: 67.19%] [G loss: 0.730040]\n",
      "epoch:26 step:24507 [D loss: 0.516272, acc.: 71.09%] [G loss: 0.991179]\n",
      "epoch:26 step:24508 [D loss: 0.461903, acc.: 74.22%] [G loss: 0.706793]\n",
      "epoch:26 step:24509 [D loss: 0.584267, acc.: 70.31%] [G loss: 0.598684]\n",
      "epoch:26 step:24510 [D loss: 0.574313, acc.: 64.06%] [G loss: 0.692048]\n",
      "epoch:26 step:24511 [D loss: 0.505733, acc.: 74.22%] [G loss: 0.805567]\n",
      "epoch:26 step:24512 [D loss: 0.585351, acc.: 66.41%] [G loss: 0.634291]\n",
      "epoch:26 step:24513 [D loss: 0.555481, acc.: 67.97%] [G loss: 0.544956]\n",
      "epoch:26 step:24514 [D loss: 0.446310, acc.: 75.00%] [G loss: 0.828056]\n",
      "epoch:26 step:24515 [D loss: 0.528185, acc.: 70.31%] [G loss: 0.812669]\n",
      "epoch:26 step:24516 [D loss: 0.531467, acc.: 71.09%] [G loss: 0.738868]\n",
      "epoch:26 step:24517 [D loss: 0.500443, acc.: 72.66%] [G loss: 0.649865]\n",
      "epoch:26 step:24518 [D loss: 0.498912, acc.: 76.56%] [G loss: 0.618441]\n",
      "epoch:26 step:24519 [D loss: 0.510513, acc.: 73.44%] [G loss: 0.741196]\n",
      "epoch:26 step:24520 [D loss: 0.574550, acc.: 67.97%] [G loss: 0.593898]\n",
      "epoch:26 step:24521 [D loss: 0.449597, acc.: 79.69%] [G loss: 0.650713]\n",
      "epoch:26 step:24522 [D loss: 0.564873, acc.: 72.66%] [G loss: 0.829910]\n",
      "epoch:26 step:24523 [D loss: 0.503642, acc.: 76.56%] [G loss: 0.856875]\n",
      "epoch:26 step:24524 [D loss: 0.439698, acc.: 79.69%] [G loss: 1.116133]\n",
      "epoch:26 step:24525 [D loss: 0.533093, acc.: 70.31%] [G loss: 0.961291]\n",
      "epoch:26 step:24526 [D loss: 0.565376, acc.: 71.09%] [G loss: 0.925771]\n",
      "epoch:26 step:24527 [D loss: 0.541031, acc.: 70.31%] [G loss: 0.686859]\n",
      "epoch:26 step:24528 [D loss: 0.593852, acc.: 60.94%] [G loss: 0.675435]\n",
      "epoch:26 step:24529 [D loss: 0.513029, acc.: 71.09%] [G loss: 0.871949]\n",
      "epoch:26 step:24530 [D loss: 0.592989, acc.: 65.62%] [G loss: 0.502551]\n",
      "epoch:26 step:24531 [D loss: 0.602663, acc.: 63.28%] [G loss: 0.558290]\n",
      "epoch:26 step:24532 [D loss: 0.546898, acc.: 69.53%] [G loss: 0.684868]\n",
      "epoch:26 step:24533 [D loss: 0.551692, acc.: 64.84%] [G loss: 0.603915]\n",
      "epoch:26 step:24534 [D loss: 0.513402, acc.: 71.88%] [G loss: 0.667446]\n",
      "epoch:26 step:24535 [D loss: 0.471078, acc.: 78.91%] [G loss: 0.646405]\n",
      "epoch:26 step:24536 [D loss: 0.544729, acc.: 69.53%] [G loss: 0.612539]\n",
      "epoch:26 step:24537 [D loss: 0.551875, acc.: 63.28%] [G loss: 0.610163]\n",
      "epoch:26 step:24538 [D loss: 0.517917, acc.: 71.88%] [G loss: 0.653999]\n",
      "epoch:26 step:24539 [D loss: 0.508956, acc.: 72.66%] [G loss: 0.701444]\n",
      "epoch:26 step:24540 [D loss: 0.553661, acc.: 71.88%] [G loss: 0.782976]\n",
      "epoch:26 step:24541 [D loss: 0.546652, acc.: 66.41%] [G loss: 0.576240]\n",
      "epoch:26 step:24542 [D loss: 0.629375, acc.: 62.50%] [G loss: 0.539958]\n",
      "epoch:26 step:24543 [D loss: 0.565727, acc.: 67.97%] [G loss: 0.515275]\n",
      "epoch:26 step:24544 [D loss: 0.535141, acc.: 75.00%] [G loss: 0.698704]\n",
      "epoch:26 step:24545 [D loss: 0.544196, acc.: 70.31%] [G loss: 0.791833]\n",
      "epoch:26 step:24546 [D loss: 0.581686, acc.: 70.31%] [G loss: 0.825323]\n",
      "epoch:26 step:24547 [D loss: 0.556570, acc.: 63.28%] [G loss: 0.756973]\n",
      "epoch:26 step:24548 [D loss: 0.525465, acc.: 71.88%] [G loss: 0.697539]\n",
      "epoch:26 step:24549 [D loss: 0.586735, acc.: 64.84%] [G loss: 0.591368]\n",
      "epoch:26 step:24550 [D loss: 0.556915, acc.: 68.75%] [G loss: 0.530767]\n",
      "epoch:26 step:24551 [D loss: 0.556186, acc.: 67.19%] [G loss: 0.586814]\n",
      "epoch:26 step:24552 [D loss: 0.470771, acc.: 77.34%] [G loss: 0.656272]\n",
      "epoch:26 step:24553 [D loss: 0.508916, acc.: 78.12%] [G loss: 0.828607]\n",
      "epoch:26 step:24554 [D loss: 0.568237, acc.: 67.97%] [G loss: 0.646098]\n",
      "epoch:26 step:24555 [D loss: 0.498468, acc.: 74.22%] [G loss: 0.727424]\n",
      "epoch:26 step:24556 [D loss: 0.426945, acc.: 82.81%] [G loss: 0.991971]\n",
      "epoch:26 step:24557 [D loss: 0.532242, acc.: 73.44%] [G loss: 0.788503]\n",
      "epoch:26 step:24558 [D loss: 0.552594, acc.: 70.31%] [G loss: 1.021317]\n",
      "epoch:26 step:24559 [D loss: 0.540459, acc.: 71.09%] [G loss: 0.643732]\n",
      "epoch:26 step:24560 [D loss: 0.487546, acc.: 75.00%] [G loss: 0.833784]\n",
      "epoch:26 step:24561 [D loss: 0.450185, acc.: 78.91%] [G loss: 0.918322]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:26 step:24562 [D loss: 0.575074, acc.: 73.44%] [G loss: 0.704953]\n",
      "epoch:26 step:24563 [D loss: 0.507745, acc.: 72.66%] [G loss: 0.792547]\n",
      "epoch:26 step:24564 [D loss: 0.523584, acc.: 75.78%] [G loss: 0.748886]\n",
      "epoch:26 step:24565 [D loss: 0.555532, acc.: 64.84%] [G loss: 0.736067]\n",
      "epoch:26 step:24566 [D loss: 0.581467, acc.: 64.06%] [G loss: 0.851844]\n",
      "epoch:26 step:24567 [D loss: 0.488119, acc.: 82.03%] [G loss: 0.840355]\n",
      "epoch:26 step:24568 [D loss: 0.518762, acc.: 72.66%] [G loss: 0.920625]\n",
      "epoch:26 step:24569 [D loss: 0.501034, acc.: 69.53%] [G loss: 0.777830]\n",
      "epoch:26 step:24570 [D loss: 0.444691, acc.: 79.69%] [G loss: 0.880928]\n",
      "epoch:26 step:24571 [D loss: 0.514164, acc.: 73.44%] [G loss: 1.013192]\n",
      "epoch:26 step:24572 [D loss: 0.644509, acc.: 60.94%] [G loss: 0.790521]\n",
      "epoch:26 step:24573 [D loss: 0.637044, acc.: 61.72%] [G loss: 0.527860]\n",
      "epoch:26 step:24574 [D loss: 0.510341, acc.: 74.22%] [G loss: 0.509755]\n",
      "epoch:26 step:24575 [D loss: 0.519946, acc.: 71.09%] [G loss: 0.570324]\n",
      "epoch:26 step:24576 [D loss: 0.574682, acc.: 65.62%] [G loss: 0.684362]\n",
      "epoch:26 step:24577 [D loss: 0.532065, acc.: 70.31%] [G loss: 0.677825]\n",
      "epoch:26 step:24578 [D loss: 0.556505, acc.: 66.41%] [G loss: 0.773507]\n",
      "epoch:26 step:24579 [D loss: 0.463079, acc.: 77.34%] [G loss: 0.747186]\n",
      "epoch:26 step:24580 [D loss: 0.518231, acc.: 73.44%] [G loss: 0.844307]\n",
      "epoch:26 step:24581 [D loss: 0.440764, acc.: 78.91%] [G loss: 1.084810]\n",
      "epoch:26 step:24582 [D loss: 0.641351, acc.: 66.41%] [G loss: 0.928014]\n",
      "epoch:26 step:24583 [D loss: 0.569245, acc.: 64.84%] [G loss: 0.763240]\n",
      "epoch:26 step:24584 [D loss: 0.504330, acc.: 70.31%] [G loss: 0.915678]\n",
      "epoch:26 step:24585 [D loss: 0.463699, acc.: 79.69%] [G loss: 1.021962]\n",
      "epoch:26 step:24586 [D loss: 0.587771, acc.: 65.62%] [G loss: 0.732167]\n",
      "epoch:26 step:24587 [D loss: 0.512962, acc.: 70.31%] [G loss: 0.750772]\n",
      "epoch:26 step:24588 [D loss: 0.571126, acc.: 64.84%] [G loss: 0.601972]\n",
      "epoch:26 step:24589 [D loss: 0.549730, acc.: 71.88%] [G loss: 0.575120]\n",
      "epoch:26 step:24590 [D loss: 0.555116, acc.: 70.31%] [G loss: 0.723627]\n",
      "epoch:26 step:24591 [D loss: 0.547687, acc.: 70.31%] [G loss: 0.764951]\n",
      "epoch:26 step:24592 [D loss: 0.514112, acc.: 74.22%] [G loss: 0.694904]\n",
      "epoch:26 step:24593 [D loss: 0.526827, acc.: 72.66%] [G loss: 0.859841]\n",
      "epoch:26 step:24594 [D loss: 0.418175, acc.: 79.69%] [G loss: 1.071691]\n",
      "epoch:26 step:24595 [D loss: 0.520016, acc.: 74.22%] [G loss: 0.783704]\n",
      "epoch:26 step:24596 [D loss: 0.599774, acc.: 70.31%] [G loss: 0.756797]\n",
      "epoch:26 step:24597 [D loss: 0.590303, acc.: 64.06%] [G loss: 0.616976]\n",
      "epoch:26 step:24598 [D loss: 0.530197, acc.: 71.09%] [G loss: 0.714894]\n",
      "epoch:26 step:24599 [D loss: 0.485312, acc.: 72.66%] [G loss: 0.834106]\n",
      "epoch:26 step:24600 [D loss: 0.605089, acc.: 64.06%] [G loss: 0.613762]\n",
      "##############\n",
      "[2.85845976 0.78578342 6.33951872 4.7958401  3.97411468 5.65742577\n",
      " 4.61164988 4.87520019 4.89744929 4.40052343]\n",
      "##########\n",
      "epoch:26 step:24601 [D loss: 0.517196, acc.: 71.09%] [G loss: 0.537530]\n",
      "epoch:26 step:24602 [D loss: 0.545375, acc.: 70.31%] [G loss: 0.681630]\n",
      "epoch:26 step:24603 [D loss: 0.523617, acc.: 75.78%] [G loss: 0.652855]\n",
      "epoch:26 step:24604 [D loss: 0.460310, acc.: 80.47%] [G loss: 0.677693]\n",
      "epoch:26 step:24605 [D loss: 0.555222, acc.: 68.75%] [G loss: 0.644536]\n",
      "epoch:26 step:24606 [D loss: 0.493101, acc.: 75.78%] [G loss: 0.760988]\n",
      "epoch:26 step:24607 [D loss: 0.540108, acc.: 71.88%] [G loss: 0.735622]\n",
      "epoch:26 step:24608 [D loss: 0.472416, acc.: 75.78%] [G loss: 0.839552]\n",
      "epoch:26 step:24609 [D loss: 0.528770, acc.: 71.09%] [G loss: 0.904046]\n",
      "epoch:26 step:24610 [D loss: 0.579752, acc.: 67.19%] [G loss: 0.935520]\n",
      "epoch:26 step:24611 [D loss: 0.556076, acc.: 73.44%] [G loss: 0.782276]\n",
      "epoch:26 step:24612 [D loss: 0.595165, acc.: 67.19%] [G loss: 0.848662]\n",
      "epoch:26 step:24613 [D loss: 0.595242, acc.: 64.84%] [G loss: 0.875292]\n",
      "epoch:26 step:24614 [D loss: 0.513586, acc.: 74.22%] [G loss: 0.697467]\n",
      "epoch:26 step:24615 [D loss: 0.563776, acc.: 69.53%] [G loss: 0.868785]\n",
      "epoch:26 step:24616 [D loss: 0.561109, acc.: 70.31%] [G loss: 0.713470]\n",
      "epoch:26 step:24617 [D loss: 0.542891, acc.: 70.31%] [G loss: 0.717327]\n",
      "epoch:26 step:24618 [D loss: 0.555727, acc.: 68.75%] [G loss: 0.577416]\n",
      "epoch:26 step:24619 [D loss: 0.548755, acc.: 71.09%] [G loss: 0.641065]\n",
      "epoch:26 step:24620 [D loss: 0.528587, acc.: 73.44%] [G loss: 0.606666]\n",
      "epoch:26 step:24621 [D loss: 0.497326, acc.: 70.31%] [G loss: 0.600359]\n",
      "epoch:26 step:24622 [D loss: 0.572145, acc.: 65.62%] [G loss: 0.660445]\n",
      "epoch:26 step:24623 [D loss: 0.506903, acc.: 69.53%] [G loss: 0.800518]\n",
      "epoch:26 step:24624 [D loss: 0.512390, acc.: 71.09%] [G loss: 0.619076]\n",
      "epoch:26 step:24625 [D loss: 0.562393, acc.: 75.00%] [G loss: 0.589537]\n",
      "epoch:26 step:24626 [D loss: 0.538236, acc.: 72.66%] [G loss: 0.703360]\n",
      "epoch:26 step:24627 [D loss: 0.477881, acc.: 75.00%] [G loss: 0.669383]\n",
      "epoch:26 step:24628 [D loss: 0.551101, acc.: 71.88%] [G loss: 0.650653]\n",
      "epoch:26 step:24629 [D loss: 0.514498, acc.: 74.22%] [G loss: 0.645899]\n",
      "epoch:26 step:24630 [D loss: 0.546441, acc.: 69.53%] [G loss: 0.697194]\n",
      "epoch:26 step:24631 [D loss: 0.529753, acc.: 72.66%] [G loss: 0.641656]\n",
      "epoch:26 step:24632 [D loss: 0.499683, acc.: 72.66%] [G loss: 0.643497]\n",
      "epoch:26 step:24633 [D loss: 0.551851, acc.: 70.31%] [G loss: 0.641024]\n",
      "epoch:26 step:24634 [D loss: 0.532830, acc.: 71.09%] [G loss: 0.783078]\n",
      "epoch:26 step:24635 [D loss: 0.500818, acc.: 72.66%] [G loss: 0.700819]\n",
      "epoch:26 step:24636 [D loss: 0.528592, acc.: 67.97%] [G loss: 0.692229]\n",
      "epoch:26 step:24637 [D loss: 0.554106, acc.: 74.22%] [G loss: 0.816234]\n",
      "epoch:26 step:24638 [D loss: 0.444527, acc.: 82.81%] [G loss: 0.754468]\n",
      "epoch:26 step:24639 [D loss: 0.689560, acc.: 63.28%] [G loss: 0.439682]\n",
      "epoch:26 step:24640 [D loss: 0.643517, acc.: 66.41%] [G loss: 0.530146]\n",
      "epoch:26 step:24641 [D loss: 0.557115, acc.: 67.19%] [G loss: 0.711066]\n",
      "epoch:26 step:24642 [D loss: 0.557085, acc.: 70.31%] [G loss: 0.686380]\n",
      "epoch:26 step:24643 [D loss: 0.546633, acc.: 68.75%] [G loss: 0.507240]\n",
      "epoch:26 step:24644 [D loss: 0.586958, acc.: 69.53%] [G loss: 0.538247]\n",
      "epoch:26 step:24645 [D loss: 0.515842, acc.: 75.00%] [G loss: 0.685058]\n",
      "epoch:26 step:24646 [D loss: 0.536467, acc.: 71.09%] [G loss: 0.674921]\n",
      "epoch:26 step:24647 [D loss: 0.534197, acc.: 70.31%] [G loss: 0.696929]\n",
      "epoch:26 step:24648 [D loss: 0.502373, acc.: 76.56%] [G loss: 0.763750]\n",
      "epoch:26 step:24649 [D loss: 0.550585, acc.: 71.09%] [G loss: 0.582458]\n",
      "epoch:26 step:24650 [D loss: 0.532196, acc.: 76.56%] [G loss: 0.678776]\n",
      "epoch:26 step:24651 [D loss: 0.543055, acc.: 67.97%] [G loss: 0.764552]\n",
      "epoch:26 step:24652 [D loss: 0.587392, acc.: 64.84%] [G loss: 0.715771]\n",
      "epoch:26 step:24653 [D loss: 0.568688, acc.: 66.41%] [G loss: 0.621825]\n",
      "epoch:26 step:24654 [D loss: 0.482303, acc.: 76.56%] [G loss: 0.538879]\n",
      "epoch:26 step:24655 [D loss: 0.573543, acc.: 67.19%] [G loss: 0.603004]\n",
      "epoch:26 step:24656 [D loss: 0.578006, acc.: 71.88%] [G loss: 0.717701]\n",
      "epoch:26 step:24657 [D loss: 0.584954, acc.: 68.75%] [G loss: 0.481969]\n",
      "epoch:26 step:24658 [D loss: 0.448803, acc.: 80.47%] [G loss: 0.650976]\n",
      "epoch:26 step:24659 [D loss: 0.550807, acc.: 67.97%] [G loss: 0.609451]\n",
      "epoch:26 step:24660 [D loss: 0.461009, acc.: 77.34%] [G loss: 0.818358]\n",
      "epoch:26 step:24661 [D loss: 0.500948, acc.: 71.09%] [G loss: 0.689166]\n",
      "epoch:26 step:24662 [D loss: 0.476639, acc.: 75.78%] [G loss: 0.967728]\n",
      "epoch:26 step:24663 [D loss: 0.624963, acc.: 65.62%] [G loss: 0.633507]\n",
      "epoch:26 step:24664 [D loss: 0.503443, acc.: 74.22%] [G loss: 0.575633]\n",
      "epoch:26 step:24665 [D loss: 0.578705, acc.: 68.75%] [G loss: 0.806934]\n",
      "epoch:26 step:24666 [D loss: 0.515306, acc.: 74.22%] [G loss: 0.727239]\n",
      "epoch:26 step:24667 [D loss: 0.530589, acc.: 71.09%] [G loss: 0.952400]\n",
      "epoch:26 step:24668 [D loss: 0.513738, acc.: 75.00%] [G loss: 0.863838]\n",
      "epoch:26 step:24669 [D loss: 0.468230, acc.: 74.22%] [G loss: 1.036384]\n",
      "epoch:26 step:24670 [D loss: 0.598188, acc.: 72.66%] [G loss: 0.601030]\n",
      "epoch:26 step:24671 [D loss: 0.489254, acc.: 75.78%] [G loss: 0.818724]\n",
      "epoch:26 step:24672 [D loss: 0.578470, acc.: 66.41%] [G loss: 0.884472]\n",
      "epoch:26 step:24673 [D loss: 0.532862, acc.: 75.00%] [G loss: 0.742295]\n",
      "epoch:26 step:24674 [D loss: 0.498943, acc.: 77.34%] [G loss: 0.993008]\n",
      "epoch:26 step:24675 [D loss: 0.486015, acc.: 71.88%] [G loss: 1.017624]\n",
      "epoch:26 step:24676 [D loss: 0.470686, acc.: 75.78%] [G loss: 0.812049]\n",
      "epoch:26 step:24677 [D loss: 0.436431, acc.: 81.25%] [G loss: 1.132660]\n",
      "epoch:26 step:24678 [D loss: 0.641176, acc.: 70.31%] [G loss: 0.671621]\n",
      "epoch:26 step:24679 [D loss: 0.538128, acc.: 71.09%] [G loss: 0.728821]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:26 step:24680 [D loss: 0.556797, acc.: 71.09%] [G loss: 0.674631]\n",
      "epoch:26 step:24681 [D loss: 0.543897, acc.: 72.66%] [G loss: 0.701709]\n",
      "epoch:26 step:24682 [D loss: 0.558280, acc.: 68.75%] [G loss: 0.657999]\n",
      "epoch:26 step:24683 [D loss: 0.463726, acc.: 75.78%] [G loss: 0.716096]\n",
      "epoch:26 step:24684 [D loss: 0.561466, acc.: 71.09%] [G loss: 0.618324]\n",
      "epoch:26 step:24685 [D loss: 0.560608, acc.: 67.97%] [G loss: 0.775355]\n",
      "epoch:26 step:24686 [D loss: 0.564106, acc.: 67.97%] [G loss: 0.559485]\n",
      "epoch:26 step:24687 [D loss: 0.536428, acc.: 72.66%] [G loss: 0.577911]\n",
      "epoch:26 step:24688 [D loss: 0.456173, acc.: 76.56%] [G loss: 0.652117]\n",
      "epoch:26 step:24689 [D loss: 0.592682, acc.: 68.75%] [G loss: 0.632209]\n",
      "epoch:26 step:24690 [D loss: 0.427993, acc.: 81.25%] [G loss: 0.890546]\n",
      "epoch:26 step:24691 [D loss: 0.534341, acc.: 74.22%] [G loss: 0.798617]\n",
      "epoch:26 step:24692 [D loss: 0.557851, acc.: 70.31%] [G loss: 0.598755]\n",
      "epoch:26 step:24693 [D loss: 0.575954, acc.: 67.97%] [G loss: 0.828447]\n",
      "epoch:26 step:24694 [D loss: 0.452576, acc.: 78.12%] [G loss: 0.607467]\n",
      "epoch:26 step:24695 [D loss: 0.505375, acc.: 77.34%] [G loss: 0.574993]\n",
      "epoch:26 step:24696 [D loss: 0.470345, acc.: 80.47%] [G loss: 0.804300]\n",
      "epoch:26 step:24697 [D loss: 0.501203, acc.: 75.00%] [G loss: 0.695304]\n",
      "epoch:26 step:24698 [D loss: 0.498592, acc.: 77.34%] [G loss: 0.691222]\n",
      "epoch:26 step:24699 [D loss: 0.476663, acc.: 76.56%] [G loss: 0.901432]\n",
      "epoch:26 step:24700 [D loss: 0.502210, acc.: 70.31%] [G loss: 0.834830]\n",
      "epoch:26 step:24701 [D loss: 0.538973, acc.: 68.75%] [G loss: 0.691322]\n",
      "epoch:26 step:24702 [D loss: 0.486560, acc.: 71.88%] [G loss: 0.709033]\n",
      "epoch:26 step:24703 [D loss: 0.598222, acc.: 71.09%] [G loss: 0.749272]\n",
      "epoch:26 step:24704 [D loss: 0.598664, acc.: 65.62%] [G loss: 0.681856]\n",
      "epoch:26 step:24705 [D loss: 0.543656, acc.: 66.41%] [G loss: 0.681760]\n",
      "epoch:26 step:24706 [D loss: 0.465599, acc.: 78.91%] [G loss: 0.978418]\n",
      "epoch:26 step:24707 [D loss: 0.587194, acc.: 68.75%] [G loss: 0.943542]\n",
      "epoch:26 step:24708 [D loss: 0.546455, acc.: 67.19%] [G loss: 0.876393]\n",
      "epoch:26 step:24709 [D loss: 0.504537, acc.: 72.66%] [G loss: 1.200543]\n",
      "epoch:26 step:24710 [D loss: 0.613285, acc.: 66.41%] [G loss: 0.834464]\n",
      "epoch:26 step:24711 [D loss: 0.740607, acc.: 59.38%] [G loss: 0.477021]\n",
      "epoch:26 step:24712 [D loss: 0.513751, acc.: 75.00%] [G loss: 0.606679]\n",
      "epoch:26 step:24713 [D loss: 0.512683, acc.: 74.22%] [G loss: 0.779140]\n",
      "epoch:26 step:24714 [D loss: 0.521978, acc.: 72.66%] [G loss: 0.756571]\n",
      "epoch:26 step:24715 [D loss: 0.542740, acc.: 70.31%] [G loss: 0.694111]\n",
      "epoch:26 step:24716 [D loss: 0.398997, acc.: 81.25%] [G loss: 0.883183]\n",
      "epoch:26 step:24717 [D loss: 0.515454, acc.: 68.75%] [G loss: 0.869234]\n",
      "epoch:26 step:24718 [D loss: 0.541903, acc.: 70.31%] [G loss: 0.756881]\n",
      "epoch:26 step:24719 [D loss: 0.456748, acc.: 78.12%] [G loss: 0.845370]\n",
      "epoch:26 step:24720 [D loss: 0.456510, acc.: 79.69%] [G loss: 0.941317]\n",
      "epoch:26 step:24721 [D loss: 0.434375, acc.: 76.56%] [G loss: 0.921667]\n",
      "epoch:26 step:24722 [D loss: 0.521974, acc.: 71.09%] [G loss: 1.008937]\n",
      "epoch:26 step:24723 [D loss: 0.471792, acc.: 78.91%] [G loss: 0.771489]\n",
      "epoch:26 step:24724 [D loss: 0.547962, acc.: 68.75%] [G loss: 0.842223]\n",
      "epoch:26 step:24725 [D loss: 0.555223, acc.: 70.31%] [G loss: 0.836183]\n",
      "epoch:26 step:24726 [D loss: 0.548128, acc.: 68.75%] [G loss: 0.869841]\n",
      "epoch:26 step:24727 [D loss: 0.567775, acc.: 71.09%] [G loss: 0.624815]\n",
      "epoch:26 step:24728 [D loss: 0.545905, acc.: 71.09%] [G loss: 0.688754]\n",
      "epoch:26 step:24729 [D loss: 0.582283, acc.: 68.75%] [G loss: 0.757687]\n",
      "epoch:26 step:24730 [D loss: 0.509597, acc.: 73.44%] [G loss: 0.603124]\n",
      "epoch:26 step:24731 [D loss: 0.498884, acc.: 73.44%] [G loss: 0.807200]\n",
      "epoch:26 step:24732 [D loss: 0.580359, acc.: 65.62%] [G loss: 0.817021]\n",
      "epoch:26 step:24733 [D loss: 0.544335, acc.: 71.88%] [G loss: 0.757393]\n",
      "epoch:26 step:24734 [D loss: 0.560545, acc.: 71.09%] [G loss: 0.823113]\n",
      "epoch:26 step:24735 [D loss: 0.538801, acc.: 71.88%] [G loss: 0.736893]\n",
      "epoch:26 step:24736 [D loss: 0.416772, acc.: 82.81%] [G loss: 0.928190]\n",
      "epoch:26 step:24737 [D loss: 0.540822, acc.: 73.44%] [G loss: 0.686359]\n",
      "epoch:26 step:24738 [D loss: 0.734051, acc.: 53.12%] [G loss: 0.547131]\n",
      "epoch:26 step:24739 [D loss: 0.548109, acc.: 68.75%] [G loss: 0.617006]\n",
      "epoch:26 step:24740 [D loss: 0.482976, acc.: 75.00%] [G loss: 0.704531]\n",
      "epoch:26 step:24741 [D loss: 0.623738, acc.: 67.97%] [G loss: 0.636003]\n",
      "epoch:26 step:24742 [D loss: 0.591615, acc.: 64.84%] [G loss: 0.568809]\n",
      "epoch:26 step:24743 [D loss: 0.473197, acc.: 74.22%] [G loss: 0.764422]\n",
      "epoch:26 step:24744 [D loss: 0.542519, acc.: 72.66%] [G loss: 0.868749]\n",
      "epoch:26 step:24745 [D loss: 0.526894, acc.: 71.88%] [G loss: 0.637026]\n",
      "epoch:26 step:24746 [D loss: 0.527465, acc.: 74.22%] [G loss: 0.663989]\n",
      "epoch:26 step:24747 [D loss: 0.444417, acc.: 77.34%] [G loss: 0.806529]\n",
      "epoch:26 step:24748 [D loss: 0.616117, acc.: 60.94%] [G loss: 0.673863]\n",
      "epoch:26 step:24749 [D loss: 0.528784, acc.: 70.31%] [G loss: 0.810134]\n",
      "epoch:26 step:24750 [D loss: 0.535921, acc.: 71.88%] [G loss: 0.818950]\n",
      "epoch:26 step:24751 [D loss: 0.482613, acc.: 76.56%] [G loss: 0.726064]\n",
      "epoch:26 step:24752 [D loss: 0.596323, acc.: 67.97%] [G loss: 0.816483]\n",
      "epoch:26 step:24753 [D loss: 0.548895, acc.: 70.31%] [G loss: 0.690986]\n",
      "epoch:26 step:24754 [D loss: 0.498813, acc.: 76.56%] [G loss: 0.621430]\n",
      "epoch:26 step:24755 [D loss: 0.594335, acc.: 67.19%] [G loss: 0.626103]\n",
      "epoch:26 step:24756 [D loss: 0.533445, acc.: 68.75%] [G loss: 0.632809]\n",
      "epoch:26 step:24757 [D loss: 0.533781, acc.: 71.88%] [G loss: 0.576719]\n",
      "epoch:26 step:24758 [D loss: 0.493128, acc.: 74.22%] [G loss: 0.713162]\n",
      "epoch:26 step:24759 [D loss: 0.548320, acc.: 67.19%] [G loss: 0.537617]\n",
      "epoch:26 step:24760 [D loss: 0.463510, acc.: 80.47%] [G loss: 0.788329]\n",
      "epoch:26 step:24761 [D loss: 0.527543, acc.: 75.00%] [G loss: 0.912814]\n",
      "epoch:26 step:24762 [D loss: 0.630159, acc.: 58.59%] [G loss: 0.639929]\n",
      "epoch:26 step:24763 [D loss: 0.628864, acc.: 64.06%] [G loss: 0.580569]\n",
      "epoch:26 step:24764 [D loss: 0.494455, acc.: 69.53%] [G loss: 0.680826]\n",
      "epoch:26 step:24765 [D loss: 0.473904, acc.: 73.44%] [G loss: 0.589099]\n",
      "epoch:26 step:24766 [D loss: 0.618770, acc.: 62.50%] [G loss: 0.494638]\n",
      "epoch:26 step:24767 [D loss: 0.543065, acc.: 71.09%] [G loss: 0.716967]\n",
      "epoch:26 step:24768 [D loss: 0.487714, acc.: 73.44%] [G loss: 0.872585]\n",
      "epoch:26 step:24769 [D loss: 0.608233, acc.: 62.50%] [G loss: 0.669110]\n",
      "epoch:26 step:24770 [D loss: 0.552454, acc.: 69.53%] [G loss: 0.912968]\n",
      "epoch:26 step:24771 [D loss: 0.572687, acc.: 67.19%] [G loss: 0.824893]\n",
      "epoch:26 step:24772 [D loss: 0.553072, acc.: 66.41%] [G loss: 0.680569]\n",
      "epoch:26 step:24773 [D loss: 0.580521, acc.: 70.31%] [G loss: 0.772113]\n",
      "epoch:26 step:24774 [D loss: 0.563670, acc.: 70.31%] [G loss: 0.655694]\n",
      "epoch:26 step:24775 [D loss: 0.557497, acc.: 71.88%] [G loss: 0.630032]\n",
      "epoch:26 step:24776 [D loss: 0.508208, acc.: 72.66%] [G loss: 0.597873]\n",
      "epoch:26 step:24777 [D loss: 0.508066, acc.: 68.75%] [G loss: 0.735942]\n",
      "epoch:26 step:24778 [D loss: 0.473505, acc.: 75.00%] [G loss: 0.824326]\n",
      "epoch:26 step:24779 [D loss: 0.547409, acc.: 74.22%] [G loss: 0.893067]\n",
      "epoch:26 step:24780 [D loss: 0.589300, acc.: 68.75%] [G loss: 0.597157]\n",
      "epoch:26 step:24781 [D loss: 0.525648, acc.: 70.31%] [G loss: 0.635679]\n",
      "epoch:26 step:24782 [D loss: 0.561207, acc.: 68.75%] [G loss: 0.772014]\n",
      "epoch:26 step:24783 [D loss: 0.595911, acc.: 69.53%] [G loss: 0.759642]\n",
      "epoch:26 step:24784 [D loss: 0.577771, acc.: 67.97%] [G loss: 0.460680]\n",
      "epoch:26 step:24785 [D loss: 0.540160, acc.: 68.75%] [G loss: 0.587337]\n",
      "epoch:26 step:24786 [D loss: 0.556903, acc.: 61.72%] [G loss: 0.746356]\n",
      "epoch:26 step:24787 [D loss: 0.490997, acc.: 75.00%] [G loss: 0.756181]\n",
      "epoch:26 step:24788 [D loss: 0.450819, acc.: 73.44%] [G loss: 0.848522]\n",
      "epoch:26 step:24789 [D loss: 0.478943, acc.: 77.34%] [G loss: 0.870102]\n",
      "epoch:26 step:24790 [D loss: 0.574279, acc.: 71.88%] [G loss: 0.718590]\n",
      "epoch:26 step:24791 [D loss: 0.481432, acc.: 80.47%] [G loss: 0.811569]\n",
      "epoch:26 step:24792 [D loss: 0.512354, acc.: 75.00%] [G loss: 0.623955]\n",
      "epoch:26 step:24793 [D loss: 0.530207, acc.: 68.75%] [G loss: 0.805750]\n",
      "epoch:26 step:24794 [D loss: 0.597738, acc.: 66.41%] [G loss: 0.652236]\n",
      "epoch:26 step:24795 [D loss: 0.549417, acc.: 73.44%] [G loss: 0.670464]\n",
      "epoch:26 step:24796 [D loss: 0.507526, acc.: 78.12%] [G loss: 0.756987]\n",
      "epoch:26 step:24797 [D loss: 0.570845, acc.: 67.97%] [G loss: 0.758309]\n",
      "epoch:26 step:24798 [D loss: 0.478864, acc.: 75.78%] [G loss: 0.853297]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:26 step:24799 [D loss: 0.700735, acc.: 59.38%] [G loss: 0.748674]\n",
      "epoch:26 step:24800 [D loss: 0.546929, acc.: 67.97%] [G loss: 0.596500]\n",
      "##############\n",
      "[2.95590237 0.78678781 6.22569101 5.08839961 4.01211375 5.81301821\n",
      " 4.63219411 4.75800431 4.65492977 4.04393317]\n",
      "##########\n",
      "epoch:26 step:24801 [D loss: 0.527764, acc.: 75.00%] [G loss: 0.714560]\n",
      "epoch:26 step:24802 [D loss: 0.495982, acc.: 71.88%] [G loss: 0.784730]\n",
      "epoch:26 step:24803 [D loss: 0.552928, acc.: 66.41%] [G loss: 0.860857]\n",
      "epoch:26 step:24804 [D loss: 0.511813, acc.: 67.19%] [G loss: 0.877691]\n",
      "epoch:26 step:24805 [D loss: 0.484083, acc.: 74.22%] [G loss: 0.804730]\n",
      "epoch:26 step:24806 [D loss: 0.478722, acc.: 80.47%] [G loss: 0.945877]\n",
      "epoch:26 step:24807 [D loss: 0.565577, acc.: 64.06%] [G loss: 0.766934]\n",
      "epoch:26 step:24808 [D loss: 0.578498, acc.: 67.19%] [G loss: 0.800794]\n",
      "epoch:26 step:24809 [D loss: 0.509195, acc.: 73.44%] [G loss: 0.674599]\n",
      "epoch:26 step:24810 [D loss: 0.588347, acc.: 71.88%] [G loss: 0.706875]\n",
      "epoch:26 step:24811 [D loss: 0.466509, acc.: 77.34%] [G loss: 0.797248]\n",
      "epoch:26 step:24812 [D loss: 0.503857, acc.: 71.88%] [G loss: 0.776564]\n",
      "epoch:26 step:24813 [D loss: 0.425906, acc.: 82.03%] [G loss: 0.793013]\n",
      "epoch:26 step:24814 [D loss: 0.479385, acc.: 75.00%] [G loss: 0.843418]\n",
      "epoch:26 step:24815 [D loss: 0.532088, acc.: 71.88%] [G loss: 0.983305]\n",
      "epoch:26 step:24816 [D loss: 0.561310, acc.: 71.09%] [G loss: 0.781305]\n",
      "epoch:26 step:24817 [D loss: 0.587976, acc.: 65.62%] [G loss: 0.717861]\n",
      "epoch:26 step:24818 [D loss: 0.638077, acc.: 62.50%] [G loss: 0.734629]\n",
      "epoch:26 step:24819 [D loss: 0.473625, acc.: 77.34%] [G loss: 0.694708]\n",
      "epoch:26 step:24820 [D loss: 0.588707, acc.: 66.41%] [G loss: 0.627445]\n",
      "epoch:26 step:24821 [D loss: 0.511388, acc.: 76.56%] [G loss: 0.702390]\n",
      "epoch:26 step:24822 [D loss: 0.461280, acc.: 82.03%] [G loss: 0.746464]\n",
      "epoch:26 step:24823 [D loss: 0.486171, acc.: 72.66%] [G loss: 0.860405]\n",
      "epoch:26 step:24824 [D loss: 0.618862, acc.: 64.06%] [G loss: 0.667147]\n",
      "epoch:26 step:24825 [D loss: 0.521874, acc.: 71.09%] [G loss: 0.739407]\n",
      "epoch:26 step:24826 [D loss: 0.516215, acc.: 72.66%] [G loss: 0.922081]\n",
      "epoch:26 step:24827 [D loss: 0.559941, acc.: 68.75%] [G loss: 0.607691]\n",
      "epoch:26 step:24828 [D loss: 0.554692, acc.: 70.31%] [G loss: 0.595150]\n",
      "epoch:26 step:24829 [D loss: 0.526646, acc.: 72.66%] [G loss: 0.621758]\n",
      "epoch:26 step:24830 [D loss: 0.540440, acc.: 71.88%] [G loss: 0.665053]\n",
      "epoch:26 step:24831 [D loss: 0.503126, acc.: 74.22%] [G loss: 0.761157]\n",
      "epoch:26 step:24832 [D loss: 0.576427, acc.: 70.31%] [G loss: 0.618036]\n",
      "epoch:26 step:24833 [D loss: 0.453511, acc.: 77.34%] [G loss: 0.772264]\n",
      "epoch:26 step:24834 [D loss: 0.425553, acc.: 80.47%] [G loss: 0.912764]\n",
      "epoch:26 step:24835 [D loss: 0.629608, acc.: 64.84%] [G loss: 0.756205]\n",
      "epoch:26 step:24836 [D loss: 0.514345, acc.: 67.97%] [G loss: 0.718294]\n",
      "epoch:26 step:24837 [D loss: 0.425942, acc.: 83.59%] [G loss: 0.838084]\n",
      "epoch:26 step:24838 [D loss: 0.506622, acc.: 75.00%] [G loss: 0.765028]\n",
      "epoch:26 step:24839 [D loss: 0.641500, acc.: 63.28%] [G loss: 0.608931]\n",
      "epoch:26 step:24840 [D loss: 0.545975, acc.: 67.19%] [G loss: 0.564291]\n",
      "epoch:26 step:24841 [D loss: 0.520742, acc.: 75.00%] [G loss: 0.562149]\n",
      "epoch:26 step:24842 [D loss: 0.571757, acc.: 71.09%] [G loss: 0.623079]\n",
      "epoch:26 step:24843 [D loss: 0.521038, acc.: 75.78%] [G loss: 0.752671]\n",
      "epoch:26 step:24844 [D loss: 0.673760, acc.: 57.81%] [G loss: 0.627039]\n",
      "epoch:26 step:24845 [D loss: 0.480017, acc.: 77.34%] [G loss: 0.692210]\n",
      "epoch:26 step:24846 [D loss: 0.475126, acc.: 74.22%] [G loss: 0.665207]\n",
      "epoch:26 step:24847 [D loss: 0.510873, acc.: 73.44%] [G loss: 0.881830]\n",
      "epoch:26 step:24848 [D loss: 0.627217, acc.: 64.84%] [G loss: 0.644337]\n",
      "epoch:26 step:24849 [D loss: 0.544495, acc.: 64.06%] [G loss: 0.662195]\n",
      "epoch:26 step:24850 [D loss: 0.546292, acc.: 67.19%] [G loss: 0.744986]\n",
      "epoch:26 step:24851 [D loss: 0.480933, acc.: 73.44%] [G loss: 0.757520]\n",
      "epoch:26 step:24852 [D loss: 0.586969, acc.: 64.84%] [G loss: 0.747252]\n",
      "epoch:26 step:24853 [D loss: 0.539928, acc.: 69.53%] [G loss: 0.642736]\n",
      "epoch:26 step:24854 [D loss: 0.578851, acc.: 68.75%] [G loss: 0.670734]\n",
      "epoch:26 step:24855 [D loss: 0.550627, acc.: 69.53%] [G loss: 0.556432]\n",
      "epoch:26 step:24856 [D loss: 0.538188, acc.: 70.31%] [G loss: 0.676186]\n",
      "epoch:26 step:24857 [D loss: 0.482222, acc.: 78.91%] [G loss: 0.742416]\n",
      "epoch:26 step:24858 [D loss: 0.524563, acc.: 76.56%] [G loss: 0.735065]\n",
      "epoch:26 step:24859 [D loss: 0.600943, acc.: 69.53%] [G loss: 0.767160]\n",
      "epoch:26 step:24860 [D loss: 0.519034, acc.: 73.44%] [G loss: 0.914711]\n",
      "epoch:26 step:24861 [D loss: 0.458126, acc.: 75.00%] [G loss: 0.825937]\n",
      "epoch:26 step:24862 [D loss: 0.575869, acc.: 64.06%] [G loss: 0.691517]\n",
      "epoch:26 step:24863 [D loss: 0.624404, acc.: 68.75%] [G loss: 0.695340]\n",
      "epoch:26 step:24864 [D loss: 0.635785, acc.: 66.41%] [G loss: 0.667840]\n",
      "epoch:26 step:24865 [D loss: 0.501800, acc.: 74.22%] [G loss: 0.622708]\n",
      "epoch:26 step:24866 [D loss: 0.480069, acc.: 75.00%] [G loss: 0.655701]\n",
      "epoch:26 step:24867 [D loss: 0.483060, acc.: 76.56%] [G loss: 0.743629]\n",
      "epoch:26 step:24868 [D loss: 0.481178, acc.: 75.78%] [G loss: 0.925849]\n",
      "epoch:26 step:24869 [D loss: 0.520944, acc.: 78.91%] [G loss: 0.801321]\n",
      "epoch:26 step:24870 [D loss: 0.421139, acc.: 81.25%] [G loss: 0.890474]\n",
      "epoch:26 step:24871 [D loss: 0.474236, acc.: 74.22%] [G loss: 1.000301]\n",
      "epoch:26 step:24872 [D loss: 0.565328, acc.: 72.66%] [G loss: 0.727637]\n",
      "epoch:26 step:24873 [D loss: 0.604164, acc.: 65.62%] [G loss: 0.734970]\n",
      "epoch:26 step:24874 [D loss: 0.581507, acc.: 70.31%] [G loss: 0.589004]\n",
      "epoch:26 step:24875 [D loss: 0.502536, acc.: 75.00%] [G loss: 0.618617]\n",
      "epoch:26 step:24876 [D loss: 0.516233, acc.: 68.75%] [G loss: 0.632259]\n",
      "epoch:26 step:24877 [D loss: 0.509026, acc.: 75.00%] [G loss: 0.571879]\n",
      "epoch:26 step:24878 [D loss: 0.492488, acc.: 77.34%] [G loss: 0.864345]\n",
      "epoch:26 step:24879 [D loss: 0.422133, acc.: 81.25%] [G loss: 0.771149]\n",
      "epoch:26 step:24880 [D loss: 0.549172, acc.: 71.09%] [G loss: 0.746055]\n",
      "epoch:26 step:24881 [D loss: 0.521544, acc.: 74.22%] [G loss: 0.717307]\n",
      "epoch:26 step:24882 [D loss: 0.503271, acc.: 75.00%] [G loss: 0.806667]\n",
      "epoch:26 step:24883 [D loss: 0.483236, acc.: 75.78%] [G loss: 0.722184]\n",
      "epoch:26 step:24884 [D loss: 0.485484, acc.: 76.56%] [G loss: 0.858126]\n",
      "epoch:26 step:24885 [D loss: 0.538731, acc.: 73.44%] [G loss: 0.612450]\n",
      "epoch:26 step:24886 [D loss: 0.541035, acc.: 71.88%] [G loss: 0.726998]\n",
      "epoch:26 step:24887 [D loss: 0.591939, acc.: 71.09%] [G loss: 0.686792]\n",
      "epoch:26 step:24888 [D loss: 0.486457, acc.: 73.44%] [G loss: 0.740390]\n",
      "epoch:26 step:24889 [D loss: 0.586907, acc.: 62.50%] [G loss: 0.651895]\n",
      "epoch:26 step:24890 [D loss: 0.683047, acc.: 63.28%] [G loss: 0.655663]\n",
      "epoch:26 step:24891 [D loss: 0.597570, acc.: 59.38%] [G loss: 0.715518]\n",
      "epoch:26 step:24892 [D loss: 0.575728, acc.: 63.28%] [G loss: 0.578656]\n",
      "epoch:26 step:24893 [D loss: 0.543906, acc.: 67.97%] [G loss: 0.673317]\n",
      "epoch:26 step:24894 [D loss: 0.511010, acc.: 75.00%] [G loss: 0.629175]\n",
      "epoch:26 step:24895 [D loss: 0.498310, acc.: 68.75%] [G loss: 0.701650]\n",
      "epoch:26 step:24896 [D loss: 0.485032, acc.: 81.25%] [G loss: 0.758428]\n",
      "epoch:26 step:24897 [D loss: 0.619057, acc.: 60.94%] [G loss: 0.571107]\n",
      "epoch:26 step:24898 [D loss: 0.492554, acc.: 72.66%] [G loss: 0.546900]\n",
      "epoch:26 step:24899 [D loss: 0.612433, acc.: 64.06%] [G loss: 0.521549]\n",
      "epoch:26 step:24900 [D loss: 0.530125, acc.: 71.09%] [G loss: 0.769282]\n",
      "epoch:26 step:24901 [D loss: 0.539891, acc.: 67.19%] [G loss: 0.648761]\n",
      "epoch:26 step:24902 [D loss: 0.617903, acc.: 62.50%] [G loss: 0.532699]\n",
      "epoch:26 step:24903 [D loss: 0.541431, acc.: 70.31%] [G loss: 0.632136]\n",
      "epoch:26 step:24904 [D loss: 0.597508, acc.: 64.06%] [G loss: 0.376039]\n",
      "epoch:26 step:24905 [D loss: 0.566241, acc.: 69.53%] [G loss: 0.643052]\n",
      "epoch:26 step:24906 [D loss: 0.559448, acc.: 67.97%] [G loss: 0.592769]\n",
      "epoch:26 step:24907 [D loss: 0.503383, acc.: 71.88%] [G loss: 0.720539]\n",
      "epoch:26 step:24908 [D loss: 0.498223, acc.: 75.78%] [G loss: 0.907252]\n",
      "epoch:26 step:24909 [D loss: 0.537121, acc.: 72.66%] [G loss: 0.717706]\n",
      "epoch:26 step:24910 [D loss: 0.501718, acc.: 70.31%] [G loss: 0.907021]\n",
      "epoch:26 step:24911 [D loss: 0.512387, acc.: 76.56%] [G loss: 0.763538]\n",
      "epoch:26 step:24912 [D loss: 0.518139, acc.: 75.78%] [G loss: 0.766058]\n",
      "epoch:26 step:24913 [D loss: 0.524622, acc.: 69.53%] [G loss: 0.743751]\n",
      "epoch:26 step:24914 [D loss: 0.486093, acc.: 75.78%] [G loss: 0.665010]\n",
      "epoch:26 step:24915 [D loss: 0.583533, acc.: 66.41%] [G loss: 0.713630]\n",
      "epoch:26 step:24916 [D loss: 0.432812, acc.: 82.03%] [G loss: 0.767814]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:26 step:24917 [D loss: 0.460720, acc.: 77.34%] [G loss: 0.831782]\n",
      "epoch:26 step:24918 [D loss: 0.548391, acc.: 72.66%] [G loss: 0.675644]\n",
      "epoch:26 step:24919 [D loss: 0.497302, acc.: 76.56%] [G loss: 0.638780]\n",
      "epoch:26 step:24920 [D loss: 0.465645, acc.: 76.56%] [G loss: 0.750581]\n",
      "epoch:26 step:24921 [D loss: 0.566007, acc.: 70.31%] [G loss: 0.735591]\n",
      "epoch:26 step:24922 [D loss: 0.508834, acc.: 71.88%] [G loss: 0.783803]\n",
      "epoch:26 step:24923 [D loss: 0.531348, acc.: 71.88%] [G loss: 0.728428]\n",
      "epoch:26 step:24924 [D loss: 0.502024, acc.: 75.78%] [G loss: 0.634731]\n",
      "epoch:26 step:24925 [D loss: 0.510443, acc.: 75.00%] [G loss: 0.695949]\n",
      "epoch:26 step:24926 [D loss: 0.508043, acc.: 74.22%] [G loss: 0.639390]\n",
      "epoch:26 step:24927 [D loss: 0.517905, acc.: 73.44%] [G loss: 0.677072]\n",
      "epoch:26 step:24928 [D loss: 0.746622, acc.: 57.03%] [G loss: 0.509702]\n",
      "epoch:26 step:24929 [D loss: 0.519661, acc.: 71.09%] [G loss: 0.539550]\n",
      "epoch:26 step:24930 [D loss: 0.521696, acc.: 73.44%] [G loss: 0.669881]\n",
      "epoch:26 step:24931 [D loss: 0.585873, acc.: 64.06%] [G loss: 0.686910]\n",
      "epoch:26 step:24932 [D loss: 0.493864, acc.: 72.66%] [G loss: 0.815757]\n",
      "epoch:26 step:24933 [D loss: 0.484257, acc.: 75.78%] [G loss: 0.690488]\n",
      "epoch:26 step:24934 [D loss: 0.511039, acc.: 77.34%] [G loss: 0.648131]\n",
      "epoch:26 step:24935 [D loss: 0.523294, acc.: 73.44%] [G loss: 0.579421]\n",
      "epoch:26 step:24936 [D loss: 0.453341, acc.: 75.78%] [G loss: 0.679585]\n",
      "epoch:26 step:24937 [D loss: 0.473410, acc.: 80.47%] [G loss: 0.765017]\n",
      "epoch:26 step:24938 [D loss: 0.599882, acc.: 67.19%] [G loss: 0.676945]\n",
      "epoch:26 step:24939 [D loss: 0.542929, acc.: 69.53%] [G loss: 0.722724]\n",
      "epoch:26 step:24940 [D loss: 0.552669, acc.: 70.31%] [G loss: 0.606427]\n",
      "epoch:26 step:24941 [D loss: 0.488410, acc.: 76.56%] [G loss: 0.756742]\n",
      "epoch:26 step:24942 [D loss: 0.655691, acc.: 60.94%] [G loss: 0.555647]\n",
      "epoch:26 step:24943 [D loss: 0.525372, acc.: 72.66%] [G loss: 0.558538]\n",
      "epoch:26 step:24944 [D loss: 0.423028, acc.: 82.81%] [G loss: 0.770258]\n",
      "epoch:26 step:24945 [D loss: 0.590899, acc.: 70.31%] [G loss: 0.948740]\n",
      "epoch:26 step:24946 [D loss: 0.632801, acc.: 63.28%] [G loss: 0.778360]\n",
      "epoch:26 step:24947 [D loss: 0.520124, acc.: 75.78%] [G loss: 0.728971]\n",
      "epoch:26 step:24948 [D loss: 0.566198, acc.: 66.41%] [G loss: 0.524342]\n",
      "epoch:26 step:24949 [D loss: 0.545946, acc.: 69.53%] [G loss: 0.675157]\n",
      "epoch:26 step:24950 [D loss: 0.560594, acc.: 67.97%] [G loss: 0.611032]\n",
      "epoch:26 step:24951 [D loss: 0.568342, acc.: 65.62%] [G loss: 0.832524]\n",
      "epoch:26 step:24952 [D loss: 0.547812, acc.: 70.31%] [G loss: 0.929449]\n",
      "epoch:26 step:24953 [D loss: 0.643121, acc.: 64.06%] [G loss: 0.490232]\n",
      "epoch:26 step:24954 [D loss: 0.477416, acc.: 79.69%] [G loss: 0.630930]\n",
      "epoch:26 step:24955 [D loss: 0.504320, acc.: 75.78%] [G loss: 0.714619]\n",
      "epoch:26 step:24956 [D loss: 0.579735, acc.: 68.75%] [G loss: 0.578228]\n",
      "epoch:26 step:24957 [D loss: 0.582282, acc.: 67.19%] [G loss: 0.679652]\n",
      "epoch:26 step:24958 [D loss: 0.504748, acc.: 74.22%] [G loss: 0.769668]\n",
      "epoch:26 step:24959 [D loss: 0.558545, acc.: 67.97%] [G loss: 0.690936]\n",
      "epoch:26 step:24960 [D loss: 0.543863, acc.: 71.88%] [G loss: 0.702416]\n",
      "epoch:26 step:24961 [D loss: 0.515987, acc.: 70.31%] [G loss: 0.676123]\n",
      "epoch:26 step:24962 [D loss: 0.597639, acc.: 66.41%] [G loss: 0.658566]\n",
      "epoch:26 step:24963 [D loss: 0.496630, acc.: 71.88%] [G loss: 0.632875]\n",
      "epoch:26 step:24964 [D loss: 0.533724, acc.: 73.44%] [G loss: 0.722997]\n",
      "epoch:26 step:24965 [D loss: 0.475687, acc.: 75.78%] [G loss: 0.860265]\n",
      "epoch:26 step:24966 [D loss: 0.548398, acc.: 68.75%] [G loss: 0.723657]\n",
      "epoch:26 step:24967 [D loss: 0.426520, acc.: 82.03%] [G loss: 0.810031]\n",
      "epoch:26 step:24968 [D loss: 0.596005, acc.: 67.97%] [G loss: 0.753088]\n",
      "epoch:26 step:24969 [D loss: 0.517908, acc.: 71.09%] [G loss: 0.754464]\n",
      "epoch:26 step:24970 [D loss: 0.543083, acc.: 67.19%] [G loss: 0.559111]\n",
      "epoch:26 step:24971 [D loss: 0.616772, acc.: 59.38%] [G loss: 0.531842]\n",
      "epoch:26 step:24972 [D loss: 0.517043, acc.: 71.09%] [G loss: 0.584128]\n",
      "epoch:26 step:24973 [D loss: 0.472661, acc.: 72.66%] [G loss: 0.716023]\n",
      "epoch:26 step:24974 [D loss: 0.540249, acc.: 67.19%] [G loss: 0.596563]\n",
      "epoch:26 step:24975 [D loss: 0.472722, acc.: 73.44%] [G loss: 0.637550]\n",
      "epoch:26 step:24976 [D loss: 0.582068, acc.: 66.41%] [G loss: 0.563909]\n",
      "epoch:26 step:24977 [D loss: 0.653444, acc.: 62.50%] [G loss: 0.677301]\n",
      "epoch:26 step:24978 [D loss: 0.564977, acc.: 70.31%] [G loss: 0.623935]\n",
      "epoch:26 step:24979 [D loss: 0.562156, acc.: 73.44%] [G loss: 0.622857]\n",
      "epoch:26 step:24980 [D loss: 0.560637, acc.: 67.97%] [G loss: 0.743797]\n",
      "epoch:26 step:24981 [D loss: 0.537298, acc.: 64.84%] [G loss: 0.746359]\n",
      "epoch:26 step:24982 [D loss: 0.567337, acc.: 65.62%] [G loss: 0.639012]\n",
      "epoch:26 step:24983 [D loss: 0.495616, acc.: 76.56%] [G loss: 0.820168]\n",
      "epoch:26 step:24984 [D loss: 0.562742, acc.: 70.31%] [G loss: 0.739986]\n",
      "epoch:26 step:24985 [D loss: 0.514496, acc.: 78.91%] [G loss: 0.738817]\n",
      "epoch:26 step:24986 [D loss: 0.476411, acc.: 75.78%] [G loss: 0.910024]\n",
      "epoch:26 step:24987 [D loss: 0.565028, acc.: 68.75%] [G loss: 0.662712]\n",
      "epoch:26 step:24988 [D loss: 0.531383, acc.: 73.44%] [G loss: 0.723433]\n",
      "epoch:26 step:24989 [D loss: 0.541721, acc.: 67.19%] [G loss: 0.591550]\n",
      "epoch:26 step:24990 [D loss: 0.549230, acc.: 75.78%] [G loss: 0.755211]\n",
      "epoch:26 step:24991 [D loss: 0.505064, acc.: 69.53%] [G loss: 0.705901]\n",
      "epoch:26 step:24992 [D loss: 0.593573, acc.: 67.97%] [G loss: 0.638968]\n",
      "epoch:26 step:24993 [D loss: 0.488129, acc.: 77.34%] [G loss: 0.675859]\n",
      "epoch:26 step:24994 [D loss: 0.487508, acc.: 77.34%] [G loss: 0.745593]\n",
      "epoch:26 step:24995 [D loss: 0.514815, acc.: 73.44%] [G loss: 0.730201]\n",
      "epoch:26 step:24996 [D loss: 0.504632, acc.: 75.78%] [G loss: 0.779745]\n",
      "epoch:26 step:24997 [D loss: 0.463879, acc.: 75.00%] [G loss: 0.915331]\n",
      "epoch:26 step:24998 [D loss: 0.582774, acc.: 66.41%] [G loss: 0.739695]\n",
      "epoch:26 step:24999 [D loss: 0.546245, acc.: 67.97%] [G loss: 0.683566]\n",
      "epoch:26 step:25000 [D loss: 0.501441, acc.: 74.22%] [G loss: 0.773638]\n",
      "##############\n",
      "[2.89476093 0.76757799 6.06120708 5.02965732 3.77087173 5.58476883\n",
      " 4.5225744  4.86413359 4.78570488 4.23030795]\n",
      "##########\n",
      "epoch:26 step:25001 [D loss: 0.502310, acc.: 72.66%] [G loss: 0.714638]\n",
      "epoch:26 step:25002 [D loss: 0.620267, acc.: 61.72%] [G loss: 0.751743]\n",
      "epoch:26 step:25003 [D loss: 0.513186, acc.: 72.66%] [G loss: 0.981674]\n",
      "epoch:26 step:25004 [D loss: 0.479126, acc.: 78.12%] [G loss: 1.025996]\n",
      "epoch:26 step:25005 [D loss: 0.510676, acc.: 71.88%] [G loss: 0.939657]\n",
      "epoch:26 step:25006 [D loss: 0.554467, acc.: 70.31%] [G loss: 0.720379]\n",
      "epoch:26 step:25007 [D loss: 0.578977, acc.: 68.75%] [G loss: 0.841143]\n",
      "epoch:26 step:25008 [D loss: 0.539965, acc.: 71.09%] [G loss: 0.675975]\n",
      "epoch:26 step:25009 [D loss: 0.473830, acc.: 75.78%] [G loss: 1.050421]\n",
      "epoch:26 step:25010 [D loss: 0.382575, acc.: 84.38%] [G loss: 1.062847]\n",
      "epoch:26 step:25011 [D loss: 0.522524, acc.: 72.66%] [G loss: 0.840071]\n",
      "epoch:26 step:25012 [D loss: 0.529073, acc.: 71.88%] [G loss: 0.836803]\n",
      "epoch:26 step:25013 [D loss: 0.557926, acc.: 70.31%] [G loss: 1.005369]\n",
      "epoch:26 step:25014 [D loss: 0.598913, acc.: 65.62%] [G loss: 0.714368]\n",
      "epoch:26 step:25015 [D loss: 0.531205, acc.: 70.31%] [G loss: 0.622448]\n",
      "epoch:26 step:25016 [D loss: 0.515125, acc.: 71.09%] [G loss: 0.827790]\n",
      "epoch:26 step:25017 [D loss: 0.574793, acc.: 67.97%] [G loss: 0.647894]\n",
      "epoch:26 step:25018 [D loss: 0.551462, acc.: 73.44%] [G loss: 0.643715]\n",
      "epoch:26 step:25019 [D loss: 0.517249, acc.: 71.09%] [G loss: 0.760270]\n",
      "epoch:26 step:25020 [D loss: 0.574601, acc.: 71.09%] [G loss: 0.759279]\n",
      "epoch:26 step:25021 [D loss: 0.516169, acc.: 75.00%] [G loss: 0.865598]\n",
      "epoch:26 step:25022 [D loss: 0.532136, acc.: 74.22%] [G loss: 0.683113]\n",
      "epoch:26 step:25023 [D loss: 0.461552, acc.: 78.91%] [G loss: 0.810260]\n",
      "epoch:26 step:25024 [D loss: 0.457413, acc.: 78.91%] [G loss: 0.806348]\n",
      "epoch:26 step:25025 [D loss: 0.548950, acc.: 68.75%] [G loss: 0.757899]\n",
      "epoch:26 step:25026 [D loss: 0.566668, acc.: 65.62%] [G loss: 0.790047]\n",
      "epoch:26 step:25027 [D loss: 0.557880, acc.: 70.31%] [G loss: 0.761339]\n",
      "epoch:26 step:25028 [D loss: 0.531196, acc.: 73.44%] [G loss: 0.675162]\n",
      "epoch:26 step:25029 [D loss: 0.506622, acc.: 75.78%] [G loss: 0.860803]\n",
      "epoch:26 step:25030 [D loss: 0.561829, acc.: 70.31%] [G loss: 0.682078]\n",
      "epoch:26 step:25031 [D loss: 0.525839, acc.: 70.31%] [G loss: 0.686758]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:26 step:25032 [D loss: 0.531401, acc.: 71.09%] [G loss: 0.704471]\n",
      "epoch:26 step:25033 [D loss: 0.605561, acc.: 70.31%] [G loss: 0.579261]\n",
      "epoch:26 step:25034 [D loss: 0.517993, acc.: 74.22%] [G loss: 0.731543]\n",
      "epoch:26 step:25035 [D loss: 0.593942, acc.: 60.16%] [G loss: 0.633174]\n",
      "epoch:26 step:25036 [D loss: 0.539171, acc.: 70.31%] [G loss: 0.866962]\n",
      "epoch:26 step:25037 [D loss: 0.585492, acc.: 64.84%] [G loss: 0.646446]\n",
      "epoch:26 step:25038 [D loss: 0.553290, acc.: 67.19%] [G loss: 0.839067]\n",
      "epoch:26 step:25039 [D loss: 0.510618, acc.: 73.44%] [G loss: 0.727925]\n",
      "epoch:26 step:25040 [D loss: 0.590743, acc.: 70.31%] [G loss: 0.709611]\n",
      "epoch:26 step:25041 [D loss: 0.472749, acc.: 75.00%] [G loss: 0.725465]\n",
      "epoch:26 step:25042 [D loss: 0.480995, acc.: 79.69%] [G loss: 0.707568]\n",
      "epoch:26 step:25043 [D loss: 0.446262, acc.: 79.69%] [G loss: 0.717246]\n",
      "epoch:26 step:25044 [D loss: 0.512941, acc.: 71.09%] [G loss: 0.619730]\n",
      "epoch:26 step:25045 [D loss: 0.551949, acc.: 67.97%] [G loss: 0.766545]\n",
      "epoch:26 step:25046 [D loss: 0.618038, acc.: 64.84%] [G loss: 0.539444]\n",
      "epoch:26 step:25047 [D loss: 0.519937, acc.: 71.09%] [G loss: 0.609701]\n",
      "epoch:26 step:25048 [D loss: 0.617069, acc.: 64.84%] [G loss: 0.595407]\n",
      "epoch:26 step:25049 [D loss: 0.527973, acc.: 71.09%] [G loss: 0.777869]\n",
      "epoch:26 step:25050 [D loss: 0.565567, acc.: 70.31%] [G loss: 0.766115]\n",
      "epoch:26 step:25051 [D loss: 0.533254, acc.: 71.09%] [G loss: 0.640273]\n",
      "epoch:26 step:25052 [D loss: 0.479599, acc.: 74.22%] [G loss: 0.664753]\n",
      "epoch:26 step:25053 [D loss: 0.499502, acc.: 75.00%] [G loss: 0.720641]\n",
      "epoch:26 step:25054 [D loss: 0.516412, acc.: 71.88%] [G loss: 0.707680]\n",
      "epoch:26 step:25055 [D loss: 0.451541, acc.: 79.69%] [G loss: 0.748840]\n",
      "epoch:26 step:25056 [D loss: 0.423808, acc.: 81.25%] [G loss: 0.759297]\n",
      "epoch:26 step:25057 [D loss: 0.484154, acc.: 74.22%] [G loss: 0.724446]\n",
      "epoch:26 step:25058 [D loss: 0.632732, acc.: 61.72%] [G loss: 0.608033]\n",
      "epoch:26 step:25059 [D loss: 0.581507, acc.: 66.41%] [G loss: 0.638731]\n",
      "epoch:26 step:25060 [D loss: 0.572043, acc.: 66.41%] [G loss: 0.534608]\n",
      "epoch:26 step:25061 [D loss: 0.523268, acc.: 71.09%] [G loss: 0.591944]\n",
      "epoch:26 step:25062 [D loss: 0.513465, acc.: 73.44%] [G loss: 0.897699]\n",
      "epoch:26 step:25063 [D loss: 0.565905, acc.: 72.66%] [G loss: 0.843737]\n",
      "epoch:26 step:25064 [D loss: 0.556628, acc.: 68.75%] [G loss: 0.728270]\n",
      "epoch:26 step:25065 [D loss: 0.591898, acc.: 64.84%] [G loss: 0.753911]\n",
      "epoch:26 step:25066 [D loss: 0.599928, acc.: 64.06%] [G loss: 0.554874]\n",
      "epoch:26 step:25067 [D loss: 0.504059, acc.: 74.22%] [G loss: 0.613525]\n",
      "epoch:26 step:25068 [D loss: 0.515175, acc.: 74.22%] [G loss: 0.545559]\n",
      "epoch:26 step:25069 [D loss: 0.531085, acc.: 70.31%] [G loss: 0.689633]\n",
      "epoch:26 step:25070 [D loss: 0.495249, acc.: 74.22%] [G loss: 0.733144]\n",
      "epoch:26 step:25071 [D loss: 0.530813, acc.: 70.31%] [G loss: 0.754050]\n",
      "epoch:26 step:25072 [D loss: 0.544155, acc.: 70.31%] [G loss: 0.761156]\n",
      "epoch:26 step:25073 [D loss: 0.505055, acc.: 72.66%] [G loss: 0.635813]\n",
      "epoch:26 step:25074 [D loss: 0.550047, acc.: 69.53%] [G loss: 0.697168]\n",
      "epoch:26 step:25075 [D loss: 0.571395, acc.: 67.97%] [G loss: 0.611843]\n",
      "epoch:26 step:25076 [D loss: 0.509334, acc.: 72.66%] [G loss: 0.680376]\n",
      "epoch:26 step:25077 [D loss: 0.521241, acc.: 75.78%] [G loss: 0.657439]\n",
      "epoch:26 step:25078 [D loss: 0.596121, acc.: 62.50%] [G loss: 0.568962]\n",
      "epoch:26 step:25079 [D loss: 0.586702, acc.: 67.19%] [G loss: 0.547715]\n",
      "epoch:26 step:25080 [D loss: 0.534178, acc.: 71.09%] [G loss: 0.729557]\n",
      "epoch:26 step:25081 [D loss: 0.531540, acc.: 71.88%] [G loss: 0.596045]\n",
      "epoch:26 step:25082 [D loss: 0.545544, acc.: 74.22%] [G loss: 0.723124]\n",
      "epoch:26 step:25083 [D loss: 0.544952, acc.: 67.97%] [G loss: 0.721351]\n",
      "epoch:26 step:25084 [D loss: 0.537854, acc.: 77.34%] [G loss: 0.572342]\n",
      "epoch:26 step:25085 [D loss: 0.571911, acc.: 70.31%] [G loss: 0.580136]\n",
      "epoch:26 step:25086 [D loss: 0.483834, acc.: 75.00%] [G loss: 0.706737]\n",
      "epoch:26 step:25087 [D loss: 0.503046, acc.: 78.12%] [G loss: 0.731464]\n",
      "epoch:26 step:25088 [D loss: 0.484513, acc.: 75.78%] [G loss: 0.762613]\n",
      "epoch:26 step:25089 [D loss: 0.535588, acc.: 72.66%] [G loss: 0.710540]\n",
      "epoch:26 step:25090 [D loss: 0.490721, acc.: 74.22%] [G loss: 0.727846]\n",
      "epoch:26 step:25091 [D loss: 0.552147, acc.: 69.53%] [G loss: 0.591949]\n",
      "epoch:26 step:25092 [D loss: 0.544557, acc.: 72.66%] [G loss: 0.470771]\n",
      "epoch:26 step:25093 [D loss: 0.560649, acc.: 67.19%] [G loss: 0.781741]\n",
      "epoch:26 step:25094 [D loss: 0.533536, acc.: 73.44%] [G loss: 0.707838]\n",
      "epoch:26 step:25095 [D loss: 0.543258, acc.: 72.66%] [G loss: 0.655438]\n",
      "epoch:26 step:25096 [D loss: 0.531245, acc.: 74.22%] [G loss: 0.711567]\n",
      "epoch:26 step:25097 [D loss: 0.549733, acc.: 64.84%] [G loss: 0.605181]\n",
      "epoch:26 step:25098 [D loss: 0.540209, acc.: 69.53%] [G loss: 0.604748]\n",
      "epoch:26 step:25099 [D loss: 0.515236, acc.: 71.88%] [G loss: 0.785475]\n",
      "epoch:26 step:25100 [D loss: 0.574488, acc.: 64.84%] [G loss: 0.597508]\n",
      "epoch:26 step:25101 [D loss: 0.609452, acc.: 69.53%] [G loss: 0.657601]\n",
      "epoch:26 step:25102 [D loss: 0.611350, acc.: 64.84%] [G loss: 0.657202]\n",
      "epoch:26 step:25103 [D loss: 0.547481, acc.: 71.09%] [G loss: 0.506165]\n",
      "epoch:26 step:25104 [D loss: 0.549542, acc.: 69.53%] [G loss: 0.747316]\n",
      "epoch:26 step:25105 [D loss: 0.546648, acc.: 70.31%] [G loss: 0.659399]\n",
      "epoch:26 step:25106 [D loss: 0.561096, acc.: 72.66%] [G loss: 0.759701]\n",
      "epoch:26 step:25107 [D loss: 0.584223, acc.: 64.06%] [G loss: 0.658339]\n",
      "epoch:26 step:25108 [D loss: 0.398188, acc.: 78.91%] [G loss: 0.807887]\n",
      "epoch:26 step:25109 [D loss: 0.456570, acc.: 75.00%] [G loss: 0.687055]\n",
      "epoch:26 step:25110 [D loss: 0.536795, acc.: 70.31%] [G loss: 0.709192]\n",
      "epoch:26 step:25111 [D loss: 0.467915, acc.: 79.69%] [G loss: 0.690447]\n",
      "epoch:26 step:25112 [D loss: 0.471982, acc.: 76.56%] [G loss: 0.701108]\n",
      "epoch:26 step:25113 [D loss: 0.485330, acc.: 75.00%] [G loss: 0.752436]\n",
      "epoch:26 step:25114 [D loss: 0.639423, acc.: 64.84%] [G loss: 0.549072]\n",
      "epoch:26 step:25115 [D loss: 0.518293, acc.: 72.66%] [G loss: 0.806169]\n",
      "epoch:26 step:25116 [D loss: 0.540043, acc.: 69.53%] [G loss: 0.654710]\n",
      "epoch:26 step:25117 [D loss: 0.542656, acc.: 71.88%] [G loss: 0.771334]\n",
      "epoch:26 step:25118 [D loss: 0.569250, acc.: 69.53%] [G loss: 0.813628]\n",
      "epoch:26 step:25119 [D loss: 0.575119, acc.: 69.53%] [G loss: 0.601962]\n",
      "epoch:26 step:25120 [D loss: 0.573238, acc.: 71.09%] [G loss: 0.699683]\n",
      "epoch:26 step:25121 [D loss: 0.540138, acc.: 72.66%] [G loss: 0.729008]\n",
      "epoch:26 step:25122 [D loss: 0.503858, acc.: 72.66%] [G loss: 0.800460]\n",
      "epoch:26 step:25123 [D loss: 0.520230, acc.: 70.31%] [G loss: 0.733337]\n",
      "epoch:26 step:25124 [D loss: 0.567778, acc.: 71.09%] [G loss: 0.734810]\n",
      "epoch:26 step:25125 [D loss: 0.537108, acc.: 71.88%] [G loss: 0.694664]\n",
      "epoch:26 step:25126 [D loss: 0.558253, acc.: 67.19%] [G loss: 0.639671]\n",
      "epoch:26 step:25127 [D loss: 0.559542, acc.: 70.31%] [G loss: 0.618323]\n",
      "epoch:26 step:25128 [D loss: 0.586406, acc.: 62.50%] [G loss: 0.534223]\n",
      "epoch:26 step:25129 [D loss: 0.499181, acc.: 77.34%] [G loss: 0.533133]\n",
      "epoch:26 step:25130 [D loss: 0.480644, acc.: 73.44%] [G loss: 0.767528]\n",
      "epoch:26 step:25131 [D loss: 0.485053, acc.: 77.34%] [G loss: 0.896954]\n",
      "epoch:26 step:25132 [D loss: 0.498448, acc.: 75.78%] [G loss: 0.818481]\n",
      "epoch:26 step:25133 [D loss: 0.504487, acc.: 78.12%] [G loss: 0.758947]\n",
      "epoch:26 step:25134 [D loss: 0.569011, acc.: 68.75%] [G loss: 0.752497]\n",
      "epoch:26 step:25135 [D loss: 0.566709, acc.: 67.19%] [G loss: 0.736726]\n",
      "epoch:26 step:25136 [D loss: 0.607539, acc.: 71.09%] [G loss: 0.697550]\n",
      "epoch:26 step:25137 [D loss: 0.499903, acc.: 71.88%] [G loss: 0.671682]\n",
      "epoch:26 step:25138 [D loss: 0.574775, acc.: 71.88%] [G loss: 0.740288]\n",
      "epoch:26 step:25139 [D loss: 0.531990, acc.: 72.66%] [G loss: 0.616963]\n",
      "epoch:26 step:25140 [D loss: 0.591833, acc.: 67.97%] [G loss: 0.770856]\n",
      "epoch:26 step:25141 [D loss: 0.516095, acc.: 74.22%] [G loss: 0.914808]\n",
      "epoch:26 step:25142 [D loss: 0.514773, acc.: 70.31%] [G loss: 1.001076]\n",
      "epoch:26 step:25143 [D loss: 0.480748, acc.: 76.56%] [G loss: 0.870591]\n",
      "epoch:26 step:25144 [D loss: 0.567515, acc.: 64.84%] [G loss: 0.903965]\n",
      "epoch:26 step:25145 [D loss: 0.513444, acc.: 74.22%] [G loss: 0.833920]\n",
      "epoch:26 step:25146 [D loss: 0.593366, acc.: 62.50%] [G loss: 0.650626]\n",
      "epoch:26 step:25147 [D loss: 0.531017, acc.: 73.44%] [G loss: 0.658780]\n",
      "epoch:26 step:25148 [D loss: 0.554961, acc.: 67.19%] [G loss: 0.663392]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:26 step:25149 [D loss: 0.599226, acc.: 70.31%] [G loss: 0.760103]\n",
      "epoch:26 step:25150 [D loss: 0.639544, acc.: 62.50%] [G loss: 0.609025]\n",
      "epoch:26 step:25151 [D loss: 0.507218, acc.: 75.78%] [G loss: 0.687678]\n",
      "epoch:26 step:25152 [D loss: 0.529298, acc.: 70.31%] [G loss: 0.740773]\n",
      "epoch:26 step:25153 [D loss: 0.551031, acc.: 71.88%] [G loss: 0.675070]\n",
      "epoch:26 step:25154 [D loss: 0.456881, acc.: 76.56%] [G loss: 0.850581]\n",
      "epoch:26 step:25155 [D loss: 0.606366, acc.: 67.97%] [G loss: 0.654256]\n",
      "epoch:26 step:25156 [D loss: 0.657991, acc.: 62.50%] [G loss: 0.754069]\n",
      "epoch:26 step:25157 [D loss: 0.557461, acc.: 68.75%] [G loss: 0.815506]\n",
      "epoch:26 step:25158 [D loss: 0.540489, acc.: 70.31%] [G loss: 0.715945]\n",
      "epoch:26 step:25159 [D loss: 0.557956, acc.: 67.97%] [G loss: 0.795596]\n",
      "epoch:26 step:25160 [D loss: 0.539356, acc.: 70.31%] [G loss: 0.705055]\n",
      "epoch:26 step:25161 [D loss: 0.566994, acc.: 69.53%] [G loss: 0.620009]\n",
      "epoch:26 step:25162 [D loss: 0.553718, acc.: 73.44%] [G loss: 0.700304]\n",
      "epoch:26 step:25163 [D loss: 0.524762, acc.: 75.00%] [G loss: 0.679331]\n",
      "epoch:26 step:25164 [D loss: 0.461141, acc.: 78.91%] [G loss: 0.963234]\n",
      "epoch:26 step:25165 [D loss: 0.520791, acc.: 76.56%] [G loss: 0.995358]\n",
      "epoch:26 step:25166 [D loss: 0.560269, acc.: 73.44%] [G loss: 0.756420]\n",
      "epoch:26 step:25167 [D loss: 0.548486, acc.: 67.19%] [G loss: 0.614016]\n",
      "epoch:26 step:25168 [D loss: 0.579866, acc.: 64.84%] [G loss: 0.648396]\n",
      "epoch:26 step:25169 [D loss: 0.517083, acc.: 71.88%] [G loss: 0.692313]\n",
      "epoch:26 step:25170 [D loss: 0.554065, acc.: 66.41%] [G loss: 0.743794]\n",
      "epoch:26 step:25171 [D loss: 0.496434, acc.: 75.00%] [G loss: 0.731237]\n",
      "epoch:26 step:25172 [D loss: 0.512923, acc.: 70.31%] [G loss: 0.724741]\n",
      "epoch:26 step:25173 [D loss: 0.549275, acc.: 72.66%] [G loss: 0.667232]\n",
      "epoch:26 step:25174 [D loss: 0.571266, acc.: 67.19%] [G loss: 0.636468]\n",
      "epoch:26 step:25175 [D loss: 0.541001, acc.: 70.31%] [G loss: 0.525889]\n",
      "epoch:26 step:25176 [D loss: 0.554771, acc.: 71.09%] [G loss: 0.625995]\n",
      "epoch:26 step:25177 [D loss: 0.520746, acc.: 74.22%] [G loss: 0.742410]\n",
      "epoch:26 step:25178 [D loss: 0.532431, acc.: 71.88%] [G loss: 0.830128]\n",
      "epoch:26 step:25179 [D loss: 0.642328, acc.: 66.41%] [G loss: 0.689353]\n",
      "epoch:26 step:25180 [D loss: 0.526332, acc.: 72.66%] [G loss: 0.701549]\n",
      "epoch:26 step:25181 [D loss: 0.507125, acc.: 74.22%] [G loss: 0.572935]\n",
      "epoch:26 step:25182 [D loss: 0.643299, acc.: 60.94%] [G loss: 0.610817]\n",
      "epoch:26 step:25183 [D loss: 0.549394, acc.: 69.53%] [G loss: 0.569997]\n",
      "epoch:26 step:25184 [D loss: 0.521905, acc.: 72.66%] [G loss: 0.578947]\n",
      "epoch:26 step:25185 [D loss: 0.386499, acc.: 82.81%] [G loss: 0.937172]\n",
      "epoch:26 step:25186 [D loss: 0.567323, acc.: 65.62%] [G loss: 0.668388]\n",
      "epoch:26 step:25187 [D loss: 0.510372, acc.: 72.66%] [G loss: 0.566661]\n",
      "epoch:26 step:25188 [D loss: 0.507868, acc.: 71.88%] [G loss: 0.829356]\n",
      "epoch:26 step:25189 [D loss: 0.495841, acc.: 74.22%] [G loss: 0.751665]\n",
      "epoch:26 step:25190 [D loss: 0.603094, acc.: 67.97%] [G loss: 0.812229]\n",
      "epoch:26 step:25191 [D loss: 0.538044, acc.: 75.78%] [G loss: 0.631794]\n",
      "epoch:26 step:25192 [D loss: 0.576433, acc.: 67.19%] [G loss: 0.614689]\n",
      "epoch:26 step:25193 [D loss: 0.508386, acc.: 74.22%] [G loss: 0.844709]\n",
      "epoch:26 step:25194 [D loss: 0.498016, acc.: 71.09%] [G loss: 0.785309]\n",
      "epoch:26 step:25195 [D loss: 0.535908, acc.: 71.88%] [G loss: 0.675247]\n",
      "epoch:26 step:25196 [D loss: 0.533723, acc.: 68.75%] [G loss: 0.574951]\n",
      "epoch:26 step:25197 [D loss: 0.536013, acc.: 69.53%] [G loss: 0.557115]\n",
      "epoch:26 step:25198 [D loss: 0.561966, acc.: 67.19%] [G loss: 0.711155]\n",
      "epoch:26 step:25199 [D loss: 0.520155, acc.: 70.31%] [G loss: 0.668279]\n",
      "epoch:26 step:25200 [D loss: 0.511947, acc.: 72.66%] [G loss: 0.657123]\n",
      "##############\n",
      "[2.95751837 0.98763458 6.16941828 4.985484   3.92658253 5.67259005\n",
      " 4.62773694 4.95700709 4.74012961 4.19489619]\n",
      "##########\n",
      "epoch:26 step:25201 [D loss: 0.500570, acc.: 74.22%] [G loss: 0.732153]\n",
      "epoch:26 step:25202 [D loss: 0.537780, acc.: 70.31%] [G loss: 0.692857]\n",
      "epoch:26 step:25203 [D loss: 0.530243, acc.: 69.53%] [G loss: 0.631999]\n",
      "epoch:26 step:25204 [D loss: 0.500201, acc.: 74.22%] [G loss: 0.780345]\n",
      "epoch:26 step:25205 [D loss: 0.540292, acc.: 75.00%] [G loss: 0.541199]\n",
      "epoch:26 step:25206 [D loss: 0.531609, acc.: 73.44%] [G loss: 0.749101]\n",
      "epoch:26 step:25207 [D loss: 0.588908, acc.: 70.31%] [G loss: 0.687721]\n",
      "epoch:26 step:25208 [D loss: 0.555924, acc.: 67.97%] [G loss: 0.593310]\n",
      "epoch:26 step:25209 [D loss: 0.653005, acc.: 61.72%] [G loss: 0.523133]\n",
      "epoch:26 step:25210 [D loss: 0.510926, acc.: 71.09%] [G loss: 0.510793]\n",
      "epoch:26 step:25211 [D loss: 0.538385, acc.: 71.09%] [G loss: 0.641629]\n",
      "epoch:26 step:25212 [D loss: 0.519074, acc.: 72.66%] [G loss: 0.664540]\n",
      "epoch:26 step:25213 [D loss: 0.599614, acc.: 60.16%] [G loss: 0.662357]\n",
      "epoch:26 step:25214 [D loss: 0.550319, acc.: 70.31%] [G loss: 0.672435]\n",
      "epoch:26 step:25215 [D loss: 0.530540, acc.: 72.66%] [G loss: 0.736225]\n",
      "epoch:26 step:25216 [D loss: 0.528977, acc.: 67.97%] [G loss: 0.596421]\n",
      "epoch:26 step:25217 [D loss: 0.536312, acc.: 69.53%] [G loss: 0.776934]\n",
      "epoch:26 step:25218 [D loss: 0.568751, acc.: 71.09%] [G loss: 0.708073]\n",
      "epoch:26 step:25219 [D loss: 0.508972, acc.: 71.09%] [G loss: 0.625843]\n",
      "epoch:26 step:25220 [D loss: 0.512149, acc.: 71.09%] [G loss: 0.690396]\n",
      "epoch:26 step:25221 [D loss: 0.601207, acc.: 64.84%] [G loss: 0.519142]\n",
      "epoch:26 step:25222 [D loss: 0.474103, acc.: 78.12%] [G loss: 0.767273]\n",
      "epoch:26 step:25223 [D loss: 0.588110, acc.: 68.75%] [G loss: 0.680562]\n",
      "epoch:26 step:25224 [D loss: 0.525200, acc.: 71.88%] [G loss: 0.619018]\n",
      "epoch:26 step:25225 [D loss: 0.564050, acc.: 70.31%] [G loss: 0.629789]\n",
      "epoch:26 step:25226 [D loss: 0.543265, acc.: 65.62%] [G loss: 0.571207]\n",
      "epoch:26 step:25227 [D loss: 0.574239, acc.: 67.19%] [G loss: 0.501042]\n",
      "epoch:26 step:25228 [D loss: 0.564522, acc.: 67.19%] [G loss: 0.591095]\n",
      "epoch:26 step:25229 [D loss: 0.644836, acc.: 59.38%] [G loss: 0.486803]\n",
      "epoch:26 step:25230 [D loss: 0.497328, acc.: 77.34%] [G loss: 0.591840]\n",
      "epoch:26 step:25231 [D loss: 0.598916, acc.: 64.06%] [G loss: 0.627661]\n",
      "epoch:26 step:25232 [D loss: 0.452035, acc.: 78.12%] [G loss: 0.791749]\n",
      "epoch:26 step:25233 [D loss: 0.437838, acc.: 81.25%] [G loss: 0.738251]\n",
      "epoch:26 step:25234 [D loss: 0.554811, acc.: 73.44%] [G loss: 0.746960]\n",
      "epoch:26 step:25235 [D loss: 0.563126, acc.: 67.97%] [G loss: 0.553459]\n",
      "epoch:26 step:25236 [D loss: 0.536624, acc.: 67.19%] [G loss: 0.646864]\n",
      "epoch:26 step:25237 [D loss: 0.500293, acc.: 73.44%] [G loss: 0.590919]\n",
      "epoch:26 step:25238 [D loss: 0.512828, acc.: 75.78%] [G loss: 0.675388]\n",
      "epoch:26 step:25239 [D loss: 0.595168, acc.: 65.62%] [G loss: 0.524078]\n",
      "epoch:26 step:25240 [D loss: 0.551848, acc.: 67.19%] [G loss: 0.522065]\n",
      "epoch:26 step:25241 [D loss: 0.578697, acc.: 63.28%] [G loss: 0.726884]\n",
      "epoch:26 step:25242 [D loss: 0.657828, acc.: 63.28%] [G loss: 0.484393]\n",
      "epoch:26 step:25243 [D loss: 0.561713, acc.: 67.19%] [G loss: 0.491431]\n",
      "epoch:26 step:25244 [D loss: 0.567639, acc.: 69.53%] [G loss: 0.553681]\n",
      "epoch:26 step:25245 [D loss: 0.589319, acc.: 64.06%] [G loss: 0.582963]\n",
      "epoch:26 step:25246 [D loss: 0.481320, acc.: 71.88%] [G loss: 0.758621]\n",
      "epoch:26 step:25247 [D loss: 0.511769, acc.: 71.09%] [G loss: 1.035839]\n",
      "epoch:26 step:25248 [D loss: 0.462955, acc.: 82.03%] [G loss: 0.867254]\n",
      "epoch:26 step:25249 [D loss: 0.515890, acc.: 74.22%] [G loss: 1.003966]\n",
      "epoch:26 step:25250 [D loss: 0.596915, acc.: 63.28%] [G loss: 0.861136]\n",
      "epoch:26 step:25251 [D loss: 0.525913, acc.: 71.09%] [G loss: 0.768326]\n",
      "epoch:26 step:25252 [D loss: 0.461515, acc.: 79.69%] [G loss: 0.849551]\n",
      "epoch:26 step:25253 [D loss: 0.695647, acc.: 57.81%] [G loss: 0.823288]\n",
      "epoch:26 step:25254 [D loss: 0.643865, acc.: 63.28%] [G loss: 0.631350]\n",
      "epoch:26 step:25255 [D loss: 0.552371, acc.: 71.09%] [G loss: 0.673065]\n",
      "epoch:26 step:25256 [D loss: 0.460487, acc.: 81.25%] [G loss: 0.720999]\n",
      "epoch:26 step:25257 [D loss: 0.515887, acc.: 70.31%] [G loss: 0.888349]\n",
      "epoch:26 step:25258 [D loss: 0.471953, acc.: 74.22%] [G loss: 0.899493]\n",
      "epoch:26 step:25259 [D loss: 0.510889, acc.: 71.88%] [G loss: 0.931691]\n",
      "epoch:26 step:25260 [D loss: 0.439496, acc.: 79.69%] [G loss: 1.097728]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:26 step:25261 [D loss: 0.501263, acc.: 78.91%] [G loss: 0.913441]\n",
      "epoch:26 step:25262 [D loss: 0.485928, acc.: 75.78%] [G loss: 0.977050]\n",
      "epoch:26 step:25263 [D loss: 0.514401, acc.: 72.66%] [G loss: 0.809298]\n",
      "epoch:26 step:25264 [D loss: 0.576905, acc.: 65.62%] [G loss: 0.817112]\n",
      "epoch:26 step:25265 [D loss: 0.570648, acc.: 72.66%] [G loss: 0.659287]\n",
      "epoch:26 step:25266 [D loss: 0.562112, acc.: 72.66%] [G loss: 0.722673]\n",
      "epoch:26 step:25267 [D loss: 0.565793, acc.: 73.44%] [G loss: 0.680316]\n",
      "epoch:26 step:25268 [D loss: 0.488893, acc.: 78.12%] [G loss: 0.841829]\n",
      "epoch:26 step:25269 [D loss: 0.537563, acc.: 73.44%] [G loss: 0.651163]\n",
      "epoch:26 step:25270 [D loss: 0.573597, acc.: 67.19%] [G loss: 0.719242]\n",
      "epoch:26 step:25271 [D loss: 0.500169, acc.: 75.00%] [G loss: 0.795981]\n",
      "epoch:26 step:25272 [D loss: 0.553678, acc.: 66.41%] [G loss: 0.692301]\n",
      "epoch:26 step:25273 [D loss: 0.520761, acc.: 72.66%] [G loss: 0.779968]\n",
      "epoch:26 step:25274 [D loss: 0.477995, acc.: 77.34%] [G loss: 0.700534]\n",
      "epoch:26 step:25275 [D loss: 0.547269, acc.: 71.88%] [G loss: 0.993089]\n",
      "epoch:26 step:25276 [D loss: 0.512700, acc.: 72.66%] [G loss: 0.866451]\n",
      "epoch:26 step:25277 [D loss: 0.629035, acc.: 63.28%] [G loss: 0.778036]\n",
      "epoch:26 step:25278 [D loss: 0.490595, acc.: 75.78%] [G loss: 0.838210]\n",
      "epoch:26 step:25279 [D loss: 0.591837, acc.: 63.28%] [G loss: 0.686967]\n",
      "epoch:26 step:25280 [D loss: 0.503939, acc.: 77.34%] [G loss: 0.829763]\n",
      "epoch:26 step:25281 [D loss: 0.410871, acc.: 82.81%] [G loss: 1.056008]\n",
      "epoch:26 step:25282 [D loss: 0.692609, acc.: 61.72%] [G loss: 0.654908]\n",
      "epoch:26 step:25283 [D loss: 0.566954, acc.: 65.62%] [G loss: 0.714676]\n",
      "epoch:26 step:25284 [D loss: 0.549139, acc.: 67.97%] [G loss: 0.645482]\n",
      "epoch:26 step:25285 [D loss: 0.424968, acc.: 78.91%] [G loss: 0.862149]\n",
      "epoch:26 step:25286 [D loss: 0.515462, acc.: 75.00%] [G loss: 0.978692]\n",
      "epoch:26 step:25287 [D loss: 0.454069, acc.: 77.34%] [G loss: 1.069921]\n",
      "epoch:26 step:25288 [D loss: 0.429342, acc.: 78.12%] [G loss: 1.274381]\n",
      "epoch:26 step:25289 [D loss: 0.491170, acc.: 73.44%] [G loss: 1.317863]\n",
      "epoch:26 step:25290 [D loss: 0.649141, acc.: 68.75%] [G loss: 1.076958]\n",
      "epoch:26 step:25291 [D loss: 0.543549, acc.: 71.88%] [G loss: 1.271167]\n",
      "epoch:26 step:25292 [D loss: 0.416935, acc.: 80.47%] [G loss: 1.339115]\n",
      "epoch:26 step:25293 [D loss: 0.529559, acc.: 69.53%] [G loss: 0.878342]\n",
      "epoch:26 step:25294 [D loss: 0.637919, acc.: 60.94%] [G loss: 0.910575]\n",
      "epoch:26 step:25295 [D loss: 0.460691, acc.: 76.56%] [G loss: 1.086684]\n",
      "epoch:26 step:25296 [D loss: 0.628350, acc.: 66.41%] [G loss: 0.997510]\n",
      "epoch:26 step:25297 [D loss: 0.483104, acc.: 75.00%] [G loss: 1.116871]\n",
      "epoch:26 step:25298 [D loss: 0.377440, acc.: 82.81%] [G loss: 1.292476]\n",
      "epoch:26 step:25299 [D loss: 0.489296, acc.: 71.88%] [G loss: 1.243550]\n",
      "epoch:27 step:25300 [D loss: 0.533518, acc.: 72.66%] [G loss: 1.172291]\n",
      "epoch:27 step:25301 [D loss: 0.494571, acc.: 73.44%] [G loss: 1.060894]\n",
      "epoch:27 step:25302 [D loss: 0.523611, acc.: 74.22%] [G loss: 1.042518]\n",
      "epoch:27 step:25303 [D loss: 0.519180, acc.: 71.09%] [G loss: 1.047668]\n",
      "epoch:27 step:25304 [D loss: 0.574258, acc.: 70.31%] [G loss: 0.909268]\n",
      "epoch:27 step:25305 [D loss: 0.566979, acc.: 69.53%] [G loss: 0.973567]\n",
      "epoch:27 step:25306 [D loss: 0.471053, acc.: 77.34%] [G loss: 0.799048]\n",
      "epoch:27 step:25307 [D loss: 0.471132, acc.: 79.69%] [G loss: 0.823196]\n",
      "epoch:27 step:25308 [D loss: 0.487049, acc.: 75.78%] [G loss: 0.822386]\n",
      "epoch:27 step:25309 [D loss: 0.504122, acc.: 74.22%] [G loss: 0.896180]\n",
      "epoch:27 step:25310 [D loss: 0.448567, acc.: 81.25%] [G loss: 0.920354]\n",
      "epoch:27 step:25311 [D loss: 0.598199, acc.: 71.88%] [G loss: 0.792230]\n",
      "epoch:27 step:25312 [D loss: 0.608147, acc.: 64.84%] [G loss: 0.673798]\n",
      "epoch:27 step:25313 [D loss: 0.499043, acc.: 74.22%] [G loss: 0.803658]\n",
      "epoch:27 step:25314 [D loss: 0.516038, acc.: 74.22%] [G loss: 0.828482]\n",
      "epoch:27 step:25315 [D loss: 0.507070, acc.: 78.91%] [G loss: 0.814710]\n",
      "epoch:27 step:25316 [D loss: 0.540816, acc.: 73.44%] [G loss: 0.967269]\n",
      "epoch:27 step:25317 [D loss: 0.540640, acc.: 73.44%] [G loss: 0.720634]\n",
      "epoch:27 step:25318 [D loss: 0.610358, acc.: 63.28%] [G loss: 0.840437]\n",
      "epoch:27 step:25319 [D loss: 0.624703, acc.: 64.84%] [G loss: 0.822759]\n",
      "epoch:27 step:25320 [D loss: 0.569430, acc.: 69.53%] [G loss: 0.781349]\n",
      "epoch:27 step:25321 [D loss: 0.464119, acc.: 82.03%] [G loss: 1.070532]\n",
      "epoch:27 step:25322 [D loss: 0.534252, acc.: 71.09%] [G loss: 0.699200]\n",
      "epoch:27 step:25323 [D loss: 0.487514, acc.: 75.78%] [G loss: 0.814036]\n",
      "epoch:27 step:25324 [D loss: 0.493086, acc.: 77.34%] [G loss: 0.614787]\n",
      "epoch:27 step:25325 [D loss: 0.624219, acc.: 62.50%] [G loss: 0.617272]\n",
      "epoch:27 step:25326 [D loss: 0.443916, acc.: 79.69%] [G loss: 0.773664]\n",
      "epoch:27 step:25327 [D loss: 0.528204, acc.: 69.53%] [G loss: 0.710193]\n",
      "epoch:27 step:25328 [D loss: 0.515183, acc.: 74.22%] [G loss: 0.762417]\n",
      "epoch:27 step:25329 [D loss: 0.496246, acc.: 75.00%] [G loss: 0.629143]\n",
      "epoch:27 step:25330 [D loss: 0.637695, acc.: 58.59%] [G loss: 0.624816]\n",
      "epoch:27 step:25331 [D loss: 0.558961, acc.: 71.09%] [G loss: 0.656376]\n",
      "epoch:27 step:25332 [D loss: 0.499447, acc.: 74.22%] [G loss: 0.900138]\n",
      "epoch:27 step:25333 [D loss: 0.561532, acc.: 67.97%] [G loss: 0.622309]\n",
      "epoch:27 step:25334 [D loss: 0.574191, acc.: 66.41%] [G loss: 0.728609]\n",
      "epoch:27 step:25335 [D loss: 0.516929, acc.: 67.97%] [G loss: 0.578865]\n",
      "epoch:27 step:25336 [D loss: 0.471186, acc.: 73.44%] [G loss: 0.742630]\n",
      "epoch:27 step:25337 [D loss: 0.592347, acc.: 67.19%] [G loss: 0.617489]\n",
      "epoch:27 step:25338 [D loss: 0.529507, acc.: 72.66%] [G loss: 0.720616]\n",
      "epoch:27 step:25339 [D loss: 0.405430, acc.: 85.16%] [G loss: 0.959830]\n",
      "epoch:27 step:25340 [D loss: 0.532368, acc.: 72.66%] [G loss: 0.685492]\n",
      "epoch:27 step:25341 [D loss: 0.525172, acc.: 67.97%] [G loss: 0.727372]\n",
      "epoch:27 step:25342 [D loss: 0.510421, acc.: 71.09%] [G loss: 0.687459]\n",
      "epoch:27 step:25343 [D loss: 0.587821, acc.: 65.62%] [G loss: 0.654272]\n",
      "epoch:27 step:25344 [D loss: 0.479544, acc.: 75.78%] [G loss: 0.751226]\n",
      "epoch:27 step:25345 [D loss: 0.538421, acc.: 71.09%] [G loss: 0.656446]\n",
      "epoch:27 step:25346 [D loss: 0.503989, acc.: 74.22%] [G loss: 0.715997]\n",
      "epoch:27 step:25347 [D loss: 0.497231, acc.: 78.91%] [G loss: 0.702558]\n",
      "epoch:27 step:25348 [D loss: 0.468672, acc.: 75.00%] [G loss: 0.812577]\n",
      "epoch:27 step:25349 [D loss: 0.523301, acc.: 72.66%] [G loss: 0.742249]\n",
      "epoch:27 step:25350 [D loss: 0.618676, acc.: 66.41%] [G loss: 0.587555]\n",
      "epoch:27 step:25351 [D loss: 0.580355, acc.: 64.06%] [G loss: 0.865029]\n",
      "epoch:27 step:25352 [D loss: 0.561050, acc.: 70.31%] [G loss: 0.677637]\n",
      "epoch:27 step:25353 [D loss: 0.486952, acc.: 72.66%] [G loss: 0.893667]\n",
      "epoch:27 step:25354 [D loss: 0.576195, acc.: 67.97%] [G loss: 0.679676]\n",
      "epoch:27 step:25355 [D loss: 0.501407, acc.: 73.44%] [G loss: 0.714540]\n",
      "epoch:27 step:25356 [D loss: 0.489010, acc.: 71.88%] [G loss: 0.721347]\n",
      "epoch:27 step:25357 [D loss: 0.534148, acc.: 69.53%] [G loss: 0.772720]\n",
      "epoch:27 step:25358 [D loss: 0.446136, acc.: 78.12%] [G loss: 1.130956]\n",
      "epoch:27 step:25359 [D loss: 0.592196, acc.: 64.84%] [G loss: 0.766668]\n",
      "epoch:27 step:25360 [D loss: 0.561994, acc.: 68.75%] [G loss: 0.700620]\n",
      "epoch:27 step:25361 [D loss: 0.607403, acc.: 64.84%] [G loss: 0.619317]\n",
      "epoch:27 step:25362 [D loss: 0.577339, acc.: 72.66%] [G loss: 0.712426]\n",
      "epoch:27 step:25363 [D loss: 0.570209, acc.: 71.09%] [G loss: 0.638002]\n",
      "epoch:27 step:25364 [D loss: 0.513036, acc.: 75.78%] [G loss: 0.597010]\n",
      "epoch:27 step:25365 [D loss: 0.506817, acc.: 75.78%] [G loss: 0.634331]\n",
      "epoch:27 step:25366 [D loss: 0.514781, acc.: 71.09%] [G loss: 0.561849]\n",
      "epoch:27 step:25367 [D loss: 0.489911, acc.: 75.78%] [G loss: 0.652422]\n",
      "epoch:27 step:25368 [D loss: 0.466568, acc.: 78.91%] [G loss: 0.905054]\n",
      "epoch:27 step:25369 [D loss: 0.485774, acc.: 78.12%] [G loss: 0.839757]\n",
      "epoch:27 step:25370 [D loss: 0.509817, acc.: 73.44%] [G loss: 0.825359]\n",
      "epoch:27 step:25371 [D loss: 0.556222, acc.: 69.53%] [G loss: 0.699193]\n",
      "epoch:27 step:25372 [D loss: 0.529441, acc.: 71.88%] [G loss: 0.743661]\n",
      "epoch:27 step:25373 [D loss: 0.493941, acc.: 73.44%] [G loss: 0.782316]\n",
      "epoch:27 step:25374 [D loss: 0.510462, acc.: 75.78%] [G loss: 0.785406]\n",
      "epoch:27 step:25375 [D loss: 0.506835, acc.: 75.00%] [G loss: 0.854868]\n",
      "epoch:27 step:25376 [D loss: 0.447685, acc.: 81.25%] [G loss: 0.759175]\n",
      "epoch:27 step:25377 [D loss: 0.586298, acc.: 70.31%] [G loss: 0.805254]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:27 step:25378 [D loss: 0.552406, acc.: 71.09%] [G loss: 0.645543]\n",
      "epoch:27 step:25379 [D loss: 0.463032, acc.: 78.12%] [G loss: 0.717115]\n",
      "epoch:27 step:25380 [D loss: 0.533242, acc.: 69.53%] [G loss: 0.723256]\n",
      "epoch:27 step:25381 [D loss: 0.529311, acc.: 70.31%] [G loss: 0.760482]\n",
      "epoch:27 step:25382 [D loss: 0.478714, acc.: 80.47%] [G loss: 0.753834]\n",
      "epoch:27 step:25383 [D loss: 0.508639, acc.: 74.22%] [G loss: 0.553668]\n",
      "epoch:27 step:25384 [D loss: 0.583188, acc.: 66.41%] [G loss: 0.660518]\n",
      "epoch:27 step:25385 [D loss: 0.551869, acc.: 70.31%] [G loss: 0.602794]\n",
      "epoch:27 step:25386 [D loss: 0.528108, acc.: 73.44%] [G loss: 0.630947]\n",
      "epoch:27 step:25387 [D loss: 0.538098, acc.: 74.22%] [G loss: 0.799785]\n",
      "epoch:27 step:25388 [D loss: 0.482764, acc.: 75.78%] [G loss: 0.816701]\n",
      "epoch:27 step:25389 [D loss: 0.495090, acc.: 75.00%] [G loss: 0.758928]\n",
      "epoch:27 step:25390 [D loss: 0.550917, acc.: 67.19%] [G loss: 0.748105]\n",
      "epoch:27 step:25391 [D loss: 0.431243, acc.: 81.25%] [G loss: 0.884124]\n",
      "epoch:27 step:25392 [D loss: 0.503609, acc.: 75.78%] [G loss: 0.819575]\n",
      "epoch:27 step:25393 [D loss: 0.504039, acc.: 73.44%] [G loss: 0.823090]\n",
      "epoch:27 step:25394 [D loss: 0.534824, acc.: 72.66%] [G loss: 0.754487]\n",
      "epoch:27 step:25395 [D loss: 0.471311, acc.: 80.47%] [G loss: 0.875833]\n",
      "epoch:27 step:25396 [D loss: 0.592442, acc.: 64.84%] [G loss: 0.757539]\n",
      "epoch:27 step:25397 [D loss: 0.510985, acc.: 75.00%] [G loss: 0.679602]\n",
      "epoch:27 step:25398 [D loss: 0.541492, acc.: 71.88%] [G loss: 0.802581]\n",
      "epoch:27 step:25399 [D loss: 0.425302, acc.: 79.69%] [G loss: 0.977055]\n",
      "epoch:27 step:25400 [D loss: 0.527507, acc.: 70.31%] [G loss: 0.865795]\n",
      "##############\n",
      "[2.53772076 1.13946946 6.08327841 4.83091007 3.90878076 5.57473597\n",
      " 4.51176478 4.75876648 4.58683928 4.23895367]\n",
      "##########\n",
      "epoch:27 step:25401 [D loss: 0.660481, acc.: 64.06%] [G loss: 0.572065]\n",
      "epoch:27 step:25402 [D loss: 0.517654, acc.: 71.09%] [G loss: 0.803733]\n",
      "epoch:27 step:25403 [D loss: 0.508314, acc.: 71.09%] [G loss: 0.786209]\n",
      "epoch:27 step:25404 [D loss: 0.563618, acc.: 64.06%] [G loss: 0.599879]\n",
      "epoch:27 step:25405 [D loss: 0.532126, acc.: 71.09%] [G loss: 0.666456]\n",
      "epoch:27 step:25406 [D loss: 0.563938, acc.: 75.78%] [G loss: 0.822497]\n",
      "epoch:27 step:25407 [D loss: 0.696678, acc.: 68.75%] [G loss: 0.703150]\n",
      "epoch:27 step:25408 [D loss: 0.514345, acc.: 75.00%] [G loss: 0.648319]\n",
      "epoch:27 step:25409 [D loss: 0.557881, acc.: 71.88%] [G loss: 0.512890]\n",
      "epoch:27 step:25410 [D loss: 0.498118, acc.: 71.88%] [G loss: 0.559316]\n",
      "epoch:27 step:25411 [D loss: 0.542385, acc.: 71.88%] [G loss: 0.643951]\n",
      "epoch:27 step:25412 [D loss: 0.510704, acc.: 76.56%] [G loss: 0.655099]\n",
      "epoch:27 step:25413 [D loss: 0.538097, acc.: 68.75%] [G loss: 0.650930]\n",
      "epoch:27 step:25414 [D loss: 0.484430, acc.: 78.12%] [G loss: 0.686538]\n",
      "epoch:27 step:25415 [D loss: 0.475638, acc.: 72.66%] [G loss: 0.829152]\n",
      "epoch:27 step:25416 [D loss: 0.486495, acc.: 75.78%] [G loss: 0.775392]\n",
      "epoch:27 step:25417 [D loss: 0.510254, acc.: 74.22%] [G loss: 0.750127]\n",
      "epoch:27 step:25418 [D loss: 0.435832, acc.: 83.59%] [G loss: 1.017255]\n",
      "epoch:27 step:25419 [D loss: 0.488237, acc.: 75.78%] [G loss: 0.942687]\n",
      "epoch:27 step:25420 [D loss: 0.549737, acc.: 67.19%] [G loss: 0.737199]\n",
      "epoch:27 step:25421 [D loss: 0.466317, acc.: 75.78%] [G loss: 0.900619]\n",
      "epoch:27 step:25422 [D loss: 0.487603, acc.: 72.66%] [G loss: 0.721684]\n",
      "epoch:27 step:25423 [D loss: 0.582616, acc.: 64.84%] [G loss: 0.687265]\n",
      "epoch:27 step:25424 [D loss: 0.554643, acc.: 71.09%] [G loss: 0.774580]\n",
      "epoch:27 step:25425 [D loss: 0.483289, acc.: 75.78%] [G loss: 0.739246]\n",
      "epoch:27 step:25426 [D loss: 0.451783, acc.: 76.56%] [G loss: 0.744849]\n",
      "epoch:27 step:25427 [D loss: 0.475934, acc.: 76.56%] [G loss: 0.616666]\n",
      "epoch:27 step:25428 [D loss: 0.525896, acc.: 77.34%] [G loss: 0.663209]\n",
      "epoch:27 step:25429 [D loss: 0.500925, acc.: 72.66%] [G loss: 0.744454]\n",
      "epoch:27 step:25430 [D loss: 0.479914, acc.: 73.44%] [G loss: 0.902202]\n",
      "epoch:27 step:25431 [D loss: 0.527689, acc.: 71.09%] [G loss: 0.814307]\n",
      "epoch:27 step:25432 [D loss: 0.531506, acc.: 70.31%] [G loss: 0.937006]\n",
      "epoch:27 step:25433 [D loss: 0.507853, acc.: 71.09%] [G loss: 0.790434]\n",
      "epoch:27 step:25434 [D loss: 0.489458, acc.: 75.78%] [G loss: 0.831135]\n",
      "epoch:27 step:25435 [D loss: 0.572988, acc.: 72.66%] [G loss: 1.143411]\n",
      "epoch:27 step:25436 [D loss: 0.603137, acc.: 65.62%] [G loss: 0.752971]\n",
      "epoch:27 step:25437 [D loss: 0.676915, acc.: 61.72%] [G loss: 0.604591]\n",
      "epoch:27 step:25438 [D loss: 0.565433, acc.: 67.97%] [G loss: 0.740116]\n",
      "epoch:27 step:25439 [D loss: 0.559622, acc.: 66.41%] [G loss: 0.764524]\n",
      "epoch:27 step:25440 [D loss: 0.551455, acc.: 65.62%] [G loss: 0.627613]\n",
      "epoch:27 step:25441 [D loss: 0.581502, acc.: 63.28%] [G loss: 0.686603]\n",
      "epoch:27 step:25442 [D loss: 0.648617, acc.: 55.47%] [G loss: 0.538354]\n",
      "epoch:27 step:25443 [D loss: 0.517458, acc.: 71.88%] [G loss: 0.706966]\n",
      "epoch:27 step:25444 [D loss: 0.568008, acc.: 66.41%] [G loss: 0.648331]\n",
      "epoch:27 step:25445 [D loss: 0.494503, acc.: 74.22%] [G loss: 0.668497]\n",
      "epoch:27 step:25446 [D loss: 0.546773, acc.: 71.88%] [G loss: 0.664803]\n",
      "epoch:27 step:25447 [D loss: 0.584990, acc.: 63.28%] [G loss: 0.716315]\n",
      "epoch:27 step:25448 [D loss: 0.509701, acc.: 75.78%] [G loss: 0.554556]\n",
      "epoch:27 step:25449 [D loss: 0.610349, acc.: 62.50%] [G loss: 0.693537]\n",
      "epoch:27 step:25450 [D loss: 0.575346, acc.: 67.97%] [G loss: 0.527427]\n",
      "epoch:27 step:25451 [D loss: 0.487617, acc.: 75.00%] [G loss: 0.884344]\n",
      "epoch:27 step:25452 [D loss: 0.579875, acc.: 67.19%] [G loss: 0.791888]\n",
      "epoch:27 step:25453 [D loss: 0.571218, acc.: 65.62%] [G loss: 0.618482]\n",
      "epoch:27 step:25454 [D loss: 0.521904, acc.: 73.44%] [G loss: 0.989057]\n",
      "epoch:27 step:25455 [D loss: 0.496086, acc.: 76.56%] [G loss: 0.782088]\n",
      "epoch:27 step:25456 [D loss: 0.577925, acc.: 69.53%] [G loss: 0.562888]\n",
      "epoch:27 step:25457 [D loss: 0.557223, acc.: 67.19%] [G loss: 0.766471]\n",
      "epoch:27 step:25458 [D loss: 0.506773, acc.: 74.22%] [G loss: 0.602169]\n",
      "epoch:27 step:25459 [D loss: 0.616675, acc.: 65.62%] [G loss: 0.739460]\n",
      "epoch:27 step:25460 [D loss: 0.512421, acc.: 70.31%] [G loss: 0.867996]\n",
      "epoch:27 step:25461 [D loss: 0.540703, acc.: 71.09%] [G loss: 0.835552]\n",
      "epoch:27 step:25462 [D loss: 0.535707, acc.: 69.53%] [G loss: 1.063858]\n",
      "epoch:27 step:25463 [D loss: 0.545649, acc.: 71.88%] [G loss: 0.774203]\n",
      "epoch:27 step:25464 [D loss: 0.482931, acc.: 70.31%] [G loss: 0.622326]\n",
      "epoch:27 step:25465 [D loss: 0.564770, acc.: 70.31%] [G loss: 0.654155]\n",
      "epoch:27 step:25466 [D loss: 0.499527, acc.: 75.78%] [G loss: 0.634906]\n",
      "epoch:27 step:25467 [D loss: 0.529786, acc.: 68.75%] [G loss: 0.565293]\n",
      "epoch:27 step:25468 [D loss: 0.576374, acc.: 70.31%] [G loss: 0.614648]\n",
      "epoch:27 step:25469 [D loss: 0.529028, acc.: 71.09%] [G loss: 0.630191]\n",
      "epoch:27 step:25470 [D loss: 0.543167, acc.: 70.31%] [G loss: 0.507475]\n",
      "epoch:27 step:25471 [D loss: 0.469195, acc.: 77.34%] [G loss: 0.849702]\n",
      "epoch:27 step:25472 [D loss: 0.462384, acc.: 78.91%] [G loss: 0.759919]\n",
      "epoch:27 step:25473 [D loss: 0.562950, acc.: 69.53%] [G loss: 0.643503]\n",
      "epoch:27 step:25474 [D loss: 0.573589, acc.: 67.97%] [G loss: 0.557929]\n",
      "epoch:27 step:25475 [D loss: 0.514267, acc.: 74.22%] [G loss: 0.624321]\n",
      "epoch:27 step:25476 [D loss: 0.497980, acc.: 78.12%] [G loss: 0.575778]\n",
      "epoch:27 step:25477 [D loss: 0.545061, acc.: 69.53%] [G loss: 0.584837]\n",
      "epoch:27 step:25478 [D loss: 0.541027, acc.: 66.41%] [G loss: 0.621008]\n",
      "epoch:27 step:25479 [D loss: 0.601703, acc.: 63.28%] [G loss: 0.606375]\n",
      "epoch:27 step:25480 [D loss: 0.564510, acc.: 68.75%] [G loss: 0.573623]\n",
      "epoch:27 step:25481 [D loss: 0.561852, acc.: 65.62%] [G loss: 0.703648]\n",
      "epoch:27 step:25482 [D loss: 0.573377, acc.: 71.88%] [G loss: 0.797747]\n",
      "epoch:27 step:25483 [D loss: 0.519213, acc.: 73.44%] [G loss: 0.685436]\n",
      "epoch:27 step:25484 [D loss: 0.545778, acc.: 70.31%] [G loss: 0.774047]\n",
      "epoch:27 step:25485 [D loss: 0.573852, acc.: 69.53%] [G loss: 0.627902]\n",
      "epoch:27 step:25486 [D loss: 0.598636, acc.: 64.84%] [G loss: 0.763147]\n",
      "epoch:27 step:25487 [D loss: 0.523827, acc.: 72.66%] [G loss: 0.679110]\n",
      "epoch:27 step:25488 [D loss: 0.565501, acc.: 66.41%] [G loss: 0.606326]\n",
      "epoch:27 step:25489 [D loss: 0.539221, acc.: 74.22%] [G loss: 0.802366]\n",
      "epoch:27 step:25490 [D loss: 0.446644, acc.: 81.25%] [G loss: 0.843615]\n",
      "epoch:27 step:25491 [D loss: 0.522978, acc.: 74.22%] [G loss: 0.748604]\n",
      "epoch:27 step:25492 [D loss: 0.520064, acc.: 74.22%] [G loss: 0.780121]\n",
      "epoch:27 step:25493 [D loss: 0.467021, acc.: 81.25%] [G loss: 0.682996]\n",
      "epoch:27 step:25494 [D loss: 0.595024, acc.: 67.19%] [G loss: 1.050413]\n",
      "epoch:27 step:25495 [D loss: 0.526085, acc.: 68.75%] [G loss: 0.684336]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:27 step:25496 [D loss: 0.452020, acc.: 80.47%] [G loss: 0.685765]\n",
      "epoch:27 step:25497 [D loss: 0.462755, acc.: 81.25%] [G loss: 0.814855]\n",
      "epoch:27 step:25498 [D loss: 0.503805, acc.: 74.22%] [G loss: 0.870274]\n",
      "epoch:27 step:25499 [D loss: 0.546786, acc.: 70.31%] [G loss: 0.867815]\n",
      "epoch:27 step:25500 [D loss: 0.502791, acc.: 73.44%] [G loss: 0.711595]\n",
      "epoch:27 step:25501 [D loss: 0.498451, acc.: 75.00%] [G loss: 0.888104]\n",
      "epoch:27 step:25502 [D loss: 0.579840, acc.: 66.41%] [G loss: 0.581832]\n",
      "epoch:27 step:25503 [D loss: 0.565779, acc.: 65.62%] [G loss: 0.707709]\n",
      "epoch:27 step:25504 [D loss: 0.548382, acc.: 71.88%] [G loss: 0.952123]\n",
      "epoch:27 step:25505 [D loss: 0.529492, acc.: 71.88%] [G loss: 0.773170]\n",
      "epoch:27 step:25506 [D loss: 0.476309, acc.: 77.34%] [G loss: 0.718432]\n",
      "epoch:27 step:25507 [D loss: 0.444027, acc.: 79.69%] [G loss: 0.900982]\n",
      "epoch:27 step:25508 [D loss: 0.468471, acc.: 74.22%] [G loss: 0.743142]\n",
      "epoch:27 step:25509 [D loss: 0.678633, acc.: 63.28%] [G loss: 0.660623]\n",
      "epoch:27 step:25510 [D loss: 0.571506, acc.: 68.75%] [G loss: 0.748582]\n",
      "epoch:27 step:25511 [D loss: 0.535340, acc.: 74.22%] [G loss: 0.618071]\n",
      "epoch:27 step:25512 [D loss: 0.488669, acc.: 74.22%] [G loss: 0.770120]\n",
      "epoch:27 step:25513 [D loss: 0.580356, acc.: 64.06%] [G loss: 0.542594]\n",
      "epoch:27 step:25514 [D loss: 0.576435, acc.: 64.84%] [G loss: 0.660495]\n",
      "epoch:27 step:25515 [D loss: 0.497265, acc.: 72.66%] [G loss: 0.800570]\n",
      "epoch:27 step:25516 [D loss: 0.494431, acc.: 74.22%] [G loss: 0.907239]\n",
      "epoch:27 step:25517 [D loss: 0.550720, acc.: 71.88%] [G loss: 0.790253]\n",
      "epoch:27 step:25518 [D loss: 0.430373, acc.: 82.81%] [G loss: 0.961929]\n",
      "epoch:27 step:25519 [D loss: 0.627033, acc.: 68.75%] [G loss: 0.676826]\n",
      "epoch:27 step:25520 [D loss: 0.490487, acc.: 72.66%] [G loss: 0.741483]\n",
      "epoch:27 step:25521 [D loss: 0.544756, acc.: 68.75%] [G loss: 0.844778]\n",
      "epoch:27 step:25522 [D loss: 0.448754, acc.: 81.25%] [G loss: 1.194480]\n",
      "epoch:27 step:25523 [D loss: 0.570364, acc.: 69.53%] [G loss: 0.829699]\n",
      "epoch:27 step:25524 [D loss: 0.519717, acc.: 71.09%] [G loss: 0.696024]\n",
      "epoch:27 step:25525 [D loss: 0.595827, acc.: 63.28%] [G loss: 0.631879]\n",
      "epoch:27 step:25526 [D loss: 0.524882, acc.: 71.09%] [G loss: 0.723413]\n",
      "epoch:27 step:25527 [D loss: 0.590359, acc.: 64.06%] [G loss: 0.712438]\n",
      "epoch:27 step:25528 [D loss: 0.525657, acc.: 73.44%] [G loss: 0.690575]\n",
      "epoch:27 step:25529 [D loss: 0.535981, acc.: 75.00%] [G loss: 0.844300]\n",
      "epoch:27 step:25530 [D loss: 0.507987, acc.: 76.56%] [G loss: 1.097594]\n",
      "epoch:27 step:25531 [D loss: 0.427308, acc.: 85.16%] [G loss: 1.201691]\n",
      "epoch:27 step:25532 [D loss: 0.526989, acc.: 71.09%] [G loss: 0.905819]\n",
      "epoch:27 step:25533 [D loss: 0.530873, acc.: 75.00%] [G loss: 0.853485]\n",
      "epoch:27 step:25534 [D loss: 0.602294, acc.: 65.62%] [G loss: 0.581503]\n",
      "epoch:27 step:25535 [D loss: 0.453610, acc.: 76.56%] [G loss: 0.868832]\n",
      "epoch:27 step:25536 [D loss: 0.525154, acc.: 71.09%] [G loss: 0.628582]\n",
      "epoch:27 step:25537 [D loss: 0.578746, acc.: 65.62%] [G loss: 0.670153]\n",
      "epoch:27 step:25538 [D loss: 0.547442, acc.: 71.88%] [G loss: 0.711678]\n",
      "epoch:27 step:25539 [D loss: 0.572142, acc.: 66.41%] [G loss: 0.615112]\n",
      "epoch:27 step:25540 [D loss: 0.535317, acc.: 71.09%] [G loss: 0.717891]\n",
      "epoch:27 step:25541 [D loss: 0.462380, acc.: 77.34%] [G loss: 0.758965]\n",
      "epoch:27 step:25542 [D loss: 0.501597, acc.: 71.88%] [G loss: 0.688420]\n",
      "epoch:27 step:25543 [D loss: 0.481192, acc.: 78.91%] [G loss: 0.682587]\n",
      "epoch:27 step:25544 [D loss: 0.480858, acc.: 75.78%] [G loss: 0.667190]\n",
      "epoch:27 step:25545 [D loss: 0.468235, acc.: 80.47%] [G loss: 0.745353]\n",
      "epoch:27 step:25546 [D loss: 0.585915, acc.: 61.72%] [G loss: 0.772362]\n",
      "epoch:27 step:25547 [D loss: 0.531713, acc.: 72.66%] [G loss: 0.775456]\n",
      "epoch:27 step:25548 [D loss: 0.529489, acc.: 70.31%] [G loss: 0.864272]\n",
      "epoch:27 step:25549 [D loss: 0.657322, acc.: 60.94%] [G loss: 0.644405]\n",
      "epoch:27 step:25550 [D loss: 0.621700, acc.: 62.50%] [G loss: 0.811180]\n",
      "epoch:27 step:25551 [D loss: 0.528197, acc.: 72.66%] [G loss: 0.931548]\n",
      "epoch:27 step:25552 [D loss: 0.591459, acc.: 69.53%] [G loss: 0.761838]\n",
      "epoch:27 step:25553 [D loss: 0.543630, acc.: 72.66%] [G loss: 0.628549]\n",
      "epoch:27 step:25554 [D loss: 0.539440, acc.: 65.62%] [G loss: 0.714633]\n",
      "epoch:27 step:25555 [D loss: 0.509754, acc.: 71.88%] [G loss: 0.760037]\n",
      "epoch:27 step:25556 [D loss: 0.618160, acc.: 59.38%] [G loss: 0.631424]\n",
      "epoch:27 step:25557 [D loss: 0.524970, acc.: 67.97%] [G loss: 0.748450]\n",
      "epoch:27 step:25558 [D loss: 0.495652, acc.: 71.09%] [G loss: 0.867310]\n",
      "epoch:27 step:25559 [D loss: 0.566420, acc.: 65.62%] [G loss: 0.617608]\n",
      "epoch:27 step:25560 [D loss: 0.458961, acc.: 79.69%] [G loss: 0.813748]\n",
      "epoch:27 step:25561 [D loss: 0.518883, acc.: 71.88%] [G loss: 0.819269]\n",
      "epoch:27 step:25562 [D loss: 0.525971, acc.: 72.66%] [G loss: 0.729946]\n",
      "epoch:27 step:25563 [D loss: 0.545261, acc.: 70.31%] [G loss: 0.538432]\n",
      "epoch:27 step:25564 [D loss: 0.561501, acc.: 68.75%] [G loss: 0.627961]\n",
      "epoch:27 step:25565 [D loss: 0.582396, acc.: 67.19%] [G loss: 0.681480]\n",
      "epoch:27 step:25566 [D loss: 0.520612, acc.: 74.22%] [G loss: 0.794069]\n",
      "epoch:27 step:25567 [D loss: 0.595614, acc.: 65.62%] [G loss: 0.665377]\n",
      "epoch:27 step:25568 [D loss: 0.528026, acc.: 74.22%] [G loss: 0.656375]\n",
      "epoch:27 step:25569 [D loss: 0.452296, acc.: 78.12%] [G loss: 0.723127]\n",
      "epoch:27 step:25570 [D loss: 0.499453, acc.: 74.22%] [G loss: 0.891202]\n",
      "epoch:27 step:25571 [D loss: 0.494155, acc.: 73.44%] [G loss: 0.928756]\n",
      "epoch:27 step:25572 [D loss: 0.486204, acc.: 76.56%] [G loss: 0.742710]\n",
      "epoch:27 step:25573 [D loss: 0.486199, acc.: 75.78%] [G loss: 0.851766]\n",
      "epoch:27 step:25574 [D loss: 0.582393, acc.: 64.84%] [G loss: 0.702240]\n",
      "epoch:27 step:25575 [D loss: 0.450033, acc.: 79.69%] [G loss: 0.840671]\n",
      "epoch:27 step:25576 [D loss: 0.655427, acc.: 64.84%] [G loss: 0.631593]\n",
      "epoch:27 step:25577 [D loss: 0.692832, acc.: 64.06%] [G loss: 0.618505]\n",
      "epoch:27 step:25578 [D loss: 0.572853, acc.: 61.72%] [G loss: 0.645667]\n",
      "epoch:27 step:25579 [D loss: 0.505036, acc.: 72.66%] [G loss: 0.656682]\n",
      "epoch:27 step:25580 [D loss: 0.590522, acc.: 68.75%] [G loss: 0.563089]\n",
      "epoch:27 step:25581 [D loss: 0.550374, acc.: 63.28%] [G loss: 0.696119]\n",
      "epoch:27 step:25582 [D loss: 0.523255, acc.: 75.78%] [G loss: 0.807013]\n",
      "epoch:27 step:25583 [D loss: 0.545355, acc.: 69.53%] [G loss: 0.765815]\n",
      "epoch:27 step:25584 [D loss: 0.501206, acc.: 71.09%] [G loss: 0.770450]\n",
      "epoch:27 step:25585 [D loss: 0.537795, acc.: 68.75%] [G loss: 0.617938]\n",
      "epoch:27 step:25586 [D loss: 0.554758, acc.: 65.62%] [G loss: 0.666313]\n",
      "epoch:27 step:25587 [D loss: 0.583234, acc.: 62.50%] [G loss: 0.691799]\n",
      "epoch:27 step:25588 [D loss: 0.539505, acc.: 70.31%] [G loss: 0.694787]\n",
      "epoch:27 step:25589 [D loss: 0.533611, acc.: 70.31%] [G loss: 0.610563]\n",
      "epoch:27 step:25590 [D loss: 0.629090, acc.: 66.41%] [G loss: 0.569591]\n",
      "epoch:27 step:25591 [D loss: 0.492109, acc.: 77.34%] [G loss: 0.648178]\n",
      "epoch:27 step:25592 [D loss: 0.565682, acc.: 69.53%] [G loss: 0.484907]\n",
      "epoch:27 step:25593 [D loss: 0.542457, acc.: 72.66%] [G loss: 0.593986]\n",
      "epoch:27 step:25594 [D loss: 0.540604, acc.: 67.97%] [G loss: 0.590384]\n",
      "epoch:27 step:25595 [D loss: 0.483644, acc.: 78.12%] [G loss: 0.545247]\n",
      "epoch:27 step:25596 [D loss: 0.563380, acc.: 67.19%] [G loss: 0.518737]\n",
      "epoch:27 step:25597 [D loss: 0.462910, acc.: 77.34%] [G loss: 0.725538]\n",
      "epoch:27 step:25598 [D loss: 0.458405, acc.: 78.12%] [G loss: 0.811514]\n",
      "epoch:27 step:25599 [D loss: 0.474366, acc.: 75.78%] [G loss: 0.716981]\n",
      "epoch:27 step:25600 [D loss: 0.635900, acc.: 66.41%] [G loss: 0.620884]\n",
      "##############\n",
      "[3.33351687 0.82058181 6.24478205 4.91497061 3.91402695 5.51364794\n",
      " 4.54938914 5.08065637 4.62589939 4.13321561]\n",
      "##########\n",
      "epoch:27 step:25601 [D loss: 0.525273, acc.: 71.09%] [G loss: 0.562758]\n",
      "epoch:27 step:25602 [D loss: 0.532078, acc.: 73.44%] [G loss: 0.773840]\n",
      "epoch:27 step:25603 [D loss: 0.524457, acc.: 74.22%] [G loss: 0.742172]\n",
      "epoch:27 step:25604 [D loss: 0.563737, acc.: 67.97%] [G loss: 0.703279]\n",
      "epoch:27 step:25605 [D loss: 0.556677, acc.: 70.31%] [G loss: 0.730445]\n",
      "epoch:27 step:25606 [D loss: 0.486309, acc.: 75.78%] [G loss: 0.725351]\n",
      "epoch:27 step:25607 [D loss: 0.553027, acc.: 75.78%] [G loss: 0.581487]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:27 step:25608 [D loss: 0.497681, acc.: 74.22%] [G loss: 0.677984]\n",
      "epoch:27 step:25609 [D loss: 0.552512, acc.: 67.97%] [G loss: 0.608600]\n",
      "epoch:27 step:25610 [D loss: 0.493550, acc.: 75.78%] [G loss: 0.834641]\n",
      "epoch:27 step:25611 [D loss: 0.429978, acc.: 82.03%] [G loss: 0.780370]\n",
      "epoch:27 step:25612 [D loss: 0.455211, acc.: 75.00%] [G loss: 1.022684]\n",
      "epoch:27 step:25613 [D loss: 0.479665, acc.: 74.22%] [G loss: 1.034800]\n",
      "epoch:27 step:25614 [D loss: 0.407283, acc.: 82.81%] [G loss: 1.006813]\n",
      "epoch:27 step:25615 [D loss: 0.638251, acc.: 67.97%] [G loss: 0.763178]\n",
      "epoch:27 step:25616 [D loss: 0.558810, acc.: 71.88%] [G loss: 0.662324]\n",
      "epoch:27 step:25617 [D loss: 0.524202, acc.: 73.44%] [G loss: 0.714131]\n",
      "epoch:27 step:25618 [D loss: 0.581216, acc.: 70.31%] [G loss: 0.626700]\n",
      "epoch:27 step:25619 [D loss: 0.542570, acc.: 71.09%] [G loss: 0.636196]\n",
      "epoch:27 step:25620 [D loss: 0.457159, acc.: 78.12%] [G loss: 0.716931]\n",
      "epoch:27 step:25621 [D loss: 0.544793, acc.: 67.19%] [G loss: 0.583510]\n",
      "epoch:27 step:25622 [D loss: 0.565214, acc.: 67.19%] [G loss: 0.698838]\n",
      "epoch:27 step:25623 [D loss: 0.544499, acc.: 73.44%] [G loss: 0.518756]\n",
      "epoch:27 step:25624 [D loss: 0.500088, acc.: 73.44%] [G loss: 0.618177]\n",
      "epoch:27 step:25625 [D loss: 0.501152, acc.: 73.44%] [G loss: 0.690205]\n",
      "epoch:27 step:25626 [D loss: 0.513193, acc.: 75.00%] [G loss: 0.742967]\n",
      "epoch:27 step:25627 [D loss: 0.494280, acc.: 75.00%] [G loss: 0.881356]\n",
      "epoch:27 step:25628 [D loss: 0.516619, acc.: 73.44%] [G loss: 0.830035]\n",
      "epoch:27 step:25629 [D loss: 0.604950, acc.: 67.19%] [G loss: 0.780371]\n",
      "epoch:27 step:25630 [D loss: 0.527019, acc.: 69.53%] [G loss: 0.706516]\n",
      "epoch:27 step:25631 [D loss: 0.523614, acc.: 74.22%] [G loss: 0.687526]\n",
      "epoch:27 step:25632 [D loss: 0.530489, acc.: 75.00%] [G loss: 0.738428]\n",
      "epoch:27 step:25633 [D loss: 0.463553, acc.: 78.12%] [G loss: 0.743880]\n",
      "epoch:27 step:25634 [D loss: 0.498228, acc.: 74.22%] [G loss: 0.875825]\n",
      "epoch:27 step:25635 [D loss: 0.490979, acc.: 75.78%] [G loss: 0.654621]\n",
      "epoch:27 step:25636 [D loss: 0.492856, acc.: 73.44%] [G loss: 0.877317]\n",
      "epoch:27 step:25637 [D loss: 0.516320, acc.: 68.75%] [G loss: 0.797216]\n",
      "epoch:27 step:25638 [D loss: 0.519650, acc.: 73.44%] [G loss: 0.685045]\n",
      "epoch:27 step:25639 [D loss: 0.503099, acc.: 76.56%] [G loss: 0.751271]\n",
      "epoch:27 step:25640 [D loss: 0.591088, acc.: 71.88%] [G loss: 0.895458]\n",
      "epoch:27 step:25641 [D loss: 0.618881, acc.: 65.62%] [G loss: 0.891963]\n",
      "epoch:27 step:25642 [D loss: 0.530365, acc.: 73.44%] [G loss: 0.857833]\n",
      "epoch:27 step:25643 [D loss: 0.484267, acc.: 78.91%] [G loss: 1.177488]\n",
      "epoch:27 step:25644 [D loss: 0.542544, acc.: 70.31%] [G loss: 0.957846]\n",
      "epoch:27 step:25645 [D loss: 0.538723, acc.: 69.53%] [G loss: 0.896877]\n",
      "epoch:27 step:25646 [D loss: 0.462123, acc.: 76.56%] [G loss: 1.060603]\n",
      "epoch:27 step:25647 [D loss: 0.562116, acc.: 71.88%] [G loss: 0.782222]\n",
      "epoch:27 step:25648 [D loss: 0.787985, acc.: 51.56%] [G loss: 0.601831]\n",
      "epoch:27 step:25649 [D loss: 0.433134, acc.: 84.38%] [G loss: 0.628728]\n",
      "epoch:27 step:25650 [D loss: 0.545854, acc.: 67.97%] [G loss: 0.821646]\n",
      "epoch:27 step:25651 [D loss: 0.536847, acc.: 66.41%] [G loss: 0.726181]\n",
      "epoch:27 step:25652 [D loss: 0.619218, acc.: 64.84%] [G loss: 0.626200]\n",
      "epoch:27 step:25653 [D loss: 0.393339, acc.: 82.03%] [G loss: 0.892778]\n",
      "epoch:27 step:25654 [D loss: 0.501551, acc.: 74.22%] [G loss: 0.915348]\n",
      "epoch:27 step:25655 [D loss: 0.532278, acc.: 73.44%] [G loss: 0.696911]\n",
      "epoch:27 step:25656 [D loss: 0.453103, acc.: 80.47%] [G loss: 0.731294]\n",
      "epoch:27 step:25657 [D loss: 0.477329, acc.: 77.34%] [G loss: 0.966725]\n",
      "epoch:27 step:25658 [D loss: 0.445045, acc.: 76.56%] [G loss: 1.047500]\n",
      "epoch:27 step:25659 [D loss: 0.466401, acc.: 74.22%] [G loss: 0.952486]\n",
      "epoch:27 step:25660 [D loss: 0.478875, acc.: 76.56%] [G loss: 0.962433]\n",
      "epoch:27 step:25661 [D loss: 0.550541, acc.: 71.88%] [G loss: 0.782540]\n",
      "epoch:27 step:25662 [D loss: 0.580690, acc.: 70.31%] [G loss: 0.671583]\n",
      "epoch:27 step:25663 [D loss: 0.574743, acc.: 67.19%] [G loss: 0.771273]\n",
      "epoch:27 step:25664 [D loss: 0.558899, acc.: 67.97%] [G loss: 0.781660]\n",
      "epoch:27 step:25665 [D loss: 0.541516, acc.: 67.19%] [G loss: 0.759066]\n",
      "epoch:27 step:25666 [D loss: 0.591678, acc.: 67.97%] [G loss: 0.735385]\n",
      "epoch:27 step:25667 [D loss: 0.523439, acc.: 71.88%] [G loss: 0.732306]\n",
      "epoch:27 step:25668 [D loss: 0.536002, acc.: 63.28%] [G loss: 0.493066]\n",
      "epoch:27 step:25669 [D loss: 0.597722, acc.: 65.62%] [G loss: 0.846374]\n",
      "epoch:27 step:25670 [D loss: 0.489616, acc.: 74.22%] [G loss: 0.917529]\n",
      "epoch:27 step:25671 [D loss: 0.519934, acc.: 75.78%] [G loss: 0.812784]\n",
      "epoch:27 step:25672 [D loss: 0.525299, acc.: 72.66%] [G loss: 0.776394]\n",
      "epoch:27 step:25673 [D loss: 0.427202, acc.: 79.69%] [G loss: 0.932249]\n",
      "epoch:27 step:25674 [D loss: 0.598124, acc.: 68.75%] [G loss: 0.712265]\n",
      "epoch:27 step:25675 [D loss: 0.696168, acc.: 56.25%] [G loss: 0.568233]\n",
      "epoch:27 step:25676 [D loss: 0.557379, acc.: 67.19%] [G loss: 0.532282]\n",
      "epoch:27 step:25677 [D loss: 0.517773, acc.: 69.53%] [G loss: 0.713572]\n",
      "epoch:27 step:25678 [D loss: 0.561357, acc.: 70.31%] [G loss: 0.632043]\n",
      "epoch:27 step:25679 [D loss: 0.586520, acc.: 67.19%] [G loss: 0.478236]\n",
      "epoch:27 step:25680 [D loss: 0.456824, acc.: 79.69%] [G loss: 0.711216]\n",
      "epoch:27 step:25681 [D loss: 0.555582, acc.: 69.53%] [G loss: 0.743064]\n",
      "epoch:27 step:25682 [D loss: 0.500438, acc.: 75.78%] [G loss: 0.728660]\n",
      "epoch:27 step:25683 [D loss: 0.539596, acc.: 72.66%] [G loss: 0.642730]\n",
      "epoch:27 step:25684 [D loss: 0.453526, acc.: 75.00%] [G loss: 0.761212]\n",
      "epoch:27 step:25685 [D loss: 0.522835, acc.: 70.31%] [G loss: 0.717681]\n",
      "epoch:27 step:25686 [D loss: 0.481346, acc.: 76.56%] [G loss: 0.805593]\n",
      "epoch:27 step:25687 [D loss: 0.514965, acc.: 72.66%] [G loss: 0.786481]\n",
      "epoch:27 step:25688 [D loss: 0.493961, acc.: 78.12%] [G loss: 0.836932]\n",
      "epoch:27 step:25689 [D loss: 0.570216, acc.: 67.97%] [G loss: 0.753693]\n",
      "epoch:27 step:25690 [D loss: 0.505890, acc.: 71.88%] [G loss: 0.704236]\n",
      "epoch:27 step:25691 [D loss: 0.485309, acc.: 72.66%] [G loss: 0.676305]\n",
      "epoch:27 step:25692 [D loss: 0.595746, acc.: 66.41%] [G loss: 0.684248]\n",
      "epoch:27 step:25693 [D loss: 0.552566, acc.: 71.09%] [G loss: 0.652562]\n",
      "epoch:27 step:25694 [D loss: 0.535131, acc.: 72.66%] [G loss: 0.716095]\n",
      "epoch:27 step:25695 [D loss: 0.525056, acc.: 73.44%] [G loss: 0.658817]\n",
      "epoch:27 step:25696 [D loss: 0.556298, acc.: 67.19%] [G loss: 0.695530]\n",
      "epoch:27 step:25697 [D loss: 0.551767, acc.: 68.75%] [G loss: 0.783084]\n",
      "epoch:27 step:25698 [D loss: 0.494401, acc.: 75.00%] [G loss: 0.943954]\n",
      "epoch:27 step:25699 [D loss: 0.634006, acc.: 57.81%] [G loss: 0.747224]\n",
      "epoch:27 step:25700 [D loss: 0.650978, acc.: 64.84%] [G loss: 0.678576]\n",
      "epoch:27 step:25701 [D loss: 0.460254, acc.: 74.22%] [G loss: 0.727963]\n",
      "epoch:27 step:25702 [D loss: 0.514084, acc.: 74.22%] [G loss: 0.873749]\n",
      "epoch:27 step:25703 [D loss: 0.566019, acc.: 71.09%] [G loss: 0.840633]\n",
      "epoch:27 step:25704 [D loss: 0.569713, acc.: 64.84%] [G loss: 0.688522]\n",
      "epoch:27 step:25705 [D loss: 0.504774, acc.: 75.00%] [G loss: 0.759828]\n",
      "epoch:27 step:25706 [D loss: 0.632132, acc.: 63.28%] [G loss: 0.698596]\n",
      "epoch:27 step:25707 [D loss: 0.558023, acc.: 70.31%] [G loss: 0.706382]\n",
      "epoch:27 step:25708 [D loss: 0.560009, acc.: 68.75%] [G loss: 0.874696]\n",
      "epoch:27 step:25709 [D loss: 0.559794, acc.: 65.62%] [G loss: 0.881661]\n",
      "epoch:27 step:25710 [D loss: 0.599236, acc.: 66.41%] [G loss: 0.524684]\n",
      "epoch:27 step:25711 [D loss: 0.625018, acc.: 64.06%] [G loss: 0.421880]\n",
      "epoch:27 step:25712 [D loss: 0.577798, acc.: 65.62%] [G loss: 0.695865]\n",
      "epoch:27 step:25713 [D loss: 0.492763, acc.: 78.12%] [G loss: 0.730078]\n",
      "epoch:27 step:25714 [D loss: 0.496133, acc.: 75.78%] [G loss: 0.771496]\n",
      "epoch:27 step:25715 [D loss: 0.497332, acc.: 74.22%] [G loss: 0.774753]\n",
      "epoch:27 step:25716 [D loss: 0.612215, acc.: 68.75%] [G loss: 0.688120]\n",
      "epoch:27 step:25717 [D loss: 0.614432, acc.: 67.19%] [G loss: 0.661299]\n",
      "epoch:27 step:25718 [D loss: 0.536666, acc.: 73.44%] [G loss: 0.749022]\n",
      "epoch:27 step:25719 [D loss: 0.551264, acc.: 67.19%] [G loss: 0.815801]\n",
      "epoch:27 step:25720 [D loss: 0.567167, acc.: 73.44%] [G loss: 0.780142]\n",
      "epoch:27 step:25721 [D loss: 0.546583, acc.: 68.75%] [G loss: 0.943464]\n",
      "epoch:27 step:25722 [D loss: 0.556709, acc.: 68.75%] [G loss: 0.555088]\n",
      "epoch:27 step:25723 [D loss: 0.575492, acc.: 64.84%] [G loss: 0.499567]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:27 step:25724 [D loss: 0.470300, acc.: 80.47%] [G loss: 0.729777]\n",
      "epoch:27 step:25725 [D loss: 0.469598, acc.: 71.88%] [G loss: 0.757090]\n",
      "epoch:27 step:25726 [D loss: 0.452293, acc.: 78.12%] [G loss: 0.953652]\n",
      "epoch:27 step:25727 [D loss: 0.515011, acc.: 71.88%] [G loss: 0.975568]\n",
      "epoch:27 step:25728 [D loss: 0.413445, acc.: 78.91%] [G loss: 1.070860]\n",
      "epoch:27 step:25729 [D loss: 0.539030, acc.: 70.31%] [G loss: 0.992751]\n",
      "epoch:27 step:25730 [D loss: 0.523941, acc.: 71.09%] [G loss: 0.700194]\n",
      "epoch:27 step:25731 [D loss: 0.605258, acc.: 62.50%] [G loss: 0.849630]\n",
      "epoch:27 step:25732 [D loss: 0.559130, acc.: 71.09%] [G loss: 0.838949]\n",
      "epoch:27 step:25733 [D loss: 0.530295, acc.: 73.44%] [G loss: 0.530207]\n",
      "epoch:27 step:25734 [D loss: 0.511861, acc.: 74.22%] [G loss: 0.567569]\n",
      "epoch:27 step:25735 [D loss: 0.461004, acc.: 74.22%] [G loss: 0.657763]\n",
      "epoch:27 step:25736 [D loss: 0.644464, acc.: 64.06%] [G loss: 0.598137]\n",
      "epoch:27 step:25737 [D loss: 0.553089, acc.: 70.31%] [G loss: 0.685470]\n",
      "epoch:27 step:25738 [D loss: 0.522544, acc.: 71.88%] [G loss: 0.766221]\n",
      "epoch:27 step:25739 [D loss: 0.500306, acc.: 74.22%] [G loss: 1.015581]\n",
      "epoch:27 step:25740 [D loss: 0.518668, acc.: 71.09%] [G loss: 0.907265]\n",
      "epoch:27 step:25741 [D loss: 0.529757, acc.: 69.53%] [G loss: 0.670956]\n",
      "epoch:27 step:25742 [D loss: 0.486647, acc.: 77.34%] [G loss: 0.734264]\n",
      "epoch:27 step:25743 [D loss: 0.499511, acc.: 71.88%] [G loss: 0.920791]\n",
      "epoch:27 step:25744 [D loss: 0.551590, acc.: 65.62%] [G loss: 0.726046]\n",
      "epoch:27 step:25745 [D loss: 0.564552, acc.: 67.97%] [G loss: 0.834883]\n",
      "epoch:27 step:25746 [D loss: 0.528150, acc.: 70.31%] [G loss: 0.622942]\n",
      "epoch:27 step:25747 [D loss: 0.443320, acc.: 82.03%] [G loss: 0.950019]\n",
      "epoch:27 step:25748 [D loss: 0.554731, acc.: 69.53%] [G loss: 0.963508]\n",
      "epoch:27 step:25749 [D loss: 0.499395, acc.: 75.00%] [G loss: 0.848351]\n",
      "epoch:27 step:25750 [D loss: 0.430499, acc.: 78.91%] [G loss: 0.767294]\n",
      "epoch:27 step:25751 [D loss: 0.473261, acc.: 74.22%] [G loss: 0.892371]\n",
      "epoch:27 step:25752 [D loss: 0.501807, acc.: 75.78%] [G loss: 0.791091]\n",
      "epoch:27 step:25753 [D loss: 0.530450, acc.: 69.53%] [G loss: 0.739521]\n",
      "epoch:27 step:25754 [D loss: 0.553846, acc.: 67.97%] [G loss: 0.800461]\n",
      "epoch:27 step:25755 [D loss: 0.641490, acc.: 66.41%] [G loss: 0.707889]\n",
      "epoch:27 step:25756 [D loss: 0.459018, acc.: 78.12%] [G loss: 0.994161]\n",
      "epoch:27 step:25757 [D loss: 0.599216, acc.: 67.19%] [G loss: 0.711592]\n",
      "epoch:27 step:25758 [D loss: 0.513021, acc.: 78.91%] [G loss: 0.599845]\n",
      "epoch:27 step:25759 [D loss: 0.489096, acc.: 78.12%] [G loss: 0.720151]\n",
      "epoch:27 step:25760 [D loss: 0.466207, acc.: 74.22%] [G loss: 0.752072]\n",
      "epoch:27 step:25761 [D loss: 0.570905, acc.: 68.75%] [G loss: 0.725826]\n",
      "epoch:27 step:25762 [D loss: 0.527525, acc.: 71.88%] [G loss: 0.502903]\n",
      "epoch:27 step:25763 [D loss: 0.543132, acc.: 67.97%] [G loss: 0.635331]\n",
      "epoch:27 step:25764 [D loss: 0.628923, acc.: 67.97%] [G loss: 0.792640]\n",
      "epoch:27 step:25765 [D loss: 0.532202, acc.: 67.97%] [G loss: 0.775670]\n",
      "epoch:27 step:25766 [D loss: 0.533926, acc.: 74.22%] [G loss: 0.707938]\n",
      "epoch:27 step:25767 [D loss: 0.534225, acc.: 70.31%] [G loss: 0.717273]\n",
      "epoch:27 step:25768 [D loss: 0.503431, acc.: 75.78%] [G loss: 0.757983]\n",
      "epoch:27 step:25769 [D loss: 0.514646, acc.: 71.09%] [G loss: 0.834358]\n",
      "epoch:27 step:25770 [D loss: 0.402820, acc.: 82.81%] [G loss: 0.954218]\n",
      "epoch:27 step:25771 [D loss: 0.441697, acc.: 79.69%] [G loss: 1.071939]\n",
      "epoch:27 step:25772 [D loss: 0.626077, acc.: 64.06%] [G loss: 0.713117]\n",
      "epoch:27 step:25773 [D loss: 0.571536, acc.: 66.41%] [G loss: 0.839180]\n",
      "epoch:27 step:25774 [D loss: 0.474194, acc.: 76.56%] [G loss: 0.816018]\n",
      "epoch:27 step:25775 [D loss: 0.515214, acc.: 75.78%] [G loss: 1.016900]\n",
      "epoch:27 step:25776 [D loss: 0.676566, acc.: 61.72%] [G loss: 0.669574]\n",
      "epoch:27 step:25777 [D loss: 0.553205, acc.: 69.53%] [G loss: 0.607545]\n",
      "epoch:27 step:25778 [D loss: 0.484674, acc.: 78.12%] [G loss: 0.756677]\n",
      "epoch:27 step:25779 [D loss: 0.639462, acc.: 69.53%] [G loss: 0.583454]\n",
      "epoch:27 step:25780 [D loss: 0.449850, acc.: 81.25%] [G loss: 0.854300]\n",
      "epoch:27 step:25781 [D loss: 0.644494, acc.: 66.41%] [G loss: 0.676779]\n",
      "epoch:27 step:25782 [D loss: 0.467847, acc.: 75.00%] [G loss: 0.766123]\n",
      "epoch:27 step:25783 [D loss: 0.517141, acc.: 70.31%] [G loss: 1.021118]\n",
      "epoch:27 step:25784 [D loss: 0.519941, acc.: 74.22%] [G loss: 0.776314]\n",
      "epoch:27 step:25785 [D loss: 0.598265, acc.: 66.41%] [G loss: 0.735172]\n",
      "epoch:27 step:25786 [D loss: 0.575419, acc.: 67.97%] [G loss: 0.651931]\n",
      "epoch:27 step:25787 [D loss: 0.507668, acc.: 73.44%] [G loss: 0.596779]\n",
      "epoch:27 step:25788 [D loss: 0.539674, acc.: 71.88%] [G loss: 0.838922]\n",
      "epoch:27 step:25789 [D loss: 0.558683, acc.: 71.09%] [G loss: 0.663787]\n",
      "epoch:27 step:25790 [D loss: 0.533397, acc.: 70.31%] [G loss: 0.557971]\n",
      "epoch:27 step:25791 [D loss: 0.584410, acc.: 64.84%] [G loss: 0.691228]\n",
      "epoch:27 step:25792 [D loss: 0.583258, acc.: 67.97%] [G loss: 0.615077]\n",
      "epoch:27 step:25793 [D loss: 0.537014, acc.: 73.44%] [G loss: 0.576827]\n",
      "epoch:27 step:25794 [D loss: 0.486991, acc.: 75.00%] [G loss: 0.788806]\n",
      "epoch:27 step:25795 [D loss: 0.493690, acc.: 77.34%] [G loss: 0.837502]\n",
      "epoch:27 step:25796 [D loss: 0.553316, acc.: 75.00%] [G loss: 0.902413]\n",
      "epoch:27 step:25797 [D loss: 0.532589, acc.: 69.53%] [G loss: 0.869429]\n",
      "epoch:27 step:25798 [D loss: 0.541176, acc.: 74.22%] [G loss: 0.757839]\n",
      "epoch:27 step:25799 [D loss: 0.566194, acc.: 69.53%] [G loss: 0.836886]\n",
      "epoch:27 step:25800 [D loss: 0.583922, acc.: 68.75%] [G loss: 0.726444]\n",
      "##############\n",
      "[2.94629235 1.28762167 6.12646973 5.0267043  3.63314781 5.65679713\n",
      " 4.63571714 4.62726724 4.77318076 4.11968342]\n",
      "##########\n",
      "epoch:27 step:25801 [D loss: 0.612965, acc.: 58.59%] [G loss: 0.659487]\n",
      "epoch:27 step:25802 [D loss: 0.497633, acc.: 75.00%] [G loss: 0.817336]\n",
      "epoch:27 step:25803 [D loss: 0.427855, acc.: 81.25%] [G loss: 0.769232]\n",
      "epoch:27 step:25804 [D loss: 0.481517, acc.: 74.22%] [G loss: 0.823936]\n",
      "epoch:27 step:25805 [D loss: 0.474022, acc.: 76.56%] [G loss: 0.863261]\n",
      "epoch:27 step:25806 [D loss: 0.487418, acc.: 76.56%] [G loss: 1.048730]\n",
      "epoch:27 step:25807 [D loss: 0.459133, acc.: 78.12%] [G loss: 1.073089]\n",
      "epoch:27 step:25808 [D loss: 0.495591, acc.: 75.00%] [G loss: 0.957418]\n",
      "epoch:27 step:25809 [D loss: 0.608359, acc.: 69.53%] [G loss: 0.637973]\n",
      "epoch:27 step:25810 [D loss: 0.673728, acc.: 57.03%] [G loss: 0.725026]\n",
      "epoch:27 step:25811 [D loss: 0.555906, acc.: 71.88%] [G loss: 0.662241]\n",
      "epoch:27 step:25812 [D loss: 0.541125, acc.: 74.22%] [G loss: 0.619724]\n",
      "epoch:27 step:25813 [D loss: 0.531361, acc.: 65.62%] [G loss: 0.897840]\n",
      "epoch:27 step:25814 [D loss: 0.511395, acc.: 71.09%] [G loss: 0.778757]\n",
      "epoch:27 step:25815 [D loss: 0.442700, acc.: 82.81%] [G loss: 0.861895]\n",
      "epoch:27 step:25816 [D loss: 0.491568, acc.: 74.22%] [G loss: 0.845819]\n",
      "epoch:27 step:25817 [D loss: 0.477287, acc.: 78.91%] [G loss: 0.827509]\n",
      "epoch:27 step:25818 [D loss: 0.468479, acc.: 77.34%] [G loss: 0.816096]\n",
      "epoch:27 step:25819 [D loss: 0.513057, acc.: 69.53%] [G loss: 0.785559]\n",
      "epoch:27 step:25820 [D loss: 0.554162, acc.: 71.09%] [G loss: 0.609101]\n",
      "epoch:27 step:25821 [D loss: 0.502409, acc.: 74.22%] [G loss: 0.882651]\n",
      "epoch:27 step:25822 [D loss: 0.531341, acc.: 70.31%] [G loss: 0.874019]\n",
      "epoch:27 step:25823 [D loss: 0.513066, acc.: 73.44%] [G loss: 0.648547]\n",
      "epoch:27 step:25824 [D loss: 0.574799, acc.: 67.97%] [G loss: 0.658301]\n",
      "epoch:27 step:25825 [D loss: 0.502091, acc.: 75.00%] [G loss: 0.713277]\n",
      "epoch:27 step:25826 [D loss: 0.515605, acc.: 71.09%] [G loss: 0.792615]\n",
      "epoch:27 step:25827 [D loss: 0.622730, acc.: 66.41%] [G loss: 0.665225]\n",
      "epoch:27 step:25828 [D loss: 0.554473, acc.: 67.97%] [G loss: 0.674209]\n",
      "epoch:27 step:25829 [D loss: 0.539248, acc.: 71.88%] [G loss: 0.755897]\n",
      "epoch:27 step:25830 [D loss: 0.557577, acc.: 67.97%] [G loss: 0.731262]\n",
      "epoch:27 step:25831 [D loss: 0.562137, acc.: 67.19%] [G loss: 0.575154]\n",
      "epoch:27 step:25832 [D loss: 0.549759, acc.: 74.22%] [G loss: 0.628501]\n",
      "epoch:27 step:25833 [D loss: 0.499341, acc.: 74.22%] [G loss: 0.758313]\n",
      "epoch:27 step:25834 [D loss: 0.557259, acc.: 67.19%] [G loss: 0.711717]\n",
      "epoch:27 step:25835 [D loss: 0.493473, acc.: 70.31%] [G loss: 0.571889]\n",
      "epoch:27 step:25836 [D loss: 0.582399, acc.: 64.84%] [G loss: 0.668519]\n",
      "epoch:27 step:25837 [D loss: 0.576823, acc.: 67.97%] [G loss: 0.802876]\n",
      "epoch:27 step:25838 [D loss: 0.514027, acc.: 71.09%] [G loss: 0.624980]\n",
      "epoch:27 step:25839 [D loss: 0.529832, acc.: 67.19%] [G loss: 0.588168]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:27 step:25840 [D loss: 0.550318, acc.: 68.75%] [G loss: 0.700400]\n",
      "epoch:27 step:25841 [D loss: 0.591913, acc.: 67.97%] [G loss: 0.546664]\n",
      "epoch:27 step:25842 [D loss: 0.527794, acc.: 70.31%] [G loss: 0.660408]\n",
      "epoch:27 step:25843 [D loss: 0.550704, acc.: 72.66%] [G loss: 0.740172]\n",
      "epoch:27 step:25844 [D loss: 0.492259, acc.: 73.44%] [G loss: 0.935076]\n",
      "epoch:27 step:25845 [D loss: 0.433909, acc.: 78.91%] [G loss: 0.993711]\n",
      "epoch:27 step:25846 [D loss: 0.591084, acc.: 69.53%] [G loss: 0.896933]\n",
      "epoch:27 step:25847 [D loss: 0.468436, acc.: 80.47%] [G loss: 0.714397]\n",
      "epoch:27 step:25848 [D loss: 0.507400, acc.: 75.00%] [G loss: 0.687034]\n",
      "epoch:27 step:25849 [D loss: 0.558017, acc.: 67.19%] [G loss: 0.771028]\n",
      "epoch:27 step:25850 [D loss: 0.489647, acc.: 78.91%] [G loss: 0.828434]\n",
      "epoch:27 step:25851 [D loss: 0.549256, acc.: 69.53%] [G loss: 0.849709]\n",
      "epoch:27 step:25852 [D loss: 0.570087, acc.: 69.53%] [G loss: 0.749365]\n",
      "epoch:27 step:25853 [D loss: 0.450189, acc.: 80.47%] [G loss: 0.771156]\n",
      "epoch:27 step:25854 [D loss: 0.455141, acc.: 76.56%] [G loss: 0.791109]\n",
      "epoch:27 step:25855 [D loss: 0.505292, acc.: 75.00%] [G loss: 0.792279]\n",
      "epoch:27 step:25856 [D loss: 0.478140, acc.: 77.34%] [G loss: 0.693767]\n",
      "epoch:27 step:25857 [D loss: 0.471584, acc.: 75.00%] [G loss: 0.778468]\n",
      "epoch:27 step:25858 [D loss: 0.581565, acc.: 68.75%] [G loss: 0.667106]\n",
      "epoch:27 step:25859 [D loss: 0.509640, acc.: 73.44%] [G loss: 0.562621]\n",
      "epoch:27 step:25860 [D loss: 0.563585, acc.: 64.06%] [G loss: 0.700944]\n",
      "epoch:27 step:25861 [D loss: 0.545908, acc.: 71.88%] [G loss: 0.536592]\n",
      "epoch:27 step:25862 [D loss: 0.520717, acc.: 71.09%] [G loss: 0.577027]\n",
      "epoch:27 step:25863 [D loss: 0.436349, acc.: 78.12%] [G loss: 0.773281]\n",
      "epoch:27 step:25864 [D loss: 0.549493, acc.: 73.44%] [G loss: 0.795470]\n",
      "epoch:27 step:25865 [D loss: 0.674040, acc.: 59.38%] [G loss: 0.588096]\n",
      "epoch:27 step:25866 [D loss: 0.532065, acc.: 70.31%] [G loss: 0.808134]\n",
      "epoch:27 step:25867 [D loss: 0.480526, acc.: 75.00%] [G loss: 0.824785]\n",
      "epoch:27 step:25868 [D loss: 0.502460, acc.: 73.44%] [G loss: 0.716955]\n",
      "epoch:27 step:25869 [D loss: 0.492819, acc.: 74.22%] [G loss: 0.639713]\n",
      "epoch:27 step:25870 [D loss: 0.581825, acc.: 67.19%] [G loss: 0.638351]\n",
      "epoch:27 step:25871 [D loss: 0.497853, acc.: 76.56%] [G loss: 0.817454]\n",
      "epoch:27 step:25872 [D loss: 0.567936, acc.: 70.31%] [G loss: 0.707898]\n",
      "epoch:27 step:25873 [D loss: 0.483047, acc.: 76.56%] [G loss: 0.771383]\n",
      "epoch:27 step:25874 [D loss: 0.484290, acc.: 76.56%] [G loss: 0.982799]\n",
      "epoch:27 step:25875 [D loss: 0.584740, acc.: 67.19%] [G loss: 0.677632]\n",
      "epoch:27 step:25876 [D loss: 0.552210, acc.: 72.66%] [G loss: 0.698052]\n",
      "epoch:27 step:25877 [D loss: 0.515441, acc.: 72.66%] [G loss: 0.682706]\n",
      "epoch:27 step:25878 [D loss: 0.525692, acc.: 72.66%] [G loss: 0.801577]\n",
      "epoch:27 step:25879 [D loss: 0.560182, acc.: 71.09%] [G loss: 0.659589]\n",
      "epoch:27 step:25880 [D loss: 0.565013, acc.: 68.75%] [G loss: 0.720934]\n",
      "epoch:27 step:25881 [D loss: 0.364228, acc.: 86.72%] [G loss: 1.083648]\n",
      "epoch:27 step:25882 [D loss: 0.569507, acc.: 67.97%] [G loss: 0.728568]\n",
      "epoch:27 step:25883 [D loss: 0.601967, acc.: 65.62%] [G loss: 0.765817]\n",
      "epoch:27 step:25884 [D loss: 0.566505, acc.: 70.31%] [G loss: 0.794349]\n",
      "epoch:27 step:25885 [D loss: 0.561596, acc.: 70.31%] [G loss: 0.630755]\n",
      "epoch:27 step:25886 [D loss: 0.529726, acc.: 72.66%] [G loss: 0.561920]\n",
      "epoch:27 step:25887 [D loss: 0.531060, acc.: 69.53%] [G loss: 0.646580]\n",
      "epoch:27 step:25888 [D loss: 0.471093, acc.: 76.56%] [G loss: 0.950152]\n",
      "epoch:27 step:25889 [D loss: 0.555984, acc.: 64.06%] [G loss: 0.716034]\n",
      "epoch:27 step:25890 [D loss: 0.569729, acc.: 70.31%] [G loss: 0.740050]\n",
      "epoch:27 step:25891 [D loss: 0.469928, acc.: 79.69%] [G loss: 0.683363]\n",
      "epoch:27 step:25892 [D loss: 0.470978, acc.: 80.47%] [G loss: 0.703425]\n",
      "epoch:27 step:25893 [D loss: 0.558946, acc.: 71.09%] [G loss: 0.773520]\n",
      "epoch:27 step:25894 [D loss: 0.589818, acc.: 68.75%] [G loss: 0.656449]\n",
      "epoch:27 step:25895 [D loss: 0.519906, acc.: 71.09%] [G loss: 0.726310]\n",
      "epoch:27 step:25896 [D loss: 0.571797, acc.: 66.41%] [G loss: 0.696990]\n",
      "epoch:27 step:25897 [D loss: 0.459526, acc.: 78.91%] [G loss: 0.751156]\n",
      "epoch:27 step:25898 [D loss: 0.527552, acc.: 68.75%] [G loss: 0.827998]\n",
      "epoch:27 step:25899 [D loss: 0.577335, acc.: 66.41%] [G loss: 0.672321]\n",
      "epoch:27 step:25900 [D loss: 0.510375, acc.: 75.00%] [G loss: 1.015631]\n",
      "epoch:27 step:25901 [D loss: 0.511925, acc.: 72.66%] [G loss: 0.796132]\n",
      "epoch:27 step:25902 [D loss: 0.463573, acc.: 77.34%] [G loss: 0.835548]\n",
      "epoch:27 step:25903 [D loss: 0.518383, acc.: 74.22%] [G loss: 0.567614]\n",
      "epoch:27 step:25904 [D loss: 0.392265, acc.: 83.59%] [G loss: 0.815476]\n",
      "epoch:27 step:25905 [D loss: 0.624443, acc.: 66.41%] [G loss: 0.740767]\n",
      "epoch:27 step:25906 [D loss: 0.562796, acc.: 71.09%] [G loss: 0.616179]\n",
      "epoch:27 step:25907 [D loss: 0.567021, acc.: 69.53%] [G loss: 0.774860]\n",
      "epoch:27 step:25908 [D loss: 0.566544, acc.: 66.41%] [G loss: 0.657989]\n",
      "epoch:27 step:25909 [D loss: 0.570573, acc.: 69.53%] [G loss: 0.566281]\n",
      "epoch:27 step:25910 [D loss: 0.509210, acc.: 74.22%] [G loss: 0.489797]\n",
      "epoch:27 step:25911 [D loss: 0.538588, acc.: 71.88%] [G loss: 0.607405]\n",
      "epoch:27 step:25912 [D loss: 0.511941, acc.: 68.75%] [G loss: 0.599870]\n",
      "epoch:27 step:25913 [D loss: 0.586888, acc.: 62.50%] [G loss: 0.723157]\n",
      "epoch:27 step:25914 [D loss: 0.566945, acc.: 66.41%] [G loss: 0.841735]\n",
      "epoch:27 step:25915 [D loss: 0.547796, acc.: 70.31%] [G loss: 0.698401]\n",
      "epoch:27 step:25916 [D loss: 0.522371, acc.: 72.66%] [G loss: 0.828126]\n",
      "epoch:27 step:25917 [D loss: 0.489851, acc.: 76.56%] [G loss: 0.890219]\n",
      "epoch:27 step:25918 [D loss: 0.577506, acc.: 67.97%] [G loss: 0.870856]\n",
      "epoch:27 step:25919 [D loss: 0.542582, acc.: 71.88%] [G loss: 0.688772]\n",
      "epoch:27 step:25920 [D loss: 0.576248, acc.: 71.09%] [G loss: 0.605423]\n",
      "epoch:27 step:25921 [D loss: 0.571938, acc.: 71.09%] [G loss: 0.676848]\n",
      "epoch:27 step:25922 [D loss: 0.492711, acc.: 75.00%] [G loss: 0.631759]\n",
      "epoch:27 step:25923 [D loss: 0.474690, acc.: 76.56%] [G loss: 0.894220]\n",
      "epoch:27 step:25924 [D loss: 0.632710, acc.: 60.16%] [G loss: 0.718367]\n",
      "epoch:27 step:25925 [D loss: 0.549061, acc.: 69.53%] [G loss: 0.643313]\n",
      "epoch:27 step:25926 [D loss: 0.542306, acc.: 67.97%] [G loss: 0.559686]\n",
      "epoch:27 step:25927 [D loss: 0.503327, acc.: 71.88%] [G loss: 0.670940]\n",
      "epoch:27 step:25928 [D loss: 0.533630, acc.: 72.66%] [G loss: 0.647503]\n",
      "epoch:27 step:25929 [D loss: 0.539162, acc.: 71.09%] [G loss: 0.713600]\n",
      "epoch:27 step:25930 [D loss: 0.452594, acc.: 79.69%] [G loss: 0.784852]\n",
      "epoch:27 step:25931 [D loss: 0.528302, acc.: 71.88%] [G loss: 0.745592]\n",
      "epoch:27 step:25932 [D loss: 0.536556, acc.: 68.75%] [G loss: 0.796233]\n",
      "epoch:27 step:25933 [D loss: 0.478977, acc.: 75.78%] [G loss: 0.770488]\n",
      "epoch:27 step:25934 [D loss: 0.518209, acc.: 71.88%] [G loss: 0.642346]\n",
      "epoch:27 step:25935 [D loss: 0.630615, acc.: 64.06%] [G loss: 0.761992]\n",
      "epoch:27 step:25936 [D loss: 0.532910, acc.: 69.53%] [G loss: 0.639998]\n",
      "epoch:27 step:25937 [D loss: 0.505347, acc.: 75.00%] [G loss: 0.625002]\n",
      "epoch:27 step:25938 [D loss: 0.497584, acc.: 73.44%] [G loss: 0.704825]\n",
      "epoch:27 step:25939 [D loss: 0.560723, acc.: 69.53%] [G loss: 0.803862]\n",
      "epoch:27 step:25940 [D loss: 0.469720, acc.: 77.34%] [G loss: 0.907481]\n",
      "epoch:27 step:25941 [D loss: 0.453021, acc.: 79.69%] [G loss: 0.883248]\n",
      "epoch:27 step:25942 [D loss: 0.565885, acc.: 65.62%] [G loss: 0.932170]\n",
      "epoch:27 step:25943 [D loss: 0.556244, acc.: 70.31%] [G loss: 0.700786]\n",
      "epoch:27 step:25944 [D loss: 0.539581, acc.: 71.09%] [G loss: 0.659295]\n",
      "epoch:27 step:25945 [D loss: 0.510330, acc.: 75.78%] [G loss: 0.778581]\n",
      "epoch:27 step:25946 [D loss: 0.417295, acc.: 79.69%] [G loss: 0.716973]\n",
      "epoch:27 step:25947 [D loss: 0.371836, acc.: 82.03%] [G loss: 0.840324]\n",
      "epoch:27 step:25948 [D loss: 0.480227, acc.: 76.56%] [G loss: 0.907610]\n",
      "epoch:27 step:25949 [D loss: 0.462564, acc.: 77.34%] [G loss: 1.068704]\n",
      "epoch:27 step:25950 [D loss: 0.507872, acc.: 73.44%] [G loss: 1.027197]\n",
      "epoch:27 step:25951 [D loss: 0.641258, acc.: 61.72%] [G loss: 0.814322]\n",
      "epoch:27 step:25952 [D loss: 0.616441, acc.: 64.84%] [G loss: 0.764313]\n",
      "epoch:27 step:25953 [D loss: 0.492548, acc.: 72.66%] [G loss: 0.728017]\n",
      "epoch:27 step:25954 [D loss: 0.526165, acc.: 73.44%] [G loss: 0.844314]\n",
      "epoch:27 step:25955 [D loss: 0.554493, acc.: 71.09%] [G loss: 0.754999]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:27 step:25956 [D loss: 0.497663, acc.: 75.78%] [G loss: 0.667454]\n",
      "epoch:27 step:25957 [D loss: 0.523617, acc.: 70.31%] [G loss: 0.914654]\n",
      "epoch:27 step:25958 [D loss: 0.527325, acc.: 71.88%] [G loss: 0.801789]\n",
      "epoch:27 step:25959 [D loss: 0.520196, acc.: 75.00%] [G loss: 0.715453]\n",
      "epoch:27 step:25960 [D loss: 0.458677, acc.: 78.91%] [G loss: 0.756220]\n",
      "epoch:27 step:25961 [D loss: 0.523725, acc.: 70.31%] [G loss: 0.651719]\n",
      "epoch:27 step:25962 [D loss: 0.523077, acc.: 71.09%] [G loss: 0.633541]\n",
      "epoch:27 step:25963 [D loss: 0.544635, acc.: 72.66%] [G loss: 0.735982]\n",
      "epoch:27 step:25964 [D loss: 0.617763, acc.: 63.28%] [G loss: 0.821780]\n",
      "epoch:27 step:25965 [D loss: 0.538806, acc.: 71.09%] [G loss: 0.722829]\n",
      "epoch:27 step:25966 [D loss: 0.541980, acc.: 74.22%] [G loss: 0.882653]\n",
      "epoch:27 step:25967 [D loss: 0.567116, acc.: 66.41%] [G loss: 0.674224]\n",
      "epoch:27 step:25968 [D loss: 0.539686, acc.: 65.62%] [G loss: 0.744133]\n",
      "epoch:27 step:25969 [D loss: 0.504489, acc.: 70.31%] [G loss: 0.813195]\n",
      "epoch:27 step:25970 [D loss: 0.524987, acc.: 70.31%] [G loss: 0.827881]\n",
      "epoch:27 step:25971 [D loss: 0.474309, acc.: 76.56%] [G loss: 0.871004]\n",
      "epoch:27 step:25972 [D loss: 0.601872, acc.: 63.28%] [G loss: 0.702846]\n",
      "epoch:27 step:25973 [D loss: 0.534332, acc.: 69.53%] [G loss: 0.739367]\n",
      "epoch:27 step:25974 [D loss: 0.604244, acc.: 64.06%] [G loss: 0.520918]\n",
      "epoch:27 step:25975 [D loss: 0.488790, acc.: 75.78%] [G loss: 0.678921]\n",
      "epoch:27 step:25976 [D loss: 0.482150, acc.: 78.12%] [G loss: 0.692761]\n",
      "epoch:27 step:25977 [D loss: 0.521356, acc.: 78.91%] [G loss: 0.656241]\n",
      "epoch:27 step:25978 [D loss: 0.536206, acc.: 70.31%] [G loss: 0.660666]\n",
      "epoch:27 step:25979 [D loss: 0.554324, acc.: 68.75%] [G loss: 0.950480]\n",
      "epoch:27 step:25980 [D loss: 0.509744, acc.: 74.22%] [G loss: 0.965585]\n",
      "epoch:27 step:25981 [D loss: 0.559501, acc.: 72.66%] [G loss: 0.625372]\n",
      "epoch:27 step:25982 [D loss: 0.526827, acc.: 71.88%] [G loss: 0.748566]\n",
      "epoch:27 step:25983 [D loss: 0.638822, acc.: 62.50%] [G loss: 0.501210]\n",
      "epoch:27 step:25984 [D loss: 0.510188, acc.: 70.31%] [G loss: 0.618130]\n",
      "epoch:27 step:25985 [D loss: 0.586473, acc.: 63.28%] [G loss: 0.569130]\n",
      "epoch:27 step:25986 [D loss: 0.555586, acc.: 68.75%] [G loss: 0.647790]\n",
      "epoch:27 step:25987 [D loss: 0.568412, acc.: 69.53%] [G loss: 0.506590]\n",
      "epoch:27 step:25988 [D loss: 0.583168, acc.: 66.41%] [G loss: 0.652884]\n",
      "epoch:27 step:25989 [D loss: 0.445619, acc.: 79.69%] [G loss: 0.755236]\n",
      "epoch:27 step:25990 [D loss: 0.472918, acc.: 79.69%] [G loss: 0.733829]\n",
      "epoch:27 step:25991 [D loss: 0.491234, acc.: 75.78%] [G loss: 0.858273]\n",
      "epoch:27 step:25992 [D loss: 0.467416, acc.: 80.47%] [G loss: 0.823960]\n",
      "epoch:27 step:25993 [D loss: 0.466950, acc.: 74.22%] [G loss: 0.800526]\n",
      "epoch:27 step:25994 [D loss: 0.474992, acc.: 76.56%] [G loss: 0.806871]\n",
      "epoch:27 step:25995 [D loss: 0.554740, acc.: 67.19%] [G loss: 0.609229]\n",
      "epoch:27 step:25996 [D loss: 0.569497, acc.: 66.41%] [G loss: 0.580733]\n",
      "epoch:27 step:25997 [D loss: 0.536505, acc.: 64.06%] [G loss: 0.639657]\n",
      "epoch:27 step:25998 [D loss: 0.523492, acc.: 72.66%] [G loss: 0.773517]\n",
      "epoch:27 step:25999 [D loss: 0.553240, acc.: 69.53%] [G loss: 0.692924]\n",
      "epoch:27 step:26000 [D loss: 0.492756, acc.: 75.00%] [G loss: 0.784788]\n",
      "##############\n",
      "[3.03641491 1.18983136 6.23466813 4.77362098 3.87126973 5.66768495\n",
      " 4.46882501 5.12328194 4.70740048 4.31870411]\n",
      "##########\n",
      "epoch:27 step:26001 [D loss: 0.570651, acc.: 67.19%] [G loss: 0.681654]\n",
      "epoch:27 step:26002 [D loss: 0.631302, acc.: 60.16%] [G loss: 0.688821]\n",
      "epoch:27 step:26003 [D loss: 0.526636, acc.: 74.22%] [G loss: 0.632266]\n",
      "epoch:27 step:26004 [D loss: 0.480275, acc.: 76.56%] [G loss: 0.689777]\n",
      "epoch:27 step:26005 [D loss: 0.578344, acc.: 69.53%] [G loss: 0.606246]\n",
      "epoch:27 step:26006 [D loss: 0.525621, acc.: 71.88%] [G loss: 0.664004]\n",
      "epoch:27 step:26007 [D loss: 0.455011, acc.: 84.38%] [G loss: 0.950208]\n",
      "epoch:27 step:26008 [D loss: 0.564147, acc.: 69.53%] [G loss: 0.733505]\n",
      "epoch:27 step:26009 [D loss: 0.555234, acc.: 70.31%] [G loss: 0.682311]\n",
      "epoch:27 step:26010 [D loss: 0.565394, acc.: 67.19%] [G loss: 0.795505]\n",
      "epoch:27 step:26011 [D loss: 0.519925, acc.: 73.44%] [G loss: 0.774227]\n",
      "epoch:27 step:26012 [D loss: 0.588358, acc.: 65.62%] [G loss: 0.677793]\n",
      "epoch:27 step:26013 [D loss: 0.511862, acc.: 70.31%] [G loss: 0.704989]\n",
      "epoch:27 step:26014 [D loss: 0.521936, acc.: 73.44%] [G loss: 0.736155]\n",
      "epoch:27 step:26015 [D loss: 0.584985, acc.: 64.06%] [G loss: 0.651552]\n",
      "epoch:27 step:26016 [D loss: 0.594273, acc.: 66.41%] [G loss: 0.640965]\n",
      "epoch:27 step:26017 [D loss: 0.524834, acc.: 71.88%] [G loss: 0.752295]\n",
      "epoch:27 step:26018 [D loss: 0.560048, acc.: 67.19%] [G loss: 0.708833]\n",
      "epoch:27 step:26019 [D loss: 0.535020, acc.: 75.00%] [G loss: 0.735427]\n",
      "epoch:27 step:26020 [D loss: 0.540157, acc.: 71.09%] [G loss: 0.610912]\n",
      "epoch:27 step:26021 [D loss: 0.503853, acc.: 78.12%] [G loss: 0.747746]\n",
      "epoch:27 step:26022 [D loss: 0.519917, acc.: 74.22%] [G loss: 0.765596]\n",
      "epoch:27 step:26023 [D loss: 0.468317, acc.: 77.34%] [G loss: 0.675705]\n",
      "epoch:27 step:26024 [D loss: 0.475563, acc.: 75.00%] [G loss: 0.866002]\n",
      "epoch:27 step:26025 [D loss: 0.544797, acc.: 71.09%] [G loss: 0.835128]\n",
      "epoch:27 step:26026 [D loss: 0.568494, acc.: 66.41%] [G loss: 0.592353]\n",
      "epoch:27 step:26027 [D loss: 0.505786, acc.: 73.44%] [G loss: 0.824678]\n",
      "epoch:27 step:26028 [D loss: 0.523277, acc.: 69.53%] [G loss: 0.856820]\n",
      "epoch:27 step:26029 [D loss: 0.446415, acc.: 77.34%] [G loss: 0.764439]\n",
      "epoch:27 step:26030 [D loss: 0.657878, acc.: 60.16%] [G loss: 0.589443]\n",
      "epoch:27 step:26031 [D loss: 0.526169, acc.: 73.44%] [G loss: 0.605352]\n",
      "epoch:27 step:26032 [D loss: 0.574239, acc.: 70.31%] [G loss: 0.657940]\n",
      "epoch:27 step:26033 [D loss: 0.497314, acc.: 75.00%] [G loss: 0.695479]\n",
      "epoch:27 step:26034 [D loss: 0.562372, acc.: 68.75%] [G loss: 0.603407]\n",
      "epoch:27 step:26035 [D loss: 0.534427, acc.: 71.09%] [G loss: 0.722014]\n",
      "epoch:27 step:26036 [D loss: 0.514696, acc.: 73.44%] [G loss: 0.648486]\n",
      "epoch:27 step:26037 [D loss: 0.506795, acc.: 72.66%] [G loss: 0.559225]\n",
      "epoch:27 step:26038 [D loss: 0.523758, acc.: 71.88%] [G loss: 0.616073]\n",
      "epoch:27 step:26039 [D loss: 0.634774, acc.: 56.25%] [G loss: 0.577550]\n",
      "epoch:27 step:26040 [D loss: 0.573815, acc.: 67.97%] [G loss: 0.609911]\n",
      "epoch:27 step:26041 [D loss: 0.583780, acc.: 64.84%] [G loss: 0.565863]\n",
      "epoch:27 step:26042 [D loss: 0.459924, acc.: 77.34%] [G loss: 0.832841]\n",
      "epoch:27 step:26043 [D loss: 0.559059, acc.: 70.31%] [G loss: 0.684315]\n",
      "epoch:27 step:26044 [D loss: 0.635201, acc.: 63.28%] [G loss: 0.815082]\n",
      "epoch:27 step:26045 [D loss: 0.480709, acc.: 77.34%] [G loss: 0.739986]\n",
      "epoch:27 step:26046 [D loss: 0.451706, acc.: 78.91%] [G loss: 0.928240]\n",
      "epoch:27 step:26047 [D loss: 0.529587, acc.: 69.53%] [G loss: 0.815637]\n",
      "epoch:27 step:26048 [D loss: 0.539639, acc.: 75.78%] [G loss: 0.689551]\n",
      "epoch:27 step:26049 [D loss: 0.514409, acc.: 72.66%] [G loss: 0.827994]\n",
      "epoch:27 step:26050 [D loss: 0.503748, acc.: 75.00%] [G loss: 0.841114]\n",
      "epoch:27 step:26051 [D loss: 0.555108, acc.: 70.31%] [G loss: 0.742145]\n",
      "epoch:27 step:26052 [D loss: 0.518723, acc.: 74.22%] [G loss: 0.750174]\n",
      "epoch:27 step:26053 [D loss: 0.523033, acc.: 71.09%] [G loss: 0.759538]\n",
      "epoch:27 step:26054 [D loss: 0.516180, acc.: 69.53%] [G loss: 0.791055]\n",
      "epoch:27 step:26055 [D loss: 0.570564, acc.: 67.19%] [G loss: 0.746207]\n",
      "epoch:27 step:26056 [D loss: 0.594879, acc.: 66.41%] [G loss: 0.659215]\n",
      "epoch:27 step:26057 [D loss: 0.561987, acc.: 72.66%] [G loss: 0.563461]\n",
      "epoch:27 step:26058 [D loss: 0.557829, acc.: 70.31%] [G loss: 0.558832]\n",
      "epoch:27 step:26059 [D loss: 0.505922, acc.: 70.31%] [G loss: 0.793236]\n",
      "epoch:27 step:26060 [D loss: 0.585010, acc.: 66.41%] [G loss: 0.705272]\n",
      "epoch:27 step:26061 [D loss: 0.602906, acc.: 65.62%] [G loss: 0.825184]\n",
      "epoch:27 step:26062 [D loss: 0.564287, acc.: 65.62%] [G loss: 0.730127]\n",
      "epoch:27 step:26063 [D loss: 0.534326, acc.: 70.31%] [G loss: 0.737969]\n",
      "epoch:27 step:26064 [D loss: 0.585390, acc.: 69.53%] [G loss: 0.544030]\n",
      "epoch:27 step:26065 [D loss: 0.580849, acc.: 67.97%] [G loss: 0.620577]\n",
      "epoch:27 step:26066 [D loss: 0.536381, acc.: 71.09%] [G loss: 0.623443]\n",
      "epoch:27 step:26067 [D loss: 0.606360, acc.: 71.09%] [G loss: 0.799548]\n",
      "epoch:27 step:26068 [D loss: 0.496431, acc.: 78.12%] [G loss: 1.063889]\n",
      "epoch:27 step:26069 [D loss: 0.496115, acc.: 75.00%] [G loss: 0.932692]\n",
      "epoch:27 step:26070 [D loss: 0.508544, acc.: 75.00%] [G loss: 0.726874]\n",
      "epoch:27 step:26071 [D loss: 0.601368, acc.: 66.41%] [G loss: 0.633669]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:27 step:26072 [D loss: 0.605572, acc.: 68.75%] [G loss: 0.674943]\n",
      "epoch:27 step:26073 [D loss: 0.520741, acc.: 71.09%] [G loss: 0.625934]\n",
      "epoch:27 step:26074 [D loss: 0.520255, acc.: 74.22%] [G loss: 0.702061]\n",
      "epoch:27 step:26075 [D loss: 0.597091, acc.: 66.41%] [G loss: 0.726425]\n",
      "epoch:27 step:26076 [D loss: 0.560548, acc.: 70.31%] [G loss: 0.629538]\n",
      "epoch:27 step:26077 [D loss: 0.557532, acc.: 68.75%] [G loss: 0.540009]\n",
      "epoch:27 step:26078 [D loss: 0.518964, acc.: 73.44%] [G loss: 0.621522]\n",
      "epoch:27 step:26079 [D loss: 0.503369, acc.: 75.00%] [G loss: 0.983031]\n",
      "epoch:27 step:26080 [D loss: 0.435050, acc.: 82.81%] [G loss: 0.994819]\n",
      "epoch:27 step:26081 [D loss: 0.514985, acc.: 75.78%] [G loss: 1.024475]\n",
      "epoch:27 step:26082 [D loss: 0.539356, acc.: 75.78%] [G loss: 0.928814]\n",
      "epoch:27 step:26083 [D loss: 0.590816, acc.: 67.19%] [G loss: 0.548420]\n",
      "epoch:27 step:26084 [D loss: 0.544705, acc.: 71.09%] [G loss: 0.742728]\n",
      "epoch:27 step:26085 [D loss: 0.533388, acc.: 72.66%] [G loss: 0.713730]\n",
      "epoch:27 step:26086 [D loss: 0.533183, acc.: 71.88%] [G loss: 0.842176]\n",
      "epoch:27 step:26087 [D loss: 0.662022, acc.: 58.59%] [G loss: 0.703573]\n",
      "epoch:27 step:26088 [D loss: 0.491270, acc.: 72.66%] [G loss: 0.620327]\n",
      "epoch:27 step:26089 [D loss: 0.539312, acc.: 68.75%] [G loss: 0.742080]\n",
      "epoch:27 step:26090 [D loss: 0.504291, acc.: 77.34%] [G loss: 0.726582]\n",
      "epoch:27 step:26091 [D loss: 0.494675, acc.: 76.56%] [G loss: 0.910283]\n",
      "epoch:27 step:26092 [D loss: 0.589147, acc.: 64.84%] [G loss: 0.747808]\n",
      "epoch:27 step:26093 [D loss: 0.612353, acc.: 65.62%] [G loss: 0.711963]\n",
      "epoch:27 step:26094 [D loss: 0.494614, acc.: 76.56%] [G loss: 0.886874]\n",
      "epoch:27 step:26095 [D loss: 0.543869, acc.: 71.88%] [G loss: 0.823905]\n",
      "epoch:27 step:26096 [D loss: 0.491068, acc.: 75.78%] [G loss: 0.992596]\n",
      "epoch:27 step:26097 [D loss: 0.510118, acc.: 71.09%] [G loss: 0.766677]\n",
      "epoch:27 step:26098 [D loss: 0.551410, acc.: 72.66%] [G loss: 0.693158]\n",
      "epoch:27 step:26099 [D loss: 0.556734, acc.: 67.19%] [G loss: 0.724589]\n",
      "epoch:27 step:26100 [D loss: 0.558926, acc.: 68.75%] [G loss: 0.704316]\n",
      "epoch:27 step:26101 [D loss: 0.503431, acc.: 80.47%] [G loss: 0.613317]\n",
      "epoch:27 step:26102 [D loss: 0.524125, acc.: 72.66%] [G loss: 0.719878]\n",
      "epoch:27 step:26103 [D loss: 0.522227, acc.: 71.88%] [G loss: 0.771952]\n",
      "epoch:27 step:26104 [D loss: 0.524280, acc.: 73.44%] [G loss: 0.563192]\n",
      "epoch:27 step:26105 [D loss: 0.548811, acc.: 62.50%] [G loss: 0.603585]\n",
      "epoch:27 step:26106 [D loss: 0.506626, acc.: 75.78%] [G loss: 0.705200]\n",
      "epoch:27 step:26107 [D loss: 0.582889, acc.: 67.97%] [G loss: 0.647569]\n",
      "epoch:27 step:26108 [D loss: 0.495528, acc.: 71.09%] [G loss: 0.640041]\n",
      "epoch:27 step:26109 [D loss: 0.519405, acc.: 73.44%] [G loss: 0.734952]\n",
      "epoch:27 step:26110 [D loss: 0.506265, acc.: 80.47%] [G loss: 0.741014]\n",
      "epoch:27 step:26111 [D loss: 0.653696, acc.: 60.16%] [G loss: 0.521991]\n",
      "epoch:27 step:26112 [D loss: 0.513628, acc.: 75.00%] [G loss: 0.497128]\n",
      "epoch:27 step:26113 [D loss: 0.477421, acc.: 73.44%] [G loss: 0.668113]\n",
      "epoch:27 step:26114 [D loss: 0.504748, acc.: 74.22%] [G loss: 0.740063]\n",
      "epoch:27 step:26115 [D loss: 0.519790, acc.: 75.00%] [G loss: 0.815608]\n",
      "epoch:27 step:26116 [D loss: 0.604738, acc.: 68.75%] [G loss: 0.725513]\n",
      "epoch:27 step:26117 [D loss: 0.539624, acc.: 71.09%] [G loss: 0.591537]\n",
      "epoch:27 step:26118 [D loss: 0.529792, acc.: 70.31%] [G loss: 0.668379]\n",
      "epoch:27 step:26119 [D loss: 0.582750, acc.: 67.97%] [G loss: 0.614012]\n",
      "epoch:27 step:26120 [D loss: 0.530061, acc.: 74.22%] [G loss: 0.647724]\n",
      "epoch:27 step:26121 [D loss: 0.533226, acc.: 71.09%] [G loss: 0.582430]\n",
      "epoch:27 step:26122 [D loss: 0.426886, acc.: 76.56%] [G loss: 0.724055]\n",
      "epoch:27 step:26123 [D loss: 0.573037, acc.: 65.62%] [G loss: 0.821117]\n",
      "epoch:27 step:26124 [D loss: 0.566091, acc.: 68.75%] [G loss: 0.622392]\n",
      "epoch:27 step:26125 [D loss: 0.516221, acc.: 72.66%] [G loss: 0.755170]\n",
      "epoch:27 step:26126 [D loss: 0.583507, acc.: 67.97%] [G loss: 0.591755]\n",
      "epoch:27 step:26127 [D loss: 0.623784, acc.: 64.06%] [G loss: 0.641676]\n",
      "epoch:27 step:26128 [D loss: 0.554263, acc.: 69.53%] [G loss: 0.878590]\n",
      "epoch:27 step:26129 [D loss: 0.554381, acc.: 70.31%] [G loss: 0.740331]\n",
      "epoch:27 step:26130 [D loss: 0.542271, acc.: 70.31%] [G loss: 0.752858]\n",
      "epoch:27 step:26131 [D loss: 0.537792, acc.: 72.66%] [G loss: 0.617773]\n",
      "epoch:27 step:26132 [D loss: 0.508485, acc.: 73.44%] [G loss: 0.736157]\n",
      "epoch:27 step:26133 [D loss: 0.508484, acc.: 66.41%] [G loss: 0.649815]\n",
      "epoch:27 step:26134 [D loss: 0.535822, acc.: 70.31%] [G loss: 0.625031]\n",
      "epoch:27 step:26135 [D loss: 0.549333, acc.: 71.09%] [G loss: 0.534872]\n",
      "epoch:27 step:26136 [D loss: 0.529179, acc.: 73.44%] [G loss: 0.567335]\n",
      "epoch:27 step:26137 [D loss: 0.547136, acc.: 69.53%] [G loss: 0.639604]\n",
      "epoch:27 step:26138 [D loss: 0.552720, acc.: 70.31%] [G loss: 0.676498]\n",
      "epoch:27 step:26139 [D loss: 0.556950, acc.: 73.44%] [G loss: 0.741596]\n",
      "epoch:27 step:26140 [D loss: 0.486820, acc.: 77.34%] [G loss: 0.642144]\n",
      "epoch:27 step:26141 [D loss: 0.489318, acc.: 73.44%] [G loss: 0.672544]\n",
      "epoch:27 step:26142 [D loss: 0.493853, acc.: 75.78%] [G loss: 0.768811]\n",
      "epoch:27 step:26143 [D loss: 0.535289, acc.: 75.00%] [G loss: 0.744533]\n",
      "epoch:27 step:26144 [D loss: 0.545638, acc.: 69.53%] [G loss: 0.878853]\n",
      "epoch:27 step:26145 [D loss: 0.550438, acc.: 69.53%] [G loss: 0.664768]\n",
      "epoch:27 step:26146 [D loss: 0.629907, acc.: 60.16%] [G loss: 0.446978]\n",
      "epoch:27 step:26147 [D loss: 0.585153, acc.: 64.84%] [G loss: 0.558572]\n",
      "epoch:27 step:26148 [D loss: 0.555339, acc.: 67.97%] [G loss: 0.654670]\n",
      "epoch:27 step:26149 [D loss: 0.517006, acc.: 74.22%] [G loss: 0.675470]\n",
      "epoch:27 step:26150 [D loss: 0.540177, acc.: 68.75%] [G loss: 0.748902]\n",
      "epoch:27 step:26151 [D loss: 0.585916, acc.: 64.84%] [G loss: 0.575155]\n",
      "epoch:27 step:26152 [D loss: 0.544151, acc.: 67.97%] [G loss: 0.870950]\n",
      "epoch:27 step:26153 [D loss: 0.518189, acc.: 71.88%] [G loss: 0.791503]\n",
      "epoch:27 step:26154 [D loss: 0.545814, acc.: 71.88%] [G loss: 0.690778]\n",
      "epoch:27 step:26155 [D loss: 0.600513, acc.: 65.62%] [G loss: 0.552237]\n",
      "epoch:27 step:26156 [D loss: 0.481270, acc.: 79.69%] [G loss: 0.742570]\n",
      "epoch:27 step:26157 [D loss: 0.608808, acc.: 63.28%] [G loss: 0.656260]\n",
      "epoch:27 step:26158 [D loss: 0.567741, acc.: 75.00%] [G loss: 0.793116]\n",
      "epoch:27 step:26159 [D loss: 0.489371, acc.: 74.22%] [G loss: 0.926282]\n",
      "epoch:27 step:26160 [D loss: 0.661978, acc.: 61.72%] [G loss: 0.712394]\n",
      "epoch:27 step:26161 [D loss: 0.591913, acc.: 65.62%] [G loss: 0.681680]\n",
      "epoch:27 step:26162 [D loss: 0.540013, acc.: 71.09%] [G loss: 0.537443]\n",
      "epoch:27 step:26163 [D loss: 0.546409, acc.: 66.41%] [G loss: 0.676985]\n",
      "epoch:27 step:26164 [D loss: 0.592415, acc.: 63.28%] [G loss: 0.824441]\n",
      "epoch:27 step:26165 [D loss: 0.533655, acc.: 72.66%] [G loss: 0.613342]\n",
      "epoch:27 step:26166 [D loss: 0.634726, acc.: 59.38%] [G loss: 0.551686]\n",
      "epoch:27 step:26167 [D loss: 0.525790, acc.: 71.09%] [G loss: 0.449324]\n",
      "epoch:27 step:26168 [D loss: 0.540993, acc.: 67.97%] [G loss: 0.708312]\n",
      "epoch:27 step:26169 [D loss: 0.447306, acc.: 78.91%] [G loss: 0.875036]\n",
      "epoch:27 step:26170 [D loss: 0.448604, acc.: 80.47%] [G loss: 0.915895]\n",
      "epoch:27 step:26171 [D loss: 0.543774, acc.: 65.62%] [G loss: 0.588636]\n",
      "epoch:27 step:26172 [D loss: 0.573181, acc.: 67.97%] [G loss: 0.792943]\n",
      "epoch:27 step:26173 [D loss: 0.539965, acc.: 72.66%] [G loss: 0.569479]\n",
      "epoch:27 step:26174 [D loss: 0.455894, acc.: 75.00%] [G loss: 0.654954]\n",
      "epoch:27 step:26175 [D loss: 0.566704, acc.: 70.31%] [G loss: 0.679380]\n",
      "epoch:27 step:26176 [D loss: 0.570301, acc.: 66.41%] [G loss: 0.650777]\n",
      "epoch:27 step:26177 [D loss: 0.516288, acc.: 67.97%] [G loss: 0.675364]\n",
      "epoch:27 step:26178 [D loss: 0.616877, acc.: 63.28%] [G loss: 0.655323]\n",
      "epoch:27 step:26179 [D loss: 0.652740, acc.: 60.16%] [G loss: 0.544983]\n",
      "epoch:27 step:26180 [D loss: 0.544502, acc.: 70.31%] [G loss: 0.571124]\n",
      "epoch:27 step:26181 [D loss: 0.580792, acc.: 65.62%] [G loss: 0.528140]\n",
      "epoch:27 step:26182 [D loss: 0.530905, acc.: 75.00%] [G loss: 0.744816]\n",
      "epoch:27 step:26183 [D loss: 0.488278, acc.: 71.09%] [G loss: 0.657972]\n",
      "epoch:27 step:26184 [D loss: 0.512671, acc.: 71.09%] [G loss: 0.686993]\n",
      "epoch:27 step:26185 [D loss: 0.502637, acc.: 75.78%] [G loss: 0.756494]\n",
      "epoch:27 step:26186 [D loss: 0.508025, acc.: 73.44%] [G loss: 0.836930]\n",
      "epoch:27 step:26187 [D loss: 0.579638, acc.: 63.28%] [G loss: 0.826546]\n",
      "epoch:27 step:26188 [D loss: 0.524416, acc.: 69.53%] [G loss: 0.656735]\n",
      "epoch:27 step:26189 [D loss: 0.482393, acc.: 76.56%] [G loss: 1.090699]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:27 step:26190 [D loss: 0.613810, acc.: 67.19%] [G loss: 0.728753]\n",
      "epoch:27 step:26191 [D loss: 0.670328, acc.: 57.03%] [G loss: 0.745565]\n",
      "epoch:27 step:26192 [D loss: 0.539682, acc.: 67.19%] [G loss: 0.658590]\n",
      "epoch:27 step:26193 [D loss: 0.449975, acc.: 77.34%] [G loss: 0.714378]\n",
      "epoch:27 step:26194 [D loss: 0.467797, acc.: 78.12%] [G loss: 0.769350]\n",
      "epoch:27 step:26195 [D loss: 0.457628, acc.: 76.56%] [G loss: 0.821011]\n",
      "epoch:27 step:26196 [D loss: 0.503532, acc.: 72.66%] [G loss: 0.949912]\n",
      "epoch:27 step:26197 [D loss: 0.468473, acc.: 75.00%] [G loss: 0.790824]\n",
      "epoch:27 step:26198 [D loss: 0.479152, acc.: 75.78%] [G loss: 0.809946]\n",
      "epoch:27 step:26199 [D loss: 0.463268, acc.: 76.56%] [G loss: 0.807833]\n",
      "epoch:27 step:26200 [D loss: 0.501692, acc.: 73.44%] [G loss: 0.815113]\n",
      "##############\n",
      "[2.96200811 1.19097851 5.97929571 4.74804983 3.94443851 5.55062128\n",
      " 4.60218107 4.92104044 4.66026221 4.37549385]\n",
      "##########\n",
      "epoch:27 step:26201 [D loss: 0.543584, acc.: 70.31%] [G loss: 0.609571]\n",
      "epoch:27 step:26202 [D loss: 0.534525, acc.: 77.34%] [G loss: 0.695013]\n",
      "epoch:27 step:26203 [D loss: 0.567697, acc.: 69.53%] [G loss: 0.692052]\n",
      "epoch:27 step:26204 [D loss: 0.566927, acc.: 72.66%] [G loss: 0.851269]\n",
      "epoch:27 step:26205 [D loss: 0.546617, acc.: 71.09%] [G loss: 0.820250]\n",
      "epoch:27 step:26206 [D loss: 0.561746, acc.: 71.09%] [G loss: 0.753650]\n",
      "epoch:27 step:26207 [D loss: 0.546723, acc.: 71.88%] [G loss: 0.878485]\n",
      "epoch:27 step:26208 [D loss: 0.474105, acc.: 76.56%] [G loss: 0.868919]\n",
      "epoch:27 step:26209 [D loss: 0.588321, acc.: 63.28%] [G loss: 0.793945]\n",
      "epoch:27 step:26210 [D loss: 0.453842, acc.: 79.69%] [G loss: 0.933779]\n",
      "epoch:27 step:26211 [D loss: 0.430715, acc.: 76.56%] [G loss: 1.071532]\n",
      "epoch:27 step:26212 [D loss: 0.546816, acc.: 71.09%] [G loss: 1.008467]\n",
      "epoch:27 step:26213 [D loss: 0.521465, acc.: 69.53%] [G loss: 1.065497]\n",
      "epoch:27 step:26214 [D loss: 0.659087, acc.: 62.50%] [G loss: 0.615991]\n",
      "epoch:27 step:26215 [D loss: 0.496918, acc.: 74.22%] [G loss: 0.732470]\n",
      "epoch:27 step:26216 [D loss: 0.595136, acc.: 64.84%] [G loss: 0.754797]\n",
      "epoch:27 step:26217 [D loss: 0.469056, acc.: 76.56%] [G loss: 0.929404]\n",
      "epoch:27 step:26218 [D loss: 0.421499, acc.: 83.59%] [G loss: 1.064746]\n",
      "epoch:27 step:26219 [D loss: 0.766550, acc.: 53.91%] [G loss: 0.602255]\n",
      "epoch:27 step:26220 [D loss: 0.480183, acc.: 75.00%] [G loss: 0.934921]\n",
      "epoch:27 step:26221 [D loss: 0.534617, acc.: 74.22%] [G loss: 0.746258]\n",
      "epoch:27 step:26222 [D loss: 0.423266, acc.: 80.47%] [G loss: 0.963390]\n",
      "epoch:27 step:26223 [D loss: 0.447002, acc.: 75.78%] [G loss: 0.752908]\n",
      "epoch:27 step:26224 [D loss: 0.418504, acc.: 82.03%] [G loss: 1.152916]\n",
      "epoch:27 step:26225 [D loss: 0.440680, acc.: 77.34%] [G loss: 1.195649]\n",
      "epoch:27 step:26226 [D loss: 0.459576, acc.: 78.91%] [G loss: 1.266800]\n",
      "epoch:27 step:26227 [D loss: 0.653948, acc.: 62.50%] [G loss: 1.033401]\n",
      "epoch:27 step:26228 [D loss: 0.468622, acc.: 77.34%] [G loss: 1.564690]\n",
      "epoch:27 step:26229 [D loss: 0.437417, acc.: 76.56%] [G loss: 1.373945]\n",
      "epoch:27 step:26230 [D loss: 0.562421, acc.: 67.97%] [G loss: 0.959140]\n",
      "epoch:27 step:26231 [D loss: 0.549005, acc.: 62.50%] [G loss: 0.964531]\n",
      "epoch:27 step:26232 [D loss: 0.483074, acc.: 74.22%] [G loss: 0.979914]\n",
      "epoch:27 step:26233 [D loss: 0.563149, acc.: 64.84%] [G loss: 1.059857]\n",
      "epoch:27 step:26234 [D loss: 0.475740, acc.: 76.56%] [G loss: 1.194637]\n",
      "epoch:27 step:26235 [D loss: 0.374984, acc.: 82.81%] [G loss: 1.360245]\n",
      "epoch:27 step:26236 [D loss: 0.449973, acc.: 80.47%] [G loss: 1.435978]\n",
      "epoch:28 step:26237 [D loss: 0.586392, acc.: 69.53%] [G loss: 1.162411]\n",
      "epoch:28 step:26238 [D loss: 0.451681, acc.: 79.69%] [G loss: 1.106415]\n",
      "epoch:28 step:26239 [D loss: 0.537924, acc.: 75.78%] [G loss: 0.886985]\n",
      "epoch:28 step:26240 [D loss: 0.507333, acc.: 76.56%] [G loss: 0.995427]\n",
      "epoch:28 step:26241 [D loss: 0.570316, acc.: 65.62%] [G loss: 0.882375]\n",
      "epoch:28 step:26242 [D loss: 0.572673, acc.: 71.88%] [G loss: 0.780669]\n",
      "epoch:28 step:26243 [D loss: 0.486733, acc.: 78.91%] [G loss: 0.840763]\n",
      "epoch:28 step:26244 [D loss: 0.496016, acc.: 76.56%] [G loss: 0.984201]\n",
      "epoch:28 step:26245 [D loss: 0.499923, acc.: 75.00%] [G loss: 0.983749]\n",
      "epoch:28 step:26246 [D loss: 0.535555, acc.: 74.22%] [G loss: 0.932072]\n",
      "epoch:28 step:26247 [D loss: 0.480342, acc.: 78.91%] [G loss: 0.830876]\n",
      "epoch:28 step:26248 [D loss: 0.562823, acc.: 68.75%] [G loss: 0.728030]\n",
      "epoch:28 step:26249 [D loss: 0.518428, acc.: 75.00%] [G loss: 0.652586]\n",
      "epoch:28 step:26250 [D loss: 0.537337, acc.: 69.53%] [G loss: 0.615227]\n",
      "epoch:28 step:26251 [D loss: 0.491229, acc.: 73.44%] [G loss: 0.608950]\n",
      "epoch:28 step:26252 [D loss: 0.494394, acc.: 72.66%] [G loss: 0.840534]\n",
      "epoch:28 step:26253 [D loss: 0.557331, acc.: 69.53%] [G loss: 0.702156]\n",
      "epoch:28 step:26254 [D loss: 0.561318, acc.: 71.09%] [G loss: 0.860754]\n",
      "epoch:28 step:26255 [D loss: 0.583789, acc.: 64.84%] [G loss: 0.680761]\n",
      "epoch:28 step:26256 [D loss: 0.574817, acc.: 65.62%] [G loss: 1.011102]\n",
      "epoch:28 step:26257 [D loss: 0.607291, acc.: 67.19%] [G loss: 0.883946]\n",
      "epoch:28 step:26258 [D loss: 0.485712, acc.: 76.56%] [G loss: 1.137268]\n",
      "epoch:28 step:26259 [D loss: 0.615689, acc.: 65.62%] [G loss: 0.590165]\n",
      "epoch:28 step:26260 [D loss: 0.503745, acc.: 72.66%] [G loss: 0.775226]\n",
      "epoch:28 step:26261 [D loss: 0.484632, acc.: 73.44%] [G loss: 0.703045]\n",
      "epoch:28 step:26262 [D loss: 0.567336, acc.: 71.88%] [G loss: 0.746657]\n",
      "epoch:28 step:26263 [D loss: 0.444496, acc.: 80.47%] [G loss: 0.824916]\n",
      "epoch:28 step:26264 [D loss: 0.540823, acc.: 68.75%] [G loss: 0.784338]\n",
      "epoch:28 step:26265 [D loss: 0.504462, acc.: 75.78%] [G loss: 0.703266]\n",
      "epoch:28 step:26266 [D loss: 0.529656, acc.: 71.88%] [G loss: 0.634318]\n",
      "epoch:28 step:26267 [D loss: 0.630415, acc.: 62.50%] [G loss: 0.581572]\n",
      "epoch:28 step:26268 [D loss: 0.563292, acc.: 67.97%] [G loss: 0.561307]\n",
      "epoch:28 step:26269 [D loss: 0.555385, acc.: 66.41%] [G loss: 0.843384]\n",
      "epoch:28 step:26270 [D loss: 0.542052, acc.: 69.53%] [G loss: 0.840684]\n",
      "epoch:28 step:26271 [D loss: 0.557712, acc.: 69.53%] [G loss: 0.748283]\n",
      "epoch:28 step:26272 [D loss: 0.533537, acc.: 68.75%] [G loss: 0.646555]\n",
      "epoch:28 step:26273 [D loss: 0.432502, acc.: 79.69%] [G loss: 0.736045]\n",
      "epoch:28 step:26274 [D loss: 0.530298, acc.: 73.44%] [G loss: 0.768839]\n",
      "epoch:28 step:26275 [D loss: 0.537402, acc.: 66.41%] [G loss: 0.761984]\n",
      "epoch:28 step:26276 [D loss: 0.452279, acc.: 82.81%] [G loss: 0.760694]\n",
      "epoch:28 step:26277 [D loss: 0.499608, acc.: 75.00%] [G loss: 0.979656]\n",
      "epoch:28 step:26278 [D loss: 0.570287, acc.: 72.66%] [G loss: 0.609295]\n",
      "epoch:28 step:26279 [D loss: 0.476428, acc.: 75.78%] [G loss: 0.556393]\n",
      "epoch:28 step:26280 [D loss: 0.623130, acc.: 65.62%] [G loss: 0.756586]\n",
      "epoch:28 step:26281 [D loss: 0.458502, acc.: 78.12%] [G loss: 0.738391]\n",
      "epoch:28 step:26282 [D loss: 0.511374, acc.: 75.00%] [G loss: 0.714036]\n",
      "epoch:28 step:26283 [D loss: 0.510575, acc.: 71.88%] [G loss: 0.767107]\n",
      "epoch:28 step:26284 [D loss: 0.533518, acc.: 72.66%] [G loss: 0.675455]\n",
      "epoch:28 step:26285 [D loss: 0.480907, acc.: 79.69%] [G loss: 0.805865]\n",
      "epoch:28 step:26286 [D loss: 0.540201, acc.: 69.53%] [G loss: 0.758973]\n",
      "epoch:28 step:26287 [D loss: 0.584293, acc.: 60.16%] [G loss: 0.871657]\n",
      "epoch:28 step:26288 [D loss: 0.596651, acc.: 64.06%] [G loss: 0.710067]\n",
      "epoch:28 step:26289 [D loss: 0.497711, acc.: 73.44%] [G loss: 0.760708]\n",
      "epoch:28 step:26290 [D loss: 0.507149, acc.: 77.34%] [G loss: 0.864981]\n",
      "epoch:28 step:26291 [D loss: 0.598379, acc.: 68.75%] [G loss: 0.896446]\n",
      "epoch:28 step:26292 [D loss: 0.523274, acc.: 67.97%] [G loss: 0.957773]\n",
      "epoch:28 step:26293 [D loss: 0.490405, acc.: 71.88%] [G loss: 0.866975]\n",
      "epoch:28 step:26294 [D loss: 0.566730, acc.: 64.84%] [G loss: 0.901133]\n",
      "epoch:28 step:26295 [D loss: 0.508055, acc.: 73.44%] [G loss: 0.760496]\n",
      "epoch:28 step:26296 [D loss: 0.592930, acc.: 64.84%] [G loss: 0.793066]\n",
      "epoch:28 step:26297 [D loss: 0.576772, acc.: 69.53%] [G loss: 0.654077]\n",
      "epoch:28 step:26298 [D loss: 0.564986, acc.: 70.31%] [G loss: 0.776033]\n",
      "epoch:28 step:26299 [D loss: 0.533997, acc.: 73.44%] [G loss: 0.697439]\n",
      "epoch:28 step:26300 [D loss: 0.576494, acc.: 71.09%] [G loss: 0.584778]\n",
      "epoch:28 step:26301 [D loss: 0.517294, acc.: 71.88%] [G loss: 0.630543]\n",
      "epoch:28 step:26302 [D loss: 0.568243, acc.: 71.09%] [G loss: 0.656692]\n",
      "epoch:28 step:26303 [D loss: 0.573961, acc.: 62.50%] [G loss: 0.644468]\n",
      "epoch:28 step:26304 [D loss: 0.517968, acc.: 71.09%] [G loss: 0.711227]\n",
      "epoch:28 step:26305 [D loss: 0.485700, acc.: 75.78%] [G loss: 0.735607]\n",
      "epoch:28 step:26306 [D loss: 0.517667, acc.: 73.44%] [G loss: 0.739171]\n",
      "epoch:28 step:26307 [D loss: 0.518539, acc.: 75.00%] [G loss: 0.773811]\n",
      "epoch:28 step:26308 [D loss: 0.558907, acc.: 67.19%] [G loss: 0.667866]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:28 step:26309 [D loss: 0.550828, acc.: 66.41%] [G loss: 0.578342]\n",
      "epoch:28 step:26310 [D loss: 0.433944, acc.: 80.47%] [G loss: 0.951941]\n",
      "epoch:28 step:26311 [D loss: 0.540554, acc.: 68.75%] [G loss: 0.820184]\n",
      "epoch:28 step:26312 [D loss: 0.483470, acc.: 75.00%] [G loss: 0.830609]\n",
      "epoch:28 step:26313 [D loss: 0.413185, acc.: 83.59%] [G loss: 1.014896]\n",
      "epoch:28 step:26314 [D loss: 0.606637, acc.: 64.84%] [G loss: 0.715516]\n",
      "epoch:28 step:26315 [D loss: 0.526140, acc.: 74.22%] [G loss: 0.642789]\n",
      "epoch:28 step:26316 [D loss: 0.499814, acc.: 78.91%] [G loss: 0.719391]\n",
      "epoch:28 step:26317 [D loss: 0.524190, acc.: 69.53%] [G loss: 0.687247]\n",
      "epoch:28 step:26318 [D loss: 0.500982, acc.: 71.88%] [G loss: 0.777966]\n",
      "epoch:28 step:26319 [D loss: 0.502252, acc.: 73.44%] [G loss: 0.822771]\n",
      "epoch:28 step:26320 [D loss: 0.492832, acc.: 77.34%] [G loss: 0.856476]\n",
      "epoch:28 step:26321 [D loss: 0.532214, acc.: 71.09%] [G loss: 0.689117]\n",
      "epoch:28 step:26322 [D loss: 0.574493, acc.: 67.97%] [G loss: 0.602021]\n",
      "epoch:28 step:26323 [D loss: 0.546656, acc.: 71.09%] [G loss: 0.711525]\n",
      "epoch:28 step:26324 [D loss: 0.469004, acc.: 78.12%] [G loss: 0.766603]\n",
      "epoch:28 step:26325 [D loss: 0.515535, acc.: 75.00%] [G loss: 0.731151]\n",
      "epoch:28 step:26326 [D loss: 0.517609, acc.: 70.31%] [G loss: 0.973242]\n",
      "epoch:28 step:26327 [D loss: 0.615121, acc.: 64.06%] [G loss: 0.763451]\n",
      "epoch:28 step:26328 [D loss: 0.442495, acc.: 79.69%] [G loss: 1.063767]\n",
      "epoch:28 step:26329 [D loss: 0.472601, acc.: 77.34%] [G loss: 1.043151]\n",
      "epoch:28 step:26330 [D loss: 0.524987, acc.: 71.09%] [G loss: 0.842242]\n",
      "epoch:28 step:26331 [D loss: 0.493890, acc.: 75.78%] [G loss: 0.862314]\n",
      "epoch:28 step:26332 [D loss: 0.519439, acc.: 71.88%] [G loss: 0.851927]\n",
      "epoch:28 step:26333 [D loss: 0.509766, acc.: 74.22%] [G loss: 0.826267]\n",
      "epoch:28 step:26334 [D loss: 0.568546, acc.: 68.75%] [G loss: 0.853221]\n",
      "epoch:28 step:26335 [D loss: 0.600003, acc.: 70.31%] [G loss: 0.708543]\n",
      "epoch:28 step:26336 [D loss: 0.483012, acc.: 78.91%] [G loss: 1.023062]\n",
      "epoch:28 step:26337 [D loss: 0.448265, acc.: 78.12%] [G loss: 1.042882]\n",
      "epoch:28 step:26338 [D loss: 0.672543, acc.: 60.94%] [G loss: 0.637388]\n",
      "epoch:28 step:26339 [D loss: 0.495469, acc.: 71.88%] [G loss: 0.663663]\n",
      "epoch:28 step:26340 [D loss: 0.513496, acc.: 69.53%] [G loss: 0.578314]\n",
      "epoch:28 step:26341 [D loss: 0.570429, acc.: 69.53%] [G loss: 0.559402]\n",
      "epoch:28 step:26342 [D loss: 0.539576, acc.: 72.66%] [G loss: 0.745693]\n",
      "epoch:28 step:26343 [D loss: 0.555156, acc.: 71.09%] [G loss: 0.732828]\n",
      "epoch:28 step:26344 [D loss: 0.645296, acc.: 65.62%] [G loss: 0.552229]\n",
      "epoch:28 step:26345 [D loss: 0.553831, acc.: 69.53%] [G loss: 0.593675]\n",
      "epoch:28 step:26346 [D loss: 0.559204, acc.: 71.88%] [G loss: 0.628085]\n",
      "epoch:28 step:26347 [D loss: 0.506363, acc.: 72.66%] [G loss: 0.779594]\n",
      "epoch:28 step:26348 [D loss: 0.537644, acc.: 73.44%] [G loss: 0.662763]\n",
      "epoch:28 step:26349 [D loss: 0.471239, acc.: 78.12%] [G loss: 0.756594]\n",
      "epoch:28 step:26350 [D loss: 0.497112, acc.: 78.12%] [G loss: 0.858979]\n",
      "epoch:28 step:26351 [D loss: 0.519617, acc.: 75.78%] [G loss: 0.749022]\n",
      "epoch:28 step:26352 [D loss: 0.518418, acc.: 68.75%] [G loss: 0.856757]\n",
      "epoch:28 step:26353 [D loss: 0.513240, acc.: 73.44%] [G loss: 0.891785]\n",
      "epoch:28 step:26354 [D loss: 0.512873, acc.: 71.09%] [G loss: 0.854484]\n",
      "epoch:28 step:26355 [D loss: 0.432122, acc.: 82.03%] [G loss: 0.891812]\n",
      "epoch:28 step:26356 [D loss: 0.551102, acc.: 71.09%] [G loss: 0.903538]\n",
      "epoch:28 step:26357 [D loss: 0.518516, acc.: 73.44%] [G loss: 0.746877]\n",
      "epoch:28 step:26358 [D loss: 0.468370, acc.: 76.56%] [G loss: 0.812102]\n",
      "epoch:28 step:26359 [D loss: 0.484548, acc.: 72.66%] [G loss: 1.113026]\n",
      "epoch:28 step:26360 [D loss: 0.546368, acc.: 71.88%] [G loss: 0.866450]\n",
      "epoch:28 step:26361 [D loss: 0.542513, acc.: 70.31%] [G loss: 0.852786]\n",
      "epoch:28 step:26362 [D loss: 0.502806, acc.: 73.44%] [G loss: 0.744284]\n",
      "epoch:28 step:26363 [D loss: 0.474461, acc.: 75.00%] [G loss: 0.817595]\n",
      "epoch:28 step:26364 [D loss: 0.473140, acc.: 71.09%] [G loss: 0.674497]\n",
      "epoch:28 step:26365 [D loss: 0.579289, acc.: 66.41%] [G loss: 0.700127]\n",
      "epoch:28 step:26366 [D loss: 0.541981, acc.: 71.09%] [G loss: 0.747304]\n",
      "epoch:28 step:26367 [D loss: 0.425090, acc.: 80.47%] [G loss: 0.864116]\n",
      "epoch:28 step:26368 [D loss: 0.515065, acc.: 71.09%] [G loss: 0.781690]\n",
      "epoch:28 step:26369 [D loss: 0.514969, acc.: 74.22%] [G loss: 0.839107]\n",
      "epoch:28 step:26370 [D loss: 0.509166, acc.: 75.00%] [G loss: 0.826628]\n",
      "epoch:28 step:26371 [D loss: 0.477489, acc.: 75.00%] [G loss: 0.992478]\n",
      "epoch:28 step:26372 [D loss: 0.539948, acc.: 75.00%] [G loss: 0.868264]\n",
      "epoch:28 step:26373 [D loss: 0.621175, acc.: 64.84%] [G loss: 0.648446]\n",
      "epoch:28 step:26374 [D loss: 0.603247, acc.: 67.97%] [G loss: 0.626590]\n",
      "epoch:28 step:26375 [D loss: 0.562000, acc.: 64.06%] [G loss: 0.658030]\n",
      "epoch:28 step:26376 [D loss: 0.512776, acc.: 71.88%] [G loss: 0.616495]\n",
      "epoch:28 step:26377 [D loss: 0.535328, acc.: 69.53%] [G loss: 0.577969]\n",
      "epoch:28 step:26378 [D loss: 0.541444, acc.: 70.31%] [G loss: 0.673124]\n",
      "epoch:28 step:26379 [D loss: 0.593506, acc.: 67.97%] [G loss: 0.666771]\n",
      "epoch:28 step:26380 [D loss: 0.508501, acc.: 69.53%] [G loss: 0.720771]\n",
      "epoch:28 step:26381 [D loss: 0.552431, acc.: 70.31%] [G loss: 0.716144]\n",
      "epoch:28 step:26382 [D loss: 0.508784, acc.: 71.09%] [G loss: 0.711333]\n",
      "epoch:28 step:26383 [D loss: 0.573221, acc.: 67.19%] [G loss: 0.808096]\n",
      "epoch:28 step:26384 [D loss: 0.563437, acc.: 69.53%] [G loss: 0.548256]\n",
      "epoch:28 step:26385 [D loss: 0.523864, acc.: 67.97%] [G loss: 0.638749]\n",
      "epoch:28 step:26386 [D loss: 0.573298, acc.: 64.84%] [G loss: 0.829011]\n",
      "epoch:28 step:26387 [D loss: 0.489893, acc.: 75.00%] [G loss: 0.757268]\n",
      "epoch:28 step:26388 [D loss: 0.470250, acc.: 80.47%] [G loss: 0.895290]\n",
      "epoch:28 step:26389 [D loss: 0.605236, acc.: 69.53%] [G loss: 0.799106]\n",
      "epoch:28 step:26390 [D loss: 0.528919, acc.: 71.88%] [G loss: 0.756289]\n",
      "epoch:28 step:26391 [D loss: 0.480566, acc.: 75.00%] [G loss: 0.816605]\n",
      "epoch:28 step:26392 [D loss: 0.525464, acc.: 71.88%] [G loss: 0.777506]\n",
      "epoch:28 step:26393 [D loss: 0.509332, acc.: 74.22%] [G loss: 0.607200]\n",
      "epoch:28 step:26394 [D loss: 0.561651, acc.: 69.53%] [G loss: 0.608475]\n",
      "epoch:28 step:26395 [D loss: 0.523270, acc.: 74.22%] [G loss: 0.737541]\n",
      "epoch:28 step:26396 [D loss: 0.578668, acc.: 71.88%] [G loss: 0.712159]\n",
      "epoch:28 step:26397 [D loss: 0.535237, acc.: 68.75%] [G loss: 0.804995]\n",
      "epoch:28 step:26398 [D loss: 0.479213, acc.: 73.44%] [G loss: 0.968452]\n",
      "epoch:28 step:26399 [D loss: 0.589971, acc.: 64.84%] [G loss: 0.949848]\n",
      "epoch:28 step:26400 [D loss: 0.526525, acc.: 73.44%] [G loss: 0.810571]\n",
      "##############\n",
      "[2.76434394 1.20879473 6.04454822 4.71715101 3.87483067 5.74501826\n",
      " 4.58420976 4.91670757 4.56074131 4.44326698]\n",
      "##########\n",
      "epoch:28 step:26401 [D loss: 0.534468, acc.: 69.53%] [G loss: 0.531207]\n",
      "epoch:28 step:26402 [D loss: 0.571130, acc.: 65.62%] [G loss: 0.588333]\n",
      "epoch:28 step:26403 [D loss: 0.537215, acc.: 71.88%] [G loss: 0.611793]\n",
      "epoch:28 step:26404 [D loss: 0.551035, acc.: 70.31%] [G loss: 0.643187]\n",
      "epoch:28 step:26405 [D loss: 0.581248, acc.: 69.53%] [G loss: 0.587550]\n",
      "epoch:28 step:26406 [D loss: 0.610045, acc.: 67.97%] [G loss: 0.656459]\n",
      "epoch:28 step:26407 [D loss: 0.540858, acc.: 71.09%] [G loss: 0.719693]\n",
      "epoch:28 step:26408 [D loss: 0.511871, acc.: 73.44%] [G loss: 0.594834]\n",
      "epoch:28 step:26409 [D loss: 0.530176, acc.: 70.31%] [G loss: 0.764782]\n",
      "epoch:28 step:26410 [D loss: 0.593282, acc.: 66.41%] [G loss: 0.614253]\n",
      "epoch:28 step:26411 [D loss: 0.571565, acc.: 64.06%] [G loss: 0.540979]\n",
      "epoch:28 step:26412 [D loss: 0.515680, acc.: 72.66%] [G loss: 0.683101]\n",
      "epoch:28 step:26413 [D loss: 0.522319, acc.: 75.00%] [G loss: 0.579245]\n",
      "epoch:28 step:26414 [D loss: 0.579715, acc.: 68.75%] [G loss: 0.602263]\n",
      "epoch:28 step:26415 [D loss: 0.572843, acc.: 67.97%] [G loss: 0.548329]\n",
      "epoch:28 step:26416 [D loss: 0.599125, acc.: 69.53%] [G loss: 0.706427]\n",
      "epoch:28 step:26417 [D loss: 0.593706, acc.: 70.31%] [G loss: 0.639353]\n",
      "epoch:28 step:26418 [D loss: 0.534872, acc.: 71.88%] [G loss: 0.752756]\n",
      "epoch:28 step:26419 [D loss: 0.529964, acc.: 73.44%] [G loss: 0.723184]\n",
      "epoch:28 step:26420 [D loss: 0.520418, acc.: 70.31%] [G loss: 0.694584]\n",
      "epoch:28 step:26421 [D loss: 0.688254, acc.: 59.38%] [G loss: 0.705508]\n",
      "epoch:28 step:26422 [D loss: 0.535131, acc.: 64.06%] [G loss: 0.739258]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:28 step:26423 [D loss: 0.538908, acc.: 70.31%] [G loss: 0.760822]\n",
      "epoch:28 step:26424 [D loss: 0.638403, acc.: 63.28%] [G loss: 0.533533]\n",
      "epoch:28 step:26425 [D loss: 0.549006, acc.: 67.97%] [G loss: 0.594461]\n",
      "epoch:28 step:26426 [D loss: 0.538557, acc.: 69.53%] [G loss: 0.616779]\n",
      "epoch:28 step:26427 [D loss: 0.483434, acc.: 76.56%] [G loss: 0.707774]\n",
      "epoch:28 step:26428 [D loss: 0.548337, acc.: 67.19%] [G loss: 0.629729]\n",
      "epoch:28 step:26429 [D loss: 0.570721, acc.: 68.75%] [G loss: 0.591285]\n",
      "epoch:28 step:26430 [D loss: 0.446021, acc.: 78.91%] [G loss: 0.699844]\n",
      "epoch:28 step:26431 [D loss: 0.568901, acc.: 75.00%] [G loss: 0.739728]\n",
      "epoch:28 step:26432 [D loss: 0.533325, acc.: 70.31%] [G loss: 0.808714]\n",
      "epoch:28 step:26433 [D loss: 0.487325, acc.: 75.78%] [G loss: 0.840966]\n",
      "epoch:28 step:26434 [D loss: 0.488896, acc.: 73.44%] [G loss: 0.859757]\n",
      "epoch:28 step:26435 [D loss: 0.554073, acc.: 66.41%] [G loss: 0.856838]\n",
      "epoch:28 step:26436 [D loss: 0.617851, acc.: 64.84%] [G loss: 0.781285]\n",
      "epoch:28 step:26437 [D loss: 0.550688, acc.: 67.97%] [G loss: 0.689970]\n",
      "epoch:28 step:26438 [D loss: 0.529263, acc.: 71.88%] [G loss: 0.785004]\n",
      "epoch:28 step:26439 [D loss: 0.582543, acc.: 64.84%] [G loss: 0.668958]\n",
      "epoch:28 step:26440 [D loss: 0.610992, acc.: 61.72%] [G loss: 0.613253]\n",
      "epoch:28 step:26441 [D loss: 0.471516, acc.: 76.56%] [G loss: 0.803129]\n",
      "epoch:28 step:26442 [D loss: 0.515948, acc.: 76.56%] [G loss: 0.811625]\n",
      "epoch:28 step:26443 [D loss: 0.473422, acc.: 77.34%] [G loss: 0.778722]\n",
      "epoch:28 step:26444 [D loss: 0.487041, acc.: 77.34%] [G loss: 0.938263]\n",
      "epoch:28 step:26445 [D loss: 0.482222, acc.: 78.91%] [G loss: 0.749631]\n",
      "epoch:28 step:26446 [D loss: 0.652047, acc.: 64.06%] [G loss: 0.694550]\n",
      "epoch:28 step:26447 [D loss: 0.609338, acc.: 64.84%] [G loss: 0.572738]\n",
      "epoch:28 step:26448 [D loss: 0.508916, acc.: 74.22%] [G loss: 0.744867]\n",
      "epoch:28 step:26449 [D loss: 0.555697, acc.: 71.09%] [G loss: 0.759313]\n",
      "epoch:28 step:26450 [D loss: 0.600491, acc.: 64.06%] [G loss: 0.721342]\n",
      "epoch:28 step:26451 [D loss: 0.547046, acc.: 70.31%] [G loss: 0.576491]\n",
      "epoch:28 step:26452 [D loss: 0.532586, acc.: 71.88%] [G loss: 0.737802]\n",
      "epoch:28 step:26453 [D loss: 0.486649, acc.: 72.66%] [G loss: 0.646718]\n",
      "epoch:28 step:26454 [D loss: 0.504403, acc.: 72.66%] [G loss: 0.715337]\n",
      "epoch:28 step:26455 [D loss: 0.447788, acc.: 79.69%] [G loss: 0.987587]\n",
      "epoch:28 step:26456 [D loss: 0.648976, acc.: 63.28%] [G loss: 0.891881]\n",
      "epoch:28 step:26457 [D loss: 0.553318, acc.: 74.22%] [G loss: 0.923689]\n",
      "epoch:28 step:26458 [D loss: 0.503251, acc.: 76.56%] [G loss: 0.722214]\n",
      "epoch:28 step:26459 [D loss: 0.493171, acc.: 79.69%] [G loss: 0.794072]\n",
      "epoch:28 step:26460 [D loss: 0.599862, acc.: 70.31%] [G loss: 0.656463]\n",
      "epoch:28 step:26461 [D loss: 0.508051, acc.: 74.22%] [G loss: 0.674175]\n",
      "epoch:28 step:26462 [D loss: 0.533500, acc.: 66.41%] [G loss: 0.646793]\n",
      "epoch:28 step:26463 [D loss: 0.491456, acc.: 75.00%] [G loss: 0.670075]\n",
      "epoch:28 step:26464 [D loss: 0.587815, acc.: 65.62%] [G loss: 0.511373]\n",
      "epoch:28 step:26465 [D loss: 0.497835, acc.: 76.56%] [G loss: 0.734885]\n",
      "epoch:28 step:26466 [D loss: 0.545574, acc.: 74.22%] [G loss: 0.764162]\n",
      "epoch:28 step:26467 [D loss: 0.544325, acc.: 68.75%] [G loss: 0.899258]\n",
      "epoch:28 step:26468 [D loss: 0.451886, acc.: 78.12%] [G loss: 0.912409]\n",
      "epoch:28 step:26469 [D loss: 0.490727, acc.: 75.78%] [G loss: 0.853871]\n",
      "epoch:28 step:26470 [D loss: 0.561634, acc.: 67.19%] [G loss: 0.769844]\n",
      "epoch:28 step:26471 [D loss: 0.592186, acc.: 64.84%] [G loss: 0.863608]\n",
      "epoch:28 step:26472 [D loss: 0.482552, acc.: 72.66%] [G loss: 0.724506]\n",
      "epoch:28 step:26473 [D loss: 0.522245, acc.: 74.22%] [G loss: 0.730118]\n",
      "epoch:28 step:26474 [D loss: 0.582289, acc.: 67.19%] [G loss: 0.674299]\n",
      "epoch:28 step:26475 [D loss: 0.492520, acc.: 76.56%] [G loss: 0.732026]\n",
      "epoch:28 step:26476 [D loss: 0.578055, acc.: 67.97%] [G loss: 0.527840]\n",
      "epoch:28 step:26477 [D loss: 0.537198, acc.: 68.75%] [G loss: 0.747044]\n",
      "epoch:28 step:26478 [D loss: 0.526488, acc.: 74.22%] [G loss: 0.713377]\n",
      "epoch:28 step:26479 [D loss: 0.525937, acc.: 71.09%] [G loss: 0.789240]\n",
      "epoch:28 step:26480 [D loss: 0.506302, acc.: 75.78%] [G loss: 0.727869]\n",
      "epoch:28 step:26481 [D loss: 0.506513, acc.: 75.78%] [G loss: 0.612454]\n",
      "epoch:28 step:26482 [D loss: 0.487606, acc.: 75.00%] [G loss: 0.769552]\n",
      "epoch:28 step:26483 [D loss: 0.508430, acc.: 73.44%] [G loss: 0.824421]\n",
      "epoch:28 step:26484 [D loss: 0.481335, acc.: 76.56%] [G loss: 0.827812]\n",
      "epoch:28 step:26485 [D loss: 0.545663, acc.: 71.88%] [G loss: 1.015251]\n",
      "epoch:28 step:26486 [D loss: 0.533911, acc.: 69.53%] [G loss: 0.761941]\n",
      "epoch:28 step:26487 [D loss: 0.610230, acc.: 63.28%] [G loss: 0.826862]\n",
      "epoch:28 step:26488 [D loss: 0.530526, acc.: 71.88%] [G loss: 0.859098]\n",
      "epoch:28 step:26489 [D loss: 0.637435, acc.: 63.28%] [G loss: 0.695989]\n",
      "epoch:28 step:26490 [D loss: 0.576762, acc.: 64.84%] [G loss: 0.571829]\n",
      "epoch:28 step:26491 [D loss: 0.563403, acc.: 62.50%] [G loss: 0.736562]\n",
      "epoch:28 step:26492 [D loss: 0.591750, acc.: 67.19%] [G loss: 0.445427]\n",
      "epoch:28 step:26493 [D loss: 0.574136, acc.: 70.31%] [G loss: 0.812106]\n",
      "epoch:28 step:26494 [D loss: 0.489884, acc.: 77.34%] [G loss: 0.539824]\n",
      "epoch:28 step:26495 [D loss: 0.531044, acc.: 66.41%] [G loss: 0.554901]\n",
      "epoch:28 step:26496 [D loss: 0.526791, acc.: 68.75%] [G loss: 0.655301]\n",
      "epoch:28 step:26497 [D loss: 0.550285, acc.: 71.88%] [G loss: 0.885819]\n",
      "epoch:28 step:26498 [D loss: 0.477851, acc.: 75.00%] [G loss: 0.834090]\n",
      "epoch:28 step:26499 [D loss: 0.547737, acc.: 71.88%] [G loss: 0.678907]\n",
      "epoch:28 step:26500 [D loss: 0.493050, acc.: 75.78%] [G loss: 0.808906]\n",
      "epoch:28 step:26501 [D loss: 0.533067, acc.: 75.00%] [G loss: 0.620831]\n",
      "epoch:28 step:26502 [D loss: 0.565408, acc.: 66.41%] [G loss: 0.581540]\n",
      "epoch:28 step:26503 [D loss: 0.561838, acc.: 67.19%] [G loss: 0.790211]\n",
      "epoch:28 step:26504 [D loss: 0.540918, acc.: 73.44%] [G loss: 0.646229]\n",
      "epoch:28 step:26505 [D loss: 0.496891, acc.: 73.44%] [G loss: 0.712154]\n",
      "epoch:28 step:26506 [D loss: 0.483457, acc.: 75.78%] [G loss: 0.647973]\n",
      "epoch:28 step:26507 [D loss: 0.517047, acc.: 72.66%] [G loss: 0.820518]\n",
      "epoch:28 step:26508 [D loss: 0.544032, acc.: 71.88%] [G loss: 0.830705]\n",
      "epoch:28 step:26509 [D loss: 0.503584, acc.: 72.66%] [G loss: 0.804541]\n",
      "epoch:28 step:26510 [D loss: 0.536322, acc.: 69.53%] [G loss: 0.720192]\n",
      "epoch:28 step:26511 [D loss: 0.563836, acc.: 67.19%] [G loss: 0.712081]\n",
      "epoch:28 step:26512 [D loss: 0.505384, acc.: 78.12%] [G loss: 0.719625]\n",
      "epoch:28 step:26513 [D loss: 0.652778, acc.: 64.06%] [G loss: 0.582674]\n",
      "epoch:28 step:26514 [D loss: 0.667673, acc.: 57.81%] [G loss: 0.521063]\n",
      "epoch:28 step:26515 [D loss: 0.571360, acc.: 61.72%] [G loss: 0.620701]\n",
      "epoch:28 step:26516 [D loss: 0.515125, acc.: 73.44%] [G loss: 0.662582]\n",
      "epoch:28 step:26517 [D loss: 0.589176, acc.: 65.62%] [G loss: 0.596418]\n",
      "epoch:28 step:26518 [D loss: 0.558942, acc.: 66.41%] [G loss: 0.528211]\n",
      "epoch:28 step:26519 [D loss: 0.508903, acc.: 73.44%] [G loss: 0.733929]\n",
      "epoch:28 step:26520 [D loss: 0.592453, acc.: 66.41%] [G loss: 0.541639]\n",
      "epoch:28 step:26521 [D loss: 0.520811, acc.: 69.53%] [G loss: 0.721722]\n",
      "epoch:28 step:26522 [D loss: 0.541054, acc.: 72.66%] [G loss: 0.643084]\n",
      "epoch:28 step:26523 [D loss: 0.540432, acc.: 66.41%] [G loss: 0.682829]\n",
      "epoch:28 step:26524 [D loss: 0.543064, acc.: 65.62%] [G loss: 0.739699]\n",
      "epoch:28 step:26525 [D loss: 0.480305, acc.: 73.44%] [G loss: 0.810319]\n",
      "epoch:28 step:26526 [D loss: 0.553076, acc.: 69.53%] [G loss: 0.908358]\n",
      "epoch:28 step:26527 [D loss: 0.616838, acc.: 62.50%] [G loss: 0.525820]\n",
      "epoch:28 step:26528 [D loss: 0.456869, acc.: 77.34%] [G loss: 0.730052]\n",
      "epoch:28 step:26529 [D loss: 0.550286, acc.: 66.41%] [G loss: 0.510223]\n",
      "epoch:28 step:26530 [D loss: 0.629182, acc.: 67.97%] [G loss: 0.618868]\n",
      "epoch:28 step:26531 [D loss: 0.582159, acc.: 67.19%] [G loss: 0.443163]\n",
      "epoch:28 step:26532 [D loss: 0.481803, acc.: 71.09%] [G loss: 0.674734]\n",
      "epoch:28 step:26533 [D loss: 0.571397, acc.: 69.53%] [G loss: 0.696926]\n",
      "epoch:28 step:26534 [D loss: 0.466924, acc.: 79.69%] [G loss: 0.741828]\n",
      "epoch:28 step:26535 [D loss: 0.455343, acc.: 76.56%] [G loss: 0.742429]\n",
      "epoch:28 step:26536 [D loss: 0.481365, acc.: 75.00%] [G loss: 0.749768]\n",
      "epoch:28 step:26537 [D loss: 0.661462, acc.: 66.41%] [G loss: 0.644350]\n",
      "epoch:28 step:26538 [D loss: 0.536339, acc.: 67.97%] [G loss: 0.589622]\n",
      "epoch:28 step:26539 [D loss: 0.536574, acc.: 71.88%] [G loss: 0.709363]\n",
      "epoch:28 step:26540 [D loss: 0.478402, acc.: 79.69%] [G loss: 0.752949]\n",
      "epoch:28 step:26541 [D loss: 0.551607, acc.: 68.75%] [G loss: 0.740898]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:28 step:26542 [D loss: 0.476286, acc.: 75.78%] [G loss: 0.646802]\n",
      "epoch:28 step:26543 [D loss: 0.462406, acc.: 77.34%] [G loss: 0.997983]\n",
      "epoch:28 step:26544 [D loss: 0.586533, acc.: 66.41%] [G loss: 0.679840]\n",
      "epoch:28 step:26545 [D loss: 0.514082, acc.: 74.22%] [G loss: 0.625231]\n",
      "epoch:28 step:26546 [D loss: 0.540414, acc.: 72.66%] [G loss: 0.670574]\n",
      "epoch:28 step:26547 [D loss: 0.450534, acc.: 76.56%] [G loss: 0.954164]\n",
      "epoch:28 step:26548 [D loss: 0.430907, acc.: 82.03%] [G loss: 0.841410]\n",
      "epoch:28 step:26549 [D loss: 0.494049, acc.: 74.22%] [G loss: 1.018334]\n",
      "epoch:28 step:26550 [D loss: 0.436585, acc.: 78.91%] [G loss: 1.021200]\n",
      "epoch:28 step:26551 [D loss: 0.576656, acc.: 69.53%] [G loss: 0.904892]\n",
      "epoch:28 step:26552 [D loss: 0.693388, acc.: 62.50%] [G loss: 0.748879]\n",
      "epoch:28 step:26553 [D loss: 0.567818, acc.: 66.41%] [G loss: 0.711379]\n",
      "epoch:28 step:26554 [D loss: 0.522218, acc.: 69.53%] [G loss: 0.687855]\n",
      "epoch:28 step:26555 [D loss: 0.549295, acc.: 70.31%] [G loss: 0.754632]\n",
      "epoch:28 step:26556 [D loss: 0.523375, acc.: 71.88%] [G loss: 0.606901]\n",
      "epoch:28 step:26557 [D loss: 0.452447, acc.: 78.12%] [G loss: 0.880358]\n",
      "epoch:28 step:26558 [D loss: 0.561797, acc.: 69.53%] [G loss: 0.706698]\n",
      "epoch:28 step:26559 [D loss: 0.546668, acc.: 71.88%] [G loss: 0.620917]\n",
      "epoch:28 step:26560 [D loss: 0.519688, acc.: 72.66%] [G loss: 0.577499]\n",
      "epoch:28 step:26561 [D loss: 0.524260, acc.: 68.75%] [G loss: 0.727642]\n",
      "epoch:28 step:26562 [D loss: 0.464042, acc.: 78.91%] [G loss: 0.684159]\n",
      "epoch:28 step:26563 [D loss: 0.538715, acc.: 72.66%] [G loss: 0.696485]\n",
      "epoch:28 step:26564 [D loss: 0.444395, acc.: 79.69%] [G loss: 0.879827]\n",
      "epoch:28 step:26565 [D loss: 0.526173, acc.: 70.31%] [G loss: 0.695469]\n",
      "epoch:28 step:26566 [D loss: 0.611606, acc.: 66.41%] [G loss: 0.711356]\n",
      "epoch:28 step:26567 [D loss: 0.550083, acc.: 70.31%] [G loss: 0.704659]\n",
      "epoch:28 step:26568 [D loss: 0.491070, acc.: 76.56%] [G loss: 0.854218]\n",
      "epoch:28 step:26569 [D loss: 0.513378, acc.: 79.69%] [G loss: 0.667470]\n",
      "epoch:28 step:26570 [D loss: 0.463989, acc.: 78.91%] [G loss: 0.920962]\n",
      "epoch:28 step:26571 [D loss: 0.489976, acc.: 77.34%] [G loss: 0.949382]\n",
      "epoch:28 step:26572 [D loss: 0.513944, acc.: 75.78%] [G loss: 0.739352]\n",
      "epoch:28 step:26573 [D loss: 0.512355, acc.: 71.09%] [G loss: 0.872135]\n",
      "epoch:28 step:26574 [D loss: 0.526334, acc.: 68.75%] [G loss: 0.850744]\n",
      "epoch:28 step:26575 [D loss: 0.485771, acc.: 77.34%] [G loss: 0.934701]\n",
      "epoch:28 step:26576 [D loss: 0.483438, acc.: 77.34%] [G loss: 0.766412]\n",
      "epoch:28 step:26577 [D loss: 0.545070, acc.: 72.66%] [G loss: 0.670929]\n",
      "epoch:28 step:26578 [D loss: 0.600084, acc.: 61.72%] [G loss: 0.630112]\n",
      "epoch:28 step:26579 [D loss: 0.468298, acc.: 81.25%] [G loss: 0.738625]\n",
      "epoch:28 step:26580 [D loss: 0.443138, acc.: 75.78%] [G loss: 1.070959]\n",
      "epoch:28 step:26581 [D loss: 0.599183, acc.: 67.97%] [G loss: 0.925656]\n",
      "epoch:28 step:26582 [D loss: 0.573447, acc.: 69.53%] [G loss: 0.985786]\n",
      "epoch:28 step:26583 [D loss: 0.487143, acc.: 72.66%] [G loss: 1.221516]\n",
      "epoch:28 step:26584 [D loss: 0.616850, acc.: 66.41%] [G loss: 1.185240]\n",
      "epoch:28 step:26585 [D loss: 0.726846, acc.: 60.16%] [G loss: 0.412548]\n",
      "epoch:28 step:26586 [D loss: 0.445864, acc.: 82.81%] [G loss: 0.633161]\n",
      "epoch:28 step:26587 [D loss: 0.510726, acc.: 75.00%] [G loss: 0.723640]\n",
      "epoch:28 step:26588 [D loss: 0.603035, acc.: 63.28%] [G loss: 0.682379]\n",
      "epoch:28 step:26589 [D loss: 0.512341, acc.: 73.44%] [G loss: 0.695213]\n",
      "epoch:28 step:26590 [D loss: 0.360587, acc.: 83.59%] [G loss: 1.021854]\n",
      "epoch:28 step:26591 [D loss: 0.530127, acc.: 71.09%] [G loss: 1.032169]\n",
      "epoch:28 step:26592 [D loss: 0.571218, acc.: 71.88%] [G loss: 0.912708]\n",
      "epoch:28 step:26593 [D loss: 0.468338, acc.: 76.56%] [G loss: 0.870977]\n",
      "epoch:28 step:26594 [D loss: 0.486338, acc.: 75.78%] [G loss: 0.784085]\n",
      "epoch:28 step:26595 [D loss: 0.498094, acc.: 72.66%] [G loss: 0.775046]\n",
      "epoch:28 step:26596 [D loss: 0.508986, acc.: 71.88%] [G loss: 0.941327]\n",
      "epoch:28 step:26597 [D loss: 0.478741, acc.: 82.03%] [G loss: 0.890095]\n",
      "epoch:28 step:26598 [D loss: 0.591698, acc.: 61.72%] [G loss: 0.686025]\n",
      "epoch:28 step:26599 [D loss: 0.574089, acc.: 67.19%] [G loss: 0.596382]\n",
      "epoch:28 step:26600 [D loss: 0.542429, acc.: 71.09%] [G loss: 0.713398]\n",
      "##############\n",
      "[2.74612827 0.81212264 6.14299481 5.16263865 3.7138391  5.65071457\n",
      " 4.70308618 4.98753318 4.76263917 4.08974325]\n",
      "##########\n",
      "epoch:28 step:26601 [D loss: 0.562549, acc.: 72.66%] [G loss: 0.813066]\n",
      "epoch:28 step:26602 [D loss: 0.525625, acc.: 68.75%] [G loss: 0.852234]\n",
      "epoch:28 step:26603 [D loss: 0.571567, acc.: 66.41%] [G loss: 0.799255]\n",
      "epoch:28 step:26604 [D loss: 0.550212, acc.: 68.75%] [G loss: 0.549693]\n",
      "epoch:28 step:26605 [D loss: 0.497906, acc.: 73.44%] [G loss: 0.696777]\n",
      "epoch:28 step:26606 [D loss: 0.521193, acc.: 71.09%] [G loss: 0.782625]\n",
      "epoch:28 step:26607 [D loss: 0.492651, acc.: 75.78%] [G loss: 0.972795]\n",
      "epoch:28 step:26608 [D loss: 0.524512, acc.: 73.44%] [G loss: 0.723151]\n",
      "epoch:28 step:26609 [D loss: 0.604309, acc.: 66.41%] [G loss: 0.835451]\n",
      "epoch:28 step:26610 [D loss: 0.441838, acc.: 83.59%] [G loss: 0.933554]\n",
      "epoch:28 step:26611 [D loss: 0.508047, acc.: 71.09%] [G loss: 0.784009]\n",
      "epoch:28 step:26612 [D loss: 0.685589, acc.: 58.59%] [G loss: 0.573060]\n",
      "epoch:28 step:26613 [D loss: 0.559640, acc.: 67.97%] [G loss: 0.599624]\n",
      "epoch:28 step:26614 [D loss: 0.523421, acc.: 73.44%] [G loss: 0.668592]\n",
      "epoch:28 step:26615 [D loss: 0.538347, acc.: 70.31%] [G loss: 0.711656]\n",
      "epoch:28 step:26616 [D loss: 0.566533, acc.: 71.88%] [G loss: 0.605186]\n",
      "epoch:28 step:26617 [D loss: 0.505599, acc.: 75.00%] [G loss: 0.742762]\n",
      "epoch:28 step:26618 [D loss: 0.502818, acc.: 77.34%] [G loss: 0.707086]\n",
      "epoch:28 step:26619 [D loss: 0.560735, acc.: 71.88%] [G loss: 0.668787]\n",
      "epoch:28 step:26620 [D loss: 0.520756, acc.: 73.44%] [G loss: 0.654069]\n",
      "epoch:28 step:26621 [D loss: 0.479841, acc.: 76.56%] [G loss: 0.537446]\n",
      "epoch:28 step:26622 [D loss: 0.570249, acc.: 71.09%] [G loss: 0.726625]\n",
      "epoch:28 step:26623 [D loss: 0.497263, acc.: 71.09%] [G loss: 0.606031]\n",
      "epoch:28 step:26624 [D loss: 0.534011, acc.: 73.44%] [G loss: 0.722753]\n",
      "epoch:28 step:26625 [D loss: 0.553894, acc.: 69.53%] [G loss: 0.975112]\n",
      "epoch:28 step:26626 [D loss: 0.557292, acc.: 66.41%] [G loss: 0.858709]\n",
      "epoch:28 step:26627 [D loss: 0.630145, acc.: 64.06%] [G loss: 0.842054]\n",
      "epoch:28 step:26628 [D loss: 0.484480, acc.: 79.69%] [G loss: 0.934200]\n",
      "epoch:28 step:26629 [D loss: 0.598935, acc.: 66.41%] [G loss: 0.879895]\n",
      "epoch:28 step:26630 [D loss: 0.566948, acc.: 67.19%] [G loss: 0.510255]\n",
      "epoch:28 step:26631 [D loss: 0.543959, acc.: 71.88%] [G loss: 0.697038]\n",
      "epoch:28 step:26632 [D loss: 0.511028, acc.: 75.78%] [G loss: 0.634669]\n",
      "epoch:28 step:26633 [D loss: 0.517086, acc.: 70.31%] [G loss: 0.945076]\n",
      "epoch:28 step:26634 [D loss: 0.469944, acc.: 71.09%] [G loss: 0.802468]\n",
      "epoch:28 step:26635 [D loss: 0.480652, acc.: 75.78%] [G loss: 1.042827]\n",
      "epoch:28 step:26636 [D loss: 0.602249, acc.: 64.84%] [G loss: 0.880510]\n",
      "epoch:28 step:26637 [D loss: 0.639742, acc.: 62.50%] [G loss: 0.526525]\n",
      "epoch:28 step:26638 [D loss: 0.453129, acc.: 74.22%] [G loss: 0.895288]\n",
      "epoch:28 step:26639 [D loss: 0.478328, acc.: 71.88%] [G loss: 0.993655]\n",
      "epoch:28 step:26640 [D loss: 0.646205, acc.: 58.59%] [G loss: 0.783672]\n",
      "epoch:28 step:26641 [D loss: 0.502632, acc.: 73.44%] [G loss: 0.992799]\n",
      "epoch:28 step:26642 [D loss: 0.530595, acc.: 73.44%] [G loss: 0.916585]\n",
      "epoch:28 step:26643 [D loss: 0.549884, acc.: 68.75%] [G loss: 0.807399]\n",
      "epoch:28 step:26644 [D loss: 0.564123, acc.: 66.41%] [G loss: 0.797271]\n",
      "epoch:28 step:26645 [D loss: 0.518689, acc.: 75.78%] [G loss: 0.730303]\n",
      "epoch:28 step:26646 [D loss: 0.606691, acc.: 63.28%] [G loss: 0.627816]\n",
      "epoch:28 step:26647 [D loss: 0.572138, acc.: 64.84%] [G loss: 0.670638]\n",
      "epoch:28 step:26648 [D loss: 0.595263, acc.: 64.06%] [G loss: 0.510020]\n",
      "epoch:28 step:26649 [D loss: 0.565474, acc.: 70.31%] [G loss: 0.697870]\n",
      "epoch:28 step:26650 [D loss: 0.510135, acc.: 74.22%] [G loss: 0.834016]\n",
      "epoch:28 step:26651 [D loss: 0.528013, acc.: 74.22%] [G loss: 1.114663]\n",
      "epoch:28 step:26652 [D loss: 0.516633, acc.: 75.78%] [G loss: 0.956894]\n",
      "epoch:28 step:26653 [D loss: 0.545067, acc.: 71.09%] [G loss: 0.898986]\n",
      "epoch:28 step:26654 [D loss: 0.613606, acc.: 63.28%] [G loss: 0.605550]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:28 step:26655 [D loss: 0.558539, acc.: 71.88%] [G loss: 0.635203]\n",
      "epoch:28 step:26656 [D loss: 0.520760, acc.: 70.31%] [G loss: 0.661571]\n",
      "epoch:28 step:26657 [D loss: 0.567575, acc.: 68.75%] [G loss: 0.643766]\n",
      "epoch:28 step:26658 [D loss: 0.561973, acc.: 71.09%] [G loss: 0.613281]\n",
      "epoch:28 step:26659 [D loss: 0.536195, acc.: 71.09%] [G loss: 0.877485]\n",
      "epoch:28 step:26660 [D loss: 0.553389, acc.: 71.88%] [G loss: 0.865416]\n",
      "epoch:28 step:26661 [D loss: 0.481765, acc.: 77.34%] [G loss: 0.869691]\n",
      "epoch:28 step:26662 [D loss: 0.484853, acc.: 73.44%] [G loss: 0.815335]\n",
      "epoch:28 step:26663 [D loss: 0.468929, acc.: 78.12%] [G loss: 0.974475]\n",
      "epoch:28 step:26664 [D loss: 0.459224, acc.: 77.34%] [G loss: 0.708468]\n",
      "epoch:28 step:26665 [D loss: 0.420140, acc.: 85.16%] [G loss: 0.864316]\n",
      "epoch:28 step:26666 [D loss: 0.600591, acc.: 66.41%] [G loss: 0.838383]\n",
      "epoch:28 step:26667 [D loss: 0.557953, acc.: 67.19%] [G loss: 0.850286]\n",
      "epoch:28 step:26668 [D loss: 0.578057, acc.: 70.31%] [G loss: 0.807183]\n",
      "epoch:28 step:26669 [D loss: 0.517084, acc.: 75.78%] [G loss: 0.726138]\n",
      "epoch:28 step:26670 [D loss: 0.454482, acc.: 79.69%] [G loss: 0.825788]\n",
      "epoch:28 step:26671 [D loss: 0.532059, acc.: 70.31%] [G loss: 0.859845]\n",
      "epoch:28 step:26672 [D loss: 0.475265, acc.: 75.78%] [G loss: 0.846775]\n",
      "epoch:28 step:26673 [D loss: 0.667100, acc.: 60.16%] [G loss: 0.729540]\n",
      "epoch:28 step:26674 [D loss: 0.519010, acc.: 71.09%] [G loss: 0.776811]\n",
      "epoch:28 step:26675 [D loss: 0.559581, acc.: 71.09%] [G loss: 0.726964]\n",
      "epoch:28 step:26676 [D loss: 0.502089, acc.: 73.44%] [G loss: 1.050665]\n",
      "epoch:28 step:26677 [D loss: 0.510341, acc.: 69.53%] [G loss: 0.923580]\n",
      "epoch:28 step:26678 [D loss: 0.556873, acc.: 67.19%] [G loss: 0.759985]\n",
      "epoch:28 step:26679 [D loss: 0.523250, acc.: 71.09%] [G loss: 0.704378]\n",
      "epoch:28 step:26680 [D loss: 0.487298, acc.: 75.00%] [G loss: 0.915719]\n",
      "epoch:28 step:26681 [D loss: 0.529727, acc.: 67.97%] [G loss: 0.840945]\n",
      "epoch:28 step:26682 [D loss: 0.538399, acc.: 71.09%] [G loss: 0.807858]\n",
      "epoch:28 step:26683 [D loss: 0.494002, acc.: 70.31%] [G loss: 0.776531]\n",
      "epoch:28 step:26684 [D loss: 0.499517, acc.: 75.00%] [G loss: 0.923630]\n",
      "epoch:28 step:26685 [D loss: 0.508140, acc.: 74.22%] [G loss: 1.009350]\n",
      "epoch:28 step:26686 [D loss: 0.469955, acc.: 77.34%] [G loss: 0.991913]\n",
      "epoch:28 step:26687 [D loss: 0.401371, acc.: 82.81%] [G loss: 0.935007]\n",
      "epoch:28 step:26688 [D loss: 0.477382, acc.: 74.22%] [G loss: 0.845757]\n",
      "epoch:28 step:26689 [D loss: 0.527468, acc.: 73.44%] [G loss: 0.677627]\n",
      "epoch:28 step:26690 [D loss: 0.544181, acc.: 73.44%] [G loss: 0.720510]\n",
      "epoch:28 step:26691 [D loss: 0.549878, acc.: 73.44%] [G loss: 0.752683]\n",
      "epoch:28 step:26692 [D loss: 0.579370, acc.: 67.19%] [G loss: 0.707543]\n",
      "epoch:28 step:26693 [D loss: 0.532565, acc.: 75.78%] [G loss: 0.868376]\n",
      "epoch:28 step:26694 [D loss: 0.705917, acc.: 62.50%] [G loss: 0.797807]\n",
      "epoch:28 step:26695 [D loss: 0.515703, acc.: 71.88%] [G loss: 0.793661]\n",
      "epoch:28 step:26696 [D loss: 0.486346, acc.: 78.12%] [G loss: 0.966572]\n",
      "epoch:28 step:26697 [D loss: 0.487230, acc.: 76.56%] [G loss: 0.936656]\n",
      "epoch:28 step:26698 [D loss: 0.506944, acc.: 71.88%] [G loss: 0.877337]\n",
      "epoch:28 step:26699 [D loss: 0.554697, acc.: 66.41%] [G loss: 0.583990]\n",
      "epoch:28 step:26700 [D loss: 0.527884, acc.: 74.22%] [G loss: 0.859200]\n",
      "epoch:28 step:26701 [D loss: 0.582763, acc.: 72.66%] [G loss: 0.636316]\n",
      "epoch:28 step:26702 [D loss: 0.548721, acc.: 70.31%] [G loss: 0.667218]\n",
      "epoch:28 step:26703 [D loss: 0.525341, acc.: 74.22%] [G loss: 0.691089]\n",
      "epoch:28 step:26704 [D loss: 0.513260, acc.: 71.88%] [G loss: 0.662552]\n",
      "epoch:28 step:26705 [D loss: 0.529076, acc.: 70.31%] [G loss: 0.772853]\n",
      "epoch:28 step:26706 [D loss: 0.508922, acc.: 72.66%] [G loss: 0.707232]\n",
      "epoch:28 step:26707 [D loss: 0.462263, acc.: 78.91%] [G loss: 0.775806]\n",
      "epoch:28 step:26708 [D loss: 0.458149, acc.: 79.69%] [G loss: 0.923810]\n",
      "epoch:28 step:26709 [D loss: 0.609507, acc.: 61.72%] [G loss: 0.803703]\n",
      "epoch:28 step:26710 [D loss: 0.533227, acc.: 68.75%] [G loss: 0.684375]\n",
      "epoch:28 step:26711 [D loss: 0.543157, acc.: 73.44%] [G loss: 0.646979]\n",
      "epoch:28 step:26712 [D loss: 0.481621, acc.: 78.91%] [G loss: 0.966323]\n",
      "epoch:28 step:26713 [D loss: 0.651389, acc.: 63.28%] [G loss: 0.551554]\n",
      "epoch:28 step:26714 [D loss: 0.537699, acc.: 67.97%] [G loss: 0.477875]\n",
      "epoch:28 step:26715 [D loss: 0.509169, acc.: 75.78%] [G loss: 0.606842]\n",
      "epoch:28 step:26716 [D loss: 0.556267, acc.: 71.88%] [G loss: 0.749025]\n",
      "epoch:28 step:26717 [D loss: 0.493531, acc.: 79.69%] [G loss: 0.770195]\n",
      "epoch:28 step:26718 [D loss: 0.558391, acc.: 71.88%] [G loss: 0.794976]\n",
      "epoch:28 step:26719 [D loss: 0.529183, acc.: 67.97%] [G loss: 0.790238]\n",
      "epoch:28 step:26720 [D loss: 0.472714, acc.: 74.22%] [G loss: 0.831459]\n",
      "epoch:28 step:26721 [D loss: 0.517255, acc.: 77.34%] [G loss: 0.657348]\n",
      "epoch:28 step:26722 [D loss: 0.558881, acc.: 71.09%] [G loss: 0.693436]\n",
      "epoch:28 step:26723 [D loss: 0.576426, acc.: 70.31%] [G loss: 0.738421]\n",
      "epoch:28 step:26724 [D loss: 0.417758, acc.: 82.03%] [G loss: 0.784330]\n",
      "epoch:28 step:26725 [D loss: 0.536610, acc.: 71.88%] [G loss: 0.761850]\n",
      "epoch:28 step:26726 [D loss: 0.569450, acc.: 69.53%] [G loss: 0.653852]\n",
      "epoch:28 step:26727 [D loss: 0.559123, acc.: 67.97%] [G loss: 0.548502]\n",
      "epoch:28 step:26728 [D loss: 0.534746, acc.: 74.22%] [G loss: 0.732884]\n",
      "epoch:28 step:26729 [D loss: 0.576015, acc.: 67.19%] [G loss: 0.677963]\n",
      "epoch:28 step:26730 [D loss: 0.536270, acc.: 71.88%] [G loss: 0.640611]\n",
      "epoch:28 step:26731 [D loss: 0.461391, acc.: 80.47%] [G loss: 0.778363]\n",
      "epoch:28 step:26732 [D loss: 0.558472, acc.: 66.41%] [G loss: 0.702237]\n",
      "epoch:28 step:26733 [D loss: 0.507073, acc.: 76.56%] [G loss: 0.949340]\n",
      "epoch:28 step:26734 [D loss: 0.518003, acc.: 71.09%] [G loss: 0.897557]\n",
      "epoch:28 step:26735 [D loss: 0.471752, acc.: 77.34%] [G loss: 0.682906]\n",
      "epoch:28 step:26736 [D loss: 0.575906, acc.: 67.97%] [G loss: 0.815679]\n",
      "epoch:28 step:26737 [D loss: 0.659712, acc.: 60.94%] [G loss: 0.703932]\n",
      "epoch:28 step:26738 [D loss: 0.595308, acc.: 68.75%] [G loss: 0.683652]\n",
      "epoch:28 step:26739 [D loss: 0.498846, acc.: 76.56%] [G loss: 0.561495]\n",
      "epoch:28 step:26740 [D loss: 0.499389, acc.: 78.91%] [G loss: 0.831576]\n",
      "epoch:28 step:26741 [D loss: 0.499262, acc.: 75.00%] [G loss: 0.871817]\n",
      "epoch:28 step:26742 [D loss: 0.507292, acc.: 75.00%] [G loss: 0.793064]\n",
      "epoch:28 step:26743 [D loss: 0.507322, acc.: 75.00%] [G loss: 0.928723]\n",
      "epoch:28 step:26744 [D loss: 0.395984, acc.: 79.69%] [G loss: 1.104623]\n",
      "epoch:28 step:26745 [D loss: 0.518247, acc.: 74.22%] [G loss: 0.841119]\n",
      "epoch:28 step:26746 [D loss: 0.552223, acc.: 74.22%] [G loss: 0.814036]\n",
      "epoch:28 step:26747 [D loss: 0.591410, acc.: 63.28%] [G loss: 0.573176]\n",
      "epoch:28 step:26748 [D loss: 0.558968, acc.: 70.31%] [G loss: 0.511233]\n",
      "epoch:28 step:26749 [D loss: 0.521546, acc.: 71.09%] [G loss: 0.752224]\n",
      "epoch:28 step:26750 [D loss: 0.493814, acc.: 72.66%] [G loss: 0.687054]\n",
      "epoch:28 step:26751 [D loss: 0.490853, acc.: 75.00%] [G loss: 0.684652]\n",
      "epoch:28 step:26752 [D loss: 0.464648, acc.: 78.12%] [G loss: 0.766542]\n",
      "epoch:28 step:26753 [D loss: 0.517870, acc.: 72.66%] [G loss: 0.906577]\n",
      "epoch:28 step:26754 [D loss: 0.504765, acc.: 76.56%] [G loss: 0.789536]\n",
      "epoch:28 step:26755 [D loss: 0.512102, acc.: 71.09%] [G loss: 0.752022]\n",
      "epoch:28 step:26756 [D loss: 0.517447, acc.: 76.56%] [G loss: 0.729859]\n",
      "epoch:28 step:26757 [D loss: 0.491278, acc.: 75.78%] [G loss: 0.791834]\n",
      "epoch:28 step:26758 [D loss: 0.495042, acc.: 78.12%] [G loss: 0.853607]\n",
      "epoch:28 step:26759 [D loss: 0.452554, acc.: 77.34%] [G loss: 0.832008]\n",
      "epoch:28 step:26760 [D loss: 0.556967, acc.: 68.75%] [G loss: 0.721870]\n",
      "epoch:28 step:26761 [D loss: 0.617228, acc.: 65.62%] [G loss: 0.806745]\n",
      "epoch:28 step:26762 [D loss: 0.461173, acc.: 75.78%] [G loss: 0.918829]\n",
      "epoch:28 step:26763 [D loss: 0.552702, acc.: 71.88%] [G loss: 0.595630]\n",
      "epoch:28 step:26764 [D loss: 0.714276, acc.: 60.16%] [G loss: 0.558923]\n",
      "epoch:28 step:26765 [D loss: 0.603858, acc.: 62.50%] [G loss: 0.602600]\n",
      "epoch:28 step:26766 [D loss: 0.521885, acc.: 68.75%] [G loss: 0.749666]\n",
      "epoch:28 step:26767 [D loss: 0.536120, acc.: 73.44%] [G loss: 0.680532]\n",
      "epoch:28 step:26768 [D loss: 0.525930, acc.: 75.00%] [G loss: 0.658844]\n",
      "epoch:28 step:26769 [D loss: 0.535961, acc.: 70.31%] [G loss: 0.662929]\n",
      "epoch:28 step:26770 [D loss: 0.435591, acc.: 76.56%] [G loss: 0.667033]\n",
      "epoch:28 step:26771 [D loss: 0.593902, acc.: 63.28%] [G loss: 0.819903]\n",
      "epoch:28 step:26772 [D loss: 0.466144, acc.: 77.34%] [G loss: 0.661332]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:28 step:26773 [D loss: 0.578115, acc.: 65.62%] [G loss: 0.708693]\n",
      "epoch:28 step:26774 [D loss: 0.569103, acc.: 70.31%] [G loss: 0.463460]\n",
      "epoch:28 step:26775 [D loss: 0.512778, acc.: 70.31%] [G loss: 0.634124]\n",
      "epoch:28 step:26776 [D loss: 0.516892, acc.: 68.75%] [G loss: 0.718922]\n",
      "epoch:28 step:26777 [D loss: 0.521165, acc.: 71.88%] [G loss: 0.790596]\n",
      "epoch:28 step:26778 [D loss: 0.613809, acc.: 67.19%] [G loss: 0.543831]\n",
      "epoch:28 step:26779 [D loss: 0.548035, acc.: 70.31%] [G loss: 0.694080]\n",
      "epoch:28 step:26780 [D loss: 0.523530, acc.: 74.22%] [G loss: 0.653538]\n",
      "epoch:28 step:26781 [D loss: 0.503266, acc.: 74.22%] [G loss: 0.663617]\n",
      "epoch:28 step:26782 [D loss: 0.537566, acc.: 73.44%] [G loss: 0.701858]\n",
      "epoch:28 step:26783 [D loss: 0.523830, acc.: 71.88%] [G loss: 0.673127]\n",
      "epoch:28 step:26784 [D loss: 0.448785, acc.: 78.12%] [G loss: 0.750388]\n",
      "epoch:28 step:26785 [D loss: 0.533076, acc.: 71.88%] [G loss: 0.765813]\n",
      "epoch:28 step:26786 [D loss: 0.535477, acc.: 70.31%] [G loss: 0.882619]\n",
      "epoch:28 step:26787 [D loss: 0.510155, acc.: 72.66%] [G loss: 0.784730]\n",
      "epoch:28 step:26788 [D loss: 0.469511, acc.: 79.69%] [G loss: 0.818998]\n",
      "epoch:28 step:26789 [D loss: 0.545657, acc.: 68.75%] [G loss: 0.625772]\n",
      "epoch:28 step:26790 [D loss: 0.425628, acc.: 82.03%] [G loss: 0.712140]\n",
      "epoch:28 step:26791 [D loss: 0.448541, acc.: 78.12%] [G loss: 0.862003]\n",
      "epoch:28 step:26792 [D loss: 0.555340, acc.: 69.53%] [G loss: 0.772775]\n",
      "epoch:28 step:26793 [D loss: 0.467415, acc.: 75.00%] [G loss: 0.981307]\n",
      "epoch:28 step:26794 [D loss: 0.453725, acc.: 80.47%] [G loss: 0.721484]\n",
      "epoch:28 step:26795 [D loss: 0.591294, acc.: 68.75%] [G loss: 0.726322]\n",
      "epoch:28 step:26796 [D loss: 0.545564, acc.: 67.97%] [G loss: 0.737120]\n",
      "epoch:28 step:26797 [D loss: 0.545465, acc.: 64.84%] [G loss: 0.781132]\n",
      "epoch:28 step:26798 [D loss: 0.516306, acc.: 73.44%] [G loss: 0.756919]\n",
      "epoch:28 step:26799 [D loss: 0.565669, acc.: 70.31%] [G loss: 0.533934]\n",
      "epoch:28 step:26800 [D loss: 0.457141, acc.: 82.03%] [G loss: 0.786304]\n",
      "##############\n",
      "[2.9159515  1.04802611 6.1692192  4.89455421 3.94942782 5.71224866\n",
      " 4.27869113 4.82063165 4.71194142 4.336752  ]\n",
      "##########\n",
      "epoch:28 step:26801 [D loss: 0.516172, acc.: 73.44%] [G loss: 0.771071]\n",
      "epoch:28 step:26802 [D loss: 0.712073, acc.: 60.16%] [G loss: 0.611039]\n",
      "epoch:28 step:26803 [D loss: 0.550925, acc.: 69.53%] [G loss: 0.735926]\n",
      "epoch:28 step:26804 [D loss: 0.489599, acc.: 76.56%] [G loss: 0.739123]\n",
      "epoch:28 step:26805 [D loss: 0.524279, acc.: 72.66%] [G loss: 0.880292]\n",
      "epoch:28 step:26806 [D loss: 0.520255, acc.: 73.44%] [G loss: 0.652714]\n",
      "epoch:28 step:26807 [D loss: 0.575770, acc.: 63.28%] [G loss: 0.772277]\n",
      "epoch:28 step:26808 [D loss: 0.538016, acc.: 70.31%] [G loss: 0.754469]\n",
      "epoch:28 step:26809 [D loss: 0.531635, acc.: 72.66%] [G loss: 0.804497]\n",
      "epoch:28 step:26810 [D loss: 0.497783, acc.: 76.56%] [G loss: 0.853385]\n",
      "epoch:28 step:26811 [D loss: 0.494131, acc.: 76.56%] [G loss: 0.976524]\n",
      "epoch:28 step:26812 [D loss: 0.569389, acc.: 67.97%] [G loss: 0.731581]\n",
      "epoch:28 step:26813 [D loss: 0.633942, acc.: 64.06%] [G loss: 0.637058]\n",
      "epoch:28 step:26814 [D loss: 0.537388, acc.: 72.66%] [G loss: 0.675585]\n",
      "epoch:28 step:26815 [D loss: 0.500981, acc.: 74.22%] [G loss: 0.658956]\n",
      "epoch:28 step:26816 [D loss: 0.535619, acc.: 72.66%] [G loss: 0.675045]\n",
      "epoch:28 step:26817 [D loss: 0.495675, acc.: 75.78%] [G loss: 0.650364]\n",
      "epoch:28 step:26818 [D loss: 0.377512, acc.: 81.25%] [G loss: 0.945698]\n",
      "epoch:28 step:26819 [D loss: 0.608238, acc.: 70.31%] [G loss: 0.904947]\n",
      "epoch:28 step:26820 [D loss: 0.681054, acc.: 62.50%] [G loss: 0.533138]\n",
      "epoch:28 step:26821 [D loss: 0.572549, acc.: 67.97%] [G loss: 0.545509]\n",
      "epoch:28 step:26822 [D loss: 0.562538, acc.: 69.53%] [G loss: 0.748601]\n",
      "epoch:28 step:26823 [D loss: 0.506858, acc.: 75.00%] [G loss: 0.613640]\n",
      "epoch:28 step:26824 [D loss: 0.540383, acc.: 68.75%] [G loss: 0.599012]\n",
      "epoch:28 step:26825 [D loss: 0.558905, acc.: 64.06%] [G loss: 0.776562]\n",
      "epoch:28 step:26826 [D loss: 0.496169, acc.: 77.34%] [G loss: 0.847195]\n",
      "epoch:28 step:26827 [D loss: 0.592367, acc.: 67.19%] [G loss: 0.660984]\n",
      "epoch:28 step:26828 [D loss: 0.456805, acc.: 78.91%] [G loss: 0.702701]\n",
      "epoch:28 step:26829 [D loss: 0.498210, acc.: 75.78%] [G loss: 0.665329]\n",
      "epoch:28 step:26830 [D loss: 0.604708, acc.: 65.62%] [G loss: 0.655826]\n",
      "epoch:28 step:26831 [D loss: 0.534004, acc.: 71.88%] [G loss: 0.659431]\n",
      "epoch:28 step:26832 [D loss: 0.534282, acc.: 68.75%] [G loss: 0.676190]\n",
      "epoch:28 step:26833 [D loss: 0.580852, acc.: 66.41%] [G loss: 0.677458]\n",
      "epoch:28 step:26834 [D loss: 0.483110, acc.: 75.00%] [G loss: 0.652909]\n",
      "epoch:28 step:26835 [D loss: 0.507533, acc.: 78.12%] [G loss: 0.870418]\n",
      "epoch:28 step:26836 [D loss: 0.551658, acc.: 70.31%] [G loss: 0.797076]\n",
      "epoch:28 step:26837 [D loss: 0.533416, acc.: 69.53%] [G loss: 0.812377]\n",
      "epoch:28 step:26838 [D loss: 0.506096, acc.: 75.00%] [G loss: 0.765828]\n",
      "epoch:28 step:26839 [D loss: 0.486167, acc.: 75.00%] [G loss: 0.876124]\n",
      "epoch:28 step:26840 [D loss: 0.507212, acc.: 72.66%] [G loss: 0.790493]\n",
      "epoch:28 step:26841 [D loss: 0.441761, acc.: 81.25%] [G loss: 0.975459]\n",
      "epoch:28 step:26842 [D loss: 0.594349, acc.: 64.84%] [G loss: 0.693427]\n",
      "epoch:28 step:26843 [D loss: 0.554336, acc.: 70.31%] [G loss: 0.581097]\n",
      "epoch:28 step:26844 [D loss: 0.518331, acc.: 72.66%] [G loss: 0.643516]\n",
      "epoch:28 step:26845 [D loss: 0.512197, acc.: 71.09%] [G loss: 0.777049]\n",
      "epoch:28 step:26846 [D loss: 0.525258, acc.: 75.78%] [G loss: 0.634547]\n",
      "epoch:28 step:26847 [D loss: 0.488445, acc.: 75.78%] [G loss: 0.500047]\n",
      "epoch:28 step:26848 [D loss: 0.570230, acc.: 75.78%] [G loss: 0.690246]\n",
      "epoch:28 step:26849 [D loss: 0.469443, acc.: 71.88%] [G loss: 0.657249]\n",
      "epoch:28 step:26850 [D loss: 0.573444, acc.: 72.66%] [G loss: 0.881925]\n",
      "epoch:28 step:26851 [D loss: 0.573926, acc.: 71.09%] [G loss: 0.785989]\n",
      "epoch:28 step:26852 [D loss: 0.556954, acc.: 70.31%] [G loss: 0.579594]\n",
      "epoch:28 step:26853 [D loss: 0.530721, acc.: 70.31%] [G loss: 0.776420]\n",
      "epoch:28 step:26854 [D loss: 0.550261, acc.: 71.09%] [G loss: 0.525438]\n",
      "epoch:28 step:26855 [D loss: 0.530088, acc.: 72.66%] [G loss: 0.824206]\n",
      "epoch:28 step:26856 [D loss: 0.503004, acc.: 73.44%] [G loss: 0.765970]\n",
      "epoch:28 step:26857 [D loss: 0.535364, acc.: 71.09%] [G loss: 0.815172]\n",
      "epoch:28 step:26858 [D loss: 0.536522, acc.: 73.44%] [G loss: 0.767531]\n",
      "epoch:28 step:26859 [D loss: 0.449146, acc.: 78.91%] [G loss: 0.614840]\n",
      "epoch:28 step:26860 [D loss: 0.447450, acc.: 79.69%] [G loss: 0.850306]\n",
      "epoch:28 step:26861 [D loss: 0.515007, acc.: 75.00%] [G loss: 0.922306]\n",
      "epoch:28 step:26862 [D loss: 0.535242, acc.: 71.09%] [G loss: 0.696471]\n",
      "epoch:28 step:26863 [D loss: 0.600643, acc.: 65.62%] [G loss: 0.664107]\n",
      "epoch:28 step:26864 [D loss: 0.570827, acc.: 66.41%] [G loss: 0.462019]\n",
      "epoch:28 step:26865 [D loss: 0.469462, acc.: 75.78%] [G loss: 0.876255]\n",
      "epoch:28 step:26866 [D loss: 0.558162, acc.: 64.06%] [G loss: 0.867339]\n",
      "epoch:28 step:26867 [D loss: 0.481139, acc.: 78.91%] [G loss: 0.661211]\n",
      "epoch:28 step:26868 [D loss: 0.519009, acc.: 71.88%] [G loss: 0.747528]\n",
      "epoch:28 step:26869 [D loss: 0.549226, acc.: 70.31%] [G loss: 0.796556]\n",
      "epoch:28 step:26870 [D loss: 0.454264, acc.: 79.69%] [G loss: 0.969644]\n",
      "epoch:28 step:26871 [D loss: 0.493728, acc.: 74.22%] [G loss: 0.747046]\n",
      "epoch:28 step:26872 [D loss: 0.553711, acc.: 70.31%] [G loss: 0.808107]\n",
      "epoch:28 step:26873 [D loss: 0.542822, acc.: 72.66%] [G loss: 0.597966]\n",
      "epoch:28 step:26874 [D loss: 0.505971, acc.: 71.88%] [G loss: 0.618299]\n",
      "epoch:28 step:26875 [D loss: 0.498350, acc.: 73.44%] [G loss: 0.657509]\n",
      "epoch:28 step:26876 [D loss: 0.632817, acc.: 64.06%] [G loss: 0.575698]\n",
      "epoch:28 step:26877 [D loss: 0.483732, acc.: 74.22%] [G loss: 0.687689]\n",
      "epoch:28 step:26878 [D loss: 0.541153, acc.: 71.09%] [G loss: 0.714583]\n",
      "epoch:28 step:26879 [D loss: 0.501130, acc.: 74.22%] [G loss: 0.868040]\n",
      "epoch:28 step:26880 [D loss: 0.554307, acc.: 69.53%] [G loss: 0.815740]\n",
      "epoch:28 step:26881 [D loss: 0.564417, acc.: 70.31%] [G loss: 0.582585]\n",
      "epoch:28 step:26882 [D loss: 0.552132, acc.: 75.00%] [G loss: 0.788418]\n",
      "epoch:28 step:26883 [D loss: 0.414186, acc.: 83.59%] [G loss: 0.984627]\n",
      "epoch:28 step:26884 [D loss: 0.410250, acc.: 83.59%] [G loss: 1.038565]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:28 step:26885 [D loss: 0.470463, acc.: 75.78%] [G loss: 1.060951]\n",
      "epoch:28 step:26886 [D loss: 0.458790, acc.: 77.34%] [G loss: 1.122299]\n",
      "epoch:28 step:26887 [D loss: 0.557878, acc.: 70.31%] [G loss: 0.933439]\n",
      "epoch:28 step:26888 [D loss: 0.619103, acc.: 71.09%] [G loss: 0.860901]\n",
      "epoch:28 step:26889 [D loss: 0.506544, acc.: 76.56%] [G loss: 0.791226]\n",
      "epoch:28 step:26890 [D loss: 0.422928, acc.: 79.69%] [G loss: 0.969202]\n",
      "epoch:28 step:26891 [D loss: 0.544971, acc.: 74.22%] [G loss: 0.821051]\n",
      "epoch:28 step:26892 [D loss: 0.539766, acc.: 68.75%] [G loss: 0.694087]\n",
      "epoch:28 step:26893 [D loss: 0.493663, acc.: 74.22%] [G loss: 0.727298]\n",
      "epoch:28 step:26894 [D loss: 0.540737, acc.: 70.31%] [G loss: 0.865799]\n",
      "epoch:28 step:26895 [D loss: 0.484188, acc.: 75.00%] [G loss: 1.001763]\n",
      "epoch:28 step:26896 [D loss: 0.486502, acc.: 75.00%] [G loss: 0.802591]\n",
      "epoch:28 step:26897 [D loss: 0.493160, acc.: 75.78%] [G loss: 0.803782]\n",
      "epoch:28 step:26898 [D loss: 0.478489, acc.: 73.44%] [G loss: 0.937836]\n",
      "epoch:28 step:26899 [D loss: 0.562285, acc.: 66.41%] [G loss: 0.720825]\n",
      "epoch:28 step:26900 [D loss: 0.537159, acc.: 72.66%] [G loss: 0.801947]\n",
      "epoch:28 step:26901 [D loss: 0.572979, acc.: 64.06%] [G loss: 0.793198]\n",
      "epoch:28 step:26902 [D loss: 0.501426, acc.: 73.44%] [G loss: 0.712060]\n",
      "epoch:28 step:26903 [D loss: 0.524677, acc.: 74.22%] [G loss: 0.885185]\n",
      "epoch:28 step:26904 [D loss: 0.508598, acc.: 75.78%] [G loss: 1.015970]\n",
      "epoch:28 step:26905 [D loss: 0.544757, acc.: 71.09%] [G loss: 0.782050]\n",
      "epoch:28 step:26906 [D loss: 0.531878, acc.: 67.97%] [G loss: 0.845648]\n",
      "epoch:28 step:26907 [D loss: 0.519545, acc.: 75.00%] [G loss: 0.664293]\n",
      "epoch:28 step:26908 [D loss: 0.521479, acc.: 72.66%] [G loss: 0.673306]\n",
      "epoch:28 step:26909 [D loss: 0.544838, acc.: 67.97%] [G loss: 0.622923]\n",
      "epoch:28 step:26910 [D loss: 0.542332, acc.: 71.09%] [G loss: 0.801520]\n",
      "epoch:28 step:26911 [D loss: 0.581653, acc.: 68.75%] [G loss: 0.677266]\n",
      "epoch:28 step:26912 [D loss: 0.555970, acc.: 70.31%] [G loss: 0.630175]\n",
      "epoch:28 step:26913 [D loss: 0.473995, acc.: 77.34%] [G loss: 0.782219]\n",
      "epoch:28 step:26914 [D loss: 0.605344, acc.: 67.97%] [G loss: 0.691951]\n",
      "epoch:28 step:26915 [D loss: 0.466134, acc.: 75.00%] [G loss: 0.737321]\n",
      "epoch:28 step:26916 [D loss: 0.508446, acc.: 77.34%] [G loss: 0.750433]\n",
      "epoch:28 step:26917 [D loss: 0.464323, acc.: 76.56%] [G loss: 0.804995]\n",
      "epoch:28 step:26918 [D loss: 0.557471, acc.: 66.41%] [G loss: 0.639509]\n",
      "epoch:28 step:26919 [D loss: 0.532242, acc.: 67.97%] [G loss: 0.716294]\n",
      "epoch:28 step:26920 [D loss: 0.612090, acc.: 62.50%] [G loss: 0.584236]\n",
      "epoch:28 step:26921 [D loss: 0.527714, acc.: 71.09%] [G loss: 0.743579]\n",
      "epoch:28 step:26922 [D loss: 0.531425, acc.: 67.97%] [G loss: 0.644096]\n",
      "epoch:28 step:26923 [D loss: 0.617904, acc.: 62.50%] [G loss: 0.556376]\n",
      "epoch:28 step:26924 [D loss: 0.566896, acc.: 68.75%] [G loss: 0.699609]\n",
      "epoch:28 step:26925 [D loss: 0.554725, acc.: 71.88%] [G loss: 0.782992]\n",
      "epoch:28 step:26926 [D loss: 0.535319, acc.: 69.53%] [G loss: 0.693494]\n",
      "epoch:28 step:26927 [D loss: 0.498024, acc.: 74.22%] [G loss: 0.776733]\n",
      "epoch:28 step:26928 [D loss: 0.553917, acc.: 70.31%] [G loss: 0.709508]\n",
      "epoch:28 step:26929 [D loss: 0.463455, acc.: 82.03%] [G loss: 0.808536]\n",
      "epoch:28 step:26930 [D loss: 0.476440, acc.: 77.34%] [G loss: 0.798855]\n",
      "epoch:28 step:26931 [D loss: 0.501978, acc.: 76.56%] [G loss: 0.768636]\n",
      "epoch:28 step:26932 [D loss: 0.649371, acc.: 60.16%] [G loss: 0.717113]\n",
      "epoch:28 step:26933 [D loss: 0.573331, acc.: 64.84%] [G loss: 0.761858]\n",
      "epoch:28 step:26934 [D loss: 0.597077, acc.: 62.50%] [G loss: 0.646553]\n",
      "epoch:28 step:26935 [D loss: 0.516867, acc.: 68.75%] [G loss: 0.818707]\n",
      "epoch:28 step:26936 [D loss: 0.555049, acc.: 69.53%] [G loss: 0.762741]\n",
      "epoch:28 step:26937 [D loss: 0.503357, acc.: 76.56%] [G loss: 0.664883]\n",
      "epoch:28 step:26938 [D loss: 0.525271, acc.: 71.09%] [G loss: 0.792707]\n",
      "epoch:28 step:26939 [D loss: 0.612605, acc.: 62.50%] [G loss: 0.786281]\n",
      "epoch:28 step:26940 [D loss: 0.601690, acc.: 62.50%] [G loss: 0.705792]\n",
      "epoch:28 step:26941 [D loss: 0.484238, acc.: 75.00%] [G loss: 0.751561]\n",
      "epoch:28 step:26942 [D loss: 0.512000, acc.: 76.56%] [G loss: 0.589002]\n",
      "epoch:28 step:26943 [D loss: 0.498639, acc.: 72.66%] [G loss: 0.749909]\n",
      "epoch:28 step:26944 [D loss: 0.487475, acc.: 76.56%] [G loss: 0.902488]\n",
      "epoch:28 step:26945 [D loss: 0.480829, acc.: 74.22%] [G loss: 0.807096]\n",
      "epoch:28 step:26946 [D loss: 0.530570, acc.: 70.31%] [G loss: 0.643010]\n",
      "epoch:28 step:26947 [D loss: 0.589139, acc.: 64.06%] [G loss: 0.540110]\n",
      "epoch:28 step:26948 [D loss: 0.530528, acc.: 72.66%] [G loss: 0.739111]\n",
      "epoch:28 step:26949 [D loss: 0.536063, acc.: 70.31%] [G loss: 0.768242]\n",
      "epoch:28 step:26950 [D loss: 0.523967, acc.: 72.66%] [G loss: 0.574809]\n",
      "epoch:28 step:26951 [D loss: 0.542796, acc.: 71.09%] [G loss: 0.767126]\n",
      "epoch:28 step:26952 [D loss: 0.559462, acc.: 70.31%] [G loss: 0.804148]\n",
      "epoch:28 step:26953 [D loss: 0.551796, acc.: 73.44%] [G loss: 0.576511]\n",
      "epoch:28 step:26954 [D loss: 0.568937, acc.: 68.75%] [G loss: 0.552668]\n",
      "epoch:28 step:26955 [D loss: 0.472242, acc.: 77.34%] [G loss: 0.893984]\n",
      "epoch:28 step:26956 [D loss: 0.536002, acc.: 75.00%] [G loss: 0.826600]\n",
      "epoch:28 step:26957 [D loss: 0.541764, acc.: 71.09%] [G loss: 0.604213]\n",
      "epoch:28 step:26958 [D loss: 0.554792, acc.: 70.31%] [G loss: 0.594374]\n",
      "epoch:28 step:26959 [D loss: 0.536446, acc.: 70.31%] [G loss: 0.669277]\n",
      "epoch:28 step:26960 [D loss: 0.522805, acc.: 75.78%] [G loss: 0.771871]\n",
      "epoch:28 step:26961 [D loss: 0.483916, acc.: 77.34%] [G loss: 0.757165]\n",
      "epoch:28 step:26962 [D loss: 0.517467, acc.: 75.00%] [G loss: 0.661145]\n",
      "epoch:28 step:26963 [D loss: 0.509010, acc.: 75.00%] [G loss: 0.697824]\n",
      "epoch:28 step:26964 [D loss: 0.583026, acc.: 65.62%] [G loss: 0.691182]\n",
      "epoch:28 step:26965 [D loss: 0.571297, acc.: 71.88%] [G loss: 0.597226]\n",
      "epoch:28 step:26966 [D loss: 0.467161, acc.: 78.91%] [G loss: 0.764938]\n",
      "epoch:28 step:26967 [D loss: 0.577105, acc.: 68.75%] [G loss: 0.694462]\n",
      "epoch:28 step:26968 [D loss: 0.533637, acc.: 69.53%] [G loss: 0.567343]\n",
      "epoch:28 step:26969 [D loss: 0.511411, acc.: 75.78%] [G loss: 0.565860]\n",
      "epoch:28 step:26970 [D loss: 0.560997, acc.: 67.19%] [G loss: 0.598772]\n",
      "epoch:28 step:26971 [D loss: 0.558377, acc.: 69.53%] [G loss: 0.662513]\n",
      "epoch:28 step:26972 [D loss: 0.505026, acc.: 72.66%] [G loss: 0.678836]\n",
      "epoch:28 step:26973 [D loss: 0.509032, acc.: 73.44%] [G loss: 0.646154]\n",
      "epoch:28 step:26974 [D loss: 0.525710, acc.: 71.88%] [G loss: 0.622308]\n",
      "epoch:28 step:26975 [D loss: 0.560612, acc.: 69.53%] [G loss: 0.799444]\n",
      "epoch:28 step:26976 [D loss: 0.604940, acc.: 64.06%] [G loss: 0.603469]\n",
      "epoch:28 step:26977 [D loss: 0.540615, acc.: 73.44%] [G loss: 0.590540]\n",
      "epoch:28 step:26978 [D loss: 0.499583, acc.: 71.88%] [G loss: 0.633484]\n",
      "epoch:28 step:26979 [D loss: 0.485902, acc.: 75.00%] [G loss: 0.773293]\n",
      "epoch:28 step:26980 [D loss: 0.582943, acc.: 71.09%] [G loss: 0.835205]\n",
      "epoch:28 step:26981 [D loss: 0.631881, acc.: 61.72%] [G loss: 0.553078]\n",
      "epoch:28 step:26982 [D loss: 0.441969, acc.: 78.91%] [G loss: 0.856854]\n",
      "epoch:28 step:26983 [D loss: 0.462546, acc.: 77.34%] [G loss: 0.903445]\n",
      "epoch:28 step:26984 [D loss: 0.514130, acc.: 73.44%] [G loss: 0.717636]\n",
      "epoch:28 step:26985 [D loss: 0.519194, acc.: 75.00%] [G loss: 0.795219]\n",
      "epoch:28 step:26986 [D loss: 0.507677, acc.: 71.88%] [G loss: 0.785329]\n",
      "epoch:28 step:26987 [D loss: 0.450667, acc.: 75.00%] [G loss: 1.089371]\n",
      "epoch:28 step:26988 [D loss: 0.574542, acc.: 67.97%] [G loss: 0.817109]\n",
      "epoch:28 step:26989 [D loss: 0.504006, acc.: 77.34%] [G loss: 0.813612]\n",
      "epoch:28 step:26990 [D loss: 0.552907, acc.: 70.31%] [G loss: 0.735940]\n",
      "epoch:28 step:26991 [D loss: 0.526083, acc.: 68.75%] [G loss: 0.860936]\n",
      "epoch:28 step:26992 [D loss: 0.533291, acc.: 71.09%] [G loss: 0.934759]\n",
      "epoch:28 step:26993 [D loss: 0.584030, acc.: 67.19%] [G loss: 0.786995]\n",
      "epoch:28 step:26994 [D loss: 0.472232, acc.: 78.12%] [G loss: 0.819107]\n",
      "epoch:28 step:26995 [D loss: 0.512631, acc.: 75.78%] [G loss: 0.603186]\n",
      "epoch:28 step:26996 [D loss: 0.562161, acc.: 66.41%] [G loss: 0.573053]\n",
      "epoch:28 step:26997 [D loss: 0.557986, acc.: 72.66%] [G loss: 0.726582]\n",
      "epoch:28 step:26998 [D loss: 0.564809, acc.: 65.62%] [G loss: 0.550225]\n",
      "epoch:28 step:26999 [D loss: 0.553932, acc.: 67.19%] [G loss: 0.632116]\n",
      "epoch:28 step:27000 [D loss: 0.538080, acc.: 73.44%] [G loss: 0.616305]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##############\n",
      "[3.1037402  1.32130618 5.93095246 4.92764469 3.61880588 5.69050014\n",
      " 4.31803541 4.61936713 4.77695992 4.36498884]\n",
      "##########\n",
      "epoch:28 step:27001 [D loss: 0.593005, acc.: 66.41%] [G loss: 0.679911]\n",
      "epoch:28 step:27002 [D loss: 0.612062, acc.: 60.94%] [G loss: 0.516210]\n",
      "epoch:28 step:27003 [D loss: 0.555384, acc.: 72.66%] [G loss: 0.808103]\n",
      "epoch:28 step:27004 [D loss: 0.508926, acc.: 73.44%] [G loss: 0.919864]\n",
      "epoch:28 step:27005 [D loss: 0.471530, acc.: 75.00%] [G loss: 0.988080]\n",
      "epoch:28 step:27006 [D loss: 0.560675, acc.: 68.75%] [G loss: 1.138061]\n",
      "epoch:28 step:27007 [D loss: 0.517806, acc.: 72.66%] [G loss: 0.766310]\n",
      "epoch:28 step:27008 [D loss: 0.519609, acc.: 72.66%] [G loss: 0.766389]\n",
      "epoch:28 step:27009 [D loss: 0.544620, acc.: 68.75%] [G loss: 0.642668]\n",
      "epoch:28 step:27010 [D loss: 0.560317, acc.: 71.88%] [G loss: 0.552754]\n",
      "epoch:28 step:27011 [D loss: 0.536738, acc.: 72.66%] [G loss: 0.741015]\n",
      "epoch:28 step:27012 [D loss: 0.543999, acc.: 69.53%] [G loss: 0.630287]\n",
      "epoch:28 step:27013 [D loss: 0.542619, acc.: 71.09%] [G loss: 0.655357]\n",
      "epoch:28 step:27014 [D loss: 0.588717, acc.: 68.75%] [G loss: 0.649934]\n",
      "epoch:28 step:27015 [D loss: 0.549044, acc.: 69.53%] [G loss: 0.657105]\n",
      "epoch:28 step:27016 [D loss: 0.489093, acc.: 76.56%] [G loss: 0.869836]\n",
      "epoch:28 step:27017 [D loss: 0.464986, acc.: 77.34%] [G loss: 1.059355]\n",
      "epoch:28 step:27018 [D loss: 0.587831, acc.: 67.97%] [G loss: 0.984349]\n",
      "epoch:28 step:27019 [D loss: 0.522961, acc.: 70.31%] [G loss: 0.935222]\n",
      "epoch:28 step:27020 [D loss: 0.651776, acc.: 65.62%] [G loss: 0.824020]\n",
      "epoch:28 step:27021 [D loss: 0.512374, acc.: 73.44%] [G loss: 0.734557]\n",
      "epoch:28 step:27022 [D loss: 0.529412, acc.: 72.66%] [G loss: 0.653801]\n",
      "epoch:28 step:27023 [D loss: 0.555913, acc.: 68.75%] [G loss: 0.899720]\n",
      "epoch:28 step:27024 [D loss: 0.639884, acc.: 63.28%] [G loss: 0.651140]\n",
      "epoch:28 step:27025 [D loss: 0.505896, acc.: 73.44%] [G loss: 0.530879]\n",
      "epoch:28 step:27026 [D loss: 0.517908, acc.: 71.88%] [G loss: 0.595936]\n",
      "epoch:28 step:27027 [D loss: 0.507003, acc.: 72.66%] [G loss: 0.635874]\n",
      "epoch:28 step:27028 [D loss: 0.454971, acc.: 78.12%] [G loss: 0.801588]\n",
      "epoch:28 step:27029 [D loss: 0.617909, acc.: 65.62%] [G loss: 0.769488]\n",
      "epoch:28 step:27030 [D loss: 0.655684, acc.: 64.84%] [G loss: 0.718853]\n",
      "epoch:28 step:27031 [D loss: 0.616730, acc.: 62.50%] [G loss: 0.814987]\n",
      "epoch:28 step:27032 [D loss: 0.525219, acc.: 70.31%] [G loss: 0.736050]\n",
      "epoch:28 step:27033 [D loss: 0.533406, acc.: 67.97%] [G loss: 0.612740]\n",
      "epoch:28 step:27034 [D loss: 0.517200, acc.: 71.09%] [G loss: 0.725118]\n",
      "epoch:28 step:27035 [D loss: 0.521609, acc.: 69.53%] [G loss: 0.614868]\n",
      "epoch:28 step:27036 [D loss: 0.590573, acc.: 64.84%] [G loss: 0.639613]\n",
      "epoch:28 step:27037 [D loss: 0.516127, acc.: 68.75%] [G loss: 0.782996]\n",
      "epoch:28 step:27038 [D loss: 0.505022, acc.: 71.88%] [G loss: 0.843215]\n",
      "epoch:28 step:27039 [D loss: 0.494114, acc.: 74.22%] [G loss: 0.899387]\n",
      "epoch:28 step:27040 [D loss: 0.548981, acc.: 71.88%] [G loss: 0.601452]\n",
      "epoch:28 step:27041 [D loss: 0.504291, acc.: 71.09%] [G loss: 0.730853]\n",
      "epoch:28 step:27042 [D loss: 0.587841, acc.: 67.97%] [G loss: 0.524576]\n",
      "epoch:28 step:27043 [D loss: 0.495474, acc.: 76.56%] [G loss: 0.587961]\n",
      "epoch:28 step:27044 [D loss: 0.491283, acc.: 75.00%] [G loss: 0.768432]\n",
      "epoch:28 step:27045 [D loss: 0.510643, acc.: 73.44%] [G loss: 0.636173]\n",
      "epoch:28 step:27046 [D loss: 0.488053, acc.: 75.00%] [G loss: 0.783314]\n",
      "epoch:28 step:27047 [D loss: 0.547922, acc.: 72.66%] [G loss: 0.620753]\n",
      "epoch:28 step:27048 [D loss: 0.643455, acc.: 64.84%] [G loss: 0.474623]\n",
      "epoch:28 step:27049 [D loss: 0.492635, acc.: 73.44%] [G loss: 0.869108]\n",
      "epoch:28 step:27050 [D loss: 0.443031, acc.: 80.47%] [G loss: 0.807445]\n",
      "epoch:28 step:27051 [D loss: 0.478956, acc.: 73.44%] [G loss: 0.933518]\n",
      "epoch:28 step:27052 [D loss: 0.606228, acc.: 64.84%] [G loss: 0.801385]\n",
      "epoch:28 step:27053 [D loss: 0.589872, acc.: 71.09%] [G loss: 0.771233]\n",
      "epoch:28 step:27054 [D loss: 0.560431, acc.: 69.53%] [G loss: 0.591780]\n",
      "epoch:28 step:27055 [D loss: 0.477491, acc.: 75.00%] [G loss: 0.636517]\n",
      "epoch:28 step:27056 [D loss: 0.623278, acc.: 66.41%] [G loss: 0.639674]\n",
      "epoch:28 step:27057 [D loss: 0.528311, acc.: 71.88%] [G loss: 0.641344]\n",
      "epoch:28 step:27058 [D loss: 0.522219, acc.: 68.75%] [G loss: 0.602902]\n",
      "epoch:28 step:27059 [D loss: 0.416026, acc.: 76.56%] [G loss: 0.746271]\n",
      "epoch:28 step:27060 [D loss: 0.527956, acc.: 71.88%] [G loss: 0.680080]\n",
      "epoch:28 step:27061 [D loss: 0.493648, acc.: 76.56%] [G loss: 0.760903]\n",
      "epoch:28 step:27062 [D loss: 0.542941, acc.: 70.31%] [G loss: 0.691539]\n",
      "epoch:28 step:27063 [D loss: 0.516508, acc.: 70.31%] [G loss: 0.679359]\n",
      "epoch:28 step:27064 [D loss: 0.598458, acc.: 63.28%] [G loss: 0.708715]\n",
      "epoch:28 step:27065 [D loss: 0.543881, acc.: 70.31%] [G loss: 0.605724]\n",
      "epoch:28 step:27066 [D loss: 0.514244, acc.: 73.44%] [G loss: 0.688612]\n",
      "epoch:28 step:27067 [D loss: 0.593214, acc.: 68.75%] [G loss: 0.655680]\n",
      "epoch:28 step:27068 [D loss: 0.543103, acc.: 71.88%] [G loss: 0.665244]\n",
      "epoch:28 step:27069 [D loss: 0.515100, acc.: 72.66%] [G loss: 0.789082]\n",
      "epoch:28 step:27070 [D loss: 0.500559, acc.: 73.44%] [G loss: 0.696682]\n",
      "epoch:28 step:27071 [D loss: 0.535895, acc.: 71.88%] [G loss: 0.656565]\n",
      "epoch:28 step:27072 [D loss: 0.520690, acc.: 72.66%] [G loss: 0.742717]\n",
      "epoch:28 step:27073 [D loss: 0.510368, acc.: 70.31%] [G loss: 0.622087]\n",
      "epoch:28 step:27074 [D loss: 0.488795, acc.: 75.78%] [G loss: 0.643088]\n",
      "epoch:28 step:27075 [D loss: 0.584757, acc.: 67.97%] [G loss: 0.662860]\n",
      "epoch:28 step:27076 [D loss: 0.551838, acc.: 71.88%] [G loss: 0.579315]\n",
      "epoch:28 step:27077 [D loss: 0.507253, acc.: 71.09%] [G loss: 0.781062]\n",
      "epoch:28 step:27078 [D loss: 0.503657, acc.: 75.78%] [G loss: 0.612613]\n",
      "epoch:28 step:27079 [D loss: 0.513294, acc.: 73.44%] [G loss: 0.722138]\n",
      "epoch:28 step:27080 [D loss: 0.515480, acc.: 75.00%] [G loss: 0.773779]\n",
      "epoch:28 step:27081 [D loss: 0.528598, acc.: 71.09%] [G loss: 0.740140]\n",
      "epoch:28 step:27082 [D loss: 0.564504, acc.: 67.97%] [G loss: 0.460886]\n",
      "epoch:28 step:27083 [D loss: 0.587861, acc.: 63.28%] [G loss: 0.640019]\n",
      "epoch:28 step:27084 [D loss: 0.511642, acc.: 72.66%] [G loss: 0.546763]\n",
      "epoch:28 step:27085 [D loss: 0.545339, acc.: 69.53%] [G loss: 0.578733]\n",
      "epoch:28 step:27086 [D loss: 0.526949, acc.: 75.78%] [G loss: 0.658969]\n",
      "epoch:28 step:27087 [D loss: 0.547115, acc.: 68.75%] [G loss: 0.708207]\n",
      "epoch:28 step:27088 [D loss: 0.584858, acc.: 68.75%] [G loss: 0.707564]\n",
      "epoch:28 step:27089 [D loss: 0.502631, acc.: 76.56%] [G loss: 0.681215]\n",
      "epoch:28 step:27090 [D loss: 0.547340, acc.: 68.75%] [G loss: 0.740224]\n",
      "epoch:28 step:27091 [D loss: 0.542940, acc.: 69.53%] [G loss: 0.837088]\n",
      "epoch:28 step:27092 [D loss: 0.562108, acc.: 69.53%] [G loss: 0.819362]\n",
      "epoch:28 step:27093 [D loss: 0.467913, acc.: 76.56%] [G loss: 0.763195]\n",
      "epoch:28 step:27094 [D loss: 0.576321, acc.: 67.19%] [G loss: 0.694449]\n",
      "epoch:28 step:27095 [D loss: 0.631850, acc.: 66.41%] [G loss: 0.691887]\n",
      "epoch:28 step:27096 [D loss: 0.450706, acc.: 76.56%] [G loss: 0.785793]\n",
      "epoch:28 step:27097 [D loss: 0.622838, acc.: 65.62%] [G loss: 0.844069]\n",
      "epoch:28 step:27098 [D loss: 0.606659, acc.: 65.62%] [G loss: 0.436724]\n",
      "epoch:28 step:27099 [D loss: 0.533420, acc.: 69.53%] [G loss: 0.653062]\n",
      "epoch:28 step:27100 [D loss: 0.575376, acc.: 64.06%] [G loss: 0.597294]\n",
      "epoch:28 step:27101 [D loss: 0.532700, acc.: 70.31%] [G loss: 0.618528]\n",
      "epoch:28 step:27102 [D loss: 0.491495, acc.: 72.66%] [G loss: 0.709877]\n",
      "epoch:28 step:27103 [D loss: 0.608402, acc.: 63.28%] [G loss: 0.523633]\n",
      "epoch:28 step:27104 [D loss: 0.520697, acc.: 70.31%] [G loss: 0.635554]\n",
      "epoch:28 step:27105 [D loss: 0.649977, acc.: 63.28%] [G loss: 0.549453]\n",
      "epoch:28 step:27106 [D loss: 0.476156, acc.: 76.56%] [G loss: 0.772005]\n",
      "epoch:28 step:27107 [D loss: 0.507986, acc.: 76.56%] [G loss: 0.673129]\n",
      "epoch:28 step:27108 [D loss: 0.509825, acc.: 71.88%] [G loss: 0.771392]\n",
      "epoch:28 step:27109 [D loss: 0.585645, acc.: 63.28%] [G loss: 0.609710]\n",
      "epoch:28 step:27110 [D loss: 0.562812, acc.: 65.62%] [G loss: 0.570166]\n",
      "epoch:28 step:27111 [D loss: 0.493713, acc.: 75.78%] [G loss: 0.650507]\n",
      "epoch:28 step:27112 [D loss: 0.579426, acc.: 68.75%] [G loss: 0.729345]\n",
      "epoch:28 step:27113 [D loss: 0.641597, acc.: 68.75%] [G loss: 0.597717]\n",
      "epoch:28 step:27114 [D loss: 0.562901, acc.: 66.41%] [G loss: 0.566603]\n",
      "epoch:28 step:27115 [D loss: 0.552595, acc.: 68.75%] [G loss: 0.618820]\n",
      "epoch:28 step:27116 [D loss: 0.702315, acc.: 53.91%] [G loss: 0.552166]\n",
      "epoch:28 step:27117 [D loss: 0.544151, acc.: 70.31%] [G loss: 0.578372]\n",
      "epoch:28 step:27118 [D loss: 0.619307, acc.: 60.16%] [G loss: 0.441012]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:28 step:27119 [D loss: 0.596196, acc.: 66.41%] [G loss: 0.429751]\n",
      "epoch:28 step:27120 [D loss: 0.524477, acc.: 73.44%] [G loss: 0.652906]\n",
      "epoch:28 step:27121 [D loss: 0.499328, acc.: 75.00%] [G loss: 0.726819]\n",
      "epoch:28 step:27122 [D loss: 0.456509, acc.: 78.91%] [G loss: 0.862719]\n",
      "epoch:28 step:27123 [D loss: 0.526550, acc.: 75.00%] [G loss: 0.883063]\n",
      "epoch:28 step:27124 [D loss: 0.516657, acc.: 73.44%] [G loss: 0.975067]\n",
      "epoch:28 step:27125 [D loss: 0.497989, acc.: 73.44%] [G loss: 0.904216]\n",
      "epoch:28 step:27126 [D loss: 0.502609, acc.: 74.22%] [G loss: 0.712079]\n",
      "epoch:28 step:27127 [D loss: 0.578674, acc.: 66.41%] [G loss: 0.809863]\n",
      "epoch:28 step:27128 [D loss: 0.640129, acc.: 64.84%] [G loss: 0.598210]\n",
      "epoch:28 step:27129 [D loss: 0.533622, acc.: 72.66%] [G loss: 0.606193]\n",
      "epoch:28 step:27130 [D loss: 0.480255, acc.: 78.12%] [G loss: 0.873069]\n",
      "epoch:28 step:27131 [D loss: 0.472745, acc.: 75.00%] [G loss: 0.937419]\n",
      "epoch:28 step:27132 [D loss: 0.509115, acc.: 73.44%] [G loss: 0.849274]\n",
      "epoch:28 step:27133 [D loss: 0.512115, acc.: 72.66%] [G loss: 0.813504]\n",
      "epoch:28 step:27134 [D loss: 0.417078, acc.: 84.38%] [G loss: 0.864608]\n",
      "epoch:28 step:27135 [D loss: 0.471931, acc.: 78.91%] [G loss: 0.883297]\n",
      "epoch:28 step:27136 [D loss: 0.479451, acc.: 81.25%] [G loss: 0.766309]\n",
      "epoch:28 step:27137 [D loss: 0.489831, acc.: 76.56%] [G loss: 1.106633]\n",
      "epoch:28 step:27138 [D loss: 0.547422, acc.: 67.97%] [G loss: 0.662357]\n",
      "epoch:28 step:27139 [D loss: 0.516659, acc.: 71.09%] [G loss: 0.923861]\n",
      "epoch:28 step:27140 [D loss: 0.531558, acc.: 73.44%] [G loss: 0.833556]\n",
      "epoch:28 step:27141 [D loss: 0.598037, acc.: 65.62%] [G loss: 0.790616]\n",
      "epoch:28 step:27142 [D loss: 0.452775, acc.: 81.25%] [G loss: 0.788100]\n",
      "epoch:28 step:27143 [D loss: 0.564508, acc.: 67.19%] [G loss: 0.693229]\n",
      "epoch:28 step:27144 [D loss: 0.520871, acc.: 71.09%] [G loss: 0.925174]\n",
      "epoch:28 step:27145 [D loss: 0.475402, acc.: 77.34%] [G loss: 0.752766]\n",
      "epoch:28 step:27146 [D loss: 0.536892, acc.: 69.53%] [G loss: 0.699540]\n",
      "epoch:28 step:27147 [D loss: 0.478257, acc.: 76.56%] [G loss: 0.731608]\n",
      "epoch:28 step:27148 [D loss: 0.451249, acc.: 75.00%] [G loss: 0.933032]\n",
      "epoch:28 step:27149 [D loss: 0.527990, acc.: 72.66%] [G loss: 0.916503]\n",
      "epoch:28 step:27150 [D loss: 0.516269, acc.: 67.97%] [G loss: 0.936518]\n",
      "epoch:28 step:27151 [D loss: 0.640854, acc.: 64.84%] [G loss: 0.845253]\n",
      "epoch:28 step:27152 [D loss: 0.511779, acc.: 78.91%] [G loss: 0.780606]\n",
      "epoch:28 step:27153 [D loss: 0.606405, acc.: 61.72%] [G loss: 0.565916]\n",
      "epoch:28 step:27154 [D loss: 0.471153, acc.: 77.34%] [G loss: 0.867927]\n",
      "epoch:28 step:27155 [D loss: 0.490019, acc.: 81.25%] [G loss: 1.343050]\n",
      "epoch:28 step:27156 [D loss: 0.772858, acc.: 59.38%] [G loss: 0.658003]\n",
      "epoch:28 step:27157 [D loss: 0.452106, acc.: 76.56%] [G loss: 0.846236]\n",
      "epoch:28 step:27158 [D loss: 0.540941, acc.: 72.66%] [G loss: 0.609386]\n",
      "epoch:28 step:27159 [D loss: 0.450394, acc.: 78.91%] [G loss: 0.811971]\n",
      "epoch:28 step:27160 [D loss: 0.468305, acc.: 71.09%] [G loss: 0.838630]\n",
      "epoch:28 step:27161 [D loss: 0.422411, acc.: 77.34%] [G loss: 1.166449]\n",
      "epoch:28 step:27162 [D loss: 0.470771, acc.: 75.00%] [G loss: 1.170924]\n",
      "epoch:28 step:27163 [D loss: 0.476006, acc.: 75.78%] [G loss: 0.957485]\n",
      "epoch:28 step:27164 [D loss: 0.618187, acc.: 68.75%] [G loss: 1.033461]\n",
      "epoch:28 step:27165 [D loss: 0.485191, acc.: 72.66%] [G loss: 1.373519]\n",
      "epoch:28 step:27166 [D loss: 0.458507, acc.: 78.12%] [G loss: 1.729461]\n",
      "epoch:28 step:27167 [D loss: 0.503826, acc.: 71.09%] [G loss: 1.165867]\n",
      "epoch:28 step:27168 [D loss: 0.628006, acc.: 64.84%] [G loss: 0.791768]\n",
      "epoch:28 step:27169 [D loss: 0.481273, acc.: 75.78%] [G loss: 1.258759]\n",
      "epoch:28 step:27170 [D loss: 0.595731, acc.: 65.62%] [G loss: 1.006258]\n",
      "epoch:28 step:27171 [D loss: 0.439357, acc.: 78.12%] [G loss: 1.050896]\n",
      "epoch:28 step:27172 [D loss: 0.388790, acc.: 82.81%] [G loss: 1.267412]\n",
      "epoch:28 step:27173 [D loss: 0.531922, acc.: 72.66%] [G loss: 1.524372]\n",
      "epoch:29 step:27174 [D loss: 0.527065, acc.: 71.09%] [G loss: 1.292063]\n",
      "epoch:29 step:27175 [D loss: 0.447851, acc.: 78.12%] [G loss: 1.173374]\n",
      "epoch:29 step:27176 [D loss: 0.528882, acc.: 73.44%] [G loss: 0.949846]\n",
      "epoch:29 step:27177 [D loss: 0.518215, acc.: 76.56%] [G loss: 1.056419]\n",
      "epoch:29 step:27178 [D loss: 0.577813, acc.: 68.75%] [G loss: 1.007223]\n",
      "epoch:29 step:27179 [D loss: 0.553953, acc.: 74.22%] [G loss: 0.888760]\n",
      "epoch:29 step:27180 [D loss: 0.488684, acc.: 76.56%] [G loss: 0.861708]\n",
      "epoch:29 step:27181 [D loss: 0.495049, acc.: 76.56%] [G loss: 0.699307]\n",
      "epoch:29 step:27182 [D loss: 0.482778, acc.: 75.78%] [G loss: 0.749994]\n",
      "epoch:29 step:27183 [D loss: 0.473069, acc.: 81.25%] [G loss: 0.778099]\n",
      "epoch:29 step:27184 [D loss: 0.478078, acc.: 79.69%] [G loss: 0.657983]\n",
      "epoch:29 step:27185 [D loss: 0.579559, acc.: 67.97%] [G loss: 0.796100]\n",
      "epoch:29 step:27186 [D loss: 0.541351, acc.: 71.88%] [G loss: 0.571895]\n",
      "epoch:29 step:27187 [D loss: 0.629503, acc.: 65.62%] [G loss: 0.694690]\n",
      "epoch:29 step:27188 [D loss: 0.511688, acc.: 72.66%] [G loss: 0.733092]\n",
      "epoch:29 step:27189 [D loss: 0.494379, acc.: 74.22%] [G loss: 0.769489]\n",
      "epoch:29 step:27190 [D loss: 0.549837, acc.: 71.88%] [G loss: 0.784155]\n",
      "epoch:29 step:27191 [D loss: 0.540914, acc.: 68.75%] [G loss: 0.661735]\n",
      "epoch:29 step:27192 [D loss: 0.519736, acc.: 72.66%] [G loss: 0.588753]\n",
      "epoch:29 step:27193 [D loss: 0.638569, acc.: 67.97%] [G loss: 0.615326]\n",
      "epoch:29 step:27194 [D loss: 0.536907, acc.: 68.75%] [G loss: 0.805063]\n",
      "epoch:29 step:27195 [D loss: 0.464555, acc.: 78.91%] [G loss: 0.930225]\n",
      "epoch:29 step:27196 [D loss: 0.538658, acc.: 72.66%] [G loss: 0.963392]\n",
      "epoch:29 step:27197 [D loss: 0.516919, acc.: 71.88%] [G loss: 0.652810]\n",
      "epoch:29 step:27198 [D loss: 0.460397, acc.: 76.56%] [G loss: 0.749842]\n",
      "epoch:29 step:27199 [D loss: 0.541216, acc.: 69.53%] [G loss: 0.711111]\n",
      "epoch:29 step:27200 [D loss: 0.460789, acc.: 78.12%] [G loss: 0.730500]\n",
      "##############\n",
      "[2.93597356 0.95111682 6.17158684 4.86274872 3.95227137 5.5114061\n",
      " 4.38597804 5.09498463 4.65643309 4.27204043]\n",
      "##########\n",
      "epoch:29 step:27201 [D loss: 0.544936, acc.: 67.97%] [G loss: 0.685969]\n",
      "epoch:29 step:27202 [D loss: 0.544595, acc.: 67.97%] [G loss: 0.842798]\n",
      "epoch:29 step:27203 [D loss: 0.532183, acc.: 72.66%] [G loss: 0.713663]\n",
      "epoch:29 step:27204 [D loss: 0.641482, acc.: 60.16%] [G loss: 0.742101]\n",
      "epoch:29 step:27205 [D loss: 0.531351, acc.: 71.09%] [G loss: 0.662639]\n",
      "epoch:29 step:27206 [D loss: 0.549473, acc.: 71.09%] [G loss: 0.947494]\n",
      "epoch:29 step:27207 [D loss: 0.530783, acc.: 67.19%] [G loss: 0.796660]\n",
      "epoch:29 step:27208 [D loss: 0.596881, acc.: 59.38%] [G loss: 0.776481]\n",
      "epoch:29 step:27209 [D loss: 0.534349, acc.: 67.97%] [G loss: 0.699745]\n",
      "epoch:29 step:27210 [D loss: 0.478534, acc.: 74.22%] [G loss: 0.813396]\n",
      "epoch:29 step:27211 [D loss: 0.524960, acc.: 74.22%] [G loss: 0.697554]\n",
      "epoch:29 step:27212 [D loss: 0.559231, acc.: 66.41%] [G loss: 0.720636]\n",
      "epoch:29 step:27213 [D loss: 0.444400, acc.: 80.47%] [G loss: 0.803841]\n",
      "epoch:29 step:27214 [D loss: 0.544246, acc.: 69.53%] [G loss: 0.867929]\n",
      "epoch:29 step:27215 [D loss: 0.500087, acc.: 68.75%] [G loss: 0.829588]\n",
      "epoch:29 step:27216 [D loss: 0.530492, acc.: 69.53%] [G loss: 0.770008]\n",
      "epoch:29 step:27217 [D loss: 0.587761, acc.: 69.53%] [G loss: 0.788194]\n",
      "epoch:29 step:27218 [D loss: 0.472552, acc.: 78.91%] [G loss: 0.817727]\n",
      "epoch:29 step:27219 [D loss: 0.471252, acc.: 77.34%] [G loss: 0.918794]\n",
      "epoch:29 step:27220 [D loss: 0.504135, acc.: 74.22%] [G loss: 0.715771]\n",
      "epoch:29 step:27221 [D loss: 0.478693, acc.: 80.47%] [G loss: 0.835834]\n",
      "epoch:29 step:27222 [D loss: 0.506602, acc.: 74.22%] [G loss: 0.696402]\n",
      "epoch:29 step:27223 [D loss: 0.519590, acc.: 71.88%] [G loss: 0.842189]\n",
      "epoch:29 step:27224 [D loss: 0.626770, acc.: 61.72%] [G loss: 0.591197]\n",
      "epoch:29 step:27225 [D loss: 0.595990, acc.: 66.41%] [G loss: 0.567888]\n",
      "epoch:29 step:27226 [D loss: 0.502593, acc.: 80.47%] [G loss: 0.719494]\n",
      "epoch:29 step:27227 [D loss: 0.461979, acc.: 75.00%] [G loss: 0.890440]\n",
      "epoch:29 step:27228 [D loss: 0.529758, acc.: 72.66%] [G loss: 1.000758]\n",
      "epoch:29 step:27229 [D loss: 0.526483, acc.: 71.88%] [G loss: 0.653472]\n",
      "epoch:29 step:27230 [D loss: 0.532541, acc.: 70.31%] [G loss: 0.754320]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:29 step:27231 [D loss: 0.549423, acc.: 67.19%] [G loss: 0.833764]\n",
      "epoch:29 step:27232 [D loss: 0.471995, acc.: 73.44%] [G loss: 0.978102]\n",
      "epoch:29 step:27233 [D loss: 0.595039, acc.: 67.97%] [G loss: 0.812059]\n",
      "epoch:29 step:27234 [D loss: 0.548083, acc.: 67.97%] [G loss: 0.573100]\n",
      "epoch:29 step:27235 [D loss: 0.531804, acc.: 72.66%] [G loss: 0.711514]\n",
      "epoch:29 step:27236 [D loss: 0.500015, acc.: 74.22%] [G loss: 0.730622]\n",
      "epoch:29 step:27237 [D loss: 0.555805, acc.: 71.88%] [G loss: 0.733680]\n",
      "epoch:29 step:27238 [D loss: 0.504593, acc.: 72.66%] [G loss: 0.799801]\n",
      "epoch:29 step:27239 [D loss: 0.591227, acc.: 67.19%] [G loss: 0.590414]\n",
      "epoch:29 step:27240 [D loss: 0.533890, acc.: 69.53%] [G loss: 0.666597]\n",
      "epoch:29 step:27241 [D loss: 0.511233, acc.: 75.00%] [G loss: 0.601612]\n",
      "epoch:29 step:27242 [D loss: 0.430158, acc.: 84.38%] [G loss: 0.770091]\n",
      "epoch:29 step:27243 [D loss: 0.566593, acc.: 74.22%] [G loss: 0.752888]\n",
      "epoch:29 step:27244 [D loss: 0.537643, acc.: 75.00%] [G loss: 0.636171]\n",
      "epoch:29 step:27245 [D loss: 0.575895, acc.: 65.62%] [G loss: 0.602611]\n",
      "epoch:29 step:27246 [D loss: 0.564070, acc.: 67.97%] [G loss: 0.695092]\n",
      "epoch:29 step:27247 [D loss: 0.493092, acc.: 75.00%] [G loss: 0.823723]\n",
      "epoch:29 step:27248 [D loss: 0.478852, acc.: 73.44%] [G loss: 1.016376]\n",
      "epoch:29 step:27249 [D loss: 0.517170, acc.: 67.97%] [G loss: 0.952216]\n",
      "epoch:29 step:27250 [D loss: 0.452429, acc.: 74.22%] [G loss: 0.990609]\n",
      "epoch:29 step:27251 [D loss: 0.615633, acc.: 67.19%] [G loss: 0.790221]\n",
      "epoch:29 step:27252 [D loss: 0.539923, acc.: 70.31%] [G loss: 0.782463]\n",
      "epoch:29 step:27253 [D loss: 0.475995, acc.: 77.34%] [G loss: 0.809867]\n",
      "epoch:29 step:27254 [D loss: 0.527935, acc.: 68.75%] [G loss: 0.843950]\n",
      "epoch:29 step:27255 [D loss: 0.523195, acc.: 69.53%] [G loss: 0.712660]\n",
      "epoch:29 step:27256 [D loss: 0.442556, acc.: 78.12%] [G loss: 0.954373]\n",
      "epoch:29 step:27257 [D loss: 0.531810, acc.: 75.00%] [G loss: 0.684895]\n",
      "epoch:29 step:27258 [D loss: 0.530223, acc.: 70.31%] [G loss: 0.701614]\n",
      "epoch:29 step:27259 [D loss: 0.547974, acc.: 71.09%] [G loss: 0.752569]\n",
      "epoch:29 step:27260 [D loss: 0.554505, acc.: 70.31%] [G loss: 0.704961]\n",
      "epoch:29 step:27261 [D loss: 0.495890, acc.: 72.66%] [G loss: 0.779787]\n",
      "epoch:29 step:27262 [D loss: 0.537556, acc.: 69.53%] [G loss: 0.839626]\n",
      "epoch:29 step:27263 [D loss: 0.531508, acc.: 71.09%] [G loss: 0.945948]\n",
      "epoch:29 step:27264 [D loss: 0.608537, acc.: 65.62%] [G loss: 0.912980]\n",
      "epoch:29 step:27265 [D loss: 0.510031, acc.: 75.78%] [G loss: 1.061165]\n",
      "epoch:29 step:27266 [D loss: 0.500694, acc.: 75.78%] [G loss: 0.886212]\n",
      "epoch:29 step:27267 [D loss: 0.522345, acc.: 71.09%] [G loss: 0.938345]\n",
      "epoch:29 step:27268 [D loss: 0.517997, acc.: 75.78%] [G loss: 0.728639]\n",
      "epoch:29 step:27269 [D loss: 0.549739, acc.: 67.97%] [G loss: 0.770961]\n",
      "epoch:29 step:27270 [D loss: 0.438291, acc.: 81.25%] [G loss: 0.856214]\n",
      "epoch:29 step:27271 [D loss: 0.544751, acc.: 74.22%] [G loss: 0.918695]\n",
      "epoch:29 step:27272 [D loss: 0.547180, acc.: 71.88%] [G loss: 0.625867]\n",
      "epoch:29 step:27273 [D loss: 0.454885, acc.: 77.34%] [G loss: 0.920394]\n",
      "epoch:29 step:27274 [D loss: 0.556071, acc.: 69.53%] [G loss: 0.830441]\n",
      "epoch:29 step:27275 [D loss: 0.646836, acc.: 60.16%] [G loss: 0.674602]\n",
      "epoch:29 step:27276 [D loss: 0.497926, acc.: 71.09%] [G loss: 0.623167]\n",
      "epoch:29 step:27277 [D loss: 0.473451, acc.: 78.12%] [G loss: 0.608782]\n",
      "epoch:29 step:27278 [D loss: 0.555524, acc.: 71.88%] [G loss: 0.643559]\n",
      "epoch:29 step:27279 [D loss: 0.498475, acc.: 75.78%] [G loss: 0.707264]\n",
      "epoch:29 step:27280 [D loss: 0.517077, acc.: 72.66%] [G loss: 0.930143]\n",
      "epoch:29 step:27281 [D loss: 0.603638, acc.: 66.41%] [G loss: 0.713015]\n",
      "epoch:29 step:27282 [D loss: 0.599350, acc.: 65.62%] [G loss: 0.860668]\n",
      "epoch:29 step:27283 [D loss: 0.523930, acc.: 74.22%] [G loss: 0.840015]\n",
      "epoch:29 step:27284 [D loss: 0.535098, acc.: 68.75%] [G loss: 0.502118]\n",
      "epoch:29 step:27285 [D loss: 0.499872, acc.: 77.34%] [G loss: 0.608060]\n",
      "epoch:29 step:27286 [D loss: 0.575181, acc.: 65.62%] [G loss: 0.634035]\n",
      "epoch:29 step:27287 [D loss: 0.535883, acc.: 71.88%] [G loss: 0.699865]\n",
      "epoch:29 step:27288 [D loss: 0.502855, acc.: 81.25%] [G loss: 0.951895]\n",
      "epoch:29 step:27289 [D loss: 0.491238, acc.: 74.22%] [G loss: 0.728037]\n",
      "epoch:29 step:27290 [D loss: 0.510013, acc.: 69.53%] [G loss: 0.893883]\n",
      "epoch:29 step:27291 [D loss: 0.519877, acc.: 73.44%] [G loss: 0.979042]\n",
      "epoch:29 step:27292 [D loss: 0.452039, acc.: 80.47%] [G loss: 0.924096]\n",
      "epoch:29 step:27293 [D loss: 0.544450, acc.: 69.53%] [G loss: 0.876028]\n",
      "epoch:29 step:27294 [D loss: 0.507024, acc.: 71.88%] [G loss: 0.727857]\n",
      "epoch:29 step:27295 [D loss: 0.431236, acc.: 82.03%] [G loss: 0.801454]\n",
      "epoch:29 step:27296 [D loss: 0.476933, acc.: 71.88%] [G loss: 0.901281]\n",
      "epoch:29 step:27297 [D loss: 0.503068, acc.: 76.56%] [G loss: 0.881911]\n",
      "epoch:29 step:27298 [D loss: 0.551644, acc.: 72.66%] [G loss: 0.779544]\n",
      "epoch:29 step:27299 [D loss: 0.470456, acc.: 75.78%] [G loss: 0.741372]\n",
      "epoch:29 step:27300 [D loss: 0.433452, acc.: 82.03%] [G loss: 0.817841]\n",
      "epoch:29 step:27301 [D loss: 0.438044, acc.: 80.47%] [G loss: 0.740922]\n",
      "epoch:29 step:27302 [D loss: 0.569846, acc.: 65.62%] [G loss: 0.672889]\n",
      "epoch:29 step:27303 [D loss: 0.498713, acc.: 73.44%] [G loss: 0.708342]\n",
      "epoch:29 step:27304 [D loss: 0.468884, acc.: 75.78%] [G loss: 0.780465]\n",
      "epoch:29 step:27305 [D loss: 0.525472, acc.: 70.31%] [G loss: 0.734744]\n",
      "epoch:29 step:27306 [D loss: 0.529821, acc.: 65.62%] [G loss: 0.959359]\n",
      "epoch:29 step:27307 [D loss: 0.517631, acc.: 69.53%] [G loss: 0.965969]\n",
      "epoch:29 step:27308 [D loss: 0.484261, acc.: 72.66%] [G loss: 0.851799]\n",
      "epoch:29 step:27309 [D loss: 0.537273, acc.: 71.88%] [G loss: 0.737823]\n",
      "epoch:29 step:27310 [D loss: 0.639828, acc.: 64.84%] [G loss: 0.884470]\n",
      "epoch:29 step:27311 [D loss: 0.542297, acc.: 72.66%] [G loss: 0.695891]\n",
      "epoch:29 step:27312 [D loss: 0.579547, acc.: 67.97%] [G loss: 0.542113]\n",
      "epoch:29 step:27313 [D loss: 0.562522, acc.: 69.53%] [G loss: 0.676987]\n",
      "epoch:29 step:27314 [D loss: 0.537439, acc.: 69.53%] [G loss: 0.685317]\n",
      "epoch:29 step:27315 [D loss: 0.550131, acc.: 63.28%] [G loss: 0.508252]\n",
      "epoch:29 step:27316 [D loss: 0.652688, acc.: 61.72%] [G loss: 0.454918]\n",
      "epoch:29 step:27317 [D loss: 0.492789, acc.: 75.00%] [G loss: 0.558841]\n",
      "epoch:29 step:27318 [D loss: 0.547706, acc.: 67.97%] [G loss: 0.804885]\n",
      "epoch:29 step:27319 [D loss: 0.470832, acc.: 72.66%] [G loss: 0.814627]\n",
      "epoch:29 step:27320 [D loss: 0.582991, acc.: 69.53%] [G loss: 0.695457]\n",
      "epoch:29 step:27321 [D loss: 0.621705, acc.: 65.62%] [G loss: 0.617627]\n",
      "epoch:29 step:27322 [D loss: 0.475213, acc.: 75.78%] [G loss: 0.706368]\n",
      "epoch:29 step:27323 [D loss: 0.548011, acc.: 71.09%] [G loss: 0.753685]\n",
      "epoch:29 step:27324 [D loss: 0.576547, acc.: 65.62%] [G loss: 0.733330]\n",
      "epoch:29 step:27325 [D loss: 0.438063, acc.: 80.47%] [G loss: 0.650228]\n",
      "epoch:29 step:27326 [D loss: 0.555706, acc.: 73.44%] [G loss: 0.758928]\n",
      "epoch:29 step:27327 [D loss: 0.548203, acc.: 65.62%] [G loss: 0.652650]\n",
      "epoch:29 step:27328 [D loss: 0.527194, acc.: 73.44%] [G loss: 0.764006]\n",
      "epoch:29 step:27329 [D loss: 0.494346, acc.: 74.22%] [G loss: 0.750554]\n",
      "epoch:29 step:27330 [D loss: 0.556957, acc.: 71.88%] [G loss: 0.693495]\n",
      "epoch:29 step:27331 [D loss: 0.584566, acc.: 64.06%] [G loss: 0.692700]\n",
      "epoch:29 step:27332 [D loss: 0.499947, acc.: 77.34%] [G loss: 0.771894]\n",
      "epoch:29 step:27333 [D loss: 0.543492, acc.: 72.66%] [G loss: 0.845993]\n",
      "epoch:29 step:27334 [D loss: 0.532012, acc.: 70.31%] [G loss: 0.790140]\n",
      "epoch:29 step:27335 [D loss: 0.441827, acc.: 78.91%] [G loss: 1.090651]\n",
      "epoch:29 step:27336 [D loss: 0.593169, acc.: 65.62%] [G loss: 0.851704]\n",
      "epoch:29 step:27337 [D loss: 0.576116, acc.: 72.66%] [G loss: 0.895411]\n",
      "epoch:29 step:27338 [D loss: 0.562547, acc.: 67.97%] [G loss: 0.585625]\n",
      "epoch:29 step:27339 [D loss: 0.492319, acc.: 72.66%] [G loss: 0.759439]\n",
      "epoch:29 step:27340 [D loss: 0.530975, acc.: 70.31%] [G loss: 0.499996]\n",
      "epoch:29 step:27341 [D loss: 0.546506, acc.: 74.22%] [G loss: 0.525459]\n",
      "epoch:29 step:27342 [D loss: 0.584809, acc.: 67.97%] [G loss: 0.585754]\n",
      "epoch:29 step:27343 [D loss: 0.502581, acc.: 76.56%] [G loss: 0.667370]\n",
      "epoch:29 step:27344 [D loss: 0.516358, acc.: 74.22%] [G loss: 0.680704]\n",
      "epoch:29 step:27345 [D loss: 0.514849, acc.: 74.22%] [G loss: 0.681290]\n",
      "epoch:29 step:27346 [D loss: 0.459534, acc.: 77.34%] [G loss: 0.741611]\n",
      "epoch:29 step:27347 [D loss: 0.552184, acc.: 66.41%] [G loss: 0.767555]\n",
      "epoch:29 step:27348 [D loss: 0.585862, acc.: 61.72%] [G loss: 0.649097]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:29 step:27349 [D loss: 0.504111, acc.: 75.00%] [G loss: 0.669524]\n",
      "epoch:29 step:27350 [D loss: 0.501940, acc.: 74.22%] [G loss: 0.570758]\n",
      "epoch:29 step:27351 [D loss: 0.590936, acc.: 61.72%] [G loss: 0.640081]\n",
      "epoch:29 step:27352 [D loss: 0.586209, acc.: 66.41%] [G loss: 0.653468]\n",
      "epoch:29 step:27353 [D loss: 0.595405, acc.: 64.06%] [G loss: 0.535086]\n",
      "epoch:29 step:27354 [D loss: 0.587783, acc.: 64.06%] [G loss: 0.552197]\n",
      "epoch:29 step:27355 [D loss: 0.513242, acc.: 69.53%] [G loss: 0.706037]\n",
      "epoch:29 step:27356 [D loss: 0.524692, acc.: 71.88%] [G loss: 0.883312]\n",
      "epoch:29 step:27357 [D loss: 0.498533, acc.: 76.56%] [G loss: 0.836472]\n",
      "epoch:29 step:27358 [D loss: 0.556572, acc.: 66.41%] [G loss: 0.813309]\n",
      "epoch:29 step:27359 [D loss: 0.599935, acc.: 67.19%] [G loss: 0.828734]\n",
      "epoch:29 step:27360 [D loss: 0.626108, acc.: 62.50%] [G loss: 0.864246]\n",
      "epoch:29 step:27361 [D loss: 0.508619, acc.: 71.88%] [G loss: 0.691170]\n",
      "epoch:29 step:27362 [D loss: 0.552795, acc.: 67.97%] [G loss: 0.677985]\n",
      "epoch:29 step:27363 [D loss: 0.447221, acc.: 78.12%] [G loss: 0.885187]\n",
      "epoch:29 step:27364 [D loss: 0.505914, acc.: 71.09%] [G loss: 0.844909]\n",
      "epoch:29 step:27365 [D loss: 0.546619, acc.: 70.31%] [G loss: 0.709645]\n",
      "epoch:29 step:27366 [D loss: 0.493504, acc.: 75.00%] [G loss: 0.762015]\n",
      "epoch:29 step:27367 [D loss: 0.482941, acc.: 78.12%] [G loss: 0.898015]\n",
      "epoch:29 step:27368 [D loss: 0.585270, acc.: 65.62%] [G loss: 0.679445]\n",
      "epoch:29 step:27369 [D loss: 0.530549, acc.: 71.09%] [G loss: 0.666260]\n",
      "epoch:29 step:27370 [D loss: 0.498377, acc.: 75.78%] [G loss: 0.911858]\n",
      "epoch:29 step:27371 [D loss: 0.522168, acc.: 74.22%] [G loss: 0.877077]\n",
      "epoch:29 step:27372 [D loss: 0.463619, acc.: 75.78%] [G loss: 0.763615]\n",
      "epoch:29 step:27373 [D loss: 0.534899, acc.: 71.09%] [G loss: 0.740666]\n",
      "epoch:29 step:27374 [D loss: 0.600499, acc.: 65.62%] [G loss: 0.651965]\n",
      "epoch:29 step:27375 [D loss: 0.475706, acc.: 78.12%] [G loss: 0.775231]\n",
      "epoch:29 step:27376 [D loss: 0.603172, acc.: 67.97%] [G loss: 0.697799]\n",
      "epoch:29 step:27377 [D loss: 0.581182, acc.: 61.72%] [G loss: 0.692243]\n",
      "epoch:29 step:27378 [D loss: 0.517169, acc.: 75.00%] [G loss: 0.766264]\n",
      "epoch:29 step:27379 [D loss: 0.508337, acc.: 76.56%] [G loss: 0.924322]\n",
      "epoch:29 step:27380 [D loss: 0.507275, acc.: 75.00%] [G loss: 0.696604]\n",
      "epoch:29 step:27381 [D loss: 0.419334, acc.: 78.91%] [G loss: 0.881127]\n",
      "epoch:29 step:27382 [D loss: 0.550395, acc.: 67.97%] [G loss: 0.758335]\n",
      "epoch:29 step:27383 [D loss: 0.608404, acc.: 66.41%] [G loss: 0.545387]\n",
      "epoch:29 step:27384 [D loss: 0.595093, acc.: 64.84%] [G loss: 0.608244]\n",
      "epoch:29 step:27385 [D loss: 0.464184, acc.: 77.34%] [G loss: 0.682115]\n",
      "epoch:29 step:27386 [D loss: 0.538336, acc.: 71.88%] [G loss: 0.582733]\n",
      "epoch:29 step:27387 [D loss: 0.622986, acc.: 65.62%] [G loss: 0.696048]\n",
      "epoch:29 step:27388 [D loss: 0.522148, acc.: 64.84%] [G loss: 0.642212]\n",
      "epoch:29 step:27389 [D loss: 0.535302, acc.: 72.66%] [G loss: 0.664055]\n",
      "epoch:29 step:27390 [D loss: 0.517011, acc.: 71.88%] [G loss: 0.859373]\n",
      "epoch:29 step:27391 [D loss: 0.517758, acc.: 75.78%] [G loss: 0.776355]\n",
      "epoch:29 step:27392 [D loss: 0.437987, acc.: 80.47%] [G loss: 0.874698]\n",
      "epoch:29 step:27393 [D loss: 0.648771, acc.: 62.50%] [G loss: 0.684168]\n",
      "epoch:29 step:27394 [D loss: 0.551660, acc.: 70.31%] [G loss: 0.807695]\n",
      "epoch:29 step:27395 [D loss: 0.474561, acc.: 75.78%] [G loss: 0.991547]\n",
      "epoch:29 step:27396 [D loss: 0.466857, acc.: 77.34%] [G loss: 0.838330]\n",
      "epoch:29 step:27397 [D loss: 0.539193, acc.: 73.44%] [G loss: 0.646912]\n",
      "epoch:29 step:27398 [D loss: 0.562735, acc.: 67.19%] [G loss: 0.788789]\n",
      "epoch:29 step:27399 [D loss: 0.612427, acc.: 63.28%] [G loss: 0.626286]\n",
      "epoch:29 step:27400 [D loss: 0.508611, acc.: 71.09%] [G loss: 0.696582]\n",
      "##############\n",
      "[3.08837333 1.28220236 6.15953041 4.82951385 4.02667595 5.85511669\n",
      " 4.40166225 5.25044283 4.828825   4.3101862 ]\n",
      "##########\n",
      "epoch:29 step:27401 [D loss: 0.607410, acc.: 63.28%] [G loss: 0.661288]\n",
      "epoch:29 step:27402 [D loss: 0.553699, acc.: 71.88%] [G loss: 0.748547]\n",
      "epoch:29 step:27403 [D loss: 0.478599, acc.: 78.91%] [G loss: 0.942942]\n",
      "epoch:29 step:27404 [D loss: 0.477474, acc.: 75.00%] [G loss: 0.927106]\n",
      "epoch:29 step:27405 [D loss: 0.453891, acc.: 78.12%] [G loss: 1.050747]\n",
      "epoch:29 step:27406 [D loss: 0.494660, acc.: 76.56%] [G loss: 0.965262]\n",
      "epoch:29 step:27407 [D loss: 0.534582, acc.: 71.88%] [G loss: 0.772967]\n",
      "epoch:29 step:27408 [D loss: 0.625422, acc.: 59.38%] [G loss: 0.623833]\n",
      "epoch:29 step:27409 [D loss: 0.467016, acc.: 80.47%] [G loss: 0.613664]\n",
      "epoch:29 step:27410 [D loss: 0.503683, acc.: 72.66%] [G loss: 0.746633]\n",
      "epoch:29 step:27411 [D loss: 0.628230, acc.: 64.84%] [G loss: 0.565968]\n",
      "epoch:29 step:27412 [D loss: 0.515339, acc.: 74.22%] [G loss: 0.638454]\n",
      "epoch:29 step:27413 [D loss: 0.533694, acc.: 73.44%] [G loss: 0.794674]\n",
      "epoch:29 step:27414 [D loss: 0.527592, acc.: 72.66%] [G loss: 0.875475]\n",
      "epoch:29 step:27415 [D loss: 0.485418, acc.: 71.88%] [G loss: 0.781762]\n",
      "epoch:29 step:27416 [D loss: 0.488526, acc.: 74.22%] [G loss: 0.986263]\n",
      "epoch:29 step:27417 [D loss: 0.488963, acc.: 71.09%] [G loss: 0.845883]\n",
      "epoch:29 step:27418 [D loss: 0.487090, acc.: 75.78%] [G loss: 0.696754]\n",
      "epoch:29 step:27419 [D loss: 0.476760, acc.: 78.91%] [G loss: 0.766837]\n",
      "epoch:29 step:27420 [D loss: 0.513747, acc.: 74.22%] [G loss: 1.016725]\n",
      "epoch:29 step:27421 [D loss: 0.495117, acc.: 75.78%] [G loss: 0.921163]\n",
      "epoch:29 step:27422 [D loss: 0.613584, acc.: 68.75%] [G loss: 1.046865]\n",
      "epoch:29 step:27423 [D loss: 0.689050, acc.: 59.38%] [G loss: 0.841235]\n",
      "epoch:29 step:27424 [D loss: 0.611814, acc.: 67.97%] [G loss: 0.678592]\n",
      "epoch:29 step:27425 [D loss: 0.546658, acc.: 69.53%] [G loss: 0.958278]\n",
      "epoch:29 step:27426 [D loss: 0.588426, acc.: 67.19%] [G loss: 0.681405]\n",
      "epoch:29 step:27427 [D loss: 0.510964, acc.: 70.31%] [G loss: 0.778429]\n",
      "epoch:29 step:27428 [D loss: 0.555698, acc.: 65.62%] [G loss: 0.790602]\n",
      "epoch:29 step:27429 [D loss: 0.535304, acc.: 67.19%] [G loss: 0.827781]\n",
      "epoch:29 step:27430 [D loss: 0.582309, acc.: 66.41%] [G loss: 0.536497]\n",
      "epoch:29 step:27431 [D loss: 0.581550, acc.: 69.53%] [G loss: 0.652322]\n",
      "epoch:29 step:27432 [D loss: 0.493301, acc.: 75.00%] [G loss: 0.836368]\n",
      "epoch:29 step:27433 [D loss: 0.567814, acc.: 64.84%] [G loss: 0.592705]\n",
      "epoch:29 step:27434 [D loss: 0.554848, acc.: 70.31%] [G loss: 0.726075]\n",
      "epoch:29 step:27435 [D loss: 0.536708, acc.: 68.75%] [G loss: 0.766899]\n",
      "epoch:29 step:27436 [D loss: 0.541357, acc.: 75.00%] [G loss: 0.671756]\n",
      "epoch:29 step:27437 [D loss: 0.543859, acc.: 66.41%] [G loss: 0.878708]\n",
      "epoch:29 step:27438 [D loss: 0.566435, acc.: 69.53%] [G loss: 0.747154]\n",
      "epoch:29 step:27439 [D loss: 0.570569, acc.: 67.97%] [G loss: 0.631001]\n",
      "epoch:29 step:27440 [D loss: 0.576862, acc.: 65.62%] [G loss: 0.713203]\n",
      "epoch:29 step:27441 [D loss: 0.520677, acc.: 72.66%] [G loss: 0.723087]\n",
      "epoch:29 step:27442 [D loss: 0.534385, acc.: 67.97%] [G loss: 0.746428]\n",
      "epoch:29 step:27443 [D loss: 0.443617, acc.: 82.03%] [G loss: 0.831319]\n",
      "epoch:29 step:27444 [D loss: 0.550629, acc.: 67.19%] [G loss: 0.700795]\n",
      "epoch:29 step:27445 [D loss: 0.545529, acc.: 67.97%] [G loss: 0.867329]\n",
      "epoch:29 step:27446 [D loss: 0.477446, acc.: 75.78%] [G loss: 0.732846]\n",
      "epoch:29 step:27447 [D loss: 0.497771, acc.: 75.78%] [G loss: 0.690818]\n",
      "epoch:29 step:27448 [D loss: 0.518539, acc.: 69.53%] [G loss: 0.658350]\n",
      "epoch:29 step:27449 [D loss: 0.449942, acc.: 75.78%] [G loss: 0.930099]\n",
      "epoch:29 step:27450 [D loss: 0.695857, acc.: 60.16%] [G loss: 0.678817]\n",
      "epoch:29 step:27451 [D loss: 0.607335, acc.: 65.62%] [G loss: 0.632634]\n",
      "epoch:29 step:27452 [D loss: 0.575982, acc.: 63.28%] [G loss: 0.728253]\n",
      "epoch:29 step:27453 [D loss: 0.530561, acc.: 75.00%] [G loss: 0.677962]\n",
      "epoch:29 step:27454 [D loss: 0.590866, acc.: 63.28%] [G loss: 0.636799]\n",
      "epoch:29 step:27455 [D loss: 0.528793, acc.: 73.44%] [G loss: 0.814017]\n",
      "epoch:29 step:27456 [D loss: 0.539231, acc.: 73.44%] [G loss: 0.545591]\n",
      "epoch:29 step:27457 [D loss: 0.523129, acc.: 72.66%] [G loss: 0.643838]\n",
      "epoch:29 step:27458 [D loss: 0.534766, acc.: 71.88%] [G loss: 0.700851]\n",
      "epoch:29 step:27459 [D loss: 0.489520, acc.: 75.00%] [G loss: 0.877651]\n",
      "epoch:29 step:27460 [D loss: 0.569495, acc.: 65.62%] [G loss: 0.584594]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:29 step:27461 [D loss: 0.595464, acc.: 66.41%] [G loss: 0.531124]\n",
      "epoch:29 step:27462 [D loss: 0.485982, acc.: 71.88%] [G loss: 0.754448]\n",
      "epoch:29 step:27463 [D loss: 0.572553, acc.: 68.75%] [G loss: 0.694118]\n",
      "epoch:29 step:27464 [D loss: 0.611424, acc.: 64.06%] [G loss: 0.587206]\n",
      "epoch:29 step:27465 [D loss: 0.508003, acc.: 74.22%] [G loss: 0.805778]\n",
      "epoch:29 step:27466 [D loss: 0.554413, acc.: 69.53%] [G loss: 0.680147]\n",
      "epoch:29 step:27467 [D loss: 0.604264, acc.: 66.41%] [G loss: 0.583211]\n",
      "epoch:29 step:27468 [D loss: 0.580522, acc.: 70.31%] [G loss: 0.657212]\n",
      "epoch:29 step:27469 [D loss: 0.512037, acc.: 71.09%] [G loss: 0.538404]\n",
      "epoch:29 step:27470 [D loss: 0.594666, acc.: 68.75%] [G loss: 0.629996]\n",
      "epoch:29 step:27471 [D loss: 0.499859, acc.: 74.22%] [G loss: 0.673386]\n",
      "epoch:29 step:27472 [D loss: 0.460169, acc.: 75.00%] [G loss: 0.892898]\n",
      "epoch:29 step:27473 [D loss: 0.486985, acc.: 75.00%] [G loss: 0.794873]\n",
      "epoch:29 step:27474 [D loss: 0.645420, acc.: 65.62%] [G loss: 0.573145]\n",
      "epoch:29 step:27475 [D loss: 0.532412, acc.: 71.88%] [G loss: 0.772178]\n",
      "epoch:29 step:27476 [D loss: 0.524218, acc.: 71.09%] [G loss: 0.633413]\n",
      "epoch:29 step:27477 [D loss: 0.465373, acc.: 77.34%] [G loss: 0.742736]\n",
      "epoch:29 step:27478 [D loss: 0.542038, acc.: 68.75%] [G loss: 0.915642]\n",
      "epoch:29 step:27479 [D loss: 0.474990, acc.: 73.44%] [G loss: 0.896332]\n",
      "epoch:29 step:27480 [D loss: 0.571433, acc.: 64.84%] [G loss: 0.818275]\n",
      "epoch:29 step:27481 [D loss: 0.556405, acc.: 74.22%] [G loss: 0.834957]\n",
      "epoch:29 step:27482 [D loss: 0.481753, acc.: 71.09%] [G loss: 0.709725]\n",
      "epoch:29 step:27483 [D loss: 0.529524, acc.: 70.31%] [G loss: 0.672887]\n",
      "epoch:29 step:27484 [D loss: 0.466348, acc.: 80.47%] [G loss: 0.753663]\n",
      "epoch:29 step:27485 [D loss: 0.440011, acc.: 84.38%] [G loss: 1.022287]\n",
      "epoch:29 step:27486 [D loss: 0.512064, acc.: 77.34%] [G loss: 0.934489]\n",
      "epoch:29 step:27487 [D loss: 0.456349, acc.: 75.78%] [G loss: 0.939026]\n",
      "epoch:29 step:27488 [D loss: 0.441679, acc.: 82.81%] [G loss: 0.930759]\n",
      "epoch:29 step:27489 [D loss: 0.746113, acc.: 54.69%] [G loss: 0.655668]\n",
      "epoch:29 step:27490 [D loss: 0.557289, acc.: 71.09%] [G loss: 0.714049]\n",
      "epoch:29 step:27491 [D loss: 0.537871, acc.: 71.09%] [G loss: 0.675588]\n",
      "epoch:29 step:27492 [D loss: 0.530636, acc.: 70.31%] [G loss: 0.707472]\n",
      "epoch:29 step:27493 [D loss: 0.543761, acc.: 67.97%] [G loss: 0.786160]\n",
      "epoch:29 step:27494 [D loss: 0.471820, acc.: 76.56%] [G loss: 0.861115]\n",
      "epoch:29 step:27495 [D loss: 0.581944, acc.: 70.31%] [G loss: 0.529959]\n",
      "epoch:29 step:27496 [D loss: 0.603403, acc.: 67.19%] [G loss: 0.573939]\n",
      "epoch:29 step:27497 [D loss: 0.551493, acc.: 63.28%] [G loss: 0.487890]\n",
      "epoch:29 step:27498 [D loss: 0.529553, acc.: 71.09%] [G loss: 0.767784]\n",
      "epoch:29 step:27499 [D loss: 0.430378, acc.: 78.91%] [G loss: 0.674006]\n",
      "epoch:29 step:27500 [D loss: 0.520214, acc.: 76.56%] [G loss: 0.800002]\n",
      "epoch:29 step:27501 [D loss: 0.445786, acc.: 75.00%] [G loss: 0.859967]\n",
      "epoch:29 step:27502 [D loss: 0.508861, acc.: 71.09%] [G loss: 0.795239]\n",
      "epoch:29 step:27503 [D loss: 0.548570, acc.: 73.44%] [G loss: 0.800608]\n",
      "epoch:29 step:27504 [D loss: 0.556165, acc.: 70.31%] [G loss: 0.557626]\n",
      "epoch:29 step:27505 [D loss: 0.529334, acc.: 70.31%] [G loss: 0.549610]\n",
      "epoch:29 step:27506 [D loss: 0.500952, acc.: 77.34%] [G loss: 0.748860]\n",
      "epoch:29 step:27507 [D loss: 0.452930, acc.: 76.56%] [G loss: 1.014283]\n",
      "epoch:29 step:27508 [D loss: 0.478896, acc.: 76.56%] [G loss: 0.709381]\n",
      "epoch:29 step:27509 [D loss: 0.472593, acc.: 80.47%] [G loss: 0.798703]\n",
      "epoch:29 step:27510 [D loss: 0.470849, acc.: 77.34%] [G loss: 0.704019]\n",
      "epoch:29 step:27511 [D loss: 0.511889, acc.: 75.78%] [G loss: 0.705473]\n",
      "epoch:29 step:27512 [D loss: 0.494021, acc.: 75.00%] [G loss: 0.797860]\n",
      "epoch:29 step:27513 [D loss: 0.511724, acc.: 68.75%] [G loss: 0.791322]\n",
      "epoch:29 step:27514 [D loss: 0.548514, acc.: 76.56%] [G loss: 0.765256]\n",
      "epoch:29 step:27515 [D loss: 0.600993, acc.: 66.41%] [G loss: 0.815703]\n",
      "epoch:29 step:27516 [D loss: 0.465805, acc.: 76.56%] [G loss: 1.037139]\n",
      "epoch:29 step:27517 [D loss: 0.494110, acc.: 77.34%] [G loss: 1.039760]\n",
      "epoch:29 step:27518 [D loss: 0.615198, acc.: 68.75%] [G loss: 1.043485]\n",
      "epoch:29 step:27519 [D loss: 0.521803, acc.: 71.88%] [G loss: 0.948596]\n",
      "epoch:29 step:27520 [D loss: 0.509202, acc.: 75.00%] [G loss: 0.789717]\n",
      "epoch:29 step:27521 [D loss: 0.622199, acc.: 64.84%] [G loss: 0.759479]\n",
      "epoch:29 step:27522 [D loss: 0.750681, acc.: 55.47%] [G loss: 0.551517]\n",
      "epoch:29 step:27523 [D loss: 0.455511, acc.: 76.56%] [G loss: 0.596050]\n",
      "epoch:29 step:27524 [D loss: 0.499380, acc.: 72.66%] [G loss: 0.894797]\n",
      "epoch:29 step:27525 [D loss: 0.566346, acc.: 65.62%] [G loss: 0.675857]\n",
      "epoch:29 step:27526 [D loss: 0.503051, acc.: 74.22%] [G loss: 0.695857]\n",
      "epoch:29 step:27527 [D loss: 0.383824, acc.: 82.81%] [G loss: 0.869313]\n",
      "epoch:29 step:27528 [D loss: 0.502816, acc.: 72.66%] [G loss: 0.900028]\n",
      "epoch:29 step:27529 [D loss: 0.503722, acc.: 74.22%] [G loss: 0.973907]\n",
      "epoch:29 step:27530 [D loss: 0.447412, acc.: 79.69%] [G loss: 0.944596]\n",
      "epoch:29 step:27531 [D loss: 0.429062, acc.: 79.69%] [G loss: 0.950192]\n",
      "epoch:29 step:27532 [D loss: 0.444895, acc.: 78.12%] [G loss: 0.865100]\n",
      "epoch:29 step:27533 [D loss: 0.500983, acc.: 73.44%] [G loss: 0.912169]\n",
      "epoch:29 step:27534 [D loss: 0.466196, acc.: 76.56%] [G loss: 1.136834]\n",
      "epoch:29 step:27535 [D loss: 0.508438, acc.: 72.66%] [G loss: 0.745960]\n",
      "epoch:29 step:27536 [D loss: 0.531952, acc.: 71.88%] [G loss: 0.617932]\n",
      "epoch:29 step:27537 [D loss: 0.514154, acc.: 74.22%] [G loss: 0.690004]\n",
      "epoch:29 step:27538 [D loss: 0.525291, acc.: 71.09%] [G loss: 0.755865]\n",
      "epoch:29 step:27539 [D loss: 0.565662, acc.: 67.19%] [G loss: 0.565282]\n",
      "epoch:29 step:27540 [D loss: 0.580795, acc.: 70.31%] [G loss: 0.687148]\n",
      "epoch:29 step:27541 [D loss: 0.548809, acc.: 68.75%] [G loss: 0.495716]\n",
      "epoch:29 step:27542 [D loss: 0.542856, acc.: 66.41%] [G loss: 0.634057]\n",
      "epoch:29 step:27543 [D loss: 0.545362, acc.: 71.09%] [G loss: 0.691741]\n",
      "epoch:29 step:27544 [D loss: 0.516412, acc.: 73.44%] [G loss: 0.681484]\n",
      "epoch:29 step:27545 [D loss: 0.531479, acc.: 71.09%] [G loss: 0.855183]\n",
      "epoch:29 step:27546 [D loss: 0.513229, acc.: 72.66%] [G loss: 0.688602]\n",
      "epoch:29 step:27547 [D loss: 0.417055, acc.: 81.25%] [G loss: 0.937487]\n",
      "epoch:29 step:27548 [D loss: 0.657429, acc.: 67.97%] [G loss: 0.821965]\n",
      "epoch:29 step:27549 [D loss: 0.676204, acc.: 58.59%] [G loss: 0.626022]\n",
      "epoch:29 step:27550 [D loss: 0.585119, acc.: 69.53%] [G loss: 0.423277]\n",
      "epoch:29 step:27551 [D loss: 0.590721, acc.: 64.84%] [G loss: 0.582637]\n",
      "epoch:29 step:27552 [D loss: 0.558183, acc.: 73.44%] [G loss: 0.733348]\n",
      "epoch:29 step:27553 [D loss: 0.543318, acc.: 71.88%] [G loss: 0.571642]\n",
      "epoch:29 step:27554 [D loss: 0.431890, acc.: 78.91%] [G loss: 0.753462]\n",
      "epoch:29 step:27555 [D loss: 0.523242, acc.: 75.78%] [G loss: 0.716927]\n",
      "epoch:29 step:27556 [D loss: 0.579259, acc.: 68.75%] [G loss: 0.503320]\n",
      "epoch:29 step:27557 [D loss: 0.511776, acc.: 73.44%] [G loss: 0.632880]\n",
      "epoch:29 step:27558 [D loss: 0.445057, acc.: 79.69%] [G loss: 0.706550]\n",
      "epoch:29 step:27559 [D loss: 0.606534, acc.: 61.72%] [G loss: 0.495851]\n",
      "epoch:29 step:27560 [D loss: 0.516940, acc.: 69.53%] [G loss: 0.713988]\n",
      "epoch:29 step:27561 [D loss: 0.529127, acc.: 75.78%] [G loss: 0.695940]\n",
      "epoch:29 step:27562 [D loss: 0.523754, acc.: 72.66%] [G loss: 0.767329]\n",
      "epoch:29 step:27563 [D loss: 0.623575, acc.: 67.19%] [G loss: 0.706144]\n",
      "epoch:29 step:27564 [D loss: 0.546522, acc.: 70.31%] [G loss: 0.674151]\n",
      "epoch:29 step:27565 [D loss: 0.490963, acc.: 75.78%] [G loss: 0.636734]\n",
      "epoch:29 step:27566 [D loss: 0.579182, acc.: 67.97%] [G loss: 0.832873]\n",
      "epoch:29 step:27567 [D loss: 0.535515, acc.: 70.31%] [G loss: 0.677114]\n",
      "epoch:29 step:27568 [D loss: 0.538459, acc.: 71.88%] [G loss: 0.673926]\n",
      "epoch:29 step:27569 [D loss: 0.535718, acc.: 70.31%] [G loss: 0.751137]\n",
      "epoch:29 step:27570 [D loss: 0.585725, acc.: 67.97%] [G loss: 0.700353]\n",
      "epoch:29 step:27571 [D loss: 0.482910, acc.: 75.78%] [G loss: 0.830057]\n",
      "epoch:29 step:27572 [D loss: 0.483977, acc.: 80.47%] [G loss: 0.816626]\n",
      "epoch:29 step:27573 [D loss: 0.565989, acc.: 63.28%] [G loss: 0.730866]\n",
      "epoch:29 step:27574 [D loss: 0.602823, acc.: 63.28%] [G loss: 0.605652]\n",
      "epoch:29 step:27575 [D loss: 0.505877, acc.: 72.66%] [G loss: 0.707491]\n",
      "epoch:29 step:27576 [D loss: 0.457747, acc.: 77.34%] [G loss: 0.833248]\n",
      "epoch:29 step:27577 [D loss: 0.645855, acc.: 60.94%] [G loss: 0.732965]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:29 step:27578 [D loss: 0.502536, acc.: 72.66%] [G loss: 0.838890]\n",
      "epoch:29 step:27579 [D loss: 0.479556, acc.: 75.00%] [G loss: 0.748869]\n",
      "epoch:29 step:27580 [D loss: 0.614995, acc.: 65.62%] [G loss: 0.717180]\n",
      "epoch:29 step:27581 [D loss: 0.545355, acc.: 69.53%] [G loss: 0.720265]\n",
      "epoch:29 step:27582 [D loss: 0.539556, acc.: 71.09%] [G loss: 0.730023]\n",
      "epoch:29 step:27583 [D loss: 0.561036, acc.: 67.19%] [G loss: 0.681880]\n",
      "epoch:29 step:27584 [D loss: 0.591899, acc.: 67.97%] [G loss: 0.612876]\n",
      "epoch:29 step:27585 [D loss: 0.563326, acc.: 69.53%] [G loss: 0.649026]\n",
      "epoch:29 step:27586 [D loss: 0.539125, acc.: 74.22%] [G loss: 0.527765]\n",
      "epoch:29 step:27587 [D loss: 0.459645, acc.: 77.34%] [G loss: 0.620619]\n",
      "epoch:29 step:27588 [D loss: 0.497476, acc.: 74.22%] [G loss: 0.911078]\n",
      "epoch:29 step:27589 [D loss: 0.483235, acc.: 75.00%] [G loss: 0.894461]\n",
      "epoch:29 step:27590 [D loss: 0.579307, acc.: 70.31%] [G loss: 0.822914]\n",
      "epoch:29 step:27591 [D loss: 0.606728, acc.: 63.28%] [G loss: 0.716081]\n",
      "epoch:29 step:27592 [D loss: 0.600128, acc.: 63.28%] [G loss: 0.834119]\n",
      "epoch:29 step:27593 [D loss: 0.555487, acc.: 67.19%] [G loss: 0.958545]\n",
      "epoch:29 step:27594 [D loss: 0.532349, acc.: 75.78%] [G loss: 0.682475]\n",
      "epoch:29 step:27595 [D loss: 0.593801, acc.: 69.53%] [G loss: 0.625147]\n",
      "epoch:29 step:27596 [D loss: 0.517963, acc.: 71.09%] [G loss: 0.606673]\n",
      "epoch:29 step:27597 [D loss: 0.557383, acc.: 67.97%] [G loss: 0.565152]\n",
      "epoch:29 step:27598 [D loss: 0.546148, acc.: 68.75%] [G loss: 0.831960]\n",
      "epoch:29 step:27599 [D loss: 0.468944, acc.: 76.56%] [G loss: 0.794076]\n",
      "epoch:29 step:27600 [D loss: 0.425475, acc.: 79.69%] [G loss: 0.868761]\n",
      "##############\n",
      "[3.49024864 1.34372949 5.96847826 5.02186356 4.0256836  5.64225115\n",
      " 4.37384597 4.88974146 4.82032003 4.31359879]\n",
      "##########\n",
      "epoch:29 step:27601 [D loss: 0.569515, acc.: 68.75%] [G loss: 0.760572]\n",
      "epoch:29 step:27602 [D loss: 0.439716, acc.: 78.91%] [G loss: 0.860354]\n",
      "epoch:29 step:27603 [D loss: 0.477453, acc.: 75.78%] [G loss: 1.002073]\n",
      "epoch:29 step:27604 [D loss: 0.553340, acc.: 67.97%] [G loss: 0.814298]\n",
      "epoch:29 step:27605 [D loss: 0.546526, acc.: 69.53%] [G loss: 0.600174]\n",
      "epoch:29 step:27606 [D loss: 0.539480, acc.: 68.75%] [G loss: 0.767806]\n",
      "epoch:29 step:27607 [D loss: 0.505171, acc.: 75.00%] [G loss: 0.738718]\n",
      "epoch:29 step:27608 [D loss: 0.519455, acc.: 71.09%] [G loss: 0.771880]\n",
      "epoch:29 step:27609 [D loss: 0.526736, acc.: 74.22%] [G loss: 0.852591]\n",
      "epoch:29 step:27610 [D loss: 0.686864, acc.: 66.41%] [G loss: 0.680884]\n",
      "epoch:29 step:27611 [D loss: 0.551060, acc.: 71.88%] [G loss: 0.600239]\n",
      "epoch:29 step:27612 [D loss: 0.543797, acc.: 65.62%] [G loss: 0.840716]\n",
      "epoch:29 step:27613 [D loss: 0.484421, acc.: 75.00%] [G loss: 0.848661]\n",
      "epoch:29 step:27614 [D loss: 0.542675, acc.: 65.62%] [G loss: 0.938054]\n",
      "epoch:29 step:27615 [D loss: 0.563442, acc.: 67.97%] [G loss: 0.794097]\n",
      "epoch:29 step:27616 [D loss: 0.548112, acc.: 67.19%] [G loss: 0.837539]\n",
      "epoch:29 step:27617 [D loss: 0.483186, acc.: 75.00%] [G loss: 0.793718]\n",
      "epoch:29 step:27618 [D loss: 0.581208, acc.: 67.97%] [G loss: 0.950726]\n",
      "epoch:29 step:27619 [D loss: 0.494219, acc.: 71.09%] [G loss: 0.913837]\n",
      "epoch:29 step:27620 [D loss: 0.516521, acc.: 72.66%] [G loss: 0.798181]\n",
      "epoch:29 step:27621 [D loss: 0.493435, acc.: 69.53%] [G loss: 0.841449]\n",
      "epoch:29 step:27622 [D loss: 0.569951, acc.: 65.62%] [G loss: 0.678735]\n",
      "epoch:29 step:27623 [D loss: 0.478340, acc.: 77.34%] [G loss: 0.897952]\n",
      "epoch:29 step:27624 [D loss: 0.424327, acc.: 80.47%] [G loss: 1.098379]\n",
      "epoch:29 step:27625 [D loss: 0.437931, acc.: 81.25%] [G loss: 0.883716]\n",
      "epoch:29 step:27626 [D loss: 0.551346, acc.: 68.75%] [G loss: 1.045867]\n",
      "epoch:29 step:27627 [D loss: 0.560344, acc.: 71.88%] [G loss: 0.745738]\n",
      "epoch:29 step:27628 [D loss: 0.594614, acc.: 71.09%] [G loss: 0.724844]\n",
      "epoch:29 step:27629 [D loss: 0.585806, acc.: 68.75%] [G loss: 0.715442]\n",
      "epoch:29 step:27630 [D loss: 0.471068, acc.: 78.12%] [G loss: 0.776415]\n",
      "epoch:29 step:27631 [D loss: 0.663667, acc.: 60.16%] [G loss: 0.526430]\n",
      "epoch:29 step:27632 [D loss: 0.511581, acc.: 71.88%] [G loss: 0.741607]\n",
      "epoch:29 step:27633 [D loss: 0.487276, acc.: 78.12%] [G loss: 0.796520]\n",
      "epoch:29 step:27634 [D loss: 0.452043, acc.: 75.78%] [G loss: 0.874191]\n",
      "epoch:29 step:27635 [D loss: 0.589806, acc.: 62.50%] [G loss: 0.676918]\n",
      "epoch:29 step:27636 [D loss: 0.501123, acc.: 73.44%] [G loss: 0.833805]\n",
      "epoch:29 step:27637 [D loss: 0.481884, acc.: 74.22%] [G loss: 0.636719]\n",
      "epoch:29 step:27638 [D loss: 0.586627, acc.: 61.72%] [G loss: 0.799101]\n",
      "epoch:29 step:27639 [D loss: 0.538844, acc.: 70.31%] [G loss: 0.885399]\n",
      "epoch:29 step:27640 [D loss: 0.565738, acc.: 70.31%] [G loss: 0.772121]\n",
      "epoch:29 step:27641 [D loss: 0.526673, acc.: 68.75%] [G loss: 0.697571]\n",
      "epoch:29 step:27642 [D loss: 0.492770, acc.: 76.56%] [G loss: 0.923156]\n",
      "epoch:29 step:27643 [D loss: 0.490611, acc.: 77.34%] [G loss: 0.925778]\n",
      "epoch:29 step:27644 [D loss: 0.398011, acc.: 85.16%] [G loss: 0.893850]\n",
      "epoch:29 step:27645 [D loss: 0.448086, acc.: 77.34%] [G loss: 1.202758]\n",
      "epoch:29 step:27646 [D loss: 0.715342, acc.: 60.16%] [G loss: 0.863920]\n",
      "epoch:29 step:27647 [D loss: 0.546534, acc.: 70.31%] [G loss: 0.742914]\n",
      "epoch:29 step:27648 [D loss: 0.463898, acc.: 75.00%] [G loss: 1.068422]\n",
      "epoch:29 step:27649 [D loss: 0.461952, acc.: 82.03%] [G loss: 0.888967]\n",
      "epoch:29 step:27650 [D loss: 0.641698, acc.: 67.19%] [G loss: 0.663796]\n",
      "epoch:29 step:27651 [D loss: 0.560132, acc.: 75.00%] [G loss: 0.593661]\n",
      "epoch:29 step:27652 [D loss: 0.561633, acc.: 71.09%] [G loss: 0.571206]\n",
      "epoch:29 step:27653 [D loss: 0.572195, acc.: 65.62%] [G loss: 0.589444]\n",
      "epoch:29 step:27654 [D loss: 0.497628, acc.: 75.78%] [G loss: 0.732791]\n",
      "epoch:29 step:27655 [D loss: 0.626926, acc.: 61.72%] [G loss: 0.615727]\n",
      "epoch:29 step:27656 [D loss: 0.497850, acc.: 77.34%] [G loss: 0.741794]\n",
      "epoch:29 step:27657 [D loss: 0.486080, acc.: 76.56%] [G loss: 0.747756]\n",
      "epoch:29 step:27658 [D loss: 0.544904, acc.: 74.22%] [G loss: 0.872876]\n",
      "epoch:29 step:27659 [D loss: 0.533663, acc.: 71.88%] [G loss: 0.765382]\n",
      "epoch:29 step:27660 [D loss: 0.541357, acc.: 68.75%] [G loss: 0.703531]\n",
      "epoch:29 step:27661 [D loss: 0.492739, acc.: 73.44%] [G loss: 0.765661]\n",
      "epoch:29 step:27662 [D loss: 0.512179, acc.: 70.31%] [G loss: 0.830911]\n",
      "epoch:29 step:27663 [D loss: 0.590823, acc.: 67.97%] [G loss: 0.743946]\n",
      "epoch:29 step:27664 [D loss: 0.512847, acc.: 71.09%] [G loss: 0.710330]\n",
      "epoch:29 step:27665 [D loss: 0.602345, acc.: 60.94%] [G loss: 0.719837]\n",
      "epoch:29 step:27666 [D loss: 0.537067, acc.: 71.09%] [G loss: 0.685888]\n",
      "epoch:29 step:27667 [D loss: 0.600001, acc.: 64.06%] [G loss: 0.584560]\n",
      "epoch:29 step:27668 [D loss: 0.506739, acc.: 74.22%] [G loss: 0.571126]\n",
      "epoch:29 step:27669 [D loss: 0.511896, acc.: 74.22%] [G loss: 0.819808]\n",
      "epoch:29 step:27670 [D loss: 0.581866, acc.: 69.53%] [G loss: 0.703577]\n",
      "epoch:29 step:27671 [D loss: 0.501743, acc.: 78.12%] [G loss: 0.738758]\n",
      "epoch:29 step:27672 [D loss: 0.464313, acc.: 77.34%] [G loss: 0.704544]\n",
      "epoch:29 step:27673 [D loss: 0.558738, acc.: 70.31%] [G loss: 0.647417]\n",
      "epoch:29 step:27674 [D loss: 0.587241, acc.: 64.84%] [G loss: 0.604124]\n",
      "epoch:29 step:27675 [D loss: 0.608294, acc.: 63.28%] [G loss: 0.571388]\n",
      "epoch:29 step:27676 [D loss: 0.499363, acc.: 75.00%] [G loss: 0.709150]\n",
      "epoch:29 step:27677 [D loss: 0.473984, acc.: 75.78%] [G loss: 0.849619]\n",
      "epoch:29 step:27678 [D loss: 0.484518, acc.: 74.22%] [G loss: 0.887881]\n",
      "epoch:29 step:27679 [D loss: 0.532557, acc.: 73.44%] [G loss: 0.750654]\n",
      "epoch:29 step:27680 [D loss: 0.460570, acc.: 81.25%] [G loss: 0.830872]\n",
      "epoch:29 step:27681 [D loss: 0.394782, acc.: 80.47%] [G loss: 1.044086]\n",
      "epoch:29 step:27682 [D loss: 0.496218, acc.: 72.66%] [G loss: 0.931643]\n",
      "epoch:29 step:27683 [D loss: 0.567746, acc.: 73.44%] [G loss: 0.682956]\n",
      "epoch:29 step:27684 [D loss: 0.687403, acc.: 57.81%] [G loss: 0.503817]\n",
      "epoch:29 step:27685 [D loss: 0.570706, acc.: 68.75%] [G loss: 0.484317]\n",
      "epoch:29 step:27686 [D loss: 0.547151, acc.: 68.75%] [G loss: 0.663772]\n",
      "epoch:29 step:27687 [D loss: 0.431405, acc.: 77.34%] [G loss: 0.970940]\n",
      "epoch:29 step:27688 [D loss: 0.537296, acc.: 72.66%] [G loss: 0.800886]\n",
      "epoch:29 step:27689 [D loss: 0.529698, acc.: 71.09%] [G loss: 0.933204]\n",
      "epoch:29 step:27690 [D loss: 0.522928, acc.: 75.78%] [G loss: 0.768422]\n",
      "epoch:29 step:27691 [D loss: 0.513161, acc.: 73.44%] [G loss: 0.713801]\n",
      "epoch:29 step:27692 [D loss: 0.548359, acc.: 73.44%] [G loss: 0.610923]\n",
      "epoch:29 step:27693 [D loss: 0.462581, acc.: 78.12%] [G loss: 0.877093]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:29 step:27694 [D loss: 0.555103, acc.: 75.00%] [G loss: 0.720865]\n",
      "epoch:29 step:27695 [D loss: 0.531176, acc.: 73.44%] [G loss: 0.850337]\n",
      "epoch:29 step:27696 [D loss: 0.458891, acc.: 75.00%] [G loss: 0.847674]\n",
      "epoch:29 step:27697 [D loss: 0.508804, acc.: 72.66%] [G loss: 0.720579]\n",
      "epoch:29 step:27698 [D loss: 0.556700, acc.: 72.66%] [G loss: 0.709861]\n",
      "epoch:29 step:27699 [D loss: 0.497006, acc.: 73.44%] [G loss: 0.801049]\n",
      "epoch:29 step:27700 [D loss: 0.567340, acc.: 69.53%] [G loss: 0.799213]\n",
      "epoch:29 step:27701 [D loss: 0.654725, acc.: 64.84%] [G loss: 0.662664]\n",
      "epoch:29 step:27702 [D loss: 0.556430, acc.: 68.75%] [G loss: 0.545465]\n",
      "epoch:29 step:27703 [D loss: 0.565407, acc.: 64.84%] [G loss: 0.619898]\n",
      "epoch:29 step:27704 [D loss: 0.535926, acc.: 71.09%] [G loss: 0.836400]\n",
      "epoch:29 step:27705 [D loss: 0.550753, acc.: 71.09%] [G loss: 0.684346]\n",
      "epoch:29 step:27706 [D loss: 0.468310, acc.: 77.34%] [G loss: 0.748299]\n",
      "epoch:29 step:27707 [D loss: 0.493683, acc.: 74.22%] [G loss: 0.672224]\n",
      "epoch:29 step:27708 [D loss: 0.607232, acc.: 65.62%] [G loss: 0.648202]\n",
      "epoch:29 step:27709 [D loss: 0.469827, acc.: 73.44%] [G loss: 0.668043]\n",
      "epoch:29 step:27710 [D loss: 0.597311, acc.: 67.19%] [G loss: 0.664568]\n",
      "epoch:29 step:27711 [D loss: 0.605348, acc.: 63.28%] [G loss: 0.538623]\n",
      "epoch:29 step:27712 [D loss: 0.509451, acc.: 67.97%] [G loss: 0.659954]\n",
      "epoch:29 step:27713 [D loss: 0.507627, acc.: 70.31%] [G loss: 0.654843]\n",
      "epoch:29 step:27714 [D loss: 0.520890, acc.: 69.53%] [G loss: 0.711201]\n",
      "epoch:29 step:27715 [D loss: 0.632850, acc.: 60.16%] [G loss: 0.552565]\n",
      "epoch:29 step:27716 [D loss: 0.500961, acc.: 74.22%] [G loss: 0.990616]\n",
      "epoch:29 step:27717 [D loss: 0.575617, acc.: 67.97%] [G loss: 0.799164]\n",
      "epoch:29 step:27718 [D loss: 0.517963, acc.: 71.88%] [G loss: 0.703369]\n",
      "epoch:29 step:27719 [D loss: 0.509293, acc.: 73.44%] [G loss: 0.785144]\n",
      "epoch:29 step:27720 [D loss: 0.535519, acc.: 74.22%] [G loss: 0.804448]\n",
      "epoch:29 step:27721 [D loss: 0.486301, acc.: 75.00%] [G loss: 0.773073]\n",
      "epoch:29 step:27722 [D loss: 0.560057, acc.: 71.09%] [G loss: 0.697227]\n",
      "epoch:29 step:27723 [D loss: 0.505673, acc.: 73.44%] [G loss: 0.846921]\n",
      "epoch:29 step:27724 [D loss: 0.489326, acc.: 75.00%] [G loss: 0.688441]\n",
      "epoch:29 step:27725 [D loss: 0.516719, acc.: 75.00%] [G loss: 0.744082]\n",
      "epoch:29 step:27726 [D loss: 0.568103, acc.: 65.62%] [G loss: 0.844358]\n",
      "epoch:29 step:27727 [D loss: 0.423942, acc.: 78.91%] [G loss: 0.836949]\n",
      "epoch:29 step:27728 [D loss: 0.474914, acc.: 78.12%] [G loss: 0.826704]\n",
      "epoch:29 step:27729 [D loss: 0.516495, acc.: 74.22%] [G loss: 0.676629]\n",
      "epoch:29 step:27730 [D loss: 0.506544, acc.: 75.00%] [G loss: 0.811228]\n",
      "epoch:29 step:27731 [D loss: 0.461358, acc.: 75.78%] [G loss: 0.824598]\n",
      "epoch:29 step:27732 [D loss: 0.576962, acc.: 67.97%] [G loss: 0.654521]\n",
      "epoch:29 step:27733 [D loss: 0.579330, acc.: 69.53%] [G loss: 0.676660]\n",
      "epoch:29 step:27734 [D loss: 0.541689, acc.: 70.31%] [G loss: 0.645948]\n",
      "epoch:29 step:27735 [D loss: 0.602390, acc.: 61.72%] [G loss: 0.488740]\n",
      "epoch:29 step:27736 [D loss: 0.556479, acc.: 71.88%] [G loss: 0.759497]\n",
      "epoch:29 step:27737 [D loss: 0.435578, acc.: 84.38%] [G loss: 0.730805]\n",
      "epoch:29 step:27738 [D loss: 0.533454, acc.: 74.22%] [G loss: 0.665437]\n",
      "epoch:29 step:27739 [D loss: 0.716021, acc.: 60.94%] [G loss: 0.562371]\n",
      "epoch:29 step:27740 [D loss: 0.484779, acc.: 75.78%] [G loss: 0.690590]\n",
      "epoch:29 step:27741 [D loss: 0.452077, acc.: 77.34%] [G loss: 0.753781]\n",
      "epoch:29 step:27742 [D loss: 0.508914, acc.: 76.56%] [G loss: 0.766079]\n",
      "epoch:29 step:27743 [D loss: 0.590655, acc.: 67.97%] [G loss: 0.716511]\n",
      "epoch:29 step:27744 [D loss: 0.538817, acc.: 68.75%] [G loss: 0.671107]\n",
      "epoch:29 step:27745 [D loss: 0.546074, acc.: 71.88%] [G loss: 0.715321]\n",
      "epoch:29 step:27746 [D loss: 0.567326, acc.: 69.53%] [G loss: 0.735395]\n",
      "epoch:29 step:27747 [D loss: 0.445766, acc.: 79.69%] [G loss: 0.883962]\n",
      "epoch:29 step:27748 [D loss: 0.511314, acc.: 75.00%] [G loss: 0.922426]\n",
      "epoch:29 step:27749 [D loss: 0.622481, acc.: 64.84%] [G loss: 0.781840]\n",
      "epoch:29 step:27750 [D loss: 0.545050, acc.: 66.41%] [G loss: 0.809538]\n",
      "epoch:29 step:27751 [D loss: 0.564874, acc.: 69.53%] [G loss: 0.539471]\n",
      "epoch:29 step:27752 [D loss: 0.508941, acc.: 75.78%] [G loss: 0.720312]\n",
      "epoch:29 step:27753 [D loss: 0.522534, acc.: 68.75%] [G loss: 0.838344]\n",
      "epoch:29 step:27754 [D loss: 0.525200, acc.: 72.66%] [G loss: 0.577893]\n",
      "epoch:29 step:27755 [D loss: 0.455058, acc.: 83.59%] [G loss: 0.981432]\n",
      "epoch:29 step:27756 [D loss: 0.535208, acc.: 71.88%] [G loss: 0.890064]\n",
      "epoch:29 step:27757 [D loss: 0.570376, acc.: 66.41%] [G loss: 0.884787]\n",
      "epoch:29 step:27758 [D loss: 0.546771, acc.: 68.75%] [G loss: 0.647196]\n",
      "epoch:29 step:27759 [D loss: 0.513374, acc.: 72.66%] [G loss: 0.665685]\n",
      "epoch:29 step:27760 [D loss: 0.528505, acc.: 69.53%] [G loss: 0.631751]\n",
      "epoch:29 step:27761 [D loss: 0.548505, acc.: 67.97%] [G loss: 0.704101]\n",
      "epoch:29 step:27762 [D loss: 0.528253, acc.: 67.19%] [G loss: 0.786827]\n",
      "epoch:29 step:27763 [D loss: 0.554737, acc.: 67.19%] [G loss: 0.573994]\n",
      "epoch:29 step:27764 [D loss: 0.555750, acc.: 74.22%] [G loss: 0.555382]\n",
      "epoch:29 step:27765 [D loss: 0.485631, acc.: 77.34%] [G loss: 0.580943]\n",
      "epoch:29 step:27766 [D loss: 0.517182, acc.: 71.88%] [G loss: 0.710371]\n",
      "epoch:29 step:27767 [D loss: 0.551486, acc.: 70.31%] [G loss: 0.629125]\n",
      "epoch:29 step:27768 [D loss: 0.587291, acc.: 67.97%] [G loss: 0.692530]\n",
      "epoch:29 step:27769 [D loss: 0.555091, acc.: 67.19%] [G loss: 0.632279]\n",
      "epoch:29 step:27770 [D loss: 0.477395, acc.: 74.22%] [G loss: 0.788884]\n",
      "epoch:29 step:27771 [D loss: 0.479495, acc.: 76.56%] [G loss: 0.850441]\n",
      "epoch:29 step:27772 [D loss: 0.480363, acc.: 75.78%] [G loss: 0.826680]\n",
      "epoch:29 step:27773 [D loss: 0.566601, acc.: 71.09%] [G loss: 0.765986]\n",
      "epoch:29 step:27774 [D loss: 0.523924, acc.: 67.97%] [G loss: 0.825437]\n",
      "epoch:29 step:27775 [D loss: 0.508755, acc.: 72.66%] [G loss: 0.816687]\n",
      "epoch:29 step:27776 [D loss: 0.483474, acc.: 74.22%] [G loss: 0.842021]\n",
      "epoch:29 step:27777 [D loss: 0.566566, acc.: 68.75%] [G loss: 0.698818]\n",
      "epoch:29 step:27778 [D loss: 0.405491, acc.: 85.16%] [G loss: 0.654034]\n",
      "epoch:29 step:27779 [D loss: 0.570760, acc.: 70.31%] [G loss: 0.710753]\n",
      "epoch:29 step:27780 [D loss: 0.529059, acc.: 67.97%] [G loss: 0.695519]\n",
      "epoch:29 step:27781 [D loss: 0.568450, acc.: 67.19%] [G loss: 0.642854]\n",
      "epoch:29 step:27782 [D loss: 0.542261, acc.: 68.75%] [G loss: 0.554668]\n",
      "epoch:29 step:27783 [D loss: 0.588561, acc.: 64.06%] [G loss: 0.511840]\n",
      "epoch:29 step:27784 [D loss: 0.533840, acc.: 70.31%] [G loss: 0.554031]\n",
      "epoch:29 step:27785 [D loss: 0.551059, acc.: 69.53%] [G loss: 0.553671]\n",
      "epoch:29 step:27786 [D loss: 0.473129, acc.: 74.22%] [G loss: 0.861425]\n",
      "epoch:29 step:27787 [D loss: 0.587587, acc.: 67.19%] [G loss: 0.651934]\n",
      "epoch:29 step:27788 [D loss: 0.573934, acc.: 63.28%] [G loss: 0.705319]\n",
      "epoch:29 step:27789 [D loss: 0.609227, acc.: 66.41%] [G loss: 0.757601]\n",
      "epoch:29 step:27790 [D loss: 0.487243, acc.: 75.00%] [G loss: 0.619303]\n",
      "epoch:29 step:27791 [D loss: 0.585244, acc.: 65.62%] [G loss: 0.711504]\n",
      "epoch:29 step:27792 [D loss: 0.561583, acc.: 68.75%] [G loss: 0.776329]\n",
      "epoch:29 step:27793 [D loss: 0.529633, acc.: 69.53%] [G loss: 0.581964]\n",
      "epoch:29 step:27794 [D loss: 0.466397, acc.: 78.91%] [G loss: 0.714986]\n",
      "epoch:29 step:27795 [D loss: 0.484960, acc.: 75.00%] [G loss: 0.636808]\n",
      "epoch:29 step:27796 [D loss: 0.500037, acc.: 78.12%] [G loss: 0.632029]\n",
      "epoch:29 step:27797 [D loss: 0.452970, acc.: 80.47%] [G loss: 0.733653]\n",
      "epoch:29 step:27798 [D loss: 0.611830, acc.: 64.84%] [G loss: 0.703937]\n",
      "epoch:29 step:27799 [D loss: 0.547269, acc.: 71.09%] [G loss: 0.636240]\n",
      "epoch:29 step:27800 [D loss: 0.569309, acc.: 71.09%] [G loss: 0.759192]\n",
      "##############\n",
      "[2.92868235 1.13228663 6.05320256 4.93303043 4.04699553 5.51435392\n",
      " 4.62027995 4.85905545 4.81787087 4.26688393]\n",
      "##########\n",
      "epoch:29 step:27801 [D loss: 0.592690, acc.: 70.31%] [G loss: 0.810274]\n",
      "epoch:29 step:27802 [D loss: 0.469717, acc.: 75.78%] [G loss: 1.010242]\n",
      "epoch:29 step:27803 [D loss: 0.550481, acc.: 69.53%] [G loss: 0.671289]\n",
      "epoch:29 step:27804 [D loss: 0.520301, acc.: 74.22%] [G loss: 0.672595]\n",
      "epoch:29 step:27805 [D loss: 0.478492, acc.: 79.69%] [G loss: 0.786260]\n",
      "epoch:29 step:27806 [D loss: 0.549525, acc.: 73.44%] [G loss: 0.736017]\n",
      "epoch:29 step:27807 [D loss: 0.451889, acc.: 82.03%] [G loss: 0.765657]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:29 step:27808 [D loss: 0.434281, acc.: 79.69%] [G loss: 0.806829]\n",
      "epoch:29 step:27809 [D loss: 0.632066, acc.: 65.62%] [G loss: 0.623955]\n",
      "epoch:29 step:27810 [D loss: 0.523422, acc.: 71.88%] [G loss: 0.703677]\n",
      "epoch:29 step:27811 [D loss: 0.525521, acc.: 73.44%] [G loss: 0.595292]\n",
      "epoch:29 step:27812 [D loss: 0.475456, acc.: 74.22%] [G loss: 0.839146]\n",
      "epoch:29 step:27813 [D loss: 0.515741, acc.: 73.44%] [G loss: 1.028958]\n",
      "epoch:29 step:27814 [D loss: 0.499148, acc.: 78.12%] [G loss: 0.874975]\n",
      "epoch:29 step:27815 [D loss: 0.474721, acc.: 76.56%] [G loss: 1.052213]\n",
      "epoch:29 step:27816 [D loss: 0.526973, acc.: 70.31%] [G loss: 0.828840]\n",
      "epoch:29 step:27817 [D loss: 0.577788, acc.: 65.62%] [G loss: 0.725522]\n",
      "epoch:29 step:27818 [D loss: 0.521574, acc.: 71.09%] [G loss: 0.816354]\n",
      "epoch:29 step:27819 [D loss: 0.601209, acc.: 68.75%] [G loss: 0.696066]\n",
      "epoch:29 step:27820 [D loss: 0.449336, acc.: 78.12%] [G loss: 0.813722]\n",
      "epoch:29 step:27821 [D loss: 0.367333, acc.: 82.03%] [G loss: 1.126478]\n",
      "epoch:29 step:27822 [D loss: 0.532653, acc.: 74.22%] [G loss: 0.905427]\n",
      "epoch:29 step:27823 [D loss: 0.486864, acc.: 78.12%] [G loss: 0.893445]\n",
      "epoch:29 step:27824 [D loss: 0.531125, acc.: 73.44%] [G loss: 1.048838]\n",
      "epoch:29 step:27825 [D loss: 0.650812, acc.: 64.06%] [G loss: 0.853560]\n",
      "epoch:29 step:27826 [D loss: 0.529069, acc.: 74.22%] [G loss: 0.733986]\n",
      "epoch:29 step:27827 [D loss: 0.486007, acc.: 75.78%] [G loss: 0.832187]\n",
      "epoch:29 step:27828 [D loss: 0.592722, acc.: 72.66%] [G loss: 0.758637]\n",
      "epoch:29 step:27829 [D loss: 0.523819, acc.: 75.78%] [G loss: 0.728551]\n",
      "epoch:29 step:27830 [D loss: 0.495288, acc.: 73.44%] [G loss: 0.797383]\n",
      "epoch:29 step:27831 [D loss: 0.552085, acc.: 68.75%] [G loss: 0.852455]\n",
      "epoch:29 step:27832 [D loss: 0.531529, acc.: 71.09%] [G loss: 0.657641]\n",
      "epoch:29 step:27833 [D loss: 0.502101, acc.: 73.44%] [G loss: 0.744296]\n",
      "epoch:29 step:27834 [D loss: 0.492161, acc.: 71.09%] [G loss: 0.726566]\n",
      "epoch:29 step:27835 [D loss: 0.506037, acc.: 75.00%] [G loss: 0.858824]\n",
      "epoch:29 step:27836 [D loss: 0.537255, acc.: 67.97%] [G loss: 0.706379]\n",
      "epoch:29 step:27837 [D loss: 0.570934, acc.: 66.41%] [G loss: 0.638617]\n",
      "epoch:29 step:27838 [D loss: 0.569987, acc.: 67.19%] [G loss: 0.771275]\n",
      "epoch:29 step:27839 [D loss: 0.500301, acc.: 72.66%] [G loss: 0.588852]\n",
      "epoch:29 step:27840 [D loss: 0.522177, acc.: 73.44%] [G loss: 0.875532]\n",
      "epoch:29 step:27841 [D loss: 0.519055, acc.: 76.56%] [G loss: 0.872087]\n",
      "epoch:29 step:27842 [D loss: 0.511946, acc.: 67.97%] [G loss: 0.726094]\n",
      "epoch:29 step:27843 [D loss: 0.526204, acc.: 67.19%] [G loss: 0.763635]\n",
      "epoch:29 step:27844 [D loss: 0.493929, acc.: 75.00%] [G loss: 1.001451]\n",
      "epoch:29 step:27845 [D loss: 0.552313, acc.: 69.53%] [G loss: 0.768106]\n",
      "epoch:29 step:27846 [D loss: 0.580141, acc.: 64.84%] [G loss: 0.939148]\n",
      "epoch:29 step:27847 [D loss: 0.486359, acc.: 75.78%] [G loss: 0.843627]\n",
      "epoch:29 step:27848 [D loss: 0.717896, acc.: 56.25%] [G loss: 0.755373]\n",
      "epoch:29 step:27849 [D loss: 0.526268, acc.: 70.31%] [G loss: 0.723771]\n",
      "epoch:29 step:27850 [D loss: 0.513828, acc.: 73.44%] [G loss: 0.724686]\n",
      "epoch:29 step:27851 [D loss: 0.555060, acc.: 67.19%] [G loss: 0.614483]\n",
      "epoch:29 step:27852 [D loss: 0.489865, acc.: 74.22%] [G loss: 0.706271]\n",
      "epoch:29 step:27853 [D loss: 0.511054, acc.: 74.22%] [G loss: 0.769818]\n",
      "epoch:29 step:27854 [D loss: 0.451266, acc.: 77.34%] [G loss: 0.719858]\n",
      "epoch:29 step:27855 [D loss: 0.527935, acc.: 72.66%] [G loss: 0.629090]\n",
      "epoch:29 step:27856 [D loss: 0.559161, acc.: 71.88%] [G loss: 0.708722]\n",
      "epoch:29 step:27857 [D loss: 0.571561, acc.: 67.97%] [G loss: 0.634648]\n",
      "epoch:29 step:27858 [D loss: 0.512192, acc.: 75.78%] [G loss: 0.599934]\n",
      "epoch:29 step:27859 [D loss: 0.623883, acc.: 68.75%] [G loss: 0.705842]\n",
      "epoch:29 step:27860 [D loss: 0.614396, acc.: 60.16%] [G loss: 0.556074]\n",
      "epoch:29 step:27861 [D loss: 0.537525, acc.: 71.09%] [G loss: 0.715956]\n",
      "epoch:29 step:27862 [D loss: 0.528165, acc.: 69.53%] [G loss: 0.812594]\n",
      "epoch:29 step:27863 [D loss: 0.466332, acc.: 79.69%] [G loss: 0.694658]\n",
      "epoch:29 step:27864 [D loss: 0.516647, acc.: 71.88%] [G loss: 0.762526]\n",
      "epoch:29 step:27865 [D loss: 0.510963, acc.: 75.00%] [G loss: 0.651508]\n",
      "epoch:29 step:27866 [D loss: 0.410787, acc.: 82.81%] [G loss: 0.898041]\n",
      "epoch:29 step:27867 [D loss: 0.457571, acc.: 76.56%] [G loss: 0.740022]\n",
      "epoch:29 step:27868 [D loss: 0.527243, acc.: 70.31%] [G loss: 0.868286]\n",
      "epoch:29 step:27869 [D loss: 0.609382, acc.: 62.50%] [G loss: 0.689145]\n",
      "epoch:29 step:27870 [D loss: 0.593724, acc.: 63.28%] [G loss: 0.662697]\n",
      "epoch:29 step:27871 [D loss: 0.561453, acc.: 71.09%] [G loss: 0.557788]\n",
      "epoch:29 step:27872 [D loss: 0.501039, acc.: 73.44%] [G loss: 0.805190]\n",
      "epoch:29 step:27873 [D loss: 0.516311, acc.: 71.88%] [G loss: 0.789310]\n",
      "epoch:29 step:27874 [D loss: 0.515158, acc.: 75.00%] [G loss: 0.680596]\n",
      "epoch:29 step:27875 [D loss: 0.558533, acc.: 70.31%] [G loss: 0.850539]\n",
      "epoch:29 step:27876 [D loss: 0.629279, acc.: 60.94%] [G loss: 0.655275]\n",
      "epoch:29 step:27877 [D loss: 0.569363, acc.: 67.19%] [G loss: 0.674280]\n",
      "epoch:29 step:27878 [D loss: 0.507656, acc.: 72.66%] [G loss: 0.711587]\n",
      "epoch:29 step:27879 [D loss: 0.478699, acc.: 77.34%] [G loss: 0.803591]\n",
      "epoch:29 step:27880 [D loss: 0.525308, acc.: 70.31%] [G loss: 0.929283]\n",
      "epoch:29 step:27881 [D loss: 0.503796, acc.: 72.66%] [G loss: 0.864349]\n",
      "epoch:29 step:27882 [D loss: 0.557866, acc.: 69.53%] [G loss: 1.125188]\n",
      "epoch:29 step:27883 [D loss: 0.532460, acc.: 73.44%] [G loss: 0.882812]\n",
      "epoch:29 step:27884 [D loss: 0.548529, acc.: 71.09%] [G loss: 0.806931]\n",
      "epoch:29 step:27885 [D loss: 0.539160, acc.: 68.75%] [G loss: 0.753823]\n",
      "epoch:29 step:27886 [D loss: 0.563558, acc.: 67.97%] [G loss: 0.723557]\n",
      "epoch:29 step:27887 [D loss: 0.497533, acc.: 76.56%] [G loss: 0.856515]\n",
      "epoch:29 step:27888 [D loss: 0.555087, acc.: 67.19%] [G loss: 0.638193]\n",
      "epoch:29 step:27889 [D loss: 0.538327, acc.: 71.09%] [G loss: 0.725135]\n",
      "epoch:29 step:27890 [D loss: 0.536787, acc.: 74.22%] [G loss: 0.635180]\n",
      "epoch:29 step:27891 [D loss: 0.535385, acc.: 71.09%] [G loss: 0.572743]\n",
      "epoch:29 step:27892 [D loss: 0.522343, acc.: 67.19%] [G loss: 0.872088]\n",
      "epoch:29 step:27893 [D loss: 0.585089, acc.: 69.53%] [G loss: 0.652161]\n",
      "epoch:29 step:27894 [D loss: 0.534493, acc.: 69.53%] [G loss: 0.676142]\n",
      "epoch:29 step:27895 [D loss: 0.541474, acc.: 72.66%] [G loss: 0.632971]\n",
      "epoch:29 step:27896 [D loss: 0.530036, acc.: 73.44%] [G loss: 0.641742]\n",
      "epoch:29 step:27897 [D loss: 0.484676, acc.: 73.44%] [G loss: 0.854488]\n",
      "epoch:29 step:27898 [D loss: 0.477746, acc.: 76.56%] [G loss: 0.904542]\n",
      "epoch:29 step:27899 [D loss: 0.462772, acc.: 78.91%] [G loss: 0.857658]\n",
      "epoch:29 step:27900 [D loss: 0.562680, acc.: 69.53%] [G loss: 0.779337]\n",
      "epoch:29 step:27901 [D loss: 0.488357, acc.: 78.12%] [G loss: 0.742609]\n",
      "epoch:29 step:27902 [D loss: 0.596244, acc.: 66.41%] [G loss: 0.687025]\n",
      "epoch:29 step:27903 [D loss: 0.501939, acc.: 75.78%] [G loss: 0.599729]\n",
      "epoch:29 step:27904 [D loss: 0.626612, acc.: 61.72%] [G loss: 0.593174]\n",
      "epoch:29 step:27905 [D loss: 0.493125, acc.: 75.78%] [G loss: 0.727798]\n",
      "epoch:29 step:27906 [D loss: 0.534341, acc.: 75.78%] [G loss: 0.741563]\n",
      "epoch:29 step:27907 [D loss: 0.540897, acc.: 71.88%] [G loss: 0.700827]\n",
      "epoch:29 step:27908 [D loss: 0.555225, acc.: 67.19%] [G loss: 0.676281]\n",
      "epoch:29 step:27909 [D loss: 0.490367, acc.: 75.00%] [G loss: 0.797047]\n",
      "epoch:29 step:27910 [D loss: 0.527554, acc.: 71.09%] [G loss: 0.672835]\n",
      "epoch:29 step:27911 [D loss: 0.526008, acc.: 69.53%] [G loss: 0.696594]\n",
      "epoch:29 step:27912 [D loss: 0.543593, acc.: 71.09%] [G loss: 0.707100]\n",
      "epoch:29 step:27913 [D loss: 0.606586, acc.: 65.62%] [G loss: 0.731398]\n",
      "epoch:29 step:27914 [D loss: 0.544122, acc.: 72.66%] [G loss: 0.617523]\n",
      "epoch:29 step:27915 [D loss: 0.505998, acc.: 75.78%] [G loss: 0.662768]\n",
      "epoch:29 step:27916 [D loss: 0.524886, acc.: 71.09%] [G loss: 0.828533]\n",
      "epoch:29 step:27917 [D loss: 0.505913, acc.: 77.34%] [G loss: 0.948994]\n",
      "epoch:29 step:27918 [D loss: 0.582974, acc.: 62.50%] [G loss: 0.744084]\n",
      "epoch:29 step:27919 [D loss: 0.423126, acc.: 79.69%] [G loss: 0.841068]\n",
      "epoch:29 step:27920 [D loss: 0.445225, acc.: 76.56%] [G loss: 0.805687]\n",
      "epoch:29 step:27921 [D loss: 0.511919, acc.: 71.09%] [G loss: 0.875158]\n",
      "epoch:29 step:27922 [D loss: 0.480711, acc.: 78.91%] [G loss: 0.889900]\n",
      "epoch:29 step:27923 [D loss: 0.499926, acc.: 75.78%] [G loss: 0.646792]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:29 step:27924 [D loss: 0.467213, acc.: 75.78%] [G loss: 1.030152]\n",
      "epoch:29 step:27925 [D loss: 0.567319, acc.: 67.97%] [G loss: 0.867433]\n",
      "epoch:29 step:27926 [D loss: 0.466251, acc.: 78.12%] [G loss: 0.945882]\n",
      "epoch:29 step:27927 [D loss: 0.548985, acc.: 68.75%] [G loss: 0.612002]\n",
      "epoch:29 step:27928 [D loss: 0.483416, acc.: 78.12%] [G loss: 0.801453]\n",
      "epoch:29 step:27929 [D loss: 0.569207, acc.: 70.31%] [G loss: 0.768272]\n",
      "epoch:29 step:27930 [D loss: 0.553879, acc.: 69.53%] [G loss: 0.646609]\n",
      "epoch:29 step:27931 [D loss: 0.531556, acc.: 75.00%] [G loss: 0.766566]\n",
      "epoch:29 step:27932 [D loss: 0.496399, acc.: 74.22%] [G loss: 0.869784]\n",
      "epoch:29 step:27933 [D loss: 0.496769, acc.: 73.44%] [G loss: 0.858002]\n",
      "epoch:29 step:27934 [D loss: 0.550760, acc.: 66.41%] [G loss: 0.673447]\n",
      "epoch:29 step:27935 [D loss: 0.560064, acc.: 68.75%] [G loss: 0.724171]\n",
      "epoch:29 step:27936 [D loss: 0.537920, acc.: 71.88%] [G loss: 0.674915]\n",
      "epoch:29 step:27937 [D loss: 0.548341, acc.: 71.09%] [G loss: 0.621218]\n",
      "epoch:29 step:27938 [D loss: 0.531165, acc.: 75.78%] [G loss: 0.695782]\n",
      "epoch:29 step:27939 [D loss: 0.596770, acc.: 65.62%] [G loss: 0.636250]\n",
      "epoch:29 step:27940 [D loss: 0.568751, acc.: 73.44%] [G loss: 0.541812]\n",
      "epoch:29 step:27941 [D loss: 0.523502, acc.: 74.22%] [G loss: 0.715231]\n",
      "epoch:29 step:27942 [D loss: 0.533721, acc.: 71.88%] [G loss: 0.738644]\n",
      "epoch:29 step:27943 [D loss: 0.485717, acc.: 75.00%] [G loss: 0.810590]\n",
      "epoch:29 step:27944 [D loss: 0.528729, acc.: 71.88%] [G loss: 0.898907]\n",
      "epoch:29 step:27945 [D loss: 0.556112, acc.: 71.09%] [G loss: 0.833198]\n",
      "epoch:29 step:27946 [D loss: 0.589680, acc.: 64.84%] [G loss: 0.674596]\n",
      "epoch:29 step:27947 [D loss: 0.527916, acc.: 75.78%] [G loss: 0.722322]\n",
      "epoch:29 step:27948 [D loss: 0.490893, acc.: 77.34%] [G loss: 0.698633]\n",
      "epoch:29 step:27949 [D loss: 0.553145, acc.: 64.84%] [G loss: 0.704250]\n",
      "epoch:29 step:27950 [D loss: 0.537542, acc.: 68.75%] [G loss: 0.693733]\n",
      "epoch:29 step:27951 [D loss: 0.588007, acc.: 69.53%] [G loss: 0.612841]\n",
      "epoch:29 step:27952 [D loss: 0.518651, acc.: 73.44%] [G loss: 0.588015]\n",
      "epoch:29 step:27953 [D loss: 0.521555, acc.: 73.44%] [G loss: 0.693742]\n",
      "epoch:29 step:27954 [D loss: 0.503935, acc.: 79.69%] [G loss: 0.799823]\n",
      "epoch:29 step:27955 [D loss: 0.489111, acc.: 73.44%] [G loss: 1.084292]\n",
      "epoch:29 step:27956 [D loss: 0.569308, acc.: 64.84%] [G loss: 1.044572]\n",
      "epoch:29 step:27957 [D loss: 0.590074, acc.: 65.62%] [G loss: 0.679937]\n",
      "epoch:29 step:27958 [D loss: 0.518243, acc.: 71.88%] [G loss: 0.800262]\n",
      "epoch:29 step:27959 [D loss: 0.512529, acc.: 75.00%] [G loss: 0.763056]\n",
      "epoch:29 step:27960 [D loss: 0.574548, acc.: 71.88%] [G loss: 0.685387]\n",
      "epoch:29 step:27961 [D loss: 0.620185, acc.: 65.62%] [G loss: 0.698790]\n",
      "epoch:29 step:27962 [D loss: 0.458503, acc.: 78.12%] [G loss: 0.646797]\n",
      "epoch:29 step:27963 [D loss: 0.530618, acc.: 71.09%] [G loss: 0.695915]\n",
      "epoch:29 step:27964 [D loss: 0.511676, acc.: 75.00%] [G loss: 0.694805]\n",
      "epoch:29 step:27965 [D loss: 0.425871, acc.: 75.78%] [G loss: 0.758075]\n",
      "epoch:29 step:27966 [D loss: 0.585755, acc.: 68.75%] [G loss: 0.739793]\n",
      "epoch:29 step:27967 [D loss: 0.577384, acc.: 68.75%] [G loss: 0.807355]\n",
      "epoch:29 step:27968 [D loss: 0.511588, acc.: 75.00%] [G loss: 0.874957]\n",
      "epoch:29 step:27969 [D loss: 0.539015, acc.: 70.31%] [G loss: 0.977530]\n",
      "epoch:29 step:27970 [D loss: 0.564768, acc.: 70.31%] [G loss: 0.937746]\n",
      "epoch:29 step:27971 [D loss: 0.535815, acc.: 65.62%] [G loss: 0.752836]\n",
      "epoch:29 step:27972 [D loss: 0.516803, acc.: 75.00%] [G loss: 0.653498]\n",
      "epoch:29 step:27973 [D loss: 0.563001, acc.: 69.53%] [G loss: 0.726716]\n",
      "epoch:29 step:27974 [D loss: 0.477566, acc.: 73.44%] [G loss: 0.798031]\n",
      "epoch:29 step:27975 [D loss: 0.508763, acc.: 76.56%] [G loss: 1.039201]\n",
      "epoch:29 step:27976 [D loss: 0.489076, acc.: 74.22%] [G loss: 1.050458]\n",
      "epoch:29 step:27977 [D loss: 0.521879, acc.: 68.75%] [G loss: 0.647052]\n",
      "epoch:29 step:27978 [D loss: 0.610087, acc.: 65.62%] [G loss: 0.601649]\n",
      "epoch:29 step:27979 [D loss: 0.524226, acc.: 73.44%] [G loss: 0.580209]\n",
      "epoch:29 step:27980 [D loss: 0.535890, acc.: 70.31%] [G loss: 0.612424]\n",
      "epoch:29 step:27981 [D loss: 0.485854, acc.: 77.34%] [G loss: 0.648160]\n",
      "epoch:29 step:27982 [D loss: 0.480230, acc.: 78.12%] [G loss: 0.595209]\n",
      "epoch:29 step:27983 [D loss: 0.508498, acc.: 72.66%] [G loss: 0.642093]\n",
      "epoch:29 step:27984 [D loss: 0.505914, acc.: 73.44%] [G loss: 0.756840]\n",
      "epoch:29 step:27985 [D loss: 0.606687, acc.: 67.97%] [G loss: 0.608441]\n",
      "epoch:29 step:27986 [D loss: 0.514903, acc.: 71.88%] [G loss: 0.556931]\n",
      "epoch:29 step:27987 [D loss: 0.458130, acc.: 73.44%] [G loss: 0.730139]\n",
      "epoch:29 step:27988 [D loss: 0.481098, acc.: 77.34%] [G loss: 0.879230]\n",
      "epoch:29 step:27989 [D loss: 0.481698, acc.: 75.00%] [G loss: 0.994013]\n",
      "epoch:29 step:27990 [D loss: 0.575574, acc.: 66.41%] [G loss: 0.922902]\n",
      "epoch:29 step:27991 [D loss: 0.578528, acc.: 70.31%] [G loss: 0.594136]\n",
      "epoch:29 step:27992 [D loss: 0.495682, acc.: 75.00%] [G loss: 0.599311]\n",
      "epoch:29 step:27993 [D loss: 0.612904, acc.: 64.84%] [G loss: 0.525183]\n",
      "epoch:29 step:27994 [D loss: 0.525221, acc.: 72.66%] [G loss: 0.563040]\n",
      "epoch:29 step:27995 [D loss: 0.553425, acc.: 67.19%] [G loss: 0.484774]\n",
      "epoch:29 step:27996 [D loss: 0.423982, acc.: 77.34%] [G loss: 0.840127]\n",
      "epoch:29 step:27997 [D loss: 0.562679, acc.: 70.31%] [G loss: 0.728471]\n",
      "epoch:29 step:27998 [D loss: 0.528967, acc.: 68.75%] [G loss: 0.786394]\n",
      "epoch:29 step:27999 [D loss: 0.542800, acc.: 65.62%] [G loss: 0.856167]\n",
      "epoch:29 step:28000 [D loss: 0.563444, acc.: 65.62%] [G loss: 0.732825]\n",
      "##############\n",
      "[3.01660375 1.10169375 6.17513371 5.06299672 3.78289016 5.66446147\n",
      " 4.66842062 4.9296711  4.68690753 4.11234126]\n",
      "##########\n",
      "epoch:29 step:28001 [D loss: 0.651904, acc.: 57.03%] [G loss: 0.582208]\n",
      "epoch:29 step:28002 [D loss: 0.532213, acc.: 67.19%] [G loss: 0.664827]\n",
      "epoch:29 step:28003 [D loss: 0.498023, acc.: 75.78%] [G loss: 0.845897]\n",
      "epoch:29 step:28004 [D loss: 0.597312, acc.: 63.28%] [G loss: 0.750981]\n",
      "epoch:29 step:28005 [D loss: 0.593966, acc.: 64.06%] [G loss: 0.688500]\n",
      "epoch:29 step:28006 [D loss: 0.530408, acc.: 72.66%] [G loss: 0.806636]\n",
      "epoch:29 step:28007 [D loss: 0.546601, acc.: 67.19%] [G loss: 0.582958]\n",
      "epoch:29 step:28008 [D loss: 0.547998, acc.: 65.62%] [G loss: 0.612716]\n",
      "epoch:29 step:28009 [D loss: 0.541197, acc.: 71.88%] [G loss: 0.610652]\n",
      "epoch:29 step:28010 [D loss: 0.530410, acc.: 75.00%] [G loss: 0.693712]\n",
      "epoch:29 step:28011 [D loss: 0.510615, acc.: 71.09%] [G loss: 0.666994]\n",
      "epoch:29 step:28012 [D loss: 0.544239, acc.: 71.09%] [G loss: 0.591348]\n",
      "epoch:29 step:28013 [D loss: 0.563800, acc.: 71.88%] [G loss: 0.582031]\n",
      "epoch:29 step:28014 [D loss: 0.529129, acc.: 75.00%] [G loss: 0.544091]\n",
      "epoch:29 step:28015 [D loss: 0.491067, acc.: 75.78%] [G loss: 0.660384]\n",
      "epoch:29 step:28016 [D loss: 0.500742, acc.: 76.56%] [G loss: 0.768416]\n",
      "epoch:29 step:28017 [D loss: 0.540913, acc.: 74.22%] [G loss: 0.710139]\n",
      "epoch:29 step:28018 [D loss: 0.532984, acc.: 71.09%] [G loss: 0.744663]\n",
      "epoch:29 step:28019 [D loss: 0.554804, acc.: 66.41%] [G loss: 0.595028]\n",
      "epoch:29 step:28020 [D loss: 0.623792, acc.: 63.28%] [G loss: 0.513382]\n",
      "epoch:29 step:28021 [D loss: 0.508585, acc.: 75.00%] [G loss: 0.520722]\n",
      "epoch:29 step:28022 [D loss: 0.554870, acc.: 68.75%] [G loss: 0.606375]\n",
      "epoch:29 step:28023 [D loss: 0.515190, acc.: 76.56%] [G loss: 0.526119]\n",
      "epoch:29 step:28024 [D loss: 0.600621, acc.: 60.16%] [G loss: 0.686983]\n",
      "epoch:29 step:28025 [D loss: 0.540000, acc.: 70.31%] [G loss: 0.702074]\n",
      "epoch:29 step:28026 [D loss: 0.584466, acc.: 65.62%] [G loss: 0.708940]\n",
      "epoch:29 step:28027 [D loss: 0.515200, acc.: 66.41%] [G loss: 0.637110]\n",
      "epoch:29 step:28028 [D loss: 0.571504, acc.: 66.41%] [G loss: 0.617833]\n",
      "epoch:29 step:28029 [D loss: 0.637952, acc.: 65.62%] [G loss: 0.551828]\n",
      "epoch:29 step:28030 [D loss: 0.457268, acc.: 76.56%] [G loss: 0.601118]\n",
      "epoch:29 step:28031 [D loss: 0.603260, acc.: 62.50%] [G loss: 0.721576]\n",
      "epoch:29 step:28032 [D loss: 0.562396, acc.: 71.09%] [G loss: 0.711543]\n",
      "epoch:29 step:28033 [D loss: 0.451301, acc.: 76.56%] [G loss: 0.793021]\n",
      "epoch:29 step:28034 [D loss: 0.577582, acc.: 66.41%] [G loss: 0.752393]\n",
      "epoch:29 step:28035 [D loss: 0.522375, acc.: 67.97%] [G loss: 0.659735]\n",
      "epoch:29 step:28036 [D loss: 0.589502, acc.: 71.09%] [G loss: 0.639153]\n",
      "epoch:29 step:28037 [D loss: 0.554047, acc.: 67.97%] [G loss: 0.627897]\n",
      "epoch:29 step:28038 [D loss: 0.607431, acc.: 59.38%] [G loss: 0.490976]\n",
      "epoch:29 step:28039 [D loss: 0.524110, acc.: 73.44%] [G loss: 0.667917]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:29 step:28040 [D loss: 0.637902, acc.: 65.62%] [G loss: 0.510232]\n",
      "epoch:29 step:28041 [D loss: 0.534511, acc.: 71.88%] [G loss: 0.545449]\n",
      "epoch:29 step:28042 [D loss: 0.589068, acc.: 67.19%] [G loss: 0.633234]\n",
      "epoch:29 step:28043 [D loss: 0.441262, acc.: 78.12%] [G loss: 0.884285]\n",
      "epoch:29 step:28044 [D loss: 0.473238, acc.: 78.12%] [G loss: 0.881273]\n",
      "epoch:29 step:28045 [D loss: 0.508110, acc.: 75.78%] [G loss: 0.593831]\n",
      "epoch:29 step:28046 [D loss: 0.582947, acc.: 70.31%] [G loss: 0.600547]\n",
      "epoch:29 step:28047 [D loss: 0.597605, acc.: 66.41%] [G loss: 0.606424]\n",
      "epoch:29 step:28048 [D loss: 0.484109, acc.: 76.56%] [G loss: 0.773792]\n",
      "epoch:29 step:28049 [D loss: 0.532281, acc.: 72.66%] [G loss: 0.756905]\n",
      "epoch:29 step:28050 [D loss: 0.593957, acc.: 65.62%] [G loss: 0.609223]\n",
      "epoch:29 step:28051 [D loss: 0.499637, acc.: 72.66%] [G loss: 0.682655]\n",
      "epoch:29 step:28052 [D loss: 0.539310, acc.: 69.53%] [G loss: 0.642323]\n",
      "epoch:29 step:28053 [D loss: 0.647798, acc.: 60.16%] [G loss: 0.468130]\n",
      "epoch:29 step:28054 [D loss: 0.564543, acc.: 67.97%] [G loss: 0.612699]\n",
      "epoch:29 step:28055 [D loss: 0.587469, acc.: 67.97%] [G loss: 0.654644]\n",
      "epoch:29 step:28056 [D loss: 0.590990, acc.: 67.97%] [G loss: 0.620188]\n",
      "epoch:29 step:28057 [D loss: 0.463556, acc.: 77.34%] [G loss: 0.655993]\n",
      "epoch:29 step:28058 [D loss: 0.521604, acc.: 74.22%] [G loss: 0.694538]\n",
      "epoch:29 step:28059 [D loss: 0.474662, acc.: 78.12%] [G loss: 1.016429]\n",
      "epoch:29 step:28060 [D loss: 0.532004, acc.: 73.44%] [G loss: 0.764567]\n",
      "epoch:29 step:28061 [D loss: 0.558937, acc.: 65.62%] [G loss: 0.727587]\n",
      "epoch:29 step:28062 [D loss: 0.538237, acc.: 70.31%] [G loss: 0.732875]\n",
      "epoch:29 step:28063 [D loss: 0.481440, acc.: 75.78%] [G loss: 0.708211]\n",
      "epoch:29 step:28064 [D loss: 0.584470, acc.: 66.41%] [G loss: 0.873142]\n",
      "epoch:29 step:28065 [D loss: 0.649248, acc.: 62.50%] [G loss: 0.524769]\n",
      "epoch:29 step:28066 [D loss: 0.548563, acc.: 67.97%] [G loss: 0.766532]\n",
      "epoch:29 step:28067 [D loss: 0.470385, acc.: 76.56%] [G loss: 0.986702]\n",
      "epoch:29 step:28068 [D loss: 0.490760, acc.: 77.34%] [G loss: 0.917137]\n",
      "epoch:29 step:28069 [D loss: 0.484836, acc.: 77.34%] [G loss: 1.008887]\n",
      "epoch:29 step:28070 [D loss: 0.529588, acc.: 69.53%] [G loss: 0.780102]\n",
      "epoch:29 step:28071 [D loss: 0.466289, acc.: 82.03%] [G loss: 0.937467]\n",
      "epoch:29 step:28072 [D loss: 0.482218, acc.: 77.34%] [G loss: 0.824421]\n",
      "epoch:29 step:28073 [D loss: 0.510690, acc.: 73.44%] [G loss: 0.960011]\n",
      "epoch:29 step:28074 [D loss: 0.505892, acc.: 73.44%] [G loss: 1.010526]\n",
      "epoch:29 step:28075 [D loss: 0.524329, acc.: 67.97%] [G loss: 0.924369]\n",
      "epoch:29 step:28076 [D loss: 0.477409, acc.: 79.69%] [G loss: 0.697877]\n",
      "epoch:29 step:28077 [D loss: 0.560361, acc.: 73.44%] [G loss: 0.768206]\n",
      "epoch:29 step:28078 [D loss: 0.588593, acc.: 65.62%] [G loss: 0.873466]\n",
      "epoch:29 step:28079 [D loss: 0.529285, acc.: 68.75%] [G loss: 0.904902]\n",
      "epoch:29 step:28080 [D loss: 0.560485, acc.: 73.44%] [G loss: 0.651431]\n",
      "epoch:29 step:28081 [D loss: 0.540247, acc.: 71.88%] [G loss: 0.824215]\n",
      "epoch:29 step:28082 [D loss: 0.550287, acc.: 73.44%] [G loss: 0.735744]\n",
      "epoch:29 step:28083 [D loss: 0.567720, acc.: 71.09%] [G loss: 0.727008]\n",
      "epoch:29 step:28084 [D loss: 0.537985, acc.: 72.66%] [G loss: 0.559177]\n",
      "epoch:29 step:28085 [D loss: 0.540337, acc.: 71.09%] [G loss: 0.764508]\n",
      "epoch:29 step:28086 [D loss: 0.531681, acc.: 73.44%] [G loss: 0.826707]\n",
      "epoch:29 step:28087 [D loss: 0.495808, acc.: 72.66%] [G loss: 0.823725]\n",
      "epoch:29 step:28088 [D loss: 0.560316, acc.: 67.19%] [G loss: 0.727790]\n",
      "epoch:29 step:28089 [D loss: 0.493437, acc.: 74.22%] [G loss: 0.698463]\n",
      "epoch:29 step:28090 [D loss: 0.596542, acc.: 62.50%] [G loss: 0.785685]\n",
      "epoch:29 step:28091 [D loss: 0.523937, acc.: 73.44%] [G loss: 0.958889]\n",
      "epoch:29 step:28092 [D loss: 0.398015, acc.: 84.38%] [G loss: 1.185032]\n",
      "epoch:29 step:28093 [D loss: 0.742335, acc.: 59.38%] [G loss: 0.734067]\n",
      "epoch:29 step:28094 [D loss: 0.431013, acc.: 78.12%] [G loss: 0.677214]\n",
      "epoch:29 step:28095 [D loss: 0.534972, acc.: 71.88%] [G loss: 0.590039]\n",
      "epoch:29 step:28096 [D loss: 0.427661, acc.: 78.91%] [G loss: 0.879373]\n",
      "epoch:29 step:28097 [D loss: 0.442790, acc.: 78.12%] [G loss: 0.946947]\n",
      "epoch:29 step:28098 [D loss: 0.406620, acc.: 79.69%] [G loss: 1.252413]\n",
      "epoch:29 step:28099 [D loss: 0.493187, acc.: 71.88%] [G loss: 1.218634]\n",
      "epoch:29 step:28100 [D loss: 0.498776, acc.: 75.00%] [G loss: 1.265180]\n",
      "epoch:29 step:28101 [D loss: 0.631987, acc.: 67.97%] [G loss: 1.405734]\n",
      "epoch:29 step:28102 [D loss: 0.414263, acc.: 81.25%] [G loss: 1.703876]\n",
      "epoch:29 step:28103 [D loss: 0.479583, acc.: 71.09%] [G loss: 1.392637]\n",
      "epoch:29 step:28104 [D loss: 0.529188, acc.: 71.88%] [G loss: 1.278092]\n",
      "epoch:29 step:28105 [D loss: 0.560913, acc.: 68.75%] [G loss: 0.790607]\n",
      "epoch:29 step:28106 [D loss: 0.522814, acc.: 74.22%] [G loss: 0.923956]\n",
      "epoch:29 step:28107 [D loss: 0.496163, acc.: 72.66%] [G loss: 0.935176]\n",
      "epoch:29 step:28108 [D loss: 0.519051, acc.: 71.88%] [G loss: 1.363818]\n",
      "epoch:29 step:28109 [D loss: 0.358726, acc.: 84.38%] [G loss: 1.342647]\n",
      "epoch:29 step:28110 [D loss: 0.468717, acc.: 78.91%] [G loss: 1.248713]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "if not os.path.isdir('saved_models_mnist_{}'.format('bgan')):\n",
    "    os.mkdir('saved_models_mnist_{}'.format('bgan'))\n",
    "f = open('saved_models_mnist_{}/log_collapse1.txt'.format('bgan'), mode='w')\n",
    "import torch.utils.data as Data\n",
    "\n",
    "from keras.datasets import mnist\n",
    "from keras.layers import Input, Dense, Reshape, Flatten, Dropout\n",
    "from keras.layers import BatchNormalization, Activation, ZeroPadding2D\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.layers.convolutional import UpSampling2D, Conv2D\n",
    "from keras.models import Sequential, Model\n",
    "from keras.optimizers import Adam\n",
    "import keras.backend as K\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "class BGAN():\n",
    "    \"\"\"Reference: https://wiseodd.github.io/techblog/2017/03/07/boundary-seeking-gan/\"\"\"\n",
    "    def __init__(self):\n",
    "        self.img_rows = 28\n",
    "        self.img_cols = 28\n",
    "        self.channels = 1\n",
    "        self.img_shape = (self.img_rows, self.img_cols, self.channels)\n",
    "        self.latent_dim = 100\n",
    "        self.x = []\n",
    "        self.y = np.zeros((31, 1), dtype=np.int)\n",
    "        self.y = list(self.y)\n",
    "        for i in range(31):\n",
    "            self.y[i] = []\n",
    "\n",
    "        optimizer = Adam(0.0002, 0.5)\n",
    "\n",
    "        # Build and compile the discriminator\n",
    "        self.discriminator = self.build_discriminator()\n",
    "        self.discriminator.compile(loss='binary_crossentropy',\n",
    "            optimizer=optimizer,\n",
    "            metrics=['accuracy'])\n",
    "\n",
    "        # Build the generator\n",
    "        self.generator = self.build_generator()\n",
    "\n",
    "        # The generator takes noise as input and generated imgs\n",
    "        z = Input(shape=(self.latent_dim,))\n",
    "        img = self.generator(z)\n",
    "\n",
    "        # For the combined model we will only train the generator\n",
    "        self.discriminator.trainable = False\n",
    "\n",
    "        # The valid takes generated images as input and determines validity\n",
    "        valid = self.discriminator(img)\n",
    "\n",
    "        # The combined model  (stacked generator and discriminator)\n",
    "        # Trains the generator to fool the discriminator\n",
    "        self.combined = Model(z, valid)\n",
    "        self.combined.compile(loss=self.boundary_loss, optimizer=optimizer)\n",
    "\n",
    "    def build_generator(self):\n",
    "\n",
    "        model = Sequential()\n",
    "\n",
    "        model.add(Dense(256, input_dim=self.latent_dim))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(Dense(512))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(Dense(1024))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(Dense(np.prod(self.img_shape), activation='tanh'))\n",
    "        model.add(Reshape(self.img_shape))\n",
    "\n",
    "        model.summary()\n",
    "\n",
    "        noise = Input(shape=(self.latent_dim,))\n",
    "        img = model(noise)\n",
    "\n",
    "        return Model(noise, img)\n",
    "\n",
    "    def build_discriminator(self):\n",
    "\n",
    "        model = Sequential()\n",
    "\n",
    "        model.add(Flatten(input_shape=self.img_shape))\n",
    "        model.add(Dense(512))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dense(256))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dense(1, activation='sigmoid'))\n",
    "        model.summary()\n",
    "\n",
    "        img = Input(shape=self.img_shape)\n",
    "        validity = model(img)\n",
    "\n",
    "        return Model(img, validity)\n",
    "\n",
    "    def boundary_loss(self, y_true, y_pred):\n",
    "        \"\"\"\n",
    "        Boundary seeking loss.\n",
    "        Reference: https://wiseodd.github.io/techblog/2017/03/07/boundary-seeking-gan/\n",
    "        \"\"\"\n",
    "        return 0.5 * K.mean((K.log(y_pred) - K.log(1 - y_pred))**2)\n",
    "\n",
    "    def train(self, epochs, batch_size=128, sample_interval=50):\n",
    "\n",
    "        # Load the dataset\n",
    "        (X_train, _), (X_test,y_test) = mnist.load_data()\n",
    "\n",
    "        # Rescale -1 to 1\n",
    "        X_train = X_train / 127.5 - 1.\n",
    "        X_train = np.expand_dims(X_train, axis=3)\n",
    "        X_test = (X_test.astype(np.float32) - 127.5) / 127.5\n",
    "        # X_test = X_test / 127.5 - 1.\n",
    "        X_test = np.expand_dims(X_test, axis=3)\n",
    "\n",
    "        # Adversarial ground truths\n",
    "        valid = np.ones((batch_size, 1))\n",
    "        fake = np.zeros((batch_size, 1))\n",
    "        nb_batches = int(X_train.shape[0] / batch_size)\n",
    "        global_step = 0\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "\n",
    "            # ---------------------\n",
    "            #  Train Discriminator\n",
    "            # ---------------------\n",
    "\n",
    "            # Select a random batch of images\n",
    "            # idx = np.random.randint(0, X_train.shape[0], batch_size)\n",
    "            for index in range(nb_batches):\n",
    "                global_step += 1\n",
    "                # progress_bar.update(index)\n",
    "\n",
    "                # get a batch of real images\n",
    "                image_batch = X_train[index * batch_size:(index + 1) * batch_size]\n",
    "\n",
    "                noise = np.random.normal(0, 1, (batch_size, self.latent_dim))\n",
    "\n",
    "                # Generate a batch of new images\n",
    "                gen_imgs = self.generator.predict(noise)\n",
    "\n",
    "                # Train the discriminator\n",
    "                d_loss_real = self.discriminator.train_on_batch(image_batch, valid)\n",
    "                d_loss_fake = self.discriminator.train_on_batch(gen_imgs, fake)\n",
    "                d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
    "\n",
    "                # ---------------------\n",
    "                #  Train Generator\n",
    "                # ---------------------\n",
    "\n",
    "                g_loss = self.combined.train_on_batch(noise, valid)\n",
    "\n",
    "                # Plot the progress\n",
    "                print(\"epoch:%d step:%d [D loss: %f, acc.: %.2f%%] [G loss: %f]\" % (epoch,global_step, d_loss[0], 100 * d_loss[1], g_loss))\n",
    "                sampleSize = 5000\n",
    "                # If at save interval => save generated image samples\n",
    "                if global_step % sample_interval == 0:\n",
    "                    s = self.sample_images(global_step, X_test,y_test, sampleSize)\n",
    "    def sample_images(self, epoch,x_test,y_test,sample_num):\n",
    "        r, c = sample_num//10, 10\n",
    "        noise = np.random.normal(0, 1, (r * c, 100))\n",
    "#         sampled_labels = np.array([num for _ in range(r) for num in range(c)])\n",
    "        gen_imgs = self.generator.predict([noise])\n",
    "        # Rescale images 0 - 1\n",
    "        gen_imgs = 0.5 * gen_imgs + 0.5\n",
    "        labels = np.squeeze(y_test[:sample_num])\n",
    "        labels = np.squeeze(labels)\n",
    "        dis_real = cal_distance_image_real(x_test[:sample_num], labels)\n",
    "        dis_fake = cal_distance_image_fake(gen_imgs)\n",
    "        dis_cha = dis_real - dis_fake\n",
    "        print('##############')\n",
    "        # print(dis_real)\n",
    "        # print(dis_fake)\n",
    "        print(dis_cha)\n",
    "        print('##########')\n",
    "        f.writelines('\\n')\n",
    "        f.writelines('epoch:' + str(epoch))\n",
    "        f.writelines('\\n')\n",
    "        f.writelines('紧度')\n",
    "        f.writelines('\\n')\n",
    "        f.writelines(' %.8f ' % (i) for i in dis_cha)\n",
    "        f.writelines('\\n')\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    bgan = BGAN()\n",
    "    bgan.train(epochs=30, batch_size=64, sample_interval=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pppppppp [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
