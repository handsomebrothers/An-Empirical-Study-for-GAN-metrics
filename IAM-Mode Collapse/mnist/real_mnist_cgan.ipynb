{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-*-coding:utf-8-*-\n",
    "import util\n",
    "import tensorflow as tf\n",
    "MNIST_CLASSIFIER_FROZEN_GRAPH = './classify_mnist_graph_def.pb'\n",
    "INPUT_TENSOR = 'inputs:0'\n",
    "OUTPUT_TENSOR = 'logits:0'\n",
    "def EuclideanDistances(A, B):\n",
    "\n",
    "    BT = B.transpose()\n",
    "    # vecProd = A * BT\n",
    "    vecProd = np.dot(A, BT)\n",
    "    # print(vecProd)\n",
    "    SqA = A ** 2\n",
    "    # print(SqA)\n",
    "    sumSqA = np.matrix(np.sum(SqA, axis=1))\n",
    "    sumSqAEx = np.tile(sumSqA.transpose(), (1, vecProd.shape[1]))\n",
    "    # print(sumSqAEx)\n",
    "\n",
    "    SqB = B ** 2\n",
    "    sumSqB = np.sum(SqB, axis=1)\n",
    "    sumSqBEx = np.tile(sumSqB, (vecProd.shape[0], 1))\n",
    "    SqED = sumSqBEx + sumSqAEx - 2 * vecProd\n",
    "    SqED[SqED < 0] = 0.0\n",
    "    ED = np.sqrt(SqED)\n",
    "    return np.divide(ED.sum(),ED.shape[0]*ED.shape[1])\n",
    "def cal_distance_image_real(images,labels):\n",
    "    eval_images=tf.convert_to_tensor(images)\n",
    "    y_logits=util.mnist_logits(eval_images, MNIST_CLASSIFIER_FROZEN_GRAPH, INPUT_TENSOR, OUTPUT_TENSOR)\n",
    "    y_logits=tf.Session().run(y_logits)\n",
    "    dict={}\n",
    "    all_dis=[]\n",
    "    for i in range(10):\n",
    "        dict[i]=[]\n",
    "    for i in range(len(labels)):\n",
    "        dict[labels[i]].append(y_logits[i])\n",
    "    for i in range(10):\n",
    "        dict[i]=np.array(dict[i])\n",
    "        if len(dict[i]):\n",
    "            dis = EuclideanDistances(dict[i], dict[i])  # 生成图片的紧度\n",
    "        else:\n",
    "            dis = -1\n",
    "        all_dis.append(dis)\n",
    "    return np.array(all_dis)\n",
    "def cal_distance_image_fake(images):\n",
    "    eval_images=tf.convert_to_tensor(images)\n",
    "    y_logits=util.mnist_logits(eval_images, MNIST_CLASSIFIER_FROZEN_GRAPH, INPUT_TENSOR, OUTPUT_TENSOR)\n",
    "    y_logits=tf.Session().run(y_logits)\n",
    "    labels = tf.Session().run(tf.argmax(y_logits, 1))\n",
    "    dict={}\n",
    "    all_dis=[]\n",
    "    for i in range(10):\n",
    "        dict[i]=[]\n",
    "    for i in range(len(labels)):\n",
    "        dict[labels[i]].append(y_logits[i])\n",
    "    for i in range(10):\n",
    "        dict[i]=np.array(dict[i])\n",
    "        if len(dict[i]):\n",
    "            dis = EuclideanDistances(dict[i], dict[i])  # 生成图片的紧度\n",
    "        else:\n",
    "            dis = -1\n",
    "        all_dis.append(dis)\n",
    "    return np.array(all_dis)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 784)               615440    \n",
      "_________________________________________________________________\n",
      "reshape_1 (Reshape)          (None, 28, 28, 1)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 14, 14, 64)        640       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 14, 14, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 7, 7, 128)         73856     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)    (None, 7, 7, 128)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 7, 7, 128)         512       \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 4, 4, 256)         295168    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)    (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 4, 4, 256)         1024      \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 4, 4, 512)         1180160   \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)    (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 8192)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 8193      \n",
      "=================================================================\n",
      "Total params: 2,175,249\n",
      "Trainable params: 2,174,353\n",
      "Non-trainable params: 896\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_3 (Dense)              (None, 25088)             2533888   \n",
      "_________________________________________________________________\n",
      "reshape_2 (Reshape)          (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 7, 7, 512)         2048      \n",
      "_________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2 (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 14, 14, 256)       1179904   \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 14, 14, 256)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 14, 14, 256)       1024      \n",
      "_________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2 (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 28, 28, 128)       295040    \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 28, 28, 128)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 28, 28, 128)       512       \n",
      "_________________________________________________________________\n",
      "up_sampling2d_3 (UpSampling2 (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 56, 56, 64)        73792     \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 56, 56, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 28, 28, 1)         577       \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 28, 28, 1)         0         \n",
      "=================================================================\n",
      "Total params: 4,086,785\n",
      "Trainable params: 4,084,993\n",
      "Non-trainable params: 1,792\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/imi432_006/anaconda3/envs/tf/lib/python3.5/site-packages/keras/engine/training.py:490: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "  'Discrepancy between trainable weights and collected trainable'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0 step:1 [D loss: 1.234361, acc.: 21.09%] [G loss: 0.187136]\n",
      "epoch:0 step:2 [D loss: 1.626225, acc.: 50.00%] [G loss: 0.371882]\n",
      "epoch:0 step:3 [D loss: 0.839789, acc.: 60.94%] [G loss: 1.734611]\n",
      "epoch:0 step:4 [D loss: 0.802841, acc.: 55.47%] [G loss: 1.941102]\n",
      "epoch:0 step:5 [D loss: 0.823138, acc.: 46.09%] [G loss: 2.343789]\n",
      "epoch:0 step:6 [D loss: 0.521292, acc.: 75.78%] [G loss: 2.581154]\n",
      "epoch:0 step:7 [D loss: 0.535790, acc.: 73.44%] [G loss: 2.141510]\n",
      "epoch:0 step:8 [D loss: 0.801034, acc.: 51.56%] [G loss: 2.974207]\n",
      "epoch:0 step:9 [D loss: 0.592668, acc.: 67.19%] [G loss: 3.432101]\n",
      "epoch:0 step:10 [D loss: 0.510780, acc.: 71.09%] [G loss: 3.015180]\n",
      "epoch:0 step:11 [D loss: 1.023798, acc.: 67.97%] [G loss: 3.135301]\n",
      "epoch:0 step:12 [D loss: 0.918855, acc.: 63.28%] [G loss: 4.431047]\n",
      "epoch:0 step:13 [D loss: 0.742997, acc.: 75.00%] [G loss: 4.041420]\n",
      "epoch:0 step:14 [D loss: 0.502613, acc.: 71.09%] [G loss: 3.551806]\n",
      "epoch:0 step:15 [D loss: 0.406933, acc.: 81.25%] [G loss: 3.980251]\n",
      "epoch:0 step:16 [D loss: 0.485036, acc.: 74.22%] [G loss: 3.247324]\n",
      "epoch:0 step:17 [D loss: 0.555814, acc.: 71.09%] [G loss: 3.688612]\n",
      "epoch:0 step:18 [D loss: 0.635419, acc.: 67.97%] [G loss: 4.342448]\n",
      "epoch:0 step:19 [D loss: 0.554576, acc.: 71.09%] [G loss: 4.086430]\n",
      "epoch:0 step:20 [D loss: 0.724033, acc.: 70.31%] [G loss: 3.666367]\n",
      "epoch:0 step:21 [D loss: 0.423355, acc.: 81.25%] [G loss: 4.099427]\n",
      "epoch:0 step:22 [D loss: 0.783034, acc.: 65.62%] [G loss: 4.016730]\n",
      "epoch:0 step:23 [D loss: 0.435765, acc.: 82.81%] [G loss: 3.751941]\n",
      "epoch:0 step:24 [D loss: 0.563339, acc.: 74.22%] [G loss: 3.692011]\n",
      "epoch:0 step:25 [D loss: 0.442546, acc.: 75.00%] [G loss: 4.040497]\n",
      "epoch:0 step:26 [D loss: 0.261700, acc.: 93.75%] [G loss: 5.384331]\n",
      "epoch:0 step:27 [D loss: 0.159802, acc.: 94.53%] [G loss: 4.020877]\n",
      "epoch:0 step:28 [D loss: 0.388710, acc.: 82.03%] [G loss: 5.042336]\n",
      "epoch:0 step:29 [D loss: 0.616380, acc.: 78.91%] [G loss: 4.350992]\n",
      "epoch:0 step:30 [D loss: 0.277514, acc.: 89.06%] [G loss: 4.432602]\n",
      "epoch:0 step:31 [D loss: 0.369672, acc.: 82.03%] [G loss: 5.744242]\n",
      "epoch:0 step:32 [D loss: 0.318349, acc.: 82.03%] [G loss: 6.281934]\n",
      "epoch:0 step:33 [D loss: 0.625745, acc.: 81.25%] [G loss: 4.253855]\n",
      "epoch:0 step:34 [D loss: 0.359697, acc.: 88.28%] [G loss: 4.379931]\n",
      "epoch:0 step:35 [D loss: 0.481231, acc.: 80.47%] [G loss: 4.225088]\n",
      "epoch:0 step:36 [D loss: 0.366381, acc.: 87.50%] [G loss: 4.385813]\n",
      "epoch:0 step:37 [D loss: 0.365398, acc.: 79.69%] [G loss: 4.195401]\n",
      "epoch:0 step:38 [D loss: 0.484946, acc.: 73.44%] [G loss: 6.170342]\n",
      "epoch:0 step:39 [D loss: 0.283932, acc.: 92.19%] [G loss: 6.537304]\n",
      "epoch:0 step:40 [D loss: 0.253857, acc.: 86.72%] [G loss: 5.477847]\n",
      "epoch:0 step:41 [D loss: 0.238169, acc.: 91.41%] [G loss: 4.284076]\n",
      "epoch:0 step:42 [D loss: 0.275073, acc.: 89.06%] [G loss: 4.914150]\n",
      "epoch:0 step:43 [D loss: 0.222931, acc.: 94.53%] [G loss: 5.714354]\n",
      "epoch:0 step:44 [D loss: 0.360732, acc.: 83.59%] [G loss: 4.733349]\n",
      "epoch:0 step:45 [D loss: 0.624374, acc.: 71.09%] [G loss: 5.087244]\n",
      "epoch:0 step:46 [D loss: 0.372787, acc.: 85.16%] [G loss: 5.987273]\n",
      "epoch:0 step:47 [D loss: 0.248383, acc.: 90.62%] [G loss: 5.074634]\n",
      "epoch:0 step:48 [D loss: 0.595543, acc.: 78.12%] [G loss: 4.290323]\n",
      "epoch:0 step:49 [D loss: 0.255828, acc.: 89.06%] [G loss: 5.027386]\n",
      "epoch:0 step:50 [D loss: 0.098811, acc.: 97.66%] [G loss: 4.108856]\n",
      "epoch:0 step:51 [D loss: 0.349190, acc.: 77.34%] [G loss: 5.588804]\n",
      "epoch:0 step:52 [D loss: 0.609306, acc.: 82.03%] [G loss: 5.976049]\n",
      "epoch:0 step:53 [D loss: 0.214853, acc.: 92.97%] [G loss: 4.689712]\n",
      "epoch:0 step:54 [D loss: 0.158151, acc.: 96.09%] [G loss: 3.964603]\n",
      "epoch:0 step:55 [D loss: 0.086412, acc.: 95.31%] [G loss: 4.315857]\n",
      "epoch:0 step:56 [D loss: 0.090150, acc.: 98.44%] [G loss: 5.184349]\n",
      "epoch:0 step:57 [D loss: 0.100585, acc.: 98.44%] [G loss: 5.307217]\n",
      "epoch:0 step:58 [D loss: 0.119426, acc.: 97.66%] [G loss: 5.539888]\n",
      "epoch:0 step:59 [D loss: 0.201917, acc.: 88.28%] [G loss: 5.425999]\n",
      "epoch:0 step:60 [D loss: 0.157124, acc.: 96.88%] [G loss: 4.593416]\n",
      "epoch:0 step:61 [D loss: 0.051868, acc.: 97.66%] [G loss: 4.210313]\n",
      "epoch:0 step:62 [D loss: 0.214996, acc.: 92.97%] [G loss: 5.430113]\n",
      "epoch:0 step:63 [D loss: 0.120739, acc.: 96.88%] [G loss: 5.638643]\n",
      "epoch:0 step:64 [D loss: 0.162448, acc.: 95.31%] [G loss: 4.588663]\n",
      "epoch:0 step:65 [D loss: 0.201737, acc.: 96.88%] [G loss: 3.901793]\n",
      "epoch:0 step:66 [D loss: 0.198585, acc.: 92.19%] [G loss: 5.517372]\n",
      "epoch:0 step:67 [D loss: 0.120824, acc.: 96.09%] [G loss: 5.494155]\n",
      "epoch:0 step:68 [D loss: 0.072964, acc.: 98.44%] [G loss: 4.938243]\n",
      "epoch:0 step:69 [D loss: 0.177369, acc.: 92.97%] [G loss: 5.521214]\n",
      "epoch:0 step:70 [D loss: 0.095692, acc.: 96.09%] [G loss: 5.458589]\n",
      "epoch:0 step:71 [D loss: 0.082260, acc.: 97.66%] [G loss: 5.984936]\n",
      "epoch:0 step:72 [D loss: 0.077469, acc.: 98.44%] [G loss: 5.588151]\n",
      "epoch:0 step:73 [D loss: 0.180423, acc.: 90.62%] [G loss: 5.415386]\n",
      "epoch:0 step:74 [D loss: 0.801694, acc.: 76.56%] [G loss: 8.504915]\n",
      "epoch:0 step:75 [D loss: 0.750866, acc.: 85.94%] [G loss: 6.044266]\n",
      "epoch:0 step:76 [D loss: 1.010084, acc.: 79.69%] [G loss: 4.209582]\n",
      "epoch:0 step:77 [D loss: 0.143115, acc.: 95.31%] [G loss: 6.021230]\n",
      "epoch:0 step:78 [D loss: 0.128228, acc.: 96.09%] [G loss: 4.701301]\n",
      "epoch:0 step:79 [D loss: 0.178097, acc.: 93.75%] [G loss: 6.391184]\n",
      "epoch:0 step:80 [D loss: 0.066394, acc.: 99.22%] [G loss: 5.269726]\n",
      "epoch:0 step:81 [D loss: 0.312819, acc.: 92.97%] [G loss: 5.625227]\n",
      "epoch:0 step:82 [D loss: 0.100061, acc.: 95.31%] [G loss: 5.255711]\n",
      "epoch:0 step:83 [D loss: 0.199636, acc.: 92.97%] [G loss: 4.021213]\n",
      "epoch:0 step:84 [D loss: 0.896704, acc.: 85.16%] [G loss: 5.845222]\n",
      "epoch:0 step:85 [D loss: 0.155160, acc.: 95.31%] [G loss: 6.235857]\n",
      "epoch:0 step:86 [D loss: 0.835613, acc.: 91.41%] [G loss: 6.727629]\n",
      "epoch:0 step:87 [D loss: 0.078290, acc.: 96.88%] [G loss: 4.581114]\n",
      "epoch:0 step:88 [D loss: 0.275284, acc.: 91.41%] [G loss: 5.665644]\n",
      "epoch:0 step:89 [D loss: 0.083323, acc.: 99.22%] [G loss: 5.880215]\n",
      "epoch:0 step:90 [D loss: 0.148598, acc.: 95.31%] [G loss: 6.054855]\n",
      "epoch:0 step:91 [D loss: 0.125834, acc.: 95.31%] [G loss: 5.366475]\n",
      "epoch:0 step:92 [D loss: 0.103896, acc.: 97.66%] [G loss: 4.507226]\n",
      "epoch:0 step:93 [D loss: 0.049302, acc.: 98.44%] [G loss: 4.476646]\n",
      "epoch:0 step:94 [D loss: 0.068049, acc.: 98.44%] [G loss: 4.304185]\n",
      "epoch:0 step:95 [D loss: 0.075703, acc.: 97.66%] [G loss: 5.552195]\n",
      "epoch:0 step:96 [D loss: 0.041720, acc.: 99.22%] [G loss: 4.866009]\n",
      "epoch:0 step:97 [D loss: 0.086436, acc.: 99.22%] [G loss: 5.787653]\n",
      "epoch:0 step:98 [D loss: 0.155413, acc.: 92.97%] [G loss: 6.388712]\n",
      "epoch:0 step:99 [D loss: 0.144807, acc.: 94.53%] [G loss: 4.547093]\n",
      "epoch:0 step:100 [D loss: 0.112094, acc.: 95.31%] [G loss: 5.226481]\n",
      "epoch:0 step:101 [D loss: 0.063641, acc.: 99.22%] [G loss: 5.782473]\n",
      "epoch:0 step:102 [D loss: 0.077370, acc.: 98.44%] [G loss: 4.165732]\n",
      "epoch:0 step:103 [D loss: 0.045873, acc.: 100.00%] [G loss: 5.766850]\n",
      "epoch:0 step:104 [D loss: 0.022366, acc.: 100.00%] [G loss: 4.865184]\n",
      "epoch:0 step:105 [D loss: 0.055352, acc.: 99.22%] [G loss: 4.383701]\n",
      "epoch:0 step:106 [D loss: 0.065063, acc.: 99.22%] [G loss: 4.860749]\n",
      "epoch:0 step:107 [D loss: 0.208850, acc.: 91.41%] [G loss: 5.929452]\n",
      "epoch:0 step:108 [D loss: 0.066986, acc.: 99.22%] [G loss: 5.078834]\n",
      "epoch:0 step:109 [D loss: 0.084181, acc.: 97.66%] [G loss: 5.792588]\n",
      "epoch:0 step:110 [D loss: 0.071559, acc.: 97.66%] [G loss: 6.026243]\n",
      "epoch:0 step:111 [D loss: 0.153674, acc.: 95.31%] [G loss: 5.844008]\n",
      "epoch:0 step:112 [D loss: 0.102967, acc.: 96.09%] [G loss: 5.277485]\n",
      "epoch:0 step:113 [D loss: 0.197197, acc.: 90.62%] [G loss: 5.348355]\n",
      "epoch:0 step:114 [D loss: 0.323968, acc.: 88.28%] [G loss: 6.133586]\n",
      "epoch:0 step:115 [D loss: 0.366836, acc.: 85.94%] [G loss: 6.359189]\n",
      "epoch:0 step:116 [D loss: 0.398383, acc.: 86.72%] [G loss: 6.494369]\n",
      "epoch:0 step:117 [D loss: 0.247072, acc.: 90.62%] [G loss: 6.089124]\n",
      "epoch:0 step:118 [D loss: 0.178233, acc.: 93.75%] [G loss: 7.191052]\n",
      "epoch:0 step:119 [D loss: 0.342921, acc.: 88.28%] [G loss: 5.683140]\n",
      "epoch:0 step:120 [D loss: 1.262861, acc.: 64.84%] [G loss: 6.336659]\n",
      "epoch:0 step:121 [D loss: 0.401140, acc.: 79.69%] [G loss: 6.086739]\n",
      "epoch:0 step:122 [D loss: 0.990416, acc.: 79.69%] [G loss: 5.301700]\n",
      "epoch:0 step:123 [D loss: 0.471125, acc.: 89.84%] [G loss: 5.746681]\n",
      "epoch:0 step:124 [D loss: 0.113927, acc.: 96.09%] [G loss: 6.807596]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0 step:125 [D loss: 0.440912, acc.: 85.94%] [G loss: 7.907975]\n",
      "epoch:0 step:126 [D loss: 0.420633, acc.: 91.41%] [G loss: 6.786548]\n",
      "epoch:0 step:127 [D loss: 0.121031, acc.: 95.31%] [G loss: 3.746032]\n",
      "epoch:0 step:128 [D loss: 0.269543, acc.: 91.41%] [G loss: 6.812435]\n",
      "epoch:0 step:129 [D loss: 0.368960, acc.: 85.94%] [G loss: 4.759154]\n",
      "epoch:0 step:130 [D loss: 0.126483, acc.: 93.75%] [G loss: 6.491962]\n",
      "epoch:0 step:131 [D loss: 0.086315, acc.: 96.88%] [G loss: 5.841400]\n",
      "epoch:0 step:132 [D loss: 0.457604, acc.: 82.81%] [G loss: 3.605254]\n",
      "epoch:0 step:133 [D loss: 0.121357, acc.: 97.66%] [G loss: 4.981948]\n",
      "epoch:0 step:134 [D loss: 0.082350, acc.: 98.44%] [G loss: 5.931878]\n",
      "epoch:0 step:135 [D loss: 0.153307, acc.: 95.31%] [G loss: 4.438735]\n",
      "epoch:0 step:136 [D loss: 0.678324, acc.: 68.75%] [G loss: 7.178815]\n",
      "epoch:0 step:137 [D loss: 0.572998, acc.: 78.12%] [G loss: 6.313098]\n",
      "epoch:0 step:138 [D loss: 0.332341, acc.: 85.16%] [G loss: 3.510972]\n",
      "epoch:0 step:139 [D loss: 1.174368, acc.: 71.09%] [G loss: 5.624765]\n",
      "epoch:0 step:140 [D loss: 0.059422, acc.: 99.22%] [G loss: 5.551446]\n",
      "epoch:0 step:141 [D loss: 0.217715, acc.: 92.97%] [G loss: 6.604347]\n",
      "epoch:0 step:142 [D loss: 0.062064, acc.: 98.44%] [G loss: 4.314976]\n",
      "epoch:0 step:143 [D loss: 0.452148, acc.: 82.03%] [G loss: 7.072825]\n",
      "epoch:0 step:144 [D loss: 0.224052, acc.: 92.97%] [G loss: 7.437607]\n",
      "epoch:0 step:145 [D loss: 0.287433, acc.: 88.28%] [G loss: 4.936586]\n",
      "epoch:0 step:146 [D loss: 0.272129, acc.: 85.94%] [G loss: 7.633411]\n",
      "epoch:0 step:147 [D loss: 0.109054, acc.: 95.31%] [G loss: 6.893252]\n",
      "epoch:0 step:148 [D loss: 0.233374, acc.: 89.84%] [G loss: 3.536928]\n",
      "epoch:0 step:149 [D loss: 0.175729, acc.: 93.75%] [G loss: 6.776051]\n",
      "epoch:0 step:150 [D loss: 0.499770, acc.: 74.22%] [G loss: 4.700378]\n",
      "epoch:0 step:151 [D loss: 0.128002, acc.: 93.75%] [G loss: 5.319767]\n",
      "epoch:0 step:152 [D loss: 0.221332, acc.: 84.38%] [G loss: 7.313442]\n",
      "epoch:0 step:153 [D loss: 1.031459, acc.: 69.53%] [G loss: 5.176143]\n",
      "epoch:0 step:154 [D loss: 0.278980, acc.: 90.62%] [G loss: 7.837737]\n",
      "epoch:0 step:155 [D loss: 0.244907, acc.: 88.28%] [G loss: 6.527667]\n",
      "epoch:0 step:156 [D loss: 1.020951, acc.: 58.59%] [G loss: 6.476108]\n",
      "epoch:0 step:157 [D loss: 0.585647, acc.: 82.03%] [G loss: 8.207064]\n",
      "epoch:0 step:158 [D loss: 0.238262, acc.: 92.97%] [G loss: 4.738817]\n",
      "epoch:0 step:159 [D loss: 0.740173, acc.: 87.50%] [G loss: 5.964221]\n",
      "epoch:0 step:160 [D loss: 0.960251, acc.: 66.41%] [G loss: 8.290735]\n",
      "epoch:0 step:161 [D loss: 1.008220, acc.: 78.12%] [G loss: 7.014081]\n",
      "epoch:0 step:162 [D loss: 0.475037, acc.: 81.25%] [G loss: 7.933883]\n",
      "epoch:0 step:163 [D loss: 0.339912, acc.: 86.72%] [G loss: 7.009145]\n",
      "epoch:0 step:164 [D loss: 0.473125, acc.: 82.03%] [G loss: 2.639974]\n",
      "epoch:0 step:165 [D loss: 0.501638, acc.: 71.09%] [G loss: 8.149817]\n",
      "epoch:0 step:166 [D loss: 0.277709, acc.: 90.62%] [G loss: 9.508980]\n",
      "epoch:0 step:167 [D loss: 0.672816, acc.: 73.44%] [G loss: 5.927770]\n",
      "epoch:0 step:168 [D loss: 0.239856, acc.: 92.19%] [G loss: 4.067236]\n",
      "epoch:0 step:169 [D loss: 0.331081, acc.: 85.16%] [G loss: 8.284223]\n",
      "epoch:0 step:170 [D loss: 0.357975, acc.: 91.41%] [G loss: 4.397085]\n",
      "epoch:0 step:171 [D loss: 0.250654, acc.: 90.62%] [G loss: 6.517790]\n",
      "epoch:0 step:172 [D loss: 0.240231, acc.: 89.06%] [G loss: 4.477332]\n",
      "epoch:0 step:173 [D loss: 0.141655, acc.: 96.09%] [G loss: 5.530490]\n",
      "epoch:0 step:174 [D loss: 0.193698, acc.: 92.97%] [G loss: 4.096397]\n",
      "epoch:0 step:175 [D loss: 0.143041, acc.: 94.53%] [G loss: 2.648271]\n",
      "epoch:0 step:176 [D loss: 0.129769, acc.: 95.31%] [G loss: 5.891462]\n",
      "epoch:0 step:177 [D loss: 0.206122, acc.: 92.97%] [G loss: 7.552938]\n",
      "epoch:0 step:178 [D loss: 0.725345, acc.: 68.75%] [G loss: 5.098812]\n",
      "epoch:0 step:179 [D loss: 0.190774, acc.: 93.75%] [G loss: 6.768548]\n",
      "epoch:0 step:180 [D loss: 0.461102, acc.: 92.19%] [G loss: 3.843946]\n",
      "epoch:0 step:181 [D loss: 0.484206, acc.: 77.34%] [G loss: 4.849546]\n",
      "epoch:0 step:182 [D loss: 0.455726, acc.: 77.34%] [G loss: 8.103730]\n",
      "epoch:0 step:183 [D loss: 1.492477, acc.: 42.97%] [G loss: 5.838155]\n",
      "epoch:0 step:184 [D loss: 0.215558, acc.: 91.41%] [G loss: 8.606489]\n",
      "epoch:0 step:185 [D loss: 1.293185, acc.: 54.69%] [G loss: 6.800703]\n",
      "epoch:0 step:186 [D loss: 0.504787, acc.: 82.81%] [G loss: 7.212742]\n",
      "epoch:0 step:187 [D loss: 0.632084, acc.: 82.81%] [G loss: 6.242543]\n",
      "epoch:0 step:188 [D loss: 0.212349, acc.: 92.19%] [G loss: 6.071693]\n",
      "epoch:0 step:189 [D loss: 1.388380, acc.: 53.91%] [G loss: 8.985378]\n",
      "epoch:0 step:190 [D loss: 1.162238, acc.: 71.88%] [G loss: 6.429085]\n",
      "epoch:0 step:191 [D loss: 0.879549, acc.: 57.03%] [G loss: 6.052854]\n",
      "epoch:0 step:192 [D loss: 0.464267, acc.: 78.12%] [G loss: 6.025440]\n",
      "epoch:0 step:193 [D loss: 0.787823, acc.: 64.06%] [G loss: 5.387962]\n",
      "epoch:0 step:194 [D loss: 1.419933, acc.: 51.56%] [G loss: 7.342843]\n",
      "epoch:0 step:195 [D loss: 1.020161, acc.: 67.19%] [G loss: 3.127057]\n",
      "epoch:0 step:196 [D loss: 0.276350, acc.: 84.38%] [G loss: 5.822417]\n",
      "epoch:0 step:197 [D loss: 0.418098, acc.: 84.38%] [G loss: 4.895874]\n",
      "epoch:0 step:198 [D loss: 0.943786, acc.: 50.00%] [G loss: 4.306278]\n",
      "epoch:0 step:199 [D loss: 0.778445, acc.: 71.88%] [G loss: 7.037634]\n",
      "epoch:0 step:200 [D loss: 1.020479, acc.: 55.47%] [G loss: 4.215339]\n",
      "WARNING:tensorflow:From /home/imi432_006/anaconda3/envs/tf/lib/python3.5/site-packages/tensorflow/contrib/gan/python/eval/python/classifier_metrics_impl.py:185: FastGFile.__init__ (from tensorflow.python.platform.gfile) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.gfile.GFile.\n",
      "##############\n",
      "[3.74514587 1.85254738 7.3264011  7.01648812 5.48599419 8.47025877\n",
      " 6.14448308 5.94482724 6.23106817 5.5014265 ]\n",
      "##########\n",
      "epoch:0 step:201 [D loss: 0.357054, acc.: 82.03%] [G loss: 4.326150]\n",
      "epoch:0 step:202 [D loss: 0.415383, acc.: 86.72%] [G loss: 3.454264]\n",
      "epoch:0 step:203 [D loss: 0.552773, acc.: 74.22%] [G loss: 2.670089]\n",
      "epoch:0 step:204 [D loss: 0.749988, acc.: 75.00%] [G loss: 4.813891]\n",
      "epoch:0 step:205 [D loss: 0.325209, acc.: 84.38%] [G loss: 3.938572]\n",
      "epoch:0 step:206 [D loss: 0.558040, acc.: 70.31%] [G loss: 4.042249]\n",
      "epoch:0 step:207 [D loss: 0.448431, acc.: 78.12%] [G loss: 6.637620]\n",
      "epoch:0 step:208 [D loss: 1.065717, acc.: 50.78%] [G loss: 5.664579]\n",
      "epoch:0 step:209 [D loss: 0.505359, acc.: 78.91%] [G loss: 6.881989]\n",
      "epoch:0 step:210 [D loss: 1.298167, acc.: 46.09%] [G loss: 4.615559]\n",
      "epoch:0 step:211 [D loss: 0.574677, acc.: 71.88%] [G loss: 7.268757]\n",
      "epoch:0 step:212 [D loss: 0.874320, acc.: 62.50%] [G loss: 3.889555]\n",
      "epoch:0 step:213 [D loss: 0.302307, acc.: 89.06%] [G loss: 4.934225]\n",
      "epoch:0 step:214 [D loss: 1.849775, acc.: 32.81%] [G loss: 4.053160]\n",
      "epoch:0 step:215 [D loss: 1.117208, acc.: 55.47%] [G loss: 4.416569]\n",
      "epoch:0 step:216 [D loss: 0.853384, acc.: 60.94%] [G loss: 4.711310]\n",
      "epoch:0 step:217 [D loss: 1.032723, acc.: 41.41%] [G loss: 4.344986]\n",
      "epoch:0 step:218 [D loss: 0.790270, acc.: 64.06%] [G loss: 5.197704]\n",
      "epoch:0 step:219 [D loss: 0.888823, acc.: 70.31%] [G loss: 2.420729]\n",
      "epoch:0 step:220 [D loss: 0.814058, acc.: 61.72%] [G loss: 3.540881]\n",
      "epoch:0 step:221 [D loss: 0.569446, acc.: 71.09%] [G loss: 4.007652]\n",
      "epoch:0 step:222 [D loss: 0.406745, acc.: 80.47%] [G loss: 4.264786]\n",
      "epoch:0 step:223 [D loss: 0.654727, acc.: 74.22%] [G loss: 4.479721]\n",
      "epoch:0 step:224 [D loss: 0.993862, acc.: 48.44%] [G loss: 3.449256]\n",
      "epoch:0 step:225 [D loss: 1.266263, acc.: 49.22%] [G loss: 3.359758]\n",
      "epoch:0 step:226 [D loss: 0.566269, acc.: 77.34%] [G loss: 5.079808]\n",
      "epoch:0 step:227 [D loss: 0.539949, acc.: 81.25%] [G loss: 3.151908]\n",
      "epoch:0 step:228 [D loss: 1.257075, acc.: 52.34%] [G loss: 3.964360]\n",
      "epoch:0 step:229 [D loss: 0.729054, acc.: 64.06%] [G loss: 4.343004]\n",
      "epoch:0 step:230 [D loss: 0.946616, acc.: 56.25%] [G loss: 3.881261]\n",
      "epoch:0 step:231 [D loss: 0.558356, acc.: 76.56%] [G loss: 4.551118]\n",
      "epoch:0 step:232 [D loss: 0.710528, acc.: 67.19%] [G loss: 4.509005]\n",
      "epoch:0 step:233 [D loss: 0.834700, acc.: 59.38%] [G loss: 3.876802]\n",
      "epoch:0 step:234 [D loss: 0.853404, acc.: 47.66%] [G loss: 4.483017]\n",
      "epoch:0 step:235 [D loss: 0.463965, acc.: 78.91%] [G loss: 5.508379]\n",
      "epoch:0 step:236 [D loss: 0.288734, acc.: 85.94%] [G loss: 5.041487]\n",
      "epoch:0 step:237 [D loss: 1.142636, acc.: 47.66%] [G loss: 3.485350]\n",
      "epoch:0 step:238 [D loss: 0.682046, acc.: 67.97%] [G loss: 3.832904]\n",
      "epoch:0 step:239 [D loss: 0.716171, acc.: 70.31%] [G loss: 3.514419]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0 step:240 [D loss: 0.429955, acc.: 79.69%] [G loss: 3.409714]\n",
      "epoch:0 step:241 [D loss: 0.421945, acc.: 79.69%] [G loss: 2.891476]\n",
      "epoch:0 step:242 [D loss: 0.577482, acc.: 72.66%] [G loss: 3.873686]\n",
      "epoch:0 step:243 [D loss: 0.402730, acc.: 83.59%] [G loss: 3.922699]\n",
      "epoch:0 step:244 [D loss: 0.528555, acc.: 74.22%] [G loss: 4.059600]\n",
      "epoch:0 step:245 [D loss: 0.494007, acc.: 75.00%] [G loss: 4.524537]\n",
      "epoch:0 step:246 [D loss: 1.233727, acc.: 32.81%] [G loss: 3.281564]\n",
      "epoch:0 step:247 [D loss: 0.579138, acc.: 65.62%] [G loss: 3.093507]\n",
      "epoch:0 step:248 [D loss: 0.910932, acc.: 60.16%] [G loss: 2.869086]\n",
      "epoch:0 step:249 [D loss: 0.531977, acc.: 75.78%] [G loss: 3.523473]\n",
      "epoch:0 step:250 [D loss: 0.814440, acc.: 60.16%] [G loss: 3.254769]\n",
      "epoch:0 step:251 [D loss: 0.469815, acc.: 76.56%] [G loss: 2.447425]\n",
      "epoch:0 step:252 [D loss: 0.523595, acc.: 70.31%] [G loss: 3.909210]\n",
      "epoch:0 step:253 [D loss: 0.305356, acc.: 89.84%] [G loss: 3.656775]\n",
      "epoch:0 step:254 [D loss: 0.401433, acc.: 79.69%] [G loss: 2.984911]\n",
      "epoch:0 step:255 [D loss: 0.774004, acc.: 64.84%] [G loss: 3.824015]\n",
      "epoch:0 step:256 [D loss: 0.625413, acc.: 71.09%] [G loss: 3.667001]\n",
      "epoch:0 step:257 [D loss: 0.570259, acc.: 69.53%] [G loss: 3.619757]\n",
      "epoch:0 step:258 [D loss: 0.316427, acc.: 88.28%] [G loss: 4.547668]\n",
      "epoch:0 step:259 [D loss: 0.251187, acc.: 90.62%] [G loss: 4.042233]\n",
      "epoch:0 step:260 [D loss: 0.410096, acc.: 76.56%] [G loss: 3.899599]\n",
      "epoch:0 step:261 [D loss: 1.237089, acc.: 46.88%] [G loss: 4.714503]\n",
      "epoch:0 step:262 [D loss: 1.087959, acc.: 47.66%] [G loss: 3.303140]\n",
      "epoch:0 step:263 [D loss: 1.371256, acc.: 35.94%] [G loss: 3.253081]\n",
      "epoch:0 step:264 [D loss: 0.565305, acc.: 73.44%] [G loss: 4.411582]\n",
      "epoch:0 step:265 [D loss: 0.933077, acc.: 58.59%] [G loss: 3.979322]\n",
      "epoch:0 step:266 [D loss: 0.531324, acc.: 73.44%] [G loss: 3.353814]\n",
      "epoch:0 step:267 [D loss: 1.133388, acc.: 60.16%] [G loss: 2.728776]\n",
      "epoch:0 step:268 [D loss: 0.430798, acc.: 76.56%] [G loss: 4.093347]\n",
      "epoch:0 step:269 [D loss: 0.374074, acc.: 85.16%] [G loss: 3.755266]\n",
      "epoch:0 step:270 [D loss: 0.439775, acc.: 77.34%] [G loss: 2.805671]\n",
      "epoch:0 step:271 [D loss: 0.756574, acc.: 66.41%] [G loss: 3.832728]\n",
      "epoch:0 step:272 [D loss: 1.509608, acc.: 42.97%] [G loss: 3.239892]\n",
      "epoch:0 step:273 [D loss: 0.719935, acc.: 71.09%] [G loss: 3.009703]\n",
      "epoch:0 step:274 [D loss: 0.886331, acc.: 57.81%] [G loss: 3.275040]\n",
      "epoch:0 step:275 [D loss: 0.963766, acc.: 49.22%] [G loss: 2.930229]\n",
      "epoch:0 step:276 [D loss: 0.620464, acc.: 78.12%] [G loss: 3.381856]\n",
      "epoch:0 step:277 [D loss: 0.839181, acc.: 61.72%] [G loss: 3.054335]\n",
      "epoch:0 step:278 [D loss: 0.569999, acc.: 75.00%] [G loss: 2.955452]\n",
      "epoch:0 step:279 [D loss: 0.744534, acc.: 63.28%] [G loss: 3.471516]\n",
      "epoch:0 step:280 [D loss: 0.468176, acc.: 75.78%] [G loss: 3.530921]\n",
      "epoch:0 step:281 [D loss: 0.357986, acc.: 83.59%] [G loss: 2.886771]\n",
      "epoch:0 step:282 [D loss: 0.644370, acc.: 67.97%] [G loss: 2.076768]\n",
      "epoch:0 step:283 [D loss: 0.417403, acc.: 83.59%] [G loss: 2.444879]\n",
      "epoch:0 step:284 [D loss: 0.235000, acc.: 94.53%] [G loss: 2.064909]\n",
      "epoch:0 step:285 [D loss: 0.531338, acc.: 78.91%] [G loss: 2.357339]\n",
      "epoch:0 step:286 [D loss: 0.572613, acc.: 72.66%] [G loss: 3.245991]\n",
      "epoch:0 step:287 [D loss: 0.640169, acc.: 67.97%] [G loss: 3.519341]\n",
      "epoch:0 step:288 [D loss: 0.673574, acc.: 64.84%] [G loss: 2.143706]\n",
      "epoch:0 step:289 [D loss: 0.680336, acc.: 60.94%] [G loss: 2.934024]\n",
      "epoch:0 step:290 [D loss: 0.652401, acc.: 65.62%] [G loss: 3.533511]\n",
      "epoch:0 step:291 [D loss: 0.803826, acc.: 60.16%] [G loss: 2.992638]\n",
      "epoch:0 step:292 [D loss: 0.710518, acc.: 58.59%] [G loss: 2.624409]\n",
      "epoch:0 step:293 [D loss: 0.429879, acc.: 82.81%] [G loss: 4.069898]\n",
      "epoch:0 step:294 [D loss: 0.524212, acc.: 75.00%] [G loss: 2.535419]\n",
      "epoch:0 step:295 [D loss: 0.548844, acc.: 75.78%] [G loss: 2.650972]\n",
      "epoch:0 step:296 [D loss: 0.410310, acc.: 80.47%] [G loss: 2.951638]\n",
      "epoch:0 step:297 [D loss: 0.905197, acc.: 49.22%] [G loss: 3.216401]\n",
      "epoch:0 step:298 [D loss: 0.966161, acc.: 50.78%] [G loss: 3.041363]\n",
      "epoch:0 step:299 [D loss: 0.767247, acc.: 58.59%] [G loss: 2.640887]\n",
      "epoch:0 step:300 [D loss: 0.505286, acc.: 77.34%] [G loss: 2.169546]\n",
      "epoch:0 step:301 [D loss: 0.678943, acc.: 62.50%] [G loss: 3.528016]\n",
      "epoch:0 step:302 [D loss: 0.449960, acc.: 78.12%] [G loss: 3.416261]\n",
      "epoch:0 step:303 [D loss: 0.664376, acc.: 62.50%] [G loss: 3.194065]\n",
      "epoch:0 step:304 [D loss: 0.752427, acc.: 60.16%] [G loss: 2.866181]\n",
      "epoch:0 step:305 [D loss: 0.859729, acc.: 59.38%] [G loss: 2.346618]\n",
      "epoch:0 step:306 [D loss: 0.830344, acc.: 49.22%] [G loss: 3.067099]\n",
      "epoch:0 step:307 [D loss: 0.510481, acc.: 79.69%] [G loss: 3.140886]\n",
      "epoch:0 step:308 [D loss: 1.016931, acc.: 52.34%] [G loss: 2.032020]\n",
      "epoch:0 step:309 [D loss: 0.669369, acc.: 69.53%] [G loss: 3.264021]\n",
      "epoch:0 step:310 [D loss: 0.660893, acc.: 69.53%] [G loss: 3.643500]\n",
      "epoch:0 step:311 [D loss: 0.739685, acc.: 64.84%] [G loss: 3.003891]\n",
      "epoch:0 step:312 [D loss: 0.644095, acc.: 64.06%] [G loss: 2.775798]\n",
      "epoch:0 step:313 [D loss: 0.647691, acc.: 68.75%] [G loss: 2.123279]\n",
      "epoch:0 step:314 [D loss: 0.469864, acc.: 75.78%] [G loss: 2.860170]\n",
      "epoch:0 step:315 [D loss: 0.729325, acc.: 63.28%] [G loss: 2.849160]\n",
      "epoch:0 step:316 [D loss: 1.194779, acc.: 35.16%] [G loss: 2.747283]\n",
      "epoch:0 step:317 [D loss: 0.767478, acc.: 53.91%] [G loss: 2.696806]\n",
      "epoch:0 step:318 [D loss: 0.596024, acc.: 68.75%] [G loss: 2.361846]\n",
      "epoch:0 step:319 [D loss: 0.527758, acc.: 72.66%] [G loss: 3.049059]\n",
      "epoch:0 step:320 [D loss: 0.462769, acc.: 80.47%] [G loss: 2.614918]\n",
      "epoch:0 step:321 [D loss: 0.651586, acc.: 69.53%] [G loss: 2.517945]\n",
      "epoch:0 step:322 [D loss: 0.771169, acc.: 59.38%] [G loss: 3.001974]\n",
      "epoch:0 step:323 [D loss: 0.685579, acc.: 62.50%] [G loss: 3.389704]\n",
      "epoch:0 step:324 [D loss: 0.676482, acc.: 68.75%] [G loss: 2.883542]\n",
      "epoch:0 step:325 [D loss: 0.632361, acc.: 64.84%] [G loss: 2.112299]\n",
      "epoch:0 step:326 [D loss: 0.673088, acc.: 60.94%] [G loss: 3.372746]\n",
      "epoch:0 step:327 [D loss: 0.610046, acc.: 67.19%] [G loss: 3.458909]\n",
      "epoch:0 step:328 [D loss: 0.495244, acc.: 76.56%] [G loss: 2.058615]\n",
      "epoch:0 step:329 [D loss: 0.812482, acc.: 57.03%] [G loss: 2.160689]\n",
      "epoch:0 step:330 [D loss: 0.799766, acc.: 58.59%] [G loss: 3.049398]\n",
      "epoch:0 step:331 [D loss: 0.666174, acc.: 67.97%] [G loss: 2.431019]\n",
      "epoch:0 step:332 [D loss: 0.648665, acc.: 69.53%] [G loss: 2.978636]\n",
      "epoch:0 step:333 [D loss: 0.499429, acc.: 78.91%] [G loss: 2.537559]\n",
      "epoch:0 step:334 [D loss: 0.566922, acc.: 71.88%] [G loss: 2.001407]\n",
      "epoch:0 step:335 [D loss: 0.667813, acc.: 63.28%] [G loss: 2.353496]\n",
      "epoch:0 step:336 [D loss: 0.583178, acc.: 68.75%] [G loss: 2.514794]\n",
      "epoch:0 step:337 [D loss: 0.685374, acc.: 67.97%] [G loss: 2.859537]\n",
      "epoch:0 step:338 [D loss: 0.547964, acc.: 72.66%] [G loss: 2.639297]\n",
      "epoch:0 step:339 [D loss: 0.735923, acc.: 64.84%] [G loss: 1.910697]\n",
      "epoch:0 step:340 [D loss: 1.039633, acc.: 53.91%] [G loss: 2.172921]\n",
      "epoch:0 step:341 [D loss: 0.562111, acc.: 72.66%] [G loss: 2.661380]\n",
      "epoch:0 step:342 [D loss: 0.621716, acc.: 64.06%] [G loss: 2.124882]\n",
      "epoch:0 step:343 [D loss: 0.717414, acc.: 58.59%] [G loss: 2.716528]\n",
      "epoch:0 step:344 [D loss: 0.754754, acc.: 57.81%] [G loss: 2.779517]\n",
      "epoch:0 step:345 [D loss: 0.699225, acc.: 63.28%] [G loss: 1.812614]\n",
      "epoch:0 step:346 [D loss: 0.736084, acc.: 64.84%] [G loss: 2.192811]\n",
      "epoch:0 step:347 [D loss: 0.610122, acc.: 66.41%] [G loss: 2.206787]\n",
      "epoch:0 step:348 [D loss: 0.612986, acc.: 64.84%] [G loss: 2.281055]\n",
      "epoch:0 step:349 [D loss: 0.801066, acc.: 53.91%] [G loss: 2.044778]\n",
      "epoch:0 step:350 [D loss: 0.700978, acc.: 67.19%] [G loss: 3.168658]\n",
      "epoch:0 step:351 [D loss: 0.596275, acc.: 71.09%] [G loss: 3.224907]\n",
      "epoch:0 step:352 [D loss: 0.782570, acc.: 53.12%] [G loss: 2.283108]\n",
      "epoch:0 step:353 [D loss: 0.579136, acc.: 71.88%] [G loss: 2.065138]\n",
      "epoch:0 step:354 [D loss: 0.652633, acc.: 74.22%] [G loss: 2.452250]\n",
      "epoch:0 step:355 [D loss: 0.677835, acc.: 70.31%] [G loss: 2.100807]\n",
      "epoch:0 step:356 [D loss: 0.580059, acc.: 74.22%] [G loss: 2.521918]\n",
      "epoch:0 step:357 [D loss: 0.807665, acc.: 55.47%] [G loss: 2.440124]\n",
      "epoch:0 step:358 [D loss: 0.616370, acc.: 70.31%] [G loss: 2.706209]\n",
      "epoch:0 step:359 [D loss: 0.510441, acc.: 77.34%] [G loss: 2.661758]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0 step:360 [D loss: 0.581041, acc.: 74.22%] [G loss: 2.040545]\n",
      "epoch:0 step:361 [D loss: 0.615525, acc.: 66.41%] [G loss: 2.110670]\n",
      "epoch:0 step:362 [D loss: 0.722844, acc.: 60.94%] [G loss: 2.308406]\n",
      "epoch:0 step:363 [D loss: 0.607670, acc.: 69.53%] [G loss: 1.976986]\n",
      "epoch:0 step:364 [D loss: 0.621980, acc.: 69.53%] [G loss: 2.192030]\n",
      "epoch:0 step:365 [D loss: 0.716356, acc.: 59.38%] [G loss: 1.971603]\n",
      "epoch:0 step:366 [D loss: 0.583665, acc.: 63.28%] [G loss: 2.542234]\n",
      "epoch:0 step:367 [D loss: 0.576557, acc.: 66.41%] [G loss: 2.249078]\n",
      "epoch:0 step:368 [D loss: 0.641104, acc.: 66.41%] [G loss: 2.451993]\n",
      "epoch:0 step:369 [D loss: 0.838630, acc.: 53.91%] [G loss: 2.025692]\n",
      "epoch:0 step:370 [D loss: 0.887565, acc.: 57.81%] [G loss: 1.786894]\n",
      "epoch:0 step:371 [D loss: 0.706221, acc.: 60.94%] [G loss: 2.188773]\n",
      "epoch:0 step:372 [D loss: 0.722085, acc.: 60.94%] [G loss: 2.483553]\n",
      "epoch:0 step:373 [D loss: 0.658515, acc.: 67.19%] [G loss: 2.618039]\n",
      "epoch:0 step:374 [D loss: 0.458783, acc.: 80.47%] [G loss: 1.969555]\n",
      "epoch:0 step:375 [D loss: 0.653587, acc.: 64.06%] [G loss: 2.074618]\n",
      "epoch:0 step:376 [D loss: 0.798059, acc.: 59.38%] [G loss: 2.097286]\n",
      "epoch:0 step:377 [D loss: 0.679687, acc.: 60.94%] [G loss: 2.498494]\n",
      "epoch:0 step:378 [D loss: 0.400583, acc.: 82.81%] [G loss: 2.469325]\n",
      "epoch:0 step:379 [D loss: 0.750971, acc.: 60.94%] [G loss: 1.995663]\n",
      "epoch:0 step:380 [D loss: 0.800255, acc.: 56.25%] [G loss: 1.776074]\n",
      "epoch:0 step:381 [D loss: 0.551181, acc.: 76.56%] [G loss: 2.098022]\n",
      "epoch:0 step:382 [D loss: 0.717773, acc.: 68.75%] [G loss: 1.951878]\n",
      "epoch:0 step:383 [D loss: 0.832518, acc.: 58.59%] [G loss: 1.992712]\n",
      "epoch:0 step:384 [D loss: 0.641389, acc.: 64.84%] [G loss: 2.296800]\n",
      "epoch:0 step:385 [D loss: 0.548057, acc.: 71.88%] [G loss: 2.457246]\n",
      "epoch:0 step:386 [D loss: 0.670197, acc.: 66.41%] [G loss: 2.244943]\n",
      "epoch:0 step:387 [D loss: 0.581987, acc.: 67.19%] [G loss: 2.027885]\n",
      "epoch:0 step:388 [D loss: 0.447396, acc.: 78.12%] [G loss: 2.132400]\n",
      "epoch:0 step:389 [D loss: 0.602868, acc.: 72.66%] [G loss: 2.068478]\n",
      "epoch:0 step:390 [D loss: 0.666638, acc.: 70.31%] [G loss: 2.617496]\n",
      "epoch:0 step:391 [D loss: 0.595025, acc.: 75.00%] [G loss: 2.585659]\n",
      "epoch:0 step:392 [D loss: 0.448928, acc.: 80.47%] [G loss: 2.302202]\n",
      "epoch:0 step:393 [D loss: 0.576145, acc.: 71.88%] [G loss: 1.902004]\n",
      "epoch:0 step:394 [D loss: 0.706840, acc.: 61.72%] [G loss: 2.750672]\n",
      "epoch:0 step:395 [D loss: 0.678294, acc.: 63.28%] [G loss: 2.211597]\n",
      "epoch:0 step:396 [D loss: 0.883620, acc.: 60.94%] [G loss: 2.159451]\n",
      "epoch:0 step:397 [D loss: 0.594837, acc.: 63.28%] [G loss: 2.354655]\n",
      "epoch:0 step:398 [D loss: 0.399273, acc.: 82.03%] [G loss: 2.634832]\n",
      "epoch:0 step:399 [D loss: 0.532700, acc.: 71.88%] [G loss: 2.047457]\n",
      "epoch:0 step:400 [D loss: 0.775134, acc.: 53.12%] [G loss: 2.031687]\n",
      "##############\n",
      "[6.38536565 1.42888684 6.8402591  6.20704601 4.80559701 5.87496308\n",
      " 4.60248292 4.96736557 4.76858837 3.76592632]\n",
      "##########\n",
      "epoch:0 step:401 [D loss: 0.790037, acc.: 54.69%] [G loss: 2.242867]\n",
      "epoch:0 step:402 [D loss: 0.550890, acc.: 70.31%] [G loss: 1.878537]\n",
      "epoch:0 step:403 [D loss: 0.719725, acc.: 58.59%] [G loss: 2.002220]\n",
      "epoch:0 step:404 [D loss: 0.917482, acc.: 52.34%] [G loss: 2.011932]\n",
      "epoch:0 step:405 [D loss: 0.652591, acc.: 64.84%] [G loss: 1.673026]\n",
      "epoch:0 step:406 [D loss: 0.647953, acc.: 61.72%] [G loss: 2.428137]\n",
      "epoch:0 step:407 [D loss: 0.862942, acc.: 54.69%] [G loss: 1.736796]\n",
      "epoch:0 step:408 [D loss: 0.560736, acc.: 71.88%] [G loss: 2.110643]\n",
      "epoch:0 step:409 [D loss: 0.658504, acc.: 64.06%] [G loss: 2.193110]\n",
      "epoch:0 step:410 [D loss: 0.801778, acc.: 58.59%] [G loss: 3.097225]\n",
      "epoch:0 step:411 [D loss: 0.732670, acc.: 60.94%] [G loss: 2.116528]\n",
      "epoch:0 step:412 [D loss: 0.745120, acc.: 64.06%] [G loss: 2.046898]\n",
      "epoch:0 step:413 [D loss: 0.770128, acc.: 54.69%] [G loss: 2.320009]\n",
      "epoch:0 step:414 [D loss: 0.789841, acc.: 58.59%] [G loss: 1.770736]\n",
      "epoch:0 step:415 [D loss: 0.707355, acc.: 61.72%] [G loss: 1.714923]\n",
      "epoch:0 step:416 [D loss: 0.732883, acc.: 60.94%] [G loss: 2.094306]\n",
      "epoch:0 step:417 [D loss: 0.690504, acc.: 65.62%] [G loss: 1.743579]\n",
      "epoch:0 step:418 [D loss: 0.879624, acc.: 44.53%] [G loss: 1.351573]\n",
      "epoch:0 step:419 [D loss: 0.549768, acc.: 69.53%] [G loss: 2.120463]\n",
      "epoch:0 step:420 [D loss: 0.741381, acc.: 64.06%] [G loss: 1.836341]\n",
      "epoch:0 step:421 [D loss: 0.783263, acc.: 55.47%] [G loss: 2.046671]\n",
      "epoch:0 step:422 [D loss: 0.677250, acc.: 61.72%] [G loss: 1.701378]\n",
      "epoch:0 step:423 [D loss: 0.689796, acc.: 53.12%] [G loss: 2.097929]\n",
      "epoch:0 step:424 [D loss: 0.737997, acc.: 59.38%] [G loss: 1.902694]\n",
      "epoch:0 step:425 [D loss: 0.752649, acc.: 59.38%] [G loss: 1.942561]\n",
      "epoch:0 step:426 [D loss: 0.554625, acc.: 69.53%] [G loss: 2.183240]\n",
      "epoch:0 step:427 [D loss: 0.573653, acc.: 76.56%] [G loss: 2.322369]\n",
      "epoch:0 step:428 [D loss: 0.524899, acc.: 75.00%] [G loss: 2.190491]\n",
      "epoch:0 step:429 [D loss: 0.624801, acc.: 67.19%] [G loss: 2.330839]\n",
      "epoch:0 step:430 [D loss: 0.445028, acc.: 81.25%] [G loss: 2.377351]\n",
      "epoch:0 step:431 [D loss: 0.658756, acc.: 61.72%] [G loss: 1.919989]\n",
      "epoch:0 step:432 [D loss: 0.651548, acc.: 65.62%] [G loss: 2.139153]\n",
      "epoch:0 step:433 [D loss: 0.571561, acc.: 70.31%] [G loss: 2.057301]\n",
      "epoch:0 step:434 [D loss: 0.775775, acc.: 57.81%] [G loss: 1.884049]\n",
      "epoch:0 step:435 [D loss: 0.551061, acc.: 70.31%] [G loss: 2.030930]\n",
      "epoch:0 step:436 [D loss: 0.626315, acc.: 64.06%] [G loss: 1.884402]\n",
      "epoch:0 step:437 [D loss: 0.644198, acc.: 67.97%] [G loss: 1.733494]\n",
      "epoch:0 step:438 [D loss: 0.493149, acc.: 74.22%] [G loss: 1.561898]\n",
      "epoch:0 step:439 [D loss: 0.524476, acc.: 66.41%] [G loss: 2.067718]\n",
      "epoch:0 step:440 [D loss: 0.422346, acc.: 76.56%] [G loss: 1.776819]\n",
      "epoch:0 step:441 [D loss: 0.833038, acc.: 50.00%] [G loss: 2.585630]\n",
      "epoch:0 step:442 [D loss: 0.695494, acc.: 56.25%] [G loss: 1.921199]\n",
      "epoch:0 step:443 [D loss: 0.594984, acc.: 66.41%] [G loss: 1.968755]\n",
      "epoch:0 step:444 [D loss: 0.744029, acc.: 56.25%] [G loss: 1.527429]\n",
      "epoch:0 step:445 [D loss: 0.478329, acc.: 76.56%] [G loss: 1.880537]\n",
      "epoch:0 step:446 [D loss: 0.401888, acc.: 82.81%] [G loss: 2.151772]\n",
      "epoch:0 step:447 [D loss: 0.607061, acc.: 65.62%] [G loss: 1.705142]\n",
      "epoch:0 step:448 [D loss: 0.946577, acc.: 49.22%] [G loss: 1.760033]\n",
      "epoch:0 step:449 [D loss: 0.796975, acc.: 55.47%] [G loss: 1.946328]\n",
      "epoch:0 step:450 [D loss: 0.645698, acc.: 68.75%] [G loss: 2.138237]\n",
      "epoch:0 step:451 [D loss: 0.729411, acc.: 58.59%] [G loss: 2.137402]\n",
      "epoch:0 step:452 [D loss: 0.724339, acc.: 59.38%] [G loss: 1.776541]\n",
      "epoch:0 step:453 [D loss: 0.853731, acc.: 50.00%] [G loss: 1.472129]\n",
      "epoch:0 step:454 [D loss: 0.798919, acc.: 51.56%] [G loss: 1.981037]\n",
      "epoch:0 step:455 [D loss: 0.675842, acc.: 61.72%] [G loss: 2.050491]\n",
      "epoch:0 step:456 [D loss: 0.883960, acc.: 45.31%] [G loss: 1.641398]\n",
      "epoch:0 step:457 [D loss: 0.716824, acc.: 61.72%] [G loss: 1.834447]\n",
      "epoch:0 step:458 [D loss: 0.806523, acc.: 54.69%] [G loss: 1.670425]\n",
      "epoch:0 step:459 [D loss: 0.659475, acc.: 67.19%] [G loss: 1.625571]\n",
      "epoch:0 step:460 [D loss: 0.520321, acc.: 73.44%] [G loss: 2.014388]\n",
      "epoch:0 step:461 [D loss: 0.567495, acc.: 73.44%] [G loss: 2.376256]\n",
      "epoch:0 step:462 [D loss: 0.641255, acc.: 56.25%] [G loss: 2.160596]\n",
      "epoch:0 step:463 [D loss: 0.783742, acc.: 57.81%] [G loss: 1.775770]\n",
      "epoch:0 step:464 [D loss: 0.666334, acc.: 58.59%] [G loss: 2.073586]\n",
      "epoch:0 step:465 [D loss: 0.951038, acc.: 50.78%] [G loss: 1.535569]\n",
      "epoch:0 step:466 [D loss: 0.700861, acc.: 60.94%] [G loss: 1.489938]\n",
      "epoch:0 step:467 [D loss: 0.673936, acc.: 57.81%] [G loss: 1.687280]\n",
      "epoch:0 step:468 [D loss: 0.576972, acc.: 71.88%] [G loss: 1.859610]\n",
      "epoch:0 step:469 [D loss: 0.688683, acc.: 60.94%] [G loss: 2.086780]\n",
      "epoch:0 step:470 [D loss: 0.698340, acc.: 60.16%] [G loss: 1.668071]\n",
      "epoch:0 step:471 [D loss: 0.655504, acc.: 58.59%] [G loss: 1.903627]\n",
      "epoch:0 step:472 [D loss: 0.733056, acc.: 57.81%] [G loss: 1.839643]\n",
      "epoch:0 step:473 [D loss: 0.720964, acc.: 58.59%] [G loss: 1.818177]\n",
      "epoch:0 step:474 [D loss: 0.716478, acc.: 60.16%] [G loss: 1.632894]\n",
      "epoch:0 step:475 [D loss: 0.640039, acc.: 66.41%] [G loss: 2.077213]\n",
      "epoch:0 step:476 [D loss: 0.618120, acc.: 66.41%] [G loss: 2.123944]\n",
      "epoch:0 step:477 [D loss: 0.747560, acc.: 53.12%] [G loss: 1.755943]\n",
      "epoch:0 step:478 [D loss: 0.617748, acc.: 67.19%] [G loss: 1.792580]\n",
      "epoch:0 step:479 [D loss: 0.665152, acc.: 58.59%] [G loss: 1.906385]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0 step:480 [D loss: 0.541810, acc.: 75.00%] [G loss: 1.773588]\n",
      "epoch:0 step:481 [D loss: 0.647252, acc.: 65.62%] [G loss: 1.632704]\n",
      "epoch:0 step:482 [D loss: 0.604321, acc.: 67.97%] [G loss: 1.528144]\n",
      "epoch:0 step:483 [D loss: 0.776792, acc.: 57.03%] [G loss: 1.425275]\n",
      "epoch:0 step:484 [D loss: 0.703198, acc.: 65.62%] [G loss: 1.834843]\n",
      "epoch:0 step:485 [D loss: 0.817426, acc.: 54.69%] [G loss: 1.874713]\n",
      "epoch:0 step:486 [D loss: 0.754897, acc.: 56.25%] [G loss: 1.769946]\n",
      "epoch:0 step:487 [D loss: 0.797479, acc.: 55.47%] [G loss: 1.810030]\n",
      "epoch:0 step:488 [D loss: 0.672101, acc.: 58.59%] [G loss: 1.557111]\n",
      "epoch:0 step:489 [D loss: 0.760933, acc.: 53.91%] [G loss: 1.540993]\n",
      "epoch:0 step:490 [D loss: 0.785679, acc.: 57.03%] [G loss: 1.678810]\n",
      "epoch:0 step:491 [D loss: 0.647939, acc.: 62.50%] [G loss: 1.633146]\n",
      "epoch:0 step:492 [D loss: 0.853688, acc.: 50.78%] [G loss: 1.583418]\n",
      "epoch:0 step:493 [D loss: 0.620797, acc.: 67.97%] [G loss: 1.486467]\n",
      "epoch:0 step:494 [D loss: 0.743720, acc.: 57.03%] [G loss: 1.588584]\n",
      "epoch:0 step:495 [D loss: 0.565196, acc.: 71.88%] [G loss: 1.866648]\n",
      "epoch:0 step:496 [D loss: 0.678396, acc.: 57.81%] [G loss: 1.651369]\n",
      "epoch:0 step:497 [D loss: 0.718725, acc.: 57.03%] [G loss: 1.531060]\n",
      "epoch:0 step:498 [D loss: 0.752735, acc.: 55.47%] [G loss: 1.854970]\n",
      "epoch:0 step:499 [D loss: 0.536877, acc.: 70.31%] [G loss: 1.975255]\n",
      "epoch:0 step:500 [D loss: 0.612929, acc.: 67.97%] [G loss: 1.962637]\n",
      "epoch:0 step:501 [D loss: 0.739689, acc.: 54.69%] [G loss: 1.557998]\n",
      "epoch:0 step:502 [D loss: 0.583127, acc.: 69.53%] [G loss: 1.520656]\n",
      "epoch:0 step:503 [D loss: 0.621644, acc.: 64.06%] [G loss: 1.685036]\n",
      "epoch:0 step:504 [D loss: 0.554010, acc.: 72.66%] [G loss: 1.628166]\n",
      "epoch:0 step:505 [D loss: 0.589853, acc.: 67.19%] [G loss: 1.566750]\n",
      "epoch:0 step:506 [D loss: 0.694783, acc.: 58.59%] [G loss: 1.745396]\n",
      "epoch:0 step:507 [D loss: 0.705549, acc.: 59.38%] [G loss: 1.704815]\n",
      "epoch:0 step:508 [D loss: 0.566041, acc.: 71.88%] [G loss: 2.010894]\n",
      "epoch:0 step:509 [D loss: 0.771363, acc.: 64.84%] [G loss: 2.042686]\n",
      "epoch:0 step:510 [D loss: 0.748284, acc.: 58.59%] [G loss: 1.915233]\n",
      "epoch:0 step:511 [D loss: 0.657966, acc.: 64.06%] [G loss: 1.814793]\n",
      "epoch:0 step:512 [D loss: 0.586157, acc.: 69.53%] [G loss: 2.137465]\n",
      "epoch:0 step:513 [D loss: 0.551884, acc.: 71.09%] [G loss: 1.747986]\n",
      "epoch:0 step:514 [D loss: 0.663745, acc.: 63.28%] [G loss: 1.780624]\n",
      "epoch:0 step:515 [D loss: 0.555226, acc.: 67.19%] [G loss: 2.116117]\n",
      "epoch:0 step:516 [D loss: 0.611403, acc.: 71.09%] [G loss: 1.990112]\n",
      "epoch:0 step:517 [D loss: 0.909554, acc.: 49.22%] [G loss: 1.875783]\n",
      "epoch:0 step:518 [D loss: 0.614584, acc.: 63.28%] [G loss: 1.776698]\n",
      "epoch:0 step:519 [D loss: 0.457190, acc.: 77.34%] [G loss: 1.680964]\n",
      "epoch:0 step:520 [D loss: 0.497482, acc.: 74.22%] [G loss: 1.657049]\n",
      "epoch:0 step:521 [D loss: 0.665831, acc.: 61.72%] [G loss: 1.694940]\n",
      "epoch:0 step:522 [D loss: 0.595902, acc.: 67.19%] [G loss: 1.802574]\n",
      "epoch:0 step:523 [D loss: 0.689695, acc.: 64.06%] [G loss: 1.784060]\n",
      "epoch:0 step:524 [D loss: 0.832510, acc.: 48.44%] [G loss: 1.641902]\n",
      "epoch:0 step:525 [D loss: 0.787280, acc.: 53.91%] [G loss: 1.596814]\n",
      "epoch:0 step:526 [D loss: 0.619761, acc.: 71.09%] [G loss: 1.586327]\n",
      "epoch:0 step:527 [D loss: 0.761912, acc.: 56.25%] [G loss: 1.413893]\n",
      "epoch:0 step:528 [D loss: 1.065051, acc.: 37.50%] [G loss: 1.717006]\n",
      "epoch:0 step:529 [D loss: 0.726043, acc.: 56.25%] [G loss: 1.575108]\n",
      "epoch:0 step:530 [D loss: 0.682867, acc.: 60.16%] [G loss: 1.465856]\n",
      "epoch:0 step:531 [D loss: 0.731647, acc.: 62.50%] [G loss: 1.569687]\n",
      "epoch:0 step:532 [D loss: 0.660655, acc.: 63.28%] [G loss: 1.458174]\n",
      "epoch:0 step:533 [D loss: 0.587041, acc.: 65.62%] [G loss: 1.647859]\n",
      "epoch:0 step:534 [D loss: 0.557315, acc.: 71.09%] [G loss: 1.509139]\n",
      "epoch:0 step:535 [D loss: 0.849737, acc.: 47.66%] [G loss: 1.360510]\n",
      "epoch:0 step:536 [D loss: 0.740963, acc.: 60.94%] [G loss: 1.279352]\n",
      "epoch:0 step:537 [D loss: 0.694673, acc.: 62.50%] [G loss: 1.635901]\n",
      "epoch:0 step:538 [D loss: 0.652172, acc.: 64.06%] [G loss: 1.537961]\n",
      "epoch:0 step:539 [D loss: 0.686509, acc.: 62.50%] [G loss: 1.408448]\n",
      "epoch:0 step:540 [D loss: 0.690389, acc.: 61.72%] [G loss: 1.732267]\n",
      "epoch:0 step:541 [D loss: 0.714651, acc.: 60.94%] [G loss: 1.525512]\n",
      "epoch:0 step:542 [D loss: 0.886808, acc.: 51.56%] [G loss: 1.648861]\n",
      "epoch:0 step:543 [D loss: 0.683020, acc.: 55.47%] [G loss: 1.793568]\n",
      "epoch:0 step:544 [D loss: 0.727450, acc.: 62.50%] [G loss: 1.653111]\n",
      "epoch:0 step:545 [D loss: 0.901086, acc.: 49.22%] [G loss: 1.495093]\n",
      "epoch:0 step:546 [D loss: 0.737367, acc.: 48.44%] [G loss: 1.401588]\n",
      "epoch:0 step:547 [D loss: 0.776934, acc.: 50.78%] [G loss: 1.359604]\n",
      "epoch:0 step:548 [D loss: 0.587496, acc.: 66.41%] [G loss: 1.541429]\n",
      "epoch:0 step:549 [D loss: 0.691167, acc.: 53.91%] [G loss: 1.498512]\n",
      "epoch:0 step:550 [D loss: 0.784316, acc.: 53.91%] [G loss: 1.503460]\n",
      "epoch:0 step:551 [D loss: 0.611571, acc.: 67.19%] [G loss: 1.482062]\n",
      "epoch:0 step:552 [D loss: 0.660035, acc.: 64.06%] [G loss: 1.789588]\n",
      "epoch:0 step:553 [D loss: 0.844525, acc.: 45.31%] [G loss: 1.812748]\n",
      "epoch:0 step:554 [D loss: 0.530188, acc.: 73.44%] [G loss: 1.754581]\n",
      "epoch:0 step:555 [D loss: 0.667036, acc.: 62.50%] [G loss: 1.660658]\n",
      "epoch:0 step:556 [D loss: 0.766648, acc.: 52.34%] [G loss: 1.614949]\n",
      "epoch:0 step:557 [D loss: 0.647465, acc.: 64.84%] [G loss: 1.402280]\n",
      "epoch:0 step:558 [D loss: 0.540962, acc.: 73.44%] [G loss: 1.775818]\n",
      "epoch:0 step:559 [D loss: 0.911391, acc.: 40.62%] [G loss: 1.769847]\n",
      "epoch:0 step:560 [D loss: 0.796618, acc.: 57.03%] [G loss: 1.459796]\n",
      "epoch:0 step:561 [D loss: 0.601016, acc.: 73.44%] [G loss: 1.632403]\n",
      "epoch:0 step:562 [D loss: 0.791513, acc.: 57.03%] [G loss: 1.390342]\n",
      "epoch:0 step:563 [D loss: 0.627048, acc.: 62.50%] [G loss: 1.617805]\n",
      "epoch:0 step:564 [D loss: 0.548225, acc.: 69.53%] [G loss: 1.525273]\n",
      "epoch:0 step:565 [D loss: 0.783645, acc.: 57.81%] [G loss: 1.466003]\n",
      "epoch:0 step:566 [D loss: 0.897953, acc.: 48.44%] [G loss: 1.674504]\n",
      "epoch:0 step:567 [D loss: 0.617504, acc.: 71.09%] [G loss: 2.014589]\n",
      "epoch:0 step:568 [D loss: 0.543156, acc.: 78.91%] [G loss: 2.058562]\n",
      "epoch:0 step:569 [D loss: 0.851981, acc.: 55.47%] [G loss: 1.399208]\n",
      "epoch:0 step:570 [D loss: 0.610280, acc.: 64.84%] [G loss: 1.501404]\n",
      "epoch:0 step:571 [D loss: 0.651584, acc.: 59.38%] [G loss: 1.558623]\n",
      "epoch:0 step:572 [D loss: 0.555874, acc.: 68.75%] [G loss: 1.782651]\n",
      "epoch:0 step:573 [D loss: 0.569560, acc.: 69.53%] [G loss: 1.375324]\n",
      "epoch:0 step:574 [D loss: 0.680492, acc.: 61.72%] [G loss: 1.576787]\n",
      "epoch:0 step:575 [D loss: 0.732046, acc.: 50.00%] [G loss: 1.525478]\n",
      "epoch:0 step:576 [D loss: 0.856207, acc.: 48.44%] [G loss: 1.340509]\n",
      "epoch:0 step:577 [D loss: 0.708794, acc.: 57.03%] [G loss: 1.262706]\n",
      "epoch:0 step:578 [D loss: 0.682343, acc.: 62.50%] [G loss: 1.378908]\n",
      "epoch:0 step:579 [D loss: 0.687981, acc.: 61.72%] [G loss: 1.454921]\n",
      "epoch:0 step:580 [D loss: 0.813429, acc.: 57.03%] [G loss: 1.592564]\n",
      "epoch:0 step:581 [D loss: 0.700359, acc.: 61.72%] [G loss: 1.477083]\n",
      "epoch:0 step:582 [D loss: 0.757296, acc.: 56.25%] [G loss: 1.390121]\n",
      "epoch:0 step:583 [D loss: 0.736465, acc.: 61.72%] [G loss: 1.387734]\n",
      "epoch:0 step:584 [D loss: 0.728332, acc.: 61.72%] [G loss: 1.475696]\n",
      "epoch:0 step:585 [D loss: 0.685600, acc.: 64.06%] [G loss: 1.588225]\n",
      "epoch:0 step:586 [D loss: 0.727194, acc.: 58.59%] [G loss: 1.361269]\n",
      "epoch:0 step:587 [D loss: 0.746703, acc.: 53.91%] [G loss: 1.653526]\n",
      "epoch:0 step:588 [D loss: 0.696861, acc.: 61.72%] [G loss: 1.462542]\n",
      "epoch:0 step:589 [D loss: 0.636642, acc.: 64.06%] [G loss: 1.677698]\n",
      "epoch:0 step:590 [D loss: 0.846252, acc.: 53.12%] [G loss: 1.601028]\n",
      "epoch:0 step:591 [D loss: 0.801453, acc.: 52.34%] [G loss: 1.520026]\n",
      "epoch:0 step:592 [D loss: 0.537707, acc.: 71.88%] [G loss: 1.592535]\n",
      "epoch:0 step:593 [D loss: 0.608258, acc.: 67.97%] [G loss: 2.023979]\n",
      "epoch:0 step:594 [D loss: 0.608661, acc.: 71.88%] [G loss: 1.305662]\n",
      "epoch:0 step:595 [D loss: 0.642587, acc.: 66.41%] [G loss: 1.217975]\n",
      "epoch:0 step:596 [D loss: 0.622049, acc.: 66.41%] [G loss: 1.401433]\n",
      "epoch:0 step:597 [D loss: 0.662102, acc.: 62.50%] [G loss: 1.389066]\n",
      "epoch:0 step:598 [D loss: 0.732308, acc.: 59.38%] [G loss: 1.590551]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0 step:599 [D loss: 0.801734, acc.: 50.00%] [G loss: 1.261603]\n",
      "epoch:0 step:600 [D loss: 0.837538, acc.: 55.47%] [G loss: 1.515878]\n",
      "##############\n",
      "[5.15926645 1.68869507 6.19854816 5.2458144  4.04542868 5.69274371\n",
      " 4.92366956 4.78950244 5.37885462 4.37238796]\n",
      "##########\n",
      "epoch:0 step:601 [D loss: 0.668028, acc.: 58.59%] [G loss: 1.507271]\n",
      "epoch:0 step:602 [D loss: 0.623456, acc.: 68.75%] [G loss: 1.607873]\n",
      "epoch:0 step:603 [D loss: 0.686278, acc.: 63.28%] [G loss: 1.343200]\n",
      "epoch:0 step:604 [D loss: 0.816430, acc.: 46.88%] [G loss: 1.133778]\n",
      "epoch:0 step:605 [D loss: 0.736829, acc.: 59.38%] [G loss: 1.325847]\n",
      "epoch:0 step:606 [D loss: 0.821212, acc.: 50.78%] [G loss: 1.368871]\n",
      "epoch:0 step:607 [D loss: 0.776293, acc.: 51.56%] [G loss: 1.254415]\n",
      "epoch:0 step:608 [D loss: 0.633234, acc.: 66.41%] [G loss: 1.507257]\n",
      "epoch:0 step:609 [D loss: 0.655966, acc.: 64.06%] [G loss: 1.370252]\n",
      "epoch:0 step:610 [D loss: 0.697297, acc.: 58.59%] [G loss: 1.468453]\n",
      "epoch:0 step:611 [D loss: 0.659897, acc.: 66.41%] [G loss: 1.352423]\n",
      "epoch:0 step:612 [D loss: 0.584891, acc.: 68.75%] [G loss: 1.462845]\n",
      "epoch:0 step:613 [D loss: 0.567329, acc.: 71.09%] [G loss: 1.386474]\n",
      "epoch:0 step:614 [D loss: 0.736500, acc.: 53.12%] [G loss: 1.377868]\n",
      "epoch:0 step:615 [D loss: 0.868892, acc.: 41.41%] [G loss: 1.049984]\n",
      "epoch:0 step:616 [D loss: 0.722529, acc.: 61.72%] [G loss: 1.333535]\n",
      "epoch:0 step:617 [D loss: 0.711135, acc.: 58.59%] [G loss: 1.234499]\n",
      "epoch:0 step:618 [D loss: 0.607450, acc.: 67.19%] [G loss: 1.422621]\n",
      "epoch:0 step:619 [D loss: 0.691735, acc.: 58.59%] [G loss: 1.407102]\n",
      "epoch:0 step:620 [D loss: 0.551595, acc.: 67.97%] [G loss: 1.660056]\n",
      "epoch:0 step:621 [D loss: 0.597621, acc.: 67.97%] [G loss: 1.437414]\n",
      "epoch:0 step:622 [D loss: 0.588439, acc.: 64.84%] [G loss: 1.557343]\n",
      "epoch:0 step:623 [D loss: 0.657830, acc.: 61.72%] [G loss: 1.248688]\n",
      "epoch:0 step:624 [D loss: 0.691254, acc.: 63.28%] [G loss: 1.376784]\n",
      "epoch:0 step:625 [D loss: 0.794659, acc.: 50.78%] [G loss: 1.345266]\n",
      "epoch:0 step:626 [D loss: 0.721060, acc.: 55.47%] [G loss: 1.409361]\n",
      "epoch:0 step:627 [D loss: 0.680233, acc.: 62.50%] [G loss: 1.408764]\n",
      "epoch:0 step:628 [D loss: 0.679368, acc.: 58.59%] [G loss: 1.332065]\n",
      "epoch:0 step:629 [D loss: 0.680038, acc.: 62.50%] [G loss: 1.419099]\n",
      "epoch:0 step:630 [D loss: 0.790798, acc.: 49.22%] [G loss: 1.335952]\n",
      "epoch:0 step:631 [D loss: 0.620695, acc.: 65.62%] [G loss: 1.378951]\n",
      "epoch:0 step:632 [D loss: 0.622217, acc.: 65.62%] [G loss: 1.287765]\n",
      "epoch:0 step:633 [D loss: 0.576176, acc.: 67.19%] [G loss: 1.430320]\n",
      "epoch:0 step:634 [D loss: 0.725856, acc.: 62.50%] [G loss: 1.257202]\n",
      "epoch:0 step:635 [D loss: 0.705721, acc.: 57.03%] [G loss: 1.497440]\n",
      "epoch:0 step:636 [D loss: 0.761811, acc.: 54.69%] [G loss: 1.368977]\n",
      "epoch:0 step:637 [D loss: 0.782098, acc.: 54.69%] [G loss: 1.241508]\n",
      "epoch:0 step:638 [D loss: 0.756243, acc.: 54.69%] [G loss: 1.566934]\n",
      "epoch:0 step:639 [D loss: 0.851896, acc.: 53.12%] [G loss: 1.570030]\n",
      "epoch:0 step:640 [D loss: 0.821697, acc.: 38.28%] [G loss: 1.312869]\n",
      "epoch:0 step:641 [D loss: 0.686328, acc.: 59.38%] [G loss: 1.545907]\n",
      "epoch:0 step:642 [D loss: 0.699847, acc.: 60.94%] [G loss: 1.649934]\n",
      "epoch:0 step:643 [D loss: 0.826249, acc.: 50.00%] [G loss: 1.528087]\n",
      "epoch:0 step:644 [D loss: 0.660152, acc.: 61.72%] [G loss: 1.248647]\n",
      "epoch:0 step:645 [D loss: 0.674587, acc.: 59.38%] [G loss: 1.331576]\n",
      "epoch:0 step:646 [D loss: 0.699767, acc.: 57.03%] [G loss: 1.531616]\n",
      "epoch:0 step:647 [D loss: 0.639612, acc.: 64.06%] [G loss: 1.455887]\n",
      "epoch:0 step:648 [D loss: 0.639380, acc.: 66.41%] [G loss: 1.615639]\n",
      "epoch:0 step:649 [D loss: 0.665968, acc.: 60.16%] [G loss: 1.420028]\n",
      "epoch:0 step:650 [D loss: 0.616087, acc.: 68.75%] [G loss: 1.179128]\n",
      "epoch:0 step:651 [D loss: 0.618564, acc.: 65.62%] [G loss: 1.551359]\n",
      "epoch:0 step:652 [D loss: 0.730941, acc.: 56.25%] [G loss: 1.441255]\n",
      "epoch:0 step:653 [D loss: 0.757137, acc.: 55.47%] [G loss: 1.088098]\n",
      "epoch:0 step:654 [D loss: 0.872320, acc.: 42.19%] [G loss: 1.354999]\n",
      "epoch:0 step:655 [D loss: 0.735409, acc.: 59.38%] [G loss: 1.264878]\n",
      "epoch:0 step:656 [D loss: 0.848304, acc.: 43.75%] [G loss: 1.353552]\n",
      "epoch:0 step:657 [D loss: 0.723894, acc.: 55.47%] [G loss: 1.571753]\n",
      "epoch:0 step:658 [D loss: 0.665109, acc.: 64.84%] [G loss: 1.623922]\n",
      "epoch:0 step:659 [D loss: 0.656401, acc.: 58.59%] [G loss: 1.353887]\n",
      "epoch:0 step:660 [D loss: 0.626538, acc.: 62.50%] [G loss: 1.383979]\n",
      "epoch:0 step:661 [D loss: 0.640448, acc.: 65.62%] [G loss: 1.457219]\n",
      "epoch:0 step:662 [D loss: 0.551565, acc.: 66.41%] [G loss: 1.638584]\n",
      "epoch:0 step:663 [D loss: 0.778883, acc.: 53.91%] [G loss: 1.530435]\n",
      "epoch:0 step:664 [D loss: 0.519804, acc.: 71.88%] [G loss: 1.653906]\n",
      "epoch:0 step:665 [D loss: 0.652158, acc.: 67.97%] [G loss: 1.332626]\n",
      "epoch:0 step:666 [D loss: 0.707003, acc.: 64.84%] [G loss: 1.541479]\n",
      "epoch:0 step:667 [D loss: 0.800923, acc.: 53.12%] [G loss: 1.566067]\n",
      "epoch:0 step:668 [D loss: 0.608359, acc.: 70.31%] [G loss: 1.322356]\n",
      "epoch:0 step:669 [D loss: 0.768909, acc.: 53.12%] [G loss: 1.479434]\n",
      "epoch:0 step:670 [D loss: 0.753036, acc.: 57.81%] [G loss: 1.379343]\n",
      "epoch:0 step:671 [D loss: 0.732005, acc.: 57.03%] [G loss: 1.191370]\n",
      "epoch:0 step:672 [D loss: 0.704868, acc.: 58.59%] [G loss: 1.321488]\n",
      "epoch:0 step:673 [D loss: 0.647245, acc.: 61.72%] [G loss: 1.437997]\n",
      "epoch:0 step:674 [D loss: 0.592860, acc.: 71.09%] [G loss: 1.353454]\n",
      "epoch:0 step:675 [D loss: 0.755858, acc.: 56.25%] [G loss: 1.243758]\n",
      "epoch:0 step:676 [D loss: 0.700903, acc.: 55.47%] [G loss: 1.278287]\n",
      "epoch:0 step:677 [D loss: 0.664260, acc.: 67.97%] [G loss: 1.279942]\n",
      "epoch:0 step:678 [D loss: 0.714281, acc.: 57.81%] [G loss: 1.583834]\n",
      "epoch:0 step:679 [D loss: 0.644389, acc.: 60.16%] [G loss: 1.239752]\n",
      "epoch:0 step:680 [D loss: 0.674015, acc.: 63.28%] [G loss: 1.396015]\n",
      "epoch:0 step:681 [D loss: 0.696488, acc.: 58.59%] [G loss: 1.496192]\n",
      "epoch:0 step:682 [D loss: 0.776720, acc.: 56.25%] [G loss: 1.298393]\n",
      "epoch:0 step:683 [D loss: 0.724663, acc.: 53.12%] [G loss: 1.068690]\n",
      "epoch:0 step:684 [D loss: 0.662420, acc.: 60.94%] [G loss: 1.212677]\n",
      "epoch:0 step:685 [D loss: 0.674781, acc.: 61.72%] [G loss: 1.270301]\n",
      "epoch:0 step:686 [D loss: 0.745445, acc.: 54.69%] [G loss: 1.435076]\n",
      "epoch:0 step:687 [D loss: 0.667013, acc.: 61.72%] [G loss: 1.411966]\n",
      "epoch:0 step:688 [D loss: 0.651818, acc.: 58.59%] [G loss: 1.322187]\n",
      "epoch:0 step:689 [D loss: 0.770938, acc.: 60.16%] [G loss: 1.313389]\n",
      "epoch:0 step:690 [D loss: 0.725741, acc.: 53.12%] [G loss: 1.181338]\n",
      "epoch:0 step:691 [D loss: 0.772740, acc.: 50.78%] [G loss: 1.201074]\n",
      "epoch:0 step:692 [D loss: 0.754843, acc.: 53.91%] [G loss: 1.258276]\n",
      "epoch:0 step:693 [D loss: 0.660511, acc.: 60.16%] [G loss: 1.487759]\n",
      "epoch:0 step:694 [D loss: 0.595471, acc.: 67.19%] [G loss: 1.366068]\n",
      "epoch:0 step:695 [D loss: 0.658207, acc.: 65.62%] [G loss: 1.193963]\n",
      "epoch:0 step:696 [D loss: 0.802601, acc.: 47.66%] [G loss: 1.289012]\n",
      "epoch:0 step:697 [D loss: 0.602119, acc.: 63.28%] [G loss: 1.485645]\n",
      "epoch:0 step:698 [D loss: 0.693867, acc.: 57.81%] [G loss: 1.404737]\n",
      "epoch:0 step:699 [D loss: 0.765828, acc.: 57.81%] [G loss: 1.232934]\n",
      "epoch:0 step:700 [D loss: 0.651779, acc.: 64.06%] [G loss: 1.248439]\n",
      "epoch:0 step:701 [D loss: 0.581483, acc.: 67.97%] [G loss: 1.258301]\n",
      "epoch:0 step:702 [D loss: 0.726011, acc.: 54.69%] [G loss: 1.200798]\n",
      "epoch:0 step:703 [D loss: 0.702225, acc.: 57.03%] [G loss: 1.130090]\n",
      "epoch:0 step:704 [D loss: 0.656358, acc.: 61.72%] [G loss: 1.353510]\n",
      "epoch:0 step:705 [D loss: 0.692457, acc.: 56.25%] [G loss: 1.319953]\n",
      "epoch:0 step:706 [D loss: 0.708557, acc.: 61.72%] [G loss: 1.308469]\n",
      "epoch:0 step:707 [D loss: 0.685652, acc.: 57.81%] [G loss: 1.228477]\n",
      "epoch:0 step:708 [D loss: 0.567408, acc.: 65.62%] [G loss: 1.284933]\n",
      "epoch:0 step:709 [D loss: 0.635698, acc.: 68.75%] [G loss: 1.308914]\n",
      "epoch:0 step:710 [D loss: 0.880478, acc.: 47.66%] [G loss: 1.112473]\n",
      "epoch:0 step:711 [D loss: 0.731000, acc.: 55.47%] [G loss: 1.202224]\n",
      "epoch:0 step:712 [D loss: 0.602765, acc.: 68.75%] [G loss: 1.188515]\n",
      "epoch:0 step:713 [D loss: 0.644909, acc.: 58.59%] [G loss: 1.341448]\n",
      "epoch:0 step:714 [D loss: 0.690158, acc.: 60.16%] [G loss: 1.466777]\n",
      "epoch:0 step:715 [D loss: 0.684560, acc.: 62.50%] [G loss: 1.337645]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0 step:716 [D loss: 0.733976, acc.: 56.25%] [G loss: 1.286534]\n",
      "epoch:0 step:717 [D loss: 0.697772, acc.: 61.72%] [G loss: 1.359950]\n",
      "epoch:0 step:718 [D loss: 0.666616, acc.: 64.84%] [G loss: 1.213531]\n",
      "epoch:0 step:719 [D loss: 0.764439, acc.: 53.12%] [G loss: 1.220696]\n",
      "epoch:0 step:720 [D loss: 0.765403, acc.: 50.00%] [G loss: 1.279283]\n",
      "epoch:0 step:721 [D loss: 0.836017, acc.: 45.31%] [G loss: 1.053917]\n",
      "epoch:0 step:722 [D loss: 0.759948, acc.: 53.12%] [G loss: 1.221104]\n",
      "epoch:0 step:723 [D loss: 0.700716, acc.: 59.38%] [G loss: 1.424150]\n",
      "epoch:0 step:724 [D loss: 0.822665, acc.: 42.97%] [G loss: 1.382048]\n",
      "epoch:0 step:725 [D loss: 0.631180, acc.: 58.59%] [G loss: 1.474691]\n",
      "epoch:0 step:726 [D loss: 0.653734, acc.: 57.03%] [G loss: 1.411981]\n",
      "epoch:0 step:727 [D loss: 0.575950, acc.: 70.31%] [G loss: 1.424366]\n",
      "epoch:0 step:728 [D loss: 0.577530, acc.: 71.88%] [G loss: 1.299794]\n",
      "epoch:0 step:729 [D loss: 0.571558, acc.: 71.09%] [G loss: 1.420835]\n",
      "epoch:0 step:730 [D loss: 0.648262, acc.: 60.94%] [G loss: 1.228460]\n",
      "epoch:0 step:731 [D loss: 0.685580, acc.: 60.94%] [G loss: 1.335388]\n",
      "epoch:0 step:732 [D loss: 0.650333, acc.: 64.06%] [G loss: 1.213158]\n",
      "epoch:0 step:733 [D loss: 0.797318, acc.: 50.00%] [G loss: 1.165608]\n",
      "epoch:0 step:734 [D loss: 0.732492, acc.: 57.81%] [G loss: 1.304260]\n",
      "epoch:0 step:735 [D loss: 0.840709, acc.: 42.97%] [G loss: 1.196909]\n",
      "epoch:0 step:736 [D loss: 0.668735, acc.: 58.59%] [G loss: 1.288190]\n",
      "epoch:0 step:737 [D loss: 0.650966, acc.: 71.09%] [G loss: 1.293560]\n",
      "epoch:0 step:738 [D loss: 0.701671, acc.: 60.16%] [G loss: 1.200482]\n",
      "epoch:0 step:739 [D loss: 0.618221, acc.: 63.28%] [G loss: 1.138301]\n",
      "epoch:0 step:740 [D loss: 0.693537, acc.: 56.25%] [G loss: 1.376532]\n",
      "epoch:0 step:741 [D loss: 0.803164, acc.: 51.56%] [G loss: 1.495740]\n",
      "epoch:0 step:742 [D loss: 0.772538, acc.: 46.09%] [G loss: 1.335133]\n",
      "epoch:0 step:743 [D loss: 0.712016, acc.: 53.12%] [G loss: 1.176875]\n",
      "epoch:0 step:744 [D loss: 0.705671, acc.: 61.72%] [G loss: 1.339375]\n",
      "epoch:0 step:745 [D loss: 0.884246, acc.: 46.88%] [G loss: 1.423714]\n",
      "epoch:0 step:746 [D loss: 0.687238, acc.: 55.47%] [G loss: 1.492435]\n",
      "epoch:0 step:747 [D loss: 0.570978, acc.: 71.88%] [G loss: 1.624887]\n",
      "epoch:0 step:748 [D loss: 0.787584, acc.: 53.12%] [G loss: 1.360441]\n",
      "epoch:0 step:749 [D loss: 0.674156, acc.: 60.16%] [G loss: 1.344579]\n",
      "epoch:0 step:750 [D loss: 0.717468, acc.: 54.69%] [G loss: 1.308975]\n",
      "epoch:0 step:751 [D loss: 0.651014, acc.: 61.72%] [G loss: 1.330978]\n",
      "epoch:0 step:752 [D loss: 0.780656, acc.: 48.44%] [G loss: 1.340613]\n",
      "epoch:0 step:753 [D loss: 0.595938, acc.: 64.06%] [G loss: 1.366112]\n",
      "epoch:0 step:754 [D loss: 0.820795, acc.: 44.53%] [G loss: 1.280367]\n",
      "epoch:0 step:755 [D loss: 0.595140, acc.: 68.75%] [G loss: 1.206419]\n",
      "epoch:0 step:756 [D loss: 0.571154, acc.: 70.31%] [G loss: 1.445779]\n",
      "epoch:0 step:757 [D loss: 0.739095, acc.: 53.91%] [G loss: 1.147136]\n",
      "epoch:0 step:758 [D loss: 0.800153, acc.: 46.88%] [G loss: 1.101219]\n",
      "epoch:0 step:759 [D loss: 0.756501, acc.: 52.34%] [G loss: 1.243886]\n",
      "epoch:0 step:760 [D loss: 0.784532, acc.: 49.22%] [G loss: 1.157481]\n",
      "epoch:0 step:761 [D loss: 0.722605, acc.: 55.47%] [G loss: 1.433952]\n",
      "epoch:0 step:762 [D loss: 0.714577, acc.: 55.47%] [G loss: 1.340160]\n",
      "epoch:0 step:763 [D loss: 0.819753, acc.: 41.41%] [G loss: 1.153049]\n",
      "epoch:0 step:764 [D loss: 0.714549, acc.: 57.81%] [G loss: 1.148979]\n",
      "epoch:0 step:765 [D loss: 0.691255, acc.: 54.69%] [G loss: 1.136514]\n",
      "epoch:0 step:766 [D loss: 0.670282, acc.: 56.25%] [G loss: 1.124760]\n",
      "epoch:0 step:767 [D loss: 0.645158, acc.: 63.28%] [G loss: 1.205368]\n",
      "epoch:0 step:768 [D loss: 0.779475, acc.: 50.78%] [G loss: 1.209400]\n",
      "epoch:0 step:769 [D loss: 0.826125, acc.: 49.22%] [G loss: 1.176737]\n",
      "epoch:0 step:770 [D loss: 0.779762, acc.: 56.25%] [G loss: 1.230606]\n",
      "epoch:0 step:771 [D loss: 0.830730, acc.: 46.09%] [G loss: 1.377360]\n",
      "epoch:0 step:772 [D loss: 0.734807, acc.: 54.69%] [G loss: 1.083506]\n",
      "epoch:0 step:773 [D loss: 0.677778, acc.: 61.72%] [G loss: 1.240965]\n",
      "epoch:0 step:774 [D loss: 0.710396, acc.: 54.69%] [G loss: 1.109711]\n",
      "epoch:0 step:775 [D loss: 0.715717, acc.: 58.59%] [G loss: 1.370117]\n",
      "epoch:0 step:776 [D loss: 0.774833, acc.: 51.56%] [G loss: 1.134435]\n",
      "epoch:0 step:777 [D loss: 0.747738, acc.: 55.47%] [G loss: 1.018272]\n",
      "epoch:0 step:778 [D loss: 0.614312, acc.: 64.84%] [G loss: 1.312265]\n",
      "epoch:0 step:779 [D loss: 0.654646, acc.: 63.28%] [G loss: 1.251665]\n",
      "epoch:0 step:780 [D loss: 0.666041, acc.: 62.50%] [G loss: 1.272801]\n",
      "epoch:0 step:781 [D loss: 0.553588, acc.: 71.09%] [G loss: 1.555572]\n",
      "epoch:0 step:782 [D loss: 0.459729, acc.: 86.72%] [G loss: 1.416690]\n",
      "epoch:0 step:783 [D loss: 0.888980, acc.: 48.44%] [G loss: 1.257502]\n",
      "epoch:0 step:784 [D loss: 0.787653, acc.: 51.56%] [G loss: 1.225045]\n",
      "epoch:0 step:785 [D loss: 0.688378, acc.: 57.03%] [G loss: 1.308720]\n",
      "epoch:0 step:786 [D loss: 0.637140, acc.: 65.62%] [G loss: 1.418240]\n",
      "epoch:0 step:787 [D loss: 0.792698, acc.: 54.69%] [G loss: 1.112310]\n",
      "epoch:0 step:788 [D loss: 0.835026, acc.: 48.44%] [G loss: 1.199954]\n",
      "epoch:0 step:789 [D loss: 0.844428, acc.: 50.78%] [G loss: 1.404305]\n",
      "epoch:0 step:790 [D loss: 0.654006, acc.: 65.62%] [G loss: 1.373161]\n",
      "epoch:0 step:791 [D loss: 0.841280, acc.: 44.53%] [G loss: 0.980163]\n",
      "epoch:0 step:792 [D loss: 0.721557, acc.: 58.59%] [G loss: 1.151300]\n",
      "epoch:0 step:793 [D loss: 0.742872, acc.: 53.12%] [G loss: 1.317268]\n",
      "epoch:0 step:794 [D loss: 0.709376, acc.: 60.16%] [G loss: 1.049022]\n",
      "epoch:0 step:795 [D loss: 0.748120, acc.: 55.47%] [G loss: 1.281135]\n",
      "epoch:0 step:796 [D loss: 0.719054, acc.: 56.25%] [G loss: 1.172908]\n",
      "epoch:0 step:797 [D loss: 0.784489, acc.: 50.78%] [G loss: 1.379040]\n",
      "epoch:0 step:798 [D loss: 0.652276, acc.: 61.72%] [G loss: 1.314299]\n",
      "epoch:0 step:799 [D loss: 0.723957, acc.: 57.81%] [G loss: 1.141500]\n",
      "epoch:0 step:800 [D loss: 0.825380, acc.: 48.44%] [G loss: 1.270262]\n",
      "##############\n",
      "[4.40270536 2.45279921 6.35393219 5.24806216 4.22710832 5.966525\n",
      " 5.01052714 5.18317067 5.55753323 4.77266804]\n",
      "##########\n",
      "epoch:0 step:801 [D loss: 0.649864, acc.: 64.84%] [G loss: 1.321559]\n",
      "epoch:0 step:802 [D loss: 0.635079, acc.: 63.28%] [G loss: 1.345596]\n",
      "epoch:0 step:803 [D loss: 0.617528, acc.: 59.38%] [G loss: 1.220695]\n",
      "epoch:0 step:804 [D loss: 0.857860, acc.: 43.75%] [G loss: 1.095794]\n",
      "epoch:0 step:805 [D loss: 0.730409, acc.: 55.47%] [G loss: 1.229443]\n",
      "epoch:0 step:806 [D loss: 0.692140, acc.: 57.03%] [G loss: 1.353201]\n",
      "epoch:0 step:807 [D loss: 0.722546, acc.: 60.16%] [G loss: 1.385216]\n",
      "epoch:0 step:808 [D loss: 0.863653, acc.: 45.31%] [G loss: 1.155758]\n",
      "epoch:0 step:809 [D loss: 0.812799, acc.: 53.12%] [G loss: 1.051925]\n",
      "epoch:0 step:810 [D loss: 0.685006, acc.: 61.72%] [G loss: 1.141885]\n",
      "epoch:0 step:811 [D loss: 0.779372, acc.: 50.00%] [G loss: 1.120723]\n",
      "epoch:0 step:812 [D loss: 0.743118, acc.: 50.78%] [G loss: 1.058208]\n",
      "epoch:0 step:813 [D loss: 0.657194, acc.: 57.03%] [G loss: 1.085569]\n",
      "epoch:0 step:814 [D loss: 0.731207, acc.: 53.91%] [G loss: 1.271234]\n",
      "epoch:0 step:815 [D loss: 0.695365, acc.: 60.16%] [G loss: 1.128739]\n",
      "epoch:0 step:816 [D loss: 0.746387, acc.: 50.00%] [G loss: 1.039279]\n",
      "epoch:0 step:817 [D loss: 0.786806, acc.: 46.09%] [G loss: 0.937196]\n",
      "epoch:0 step:818 [D loss: 0.762511, acc.: 48.44%] [G loss: 0.989546]\n",
      "epoch:0 step:819 [D loss: 0.759136, acc.: 56.25%] [G loss: 1.092939]\n",
      "epoch:0 step:820 [D loss: 0.666617, acc.: 59.38%] [G loss: 1.141271]\n",
      "epoch:0 step:821 [D loss: 0.669486, acc.: 60.16%] [G loss: 1.129037]\n",
      "epoch:0 step:822 [D loss: 0.684844, acc.: 59.38%] [G loss: 1.193532]\n",
      "epoch:0 step:823 [D loss: 0.669093, acc.: 64.06%] [G loss: 1.234143]\n",
      "epoch:0 step:824 [D loss: 0.857178, acc.: 40.62%] [G loss: 1.051074]\n",
      "epoch:0 step:825 [D loss: 0.751819, acc.: 51.56%] [G loss: 0.957088]\n",
      "epoch:0 step:826 [D loss: 0.691776, acc.: 58.59%] [G loss: 0.981774]\n",
      "epoch:0 step:827 [D loss: 0.749778, acc.: 41.41%] [G loss: 1.044254]\n",
      "epoch:0 step:828 [D loss: 0.669916, acc.: 61.72%] [G loss: 1.160078]\n",
      "epoch:0 step:829 [D loss: 0.646131, acc.: 59.38%] [G loss: 1.113716]\n",
      "epoch:0 step:830 [D loss: 0.761011, acc.: 50.00%] [G loss: 1.128684]\n",
      "epoch:0 step:831 [D loss: 0.654736, acc.: 61.72%] [G loss: 1.077652]\n",
      "epoch:0 step:832 [D loss: 0.688940, acc.: 50.78%] [G loss: 1.148113]\n",
      "epoch:0 step:833 [D loss: 0.620972, acc.: 66.41%] [G loss: 1.358978]\n",
      "epoch:0 step:834 [D loss: 0.609768, acc.: 67.19%] [G loss: 1.230720]\n",
      "epoch:0 step:835 [D loss: 0.627980, acc.: 60.16%] [G loss: 1.200589]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0 step:836 [D loss: 0.699130, acc.: 60.94%] [G loss: 1.112756]\n",
      "epoch:0 step:837 [D loss: 0.642488, acc.: 61.72%] [G loss: 1.203892]\n",
      "epoch:0 step:838 [D loss: 0.651458, acc.: 65.62%] [G loss: 1.151004]\n",
      "epoch:0 step:839 [D loss: 0.736008, acc.: 55.47%] [G loss: 1.051093]\n",
      "epoch:0 step:840 [D loss: 0.771023, acc.: 50.78%] [G loss: 1.121672]\n",
      "epoch:0 step:841 [D loss: 0.713919, acc.: 52.34%] [G loss: 1.191760]\n",
      "epoch:0 step:842 [D loss: 0.599970, acc.: 67.19%] [G loss: 1.268996]\n",
      "epoch:0 step:843 [D loss: 0.871603, acc.: 42.97%] [G loss: 1.325951]\n",
      "epoch:0 step:844 [D loss: 0.716231, acc.: 51.56%] [G loss: 1.417380]\n",
      "epoch:0 step:845 [D loss: 0.706136, acc.: 59.38%] [G loss: 1.359954]\n",
      "epoch:0 step:846 [D loss: 0.629204, acc.: 64.84%] [G loss: 1.228430]\n",
      "epoch:0 step:847 [D loss: 0.727721, acc.: 53.91%] [G loss: 1.133168]\n",
      "epoch:0 step:848 [D loss: 0.734658, acc.: 50.78%] [G loss: 1.093183]\n",
      "epoch:0 step:849 [D loss: 0.664502, acc.: 62.50%] [G loss: 1.164823]\n",
      "epoch:0 step:850 [D loss: 0.750278, acc.: 53.12%] [G loss: 1.137436]\n",
      "epoch:0 step:851 [D loss: 0.654932, acc.: 57.03%] [G loss: 1.161437]\n",
      "epoch:0 step:852 [D loss: 0.758721, acc.: 56.25%] [G loss: 1.122152]\n",
      "epoch:0 step:853 [D loss: 0.641866, acc.: 63.28%] [G loss: 1.199521]\n",
      "epoch:0 step:854 [D loss: 0.710960, acc.: 60.94%] [G loss: 1.241712]\n",
      "epoch:0 step:855 [D loss: 0.745767, acc.: 50.78%] [G loss: 1.143128]\n",
      "epoch:0 step:856 [D loss: 0.769853, acc.: 48.44%] [G loss: 1.119081]\n",
      "epoch:0 step:857 [D loss: 0.748671, acc.: 53.91%] [G loss: 1.141472]\n",
      "epoch:0 step:858 [D loss: 0.761194, acc.: 53.91%] [G loss: 1.218895]\n",
      "epoch:0 step:859 [D loss: 0.675804, acc.: 64.84%] [G loss: 1.305269]\n",
      "epoch:0 step:860 [D loss: 0.567154, acc.: 73.44%] [G loss: 1.326919]\n",
      "epoch:0 step:861 [D loss: 0.839309, acc.: 46.09%] [G loss: 1.056335]\n",
      "epoch:0 step:862 [D loss: 0.751637, acc.: 51.56%] [G loss: 1.143130]\n",
      "epoch:0 step:863 [D loss: 0.688297, acc.: 60.16%] [G loss: 1.053903]\n",
      "epoch:0 step:864 [D loss: 0.723137, acc.: 54.69%] [G loss: 1.152806]\n",
      "epoch:0 step:865 [D loss: 0.783764, acc.: 53.12%] [G loss: 1.205750]\n",
      "epoch:0 step:866 [D loss: 0.663077, acc.: 67.19%] [G loss: 1.055788]\n",
      "epoch:0 step:867 [D loss: 0.641720, acc.: 63.28%] [G loss: 1.306805]\n",
      "epoch:0 step:868 [D loss: 0.730216, acc.: 54.69%] [G loss: 1.136249]\n",
      "epoch:0 step:869 [D loss: 0.608621, acc.: 64.06%] [G loss: 1.235969]\n",
      "epoch:0 step:870 [D loss: 0.686160, acc.: 64.06%] [G loss: 1.286470]\n",
      "epoch:0 step:871 [D loss: 0.585353, acc.: 68.75%] [G loss: 1.202055]\n",
      "epoch:0 step:872 [D loss: 0.639785, acc.: 64.84%] [G loss: 1.281861]\n",
      "epoch:0 step:873 [D loss: 0.785282, acc.: 50.00%] [G loss: 0.909781]\n",
      "epoch:0 step:874 [D loss: 0.805022, acc.: 50.78%] [G loss: 1.114545]\n",
      "epoch:0 step:875 [D loss: 0.662104, acc.: 64.06%] [G loss: 1.212230]\n",
      "epoch:0 step:876 [D loss: 0.750529, acc.: 57.03%] [G loss: 1.100067]\n",
      "epoch:0 step:877 [D loss: 0.836055, acc.: 38.28%] [G loss: 1.031660]\n",
      "epoch:0 step:878 [D loss: 0.723128, acc.: 57.03%] [G loss: 1.211453]\n",
      "epoch:0 step:879 [D loss: 0.670749, acc.: 64.06%] [G loss: 1.217466]\n",
      "epoch:0 step:880 [D loss: 0.769746, acc.: 50.78%] [G loss: 1.201349]\n",
      "epoch:0 step:881 [D loss: 0.645808, acc.: 64.06%] [G loss: 1.180477]\n",
      "epoch:0 step:882 [D loss: 0.689678, acc.: 57.81%] [G loss: 1.273851]\n",
      "epoch:0 step:883 [D loss: 0.837108, acc.: 47.66%] [G loss: 1.102085]\n",
      "epoch:0 step:884 [D loss: 0.797306, acc.: 45.31%] [G loss: 1.055459]\n",
      "epoch:0 step:885 [D loss: 0.690760, acc.: 57.03%] [G loss: 1.193792]\n",
      "epoch:0 step:886 [D loss: 0.660009, acc.: 62.50%] [G loss: 1.198770]\n",
      "epoch:0 step:887 [D loss: 0.588094, acc.: 70.31%] [G loss: 1.395278]\n",
      "epoch:0 step:888 [D loss: 0.665146, acc.: 64.06%] [G loss: 1.245601]\n",
      "epoch:0 step:889 [D loss: 0.703798, acc.: 52.34%] [G loss: 1.144960]\n",
      "epoch:0 step:890 [D loss: 0.610238, acc.: 64.84%] [G loss: 1.409317]\n",
      "epoch:0 step:891 [D loss: 0.863340, acc.: 46.88%] [G loss: 1.156888]\n",
      "epoch:0 step:892 [D loss: 0.889445, acc.: 46.88%] [G loss: 1.276182]\n",
      "epoch:0 step:893 [D loss: 0.667479, acc.: 57.81%] [G loss: 1.150744]\n",
      "epoch:0 step:894 [D loss: 0.661971, acc.: 64.06%] [G loss: 1.065839]\n",
      "epoch:0 step:895 [D loss: 0.706640, acc.: 60.94%] [G loss: 1.266663]\n",
      "epoch:0 step:896 [D loss: 0.687970, acc.: 62.50%] [G loss: 1.176881]\n",
      "epoch:0 step:897 [D loss: 0.700291, acc.: 61.72%] [G loss: 1.167086]\n",
      "epoch:0 step:898 [D loss: 0.744235, acc.: 52.34%] [G loss: 1.207450]\n",
      "epoch:0 step:899 [D loss: 0.658934, acc.: 62.50%] [G loss: 1.110608]\n",
      "epoch:0 step:900 [D loss: 0.687330, acc.: 58.59%] [G loss: 1.218297]\n",
      "epoch:0 step:901 [D loss: 0.730573, acc.: 53.91%] [G loss: 1.192640]\n",
      "epoch:0 step:902 [D loss: 0.639828, acc.: 71.09%] [G loss: 1.113419]\n",
      "epoch:0 step:903 [D loss: 0.755834, acc.: 50.78%] [G loss: 1.109252]\n",
      "epoch:0 step:904 [D loss: 0.836221, acc.: 48.44%] [G loss: 1.122925]\n",
      "epoch:0 step:905 [D loss: 0.653721, acc.: 62.50%] [G loss: 1.045763]\n",
      "epoch:0 step:906 [D loss: 0.700741, acc.: 60.94%] [G loss: 1.035400]\n",
      "epoch:0 step:907 [D loss: 0.633815, acc.: 60.94%] [G loss: 1.205342]\n",
      "epoch:0 step:908 [D loss: 0.673241, acc.: 67.19%] [G loss: 1.141381]\n",
      "epoch:0 step:909 [D loss: 0.737646, acc.: 57.81%] [G loss: 0.972316]\n",
      "epoch:0 step:910 [D loss: 0.757815, acc.: 51.56%] [G loss: 1.164103]\n",
      "epoch:0 step:911 [D loss: 0.719560, acc.: 59.38%] [G loss: 0.952872]\n",
      "epoch:0 step:912 [D loss: 0.630100, acc.: 68.75%] [G loss: 1.214034]\n",
      "epoch:0 step:913 [D loss: 0.739960, acc.: 49.22%] [G loss: 1.117709]\n",
      "epoch:0 step:914 [D loss: 0.733724, acc.: 46.88%] [G loss: 1.134357]\n",
      "epoch:0 step:915 [D loss: 0.788294, acc.: 50.78%] [G loss: 1.135736]\n",
      "epoch:0 step:916 [D loss: 0.830217, acc.: 38.28%] [G loss: 1.043009]\n",
      "epoch:0 step:917 [D loss: 0.791005, acc.: 46.88%] [G loss: 1.113193]\n",
      "epoch:0 step:918 [D loss: 0.641519, acc.: 61.72%] [G loss: 1.257767]\n",
      "epoch:0 step:919 [D loss: 0.647471, acc.: 60.16%] [G loss: 1.222786]\n",
      "epoch:0 step:920 [D loss: 0.772248, acc.: 52.34%] [G loss: 1.198181]\n",
      "epoch:0 step:921 [D loss: 0.637158, acc.: 65.62%] [G loss: 1.258657]\n",
      "epoch:0 step:922 [D loss: 0.755984, acc.: 50.00%] [G loss: 1.010299]\n",
      "epoch:0 step:923 [D loss: 0.658289, acc.: 60.16%] [G loss: 1.139251]\n",
      "epoch:0 step:924 [D loss: 0.683791, acc.: 56.25%] [G loss: 1.264974]\n",
      "epoch:0 step:925 [D loss: 0.646275, acc.: 64.06%] [G loss: 1.243108]\n",
      "epoch:0 step:926 [D loss: 0.568039, acc.: 71.88%] [G loss: 1.322477]\n",
      "epoch:0 step:927 [D loss: 0.702211, acc.: 59.38%] [G loss: 1.348579]\n",
      "epoch:0 step:928 [D loss: 0.756930, acc.: 59.38%] [G loss: 1.342465]\n",
      "epoch:0 step:929 [D loss: 0.708422, acc.: 51.56%] [G loss: 1.000933]\n",
      "epoch:0 step:930 [D loss: 0.562777, acc.: 75.78%] [G loss: 1.320026]\n",
      "epoch:0 step:931 [D loss: 0.778470, acc.: 48.44%] [G loss: 1.192959]\n",
      "epoch:0 step:932 [D loss: 0.888656, acc.: 40.62%] [G loss: 1.089406]\n",
      "epoch:0 step:933 [D loss: 0.768401, acc.: 51.56%] [G loss: 1.035900]\n",
      "epoch:0 step:934 [D loss: 0.787428, acc.: 50.00%] [G loss: 1.112947]\n",
      "epoch:0 step:935 [D loss: 0.607959, acc.: 66.41%] [G loss: 1.195724]\n",
      "epoch:0 step:936 [D loss: 0.574928, acc.: 67.97%] [G loss: 1.140086]\n",
      "epoch:0 step:937 [D loss: 0.712357, acc.: 55.47%] [G loss: 1.336241]\n",
      "epoch:1 step:938 [D loss: 0.699254, acc.: 57.03%] [G loss: 1.299524]\n",
      "epoch:1 step:939 [D loss: 0.851406, acc.: 46.09%] [G loss: 1.216825]\n",
      "epoch:1 step:940 [D loss: 0.754159, acc.: 56.25%] [G loss: 1.369035]\n",
      "epoch:1 step:941 [D loss: 0.732801, acc.: 55.47%] [G loss: 1.141389]\n",
      "epoch:1 step:942 [D loss: 0.652768, acc.: 64.06%] [G loss: 1.338783]\n",
      "epoch:1 step:943 [D loss: 0.665563, acc.: 63.28%] [G loss: 1.181771]\n",
      "epoch:1 step:944 [D loss: 0.704661, acc.: 60.16%] [G loss: 1.149755]\n",
      "epoch:1 step:945 [D loss: 0.706333, acc.: 60.16%] [G loss: 1.184133]\n",
      "epoch:1 step:946 [D loss: 0.702297, acc.: 58.59%] [G loss: 1.102191]\n",
      "epoch:1 step:947 [D loss: 0.668405, acc.: 60.16%] [G loss: 1.222181]\n",
      "epoch:1 step:948 [D loss: 0.748243, acc.: 51.56%] [G loss: 1.303470]\n",
      "epoch:1 step:949 [D loss: 0.765841, acc.: 54.69%] [G loss: 1.228589]\n",
      "epoch:1 step:950 [D loss: 0.642025, acc.: 66.41%] [G loss: 1.454956]\n",
      "epoch:1 step:951 [D loss: 0.670631, acc.: 63.28%] [G loss: 1.311247]\n",
      "epoch:1 step:952 [D loss: 0.717095, acc.: 56.25%] [G loss: 1.316780]\n",
      "epoch:1 step:953 [D loss: 0.802789, acc.: 53.12%] [G loss: 1.085565]\n",
      "epoch:1 step:954 [D loss: 0.871903, acc.: 39.84%] [G loss: 1.116399]\n",
      "epoch:1 step:955 [D loss: 0.763559, acc.: 46.09%] [G loss: 1.086141]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1 step:956 [D loss: 0.699227, acc.: 60.94%] [G loss: 1.238494]\n",
      "epoch:1 step:957 [D loss: 0.699807, acc.: 56.25%] [G loss: 1.184952]\n",
      "epoch:1 step:958 [D loss: 0.727275, acc.: 57.81%] [G loss: 1.104390]\n",
      "epoch:1 step:959 [D loss: 0.632477, acc.: 64.84%] [G loss: 1.165287]\n",
      "epoch:1 step:960 [D loss: 0.833777, acc.: 40.62%] [G loss: 1.122282]\n",
      "epoch:1 step:961 [D loss: 0.862015, acc.: 45.31%] [G loss: 1.235056]\n",
      "epoch:1 step:962 [D loss: 0.705245, acc.: 56.25%] [G loss: 1.355142]\n",
      "epoch:1 step:963 [D loss: 0.703622, acc.: 57.03%] [G loss: 1.233561]\n",
      "epoch:1 step:964 [D loss: 0.733066, acc.: 60.94%] [G loss: 1.179268]\n",
      "epoch:1 step:965 [D loss: 0.630411, acc.: 70.31%] [G loss: 1.284675]\n",
      "epoch:1 step:966 [D loss: 0.657524, acc.: 61.72%] [G loss: 1.186644]\n",
      "epoch:1 step:967 [D loss: 0.691595, acc.: 56.25%] [G loss: 1.171151]\n",
      "epoch:1 step:968 [D loss: 0.800208, acc.: 48.44%] [G loss: 0.957970]\n",
      "epoch:1 step:969 [D loss: 0.778143, acc.: 48.44%] [G loss: 1.159082]\n",
      "epoch:1 step:970 [D loss: 0.681303, acc.: 60.16%] [G loss: 1.152821]\n",
      "epoch:1 step:971 [D loss: 0.717477, acc.: 54.69%] [G loss: 1.178157]\n",
      "epoch:1 step:972 [D loss: 0.682902, acc.: 59.38%] [G loss: 1.118001]\n",
      "epoch:1 step:973 [D loss: 0.634581, acc.: 64.06%] [G loss: 1.008630]\n",
      "epoch:1 step:974 [D loss: 0.763491, acc.: 50.00%] [G loss: 1.091087]\n",
      "epoch:1 step:975 [D loss: 0.776659, acc.: 46.09%] [G loss: 1.002335]\n",
      "epoch:1 step:976 [D loss: 0.791710, acc.: 49.22%] [G loss: 0.977246]\n",
      "epoch:1 step:977 [D loss: 0.705682, acc.: 56.25%] [G loss: 1.104757]\n",
      "epoch:1 step:978 [D loss: 0.671910, acc.: 58.59%] [G loss: 1.087998]\n",
      "epoch:1 step:979 [D loss: 0.704193, acc.: 57.81%] [G loss: 1.160043]\n",
      "epoch:1 step:980 [D loss: 0.734429, acc.: 52.34%] [G loss: 1.139942]\n",
      "epoch:1 step:981 [D loss: 0.806269, acc.: 40.62%] [G loss: 1.085755]\n",
      "epoch:1 step:982 [D loss: 0.727179, acc.: 50.00%] [G loss: 0.992612]\n",
      "epoch:1 step:983 [D loss: 0.805425, acc.: 43.75%] [G loss: 0.927484]\n",
      "epoch:1 step:984 [D loss: 0.678546, acc.: 57.81%] [G loss: 0.960837]\n",
      "epoch:1 step:985 [D loss: 0.662578, acc.: 57.81%] [G loss: 1.093708]\n",
      "epoch:1 step:986 [D loss: 0.661690, acc.: 60.94%] [G loss: 1.132173]\n",
      "epoch:1 step:987 [D loss: 0.646618, acc.: 60.94%] [G loss: 1.103906]\n",
      "epoch:1 step:988 [D loss: 0.785538, acc.: 53.91%] [G loss: 0.932586]\n",
      "epoch:1 step:989 [D loss: 0.714953, acc.: 57.03%] [G loss: 1.056444]\n",
      "epoch:1 step:990 [D loss: 0.707840, acc.: 57.81%] [G loss: 1.005634]\n",
      "epoch:1 step:991 [D loss: 0.704522, acc.: 51.56%] [G loss: 1.146788]\n",
      "epoch:1 step:992 [D loss: 0.680348, acc.: 58.59%] [G loss: 1.089290]\n",
      "epoch:1 step:993 [D loss: 0.738291, acc.: 58.59%] [G loss: 1.145902]\n",
      "epoch:1 step:994 [D loss: 0.732085, acc.: 53.12%] [G loss: 1.254735]\n",
      "epoch:1 step:995 [D loss: 0.688586, acc.: 57.81%] [G loss: 1.072681]\n",
      "epoch:1 step:996 [D loss: 0.775647, acc.: 51.56%] [G loss: 1.067695]\n",
      "epoch:1 step:997 [D loss: 0.722567, acc.: 54.69%] [G loss: 1.054889]\n",
      "epoch:1 step:998 [D loss: 0.731940, acc.: 51.56%] [G loss: 1.263070]\n",
      "epoch:1 step:999 [D loss: 0.651502, acc.: 58.59%] [G loss: 1.219233]\n",
      "epoch:1 step:1000 [D loss: 0.651975, acc.: 60.16%] [G loss: 1.099636]\n",
      "##############\n",
      "[4.5528309  2.52846779 6.27517025 5.49179868 4.24496316 5.81230138\n",
      " 4.8134847  5.5092632  5.02800167 4.65166584]\n",
      "##########\n",
      "epoch:1 step:1001 [D loss: 0.634820, acc.: 58.59%] [G loss: 1.095001]\n",
      "epoch:1 step:1002 [D loss: 0.738819, acc.: 53.91%] [G loss: 1.090668]\n",
      "epoch:1 step:1003 [D loss: 0.727871, acc.: 51.56%] [G loss: 0.933841]\n",
      "epoch:1 step:1004 [D loss: 0.753444, acc.: 52.34%] [G loss: 0.983221]\n",
      "epoch:1 step:1005 [D loss: 0.775474, acc.: 50.00%] [G loss: 1.082222]\n",
      "epoch:1 step:1006 [D loss: 0.678467, acc.: 61.72%] [G loss: 1.092608]\n",
      "epoch:1 step:1007 [D loss: 0.662390, acc.: 63.28%] [G loss: 0.939969]\n",
      "epoch:1 step:1008 [D loss: 0.753043, acc.: 51.56%] [G loss: 0.999317]\n",
      "epoch:1 step:1009 [D loss: 0.671317, acc.: 61.72%] [G loss: 0.988505]\n",
      "epoch:1 step:1010 [D loss: 0.668337, acc.: 62.50%] [G loss: 1.007890]\n",
      "epoch:1 step:1011 [D loss: 0.720228, acc.: 55.47%] [G loss: 0.874519]\n",
      "epoch:1 step:1012 [D loss: 0.685338, acc.: 57.81%] [G loss: 1.066118]\n",
      "epoch:1 step:1013 [D loss: 0.631873, acc.: 66.41%] [G loss: 1.221152]\n",
      "epoch:1 step:1014 [D loss: 0.632294, acc.: 72.66%] [G loss: 1.120585]\n",
      "epoch:1 step:1015 [D loss: 0.845416, acc.: 44.53%] [G loss: 0.986830]\n",
      "epoch:1 step:1016 [D loss: 0.751230, acc.: 45.31%] [G loss: 1.033304]\n",
      "epoch:1 step:1017 [D loss: 0.719980, acc.: 54.69%] [G loss: 0.929030]\n",
      "epoch:1 step:1018 [D loss: 0.772489, acc.: 46.88%] [G loss: 1.052424]\n",
      "epoch:1 step:1019 [D loss: 0.721666, acc.: 52.34%] [G loss: 0.986946]\n",
      "epoch:1 step:1020 [D loss: 0.669884, acc.: 57.03%] [G loss: 1.036813]\n",
      "epoch:1 step:1021 [D loss: 0.688658, acc.: 55.47%] [G loss: 1.130222]\n",
      "epoch:1 step:1022 [D loss: 0.717897, acc.: 54.69%] [G loss: 1.049306]\n",
      "epoch:1 step:1023 [D loss: 0.605628, acc.: 67.97%] [G loss: 1.065361]\n",
      "epoch:1 step:1024 [D loss: 0.746326, acc.: 46.88%] [G loss: 0.984499]\n",
      "epoch:1 step:1025 [D loss: 0.667078, acc.: 57.03%] [G loss: 1.037934]\n",
      "epoch:1 step:1026 [D loss: 0.683039, acc.: 58.59%] [G loss: 1.039528]\n",
      "epoch:1 step:1027 [D loss: 0.705199, acc.: 56.25%] [G loss: 1.013086]\n",
      "epoch:1 step:1028 [D loss: 0.753784, acc.: 50.00%] [G loss: 0.927716]\n",
      "epoch:1 step:1029 [D loss: 0.622476, acc.: 57.03%] [G loss: 1.029563]\n",
      "epoch:1 step:1030 [D loss: 0.632285, acc.: 62.50%] [G loss: 0.991524]\n",
      "epoch:1 step:1031 [D loss: 0.618156, acc.: 64.06%] [G loss: 1.121727]\n",
      "epoch:1 step:1032 [D loss: 0.748475, acc.: 51.56%] [G loss: 1.152930]\n",
      "epoch:1 step:1033 [D loss: 0.627121, acc.: 65.62%] [G loss: 1.255972]\n",
      "epoch:1 step:1034 [D loss: 0.709243, acc.: 55.47%] [G loss: 1.220433]\n",
      "epoch:1 step:1035 [D loss: 0.744123, acc.: 49.22%] [G loss: 1.018200]\n",
      "epoch:1 step:1036 [D loss: 0.725906, acc.: 56.25%] [G loss: 0.972079]\n",
      "epoch:1 step:1037 [D loss: 0.626649, acc.: 62.50%] [G loss: 1.309892]\n",
      "epoch:1 step:1038 [D loss: 0.799192, acc.: 46.88%] [G loss: 0.951544]\n",
      "epoch:1 step:1039 [D loss: 0.738780, acc.: 49.22%] [G loss: 1.081647]\n",
      "epoch:1 step:1040 [D loss: 0.711772, acc.: 50.00%] [G loss: 1.143852]\n",
      "epoch:1 step:1041 [D loss: 0.683591, acc.: 57.03%] [G loss: 1.036422]\n",
      "epoch:1 step:1042 [D loss: 0.640819, acc.: 63.28%] [G loss: 1.313185]\n",
      "epoch:1 step:1043 [D loss: 0.630643, acc.: 61.72%] [G loss: 1.235449]\n",
      "epoch:1 step:1044 [D loss: 0.569973, acc.: 70.31%] [G loss: 1.232144]\n",
      "epoch:1 step:1045 [D loss: 0.792952, acc.: 50.00%] [G loss: 1.082355]\n",
      "epoch:1 step:1046 [D loss: 0.828666, acc.: 42.19%] [G loss: 1.001495]\n",
      "epoch:1 step:1047 [D loss: 0.783563, acc.: 41.41%] [G loss: 1.116808]\n",
      "epoch:1 step:1048 [D loss: 0.771379, acc.: 41.41%] [G loss: 1.089452]\n",
      "epoch:1 step:1049 [D loss: 0.730299, acc.: 56.25%] [G loss: 1.086122]\n",
      "epoch:1 step:1050 [D loss: 0.751242, acc.: 50.78%] [G loss: 1.158432]\n",
      "epoch:1 step:1051 [D loss: 0.832521, acc.: 46.09%] [G loss: 1.104171]\n",
      "epoch:1 step:1052 [D loss: 0.686778, acc.: 57.03%] [G loss: 1.123838]\n",
      "epoch:1 step:1053 [D loss: 0.750819, acc.: 52.34%] [G loss: 1.168006]\n",
      "epoch:1 step:1054 [D loss: 0.723620, acc.: 57.03%] [G loss: 1.243838]\n",
      "epoch:1 step:1055 [D loss: 0.594959, acc.: 65.62%] [G loss: 1.230859]\n",
      "epoch:1 step:1056 [D loss: 0.621526, acc.: 64.06%] [G loss: 1.271239]\n",
      "epoch:1 step:1057 [D loss: 0.738558, acc.: 56.25%] [G loss: 1.057947]\n",
      "epoch:1 step:1058 [D loss: 0.729694, acc.: 50.78%] [G loss: 0.944353]\n",
      "epoch:1 step:1059 [D loss: 0.707564, acc.: 55.47%] [G loss: 1.097363]\n",
      "epoch:1 step:1060 [D loss: 0.709726, acc.: 54.69%] [G loss: 1.054255]\n",
      "epoch:1 step:1061 [D loss: 0.615209, acc.: 66.41%] [G loss: 1.140983]\n",
      "epoch:1 step:1062 [D loss: 0.678431, acc.: 63.28%] [G loss: 1.170621]\n",
      "epoch:1 step:1063 [D loss: 0.650831, acc.: 57.81%] [G loss: 1.062407]\n",
      "epoch:1 step:1064 [D loss: 0.723011, acc.: 53.12%] [G loss: 1.257507]\n",
      "epoch:1 step:1065 [D loss: 0.776029, acc.: 42.19%] [G loss: 0.974388]\n",
      "epoch:1 step:1066 [D loss: 0.645647, acc.: 60.94%] [G loss: 1.139752]\n",
      "epoch:1 step:1067 [D loss: 0.660163, acc.: 58.59%] [G loss: 1.166654]\n",
      "epoch:1 step:1068 [D loss: 0.730264, acc.: 52.34%] [G loss: 1.050762]\n",
      "epoch:1 step:1069 [D loss: 0.726748, acc.: 54.69%] [G loss: 1.072128]\n",
      "epoch:1 step:1070 [D loss: 0.955532, acc.: 39.84%] [G loss: 0.923509]\n",
      "epoch:1 step:1071 [D loss: 0.775843, acc.: 53.91%] [G loss: 1.009874]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1 step:1072 [D loss: 0.681647, acc.: 59.38%] [G loss: 1.140277]\n",
      "epoch:1 step:1073 [D loss: 0.708365, acc.: 53.12%] [G loss: 1.056358]\n",
      "epoch:1 step:1074 [D loss: 0.725496, acc.: 55.47%] [G loss: 1.068913]\n",
      "epoch:1 step:1075 [D loss: 0.752737, acc.: 46.88%] [G loss: 1.045648]\n",
      "epoch:1 step:1076 [D loss: 0.678090, acc.: 60.16%] [G loss: 1.015846]\n",
      "epoch:1 step:1077 [D loss: 0.680020, acc.: 59.38%] [G loss: 0.952735]\n",
      "epoch:1 step:1078 [D loss: 0.723802, acc.: 53.91%] [G loss: 1.005254]\n",
      "epoch:1 step:1079 [D loss: 0.672937, acc.: 63.28%] [G loss: 1.136393]\n",
      "epoch:1 step:1080 [D loss: 0.707744, acc.: 52.34%] [G loss: 1.027603]\n",
      "epoch:1 step:1081 [D loss: 0.655548, acc.: 61.72%] [G loss: 1.159466]\n",
      "epoch:1 step:1082 [D loss: 0.643468, acc.: 64.84%] [G loss: 1.093960]\n",
      "epoch:1 step:1083 [D loss: 0.628289, acc.: 66.41%] [G loss: 1.057914]\n",
      "epoch:1 step:1084 [D loss: 0.765915, acc.: 48.44%] [G loss: 0.986376]\n",
      "epoch:1 step:1085 [D loss: 0.745592, acc.: 54.69%] [G loss: 1.052908]\n",
      "epoch:1 step:1086 [D loss: 0.799735, acc.: 49.22%] [G loss: 1.008616]\n",
      "epoch:1 step:1087 [D loss: 0.640638, acc.: 67.97%] [G loss: 1.112085]\n",
      "epoch:1 step:1088 [D loss: 0.691836, acc.: 55.47%] [G loss: 0.984880]\n",
      "epoch:1 step:1089 [D loss: 0.784424, acc.: 59.38%] [G loss: 1.162054]\n",
      "epoch:1 step:1090 [D loss: 0.746909, acc.: 50.00%] [G loss: 1.136260]\n",
      "epoch:1 step:1091 [D loss: 0.762610, acc.: 56.25%] [G loss: 0.941984]\n",
      "epoch:1 step:1092 [D loss: 0.631236, acc.: 67.97%] [G loss: 1.113865]\n",
      "epoch:1 step:1093 [D loss: 0.659501, acc.: 60.16%] [G loss: 1.057911]\n",
      "epoch:1 step:1094 [D loss: 0.653377, acc.: 57.81%] [G loss: 1.112695]\n",
      "epoch:1 step:1095 [D loss: 0.628857, acc.: 63.28%] [G loss: 1.104915]\n",
      "epoch:1 step:1096 [D loss: 0.759073, acc.: 50.00%] [G loss: 0.927615]\n",
      "epoch:1 step:1097 [D loss: 0.703127, acc.: 55.47%] [G loss: 1.036173]\n",
      "epoch:1 step:1098 [D loss: 0.719237, acc.: 53.12%] [G loss: 1.039280]\n",
      "epoch:1 step:1099 [D loss: 0.658677, acc.: 59.38%] [G loss: 1.137209]\n",
      "epoch:1 step:1100 [D loss: 0.742913, acc.: 52.34%] [G loss: 1.069854]\n",
      "epoch:1 step:1101 [D loss: 0.692221, acc.: 55.47%] [G loss: 1.046313]\n",
      "epoch:1 step:1102 [D loss: 0.665029, acc.: 60.94%] [G loss: 1.098524]\n",
      "epoch:1 step:1103 [D loss: 0.798429, acc.: 47.66%] [G loss: 1.104614]\n",
      "epoch:1 step:1104 [D loss: 0.762016, acc.: 49.22%] [G loss: 1.031239]\n",
      "epoch:1 step:1105 [D loss: 0.666040, acc.: 60.94%] [G loss: 1.160558]\n",
      "epoch:1 step:1106 [D loss: 0.746845, acc.: 57.03%] [G loss: 1.188860]\n",
      "epoch:1 step:1107 [D loss: 0.741949, acc.: 55.47%] [G loss: 1.045359]\n",
      "epoch:1 step:1108 [D loss: 0.691444, acc.: 60.94%] [G loss: 1.070563]\n",
      "epoch:1 step:1109 [D loss: 0.664178, acc.: 67.19%] [G loss: 1.065022]\n",
      "epoch:1 step:1110 [D loss: 0.755483, acc.: 47.66%] [G loss: 0.992462]\n",
      "epoch:1 step:1111 [D loss: 0.719529, acc.: 54.69%] [G loss: 1.054346]\n",
      "epoch:1 step:1112 [D loss: 0.700610, acc.: 56.25%] [G loss: 1.123360]\n",
      "epoch:1 step:1113 [D loss: 0.637827, acc.: 59.38%] [G loss: 1.036458]\n",
      "epoch:1 step:1114 [D loss: 0.716011, acc.: 57.81%] [G loss: 1.053191]\n",
      "epoch:1 step:1115 [D loss: 0.753521, acc.: 48.44%] [G loss: 0.990564]\n",
      "epoch:1 step:1116 [D loss: 0.696483, acc.: 52.34%] [G loss: 0.982778]\n",
      "epoch:1 step:1117 [D loss: 0.693069, acc.: 54.69%] [G loss: 0.998878]\n",
      "epoch:1 step:1118 [D loss: 0.752784, acc.: 46.88%] [G loss: 1.032013]\n",
      "epoch:1 step:1119 [D loss: 0.738184, acc.: 53.91%] [G loss: 1.206014]\n",
      "epoch:1 step:1120 [D loss: 0.657767, acc.: 60.16%] [G loss: 1.161796]\n",
      "epoch:1 step:1121 [D loss: 0.658011, acc.: 60.16%] [G loss: 1.115131]\n",
      "epoch:1 step:1122 [D loss: 0.666962, acc.: 60.94%] [G loss: 1.306000]\n",
      "epoch:1 step:1123 [D loss: 0.685170, acc.: 54.69%] [G loss: 1.055948]\n",
      "epoch:1 step:1124 [D loss: 0.736020, acc.: 59.38%] [G loss: 1.123806]\n",
      "epoch:1 step:1125 [D loss: 0.808600, acc.: 49.22%] [G loss: 1.030075]\n",
      "epoch:1 step:1126 [D loss: 0.704558, acc.: 53.91%] [G loss: 1.012278]\n",
      "epoch:1 step:1127 [D loss: 0.727307, acc.: 60.16%] [G loss: 0.981067]\n",
      "epoch:1 step:1128 [D loss: 0.634240, acc.: 64.84%] [G loss: 1.250468]\n",
      "epoch:1 step:1129 [D loss: 0.721493, acc.: 56.25%] [G loss: 1.130634]\n",
      "epoch:1 step:1130 [D loss: 0.657000, acc.: 56.25%] [G loss: 1.060100]\n",
      "epoch:1 step:1131 [D loss: 0.744084, acc.: 46.88%] [G loss: 1.151138]\n",
      "epoch:1 step:1132 [D loss: 0.693166, acc.: 59.38%] [G loss: 1.013352]\n",
      "epoch:1 step:1133 [D loss: 0.674095, acc.: 57.81%] [G loss: 1.130030]\n",
      "epoch:1 step:1134 [D loss: 0.687392, acc.: 57.03%] [G loss: 1.026577]\n",
      "epoch:1 step:1135 [D loss: 0.644751, acc.: 58.59%] [G loss: 1.099554]\n",
      "epoch:1 step:1136 [D loss: 0.716319, acc.: 53.12%] [G loss: 1.144552]\n",
      "epoch:1 step:1137 [D loss: 0.753465, acc.: 52.34%] [G loss: 1.127314]\n",
      "epoch:1 step:1138 [D loss: 0.789301, acc.: 45.31%] [G loss: 0.968955]\n",
      "epoch:1 step:1139 [D loss: 0.699948, acc.: 58.59%] [G loss: 1.051595]\n",
      "epoch:1 step:1140 [D loss: 0.781110, acc.: 49.22%] [G loss: 1.029956]\n",
      "epoch:1 step:1141 [D loss: 0.707021, acc.: 53.91%] [G loss: 1.114705]\n",
      "epoch:1 step:1142 [D loss: 0.615994, acc.: 64.84%] [G loss: 1.077963]\n",
      "epoch:1 step:1143 [D loss: 0.675439, acc.: 60.16%] [G loss: 1.103996]\n",
      "epoch:1 step:1144 [D loss: 0.679931, acc.: 55.47%] [G loss: 1.150655]\n",
      "epoch:1 step:1145 [D loss: 0.712643, acc.: 54.69%] [G loss: 1.142125]\n",
      "epoch:1 step:1146 [D loss: 0.687581, acc.: 61.72%] [G loss: 1.009027]\n",
      "epoch:1 step:1147 [D loss: 0.808026, acc.: 46.88%] [G loss: 0.997756]\n",
      "epoch:1 step:1148 [D loss: 0.805615, acc.: 44.53%] [G loss: 0.953051]\n",
      "epoch:1 step:1149 [D loss: 0.724181, acc.: 57.81%] [G loss: 0.911122]\n",
      "epoch:1 step:1150 [D loss: 0.682386, acc.: 59.38%] [G loss: 0.971343]\n",
      "epoch:1 step:1151 [D loss: 0.741444, acc.: 49.22%] [G loss: 0.941375]\n",
      "epoch:1 step:1152 [D loss: 0.722120, acc.: 50.78%] [G loss: 1.051782]\n",
      "epoch:1 step:1153 [D loss: 0.705393, acc.: 53.91%] [G loss: 0.947734]\n",
      "epoch:1 step:1154 [D loss: 0.699204, acc.: 54.69%] [G loss: 0.944607]\n",
      "epoch:1 step:1155 [D loss: 0.720665, acc.: 50.78%] [G loss: 0.993753]\n",
      "epoch:1 step:1156 [D loss: 0.612708, acc.: 65.62%] [G loss: 1.197612]\n",
      "epoch:1 step:1157 [D loss: 0.726932, acc.: 55.47%] [G loss: 1.114314]\n",
      "epoch:1 step:1158 [D loss: 0.629340, acc.: 60.16%] [G loss: 1.070219]\n",
      "epoch:1 step:1159 [D loss: 0.692987, acc.: 57.81%] [G loss: 1.081340]\n",
      "epoch:1 step:1160 [D loss: 0.590913, acc.: 66.41%] [G loss: 1.234711]\n",
      "epoch:1 step:1161 [D loss: 0.733975, acc.: 53.91%] [G loss: 1.117507]\n",
      "epoch:1 step:1162 [D loss: 0.715748, acc.: 59.38%] [G loss: 1.161258]\n",
      "epoch:1 step:1163 [D loss: 0.661391, acc.: 55.47%] [G loss: 1.125285]\n",
      "epoch:1 step:1164 [D loss: 0.692301, acc.: 53.91%] [G loss: 1.070091]\n",
      "epoch:1 step:1165 [D loss: 0.715751, acc.: 51.56%] [G loss: 0.989783]\n",
      "epoch:1 step:1166 [D loss: 0.711107, acc.: 53.91%] [G loss: 1.145653]\n",
      "epoch:1 step:1167 [D loss: 0.570810, acc.: 66.41%] [G loss: 0.978240]\n",
      "epoch:1 step:1168 [D loss: 0.677169, acc.: 62.50%] [G loss: 1.184491]\n",
      "epoch:1 step:1169 [D loss: 0.633928, acc.: 63.28%] [G loss: 1.237861]\n",
      "epoch:1 step:1170 [D loss: 0.750691, acc.: 47.66%] [G loss: 0.971850]\n",
      "epoch:1 step:1171 [D loss: 0.741433, acc.: 51.56%] [G loss: 1.162851]\n",
      "epoch:1 step:1172 [D loss: 0.642912, acc.: 60.16%] [G loss: 0.919805]\n",
      "epoch:1 step:1173 [D loss: 0.712014, acc.: 57.81%] [G loss: 0.923275]\n",
      "epoch:1 step:1174 [D loss: 0.807759, acc.: 50.78%] [G loss: 0.999693]\n",
      "epoch:1 step:1175 [D loss: 0.765340, acc.: 54.69%] [G loss: 0.932986]\n",
      "epoch:1 step:1176 [D loss: 0.683853, acc.: 56.25%] [G loss: 1.063044]\n",
      "epoch:1 step:1177 [D loss: 0.705128, acc.: 59.38%] [G loss: 0.973535]\n",
      "epoch:1 step:1178 [D loss: 0.812506, acc.: 46.09%] [G loss: 1.040027]\n",
      "epoch:1 step:1179 [D loss: 0.712410, acc.: 60.16%] [G loss: 1.199969]\n",
      "epoch:1 step:1180 [D loss: 0.649376, acc.: 60.16%] [G loss: 1.172639]\n",
      "epoch:1 step:1181 [D loss: 0.693231, acc.: 55.47%] [G loss: 0.989815]\n",
      "epoch:1 step:1182 [D loss: 0.677418, acc.: 58.59%] [G loss: 1.053585]\n",
      "epoch:1 step:1183 [D loss: 0.744478, acc.: 55.47%] [G loss: 1.009974]\n",
      "epoch:1 step:1184 [D loss: 0.742844, acc.: 46.88%] [G loss: 1.056651]\n",
      "epoch:1 step:1185 [D loss: 0.683734, acc.: 57.81%] [G loss: 1.026512]\n",
      "epoch:1 step:1186 [D loss: 0.758602, acc.: 49.22%] [G loss: 0.987668]\n",
      "epoch:1 step:1187 [D loss: 0.751241, acc.: 49.22%] [G loss: 0.979897]\n",
      "epoch:1 step:1188 [D loss: 0.703524, acc.: 58.59%] [G loss: 1.028725]\n",
      "epoch:1 step:1189 [D loss: 0.682429, acc.: 53.91%] [G loss: 1.027735]\n",
      "epoch:1 step:1190 [D loss: 0.749701, acc.: 50.00%] [G loss: 1.090461]\n",
      "epoch:1 step:1191 [D loss: 0.678114, acc.: 65.62%] [G loss: 1.008107]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1 step:1192 [D loss: 0.736387, acc.: 55.47%] [G loss: 0.989974]\n",
      "epoch:1 step:1193 [D loss: 0.755264, acc.: 50.00%] [G loss: 0.993343]\n",
      "epoch:1 step:1194 [D loss: 0.691297, acc.: 60.94%] [G loss: 0.962285]\n",
      "epoch:1 step:1195 [D loss: 0.639148, acc.: 66.41%] [G loss: 1.050327]\n",
      "epoch:1 step:1196 [D loss: 0.613486, acc.: 65.62%] [G loss: 1.002371]\n",
      "epoch:1 step:1197 [D loss: 0.690165, acc.: 60.16%] [G loss: 1.079651]\n",
      "epoch:1 step:1198 [D loss: 0.661164, acc.: 62.50%] [G loss: 1.023504]\n",
      "epoch:1 step:1199 [D loss: 0.679829, acc.: 59.38%] [G loss: 0.952536]\n",
      "epoch:1 step:1200 [D loss: 0.748810, acc.: 50.78%] [G loss: 0.997207]\n",
      "##############\n",
      "[4.70379655 2.33591897 6.29348765 5.62835287 4.19302537 5.98936026\n",
      " 5.0063276  5.31139106 5.52636247 4.46920844]\n",
      "##########\n",
      "epoch:1 step:1201 [D loss: 0.736818, acc.: 56.25%] [G loss: 1.096281]\n",
      "epoch:1 step:1202 [D loss: 0.753348, acc.: 54.69%] [G loss: 1.008905]\n",
      "epoch:1 step:1203 [D loss: 0.760178, acc.: 51.56%] [G loss: 0.937233]\n",
      "epoch:1 step:1204 [D loss: 0.709710, acc.: 53.12%] [G loss: 1.010014]\n",
      "epoch:1 step:1205 [D loss: 0.716005, acc.: 53.91%] [G loss: 1.035887]\n",
      "epoch:1 step:1206 [D loss: 0.755946, acc.: 50.78%] [G loss: 1.151172]\n",
      "epoch:1 step:1207 [D loss: 0.627769, acc.: 65.62%] [G loss: 1.251220]\n",
      "epoch:1 step:1208 [D loss: 0.682657, acc.: 58.59%] [G loss: 1.113540]\n",
      "epoch:1 step:1209 [D loss: 0.743013, acc.: 46.88%] [G loss: 1.052616]\n",
      "epoch:1 step:1210 [D loss: 0.727944, acc.: 50.78%] [G loss: 1.100152]\n",
      "epoch:1 step:1211 [D loss: 0.681531, acc.: 61.72%] [G loss: 0.939048]\n",
      "epoch:1 step:1212 [D loss: 0.723045, acc.: 56.25%] [G loss: 1.071023]\n",
      "epoch:1 step:1213 [D loss: 0.756080, acc.: 48.44%] [G loss: 0.986344]\n",
      "epoch:1 step:1214 [D loss: 0.717339, acc.: 46.88%] [G loss: 1.017876]\n",
      "epoch:1 step:1215 [D loss: 0.686205, acc.: 57.81%] [G loss: 0.999260]\n",
      "epoch:1 step:1216 [D loss: 0.733526, acc.: 49.22%] [G loss: 1.045076]\n",
      "epoch:1 step:1217 [D loss: 0.646667, acc.: 64.84%] [G loss: 0.999787]\n",
      "epoch:1 step:1218 [D loss: 0.753845, acc.: 50.78%] [G loss: 0.971846]\n",
      "epoch:1 step:1219 [D loss: 0.786487, acc.: 46.09%] [G loss: 0.919028]\n",
      "epoch:1 step:1220 [D loss: 0.700980, acc.: 53.91%] [G loss: 1.008150]\n",
      "epoch:1 step:1221 [D loss: 0.629368, acc.: 62.50%] [G loss: 0.985489]\n",
      "epoch:1 step:1222 [D loss: 0.654098, acc.: 67.97%] [G loss: 1.149086]\n",
      "epoch:1 step:1223 [D loss: 0.703481, acc.: 60.16%] [G loss: 1.173364]\n",
      "epoch:1 step:1224 [D loss: 0.701672, acc.: 52.34%] [G loss: 1.174001]\n",
      "epoch:1 step:1225 [D loss: 0.690434, acc.: 57.81%] [G loss: 1.134803]\n",
      "epoch:1 step:1226 [D loss: 0.591992, acc.: 66.41%] [G loss: 1.125557]\n",
      "epoch:1 step:1227 [D loss: 0.691324, acc.: 57.81%] [G loss: 1.083091]\n",
      "epoch:1 step:1228 [D loss: 0.708506, acc.: 56.25%] [G loss: 1.297516]\n",
      "epoch:1 step:1229 [D loss: 0.660041, acc.: 58.59%] [G loss: 1.110587]\n",
      "epoch:1 step:1230 [D loss: 0.707895, acc.: 56.25%] [G loss: 1.042800]\n",
      "epoch:1 step:1231 [D loss: 0.802580, acc.: 46.88%] [G loss: 1.117354]\n",
      "epoch:1 step:1232 [D loss: 0.717093, acc.: 54.69%] [G loss: 1.099415]\n",
      "epoch:1 step:1233 [D loss: 0.660098, acc.: 62.50%] [G loss: 1.017902]\n",
      "epoch:1 step:1234 [D loss: 0.760239, acc.: 51.56%] [G loss: 1.022024]\n",
      "epoch:1 step:1235 [D loss: 0.747613, acc.: 53.12%] [G loss: 1.058887]\n",
      "epoch:1 step:1236 [D loss: 0.655544, acc.: 62.50%] [G loss: 1.069036]\n",
      "epoch:1 step:1237 [D loss: 0.729069, acc.: 57.81%] [G loss: 1.039947]\n",
      "epoch:1 step:1238 [D loss: 0.695995, acc.: 50.00%] [G loss: 1.163401]\n",
      "epoch:1 step:1239 [D loss: 0.701438, acc.: 51.56%] [G loss: 0.973010]\n",
      "epoch:1 step:1240 [D loss: 0.677145, acc.: 58.59%] [G loss: 1.114478]\n",
      "epoch:1 step:1241 [D loss: 0.628822, acc.: 66.41%] [G loss: 1.075595]\n",
      "epoch:1 step:1242 [D loss: 0.685638, acc.: 53.91%] [G loss: 1.015950]\n",
      "epoch:1 step:1243 [D loss: 0.663740, acc.: 58.59%] [G loss: 1.013962]\n",
      "epoch:1 step:1244 [D loss: 0.729223, acc.: 57.81%] [G loss: 1.014839]\n",
      "epoch:1 step:1245 [D loss: 0.771607, acc.: 46.88%] [G loss: 0.908449]\n",
      "epoch:1 step:1246 [D loss: 0.724689, acc.: 49.22%] [G loss: 1.002892]\n",
      "epoch:1 step:1247 [D loss: 0.669912, acc.: 57.81%] [G loss: 1.084984]\n",
      "epoch:1 step:1248 [D loss: 0.678357, acc.: 59.38%] [G loss: 1.023159]\n",
      "epoch:1 step:1249 [D loss: 0.646348, acc.: 58.59%] [G loss: 1.135721]\n",
      "epoch:1 step:1250 [D loss: 0.601237, acc.: 69.53%] [G loss: 1.150886]\n",
      "epoch:1 step:1251 [D loss: 0.621457, acc.: 67.97%] [G loss: 1.211116]\n",
      "epoch:1 step:1252 [D loss: 0.619727, acc.: 65.62%] [G loss: 1.270231]\n",
      "epoch:1 step:1253 [D loss: 0.793254, acc.: 48.44%] [G loss: 1.045915]\n",
      "epoch:1 step:1254 [D loss: 0.771655, acc.: 48.44%] [G loss: 1.036047]\n",
      "epoch:1 step:1255 [D loss: 0.698453, acc.: 59.38%] [G loss: 1.044798]\n",
      "epoch:1 step:1256 [D loss: 0.685835, acc.: 55.47%] [G loss: 0.942349]\n",
      "epoch:1 step:1257 [D loss: 0.737066, acc.: 50.00%] [G loss: 0.961527]\n",
      "epoch:1 step:1258 [D loss: 0.661281, acc.: 63.28%] [G loss: 0.958045]\n",
      "epoch:1 step:1259 [D loss: 0.720366, acc.: 55.47%] [G loss: 1.010925]\n",
      "epoch:1 step:1260 [D loss: 0.759218, acc.: 55.47%] [G loss: 1.068321]\n",
      "epoch:1 step:1261 [D loss: 0.731872, acc.: 59.38%] [G loss: 1.025770]\n",
      "epoch:1 step:1262 [D loss: 0.661032, acc.: 59.38%] [G loss: 0.969673]\n",
      "epoch:1 step:1263 [D loss: 0.744220, acc.: 54.69%] [G loss: 1.003409]\n",
      "epoch:1 step:1264 [D loss: 0.695475, acc.: 56.25%] [G loss: 1.097258]\n",
      "epoch:1 step:1265 [D loss: 0.642574, acc.: 61.72%] [G loss: 1.085334]\n",
      "epoch:1 step:1266 [D loss: 0.807742, acc.: 46.88%] [G loss: 1.049560]\n",
      "epoch:1 step:1267 [D loss: 0.742574, acc.: 51.56%] [G loss: 0.895670]\n",
      "epoch:1 step:1268 [D loss: 0.714383, acc.: 56.25%] [G loss: 0.919965]\n",
      "epoch:1 step:1269 [D loss: 0.685279, acc.: 54.69%] [G loss: 0.905458]\n",
      "epoch:1 step:1270 [D loss: 0.647223, acc.: 63.28%] [G loss: 1.060962]\n",
      "epoch:1 step:1271 [D loss: 0.662757, acc.: 61.72%] [G loss: 1.066222]\n",
      "epoch:1 step:1272 [D loss: 0.625158, acc.: 67.97%] [G loss: 1.050632]\n",
      "epoch:1 step:1273 [D loss: 0.629381, acc.: 63.28%] [G loss: 1.075416]\n",
      "epoch:1 step:1274 [D loss: 0.750440, acc.: 50.00%] [G loss: 1.047500]\n",
      "epoch:1 step:1275 [D loss: 0.745745, acc.: 59.38%] [G loss: 1.004379]\n",
      "epoch:1 step:1276 [D loss: 0.613381, acc.: 64.84%] [G loss: 1.143284]\n",
      "epoch:1 step:1277 [D loss: 0.698388, acc.: 51.56%] [G loss: 1.213818]\n",
      "epoch:1 step:1278 [D loss: 0.790546, acc.: 43.75%] [G loss: 0.960669]\n",
      "epoch:1 step:1279 [D loss: 0.695458, acc.: 58.59%] [G loss: 1.001849]\n",
      "epoch:1 step:1280 [D loss: 0.645172, acc.: 59.38%] [G loss: 1.021576]\n",
      "epoch:1 step:1281 [D loss: 0.581072, acc.: 65.62%] [G loss: 1.122894]\n",
      "epoch:1 step:1282 [D loss: 0.711229, acc.: 57.81%] [G loss: 1.029615]\n",
      "epoch:1 step:1283 [D loss: 0.616695, acc.: 64.84%] [G loss: 1.072733]\n",
      "epoch:1 step:1284 [D loss: 0.633207, acc.: 65.62%] [G loss: 1.198452]\n",
      "epoch:1 step:1285 [D loss: 0.820091, acc.: 50.00%] [G loss: 1.016535]\n",
      "epoch:1 step:1286 [D loss: 0.906219, acc.: 35.16%] [G loss: 0.902465]\n",
      "epoch:1 step:1287 [D loss: 0.722910, acc.: 53.12%] [G loss: 0.947761]\n",
      "epoch:1 step:1288 [D loss: 0.707143, acc.: 53.91%] [G loss: 0.973239]\n",
      "epoch:1 step:1289 [D loss: 0.652802, acc.: 63.28%] [G loss: 0.941574]\n",
      "epoch:1 step:1290 [D loss: 0.733665, acc.: 54.69%] [G loss: 0.995132]\n",
      "epoch:1 step:1291 [D loss: 0.622338, acc.: 71.09%] [G loss: 1.080551]\n",
      "epoch:1 step:1292 [D loss: 0.747734, acc.: 54.69%] [G loss: 1.077773]\n",
      "epoch:1 step:1293 [D loss: 0.743700, acc.: 47.66%] [G loss: 0.972520]\n",
      "epoch:1 step:1294 [D loss: 0.689715, acc.: 56.25%] [G loss: 1.081429]\n",
      "epoch:1 step:1295 [D loss: 0.658373, acc.: 59.38%] [G loss: 1.090417]\n",
      "epoch:1 step:1296 [D loss: 0.710671, acc.: 55.47%] [G loss: 0.933610]\n",
      "epoch:1 step:1297 [D loss: 0.659700, acc.: 59.38%] [G loss: 1.069975]\n",
      "epoch:1 step:1298 [D loss: 0.669630, acc.: 57.03%] [G loss: 1.137687]\n",
      "epoch:1 step:1299 [D loss: 0.729782, acc.: 52.34%] [G loss: 1.067583]\n",
      "epoch:1 step:1300 [D loss: 0.728306, acc.: 59.38%] [G loss: 0.969597]\n",
      "epoch:1 step:1301 [D loss: 0.718432, acc.: 50.78%] [G loss: 1.077652]\n",
      "epoch:1 step:1302 [D loss: 0.726844, acc.: 53.12%] [G loss: 1.054748]\n",
      "epoch:1 step:1303 [D loss: 0.706449, acc.: 56.25%] [G loss: 1.121274]\n",
      "epoch:1 step:1304 [D loss: 0.668614, acc.: 52.34%] [G loss: 1.147426]\n",
      "epoch:1 step:1305 [D loss: 0.624043, acc.: 63.28%] [G loss: 1.047292]\n",
      "epoch:1 step:1306 [D loss: 0.662374, acc.: 59.38%] [G loss: 1.079800]\n",
      "epoch:1 step:1307 [D loss: 0.634607, acc.: 60.94%] [G loss: 1.060052]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1 step:1308 [D loss: 0.720874, acc.: 53.91%] [G loss: 0.946121]\n",
      "epoch:1 step:1309 [D loss: 0.654429, acc.: 64.84%] [G loss: 0.977922]\n",
      "epoch:1 step:1310 [D loss: 0.808767, acc.: 46.88%] [G loss: 1.009872]\n",
      "epoch:1 step:1311 [D loss: 0.634842, acc.: 63.28%] [G loss: 1.071308]\n",
      "epoch:1 step:1312 [D loss: 0.706735, acc.: 58.59%] [G loss: 0.991717]\n",
      "epoch:1 step:1313 [D loss: 0.746723, acc.: 54.69%] [G loss: 0.968767]\n",
      "epoch:1 step:1314 [D loss: 0.717457, acc.: 55.47%] [G loss: 1.101270]\n",
      "epoch:1 step:1315 [D loss: 0.676451, acc.: 58.59%] [G loss: 1.107254]\n",
      "epoch:1 step:1316 [D loss: 0.700364, acc.: 53.12%] [G loss: 1.134775]\n",
      "epoch:1 step:1317 [D loss: 0.779386, acc.: 51.56%] [G loss: 0.907999]\n",
      "epoch:1 step:1318 [D loss: 0.718851, acc.: 53.91%] [G loss: 0.919720]\n",
      "epoch:1 step:1319 [D loss: 0.719511, acc.: 50.00%] [G loss: 1.060429]\n",
      "epoch:1 step:1320 [D loss: 0.733221, acc.: 49.22%] [G loss: 0.957320]\n",
      "epoch:1 step:1321 [D loss: 0.704938, acc.: 57.03%] [G loss: 1.024435]\n",
      "epoch:1 step:1322 [D loss: 0.636362, acc.: 63.28%] [G loss: 1.086053]\n",
      "epoch:1 step:1323 [D loss: 0.720978, acc.: 50.78%] [G loss: 1.048087]\n",
      "epoch:1 step:1324 [D loss: 0.678625, acc.: 51.56%] [G loss: 1.028070]\n",
      "epoch:1 step:1325 [D loss: 0.639425, acc.: 64.84%] [G loss: 0.985125]\n",
      "epoch:1 step:1326 [D loss: 0.761789, acc.: 47.66%] [G loss: 0.928823]\n",
      "epoch:1 step:1327 [D loss: 0.768071, acc.: 44.53%] [G loss: 0.956803]\n",
      "epoch:1 step:1328 [D loss: 0.688544, acc.: 62.50%] [G loss: 1.087200]\n",
      "epoch:1 step:1329 [D loss: 0.807748, acc.: 45.31%] [G loss: 0.973559]\n",
      "epoch:1 step:1330 [D loss: 0.772938, acc.: 50.00%] [G loss: 0.866839]\n",
      "epoch:1 step:1331 [D loss: 0.722382, acc.: 53.91%] [G loss: 0.930969]\n",
      "epoch:1 step:1332 [D loss: 0.746573, acc.: 50.78%] [G loss: 1.019799]\n",
      "epoch:1 step:1333 [D loss: 0.758273, acc.: 50.78%] [G loss: 1.042861]\n",
      "epoch:1 step:1334 [D loss: 0.757628, acc.: 47.66%] [G loss: 1.077234]\n",
      "epoch:1 step:1335 [D loss: 0.576687, acc.: 71.09%] [G loss: 1.074982]\n",
      "epoch:1 step:1336 [D loss: 0.583364, acc.: 66.41%] [G loss: 1.199759]\n",
      "epoch:1 step:1337 [D loss: 0.692190, acc.: 53.91%] [G loss: 1.051142]\n",
      "epoch:1 step:1338 [D loss: 0.746422, acc.: 46.09%] [G loss: 0.935176]\n",
      "epoch:1 step:1339 [D loss: 0.638436, acc.: 67.19%] [G loss: 0.916571]\n",
      "epoch:1 step:1340 [D loss: 0.778244, acc.: 46.09%] [G loss: 0.988279]\n",
      "epoch:1 step:1341 [D loss: 0.736868, acc.: 50.78%] [G loss: 0.910791]\n",
      "epoch:1 step:1342 [D loss: 0.739566, acc.: 46.88%] [G loss: 0.938715]\n",
      "epoch:1 step:1343 [D loss: 0.642360, acc.: 58.59%] [G loss: 0.931196]\n",
      "epoch:1 step:1344 [D loss: 0.716040, acc.: 52.34%] [G loss: 0.931317]\n",
      "epoch:1 step:1345 [D loss: 0.658787, acc.: 57.81%] [G loss: 0.871783]\n",
      "epoch:1 step:1346 [D loss: 0.687328, acc.: 54.69%] [G loss: 0.924453]\n",
      "epoch:1 step:1347 [D loss: 0.705714, acc.: 51.56%] [G loss: 0.946612]\n",
      "epoch:1 step:1348 [D loss: 0.727728, acc.: 48.44%] [G loss: 0.991050]\n",
      "epoch:1 step:1349 [D loss: 0.741581, acc.: 50.78%] [G loss: 0.899002]\n",
      "epoch:1 step:1350 [D loss: 0.731903, acc.: 48.44%] [G loss: 0.943691]\n",
      "epoch:1 step:1351 [D loss: 0.642291, acc.: 65.62%] [G loss: 0.967994]\n",
      "epoch:1 step:1352 [D loss: 0.694612, acc.: 56.25%] [G loss: 0.935487]\n",
      "epoch:1 step:1353 [D loss: 0.636131, acc.: 63.28%] [G loss: 1.024498]\n",
      "epoch:1 step:1354 [D loss: 0.650798, acc.: 57.81%] [G loss: 1.097907]\n",
      "epoch:1 step:1355 [D loss: 0.700278, acc.: 52.34%] [G loss: 0.965044]\n",
      "epoch:1 step:1356 [D loss: 0.673183, acc.: 57.81%] [G loss: 1.029430]\n",
      "epoch:1 step:1357 [D loss: 0.740488, acc.: 49.22%] [G loss: 1.029457]\n",
      "epoch:1 step:1358 [D loss: 0.694735, acc.: 50.00%] [G loss: 1.092105]\n",
      "epoch:1 step:1359 [D loss: 0.721314, acc.: 47.66%] [G loss: 1.086024]\n",
      "epoch:1 step:1360 [D loss: 0.664482, acc.: 57.81%] [G loss: 1.065061]\n",
      "epoch:1 step:1361 [D loss: 0.671446, acc.: 53.91%] [G loss: 0.945125]\n",
      "epoch:1 step:1362 [D loss: 0.652094, acc.: 59.38%] [G loss: 1.127328]\n",
      "epoch:1 step:1363 [D loss: 0.653891, acc.: 61.72%] [G loss: 1.080874]\n",
      "epoch:1 step:1364 [D loss: 0.708884, acc.: 54.69%] [G loss: 1.118472]\n",
      "epoch:1 step:1365 [D loss: 0.669744, acc.: 64.06%] [G loss: 1.065388]\n",
      "epoch:1 step:1366 [D loss: 0.716882, acc.: 57.03%] [G loss: 0.982948]\n",
      "epoch:1 step:1367 [D loss: 0.647827, acc.: 64.06%] [G loss: 1.060647]\n",
      "epoch:1 step:1368 [D loss: 0.784528, acc.: 46.88%] [G loss: 0.843470]\n",
      "epoch:1 step:1369 [D loss: 0.871779, acc.: 37.50%] [G loss: 0.943266]\n",
      "epoch:1 step:1370 [D loss: 0.808679, acc.: 39.84%] [G loss: 0.967897]\n",
      "epoch:1 step:1371 [D loss: 0.694390, acc.: 60.16%] [G loss: 1.003910]\n",
      "epoch:1 step:1372 [D loss: 0.687870, acc.: 56.25%] [G loss: 1.022855]\n",
      "epoch:1 step:1373 [D loss: 0.647490, acc.: 60.94%] [G loss: 0.969112]\n",
      "epoch:1 step:1374 [D loss: 0.774577, acc.: 46.88%] [G loss: 0.976863]\n",
      "epoch:1 step:1375 [D loss: 0.649593, acc.: 67.19%] [G loss: 1.028310]\n",
      "epoch:1 step:1376 [D loss: 0.723092, acc.: 52.34%] [G loss: 0.973614]\n",
      "epoch:1 step:1377 [D loss: 0.672037, acc.: 63.28%] [G loss: 1.094871]\n",
      "epoch:1 step:1378 [D loss: 0.718265, acc.: 57.03%] [G loss: 1.025030]\n",
      "epoch:1 step:1379 [D loss: 0.664126, acc.: 60.16%] [G loss: 0.965677]\n",
      "epoch:1 step:1380 [D loss: 0.714961, acc.: 53.12%] [G loss: 0.859885]\n",
      "epoch:1 step:1381 [D loss: 0.705830, acc.: 59.38%] [G loss: 0.891527]\n",
      "epoch:1 step:1382 [D loss: 0.647929, acc.: 64.06%] [G loss: 1.033459]\n",
      "epoch:1 step:1383 [D loss: 0.670252, acc.: 67.97%] [G loss: 0.960294]\n",
      "epoch:1 step:1384 [D loss: 0.673035, acc.: 59.38%] [G loss: 0.953442]\n",
      "epoch:1 step:1385 [D loss: 0.766157, acc.: 51.56%] [G loss: 0.990285]\n",
      "epoch:1 step:1386 [D loss: 0.704105, acc.: 53.91%] [G loss: 1.025186]\n",
      "epoch:1 step:1387 [D loss: 0.654430, acc.: 64.06%] [G loss: 1.030936]\n",
      "epoch:1 step:1388 [D loss: 0.734372, acc.: 56.25%] [G loss: 1.070243]\n",
      "epoch:1 step:1389 [D loss: 0.679232, acc.: 60.16%] [G loss: 1.084593]\n",
      "epoch:1 step:1390 [D loss: 0.658357, acc.: 62.50%] [G loss: 1.037856]\n",
      "epoch:1 step:1391 [D loss: 0.680789, acc.: 64.84%] [G loss: 1.076364]\n",
      "epoch:1 step:1392 [D loss: 0.628470, acc.: 66.41%] [G loss: 1.073238]\n",
      "epoch:1 step:1393 [D loss: 0.659606, acc.: 57.03%] [G loss: 1.174120]\n",
      "epoch:1 step:1394 [D loss: 0.678918, acc.: 64.06%] [G loss: 1.070063]\n",
      "epoch:1 step:1395 [D loss: 0.852558, acc.: 45.31%] [G loss: 0.990595]\n",
      "epoch:1 step:1396 [D loss: 0.757202, acc.: 43.75%] [G loss: 0.925451]\n",
      "epoch:1 step:1397 [D loss: 0.699184, acc.: 56.25%] [G loss: 0.968760]\n",
      "epoch:1 step:1398 [D loss: 0.659896, acc.: 60.16%] [G loss: 1.177373]\n",
      "epoch:1 step:1399 [D loss: 0.627892, acc.: 64.06%] [G loss: 1.054363]\n",
      "epoch:1 step:1400 [D loss: 0.665879, acc.: 65.62%] [G loss: 1.025053]\n",
      "##############\n",
      "[4.02401373 2.56518574 6.3251388  5.6075109  4.12721745 5.86978343\n",
      " 4.90137183 5.4373796  5.21585588 4.51160767]\n",
      "##########\n",
      "epoch:1 step:1401 [D loss: 0.661428, acc.: 60.16%] [G loss: 1.129654]\n",
      "epoch:1 step:1402 [D loss: 0.688381, acc.: 53.12%] [G loss: 1.071956]\n",
      "epoch:1 step:1403 [D loss: 0.778676, acc.: 46.88%] [G loss: 0.965782]\n",
      "epoch:1 step:1404 [D loss: 0.699661, acc.: 55.47%] [G loss: 0.983706]\n",
      "epoch:1 step:1405 [D loss: 0.749293, acc.: 48.44%] [G loss: 0.924489]\n",
      "epoch:1 step:1406 [D loss: 0.690657, acc.: 54.69%] [G loss: 0.862464]\n",
      "epoch:1 step:1407 [D loss: 0.682739, acc.: 57.81%] [G loss: 0.943238]\n",
      "epoch:1 step:1408 [D loss: 0.712761, acc.: 50.78%] [G loss: 0.906237]\n",
      "epoch:1 step:1409 [D loss: 0.727934, acc.: 54.69%] [G loss: 0.990766]\n",
      "epoch:1 step:1410 [D loss: 0.769608, acc.: 42.97%] [G loss: 0.961733]\n",
      "epoch:1 step:1411 [D loss: 0.670954, acc.: 55.47%] [G loss: 1.045740]\n",
      "epoch:1 step:1412 [D loss: 0.643203, acc.: 62.50%] [G loss: 1.141212]\n",
      "epoch:1 step:1413 [D loss: 0.668052, acc.: 57.03%] [G loss: 1.122642]\n",
      "epoch:1 step:1414 [D loss: 0.698058, acc.: 50.00%] [G loss: 1.075690]\n",
      "epoch:1 step:1415 [D loss: 0.700533, acc.: 57.81%] [G loss: 1.088244]\n",
      "epoch:1 step:1416 [D loss: 0.674184, acc.: 57.81%] [G loss: 0.933837]\n",
      "epoch:1 step:1417 [D loss: 0.686087, acc.: 54.69%] [G loss: 0.970758]\n",
      "epoch:1 step:1418 [D loss: 0.675061, acc.: 61.72%] [G loss: 0.927433]\n",
      "epoch:1 step:1419 [D loss: 0.787959, acc.: 40.62%] [G loss: 0.877193]\n",
      "epoch:1 step:1420 [D loss: 0.697042, acc.: 50.78%] [G loss: 0.909766]\n",
      "epoch:1 step:1421 [D loss: 0.677853, acc.: 62.50%] [G loss: 0.848871]\n",
      "epoch:1 step:1422 [D loss: 0.711800, acc.: 53.12%] [G loss: 0.913392]\n",
      "epoch:1 step:1423 [D loss: 0.744782, acc.: 49.22%] [G loss: 0.934365]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1 step:1424 [D loss: 0.719505, acc.: 51.56%] [G loss: 0.927720]\n",
      "epoch:1 step:1425 [D loss: 0.699759, acc.: 58.59%] [G loss: 0.926130]\n",
      "epoch:1 step:1426 [D loss: 0.719001, acc.: 53.12%] [G loss: 0.944345]\n",
      "epoch:1 step:1427 [D loss: 0.630453, acc.: 59.38%] [G loss: 0.898158]\n",
      "epoch:1 step:1428 [D loss: 0.653730, acc.: 60.94%] [G loss: 1.041696]\n",
      "epoch:1 step:1429 [D loss: 0.731649, acc.: 50.00%] [G loss: 1.019919]\n",
      "epoch:1 step:1430 [D loss: 0.681539, acc.: 56.25%] [G loss: 0.954912]\n",
      "epoch:1 step:1431 [D loss: 0.671998, acc.: 57.81%] [G loss: 0.995940]\n",
      "epoch:1 step:1432 [D loss: 0.620224, acc.: 68.75%] [G loss: 0.982928]\n",
      "epoch:1 step:1433 [D loss: 0.662496, acc.: 57.03%] [G loss: 1.035841]\n",
      "epoch:1 step:1434 [D loss: 0.690141, acc.: 54.69%] [G loss: 1.081442]\n",
      "epoch:1 step:1435 [D loss: 0.706540, acc.: 54.69%] [G loss: 0.970350]\n",
      "epoch:1 step:1436 [D loss: 0.656811, acc.: 62.50%] [G loss: 0.979227]\n",
      "epoch:1 step:1437 [D loss: 0.756317, acc.: 50.78%] [G loss: 0.921805]\n",
      "epoch:1 step:1438 [D loss: 0.706000, acc.: 51.56%] [G loss: 0.961086]\n",
      "epoch:1 step:1439 [D loss: 0.731871, acc.: 50.78%] [G loss: 0.884992]\n",
      "epoch:1 step:1440 [D loss: 0.767059, acc.: 48.44%] [G loss: 0.909568]\n",
      "epoch:1 step:1441 [D loss: 0.703335, acc.: 52.34%] [G loss: 1.047734]\n",
      "epoch:1 step:1442 [D loss: 0.665437, acc.: 60.16%] [G loss: 1.006392]\n",
      "epoch:1 step:1443 [D loss: 0.681603, acc.: 57.03%] [G loss: 0.925046]\n",
      "epoch:1 step:1444 [D loss: 0.631106, acc.: 60.94%] [G loss: 1.049590]\n",
      "epoch:1 step:1445 [D loss: 0.641601, acc.: 60.16%] [G loss: 1.044442]\n",
      "epoch:1 step:1446 [D loss: 0.772167, acc.: 43.75%] [G loss: 1.025138]\n",
      "epoch:1 step:1447 [D loss: 0.782903, acc.: 41.41%] [G loss: 0.942929]\n",
      "epoch:1 step:1448 [D loss: 0.752867, acc.: 44.53%] [G loss: 0.951332]\n",
      "epoch:1 step:1449 [D loss: 0.664625, acc.: 63.28%] [G loss: 1.037215]\n",
      "epoch:1 step:1450 [D loss: 0.588455, acc.: 70.31%] [G loss: 1.054431]\n",
      "epoch:1 step:1451 [D loss: 0.673798, acc.: 57.03%] [G loss: 1.133799]\n",
      "epoch:1 step:1452 [D loss: 0.627856, acc.: 66.41%] [G loss: 1.009789]\n",
      "epoch:1 step:1453 [D loss: 0.713832, acc.: 59.38%] [G loss: 1.018439]\n",
      "epoch:1 step:1454 [D loss: 0.783554, acc.: 46.09%] [G loss: 1.009159]\n",
      "epoch:1 step:1455 [D loss: 0.695605, acc.: 58.59%] [G loss: 0.918265]\n",
      "epoch:1 step:1456 [D loss: 0.693884, acc.: 57.03%] [G loss: 0.911763]\n",
      "epoch:1 step:1457 [D loss: 0.635376, acc.: 62.50%] [G loss: 0.923209]\n",
      "epoch:1 step:1458 [D loss: 0.647840, acc.: 64.06%] [G loss: 0.986984]\n",
      "epoch:1 step:1459 [D loss: 0.611400, acc.: 67.97%] [G loss: 1.032197]\n",
      "epoch:1 step:1460 [D loss: 0.685676, acc.: 57.81%] [G loss: 0.994810]\n",
      "epoch:1 step:1461 [D loss: 0.714539, acc.: 56.25%] [G loss: 0.946953]\n",
      "epoch:1 step:1462 [D loss: 0.741643, acc.: 52.34%] [G loss: 0.982885]\n",
      "epoch:1 step:1463 [D loss: 0.781129, acc.: 49.22%] [G loss: 0.904017]\n",
      "epoch:1 step:1464 [D loss: 0.725603, acc.: 53.12%] [G loss: 0.938379]\n",
      "epoch:1 step:1465 [D loss: 0.791691, acc.: 45.31%] [G loss: 0.917881]\n",
      "epoch:1 step:1466 [D loss: 0.703249, acc.: 50.00%] [G loss: 0.884189]\n",
      "epoch:1 step:1467 [D loss: 0.641852, acc.: 64.06%] [G loss: 0.797653]\n",
      "epoch:1 step:1468 [D loss: 0.702859, acc.: 52.34%] [G loss: 0.938799]\n",
      "epoch:1 step:1469 [D loss: 0.770796, acc.: 47.66%] [G loss: 0.943848]\n",
      "epoch:1 step:1470 [D loss: 0.703864, acc.: 55.47%] [G loss: 0.985027]\n",
      "epoch:1 step:1471 [D loss: 0.689438, acc.: 59.38%] [G loss: 0.965925]\n",
      "epoch:1 step:1472 [D loss: 0.741390, acc.: 42.97%] [G loss: 1.052274]\n",
      "epoch:1 step:1473 [D loss: 0.693889, acc.: 55.47%] [G loss: 0.913510]\n",
      "epoch:1 step:1474 [D loss: 0.711885, acc.: 54.69%] [G loss: 0.898513]\n",
      "epoch:1 step:1475 [D loss: 0.693802, acc.: 53.12%] [G loss: 0.945789]\n",
      "epoch:1 step:1476 [D loss: 0.675689, acc.: 59.38%] [G loss: 1.044683]\n",
      "epoch:1 step:1477 [D loss: 0.688484, acc.: 52.34%] [G loss: 0.973279]\n",
      "epoch:1 step:1478 [D loss: 0.653879, acc.: 60.16%] [G loss: 1.006438]\n",
      "epoch:1 step:1479 [D loss: 0.736847, acc.: 53.12%] [G loss: 0.980272]\n",
      "epoch:1 step:1480 [D loss: 0.693049, acc.: 55.47%] [G loss: 1.024142]\n",
      "epoch:1 step:1481 [D loss: 0.722436, acc.: 51.56%] [G loss: 0.965241]\n",
      "epoch:1 step:1482 [D loss: 0.766198, acc.: 44.53%] [G loss: 0.840667]\n",
      "epoch:1 step:1483 [D loss: 0.648164, acc.: 60.94%] [G loss: 0.870635]\n",
      "epoch:1 step:1484 [D loss: 0.742327, acc.: 49.22%] [G loss: 0.917579]\n",
      "epoch:1 step:1485 [D loss: 0.688221, acc.: 56.25%] [G loss: 0.846443]\n",
      "epoch:1 step:1486 [D loss: 0.656117, acc.: 65.62%] [G loss: 0.854063]\n",
      "epoch:1 step:1487 [D loss: 0.683482, acc.: 57.81%] [G loss: 0.974949]\n",
      "epoch:1 step:1488 [D loss: 0.636934, acc.: 62.50%] [G loss: 0.977332]\n",
      "epoch:1 step:1489 [D loss: 0.623671, acc.: 63.28%] [G loss: 0.948202]\n",
      "epoch:1 step:1490 [D loss: 0.721212, acc.: 52.34%] [G loss: 0.981557]\n",
      "epoch:1 step:1491 [D loss: 0.683178, acc.: 56.25%] [G loss: 0.990554]\n",
      "epoch:1 step:1492 [D loss: 0.637205, acc.: 63.28%] [G loss: 0.968547]\n",
      "epoch:1 step:1493 [D loss: 0.631946, acc.: 71.88%] [G loss: 0.927921]\n",
      "epoch:1 step:1494 [D loss: 0.648362, acc.: 61.72%] [G loss: 1.037647]\n",
      "epoch:1 step:1495 [D loss: 0.697540, acc.: 62.50%] [G loss: 1.013613]\n",
      "epoch:1 step:1496 [D loss: 0.784050, acc.: 45.31%] [G loss: 0.998197]\n",
      "epoch:1 step:1497 [D loss: 0.701180, acc.: 56.25%] [G loss: 0.966149]\n",
      "epoch:1 step:1498 [D loss: 0.706035, acc.: 57.03%] [G loss: 0.895708]\n",
      "epoch:1 step:1499 [D loss: 0.732711, acc.: 50.78%] [G loss: 0.860273]\n",
      "epoch:1 step:1500 [D loss: 0.723944, acc.: 50.00%] [G loss: 0.816594]\n",
      "epoch:1 step:1501 [D loss: 0.649781, acc.: 60.94%] [G loss: 0.857173]\n",
      "epoch:1 step:1502 [D loss: 0.738502, acc.: 53.91%] [G loss: 0.928737]\n",
      "epoch:1 step:1503 [D loss: 0.778228, acc.: 46.09%] [G loss: 0.841181]\n",
      "epoch:1 step:1504 [D loss: 0.694961, acc.: 57.81%] [G loss: 0.893084]\n",
      "epoch:1 step:1505 [D loss: 0.670218, acc.: 60.94%] [G loss: 1.019779]\n",
      "epoch:1 step:1506 [D loss: 0.782628, acc.: 51.56%] [G loss: 0.967130]\n",
      "epoch:1 step:1507 [D loss: 0.746893, acc.: 53.12%] [G loss: 0.936571]\n",
      "epoch:1 step:1508 [D loss: 0.689530, acc.: 57.81%] [G loss: 0.930741]\n",
      "epoch:1 step:1509 [D loss: 0.691277, acc.: 54.69%] [G loss: 0.956128]\n",
      "epoch:1 step:1510 [D loss: 0.675536, acc.: 59.38%] [G loss: 0.934922]\n",
      "epoch:1 step:1511 [D loss: 0.648696, acc.: 59.38%] [G loss: 0.995295]\n",
      "epoch:1 step:1512 [D loss: 0.627588, acc.: 60.16%] [G loss: 0.942336]\n",
      "epoch:1 step:1513 [D loss: 0.768270, acc.: 45.31%] [G loss: 0.875418]\n",
      "epoch:1 step:1514 [D loss: 0.749422, acc.: 46.88%] [G loss: 0.894735]\n",
      "epoch:1 step:1515 [D loss: 0.746995, acc.: 54.69%] [G loss: 0.862589]\n",
      "epoch:1 step:1516 [D loss: 0.706800, acc.: 57.03%] [G loss: 0.854212]\n",
      "epoch:1 step:1517 [D loss: 0.709728, acc.: 52.34%] [G loss: 0.967816]\n",
      "epoch:1 step:1518 [D loss: 0.681878, acc.: 57.81%] [G loss: 1.060384]\n",
      "epoch:1 step:1519 [D loss: 0.682731, acc.: 56.25%] [G loss: 0.999362]\n",
      "epoch:1 step:1520 [D loss: 0.691473, acc.: 57.81%] [G loss: 0.958687]\n",
      "epoch:1 step:1521 [D loss: 0.763602, acc.: 46.09%] [G loss: 0.888125]\n",
      "epoch:1 step:1522 [D loss: 0.740366, acc.: 50.00%] [G loss: 1.032299]\n",
      "epoch:1 step:1523 [D loss: 0.688095, acc.: 61.72%] [G loss: 0.916435]\n",
      "epoch:1 step:1524 [D loss: 0.727751, acc.: 56.25%] [G loss: 0.938267]\n",
      "epoch:1 step:1525 [D loss: 0.678518, acc.: 55.47%] [G loss: 1.021216]\n",
      "epoch:1 step:1526 [D loss: 0.599414, acc.: 66.41%] [G loss: 1.019287]\n",
      "epoch:1 step:1527 [D loss: 0.735892, acc.: 54.69%] [G loss: 0.947557]\n",
      "epoch:1 step:1528 [D loss: 0.751167, acc.: 49.22%] [G loss: 0.986093]\n",
      "epoch:1 step:1529 [D loss: 0.756853, acc.: 54.69%] [G loss: 0.919496]\n",
      "epoch:1 step:1530 [D loss: 0.703846, acc.: 53.91%] [G loss: 1.002361]\n",
      "epoch:1 step:1531 [D loss: 0.715377, acc.: 55.47%] [G loss: 1.051433]\n",
      "epoch:1 step:1532 [D loss: 0.617250, acc.: 63.28%] [G loss: 1.045078]\n",
      "epoch:1 step:1533 [D loss: 0.695163, acc.: 52.34%] [G loss: 1.204839]\n",
      "epoch:1 step:1534 [D loss: 0.640506, acc.: 60.94%] [G loss: 1.166000]\n",
      "epoch:1 step:1535 [D loss: 0.645665, acc.: 62.50%] [G loss: 1.074403]\n",
      "epoch:1 step:1536 [D loss: 0.664344, acc.: 59.38%] [G loss: 1.060501]\n",
      "epoch:1 step:1537 [D loss: 0.696140, acc.: 58.59%] [G loss: 0.857389]\n",
      "epoch:1 step:1538 [D loss: 0.706891, acc.: 56.25%] [G loss: 0.861472]\n",
      "epoch:1 step:1539 [D loss: 0.697659, acc.: 55.47%] [G loss: 1.023122]\n",
      "epoch:1 step:1540 [D loss: 0.724194, acc.: 50.00%] [G loss: 0.905056]\n",
      "epoch:1 step:1541 [D loss: 0.736927, acc.: 53.91%] [G loss: 0.876301]\n",
      "epoch:1 step:1542 [D loss: 0.719196, acc.: 54.69%] [G loss: 0.888853]\n",
      "epoch:1 step:1543 [D loss: 0.714443, acc.: 48.44%] [G loss: 0.927474]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1 step:1544 [D loss: 0.702107, acc.: 49.22%] [G loss: 1.014018]\n",
      "epoch:1 step:1545 [D loss: 0.727990, acc.: 46.09%] [G loss: 0.783993]\n",
      "epoch:1 step:1546 [D loss: 0.680805, acc.: 56.25%] [G loss: 0.781557]\n",
      "epoch:1 step:1547 [D loss: 0.717260, acc.: 53.12%] [G loss: 0.837943]\n",
      "epoch:1 step:1548 [D loss: 0.744806, acc.: 52.34%] [G loss: 0.980073]\n",
      "epoch:1 step:1549 [D loss: 0.656709, acc.: 60.16%] [G loss: 0.983640]\n",
      "epoch:1 step:1550 [D loss: 0.712001, acc.: 54.69%] [G loss: 0.944599]\n",
      "epoch:1 step:1551 [D loss: 0.755020, acc.: 43.75%] [G loss: 0.885367]\n",
      "epoch:1 step:1552 [D loss: 0.711477, acc.: 56.25%] [G loss: 0.911843]\n",
      "epoch:1 step:1553 [D loss: 0.702309, acc.: 56.25%] [G loss: 0.879172]\n",
      "epoch:1 step:1554 [D loss: 0.668571, acc.: 60.94%] [G loss: 0.965087]\n",
      "epoch:1 step:1555 [D loss: 0.618297, acc.: 67.19%] [G loss: 0.902958]\n",
      "epoch:1 step:1556 [D loss: 0.642738, acc.: 62.50%] [G loss: 0.970118]\n",
      "epoch:1 step:1557 [D loss: 0.649187, acc.: 57.81%] [G loss: 1.081730]\n",
      "epoch:1 step:1558 [D loss: 0.702398, acc.: 59.38%] [G loss: 0.918604]\n",
      "epoch:1 step:1559 [D loss: 0.724198, acc.: 44.53%] [G loss: 0.845689]\n",
      "epoch:1 step:1560 [D loss: 0.748802, acc.: 50.00%] [G loss: 0.945646]\n",
      "epoch:1 step:1561 [D loss: 0.682059, acc.: 57.03%] [G loss: 0.952893]\n",
      "epoch:1 step:1562 [D loss: 0.706877, acc.: 52.34%] [G loss: 0.882532]\n",
      "epoch:1 step:1563 [D loss: 0.693634, acc.: 54.69%] [G loss: 0.970143]\n",
      "epoch:1 step:1564 [D loss: 0.677914, acc.: 57.03%] [G loss: 0.950090]\n",
      "epoch:1 step:1565 [D loss: 0.669169, acc.: 62.50%] [G loss: 0.993893]\n",
      "epoch:1 step:1566 [D loss: 0.666770, acc.: 59.38%] [G loss: 0.965271]\n",
      "epoch:1 step:1567 [D loss: 0.680110, acc.: 62.50%] [G loss: 0.979072]\n",
      "epoch:1 step:1568 [D loss: 0.680664, acc.: 55.47%] [G loss: 0.976114]\n",
      "epoch:1 step:1569 [D loss: 0.692439, acc.: 55.47%] [G loss: 0.931305]\n",
      "epoch:1 step:1570 [D loss: 0.761579, acc.: 43.75%] [G loss: 0.885318]\n",
      "epoch:1 step:1571 [D loss: 0.754636, acc.: 51.56%] [G loss: 0.892763]\n",
      "epoch:1 step:1572 [D loss: 0.656291, acc.: 53.91%] [G loss: 1.009894]\n",
      "epoch:1 step:1573 [D loss: 0.739978, acc.: 46.88%] [G loss: 0.893394]\n",
      "epoch:1 step:1574 [D loss: 0.668186, acc.: 59.38%] [G loss: 0.822199]\n",
      "epoch:1 step:1575 [D loss: 0.797560, acc.: 43.75%] [G loss: 0.902538]\n",
      "epoch:1 step:1576 [D loss: 0.722962, acc.: 53.12%] [G loss: 0.961206]\n",
      "epoch:1 step:1577 [D loss: 0.754474, acc.: 47.66%] [G loss: 0.927567]\n",
      "epoch:1 step:1578 [D loss: 0.733489, acc.: 51.56%] [G loss: 0.901898]\n",
      "epoch:1 step:1579 [D loss: 0.695002, acc.: 56.25%] [G loss: 0.906391]\n",
      "epoch:1 step:1580 [D loss: 0.738147, acc.: 50.78%] [G loss: 0.972088]\n",
      "epoch:1 step:1581 [D loss: 0.719817, acc.: 47.66%] [G loss: 0.965071]\n",
      "epoch:1 step:1582 [D loss: 0.723145, acc.: 51.56%] [G loss: 0.873156]\n",
      "epoch:1 step:1583 [D loss: 0.706680, acc.: 56.25%] [G loss: 0.900784]\n",
      "epoch:1 step:1584 [D loss: 0.726824, acc.: 50.78%] [G loss: 0.909803]\n",
      "epoch:1 step:1585 [D loss: 0.625070, acc.: 65.62%] [G loss: 0.959017]\n",
      "epoch:1 step:1586 [D loss: 0.672802, acc.: 54.69%] [G loss: 0.908413]\n",
      "epoch:1 step:1587 [D loss: 0.667802, acc.: 59.38%] [G loss: 0.843601]\n",
      "epoch:1 step:1588 [D loss: 0.696666, acc.: 57.81%] [G loss: 0.940522]\n",
      "epoch:1 step:1589 [D loss: 0.720294, acc.: 50.78%] [G loss: 0.912306]\n",
      "epoch:1 step:1590 [D loss: 0.684792, acc.: 54.69%] [G loss: 0.919429]\n",
      "epoch:1 step:1591 [D loss: 0.773695, acc.: 47.66%] [G loss: 0.951450]\n",
      "epoch:1 step:1592 [D loss: 0.769390, acc.: 48.44%] [G loss: 0.892702]\n",
      "epoch:1 step:1593 [D loss: 0.760426, acc.: 38.28%] [G loss: 0.856831]\n",
      "epoch:1 step:1594 [D loss: 0.719538, acc.: 50.78%] [G loss: 0.912006]\n",
      "epoch:1 step:1595 [D loss: 0.690216, acc.: 53.12%] [G loss: 0.911162]\n",
      "epoch:1 step:1596 [D loss: 0.620432, acc.: 62.50%] [G loss: 0.993188]\n",
      "epoch:1 step:1597 [D loss: 0.618940, acc.: 67.97%] [G loss: 1.078898]\n",
      "epoch:1 step:1598 [D loss: 0.609667, acc.: 64.06%] [G loss: 0.994822]\n",
      "epoch:1 step:1599 [D loss: 0.713440, acc.: 56.25%] [G loss: 0.933283]\n",
      "epoch:1 step:1600 [D loss: 0.764449, acc.: 46.09%] [G loss: 0.967628]\n",
      "##############\n",
      "[3.94450742 2.242205   6.43472384 5.17972688 4.39697732 5.66220389\n",
      " 5.26942865 5.4153856  5.6245098  4.79563525]\n",
      "##########\n",
      "epoch:1 step:1601 [D loss: 0.714397, acc.: 50.00%] [G loss: 0.887420]\n",
      "epoch:1 step:1602 [D loss: 0.787437, acc.: 40.62%] [G loss: 0.875202]\n",
      "epoch:1 step:1603 [D loss: 0.695146, acc.: 50.78%] [G loss: 0.867218]\n",
      "epoch:1 step:1604 [D loss: 0.690304, acc.: 53.91%] [G loss: 0.894747]\n",
      "epoch:1 step:1605 [D loss: 0.679685, acc.: 54.69%] [G loss: 0.859064]\n",
      "epoch:1 step:1606 [D loss: 0.718115, acc.: 53.12%] [G loss: 0.869993]\n",
      "epoch:1 step:1607 [D loss: 0.691520, acc.: 50.78%] [G loss: 0.919481]\n",
      "epoch:1 step:1608 [D loss: 0.710783, acc.: 54.69%] [G loss: 0.945772]\n",
      "epoch:1 step:1609 [D loss: 0.700909, acc.: 53.12%] [G loss: 0.948617]\n",
      "epoch:1 step:1610 [D loss: 0.672121, acc.: 60.16%] [G loss: 0.882543]\n",
      "epoch:1 step:1611 [D loss: 0.622148, acc.: 65.62%] [G loss: 0.974457]\n",
      "epoch:1 step:1612 [D loss: 0.712953, acc.: 53.91%] [G loss: 0.902316]\n",
      "epoch:1 step:1613 [D loss: 0.726151, acc.: 49.22%] [G loss: 0.886761]\n",
      "epoch:1 step:1614 [D loss: 0.676757, acc.: 57.81%] [G loss: 0.807992]\n",
      "epoch:1 step:1615 [D loss: 0.722427, acc.: 50.78%] [G loss: 0.970395]\n",
      "epoch:1 step:1616 [D loss: 0.660124, acc.: 59.38%] [G loss: 0.970844]\n",
      "epoch:1 step:1617 [D loss: 0.671124, acc.: 60.16%] [G loss: 0.904995]\n",
      "epoch:1 step:1618 [D loss: 0.672366, acc.: 57.81%] [G loss: 0.831120]\n",
      "epoch:1 step:1619 [D loss: 0.702537, acc.: 53.91%] [G loss: 0.913291]\n",
      "epoch:1 step:1620 [D loss: 0.675787, acc.: 54.69%] [G loss: 0.880797]\n",
      "epoch:1 step:1621 [D loss: 0.650531, acc.: 61.72%] [G loss: 0.942281]\n",
      "epoch:1 step:1622 [D loss: 0.682303, acc.: 51.56%] [G loss: 0.781792]\n",
      "epoch:1 step:1623 [D loss: 0.726075, acc.: 53.91%] [G loss: 0.886996]\n",
      "epoch:1 step:1624 [D loss: 0.706875, acc.: 53.12%] [G loss: 0.884460]\n",
      "epoch:1 step:1625 [D loss: 0.696168, acc.: 55.47%] [G loss: 0.920066]\n",
      "epoch:1 step:1626 [D loss: 0.698382, acc.: 53.91%] [G loss: 0.951998]\n",
      "epoch:1 step:1627 [D loss: 0.713992, acc.: 53.91%] [G loss: 0.904623]\n",
      "epoch:1 step:1628 [D loss: 0.742883, acc.: 45.31%] [G loss: 0.942272]\n",
      "epoch:1 step:1629 [D loss: 0.678048, acc.: 57.81%] [G loss: 0.934261]\n",
      "epoch:1 step:1630 [D loss: 0.688774, acc.: 54.69%] [G loss: 0.951603]\n",
      "epoch:1 step:1631 [D loss: 0.704971, acc.: 51.56%] [G loss: 0.912815]\n",
      "epoch:1 step:1632 [D loss: 0.680332, acc.: 57.03%] [G loss: 0.953072]\n",
      "epoch:1 step:1633 [D loss: 0.764717, acc.: 42.97%] [G loss: 0.888672]\n",
      "epoch:1 step:1634 [D loss: 0.718632, acc.: 46.88%] [G loss: 0.893145]\n",
      "epoch:1 step:1635 [D loss: 0.723467, acc.: 48.44%] [G loss: 0.834823]\n",
      "epoch:1 step:1636 [D loss: 0.691888, acc.: 56.25%] [G loss: 0.966776]\n",
      "epoch:1 step:1637 [D loss: 0.750454, acc.: 48.44%] [G loss: 0.959200]\n",
      "epoch:1 step:1638 [D loss: 0.679158, acc.: 57.03%] [G loss: 0.984109]\n",
      "epoch:1 step:1639 [D loss: 0.734198, acc.: 44.53%] [G loss: 0.891196]\n",
      "epoch:1 step:1640 [D loss: 0.717904, acc.: 46.09%] [G loss: 0.966586]\n",
      "epoch:1 step:1641 [D loss: 0.681811, acc.: 56.25%] [G loss: 0.907519]\n",
      "epoch:1 step:1642 [D loss: 0.662448, acc.: 55.47%] [G loss: 0.881592]\n",
      "epoch:1 step:1643 [D loss: 0.734113, acc.: 46.88%] [G loss: 0.859825]\n",
      "epoch:1 step:1644 [D loss: 0.720673, acc.: 47.66%] [G loss: 0.924993]\n",
      "epoch:1 step:1645 [D loss: 0.643976, acc.: 66.41%] [G loss: 0.982975]\n",
      "epoch:1 step:1646 [D loss: 0.678478, acc.: 58.59%] [G loss: 0.961811]\n",
      "epoch:1 step:1647 [D loss: 0.814909, acc.: 39.84%] [G loss: 0.940571]\n",
      "epoch:1 step:1648 [D loss: 0.708254, acc.: 47.66%] [G loss: 0.883605]\n",
      "epoch:1 step:1649 [D loss: 0.703931, acc.: 49.22%] [G loss: 0.951928]\n",
      "epoch:1 step:1650 [D loss: 0.622620, acc.: 62.50%] [G loss: 0.891354]\n",
      "epoch:1 step:1651 [D loss: 0.689976, acc.: 54.69%] [G loss: 0.918984]\n",
      "epoch:1 step:1652 [D loss: 0.708062, acc.: 52.34%] [G loss: 0.799943]\n",
      "epoch:1 step:1653 [D loss: 0.716180, acc.: 53.91%] [G loss: 0.780783]\n",
      "epoch:1 step:1654 [D loss: 0.694064, acc.: 57.81%] [G loss: 0.965365]\n",
      "epoch:1 step:1655 [D loss: 0.639240, acc.: 64.06%] [G loss: 0.922455]\n",
      "epoch:1 step:1656 [D loss: 0.692376, acc.: 55.47%] [G loss: 0.954197]\n",
      "epoch:1 step:1657 [D loss: 0.672463, acc.: 55.47%] [G loss: 0.896939]\n",
      "epoch:1 step:1658 [D loss: 0.749574, acc.: 47.66%] [G loss: 0.861754]\n",
      "epoch:1 step:1659 [D loss: 0.742169, acc.: 51.56%] [G loss: 0.898872]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1 step:1660 [D loss: 0.729544, acc.: 50.00%] [G loss: 0.841990]\n",
      "epoch:1 step:1661 [D loss: 0.720142, acc.: 48.44%] [G loss: 0.900191]\n",
      "epoch:1 step:1662 [D loss: 0.691883, acc.: 53.12%] [G loss: 0.895096]\n",
      "epoch:1 step:1663 [D loss: 0.687368, acc.: 56.25%] [G loss: 0.988626]\n",
      "epoch:1 step:1664 [D loss: 0.669437, acc.: 62.50%] [G loss: 1.019877]\n",
      "epoch:1 step:1665 [D loss: 0.684733, acc.: 57.03%] [G loss: 1.034990]\n",
      "epoch:1 step:1666 [D loss: 0.653562, acc.: 57.03%] [G loss: 0.993692]\n",
      "epoch:1 step:1667 [D loss: 0.604791, acc.: 68.75%] [G loss: 0.896001]\n",
      "epoch:1 step:1668 [D loss: 0.644141, acc.: 64.84%] [G loss: 1.013381]\n",
      "epoch:1 step:1669 [D loss: 0.646057, acc.: 63.28%] [G loss: 0.968470]\n",
      "epoch:1 step:1670 [D loss: 0.654495, acc.: 64.84%] [G loss: 0.876088]\n",
      "epoch:1 step:1671 [D loss: 0.738092, acc.: 47.66%] [G loss: 0.841470]\n",
      "epoch:1 step:1672 [D loss: 0.794903, acc.: 41.41%] [G loss: 0.821549]\n",
      "epoch:1 step:1673 [D loss: 0.751843, acc.: 48.44%] [G loss: 0.819831]\n",
      "epoch:1 step:1674 [D loss: 0.714985, acc.: 48.44%] [G loss: 0.897105]\n",
      "epoch:1 step:1675 [D loss: 0.659833, acc.: 57.03%] [G loss: 0.909045]\n",
      "epoch:1 step:1676 [D loss: 0.687407, acc.: 59.38%] [G loss: 0.896726]\n",
      "epoch:1 step:1677 [D loss: 0.705683, acc.: 53.12%] [G loss: 0.844906]\n",
      "epoch:1 step:1678 [D loss: 0.735517, acc.: 47.66%] [G loss: 0.871657]\n",
      "epoch:1 step:1679 [D loss: 0.783864, acc.: 42.19%] [G loss: 0.829815]\n",
      "epoch:1 step:1680 [D loss: 0.731038, acc.: 51.56%] [G loss: 0.837431]\n",
      "epoch:1 step:1681 [D loss: 0.675788, acc.: 55.47%] [G loss: 0.949901]\n",
      "epoch:1 step:1682 [D loss: 0.728143, acc.: 50.00%] [G loss: 0.853257]\n",
      "epoch:1 step:1683 [D loss: 0.687221, acc.: 52.34%] [G loss: 0.952044]\n",
      "epoch:1 step:1684 [D loss: 0.647349, acc.: 62.50%] [G loss: 0.948387]\n",
      "epoch:1 step:1685 [D loss: 0.751088, acc.: 44.53%] [G loss: 0.927739]\n",
      "epoch:1 step:1686 [D loss: 0.730289, acc.: 40.62%] [G loss: 0.848800]\n",
      "epoch:1 step:1687 [D loss: 0.701496, acc.: 52.34%] [G loss: 0.902431]\n",
      "epoch:1 step:1688 [D loss: 0.713640, acc.: 50.78%] [G loss: 0.856486]\n",
      "epoch:1 step:1689 [D loss: 0.721859, acc.: 54.69%] [G loss: 0.816281]\n",
      "epoch:1 step:1690 [D loss: 0.698369, acc.: 57.81%] [G loss: 0.917888]\n",
      "epoch:1 step:1691 [D loss: 0.732849, acc.: 51.56%] [G loss: 0.834898]\n",
      "epoch:1 step:1692 [D loss: 0.725940, acc.: 49.22%] [G loss: 0.900254]\n",
      "epoch:1 step:1693 [D loss: 0.666651, acc.: 58.59%] [G loss: 0.789217]\n",
      "epoch:1 step:1694 [D loss: 0.670628, acc.: 56.25%] [G loss: 0.830415]\n",
      "epoch:1 step:1695 [D loss: 0.789978, acc.: 38.28%] [G loss: 0.904777]\n",
      "epoch:1 step:1696 [D loss: 0.673062, acc.: 60.16%] [G loss: 0.934556]\n",
      "epoch:1 step:1697 [D loss: 0.714613, acc.: 54.69%] [G loss: 0.917655]\n",
      "epoch:1 step:1698 [D loss: 0.657619, acc.: 62.50%] [G loss: 0.976856]\n",
      "epoch:1 step:1699 [D loss: 0.695039, acc.: 60.94%] [G loss: 0.921821]\n",
      "epoch:1 step:1700 [D loss: 0.678744, acc.: 61.72%] [G loss: 0.972736]\n",
      "epoch:1 step:1701 [D loss: 0.691497, acc.: 53.12%] [G loss: 0.818620]\n",
      "epoch:1 step:1702 [D loss: 0.676117, acc.: 53.12%] [G loss: 0.893592]\n",
      "epoch:1 step:1703 [D loss: 0.613221, acc.: 64.06%] [G loss: 0.918032]\n",
      "epoch:1 step:1704 [D loss: 0.663298, acc.: 59.38%] [G loss: 0.915797]\n",
      "epoch:1 step:1705 [D loss: 0.720588, acc.: 53.12%] [G loss: 0.897704]\n",
      "epoch:1 step:1706 [D loss: 0.746260, acc.: 50.00%] [G loss: 0.877054]\n",
      "epoch:1 step:1707 [D loss: 0.709531, acc.: 54.69%] [G loss: 0.887925]\n",
      "epoch:1 step:1708 [D loss: 0.715131, acc.: 53.12%] [G loss: 0.897327]\n",
      "epoch:1 step:1709 [D loss: 0.735388, acc.: 53.91%] [G loss: 0.944140]\n",
      "epoch:1 step:1710 [D loss: 0.697413, acc.: 56.25%] [G loss: 0.925163]\n",
      "epoch:1 step:1711 [D loss: 0.668582, acc.: 60.16%] [G loss: 0.969515]\n",
      "epoch:1 step:1712 [D loss: 0.685513, acc.: 58.59%] [G loss: 0.978426]\n",
      "epoch:1 step:1713 [D loss: 0.732724, acc.: 50.00%] [G loss: 0.904538]\n",
      "epoch:1 step:1714 [D loss: 0.700814, acc.: 46.88%] [G loss: 0.925712]\n",
      "epoch:1 step:1715 [D loss: 0.653387, acc.: 62.50%] [G loss: 0.986580]\n",
      "epoch:1 step:1716 [D loss: 0.728213, acc.: 53.12%] [G loss: 0.934066]\n",
      "epoch:1 step:1717 [D loss: 0.728089, acc.: 53.12%] [G loss: 0.969185]\n",
      "epoch:1 step:1718 [D loss: 0.711603, acc.: 48.44%] [G loss: 0.875647]\n",
      "epoch:1 step:1719 [D loss: 0.646871, acc.: 62.50%] [G loss: 0.914863]\n",
      "epoch:1 step:1720 [D loss: 0.739896, acc.: 53.91%] [G loss: 0.888269]\n",
      "epoch:1 step:1721 [D loss: 0.754898, acc.: 48.44%] [G loss: 0.828567]\n",
      "epoch:1 step:1722 [D loss: 0.701404, acc.: 54.69%] [G loss: 0.863507]\n",
      "epoch:1 step:1723 [D loss: 0.692366, acc.: 58.59%] [G loss: 0.936297]\n",
      "epoch:1 step:1724 [D loss: 0.760881, acc.: 46.09%] [G loss: 0.846555]\n",
      "epoch:1 step:1725 [D loss: 0.719065, acc.: 48.44%] [G loss: 0.929901]\n",
      "epoch:1 step:1726 [D loss: 0.720335, acc.: 51.56%] [G loss: 0.878451]\n",
      "epoch:1 step:1727 [D loss: 0.716193, acc.: 48.44%] [G loss: 0.864441]\n",
      "epoch:1 step:1728 [D loss: 0.811197, acc.: 39.84%] [G loss: 0.850462]\n",
      "epoch:1 step:1729 [D loss: 0.693430, acc.: 55.47%] [G loss: 0.866621]\n",
      "epoch:1 step:1730 [D loss: 0.700664, acc.: 56.25%] [G loss: 0.906749]\n",
      "epoch:1 step:1731 [D loss: 0.712980, acc.: 52.34%] [G loss: 0.915427]\n",
      "epoch:1 step:1732 [D loss: 0.739640, acc.: 47.66%] [G loss: 0.882227]\n",
      "epoch:1 step:1733 [D loss: 0.695579, acc.: 56.25%] [G loss: 0.875151]\n",
      "epoch:1 step:1734 [D loss: 0.694167, acc.: 56.25%] [G loss: 0.941962]\n",
      "epoch:1 step:1735 [D loss: 0.663483, acc.: 60.94%] [G loss: 0.920920]\n",
      "epoch:1 step:1736 [D loss: 0.698960, acc.: 54.69%] [G loss: 0.856750]\n",
      "epoch:1 step:1737 [D loss: 0.747927, acc.: 53.12%] [G loss: 0.834154]\n",
      "epoch:1 step:1738 [D loss: 0.695354, acc.: 52.34%] [G loss: 0.885226]\n",
      "epoch:1 step:1739 [D loss: 0.640969, acc.: 64.84%] [G loss: 0.952455]\n",
      "epoch:1 step:1740 [D loss: 0.672060, acc.: 60.94%] [G loss: 0.882229]\n",
      "epoch:1 step:1741 [D loss: 0.735606, acc.: 57.03%] [G loss: 0.793902]\n",
      "epoch:1 step:1742 [D loss: 0.714313, acc.: 50.78%] [G loss: 0.867317]\n",
      "epoch:1 step:1743 [D loss: 0.701078, acc.: 50.00%] [G loss: 0.854270]\n",
      "epoch:1 step:1744 [D loss: 0.704796, acc.: 53.91%] [G loss: 0.872240]\n",
      "epoch:1 step:1745 [D loss: 0.743627, acc.: 45.31%] [G loss: 0.834575]\n",
      "epoch:1 step:1746 [D loss: 0.678282, acc.: 54.69%] [G loss: 0.866584]\n",
      "epoch:1 step:1747 [D loss: 0.695731, acc.: 59.38%] [G loss: 0.858581]\n",
      "epoch:1 step:1748 [D loss: 0.722143, acc.: 50.00%] [G loss: 0.873648]\n",
      "epoch:1 step:1749 [D loss: 0.719603, acc.: 50.00%] [G loss: 0.806822]\n",
      "epoch:1 step:1750 [D loss: 0.713196, acc.: 53.12%] [G loss: 0.829531]\n",
      "epoch:1 step:1751 [D loss: 0.715269, acc.: 50.00%] [G loss: 0.897762]\n",
      "epoch:1 step:1752 [D loss: 0.691793, acc.: 55.47%] [G loss: 0.869123]\n",
      "epoch:1 step:1753 [D loss: 0.685363, acc.: 53.12%] [G loss: 0.877421]\n",
      "epoch:1 step:1754 [D loss: 0.688838, acc.: 58.59%] [G loss: 0.823144]\n",
      "epoch:1 step:1755 [D loss: 0.748199, acc.: 42.19%] [G loss: 0.836931]\n",
      "epoch:1 step:1756 [D loss: 0.716250, acc.: 50.78%] [G loss: 0.872726]\n",
      "epoch:1 step:1757 [D loss: 0.782407, acc.: 42.19%] [G loss: 0.844695]\n",
      "epoch:1 step:1758 [D loss: 0.720278, acc.: 46.88%] [G loss: 0.897769]\n",
      "epoch:1 step:1759 [D loss: 0.714720, acc.: 50.78%] [G loss: 0.880744]\n",
      "epoch:1 step:1760 [D loss: 0.669813, acc.: 62.50%] [G loss: 0.866421]\n",
      "epoch:1 step:1761 [D loss: 0.704051, acc.: 51.56%] [G loss: 0.920488]\n",
      "epoch:1 step:1762 [D loss: 0.722284, acc.: 47.66%] [G loss: 0.836754]\n",
      "epoch:1 step:1763 [D loss: 0.718808, acc.: 46.09%] [G loss: 0.891359]\n",
      "epoch:1 step:1764 [D loss: 0.736470, acc.: 45.31%] [G loss: 0.873392]\n",
      "epoch:1 step:1765 [D loss: 0.689504, acc.: 53.91%] [G loss: 0.815005]\n",
      "epoch:1 step:1766 [D loss: 0.670923, acc.: 59.38%] [G loss: 0.917490]\n",
      "epoch:1 step:1767 [D loss: 0.690864, acc.: 53.12%] [G loss: 0.808979]\n",
      "epoch:1 step:1768 [D loss: 0.719399, acc.: 49.22%] [G loss: 0.906384]\n",
      "epoch:1 step:1769 [D loss: 0.725214, acc.: 51.56%] [G loss: 0.902710]\n",
      "epoch:1 step:1770 [D loss: 0.708889, acc.: 50.00%] [G loss: 0.874997]\n",
      "epoch:1 step:1771 [D loss: 0.690681, acc.: 55.47%] [G loss: 0.975561]\n",
      "epoch:1 step:1772 [D loss: 0.767071, acc.: 45.31%] [G loss: 0.849234]\n",
      "epoch:1 step:1773 [D loss: 0.649875, acc.: 58.59%] [G loss: 0.905793]\n",
      "epoch:1 step:1774 [D loss: 0.641299, acc.: 67.19%] [G loss: 0.889290]\n",
      "epoch:1 step:1775 [D loss: 0.663784, acc.: 57.81%] [G loss: 0.899746]\n",
      "epoch:1 step:1776 [D loss: 0.656997, acc.: 64.06%] [G loss: 0.876145]\n",
      "epoch:1 step:1777 [D loss: 0.660294, acc.: 59.38%] [G loss: 0.906163]\n",
      "epoch:1 step:1778 [D loss: 0.675597, acc.: 54.69%] [G loss: 0.875748]\n",
      "epoch:1 step:1779 [D loss: 0.658566, acc.: 60.94%] [G loss: 0.878438]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1 step:1780 [D loss: 0.781879, acc.: 40.62%] [G loss: 0.850566]\n",
      "epoch:1 step:1781 [D loss: 0.704063, acc.: 50.00%] [G loss: 0.906459]\n",
      "epoch:1 step:1782 [D loss: 0.729005, acc.: 50.00%] [G loss: 0.867968]\n",
      "epoch:1 step:1783 [D loss: 0.659833, acc.: 56.25%] [G loss: 0.884202]\n",
      "epoch:1 step:1784 [D loss: 0.714631, acc.: 45.31%] [G loss: 0.967688]\n",
      "epoch:1 step:1785 [D loss: 0.742401, acc.: 50.00%] [G loss: 0.921768]\n",
      "epoch:1 step:1786 [D loss: 0.660551, acc.: 60.94%] [G loss: 0.947290]\n",
      "epoch:1 step:1787 [D loss: 0.744809, acc.: 50.00%] [G loss: 0.923896]\n",
      "epoch:1 step:1788 [D loss: 0.636181, acc.: 62.50%] [G loss: 1.008065]\n",
      "epoch:1 step:1789 [D loss: 0.629066, acc.: 62.50%] [G loss: 0.994881]\n",
      "epoch:1 step:1790 [D loss: 0.687205, acc.: 54.69%] [G loss: 0.968778]\n",
      "epoch:1 step:1791 [D loss: 0.681887, acc.: 57.81%] [G loss: 0.984012]\n",
      "epoch:1 step:1792 [D loss: 0.704893, acc.: 53.12%] [G loss: 0.799502]\n",
      "epoch:1 step:1793 [D loss: 0.727536, acc.: 48.44%] [G loss: 0.898645]\n",
      "epoch:1 step:1794 [D loss: 0.672091, acc.: 58.59%] [G loss: 0.893438]\n",
      "epoch:1 step:1795 [D loss: 0.810831, acc.: 37.50%] [G loss: 0.912789]\n",
      "epoch:1 step:1796 [D loss: 0.731260, acc.: 46.88%] [G loss: 0.938912]\n",
      "epoch:1 step:1797 [D loss: 0.687823, acc.: 53.91%] [G loss: 0.930788]\n",
      "epoch:1 step:1798 [D loss: 0.719418, acc.: 54.69%] [G loss: 0.991447]\n",
      "epoch:1 step:1799 [D loss: 0.704898, acc.: 46.09%] [G loss: 0.843296]\n",
      "epoch:1 step:1800 [D loss: 0.702995, acc.: 55.47%] [G loss: 0.853773]\n",
      "##############\n",
      "[4.43675382 2.56155225 6.26957257 5.41167481 4.42756992 6.11801904\n",
      " 5.08395539 5.59654771 6.05295361 4.81407788]\n",
      "##########\n",
      "epoch:1 step:1801 [D loss: 0.727749, acc.: 52.34%] [G loss: 0.907246]\n",
      "epoch:1 step:1802 [D loss: 0.763809, acc.: 47.66%] [G loss: 0.859616]\n",
      "epoch:1 step:1803 [D loss: 0.695622, acc.: 52.34%] [G loss: 0.928061]\n",
      "epoch:1 step:1804 [D loss: 0.735437, acc.: 45.31%] [G loss: 0.871957]\n",
      "epoch:1 step:1805 [D loss: 0.755935, acc.: 50.00%] [G loss: 0.853595]\n",
      "epoch:1 step:1806 [D loss: 0.750296, acc.: 50.00%] [G loss: 0.829514]\n",
      "epoch:1 step:1807 [D loss: 0.707815, acc.: 53.91%] [G loss: 0.856142]\n",
      "epoch:1 step:1808 [D loss: 0.711060, acc.: 52.34%] [G loss: 0.885683]\n",
      "epoch:1 step:1809 [D loss: 0.688847, acc.: 57.03%] [G loss: 0.864771]\n",
      "epoch:1 step:1810 [D loss: 0.680633, acc.: 56.25%] [G loss: 0.935685]\n",
      "epoch:1 step:1811 [D loss: 0.686385, acc.: 53.12%] [G loss: 0.864647]\n",
      "epoch:1 step:1812 [D loss: 0.604652, acc.: 68.75%] [G loss: 0.931316]\n",
      "epoch:1 step:1813 [D loss: 0.708480, acc.: 52.34%] [G loss: 0.939945]\n",
      "epoch:1 step:1814 [D loss: 0.727592, acc.: 46.88%] [G loss: 0.907455]\n",
      "epoch:1 step:1815 [D loss: 0.766598, acc.: 42.19%] [G loss: 0.834007]\n",
      "epoch:1 step:1816 [D loss: 0.729096, acc.: 46.88%] [G loss: 0.785497]\n",
      "epoch:1 step:1817 [D loss: 0.734330, acc.: 49.22%] [G loss: 0.804786]\n",
      "epoch:1 step:1818 [D loss: 0.699034, acc.: 50.78%] [G loss: 0.845511]\n",
      "epoch:1 step:1819 [D loss: 0.741420, acc.: 47.66%] [G loss: 0.796480]\n",
      "epoch:1 step:1820 [D loss: 0.750921, acc.: 50.00%] [G loss: 0.792908]\n",
      "epoch:1 step:1821 [D loss: 0.693707, acc.: 53.91%] [G loss: 0.883512]\n",
      "epoch:1 step:1822 [D loss: 0.682928, acc.: 54.69%] [G loss: 0.848413]\n",
      "epoch:1 step:1823 [D loss: 0.654602, acc.: 61.72%] [G loss: 0.886211]\n",
      "epoch:1 step:1824 [D loss: 0.683603, acc.: 59.38%] [G loss: 0.935068]\n",
      "epoch:1 step:1825 [D loss: 0.723118, acc.: 51.56%] [G loss: 0.886638]\n",
      "epoch:1 step:1826 [D loss: 0.671140, acc.: 53.91%] [G loss: 0.889906]\n",
      "epoch:1 step:1827 [D loss: 0.698142, acc.: 57.03%] [G loss: 0.846857]\n",
      "epoch:1 step:1828 [D loss: 0.749314, acc.: 50.78%] [G loss: 0.940263]\n",
      "epoch:1 step:1829 [D loss: 0.788101, acc.: 40.62%] [G loss: 0.819935]\n",
      "epoch:1 step:1830 [D loss: 0.725485, acc.: 47.66%] [G loss: 0.755130]\n",
      "epoch:1 step:1831 [D loss: 0.720938, acc.: 47.66%] [G loss: 0.815063]\n",
      "epoch:1 step:1832 [D loss: 0.727273, acc.: 50.78%] [G loss: 0.879186]\n",
      "epoch:1 step:1833 [D loss: 0.691699, acc.: 57.03%] [G loss: 0.868182]\n",
      "epoch:1 step:1834 [D loss: 0.688979, acc.: 52.34%] [G loss: 0.946435]\n",
      "epoch:1 step:1835 [D loss: 0.658161, acc.: 56.25%] [G loss: 0.918494]\n",
      "epoch:1 step:1836 [D loss: 0.658350, acc.: 58.59%] [G loss: 0.920068]\n",
      "epoch:1 step:1837 [D loss: 0.666931, acc.: 57.03%] [G loss: 0.937219]\n",
      "epoch:1 step:1838 [D loss: 0.709173, acc.: 51.56%] [G loss: 0.828859]\n",
      "epoch:1 step:1839 [D loss: 0.682353, acc.: 54.69%] [G loss: 0.850267]\n",
      "epoch:1 step:1840 [D loss: 0.753102, acc.: 47.66%] [G loss: 0.755149]\n",
      "epoch:1 step:1841 [D loss: 0.809711, acc.: 35.16%] [G loss: 0.786290]\n",
      "epoch:1 step:1842 [D loss: 0.708860, acc.: 51.56%] [G loss: 0.779919]\n",
      "epoch:1 step:1843 [D loss: 0.713628, acc.: 52.34%] [G loss: 0.809690]\n",
      "epoch:1 step:1844 [D loss: 0.720692, acc.: 53.12%] [G loss: 0.778371]\n",
      "epoch:1 step:1845 [D loss: 0.705348, acc.: 51.56%] [G loss: 0.789834]\n",
      "epoch:1 step:1846 [D loss: 0.742755, acc.: 43.75%] [G loss: 0.831725]\n",
      "epoch:1 step:1847 [D loss: 0.744593, acc.: 42.19%] [G loss: 0.824426]\n",
      "epoch:1 step:1848 [D loss: 0.665269, acc.: 60.94%] [G loss: 0.827546]\n",
      "epoch:1 step:1849 [D loss: 0.666297, acc.: 61.72%] [G loss: 0.839075]\n",
      "epoch:1 step:1850 [D loss: 0.715581, acc.: 54.69%] [G loss: 0.838580]\n",
      "epoch:1 step:1851 [D loss: 0.663639, acc.: 57.81%] [G loss: 0.905917]\n",
      "epoch:1 step:1852 [D loss: 0.698534, acc.: 52.34%] [G loss: 0.847414]\n",
      "epoch:1 step:1853 [D loss: 0.689676, acc.: 57.03%] [G loss: 0.859037]\n",
      "epoch:1 step:1854 [D loss: 0.743511, acc.: 46.88%] [G loss: 0.981680]\n",
      "epoch:1 step:1855 [D loss: 0.668050, acc.: 57.81%] [G loss: 0.910300]\n",
      "epoch:1 step:1856 [D loss: 0.644819, acc.: 67.19%] [G loss: 0.876532]\n",
      "epoch:1 step:1857 [D loss: 0.777109, acc.: 42.19%] [G loss: 0.843342]\n",
      "epoch:1 step:1858 [D loss: 0.662546, acc.: 56.25%] [G loss: 0.867261]\n",
      "epoch:1 step:1859 [D loss: 0.631924, acc.: 64.84%] [G loss: 0.865247]\n",
      "epoch:1 step:1860 [D loss: 0.652001, acc.: 62.50%] [G loss: 0.908367]\n",
      "epoch:1 step:1861 [D loss: 0.615183, acc.: 71.88%] [G loss: 0.923558]\n",
      "epoch:1 step:1862 [D loss: 0.599663, acc.: 66.41%] [G loss: 0.934026]\n",
      "epoch:1 step:1863 [D loss: 0.653550, acc.: 61.72%] [G loss: 0.916948]\n",
      "epoch:1 step:1864 [D loss: 0.631178, acc.: 60.16%] [G loss: 0.980251]\n",
      "epoch:1 step:1865 [D loss: 0.808464, acc.: 41.41%] [G loss: 0.913027]\n",
      "epoch:1 step:1866 [D loss: 0.735289, acc.: 48.44%] [G loss: 0.933173]\n",
      "epoch:1 step:1867 [D loss: 0.626165, acc.: 59.38%] [G loss: 0.880440]\n",
      "epoch:1 step:1868 [D loss: 0.743166, acc.: 50.00%] [G loss: 0.886076]\n",
      "epoch:1 step:1869 [D loss: 0.742489, acc.: 44.53%] [G loss: 0.792211]\n",
      "epoch:1 step:1870 [D loss: 0.712348, acc.: 48.44%] [G loss: 0.833862]\n",
      "epoch:1 step:1871 [D loss: 0.754855, acc.: 44.53%] [G loss: 0.849215]\n",
      "epoch:1 step:1872 [D loss: 0.655408, acc.: 57.03%] [G loss: 0.819923]\n",
      "epoch:1 step:1873 [D loss: 0.631820, acc.: 61.72%] [G loss: 0.913315]\n",
      "epoch:1 step:1874 [D loss: 0.773203, acc.: 42.97%] [G loss: 0.968389]\n",
      "epoch:2 step:1875 [D loss: 0.703266, acc.: 60.94%] [G loss: 0.955337]\n",
      "epoch:2 step:1876 [D loss: 0.708393, acc.: 53.12%] [G loss: 0.888729]\n",
      "epoch:2 step:1877 [D loss: 0.722390, acc.: 50.00%] [G loss: 0.931033]\n",
      "epoch:2 step:1878 [D loss: 0.667363, acc.: 59.38%] [G loss: 0.920430]\n",
      "epoch:2 step:1879 [D loss: 0.648270, acc.: 57.81%] [G loss: 0.870893]\n",
      "epoch:2 step:1880 [D loss: 0.650712, acc.: 62.50%] [G loss: 0.893367]\n",
      "epoch:2 step:1881 [D loss: 0.656056, acc.: 58.59%] [G loss: 0.904546]\n",
      "epoch:2 step:1882 [D loss: 0.716036, acc.: 50.00%] [G loss: 0.915891]\n",
      "epoch:2 step:1883 [D loss: 0.702839, acc.: 54.69%] [G loss: 0.877424]\n",
      "epoch:2 step:1884 [D loss: 0.743717, acc.: 48.44%] [G loss: 0.909979]\n",
      "epoch:2 step:1885 [D loss: 0.689507, acc.: 54.69%] [G loss: 0.902945]\n",
      "epoch:2 step:1886 [D loss: 0.718720, acc.: 48.44%] [G loss: 0.907016]\n",
      "epoch:2 step:1887 [D loss: 0.623409, acc.: 66.41%] [G loss: 0.954447]\n",
      "epoch:2 step:1888 [D loss: 0.656140, acc.: 59.38%] [G loss: 0.884021]\n",
      "epoch:2 step:1889 [D loss: 0.638069, acc.: 68.75%] [G loss: 0.915901]\n",
      "epoch:2 step:1890 [D loss: 0.694970, acc.: 57.03%] [G loss: 0.958723]\n",
      "epoch:2 step:1891 [D loss: 0.720561, acc.: 48.44%] [G loss: 0.952579]\n",
      "epoch:2 step:1892 [D loss: 0.707286, acc.: 54.69%] [G loss: 0.899054]\n",
      "epoch:2 step:1893 [D loss: 0.699335, acc.: 53.12%] [G loss: 0.899050]\n",
      "epoch:2 step:1894 [D loss: 0.763368, acc.: 51.56%] [G loss: 0.887968]\n",
      "epoch:2 step:1895 [D loss: 0.696042, acc.: 54.69%] [G loss: 0.828286]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:2 step:1896 [D loss: 0.647856, acc.: 58.59%] [G loss: 0.978667]\n",
      "epoch:2 step:1897 [D loss: 0.712561, acc.: 54.69%] [G loss: 0.956453]\n",
      "epoch:2 step:1898 [D loss: 0.790465, acc.: 44.53%] [G loss: 0.836067]\n",
      "epoch:2 step:1899 [D loss: 0.715362, acc.: 53.12%] [G loss: 0.965406]\n",
      "epoch:2 step:1900 [D loss: 0.736871, acc.: 48.44%] [G loss: 0.929833]\n",
      "epoch:2 step:1901 [D loss: 0.713299, acc.: 49.22%] [G loss: 0.866793]\n",
      "epoch:2 step:1902 [D loss: 0.753345, acc.: 46.09%] [G loss: 0.961256]\n",
      "epoch:2 step:1903 [D loss: 0.687138, acc.: 53.91%] [G loss: 0.974813]\n",
      "epoch:2 step:1904 [D loss: 0.737489, acc.: 57.03%] [G loss: 0.886903]\n",
      "epoch:2 step:1905 [D loss: 0.685350, acc.: 58.59%] [G loss: 0.869904]\n",
      "epoch:2 step:1906 [D loss: 0.731078, acc.: 51.56%] [G loss: 0.833268]\n",
      "epoch:2 step:1907 [D loss: 0.709367, acc.: 54.69%] [G loss: 0.832886]\n",
      "epoch:2 step:1908 [D loss: 0.726442, acc.: 55.47%] [G loss: 0.871818]\n",
      "epoch:2 step:1909 [D loss: 0.660120, acc.: 58.59%] [G loss: 0.913893]\n",
      "epoch:2 step:1910 [D loss: 0.637856, acc.: 59.38%] [G loss: 0.952462]\n",
      "epoch:2 step:1911 [D loss: 0.729409, acc.: 54.69%] [G loss: 0.830080]\n",
      "epoch:2 step:1912 [D loss: 0.723944, acc.: 48.44%] [G loss: 0.838150]\n",
      "epoch:2 step:1913 [D loss: 0.735871, acc.: 43.75%] [G loss: 0.795423]\n",
      "epoch:2 step:1914 [D loss: 0.687876, acc.: 56.25%] [G loss: 0.861595]\n",
      "epoch:2 step:1915 [D loss: 0.685685, acc.: 55.47%] [G loss: 0.855298]\n",
      "epoch:2 step:1916 [D loss: 0.646995, acc.: 63.28%] [G loss: 0.907161]\n",
      "epoch:2 step:1917 [D loss: 0.686135, acc.: 55.47%] [G loss: 0.855260]\n",
      "epoch:2 step:1918 [D loss: 0.730196, acc.: 44.53%] [G loss: 0.934464]\n",
      "epoch:2 step:1919 [D loss: 0.678926, acc.: 57.03%] [G loss: 0.836843]\n",
      "epoch:2 step:1920 [D loss: 0.735067, acc.: 45.31%] [G loss: 0.923877]\n",
      "epoch:2 step:1921 [D loss: 0.698260, acc.: 48.44%] [G loss: 0.829518]\n",
      "epoch:2 step:1922 [D loss: 0.696833, acc.: 47.66%] [G loss: 0.790292]\n",
      "epoch:2 step:1923 [D loss: 0.682643, acc.: 54.69%] [G loss: 0.831187]\n",
      "epoch:2 step:1924 [D loss: 0.713555, acc.: 54.69%] [G loss: 0.828776]\n",
      "epoch:2 step:1925 [D loss: 0.698575, acc.: 53.12%] [G loss: 0.859052]\n",
      "epoch:2 step:1926 [D loss: 0.707505, acc.: 50.78%] [G loss: 0.837319]\n",
      "epoch:2 step:1927 [D loss: 0.647632, acc.: 60.16%] [G loss: 0.909020]\n",
      "epoch:2 step:1928 [D loss: 0.697320, acc.: 53.91%] [G loss: 0.876576]\n",
      "epoch:2 step:1929 [D loss: 0.724519, acc.: 50.00%] [G loss: 0.806086]\n",
      "epoch:2 step:1930 [D loss: 0.728079, acc.: 51.56%] [G loss: 0.889903]\n",
      "epoch:2 step:1931 [D loss: 0.731084, acc.: 49.22%] [G loss: 0.856147]\n",
      "epoch:2 step:1932 [D loss: 0.687587, acc.: 56.25%] [G loss: 0.815595]\n",
      "epoch:2 step:1933 [D loss: 0.707227, acc.: 50.78%] [G loss: 0.897250]\n",
      "epoch:2 step:1934 [D loss: 0.692786, acc.: 50.78%] [G loss: 0.880349]\n",
      "epoch:2 step:1935 [D loss: 0.704191, acc.: 49.22%] [G loss: 0.864994]\n",
      "epoch:2 step:1936 [D loss: 0.729489, acc.: 43.75%] [G loss: 0.865639]\n",
      "epoch:2 step:1937 [D loss: 0.670613, acc.: 57.81%] [G loss: 0.862850]\n",
      "epoch:2 step:1938 [D loss: 0.727988, acc.: 49.22%] [G loss: 0.806553]\n",
      "epoch:2 step:1939 [D loss: 0.697822, acc.: 55.47%] [G loss: 0.848495]\n",
      "epoch:2 step:1940 [D loss: 0.723023, acc.: 55.47%] [G loss: 0.814944]\n",
      "epoch:2 step:1941 [D loss: 0.674297, acc.: 56.25%] [G loss: 0.866062]\n",
      "epoch:2 step:1942 [D loss: 0.723591, acc.: 50.00%] [G loss: 0.837652]\n",
      "epoch:2 step:1943 [D loss: 0.691159, acc.: 54.69%] [G loss: 0.809559]\n",
      "epoch:2 step:1944 [D loss: 0.723999, acc.: 50.78%] [G loss: 0.852762]\n",
      "epoch:2 step:1945 [D loss: 0.752731, acc.: 48.44%] [G loss: 0.818503]\n",
      "epoch:2 step:1946 [D loss: 0.716035, acc.: 50.78%] [G loss: 0.877134]\n",
      "epoch:2 step:1947 [D loss: 0.683042, acc.: 52.34%] [G loss: 0.863401]\n",
      "epoch:2 step:1948 [D loss: 0.653341, acc.: 62.50%] [G loss: 0.936027]\n",
      "epoch:2 step:1949 [D loss: 0.712466, acc.: 53.12%] [G loss: 0.953451]\n",
      "epoch:2 step:1950 [D loss: 0.631514, acc.: 62.50%] [G loss: 0.968596]\n",
      "epoch:2 step:1951 [D loss: 0.625471, acc.: 65.62%] [G loss: 0.952030]\n",
      "epoch:2 step:1952 [D loss: 0.699310, acc.: 53.12%] [G loss: 0.957242]\n",
      "epoch:2 step:1953 [D loss: 0.673518, acc.: 57.03%] [G loss: 0.923557]\n",
      "epoch:2 step:1954 [D loss: 0.662194, acc.: 60.16%] [G loss: 0.870748]\n",
      "epoch:2 step:1955 [D loss: 0.695701, acc.: 60.94%] [G loss: 0.808460]\n",
      "epoch:2 step:1956 [D loss: 0.711557, acc.: 48.44%] [G loss: 0.813106]\n",
      "epoch:2 step:1957 [D loss: 0.694852, acc.: 55.47%] [G loss: 0.804955]\n",
      "epoch:2 step:1958 [D loss: 0.686345, acc.: 53.91%] [G loss: 0.823155]\n",
      "epoch:2 step:1959 [D loss: 0.740252, acc.: 49.22%] [G loss: 0.823515]\n",
      "epoch:2 step:1960 [D loss: 0.715756, acc.: 49.22%] [G loss: 0.835629]\n",
      "epoch:2 step:1961 [D loss: 0.747920, acc.: 42.97%] [G loss: 0.874493]\n",
      "epoch:2 step:1962 [D loss: 0.662556, acc.: 64.06%] [G loss: 0.875242]\n",
      "epoch:2 step:1963 [D loss: 0.689856, acc.: 54.69%] [G loss: 0.784371]\n",
      "epoch:2 step:1964 [D loss: 0.700652, acc.: 53.91%] [G loss: 0.826966]\n",
      "epoch:2 step:1965 [D loss: 0.636192, acc.: 62.50%] [G loss: 0.831480]\n",
      "epoch:2 step:1966 [D loss: 0.642127, acc.: 64.84%] [G loss: 0.891143]\n",
      "epoch:2 step:1967 [D loss: 0.634988, acc.: 67.97%] [G loss: 0.901851]\n",
      "epoch:2 step:1968 [D loss: 0.747485, acc.: 47.66%] [G loss: 0.877402]\n",
      "epoch:2 step:1969 [D loss: 0.773615, acc.: 42.19%] [G loss: 0.804830]\n",
      "epoch:2 step:1970 [D loss: 0.730439, acc.: 46.88%] [G loss: 0.766201]\n",
      "epoch:2 step:1971 [D loss: 0.679490, acc.: 58.59%] [G loss: 0.853834]\n",
      "epoch:2 step:1972 [D loss: 0.726314, acc.: 47.66%] [G loss: 0.815378]\n",
      "epoch:2 step:1973 [D loss: 0.710452, acc.: 49.22%] [G loss: 0.797242]\n",
      "epoch:2 step:1974 [D loss: 0.685817, acc.: 63.28%] [G loss: 0.853260]\n",
      "epoch:2 step:1975 [D loss: 0.764802, acc.: 37.50%] [G loss: 0.809157]\n",
      "epoch:2 step:1976 [D loss: 0.698582, acc.: 53.12%] [G loss: 0.891260]\n",
      "epoch:2 step:1977 [D loss: 0.761657, acc.: 35.16%] [G loss: 0.831847]\n",
      "epoch:2 step:1978 [D loss: 0.700645, acc.: 52.34%] [G loss: 0.835781]\n",
      "epoch:2 step:1979 [D loss: 0.722663, acc.: 43.75%] [G loss: 0.784532]\n",
      "epoch:2 step:1980 [D loss: 0.663456, acc.: 58.59%] [G loss: 0.874370]\n",
      "epoch:2 step:1981 [D loss: 0.633267, acc.: 65.62%] [G loss: 0.870224]\n",
      "epoch:2 step:1982 [D loss: 0.696453, acc.: 51.56%] [G loss: 0.836567]\n",
      "epoch:2 step:1983 [D loss: 0.669562, acc.: 57.81%] [G loss: 0.926024]\n",
      "epoch:2 step:1984 [D loss: 0.669429, acc.: 59.38%] [G loss: 0.900163]\n",
      "epoch:2 step:1985 [D loss: 0.674745, acc.: 59.38%] [G loss: 0.860003]\n",
      "epoch:2 step:1986 [D loss: 0.646253, acc.: 63.28%] [G loss: 0.904277]\n",
      "epoch:2 step:1987 [D loss: 0.667137, acc.: 55.47%] [G loss: 0.863209]\n",
      "epoch:2 step:1988 [D loss: 0.660907, acc.: 57.03%] [G loss: 0.855635]\n",
      "epoch:2 step:1989 [D loss: 0.667725, acc.: 60.94%] [G loss: 0.857383]\n",
      "epoch:2 step:1990 [D loss: 0.719895, acc.: 50.00%] [G loss: 0.808613]\n",
      "epoch:2 step:1991 [D loss: 0.737129, acc.: 54.69%] [G loss: 0.802624]\n",
      "epoch:2 step:1992 [D loss: 0.727110, acc.: 52.34%] [G loss: 0.847456]\n",
      "epoch:2 step:1993 [D loss: 0.736805, acc.: 44.53%] [G loss: 0.851822]\n",
      "epoch:2 step:1994 [D loss: 0.799083, acc.: 35.16%] [G loss: 0.869692]\n",
      "epoch:2 step:1995 [D loss: 0.754354, acc.: 37.50%] [G loss: 0.858243]\n",
      "epoch:2 step:1996 [D loss: 0.699051, acc.: 56.25%] [G loss: 0.904588]\n",
      "epoch:2 step:1997 [D loss: 0.646269, acc.: 57.03%] [G loss: 1.029483]\n",
      "epoch:2 step:1998 [D loss: 0.671741, acc.: 54.69%] [G loss: 0.985670]\n",
      "epoch:2 step:1999 [D loss: 0.627125, acc.: 58.59%] [G loss: 1.022988]\n",
      "epoch:2 step:2000 [D loss: 0.623088, acc.: 64.06%] [G loss: 1.031409]\n",
      "##############\n",
      "[4.27010333 2.5339567  6.45664888 5.64662554 4.67934568 6.62201547\n",
      " 5.22440397 5.80490321 5.91951104 4.98961239]\n",
      "##########\n",
      "epoch:2 step:2001 [D loss: 0.616237, acc.: 67.97%] [G loss: 0.957741]\n",
      "epoch:2 step:2002 [D loss: 0.709852, acc.: 52.34%] [G loss: 0.899227]\n",
      "epoch:2 step:2003 [D loss: 0.780781, acc.: 45.31%] [G loss: 0.815051]\n",
      "epoch:2 step:2004 [D loss: 0.649090, acc.: 62.50%] [G loss: 0.826576]\n",
      "epoch:2 step:2005 [D loss: 0.733018, acc.: 48.44%] [G loss: 0.847952]\n",
      "epoch:2 step:2006 [D loss: 0.711178, acc.: 47.66%] [G loss: 0.891490]\n",
      "epoch:2 step:2007 [D loss: 0.704290, acc.: 55.47%] [G loss: 0.876372]\n",
      "epoch:2 step:2008 [D loss: 0.708104, acc.: 48.44%] [G loss: 0.799612]\n",
      "epoch:2 step:2009 [D loss: 0.750350, acc.: 46.09%] [G loss: 0.873770]\n",
      "epoch:2 step:2010 [D loss: 0.680776, acc.: 57.81%] [G loss: 0.847090]\n",
      "epoch:2 step:2011 [D loss: 0.733096, acc.: 45.31%] [G loss: 0.874939]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:2 step:2012 [D loss: 0.684486, acc.: 56.25%] [G loss: 0.933511]\n",
      "epoch:2 step:2013 [D loss: 0.671106, acc.: 60.94%] [G loss: 0.899285]\n",
      "epoch:2 step:2014 [D loss: 0.682801, acc.: 49.22%] [G loss: 0.900921]\n",
      "epoch:2 step:2015 [D loss: 0.673983, acc.: 57.03%] [G loss: 0.935743]\n",
      "epoch:2 step:2016 [D loss: 0.725207, acc.: 53.91%] [G loss: 0.868225]\n",
      "epoch:2 step:2017 [D loss: 0.719765, acc.: 50.00%] [G loss: 0.846085]\n",
      "epoch:2 step:2018 [D loss: 0.650652, acc.: 60.16%] [G loss: 0.812536]\n",
      "epoch:2 step:2019 [D loss: 0.657837, acc.: 60.16%] [G loss: 0.823114]\n",
      "epoch:2 step:2020 [D loss: 0.749919, acc.: 48.44%] [G loss: 0.838787]\n",
      "epoch:2 step:2021 [D loss: 0.707060, acc.: 53.91%] [G loss: 0.726993]\n",
      "epoch:2 step:2022 [D loss: 0.731004, acc.: 46.09%] [G loss: 0.729427]\n",
      "epoch:2 step:2023 [D loss: 0.706159, acc.: 52.34%] [G loss: 0.750442]\n",
      "epoch:2 step:2024 [D loss: 0.689553, acc.: 55.47%] [G loss: 0.807765]\n",
      "epoch:2 step:2025 [D loss: 0.700719, acc.: 53.91%] [G loss: 0.801779]\n",
      "epoch:2 step:2026 [D loss: 0.676805, acc.: 54.69%] [G loss: 0.927704]\n",
      "epoch:2 step:2027 [D loss: 0.717475, acc.: 48.44%] [G loss: 0.915828]\n",
      "epoch:2 step:2028 [D loss: 0.692010, acc.: 54.69%] [G loss: 0.889165]\n",
      "epoch:2 step:2029 [D loss: 0.663670, acc.: 57.81%] [G loss: 0.870830]\n",
      "epoch:2 step:2030 [D loss: 0.689166, acc.: 55.47%] [G loss: 0.798488]\n",
      "epoch:2 step:2031 [D loss: 0.639480, acc.: 66.41%] [G loss: 0.854159]\n",
      "epoch:2 step:2032 [D loss: 0.665267, acc.: 57.03%] [G loss: 0.847781]\n",
      "epoch:2 step:2033 [D loss: 0.683315, acc.: 54.69%] [G loss: 0.792881]\n",
      "epoch:2 step:2034 [D loss: 0.745564, acc.: 44.53%] [G loss: 0.828620]\n",
      "epoch:2 step:2035 [D loss: 0.716305, acc.: 54.69%] [G loss: 0.798308]\n",
      "epoch:2 step:2036 [D loss: 0.692644, acc.: 54.69%] [G loss: 0.886068]\n",
      "epoch:2 step:2037 [D loss: 0.706846, acc.: 55.47%] [G loss: 0.771852]\n",
      "epoch:2 step:2038 [D loss: 0.676131, acc.: 57.81%] [G loss: 0.814090]\n",
      "epoch:2 step:2039 [D loss: 0.721627, acc.: 50.78%] [G loss: 0.819322]\n",
      "epoch:2 step:2040 [D loss: 0.709259, acc.: 48.44%] [G loss: 0.787515]\n",
      "epoch:2 step:2041 [D loss: 0.737077, acc.: 45.31%] [G loss: 0.867087]\n",
      "epoch:2 step:2042 [D loss: 0.717339, acc.: 50.78%] [G loss: 0.851533]\n",
      "epoch:2 step:2043 [D loss: 0.709516, acc.: 50.78%] [G loss: 0.765202]\n",
      "epoch:2 step:2044 [D loss: 0.736472, acc.: 43.75%] [G loss: 0.802780]\n",
      "epoch:2 step:2045 [D loss: 0.673674, acc.: 60.94%] [G loss: 0.824563]\n",
      "epoch:2 step:2046 [D loss: 0.694034, acc.: 57.03%] [G loss: 0.803826]\n",
      "epoch:2 step:2047 [D loss: 0.708513, acc.: 49.22%] [G loss: 0.859846]\n",
      "epoch:2 step:2048 [D loss: 0.705030, acc.: 48.44%] [G loss: 0.823843]\n",
      "epoch:2 step:2049 [D loss: 0.682095, acc.: 51.56%] [G loss: 0.871942]\n",
      "epoch:2 step:2050 [D loss: 0.629253, acc.: 64.84%] [G loss: 0.841853]\n",
      "epoch:2 step:2051 [D loss: 0.645277, acc.: 63.28%] [G loss: 0.894211]\n",
      "epoch:2 step:2052 [D loss: 0.680862, acc.: 55.47%] [G loss: 0.865708]\n",
      "epoch:2 step:2053 [D loss: 0.723805, acc.: 48.44%] [G loss: 0.791642]\n",
      "epoch:2 step:2054 [D loss: 0.725854, acc.: 46.09%] [G loss: 0.789140]\n",
      "epoch:2 step:2055 [D loss: 0.716116, acc.: 45.31%] [G loss: 0.788941]\n",
      "epoch:2 step:2056 [D loss: 0.737913, acc.: 42.19%] [G loss: 0.828314]\n",
      "epoch:2 step:2057 [D loss: 0.675699, acc.: 57.81%] [G loss: 0.787537]\n",
      "epoch:2 step:2058 [D loss: 0.705638, acc.: 50.00%] [G loss: 0.826776]\n",
      "epoch:2 step:2059 [D loss: 0.689513, acc.: 53.91%] [G loss: 0.811064]\n",
      "epoch:2 step:2060 [D loss: 0.773570, acc.: 38.28%] [G loss: 0.816173]\n",
      "epoch:2 step:2061 [D loss: 0.715240, acc.: 52.34%] [G loss: 0.842340]\n",
      "epoch:2 step:2062 [D loss: 0.726133, acc.: 47.66%] [G loss: 0.845465]\n",
      "epoch:2 step:2063 [D loss: 0.687622, acc.: 57.81%] [G loss: 0.773385]\n",
      "epoch:2 step:2064 [D loss: 0.680552, acc.: 54.69%] [G loss: 0.837076]\n",
      "epoch:2 step:2065 [D loss: 0.644784, acc.: 62.50%] [G loss: 0.848091]\n",
      "epoch:2 step:2066 [D loss: 0.689570, acc.: 50.78%] [G loss: 0.816548]\n",
      "epoch:2 step:2067 [D loss: 0.664015, acc.: 58.59%] [G loss: 0.828949]\n",
      "epoch:2 step:2068 [D loss: 0.686952, acc.: 50.78%] [G loss: 0.826934]\n",
      "epoch:2 step:2069 [D loss: 0.730271, acc.: 44.53%] [G loss: 0.841493]\n",
      "epoch:2 step:2070 [D loss: 0.718073, acc.: 49.22%] [G loss: 0.828104]\n",
      "epoch:2 step:2071 [D loss: 0.727426, acc.: 46.88%] [G loss: 0.830134]\n",
      "epoch:2 step:2072 [D loss: 0.698651, acc.: 51.56%] [G loss: 0.836747]\n",
      "epoch:2 step:2073 [D loss: 0.699327, acc.: 47.66%] [G loss: 0.822634]\n",
      "epoch:2 step:2074 [D loss: 0.747560, acc.: 39.06%] [G loss: 0.829849]\n",
      "epoch:2 step:2075 [D loss: 0.694938, acc.: 53.91%] [G loss: 0.930630]\n",
      "epoch:2 step:2076 [D loss: 0.698327, acc.: 54.69%] [G loss: 0.855187]\n",
      "epoch:2 step:2077 [D loss: 0.665208, acc.: 61.72%] [G loss: 0.855224]\n",
      "epoch:2 step:2078 [D loss: 0.668193, acc.: 55.47%] [G loss: 0.796796]\n",
      "epoch:2 step:2079 [D loss: 0.696412, acc.: 50.78%] [G loss: 0.818087]\n",
      "epoch:2 step:2080 [D loss: 0.687173, acc.: 53.91%] [G loss: 0.849418]\n",
      "epoch:2 step:2081 [D loss: 0.667346, acc.: 60.94%] [G loss: 0.806210]\n",
      "epoch:2 step:2082 [D loss: 0.638714, acc.: 64.06%] [G loss: 0.850288]\n",
      "epoch:2 step:2083 [D loss: 0.629067, acc.: 62.50%] [G loss: 0.859264]\n",
      "epoch:2 step:2084 [D loss: 0.737064, acc.: 45.31%] [G loss: 0.793831]\n",
      "epoch:2 step:2085 [D loss: 0.712068, acc.: 53.12%] [G loss: 0.814562]\n",
      "epoch:2 step:2086 [D loss: 0.691682, acc.: 56.25%] [G loss: 0.806278]\n",
      "epoch:2 step:2087 [D loss: 0.710807, acc.: 57.81%] [G loss: 0.819028]\n",
      "epoch:2 step:2088 [D loss: 0.689654, acc.: 52.34%] [G loss: 0.829901]\n",
      "epoch:2 step:2089 [D loss: 0.710559, acc.: 53.91%] [G loss: 0.787409]\n",
      "epoch:2 step:2090 [D loss: 0.773040, acc.: 41.41%] [G loss: 0.828083]\n",
      "epoch:2 step:2091 [D loss: 0.708969, acc.: 49.22%] [G loss: 0.782005]\n",
      "epoch:2 step:2092 [D loss: 0.724059, acc.: 50.00%] [G loss: 0.794157]\n",
      "epoch:2 step:2093 [D loss: 0.691840, acc.: 60.94%] [G loss: 0.776001]\n",
      "epoch:2 step:2094 [D loss: 0.795941, acc.: 37.50%] [G loss: 0.844666]\n",
      "epoch:2 step:2095 [D loss: 0.725441, acc.: 49.22%] [G loss: 0.796367]\n",
      "epoch:2 step:2096 [D loss: 0.669132, acc.: 54.69%] [G loss: 0.877641]\n",
      "epoch:2 step:2097 [D loss: 0.657724, acc.: 57.03%] [G loss: 0.849665]\n",
      "epoch:2 step:2098 [D loss: 0.649993, acc.: 64.06%] [G loss: 0.878808]\n",
      "epoch:2 step:2099 [D loss: 0.719394, acc.: 47.66%] [G loss: 0.862430]\n",
      "epoch:2 step:2100 [D loss: 0.667090, acc.: 60.94%] [G loss: 0.835755]\n",
      "epoch:2 step:2101 [D loss: 0.677389, acc.: 57.81%] [G loss: 0.848387]\n",
      "epoch:2 step:2102 [D loss: 0.690838, acc.: 54.69%] [G loss: 0.869877]\n",
      "epoch:2 step:2103 [D loss: 0.684515, acc.: 57.03%] [G loss: 0.836463]\n",
      "epoch:2 step:2104 [D loss: 0.645712, acc.: 62.50%] [G loss: 0.902174]\n",
      "epoch:2 step:2105 [D loss: 0.641534, acc.: 65.62%] [G loss: 0.887601]\n",
      "epoch:2 step:2106 [D loss: 0.622709, acc.: 64.84%] [G loss: 0.867874]\n",
      "epoch:2 step:2107 [D loss: 0.695939, acc.: 58.59%] [G loss: 0.880147]\n",
      "epoch:2 step:2108 [D loss: 0.757626, acc.: 43.75%] [G loss: 0.898915]\n",
      "epoch:2 step:2109 [D loss: 0.697862, acc.: 51.56%] [G loss: 0.881933]\n",
      "epoch:2 step:2110 [D loss: 0.704661, acc.: 53.91%] [G loss: 0.830211]\n",
      "epoch:2 step:2111 [D loss: 0.700404, acc.: 53.12%] [G loss: 0.801752]\n",
      "epoch:2 step:2112 [D loss: 0.705711, acc.: 53.12%] [G loss: 0.851978]\n",
      "epoch:2 step:2113 [D loss: 0.705538, acc.: 55.47%] [G loss: 0.887015]\n",
      "epoch:2 step:2114 [D loss: 0.691148, acc.: 55.47%] [G loss: 0.817670]\n",
      "epoch:2 step:2115 [D loss: 0.697612, acc.: 48.44%] [G loss: 0.808145]\n",
      "epoch:2 step:2116 [D loss: 0.677843, acc.: 59.38%] [G loss: 0.816148]\n",
      "epoch:2 step:2117 [D loss: 0.683435, acc.: 58.59%] [G loss: 0.807810]\n",
      "epoch:2 step:2118 [D loss: 0.690304, acc.: 51.56%] [G loss: 0.886950]\n",
      "epoch:2 step:2119 [D loss: 0.696585, acc.: 50.78%] [G loss: 0.872534]\n",
      "epoch:2 step:2120 [D loss: 0.703188, acc.: 50.78%] [G loss: 0.858395]\n",
      "epoch:2 step:2121 [D loss: 0.706929, acc.: 48.44%] [G loss: 0.872494]\n",
      "epoch:2 step:2122 [D loss: 0.684294, acc.: 53.91%] [G loss: 0.829071]\n",
      "epoch:2 step:2123 [D loss: 0.732790, acc.: 50.00%] [G loss: 0.803984]\n",
      "epoch:2 step:2124 [D loss: 0.707803, acc.: 49.22%] [G loss: 0.841923]\n",
      "epoch:2 step:2125 [D loss: 0.723915, acc.: 42.97%] [G loss: 0.856298]\n",
      "epoch:2 step:2126 [D loss: 0.689850, acc.: 49.22%] [G loss: 0.899684]\n",
      "epoch:2 step:2127 [D loss: 0.671262, acc.: 55.47%] [G loss: 0.842134]\n",
      "epoch:2 step:2128 [D loss: 0.652429, acc.: 58.59%] [G loss: 0.913129]\n",
      "epoch:2 step:2129 [D loss: 0.701681, acc.: 51.56%] [G loss: 0.921153]\n",
      "epoch:2 step:2130 [D loss: 0.658671, acc.: 60.16%] [G loss: 0.865616]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:2 step:2131 [D loss: 0.663841, acc.: 60.94%] [G loss: 0.847835]\n",
      "epoch:2 step:2132 [D loss: 0.656820, acc.: 66.41%] [G loss: 0.841419]\n",
      "epoch:2 step:2133 [D loss: 0.692753, acc.: 55.47%] [G loss: 0.835887]\n",
      "epoch:2 step:2134 [D loss: 0.720070, acc.: 49.22%] [G loss: 0.761021]\n",
      "epoch:2 step:2135 [D loss: 0.716134, acc.: 51.56%] [G loss: 0.775571]\n",
      "epoch:2 step:2136 [D loss: 0.689433, acc.: 61.72%] [G loss: 0.760614]\n",
      "epoch:2 step:2137 [D loss: 0.758609, acc.: 42.97%] [G loss: 0.800762]\n",
      "epoch:2 step:2138 [D loss: 0.752675, acc.: 39.06%] [G loss: 0.803727]\n",
      "epoch:2 step:2139 [D loss: 0.688117, acc.: 60.16%] [G loss: 0.824274]\n",
      "epoch:2 step:2140 [D loss: 0.693062, acc.: 55.47%] [G loss: 0.822863]\n",
      "epoch:2 step:2141 [D loss: 0.685724, acc.: 51.56%] [G loss: 0.852004]\n",
      "epoch:2 step:2142 [D loss: 0.666808, acc.: 58.59%] [G loss: 0.862594]\n",
      "epoch:2 step:2143 [D loss: 0.713152, acc.: 50.78%] [G loss: 0.818120]\n",
      "epoch:2 step:2144 [D loss: 0.707589, acc.: 48.44%] [G loss: 0.864264]\n",
      "epoch:2 step:2145 [D loss: 0.664224, acc.: 62.50%] [G loss: 0.860824]\n",
      "epoch:2 step:2146 [D loss: 0.680380, acc.: 57.03%] [G loss: 0.897888]\n",
      "epoch:2 step:2147 [D loss: 0.705831, acc.: 50.78%] [G loss: 0.846631]\n",
      "epoch:2 step:2148 [D loss: 0.644971, acc.: 62.50%] [G loss: 0.875256]\n",
      "epoch:2 step:2149 [D loss: 0.647136, acc.: 60.94%] [G loss: 0.869258]\n",
      "epoch:2 step:2150 [D loss: 0.675449, acc.: 53.12%] [G loss: 0.942230]\n",
      "epoch:2 step:2151 [D loss: 0.740356, acc.: 50.00%] [G loss: 0.867476]\n",
      "epoch:2 step:2152 [D loss: 0.706062, acc.: 53.91%] [G loss: 0.811819]\n",
      "epoch:2 step:2153 [D loss: 0.715825, acc.: 50.00%] [G loss: 0.833940]\n",
      "epoch:2 step:2154 [D loss: 0.697897, acc.: 57.03%] [G loss: 0.819920]\n",
      "epoch:2 step:2155 [D loss: 0.745082, acc.: 45.31%] [G loss: 0.920969]\n",
      "epoch:2 step:2156 [D loss: 0.707666, acc.: 53.12%] [G loss: 0.927384]\n",
      "epoch:2 step:2157 [D loss: 0.677831, acc.: 54.69%] [G loss: 0.838919]\n",
      "epoch:2 step:2158 [D loss: 0.619767, acc.: 66.41%] [G loss: 0.962875]\n",
      "epoch:2 step:2159 [D loss: 0.654601, acc.: 58.59%] [G loss: 0.863621]\n",
      "epoch:2 step:2160 [D loss: 0.659094, acc.: 65.62%] [G loss: 0.909085]\n",
      "epoch:2 step:2161 [D loss: 0.704061, acc.: 56.25%] [G loss: 0.852885]\n",
      "epoch:2 step:2162 [D loss: 0.697271, acc.: 51.56%] [G loss: 0.768659]\n",
      "epoch:2 step:2163 [D loss: 0.675917, acc.: 57.81%] [G loss: 0.783454]\n",
      "epoch:2 step:2164 [D loss: 0.708341, acc.: 56.25%] [G loss: 0.721659]\n",
      "epoch:2 step:2165 [D loss: 0.764948, acc.: 46.09%] [G loss: 0.781248]\n",
      "epoch:2 step:2166 [D loss: 0.684181, acc.: 54.69%] [G loss: 0.758100]\n",
      "epoch:2 step:2167 [D loss: 0.719437, acc.: 48.44%] [G loss: 0.808423]\n",
      "epoch:2 step:2168 [D loss: 0.735946, acc.: 42.19%] [G loss: 0.752784]\n",
      "epoch:2 step:2169 [D loss: 0.744454, acc.: 45.31%] [G loss: 0.831857]\n",
      "epoch:2 step:2170 [D loss: 0.669769, acc.: 53.12%] [G loss: 0.874222]\n",
      "epoch:2 step:2171 [D loss: 0.707552, acc.: 51.56%] [G loss: 0.874998]\n",
      "epoch:2 step:2172 [D loss: 0.686869, acc.: 56.25%] [G loss: 0.872541]\n",
      "epoch:2 step:2173 [D loss: 0.671168, acc.: 56.25%] [G loss: 0.820799]\n",
      "epoch:2 step:2174 [D loss: 0.679000, acc.: 50.78%] [G loss: 0.813405]\n",
      "epoch:2 step:2175 [D loss: 0.749528, acc.: 38.28%] [G loss: 0.814672]\n",
      "epoch:2 step:2176 [D loss: 0.707170, acc.: 53.12%] [G loss: 0.793346]\n",
      "epoch:2 step:2177 [D loss: 0.716319, acc.: 50.78%] [G loss: 0.811837]\n",
      "epoch:2 step:2178 [D loss: 0.712141, acc.: 52.34%] [G loss: 0.815732]\n",
      "epoch:2 step:2179 [D loss: 0.742552, acc.: 42.97%] [G loss: 0.826317]\n",
      "epoch:2 step:2180 [D loss: 0.749954, acc.: 42.97%] [G loss: 0.816230]\n",
      "epoch:2 step:2181 [D loss: 0.706082, acc.: 50.78%] [G loss: 0.796982]\n",
      "epoch:2 step:2182 [D loss: 0.710744, acc.: 51.56%] [G loss: 0.843612]\n",
      "epoch:2 step:2183 [D loss: 0.656926, acc.: 58.59%] [G loss: 0.849578]\n",
      "epoch:2 step:2184 [D loss: 0.627904, acc.: 67.19%] [G loss: 0.864993]\n",
      "epoch:2 step:2185 [D loss: 0.614573, acc.: 63.28%] [G loss: 0.867553]\n",
      "epoch:2 step:2186 [D loss: 0.620529, acc.: 68.75%] [G loss: 0.917093]\n",
      "epoch:2 step:2187 [D loss: 0.626646, acc.: 64.84%] [G loss: 0.910819]\n",
      "epoch:2 step:2188 [D loss: 0.593593, acc.: 71.88%] [G loss: 0.927512]\n",
      "epoch:2 step:2189 [D loss: 0.612130, acc.: 67.19%] [G loss: 0.959562]\n",
      "epoch:2 step:2190 [D loss: 0.745306, acc.: 48.44%] [G loss: 0.787987]\n",
      "epoch:2 step:2191 [D loss: 0.749518, acc.: 50.00%] [G loss: 0.861958]\n",
      "epoch:2 step:2192 [D loss: 0.701777, acc.: 53.12%] [G loss: 0.791113]\n",
      "epoch:2 step:2193 [D loss: 0.725931, acc.: 46.09%] [G loss: 0.849037]\n",
      "epoch:2 step:2194 [D loss: 0.759382, acc.: 42.19%] [G loss: 0.843818]\n",
      "epoch:2 step:2195 [D loss: 0.754771, acc.: 46.09%] [G loss: 0.770117]\n",
      "epoch:2 step:2196 [D loss: 0.707281, acc.: 53.91%] [G loss: 0.773888]\n",
      "epoch:2 step:2197 [D loss: 0.716279, acc.: 47.66%] [G loss: 0.833734]\n",
      "epoch:2 step:2198 [D loss: 0.727513, acc.: 46.88%] [G loss: 0.830990]\n",
      "epoch:2 step:2199 [D loss: 0.700179, acc.: 50.00%] [G loss: 0.809627]\n",
      "epoch:2 step:2200 [D loss: 0.652777, acc.: 63.28%] [G loss: 0.803418]\n",
      "##############\n",
      "[4.43447879 2.55277614 6.46317231 5.18380709 4.24592205 5.60925298\n",
      " 4.96591554 5.19725001 5.89401901 4.72601434]\n",
      "##########\n",
      "epoch:2 step:2201 [D loss: 0.655107, acc.: 60.94%] [G loss: 0.863622]\n",
      "epoch:2 step:2202 [D loss: 0.655311, acc.: 62.50%] [G loss: 0.854357]\n",
      "epoch:2 step:2203 [D loss: 0.709410, acc.: 50.78%] [G loss: 0.827726]\n",
      "epoch:2 step:2204 [D loss: 0.712731, acc.: 53.91%] [G loss: 0.915067]\n",
      "epoch:2 step:2205 [D loss: 0.663025, acc.: 64.06%] [G loss: 0.856350]\n",
      "epoch:2 step:2206 [D loss: 0.688868, acc.: 58.59%] [G loss: 0.834974]\n",
      "epoch:2 step:2207 [D loss: 0.712581, acc.: 53.91%] [G loss: 0.838632]\n",
      "epoch:2 step:2208 [D loss: 0.714382, acc.: 51.56%] [G loss: 0.776811]\n",
      "epoch:2 step:2209 [D loss: 0.699396, acc.: 53.12%] [G loss: 0.770955]\n",
      "epoch:2 step:2210 [D loss: 0.694238, acc.: 50.78%] [G loss: 0.809429]\n",
      "epoch:2 step:2211 [D loss: 0.724385, acc.: 51.56%] [G loss: 0.910501]\n",
      "epoch:2 step:2212 [D loss: 0.699930, acc.: 48.44%] [G loss: 0.897104]\n",
      "epoch:2 step:2213 [D loss: 0.697572, acc.: 53.91%] [G loss: 0.847722]\n",
      "epoch:2 step:2214 [D loss: 0.699288, acc.: 50.78%] [G loss: 0.823886]\n",
      "epoch:2 step:2215 [D loss: 0.693106, acc.: 53.91%] [G loss: 0.846239]\n",
      "epoch:2 step:2216 [D loss: 0.701296, acc.: 56.25%] [G loss: 0.866094]\n",
      "epoch:2 step:2217 [D loss: 0.647507, acc.: 62.50%] [G loss: 0.903523]\n",
      "epoch:2 step:2218 [D loss: 0.590700, acc.: 70.31%] [G loss: 1.031946]\n",
      "epoch:2 step:2219 [D loss: 0.636855, acc.: 62.50%] [G loss: 0.975971]\n",
      "epoch:2 step:2220 [D loss: 0.686247, acc.: 58.59%] [G loss: 0.941695]\n",
      "epoch:2 step:2221 [D loss: 0.593241, acc.: 72.66%] [G loss: 0.967960]\n",
      "epoch:2 step:2222 [D loss: 0.745236, acc.: 54.69%] [G loss: 0.852502]\n",
      "epoch:2 step:2223 [D loss: 0.791507, acc.: 40.62%] [G loss: 0.819817]\n",
      "epoch:2 step:2224 [D loss: 0.691766, acc.: 52.34%] [G loss: 0.781672]\n",
      "epoch:2 step:2225 [D loss: 0.706795, acc.: 50.00%] [G loss: 0.756064]\n",
      "epoch:2 step:2226 [D loss: 0.728572, acc.: 46.88%] [G loss: 0.892419]\n",
      "epoch:2 step:2227 [D loss: 0.687472, acc.: 59.38%] [G loss: 0.857492]\n",
      "epoch:2 step:2228 [D loss: 0.658230, acc.: 62.50%] [G loss: 0.822589]\n",
      "epoch:2 step:2229 [D loss: 0.700608, acc.: 55.47%] [G loss: 0.919253]\n",
      "epoch:2 step:2230 [D loss: 0.657878, acc.: 63.28%] [G loss: 0.807271]\n",
      "epoch:2 step:2231 [D loss: 0.715443, acc.: 52.34%] [G loss: 0.813445]\n",
      "epoch:2 step:2232 [D loss: 0.646561, acc.: 63.28%] [G loss: 0.879433]\n",
      "epoch:2 step:2233 [D loss: 0.688942, acc.: 55.47%] [G loss: 0.793717]\n",
      "epoch:2 step:2234 [D loss: 0.736677, acc.: 48.44%] [G loss: 0.852473]\n",
      "epoch:2 step:2235 [D loss: 0.703132, acc.: 46.88%] [G loss: 0.808431]\n",
      "epoch:2 step:2236 [D loss: 0.717746, acc.: 46.09%] [G loss: 0.903540]\n",
      "epoch:2 step:2237 [D loss: 0.681172, acc.: 60.94%] [G loss: 0.842445]\n",
      "epoch:2 step:2238 [D loss: 0.673842, acc.: 57.03%] [G loss: 0.801640]\n",
      "epoch:2 step:2239 [D loss: 0.696254, acc.: 57.81%] [G loss: 0.854711]\n",
      "epoch:2 step:2240 [D loss: 0.722028, acc.: 47.66%] [G loss: 0.877280]\n",
      "epoch:2 step:2241 [D loss: 0.717925, acc.: 49.22%] [G loss: 0.888238]\n",
      "epoch:2 step:2242 [D loss: 0.690278, acc.: 57.81%] [G loss: 0.878347]\n",
      "epoch:2 step:2243 [D loss: 0.670382, acc.: 59.38%] [G loss: 0.891291]\n",
      "epoch:2 step:2244 [D loss: 0.669618, acc.: 57.03%] [G loss: 0.976774]\n",
      "epoch:2 step:2245 [D loss: 0.684199, acc.: 51.56%] [G loss: 0.901555]\n",
      "epoch:2 step:2246 [D loss: 0.697026, acc.: 57.81%] [G loss: 0.765586]\n",
      "epoch:2 step:2247 [D loss: 0.729473, acc.: 49.22%] [G loss: 0.801269]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:2 step:2248 [D loss: 0.641685, acc.: 66.41%] [G loss: 0.851575]\n",
      "epoch:2 step:2249 [D loss: 0.677448, acc.: 54.69%] [G loss: 0.832269]\n",
      "epoch:2 step:2250 [D loss: 0.711869, acc.: 52.34%] [G loss: 0.832371]\n",
      "epoch:2 step:2251 [D loss: 0.711098, acc.: 51.56%] [G loss: 0.921297]\n",
      "epoch:2 step:2252 [D loss: 0.684752, acc.: 53.91%] [G loss: 0.886299]\n",
      "epoch:2 step:2253 [D loss: 0.729975, acc.: 44.53%] [G loss: 0.826896]\n",
      "epoch:2 step:2254 [D loss: 0.708201, acc.: 52.34%] [G loss: 0.898038]\n",
      "epoch:2 step:2255 [D loss: 0.656114, acc.: 60.94%] [G loss: 0.891730]\n",
      "epoch:2 step:2256 [D loss: 0.673990, acc.: 58.59%] [G loss: 0.890835]\n",
      "epoch:2 step:2257 [D loss: 0.642322, acc.: 60.94%] [G loss: 0.929415]\n",
      "epoch:2 step:2258 [D loss: 0.701861, acc.: 51.56%] [G loss: 0.857659]\n",
      "epoch:2 step:2259 [D loss: 0.651302, acc.: 60.94%] [G loss: 0.900468]\n",
      "epoch:2 step:2260 [D loss: 0.637564, acc.: 69.53%] [G loss: 0.797043]\n",
      "epoch:2 step:2261 [D loss: 0.708801, acc.: 50.00%] [G loss: 0.805391]\n",
      "epoch:2 step:2262 [D loss: 0.680357, acc.: 56.25%] [G loss: 0.777779]\n",
      "epoch:2 step:2263 [D loss: 0.726339, acc.: 46.09%] [G loss: 0.794654]\n",
      "epoch:2 step:2264 [D loss: 0.708476, acc.: 50.00%] [G loss: 0.799443]\n",
      "epoch:2 step:2265 [D loss: 0.730684, acc.: 51.56%] [G loss: 0.829711]\n",
      "epoch:2 step:2266 [D loss: 0.702554, acc.: 55.47%] [G loss: 0.852822]\n",
      "epoch:2 step:2267 [D loss: 0.706232, acc.: 55.47%] [G loss: 0.838998]\n",
      "epoch:2 step:2268 [D loss: 0.708235, acc.: 44.53%] [G loss: 0.799504]\n",
      "epoch:2 step:2269 [D loss: 0.699500, acc.: 52.34%] [G loss: 0.780007]\n",
      "epoch:2 step:2270 [D loss: 0.735762, acc.: 46.88%] [G loss: 0.814984]\n",
      "epoch:2 step:2271 [D loss: 0.688517, acc.: 57.81%] [G loss: 0.882494]\n",
      "epoch:2 step:2272 [D loss: 0.652403, acc.: 59.38%] [G loss: 0.784681]\n",
      "epoch:2 step:2273 [D loss: 0.649117, acc.: 62.50%] [G loss: 0.858770]\n",
      "epoch:2 step:2274 [D loss: 0.641180, acc.: 59.38%] [G loss: 0.792347]\n",
      "epoch:2 step:2275 [D loss: 0.694314, acc.: 51.56%] [G loss: 0.811259]\n",
      "epoch:2 step:2276 [D loss: 0.638502, acc.: 63.28%] [G loss: 0.820183]\n",
      "epoch:2 step:2277 [D loss: 0.668245, acc.: 55.47%] [G loss: 0.847658]\n",
      "epoch:2 step:2278 [D loss: 0.680166, acc.: 59.38%] [G loss: 0.821940]\n",
      "epoch:2 step:2279 [D loss: 0.673144, acc.: 56.25%] [G loss: 0.765259]\n",
      "epoch:2 step:2280 [D loss: 0.648272, acc.: 63.28%] [G loss: 0.867354]\n",
      "epoch:2 step:2281 [D loss: 0.681375, acc.: 56.25%] [G loss: 0.862816]\n",
      "epoch:2 step:2282 [D loss: 0.715564, acc.: 61.72%] [G loss: 0.806766]\n",
      "epoch:2 step:2283 [D loss: 0.706193, acc.: 60.16%] [G loss: 0.781061]\n",
      "epoch:2 step:2284 [D loss: 0.749853, acc.: 42.97%] [G loss: 0.782449]\n",
      "epoch:2 step:2285 [D loss: 0.732296, acc.: 52.34%] [G loss: 0.843580]\n",
      "epoch:2 step:2286 [D loss: 0.697736, acc.: 57.03%] [G loss: 0.844319]\n",
      "epoch:2 step:2287 [D loss: 0.700212, acc.: 53.12%] [G loss: 0.874117]\n",
      "epoch:2 step:2288 [D loss: 0.666821, acc.: 55.47%] [G loss: 0.875306]\n",
      "epoch:2 step:2289 [D loss: 0.684281, acc.: 51.56%] [G loss: 0.890785]\n",
      "epoch:2 step:2290 [D loss: 0.672919, acc.: 56.25%] [G loss: 0.893180]\n",
      "epoch:2 step:2291 [D loss: 0.676953, acc.: 60.16%] [G loss: 0.822606]\n",
      "epoch:2 step:2292 [D loss: 0.680291, acc.: 51.56%] [G loss: 0.878935]\n",
      "epoch:2 step:2293 [D loss: 0.682600, acc.: 58.59%] [G loss: 0.840295]\n",
      "epoch:2 step:2294 [D loss: 0.692193, acc.: 54.69%] [G loss: 0.868499]\n",
      "epoch:2 step:2295 [D loss: 0.730701, acc.: 46.88%] [G loss: 0.815375]\n",
      "epoch:2 step:2296 [D loss: 0.732734, acc.: 43.75%] [G loss: 0.787969]\n",
      "epoch:2 step:2297 [D loss: 0.678308, acc.: 54.69%] [G loss: 0.795516]\n",
      "epoch:2 step:2298 [D loss: 0.696525, acc.: 52.34%] [G loss: 0.864051]\n",
      "epoch:2 step:2299 [D loss: 0.646851, acc.: 64.84%] [G loss: 0.769047]\n",
      "epoch:2 step:2300 [D loss: 0.660401, acc.: 62.50%] [G loss: 0.870559]\n",
      "epoch:2 step:2301 [D loss: 0.723940, acc.: 48.44%] [G loss: 0.798949]\n",
      "epoch:2 step:2302 [D loss: 0.655356, acc.: 65.62%] [G loss: 0.849530]\n",
      "epoch:2 step:2303 [D loss: 0.687075, acc.: 55.47%] [G loss: 0.882431]\n",
      "epoch:2 step:2304 [D loss: 0.664634, acc.: 60.94%] [G loss: 0.934015]\n",
      "epoch:2 step:2305 [D loss: 0.693320, acc.: 57.03%] [G loss: 0.820560]\n",
      "epoch:2 step:2306 [D loss: 0.738671, acc.: 47.66%] [G loss: 0.858570]\n",
      "epoch:2 step:2307 [D loss: 0.703245, acc.: 54.69%] [G loss: 0.890882]\n",
      "epoch:2 step:2308 [D loss: 0.651917, acc.: 57.03%] [G loss: 0.871789]\n",
      "epoch:2 step:2309 [D loss: 0.682975, acc.: 59.38%] [G loss: 0.839795]\n",
      "epoch:2 step:2310 [D loss: 0.650752, acc.: 61.72%] [G loss: 0.832587]\n",
      "epoch:2 step:2311 [D loss: 0.774641, acc.: 43.75%] [G loss: 0.793119]\n",
      "epoch:2 step:2312 [D loss: 0.687154, acc.: 49.22%] [G loss: 0.885634]\n",
      "epoch:2 step:2313 [D loss: 0.714758, acc.: 50.00%] [G loss: 0.824084]\n",
      "epoch:2 step:2314 [D loss: 0.711258, acc.: 51.56%] [G loss: 0.870093]\n",
      "epoch:2 step:2315 [D loss: 0.721949, acc.: 47.66%] [G loss: 0.842907]\n",
      "epoch:2 step:2316 [D loss: 0.688175, acc.: 57.03%] [G loss: 0.913509]\n",
      "epoch:2 step:2317 [D loss: 0.694111, acc.: 53.12%] [G loss: 0.885352]\n",
      "epoch:2 step:2318 [D loss: 0.662295, acc.: 56.25%] [G loss: 0.948955]\n",
      "epoch:2 step:2319 [D loss: 0.677465, acc.: 58.59%] [G loss: 0.909154]\n",
      "epoch:2 step:2320 [D loss: 0.673814, acc.: 56.25%] [G loss: 0.899266]\n",
      "epoch:2 step:2321 [D loss: 0.675396, acc.: 55.47%] [G loss: 0.828953]\n",
      "epoch:2 step:2322 [D loss: 0.733517, acc.: 49.22%] [G loss: 0.823430]\n",
      "epoch:2 step:2323 [D loss: 0.729880, acc.: 47.66%] [G loss: 0.828232]\n",
      "epoch:2 step:2324 [D loss: 0.695087, acc.: 57.03%] [G loss: 0.786447]\n",
      "epoch:2 step:2325 [D loss: 0.703797, acc.: 50.78%] [G loss: 0.872953]\n",
      "epoch:2 step:2326 [D loss: 0.675230, acc.: 57.81%] [G loss: 0.883596]\n",
      "epoch:2 step:2327 [D loss: 0.694247, acc.: 51.56%] [G loss: 0.822693]\n",
      "epoch:2 step:2328 [D loss: 0.695351, acc.: 56.25%] [G loss: 0.884805]\n",
      "epoch:2 step:2329 [D loss: 0.653688, acc.: 57.03%] [G loss: 0.879597]\n",
      "epoch:2 step:2330 [D loss: 0.642247, acc.: 60.94%] [G loss: 0.943888]\n",
      "epoch:2 step:2331 [D loss: 0.632594, acc.: 64.84%] [G loss: 0.928500]\n",
      "epoch:2 step:2332 [D loss: 0.698677, acc.: 52.34%] [G loss: 0.868438]\n",
      "epoch:2 step:2333 [D loss: 0.695615, acc.: 55.47%] [G loss: 0.848498]\n",
      "epoch:2 step:2334 [D loss: 0.705340, acc.: 53.12%] [G loss: 0.782567]\n",
      "epoch:2 step:2335 [D loss: 0.716322, acc.: 54.69%] [G loss: 0.835964]\n",
      "epoch:2 step:2336 [D loss: 0.753857, acc.: 45.31%] [G loss: 0.838197]\n",
      "epoch:2 step:2337 [D loss: 0.672073, acc.: 56.25%] [G loss: 0.837297]\n",
      "epoch:2 step:2338 [D loss: 0.677020, acc.: 60.16%] [G loss: 0.819198]\n",
      "epoch:2 step:2339 [D loss: 0.687440, acc.: 57.03%] [G loss: 0.892862]\n",
      "epoch:2 step:2340 [D loss: 0.673875, acc.: 57.81%] [G loss: 0.846869]\n",
      "epoch:2 step:2341 [D loss: 0.668434, acc.: 59.38%] [G loss: 0.900449]\n",
      "epoch:2 step:2342 [D loss: 0.657155, acc.: 62.50%] [G loss: 0.887102]\n",
      "epoch:2 step:2343 [D loss: 0.697730, acc.: 50.00%] [G loss: 0.846213]\n",
      "epoch:2 step:2344 [D loss: 0.682423, acc.: 54.69%] [G loss: 0.847852]\n",
      "epoch:2 step:2345 [D loss: 0.700790, acc.: 55.47%] [G loss: 0.774851]\n",
      "epoch:2 step:2346 [D loss: 0.695917, acc.: 55.47%] [G loss: 0.873206]\n",
      "epoch:2 step:2347 [D loss: 0.739189, acc.: 41.41%] [G loss: 0.856750]\n",
      "epoch:2 step:2348 [D loss: 0.712018, acc.: 50.00%] [G loss: 0.838467]\n",
      "epoch:2 step:2349 [D loss: 0.655767, acc.: 61.72%] [G loss: 0.890334]\n",
      "epoch:2 step:2350 [D loss: 0.666103, acc.: 56.25%] [G loss: 0.865940]\n",
      "epoch:2 step:2351 [D loss: 0.681435, acc.: 54.69%] [G loss: 0.904933]\n",
      "epoch:2 step:2352 [D loss: 0.677188, acc.: 58.59%] [G loss: 0.865953]\n",
      "epoch:2 step:2353 [D loss: 0.707276, acc.: 51.56%] [G loss: 0.809239]\n",
      "epoch:2 step:2354 [D loss: 0.723768, acc.: 48.44%] [G loss: 0.796371]\n",
      "epoch:2 step:2355 [D loss: 0.717988, acc.: 40.62%] [G loss: 0.797806]\n",
      "epoch:2 step:2356 [D loss: 0.699167, acc.: 51.56%] [G loss: 0.812912]\n",
      "epoch:2 step:2357 [D loss: 0.670715, acc.: 53.91%] [G loss: 0.811828]\n",
      "epoch:2 step:2358 [D loss: 0.668864, acc.: 60.16%] [G loss: 0.737563]\n",
      "epoch:2 step:2359 [D loss: 0.672518, acc.: 57.81%] [G loss: 0.804136]\n",
      "epoch:2 step:2360 [D loss: 0.729374, acc.: 42.97%] [G loss: 0.849545]\n",
      "epoch:2 step:2361 [D loss: 0.730719, acc.: 50.00%] [G loss: 0.798136]\n",
      "epoch:2 step:2362 [D loss: 0.693748, acc.: 52.34%] [G loss: 0.764896]\n",
      "epoch:2 step:2363 [D loss: 0.688856, acc.: 51.56%] [G loss: 0.787909]\n",
      "epoch:2 step:2364 [D loss: 0.688117, acc.: 54.69%] [G loss: 0.746205]\n",
      "epoch:2 step:2365 [D loss: 0.724807, acc.: 48.44%] [G loss: 0.771075]\n",
      "epoch:2 step:2366 [D loss: 0.703127, acc.: 50.78%] [G loss: 0.795528]\n",
      "epoch:2 step:2367 [D loss: 0.657424, acc.: 61.72%] [G loss: 0.852586]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:2 step:2368 [D loss: 0.659019, acc.: 64.84%] [G loss: 0.852353]\n",
      "epoch:2 step:2369 [D loss: 0.660543, acc.: 58.59%] [G loss: 0.768572]\n",
      "epoch:2 step:2370 [D loss: 0.714960, acc.: 53.12%] [G loss: 0.860266]\n",
      "epoch:2 step:2371 [D loss: 0.662901, acc.: 64.84%] [G loss: 0.853489]\n",
      "epoch:2 step:2372 [D loss: 0.703018, acc.: 57.03%] [G loss: 0.835859]\n",
      "epoch:2 step:2373 [D loss: 0.661728, acc.: 55.47%] [G loss: 0.824201]\n",
      "epoch:2 step:2374 [D loss: 0.725962, acc.: 48.44%] [G loss: 0.856203]\n",
      "epoch:2 step:2375 [D loss: 0.766416, acc.: 41.41%] [G loss: 0.788067]\n",
      "epoch:2 step:2376 [D loss: 0.703653, acc.: 50.78%] [G loss: 0.824102]\n",
      "epoch:2 step:2377 [D loss: 0.712200, acc.: 46.88%] [G loss: 0.812417]\n",
      "epoch:2 step:2378 [D loss: 0.673373, acc.: 58.59%] [G loss: 0.838954]\n",
      "epoch:2 step:2379 [D loss: 0.672906, acc.: 58.59%] [G loss: 0.870230]\n",
      "epoch:2 step:2380 [D loss: 0.706024, acc.: 41.41%] [G loss: 0.854050]\n",
      "epoch:2 step:2381 [D loss: 0.659618, acc.: 62.50%] [G loss: 0.892273]\n",
      "epoch:2 step:2382 [D loss: 0.635025, acc.: 64.06%] [G loss: 0.809648]\n",
      "epoch:2 step:2383 [D loss: 0.673337, acc.: 60.16%] [G loss: 0.853381]\n",
      "epoch:2 step:2384 [D loss: 0.760821, acc.: 39.06%] [G loss: 0.803712]\n",
      "epoch:2 step:2385 [D loss: 0.737205, acc.: 41.41%] [G loss: 0.762572]\n",
      "epoch:2 step:2386 [D loss: 0.700058, acc.: 50.78%] [G loss: 0.757231]\n",
      "epoch:2 step:2387 [D loss: 0.664923, acc.: 59.38%] [G loss: 0.844784]\n",
      "epoch:2 step:2388 [D loss: 0.681814, acc.: 57.03%] [G loss: 0.863445]\n",
      "epoch:2 step:2389 [D loss: 0.659860, acc.: 63.28%] [G loss: 0.842526]\n",
      "epoch:2 step:2390 [D loss: 0.623850, acc.: 69.53%] [G loss: 0.876459]\n",
      "epoch:2 step:2391 [D loss: 0.682875, acc.: 48.44%] [G loss: 0.851611]\n",
      "epoch:2 step:2392 [D loss: 0.689616, acc.: 53.12%] [G loss: 0.847332]\n",
      "epoch:2 step:2393 [D loss: 0.677713, acc.: 58.59%] [G loss: 0.786155]\n",
      "epoch:2 step:2394 [D loss: 0.647873, acc.: 65.62%] [G loss: 0.848799]\n",
      "epoch:2 step:2395 [D loss: 0.672385, acc.: 56.25%] [G loss: 0.905787]\n",
      "epoch:2 step:2396 [D loss: 0.642001, acc.: 63.28%] [G loss: 0.875007]\n",
      "epoch:2 step:2397 [D loss: 0.650723, acc.: 65.62%] [G loss: 0.831411]\n",
      "epoch:2 step:2398 [D loss: 0.680217, acc.: 55.47%] [G loss: 0.792482]\n",
      "epoch:2 step:2399 [D loss: 0.731159, acc.: 48.44%] [G loss: 0.766786]\n",
      "epoch:2 step:2400 [D loss: 0.720692, acc.: 50.00%] [G loss: 0.863377]\n",
      "##############\n",
      "[3.74876928 2.60061065 5.98064635 5.06443877 3.99915482 6.01456153\n",
      " 4.79227317 5.30221278 5.09172035 4.59612304]\n",
      "##########\n",
      "epoch:2 step:2401 [D loss: 0.742014, acc.: 48.44%] [G loss: 0.812471]\n",
      "epoch:2 step:2402 [D loss: 0.741048, acc.: 42.97%] [G loss: 0.753852]\n",
      "epoch:2 step:2403 [D loss: 0.739523, acc.: 46.09%] [G loss: 0.778305]\n",
      "epoch:2 step:2404 [D loss: 0.699105, acc.: 49.22%] [G loss: 0.825570]\n",
      "epoch:2 step:2405 [D loss: 0.681308, acc.: 54.69%] [G loss: 0.889230]\n",
      "epoch:2 step:2406 [D loss: 0.703120, acc.: 58.59%] [G loss: 0.822972]\n",
      "epoch:2 step:2407 [D loss: 0.666639, acc.: 60.16%] [G loss: 0.820270]\n",
      "epoch:2 step:2408 [D loss: 0.680108, acc.: 55.47%] [G loss: 0.800742]\n",
      "epoch:2 step:2409 [D loss: 0.689031, acc.: 53.91%] [G loss: 0.801788]\n",
      "epoch:2 step:2410 [D loss: 0.680427, acc.: 50.00%] [G loss: 0.784772]\n",
      "epoch:2 step:2411 [D loss: 0.748172, acc.: 46.09%] [G loss: 0.771509]\n",
      "epoch:2 step:2412 [D loss: 0.655195, acc.: 62.50%] [G loss: 0.820423]\n",
      "epoch:2 step:2413 [D loss: 0.714248, acc.: 51.56%] [G loss: 0.787333]\n",
      "epoch:2 step:2414 [D loss: 0.706895, acc.: 46.88%] [G loss: 0.704316]\n",
      "epoch:2 step:2415 [D loss: 0.674530, acc.: 59.38%] [G loss: 0.727107]\n",
      "epoch:2 step:2416 [D loss: 0.726189, acc.: 46.09%] [G loss: 0.764707]\n",
      "epoch:2 step:2417 [D loss: 0.703934, acc.: 52.34%] [G loss: 0.787666]\n",
      "epoch:2 step:2418 [D loss: 0.682105, acc.: 57.03%] [G loss: 0.852460]\n",
      "epoch:2 step:2419 [D loss: 0.687474, acc.: 53.91%] [G loss: 0.737577]\n",
      "epoch:2 step:2420 [D loss: 0.671648, acc.: 58.59%] [G loss: 0.807503]\n",
      "epoch:2 step:2421 [D loss: 0.690602, acc.: 53.91%] [G loss: 0.858650]\n",
      "epoch:2 step:2422 [D loss: 0.630407, acc.: 64.84%] [G loss: 0.773695]\n",
      "epoch:2 step:2423 [D loss: 0.672773, acc.: 60.16%] [G loss: 0.849812]\n",
      "epoch:2 step:2424 [D loss: 0.670048, acc.: 60.94%] [G loss: 0.851887]\n",
      "epoch:2 step:2425 [D loss: 0.624660, acc.: 69.53%] [G loss: 0.834902]\n",
      "epoch:2 step:2426 [D loss: 0.665287, acc.: 57.03%] [G loss: 0.841462]\n",
      "epoch:2 step:2427 [D loss: 0.730431, acc.: 48.44%] [G loss: 0.740858]\n",
      "epoch:2 step:2428 [D loss: 0.679075, acc.: 55.47%] [G loss: 0.802585]\n",
      "epoch:2 step:2429 [D loss: 0.683277, acc.: 55.47%] [G loss: 0.871356]\n",
      "epoch:2 step:2430 [D loss: 0.687358, acc.: 55.47%] [G loss: 0.818315]\n",
      "epoch:2 step:2431 [D loss: 0.674823, acc.: 60.16%] [G loss: 0.869257]\n",
      "epoch:2 step:2432 [D loss: 0.673845, acc.: 56.25%] [G loss: 0.896326]\n",
      "epoch:2 step:2433 [D loss: 0.700801, acc.: 51.56%] [G loss: 0.889783]\n",
      "epoch:2 step:2434 [D loss: 0.700574, acc.: 53.91%] [G loss: 0.889069]\n",
      "epoch:2 step:2435 [D loss: 0.657881, acc.: 62.50%] [G loss: 0.870641]\n",
      "epoch:2 step:2436 [D loss: 0.688483, acc.: 51.56%] [G loss: 0.856722]\n",
      "epoch:2 step:2437 [D loss: 0.655863, acc.: 59.38%] [G loss: 0.851731]\n",
      "epoch:2 step:2438 [D loss: 0.641697, acc.: 63.28%] [G loss: 0.883228]\n",
      "epoch:2 step:2439 [D loss: 0.725773, acc.: 47.66%] [G loss: 0.872611]\n",
      "epoch:2 step:2440 [D loss: 0.745171, acc.: 40.62%] [G loss: 0.845042]\n",
      "epoch:2 step:2441 [D loss: 0.697339, acc.: 57.03%] [G loss: 0.831501]\n",
      "epoch:2 step:2442 [D loss: 0.644228, acc.: 62.50%] [G loss: 0.958533]\n",
      "epoch:2 step:2443 [D loss: 0.677815, acc.: 57.81%] [G loss: 1.047915]\n",
      "epoch:2 step:2444 [D loss: 0.662380, acc.: 64.06%] [G loss: 0.956548]\n",
      "epoch:2 step:2445 [D loss: 0.630970, acc.: 65.62%] [G loss: 0.951458]\n",
      "epoch:2 step:2446 [D loss: 0.648800, acc.: 60.94%] [G loss: 0.914952]\n",
      "epoch:2 step:2447 [D loss: 0.610672, acc.: 67.97%] [G loss: 0.912730]\n",
      "epoch:2 step:2448 [D loss: 0.626041, acc.: 66.41%] [G loss: 0.908570]\n",
      "epoch:2 step:2449 [D loss: 0.651191, acc.: 62.50%] [G loss: 0.946881]\n",
      "epoch:2 step:2450 [D loss: 0.750096, acc.: 46.88%] [G loss: 0.813434]\n",
      "epoch:2 step:2451 [D loss: 0.780347, acc.: 37.50%] [G loss: 0.752312]\n",
      "epoch:2 step:2452 [D loss: 0.737668, acc.: 48.44%] [G loss: 0.775513]\n",
      "epoch:2 step:2453 [D loss: 0.720420, acc.: 56.25%] [G loss: 0.858996]\n",
      "epoch:2 step:2454 [D loss: 0.756015, acc.: 43.75%] [G loss: 0.822559]\n",
      "epoch:2 step:2455 [D loss: 0.707117, acc.: 46.88%] [G loss: 0.879574]\n",
      "epoch:2 step:2456 [D loss: 0.708801, acc.: 53.12%] [G loss: 0.839019]\n",
      "epoch:2 step:2457 [D loss: 0.705170, acc.: 49.22%] [G loss: 0.842066]\n",
      "epoch:2 step:2458 [D loss: 0.699221, acc.: 50.78%] [G loss: 0.906218]\n",
      "epoch:2 step:2459 [D loss: 0.668144, acc.: 55.47%] [G loss: 0.955969]\n",
      "epoch:2 step:2460 [D loss: 0.627623, acc.: 66.41%] [G loss: 0.964095]\n",
      "epoch:2 step:2461 [D loss: 0.684941, acc.: 53.12%] [G loss: 0.905870]\n",
      "epoch:2 step:2462 [D loss: 0.643160, acc.: 71.09%] [G loss: 0.913918]\n",
      "epoch:2 step:2463 [D loss: 0.604970, acc.: 71.88%] [G loss: 0.971013]\n",
      "epoch:2 step:2464 [D loss: 0.663104, acc.: 63.28%] [G loss: 0.933467]\n",
      "epoch:2 step:2465 [D loss: 0.668205, acc.: 56.25%] [G loss: 0.921525]\n",
      "epoch:2 step:2466 [D loss: 0.703540, acc.: 53.12%] [G loss: 0.816428]\n",
      "epoch:2 step:2467 [D loss: 0.753848, acc.: 44.53%] [G loss: 0.843078]\n",
      "epoch:2 step:2468 [D loss: 0.732347, acc.: 43.75%] [G loss: 0.812703]\n",
      "epoch:2 step:2469 [D loss: 0.672635, acc.: 54.69%] [G loss: 0.782982]\n",
      "epoch:2 step:2470 [D loss: 0.713860, acc.: 51.56%] [G loss: 0.799396]\n",
      "epoch:2 step:2471 [D loss: 0.754646, acc.: 47.66%] [G loss: 0.876103]\n",
      "epoch:2 step:2472 [D loss: 0.648686, acc.: 67.19%] [G loss: 0.854999]\n",
      "epoch:2 step:2473 [D loss: 0.693086, acc.: 59.38%] [G loss: 0.892453]\n",
      "epoch:2 step:2474 [D loss: 0.679230, acc.: 53.12%] [G loss: 0.932100]\n",
      "epoch:2 step:2475 [D loss: 0.708750, acc.: 49.22%] [G loss: 0.915859]\n",
      "epoch:2 step:2476 [D loss: 0.698349, acc.: 48.44%] [G loss: 0.956544]\n",
      "epoch:2 step:2477 [D loss: 0.686065, acc.: 58.59%] [G loss: 0.888301]\n",
      "epoch:2 step:2478 [D loss: 0.703080, acc.: 53.12%] [G loss: 0.833347]\n",
      "epoch:2 step:2479 [D loss: 0.678391, acc.: 57.03%] [G loss: 0.815783]\n",
      "epoch:2 step:2480 [D loss: 0.705696, acc.: 47.66%] [G loss: 0.775012]\n",
      "epoch:2 step:2481 [D loss: 0.721335, acc.: 53.12%] [G loss: 0.789392]\n",
      "epoch:2 step:2482 [D loss: 0.726810, acc.: 49.22%] [G loss: 0.764216]\n",
      "epoch:2 step:2483 [D loss: 0.718379, acc.: 50.78%] [G loss: 0.787898]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:2 step:2484 [D loss: 0.726101, acc.: 44.53%] [G loss: 0.756310]\n",
      "epoch:2 step:2485 [D loss: 0.688051, acc.: 50.78%] [G loss: 0.704529]\n",
      "epoch:2 step:2486 [D loss: 0.653643, acc.: 60.16%] [G loss: 0.784898]\n",
      "epoch:2 step:2487 [D loss: 0.699486, acc.: 49.22%] [G loss: 0.769276]\n",
      "epoch:2 step:2488 [D loss: 0.762460, acc.: 41.41%] [G loss: 0.778288]\n",
      "epoch:2 step:2489 [D loss: 0.752848, acc.: 39.84%] [G loss: 0.762611]\n",
      "epoch:2 step:2490 [D loss: 0.706021, acc.: 47.66%] [G loss: 0.796846]\n",
      "epoch:2 step:2491 [D loss: 0.675802, acc.: 55.47%] [G loss: 0.769604]\n",
      "epoch:2 step:2492 [D loss: 0.660542, acc.: 59.38%] [G loss: 0.835255]\n",
      "epoch:2 step:2493 [D loss: 0.681709, acc.: 56.25%] [G loss: 0.787938]\n",
      "epoch:2 step:2494 [D loss: 0.651907, acc.: 59.38%] [G loss: 0.769210]\n",
      "epoch:2 step:2495 [D loss: 0.684146, acc.: 50.78%] [G loss: 0.820121]\n",
      "epoch:2 step:2496 [D loss: 0.655489, acc.: 54.69%] [G loss: 0.831828]\n",
      "epoch:2 step:2497 [D loss: 0.686372, acc.: 57.81%] [G loss: 0.868700]\n",
      "epoch:2 step:2498 [D loss: 0.662285, acc.: 57.81%] [G loss: 0.869881]\n",
      "epoch:2 step:2499 [D loss: 0.757711, acc.: 50.00%] [G loss: 0.813998]\n",
      "epoch:2 step:2500 [D loss: 0.703910, acc.: 56.25%] [G loss: 0.780254]\n",
      "epoch:2 step:2501 [D loss: 0.679540, acc.: 56.25%] [G loss: 0.751303]\n",
      "epoch:2 step:2502 [D loss: 0.698936, acc.: 53.91%] [G loss: 0.813884]\n",
      "epoch:2 step:2503 [D loss: 0.682782, acc.: 58.59%] [G loss: 0.792700]\n",
      "epoch:2 step:2504 [D loss: 0.663812, acc.: 59.38%] [G loss: 0.901869]\n",
      "epoch:2 step:2505 [D loss: 0.661328, acc.: 64.06%] [G loss: 0.883445]\n",
      "epoch:2 step:2506 [D loss: 0.692698, acc.: 59.38%] [G loss: 0.857182]\n",
      "epoch:2 step:2507 [D loss: 0.724460, acc.: 47.66%] [G loss: 0.845786]\n",
      "epoch:2 step:2508 [D loss: 0.645007, acc.: 65.62%] [G loss: 0.854491]\n",
      "epoch:2 step:2509 [D loss: 0.653177, acc.: 58.59%] [G loss: 0.892318]\n",
      "epoch:2 step:2510 [D loss: 0.668290, acc.: 57.81%] [G loss: 0.869794]\n",
      "epoch:2 step:2511 [D loss: 0.670826, acc.: 55.47%] [G loss: 0.875820]\n",
      "epoch:2 step:2512 [D loss: 0.710869, acc.: 50.00%] [G loss: 0.873122]\n",
      "epoch:2 step:2513 [D loss: 0.697119, acc.: 49.22%] [G loss: 0.821886]\n",
      "epoch:2 step:2514 [D loss: 0.711044, acc.: 45.31%] [G loss: 0.792761]\n",
      "epoch:2 step:2515 [D loss: 0.726061, acc.: 50.00%] [G loss: 0.794908]\n",
      "epoch:2 step:2516 [D loss: 0.736151, acc.: 47.66%] [G loss: 0.776214]\n",
      "epoch:2 step:2517 [D loss: 0.726921, acc.: 49.22%] [G loss: 0.813708]\n",
      "epoch:2 step:2518 [D loss: 0.718776, acc.: 43.75%] [G loss: 0.753082]\n",
      "epoch:2 step:2519 [D loss: 0.715660, acc.: 53.91%] [G loss: 0.797716]\n",
      "epoch:2 step:2520 [D loss: 0.713672, acc.: 50.00%] [G loss: 0.848483]\n",
      "epoch:2 step:2521 [D loss: 0.678670, acc.: 51.56%] [G loss: 0.834673]\n",
      "epoch:2 step:2522 [D loss: 0.654160, acc.: 60.94%] [G loss: 0.905959]\n",
      "epoch:2 step:2523 [D loss: 0.679479, acc.: 53.91%] [G loss: 0.971537]\n",
      "epoch:2 step:2524 [D loss: 0.618392, acc.: 65.62%] [G loss: 0.856473]\n",
      "epoch:2 step:2525 [D loss: 0.661073, acc.: 61.72%] [G loss: 0.863855]\n",
      "epoch:2 step:2526 [D loss: 0.721204, acc.: 51.56%] [G loss: 0.813887]\n",
      "epoch:2 step:2527 [D loss: 0.693764, acc.: 48.44%] [G loss: 0.839659]\n",
      "epoch:2 step:2528 [D loss: 0.700138, acc.: 56.25%] [G loss: 0.834500]\n",
      "epoch:2 step:2529 [D loss: 0.727989, acc.: 49.22%] [G loss: 0.804714]\n",
      "epoch:2 step:2530 [D loss: 0.719533, acc.: 50.78%] [G loss: 0.843770]\n",
      "epoch:2 step:2531 [D loss: 0.703139, acc.: 53.91%] [G loss: 0.764306]\n",
      "epoch:2 step:2532 [D loss: 0.706205, acc.: 49.22%] [G loss: 0.785670]\n",
      "epoch:2 step:2533 [D loss: 0.660564, acc.: 59.38%] [G loss: 0.837406]\n",
      "epoch:2 step:2534 [D loss: 0.624810, acc.: 67.19%] [G loss: 0.810674]\n",
      "epoch:2 step:2535 [D loss: 0.626229, acc.: 66.41%] [G loss: 0.909984]\n",
      "epoch:2 step:2536 [D loss: 0.697310, acc.: 52.34%] [G loss: 0.863901]\n",
      "epoch:2 step:2537 [D loss: 0.719977, acc.: 53.91%] [G loss: 0.849307]\n",
      "epoch:2 step:2538 [D loss: 0.685056, acc.: 53.91%] [G loss: 0.844253]\n",
      "epoch:2 step:2539 [D loss: 0.718188, acc.: 43.75%] [G loss: 0.804739]\n",
      "epoch:2 step:2540 [D loss: 0.682528, acc.: 54.69%] [G loss: 0.780115]\n",
      "epoch:2 step:2541 [D loss: 0.702275, acc.: 52.34%] [G loss: 0.803472]\n",
      "epoch:2 step:2542 [D loss: 0.688459, acc.: 57.81%] [G loss: 0.763573]\n",
      "epoch:2 step:2543 [D loss: 0.710473, acc.: 47.66%] [G loss: 0.798652]\n",
      "epoch:2 step:2544 [D loss: 0.733713, acc.: 43.75%] [G loss: 0.782603]\n",
      "epoch:2 step:2545 [D loss: 0.736700, acc.: 46.09%] [G loss: 0.800366]\n",
      "epoch:2 step:2546 [D loss: 0.717965, acc.: 48.44%] [G loss: 0.813043]\n",
      "epoch:2 step:2547 [D loss: 0.689020, acc.: 52.34%] [G loss: 0.815765]\n",
      "epoch:2 step:2548 [D loss: 0.708374, acc.: 47.66%] [G loss: 0.861559]\n",
      "epoch:2 step:2549 [D loss: 0.721689, acc.: 48.44%] [G loss: 0.801423]\n",
      "epoch:2 step:2550 [D loss: 0.673898, acc.: 58.59%] [G loss: 0.836308]\n",
      "epoch:2 step:2551 [D loss: 0.656166, acc.: 57.81%] [G loss: 0.844937]\n",
      "epoch:2 step:2552 [D loss: 0.659659, acc.: 60.16%] [G loss: 0.824212]\n",
      "epoch:2 step:2553 [D loss: 0.681808, acc.: 53.91%] [G loss: 0.834894]\n",
      "epoch:2 step:2554 [D loss: 0.659618, acc.: 61.72%] [G loss: 0.788604]\n",
      "epoch:2 step:2555 [D loss: 0.665478, acc.: 61.72%] [G loss: 0.869318]\n",
      "epoch:2 step:2556 [D loss: 0.696743, acc.: 49.22%] [G loss: 0.797780]\n",
      "epoch:2 step:2557 [D loss: 0.716904, acc.: 45.31%] [G loss: 0.778107]\n",
      "epoch:2 step:2558 [D loss: 0.723676, acc.: 50.00%] [G loss: 0.786898]\n",
      "epoch:2 step:2559 [D loss: 0.682026, acc.: 60.94%] [G loss: 0.777973]\n",
      "epoch:2 step:2560 [D loss: 0.663369, acc.: 64.06%] [G loss: 0.748304]\n",
      "epoch:2 step:2561 [D loss: 0.673382, acc.: 61.72%] [G loss: 0.844254]\n",
      "epoch:2 step:2562 [D loss: 0.659972, acc.: 61.72%] [G loss: 0.793240]\n",
      "epoch:2 step:2563 [D loss: 0.702837, acc.: 50.78%] [G loss: 0.768332]\n",
      "epoch:2 step:2564 [D loss: 0.708619, acc.: 48.44%] [G loss: 0.812823]\n",
      "epoch:2 step:2565 [D loss: 0.694456, acc.: 52.34%] [G loss: 0.738367]\n",
      "epoch:2 step:2566 [D loss: 0.741247, acc.: 48.44%] [G loss: 0.806215]\n",
      "epoch:2 step:2567 [D loss: 0.683058, acc.: 59.38%] [G loss: 0.794692]\n",
      "epoch:2 step:2568 [D loss: 0.652525, acc.: 64.84%] [G loss: 0.821283]\n",
      "epoch:2 step:2569 [D loss: 0.716715, acc.: 52.34%] [G loss: 0.834347]\n",
      "epoch:2 step:2570 [D loss: 0.704633, acc.: 48.44%] [G loss: 0.835999]\n",
      "epoch:2 step:2571 [D loss: 0.682551, acc.: 57.81%] [G loss: 0.901412]\n",
      "epoch:2 step:2572 [D loss: 0.695436, acc.: 52.34%] [G loss: 0.863414]\n",
      "epoch:2 step:2573 [D loss: 0.716041, acc.: 53.12%] [G loss: 0.817856]\n",
      "epoch:2 step:2574 [D loss: 0.644278, acc.: 59.38%] [G loss: 0.854739]\n",
      "epoch:2 step:2575 [D loss: 0.652027, acc.: 60.16%] [G loss: 0.878404]\n",
      "epoch:2 step:2576 [D loss: 0.681109, acc.: 55.47%] [G loss: 0.866762]\n",
      "epoch:2 step:2577 [D loss: 0.667480, acc.: 56.25%] [G loss: 0.829993]\n",
      "epoch:2 step:2578 [D loss: 0.703692, acc.: 49.22%] [G loss: 0.832537]\n",
      "epoch:2 step:2579 [D loss: 0.705793, acc.: 47.66%] [G loss: 0.835344]\n",
      "epoch:2 step:2580 [D loss: 0.721813, acc.: 53.12%] [G loss: 0.784134]\n",
      "epoch:2 step:2581 [D loss: 0.706899, acc.: 48.44%] [G loss: 0.779983]\n",
      "epoch:2 step:2582 [D loss: 0.669471, acc.: 57.81%] [G loss: 0.831793]\n",
      "epoch:2 step:2583 [D loss: 0.664577, acc.: 56.25%] [G loss: 0.794392]\n",
      "epoch:2 step:2584 [D loss: 0.779033, acc.: 32.81%] [G loss: 0.854386]\n",
      "epoch:2 step:2585 [D loss: 0.723326, acc.: 49.22%] [G loss: 0.772682]\n",
      "epoch:2 step:2586 [D loss: 0.658095, acc.: 58.59%] [G loss: 0.794654]\n",
      "epoch:2 step:2587 [D loss: 0.662257, acc.: 53.91%] [G loss: 0.790317]\n",
      "epoch:2 step:2588 [D loss: 0.698366, acc.: 53.12%] [G loss: 0.768459]\n",
      "epoch:2 step:2589 [D loss: 0.707392, acc.: 47.66%] [G loss: 0.799248]\n",
      "epoch:2 step:2590 [D loss: 0.734389, acc.: 46.09%] [G loss: 0.752557]\n",
      "epoch:2 step:2591 [D loss: 0.678889, acc.: 52.34%] [G loss: 0.811738]\n",
      "epoch:2 step:2592 [D loss: 0.683842, acc.: 53.12%] [G loss: 0.771184]\n",
      "epoch:2 step:2593 [D loss: 0.667199, acc.: 57.81%] [G loss: 0.787567]\n",
      "epoch:2 step:2594 [D loss: 0.675188, acc.: 61.72%] [G loss: 0.819100]\n",
      "epoch:2 step:2595 [D loss: 0.690571, acc.: 53.12%] [G loss: 0.806086]\n",
      "epoch:2 step:2596 [D loss: 0.704195, acc.: 55.47%] [G loss: 0.842585]\n",
      "epoch:2 step:2597 [D loss: 0.666041, acc.: 56.25%] [G loss: 0.811375]\n",
      "epoch:2 step:2598 [D loss: 0.707074, acc.: 52.34%] [G loss: 0.838428]\n",
      "epoch:2 step:2599 [D loss: 0.679251, acc.: 58.59%] [G loss: 0.866696]\n",
      "epoch:2 step:2600 [D loss: 0.669501, acc.: 61.72%] [G loss: 0.833657]\n",
      "##############\n",
      "[4.32010038 2.74150444 6.65984001 5.33406576 4.46704946 6.07010996\n",
      " 5.1640419  5.35855508 5.71912534 4.78246252]\n",
      "##########\n",
      "epoch:2 step:2601 [D loss: 0.725883, acc.: 46.09%] [G loss: 0.820026]\n",
      "epoch:2 step:2602 [D loss: 0.705854, acc.: 47.66%] [G loss: 0.803113]\n",
      "epoch:2 step:2603 [D loss: 0.683188, acc.: 58.59%] [G loss: 0.800208]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:2 step:2604 [D loss: 0.695885, acc.: 54.69%] [G loss: 0.753995]\n",
      "epoch:2 step:2605 [D loss: 0.681791, acc.: 56.25%] [G loss: 0.834243]\n",
      "epoch:2 step:2606 [D loss: 0.659115, acc.: 60.94%] [G loss: 0.800942]\n",
      "epoch:2 step:2607 [D loss: 0.651999, acc.: 60.16%] [G loss: 0.805027]\n",
      "epoch:2 step:2608 [D loss: 0.704766, acc.: 50.00%] [G loss: 0.832980]\n",
      "epoch:2 step:2609 [D loss: 0.738771, acc.: 51.56%] [G loss: 0.793756]\n",
      "epoch:2 step:2610 [D loss: 0.701092, acc.: 46.88%] [G loss: 0.828688]\n",
      "epoch:2 step:2611 [D loss: 0.703712, acc.: 57.81%] [G loss: 0.784660]\n",
      "epoch:2 step:2612 [D loss: 0.715538, acc.: 48.44%] [G loss: 0.798865]\n",
      "epoch:2 step:2613 [D loss: 0.713247, acc.: 50.78%] [G loss: 0.800818]\n",
      "epoch:2 step:2614 [D loss: 0.697135, acc.: 51.56%] [G loss: 0.788609]\n",
      "epoch:2 step:2615 [D loss: 0.695794, acc.: 49.22%] [G loss: 0.787619]\n",
      "epoch:2 step:2616 [D loss: 0.692950, acc.: 55.47%] [G loss: 0.783769]\n",
      "epoch:2 step:2617 [D loss: 0.706626, acc.: 50.78%] [G loss: 0.773412]\n",
      "epoch:2 step:2618 [D loss: 0.700906, acc.: 51.56%] [G loss: 0.765927]\n",
      "epoch:2 step:2619 [D loss: 0.709580, acc.: 52.34%] [G loss: 0.779491]\n",
      "epoch:2 step:2620 [D loss: 0.681949, acc.: 53.91%] [G loss: 0.793886]\n",
      "epoch:2 step:2621 [D loss: 0.687817, acc.: 57.03%] [G loss: 0.794502]\n",
      "epoch:2 step:2622 [D loss: 0.730309, acc.: 46.09%] [G loss: 0.811756]\n",
      "epoch:2 step:2623 [D loss: 0.695356, acc.: 57.03%] [G loss: 0.781232]\n",
      "epoch:2 step:2624 [D loss: 0.697008, acc.: 55.47%] [G loss: 0.745812]\n",
      "epoch:2 step:2625 [D loss: 0.679330, acc.: 53.12%] [G loss: 0.771804]\n",
      "epoch:2 step:2626 [D loss: 0.711988, acc.: 46.88%] [G loss: 0.741182]\n",
      "epoch:2 step:2627 [D loss: 0.695773, acc.: 51.56%] [G loss: 0.787414]\n",
      "epoch:2 step:2628 [D loss: 0.666729, acc.: 61.72%] [G loss: 0.774387]\n",
      "epoch:2 step:2629 [D loss: 0.659822, acc.: 60.94%] [G loss: 0.805991]\n",
      "epoch:2 step:2630 [D loss: 0.659456, acc.: 65.62%] [G loss: 0.823646]\n",
      "epoch:2 step:2631 [D loss: 0.660124, acc.: 58.59%] [G loss: 0.858760]\n",
      "epoch:2 step:2632 [D loss: 0.697706, acc.: 56.25%] [G loss: 0.813324]\n",
      "epoch:2 step:2633 [D loss: 0.685236, acc.: 54.69%] [G loss: 0.849941]\n",
      "epoch:2 step:2634 [D loss: 0.715238, acc.: 49.22%] [G loss: 0.753141]\n",
      "epoch:2 step:2635 [D loss: 0.672150, acc.: 57.81%] [G loss: 0.798546]\n",
      "epoch:2 step:2636 [D loss: 0.664831, acc.: 56.25%] [G loss: 0.793192]\n",
      "epoch:2 step:2637 [D loss: 0.702978, acc.: 50.00%] [G loss: 0.847026]\n",
      "epoch:2 step:2638 [D loss: 0.710967, acc.: 50.00%] [G loss: 0.780500]\n",
      "epoch:2 step:2639 [D loss: 0.740615, acc.: 44.53%] [G loss: 0.803897]\n",
      "epoch:2 step:2640 [D loss: 0.712303, acc.: 52.34%] [G loss: 0.846250]\n",
      "epoch:2 step:2641 [D loss: 0.703141, acc.: 52.34%] [G loss: 0.818708]\n",
      "epoch:2 step:2642 [D loss: 0.716776, acc.: 53.12%] [G loss: 0.816104]\n",
      "epoch:2 step:2643 [D loss: 0.699459, acc.: 54.69%] [G loss: 0.835388]\n",
      "epoch:2 step:2644 [D loss: 0.668523, acc.: 57.03%] [G loss: 0.854360]\n",
      "epoch:2 step:2645 [D loss: 0.660652, acc.: 60.94%] [G loss: 0.870524]\n",
      "epoch:2 step:2646 [D loss: 0.718660, acc.: 46.09%] [G loss: 0.839168]\n",
      "epoch:2 step:2647 [D loss: 0.663959, acc.: 61.72%] [G loss: 0.836869]\n",
      "epoch:2 step:2648 [D loss: 0.684689, acc.: 56.25%] [G loss: 0.815517]\n",
      "epoch:2 step:2649 [D loss: 0.664629, acc.: 60.16%] [G loss: 0.810258]\n",
      "epoch:2 step:2650 [D loss: 0.678752, acc.: 55.47%] [G loss: 0.742430]\n",
      "epoch:2 step:2651 [D loss: 0.719549, acc.: 54.69%] [G loss: 0.786839]\n",
      "epoch:2 step:2652 [D loss: 0.699017, acc.: 57.03%] [G loss: 0.849138]\n",
      "epoch:2 step:2653 [D loss: 0.728121, acc.: 48.44%] [G loss: 0.745323]\n",
      "epoch:2 step:2654 [D loss: 0.681726, acc.: 56.25%] [G loss: 0.811368]\n",
      "epoch:2 step:2655 [D loss: 0.682562, acc.: 59.38%] [G loss: 0.787059]\n",
      "epoch:2 step:2656 [D loss: 0.660839, acc.: 63.28%] [G loss: 0.811675]\n",
      "epoch:2 step:2657 [D loss: 0.714514, acc.: 54.69%] [G loss: 0.876544]\n",
      "epoch:2 step:2658 [D loss: 0.683712, acc.: 52.34%] [G loss: 0.914097]\n",
      "epoch:2 step:2659 [D loss: 0.658315, acc.: 62.50%] [G loss: 0.925056]\n",
      "epoch:2 step:2660 [D loss: 0.637148, acc.: 60.94%] [G loss: 0.879959]\n",
      "epoch:2 step:2661 [D loss: 0.695127, acc.: 56.25%] [G loss: 0.845419]\n",
      "epoch:2 step:2662 [D loss: 0.691413, acc.: 57.03%] [G loss: 0.849703]\n",
      "epoch:2 step:2663 [D loss: 0.714634, acc.: 53.91%] [G loss: 0.851272]\n",
      "epoch:2 step:2664 [D loss: 0.719166, acc.: 49.22%] [G loss: 0.838532]\n",
      "epoch:2 step:2665 [D loss: 0.706886, acc.: 54.69%] [G loss: 0.749756]\n",
      "epoch:2 step:2666 [D loss: 0.684292, acc.: 52.34%] [G loss: 0.780864]\n",
      "epoch:2 step:2667 [D loss: 0.684208, acc.: 58.59%] [G loss: 0.744654]\n",
      "epoch:2 step:2668 [D loss: 0.689753, acc.: 53.91%] [G loss: 0.781111]\n",
      "epoch:2 step:2669 [D loss: 0.705167, acc.: 51.56%] [G loss: 0.733311]\n",
      "epoch:2 step:2670 [D loss: 0.711291, acc.: 46.88%] [G loss: 0.728310]\n",
      "epoch:2 step:2671 [D loss: 0.747066, acc.: 40.62%] [G loss: 0.771203]\n",
      "epoch:2 step:2672 [D loss: 0.713761, acc.: 42.97%] [G loss: 0.815864]\n",
      "epoch:2 step:2673 [D loss: 0.691590, acc.: 53.91%] [G loss: 0.752839]\n",
      "epoch:2 step:2674 [D loss: 0.741324, acc.: 46.88%] [G loss: 0.783112]\n",
      "epoch:2 step:2675 [D loss: 0.739420, acc.: 44.53%] [G loss: 0.768234]\n",
      "epoch:2 step:2676 [D loss: 0.660179, acc.: 60.94%] [G loss: 0.803223]\n",
      "epoch:2 step:2677 [D loss: 0.683301, acc.: 53.91%] [G loss: 0.827824]\n",
      "epoch:2 step:2678 [D loss: 0.671336, acc.: 61.72%] [G loss: 0.783551]\n",
      "epoch:2 step:2679 [D loss: 0.713911, acc.: 44.53%] [G loss: 0.824163]\n",
      "epoch:2 step:2680 [D loss: 0.663897, acc.: 60.94%] [G loss: 0.820277]\n",
      "epoch:2 step:2681 [D loss: 0.690219, acc.: 54.69%] [G loss: 0.825582]\n",
      "epoch:2 step:2682 [D loss: 0.692918, acc.: 57.81%] [G loss: 0.832829]\n",
      "epoch:2 step:2683 [D loss: 0.701242, acc.: 53.91%] [G loss: 0.759070]\n",
      "epoch:2 step:2684 [D loss: 0.698155, acc.: 48.44%] [G loss: 0.788977]\n",
      "epoch:2 step:2685 [D loss: 0.693344, acc.: 52.34%] [G loss: 0.766369]\n",
      "epoch:2 step:2686 [D loss: 0.704401, acc.: 55.47%] [G loss: 0.763598]\n",
      "epoch:2 step:2687 [D loss: 0.687735, acc.: 56.25%] [G loss: 0.757062]\n",
      "epoch:2 step:2688 [D loss: 0.667595, acc.: 61.72%] [G loss: 0.804783]\n",
      "epoch:2 step:2689 [D loss: 0.637911, acc.: 66.41%] [G loss: 0.803176]\n",
      "epoch:2 step:2690 [D loss: 0.706924, acc.: 50.78%] [G loss: 0.798639]\n",
      "epoch:2 step:2691 [D loss: 0.654530, acc.: 59.38%] [G loss: 0.835668]\n",
      "epoch:2 step:2692 [D loss: 0.741800, acc.: 46.09%] [G loss: 0.767928]\n",
      "epoch:2 step:2693 [D loss: 0.742837, acc.: 42.97%] [G loss: 0.809899]\n",
      "epoch:2 step:2694 [D loss: 0.714675, acc.: 46.88%] [G loss: 0.817920]\n",
      "epoch:2 step:2695 [D loss: 0.698842, acc.: 50.78%] [G loss: 0.888471]\n",
      "epoch:2 step:2696 [D loss: 0.672191, acc.: 59.38%] [G loss: 0.819781]\n",
      "epoch:2 step:2697 [D loss: 0.660290, acc.: 62.50%] [G loss: 0.819649]\n",
      "epoch:2 step:2698 [D loss: 0.698090, acc.: 55.47%] [G loss: 0.854536]\n",
      "epoch:2 step:2699 [D loss: 0.681681, acc.: 59.38%] [G loss: 0.854024]\n",
      "epoch:2 step:2700 [D loss: 0.647250, acc.: 63.28%] [G loss: 0.810427]\n",
      "epoch:2 step:2701 [D loss: 0.713604, acc.: 47.66%] [G loss: 0.807793]\n",
      "epoch:2 step:2702 [D loss: 0.694852, acc.: 57.81%] [G loss: 0.749451]\n",
      "epoch:2 step:2703 [D loss: 0.667967, acc.: 58.59%] [G loss: 0.785287]\n",
      "epoch:2 step:2704 [D loss: 0.684468, acc.: 57.03%] [G loss: 0.776707]\n",
      "epoch:2 step:2705 [D loss: 0.700978, acc.: 49.22%] [G loss: 0.740366]\n",
      "epoch:2 step:2706 [D loss: 0.698461, acc.: 55.47%] [G loss: 0.873040]\n",
      "epoch:2 step:2707 [D loss: 0.694376, acc.: 49.22%] [G loss: 0.765628]\n",
      "epoch:2 step:2708 [D loss: 0.732650, acc.: 42.97%] [G loss: 0.801321]\n",
      "epoch:2 step:2709 [D loss: 0.719728, acc.: 45.31%] [G loss: 0.755865]\n",
      "epoch:2 step:2710 [D loss: 0.682258, acc.: 60.94%] [G loss: 0.802860]\n",
      "epoch:2 step:2711 [D loss: 0.667011, acc.: 61.72%] [G loss: 0.774447]\n",
      "epoch:2 step:2712 [D loss: 0.644116, acc.: 60.94%] [G loss: 0.803263]\n",
      "epoch:2 step:2713 [D loss: 0.675247, acc.: 61.72%] [G loss: 0.809714]\n",
      "epoch:2 step:2714 [D loss: 0.686961, acc.: 56.25%] [G loss: 0.814788]\n",
      "epoch:2 step:2715 [D loss: 0.676418, acc.: 56.25%] [G loss: 0.767328]\n",
      "epoch:2 step:2716 [D loss: 0.649059, acc.: 58.59%] [G loss: 0.789402]\n",
      "epoch:2 step:2717 [D loss: 0.735704, acc.: 41.41%] [G loss: 0.779303]\n",
      "epoch:2 step:2718 [D loss: 0.706109, acc.: 48.44%] [G loss: 0.809497]\n",
      "epoch:2 step:2719 [D loss: 0.670858, acc.: 56.25%] [G loss: 0.788047]\n",
      "epoch:2 step:2720 [D loss: 0.693597, acc.: 55.47%] [G loss: 0.784089]\n",
      "epoch:2 step:2721 [D loss: 0.693153, acc.: 54.69%] [G loss: 0.825648]\n",
      "epoch:2 step:2722 [D loss: 0.732391, acc.: 46.09%] [G loss: 0.859736]\n",
      "epoch:2 step:2723 [D loss: 0.681201, acc.: 53.12%] [G loss: 0.827349]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:2 step:2724 [D loss: 0.708085, acc.: 45.31%] [G loss: 0.792254]\n",
      "epoch:2 step:2725 [D loss: 0.702681, acc.: 47.66%] [G loss: 0.846821]\n",
      "epoch:2 step:2726 [D loss: 0.636479, acc.: 69.53%] [G loss: 0.845041]\n",
      "epoch:2 step:2727 [D loss: 0.691048, acc.: 50.00%] [G loss: 0.775149]\n",
      "epoch:2 step:2728 [D loss: 0.700842, acc.: 45.31%] [G loss: 0.834481]\n",
      "epoch:2 step:2729 [D loss: 0.684261, acc.: 58.59%] [G loss: 0.842437]\n",
      "epoch:2 step:2730 [D loss: 0.670522, acc.: 60.16%] [G loss: 0.844796]\n",
      "epoch:2 step:2731 [D loss: 0.681429, acc.: 61.72%] [G loss: 0.845400]\n",
      "epoch:2 step:2732 [D loss: 0.762921, acc.: 37.50%] [G loss: 0.861034]\n",
      "epoch:2 step:2733 [D loss: 0.741679, acc.: 36.72%] [G loss: 0.829543]\n",
      "epoch:2 step:2734 [D loss: 0.701179, acc.: 57.81%] [G loss: 0.844644]\n",
      "epoch:2 step:2735 [D loss: 0.681428, acc.: 56.25%] [G loss: 0.822813]\n",
      "epoch:2 step:2736 [D loss: 0.706634, acc.: 52.34%] [G loss: 0.806714]\n",
      "epoch:2 step:2737 [D loss: 0.697956, acc.: 49.22%] [G loss: 0.757593]\n",
      "epoch:2 step:2738 [D loss: 0.666116, acc.: 54.69%] [G loss: 0.831437]\n",
      "epoch:2 step:2739 [D loss: 0.692156, acc.: 50.78%] [G loss: 0.820756]\n",
      "epoch:2 step:2740 [D loss: 0.678081, acc.: 57.81%] [G loss: 0.768176]\n",
      "epoch:2 step:2741 [D loss: 0.677711, acc.: 52.34%] [G loss: 0.798091]\n",
      "epoch:2 step:2742 [D loss: 0.711455, acc.: 51.56%] [G loss: 0.817970]\n",
      "epoch:2 step:2743 [D loss: 0.687657, acc.: 55.47%] [G loss: 0.826269]\n",
      "epoch:2 step:2744 [D loss: 0.673957, acc.: 60.16%] [G loss: 0.832707]\n",
      "epoch:2 step:2745 [D loss: 0.679973, acc.: 52.34%] [G loss: 0.815580]\n",
      "epoch:2 step:2746 [D loss: 0.691510, acc.: 56.25%] [G loss: 0.793252]\n",
      "epoch:2 step:2747 [D loss: 0.715151, acc.: 49.22%] [G loss: 0.802602]\n",
      "epoch:2 step:2748 [D loss: 0.688045, acc.: 54.69%] [G loss: 0.755608]\n",
      "epoch:2 step:2749 [D loss: 0.674203, acc.: 53.12%] [G loss: 0.776628]\n",
      "epoch:2 step:2750 [D loss: 0.669009, acc.: 63.28%] [G loss: 0.760624]\n",
      "epoch:2 step:2751 [D loss: 0.695658, acc.: 53.91%] [G loss: 0.779322]\n",
      "epoch:2 step:2752 [D loss: 0.663219, acc.: 61.72%] [G loss: 0.762652]\n",
      "epoch:2 step:2753 [D loss: 0.698261, acc.: 49.22%] [G loss: 0.795462]\n",
      "epoch:2 step:2754 [D loss: 0.724843, acc.: 46.09%] [G loss: 0.764772]\n",
      "epoch:2 step:2755 [D loss: 0.683338, acc.: 55.47%] [G loss: 0.792222]\n",
      "epoch:2 step:2756 [D loss: 0.689306, acc.: 57.03%] [G loss: 0.803607]\n",
      "epoch:2 step:2757 [D loss: 0.705380, acc.: 49.22%] [G loss: 0.827894]\n",
      "epoch:2 step:2758 [D loss: 0.709871, acc.: 49.22%] [G loss: 0.841077]\n",
      "epoch:2 step:2759 [D loss: 0.699051, acc.: 56.25%] [G loss: 0.767615]\n",
      "epoch:2 step:2760 [D loss: 0.687930, acc.: 54.69%] [G loss: 0.818934]\n",
      "epoch:2 step:2761 [D loss: 0.704358, acc.: 50.00%] [G loss: 0.819958]\n",
      "epoch:2 step:2762 [D loss: 0.706488, acc.: 50.00%] [G loss: 0.831536]\n",
      "epoch:2 step:2763 [D loss: 0.676202, acc.: 57.03%] [G loss: 0.796468]\n",
      "epoch:2 step:2764 [D loss: 0.678251, acc.: 59.38%] [G loss: 0.837124]\n",
      "epoch:2 step:2765 [D loss: 0.738550, acc.: 45.31%] [G loss: 0.833141]\n",
      "epoch:2 step:2766 [D loss: 0.772573, acc.: 32.81%] [G loss: 0.768885]\n",
      "epoch:2 step:2767 [D loss: 0.717163, acc.: 45.31%] [G loss: 0.754782]\n",
      "epoch:2 step:2768 [D loss: 0.709466, acc.: 43.75%] [G loss: 0.775478]\n",
      "epoch:2 step:2769 [D loss: 0.704238, acc.: 50.78%] [G loss: 0.807127]\n",
      "epoch:2 step:2770 [D loss: 0.684799, acc.: 57.03%] [G loss: 0.789078]\n",
      "epoch:2 step:2771 [D loss: 0.675609, acc.: 57.03%] [G loss: 0.857707]\n",
      "epoch:2 step:2772 [D loss: 0.670285, acc.: 55.47%] [G loss: 0.809192]\n",
      "epoch:2 step:2773 [D loss: 0.656990, acc.: 58.59%] [G loss: 0.844479]\n",
      "epoch:2 step:2774 [D loss: 0.679606, acc.: 63.28%] [G loss: 0.855789]\n",
      "epoch:2 step:2775 [D loss: 0.661232, acc.: 63.28%] [G loss: 0.793495]\n",
      "epoch:2 step:2776 [D loss: 0.695705, acc.: 53.91%] [G loss: 0.816585]\n",
      "epoch:2 step:2777 [D loss: 0.711468, acc.: 48.44%] [G loss: 0.815772]\n",
      "epoch:2 step:2778 [D loss: 0.731109, acc.: 38.28%] [G loss: 0.776097]\n",
      "epoch:2 step:2779 [D loss: 0.691702, acc.: 55.47%] [G loss: 0.792663]\n",
      "epoch:2 step:2780 [D loss: 0.723704, acc.: 45.31%] [G loss: 0.823479]\n",
      "epoch:2 step:2781 [D loss: 0.703806, acc.: 48.44%] [G loss: 0.740780]\n",
      "epoch:2 step:2782 [D loss: 0.709443, acc.: 46.09%] [G loss: 0.771400]\n",
      "epoch:2 step:2783 [D loss: 0.684496, acc.: 53.91%] [G loss: 0.773277]\n",
      "epoch:2 step:2784 [D loss: 0.690410, acc.: 48.44%] [G loss: 0.735133]\n",
      "epoch:2 step:2785 [D loss: 0.666148, acc.: 55.47%] [G loss: 0.766104]\n",
      "epoch:2 step:2786 [D loss: 0.665315, acc.: 64.84%] [G loss: 0.757605]\n",
      "epoch:2 step:2787 [D loss: 0.702394, acc.: 50.00%] [G loss: 0.743213]\n",
      "epoch:2 step:2788 [D loss: 0.708606, acc.: 50.78%] [G loss: 0.830361]\n",
      "epoch:2 step:2789 [D loss: 0.697680, acc.: 50.00%] [G loss: 0.795844]\n",
      "epoch:2 step:2790 [D loss: 0.682050, acc.: 53.12%] [G loss: 0.811549]\n",
      "epoch:2 step:2791 [D loss: 0.682975, acc.: 53.91%] [G loss: 0.804926]\n",
      "epoch:2 step:2792 [D loss: 0.678268, acc.: 58.59%] [G loss: 0.773906]\n",
      "epoch:2 step:2793 [D loss: 0.674138, acc.: 58.59%] [G loss: 0.783183]\n",
      "epoch:2 step:2794 [D loss: 0.750057, acc.: 42.19%] [G loss: 0.772146]\n",
      "epoch:2 step:2795 [D loss: 0.689027, acc.: 55.47%] [G loss: 0.794958]\n",
      "epoch:2 step:2796 [D loss: 0.675479, acc.: 57.81%] [G loss: 0.823860]\n",
      "epoch:2 step:2797 [D loss: 0.650468, acc.: 62.50%] [G loss: 0.799353]\n",
      "epoch:2 step:2798 [D loss: 0.664022, acc.: 62.50%] [G loss: 0.777416]\n",
      "epoch:2 step:2799 [D loss: 0.640386, acc.: 64.84%] [G loss: 0.853480]\n",
      "epoch:2 step:2800 [D loss: 0.661036, acc.: 57.81%] [G loss: 0.806022]\n",
      "##############\n",
      "[4.13965794 2.75251967 6.46918891 5.24544717 4.61043995 5.82224637\n",
      " 5.25133373 5.70285409 5.61918666 4.93257616]\n",
      "##########\n",
      "epoch:2 step:2801 [D loss: 0.659228, acc.: 60.94%] [G loss: 0.755085]\n",
      "epoch:2 step:2802 [D loss: 0.736027, acc.: 48.44%] [G loss: 0.852722]\n",
      "epoch:2 step:2803 [D loss: 0.648283, acc.: 57.81%] [G loss: 0.849861]\n",
      "epoch:2 step:2804 [D loss: 0.635225, acc.: 60.94%] [G loss: 0.829512]\n",
      "epoch:2 step:2805 [D loss: 0.682863, acc.: 53.12%] [G loss: 0.798416]\n",
      "epoch:2 step:2806 [D loss: 0.755654, acc.: 40.62%] [G loss: 0.780745]\n",
      "epoch:2 step:2807 [D loss: 0.748395, acc.: 44.53%] [G loss: 0.804555]\n",
      "epoch:2 step:2808 [D loss: 0.745988, acc.: 37.50%] [G loss: 0.758092]\n",
      "epoch:2 step:2809 [D loss: 0.678380, acc.: 57.03%] [G loss: 0.753226]\n",
      "epoch:2 step:2810 [D loss: 0.656432, acc.: 60.94%] [G loss: 0.733603]\n",
      "epoch:2 step:2811 [D loss: 0.715092, acc.: 48.44%] [G loss: 0.807569]\n",
      "epoch:3 step:2812 [D loss: 0.688404, acc.: 53.91%] [G loss: 0.851178]\n",
      "epoch:3 step:2813 [D loss: 0.728606, acc.: 48.44%] [G loss: 0.762046]\n",
      "epoch:3 step:2814 [D loss: 0.719006, acc.: 45.31%] [G loss: 0.789238]\n",
      "epoch:3 step:2815 [D loss: 0.707384, acc.: 46.88%] [G loss: 0.817017]\n",
      "epoch:3 step:2816 [D loss: 0.675835, acc.: 63.28%] [G loss: 0.808677]\n",
      "epoch:3 step:2817 [D loss: 0.676235, acc.: 57.81%] [G loss: 0.795794]\n",
      "epoch:3 step:2818 [D loss: 0.672115, acc.: 57.03%] [G loss: 0.770850]\n",
      "epoch:3 step:2819 [D loss: 0.676549, acc.: 59.38%] [G loss: 0.810571]\n",
      "epoch:3 step:2820 [D loss: 0.671713, acc.: 59.38%] [G loss: 0.810568]\n",
      "epoch:3 step:2821 [D loss: 0.662270, acc.: 55.47%] [G loss: 0.857208]\n",
      "epoch:3 step:2822 [D loss: 0.666777, acc.: 57.81%] [G loss: 0.845039]\n",
      "epoch:3 step:2823 [D loss: 0.673837, acc.: 59.38%] [G loss: 0.756546]\n",
      "epoch:3 step:2824 [D loss: 0.651248, acc.: 60.94%] [G loss: 0.887498]\n",
      "epoch:3 step:2825 [D loss: 0.666374, acc.: 62.50%] [G loss: 0.891917]\n",
      "epoch:3 step:2826 [D loss: 0.690951, acc.: 56.25%] [G loss: 0.816370]\n",
      "epoch:3 step:2827 [D loss: 0.689096, acc.: 51.56%] [G loss: 0.819628]\n",
      "epoch:3 step:2828 [D loss: 0.674676, acc.: 61.72%] [G loss: 0.848717]\n",
      "epoch:3 step:2829 [D loss: 0.675240, acc.: 60.16%] [G loss: 0.848586]\n",
      "epoch:3 step:2830 [D loss: 0.717426, acc.: 51.56%] [G loss: 0.814422]\n",
      "epoch:3 step:2831 [D loss: 0.711859, acc.: 45.31%] [G loss: 0.806060]\n",
      "epoch:3 step:2832 [D loss: 0.673049, acc.: 59.38%] [G loss: 0.826159]\n",
      "epoch:3 step:2833 [D loss: 0.683350, acc.: 55.47%] [G loss: 0.846238]\n",
      "epoch:3 step:2834 [D loss: 0.702024, acc.: 48.44%] [G loss: 0.884157]\n",
      "epoch:3 step:2835 [D loss: 0.706988, acc.: 58.59%] [G loss: 0.836335]\n",
      "epoch:3 step:2836 [D loss: 0.663422, acc.: 57.03%] [G loss: 0.832418]\n",
      "epoch:3 step:2837 [D loss: 0.725047, acc.: 42.97%] [G loss: 0.752632]\n",
      "epoch:3 step:2838 [D loss: 0.739909, acc.: 46.09%] [G loss: 0.744524]\n",
      "epoch:3 step:2839 [D loss: 0.748791, acc.: 42.97%] [G loss: 0.747248]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:3 step:2840 [D loss: 0.688446, acc.: 53.91%] [G loss: 0.809749]\n",
      "epoch:3 step:2841 [D loss: 0.692476, acc.: 57.03%] [G loss: 0.809343]\n",
      "epoch:3 step:2842 [D loss: 0.685929, acc.: 51.56%] [G loss: 0.736055]\n",
      "epoch:3 step:2843 [D loss: 0.683576, acc.: 56.25%] [G loss: 0.773940]\n",
      "epoch:3 step:2844 [D loss: 0.672689, acc.: 53.12%] [G loss: 0.810093]\n",
      "epoch:3 step:2845 [D loss: 0.696472, acc.: 53.12%] [G loss: 0.784684]\n",
      "epoch:3 step:2846 [D loss: 0.685010, acc.: 53.91%] [G loss: 0.770524]\n",
      "epoch:3 step:2847 [D loss: 0.689358, acc.: 56.25%] [G loss: 0.800517]\n",
      "epoch:3 step:2848 [D loss: 0.705090, acc.: 58.59%] [G loss: 0.795859]\n",
      "epoch:3 step:2849 [D loss: 0.710078, acc.: 52.34%] [G loss: 0.806203]\n",
      "epoch:3 step:2850 [D loss: 0.712673, acc.: 50.78%] [G loss: 0.828353]\n",
      "epoch:3 step:2851 [D loss: 0.671455, acc.: 61.72%] [G loss: 0.768181]\n",
      "epoch:3 step:2852 [D loss: 0.708189, acc.: 48.44%] [G loss: 0.786147]\n",
      "epoch:3 step:2853 [D loss: 0.698337, acc.: 52.34%] [G loss: 0.761675]\n",
      "epoch:3 step:2854 [D loss: 0.693491, acc.: 59.38%] [G loss: 0.729297]\n",
      "epoch:3 step:2855 [D loss: 0.716749, acc.: 48.44%] [G loss: 0.775424]\n",
      "epoch:3 step:2856 [D loss: 0.687569, acc.: 55.47%] [G loss: 0.825313]\n",
      "epoch:3 step:2857 [D loss: 0.686453, acc.: 53.12%] [G loss: 0.761511]\n",
      "epoch:3 step:2858 [D loss: 0.676809, acc.: 57.03%] [G loss: 0.790711]\n",
      "epoch:3 step:2859 [D loss: 0.682759, acc.: 54.69%] [G loss: 0.801791]\n",
      "epoch:3 step:2860 [D loss: 0.670698, acc.: 59.38%] [G loss: 0.801736]\n",
      "epoch:3 step:2861 [D loss: 0.680971, acc.: 55.47%] [G loss: 0.832599]\n",
      "epoch:3 step:2862 [D loss: 0.684193, acc.: 57.03%] [G loss: 0.814129]\n",
      "epoch:3 step:2863 [D loss: 0.690086, acc.: 50.00%] [G loss: 0.785569]\n",
      "epoch:3 step:2864 [D loss: 0.651460, acc.: 64.06%] [G loss: 0.785915]\n",
      "epoch:3 step:2865 [D loss: 0.676840, acc.: 58.59%] [G loss: 0.793126]\n",
      "epoch:3 step:2866 [D loss: 0.703696, acc.: 49.22%] [G loss: 0.843989]\n",
      "epoch:3 step:2867 [D loss: 0.696748, acc.: 53.91%] [G loss: 0.813737]\n",
      "epoch:3 step:2868 [D loss: 0.688710, acc.: 51.56%] [G loss: 0.791140]\n",
      "epoch:3 step:2869 [D loss: 0.709829, acc.: 53.91%] [G loss: 0.797141]\n",
      "epoch:3 step:2870 [D loss: 0.727100, acc.: 45.31%] [G loss: 0.783580]\n",
      "epoch:3 step:2871 [D loss: 0.712328, acc.: 50.00%] [G loss: 0.794270]\n",
      "epoch:3 step:2872 [D loss: 0.707517, acc.: 49.22%] [G loss: 0.779109]\n",
      "epoch:3 step:2873 [D loss: 0.704261, acc.: 49.22%] [G loss: 0.783019]\n",
      "epoch:3 step:2874 [D loss: 0.682919, acc.: 50.00%] [G loss: 0.793535]\n",
      "epoch:3 step:2875 [D loss: 0.717202, acc.: 48.44%] [G loss: 0.764172]\n",
      "epoch:3 step:2876 [D loss: 0.700935, acc.: 53.91%] [G loss: 0.744646]\n",
      "epoch:3 step:2877 [D loss: 0.705294, acc.: 47.66%] [G loss: 0.797722]\n",
      "epoch:3 step:2878 [D loss: 0.700620, acc.: 48.44%] [G loss: 0.763185]\n",
      "epoch:3 step:2879 [D loss: 0.705342, acc.: 50.78%] [G loss: 0.798229]\n",
      "epoch:3 step:2880 [D loss: 0.685717, acc.: 54.69%] [G loss: 0.789399]\n",
      "epoch:3 step:2881 [D loss: 0.703245, acc.: 51.56%] [G loss: 0.803654]\n",
      "epoch:3 step:2882 [D loss: 0.687717, acc.: 52.34%] [G loss: 0.806699]\n",
      "epoch:3 step:2883 [D loss: 0.670386, acc.: 53.91%] [G loss: 0.776647]\n",
      "epoch:3 step:2884 [D loss: 0.670076, acc.: 56.25%] [G loss: 0.805348]\n",
      "epoch:3 step:2885 [D loss: 0.650011, acc.: 60.16%] [G loss: 0.827498]\n",
      "epoch:3 step:2886 [D loss: 0.688809, acc.: 51.56%] [G loss: 0.808204]\n",
      "epoch:3 step:2887 [D loss: 0.664650, acc.: 64.06%] [G loss: 0.812316]\n",
      "epoch:3 step:2888 [D loss: 0.664200, acc.: 60.94%] [G loss: 0.938625]\n",
      "epoch:3 step:2889 [D loss: 0.689319, acc.: 57.03%] [G loss: 0.781960]\n",
      "epoch:3 step:2890 [D loss: 0.714862, acc.: 49.22%] [G loss: 0.812559]\n",
      "epoch:3 step:2891 [D loss: 0.677824, acc.: 58.59%] [G loss: 0.812518]\n",
      "epoch:3 step:2892 [D loss: 0.700147, acc.: 52.34%] [G loss: 0.766341]\n",
      "epoch:3 step:2893 [D loss: 0.728223, acc.: 46.88%] [G loss: 0.772215]\n",
      "epoch:3 step:2894 [D loss: 0.698654, acc.: 52.34%] [G loss: 0.798522]\n",
      "epoch:3 step:2895 [D loss: 0.708957, acc.: 46.09%] [G loss: 0.815064]\n",
      "epoch:3 step:2896 [D loss: 0.694783, acc.: 53.91%] [G loss: 0.778977]\n",
      "epoch:3 step:2897 [D loss: 0.691309, acc.: 58.59%] [G loss: 0.851550]\n",
      "epoch:3 step:2898 [D loss: 0.666183, acc.: 57.03%] [G loss: 0.821738]\n",
      "epoch:3 step:2899 [D loss: 0.640243, acc.: 62.50%] [G loss: 0.803217]\n",
      "epoch:3 step:2900 [D loss: 0.685526, acc.: 53.12%] [G loss: 0.832248]\n",
      "epoch:3 step:2901 [D loss: 0.676417, acc.: 58.59%] [G loss: 0.814013]\n",
      "epoch:3 step:2902 [D loss: 0.693961, acc.: 54.69%] [G loss: 0.839022]\n",
      "epoch:3 step:2903 [D loss: 0.650391, acc.: 61.72%] [G loss: 0.850697]\n",
      "epoch:3 step:2904 [D loss: 0.664158, acc.: 53.91%] [G loss: 0.777131]\n",
      "epoch:3 step:2905 [D loss: 0.680879, acc.: 55.47%] [G loss: 0.764684]\n",
      "epoch:3 step:2906 [D loss: 0.724651, acc.: 43.75%] [G loss: 0.783077]\n",
      "epoch:3 step:2907 [D loss: 0.684836, acc.: 50.78%] [G loss: 0.752412]\n",
      "epoch:3 step:2908 [D loss: 0.695512, acc.: 51.56%] [G loss: 0.740152]\n",
      "epoch:3 step:2909 [D loss: 0.692043, acc.: 50.00%] [G loss: 0.749907]\n",
      "epoch:3 step:2910 [D loss: 0.689104, acc.: 57.03%] [G loss: 0.764022]\n",
      "epoch:3 step:2911 [D loss: 0.668670, acc.: 56.25%] [G loss: 0.783277]\n",
      "epoch:3 step:2912 [D loss: 0.714580, acc.: 44.53%] [G loss: 0.810504]\n",
      "epoch:3 step:2913 [D loss: 0.742405, acc.: 44.53%] [G loss: 0.784137]\n",
      "epoch:3 step:2914 [D loss: 0.715436, acc.: 46.09%] [G loss: 0.765374]\n",
      "epoch:3 step:2915 [D loss: 0.706112, acc.: 46.88%] [G loss: 0.732993]\n",
      "epoch:3 step:2916 [D loss: 0.673416, acc.: 57.03%] [G loss: 0.826527]\n",
      "epoch:3 step:2917 [D loss: 0.649064, acc.: 67.97%] [G loss: 0.849264]\n",
      "epoch:3 step:2918 [D loss: 0.627765, acc.: 66.41%] [G loss: 0.877786]\n",
      "epoch:3 step:2919 [D loss: 0.706061, acc.: 53.91%] [G loss: 0.825030]\n",
      "epoch:3 step:2920 [D loss: 0.689066, acc.: 61.72%] [G loss: 0.839765]\n",
      "epoch:3 step:2921 [D loss: 0.684153, acc.: 59.38%] [G loss: 0.779570]\n",
      "epoch:3 step:2922 [D loss: 0.656227, acc.: 61.72%] [G loss: 0.837483]\n",
      "epoch:3 step:2923 [D loss: 0.652605, acc.: 61.72%] [G loss: 0.816305]\n",
      "epoch:3 step:2924 [D loss: 0.659577, acc.: 61.72%] [G loss: 0.790816]\n",
      "epoch:3 step:2925 [D loss: 0.679807, acc.: 54.69%] [G loss: 0.787466]\n",
      "epoch:3 step:2926 [D loss: 0.656982, acc.: 59.38%] [G loss: 0.766829]\n",
      "epoch:3 step:2927 [D loss: 0.701116, acc.: 46.09%] [G loss: 0.853634]\n",
      "epoch:3 step:2928 [D loss: 0.720975, acc.: 48.44%] [G loss: 0.821732]\n",
      "epoch:3 step:2929 [D loss: 0.688079, acc.: 50.78%] [G loss: 0.855491]\n",
      "epoch:3 step:2930 [D loss: 0.674839, acc.: 58.59%] [G loss: 0.911209]\n",
      "epoch:3 step:2931 [D loss: 0.712974, acc.: 49.22%] [G loss: 0.907804]\n",
      "epoch:3 step:2932 [D loss: 0.710375, acc.: 53.12%] [G loss: 0.905809]\n",
      "epoch:3 step:2933 [D loss: 0.692818, acc.: 53.12%] [G loss: 0.938187]\n",
      "epoch:3 step:2934 [D loss: 0.673939, acc.: 57.81%] [G loss: 0.941988]\n",
      "epoch:3 step:2935 [D loss: 0.635039, acc.: 64.84%] [G loss: 0.962557]\n",
      "epoch:3 step:2936 [D loss: 0.676613, acc.: 57.03%] [G loss: 0.874815]\n",
      "epoch:3 step:2937 [D loss: 0.649243, acc.: 62.50%] [G loss: 0.867848]\n",
      "epoch:3 step:2938 [D loss: 0.684110, acc.: 57.81%] [G loss: 0.811252]\n",
      "epoch:3 step:2939 [D loss: 0.761374, acc.: 39.06%] [G loss: 0.809820]\n",
      "epoch:3 step:2940 [D loss: 0.760387, acc.: 45.31%] [G loss: 0.749888]\n",
      "epoch:3 step:2941 [D loss: 0.710904, acc.: 49.22%] [G loss: 0.743811]\n",
      "epoch:3 step:2942 [D loss: 0.704631, acc.: 54.69%] [G loss: 0.754307]\n",
      "epoch:3 step:2943 [D loss: 0.705990, acc.: 51.56%] [G loss: 0.768783]\n",
      "epoch:3 step:2944 [D loss: 0.694322, acc.: 55.47%] [G loss: 0.767884]\n",
      "epoch:3 step:2945 [D loss: 0.744834, acc.: 46.09%] [G loss: 0.752583]\n",
      "epoch:3 step:2946 [D loss: 0.719685, acc.: 47.66%] [G loss: 0.794986]\n",
      "epoch:3 step:2947 [D loss: 0.679343, acc.: 54.69%] [G loss: 0.758293]\n",
      "epoch:3 step:2948 [D loss: 0.690548, acc.: 50.78%] [G loss: 0.795234]\n",
      "epoch:3 step:2949 [D loss: 0.682290, acc.: 51.56%] [G loss: 0.804093]\n",
      "epoch:3 step:2950 [D loss: 0.653355, acc.: 57.81%] [G loss: 0.862701]\n",
      "epoch:3 step:2951 [D loss: 0.701006, acc.: 49.22%] [G loss: 0.799256]\n",
      "epoch:3 step:2952 [D loss: 0.704607, acc.: 47.66%] [G loss: 0.803417]\n",
      "epoch:3 step:2953 [D loss: 0.707932, acc.: 42.19%] [G loss: 0.814334]\n",
      "epoch:3 step:2954 [D loss: 0.676843, acc.: 54.69%] [G loss: 0.824619]\n",
      "epoch:3 step:2955 [D loss: 0.661625, acc.: 58.59%] [G loss: 0.767962]\n",
      "epoch:3 step:2956 [D loss: 0.670152, acc.: 63.28%] [G loss: 0.805110]\n",
      "epoch:3 step:2957 [D loss: 0.693949, acc.: 53.91%] [G loss: 0.802625]\n",
      "epoch:3 step:2958 [D loss: 0.713897, acc.: 47.66%] [G loss: 0.792789]\n",
      "epoch:3 step:2959 [D loss: 0.685204, acc.: 54.69%] [G loss: 0.778729]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:3 step:2960 [D loss: 0.696412, acc.: 53.91%] [G loss: 0.762664]\n",
      "epoch:3 step:2961 [D loss: 0.670437, acc.: 56.25%] [G loss: 0.815626]\n",
      "epoch:3 step:2962 [D loss: 0.675409, acc.: 56.25%] [G loss: 0.815571]\n",
      "epoch:3 step:2963 [D loss: 0.660923, acc.: 61.72%] [G loss: 0.783060]\n",
      "epoch:3 step:2964 [D loss: 0.729638, acc.: 46.09%] [G loss: 0.855083]\n",
      "epoch:3 step:2965 [D loss: 0.676577, acc.: 53.12%] [G loss: 0.840960]\n",
      "epoch:3 step:2966 [D loss: 0.670400, acc.: 54.69%] [G loss: 0.826981]\n",
      "epoch:3 step:2967 [D loss: 0.708448, acc.: 50.78%] [G loss: 0.829551]\n",
      "epoch:3 step:2968 [D loss: 0.657080, acc.: 60.94%] [G loss: 0.780544]\n",
      "epoch:3 step:2969 [D loss: 0.694577, acc.: 50.00%] [G loss: 0.859483]\n",
      "epoch:3 step:2970 [D loss: 0.671230, acc.: 58.59%] [G loss: 0.785907]\n",
      "epoch:3 step:2971 [D loss: 0.667410, acc.: 60.16%] [G loss: 0.772409]\n",
      "epoch:3 step:2972 [D loss: 0.671204, acc.: 59.38%] [G loss: 0.791258]\n",
      "epoch:3 step:2973 [D loss: 0.669395, acc.: 57.03%] [G loss: 0.794043]\n",
      "epoch:3 step:2974 [D loss: 0.697020, acc.: 54.69%] [G loss: 0.787533]\n",
      "epoch:3 step:2975 [D loss: 0.692042, acc.: 51.56%] [G loss: 0.781492]\n",
      "epoch:3 step:2976 [D loss: 0.711920, acc.: 51.56%] [G loss: 0.754371]\n",
      "epoch:3 step:2977 [D loss: 0.691833, acc.: 49.22%] [G loss: 0.800448]\n",
      "epoch:3 step:2978 [D loss: 0.724409, acc.: 46.88%] [G loss: 0.778643]\n",
      "epoch:3 step:2979 [D loss: 0.711079, acc.: 55.47%] [G loss: 0.762549]\n",
      "epoch:3 step:2980 [D loss: 0.699362, acc.: 51.56%] [G loss: 0.799890]\n",
      "epoch:3 step:2981 [D loss: 0.663128, acc.: 61.72%] [G loss: 0.788579]\n",
      "epoch:3 step:2982 [D loss: 0.662875, acc.: 56.25%] [G loss: 0.846640]\n",
      "epoch:3 step:2983 [D loss: 0.679445, acc.: 57.81%] [G loss: 0.784418]\n",
      "epoch:3 step:2984 [D loss: 0.682121, acc.: 53.91%] [G loss: 0.851168]\n",
      "epoch:3 step:2985 [D loss: 0.700282, acc.: 50.00%] [G loss: 0.801816]\n",
      "epoch:3 step:2986 [D loss: 0.702657, acc.: 50.00%] [G loss: 0.784377]\n",
      "epoch:3 step:2987 [D loss: 0.655545, acc.: 61.72%] [G loss: 0.846772]\n",
      "epoch:3 step:2988 [D loss: 0.714194, acc.: 53.91%] [G loss: 0.810981]\n",
      "epoch:3 step:2989 [D loss: 0.718244, acc.: 53.91%] [G loss: 0.799197]\n",
      "epoch:3 step:2990 [D loss: 0.744774, acc.: 42.19%] [G loss: 0.770465]\n",
      "epoch:3 step:2991 [D loss: 0.711160, acc.: 46.09%] [G loss: 0.758555]\n",
      "epoch:3 step:2992 [D loss: 0.698872, acc.: 51.56%] [G loss: 0.771892]\n",
      "epoch:3 step:2993 [D loss: 0.684797, acc.: 56.25%] [G loss: 0.756730]\n",
      "epoch:3 step:2994 [D loss: 0.694308, acc.: 48.44%] [G loss: 0.797242]\n",
      "epoch:3 step:2995 [D loss: 0.658981, acc.: 58.59%] [G loss: 0.765730]\n",
      "epoch:3 step:2996 [D loss: 0.674525, acc.: 52.34%] [G loss: 0.825682]\n",
      "epoch:3 step:2997 [D loss: 0.712364, acc.: 46.09%] [G loss: 0.808899]\n",
      "epoch:3 step:2998 [D loss: 0.673628, acc.: 52.34%] [G loss: 0.794621]\n",
      "epoch:3 step:2999 [D loss: 0.711470, acc.: 54.69%] [G loss: 0.778174]\n",
      "epoch:3 step:3000 [D loss: 0.696463, acc.: 45.31%] [G loss: 0.765348]\n",
      "##############\n",
      "[4.0049341  2.7696576  6.38060374 5.53303899 4.25742512 6.48645941\n",
      " 4.90404527 6.31383771 5.75649155 5.33457047]\n",
      "##########\n",
      "epoch:3 step:3001 [D loss: 0.702606, acc.: 47.66%] [G loss: 0.778488]\n",
      "epoch:3 step:3002 [D loss: 0.663092, acc.: 59.38%] [G loss: 0.824727]\n",
      "epoch:3 step:3003 [D loss: 0.689172, acc.: 53.12%] [G loss: 0.818759]\n",
      "epoch:3 step:3004 [D loss: 0.705998, acc.: 52.34%] [G loss: 0.818288]\n",
      "epoch:3 step:3005 [D loss: 0.687064, acc.: 57.03%] [G loss: 0.827071]\n",
      "epoch:3 step:3006 [D loss: 0.675370, acc.: 60.94%] [G loss: 0.782907]\n",
      "epoch:3 step:3007 [D loss: 0.688631, acc.: 50.78%] [G loss: 0.802626]\n",
      "epoch:3 step:3008 [D loss: 0.685545, acc.: 57.03%] [G loss: 0.848274]\n",
      "epoch:3 step:3009 [D loss: 0.682163, acc.: 53.91%] [G loss: 0.818682]\n",
      "epoch:3 step:3010 [D loss: 0.703530, acc.: 50.00%] [G loss: 0.786443]\n",
      "epoch:3 step:3011 [D loss: 0.696189, acc.: 55.47%] [G loss: 0.869406]\n",
      "epoch:3 step:3012 [D loss: 0.732348, acc.: 39.84%] [G loss: 0.790605]\n",
      "epoch:3 step:3013 [D loss: 0.693921, acc.: 53.91%] [G loss: 0.780633]\n",
      "epoch:3 step:3014 [D loss: 0.705870, acc.: 53.12%] [G loss: 0.813684]\n",
      "epoch:3 step:3015 [D loss: 0.683702, acc.: 62.50%] [G loss: 0.813110]\n",
      "epoch:3 step:3016 [D loss: 0.676591, acc.: 59.38%] [G loss: 0.801376]\n",
      "epoch:3 step:3017 [D loss: 0.661260, acc.: 59.38%] [G loss: 0.827826]\n",
      "epoch:3 step:3018 [D loss: 0.655102, acc.: 62.50%] [G loss: 0.802817]\n",
      "epoch:3 step:3019 [D loss: 0.652948, acc.: 64.84%] [G loss: 0.815041]\n",
      "epoch:3 step:3020 [D loss: 0.642038, acc.: 62.50%] [G loss: 0.799823]\n",
      "epoch:3 step:3021 [D loss: 0.720204, acc.: 46.88%] [G loss: 0.787408]\n",
      "epoch:3 step:3022 [D loss: 0.724256, acc.: 45.31%] [G loss: 0.798683]\n",
      "epoch:3 step:3023 [D loss: 0.683575, acc.: 46.88%] [G loss: 0.789868]\n",
      "epoch:3 step:3024 [D loss: 0.686720, acc.: 52.34%] [G loss: 0.814671]\n",
      "epoch:3 step:3025 [D loss: 0.697342, acc.: 52.34%] [G loss: 0.807197]\n",
      "epoch:3 step:3026 [D loss: 0.703245, acc.: 52.34%] [G loss: 0.766858]\n",
      "epoch:3 step:3027 [D loss: 0.733698, acc.: 56.25%] [G loss: 0.728684]\n",
      "epoch:3 step:3028 [D loss: 0.705422, acc.: 46.09%] [G loss: 0.750370]\n",
      "epoch:3 step:3029 [D loss: 0.691033, acc.: 46.09%] [G loss: 0.770966]\n",
      "epoch:3 step:3030 [D loss: 0.679833, acc.: 51.56%] [G loss: 0.784544]\n",
      "epoch:3 step:3031 [D loss: 0.732831, acc.: 40.62%] [G loss: 0.780483]\n",
      "epoch:3 step:3032 [D loss: 0.675934, acc.: 58.59%] [G loss: 0.809830]\n",
      "epoch:3 step:3033 [D loss: 0.672688, acc.: 59.38%] [G loss: 0.832051]\n",
      "epoch:3 step:3034 [D loss: 0.664042, acc.: 60.94%] [G loss: 0.811826]\n",
      "epoch:3 step:3035 [D loss: 0.682216, acc.: 57.03%] [G loss: 0.856059]\n",
      "epoch:3 step:3036 [D loss: 0.708010, acc.: 53.91%] [G loss: 0.831216]\n",
      "epoch:3 step:3037 [D loss: 0.683690, acc.: 52.34%] [G loss: 0.848169]\n",
      "epoch:3 step:3038 [D loss: 0.691092, acc.: 52.34%] [G loss: 0.803095]\n",
      "epoch:3 step:3039 [D loss: 0.686886, acc.: 53.12%] [G loss: 0.833843]\n",
      "epoch:3 step:3040 [D loss: 0.705535, acc.: 50.78%] [G loss: 0.844999]\n",
      "epoch:3 step:3041 [D loss: 0.627866, acc.: 64.06%] [G loss: 0.825338]\n",
      "epoch:3 step:3042 [D loss: 0.642838, acc.: 59.38%] [G loss: 0.872938]\n",
      "epoch:3 step:3043 [D loss: 0.653753, acc.: 60.16%] [G loss: 0.823067]\n",
      "epoch:3 step:3044 [D loss: 0.754524, acc.: 46.09%] [G loss: 0.815106]\n",
      "epoch:3 step:3045 [D loss: 0.746192, acc.: 41.41%] [G loss: 0.803645]\n",
      "epoch:3 step:3046 [D loss: 0.687265, acc.: 57.03%] [G loss: 0.760933]\n",
      "epoch:3 step:3047 [D loss: 0.685175, acc.: 57.03%] [G loss: 0.763895]\n",
      "epoch:3 step:3048 [D loss: 0.695404, acc.: 51.56%] [G loss: 0.832484]\n",
      "epoch:3 step:3049 [D loss: 0.698134, acc.: 51.56%] [G loss: 0.778781]\n",
      "epoch:3 step:3050 [D loss: 0.681449, acc.: 60.16%] [G loss: 0.730526]\n",
      "epoch:3 step:3051 [D loss: 0.696696, acc.: 50.00%] [G loss: 0.810173]\n",
      "epoch:3 step:3052 [D loss: 0.672181, acc.: 57.81%] [G loss: 0.801143]\n",
      "epoch:3 step:3053 [D loss: 0.700546, acc.: 50.00%] [G loss: 0.781662]\n",
      "epoch:3 step:3054 [D loss: 0.682302, acc.: 55.47%] [G loss: 0.763301]\n",
      "epoch:3 step:3055 [D loss: 0.677444, acc.: 53.91%] [G loss: 0.790970]\n",
      "epoch:3 step:3056 [D loss: 0.689704, acc.: 60.16%] [G loss: 0.813981]\n",
      "epoch:3 step:3057 [D loss: 0.684878, acc.: 54.69%] [G loss: 0.842925]\n",
      "epoch:3 step:3058 [D loss: 0.676654, acc.: 54.69%] [G loss: 0.761972]\n",
      "epoch:3 step:3059 [D loss: 0.694521, acc.: 56.25%] [G loss: 0.806693]\n",
      "epoch:3 step:3060 [D loss: 0.709669, acc.: 50.00%] [G loss: 0.764057]\n",
      "epoch:3 step:3061 [D loss: 0.729519, acc.: 39.84%] [G loss: 0.801105]\n",
      "epoch:3 step:3062 [D loss: 0.726297, acc.: 44.53%] [G loss: 0.848294]\n",
      "epoch:3 step:3063 [D loss: 0.697140, acc.: 50.78%] [G loss: 0.897186]\n",
      "epoch:3 step:3064 [D loss: 0.671434, acc.: 60.16%] [G loss: 0.878808]\n",
      "epoch:3 step:3065 [D loss: 0.691724, acc.: 57.03%] [G loss: 0.840608]\n",
      "epoch:3 step:3066 [D loss: 0.707472, acc.: 52.34%] [G loss: 0.811049]\n",
      "epoch:3 step:3067 [D loss: 0.663849, acc.: 60.94%] [G loss: 0.836337]\n",
      "epoch:3 step:3068 [D loss: 0.689785, acc.: 56.25%] [G loss: 0.828936]\n",
      "epoch:3 step:3069 [D loss: 0.684305, acc.: 54.69%] [G loss: 0.767907]\n",
      "epoch:3 step:3070 [D loss: 0.715672, acc.: 50.78%] [G loss: 0.762116]\n",
      "epoch:3 step:3071 [D loss: 0.707384, acc.: 49.22%] [G loss: 0.726275]\n",
      "epoch:3 step:3072 [D loss: 0.689847, acc.: 52.34%] [G loss: 0.795265]\n",
      "epoch:3 step:3073 [D loss: 0.706975, acc.: 56.25%] [G loss: 0.768747]\n",
      "epoch:3 step:3074 [D loss: 0.714246, acc.: 47.66%] [G loss: 0.799858]\n",
      "epoch:3 step:3075 [D loss: 0.706829, acc.: 49.22%] [G loss: 0.785714]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:3 step:3076 [D loss: 0.681952, acc.: 57.03%] [G loss: 0.775559]\n",
      "epoch:3 step:3077 [D loss: 0.709108, acc.: 49.22%] [G loss: 0.825639]\n",
      "epoch:3 step:3078 [D loss: 0.670675, acc.: 54.69%] [G loss: 0.786897]\n",
      "epoch:3 step:3079 [D loss: 0.689901, acc.: 53.91%] [G loss: 0.725981]\n",
      "epoch:3 step:3080 [D loss: 0.709492, acc.: 49.22%] [G loss: 0.773175]\n",
      "epoch:3 step:3081 [D loss: 0.702766, acc.: 48.44%] [G loss: 0.782476]\n",
      "epoch:3 step:3082 [D loss: 0.687378, acc.: 50.00%] [G loss: 0.771972]\n",
      "epoch:3 step:3083 [D loss: 0.667873, acc.: 59.38%] [G loss: 0.826240]\n",
      "epoch:3 step:3084 [D loss: 0.661513, acc.: 60.94%] [G loss: 0.854236]\n",
      "epoch:3 step:3085 [D loss: 0.655356, acc.: 61.72%] [G loss: 0.867816]\n",
      "epoch:3 step:3086 [D loss: 0.613487, acc.: 70.31%] [G loss: 0.800345]\n",
      "epoch:3 step:3087 [D loss: 0.641600, acc.: 59.38%] [G loss: 0.819951]\n",
      "epoch:3 step:3088 [D loss: 0.650387, acc.: 57.81%] [G loss: 0.889180]\n",
      "epoch:3 step:3089 [D loss: 0.698248, acc.: 52.34%] [G loss: 0.843843]\n",
      "epoch:3 step:3090 [D loss: 0.696425, acc.: 51.56%] [G loss: 0.785979]\n",
      "epoch:3 step:3091 [D loss: 0.711019, acc.: 48.44%] [G loss: 0.746637]\n",
      "epoch:3 step:3092 [D loss: 0.748629, acc.: 50.00%] [G loss: 0.771854]\n",
      "epoch:3 step:3093 [D loss: 0.740140, acc.: 46.09%] [G loss: 0.767863]\n",
      "epoch:3 step:3094 [D loss: 0.688332, acc.: 51.56%] [G loss: 0.803177]\n",
      "epoch:3 step:3095 [D loss: 0.653256, acc.: 67.97%] [G loss: 0.819068]\n",
      "epoch:3 step:3096 [D loss: 0.631341, acc.: 67.97%] [G loss: 0.880513]\n",
      "epoch:3 step:3097 [D loss: 0.660225, acc.: 54.69%] [G loss: 0.839408]\n",
      "epoch:3 step:3098 [D loss: 0.699624, acc.: 54.69%] [G loss: 0.858564]\n",
      "epoch:3 step:3099 [D loss: 0.682131, acc.: 55.47%] [G loss: 0.849728]\n",
      "epoch:3 step:3100 [D loss: 0.673536, acc.: 57.03%] [G loss: 0.851106]\n",
      "epoch:3 step:3101 [D loss: 0.675213, acc.: 55.47%] [G loss: 0.889700]\n",
      "epoch:3 step:3102 [D loss: 0.725378, acc.: 39.84%] [G loss: 0.743366]\n",
      "epoch:3 step:3103 [D loss: 0.710078, acc.: 50.78%] [G loss: 0.819218]\n",
      "epoch:3 step:3104 [D loss: 0.678341, acc.: 59.38%] [G loss: 0.799824]\n",
      "epoch:3 step:3105 [D loss: 0.729762, acc.: 49.22%] [G loss: 0.764138]\n",
      "epoch:3 step:3106 [D loss: 0.726553, acc.: 41.41%] [G loss: 0.805481]\n",
      "epoch:3 step:3107 [D loss: 0.670009, acc.: 51.56%] [G loss: 0.814436]\n",
      "epoch:3 step:3108 [D loss: 0.731721, acc.: 39.84%] [G loss: 0.788453]\n",
      "epoch:3 step:3109 [D loss: 0.688527, acc.: 55.47%] [G loss: 0.757075]\n",
      "epoch:3 step:3110 [D loss: 0.674201, acc.: 54.69%] [G loss: 0.808968]\n",
      "epoch:3 step:3111 [D loss: 0.685859, acc.: 57.81%] [G loss: 0.804862]\n",
      "epoch:3 step:3112 [D loss: 0.711797, acc.: 46.09%] [G loss: 0.809781]\n",
      "epoch:3 step:3113 [D loss: 0.692576, acc.: 53.91%] [G loss: 0.789710]\n",
      "epoch:3 step:3114 [D loss: 0.712140, acc.: 50.78%] [G loss: 0.773291]\n",
      "epoch:3 step:3115 [D loss: 0.708882, acc.: 50.00%] [G loss: 0.741284]\n",
      "epoch:3 step:3116 [D loss: 0.699627, acc.: 48.44%] [G loss: 0.798884]\n",
      "epoch:3 step:3117 [D loss: 0.685180, acc.: 53.12%] [G loss: 0.771770]\n",
      "epoch:3 step:3118 [D loss: 0.690833, acc.: 53.91%] [G loss: 0.844353]\n",
      "epoch:3 step:3119 [D loss: 0.674487, acc.: 51.56%] [G loss: 0.832959]\n",
      "epoch:3 step:3120 [D loss: 0.680573, acc.: 56.25%] [G loss: 0.776363]\n",
      "epoch:3 step:3121 [D loss: 0.656781, acc.: 66.41%] [G loss: 0.842103]\n",
      "epoch:3 step:3122 [D loss: 0.675309, acc.: 57.03%] [G loss: 0.829170]\n",
      "epoch:3 step:3123 [D loss: 0.658694, acc.: 64.84%] [G loss: 0.870241]\n",
      "epoch:3 step:3124 [D loss: 0.655949, acc.: 58.59%] [G loss: 0.767267]\n",
      "epoch:3 step:3125 [D loss: 0.662302, acc.: 57.03%] [G loss: 0.795474]\n",
      "epoch:3 step:3126 [D loss: 0.668753, acc.: 58.59%] [G loss: 0.770886]\n",
      "epoch:3 step:3127 [D loss: 0.744386, acc.: 46.09%] [G loss: 0.775287]\n",
      "epoch:3 step:3128 [D loss: 0.732275, acc.: 41.41%] [G loss: 0.814226]\n",
      "epoch:3 step:3129 [D loss: 0.713629, acc.: 50.00%] [G loss: 0.789239]\n",
      "epoch:3 step:3130 [D loss: 0.670457, acc.: 57.81%] [G loss: 0.784293]\n",
      "epoch:3 step:3131 [D loss: 0.714721, acc.: 45.31%] [G loss: 0.817600]\n",
      "epoch:3 step:3132 [D loss: 0.733050, acc.: 43.75%] [G loss: 0.813135]\n",
      "epoch:3 step:3133 [D loss: 0.666612, acc.: 58.59%] [G loss: 0.817285]\n",
      "epoch:3 step:3134 [D loss: 0.677471, acc.: 58.59%] [G loss: 0.800173]\n",
      "epoch:3 step:3135 [D loss: 0.679155, acc.: 57.03%] [G loss: 0.803893]\n",
      "epoch:3 step:3136 [D loss: 0.663135, acc.: 60.94%] [G loss: 0.809764]\n",
      "epoch:3 step:3137 [D loss: 0.689896, acc.: 46.88%] [G loss: 0.803753]\n",
      "epoch:3 step:3138 [D loss: 0.679264, acc.: 52.34%] [G loss: 0.842501]\n",
      "epoch:3 step:3139 [D loss: 0.640808, acc.: 67.19%] [G loss: 0.784184]\n",
      "epoch:3 step:3140 [D loss: 0.705507, acc.: 49.22%] [G loss: 0.723454]\n",
      "epoch:3 step:3141 [D loss: 0.704075, acc.: 50.78%] [G loss: 0.800885]\n",
      "epoch:3 step:3142 [D loss: 0.707688, acc.: 54.69%] [G loss: 0.793504]\n",
      "epoch:3 step:3143 [D loss: 0.698046, acc.: 53.91%] [G loss: 0.775752]\n",
      "epoch:3 step:3144 [D loss: 0.745172, acc.: 50.78%] [G loss: 0.730956]\n",
      "epoch:3 step:3145 [D loss: 0.745856, acc.: 42.97%] [G loss: 0.773373]\n",
      "epoch:3 step:3146 [D loss: 0.714456, acc.: 43.75%] [G loss: 0.776899]\n",
      "epoch:3 step:3147 [D loss: 0.659538, acc.: 63.28%] [G loss: 0.826589]\n",
      "epoch:3 step:3148 [D loss: 0.681470, acc.: 49.22%] [G loss: 0.816633]\n",
      "epoch:3 step:3149 [D loss: 0.674861, acc.: 57.03%] [G loss: 0.846022]\n",
      "epoch:3 step:3150 [D loss: 0.648840, acc.: 67.19%] [G loss: 0.877594]\n",
      "epoch:3 step:3151 [D loss: 0.677554, acc.: 53.12%] [G loss: 0.830741]\n",
      "epoch:3 step:3152 [D loss: 0.660665, acc.: 57.81%] [G loss: 0.867006]\n",
      "epoch:3 step:3153 [D loss: 0.650215, acc.: 64.06%] [G loss: 0.831512]\n",
      "epoch:3 step:3154 [D loss: 0.629806, acc.: 65.62%] [G loss: 0.843756]\n",
      "epoch:3 step:3155 [D loss: 0.662145, acc.: 62.50%] [G loss: 0.863413]\n",
      "epoch:3 step:3156 [D loss: 0.720909, acc.: 47.66%] [G loss: 0.837407]\n",
      "epoch:3 step:3157 [D loss: 0.714019, acc.: 44.53%] [G loss: 0.766977]\n",
      "epoch:3 step:3158 [D loss: 0.678644, acc.: 58.59%] [G loss: 0.751302]\n",
      "epoch:3 step:3159 [D loss: 0.741643, acc.: 47.66%] [G loss: 0.752903]\n",
      "epoch:3 step:3160 [D loss: 0.739597, acc.: 41.41%] [G loss: 0.775955]\n",
      "epoch:3 step:3161 [D loss: 0.688403, acc.: 56.25%] [G loss: 0.770380]\n",
      "epoch:3 step:3162 [D loss: 0.696077, acc.: 52.34%] [G loss: 0.791055]\n",
      "epoch:3 step:3163 [D loss: 0.693118, acc.: 48.44%] [G loss: 0.817269]\n",
      "epoch:3 step:3164 [D loss: 0.683098, acc.: 57.03%] [G loss: 0.817734]\n",
      "epoch:3 step:3165 [D loss: 0.669680, acc.: 55.47%] [G loss: 0.867286]\n",
      "epoch:3 step:3166 [D loss: 0.675792, acc.: 56.25%] [G loss: 0.808224]\n",
      "epoch:3 step:3167 [D loss: 0.707507, acc.: 53.12%] [G loss: 0.807419]\n",
      "epoch:3 step:3168 [D loss: 0.683151, acc.: 54.69%] [G loss: 0.792453]\n",
      "epoch:3 step:3169 [D loss: 0.690137, acc.: 50.78%] [G loss: 0.767500]\n",
      "epoch:3 step:3170 [D loss: 0.686317, acc.: 57.81%] [G loss: 0.808482]\n",
      "epoch:3 step:3171 [D loss: 0.670785, acc.: 55.47%] [G loss: 0.753077]\n",
      "epoch:3 step:3172 [D loss: 0.728831, acc.: 51.56%] [G loss: 0.784781]\n",
      "epoch:3 step:3173 [D loss: 0.723941, acc.: 42.97%] [G loss: 0.812222]\n",
      "epoch:3 step:3174 [D loss: 0.742559, acc.: 42.97%] [G loss: 0.777528]\n",
      "epoch:3 step:3175 [D loss: 0.664175, acc.: 56.25%] [G loss: 0.815348]\n",
      "epoch:3 step:3176 [D loss: 0.700098, acc.: 54.69%] [G loss: 0.793261]\n",
      "epoch:3 step:3177 [D loss: 0.699700, acc.: 53.12%] [G loss: 0.805885]\n",
      "epoch:3 step:3178 [D loss: 0.690901, acc.: 54.69%] [G loss: 0.805436]\n",
      "epoch:3 step:3179 [D loss: 0.673992, acc.: 53.91%] [G loss: 0.860309]\n",
      "epoch:3 step:3180 [D loss: 0.686477, acc.: 61.72%] [G loss: 0.816353]\n",
      "epoch:3 step:3181 [D loss: 0.664739, acc.: 61.72%] [G loss: 0.766039]\n",
      "epoch:3 step:3182 [D loss: 0.690529, acc.: 54.69%] [G loss: 0.802131]\n",
      "epoch:3 step:3183 [D loss: 0.700417, acc.: 50.00%] [G loss: 0.816266]\n",
      "epoch:3 step:3184 [D loss: 0.692228, acc.: 51.56%] [G loss: 0.821538]\n",
      "epoch:3 step:3185 [D loss: 0.676659, acc.: 54.69%] [G loss: 0.778036]\n",
      "epoch:3 step:3186 [D loss: 0.684609, acc.: 56.25%] [G loss: 0.816807]\n",
      "epoch:3 step:3187 [D loss: 0.698131, acc.: 59.38%] [G loss: 0.801107]\n",
      "epoch:3 step:3188 [D loss: 0.699473, acc.: 50.78%] [G loss: 0.791451]\n",
      "epoch:3 step:3189 [D loss: 0.662459, acc.: 57.03%] [G loss: 0.755455]\n",
      "epoch:3 step:3190 [D loss: 0.722286, acc.: 48.44%] [G loss: 0.771961]\n",
      "epoch:3 step:3191 [D loss: 0.689512, acc.: 53.91%] [G loss: 0.791326]\n",
      "epoch:3 step:3192 [D loss: 0.696213, acc.: 53.91%] [G loss: 0.741825]\n",
      "epoch:3 step:3193 [D loss: 0.707860, acc.: 47.66%] [G loss: 0.742054]\n",
      "epoch:3 step:3194 [D loss: 0.692169, acc.: 50.78%] [G loss: 0.773320]\n",
      "epoch:3 step:3195 [D loss: 0.698929, acc.: 46.09%] [G loss: 0.763234]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:3 step:3196 [D loss: 0.667343, acc.: 57.81%] [G loss: 0.795169]\n",
      "epoch:3 step:3197 [D loss: 0.677904, acc.: 59.38%] [G loss: 0.813989]\n",
      "epoch:3 step:3198 [D loss: 0.676191, acc.: 55.47%] [G loss: 0.805173]\n",
      "epoch:3 step:3199 [D loss: 0.663995, acc.: 60.94%] [G loss: 0.787843]\n",
      "epoch:3 step:3200 [D loss: 0.698400, acc.: 56.25%] [G loss: 0.811826]\n",
      "##############\n",
      "[4.03132746 2.38119982 6.3051718  5.52113534 4.29937253 5.98610678\n",
      " 5.04437825 5.50040156 5.6676053  4.91879397]\n",
      "##########\n",
      "epoch:3 step:3201 [D loss: 0.737839, acc.: 43.75%] [G loss: 0.739293]\n",
      "epoch:3 step:3202 [D loss: 0.694888, acc.: 46.88%] [G loss: 0.786306]\n",
      "epoch:3 step:3203 [D loss: 0.686878, acc.: 57.03%] [G loss: 0.790771]\n",
      "epoch:3 step:3204 [D loss: 0.701507, acc.: 48.44%] [G loss: 0.763871]\n",
      "epoch:3 step:3205 [D loss: 0.703592, acc.: 53.12%] [G loss: 0.782430]\n",
      "epoch:3 step:3206 [D loss: 0.703150, acc.: 49.22%] [G loss: 0.752310]\n",
      "epoch:3 step:3207 [D loss: 0.712235, acc.: 48.44%] [G loss: 0.730995]\n",
      "epoch:3 step:3208 [D loss: 0.689315, acc.: 52.34%] [G loss: 0.779207]\n",
      "epoch:3 step:3209 [D loss: 0.677168, acc.: 57.81%] [G loss: 0.780201]\n",
      "epoch:3 step:3210 [D loss: 0.656338, acc.: 58.59%] [G loss: 0.786457]\n",
      "epoch:3 step:3211 [D loss: 0.683919, acc.: 56.25%] [G loss: 0.801557]\n",
      "epoch:3 step:3212 [D loss: 0.679714, acc.: 53.12%] [G loss: 0.816688]\n",
      "epoch:3 step:3213 [D loss: 0.651983, acc.: 58.59%] [G loss: 0.793800]\n",
      "epoch:3 step:3214 [D loss: 0.671956, acc.: 58.59%] [G loss: 0.821779]\n",
      "epoch:3 step:3215 [D loss: 0.665590, acc.: 58.59%] [G loss: 0.737057]\n",
      "epoch:3 step:3216 [D loss: 0.687173, acc.: 49.22%] [G loss: 0.782897]\n",
      "epoch:3 step:3217 [D loss: 0.657649, acc.: 60.94%] [G loss: 0.827781]\n",
      "epoch:3 step:3218 [D loss: 0.681414, acc.: 53.91%] [G loss: 0.826057]\n",
      "epoch:3 step:3219 [D loss: 0.684706, acc.: 53.12%] [G loss: 0.775648]\n",
      "epoch:3 step:3220 [D loss: 0.683878, acc.: 50.78%] [G loss: 0.787953]\n",
      "epoch:3 step:3221 [D loss: 0.698483, acc.: 50.00%] [G loss: 0.778620]\n",
      "epoch:3 step:3222 [D loss: 0.758411, acc.: 45.31%] [G loss: 0.765860]\n",
      "epoch:3 step:3223 [D loss: 0.710067, acc.: 52.34%] [G loss: 0.762663]\n",
      "epoch:3 step:3224 [D loss: 0.691536, acc.: 45.31%] [G loss: 0.735375]\n",
      "epoch:3 step:3225 [D loss: 0.703840, acc.: 49.22%] [G loss: 0.823234]\n",
      "epoch:3 step:3226 [D loss: 0.674377, acc.: 53.91%] [G loss: 0.745569]\n",
      "epoch:3 step:3227 [D loss: 0.686669, acc.: 62.50%] [G loss: 0.790434]\n",
      "epoch:3 step:3228 [D loss: 0.686044, acc.: 54.69%] [G loss: 0.806919]\n",
      "epoch:3 step:3229 [D loss: 0.678556, acc.: 54.69%] [G loss: 0.798355]\n",
      "epoch:3 step:3230 [D loss: 0.675723, acc.: 55.47%] [G loss: 0.803477]\n",
      "epoch:3 step:3231 [D loss: 0.670137, acc.: 59.38%] [G loss: 0.819651]\n",
      "epoch:3 step:3232 [D loss: 0.672549, acc.: 59.38%] [G loss: 0.866534]\n",
      "epoch:3 step:3233 [D loss: 0.727721, acc.: 46.88%] [G loss: 0.796089]\n",
      "epoch:3 step:3234 [D loss: 0.666958, acc.: 60.16%] [G loss: 0.841937]\n",
      "epoch:3 step:3235 [D loss: 0.643417, acc.: 63.28%] [G loss: 0.801064]\n",
      "epoch:3 step:3236 [D loss: 0.651155, acc.: 61.72%] [G loss: 0.833077]\n",
      "epoch:3 step:3237 [D loss: 0.623906, acc.: 67.97%] [G loss: 0.836102]\n",
      "epoch:3 step:3238 [D loss: 0.661387, acc.: 60.94%] [G loss: 0.859686]\n",
      "epoch:3 step:3239 [D loss: 0.684139, acc.: 51.56%] [G loss: 0.837842]\n",
      "epoch:3 step:3240 [D loss: 0.651923, acc.: 60.16%] [G loss: 0.880542]\n",
      "epoch:3 step:3241 [D loss: 0.685746, acc.: 54.69%] [G loss: 0.881720]\n",
      "epoch:3 step:3242 [D loss: 0.722078, acc.: 51.56%] [G loss: 0.814990]\n",
      "epoch:3 step:3243 [D loss: 0.759688, acc.: 44.53%] [G loss: 0.748255]\n",
      "epoch:3 step:3244 [D loss: 0.696340, acc.: 49.22%] [G loss: 0.770829]\n",
      "epoch:3 step:3245 [D loss: 0.702314, acc.: 52.34%] [G loss: 0.797027]\n",
      "epoch:3 step:3246 [D loss: 0.675896, acc.: 56.25%] [G loss: 0.782201]\n",
      "epoch:3 step:3247 [D loss: 0.657809, acc.: 59.38%] [G loss: 0.777104]\n",
      "epoch:3 step:3248 [D loss: 0.726705, acc.: 43.75%] [G loss: 0.818761]\n",
      "epoch:3 step:3249 [D loss: 0.693409, acc.: 53.12%] [G loss: 0.770498]\n",
      "epoch:3 step:3250 [D loss: 0.710974, acc.: 48.44%] [G loss: 0.819645]\n",
      "epoch:3 step:3251 [D loss: 0.697443, acc.: 50.00%] [G loss: 0.754818]\n",
      "epoch:3 step:3252 [D loss: 0.675048, acc.: 53.12%] [G loss: 0.795756]\n",
      "epoch:3 step:3253 [D loss: 0.683835, acc.: 61.72%] [G loss: 0.780685]\n",
      "epoch:3 step:3254 [D loss: 0.699500, acc.: 55.47%] [G loss: 0.801633]\n",
      "epoch:3 step:3255 [D loss: 0.662946, acc.: 57.03%] [G loss: 0.855090]\n",
      "epoch:3 step:3256 [D loss: 0.685582, acc.: 57.03%] [G loss: 0.810538]\n",
      "epoch:3 step:3257 [D loss: 0.688767, acc.: 53.91%] [G loss: 0.777535]\n",
      "epoch:3 step:3258 [D loss: 0.695084, acc.: 55.47%] [G loss: 0.799846]\n",
      "epoch:3 step:3259 [D loss: 0.718766, acc.: 43.75%] [G loss: 0.746153]\n",
      "epoch:3 step:3260 [D loss: 0.710493, acc.: 53.12%] [G loss: 0.787238]\n",
      "epoch:3 step:3261 [D loss: 0.677940, acc.: 55.47%] [G loss: 0.785401]\n",
      "epoch:3 step:3262 [D loss: 0.691774, acc.: 49.22%] [G loss: 0.837106]\n",
      "epoch:3 step:3263 [D loss: 0.699715, acc.: 53.91%] [G loss: 0.864879]\n",
      "epoch:3 step:3264 [D loss: 0.674906, acc.: 53.12%] [G loss: 0.784731]\n",
      "epoch:3 step:3265 [D loss: 0.675113, acc.: 56.25%] [G loss: 0.813726]\n",
      "epoch:3 step:3266 [D loss: 0.669872, acc.: 57.81%] [G loss: 0.852240]\n",
      "epoch:3 step:3267 [D loss: 0.678369, acc.: 56.25%] [G loss: 0.813645]\n",
      "epoch:3 step:3268 [D loss: 0.667242, acc.: 55.47%] [G loss: 0.791165]\n",
      "epoch:3 step:3269 [D loss: 0.699965, acc.: 55.47%] [G loss: 0.796152]\n",
      "epoch:3 step:3270 [D loss: 0.700075, acc.: 52.34%] [G loss: 0.795233]\n",
      "epoch:3 step:3271 [D loss: 0.670180, acc.: 58.59%] [G loss: 0.846333]\n",
      "epoch:3 step:3272 [D loss: 0.675100, acc.: 55.47%] [G loss: 0.794280]\n",
      "epoch:3 step:3273 [D loss: 0.712382, acc.: 51.56%] [G loss: 0.769071]\n",
      "epoch:3 step:3274 [D loss: 0.707714, acc.: 50.78%] [G loss: 0.806911]\n",
      "epoch:3 step:3275 [D loss: 0.690402, acc.: 52.34%] [G loss: 0.818062]\n",
      "epoch:3 step:3276 [D loss: 0.702583, acc.: 50.00%] [G loss: 0.778143]\n",
      "epoch:3 step:3277 [D loss: 0.685898, acc.: 52.34%] [G loss: 0.757133]\n",
      "epoch:3 step:3278 [D loss: 0.695458, acc.: 51.56%] [G loss: 0.768980]\n",
      "epoch:3 step:3279 [D loss: 0.676320, acc.: 52.34%] [G loss: 0.795257]\n",
      "epoch:3 step:3280 [D loss: 0.653100, acc.: 63.28%] [G loss: 0.816438]\n",
      "epoch:3 step:3281 [D loss: 0.666106, acc.: 54.69%] [G loss: 0.787641]\n",
      "epoch:3 step:3282 [D loss: 0.662545, acc.: 58.59%] [G loss: 0.809120]\n",
      "epoch:3 step:3283 [D loss: 0.700837, acc.: 50.00%] [G loss: 0.843532]\n",
      "epoch:3 step:3284 [D loss: 0.739519, acc.: 44.53%] [G loss: 0.756007]\n",
      "epoch:3 step:3285 [D loss: 0.715443, acc.: 48.44%] [G loss: 0.828330]\n",
      "epoch:3 step:3286 [D loss: 0.667266, acc.: 57.03%] [G loss: 0.795118]\n",
      "epoch:3 step:3287 [D loss: 0.713314, acc.: 49.22%] [G loss: 0.748193]\n",
      "epoch:3 step:3288 [D loss: 0.713398, acc.: 47.66%] [G loss: 0.766266]\n",
      "epoch:3 step:3289 [D loss: 0.694302, acc.: 50.78%] [G loss: 0.817704]\n",
      "epoch:3 step:3290 [D loss: 0.686565, acc.: 52.34%] [G loss: 0.755453]\n",
      "epoch:3 step:3291 [D loss: 0.712076, acc.: 42.19%] [G loss: 0.817663]\n",
      "epoch:3 step:3292 [D loss: 0.672952, acc.: 54.69%] [G loss: 0.748334]\n",
      "epoch:3 step:3293 [D loss: 0.692888, acc.: 50.00%] [G loss: 0.780005]\n",
      "epoch:3 step:3294 [D loss: 0.687841, acc.: 55.47%] [G loss: 0.791496]\n",
      "epoch:3 step:3295 [D loss: 0.686572, acc.: 53.91%] [G loss: 0.812270]\n",
      "epoch:3 step:3296 [D loss: 0.647819, acc.: 67.19%] [G loss: 0.835925]\n",
      "epoch:3 step:3297 [D loss: 0.694022, acc.: 55.47%] [G loss: 0.819817]\n",
      "epoch:3 step:3298 [D loss: 0.707380, acc.: 45.31%] [G loss: 0.797833]\n",
      "epoch:3 step:3299 [D loss: 0.718817, acc.: 50.00%] [G loss: 0.773161]\n",
      "epoch:3 step:3300 [D loss: 0.721367, acc.: 48.44%] [G loss: 0.772197]\n",
      "epoch:3 step:3301 [D loss: 0.695464, acc.: 58.59%] [G loss: 0.769430]\n",
      "epoch:3 step:3302 [D loss: 0.710231, acc.: 46.88%] [G loss: 0.768101]\n",
      "epoch:3 step:3303 [D loss: 0.719141, acc.: 43.75%] [G loss: 0.753923]\n",
      "epoch:3 step:3304 [D loss: 0.683990, acc.: 54.69%] [G loss: 0.768102]\n",
      "epoch:3 step:3305 [D loss: 0.700202, acc.: 46.88%] [G loss: 0.763122]\n",
      "epoch:3 step:3306 [D loss: 0.688318, acc.: 53.91%] [G loss: 0.772780]\n",
      "epoch:3 step:3307 [D loss: 0.687916, acc.: 53.12%] [G loss: 0.794524]\n",
      "epoch:3 step:3308 [D loss: 0.686318, acc.: 60.94%] [G loss: 0.744868]\n",
      "epoch:3 step:3309 [D loss: 0.692161, acc.: 57.03%] [G loss: 0.795445]\n",
      "epoch:3 step:3310 [D loss: 0.660604, acc.: 62.50%] [G loss: 0.819361]\n",
      "epoch:3 step:3311 [D loss: 0.707813, acc.: 52.34%] [G loss: 0.755236]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:3 step:3312 [D loss: 0.710469, acc.: 46.88%] [G loss: 0.773416]\n",
      "epoch:3 step:3313 [D loss: 0.699250, acc.: 45.31%] [G loss: 0.765173]\n",
      "epoch:3 step:3314 [D loss: 0.703239, acc.: 48.44%] [G loss: 0.775959]\n",
      "epoch:3 step:3315 [D loss: 0.664976, acc.: 60.16%] [G loss: 0.792905]\n",
      "epoch:3 step:3316 [D loss: 0.660246, acc.: 59.38%] [G loss: 0.792146]\n",
      "epoch:3 step:3317 [D loss: 0.719420, acc.: 44.53%] [G loss: 0.781589]\n",
      "epoch:3 step:3318 [D loss: 0.679821, acc.: 53.91%] [G loss: 0.780447]\n",
      "epoch:3 step:3319 [D loss: 0.636358, acc.: 65.62%] [G loss: 0.758263]\n",
      "epoch:3 step:3320 [D loss: 0.694069, acc.: 53.12%] [G loss: 0.806740]\n",
      "epoch:3 step:3321 [D loss: 0.722456, acc.: 49.22%] [G loss: 0.751722]\n",
      "epoch:3 step:3322 [D loss: 0.712871, acc.: 46.09%] [G loss: 0.747741]\n",
      "epoch:3 step:3323 [D loss: 0.741550, acc.: 41.41%] [G loss: 0.751550]\n",
      "epoch:3 step:3324 [D loss: 0.680144, acc.: 50.00%] [G loss: 0.776161]\n",
      "epoch:3 step:3325 [D loss: 0.711778, acc.: 50.00%] [G loss: 0.724318]\n",
      "epoch:3 step:3326 [D loss: 0.669976, acc.: 57.81%] [G loss: 0.756611]\n",
      "epoch:3 step:3327 [D loss: 0.698359, acc.: 53.12%] [G loss: 0.764977]\n",
      "epoch:3 step:3328 [D loss: 0.696742, acc.: 55.47%] [G loss: 0.726827]\n",
      "epoch:3 step:3329 [D loss: 0.704873, acc.: 44.53%] [G loss: 0.722970]\n",
      "epoch:3 step:3330 [D loss: 0.693474, acc.: 51.56%] [G loss: 0.733329]\n",
      "epoch:3 step:3331 [D loss: 0.662600, acc.: 61.72%] [G loss: 0.768085]\n",
      "epoch:3 step:3332 [D loss: 0.680473, acc.: 60.16%] [G loss: 0.753518]\n",
      "epoch:3 step:3333 [D loss: 0.671251, acc.: 53.12%] [G loss: 0.782129]\n",
      "epoch:3 step:3334 [D loss: 0.669258, acc.: 59.38%] [G loss: 0.729338]\n",
      "epoch:3 step:3335 [D loss: 0.684317, acc.: 55.47%] [G loss: 0.775124]\n",
      "epoch:3 step:3336 [D loss: 0.699377, acc.: 57.81%] [G loss: 0.799927]\n",
      "epoch:3 step:3337 [D loss: 0.667694, acc.: 60.94%] [G loss: 0.799434]\n",
      "epoch:3 step:3338 [D loss: 0.634065, acc.: 70.31%] [G loss: 0.820036]\n",
      "epoch:3 step:3339 [D loss: 0.720799, acc.: 50.00%] [G loss: 0.788728]\n",
      "epoch:3 step:3340 [D loss: 0.746695, acc.: 42.19%] [G loss: 0.780613]\n",
      "epoch:3 step:3341 [D loss: 0.670432, acc.: 53.91%] [G loss: 0.766241]\n",
      "epoch:3 step:3342 [D loss: 0.678820, acc.: 57.81%] [G loss: 0.805803]\n",
      "epoch:3 step:3343 [D loss: 0.711736, acc.: 46.88%] [G loss: 0.791087]\n",
      "epoch:3 step:3344 [D loss: 0.683672, acc.: 48.44%] [G loss: 0.779070]\n",
      "epoch:3 step:3345 [D loss: 0.685238, acc.: 54.69%] [G loss: 0.774744]\n",
      "epoch:3 step:3346 [D loss: 0.687432, acc.: 55.47%] [G loss: 0.817049]\n",
      "epoch:3 step:3347 [D loss: 0.706205, acc.: 58.59%] [G loss: 0.739645]\n",
      "epoch:3 step:3348 [D loss: 0.686648, acc.: 57.81%] [G loss: 0.759223]\n",
      "epoch:3 step:3349 [D loss: 0.676896, acc.: 60.94%] [G loss: 0.781909]\n",
      "epoch:3 step:3350 [D loss: 0.741652, acc.: 42.97%] [G loss: 0.744618]\n",
      "epoch:3 step:3351 [D loss: 0.703983, acc.: 51.56%] [G loss: 0.768154]\n",
      "epoch:3 step:3352 [D loss: 0.662804, acc.: 54.69%] [G loss: 0.758602]\n",
      "epoch:3 step:3353 [D loss: 0.709447, acc.: 49.22%] [G loss: 0.785711]\n",
      "epoch:3 step:3354 [D loss: 0.712520, acc.: 46.88%] [G loss: 0.750118]\n",
      "epoch:3 step:3355 [D loss: 0.694505, acc.: 54.69%] [G loss: 0.771679]\n",
      "epoch:3 step:3356 [D loss: 0.699961, acc.: 50.00%] [G loss: 0.777081]\n",
      "epoch:3 step:3357 [D loss: 0.685138, acc.: 51.56%] [G loss: 0.784487]\n",
      "epoch:3 step:3358 [D loss: 0.669698, acc.: 56.25%] [G loss: 0.744882]\n",
      "epoch:3 step:3359 [D loss: 0.678875, acc.: 54.69%] [G loss: 0.777543]\n",
      "epoch:3 step:3360 [D loss: 0.659818, acc.: 61.72%] [G loss: 0.761385]\n",
      "epoch:3 step:3361 [D loss: 0.670906, acc.: 62.50%] [G loss: 0.783515]\n",
      "epoch:3 step:3362 [D loss: 0.662223, acc.: 58.59%] [G loss: 0.833211]\n",
      "epoch:3 step:3363 [D loss: 0.670103, acc.: 63.28%] [G loss: 0.784767]\n",
      "epoch:3 step:3364 [D loss: 0.688944, acc.: 53.91%] [G loss: 0.816843]\n",
      "epoch:3 step:3365 [D loss: 0.650433, acc.: 64.06%] [G loss: 0.816803]\n",
      "epoch:3 step:3366 [D loss: 0.650977, acc.: 60.94%] [G loss: 0.821953]\n",
      "epoch:3 step:3367 [D loss: 0.673335, acc.: 58.59%] [G loss: 0.775405]\n",
      "epoch:3 step:3368 [D loss: 0.646810, acc.: 64.06%] [G loss: 0.864632]\n",
      "epoch:3 step:3369 [D loss: 0.682894, acc.: 60.16%] [G loss: 0.772909]\n",
      "epoch:3 step:3370 [D loss: 0.781110, acc.: 39.06%] [G loss: 0.805955]\n",
      "epoch:3 step:3371 [D loss: 0.710196, acc.: 44.53%] [G loss: 0.856127]\n",
      "epoch:3 step:3372 [D loss: 0.698924, acc.: 49.22%] [G loss: 0.830052]\n",
      "epoch:3 step:3373 [D loss: 0.698861, acc.: 55.47%] [G loss: 0.803126]\n",
      "epoch:3 step:3374 [D loss: 0.735730, acc.: 46.88%] [G loss: 0.816184]\n",
      "epoch:3 step:3375 [D loss: 0.684074, acc.: 53.91%] [G loss: 0.803836]\n",
      "epoch:3 step:3376 [D loss: 0.689376, acc.: 52.34%] [G loss: 0.781127]\n",
      "epoch:3 step:3377 [D loss: 0.690586, acc.: 50.00%] [G loss: 0.833098]\n",
      "epoch:3 step:3378 [D loss: 0.654224, acc.: 62.50%] [G loss: 0.811369]\n",
      "epoch:3 step:3379 [D loss: 0.647794, acc.: 67.97%] [G loss: 0.812700]\n",
      "epoch:3 step:3380 [D loss: 0.736434, acc.: 44.53%] [G loss: 0.784793]\n",
      "epoch:3 step:3381 [D loss: 0.687904, acc.: 56.25%] [G loss: 0.764086]\n",
      "epoch:3 step:3382 [D loss: 0.690013, acc.: 53.12%] [G loss: 0.827898]\n",
      "epoch:3 step:3383 [D loss: 0.664458, acc.: 63.28%] [G loss: 0.811262]\n",
      "epoch:3 step:3384 [D loss: 0.666296, acc.: 55.47%] [G loss: 0.823053]\n",
      "epoch:3 step:3385 [D loss: 0.673682, acc.: 59.38%] [G loss: 0.773825]\n",
      "epoch:3 step:3386 [D loss: 0.632606, acc.: 62.50%] [G loss: 0.782707]\n",
      "epoch:3 step:3387 [D loss: 0.735974, acc.: 45.31%] [G loss: 0.796980]\n",
      "epoch:3 step:3388 [D loss: 0.710708, acc.: 43.75%] [G loss: 0.782810]\n",
      "epoch:3 step:3389 [D loss: 0.704031, acc.: 51.56%] [G loss: 0.750618]\n",
      "epoch:3 step:3390 [D loss: 0.691589, acc.: 53.12%] [G loss: 0.785677]\n",
      "epoch:3 step:3391 [D loss: 0.744509, acc.: 48.44%] [G loss: 0.771971]\n",
      "epoch:3 step:3392 [D loss: 0.695091, acc.: 56.25%] [G loss: 0.784676]\n",
      "epoch:3 step:3393 [D loss: 0.683115, acc.: 57.03%] [G loss: 0.834642]\n",
      "epoch:3 step:3394 [D loss: 0.742838, acc.: 46.09%] [G loss: 0.794960]\n",
      "epoch:3 step:3395 [D loss: 0.702744, acc.: 45.31%] [G loss: 0.780173]\n",
      "epoch:3 step:3396 [D loss: 0.661401, acc.: 55.47%] [G loss: 0.822095]\n",
      "epoch:3 step:3397 [D loss: 0.638592, acc.: 67.19%] [G loss: 0.859073]\n",
      "epoch:3 step:3398 [D loss: 0.677575, acc.: 58.59%] [G loss: 0.870111]\n",
      "epoch:3 step:3399 [D loss: 0.668773, acc.: 57.03%] [G loss: 0.842423]\n",
      "epoch:3 step:3400 [D loss: 0.678530, acc.: 54.69%] [G loss: 0.785840]\n",
      "##############\n",
      "[4.43272493 2.75937102 6.51101756 5.52371617 4.062642   6.32105775\n",
      " 4.94993833 5.4642312  5.6937159  4.94295534]\n",
      "##########\n",
      "epoch:3 step:3401 [D loss: 0.735484, acc.: 47.66%] [G loss: 0.758056]\n",
      "epoch:3 step:3402 [D loss: 0.735564, acc.: 44.53%] [G loss: 0.757035]\n",
      "epoch:3 step:3403 [D loss: 0.718165, acc.: 50.00%] [G loss: 0.761826]\n",
      "epoch:3 step:3404 [D loss: 0.689393, acc.: 46.88%] [G loss: 0.807935]\n",
      "epoch:3 step:3405 [D loss: 0.697714, acc.: 49.22%] [G loss: 0.781354]\n",
      "epoch:3 step:3406 [D loss: 0.675033, acc.: 53.91%] [G loss: 0.776828]\n",
      "epoch:3 step:3407 [D loss: 0.665633, acc.: 64.84%] [G loss: 0.805006]\n",
      "epoch:3 step:3408 [D loss: 0.676101, acc.: 56.25%] [G loss: 0.799266]\n",
      "epoch:3 step:3409 [D loss: 0.639491, acc.: 66.41%] [G loss: 0.859824]\n",
      "epoch:3 step:3410 [D loss: 0.656179, acc.: 58.59%] [G loss: 0.904706]\n",
      "epoch:3 step:3411 [D loss: 0.673494, acc.: 60.94%] [G loss: 0.870231]\n",
      "epoch:3 step:3412 [D loss: 0.675519, acc.: 58.59%] [G loss: 0.807541]\n",
      "epoch:3 step:3413 [D loss: 0.687237, acc.: 56.25%] [G loss: 0.863696]\n",
      "epoch:3 step:3414 [D loss: 0.674758, acc.: 60.16%] [G loss: 0.828235]\n",
      "epoch:3 step:3415 [D loss: 0.742769, acc.: 42.19%] [G loss: 0.768807]\n",
      "epoch:3 step:3416 [D loss: 0.698227, acc.: 50.78%] [G loss: 0.798511]\n",
      "epoch:3 step:3417 [D loss: 0.736280, acc.: 39.84%] [G loss: 0.765410]\n",
      "epoch:3 step:3418 [D loss: 0.739012, acc.: 39.84%] [G loss: 0.773453]\n",
      "epoch:3 step:3419 [D loss: 0.696593, acc.: 54.69%] [G loss: 0.809921]\n",
      "epoch:3 step:3420 [D loss: 0.709218, acc.: 53.12%] [G loss: 0.766419]\n",
      "epoch:3 step:3421 [D loss: 0.706170, acc.: 49.22%] [G loss: 0.794431]\n",
      "epoch:3 step:3422 [D loss: 0.685113, acc.: 55.47%] [G loss: 0.784015]\n",
      "epoch:3 step:3423 [D loss: 0.689082, acc.: 60.16%] [G loss: 0.795484]\n",
      "epoch:3 step:3424 [D loss: 0.727497, acc.: 42.19%] [G loss: 0.766772]\n",
      "epoch:3 step:3425 [D loss: 0.724231, acc.: 42.97%] [G loss: 0.754008]\n",
      "epoch:3 step:3426 [D loss: 0.707176, acc.: 50.00%] [G loss: 0.776870]\n",
      "epoch:3 step:3427 [D loss: 0.678825, acc.: 57.81%] [G loss: 0.776697]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:3 step:3428 [D loss: 0.694223, acc.: 57.81%] [G loss: 0.785022]\n",
      "epoch:3 step:3429 [D loss: 0.694270, acc.: 46.09%] [G loss: 0.791713]\n",
      "epoch:3 step:3430 [D loss: 0.685881, acc.: 50.00%] [G loss: 0.768473]\n",
      "epoch:3 step:3431 [D loss: 0.650500, acc.: 65.62%] [G loss: 0.755699]\n",
      "epoch:3 step:3432 [D loss: 0.677748, acc.: 58.59%] [G loss: 0.866065]\n",
      "epoch:3 step:3433 [D loss: 0.681329, acc.: 53.91%] [G loss: 0.783812]\n",
      "epoch:3 step:3434 [D loss: 0.675100, acc.: 58.59%] [G loss: 0.764976]\n",
      "epoch:3 step:3435 [D loss: 0.677431, acc.: 59.38%] [G loss: 0.810323]\n",
      "epoch:3 step:3436 [D loss: 0.744084, acc.: 43.75%] [G loss: 0.801929]\n",
      "epoch:3 step:3437 [D loss: 0.727255, acc.: 50.78%] [G loss: 0.759131]\n",
      "epoch:3 step:3438 [D loss: 0.695533, acc.: 55.47%] [G loss: 0.795903]\n",
      "epoch:3 step:3439 [D loss: 0.700212, acc.: 55.47%] [G loss: 0.802655]\n",
      "epoch:3 step:3440 [D loss: 0.681893, acc.: 53.12%] [G loss: 0.753856]\n",
      "epoch:3 step:3441 [D loss: 0.699637, acc.: 49.22%] [G loss: 0.787101]\n",
      "epoch:3 step:3442 [D loss: 0.703189, acc.: 51.56%] [G loss: 0.787924]\n",
      "epoch:3 step:3443 [D loss: 0.670266, acc.: 65.62%] [G loss: 0.818544]\n",
      "epoch:3 step:3444 [D loss: 0.707980, acc.: 55.47%] [G loss: 0.824811]\n",
      "epoch:3 step:3445 [D loss: 0.705091, acc.: 53.12%] [G loss: 0.816476]\n",
      "epoch:3 step:3446 [D loss: 0.682265, acc.: 57.03%] [G loss: 0.785416]\n",
      "epoch:3 step:3447 [D loss: 0.684645, acc.: 57.03%] [G loss: 0.780135]\n",
      "epoch:3 step:3448 [D loss: 0.701070, acc.: 49.22%] [G loss: 0.751626]\n",
      "epoch:3 step:3449 [D loss: 0.693546, acc.: 55.47%] [G loss: 0.749565]\n",
      "epoch:3 step:3450 [D loss: 0.695097, acc.: 52.34%] [G loss: 0.770947]\n",
      "epoch:3 step:3451 [D loss: 0.722692, acc.: 40.62%] [G loss: 0.718696]\n",
      "epoch:3 step:3452 [D loss: 0.705390, acc.: 48.44%] [G loss: 0.739865]\n",
      "epoch:3 step:3453 [D loss: 0.688457, acc.: 53.91%] [G loss: 0.719034]\n",
      "epoch:3 step:3454 [D loss: 0.683690, acc.: 53.91%] [G loss: 0.724145]\n",
      "epoch:3 step:3455 [D loss: 0.704265, acc.: 51.56%] [G loss: 0.757707]\n",
      "epoch:3 step:3456 [D loss: 0.708828, acc.: 47.66%] [G loss: 0.755561]\n",
      "epoch:3 step:3457 [D loss: 0.687108, acc.: 51.56%] [G loss: 0.754843]\n",
      "epoch:3 step:3458 [D loss: 0.677429, acc.: 57.03%] [G loss: 0.794755]\n",
      "epoch:3 step:3459 [D loss: 0.650272, acc.: 61.72%] [G loss: 0.784035]\n",
      "epoch:3 step:3460 [D loss: 0.666014, acc.: 56.25%] [G loss: 0.821266]\n",
      "epoch:3 step:3461 [D loss: 0.664507, acc.: 59.38%] [G loss: 0.776426]\n",
      "epoch:3 step:3462 [D loss: 0.680568, acc.: 51.56%] [G loss: 0.770838]\n",
      "epoch:3 step:3463 [D loss: 0.650317, acc.: 62.50%] [G loss: 0.813709]\n",
      "epoch:3 step:3464 [D loss: 0.683413, acc.: 53.91%] [G loss: 0.764974]\n",
      "epoch:3 step:3465 [D loss: 0.701375, acc.: 53.91%] [G loss: 0.763581]\n",
      "epoch:3 step:3466 [D loss: 0.717402, acc.: 50.00%] [G loss: 0.758513]\n",
      "epoch:3 step:3467 [D loss: 0.712656, acc.: 50.00%] [G loss: 0.783477]\n",
      "epoch:3 step:3468 [D loss: 0.734791, acc.: 36.72%] [G loss: 0.741470]\n",
      "epoch:3 step:3469 [D loss: 0.739552, acc.: 44.53%] [G loss: 0.726058]\n",
      "epoch:3 step:3470 [D loss: 0.680467, acc.: 53.12%] [G loss: 0.742530]\n",
      "epoch:3 step:3471 [D loss: 0.668938, acc.: 57.81%] [G loss: 0.786309]\n",
      "epoch:3 step:3472 [D loss: 0.654655, acc.: 62.50%] [G loss: 0.832519]\n",
      "epoch:3 step:3473 [D loss: 0.691970, acc.: 58.59%] [G loss: 0.813926]\n",
      "epoch:3 step:3474 [D loss: 0.709478, acc.: 47.66%] [G loss: 0.784831]\n",
      "epoch:3 step:3475 [D loss: 0.679636, acc.: 53.91%] [G loss: 0.790774]\n",
      "epoch:3 step:3476 [D loss: 0.690488, acc.: 49.22%] [G loss: 0.777346]\n",
      "epoch:3 step:3477 [D loss: 0.658256, acc.: 63.28%] [G loss: 0.781435]\n",
      "epoch:3 step:3478 [D loss: 0.659121, acc.: 61.72%] [G loss: 0.804541]\n",
      "epoch:3 step:3479 [D loss: 0.694372, acc.: 55.47%] [G loss: 0.766020]\n",
      "epoch:3 step:3480 [D loss: 0.705120, acc.: 50.00%] [G loss: 0.753468]\n",
      "epoch:3 step:3481 [D loss: 0.721627, acc.: 46.88%] [G loss: 0.793773]\n",
      "epoch:3 step:3482 [D loss: 0.734877, acc.: 40.62%] [G loss: 0.760312]\n",
      "epoch:3 step:3483 [D loss: 0.714217, acc.: 46.88%] [G loss: 0.739245]\n",
      "epoch:3 step:3484 [D loss: 0.729182, acc.: 42.19%] [G loss: 0.720315]\n",
      "epoch:3 step:3485 [D loss: 0.713045, acc.: 48.44%] [G loss: 0.721507]\n",
      "epoch:3 step:3486 [D loss: 0.695625, acc.: 52.34%] [G loss: 0.750987]\n",
      "epoch:3 step:3487 [D loss: 0.688192, acc.: 47.66%] [G loss: 0.740457]\n",
      "epoch:3 step:3488 [D loss: 0.682584, acc.: 60.16%] [G loss: 0.737234]\n",
      "epoch:3 step:3489 [D loss: 0.684761, acc.: 60.94%] [G loss: 0.793966]\n",
      "epoch:3 step:3490 [D loss: 0.679029, acc.: 56.25%] [G loss: 0.767034]\n",
      "epoch:3 step:3491 [D loss: 0.697517, acc.: 53.91%] [G loss: 0.730114]\n",
      "epoch:3 step:3492 [D loss: 0.662575, acc.: 57.81%] [G loss: 0.783405]\n",
      "epoch:3 step:3493 [D loss: 0.698714, acc.: 47.66%] [G loss: 0.733232]\n",
      "epoch:3 step:3494 [D loss: 0.682881, acc.: 54.69%] [G loss: 0.740804]\n",
      "epoch:3 step:3495 [D loss: 0.701403, acc.: 48.44%] [G loss: 0.748056]\n",
      "epoch:3 step:3496 [D loss: 0.671702, acc.: 59.38%] [G loss: 0.764344]\n",
      "epoch:3 step:3497 [D loss: 0.701028, acc.: 50.78%] [G loss: 0.738716]\n",
      "epoch:3 step:3498 [D loss: 0.694275, acc.: 52.34%] [G loss: 0.736487]\n",
      "epoch:3 step:3499 [D loss: 0.684831, acc.: 52.34%] [G loss: 0.751916]\n",
      "epoch:3 step:3500 [D loss: 0.694580, acc.: 53.12%] [G loss: 0.757907]\n",
      "epoch:3 step:3501 [D loss: 0.702008, acc.: 53.12%] [G loss: 0.780889]\n",
      "epoch:3 step:3502 [D loss: 0.702632, acc.: 48.44%] [G loss: 0.788844]\n",
      "epoch:3 step:3503 [D loss: 0.697862, acc.: 54.69%] [G loss: 0.747316]\n",
      "epoch:3 step:3504 [D loss: 0.683911, acc.: 57.81%] [G loss: 0.789871]\n",
      "epoch:3 step:3505 [D loss: 0.675900, acc.: 54.69%] [G loss: 0.766881]\n",
      "epoch:3 step:3506 [D loss: 0.699127, acc.: 47.66%] [G loss: 0.836712]\n",
      "epoch:3 step:3507 [D loss: 0.701480, acc.: 53.91%] [G loss: 0.776033]\n",
      "epoch:3 step:3508 [D loss: 0.690587, acc.: 52.34%] [G loss: 0.771736]\n",
      "epoch:3 step:3509 [D loss: 0.693857, acc.: 53.91%] [G loss: 0.831804]\n",
      "epoch:3 step:3510 [D loss: 0.723649, acc.: 44.53%] [G loss: 0.758334]\n",
      "epoch:3 step:3511 [D loss: 0.670709, acc.: 60.16%] [G loss: 0.831848]\n",
      "epoch:3 step:3512 [D loss: 0.685148, acc.: 57.81%] [G loss: 0.769379]\n",
      "epoch:3 step:3513 [D loss: 0.687406, acc.: 57.81%] [G loss: 0.794118]\n",
      "epoch:3 step:3514 [D loss: 0.681908, acc.: 53.12%] [G loss: 0.839711]\n",
      "epoch:3 step:3515 [D loss: 0.681927, acc.: 56.25%] [G loss: 0.803623]\n",
      "epoch:3 step:3516 [D loss: 0.667667, acc.: 53.91%] [G loss: 0.795672]\n",
      "epoch:3 step:3517 [D loss: 0.652947, acc.: 59.38%] [G loss: 0.825454]\n",
      "epoch:3 step:3518 [D loss: 0.650406, acc.: 61.72%] [G loss: 0.809540]\n",
      "epoch:3 step:3519 [D loss: 0.679721, acc.: 57.81%] [G loss: 0.785018]\n",
      "epoch:3 step:3520 [D loss: 0.702838, acc.: 51.56%] [G loss: 0.796145]\n",
      "epoch:3 step:3521 [D loss: 0.769860, acc.: 40.62%] [G loss: 0.744178]\n",
      "epoch:3 step:3522 [D loss: 0.711081, acc.: 47.66%] [G loss: 0.757084]\n",
      "epoch:3 step:3523 [D loss: 0.647462, acc.: 64.06%] [G loss: 0.792017]\n",
      "epoch:3 step:3524 [D loss: 0.668618, acc.: 62.50%] [G loss: 0.828246]\n",
      "epoch:3 step:3525 [D loss: 0.670090, acc.: 61.72%] [G loss: 0.766050]\n",
      "epoch:3 step:3526 [D loss: 0.732802, acc.: 51.56%] [G loss: 0.767712]\n",
      "epoch:3 step:3527 [D loss: 0.703444, acc.: 57.81%] [G loss: 0.765343]\n",
      "epoch:3 step:3528 [D loss: 0.693027, acc.: 50.00%] [G loss: 0.788292]\n",
      "epoch:3 step:3529 [D loss: 0.700681, acc.: 56.25%] [G loss: 0.762953]\n",
      "epoch:3 step:3530 [D loss: 0.667432, acc.: 52.34%] [G loss: 0.782121]\n",
      "epoch:3 step:3531 [D loss: 0.663788, acc.: 61.72%] [G loss: 0.795865]\n",
      "epoch:3 step:3532 [D loss: 0.680067, acc.: 55.47%] [G loss: 0.813869]\n",
      "epoch:3 step:3533 [D loss: 0.731990, acc.: 38.28%] [G loss: 0.807783]\n",
      "epoch:3 step:3534 [D loss: 0.699084, acc.: 51.56%] [G loss: 0.750821]\n",
      "epoch:3 step:3535 [D loss: 0.674000, acc.: 53.91%] [G loss: 0.814395]\n",
      "epoch:3 step:3536 [D loss: 0.669415, acc.: 56.25%] [G loss: 0.889409]\n",
      "epoch:3 step:3537 [D loss: 0.668458, acc.: 57.81%] [G loss: 0.907825]\n",
      "epoch:3 step:3538 [D loss: 0.699412, acc.: 52.34%] [G loss: 1.000030]\n",
      "epoch:3 step:3539 [D loss: 0.699299, acc.: 50.78%] [G loss: 0.887168]\n",
      "epoch:3 step:3540 [D loss: 0.671039, acc.: 57.81%] [G loss: 0.896597]\n",
      "epoch:3 step:3541 [D loss: 0.631820, acc.: 67.19%] [G loss: 0.852665]\n",
      "epoch:3 step:3542 [D loss: 0.669991, acc.: 63.28%] [G loss: 0.792701]\n",
      "epoch:3 step:3543 [D loss: 0.658910, acc.: 60.94%] [G loss: 0.898716]\n",
      "epoch:3 step:3544 [D loss: 0.687685, acc.: 54.69%] [G loss: 0.866140]\n",
      "epoch:3 step:3545 [D loss: 0.711465, acc.: 55.47%] [G loss: 0.795084]\n",
      "epoch:3 step:3546 [D loss: 0.767758, acc.: 46.09%] [G loss: 0.756916]\n",
      "epoch:3 step:3547 [D loss: 0.734084, acc.: 45.31%] [G loss: 0.807907]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:3 step:3548 [D loss: 0.656085, acc.: 53.12%] [G loss: 0.800981]\n",
      "epoch:3 step:3549 [D loss: 0.679133, acc.: 49.22%] [G loss: 0.784899]\n",
      "epoch:3 step:3550 [D loss: 0.646741, acc.: 56.25%] [G loss: 0.770460]\n",
      "epoch:3 step:3551 [D loss: 0.698250, acc.: 47.66%] [G loss: 0.828372]\n",
      "epoch:3 step:3552 [D loss: 0.711791, acc.: 43.75%] [G loss: 0.898015]\n",
      "epoch:3 step:3553 [D loss: 0.707636, acc.: 51.56%] [G loss: 0.804349]\n",
      "epoch:3 step:3554 [D loss: 0.705968, acc.: 48.44%] [G loss: 0.788817]\n",
      "epoch:3 step:3555 [D loss: 0.685742, acc.: 58.59%] [G loss: 0.770406]\n",
      "epoch:3 step:3556 [D loss: 0.718910, acc.: 44.53%] [G loss: 0.744328]\n",
      "epoch:3 step:3557 [D loss: 0.683085, acc.: 52.34%] [G loss: 0.791942]\n",
      "epoch:3 step:3558 [D loss: 0.668956, acc.: 59.38%] [G loss: 0.809896]\n",
      "epoch:3 step:3559 [D loss: 0.717166, acc.: 44.53%] [G loss: 0.829749]\n",
      "epoch:3 step:3560 [D loss: 0.700369, acc.: 48.44%] [G loss: 0.827620]\n",
      "epoch:3 step:3561 [D loss: 0.673483, acc.: 61.72%] [G loss: 0.784454]\n",
      "epoch:3 step:3562 [D loss: 0.680559, acc.: 57.03%] [G loss: 0.853116]\n",
      "epoch:3 step:3563 [D loss: 0.716385, acc.: 37.50%] [G loss: 0.827359]\n",
      "epoch:3 step:3564 [D loss: 0.669785, acc.: 53.12%] [G loss: 0.803410]\n",
      "epoch:3 step:3565 [D loss: 0.669416, acc.: 53.12%] [G loss: 0.816167]\n",
      "epoch:3 step:3566 [D loss: 0.684764, acc.: 53.12%] [G loss: 0.814170]\n",
      "epoch:3 step:3567 [D loss: 0.674770, acc.: 60.94%] [G loss: 0.786481]\n",
      "epoch:3 step:3568 [D loss: 0.700144, acc.: 47.66%] [G loss: 0.766031]\n",
      "epoch:3 step:3569 [D loss: 0.712511, acc.: 44.53%] [G loss: 0.784656]\n",
      "epoch:3 step:3570 [D loss: 0.698828, acc.: 54.69%] [G loss: 0.734736]\n",
      "epoch:3 step:3571 [D loss: 0.720350, acc.: 46.09%] [G loss: 0.714114]\n",
      "epoch:3 step:3572 [D loss: 0.692839, acc.: 50.00%] [G loss: 0.760451]\n",
      "epoch:3 step:3573 [D loss: 0.680343, acc.: 52.34%] [G loss: 0.746620]\n",
      "epoch:3 step:3574 [D loss: 0.689055, acc.: 56.25%] [G loss: 0.797090]\n",
      "epoch:3 step:3575 [D loss: 0.696259, acc.: 48.44%] [G loss: 0.729955]\n",
      "epoch:3 step:3576 [D loss: 0.714430, acc.: 36.72%] [G loss: 0.784603]\n",
      "epoch:3 step:3577 [D loss: 0.713318, acc.: 50.00%] [G loss: 0.792115]\n",
      "epoch:3 step:3578 [D loss: 0.704848, acc.: 47.66%] [G loss: 0.798711]\n",
      "epoch:3 step:3579 [D loss: 0.668194, acc.: 61.72%] [G loss: 0.779871]\n",
      "epoch:3 step:3580 [D loss: 0.686779, acc.: 50.00%] [G loss: 0.797321]\n",
      "epoch:3 step:3581 [D loss: 0.671688, acc.: 56.25%] [G loss: 0.802340]\n",
      "epoch:3 step:3582 [D loss: 0.660695, acc.: 59.38%] [G loss: 0.854047]\n",
      "epoch:3 step:3583 [D loss: 0.684804, acc.: 54.69%] [G loss: 0.805232]\n",
      "epoch:3 step:3584 [D loss: 0.677094, acc.: 52.34%] [G loss: 0.761257]\n",
      "epoch:3 step:3585 [D loss: 0.666931, acc.: 51.56%] [G loss: 0.812513]\n",
      "epoch:3 step:3586 [D loss: 0.677637, acc.: 60.16%] [G loss: 0.796719]\n",
      "epoch:3 step:3587 [D loss: 0.690120, acc.: 54.69%] [G loss: 0.776503]\n",
      "epoch:3 step:3588 [D loss: 0.708533, acc.: 45.31%] [G loss: 0.760038]\n",
      "epoch:3 step:3589 [D loss: 0.695362, acc.: 47.66%] [G loss: 0.787128]\n",
      "epoch:3 step:3590 [D loss: 0.713282, acc.: 46.88%] [G loss: 0.717824]\n",
      "epoch:3 step:3591 [D loss: 0.677016, acc.: 53.91%] [G loss: 0.741301]\n",
      "epoch:3 step:3592 [D loss: 0.687238, acc.: 58.59%] [G loss: 0.774137]\n",
      "epoch:3 step:3593 [D loss: 0.691899, acc.: 54.69%] [G loss: 0.797570]\n",
      "epoch:3 step:3594 [D loss: 0.721594, acc.: 49.22%] [G loss: 0.789444]\n",
      "epoch:3 step:3595 [D loss: 0.702603, acc.: 49.22%] [G loss: 0.845979]\n",
      "epoch:3 step:3596 [D loss: 0.657453, acc.: 65.62%] [G loss: 0.850987]\n",
      "epoch:3 step:3597 [D loss: 0.666589, acc.: 57.81%] [G loss: 0.863575]\n",
      "epoch:3 step:3598 [D loss: 0.670025, acc.: 60.16%] [G loss: 0.878186]\n",
      "epoch:3 step:3599 [D loss: 0.658474, acc.: 57.81%] [G loss: 0.834332]\n",
      "epoch:3 step:3600 [D loss: 0.669758, acc.: 57.81%] [G loss: 0.878204]\n",
      "##############\n",
      "[3.77839709 2.53022803 6.17931807 5.42075183 4.09862859 5.85502756\n",
      " 4.84711761 5.49893478 5.36286969 4.63995507]\n",
      "##########\n",
      "epoch:3 step:3601 [D loss: 0.658761, acc.: 61.72%] [G loss: 0.813056]\n",
      "epoch:3 step:3602 [D loss: 0.702743, acc.: 47.66%] [G loss: 0.752814]\n",
      "epoch:3 step:3603 [D loss: 0.671387, acc.: 55.47%] [G loss: 0.787382]\n",
      "epoch:3 step:3604 [D loss: 0.661653, acc.: 61.72%] [G loss: 0.818922]\n",
      "epoch:3 step:3605 [D loss: 0.689532, acc.: 55.47%] [G loss: 0.801110]\n",
      "epoch:3 step:3606 [D loss: 0.716789, acc.: 52.34%] [G loss: 0.743188]\n",
      "epoch:3 step:3607 [D loss: 0.698124, acc.: 53.12%] [G loss: 0.765817]\n",
      "epoch:3 step:3608 [D loss: 0.766114, acc.: 39.06%] [G loss: 0.760520]\n",
      "epoch:3 step:3609 [D loss: 0.732324, acc.: 40.62%] [G loss: 0.768128]\n",
      "epoch:3 step:3610 [D loss: 0.701546, acc.: 46.88%] [G loss: 0.770102]\n",
      "epoch:3 step:3611 [D loss: 0.728422, acc.: 42.97%] [G loss: 0.763493]\n",
      "epoch:3 step:3612 [D loss: 0.707506, acc.: 51.56%] [G loss: 0.814147]\n",
      "epoch:3 step:3613 [D loss: 0.626303, acc.: 71.09%] [G loss: 0.837104]\n",
      "epoch:3 step:3614 [D loss: 0.682010, acc.: 60.16%] [G loss: 0.808349]\n",
      "epoch:3 step:3615 [D loss: 0.703958, acc.: 51.56%] [G loss: 0.803554]\n",
      "epoch:3 step:3616 [D loss: 0.671414, acc.: 56.25%] [G loss: 0.898950]\n",
      "epoch:3 step:3617 [D loss: 0.666182, acc.: 55.47%] [G loss: 0.802449]\n",
      "epoch:3 step:3618 [D loss: 0.663882, acc.: 59.38%] [G loss: 0.786801]\n",
      "epoch:3 step:3619 [D loss: 0.658118, acc.: 63.28%] [G loss: 0.773679]\n",
      "epoch:3 step:3620 [D loss: 0.690017, acc.: 51.56%] [G loss: 0.760883]\n",
      "epoch:3 step:3621 [D loss: 0.696814, acc.: 51.56%] [G loss: 0.785551]\n",
      "epoch:3 step:3622 [D loss: 0.680816, acc.: 54.69%] [G loss: 0.761512]\n",
      "epoch:3 step:3623 [D loss: 0.725066, acc.: 44.53%] [G loss: 0.816766]\n",
      "epoch:3 step:3624 [D loss: 0.683757, acc.: 54.69%] [G loss: 0.830991]\n",
      "epoch:3 step:3625 [D loss: 0.702010, acc.: 45.31%] [G loss: 0.801842]\n",
      "epoch:3 step:3626 [D loss: 0.689248, acc.: 55.47%] [G loss: 0.749083]\n",
      "epoch:3 step:3627 [D loss: 0.694747, acc.: 50.00%] [G loss: 0.788201]\n",
      "epoch:3 step:3628 [D loss: 0.695073, acc.: 52.34%] [G loss: 0.815078]\n",
      "epoch:3 step:3629 [D loss: 0.749272, acc.: 48.44%] [G loss: 0.789027]\n",
      "epoch:3 step:3630 [D loss: 0.715331, acc.: 42.97%] [G loss: 0.749210]\n",
      "epoch:3 step:3631 [D loss: 0.694685, acc.: 55.47%] [G loss: 0.820273]\n",
      "epoch:3 step:3632 [D loss: 0.655942, acc.: 64.84%] [G loss: 0.825639]\n",
      "epoch:3 step:3633 [D loss: 0.669958, acc.: 62.50%] [G loss: 0.816693]\n",
      "epoch:3 step:3634 [D loss: 0.663697, acc.: 59.38%] [G loss: 0.856699]\n",
      "epoch:3 step:3635 [D loss: 0.698215, acc.: 53.91%] [G loss: 0.777317]\n",
      "epoch:3 step:3636 [D loss: 0.706364, acc.: 47.66%] [G loss: 0.767335]\n",
      "epoch:3 step:3637 [D loss: 0.665399, acc.: 59.38%] [G loss: 0.770003]\n",
      "epoch:3 step:3638 [D loss: 0.704460, acc.: 50.00%] [G loss: 0.809491]\n",
      "epoch:3 step:3639 [D loss: 0.705119, acc.: 50.78%] [G loss: 0.794052]\n",
      "epoch:3 step:3640 [D loss: 0.700196, acc.: 51.56%] [G loss: 0.743737]\n",
      "epoch:3 step:3641 [D loss: 0.690942, acc.: 52.34%] [G loss: 0.739404]\n",
      "epoch:3 step:3642 [D loss: 0.702912, acc.: 55.47%] [G loss: 0.760552]\n",
      "epoch:3 step:3643 [D loss: 0.712332, acc.: 52.34%] [G loss: 0.768799]\n",
      "epoch:3 step:3644 [D loss: 0.713543, acc.: 44.53%] [G loss: 0.725770]\n",
      "epoch:3 step:3645 [D loss: 0.711187, acc.: 45.31%] [G loss: 0.778024]\n",
      "epoch:3 step:3646 [D loss: 0.697410, acc.: 51.56%] [G loss: 0.761591]\n",
      "epoch:3 step:3647 [D loss: 0.681030, acc.: 53.12%] [G loss: 0.803000]\n",
      "epoch:3 step:3648 [D loss: 0.657626, acc.: 61.72%] [G loss: 0.791310]\n",
      "epoch:3 step:3649 [D loss: 0.655416, acc.: 64.06%] [G loss: 0.847578]\n",
      "epoch:3 step:3650 [D loss: 0.684390, acc.: 55.47%] [G loss: 0.807814]\n",
      "epoch:3 step:3651 [D loss: 0.674146, acc.: 54.69%] [G loss: 0.799725]\n",
      "epoch:3 step:3652 [D loss: 0.690280, acc.: 55.47%] [G loss: 0.813872]\n",
      "epoch:3 step:3653 [D loss: 0.657100, acc.: 59.38%] [G loss: 0.806719]\n",
      "epoch:3 step:3654 [D loss: 0.741382, acc.: 51.56%] [G loss: 0.758535]\n",
      "epoch:3 step:3655 [D loss: 0.712345, acc.: 49.22%] [G loss: 0.769901]\n",
      "epoch:3 step:3656 [D loss: 0.718677, acc.: 45.31%] [G loss: 0.781335]\n",
      "epoch:3 step:3657 [D loss: 0.707732, acc.: 47.66%] [G loss: 0.757637]\n",
      "epoch:3 step:3658 [D loss: 0.709316, acc.: 42.19%] [G loss: 0.788497]\n",
      "epoch:3 step:3659 [D loss: 0.720732, acc.: 46.88%] [G loss: 0.760085]\n",
      "epoch:3 step:3660 [D loss: 0.700975, acc.: 50.78%] [G loss: 0.785839]\n",
      "epoch:3 step:3661 [D loss: 0.693870, acc.: 51.56%] [G loss: 0.789569]\n",
      "epoch:3 step:3662 [D loss: 0.661400, acc.: 54.69%] [G loss: 0.837514]\n",
      "epoch:3 step:3663 [D loss: 0.638375, acc.: 66.41%] [G loss: 0.850678]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:3 step:3664 [D loss: 0.634552, acc.: 67.97%] [G loss: 0.898410]\n",
      "epoch:3 step:3665 [D loss: 0.620958, acc.: 68.75%] [G loss: 0.908066]\n",
      "epoch:3 step:3666 [D loss: 0.652939, acc.: 62.50%] [G loss: 0.864692]\n",
      "epoch:3 step:3667 [D loss: 0.682769, acc.: 53.12%] [G loss: 0.866047]\n",
      "epoch:3 step:3668 [D loss: 0.657506, acc.: 59.38%] [G loss: 0.850356]\n",
      "epoch:3 step:3669 [D loss: 0.746900, acc.: 46.88%] [G loss: 0.821989]\n",
      "epoch:3 step:3670 [D loss: 0.781851, acc.: 33.59%] [G loss: 0.759584]\n",
      "epoch:3 step:3671 [D loss: 0.712723, acc.: 50.00%] [G loss: 0.750437]\n",
      "epoch:3 step:3672 [D loss: 0.753791, acc.: 36.72%] [G loss: 0.708060]\n",
      "epoch:3 step:3673 [D loss: 0.743245, acc.: 36.72%] [G loss: 0.695480]\n",
      "epoch:3 step:3674 [D loss: 0.706429, acc.: 45.31%] [G loss: 0.709663]\n",
      "epoch:3 step:3675 [D loss: 0.716995, acc.: 46.09%] [G loss: 0.750673]\n",
      "epoch:3 step:3676 [D loss: 0.723743, acc.: 45.31%] [G loss: 0.776135]\n",
      "epoch:3 step:3677 [D loss: 0.662486, acc.: 64.06%] [G loss: 0.794521]\n",
      "epoch:3 step:3678 [D loss: 0.681479, acc.: 57.81%] [G loss: 0.775724]\n",
      "epoch:3 step:3679 [D loss: 0.705055, acc.: 47.66%] [G loss: 0.777821]\n",
      "epoch:3 step:3680 [D loss: 0.680138, acc.: 59.38%] [G loss: 0.786037]\n",
      "epoch:3 step:3681 [D loss: 0.685419, acc.: 53.91%] [G loss: 0.795975]\n",
      "epoch:3 step:3682 [D loss: 0.683283, acc.: 51.56%] [G loss: 0.759235]\n",
      "epoch:3 step:3683 [D loss: 0.695381, acc.: 52.34%] [G loss: 0.782871]\n",
      "epoch:3 step:3684 [D loss: 0.687348, acc.: 54.69%] [G loss: 0.756025]\n",
      "epoch:3 step:3685 [D loss: 0.667489, acc.: 53.91%] [G loss: 0.747413]\n",
      "epoch:3 step:3686 [D loss: 0.654324, acc.: 60.94%] [G loss: 0.718982]\n",
      "epoch:3 step:3687 [D loss: 0.707251, acc.: 51.56%] [G loss: 0.767314]\n",
      "epoch:3 step:3688 [D loss: 0.697450, acc.: 49.22%] [G loss: 0.723310]\n",
      "epoch:3 step:3689 [D loss: 0.692890, acc.: 58.59%] [G loss: 0.767131]\n",
      "epoch:3 step:3690 [D loss: 0.671878, acc.: 60.16%] [G loss: 0.823193]\n",
      "epoch:3 step:3691 [D loss: 0.717169, acc.: 43.75%] [G loss: 0.727274]\n",
      "epoch:3 step:3692 [D loss: 0.699668, acc.: 51.56%] [G loss: 0.765590]\n",
      "epoch:3 step:3693 [D loss: 0.669086, acc.: 61.72%] [G loss: 0.742579]\n",
      "epoch:3 step:3694 [D loss: 0.696517, acc.: 45.31%] [G loss: 0.840135]\n",
      "epoch:3 step:3695 [D loss: 0.696243, acc.: 45.31%] [G loss: 0.767364]\n",
      "epoch:3 step:3696 [D loss: 0.669761, acc.: 60.16%] [G loss: 0.802479]\n",
      "epoch:3 step:3697 [D loss: 0.658712, acc.: 60.94%] [G loss: 0.860422]\n",
      "epoch:3 step:3698 [D loss: 0.663322, acc.: 60.16%] [G loss: 0.769631]\n",
      "epoch:3 step:3699 [D loss: 0.664091, acc.: 53.12%] [G loss: 0.799110]\n",
      "epoch:3 step:3700 [D loss: 0.674203, acc.: 56.25%] [G loss: 0.803947]\n",
      "epoch:3 step:3701 [D loss: 0.652413, acc.: 65.62%] [G loss: 0.817686]\n",
      "epoch:3 step:3702 [D loss: 0.727328, acc.: 50.00%] [G loss: 0.826239]\n",
      "epoch:3 step:3703 [D loss: 0.751502, acc.: 43.75%] [G loss: 0.743765]\n",
      "epoch:3 step:3704 [D loss: 0.715077, acc.: 43.75%] [G loss: 0.769448]\n",
      "epoch:3 step:3705 [D loss: 0.698305, acc.: 50.00%] [G loss: 0.716603]\n",
      "epoch:3 step:3706 [D loss: 0.702208, acc.: 47.66%] [G loss: 0.770796]\n",
      "epoch:3 step:3707 [D loss: 0.738828, acc.: 43.75%] [G loss: 0.732604]\n",
      "epoch:3 step:3708 [D loss: 0.728078, acc.: 49.22%] [G loss: 0.796855]\n",
      "epoch:3 step:3709 [D loss: 0.689688, acc.: 50.78%] [G loss: 0.790814]\n",
      "epoch:3 step:3710 [D loss: 0.673120, acc.: 56.25%] [G loss: 0.876008]\n",
      "epoch:3 step:3711 [D loss: 0.674160, acc.: 54.69%] [G loss: 0.799472]\n",
      "epoch:3 step:3712 [D loss: 0.682833, acc.: 51.56%] [G loss: 0.830039]\n",
      "epoch:3 step:3713 [D loss: 0.668443, acc.: 59.38%] [G loss: 0.800740]\n",
      "epoch:3 step:3714 [D loss: 0.656180, acc.: 59.38%] [G loss: 0.843906]\n",
      "epoch:3 step:3715 [D loss: 0.723612, acc.: 42.19%] [G loss: 0.822736]\n",
      "epoch:3 step:3716 [D loss: 0.681042, acc.: 53.91%] [G loss: 0.765300]\n",
      "epoch:3 step:3717 [D loss: 0.701758, acc.: 44.53%] [G loss: 0.802346]\n",
      "epoch:3 step:3718 [D loss: 0.713074, acc.: 47.66%] [G loss: 0.741596]\n",
      "epoch:3 step:3719 [D loss: 0.703225, acc.: 52.34%] [G loss: 0.730373]\n",
      "epoch:3 step:3720 [D loss: 0.701818, acc.: 45.31%] [G loss: 0.763262]\n",
      "epoch:3 step:3721 [D loss: 0.670794, acc.: 59.38%] [G loss: 0.742785]\n",
      "epoch:3 step:3722 [D loss: 0.677359, acc.: 62.50%] [G loss: 0.752918]\n",
      "epoch:3 step:3723 [D loss: 0.699032, acc.: 58.59%] [G loss: 0.750093]\n",
      "epoch:3 step:3724 [D loss: 0.685881, acc.: 53.12%] [G loss: 0.761257]\n",
      "epoch:3 step:3725 [D loss: 0.636595, acc.: 62.50%] [G loss: 0.858327]\n",
      "epoch:3 step:3726 [D loss: 0.674841, acc.: 53.12%] [G loss: 0.838125]\n",
      "epoch:3 step:3727 [D loss: 0.700676, acc.: 46.88%] [G loss: 0.795689]\n",
      "epoch:3 step:3728 [D loss: 0.719010, acc.: 46.09%] [G loss: 0.839128]\n",
      "epoch:3 step:3729 [D loss: 0.682615, acc.: 57.81%] [G loss: 0.755717]\n",
      "epoch:3 step:3730 [D loss: 0.681345, acc.: 63.28%] [G loss: 0.739185]\n",
      "epoch:3 step:3731 [D loss: 0.815006, acc.: 30.47%] [G loss: 0.748682]\n",
      "epoch:3 step:3732 [D loss: 0.715376, acc.: 49.22%] [G loss: 0.749544]\n",
      "epoch:3 step:3733 [D loss: 0.671573, acc.: 62.50%] [G loss: 0.792311]\n",
      "epoch:3 step:3734 [D loss: 0.662137, acc.: 64.84%] [G loss: 0.781182]\n",
      "epoch:3 step:3735 [D loss: 0.668925, acc.: 64.06%] [G loss: 0.762528]\n",
      "epoch:3 step:3736 [D loss: 0.671701, acc.: 64.06%] [G loss: 0.757047]\n",
      "epoch:3 step:3737 [D loss: 0.666260, acc.: 63.28%] [G loss: 0.776965]\n",
      "epoch:3 step:3738 [D loss: 0.644377, acc.: 64.06%] [G loss: 0.753523]\n",
      "epoch:3 step:3739 [D loss: 0.698565, acc.: 50.78%] [G loss: 0.883372]\n",
      "epoch:3 step:3740 [D loss: 0.712695, acc.: 46.09%] [G loss: 0.810165]\n",
      "epoch:3 step:3741 [D loss: 0.639041, acc.: 65.62%] [G loss: 0.855152]\n",
      "epoch:3 step:3742 [D loss: 0.653666, acc.: 60.94%] [G loss: 0.768316]\n",
      "epoch:3 step:3743 [D loss: 0.700010, acc.: 52.34%] [G loss: 0.797833]\n",
      "epoch:3 step:3744 [D loss: 0.717892, acc.: 51.56%] [G loss: 0.772263]\n",
      "epoch:3 step:3745 [D loss: 0.729630, acc.: 39.84%] [G loss: 0.760711]\n",
      "epoch:3 step:3746 [D loss: 0.693449, acc.: 51.56%] [G loss: 0.762813]\n",
      "epoch:3 step:3747 [D loss: 0.641738, acc.: 66.41%] [G loss: 0.763627]\n",
      "epoch:3 step:3748 [D loss: 0.682340, acc.: 60.16%] [G loss: 0.774777]\n",
      "epoch:4 step:3749 [D loss: 0.716412, acc.: 57.03%] [G loss: 0.698364]\n",
      "epoch:4 step:3750 [D loss: 0.752977, acc.: 49.22%] [G loss: 0.730310]\n",
      "epoch:4 step:3751 [D loss: 0.711254, acc.: 46.09%] [G loss: 0.754862]\n",
      "epoch:4 step:3752 [D loss: 0.724683, acc.: 46.88%] [G loss: 0.749558]\n",
      "epoch:4 step:3753 [D loss: 0.660397, acc.: 65.62%] [G loss: 0.798891]\n",
      "epoch:4 step:3754 [D loss: 0.682329, acc.: 57.03%] [G loss: 0.820805]\n",
      "epoch:4 step:3755 [D loss: 0.671652, acc.: 58.59%] [G loss: 0.798929]\n",
      "epoch:4 step:3756 [D loss: 0.650262, acc.: 63.28%] [G loss: 0.815921]\n",
      "epoch:4 step:3757 [D loss: 0.661427, acc.: 64.06%] [G loss: 0.840352]\n",
      "epoch:4 step:3758 [D loss: 0.676017, acc.: 60.16%] [G loss: 0.829233]\n",
      "epoch:4 step:3759 [D loss: 0.681136, acc.: 56.25%] [G loss: 0.778916]\n",
      "epoch:4 step:3760 [D loss: 0.716099, acc.: 45.31%] [G loss: 0.806408]\n",
      "epoch:4 step:3761 [D loss: 0.663943, acc.: 60.94%] [G loss: 0.799418]\n",
      "epoch:4 step:3762 [D loss: 0.694536, acc.: 59.38%] [G loss: 0.805267]\n",
      "epoch:4 step:3763 [D loss: 0.676481, acc.: 54.69%] [G loss: 0.827799]\n",
      "epoch:4 step:3764 [D loss: 0.694665, acc.: 56.25%] [G loss: 0.799491]\n",
      "epoch:4 step:3765 [D loss: 0.736459, acc.: 47.66%] [G loss: 0.778770]\n",
      "epoch:4 step:3766 [D loss: 0.679668, acc.: 53.12%] [G loss: 0.789851]\n",
      "epoch:4 step:3767 [D loss: 0.712314, acc.: 44.53%] [G loss: 0.828818]\n",
      "epoch:4 step:3768 [D loss: 0.685246, acc.: 55.47%] [G loss: 0.833843]\n",
      "epoch:4 step:3769 [D loss: 0.679286, acc.: 57.03%] [G loss: 0.911838]\n",
      "epoch:4 step:3770 [D loss: 0.621686, acc.: 72.66%] [G loss: 0.885033]\n",
      "epoch:4 step:3771 [D loss: 0.723714, acc.: 50.00%] [G loss: 0.926302]\n",
      "epoch:4 step:3772 [D loss: 0.731762, acc.: 46.09%] [G loss: 0.895674]\n",
      "epoch:4 step:3773 [D loss: 0.667794, acc.: 60.94%] [G loss: 0.822378]\n",
      "epoch:4 step:3774 [D loss: 0.721252, acc.: 51.56%] [G loss: 0.820859]\n",
      "epoch:4 step:3775 [D loss: 0.724617, acc.: 42.19%] [G loss: 0.792607]\n",
      "epoch:4 step:3776 [D loss: 0.738780, acc.: 39.84%] [G loss: 0.793849]\n",
      "epoch:4 step:3777 [D loss: 0.709920, acc.: 52.34%] [G loss: 0.753798]\n",
      "epoch:4 step:3778 [D loss: 0.693594, acc.: 55.47%] [G loss: 0.768744]\n",
      "epoch:4 step:3779 [D loss: 0.675875, acc.: 53.91%] [G loss: 0.779406]\n",
      "epoch:4 step:3780 [D loss: 0.688159, acc.: 55.47%] [G loss: 0.775224]\n",
      "epoch:4 step:3781 [D loss: 0.696441, acc.: 54.69%] [G loss: 0.817245]\n",
      "epoch:4 step:3782 [D loss: 0.672578, acc.: 59.38%] [G loss: 0.777457]\n",
      "epoch:4 step:3783 [D loss: 0.661673, acc.: 60.94%] [G loss: 0.819096]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:4 step:3784 [D loss: 0.625575, acc.: 70.31%] [G loss: 0.847094]\n",
      "epoch:4 step:3785 [D loss: 0.665700, acc.: 58.59%] [G loss: 0.814975]\n",
      "epoch:4 step:3786 [D loss: 0.671769, acc.: 58.59%] [G loss: 0.825935]\n",
      "epoch:4 step:3787 [D loss: 0.728991, acc.: 44.53%] [G loss: 0.784517]\n",
      "epoch:4 step:3788 [D loss: 0.690193, acc.: 53.91%] [G loss: 0.785839]\n",
      "epoch:4 step:3789 [D loss: 0.688417, acc.: 52.34%] [G loss: 0.811568]\n",
      "epoch:4 step:3790 [D loss: 0.717319, acc.: 46.09%] [G loss: 0.789206]\n",
      "epoch:4 step:3791 [D loss: 0.688581, acc.: 50.00%] [G loss: 0.817632]\n",
      "epoch:4 step:3792 [D loss: 0.714849, acc.: 40.62%] [G loss: 0.766669]\n",
      "epoch:4 step:3793 [D loss: 0.665850, acc.: 63.28%] [G loss: 0.811906]\n",
      "epoch:4 step:3794 [D loss: 0.692329, acc.: 53.91%] [G loss: 0.845802]\n",
      "epoch:4 step:3795 [D loss: 0.657817, acc.: 59.38%] [G loss: 0.886437]\n",
      "epoch:4 step:3796 [D loss: 0.652709, acc.: 59.38%] [G loss: 0.815804]\n",
      "epoch:4 step:3797 [D loss: 0.674040, acc.: 54.69%] [G loss: 0.861160]\n",
      "epoch:4 step:3798 [D loss: 0.686220, acc.: 53.12%] [G loss: 0.764267]\n",
      "epoch:4 step:3799 [D loss: 0.727714, acc.: 47.66%] [G loss: 0.786768]\n",
      "epoch:4 step:3800 [D loss: 0.722751, acc.: 43.75%] [G loss: 0.711197]\n",
      "##############\n",
      "[3.92957591 2.08020531 6.45820093 5.71756719 4.17201796 5.86734938\n",
      " 5.16411782 5.35620813 5.61835745 4.84279712]\n",
      "##########\n",
      "epoch:4 step:3801 [D loss: 0.706634, acc.: 50.00%] [G loss: 0.739074]\n",
      "epoch:4 step:3802 [D loss: 0.715086, acc.: 39.06%] [G loss: 0.734229]\n",
      "epoch:4 step:3803 [D loss: 0.709565, acc.: 48.44%] [G loss: 0.695693]\n",
      "epoch:4 step:3804 [D loss: 0.706084, acc.: 49.22%] [G loss: 0.754844]\n",
      "epoch:4 step:3805 [D loss: 0.703469, acc.: 46.09%] [G loss: 0.773417]\n",
      "epoch:4 step:3806 [D loss: 0.673187, acc.: 53.91%] [G loss: 0.740557]\n",
      "epoch:4 step:3807 [D loss: 0.709256, acc.: 48.44%] [G loss: 0.766465]\n",
      "epoch:4 step:3808 [D loss: 0.685218, acc.: 54.69%] [G loss: 0.772135]\n",
      "epoch:4 step:3809 [D loss: 0.699625, acc.: 53.91%] [G loss: 0.790376]\n",
      "epoch:4 step:3810 [D loss: 0.669946, acc.: 60.16%] [G loss: 0.781504]\n",
      "epoch:4 step:3811 [D loss: 0.644395, acc.: 70.31%] [G loss: 0.738526]\n",
      "epoch:4 step:3812 [D loss: 0.695269, acc.: 50.78%] [G loss: 0.739825]\n",
      "epoch:4 step:3813 [D loss: 0.713518, acc.: 46.09%] [G loss: 0.729190]\n",
      "epoch:4 step:3814 [D loss: 0.681540, acc.: 57.81%] [G loss: 0.759738]\n",
      "epoch:4 step:3815 [D loss: 0.695731, acc.: 53.91%] [G loss: 0.697566]\n",
      "epoch:4 step:3816 [D loss: 0.692538, acc.: 48.44%] [G loss: 0.714871]\n",
      "epoch:4 step:3817 [D loss: 0.680986, acc.: 51.56%] [G loss: 0.722558]\n",
      "epoch:4 step:3818 [D loss: 0.701117, acc.: 58.59%] [G loss: 0.743488]\n",
      "epoch:4 step:3819 [D loss: 0.708195, acc.: 40.62%] [G loss: 0.717760]\n",
      "epoch:4 step:3820 [D loss: 0.674773, acc.: 54.69%] [G loss: 0.772387]\n",
      "epoch:4 step:3821 [D loss: 0.687684, acc.: 50.78%] [G loss: 0.771913]\n",
      "epoch:4 step:3822 [D loss: 0.678609, acc.: 54.69%] [G loss: 0.750421]\n",
      "epoch:4 step:3823 [D loss: 0.684222, acc.: 51.56%] [G loss: 0.737006]\n",
      "epoch:4 step:3824 [D loss: 0.660976, acc.: 58.59%] [G loss: 0.741691]\n",
      "epoch:4 step:3825 [D loss: 0.671785, acc.: 56.25%] [G loss: 0.757918]\n",
      "epoch:4 step:3826 [D loss: 0.675291, acc.: 57.03%] [G loss: 0.834453]\n",
      "epoch:4 step:3827 [D loss: 0.694896, acc.: 50.00%] [G loss: 0.790197]\n",
      "epoch:4 step:3828 [D loss: 0.661798, acc.: 56.25%] [G loss: 0.800644]\n",
      "epoch:4 step:3829 [D loss: 0.699995, acc.: 51.56%] [G loss: 0.753416]\n",
      "epoch:4 step:3830 [D loss: 0.710408, acc.: 48.44%] [G loss: 0.745087]\n",
      "epoch:4 step:3831 [D loss: 0.695557, acc.: 49.22%] [G loss: 0.760847]\n",
      "epoch:4 step:3832 [D loss: 0.700336, acc.: 52.34%] [G loss: 0.765401]\n",
      "epoch:4 step:3833 [D loss: 0.692387, acc.: 48.44%] [G loss: 0.685324]\n",
      "epoch:4 step:3834 [D loss: 0.693447, acc.: 54.69%] [G loss: 0.744336]\n",
      "epoch:4 step:3835 [D loss: 0.703148, acc.: 46.88%] [G loss: 0.721640]\n",
      "epoch:4 step:3836 [D loss: 0.673817, acc.: 55.47%] [G loss: 0.729789]\n",
      "epoch:4 step:3837 [D loss: 0.659745, acc.: 57.81%] [G loss: 0.810847]\n",
      "epoch:4 step:3838 [D loss: 0.677395, acc.: 57.81%] [G loss: 0.796888]\n",
      "epoch:4 step:3839 [D loss: 0.652327, acc.: 61.72%] [G loss: 0.773561]\n",
      "epoch:4 step:3840 [D loss: 0.634628, acc.: 64.84%] [G loss: 0.861286]\n",
      "epoch:4 step:3841 [D loss: 0.621977, acc.: 65.62%] [G loss: 0.774004]\n",
      "epoch:4 step:3842 [D loss: 0.711994, acc.: 52.34%] [G loss: 0.780519]\n",
      "epoch:4 step:3843 [D loss: 0.737496, acc.: 44.53%] [G loss: 0.737523]\n",
      "epoch:4 step:3844 [D loss: 0.715732, acc.: 51.56%] [G loss: 0.768952]\n",
      "epoch:4 step:3845 [D loss: 0.701242, acc.: 53.12%] [G loss: 0.781802]\n",
      "epoch:4 step:3846 [D loss: 0.735067, acc.: 42.19%] [G loss: 0.704947]\n",
      "epoch:4 step:3847 [D loss: 0.704941, acc.: 44.53%] [G loss: 0.717824]\n",
      "epoch:4 step:3848 [D loss: 0.693103, acc.: 50.78%] [G loss: 0.727919]\n",
      "epoch:4 step:3849 [D loss: 0.695418, acc.: 46.88%] [G loss: 0.745085]\n",
      "epoch:4 step:3850 [D loss: 0.700234, acc.: 45.31%] [G loss: 0.732505]\n",
      "epoch:4 step:3851 [D loss: 0.708622, acc.: 43.75%] [G loss: 0.798844]\n",
      "epoch:4 step:3852 [D loss: 0.682927, acc.: 61.72%] [G loss: 0.763080]\n",
      "epoch:4 step:3853 [D loss: 0.685249, acc.: 55.47%] [G loss: 0.795656]\n",
      "epoch:4 step:3854 [D loss: 0.663592, acc.: 63.28%] [G loss: 0.773482]\n",
      "epoch:4 step:3855 [D loss: 0.669696, acc.: 60.94%] [G loss: 0.747023]\n",
      "epoch:4 step:3856 [D loss: 0.698899, acc.: 50.00%] [G loss: 0.766805]\n",
      "epoch:4 step:3857 [D loss: 0.680128, acc.: 55.47%] [G loss: 0.764838]\n",
      "epoch:4 step:3858 [D loss: 0.666740, acc.: 64.84%] [G loss: 0.789763]\n",
      "epoch:4 step:3859 [D loss: 0.701825, acc.: 53.12%] [G loss: 0.731897]\n",
      "epoch:4 step:3860 [D loss: 0.648638, acc.: 66.41%] [G loss: 0.756206]\n",
      "epoch:4 step:3861 [D loss: 0.692390, acc.: 53.91%] [G loss: 0.720438]\n",
      "epoch:4 step:3862 [D loss: 0.709878, acc.: 49.22%] [G loss: 0.726575]\n",
      "epoch:4 step:3863 [D loss: 0.677745, acc.: 57.03%] [G loss: 0.716959]\n",
      "epoch:4 step:3864 [D loss: 0.680589, acc.: 56.25%] [G loss: 0.768786]\n",
      "epoch:4 step:3865 [D loss: 0.697149, acc.: 53.91%] [G loss: 0.749276]\n",
      "epoch:4 step:3866 [D loss: 0.678955, acc.: 59.38%] [G loss: 0.744763]\n",
      "epoch:4 step:3867 [D loss: 0.676856, acc.: 56.25%] [G loss: 0.751911]\n",
      "epoch:4 step:3868 [D loss: 0.741777, acc.: 42.97%] [G loss: 0.783123]\n",
      "epoch:4 step:3869 [D loss: 0.726545, acc.: 41.41%] [G loss: 0.803229]\n",
      "epoch:4 step:3870 [D loss: 0.697940, acc.: 54.69%] [G loss: 0.775360]\n",
      "epoch:4 step:3871 [D loss: 0.653320, acc.: 63.28%] [G loss: 0.800695]\n",
      "epoch:4 step:3872 [D loss: 0.668824, acc.: 58.59%] [G loss: 0.850440]\n",
      "epoch:4 step:3873 [D loss: 0.630123, acc.: 66.41%] [G loss: 0.825975]\n",
      "epoch:4 step:3874 [D loss: 0.639576, acc.: 67.19%] [G loss: 0.852418]\n",
      "epoch:4 step:3875 [D loss: 0.664232, acc.: 63.28%] [G loss: 0.862725]\n",
      "epoch:4 step:3876 [D loss: 0.723432, acc.: 47.66%] [G loss: 0.856268]\n",
      "epoch:4 step:3877 [D loss: 0.721058, acc.: 48.44%] [G loss: 0.791721]\n",
      "epoch:4 step:3878 [D loss: 0.655589, acc.: 62.50%] [G loss: 0.808351]\n",
      "epoch:4 step:3879 [D loss: 0.698633, acc.: 53.12%] [G loss: 0.768363]\n",
      "epoch:4 step:3880 [D loss: 0.690661, acc.: 56.25%] [G loss: 0.748387]\n",
      "epoch:4 step:3881 [D loss: 0.695930, acc.: 54.69%] [G loss: 0.725718]\n",
      "epoch:4 step:3882 [D loss: 0.699441, acc.: 53.91%] [G loss: 0.721521]\n",
      "epoch:4 step:3883 [D loss: 0.722921, acc.: 53.12%] [G loss: 0.716322]\n",
      "epoch:4 step:3884 [D loss: 0.698270, acc.: 54.69%] [G loss: 0.744126]\n",
      "epoch:4 step:3885 [D loss: 0.694859, acc.: 53.91%] [G loss: 0.708117]\n",
      "epoch:4 step:3886 [D loss: 0.701563, acc.: 49.22%] [G loss: 0.742657]\n",
      "epoch:4 step:3887 [D loss: 0.686680, acc.: 55.47%] [G loss: 0.755272]\n",
      "epoch:4 step:3888 [D loss: 0.673060, acc.: 58.59%] [G loss: 0.788741]\n",
      "epoch:4 step:3889 [D loss: 0.658323, acc.: 59.38%] [G loss: 0.903466]\n",
      "epoch:4 step:3890 [D loss: 0.658930, acc.: 63.28%] [G loss: 0.929533]\n",
      "epoch:4 step:3891 [D loss: 0.647734, acc.: 64.06%] [G loss: 0.916017]\n",
      "epoch:4 step:3892 [D loss: 0.617560, acc.: 68.75%] [G loss: 0.908818]\n",
      "epoch:4 step:3893 [D loss: 0.633349, acc.: 68.75%] [G loss: 0.886774]\n",
      "epoch:4 step:3894 [D loss: 0.654069, acc.: 57.03%] [G loss: 0.862088]\n",
      "epoch:4 step:3895 [D loss: 0.705872, acc.: 51.56%] [G loss: 0.841128]\n",
      "epoch:4 step:3896 [D loss: 0.692297, acc.: 53.91%] [G loss: 0.738620]\n",
      "epoch:4 step:3897 [D loss: 0.713330, acc.: 51.56%] [G loss: 0.710022]\n",
      "epoch:4 step:3898 [D loss: 0.704839, acc.: 46.88%] [G loss: 0.774815]\n",
      "epoch:4 step:3899 [D loss: 0.680118, acc.: 57.81%] [G loss: 0.764732]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:4 step:3900 [D loss: 0.713713, acc.: 53.91%] [G loss: 0.871323]\n",
      "epoch:4 step:3901 [D loss: 0.742940, acc.: 50.00%] [G loss: 0.825573]\n",
      "epoch:4 step:3902 [D loss: 0.700275, acc.: 47.66%] [G loss: 0.818601]\n",
      "epoch:4 step:3903 [D loss: 0.713422, acc.: 51.56%] [G loss: 0.864524]\n",
      "epoch:4 step:3904 [D loss: 0.697110, acc.: 53.91%] [G loss: 0.848136]\n",
      "epoch:4 step:3905 [D loss: 0.637886, acc.: 64.84%] [G loss: 0.877639]\n",
      "epoch:4 step:3906 [D loss: 0.649012, acc.: 60.16%] [G loss: 0.854930]\n",
      "epoch:4 step:3907 [D loss: 0.699580, acc.: 54.69%] [G loss: 0.875787]\n",
      "epoch:4 step:3908 [D loss: 0.678186, acc.: 57.81%] [G loss: 0.809395]\n",
      "epoch:4 step:3909 [D loss: 0.678247, acc.: 57.81%] [G loss: 0.793709]\n",
      "epoch:4 step:3910 [D loss: 0.686885, acc.: 57.03%] [G loss: 0.796272]\n",
      "epoch:4 step:3911 [D loss: 0.711661, acc.: 41.41%] [G loss: 0.767120]\n",
      "epoch:4 step:3912 [D loss: 0.696488, acc.: 47.66%] [G loss: 0.752644]\n",
      "epoch:4 step:3913 [D loss: 0.702087, acc.: 47.66%] [G loss: 0.712385]\n",
      "epoch:4 step:3914 [D loss: 0.710989, acc.: 47.66%] [G loss: 0.738070]\n",
      "epoch:4 step:3915 [D loss: 0.735533, acc.: 39.84%] [G loss: 0.730458]\n",
      "epoch:4 step:3916 [D loss: 0.697412, acc.: 50.00%] [G loss: 0.771430]\n",
      "epoch:4 step:3917 [D loss: 0.683631, acc.: 56.25%] [G loss: 0.765825]\n",
      "epoch:4 step:3918 [D loss: 0.687750, acc.: 53.12%] [G loss: 0.786865]\n",
      "epoch:4 step:3919 [D loss: 0.701433, acc.: 50.78%] [G loss: 0.782771]\n",
      "epoch:4 step:3920 [D loss: 0.688963, acc.: 53.91%] [G loss: 0.759151]\n",
      "epoch:4 step:3921 [D loss: 0.690756, acc.: 53.91%] [G loss: 0.799411]\n",
      "epoch:4 step:3922 [D loss: 0.673311, acc.: 53.12%] [G loss: 0.780101]\n",
      "epoch:4 step:3923 [D loss: 0.688166, acc.: 54.69%] [G loss: 0.808619]\n",
      "epoch:4 step:3924 [D loss: 0.667210, acc.: 60.94%] [G loss: 0.777708]\n",
      "epoch:4 step:3925 [D loss: 0.668437, acc.: 62.50%] [G loss: 0.784441]\n",
      "epoch:4 step:3926 [D loss: 0.684180, acc.: 57.81%] [G loss: 0.810854]\n",
      "epoch:4 step:3927 [D loss: 0.708780, acc.: 53.91%] [G loss: 0.779185]\n",
      "epoch:4 step:3928 [D loss: 0.701077, acc.: 56.25%] [G loss: 0.722324]\n",
      "epoch:4 step:3929 [D loss: 0.689099, acc.: 52.34%] [G loss: 0.750089]\n",
      "epoch:4 step:3930 [D loss: 0.694399, acc.: 50.78%] [G loss: 0.761552]\n",
      "epoch:4 step:3931 [D loss: 0.693272, acc.: 51.56%] [G loss: 0.773711]\n",
      "epoch:4 step:3932 [D loss: 0.668754, acc.: 54.69%] [G loss: 0.770163]\n",
      "epoch:4 step:3933 [D loss: 0.694362, acc.: 57.81%] [G loss: 0.795521]\n",
      "epoch:4 step:3934 [D loss: 0.709195, acc.: 50.78%] [G loss: 0.820003]\n",
      "epoch:4 step:3935 [D loss: 0.688499, acc.: 53.91%] [G loss: 0.811553]\n",
      "epoch:4 step:3936 [D loss: 0.688821, acc.: 54.69%] [G loss: 0.791921]\n",
      "epoch:4 step:3937 [D loss: 0.676229, acc.: 59.38%] [G loss: 0.826128]\n",
      "epoch:4 step:3938 [D loss: 0.658687, acc.: 60.16%] [G loss: 0.804269]\n",
      "epoch:4 step:3939 [D loss: 0.671132, acc.: 57.81%] [G loss: 0.825854]\n",
      "epoch:4 step:3940 [D loss: 0.703385, acc.: 48.44%] [G loss: 0.838559]\n",
      "epoch:4 step:3941 [D loss: 0.686946, acc.: 50.78%] [G loss: 0.796991]\n",
      "epoch:4 step:3942 [D loss: 0.656494, acc.: 59.38%] [G loss: 0.758711]\n",
      "epoch:4 step:3943 [D loss: 0.684280, acc.: 53.12%] [G loss: 0.791784]\n",
      "epoch:4 step:3944 [D loss: 0.724669, acc.: 46.88%] [G loss: 0.769476]\n",
      "epoch:4 step:3945 [D loss: 0.685545, acc.: 56.25%] [G loss: 0.755521]\n",
      "epoch:4 step:3946 [D loss: 0.700482, acc.: 49.22%] [G loss: 0.776319]\n",
      "epoch:4 step:3947 [D loss: 0.708978, acc.: 46.09%] [G loss: 0.790647]\n",
      "epoch:4 step:3948 [D loss: 0.738820, acc.: 46.09%] [G loss: 0.809910]\n",
      "epoch:4 step:3949 [D loss: 0.714435, acc.: 48.44%] [G loss: 0.830884]\n",
      "epoch:4 step:3950 [D loss: 0.668369, acc.: 61.72%] [G loss: 0.764277]\n",
      "epoch:4 step:3951 [D loss: 0.688563, acc.: 52.34%] [G loss: 0.774655]\n",
      "epoch:4 step:3952 [D loss: 0.695291, acc.: 50.00%] [G loss: 0.805910]\n",
      "epoch:4 step:3953 [D loss: 0.683907, acc.: 55.47%] [G loss: 0.784763]\n",
      "epoch:4 step:3954 [D loss: 0.688456, acc.: 52.34%] [G loss: 0.790412]\n",
      "epoch:4 step:3955 [D loss: 0.709974, acc.: 53.12%] [G loss: 0.749401]\n",
      "epoch:4 step:3956 [D loss: 0.692055, acc.: 55.47%] [G loss: 0.759174]\n",
      "epoch:4 step:3957 [D loss: 0.661166, acc.: 62.50%] [G loss: 0.833525]\n",
      "epoch:4 step:3958 [D loss: 0.701421, acc.: 52.34%] [G loss: 0.742220]\n",
      "epoch:4 step:3959 [D loss: 0.704150, acc.: 53.12%] [G loss: 0.760311]\n",
      "epoch:4 step:3960 [D loss: 0.707265, acc.: 48.44%] [G loss: 0.769559]\n",
      "epoch:4 step:3961 [D loss: 0.708118, acc.: 46.09%] [G loss: 0.795906]\n",
      "epoch:4 step:3962 [D loss: 0.689533, acc.: 52.34%] [G loss: 0.744403]\n",
      "epoch:4 step:3963 [D loss: 0.704218, acc.: 50.00%] [G loss: 0.775839]\n",
      "epoch:4 step:3964 [D loss: 0.706825, acc.: 50.78%] [G loss: 0.761288]\n",
      "epoch:4 step:3965 [D loss: 0.675616, acc.: 57.81%] [G loss: 0.809719]\n",
      "epoch:4 step:3966 [D loss: 0.694655, acc.: 44.53%] [G loss: 0.734228]\n",
      "epoch:4 step:3967 [D loss: 0.685331, acc.: 53.12%] [G loss: 0.783852]\n",
      "epoch:4 step:3968 [D loss: 0.763417, acc.: 35.94%] [G loss: 0.765682]\n",
      "epoch:4 step:3969 [D loss: 0.691220, acc.: 48.44%] [G loss: 0.772331]\n",
      "epoch:4 step:3970 [D loss: 0.670908, acc.: 55.47%] [G loss: 0.775046]\n",
      "epoch:4 step:3971 [D loss: 0.662384, acc.: 61.72%] [G loss: 0.788024]\n",
      "epoch:4 step:3972 [D loss: 0.668393, acc.: 60.94%] [G loss: 0.773706]\n",
      "epoch:4 step:3973 [D loss: 0.701025, acc.: 52.34%] [G loss: 0.796295]\n",
      "epoch:4 step:3974 [D loss: 0.691693, acc.: 51.56%] [G loss: 0.723093]\n",
      "epoch:4 step:3975 [D loss: 0.706863, acc.: 49.22%] [G loss: 0.758427]\n",
      "epoch:4 step:3976 [D loss: 0.685197, acc.: 51.56%] [G loss: 0.790061]\n",
      "epoch:4 step:3977 [D loss: 0.680651, acc.: 57.81%] [G loss: 0.779419]\n",
      "epoch:4 step:3978 [D loss: 0.657626, acc.: 64.06%] [G loss: 0.769958]\n",
      "epoch:4 step:3979 [D loss: 0.633508, acc.: 60.16%] [G loss: 0.723140]\n",
      "epoch:4 step:3980 [D loss: 0.656308, acc.: 60.16%] [G loss: 0.801260]\n",
      "epoch:4 step:3981 [D loss: 0.696588, acc.: 52.34%] [G loss: 0.749911]\n",
      "epoch:4 step:3982 [D loss: 0.741960, acc.: 42.97%] [G loss: 0.785107]\n",
      "epoch:4 step:3983 [D loss: 0.705278, acc.: 42.97%] [G loss: 0.729976]\n",
      "epoch:4 step:3984 [D loss: 0.688164, acc.: 55.47%] [G loss: 0.713595]\n",
      "epoch:4 step:3985 [D loss: 0.717011, acc.: 42.97%] [G loss: 0.764724]\n",
      "epoch:4 step:3986 [D loss: 0.691020, acc.: 51.56%] [G loss: 0.786115]\n",
      "epoch:4 step:3987 [D loss: 0.676292, acc.: 58.59%] [G loss: 0.826084]\n",
      "epoch:4 step:3988 [D loss: 0.684955, acc.: 57.81%] [G loss: 0.839289]\n",
      "epoch:4 step:3989 [D loss: 0.662373, acc.: 60.94%] [G loss: 0.812392]\n",
      "epoch:4 step:3990 [D loss: 0.673869, acc.: 57.81%] [G loss: 0.836779]\n",
      "epoch:4 step:3991 [D loss: 0.673056, acc.: 60.94%] [G loss: 0.832595]\n",
      "epoch:4 step:3992 [D loss: 0.688791, acc.: 60.16%] [G loss: 0.847525]\n",
      "epoch:4 step:3993 [D loss: 0.653064, acc.: 62.50%] [G loss: 0.832989]\n",
      "epoch:4 step:3994 [D loss: 0.706864, acc.: 50.00%] [G loss: 0.843668]\n",
      "epoch:4 step:3995 [D loss: 0.704633, acc.: 47.66%] [G loss: 0.792226]\n",
      "epoch:4 step:3996 [D loss: 0.692281, acc.: 50.78%] [G loss: 0.785005]\n",
      "epoch:4 step:3997 [D loss: 0.703348, acc.: 49.22%] [G loss: 0.800611]\n",
      "epoch:4 step:3998 [D loss: 0.719026, acc.: 47.66%] [G loss: 0.839339]\n",
      "epoch:4 step:3999 [D loss: 0.687929, acc.: 52.34%] [G loss: 0.799800]\n",
      "epoch:4 step:4000 [D loss: 0.692552, acc.: 56.25%] [G loss: 0.830495]\n",
      "##############\n",
      "[3.74579602 2.40802642 6.30003007 5.4494721  4.35775202 6.16053325\n",
      " 5.17926477 5.18832696 5.71204497 4.76930065]\n",
      "##########\n",
      "epoch:4 step:4001 [D loss: 0.671916, acc.: 57.81%] [G loss: 0.814779]\n",
      "epoch:4 step:4002 [D loss: 0.669709, acc.: 57.81%] [G loss: 0.802162]\n",
      "epoch:4 step:4003 [D loss: 0.691917, acc.: 52.34%] [G loss: 0.787612]\n",
      "epoch:4 step:4004 [D loss: 0.711237, acc.: 48.44%] [G loss: 0.789205]\n",
      "epoch:4 step:4005 [D loss: 0.663186, acc.: 60.94%] [G loss: 0.740728]\n",
      "epoch:4 step:4006 [D loss: 0.691058, acc.: 50.78%] [G loss: 0.804754]\n",
      "epoch:4 step:4007 [D loss: 0.701260, acc.: 50.78%] [G loss: 0.725434]\n",
      "epoch:4 step:4008 [D loss: 0.704171, acc.: 51.56%] [G loss: 0.768173]\n",
      "epoch:4 step:4009 [D loss: 0.687613, acc.: 56.25%] [G loss: 0.779186]\n",
      "epoch:4 step:4010 [D loss: 0.681247, acc.: 57.03%] [G loss: 0.751101]\n",
      "epoch:4 step:4011 [D loss: 0.740032, acc.: 45.31%] [G loss: 0.770092]\n",
      "epoch:4 step:4012 [D loss: 0.687428, acc.: 53.91%] [G loss: 0.796490]\n",
      "epoch:4 step:4013 [D loss: 0.674936, acc.: 56.25%] [G loss: 0.804532]\n",
      "epoch:4 step:4014 [D loss: 0.710844, acc.: 48.44%] [G loss: 0.731209]\n",
      "epoch:4 step:4015 [D loss: 0.701268, acc.: 55.47%] [G loss: 0.774105]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:4 step:4016 [D loss: 0.699935, acc.: 55.47%] [G loss: 0.738383]\n",
      "epoch:4 step:4017 [D loss: 0.693542, acc.: 55.47%] [G loss: 0.756162]\n",
      "epoch:4 step:4018 [D loss: 0.703166, acc.: 46.88%] [G loss: 0.749270]\n",
      "epoch:4 step:4019 [D loss: 0.681224, acc.: 53.12%] [G loss: 0.744484]\n",
      "epoch:4 step:4020 [D loss: 0.704303, acc.: 52.34%] [G loss: 0.746123]\n",
      "epoch:4 step:4021 [D loss: 0.688967, acc.: 57.03%] [G loss: 0.766260]\n",
      "epoch:4 step:4022 [D loss: 0.659456, acc.: 60.16%] [G loss: 0.780126]\n",
      "epoch:4 step:4023 [D loss: 0.673013, acc.: 54.69%] [G loss: 0.792907]\n",
      "epoch:4 step:4024 [D loss: 0.658781, acc.: 61.72%] [G loss: 0.817741]\n",
      "epoch:4 step:4025 [D loss: 0.678973, acc.: 57.03%] [G loss: 0.766429]\n",
      "epoch:4 step:4026 [D loss: 0.711988, acc.: 45.31%] [G loss: 0.767829]\n",
      "epoch:4 step:4027 [D loss: 0.733203, acc.: 42.97%] [G loss: 0.744275]\n",
      "epoch:4 step:4028 [D loss: 0.696903, acc.: 52.34%] [G loss: 0.747613]\n",
      "epoch:4 step:4029 [D loss: 0.693211, acc.: 54.69%] [G loss: 0.753642]\n",
      "epoch:4 step:4030 [D loss: 0.694333, acc.: 50.00%] [G loss: 0.797602]\n",
      "epoch:4 step:4031 [D loss: 0.672144, acc.: 56.25%] [G loss: 0.831481]\n",
      "epoch:4 step:4032 [D loss: 0.651847, acc.: 61.72%] [G loss: 0.842833]\n",
      "epoch:4 step:4033 [D loss: 0.635341, acc.: 67.97%] [G loss: 0.849590]\n",
      "epoch:4 step:4034 [D loss: 0.649456, acc.: 68.75%] [G loss: 0.839819]\n",
      "epoch:4 step:4035 [D loss: 0.707379, acc.: 50.78%] [G loss: 0.933259]\n",
      "epoch:4 step:4036 [D loss: 0.720287, acc.: 46.09%] [G loss: 0.849295]\n",
      "epoch:4 step:4037 [D loss: 0.698823, acc.: 46.88%] [G loss: 0.771255]\n",
      "epoch:4 step:4038 [D loss: 0.684265, acc.: 50.00%] [G loss: 0.714441]\n",
      "epoch:4 step:4039 [D loss: 0.730247, acc.: 39.84%] [G loss: 0.729449]\n",
      "epoch:4 step:4040 [D loss: 0.704430, acc.: 47.66%] [G loss: 0.762787]\n",
      "epoch:4 step:4041 [D loss: 0.694870, acc.: 49.22%] [G loss: 0.761047]\n",
      "epoch:4 step:4042 [D loss: 0.699004, acc.: 54.69%] [G loss: 0.762495]\n",
      "epoch:4 step:4043 [D loss: 0.692533, acc.: 50.78%] [G loss: 0.772362]\n",
      "epoch:4 step:4044 [D loss: 0.669485, acc.: 56.25%] [G loss: 0.762597]\n",
      "epoch:4 step:4045 [D loss: 0.718347, acc.: 43.75%] [G loss: 0.767708]\n",
      "epoch:4 step:4046 [D loss: 0.665769, acc.: 61.72%] [G loss: 0.832517]\n",
      "epoch:4 step:4047 [D loss: 0.675156, acc.: 50.78%] [G loss: 0.769437]\n",
      "epoch:4 step:4048 [D loss: 0.663038, acc.: 58.59%] [G loss: 0.858498]\n",
      "epoch:4 step:4049 [D loss: 0.730473, acc.: 49.22%] [G loss: 0.766990]\n",
      "epoch:4 step:4050 [D loss: 0.748197, acc.: 42.19%] [G loss: 0.732828]\n",
      "epoch:4 step:4051 [D loss: 0.721667, acc.: 47.66%] [G loss: 0.729331]\n",
      "epoch:4 step:4052 [D loss: 0.748435, acc.: 35.16%] [G loss: 0.722504]\n",
      "epoch:4 step:4053 [D loss: 0.764412, acc.: 31.25%] [G loss: 0.695816]\n",
      "epoch:4 step:4054 [D loss: 0.705092, acc.: 48.44%] [G loss: 0.733911]\n",
      "epoch:4 step:4055 [D loss: 0.674753, acc.: 59.38%] [G loss: 0.761882]\n",
      "epoch:4 step:4056 [D loss: 0.680362, acc.: 57.81%] [G loss: 0.811828]\n",
      "epoch:4 step:4057 [D loss: 0.655353, acc.: 64.84%] [G loss: 0.776769]\n",
      "epoch:4 step:4058 [D loss: 0.655054, acc.: 61.72%] [G loss: 0.790924]\n",
      "epoch:4 step:4059 [D loss: 0.616949, acc.: 63.28%] [G loss: 0.773498]\n",
      "epoch:4 step:4060 [D loss: 0.693815, acc.: 53.12%] [G loss: 0.775955]\n",
      "epoch:4 step:4061 [D loss: 0.676175, acc.: 55.47%] [G loss: 0.825463]\n",
      "epoch:4 step:4062 [D loss: 0.693379, acc.: 52.34%] [G loss: 0.769401]\n",
      "epoch:4 step:4063 [D loss: 0.688912, acc.: 57.03%] [G loss: 0.740410]\n",
      "epoch:4 step:4064 [D loss: 0.750150, acc.: 42.97%] [G loss: 0.718392]\n",
      "epoch:4 step:4065 [D loss: 0.750530, acc.: 40.62%] [G loss: 0.753767]\n",
      "epoch:4 step:4066 [D loss: 0.690477, acc.: 50.78%] [G loss: 0.697410]\n",
      "epoch:4 step:4067 [D loss: 0.711736, acc.: 47.66%] [G loss: 0.765041]\n",
      "epoch:4 step:4068 [D loss: 0.723511, acc.: 39.84%] [G loss: 0.757206]\n",
      "epoch:4 step:4069 [D loss: 0.680163, acc.: 60.16%] [G loss: 0.738645]\n",
      "epoch:4 step:4070 [D loss: 0.689873, acc.: 56.25%] [G loss: 0.790575]\n",
      "epoch:4 step:4071 [D loss: 0.682151, acc.: 55.47%] [G loss: 0.748007]\n",
      "epoch:4 step:4072 [D loss: 0.689947, acc.: 52.34%] [G loss: 0.745960]\n",
      "epoch:4 step:4073 [D loss: 0.656760, acc.: 64.06%] [G loss: 0.816249]\n",
      "epoch:4 step:4074 [D loss: 0.686870, acc.: 52.34%] [G loss: 0.780043]\n",
      "epoch:4 step:4075 [D loss: 0.689167, acc.: 53.91%] [G loss: 0.836789]\n",
      "epoch:4 step:4076 [D loss: 0.690782, acc.: 47.66%] [G loss: 0.788420]\n",
      "epoch:4 step:4077 [D loss: 0.702773, acc.: 49.22%] [G loss: 0.764875]\n",
      "epoch:4 step:4078 [D loss: 0.712058, acc.: 48.44%] [G loss: 0.765916]\n",
      "epoch:4 step:4079 [D loss: 0.689620, acc.: 58.59%] [G loss: 0.746293]\n",
      "epoch:4 step:4080 [D loss: 0.680737, acc.: 59.38%] [G loss: 0.747656]\n",
      "epoch:4 step:4081 [D loss: 0.701033, acc.: 51.56%] [G loss: 0.737601]\n",
      "epoch:4 step:4082 [D loss: 0.669761, acc.: 54.69%] [G loss: 0.747990]\n",
      "epoch:4 step:4083 [D loss: 0.665515, acc.: 64.06%] [G loss: 0.755116]\n",
      "epoch:4 step:4084 [D loss: 0.688038, acc.: 57.81%] [G loss: 0.795415]\n",
      "epoch:4 step:4085 [D loss: 0.694314, acc.: 57.81%] [G loss: 0.776414]\n",
      "epoch:4 step:4086 [D loss: 0.678577, acc.: 57.81%] [G loss: 0.778502]\n",
      "epoch:4 step:4087 [D loss: 0.695333, acc.: 55.47%] [G loss: 0.764079]\n",
      "epoch:4 step:4088 [D loss: 0.671744, acc.: 53.91%] [G loss: 0.751387]\n",
      "epoch:4 step:4089 [D loss: 0.710832, acc.: 51.56%] [G loss: 0.756172]\n",
      "epoch:4 step:4090 [D loss: 0.685312, acc.: 54.69%] [G loss: 0.762713]\n",
      "epoch:4 step:4091 [D loss: 0.668478, acc.: 57.81%] [G loss: 0.767111]\n",
      "epoch:4 step:4092 [D loss: 0.672020, acc.: 53.12%] [G loss: 0.764351]\n",
      "epoch:4 step:4093 [D loss: 0.687195, acc.: 48.44%] [G loss: 0.777015]\n",
      "epoch:4 step:4094 [D loss: 0.659804, acc.: 57.81%] [G loss: 0.763310]\n",
      "epoch:4 step:4095 [D loss: 0.646658, acc.: 64.84%] [G loss: 0.807900]\n",
      "epoch:4 step:4096 [D loss: 0.718543, acc.: 50.00%] [G loss: 0.768994]\n",
      "epoch:4 step:4097 [D loss: 0.729878, acc.: 41.41%] [G loss: 0.746108]\n",
      "epoch:4 step:4098 [D loss: 0.716314, acc.: 49.22%] [G loss: 0.738751]\n",
      "epoch:4 step:4099 [D loss: 0.720763, acc.: 46.88%] [G loss: 0.778030]\n",
      "epoch:4 step:4100 [D loss: 0.704473, acc.: 46.88%] [G loss: 0.753754]\n",
      "epoch:4 step:4101 [D loss: 0.684516, acc.: 52.34%] [G loss: 0.755956]\n",
      "epoch:4 step:4102 [D loss: 0.663875, acc.: 58.59%] [G loss: 0.799817]\n",
      "epoch:4 step:4103 [D loss: 0.691938, acc.: 60.94%] [G loss: 0.762845]\n",
      "epoch:4 step:4104 [D loss: 0.683546, acc.: 52.34%] [G loss: 0.751794]\n",
      "epoch:4 step:4105 [D loss: 0.724949, acc.: 45.31%] [G loss: 0.704350]\n",
      "epoch:4 step:4106 [D loss: 0.668900, acc.: 56.25%] [G loss: 0.780546]\n",
      "epoch:4 step:4107 [D loss: 0.670173, acc.: 60.16%] [G loss: 0.794293]\n",
      "epoch:4 step:4108 [D loss: 0.666886, acc.: 54.69%] [G loss: 0.781141]\n",
      "epoch:4 step:4109 [D loss: 0.695502, acc.: 50.00%] [G loss: 0.788071]\n",
      "epoch:4 step:4110 [D loss: 0.723209, acc.: 47.66%] [G loss: 0.826250]\n",
      "epoch:4 step:4111 [D loss: 0.743448, acc.: 46.09%] [G loss: 0.754970]\n",
      "epoch:4 step:4112 [D loss: 0.680448, acc.: 53.91%] [G loss: 0.753043]\n",
      "epoch:4 step:4113 [D loss: 0.693807, acc.: 55.47%] [G loss: 0.736868]\n",
      "epoch:4 step:4114 [D loss: 0.689335, acc.: 53.12%] [G loss: 0.791068]\n",
      "epoch:4 step:4115 [D loss: 0.684430, acc.: 56.25%] [G loss: 0.784923]\n",
      "epoch:4 step:4116 [D loss: 0.662218, acc.: 65.62%] [G loss: 0.825893]\n",
      "epoch:4 step:4117 [D loss: 0.681020, acc.: 56.25%] [G loss: 0.776239]\n",
      "epoch:4 step:4118 [D loss: 0.680659, acc.: 53.91%] [G loss: 0.747485]\n",
      "epoch:4 step:4119 [D loss: 0.669712, acc.: 59.38%] [G loss: 0.786054]\n",
      "epoch:4 step:4120 [D loss: 0.668267, acc.: 60.94%] [G loss: 0.787975]\n",
      "epoch:4 step:4121 [D loss: 0.707994, acc.: 46.09%] [G loss: 0.767926]\n",
      "epoch:4 step:4122 [D loss: 0.667941, acc.: 57.03%] [G loss: 0.825615]\n",
      "epoch:4 step:4123 [D loss: 0.688423, acc.: 51.56%] [G loss: 0.783779]\n",
      "epoch:4 step:4124 [D loss: 0.748429, acc.: 42.97%] [G loss: 0.732329]\n",
      "epoch:4 step:4125 [D loss: 0.744120, acc.: 39.06%] [G loss: 0.727824]\n",
      "epoch:4 step:4126 [D loss: 0.711506, acc.: 47.66%] [G loss: 0.753303]\n",
      "epoch:4 step:4127 [D loss: 0.718946, acc.: 49.22%] [G loss: 0.741345]\n",
      "epoch:4 step:4128 [D loss: 0.674556, acc.: 65.62%] [G loss: 0.769255]\n",
      "epoch:4 step:4129 [D loss: 0.691937, acc.: 54.69%] [G loss: 0.775797]\n",
      "epoch:4 step:4130 [D loss: 0.693172, acc.: 58.59%] [G loss: 0.766638]\n",
      "epoch:4 step:4131 [D loss: 0.674479, acc.: 60.94%] [G loss: 0.781883]\n",
      "epoch:4 step:4132 [D loss: 0.687435, acc.: 53.12%] [G loss: 0.763002]\n",
      "epoch:4 step:4133 [D loss: 0.661056, acc.: 61.72%] [G loss: 0.831014]\n",
      "epoch:4 step:4134 [D loss: 0.657888, acc.: 64.84%] [G loss: 0.782510]\n",
      "epoch:4 step:4135 [D loss: 0.662060, acc.: 61.72%] [G loss: 0.791592]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:4 step:4136 [D loss: 0.657685, acc.: 61.72%] [G loss: 0.784460]\n",
      "epoch:4 step:4137 [D loss: 0.678107, acc.: 57.81%] [G loss: 0.758427]\n",
      "epoch:4 step:4138 [D loss: 0.725784, acc.: 44.53%] [G loss: 0.859194]\n",
      "epoch:4 step:4139 [D loss: 0.681037, acc.: 49.22%] [G loss: 0.725849]\n",
      "epoch:4 step:4140 [D loss: 0.676779, acc.: 54.69%] [G loss: 0.734048]\n",
      "epoch:4 step:4141 [D loss: 0.718684, acc.: 49.22%] [G loss: 0.764643]\n",
      "epoch:4 step:4142 [D loss: 0.710060, acc.: 52.34%] [G loss: 0.766159]\n",
      "epoch:4 step:4143 [D loss: 0.719733, acc.: 42.97%] [G loss: 0.756325]\n",
      "epoch:4 step:4144 [D loss: 0.698232, acc.: 48.44%] [G loss: 0.732736]\n",
      "epoch:4 step:4145 [D loss: 0.673340, acc.: 60.16%] [G loss: 0.724451]\n",
      "epoch:4 step:4146 [D loss: 0.661433, acc.: 60.94%] [G loss: 0.750208]\n",
      "epoch:4 step:4147 [D loss: 0.689519, acc.: 54.69%] [G loss: 0.752369]\n",
      "epoch:4 step:4148 [D loss: 0.693539, acc.: 51.56%] [G loss: 0.742576]\n",
      "epoch:4 step:4149 [D loss: 0.702564, acc.: 51.56%] [G loss: 0.750764]\n",
      "epoch:4 step:4150 [D loss: 0.652339, acc.: 59.38%] [G loss: 0.823895]\n",
      "epoch:4 step:4151 [D loss: 0.707135, acc.: 53.12%] [G loss: 0.782124]\n",
      "epoch:4 step:4152 [D loss: 0.646929, acc.: 66.41%] [G loss: 0.803416]\n",
      "epoch:4 step:4153 [D loss: 0.669150, acc.: 60.94%] [G loss: 0.767462]\n",
      "epoch:4 step:4154 [D loss: 0.644793, acc.: 64.84%] [G loss: 0.797748]\n",
      "epoch:4 step:4155 [D loss: 0.661874, acc.: 58.59%] [G loss: 0.809362]\n",
      "epoch:4 step:4156 [D loss: 0.675934, acc.: 55.47%] [G loss: 0.742514]\n",
      "epoch:4 step:4157 [D loss: 0.669007, acc.: 61.72%] [G loss: 0.796472]\n",
      "epoch:4 step:4158 [D loss: 0.720945, acc.: 46.09%] [G loss: 0.745671]\n",
      "epoch:4 step:4159 [D loss: 0.696520, acc.: 55.47%] [G loss: 0.756278]\n",
      "epoch:4 step:4160 [D loss: 0.693627, acc.: 56.25%] [G loss: 0.765077]\n",
      "epoch:4 step:4161 [D loss: 0.681053, acc.: 54.69%] [G loss: 0.740872]\n",
      "epoch:4 step:4162 [D loss: 0.701594, acc.: 50.78%] [G loss: 0.808480]\n",
      "epoch:4 step:4163 [D loss: 0.668692, acc.: 53.91%] [G loss: 0.774156]\n",
      "epoch:4 step:4164 [D loss: 0.688894, acc.: 61.72%] [G loss: 0.767107]\n",
      "epoch:4 step:4165 [D loss: 0.717979, acc.: 44.53%] [G loss: 0.768013]\n",
      "epoch:4 step:4166 [D loss: 0.720290, acc.: 44.53%] [G loss: 0.784043]\n",
      "epoch:4 step:4167 [D loss: 0.661369, acc.: 59.38%] [G loss: 0.808707]\n",
      "epoch:4 step:4168 [D loss: 0.677452, acc.: 54.69%] [G loss: 0.794317]\n",
      "epoch:4 step:4169 [D loss: 0.697750, acc.: 51.56%] [G loss: 0.796087]\n",
      "epoch:4 step:4170 [D loss: 0.737047, acc.: 39.84%] [G loss: 0.814209]\n",
      "epoch:4 step:4171 [D loss: 0.684015, acc.: 53.12%] [G loss: 0.802027]\n",
      "epoch:4 step:4172 [D loss: 0.667962, acc.: 60.16%] [G loss: 0.763000]\n",
      "epoch:4 step:4173 [D loss: 0.663144, acc.: 60.94%] [G loss: 0.784465]\n",
      "epoch:4 step:4174 [D loss: 0.657124, acc.: 58.59%] [G loss: 0.801664]\n",
      "epoch:4 step:4175 [D loss: 0.661190, acc.: 60.94%] [G loss: 0.797464]\n",
      "epoch:4 step:4176 [D loss: 0.669100, acc.: 52.34%] [G loss: 0.764436]\n",
      "epoch:4 step:4177 [D loss: 0.648863, acc.: 61.72%] [G loss: 0.812024]\n",
      "epoch:4 step:4178 [D loss: 0.689520, acc.: 61.72%] [G loss: 0.780233]\n",
      "epoch:4 step:4179 [D loss: 0.710605, acc.: 51.56%] [G loss: 0.812402]\n",
      "epoch:4 step:4180 [D loss: 0.760919, acc.: 45.31%] [G loss: 0.765330]\n",
      "epoch:4 step:4181 [D loss: 0.701304, acc.: 51.56%] [G loss: 0.791943]\n",
      "epoch:4 step:4182 [D loss: 0.709039, acc.: 42.97%] [G loss: 0.800463]\n",
      "epoch:4 step:4183 [D loss: 0.650708, acc.: 60.94%] [G loss: 0.769351]\n",
      "epoch:4 step:4184 [D loss: 0.678746, acc.: 60.16%] [G loss: 0.820255]\n",
      "epoch:4 step:4185 [D loss: 0.749332, acc.: 41.41%] [G loss: 0.771086]\n",
      "epoch:4 step:4186 [D loss: 0.705321, acc.: 50.78%] [G loss: 0.711626]\n",
      "epoch:4 step:4187 [D loss: 0.695672, acc.: 49.22%] [G loss: 0.753695]\n",
      "epoch:4 step:4188 [D loss: 0.702815, acc.: 49.22%] [G loss: 0.742788]\n",
      "epoch:4 step:4189 [D loss: 0.669238, acc.: 53.91%] [G loss: 0.748622]\n",
      "epoch:4 step:4190 [D loss: 0.706207, acc.: 52.34%] [G loss: 0.744013]\n",
      "epoch:4 step:4191 [D loss: 0.679124, acc.: 51.56%] [G loss: 0.751102]\n",
      "epoch:4 step:4192 [D loss: 0.664519, acc.: 52.34%] [G loss: 0.757489]\n",
      "epoch:4 step:4193 [D loss: 0.669334, acc.: 57.81%] [G loss: 0.811605]\n",
      "epoch:4 step:4194 [D loss: 0.659701, acc.: 56.25%] [G loss: 0.880751]\n",
      "epoch:4 step:4195 [D loss: 0.650989, acc.: 60.16%] [G loss: 0.806461]\n",
      "epoch:4 step:4196 [D loss: 0.695973, acc.: 53.12%] [G loss: 0.766727]\n",
      "epoch:4 step:4197 [D loss: 0.686976, acc.: 59.38%] [G loss: 0.763755]\n",
      "epoch:4 step:4198 [D loss: 0.679035, acc.: 58.59%] [G loss: 0.780387]\n",
      "epoch:4 step:4199 [D loss: 0.675616, acc.: 58.59%] [G loss: 0.811385]\n",
      "epoch:4 step:4200 [D loss: 0.695791, acc.: 50.78%] [G loss: 0.771106]\n",
      "##############\n",
      "[3.60972661 2.09379867 6.2191734  5.28556835 4.48578356 5.77513916\n",
      " 5.01649714 5.33219168 5.55737102 4.3735044 ]\n",
      "##########\n",
      "epoch:4 step:4201 [D loss: 0.674057, acc.: 57.81%] [G loss: 0.820130]\n",
      "epoch:4 step:4202 [D loss: 0.682325, acc.: 56.25%] [G loss: 0.814463]\n",
      "epoch:4 step:4203 [D loss: 0.703223, acc.: 51.56%] [G loss: 0.804449]\n",
      "epoch:4 step:4204 [D loss: 0.692767, acc.: 53.91%] [G loss: 0.761171]\n",
      "epoch:4 step:4205 [D loss: 0.692149, acc.: 51.56%] [G loss: 0.858496]\n",
      "epoch:4 step:4206 [D loss: 0.727497, acc.: 43.75%] [G loss: 0.763352]\n",
      "epoch:4 step:4207 [D loss: 0.679659, acc.: 59.38%] [G loss: 0.722190]\n",
      "epoch:4 step:4208 [D loss: 0.687563, acc.: 53.12%] [G loss: 0.782608]\n",
      "epoch:4 step:4209 [D loss: 0.730744, acc.: 46.09%] [G loss: 0.750772]\n",
      "epoch:4 step:4210 [D loss: 0.721621, acc.: 45.31%] [G loss: 0.768634]\n",
      "epoch:4 step:4211 [D loss: 0.677627, acc.: 53.91%] [G loss: 0.765591]\n",
      "epoch:4 step:4212 [D loss: 0.674120, acc.: 53.91%] [G loss: 0.752590]\n",
      "epoch:4 step:4213 [D loss: 0.688163, acc.: 53.91%] [G loss: 0.781450]\n",
      "epoch:4 step:4214 [D loss: 0.684853, acc.: 56.25%] [G loss: 0.801616]\n",
      "epoch:4 step:4215 [D loss: 0.697019, acc.: 55.47%] [G loss: 0.829317]\n",
      "epoch:4 step:4216 [D loss: 0.687875, acc.: 56.25%] [G loss: 0.763510]\n",
      "epoch:4 step:4217 [D loss: 0.702070, acc.: 45.31%] [G loss: 0.746448]\n",
      "epoch:4 step:4218 [D loss: 0.703034, acc.: 46.88%] [G loss: 0.718455]\n",
      "epoch:4 step:4219 [D loss: 0.707690, acc.: 47.66%] [G loss: 0.751046]\n",
      "epoch:4 step:4220 [D loss: 0.687895, acc.: 57.03%] [G loss: 0.792472]\n",
      "epoch:4 step:4221 [D loss: 0.727917, acc.: 46.09%] [G loss: 0.797084]\n",
      "epoch:4 step:4222 [D loss: 0.697633, acc.: 46.88%] [G loss: 0.816944]\n",
      "epoch:4 step:4223 [D loss: 0.652370, acc.: 64.84%] [G loss: 0.810985]\n",
      "epoch:4 step:4224 [D loss: 0.654944, acc.: 60.94%] [G loss: 0.801076]\n",
      "epoch:4 step:4225 [D loss: 0.690769, acc.: 52.34%] [G loss: 0.850394]\n",
      "epoch:4 step:4226 [D loss: 0.668989, acc.: 59.38%] [G loss: 0.856372]\n",
      "epoch:4 step:4227 [D loss: 0.711678, acc.: 46.88%] [G loss: 0.791019]\n",
      "epoch:4 step:4228 [D loss: 0.715567, acc.: 48.44%] [G loss: 0.780273]\n",
      "epoch:4 step:4229 [D loss: 0.703074, acc.: 45.31%] [G loss: 0.760087]\n",
      "epoch:4 step:4230 [D loss: 0.693794, acc.: 54.69%] [G loss: 0.800038]\n",
      "epoch:4 step:4231 [D loss: 0.656707, acc.: 64.84%] [G loss: 0.778794]\n",
      "epoch:4 step:4232 [D loss: 0.684686, acc.: 56.25%] [G loss: 0.727826]\n",
      "epoch:4 step:4233 [D loss: 0.674157, acc.: 54.69%] [G loss: 0.744183]\n",
      "epoch:4 step:4234 [D loss: 0.741351, acc.: 42.19%] [G loss: 0.741537]\n",
      "epoch:4 step:4235 [D loss: 0.711848, acc.: 54.69%] [G loss: 0.756416]\n",
      "epoch:4 step:4236 [D loss: 0.709282, acc.: 50.00%] [G loss: 0.778450]\n",
      "epoch:4 step:4237 [D loss: 0.705054, acc.: 50.00%] [G loss: 0.754329]\n",
      "epoch:4 step:4238 [D loss: 0.698317, acc.: 45.31%] [G loss: 0.751798]\n",
      "epoch:4 step:4239 [D loss: 0.671630, acc.: 56.25%] [G loss: 0.768460]\n",
      "epoch:4 step:4240 [D loss: 0.673990, acc.: 57.03%] [G loss: 0.766387]\n",
      "epoch:4 step:4241 [D loss: 0.685059, acc.: 53.12%] [G loss: 0.841241]\n",
      "epoch:4 step:4242 [D loss: 0.673690, acc.: 57.81%] [G loss: 0.784319]\n",
      "epoch:4 step:4243 [D loss: 0.635153, acc.: 65.62%] [G loss: 0.733375]\n",
      "epoch:4 step:4244 [D loss: 0.693962, acc.: 51.56%] [G loss: 0.750164]\n",
      "epoch:4 step:4245 [D loss: 0.648515, acc.: 67.97%] [G loss: 0.778504]\n",
      "epoch:4 step:4246 [D loss: 0.696687, acc.: 53.91%] [G loss: 0.741505]\n",
      "epoch:4 step:4247 [D loss: 0.675602, acc.: 57.81%] [G loss: 0.779979]\n",
      "epoch:4 step:4248 [D loss: 0.698361, acc.: 55.47%] [G loss: 0.757469]\n",
      "epoch:4 step:4249 [D loss: 0.733968, acc.: 42.97%] [G loss: 0.739585]\n",
      "epoch:4 step:4250 [D loss: 0.714330, acc.: 44.53%] [G loss: 0.816620]\n",
      "epoch:4 step:4251 [D loss: 0.718699, acc.: 52.34%] [G loss: 0.778003]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:4 step:4252 [D loss: 0.672082, acc.: 60.94%] [G loss: 0.776418]\n",
      "epoch:4 step:4253 [D loss: 0.659711, acc.: 61.72%] [G loss: 0.825191]\n",
      "epoch:4 step:4254 [D loss: 0.671634, acc.: 53.91%] [G loss: 0.827763]\n",
      "epoch:4 step:4255 [D loss: 0.660316, acc.: 57.81%] [G loss: 0.789047]\n",
      "epoch:4 step:4256 [D loss: 0.655859, acc.: 64.06%] [G loss: 0.799747]\n",
      "epoch:4 step:4257 [D loss: 0.710700, acc.: 46.88%] [G loss: 0.763097]\n",
      "epoch:4 step:4258 [D loss: 0.719409, acc.: 51.56%] [G loss: 0.797225]\n",
      "epoch:4 step:4259 [D loss: 0.709591, acc.: 42.19%] [G loss: 0.783285]\n",
      "epoch:4 step:4260 [D loss: 0.735329, acc.: 46.09%] [G loss: 0.757551]\n",
      "epoch:4 step:4261 [D loss: 0.666293, acc.: 58.59%] [G loss: 0.740006]\n",
      "epoch:4 step:4262 [D loss: 0.688306, acc.: 51.56%] [G loss: 0.757304]\n",
      "epoch:4 step:4263 [D loss: 0.645774, acc.: 60.16%] [G loss: 0.766641]\n",
      "epoch:4 step:4264 [D loss: 0.662123, acc.: 62.50%] [G loss: 0.783729]\n",
      "epoch:4 step:4265 [D loss: 0.695170, acc.: 47.66%] [G loss: 0.767894]\n",
      "epoch:4 step:4266 [D loss: 0.698032, acc.: 49.22%] [G loss: 0.771471]\n",
      "epoch:4 step:4267 [D loss: 0.676051, acc.: 61.72%] [G loss: 0.762861]\n",
      "epoch:4 step:4268 [D loss: 0.657944, acc.: 64.06%] [G loss: 0.767925]\n",
      "epoch:4 step:4269 [D loss: 0.656562, acc.: 67.97%] [G loss: 0.749316]\n",
      "epoch:4 step:4270 [D loss: 0.675003, acc.: 63.28%] [G loss: 0.783469]\n",
      "epoch:4 step:4271 [D loss: 0.654341, acc.: 65.62%] [G loss: 0.807785]\n",
      "epoch:4 step:4272 [D loss: 0.701113, acc.: 50.78%] [G loss: 0.839427]\n",
      "epoch:4 step:4273 [D loss: 0.697920, acc.: 55.47%] [G loss: 0.823212]\n",
      "epoch:4 step:4274 [D loss: 0.661956, acc.: 57.81%] [G loss: 0.787590]\n",
      "epoch:4 step:4275 [D loss: 0.688072, acc.: 58.59%] [G loss: 0.751441]\n",
      "epoch:4 step:4276 [D loss: 0.718568, acc.: 45.31%] [G loss: 0.764284]\n",
      "epoch:4 step:4277 [D loss: 0.748952, acc.: 39.84%] [G loss: 0.857004]\n",
      "epoch:4 step:4278 [D loss: 0.671524, acc.: 56.25%] [G loss: 0.811967]\n",
      "epoch:4 step:4279 [D loss: 0.672138, acc.: 59.38%] [G loss: 0.849208]\n",
      "epoch:4 step:4280 [D loss: 0.724455, acc.: 46.88%] [G loss: 0.777975]\n",
      "epoch:4 step:4281 [D loss: 0.693851, acc.: 52.34%] [G loss: 0.729664]\n",
      "epoch:4 step:4282 [D loss: 0.683370, acc.: 57.81%] [G loss: 0.752857]\n",
      "epoch:4 step:4283 [D loss: 0.695058, acc.: 53.12%] [G loss: 0.741174]\n",
      "epoch:4 step:4284 [D loss: 0.701852, acc.: 54.69%] [G loss: 0.749506]\n",
      "epoch:4 step:4285 [D loss: 0.694495, acc.: 53.12%] [G loss: 0.798250]\n",
      "epoch:4 step:4286 [D loss: 0.658681, acc.: 63.28%] [G loss: 0.779860]\n",
      "epoch:4 step:4287 [D loss: 0.705142, acc.: 50.00%] [G loss: 0.750899]\n",
      "epoch:4 step:4288 [D loss: 0.721681, acc.: 39.84%] [G loss: 0.695010]\n",
      "epoch:4 step:4289 [D loss: 0.680554, acc.: 54.69%] [G loss: 0.757185]\n",
      "epoch:4 step:4290 [D loss: 0.733887, acc.: 37.50%] [G loss: 0.755184]\n",
      "epoch:4 step:4291 [D loss: 0.698296, acc.: 40.62%] [G loss: 0.732631]\n",
      "epoch:4 step:4292 [D loss: 0.702326, acc.: 51.56%] [G loss: 0.737019]\n",
      "epoch:4 step:4293 [D loss: 0.691889, acc.: 54.69%] [G loss: 0.761876]\n",
      "epoch:4 step:4294 [D loss: 0.694634, acc.: 51.56%] [G loss: 0.789563]\n",
      "epoch:4 step:4295 [D loss: 0.718657, acc.: 45.31%] [G loss: 0.774437]\n",
      "epoch:4 step:4296 [D loss: 0.674291, acc.: 57.81%] [G loss: 0.760406]\n",
      "epoch:4 step:4297 [D loss: 0.676440, acc.: 64.06%] [G loss: 0.752074]\n",
      "epoch:4 step:4298 [D loss: 0.682582, acc.: 55.47%] [G loss: 0.809094]\n",
      "epoch:4 step:4299 [D loss: 0.670783, acc.: 59.38%] [G loss: 0.786275]\n",
      "epoch:4 step:4300 [D loss: 0.679267, acc.: 55.47%] [G loss: 0.805263]\n",
      "epoch:4 step:4301 [D loss: 0.685244, acc.: 54.69%] [G loss: 0.756459]\n",
      "epoch:4 step:4302 [D loss: 0.682700, acc.: 55.47%] [G loss: 0.787883]\n",
      "epoch:4 step:4303 [D loss: 0.654622, acc.: 67.97%] [G loss: 0.796674]\n",
      "epoch:4 step:4304 [D loss: 0.650447, acc.: 65.62%] [G loss: 0.784016]\n",
      "epoch:4 step:4305 [D loss: 0.668232, acc.: 57.03%] [G loss: 0.800753]\n",
      "epoch:4 step:4306 [D loss: 0.668876, acc.: 65.62%] [G loss: 0.825501]\n",
      "epoch:4 step:4307 [D loss: 0.697107, acc.: 53.91%] [G loss: 0.836505]\n",
      "epoch:4 step:4308 [D loss: 0.716489, acc.: 49.22%] [G loss: 0.807869]\n",
      "epoch:4 step:4309 [D loss: 0.663992, acc.: 57.81%] [G loss: 0.803550]\n",
      "epoch:4 step:4310 [D loss: 0.686317, acc.: 53.12%] [G loss: 0.832530]\n",
      "epoch:4 step:4311 [D loss: 0.690557, acc.: 55.47%] [G loss: 0.780558]\n",
      "epoch:4 step:4312 [D loss: 0.692956, acc.: 49.22%] [G loss: 0.756646]\n",
      "epoch:4 step:4313 [D loss: 0.691072, acc.: 51.56%] [G loss: 0.765519]\n",
      "epoch:4 step:4314 [D loss: 0.705548, acc.: 49.22%] [G loss: 0.815988]\n",
      "epoch:4 step:4315 [D loss: 0.659160, acc.: 54.69%] [G loss: 0.834305]\n",
      "epoch:4 step:4316 [D loss: 0.600868, acc.: 73.44%] [G loss: 0.896189]\n",
      "epoch:4 step:4317 [D loss: 0.697241, acc.: 57.81%] [G loss: 0.882022]\n",
      "epoch:4 step:4318 [D loss: 0.666489, acc.: 59.38%] [G loss: 0.897715]\n",
      "epoch:4 step:4319 [D loss: 0.679841, acc.: 58.59%] [G loss: 0.858711]\n",
      "epoch:4 step:4320 [D loss: 0.622464, acc.: 65.62%] [G loss: 0.920038]\n",
      "epoch:4 step:4321 [D loss: 0.624749, acc.: 64.84%] [G loss: 0.896564]\n",
      "epoch:4 step:4322 [D loss: 0.624321, acc.: 62.50%] [G loss: 0.884429]\n",
      "epoch:4 step:4323 [D loss: 0.649841, acc.: 60.16%] [G loss: 0.829866]\n",
      "epoch:4 step:4324 [D loss: 0.758803, acc.: 46.09%] [G loss: 0.728805]\n",
      "epoch:4 step:4325 [D loss: 0.797787, acc.: 37.50%] [G loss: 0.718844]\n",
      "epoch:4 step:4326 [D loss: 0.779649, acc.: 36.72%] [G loss: 0.714188]\n",
      "epoch:4 step:4327 [D loss: 0.704110, acc.: 46.09%] [G loss: 0.728834]\n",
      "epoch:4 step:4328 [D loss: 0.736311, acc.: 47.66%] [G loss: 0.749279]\n",
      "epoch:4 step:4329 [D loss: 0.690695, acc.: 52.34%] [G loss: 0.728800]\n",
      "epoch:4 step:4330 [D loss: 0.695943, acc.: 56.25%] [G loss: 0.768083]\n",
      "epoch:4 step:4331 [D loss: 0.676973, acc.: 55.47%] [G loss: 0.810579]\n",
      "epoch:4 step:4332 [D loss: 0.655307, acc.: 60.16%] [G loss: 0.826366]\n",
      "epoch:4 step:4333 [D loss: 0.659640, acc.: 64.06%] [G loss: 0.865564]\n",
      "epoch:4 step:4334 [D loss: 0.643215, acc.: 61.72%] [G loss: 0.894457]\n",
      "epoch:4 step:4335 [D loss: 0.691186, acc.: 53.12%] [G loss: 0.858304]\n",
      "epoch:4 step:4336 [D loss: 0.652008, acc.: 56.25%] [G loss: 0.953377]\n",
      "epoch:4 step:4337 [D loss: 0.681985, acc.: 60.94%] [G loss: 0.803450]\n",
      "epoch:4 step:4338 [D loss: 0.716329, acc.: 48.44%] [G loss: 0.871068]\n",
      "epoch:4 step:4339 [D loss: 0.722463, acc.: 48.44%] [G loss: 0.830433]\n",
      "epoch:4 step:4340 [D loss: 0.723776, acc.: 48.44%] [G loss: 0.754795]\n",
      "epoch:4 step:4341 [D loss: 0.716001, acc.: 44.53%] [G loss: 0.765610]\n",
      "epoch:4 step:4342 [D loss: 0.708198, acc.: 53.91%] [G loss: 0.805401]\n",
      "epoch:4 step:4343 [D loss: 0.670522, acc.: 61.72%] [G loss: 0.765634]\n",
      "epoch:4 step:4344 [D loss: 0.699708, acc.: 54.69%] [G loss: 0.789308]\n",
      "epoch:4 step:4345 [D loss: 0.673751, acc.: 53.91%] [G loss: 0.897805]\n",
      "epoch:4 step:4346 [D loss: 0.655365, acc.: 61.72%] [G loss: 0.846144]\n",
      "epoch:4 step:4347 [D loss: 0.708136, acc.: 50.78%] [G loss: 0.851804]\n",
      "epoch:4 step:4348 [D loss: 0.664032, acc.: 65.62%] [G loss: 0.810067]\n",
      "epoch:4 step:4349 [D loss: 0.718118, acc.: 53.12%] [G loss: 0.832348]\n",
      "epoch:4 step:4350 [D loss: 0.685233, acc.: 58.59%] [G loss: 0.747731]\n",
      "epoch:4 step:4351 [D loss: 0.673580, acc.: 57.81%] [G loss: 0.768038]\n",
      "epoch:4 step:4352 [D loss: 0.713000, acc.: 46.88%] [G loss: 0.761174]\n",
      "epoch:4 step:4353 [D loss: 0.681548, acc.: 52.34%] [G loss: 0.766638]\n",
      "epoch:4 step:4354 [D loss: 0.705303, acc.: 43.75%] [G loss: 0.780889]\n",
      "epoch:4 step:4355 [D loss: 0.726269, acc.: 49.22%] [G loss: 0.716603]\n",
      "epoch:4 step:4356 [D loss: 0.707112, acc.: 44.53%] [G loss: 0.729923]\n",
      "epoch:4 step:4357 [D loss: 0.699921, acc.: 52.34%] [G loss: 0.731175]\n",
      "epoch:4 step:4358 [D loss: 0.677264, acc.: 53.12%] [G loss: 0.766822]\n",
      "epoch:4 step:4359 [D loss: 0.704160, acc.: 42.97%] [G loss: 0.730322]\n",
      "epoch:4 step:4360 [D loss: 0.690851, acc.: 49.22%] [G loss: 0.750031]\n",
      "epoch:4 step:4361 [D loss: 0.695372, acc.: 51.56%] [G loss: 0.713334]\n",
      "epoch:4 step:4362 [D loss: 0.728958, acc.: 42.19%] [G loss: 0.744735]\n",
      "epoch:4 step:4363 [D loss: 0.707032, acc.: 55.47%] [G loss: 0.767488]\n",
      "epoch:4 step:4364 [D loss: 0.667131, acc.: 61.72%] [G loss: 0.760195]\n",
      "epoch:4 step:4365 [D loss: 0.665470, acc.: 63.28%] [G loss: 0.757741]\n",
      "epoch:4 step:4366 [D loss: 0.690376, acc.: 47.66%] [G loss: 0.780726]\n",
      "epoch:4 step:4367 [D loss: 0.680155, acc.: 58.59%] [G loss: 0.741042]\n",
      "epoch:4 step:4368 [D loss: 0.658147, acc.: 61.72%] [G loss: 0.751304]\n",
      "epoch:4 step:4369 [D loss: 0.709029, acc.: 50.00%] [G loss: 0.762347]\n",
      "epoch:4 step:4370 [D loss: 0.672387, acc.: 52.34%] [G loss: 0.749049]\n",
      "epoch:4 step:4371 [D loss: 0.703951, acc.: 46.88%] [G loss: 0.765323]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:4 step:4372 [D loss: 0.676722, acc.: 61.72%] [G loss: 0.725517]\n",
      "epoch:4 step:4373 [D loss: 0.717664, acc.: 50.78%] [G loss: 0.749228]\n",
      "epoch:4 step:4374 [D loss: 0.701503, acc.: 46.09%] [G loss: 0.792100]\n",
      "epoch:4 step:4375 [D loss: 0.677987, acc.: 54.69%] [G loss: 0.813206]\n",
      "epoch:4 step:4376 [D loss: 0.700808, acc.: 53.12%] [G loss: 0.809691]\n",
      "epoch:4 step:4377 [D loss: 0.679843, acc.: 60.16%] [G loss: 0.782990]\n",
      "epoch:4 step:4378 [D loss: 0.696910, acc.: 57.03%] [G loss: 0.813730]\n",
      "epoch:4 step:4379 [D loss: 0.664932, acc.: 62.50%] [G loss: 0.830108]\n",
      "epoch:4 step:4380 [D loss: 0.680557, acc.: 59.38%] [G loss: 0.860754]\n",
      "epoch:4 step:4381 [D loss: 0.658939, acc.: 65.62%] [G loss: 0.834893]\n",
      "epoch:4 step:4382 [D loss: 0.671996, acc.: 60.94%] [G loss: 0.825303]\n",
      "epoch:4 step:4383 [D loss: 0.686120, acc.: 57.03%] [G loss: 0.790593]\n",
      "epoch:4 step:4384 [D loss: 0.674172, acc.: 58.59%] [G loss: 0.812194]\n",
      "epoch:4 step:4385 [D loss: 0.659106, acc.: 61.72%] [G loss: 0.838933]\n",
      "epoch:4 step:4386 [D loss: 0.714699, acc.: 51.56%] [G loss: 0.750049]\n",
      "epoch:4 step:4387 [D loss: 0.721469, acc.: 45.31%] [G loss: 0.781765]\n",
      "epoch:4 step:4388 [D loss: 0.736384, acc.: 40.62%] [G loss: 0.754437]\n",
      "epoch:4 step:4389 [D loss: 0.714654, acc.: 51.56%] [G loss: 0.737947]\n",
      "epoch:4 step:4390 [D loss: 0.699151, acc.: 51.56%] [G loss: 0.722098]\n",
      "epoch:4 step:4391 [D loss: 0.701321, acc.: 51.56%] [G loss: 0.763401]\n",
      "epoch:4 step:4392 [D loss: 0.705449, acc.: 50.00%] [G loss: 0.725548]\n",
      "epoch:4 step:4393 [D loss: 0.716798, acc.: 44.53%] [G loss: 0.753425]\n",
      "epoch:4 step:4394 [D loss: 0.691397, acc.: 51.56%] [G loss: 0.728259]\n",
      "epoch:4 step:4395 [D loss: 0.690646, acc.: 50.78%] [G loss: 0.756952]\n",
      "epoch:4 step:4396 [D loss: 0.659170, acc.: 61.72%] [G loss: 0.744050]\n",
      "epoch:4 step:4397 [D loss: 0.678172, acc.: 57.81%] [G loss: 0.774066]\n",
      "epoch:4 step:4398 [D loss: 0.640269, acc.: 62.50%] [G loss: 0.775023]\n",
      "epoch:4 step:4399 [D loss: 0.672140, acc.: 58.59%] [G loss: 0.787694]\n",
      "epoch:4 step:4400 [D loss: 0.712267, acc.: 50.78%] [G loss: 0.780501]\n",
      "##############\n",
      "[3.51687178 2.15561343 6.34920359 5.31054469 3.45586931 5.87880885\n",
      " 4.91378912 5.03604321 5.56587146 4.85982752]\n",
      "##########\n",
      "epoch:4 step:4401 [D loss: 0.678504, acc.: 51.56%] [G loss: 0.765938]\n",
      "epoch:4 step:4402 [D loss: 0.694049, acc.: 50.78%] [G loss: 0.755523]\n",
      "epoch:4 step:4403 [D loss: 0.689076, acc.: 48.44%] [G loss: 0.724099]\n",
      "epoch:4 step:4404 [D loss: 0.708700, acc.: 50.78%] [G loss: 0.698604]\n",
      "epoch:4 step:4405 [D loss: 0.693530, acc.: 48.44%] [G loss: 0.749232]\n",
      "epoch:4 step:4406 [D loss: 0.731606, acc.: 42.97%] [G loss: 0.715722]\n",
      "epoch:4 step:4407 [D loss: 0.685062, acc.: 57.81%] [G loss: 0.736524]\n",
      "epoch:4 step:4408 [D loss: 0.679933, acc.: 57.81%] [G loss: 0.728182]\n",
      "epoch:4 step:4409 [D loss: 0.651256, acc.: 63.28%] [G loss: 0.755658]\n",
      "epoch:4 step:4410 [D loss: 0.690283, acc.: 53.12%] [G loss: 0.750498]\n",
      "epoch:4 step:4411 [D loss: 0.712944, acc.: 50.00%] [G loss: 0.799128]\n",
      "epoch:4 step:4412 [D loss: 0.665531, acc.: 61.72%] [G loss: 0.775965]\n",
      "epoch:4 step:4413 [D loss: 0.685818, acc.: 55.47%] [G loss: 0.768712]\n",
      "epoch:4 step:4414 [D loss: 0.669168, acc.: 56.25%] [G loss: 0.742953]\n",
      "epoch:4 step:4415 [D loss: 0.672314, acc.: 59.38%] [G loss: 0.762001]\n",
      "epoch:4 step:4416 [D loss: 0.668658, acc.: 56.25%] [G loss: 0.768945]\n",
      "epoch:4 step:4417 [D loss: 0.677525, acc.: 56.25%] [G loss: 0.764275]\n",
      "epoch:4 step:4418 [D loss: 0.712497, acc.: 46.09%] [G loss: 0.797407]\n",
      "epoch:4 step:4419 [D loss: 0.698890, acc.: 50.00%] [G loss: 0.800868]\n",
      "epoch:4 step:4420 [D loss: 0.715131, acc.: 46.09%] [G loss: 0.784770]\n",
      "epoch:4 step:4421 [D loss: 0.706195, acc.: 39.84%] [G loss: 0.772349]\n",
      "epoch:4 step:4422 [D loss: 0.687279, acc.: 46.88%] [G loss: 0.750225]\n",
      "epoch:4 step:4423 [D loss: 0.691051, acc.: 49.22%] [G loss: 0.735639]\n",
      "epoch:4 step:4424 [D loss: 0.678511, acc.: 59.38%] [G loss: 0.769177]\n",
      "epoch:4 step:4425 [D loss: 0.689437, acc.: 54.69%] [G loss: 0.741520]\n",
      "epoch:4 step:4426 [D loss: 0.675887, acc.: 62.50%] [G loss: 0.790463]\n",
      "epoch:4 step:4427 [D loss: 0.683894, acc.: 58.59%] [G loss: 0.773301]\n",
      "epoch:4 step:4428 [D loss: 0.658415, acc.: 59.38%] [G loss: 0.709904]\n",
      "epoch:4 step:4429 [D loss: 0.715209, acc.: 52.34%] [G loss: 0.696175]\n",
      "epoch:4 step:4430 [D loss: 0.701581, acc.: 56.25%] [G loss: 0.782326]\n",
      "epoch:4 step:4431 [D loss: 0.707843, acc.: 52.34%] [G loss: 0.708541]\n",
      "epoch:4 step:4432 [D loss: 0.704347, acc.: 44.53%] [G loss: 0.740716]\n",
      "epoch:4 step:4433 [D loss: 0.699746, acc.: 55.47%] [G loss: 0.776227]\n",
      "epoch:4 step:4434 [D loss: 0.668585, acc.: 60.16%] [G loss: 0.718404]\n",
      "epoch:4 step:4435 [D loss: 0.691847, acc.: 50.00%] [G loss: 0.739300]\n",
      "epoch:4 step:4436 [D loss: 0.674120, acc.: 57.81%] [G loss: 0.752078]\n",
      "epoch:4 step:4437 [D loss: 0.709848, acc.: 50.78%] [G loss: 0.753369]\n",
      "epoch:4 step:4438 [D loss: 0.687110, acc.: 55.47%] [G loss: 0.766726]\n",
      "epoch:4 step:4439 [D loss: 0.709226, acc.: 53.12%] [G loss: 0.767968]\n",
      "epoch:4 step:4440 [D loss: 0.697758, acc.: 50.00%] [G loss: 0.776109]\n",
      "epoch:4 step:4441 [D loss: 0.688569, acc.: 53.12%] [G loss: 0.773514]\n",
      "epoch:4 step:4442 [D loss: 0.660309, acc.: 65.62%] [G loss: 0.770355]\n",
      "epoch:4 step:4443 [D loss: 0.700283, acc.: 49.22%] [G loss: 0.798974]\n",
      "epoch:4 step:4444 [D loss: 0.704177, acc.: 49.22%] [G loss: 0.818282]\n",
      "epoch:4 step:4445 [D loss: 0.708168, acc.: 50.78%] [G loss: 0.807534]\n",
      "epoch:4 step:4446 [D loss: 0.698466, acc.: 53.91%] [G loss: 0.789166]\n",
      "epoch:4 step:4447 [D loss: 0.673664, acc.: 60.94%] [G loss: 0.792786]\n",
      "epoch:4 step:4448 [D loss: 0.667961, acc.: 57.03%] [G loss: 0.807533]\n",
      "epoch:4 step:4449 [D loss: 0.664347, acc.: 62.50%] [G loss: 0.812855]\n",
      "epoch:4 step:4450 [D loss: 0.721929, acc.: 49.22%] [G loss: 0.800294]\n",
      "epoch:4 step:4451 [D loss: 0.713748, acc.: 50.78%] [G loss: 0.795131]\n",
      "epoch:4 step:4452 [D loss: 0.696379, acc.: 53.12%] [G loss: 0.778560]\n",
      "epoch:4 step:4453 [D loss: 0.688208, acc.: 55.47%] [G loss: 0.762166]\n",
      "epoch:4 step:4454 [D loss: 0.688601, acc.: 57.03%] [G loss: 0.716908]\n",
      "epoch:4 step:4455 [D loss: 0.662791, acc.: 60.16%] [G loss: 0.746642]\n",
      "epoch:4 step:4456 [D loss: 0.682265, acc.: 58.59%] [G loss: 0.788009]\n",
      "epoch:4 step:4457 [D loss: 0.678691, acc.: 52.34%] [G loss: 0.776669]\n",
      "epoch:4 step:4458 [D loss: 0.716523, acc.: 42.19%] [G loss: 0.781919]\n",
      "epoch:4 step:4459 [D loss: 0.702099, acc.: 49.22%] [G loss: 0.766784]\n",
      "epoch:4 step:4460 [D loss: 0.671447, acc.: 57.81%] [G loss: 0.783939]\n",
      "epoch:4 step:4461 [D loss: 0.666928, acc.: 56.25%] [G loss: 0.823159]\n",
      "epoch:4 step:4462 [D loss: 0.701653, acc.: 51.56%] [G loss: 0.713256]\n",
      "epoch:4 step:4463 [D loss: 0.704141, acc.: 46.88%] [G loss: 0.723632]\n",
      "epoch:4 step:4464 [D loss: 0.701341, acc.: 53.12%] [G loss: 0.773990]\n",
      "epoch:4 step:4465 [D loss: 0.694414, acc.: 53.91%] [G loss: 0.755666]\n",
      "epoch:4 step:4466 [D loss: 0.682289, acc.: 57.03%] [G loss: 0.792812]\n",
      "epoch:4 step:4467 [D loss: 0.695809, acc.: 53.12%] [G loss: 0.752587]\n",
      "epoch:4 step:4468 [D loss: 0.677041, acc.: 58.59%] [G loss: 0.784215]\n",
      "epoch:4 step:4469 [D loss: 0.687642, acc.: 56.25%] [G loss: 0.728023]\n",
      "epoch:4 step:4470 [D loss: 0.760686, acc.: 39.06%] [G loss: 0.740883]\n",
      "epoch:4 step:4471 [D loss: 0.692902, acc.: 48.44%] [G loss: 0.749625]\n",
      "epoch:4 step:4472 [D loss: 0.700874, acc.: 45.31%] [G loss: 0.753251]\n",
      "epoch:4 step:4473 [D loss: 0.707677, acc.: 53.91%] [G loss: 0.811249]\n",
      "epoch:4 step:4474 [D loss: 0.671642, acc.: 59.38%] [G loss: 0.823543]\n",
      "epoch:4 step:4475 [D loss: 0.685665, acc.: 54.69%] [G loss: 0.834689]\n",
      "epoch:4 step:4476 [D loss: 0.686222, acc.: 56.25%] [G loss: 0.805828]\n",
      "epoch:4 step:4477 [D loss: 0.670639, acc.: 60.94%] [G loss: 0.857384]\n",
      "epoch:4 step:4478 [D loss: 0.654429, acc.: 63.28%] [G loss: 0.818874]\n",
      "epoch:4 step:4479 [D loss: 0.671238, acc.: 66.41%] [G loss: 0.868293]\n",
      "epoch:4 step:4480 [D loss: 0.660786, acc.: 59.38%] [G loss: 0.800133]\n",
      "epoch:4 step:4481 [D loss: 0.680424, acc.: 57.03%] [G loss: 0.794512]\n",
      "epoch:4 step:4482 [D loss: 0.728915, acc.: 46.09%] [G loss: 0.720487]\n",
      "epoch:4 step:4483 [D loss: 0.740777, acc.: 39.84%] [G loss: 0.779343]\n",
      "epoch:4 step:4484 [D loss: 0.699250, acc.: 52.34%] [G loss: 0.732858]\n",
      "epoch:4 step:4485 [D loss: 0.692529, acc.: 56.25%] [G loss: 0.743977]\n",
      "epoch:4 step:4486 [D loss: 0.727070, acc.: 41.41%] [G loss: 0.770582]\n",
      "epoch:4 step:4487 [D loss: 0.689953, acc.: 46.88%] [G loss: 0.807300]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:4 step:4488 [D loss: 0.665341, acc.: 57.81%] [G loss: 0.810070]\n",
      "epoch:4 step:4489 [D loss: 0.680664, acc.: 51.56%] [G loss: 0.783750]\n",
      "epoch:4 step:4490 [D loss: 0.700161, acc.: 50.78%] [G loss: 0.787796]\n",
      "epoch:4 step:4491 [D loss: 0.680140, acc.: 54.69%] [G loss: 0.856186]\n",
      "epoch:4 step:4492 [D loss: 0.698463, acc.: 55.47%] [G loss: 0.795098]\n",
      "epoch:4 step:4493 [D loss: 0.749799, acc.: 40.62%] [G loss: 0.733321]\n",
      "epoch:4 step:4494 [D loss: 0.684223, acc.: 51.56%] [G loss: 0.739105]\n",
      "epoch:4 step:4495 [D loss: 0.693720, acc.: 50.00%] [G loss: 0.702718]\n",
      "epoch:4 step:4496 [D loss: 0.722447, acc.: 47.66%] [G loss: 0.727163]\n",
      "epoch:4 step:4497 [D loss: 0.697592, acc.: 51.56%] [G loss: 0.728537]\n",
      "epoch:4 step:4498 [D loss: 0.693072, acc.: 56.25%] [G loss: 0.715877]\n",
      "epoch:4 step:4499 [D loss: 0.700001, acc.: 51.56%] [G loss: 0.725598]\n",
      "epoch:4 step:4500 [D loss: 0.707286, acc.: 43.75%] [G loss: 0.753597]\n",
      "epoch:4 step:4501 [D loss: 0.687829, acc.: 54.69%] [G loss: 0.769830]\n",
      "epoch:4 step:4502 [D loss: 0.662883, acc.: 62.50%] [G loss: 0.761625]\n",
      "epoch:4 step:4503 [D loss: 0.660264, acc.: 59.38%] [G loss: 0.783888]\n",
      "epoch:4 step:4504 [D loss: 0.640677, acc.: 63.28%] [G loss: 0.850546]\n",
      "epoch:4 step:4505 [D loss: 0.669141, acc.: 60.16%] [G loss: 0.760649]\n",
      "epoch:4 step:4506 [D loss: 0.702978, acc.: 50.78%] [G loss: 0.791316]\n",
      "epoch:4 step:4507 [D loss: 0.665801, acc.: 53.91%] [G loss: 0.740437]\n",
      "epoch:4 step:4508 [D loss: 0.714716, acc.: 46.09%] [G loss: 0.730663]\n",
      "epoch:4 step:4509 [D loss: 0.692146, acc.: 53.91%] [G loss: 0.760320]\n",
      "epoch:4 step:4510 [D loss: 0.681664, acc.: 56.25%] [G loss: 0.753015]\n",
      "epoch:4 step:4511 [D loss: 0.685093, acc.: 55.47%] [G loss: 0.749812]\n",
      "epoch:4 step:4512 [D loss: 0.692893, acc.: 53.12%] [G loss: 0.727804]\n",
      "epoch:4 step:4513 [D loss: 0.707165, acc.: 44.53%] [G loss: 0.742157]\n",
      "epoch:4 step:4514 [D loss: 0.708433, acc.: 46.88%] [G loss: 0.727118]\n",
      "epoch:4 step:4515 [D loss: 0.690535, acc.: 60.94%] [G loss: 0.746270]\n",
      "epoch:4 step:4516 [D loss: 0.704822, acc.: 48.44%] [G loss: 0.765646]\n",
      "epoch:4 step:4517 [D loss: 0.691976, acc.: 57.03%] [G loss: 0.766831]\n",
      "epoch:4 step:4518 [D loss: 0.668845, acc.: 60.16%] [G loss: 0.791413]\n",
      "epoch:4 step:4519 [D loss: 0.686021, acc.: 55.47%] [G loss: 0.784499]\n",
      "epoch:4 step:4520 [D loss: 0.663675, acc.: 57.81%] [G loss: 0.812179]\n",
      "epoch:4 step:4521 [D loss: 0.664409, acc.: 59.38%] [G loss: 0.840643]\n",
      "epoch:4 step:4522 [D loss: 0.664515, acc.: 61.72%] [G loss: 0.822829]\n",
      "epoch:4 step:4523 [D loss: 0.658263, acc.: 63.28%] [G loss: 0.819334]\n",
      "epoch:4 step:4524 [D loss: 0.707367, acc.: 49.22%] [G loss: 0.764942]\n",
      "epoch:4 step:4525 [D loss: 0.703638, acc.: 51.56%] [G loss: 0.814958]\n",
      "epoch:4 step:4526 [D loss: 0.730703, acc.: 47.66%] [G loss: 0.756039]\n",
      "epoch:4 step:4527 [D loss: 0.733448, acc.: 42.19%] [G loss: 0.689316]\n",
      "epoch:4 step:4528 [D loss: 0.731012, acc.: 42.19%] [G loss: 0.719315]\n",
      "epoch:4 step:4529 [D loss: 0.707815, acc.: 48.44%] [G loss: 0.745480]\n",
      "epoch:4 step:4530 [D loss: 0.694992, acc.: 57.03%] [G loss: 0.781911]\n",
      "epoch:4 step:4531 [D loss: 0.716827, acc.: 43.75%] [G loss: 0.791287]\n",
      "epoch:4 step:4532 [D loss: 0.707376, acc.: 57.03%] [G loss: 0.813583]\n",
      "epoch:4 step:4533 [D loss: 0.647727, acc.: 65.62%] [G loss: 0.829408]\n",
      "epoch:4 step:4534 [D loss: 0.645543, acc.: 66.41%] [G loss: 0.858986]\n",
      "epoch:4 step:4535 [D loss: 0.677164, acc.: 59.38%] [G loss: 0.877585]\n",
      "epoch:4 step:4536 [D loss: 0.671841, acc.: 57.03%] [G loss: 0.881920]\n",
      "epoch:4 step:4537 [D loss: 0.719812, acc.: 47.66%] [G loss: 0.824622]\n",
      "epoch:4 step:4538 [D loss: 0.704704, acc.: 50.78%] [G loss: 0.783915]\n",
      "epoch:4 step:4539 [D loss: 0.692337, acc.: 53.12%] [G loss: 0.789792]\n",
      "epoch:4 step:4540 [D loss: 0.692271, acc.: 53.91%] [G loss: 0.708563]\n",
      "epoch:4 step:4541 [D loss: 0.705440, acc.: 51.56%] [G loss: 0.699858]\n",
      "epoch:4 step:4542 [D loss: 0.699664, acc.: 49.22%] [G loss: 0.732685]\n",
      "epoch:4 step:4543 [D loss: 0.684524, acc.: 52.34%] [G loss: 0.739166]\n",
      "epoch:4 step:4544 [D loss: 0.699010, acc.: 52.34%] [G loss: 0.705810]\n",
      "epoch:4 step:4545 [D loss: 0.712804, acc.: 45.31%] [G loss: 0.747328]\n",
      "epoch:4 step:4546 [D loss: 0.713626, acc.: 50.00%] [G loss: 0.702844]\n",
      "epoch:4 step:4547 [D loss: 0.698253, acc.: 50.00%] [G loss: 0.725023]\n",
      "epoch:4 step:4548 [D loss: 0.761634, acc.: 33.59%] [G loss: 0.747332]\n",
      "epoch:4 step:4549 [D loss: 0.708758, acc.: 49.22%] [G loss: 0.767164]\n",
      "epoch:4 step:4550 [D loss: 0.690297, acc.: 56.25%] [G loss: 0.761041]\n",
      "epoch:4 step:4551 [D loss: 0.668949, acc.: 62.50%] [G loss: 0.810868]\n",
      "epoch:4 step:4552 [D loss: 0.680474, acc.: 50.78%] [G loss: 0.750568]\n",
      "epoch:4 step:4553 [D loss: 0.646972, acc.: 66.41%] [G loss: 0.796789]\n",
      "epoch:4 step:4554 [D loss: 0.656854, acc.: 67.19%] [G loss: 0.821854]\n",
      "epoch:4 step:4555 [D loss: 0.672931, acc.: 60.94%] [G loss: 0.794590]\n",
      "epoch:4 step:4556 [D loss: 0.688090, acc.: 54.69%] [G loss: 0.795572]\n",
      "epoch:4 step:4557 [D loss: 0.690458, acc.: 55.47%] [G loss: 0.763637]\n",
      "epoch:4 step:4558 [D loss: 0.691019, acc.: 56.25%] [G loss: 0.761183]\n",
      "epoch:4 step:4559 [D loss: 0.685329, acc.: 57.03%] [G loss: 0.745090]\n",
      "epoch:4 step:4560 [D loss: 0.700974, acc.: 51.56%] [G loss: 0.762252]\n",
      "epoch:4 step:4561 [D loss: 0.687485, acc.: 60.94%] [G loss: 0.732941]\n",
      "epoch:4 step:4562 [D loss: 0.683712, acc.: 56.25%] [G loss: 0.752717]\n",
      "epoch:4 step:4563 [D loss: 0.669439, acc.: 57.03%] [G loss: 0.799828]\n",
      "epoch:4 step:4564 [D loss: 0.695745, acc.: 44.53%] [G loss: 0.720389]\n",
      "epoch:4 step:4565 [D loss: 0.701883, acc.: 44.53%] [G loss: 0.752980]\n",
      "epoch:4 step:4566 [D loss: 0.738269, acc.: 41.41%] [G loss: 0.750073]\n",
      "epoch:4 step:4567 [D loss: 0.693114, acc.: 50.78%] [G loss: 0.790321]\n",
      "epoch:4 step:4568 [D loss: 0.696320, acc.: 52.34%] [G loss: 0.754637]\n",
      "epoch:4 step:4569 [D loss: 0.654195, acc.: 60.94%] [G loss: 0.763645]\n",
      "epoch:4 step:4570 [D loss: 0.689201, acc.: 57.03%] [G loss: 0.780326]\n",
      "epoch:4 step:4571 [D loss: 0.679197, acc.: 61.72%] [G loss: 0.736574]\n",
      "epoch:4 step:4572 [D loss: 0.694717, acc.: 49.22%] [G loss: 0.750874]\n",
      "epoch:4 step:4573 [D loss: 0.696231, acc.: 55.47%] [G loss: 0.756656]\n",
      "epoch:4 step:4574 [D loss: 0.683304, acc.: 53.91%] [G loss: 0.749348]\n",
      "epoch:4 step:4575 [D loss: 0.699112, acc.: 48.44%] [G loss: 0.756346]\n",
      "epoch:4 step:4576 [D loss: 0.706178, acc.: 51.56%] [G loss: 0.754951]\n",
      "epoch:4 step:4577 [D loss: 0.686388, acc.: 58.59%] [G loss: 0.756612]\n",
      "epoch:4 step:4578 [D loss: 0.678800, acc.: 57.81%] [G loss: 0.780242]\n",
      "epoch:4 step:4579 [D loss: 0.688216, acc.: 51.56%] [G loss: 0.729000]\n",
      "epoch:4 step:4580 [D loss: 0.688332, acc.: 52.34%] [G loss: 0.728516]\n",
      "epoch:4 step:4581 [D loss: 0.697058, acc.: 53.91%] [G loss: 0.774027]\n",
      "epoch:4 step:4582 [D loss: 0.738843, acc.: 44.53%] [G loss: 0.776675]\n",
      "epoch:4 step:4583 [D loss: 0.712495, acc.: 44.53%] [G loss: 0.741592]\n",
      "epoch:4 step:4584 [D loss: 0.692443, acc.: 50.78%] [G loss: 0.776565]\n",
      "epoch:4 step:4585 [D loss: 0.684062, acc.: 56.25%] [G loss: 0.790105]\n",
      "epoch:4 step:4586 [D loss: 0.664522, acc.: 62.50%] [G loss: 0.775636]\n",
      "epoch:4 step:4587 [D loss: 0.688817, acc.: 51.56%] [G loss: 0.763129]\n",
      "epoch:4 step:4588 [D loss: 0.711819, acc.: 46.09%] [G loss: 0.753931]\n",
      "epoch:4 step:4589 [D loss: 0.723901, acc.: 47.66%] [G loss: 0.766218]\n",
      "epoch:4 step:4590 [D loss: 0.662409, acc.: 62.50%] [G loss: 0.789311]\n",
      "epoch:4 step:4591 [D loss: 0.726016, acc.: 47.66%] [G loss: 0.773502]\n",
      "epoch:4 step:4592 [D loss: 0.686289, acc.: 57.81%] [G loss: 0.761341]\n",
      "epoch:4 step:4593 [D loss: 0.670974, acc.: 59.38%] [G loss: 0.757062]\n",
      "epoch:4 step:4594 [D loss: 0.675003, acc.: 59.38%] [G loss: 0.743219]\n",
      "epoch:4 step:4595 [D loss: 0.708714, acc.: 42.19%] [G loss: 0.796828]\n",
      "epoch:4 step:4596 [D loss: 0.719196, acc.: 41.41%] [G loss: 0.751927]\n",
      "epoch:4 step:4597 [D loss: 0.683443, acc.: 57.81%] [G loss: 0.779725]\n",
      "epoch:4 step:4598 [D loss: 0.678543, acc.: 55.47%] [G loss: 0.739858]\n",
      "epoch:4 step:4599 [D loss: 0.671606, acc.: 60.94%] [G loss: 0.770385]\n",
      "epoch:4 step:4600 [D loss: 0.663449, acc.: 57.81%] [G loss: 0.799113]\n",
      "##############\n",
      "[3.79444967 2.61755809 6.25380264 5.26610413 4.64394928 6.17719682\n",
      " 4.98294088 5.93535615 6.02448876 5.02361289]\n",
      "##########\n",
      "epoch:4 step:4601 [D loss: 0.666669, acc.: 56.25%] [G loss: 0.820125]\n",
      "epoch:4 step:4602 [D loss: 0.668898, acc.: 59.38%] [G loss: 0.794419]\n",
      "epoch:4 step:4603 [D loss: 0.663312, acc.: 62.50%] [G loss: 0.849748]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:4 step:4604 [D loss: 0.700810, acc.: 49.22%] [G loss: 0.840716]\n",
      "epoch:4 step:4605 [D loss: 0.706316, acc.: 50.00%] [G loss: 0.812697]\n",
      "epoch:4 step:4606 [D loss: 0.779222, acc.: 32.81%] [G loss: 0.787782]\n",
      "epoch:4 step:4607 [D loss: 0.732422, acc.: 43.75%] [G loss: 0.762100]\n",
      "epoch:4 step:4608 [D loss: 0.684842, acc.: 51.56%] [G loss: 0.757657]\n",
      "epoch:4 step:4609 [D loss: 0.717384, acc.: 39.84%] [G loss: 0.726783]\n",
      "epoch:4 step:4610 [D loss: 0.699106, acc.: 47.66%] [G loss: 0.710446]\n",
      "epoch:4 step:4611 [D loss: 0.706666, acc.: 46.88%] [G loss: 0.740342]\n",
      "epoch:4 step:4612 [D loss: 0.685956, acc.: 56.25%] [G loss: 0.747739]\n",
      "epoch:4 step:4613 [D loss: 0.688189, acc.: 50.00%] [G loss: 0.768033]\n",
      "epoch:4 step:4614 [D loss: 0.677419, acc.: 60.16%] [G loss: 0.751489]\n",
      "epoch:4 step:4615 [D loss: 0.674762, acc.: 58.59%] [G loss: 0.745907]\n",
      "epoch:4 step:4616 [D loss: 0.674820, acc.: 57.81%] [G loss: 0.808540]\n",
      "epoch:4 step:4617 [D loss: 0.682931, acc.: 56.25%] [G loss: 0.771280]\n",
      "epoch:4 step:4618 [D loss: 0.682561, acc.: 52.34%] [G loss: 0.767429]\n",
      "epoch:4 step:4619 [D loss: 0.708352, acc.: 48.44%] [G loss: 0.736066]\n",
      "epoch:4 step:4620 [D loss: 0.708084, acc.: 47.66%] [G loss: 0.760791]\n",
      "epoch:4 step:4621 [D loss: 0.693903, acc.: 54.69%] [G loss: 0.740610]\n",
      "epoch:4 step:4622 [D loss: 0.687852, acc.: 54.69%] [G loss: 0.743113]\n",
      "epoch:4 step:4623 [D loss: 0.679036, acc.: 57.81%] [G loss: 0.756308]\n",
      "epoch:4 step:4624 [D loss: 0.697813, acc.: 49.22%] [G loss: 0.715089]\n",
      "epoch:4 step:4625 [D loss: 0.706899, acc.: 53.12%] [G loss: 0.757537]\n",
      "epoch:4 step:4626 [D loss: 0.671098, acc.: 64.06%] [G loss: 0.768982]\n",
      "epoch:4 step:4627 [D loss: 0.683526, acc.: 53.12%] [G loss: 0.778813]\n",
      "epoch:4 step:4628 [D loss: 0.695879, acc.: 48.44%] [G loss: 0.749458]\n",
      "epoch:4 step:4629 [D loss: 0.720992, acc.: 46.88%] [G loss: 0.702504]\n",
      "epoch:4 step:4630 [D loss: 0.698421, acc.: 47.66%] [G loss: 0.724339]\n",
      "epoch:4 step:4631 [D loss: 0.700563, acc.: 44.53%] [G loss: 0.741385]\n",
      "epoch:4 step:4632 [D loss: 0.686013, acc.: 51.56%] [G loss: 0.754360]\n",
      "epoch:4 step:4633 [D loss: 0.665609, acc.: 59.38%] [G loss: 0.763277]\n",
      "epoch:4 step:4634 [D loss: 0.659425, acc.: 61.72%] [G loss: 0.764539]\n",
      "epoch:4 step:4635 [D loss: 0.686295, acc.: 47.66%] [G loss: 0.815567]\n",
      "epoch:4 step:4636 [D loss: 0.656667, acc.: 59.38%] [G loss: 0.763468]\n",
      "epoch:4 step:4637 [D loss: 0.660411, acc.: 63.28%] [G loss: 0.785969]\n",
      "epoch:4 step:4638 [D loss: 0.683524, acc.: 57.03%] [G loss: 0.805538]\n",
      "epoch:4 step:4639 [D loss: 0.713659, acc.: 37.50%] [G loss: 0.788252]\n",
      "epoch:4 step:4640 [D loss: 0.752046, acc.: 39.06%] [G loss: 0.777729]\n",
      "epoch:4 step:4641 [D loss: 0.704782, acc.: 46.88%] [G loss: 0.788477]\n",
      "epoch:4 step:4642 [D loss: 0.687575, acc.: 50.78%] [G loss: 0.811139]\n",
      "epoch:4 step:4643 [D loss: 0.691664, acc.: 47.66%] [G loss: 0.734588]\n",
      "epoch:4 step:4644 [D loss: 0.711488, acc.: 43.75%] [G loss: 0.772097]\n",
      "epoch:4 step:4645 [D loss: 0.716118, acc.: 46.09%] [G loss: 0.772082]\n",
      "epoch:4 step:4646 [D loss: 0.675002, acc.: 54.69%] [G loss: 0.790417]\n",
      "epoch:4 step:4647 [D loss: 0.673584, acc.: 58.59%] [G loss: 0.766354]\n",
      "epoch:4 step:4648 [D loss: 0.701760, acc.: 53.12%] [G loss: 0.798885]\n",
      "epoch:4 step:4649 [D loss: 0.682378, acc.: 64.84%] [G loss: 0.816114]\n",
      "epoch:4 step:4650 [D loss: 0.714690, acc.: 44.53%] [G loss: 0.787510]\n",
      "epoch:4 step:4651 [D loss: 0.685706, acc.: 57.81%] [G loss: 0.767819]\n",
      "epoch:4 step:4652 [D loss: 0.732988, acc.: 39.06%] [G loss: 0.760400]\n",
      "epoch:4 step:4653 [D loss: 0.701405, acc.: 51.56%] [G loss: 0.764338]\n",
      "epoch:4 step:4654 [D loss: 0.695009, acc.: 48.44%] [G loss: 0.736790]\n",
      "epoch:4 step:4655 [D loss: 0.679230, acc.: 56.25%] [G loss: 0.726256]\n",
      "epoch:4 step:4656 [D loss: 0.687316, acc.: 57.81%] [G loss: 0.746098]\n",
      "epoch:4 step:4657 [D loss: 0.680161, acc.: 61.72%] [G loss: 0.775881]\n",
      "epoch:4 step:4658 [D loss: 0.694519, acc.: 57.03%] [G loss: 0.744378]\n",
      "epoch:4 step:4659 [D loss: 0.681985, acc.: 56.25%] [G loss: 0.734698]\n",
      "epoch:4 step:4660 [D loss: 0.701399, acc.: 50.00%] [G loss: 0.747010]\n",
      "epoch:4 step:4661 [D loss: 0.682312, acc.: 55.47%] [G loss: 0.730181]\n",
      "epoch:4 step:4662 [D loss: 0.648404, acc.: 64.06%] [G loss: 0.745790]\n",
      "epoch:4 step:4663 [D loss: 0.684126, acc.: 55.47%] [G loss: 0.776064]\n",
      "epoch:4 step:4664 [D loss: 0.700561, acc.: 43.75%] [G loss: 0.747130]\n",
      "epoch:4 step:4665 [D loss: 0.717477, acc.: 48.44%] [G loss: 0.726821]\n",
      "epoch:4 step:4666 [D loss: 0.676164, acc.: 54.69%] [G loss: 0.718988]\n",
      "epoch:4 step:4667 [D loss: 0.681168, acc.: 55.47%] [G loss: 0.789552]\n",
      "epoch:4 step:4668 [D loss: 0.757533, acc.: 38.28%] [G loss: 0.710838]\n",
      "epoch:4 step:4669 [D loss: 0.673931, acc.: 55.47%] [G loss: 0.704678]\n",
      "epoch:4 step:4670 [D loss: 0.659137, acc.: 60.16%] [G loss: 0.743818]\n",
      "epoch:4 step:4671 [D loss: 0.664063, acc.: 64.84%] [G loss: 0.744900]\n",
      "epoch:4 step:4672 [D loss: 0.673899, acc.: 58.59%] [G loss: 0.750739]\n",
      "epoch:4 step:4673 [D loss: 0.695224, acc.: 53.91%] [G loss: 0.746668]\n",
      "epoch:4 step:4674 [D loss: 0.701753, acc.: 52.34%] [G loss: 0.721470]\n",
      "epoch:4 step:4675 [D loss: 0.683107, acc.: 54.69%] [G loss: 0.759581]\n",
      "epoch:4 step:4676 [D loss: 0.678576, acc.: 56.25%] [G loss: 0.800305]\n",
      "epoch:4 step:4677 [D loss: 0.627506, acc.: 67.97%] [G loss: 0.771366]\n",
      "epoch:4 step:4678 [D loss: 0.674745, acc.: 58.59%] [G loss: 0.826068]\n",
      "epoch:4 step:4679 [D loss: 0.713500, acc.: 50.00%] [G loss: 0.781643]\n",
      "epoch:4 step:4680 [D loss: 0.771679, acc.: 36.72%] [G loss: 0.775103]\n",
      "epoch:4 step:4681 [D loss: 0.704120, acc.: 50.00%] [G loss: 0.731139]\n",
      "epoch:4 step:4682 [D loss: 0.725616, acc.: 46.88%] [G loss: 0.747333]\n",
      "epoch:4 step:4683 [D loss: 0.677450, acc.: 57.03%] [G loss: 0.765172]\n",
      "epoch:4 step:4684 [D loss: 0.666049, acc.: 60.94%] [G loss: 0.735117]\n",
      "epoch:4 step:4685 [D loss: 0.701066, acc.: 50.00%] [G loss: 0.751858]\n",
      "epoch:5 step:4686 [D loss: 0.680739, acc.: 54.69%] [G loss: 0.784704]\n",
      "epoch:5 step:4687 [D loss: 0.712199, acc.: 46.88%] [G loss: 0.760198]\n",
      "epoch:5 step:4688 [D loss: 0.700333, acc.: 49.22%] [G loss: 0.754403]\n",
      "epoch:5 step:4689 [D loss: 0.718734, acc.: 42.19%] [G loss: 0.780176]\n",
      "epoch:5 step:4690 [D loss: 0.670364, acc.: 63.28%] [G loss: 0.781552]\n",
      "epoch:5 step:4691 [D loss: 0.686065, acc.: 56.25%] [G loss: 0.791034]\n",
      "epoch:5 step:4692 [D loss: 0.662642, acc.: 64.84%] [G loss: 0.759504]\n",
      "epoch:5 step:4693 [D loss: 0.695600, acc.: 53.91%] [G loss: 0.750959]\n",
      "epoch:5 step:4694 [D loss: 0.702018, acc.: 50.78%] [G loss: 0.777796]\n",
      "epoch:5 step:4695 [D loss: 0.699618, acc.: 54.69%] [G loss: 0.728091]\n",
      "epoch:5 step:4696 [D loss: 0.669580, acc.: 61.72%] [G loss: 0.719554]\n",
      "epoch:5 step:4697 [D loss: 0.692604, acc.: 53.12%] [G loss: 0.744692]\n",
      "epoch:5 step:4698 [D loss: 0.662286, acc.: 60.94%] [G loss: 0.821470]\n",
      "epoch:5 step:4699 [D loss: 0.681600, acc.: 55.47%] [G loss: 0.833227]\n",
      "epoch:5 step:4700 [D loss: 0.660557, acc.: 57.03%] [G loss: 0.817416]\n",
      "epoch:5 step:4701 [D loss: 0.684922, acc.: 56.25%] [G loss: 0.783829]\n",
      "epoch:5 step:4702 [D loss: 0.716008, acc.: 51.56%] [G loss: 0.773418]\n",
      "epoch:5 step:4703 [D loss: 0.670297, acc.: 58.59%] [G loss: 0.785156]\n",
      "epoch:5 step:4704 [D loss: 0.697765, acc.: 51.56%] [G loss: 0.763693]\n",
      "epoch:5 step:4705 [D loss: 0.685391, acc.: 57.03%] [G loss: 0.817954]\n",
      "epoch:5 step:4706 [D loss: 0.673841, acc.: 57.81%] [G loss: 0.816528]\n",
      "epoch:5 step:4707 [D loss: 0.664437, acc.: 60.16%] [G loss: 0.895261]\n",
      "epoch:5 step:4708 [D loss: 0.733877, acc.: 46.88%] [G loss: 0.960991]\n",
      "epoch:5 step:4709 [D loss: 0.741154, acc.: 48.44%] [G loss: 0.780390]\n",
      "epoch:5 step:4710 [D loss: 0.667734, acc.: 57.81%] [G loss: 0.797490]\n",
      "epoch:5 step:4711 [D loss: 0.747706, acc.: 41.41%] [G loss: 0.773872]\n",
      "epoch:5 step:4712 [D loss: 0.720605, acc.: 46.88%] [G loss: 0.784212]\n",
      "epoch:5 step:4713 [D loss: 0.682272, acc.: 50.78%] [G loss: 0.770368]\n",
      "epoch:5 step:4714 [D loss: 0.670922, acc.: 59.38%] [G loss: 0.794634]\n",
      "epoch:5 step:4715 [D loss: 0.665015, acc.: 57.81%] [G loss: 0.812943]\n",
      "epoch:5 step:4716 [D loss: 0.666963, acc.: 59.38%] [G loss: 0.840390]\n",
      "epoch:5 step:4717 [D loss: 0.695290, acc.: 47.66%] [G loss: 0.805992]\n",
      "epoch:5 step:4718 [D loss: 0.709374, acc.: 51.56%] [G loss: 0.771542]\n",
      "epoch:5 step:4719 [D loss: 0.674940, acc.: 50.78%] [G loss: 0.755514]\n",
      "epoch:5 step:4720 [D loss: 0.656598, acc.: 60.16%] [G loss: 0.755507]\n",
      "epoch:5 step:4721 [D loss: 0.669148, acc.: 57.81%] [G loss: 0.801974]\n",
      "epoch:5 step:4722 [D loss: 0.745916, acc.: 43.75%] [G loss: 0.769443]\n",
      "epoch:5 step:4723 [D loss: 0.689241, acc.: 50.78%] [G loss: 0.777779]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:5 step:4724 [D loss: 0.719229, acc.: 47.66%] [G loss: 0.779011]\n",
      "epoch:5 step:4725 [D loss: 0.691614, acc.: 55.47%] [G loss: 0.796151]\n",
      "epoch:5 step:4726 [D loss: 0.691871, acc.: 57.81%] [G loss: 0.796031]\n",
      "epoch:5 step:4727 [D loss: 0.703936, acc.: 49.22%] [G loss: 0.806443]\n",
      "epoch:5 step:4728 [D loss: 0.691558, acc.: 52.34%] [G loss: 0.787263]\n",
      "epoch:5 step:4729 [D loss: 0.681356, acc.: 53.91%] [G loss: 0.841384]\n",
      "epoch:5 step:4730 [D loss: 0.667875, acc.: 59.38%] [G loss: 0.807384]\n",
      "epoch:5 step:4731 [D loss: 0.679468, acc.: 56.25%] [G loss: 0.791809]\n",
      "epoch:5 step:4732 [D loss: 0.686067, acc.: 52.34%] [G loss: 0.819040]\n",
      "epoch:5 step:4733 [D loss: 0.670254, acc.: 58.59%] [G loss: 0.824487]\n",
      "epoch:5 step:4734 [D loss: 0.685279, acc.: 55.47%] [G loss: 0.848571]\n",
      "epoch:5 step:4735 [D loss: 0.701094, acc.: 46.88%] [G loss: 0.798471]\n",
      "epoch:5 step:4736 [D loss: 0.711074, acc.: 46.88%] [G loss: 0.778776]\n",
      "epoch:5 step:4737 [D loss: 0.702654, acc.: 53.12%] [G loss: 0.777734]\n",
      "epoch:5 step:4738 [D loss: 0.671093, acc.: 58.59%] [G loss: 0.748659]\n",
      "epoch:5 step:4739 [D loss: 0.705248, acc.: 53.12%] [G loss: 0.709056]\n",
      "epoch:5 step:4740 [D loss: 0.698686, acc.: 51.56%] [G loss: 0.790736]\n",
      "epoch:5 step:4741 [D loss: 0.698048, acc.: 50.78%] [G loss: 0.742697]\n",
      "epoch:5 step:4742 [D loss: 0.682996, acc.: 60.94%] [G loss: 0.785266]\n",
      "epoch:5 step:4743 [D loss: 0.692910, acc.: 52.34%] [G loss: 0.749262]\n",
      "epoch:5 step:4744 [D loss: 0.693882, acc.: 49.22%] [G loss: 0.744280]\n",
      "epoch:5 step:4745 [D loss: 0.719180, acc.: 44.53%] [G loss: 0.742216]\n",
      "epoch:5 step:4746 [D loss: 0.677331, acc.: 55.47%] [G loss: 0.758242]\n",
      "epoch:5 step:4747 [D loss: 0.683198, acc.: 51.56%] [G loss: 0.755510]\n",
      "epoch:5 step:4748 [D loss: 0.677518, acc.: 56.25%] [G loss: 0.737144]\n",
      "epoch:5 step:4749 [D loss: 0.702205, acc.: 47.66%] [G loss: 0.738903]\n",
      "epoch:5 step:4750 [D loss: 0.708238, acc.: 46.88%] [G loss: 0.743513]\n",
      "epoch:5 step:4751 [D loss: 0.680818, acc.: 48.44%] [G loss: 0.754053]\n",
      "epoch:5 step:4752 [D loss: 0.687544, acc.: 49.22%] [G loss: 0.723394]\n",
      "epoch:5 step:4753 [D loss: 0.717285, acc.: 47.66%] [G loss: 0.724312]\n",
      "epoch:5 step:4754 [D loss: 0.704566, acc.: 50.00%] [G loss: 0.677430]\n",
      "epoch:5 step:4755 [D loss: 0.697951, acc.: 54.69%] [G loss: 0.730790]\n",
      "epoch:5 step:4756 [D loss: 0.702446, acc.: 44.53%] [G loss: 0.731606]\n",
      "epoch:5 step:4757 [D loss: 0.671646, acc.: 58.59%] [G loss: 0.722763]\n",
      "epoch:5 step:4758 [D loss: 0.664777, acc.: 55.47%] [G loss: 0.748095]\n",
      "epoch:5 step:4759 [D loss: 0.683821, acc.: 53.91%] [G loss: 0.770214]\n",
      "epoch:5 step:4760 [D loss: 0.678712, acc.: 58.59%] [G loss: 0.767985]\n",
      "epoch:5 step:4761 [D loss: 0.668750, acc.: 57.81%] [G loss: 0.751251]\n",
      "epoch:5 step:4762 [D loss: 0.665511, acc.: 60.94%] [G loss: 0.794409]\n",
      "epoch:5 step:4763 [D loss: 0.677703, acc.: 62.50%] [G loss: 0.787281]\n",
      "epoch:5 step:4764 [D loss: 0.675079, acc.: 58.59%] [G loss: 0.760477]\n",
      "epoch:5 step:4765 [D loss: 0.701614, acc.: 51.56%] [G loss: 0.772603]\n",
      "epoch:5 step:4766 [D loss: 0.701388, acc.: 50.00%] [G loss: 0.795357]\n",
      "epoch:5 step:4767 [D loss: 0.711503, acc.: 46.88%] [G loss: 0.758134]\n",
      "epoch:5 step:4768 [D loss: 0.688807, acc.: 53.12%] [G loss: 0.735696]\n",
      "epoch:5 step:4769 [D loss: 0.708131, acc.: 48.44%] [G loss: 0.736277]\n",
      "epoch:5 step:4770 [D loss: 0.696865, acc.: 50.00%] [G loss: 0.757693]\n",
      "epoch:5 step:4771 [D loss: 0.689194, acc.: 52.34%] [G loss: 0.766933]\n",
      "epoch:5 step:4772 [D loss: 0.683012, acc.: 50.00%] [G loss: 0.722857]\n",
      "epoch:5 step:4773 [D loss: 0.677639, acc.: 52.34%] [G loss: 0.766746]\n",
      "epoch:5 step:4774 [D loss: 0.682151, acc.: 59.38%] [G loss: 0.712322]\n",
      "epoch:5 step:4775 [D loss: 0.682925, acc.: 53.12%] [G loss: 0.741639]\n",
      "epoch:5 step:4776 [D loss: 0.680013, acc.: 53.12%] [G loss: 0.770122]\n",
      "epoch:5 step:4777 [D loss: 0.670725, acc.: 52.34%] [G loss: 0.773608]\n",
      "epoch:5 step:4778 [D loss: 0.659106, acc.: 62.50%] [G loss: 0.813373]\n",
      "epoch:5 step:4779 [D loss: 0.674064, acc.: 59.38%] [G loss: 0.824628]\n",
      "epoch:5 step:4780 [D loss: 0.695330, acc.: 52.34%] [G loss: 0.758139]\n",
      "epoch:5 step:4781 [D loss: 0.704197, acc.: 52.34%] [G loss: 0.763045]\n",
      "epoch:5 step:4782 [D loss: 0.680580, acc.: 57.81%] [G loss: 0.793293]\n",
      "epoch:5 step:4783 [D loss: 0.723277, acc.: 44.53%] [G loss: 0.736221]\n",
      "epoch:5 step:4784 [D loss: 0.699610, acc.: 53.91%] [G loss: 0.755501]\n",
      "epoch:5 step:4785 [D loss: 0.672485, acc.: 60.94%] [G loss: 0.754262]\n",
      "epoch:5 step:4786 [D loss: 0.695717, acc.: 50.78%] [G loss: 0.753908]\n",
      "epoch:5 step:4787 [D loss: 0.690776, acc.: 55.47%] [G loss: 0.783527]\n",
      "epoch:5 step:4788 [D loss: 0.724491, acc.: 40.62%] [G loss: 0.758838]\n",
      "epoch:5 step:4789 [D loss: 0.663149, acc.: 58.59%] [G loss: 0.807925]\n",
      "epoch:5 step:4790 [D loss: 0.673674, acc.: 57.81%] [G loss: 0.796029]\n",
      "epoch:5 step:4791 [D loss: 0.651920, acc.: 60.16%] [G loss: 0.776419]\n",
      "epoch:5 step:4792 [D loss: 0.686289, acc.: 60.94%] [G loss: 0.714842]\n",
      "epoch:5 step:4793 [D loss: 0.721004, acc.: 45.31%] [G loss: 0.739365]\n",
      "epoch:5 step:4794 [D loss: 0.697387, acc.: 54.69%] [G loss: 0.762091]\n",
      "epoch:5 step:4795 [D loss: 0.721497, acc.: 50.00%] [G loss: 0.731654]\n",
      "epoch:5 step:4796 [D loss: 0.696141, acc.: 53.12%] [G loss: 0.720338]\n",
      "epoch:5 step:4797 [D loss: 0.685057, acc.: 57.81%] [G loss: 0.737127]\n",
      "epoch:5 step:4798 [D loss: 0.696772, acc.: 46.88%] [G loss: 0.751711]\n",
      "epoch:5 step:4799 [D loss: 0.701474, acc.: 51.56%] [G loss: 0.751682]\n",
      "epoch:5 step:4800 [D loss: 0.673346, acc.: 54.69%] [G loss: 0.774923]\n",
      "##############\n",
      "[3.66166071 2.24576397 6.23780362 5.32592663 3.94440964 6.26106548\n",
      " 4.910027   5.71954911 5.37150605 4.84921297]\n",
      "##########\n",
      "epoch:5 step:4801 [D loss: 0.694762, acc.: 46.09%] [G loss: 0.798655]\n",
      "epoch:5 step:4802 [D loss: 0.679953, acc.: 54.69%] [G loss: 0.815608]\n",
      "epoch:5 step:4803 [D loss: 0.687218, acc.: 53.91%] [G loss: 0.790785]\n",
      "epoch:5 step:4804 [D loss: 0.658526, acc.: 59.38%] [G loss: 0.770126]\n",
      "epoch:5 step:4805 [D loss: 0.698367, acc.: 57.81%] [G loss: 0.823554]\n",
      "epoch:5 step:4806 [D loss: 0.717641, acc.: 46.88%] [G loss: 0.797993]\n",
      "epoch:5 step:4807 [D loss: 0.698015, acc.: 53.12%] [G loss: 0.831044]\n",
      "epoch:5 step:4808 [D loss: 0.661654, acc.: 60.16%] [G loss: 0.831279]\n",
      "epoch:5 step:4809 [D loss: 0.642938, acc.: 60.94%] [G loss: 0.857986]\n",
      "epoch:5 step:4810 [D loss: 0.674749, acc.: 60.94%] [G loss: 0.865892]\n",
      "epoch:5 step:4811 [D loss: 0.629810, acc.: 65.62%] [G loss: 0.849228]\n",
      "epoch:5 step:4812 [D loss: 0.662080, acc.: 56.25%] [G loss: 0.812326]\n",
      "epoch:5 step:4813 [D loss: 0.715962, acc.: 50.00%] [G loss: 0.811035]\n",
      "epoch:5 step:4814 [D loss: 0.728328, acc.: 41.41%] [G loss: 0.769117]\n",
      "epoch:5 step:4815 [D loss: 0.743851, acc.: 46.09%] [G loss: 0.791376]\n",
      "epoch:5 step:4816 [D loss: 0.715054, acc.: 49.22%] [G loss: 0.745025]\n",
      "epoch:5 step:4817 [D loss: 0.711013, acc.: 46.88%] [G loss: 0.739948]\n",
      "epoch:5 step:4818 [D loss: 0.701254, acc.: 46.09%] [G loss: 0.718962]\n",
      "epoch:5 step:4819 [D loss: 0.691784, acc.: 61.72%] [G loss: 0.746163]\n",
      "epoch:5 step:4820 [D loss: 0.680410, acc.: 58.59%] [G loss: 0.764040]\n",
      "epoch:5 step:4821 [D loss: 0.689728, acc.: 53.12%] [G loss: 0.734989]\n",
      "epoch:5 step:4822 [D loss: 0.682298, acc.: 49.22%] [G loss: 0.754851]\n",
      "epoch:5 step:4823 [D loss: 0.695472, acc.: 51.56%] [G loss: 0.774477]\n",
      "epoch:5 step:4824 [D loss: 0.636080, acc.: 68.75%] [G loss: 0.779855]\n",
      "epoch:5 step:4825 [D loss: 0.655774, acc.: 60.94%] [G loss: 0.779209]\n",
      "epoch:5 step:4826 [D loss: 0.677600, acc.: 62.50%] [G loss: 0.798354]\n",
      "epoch:5 step:4827 [D loss: 0.679903, acc.: 56.25%] [G loss: 0.832042]\n",
      "epoch:5 step:4828 [D loss: 0.662575, acc.: 63.28%] [G loss: 0.822106]\n",
      "epoch:5 step:4829 [D loss: 0.652260, acc.: 65.62%] [G loss: 0.758268]\n",
      "epoch:5 step:4830 [D loss: 0.717421, acc.: 52.34%] [G loss: 0.744827]\n",
      "epoch:5 step:4831 [D loss: 0.715264, acc.: 44.53%] [G loss: 0.727194]\n",
      "epoch:5 step:4832 [D loss: 0.748762, acc.: 32.81%] [G loss: 0.724054]\n",
      "epoch:5 step:4833 [D loss: 0.707941, acc.: 46.09%] [G loss: 0.749910]\n",
      "epoch:5 step:4834 [D loss: 0.695175, acc.: 48.44%] [G loss: 0.803338]\n",
      "epoch:5 step:4835 [D loss: 0.688603, acc.: 51.56%] [G loss: 0.811206]\n",
      "epoch:5 step:4836 [D loss: 0.667205, acc.: 59.38%] [G loss: 0.835705]\n",
      "epoch:5 step:4837 [D loss: 0.667566, acc.: 59.38%] [G loss: 0.866453]\n",
      "epoch:5 step:4838 [D loss: 0.693122, acc.: 55.47%] [G loss: 0.882052]\n",
      "epoch:5 step:4839 [D loss: 0.693426, acc.: 56.25%] [G loss: 0.866181]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:5 step:4840 [D loss: 0.669775, acc.: 64.06%] [G loss: 0.874179]\n",
      "epoch:5 step:4841 [D loss: 0.721919, acc.: 48.44%] [G loss: 0.777977]\n",
      "epoch:5 step:4842 [D loss: 0.665788, acc.: 57.81%] [G loss: 0.800801]\n",
      "epoch:5 step:4843 [D loss: 0.683718, acc.: 53.91%] [G loss: 0.751661]\n",
      "epoch:5 step:4844 [D loss: 0.727840, acc.: 44.53%] [G loss: 0.759262]\n",
      "epoch:5 step:4845 [D loss: 0.716505, acc.: 50.00%] [G loss: 0.763075]\n",
      "epoch:5 step:4846 [D loss: 0.702037, acc.: 51.56%] [G loss: 0.692672]\n",
      "epoch:5 step:4847 [D loss: 0.700816, acc.: 47.66%] [G loss: 0.712563]\n",
      "epoch:5 step:4848 [D loss: 0.701297, acc.: 44.53%] [G loss: 0.715674]\n",
      "epoch:5 step:4849 [D loss: 0.701426, acc.: 47.66%] [G loss: 0.730927]\n",
      "epoch:5 step:4850 [D loss: 0.694028, acc.: 48.44%] [G loss: 0.718963]\n",
      "epoch:5 step:4851 [D loss: 0.690384, acc.: 56.25%] [G loss: 0.770457]\n",
      "epoch:5 step:4852 [D loss: 0.666518, acc.: 60.94%] [G loss: 0.786777]\n",
      "epoch:5 step:4853 [D loss: 0.646424, acc.: 67.97%] [G loss: 0.820552]\n",
      "epoch:5 step:4854 [D loss: 0.678373, acc.: 59.38%] [G loss: 0.833277]\n",
      "epoch:5 step:4855 [D loss: 0.719393, acc.: 46.88%] [G loss: 0.772110]\n",
      "epoch:5 step:4856 [D loss: 0.711879, acc.: 53.12%] [G loss: 0.761526]\n",
      "epoch:5 step:4857 [D loss: 0.697730, acc.: 50.00%] [G loss: 0.743914]\n",
      "epoch:5 step:4858 [D loss: 0.694926, acc.: 51.56%] [G loss: 0.771895]\n",
      "epoch:5 step:4859 [D loss: 0.713668, acc.: 46.88%] [G loss: 0.722116]\n",
      "epoch:5 step:4860 [D loss: 0.707029, acc.: 46.09%] [G loss: 0.711408]\n",
      "epoch:5 step:4861 [D loss: 0.676377, acc.: 60.16%] [G loss: 0.757574]\n",
      "epoch:5 step:4862 [D loss: 0.693039, acc.: 57.81%] [G loss: 0.741593]\n",
      "epoch:5 step:4863 [D loss: 0.684154, acc.: 56.25%] [G loss: 0.757296]\n",
      "epoch:5 step:4864 [D loss: 0.681394, acc.: 53.12%] [G loss: 0.756033]\n",
      "epoch:5 step:4865 [D loss: 0.684352, acc.: 60.94%] [G loss: 0.753664]\n",
      "epoch:5 step:4866 [D loss: 0.688467, acc.: 53.12%] [G loss: 0.764993]\n",
      "epoch:5 step:4867 [D loss: 0.722227, acc.: 39.06%] [G loss: 0.768988]\n",
      "epoch:5 step:4868 [D loss: 0.712626, acc.: 46.88%] [G loss: 0.737628]\n",
      "epoch:5 step:4869 [D loss: 0.664559, acc.: 60.94%] [G loss: 0.750608]\n",
      "epoch:5 step:4870 [D loss: 0.670841, acc.: 54.69%] [G loss: 0.832057]\n",
      "epoch:5 step:4871 [D loss: 0.685302, acc.: 54.69%] [G loss: 0.792951]\n",
      "epoch:5 step:4872 [D loss: 0.670597, acc.: 54.69%] [G loss: 0.796365]\n",
      "epoch:5 step:4873 [D loss: 0.702218, acc.: 50.78%] [G loss: 0.775589]\n",
      "epoch:5 step:4874 [D loss: 0.686084, acc.: 50.00%] [G loss: 0.733472]\n",
      "epoch:5 step:4875 [D loss: 0.694877, acc.: 53.12%] [G loss: 0.759791]\n",
      "epoch:5 step:4876 [D loss: 0.664403, acc.: 60.16%] [G loss: 0.767529]\n",
      "epoch:5 step:4877 [D loss: 0.712200, acc.: 45.31%] [G loss: 0.758893]\n",
      "epoch:5 step:4878 [D loss: 0.696902, acc.: 46.09%] [G loss: 0.736376]\n",
      "epoch:5 step:4879 [D loss: 0.682731, acc.: 56.25%] [G loss: 0.758848]\n",
      "epoch:5 step:4880 [D loss: 0.696175, acc.: 51.56%] [G loss: 0.778650]\n",
      "epoch:5 step:4881 [D loss: 0.710033, acc.: 53.91%] [G loss: 0.752746]\n",
      "epoch:5 step:4882 [D loss: 0.668096, acc.: 64.06%] [G loss: 0.763044]\n",
      "epoch:5 step:4883 [D loss: 0.660039, acc.: 60.94%] [G loss: 0.827044]\n",
      "epoch:5 step:4884 [D loss: 0.689952, acc.: 56.25%] [G loss: 0.806015]\n",
      "epoch:5 step:4885 [D loss: 0.688431, acc.: 55.47%] [G loss: 0.817053]\n",
      "epoch:5 step:4886 [D loss: 0.681858, acc.: 58.59%] [G loss: 0.828011]\n",
      "epoch:5 step:4887 [D loss: 0.664441, acc.: 63.28%] [G loss: 0.832504]\n",
      "epoch:5 step:4888 [D loss: 0.695439, acc.: 53.12%] [G loss: 0.809052]\n",
      "epoch:5 step:4889 [D loss: 0.705356, acc.: 53.12%] [G loss: 0.749388]\n",
      "epoch:5 step:4890 [D loss: 0.687405, acc.: 53.91%] [G loss: 0.716034]\n",
      "epoch:5 step:4891 [D loss: 0.677160, acc.: 63.28%] [G loss: 0.774047]\n",
      "epoch:5 step:4892 [D loss: 0.659317, acc.: 64.84%] [G loss: 0.803142]\n",
      "epoch:5 step:4893 [D loss: 0.674847, acc.: 54.69%] [G loss: 0.812652]\n",
      "epoch:5 step:4894 [D loss: 0.669194, acc.: 56.25%] [G loss: 0.775233]\n",
      "epoch:5 step:4895 [D loss: 0.698602, acc.: 48.44%] [G loss: 0.782844]\n",
      "epoch:5 step:4896 [D loss: 0.689863, acc.: 50.78%] [G loss: 0.828193]\n",
      "epoch:5 step:4897 [D loss: 0.671036, acc.: 59.38%] [G loss: 0.809052]\n",
      "epoch:5 step:4898 [D loss: 0.691504, acc.: 52.34%] [G loss: 0.783504]\n",
      "epoch:5 step:4899 [D loss: 0.747055, acc.: 38.28%] [G loss: 0.805221]\n",
      "epoch:5 step:4900 [D loss: 0.718383, acc.: 44.53%] [G loss: 0.748666]\n",
      "epoch:5 step:4901 [D loss: 0.701306, acc.: 53.12%] [G loss: 0.806310]\n",
      "epoch:5 step:4902 [D loss: 0.708925, acc.: 50.00%] [G loss: 0.775962]\n",
      "epoch:5 step:4903 [D loss: 0.717854, acc.: 48.44%] [G loss: 0.753954]\n",
      "epoch:5 step:4904 [D loss: 0.722419, acc.: 46.88%] [G loss: 0.778667]\n",
      "epoch:5 step:4905 [D loss: 0.719664, acc.: 46.09%] [G loss: 0.735276]\n",
      "epoch:5 step:4906 [D loss: 0.673642, acc.: 57.81%] [G loss: 0.793396]\n",
      "epoch:5 step:4907 [D loss: 0.635600, acc.: 62.50%] [G loss: 0.804008]\n",
      "epoch:5 step:4908 [D loss: 0.633490, acc.: 63.28%] [G loss: 0.805509]\n",
      "epoch:5 step:4909 [D loss: 0.664030, acc.: 65.62%] [G loss: 0.806073]\n",
      "epoch:5 step:4910 [D loss: 0.718629, acc.: 45.31%] [G loss: 0.754632]\n",
      "epoch:5 step:4911 [D loss: 0.705661, acc.: 45.31%] [G loss: 0.724017]\n",
      "epoch:5 step:4912 [D loss: 0.692936, acc.: 51.56%] [G loss: 0.803091]\n",
      "epoch:5 step:4913 [D loss: 0.711716, acc.: 46.88%] [G loss: 0.723459]\n",
      "epoch:5 step:4914 [D loss: 0.700899, acc.: 53.91%] [G loss: 0.767521]\n",
      "epoch:5 step:4915 [D loss: 0.667893, acc.: 59.38%] [G loss: 0.800494]\n",
      "epoch:5 step:4916 [D loss: 0.646991, acc.: 64.06%] [G loss: 0.782693]\n",
      "epoch:5 step:4917 [D loss: 0.611511, acc.: 68.75%] [G loss: 0.770442]\n",
      "epoch:5 step:4918 [D loss: 0.684210, acc.: 53.91%] [G loss: 0.777204]\n",
      "epoch:5 step:4919 [D loss: 0.717640, acc.: 46.09%] [G loss: 0.784294]\n",
      "epoch:5 step:4920 [D loss: 0.706548, acc.: 57.81%] [G loss: 0.773834]\n",
      "epoch:5 step:4921 [D loss: 0.695671, acc.: 51.56%] [G loss: 0.772866]\n",
      "epoch:5 step:4922 [D loss: 0.683345, acc.: 50.78%] [G loss: 0.859033]\n",
      "epoch:5 step:4923 [D loss: 0.694107, acc.: 49.22%] [G loss: 0.903170]\n",
      "epoch:5 step:4924 [D loss: 0.702164, acc.: 49.22%] [G loss: 0.819044]\n",
      "epoch:5 step:4925 [D loss: 0.676398, acc.: 55.47%] [G loss: 0.843095]\n",
      "epoch:5 step:4926 [D loss: 0.677161, acc.: 61.72%] [G loss: 0.879642]\n",
      "epoch:5 step:4927 [D loss: 0.679368, acc.: 57.81%] [G loss: 0.888074]\n",
      "epoch:5 step:4928 [D loss: 0.682889, acc.: 57.81%] [G loss: 0.812990]\n",
      "epoch:5 step:4929 [D loss: 0.702981, acc.: 54.69%] [G loss: 0.780898]\n",
      "epoch:5 step:4930 [D loss: 0.686515, acc.: 53.12%] [G loss: 0.785626]\n",
      "epoch:5 step:4931 [D loss: 0.743409, acc.: 40.62%] [G loss: 0.746554]\n",
      "epoch:5 step:4932 [D loss: 0.705967, acc.: 46.88%] [G loss: 0.751721]\n",
      "epoch:5 step:4933 [D loss: 0.676044, acc.: 54.69%] [G loss: 0.787967]\n",
      "epoch:5 step:4934 [D loss: 0.710810, acc.: 52.34%] [G loss: 0.764446]\n",
      "epoch:5 step:4935 [D loss: 0.685340, acc.: 56.25%] [G loss: 0.763415]\n",
      "epoch:5 step:4936 [D loss: 0.691345, acc.: 53.91%] [G loss: 0.753874]\n",
      "epoch:5 step:4937 [D loss: 0.710083, acc.: 51.56%] [G loss: 0.773724]\n",
      "epoch:5 step:4938 [D loss: 0.684692, acc.: 50.78%] [G loss: 0.778996]\n",
      "epoch:5 step:4939 [D loss: 0.717481, acc.: 45.31%] [G loss: 0.729786]\n",
      "epoch:5 step:4940 [D loss: 0.702139, acc.: 52.34%] [G loss: 0.755679]\n",
      "epoch:5 step:4941 [D loss: 0.696875, acc.: 52.34%] [G loss: 0.728396]\n",
      "epoch:5 step:4942 [D loss: 0.679055, acc.: 54.69%] [G loss: 0.742056]\n",
      "epoch:5 step:4943 [D loss: 0.697020, acc.: 45.31%] [G loss: 0.731149]\n",
      "epoch:5 step:4944 [D loss: 0.705136, acc.: 50.78%] [G loss: 0.713957]\n",
      "epoch:5 step:4945 [D loss: 0.712557, acc.: 40.62%] [G loss: 0.735591]\n",
      "epoch:5 step:4946 [D loss: 0.681611, acc.: 58.59%] [G loss: 0.776601]\n",
      "epoch:5 step:4947 [D loss: 0.683962, acc.: 58.59%] [G loss: 0.728739]\n",
      "epoch:5 step:4948 [D loss: 0.711121, acc.: 46.09%] [G loss: 0.738470]\n",
      "epoch:5 step:4949 [D loss: 0.684859, acc.: 50.78%] [G loss: 0.749416]\n",
      "epoch:5 step:4950 [D loss: 0.692239, acc.: 53.12%] [G loss: 0.737012]\n",
      "epoch:5 step:4951 [D loss: 0.713136, acc.: 48.44%] [G loss: 0.759037]\n",
      "epoch:5 step:4952 [D loss: 0.729050, acc.: 46.88%] [G loss: 0.729318]\n",
      "epoch:5 step:4953 [D loss: 0.683352, acc.: 56.25%] [G loss: 0.781114]\n",
      "epoch:5 step:4954 [D loss: 0.666963, acc.: 57.03%] [G loss: 0.769934]\n",
      "epoch:5 step:4955 [D loss: 0.669457, acc.: 60.94%] [G loss: 0.778796]\n",
      "epoch:5 step:4956 [D loss: 0.659773, acc.: 63.28%] [G loss: 0.798456]\n",
      "epoch:5 step:4957 [D loss: 0.681473, acc.: 50.78%] [G loss: 0.818110]\n",
      "epoch:5 step:4958 [D loss: 0.669382, acc.: 57.03%] [G loss: 0.818079]\n",
      "epoch:5 step:4959 [D loss: 0.645002, acc.: 63.28%] [G loss: 0.771356]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:5 step:4960 [D loss: 0.672288, acc.: 55.47%] [G loss: 0.713879]\n",
      "epoch:5 step:4961 [D loss: 0.701981, acc.: 55.47%] [G loss: 0.806113]\n",
      "epoch:5 step:4962 [D loss: 0.665116, acc.: 60.16%] [G loss: 0.801377]\n",
      "epoch:5 step:4963 [D loss: 0.751756, acc.: 45.31%] [G loss: 0.720957]\n",
      "epoch:5 step:4964 [D loss: 0.705969, acc.: 48.44%] [G loss: 0.739049]\n",
      "epoch:5 step:4965 [D loss: 0.692419, acc.: 50.78%] [G loss: 0.730231]\n",
      "epoch:5 step:4966 [D loss: 0.764505, acc.: 38.28%] [G loss: 0.697557]\n",
      "epoch:5 step:4967 [D loss: 0.729216, acc.: 44.53%] [G loss: 0.749420]\n",
      "epoch:5 step:4968 [D loss: 0.678897, acc.: 58.59%] [G loss: 0.740010]\n",
      "epoch:5 step:4969 [D loss: 0.663204, acc.: 59.38%] [G loss: 0.779056]\n",
      "epoch:5 step:4970 [D loss: 0.662501, acc.: 53.12%] [G loss: 0.764163]\n",
      "epoch:5 step:4971 [D loss: 0.667483, acc.: 57.03%] [G loss: 0.711718]\n",
      "epoch:5 step:4972 [D loss: 0.675375, acc.: 54.69%] [G loss: 0.799075]\n",
      "epoch:5 step:4973 [D loss: 0.668243, acc.: 60.94%] [G loss: 0.761249]\n",
      "epoch:5 step:4974 [D loss: 0.685513, acc.: 53.12%] [G loss: 0.820207]\n",
      "epoch:5 step:4975 [D loss: 0.656120, acc.: 58.59%] [G loss: 0.795493]\n",
      "epoch:5 step:4976 [D loss: 0.696243, acc.: 50.00%] [G loss: 0.760312]\n",
      "epoch:5 step:4977 [D loss: 0.677906, acc.: 58.59%] [G loss: 0.711372]\n",
      "epoch:5 step:4978 [D loss: 0.713687, acc.: 52.34%] [G loss: 0.734517]\n",
      "epoch:5 step:4979 [D loss: 0.723122, acc.: 44.53%] [G loss: 0.774979]\n",
      "epoch:5 step:4980 [D loss: 0.716676, acc.: 44.53%] [G loss: 0.715312]\n",
      "epoch:5 step:4981 [D loss: 0.707663, acc.: 48.44%] [G loss: 0.717582]\n",
      "epoch:5 step:4982 [D loss: 0.712354, acc.: 44.53%] [G loss: 0.740129]\n",
      "epoch:5 step:4983 [D loss: 0.699821, acc.: 49.22%] [G loss: 0.764598]\n",
      "epoch:5 step:4984 [D loss: 0.688271, acc.: 56.25%] [G loss: 0.754979]\n",
      "epoch:5 step:4985 [D loss: 0.691208, acc.: 62.50%] [G loss: 0.774645]\n",
      "epoch:5 step:4986 [D loss: 0.716677, acc.: 44.53%] [G loss: 0.711813]\n",
      "epoch:5 step:4987 [D loss: 0.697978, acc.: 50.78%] [G loss: 0.750934]\n",
      "epoch:5 step:4988 [D loss: 0.680522, acc.: 56.25%] [G loss: 0.773009]\n",
      "epoch:5 step:4989 [D loss: 0.698390, acc.: 54.69%] [G loss: 0.791149]\n",
      "epoch:5 step:4990 [D loss: 0.701674, acc.: 50.00%] [G loss: 0.717378]\n",
      "epoch:5 step:4991 [D loss: 0.718436, acc.: 50.00%] [G loss: 0.732424]\n",
      "epoch:5 step:4992 [D loss: 0.692482, acc.: 51.56%] [G loss: 0.747437]\n",
      "epoch:5 step:4993 [D loss: 0.716418, acc.: 42.97%] [G loss: 0.712471]\n",
      "epoch:5 step:4994 [D loss: 0.693745, acc.: 53.12%] [G loss: 0.703839]\n",
      "epoch:5 step:4995 [D loss: 0.692293, acc.: 53.91%] [G loss: 0.751250]\n",
      "epoch:5 step:4996 [D loss: 0.686618, acc.: 52.34%] [G loss: 0.742934]\n",
      "epoch:5 step:4997 [D loss: 0.670279, acc.: 53.91%] [G loss: 0.740662]\n",
      "epoch:5 step:4998 [D loss: 0.654227, acc.: 60.94%] [G loss: 0.728489]\n",
      "epoch:5 step:4999 [D loss: 0.618023, acc.: 64.84%] [G loss: 0.780662]\n",
      "epoch:5 step:5000 [D loss: 0.629991, acc.: 60.94%] [G loss: 0.748474]\n",
      "##############\n",
      "[3.98022147 1.91362262 6.06424516 5.41377913 3.8549082  5.88232806\n",
      " 5.14874232 5.30092351 5.52495539 4.79908966]\n",
      "##########\n",
      "epoch:5 step:5001 [D loss: 0.698022, acc.: 42.97%] [G loss: 0.771391]\n",
      "epoch:5 step:5002 [D loss: 0.690390, acc.: 52.34%] [G loss: 0.770166]\n",
      "epoch:5 step:5003 [D loss: 0.695443, acc.: 54.69%] [G loss: 0.765626]\n",
      "epoch:5 step:5004 [D loss: 0.682675, acc.: 57.03%] [G loss: 0.781193]\n",
      "epoch:5 step:5005 [D loss: 0.710178, acc.: 43.75%] [G loss: 0.792440]\n",
      "epoch:5 step:5006 [D loss: 0.724928, acc.: 50.00%] [G loss: 0.744696]\n",
      "epoch:5 step:5007 [D loss: 0.704046, acc.: 53.12%] [G loss: 0.770960]\n",
      "epoch:5 step:5008 [D loss: 0.714598, acc.: 49.22%] [G loss: 0.756313]\n",
      "epoch:5 step:5009 [D loss: 0.718526, acc.: 50.00%] [G loss: 0.732887]\n",
      "epoch:5 step:5010 [D loss: 0.698674, acc.: 51.56%] [G loss: 0.721005]\n",
      "epoch:5 step:5011 [D loss: 0.690206, acc.: 54.69%] [G loss: 0.735951]\n",
      "epoch:5 step:5012 [D loss: 0.670023, acc.: 55.47%] [G loss: 0.787124]\n",
      "epoch:5 step:5013 [D loss: 0.668097, acc.: 55.47%] [G loss: 0.782865]\n",
      "epoch:5 step:5014 [D loss: 0.706435, acc.: 45.31%] [G loss: 0.876266]\n",
      "epoch:5 step:5015 [D loss: 0.689208, acc.: 56.25%] [G loss: 0.804149]\n",
      "epoch:5 step:5016 [D loss: 0.673274, acc.: 60.94%] [G loss: 0.827084]\n",
      "epoch:5 step:5017 [D loss: 0.664123, acc.: 64.06%] [G loss: 0.795784]\n",
      "epoch:5 step:5018 [D loss: 0.685661, acc.: 58.59%] [G loss: 0.798993]\n",
      "epoch:5 step:5019 [D loss: 0.685772, acc.: 55.47%] [G loss: 0.783162]\n",
      "epoch:5 step:5020 [D loss: 0.710674, acc.: 53.91%] [G loss: 0.729233]\n",
      "epoch:5 step:5021 [D loss: 0.644164, acc.: 62.50%] [G loss: 0.772064]\n",
      "epoch:5 step:5022 [D loss: 0.653835, acc.: 62.50%] [G loss: 0.748007]\n",
      "epoch:5 step:5023 [D loss: 0.719763, acc.: 46.88%] [G loss: 0.707133]\n",
      "epoch:5 step:5024 [D loss: 0.691836, acc.: 55.47%] [G loss: 0.743392]\n",
      "epoch:5 step:5025 [D loss: 0.711713, acc.: 50.78%] [G loss: 0.736042]\n",
      "epoch:5 step:5026 [D loss: 0.663468, acc.: 53.12%] [G loss: 0.757048]\n",
      "epoch:5 step:5027 [D loss: 0.689479, acc.: 50.78%] [G loss: 0.750589]\n",
      "epoch:5 step:5028 [D loss: 0.680177, acc.: 52.34%] [G loss: 0.721605]\n",
      "epoch:5 step:5029 [D loss: 0.654173, acc.: 61.72%] [G loss: 0.750445]\n",
      "epoch:5 step:5030 [D loss: 0.702218, acc.: 49.22%] [G loss: 0.757424]\n",
      "epoch:5 step:5031 [D loss: 0.690391, acc.: 51.56%] [G loss: 0.754475]\n",
      "epoch:5 step:5032 [D loss: 0.660441, acc.: 64.06%] [G loss: 0.778182]\n",
      "epoch:5 step:5033 [D loss: 0.725290, acc.: 45.31%] [G loss: 0.824418]\n",
      "epoch:5 step:5034 [D loss: 0.737541, acc.: 45.31%] [G loss: 0.789903]\n",
      "epoch:5 step:5035 [D loss: 0.712441, acc.: 52.34%] [G loss: 0.756654]\n",
      "epoch:5 step:5036 [D loss: 0.714384, acc.: 46.88%] [G loss: 0.739989]\n",
      "epoch:5 step:5037 [D loss: 0.700645, acc.: 51.56%] [G loss: 0.756126]\n",
      "epoch:5 step:5038 [D loss: 0.712050, acc.: 42.97%] [G loss: 0.731129]\n",
      "epoch:5 step:5039 [D loss: 0.684583, acc.: 53.91%] [G loss: 0.746653]\n",
      "epoch:5 step:5040 [D loss: 0.687814, acc.: 57.03%] [G loss: 0.773380]\n",
      "epoch:5 step:5041 [D loss: 0.688057, acc.: 56.25%] [G loss: 0.813075]\n",
      "epoch:5 step:5042 [D loss: 0.702974, acc.: 46.09%] [G loss: 0.805259]\n",
      "epoch:5 step:5043 [D loss: 0.642442, acc.: 67.97%] [G loss: 0.838671]\n",
      "epoch:5 step:5044 [D loss: 0.650850, acc.: 61.72%] [G loss: 0.816924]\n",
      "epoch:5 step:5045 [D loss: 0.640103, acc.: 66.41%] [G loss: 0.798858]\n",
      "epoch:5 step:5046 [D loss: 0.653349, acc.: 60.94%] [G loss: 0.851323]\n",
      "epoch:5 step:5047 [D loss: 0.694359, acc.: 53.91%] [G loss: 0.823491]\n",
      "epoch:5 step:5048 [D loss: 0.697099, acc.: 53.12%] [G loss: 0.789636]\n",
      "epoch:5 step:5049 [D loss: 0.665123, acc.: 59.38%] [G loss: 0.798945]\n",
      "epoch:5 step:5050 [D loss: 0.712226, acc.: 47.66%] [G loss: 0.807519]\n",
      "epoch:5 step:5051 [D loss: 0.711468, acc.: 52.34%] [G loss: 0.740362]\n",
      "epoch:5 step:5052 [D loss: 0.710242, acc.: 49.22%] [G loss: 0.736724]\n",
      "epoch:5 step:5053 [D loss: 0.685879, acc.: 50.78%] [G loss: 0.723715]\n",
      "epoch:5 step:5054 [D loss: 0.707559, acc.: 53.12%] [G loss: 0.706637]\n",
      "epoch:5 step:5055 [D loss: 0.706112, acc.: 49.22%] [G loss: 0.790018]\n",
      "epoch:5 step:5056 [D loss: 0.722914, acc.: 47.66%] [G loss: 0.785622]\n",
      "epoch:5 step:5057 [D loss: 0.677036, acc.: 56.25%] [G loss: 0.769424]\n",
      "epoch:5 step:5058 [D loss: 0.673378, acc.: 53.12%] [G loss: 0.866978]\n",
      "epoch:5 step:5059 [D loss: 0.635854, acc.: 67.97%] [G loss: 0.814586]\n",
      "epoch:5 step:5060 [D loss: 0.671934, acc.: 56.25%] [G loss: 0.864687]\n",
      "epoch:5 step:5061 [D loss: 0.715874, acc.: 50.00%] [G loss: 0.732398]\n",
      "epoch:5 step:5062 [D loss: 0.693044, acc.: 57.03%] [G loss: 0.722917]\n",
      "epoch:5 step:5063 [D loss: 0.699142, acc.: 50.00%] [G loss: 0.736246]\n",
      "epoch:5 step:5064 [D loss: 0.693718, acc.: 56.25%] [G loss: 0.719620]\n",
      "epoch:5 step:5065 [D loss: 0.695514, acc.: 57.81%] [G loss: 0.735409]\n",
      "epoch:5 step:5066 [D loss: 0.693142, acc.: 53.12%] [G loss: 0.755956]\n",
      "epoch:5 step:5067 [D loss: 0.715757, acc.: 45.31%] [G loss: 0.740567]\n",
      "epoch:5 step:5068 [D loss: 0.705202, acc.: 44.53%] [G loss: 0.758457]\n",
      "epoch:5 step:5069 [D loss: 0.690107, acc.: 48.44%] [G loss: 0.718554]\n",
      "epoch:5 step:5070 [D loss: 0.671137, acc.: 62.50%] [G loss: 0.739365]\n",
      "epoch:5 step:5071 [D loss: 0.705057, acc.: 49.22%] [G loss: 0.762002]\n",
      "epoch:5 step:5072 [D loss: 0.691336, acc.: 58.59%] [G loss: 0.767383]\n",
      "epoch:5 step:5073 [D loss: 0.672332, acc.: 56.25%] [G loss: 0.784235]\n",
      "epoch:5 step:5074 [D loss: 0.706311, acc.: 50.78%] [G loss: 0.789482]\n",
      "epoch:5 step:5075 [D loss: 0.721739, acc.: 43.75%] [G loss: 0.726786]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:5 step:5076 [D loss: 0.689429, acc.: 53.91%] [G loss: 0.779475]\n",
      "epoch:5 step:5077 [D loss: 0.716173, acc.: 46.88%] [G loss: 0.754421]\n",
      "epoch:5 step:5078 [D loss: 0.716296, acc.: 49.22%] [G loss: 0.723840]\n",
      "epoch:5 step:5079 [D loss: 0.710279, acc.: 53.12%] [G loss: 0.707422]\n",
      "epoch:5 step:5080 [D loss: 0.730856, acc.: 37.50%] [G loss: 0.715971]\n",
      "epoch:5 step:5081 [D loss: 0.688017, acc.: 54.69%] [G loss: 0.719524]\n",
      "epoch:5 step:5082 [D loss: 0.689109, acc.: 57.03%] [G loss: 0.732123]\n",
      "epoch:5 step:5083 [D loss: 0.683503, acc.: 58.59%] [G loss: 0.737699]\n",
      "epoch:5 step:5084 [D loss: 0.660964, acc.: 60.16%] [G loss: 0.710703]\n",
      "epoch:5 step:5085 [D loss: 0.672560, acc.: 57.81%] [G loss: 0.772068]\n",
      "epoch:5 step:5086 [D loss: 0.702215, acc.: 49.22%] [G loss: 0.789953]\n",
      "epoch:5 step:5087 [D loss: 0.649683, acc.: 66.41%] [G loss: 0.752450]\n",
      "epoch:5 step:5088 [D loss: 0.663067, acc.: 66.41%] [G loss: 0.801741]\n",
      "epoch:5 step:5089 [D loss: 0.661983, acc.: 59.38%] [G loss: 0.815646]\n",
      "epoch:5 step:5090 [D loss: 0.659138, acc.: 64.84%] [G loss: 0.826655]\n",
      "epoch:5 step:5091 [D loss: 0.622492, acc.: 68.75%] [G loss: 0.852626]\n",
      "epoch:5 step:5092 [D loss: 0.647710, acc.: 61.72%] [G loss: 0.874188]\n",
      "epoch:5 step:5093 [D loss: 0.642686, acc.: 65.62%] [G loss: 0.772966]\n",
      "epoch:5 step:5094 [D loss: 0.672404, acc.: 57.81%] [G loss: 0.813110]\n",
      "epoch:5 step:5095 [D loss: 0.754790, acc.: 46.88%] [G loss: 0.709323]\n",
      "epoch:5 step:5096 [D loss: 0.759256, acc.: 39.84%] [G loss: 0.740653]\n",
      "epoch:5 step:5097 [D loss: 0.725495, acc.: 46.09%] [G loss: 0.712816]\n",
      "epoch:5 step:5098 [D loss: 0.698549, acc.: 50.00%] [G loss: 0.739415]\n",
      "epoch:5 step:5099 [D loss: 0.692617, acc.: 57.03%] [G loss: 0.716502]\n",
      "epoch:5 step:5100 [D loss: 0.687698, acc.: 53.12%] [G loss: 0.763925]\n",
      "epoch:5 step:5101 [D loss: 0.710360, acc.: 54.69%] [G loss: 0.733492]\n",
      "epoch:5 step:5102 [D loss: 0.688452, acc.: 52.34%] [G loss: 0.760361]\n",
      "epoch:5 step:5103 [D loss: 0.706524, acc.: 46.88%] [G loss: 0.820888]\n",
      "epoch:5 step:5104 [D loss: 0.677229, acc.: 58.59%] [G loss: 0.783788]\n",
      "epoch:5 step:5105 [D loss: 0.668912, acc.: 57.81%] [G loss: 0.778481]\n",
      "epoch:5 step:5106 [D loss: 0.683122, acc.: 54.69%] [G loss: 0.786170]\n",
      "epoch:5 step:5107 [D loss: 0.686560, acc.: 53.12%] [G loss: 0.819276]\n",
      "epoch:5 step:5108 [D loss: 0.659079, acc.: 59.38%] [G loss: 0.774111]\n",
      "epoch:5 step:5109 [D loss: 0.686969, acc.: 52.34%] [G loss: 0.825435]\n",
      "epoch:5 step:5110 [D loss: 0.670275, acc.: 56.25%] [G loss: 0.766504]\n",
      "epoch:5 step:5111 [D loss: 0.680774, acc.: 53.91%] [G loss: 0.828043]\n",
      "epoch:5 step:5112 [D loss: 0.679337, acc.: 60.94%] [G loss: 0.741000]\n",
      "epoch:5 step:5113 [D loss: 0.727643, acc.: 52.34%] [G loss: 0.828450]\n",
      "epoch:5 step:5114 [D loss: 0.638951, acc.: 60.94%] [G loss: 0.822658]\n",
      "epoch:5 step:5115 [D loss: 0.673456, acc.: 53.91%] [G loss: 0.838535]\n",
      "epoch:5 step:5116 [D loss: 0.703463, acc.: 46.09%] [G loss: 0.835840]\n",
      "epoch:5 step:5117 [D loss: 0.688196, acc.: 56.25%] [G loss: 0.868455]\n",
      "epoch:5 step:5118 [D loss: 0.707258, acc.: 48.44%] [G loss: 0.816968]\n",
      "epoch:5 step:5119 [D loss: 0.689475, acc.: 55.47%] [G loss: 0.812569]\n",
      "epoch:5 step:5120 [D loss: 0.646345, acc.: 62.50%] [G loss: 0.803814]\n",
      "epoch:5 step:5121 [D loss: 0.678321, acc.: 59.38%] [G loss: 0.802754]\n",
      "epoch:5 step:5122 [D loss: 0.764056, acc.: 42.19%] [G loss: 0.735818]\n",
      "epoch:5 step:5123 [D loss: 0.739832, acc.: 39.84%] [G loss: 0.745921]\n",
      "epoch:5 step:5124 [D loss: 0.731159, acc.: 46.09%] [G loss: 0.734016]\n",
      "epoch:5 step:5125 [D loss: 0.713796, acc.: 49.22%] [G loss: 0.732869]\n",
      "epoch:5 step:5126 [D loss: 0.714990, acc.: 48.44%] [G loss: 0.736651]\n",
      "epoch:5 step:5127 [D loss: 0.691021, acc.: 56.25%] [G loss: 0.777859]\n",
      "epoch:5 step:5128 [D loss: 0.695365, acc.: 54.69%] [G loss: 0.779713]\n",
      "epoch:5 step:5129 [D loss: 0.662263, acc.: 61.72%] [G loss: 0.803663]\n",
      "epoch:5 step:5130 [D loss: 0.671477, acc.: 57.03%] [G loss: 0.794390]\n",
      "epoch:5 step:5131 [D loss: 0.676743, acc.: 50.78%] [G loss: 0.791234]\n",
      "epoch:5 step:5132 [D loss: 0.658169, acc.: 57.03%] [G loss: 0.810176]\n",
      "epoch:5 step:5133 [D loss: 0.678961, acc.: 59.38%] [G loss: 0.818804]\n",
      "epoch:5 step:5134 [D loss: 0.698727, acc.: 54.69%] [G loss: 0.774718]\n",
      "epoch:5 step:5135 [D loss: 0.692699, acc.: 49.22%] [G loss: 0.772233]\n",
      "epoch:5 step:5136 [D loss: 0.671428, acc.: 60.94%] [G loss: 0.752427]\n",
      "epoch:5 step:5137 [D loss: 0.678045, acc.: 57.81%] [G loss: 0.770689]\n",
      "epoch:5 step:5138 [D loss: 0.682089, acc.: 54.69%] [G loss: 0.779408]\n",
      "epoch:5 step:5139 [D loss: 0.687286, acc.: 55.47%] [G loss: 0.766510]\n",
      "epoch:5 step:5140 [D loss: 0.702098, acc.: 57.03%] [G loss: 0.792365]\n",
      "epoch:5 step:5141 [D loss: 0.713040, acc.: 53.91%] [G loss: 0.804608]\n",
      "epoch:5 step:5142 [D loss: 0.662201, acc.: 62.50%] [G loss: 0.757923]\n",
      "epoch:5 step:5143 [D loss: 0.723719, acc.: 41.41%] [G loss: 0.758194]\n",
      "epoch:5 step:5144 [D loss: 0.655730, acc.: 60.94%] [G loss: 0.829894]\n",
      "epoch:5 step:5145 [D loss: 0.701736, acc.: 52.34%] [G loss: 0.791721]\n",
      "epoch:5 step:5146 [D loss: 0.694338, acc.: 50.78%] [G loss: 0.766369]\n",
      "epoch:5 step:5147 [D loss: 0.702649, acc.: 44.53%] [G loss: 0.792159]\n",
      "epoch:5 step:5148 [D loss: 0.661194, acc.: 65.62%] [G loss: 0.799737]\n",
      "epoch:5 step:5149 [D loss: 0.677579, acc.: 54.69%] [G loss: 0.802750]\n",
      "epoch:5 step:5150 [D loss: 0.647807, acc.: 67.19%] [G loss: 0.783752]\n",
      "epoch:5 step:5151 [D loss: 0.683296, acc.: 54.69%] [G loss: 0.817842]\n",
      "epoch:5 step:5152 [D loss: 0.670452, acc.: 55.47%] [G loss: 0.744773]\n",
      "epoch:5 step:5153 [D loss: 0.666286, acc.: 57.81%] [G loss: 0.736530]\n",
      "epoch:5 step:5154 [D loss: 0.679836, acc.: 54.69%] [G loss: 0.755880]\n",
      "epoch:5 step:5155 [D loss: 0.698248, acc.: 57.81%] [G loss: 0.759695]\n",
      "epoch:5 step:5156 [D loss: 0.697840, acc.: 53.12%] [G loss: 0.743492]\n",
      "epoch:5 step:5157 [D loss: 0.711029, acc.: 48.44%] [G loss: 0.759591]\n",
      "epoch:5 step:5158 [D loss: 0.725537, acc.: 48.44%] [G loss: 0.784946]\n",
      "epoch:5 step:5159 [D loss: 0.699026, acc.: 57.03%] [G loss: 0.804966]\n",
      "epoch:5 step:5160 [D loss: 0.676690, acc.: 57.81%] [G loss: 0.878761]\n",
      "epoch:5 step:5161 [D loss: 0.655213, acc.: 63.28%] [G loss: 0.903098]\n",
      "epoch:5 step:5162 [D loss: 0.676809, acc.: 53.91%] [G loss: 0.932948]\n",
      "epoch:5 step:5163 [D loss: 0.665617, acc.: 62.50%] [G loss: 0.999116]\n",
      "epoch:5 step:5164 [D loss: 0.740246, acc.: 46.09%] [G loss: 0.828718]\n",
      "epoch:5 step:5165 [D loss: 0.731281, acc.: 42.97%] [G loss: 0.809553]\n",
      "epoch:5 step:5166 [D loss: 0.732616, acc.: 37.50%] [G loss: 0.741673]\n",
      "epoch:5 step:5167 [D loss: 0.690926, acc.: 51.56%] [G loss: 0.700038]\n",
      "epoch:5 step:5168 [D loss: 0.693685, acc.: 53.91%] [G loss: 0.711681]\n",
      "epoch:5 step:5169 [D loss: 0.716910, acc.: 45.31%] [G loss: 0.716717]\n",
      "epoch:5 step:5170 [D loss: 0.701618, acc.: 50.78%] [G loss: 0.737888]\n",
      "epoch:5 step:5171 [D loss: 0.714583, acc.: 42.19%] [G loss: 0.703557]\n",
      "epoch:5 step:5172 [D loss: 0.702576, acc.: 53.12%] [G loss: 0.733758]\n",
      "epoch:5 step:5173 [D loss: 0.703141, acc.: 50.78%] [G loss: 0.744868]\n",
      "epoch:5 step:5174 [D loss: 0.703160, acc.: 47.66%] [G loss: 0.737889]\n",
      "epoch:5 step:5175 [D loss: 0.685636, acc.: 48.44%] [G loss: 0.735688]\n",
      "epoch:5 step:5176 [D loss: 0.676258, acc.: 58.59%] [G loss: 0.756564]\n",
      "epoch:5 step:5177 [D loss: 0.678841, acc.: 55.47%] [G loss: 0.752325]\n",
      "epoch:5 step:5178 [D loss: 0.674044, acc.: 67.19%] [G loss: 0.735748]\n",
      "epoch:5 step:5179 [D loss: 0.671891, acc.: 62.50%] [G loss: 0.743917]\n",
      "epoch:5 step:5180 [D loss: 0.667989, acc.: 62.50%] [G loss: 0.740642]\n",
      "epoch:5 step:5181 [D loss: 0.657216, acc.: 66.41%] [G loss: 0.773693]\n",
      "epoch:5 step:5182 [D loss: 0.664193, acc.: 64.84%] [G loss: 0.734559]\n",
      "epoch:5 step:5183 [D loss: 0.647035, acc.: 62.50%] [G loss: 0.769819]\n",
      "epoch:5 step:5184 [D loss: 0.655421, acc.: 61.72%] [G loss: 0.726433]\n",
      "epoch:5 step:5185 [D loss: 0.715827, acc.: 52.34%] [G loss: 0.742558]\n",
      "epoch:5 step:5186 [D loss: 0.744302, acc.: 40.62%] [G loss: 0.814666]\n",
      "epoch:5 step:5187 [D loss: 0.703078, acc.: 48.44%] [G loss: 0.779742]\n",
      "epoch:5 step:5188 [D loss: 0.705352, acc.: 54.69%] [G loss: 0.836099]\n",
      "epoch:5 step:5189 [D loss: 0.674683, acc.: 60.94%] [G loss: 0.833779]\n",
      "epoch:5 step:5190 [D loss: 0.664128, acc.: 55.47%] [G loss: 0.839728]\n",
      "epoch:5 step:5191 [D loss: 0.661902, acc.: 57.81%] [G loss: 0.845468]\n",
      "epoch:5 step:5192 [D loss: 0.693362, acc.: 56.25%] [G loss: 0.824793]\n",
      "epoch:5 step:5193 [D loss: 0.673889, acc.: 55.47%] [G loss: 0.818541]\n",
      "epoch:5 step:5194 [D loss: 0.774576, acc.: 41.41%] [G loss: 0.782635]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:5 step:5195 [D loss: 0.739377, acc.: 39.84%] [G loss: 0.713692]\n",
      "epoch:5 step:5196 [D loss: 0.743162, acc.: 29.69%] [G loss: 0.768373]\n",
      "epoch:5 step:5197 [D loss: 0.721132, acc.: 38.28%] [G loss: 0.733609]\n",
      "epoch:5 step:5198 [D loss: 0.676549, acc.: 55.47%] [G loss: 0.738531]\n",
      "epoch:5 step:5199 [D loss: 0.685887, acc.: 54.69%] [G loss: 0.781222]\n",
      "epoch:5 step:5200 [D loss: 0.657231, acc.: 60.94%] [G loss: 0.746095]\n",
      "##############\n",
      "[4.5411535  2.16026845 6.0854286  5.19086593 4.08243243 6.28727463\n",
      " 4.85204809 4.94695485 5.30759348 4.92469967]\n",
      "##########\n",
      "epoch:5 step:5201 [D loss: 0.671178, acc.: 62.50%] [G loss: 0.784856]\n",
      "epoch:5 step:5202 [D loss: 0.689193, acc.: 57.03%] [G loss: 0.766345]\n",
      "epoch:5 step:5203 [D loss: 0.688936, acc.: 57.81%] [G loss: 0.780603]\n",
      "epoch:5 step:5204 [D loss: 0.681881, acc.: 58.59%] [G loss: 0.755222]\n",
      "epoch:5 step:5205 [D loss: 0.679190, acc.: 54.69%] [G loss: 0.760187]\n",
      "epoch:5 step:5206 [D loss: 0.671410, acc.: 64.84%] [G loss: 0.756388]\n",
      "epoch:5 step:5207 [D loss: 0.678206, acc.: 58.59%] [G loss: 0.749783]\n",
      "epoch:5 step:5208 [D loss: 0.642078, acc.: 67.97%] [G loss: 0.772877]\n",
      "epoch:5 step:5209 [D loss: 0.668111, acc.: 59.38%] [G loss: 0.758778]\n",
      "epoch:5 step:5210 [D loss: 0.698535, acc.: 55.47%] [G loss: 0.735450]\n",
      "epoch:5 step:5211 [D loss: 0.714463, acc.: 46.88%] [G loss: 0.748411]\n",
      "epoch:5 step:5212 [D loss: 0.711184, acc.: 50.78%] [G loss: 0.740110]\n",
      "epoch:5 step:5213 [D loss: 0.713583, acc.: 47.66%] [G loss: 0.726923]\n",
      "epoch:5 step:5214 [D loss: 0.723819, acc.: 50.00%] [G loss: 0.782804]\n",
      "epoch:5 step:5215 [D loss: 0.674913, acc.: 57.81%] [G loss: 0.796368]\n",
      "epoch:5 step:5216 [D loss: 0.681515, acc.: 57.03%] [G loss: 0.849720]\n",
      "epoch:5 step:5217 [D loss: 0.667981, acc.: 60.94%] [G loss: 0.847182]\n",
      "epoch:5 step:5218 [D loss: 0.666278, acc.: 59.38%] [G loss: 0.815799]\n",
      "epoch:5 step:5219 [D loss: 0.659049, acc.: 63.28%] [G loss: 0.862114]\n",
      "epoch:5 step:5220 [D loss: 0.690060, acc.: 53.12%] [G loss: 0.840082]\n",
      "epoch:5 step:5221 [D loss: 0.723691, acc.: 48.44%] [G loss: 0.779554]\n",
      "epoch:5 step:5222 [D loss: 0.692029, acc.: 50.78%] [G loss: 0.740265]\n",
      "epoch:5 step:5223 [D loss: 0.710497, acc.: 51.56%] [G loss: 0.768898]\n",
      "epoch:5 step:5224 [D loss: 0.741289, acc.: 46.09%] [G loss: 0.763703]\n",
      "epoch:5 step:5225 [D loss: 0.696767, acc.: 50.00%] [G loss: 0.758656]\n",
      "epoch:5 step:5226 [D loss: 0.684473, acc.: 52.34%] [G loss: 0.751354]\n",
      "epoch:5 step:5227 [D loss: 0.729023, acc.: 37.50%] [G loss: 0.745437]\n",
      "epoch:5 step:5228 [D loss: 0.699086, acc.: 47.66%] [G loss: 0.726916]\n",
      "epoch:5 step:5229 [D loss: 0.676449, acc.: 58.59%] [G loss: 0.761447]\n",
      "epoch:5 step:5230 [D loss: 0.693277, acc.: 50.00%] [G loss: 0.742392]\n",
      "epoch:5 step:5231 [D loss: 0.667911, acc.: 60.94%] [G loss: 0.726741]\n",
      "epoch:5 step:5232 [D loss: 0.658490, acc.: 64.06%] [G loss: 0.735339]\n",
      "epoch:5 step:5233 [D loss: 0.679651, acc.: 57.81%] [G loss: 0.770447]\n",
      "epoch:5 step:5234 [D loss: 0.693969, acc.: 50.00%] [G loss: 0.799736]\n",
      "epoch:5 step:5235 [D loss: 0.669545, acc.: 61.72%] [G loss: 0.705864]\n",
      "epoch:5 step:5236 [D loss: 0.664394, acc.: 60.94%] [G loss: 0.746579]\n",
      "epoch:5 step:5237 [D loss: 0.691892, acc.: 58.59%] [G loss: 0.803087]\n",
      "epoch:5 step:5238 [D loss: 0.709938, acc.: 50.78%] [G loss: 0.798677]\n",
      "epoch:5 step:5239 [D loss: 0.680567, acc.: 55.47%] [G loss: 0.813978]\n",
      "epoch:5 step:5240 [D loss: 0.685779, acc.: 54.69%] [G loss: 0.765901]\n",
      "epoch:5 step:5241 [D loss: 0.691573, acc.: 58.59%] [G loss: 0.737733]\n",
      "epoch:5 step:5242 [D loss: 0.668738, acc.: 57.81%] [G loss: 0.782128]\n",
      "epoch:5 step:5243 [D loss: 0.686800, acc.: 60.16%] [G loss: 0.790664]\n",
      "epoch:5 step:5244 [D loss: 0.745164, acc.: 44.53%] [G loss: 0.770549]\n",
      "epoch:5 step:5245 [D loss: 0.699857, acc.: 52.34%] [G loss: 0.783090]\n",
      "epoch:5 step:5246 [D loss: 0.641169, acc.: 64.06%] [G loss: 0.833034]\n",
      "epoch:5 step:5247 [D loss: 0.673885, acc.: 57.03%] [G loss: 0.835768]\n",
      "epoch:5 step:5248 [D loss: 0.655940, acc.: 62.50%] [G loss: 0.806242]\n",
      "epoch:5 step:5249 [D loss: 0.671774, acc.: 57.03%] [G loss: 0.797244]\n",
      "epoch:5 step:5250 [D loss: 0.658363, acc.: 62.50%] [G loss: 0.785784]\n",
      "epoch:5 step:5251 [D loss: 0.635439, acc.: 69.53%] [G loss: 0.890900]\n",
      "epoch:5 step:5252 [D loss: 0.604878, acc.: 71.88%] [G loss: 0.913642]\n",
      "epoch:5 step:5253 [D loss: 0.622702, acc.: 63.28%] [G loss: 0.865929]\n",
      "epoch:5 step:5254 [D loss: 0.733007, acc.: 53.12%] [G loss: 0.851677]\n",
      "epoch:5 step:5255 [D loss: 0.648425, acc.: 66.41%] [G loss: 0.843001]\n",
      "epoch:5 step:5256 [D loss: 0.676358, acc.: 56.25%] [G loss: 0.816416]\n",
      "epoch:5 step:5257 [D loss: 0.648912, acc.: 57.81%] [G loss: 0.863174]\n",
      "epoch:5 step:5258 [D loss: 0.699172, acc.: 52.34%] [G loss: 0.750436]\n",
      "epoch:5 step:5259 [D loss: 0.655123, acc.: 59.38%] [G loss: 0.772718]\n",
      "epoch:5 step:5260 [D loss: 0.702604, acc.: 52.34%] [G loss: 0.719183]\n",
      "epoch:5 step:5261 [D loss: 0.777187, acc.: 36.72%] [G loss: 0.763470]\n",
      "epoch:5 step:5262 [D loss: 0.745406, acc.: 44.53%] [G loss: 0.742731]\n",
      "epoch:5 step:5263 [D loss: 0.740326, acc.: 48.44%] [G loss: 0.771010]\n",
      "epoch:5 step:5264 [D loss: 0.701684, acc.: 53.12%] [G loss: 0.867756]\n",
      "epoch:5 step:5265 [D loss: 0.668939, acc.: 64.06%] [G loss: 0.913450]\n",
      "epoch:5 step:5266 [D loss: 0.668717, acc.: 57.03%] [G loss: 0.877896]\n",
      "epoch:5 step:5267 [D loss: 0.664327, acc.: 56.25%] [G loss: 0.827182]\n",
      "epoch:5 step:5268 [D loss: 0.700810, acc.: 54.69%] [G loss: 0.783951]\n",
      "epoch:5 step:5269 [D loss: 0.687094, acc.: 54.69%] [G loss: 0.836548]\n",
      "epoch:5 step:5270 [D loss: 0.671539, acc.: 61.72%] [G loss: 0.797449]\n",
      "epoch:5 step:5271 [D loss: 0.671302, acc.: 58.59%] [G loss: 0.796377]\n",
      "epoch:5 step:5272 [D loss: 0.688286, acc.: 55.47%] [G loss: 0.784335]\n",
      "epoch:5 step:5273 [D loss: 0.699343, acc.: 53.12%] [G loss: 0.773812]\n",
      "epoch:5 step:5274 [D loss: 0.647586, acc.: 64.84%] [G loss: 0.799854]\n",
      "epoch:5 step:5275 [D loss: 0.693940, acc.: 48.44%] [G loss: 0.768136]\n",
      "epoch:5 step:5276 [D loss: 0.682949, acc.: 50.00%] [G loss: 0.754110]\n",
      "epoch:5 step:5277 [D loss: 0.674251, acc.: 62.50%] [G loss: 0.824848]\n",
      "epoch:5 step:5278 [D loss: 0.687014, acc.: 60.16%] [G loss: 0.786435]\n",
      "epoch:5 step:5279 [D loss: 0.657628, acc.: 64.84%] [G loss: 0.844651]\n",
      "epoch:5 step:5280 [D loss: 0.646635, acc.: 60.94%] [G loss: 0.864355]\n",
      "epoch:5 step:5281 [D loss: 0.721925, acc.: 48.44%] [G loss: 0.825623]\n",
      "epoch:5 step:5282 [D loss: 0.715240, acc.: 46.09%] [G loss: 0.875466]\n",
      "epoch:5 step:5283 [D loss: 0.705318, acc.: 50.78%] [G loss: 0.774481]\n",
      "epoch:5 step:5284 [D loss: 0.693052, acc.: 53.12%] [G loss: 0.775830]\n",
      "epoch:5 step:5285 [D loss: 0.688741, acc.: 55.47%] [G loss: 0.718583]\n",
      "epoch:5 step:5286 [D loss: 0.719140, acc.: 48.44%] [G loss: 0.737211]\n",
      "epoch:5 step:5287 [D loss: 0.690018, acc.: 51.56%] [G loss: 0.739545]\n",
      "epoch:5 step:5288 [D loss: 0.683929, acc.: 53.91%] [G loss: 0.711116]\n",
      "epoch:5 step:5289 [D loss: 0.715071, acc.: 51.56%] [G loss: 0.753707]\n",
      "epoch:5 step:5290 [D loss: 0.682973, acc.: 54.69%] [G loss: 0.755609]\n",
      "epoch:5 step:5291 [D loss: 0.722543, acc.: 47.66%] [G loss: 0.757169]\n",
      "epoch:5 step:5292 [D loss: 0.725370, acc.: 46.88%] [G loss: 0.764836]\n",
      "epoch:5 step:5293 [D loss: 0.697852, acc.: 54.69%] [G loss: 0.741937]\n",
      "epoch:5 step:5294 [D loss: 0.683030, acc.: 57.81%] [G loss: 0.800754]\n",
      "epoch:5 step:5295 [D loss: 0.662189, acc.: 62.50%] [G loss: 0.751744]\n",
      "epoch:5 step:5296 [D loss: 0.699602, acc.: 53.91%] [G loss: 0.772823]\n",
      "epoch:5 step:5297 [D loss: 0.687624, acc.: 51.56%] [G loss: 0.765006]\n",
      "epoch:5 step:5298 [D loss: 0.676357, acc.: 55.47%] [G loss: 0.787383]\n",
      "epoch:5 step:5299 [D loss: 0.694878, acc.: 54.69%] [G loss: 0.746987]\n",
      "epoch:5 step:5300 [D loss: 0.690546, acc.: 53.91%] [G loss: 0.818372]\n",
      "epoch:5 step:5301 [D loss: 0.674134, acc.: 56.25%] [G loss: 0.805499]\n",
      "epoch:5 step:5302 [D loss: 0.706584, acc.: 47.66%] [G loss: 0.750845]\n",
      "epoch:5 step:5303 [D loss: 0.702697, acc.: 50.00%] [G loss: 0.804860]\n",
      "epoch:5 step:5304 [D loss: 0.658411, acc.: 64.06%] [G loss: 0.757187]\n",
      "epoch:5 step:5305 [D loss: 0.679046, acc.: 58.59%] [G loss: 0.834944]\n",
      "epoch:5 step:5306 [D loss: 0.729945, acc.: 46.09%] [G loss: 0.766640]\n",
      "epoch:5 step:5307 [D loss: 0.718648, acc.: 47.66%] [G loss: 0.746080]\n",
      "epoch:5 step:5308 [D loss: 0.702107, acc.: 46.09%] [G loss: 0.757410]\n",
      "epoch:5 step:5309 [D loss: 0.673047, acc.: 60.94%] [G loss: 0.789625]\n",
      "epoch:5 step:5310 [D loss: 0.686932, acc.: 53.91%] [G loss: 0.769369]\n",
      "epoch:5 step:5311 [D loss: 0.699680, acc.: 53.91%] [G loss: 0.812780]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:5 step:5312 [D loss: 0.675322, acc.: 61.72%] [G loss: 0.840256]\n",
      "epoch:5 step:5313 [D loss: 0.695127, acc.: 56.25%] [G loss: 0.761956]\n",
      "epoch:5 step:5314 [D loss: 0.682384, acc.: 55.47%] [G loss: 0.785473]\n",
      "epoch:5 step:5315 [D loss: 0.687113, acc.: 57.03%] [G loss: 0.782866]\n",
      "epoch:5 step:5316 [D loss: 0.675025, acc.: 57.81%] [G loss: 0.769195]\n",
      "epoch:5 step:5317 [D loss: 0.691159, acc.: 57.03%] [G loss: 0.805335]\n",
      "epoch:5 step:5318 [D loss: 0.671512, acc.: 61.72%] [G loss: 0.809240]\n",
      "epoch:5 step:5319 [D loss: 0.691662, acc.: 52.34%] [G loss: 0.760948]\n",
      "epoch:5 step:5320 [D loss: 0.679551, acc.: 54.69%] [G loss: 0.746433]\n",
      "epoch:5 step:5321 [D loss: 0.681877, acc.: 57.81%] [G loss: 0.809292]\n",
      "epoch:5 step:5322 [D loss: 0.705906, acc.: 52.34%] [G loss: 0.739281]\n",
      "epoch:5 step:5323 [D loss: 0.704463, acc.: 59.38%] [G loss: 0.767407]\n",
      "epoch:5 step:5324 [D loss: 0.726426, acc.: 46.88%] [G loss: 0.735863]\n",
      "epoch:5 step:5325 [D loss: 0.712828, acc.: 44.53%] [G loss: 0.781691]\n",
      "epoch:5 step:5326 [D loss: 0.686730, acc.: 50.78%] [G loss: 0.748187]\n",
      "epoch:5 step:5327 [D loss: 0.664760, acc.: 57.81%] [G loss: 0.744741]\n",
      "epoch:5 step:5328 [D loss: 0.691628, acc.: 57.81%] [G loss: 0.768635]\n",
      "epoch:5 step:5329 [D loss: 0.716298, acc.: 48.44%] [G loss: 0.728648]\n",
      "epoch:5 step:5330 [D loss: 0.699109, acc.: 53.91%] [G loss: 0.774366]\n",
      "epoch:5 step:5331 [D loss: 0.706815, acc.: 53.12%] [G loss: 0.740573]\n",
      "epoch:5 step:5332 [D loss: 0.674004, acc.: 59.38%] [G loss: 0.770888]\n",
      "epoch:5 step:5333 [D loss: 0.676602, acc.: 61.72%] [G loss: 0.784863]\n",
      "epoch:5 step:5334 [D loss: 0.677779, acc.: 53.91%] [G loss: 0.801614]\n",
      "epoch:5 step:5335 [D loss: 0.668968, acc.: 60.16%] [G loss: 0.775428]\n",
      "epoch:5 step:5336 [D loss: 0.663005, acc.: 58.59%] [G loss: 0.795091]\n",
      "epoch:5 step:5337 [D loss: 0.672971, acc.: 62.50%] [G loss: 0.735222]\n",
      "epoch:5 step:5338 [D loss: 0.667021, acc.: 55.47%] [G loss: 0.772192]\n",
      "epoch:5 step:5339 [D loss: 0.680599, acc.: 60.16%] [G loss: 0.788538]\n",
      "epoch:5 step:5340 [D loss: 0.689837, acc.: 52.34%] [G loss: 0.754789]\n",
      "epoch:5 step:5341 [D loss: 0.697445, acc.: 51.56%] [G loss: 0.788824]\n",
      "epoch:5 step:5342 [D loss: 0.705341, acc.: 53.91%] [G loss: 0.776446]\n",
      "epoch:5 step:5343 [D loss: 0.697711, acc.: 50.00%] [G loss: 0.813201]\n",
      "epoch:5 step:5344 [D loss: 0.673700, acc.: 53.12%] [G loss: 0.779962]\n",
      "epoch:5 step:5345 [D loss: 0.655915, acc.: 64.06%] [G loss: 0.850050]\n",
      "epoch:5 step:5346 [D loss: 0.647120, acc.: 62.50%] [G loss: 0.810406]\n",
      "epoch:5 step:5347 [D loss: 0.653975, acc.: 60.94%] [G loss: 0.868518]\n",
      "epoch:5 step:5348 [D loss: 0.774594, acc.: 39.06%] [G loss: 0.785537]\n",
      "epoch:5 step:5349 [D loss: 0.717267, acc.: 50.00%] [G loss: 0.768223]\n",
      "epoch:5 step:5350 [D loss: 0.705414, acc.: 46.88%] [G loss: 0.758384]\n",
      "epoch:5 step:5351 [D loss: 0.637571, acc.: 62.50%] [G loss: 0.725772]\n",
      "epoch:5 step:5352 [D loss: 0.661759, acc.: 64.84%] [G loss: 0.691841]\n",
      "epoch:5 step:5353 [D loss: 0.702414, acc.: 53.12%] [G loss: 0.719951]\n",
      "epoch:5 step:5354 [D loss: 0.680812, acc.: 52.34%] [G loss: 0.764631]\n",
      "epoch:5 step:5355 [D loss: 0.691024, acc.: 53.91%] [G loss: 0.714232]\n",
      "epoch:5 step:5356 [D loss: 0.676732, acc.: 57.81%] [G loss: 0.763465]\n",
      "epoch:5 step:5357 [D loss: 0.711184, acc.: 51.56%] [G loss: 0.802591]\n",
      "epoch:5 step:5358 [D loss: 0.677995, acc.: 60.16%] [G loss: 0.799539]\n",
      "epoch:5 step:5359 [D loss: 0.650195, acc.: 63.28%] [G loss: 0.882325]\n",
      "epoch:5 step:5360 [D loss: 0.685630, acc.: 53.91%] [G loss: 0.779979]\n",
      "epoch:5 step:5361 [D loss: 0.674595, acc.: 56.25%] [G loss: 0.763989]\n",
      "epoch:5 step:5362 [D loss: 0.678558, acc.: 55.47%] [G loss: 0.844071]\n",
      "epoch:5 step:5363 [D loss: 0.703405, acc.: 60.94%] [G loss: 0.794089]\n",
      "epoch:5 step:5364 [D loss: 0.727284, acc.: 48.44%] [G loss: 0.759716]\n",
      "epoch:5 step:5365 [D loss: 0.691012, acc.: 50.78%] [G loss: 0.763423]\n",
      "epoch:5 step:5366 [D loss: 0.704650, acc.: 53.12%] [G loss: 0.786849]\n",
      "epoch:5 step:5367 [D loss: 0.686548, acc.: 53.91%] [G loss: 0.788593]\n",
      "epoch:5 step:5368 [D loss: 0.692002, acc.: 48.44%] [G loss: 0.790581]\n",
      "epoch:5 step:5369 [D loss: 0.675770, acc.: 55.47%] [G loss: 0.850858]\n",
      "epoch:5 step:5370 [D loss: 0.686767, acc.: 56.25%] [G loss: 0.804294]\n",
      "epoch:5 step:5371 [D loss: 0.702521, acc.: 52.34%] [G loss: 0.804960]\n",
      "epoch:5 step:5372 [D loss: 0.761362, acc.: 39.84%] [G loss: 0.760202]\n",
      "epoch:5 step:5373 [D loss: 0.723065, acc.: 45.31%] [G loss: 0.728323]\n",
      "epoch:5 step:5374 [D loss: 0.723033, acc.: 41.41%] [G loss: 0.751669]\n",
      "epoch:5 step:5375 [D loss: 0.704706, acc.: 46.88%] [G loss: 0.757546]\n",
      "epoch:5 step:5376 [D loss: 0.719100, acc.: 43.75%] [G loss: 0.767975]\n",
      "epoch:5 step:5377 [D loss: 0.704180, acc.: 43.75%] [G loss: 0.745392]\n",
      "epoch:5 step:5378 [D loss: 0.686665, acc.: 58.59%] [G loss: 0.763596]\n",
      "epoch:5 step:5379 [D loss: 0.686492, acc.: 50.00%] [G loss: 0.744153]\n",
      "epoch:5 step:5380 [D loss: 0.683294, acc.: 54.69%] [G loss: 0.736590]\n",
      "epoch:5 step:5381 [D loss: 0.686234, acc.: 55.47%] [G loss: 0.740328]\n",
      "epoch:5 step:5382 [D loss: 0.669233, acc.: 57.03%] [G loss: 0.772578]\n",
      "epoch:5 step:5383 [D loss: 0.664260, acc.: 60.16%] [G loss: 0.811766]\n",
      "epoch:5 step:5384 [D loss: 0.645845, acc.: 64.84%] [G loss: 0.815822]\n",
      "epoch:5 step:5385 [D loss: 0.644293, acc.: 64.06%] [G loss: 0.843072]\n",
      "epoch:5 step:5386 [D loss: 0.625011, acc.: 62.50%] [G loss: 0.781948]\n",
      "epoch:5 step:5387 [D loss: 0.686426, acc.: 57.81%] [G loss: 0.810222]\n",
      "epoch:5 step:5388 [D loss: 0.738258, acc.: 45.31%] [G loss: 0.772198]\n",
      "epoch:5 step:5389 [D loss: 0.680665, acc.: 51.56%] [G loss: 0.795702]\n",
      "epoch:5 step:5390 [D loss: 0.695676, acc.: 53.12%] [G loss: 0.802751]\n",
      "epoch:5 step:5391 [D loss: 0.646463, acc.: 66.41%] [G loss: 0.718861]\n",
      "epoch:5 step:5392 [D loss: 0.678398, acc.: 58.59%] [G loss: 0.777353]\n",
      "epoch:5 step:5393 [D loss: 0.665189, acc.: 58.59%] [G loss: 0.796000]\n",
      "epoch:5 step:5394 [D loss: 0.659024, acc.: 59.38%] [G loss: 0.830271]\n",
      "epoch:5 step:5395 [D loss: 0.746069, acc.: 44.53%] [G loss: 0.788763]\n",
      "epoch:5 step:5396 [D loss: 0.720163, acc.: 41.41%] [G loss: 0.751405]\n",
      "epoch:5 step:5397 [D loss: 0.679562, acc.: 52.34%] [G loss: 0.767954]\n",
      "epoch:5 step:5398 [D loss: 0.689028, acc.: 55.47%] [G loss: 0.727635]\n",
      "epoch:5 step:5399 [D loss: 0.689943, acc.: 60.16%] [G loss: 0.773615]\n",
      "epoch:5 step:5400 [D loss: 0.729090, acc.: 41.41%] [G loss: 0.729838]\n",
      "##############\n",
      "[3.84585512 1.84223413 6.09392678 5.27650201 3.98947662 5.72144673\n",
      " 5.18666878 5.08260876 5.34535953 4.3791695 ]\n",
      "##########\n",
      "epoch:5 step:5401 [D loss: 0.709080, acc.: 56.25%] [G loss: 0.760180]\n",
      "epoch:5 step:5402 [D loss: 0.687565, acc.: 53.91%] [G loss: 0.792207]\n",
      "epoch:5 step:5403 [D loss: 0.697255, acc.: 52.34%] [G loss: 0.793103]\n",
      "epoch:5 step:5404 [D loss: 0.700536, acc.: 47.66%] [G loss: 0.748164]\n",
      "epoch:5 step:5405 [D loss: 0.664305, acc.: 60.94%] [G loss: 0.831427]\n",
      "epoch:5 step:5406 [D loss: 0.689918, acc.: 56.25%] [G loss: 0.773829]\n",
      "epoch:5 step:5407 [D loss: 0.710284, acc.: 50.00%] [G loss: 0.792381]\n",
      "epoch:5 step:5408 [D loss: 0.674620, acc.: 64.06%] [G loss: 0.817504]\n",
      "epoch:5 step:5409 [D loss: 0.675923, acc.: 57.81%] [G loss: 0.788186]\n",
      "epoch:5 step:5410 [D loss: 0.669283, acc.: 58.59%] [G loss: 0.813694]\n",
      "epoch:5 step:5411 [D loss: 0.708279, acc.: 53.91%] [G loss: 0.789434]\n",
      "epoch:5 step:5412 [D loss: 0.699561, acc.: 48.44%] [G loss: 0.784282]\n",
      "epoch:5 step:5413 [D loss: 0.732090, acc.: 50.78%] [G loss: 0.749630]\n",
      "epoch:5 step:5414 [D loss: 0.698097, acc.: 55.47%] [G loss: 0.759742]\n",
      "epoch:5 step:5415 [D loss: 0.667268, acc.: 54.69%] [G loss: 0.752075]\n",
      "epoch:5 step:5416 [D loss: 0.667456, acc.: 66.41%] [G loss: 0.762402]\n",
      "epoch:5 step:5417 [D loss: 0.631315, acc.: 65.62%] [G loss: 0.828259]\n",
      "epoch:5 step:5418 [D loss: 0.659334, acc.: 60.16%] [G loss: 0.837498]\n",
      "epoch:5 step:5419 [D loss: 0.695530, acc.: 53.12%] [G loss: 0.795351]\n",
      "epoch:5 step:5420 [D loss: 0.701078, acc.: 47.66%] [G loss: 0.804102]\n",
      "epoch:5 step:5421 [D loss: 0.701389, acc.: 46.88%] [G loss: 0.796710]\n",
      "epoch:5 step:5422 [D loss: 0.695747, acc.: 56.25%] [G loss: 0.766513]\n",
      "epoch:5 step:5423 [D loss: 0.723017, acc.: 45.31%] [G loss: 0.753477]\n",
      "epoch:5 step:5424 [D loss: 0.704523, acc.: 50.78%] [G loss: 0.745408]\n",
      "epoch:5 step:5425 [D loss: 0.683026, acc.: 57.03%] [G loss: 0.743852]\n",
      "epoch:5 step:5426 [D loss: 0.727750, acc.: 42.19%] [G loss: 0.745111]\n",
      "epoch:5 step:5427 [D loss: 0.714885, acc.: 46.09%] [G loss: 0.761388]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:5 step:5428 [D loss: 0.695250, acc.: 53.12%] [G loss: 0.760634]\n",
      "epoch:5 step:5429 [D loss: 0.689399, acc.: 56.25%] [G loss: 0.770496]\n",
      "epoch:5 step:5430 [D loss: 0.684777, acc.: 53.12%] [G loss: 0.772484]\n",
      "epoch:5 step:5431 [D loss: 0.688091, acc.: 49.22%] [G loss: 0.752798]\n",
      "epoch:5 step:5432 [D loss: 0.673231, acc.: 57.03%] [G loss: 0.775917]\n",
      "epoch:5 step:5433 [D loss: 0.684750, acc.: 57.81%] [G loss: 0.791088]\n",
      "epoch:5 step:5434 [D loss: 0.697896, acc.: 46.88%] [G loss: 0.728142]\n",
      "epoch:5 step:5435 [D loss: 0.666070, acc.: 60.16%] [G loss: 0.762482]\n",
      "epoch:5 step:5436 [D loss: 0.694747, acc.: 52.34%] [G loss: 0.790545]\n",
      "epoch:5 step:5437 [D loss: 0.686752, acc.: 54.69%] [G loss: 0.757112]\n",
      "epoch:5 step:5438 [D loss: 0.722423, acc.: 42.97%] [G loss: 0.718685]\n",
      "epoch:5 step:5439 [D loss: 0.688174, acc.: 50.00%] [G loss: 0.757214]\n",
      "epoch:5 step:5440 [D loss: 0.686735, acc.: 57.03%] [G loss: 0.741876]\n",
      "epoch:5 step:5441 [D loss: 0.684232, acc.: 57.81%] [G loss: 0.744523]\n",
      "epoch:5 step:5442 [D loss: 0.703476, acc.: 54.69%] [G loss: 0.698341]\n",
      "epoch:5 step:5443 [D loss: 0.700947, acc.: 44.53%] [G loss: 0.741581]\n",
      "epoch:5 step:5444 [D loss: 0.688404, acc.: 50.78%] [G loss: 0.734021]\n",
      "epoch:5 step:5445 [D loss: 0.709932, acc.: 46.88%] [G loss: 0.718496]\n",
      "epoch:5 step:5446 [D loss: 0.688789, acc.: 50.78%] [G loss: 0.753708]\n",
      "epoch:5 step:5447 [D loss: 0.690567, acc.: 53.91%] [G loss: 0.747035]\n",
      "epoch:5 step:5448 [D loss: 0.703768, acc.: 48.44%] [G loss: 0.764045]\n",
      "epoch:5 step:5449 [D loss: 0.682544, acc.: 55.47%] [G loss: 0.701793]\n",
      "epoch:5 step:5450 [D loss: 0.709713, acc.: 49.22%] [G loss: 0.720769]\n",
      "epoch:5 step:5451 [D loss: 0.686934, acc.: 54.69%] [G loss: 0.711018]\n",
      "epoch:5 step:5452 [D loss: 0.678878, acc.: 51.56%] [G loss: 0.724897]\n",
      "epoch:5 step:5453 [D loss: 0.708233, acc.: 48.44%] [G loss: 0.736455]\n",
      "epoch:5 step:5454 [D loss: 0.681795, acc.: 53.12%] [G loss: 0.742424]\n",
      "epoch:5 step:5455 [D loss: 0.698707, acc.: 57.81%] [G loss: 0.721225]\n",
      "epoch:5 step:5456 [D loss: 0.683126, acc.: 57.03%] [G loss: 0.736414]\n",
      "epoch:5 step:5457 [D loss: 0.702402, acc.: 50.78%] [G loss: 0.754712]\n",
      "epoch:5 step:5458 [D loss: 0.683728, acc.: 50.00%] [G loss: 0.748172]\n",
      "epoch:5 step:5459 [D loss: 0.700806, acc.: 53.12%] [G loss: 0.733824]\n",
      "epoch:5 step:5460 [D loss: 0.669290, acc.: 60.16%] [G loss: 0.805457]\n",
      "epoch:5 step:5461 [D loss: 0.681552, acc.: 57.81%] [G loss: 0.767056]\n",
      "epoch:5 step:5462 [D loss: 0.695462, acc.: 47.66%] [G loss: 0.769532]\n",
      "epoch:5 step:5463 [D loss: 0.668316, acc.: 58.59%] [G loss: 0.758638]\n",
      "epoch:5 step:5464 [D loss: 0.703365, acc.: 54.69%] [G loss: 0.765124]\n",
      "epoch:5 step:5465 [D loss: 0.696814, acc.: 51.56%] [G loss: 0.759813]\n",
      "epoch:5 step:5466 [D loss: 0.693491, acc.: 52.34%] [G loss: 0.779333]\n",
      "epoch:5 step:5467 [D loss: 0.665855, acc.: 59.38%] [G loss: 0.792712]\n",
      "epoch:5 step:5468 [D loss: 0.701069, acc.: 53.91%] [G loss: 0.801633]\n",
      "epoch:5 step:5469 [D loss: 0.702539, acc.: 52.34%] [G loss: 0.742203]\n",
      "epoch:5 step:5470 [D loss: 0.688808, acc.: 47.66%] [G loss: 0.759484]\n",
      "epoch:5 step:5471 [D loss: 0.677638, acc.: 57.03%] [G loss: 0.825762]\n",
      "epoch:5 step:5472 [D loss: 0.722461, acc.: 46.88%] [G loss: 0.750739]\n",
      "epoch:5 step:5473 [D loss: 0.714320, acc.: 46.09%] [G loss: 0.746043]\n",
      "epoch:5 step:5474 [D loss: 0.717352, acc.: 46.88%] [G loss: 0.720611]\n",
      "epoch:5 step:5475 [D loss: 0.674327, acc.: 55.47%] [G loss: 0.726621]\n",
      "epoch:5 step:5476 [D loss: 0.718062, acc.: 53.12%] [G loss: 0.744317]\n",
      "epoch:5 step:5477 [D loss: 0.669302, acc.: 55.47%] [G loss: 0.740502]\n",
      "epoch:5 step:5478 [D loss: 0.699078, acc.: 53.91%] [G loss: 0.737158]\n",
      "epoch:5 step:5479 [D loss: 0.716014, acc.: 45.31%] [G loss: 0.758924]\n",
      "epoch:5 step:5480 [D loss: 0.670572, acc.: 63.28%] [G loss: 0.733626]\n",
      "epoch:5 step:5481 [D loss: 0.666680, acc.: 55.47%] [G loss: 0.746467]\n",
      "epoch:5 step:5482 [D loss: 0.675368, acc.: 53.12%] [G loss: 0.750384]\n",
      "epoch:5 step:5483 [D loss: 0.742156, acc.: 50.78%] [G loss: 0.785803]\n",
      "epoch:5 step:5484 [D loss: 0.674940, acc.: 61.72%] [G loss: 0.776672]\n",
      "epoch:5 step:5485 [D loss: 0.717943, acc.: 44.53%] [G loss: 0.773446]\n",
      "epoch:5 step:5486 [D loss: 0.690258, acc.: 46.09%] [G loss: 0.783651]\n",
      "epoch:5 step:5487 [D loss: 0.657008, acc.: 58.59%] [G loss: 0.794471]\n",
      "epoch:5 step:5488 [D loss: 0.670494, acc.: 60.94%] [G loss: 0.777231]\n",
      "epoch:5 step:5489 [D loss: 0.697887, acc.: 55.47%] [G loss: 0.799084]\n",
      "epoch:5 step:5490 [D loss: 0.702341, acc.: 48.44%] [G loss: 0.761213]\n",
      "epoch:5 step:5491 [D loss: 0.698095, acc.: 51.56%] [G loss: 0.740074]\n",
      "epoch:5 step:5492 [D loss: 0.689816, acc.: 55.47%] [G loss: 0.724005]\n",
      "epoch:5 step:5493 [D loss: 0.706806, acc.: 46.88%] [G loss: 0.769808]\n",
      "epoch:5 step:5494 [D loss: 0.700620, acc.: 48.44%] [G loss: 0.773574]\n",
      "epoch:5 step:5495 [D loss: 0.683933, acc.: 53.12%] [G loss: 0.801002]\n",
      "epoch:5 step:5496 [D loss: 0.676836, acc.: 55.47%] [G loss: 0.810453]\n",
      "epoch:5 step:5497 [D loss: 0.718561, acc.: 48.44%] [G loss: 0.790364]\n",
      "epoch:5 step:5498 [D loss: 0.690628, acc.: 56.25%] [G loss: 0.776330]\n",
      "epoch:5 step:5499 [D loss: 0.690309, acc.: 55.47%] [G loss: 0.746993]\n",
      "epoch:5 step:5500 [D loss: 0.669899, acc.: 57.81%] [G loss: 0.742429]\n",
      "epoch:5 step:5501 [D loss: 0.705065, acc.: 53.12%] [G loss: 0.757890]\n",
      "epoch:5 step:5502 [D loss: 0.723623, acc.: 43.75%] [G loss: 0.751897]\n",
      "epoch:5 step:5503 [D loss: 0.709620, acc.: 48.44%] [G loss: 0.766501]\n",
      "epoch:5 step:5504 [D loss: 0.705508, acc.: 50.00%] [G loss: 0.733195]\n",
      "epoch:5 step:5505 [D loss: 0.693872, acc.: 57.03%] [G loss: 0.746161]\n",
      "epoch:5 step:5506 [D loss: 0.692376, acc.: 52.34%] [G loss: 0.764556]\n",
      "epoch:5 step:5507 [D loss: 0.698191, acc.: 43.75%] [G loss: 0.734095]\n",
      "epoch:5 step:5508 [D loss: 0.714004, acc.: 46.09%] [G loss: 0.750047]\n",
      "epoch:5 step:5509 [D loss: 0.702031, acc.: 50.00%] [G loss: 0.712410]\n",
      "epoch:5 step:5510 [D loss: 0.711597, acc.: 46.09%] [G loss: 0.739179]\n",
      "epoch:5 step:5511 [D loss: 0.686409, acc.: 51.56%] [G loss: 0.748206]\n",
      "epoch:5 step:5512 [D loss: 0.702278, acc.: 50.00%] [G loss: 0.731754]\n",
      "epoch:5 step:5513 [D loss: 0.710151, acc.: 52.34%] [G loss: 0.722994]\n",
      "epoch:5 step:5514 [D loss: 0.676432, acc.: 60.94%] [G loss: 0.767181]\n",
      "epoch:5 step:5515 [D loss: 0.689682, acc.: 50.78%] [G loss: 0.709714]\n",
      "epoch:5 step:5516 [D loss: 0.701043, acc.: 50.00%] [G loss: 0.744444]\n",
      "epoch:5 step:5517 [D loss: 0.687525, acc.: 53.12%] [G loss: 0.728178]\n",
      "epoch:5 step:5518 [D loss: 0.676808, acc.: 60.16%] [G loss: 0.732197]\n",
      "epoch:5 step:5519 [D loss: 0.704168, acc.: 47.66%] [G loss: 0.760425]\n",
      "epoch:5 step:5520 [D loss: 0.685380, acc.: 46.88%] [G loss: 0.771826]\n",
      "epoch:5 step:5521 [D loss: 0.661617, acc.: 60.94%] [G loss: 0.767997]\n",
      "epoch:5 step:5522 [D loss: 0.653822, acc.: 59.38%] [G loss: 0.760009]\n",
      "epoch:5 step:5523 [D loss: 0.657800, acc.: 62.50%] [G loss: 0.806650]\n",
      "epoch:5 step:5524 [D loss: 0.661916, acc.: 60.94%] [G loss: 0.758257]\n",
      "epoch:5 step:5525 [D loss: 0.709720, acc.: 50.78%] [G loss: 0.804569]\n",
      "epoch:5 step:5526 [D loss: 0.658179, acc.: 58.59%] [G loss: 0.755564]\n",
      "epoch:5 step:5527 [D loss: 0.649416, acc.: 61.72%] [G loss: 0.779636]\n",
      "epoch:5 step:5528 [D loss: 0.712112, acc.: 51.56%] [G loss: 0.732924]\n",
      "epoch:5 step:5529 [D loss: 0.716342, acc.: 53.12%] [G loss: 0.765873]\n",
      "epoch:5 step:5530 [D loss: 0.725045, acc.: 49.22%] [G loss: 0.722271]\n",
      "epoch:5 step:5531 [D loss: 0.693811, acc.: 53.91%] [G loss: 0.712946]\n",
      "epoch:5 step:5532 [D loss: 0.724152, acc.: 48.44%] [G loss: 0.722685]\n",
      "epoch:5 step:5533 [D loss: 0.723584, acc.: 44.53%] [G loss: 0.722770]\n",
      "epoch:5 step:5534 [D loss: 0.706167, acc.: 50.00%] [G loss: 0.738503]\n",
      "epoch:5 step:5535 [D loss: 0.728821, acc.: 33.59%] [G loss: 0.759618]\n",
      "epoch:5 step:5536 [D loss: 0.676912, acc.: 53.12%] [G loss: 0.761445]\n",
      "epoch:5 step:5537 [D loss: 0.663599, acc.: 61.72%] [G loss: 0.798040]\n",
      "epoch:5 step:5538 [D loss: 0.664103, acc.: 61.72%] [G loss: 0.800775]\n",
      "epoch:5 step:5539 [D loss: 0.651141, acc.: 65.62%] [G loss: 0.853707]\n",
      "epoch:5 step:5540 [D loss: 0.652064, acc.: 65.62%] [G loss: 0.822144]\n",
      "epoch:5 step:5541 [D loss: 0.649081, acc.: 65.62%] [G loss: 0.840395]\n",
      "epoch:5 step:5542 [D loss: 0.688776, acc.: 50.78%] [G loss: 0.796657]\n",
      "epoch:5 step:5543 [D loss: 0.738667, acc.: 41.41%] [G loss: 0.797261]\n",
      "epoch:5 step:5544 [D loss: 0.719677, acc.: 44.53%] [G loss: 0.758240]\n",
      "epoch:5 step:5545 [D loss: 0.699539, acc.: 53.12%] [G loss: 0.762166]\n",
      "epoch:5 step:5546 [D loss: 0.736654, acc.: 40.62%] [G loss: 0.739744]\n",
      "epoch:5 step:5547 [D loss: 0.709369, acc.: 43.75%] [G loss: 0.697952]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:5 step:5548 [D loss: 0.709731, acc.: 46.09%] [G loss: 0.717759]\n",
      "epoch:5 step:5549 [D loss: 0.697179, acc.: 50.00%] [G loss: 0.735478]\n",
      "epoch:5 step:5550 [D loss: 0.712911, acc.: 47.66%] [G loss: 0.741041]\n",
      "epoch:5 step:5551 [D loss: 0.687130, acc.: 60.16%] [G loss: 0.741633]\n",
      "epoch:5 step:5552 [D loss: 0.684277, acc.: 57.81%] [G loss: 0.750861]\n",
      "epoch:5 step:5553 [D loss: 0.685286, acc.: 59.38%] [G loss: 0.790819]\n",
      "epoch:5 step:5554 [D loss: 0.675313, acc.: 55.47%] [G loss: 0.745699]\n",
      "epoch:5 step:5555 [D loss: 0.693389, acc.: 47.66%] [G loss: 0.761844]\n",
      "epoch:5 step:5556 [D loss: 0.695154, acc.: 51.56%] [G loss: 0.746425]\n",
      "epoch:5 step:5557 [D loss: 0.704124, acc.: 49.22%] [G loss: 0.724742]\n",
      "epoch:5 step:5558 [D loss: 0.696238, acc.: 52.34%] [G loss: 0.722930]\n",
      "epoch:5 step:5559 [D loss: 0.669672, acc.: 58.59%] [G loss: 0.775324]\n",
      "epoch:5 step:5560 [D loss: 0.680308, acc.: 64.06%] [G loss: 0.735314]\n",
      "epoch:5 step:5561 [D loss: 0.684116, acc.: 59.38%] [G loss: 0.739264]\n",
      "epoch:5 step:5562 [D loss: 0.695863, acc.: 50.00%] [G loss: 0.764884]\n",
      "epoch:5 step:5563 [D loss: 0.686146, acc.: 57.81%] [G loss: 0.753367]\n",
      "epoch:5 step:5564 [D loss: 0.678833, acc.: 63.28%] [G loss: 0.787064]\n",
      "epoch:5 step:5565 [D loss: 0.708548, acc.: 46.88%] [G loss: 0.772024]\n",
      "epoch:5 step:5566 [D loss: 0.683686, acc.: 50.78%] [G loss: 0.746919]\n",
      "epoch:5 step:5567 [D loss: 0.673366, acc.: 53.91%] [G loss: 0.853200]\n",
      "epoch:5 step:5568 [D loss: 0.689710, acc.: 60.16%] [G loss: 0.766428]\n",
      "epoch:5 step:5569 [D loss: 0.696007, acc.: 53.12%] [G loss: 0.762556]\n",
      "epoch:5 step:5570 [D loss: 0.675265, acc.: 60.16%] [G loss: 0.767200]\n",
      "epoch:5 step:5571 [D loss: 0.664984, acc.: 57.03%] [G loss: 0.788347]\n",
      "epoch:5 step:5572 [D loss: 0.652202, acc.: 64.84%] [G loss: 0.778743]\n",
      "epoch:5 step:5573 [D loss: 0.642146, acc.: 64.06%] [G loss: 0.849767]\n",
      "epoch:5 step:5574 [D loss: 0.639261, acc.: 63.28%] [G loss: 0.815323]\n",
      "epoch:5 step:5575 [D loss: 0.673946, acc.: 54.69%] [G loss: 0.731495]\n",
      "epoch:5 step:5576 [D loss: 0.809950, acc.: 32.81%] [G loss: 0.735945]\n",
      "epoch:5 step:5577 [D loss: 0.740066, acc.: 43.75%] [G loss: 0.754356]\n",
      "epoch:5 step:5578 [D loss: 0.722577, acc.: 41.41%] [G loss: 0.759534]\n",
      "epoch:5 step:5579 [D loss: 0.691180, acc.: 52.34%] [G loss: 0.822502]\n",
      "epoch:5 step:5580 [D loss: 0.673231, acc.: 62.50%] [G loss: 0.850776]\n",
      "epoch:5 step:5581 [D loss: 0.662768, acc.: 58.59%] [G loss: 0.794428]\n",
      "epoch:5 step:5582 [D loss: 0.639485, acc.: 69.53%] [G loss: 0.848431]\n",
      "epoch:5 step:5583 [D loss: 0.639400, acc.: 63.28%] [G loss: 0.845544]\n",
      "epoch:5 step:5584 [D loss: 0.654257, acc.: 59.38%] [G loss: 0.882034]\n",
      "epoch:5 step:5585 [D loss: 0.707025, acc.: 50.78%] [G loss: 0.827333]\n",
      "epoch:5 step:5586 [D loss: 0.653232, acc.: 58.59%] [G loss: 0.827320]\n",
      "epoch:5 step:5587 [D loss: 0.730640, acc.: 45.31%] [G loss: 0.785935]\n",
      "epoch:5 step:5588 [D loss: 0.711564, acc.: 51.56%] [G loss: 0.753280]\n",
      "epoch:5 step:5589 [D loss: 0.785385, acc.: 32.81%] [G loss: 0.736818]\n",
      "epoch:5 step:5590 [D loss: 0.727246, acc.: 40.62%] [G loss: 0.756405]\n",
      "epoch:5 step:5591 [D loss: 0.705334, acc.: 50.78%] [G loss: 0.773488]\n",
      "epoch:5 step:5592 [D loss: 0.686252, acc.: 54.69%] [G loss: 0.779992]\n",
      "epoch:5 step:5593 [D loss: 0.670198, acc.: 64.06%] [G loss: 0.806991]\n",
      "epoch:5 step:5594 [D loss: 0.669446, acc.: 61.72%] [G loss: 0.827364]\n",
      "epoch:5 step:5595 [D loss: 0.668038, acc.: 57.03%] [G loss: 0.798738]\n",
      "epoch:5 step:5596 [D loss: 0.656622, acc.: 65.62%] [G loss: 0.842217]\n",
      "epoch:5 step:5597 [D loss: 0.688643, acc.: 55.47%] [G loss: 0.872369]\n",
      "epoch:5 step:5598 [D loss: 0.631345, acc.: 64.84%] [G loss: 0.903600]\n",
      "epoch:5 step:5599 [D loss: 0.654923, acc.: 67.19%] [G loss: 0.878994]\n",
      "epoch:5 step:5600 [D loss: 0.665918, acc.: 57.81%] [G loss: 0.863667]\n",
      "##############\n",
      "[3.69919171 2.40757229 6.0638891  5.35282826 4.13856289 5.98075736\n",
      " 5.21682349 5.21281542 5.36310317 4.99125337]\n",
      "##########\n",
      "epoch:5 step:5601 [D loss: 0.730880, acc.: 41.41%] [G loss: 0.764445]\n",
      "epoch:5 step:5602 [D loss: 0.743086, acc.: 42.19%] [G loss: 0.683058]\n",
      "epoch:5 step:5603 [D loss: 0.695648, acc.: 52.34%] [G loss: 0.715694]\n",
      "epoch:5 step:5604 [D loss: 0.724870, acc.: 51.56%] [G loss: 0.671819]\n",
      "epoch:5 step:5605 [D loss: 0.730080, acc.: 41.41%] [G loss: 0.673132]\n",
      "epoch:5 step:5606 [D loss: 0.696546, acc.: 53.91%] [G loss: 0.698920]\n",
      "epoch:5 step:5607 [D loss: 0.675646, acc.: 59.38%] [G loss: 0.714495]\n",
      "epoch:5 step:5608 [D loss: 0.679243, acc.: 58.59%] [G loss: 0.706996]\n",
      "epoch:5 step:5609 [D loss: 0.694285, acc.: 52.34%] [G loss: 0.712738]\n",
      "epoch:5 step:5610 [D loss: 0.692611, acc.: 57.81%] [G loss: 0.722370]\n",
      "epoch:5 step:5611 [D loss: 0.670992, acc.: 58.59%] [G loss: 0.751798]\n",
      "epoch:5 step:5612 [D loss: 0.687543, acc.: 49.22%] [G loss: 0.809073]\n",
      "epoch:5 step:5613 [D loss: 0.740460, acc.: 44.53%] [G loss: 0.756635]\n",
      "epoch:5 step:5614 [D loss: 0.737811, acc.: 42.97%] [G loss: 0.762333]\n",
      "epoch:5 step:5615 [D loss: 0.654996, acc.: 64.84%] [G loss: 0.772733]\n",
      "epoch:5 step:5616 [D loss: 0.679725, acc.: 59.38%] [G loss: 0.757667]\n",
      "epoch:5 step:5617 [D loss: 0.702246, acc.: 49.22%] [G loss: 0.772705]\n",
      "epoch:5 step:5618 [D loss: 0.681289, acc.: 53.91%] [G loss: 0.749070]\n",
      "epoch:5 step:5619 [D loss: 0.680879, acc.: 54.69%] [G loss: 0.774814]\n",
      "epoch:5 step:5620 [D loss: 0.652058, acc.: 63.28%] [G loss: 0.782240]\n",
      "epoch:5 step:5621 [D loss: 0.645284, acc.: 64.06%] [G loss: 0.777390]\n",
      "epoch:5 step:5622 [D loss: 0.669211, acc.: 57.81%] [G loss: 0.785123]\n",
      "epoch:6 step:5623 [D loss: 0.723360, acc.: 48.44%] [G loss: 0.715117]\n",
      "epoch:6 step:5624 [D loss: 0.710313, acc.: 49.22%] [G loss: 0.762970]\n",
      "epoch:6 step:5625 [D loss: 0.695264, acc.: 56.25%] [G loss: 0.777174]\n",
      "epoch:6 step:5626 [D loss: 0.729205, acc.: 36.72%] [G loss: 0.755210]\n",
      "epoch:6 step:5627 [D loss: 0.700855, acc.: 48.44%] [G loss: 0.787178]\n",
      "epoch:6 step:5628 [D loss: 0.682535, acc.: 54.69%] [G loss: 0.764263]\n",
      "epoch:6 step:5629 [D loss: 0.685354, acc.: 53.91%] [G loss: 0.772848]\n",
      "epoch:6 step:5630 [D loss: 0.697517, acc.: 46.88%] [G loss: 0.764473]\n",
      "epoch:6 step:5631 [D loss: 0.650122, acc.: 67.19%] [G loss: 0.784851]\n",
      "epoch:6 step:5632 [D loss: 0.674449, acc.: 57.81%] [G loss: 0.762672]\n",
      "epoch:6 step:5633 [D loss: 0.658002, acc.: 60.94%] [G loss: 0.777325]\n",
      "epoch:6 step:5634 [D loss: 0.677613, acc.: 57.81%] [G loss: 0.823934]\n",
      "epoch:6 step:5635 [D loss: 0.652722, acc.: 65.62%] [G loss: 0.755684]\n",
      "epoch:6 step:5636 [D loss: 0.680880, acc.: 60.16%] [G loss: 0.768266]\n",
      "epoch:6 step:5637 [D loss: 0.683616, acc.: 54.69%] [G loss: 0.811340]\n",
      "epoch:6 step:5638 [D loss: 0.685060, acc.: 49.22%] [G loss: 0.778357]\n",
      "epoch:6 step:5639 [D loss: 0.716927, acc.: 42.19%] [G loss: 0.785362]\n",
      "epoch:6 step:5640 [D loss: 0.685053, acc.: 51.56%] [G loss: 0.762125]\n",
      "epoch:6 step:5641 [D loss: 0.724522, acc.: 52.34%] [G loss: 0.761194]\n",
      "epoch:6 step:5642 [D loss: 0.712404, acc.: 45.31%] [G loss: 0.781822]\n",
      "epoch:6 step:5643 [D loss: 0.662131, acc.: 57.03%] [G loss: 0.833314]\n",
      "epoch:6 step:5644 [D loss: 0.622689, acc.: 71.09%] [G loss: 0.843896]\n",
      "epoch:6 step:5645 [D loss: 0.682766, acc.: 54.69%] [G loss: 0.850499]\n",
      "epoch:6 step:5646 [D loss: 0.716494, acc.: 57.81%] [G loss: 0.790281]\n",
      "epoch:6 step:5647 [D loss: 0.676237, acc.: 58.59%] [G loss: 0.787135]\n",
      "epoch:6 step:5648 [D loss: 0.711269, acc.: 54.69%] [G loss: 0.774072]\n",
      "epoch:6 step:5649 [D loss: 0.705535, acc.: 47.66%] [G loss: 0.718753]\n",
      "epoch:6 step:5650 [D loss: 0.693338, acc.: 50.78%] [G loss: 0.726630]\n",
      "epoch:6 step:5651 [D loss: 0.694940, acc.: 52.34%] [G loss: 0.767009]\n",
      "epoch:6 step:5652 [D loss: 0.697877, acc.: 53.91%] [G loss: 0.731894]\n",
      "epoch:6 step:5653 [D loss: 0.714316, acc.: 47.66%] [G loss: 0.753306]\n",
      "epoch:6 step:5654 [D loss: 0.691133, acc.: 52.34%] [G loss: 0.737080]\n",
      "epoch:6 step:5655 [D loss: 0.704277, acc.: 50.00%] [G loss: 0.750540]\n",
      "epoch:6 step:5656 [D loss: 0.696096, acc.: 53.12%] [G loss: 0.745141]\n",
      "epoch:6 step:5657 [D loss: 0.649598, acc.: 64.84%] [G loss: 0.777185]\n",
      "epoch:6 step:5658 [D loss: 0.673685, acc.: 63.28%] [G loss: 0.786319]\n",
      "epoch:6 step:5659 [D loss: 0.678032, acc.: 52.34%] [G loss: 0.825821]\n",
      "epoch:6 step:5660 [D loss: 0.689690, acc.: 55.47%] [G loss: 0.843768]\n",
      "epoch:6 step:5661 [D loss: 0.700640, acc.: 50.78%] [G loss: 0.877017]\n",
      "epoch:6 step:5662 [D loss: 0.676083, acc.: 54.69%] [G loss: 0.794965]\n",
      "epoch:6 step:5663 [D loss: 0.712020, acc.: 48.44%] [G loss: 0.809630]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:6 step:5664 [D loss: 0.691259, acc.: 51.56%] [G loss: 0.784645]\n",
      "epoch:6 step:5665 [D loss: 0.696804, acc.: 53.12%] [G loss: 0.736463]\n",
      "epoch:6 step:5666 [D loss: 0.705005, acc.: 43.75%] [G loss: 0.766255]\n",
      "epoch:6 step:5667 [D loss: 0.711378, acc.: 50.00%] [G loss: 0.736185]\n",
      "epoch:6 step:5668 [D loss: 0.684516, acc.: 53.12%] [G loss: 0.754741]\n",
      "epoch:6 step:5669 [D loss: 0.694431, acc.: 57.03%] [G loss: 0.759315]\n",
      "epoch:6 step:5670 [D loss: 0.666774, acc.: 60.16%] [G loss: 0.771594]\n",
      "epoch:6 step:5671 [D loss: 0.654229, acc.: 61.72%] [G loss: 0.845035]\n",
      "epoch:6 step:5672 [D loss: 0.653940, acc.: 60.94%] [G loss: 0.810486]\n",
      "epoch:6 step:5673 [D loss: 0.699412, acc.: 50.00%] [G loss: 0.798993]\n",
      "epoch:6 step:5674 [D loss: 0.680881, acc.: 53.12%] [G loss: 0.792358]\n",
      "epoch:6 step:5675 [D loss: 0.678282, acc.: 57.03%] [G loss: 0.809516]\n",
      "epoch:6 step:5676 [D loss: 0.684881, acc.: 53.91%] [G loss: 0.760651]\n",
      "epoch:6 step:5677 [D loss: 0.723761, acc.: 41.41%] [G loss: 0.722683]\n",
      "epoch:6 step:5678 [D loss: 0.683476, acc.: 50.00%] [G loss: 0.693450]\n",
      "epoch:6 step:5679 [D loss: 0.691561, acc.: 53.12%] [G loss: 0.723152]\n",
      "epoch:6 step:5680 [D loss: 0.695362, acc.: 51.56%] [G loss: 0.747987]\n",
      "epoch:6 step:5681 [D loss: 0.698272, acc.: 47.66%] [G loss: 0.723124]\n",
      "epoch:6 step:5682 [D loss: 0.694096, acc.: 56.25%] [G loss: 0.739325]\n",
      "epoch:6 step:5683 [D loss: 0.698977, acc.: 49.22%] [G loss: 0.725319]\n",
      "epoch:6 step:5684 [D loss: 0.708507, acc.: 47.66%] [G loss: 0.733930]\n",
      "epoch:6 step:5685 [D loss: 0.688440, acc.: 51.56%] [G loss: 0.740981]\n",
      "epoch:6 step:5686 [D loss: 0.700511, acc.: 44.53%] [G loss: 0.730157]\n",
      "epoch:6 step:5687 [D loss: 0.726891, acc.: 48.44%] [G loss: 0.716221]\n",
      "epoch:6 step:5688 [D loss: 0.694786, acc.: 51.56%] [G loss: 0.723590]\n",
      "epoch:6 step:5689 [D loss: 0.712812, acc.: 47.66%] [G loss: 0.733228]\n",
      "epoch:6 step:5690 [D loss: 0.696573, acc.: 52.34%] [G loss: 0.758911]\n",
      "epoch:6 step:5691 [D loss: 0.705945, acc.: 43.75%] [G loss: 0.745535]\n",
      "epoch:6 step:5692 [D loss: 0.686751, acc.: 53.12%] [G loss: 0.726041]\n",
      "epoch:6 step:5693 [D loss: 0.690699, acc.: 55.47%] [G loss: 0.746939]\n",
      "epoch:6 step:5694 [D loss: 0.694427, acc.: 51.56%] [G loss: 0.715937]\n",
      "epoch:6 step:5695 [D loss: 0.683181, acc.: 49.22%] [G loss: 0.758091]\n",
      "epoch:6 step:5696 [D loss: 0.669039, acc.: 63.28%] [G loss: 0.759924]\n",
      "epoch:6 step:5697 [D loss: 0.665941, acc.: 59.38%] [G loss: 0.764751]\n",
      "epoch:6 step:5698 [D loss: 0.661647, acc.: 63.28%] [G loss: 0.824381]\n",
      "epoch:6 step:5699 [D loss: 0.634917, acc.: 67.97%] [G loss: 0.803130]\n",
      "epoch:6 step:5700 [D loss: 0.718392, acc.: 50.78%] [G loss: 0.775158]\n",
      "epoch:6 step:5701 [D loss: 0.674635, acc.: 53.91%] [G loss: 0.783511]\n",
      "epoch:6 step:5702 [D loss: 0.709471, acc.: 49.22%] [G loss: 0.797445]\n",
      "epoch:6 step:5703 [D loss: 0.711679, acc.: 46.88%] [G loss: 0.761195]\n",
      "epoch:6 step:5704 [D loss: 0.707653, acc.: 42.97%] [G loss: 0.774672]\n",
      "epoch:6 step:5705 [D loss: 0.693901, acc.: 55.47%] [G loss: 0.721970]\n",
      "epoch:6 step:5706 [D loss: 0.698650, acc.: 50.78%] [G loss: 0.754216]\n",
      "epoch:6 step:5707 [D loss: 0.685891, acc.: 50.78%] [G loss: 0.750186]\n",
      "epoch:6 step:5708 [D loss: 0.685751, acc.: 51.56%] [G loss: 0.733431]\n",
      "epoch:6 step:5709 [D loss: 0.685599, acc.: 50.00%] [G loss: 0.754745]\n",
      "epoch:6 step:5710 [D loss: 0.677455, acc.: 56.25%] [G loss: 0.766556]\n",
      "epoch:6 step:5711 [D loss: 0.686942, acc.: 50.00%] [G loss: 0.798685]\n",
      "epoch:6 step:5712 [D loss: 0.683464, acc.: 57.03%] [G loss: 0.808640]\n",
      "epoch:6 step:5713 [D loss: 0.664075, acc.: 60.94%] [G loss: 0.813348]\n",
      "epoch:6 step:5714 [D loss: 0.643928, acc.: 60.94%] [G loss: 0.789019]\n",
      "epoch:6 step:5715 [D loss: 0.639882, acc.: 58.59%] [G loss: 0.789695]\n",
      "epoch:6 step:5716 [D loss: 0.720505, acc.: 51.56%] [G loss: 0.827607]\n",
      "epoch:6 step:5717 [D loss: 0.693505, acc.: 53.91%] [G loss: 0.814313]\n",
      "epoch:6 step:5718 [D loss: 0.686200, acc.: 57.81%] [G loss: 0.801245]\n",
      "epoch:6 step:5719 [D loss: 0.660412, acc.: 64.84%] [G loss: 0.801028]\n",
      "epoch:6 step:5720 [D loss: 0.708002, acc.: 50.00%] [G loss: 0.804011]\n",
      "epoch:6 step:5721 [D loss: 0.704685, acc.: 53.91%] [G loss: 0.811146]\n",
      "epoch:6 step:5722 [D loss: 0.659321, acc.: 67.19%] [G loss: 0.788938]\n",
      "epoch:6 step:5723 [D loss: 0.698713, acc.: 51.56%] [G loss: 0.793751]\n",
      "epoch:6 step:5724 [D loss: 0.663024, acc.: 59.38%] [G loss: 0.833529]\n",
      "epoch:6 step:5725 [D loss: 0.696108, acc.: 51.56%] [G loss: 0.799019]\n",
      "epoch:6 step:5726 [D loss: 0.675717, acc.: 54.69%] [G loss: 0.799228]\n",
      "epoch:6 step:5727 [D loss: 0.686973, acc.: 53.12%] [G loss: 0.761782]\n",
      "epoch:6 step:5728 [D loss: 0.644537, acc.: 65.62%] [G loss: 0.806977]\n",
      "epoch:6 step:5729 [D loss: 0.658828, acc.: 61.72%] [G loss: 0.720073]\n",
      "epoch:6 step:5730 [D loss: 0.727679, acc.: 56.25%] [G loss: 0.752218]\n",
      "epoch:6 step:5731 [D loss: 0.709304, acc.: 52.34%] [G loss: 0.758969]\n",
      "epoch:6 step:5732 [D loss: 0.684856, acc.: 52.34%] [G loss: 0.817248]\n",
      "epoch:6 step:5733 [D loss: 0.685047, acc.: 50.78%] [G loss: 0.864573]\n",
      "epoch:6 step:5734 [D loss: 0.674092, acc.: 57.81%] [G loss: 0.829910]\n",
      "epoch:6 step:5735 [D loss: 0.656274, acc.: 57.03%] [G loss: 0.877799]\n",
      "epoch:6 step:5736 [D loss: 0.692794, acc.: 52.34%] [G loss: 0.830136]\n",
      "epoch:6 step:5737 [D loss: 0.676458, acc.: 57.03%] [G loss: 0.871177]\n",
      "epoch:6 step:5738 [D loss: 0.712467, acc.: 50.00%] [G loss: 0.865128]\n",
      "epoch:6 step:5739 [D loss: 0.742555, acc.: 43.75%] [G loss: 0.871918]\n",
      "epoch:6 step:5740 [D loss: 0.684090, acc.: 51.56%] [G loss: 0.753828]\n",
      "epoch:6 step:5741 [D loss: 0.704769, acc.: 46.88%] [G loss: 0.745153]\n",
      "epoch:6 step:5742 [D loss: 0.739755, acc.: 44.53%] [G loss: 0.741985]\n",
      "epoch:6 step:5743 [D loss: 0.740569, acc.: 42.97%] [G loss: 0.741817]\n",
      "epoch:6 step:5744 [D loss: 0.705028, acc.: 44.53%] [G loss: 0.738434]\n",
      "epoch:6 step:5745 [D loss: 0.695972, acc.: 60.94%] [G loss: 0.765309]\n",
      "epoch:6 step:5746 [D loss: 0.702474, acc.: 50.00%] [G loss: 0.719656]\n",
      "epoch:6 step:5747 [D loss: 0.667463, acc.: 60.16%] [G loss: 0.766851]\n",
      "epoch:6 step:5748 [D loss: 0.642917, acc.: 68.75%] [G loss: 0.784095]\n",
      "epoch:6 step:5749 [D loss: 0.668922, acc.: 59.38%] [G loss: 0.768886]\n",
      "epoch:6 step:5750 [D loss: 0.698219, acc.: 48.44%] [G loss: 0.782487]\n",
      "epoch:6 step:5751 [D loss: 0.689287, acc.: 51.56%] [G loss: 0.775011]\n",
      "epoch:6 step:5752 [D loss: 0.658709, acc.: 60.94%] [G loss: 0.807359]\n",
      "epoch:6 step:5753 [D loss: 0.662542, acc.: 64.06%] [G loss: 0.759815]\n",
      "epoch:6 step:5754 [D loss: 0.679107, acc.: 57.03%] [G loss: 0.781199]\n",
      "epoch:6 step:5755 [D loss: 0.713833, acc.: 42.19%] [G loss: 0.787019]\n",
      "epoch:6 step:5756 [D loss: 0.677771, acc.: 62.50%] [G loss: 0.750410]\n",
      "epoch:6 step:5757 [D loss: 0.669089, acc.: 57.81%] [G loss: 0.757357]\n",
      "epoch:6 step:5758 [D loss: 0.675951, acc.: 57.03%] [G loss: 0.748107]\n",
      "epoch:6 step:5759 [D loss: 0.690096, acc.: 50.78%] [G loss: 0.743991]\n",
      "epoch:6 step:5760 [D loss: 0.703738, acc.: 52.34%] [G loss: 0.731604]\n",
      "epoch:6 step:5761 [D loss: 0.674270, acc.: 54.69%] [G loss: 0.754557]\n",
      "epoch:6 step:5762 [D loss: 0.656420, acc.: 60.16%] [G loss: 0.751754]\n",
      "epoch:6 step:5763 [D loss: 0.695673, acc.: 53.12%] [G loss: 0.752095]\n",
      "epoch:6 step:5764 [D loss: 0.675810, acc.: 53.91%] [G loss: 0.777037]\n",
      "epoch:6 step:5765 [D loss: 0.659550, acc.: 64.84%] [G loss: 0.782741]\n",
      "epoch:6 step:5766 [D loss: 0.663878, acc.: 58.59%] [G loss: 0.771233]\n",
      "epoch:6 step:5767 [D loss: 0.640019, acc.: 64.84%] [G loss: 0.811809]\n",
      "epoch:6 step:5768 [D loss: 0.687172, acc.: 51.56%] [G loss: 0.826279]\n",
      "epoch:6 step:5769 [D loss: 0.718157, acc.: 47.66%] [G loss: 0.759236]\n",
      "epoch:6 step:5770 [D loss: 0.720796, acc.: 44.53%] [G loss: 0.820218]\n",
      "epoch:6 step:5771 [D loss: 0.689152, acc.: 49.22%] [G loss: 0.727824]\n",
      "epoch:6 step:5772 [D loss: 0.695452, acc.: 51.56%] [G loss: 0.753901]\n",
      "epoch:6 step:5773 [D loss: 0.669389, acc.: 60.94%] [G loss: 0.799848]\n",
      "epoch:6 step:5774 [D loss: 0.653677, acc.: 62.50%] [G loss: 0.785165]\n",
      "epoch:6 step:5775 [D loss: 0.696535, acc.: 54.69%] [G loss: 0.853316]\n",
      "epoch:6 step:5776 [D loss: 0.722883, acc.: 48.44%] [G loss: 0.785241]\n",
      "epoch:6 step:5777 [D loss: 0.729588, acc.: 39.84%] [G loss: 0.787480]\n",
      "epoch:6 step:5778 [D loss: 0.695329, acc.: 46.88%] [G loss: 0.829201]\n",
      "epoch:6 step:5779 [D loss: 0.721000, acc.: 43.75%] [G loss: 0.784266]\n",
      "epoch:6 step:5780 [D loss: 0.715025, acc.: 50.00%] [G loss: 0.772908]\n",
      "epoch:6 step:5781 [D loss: 0.705308, acc.: 48.44%] [G loss: 0.728521]\n",
      "epoch:6 step:5782 [D loss: 0.743006, acc.: 42.97%] [G loss: 0.751034]\n",
      "epoch:6 step:5783 [D loss: 0.734775, acc.: 45.31%] [G loss: 0.780194]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:6 step:5784 [D loss: 0.683655, acc.: 56.25%] [G loss: 0.737878]\n",
      "epoch:6 step:5785 [D loss: 0.682353, acc.: 51.56%] [G loss: 0.782954]\n",
      "epoch:6 step:5786 [D loss: 0.662652, acc.: 61.72%] [G loss: 0.718637]\n",
      "epoch:6 step:5787 [D loss: 0.658879, acc.: 61.72%] [G loss: 0.798930]\n",
      "epoch:6 step:5788 [D loss: 0.699975, acc.: 46.09%] [G loss: 0.757129]\n",
      "epoch:6 step:5789 [D loss: 0.671037, acc.: 57.03%] [G loss: 0.750597]\n",
      "epoch:6 step:5790 [D loss: 0.662603, acc.: 57.81%] [G loss: 0.779119]\n",
      "epoch:6 step:5791 [D loss: 0.664100, acc.: 64.84%] [G loss: 0.781110]\n",
      "epoch:6 step:5792 [D loss: 0.702802, acc.: 52.34%] [G loss: 0.778261]\n",
      "epoch:6 step:5793 [D loss: 0.692145, acc.: 53.12%] [G loss: 0.765198]\n",
      "epoch:6 step:5794 [D loss: 0.685275, acc.: 57.03%] [G loss: 0.712057]\n",
      "epoch:6 step:5795 [D loss: 0.706454, acc.: 51.56%] [G loss: 0.744161]\n",
      "epoch:6 step:5796 [D loss: 0.675578, acc.: 56.25%] [G loss: 0.737959]\n",
      "epoch:6 step:5797 [D loss: 0.679271, acc.: 52.34%] [G loss: 0.748255]\n",
      "epoch:6 step:5798 [D loss: 0.669630, acc.: 58.59%] [G loss: 0.742898]\n",
      "epoch:6 step:5799 [D loss: 0.689856, acc.: 50.78%] [G loss: 0.776233]\n",
      "epoch:6 step:5800 [D loss: 0.728942, acc.: 47.66%] [G loss: 0.744407]\n",
      "##############\n",
      "[4.06639911 2.32011261 6.37106272 5.75998266 4.33226035 6.13754701\n",
      " 4.74283535 5.46660125 5.25841784 4.76509147]\n",
      "##########\n",
      "epoch:6 step:5801 [D loss: 0.705924, acc.: 52.34%] [G loss: 0.741231]\n",
      "epoch:6 step:5802 [D loss: 0.712362, acc.: 44.53%] [G loss: 0.763470]\n",
      "epoch:6 step:5803 [D loss: 0.675302, acc.: 58.59%] [G loss: 0.768902]\n",
      "epoch:6 step:5804 [D loss: 0.697029, acc.: 49.22%] [G loss: 0.794025]\n",
      "epoch:6 step:5805 [D loss: 0.685885, acc.: 52.34%] [G loss: 0.774305]\n",
      "epoch:6 step:5806 [D loss: 0.658491, acc.: 57.03%] [G loss: 0.791083]\n",
      "epoch:6 step:5807 [D loss: 0.698265, acc.: 47.66%] [G loss: 0.836832]\n",
      "epoch:6 step:5808 [D loss: 0.738857, acc.: 48.44%] [G loss: 0.842441]\n",
      "epoch:6 step:5809 [D loss: 0.683377, acc.: 57.03%] [G loss: 0.771745]\n",
      "epoch:6 step:5810 [D loss: 0.693697, acc.: 54.69%] [G loss: 0.759795]\n",
      "epoch:6 step:5811 [D loss: 0.700010, acc.: 52.34%] [G loss: 0.774105]\n",
      "epoch:6 step:5812 [D loss: 0.668250, acc.: 57.81%] [G loss: 0.738934]\n",
      "epoch:6 step:5813 [D loss: 0.680300, acc.: 57.81%] [G loss: 0.783691]\n",
      "epoch:6 step:5814 [D loss: 0.703835, acc.: 46.88%] [G loss: 0.724041]\n",
      "epoch:6 step:5815 [D loss: 0.708140, acc.: 43.75%] [G loss: 0.749820]\n",
      "epoch:6 step:5816 [D loss: 0.689343, acc.: 48.44%] [G loss: 0.758901]\n",
      "epoch:6 step:5817 [D loss: 0.699272, acc.: 54.69%] [G loss: 0.735536]\n",
      "epoch:6 step:5818 [D loss: 0.695073, acc.: 49.22%] [G loss: 0.737682]\n",
      "epoch:6 step:5819 [D loss: 0.689222, acc.: 53.91%] [G loss: 0.825781]\n",
      "epoch:6 step:5820 [D loss: 0.677709, acc.: 50.00%] [G loss: 0.838478]\n",
      "epoch:6 step:5821 [D loss: 0.666589, acc.: 60.16%] [G loss: 0.806774]\n",
      "epoch:6 step:5822 [D loss: 0.702288, acc.: 47.66%] [G loss: 0.817621]\n",
      "epoch:6 step:5823 [D loss: 0.692239, acc.: 48.44%] [G loss: 0.801087]\n",
      "epoch:6 step:5824 [D loss: 0.675307, acc.: 57.03%] [G loss: 0.758002]\n",
      "epoch:6 step:5825 [D loss: 0.707884, acc.: 50.78%] [G loss: 0.821247]\n",
      "epoch:6 step:5826 [D loss: 0.702197, acc.: 49.22%] [G loss: 0.777103]\n",
      "epoch:6 step:5827 [D loss: 0.684031, acc.: 56.25%] [G loss: 0.766024]\n",
      "epoch:6 step:5828 [D loss: 0.688747, acc.: 52.34%] [G loss: 0.783205]\n",
      "epoch:6 step:5829 [D loss: 0.664275, acc.: 60.94%] [G loss: 0.796647]\n",
      "epoch:6 step:5830 [D loss: 0.671298, acc.: 57.03%] [G loss: 0.792999]\n",
      "epoch:6 step:5831 [D loss: 0.667596, acc.: 57.81%] [G loss: 0.756549]\n",
      "epoch:6 step:5832 [D loss: 0.726990, acc.: 47.66%] [G loss: 0.797654]\n",
      "epoch:6 step:5833 [D loss: 0.713423, acc.: 44.53%] [G loss: 0.716262]\n",
      "epoch:6 step:5834 [D loss: 0.677298, acc.: 56.25%] [G loss: 0.782814]\n",
      "epoch:6 step:5835 [D loss: 0.687647, acc.: 52.34%] [G loss: 0.826368]\n",
      "epoch:6 step:5836 [D loss: 0.723431, acc.: 48.44%] [G loss: 0.801677]\n",
      "epoch:6 step:5837 [D loss: 0.720563, acc.: 43.75%] [G loss: 0.759862]\n",
      "epoch:6 step:5838 [D loss: 0.745773, acc.: 39.84%] [G loss: 0.737266]\n",
      "epoch:6 step:5839 [D loss: 0.719974, acc.: 47.66%] [G loss: 0.711210]\n",
      "epoch:6 step:5840 [D loss: 0.700237, acc.: 49.22%] [G loss: 0.727297]\n",
      "epoch:6 step:5841 [D loss: 0.710106, acc.: 48.44%] [G loss: 0.737531]\n",
      "epoch:6 step:5842 [D loss: 0.710069, acc.: 46.09%] [G loss: 0.756611]\n",
      "epoch:6 step:5843 [D loss: 0.653948, acc.: 63.28%] [G loss: 0.731742]\n",
      "epoch:6 step:5844 [D loss: 0.663308, acc.: 62.50%] [G loss: 0.741081]\n",
      "epoch:6 step:5845 [D loss: 0.609445, acc.: 73.44%] [G loss: 0.763338]\n",
      "epoch:6 step:5846 [D loss: 0.676913, acc.: 59.38%] [G loss: 0.830483]\n",
      "epoch:6 step:5847 [D loss: 0.702120, acc.: 50.78%] [G loss: 0.815483]\n",
      "epoch:6 step:5848 [D loss: 0.673516, acc.: 58.59%] [G loss: 0.790256]\n",
      "epoch:6 step:5849 [D loss: 0.680513, acc.: 59.38%] [G loss: 0.760495]\n",
      "epoch:6 step:5850 [D loss: 0.683883, acc.: 55.47%] [G loss: 0.773247]\n",
      "epoch:6 step:5851 [D loss: 0.632802, acc.: 66.41%] [G loss: 0.866381]\n",
      "epoch:6 step:5852 [D loss: 0.579753, acc.: 71.09%] [G loss: 0.807312]\n",
      "epoch:6 step:5853 [D loss: 0.630856, acc.: 60.94%] [G loss: 0.809973]\n",
      "epoch:6 step:5854 [D loss: 0.570875, acc.: 69.53%] [G loss: 0.748874]\n",
      "epoch:6 step:5855 [D loss: 0.708726, acc.: 54.69%] [G loss: 0.686924]\n",
      "epoch:6 step:5856 [D loss: 0.651344, acc.: 59.38%] [G loss: 0.794506]\n",
      "epoch:6 step:5857 [D loss: 0.786048, acc.: 38.28%] [G loss: 0.846618]\n",
      "epoch:6 step:5858 [D loss: 0.723112, acc.: 49.22%] [G loss: 0.774164]\n",
      "epoch:6 step:5859 [D loss: 0.718581, acc.: 44.53%] [G loss: 0.851762]\n",
      "epoch:6 step:5860 [D loss: 0.678441, acc.: 52.34%] [G loss: 0.831268]\n",
      "epoch:6 step:5861 [D loss: 0.687127, acc.: 50.00%] [G loss: 0.852983]\n",
      "epoch:6 step:5862 [D loss: 0.668321, acc.: 57.81%] [G loss: 0.899023]\n",
      "epoch:6 step:5863 [D loss: 0.687798, acc.: 55.47%] [G loss: 0.922373]\n",
      "epoch:6 step:5864 [D loss: 0.671904, acc.: 54.69%] [G loss: 0.818291]\n",
      "epoch:6 step:5865 [D loss: 0.704273, acc.: 54.69%] [G loss: 0.798922]\n",
      "epoch:6 step:5866 [D loss: 0.702961, acc.: 55.47%] [G loss: 0.798513]\n",
      "epoch:6 step:5867 [D loss: 0.704893, acc.: 47.66%] [G loss: 0.758370]\n",
      "epoch:6 step:5868 [D loss: 0.752397, acc.: 42.97%] [G loss: 0.776394]\n",
      "epoch:6 step:5869 [D loss: 0.694469, acc.: 49.22%] [G loss: 0.771035]\n",
      "epoch:6 step:5870 [D loss: 0.683338, acc.: 49.22%] [G loss: 0.788419]\n",
      "epoch:6 step:5871 [D loss: 0.688541, acc.: 53.91%] [G loss: 0.786095]\n",
      "epoch:6 step:5872 [D loss: 0.701183, acc.: 51.56%] [G loss: 0.796728]\n",
      "epoch:6 step:5873 [D loss: 0.701505, acc.: 46.88%] [G loss: 0.745070]\n",
      "epoch:6 step:5874 [D loss: 0.703374, acc.: 49.22%] [G loss: 0.779522]\n",
      "epoch:6 step:5875 [D loss: 0.694666, acc.: 50.78%] [G loss: 0.747208]\n",
      "epoch:6 step:5876 [D loss: 0.690482, acc.: 49.22%] [G loss: 0.747394]\n",
      "epoch:6 step:5877 [D loss: 0.688731, acc.: 55.47%] [G loss: 0.785646]\n",
      "epoch:6 step:5878 [D loss: 0.683917, acc.: 58.59%] [G loss: 0.746304]\n",
      "epoch:6 step:5879 [D loss: 0.682124, acc.: 59.38%] [G loss: 0.721810]\n",
      "epoch:6 step:5880 [D loss: 0.680759, acc.: 56.25%] [G loss: 0.737241]\n",
      "epoch:6 step:5881 [D loss: 0.689566, acc.: 56.25%] [G loss: 0.755132]\n",
      "epoch:6 step:5882 [D loss: 0.685949, acc.: 51.56%] [G loss: 0.762162]\n",
      "epoch:6 step:5883 [D loss: 0.667290, acc.: 60.16%] [G loss: 0.810145]\n",
      "epoch:6 step:5884 [D loss: 0.668143, acc.: 56.25%] [G loss: 0.758800]\n",
      "epoch:6 step:5885 [D loss: 0.711352, acc.: 49.22%] [G loss: 0.778847]\n",
      "epoch:6 step:5886 [D loss: 0.704794, acc.: 51.56%] [G loss: 0.768993]\n",
      "epoch:6 step:5887 [D loss: 0.674550, acc.: 60.94%] [G loss: 0.750688]\n",
      "epoch:6 step:5888 [D loss: 0.687769, acc.: 55.47%] [G loss: 0.752952]\n",
      "epoch:6 step:5889 [D loss: 0.687325, acc.: 54.69%] [G loss: 0.739012]\n",
      "epoch:6 step:5890 [D loss: 0.719016, acc.: 50.00%] [G loss: 0.699288]\n",
      "epoch:6 step:5891 [D loss: 0.697846, acc.: 49.22%] [G loss: 0.773555]\n",
      "epoch:6 step:5892 [D loss: 0.695134, acc.: 50.00%] [G loss: 0.723383]\n",
      "epoch:6 step:5893 [D loss: 0.717138, acc.: 46.88%] [G loss: 0.760909]\n",
      "epoch:6 step:5894 [D loss: 0.715646, acc.: 44.53%] [G loss: 0.801140]\n",
      "epoch:6 step:5895 [D loss: 0.686495, acc.: 53.91%] [G loss: 0.807089]\n",
      "epoch:6 step:5896 [D loss: 0.663506, acc.: 62.50%] [G loss: 0.791755]\n",
      "epoch:6 step:5897 [D loss: 0.681068, acc.: 51.56%] [G loss: 0.770319]\n",
      "epoch:6 step:5898 [D loss: 0.665476, acc.: 55.47%] [G loss: 0.809558]\n",
      "epoch:6 step:5899 [D loss: 0.682708, acc.: 57.03%] [G loss: 0.775815]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:6 step:5900 [D loss: 0.704308, acc.: 53.91%] [G loss: 0.763677]\n",
      "epoch:6 step:5901 [D loss: 0.696496, acc.: 52.34%] [G loss: 0.750350]\n",
      "epoch:6 step:5902 [D loss: 0.704657, acc.: 48.44%] [G loss: 0.724983]\n",
      "epoch:6 step:5903 [D loss: 0.731054, acc.: 43.75%] [G loss: 0.719666]\n",
      "epoch:6 step:5904 [D loss: 0.692062, acc.: 50.78%] [G loss: 0.775517]\n",
      "epoch:6 step:5905 [D loss: 0.679164, acc.: 52.34%] [G loss: 0.748701]\n",
      "epoch:6 step:5906 [D loss: 0.666563, acc.: 60.94%] [G loss: 0.790445]\n",
      "epoch:6 step:5907 [D loss: 0.676707, acc.: 57.81%] [G loss: 0.791830]\n",
      "epoch:6 step:5908 [D loss: 0.686592, acc.: 56.25%] [G loss: 0.762066]\n",
      "epoch:6 step:5909 [D loss: 0.667256, acc.: 60.94%] [G loss: 0.834566]\n",
      "epoch:6 step:5910 [D loss: 0.699032, acc.: 50.00%] [G loss: 0.820405]\n",
      "epoch:6 step:5911 [D loss: 0.655810, acc.: 60.94%] [G loss: 0.759030]\n",
      "epoch:6 step:5912 [D loss: 0.684340, acc.: 53.12%] [G loss: 0.735606]\n",
      "epoch:6 step:5913 [D loss: 0.713391, acc.: 47.66%] [G loss: 0.760654]\n",
      "epoch:6 step:5914 [D loss: 0.682892, acc.: 53.12%] [G loss: 0.767821]\n",
      "epoch:6 step:5915 [D loss: 0.692441, acc.: 57.81%] [G loss: 0.744855]\n",
      "epoch:6 step:5916 [D loss: 0.693115, acc.: 53.91%] [G loss: 0.745634]\n",
      "epoch:6 step:5917 [D loss: 0.704588, acc.: 50.00%] [G loss: 0.764837]\n",
      "epoch:6 step:5918 [D loss: 0.686858, acc.: 54.69%] [G loss: 0.767240]\n",
      "epoch:6 step:5919 [D loss: 0.698762, acc.: 50.78%] [G loss: 0.763081]\n",
      "epoch:6 step:5920 [D loss: 0.683952, acc.: 53.12%] [G loss: 0.775629]\n",
      "epoch:6 step:5921 [D loss: 0.680696, acc.: 54.69%] [G loss: 0.766477]\n",
      "epoch:6 step:5922 [D loss: 0.674849, acc.: 60.94%] [G loss: 0.774338]\n",
      "epoch:6 step:5923 [D loss: 0.716359, acc.: 47.66%] [G loss: 0.760056]\n",
      "epoch:6 step:5924 [D loss: 0.703816, acc.: 50.78%] [G loss: 0.765333]\n",
      "epoch:6 step:5925 [D loss: 0.699795, acc.: 51.56%] [G loss: 0.708105]\n",
      "epoch:6 step:5926 [D loss: 0.711401, acc.: 40.62%] [G loss: 0.742567]\n",
      "epoch:6 step:5927 [D loss: 0.713632, acc.: 49.22%] [G loss: 0.749912]\n",
      "epoch:6 step:5928 [D loss: 0.696056, acc.: 53.12%] [G loss: 0.776116]\n",
      "epoch:6 step:5929 [D loss: 0.656793, acc.: 65.62%] [G loss: 0.792878]\n",
      "epoch:6 step:5930 [D loss: 0.692348, acc.: 56.25%] [G loss: 0.773537]\n",
      "epoch:6 step:5931 [D loss: 0.660492, acc.: 67.19%] [G loss: 0.782309]\n",
      "epoch:6 step:5932 [D loss: 0.661899, acc.: 61.72%] [G loss: 0.794592]\n",
      "epoch:6 step:5933 [D loss: 0.659097, acc.: 63.28%] [G loss: 0.771684]\n",
      "epoch:6 step:5934 [D loss: 0.603612, acc.: 69.53%] [G loss: 0.729254]\n",
      "epoch:6 step:5935 [D loss: 0.596217, acc.: 64.84%] [G loss: 0.716558]\n",
      "epoch:6 step:5936 [D loss: 0.514673, acc.: 78.12%] [G loss: 0.809260]\n",
      "epoch:6 step:5937 [D loss: 0.604812, acc.: 68.75%] [G loss: 0.732801]\n",
      "epoch:6 step:5938 [D loss: 0.741826, acc.: 42.97%] [G loss: 0.665500]\n",
      "epoch:6 step:5939 [D loss: 0.712540, acc.: 46.88%] [G loss: 0.743817]\n",
      "epoch:6 step:5940 [D loss: 0.730234, acc.: 45.31%] [G loss: 0.655477]\n",
      "epoch:6 step:5941 [D loss: 0.717278, acc.: 42.19%] [G loss: 0.782449]\n",
      "epoch:6 step:5942 [D loss: 0.726800, acc.: 42.97%] [G loss: 0.787917]\n",
      "epoch:6 step:5943 [D loss: 0.713494, acc.: 43.75%] [G loss: 0.791393]\n",
      "epoch:6 step:5944 [D loss: 0.698809, acc.: 53.12%] [G loss: 0.836809]\n",
      "epoch:6 step:5945 [D loss: 0.669859, acc.: 60.94%] [G loss: 0.861773]\n",
      "epoch:6 step:5946 [D loss: 0.665899, acc.: 60.94%] [G loss: 0.899251]\n",
      "epoch:6 step:5947 [D loss: 0.658873, acc.: 62.50%] [G loss: 0.914252]\n",
      "epoch:6 step:5948 [D loss: 0.659806, acc.: 56.25%] [G loss: 0.834149]\n",
      "epoch:6 step:5949 [D loss: 0.689282, acc.: 49.22%] [G loss: 1.379780]\n",
      "epoch:6 step:5950 [D loss: 0.709141, acc.: 53.12%] [G loss: 0.978019]\n",
      "epoch:6 step:5951 [D loss: 0.733953, acc.: 42.19%] [G loss: 0.754646]\n",
      "epoch:6 step:5952 [D loss: 0.741308, acc.: 36.72%] [G loss: 0.816386]\n",
      "epoch:6 step:5953 [D loss: 0.715584, acc.: 49.22%] [G loss: 0.776352]\n",
      "epoch:6 step:5954 [D loss: 0.715366, acc.: 46.88%] [G loss: 0.789889]\n",
      "epoch:6 step:5955 [D loss: 0.674603, acc.: 51.56%] [G loss: 0.797888]\n",
      "epoch:6 step:5956 [D loss: 0.678629, acc.: 49.22%] [G loss: 0.825145]\n",
      "epoch:6 step:5957 [D loss: 0.678720, acc.: 48.44%] [G loss: 0.871091]\n",
      "epoch:6 step:5958 [D loss: 0.636673, acc.: 61.72%] [G loss: 0.845817]\n",
      "epoch:6 step:5959 [D loss: 0.653194, acc.: 57.03%] [G loss: 0.706401]\n",
      "epoch:6 step:5960 [D loss: 0.648842, acc.: 64.84%] [G loss: 0.835349]\n",
      "epoch:6 step:5961 [D loss: 0.675265, acc.: 57.03%] [G loss: 0.795224]\n",
      "epoch:6 step:5962 [D loss: 0.672262, acc.: 53.91%] [G loss: 0.733069]\n",
      "epoch:6 step:5963 [D loss: 0.716206, acc.: 53.12%] [G loss: 0.804775]\n",
      "epoch:6 step:5964 [D loss: 0.701423, acc.: 53.12%] [G loss: 0.787325]\n",
      "epoch:6 step:5965 [D loss: 0.652442, acc.: 60.16%] [G loss: 0.771069]\n",
      "epoch:6 step:5966 [D loss: 0.679881, acc.: 57.81%] [G loss: 0.805381]\n",
      "epoch:6 step:5967 [D loss: 0.661836, acc.: 61.72%] [G loss: 0.791191]\n",
      "epoch:6 step:5968 [D loss: 0.648339, acc.: 54.69%] [G loss: 0.854761]\n",
      "epoch:6 step:5969 [D loss: 0.636877, acc.: 62.50%] [G loss: 0.793205]\n",
      "epoch:6 step:5970 [D loss: 0.776710, acc.: 39.84%] [G loss: 0.802662]\n",
      "epoch:6 step:5971 [D loss: 0.732965, acc.: 39.84%] [G loss: 0.787989]\n",
      "epoch:6 step:5972 [D loss: 0.776976, acc.: 48.44%] [G loss: 0.793076]\n",
      "epoch:6 step:5973 [D loss: 0.682056, acc.: 53.12%] [G loss: 0.795880]\n",
      "epoch:6 step:5974 [D loss: 0.685217, acc.: 53.91%] [G loss: 0.791914]\n",
      "epoch:6 step:5975 [D loss: 0.661360, acc.: 59.38%] [G loss: 0.816719]\n",
      "epoch:6 step:5976 [D loss: 0.648426, acc.: 58.59%] [G loss: 0.891317]\n",
      "epoch:6 step:5977 [D loss: 0.706241, acc.: 48.44%] [G loss: 0.776171]\n",
      "epoch:6 step:5978 [D loss: 0.670437, acc.: 57.03%] [G loss: 0.789751]\n",
      "epoch:6 step:5979 [D loss: 0.718660, acc.: 50.78%] [G loss: 0.755521]\n",
      "epoch:6 step:5980 [D loss: 0.679737, acc.: 56.25%] [G loss: 0.745043]\n",
      "epoch:6 step:5981 [D loss: 0.679540, acc.: 56.25%] [G loss: 0.779406]\n",
      "epoch:6 step:5982 [D loss: 0.671751, acc.: 60.16%] [G loss: 0.763942]\n",
      "epoch:6 step:5983 [D loss: 0.688397, acc.: 50.00%] [G loss: 0.813195]\n",
      "epoch:6 step:5984 [D loss: 0.715442, acc.: 46.09%] [G loss: 0.768710]\n",
      "epoch:6 step:5985 [D loss: 0.704214, acc.: 49.22%] [G loss: 0.767288]\n",
      "epoch:6 step:5986 [D loss: 0.722261, acc.: 37.50%] [G loss: 0.760732]\n",
      "epoch:6 step:5987 [D loss: 0.706707, acc.: 51.56%] [G loss: 0.780458]\n",
      "epoch:6 step:5988 [D loss: 0.699903, acc.: 53.12%] [G loss: 0.779501]\n",
      "epoch:6 step:5989 [D loss: 0.615795, acc.: 68.75%] [G loss: 0.832566]\n",
      "epoch:6 step:5990 [D loss: 0.685667, acc.: 57.03%] [G loss: 0.801152]\n",
      "epoch:6 step:5991 [D loss: 0.659041, acc.: 66.41%] [G loss: 0.828161]\n",
      "epoch:6 step:5992 [D loss: 0.692602, acc.: 54.69%] [G loss: 0.807087]\n",
      "epoch:6 step:5993 [D loss: 0.667440, acc.: 60.16%] [G loss: 0.866269]\n",
      "epoch:6 step:5994 [D loss: 0.652965, acc.: 62.50%] [G loss: 0.856296]\n",
      "epoch:6 step:5995 [D loss: 0.696791, acc.: 51.56%] [G loss: 0.811381]\n",
      "epoch:6 step:5996 [D loss: 0.663478, acc.: 56.25%] [G loss: 0.833643]\n",
      "epoch:6 step:5997 [D loss: 0.654876, acc.: 60.16%] [G loss: 0.868962]\n",
      "epoch:6 step:5998 [D loss: 0.739288, acc.: 56.25%] [G loss: 0.818552]\n",
      "epoch:6 step:5999 [D loss: 0.667382, acc.: 54.69%] [G loss: 0.750949]\n",
      "epoch:6 step:6000 [D loss: 0.690366, acc.: 51.56%] [G loss: 0.743450]\n",
      "##############\n",
      "[2.92473424 1.86462836 6.38445289 5.39774773 4.24307806 5.82533612\n",
      " 4.66458134 5.49733252 5.26646048 4.58245427]\n",
      "##########\n",
      "epoch:6 step:6001 [D loss: 0.715944, acc.: 50.00%] [G loss: 0.758394]\n",
      "epoch:6 step:6002 [D loss: 0.699645, acc.: 49.22%] [G loss: 0.777978]\n",
      "epoch:6 step:6003 [D loss: 0.688727, acc.: 44.53%] [G loss: 0.722745]\n",
      "epoch:6 step:6004 [D loss: 0.710394, acc.: 47.66%] [G loss: 0.793371]\n",
      "epoch:6 step:6005 [D loss: 0.709102, acc.: 46.09%] [G loss: 0.738975]\n",
      "epoch:6 step:6006 [D loss: 0.703607, acc.: 50.78%] [G loss: 0.731409]\n",
      "epoch:6 step:6007 [D loss: 0.697599, acc.: 49.22%] [G loss: 0.741823]\n",
      "epoch:6 step:6008 [D loss: 0.689729, acc.: 55.47%] [G loss: 0.752735]\n",
      "epoch:6 step:6009 [D loss: 0.688271, acc.: 51.56%] [G loss: 0.738990]\n",
      "epoch:6 step:6010 [D loss: 0.671961, acc.: 57.03%] [G loss: 0.734089]\n",
      "epoch:6 step:6011 [D loss: 0.686136, acc.: 54.69%] [G loss: 0.769630]\n",
      "epoch:6 step:6012 [D loss: 0.705555, acc.: 50.78%] [G loss: 0.719616]\n",
      "epoch:6 step:6013 [D loss: 0.669523, acc.: 58.59%] [G loss: 0.765985]\n",
      "epoch:6 step:6014 [D loss: 0.706996, acc.: 49.22%] [G loss: 0.787498]\n",
      "epoch:6 step:6015 [D loss: 0.690097, acc.: 50.78%] [G loss: 0.739529]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:6 step:6016 [D loss: 0.682747, acc.: 56.25%] [G loss: 0.756470]\n",
      "epoch:6 step:6017 [D loss: 0.682312, acc.: 56.25%] [G loss: 0.754461]\n",
      "epoch:6 step:6018 [D loss: 0.733055, acc.: 47.66%] [G loss: 0.720241]\n",
      "epoch:6 step:6019 [D loss: 0.678354, acc.: 53.91%] [G loss: 0.714952]\n",
      "epoch:6 step:6020 [D loss: 0.694824, acc.: 58.59%] [G loss: 0.720864]\n",
      "epoch:6 step:6021 [D loss: 0.640821, acc.: 60.16%] [G loss: 0.689700]\n",
      "epoch:6 step:6022 [D loss: 0.686731, acc.: 59.38%] [G loss: 0.745402]\n",
      "epoch:6 step:6023 [D loss: 0.684395, acc.: 53.91%] [G loss: 0.721173]\n",
      "epoch:6 step:6024 [D loss: 0.656844, acc.: 61.72%] [G loss: 0.712641]\n",
      "epoch:6 step:6025 [D loss: 0.659329, acc.: 59.38%] [G loss: 0.697593]\n",
      "epoch:6 step:6026 [D loss: 0.644470, acc.: 64.06%] [G loss: 0.749022]\n",
      "epoch:6 step:6027 [D loss: 0.653716, acc.: 59.38%] [G loss: 0.770151]\n",
      "epoch:6 step:6028 [D loss: 0.677868, acc.: 60.16%] [G loss: 0.732606]\n",
      "epoch:6 step:6029 [D loss: 0.607126, acc.: 66.41%] [G loss: 0.719299]\n",
      "epoch:6 step:6030 [D loss: 0.734470, acc.: 52.34%] [G loss: 0.809851]\n",
      "epoch:6 step:6031 [D loss: 0.675866, acc.: 57.81%] [G loss: 0.856482]\n",
      "epoch:6 step:6032 [D loss: 0.666764, acc.: 56.25%] [G loss: 0.966697]\n",
      "epoch:6 step:6033 [D loss: 0.720705, acc.: 49.22%] [G loss: 0.882301]\n",
      "epoch:6 step:6034 [D loss: 0.676504, acc.: 53.12%] [G loss: 0.958248]\n",
      "epoch:6 step:6035 [D loss: 0.724779, acc.: 41.41%] [G loss: 0.807119]\n",
      "epoch:6 step:6036 [D loss: 0.696026, acc.: 53.91%] [G loss: 0.805422]\n",
      "epoch:6 step:6037 [D loss: 0.693806, acc.: 57.81%] [G loss: 0.758579]\n",
      "epoch:6 step:6038 [D loss: 0.657943, acc.: 62.50%] [G loss: 0.776045]\n",
      "epoch:6 step:6039 [D loss: 0.704055, acc.: 47.66%] [G loss: 0.721066]\n",
      "epoch:6 step:6040 [D loss: 0.759704, acc.: 36.72%] [G loss: 0.737282]\n",
      "epoch:6 step:6041 [D loss: 0.668470, acc.: 48.44%] [G loss: 0.753296]\n",
      "epoch:6 step:6042 [D loss: 0.676994, acc.: 52.34%] [G loss: 0.706369]\n",
      "epoch:6 step:6043 [D loss: 0.711920, acc.: 45.31%] [G loss: 0.787921]\n",
      "epoch:6 step:6044 [D loss: 0.707864, acc.: 47.66%] [G loss: 0.805281]\n",
      "epoch:6 step:6045 [D loss: 0.670439, acc.: 62.50%] [G loss: 0.839620]\n",
      "epoch:6 step:6046 [D loss: 0.681709, acc.: 58.59%] [G loss: 0.839285]\n",
      "epoch:6 step:6047 [D loss: 0.646032, acc.: 66.41%] [G loss: 0.802705]\n",
      "epoch:6 step:6048 [D loss: 0.639324, acc.: 66.41%] [G loss: 0.784564]\n",
      "epoch:6 step:6049 [D loss: 0.659941, acc.: 63.28%] [G loss: 0.794740]\n",
      "epoch:6 step:6050 [D loss: 0.646280, acc.: 56.25%] [G loss: 0.825257]\n",
      "epoch:6 step:6051 [D loss: 0.575292, acc.: 66.41%] [G loss: 0.906225]\n",
      "epoch:6 step:6052 [D loss: 0.656031, acc.: 59.38%] [G loss: 0.859505]\n",
      "epoch:6 step:6053 [D loss: 0.832015, acc.: 34.38%] [G loss: 0.900876]\n",
      "epoch:6 step:6054 [D loss: 0.763927, acc.: 35.94%] [G loss: 0.873660]\n",
      "epoch:6 step:6055 [D loss: 0.669862, acc.: 52.34%] [G loss: 1.057068]\n",
      "epoch:6 step:6056 [D loss: 0.695985, acc.: 53.12%] [G loss: 1.036853]\n",
      "epoch:6 step:6057 [D loss: 0.677587, acc.: 52.34%] [G loss: 0.836223]\n",
      "epoch:6 step:6058 [D loss: 0.692787, acc.: 53.12%] [G loss: 0.799629]\n",
      "epoch:6 step:6059 [D loss: 0.699092, acc.: 49.22%] [G loss: 0.786116]\n",
      "epoch:6 step:6060 [D loss: 0.684123, acc.: 58.59%] [G loss: 0.813918]\n",
      "epoch:6 step:6061 [D loss: 0.734403, acc.: 50.00%] [G loss: 0.791244]\n",
      "epoch:6 step:6062 [D loss: 0.704516, acc.: 50.00%] [G loss: 0.763776]\n",
      "epoch:6 step:6063 [D loss: 0.703886, acc.: 53.12%] [G loss: 0.774447]\n",
      "epoch:6 step:6064 [D loss: 0.696333, acc.: 56.25%] [G loss: 0.771014]\n",
      "epoch:6 step:6065 [D loss: 0.682993, acc.: 51.56%] [G loss: 0.752492]\n",
      "epoch:6 step:6066 [D loss: 0.684414, acc.: 54.69%] [G loss: 0.743605]\n",
      "epoch:6 step:6067 [D loss: 0.675982, acc.: 57.81%] [G loss: 0.766703]\n",
      "epoch:6 step:6068 [D loss: 0.674383, acc.: 55.47%] [G loss: 0.766250]\n",
      "epoch:6 step:6069 [D loss: 0.656351, acc.: 58.59%] [G loss: 0.792357]\n",
      "epoch:6 step:6070 [D loss: 0.706812, acc.: 51.56%] [G loss: 0.700879]\n",
      "epoch:6 step:6071 [D loss: 0.688371, acc.: 61.72%] [G loss: 0.779336]\n",
      "epoch:6 step:6072 [D loss: 0.669276, acc.: 59.38%] [G loss: 0.786477]\n",
      "epoch:6 step:6073 [D loss: 0.687389, acc.: 56.25%] [G loss: 0.735684]\n",
      "epoch:6 step:6074 [D loss: 0.647577, acc.: 66.41%] [G loss: 0.809964]\n",
      "epoch:6 step:6075 [D loss: 0.671861, acc.: 57.81%] [G loss: 0.813793]\n",
      "epoch:6 step:6076 [D loss: 0.651200, acc.: 67.97%] [G loss: 0.815202]\n",
      "epoch:6 step:6077 [D loss: 0.679502, acc.: 59.38%] [G loss: 0.831595]\n",
      "epoch:6 step:6078 [D loss: 0.685547, acc.: 56.25%] [G loss: 0.826454]\n",
      "epoch:6 step:6079 [D loss: 0.654872, acc.: 62.50%] [G loss: 0.823293]\n",
      "epoch:6 step:6080 [D loss: 0.677514, acc.: 57.81%] [G loss: 0.836510]\n",
      "epoch:6 step:6081 [D loss: 0.707069, acc.: 50.00%] [G loss: 0.728238]\n",
      "epoch:6 step:6082 [D loss: 0.688676, acc.: 59.38%] [G loss: 0.789513]\n",
      "epoch:6 step:6083 [D loss: 0.706224, acc.: 52.34%] [G loss: 0.778761]\n",
      "epoch:6 step:6084 [D loss: 0.715001, acc.: 46.88%] [G loss: 0.838796]\n",
      "epoch:6 step:6085 [D loss: 0.690432, acc.: 54.69%] [G loss: 0.796827]\n",
      "epoch:6 step:6086 [D loss: 0.696854, acc.: 50.78%] [G loss: 0.760897]\n",
      "epoch:6 step:6087 [D loss: 0.732303, acc.: 46.09%] [G loss: 0.741422]\n",
      "epoch:6 step:6088 [D loss: 0.708813, acc.: 42.97%] [G loss: 0.746271]\n",
      "epoch:6 step:6089 [D loss: 0.706465, acc.: 47.66%] [G loss: 0.733770]\n",
      "epoch:6 step:6090 [D loss: 0.703029, acc.: 53.91%] [G loss: 0.736625]\n",
      "epoch:6 step:6091 [D loss: 0.674138, acc.: 55.47%] [G loss: 0.744568]\n",
      "epoch:6 step:6092 [D loss: 0.689282, acc.: 52.34%] [G loss: 0.758213]\n",
      "epoch:6 step:6093 [D loss: 0.682938, acc.: 57.03%] [G loss: 0.760858]\n",
      "epoch:6 step:6094 [D loss: 0.693000, acc.: 53.91%] [G loss: 0.780062]\n",
      "epoch:6 step:6095 [D loss: 0.717113, acc.: 47.66%] [G loss: 0.741256]\n",
      "epoch:6 step:6096 [D loss: 0.704524, acc.: 49.22%] [G loss: 0.754456]\n",
      "epoch:6 step:6097 [D loss: 0.676328, acc.: 56.25%] [G loss: 0.783322]\n",
      "epoch:6 step:6098 [D loss: 0.673356, acc.: 61.72%] [G loss: 0.736137]\n",
      "epoch:6 step:6099 [D loss: 0.725634, acc.: 45.31%] [G loss: 0.742192]\n",
      "epoch:6 step:6100 [D loss: 0.670332, acc.: 64.06%] [G loss: 0.743424]\n",
      "epoch:6 step:6101 [D loss: 0.685692, acc.: 55.47%] [G loss: 0.738073]\n",
      "epoch:6 step:6102 [D loss: 0.683880, acc.: 57.03%] [G loss: 0.765141]\n",
      "epoch:6 step:6103 [D loss: 0.678486, acc.: 62.50%] [G loss: 0.764346]\n",
      "epoch:6 step:6104 [D loss: 0.688131, acc.: 53.91%] [G loss: 0.796317]\n",
      "epoch:6 step:6105 [D loss: 0.714462, acc.: 50.00%] [G loss: 0.738183]\n",
      "epoch:6 step:6106 [D loss: 0.712017, acc.: 47.66%] [G loss: 0.775119]\n",
      "epoch:6 step:6107 [D loss: 0.686289, acc.: 57.81%] [G loss: 0.737527]\n",
      "epoch:6 step:6108 [D loss: 0.680614, acc.: 57.03%] [G loss: 0.760188]\n",
      "epoch:6 step:6109 [D loss: 0.684328, acc.: 51.56%] [G loss: 0.760746]\n",
      "epoch:6 step:6110 [D loss: 0.645409, acc.: 64.84%] [G loss: 0.778713]\n",
      "epoch:6 step:6111 [D loss: 0.709710, acc.: 55.47%] [G loss: 0.755347]\n",
      "epoch:6 step:6112 [D loss: 0.711753, acc.: 49.22%] [G loss: 0.750059]\n",
      "epoch:6 step:6113 [D loss: 0.689674, acc.: 56.25%] [G loss: 0.738585]\n",
      "epoch:6 step:6114 [D loss: 0.694481, acc.: 49.22%] [G loss: 0.751025]\n",
      "epoch:6 step:6115 [D loss: 0.676821, acc.: 55.47%] [G loss: 0.743196]\n",
      "epoch:6 step:6116 [D loss: 0.672074, acc.: 58.59%] [G loss: 0.771039]\n",
      "epoch:6 step:6117 [D loss: 0.672574, acc.: 55.47%] [G loss: 0.782553]\n",
      "epoch:6 step:6118 [D loss: 0.678810, acc.: 59.38%] [G loss: 0.775830]\n",
      "epoch:6 step:6119 [D loss: 0.667902, acc.: 58.59%] [G loss: 0.760565]\n",
      "epoch:6 step:6120 [D loss: 0.637347, acc.: 61.72%] [G loss: 0.790306]\n",
      "epoch:6 step:6121 [D loss: 0.627794, acc.: 60.16%] [G loss: 0.813547]\n",
      "epoch:6 step:6122 [D loss: 0.702394, acc.: 56.25%] [G loss: 0.745795]\n",
      "epoch:6 step:6123 [D loss: 0.724369, acc.: 42.97%] [G loss: 0.734117]\n",
      "epoch:6 step:6124 [D loss: 0.708229, acc.: 48.44%] [G loss: 0.779522]\n",
      "epoch:6 step:6125 [D loss: 0.690382, acc.: 50.00%] [G loss: 0.794004]\n",
      "epoch:6 step:6126 [D loss: 0.690893, acc.: 50.78%] [G loss: 0.813715]\n",
      "epoch:6 step:6127 [D loss: 0.658861, acc.: 63.28%] [G loss: 0.802326]\n",
      "epoch:6 step:6128 [D loss: 0.671845, acc.: 57.03%] [G loss: 0.829658]\n",
      "epoch:6 step:6129 [D loss: 0.682298, acc.: 59.38%] [G loss: 0.850617]\n",
      "epoch:6 step:6130 [D loss: 0.668875, acc.: 61.72%] [G loss: 0.768337]\n",
      "epoch:6 step:6131 [D loss: 0.739045, acc.: 42.97%] [G loss: 0.816607]\n",
      "epoch:6 step:6132 [D loss: 0.698062, acc.: 52.34%] [G loss: 0.884010]\n",
      "epoch:6 step:6133 [D loss: 0.749928, acc.: 41.41%] [G loss: 0.803838]\n",
      "epoch:6 step:6134 [D loss: 0.698916, acc.: 50.00%] [G loss: 0.780004]\n",
      "epoch:6 step:6135 [D loss: 0.663881, acc.: 61.72%] [G loss: 0.757186]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:6 step:6136 [D loss: 0.685107, acc.: 57.03%] [G loss: 0.797089]\n",
      "epoch:6 step:6137 [D loss: 0.657086, acc.: 62.50%] [G loss: 0.774904]\n",
      "epoch:6 step:6138 [D loss: 0.663332, acc.: 62.50%] [G loss: 0.754239]\n",
      "epoch:6 step:6139 [D loss: 0.684973, acc.: 55.47%] [G loss: 0.781246]\n",
      "epoch:6 step:6140 [D loss: 0.682530, acc.: 54.69%] [G loss: 0.784085]\n",
      "epoch:6 step:6141 [D loss: 0.685388, acc.: 58.59%] [G loss: 0.770533]\n",
      "epoch:6 step:6142 [D loss: 0.667554, acc.: 60.94%] [G loss: 0.804715]\n",
      "epoch:6 step:6143 [D loss: 0.668937, acc.: 57.81%] [G loss: 0.810818]\n",
      "epoch:6 step:6144 [D loss: 0.657820, acc.: 64.84%] [G loss: 0.811038]\n",
      "epoch:6 step:6145 [D loss: 0.647035, acc.: 67.97%] [G loss: 0.759711]\n",
      "epoch:6 step:6146 [D loss: 0.678989, acc.: 57.81%] [G loss: 0.801250]\n",
      "epoch:6 step:6147 [D loss: 0.702767, acc.: 54.69%] [G loss: 0.824029]\n",
      "epoch:6 step:6148 [D loss: 0.651341, acc.: 60.16%] [G loss: 0.814489]\n",
      "epoch:6 step:6149 [D loss: 0.702199, acc.: 50.78%] [G loss: 0.793096]\n",
      "epoch:6 step:6150 [D loss: 0.708396, acc.: 49.22%] [G loss: 0.787116]\n",
      "epoch:6 step:6151 [D loss: 0.731657, acc.: 46.88%] [G loss: 0.820965]\n",
      "epoch:6 step:6152 [D loss: 0.650077, acc.: 65.62%] [G loss: 0.806515]\n",
      "epoch:6 step:6153 [D loss: 0.691617, acc.: 50.00%] [G loss: 0.796878]\n",
      "epoch:6 step:6154 [D loss: 0.696750, acc.: 52.34%] [G loss: 0.788667]\n",
      "epoch:6 step:6155 [D loss: 0.686291, acc.: 51.56%] [G loss: 0.801846]\n",
      "epoch:6 step:6156 [D loss: 0.694531, acc.: 54.69%] [G loss: 0.728373]\n",
      "epoch:6 step:6157 [D loss: 0.719272, acc.: 42.97%] [G loss: 0.746435]\n",
      "epoch:6 step:6158 [D loss: 0.708436, acc.: 51.56%] [G loss: 0.740950]\n",
      "epoch:6 step:6159 [D loss: 0.681523, acc.: 51.56%] [G loss: 0.718675]\n",
      "epoch:6 step:6160 [D loss: 0.656251, acc.: 64.84%] [G loss: 0.748771]\n",
      "epoch:6 step:6161 [D loss: 0.709398, acc.: 47.66%] [G loss: 0.712200]\n",
      "epoch:6 step:6162 [D loss: 0.679140, acc.: 54.69%] [G loss: 0.761694]\n",
      "epoch:6 step:6163 [D loss: 0.686757, acc.: 54.69%] [G loss: 0.728677]\n",
      "epoch:6 step:6164 [D loss: 0.733650, acc.: 40.62%] [G loss: 0.747905]\n",
      "epoch:6 step:6165 [D loss: 0.686968, acc.: 56.25%] [G loss: 0.783790]\n",
      "epoch:6 step:6166 [D loss: 0.681907, acc.: 50.00%] [G loss: 0.746641]\n",
      "epoch:6 step:6167 [D loss: 0.681396, acc.: 58.59%] [G loss: 0.755926]\n",
      "epoch:6 step:6168 [D loss: 0.684920, acc.: 56.25%] [G loss: 0.804809]\n",
      "epoch:6 step:6169 [D loss: 0.689353, acc.: 57.03%] [G loss: 0.790250]\n",
      "epoch:6 step:6170 [D loss: 0.671134, acc.: 57.81%] [G loss: 0.755161]\n",
      "epoch:6 step:6171 [D loss: 0.673271, acc.: 59.38%] [G loss: 0.783011]\n",
      "epoch:6 step:6172 [D loss: 0.666986, acc.: 59.38%] [G loss: 0.794461]\n",
      "epoch:6 step:6173 [D loss: 0.650045, acc.: 60.16%] [G loss: 0.751770]\n",
      "epoch:6 step:6174 [D loss: 0.681342, acc.: 60.16%] [G loss: 0.842375]\n",
      "epoch:6 step:6175 [D loss: 0.712021, acc.: 46.88%] [G loss: 0.816936]\n",
      "epoch:6 step:6176 [D loss: 0.656047, acc.: 60.94%] [G loss: 0.799892]\n",
      "epoch:6 step:6177 [D loss: 0.666082, acc.: 57.03%] [G loss: 0.876989]\n",
      "epoch:6 step:6178 [D loss: 0.668238, acc.: 58.59%] [G loss: 0.875592]\n",
      "epoch:6 step:6179 [D loss: 0.659605, acc.: 59.38%] [G loss: 0.991284]\n",
      "epoch:6 step:6180 [D loss: 0.720649, acc.: 56.25%] [G loss: 0.830688]\n",
      "epoch:6 step:6181 [D loss: 0.791213, acc.: 42.19%] [G loss: 0.804118]\n",
      "epoch:6 step:6182 [D loss: 0.699613, acc.: 53.91%] [G loss: 0.769269]\n",
      "epoch:6 step:6183 [D loss: 0.696307, acc.: 53.91%] [G loss: 0.776763]\n",
      "epoch:6 step:6184 [D loss: 0.682586, acc.: 57.03%] [G loss: 0.850318]\n",
      "epoch:6 step:6185 [D loss: 0.666853, acc.: 61.72%] [G loss: 0.767450]\n",
      "epoch:6 step:6186 [D loss: 0.650600, acc.: 59.38%] [G loss: 0.789756]\n",
      "epoch:6 step:6187 [D loss: 0.674413, acc.: 57.81%] [G loss: 0.798984]\n",
      "epoch:6 step:6188 [D loss: 0.594307, acc.: 67.97%] [G loss: 0.842823]\n",
      "epoch:6 step:6189 [D loss: 0.633307, acc.: 60.94%] [G loss: 0.818953]\n",
      "epoch:6 step:6190 [D loss: 0.611756, acc.: 64.06%] [G loss: 0.810765]\n",
      "epoch:6 step:6191 [D loss: 0.734709, acc.: 47.66%] [G loss: 0.639945]\n",
      "epoch:6 step:6192 [D loss: 0.694765, acc.: 58.59%] [G loss: 0.805504]\n",
      "epoch:6 step:6193 [D loss: 0.718934, acc.: 48.44%] [G loss: 0.730623]\n",
      "epoch:6 step:6194 [D loss: 0.703797, acc.: 53.12%] [G loss: 0.767366]\n",
      "epoch:6 step:6195 [D loss: 0.680520, acc.: 53.91%] [G loss: 0.705295]\n",
      "epoch:6 step:6196 [D loss: 0.678715, acc.: 53.91%] [G loss: 0.847669]\n",
      "epoch:6 step:6197 [D loss: 0.641417, acc.: 60.94%] [G loss: 0.838461]\n",
      "epoch:6 step:6198 [D loss: 0.687530, acc.: 50.00%] [G loss: 0.825907]\n",
      "epoch:6 step:6199 [D loss: 0.667409, acc.: 54.69%] [G loss: 0.834292]\n",
      "epoch:6 step:6200 [D loss: 0.650144, acc.: 64.06%] [G loss: 0.829099]\n",
      "##############\n",
      "[3.7925391  1.52806886 6.41785935 5.59343085 3.94831402 6.03666361\n",
      " 4.64097205 4.51818533 5.38651773 4.318055  ]\n",
      "##########\n",
      "epoch:6 step:6201 [D loss: 0.702164, acc.: 50.00%] [G loss: 0.858254]\n",
      "epoch:6 step:6202 [D loss: 0.669540, acc.: 60.16%] [G loss: 0.951221]\n",
      "epoch:6 step:6203 [D loss: 0.678702, acc.: 53.91%] [G loss: 0.910927]\n",
      "epoch:6 step:6204 [D loss: 0.651254, acc.: 59.38%] [G loss: 0.835597]\n",
      "epoch:6 step:6205 [D loss: 0.685517, acc.: 53.91%] [G loss: 0.849741]\n",
      "epoch:6 step:6206 [D loss: 0.688857, acc.: 52.34%] [G loss: 0.832875]\n",
      "epoch:6 step:6207 [D loss: 0.728644, acc.: 52.34%] [G loss: 0.805107]\n",
      "epoch:6 step:6208 [D loss: 0.678459, acc.: 57.03%] [G loss: 0.783202]\n",
      "epoch:6 step:6209 [D loss: 0.729220, acc.: 46.88%] [G loss: 0.786911]\n",
      "epoch:6 step:6210 [D loss: 0.673036, acc.: 56.25%] [G loss: 0.809746]\n",
      "epoch:6 step:6211 [D loss: 0.639465, acc.: 62.50%] [G loss: 0.774775]\n",
      "epoch:6 step:6212 [D loss: 0.653715, acc.: 57.03%] [G loss: 0.821766]\n",
      "epoch:6 step:6213 [D loss: 0.690524, acc.: 53.12%] [G loss: 0.789774]\n",
      "epoch:6 step:6214 [D loss: 0.695522, acc.: 64.06%] [G loss: 0.869853]\n",
      "epoch:6 step:6215 [D loss: 0.689801, acc.: 54.69%] [G loss: 0.748675]\n",
      "epoch:6 step:6216 [D loss: 0.713032, acc.: 45.31%] [G loss: 0.762386]\n",
      "epoch:6 step:6217 [D loss: 0.670753, acc.: 62.50%] [G loss: 0.790808]\n",
      "epoch:6 step:6218 [D loss: 0.758581, acc.: 36.72%] [G loss: 0.797427]\n",
      "epoch:6 step:6219 [D loss: 0.707791, acc.: 50.00%] [G loss: 0.788193]\n",
      "epoch:6 step:6220 [D loss: 0.661636, acc.: 63.28%] [G loss: 0.815014]\n",
      "epoch:6 step:6221 [D loss: 0.671241, acc.: 59.38%] [G loss: 0.804298]\n",
      "epoch:6 step:6222 [D loss: 0.680250, acc.: 53.91%] [G loss: 0.809945]\n",
      "epoch:6 step:6223 [D loss: 0.678482, acc.: 60.94%] [G loss: 0.797601]\n",
      "epoch:6 step:6224 [D loss: 0.673655, acc.: 60.16%] [G loss: 0.785025]\n",
      "epoch:6 step:6225 [D loss: 0.685472, acc.: 53.91%] [G loss: 0.746024]\n",
      "epoch:6 step:6226 [D loss: 0.700995, acc.: 50.00%] [G loss: 0.751304]\n",
      "epoch:6 step:6227 [D loss: 0.697899, acc.: 46.09%] [G loss: 0.747735]\n",
      "epoch:6 step:6228 [D loss: 0.704029, acc.: 55.47%] [G loss: 0.778395]\n",
      "epoch:6 step:6229 [D loss: 0.707535, acc.: 50.78%] [G loss: 0.781531]\n",
      "epoch:6 step:6230 [D loss: 0.717066, acc.: 46.09%] [G loss: 0.722405]\n",
      "epoch:6 step:6231 [D loss: 0.692701, acc.: 53.12%] [G loss: 0.753193]\n",
      "epoch:6 step:6232 [D loss: 0.687829, acc.: 56.25%] [G loss: 0.753750]\n",
      "epoch:6 step:6233 [D loss: 0.675555, acc.: 59.38%] [G loss: 0.773726]\n",
      "epoch:6 step:6234 [D loss: 0.690523, acc.: 53.12%] [G loss: 0.786252]\n",
      "epoch:6 step:6235 [D loss: 0.684597, acc.: 57.81%] [G loss: 0.759754]\n",
      "epoch:6 step:6236 [D loss: 0.710466, acc.: 49.22%] [G loss: 0.722878]\n",
      "epoch:6 step:6237 [D loss: 0.708293, acc.: 54.69%] [G loss: 0.747577]\n",
      "epoch:6 step:6238 [D loss: 0.687389, acc.: 51.56%] [G loss: 0.766868]\n",
      "epoch:6 step:6239 [D loss: 0.693786, acc.: 51.56%] [G loss: 0.747917]\n",
      "epoch:6 step:6240 [D loss: 0.694120, acc.: 51.56%] [G loss: 0.788847]\n",
      "epoch:6 step:6241 [D loss: 0.668986, acc.: 60.94%] [G loss: 0.758561]\n",
      "epoch:6 step:6242 [D loss: 0.681925, acc.: 54.69%] [G loss: 0.757476]\n",
      "epoch:6 step:6243 [D loss: 0.680950, acc.: 52.34%] [G loss: 0.771487]\n",
      "epoch:6 step:6244 [D loss: 0.678824, acc.: 54.69%] [G loss: 0.784283]\n",
      "epoch:6 step:6245 [D loss: 0.720117, acc.: 47.66%] [G loss: 0.776863]\n",
      "epoch:6 step:6246 [D loss: 0.684654, acc.: 57.03%] [G loss: 0.721850]\n",
      "epoch:6 step:6247 [D loss: 0.733128, acc.: 42.97%] [G loss: 0.735869]\n",
      "epoch:6 step:6248 [D loss: 0.712351, acc.: 45.31%] [G loss: 0.747804]\n",
      "epoch:6 step:6249 [D loss: 0.703821, acc.: 47.66%] [G loss: 0.753848]\n",
      "epoch:6 step:6250 [D loss: 0.689856, acc.: 53.91%] [G loss: 0.769067]\n",
      "epoch:6 step:6251 [D loss: 0.682323, acc.: 52.34%] [G loss: 0.811840]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:6 step:6252 [D loss: 0.674675, acc.: 63.28%] [G loss: 0.783435]\n",
      "epoch:6 step:6253 [D loss: 0.690937, acc.: 52.34%] [G loss: 0.792528]\n",
      "epoch:6 step:6254 [D loss: 0.652747, acc.: 67.19%] [G loss: 0.869690]\n",
      "epoch:6 step:6255 [D loss: 0.648126, acc.: 65.62%] [G loss: 0.806190]\n",
      "epoch:6 step:6256 [D loss: 0.660561, acc.: 62.50%] [G loss: 0.872923]\n",
      "epoch:6 step:6257 [D loss: 0.668251, acc.: 64.84%] [G loss: 0.831734]\n",
      "epoch:6 step:6258 [D loss: 0.692021, acc.: 57.81%] [G loss: 0.819320]\n",
      "epoch:6 step:6259 [D loss: 0.683501, acc.: 53.91%] [G loss: 0.722533]\n",
      "epoch:6 step:6260 [D loss: 0.707202, acc.: 50.00%] [G loss: 0.748348]\n",
      "epoch:6 step:6261 [D loss: 0.722529, acc.: 43.75%] [G loss: 0.819665]\n",
      "epoch:6 step:6262 [D loss: 0.726244, acc.: 43.75%] [G loss: 0.773977]\n",
      "epoch:6 step:6263 [D loss: 0.694798, acc.: 53.12%] [G loss: 0.721478]\n",
      "epoch:6 step:6264 [D loss: 0.669352, acc.: 58.59%] [G loss: 0.750874]\n",
      "epoch:6 step:6265 [D loss: 0.681804, acc.: 53.91%] [G loss: 0.736802]\n",
      "epoch:6 step:6266 [D loss: 0.683450, acc.: 50.78%] [G loss: 0.744015]\n",
      "epoch:6 step:6267 [D loss: 0.690862, acc.: 50.78%] [G loss: 0.763520]\n",
      "epoch:6 step:6268 [D loss: 0.703676, acc.: 53.12%] [G loss: 0.709199]\n",
      "epoch:6 step:6269 [D loss: 0.704662, acc.: 52.34%] [G loss: 0.755589]\n",
      "epoch:6 step:6270 [D loss: 0.668072, acc.: 57.03%] [G loss: 0.768090]\n",
      "epoch:6 step:6271 [D loss: 0.666517, acc.: 60.16%] [G loss: 0.808071]\n",
      "epoch:6 step:6272 [D loss: 0.661817, acc.: 60.94%] [G loss: 0.777305]\n",
      "epoch:6 step:6273 [D loss: 0.666423, acc.: 59.38%] [G loss: 0.732876]\n",
      "epoch:6 step:6274 [D loss: 0.686275, acc.: 54.69%] [G loss: 0.760096]\n",
      "epoch:6 step:6275 [D loss: 0.685177, acc.: 52.34%] [G loss: 0.743082]\n",
      "epoch:6 step:6276 [D loss: 0.700520, acc.: 55.47%] [G loss: 0.709477]\n",
      "epoch:6 step:6277 [D loss: 0.750149, acc.: 40.62%] [G loss: 0.716284]\n",
      "epoch:6 step:6278 [D loss: 0.702176, acc.: 46.09%] [G loss: 0.738552]\n",
      "epoch:6 step:6279 [D loss: 0.732910, acc.: 47.66%] [G loss: 0.769844]\n",
      "epoch:6 step:6280 [D loss: 0.692931, acc.: 52.34%] [G loss: 0.791136]\n",
      "epoch:6 step:6281 [D loss: 0.663646, acc.: 61.72%] [G loss: 0.814821]\n",
      "epoch:6 step:6282 [D loss: 0.658171, acc.: 61.72%] [G loss: 0.786491]\n",
      "epoch:6 step:6283 [D loss: 0.673660, acc.: 60.16%] [G loss: 0.796104]\n",
      "epoch:6 step:6284 [D loss: 0.701711, acc.: 50.78%] [G loss: 0.743918]\n",
      "epoch:6 step:6285 [D loss: 0.622081, acc.: 67.19%] [G loss: 0.746426]\n",
      "epoch:6 step:6286 [D loss: 0.634796, acc.: 67.19%] [G loss: 0.777070]\n",
      "epoch:6 step:6287 [D loss: 0.612507, acc.: 70.31%] [G loss: 0.811494]\n",
      "epoch:6 step:6288 [D loss: 0.663654, acc.: 61.72%] [G loss: 0.795586]\n",
      "epoch:6 step:6289 [D loss: 0.634272, acc.: 71.09%] [G loss: 0.723450]\n",
      "epoch:6 step:6290 [D loss: 0.608704, acc.: 56.25%] [G loss: 0.625618]\n",
      "epoch:6 step:6291 [D loss: 0.631176, acc.: 67.19%] [G loss: 0.771291]\n",
      "epoch:6 step:6292 [D loss: 0.562318, acc.: 69.53%] [G loss: 0.717314]\n",
      "epoch:6 step:6293 [D loss: 0.649134, acc.: 68.75%] [G loss: 0.735107]\n",
      "epoch:6 step:6294 [D loss: 0.742377, acc.: 46.88%] [G loss: 0.594099]\n",
      "epoch:6 step:6295 [D loss: 0.731015, acc.: 50.78%] [G loss: 0.693548]\n",
      "epoch:6 step:6296 [D loss: 0.805049, acc.: 39.84%] [G loss: 0.729252]\n",
      "epoch:6 step:6297 [D loss: 0.865391, acc.: 29.69%] [G loss: 0.629935]\n",
      "epoch:6 step:6298 [D loss: 0.785603, acc.: 41.41%] [G loss: 0.999961]\n",
      "epoch:6 step:6299 [D loss: 0.674665, acc.: 57.03%] [G loss: 1.200055]\n",
      "epoch:6 step:6300 [D loss: 0.701011, acc.: 53.12%] [G loss: 1.123088]\n",
      "epoch:6 step:6301 [D loss: 0.684443, acc.: 55.47%] [G loss: 0.849173]\n",
      "epoch:6 step:6302 [D loss: 0.706523, acc.: 53.12%] [G loss: 0.819574]\n",
      "epoch:6 step:6303 [D loss: 0.700995, acc.: 52.34%] [G loss: 0.816581]\n",
      "epoch:6 step:6304 [D loss: 0.740166, acc.: 46.09%] [G loss: 0.752178]\n",
      "epoch:6 step:6305 [D loss: 0.691605, acc.: 55.47%] [G loss: 0.790938]\n",
      "epoch:6 step:6306 [D loss: 0.697833, acc.: 51.56%] [G loss: 0.791188]\n",
      "epoch:6 step:6307 [D loss: 0.694872, acc.: 50.00%] [G loss: 0.795792]\n",
      "epoch:6 step:6308 [D loss: 0.699851, acc.: 50.78%] [G loss: 0.771065]\n",
      "epoch:6 step:6309 [D loss: 0.720631, acc.: 40.62%] [G loss: 0.736212]\n",
      "epoch:6 step:6310 [D loss: 0.707557, acc.: 47.66%] [G loss: 0.727998]\n",
      "epoch:6 step:6311 [D loss: 0.695920, acc.: 51.56%] [G loss: 0.793131]\n",
      "epoch:6 step:6312 [D loss: 0.716944, acc.: 45.31%] [G loss: 0.751414]\n",
      "epoch:6 step:6313 [D loss: 0.689105, acc.: 57.03%] [G loss: 0.738089]\n",
      "epoch:6 step:6314 [D loss: 0.691402, acc.: 52.34%] [G loss: 0.747148]\n",
      "epoch:6 step:6315 [D loss: 0.664478, acc.: 60.94%] [G loss: 0.754294]\n",
      "epoch:6 step:6316 [D loss: 0.655003, acc.: 65.62%] [G loss: 0.779237]\n",
      "epoch:6 step:6317 [D loss: 0.667061, acc.: 62.50%] [G loss: 0.776508]\n",
      "epoch:6 step:6318 [D loss: 0.703122, acc.: 46.09%] [G loss: 0.794583]\n",
      "epoch:6 step:6319 [D loss: 0.689312, acc.: 53.12%] [G loss: 0.798695]\n",
      "epoch:6 step:6320 [D loss: 0.672336, acc.: 53.12%] [G loss: 0.830146]\n",
      "epoch:6 step:6321 [D loss: 0.673411, acc.: 53.91%] [G loss: 0.762406]\n",
      "epoch:6 step:6322 [D loss: 0.668006, acc.: 57.03%] [G loss: 0.768779]\n",
      "epoch:6 step:6323 [D loss: 0.626368, acc.: 66.41%] [G loss: 0.795990]\n",
      "epoch:6 step:6324 [D loss: 0.659800, acc.: 58.59%] [G loss: 0.809959]\n",
      "epoch:6 step:6325 [D loss: 0.657075, acc.: 64.84%] [G loss: 0.821723]\n",
      "epoch:6 step:6326 [D loss: 0.693950, acc.: 59.38%] [G loss: 0.811821]\n",
      "epoch:6 step:6327 [D loss: 0.654408, acc.: 60.16%] [G loss: 0.874250]\n",
      "epoch:6 step:6328 [D loss: 0.577338, acc.: 71.88%] [G loss: 0.795694]\n",
      "epoch:6 step:6329 [D loss: 0.573427, acc.: 75.00%] [G loss: 0.881341]\n",
      "epoch:6 step:6330 [D loss: 0.594458, acc.: 67.97%] [G loss: 0.881563]\n",
      "epoch:6 step:6331 [D loss: 0.661085, acc.: 60.94%] [G loss: 0.907793]\n",
      "epoch:6 step:6332 [D loss: 0.849720, acc.: 31.25%] [G loss: 0.783489]\n",
      "epoch:6 step:6333 [D loss: 0.744233, acc.: 44.53%] [G loss: 0.770698]\n",
      "epoch:6 step:6334 [D loss: 0.684978, acc.: 57.03%] [G loss: 0.786415]\n",
      "epoch:6 step:6335 [D loss: 0.662508, acc.: 60.94%] [G loss: 0.809413]\n",
      "epoch:6 step:6336 [D loss: 0.659892, acc.: 61.72%] [G loss: 0.796579]\n",
      "epoch:6 step:6337 [D loss: 0.666836, acc.: 54.69%] [G loss: 0.784664]\n",
      "epoch:6 step:6338 [D loss: 0.688611, acc.: 51.56%] [G loss: 0.778544]\n",
      "epoch:6 step:6339 [D loss: 0.702391, acc.: 51.56%] [G loss: 0.824023]\n",
      "epoch:6 step:6340 [D loss: 0.668391, acc.: 50.78%] [G loss: 0.754834]\n",
      "epoch:6 step:6341 [D loss: 0.709804, acc.: 51.56%] [G loss: 0.628166]\n",
      "epoch:6 step:6342 [D loss: 0.676257, acc.: 57.03%] [G loss: 0.691445]\n",
      "epoch:6 step:6343 [D loss: 0.690943, acc.: 53.91%] [G loss: 0.720041]\n",
      "epoch:6 step:6344 [D loss: 0.687263, acc.: 55.47%] [G loss: 0.677073]\n",
      "epoch:6 step:6345 [D loss: 0.679298, acc.: 60.16%] [G loss: 0.796605]\n",
      "epoch:6 step:6346 [D loss: 0.743672, acc.: 46.88%] [G loss: 0.840775]\n",
      "epoch:6 step:6347 [D loss: 0.699189, acc.: 52.34%] [G loss: 0.897159]\n",
      "epoch:6 step:6348 [D loss: 0.686803, acc.: 52.34%] [G loss: 0.947169]\n",
      "epoch:6 step:6349 [D loss: 0.684743, acc.: 48.44%] [G loss: 1.015505]\n",
      "epoch:6 step:6350 [D loss: 0.685865, acc.: 57.03%] [G loss: 0.828887]\n",
      "epoch:6 step:6351 [D loss: 0.705562, acc.: 50.00%] [G loss: 0.767447]\n",
      "epoch:6 step:6352 [D loss: 0.652246, acc.: 59.38%] [G loss: 0.704225]\n",
      "epoch:6 step:6353 [D loss: 0.641252, acc.: 59.38%] [G loss: 0.715204]\n",
      "epoch:6 step:6354 [D loss: 0.631577, acc.: 67.97%] [G loss: 0.743312]\n",
      "epoch:6 step:6355 [D loss: 0.648856, acc.: 67.19%] [G loss: 0.685165]\n",
      "epoch:6 step:6356 [D loss: 0.735521, acc.: 47.66%] [G loss: 0.720031]\n",
      "epoch:6 step:6357 [D loss: 0.816448, acc.: 34.38%] [G loss: 0.793888]\n",
      "epoch:6 step:6358 [D loss: 0.740751, acc.: 47.66%] [G loss: 0.873350]\n",
      "epoch:6 step:6359 [D loss: 0.675257, acc.: 62.50%] [G loss: 0.958666]\n",
      "epoch:6 step:6360 [D loss: 0.661785, acc.: 62.50%] [G loss: 0.872782]\n",
      "epoch:6 step:6361 [D loss: 0.647530, acc.: 60.16%] [G loss: 0.942585]\n",
      "epoch:6 step:6362 [D loss: 0.663677, acc.: 62.50%] [G loss: 0.833794]\n",
      "epoch:6 step:6363 [D loss: 0.694320, acc.: 46.88%] [G loss: 0.849584]\n",
      "epoch:6 step:6364 [D loss: 0.707626, acc.: 45.31%] [G loss: 0.831927]\n",
      "epoch:6 step:6365 [D loss: 0.704829, acc.: 47.66%] [G loss: 0.816011]\n",
      "epoch:6 step:6366 [D loss: 0.781113, acc.: 42.97%] [G loss: 0.758905]\n",
      "epoch:6 step:6367 [D loss: 0.749439, acc.: 41.41%] [G loss: 0.758696]\n",
      "epoch:6 step:6368 [D loss: 0.699585, acc.: 49.22%] [G loss: 0.776404]\n",
      "epoch:6 step:6369 [D loss: 0.655239, acc.: 65.62%] [G loss: 0.769013]\n",
      "epoch:6 step:6370 [D loss: 0.698752, acc.: 52.34%] [G loss: 0.800966]\n",
      "epoch:6 step:6371 [D loss: 0.673947, acc.: 60.16%] [G loss: 0.850985]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:6 step:6372 [D loss: 0.659657, acc.: 61.72%] [G loss: 0.845739]\n",
      "epoch:6 step:6373 [D loss: 0.664102, acc.: 60.16%] [G loss: 0.860822]\n",
      "epoch:6 step:6374 [D loss: 0.672087, acc.: 64.06%] [G loss: 0.845950]\n",
      "epoch:6 step:6375 [D loss: 0.684393, acc.: 56.25%] [G loss: 0.806824]\n",
      "epoch:6 step:6376 [D loss: 0.664579, acc.: 57.81%] [G loss: 0.791264]\n",
      "epoch:6 step:6377 [D loss: 0.679190, acc.: 56.25%] [G loss: 0.785853]\n",
      "epoch:6 step:6378 [D loss: 0.703137, acc.: 49.22%] [G loss: 0.772154]\n",
      "epoch:6 step:6379 [D loss: 0.707306, acc.: 50.78%] [G loss: 0.730256]\n",
      "epoch:6 step:6380 [D loss: 0.711856, acc.: 46.09%] [G loss: 0.711001]\n",
      "epoch:6 step:6381 [D loss: 0.740452, acc.: 41.41%] [G loss: 0.705882]\n",
      "epoch:6 step:6382 [D loss: 0.723732, acc.: 39.84%] [G loss: 0.722789]\n",
      "epoch:6 step:6383 [D loss: 0.702571, acc.: 47.66%] [G loss: 0.747987]\n",
      "epoch:6 step:6384 [D loss: 0.671224, acc.: 57.81%] [G loss: 0.742331]\n",
      "epoch:6 step:6385 [D loss: 0.701822, acc.: 48.44%] [G loss: 0.759872]\n",
      "epoch:6 step:6386 [D loss: 0.636040, acc.: 65.62%] [G loss: 0.753858]\n",
      "epoch:6 step:6387 [D loss: 0.687933, acc.: 57.03%] [G loss: 0.761156]\n",
      "epoch:6 step:6388 [D loss: 0.671763, acc.: 61.72%] [G loss: 0.773386]\n",
      "epoch:6 step:6389 [D loss: 0.663876, acc.: 61.72%] [G loss: 0.781937]\n",
      "epoch:6 step:6390 [D loss: 0.648068, acc.: 68.75%] [G loss: 0.789358]\n",
      "epoch:6 step:6391 [D loss: 0.690500, acc.: 57.81%] [G loss: 0.828267]\n",
      "epoch:6 step:6392 [D loss: 0.653931, acc.: 55.47%] [G loss: 0.820929]\n",
      "epoch:6 step:6393 [D loss: 0.685225, acc.: 57.81%] [G loss: 0.791028]\n",
      "epoch:6 step:6394 [D loss: 0.713534, acc.: 56.25%] [G loss: 0.808528]\n",
      "epoch:6 step:6395 [D loss: 0.671622, acc.: 53.91%] [G loss: 0.743672]\n",
      "epoch:6 step:6396 [D loss: 0.704072, acc.: 44.53%] [G loss: 0.822981]\n",
      "epoch:6 step:6397 [D loss: 0.651175, acc.: 63.28%] [G loss: 0.834829]\n",
      "epoch:6 step:6398 [D loss: 0.703831, acc.: 51.56%] [G loss: 0.837476]\n",
      "epoch:6 step:6399 [D loss: 0.684260, acc.: 54.69%] [G loss: 0.843942]\n",
      "epoch:6 step:6400 [D loss: 0.687616, acc.: 54.69%] [G loss: 0.915932]\n",
      "##############\n",
      "[3.76969705 2.79296256 6.42827061 5.3431594  4.30023967 6.39672843\n",
      " 5.25140511 5.81099497 5.38258756 4.80579282]\n",
      "##########\n",
      "epoch:6 step:6401 [D loss: 0.685854, acc.: 45.31%] [G loss: 0.833329]\n",
      "epoch:6 step:6402 [D loss: 0.689833, acc.: 56.25%] [G loss: 0.816211]\n",
      "epoch:6 step:6403 [D loss: 0.678821, acc.: 53.91%] [G loss: 0.846687]\n",
      "epoch:6 step:6404 [D loss: 0.688726, acc.: 56.25%] [G loss: 0.761788]\n",
      "epoch:6 step:6405 [D loss: 0.740398, acc.: 43.75%] [G loss: 0.760856]\n",
      "epoch:6 step:6406 [D loss: 0.688729, acc.: 55.47%] [G loss: 0.770086]\n",
      "epoch:6 step:6407 [D loss: 0.686537, acc.: 57.81%] [G loss: 0.720577]\n",
      "epoch:6 step:6408 [D loss: 0.686906, acc.: 57.81%] [G loss: 0.755818]\n",
      "epoch:6 step:6409 [D loss: 0.706004, acc.: 50.78%] [G loss: 0.722344]\n",
      "epoch:6 step:6410 [D loss: 0.698800, acc.: 53.12%] [G loss: 0.678367]\n",
      "epoch:6 step:6411 [D loss: 0.721454, acc.: 51.56%] [G loss: 0.768156]\n",
      "epoch:6 step:6412 [D loss: 0.662645, acc.: 54.69%] [G loss: 0.737165]\n",
      "epoch:6 step:6413 [D loss: 0.620366, acc.: 64.06%] [G loss: 0.750392]\n",
      "epoch:6 step:6414 [D loss: 0.640959, acc.: 64.06%] [G loss: 0.800829]\n",
      "epoch:6 step:6415 [D loss: 0.667464, acc.: 59.38%] [G loss: 0.797531]\n",
      "epoch:6 step:6416 [D loss: 0.728586, acc.: 53.91%] [G loss: 0.673140]\n",
      "epoch:6 step:6417 [D loss: 0.668920, acc.: 56.25%] [G loss: 0.695363]\n",
      "epoch:6 step:6418 [D loss: 0.658512, acc.: 62.50%] [G loss: 0.612444]\n",
      "epoch:6 step:6419 [D loss: 0.707605, acc.: 50.00%] [G loss: 0.718120]\n",
      "epoch:6 step:6420 [D loss: 0.731168, acc.: 53.91%] [G loss: 0.726673]\n",
      "epoch:6 step:6421 [D loss: 0.658975, acc.: 69.53%] [G loss: 0.754975]\n",
      "epoch:6 step:6422 [D loss: 0.797322, acc.: 31.25%] [G loss: 0.768321]\n",
      "epoch:6 step:6423 [D loss: 0.700454, acc.: 51.56%] [G loss: 0.796230]\n",
      "epoch:6 step:6424 [D loss: 0.659097, acc.: 57.81%] [G loss: 0.863198]\n",
      "epoch:6 step:6425 [D loss: 0.685899, acc.: 52.34%] [G loss: 0.821133]\n",
      "epoch:6 step:6426 [D loss: 0.736698, acc.: 52.34%] [G loss: 0.808657]\n",
      "epoch:6 step:6427 [D loss: 0.672339, acc.: 51.56%] [G loss: 0.805829]\n",
      "epoch:6 step:6428 [D loss: 0.693995, acc.: 55.47%] [G loss: 0.937879]\n",
      "epoch:6 step:6429 [D loss: 0.711850, acc.: 53.91%] [G loss: 0.809095]\n",
      "epoch:6 step:6430 [D loss: 0.710281, acc.: 50.78%] [G loss: 0.761314]\n",
      "epoch:6 step:6431 [D loss: 0.686274, acc.: 54.69%] [G loss: 0.786246]\n",
      "epoch:6 step:6432 [D loss: 0.680442, acc.: 60.16%] [G loss: 0.789545]\n",
      "epoch:6 step:6433 [D loss: 0.682376, acc.: 53.91%] [G loss: 0.768047]\n",
      "epoch:6 step:6434 [D loss: 0.708872, acc.: 51.56%] [G loss: 0.769820]\n",
      "epoch:6 step:6435 [D loss: 0.690028, acc.: 57.81%] [G loss: 0.764170]\n",
      "epoch:6 step:6436 [D loss: 0.684449, acc.: 53.91%] [G loss: 0.815522]\n",
      "epoch:6 step:6437 [D loss: 0.678980, acc.: 57.81%] [G loss: 0.779948]\n",
      "epoch:6 step:6438 [D loss: 0.681714, acc.: 59.38%] [G loss: 0.826267]\n",
      "epoch:6 step:6439 [D loss: 0.699661, acc.: 47.66%] [G loss: 0.775340]\n",
      "epoch:6 step:6440 [D loss: 0.691941, acc.: 55.47%] [G loss: 0.776102]\n",
      "epoch:6 step:6441 [D loss: 0.692726, acc.: 52.34%] [G loss: 0.761841]\n",
      "epoch:6 step:6442 [D loss: 0.702214, acc.: 48.44%] [G loss: 0.787666]\n",
      "epoch:6 step:6443 [D loss: 0.681541, acc.: 52.34%] [G loss: 0.759484]\n",
      "epoch:6 step:6444 [D loss: 0.669938, acc.: 58.59%] [G loss: 0.748588]\n",
      "epoch:6 step:6445 [D loss: 0.700428, acc.: 50.78%] [G loss: 0.771604]\n",
      "epoch:6 step:6446 [D loss: 0.691402, acc.: 51.56%] [G loss: 0.777433]\n",
      "epoch:6 step:6447 [D loss: 0.690004, acc.: 55.47%] [G loss: 0.749956]\n",
      "epoch:6 step:6448 [D loss: 0.685252, acc.: 56.25%] [G loss: 0.758628]\n",
      "epoch:6 step:6449 [D loss: 0.678026, acc.: 60.16%] [G loss: 0.779123]\n",
      "epoch:6 step:6450 [D loss: 0.699669, acc.: 51.56%] [G loss: 0.730977]\n",
      "epoch:6 step:6451 [D loss: 0.681863, acc.: 58.59%] [G loss: 0.755374]\n",
      "epoch:6 step:6452 [D loss: 0.674333, acc.: 61.72%] [G loss: 0.760480]\n",
      "epoch:6 step:6453 [D loss: 0.701137, acc.: 47.66%] [G loss: 0.765388]\n",
      "epoch:6 step:6454 [D loss: 0.709335, acc.: 49.22%] [G loss: 0.747441]\n",
      "epoch:6 step:6455 [D loss: 0.694188, acc.: 49.22%] [G loss: 0.753479]\n",
      "epoch:6 step:6456 [D loss: 0.708218, acc.: 50.78%] [G loss: 0.738964]\n",
      "epoch:6 step:6457 [D loss: 0.687989, acc.: 56.25%] [G loss: 0.752055]\n",
      "epoch:6 step:6458 [D loss: 0.672876, acc.: 51.56%] [G loss: 0.757862]\n",
      "epoch:6 step:6459 [D loss: 0.664033, acc.: 61.72%] [G loss: 0.753528]\n",
      "epoch:6 step:6460 [D loss: 0.686123, acc.: 55.47%] [G loss: 0.700653]\n",
      "epoch:6 step:6461 [D loss: 0.677079, acc.: 53.12%] [G loss: 0.705395]\n",
      "epoch:6 step:6462 [D loss: 0.681973, acc.: 52.34%] [G loss: 0.711999]\n",
      "epoch:6 step:6463 [D loss: 0.658063, acc.: 58.59%] [G loss: 0.662570]\n",
      "epoch:6 step:6464 [D loss: 0.651038, acc.: 61.72%] [G loss: 0.749950]\n",
      "epoch:6 step:6465 [D loss: 0.697604, acc.: 53.12%] [G loss: 0.802588]\n",
      "epoch:6 step:6466 [D loss: 0.680487, acc.: 56.25%] [G loss: 0.722810]\n",
      "epoch:6 step:6467 [D loss: 0.679757, acc.: 57.03%] [G loss: 0.770822]\n",
      "epoch:6 step:6468 [D loss: 0.695131, acc.: 55.47%] [G loss: 0.750144]\n",
      "epoch:6 step:6469 [D loss: 0.706248, acc.: 47.66%] [G loss: 0.758499]\n",
      "epoch:6 step:6470 [D loss: 0.722353, acc.: 47.66%] [G loss: 0.734128]\n",
      "epoch:6 step:6471 [D loss: 0.690915, acc.: 60.16%] [G loss: 0.771780]\n",
      "epoch:6 step:6472 [D loss: 0.702585, acc.: 49.22%] [G loss: 0.762121]\n",
      "epoch:6 step:6473 [D loss: 0.679461, acc.: 60.94%] [G loss: 0.801441]\n",
      "epoch:6 step:6474 [D loss: 0.681765, acc.: 53.91%] [G loss: 0.858655]\n",
      "epoch:6 step:6475 [D loss: 0.706893, acc.: 50.78%] [G loss: 0.801040]\n",
      "epoch:6 step:6476 [D loss: 0.655447, acc.: 63.28%] [G loss: 0.793765]\n",
      "epoch:6 step:6477 [D loss: 0.678275, acc.: 55.47%] [G loss: 0.768476]\n",
      "epoch:6 step:6478 [D loss: 0.689779, acc.: 54.69%] [G loss: 0.761433]\n",
      "epoch:6 step:6479 [D loss: 0.691543, acc.: 54.69%] [G loss: 0.771260]\n",
      "epoch:6 step:6480 [D loss: 0.719405, acc.: 42.97%] [G loss: 0.757610]\n",
      "epoch:6 step:6481 [D loss: 0.704770, acc.: 47.66%] [G loss: 0.756817]\n",
      "epoch:6 step:6482 [D loss: 0.687913, acc.: 55.47%] [G loss: 0.778879]\n",
      "epoch:6 step:6483 [D loss: 0.714005, acc.: 49.22%] [G loss: 0.744820]\n",
      "epoch:6 step:6484 [D loss: 0.704178, acc.: 45.31%] [G loss: 0.755123]\n",
      "epoch:6 step:6485 [D loss: 0.688162, acc.: 52.34%] [G loss: 0.740627]\n",
      "epoch:6 step:6486 [D loss: 0.703613, acc.: 53.91%] [G loss: 0.759120]\n",
      "epoch:6 step:6487 [D loss: 0.698029, acc.: 53.12%] [G loss: 0.836534]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:6 step:6488 [D loss: 0.667067, acc.: 56.25%] [G loss: 0.770999]\n",
      "epoch:6 step:6489 [D loss: 0.681267, acc.: 56.25%] [G loss: 0.775689]\n",
      "epoch:6 step:6490 [D loss: 0.676981, acc.: 57.81%] [G loss: 0.752479]\n",
      "epoch:6 step:6491 [D loss: 0.667870, acc.: 56.25%] [G loss: 0.783506]\n",
      "epoch:6 step:6492 [D loss: 0.708826, acc.: 49.22%] [G loss: 0.774245]\n",
      "epoch:6 step:6493 [D loss: 0.701751, acc.: 53.91%] [G loss: 0.770606]\n",
      "epoch:6 step:6494 [D loss: 0.683789, acc.: 55.47%] [G loss: 0.799165]\n",
      "epoch:6 step:6495 [D loss: 0.683268, acc.: 60.16%] [G loss: 0.738299]\n",
      "epoch:6 step:6496 [D loss: 0.673573, acc.: 66.41%] [G loss: 0.775770]\n",
      "epoch:6 step:6497 [D loss: 0.673195, acc.: 57.03%] [G loss: 0.779171]\n",
      "epoch:6 step:6498 [D loss: 0.712523, acc.: 47.66%] [G loss: 0.735463]\n",
      "epoch:6 step:6499 [D loss: 0.695892, acc.: 53.91%] [G loss: 0.780157]\n",
      "epoch:6 step:6500 [D loss: 0.687322, acc.: 55.47%] [G loss: 0.788104]\n",
      "epoch:6 step:6501 [D loss: 0.700399, acc.: 46.88%] [G loss: 0.784645]\n",
      "epoch:6 step:6502 [D loss: 0.713961, acc.: 43.75%] [G loss: 0.730617]\n",
      "epoch:6 step:6503 [D loss: 0.701967, acc.: 48.44%] [G loss: 0.716347]\n",
      "epoch:6 step:6504 [D loss: 0.680740, acc.: 56.25%] [G loss: 0.736007]\n",
      "epoch:6 step:6505 [D loss: 0.707128, acc.: 45.31%] [G loss: 0.741193]\n",
      "epoch:6 step:6506 [D loss: 0.690319, acc.: 52.34%] [G loss: 0.719348]\n",
      "epoch:6 step:6507 [D loss: 0.676926, acc.: 61.72%] [G loss: 0.715284]\n",
      "epoch:6 step:6508 [D loss: 0.667938, acc.: 53.12%] [G loss: 0.733720]\n",
      "epoch:6 step:6509 [D loss: 0.625202, acc.: 67.19%] [G loss: 0.798212]\n",
      "epoch:6 step:6510 [D loss: 0.664081, acc.: 59.38%] [G loss: 0.802102]\n",
      "epoch:6 step:6511 [D loss: 0.607419, acc.: 62.50%] [G loss: 0.791960]\n",
      "epoch:6 step:6512 [D loss: 0.672385, acc.: 60.94%] [G loss: 0.817621]\n",
      "epoch:6 step:6513 [D loss: 0.747732, acc.: 46.09%] [G loss: 0.794624]\n",
      "epoch:6 step:6514 [D loss: 0.781837, acc.: 33.59%] [G loss: 0.872873]\n",
      "epoch:6 step:6515 [D loss: 0.696346, acc.: 46.88%] [G loss: 0.835407]\n",
      "epoch:6 step:6516 [D loss: 0.696987, acc.: 48.44%] [G loss: 0.849501]\n",
      "epoch:6 step:6517 [D loss: 0.681942, acc.: 55.47%] [G loss: 0.833877]\n",
      "epoch:6 step:6518 [D loss: 0.684193, acc.: 53.12%] [G loss: 0.851675]\n",
      "epoch:6 step:6519 [D loss: 0.663089, acc.: 62.50%] [G loss: 0.858744]\n",
      "epoch:6 step:6520 [D loss: 0.647018, acc.: 65.62%] [G loss: 0.868496]\n",
      "epoch:6 step:6521 [D loss: 0.629178, acc.: 66.41%] [G loss: 0.869163]\n",
      "epoch:6 step:6522 [D loss: 0.700278, acc.: 50.78%] [G loss: 0.814644]\n",
      "epoch:6 step:6523 [D loss: 0.687270, acc.: 50.00%] [G loss: 0.817383]\n",
      "epoch:6 step:6524 [D loss: 0.710740, acc.: 53.12%] [G loss: 0.748657]\n",
      "epoch:6 step:6525 [D loss: 0.706537, acc.: 55.47%] [G loss: 0.752120]\n",
      "epoch:6 step:6526 [D loss: 0.736509, acc.: 47.66%] [G loss: 0.726519]\n",
      "epoch:6 step:6527 [D loss: 0.706788, acc.: 49.22%] [G loss: 0.738730]\n",
      "epoch:6 step:6528 [D loss: 0.721972, acc.: 45.31%] [G loss: 0.695967]\n",
      "epoch:6 step:6529 [D loss: 0.717964, acc.: 50.78%] [G loss: 0.735093]\n",
      "epoch:6 step:6530 [D loss: 0.698783, acc.: 50.00%] [G loss: 0.724478]\n",
      "epoch:6 step:6531 [D loss: 0.684559, acc.: 53.91%] [G loss: 0.732174]\n",
      "epoch:6 step:6532 [D loss: 0.694530, acc.: 48.44%] [G loss: 0.749906]\n",
      "epoch:6 step:6533 [D loss: 0.673904, acc.: 59.38%] [G loss: 0.709531]\n",
      "epoch:6 step:6534 [D loss: 0.686909, acc.: 58.59%] [G loss: 0.742211]\n",
      "epoch:6 step:6535 [D loss: 0.676155, acc.: 57.03%] [G loss: 0.731936]\n",
      "epoch:6 step:6536 [D loss: 0.670781, acc.: 60.16%] [G loss: 0.762945]\n",
      "epoch:6 step:6537 [D loss: 0.684198, acc.: 48.44%] [G loss: 0.786759]\n",
      "epoch:6 step:6538 [D loss: 0.697339, acc.: 53.12%] [G loss: 0.775512]\n",
      "epoch:6 step:6539 [D loss: 0.705210, acc.: 50.00%] [G loss: 0.724205]\n",
      "epoch:6 step:6540 [D loss: 0.682856, acc.: 57.03%] [G loss: 0.753127]\n",
      "epoch:6 step:6541 [D loss: 0.696091, acc.: 55.47%] [G loss: 0.741113]\n",
      "epoch:6 step:6542 [D loss: 0.702148, acc.: 54.69%] [G loss: 0.744955]\n",
      "epoch:6 step:6543 [D loss: 0.679715, acc.: 62.50%] [G loss: 0.696904]\n",
      "epoch:6 step:6544 [D loss: 0.666265, acc.: 60.94%] [G loss: 0.736857]\n",
      "epoch:6 step:6545 [D loss: 0.676648, acc.: 60.94%] [G loss: 0.715272]\n",
      "epoch:6 step:6546 [D loss: 0.692045, acc.: 58.59%] [G loss: 0.724585]\n",
      "epoch:6 step:6547 [D loss: 0.643700, acc.: 69.53%] [G loss: 0.800432]\n",
      "epoch:6 step:6548 [D loss: 0.655338, acc.: 63.28%] [G loss: 0.756458]\n",
      "epoch:6 step:6549 [D loss: 0.683756, acc.: 60.94%] [G loss: 0.744077]\n",
      "epoch:6 step:6550 [D loss: 0.730123, acc.: 50.78%] [G loss: 0.832660]\n",
      "epoch:6 step:6551 [D loss: 0.721947, acc.: 46.09%] [G loss: 0.742811]\n",
      "epoch:6 step:6552 [D loss: 0.672745, acc.: 60.94%] [G loss: 0.777381]\n",
      "epoch:6 step:6553 [D loss: 0.703320, acc.: 52.34%] [G loss: 0.741002]\n",
      "epoch:6 step:6554 [D loss: 0.699481, acc.: 49.22%] [G loss: 0.736940]\n",
      "epoch:6 step:6555 [D loss: 0.698929, acc.: 50.78%] [G loss: 0.765549]\n",
      "epoch:6 step:6556 [D loss: 0.723409, acc.: 48.44%] [G loss: 0.718933]\n",
      "epoch:6 step:6557 [D loss: 0.662309, acc.: 60.94%] [G loss: 0.755299]\n",
      "epoch:6 step:6558 [D loss: 0.660332, acc.: 65.62%] [G loss: 0.764689]\n",
      "epoch:6 step:6559 [D loss: 0.669951, acc.: 64.06%] [G loss: 0.770853]\n",
      "epoch:7 step:6560 [D loss: 0.692579, acc.: 55.47%] [G loss: 0.756171]\n",
      "epoch:7 step:6561 [D loss: 0.722489, acc.: 51.56%] [G loss: 0.738147]\n",
      "epoch:7 step:6562 [D loss: 0.704395, acc.: 51.56%] [G loss: 0.743377]\n",
      "epoch:7 step:6563 [D loss: 0.729575, acc.: 44.53%] [G loss: 0.759686]\n",
      "epoch:7 step:6564 [D loss: 0.682489, acc.: 59.38%] [G loss: 0.786680]\n",
      "epoch:7 step:6565 [D loss: 0.694643, acc.: 50.78%] [G loss: 0.746007]\n",
      "epoch:7 step:6566 [D loss: 0.686347, acc.: 55.47%] [G loss: 0.750122]\n",
      "epoch:7 step:6567 [D loss: 0.693314, acc.: 55.47%] [G loss: 0.715425]\n",
      "epoch:7 step:6568 [D loss: 0.684248, acc.: 57.81%] [G loss: 0.714523]\n",
      "epoch:7 step:6569 [D loss: 0.695462, acc.: 53.91%] [G loss: 0.752711]\n",
      "epoch:7 step:6570 [D loss: 0.696137, acc.: 49.22%] [G loss: 0.791291]\n",
      "epoch:7 step:6571 [D loss: 0.697765, acc.: 51.56%] [G loss: 0.744988]\n",
      "epoch:7 step:6572 [D loss: 0.702947, acc.: 47.66%] [G loss: 0.756368]\n",
      "epoch:7 step:6573 [D loss: 0.668747, acc.: 60.94%] [G loss: 0.785513]\n",
      "epoch:7 step:6574 [D loss: 0.670016, acc.: 61.72%] [G loss: 0.799147]\n",
      "epoch:7 step:6575 [D loss: 0.678302, acc.: 56.25%] [G loss: 0.812526]\n",
      "epoch:7 step:6576 [D loss: 0.688291, acc.: 57.03%] [G loss: 0.748332]\n",
      "epoch:7 step:6577 [D loss: 0.692812, acc.: 57.81%] [G loss: 0.756484]\n",
      "epoch:7 step:6578 [D loss: 0.713980, acc.: 48.44%] [G loss: 0.788202]\n",
      "epoch:7 step:6579 [D loss: 0.696791, acc.: 53.12%] [G loss: 0.838764]\n",
      "epoch:7 step:6580 [D loss: 0.682623, acc.: 53.91%] [G loss: 0.823630]\n",
      "epoch:7 step:6581 [D loss: 0.662492, acc.: 64.06%] [G loss: 0.838888]\n",
      "epoch:7 step:6582 [D loss: 0.704506, acc.: 48.44%] [G loss: 0.804665]\n",
      "epoch:7 step:6583 [D loss: 0.730070, acc.: 45.31%] [G loss: 0.753312]\n",
      "epoch:7 step:6584 [D loss: 0.684740, acc.: 57.81%] [G loss: 0.770871]\n",
      "epoch:7 step:6585 [D loss: 0.695365, acc.: 53.12%] [G loss: 0.758229]\n",
      "epoch:7 step:6586 [D loss: 0.712812, acc.: 46.88%] [G loss: 0.762048]\n",
      "epoch:7 step:6587 [D loss: 0.688811, acc.: 54.69%] [G loss: 0.754269]\n",
      "epoch:7 step:6588 [D loss: 0.677991, acc.: 51.56%] [G loss: 0.765124]\n",
      "epoch:7 step:6589 [D loss: 0.693922, acc.: 48.44%] [G loss: 0.774429]\n",
      "epoch:7 step:6590 [D loss: 0.677102, acc.: 57.81%] [G loss: 0.790316]\n",
      "epoch:7 step:6591 [D loss: 0.682354, acc.: 51.56%] [G loss: 0.804054]\n",
      "epoch:7 step:6592 [D loss: 0.671799, acc.: 54.69%] [G loss: 0.795482]\n",
      "epoch:7 step:6593 [D loss: 0.669315, acc.: 63.28%] [G loss: 0.799254]\n",
      "epoch:7 step:6594 [D loss: 0.670507, acc.: 58.59%] [G loss: 0.774923]\n",
      "epoch:7 step:6595 [D loss: 0.630753, acc.: 64.06%] [G loss: 0.826190]\n",
      "epoch:7 step:6596 [D loss: 0.717073, acc.: 50.78%] [G loss: 0.814876]\n",
      "epoch:7 step:6597 [D loss: 0.712901, acc.: 46.88%] [G loss: 0.802024]\n",
      "epoch:7 step:6598 [D loss: 0.696950, acc.: 54.69%] [G loss: 0.790925]\n",
      "epoch:7 step:6599 [D loss: 0.679058, acc.: 60.16%] [G loss: 0.808518]\n",
      "epoch:7 step:6600 [D loss: 0.705202, acc.: 43.75%] [G loss: 0.757311]\n",
      "##############\n",
      "[3.86605346 2.31326406 6.42450985 5.97037043 4.71255461 6.40209288\n",
      " 5.46344157 5.42298775 5.77654954 4.9559055 ]\n",
      "##########\n",
      "epoch:7 step:6601 [D loss: 0.713168, acc.: 50.00%] [G loss: 0.760080]\n",
      "epoch:7 step:6602 [D loss: 0.701272, acc.: 49.22%] [G loss: 0.731506]\n",
      "epoch:7 step:6603 [D loss: 0.716119, acc.: 45.31%] [G loss: 0.713583]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:7 step:6604 [D loss: 0.691669, acc.: 50.78%] [G loss: 0.743376]\n",
      "epoch:7 step:6605 [D loss: 0.694776, acc.: 55.47%] [G loss: 0.726491]\n",
      "epoch:7 step:6606 [D loss: 0.699863, acc.: 50.00%] [G loss: 0.751801]\n",
      "epoch:7 step:6607 [D loss: 0.700593, acc.: 51.56%] [G loss: 0.763584]\n",
      "epoch:7 step:6608 [D loss: 0.691932, acc.: 55.47%] [G loss: 0.724494]\n",
      "epoch:7 step:6609 [D loss: 0.678883, acc.: 57.81%] [G loss: 0.743007]\n",
      "epoch:7 step:6610 [D loss: 0.709772, acc.: 50.00%] [G loss: 0.755179]\n",
      "epoch:7 step:6611 [D loss: 0.672001, acc.: 61.72%] [G loss: 0.772826]\n",
      "epoch:7 step:6612 [D loss: 0.696049, acc.: 51.56%] [G loss: 0.749839]\n",
      "epoch:7 step:6613 [D loss: 0.674895, acc.: 59.38%] [G loss: 0.711719]\n",
      "epoch:7 step:6614 [D loss: 0.700794, acc.: 43.75%] [G loss: 0.761693]\n",
      "epoch:7 step:6615 [D loss: 0.699942, acc.: 49.22%] [G loss: 0.736311]\n",
      "epoch:7 step:6616 [D loss: 0.678918, acc.: 58.59%] [G loss: 0.755386]\n",
      "epoch:7 step:6617 [D loss: 0.690781, acc.: 46.88%] [G loss: 0.761364]\n",
      "epoch:7 step:6618 [D loss: 0.693135, acc.: 53.91%] [G loss: 0.711033]\n",
      "epoch:7 step:6619 [D loss: 0.683917, acc.: 52.34%] [G loss: 0.756359]\n",
      "epoch:7 step:6620 [D loss: 0.727249, acc.: 42.19%] [G loss: 0.743222]\n",
      "epoch:7 step:6621 [D loss: 0.680133, acc.: 58.59%] [G loss: 0.740185]\n",
      "epoch:7 step:6622 [D loss: 0.657498, acc.: 56.25%] [G loss: 0.724601]\n",
      "epoch:7 step:6623 [D loss: 0.685855, acc.: 52.34%] [G loss: 0.739706]\n",
      "epoch:7 step:6624 [D loss: 0.682987, acc.: 57.81%] [G loss: 0.741896]\n",
      "epoch:7 step:6625 [D loss: 0.686112, acc.: 51.56%] [G loss: 0.729961]\n",
      "epoch:7 step:6626 [D loss: 0.653715, acc.: 67.97%] [G loss: 0.761175]\n",
      "epoch:7 step:6627 [D loss: 0.668305, acc.: 57.81%] [G loss: 0.742261]\n",
      "epoch:7 step:6628 [D loss: 0.678658, acc.: 59.38%] [G loss: 0.775683]\n",
      "epoch:7 step:6629 [D loss: 0.704225, acc.: 51.56%] [G loss: 0.768806]\n",
      "epoch:7 step:6630 [D loss: 0.674325, acc.: 62.50%] [G loss: 0.770783]\n",
      "epoch:7 step:6631 [D loss: 0.687407, acc.: 48.44%] [G loss: 0.751484]\n",
      "epoch:7 step:6632 [D loss: 0.679184, acc.: 56.25%] [G loss: 0.763553]\n",
      "epoch:7 step:6633 [D loss: 0.692637, acc.: 56.25%] [G loss: 0.753014]\n",
      "epoch:7 step:6634 [D loss: 0.689054, acc.: 55.47%] [G loss: 0.792121]\n",
      "epoch:7 step:6635 [D loss: 0.654466, acc.: 64.84%] [G loss: 0.790043]\n",
      "epoch:7 step:6636 [D loss: 0.661258, acc.: 61.72%] [G loss: 0.758178]\n",
      "epoch:7 step:6637 [D loss: 0.713382, acc.: 49.22%] [G loss: 0.840020]\n",
      "epoch:7 step:6638 [D loss: 0.679480, acc.: 54.69%] [G loss: 0.773441]\n",
      "epoch:7 step:6639 [D loss: 0.691309, acc.: 55.47%] [G loss: 0.778262]\n",
      "epoch:7 step:6640 [D loss: 0.697264, acc.: 52.34%] [G loss: 0.799192]\n",
      "epoch:7 step:6641 [D loss: 0.726918, acc.: 46.09%] [G loss: 0.761623]\n",
      "epoch:7 step:6642 [D loss: 0.719708, acc.: 47.66%] [G loss: 0.744535]\n",
      "epoch:7 step:6643 [D loss: 0.711632, acc.: 47.66%] [G loss: 0.773628]\n",
      "epoch:7 step:6644 [D loss: 0.688979, acc.: 53.91%] [G loss: 0.763074]\n",
      "epoch:7 step:6645 [D loss: 0.677743, acc.: 57.81%] [G loss: 0.767632]\n",
      "epoch:7 step:6646 [D loss: 0.687171, acc.: 53.12%] [G loss: 0.739940]\n",
      "epoch:7 step:6647 [D loss: 0.661055, acc.: 62.50%] [G loss: 0.762130]\n",
      "epoch:7 step:6648 [D loss: 0.692187, acc.: 50.78%] [G loss: 0.717677]\n",
      "epoch:7 step:6649 [D loss: 0.680024, acc.: 63.28%] [G loss: 0.805988]\n",
      "epoch:7 step:6650 [D loss: 0.673539, acc.: 60.94%] [G loss: 0.754080]\n",
      "epoch:7 step:6651 [D loss: 0.653808, acc.: 62.50%] [G loss: 0.812124]\n",
      "epoch:7 step:6652 [D loss: 0.665448, acc.: 60.16%] [G loss: 0.779907]\n",
      "epoch:7 step:6653 [D loss: 0.706127, acc.: 48.44%] [G loss: 0.793946]\n",
      "epoch:7 step:6654 [D loss: 0.686652, acc.: 55.47%] [G loss: 0.741058]\n",
      "epoch:7 step:6655 [D loss: 0.676845, acc.: 52.34%] [G loss: 0.818664]\n",
      "epoch:7 step:6656 [D loss: 0.678356, acc.: 57.03%] [G loss: 0.784665]\n",
      "epoch:7 step:6657 [D loss: 0.685915, acc.: 54.69%] [G loss: 0.769456]\n",
      "epoch:7 step:6658 [D loss: 0.671652, acc.: 57.03%] [G loss: 0.787666]\n",
      "epoch:7 step:6659 [D loss: 0.666110, acc.: 55.47%] [G loss: 0.772459]\n",
      "epoch:7 step:6660 [D loss: 0.672344, acc.: 57.03%] [G loss: 0.814780]\n",
      "epoch:7 step:6661 [D loss: 0.668136, acc.: 60.16%] [G loss: 0.783164]\n",
      "epoch:7 step:6662 [D loss: 0.706196, acc.: 46.88%] [G loss: 0.760777]\n",
      "epoch:7 step:6663 [D loss: 0.681403, acc.: 54.69%] [G loss: 0.780105]\n",
      "epoch:7 step:6664 [D loss: 0.676348, acc.: 60.16%] [G loss: 0.765162]\n",
      "epoch:7 step:6665 [D loss: 0.689940, acc.: 57.03%] [G loss: 0.746462]\n",
      "epoch:7 step:6666 [D loss: 0.656822, acc.: 57.81%] [G loss: 0.741127]\n",
      "epoch:7 step:6667 [D loss: 0.731827, acc.: 43.75%] [G loss: 0.735483]\n",
      "epoch:7 step:6668 [D loss: 0.735623, acc.: 43.75%] [G loss: 0.756127]\n",
      "epoch:7 step:6669 [D loss: 0.694852, acc.: 54.69%] [G loss: 0.753922]\n",
      "epoch:7 step:6670 [D loss: 0.683557, acc.: 49.22%] [G loss: 0.738428]\n",
      "epoch:7 step:6671 [D loss: 0.693439, acc.: 54.69%] [G loss: 0.792328]\n",
      "epoch:7 step:6672 [D loss: 0.689454, acc.: 52.34%] [G loss: 0.772837]\n",
      "epoch:7 step:6673 [D loss: 0.694137, acc.: 49.22%] [G loss: 0.773921]\n",
      "epoch:7 step:6674 [D loss: 0.702335, acc.: 53.91%] [G loss: 0.782467]\n",
      "epoch:7 step:6675 [D loss: 0.701856, acc.: 50.78%] [G loss: 0.817054]\n",
      "epoch:7 step:6676 [D loss: 0.709336, acc.: 58.59%] [G loss: 0.780969]\n",
      "epoch:7 step:6677 [D loss: 0.652407, acc.: 65.62%] [G loss: 0.769580]\n",
      "epoch:7 step:6678 [D loss: 0.702430, acc.: 56.25%] [G loss: 0.770936]\n",
      "epoch:7 step:6679 [D loss: 0.708357, acc.: 46.09%] [G loss: 0.761232]\n",
      "epoch:7 step:6680 [D loss: 0.710778, acc.: 46.09%] [G loss: 0.822449]\n",
      "epoch:7 step:6681 [D loss: 0.676411, acc.: 59.38%] [G loss: 0.816835]\n",
      "epoch:7 step:6682 [D loss: 0.687903, acc.: 53.91%] [G loss: 0.794604]\n",
      "epoch:7 step:6683 [D loss: 0.647680, acc.: 61.72%] [G loss: 0.819478]\n",
      "epoch:7 step:6684 [D loss: 0.649655, acc.: 60.94%] [G loss: 0.752419]\n",
      "epoch:7 step:6685 [D loss: 0.657061, acc.: 60.16%] [G loss: 0.774431]\n",
      "epoch:7 step:6686 [D loss: 0.672032, acc.: 57.81%] [G loss: 0.771543]\n",
      "epoch:7 step:6687 [D loss: 0.689559, acc.: 52.34%] [G loss: 0.754856]\n",
      "epoch:7 step:6688 [D loss: 0.664194, acc.: 60.94%] [G loss: 0.758134]\n",
      "epoch:7 step:6689 [D loss: 0.666429, acc.: 59.38%] [G loss: 0.797744]\n",
      "epoch:7 step:6690 [D loss: 0.648977, acc.: 63.28%] [G loss: 0.814068]\n",
      "epoch:7 step:6691 [D loss: 0.690007, acc.: 53.12%] [G loss: 0.831663]\n",
      "epoch:7 step:6692 [D loss: 0.740827, acc.: 41.41%] [G loss: 0.763677]\n",
      "epoch:7 step:6693 [D loss: 0.712642, acc.: 50.78%] [G loss: 0.769800]\n",
      "epoch:7 step:6694 [D loss: 0.707770, acc.: 51.56%] [G loss: 0.713976]\n",
      "epoch:7 step:6695 [D loss: 0.694303, acc.: 56.25%] [G loss: 0.732609]\n",
      "epoch:7 step:6696 [D loss: 0.684542, acc.: 54.69%] [G loss: 0.742985]\n",
      "epoch:7 step:6697 [D loss: 0.689845, acc.: 50.78%] [G loss: 0.752703]\n",
      "epoch:7 step:6698 [D loss: 0.671612, acc.: 61.72%] [G loss: 0.707846]\n",
      "epoch:7 step:6699 [D loss: 0.647802, acc.: 62.50%] [G loss: 0.697094]\n",
      "epoch:7 step:6700 [D loss: 0.653045, acc.: 69.53%] [G loss: 0.773515]\n",
      "epoch:7 step:6701 [D loss: 0.644289, acc.: 62.50%] [G loss: 0.791382]\n",
      "epoch:7 step:6702 [D loss: 0.641726, acc.: 60.94%] [G loss: 0.772322]\n",
      "epoch:7 step:6703 [D loss: 0.653252, acc.: 60.94%] [G loss: 0.643556]\n",
      "epoch:7 step:6704 [D loss: 0.722195, acc.: 54.69%] [G loss: 0.746214]\n",
      "epoch:7 step:6705 [D loss: 0.719717, acc.: 48.44%] [G loss: 0.792058]\n",
      "epoch:7 step:6706 [D loss: 0.678208, acc.: 60.94%] [G loss: 0.807143]\n",
      "epoch:7 step:6707 [D loss: 0.741886, acc.: 41.41%] [G loss: 0.691822]\n",
      "epoch:7 step:6708 [D loss: 0.700448, acc.: 50.78%] [G loss: 0.766498]\n",
      "epoch:7 step:6709 [D loss: 0.838492, acc.: 46.88%] [G loss: 0.791921]\n",
      "epoch:7 step:6710 [D loss: 0.673085, acc.: 55.47%] [G loss: 1.107307]\n",
      "epoch:7 step:6711 [D loss: 0.720030, acc.: 56.25%] [G loss: 0.903291]\n",
      "epoch:7 step:6712 [D loss: 0.710716, acc.: 48.44%] [G loss: 0.828438]\n",
      "epoch:7 step:6713 [D loss: 0.699019, acc.: 43.75%] [G loss: 0.837719]\n",
      "epoch:7 step:6714 [D loss: 0.701914, acc.: 49.22%] [G loss: 0.809153]\n",
      "epoch:7 step:6715 [D loss: 0.677660, acc.: 60.94%] [G loss: 0.793450]\n",
      "epoch:7 step:6716 [D loss: 0.683402, acc.: 59.38%] [G loss: 0.803432]\n",
      "epoch:7 step:6717 [D loss: 0.677561, acc.: 57.03%] [G loss: 0.825033]\n",
      "epoch:7 step:6718 [D loss: 0.661021, acc.: 62.50%] [G loss: 0.849687]\n",
      "epoch:7 step:6719 [D loss: 0.701712, acc.: 51.56%] [G loss: 0.888168]\n",
      "epoch:7 step:6720 [D loss: 0.737955, acc.: 50.00%] [G loss: 0.794167]\n",
      "epoch:7 step:6721 [D loss: 0.679436, acc.: 55.47%] [G loss: 0.793682]\n",
      "epoch:7 step:6722 [D loss: 0.704061, acc.: 44.53%] [G loss: 0.811140]\n",
      "epoch:7 step:6723 [D loss: 0.660821, acc.: 64.84%] [G loss: 0.816971]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:7 step:6724 [D loss: 0.643072, acc.: 64.06%] [G loss: 0.762930]\n",
      "epoch:7 step:6725 [D loss: 0.661299, acc.: 61.72%] [G loss: 0.792912]\n",
      "epoch:7 step:6726 [D loss: 0.666189, acc.: 61.72%] [G loss: 0.716339]\n",
      "epoch:7 step:6727 [D loss: 0.658504, acc.: 64.06%] [G loss: 0.809149]\n",
      "epoch:7 step:6728 [D loss: 0.666362, acc.: 60.16%] [G loss: 0.740596]\n",
      "epoch:7 step:6729 [D loss: 0.686366, acc.: 53.12%] [G loss: 0.788792]\n",
      "epoch:7 step:6730 [D loss: 0.674053, acc.: 60.16%] [G loss: 0.801939]\n",
      "epoch:7 step:6731 [D loss: 0.669329, acc.: 57.03%] [G loss: 0.797539]\n",
      "epoch:7 step:6732 [D loss: 0.678907, acc.: 59.38%] [G loss: 0.796977]\n",
      "epoch:7 step:6733 [D loss: 0.686732, acc.: 56.25%] [G loss: 0.768886]\n",
      "epoch:7 step:6734 [D loss: 0.696153, acc.: 52.34%] [G loss: 0.749339]\n",
      "epoch:7 step:6735 [D loss: 0.660392, acc.: 60.16%] [G loss: 0.747227]\n",
      "epoch:7 step:6736 [D loss: 0.669376, acc.: 56.25%] [G loss: 0.730461]\n",
      "epoch:7 step:6737 [D loss: 0.754481, acc.: 50.00%] [G loss: 0.781146]\n",
      "epoch:7 step:6738 [D loss: 0.705148, acc.: 50.78%] [G loss: 0.830855]\n",
      "epoch:7 step:6739 [D loss: 0.698854, acc.: 46.88%] [G loss: 0.791643]\n",
      "epoch:7 step:6740 [D loss: 0.697018, acc.: 53.12%] [G loss: 0.771618]\n",
      "epoch:7 step:6741 [D loss: 0.718459, acc.: 46.09%] [G loss: 0.853247]\n",
      "epoch:7 step:6742 [D loss: 0.689200, acc.: 56.25%] [G loss: 0.792374]\n",
      "epoch:7 step:6743 [D loss: 0.670986, acc.: 56.25%] [G loss: 0.786661]\n",
      "epoch:7 step:6744 [D loss: 0.699022, acc.: 47.66%] [G loss: 0.830020]\n",
      "epoch:7 step:6745 [D loss: 0.707339, acc.: 53.12%] [G loss: 0.781275]\n",
      "epoch:7 step:6746 [D loss: 0.705139, acc.: 47.66%] [G loss: 0.783484]\n",
      "epoch:7 step:6747 [D loss: 0.694199, acc.: 53.91%] [G loss: 0.779869]\n",
      "epoch:7 step:6748 [D loss: 0.703460, acc.: 50.00%] [G loss: 0.810101]\n",
      "epoch:7 step:6749 [D loss: 0.659021, acc.: 63.28%] [G loss: 0.765241]\n",
      "epoch:7 step:6750 [D loss: 0.663533, acc.: 60.94%] [G loss: 0.787277]\n",
      "epoch:7 step:6751 [D loss: 0.703841, acc.: 49.22%] [G loss: 0.795408]\n",
      "epoch:7 step:6752 [D loss: 0.663845, acc.: 57.03%] [G loss: 0.818451]\n",
      "epoch:7 step:6753 [D loss: 0.657962, acc.: 60.16%] [G loss: 0.853598]\n",
      "epoch:7 step:6754 [D loss: 0.659944, acc.: 67.19%] [G loss: 0.882524]\n",
      "epoch:7 step:6755 [D loss: 0.658477, acc.: 60.94%] [G loss: 0.819427]\n",
      "epoch:7 step:6756 [D loss: 0.651267, acc.: 61.72%] [G loss: 0.814639]\n",
      "epoch:7 step:6757 [D loss: 0.656337, acc.: 64.84%] [G loss: 0.795103]\n",
      "epoch:7 step:6758 [D loss: 0.678218, acc.: 54.69%] [G loss: 0.813210]\n",
      "epoch:7 step:6759 [D loss: 0.695921, acc.: 56.25%] [G loss: 0.816063]\n",
      "epoch:7 step:6760 [D loss: 0.685719, acc.: 57.03%] [G loss: 0.756609]\n",
      "epoch:7 step:6761 [D loss: 0.745427, acc.: 46.88%] [G loss: 0.730150]\n",
      "epoch:7 step:6762 [D loss: 0.774916, acc.: 39.06%] [G loss: 0.714311]\n",
      "epoch:7 step:6763 [D loss: 0.700089, acc.: 54.69%] [G loss: 0.746265]\n",
      "epoch:7 step:6764 [D loss: 0.680226, acc.: 56.25%] [G loss: 0.860205]\n",
      "epoch:7 step:6765 [D loss: 0.668739, acc.: 57.81%] [G loss: 0.911044]\n",
      "epoch:7 step:6766 [D loss: 0.627431, acc.: 64.84%] [G loss: 0.916242]\n",
      "epoch:7 step:6767 [D loss: 0.662930, acc.: 60.94%] [G loss: 0.853708]\n",
      "epoch:7 step:6768 [D loss: 0.668314, acc.: 55.47%] [G loss: 0.797685]\n",
      "epoch:7 step:6769 [D loss: 0.749949, acc.: 42.97%] [G loss: 0.695871]\n",
      "epoch:7 step:6770 [D loss: 0.697319, acc.: 52.34%] [G loss: 0.730670]\n",
      "epoch:7 step:6771 [D loss: 0.666938, acc.: 64.06%] [G loss: 0.773866]\n",
      "epoch:7 step:6772 [D loss: 0.709077, acc.: 49.22%] [G loss: 0.709372]\n",
      "epoch:7 step:6773 [D loss: 0.713286, acc.: 52.34%] [G loss: 0.633150]\n",
      "epoch:7 step:6774 [D loss: 0.734081, acc.: 42.97%] [G loss: 0.692860]\n",
      "epoch:7 step:6775 [D loss: 0.692086, acc.: 58.59%] [G loss: 0.676602]\n",
      "epoch:7 step:6776 [D loss: 0.686931, acc.: 57.03%] [G loss: 0.651415]\n",
      "epoch:7 step:6777 [D loss: 0.682130, acc.: 53.12%] [G loss: 0.732391]\n",
      "epoch:7 step:6778 [D loss: 0.658472, acc.: 63.28%] [G loss: 0.741254]\n",
      "epoch:7 step:6779 [D loss: 0.732069, acc.: 45.31%] [G loss: 0.740900]\n",
      "epoch:7 step:6780 [D loss: 0.659061, acc.: 57.03%] [G loss: 0.729999]\n",
      "epoch:7 step:6781 [D loss: 0.659914, acc.: 56.25%] [G loss: 0.763044]\n",
      "epoch:7 step:6782 [D loss: 0.617883, acc.: 67.97%] [G loss: 0.800659]\n",
      "epoch:7 step:6783 [D loss: 0.694493, acc.: 55.47%] [G loss: 0.796008]\n",
      "epoch:7 step:6784 [D loss: 0.717217, acc.: 44.53%] [G loss: 0.707168]\n",
      "epoch:7 step:6785 [D loss: 0.698923, acc.: 55.47%] [G loss: 0.759348]\n",
      "epoch:7 step:6786 [D loss: 0.652212, acc.: 62.50%] [G loss: 0.758116]\n",
      "epoch:7 step:6787 [D loss: 0.700166, acc.: 54.69%] [G loss: 0.743882]\n",
      "epoch:7 step:6788 [D loss: 0.674548, acc.: 52.34%] [G loss: 0.781348]\n",
      "epoch:7 step:6789 [D loss: 0.549048, acc.: 83.59%] [G loss: 0.826217]\n",
      "epoch:7 step:6790 [D loss: 0.702845, acc.: 58.59%] [G loss: 0.831179]\n",
      "epoch:7 step:6791 [D loss: 0.511670, acc.: 75.00%] [G loss: 0.923817]\n",
      "epoch:7 step:6792 [D loss: 0.669462, acc.: 57.03%] [G loss: 0.833432]\n",
      "epoch:7 step:6793 [D loss: 0.907205, acc.: 42.97%] [G loss: 0.957379]\n",
      "epoch:7 step:6794 [D loss: 0.665061, acc.: 57.03%] [G loss: 0.908120]\n",
      "epoch:7 step:6795 [D loss: 0.681024, acc.: 57.81%] [G loss: 0.897269]\n",
      "epoch:7 step:6796 [D loss: 0.663631, acc.: 58.59%] [G loss: 0.892022]\n",
      "epoch:7 step:6797 [D loss: 0.690324, acc.: 52.34%] [G loss: 0.884502]\n",
      "epoch:7 step:6798 [D loss: 0.712029, acc.: 49.22%] [G loss: 0.799698]\n",
      "epoch:7 step:6799 [D loss: 0.671540, acc.: 60.94%] [G loss: 0.795914]\n",
      "epoch:7 step:6800 [D loss: 0.660277, acc.: 60.94%] [G loss: 0.829091]\n",
      "##############\n",
      "[4.51920064 2.07156419 6.05292701 5.3867155  4.62487918 6.56757972\n",
      " 5.13240292 5.27440748 5.80334734 4.79368662]\n",
      "##########\n",
      "epoch:7 step:6801 [D loss: 0.683873, acc.: 57.81%] [G loss: 0.775009]\n",
      "epoch:7 step:6802 [D loss: 0.694308, acc.: 55.47%] [G loss: 0.775743]\n",
      "epoch:7 step:6803 [D loss: 0.701249, acc.: 51.56%] [G loss: 0.781641]\n",
      "epoch:7 step:6804 [D loss: 0.691899, acc.: 49.22%] [G loss: 0.747047]\n",
      "epoch:7 step:6805 [D loss: 0.824935, acc.: 37.50%] [G loss: 0.852473]\n",
      "epoch:7 step:6806 [D loss: 0.700453, acc.: 51.56%] [G loss: 0.819768]\n",
      "epoch:7 step:6807 [D loss: 0.671375, acc.: 58.59%] [G loss: 0.849505]\n",
      "epoch:7 step:6808 [D loss: 0.670907, acc.: 56.25%] [G loss: 0.825953]\n",
      "epoch:7 step:6809 [D loss: 0.681832, acc.: 58.59%] [G loss: 0.788293]\n",
      "epoch:7 step:6810 [D loss: 0.695314, acc.: 45.31%] [G loss: 0.822529]\n",
      "epoch:7 step:6811 [D loss: 0.709018, acc.: 47.66%] [G loss: 0.804854]\n",
      "epoch:7 step:6812 [D loss: 0.695074, acc.: 51.56%] [G loss: 0.839337]\n",
      "epoch:7 step:6813 [D loss: 0.681355, acc.: 50.00%] [G loss: 0.841643]\n",
      "epoch:7 step:6814 [D loss: 0.663897, acc.: 60.16%] [G loss: 0.872905]\n",
      "epoch:7 step:6815 [D loss: 0.689936, acc.: 57.03%] [G loss: 0.863769]\n",
      "epoch:7 step:6816 [D loss: 0.674313, acc.: 61.72%] [G loss: 0.770507]\n",
      "epoch:7 step:6817 [D loss: 0.656832, acc.: 62.50%] [G loss: 0.824269]\n",
      "epoch:7 step:6818 [D loss: 0.668200, acc.: 57.03%] [G loss: 0.760692]\n",
      "epoch:7 step:6819 [D loss: 0.669203, acc.: 53.12%] [G loss: 0.806010]\n",
      "epoch:7 step:6820 [D loss: 0.670776, acc.: 54.69%] [G loss: 0.708028]\n",
      "epoch:7 step:6821 [D loss: 0.636460, acc.: 61.72%] [G loss: 0.767271]\n",
      "epoch:7 step:6822 [D loss: 0.721661, acc.: 42.97%] [G loss: 0.770274]\n",
      "epoch:7 step:6823 [D loss: 0.731765, acc.: 46.88%] [G loss: 0.727440]\n",
      "epoch:7 step:6824 [D loss: 0.640058, acc.: 63.28%] [G loss: 0.659583]\n",
      "epoch:7 step:6825 [D loss: 0.636469, acc.: 54.69%] [G loss: 0.697486]\n",
      "epoch:7 step:6826 [D loss: 0.649328, acc.: 64.06%] [G loss: 0.725752]\n",
      "epoch:7 step:6827 [D loss: 0.804375, acc.: 43.75%] [G loss: 0.657816]\n",
      "epoch:7 step:6828 [D loss: 0.715102, acc.: 46.09%] [G loss: 0.890842]\n",
      "epoch:7 step:6829 [D loss: 0.707469, acc.: 44.53%] [G loss: 0.959651]\n",
      "epoch:7 step:6830 [D loss: 0.648696, acc.: 61.72%] [G loss: 1.058058]\n",
      "epoch:7 step:6831 [D loss: 0.666535, acc.: 60.94%] [G loss: 0.946564]\n",
      "epoch:7 step:6832 [D loss: 0.658363, acc.: 65.62%] [G loss: 0.968254]\n",
      "epoch:7 step:6833 [D loss: 0.653101, acc.: 65.62%] [G loss: 0.869254]\n",
      "epoch:7 step:6834 [D loss: 0.676500, acc.: 57.81%] [G loss: 0.886224]\n",
      "epoch:7 step:6835 [D loss: 0.688368, acc.: 53.12%] [G loss: 0.814470]\n",
      "epoch:7 step:6836 [D loss: 0.709877, acc.: 55.47%] [G loss: 0.806045]\n",
      "epoch:7 step:6837 [D loss: 0.704069, acc.: 47.66%] [G loss: 0.768234]\n",
      "epoch:7 step:6838 [D loss: 0.690293, acc.: 52.34%] [G loss: 0.768038]\n",
      "epoch:7 step:6839 [D loss: 0.686963, acc.: 58.59%] [G loss: 0.799276]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:7 step:6840 [D loss: 0.692289, acc.: 52.34%] [G loss: 0.768215]\n",
      "epoch:7 step:6841 [D loss: 0.683714, acc.: 51.56%] [G loss: 0.774072]\n",
      "epoch:7 step:6842 [D loss: 0.677868, acc.: 56.25%] [G loss: 0.735241]\n",
      "epoch:7 step:6843 [D loss: 0.646584, acc.: 60.94%] [G loss: 0.787164]\n",
      "epoch:7 step:6844 [D loss: 0.658926, acc.: 57.03%] [G loss: 0.800232]\n",
      "epoch:7 step:6845 [D loss: 0.657561, acc.: 61.72%] [G loss: 0.718968]\n",
      "epoch:7 step:6846 [D loss: 0.808601, acc.: 41.41%] [G loss: 0.808482]\n",
      "epoch:7 step:6847 [D loss: 0.693008, acc.: 50.00%] [G loss: 0.793972]\n",
      "epoch:7 step:6848 [D loss: 0.703763, acc.: 52.34%] [G loss: 0.788014]\n",
      "epoch:7 step:6849 [D loss: 0.654135, acc.: 61.72%] [G loss: 0.796235]\n",
      "epoch:7 step:6850 [D loss: 0.737891, acc.: 46.09%] [G loss: 0.783479]\n",
      "epoch:7 step:6851 [D loss: 0.690218, acc.: 56.25%] [G loss: 0.775147]\n",
      "epoch:7 step:6852 [D loss: 0.651569, acc.: 67.97%] [G loss: 0.791260]\n",
      "epoch:7 step:6853 [D loss: 0.698863, acc.: 54.69%] [G loss: 0.790783]\n",
      "epoch:7 step:6854 [D loss: 0.693202, acc.: 50.00%] [G loss: 0.779175]\n",
      "epoch:7 step:6855 [D loss: 0.677247, acc.: 54.69%] [G loss: 0.764341]\n",
      "epoch:7 step:6856 [D loss: 0.672634, acc.: 55.47%] [G loss: 0.777271]\n",
      "epoch:7 step:6857 [D loss: 0.683722, acc.: 55.47%] [G loss: 0.723726]\n",
      "epoch:7 step:6858 [D loss: 0.693443, acc.: 53.91%] [G loss: 0.758901]\n",
      "epoch:7 step:6859 [D loss: 0.680063, acc.: 51.56%] [G loss: 0.750512]\n",
      "epoch:7 step:6860 [D loss: 0.734695, acc.: 43.75%] [G loss: 0.766483]\n",
      "epoch:7 step:6861 [D loss: 0.702657, acc.: 51.56%] [G loss: 0.747859]\n",
      "epoch:7 step:6862 [D loss: 0.691924, acc.: 48.44%] [G loss: 0.742483]\n",
      "epoch:7 step:6863 [D loss: 0.677555, acc.: 54.69%] [G loss: 0.766668]\n",
      "epoch:7 step:6864 [D loss: 0.706409, acc.: 53.12%] [G loss: 0.758497]\n",
      "epoch:7 step:6865 [D loss: 0.683157, acc.: 51.56%] [G loss: 0.832102]\n",
      "epoch:7 step:6866 [D loss: 0.674103, acc.: 60.16%] [G loss: 0.865273]\n",
      "epoch:7 step:6867 [D loss: 0.647530, acc.: 64.84%] [G loss: 0.944233]\n",
      "epoch:7 step:6868 [D loss: 0.607975, acc.: 71.09%] [G loss: 0.869553]\n",
      "epoch:7 step:6869 [D loss: 0.633766, acc.: 71.88%] [G loss: 0.815749]\n",
      "epoch:7 step:6870 [D loss: 0.620219, acc.: 67.19%] [G loss: 0.809970]\n",
      "epoch:7 step:6871 [D loss: 0.570863, acc.: 68.75%] [G loss: 0.803508]\n",
      "epoch:7 step:6872 [D loss: 0.558558, acc.: 71.88%] [G loss: 0.811193]\n",
      "epoch:7 step:6873 [D loss: 0.543081, acc.: 63.28%] [G loss: 0.841793]\n",
      "epoch:7 step:6874 [D loss: 0.609920, acc.: 72.66%] [G loss: 0.822700]\n",
      "epoch:7 step:6875 [D loss: 0.731411, acc.: 47.66%] [G loss: 0.844746]\n",
      "epoch:7 step:6876 [D loss: 0.738660, acc.: 39.84%] [G loss: 0.918109]\n",
      "epoch:7 step:6877 [D loss: 0.676909, acc.: 55.47%] [G loss: 0.843163]\n",
      "epoch:7 step:6878 [D loss: 0.673343, acc.: 52.34%] [G loss: 0.862182]\n",
      "epoch:7 step:6879 [D loss: 0.693441, acc.: 47.66%] [G loss: 0.804027]\n",
      "epoch:7 step:6880 [D loss: 0.711747, acc.: 53.91%] [G loss: 0.824329]\n",
      "epoch:7 step:6881 [D loss: 0.687586, acc.: 55.47%] [G loss: 0.795577]\n",
      "epoch:7 step:6882 [D loss: 0.724514, acc.: 48.44%] [G loss: 0.823719]\n",
      "epoch:7 step:6883 [D loss: 0.719204, acc.: 46.88%] [G loss: 0.757040]\n",
      "epoch:7 step:6884 [D loss: 0.673859, acc.: 57.03%] [G loss: 0.769753]\n",
      "epoch:7 step:6885 [D loss: 0.721130, acc.: 45.31%] [G loss: 0.769617]\n",
      "epoch:7 step:6886 [D loss: 0.685090, acc.: 57.81%] [G loss: 0.756654]\n",
      "epoch:7 step:6887 [D loss: 0.682470, acc.: 56.25%] [G loss: 0.785657]\n",
      "epoch:7 step:6888 [D loss: 0.697579, acc.: 52.34%] [G loss: 0.765400]\n",
      "epoch:7 step:6889 [D loss: 0.718044, acc.: 46.88%] [G loss: 0.787510]\n",
      "epoch:7 step:6890 [D loss: 0.679769, acc.: 55.47%] [G loss: 0.773893]\n",
      "epoch:7 step:6891 [D loss: 0.706559, acc.: 46.09%] [G loss: 0.807883]\n",
      "epoch:7 step:6892 [D loss: 0.691354, acc.: 50.00%] [G loss: 0.797363]\n",
      "epoch:7 step:6893 [D loss: 0.666492, acc.: 64.06%] [G loss: 0.791791]\n",
      "epoch:7 step:6894 [D loss: 0.639787, acc.: 67.19%] [G loss: 0.778716]\n",
      "epoch:7 step:6895 [D loss: 0.654461, acc.: 65.62%] [G loss: 0.794206]\n",
      "epoch:7 step:6896 [D loss: 0.658034, acc.: 61.72%] [G loss: 0.760286]\n",
      "epoch:7 step:6897 [D loss: 0.696380, acc.: 53.12%] [G loss: 0.802872]\n",
      "epoch:7 step:6898 [D loss: 0.688193, acc.: 54.69%] [G loss: 0.781640]\n",
      "epoch:7 step:6899 [D loss: 0.669253, acc.: 60.16%] [G loss: 0.723695]\n",
      "epoch:7 step:6900 [D loss: 0.704063, acc.: 57.03%] [G loss: 0.759488]\n",
      "epoch:7 step:6901 [D loss: 0.662719, acc.: 61.72%] [G loss: 0.737088]\n",
      "epoch:7 step:6902 [D loss: 0.661420, acc.: 63.28%] [G loss: 0.786790]\n",
      "epoch:7 step:6903 [D loss: 0.668762, acc.: 60.94%] [G loss: 0.725417]\n",
      "epoch:7 step:6904 [D loss: 0.707179, acc.: 51.56%] [G loss: 0.711860]\n",
      "epoch:7 step:6905 [D loss: 0.645085, acc.: 56.25%] [G loss: 0.788759]\n",
      "epoch:7 step:6906 [D loss: 0.647222, acc.: 64.84%] [G loss: 0.787260]\n",
      "epoch:7 step:6907 [D loss: 0.713823, acc.: 52.34%] [G loss: 0.775598]\n",
      "epoch:7 step:6908 [D loss: 0.750427, acc.: 41.41%] [G loss: 0.788528]\n",
      "epoch:7 step:6909 [D loss: 0.701138, acc.: 48.44%] [G loss: 0.502220]\n",
      "epoch:7 step:6910 [D loss: 0.681061, acc.: 49.22%] [G loss: 0.533027]\n",
      "epoch:7 step:6911 [D loss: 0.676871, acc.: 59.38%] [G loss: 0.802599]\n",
      "epoch:7 step:6912 [D loss: 0.658875, acc.: 62.50%] [G loss: 0.855637]\n",
      "epoch:7 step:6913 [D loss: 0.691968, acc.: 56.25%] [G loss: 0.937367]\n",
      "epoch:7 step:6914 [D loss: 0.705344, acc.: 50.78%] [G loss: 0.884207]\n",
      "epoch:7 step:6915 [D loss: 0.675703, acc.: 54.69%] [G loss: 0.830507]\n",
      "epoch:7 step:6916 [D loss: 0.677624, acc.: 57.81%] [G loss: 0.869145]\n",
      "epoch:7 step:6917 [D loss: 0.675834, acc.: 56.25%] [G loss: 0.908465]\n",
      "epoch:7 step:6918 [D loss: 0.665437, acc.: 60.16%] [G loss: 0.842158]\n",
      "epoch:7 step:6919 [D loss: 0.673622, acc.: 57.81%] [G loss: 0.858086]\n",
      "epoch:7 step:6920 [D loss: 0.653090, acc.: 60.16%] [G loss: 0.786556]\n",
      "epoch:7 step:6921 [D loss: 0.732148, acc.: 47.66%] [G loss: 0.860223]\n",
      "epoch:7 step:6922 [D loss: 0.728361, acc.: 44.53%] [G loss: 0.846718]\n",
      "epoch:7 step:6923 [D loss: 0.680336, acc.: 50.00%] [G loss: 0.820460]\n",
      "epoch:7 step:6924 [D loss: 0.752650, acc.: 42.97%] [G loss: 0.761613]\n",
      "epoch:7 step:6925 [D loss: 0.726913, acc.: 44.53%] [G loss: 0.762749]\n",
      "epoch:7 step:6926 [D loss: 0.603167, acc.: 70.31%] [G loss: 0.809948]\n",
      "epoch:7 step:6927 [D loss: 0.687301, acc.: 54.69%] [G loss: 0.754980]\n",
      "epoch:7 step:6928 [D loss: 0.667731, acc.: 64.06%] [G loss: 0.822766]\n",
      "epoch:7 step:6929 [D loss: 0.678434, acc.: 54.69%] [G loss: 0.777864]\n",
      "epoch:7 step:6930 [D loss: 0.666005, acc.: 61.72%] [G loss: 0.778709]\n",
      "epoch:7 step:6931 [D loss: 0.657263, acc.: 64.06%] [G loss: 0.863894]\n",
      "epoch:7 step:6932 [D loss: 0.602382, acc.: 72.66%] [G loss: 0.830851]\n",
      "epoch:7 step:6933 [D loss: 0.626519, acc.: 67.19%] [G loss: 0.828383]\n",
      "epoch:7 step:6934 [D loss: 0.672921, acc.: 61.72%] [G loss: 0.769767]\n",
      "epoch:7 step:6935 [D loss: 0.690718, acc.: 50.00%] [G loss: 0.730544]\n",
      "epoch:7 step:6936 [D loss: 0.685192, acc.: 50.00%] [G loss: 0.767572]\n",
      "epoch:7 step:6937 [D loss: 0.666062, acc.: 53.91%] [G loss: 0.762495]\n",
      "epoch:7 step:6938 [D loss: 0.693539, acc.: 53.12%] [G loss: 0.708783]\n",
      "epoch:7 step:6939 [D loss: 0.751042, acc.: 42.19%] [G loss: 0.540055]\n",
      "epoch:7 step:6940 [D loss: 0.666529, acc.: 57.81%] [G loss: 0.686639]\n",
      "epoch:7 step:6941 [D loss: 0.666500, acc.: 58.59%] [G loss: 0.850412]\n",
      "epoch:7 step:6942 [D loss: 0.639221, acc.: 63.28%] [G loss: 0.829879]\n",
      "epoch:7 step:6943 [D loss: 0.698366, acc.: 53.12%] [G loss: 0.851824]\n",
      "epoch:7 step:6944 [D loss: 0.663956, acc.: 57.81%] [G loss: 0.817749]\n",
      "epoch:7 step:6945 [D loss: 0.677955, acc.: 55.47%] [G loss: 0.865733]\n",
      "epoch:7 step:6946 [D loss: 0.734816, acc.: 51.56%] [G loss: 0.976449]\n",
      "epoch:7 step:6947 [D loss: 0.650073, acc.: 57.03%] [G loss: 1.016064]\n",
      "epoch:7 step:6948 [D loss: 0.693640, acc.: 57.81%] [G loss: 0.939270]\n",
      "epoch:7 step:6949 [D loss: 0.780002, acc.: 39.06%] [G loss: 0.782615]\n",
      "epoch:7 step:6950 [D loss: 0.729615, acc.: 43.75%] [G loss: 0.814542]\n",
      "epoch:7 step:6951 [D loss: 0.749160, acc.: 40.62%] [G loss: 0.790427]\n",
      "epoch:7 step:6952 [D loss: 0.724521, acc.: 44.53%] [G loss: 0.804177]\n",
      "epoch:7 step:6953 [D loss: 0.672979, acc.: 63.28%] [G loss: 0.790836]\n",
      "epoch:7 step:6954 [D loss: 0.706275, acc.: 49.22%] [G loss: 0.805174]\n",
      "epoch:7 step:6955 [D loss: 0.715636, acc.: 52.34%] [G loss: 0.789962]\n",
      "epoch:7 step:6956 [D loss: 0.670311, acc.: 57.81%] [G loss: 0.765580]\n",
      "epoch:7 step:6957 [D loss: 0.672707, acc.: 57.81%] [G loss: 0.778076]\n",
      "epoch:7 step:6958 [D loss: 0.678419, acc.: 55.47%] [G loss: 0.796894]\n",
      "epoch:7 step:6959 [D loss: 0.674420, acc.: 58.59%] [G loss: 0.770363]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:7 step:6960 [D loss: 0.673233, acc.: 57.81%] [G loss: 0.762852]\n",
      "epoch:7 step:6961 [D loss: 0.623174, acc.: 72.66%] [G loss: 0.832315]\n",
      "epoch:7 step:6962 [D loss: 0.655762, acc.: 60.16%] [G loss: 0.781232]\n",
      "epoch:7 step:6963 [D loss: 0.669124, acc.: 59.38%] [G loss: 0.800329]\n",
      "epoch:7 step:6964 [D loss: 0.665363, acc.: 62.50%] [G loss: 0.853128]\n",
      "epoch:7 step:6965 [D loss: 0.678220, acc.: 59.38%] [G loss: 0.741098]\n",
      "epoch:7 step:6966 [D loss: 0.536338, acc.: 70.31%] [G loss: 0.791993]\n",
      "epoch:7 step:6967 [D loss: 0.656432, acc.: 65.62%] [G loss: 0.815943]\n",
      "epoch:7 step:6968 [D loss: 0.684175, acc.: 57.03%] [G loss: 0.824893]\n",
      "epoch:7 step:6969 [D loss: 0.703567, acc.: 53.91%] [G loss: 0.786577]\n",
      "epoch:7 step:6970 [D loss: 0.720720, acc.: 53.12%] [G loss: 0.821124]\n",
      "epoch:7 step:6971 [D loss: 0.702679, acc.: 55.47%] [G loss: 0.814453]\n",
      "epoch:7 step:6972 [D loss: 0.704552, acc.: 51.56%] [G loss: 0.807592]\n",
      "epoch:7 step:6973 [D loss: 0.689976, acc.: 53.91%] [G loss: 0.779020]\n",
      "epoch:7 step:6974 [D loss: 0.685937, acc.: 53.91%] [G loss: 0.774897]\n",
      "epoch:7 step:6975 [D loss: 0.729965, acc.: 50.78%] [G loss: 0.762791]\n",
      "epoch:7 step:6976 [D loss: 0.686641, acc.: 51.56%] [G loss: 0.780766]\n",
      "epoch:7 step:6977 [D loss: 0.682038, acc.: 52.34%] [G loss: 0.743656]\n",
      "epoch:7 step:6978 [D loss: 0.630105, acc.: 63.28%] [G loss: 0.822272]\n",
      "epoch:7 step:6979 [D loss: 0.678079, acc.: 56.25%] [G loss: 0.859592]\n",
      "epoch:7 step:6980 [D loss: 0.685841, acc.: 54.69%] [G loss: 0.842874]\n",
      "epoch:7 step:6981 [D loss: 0.668823, acc.: 55.47%] [G loss: 0.866858]\n",
      "epoch:7 step:6982 [D loss: 0.658214, acc.: 61.72%] [G loss: 0.865624]\n",
      "epoch:7 step:6983 [D loss: 0.705216, acc.: 49.22%] [G loss: 0.868587]\n",
      "epoch:7 step:6984 [D loss: 0.684740, acc.: 57.03%] [G loss: 0.834095]\n",
      "epoch:7 step:6985 [D loss: 0.665959, acc.: 59.38%] [G loss: 0.802784]\n",
      "epoch:7 step:6986 [D loss: 0.613731, acc.: 63.28%] [G loss: 0.834235]\n",
      "epoch:7 step:6987 [D loss: 0.547428, acc.: 78.12%] [G loss: 0.808080]\n",
      "epoch:7 step:6988 [D loss: 0.479771, acc.: 75.78%] [G loss: 0.909741]\n",
      "epoch:7 step:6989 [D loss: 0.601534, acc.: 64.06%] [G loss: 0.666368]\n",
      "epoch:7 step:6990 [D loss: 0.700806, acc.: 50.00%] [G loss: 0.834317]\n",
      "epoch:7 step:6991 [D loss: 0.794006, acc.: 39.84%] [G loss: 0.568452]\n",
      "epoch:7 step:6992 [D loss: 0.762813, acc.: 32.81%] [G loss: 0.881089]\n",
      "epoch:7 step:6993 [D loss: 0.798876, acc.: 36.72%] [G loss: 0.855289]\n",
      "epoch:7 step:6994 [D loss: 0.638317, acc.: 61.72%] [G loss: 0.931103]\n",
      "epoch:7 step:6995 [D loss: 0.658045, acc.: 57.81%] [G loss: 1.032212]\n",
      "epoch:7 step:6996 [D loss: 0.674424, acc.: 53.91%] [G loss: 0.990047]\n",
      "epoch:7 step:6997 [D loss: 0.637515, acc.: 57.03%] [G loss: 0.937176]\n",
      "epoch:7 step:6998 [D loss: 0.706877, acc.: 50.00%] [G loss: 1.019822]\n",
      "epoch:7 step:6999 [D loss: 0.683320, acc.: 52.34%] [G loss: 1.006042]\n",
      "epoch:7 step:7000 [D loss: 0.678156, acc.: 54.69%] [G loss: 0.836342]\n",
      "##############\n",
      "[3.94816075 1.08142791 6.71260583 5.51926653 3.89418369 6.12952155\n",
      " 4.84011153 4.91827021 5.3010355  4.47240695]\n",
      "##########\n",
      "epoch:7 step:7001 [D loss: 0.708883, acc.: 49.22%] [G loss: 0.821684]\n",
      "epoch:7 step:7002 [D loss: 0.648223, acc.: 57.81%] [G loss: 0.904642]\n",
      "epoch:7 step:7003 [D loss: 0.691761, acc.: 55.47%] [G loss: 0.885161]\n",
      "epoch:7 step:7004 [D loss: 0.651091, acc.: 64.06%] [G loss: 0.851004]\n",
      "epoch:7 step:7005 [D loss: 0.689494, acc.: 53.12%] [G loss: 0.812437]\n",
      "epoch:7 step:7006 [D loss: 0.644338, acc.: 62.50%] [G loss: 0.852913]\n",
      "epoch:7 step:7007 [D loss: 0.670200, acc.: 57.03%] [G loss: 0.866207]\n",
      "epoch:7 step:7008 [D loss: 0.638864, acc.: 62.50%] [G loss: 0.808336]\n",
      "epoch:7 step:7009 [D loss: 0.656813, acc.: 65.62%] [G loss: 0.771425]\n",
      "epoch:7 step:7010 [D loss: 0.661978, acc.: 61.72%] [G loss: 0.765582]\n",
      "epoch:7 step:7011 [D loss: 0.678256, acc.: 59.38%] [G loss: 0.836328]\n",
      "epoch:7 step:7012 [D loss: 0.665886, acc.: 60.16%] [G loss: 0.850519]\n",
      "epoch:7 step:7013 [D loss: 0.680458, acc.: 51.56%] [G loss: 0.776847]\n",
      "epoch:7 step:7014 [D loss: 0.665935, acc.: 57.81%] [G loss: 0.820254]\n",
      "epoch:7 step:7015 [D loss: 0.671613, acc.: 57.03%] [G loss: 0.821693]\n",
      "epoch:7 step:7016 [D loss: 0.652240, acc.: 64.06%] [G loss: 0.814030]\n",
      "epoch:7 step:7017 [D loss: 0.720055, acc.: 57.81%] [G loss: 0.928180]\n",
      "epoch:7 step:7018 [D loss: 0.647032, acc.: 68.75%] [G loss: 0.910001]\n",
      "epoch:7 step:7019 [D loss: 0.633074, acc.: 67.19%] [G loss: 0.960169]\n",
      "epoch:7 step:7020 [D loss: 0.652860, acc.: 67.19%] [G loss: 0.959101]\n",
      "epoch:7 step:7021 [D loss: 0.739965, acc.: 42.97%] [G loss: 0.836886]\n",
      "epoch:7 step:7022 [D loss: 0.709524, acc.: 48.44%] [G loss: 0.802886]\n",
      "epoch:7 step:7023 [D loss: 0.681023, acc.: 54.69%] [G loss: 0.754159]\n",
      "epoch:7 step:7024 [D loss: 0.722826, acc.: 46.88%] [G loss: 0.724961]\n",
      "epoch:7 step:7025 [D loss: 0.686868, acc.: 56.25%] [G loss: 0.762521]\n",
      "epoch:7 step:7026 [D loss: 0.689056, acc.: 49.22%] [G loss: 0.802886]\n",
      "epoch:7 step:7027 [D loss: 0.654905, acc.: 64.06%] [G loss: 0.897085]\n",
      "epoch:7 step:7028 [D loss: 0.629062, acc.: 71.88%] [G loss: 0.849021]\n",
      "epoch:7 step:7029 [D loss: 0.632166, acc.: 64.84%] [G loss: 0.875898]\n",
      "epoch:7 step:7030 [D loss: 0.661925, acc.: 59.38%] [G loss: 0.919882]\n",
      "epoch:7 step:7031 [D loss: 0.677195, acc.: 53.12%] [G loss: 0.816160]\n",
      "epoch:7 step:7032 [D loss: 0.746802, acc.: 36.72%] [G loss: 0.747821]\n",
      "epoch:7 step:7033 [D loss: 0.714406, acc.: 44.53%] [G loss: 0.764468]\n",
      "epoch:7 step:7034 [D loss: 0.690293, acc.: 46.88%] [G loss: 0.727054]\n",
      "epoch:7 step:7035 [D loss: 0.709554, acc.: 50.00%] [G loss: 0.811024]\n",
      "epoch:7 step:7036 [D loss: 0.720840, acc.: 49.22%] [G loss: 0.738548]\n",
      "epoch:7 step:7037 [D loss: 0.685483, acc.: 54.69%] [G loss: 0.795936]\n",
      "epoch:7 step:7038 [D loss: 0.667425, acc.: 54.69%] [G loss: 0.773462]\n",
      "epoch:7 step:7039 [D loss: 0.689593, acc.: 53.91%] [G loss: 0.785333]\n",
      "epoch:7 step:7040 [D loss: 0.647314, acc.: 71.09%] [G loss: 0.823623]\n",
      "epoch:7 step:7041 [D loss: 0.672002, acc.: 55.47%] [G loss: 0.798133]\n",
      "epoch:7 step:7042 [D loss: 0.690603, acc.: 60.16%] [G loss: 0.899295]\n",
      "epoch:7 step:7043 [D loss: 0.694179, acc.: 54.69%] [G loss: 0.861794]\n",
      "epoch:7 step:7044 [D loss: 0.672395, acc.: 54.69%] [G loss: 0.828607]\n",
      "epoch:7 step:7045 [D loss: 0.689293, acc.: 53.91%] [G loss: 0.846486]\n",
      "epoch:7 step:7046 [D loss: 0.703620, acc.: 56.25%] [G loss: 0.756642]\n",
      "epoch:7 step:7047 [D loss: 0.697576, acc.: 46.88%] [G loss: 0.738710]\n",
      "epoch:7 step:7048 [D loss: 0.662889, acc.: 64.06%] [G loss: 0.791298]\n",
      "epoch:7 step:7049 [D loss: 0.693375, acc.: 52.34%] [G loss: 0.735396]\n",
      "epoch:7 step:7050 [D loss: 0.695158, acc.: 52.34%] [G loss: 0.763316]\n",
      "epoch:7 step:7051 [D loss: 0.706788, acc.: 52.34%] [G loss: 0.727157]\n",
      "epoch:7 step:7052 [D loss: 0.682405, acc.: 55.47%] [G loss: 0.791001]\n",
      "epoch:7 step:7053 [D loss: 0.676700, acc.: 55.47%] [G loss: 0.757013]\n",
      "epoch:7 step:7054 [D loss: 0.686323, acc.: 56.25%] [G loss: 0.833233]\n",
      "epoch:7 step:7055 [D loss: 0.691003, acc.: 57.81%] [G loss: 0.817932]\n",
      "epoch:7 step:7056 [D loss: 0.652498, acc.: 62.50%] [G loss: 0.802518]\n",
      "epoch:7 step:7057 [D loss: 0.580897, acc.: 69.53%] [G loss: 0.762687]\n",
      "epoch:7 step:7058 [D loss: 0.494863, acc.: 74.22%] [G loss: 0.842564]\n",
      "epoch:7 step:7059 [D loss: 0.744936, acc.: 50.78%] [G loss: 0.793555]\n",
      "epoch:7 step:7060 [D loss: 0.755653, acc.: 40.62%] [G loss: 0.824013]\n",
      "epoch:7 step:7061 [D loss: 0.737151, acc.: 42.97%] [G loss: 0.857504]\n",
      "epoch:7 step:7062 [D loss: 0.686445, acc.: 51.56%] [G loss: 0.857140]\n",
      "epoch:7 step:7063 [D loss: 0.671823, acc.: 60.16%] [G loss: 0.818763]\n",
      "epoch:7 step:7064 [D loss: 0.637687, acc.: 65.62%] [G loss: 0.873241]\n",
      "epoch:7 step:7065 [D loss: 0.655141, acc.: 62.50%] [G loss: 0.890510]\n",
      "epoch:7 step:7066 [D loss: 0.650894, acc.: 65.62%] [G loss: 0.831972]\n",
      "epoch:7 step:7067 [D loss: 0.645497, acc.: 62.50%] [G loss: 0.840070]\n",
      "epoch:7 step:7068 [D loss: 0.701142, acc.: 50.78%] [G loss: 0.791290]\n",
      "epoch:7 step:7069 [D loss: 0.747048, acc.: 50.78%] [G loss: 0.810077]\n",
      "epoch:7 step:7070 [D loss: 0.744718, acc.: 39.06%] [G loss: 0.753228]\n",
      "epoch:7 step:7071 [D loss: 0.661342, acc.: 64.06%] [G loss: 0.772622]\n",
      "epoch:7 step:7072 [D loss: 0.598638, acc.: 74.22%] [G loss: 0.852205]\n",
      "epoch:7 step:7073 [D loss: 0.645178, acc.: 66.41%] [G loss: 0.875461]\n",
      "epoch:7 step:7074 [D loss: 0.617310, acc.: 68.75%] [G loss: 0.856907]\n",
      "epoch:7 step:7075 [D loss: 0.618443, acc.: 68.75%] [G loss: 0.696398]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:7 step:7076 [D loss: 0.732141, acc.: 51.56%] [G loss: 0.717060]\n",
      "epoch:7 step:7077 [D loss: 0.735377, acc.: 43.75%] [G loss: 0.740791]\n",
      "epoch:7 step:7078 [D loss: 0.683297, acc.: 53.91%] [G loss: 0.759129]\n",
      "epoch:7 step:7079 [D loss: 0.673392, acc.: 54.69%] [G loss: 0.765488]\n",
      "epoch:7 step:7080 [D loss: 0.672326, acc.: 56.25%] [G loss: 0.665752]\n",
      "epoch:7 step:7081 [D loss: 0.673118, acc.: 55.47%] [G loss: 0.733474]\n",
      "epoch:7 step:7082 [D loss: 0.724729, acc.: 45.31%] [G loss: 0.761507]\n",
      "epoch:7 step:7083 [D loss: 0.700215, acc.: 56.25%] [G loss: 0.789349]\n",
      "epoch:7 step:7084 [D loss: 0.701162, acc.: 47.66%] [G loss: 0.836878]\n",
      "epoch:7 step:7085 [D loss: 0.672306, acc.: 54.69%] [G loss: 0.788121]\n",
      "epoch:7 step:7086 [D loss: 0.673931, acc.: 50.78%] [G loss: 0.804044]\n",
      "epoch:7 step:7087 [D loss: 0.723829, acc.: 50.78%] [G loss: 0.796424]\n",
      "epoch:7 step:7088 [D loss: 0.709917, acc.: 49.22%] [G loss: 0.765749]\n",
      "epoch:7 step:7089 [D loss: 0.660282, acc.: 60.16%] [G loss: 0.780210]\n",
      "epoch:7 step:7090 [D loss: 0.692924, acc.: 47.66%] [G loss: 0.849552]\n",
      "epoch:7 step:7091 [D loss: 0.677754, acc.: 58.59%] [G loss: 0.857622]\n",
      "epoch:7 step:7092 [D loss: 0.673469, acc.: 61.72%] [G loss: 0.789444]\n",
      "epoch:7 step:7093 [D loss: 0.643824, acc.: 66.41%] [G loss: 0.852029]\n",
      "epoch:7 step:7094 [D loss: 0.733829, acc.: 46.09%] [G loss: 0.819347]\n",
      "epoch:7 step:7095 [D loss: 0.721907, acc.: 44.53%] [G loss: 0.810063]\n",
      "epoch:7 step:7096 [D loss: 0.705347, acc.: 51.56%] [G loss: 0.744281]\n",
      "epoch:7 step:7097 [D loss: 0.665830, acc.: 57.03%] [G loss: 0.730205]\n",
      "epoch:7 step:7098 [D loss: 0.747059, acc.: 39.84%] [G loss: 0.795395]\n",
      "epoch:7 step:7099 [D loss: 0.679102, acc.: 58.59%] [G loss: 0.788422]\n",
      "epoch:7 step:7100 [D loss: 0.667522, acc.: 57.81%] [G loss: 0.778299]\n",
      "epoch:7 step:7101 [D loss: 0.694311, acc.: 47.66%] [G loss: 0.790585]\n",
      "epoch:7 step:7102 [D loss: 0.655335, acc.: 63.28%] [G loss: 0.773297]\n",
      "epoch:7 step:7103 [D loss: 0.680356, acc.: 56.25%] [G loss: 0.830104]\n",
      "epoch:7 step:7104 [D loss: 0.681862, acc.: 56.25%] [G loss: 0.818437]\n",
      "epoch:7 step:7105 [D loss: 0.647824, acc.: 70.31%] [G loss: 0.782946]\n",
      "epoch:7 step:7106 [D loss: 0.643126, acc.: 60.94%] [G loss: 0.745113]\n",
      "epoch:7 step:7107 [D loss: 0.641298, acc.: 66.41%] [G loss: 0.783175]\n",
      "epoch:7 step:7108 [D loss: 0.658843, acc.: 63.28%] [G loss: 0.804525]\n",
      "epoch:7 step:7109 [D loss: 0.655887, acc.: 62.50%] [G loss: 0.751401]\n",
      "epoch:7 step:7110 [D loss: 0.667572, acc.: 60.94%] [G loss: 0.781481]\n",
      "epoch:7 step:7111 [D loss: 0.653346, acc.: 63.28%] [G loss: 0.819697]\n",
      "epoch:7 step:7112 [D loss: 0.682323, acc.: 56.25%] [G loss: 0.781648]\n",
      "epoch:7 step:7113 [D loss: 0.675396, acc.: 59.38%] [G loss: 0.757959]\n",
      "epoch:7 step:7114 [D loss: 0.684215, acc.: 58.59%] [G loss: 0.741205]\n",
      "epoch:7 step:7115 [D loss: 0.710382, acc.: 45.31%] [G loss: 0.853537]\n",
      "epoch:7 step:7116 [D loss: 0.661255, acc.: 59.38%] [G loss: 0.814999]\n",
      "epoch:7 step:7117 [D loss: 0.668707, acc.: 60.94%] [G loss: 0.843468]\n",
      "epoch:7 step:7118 [D loss: 0.704155, acc.: 58.59%] [G loss: 0.911495]\n",
      "epoch:7 step:7119 [D loss: 0.714115, acc.: 48.44%] [G loss: 0.848060]\n",
      "epoch:7 step:7120 [D loss: 0.638546, acc.: 61.72%] [G loss: 0.835259]\n",
      "epoch:7 step:7121 [D loss: 0.702440, acc.: 45.31%] [G loss: 0.867051]\n",
      "epoch:7 step:7122 [D loss: 0.649066, acc.: 64.06%] [G loss: 0.828921]\n",
      "epoch:7 step:7123 [D loss: 0.645104, acc.: 58.59%] [G loss: 0.945616]\n",
      "epoch:7 step:7124 [D loss: 0.637599, acc.: 67.19%] [G loss: 0.799217]\n",
      "epoch:7 step:7125 [D loss: 0.441097, acc.: 75.78%] [G loss: 0.833291]\n",
      "epoch:7 step:7126 [D loss: 0.538740, acc.: 77.34%] [G loss: 0.779018]\n",
      "epoch:7 step:7127 [D loss: 0.540111, acc.: 75.00%] [G loss: 1.099727]\n",
      "epoch:7 step:7128 [D loss: 0.731844, acc.: 50.00%] [G loss: 0.980594]\n",
      "epoch:7 step:7129 [D loss: 0.634465, acc.: 60.16%] [G loss: 0.750976]\n",
      "epoch:7 step:7130 [D loss: 0.989426, acc.: 42.19%] [G loss: 0.852838]\n",
      "epoch:7 step:7131 [D loss: 0.708103, acc.: 52.34%] [G loss: 0.855910]\n",
      "epoch:7 step:7132 [D loss: 0.638645, acc.: 67.97%] [G loss: 0.773417]\n",
      "epoch:7 step:7133 [D loss: 0.655614, acc.: 56.25%] [G loss: 0.938924]\n",
      "epoch:7 step:7134 [D loss: 0.658946, acc.: 54.69%] [G loss: 0.780115]\n",
      "epoch:7 step:7135 [D loss: 0.851862, acc.: 34.38%] [G loss: 0.812740]\n",
      "epoch:7 step:7136 [D loss: 0.714416, acc.: 49.22%] [G loss: 0.834607]\n",
      "epoch:7 step:7137 [D loss: 0.703085, acc.: 45.31%] [G loss: 0.782838]\n",
      "epoch:7 step:7138 [D loss: 0.674004, acc.: 60.16%] [G loss: 0.829718]\n",
      "epoch:7 step:7139 [D loss: 0.713513, acc.: 51.56%] [G loss: 0.731839]\n",
      "epoch:7 step:7140 [D loss: 0.671912, acc.: 58.59%] [G loss: 0.795280]\n",
      "epoch:7 step:7141 [D loss: 0.681531, acc.: 60.16%] [G loss: 0.842114]\n",
      "epoch:7 step:7142 [D loss: 0.691892, acc.: 53.12%] [G loss: 0.818920]\n",
      "epoch:7 step:7143 [D loss: 0.690646, acc.: 57.03%] [G loss: 0.870045]\n",
      "epoch:7 step:7144 [D loss: 0.614920, acc.: 69.53%] [G loss: 0.867240]\n",
      "epoch:7 step:7145 [D loss: 0.650720, acc.: 63.28%] [G loss: 0.922985]\n",
      "epoch:7 step:7146 [D loss: 0.643505, acc.: 58.59%] [G loss: 0.939873]\n",
      "epoch:7 step:7147 [D loss: 0.647539, acc.: 60.16%] [G loss: 0.852686]\n",
      "epoch:7 step:7148 [D loss: 0.621652, acc.: 70.31%] [G loss: 0.856627]\n",
      "epoch:7 step:7149 [D loss: 0.668696, acc.: 54.69%] [G loss: 0.888730]\n",
      "epoch:7 step:7150 [D loss: 0.697087, acc.: 50.78%] [G loss: 0.884502]\n",
      "epoch:7 step:7151 [D loss: 0.674808, acc.: 57.81%] [G loss: 0.843589]\n",
      "epoch:7 step:7152 [D loss: 0.714238, acc.: 49.22%] [G loss: 0.899001]\n",
      "epoch:7 step:7153 [D loss: 0.803835, acc.: 34.38%] [G loss: 0.924682]\n",
      "epoch:7 step:7154 [D loss: 0.656817, acc.: 62.50%] [G loss: 0.931208]\n",
      "epoch:7 step:7155 [D loss: 0.646173, acc.: 66.41%] [G loss: 0.942204]\n",
      "epoch:7 step:7156 [D loss: 0.700550, acc.: 54.69%] [G loss: 0.935784]\n",
      "epoch:7 step:7157 [D loss: 0.693463, acc.: 49.22%] [G loss: 0.835385]\n",
      "epoch:7 step:7158 [D loss: 0.689825, acc.: 58.59%] [G loss: 0.873960]\n",
      "epoch:7 step:7159 [D loss: 0.725885, acc.: 48.44%] [G loss: 0.813937]\n",
      "epoch:7 step:7160 [D loss: 0.722507, acc.: 46.09%] [G loss: 0.736565]\n",
      "epoch:7 step:7161 [D loss: 0.711865, acc.: 46.88%] [G loss: 0.716822]\n",
      "epoch:7 step:7162 [D loss: 0.704031, acc.: 53.91%] [G loss: 0.721725]\n",
      "epoch:7 step:7163 [D loss: 0.679647, acc.: 60.16%] [G loss: 0.747705]\n",
      "epoch:7 step:7164 [D loss: 0.662350, acc.: 57.03%] [G loss: 0.745277]\n",
      "epoch:7 step:7165 [D loss: 0.689644, acc.: 53.91%] [G loss: 0.808398]\n",
      "epoch:7 step:7166 [D loss: 0.695345, acc.: 53.12%] [G loss: 0.786605]\n",
      "epoch:7 step:7167 [D loss: 0.653633, acc.: 62.50%] [G loss: 0.784859]\n",
      "epoch:7 step:7168 [D loss: 0.668603, acc.: 58.59%] [G loss: 0.779377]\n",
      "epoch:7 step:7169 [D loss: 0.670443, acc.: 58.59%] [G loss: 0.809892]\n",
      "epoch:7 step:7170 [D loss: 0.643166, acc.: 57.81%] [G loss: 0.795866]\n",
      "epoch:7 step:7171 [D loss: 0.677421, acc.: 63.28%] [G loss: 0.802228]\n",
      "epoch:7 step:7172 [D loss: 0.662487, acc.: 62.50%] [G loss: 0.779225]\n",
      "epoch:7 step:7173 [D loss: 0.700444, acc.: 51.56%] [G loss: 0.771632]\n",
      "epoch:7 step:7174 [D loss: 0.685265, acc.: 55.47%] [G loss: 0.764614]\n",
      "epoch:7 step:7175 [D loss: 0.710201, acc.: 49.22%] [G loss: 0.776104]\n",
      "epoch:7 step:7176 [D loss: 0.690056, acc.: 57.81%] [G loss: 0.749476]\n",
      "epoch:7 step:7177 [D loss: 0.692644, acc.: 56.25%] [G loss: 0.738158]\n",
      "epoch:7 step:7178 [D loss: 0.688614, acc.: 52.34%] [G loss: 0.734490]\n",
      "epoch:7 step:7179 [D loss: 0.656969, acc.: 59.38%] [G loss: 0.791162]\n",
      "epoch:7 step:7180 [D loss: 0.681536, acc.: 53.12%] [G loss: 0.766924]\n",
      "epoch:7 step:7181 [D loss: 0.684554, acc.: 50.00%] [G loss: 0.795032]\n",
      "epoch:7 step:7182 [D loss: 0.671409, acc.: 53.91%] [G loss: 0.826237]\n",
      "epoch:7 step:7183 [D loss: 0.683242, acc.: 57.81%] [G loss: 0.763006]\n",
      "epoch:7 step:7184 [D loss: 0.687138, acc.: 51.56%] [G loss: 0.739710]\n",
      "epoch:7 step:7185 [D loss: 0.683314, acc.: 50.78%] [G loss: 0.756187]\n",
      "epoch:7 step:7186 [D loss: 0.654770, acc.: 64.84%] [G loss: 0.780370]\n",
      "epoch:7 step:7187 [D loss: 0.658771, acc.: 57.81%] [G loss: 0.804101]\n",
      "epoch:7 step:7188 [D loss: 0.654687, acc.: 65.62%] [G loss: 0.840545]\n",
      "epoch:7 step:7189 [D loss: 0.700710, acc.: 53.12%] [G loss: 0.795328]\n",
      "epoch:7 step:7190 [D loss: 0.659647, acc.: 60.16%] [G loss: 0.880266]\n",
      "epoch:7 step:7191 [D loss: 0.673373, acc.: 60.16%] [G loss: 0.814327]\n",
      "epoch:7 step:7192 [D loss: 0.665278, acc.: 58.59%] [G loss: 0.808927]\n",
      "epoch:7 step:7193 [D loss: 0.663541, acc.: 59.38%] [G loss: 0.820547]\n",
      "epoch:7 step:7194 [D loss: 0.765882, acc.: 42.19%] [G loss: 0.878837]\n",
      "epoch:7 step:7195 [D loss: 0.696908, acc.: 52.34%] [G loss: 0.815808]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:7 step:7196 [D loss: 0.677241, acc.: 59.38%] [G loss: 0.765545]\n",
      "epoch:7 step:7197 [D loss: 0.714997, acc.: 49.22%] [G loss: 0.761999]\n",
      "epoch:7 step:7198 [D loss: 0.730463, acc.: 42.19%] [G loss: 0.828016]\n",
      "epoch:7 step:7199 [D loss: 0.705741, acc.: 46.09%] [G loss: 0.824537]\n",
      "epoch:7 step:7200 [D loss: 0.669786, acc.: 53.91%] [G loss: 0.772385]\n",
      "##############\n",
      "[3.89082103 2.53804257 6.08978255 5.32792357 3.85061219 5.82853718\n",
      " 4.986491   5.23986913 5.22893287 4.66169923]\n",
      "##########\n",
      "epoch:7 step:7201 [D loss: 0.654718, acc.: 59.38%] [G loss: 0.801273]\n",
      "epoch:7 step:7202 [D loss: 0.668861, acc.: 60.94%] [G loss: 0.758786]\n",
      "epoch:7 step:7203 [D loss: 0.682604, acc.: 53.12%] [G loss: 0.778755]\n",
      "epoch:7 step:7204 [D loss: 0.727281, acc.: 46.88%] [G loss: 0.731571]\n",
      "epoch:7 step:7205 [D loss: 0.711231, acc.: 52.34%] [G loss: 0.770451]\n",
      "epoch:7 step:7206 [D loss: 0.673226, acc.: 56.25%] [G loss: 0.767770]\n",
      "epoch:7 step:7207 [D loss: 0.626398, acc.: 70.31%] [G loss: 0.806724]\n",
      "epoch:7 step:7208 [D loss: 0.673177, acc.: 55.47%] [G loss: 0.778119]\n",
      "epoch:7 step:7209 [D loss: 0.661535, acc.: 63.28%] [G loss: 0.849285]\n",
      "epoch:7 step:7210 [D loss: 0.708201, acc.: 53.12%] [G loss: 0.821566]\n",
      "epoch:7 step:7211 [D loss: 0.712836, acc.: 51.56%] [G loss: 0.743209]\n",
      "epoch:7 step:7212 [D loss: 0.714829, acc.: 46.09%] [G loss: 0.777085]\n",
      "epoch:7 step:7213 [D loss: 0.679876, acc.: 53.12%] [G loss: 0.800945]\n",
      "epoch:7 step:7214 [D loss: 0.705689, acc.: 46.09%] [G loss: 0.759129]\n",
      "epoch:7 step:7215 [D loss: 0.694300, acc.: 54.69%] [G loss: 0.743816]\n",
      "epoch:7 step:7216 [D loss: 0.717461, acc.: 50.00%] [G loss: 0.776269]\n",
      "epoch:7 step:7217 [D loss: 0.692211, acc.: 55.47%] [G loss: 0.843595]\n",
      "epoch:7 step:7218 [D loss: 0.632442, acc.: 67.19%] [G loss: 0.835613]\n",
      "epoch:7 step:7219 [D loss: 0.658048, acc.: 60.16%] [G loss: 0.874125]\n",
      "epoch:7 step:7220 [D loss: 0.649188, acc.: 62.50%] [G loss: 0.841397]\n",
      "epoch:7 step:7221 [D loss: 0.663344, acc.: 57.03%] [G loss: 0.822079]\n",
      "epoch:7 step:7222 [D loss: 0.549000, acc.: 74.22%] [G loss: 0.848887]\n",
      "epoch:7 step:7223 [D loss: 0.598439, acc.: 75.78%] [G loss: 0.881780]\n",
      "epoch:7 step:7224 [D loss: 0.612786, acc.: 68.75%] [G loss: 0.852725]\n",
      "epoch:7 step:7225 [D loss: 0.661728, acc.: 61.72%] [G loss: 0.772873]\n",
      "epoch:7 step:7226 [D loss: 0.620232, acc.: 67.97%] [G loss: 0.821466]\n",
      "epoch:7 step:7227 [D loss: 0.515586, acc.: 67.97%] [G loss: 0.796907]\n",
      "epoch:7 step:7228 [D loss: 0.629541, acc.: 63.28%] [G loss: 0.882604]\n",
      "epoch:7 step:7229 [D loss: 0.780862, acc.: 53.12%] [G loss: 0.894185]\n",
      "epoch:7 step:7230 [D loss: 0.669344, acc.: 54.69%] [G loss: 0.960953]\n",
      "epoch:7 step:7231 [D loss: 0.663446, acc.: 58.59%] [G loss: 0.886439]\n",
      "epoch:7 step:7232 [D loss: 0.711264, acc.: 48.44%] [G loss: 0.887243]\n",
      "epoch:7 step:7233 [D loss: 0.645710, acc.: 65.62%] [G loss: 0.839021]\n",
      "epoch:7 step:7234 [D loss: 0.741855, acc.: 47.66%] [G loss: 0.843585]\n",
      "epoch:7 step:7235 [D loss: 0.688654, acc.: 57.81%] [G loss: 0.849651]\n",
      "epoch:7 step:7236 [D loss: 0.707061, acc.: 53.91%] [G loss: 0.841069]\n",
      "epoch:7 step:7237 [D loss: 0.707938, acc.: 46.09%] [G loss: 0.787260]\n",
      "epoch:7 step:7238 [D loss: 0.716894, acc.: 46.88%] [G loss: 0.691883]\n",
      "epoch:7 step:7239 [D loss: 0.671019, acc.: 54.69%] [G loss: 0.753433]\n",
      "epoch:7 step:7240 [D loss: 0.706921, acc.: 50.78%] [G loss: 0.713262]\n",
      "epoch:7 step:7241 [D loss: 0.723290, acc.: 50.78%] [G loss: 0.756544]\n",
      "epoch:7 step:7242 [D loss: 0.686573, acc.: 50.78%] [G loss: 0.737721]\n",
      "epoch:7 step:7243 [D loss: 0.703899, acc.: 52.34%] [G loss: 0.583848]\n",
      "epoch:7 step:7244 [D loss: 0.670963, acc.: 57.81%] [G loss: 0.825852]\n",
      "epoch:7 step:7245 [D loss: 0.671144, acc.: 64.06%] [G loss: 0.862612]\n",
      "epoch:7 step:7246 [D loss: 0.685825, acc.: 51.56%] [G loss: 0.870251]\n",
      "epoch:7 step:7247 [D loss: 0.679384, acc.: 58.59%] [G loss: 0.837923]\n",
      "epoch:7 step:7248 [D loss: 0.699195, acc.: 48.44%] [G loss: 0.603533]\n",
      "epoch:7 step:7249 [D loss: 0.702559, acc.: 54.69%] [G loss: 0.903920]\n",
      "epoch:7 step:7250 [D loss: 0.654775, acc.: 64.06%] [G loss: 0.845651]\n",
      "epoch:7 step:7251 [D loss: 0.679810, acc.: 60.16%] [G loss: 0.841720]\n",
      "epoch:7 step:7252 [D loss: 0.664835, acc.: 61.72%] [G loss: 0.848134]\n",
      "epoch:7 step:7253 [D loss: 0.670051, acc.: 59.38%] [G loss: 0.718028]\n",
      "epoch:7 step:7254 [D loss: 0.736340, acc.: 49.22%] [G loss: 0.859180]\n",
      "epoch:7 step:7255 [D loss: 0.745187, acc.: 45.31%] [G loss: 0.788210]\n",
      "epoch:7 step:7256 [D loss: 0.680615, acc.: 58.59%] [G loss: 0.793358]\n",
      "epoch:7 step:7257 [D loss: 0.688944, acc.: 53.12%] [G loss: 0.776467]\n",
      "epoch:7 step:7258 [D loss: 0.708989, acc.: 52.34%] [G loss: 0.680305]\n",
      "epoch:7 step:7259 [D loss: 0.659478, acc.: 58.59%] [G loss: 0.755410]\n",
      "epoch:7 step:7260 [D loss: 0.675789, acc.: 55.47%] [G loss: 0.792519]\n",
      "epoch:7 step:7261 [D loss: 0.692623, acc.: 53.91%] [G loss: 0.754274]\n",
      "epoch:7 step:7262 [D loss: 0.690043, acc.: 54.69%] [G loss: 0.762228]\n",
      "epoch:7 step:7263 [D loss: 0.679302, acc.: 58.59%] [G loss: 0.754126]\n",
      "epoch:7 step:7264 [D loss: 0.707931, acc.: 47.66%] [G loss: 0.763794]\n",
      "epoch:7 step:7265 [D loss: 0.612457, acc.: 64.84%] [G loss: 0.749266]\n",
      "epoch:7 step:7266 [D loss: 0.554418, acc.: 71.09%] [G loss: 0.787713]\n",
      "epoch:7 step:7267 [D loss: 0.633568, acc.: 66.41%] [G loss: 0.792913]\n",
      "epoch:7 step:7268 [D loss: 0.630669, acc.: 64.84%] [G loss: 0.757541]\n",
      "epoch:7 step:7269 [D loss: 0.748403, acc.: 48.44%] [G loss: 0.812290]\n",
      "epoch:7 step:7270 [D loss: 0.735785, acc.: 49.22%] [G loss: 0.802956]\n",
      "epoch:7 step:7271 [D loss: 0.628003, acc.: 62.50%] [G loss: 0.797369]\n",
      "epoch:7 step:7272 [D loss: 0.605313, acc.: 68.75%] [G loss: 0.775218]\n",
      "epoch:7 step:7273 [D loss: 0.542645, acc.: 72.66%] [G loss: 0.868952]\n",
      "epoch:7 step:7274 [D loss: 0.687873, acc.: 59.38%] [G loss: 0.728732]\n",
      "epoch:7 step:7275 [D loss: 0.726779, acc.: 53.12%] [G loss: 0.773624]\n",
      "epoch:7 step:7276 [D loss: 0.653948, acc.: 63.28%] [G loss: 0.485166]\n",
      "epoch:7 step:7277 [D loss: 0.860107, acc.: 41.41%] [G loss: 0.855035]\n",
      "epoch:7 step:7278 [D loss: 0.707467, acc.: 50.78%] [G loss: 0.881054]\n",
      "epoch:7 step:7279 [D loss: 0.655023, acc.: 59.38%] [G loss: 0.936217]\n",
      "epoch:7 step:7280 [D loss: 0.715400, acc.: 50.00%] [G loss: 0.855623]\n",
      "epoch:7 step:7281 [D loss: 0.705735, acc.: 53.12%] [G loss: 0.915302]\n",
      "epoch:7 step:7282 [D loss: 0.673012, acc.: 59.38%] [G loss: 0.797487]\n",
      "epoch:7 step:7283 [D loss: 0.694019, acc.: 51.56%] [G loss: 0.865376]\n",
      "epoch:7 step:7284 [D loss: 0.728896, acc.: 47.66%] [G loss: 0.865699]\n",
      "epoch:7 step:7285 [D loss: 0.675220, acc.: 58.59%] [G loss: 0.776040]\n",
      "epoch:7 step:7286 [D loss: 0.694765, acc.: 53.91%] [G loss: 0.863147]\n",
      "epoch:7 step:7287 [D loss: 0.654629, acc.: 63.28%] [G loss: 0.793315]\n",
      "epoch:7 step:7288 [D loss: 0.705321, acc.: 50.00%] [G loss: 0.863682]\n",
      "epoch:7 step:7289 [D loss: 0.628820, acc.: 67.97%] [G loss: 0.872703]\n",
      "epoch:7 step:7290 [D loss: 0.627823, acc.: 66.41%] [G loss: 0.796494]\n",
      "epoch:7 step:7291 [D loss: 0.630859, acc.: 58.59%] [G loss: 0.834192]\n",
      "epoch:7 step:7292 [D loss: 0.608011, acc.: 71.09%] [G loss: 0.820583]\n",
      "epoch:7 step:7293 [D loss: 0.655833, acc.: 54.69%] [G loss: 0.762556]\n",
      "epoch:7 step:7294 [D loss: 0.667799, acc.: 61.72%] [G loss: 0.753934]\n",
      "epoch:7 step:7295 [D loss: 0.691986, acc.: 50.78%] [G loss: 0.794691]\n",
      "epoch:7 step:7296 [D loss: 0.607677, acc.: 60.94%] [G loss: 0.764709]\n",
      "epoch:7 step:7297 [D loss: 0.726284, acc.: 53.91%] [G loss: 0.806753]\n",
      "epoch:7 step:7298 [D loss: 0.852545, acc.: 54.69%] [G loss: 0.839945]\n",
      "epoch:7 step:7299 [D loss: 0.626700, acc.: 69.53%] [G loss: 0.961460]\n",
      "epoch:7 step:7300 [D loss: 0.729197, acc.: 40.62%] [G loss: 0.867100]\n",
      "epoch:7 step:7301 [D loss: 0.699471, acc.: 48.44%] [G loss: 0.843102]\n",
      "epoch:7 step:7302 [D loss: 0.719825, acc.: 52.34%] [G loss: 0.880047]\n",
      "epoch:7 step:7303 [D loss: 0.716369, acc.: 53.91%] [G loss: 0.888025]\n",
      "epoch:7 step:7304 [D loss: 0.728812, acc.: 46.09%] [G loss: 0.815855]\n",
      "epoch:7 step:7305 [D loss: 0.713219, acc.: 50.78%] [G loss: 0.830806]\n",
      "epoch:7 step:7306 [D loss: 0.688609, acc.: 53.91%] [G loss: 0.819264]\n",
      "epoch:7 step:7307 [D loss: 0.697378, acc.: 51.56%] [G loss: 0.806224]\n",
      "epoch:7 step:7308 [D loss: 0.672419, acc.: 55.47%] [G loss: 0.808475]\n",
      "epoch:7 step:7309 [D loss: 0.682798, acc.: 50.78%] [G loss: 0.816672]\n",
      "epoch:7 step:7310 [D loss: 0.679742, acc.: 58.59%] [G loss: 0.816263]\n",
      "epoch:7 step:7311 [D loss: 0.681621, acc.: 56.25%] [G loss: 0.801420]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:7 step:7312 [D loss: 0.693274, acc.: 52.34%] [G loss: 0.807894]\n",
      "epoch:7 step:7313 [D loss: 0.689459, acc.: 56.25%] [G loss: 0.775249]\n",
      "epoch:7 step:7314 [D loss: 0.683662, acc.: 55.47%] [G loss: 0.872774]\n",
      "epoch:7 step:7315 [D loss: 0.672728, acc.: 64.06%] [G loss: 0.811941]\n",
      "epoch:7 step:7316 [D loss: 0.674033, acc.: 54.69%] [G loss: 0.744764]\n",
      "epoch:7 step:7317 [D loss: 0.668211, acc.: 61.72%] [G loss: 0.802451]\n",
      "epoch:7 step:7318 [D loss: 0.710732, acc.: 50.78%] [G loss: 0.747900]\n",
      "epoch:7 step:7319 [D loss: 0.713734, acc.: 50.78%] [G loss: 0.759453]\n",
      "epoch:7 step:7320 [D loss: 0.697325, acc.: 50.78%] [G loss: 0.737118]\n",
      "epoch:7 step:7321 [D loss: 0.688706, acc.: 56.25%] [G loss: 0.774601]\n",
      "epoch:7 step:7322 [D loss: 0.712224, acc.: 50.78%] [G loss: 0.747887]\n",
      "epoch:7 step:7323 [D loss: 0.649716, acc.: 64.06%] [G loss: 0.750969]\n",
      "epoch:7 step:7324 [D loss: 0.707180, acc.: 52.34%] [G loss: 0.773402]\n",
      "epoch:7 step:7325 [D loss: 0.684518, acc.: 57.03%] [G loss: 0.789823]\n",
      "epoch:7 step:7326 [D loss: 0.699433, acc.: 47.66%] [G loss: 0.808712]\n",
      "epoch:7 step:7327 [D loss: 0.663785, acc.: 61.72%] [G loss: 0.829191]\n",
      "epoch:7 step:7328 [D loss: 0.651531, acc.: 61.72%] [G loss: 0.833162]\n",
      "epoch:7 step:7329 [D loss: 0.617261, acc.: 71.88%] [G loss: 0.841693]\n",
      "epoch:7 step:7330 [D loss: 0.669879, acc.: 61.72%] [G loss: 0.812664]\n",
      "epoch:7 step:7331 [D loss: 0.646185, acc.: 66.41%] [G loss: 0.804754]\n",
      "epoch:7 step:7332 [D loss: 0.651131, acc.: 60.16%] [G loss: 0.797997]\n",
      "epoch:7 step:7333 [D loss: 0.695633, acc.: 50.78%] [G loss: 0.803355]\n",
      "epoch:7 step:7334 [D loss: 0.632063, acc.: 71.88%] [G loss: 0.795458]\n",
      "epoch:7 step:7335 [D loss: 0.702884, acc.: 51.56%] [G loss: 0.768030]\n",
      "epoch:7 step:7336 [D loss: 0.697590, acc.: 53.12%] [G loss: 0.755174]\n",
      "epoch:7 step:7337 [D loss: 0.718794, acc.: 55.47%] [G loss: 0.751705]\n",
      "epoch:7 step:7338 [D loss: 0.667052, acc.: 53.91%] [G loss: 0.732776]\n",
      "epoch:7 step:7339 [D loss: 0.725528, acc.: 50.00%] [G loss: 0.681281]\n",
      "epoch:7 step:7340 [D loss: 0.700266, acc.: 54.69%] [G loss: 0.797394]\n",
      "epoch:7 step:7341 [D loss: 0.643568, acc.: 60.94%] [G loss: 0.842945]\n",
      "epoch:7 step:7342 [D loss: 0.702694, acc.: 55.47%] [G loss: 0.954405]\n",
      "epoch:7 step:7343 [D loss: 0.720615, acc.: 50.00%] [G loss: 0.852742]\n",
      "epoch:7 step:7344 [D loss: 0.662318, acc.: 57.03%] [G loss: 0.893213]\n",
      "epoch:7 step:7345 [D loss: 0.628240, acc.: 67.19%] [G loss: 0.878736]\n",
      "epoch:7 step:7346 [D loss: 0.698547, acc.: 55.47%] [G loss: 0.833157]\n",
      "epoch:7 step:7347 [D loss: 0.699767, acc.: 53.12%] [G loss: 0.817155]\n",
      "epoch:7 step:7348 [D loss: 0.670766, acc.: 60.16%] [G loss: 0.827601]\n",
      "epoch:7 step:7349 [D loss: 0.608678, acc.: 64.84%] [G loss: 0.782859]\n",
      "epoch:7 step:7350 [D loss: 0.514103, acc.: 67.97%] [G loss: 0.791971]\n",
      "epoch:7 step:7351 [D loss: 0.641415, acc.: 63.28%] [G loss: 0.667192]\n",
      "epoch:7 step:7352 [D loss: 0.622147, acc.: 63.28%] [G loss: 0.817041]\n",
      "epoch:7 step:7353 [D loss: 0.695929, acc.: 53.91%] [G loss: 0.857859]\n",
      "epoch:7 step:7354 [D loss: 0.672379, acc.: 57.03%] [G loss: 0.761988]\n",
      "epoch:7 step:7355 [D loss: 0.693863, acc.: 53.12%] [G loss: 0.783438]\n",
      "epoch:7 step:7356 [D loss: 0.723833, acc.: 50.00%] [G loss: 0.780511]\n",
      "epoch:7 step:7357 [D loss: 0.718378, acc.: 52.34%] [G loss: 0.378714]\n",
      "epoch:7 step:7358 [D loss: 0.737381, acc.: 43.75%] [G loss: 0.828804]\n",
      "epoch:7 step:7359 [D loss: 1.067741, acc.: 15.62%] [G loss: 0.839582]\n",
      "epoch:7 step:7360 [D loss: 0.685294, acc.: 55.47%] [G loss: 0.957429]\n",
      "epoch:7 step:7361 [D loss: 0.667682, acc.: 58.59%] [G loss: 1.016179]\n",
      "epoch:7 step:7362 [D loss: 0.636429, acc.: 62.50%] [G loss: 0.924875]\n",
      "epoch:7 step:7363 [D loss: 0.711936, acc.: 61.72%] [G loss: 0.836987]\n",
      "epoch:7 step:7364 [D loss: 0.698420, acc.: 50.78%] [G loss: 0.841008]\n",
      "epoch:7 step:7365 [D loss: 0.650706, acc.: 63.28%] [G loss: 0.848614]\n",
      "epoch:7 step:7366 [D loss: 0.703334, acc.: 53.12%] [G loss: 0.795898]\n",
      "epoch:7 step:7367 [D loss: 0.738966, acc.: 41.41%] [G loss: 0.732258]\n",
      "epoch:7 step:7368 [D loss: 0.695319, acc.: 53.12%] [G loss: 0.780107]\n",
      "epoch:7 step:7369 [D loss: 0.654278, acc.: 64.84%] [G loss: 0.840624]\n",
      "epoch:7 step:7370 [D loss: 0.682535, acc.: 58.59%] [G loss: 0.855860]\n",
      "epoch:7 step:7371 [D loss: 0.700117, acc.: 49.22%] [G loss: 0.769376]\n",
      "epoch:7 step:7372 [D loss: 0.653083, acc.: 64.06%] [G loss: 0.797676]\n",
      "epoch:7 step:7373 [D loss: 0.662475, acc.: 59.38%] [G loss: 0.801732]\n",
      "epoch:7 step:7374 [D loss: 0.670908, acc.: 58.59%] [G loss: 0.803852]\n",
      "epoch:7 step:7375 [D loss: 0.695159, acc.: 56.25%] [G loss: 0.797386]\n",
      "epoch:7 step:7376 [D loss: 0.687689, acc.: 56.25%] [G loss: 0.776101]\n",
      "epoch:7 step:7377 [D loss: 0.725245, acc.: 48.44%] [G loss: 0.856345]\n",
      "epoch:7 step:7378 [D loss: 0.684271, acc.: 53.91%] [G loss: 0.791054]\n",
      "epoch:7 step:7379 [D loss: 0.679792, acc.: 51.56%] [G loss: 0.790002]\n",
      "epoch:7 step:7380 [D loss: 0.700168, acc.: 45.31%] [G loss: 0.775589]\n",
      "epoch:7 step:7381 [D loss: 0.667667, acc.: 58.59%] [G loss: 0.767736]\n",
      "epoch:7 step:7382 [D loss: 0.706368, acc.: 42.97%] [G loss: 0.754557]\n",
      "epoch:7 step:7383 [D loss: 0.704877, acc.: 53.12%] [G loss: 0.768310]\n",
      "epoch:7 step:7384 [D loss: 0.680841, acc.: 49.22%] [G loss: 0.751113]\n",
      "epoch:7 step:7385 [D loss: 0.701276, acc.: 54.69%] [G loss: 0.758619]\n",
      "epoch:7 step:7386 [D loss: 0.692852, acc.: 53.91%] [G loss: 0.768547]\n",
      "epoch:7 step:7387 [D loss: 0.684964, acc.: 54.69%] [G loss: 0.742005]\n",
      "epoch:7 step:7388 [D loss: 0.678505, acc.: 60.94%] [G loss: 0.786032]\n",
      "epoch:7 step:7389 [D loss: 0.678681, acc.: 58.59%] [G loss: 0.773187]\n",
      "epoch:7 step:7390 [D loss: 0.660586, acc.: 68.75%] [G loss: 0.753741]\n",
      "epoch:7 step:7391 [D loss: 0.633193, acc.: 71.09%] [G loss: 0.794724]\n",
      "epoch:7 step:7392 [D loss: 0.670538, acc.: 59.38%] [G loss: 0.801676]\n",
      "epoch:7 step:7393 [D loss: 0.737192, acc.: 46.09%] [G loss: 0.761007]\n",
      "epoch:7 step:7394 [D loss: 0.727414, acc.: 44.53%] [G loss: 0.773895]\n",
      "epoch:7 step:7395 [D loss: 0.695924, acc.: 51.56%] [G loss: 0.741694]\n",
      "epoch:7 step:7396 [D loss: 0.712864, acc.: 47.66%] [G loss: 0.760008]\n",
      "epoch:7 step:7397 [D loss: 0.675726, acc.: 55.47%] [G loss: 0.755537]\n",
      "epoch:7 step:7398 [D loss: 0.653827, acc.: 65.62%] [G loss: 0.729436]\n",
      "epoch:7 step:7399 [D loss: 0.685407, acc.: 60.16%] [G loss: 0.733597]\n",
      "epoch:7 step:7400 [D loss: 0.610370, acc.: 64.06%] [G loss: 0.772179]\n",
      "##############\n",
      "[4.07551473 2.338535   6.21590661 5.82826085 4.21295924 6.06019142\n",
      " 5.09105393 5.39303216 5.82667885 4.83260988]\n",
      "##########\n",
      "epoch:7 step:7401 [D loss: 0.673863, acc.: 56.25%] [G loss: 0.761642]\n",
      "epoch:7 step:7402 [D loss: 0.695614, acc.: 59.38%] [G loss: 0.747159]\n",
      "epoch:7 step:7403 [D loss: 0.693312, acc.: 51.56%] [G loss: 0.788192]\n",
      "epoch:7 step:7404 [D loss: 0.674079, acc.: 61.72%] [G loss: 0.765608]\n",
      "epoch:7 step:7405 [D loss: 0.661161, acc.: 59.38%] [G loss: 0.789631]\n",
      "epoch:7 step:7406 [D loss: 0.684994, acc.: 56.25%] [G loss: 0.819537]\n",
      "epoch:7 step:7407 [D loss: 0.654953, acc.: 61.72%] [G loss: 0.849988]\n",
      "epoch:7 step:7408 [D loss: 0.687920, acc.: 53.12%] [G loss: 0.769294]\n",
      "epoch:7 step:7409 [D loss: 0.708436, acc.: 42.97%] [G loss: 0.777347]\n",
      "epoch:7 step:7410 [D loss: 0.680688, acc.: 53.91%] [G loss: 0.751452]\n",
      "epoch:7 step:7411 [D loss: 0.664915, acc.: 63.28%] [G loss: 0.754351]\n",
      "epoch:7 step:7412 [D loss: 0.674097, acc.: 61.72%] [G loss: 0.728346]\n",
      "epoch:7 step:7413 [D loss: 0.657109, acc.: 65.62%] [G loss: 0.782835]\n",
      "epoch:7 step:7414 [D loss: 0.697672, acc.: 53.12%] [G loss: 0.774731]\n",
      "epoch:7 step:7415 [D loss: 0.689852, acc.: 53.91%] [G loss: 0.694426]\n",
      "epoch:7 step:7416 [D loss: 0.638169, acc.: 63.28%] [G loss: 0.787318]\n",
      "epoch:7 step:7417 [D loss: 0.727587, acc.: 39.84%] [G loss: 0.614361]\n",
      "epoch:7 step:7418 [D loss: 0.751133, acc.: 41.41%] [G loss: 0.754867]\n",
      "epoch:7 step:7419 [D loss: 0.718133, acc.: 49.22%] [G loss: 0.817861]\n",
      "epoch:7 step:7420 [D loss: 0.718220, acc.: 46.88%] [G loss: 0.746297]\n",
      "epoch:7 step:7421 [D loss: 0.716735, acc.: 43.75%] [G loss: 0.791428]\n",
      "epoch:7 step:7422 [D loss: 0.703274, acc.: 50.78%] [G loss: 0.770568]\n",
      "epoch:7 step:7423 [D loss: 0.700063, acc.: 41.41%] [G loss: 0.896336]\n",
      "epoch:7 step:7424 [D loss: 0.686045, acc.: 50.78%] [G loss: 0.880702]\n",
      "epoch:7 step:7425 [D loss: 0.631628, acc.: 61.72%] [G loss: 0.820459]\n",
      "epoch:7 step:7426 [D loss: 0.700167, acc.: 53.12%] [G loss: 0.779349]\n",
      "epoch:7 step:7427 [D loss: 0.682542, acc.: 56.25%] [G loss: 0.866504]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:7 step:7428 [D loss: 0.704570, acc.: 49.22%] [G loss: 0.818273]\n",
      "epoch:7 step:7429 [D loss: 0.695918, acc.: 52.34%] [G loss: 0.825272]\n",
      "epoch:7 step:7430 [D loss: 0.645402, acc.: 63.28%] [G loss: 0.956282]\n",
      "epoch:7 step:7431 [D loss: 0.737087, acc.: 44.53%] [G loss: 0.759567]\n",
      "epoch:7 step:7432 [D loss: 0.694303, acc.: 50.00%] [G loss: 0.884797]\n",
      "epoch:7 step:7433 [D loss: 0.687632, acc.: 47.66%] [G loss: 0.812737]\n",
      "epoch:7 step:7434 [D loss: 0.687649, acc.: 55.47%] [G loss: 0.773518]\n",
      "epoch:7 step:7435 [D loss: 0.683758, acc.: 56.25%] [G loss: 0.771010]\n",
      "epoch:7 step:7436 [D loss: 0.654191, acc.: 62.50%] [G loss: 0.833344]\n",
      "epoch:7 step:7437 [D loss: 0.666117, acc.: 62.50%] [G loss: 0.860837]\n",
      "epoch:7 step:7438 [D loss: 0.685328, acc.: 55.47%] [G loss: 0.838913]\n",
      "epoch:7 step:7439 [D loss: 0.695713, acc.: 50.78%] [G loss: 0.835226]\n",
      "epoch:7 step:7440 [D loss: 0.680949, acc.: 59.38%] [G loss: 0.804550]\n",
      "epoch:7 step:7441 [D loss: 0.698315, acc.: 51.56%] [G loss: 0.816568]\n",
      "epoch:7 step:7442 [D loss: 0.667633, acc.: 58.59%] [G loss: 0.826617]\n",
      "epoch:7 step:7443 [D loss: 0.704666, acc.: 52.34%] [G loss: 0.788844]\n",
      "epoch:7 step:7444 [D loss: 0.638880, acc.: 65.62%] [G loss: 0.834802]\n",
      "epoch:7 step:7445 [D loss: 0.673126, acc.: 55.47%] [G loss: 0.812212]\n",
      "epoch:7 step:7446 [D loss: 0.555313, acc.: 70.31%] [G loss: 0.818088]\n",
      "epoch:7 step:7447 [D loss: 0.668074, acc.: 57.81%] [G loss: 0.821476]\n",
      "epoch:7 step:7448 [D loss: 0.580781, acc.: 68.75%] [G loss: 0.864292]\n",
      "epoch:7 step:7449 [D loss: 0.603314, acc.: 71.88%] [G loss: 0.862203]\n",
      "epoch:7 step:7450 [D loss: 0.748998, acc.: 46.09%] [G loss: 0.803568]\n",
      "epoch:7 step:7451 [D loss: 0.857291, acc.: 32.03%] [G loss: 0.828124]\n",
      "epoch:7 step:7452 [D loss: 0.816389, acc.: 32.81%] [G loss: 0.893200]\n",
      "epoch:7 step:7453 [D loss: 0.709361, acc.: 47.66%] [G loss: 0.861024]\n",
      "epoch:7 step:7454 [D loss: 0.683268, acc.: 55.47%] [G loss: 0.900330]\n",
      "epoch:7 step:7455 [D loss: 0.680444, acc.: 57.03%] [G loss: 0.800131]\n",
      "epoch:7 step:7456 [D loss: 0.683874, acc.: 55.47%] [G loss: 0.887762]\n",
      "epoch:7 step:7457 [D loss: 0.669727, acc.: 61.72%] [G loss: 0.842230]\n",
      "epoch:7 step:7458 [D loss: 0.667939, acc.: 57.03%] [G loss: 0.823317]\n",
      "epoch:7 step:7459 [D loss: 0.690962, acc.: 53.12%] [G loss: 0.841683]\n",
      "epoch:7 step:7460 [D loss: 0.688619, acc.: 57.03%] [G loss: 0.808480]\n",
      "epoch:7 step:7461 [D loss: 0.717089, acc.: 45.31%] [G loss: 0.814064]\n",
      "epoch:7 step:7462 [D loss: 0.690466, acc.: 48.44%] [G loss: 0.770907]\n",
      "epoch:7 step:7463 [D loss: 0.715283, acc.: 46.88%] [G loss: 0.745854]\n",
      "epoch:7 step:7464 [D loss: 0.678256, acc.: 57.81%] [G loss: 0.769153]\n",
      "epoch:7 step:7465 [D loss: 0.719565, acc.: 45.31%] [G loss: 0.757388]\n",
      "epoch:7 step:7466 [D loss: 0.673208, acc.: 55.47%] [G loss: 0.762441]\n",
      "epoch:7 step:7467 [D loss: 0.677486, acc.: 52.34%] [G loss: 0.769094]\n",
      "epoch:7 step:7468 [D loss: 0.688820, acc.: 53.91%] [G loss: 0.695285]\n",
      "epoch:7 step:7469 [D loss: 0.645501, acc.: 60.94%] [G loss: 0.734918]\n",
      "epoch:7 step:7470 [D loss: 0.689698, acc.: 61.72%] [G loss: 0.732606]\n",
      "epoch:7 step:7471 [D loss: 0.699787, acc.: 51.56%] [G loss: 0.679687]\n",
      "epoch:7 step:7472 [D loss: 0.711592, acc.: 51.56%] [G loss: 0.733709]\n",
      "epoch:7 step:7473 [D loss: 0.669076, acc.: 58.59%] [G loss: 0.744531]\n",
      "epoch:7 step:7474 [D loss: 0.688572, acc.: 54.69%] [G loss: 0.762863]\n",
      "epoch:7 step:7475 [D loss: 0.692609, acc.: 53.12%] [G loss: 0.750847]\n",
      "epoch:7 step:7476 [D loss: 0.713452, acc.: 47.66%] [G loss: 0.775136]\n",
      "epoch:7 step:7477 [D loss: 0.651218, acc.: 64.84%] [G loss: 0.724438]\n",
      "epoch:7 step:7478 [D loss: 0.667767, acc.: 62.50%] [G loss: 0.753608]\n",
      "epoch:7 step:7479 [D loss: 0.739122, acc.: 42.19%] [G loss: 0.755738]\n",
      "epoch:7 step:7480 [D loss: 0.659753, acc.: 62.50%] [G loss: 0.784999]\n",
      "epoch:7 step:7481 [D loss: 0.640407, acc.: 67.97%] [G loss: 0.845619]\n",
      "epoch:7 step:7482 [D loss: 0.645644, acc.: 67.19%] [G loss: 0.779426]\n",
      "epoch:7 step:7483 [D loss: 0.654497, acc.: 63.28%] [G loss: 0.795672]\n",
      "epoch:7 step:7484 [D loss: 0.653642, acc.: 60.16%] [G loss: 0.747009]\n",
      "epoch:7 step:7485 [D loss: 0.676179, acc.: 57.03%] [G loss: 0.735553]\n",
      "epoch:7 step:7486 [D loss: 0.639518, acc.: 62.50%] [G loss: 0.845429]\n",
      "epoch:7 step:7487 [D loss: 0.735431, acc.: 45.31%] [G loss: 0.746478]\n",
      "epoch:7 step:7488 [D loss: 0.588291, acc.: 72.66%] [G loss: 0.829524]\n",
      "epoch:7 step:7489 [D loss: 0.648970, acc.: 67.19%] [G loss: 0.845939]\n",
      "epoch:7 step:7490 [D loss: 0.697995, acc.: 55.47%] [G loss: 0.825961]\n",
      "epoch:7 step:7491 [D loss: 0.711825, acc.: 49.22%] [G loss: 0.765888]\n",
      "epoch:7 step:7492 [D loss: 0.714083, acc.: 51.56%] [G loss: 0.799607]\n",
      "epoch:7 step:7493 [D loss: 0.656979, acc.: 62.50%] [G loss: 0.810679]\n",
      "epoch:7 step:7494 [D loss: 0.619358, acc.: 69.53%] [G loss: 0.840648]\n",
      "epoch:7 step:7495 [D loss: 0.594503, acc.: 71.09%] [G loss: 0.834158]\n",
      "epoch:7 step:7496 [D loss: 0.629049, acc.: 66.41%] [G loss: 0.750131]\n",
      "epoch:8 step:7497 [D loss: 0.661049, acc.: 57.81%] [G loss: 0.869277]\n",
      "epoch:8 step:7498 [D loss: 0.720914, acc.: 53.91%] [G loss: 0.787724]\n",
      "epoch:8 step:7499 [D loss: 0.691238, acc.: 58.59%] [G loss: 0.796267]\n",
      "epoch:8 step:7500 [D loss: 0.704059, acc.: 50.78%] [G loss: 0.804577]\n",
      "epoch:8 step:7501 [D loss: 0.704889, acc.: 55.47%] [G loss: 0.793168]\n",
      "epoch:8 step:7502 [D loss: 0.707756, acc.: 50.78%] [G loss: 0.753497]\n",
      "epoch:8 step:7503 [D loss: 0.693323, acc.: 55.47%] [G loss: 0.704091]\n",
      "epoch:8 step:7504 [D loss: 0.722743, acc.: 49.22%] [G loss: 0.694301]\n",
      "epoch:8 step:7505 [D loss: 0.697342, acc.: 50.00%] [G loss: 0.738947]\n",
      "epoch:8 step:7506 [D loss: 0.707471, acc.: 48.44%] [G loss: 0.706530]\n",
      "epoch:8 step:7507 [D loss: 0.721594, acc.: 46.09%] [G loss: 0.750149]\n",
      "epoch:8 step:7508 [D loss: 0.708314, acc.: 49.22%] [G loss: 0.726419]\n",
      "epoch:8 step:7509 [D loss: 0.655558, acc.: 61.72%] [G loss: 0.778795]\n",
      "epoch:8 step:7510 [D loss: 0.667473, acc.: 58.59%] [G loss: 0.786582]\n",
      "epoch:8 step:7511 [D loss: 0.666466, acc.: 56.25%] [G loss: 0.825117]\n",
      "epoch:8 step:7512 [D loss: 0.688841, acc.: 51.56%] [G loss: 0.862771]\n",
      "epoch:8 step:7513 [D loss: 0.731113, acc.: 48.44%] [G loss: 0.847465]\n",
      "epoch:8 step:7514 [D loss: 0.689504, acc.: 53.12%] [G loss: 0.760562]\n",
      "epoch:8 step:7515 [D loss: 0.680112, acc.: 60.16%] [G loss: 0.837222]\n",
      "epoch:8 step:7516 [D loss: 0.672569, acc.: 58.59%] [G loss: 0.762445]\n",
      "epoch:8 step:7517 [D loss: 0.638610, acc.: 70.31%] [G loss: 0.965379]\n",
      "epoch:8 step:7518 [D loss: 0.628419, acc.: 67.19%] [G loss: 0.897570]\n",
      "epoch:8 step:7519 [D loss: 0.741389, acc.: 41.41%] [G loss: 0.757482]\n",
      "epoch:8 step:7520 [D loss: 0.720376, acc.: 48.44%] [G loss: 0.724225]\n",
      "epoch:8 step:7521 [D loss: 0.696928, acc.: 49.22%] [G loss: 0.730666]\n",
      "epoch:8 step:7522 [D loss: 0.698880, acc.: 55.47%] [G loss: 0.756932]\n",
      "epoch:8 step:7523 [D loss: 0.715244, acc.: 47.66%] [G loss: 0.778005]\n",
      "epoch:8 step:7524 [D loss: 0.695090, acc.: 53.91%] [G loss: 0.767365]\n",
      "epoch:8 step:7525 [D loss: 0.666689, acc.: 55.47%] [G loss: 0.777119]\n",
      "epoch:8 step:7526 [D loss: 0.657489, acc.: 57.81%] [G loss: 0.792311]\n",
      "epoch:8 step:7527 [D loss: 0.679614, acc.: 57.81%] [G loss: 0.754559]\n",
      "epoch:8 step:7528 [D loss: 0.651973, acc.: 58.59%] [G loss: 0.808571]\n",
      "epoch:8 step:7529 [D loss: 0.673941, acc.: 55.47%] [G loss: 0.799671]\n",
      "epoch:8 step:7530 [D loss: 0.660586, acc.: 63.28%] [G loss: 0.894451]\n",
      "epoch:8 step:7531 [D loss: 0.633329, acc.: 68.75%] [G loss: 0.749271]\n",
      "epoch:8 step:7532 [D loss: 0.645700, acc.: 60.94%] [G loss: 0.874095]\n",
      "epoch:8 step:7533 [D loss: 0.730049, acc.: 53.12%] [G loss: 0.777278]\n",
      "epoch:8 step:7534 [D loss: 0.728588, acc.: 47.66%] [G loss: 0.790958]\n",
      "epoch:8 step:7535 [D loss: 0.734155, acc.: 45.31%] [G loss: 0.779056]\n",
      "epoch:8 step:7536 [D loss: 0.705644, acc.: 55.47%] [G loss: 0.800950]\n",
      "epoch:8 step:7537 [D loss: 0.692262, acc.: 52.34%] [G loss: 0.817132]\n",
      "epoch:8 step:7538 [D loss: 0.678674, acc.: 57.81%] [G loss: 0.819454]\n",
      "epoch:8 step:7539 [D loss: 0.670708, acc.: 60.16%] [G loss: 0.783997]\n",
      "epoch:8 step:7540 [D loss: 0.667406, acc.: 58.59%] [G loss: 0.773748]\n",
      "epoch:8 step:7541 [D loss: 0.737596, acc.: 42.97%] [G loss: 0.788819]\n",
      "epoch:8 step:7542 [D loss: 0.673412, acc.: 61.72%] [G loss: 0.777967]\n",
      "epoch:8 step:7543 [D loss: 0.668901, acc.: 61.72%] [G loss: 0.828954]\n",
      "epoch:8 step:7544 [D loss: 0.655620, acc.: 61.72%] [G loss: 0.844816]\n",
      "epoch:8 step:7545 [D loss: 0.649132, acc.: 66.41%] [G loss: 0.850226]\n",
      "epoch:8 step:7546 [D loss: 0.679463, acc.: 53.12%] [G loss: 0.808451]\n",
      "epoch:8 step:7547 [D loss: 0.667357, acc.: 60.94%] [G loss: 0.809328]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:8 step:7548 [D loss: 0.674956, acc.: 54.69%] [G loss: 0.803129]\n",
      "epoch:8 step:7549 [D loss: 0.683152, acc.: 54.69%] [G loss: 0.796231]\n",
      "epoch:8 step:7550 [D loss: 0.690618, acc.: 56.25%] [G loss: 0.762614]\n",
      "epoch:8 step:7551 [D loss: 0.667958, acc.: 57.81%] [G loss: 0.777337]\n",
      "epoch:8 step:7552 [D loss: 0.683464, acc.: 53.91%] [G loss: 0.799135]\n",
      "epoch:8 step:7553 [D loss: 0.654716, acc.: 60.16%] [G loss: 0.750893]\n",
      "epoch:8 step:7554 [D loss: 0.701826, acc.: 52.34%] [G loss: 0.745596]\n",
      "epoch:8 step:7555 [D loss: 0.717483, acc.: 44.53%] [G loss: 0.703248]\n",
      "epoch:8 step:7556 [D loss: 0.677184, acc.: 60.16%] [G loss: 0.749020]\n",
      "epoch:8 step:7557 [D loss: 0.684014, acc.: 53.91%] [G loss: 0.472092]\n",
      "epoch:8 step:7558 [D loss: 0.738870, acc.: 42.19%] [G loss: 0.727875]\n",
      "epoch:8 step:7559 [D loss: 0.659879, acc.: 60.16%] [G loss: 0.703293]\n",
      "epoch:8 step:7560 [D loss: 0.688861, acc.: 56.25%] [G loss: 0.743894]\n",
      "epoch:8 step:7561 [D loss: 0.691694, acc.: 50.00%] [G loss: 0.766936]\n",
      "epoch:8 step:7562 [D loss: 0.699097, acc.: 53.91%] [G loss: 0.718456]\n",
      "epoch:8 step:7563 [D loss: 0.681370, acc.: 52.34%] [G loss: 0.773800]\n",
      "epoch:8 step:7564 [D loss: 0.682580, acc.: 53.12%] [G loss: 0.772949]\n",
      "epoch:8 step:7565 [D loss: 0.684539, acc.: 53.12%] [G loss: 0.786453]\n",
      "epoch:8 step:7566 [D loss: 0.673858, acc.: 57.81%] [G loss: 0.799039]\n",
      "epoch:8 step:7567 [D loss: 0.666060, acc.: 63.28%] [G loss: 0.762285]\n",
      "epoch:8 step:7568 [D loss: 0.594289, acc.: 69.53%] [G loss: 0.761293]\n",
      "epoch:8 step:7569 [D loss: 0.726451, acc.: 43.75%] [G loss: 0.798957]\n",
      "epoch:8 step:7570 [D loss: 0.635987, acc.: 67.19%] [G loss: 0.793609]\n",
      "epoch:8 step:7571 [D loss: 0.663624, acc.: 58.59%] [G loss: 0.859242]\n",
      "epoch:8 step:7572 [D loss: 0.667741, acc.: 61.72%] [G loss: 0.792827]\n",
      "epoch:8 step:7573 [D loss: 0.588508, acc.: 76.56%] [G loss: 0.804214]\n",
      "epoch:8 step:7574 [D loss: 0.696518, acc.: 53.12%] [G loss: 0.850141]\n",
      "epoch:8 step:7575 [D loss: 0.717593, acc.: 46.88%] [G loss: 0.825921]\n",
      "epoch:8 step:7576 [D loss: 0.680955, acc.: 57.81%] [G loss: 0.776422]\n",
      "epoch:8 step:7577 [D loss: 0.725274, acc.: 44.53%] [G loss: 0.795571]\n",
      "epoch:8 step:7578 [D loss: 0.738591, acc.: 39.06%] [G loss: 0.784248]\n",
      "epoch:8 step:7579 [D loss: 0.725128, acc.: 46.09%] [G loss: 0.797648]\n",
      "epoch:8 step:7580 [D loss: 0.681729, acc.: 61.72%] [G loss: 0.791184]\n",
      "epoch:8 step:7581 [D loss: 0.697251, acc.: 53.91%] [G loss: 0.763047]\n",
      "epoch:8 step:7582 [D loss: 0.662148, acc.: 63.28%] [G loss: 0.788186]\n",
      "epoch:8 step:7583 [D loss: 0.695957, acc.: 53.12%] [G loss: 0.808272]\n",
      "epoch:8 step:7584 [D loss: 0.677867, acc.: 60.16%] [G loss: 0.801829]\n",
      "epoch:8 step:7585 [D loss: 0.656666, acc.: 64.06%] [G loss: 0.760402]\n",
      "epoch:8 step:7586 [D loss: 0.660146, acc.: 62.50%] [G loss: 0.804246]\n",
      "epoch:8 step:7587 [D loss: 0.672756, acc.: 60.16%] [G loss: 0.878576]\n",
      "epoch:8 step:7588 [D loss: 0.629479, acc.: 64.84%] [G loss: 0.872371]\n",
      "epoch:8 step:7589 [D loss: 0.591726, acc.: 74.22%] [G loss: 0.930001]\n",
      "epoch:8 step:7590 [D loss: 0.681035, acc.: 57.81%] [G loss: 0.886681]\n",
      "epoch:8 step:7591 [D loss: 0.679373, acc.: 59.38%] [G loss: 0.942129]\n",
      "epoch:8 step:7592 [D loss: 0.620558, acc.: 67.97%] [G loss: 0.927077]\n",
      "epoch:8 step:7593 [D loss: 0.658602, acc.: 59.38%] [G loss: 0.841642]\n",
      "epoch:8 step:7594 [D loss: 0.673296, acc.: 57.81%] [G loss: 0.906777]\n",
      "epoch:8 step:7595 [D loss: 0.646625, acc.: 62.50%] [G loss: 0.875491]\n",
      "epoch:8 step:7596 [D loss: 0.654352, acc.: 60.16%] [G loss: 0.923849]\n",
      "epoch:8 step:7597 [D loss: 0.670786, acc.: 57.81%] [G loss: 0.953426]\n",
      "epoch:8 step:7598 [D loss: 0.619869, acc.: 67.97%] [G loss: 0.936693]\n",
      "epoch:8 step:7599 [D loss: 0.683635, acc.: 56.25%] [G loss: 0.819232]\n",
      "epoch:8 step:7600 [D loss: 0.717512, acc.: 52.34%] [G loss: 0.791405]\n",
      "##############\n",
      "[4.05025969 2.6319039  6.1690189  5.6503236  4.16990109 6.06185707\n",
      " 4.73002853 5.17956379 5.42215127 4.78747437]\n",
      "##########\n",
      "epoch:8 step:7601 [D loss: 0.708377, acc.: 58.59%] [G loss: 0.806614]\n",
      "epoch:8 step:7602 [D loss: 0.651694, acc.: 58.59%] [G loss: 0.815727]\n",
      "epoch:8 step:7603 [D loss: 0.660232, acc.: 54.69%] [G loss: 0.716842]\n",
      "epoch:8 step:7604 [D loss: 0.808649, acc.: 38.28%] [G loss: 0.756172]\n",
      "epoch:8 step:7605 [D loss: 0.790280, acc.: 32.81%] [G loss: 0.776757]\n",
      "epoch:8 step:7606 [D loss: 0.706722, acc.: 50.00%] [G loss: 0.841895]\n",
      "epoch:8 step:7607 [D loss: 0.688597, acc.: 57.03%] [G loss: 0.799083]\n",
      "epoch:8 step:7608 [D loss: 0.689563, acc.: 49.22%] [G loss: 0.840672]\n",
      "epoch:8 step:7609 [D loss: 0.671204, acc.: 57.03%] [G loss: 0.884382]\n",
      "epoch:8 step:7610 [D loss: 0.662970, acc.: 60.94%] [G loss: 0.905045]\n",
      "epoch:8 step:7611 [D loss: 0.674006, acc.: 59.38%] [G loss: 0.801324]\n",
      "epoch:8 step:7612 [D loss: 0.696269, acc.: 46.88%] [G loss: 0.752566]\n",
      "epoch:8 step:7613 [D loss: 0.681689, acc.: 55.47%] [G loss: 0.854364]\n",
      "epoch:8 step:7614 [D loss: 0.680587, acc.: 53.12%] [G loss: 0.876843]\n",
      "epoch:8 step:7615 [D loss: 0.666017, acc.: 60.94%] [G loss: 0.831922]\n",
      "epoch:8 step:7616 [D loss: 0.703813, acc.: 53.12%] [G loss: 0.787846]\n",
      "epoch:8 step:7617 [D loss: 0.701192, acc.: 52.34%] [G loss: 0.819122]\n",
      "epoch:8 step:7618 [D loss: 0.685221, acc.: 57.81%] [G loss: 0.824519]\n",
      "epoch:8 step:7619 [D loss: 0.657387, acc.: 55.47%] [G loss: 0.851291]\n",
      "epoch:8 step:7620 [D loss: 0.601410, acc.: 67.19%] [G loss: 0.809309]\n",
      "epoch:8 step:7621 [D loss: 0.608047, acc.: 66.41%] [G loss: 0.871343]\n",
      "epoch:8 step:7622 [D loss: 0.667078, acc.: 58.59%] [G loss: 0.825853]\n",
      "epoch:8 step:7623 [D loss: 0.655124, acc.: 60.16%] [G loss: 0.836043]\n",
      "epoch:8 step:7624 [D loss: 0.719844, acc.: 44.53%] [G loss: 0.747989]\n",
      "epoch:8 step:7625 [D loss: 0.699162, acc.: 49.22%] [G loss: 0.780906]\n",
      "epoch:8 step:7626 [D loss: 0.667644, acc.: 57.81%] [G loss: 0.756119]\n",
      "epoch:8 step:7627 [D loss: 0.737242, acc.: 48.44%] [G loss: 0.769928]\n",
      "epoch:8 step:7628 [D loss: 0.693745, acc.: 53.91%] [G loss: 0.820952]\n",
      "epoch:8 step:7629 [D loss: 0.671051, acc.: 50.78%] [G loss: 0.795014]\n",
      "epoch:8 step:7630 [D loss: 0.679133, acc.: 59.38%] [G loss: 0.774113]\n",
      "epoch:8 step:7631 [D loss: 0.783952, acc.: 46.09%] [G loss: 0.836172]\n",
      "epoch:8 step:7632 [D loss: 0.655983, acc.: 58.59%] [G loss: 0.823565]\n",
      "epoch:8 step:7633 [D loss: 0.716878, acc.: 43.75%] [G loss: 0.809717]\n",
      "epoch:8 step:7634 [D loss: 0.724379, acc.: 45.31%] [G loss: 0.824366]\n",
      "epoch:8 step:7635 [D loss: 0.670089, acc.: 59.38%] [G loss: 0.830481]\n",
      "epoch:8 step:7636 [D loss: 0.610110, acc.: 70.31%] [G loss: 0.841477]\n",
      "epoch:8 step:7637 [D loss: 0.645947, acc.: 65.62%] [G loss: 0.777477]\n",
      "epoch:8 step:7638 [D loss: 0.657546, acc.: 62.50%] [G loss: 0.801033]\n",
      "epoch:8 step:7639 [D loss: 0.749991, acc.: 51.56%] [G loss: 0.805676]\n",
      "epoch:8 step:7640 [D loss: 0.653242, acc.: 61.72%] [G loss: 0.757346]\n",
      "epoch:8 step:7641 [D loss: 0.645338, acc.: 62.50%] [G loss: 0.831789]\n",
      "epoch:8 step:7642 [D loss: 0.687256, acc.: 54.69%] [G loss: 0.788387]\n",
      "epoch:8 step:7643 [D loss: 0.708759, acc.: 55.47%] [G loss: 0.796328]\n",
      "epoch:8 step:7644 [D loss: 0.686020, acc.: 53.91%] [G loss: 0.790768]\n",
      "epoch:8 step:7645 [D loss: 0.667152, acc.: 56.25%] [G loss: 0.744194]\n",
      "epoch:8 step:7646 [D loss: 0.568948, acc.: 71.09%] [G loss: 0.786876]\n",
      "epoch:8 step:7647 [D loss: 0.636451, acc.: 63.28%] [G loss: 0.755572]\n",
      "epoch:8 step:7648 [D loss: 0.695923, acc.: 56.25%] [G loss: 0.828546]\n",
      "epoch:8 step:7649 [D loss: 0.744358, acc.: 40.62%] [G loss: 0.821533]\n",
      "epoch:8 step:7650 [D loss: 0.691585, acc.: 50.00%] [G loss: 0.836478]\n",
      "epoch:8 step:7651 [D loss: 0.692097, acc.: 48.44%] [G loss: 0.869434]\n",
      "epoch:8 step:7652 [D loss: 0.698152, acc.: 49.22%] [G loss: 0.795325]\n",
      "epoch:8 step:7653 [D loss: 0.664699, acc.: 57.81%] [G loss: 0.866807]\n",
      "epoch:8 step:7654 [D loss: 0.716904, acc.: 52.34%] [G loss: 0.758087]\n",
      "epoch:8 step:7655 [D loss: 0.696197, acc.: 55.47%] [G loss: 0.748877]\n",
      "epoch:8 step:7656 [D loss: 0.734314, acc.: 45.31%] [G loss: 0.780207]\n",
      "epoch:8 step:7657 [D loss: 0.573342, acc.: 76.56%] [G loss: 0.763349]\n",
      "epoch:8 step:7658 [D loss: 0.745770, acc.: 45.31%] [G loss: 0.739205]\n",
      "epoch:8 step:7659 [D loss: 0.699872, acc.: 49.22%] [G loss: 0.757450]\n",
      "epoch:8 step:7660 [D loss: 0.682304, acc.: 51.56%] [G loss: 0.787655]\n",
      "epoch:8 step:7661 [D loss: 0.703923, acc.: 56.25%] [G loss: 0.743572]\n",
      "epoch:8 step:7662 [D loss: 0.703111, acc.: 47.66%] [G loss: 0.737750]\n",
      "epoch:8 step:7663 [D loss: 0.807691, acc.: 35.16%] [G loss: 0.826327]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:8 step:7664 [D loss: 0.686345, acc.: 54.69%] [G loss: 0.862368]\n",
      "epoch:8 step:7665 [D loss: 0.650332, acc.: 63.28%] [G loss: 0.870517]\n",
      "epoch:8 step:7666 [D loss: 0.656583, acc.: 57.81%] [G loss: 0.913723]\n",
      "epoch:8 step:7667 [D loss: 0.639718, acc.: 71.09%] [G loss: 0.835196]\n",
      "epoch:8 step:7668 [D loss: 0.652750, acc.: 60.94%] [G loss: 0.923781]\n",
      "epoch:8 step:7669 [D loss: 0.649793, acc.: 64.84%] [G loss: 0.819811]\n",
      "epoch:8 step:7670 [D loss: 0.672558, acc.: 61.72%] [G loss: 0.835243]\n",
      "epoch:8 step:7671 [D loss: 0.688895, acc.: 53.91%] [G loss: 0.766428]\n",
      "epoch:8 step:7672 [D loss: 0.635323, acc.: 59.38%] [G loss: 0.734385]\n",
      "epoch:8 step:7673 [D loss: 0.677141, acc.: 58.59%] [G loss: 0.774617]\n",
      "epoch:8 step:7674 [D loss: 0.682640, acc.: 57.03%] [G loss: 0.774795]\n",
      "epoch:8 step:7675 [D loss: 0.706759, acc.: 50.78%] [G loss: 0.746841]\n",
      "epoch:8 step:7676 [D loss: 0.701572, acc.: 50.78%] [G loss: 0.727719]\n",
      "epoch:8 step:7677 [D loss: 0.717304, acc.: 48.44%] [G loss: 0.760771]\n",
      "epoch:8 step:7678 [D loss: 0.714699, acc.: 46.09%] [G loss: 0.781160]\n",
      "epoch:8 step:7679 [D loss: 0.685933, acc.: 47.66%] [G loss: 0.760919]\n",
      "epoch:8 step:7680 [D loss: 0.700287, acc.: 51.56%] [G loss: 0.756138]\n",
      "epoch:8 step:7681 [D loss: 0.701444, acc.: 49.22%] [G loss: 0.778386]\n",
      "epoch:8 step:7682 [D loss: 0.713500, acc.: 46.88%] [G loss: 0.777663]\n",
      "epoch:8 step:7683 [D loss: 0.698092, acc.: 51.56%] [G loss: 0.728657]\n",
      "epoch:8 step:7684 [D loss: 0.686452, acc.: 54.69%] [G loss: 0.788707]\n",
      "epoch:8 step:7685 [D loss: 0.696163, acc.: 51.56%] [G loss: 0.758734]\n",
      "epoch:8 step:7686 [D loss: 0.657108, acc.: 58.59%] [G loss: 0.856017]\n",
      "epoch:8 step:7687 [D loss: 0.664067, acc.: 60.94%] [G loss: 0.785861]\n",
      "epoch:8 step:7688 [D loss: 0.685487, acc.: 55.47%] [G loss: 0.765606]\n",
      "epoch:8 step:7689 [D loss: 0.697498, acc.: 53.12%] [G loss: 0.788169]\n",
      "epoch:8 step:7690 [D loss: 0.662629, acc.: 59.38%] [G loss: 0.807031]\n",
      "epoch:8 step:7691 [D loss: 0.682352, acc.: 57.81%] [G loss: 0.817062]\n",
      "epoch:8 step:7692 [D loss: 0.707230, acc.: 47.66%] [G loss: 0.812142]\n",
      "epoch:8 step:7693 [D loss: 0.681174, acc.: 60.94%] [G loss: 0.813300]\n",
      "epoch:8 step:7694 [D loss: 0.671426, acc.: 58.59%] [G loss: 0.806889]\n",
      "epoch:8 step:7695 [D loss: 0.664174, acc.: 56.25%] [G loss: 0.793795]\n",
      "epoch:8 step:7696 [D loss: 0.668734, acc.: 54.69%] [G loss: 0.844849]\n",
      "epoch:8 step:7697 [D loss: 0.679513, acc.: 54.69%] [G loss: 0.830680]\n",
      "epoch:8 step:7698 [D loss: 0.651900, acc.: 60.16%] [G loss: 0.851552]\n",
      "epoch:8 step:7699 [D loss: 0.694566, acc.: 56.25%] [G loss: 0.782924]\n",
      "epoch:8 step:7700 [D loss: 0.679788, acc.: 53.91%] [G loss: 0.769722]\n",
      "epoch:8 step:7701 [D loss: 0.697821, acc.: 51.56%] [G loss: 0.788926]\n",
      "epoch:8 step:7702 [D loss: 0.696650, acc.: 49.22%] [G loss: 0.782740]\n",
      "epoch:8 step:7703 [D loss: 0.640596, acc.: 65.62%] [G loss: 0.765794]\n",
      "epoch:8 step:7704 [D loss: 0.696389, acc.: 53.12%] [G loss: 0.702047]\n",
      "epoch:8 step:7705 [D loss: 0.697586, acc.: 50.78%] [G loss: 0.776140]\n",
      "epoch:8 step:7706 [D loss: 0.704309, acc.: 51.56%] [G loss: 0.703014]\n",
      "epoch:8 step:7707 [D loss: 0.714818, acc.: 46.88%] [G loss: 0.716226]\n",
      "epoch:8 step:7708 [D loss: 0.704566, acc.: 47.66%] [G loss: 0.732167]\n",
      "epoch:8 step:7709 [D loss: 0.704863, acc.: 47.66%] [G loss: 0.692866]\n",
      "epoch:8 step:7710 [D loss: 0.733577, acc.: 42.97%] [G loss: 0.784403]\n",
      "epoch:8 step:7711 [D loss: 0.714727, acc.: 44.53%] [G loss: 0.809181]\n",
      "epoch:8 step:7712 [D loss: 0.691964, acc.: 50.00%] [G loss: 0.753534]\n",
      "epoch:8 step:7713 [D loss: 0.677270, acc.: 56.25%] [G loss: 0.764663]\n",
      "epoch:8 step:7714 [D loss: 0.651997, acc.: 64.06%] [G loss: 0.754192]\n",
      "epoch:8 step:7715 [D loss: 0.661810, acc.: 60.16%] [G loss: 0.787145]\n",
      "epoch:8 step:7716 [D loss: 0.649211, acc.: 67.19%] [G loss: 0.782048]\n",
      "epoch:8 step:7717 [D loss: 0.632352, acc.: 71.88%] [G loss: 0.819372]\n",
      "epoch:8 step:7718 [D loss: 0.612270, acc.: 71.88%] [G loss: 0.764111]\n",
      "epoch:8 step:7719 [D loss: 0.564853, acc.: 75.78%] [G loss: 0.707572]\n",
      "epoch:8 step:7720 [D loss: 0.693037, acc.: 59.38%] [G loss: 0.795246]\n",
      "epoch:8 step:7721 [D loss: 0.723544, acc.: 45.31%] [G loss: 0.720706]\n",
      "epoch:8 step:7722 [D loss: 0.688049, acc.: 53.91%] [G loss: 0.791161]\n",
      "epoch:8 step:7723 [D loss: 0.641157, acc.: 60.16%] [G loss: 0.758673]\n",
      "epoch:8 step:7724 [D loss: 0.669358, acc.: 57.81%] [G loss: 0.698247]\n",
      "epoch:8 step:7725 [D loss: 0.625189, acc.: 60.16%] [G loss: 0.810067]\n",
      "epoch:8 step:7726 [D loss: 0.499520, acc.: 75.00%] [G loss: 0.822082]\n",
      "epoch:8 step:7727 [D loss: 0.637481, acc.: 64.06%] [G loss: 0.866279]\n",
      "epoch:8 step:7728 [D loss: 0.425193, acc.: 77.34%] [G loss: 0.836933]\n",
      "epoch:8 step:7729 [D loss: 0.692878, acc.: 57.81%] [G loss: 0.798999]\n",
      "epoch:8 step:7730 [D loss: 1.021326, acc.: 50.78%] [G loss: 0.795518]\n",
      "epoch:8 step:7731 [D loss: 0.685996, acc.: 49.22%] [G loss: 1.437622]\n",
      "epoch:8 step:7732 [D loss: 0.698999, acc.: 48.44%] [G loss: 1.030824]\n",
      "epoch:8 step:7733 [D loss: 0.738761, acc.: 50.78%] [G loss: 0.954018]\n",
      "epoch:8 step:7734 [D loss: 0.702007, acc.: 54.69%] [G loss: 0.956702]\n",
      "epoch:8 step:7735 [D loss: 0.690138, acc.: 53.91%] [G loss: 0.874508]\n",
      "epoch:8 step:7736 [D loss: 0.687884, acc.: 55.47%] [G loss: 0.889559]\n",
      "epoch:8 step:7737 [D loss: 0.665609, acc.: 58.59%] [G loss: 0.735265]\n",
      "epoch:8 step:7738 [D loss: 0.669263, acc.: 61.72%] [G loss: 0.845199]\n",
      "epoch:8 step:7739 [D loss: 0.706494, acc.: 46.09%] [G loss: 0.844434]\n",
      "epoch:8 step:7740 [D loss: 0.756460, acc.: 43.75%] [G loss: 0.871466]\n",
      "epoch:8 step:7741 [D loss: 0.653207, acc.: 63.28%] [G loss: 0.866439]\n",
      "epoch:8 step:7742 [D loss: 0.661807, acc.: 57.03%] [G loss: 1.237751]\n",
      "epoch:8 step:7743 [D loss: 0.648585, acc.: 55.47%] [G loss: 0.950395]\n",
      "epoch:8 step:7744 [D loss: 0.667906, acc.: 59.38%] [G loss: 0.804143]\n",
      "epoch:8 step:7745 [D loss: 0.699987, acc.: 52.34%] [G loss: 0.803191]\n",
      "epoch:8 step:7746 [D loss: 0.693912, acc.: 57.03%] [G loss: 0.779827]\n",
      "epoch:8 step:7747 [D loss: 0.667219, acc.: 53.12%] [G loss: 0.763226]\n",
      "epoch:8 step:7748 [D loss: 0.711654, acc.: 50.00%] [G loss: 0.759004]\n",
      "epoch:8 step:7749 [D loss: 0.710741, acc.: 51.56%] [G loss: 0.742832]\n",
      "epoch:8 step:7750 [D loss: 0.700828, acc.: 49.22%] [G loss: 0.780855]\n",
      "epoch:8 step:7751 [D loss: 0.692313, acc.: 51.56%] [G loss: 0.752434]\n",
      "epoch:8 step:7752 [D loss: 0.710332, acc.: 50.00%] [G loss: 0.766573]\n",
      "epoch:8 step:7753 [D loss: 0.687346, acc.: 50.00%] [G loss: 0.776458]\n",
      "epoch:8 step:7754 [D loss: 0.663107, acc.: 64.06%] [G loss: 0.812824]\n",
      "epoch:8 step:7755 [D loss: 0.653304, acc.: 60.16%] [G loss: 0.818779]\n",
      "epoch:8 step:7756 [D loss: 0.656761, acc.: 57.03%] [G loss: 0.791585]\n",
      "epoch:8 step:7757 [D loss: 0.671254, acc.: 61.72%] [G loss: 0.759297]\n",
      "epoch:8 step:7758 [D loss: 0.637980, acc.: 61.72%] [G loss: 0.738616]\n",
      "epoch:8 step:7759 [D loss: 0.655759, acc.: 59.38%] [G loss: 0.817129]\n",
      "epoch:8 step:7760 [D loss: 0.678095, acc.: 58.59%] [G loss: 0.680475]\n",
      "epoch:8 step:7761 [D loss: 0.634191, acc.: 61.72%] [G loss: 0.724593]\n",
      "epoch:8 step:7762 [D loss: 0.641108, acc.: 57.81%] [G loss: 0.833521]\n",
      "epoch:8 step:7763 [D loss: 0.635110, acc.: 64.06%] [G loss: 0.746374]\n",
      "epoch:8 step:7764 [D loss: 0.685169, acc.: 59.38%] [G loss: 0.772972]\n",
      "epoch:8 step:7765 [D loss: 0.653648, acc.: 61.72%] [G loss: 0.873654]\n",
      "epoch:8 step:7766 [D loss: 0.672225, acc.: 56.25%] [G loss: 0.872624]\n",
      "epoch:8 step:7767 [D loss: 0.678678, acc.: 57.81%] [G loss: 0.782328]\n",
      "epoch:8 step:7768 [D loss: 0.851249, acc.: 29.69%] [G loss: 0.789748]\n",
      "epoch:8 step:7769 [D loss: 0.717690, acc.: 47.66%] [G loss: 0.830434]\n",
      "epoch:8 step:7770 [D loss: 0.659419, acc.: 60.16%] [G loss: 0.848544]\n",
      "epoch:8 step:7771 [D loss: 0.685764, acc.: 58.59%] [G loss: 0.853754]\n",
      "epoch:8 step:7772 [D loss: 0.671703, acc.: 62.50%] [G loss: 0.784580]\n",
      "epoch:8 step:7773 [D loss: 0.701585, acc.: 50.78%] [G loss: 0.818044]\n",
      "epoch:8 step:7774 [D loss: 0.722069, acc.: 44.53%] [G loss: 0.771434]\n",
      "epoch:8 step:7775 [D loss: 0.623307, acc.: 67.19%] [G loss: 0.683298]\n",
      "epoch:8 step:7776 [D loss: 0.723573, acc.: 48.44%] [G loss: 0.633241]\n",
      "epoch:8 step:7777 [D loss: 0.731336, acc.: 50.78%] [G loss: 0.750021]\n",
      "epoch:8 step:7778 [D loss: 0.714649, acc.: 50.78%] [G loss: 0.799032]\n",
      "epoch:8 step:7779 [D loss: 0.703862, acc.: 49.22%] [G loss: 0.799225]\n",
      "epoch:8 step:7780 [D loss: 0.679755, acc.: 60.94%] [G loss: 0.789338]\n",
      "epoch:8 step:7781 [D loss: 0.611579, acc.: 67.19%] [G loss: 0.833077]\n",
      "epoch:8 step:7782 [D loss: 0.690779, acc.: 55.47%] [G loss: 0.770159]\n",
      "epoch:8 step:7783 [D loss: 0.705232, acc.: 49.22%] [G loss: 0.741313]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:8 step:7784 [D loss: 0.667033, acc.: 52.34%] [G loss: 0.750675]\n",
      "epoch:8 step:7785 [D loss: 0.662822, acc.: 55.47%] [G loss: 0.779530]\n",
      "epoch:8 step:7786 [D loss: 0.738072, acc.: 49.22%] [G loss: 0.780622]\n",
      "epoch:8 step:7787 [D loss: 0.719770, acc.: 47.66%] [G loss: 0.779198]\n",
      "epoch:8 step:7788 [D loss: 0.701009, acc.: 51.56%] [G loss: 0.758248]\n",
      "epoch:8 step:7789 [D loss: 0.716260, acc.: 47.66%] [G loss: 0.791380]\n",
      "epoch:8 step:7790 [D loss: 0.685230, acc.: 55.47%] [G loss: 0.780974]\n",
      "epoch:8 step:7791 [D loss: 0.670985, acc.: 57.03%] [G loss: 0.777194]\n",
      "epoch:8 step:7792 [D loss: 0.686284, acc.: 57.81%] [G loss: 0.824425]\n",
      "epoch:8 step:7793 [D loss: 0.690929, acc.: 53.12%] [G loss: 0.812207]\n",
      "epoch:8 step:7794 [D loss: 0.679562, acc.: 57.81%] [G loss: 0.814584]\n",
      "epoch:8 step:7795 [D loss: 0.697630, acc.: 53.12%] [G loss: 0.771420]\n",
      "epoch:8 step:7796 [D loss: 0.687170, acc.: 50.00%] [G loss: 0.750065]\n",
      "epoch:8 step:7797 [D loss: 0.712415, acc.: 49.22%] [G loss: 0.763992]\n",
      "epoch:8 step:7798 [D loss: 0.691834, acc.: 46.88%] [G loss: 0.795432]\n",
      "epoch:8 step:7799 [D loss: 0.691495, acc.: 49.22%] [G loss: 0.770607]\n",
      "epoch:8 step:7800 [D loss: 0.712266, acc.: 43.75%] [G loss: 0.773988]\n",
      "##############\n",
      "[4.21596324 2.4978193  6.12654875 5.2781196  4.13279822 5.92393255\n",
      " 4.92599693 5.7979912  5.55008884 4.62665007]\n",
      "##########\n",
      "epoch:8 step:7801 [D loss: 0.701383, acc.: 47.66%] [G loss: 0.751180]\n",
      "epoch:8 step:7802 [D loss: 0.693203, acc.: 50.00%] [G loss: 0.742321]\n",
      "epoch:8 step:7803 [D loss: 0.665656, acc.: 63.28%] [G loss: 0.777528]\n",
      "epoch:8 step:7804 [D loss: 0.603538, acc.: 72.66%] [G loss: 0.748320]\n",
      "epoch:8 step:7805 [D loss: 0.611492, acc.: 65.62%] [G loss: 0.770096]\n",
      "epoch:8 step:7806 [D loss: 0.654890, acc.: 57.81%] [G loss: 0.781007]\n",
      "epoch:8 step:7807 [D loss: 0.637682, acc.: 64.84%] [G loss: 0.776402]\n",
      "epoch:8 step:7808 [D loss: 0.531828, acc.: 73.44%] [G loss: 0.750004]\n",
      "epoch:8 step:7809 [D loss: 0.585426, acc.: 67.97%] [G loss: 0.759821]\n",
      "epoch:8 step:7810 [D loss: 0.428865, acc.: 76.56%] [G loss: 0.789629]\n",
      "epoch:8 step:7811 [D loss: 0.633102, acc.: 64.06%] [G loss: 0.732733]\n",
      "epoch:8 step:7812 [D loss: 0.732730, acc.: 51.56%] [G loss: 0.770185]\n",
      "epoch:8 step:7813 [D loss: 0.737142, acc.: 40.62%] [G loss: 0.807541]\n",
      "epoch:8 step:7814 [D loss: 0.711178, acc.: 48.44%] [G loss: 0.692470]\n",
      "epoch:8 step:7815 [D loss: 0.719413, acc.: 52.34%] [G loss: 0.764711]\n",
      "epoch:8 step:7816 [D loss: 0.717475, acc.: 44.53%] [G loss: 0.812178]\n",
      "epoch:8 step:7817 [D loss: 0.862659, acc.: 33.59%] [G loss: 0.830012]\n",
      "epoch:8 step:7818 [D loss: 0.683437, acc.: 57.81%] [G loss: 0.860523]\n",
      "epoch:8 step:7819 [D loss: 0.707239, acc.: 49.22%] [G loss: 0.823848]\n",
      "epoch:8 step:7820 [D loss: 0.705204, acc.: 52.34%] [G loss: 0.814590]\n",
      "epoch:8 step:7821 [D loss: 0.672826, acc.: 57.03%] [G loss: 0.812272]\n",
      "epoch:8 step:7822 [D loss: 0.684771, acc.: 55.47%] [G loss: 0.846196]\n",
      "epoch:8 step:7823 [D loss: 0.659883, acc.: 59.38%] [G loss: 0.778798]\n",
      "epoch:8 step:7824 [D loss: 0.674054, acc.: 58.59%] [G loss: 0.865981]\n",
      "epoch:8 step:7825 [D loss: 0.672055, acc.: 55.47%] [G loss: 0.890378]\n",
      "epoch:8 step:7826 [D loss: 0.703875, acc.: 53.12%] [G loss: 0.826044]\n",
      "epoch:8 step:7827 [D loss: 0.669976, acc.: 59.38%] [G loss: 0.827383]\n",
      "epoch:8 step:7828 [D loss: 0.710873, acc.: 48.44%] [G loss: 0.817085]\n",
      "epoch:8 step:7829 [D loss: 0.700969, acc.: 52.34%] [G loss: 0.807944]\n",
      "epoch:8 step:7830 [D loss: 0.650402, acc.: 64.84%] [G loss: 0.782125]\n",
      "epoch:8 step:7831 [D loss: 0.640083, acc.: 66.41%] [G loss: 0.777170]\n",
      "epoch:8 step:7832 [D loss: 0.656904, acc.: 65.62%] [G loss: 0.812023]\n",
      "epoch:8 step:7833 [D loss: 0.637153, acc.: 68.75%] [G loss: 0.802313]\n",
      "epoch:8 step:7834 [D loss: 0.680997, acc.: 58.59%] [G loss: 0.816506]\n",
      "epoch:8 step:7835 [D loss: 0.667234, acc.: 57.81%] [G loss: 0.747995]\n",
      "epoch:8 step:7836 [D loss: 0.699495, acc.: 54.69%] [G loss: 0.750521]\n",
      "epoch:8 step:7837 [D loss: 0.684796, acc.: 60.94%] [G loss: 0.798598]\n",
      "epoch:8 step:7838 [D loss: 0.643873, acc.: 59.38%] [G loss: 0.791112]\n",
      "epoch:8 step:7839 [D loss: 0.639896, acc.: 60.94%] [G loss: 0.786085]\n",
      "epoch:8 step:7840 [D loss: 0.627091, acc.: 71.88%] [G loss: 0.724069]\n",
      "epoch:8 step:7841 [D loss: 0.672356, acc.: 58.59%] [G loss: 0.758057]\n",
      "epoch:8 step:7842 [D loss: 0.684601, acc.: 52.34%] [G loss: 0.748027]\n",
      "epoch:8 step:7843 [D loss: 0.613499, acc.: 67.97%] [G loss: 0.751712]\n",
      "epoch:8 step:7844 [D loss: 0.705572, acc.: 52.34%] [G loss: 0.669315]\n",
      "epoch:8 step:7845 [D loss: 0.797390, acc.: 39.84%] [G loss: 0.569341]\n",
      "epoch:8 step:7846 [D loss: 0.526460, acc.: 75.00%] [G loss: 0.757713]\n",
      "epoch:8 step:7847 [D loss: 0.691123, acc.: 46.09%] [G loss: 0.545802]\n",
      "epoch:8 step:7848 [D loss: 0.729904, acc.: 50.78%] [G loss: 0.826416]\n",
      "epoch:8 step:7849 [D loss: 0.636198, acc.: 64.06%] [G loss: 0.923402]\n",
      "epoch:8 step:7850 [D loss: 0.797322, acc.: 43.75%] [G loss: 1.124887]\n",
      "epoch:8 step:7851 [D loss: 0.620020, acc.: 60.16%] [G loss: 1.708186]\n",
      "epoch:8 step:7852 [D loss: 0.548351, acc.: 71.09%] [G loss: 1.017503]\n",
      "epoch:8 step:7853 [D loss: 0.550213, acc.: 62.50%] [G loss: 1.954772]\n",
      "epoch:8 step:7854 [D loss: 0.628959, acc.: 64.84%] [G loss: 0.897757]\n",
      "epoch:8 step:7855 [D loss: 0.649598, acc.: 68.75%] [G loss: 0.947163]\n",
      "epoch:8 step:7856 [D loss: 0.617288, acc.: 68.75%] [G loss: 0.933689]\n",
      "epoch:8 step:7857 [D loss: 0.659149, acc.: 58.59%] [G loss: 0.853286]\n",
      "epoch:8 step:7858 [D loss: 0.772171, acc.: 39.06%] [G loss: 0.901382]\n",
      "epoch:8 step:7859 [D loss: 0.724619, acc.: 49.22%] [G loss: 0.840767]\n",
      "epoch:8 step:7860 [D loss: 0.650511, acc.: 66.41%] [G loss: 0.866045]\n",
      "epoch:8 step:7861 [D loss: 0.814121, acc.: 36.72%] [G loss: 0.842391]\n",
      "epoch:8 step:7862 [D loss: 0.756973, acc.: 38.28%] [G loss: 0.790532]\n",
      "epoch:8 step:7863 [D loss: 0.962692, acc.: 43.75%] [G loss: 0.851143]\n",
      "epoch:8 step:7864 [D loss: 0.678850, acc.: 57.81%] [G loss: 0.794626]\n",
      "epoch:8 step:7865 [D loss: 0.671629, acc.: 61.72%] [G loss: 0.778624]\n",
      "epoch:8 step:7866 [D loss: 0.639050, acc.: 62.50%] [G loss: 0.752871]\n",
      "epoch:8 step:7867 [D loss: 0.654162, acc.: 60.16%] [G loss: 0.803723]\n",
      "epoch:8 step:7868 [D loss: 0.636934, acc.: 59.38%] [G loss: 0.801299]\n",
      "epoch:8 step:7869 [D loss: 0.667121, acc.: 62.50%] [G loss: 0.810964]\n",
      "epoch:8 step:7870 [D loss: 0.633503, acc.: 62.50%] [G loss: 0.799895]\n",
      "epoch:8 step:7871 [D loss: 0.675556, acc.: 52.34%] [G loss: 0.770088]\n",
      "epoch:8 step:7872 [D loss: 0.675077, acc.: 55.47%] [G loss: 0.793659]\n",
      "epoch:8 step:7873 [D loss: 0.699142, acc.: 50.78%] [G loss: 0.722313]\n",
      "epoch:8 step:7874 [D loss: 0.649512, acc.: 61.72%] [G loss: 0.786228]\n",
      "epoch:8 step:7875 [D loss: 0.623067, acc.: 70.31%] [G loss: 0.765805]\n",
      "epoch:8 step:7876 [D loss: 0.696407, acc.: 53.91%] [G loss: 0.840181]\n",
      "epoch:8 step:7877 [D loss: 0.630786, acc.: 64.06%] [G loss: 0.795181]\n",
      "epoch:8 step:7878 [D loss: 0.684756, acc.: 52.34%] [G loss: 0.820393]\n",
      "epoch:8 step:7879 [D loss: 0.678030, acc.: 60.16%] [G loss: 0.779263]\n",
      "epoch:8 step:7880 [D loss: 0.690905, acc.: 50.00%] [G loss: 0.779638]\n",
      "epoch:8 step:7881 [D loss: 0.672059, acc.: 57.03%] [G loss: 0.781876]\n",
      "epoch:8 step:7882 [D loss: 0.690302, acc.: 57.03%] [G loss: 0.836239]\n",
      "epoch:8 step:7883 [D loss: 0.696264, acc.: 52.34%] [G loss: 0.773652]\n",
      "epoch:8 step:7884 [D loss: 0.677456, acc.: 50.78%] [G loss: 0.799195]\n",
      "epoch:8 step:7885 [D loss: 0.700281, acc.: 51.56%] [G loss: 0.766052]\n",
      "epoch:8 step:7886 [D loss: 0.708412, acc.: 46.88%] [G loss: 0.809319]\n",
      "epoch:8 step:7887 [D loss: 0.691366, acc.: 52.34%] [G loss: 0.811460]\n",
      "epoch:8 step:7888 [D loss: 0.730258, acc.: 45.31%] [G loss: 0.775429]\n",
      "epoch:8 step:7889 [D loss: 0.710585, acc.: 48.44%] [G loss: 0.805765]\n",
      "epoch:8 step:7890 [D loss: 0.694931, acc.: 55.47%] [G loss: 0.794378]\n",
      "epoch:8 step:7891 [D loss: 0.691203, acc.: 58.59%] [G loss: 0.808900]\n",
      "epoch:8 step:7892 [D loss: 0.655101, acc.: 60.94%] [G loss: 0.777092]\n",
      "epoch:8 step:7893 [D loss: 0.625218, acc.: 67.97%] [G loss: 0.784858]\n",
      "epoch:8 step:7894 [D loss: 0.647938, acc.: 65.62%] [G loss: 0.758449]\n",
      "epoch:8 step:7895 [D loss: 0.507914, acc.: 72.66%] [G loss: 0.802374]\n",
      "epoch:8 step:7896 [D loss: 0.711388, acc.: 47.66%] [G loss: 0.731583]\n",
      "epoch:8 step:7897 [D loss: 0.706633, acc.: 49.22%] [G loss: 0.813261]\n",
      "epoch:8 step:7898 [D loss: 0.654289, acc.: 63.28%] [G loss: 0.762446]\n",
      "epoch:8 step:7899 [D loss: 0.700350, acc.: 53.12%] [G loss: 0.703937]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:8 step:7900 [D loss: 0.672368, acc.: 57.03%] [G loss: 0.777990]\n",
      "epoch:8 step:7901 [D loss: 0.619486, acc.: 67.19%] [G loss: 0.682450]\n",
      "epoch:8 step:7902 [D loss: 0.634189, acc.: 67.19%] [G loss: 0.795756]\n",
      "epoch:8 step:7903 [D loss: 0.527362, acc.: 64.84%] [G loss: 0.803560]\n",
      "epoch:8 step:7904 [D loss: 0.688273, acc.: 55.47%] [G loss: 0.855973]\n",
      "epoch:8 step:7905 [D loss: 0.670195, acc.: 57.81%] [G loss: 0.423122]\n",
      "epoch:8 step:7906 [D loss: 0.680353, acc.: 54.69%] [G loss: 0.763902]\n",
      "epoch:8 step:7907 [D loss: 0.799417, acc.: 36.72%] [G loss: 0.858714]\n",
      "epoch:8 step:7908 [D loss: 0.695746, acc.: 53.12%] [G loss: 0.875022]\n",
      "epoch:8 step:7909 [D loss: 0.643087, acc.: 57.81%] [G loss: 0.857584]\n",
      "epoch:8 step:7910 [D loss: 0.627783, acc.: 65.62%] [G loss: 0.876195]\n",
      "epoch:8 step:7911 [D loss: 0.672575, acc.: 60.16%] [G loss: 0.857590]\n",
      "epoch:8 step:7912 [D loss: 0.695522, acc.: 58.59%] [G loss: 0.891613]\n",
      "epoch:8 step:7913 [D loss: 0.641574, acc.: 64.06%] [G loss: 1.026080]\n",
      "epoch:8 step:7914 [D loss: 0.708012, acc.: 50.00%] [G loss: 0.886093]\n",
      "epoch:8 step:7915 [D loss: 0.556750, acc.: 66.41%] [G loss: 1.035687]\n",
      "epoch:8 step:7916 [D loss: 0.692641, acc.: 50.78%] [G loss: 0.905539]\n",
      "epoch:8 step:7917 [D loss: 0.696296, acc.: 51.56%] [G loss: 0.933924]\n",
      "epoch:8 step:7918 [D loss: 0.713983, acc.: 46.09%] [G loss: 0.941930]\n",
      "epoch:8 step:7919 [D loss: 0.710856, acc.: 52.34%] [G loss: 0.852242]\n",
      "epoch:8 step:7920 [D loss: 0.695773, acc.: 50.00%] [G loss: 0.874525]\n",
      "epoch:8 step:7921 [D loss: 0.684559, acc.: 57.81%] [G loss: 0.851813]\n",
      "epoch:8 step:7922 [D loss: 0.645135, acc.: 64.06%] [G loss: 0.819050]\n",
      "epoch:8 step:7923 [D loss: 0.597901, acc.: 64.84%] [G loss: 0.880902]\n",
      "epoch:8 step:7924 [D loss: 0.524498, acc.: 74.22%] [G loss: 0.774975]\n",
      "epoch:8 step:7925 [D loss: 0.521321, acc.: 67.97%] [G loss: 0.902657]\n",
      "epoch:8 step:7926 [D loss: 0.831197, acc.: 56.25%] [G loss: 0.970141]\n",
      "epoch:8 step:7927 [D loss: 0.681064, acc.: 55.47%] [G loss: 1.058175]\n",
      "epoch:8 step:7928 [D loss: 0.710690, acc.: 52.34%] [G loss: 1.058823]\n",
      "epoch:8 step:7929 [D loss: 0.706584, acc.: 53.91%] [G loss: 0.910465]\n",
      "epoch:8 step:7930 [D loss: 0.653337, acc.: 62.50%] [G loss: 0.957657]\n",
      "epoch:8 step:7931 [D loss: 0.678008, acc.: 57.03%] [G loss: 0.919247]\n",
      "epoch:8 step:7932 [D loss: 0.676533, acc.: 64.84%] [G loss: 0.896682]\n",
      "epoch:8 step:7933 [D loss: 0.727624, acc.: 46.09%] [G loss: 0.797017]\n",
      "epoch:8 step:7934 [D loss: 0.710054, acc.: 53.12%] [G loss: 0.834745]\n",
      "epoch:8 step:7935 [D loss: 0.673742, acc.: 54.69%] [G loss: 0.871728]\n",
      "epoch:8 step:7936 [D loss: 0.651909, acc.: 64.84%] [G loss: 0.941738]\n",
      "epoch:8 step:7937 [D loss: 0.639839, acc.: 63.28%] [G loss: 0.859663]\n",
      "epoch:8 step:7938 [D loss: 0.644359, acc.: 66.41%] [G loss: 0.832241]\n",
      "epoch:8 step:7939 [D loss: 0.645040, acc.: 62.50%] [G loss: 0.890222]\n",
      "epoch:8 step:7940 [D loss: 0.648024, acc.: 62.50%] [G loss: 0.846956]\n",
      "epoch:8 step:7941 [D loss: 0.673736, acc.: 63.28%] [G loss: 0.796793]\n",
      "epoch:8 step:7942 [D loss: 0.640104, acc.: 64.84%] [G loss: 0.803336]\n",
      "epoch:8 step:7943 [D loss: 0.649811, acc.: 58.59%] [G loss: 0.785250]\n",
      "epoch:8 step:7944 [D loss: 0.729693, acc.: 46.09%] [G loss: 0.814126]\n",
      "epoch:8 step:7945 [D loss: 0.704427, acc.: 51.56%] [G loss: 0.730236]\n",
      "epoch:8 step:7946 [D loss: 0.664201, acc.: 60.94%] [G loss: 0.806399]\n",
      "epoch:8 step:7947 [D loss: 0.691982, acc.: 54.69%] [G loss: 0.872319]\n",
      "epoch:8 step:7948 [D loss: 0.668707, acc.: 53.91%] [G loss: 0.943505]\n",
      "epoch:8 step:7949 [D loss: 0.635687, acc.: 61.72%] [G loss: 0.868824]\n",
      "epoch:8 step:7950 [D loss: 0.639349, acc.: 65.62%] [G loss: 0.915489]\n",
      "epoch:8 step:7951 [D loss: 0.640776, acc.: 60.16%] [G loss: 0.933685]\n",
      "epoch:8 step:7952 [D loss: 0.638571, acc.: 63.28%] [G loss: 0.892016]\n",
      "epoch:8 step:7953 [D loss: 0.645143, acc.: 62.50%] [G loss: 0.885309]\n",
      "epoch:8 step:7954 [D loss: 0.756127, acc.: 49.22%] [G loss: 0.771211]\n",
      "epoch:8 step:7955 [D loss: 0.721752, acc.: 55.47%] [G loss: 0.812756]\n",
      "epoch:8 step:7956 [D loss: 0.677235, acc.: 53.91%] [G loss: 0.771425]\n",
      "epoch:8 step:7957 [D loss: 0.733560, acc.: 56.25%] [G loss: 0.725231]\n",
      "epoch:8 step:7958 [D loss: 0.739182, acc.: 42.97%] [G loss: 0.798903]\n",
      "epoch:8 step:7959 [D loss: 0.681694, acc.: 50.78%] [G loss: 0.847375]\n",
      "epoch:8 step:7960 [D loss: 0.681424, acc.: 59.38%] [G loss: 0.860661]\n",
      "epoch:8 step:7961 [D loss: 0.681198, acc.: 53.91%] [G loss: 0.764542]\n",
      "epoch:8 step:7962 [D loss: 0.691401, acc.: 54.69%] [G loss: 0.804163]\n",
      "epoch:8 step:7963 [D loss: 0.644956, acc.: 62.50%] [G loss: 0.819588]\n",
      "epoch:8 step:7964 [D loss: 0.673179, acc.: 62.50%] [G loss: 0.826202]\n",
      "epoch:8 step:7965 [D loss: 0.660949, acc.: 62.50%] [G loss: 0.827475]\n",
      "epoch:8 step:7966 [D loss: 0.634450, acc.: 65.62%] [G loss: 0.806564]\n",
      "epoch:8 step:7967 [D loss: 0.673906, acc.: 59.38%] [G loss: 0.854478]\n",
      "epoch:8 step:7968 [D loss: 0.684618, acc.: 57.81%] [G loss: 0.826965]\n",
      "epoch:8 step:7969 [D loss: 0.739466, acc.: 45.31%] [G loss: 0.762683]\n",
      "epoch:8 step:7970 [D loss: 0.714352, acc.: 42.97%] [G loss: 0.794316]\n",
      "epoch:8 step:7971 [D loss: 0.678307, acc.: 60.94%] [G loss: 0.790790]\n",
      "epoch:8 step:7972 [D loss: 0.666786, acc.: 63.28%] [G loss: 0.783288]\n",
      "epoch:8 step:7973 [D loss: 0.683599, acc.: 54.69%] [G loss: 0.802744]\n",
      "epoch:8 step:7974 [D loss: 0.704836, acc.: 54.69%] [G loss: 0.790064]\n",
      "epoch:8 step:7975 [D loss: 0.684721, acc.: 58.59%] [G loss: 0.796827]\n",
      "epoch:8 step:7976 [D loss: 0.669816, acc.: 63.28%] [G loss: 0.783651]\n",
      "epoch:8 step:7977 [D loss: 0.646423, acc.: 63.28%] [G loss: 0.766219]\n",
      "epoch:8 step:7978 [D loss: 0.692916, acc.: 50.78%] [G loss: 0.776901]\n",
      "epoch:8 step:7979 [D loss: 0.694547, acc.: 53.91%] [G loss: 0.811154]\n",
      "epoch:8 step:7980 [D loss: 0.652602, acc.: 64.06%] [G loss: 0.797668]\n",
      "epoch:8 step:7981 [D loss: 0.631667, acc.: 67.19%] [G loss: 0.851681]\n",
      "epoch:8 step:7982 [D loss: 0.682177, acc.: 54.69%] [G loss: 0.812099]\n",
      "epoch:8 step:7983 [D loss: 0.650454, acc.: 60.94%] [G loss: 0.791111]\n",
      "epoch:8 step:7984 [D loss: 0.649076, acc.: 59.38%] [G loss: 0.779590]\n",
      "epoch:8 step:7985 [D loss: 0.710111, acc.: 50.78%] [G loss: 0.795407]\n",
      "epoch:8 step:7986 [D loss: 0.687089, acc.: 50.00%] [G loss: 0.838428]\n",
      "epoch:8 step:7987 [D loss: 0.694122, acc.: 53.12%] [G loss: 0.750058]\n",
      "epoch:8 step:7988 [D loss: 0.695815, acc.: 50.78%] [G loss: 0.774935]\n",
      "epoch:8 step:7989 [D loss: 0.714633, acc.: 45.31%] [G loss: 0.757444]\n",
      "epoch:8 step:7990 [D loss: 0.709774, acc.: 52.34%] [G loss: 0.784816]\n",
      "epoch:8 step:7991 [D loss: 0.682923, acc.: 51.56%] [G loss: 0.763189]\n",
      "epoch:8 step:7992 [D loss: 0.693594, acc.: 51.56%] [G loss: 0.803817]\n",
      "epoch:8 step:7993 [D loss: 0.647856, acc.: 67.19%] [G loss: 0.783953]\n",
      "epoch:8 step:7994 [D loss: 0.568159, acc.: 70.31%] [G loss: 0.853349]\n",
      "epoch:8 step:7995 [D loss: 0.441864, acc.: 81.25%] [G loss: 0.947847]\n",
      "epoch:8 step:7996 [D loss: 0.655107, acc.: 60.94%] [G loss: 0.919745]\n",
      "epoch:8 step:7997 [D loss: 0.700243, acc.: 53.91%] [G loss: 1.039877]\n",
      "epoch:8 step:7998 [D loss: 0.636804, acc.: 66.41%] [G loss: 0.870767]\n",
      "epoch:8 step:7999 [D loss: 0.699648, acc.: 52.34%] [G loss: 0.857178]\n",
      "epoch:8 step:8000 [D loss: 0.654536, acc.: 60.94%] [G loss: 0.890907]\n",
      "##############\n",
      "[4.08751851 2.334997   6.53133584 5.82906682 4.83828632 5.87323318\n",
      " 5.09217423 5.52141324 5.42486566 4.72077585]\n",
      "##########\n",
      "epoch:8 step:8001 [D loss: 0.674318, acc.: 56.25%] [G loss: 0.945758]\n",
      "epoch:8 step:8002 [D loss: 0.693392, acc.: 50.78%] [G loss: 0.910187]\n",
      "epoch:8 step:8003 [D loss: 0.702064, acc.: 57.81%] [G loss: 0.816444]\n",
      "epoch:8 step:8004 [D loss: 0.650121, acc.: 62.50%] [G loss: 0.790744]\n",
      "epoch:8 step:8005 [D loss: 0.688002, acc.: 64.06%] [G loss: 0.886880]\n",
      "epoch:8 step:8006 [D loss: 0.704654, acc.: 49.22%] [G loss: 0.835846]\n",
      "epoch:8 step:8007 [D loss: 0.698369, acc.: 52.34%] [G loss: 0.846245]\n",
      "epoch:8 step:8008 [D loss: 0.576030, acc.: 75.00%] [G loss: 0.956443]\n",
      "epoch:8 step:8009 [D loss: 0.499820, acc.: 80.47%] [G loss: 0.915640]\n",
      "epoch:8 step:8010 [D loss: 0.656399, acc.: 64.84%] [G loss: 0.886403]\n",
      "epoch:8 step:8011 [D loss: 0.618478, acc.: 64.84%] [G loss: 0.917583]\n",
      "epoch:8 step:8012 [D loss: 0.615228, acc.: 63.28%] [G loss: 0.892386]\n",
      "epoch:8 step:8013 [D loss: 0.726903, acc.: 48.44%] [G loss: 0.740577]\n",
      "epoch:8 step:8014 [D loss: 0.687854, acc.: 54.69%] [G loss: 0.766434]\n",
      "epoch:8 step:8015 [D loss: 0.673722, acc.: 56.25%] [G loss: 0.798721]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:8 step:8016 [D loss: 0.647894, acc.: 63.28%] [G loss: 0.758896]\n",
      "epoch:8 step:8017 [D loss: 0.684557, acc.: 55.47%] [G loss: 0.716022]\n",
      "epoch:8 step:8018 [D loss: 0.659289, acc.: 61.72%] [G loss: 0.790920]\n",
      "epoch:8 step:8019 [D loss: 0.682001, acc.: 58.59%] [G loss: 0.797881]\n",
      "epoch:8 step:8020 [D loss: 0.683589, acc.: 55.47%] [G loss: 0.825310]\n",
      "epoch:8 step:8021 [D loss: 0.673956, acc.: 62.50%] [G loss: 0.797962]\n",
      "epoch:8 step:8022 [D loss: 0.684310, acc.: 57.03%] [G loss: 0.848330]\n",
      "epoch:8 step:8023 [D loss: 0.700631, acc.: 52.34%] [G loss: 0.920725]\n",
      "epoch:8 step:8024 [D loss: 0.678567, acc.: 64.06%] [G loss: 0.944453]\n",
      "epoch:8 step:8025 [D loss: 0.660217, acc.: 60.16%] [G loss: 0.933745]\n",
      "epoch:8 step:8026 [D loss: 0.637553, acc.: 60.16%] [G loss: 0.906778]\n",
      "epoch:8 step:8027 [D loss: 0.665130, acc.: 55.47%] [G loss: 0.935432]\n",
      "epoch:8 step:8028 [D loss: 0.674553, acc.: 56.25%] [G loss: 0.876824]\n",
      "epoch:8 step:8029 [D loss: 0.650118, acc.: 60.94%] [G loss: 0.791766]\n",
      "epoch:8 step:8030 [D loss: 0.686346, acc.: 58.59%] [G loss: 0.838956]\n",
      "epoch:8 step:8031 [D loss: 0.717667, acc.: 48.44%] [G loss: 0.779956]\n",
      "epoch:8 step:8032 [D loss: 0.651671, acc.: 63.28%] [G loss: 0.764257]\n",
      "epoch:8 step:8033 [D loss: 0.711286, acc.: 53.91%] [G loss: 0.769930]\n",
      "epoch:8 step:8034 [D loss: 0.712395, acc.: 53.12%] [G loss: 0.846445]\n",
      "epoch:8 step:8035 [D loss: 0.693965, acc.: 53.91%] [G loss: 0.707990]\n",
      "epoch:8 step:8036 [D loss: 0.691579, acc.: 53.12%] [G loss: 0.885754]\n",
      "epoch:8 step:8037 [D loss: 0.622503, acc.: 65.62%] [G loss: 0.773179]\n",
      "epoch:8 step:8038 [D loss: 0.704851, acc.: 55.47%] [G loss: 0.840230]\n",
      "epoch:8 step:8039 [D loss: 0.665504, acc.: 59.38%] [G loss: 0.797203]\n",
      "epoch:8 step:8040 [D loss: 0.712701, acc.: 50.78%] [G loss: 0.864521]\n",
      "epoch:8 step:8041 [D loss: 0.635381, acc.: 70.31%] [G loss: 0.871437]\n",
      "epoch:8 step:8042 [D loss: 0.619395, acc.: 74.22%] [G loss: 1.012182]\n",
      "epoch:8 step:8043 [D loss: 0.665830, acc.: 62.50%] [G loss: 0.942964]\n",
      "epoch:8 step:8044 [D loss: 0.674465, acc.: 58.59%] [G loss: 0.936660]\n",
      "epoch:8 step:8045 [D loss: 0.616493, acc.: 66.41%] [G loss: 0.903503]\n",
      "epoch:8 step:8046 [D loss: 0.615820, acc.: 72.66%] [G loss: 0.888028]\n",
      "epoch:8 step:8047 [D loss: 0.677478, acc.: 57.81%] [G loss: 0.874830]\n",
      "epoch:8 step:8048 [D loss: 0.672269, acc.: 58.59%] [G loss: 0.818471]\n",
      "epoch:8 step:8049 [D loss: 0.732659, acc.: 50.78%] [G loss: 0.796292]\n",
      "epoch:8 step:8050 [D loss: 0.635099, acc.: 60.16%] [G loss: 0.840118]\n",
      "epoch:8 step:8051 [D loss: 0.665730, acc.: 59.38%] [G loss: 0.911866]\n",
      "epoch:8 step:8052 [D loss: 0.671697, acc.: 56.25%] [G loss: 0.862038]\n",
      "epoch:8 step:8053 [D loss: 0.635173, acc.: 60.94%] [G loss: 1.008923]\n",
      "epoch:8 step:8054 [D loss: 0.679856, acc.: 60.16%] [G loss: 0.817972]\n",
      "epoch:8 step:8055 [D loss: 0.728487, acc.: 56.25%] [G loss: 0.963025]\n",
      "epoch:8 step:8056 [D loss: 0.721328, acc.: 56.25%] [G loss: 0.917984]\n",
      "epoch:8 step:8057 [D loss: 0.655986, acc.: 60.94%] [G loss: 0.816102]\n",
      "epoch:8 step:8058 [D loss: 0.700827, acc.: 50.78%] [G loss: 0.872222]\n",
      "epoch:8 step:8059 [D loss: 0.682055, acc.: 57.81%] [G loss: 0.838252]\n",
      "epoch:8 step:8060 [D loss: 0.648560, acc.: 59.38%] [G loss: 0.844838]\n",
      "epoch:8 step:8061 [D loss: 0.619845, acc.: 64.84%] [G loss: 0.841297]\n",
      "epoch:8 step:8062 [D loss: 0.415652, acc.: 85.16%] [G loss: 0.946121]\n",
      "epoch:8 step:8063 [D loss: 0.526379, acc.: 74.22%] [G loss: 0.963432]\n",
      "epoch:8 step:8064 [D loss: 0.521671, acc.: 82.81%] [G loss: 1.029901]\n",
      "epoch:8 step:8065 [D loss: 0.619286, acc.: 64.84%] [G loss: 0.832147]\n",
      "epoch:8 step:8066 [D loss: 0.597817, acc.: 61.72%] [G loss: 0.727860]\n",
      "epoch:8 step:8067 [D loss: 0.664268, acc.: 63.28%] [G loss: 0.654458]\n",
      "epoch:8 step:8068 [D loss: 0.728920, acc.: 50.00%] [G loss: 0.870959]\n",
      "epoch:8 step:8069 [D loss: 1.296646, acc.: 34.38%] [G loss: 0.938791]\n",
      "epoch:8 step:8070 [D loss: 0.647198, acc.: 63.28%] [G loss: 1.064643]\n",
      "epoch:8 step:8071 [D loss: 0.675626, acc.: 58.59%] [G loss: 1.041152]\n",
      "epoch:8 step:8072 [D loss: 0.757460, acc.: 49.22%] [G loss: 1.148235]\n",
      "epoch:8 step:8073 [D loss: 0.726644, acc.: 48.44%] [G loss: 0.912318]\n",
      "epoch:8 step:8074 [D loss: 0.740294, acc.: 47.66%] [G loss: 0.851172]\n",
      "epoch:8 step:8075 [D loss: 0.736537, acc.: 41.41%] [G loss: 0.811432]\n",
      "epoch:8 step:8076 [D loss: 0.718946, acc.: 56.25%] [G loss: 0.886476]\n",
      "epoch:8 step:8077 [D loss: 0.660922, acc.: 59.38%] [G loss: 0.854013]\n",
      "epoch:8 step:8078 [D loss: 0.628539, acc.: 67.97%] [G loss: 0.867352]\n",
      "epoch:8 step:8079 [D loss: 0.709103, acc.: 50.78%] [G loss: 0.895192]\n",
      "epoch:8 step:8080 [D loss: 0.655710, acc.: 60.16%] [G loss: 0.880844]\n",
      "epoch:8 step:8081 [D loss: 0.703631, acc.: 57.03%] [G loss: 0.963381]\n",
      "epoch:8 step:8082 [D loss: 0.622502, acc.: 67.97%] [G loss: 0.997034]\n",
      "epoch:8 step:8083 [D loss: 0.688529, acc.: 66.41%] [G loss: 0.940289]\n",
      "epoch:8 step:8084 [D loss: 0.641243, acc.: 63.28%] [G loss: 0.810733]\n",
      "epoch:8 step:8085 [D loss: 0.549476, acc.: 69.53%] [G loss: 0.767467]\n",
      "epoch:8 step:8086 [D loss: 0.698175, acc.: 56.25%] [G loss: 0.854007]\n",
      "epoch:8 step:8087 [D loss: 0.676936, acc.: 58.59%] [G loss: 0.896711]\n",
      "epoch:8 step:8088 [D loss: 0.738907, acc.: 51.56%] [G loss: 0.812081]\n",
      "epoch:8 step:8089 [D loss: 0.702296, acc.: 55.47%] [G loss: 0.746469]\n",
      "epoch:8 step:8090 [D loss: 0.769570, acc.: 41.41%] [G loss: 0.794006]\n",
      "epoch:8 step:8091 [D loss: 0.667059, acc.: 56.25%] [G loss: 0.825467]\n",
      "epoch:8 step:8092 [D loss: 0.691848, acc.: 49.22%] [G loss: 0.842032]\n",
      "epoch:8 step:8093 [D loss: 0.691646, acc.: 56.25%] [G loss: 0.856137]\n",
      "epoch:8 step:8094 [D loss: 0.665166, acc.: 62.50%] [G loss: 0.883035]\n",
      "epoch:8 step:8095 [D loss: 0.675417, acc.: 52.34%] [G loss: 0.811831]\n",
      "epoch:8 step:8096 [D loss: 0.605710, acc.: 66.41%] [G loss: 0.850423]\n",
      "epoch:8 step:8097 [D loss: 0.679483, acc.: 57.03%] [G loss: 0.874434]\n",
      "epoch:8 step:8098 [D loss: 0.737623, acc.: 50.78%] [G loss: 0.832009]\n",
      "epoch:8 step:8099 [D loss: 0.717301, acc.: 47.66%] [G loss: 0.836706]\n",
      "epoch:8 step:8100 [D loss: 0.661273, acc.: 60.94%] [G loss: 0.823786]\n",
      "epoch:8 step:8101 [D loss: 0.628963, acc.: 68.75%] [G loss: 0.808911]\n",
      "epoch:8 step:8102 [D loss: 0.706397, acc.: 46.09%] [G loss: 0.824615]\n",
      "epoch:8 step:8103 [D loss: 0.723429, acc.: 48.44%] [G loss: 0.605330]\n",
      "epoch:8 step:8104 [D loss: 0.688712, acc.: 50.78%] [G loss: 0.834912]\n",
      "epoch:8 step:8105 [D loss: 0.667916, acc.: 57.81%] [G loss: 0.726283]\n",
      "epoch:8 step:8106 [D loss: 0.674728, acc.: 60.94%] [G loss: 0.631629]\n",
      "epoch:8 step:8107 [D loss: 0.849139, acc.: 40.62%] [G loss: 0.895652]\n",
      "epoch:8 step:8108 [D loss: 0.654615, acc.: 58.59%] [G loss: 0.952675]\n",
      "epoch:8 step:8109 [D loss: 0.627357, acc.: 65.62%] [G loss: 0.916869]\n",
      "epoch:8 step:8110 [D loss: 0.620333, acc.: 64.84%] [G loss: 0.929205]\n",
      "epoch:8 step:8111 [D loss: 0.623412, acc.: 55.47%] [G loss: 0.964947]\n",
      "epoch:8 step:8112 [D loss: 0.654800, acc.: 64.06%] [G loss: 0.877168]\n",
      "epoch:8 step:8113 [D loss: 0.612568, acc.: 60.94%] [G loss: 1.039798]\n",
      "epoch:8 step:8114 [D loss: 0.632647, acc.: 57.81%] [G loss: 1.351411]\n",
      "epoch:8 step:8115 [D loss: 0.688601, acc.: 57.03%] [G loss: 0.961508]\n",
      "epoch:8 step:8116 [D loss: 0.693849, acc.: 52.34%] [G loss: 0.808241]\n",
      "epoch:8 step:8117 [D loss: 0.724976, acc.: 48.44%] [G loss: 0.811084]\n",
      "epoch:8 step:8118 [D loss: 0.750658, acc.: 39.06%] [G loss: 0.830135]\n",
      "epoch:8 step:8119 [D loss: 0.692048, acc.: 57.03%] [G loss: 0.861000]\n",
      "epoch:8 step:8120 [D loss: 0.601029, acc.: 73.44%] [G loss: 0.952965]\n",
      "epoch:8 step:8121 [D loss: 0.662651, acc.: 57.81%] [G loss: 0.912631]\n",
      "epoch:8 step:8122 [D loss: 0.672699, acc.: 61.72%] [G loss: 0.863743]\n",
      "epoch:8 step:8123 [D loss: 0.639150, acc.: 61.72%] [G loss: 0.828462]\n",
      "epoch:8 step:8124 [D loss: 0.666092, acc.: 62.50%] [G loss: 0.897604]\n",
      "epoch:8 step:8125 [D loss: 0.676604, acc.: 55.47%] [G loss: 0.840460]\n",
      "epoch:8 step:8126 [D loss: 0.657193, acc.: 66.41%] [G loss: 0.824660]\n",
      "epoch:8 step:8127 [D loss: 0.666677, acc.: 60.94%] [G loss: 0.828687]\n",
      "epoch:8 step:8128 [D loss: 0.686337, acc.: 56.25%] [G loss: 0.788715]\n",
      "epoch:8 step:8129 [D loss: 0.644650, acc.: 60.94%] [G loss: 0.845129]\n",
      "epoch:8 step:8130 [D loss: 0.639573, acc.: 60.94%] [G loss: 0.882411]\n",
      "epoch:8 step:8131 [D loss: 0.798330, acc.: 46.09%] [G loss: 0.841269]\n",
      "epoch:8 step:8132 [D loss: 0.658651, acc.: 60.94%] [G loss: 0.877874]\n",
      "epoch:8 step:8133 [D loss: 0.642672, acc.: 67.19%] [G loss: 0.889152]\n",
      "epoch:8 step:8134 [D loss: 0.651290, acc.: 60.94%] [G loss: 0.945521]\n",
      "epoch:8 step:8135 [D loss: 0.641553, acc.: 59.38%] [G loss: 0.824971]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:8 step:8136 [D loss: 0.678225, acc.: 57.81%] [G loss: 0.854958]\n",
      "epoch:8 step:8137 [D loss: 0.672138, acc.: 60.16%] [G loss: 1.025971]\n",
      "epoch:8 step:8138 [D loss: 0.597723, acc.: 69.53%] [G loss: 1.046982]\n",
      "epoch:8 step:8139 [D loss: 0.701785, acc.: 53.12%] [G loss: 0.825772]\n",
      "epoch:8 step:8140 [D loss: 0.677634, acc.: 57.81%] [G loss: 0.817999]\n",
      "epoch:8 step:8141 [D loss: 0.741451, acc.: 44.53%] [G loss: 0.784190]\n",
      "epoch:8 step:8142 [D loss: 0.729140, acc.: 46.88%] [G loss: 0.728052]\n",
      "epoch:8 step:8143 [D loss: 0.726360, acc.: 47.66%] [G loss: 0.777735]\n",
      "epoch:8 step:8144 [D loss: 0.630958, acc.: 66.41%] [G loss: 0.933602]\n",
      "epoch:8 step:8145 [D loss: 0.647745, acc.: 62.50%] [G loss: 0.919540]\n",
      "epoch:8 step:8146 [D loss: 0.662019, acc.: 58.59%] [G loss: 0.836967]\n",
      "epoch:8 step:8147 [D loss: 0.648643, acc.: 56.25%] [G loss: 0.889826]\n",
      "epoch:8 step:8148 [D loss: 0.670048, acc.: 64.84%] [G loss: 0.860291]\n",
      "epoch:8 step:8149 [D loss: 0.700458, acc.: 55.47%] [G loss: 0.795177]\n",
      "epoch:8 step:8150 [D loss: 0.723295, acc.: 49.22%] [G loss: 0.817973]\n",
      "epoch:8 step:8151 [D loss: 0.761992, acc.: 42.97%] [G loss: 0.719100]\n",
      "epoch:8 step:8152 [D loss: 0.679035, acc.: 58.59%] [G loss: 0.802757]\n",
      "epoch:8 step:8153 [D loss: 0.733703, acc.: 47.66%] [G loss: 0.745019]\n",
      "epoch:8 step:8154 [D loss: 0.709018, acc.: 52.34%] [G loss: 0.768255]\n",
      "epoch:8 step:8155 [D loss: 0.671927, acc.: 58.59%] [G loss: 0.802219]\n",
      "epoch:8 step:8156 [D loss: 0.647584, acc.: 62.50%] [G loss: 0.925738]\n",
      "epoch:8 step:8157 [D loss: 0.652219, acc.: 60.94%] [G loss: 0.834302]\n",
      "epoch:8 step:8158 [D loss: 0.675531, acc.: 54.69%] [G loss: 0.852562]\n",
      "epoch:8 step:8159 [D loss: 0.536579, acc.: 73.44%] [G loss: 0.886403]\n",
      "epoch:8 step:8160 [D loss: 0.545544, acc.: 80.47%] [G loss: 0.860208]\n",
      "epoch:8 step:8161 [D loss: 0.607347, acc.: 67.97%] [G loss: 0.922492]\n",
      "epoch:8 step:8162 [D loss: 0.680559, acc.: 63.28%] [G loss: 0.875563]\n",
      "epoch:8 step:8163 [D loss: 0.656600, acc.: 60.94%] [G loss: 0.828315]\n",
      "epoch:8 step:8164 [D loss: 0.563141, acc.: 70.31%] [G loss: 0.872222]\n",
      "epoch:8 step:8165 [D loss: 0.632782, acc.: 63.28%] [G loss: 0.799495]\n",
      "epoch:8 step:8166 [D loss: 0.581359, acc.: 54.69%] [G loss: 0.846866]\n",
      "epoch:8 step:8167 [D loss: 0.624082, acc.: 71.88%] [G loss: 0.601265]\n",
      "epoch:8 step:8168 [D loss: 0.693655, acc.: 58.59%] [G loss: 0.804570]\n",
      "epoch:8 step:8169 [D loss: 0.707856, acc.: 53.12%] [G loss: 0.759529]\n",
      "epoch:8 step:8170 [D loss: 0.668728, acc.: 60.16%] [G loss: 0.746611]\n",
      "epoch:8 step:8171 [D loss: 0.708273, acc.: 51.56%] [G loss: 0.779658]\n",
      "epoch:8 step:8172 [D loss: 0.697813, acc.: 51.56%] [G loss: 0.810325]\n",
      "epoch:8 step:8173 [D loss: 0.825737, acc.: 42.19%] [G loss: 0.885636]\n",
      "epoch:8 step:8174 [D loss: 0.689941, acc.: 51.56%] [G loss: 0.889202]\n",
      "epoch:8 step:8175 [D loss: 0.686704, acc.: 53.12%] [G loss: 0.883898]\n",
      "epoch:8 step:8176 [D loss: 0.632558, acc.: 63.28%] [G loss: 0.898393]\n",
      "epoch:8 step:8177 [D loss: 0.667409, acc.: 53.12%] [G loss: 0.831159]\n",
      "epoch:8 step:8178 [D loss: 0.711073, acc.: 46.09%] [G loss: 0.835978]\n",
      "epoch:8 step:8179 [D loss: 0.706738, acc.: 50.00%] [G loss: 0.805619]\n",
      "epoch:8 step:8180 [D loss: 0.684427, acc.: 60.16%] [G loss: 0.817007]\n",
      "epoch:8 step:8181 [D loss: 0.708077, acc.: 50.78%] [G loss: 0.787566]\n",
      "epoch:8 step:8182 [D loss: 0.696704, acc.: 51.56%] [G loss: 0.839091]\n",
      "epoch:8 step:8183 [D loss: 0.715964, acc.: 54.69%] [G loss: 0.871864]\n",
      "epoch:8 step:8184 [D loss: 0.658606, acc.: 60.16%] [G loss: 0.786392]\n",
      "epoch:8 step:8185 [D loss: 0.678742, acc.: 54.69%] [G loss: 0.724710]\n",
      "epoch:8 step:8186 [D loss: 0.680946, acc.: 56.25%] [G loss: 0.786482]\n",
      "epoch:8 step:8187 [D loss: 0.689016, acc.: 59.38%] [G loss: 0.779315]\n",
      "epoch:8 step:8188 [D loss: 0.664553, acc.: 65.62%] [G loss: 0.751648]\n",
      "epoch:8 step:8189 [D loss: 0.679102, acc.: 58.59%] [G loss: 0.816580]\n",
      "epoch:8 step:8190 [D loss: 0.867215, acc.: 42.19%] [G loss: 0.899730]\n",
      "epoch:8 step:8191 [D loss: 0.736865, acc.: 49.22%] [G loss: 0.806681]\n",
      "epoch:8 step:8192 [D loss: 0.722165, acc.: 53.91%] [G loss: 0.854058]\n",
      "epoch:8 step:8193 [D loss: 0.713171, acc.: 47.66%] [G loss: 0.787213]\n",
      "epoch:8 step:8194 [D loss: 0.688103, acc.: 49.22%] [G loss: 0.797090]\n",
      "epoch:8 step:8195 [D loss: 0.679822, acc.: 57.81%] [G loss: 0.786505]\n",
      "epoch:8 step:8196 [D loss: 0.618503, acc.: 69.53%] [G loss: 0.829491]\n",
      "epoch:8 step:8197 [D loss: 0.624404, acc.: 65.62%] [G loss: 0.846787]\n",
      "epoch:8 step:8198 [D loss: 0.632630, acc.: 64.06%] [G loss: 0.848726]\n",
      "epoch:8 step:8199 [D loss: 0.641310, acc.: 63.28%] [G loss: 0.804695]\n",
      "epoch:8 step:8200 [D loss: 0.678899, acc.: 57.81%] [G loss: 0.884061]\n",
      "##############\n",
      "[3.92309565 2.30380397 6.26750348 5.54677536 4.11268999 6.00608137\n",
      " 5.30085105 5.2710236  5.7029207  4.77670224]\n",
      "##########\n",
      "epoch:8 step:8201 [D loss: 0.657163, acc.: 59.38%] [G loss: 0.832138]\n",
      "epoch:8 step:8202 [D loss: 0.510019, acc.: 75.00%] [G loss: 0.806676]\n",
      "epoch:8 step:8203 [D loss: 0.457753, acc.: 75.00%] [G loss: 0.918183]\n",
      "epoch:8 step:8204 [D loss: 0.540584, acc.: 77.34%] [G loss: 0.960647]\n",
      "epoch:8 step:8205 [D loss: 0.559797, acc.: 77.34%] [G loss: 0.828513]\n",
      "epoch:8 step:8206 [D loss: 0.768068, acc.: 44.53%] [G loss: 0.745550]\n",
      "epoch:8 step:8207 [D loss: 0.752048, acc.: 42.97%] [G loss: 0.720032]\n",
      "epoch:8 step:8208 [D loss: 0.644200, acc.: 60.94%] [G loss: 0.753206]\n",
      "epoch:8 step:8209 [D loss: 0.547825, acc.: 62.50%] [G loss: 0.777186]\n",
      "epoch:8 step:8210 [D loss: 0.478851, acc.: 72.66%] [G loss: 0.857362]\n",
      "epoch:8 step:8211 [D loss: 0.745962, acc.: 47.66%] [G loss: 0.706348]\n",
      "epoch:8 step:8212 [D loss: 0.931782, acc.: 26.56%] [G loss: 0.918853]\n",
      "epoch:8 step:8213 [D loss: 0.719774, acc.: 50.00%] [G loss: 0.901655]\n",
      "epoch:8 step:8214 [D loss: 0.720996, acc.: 52.34%] [G loss: 0.895601]\n",
      "epoch:8 step:8215 [D loss: 0.706405, acc.: 50.78%] [G loss: 0.892118]\n",
      "epoch:8 step:8216 [D loss: 0.694517, acc.: 51.56%] [G loss: 0.870845]\n",
      "epoch:8 step:8217 [D loss: 0.723793, acc.: 47.66%] [G loss: 0.821430]\n",
      "epoch:8 step:8218 [D loss: 0.699643, acc.: 54.69%] [G loss: 0.918353]\n",
      "epoch:8 step:8219 [D loss: 0.648551, acc.: 62.50%] [G loss: 0.969000]\n",
      "epoch:8 step:8220 [D loss: 0.667818, acc.: 59.38%] [G loss: 1.014408]\n",
      "epoch:8 step:8221 [D loss: 0.644246, acc.: 62.50%] [G loss: 0.965624]\n",
      "epoch:8 step:8222 [D loss: 0.655192, acc.: 60.94%] [G loss: 0.983100]\n",
      "epoch:8 step:8223 [D loss: 0.699521, acc.: 52.34%] [G loss: 0.862192]\n",
      "epoch:8 step:8224 [D loss: 0.750459, acc.: 47.66%] [G loss: 0.783863]\n",
      "epoch:8 step:8225 [D loss: 0.697182, acc.: 53.12%] [G loss: 0.836550]\n",
      "epoch:8 step:8226 [D loss: 0.649517, acc.: 64.06%] [G loss: 0.798998]\n",
      "epoch:8 step:8227 [D loss: 0.780762, acc.: 47.66%] [G loss: 0.781145]\n",
      "epoch:8 step:8228 [D loss: 0.670662, acc.: 54.69%] [G loss: 0.788764]\n",
      "epoch:8 step:8229 [D loss: 0.659231, acc.: 58.59%] [G loss: 0.778916]\n",
      "epoch:8 step:8230 [D loss: 0.701219, acc.: 51.56%] [G loss: 0.800150]\n",
      "epoch:8 step:8231 [D loss: 0.706356, acc.: 53.91%] [G loss: 0.782560]\n",
      "epoch:8 step:8232 [D loss: 0.650975, acc.: 64.06%] [G loss: 0.848185]\n",
      "epoch:8 step:8233 [D loss: 0.676344, acc.: 53.91%] [G loss: 0.826127]\n",
      "epoch:8 step:8234 [D loss: 0.684578, acc.: 55.47%] [G loss: 0.791731]\n",
      "epoch:8 step:8235 [D loss: 0.691373, acc.: 53.12%] [G loss: 0.743238]\n",
      "epoch:8 step:8236 [D loss: 0.695890, acc.: 53.91%] [G loss: 0.842682]\n",
      "epoch:8 step:8237 [D loss: 0.679054, acc.: 53.91%] [G loss: 0.813860]\n",
      "epoch:8 step:8238 [D loss: 0.679260, acc.: 56.25%] [G loss: 0.808603]\n",
      "epoch:8 step:8239 [D loss: 0.665638, acc.: 56.25%] [G loss: 0.808847]\n",
      "epoch:8 step:8240 [D loss: 0.680881, acc.: 56.25%] [G loss: 0.844103]\n",
      "epoch:8 step:8241 [D loss: 0.706645, acc.: 54.69%] [G loss: 0.791114]\n",
      "epoch:8 step:8242 [D loss: 0.607851, acc.: 69.53%] [G loss: 0.744441]\n",
      "epoch:8 step:8243 [D loss: 0.661327, acc.: 60.16%] [G loss: 0.803622]\n",
      "epoch:8 step:8244 [D loss: 0.941469, acc.: 35.16%] [G loss: 0.844617]\n",
      "epoch:8 step:8245 [D loss: 0.702789, acc.: 46.88%] [G loss: 0.872404]\n",
      "epoch:8 step:8246 [D loss: 0.651101, acc.: 59.38%] [G loss: 0.866867]\n",
      "epoch:8 step:8247 [D loss: 0.689000, acc.: 60.94%] [G loss: 0.866892]\n",
      "epoch:8 step:8248 [D loss: 0.681769, acc.: 52.34%] [G loss: 0.791956]\n",
      "epoch:8 step:8249 [D loss: 0.717474, acc.: 46.88%] [G loss: 0.759627]\n",
      "epoch:8 step:8250 [D loss: 0.706584, acc.: 48.44%] [G loss: 0.825508]\n",
      "epoch:8 step:8251 [D loss: 0.690594, acc.: 57.03%] [G loss: 0.783832]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:8 step:8252 [D loss: 0.687878, acc.: 53.91%] [G loss: 0.781342]\n",
      "epoch:8 step:8253 [D loss: 0.694545, acc.: 57.03%] [G loss: 0.773665]\n",
      "epoch:8 step:8254 [D loss: 0.700654, acc.: 48.44%] [G loss: 0.801477]\n",
      "epoch:8 step:8255 [D loss: 0.685158, acc.: 58.59%] [G loss: 0.788758]\n",
      "epoch:8 step:8256 [D loss: 0.692729, acc.: 53.91%] [G loss: 0.783764]\n",
      "epoch:8 step:8257 [D loss: 0.689123, acc.: 51.56%] [G loss: 0.811592]\n",
      "epoch:8 step:8258 [D loss: 0.665841, acc.: 58.59%] [G loss: 0.761368]\n",
      "epoch:8 step:8259 [D loss: 0.699552, acc.: 51.56%] [G loss: 0.772955]\n",
      "epoch:8 step:8260 [D loss: 0.634373, acc.: 67.19%] [G loss: 0.750899]\n",
      "epoch:8 step:8261 [D loss: 0.691422, acc.: 57.03%] [G loss: 0.815746]\n",
      "epoch:8 step:8262 [D loss: 0.645815, acc.: 64.84%] [G loss: 0.749143]\n",
      "epoch:8 step:8263 [D loss: 0.682551, acc.: 60.94%] [G loss: 0.792297]\n",
      "epoch:8 step:8264 [D loss: 0.673148, acc.: 57.81%] [G loss: 0.759108]\n",
      "epoch:8 step:8265 [D loss: 0.683661, acc.: 52.34%] [G loss: 0.763177]\n",
      "epoch:8 step:8266 [D loss: 0.663247, acc.: 57.03%] [G loss: 0.772366]\n",
      "epoch:8 step:8267 [D loss: 0.706106, acc.: 50.78%] [G loss: 0.743480]\n",
      "epoch:8 step:8268 [D loss: 0.703491, acc.: 50.00%] [G loss: 0.724774]\n",
      "epoch:8 step:8269 [D loss: 0.683614, acc.: 58.59%] [G loss: 0.692033]\n",
      "epoch:8 step:8270 [D loss: 0.740377, acc.: 48.44%] [G loss: 0.737599]\n",
      "epoch:8 step:8271 [D loss: 0.679805, acc.: 53.12%] [G loss: 0.743952]\n",
      "epoch:8 step:8272 [D loss: 0.714083, acc.: 52.34%] [G loss: 0.823403]\n",
      "epoch:8 step:8273 [D loss: 0.690802, acc.: 53.12%] [G loss: 0.799488]\n",
      "epoch:8 step:8274 [D loss: 0.723172, acc.: 46.88%] [G loss: 0.765786]\n",
      "epoch:8 step:8275 [D loss: 0.710541, acc.: 55.47%] [G loss: 0.834046]\n",
      "epoch:8 step:8276 [D loss: 0.687662, acc.: 57.81%] [G loss: 0.781925]\n",
      "epoch:8 step:8277 [D loss: 0.680264, acc.: 59.38%] [G loss: 0.821435]\n",
      "epoch:8 step:8278 [D loss: 0.641555, acc.: 70.31%] [G loss: 0.779431]\n",
      "epoch:8 step:8279 [D loss: 0.669319, acc.: 57.03%] [G loss: 0.783678]\n",
      "epoch:8 step:8280 [D loss: 0.690249, acc.: 53.91%] [G loss: 0.807496]\n",
      "epoch:8 step:8281 [D loss: 0.658434, acc.: 63.28%] [G loss: 0.920817]\n",
      "epoch:8 step:8282 [D loss: 0.684441, acc.: 53.91%] [G loss: 0.780547]\n",
      "epoch:8 step:8283 [D loss: 0.701143, acc.: 47.66%] [G loss: 0.810086]\n",
      "epoch:8 step:8284 [D loss: 0.714999, acc.: 46.88%] [G loss: 0.750744]\n",
      "epoch:8 step:8285 [D loss: 0.711252, acc.: 48.44%] [G loss: 0.730088]\n",
      "epoch:8 step:8286 [D loss: 0.669653, acc.: 57.81%] [G loss: 0.733284]\n",
      "epoch:8 step:8287 [D loss: 0.571867, acc.: 71.09%] [G loss: 0.777311]\n",
      "epoch:8 step:8288 [D loss: 0.645979, acc.: 61.72%] [G loss: 0.797569]\n",
      "epoch:8 step:8289 [D loss: 0.643216, acc.: 65.62%] [G loss: 0.761180]\n",
      "epoch:8 step:8290 [D loss: 0.700033, acc.: 57.81%] [G loss: 0.807421]\n",
      "epoch:8 step:8291 [D loss: 0.640851, acc.: 67.19%] [G loss: 0.848617]\n",
      "epoch:8 step:8292 [D loss: 0.635089, acc.: 70.31%] [G loss: 0.776832]\n",
      "epoch:8 step:8293 [D loss: 0.722386, acc.: 50.00%] [G loss: 0.781912]\n",
      "epoch:8 step:8294 [D loss: 0.670405, acc.: 63.28%] [G loss: 0.698989]\n",
      "epoch:8 step:8295 [D loss: 0.710377, acc.: 51.56%] [G loss: 0.782228]\n",
      "epoch:8 step:8296 [D loss: 0.742860, acc.: 43.75%] [G loss: 0.748448]\n",
      "epoch:8 step:8297 [D loss: 0.681804, acc.: 53.12%] [G loss: 0.773849]\n",
      "epoch:8 step:8298 [D loss: 0.693552, acc.: 52.34%] [G loss: 0.602178]\n",
      "epoch:8 step:8299 [D loss: 0.646835, acc.: 63.28%] [G loss: 0.787084]\n",
      "epoch:8 step:8300 [D loss: 0.507574, acc.: 78.12%] [G loss: 0.752833]\n",
      "epoch:8 step:8301 [D loss: 0.641770, acc.: 66.41%] [G loss: 0.760432]\n",
      "epoch:8 step:8302 [D loss: 0.576242, acc.: 75.00%] [G loss: 0.789097]\n",
      "epoch:8 step:8303 [D loss: 0.758502, acc.: 46.88%] [G loss: 0.790886]\n",
      "epoch:8 step:8304 [D loss: 0.845079, acc.: 37.50%] [G loss: 0.777730]\n",
      "epoch:8 step:8305 [D loss: 0.690236, acc.: 55.47%] [G loss: 0.900707]\n",
      "epoch:8 step:8306 [D loss: 0.661104, acc.: 59.38%] [G loss: 0.908250]\n",
      "epoch:8 step:8307 [D loss: 0.705060, acc.: 48.44%] [G loss: 0.884798]\n",
      "epoch:8 step:8308 [D loss: 0.674087, acc.: 58.59%] [G loss: 0.848783]\n",
      "epoch:8 step:8309 [D loss: 0.654529, acc.: 66.41%] [G loss: 0.884428]\n",
      "epoch:8 step:8310 [D loss: 0.692800, acc.: 54.69%] [G loss: 0.862815]\n",
      "epoch:8 step:8311 [D loss: 0.645583, acc.: 60.94%] [G loss: 0.853896]\n",
      "epoch:8 step:8312 [D loss: 0.674311, acc.: 56.25%] [G loss: 0.844941]\n",
      "epoch:8 step:8313 [D loss: 0.707835, acc.: 52.34%] [G loss: 0.793165]\n",
      "epoch:8 step:8314 [D loss: 0.692668, acc.: 50.78%] [G loss: 0.842504]\n",
      "epoch:8 step:8315 [D loss: 0.691045, acc.: 53.12%] [G loss: 0.813289]\n",
      "epoch:8 step:8316 [D loss: 0.708596, acc.: 47.66%] [G loss: 0.797283]\n",
      "epoch:8 step:8317 [D loss: 0.699239, acc.: 47.66%] [G loss: 0.730600]\n",
      "epoch:8 step:8318 [D loss: 0.675789, acc.: 51.56%] [G loss: 0.775121]\n",
      "epoch:8 step:8319 [D loss: 0.675104, acc.: 58.59%] [G loss: 0.809219]\n",
      "epoch:8 step:8320 [D loss: 0.687817, acc.: 55.47%] [G loss: 0.772414]\n",
      "epoch:8 step:8321 [D loss: 0.668114, acc.: 58.59%] [G loss: 0.755315]\n",
      "epoch:8 step:8322 [D loss: 0.698333, acc.: 56.25%] [G loss: 0.813615]\n",
      "epoch:8 step:8323 [D loss: 0.688973, acc.: 55.47%] [G loss: 0.769077]\n",
      "epoch:8 step:8324 [D loss: 0.677075, acc.: 55.47%] [G loss: 0.856704]\n",
      "epoch:8 step:8325 [D loss: 0.636142, acc.: 67.19%] [G loss: 0.827492]\n",
      "epoch:8 step:8326 [D loss: 0.672903, acc.: 58.59%] [G loss: 0.755633]\n",
      "epoch:8 step:8327 [D loss: 0.674603, acc.: 57.81%] [G loss: 0.802959]\n",
      "epoch:8 step:8328 [D loss: 0.656226, acc.: 64.06%] [G loss: 0.814812]\n",
      "epoch:8 step:8329 [D loss: 0.663552, acc.: 64.06%] [G loss: 0.758670]\n",
      "epoch:8 step:8330 [D loss: 0.768396, acc.: 39.06%] [G loss: 0.814052]\n",
      "epoch:8 step:8331 [D loss: 0.731261, acc.: 51.56%] [G loss: 0.751318]\n",
      "epoch:8 step:8332 [D loss: 0.685791, acc.: 54.69%] [G loss: 0.789176]\n",
      "epoch:8 step:8333 [D loss: 0.663735, acc.: 59.38%] [G loss: 0.774616]\n",
      "epoch:8 step:8334 [D loss: 0.688689, acc.: 57.03%] [G loss: 0.716208]\n",
      "epoch:8 step:8335 [D loss: 0.670740, acc.: 58.59%] [G loss: 0.729912]\n",
      "epoch:8 step:8336 [D loss: 0.687160, acc.: 55.47%] [G loss: 0.773210]\n",
      "epoch:8 step:8337 [D loss: 0.718884, acc.: 49.22%] [G loss: 0.749424]\n",
      "epoch:8 step:8338 [D loss: 0.645741, acc.: 63.28%] [G loss: 0.779788]\n",
      "epoch:8 step:8339 [D loss: 0.693428, acc.: 53.12%] [G loss: 0.748043]\n",
      "epoch:8 step:8340 [D loss: 0.694376, acc.: 57.03%] [G loss: 0.751173]\n",
      "epoch:8 step:8341 [D loss: 0.668471, acc.: 57.03%] [G loss: 0.796084]\n",
      "epoch:8 step:8342 [D loss: 0.667637, acc.: 57.81%] [G loss: 0.759727]\n",
      "epoch:8 step:8343 [D loss: 0.700999, acc.: 50.00%] [G loss: 0.720625]\n",
      "epoch:8 step:8344 [D loss: 0.675502, acc.: 56.25%] [G loss: 0.754110]\n",
      "epoch:8 step:8345 [D loss: 0.672202, acc.: 59.38%] [G loss: 0.730011]\n",
      "epoch:8 step:8346 [D loss: 0.688061, acc.: 54.69%] [G loss: 0.649247]\n",
      "epoch:8 step:8347 [D loss: 0.663542, acc.: 63.28%] [G loss: 0.774845]\n",
      "epoch:8 step:8348 [D loss: 0.665057, acc.: 59.38%] [G loss: 0.773754]\n",
      "epoch:8 step:8349 [D loss: 0.694709, acc.: 54.69%] [G loss: 0.769480]\n",
      "epoch:8 step:8350 [D loss: 0.627195, acc.: 69.53%] [G loss: 0.817999]\n",
      "epoch:8 step:8351 [D loss: 0.637307, acc.: 67.97%] [G loss: 0.889649]\n",
      "epoch:8 step:8352 [D loss: 0.679148, acc.: 57.81%] [G loss: 0.881866]\n",
      "epoch:8 step:8353 [D loss: 0.643342, acc.: 64.06%] [G loss: 0.751570]\n",
      "epoch:8 step:8354 [D loss: 0.772263, acc.: 36.72%] [G loss: 0.774163]\n",
      "epoch:8 step:8355 [D loss: 0.709403, acc.: 49.22%] [G loss: 0.780780]\n",
      "epoch:8 step:8356 [D loss: 0.704608, acc.: 46.88%] [G loss: 0.751555]\n",
      "epoch:8 step:8357 [D loss: 0.721336, acc.: 46.09%] [G loss: 0.732006]\n",
      "epoch:8 step:8358 [D loss: 0.737461, acc.: 46.09%] [G loss: 0.708108]\n",
      "epoch:8 step:8359 [D loss: 0.712344, acc.: 49.22%] [G loss: 0.749316]\n",
      "epoch:8 step:8360 [D loss: 0.704481, acc.: 50.00%] [G loss: 0.715820]\n",
      "epoch:8 step:8361 [D loss: 0.689206, acc.: 51.56%] [G loss: 0.784079]\n",
      "epoch:8 step:8362 [D loss: 0.681680, acc.: 53.12%] [G loss: 0.789269]\n",
      "epoch:8 step:8363 [D loss: 0.708230, acc.: 50.00%] [G loss: 0.777514]\n",
      "epoch:8 step:8364 [D loss: 0.674023, acc.: 60.16%] [G loss: 0.850940]\n",
      "epoch:8 step:8365 [D loss: 0.688890, acc.: 56.25%] [G loss: 0.782328]\n",
      "epoch:8 step:8366 [D loss: 0.670363, acc.: 61.72%] [G loss: 0.823151]\n",
      "epoch:8 step:8367 [D loss: 0.658775, acc.: 64.06%] [G loss: 0.821882]\n",
      "epoch:8 step:8368 [D loss: 0.716585, acc.: 47.66%] [G loss: 0.856184]\n",
      "epoch:8 step:8369 [D loss: 0.665826, acc.: 53.91%] [G loss: 0.820535]\n",
      "epoch:8 step:8370 [D loss: 0.648574, acc.: 64.84%] [G loss: 0.806226]\n",
      "epoch:8 step:8371 [D loss: 0.674126, acc.: 58.59%] [G loss: 0.766434]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:8 step:8372 [D loss: 0.660027, acc.: 64.84%] [G loss: 0.855340]\n",
      "epoch:8 step:8373 [D loss: 0.693981, acc.: 53.91%] [G loss: 0.802017]\n",
      "epoch:8 step:8374 [D loss: 0.622760, acc.: 69.53%] [G loss: 0.794526]\n",
      "epoch:8 step:8375 [D loss: 0.667621, acc.: 58.59%] [G loss: 0.821885]\n",
      "epoch:8 step:8376 [D loss: 0.720791, acc.: 50.78%] [G loss: 0.810045]\n",
      "epoch:8 step:8377 [D loss: 0.698525, acc.: 53.91%] [G loss: 0.761667]\n",
      "epoch:8 step:8378 [D loss: 0.715500, acc.: 42.19%] [G loss: 0.737713]\n",
      "epoch:8 step:8379 [D loss: 0.741020, acc.: 41.41%] [G loss: 0.749128]\n",
      "epoch:8 step:8380 [D loss: 0.728243, acc.: 43.75%] [G loss: 0.736171]\n",
      "epoch:8 step:8381 [D loss: 0.674815, acc.: 54.69%] [G loss: 0.743227]\n",
      "epoch:8 step:8382 [D loss: 0.666713, acc.: 57.81%] [G loss: 0.777424]\n",
      "epoch:8 step:8383 [D loss: 0.611771, acc.: 64.06%] [G loss: 0.780854]\n",
      "epoch:8 step:8384 [D loss: 0.679944, acc.: 53.12%] [G loss: 0.766162]\n",
      "epoch:8 step:8385 [D loss: 0.624669, acc.: 64.84%] [G loss: 0.818505]\n",
      "epoch:8 step:8386 [D loss: 0.630144, acc.: 66.41%] [G loss: 0.808842]\n",
      "epoch:8 step:8387 [D loss: 0.710740, acc.: 50.00%] [G loss: 0.784018]\n",
      "epoch:8 step:8388 [D loss: 0.811060, acc.: 39.84%] [G loss: 0.796988]\n",
      "epoch:8 step:8389 [D loss: 0.695443, acc.: 57.03%] [G loss: 0.793841]\n",
      "epoch:8 step:8390 [D loss: 0.687399, acc.: 53.91%] [G loss: 0.819893]\n",
      "epoch:8 step:8391 [D loss: 0.661750, acc.: 64.06%] [G loss: 0.795007]\n",
      "epoch:8 step:8392 [D loss: 0.673968, acc.: 63.28%] [G loss: 0.785820]\n",
      "epoch:8 step:8393 [D loss: 0.664417, acc.: 59.38%] [G loss: 0.847858]\n",
      "epoch:8 step:8394 [D loss: 0.653070, acc.: 60.94%] [G loss: 0.817437]\n",
      "epoch:8 step:8395 [D loss: 0.649883, acc.: 58.59%] [G loss: 0.765199]\n",
      "epoch:8 step:8396 [D loss: 0.694147, acc.: 53.12%] [G loss: 0.819494]\n",
      "epoch:8 step:8397 [D loss: 0.687995, acc.: 56.25%] [G loss: 0.801383]\n",
      "epoch:8 step:8398 [D loss: 0.710914, acc.: 50.78%] [G loss: 0.746157]\n",
      "epoch:8 step:8399 [D loss: 0.712541, acc.: 50.00%] [G loss: 0.710079]\n",
      "epoch:8 step:8400 [D loss: 0.713127, acc.: 47.66%] [G loss: 0.755207]\n",
      "##############\n",
      "[4.37503464 2.12183006 6.38140497 5.67480297 3.95821542 6.24306051\n",
      " 5.34224172 5.41543418 5.95211453 4.62019708]\n",
      "##########\n",
      "epoch:8 step:8401 [D loss: 0.677554, acc.: 52.34%] [G loss: 0.755386]\n",
      "epoch:8 step:8402 [D loss: 0.694477, acc.: 46.88%] [G loss: 0.753979]\n",
      "epoch:8 step:8403 [D loss: 0.689671, acc.: 53.91%] [G loss: 0.779097]\n",
      "epoch:8 step:8404 [D loss: 0.661935, acc.: 62.50%] [G loss: 0.748659]\n",
      "epoch:8 step:8405 [D loss: 0.675506, acc.: 60.16%] [G loss: 0.795410]\n",
      "epoch:8 step:8406 [D loss: 0.586700, acc.: 63.28%] [G loss: 0.814578]\n",
      "epoch:8 step:8407 [D loss: 0.700819, acc.: 54.69%] [G loss: 0.661789]\n",
      "epoch:8 step:8408 [D loss: 0.678616, acc.: 56.25%] [G loss: 0.721673]\n",
      "epoch:8 step:8409 [D loss: 0.690474, acc.: 51.56%] [G loss: 0.711820]\n",
      "epoch:8 step:8410 [D loss: 0.727407, acc.: 42.19%] [G loss: 0.758877]\n",
      "epoch:8 step:8411 [D loss: 0.688106, acc.: 48.44%] [G loss: 0.722639]\n",
      "epoch:8 step:8412 [D loss: 0.799810, acc.: 47.66%] [G loss: 0.760973]\n",
      "epoch:8 step:8413 [D loss: 0.665597, acc.: 53.12%] [G loss: 0.795091]\n",
      "epoch:8 step:8414 [D loss: 0.656620, acc.: 64.84%] [G loss: 0.752786]\n",
      "epoch:8 step:8415 [D loss: 0.678419, acc.: 58.59%] [G loss: 0.761250]\n",
      "epoch:8 step:8416 [D loss: 0.729130, acc.: 46.88%] [G loss: 0.930314]\n",
      "epoch:8 step:8417 [D loss: 0.713937, acc.: 46.09%] [G loss: 0.776931]\n",
      "epoch:8 step:8418 [D loss: 0.647604, acc.: 61.72%] [G loss: 0.788695]\n",
      "epoch:8 step:8419 [D loss: 0.691580, acc.: 57.81%] [G loss: 0.842444]\n",
      "epoch:8 step:8420 [D loss: 0.655837, acc.: 66.41%] [G loss: 0.800230]\n",
      "epoch:8 step:8421 [D loss: 0.651882, acc.: 64.06%] [G loss: 0.717157]\n",
      "epoch:8 step:8422 [D loss: 0.656437, acc.: 62.50%] [G loss: 0.786150]\n",
      "epoch:8 step:8423 [D loss: 0.633572, acc.: 65.62%] [G loss: 0.805023]\n",
      "epoch:8 step:8424 [D loss: 0.665143, acc.: 57.81%] [G loss: 0.808999]\n",
      "epoch:8 step:8425 [D loss: 0.485344, acc.: 74.22%] [G loss: 0.898379]\n",
      "epoch:8 step:8426 [D loss: 0.644952, acc.: 71.88%] [G loss: 0.857009]\n",
      "epoch:8 step:8427 [D loss: 0.644813, acc.: 64.06%] [G loss: 0.871224]\n",
      "epoch:8 step:8428 [D loss: 0.731674, acc.: 50.00%] [G loss: 0.827498]\n",
      "epoch:8 step:8429 [D loss: 0.704910, acc.: 51.56%] [G loss: 0.734536]\n",
      "epoch:8 step:8430 [D loss: 0.731835, acc.: 51.56%] [G loss: 0.757868]\n",
      "epoch:8 step:8431 [D loss: 0.618021, acc.: 69.53%] [G loss: 0.713612]\n",
      "epoch:8 step:8432 [D loss: 0.581707, acc.: 73.44%] [G loss: 0.758545]\n",
      "epoch:8 step:8433 [D loss: 0.668440, acc.: 58.59%] [G loss: 0.671757]\n",
      "epoch:9 step:8434 [D loss: 0.705314, acc.: 59.38%] [G loss: 0.770600]\n",
      "epoch:9 step:8435 [D loss: 0.767716, acc.: 42.97%] [G loss: 0.792977]\n",
      "epoch:9 step:8436 [D loss: 0.662825, acc.: 65.62%] [G loss: 0.806991]\n",
      "epoch:9 step:8437 [D loss: 0.688506, acc.: 54.69%] [G loss: 0.725600]\n",
      "epoch:9 step:8438 [D loss: 0.666505, acc.: 62.50%] [G loss: 0.728972]\n",
      "epoch:9 step:8439 [D loss: 0.716340, acc.: 46.88%] [G loss: 0.717622]\n",
      "epoch:9 step:8440 [D loss: 0.681786, acc.: 50.78%] [G loss: 0.812481]\n",
      "epoch:9 step:8441 [D loss: 0.670748, acc.: 57.81%] [G loss: 0.771342]\n",
      "epoch:9 step:8442 [D loss: 0.689099, acc.: 57.03%] [G loss: 0.739918]\n",
      "epoch:9 step:8443 [D loss: 0.666737, acc.: 58.59%] [G loss: 0.738294]\n",
      "epoch:9 step:8444 [D loss: 0.687355, acc.: 53.12%] [G loss: 0.807739]\n",
      "epoch:9 step:8445 [D loss: 0.702699, acc.: 50.00%] [G loss: 0.756701]\n",
      "epoch:9 step:8446 [D loss: 0.689543, acc.: 55.47%] [G loss: 0.747606]\n",
      "epoch:9 step:8447 [D loss: 0.678435, acc.: 57.03%] [G loss: 0.766875]\n",
      "epoch:9 step:8448 [D loss: 0.691528, acc.: 56.25%] [G loss: 0.790872]\n",
      "epoch:9 step:8449 [D loss: 0.712376, acc.: 46.88%] [G loss: 0.769593]\n",
      "epoch:9 step:8450 [D loss: 0.693737, acc.: 53.91%] [G loss: 0.782542]\n",
      "epoch:9 step:8451 [D loss: 0.662449, acc.: 58.59%] [G loss: 0.823735]\n",
      "epoch:9 step:8452 [D loss: 0.683742, acc.: 51.56%] [G loss: 0.792015]\n",
      "epoch:9 step:8453 [D loss: 0.734600, acc.: 39.06%] [G loss: 0.783014]\n",
      "epoch:9 step:8454 [D loss: 0.669454, acc.: 58.59%] [G loss: 0.831893]\n",
      "epoch:9 step:8455 [D loss: 0.637161, acc.: 70.31%] [G loss: 0.810050]\n",
      "epoch:9 step:8456 [D loss: 0.720389, acc.: 45.31%] [G loss: 0.779112]\n",
      "epoch:9 step:8457 [D loss: 0.684975, acc.: 60.16%] [G loss: 0.795406]\n",
      "epoch:9 step:8458 [D loss: 0.656620, acc.: 62.50%] [G loss: 0.815087]\n",
      "epoch:9 step:8459 [D loss: 0.685217, acc.: 55.47%] [G loss: 0.771801]\n",
      "epoch:9 step:8460 [D loss: 0.757137, acc.: 38.28%] [G loss: 0.762934]\n",
      "epoch:9 step:8461 [D loss: 0.707038, acc.: 52.34%] [G loss: 0.809686]\n",
      "epoch:9 step:8462 [D loss: 0.696207, acc.: 55.47%] [G loss: 0.751831]\n",
      "epoch:9 step:8463 [D loss: 0.679295, acc.: 57.03%] [G loss: 0.756831]\n",
      "epoch:9 step:8464 [D loss: 0.690212, acc.: 59.38%] [G loss: 0.762996]\n",
      "epoch:9 step:8465 [D loss: 0.662104, acc.: 61.72%] [G loss: 0.772586]\n",
      "epoch:9 step:8466 [D loss: 0.680935, acc.: 57.81%] [G loss: 0.812572]\n",
      "epoch:9 step:8467 [D loss: 0.670971, acc.: 61.72%] [G loss: 0.787159]\n",
      "epoch:9 step:8468 [D loss: 0.643148, acc.: 64.84%] [G loss: 0.746939]\n",
      "epoch:9 step:8469 [D loss: 0.615671, acc.: 67.97%] [G loss: 0.878153]\n",
      "epoch:9 step:8470 [D loss: 0.732443, acc.: 52.34%] [G loss: 0.823307]\n",
      "epoch:9 step:8471 [D loss: 0.712164, acc.: 47.66%] [G loss: 0.791615]\n",
      "epoch:9 step:8472 [D loss: 0.728577, acc.: 50.00%] [G loss: 0.770813]\n",
      "epoch:9 step:8473 [D loss: 0.679047, acc.: 57.81%] [G loss: 0.768566]\n",
      "epoch:9 step:8474 [D loss: 0.694118, acc.: 52.34%] [G loss: 0.763788]\n",
      "epoch:9 step:8475 [D loss: 0.683891, acc.: 57.81%] [G loss: 0.767124]\n",
      "epoch:9 step:8476 [D loss: 0.666974, acc.: 53.91%] [G loss: 0.765302]\n",
      "epoch:9 step:8477 [D loss: 0.617159, acc.: 61.72%] [G loss: 0.693947]\n",
      "epoch:9 step:8478 [D loss: 0.622441, acc.: 67.97%] [G loss: 0.809418]\n",
      "epoch:9 step:8479 [D loss: 0.676241, acc.: 57.81%] [G loss: 0.727795]\n",
      "epoch:9 step:8480 [D loss: 0.722106, acc.: 49.22%] [G loss: 0.648255]\n",
      "epoch:9 step:8481 [D loss: 0.673454, acc.: 61.72%] [G loss: 0.775552]\n",
      "epoch:9 step:8482 [D loss: 0.861697, acc.: 47.66%] [G loss: 0.733454]\n",
      "epoch:9 step:8483 [D loss: 0.680238, acc.: 51.56%] [G loss: 0.772466]\n",
      "epoch:9 step:8484 [D loss: 0.721353, acc.: 51.56%] [G loss: 0.755790]\n",
      "epoch:9 step:8485 [D loss: 0.679636, acc.: 57.03%] [G loss: 0.919744]\n",
      "epoch:9 step:8486 [D loss: 0.684934, acc.: 50.00%] [G loss: 0.777821]\n",
      "epoch:9 step:8487 [D loss: 0.670207, acc.: 56.25%] [G loss: 0.756572]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:9 step:8488 [D loss: 0.689835, acc.: 50.78%] [G loss: 0.890266]\n",
      "epoch:9 step:8489 [D loss: 0.665601, acc.: 54.69%] [G loss: 0.810350]\n",
      "epoch:9 step:8490 [D loss: 0.657108, acc.: 56.25%] [G loss: 0.785649]\n",
      "epoch:9 step:8491 [D loss: 0.647870, acc.: 60.16%] [G loss: 0.772773]\n",
      "epoch:9 step:8492 [D loss: 0.679810, acc.: 57.03%] [G loss: 0.820073]\n",
      "epoch:9 step:8493 [D loss: 0.655736, acc.: 63.28%] [G loss: 0.835552]\n",
      "epoch:9 step:8494 [D loss: 0.710411, acc.: 53.12%] [G loss: 0.831901]\n",
      "epoch:9 step:8495 [D loss: 0.687117, acc.: 58.59%] [G loss: 0.813620]\n",
      "epoch:9 step:8496 [D loss: 0.643447, acc.: 64.06%] [G loss: 0.813338]\n",
      "epoch:9 step:8497 [D loss: 0.682476, acc.: 53.91%] [G loss: 0.798836]\n",
      "epoch:9 step:8498 [D loss: 0.685985, acc.: 54.69%] [G loss: 0.798625]\n",
      "epoch:9 step:8499 [D loss: 0.696466, acc.: 48.44%] [G loss: 0.792300]\n",
      "epoch:9 step:8500 [D loss: 0.691842, acc.: 50.78%] [G loss: 0.779479]\n",
      "epoch:9 step:8501 [D loss: 0.689764, acc.: 56.25%] [G loss: 0.779178]\n",
      "epoch:9 step:8502 [D loss: 0.674154, acc.: 60.16%] [G loss: 0.774839]\n",
      "epoch:9 step:8503 [D loss: 0.716936, acc.: 46.09%] [G loss: 0.783463]\n",
      "epoch:9 step:8504 [D loss: 0.711000, acc.: 50.00%] [G loss: 0.731730]\n",
      "epoch:9 step:8505 [D loss: 0.637013, acc.: 57.03%] [G loss: 0.771258]\n",
      "epoch:9 step:8506 [D loss: 0.678577, acc.: 56.25%] [G loss: 0.768586]\n",
      "epoch:9 step:8507 [D loss: 0.695933, acc.: 50.00%] [G loss: 0.747725]\n",
      "epoch:9 step:8508 [D loss: 0.695340, acc.: 50.78%] [G loss: 0.741268]\n",
      "epoch:9 step:8509 [D loss: 0.649969, acc.: 59.38%] [G loss: 0.775876]\n",
      "epoch:9 step:8510 [D loss: 0.637606, acc.: 67.19%] [G loss: 0.808213]\n",
      "epoch:9 step:8511 [D loss: 0.708959, acc.: 43.75%] [G loss: 0.770145]\n",
      "epoch:9 step:8512 [D loss: 0.707286, acc.: 53.91%] [G loss: 0.793758]\n",
      "epoch:9 step:8513 [D loss: 0.676882, acc.: 58.59%] [G loss: 0.752070]\n",
      "epoch:9 step:8514 [D loss: 0.701805, acc.: 55.47%] [G loss: 0.773446]\n",
      "epoch:9 step:8515 [D loss: 0.739630, acc.: 47.66%] [G loss: 0.770555]\n",
      "epoch:9 step:8516 [D loss: 0.686121, acc.: 50.00%] [G loss: 0.761640]\n",
      "epoch:9 step:8517 [D loss: 0.668676, acc.: 57.03%] [G loss: 0.799354]\n",
      "epoch:9 step:8518 [D loss: 0.683212, acc.: 58.59%] [G loss: 0.765378]\n",
      "epoch:9 step:8519 [D loss: 0.706689, acc.: 49.22%] [G loss: 0.700422]\n",
      "epoch:9 step:8520 [D loss: 0.674778, acc.: 60.94%] [G loss: 0.827693]\n",
      "epoch:9 step:8521 [D loss: 0.659648, acc.: 62.50%] [G loss: 0.754037]\n",
      "epoch:9 step:8522 [D loss: 0.652844, acc.: 65.62%] [G loss: 0.873225]\n",
      "epoch:9 step:8523 [D loss: 0.666550, acc.: 60.94%] [G loss: 0.844891]\n",
      "epoch:9 step:8524 [D loss: 0.630800, acc.: 67.19%] [G loss: 0.903803]\n",
      "epoch:9 step:8525 [D loss: 0.627672, acc.: 64.84%] [G loss: 0.914258]\n",
      "epoch:9 step:8526 [D loss: 0.625186, acc.: 64.84%] [G loss: 0.860873]\n",
      "epoch:9 step:8527 [D loss: 0.679031, acc.: 60.16%] [G loss: 0.823558]\n",
      "epoch:9 step:8528 [D loss: 0.703129, acc.: 52.34%] [G loss: 0.881777]\n",
      "epoch:9 step:8529 [D loss: 0.636025, acc.: 62.50%] [G loss: 0.822797]\n",
      "epoch:9 step:8530 [D loss: 0.644883, acc.: 63.28%] [G loss: 0.812499]\n",
      "epoch:9 step:8531 [D loss: 0.674898, acc.: 51.56%] [G loss: 0.850329]\n",
      "epoch:9 step:8532 [D loss: 0.673143, acc.: 58.59%] [G loss: 0.801903]\n",
      "epoch:9 step:8533 [D loss: 0.636413, acc.: 65.62%] [G loss: 0.855665]\n",
      "epoch:9 step:8534 [D loss: 0.698739, acc.: 49.22%] [G loss: 0.773474]\n",
      "epoch:9 step:8535 [D loss: 0.719278, acc.: 56.25%] [G loss: 0.790988]\n",
      "epoch:9 step:8536 [D loss: 0.704554, acc.: 50.78%] [G loss: 0.752209]\n",
      "epoch:9 step:8537 [D loss: 0.654561, acc.: 58.59%] [G loss: 0.842468]\n",
      "epoch:9 step:8538 [D loss: 0.707224, acc.: 50.78%] [G loss: 0.752117]\n",
      "epoch:9 step:8539 [D loss: 0.680107, acc.: 63.28%] [G loss: 0.855154]\n",
      "epoch:9 step:8540 [D loss: 0.632276, acc.: 66.41%] [G loss: 0.811471]\n",
      "epoch:9 step:8541 [D loss: 0.659181, acc.: 59.38%] [G loss: 0.891101]\n",
      "epoch:9 step:8542 [D loss: 0.640459, acc.: 59.38%] [G loss: 0.970246]\n",
      "epoch:9 step:8543 [D loss: 0.738328, acc.: 50.00%] [G loss: 0.808872]\n",
      "epoch:9 step:8544 [D loss: 0.671326, acc.: 52.34%] [G loss: 0.719679]\n",
      "epoch:9 step:8545 [D loss: 0.714079, acc.: 50.78%] [G loss: 0.802278]\n",
      "epoch:9 step:8546 [D loss: 0.706386, acc.: 56.25%] [G loss: 0.729354]\n",
      "epoch:9 step:8547 [D loss: 0.709506, acc.: 54.69%] [G loss: 0.709638]\n",
      "epoch:9 step:8548 [D loss: 0.694693, acc.: 56.25%] [G loss: 0.726548]\n",
      "epoch:9 step:8549 [D loss: 0.721639, acc.: 53.91%] [G loss: 0.673430]\n",
      "epoch:9 step:8550 [D loss: 0.722280, acc.: 45.31%] [G loss: 0.739408]\n",
      "epoch:9 step:8551 [D loss: 0.696844, acc.: 53.12%] [G loss: 0.738966]\n",
      "epoch:9 step:8552 [D loss: 0.660116, acc.: 60.94%] [G loss: 0.796439]\n",
      "epoch:9 step:8553 [D loss: 0.687229, acc.: 55.47%] [G loss: 0.874123]\n",
      "epoch:9 step:8554 [D loss: 0.666220, acc.: 58.59%] [G loss: 0.952953]\n",
      "epoch:9 step:8555 [D loss: 0.661979, acc.: 60.16%] [G loss: 0.964889]\n",
      "epoch:9 step:8556 [D loss: 0.652332, acc.: 62.50%] [G loss: 0.932129]\n",
      "epoch:9 step:8557 [D loss: 0.618938, acc.: 66.41%] [G loss: 0.916903]\n",
      "epoch:9 step:8558 [D loss: 0.610790, acc.: 67.19%] [G loss: 0.964416]\n",
      "epoch:9 step:8559 [D loss: 0.647332, acc.: 64.84%] [G loss: 1.066387]\n",
      "epoch:9 step:8560 [D loss: 0.667848, acc.: 53.12%] [G loss: 0.901508]\n",
      "epoch:9 step:8561 [D loss: 0.730357, acc.: 49.22%] [G loss: 0.774745]\n",
      "epoch:9 step:8562 [D loss: 0.738820, acc.: 46.88%] [G loss: 0.751166]\n",
      "epoch:9 step:8563 [D loss: 0.694892, acc.: 50.00%] [G loss: 0.795697]\n",
      "epoch:9 step:8564 [D loss: 0.689342, acc.: 54.69%] [G loss: 0.806315]\n",
      "epoch:9 step:8565 [D loss: 0.681255, acc.: 54.69%] [G loss: 0.785417]\n",
      "epoch:9 step:8566 [D loss: 0.682755, acc.: 55.47%] [G loss: 0.760381]\n",
      "epoch:9 step:8567 [D loss: 0.662691, acc.: 63.28%] [G loss: 0.798082]\n",
      "epoch:9 step:8568 [D loss: 0.648137, acc.: 57.03%] [G loss: 0.812420]\n",
      "epoch:9 step:8569 [D loss: 0.697244, acc.: 53.91%] [G loss: 0.792262]\n",
      "epoch:9 step:8570 [D loss: 0.670436, acc.: 64.84%] [G loss: 0.722898]\n",
      "epoch:9 step:8571 [D loss: 0.699281, acc.: 55.47%] [G loss: 0.744709]\n",
      "epoch:9 step:8572 [D loss: 0.637741, acc.: 60.94%] [G loss: 0.753421]\n",
      "epoch:9 step:8573 [D loss: 0.557572, acc.: 76.56%] [G loss: 0.856849]\n",
      "epoch:9 step:8574 [D loss: 0.716411, acc.: 51.56%] [G loss: 0.797939]\n",
      "epoch:9 step:8575 [D loss: 0.609956, acc.: 67.19%] [G loss: 0.953130]\n",
      "epoch:9 step:8576 [D loss: 0.587651, acc.: 79.69%] [G loss: 0.868494]\n",
      "epoch:9 step:8577 [D loss: 0.653028, acc.: 65.62%] [G loss: 0.857472]\n",
      "epoch:9 step:8578 [D loss: 0.642005, acc.: 67.19%] [G loss: 0.768238]\n",
      "epoch:9 step:8579 [D loss: 0.722306, acc.: 52.34%] [G loss: 0.988280]\n",
      "epoch:9 step:8580 [D loss: 0.640249, acc.: 62.50%] [G loss: 0.817383]\n",
      "epoch:9 step:8581 [D loss: 0.713519, acc.: 52.34%] [G loss: 0.785770]\n",
      "epoch:9 step:8582 [D loss: 0.760781, acc.: 49.22%] [G loss: 0.720767]\n",
      "epoch:9 step:8583 [D loss: 0.587863, acc.: 66.41%] [G loss: 0.800480]\n",
      "epoch:9 step:8584 [D loss: 0.662241, acc.: 57.81%] [G loss: 0.865332]\n",
      "epoch:9 step:8585 [D loss: 0.568203, acc.: 67.97%] [G loss: 0.865077]\n",
      "epoch:9 step:8586 [D loss: 0.711252, acc.: 45.31%] [G loss: 0.702230]\n",
      "epoch:9 step:8587 [D loss: 0.838595, acc.: 38.28%] [G loss: 0.982919]\n",
      "epoch:9 step:8588 [D loss: 0.677336, acc.: 52.34%] [G loss: 1.182927]\n",
      "epoch:9 step:8589 [D loss: 0.681757, acc.: 50.00%] [G loss: 0.894232]\n",
      "epoch:9 step:8590 [D loss: 0.668314, acc.: 54.69%] [G loss: 0.853626]\n",
      "epoch:9 step:8591 [D loss: 0.679988, acc.: 53.12%] [G loss: 0.895439]\n",
      "epoch:9 step:8592 [D loss: 0.651175, acc.: 57.03%] [G loss: 0.912618]\n",
      "epoch:9 step:8593 [D loss: 0.749855, acc.: 44.53%] [G loss: 0.861095]\n",
      "epoch:9 step:8594 [D loss: 0.675851, acc.: 57.03%] [G loss: 0.833211]\n",
      "epoch:9 step:8595 [D loss: 0.701327, acc.: 54.69%] [G loss: 0.816895]\n",
      "epoch:9 step:8596 [D loss: 0.684904, acc.: 64.06%] [G loss: 0.834490]\n",
      "epoch:9 step:8597 [D loss: 0.666087, acc.: 60.16%] [G loss: 0.752019]\n",
      "epoch:9 step:8598 [D loss: 0.681896, acc.: 56.25%] [G loss: 0.771334]\n",
      "epoch:9 step:8599 [D loss: 0.648552, acc.: 63.28%] [G loss: 0.732156]\n",
      "epoch:9 step:8600 [D loss: 0.669071, acc.: 58.59%] [G loss: 0.805319]\n",
      "##############\n",
      "[4.58745857 2.19072007 6.37464868 5.37630845 4.04733293 5.76833168\n",
      " 4.93900185 4.78605274 5.72663344 4.90407591]\n",
      "##########\n",
      "epoch:9 step:8601 [D loss: 0.644420, acc.: 61.72%] [G loss: 0.805833]\n",
      "epoch:9 step:8602 [D loss: 0.655452, acc.: 62.50%] [G loss: 0.839942]\n",
      "epoch:9 step:8603 [D loss: 0.664403, acc.: 61.72%] [G loss: 0.812327]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:9 step:8604 [D loss: 0.671469, acc.: 56.25%] [G loss: 0.893263]\n",
      "epoch:9 step:8605 [D loss: 0.659157, acc.: 62.50%] [G loss: 0.778865]\n",
      "epoch:9 step:8606 [D loss: 0.665603, acc.: 60.94%] [G loss: 0.813060]\n",
      "epoch:9 step:8607 [D loss: 0.624974, acc.: 68.75%] [G loss: 0.801094]\n",
      "epoch:9 step:8608 [D loss: 0.666877, acc.: 55.47%] [G loss: 0.852128]\n",
      "epoch:9 step:8609 [D loss: 0.594164, acc.: 71.09%] [G loss: 0.831271]\n",
      "epoch:9 step:8610 [D loss: 0.670054, acc.: 57.03%] [G loss: 0.742639]\n",
      "epoch:9 step:8611 [D loss: 0.722386, acc.: 53.12%] [G loss: 0.743393]\n",
      "epoch:9 step:8612 [D loss: 0.655752, acc.: 61.72%] [G loss: 0.821263]\n",
      "epoch:9 step:8613 [D loss: 0.694766, acc.: 50.78%] [G loss: 0.808923]\n",
      "epoch:9 step:8614 [D loss: 0.708093, acc.: 52.34%] [G loss: 0.812118]\n",
      "epoch:9 step:8615 [D loss: 0.681509, acc.: 56.25%] [G loss: 0.845683]\n",
      "epoch:9 step:8616 [D loss: 0.666999, acc.: 60.94%] [G loss: 0.845310]\n",
      "epoch:9 step:8617 [D loss: 0.660762, acc.: 58.59%] [G loss: 0.817790]\n",
      "epoch:9 step:8618 [D loss: 0.678414, acc.: 56.25%] [G loss: 0.801359]\n",
      "epoch:9 step:8619 [D loss: 0.703722, acc.: 51.56%] [G loss: 0.764916]\n",
      "epoch:9 step:8620 [D loss: 0.677756, acc.: 59.38%] [G loss: 0.825480]\n",
      "epoch:9 step:8621 [D loss: 0.687835, acc.: 56.25%] [G loss: 0.803011]\n",
      "epoch:9 step:8622 [D loss: 0.674484, acc.: 54.69%] [G loss: 0.836806]\n",
      "epoch:9 step:8623 [D loss: 0.684616, acc.: 52.34%] [G loss: 0.840614]\n",
      "epoch:9 step:8624 [D loss: 0.674237, acc.: 60.94%] [G loss: 0.779238]\n",
      "epoch:9 step:8625 [D loss: 0.693528, acc.: 53.91%] [G loss: 0.841121]\n",
      "epoch:9 step:8626 [D loss: 0.710119, acc.: 47.66%] [G loss: 0.738639]\n",
      "epoch:9 step:8627 [D loss: 0.693396, acc.: 53.91%] [G loss: 0.847061]\n",
      "epoch:9 step:8628 [D loss: 0.687851, acc.: 59.38%] [G loss: 0.869021]\n",
      "epoch:9 step:8629 [D loss: 0.672963, acc.: 55.47%] [G loss: 0.813349]\n",
      "epoch:9 step:8630 [D loss: 0.674824, acc.: 56.25%] [G loss: 0.868366]\n",
      "epoch:9 step:8631 [D loss: 0.678884, acc.: 60.16%] [G loss: 0.871514]\n",
      "epoch:9 step:8632 [D loss: 0.655802, acc.: 62.50%] [G loss: 0.803886]\n",
      "epoch:9 step:8633 [D loss: 0.642150, acc.: 64.06%] [G loss: 0.883509]\n",
      "epoch:9 step:8634 [D loss: 0.652067, acc.: 62.50%] [G loss: 0.926219]\n",
      "epoch:9 step:8635 [D loss: 0.673025, acc.: 57.03%] [G loss: 0.896872]\n",
      "epoch:9 step:8636 [D loss: 0.733959, acc.: 53.91%] [G loss: 0.844438]\n",
      "epoch:9 step:8637 [D loss: 0.677475, acc.: 51.56%] [G loss: 0.769390]\n",
      "epoch:9 step:8638 [D loss: 0.704195, acc.: 53.91%] [G loss: 0.782544]\n",
      "epoch:9 step:8639 [D loss: 0.672206, acc.: 55.47%] [G loss: 0.814149]\n",
      "epoch:9 step:8640 [D loss: 0.658692, acc.: 64.84%] [G loss: 0.829130]\n",
      "epoch:9 step:8641 [D loss: 0.691022, acc.: 50.78%] [G loss: 0.878670]\n",
      "epoch:9 step:8642 [D loss: 0.677151, acc.: 56.25%] [G loss: 0.857267]\n",
      "epoch:9 step:8643 [D loss: 0.709400, acc.: 48.44%] [G loss: 0.817306]\n",
      "epoch:9 step:8644 [D loss: 0.724495, acc.: 49.22%] [G loss: 0.798768]\n",
      "epoch:9 step:8645 [D loss: 0.682262, acc.: 59.38%] [G loss: 0.889936]\n",
      "epoch:9 step:8646 [D loss: 0.695419, acc.: 53.91%] [G loss: 0.714646]\n",
      "epoch:9 step:8647 [D loss: 0.743566, acc.: 42.19%] [G loss: 0.772526]\n",
      "epoch:9 step:8648 [D loss: 0.721242, acc.: 50.00%] [G loss: 0.770850]\n",
      "epoch:9 step:8649 [D loss: 0.711653, acc.: 46.09%] [G loss: 0.782495]\n",
      "epoch:9 step:8650 [D loss: 0.666802, acc.: 59.38%] [G loss: 0.772797]\n",
      "epoch:9 step:8651 [D loss: 0.695777, acc.: 56.25%] [G loss: 0.700679]\n",
      "epoch:9 step:8652 [D loss: 0.670670, acc.: 55.47%] [G loss: 0.695593]\n",
      "epoch:9 step:8653 [D loss: 0.573927, acc.: 67.97%] [G loss: 0.713937]\n",
      "epoch:9 step:8654 [D loss: 0.576056, acc.: 75.78%] [G loss: 0.785352]\n",
      "epoch:9 step:8655 [D loss: 0.681422, acc.: 64.84%] [G loss: 0.827819]\n",
      "epoch:9 step:8656 [D loss: 0.491519, acc.: 84.38%] [G loss: 0.819925]\n",
      "epoch:9 step:8657 [D loss: 0.676434, acc.: 53.12%] [G loss: 0.814508]\n",
      "epoch:9 step:8658 [D loss: 0.685984, acc.: 57.81%] [G loss: 0.803280]\n",
      "epoch:9 step:8659 [D loss: 0.665208, acc.: 57.81%] [G loss: 0.805674]\n",
      "epoch:9 step:8660 [D loss: 0.587476, acc.: 66.41%] [G loss: 0.814976]\n",
      "epoch:9 step:8661 [D loss: 0.651307, acc.: 64.06%] [G loss: 0.808069]\n",
      "epoch:9 step:8662 [D loss: 0.516787, acc.: 71.09%] [G loss: 0.796597]\n",
      "epoch:9 step:8663 [D loss: 0.447627, acc.: 72.66%] [G loss: 0.840214]\n",
      "epoch:9 step:8664 [D loss: 0.633636, acc.: 60.16%] [G loss: 0.936386]\n",
      "epoch:9 step:8665 [D loss: 0.291145, acc.: 95.31%] [G loss: 0.984701]\n",
      "epoch:9 step:8666 [D loss: 0.616066, acc.: 67.19%] [G loss: 0.816770]\n",
      "epoch:9 step:8667 [D loss: 0.978182, acc.: 57.03%] [G loss: 1.002441]\n",
      "epoch:9 step:8668 [D loss: 0.717104, acc.: 56.25%] [G loss: 1.080498]\n",
      "epoch:9 step:8669 [D loss: 0.810105, acc.: 46.09%] [G loss: 1.049029]\n",
      "epoch:9 step:8670 [D loss: 0.802416, acc.: 45.31%] [G loss: 1.020709]\n",
      "epoch:9 step:8671 [D loss: 0.727804, acc.: 54.69%] [G loss: 1.028379]\n",
      "epoch:9 step:8672 [D loss: 0.695803, acc.: 57.81%] [G loss: 0.965942]\n",
      "epoch:9 step:8673 [D loss: 0.679165, acc.: 56.25%] [G loss: 0.906958]\n",
      "epoch:9 step:8674 [D loss: 0.700141, acc.: 44.53%] [G loss: 0.875489]\n",
      "epoch:9 step:8675 [D loss: 0.699513, acc.: 50.78%] [G loss: 0.850108]\n",
      "epoch:9 step:8676 [D loss: 0.712818, acc.: 50.78%] [G loss: 0.853809]\n",
      "epoch:9 step:8677 [D loss: 0.731123, acc.: 48.44%] [G loss: 0.855852]\n",
      "epoch:9 step:8678 [D loss: 0.670967, acc.: 60.16%] [G loss: 0.814770]\n",
      "epoch:9 step:8679 [D loss: 0.664919, acc.: 63.28%] [G loss: 0.799888]\n",
      "epoch:9 step:8680 [D loss: 0.682338, acc.: 51.56%] [G loss: 0.785968]\n",
      "epoch:9 step:8681 [D loss: 0.640471, acc.: 66.41%] [G loss: 0.788990]\n",
      "epoch:9 step:8682 [D loss: 0.682481, acc.: 57.81%] [G loss: 0.754574]\n",
      "epoch:9 step:8683 [D loss: 0.668779, acc.: 60.16%] [G loss: 0.771153]\n",
      "epoch:9 step:8684 [D loss: 0.695374, acc.: 53.12%] [G loss: 0.760046]\n",
      "epoch:9 step:8685 [D loss: 0.676419, acc.: 59.38%] [G loss: 0.732111]\n",
      "epoch:9 step:8686 [D loss: 0.709594, acc.: 45.31%] [G loss: 0.804326]\n",
      "epoch:9 step:8687 [D loss: 0.678990, acc.: 59.38%] [G loss: 0.732938]\n",
      "epoch:9 step:8688 [D loss: 0.711997, acc.: 43.75%] [G loss: 0.787252]\n",
      "epoch:9 step:8689 [D loss: 0.686717, acc.: 57.81%] [G loss: 0.798705]\n",
      "epoch:9 step:8690 [D loss: 0.667675, acc.: 60.16%] [G loss: 0.791327]\n",
      "epoch:9 step:8691 [D loss: 0.669743, acc.: 55.47%] [G loss: 0.792958]\n",
      "epoch:9 step:8692 [D loss: 0.601073, acc.: 67.97%] [G loss: 0.801261]\n",
      "epoch:9 step:8693 [D loss: 0.648129, acc.: 58.59%] [G loss: 0.800797]\n",
      "epoch:9 step:8694 [D loss: 0.655270, acc.: 60.94%] [G loss: 0.826533]\n",
      "epoch:9 step:8695 [D loss: 0.617515, acc.: 64.06%] [G loss: 0.817382]\n",
      "epoch:9 step:8696 [D loss: 0.659414, acc.: 53.91%] [G loss: 0.743157]\n",
      "epoch:9 step:8697 [D loss: 0.639359, acc.: 64.06%] [G loss: 0.700140]\n",
      "epoch:9 step:8698 [D loss: 0.614345, acc.: 60.16%] [G loss: 0.757391]\n",
      "epoch:9 step:8699 [D loss: 0.520772, acc.: 65.62%] [G loss: 0.617046]\n",
      "epoch:9 step:8700 [D loss: 0.608111, acc.: 62.50%] [G loss: 0.692500]\n",
      "epoch:9 step:8701 [D loss: 0.674607, acc.: 52.34%] [G loss: 0.751573]\n",
      "epoch:9 step:8702 [D loss: 0.751445, acc.: 46.09%] [G loss: 0.764485]\n",
      "epoch:9 step:8703 [D loss: 0.855755, acc.: 39.06%] [G loss: 0.798972]\n",
      "epoch:9 step:8704 [D loss: 0.650249, acc.: 67.19%] [G loss: 0.813584]\n",
      "epoch:9 step:8705 [D loss: 0.728970, acc.: 46.09%] [G loss: 0.834959]\n",
      "epoch:9 step:8706 [D loss: 0.822143, acc.: 36.72%] [G loss: 0.911541]\n",
      "epoch:9 step:8707 [D loss: 0.658883, acc.: 57.81%] [G loss: 0.957662]\n",
      "epoch:9 step:8708 [D loss: 0.631053, acc.: 63.28%] [G loss: 1.315500]\n",
      "epoch:9 step:8709 [D loss: 0.639408, acc.: 67.19%] [G loss: 0.975396]\n",
      "epoch:9 step:8710 [D loss: 0.695889, acc.: 56.25%] [G loss: 0.895466]\n",
      "epoch:9 step:8711 [D loss: 0.682048, acc.: 57.03%] [G loss: 0.823243]\n",
      "epoch:9 step:8712 [D loss: 0.798777, acc.: 47.66%] [G loss: 0.815220]\n",
      "epoch:9 step:8713 [D loss: 0.663519, acc.: 60.16%] [G loss: 0.794824]\n",
      "epoch:9 step:8714 [D loss: 0.705250, acc.: 46.09%] [G loss: 0.860058]\n",
      "epoch:9 step:8715 [D loss: 0.687408, acc.: 53.12%] [G loss: 0.819151]\n",
      "epoch:9 step:8716 [D loss: 0.707586, acc.: 49.22%] [G loss: 0.796132]\n",
      "epoch:9 step:8717 [D loss: 0.650522, acc.: 60.94%] [G loss: 0.833045]\n",
      "epoch:9 step:8718 [D loss: 0.628223, acc.: 62.50%] [G loss: 0.827877]\n",
      "epoch:9 step:8719 [D loss: 0.658017, acc.: 64.06%] [G loss: 0.777761]\n",
      "epoch:9 step:8720 [D loss: 0.680885, acc.: 53.12%] [G loss: 0.781078]\n",
      "epoch:9 step:8721 [D loss: 0.711410, acc.: 50.00%] [G loss: 0.766028]\n",
      "epoch:9 step:8722 [D loss: 0.670729, acc.: 55.47%] [G loss: 0.773618]\n",
      "epoch:9 step:8723 [D loss: 0.633590, acc.: 59.38%] [G loss: 0.830245]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:9 step:8724 [D loss: 0.712221, acc.: 49.22%] [G loss: 0.788459]\n",
      "epoch:9 step:8725 [D loss: 0.712178, acc.: 50.00%] [G loss: 0.713584]\n",
      "epoch:9 step:8726 [D loss: 0.559178, acc.: 70.31%] [G loss: 0.770127]\n",
      "epoch:9 step:8727 [D loss: 0.705197, acc.: 53.91%] [G loss: 0.741907]\n",
      "epoch:9 step:8728 [D loss: 0.716281, acc.: 42.97%] [G loss: 0.770089]\n",
      "epoch:9 step:8729 [D loss: 0.774076, acc.: 42.19%] [G loss: 0.758448]\n",
      "epoch:9 step:8730 [D loss: 0.699946, acc.: 47.66%] [G loss: 0.811033]\n",
      "epoch:9 step:8731 [D loss: 0.702570, acc.: 49.22%] [G loss: 0.856346]\n",
      "epoch:9 step:8732 [D loss: 0.689201, acc.: 50.00%] [G loss: 0.906735]\n",
      "epoch:9 step:8733 [D loss: 0.662677, acc.: 58.59%] [G loss: 0.797009]\n",
      "epoch:9 step:8734 [D loss: 0.690895, acc.: 53.12%] [G loss: 0.857863]\n",
      "epoch:9 step:8735 [D loss: 0.684670, acc.: 55.47%] [G loss: 0.861266]\n",
      "epoch:9 step:8736 [D loss: 0.662850, acc.: 60.94%] [G loss: 0.854989]\n",
      "epoch:9 step:8737 [D loss: 0.787993, acc.: 44.53%] [G loss: 0.899091]\n",
      "epoch:9 step:8738 [D loss: 0.679104, acc.: 55.47%] [G loss: 0.917117]\n",
      "epoch:9 step:8739 [D loss: 0.675973, acc.: 51.56%] [G loss: 0.890794]\n",
      "epoch:9 step:8740 [D loss: 0.669373, acc.: 62.50%] [G loss: 0.890175]\n",
      "epoch:9 step:8741 [D loss: 0.705438, acc.: 54.69%] [G loss: 0.818844]\n",
      "epoch:9 step:8742 [D loss: 0.599808, acc.: 71.09%] [G loss: 0.790450]\n",
      "epoch:9 step:8743 [D loss: 0.666595, acc.: 64.84%] [G loss: 0.775907]\n",
      "epoch:9 step:8744 [D loss: 0.635184, acc.: 69.53%] [G loss: 0.792457]\n",
      "epoch:9 step:8745 [D loss: 0.534810, acc.: 71.88%] [G loss: 0.813881]\n",
      "epoch:9 step:8746 [D loss: 0.598792, acc.: 73.44%] [G loss: 0.810751]\n",
      "epoch:9 step:8747 [D loss: 0.448421, acc.: 76.56%] [G loss: 0.747265]\n",
      "epoch:9 step:8748 [D loss: 0.699352, acc.: 62.50%] [G loss: 0.764260]\n",
      "epoch:9 step:8749 [D loss: 0.718185, acc.: 53.12%] [G loss: 0.840921]\n",
      "epoch:9 step:8750 [D loss: 0.711892, acc.: 46.09%] [G loss: 0.839352]\n",
      "epoch:9 step:8751 [D loss: 0.724832, acc.: 39.84%] [G loss: 0.843969]\n",
      "epoch:9 step:8752 [D loss: 0.702859, acc.: 46.88%] [G loss: 0.899109]\n",
      "epoch:9 step:8753 [D loss: 0.639909, acc.: 64.06%] [G loss: 0.845157]\n",
      "epoch:9 step:8754 [D loss: 0.826115, acc.: 42.19%] [G loss: 0.978311]\n",
      "epoch:9 step:8755 [D loss: 0.637460, acc.: 62.50%] [G loss: 1.130393]\n",
      "epoch:9 step:8756 [D loss: 0.645999, acc.: 60.16%] [G loss: 1.016382]\n",
      "epoch:9 step:8757 [D loss: 0.672784, acc.: 60.94%] [G loss: 1.230343]\n",
      "epoch:9 step:8758 [D loss: 0.695298, acc.: 57.03%] [G loss: 0.869550]\n",
      "epoch:9 step:8759 [D loss: 0.669315, acc.: 57.03%] [G loss: 1.013711]\n",
      "epoch:9 step:8760 [D loss: 0.645581, acc.: 64.06%] [G loss: 0.816110]\n",
      "epoch:9 step:8761 [D loss: 0.678314, acc.: 57.81%] [G loss: 0.776472]\n",
      "epoch:9 step:8762 [D loss: 0.682285, acc.: 53.91%] [G loss: 0.786488]\n",
      "epoch:9 step:8763 [D loss: 0.734437, acc.: 46.88%] [G loss: 0.796157]\n",
      "epoch:9 step:8764 [D loss: 0.686728, acc.: 53.91%] [G loss: 0.808652]\n",
      "epoch:9 step:8765 [D loss: 0.716465, acc.: 46.88%] [G loss: 0.775359]\n",
      "epoch:9 step:8766 [D loss: 0.727722, acc.: 43.75%] [G loss: 0.740113]\n",
      "epoch:9 step:8767 [D loss: 0.691739, acc.: 57.03%] [G loss: 0.771186]\n",
      "epoch:9 step:8768 [D loss: 0.636318, acc.: 67.97%] [G loss: 0.869514]\n",
      "epoch:9 step:8769 [D loss: 0.637747, acc.: 67.97%] [G loss: 0.865250]\n",
      "epoch:9 step:8770 [D loss: 0.648371, acc.: 67.19%] [G loss: 0.782261]\n",
      "epoch:9 step:8771 [D loss: 0.625604, acc.: 66.41%] [G loss: 0.822725]\n",
      "epoch:9 step:8772 [D loss: 0.674619, acc.: 53.91%] [G loss: 0.760595]\n",
      "epoch:9 step:8773 [D loss: 0.638780, acc.: 62.50%] [G loss: 0.797335]\n",
      "epoch:9 step:8774 [D loss: 0.626589, acc.: 67.97%] [G loss: 0.818859]\n",
      "epoch:9 step:8775 [D loss: 0.635928, acc.: 64.06%] [G loss: 0.844928]\n",
      "epoch:9 step:8776 [D loss: 0.594188, acc.: 68.75%] [G loss: 0.881811]\n",
      "epoch:9 step:8777 [D loss: 0.566597, acc.: 72.66%] [G loss: 1.000093]\n",
      "epoch:9 step:8778 [D loss: 0.779750, acc.: 53.12%] [G loss: 0.999503]\n",
      "epoch:9 step:8779 [D loss: 0.569381, acc.: 73.44%] [G loss: 0.957301]\n",
      "epoch:9 step:8780 [D loss: 0.589834, acc.: 71.88%] [G loss: 0.932566]\n",
      "epoch:9 step:8781 [D loss: 0.768036, acc.: 46.88%] [G loss: 0.844108]\n",
      "epoch:9 step:8782 [D loss: 0.751323, acc.: 50.78%] [G loss: 0.732169]\n",
      "epoch:9 step:8783 [D loss: 0.828233, acc.: 53.91%] [G loss: 0.902009]\n",
      "epoch:9 step:8784 [D loss: 0.705758, acc.: 52.34%] [G loss: 0.885830]\n",
      "epoch:9 step:8785 [D loss: 0.696879, acc.: 56.25%] [G loss: 0.901123]\n",
      "epoch:9 step:8786 [D loss: 0.702516, acc.: 47.66%] [G loss: 0.824920]\n",
      "epoch:9 step:8787 [D loss: 0.662330, acc.: 56.25%] [G loss: 0.878994]\n",
      "epoch:9 step:8788 [D loss: 0.712215, acc.: 56.25%] [G loss: 0.880959]\n",
      "epoch:9 step:8789 [D loss: 0.666032, acc.: 64.06%] [G loss: 0.939982]\n",
      "epoch:9 step:8790 [D loss: 0.668396, acc.: 56.25%] [G loss: 0.877672]\n",
      "epoch:9 step:8791 [D loss: 0.626584, acc.: 66.41%] [G loss: 0.864558]\n",
      "epoch:9 step:8792 [D loss: 0.657508, acc.: 57.81%] [G loss: 0.863272]\n",
      "epoch:9 step:8793 [D loss: 0.648003, acc.: 62.50%] [G loss: 0.920076]\n",
      "epoch:9 step:8794 [D loss: 0.688941, acc.: 53.12%] [G loss: 0.927865]\n",
      "epoch:9 step:8795 [D loss: 0.718100, acc.: 52.34%] [G loss: 0.823470]\n",
      "epoch:9 step:8796 [D loss: 0.704354, acc.: 50.00%] [G loss: 0.841887]\n",
      "epoch:9 step:8797 [D loss: 0.663038, acc.: 58.59%] [G loss: 0.776217]\n",
      "epoch:9 step:8798 [D loss: 0.724986, acc.: 51.56%] [G loss: 0.804586]\n",
      "epoch:9 step:8799 [D loss: 0.710983, acc.: 50.78%] [G loss: 0.980583]\n",
      "epoch:9 step:8800 [D loss: 0.643907, acc.: 54.69%] [G loss: 0.872792]\n",
      "##############\n",
      "[3.99777728 2.42185646 6.26850194 5.74480467 4.14074367 5.77403995\n",
      " 4.97028974 5.36584734 5.86994775 4.6712303 ]\n",
      "##########\n",
      "epoch:9 step:8801 [D loss: 0.696679, acc.: 52.34%] [G loss: 0.786452]\n",
      "epoch:9 step:8802 [D loss: 0.706905, acc.: 52.34%] [G loss: 0.774704]\n",
      "epoch:9 step:8803 [D loss: 0.655704, acc.: 64.84%] [G loss: 0.806927]\n",
      "epoch:9 step:8804 [D loss: 0.669027, acc.: 60.16%] [G loss: 0.775441]\n",
      "epoch:9 step:8805 [D loss: 0.676333, acc.: 55.47%] [G loss: 0.873363]\n",
      "epoch:9 step:8806 [D loss: 0.810689, acc.: 46.09%] [G loss: 0.820271]\n",
      "epoch:9 step:8807 [D loss: 0.651426, acc.: 69.53%] [G loss: 0.858104]\n",
      "epoch:9 step:8808 [D loss: 0.754373, acc.: 43.75%] [G loss: 0.770137]\n",
      "epoch:9 step:8809 [D loss: 0.649398, acc.: 67.97%] [G loss: 0.817158]\n",
      "epoch:9 step:8810 [D loss: 0.661137, acc.: 60.16%] [G loss: 0.819394]\n",
      "epoch:9 step:8811 [D loss: 0.667270, acc.: 58.59%] [G loss: 0.808230]\n",
      "epoch:9 step:8812 [D loss: 0.654593, acc.: 63.28%] [G loss: 0.792631]\n",
      "epoch:9 step:8813 [D loss: 0.668907, acc.: 64.06%] [G loss: 0.776381]\n",
      "epoch:9 step:8814 [D loss: 0.641422, acc.: 68.75%] [G loss: 0.763709]\n",
      "epoch:9 step:8815 [D loss: 0.677613, acc.: 53.12%] [G loss: 0.776241]\n",
      "epoch:9 step:8816 [D loss: 0.713728, acc.: 49.22%] [G loss: 0.787363]\n",
      "epoch:9 step:8817 [D loss: 0.681986, acc.: 60.16%] [G loss: 0.792603]\n",
      "epoch:9 step:8818 [D loss: 0.710721, acc.: 46.88%] [G loss: 0.731112]\n",
      "epoch:9 step:8819 [D loss: 0.709601, acc.: 55.47%] [G loss: 0.689492]\n",
      "epoch:9 step:8820 [D loss: 0.736877, acc.: 47.66%] [G loss: 0.701051]\n",
      "epoch:9 step:8821 [D loss: 0.700856, acc.: 51.56%] [G loss: 0.746756]\n",
      "epoch:9 step:8822 [D loss: 0.734325, acc.: 45.31%] [G loss: 0.705366]\n",
      "epoch:9 step:8823 [D loss: 0.730706, acc.: 40.62%] [G loss: 0.732007]\n",
      "epoch:9 step:8824 [D loss: 0.693620, acc.: 50.78%] [G loss: 0.733967]\n",
      "epoch:9 step:8825 [D loss: 0.706753, acc.: 51.56%] [G loss: 0.732955]\n",
      "epoch:9 step:8826 [D loss: 0.709079, acc.: 50.00%] [G loss: 0.769356]\n",
      "epoch:9 step:8827 [D loss: 0.698844, acc.: 49.22%] [G loss: 0.767117]\n",
      "epoch:9 step:8828 [D loss: 0.698108, acc.: 50.78%] [G loss: 0.763450]\n",
      "epoch:9 step:8829 [D loss: 0.665495, acc.: 57.81%] [G loss: 0.774583]\n",
      "epoch:9 step:8830 [D loss: 0.664651, acc.: 59.38%] [G loss: 0.773693]\n",
      "epoch:9 step:8831 [D loss: 0.667180, acc.: 63.28%] [G loss: 0.765823]\n",
      "epoch:9 step:8832 [D loss: 0.502941, acc.: 78.91%] [G loss: 0.797899]\n",
      "epoch:9 step:8833 [D loss: 0.686342, acc.: 57.81%] [G loss: 0.816503]\n",
      "epoch:9 step:8834 [D loss: 0.700623, acc.: 48.44%] [G loss: 0.742396]\n",
      "epoch:9 step:8835 [D loss: 0.643016, acc.: 70.31%] [G loss: 0.765736]\n",
      "epoch:9 step:8836 [D loss: 0.688496, acc.: 54.69%] [G loss: 0.729560]\n",
      "epoch:9 step:8837 [D loss: 0.648820, acc.: 61.72%] [G loss: 0.781758]\n",
      "epoch:9 step:8838 [D loss: 0.634371, acc.: 71.09%] [G loss: 0.760186]\n",
      "epoch:9 step:8839 [D loss: 0.628234, acc.: 66.41%] [G loss: 0.799394]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:9 step:8840 [D loss: 0.504403, acc.: 71.88%] [G loss: 0.823075]\n",
      "epoch:9 step:8841 [D loss: 0.666635, acc.: 57.81%] [G loss: 0.818962]\n",
      "epoch:9 step:8842 [D loss: 0.825469, acc.: 40.62%] [G loss: 0.827299]\n",
      "epoch:9 step:8843 [D loss: 0.773727, acc.: 48.44%] [G loss: 0.813574]\n",
      "epoch:9 step:8844 [D loss: 0.686574, acc.: 58.59%] [G loss: 0.863948]\n",
      "epoch:9 step:8845 [D loss: 0.678647, acc.: 57.81%] [G loss: 0.827407]\n",
      "epoch:9 step:8846 [D loss: 0.660023, acc.: 56.25%] [G loss: 0.834395]\n",
      "epoch:9 step:8847 [D loss: 0.642425, acc.: 64.84%] [G loss: 0.761777]\n",
      "epoch:9 step:8848 [D loss: 0.672007, acc.: 56.25%] [G loss: 0.820664]\n",
      "epoch:9 step:8849 [D loss: 0.650555, acc.: 60.94%] [G loss: 0.824472]\n",
      "epoch:9 step:8850 [D loss: 0.640346, acc.: 60.94%] [G loss: 0.850949]\n",
      "epoch:9 step:8851 [D loss: 0.672149, acc.: 64.06%] [G loss: 0.782637]\n",
      "epoch:9 step:8852 [D loss: 0.579111, acc.: 62.50%] [G loss: 0.821787]\n",
      "epoch:9 step:8853 [D loss: 0.660535, acc.: 61.72%] [G loss: 0.856418]\n",
      "epoch:9 step:8854 [D loss: 0.720481, acc.: 50.00%] [G loss: 0.849485]\n",
      "epoch:9 step:8855 [D loss: 0.751147, acc.: 37.50%] [G loss: 0.775839]\n",
      "epoch:9 step:8856 [D loss: 0.657465, acc.: 64.84%] [G loss: 0.836194]\n",
      "epoch:9 step:8857 [D loss: 0.602743, acc.: 75.78%] [G loss: 0.824921]\n",
      "epoch:9 step:8858 [D loss: 0.617934, acc.: 71.09%] [G loss: 0.803291]\n",
      "epoch:9 step:8859 [D loss: 0.606579, acc.: 72.66%] [G loss: 0.841702]\n",
      "epoch:9 step:8860 [D loss: 0.472246, acc.: 77.34%] [G loss: 0.869914]\n",
      "epoch:9 step:8861 [D loss: 0.428881, acc.: 85.16%] [G loss: 0.865216]\n",
      "epoch:9 step:8862 [D loss: 0.396675, acc.: 88.28%] [G loss: 0.896789]\n",
      "epoch:9 step:8863 [D loss: 0.396008, acc.: 82.03%] [G loss: 0.662123]\n",
      "epoch:9 step:8864 [D loss: 0.926513, acc.: 29.69%] [G loss: 0.435142]\n",
      "epoch:9 step:8865 [D loss: 0.843681, acc.: 33.59%] [G loss: 0.940810]\n",
      "epoch:9 step:8866 [D loss: 0.771437, acc.: 40.62%] [G loss: 0.877424]\n",
      "epoch:9 step:8867 [D loss: 0.743796, acc.: 45.31%] [G loss: 0.854551]\n",
      "epoch:9 step:8868 [D loss: 0.690865, acc.: 52.34%] [G loss: 1.060328]\n",
      "epoch:9 step:8869 [D loss: 0.714703, acc.: 48.44%] [G loss: 1.358953]\n",
      "epoch:9 step:8870 [D loss: 0.652645, acc.: 49.22%] [G loss: 1.482714]\n",
      "epoch:9 step:8871 [D loss: 0.678614, acc.: 46.88%] [G loss: 1.311210]\n",
      "epoch:9 step:8872 [D loss: 0.672362, acc.: 50.00%] [G loss: 1.164237]\n",
      "epoch:9 step:8873 [D loss: 0.679432, acc.: 52.34%] [G loss: 1.116420]\n",
      "epoch:9 step:8874 [D loss: 0.702574, acc.: 50.78%] [G loss: 0.956572]\n",
      "epoch:9 step:8875 [D loss: 0.685119, acc.: 57.81%] [G loss: 0.959677]\n",
      "epoch:9 step:8876 [D loss: 0.623727, acc.: 66.41%] [G loss: 0.963539]\n",
      "epoch:9 step:8877 [D loss: 0.642135, acc.: 60.16%] [G loss: 0.976813]\n",
      "epoch:9 step:8878 [D loss: 0.614074, acc.: 68.75%] [G loss: 0.934578]\n",
      "epoch:9 step:8879 [D loss: 0.663692, acc.: 56.25%] [G loss: 0.903420]\n",
      "epoch:9 step:8880 [D loss: 0.664896, acc.: 58.59%] [G loss: 0.894020]\n",
      "epoch:9 step:8881 [D loss: 0.664536, acc.: 61.72%] [G loss: 0.892000]\n",
      "epoch:9 step:8882 [D loss: 0.649360, acc.: 62.50%] [G loss: 0.884552]\n",
      "epoch:9 step:8883 [D loss: 0.649484, acc.: 65.62%] [G loss: 0.914211]\n",
      "epoch:9 step:8884 [D loss: 0.598346, acc.: 72.66%] [G loss: 0.885502]\n",
      "epoch:9 step:8885 [D loss: 0.593656, acc.: 72.66%] [G loss: 0.904640]\n",
      "epoch:9 step:8886 [D loss: 0.602996, acc.: 66.41%] [G loss: 0.911778]\n",
      "epoch:9 step:8887 [D loss: 0.648911, acc.: 64.06%] [G loss: 0.922346]\n",
      "epoch:9 step:8888 [D loss: 0.615249, acc.: 67.19%] [G loss: 1.011674]\n",
      "epoch:9 step:8889 [D loss: 0.654308, acc.: 60.94%] [G loss: 0.879752]\n",
      "epoch:9 step:8890 [D loss: 0.625410, acc.: 66.41%] [G loss: 0.919866]\n",
      "epoch:9 step:8891 [D loss: 0.707820, acc.: 51.56%] [G loss: 0.878669]\n",
      "epoch:9 step:8892 [D loss: 0.655730, acc.: 64.06%] [G loss: 0.914822]\n",
      "epoch:9 step:8893 [D loss: 0.643369, acc.: 65.62%] [G loss: 0.950134]\n",
      "epoch:9 step:8894 [D loss: 0.626560, acc.: 63.28%] [G loss: 0.970349]\n",
      "epoch:9 step:8895 [D loss: 0.681951, acc.: 53.12%] [G loss: 0.963070]\n",
      "epoch:9 step:8896 [D loss: 0.732177, acc.: 50.78%] [G loss: 0.899027]\n",
      "epoch:9 step:8897 [D loss: 0.701101, acc.: 50.78%] [G loss: 0.893163]\n",
      "epoch:9 step:8898 [D loss: 0.675777, acc.: 57.81%] [G loss: 0.868345]\n",
      "epoch:9 step:8899 [D loss: 0.676195, acc.: 55.47%] [G loss: 0.808654]\n",
      "epoch:9 step:8900 [D loss: 0.657790, acc.: 60.16%] [G loss: 0.892412]\n",
      "epoch:9 step:8901 [D loss: 0.646031, acc.: 60.16%] [G loss: 0.872117]\n",
      "epoch:9 step:8902 [D loss: 0.596585, acc.: 72.66%] [G loss: 0.940028]\n",
      "epoch:9 step:8903 [D loss: 0.610784, acc.: 69.53%] [G loss: 0.910816]\n",
      "epoch:9 step:8904 [D loss: 0.579465, acc.: 77.34%] [G loss: 0.904038]\n",
      "epoch:9 step:8905 [D loss: 0.625757, acc.: 62.50%] [G loss: 0.975702]\n",
      "epoch:9 step:8906 [D loss: 0.809968, acc.: 39.84%] [G loss: 0.873779]\n",
      "epoch:9 step:8907 [D loss: 0.715152, acc.: 45.31%] [G loss: 0.876507]\n",
      "epoch:9 step:8908 [D loss: 0.703592, acc.: 49.22%] [G loss: 0.878422]\n",
      "epoch:9 step:8909 [D loss: 0.704220, acc.: 51.56%] [G loss: 0.849815]\n",
      "epoch:9 step:8910 [D loss: 0.704475, acc.: 57.03%] [G loss: 0.908165]\n",
      "epoch:9 step:8911 [D loss: 0.689990, acc.: 57.03%] [G loss: 0.809800]\n",
      "epoch:9 step:8912 [D loss: 0.693532, acc.: 50.78%] [G loss: 0.847624]\n",
      "epoch:9 step:8913 [D loss: 0.688651, acc.: 56.25%] [G loss: 0.829869]\n",
      "epoch:9 step:8914 [D loss: 0.660881, acc.: 60.94%] [G loss: 0.844119]\n",
      "epoch:9 step:8915 [D loss: 0.697322, acc.: 53.91%] [G loss: 0.847558]\n",
      "epoch:9 step:8916 [D loss: 0.704930, acc.: 56.25%] [G loss: 0.852029]\n",
      "epoch:9 step:8917 [D loss: 0.653469, acc.: 63.28%] [G loss: 0.810770]\n",
      "epoch:9 step:8918 [D loss: 0.656833, acc.: 57.03%] [G loss: 0.871337]\n",
      "epoch:9 step:8919 [D loss: 0.693807, acc.: 51.56%] [G loss: 0.818117]\n",
      "epoch:9 step:8920 [D loss: 0.663447, acc.: 57.81%] [G loss: 0.796303]\n",
      "epoch:9 step:8921 [D loss: 0.662143, acc.: 57.81%] [G loss: 0.842166]\n",
      "epoch:9 step:8922 [D loss: 0.706421, acc.: 52.34%] [G loss: 0.791196]\n",
      "epoch:9 step:8923 [D loss: 0.644170, acc.: 64.06%] [G loss: 0.888421]\n",
      "epoch:9 step:8924 [D loss: 0.687559, acc.: 56.25%] [G loss: 0.843582]\n",
      "epoch:9 step:8925 [D loss: 0.671085, acc.: 57.03%] [G loss: 0.780634]\n",
      "epoch:9 step:8926 [D loss: 0.697153, acc.: 58.59%] [G loss: 0.945825]\n",
      "epoch:9 step:8927 [D loss: 0.672657, acc.: 59.38%] [G loss: 0.921172]\n",
      "epoch:9 step:8928 [D loss: 0.641121, acc.: 60.94%] [G loss: 0.747543]\n",
      "epoch:9 step:8929 [D loss: 0.654365, acc.: 58.59%] [G loss: 0.836672]\n",
      "epoch:9 step:8930 [D loss: 0.618239, acc.: 67.19%] [G loss: 0.859491]\n",
      "epoch:9 step:8931 [D loss: 0.566096, acc.: 71.88%] [G loss: 0.824005]\n",
      "epoch:9 step:8932 [D loss: 0.471249, acc.: 76.56%] [G loss: 1.037399]\n",
      "epoch:9 step:8933 [D loss: 0.765537, acc.: 48.44%] [G loss: 0.939392]\n",
      "epoch:9 step:8934 [D loss: 0.783501, acc.: 41.41%] [G loss: 0.835349]\n",
      "epoch:9 step:8935 [D loss: 0.721609, acc.: 44.53%] [G loss: 0.725648]\n",
      "epoch:9 step:8936 [D loss: 0.732007, acc.: 45.31%] [G loss: 0.795132]\n",
      "epoch:9 step:8937 [D loss: 0.709941, acc.: 44.53%] [G loss: 0.800219]\n",
      "epoch:9 step:8938 [D loss: 0.652423, acc.: 63.28%] [G loss: 0.823368]\n",
      "epoch:9 step:8939 [D loss: 0.656884, acc.: 64.06%] [G loss: 0.893331]\n",
      "epoch:9 step:8940 [D loss: 0.649691, acc.: 61.72%] [G loss: 0.966183]\n",
      "epoch:9 step:8941 [D loss: 0.611516, acc.: 63.28%] [G loss: 0.933732]\n",
      "epoch:9 step:8942 [D loss: 0.665125, acc.: 55.47%] [G loss: 0.957093]\n",
      "epoch:9 step:8943 [D loss: 0.678508, acc.: 57.81%] [G loss: 0.844771]\n",
      "epoch:9 step:8944 [D loss: 0.693303, acc.: 60.16%] [G loss: 0.843479]\n",
      "epoch:9 step:8945 [D loss: 0.670924, acc.: 54.69%] [G loss: 0.829468]\n",
      "epoch:9 step:8946 [D loss: 0.571751, acc.: 68.75%] [G loss: 0.709307]\n",
      "epoch:9 step:8947 [D loss: 0.698050, acc.: 60.16%] [G loss: 0.753399]\n",
      "epoch:9 step:8948 [D loss: 0.609416, acc.: 69.53%] [G loss: 0.820682]\n",
      "epoch:9 step:8949 [D loss: 0.665061, acc.: 60.94%] [G loss: 0.819933]\n",
      "epoch:9 step:8950 [D loss: 0.736368, acc.: 54.69%] [G loss: 0.782343]\n",
      "epoch:9 step:8951 [D loss: 0.683821, acc.: 56.25%] [G loss: 0.825610]\n",
      "epoch:9 step:8952 [D loss: 0.679729, acc.: 57.03%] [G loss: 0.809201]\n",
      "epoch:9 step:8953 [D loss: 0.650588, acc.: 62.50%] [G loss: 0.767544]\n",
      "epoch:9 step:8954 [D loss: 0.687042, acc.: 60.94%] [G loss: 0.955890]\n",
      "epoch:9 step:8955 [D loss: 0.661846, acc.: 60.94%] [G loss: 0.909515]\n",
      "epoch:9 step:8956 [D loss: 0.660970, acc.: 60.16%] [G loss: 0.824778]\n",
      "epoch:9 step:8957 [D loss: 0.721240, acc.: 53.91%] [G loss: 0.860314]\n",
      "epoch:9 step:8958 [D loss: 0.701637, acc.: 57.03%] [G loss: 0.803086]\n",
      "epoch:9 step:8959 [D loss: 0.672893, acc.: 57.81%] [G loss: 0.813664]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:9 step:8960 [D loss: 0.706803, acc.: 53.12%] [G loss: 0.768352]\n",
      "epoch:9 step:8961 [D loss: 0.777623, acc.: 43.75%] [G loss: 0.752035]\n",
      "epoch:9 step:8962 [D loss: 0.739851, acc.: 42.97%] [G loss: 0.782996]\n",
      "epoch:9 step:8963 [D loss: 0.711540, acc.: 48.44%] [G loss: 0.807681]\n",
      "epoch:9 step:8964 [D loss: 0.689162, acc.: 60.16%] [G loss: 0.817670]\n",
      "epoch:9 step:8965 [D loss: 0.697021, acc.: 52.34%] [G loss: 0.804041]\n",
      "epoch:9 step:8966 [D loss: 0.658324, acc.: 58.59%] [G loss: 0.813370]\n",
      "epoch:9 step:8967 [D loss: 0.670145, acc.: 60.16%] [G loss: 0.841763]\n",
      "epoch:9 step:8968 [D loss: 0.677550, acc.: 59.38%] [G loss: 0.860531]\n",
      "epoch:9 step:8969 [D loss: 0.627699, acc.: 66.41%] [G loss: 0.833718]\n",
      "epoch:9 step:8970 [D loss: 0.641877, acc.: 63.28%] [G loss: 0.813794]\n",
      "epoch:9 step:8971 [D loss: 0.660620, acc.: 63.28%] [G loss: 0.797311]\n",
      "epoch:9 step:8972 [D loss: 0.691172, acc.: 55.47%] [G loss: 0.881986]\n",
      "epoch:9 step:8973 [D loss: 0.668980, acc.: 58.59%] [G loss: 0.849530]\n",
      "epoch:9 step:8974 [D loss: 0.670091, acc.: 64.84%] [G loss: 0.842645]\n",
      "epoch:9 step:8975 [D loss: 0.720540, acc.: 50.00%] [G loss: 0.810383]\n",
      "epoch:9 step:8976 [D loss: 0.662507, acc.: 56.25%] [G loss: 0.851268]\n",
      "epoch:9 step:8977 [D loss: 0.684331, acc.: 52.34%] [G loss: 0.798810]\n",
      "epoch:9 step:8978 [D loss: 0.626701, acc.: 62.50%] [G loss: 0.801926]\n",
      "epoch:9 step:8979 [D loss: 0.663055, acc.: 58.59%] [G loss: 0.872284]\n",
      "epoch:9 step:8980 [D loss: 0.674091, acc.: 57.81%] [G loss: 0.768785]\n",
      "epoch:9 step:8981 [D loss: 0.630631, acc.: 63.28%] [G loss: 0.773835]\n",
      "epoch:9 step:8982 [D loss: 0.658139, acc.: 63.28%] [G loss: 0.874998]\n",
      "epoch:9 step:8983 [D loss: 0.655925, acc.: 61.72%] [G loss: 0.851854]\n",
      "epoch:9 step:8984 [D loss: 0.680925, acc.: 56.25%] [G loss: 0.877394]\n",
      "epoch:9 step:8985 [D loss: 0.661757, acc.: 63.28%] [G loss: 0.867811]\n",
      "epoch:9 step:8986 [D loss: 0.723870, acc.: 51.56%] [G loss: 0.806199]\n",
      "epoch:9 step:8987 [D loss: 0.617265, acc.: 68.75%] [G loss: 0.855271]\n",
      "epoch:9 step:8988 [D loss: 0.634221, acc.: 64.06%] [G loss: 0.847674]\n",
      "epoch:9 step:8989 [D loss: 0.628647, acc.: 62.50%] [G loss: 0.860367]\n",
      "epoch:9 step:8990 [D loss: 0.654610, acc.: 58.59%] [G loss: 0.961515]\n",
      "epoch:9 step:8991 [D loss: 0.662181, acc.: 64.84%] [G loss: 0.943308]\n",
      "epoch:9 step:8992 [D loss: 0.684704, acc.: 59.38%] [G loss: 0.867539]\n",
      "epoch:9 step:8993 [D loss: 0.703889, acc.: 53.91%] [G loss: 0.809397]\n",
      "epoch:9 step:8994 [D loss: 0.617997, acc.: 67.97%] [G loss: 0.836891]\n",
      "epoch:9 step:8995 [D loss: 0.669745, acc.: 51.56%] [G loss: 0.807490]\n",
      "epoch:9 step:8996 [D loss: 0.660386, acc.: 63.28%] [G loss: 0.916315]\n",
      "epoch:9 step:8997 [D loss: 0.638928, acc.: 61.72%] [G loss: 0.792758]\n",
      "epoch:9 step:8998 [D loss: 0.648815, acc.: 62.50%] [G loss: 0.876695]\n",
      "epoch:9 step:8999 [D loss: 0.556725, acc.: 68.75%] [G loss: 1.006009]\n",
      "epoch:9 step:9000 [D loss: 0.482765, acc.: 80.47%] [G loss: 0.970452]\n",
      "##############\n",
      "[4.31243535 2.38141193 6.5864602  5.85596411 4.91390464 6.467933\n",
      " 5.15731867 5.75402982 5.77494675 5.02862805]\n",
      "##########\n",
      "epoch:9 step:9001 [D loss: 0.529511, acc.: 77.34%] [G loss: 0.957649]\n",
      "epoch:9 step:9002 [D loss: 0.664132, acc.: 59.38%] [G loss: 1.009315]\n",
      "epoch:9 step:9003 [D loss: 0.617375, acc.: 67.19%] [G loss: 1.028671]\n",
      "epoch:9 step:9004 [D loss: 0.734145, acc.: 50.78%] [G loss: 0.788742]\n",
      "epoch:9 step:9005 [D loss: 0.676050, acc.: 58.59%] [G loss: 0.794362]\n",
      "epoch:9 step:9006 [D loss: 0.637092, acc.: 64.06%] [G loss: 0.822640]\n",
      "epoch:9 step:9007 [D loss: 0.724846, acc.: 50.00%] [G loss: 0.693051]\n",
      "epoch:9 step:9008 [D loss: 0.746001, acc.: 52.34%] [G loss: 0.891050]\n",
      "epoch:9 step:9009 [D loss: 0.733883, acc.: 49.22%] [G loss: 0.935509]\n",
      "epoch:9 step:9010 [D loss: 0.702050, acc.: 53.12%] [G loss: 0.886006]\n",
      "epoch:9 step:9011 [D loss: 0.755560, acc.: 42.19%] [G loss: 0.852649]\n",
      "epoch:9 step:9012 [D loss: 0.762895, acc.: 51.56%] [G loss: 0.836653]\n",
      "epoch:9 step:9013 [D loss: 0.715043, acc.: 51.56%] [G loss: 0.896239]\n",
      "epoch:9 step:9014 [D loss: 0.680388, acc.: 57.03%] [G loss: 0.900366]\n",
      "epoch:9 step:9015 [D loss: 0.683735, acc.: 53.12%] [G loss: 0.920228]\n",
      "epoch:9 step:9016 [D loss: 0.678776, acc.: 53.91%] [G loss: 0.924487]\n",
      "epoch:9 step:9017 [D loss: 0.685927, acc.: 56.25%] [G loss: 0.870488]\n",
      "epoch:9 step:9018 [D loss: 0.659382, acc.: 60.16%] [G loss: 0.863398]\n",
      "epoch:9 step:9019 [D loss: 0.645722, acc.: 65.62%] [G loss: 0.853869]\n",
      "epoch:9 step:9020 [D loss: 0.570138, acc.: 75.78%] [G loss: 0.936599]\n",
      "epoch:9 step:9021 [D loss: 0.645591, acc.: 62.50%] [G loss: 0.975798]\n",
      "epoch:9 step:9022 [D loss: 0.524857, acc.: 75.00%] [G loss: 0.914058]\n",
      "epoch:9 step:9023 [D loss: 0.617930, acc.: 64.06%] [G loss: 0.821995]\n",
      "epoch:9 step:9024 [D loss: 0.653489, acc.: 62.50%] [G loss: 0.849539]\n",
      "epoch:9 step:9025 [D loss: 0.680815, acc.: 57.81%] [G loss: 0.800751]\n",
      "epoch:9 step:9026 [D loss: 0.695004, acc.: 52.34%] [G loss: 0.820324]\n",
      "epoch:9 step:9027 [D loss: 0.772158, acc.: 45.31%] [G loss: 0.931633]\n",
      "epoch:9 step:9028 [D loss: 0.600140, acc.: 73.44%] [G loss: 0.931424]\n",
      "epoch:9 step:9029 [D loss: 0.691819, acc.: 56.25%] [G loss: 0.981333]\n",
      "epoch:9 step:9030 [D loss: 0.675074, acc.: 55.47%] [G loss: 0.902035]\n",
      "epoch:9 step:9031 [D loss: 0.676161, acc.: 59.38%] [G loss: 0.918112]\n",
      "epoch:9 step:9032 [D loss: 0.697084, acc.: 53.91%] [G loss: 0.974370]\n",
      "epoch:9 step:9033 [D loss: 0.637017, acc.: 59.38%] [G loss: 0.921331]\n",
      "epoch:9 step:9034 [D loss: 0.690081, acc.: 58.59%] [G loss: 0.886766]\n",
      "epoch:9 step:9035 [D loss: 0.688420, acc.: 61.72%] [G loss: 0.826971]\n",
      "epoch:9 step:9036 [D loss: 0.788901, acc.: 46.88%] [G loss: 0.798899]\n",
      "epoch:9 step:9037 [D loss: 0.682294, acc.: 57.81%] [G loss: 0.820594]\n",
      "epoch:9 step:9038 [D loss: 0.705592, acc.: 51.56%] [G loss: 0.815871]\n",
      "epoch:9 step:9039 [D loss: 0.708213, acc.: 50.00%] [G loss: 0.850372]\n",
      "epoch:9 step:9040 [D loss: 0.750411, acc.: 45.31%] [G loss: 0.875184]\n",
      "epoch:9 step:9041 [D loss: 0.693645, acc.: 55.47%] [G loss: 1.160037]\n",
      "epoch:9 step:9042 [D loss: 0.672167, acc.: 52.34%] [G loss: 0.935213]\n",
      "epoch:9 step:9043 [D loss: 0.712733, acc.: 53.12%] [G loss: 0.818212]\n",
      "epoch:9 step:9044 [D loss: 0.671482, acc.: 56.25%] [G loss: 0.784932]\n",
      "epoch:9 step:9045 [D loss: 0.653384, acc.: 63.28%] [G loss: 0.798635]\n",
      "epoch:9 step:9046 [D loss: 0.635121, acc.: 65.62%] [G loss: 0.787773]\n",
      "epoch:9 step:9047 [D loss: 0.658251, acc.: 54.69%] [G loss: 0.825181]\n",
      "epoch:9 step:9048 [D loss: 0.697702, acc.: 51.56%] [G loss: 0.747392]\n",
      "epoch:9 step:9049 [D loss: 0.685558, acc.: 57.03%] [G loss: 0.817178]\n",
      "epoch:9 step:9050 [D loss: 0.688864, acc.: 57.03%] [G loss: 0.803335]\n",
      "epoch:9 step:9051 [D loss: 0.697071, acc.: 50.78%] [G loss: 0.749537]\n",
      "epoch:9 step:9052 [D loss: 0.658809, acc.: 61.72%] [G loss: 0.839824]\n",
      "epoch:9 step:9053 [D loss: 0.688021, acc.: 53.12%] [G loss: 0.761633]\n",
      "epoch:9 step:9054 [D loss: 0.700478, acc.: 53.91%] [G loss: 0.763381]\n",
      "epoch:9 step:9055 [D loss: 0.696878, acc.: 55.47%] [G loss: 0.751062]\n",
      "epoch:9 step:9056 [D loss: 0.677683, acc.: 56.25%] [G loss: 0.845418]\n",
      "epoch:9 step:9057 [D loss: 0.645890, acc.: 64.06%] [G loss: 0.839150]\n",
      "epoch:9 step:9058 [D loss: 0.656788, acc.: 65.62%] [G loss: 0.811248]\n",
      "epoch:9 step:9059 [D loss: 0.653738, acc.: 65.62%] [G loss: 0.803752]\n",
      "epoch:9 step:9060 [D loss: 0.670548, acc.: 56.25%] [G loss: 0.749202]\n",
      "epoch:9 step:9061 [D loss: 0.674804, acc.: 59.38%] [G loss: 0.815020]\n",
      "epoch:9 step:9062 [D loss: 0.674462, acc.: 58.59%] [G loss: 0.806764]\n",
      "epoch:9 step:9063 [D loss: 0.677069, acc.: 58.59%] [G loss: 0.803170]\n",
      "epoch:9 step:9064 [D loss: 0.639413, acc.: 58.59%] [G loss: 0.745167]\n",
      "epoch:9 step:9065 [D loss: 0.656773, acc.: 64.84%] [G loss: 0.847431]\n",
      "epoch:9 step:9066 [D loss: 0.757752, acc.: 44.53%] [G loss: 0.779642]\n",
      "epoch:9 step:9067 [D loss: 0.697359, acc.: 60.16%] [G loss: 0.760756]\n",
      "epoch:9 step:9068 [D loss: 0.778489, acc.: 41.41%] [G loss: 0.760249]\n",
      "epoch:9 step:9069 [D loss: 0.685119, acc.: 60.16%] [G loss: 0.824533]\n",
      "epoch:9 step:9070 [D loss: 0.661472, acc.: 63.28%] [G loss: 0.830072]\n",
      "epoch:9 step:9071 [D loss: 0.671990, acc.: 57.03%] [G loss: 0.808838]\n",
      "epoch:9 step:9072 [D loss: 0.594920, acc.: 73.44%] [G loss: 0.840198]\n",
      "epoch:9 step:9073 [D loss: 0.617889, acc.: 70.31%] [G loss: 0.890481]\n",
      "epoch:9 step:9074 [D loss: 0.608415, acc.: 65.62%] [G loss: 0.808198]\n",
      "epoch:9 step:9075 [D loss: 0.563875, acc.: 69.53%] [G loss: 1.028344]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:9 step:9076 [D loss: 0.736889, acc.: 50.00%] [G loss: 0.862718]\n",
      "epoch:9 step:9077 [D loss: 0.740840, acc.: 47.66%] [G loss: 0.764239]\n",
      "epoch:9 step:9078 [D loss: 0.708961, acc.: 53.91%] [G loss: 0.810488]\n",
      "epoch:9 step:9079 [D loss: 0.730021, acc.: 46.88%] [G loss: 0.735693]\n",
      "epoch:9 step:9080 [D loss: 0.697734, acc.: 54.69%] [G loss: 0.715884]\n",
      "epoch:9 step:9081 [D loss: 0.672751, acc.: 61.72%] [G loss: 0.785824]\n",
      "epoch:9 step:9082 [D loss: 0.685180, acc.: 56.25%] [G loss: 0.825914]\n",
      "epoch:9 step:9083 [D loss: 0.648010, acc.: 60.16%] [G loss: 0.889710]\n",
      "epoch:9 step:9084 [D loss: 0.654866, acc.: 64.06%] [G loss: 0.811756]\n",
      "epoch:9 step:9085 [D loss: 0.715156, acc.: 50.00%] [G loss: 0.758429]\n",
      "epoch:9 step:9086 [D loss: 0.698119, acc.: 52.34%] [G loss: 0.778162]\n",
      "epoch:9 step:9087 [D loss: 0.687063, acc.: 52.34%] [G loss: 0.831707]\n",
      "epoch:9 step:9088 [D loss: 0.700045, acc.: 50.00%] [G loss: 0.850646]\n",
      "epoch:9 step:9089 [D loss: 0.678197, acc.: 57.81%] [G loss: 0.740610]\n",
      "epoch:9 step:9090 [D loss: 0.713761, acc.: 52.34%] [G loss: 0.730958]\n",
      "epoch:9 step:9091 [D loss: 0.699670, acc.: 50.00%] [G loss: 0.781166]\n",
      "epoch:9 step:9092 [D loss: 0.683138, acc.: 57.03%] [G loss: 0.758230]\n",
      "epoch:9 step:9093 [D loss: 0.650041, acc.: 66.41%] [G loss: 0.819546]\n",
      "epoch:9 step:9094 [D loss: 0.675926, acc.: 57.81%] [G loss: 0.810636]\n",
      "epoch:9 step:9095 [D loss: 0.660064, acc.: 64.06%] [G loss: 0.803715]\n",
      "epoch:9 step:9096 [D loss: 0.538042, acc.: 78.91%] [G loss: 0.837255]\n",
      "epoch:9 step:9097 [D loss: 0.588221, acc.: 77.34%] [G loss: 0.845293]\n",
      "epoch:9 step:9098 [D loss: 0.620443, acc.: 65.62%] [G loss: 0.869269]\n",
      "epoch:9 step:9099 [D loss: 0.689483, acc.: 56.25%] [G loss: 0.851390]\n",
      "epoch:9 step:9100 [D loss: 0.702542, acc.: 56.25%] [G loss: 0.817744]\n",
      "epoch:9 step:9101 [D loss: 0.627066, acc.: 63.28%] [G loss: 0.698980]\n",
      "epoch:9 step:9102 [D loss: 0.652402, acc.: 62.50%] [G loss: 0.842059]\n",
      "epoch:9 step:9103 [D loss: 0.631393, acc.: 63.28%] [G loss: 0.788598]\n",
      "epoch:9 step:9104 [D loss: 0.692394, acc.: 57.03%] [G loss: 0.825600]\n",
      "epoch:9 step:9105 [D loss: 0.708759, acc.: 52.34%] [G loss: 0.781068]\n",
      "epoch:9 step:9106 [D loss: 0.735031, acc.: 52.34%] [G loss: 0.787878]\n",
      "epoch:9 step:9107 [D loss: 0.640308, acc.: 64.06%] [G loss: 0.797912]\n",
      "epoch:9 step:9108 [D loss: 0.719935, acc.: 46.09%] [G loss: 0.806605]\n",
      "epoch:9 step:9109 [D loss: 0.693087, acc.: 50.00%] [G loss: 0.814240]\n",
      "epoch:9 step:9110 [D loss: 0.714790, acc.: 47.66%] [G loss: 0.798113]\n",
      "epoch:9 step:9111 [D loss: 0.742937, acc.: 48.44%] [G loss: 0.794741]\n",
      "epoch:9 step:9112 [D loss: 0.697201, acc.: 50.78%] [G loss: 0.813037]\n",
      "epoch:9 step:9113 [D loss: 0.650505, acc.: 58.59%] [G loss: 0.852285]\n",
      "epoch:9 step:9114 [D loss: 0.674070, acc.: 58.59%] [G loss: 0.855062]\n",
      "epoch:9 step:9115 [D loss: 0.698471, acc.: 56.25%] [G loss: 0.818764]\n",
      "epoch:9 step:9116 [D loss: 0.695166, acc.: 54.69%] [G loss: 0.820749]\n",
      "epoch:9 step:9117 [D loss: 0.700292, acc.: 50.00%] [G loss: 0.811899]\n",
      "epoch:9 step:9118 [D loss: 0.699706, acc.: 50.00%] [G loss: 0.784820]\n",
      "epoch:9 step:9119 [D loss: 0.680817, acc.: 57.03%] [G loss: 0.797576]\n",
      "epoch:9 step:9120 [D loss: 0.671523, acc.: 57.81%] [G loss: 0.837902]\n",
      "epoch:9 step:9121 [D loss: 0.679700, acc.: 60.94%] [G loss: 0.929437]\n",
      "epoch:9 step:9122 [D loss: 0.692898, acc.: 52.34%] [G loss: 0.755804]\n",
      "epoch:9 step:9123 [D loss: 0.749641, acc.: 49.22%] [G loss: 0.763585]\n",
      "epoch:9 step:9124 [D loss: 0.699029, acc.: 55.47%] [G loss: 0.787020]\n",
      "epoch:9 step:9125 [D loss: 0.688839, acc.: 59.38%] [G loss: 0.763553]\n",
      "epoch:9 step:9126 [D loss: 0.683020, acc.: 52.34%] [G loss: 0.761953]\n",
      "epoch:9 step:9127 [D loss: 0.658004, acc.: 57.03%] [G loss: 0.813145]\n",
      "epoch:9 step:9128 [D loss: 0.716707, acc.: 43.75%] [G loss: 0.803406]\n",
      "epoch:9 step:9129 [D loss: 0.701787, acc.: 51.56%] [G loss: 0.774311]\n",
      "epoch:9 step:9130 [D loss: 0.674939, acc.: 62.50%] [G loss: 0.786295]\n",
      "epoch:9 step:9131 [D loss: 0.707763, acc.: 52.34%] [G loss: 0.809374]\n",
      "epoch:9 step:9132 [D loss: 0.670802, acc.: 60.16%] [G loss: 0.847809]\n",
      "epoch:9 step:9133 [D loss: 0.679919, acc.: 53.12%] [G loss: 0.840049]\n",
      "epoch:9 step:9134 [D loss: 0.639760, acc.: 64.84%] [G loss: 0.857296]\n",
      "epoch:9 step:9135 [D loss: 0.615679, acc.: 68.75%] [G loss: 0.804261]\n",
      "epoch:9 step:9136 [D loss: 0.756352, acc.: 49.22%] [G loss: 0.823834]\n",
      "epoch:9 step:9137 [D loss: 0.691640, acc.: 56.25%] [G loss: 0.847211]\n",
      "epoch:9 step:9138 [D loss: 0.676269, acc.: 57.03%] [G loss: 0.937717]\n",
      "epoch:9 step:9139 [D loss: 0.553362, acc.: 71.88%] [G loss: 0.869110]\n",
      "epoch:9 step:9140 [D loss: 0.428659, acc.: 84.38%] [G loss: 0.885851]\n",
      "epoch:9 step:9141 [D loss: 0.570323, acc.: 78.91%] [G loss: 0.866291]\n",
      "epoch:9 step:9142 [D loss: 0.563989, acc.: 77.34%] [G loss: 0.848130]\n",
      "epoch:9 step:9143 [D loss: 0.736888, acc.: 46.09%] [G loss: 0.782045]\n",
      "epoch:9 step:9144 [D loss: 0.724601, acc.: 47.66%] [G loss: 0.814313]\n",
      "epoch:9 step:9145 [D loss: 0.664980, acc.: 60.94%] [G loss: 0.804015]\n",
      "epoch:9 step:9146 [D loss: 0.433314, acc.: 85.94%] [G loss: 1.021575]\n",
      "epoch:9 step:9147 [D loss: 0.439070, acc.: 80.47%] [G loss: 0.987305]\n",
      "epoch:9 step:9148 [D loss: 0.690346, acc.: 57.81%] [G loss: 0.771801]\n",
      "epoch:9 step:9149 [D loss: 0.707135, acc.: 55.47%] [G loss: 0.674919]\n",
      "epoch:9 step:9150 [D loss: 0.693776, acc.: 55.47%] [G loss: 0.850785]\n",
      "epoch:9 step:9151 [D loss: 1.332150, acc.: 30.47%] [G loss: 0.783661]\n",
      "epoch:9 step:9152 [D loss: 0.668606, acc.: 60.16%] [G loss: 0.887659]\n",
      "epoch:9 step:9153 [D loss: 0.682998, acc.: 60.16%] [G loss: 0.841991]\n",
      "epoch:9 step:9154 [D loss: 0.740764, acc.: 47.66%] [G loss: 0.843180]\n",
      "epoch:9 step:9155 [D loss: 0.702001, acc.: 53.12%] [G loss: 0.863238]\n",
      "epoch:9 step:9156 [D loss: 0.660316, acc.: 62.50%] [G loss: 0.861992]\n",
      "epoch:9 step:9157 [D loss: 0.702180, acc.: 58.59%] [G loss: 0.813962]\n",
      "epoch:9 step:9158 [D loss: 0.708289, acc.: 50.78%] [G loss: 0.891398]\n",
      "epoch:9 step:9159 [D loss: 0.675687, acc.: 59.38%] [G loss: 0.873370]\n",
      "epoch:9 step:9160 [D loss: 0.692935, acc.: 56.25%] [G loss: 0.806814]\n",
      "epoch:9 step:9161 [D loss: 0.595961, acc.: 64.84%] [G loss: 0.811870]\n",
      "epoch:9 step:9162 [D loss: 0.638094, acc.: 64.06%] [G loss: 0.792943]\n",
      "epoch:9 step:9163 [D loss: 0.582661, acc.: 73.44%] [G loss: 0.786803]\n",
      "epoch:9 step:9164 [D loss: 0.629076, acc.: 57.81%] [G loss: 0.616882]\n",
      "epoch:9 step:9165 [D loss: 0.508946, acc.: 77.34%] [G loss: 0.696928]\n",
      "epoch:9 step:9166 [D loss: 0.487271, acc.: 86.72%] [G loss: 0.757500]\n",
      "epoch:9 step:9167 [D loss: 0.886821, acc.: 42.97%] [G loss: 0.691712]\n",
      "epoch:9 step:9168 [D loss: 0.675479, acc.: 53.91%] [G loss: 0.967957]\n",
      "epoch:9 step:9169 [D loss: 0.850338, acc.: 36.72%] [G loss: 0.971503]\n",
      "epoch:9 step:9170 [D loss: 0.690553, acc.: 57.03%] [G loss: 1.070470]\n",
      "epoch:9 step:9171 [D loss: 0.664222, acc.: 57.03%] [G loss: 1.051032]\n",
      "epoch:9 step:9172 [D loss: 0.684594, acc.: 59.38%] [G loss: 0.915339]\n",
      "epoch:9 step:9173 [D loss: 0.655290, acc.: 61.72%] [G loss: 0.935499]\n",
      "epoch:9 step:9174 [D loss: 0.622736, acc.: 63.28%] [G loss: 0.951933]\n",
      "epoch:9 step:9175 [D loss: 0.667579, acc.: 62.50%] [G loss: 1.037810]\n",
      "epoch:9 step:9176 [D loss: 0.637839, acc.: 59.38%] [G loss: 1.033990]\n",
      "epoch:9 step:9177 [D loss: 0.735848, acc.: 59.38%] [G loss: 0.901381]\n",
      "epoch:9 step:9178 [D loss: 0.808152, acc.: 39.84%] [G loss: 0.976624]\n",
      "epoch:9 step:9179 [D loss: 0.684035, acc.: 57.81%] [G loss: 0.864602]\n",
      "epoch:9 step:9180 [D loss: 0.694708, acc.: 52.34%] [G loss: 0.845185]\n",
      "epoch:9 step:9181 [D loss: 0.692392, acc.: 49.22%] [G loss: 0.867614]\n",
      "epoch:9 step:9182 [D loss: 0.656433, acc.: 61.72%] [G loss: 0.917936]\n",
      "epoch:9 step:9183 [D loss: 0.612728, acc.: 62.50%] [G loss: 0.879730]\n",
      "epoch:9 step:9184 [D loss: 0.675763, acc.: 58.59%] [G loss: 0.873252]\n",
      "epoch:9 step:9185 [D loss: 0.689721, acc.: 52.34%] [G loss: 0.841529]\n",
      "epoch:9 step:9186 [D loss: 0.693300, acc.: 54.69%] [G loss: 0.789964]\n",
      "epoch:9 step:9187 [D loss: 0.748774, acc.: 40.62%] [G loss: 0.808417]\n",
      "epoch:9 step:9188 [D loss: 0.679694, acc.: 57.81%] [G loss: 0.829197]\n",
      "epoch:9 step:9189 [D loss: 0.648914, acc.: 62.50%] [G loss: 0.892378]\n",
      "epoch:9 step:9190 [D loss: 0.692959, acc.: 51.56%] [G loss: 0.860321]\n",
      "epoch:9 step:9191 [D loss: 0.663289, acc.: 59.38%] [G loss: 0.863821]\n",
      "epoch:9 step:9192 [D loss: 0.660512, acc.: 64.84%] [G loss: 0.869129]\n",
      "epoch:9 step:9193 [D loss: 0.686133, acc.: 59.38%] [G loss: 0.851081]\n",
      "epoch:9 step:9194 [D loss: 0.628546, acc.: 64.06%] [G loss: 0.902050]\n",
      "epoch:9 step:9195 [D loss: 0.694057, acc.: 49.22%] [G loss: 0.894700]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:9 step:9196 [D loss: 0.669065, acc.: 57.81%] [G loss: 0.973547]\n",
      "epoch:9 step:9197 [D loss: 0.571456, acc.: 72.66%] [G loss: 0.943604]\n",
      "epoch:9 step:9198 [D loss: 0.721063, acc.: 51.56%] [G loss: 0.836548]\n",
      "epoch:9 step:9199 [D loss: 0.642001, acc.: 65.62%] [G loss: 0.868655]\n",
      "epoch:9 step:9200 [D loss: 0.680993, acc.: 52.34%] [G loss: 0.725267]\n",
      "##############\n",
      "[4.13030145 2.21295521 6.36685753 5.13528578 4.25370509 5.83062702\n",
      " 4.95522818 5.30808053 5.70832496 4.78557016]\n",
      "##########\n",
      "epoch:9 step:9201 [D loss: 0.645749, acc.: 64.06%] [G loss: 0.866499]\n",
      "epoch:9 step:9202 [D loss: 0.673029, acc.: 57.03%] [G loss: 0.736520]\n",
      "epoch:9 step:9203 [D loss: 0.658005, acc.: 55.47%] [G loss: 0.773569]\n",
      "epoch:9 step:9204 [D loss: 0.689792, acc.: 53.91%] [G loss: 0.749475]\n",
      "epoch:9 step:9205 [D loss: 0.730086, acc.: 49.22%] [G loss: 0.811458]\n",
      "epoch:9 step:9206 [D loss: 0.693492, acc.: 52.34%] [G loss: 0.845778]\n",
      "epoch:9 step:9207 [D loss: 0.677959, acc.: 57.03%] [G loss: 0.814879]\n",
      "epoch:9 step:9208 [D loss: 0.644166, acc.: 64.84%] [G loss: 0.988543]\n",
      "epoch:9 step:9209 [D loss: 0.689164, acc.: 60.16%] [G loss: 0.962506]\n",
      "epoch:9 step:9210 [D loss: 0.679054, acc.: 56.25%] [G loss: 0.936877]\n",
      "epoch:9 step:9211 [D loss: 0.709946, acc.: 53.12%] [G loss: 0.816583]\n",
      "epoch:9 step:9212 [D loss: 0.721816, acc.: 44.53%] [G loss: 0.833697]\n",
      "epoch:9 step:9213 [D loss: 0.740428, acc.: 47.66%] [G loss: 0.761326]\n",
      "epoch:9 step:9214 [D loss: 0.692658, acc.: 54.69%] [G loss: 0.746256]\n",
      "epoch:9 step:9215 [D loss: 0.644589, acc.: 61.72%] [G loss: 0.825945]\n",
      "epoch:9 step:9216 [D loss: 0.707204, acc.: 53.91%] [G loss: 0.799482]\n",
      "epoch:9 step:9217 [D loss: 0.681273, acc.: 48.44%] [G loss: 0.831596]\n",
      "epoch:9 step:9218 [D loss: 0.659145, acc.: 58.59%] [G loss: 0.829164]\n",
      "epoch:9 step:9219 [D loss: 0.680357, acc.: 55.47%] [G loss: 0.804859]\n",
      "epoch:9 step:9220 [D loss: 0.705419, acc.: 55.47%] [G loss: 0.755959]\n",
      "epoch:9 step:9221 [D loss: 0.685207, acc.: 53.12%] [G loss: 0.803328]\n",
      "epoch:9 step:9222 [D loss: 0.686638, acc.: 53.91%] [G loss: 0.757655]\n",
      "epoch:9 step:9223 [D loss: 0.614637, acc.: 66.41%] [G loss: 0.832274]\n",
      "epoch:9 step:9224 [D loss: 0.604264, acc.: 64.84%] [G loss: 0.819304]\n",
      "epoch:9 step:9225 [D loss: 0.579885, acc.: 74.22%] [G loss: 0.825564]\n",
      "epoch:9 step:9226 [D loss: 0.601654, acc.: 67.19%] [G loss: 0.726830]\n",
      "epoch:9 step:9227 [D loss: 0.654143, acc.: 62.50%] [G loss: 0.805208]\n",
      "epoch:9 step:9228 [D loss: 0.670312, acc.: 57.81%] [G loss: 0.813655]\n",
      "epoch:9 step:9229 [D loss: 0.612489, acc.: 65.62%] [G loss: 0.735192]\n",
      "epoch:9 step:9230 [D loss: 0.670515, acc.: 54.69%] [G loss: 0.751786]\n",
      "epoch:9 step:9231 [D loss: 0.693424, acc.: 58.59%] [G loss: 0.838149]\n",
      "epoch:9 step:9232 [D loss: 0.655609, acc.: 62.50%] [G loss: 0.843674]\n",
      "epoch:9 step:9233 [D loss: 0.717163, acc.: 50.78%] [G loss: 0.828205]\n",
      "epoch:9 step:9234 [D loss: 0.757698, acc.: 47.66%] [G loss: 0.921058]\n",
      "epoch:9 step:9235 [D loss: 0.639605, acc.: 62.50%] [G loss: 1.053470]\n",
      "epoch:9 step:9236 [D loss: 0.706628, acc.: 53.12%] [G loss: 0.970094]\n",
      "epoch:9 step:9237 [D loss: 0.746425, acc.: 64.84%] [G loss: 0.864350]\n",
      "epoch:9 step:9238 [D loss: 0.681817, acc.: 55.47%] [G loss: 0.811431]\n",
      "epoch:9 step:9239 [D loss: 0.572454, acc.: 70.31%] [G loss: 0.846723]\n",
      "epoch:9 step:9240 [D loss: 0.659674, acc.: 60.16%] [G loss: 0.811959]\n",
      "epoch:9 step:9241 [D loss: 0.693098, acc.: 53.91%] [G loss: 0.838161]\n",
      "epoch:9 step:9242 [D loss: 0.662959, acc.: 57.03%] [G loss: 0.850499]\n",
      "epoch:9 step:9243 [D loss: 0.665495, acc.: 60.94%] [G loss: 0.813331]\n",
      "epoch:9 step:9244 [D loss: 0.650678, acc.: 59.38%] [G loss: 0.819491]\n",
      "epoch:9 step:9245 [D loss: 0.685048, acc.: 59.38%] [G loss: 0.805551]\n",
      "epoch:9 step:9246 [D loss: 0.677677, acc.: 53.91%] [G loss: 0.794296]\n",
      "epoch:9 step:9247 [D loss: 0.660662, acc.: 56.25%] [G loss: 0.850317]\n",
      "epoch:9 step:9248 [D loss: 0.663126, acc.: 61.72%] [G loss: 0.815557]\n",
      "epoch:9 step:9249 [D loss: 0.679867, acc.: 55.47%] [G loss: 0.794968]\n",
      "epoch:9 step:9250 [D loss: 0.688659, acc.: 50.00%] [G loss: 0.812236]\n",
      "epoch:9 step:9251 [D loss: 0.746324, acc.: 45.31%] [G loss: 0.786789]\n",
      "epoch:9 step:9252 [D loss: 0.669054, acc.: 57.81%] [G loss: 0.824385]\n",
      "epoch:9 step:9253 [D loss: 0.719124, acc.: 48.44%] [G loss: 0.815174]\n",
      "epoch:9 step:9254 [D loss: 0.683087, acc.: 56.25%] [G loss: 0.895851]\n",
      "epoch:9 step:9255 [D loss: 0.673176, acc.: 58.59%] [G loss: 0.854452]\n",
      "epoch:9 step:9256 [D loss: 0.700899, acc.: 49.22%] [G loss: 0.830507]\n",
      "epoch:9 step:9257 [D loss: 0.662373, acc.: 64.06%] [G loss: 0.877603]\n",
      "epoch:9 step:9258 [D loss: 0.642351, acc.: 65.62%] [G loss: 0.793179]\n",
      "epoch:9 step:9259 [D loss: 0.703041, acc.: 57.03%] [G loss: 0.798282]\n",
      "epoch:9 step:9260 [D loss: 0.700979, acc.: 46.88%] [G loss: 0.781442]\n",
      "epoch:9 step:9261 [D loss: 0.704774, acc.: 46.09%] [G loss: 0.847801]\n",
      "epoch:9 step:9262 [D loss: 0.656210, acc.: 60.94%] [G loss: 0.812091]\n",
      "epoch:9 step:9263 [D loss: 0.664824, acc.: 60.94%] [G loss: 0.783619]\n",
      "epoch:9 step:9264 [D loss: 0.647073, acc.: 64.06%] [G loss: 0.806530]\n",
      "epoch:9 step:9265 [D loss: 0.634805, acc.: 63.28%] [G loss: 0.714779]\n",
      "epoch:9 step:9266 [D loss: 0.659638, acc.: 60.94%] [G loss: 0.801645]\n",
      "epoch:9 step:9267 [D loss: 0.719859, acc.: 59.38%] [G loss: 0.788842]\n",
      "epoch:9 step:9268 [D loss: 0.733083, acc.: 54.69%] [G loss: 0.767068]\n",
      "epoch:9 step:9269 [D loss: 0.689186, acc.: 56.25%] [G loss: 0.755560]\n",
      "epoch:9 step:9270 [D loss: 0.659033, acc.: 60.16%] [G loss: 0.834911]\n",
      "epoch:9 step:9271 [D loss: 0.617436, acc.: 67.19%] [G loss: 0.905189]\n",
      "epoch:9 step:9272 [D loss: 0.630819, acc.: 62.50%] [G loss: 0.712382]\n",
      "epoch:9 step:9273 [D loss: 0.655619, acc.: 64.06%] [G loss: 0.809842]\n",
      "epoch:9 step:9274 [D loss: 0.639063, acc.: 58.59%] [G loss: 0.725841]\n",
      "epoch:9 step:9275 [D loss: 0.656811, acc.: 60.16%] [G loss: 0.881071]\n",
      "epoch:9 step:9276 [D loss: 0.713216, acc.: 49.22%] [G loss: 0.866364]\n",
      "epoch:9 step:9277 [D loss: 0.675392, acc.: 51.56%] [G loss: 0.849538]\n",
      "epoch:9 step:9278 [D loss: 0.682850, acc.: 53.12%] [G loss: 0.719716]\n",
      "epoch:9 step:9279 [D loss: 0.642189, acc.: 58.59%] [G loss: 0.815746]\n",
      "epoch:9 step:9280 [D loss: 0.654487, acc.: 63.28%] [G loss: 0.867204]\n",
      "epoch:9 step:9281 [D loss: 0.718266, acc.: 49.22%] [G loss: 0.749898]\n",
      "epoch:9 step:9282 [D loss: 0.691330, acc.: 60.16%] [G loss: 0.807396]\n",
      "epoch:9 step:9283 [D loss: 0.525155, acc.: 74.22%] [G loss: 0.882842]\n",
      "epoch:9 step:9284 [D loss: 0.614021, acc.: 64.84%] [G loss: 0.885741]\n",
      "epoch:9 step:9285 [D loss: 0.556376, acc.: 75.78%] [G loss: 0.871539]\n",
      "epoch:9 step:9286 [D loss: 0.726839, acc.: 51.56%] [G loss: 0.943163]\n",
      "epoch:9 step:9287 [D loss: 0.656539, acc.: 56.25%] [G loss: 1.157443]\n",
      "epoch:9 step:9288 [D loss: 0.695171, acc.: 59.38%] [G loss: 0.953452]\n",
      "epoch:9 step:9289 [D loss: 0.746250, acc.: 43.75%] [G loss: 0.954864]\n",
      "epoch:9 step:9290 [D loss: 0.740846, acc.: 50.78%] [G loss: 0.936283]\n",
      "epoch:9 step:9291 [D loss: 0.797588, acc.: 39.84%] [G loss: 0.820083]\n",
      "epoch:9 step:9292 [D loss: 0.824971, acc.: 33.59%] [G loss: 0.982125]\n",
      "epoch:9 step:9293 [D loss: 0.691244, acc.: 58.59%] [G loss: 0.868325]\n",
      "epoch:9 step:9294 [D loss: 0.704487, acc.: 55.47%] [G loss: 0.989198]\n",
      "epoch:9 step:9295 [D loss: 0.682807, acc.: 53.91%] [G loss: 0.916379]\n",
      "epoch:9 step:9296 [D loss: 0.672670, acc.: 55.47%] [G loss: 0.924283]\n",
      "epoch:9 step:9297 [D loss: 0.648445, acc.: 60.16%] [G loss: 0.915976]\n",
      "epoch:9 step:9298 [D loss: 0.708282, acc.: 51.56%] [G loss: 0.940713]\n",
      "epoch:9 step:9299 [D loss: 0.663700, acc.: 53.91%] [G loss: 0.895715]\n",
      "epoch:9 step:9300 [D loss: 0.684346, acc.: 49.22%] [G loss: 0.869326]\n",
      "epoch:9 step:9301 [D loss: 0.651945, acc.: 67.19%] [G loss: 0.847418]\n",
      "epoch:9 step:9302 [D loss: 0.662284, acc.: 53.91%] [G loss: 0.927370]\n",
      "epoch:9 step:9303 [D loss: 0.654492, acc.: 65.62%] [G loss: 0.868838]\n",
      "epoch:9 step:9304 [D loss: 0.663242, acc.: 64.84%] [G loss: 0.865111]\n",
      "epoch:9 step:9305 [D loss: 0.724567, acc.: 51.56%] [G loss: 0.792270]\n",
      "epoch:9 step:9306 [D loss: 0.679645, acc.: 57.03%] [G loss: 0.804929]\n",
      "epoch:9 step:9307 [D loss: 0.657398, acc.: 60.16%] [G loss: 0.880438]\n",
      "epoch:9 step:9308 [D loss: 0.682739, acc.: 63.28%] [G loss: 0.809167]\n",
      "epoch:9 step:9309 [D loss: 0.675291, acc.: 59.38%] [G loss: 0.818611]\n",
      "epoch:9 step:9310 [D loss: 0.703830, acc.: 54.69%] [G loss: 0.739661]\n",
      "epoch:9 step:9311 [D loss: 0.640297, acc.: 65.62%] [G loss: 0.826888]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:9 step:9312 [D loss: 0.725513, acc.: 43.75%] [G loss: 0.818446]\n",
      "epoch:9 step:9313 [D loss: 0.717917, acc.: 51.56%] [G loss: 0.880879]\n",
      "epoch:9 step:9314 [D loss: 0.714436, acc.: 52.34%] [G loss: 0.796920]\n",
      "epoch:9 step:9315 [D loss: 0.716891, acc.: 47.66%] [G loss: 0.774914]\n",
      "epoch:9 step:9316 [D loss: 0.682237, acc.: 51.56%] [G loss: 0.763919]\n",
      "epoch:9 step:9317 [D loss: 0.664873, acc.: 57.03%] [G loss: 0.735040]\n",
      "epoch:9 step:9318 [D loss: 0.611510, acc.: 64.06%] [G loss: 0.776964]\n",
      "epoch:9 step:9319 [D loss: 0.568350, acc.: 78.12%] [G loss: 0.808416]\n",
      "epoch:9 step:9320 [D loss: 0.608397, acc.: 65.62%] [G loss: 0.823059]\n",
      "epoch:9 step:9321 [D loss: 0.623413, acc.: 67.19%] [G loss: 0.846849]\n",
      "epoch:9 step:9322 [D loss: 0.517409, acc.: 78.12%] [G loss: 0.811852]\n",
      "epoch:9 step:9323 [D loss: 0.514297, acc.: 75.78%] [G loss: 0.814255]\n",
      "epoch:9 step:9324 [D loss: 0.693263, acc.: 60.16%] [G loss: 0.843792]\n",
      "epoch:9 step:9325 [D loss: 0.805152, acc.: 36.72%] [G loss: 0.841984]\n",
      "epoch:9 step:9326 [D loss: 0.700907, acc.: 50.00%] [G loss: 0.806218]\n",
      "epoch:9 step:9327 [D loss: 0.719121, acc.: 42.19%] [G loss: 0.630473]\n",
      "epoch:9 step:9328 [D loss: 0.726316, acc.: 48.44%] [G loss: 0.761374]\n",
      "epoch:9 step:9329 [D loss: 0.717918, acc.: 47.66%] [G loss: 0.809041]\n",
      "epoch:9 step:9330 [D loss: 0.659989, acc.: 59.38%] [G loss: 0.809060]\n",
      "epoch:9 step:9331 [D loss: 0.633526, acc.: 58.59%] [G loss: 0.856166]\n",
      "epoch:9 step:9332 [D loss: 0.607226, acc.: 70.31%] [G loss: 0.869493]\n",
      "epoch:9 step:9333 [D loss: 0.777293, acc.: 42.19%] [G loss: 0.948040]\n",
      "epoch:9 step:9334 [D loss: 0.726406, acc.: 54.69%] [G loss: 0.996766]\n",
      "epoch:9 step:9335 [D loss: 0.677162, acc.: 57.03%] [G loss: 0.936568]\n",
      "epoch:9 step:9336 [D loss: 0.649611, acc.: 60.94%] [G loss: 0.967409]\n",
      "epoch:9 step:9337 [D loss: 0.802982, acc.: 54.69%] [G loss: 0.928908]\n",
      "epoch:9 step:9338 [D loss: 0.729360, acc.: 53.12%] [G loss: 0.820100]\n",
      "epoch:9 step:9339 [D loss: 0.654849, acc.: 60.16%] [G loss: 0.787287]\n",
      "epoch:9 step:9340 [D loss: 0.698324, acc.: 54.69%] [G loss: 0.772259]\n",
      "epoch:9 step:9341 [D loss: 0.676488, acc.: 56.25%] [G loss: 0.728531]\n",
      "epoch:9 step:9342 [D loss: 0.678403, acc.: 56.25%] [G loss: 0.773573]\n",
      "epoch:9 step:9343 [D loss: 0.632433, acc.: 58.59%] [G loss: 0.743373]\n",
      "epoch:9 step:9344 [D loss: 0.678531, acc.: 53.91%] [G loss: 0.771172]\n",
      "epoch:9 step:9345 [D loss: 0.554013, acc.: 75.00%] [G loss: 0.800391]\n",
      "epoch:9 step:9346 [D loss: 0.701554, acc.: 53.91%] [G loss: 0.807235]\n",
      "epoch:9 step:9347 [D loss: 0.689869, acc.: 51.56%] [G loss: 0.808583]\n",
      "epoch:9 step:9348 [D loss: 0.655771, acc.: 64.06%] [G loss: 0.741026]\n",
      "epoch:9 step:9349 [D loss: 0.673580, acc.: 58.59%] [G loss: 0.777352]\n",
      "epoch:9 step:9350 [D loss: 0.643980, acc.: 64.06%] [G loss: 0.809311]\n",
      "epoch:9 step:9351 [D loss: 0.607610, acc.: 69.53%] [G loss: 0.830650]\n",
      "epoch:9 step:9352 [D loss: 0.570883, acc.: 75.00%] [G loss: 0.905641]\n",
      "epoch:9 step:9353 [D loss: 0.724795, acc.: 52.34%] [G loss: 0.841479]\n",
      "epoch:9 step:9354 [D loss: 0.714780, acc.: 48.44%] [G loss: 0.851767]\n",
      "epoch:9 step:9355 [D loss: 0.581288, acc.: 75.00%] [G loss: 0.927792]\n",
      "epoch:9 step:9356 [D loss: 0.548930, acc.: 75.78%] [G loss: 0.926847]\n",
      "epoch:9 step:9357 [D loss: 0.540096, acc.: 79.69%] [G loss: 1.010980]\n",
      "epoch:9 step:9358 [D loss: 0.559407, acc.: 74.22%] [G loss: 0.935591]\n",
      "epoch:9 step:9359 [D loss: 0.516365, acc.: 76.56%] [G loss: 0.888579]\n",
      "epoch:9 step:9360 [D loss: 0.636146, acc.: 66.41%] [G loss: 0.896100]\n",
      "epoch:9 step:9361 [D loss: 0.749017, acc.: 53.12%] [G loss: 0.848134]\n",
      "epoch:9 step:9362 [D loss: 0.401024, acc.: 90.62%] [G loss: 0.959805]\n",
      "epoch:9 step:9363 [D loss: 0.559709, acc.: 75.78%] [G loss: 1.064914]\n",
      "epoch:9 step:9364 [D loss: 0.570083, acc.: 74.22%] [G loss: 0.773986]\n",
      "epoch:9 step:9365 [D loss: 0.834338, acc.: 39.84%] [G loss: 0.858898]\n",
      "epoch:9 step:9366 [D loss: 0.673210, acc.: 56.25%] [G loss: 0.794716]\n",
      "epoch:9 step:9367 [D loss: 0.589669, acc.: 67.97%] [G loss: 0.791969]\n",
      "epoch:9 step:9368 [D loss: 0.530419, acc.: 78.91%] [G loss: 0.701853]\n",
      "epoch:9 step:9369 [D loss: 0.499693, acc.: 75.78%] [G loss: 0.747557]\n",
      "epoch:9 step:9370 [D loss: 0.519427, acc.: 77.34%] [G loss: 0.922059]\n",
      "epoch:10 step:9371 [D loss: 0.699362, acc.: 61.72%] [G loss: 0.854500]\n",
      "epoch:10 step:9372 [D loss: 0.821469, acc.: 39.06%] [G loss: 0.855852]\n",
      "epoch:10 step:9373 [D loss: 0.821629, acc.: 37.50%] [G loss: 0.912024]\n",
      "epoch:10 step:9374 [D loss: 0.788716, acc.: 37.50%] [G loss: 0.850922]\n",
      "epoch:10 step:9375 [D loss: 0.702601, acc.: 53.91%] [G loss: 0.819849]\n",
      "epoch:10 step:9376 [D loss: 0.780210, acc.: 39.84%] [G loss: 0.829951]\n",
      "epoch:10 step:9377 [D loss: 0.701968, acc.: 50.78%] [G loss: 0.717572]\n",
      "epoch:10 step:9378 [D loss: 0.754997, acc.: 40.62%] [G loss: 0.862294]\n",
      "epoch:10 step:9379 [D loss: 0.695974, acc.: 54.69%] [G loss: 0.824034]\n",
      "epoch:10 step:9380 [D loss: 0.713051, acc.: 49.22%] [G loss: 0.841454]\n",
      "epoch:10 step:9381 [D loss: 0.644186, acc.: 62.50%] [G loss: 0.875460]\n",
      "epoch:10 step:9382 [D loss: 0.701492, acc.: 57.03%] [G loss: 0.921911]\n",
      "epoch:10 step:9383 [D loss: 0.665101, acc.: 61.72%] [G loss: 0.856693]\n",
      "epoch:10 step:9384 [D loss: 0.670273, acc.: 59.38%] [G loss: 0.956200]\n",
      "epoch:10 step:9385 [D loss: 0.701489, acc.: 57.03%] [G loss: 0.900147]\n",
      "epoch:10 step:9386 [D loss: 0.679969, acc.: 65.62%] [G loss: 0.811332]\n",
      "epoch:10 step:9387 [D loss: 0.752717, acc.: 44.53%] [G loss: 0.798572]\n",
      "epoch:10 step:9388 [D loss: 0.669202, acc.: 58.59%] [G loss: 0.872423]\n",
      "epoch:10 step:9389 [D loss: 0.648745, acc.: 61.72%] [G loss: 0.948786]\n",
      "epoch:10 step:9390 [D loss: 0.661442, acc.: 63.28%] [G loss: 0.839331]\n",
      "epoch:10 step:9391 [D loss: 0.642208, acc.: 66.41%] [G loss: 0.861887]\n",
      "epoch:10 step:9392 [D loss: 0.650242, acc.: 58.59%] [G loss: 0.915494]\n",
      "epoch:10 step:9393 [D loss: 0.699404, acc.: 49.22%] [G loss: 0.900731]\n",
      "epoch:10 step:9394 [D loss: 0.709561, acc.: 49.22%] [G loss: 0.856116]\n",
      "epoch:10 step:9395 [D loss: 0.619780, acc.: 69.53%] [G loss: 0.936243]\n",
      "epoch:10 step:9396 [D loss: 0.697468, acc.: 56.25%] [G loss: 0.903316]\n",
      "epoch:10 step:9397 [D loss: 0.632907, acc.: 61.72%] [G loss: 0.992361]\n",
      "epoch:10 step:9398 [D loss: 0.615993, acc.: 62.50%] [G loss: 0.973684]\n",
      "epoch:10 step:9399 [D loss: 0.612969, acc.: 71.88%] [G loss: 0.998074]\n",
      "epoch:10 step:9400 [D loss: 0.595327, acc.: 75.78%] [G loss: 1.087424]\n",
      "##############\n",
      "[4.60835626 2.23778118 6.61132822 5.59703987 4.70475446 6.08921801\n",
      " 5.35158465 5.84721848 5.86525983 5.29993065]\n",
      "##########\n",
      "epoch:10 step:9401 [D loss: 0.602825, acc.: 69.53%] [G loss: 1.059694]\n",
      "epoch:10 step:9402 [D loss: 0.662504, acc.: 59.38%] [G loss: 0.944616]\n",
      "epoch:10 step:9403 [D loss: 0.625031, acc.: 64.06%] [G loss: 0.739372]\n",
      "epoch:10 step:9404 [D loss: 0.757725, acc.: 54.69%] [G loss: 1.047585]\n",
      "epoch:10 step:9405 [D loss: 0.647627, acc.: 59.38%] [G loss: 0.935948]\n",
      "epoch:10 step:9406 [D loss: 0.484356, acc.: 81.25%] [G loss: 0.888377]\n",
      "epoch:10 step:9407 [D loss: 0.754633, acc.: 44.53%] [G loss: 0.773159]\n",
      "epoch:10 step:9408 [D loss: 0.922382, acc.: 28.12%] [G loss: 0.780480]\n",
      "epoch:10 step:9409 [D loss: 0.819638, acc.: 39.06%] [G loss: 0.835241]\n",
      "epoch:10 step:9410 [D loss: 0.742650, acc.: 50.78%] [G loss: 0.801721]\n",
      "epoch:10 step:9411 [D loss: 0.714460, acc.: 57.81%] [G loss: 0.856592]\n",
      "epoch:10 step:9412 [D loss: 0.671613, acc.: 61.72%] [G loss: 0.922695]\n",
      "epoch:10 step:9413 [D loss: 0.663993, acc.: 57.03%] [G loss: 0.933523]\n",
      "epoch:10 step:9414 [D loss: 0.673921, acc.: 59.38%] [G loss: 0.833969]\n",
      "epoch:10 step:9415 [D loss: 0.676414, acc.: 59.38%] [G loss: 0.845842]\n",
      "epoch:10 step:9416 [D loss: 0.693733, acc.: 51.56%] [G loss: 0.786470]\n",
      "epoch:10 step:9417 [D loss: 0.719182, acc.: 50.78%] [G loss: 0.818654]\n",
      "epoch:10 step:9418 [D loss: 0.666366, acc.: 56.25%] [G loss: 0.775617]\n",
      "epoch:10 step:9419 [D loss: 0.677068, acc.: 55.47%] [G loss: 0.806603]\n",
      "epoch:10 step:9420 [D loss: 0.637748, acc.: 63.28%] [G loss: 0.835060]\n",
      "epoch:10 step:9421 [D loss: 0.671579, acc.: 60.16%] [G loss: 0.779148]\n",
      "epoch:10 step:9422 [D loss: 0.658518, acc.: 58.59%] [G loss: 0.865080]\n",
      "epoch:10 step:9423 [D loss: 0.644601, acc.: 64.06%] [G loss: 0.814802]\n",
      "epoch:10 step:9424 [D loss: 0.652962, acc.: 65.62%] [G loss: 0.884706]\n",
      "epoch:10 step:9425 [D loss: 0.635886, acc.: 66.41%] [G loss: 0.851313]\n",
      "epoch:10 step:9426 [D loss: 0.720138, acc.: 50.00%] [G loss: 0.854370]\n",
      "epoch:10 step:9427 [D loss: 0.633697, acc.: 67.19%] [G loss: 0.820882]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:10 step:9428 [D loss: 0.649626, acc.: 60.16%] [G loss: 0.825833]\n",
      "epoch:10 step:9429 [D loss: 0.694812, acc.: 53.12%] [G loss: 0.805165]\n",
      "epoch:10 step:9430 [D loss: 0.649455, acc.: 60.16%] [G loss: 0.866132]\n",
      "epoch:10 step:9431 [D loss: 0.677688, acc.: 55.47%] [G loss: 0.855162]\n",
      "epoch:10 step:9432 [D loss: 0.669150, acc.: 60.94%] [G loss: 0.850313]\n",
      "epoch:10 step:9433 [D loss: 0.599633, acc.: 72.66%] [G loss: 0.870176]\n",
      "epoch:10 step:9434 [D loss: 0.648099, acc.: 57.03%] [G loss: 0.832561]\n",
      "epoch:10 step:9435 [D loss: 0.639800, acc.: 66.41%] [G loss: 0.815660]\n",
      "epoch:10 step:9436 [D loss: 0.700582, acc.: 50.00%] [G loss: 0.722667]\n",
      "epoch:10 step:9437 [D loss: 0.691424, acc.: 53.12%] [G loss: 0.901103]\n",
      "epoch:10 step:9438 [D loss: 0.745052, acc.: 50.78%] [G loss: 0.833078]\n",
      "epoch:10 step:9439 [D loss: 0.625973, acc.: 70.31%] [G loss: 0.907754]\n",
      "epoch:10 step:9440 [D loss: 0.743743, acc.: 46.88%] [G loss: 0.969875]\n",
      "epoch:10 step:9441 [D loss: 0.667369, acc.: 52.34%] [G loss: 0.836794]\n",
      "epoch:10 step:9442 [D loss: 0.739200, acc.: 44.53%] [G loss: 0.753783]\n",
      "epoch:10 step:9443 [D loss: 0.764561, acc.: 35.16%] [G loss: 0.861912]\n",
      "epoch:10 step:9444 [D loss: 0.657107, acc.: 61.72%] [G loss: 0.888545]\n",
      "epoch:10 step:9445 [D loss: 0.696546, acc.: 51.56%] [G loss: 0.846578]\n",
      "epoch:10 step:9446 [D loss: 0.506435, acc.: 83.59%] [G loss: 0.838080]\n",
      "epoch:10 step:9447 [D loss: 0.536860, acc.: 76.56%] [G loss: 0.900971]\n",
      "epoch:10 step:9448 [D loss: 0.638145, acc.: 62.50%] [G loss: 0.809418]\n",
      "epoch:10 step:9449 [D loss: 0.683333, acc.: 58.59%] [G loss: 0.820820]\n",
      "epoch:10 step:9450 [D loss: 0.722476, acc.: 48.44%] [G loss: 0.833259]\n",
      "epoch:10 step:9451 [D loss: 0.709163, acc.: 57.81%] [G loss: 0.776747]\n",
      "epoch:10 step:9452 [D loss: 0.730434, acc.: 44.53%] [G loss: 0.807362]\n",
      "epoch:10 step:9453 [D loss: 0.674652, acc.: 57.03%] [G loss: 0.850897]\n",
      "epoch:10 step:9454 [D loss: 0.687679, acc.: 55.47%] [G loss: 0.787363]\n",
      "epoch:10 step:9455 [D loss: 0.683718, acc.: 53.12%] [G loss: 0.574675]\n",
      "epoch:10 step:9456 [D loss: 0.654103, acc.: 64.84%] [G loss: 0.786800]\n",
      "epoch:10 step:9457 [D loss: 0.754020, acc.: 43.75%] [G loss: 0.865670]\n",
      "epoch:10 step:9458 [D loss: 0.670148, acc.: 60.94%] [G loss: 0.844074]\n",
      "epoch:10 step:9459 [D loss: 0.671259, acc.: 60.94%] [G loss: 0.923558]\n",
      "epoch:10 step:9460 [D loss: 0.667792, acc.: 59.38%] [G loss: 0.854773]\n",
      "epoch:10 step:9461 [D loss: 0.646604, acc.: 53.12%] [G loss: 0.922530]\n",
      "epoch:10 step:9462 [D loss: 0.596688, acc.: 73.44%] [G loss: 1.003103]\n",
      "epoch:10 step:9463 [D loss: 0.630518, acc.: 67.19%] [G loss: 0.953011]\n",
      "epoch:10 step:9464 [D loss: 0.654008, acc.: 60.16%] [G loss: 0.963184]\n",
      "epoch:10 step:9465 [D loss: 0.697627, acc.: 60.16%] [G loss: 0.798020]\n",
      "epoch:10 step:9466 [D loss: 0.677283, acc.: 60.16%] [G loss: 0.806994]\n",
      "epoch:10 step:9467 [D loss: 0.639655, acc.: 62.50%] [G loss: 0.713710]\n",
      "epoch:10 step:9468 [D loss: 0.676876, acc.: 61.72%] [G loss: 0.738107]\n",
      "epoch:10 step:9469 [D loss: 0.684052, acc.: 58.59%] [G loss: 0.811120]\n",
      "epoch:10 step:9470 [D loss: 0.721826, acc.: 46.09%] [G loss: 0.875997]\n",
      "epoch:10 step:9471 [D loss: 0.688919, acc.: 53.91%] [G loss: 0.907999]\n",
      "epoch:10 step:9472 [D loss: 0.662000, acc.: 64.84%] [G loss: 0.840017]\n",
      "epoch:10 step:9473 [D loss: 0.690314, acc.: 53.91%] [G loss: 0.867599]\n",
      "epoch:10 step:9474 [D loss: 0.644783, acc.: 67.19%] [G loss: 0.857714]\n",
      "epoch:10 step:9475 [D loss: 0.619635, acc.: 66.41%] [G loss: 0.924529]\n",
      "epoch:10 step:9476 [D loss: 0.655782, acc.: 62.50%] [G loss: 0.839824]\n",
      "epoch:10 step:9477 [D loss: 0.614120, acc.: 67.97%] [G loss: 0.886744]\n",
      "epoch:10 step:9478 [D loss: 0.711321, acc.: 56.25%] [G loss: 0.848591]\n",
      "epoch:10 step:9479 [D loss: 0.753018, acc.: 43.75%] [G loss: 0.829983]\n",
      "epoch:10 step:9480 [D loss: 0.693115, acc.: 53.12%] [G loss: 0.870229]\n",
      "epoch:10 step:9481 [D loss: 0.680564, acc.: 59.38%] [G loss: 0.839227]\n",
      "epoch:10 step:9482 [D loss: 0.692613, acc.: 53.91%] [G loss: 0.859425]\n",
      "epoch:10 step:9483 [D loss: 0.664898, acc.: 64.06%] [G loss: 0.881400]\n",
      "epoch:10 step:9484 [D loss: 0.676223, acc.: 56.25%] [G loss: 0.889583]\n",
      "epoch:10 step:9485 [D loss: 0.661592, acc.: 63.28%] [G loss: 0.958873]\n",
      "epoch:10 step:9486 [D loss: 0.695023, acc.: 57.81%] [G loss: 0.866092]\n",
      "epoch:10 step:9487 [D loss: 0.789301, acc.: 42.97%] [G loss: 0.824938]\n",
      "epoch:10 step:9488 [D loss: 0.672239, acc.: 50.00%] [G loss: 0.857203]\n",
      "epoch:10 step:9489 [D loss: 0.627648, acc.: 67.97%] [G loss: 0.897574]\n",
      "epoch:10 step:9490 [D loss: 0.671008, acc.: 53.12%] [G loss: 0.871595]\n",
      "epoch:10 step:9491 [D loss: 0.657349, acc.: 60.94%] [G loss: 0.907009]\n",
      "epoch:10 step:9492 [D loss: 0.621599, acc.: 70.31%] [G loss: 1.028567]\n",
      "epoch:10 step:9493 [D loss: 0.644225, acc.: 60.16%] [G loss: 0.956995]\n",
      "epoch:10 step:9494 [D loss: 0.602823, acc.: 70.31%] [G loss: 0.935845]\n",
      "epoch:10 step:9495 [D loss: 0.630922, acc.: 63.28%] [G loss: 0.844093]\n",
      "epoch:10 step:9496 [D loss: 0.637151, acc.: 61.72%] [G loss: 0.853092]\n",
      "epoch:10 step:9497 [D loss: 0.665037, acc.: 57.81%] [G loss: 0.875869]\n",
      "epoch:10 step:9498 [D loss: 0.701697, acc.: 53.91%] [G loss: 0.839691]\n",
      "epoch:10 step:9499 [D loss: 0.723485, acc.: 45.31%] [G loss: 0.834314]\n",
      "epoch:10 step:9500 [D loss: 0.644327, acc.: 62.50%] [G loss: 0.763659]\n",
      "epoch:10 step:9501 [D loss: 0.726875, acc.: 50.78%] [G loss: 0.751206]\n",
      "epoch:10 step:9502 [D loss: 0.663433, acc.: 60.94%] [G loss: 0.796169]\n",
      "epoch:10 step:9503 [D loss: 0.666629, acc.: 61.72%] [G loss: 0.812581]\n",
      "epoch:10 step:9504 [D loss: 0.546354, acc.: 70.31%] [G loss: 0.826507]\n",
      "epoch:10 step:9505 [D loss: 0.594946, acc.: 64.84%] [G loss: 0.840078]\n",
      "epoch:10 step:9506 [D loss: 0.655699, acc.: 57.81%] [G loss: 0.746182]\n",
      "epoch:10 step:9507 [D loss: 0.681643, acc.: 58.59%] [G loss: 0.713895]\n",
      "epoch:10 step:9508 [D loss: 0.704200, acc.: 50.78%] [G loss: 0.738765]\n",
      "epoch:10 step:9509 [D loss: 0.677265, acc.: 56.25%] [G loss: 0.742935]\n",
      "epoch:10 step:9510 [D loss: 0.523470, acc.: 75.78%] [G loss: 0.838175]\n",
      "epoch:10 step:9511 [D loss: 0.506968, acc.: 78.91%] [G loss: 0.800752]\n",
      "epoch:10 step:9512 [D loss: 0.656015, acc.: 62.50%] [G loss: 0.920597]\n",
      "epoch:10 step:9513 [D loss: 0.699518, acc.: 59.38%] [G loss: 1.013466]\n",
      "epoch:10 step:9514 [D loss: 0.615273, acc.: 66.41%] [G loss: 0.893259]\n",
      "epoch:10 step:9515 [D loss: 0.655215, acc.: 64.06%] [G loss: 0.959578]\n",
      "epoch:10 step:9516 [D loss: 0.659358, acc.: 58.59%] [G loss: 0.939773]\n",
      "epoch:10 step:9517 [D loss: 0.762809, acc.: 47.66%] [G loss: 0.783458]\n",
      "epoch:10 step:9518 [D loss: 0.785802, acc.: 38.28%] [G loss: 0.782389]\n",
      "epoch:10 step:9519 [D loss: 0.618823, acc.: 64.06%] [G loss: 0.857593]\n",
      "epoch:10 step:9520 [D loss: 0.525545, acc.: 67.97%] [G loss: 0.834659]\n",
      "epoch:10 step:9521 [D loss: 0.618117, acc.: 70.31%] [G loss: 0.911973]\n",
      "epoch:10 step:9522 [D loss: 0.598352, acc.: 68.75%] [G loss: 0.915979]\n",
      "epoch:10 step:9523 [D loss: 0.871985, acc.: 32.81%] [G loss: 0.972041]\n",
      "epoch:10 step:9524 [D loss: 0.651957, acc.: 56.25%] [G loss: 0.942142]\n",
      "epoch:10 step:9525 [D loss: 0.640666, acc.: 59.38%] [G loss: 1.057770]\n",
      "epoch:10 step:9526 [D loss: 0.607933, acc.: 61.72%] [G loss: 0.999116]\n",
      "epoch:10 step:9527 [D loss: 0.694445, acc.: 53.91%] [G loss: 0.953974]\n",
      "epoch:10 step:9528 [D loss: 0.733727, acc.: 52.34%] [G loss: 0.821956]\n",
      "epoch:10 step:9529 [D loss: 0.691890, acc.: 54.69%] [G loss: 1.016242]\n",
      "epoch:10 step:9530 [D loss: 0.720338, acc.: 57.81%] [G loss: 0.843508]\n",
      "epoch:10 step:9531 [D loss: 0.652472, acc.: 63.28%] [G loss: 0.822874]\n",
      "epoch:10 step:9532 [D loss: 0.640700, acc.: 64.06%] [G loss: 0.807957]\n",
      "epoch:10 step:9533 [D loss: 0.690371, acc.: 52.34%] [G loss: 0.789884]\n",
      "epoch:10 step:9534 [D loss: 0.664364, acc.: 56.25%] [G loss: 0.759601]\n",
      "epoch:10 step:9535 [D loss: 0.678583, acc.: 52.34%] [G loss: 0.750846]\n",
      "epoch:10 step:9536 [D loss: 0.694184, acc.: 50.00%] [G loss: 0.614486]\n",
      "epoch:10 step:9537 [D loss: 0.708286, acc.: 51.56%] [G loss: 0.731040]\n",
      "epoch:10 step:9538 [D loss: 0.675261, acc.: 61.72%] [G loss: 0.831726]\n",
      "epoch:10 step:9539 [D loss: 0.680657, acc.: 56.25%] [G loss: 0.820091]\n",
      "epoch:10 step:9540 [D loss: 0.674889, acc.: 55.47%] [G loss: 0.759222]\n",
      "epoch:10 step:9541 [D loss: 0.651872, acc.: 65.62%] [G loss: 0.817881]\n",
      "epoch:10 step:9542 [D loss: 0.665842, acc.: 58.59%] [G loss: 0.693570]\n",
      "epoch:10 step:9543 [D loss: 0.640526, acc.: 65.62%] [G loss: 0.795140]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:10 step:9544 [D loss: 0.644088, acc.: 64.84%] [G loss: 0.852872]\n",
      "epoch:10 step:9545 [D loss: 0.650735, acc.: 55.47%] [G loss: 0.927320]\n",
      "epoch:10 step:9546 [D loss: 0.546123, acc.: 75.78%] [G loss: 0.841840]\n",
      "epoch:10 step:9547 [D loss: 0.615618, acc.: 67.19%] [G loss: 0.896179]\n",
      "epoch:10 step:9548 [D loss: 0.657591, acc.: 64.84%] [G loss: 0.758425]\n",
      "epoch:10 step:9549 [D loss: 0.582977, acc.: 67.97%] [G loss: 0.772903]\n",
      "epoch:10 step:9550 [D loss: 0.685272, acc.: 55.47%] [G loss: 0.826774]\n",
      "epoch:10 step:9551 [D loss: 0.669337, acc.: 55.47%] [G loss: 0.573773]\n",
      "epoch:10 step:9552 [D loss: 0.845980, acc.: 36.72%] [G loss: 0.823593]\n",
      "epoch:10 step:9553 [D loss: 0.745814, acc.: 45.31%] [G loss: 0.803669]\n",
      "epoch:10 step:9554 [D loss: 0.625859, acc.: 67.19%] [G loss: 0.935979]\n",
      "epoch:10 step:9555 [D loss: 0.702172, acc.: 47.66%] [G loss: 0.981010]\n",
      "epoch:10 step:9556 [D loss: 0.779429, acc.: 40.62%] [G loss: 1.024909]\n",
      "epoch:10 step:9557 [D loss: 0.623372, acc.: 67.97%] [G loss: 1.055131]\n",
      "epoch:10 step:9558 [D loss: 0.661950, acc.: 60.94%] [G loss: 0.963721]\n",
      "epoch:10 step:9559 [D loss: 0.685030, acc.: 55.47%] [G loss: 0.885157]\n",
      "epoch:10 step:9560 [D loss: 0.640756, acc.: 63.28%] [G loss: 0.953458]\n",
      "epoch:10 step:9561 [D loss: 0.661503, acc.: 62.50%] [G loss: 0.874118]\n",
      "epoch:10 step:9562 [D loss: 0.649649, acc.: 57.81%] [G loss: 0.882432]\n",
      "epoch:10 step:9563 [D loss: 0.683325, acc.: 50.78%] [G loss: 0.787618]\n",
      "epoch:10 step:9564 [D loss: 0.617554, acc.: 65.62%] [G loss: 0.830288]\n",
      "epoch:10 step:9565 [D loss: 0.615943, acc.: 68.75%] [G loss: 0.859096]\n",
      "epoch:10 step:9566 [D loss: 0.660641, acc.: 67.97%] [G loss: 0.867855]\n",
      "epoch:10 step:9567 [D loss: 0.689925, acc.: 53.12%] [G loss: 0.814341]\n",
      "epoch:10 step:9568 [D loss: 0.654624, acc.: 60.94%] [G loss: 0.947142]\n",
      "epoch:10 step:9569 [D loss: 0.850869, acc.: 39.06%] [G loss: 0.816903]\n",
      "epoch:10 step:9570 [D loss: 0.788625, acc.: 49.22%] [G loss: 0.776640]\n",
      "epoch:10 step:9571 [D loss: 0.720045, acc.: 56.25%] [G loss: 0.804008]\n",
      "epoch:10 step:9572 [D loss: 0.692855, acc.: 53.12%] [G loss: 0.885089]\n",
      "epoch:10 step:9573 [D loss: 0.671306, acc.: 60.94%] [G loss: 0.807099]\n",
      "epoch:10 step:9574 [D loss: 0.637137, acc.: 66.41%] [G loss: 0.781877]\n",
      "epoch:10 step:9575 [D loss: 0.667303, acc.: 57.03%] [G loss: 0.804599]\n",
      "epoch:10 step:9576 [D loss: 0.666919, acc.: 58.59%] [G loss: 0.849465]\n",
      "epoch:10 step:9577 [D loss: 0.631430, acc.: 63.28%] [G loss: 0.918035]\n",
      "epoch:10 step:9578 [D loss: 0.672304, acc.: 59.38%] [G loss: 0.831521]\n",
      "epoch:10 step:9579 [D loss: 0.678007, acc.: 57.81%] [G loss: 0.822367]\n",
      "epoch:10 step:9580 [D loss: 0.698009, acc.: 49.22%] [G loss: 0.820303]\n",
      "epoch:10 step:9581 [D loss: 0.712315, acc.: 49.22%] [G loss: 0.783155]\n",
      "epoch:10 step:9582 [D loss: 0.649052, acc.: 61.72%] [G loss: 0.860028]\n",
      "epoch:10 step:9583 [D loss: 0.723246, acc.: 48.44%] [G loss: 0.831746]\n",
      "epoch:10 step:9584 [D loss: 0.729684, acc.: 47.66%] [G loss: 0.834435]\n",
      "epoch:10 step:9585 [D loss: 0.680818, acc.: 59.38%] [G loss: 0.793904]\n",
      "epoch:10 step:9586 [D loss: 0.691990, acc.: 55.47%] [G loss: 0.807592]\n",
      "epoch:10 step:9587 [D loss: 0.690272, acc.: 57.03%] [G loss: 0.804686]\n",
      "epoch:10 step:9588 [D loss: 0.708106, acc.: 54.69%] [G loss: 0.808649]\n",
      "epoch:10 step:9589 [D loss: 0.631311, acc.: 63.28%] [G loss: 0.791687]\n",
      "epoch:10 step:9590 [D loss: 0.456458, acc.: 72.66%] [G loss: 0.778714]\n",
      "epoch:10 step:9591 [D loss: 0.408373, acc.: 84.38%] [G loss: 0.835097]\n",
      "epoch:10 step:9592 [D loss: 0.681395, acc.: 56.25%] [G loss: 0.871446]\n",
      "epoch:10 step:9593 [D loss: 0.445668, acc.: 88.28%] [G loss: 0.867540]\n",
      "epoch:10 step:9594 [D loss: 0.697380, acc.: 51.56%] [G loss: 0.708161]\n",
      "epoch:10 step:9595 [D loss: 0.770898, acc.: 37.50%] [G loss: 0.740712]\n",
      "epoch:10 step:9596 [D loss: 0.738231, acc.: 50.78%] [G loss: 0.748950]\n",
      "epoch:10 step:9597 [D loss: 0.577219, acc.: 75.00%] [G loss: 0.770204]\n",
      "epoch:10 step:9598 [D loss: 0.673753, acc.: 57.03%] [G loss: 0.861425]\n",
      "epoch:10 step:9599 [D loss: 0.586477, acc.: 67.97%] [G loss: 0.765520]\n",
      "epoch:10 step:9600 [D loss: 0.423338, acc.: 71.09%] [G loss: 0.897129]\n",
      "##############\n",
      "[4.14894283 2.30928179 6.46740072 5.1942475  4.61846988 6.03720756\n",
      " 5.20454192 5.75890862 5.60596805 5.1566804 ]\n",
      "##########\n",
      "epoch:10 step:9601 [D loss: 0.490327, acc.: 82.03%] [G loss: 1.087912]\n",
      "epoch:10 step:9602 [D loss: 0.356839, acc.: 85.16%] [G loss: 1.138239]\n",
      "epoch:10 step:9603 [D loss: 0.647146, acc.: 70.31%] [G loss: 1.030115]\n",
      "epoch:10 step:9604 [D loss: 0.451889, acc.: 80.47%] [G loss: 1.057267]\n",
      "epoch:10 step:9605 [D loss: 0.723903, acc.: 50.78%] [G loss: 1.091494]\n",
      "epoch:10 step:9606 [D loss: 0.708432, acc.: 52.34%] [G loss: 0.865481]\n",
      "epoch:10 step:9607 [D loss: 0.537605, acc.: 71.09%] [G loss: 0.942571]\n",
      "epoch:10 step:9608 [D loss: 0.687388, acc.: 55.47%] [G loss: 0.919790]\n",
      "epoch:10 step:9609 [D loss: 0.919115, acc.: 21.09%] [G loss: 0.775472]\n",
      "epoch:10 step:9610 [D loss: 0.872798, acc.: 22.66%] [G loss: 0.898144]\n",
      "epoch:10 step:9611 [D loss: 0.744143, acc.: 45.31%] [G loss: 1.004116]\n",
      "epoch:10 step:9612 [D loss: 0.830401, acc.: 35.94%] [G loss: 1.083395]\n",
      "epoch:10 step:9613 [D loss: 0.669182, acc.: 55.47%] [G loss: 1.011497]\n",
      "epoch:10 step:9614 [D loss: 0.747349, acc.: 42.19%] [G loss: 1.077498]\n",
      "epoch:10 step:9615 [D loss: 0.633139, acc.: 61.72%] [G loss: 1.063930]\n",
      "epoch:10 step:9616 [D loss: 0.741666, acc.: 47.66%] [G loss: 1.012127]\n",
      "epoch:10 step:9617 [D loss: 0.639555, acc.: 61.72%] [G loss: 1.152797]\n",
      "epoch:10 step:9618 [D loss: 0.614600, acc.: 69.53%] [G loss: 0.953268]\n",
      "epoch:10 step:9619 [D loss: 0.700422, acc.: 53.91%] [G loss: 0.958036]\n",
      "epoch:10 step:9620 [D loss: 0.613673, acc.: 66.41%] [G loss: 1.005261]\n",
      "epoch:10 step:9621 [D loss: 0.643971, acc.: 66.41%] [G loss: 0.841993]\n",
      "epoch:10 step:9622 [D loss: 0.635132, acc.: 65.62%] [G loss: 0.883368]\n",
      "epoch:10 step:9623 [D loss: 0.681102, acc.: 57.81%] [G loss: 0.848847]\n",
      "epoch:10 step:9624 [D loss: 0.670855, acc.: 60.16%] [G loss: 0.783687]\n",
      "epoch:10 step:9625 [D loss: 0.753438, acc.: 43.75%] [G loss: 0.776539]\n",
      "epoch:10 step:9626 [D loss: 0.715813, acc.: 50.00%] [G loss: 0.820107]\n",
      "epoch:10 step:9627 [D loss: 0.697614, acc.: 50.00%] [G loss: 0.816507]\n",
      "epoch:10 step:9628 [D loss: 0.644196, acc.: 68.75%] [G loss: 0.789331]\n",
      "epoch:10 step:9629 [D loss: 0.547706, acc.: 72.66%] [G loss: 0.930788]\n",
      "epoch:10 step:9630 [D loss: 0.670502, acc.: 60.16%] [G loss: 0.862107]\n",
      "epoch:10 step:9631 [D loss: 0.674627, acc.: 64.84%] [G loss: 0.884565]\n",
      "epoch:10 step:9632 [D loss: 0.645966, acc.: 59.38%] [G loss: 0.814015]\n",
      "epoch:10 step:9633 [D loss: 0.601657, acc.: 71.09%] [G loss: 0.859056]\n",
      "epoch:10 step:9634 [D loss: 0.609307, acc.: 71.09%] [G loss: 0.803971]\n",
      "epoch:10 step:9635 [D loss: 0.567834, acc.: 77.34%] [G loss: 0.829901]\n",
      "epoch:10 step:9636 [D loss: 0.636185, acc.: 63.28%] [G loss: 0.868868]\n",
      "epoch:10 step:9637 [D loss: 0.607711, acc.: 63.28%] [G loss: 0.940551]\n",
      "epoch:10 step:9638 [D loss: 0.653996, acc.: 60.16%] [G loss: 0.834679]\n",
      "epoch:10 step:9639 [D loss: 0.632784, acc.: 60.94%] [G loss: 0.644004]\n",
      "epoch:10 step:9640 [D loss: 0.700996, acc.: 56.25%] [G loss: 0.763054]\n",
      "epoch:10 step:9641 [D loss: 0.662232, acc.: 65.62%] [G loss: 0.600350]\n",
      "epoch:10 step:9642 [D loss: 0.713379, acc.: 53.12%] [G loss: 0.863404]\n",
      "epoch:10 step:9643 [D loss: 0.724616, acc.: 57.81%] [G loss: 0.993106]\n",
      "epoch:10 step:9644 [D loss: 0.591919, acc.: 67.97%] [G loss: 1.004737]\n",
      "epoch:10 step:9645 [D loss: 0.616401, acc.: 67.97%] [G loss: 0.965907]\n",
      "epoch:10 step:9646 [D loss: 0.587304, acc.: 71.09%] [G loss: 0.957529]\n",
      "epoch:10 step:9647 [D loss: 0.688481, acc.: 56.25%] [G loss: 0.837502]\n",
      "epoch:10 step:9648 [D loss: 0.677252, acc.: 54.69%] [G loss: 0.872615]\n",
      "epoch:10 step:9649 [D loss: 0.440157, acc.: 76.56%] [G loss: 0.844645]\n",
      "epoch:10 step:9650 [D loss: 0.733073, acc.: 50.00%] [G loss: 0.750363]\n",
      "epoch:10 step:9651 [D loss: 0.881821, acc.: 40.62%] [G loss: 0.869270]\n",
      "epoch:10 step:9652 [D loss: 0.655776, acc.: 59.38%] [G loss: 0.944146]\n",
      "epoch:10 step:9653 [D loss: 0.676650, acc.: 56.25%] [G loss: 0.964333]\n",
      "epoch:10 step:9654 [D loss: 0.659744, acc.: 71.88%] [G loss: 0.967483]\n",
      "epoch:10 step:9655 [D loss: 0.687583, acc.: 55.47%] [G loss: 0.871428]\n",
      "epoch:10 step:9656 [D loss: 0.683504, acc.: 57.03%] [G loss: 0.851670]\n",
      "epoch:10 step:9657 [D loss: 0.714490, acc.: 46.88%] [G loss: 0.910345]\n",
      "epoch:10 step:9658 [D loss: 0.684927, acc.: 53.12%] [G loss: 0.978932]\n",
      "epoch:10 step:9659 [D loss: 0.627008, acc.: 67.97%] [G loss: 0.892944]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:10 step:9660 [D loss: 0.600087, acc.: 68.75%] [G loss: 0.926744]\n",
      "epoch:10 step:9661 [D loss: 0.855608, acc.: 40.62%] [G loss: 0.869424]\n",
      "epoch:10 step:9662 [D loss: 0.629978, acc.: 62.50%] [G loss: 0.911203]\n",
      "epoch:10 step:9663 [D loss: 0.682468, acc.: 58.59%] [G loss: 0.847057]\n",
      "epoch:10 step:9664 [D loss: 0.669091, acc.: 57.03%] [G loss: 0.813346]\n",
      "epoch:10 step:9665 [D loss: 0.750652, acc.: 45.31%] [G loss: 0.846671]\n",
      "epoch:10 step:9666 [D loss: 0.673775, acc.: 61.72%] [G loss: 0.900588]\n",
      "epoch:10 step:9667 [D loss: 0.680250, acc.: 56.25%] [G loss: 0.813006]\n",
      "epoch:10 step:9668 [D loss: 0.700155, acc.: 50.78%] [G loss: 0.775119]\n",
      "epoch:10 step:9669 [D loss: 0.635290, acc.: 66.41%] [G loss: 0.819112]\n",
      "epoch:10 step:9670 [D loss: 0.674455, acc.: 55.47%] [G loss: 0.753250]\n",
      "epoch:10 step:9671 [D loss: 0.690159, acc.: 57.81%] [G loss: 0.802116]\n",
      "epoch:10 step:9672 [D loss: 0.682417, acc.: 57.81%] [G loss: 0.799648]\n",
      "epoch:10 step:9673 [D loss: 0.700107, acc.: 51.56%] [G loss: 0.792213]\n",
      "epoch:10 step:9674 [D loss: 0.686074, acc.: 55.47%] [G loss: 0.816769]\n",
      "epoch:10 step:9675 [D loss: 0.686304, acc.: 57.81%] [G loss: 0.815248]\n",
      "epoch:10 step:9676 [D loss: 0.695431, acc.: 51.56%] [G loss: 0.795762]\n",
      "epoch:10 step:9677 [D loss: 0.669064, acc.: 59.38%] [G loss: 0.784641]\n",
      "epoch:10 step:9678 [D loss: 0.573835, acc.: 78.12%] [G loss: 0.804819]\n",
      "epoch:10 step:9679 [D loss: 0.415537, acc.: 84.38%] [G loss: 0.830843]\n",
      "epoch:10 step:9680 [D loss: 0.638122, acc.: 62.50%] [G loss: 0.847663]\n",
      "epoch:10 step:9681 [D loss: 0.608923, acc.: 67.97%] [G loss: 0.816571]\n",
      "epoch:10 step:9682 [D loss: 0.411949, acc.: 82.03%] [G loss: 0.894690]\n",
      "epoch:10 step:9683 [D loss: 0.456116, acc.: 79.69%] [G loss: 0.980743]\n",
      "epoch:10 step:9684 [D loss: 0.322318, acc.: 86.72%] [G loss: 0.756556]\n",
      "epoch:10 step:9685 [D loss: 0.573394, acc.: 70.31%] [G loss: 0.922498]\n",
      "epoch:10 step:9686 [D loss: 0.810127, acc.: 37.50%] [G loss: 0.917738]\n",
      "epoch:10 step:9687 [D loss: 0.773407, acc.: 45.31%] [G loss: 0.954597]\n",
      "epoch:10 step:9688 [D loss: 0.691243, acc.: 53.12%] [G loss: 1.073631]\n",
      "epoch:10 step:9689 [D loss: 0.690130, acc.: 53.91%] [G loss: 0.995819]\n",
      "epoch:10 step:9690 [D loss: 0.660473, acc.: 57.03%] [G loss: 1.020798]\n",
      "epoch:10 step:9691 [D loss: 0.663744, acc.: 60.16%] [G loss: 0.953316]\n",
      "epoch:10 step:9692 [D loss: 0.623789, acc.: 63.28%] [G loss: 0.901596]\n",
      "epoch:10 step:9693 [D loss: 0.885434, acc.: 37.50%] [G loss: 1.080944]\n",
      "epoch:10 step:9694 [D loss: 0.699260, acc.: 57.81%] [G loss: 1.021640]\n",
      "epoch:10 step:9695 [D loss: 0.744838, acc.: 50.78%] [G loss: 0.852416]\n",
      "epoch:10 step:9696 [D loss: 0.629221, acc.: 64.06%] [G loss: 1.247986]\n",
      "epoch:10 step:9697 [D loss: 0.647332, acc.: 68.75%] [G loss: 0.803738]\n",
      "epoch:10 step:9698 [D loss: 0.612874, acc.: 66.41%] [G loss: 0.788359]\n",
      "epoch:10 step:9699 [D loss: 0.706831, acc.: 53.12%] [G loss: 0.786630]\n",
      "epoch:10 step:9700 [D loss: 0.721378, acc.: 47.66%] [G loss: 0.850899]\n",
      "epoch:10 step:9701 [D loss: 0.682074, acc.: 57.03%] [G loss: 0.845599]\n",
      "epoch:10 step:9702 [D loss: 0.746828, acc.: 44.53%] [G loss: 0.988293]\n",
      "epoch:10 step:9703 [D loss: 0.729065, acc.: 46.88%] [G loss: 0.856522]\n",
      "epoch:10 step:9704 [D loss: 0.627149, acc.: 61.72%] [G loss: 0.893621]\n",
      "epoch:10 step:9705 [D loss: 0.639857, acc.: 59.38%] [G loss: 0.949006]\n",
      "epoch:10 step:9706 [D loss: 0.617905, acc.: 75.00%] [G loss: 0.888115]\n",
      "epoch:10 step:9707 [D loss: 0.628289, acc.: 64.84%] [G loss: 0.839593]\n",
      "epoch:10 step:9708 [D loss: 0.681298, acc.: 59.38%] [G loss: 0.894145]\n",
      "epoch:10 step:9709 [D loss: 0.683474, acc.: 55.47%] [G loss: 0.834581]\n",
      "epoch:10 step:9710 [D loss: 0.752722, acc.: 46.09%] [G loss: 0.807770]\n",
      "epoch:10 step:9711 [D loss: 0.670250, acc.: 57.81%] [G loss: 0.783650]\n",
      "epoch:10 step:9712 [D loss: 0.662429, acc.: 56.25%] [G loss: 0.815830]\n",
      "epoch:10 step:9713 [D loss: 0.565870, acc.: 77.34%] [G loss: 0.873880]\n",
      "epoch:10 step:9714 [D loss: 0.609903, acc.: 62.50%] [G loss: 0.834717]\n",
      "epoch:10 step:9715 [D loss: 0.652916, acc.: 57.81%] [G loss: 0.841738]\n",
      "epoch:10 step:9716 [D loss: 0.520495, acc.: 74.22%] [G loss: 0.816060]\n",
      "epoch:10 step:9717 [D loss: 0.507052, acc.: 74.22%] [G loss: 0.821553]\n",
      "epoch:10 step:9718 [D loss: 0.746861, acc.: 48.44%] [G loss: 0.838310]\n",
      "epoch:10 step:9719 [D loss: 0.740913, acc.: 43.75%] [G loss: 0.815309]\n",
      "epoch:10 step:9720 [D loss: 0.622221, acc.: 65.62%] [G loss: 0.740833]\n",
      "epoch:10 step:9721 [D loss: 0.717975, acc.: 57.03%] [G loss: 0.967004]\n",
      "epoch:10 step:9722 [D loss: 0.793719, acc.: 39.84%] [G loss: 0.930865]\n",
      "epoch:10 step:9723 [D loss: 0.695037, acc.: 57.03%] [G loss: 0.943102]\n",
      "epoch:10 step:9724 [D loss: 0.676675, acc.: 57.81%] [G loss: 0.883054]\n",
      "epoch:10 step:9725 [D loss: 0.750076, acc.: 40.62%] [G loss: 0.917318]\n",
      "epoch:10 step:9726 [D loss: 0.656480, acc.: 61.72%] [G loss: 0.894483]\n",
      "epoch:10 step:9727 [D loss: 0.684719, acc.: 55.47%] [G loss: 0.860930]\n",
      "epoch:10 step:9728 [D loss: 0.650355, acc.: 58.59%] [G loss: 0.802666]\n",
      "epoch:10 step:9729 [D loss: 0.606426, acc.: 65.62%] [G loss: 0.818381]\n",
      "epoch:10 step:9730 [D loss: 0.651900, acc.: 67.19%] [G loss: 0.864545]\n",
      "epoch:10 step:9731 [D loss: 0.635693, acc.: 66.41%] [G loss: 0.884772]\n",
      "epoch:10 step:9732 [D loss: 0.658943, acc.: 65.62%] [G loss: 0.936313]\n",
      "epoch:10 step:9733 [D loss: 0.676764, acc.: 53.91%] [G loss: 0.852338]\n",
      "epoch:10 step:9734 [D loss: 0.655502, acc.: 60.16%] [G loss: 0.831211]\n",
      "epoch:10 step:9735 [D loss: 0.653404, acc.: 60.94%] [G loss: 0.700059]\n",
      "epoch:10 step:9736 [D loss: 0.645575, acc.: 58.59%] [G loss: 0.797284]\n",
      "epoch:10 step:9737 [D loss: 0.596024, acc.: 68.75%] [G loss: 0.819589]\n",
      "epoch:10 step:9738 [D loss: 0.701434, acc.: 56.25%] [G loss: 0.789350]\n",
      "epoch:10 step:9739 [D loss: 0.714412, acc.: 49.22%] [G loss: 0.715910]\n",
      "epoch:10 step:9740 [D loss: 0.702876, acc.: 53.12%] [G loss: 0.844235]\n",
      "epoch:10 step:9741 [D loss: 0.632363, acc.: 62.50%] [G loss: 0.847008]\n",
      "epoch:10 step:9742 [D loss: 0.688547, acc.: 56.25%] [G loss: 0.809494]\n",
      "epoch:10 step:9743 [D loss: 0.692767, acc.: 52.34%] [G loss: 0.879124]\n",
      "epoch:10 step:9744 [D loss: 0.689350, acc.: 55.47%] [G loss: 0.815870]\n",
      "epoch:10 step:9745 [D loss: 0.681149, acc.: 59.38%] [G loss: 0.876835]\n",
      "epoch:10 step:9746 [D loss: 0.711491, acc.: 56.25%] [G loss: 0.831481]\n",
      "epoch:10 step:9747 [D loss: 0.682612, acc.: 58.59%] [G loss: 0.805586]\n",
      "epoch:10 step:9748 [D loss: 0.687507, acc.: 57.81%] [G loss: 0.864865]\n",
      "epoch:10 step:9749 [D loss: 0.695081, acc.: 57.81%] [G loss: 0.821381]\n",
      "epoch:10 step:9750 [D loss: 0.630031, acc.: 67.97%] [G loss: 0.879049]\n",
      "epoch:10 step:9751 [D loss: 0.655421, acc.: 59.38%] [G loss: 0.899817]\n",
      "epoch:10 step:9752 [D loss: 0.674276, acc.: 60.94%] [G loss: 0.796987]\n",
      "epoch:10 step:9753 [D loss: 0.733311, acc.: 48.44%] [G loss: 0.772735]\n",
      "epoch:10 step:9754 [D loss: 0.674607, acc.: 60.94%] [G loss: 0.734231]\n",
      "epoch:10 step:9755 [D loss: 0.683002, acc.: 55.47%] [G loss: 0.740762]\n",
      "epoch:10 step:9756 [D loss: 0.670333, acc.: 57.81%] [G loss: 0.738886]\n",
      "epoch:10 step:9757 [D loss: 0.693985, acc.: 57.81%] [G loss: 0.875648]\n",
      "epoch:10 step:9758 [D loss: 0.637506, acc.: 67.19%] [G loss: 0.829052]\n",
      "epoch:10 step:9759 [D loss: 0.664865, acc.: 65.62%] [G loss: 0.830228]\n",
      "epoch:10 step:9760 [D loss: 0.745907, acc.: 47.66%] [G loss: 0.722446]\n",
      "epoch:10 step:9761 [D loss: 0.650920, acc.: 66.41%] [G loss: 0.790911]\n",
      "epoch:10 step:9762 [D loss: 0.693758, acc.: 53.91%] [G loss: 0.680634]\n",
      "epoch:10 step:9763 [D loss: 0.773803, acc.: 39.84%] [G loss: 0.811323]\n",
      "epoch:10 step:9764 [D loss: 0.739003, acc.: 46.09%] [G loss: 0.809792]\n",
      "epoch:10 step:9765 [D loss: 0.695118, acc.: 56.25%] [G loss: 0.782788]\n",
      "epoch:10 step:9766 [D loss: 0.639517, acc.: 58.59%] [G loss: 0.808015]\n",
      "epoch:10 step:9767 [D loss: 0.606687, acc.: 64.84%] [G loss: 0.825741]\n",
      "epoch:10 step:9768 [D loss: 0.659648, acc.: 62.50%] [G loss: 0.863610]\n",
      "epoch:10 step:9769 [D loss: 0.428432, acc.: 73.44%] [G loss: 0.872369]\n",
      "epoch:10 step:9770 [D loss: 0.680229, acc.: 53.91%] [G loss: 0.913241]\n",
      "epoch:10 step:9771 [D loss: 0.658593, acc.: 58.59%] [G loss: 0.840713]\n",
      "epoch:10 step:9772 [D loss: 0.552431, acc.: 71.88%] [G loss: 0.858305]\n",
      "epoch:10 step:9773 [D loss: 0.607424, acc.: 66.41%] [G loss: 0.859433]\n",
      "epoch:10 step:9774 [D loss: 0.532967, acc.: 82.03%] [G loss: 0.757526]\n",
      "epoch:10 step:9775 [D loss: 0.432378, acc.: 81.25%] [G loss: 0.725400]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:10 step:9776 [D loss: 0.450965, acc.: 89.84%] [G loss: 0.911503]\n",
      "epoch:10 step:9777 [D loss: 0.347628, acc.: 83.59%] [G loss: 0.890125]\n",
      "epoch:10 step:9778 [D loss: 0.887563, acc.: 48.44%] [G loss: 0.863379]\n",
      "epoch:10 step:9779 [D loss: 0.513291, acc.: 75.78%] [G loss: 0.887307]\n",
      "epoch:10 step:9780 [D loss: 0.640090, acc.: 64.84%] [G loss: 0.788873]\n",
      "epoch:10 step:9781 [D loss: 0.829361, acc.: 34.38%] [G loss: 1.029192]\n",
      "epoch:10 step:9782 [D loss: 0.858608, acc.: 44.53%] [G loss: 0.989228]\n",
      "epoch:10 step:9783 [D loss: 0.644117, acc.: 65.62%] [G loss: 0.701529]\n",
      "epoch:10 step:9784 [D loss: 0.689968, acc.: 57.81%] [G loss: 0.919078]\n",
      "epoch:10 step:9785 [D loss: 0.896395, acc.: 39.06%] [G loss: 0.864516]\n",
      "epoch:10 step:9786 [D loss: 0.937882, acc.: 39.84%] [G loss: 1.067383]\n",
      "epoch:10 step:9787 [D loss: 0.650143, acc.: 60.94%] [G loss: 1.134686]\n",
      "epoch:10 step:9788 [D loss: 0.678017, acc.: 58.59%] [G loss: 1.027808]\n",
      "epoch:10 step:9789 [D loss: 0.627355, acc.: 71.88%] [G loss: 0.979495]\n",
      "epoch:10 step:9790 [D loss: 0.646542, acc.: 60.16%] [G loss: 0.974419]\n",
      "epoch:10 step:9791 [D loss: 0.756987, acc.: 46.09%] [G loss: 0.855733]\n",
      "epoch:10 step:9792 [D loss: 0.783074, acc.: 38.28%] [G loss: 0.867943]\n",
      "epoch:10 step:9793 [D loss: 0.679535, acc.: 57.81%] [G loss: 0.846787]\n",
      "epoch:10 step:9794 [D loss: 0.582556, acc.: 70.31%] [G loss: 0.856838]\n",
      "epoch:10 step:9795 [D loss: 0.531799, acc.: 79.69%] [G loss: 0.784026]\n",
      "epoch:10 step:9796 [D loss: 0.707845, acc.: 56.25%] [G loss: 0.769454]\n",
      "epoch:10 step:9797 [D loss: 0.448207, acc.: 85.16%] [G loss: 0.760942]\n",
      "epoch:10 step:9798 [D loss: 0.706715, acc.: 54.69%] [G loss: 0.987259]\n",
      "epoch:10 step:9799 [D loss: 0.699965, acc.: 58.59%] [G loss: 0.900765]\n",
      "epoch:10 step:9800 [D loss: 0.452041, acc.: 89.06%] [G loss: 1.029949]\n",
      "##############\n",
      "[3.5292208  2.66094124 6.56033019 5.79650929 4.38922866 6.13604108\n",
      " 5.09097661 5.63218299 5.8444866  4.64106782]\n",
      "##########\n",
      "epoch:10 step:9801 [D loss: 0.742022, acc.: 50.00%] [G loss: 0.942762]\n",
      "epoch:10 step:9802 [D loss: 0.725528, acc.: 51.56%] [G loss: 0.948549]\n",
      "epoch:10 step:9803 [D loss: 0.675538, acc.: 57.81%] [G loss: 0.945434]\n",
      "epoch:10 step:9804 [D loss: 0.748777, acc.: 47.66%] [G loss: 0.753114]\n",
      "epoch:10 step:9805 [D loss: 0.698319, acc.: 51.56%] [G loss: 1.038221]\n",
      "epoch:10 step:9806 [D loss: 0.666401, acc.: 58.59%] [G loss: 1.173278]\n",
      "epoch:10 step:9807 [D loss: 0.667714, acc.: 55.47%] [G loss: 1.160109]\n",
      "epoch:10 step:9808 [D loss: 0.656248, acc.: 60.16%] [G loss: 1.359553]\n",
      "epoch:10 step:9809 [D loss: 0.645612, acc.: 63.28%] [G loss: 1.338126]\n",
      "epoch:10 step:9810 [D loss: 0.619259, acc.: 63.28%] [G loss: 1.133068]\n",
      "epoch:10 step:9811 [D loss: 0.636205, acc.: 65.62%] [G loss: 1.069244]\n",
      "epoch:10 step:9812 [D loss: 0.635228, acc.: 67.19%] [G loss: 1.093490]\n",
      "epoch:10 step:9813 [D loss: 0.634003, acc.: 66.41%] [G loss: 0.893368]\n",
      "epoch:10 step:9814 [D loss: 0.646637, acc.: 63.28%] [G loss: 0.921506]\n",
      "epoch:10 step:9815 [D loss: 0.660471, acc.: 57.03%] [G loss: 0.952729]\n",
      "epoch:10 step:9816 [D loss: 0.638745, acc.: 65.62%] [G loss: 0.913478]\n",
      "epoch:10 step:9817 [D loss: 0.646978, acc.: 59.38%] [G loss: 0.920234]\n",
      "epoch:10 step:9818 [D loss: 0.624252, acc.: 64.06%] [G loss: 0.890771]\n",
      "epoch:10 step:9819 [D loss: 0.593284, acc.: 71.09%] [G loss: 0.958079]\n",
      "epoch:10 step:9820 [D loss: 0.613857, acc.: 69.53%] [G loss: 0.887197]\n",
      "epoch:10 step:9821 [D loss: 0.523858, acc.: 84.38%] [G loss: 1.060959]\n",
      "epoch:10 step:9822 [D loss: 0.535384, acc.: 77.34%] [G loss: 1.031863]\n",
      "epoch:10 step:9823 [D loss: 0.554306, acc.: 75.00%] [G loss: 1.159416]\n",
      "epoch:10 step:9824 [D loss: 0.602574, acc.: 64.84%] [G loss: 1.015743]\n",
      "epoch:10 step:9825 [D loss: 0.587608, acc.: 65.62%] [G loss: 1.021467]\n",
      "epoch:10 step:9826 [D loss: 0.507133, acc.: 80.47%] [G loss: 1.187586]\n",
      "epoch:10 step:9827 [D loss: 0.526518, acc.: 78.91%] [G loss: 1.081797]\n",
      "epoch:10 step:9828 [D loss: 0.771659, acc.: 45.31%] [G loss: 0.989446]\n",
      "epoch:10 step:9829 [D loss: 0.658004, acc.: 60.16%] [G loss: 0.953996]\n",
      "epoch:10 step:9830 [D loss: 0.669420, acc.: 60.94%] [G loss: 1.123910]\n",
      "epoch:10 step:9831 [D loss: 0.741356, acc.: 45.31%] [G loss: 1.007912]\n",
      "epoch:10 step:9832 [D loss: 0.745370, acc.: 50.00%] [G loss: 0.949952]\n",
      "epoch:10 step:9833 [D loss: 0.706828, acc.: 53.91%] [G loss: 0.958545]\n",
      "epoch:10 step:9834 [D loss: 0.621397, acc.: 67.19%] [G loss: 0.872970]\n",
      "epoch:10 step:9835 [D loss: 0.648613, acc.: 57.03%] [G loss: 0.865741]\n",
      "epoch:10 step:9836 [D loss: 0.687213, acc.: 58.59%] [G loss: 0.782891]\n",
      "epoch:10 step:9837 [D loss: 0.689713, acc.: 53.12%] [G loss: 0.927391]\n",
      "epoch:10 step:9838 [D loss: 0.558613, acc.: 75.78%] [G loss: 0.958222]\n",
      "epoch:10 step:9839 [D loss: 0.622691, acc.: 68.75%] [G loss: 0.925978]\n",
      "epoch:10 step:9840 [D loss: 0.613901, acc.: 66.41%] [G loss: 1.075032]\n",
      "epoch:10 step:9841 [D loss: 0.634569, acc.: 64.84%] [G loss: 1.050023]\n",
      "epoch:10 step:9842 [D loss: 0.612553, acc.: 66.41%] [G loss: 1.180551]\n",
      "epoch:10 step:9843 [D loss: 0.766805, acc.: 46.88%] [G loss: 1.088652]\n",
      "epoch:10 step:9844 [D loss: 0.633596, acc.: 63.28%] [G loss: 0.956864]\n",
      "epoch:10 step:9845 [D loss: 0.588824, acc.: 73.44%] [G loss: 1.135397]\n",
      "epoch:10 step:9846 [D loss: 0.703330, acc.: 64.06%] [G loss: 1.075421]\n",
      "epoch:10 step:9847 [D loss: 0.788552, acc.: 46.09%] [G loss: 1.021856]\n",
      "epoch:10 step:9848 [D loss: 0.714288, acc.: 54.69%] [G loss: 0.934211]\n",
      "epoch:10 step:9849 [D loss: 0.761791, acc.: 44.53%] [G loss: 0.856986]\n",
      "epoch:10 step:9850 [D loss: 0.679921, acc.: 57.81%] [G loss: 0.899299]\n",
      "epoch:10 step:9851 [D loss: 0.644153, acc.: 64.06%] [G loss: 0.902439]\n",
      "epoch:10 step:9852 [D loss: 0.628481, acc.: 66.41%] [G loss: 0.867429]\n",
      "epoch:10 step:9853 [D loss: 0.675877, acc.: 62.50%] [G loss: 0.853906]\n",
      "epoch:10 step:9854 [D loss: 0.658408, acc.: 57.03%] [G loss: 0.884114]\n",
      "epoch:10 step:9855 [D loss: 0.627280, acc.: 67.97%] [G loss: 0.917935]\n",
      "epoch:10 step:9856 [D loss: 0.650699, acc.: 65.62%] [G loss: 0.903975]\n",
      "epoch:10 step:9857 [D loss: 0.604866, acc.: 69.53%] [G loss: 0.867031]\n",
      "epoch:10 step:9858 [D loss: 0.602448, acc.: 69.53%] [G loss: 0.899056]\n",
      "epoch:10 step:9859 [D loss: 0.672795, acc.: 64.06%] [G loss: 0.934312]\n",
      "epoch:10 step:9860 [D loss: 0.728639, acc.: 44.53%] [G loss: 0.813415]\n",
      "epoch:10 step:9861 [D loss: 0.750922, acc.: 47.66%] [G loss: 0.879478]\n",
      "epoch:10 step:9862 [D loss: 0.731827, acc.: 48.44%] [G loss: 0.840334]\n",
      "epoch:10 step:9863 [D loss: 0.708365, acc.: 51.56%] [G loss: 0.863975]\n",
      "epoch:10 step:9864 [D loss: 0.692371, acc.: 53.12%] [G loss: 0.883286]\n",
      "epoch:10 step:9865 [D loss: 0.650531, acc.: 61.72%] [G loss: 0.806005]\n",
      "epoch:10 step:9866 [D loss: 0.655767, acc.: 57.81%] [G loss: 0.849059]\n",
      "epoch:10 step:9867 [D loss: 0.606750, acc.: 76.56%] [G loss: 0.802575]\n",
      "epoch:10 step:9868 [D loss: 0.462352, acc.: 78.12%] [G loss: 0.855699]\n",
      "epoch:10 step:9869 [D loss: 0.421217, acc.: 81.25%] [G loss: 0.905340]\n",
      "epoch:10 step:9870 [D loss: 0.736570, acc.: 51.56%] [G loss: 0.945629]\n",
      "epoch:10 step:9871 [D loss: 0.742314, acc.: 46.88%] [G loss: 0.960357]\n",
      "epoch:10 step:9872 [D loss: 0.700363, acc.: 53.91%] [G loss: 0.954223]\n",
      "epoch:10 step:9873 [D loss: 0.673305, acc.: 55.47%] [G loss: 0.905683]\n",
      "epoch:10 step:9874 [D loss: 0.632076, acc.: 66.41%] [G loss: 0.865612]\n",
      "epoch:10 step:9875 [D loss: 0.629522, acc.: 64.06%] [G loss: 0.964341]\n",
      "epoch:10 step:9876 [D loss: 0.686142, acc.: 60.16%] [G loss: 0.906946]\n",
      "epoch:10 step:9877 [D loss: 0.654892, acc.: 64.84%] [G loss: 0.937728]\n",
      "epoch:10 step:9878 [D loss: 0.630768, acc.: 68.75%] [G loss: 0.859585]\n",
      "epoch:10 step:9879 [D loss: 0.689855, acc.: 52.34%] [G loss: 0.864770]\n",
      "epoch:10 step:9880 [D loss: 0.655875, acc.: 63.28%] [G loss: 0.891277]\n",
      "epoch:10 step:9881 [D loss: 0.611461, acc.: 63.28%] [G loss: 0.735451]\n",
      "epoch:10 step:9882 [D loss: 0.511748, acc.: 77.34%] [G loss: 0.860193]\n",
      "epoch:10 step:9883 [D loss: 0.479691, acc.: 80.47%] [G loss: 0.912425]\n",
      "epoch:10 step:9884 [D loss: 0.621189, acc.: 63.28%] [G loss: 0.924349]\n",
      "epoch:10 step:9885 [D loss: 0.679679, acc.: 60.94%] [G loss: 0.882892]\n",
      "epoch:10 step:9886 [D loss: 0.608391, acc.: 70.31%] [G loss: 0.952895]\n",
      "epoch:10 step:9887 [D loss: 0.634987, acc.: 60.16%] [G loss: 0.800874]\n",
      "epoch:10 step:9888 [D loss: 0.655306, acc.: 61.72%] [G loss: 0.492976]\n",
      "epoch:10 step:9889 [D loss: 0.654988, acc.: 55.47%] [G loss: 0.863484]\n",
      "epoch:10 step:9890 [D loss: 0.621907, acc.: 64.06%] [G loss: 1.018319]\n",
      "epoch:10 step:9891 [D loss: 0.799757, acc.: 39.84%] [G loss: 0.952593]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:10 step:9892 [D loss: 0.610657, acc.: 67.97%] [G loss: 0.921043]\n",
      "epoch:10 step:9893 [D loss: 0.610639, acc.: 60.94%] [G loss: 1.070654]\n",
      "epoch:10 step:9894 [D loss: 0.726095, acc.: 57.81%] [G loss: 0.981087]\n",
      "epoch:10 step:9895 [D loss: 0.701430, acc.: 54.69%] [G loss: 0.934674]\n",
      "epoch:10 step:9896 [D loss: 0.702267, acc.: 59.38%] [G loss: 0.856922]\n",
      "epoch:10 step:9897 [D loss: 0.672940, acc.: 52.34%] [G loss: 1.005892]\n",
      "epoch:10 step:9898 [D loss: 0.740275, acc.: 47.66%] [G loss: 0.919879]\n",
      "epoch:10 step:9899 [D loss: 0.739017, acc.: 46.88%] [G loss: 0.874716]\n",
      "epoch:10 step:9900 [D loss: 0.717509, acc.: 48.44%] [G loss: 0.924867]\n",
      "epoch:10 step:9901 [D loss: 0.581431, acc.: 69.53%] [G loss: 0.944475]\n",
      "epoch:10 step:9902 [D loss: 0.590138, acc.: 71.88%] [G loss: 0.963780]\n",
      "epoch:10 step:9903 [D loss: 0.562386, acc.: 67.97%] [G loss: 0.946418]\n",
      "epoch:10 step:9904 [D loss: 0.548901, acc.: 75.78%] [G loss: 0.920104]\n",
      "epoch:10 step:9905 [D loss: 0.702955, acc.: 54.69%] [G loss: 0.939752]\n",
      "epoch:10 step:9906 [D loss: 0.663338, acc.: 58.59%] [G loss: 0.807667]\n",
      "epoch:10 step:9907 [D loss: 0.615651, acc.: 65.62%] [G loss: 0.833273]\n",
      "epoch:10 step:9908 [D loss: 0.728140, acc.: 52.34%] [G loss: 0.852287]\n",
      "epoch:10 step:9909 [D loss: 0.777561, acc.: 43.75%] [G loss: 0.894002]\n",
      "epoch:10 step:9910 [D loss: 0.714496, acc.: 50.00%] [G loss: 0.867940]\n",
      "epoch:10 step:9911 [D loss: 0.705187, acc.: 59.38%] [G loss: 0.853829]\n",
      "epoch:10 step:9912 [D loss: 0.621272, acc.: 69.53%] [G loss: 0.833224]\n",
      "epoch:10 step:9913 [D loss: 0.626092, acc.: 65.62%] [G loss: 0.880742]\n",
      "epoch:10 step:9914 [D loss: 0.622254, acc.: 67.97%] [G loss: 0.820580]\n",
      "epoch:10 step:9915 [D loss: 0.522784, acc.: 83.59%] [G loss: 1.008025]\n",
      "epoch:10 step:9916 [D loss: 0.559102, acc.: 73.44%] [G loss: 0.980161]\n",
      "epoch:10 step:9917 [D loss: 0.517506, acc.: 78.12%] [G loss: 1.192383]\n",
      "epoch:10 step:9918 [D loss: 0.553233, acc.: 75.78%] [G loss: 0.890876]\n",
      "epoch:10 step:9919 [D loss: 0.608088, acc.: 70.31%] [G loss: 0.832877]\n",
      "epoch:10 step:9920 [D loss: 0.527538, acc.: 75.00%] [G loss: 1.086237]\n",
      "epoch:10 step:9921 [D loss: 0.684970, acc.: 56.25%] [G loss: 1.181537]\n",
      "epoch:10 step:9922 [D loss: 0.519637, acc.: 78.91%] [G loss: 1.157554]\n",
      "epoch:10 step:9923 [D loss: 0.672039, acc.: 62.50%] [G loss: 0.820003]\n",
      "epoch:10 step:9924 [D loss: 0.579993, acc.: 65.62%] [G loss: 1.064914]\n",
      "epoch:10 step:9925 [D loss: 0.718880, acc.: 57.03%] [G loss: 1.166743]\n",
      "epoch:10 step:9926 [D loss: 0.638278, acc.: 62.50%] [G loss: 1.025877]\n",
      "epoch:10 step:9927 [D loss: 0.667509, acc.: 57.81%] [G loss: 1.170996]\n",
      "epoch:10 step:9928 [D loss: 0.747972, acc.: 53.91%] [G loss: 0.899989]\n",
      "epoch:10 step:9929 [D loss: 0.683120, acc.: 61.72%] [G loss: 1.238967]\n",
      "epoch:10 step:9930 [D loss: 0.787512, acc.: 53.12%] [G loss: 1.173519]\n",
      "epoch:10 step:9931 [D loss: 0.457449, acc.: 83.59%] [G loss: 1.006905]\n",
      "epoch:10 step:9932 [D loss: 0.687691, acc.: 64.06%] [G loss: 1.141532]\n",
      "epoch:10 step:9933 [D loss: 0.633572, acc.: 64.06%] [G loss: 1.030860]\n",
      "epoch:10 step:9934 [D loss: 0.639451, acc.: 66.41%] [G loss: 0.971726]\n",
      "epoch:10 step:9935 [D loss: 0.633364, acc.: 59.38%] [G loss: 0.894021]\n",
      "epoch:10 step:9936 [D loss: 0.335125, acc.: 87.50%] [G loss: 0.943378]\n",
      "epoch:10 step:9937 [D loss: 0.362398, acc.: 87.50%] [G loss: 1.106486]\n",
      "epoch:10 step:9938 [D loss: 0.419765, acc.: 89.06%] [G loss: 1.255504]\n",
      "epoch:10 step:9939 [D loss: 0.613510, acc.: 67.19%] [G loss: 1.060040]\n",
      "epoch:10 step:9940 [D loss: 0.505477, acc.: 80.47%] [G loss: 0.923248]\n",
      "epoch:10 step:9941 [D loss: 0.742057, acc.: 50.78%] [G loss: 0.936019]\n",
      "epoch:10 step:9942 [D loss: 1.223053, acc.: 45.31%] [G loss: 1.711921]\n",
      "epoch:10 step:9943 [D loss: 0.628909, acc.: 67.19%] [G loss: 1.889416]\n",
      "epoch:10 step:9944 [D loss: 0.667013, acc.: 58.59%] [G loss: 1.617948]\n",
      "epoch:10 step:9945 [D loss: 0.674510, acc.: 64.84%] [G loss: 1.057834]\n",
      "epoch:10 step:9946 [D loss: 0.861123, acc.: 37.50%] [G loss: 0.895972]\n",
      "epoch:10 step:9947 [D loss: 0.700002, acc.: 53.12%] [G loss: 0.879315]\n",
      "epoch:10 step:9948 [D loss: 0.717268, acc.: 53.12%] [G loss: 0.828596]\n",
      "epoch:10 step:9949 [D loss: 0.662705, acc.: 59.38%] [G loss: 0.908418]\n",
      "epoch:10 step:9950 [D loss: 0.711971, acc.: 57.81%] [G loss: 0.886983]\n",
      "epoch:10 step:9951 [D loss: 0.650865, acc.: 60.16%] [G loss: 0.896026]\n",
      "epoch:10 step:9952 [D loss: 0.586825, acc.: 69.53%] [G loss: 0.689270]\n",
      "epoch:10 step:9953 [D loss: 0.679584, acc.: 55.47%] [G loss: 0.785321]\n",
      "epoch:10 step:9954 [D loss: 0.729550, acc.: 55.47%] [G loss: 1.074336]\n",
      "epoch:10 step:9955 [D loss: 0.645647, acc.: 65.62%] [G loss: 0.896609]\n",
      "epoch:10 step:9956 [D loss: 0.589168, acc.: 71.09%] [G loss: 1.068302]\n",
      "epoch:10 step:9957 [D loss: 0.423829, acc.: 82.81%] [G loss: 0.965374]\n",
      "epoch:10 step:9958 [D loss: 0.520065, acc.: 78.91%] [G loss: 1.110562]\n",
      "epoch:10 step:9959 [D loss: 0.417150, acc.: 78.12%] [G loss: 1.174409]\n",
      "epoch:10 step:9960 [D loss: 0.649180, acc.: 62.50%] [G loss: 0.944916]\n",
      "epoch:10 step:9961 [D loss: 0.679885, acc.: 54.69%] [G loss: 0.980331]\n",
      "epoch:10 step:9962 [D loss: 0.674180, acc.: 60.16%] [G loss: 0.911554]\n",
      "epoch:10 step:9963 [D loss: 0.881498, acc.: 34.38%] [G loss: 0.878219]\n",
      "epoch:10 step:9964 [D loss: 0.774605, acc.: 44.53%] [G loss: 0.935883]\n",
      "epoch:10 step:9965 [D loss: 0.683136, acc.: 58.59%] [G loss: 0.900732]\n",
      "epoch:10 step:9966 [D loss: 0.624567, acc.: 68.75%] [G loss: 0.963741]\n",
      "epoch:10 step:9967 [D loss: 0.676158, acc.: 50.78%] [G loss: 1.033753]\n",
      "epoch:10 step:9968 [D loss: 0.610089, acc.: 69.53%] [G loss: 1.135454]\n",
      "epoch:10 step:9969 [D loss: 0.622268, acc.: 62.50%] [G loss: 1.135772]\n",
      "epoch:10 step:9970 [D loss: 0.670284, acc.: 70.31%] [G loss: 1.047036]\n",
      "epoch:10 step:9971 [D loss: 0.752345, acc.: 43.75%] [G loss: 0.958831]\n",
      "epoch:10 step:9972 [D loss: 0.630949, acc.: 64.84%] [G loss: 0.915766]\n",
      "epoch:10 step:9973 [D loss: 0.603413, acc.: 67.97%] [G loss: 1.046681]\n",
      "epoch:10 step:9974 [D loss: 0.615445, acc.: 70.31%] [G loss: 0.967509]\n",
      "epoch:10 step:9975 [D loss: 0.604127, acc.: 69.53%] [G loss: 0.918980]\n",
      "epoch:10 step:9976 [D loss: 0.664664, acc.: 57.03%] [G loss: 0.967597]\n",
      "epoch:10 step:9977 [D loss: 0.702256, acc.: 56.25%] [G loss: 0.800826]\n",
      "epoch:10 step:9978 [D loss: 0.693477, acc.: 56.25%] [G loss: 0.995711]\n",
      "epoch:10 step:9979 [D loss: 0.795527, acc.: 42.19%] [G loss: 0.929174]\n",
      "epoch:10 step:9980 [D loss: 0.694739, acc.: 50.00%] [G loss: 0.826134]\n",
      "epoch:10 step:9981 [D loss: 0.694956, acc.: 53.12%] [G loss: 0.800348]\n",
      "epoch:10 step:9982 [D loss: 0.758749, acc.: 42.19%] [G loss: 0.845825]\n",
      "epoch:10 step:9983 [D loss: 0.593004, acc.: 71.88%] [G loss: 0.807992]\n",
      "epoch:10 step:9984 [D loss: 0.712830, acc.: 50.00%] [G loss: 0.838571]\n",
      "epoch:10 step:9985 [D loss: 0.676488, acc.: 55.47%] [G loss: 0.807302]\n",
      "epoch:10 step:9986 [D loss: 0.681494, acc.: 56.25%] [G loss: 0.747606]\n",
      "epoch:10 step:9987 [D loss: 0.693871, acc.: 52.34%] [G loss: 0.917756]\n",
      "epoch:10 step:9988 [D loss: 0.692717, acc.: 56.25%] [G loss: 0.824733]\n",
      "epoch:10 step:9989 [D loss: 0.676332, acc.: 57.03%] [G loss: 0.827891]\n",
      "epoch:10 step:9990 [D loss: 0.612175, acc.: 62.50%] [G loss: 1.001809]\n",
      "epoch:10 step:9991 [D loss: 0.721466, acc.: 49.22%] [G loss: 0.885395]\n",
      "epoch:10 step:9992 [D loss: 0.717731, acc.: 49.22%] [G loss: 0.949049]\n",
      "epoch:10 step:9993 [D loss: 0.676702, acc.: 57.81%] [G loss: 0.903896]\n",
      "epoch:10 step:9994 [D loss: 0.649589, acc.: 64.06%] [G loss: 0.849749]\n",
      "epoch:10 step:9995 [D loss: 0.733611, acc.: 44.53%] [G loss: 0.828357]\n",
      "epoch:10 step:9996 [D loss: 0.692450, acc.: 53.12%] [G loss: 0.915842]\n",
      "epoch:10 step:9997 [D loss: 0.653530, acc.: 56.25%] [G loss: 0.947103]\n",
      "epoch:10 step:9998 [D loss: 0.673790, acc.: 57.81%] [G loss: 0.886358]\n",
      "epoch:10 step:9999 [D loss: 0.668914, acc.: 62.50%] [G loss: 0.926211]\n",
      "epoch:10 step:10000 [D loss: 0.631760, acc.: 67.97%] [G loss: 0.869653]\n",
      "##############\n",
      "[3.95237944 2.25404132 6.29396518 5.39888583 4.47036407 6.07935677\n",
      " 5.0445535  4.85863935 5.50158213 4.71252302]\n",
      "##########\n",
      "epoch:10 step:10001 [D loss: 0.721642, acc.: 50.00%] [G loss: 0.869020]\n",
      "epoch:10 step:10002 [D loss: 0.631437, acc.: 64.06%] [G loss: 0.772535]\n",
      "epoch:10 step:10003 [D loss: 0.679482, acc.: 58.59%] [G loss: 0.731717]\n",
      "epoch:10 step:10004 [D loss: 0.715943, acc.: 54.69%] [G loss: 0.838224]\n",
      "epoch:10 step:10005 [D loss: 0.663219, acc.: 55.47%] [G loss: 0.883061]\n",
      "epoch:10 step:10006 [D loss: 0.703743, acc.: 51.56%] [G loss: 0.799349]\n",
      "epoch:10 step:10007 [D loss: 0.639159, acc.: 67.19%] [G loss: 0.795622]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:10 step:10008 [D loss: 0.669503, acc.: 63.28%] [G loss: 0.848808]\n",
      "epoch:10 step:10009 [D loss: 0.684115, acc.: 55.47%] [G loss: 0.867336]\n",
      "epoch:10 step:10010 [D loss: 0.650760, acc.: 63.28%] [G loss: 0.828056]\n",
      "epoch:10 step:10011 [D loss: 0.537533, acc.: 76.56%] [G loss: 0.950453]\n",
      "epoch:10 step:10012 [D loss: 0.560311, acc.: 77.34%] [G loss: 0.879590]\n",
      "epoch:10 step:10013 [D loss: 0.748255, acc.: 50.00%] [G loss: 0.980107]\n",
      "epoch:10 step:10014 [D loss: 0.684712, acc.: 54.69%] [G loss: 0.890387]\n",
      "epoch:10 step:10015 [D loss: 0.732029, acc.: 47.66%] [G loss: 0.882739]\n",
      "epoch:10 step:10016 [D loss: 0.719067, acc.: 47.66%] [G loss: 0.858918]\n",
      "epoch:10 step:10017 [D loss: 0.701412, acc.: 55.47%] [G loss: 0.813667]\n",
      "epoch:10 step:10018 [D loss: 0.652495, acc.: 60.16%] [G loss: 0.862689]\n",
      "epoch:10 step:10019 [D loss: 0.677824, acc.: 53.91%] [G loss: 0.833904]\n",
      "epoch:10 step:10020 [D loss: 0.611110, acc.: 67.97%] [G loss: 0.873030]\n",
      "epoch:10 step:10021 [D loss: 0.646313, acc.: 61.72%] [G loss: 0.858510]\n",
      "epoch:10 step:10022 [D loss: 0.698016, acc.: 59.38%] [G loss: 0.878530]\n",
      "epoch:10 step:10023 [D loss: 0.689553, acc.: 58.59%] [G loss: 0.902397]\n",
      "epoch:10 step:10024 [D loss: 0.694073, acc.: 56.25%] [G loss: 0.823238]\n",
      "epoch:10 step:10025 [D loss: 0.667374, acc.: 66.41%] [G loss: 0.845282]\n",
      "epoch:10 step:10026 [D loss: 0.673543, acc.: 57.81%] [G loss: 0.824290]\n",
      "epoch:10 step:10027 [D loss: 0.684168, acc.: 52.34%] [G loss: 0.782627]\n",
      "epoch:10 step:10028 [D loss: 0.704454, acc.: 48.44%] [G loss: 0.784680]\n",
      "epoch:10 step:10029 [D loss: 0.639479, acc.: 54.69%] [G loss: 0.712638]\n",
      "epoch:10 step:10030 [D loss: 0.649020, acc.: 64.06%] [G loss: 0.867158]\n",
      "epoch:10 step:10031 [D loss: 0.597237, acc.: 70.31%] [G loss: 0.815404]\n",
      "epoch:10 step:10032 [D loss: 0.681236, acc.: 55.47%] [G loss: 0.712613]\n",
      "epoch:10 step:10033 [D loss: 0.438939, acc.: 77.34%] [G loss: 0.790807]\n",
      "epoch:10 step:10034 [D loss: 0.534898, acc.: 75.78%] [G loss: 0.853506]\n",
      "epoch:10 step:10035 [D loss: 0.448411, acc.: 81.25%] [G loss: 0.940642]\n",
      "epoch:10 step:10036 [D loss: 0.656754, acc.: 61.72%] [G loss: 0.898053]\n",
      "epoch:10 step:10037 [D loss: 0.626030, acc.: 67.19%] [G loss: 0.928429]\n",
      "epoch:10 step:10038 [D loss: 0.618474, acc.: 60.16%] [G loss: 0.935574]\n",
      "epoch:10 step:10039 [D loss: 0.588709, acc.: 68.75%] [G loss: 0.892184]\n",
      "epoch:10 step:10040 [D loss: 0.687330, acc.: 55.47%] [G loss: 0.811765]\n",
      "epoch:10 step:10041 [D loss: 0.632584, acc.: 64.84%] [G loss: 0.812535]\n",
      "epoch:10 step:10042 [D loss: 0.745722, acc.: 46.09%] [G loss: 0.913511]\n",
      "epoch:10 step:10043 [D loss: 0.726742, acc.: 51.56%] [G loss: 0.790922]\n",
      "epoch:10 step:10044 [D loss: 0.780839, acc.: 48.44%] [G loss: 0.976791]\n",
      "epoch:10 step:10045 [D loss: 0.743631, acc.: 40.62%] [G loss: 0.789868]\n",
      "epoch:10 step:10046 [D loss: 0.696707, acc.: 53.91%] [G loss: 0.907874]\n",
      "epoch:10 step:10047 [D loss: 0.711535, acc.: 54.69%] [G loss: 0.906389]\n",
      "epoch:10 step:10048 [D loss: 0.673583, acc.: 52.34%] [G loss: 0.899279]\n",
      "epoch:10 step:10049 [D loss: 0.705107, acc.: 53.12%] [G loss: 0.826513]\n",
      "epoch:10 step:10050 [D loss: 0.612887, acc.: 70.31%] [G loss: 0.915995]\n",
      "epoch:10 step:10051 [D loss: 0.679187, acc.: 53.91%] [G loss: 0.950806]\n",
      "epoch:10 step:10052 [D loss: 0.935520, acc.: 36.72%] [G loss: 0.961231]\n",
      "epoch:10 step:10053 [D loss: 0.672373, acc.: 67.19%] [G loss: 0.927366]\n",
      "epoch:10 step:10054 [D loss: 0.670094, acc.: 60.94%] [G loss: 1.038399]\n",
      "epoch:10 step:10055 [D loss: 0.692244, acc.: 58.59%] [G loss: 0.923174]\n",
      "epoch:10 step:10056 [D loss: 0.688962, acc.: 57.81%] [G loss: 1.025032]\n",
      "epoch:10 step:10057 [D loss: 0.659656, acc.: 58.59%] [G loss: 0.906174]\n",
      "epoch:10 step:10058 [D loss: 0.668971, acc.: 57.81%] [G loss: 0.809626]\n",
      "epoch:10 step:10059 [D loss: 0.672410, acc.: 53.91%] [G loss: 0.852210]\n",
      "epoch:10 step:10060 [D loss: 0.679516, acc.: 60.16%] [G loss: 0.884184]\n",
      "epoch:10 step:10061 [D loss: 0.656130, acc.: 63.28%] [G loss: 0.845047]\n",
      "epoch:10 step:10062 [D loss: 0.688901, acc.: 60.94%] [G loss: 0.823689]\n",
      "epoch:10 step:10063 [D loss: 0.657203, acc.: 57.03%] [G loss: 0.833125]\n",
      "epoch:10 step:10064 [D loss: 0.624016, acc.: 67.19%] [G loss: 0.854477]\n",
      "epoch:10 step:10065 [D loss: 0.726666, acc.: 49.22%] [G loss: 0.937833]\n",
      "epoch:10 step:10066 [D loss: 0.644818, acc.: 64.84%] [G loss: 0.778299]\n",
      "epoch:10 step:10067 [D loss: 0.557603, acc.: 69.53%] [G loss: 0.905987]\n",
      "epoch:10 step:10068 [D loss: 0.665213, acc.: 61.72%] [G loss: 0.797068]\n",
      "epoch:10 step:10069 [D loss: 0.717791, acc.: 60.16%] [G loss: 0.861011]\n",
      "epoch:10 step:10070 [D loss: 0.578540, acc.: 74.22%] [G loss: 0.832824]\n",
      "epoch:10 step:10071 [D loss: 0.574256, acc.: 69.53%] [G loss: 0.866546]\n",
      "epoch:10 step:10072 [D loss: 0.526279, acc.: 82.03%] [G loss: 0.908224]\n",
      "epoch:10 step:10073 [D loss: 0.714670, acc.: 50.78%] [G loss: 0.969289]\n",
      "epoch:10 step:10074 [D loss: 0.643384, acc.: 62.50%] [G loss: 0.855892]\n",
      "epoch:10 step:10075 [D loss: 0.670477, acc.: 58.59%] [G loss: 0.905895]\n",
      "epoch:10 step:10076 [D loss: 0.380101, acc.: 91.41%] [G loss: 0.968460]\n",
      "epoch:10 step:10077 [D loss: 0.332988, acc.: 89.06%] [G loss: 1.076367]\n",
      "epoch:10 step:10078 [D loss: 0.472420, acc.: 85.94%] [G loss: 0.882845]\n",
      "epoch:10 step:10079 [D loss: 0.523098, acc.: 78.91%] [G loss: 0.989520]\n",
      "epoch:10 step:10080 [D loss: 0.766387, acc.: 50.00%] [G loss: 0.550092]\n",
      "epoch:10 step:10081 [D loss: 0.698284, acc.: 54.69%] [G loss: 0.952729]\n",
      "epoch:10 step:10082 [D loss: 0.580286, acc.: 75.00%] [G loss: 0.837627]\n",
      "epoch:10 step:10083 [D loss: 0.331543, acc.: 85.16%] [G loss: 0.951663]\n",
      "epoch:10 step:10084 [D loss: 0.355592, acc.: 87.50%] [G loss: 0.983539]\n",
      "epoch:10 step:10085 [D loss: 0.661345, acc.: 61.72%] [G loss: 0.701142]\n",
      "epoch:10 step:10086 [D loss: 0.740764, acc.: 53.12%] [G loss: 0.990340]\n",
      "epoch:10 step:10087 [D loss: 0.848370, acc.: 37.50%] [G loss: 0.654034]\n",
      "epoch:10 step:10088 [D loss: 0.723376, acc.: 47.66%] [G loss: 1.065018]\n",
      "epoch:10 step:10089 [D loss: 0.582655, acc.: 72.66%] [G loss: 1.020414]\n",
      "epoch:10 step:10090 [D loss: 0.610818, acc.: 67.97%] [G loss: 1.064424]\n",
      "epoch:10 step:10091 [D loss: 0.688026, acc.: 53.12%] [G loss: 1.132507]\n",
      "epoch:10 step:10092 [D loss: 0.721680, acc.: 51.56%] [G loss: 1.056024]\n",
      "epoch:10 step:10093 [D loss: 0.644475, acc.: 62.50%] [G loss: 1.048582]\n",
      "epoch:10 step:10094 [D loss: 0.618922, acc.: 59.38%] [G loss: 1.019698]\n",
      "epoch:10 step:10095 [D loss: 0.833594, acc.: 40.62%] [G loss: 1.085185]\n",
      "epoch:10 step:10096 [D loss: 0.551585, acc.: 73.44%] [G loss: 1.230485]\n",
      "epoch:10 step:10097 [D loss: 0.803943, acc.: 41.41%] [G loss: 1.107020]\n",
      "epoch:10 step:10098 [D loss: 0.526982, acc.: 73.44%] [G loss: 1.207097]\n",
      "epoch:10 step:10099 [D loss: 0.659107, acc.: 65.62%] [G loss: 1.031399]\n",
      "epoch:10 step:10100 [D loss: 0.557412, acc.: 74.22%] [G loss: 1.001543]\n",
      "epoch:10 step:10101 [D loss: 0.557234, acc.: 70.31%] [G loss: 1.059277]\n",
      "epoch:10 step:10102 [D loss: 0.413296, acc.: 81.25%] [G loss: 1.022637]\n",
      "epoch:10 step:10103 [D loss: 0.464679, acc.: 85.16%] [G loss: 0.792516]\n",
      "epoch:10 step:10104 [D loss: 0.682957, acc.: 53.91%] [G loss: 1.056752]\n",
      "epoch:10 step:10105 [D loss: 0.671821, acc.: 57.03%] [G loss: 0.989605]\n",
      "epoch:10 step:10106 [D loss: 0.683186, acc.: 46.88%] [G loss: 0.746984]\n",
      "epoch:10 step:10107 [D loss: 0.685582, acc.: 57.81%] [G loss: 0.863249]\n",
      "epoch:10 step:10108 [D loss: 0.658966, acc.: 56.25%] [G loss: 0.985267]\n",
      "epoch:10 step:10109 [D loss: 0.652003, acc.: 57.81%] [G loss: 0.622595]\n",
      "epoch:10 step:10110 [D loss: 0.828142, acc.: 35.94%] [G loss: 0.900914]\n",
      "epoch:10 step:10111 [D loss: 0.644043, acc.: 59.38%] [G loss: 1.149137]\n",
      "epoch:10 step:10112 [D loss: 0.675311, acc.: 50.78%] [G loss: 1.290279]\n",
      "epoch:10 step:10113 [D loss: 0.499885, acc.: 76.56%] [G loss: 1.131232]\n",
      "epoch:10 step:10114 [D loss: 0.696694, acc.: 56.25%] [G loss: 1.228620]\n",
      "epoch:10 step:10115 [D loss: 0.785485, acc.: 44.53%] [G loss: 1.202280]\n",
      "epoch:10 step:10116 [D loss: 0.609568, acc.: 65.62%] [G loss: 1.193978]\n",
      "epoch:10 step:10117 [D loss: 0.669481, acc.: 60.94%] [G loss: 1.087991]\n",
      "epoch:10 step:10118 [D loss: 0.617799, acc.: 62.50%] [G loss: 1.025275]\n",
      "epoch:10 step:10119 [D loss: 0.479750, acc.: 84.38%] [G loss: 1.136394]\n",
      "epoch:10 step:10120 [D loss: 0.459272, acc.: 86.72%] [G loss: 0.971850]\n",
      "epoch:10 step:10121 [D loss: 0.743300, acc.: 50.78%] [G loss: 0.777887]\n",
      "epoch:10 step:10122 [D loss: 0.790318, acc.: 46.09%] [G loss: 0.740439]\n",
      "epoch:10 step:10123 [D loss: 0.726012, acc.: 56.25%] [G loss: 0.757227]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:10 step:10124 [D loss: 0.807269, acc.: 44.53%] [G loss: 0.765564]\n",
      "epoch:10 step:10125 [D loss: 0.756883, acc.: 42.19%] [G loss: 0.913544]\n",
      "epoch:10 step:10126 [D loss: 0.697368, acc.: 49.22%] [G loss: 0.898957]\n",
      "epoch:10 step:10127 [D loss: 0.726301, acc.: 50.00%] [G loss: 0.843780]\n",
      "epoch:10 step:10128 [D loss: 0.696850, acc.: 55.47%] [G loss: 0.879269]\n",
      "epoch:10 step:10129 [D loss: 0.629327, acc.: 67.19%] [G loss: 0.787043]\n",
      "epoch:10 step:10130 [D loss: 0.609242, acc.: 63.28%] [G loss: 0.954957]\n",
      "epoch:10 step:10131 [D loss: 0.607225, acc.: 70.31%] [G loss: 0.849317]\n",
      "epoch:10 step:10132 [D loss: 0.645459, acc.: 61.72%] [G loss: 0.848483]\n",
      "epoch:10 step:10133 [D loss: 0.663942, acc.: 59.38%] [G loss: 1.006456]\n",
      "epoch:10 step:10134 [D loss: 0.529579, acc.: 71.09%] [G loss: 0.972877]\n",
      "epoch:10 step:10135 [D loss: 0.688535, acc.: 59.38%] [G loss: 0.946534]\n",
      "epoch:10 step:10136 [D loss: 0.642423, acc.: 65.62%] [G loss: 0.881212]\n",
      "epoch:10 step:10137 [D loss: 0.653337, acc.: 61.72%] [G loss: 0.877964]\n",
      "epoch:10 step:10138 [D loss: 0.644616, acc.: 66.41%] [G loss: 0.831208]\n",
      "epoch:10 step:10139 [D loss: 0.671985, acc.: 57.03%] [G loss: 0.831088]\n",
      "epoch:10 step:10140 [D loss: 0.601591, acc.: 60.94%] [G loss: 1.028102]\n",
      "epoch:10 step:10141 [D loss: 0.712622, acc.: 53.91%] [G loss: 0.971693]\n",
      "epoch:10 step:10142 [D loss: 0.689398, acc.: 54.69%] [G loss: 0.857309]\n",
      "epoch:10 step:10143 [D loss: 0.702201, acc.: 54.69%] [G loss: 0.825189]\n",
      "epoch:10 step:10144 [D loss: 0.744455, acc.: 49.22%] [G loss: 0.808021]\n",
      "epoch:10 step:10145 [D loss: 0.667230, acc.: 60.94%] [G loss: 0.827801]\n",
      "epoch:10 step:10146 [D loss: 0.724584, acc.: 46.88%] [G loss: 0.781115]\n",
      "epoch:10 step:10147 [D loss: 0.693469, acc.: 54.69%] [G loss: 0.773425]\n",
      "epoch:10 step:10148 [D loss: 0.692779, acc.: 51.56%] [G loss: 0.706495]\n",
      "epoch:10 step:10149 [D loss: 0.668123, acc.: 60.94%] [G loss: 0.778902]\n",
      "epoch:10 step:10150 [D loss: 0.578763, acc.: 76.56%] [G loss: 0.831720]\n",
      "epoch:10 step:10151 [D loss: 0.561795, acc.: 71.09%] [G loss: 0.791992]\n",
      "epoch:10 step:10152 [D loss: 0.535536, acc.: 67.97%] [G loss: 0.850287]\n",
      "epoch:10 step:10153 [D loss: 0.675516, acc.: 58.59%] [G loss: 0.976408]\n",
      "epoch:10 step:10154 [D loss: 0.808388, acc.: 43.75%] [G loss: 0.827450]\n",
      "epoch:10 step:10155 [D loss: 0.677363, acc.: 57.81%] [G loss: 0.886944]\n",
      "epoch:10 step:10156 [D loss: 0.546242, acc.: 77.34%] [G loss: 0.902074]\n",
      "epoch:10 step:10157 [D loss: 0.695799, acc.: 57.03%] [G loss: 0.805561]\n",
      "epoch:10 step:10158 [D loss: 0.639782, acc.: 63.28%] [G loss: 0.902027]\n",
      "epoch:10 step:10159 [D loss: 0.727735, acc.: 53.12%] [G loss: 0.808803]\n",
      "epoch:10 step:10160 [D loss: 0.652194, acc.: 57.03%] [G loss: 0.918225]\n",
      "epoch:10 step:10161 [D loss: 0.386783, acc.: 85.16%] [G loss: 0.881401]\n",
      "epoch:10 step:10162 [D loss: 0.516372, acc.: 67.97%] [G loss: 0.891020]\n",
      "epoch:10 step:10163 [D loss: 0.687509, acc.: 63.28%] [G loss: 1.062950]\n",
      "epoch:10 step:10164 [D loss: 0.637042, acc.: 67.97%] [G loss: 1.244668]\n",
      "epoch:10 step:10165 [D loss: 0.579638, acc.: 69.53%] [G loss: 1.165334]\n",
      "epoch:10 step:10166 [D loss: 0.604641, acc.: 71.09%] [G loss: 0.985044]\n",
      "epoch:10 step:10167 [D loss: 0.737922, acc.: 55.47%] [G loss: 0.928697]\n",
      "epoch:10 step:10168 [D loss: 0.731653, acc.: 47.66%] [G loss: 0.845042]\n",
      "epoch:10 step:10169 [D loss: 0.684237, acc.: 55.47%] [G loss: 0.817167]\n",
      "epoch:10 step:10170 [D loss: 0.794439, acc.: 35.16%] [G loss: 0.912182]\n",
      "epoch:10 step:10171 [D loss: 0.724414, acc.: 48.44%] [G loss: 0.906337]\n",
      "epoch:10 step:10172 [D loss: 0.655476, acc.: 60.94%] [G loss: 1.010406]\n",
      "epoch:10 step:10173 [D loss: 0.659665, acc.: 58.59%] [G loss: 0.984894]\n",
      "epoch:10 step:10174 [D loss: 0.404388, acc.: 89.06%] [G loss: 0.992741]\n",
      "epoch:10 step:10175 [D loss: 0.648495, acc.: 66.41%] [G loss: 0.954620]\n",
      "epoch:10 step:10176 [D loss: 0.353937, acc.: 84.38%] [G loss: 0.918563]\n",
      "epoch:10 step:10177 [D loss: 0.679805, acc.: 55.47%] [G loss: 0.538447]\n",
      "epoch:10 step:10178 [D loss: 0.824633, acc.: 42.97%] [G loss: 1.091383]\n",
      "epoch:10 step:10179 [D loss: 0.592391, acc.: 64.06%] [G loss: 1.152294]\n",
      "epoch:10 step:10180 [D loss: 0.585752, acc.: 70.31%] [G loss: 1.061043]\n",
      "epoch:10 step:10181 [D loss: 0.721014, acc.: 53.91%] [G loss: 1.020272]\n",
      "epoch:10 step:10182 [D loss: 0.675820, acc.: 55.47%] [G loss: 1.000228]\n",
      "epoch:10 step:10183 [D loss: 0.663797, acc.: 55.47%] [G loss: 0.874851]\n",
      "epoch:10 step:10184 [D loss: 0.715463, acc.: 48.44%] [G loss: 0.909720]\n",
      "epoch:10 step:10185 [D loss: 0.555626, acc.: 78.12%] [G loss: 1.078117]\n",
      "epoch:10 step:10186 [D loss: 0.655802, acc.: 57.81%] [G loss: 0.892369]\n",
      "epoch:10 step:10187 [D loss: 0.671937, acc.: 56.25%] [G loss: 0.926771]\n",
      "epoch:10 step:10188 [D loss: 0.692370, acc.: 57.81%] [G loss: 0.834290]\n",
      "epoch:10 step:10189 [D loss: 0.720376, acc.: 52.34%] [G loss: 0.855504]\n",
      "epoch:10 step:10190 [D loss: 0.813531, acc.: 37.50%] [G loss: 0.947205]\n",
      "epoch:10 step:10191 [D loss: 0.730214, acc.: 49.22%] [G loss: 0.938596]\n",
      "epoch:10 step:10192 [D loss: 0.705771, acc.: 49.22%] [G loss: 0.944310]\n",
      "epoch:10 step:10193 [D loss: 0.697005, acc.: 55.47%] [G loss: 0.831872]\n",
      "epoch:10 step:10194 [D loss: 0.651824, acc.: 64.06%] [G loss: 0.798807]\n",
      "epoch:10 step:10195 [D loss: 0.635430, acc.: 63.28%] [G loss: 0.814479]\n",
      "epoch:10 step:10196 [D loss: 0.634399, acc.: 64.06%] [G loss: 0.806137]\n",
      "epoch:10 step:10197 [D loss: 0.731079, acc.: 53.12%] [G loss: 0.712978]\n",
      "epoch:10 step:10198 [D loss: 0.689205, acc.: 52.34%] [G loss: 0.783437]\n",
      "epoch:10 step:10199 [D loss: 0.633257, acc.: 68.75%] [G loss: 0.943135]\n",
      "epoch:10 step:10200 [D loss: 0.657331, acc.: 62.50%] [G loss: 0.846532]\n",
      "##############\n",
      "[3.65364089 2.58662483 6.70541336 5.55287701 4.1707891  6.068247\n",
      " 4.88432635 5.15907266 5.58227636 4.55915368]\n",
      "##########\n",
      "epoch:10 step:10201 [D loss: 0.623709, acc.: 69.53%] [G loss: 0.949382]\n",
      "epoch:10 step:10202 [D loss: 0.613102, acc.: 64.84%] [G loss: 0.755061]\n",
      "epoch:10 step:10203 [D loss: 0.673108, acc.: 57.81%] [G loss: 0.711452]\n",
      "epoch:10 step:10204 [D loss: 0.700815, acc.: 57.03%] [G loss: 0.662914]\n",
      "epoch:10 step:10205 [D loss: 0.681454, acc.: 57.81%] [G loss: 0.866092]\n",
      "epoch:10 step:10206 [D loss: 0.664203, acc.: 64.06%] [G loss: 0.983599]\n",
      "epoch:10 step:10207 [D loss: 0.699017, acc.: 53.91%] [G loss: 0.822316]\n",
      "epoch:10 step:10208 [D loss: 0.681677, acc.: 48.44%] [G loss: 0.871087]\n",
      "epoch:10 step:10209 [D loss: 0.649224, acc.: 60.94%] [G loss: 0.820551]\n",
      "epoch:10 step:10210 [D loss: 0.686560, acc.: 56.25%] [G loss: 0.839700]\n",
      "epoch:10 step:10211 [D loss: 0.620059, acc.: 65.62%] [G loss: 0.964487]\n",
      "epoch:10 step:10212 [D loss: 0.606207, acc.: 67.19%] [G loss: 0.934114]\n",
      "epoch:10 step:10213 [D loss: 0.736168, acc.: 50.00%] [G loss: 0.913483]\n",
      "epoch:10 step:10214 [D loss: 0.640524, acc.: 60.94%] [G loss: 0.812911]\n",
      "epoch:10 step:10215 [D loss: 0.663675, acc.: 59.38%] [G loss: 0.745477]\n",
      "epoch:10 step:10216 [D loss: 0.645500, acc.: 62.50%] [G loss: 0.859451]\n",
      "epoch:10 step:10217 [D loss: 0.658901, acc.: 59.38%] [G loss: 0.921608]\n",
      "epoch:10 step:10218 [D loss: 0.720634, acc.: 51.56%] [G loss: 0.836317]\n",
      "epoch:10 step:10219 [D loss: 0.636154, acc.: 65.62%] [G loss: 0.540416]\n",
      "epoch:10 step:10220 [D loss: 0.466666, acc.: 78.12%] [G loss: 0.942686]\n",
      "epoch:10 step:10221 [D loss: 0.516257, acc.: 82.81%] [G loss: 0.975951]\n",
      "epoch:10 step:10222 [D loss: 0.553246, acc.: 72.66%] [G loss: 0.854000]\n",
      "epoch:10 step:10223 [D loss: 0.610245, acc.: 69.53%] [G loss: 0.904322]\n",
      "epoch:10 step:10224 [D loss: 0.411261, acc.: 82.03%] [G loss: 0.944184]\n",
      "epoch:10 step:10225 [D loss: 0.669734, acc.: 60.94%] [G loss: 0.944330]\n",
      "epoch:10 step:10226 [D loss: 0.761381, acc.: 42.97%] [G loss: 1.049519]\n",
      "epoch:10 step:10227 [D loss: 0.522845, acc.: 79.69%] [G loss: 0.740351]\n",
      "epoch:10 step:10228 [D loss: 0.980567, acc.: 25.78%] [G loss: 0.733929]\n",
      "epoch:10 step:10229 [D loss: 0.724546, acc.: 43.75%] [G loss: 0.885690]\n",
      "epoch:10 step:10230 [D loss: 0.836162, acc.: 35.94%] [G loss: 0.983792]\n",
      "epoch:10 step:10231 [D loss: 0.801193, acc.: 35.94%] [G loss: 0.988159]\n",
      "epoch:10 step:10232 [D loss: 0.675337, acc.: 53.91%] [G loss: 1.023448]\n",
      "epoch:10 step:10233 [D loss: 0.663782, acc.: 56.25%] [G loss: 1.021545]\n",
      "epoch:10 step:10234 [D loss: 0.637008, acc.: 60.94%] [G loss: 1.044702]\n",
      "epoch:10 step:10235 [D loss: 0.694660, acc.: 54.69%] [G loss: 1.194713]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:10 step:10236 [D loss: 0.631442, acc.: 60.16%] [G loss: 1.054989]\n",
      "epoch:10 step:10237 [D loss: 0.670378, acc.: 60.94%] [G loss: 0.991891]\n",
      "epoch:10 step:10238 [D loss: 0.648778, acc.: 60.16%] [G loss: 0.886126]\n",
      "epoch:10 step:10239 [D loss: 0.683134, acc.: 57.03%] [G loss: 1.058403]\n",
      "epoch:10 step:10240 [D loss: 0.626513, acc.: 60.16%] [G loss: 0.931591]\n",
      "epoch:10 step:10241 [D loss: 0.586874, acc.: 71.88%] [G loss: 1.020536]\n",
      "epoch:10 step:10242 [D loss: 0.749365, acc.: 51.56%] [G loss: 0.820570]\n",
      "epoch:10 step:10243 [D loss: 0.672388, acc.: 65.62%] [G loss: 0.801156]\n",
      "epoch:10 step:10244 [D loss: 0.634661, acc.: 65.62%] [G loss: 0.766356]\n",
      "epoch:10 step:10245 [D loss: 0.640770, acc.: 61.72%] [G loss: 0.918176]\n",
      "epoch:10 step:10246 [D loss: 0.671173, acc.: 61.72%] [G loss: 0.978973]\n",
      "epoch:10 step:10247 [D loss: 0.617878, acc.: 66.41%] [G loss: 0.676586]\n",
      "epoch:10 step:10248 [D loss: 0.552494, acc.: 76.56%] [G loss: 0.855947]\n",
      "epoch:10 step:10249 [D loss: 0.755491, acc.: 37.50%] [G loss: 0.884811]\n",
      "epoch:10 step:10250 [D loss: 0.766203, acc.: 50.00%] [G loss: 0.789944]\n",
      "epoch:10 step:10251 [D loss: 0.706361, acc.: 53.91%] [G loss: 0.937594]\n",
      "epoch:10 step:10252 [D loss: 0.660813, acc.: 61.72%] [G loss: 0.793669]\n",
      "epoch:10 step:10253 [D loss: 0.696523, acc.: 53.91%] [G loss: 0.827020]\n",
      "epoch:10 step:10254 [D loss: 0.664690, acc.: 60.94%] [G loss: 0.866234]\n",
      "epoch:10 step:10255 [D loss: 0.432390, acc.: 76.56%] [G loss: 0.912915]\n",
      "epoch:10 step:10256 [D loss: 0.569367, acc.: 68.75%] [G loss: 0.914764]\n",
      "epoch:10 step:10257 [D loss: 0.557072, acc.: 73.44%] [G loss: 0.832752]\n",
      "epoch:10 step:10258 [D loss: 0.627388, acc.: 67.97%] [G loss: 1.024327]\n",
      "epoch:10 step:10259 [D loss: 0.486230, acc.: 82.03%] [G loss: 1.022221]\n",
      "epoch:10 step:10260 [D loss: 0.439220, acc.: 83.59%] [G loss: 0.947565]\n",
      "epoch:10 step:10261 [D loss: 0.786593, acc.: 42.19%] [G loss: 0.821944]\n",
      "epoch:10 step:10262 [D loss: 0.753459, acc.: 49.22%] [G loss: 0.807699]\n",
      "epoch:10 step:10263 [D loss: 0.690757, acc.: 50.78%] [G loss: 1.025716]\n",
      "epoch:10 step:10264 [D loss: 0.734842, acc.: 44.53%] [G loss: 0.923749]\n",
      "epoch:10 step:10265 [D loss: 0.667930, acc.: 59.38%] [G loss: 0.911444]\n",
      "epoch:10 step:10266 [D loss: 0.689001, acc.: 59.38%] [G loss: 0.847830]\n",
      "epoch:10 step:10267 [D loss: 0.712241, acc.: 48.44%] [G loss: 0.820973]\n",
      "epoch:10 step:10268 [D loss: 0.666730, acc.: 58.59%] [G loss: 0.862093]\n",
      "epoch:10 step:10269 [D loss: 0.633957, acc.: 66.41%] [G loss: 0.935636]\n",
      "epoch:10 step:10270 [D loss: 0.628086, acc.: 63.28%] [G loss: 0.957956]\n",
      "epoch:10 step:10271 [D loss: 0.596302, acc.: 65.62%] [G loss: 0.945191]\n",
      "epoch:10 step:10272 [D loss: 0.663678, acc.: 57.81%] [G loss: 0.874990]\n",
      "epoch:10 step:10273 [D loss: 0.680899, acc.: 55.47%] [G loss: 0.852223]\n",
      "epoch:10 step:10274 [D loss: 0.492465, acc.: 74.22%] [G loss: 0.793339]\n",
      "epoch:10 step:10275 [D loss: 0.637810, acc.: 63.28%] [G loss: 0.804797]\n",
      "epoch:10 step:10276 [D loss: 0.593050, acc.: 73.44%] [G loss: 0.886160]\n",
      "epoch:10 step:10277 [D loss: 0.714902, acc.: 50.00%] [G loss: 0.877389]\n",
      "epoch:10 step:10278 [D loss: 0.662928, acc.: 57.81%] [G loss: 0.903974]\n",
      "epoch:10 step:10279 [D loss: 0.693675, acc.: 53.91%] [G loss: 0.858656]\n",
      "epoch:10 step:10280 [D loss: 1.121209, acc.: 44.53%] [G loss: 0.891107]\n",
      "epoch:10 step:10281 [D loss: 0.632907, acc.: 67.97%] [G loss: 0.877561]\n",
      "epoch:10 step:10282 [D loss: 0.526771, acc.: 76.56%] [G loss: 0.915907]\n",
      "epoch:10 step:10283 [D loss: 0.711601, acc.: 53.12%] [G loss: 0.805460]\n",
      "epoch:10 step:10284 [D loss: 0.689203, acc.: 55.47%] [G loss: 0.870711]\n",
      "epoch:10 step:10285 [D loss: 0.713117, acc.: 48.44%] [G loss: 0.850309]\n",
      "epoch:10 step:10286 [D loss: 0.685347, acc.: 54.69%] [G loss: 0.788461]\n",
      "epoch:10 step:10287 [D loss: 0.649859, acc.: 61.72%] [G loss: 0.777864]\n",
      "epoch:10 step:10288 [D loss: 0.623870, acc.: 64.84%] [G loss: 0.868249]\n",
      "epoch:10 step:10289 [D loss: 0.706011, acc.: 55.47%] [G loss: 0.864416]\n",
      "epoch:10 step:10290 [D loss: 0.712139, acc.: 53.91%] [G loss: 0.778012]\n",
      "epoch:10 step:10291 [D loss: 0.627787, acc.: 64.06%] [G loss: 0.887182]\n",
      "epoch:10 step:10292 [D loss: 0.674810, acc.: 59.38%] [G loss: 0.861778]\n",
      "epoch:10 step:10293 [D loss: 0.587965, acc.: 72.66%] [G loss: 0.882324]\n",
      "epoch:10 step:10294 [D loss: 0.545902, acc.: 80.47%] [G loss: 0.912041]\n",
      "epoch:10 step:10295 [D loss: 0.594644, acc.: 70.31%] [G loss: 0.762423]\n",
      "epoch:10 step:10296 [D loss: 0.542333, acc.: 77.34%] [G loss: 0.872040]\n",
      "epoch:10 step:10297 [D loss: 0.587211, acc.: 70.31%] [G loss: 1.101376]\n",
      "epoch:10 step:10298 [D loss: 0.723329, acc.: 50.78%] [G loss: 1.019855]\n",
      "epoch:10 step:10299 [D loss: 0.414015, acc.: 78.91%] [G loss: 0.881953]\n",
      "epoch:10 step:10300 [D loss: 0.639225, acc.: 62.50%] [G loss: 0.999115]\n",
      "epoch:10 step:10301 [D loss: 0.590159, acc.: 75.78%] [G loss: 1.025272]\n",
      "epoch:10 step:10302 [D loss: 0.669273, acc.: 60.94%] [G loss: 0.812354]\n",
      "epoch:10 step:10303 [D loss: 0.633640, acc.: 67.97%] [G loss: 0.850261]\n",
      "epoch:10 step:10304 [D loss: 0.613946, acc.: 67.97%] [G loss: 0.895872]\n",
      "epoch:10 step:10305 [D loss: 0.516706, acc.: 78.12%] [G loss: 0.725771]\n",
      "epoch:10 step:10306 [D loss: 0.506869, acc.: 72.66%] [G loss: 0.801490]\n",
      "epoch:10 step:10307 [D loss: 0.549952, acc.: 69.53%] [G loss: 0.771360]\n",
      "epoch:11 step:10308 [D loss: 0.888143, acc.: 34.38%] [G loss: 0.747112]\n",
      "epoch:11 step:10309 [D loss: 0.897867, acc.: 24.22%] [G loss: 0.899517]\n",
      "epoch:11 step:10310 [D loss: 0.780894, acc.: 41.41%] [G loss: 0.970528]\n",
      "epoch:11 step:10311 [D loss: 0.781619, acc.: 40.62%] [G loss: 0.901917]\n",
      "epoch:11 step:10312 [D loss: 0.706531, acc.: 50.78%] [G loss: 0.902738]\n",
      "epoch:11 step:10313 [D loss: 0.765588, acc.: 46.88%] [G loss: 0.842455]\n",
      "epoch:11 step:10314 [D loss: 0.717222, acc.: 46.88%] [G loss: 0.836572]\n",
      "epoch:11 step:10315 [D loss: 0.732019, acc.: 42.97%] [G loss: 0.776426]\n",
      "epoch:11 step:10316 [D loss: 0.703200, acc.: 47.66%] [G loss: 0.877290]\n",
      "epoch:11 step:10317 [D loss: 0.674642, acc.: 57.81%] [G loss: 0.792879]\n",
      "epoch:11 step:10318 [D loss: 0.675980, acc.: 57.81%] [G loss: 0.747079]\n",
      "epoch:11 step:10319 [D loss: 0.721765, acc.: 49.22%] [G loss: 0.786078]\n",
      "epoch:11 step:10320 [D loss: 0.715709, acc.: 47.66%] [G loss: 0.778639]\n",
      "epoch:11 step:10321 [D loss: 0.689428, acc.: 57.03%] [G loss: 0.869699]\n",
      "epoch:11 step:10322 [D loss: 0.705664, acc.: 54.69%] [G loss: 0.829087]\n",
      "epoch:11 step:10323 [D loss: 0.675428, acc.: 60.94%] [G loss: 0.809239]\n",
      "epoch:11 step:10324 [D loss: 0.749588, acc.: 42.19%] [G loss: 0.806733]\n",
      "epoch:11 step:10325 [D loss: 0.696097, acc.: 53.91%] [G loss: 0.788975]\n",
      "epoch:11 step:10326 [D loss: 0.716591, acc.: 50.78%] [G loss: 0.840792]\n",
      "epoch:11 step:10327 [D loss: 0.740082, acc.: 46.88%] [G loss: 0.900475]\n",
      "epoch:11 step:10328 [D loss: 0.699166, acc.: 52.34%] [G loss: 0.813911]\n",
      "epoch:11 step:10329 [D loss: 0.679230, acc.: 54.69%] [G loss: 0.906705]\n",
      "epoch:11 step:10330 [D loss: 0.654121, acc.: 62.50%] [G loss: 0.954733]\n",
      "epoch:11 step:10331 [D loss: 0.695102, acc.: 56.25%] [G loss: 0.883942]\n",
      "epoch:11 step:10332 [D loss: 0.640406, acc.: 65.62%] [G loss: 0.967075]\n",
      "epoch:11 step:10333 [D loss: 0.695704, acc.: 57.03%] [G loss: 0.897009]\n",
      "epoch:11 step:10334 [D loss: 0.602809, acc.: 69.53%] [G loss: 0.951594]\n",
      "epoch:11 step:10335 [D loss: 0.658357, acc.: 64.06%] [G loss: 0.929195]\n",
      "epoch:11 step:10336 [D loss: 0.657102, acc.: 61.72%] [G loss: 0.980519]\n",
      "epoch:11 step:10337 [D loss: 0.628154, acc.: 66.41%] [G loss: 0.941223]\n",
      "epoch:11 step:10338 [D loss: 0.593274, acc.: 72.66%] [G loss: 0.957492]\n",
      "epoch:11 step:10339 [D loss: 0.593530, acc.: 73.44%] [G loss: 0.850358]\n",
      "epoch:11 step:10340 [D loss: 0.577925, acc.: 76.56%] [G loss: 0.921721]\n",
      "epoch:11 step:10341 [D loss: 0.596780, acc.: 70.31%] [G loss: 1.033652]\n",
      "epoch:11 step:10342 [D loss: 0.447085, acc.: 89.84%] [G loss: 1.019088]\n",
      "epoch:11 step:10343 [D loss: 0.428097, acc.: 75.78%] [G loss: 1.207182]\n",
      "epoch:11 step:10344 [D loss: 0.761450, acc.: 48.44%] [G loss: 0.993296]\n",
      "epoch:11 step:10345 [D loss: 0.898769, acc.: 36.72%] [G loss: 0.927548]\n",
      "epoch:11 step:10346 [D loss: 0.768786, acc.: 40.62%] [G loss: 0.816749]\n",
      "epoch:11 step:10347 [D loss: 0.720585, acc.: 53.12%] [G loss: 0.818843]\n",
      "epoch:11 step:10348 [D loss: 0.702338, acc.: 50.00%] [G loss: 0.796202]\n",
      "epoch:11 step:10349 [D loss: 0.636972, acc.: 66.41%] [G loss: 0.804736]\n",
      "epoch:11 step:10350 [D loss: 0.627093, acc.: 62.50%] [G loss: 0.804852]\n",
      "epoch:11 step:10351 [D loss: 0.622677, acc.: 61.72%] [G loss: 0.822493]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:11 step:10352 [D loss: 0.701053, acc.: 59.38%] [G loss: 0.715027]\n",
      "epoch:11 step:10353 [D loss: 0.705964, acc.: 55.47%] [G loss: 0.774996]\n",
      "epoch:11 step:10354 [D loss: 0.718215, acc.: 48.44%] [G loss: 0.811602]\n",
      "epoch:11 step:10355 [D loss: 0.709991, acc.: 50.00%] [G loss: 0.866724]\n",
      "epoch:11 step:10356 [D loss: 0.687115, acc.: 60.94%] [G loss: 0.747617]\n",
      "epoch:11 step:10357 [D loss: 0.650700, acc.: 54.69%] [G loss: 0.747260]\n",
      "epoch:11 step:10358 [D loss: 0.674289, acc.: 58.59%] [G loss: 0.862141]\n",
      "epoch:11 step:10359 [D loss: 0.721235, acc.: 46.09%] [G loss: 0.867466]\n",
      "epoch:11 step:10360 [D loss: 0.682351, acc.: 55.47%] [G loss: 0.769004]\n",
      "epoch:11 step:10361 [D loss: 0.692477, acc.: 52.34%] [G loss: 0.929506]\n",
      "epoch:11 step:10362 [D loss: 0.732805, acc.: 54.69%] [G loss: 0.809176]\n",
      "epoch:11 step:10363 [D loss: 0.645340, acc.: 60.94%] [G loss: 0.810472]\n",
      "epoch:11 step:10364 [D loss: 0.651989, acc.: 57.81%] [G loss: 0.870896]\n",
      "epoch:11 step:10365 [D loss: 0.757584, acc.: 55.47%] [G loss: 0.929037]\n",
      "epoch:11 step:10366 [D loss: 0.654970, acc.: 60.16%] [G loss: 0.999306]\n",
      "epoch:11 step:10367 [D loss: 0.595495, acc.: 67.97%] [G loss: 0.962056]\n",
      "epoch:11 step:10368 [D loss: 0.659478, acc.: 62.50%] [G loss: 1.057509]\n",
      "epoch:11 step:10369 [D loss: 0.621166, acc.: 68.75%] [G loss: 0.915979]\n",
      "epoch:11 step:10370 [D loss: 0.654174, acc.: 64.84%] [G loss: 0.971305]\n",
      "epoch:11 step:10371 [D loss: 0.620882, acc.: 70.31%] [G loss: 0.829775]\n",
      "epoch:11 step:10372 [D loss: 0.682926, acc.: 60.94%] [G loss: 0.990910]\n",
      "epoch:11 step:10373 [D loss: 0.683029, acc.: 53.91%] [G loss: 0.913201]\n",
      "epoch:11 step:10374 [D loss: 0.664861, acc.: 57.03%] [G loss: 0.829879]\n",
      "epoch:11 step:10375 [D loss: 0.668315, acc.: 54.69%] [G loss: 0.805595]\n",
      "epoch:11 step:10376 [D loss: 0.667072, acc.: 60.94%] [G loss: 0.800138]\n",
      "epoch:11 step:10377 [D loss: 0.649541, acc.: 62.50%] [G loss: 0.804390]\n",
      "epoch:11 step:10378 [D loss: 0.693667, acc.: 57.03%] [G loss: 0.832113]\n",
      "epoch:11 step:10379 [D loss: 0.691881, acc.: 57.81%] [G loss: 0.821540]\n",
      "epoch:11 step:10380 [D loss: 0.716218, acc.: 52.34%] [G loss: 0.779122]\n",
      "epoch:11 step:10381 [D loss: 0.689901, acc.: 56.25%] [G loss: 0.757556]\n",
      "epoch:11 step:10382 [D loss: 0.676296, acc.: 56.25%] [G loss: 0.810987]\n",
      "epoch:11 step:10383 [D loss: 0.530360, acc.: 76.56%] [G loss: 0.819124]\n",
      "epoch:11 step:10384 [D loss: 0.521371, acc.: 76.56%] [G loss: 0.851579]\n",
      "epoch:11 step:10385 [D loss: 0.693059, acc.: 50.78%] [G loss: 0.822140]\n",
      "epoch:11 step:10386 [D loss: 0.656077, acc.: 59.38%] [G loss: 0.873559]\n",
      "epoch:11 step:10387 [D loss: 0.666885, acc.: 57.81%] [G loss: 0.802743]\n",
      "epoch:11 step:10388 [D loss: 0.675654, acc.: 57.03%] [G loss: 0.842579]\n",
      "epoch:11 step:10389 [D loss: 0.697309, acc.: 48.44%] [G loss: 0.890729]\n",
      "epoch:11 step:10390 [D loss: 0.686373, acc.: 55.47%] [G loss: 0.835872]\n",
      "epoch:11 step:10391 [D loss: 0.686975, acc.: 54.69%] [G loss: 0.816111]\n",
      "epoch:11 step:10392 [D loss: 0.682987, acc.: 55.47%] [G loss: 0.832706]\n",
      "epoch:11 step:10393 [D loss: 0.650887, acc.: 62.50%] [G loss: 0.804142]\n",
      "epoch:11 step:10394 [D loss: 0.643663, acc.: 64.06%] [G loss: 0.824350]\n",
      "epoch:11 step:10395 [D loss: 0.618556, acc.: 67.19%] [G loss: 0.886816]\n",
      "epoch:11 step:10396 [D loss: 0.601141, acc.: 76.56%] [G loss: 0.809821]\n",
      "epoch:11 step:10397 [D loss: 0.652132, acc.: 67.97%] [G loss: 0.920835]\n",
      "epoch:11 step:10398 [D loss: 0.646426, acc.: 62.50%] [G loss: 0.891423]\n",
      "epoch:11 step:10399 [D loss: 0.631980, acc.: 64.84%] [G loss: 0.715808]\n",
      "epoch:11 step:10400 [D loss: 0.627053, acc.: 60.16%] [G loss: 0.765133]\n",
      "##############\n",
      "[4.08625482 2.39674669 6.98485778 5.67572959 4.59600508 5.80660747\n",
      " 5.42131099 5.82636326 5.57692159 4.97444997]\n",
      "##########\n",
      "epoch:11 step:10401 [D loss: 0.675791, acc.: 58.59%] [G loss: 0.889007]\n",
      "epoch:11 step:10402 [D loss: 0.638255, acc.: 66.41%] [G loss: 0.664110]\n",
      "epoch:11 step:10403 [D loss: 0.708426, acc.: 54.69%] [G loss: 0.795713]\n",
      "epoch:11 step:10404 [D loss: 0.641073, acc.: 61.72%] [G loss: 0.868764]\n",
      "epoch:11 step:10405 [D loss: 0.666608, acc.: 63.28%] [G loss: 0.849077]\n",
      "epoch:11 step:10406 [D loss: 0.697477, acc.: 54.69%] [G loss: 0.885001]\n",
      "epoch:11 step:10407 [D loss: 0.669441, acc.: 58.59%] [G loss: 0.820600]\n",
      "epoch:11 step:10408 [D loss: 0.705148, acc.: 53.12%] [G loss: 0.831452]\n",
      "epoch:11 step:10409 [D loss: 0.688940, acc.: 54.69%] [G loss: 0.859371]\n",
      "epoch:11 step:10410 [D loss: 0.666443, acc.: 60.94%] [G loss: 0.858365]\n",
      "epoch:11 step:10411 [D loss: 0.676937, acc.: 59.38%] [G loss: 0.844182]\n",
      "epoch:11 step:10412 [D loss: 0.560175, acc.: 71.88%] [G loss: 0.963562]\n",
      "epoch:11 step:10413 [D loss: 0.615975, acc.: 68.75%] [G loss: 0.868615]\n",
      "epoch:11 step:10414 [D loss: 0.586152, acc.: 67.19%] [G loss: 0.978021]\n",
      "epoch:11 step:10415 [D loss: 0.633638, acc.: 65.62%] [G loss: 0.879030]\n",
      "epoch:11 step:10416 [D loss: 0.619599, acc.: 69.53%] [G loss: 0.891694]\n",
      "epoch:11 step:10417 [D loss: 0.670968, acc.: 59.38%] [G loss: 0.918948]\n",
      "epoch:11 step:10418 [D loss: 0.737541, acc.: 47.66%] [G loss: 0.873006]\n",
      "epoch:11 step:10419 [D loss: 0.635536, acc.: 63.28%] [G loss: 0.858700]\n",
      "epoch:11 step:10420 [D loss: 0.804188, acc.: 49.22%] [G loss: 0.981585]\n",
      "epoch:11 step:10421 [D loss: 0.677803, acc.: 58.59%] [G loss: 0.864670]\n",
      "epoch:11 step:10422 [D loss: 0.681961, acc.: 58.59%] [G loss: 0.933232]\n",
      "epoch:11 step:10423 [D loss: 0.677088, acc.: 59.38%] [G loss: 0.871398]\n",
      "epoch:11 step:10424 [D loss: 0.646540, acc.: 65.62%] [G loss: 0.923055]\n",
      "epoch:11 step:10425 [D loss: 0.575290, acc.: 72.66%] [G loss: 1.019432]\n",
      "epoch:11 step:10426 [D loss: 0.521997, acc.: 72.66%] [G loss: 0.957363]\n",
      "epoch:11 step:10427 [D loss: 0.747625, acc.: 49.22%] [G loss: 0.906658]\n",
      "epoch:11 step:10428 [D loss: 0.767531, acc.: 43.75%] [G loss: 0.897426]\n",
      "epoch:11 step:10429 [D loss: 0.691668, acc.: 57.03%] [G loss: 0.823014]\n",
      "epoch:11 step:10430 [D loss: 0.734930, acc.: 48.44%] [G loss: 0.849452]\n",
      "epoch:11 step:10431 [D loss: 0.602146, acc.: 65.62%] [G loss: 0.874319]\n",
      "epoch:11 step:10432 [D loss: 0.629851, acc.: 65.62%] [G loss: 0.874085]\n",
      "epoch:11 step:10433 [D loss: 0.571732, acc.: 75.00%] [G loss: 0.976277]\n",
      "epoch:11 step:10434 [D loss: 0.638334, acc.: 63.28%] [G loss: 1.028198]\n",
      "epoch:11 step:10435 [D loss: 0.693337, acc.: 52.34%] [G loss: 0.949507]\n",
      "epoch:11 step:10436 [D loss: 0.670875, acc.: 54.69%] [G loss: 0.919286]\n",
      "epoch:11 step:10437 [D loss: 0.594400, acc.: 67.19%] [G loss: 0.865502]\n",
      "epoch:11 step:10438 [D loss: 0.679618, acc.: 54.69%] [G loss: 0.880390]\n",
      "epoch:11 step:10439 [D loss: 0.654313, acc.: 62.50%] [G loss: 0.853078]\n",
      "epoch:11 step:10440 [D loss: 0.576050, acc.: 72.66%] [G loss: 0.839557]\n",
      "epoch:11 step:10441 [D loss: 0.513677, acc.: 77.34%] [G loss: 0.827369]\n",
      "epoch:11 step:10442 [D loss: 0.612052, acc.: 68.75%] [G loss: 0.883978]\n",
      "epoch:11 step:10443 [D loss: 0.636891, acc.: 67.19%] [G loss: 0.939210]\n",
      "epoch:11 step:10444 [D loss: 0.732221, acc.: 53.91%] [G loss: 0.935326]\n",
      "epoch:11 step:10445 [D loss: 0.728962, acc.: 48.44%] [G loss: 0.836361]\n",
      "epoch:11 step:10446 [D loss: 0.666941, acc.: 58.59%] [G loss: 0.881393]\n",
      "epoch:11 step:10447 [D loss: 0.550131, acc.: 75.78%] [G loss: 0.830460]\n",
      "epoch:11 step:10448 [D loss: 0.609791, acc.: 67.97%] [G loss: 0.863759]\n",
      "epoch:11 step:10449 [D loss: 0.646144, acc.: 63.28%] [G loss: 0.907558]\n",
      "epoch:11 step:10450 [D loss: 0.717334, acc.: 56.25%] [G loss: 0.803182]\n",
      "epoch:11 step:10451 [D loss: 0.595483, acc.: 70.31%] [G loss: 0.951536]\n",
      "epoch:11 step:10452 [D loss: 0.514694, acc.: 82.03%] [G loss: 0.971052]\n",
      "epoch:11 step:10453 [D loss: 0.615558, acc.: 67.19%] [G loss: 0.799591]\n",
      "epoch:11 step:10454 [D loss: 0.634487, acc.: 63.28%] [G loss: 0.910233]\n",
      "epoch:11 step:10455 [D loss: 0.756473, acc.: 46.09%] [G loss: 0.875028]\n",
      "epoch:11 step:10456 [D loss: 0.434608, acc.: 73.44%] [G loss: 1.019934]\n",
      "epoch:11 step:10457 [D loss: 0.269173, acc.: 96.09%] [G loss: 1.020962]\n",
      "epoch:11 step:10458 [D loss: 0.485875, acc.: 82.03%] [G loss: 0.967338]\n",
      "epoch:11 step:10459 [D loss: 0.575517, acc.: 67.19%] [G loss: 1.001822]\n",
      "epoch:11 step:10460 [D loss: 0.758693, acc.: 48.44%] [G loss: 0.923014]\n",
      "epoch:11 step:10461 [D loss: 0.793619, acc.: 35.94%] [G loss: 0.865047]\n",
      "epoch:11 step:10462 [D loss: 0.692725, acc.: 52.34%] [G loss: 0.792490]\n",
      "epoch:11 step:10463 [D loss: 0.724073, acc.: 51.56%] [G loss: 0.818913]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:11 step:10464 [D loss: 0.703678, acc.: 57.81%] [G loss: 0.880664]\n",
      "epoch:11 step:10465 [D loss: 0.682647, acc.: 51.56%] [G loss: 0.895685]\n",
      "epoch:11 step:10466 [D loss: 0.878405, acc.: 30.47%] [G loss: 1.118885]\n",
      "epoch:11 step:10467 [D loss: 0.686282, acc.: 61.72%] [G loss: 0.995282]\n",
      "epoch:11 step:10468 [D loss: 0.648096, acc.: 59.38%] [G loss: 0.965263]\n",
      "epoch:11 step:10469 [D loss: 0.580091, acc.: 71.88%] [G loss: 0.977150]\n",
      "epoch:11 step:10470 [D loss: 0.690903, acc.: 60.16%] [G loss: 0.759668]\n",
      "epoch:11 step:10471 [D loss: 0.644111, acc.: 59.38%] [G loss: 0.951345]\n",
      "epoch:11 step:10472 [D loss: 0.765481, acc.: 47.66%] [G loss: 0.835096]\n",
      "epoch:11 step:10473 [D loss: 0.768429, acc.: 51.56%] [G loss: 0.896015]\n",
      "epoch:11 step:10474 [D loss: 0.835546, acc.: 44.53%] [G loss: 0.924925]\n",
      "epoch:11 step:10475 [D loss: 0.707910, acc.: 53.91%] [G loss: 1.064899]\n",
      "epoch:11 step:10476 [D loss: 0.691504, acc.: 55.47%] [G loss: 1.263085]\n",
      "epoch:11 step:10477 [D loss: 0.647246, acc.: 63.28%] [G loss: 1.450960]\n",
      "epoch:11 step:10478 [D loss: 0.537466, acc.: 70.31%] [G loss: 1.280473]\n",
      "epoch:11 step:10479 [D loss: 0.590516, acc.: 67.19%] [G loss: 1.156300]\n",
      "epoch:11 step:10480 [D loss: 0.535867, acc.: 77.34%] [G loss: 1.614409]\n",
      "epoch:11 step:10481 [D loss: 0.716953, acc.: 53.12%] [G loss: 0.928358]\n",
      "epoch:11 step:10482 [D loss: 0.796523, acc.: 44.53%] [G loss: 0.940536]\n",
      "epoch:11 step:10483 [D loss: 0.559397, acc.: 71.88%] [G loss: 0.892511]\n",
      "epoch:11 step:10484 [D loss: 0.621661, acc.: 59.38%] [G loss: 0.929536]\n",
      "epoch:11 step:10485 [D loss: 0.723312, acc.: 51.56%] [G loss: 0.682009]\n",
      "epoch:11 step:10486 [D loss: 0.752851, acc.: 44.53%] [G loss: 0.779882]\n",
      "epoch:11 step:10487 [D loss: 0.727939, acc.: 53.91%] [G loss: 0.820434]\n",
      "epoch:11 step:10488 [D loss: 0.600734, acc.: 65.62%] [G loss: 0.807516]\n",
      "epoch:11 step:10489 [D loss: 0.710525, acc.: 48.44%] [G loss: 0.801832]\n",
      "epoch:11 step:10490 [D loss: 0.679573, acc.: 56.25%] [G loss: 0.804484]\n",
      "epoch:11 step:10491 [D loss: 0.674049, acc.: 63.28%] [G loss: 0.839550]\n",
      "epoch:11 step:10492 [D loss: 0.715928, acc.: 46.88%] [G loss: 0.757737]\n",
      "epoch:11 step:10493 [D loss: 0.760741, acc.: 37.50%] [G loss: 0.686387]\n",
      "epoch:11 step:10494 [D loss: 0.598007, acc.: 71.09%] [G loss: 0.730131]\n",
      "epoch:11 step:10495 [D loss: 0.657311, acc.: 60.94%] [G loss: 0.856745]\n",
      "epoch:11 step:10496 [D loss: 0.617995, acc.: 72.66%] [G loss: 0.773455]\n",
      "epoch:11 step:10497 [D loss: 0.691079, acc.: 53.91%] [G loss: 0.773164]\n",
      "epoch:11 step:10498 [D loss: 0.660373, acc.: 57.81%] [G loss: 0.915803]\n",
      "epoch:11 step:10499 [D loss: 0.577201, acc.: 71.88%] [G loss: 0.935599]\n",
      "epoch:11 step:10500 [D loss: 0.673767, acc.: 59.38%] [G loss: 0.884920]\n",
      "epoch:11 step:10501 [D loss: 0.656837, acc.: 64.84%] [G loss: 0.990663]\n",
      "epoch:11 step:10502 [D loss: 0.630862, acc.: 57.81%] [G loss: 0.898121]\n",
      "epoch:11 step:10503 [D loss: 0.637033, acc.: 63.28%] [G loss: 0.809165]\n",
      "epoch:11 step:10504 [D loss: 0.654349, acc.: 59.38%] [G loss: 0.970649]\n",
      "epoch:11 step:10505 [D loss: 0.669606, acc.: 59.38%] [G loss: 0.755268]\n",
      "epoch:11 step:10506 [D loss: 0.694425, acc.: 53.91%] [G loss: 0.926734]\n",
      "epoch:11 step:10507 [D loss: 0.746565, acc.: 54.69%] [G loss: 0.949096]\n",
      "epoch:11 step:10508 [D loss: 0.778540, acc.: 47.66%] [G loss: 0.904828]\n",
      "epoch:11 step:10509 [D loss: 0.689415, acc.: 57.81%] [G loss: 0.948581]\n",
      "epoch:11 step:10510 [D loss: 0.680011, acc.: 62.50%] [G loss: 0.868540]\n",
      "epoch:11 step:10511 [D loss: 0.632709, acc.: 63.28%] [G loss: 0.792651]\n",
      "epoch:11 step:10512 [D loss: 0.712391, acc.: 52.34%] [G loss: 0.772030]\n",
      "epoch:11 step:10513 [D loss: 0.722365, acc.: 55.47%] [G loss: 0.842078]\n",
      "epoch:11 step:10514 [D loss: 0.666440, acc.: 60.16%] [G loss: 0.794609]\n",
      "epoch:11 step:10515 [D loss: 0.655772, acc.: 61.72%] [G loss: 0.797306]\n",
      "epoch:11 step:10516 [D loss: 0.666637, acc.: 58.59%] [G loss: 0.786421]\n",
      "epoch:11 step:10517 [D loss: 0.689948, acc.: 53.91%] [G loss: 0.830263]\n",
      "epoch:11 step:10518 [D loss: 0.726551, acc.: 43.75%] [G loss: 0.823914]\n",
      "epoch:11 step:10519 [D loss: 0.700785, acc.: 56.25%] [G loss: 0.884850]\n",
      "epoch:11 step:10520 [D loss: 0.735654, acc.: 53.12%] [G loss: 0.876681]\n",
      "epoch:11 step:10521 [D loss: 0.695501, acc.: 52.34%] [G loss: 0.807260]\n",
      "epoch:11 step:10522 [D loss: 0.684822, acc.: 57.81%] [G loss: 0.714347]\n",
      "epoch:11 step:10523 [D loss: 0.709484, acc.: 52.34%] [G loss: 0.775018]\n",
      "epoch:11 step:10524 [D loss: 0.711079, acc.: 52.34%] [G loss: 0.855623]\n",
      "epoch:11 step:10525 [D loss: 0.690337, acc.: 50.78%] [G loss: 0.804776]\n",
      "epoch:11 step:10526 [D loss: 0.653092, acc.: 59.38%] [G loss: 0.753036]\n",
      "epoch:11 step:10527 [D loss: 0.498497, acc.: 73.44%] [G loss: 0.831317]\n",
      "epoch:11 step:10528 [D loss: 0.464080, acc.: 75.78%] [G loss: 0.879290]\n",
      "epoch:11 step:10529 [D loss: 0.686142, acc.: 54.69%] [G loss: 0.854853]\n",
      "epoch:11 step:10530 [D loss: 0.612597, acc.: 71.88%] [G loss: 0.881588]\n",
      "epoch:11 step:10531 [D loss: 0.736323, acc.: 42.19%] [G loss: 0.844466]\n",
      "epoch:11 step:10532 [D loss: 0.684681, acc.: 55.47%] [G loss: 0.870475]\n",
      "epoch:11 step:10533 [D loss: 0.618882, acc.: 71.09%] [G loss: 0.868036]\n",
      "epoch:11 step:10534 [D loss: 0.638813, acc.: 63.28%] [G loss: 0.720838]\n",
      "epoch:11 step:10535 [D loss: 0.725007, acc.: 51.56%] [G loss: 0.777103]\n",
      "epoch:11 step:10536 [D loss: 0.631988, acc.: 64.06%] [G loss: 0.817343]\n",
      "epoch:11 step:10537 [D loss: 0.420269, acc.: 74.22%] [G loss: 0.885266]\n",
      "epoch:11 step:10538 [D loss: 0.578198, acc.: 71.09%] [G loss: 0.855433]\n",
      "epoch:11 step:10539 [D loss: 0.301129, acc.: 94.53%] [G loss: 0.971732]\n",
      "epoch:11 step:10540 [D loss: 0.648733, acc.: 65.62%] [G loss: 0.955429]\n",
      "epoch:11 step:10541 [D loss: 0.505474, acc.: 80.47%] [G loss: 1.019827]\n",
      "epoch:11 step:10542 [D loss: 0.652053, acc.: 65.62%] [G loss: 0.991568]\n",
      "epoch:11 step:10543 [D loss: 0.688014, acc.: 57.81%] [G loss: 0.934095]\n",
      "epoch:11 step:10544 [D loss: 0.467815, acc.: 86.72%] [G loss: 0.901852]\n",
      "epoch:11 step:10545 [D loss: 0.694371, acc.: 55.47%] [G loss: 0.953836]\n",
      "epoch:11 step:10546 [D loss: 0.708971, acc.: 55.47%] [G loss: 0.768961]\n",
      "epoch:11 step:10547 [D loss: 0.709227, acc.: 53.91%] [G loss: 0.864669]\n",
      "epoch:11 step:10548 [D loss: 0.838223, acc.: 28.12%] [G loss: 0.897344]\n",
      "epoch:11 step:10549 [D loss: 0.725716, acc.: 48.44%] [G loss: 0.887452]\n",
      "epoch:11 step:10550 [D loss: 0.630793, acc.: 63.28%] [G loss: 0.966034]\n",
      "epoch:11 step:10551 [D loss: 0.747571, acc.: 46.88%] [G loss: 0.899987]\n",
      "epoch:11 step:10552 [D loss: 0.795578, acc.: 38.28%] [G loss: 0.859073]\n",
      "epoch:11 step:10553 [D loss: 0.734463, acc.: 46.09%] [G loss: 0.927473]\n",
      "epoch:11 step:10554 [D loss: 0.924438, acc.: 33.59%] [G loss: 0.894536]\n",
      "epoch:11 step:10555 [D loss: 0.651909, acc.: 57.81%] [G loss: 0.878432]\n",
      "epoch:11 step:10556 [D loss: 0.728826, acc.: 47.66%] [G loss: 0.945708]\n",
      "epoch:11 step:10557 [D loss: 0.701697, acc.: 53.91%] [G loss: 0.875641]\n",
      "epoch:11 step:10558 [D loss: 0.695617, acc.: 50.00%] [G loss: 0.778263]\n",
      "epoch:11 step:10559 [D loss: 0.683934, acc.: 58.59%] [G loss: 0.922767]\n",
      "epoch:11 step:10560 [D loss: 0.668743, acc.: 58.59%] [G loss: 0.878196]\n",
      "epoch:11 step:10561 [D loss: 0.676711, acc.: 53.91%] [G loss: 0.971137]\n",
      "epoch:11 step:10562 [D loss: 0.674978, acc.: 50.78%] [G loss: 0.873573]\n",
      "epoch:11 step:10563 [D loss: 0.553407, acc.: 75.00%] [G loss: 0.905814]\n",
      "epoch:11 step:10564 [D loss: 0.668113, acc.: 55.47%] [G loss: 0.926585]\n",
      "epoch:11 step:10565 [D loss: 0.695015, acc.: 62.50%] [G loss: 0.854510]\n",
      "epoch:11 step:10566 [D loss: 0.473140, acc.: 75.78%] [G loss: 0.872656]\n",
      "epoch:11 step:10567 [D loss: 0.546990, acc.: 71.88%] [G loss: 0.783085]\n",
      "epoch:11 step:10568 [D loss: 0.595236, acc.: 73.44%] [G loss: 0.920043]\n",
      "epoch:11 step:10569 [D loss: 0.614014, acc.: 71.88%] [G loss: 0.799418]\n",
      "epoch:11 step:10570 [D loss: 0.759241, acc.: 48.44%] [G loss: 0.920275]\n",
      "epoch:11 step:10571 [D loss: 0.640121, acc.: 64.06%] [G loss: 0.858385]\n",
      "epoch:11 step:10572 [D loss: 0.716886, acc.: 53.91%] [G loss: 0.812702]\n",
      "epoch:11 step:10573 [D loss: 0.687590, acc.: 54.69%] [G loss: 0.957964]\n",
      "epoch:11 step:10574 [D loss: 0.709147, acc.: 50.78%] [G loss: 0.880137]\n",
      "epoch:11 step:10575 [D loss: 0.644278, acc.: 60.16%] [G loss: 0.938948]\n",
      "epoch:11 step:10576 [D loss: 0.623638, acc.: 62.50%] [G loss: 1.043160]\n",
      "epoch:11 step:10577 [D loss: 0.704110, acc.: 50.00%] [G loss: 0.842385]\n",
      "epoch:11 step:10578 [D loss: 0.623961, acc.: 62.50%] [G loss: 1.018462]\n",
      "epoch:11 step:10579 [D loss: 0.650509, acc.: 60.94%] [G loss: 0.973884]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:11 step:10580 [D loss: 0.615451, acc.: 66.41%] [G loss: 1.047343]\n",
      "epoch:11 step:10581 [D loss: 0.592433, acc.: 73.44%] [G loss: 0.918262]\n",
      "epoch:11 step:10582 [D loss: 0.649574, acc.: 65.62%] [G loss: 0.876671]\n",
      "epoch:11 step:10583 [D loss: 0.614066, acc.: 67.97%] [G loss: 0.931935]\n",
      "epoch:11 step:10584 [D loss: 0.697998, acc.: 55.47%] [G loss: 0.861027]\n",
      "epoch:11 step:10585 [D loss: 0.772160, acc.: 48.44%] [G loss: 0.932396]\n",
      "epoch:11 step:10586 [D loss: 0.466045, acc.: 78.91%] [G loss: 0.842581]\n",
      "epoch:11 step:10587 [D loss: 0.704459, acc.: 54.69%] [G loss: 0.949249]\n",
      "epoch:11 step:10588 [D loss: 0.664334, acc.: 57.03%] [G loss: 0.861319]\n",
      "epoch:11 step:10589 [D loss: 0.652448, acc.: 53.91%] [G loss: 0.877152]\n",
      "epoch:11 step:10590 [D loss: 0.652384, acc.: 61.72%] [G loss: 0.793624]\n",
      "epoch:11 step:10591 [D loss: 0.678426, acc.: 56.25%] [G loss: 0.827782]\n",
      "epoch:11 step:10592 [D loss: 0.679735, acc.: 64.84%] [G loss: 0.839129]\n",
      "epoch:11 step:10593 [D loss: 0.691757, acc.: 57.81%] [G loss: 0.859331]\n",
      "epoch:11 step:10594 [D loss: 0.686969, acc.: 54.69%] [G loss: 0.822677]\n",
      "epoch:11 step:10595 [D loss: 0.659032, acc.: 53.91%] [G loss: 0.799082]\n",
      "epoch:11 step:10596 [D loss: 0.588323, acc.: 67.97%] [G loss: 0.915548]\n",
      "epoch:11 step:10597 [D loss: 0.514009, acc.: 70.31%] [G loss: 0.860591]\n",
      "epoch:11 step:10598 [D loss: 0.669628, acc.: 60.16%] [G loss: 0.769511]\n",
      "epoch:11 step:10599 [D loss: 0.551669, acc.: 75.00%] [G loss: 0.956189]\n",
      "epoch:11 step:10600 [D loss: 0.477992, acc.: 72.66%] [G loss: 0.886230]\n",
      "##############\n",
      "[4.05734081 2.11447195 6.71526011 5.51706391 4.227515   5.83798823\n",
      " 5.39089792 5.5614323  5.8870929  4.74882021]\n",
      "##########\n",
      "epoch:11 step:10601 [D loss: 0.577971, acc.: 77.34%] [G loss: 0.752033]\n",
      "epoch:11 step:10602 [D loss: 1.173249, acc.: 17.19%] [G loss: 0.915160]\n",
      "epoch:11 step:10603 [D loss: 0.731798, acc.: 50.78%] [G loss: 0.869047]\n",
      "epoch:11 step:10604 [D loss: 0.758891, acc.: 42.97%] [G loss: 0.874271]\n",
      "epoch:11 step:10605 [D loss: 0.682579, acc.: 57.03%] [G loss: 0.903634]\n",
      "epoch:11 step:10606 [D loss: 0.696746, acc.: 50.00%] [G loss: 0.859939]\n",
      "epoch:11 step:10607 [D loss: 0.668911, acc.: 60.94%] [G loss: 0.469175]\n",
      "epoch:11 step:10608 [D loss: 0.724140, acc.: 51.56%] [G loss: 0.846742]\n",
      "epoch:11 step:10609 [D loss: 0.699753, acc.: 51.56%] [G loss: 0.853113]\n",
      "epoch:11 step:10610 [D loss: 0.692958, acc.: 54.69%] [G loss: 0.841326]\n",
      "epoch:11 step:10611 [D loss: 0.688056, acc.: 53.12%] [G loss: 0.819269]\n",
      "epoch:11 step:10612 [D loss: 0.691700, acc.: 53.91%] [G loss: 0.851237]\n",
      "epoch:11 step:10613 [D loss: 0.690545, acc.: 50.78%] [G loss: 0.878363]\n",
      "epoch:11 step:10614 [D loss: 0.651017, acc.: 65.62%] [G loss: 0.814942]\n",
      "epoch:11 step:10615 [D loss: 0.664101, acc.: 60.94%] [G loss: 0.819845]\n",
      "epoch:11 step:10616 [D loss: 0.439020, acc.: 82.03%] [G loss: 0.838342]\n",
      "epoch:11 step:10617 [D loss: 0.727387, acc.: 50.00%] [G loss: 0.846473]\n",
      "epoch:11 step:10618 [D loss: 0.617314, acc.: 68.75%] [G loss: 0.806643]\n",
      "epoch:11 step:10619 [D loss: 0.400180, acc.: 83.59%] [G loss: 0.858882]\n",
      "epoch:11 step:10620 [D loss: 0.391857, acc.: 83.59%] [G loss: 0.905843]\n",
      "epoch:11 step:10621 [D loss: 0.350791, acc.: 83.59%] [G loss: 1.018770]\n",
      "epoch:11 step:10622 [D loss: 0.469558, acc.: 84.38%] [G loss: 0.939908]\n",
      "epoch:11 step:10623 [D loss: 0.728170, acc.: 50.00%] [G loss: 0.945927]\n",
      "epoch:11 step:10624 [D loss: 0.756916, acc.: 42.19%] [G loss: 0.926859]\n",
      "epoch:11 step:10625 [D loss: 0.686912, acc.: 55.47%] [G loss: 0.848692]\n",
      "epoch:11 step:10626 [D loss: 0.678196, acc.: 58.59%] [G loss: 0.930202]\n",
      "epoch:11 step:10627 [D loss: 0.686061, acc.: 57.03%] [G loss: 0.905168]\n",
      "epoch:11 step:10628 [D loss: 0.703496, acc.: 55.47%] [G loss: 0.977485]\n",
      "epoch:11 step:10629 [D loss: 0.641272, acc.: 62.50%] [G loss: 0.969788]\n",
      "epoch:11 step:10630 [D loss: 0.761210, acc.: 47.66%] [G loss: 0.911968]\n",
      "epoch:11 step:10631 [D loss: 0.693467, acc.: 57.81%] [G loss: 0.935755]\n",
      "epoch:11 step:10632 [D loss: 0.673486, acc.: 59.38%] [G loss: 0.913276]\n",
      "epoch:11 step:10633 [D loss: 0.626353, acc.: 61.72%] [G loss: 0.865791]\n",
      "epoch:11 step:10634 [D loss: 0.537769, acc.: 79.69%] [G loss: 0.792467]\n",
      "epoch:11 step:10635 [D loss: 0.553529, acc.: 75.78%] [G loss: 0.905628]\n",
      "epoch:11 step:10636 [D loss: 0.695266, acc.: 55.47%] [G loss: 0.872652]\n",
      "epoch:11 step:10637 [D loss: 0.739850, acc.: 48.44%] [G loss: 0.827433]\n",
      "epoch:11 step:10638 [D loss: 0.668710, acc.: 53.91%] [G loss: 0.916286]\n",
      "epoch:11 step:10639 [D loss: 0.726649, acc.: 49.22%] [G loss: 0.712008]\n",
      "epoch:11 step:10640 [D loss: 0.657649, acc.: 57.03%] [G loss: 0.832284]\n",
      "epoch:11 step:10641 [D loss: 0.408289, acc.: 83.59%] [G loss: 0.889703]\n",
      "epoch:11 step:10642 [D loss: 0.607882, acc.: 67.19%] [G loss: 0.853366]\n",
      "epoch:11 step:10643 [D loss: 0.582950, acc.: 73.44%] [G loss: 0.564591]\n",
      "epoch:11 step:10644 [D loss: 0.669020, acc.: 57.81%] [G loss: 0.247559]\n",
      "epoch:11 step:10645 [D loss: 0.632949, acc.: 67.19%] [G loss: 0.844736]\n",
      "epoch:11 step:10646 [D loss: 0.702894, acc.: 53.91%] [G loss: 0.645022]\n",
      "epoch:11 step:10647 [D loss: 0.679737, acc.: 56.25%] [G loss: 0.830259]\n",
      "epoch:11 step:10648 [D loss: 1.207036, acc.: 25.78%] [G loss: 0.941825]\n",
      "epoch:11 step:10649 [D loss: 0.669236, acc.: 60.94%] [G loss: 0.975678]\n",
      "epoch:11 step:10650 [D loss: 0.674291, acc.: 63.28%] [G loss: 0.879520]\n",
      "epoch:11 step:10651 [D loss: 0.631511, acc.: 63.28%] [G loss: 0.923517]\n",
      "epoch:11 step:10652 [D loss: 0.688907, acc.: 59.38%] [G loss: 0.783262]\n",
      "epoch:11 step:10653 [D loss: 0.688675, acc.: 51.56%] [G loss: 0.836867]\n",
      "epoch:11 step:10654 [D loss: 0.794346, acc.: 52.34%] [G loss: 0.667480]\n",
      "epoch:11 step:10655 [D loss: 0.833661, acc.: 36.72%] [G loss: 1.080147]\n",
      "epoch:11 step:10656 [D loss: 0.734479, acc.: 46.88%] [G loss: 1.175313]\n",
      "epoch:11 step:10657 [D loss: 0.836308, acc.: 47.66%] [G loss: 0.957502]\n",
      "epoch:11 step:10658 [D loss: 0.567542, acc.: 73.44%] [G loss: 1.169340]\n",
      "epoch:11 step:10659 [D loss: 0.554001, acc.: 81.25%] [G loss: 1.287764]\n",
      "epoch:11 step:10660 [D loss: 0.527044, acc.: 81.25%] [G loss: 1.125757]\n",
      "epoch:11 step:10661 [D loss: 0.527585, acc.: 85.94%] [G loss: 0.993226]\n",
      "epoch:11 step:10662 [D loss: 0.596871, acc.: 64.84%] [G loss: 0.905303]\n",
      "epoch:11 step:10663 [D loss: 0.609659, acc.: 67.19%] [G loss: 0.956303]\n",
      "epoch:11 step:10664 [D loss: 0.654574, acc.: 67.97%] [G loss: 0.887642]\n",
      "epoch:11 step:10665 [D loss: 0.547653, acc.: 75.78%] [G loss: 1.009143]\n",
      "epoch:11 step:10666 [D loss: 0.722965, acc.: 58.59%] [G loss: 0.939100]\n",
      "epoch:11 step:10667 [D loss: 0.608995, acc.: 72.66%] [G loss: 0.924821]\n",
      "epoch:11 step:10668 [D loss: 0.639777, acc.: 68.75%] [G loss: 0.823149]\n",
      "epoch:11 step:10669 [D loss: 0.826302, acc.: 39.06%] [G loss: 0.889754]\n",
      "epoch:11 step:10670 [D loss: 0.684327, acc.: 59.38%] [G loss: 0.740513]\n",
      "epoch:11 step:10671 [D loss: 0.652124, acc.: 56.25%] [G loss: 0.808199]\n",
      "epoch:11 step:10672 [D loss: 0.777858, acc.: 40.62%] [G loss: 0.783230]\n",
      "epoch:11 step:10673 [D loss: 0.821896, acc.: 39.84%] [G loss: 0.796700]\n",
      "epoch:11 step:10674 [D loss: 0.746166, acc.: 56.25%] [G loss: 0.867946]\n",
      "epoch:11 step:10675 [D loss: 0.696672, acc.: 53.91%] [G loss: 0.709340]\n",
      "epoch:11 step:10676 [D loss: 0.667079, acc.: 60.94%] [G loss: 0.883684]\n",
      "epoch:11 step:10677 [D loss: 0.600962, acc.: 68.75%] [G loss: 0.916706]\n",
      "epoch:11 step:10678 [D loss: 0.609047, acc.: 68.75%] [G loss: 0.937996]\n",
      "epoch:11 step:10679 [D loss: 0.675663, acc.: 62.50%] [G loss: 0.911488]\n",
      "epoch:11 step:10680 [D loss: 0.703268, acc.: 53.12%] [G loss: 0.874839]\n",
      "epoch:11 step:10681 [D loss: 0.640082, acc.: 67.97%] [G loss: 0.902241]\n",
      "epoch:11 step:10682 [D loss: 0.702048, acc.: 53.91%] [G loss: 0.754214]\n",
      "epoch:11 step:10683 [D loss: 0.690451, acc.: 60.94%] [G loss: 0.861313]\n",
      "epoch:11 step:10684 [D loss: 0.763064, acc.: 47.66%] [G loss: 0.867053]\n",
      "epoch:11 step:10685 [D loss: 0.679835, acc.: 62.50%] [G loss: 0.791654]\n",
      "epoch:11 step:10686 [D loss: 0.669791, acc.: 55.47%] [G loss: 0.891192]\n",
      "epoch:11 step:10687 [D loss: 0.700043, acc.: 53.12%] [G loss: 0.821636]\n",
      "epoch:11 step:10688 [D loss: 0.649250, acc.: 61.72%] [G loss: 0.812890]\n",
      "epoch:11 step:10689 [D loss: 0.707163, acc.: 47.66%] [G loss: 0.771402]\n",
      "epoch:11 step:10690 [D loss: 0.683271, acc.: 54.69%] [G loss: 0.869836]\n",
      "epoch:11 step:10691 [D loss: 0.655215, acc.: 59.38%] [G loss: 0.893373]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:11 step:10692 [D loss: 0.688600, acc.: 63.28%] [G loss: 0.886542]\n",
      "epoch:11 step:10693 [D loss: 0.704949, acc.: 54.69%] [G loss: 0.796953]\n",
      "epoch:11 step:10694 [D loss: 0.674651, acc.: 60.16%] [G loss: 0.874528]\n",
      "epoch:11 step:10695 [D loss: 0.668711, acc.: 60.16%] [G loss: 0.825465]\n",
      "epoch:11 step:10696 [D loss: 0.686435, acc.: 58.59%] [G loss: 0.850255]\n",
      "epoch:11 step:10697 [D loss: 0.705411, acc.: 49.22%] [G loss: 0.760767]\n",
      "epoch:11 step:10698 [D loss: 0.684093, acc.: 56.25%] [G loss: 0.828586]\n",
      "epoch:11 step:10699 [D loss: 0.658904, acc.: 59.38%] [G loss: 0.820354]\n",
      "epoch:11 step:10700 [D loss: 0.692442, acc.: 56.25%] [G loss: 0.838380]\n",
      "epoch:11 step:10701 [D loss: 0.655362, acc.: 63.28%] [G loss: 0.747091]\n",
      "epoch:11 step:10702 [D loss: 0.650840, acc.: 59.38%] [G loss: 0.741721]\n",
      "epoch:11 step:10703 [D loss: 0.563964, acc.: 75.00%] [G loss: 0.828378]\n",
      "epoch:11 step:10704 [D loss: 0.601381, acc.: 67.19%] [G loss: 0.758420]\n",
      "epoch:11 step:10705 [D loss: 0.608009, acc.: 67.97%] [G loss: 0.758189]\n",
      "epoch:11 step:10706 [D loss: 0.415254, acc.: 81.25%] [G loss: 0.938947]\n",
      "epoch:11 step:10707 [D loss: 0.753812, acc.: 43.75%] [G loss: 0.892511]\n",
      "epoch:11 step:10708 [D loss: 0.710069, acc.: 53.91%] [G loss: 0.963965]\n",
      "epoch:11 step:10709 [D loss: 0.580236, acc.: 70.31%] [G loss: 1.113233]\n",
      "epoch:11 step:10710 [D loss: 0.593773, acc.: 72.66%] [G loss: 0.908904]\n",
      "epoch:11 step:10711 [D loss: 0.555996, acc.: 75.78%] [G loss: 0.793962]\n",
      "epoch:11 step:10712 [D loss: 0.541835, acc.: 75.00%] [G loss: 0.868390]\n",
      "epoch:11 step:10713 [D loss: 0.653625, acc.: 58.59%] [G loss: 0.758334]\n",
      "epoch:11 step:10714 [D loss: 0.431279, acc.: 75.78%] [G loss: 0.773368]\n",
      "epoch:11 step:10715 [D loss: 0.713198, acc.: 59.38%] [G loss: 1.203863]\n",
      "epoch:11 step:10716 [D loss: 0.631653, acc.: 62.50%] [G loss: 0.521619]\n",
      "epoch:11 step:10717 [D loss: 0.692881, acc.: 57.03%] [G loss: 1.111543]\n",
      "epoch:11 step:10718 [D loss: 0.952859, acc.: 28.12%] [G loss: 0.961594]\n",
      "epoch:11 step:10719 [D loss: 0.751955, acc.: 46.09%] [G loss: 0.855949]\n",
      "epoch:11 step:10720 [D loss: 0.658104, acc.: 57.03%] [G loss: 0.873867]\n",
      "epoch:11 step:10721 [D loss: 0.647649, acc.: 61.72%] [G loss: 0.859792]\n",
      "epoch:11 step:10722 [D loss: 0.744868, acc.: 50.00%] [G loss: 0.797980]\n",
      "epoch:11 step:10723 [D loss: 0.615115, acc.: 60.94%] [G loss: 0.948837]\n",
      "epoch:11 step:10724 [D loss: 0.645553, acc.: 60.94%] [G loss: 0.917427]\n",
      "epoch:11 step:10725 [D loss: 0.661659, acc.: 60.16%] [G loss: 0.792857]\n",
      "epoch:11 step:10726 [D loss: 0.485164, acc.: 77.34%] [G loss: 0.856424]\n",
      "epoch:11 step:10727 [D loss: 0.674921, acc.: 53.12%] [G loss: 0.766606]\n",
      "epoch:11 step:10728 [D loss: 1.193010, acc.: 16.41%] [G loss: 0.443033]\n",
      "epoch:11 step:10729 [D loss: 0.725001, acc.: 53.12%] [G loss: 0.896126]\n",
      "epoch:11 step:10730 [D loss: 0.678381, acc.: 57.03%] [G loss: 0.968364]\n",
      "epoch:11 step:10731 [D loss: 0.617174, acc.: 69.53%] [G loss: 0.909869]\n",
      "epoch:11 step:10732 [D loss: 0.594824, acc.: 71.88%] [G loss: 0.972321]\n",
      "epoch:11 step:10733 [D loss: 0.642437, acc.: 64.84%] [G loss: 0.792606]\n",
      "epoch:11 step:10734 [D loss: 0.506433, acc.: 71.88%] [G loss: 0.989017]\n",
      "epoch:11 step:10735 [D loss: 0.415010, acc.: 81.25%] [G loss: 0.964971]\n",
      "epoch:11 step:10736 [D loss: 0.550867, acc.: 82.03%] [G loss: 0.979317]\n",
      "epoch:11 step:10737 [D loss: 0.727601, acc.: 57.81%] [G loss: 1.106544]\n",
      "epoch:11 step:10738 [D loss: 0.663392, acc.: 57.81%] [G loss: 1.020484]\n",
      "epoch:11 step:10739 [D loss: 0.680987, acc.: 57.03%] [G loss: 1.123493]\n",
      "epoch:11 step:10740 [D loss: 0.658183, acc.: 58.59%] [G loss: 1.020596]\n",
      "epoch:11 step:10741 [D loss: 0.654899, acc.: 60.94%] [G loss: 1.059871]\n",
      "epoch:11 step:10742 [D loss: 0.659640, acc.: 59.38%] [G loss: 0.935505]\n",
      "epoch:11 step:10743 [D loss: 0.617095, acc.: 64.84%] [G loss: 0.967949]\n",
      "epoch:11 step:10744 [D loss: 0.737071, acc.: 49.22%] [G loss: 0.825138]\n",
      "epoch:11 step:10745 [D loss: 0.682702, acc.: 58.59%] [G loss: 0.909572]\n",
      "epoch:11 step:10746 [D loss: 0.662881, acc.: 62.50%] [G loss: 0.825289]\n",
      "epoch:11 step:10747 [D loss: 0.678051, acc.: 53.91%] [G loss: 0.558754]\n",
      "epoch:11 step:10748 [D loss: 0.863246, acc.: 38.28%] [G loss: 0.788275]\n",
      "epoch:11 step:10749 [D loss: 0.662158, acc.: 62.50%] [G loss: 0.957594]\n",
      "epoch:11 step:10750 [D loss: 0.584912, acc.: 75.00%] [G loss: 0.910254]\n",
      "epoch:11 step:10751 [D loss: 0.640694, acc.: 63.28%] [G loss: 1.001623]\n",
      "epoch:11 step:10752 [D loss: 0.666728, acc.: 56.25%] [G loss: 0.932910]\n",
      "epoch:11 step:10753 [D loss: 0.656154, acc.: 60.16%] [G loss: 0.958424]\n",
      "epoch:11 step:10754 [D loss: 0.787485, acc.: 40.62%] [G loss: 1.018387]\n",
      "epoch:11 step:10755 [D loss: 0.592674, acc.: 67.97%] [G loss: 1.021802]\n",
      "epoch:11 step:10756 [D loss: 0.534125, acc.: 70.31%] [G loss: 1.129115]\n",
      "epoch:11 step:10757 [D loss: 0.537537, acc.: 78.12%] [G loss: 1.004576]\n",
      "epoch:11 step:10758 [D loss: 0.449559, acc.: 85.16%] [G loss: 1.250814]\n",
      "epoch:11 step:10759 [D loss: 0.474317, acc.: 89.06%] [G loss: 1.441861]\n",
      "epoch:11 step:10760 [D loss: 0.484377, acc.: 83.59%] [G loss: 0.923402]\n",
      "epoch:11 step:10761 [D loss: 0.555642, acc.: 75.00%] [G loss: 0.958801]\n",
      "epoch:11 step:10762 [D loss: 0.404162, acc.: 92.97%] [G loss: 1.277898]\n",
      "epoch:11 step:10763 [D loss: 0.466047, acc.: 82.03%] [G loss: 1.410811]\n",
      "epoch:11 step:10764 [D loss: 0.585092, acc.: 65.62%] [G loss: 1.422899]\n",
      "epoch:11 step:10765 [D loss: 0.973201, acc.: 30.47%] [G loss: 0.997818]\n",
      "epoch:11 step:10766 [D loss: 0.752043, acc.: 50.78%] [G loss: 0.862486]\n",
      "epoch:11 step:10767 [D loss: 0.757265, acc.: 48.44%] [G loss: 1.050503]\n",
      "epoch:11 step:10768 [D loss: 0.887131, acc.: 34.38%] [G loss: 0.935285]\n",
      "epoch:11 step:10769 [D loss: 0.845398, acc.: 42.97%] [G loss: 0.888822]\n",
      "epoch:11 step:10770 [D loss: 0.690451, acc.: 52.34%] [G loss: 0.923559]\n",
      "epoch:11 step:10771 [D loss: 0.628258, acc.: 69.53%] [G loss: 1.038159]\n",
      "epoch:11 step:10772 [D loss: 0.740336, acc.: 49.22%] [G loss: 0.995803]\n",
      "epoch:11 step:10773 [D loss: 0.603422, acc.: 67.19%] [G loss: 0.871513]\n",
      "epoch:11 step:10774 [D loss: 0.682536, acc.: 52.34%] [G loss: 0.936318]\n",
      "epoch:11 step:10775 [D loss: 0.578272, acc.: 71.09%] [G loss: 1.048189]\n",
      "epoch:11 step:10776 [D loss: 0.593508, acc.: 73.44%] [G loss: 1.079205]\n",
      "epoch:11 step:10777 [D loss: 0.560237, acc.: 76.56%] [G loss: 1.070553]\n",
      "epoch:11 step:10778 [D loss: 0.699896, acc.: 59.38%] [G loss: 0.921056]\n",
      "epoch:11 step:10779 [D loss: 0.642870, acc.: 63.28%] [G loss: 0.903435]\n",
      "epoch:11 step:10780 [D loss: 0.687984, acc.: 61.72%] [G loss: 1.111065]\n",
      "epoch:11 step:10781 [D loss: 0.642856, acc.: 65.62%] [G loss: 1.222306]\n",
      "epoch:11 step:10782 [D loss: 0.515030, acc.: 78.91%] [G loss: 1.176831]\n",
      "epoch:11 step:10783 [D loss: 0.624555, acc.: 64.06%] [G loss: 1.027447]\n",
      "epoch:11 step:10784 [D loss: 0.705216, acc.: 53.12%] [G loss: 1.037694]\n",
      "epoch:11 step:10785 [D loss: 0.681441, acc.: 60.16%] [G loss: 1.028585]\n",
      "epoch:11 step:10786 [D loss: 0.744258, acc.: 52.34%] [G loss: 0.955514]\n",
      "epoch:11 step:10787 [D loss: 0.742045, acc.: 52.34%] [G loss: 0.937735]\n",
      "epoch:11 step:10788 [D loss: 0.717368, acc.: 48.44%] [G loss: 0.825958]\n",
      "epoch:11 step:10789 [D loss: 0.663790, acc.: 62.50%] [G loss: 0.916196]\n",
      "epoch:11 step:10790 [D loss: 0.609958, acc.: 70.31%] [G loss: 0.949107]\n",
      "epoch:11 step:10791 [D loss: 0.486285, acc.: 86.72%] [G loss: 0.935541]\n",
      "epoch:11 step:10792 [D loss: 0.636837, acc.: 66.41%] [G loss: 0.948705]\n",
      "epoch:11 step:10793 [D loss: 0.651344, acc.: 64.84%] [G loss: 0.836994]\n",
      "epoch:11 step:10794 [D loss: 0.595335, acc.: 68.75%] [G loss: 1.007625]\n",
      "epoch:11 step:10795 [D loss: 0.542175, acc.: 82.03%] [G loss: 0.793757]\n",
      "epoch:11 step:10796 [D loss: 0.793390, acc.: 39.84%] [G loss: 0.996516]\n",
      "epoch:11 step:10797 [D loss: 0.754415, acc.: 47.66%] [G loss: 0.815371]\n",
      "epoch:11 step:10798 [D loss: 0.756583, acc.: 47.66%] [G loss: 0.923853]\n",
      "epoch:11 step:10799 [D loss: 0.724767, acc.: 50.78%] [G loss: 1.068268]\n",
      "epoch:11 step:10800 [D loss: 0.690216, acc.: 54.69%] [G loss: 0.985512]\n",
      "##############\n",
      "[4.75412724 2.42970208 6.6764029  5.71595742 4.45271256 6.14122839\n",
      " 5.22749494 5.76727691 5.79411737 4.93936381]\n",
      "##########\n",
      "epoch:11 step:10801 [D loss: 0.670004, acc.: 55.47%] [G loss: 0.845570]\n",
      "epoch:11 step:10802 [D loss: 0.668759, acc.: 59.38%] [G loss: 0.791890]\n",
      "epoch:11 step:10803 [D loss: 0.670278, acc.: 57.81%] [G loss: 0.966777]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:11 step:10804 [D loss: 0.599664, acc.: 76.56%] [G loss: 0.919396]\n",
      "epoch:11 step:10805 [D loss: 0.459578, acc.: 79.69%] [G loss: 0.868139]\n",
      "epoch:11 step:10806 [D loss: 0.407982, acc.: 79.69%] [G loss: 1.080189]\n",
      "epoch:11 step:10807 [D loss: 0.740694, acc.: 55.47%] [G loss: 1.039043]\n",
      "epoch:11 step:10808 [D loss: 0.735972, acc.: 50.78%] [G loss: 0.839115]\n",
      "epoch:11 step:10809 [D loss: 0.679523, acc.: 53.12%] [G loss: 0.985296]\n",
      "epoch:11 step:10810 [D loss: 0.736751, acc.: 46.09%] [G loss: 0.926788]\n",
      "epoch:11 step:10811 [D loss: 0.578702, acc.: 72.66%] [G loss: 0.956181]\n",
      "epoch:11 step:10812 [D loss: 0.626331, acc.: 67.19%] [G loss: 1.106107]\n",
      "epoch:11 step:10813 [D loss: 0.636081, acc.: 68.75%] [G loss: 0.988749]\n",
      "epoch:11 step:10814 [D loss: 0.588933, acc.: 71.88%] [G loss: 1.063178]\n",
      "epoch:11 step:10815 [D loss: 0.575022, acc.: 67.97%] [G loss: 1.101727]\n",
      "epoch:11 step:10816 [D loss: 0.664198, acc.: 60.94%] [G loss: 0.928975]\n",
      "epoch:11 step:10817 [D loss: 0.734359, acc.: 54.69%] [G loss: 0.921109]\n",
      "epoch:11 step:10818 [D loss: 0.708346, acc.: 53.91%] [G loss: 0.889292]\n",
      "epoch:11 step:10819 [D loss: 0.625355, acc.: 66.41%] [G loss: 0.811305]\n",
      "epoch:11 step:10820 [D loss: 0.499657, acc.: 74.22%] [G loss: 0.787327]\n",
      "epoch:11 step:10821 [D loss: 0.649428, acc.: 65.62%] [G loss: 0.870231]\n",
      "epoch:11 step:10822 [D loss: 0.595604, acc.: 63.28%] [G loss: 0.773777]\n",
      "epoch:11 step:10823 [D loss: 0.592742, acc.: 70.31%] [G loss: 0.913248]\n",
      "epoch:11 step:10824 [D loss: 0.602785, acc.: 66.41%] [G loss: 0.888498]\n",
      "epoch:11 step:10825 [D loss: 0.634074, acc.: 61.72%] [G loss: 0.849596]\n",
      "epoch:11 step:10826 [D loss: 0.656453, acc.: 56.25%] [G loss: 0.836910]\n",
      "epoch:11 step:10827 [D loss: 0.605124, acc.: 67.19%] [G loss: 0.852818]\n",
      "epoch:11 step:10828 [D loss: 0.633148, acc.: 66.41%] [G loss: 0.757137]\n",
      "epoch:11 step:10829 [D loss: 0.659778, acc.: 55.47%] [G loss: 0.908563]\n",
      "epoch:11 step:10830 [D loss: 0.674929, acc.: 59.38%] [G loss: 0.954906]\n",
      "epoch:11 step:10831 [D loss: 0.607448, acc.: 69.53%] [G loss: 0.912480]\n",
      "epoch:11 step:10832 [D loss: 0.655068, acc.: 57.81%] [G loss: 0.889718]\n",
      "epoch:11 step:10833 [D loss: 0.672197, acc.: 60.16%] [G loss: 0.878208]\n",
      "epoch:11 step:10834 [D loss: 0.623343, acc.: 61.72%] [G loss: 0.935892]\n",
      "epoch:11 step:10835 [D loss: 0.747791, acc.: 50.78%] [G loss: 0.855078]\n",
      "epoch:11 step:10836 [D loss: 0.759867, acc.: 44.53%] [G loss: 0.863670]\n",
      "epoch:11 step:10837 [D loss: 0.740691, acc.: 42.19%] [G loss: 0.809013]\n",
      "epoch:11 step:10838 [D loss: 0.621375, acc.: 64.84%] [G loss: 0.836040]\n",
      "epoch:11 step:10839 [D loss: 0.678639, acc.: 55.47%] [G loss: 0.790268]\n",
      "epoch:11 step:10840 [D loss: 0.637687, acc.: 63.28%] [G loss: 0.894273]\n",
      "epoch:11 step:10841 [D loss: 0.616074, acc.: 67.19%] [G loss: 0.845701]\n",
      "epoch:11 step:10842 [D loss: 0.620406, acc.: 64.84%] [G loss: 0.783962]\n",
      "epoch:11 step:10843 [D loss: 0.447515, acc.: 80.47%] [G loss: 0.902865]\n",
      "epoch:11 step:10844 [D loss: 0.496118, acc.: 69.53%] [G loss: 0.993976]\n",
      "epoch:11 step:10845 [D loss: 0.598603, acc.: 72.66%] [G loss: 0.987913]\n",
      "epoch:11 step:10846 [D loss: 0.669850, acc.: 57.81%] [G loss: 0.950967]\n",
      "epoch:11 step:10847 [D loss: 0.678954, acc.: 56.25%] [G loss: 0.729991]\n",
      "epoch:11 step:10848 [D loss: 0.598635, acc.: 67.97%] [G loss: 0.805423]\n",
      "epoch:11 step:10849 [D loss: 0.629387, acc.: 60.16%] [G loss: 0.819835]\n",
      "epoch:11 step:10850 [D loss: 0.611544, acc.: 69.53%] [G loss: 0.977111]\n",
      "epoch:11 step:10851 [D loss: 0.648879, acc.: 55.47%] [G loss: 0.805903]\n",
      "epoch:11 step:10852 [D loss: 0.645214, acc.: 58.59%] [G loss: 0.952557]\n",
      "epoch:11 step:10853 [D loss: 0.650870, acc.: 61.72%] [G loss: 0.913688]\n",
      "epoch:11 step:10854 [D loss: 0.608784, acc.: 67.97%] [G loss: 0.850851]\n",
      "epoch:11 step:10855 [D loss: 0.598803, acc.: 64.06%] [G loss: 1.020356]\n",
      "epoch:11 step:10856 [D loss: 0.592422, acc.: 67.97%] [G loss: 0.946990]\n",
      "epoch:11 step:10857 [D loss: 0.513238, acc.: 76.56%] [G loss: 1.068811]\n",
      "epoch:11 step:10858 [D loss: 0.601386, acc.: 63.28%] [G loss: 1.088578]\n",
      "epoch:11 step:10859 [D loss: 0.488727, acc.: 82.81%] [G loss: 1.251129]\n",
      "epoch:11 step:10860 [D loss: 0.640017, acc.: 61.72%] [G loss: 0.784802]\n",
      "epoch:11 step:10861 [D loss: 0.426838, acc.: 85.16%] [G loss: 1.011841]\n",
      "epoch:11 step:10862 [D loss: 0.537740, acc.: 74.22%] [G loss: 1.022494]\n",
      "epoch:11 step:10863 [D loss: 0.470343, acc.: 81.25%] [G loss: 1.109554]\n",
      "epoch:11 step:10864 [D loss: 0.546824, acc.: 69.53%] [G loss: 0.854403]\n",
      "epoch:11 step:10865 [D loss: 0.647319, acc.: 62.50%] [G loss: 1.027576]\n",
      "epoch:11 step:10866 [D loss: 0.604511, acc.: 72.66%] [G loss: 0.927915]\n",
      "epoch:11 step:10867 [D loss: 0.762315, acc.: 55.47%] [G loss: 0.934946]\n",
      "epoch:11 step:10868 [D loss: 0.485604, acc.: 78.91%] [G loss: 0.892306]\n",
      "epoch:11 step:10869 [D loss: 0.734226, acc.: 46.88%] [G loss: 0.991266]\n",
      "epoch:11 step:10870 [D loss: 0.629106, acc.: 63.28%] [G loss: 0.916915]\n",
      "epoch:11 step:10871 [D loss: 0.687892, acc.: 57.81%] [G loss: 0.964447]\n",
      "epoch:11 step:10872 [D loss: 0.748993, acc.: 51.56%] [G loss: 1.049865]\n",
      "epoch:11 step:10873 [D loss: 0.368740, acc.: 78.91%] [G loss: 1.186473]\n",
      "epoch:11 step:10874 [D loss: 0.270746, acc.: 94.53%] [G loss: 1.353029]\n",
      "epoch:11 step:10875 [D loss: 0.468995, acc.: 82.03%] [G loss: 1.309155]\n",
      "epoch:11 step:10876 [D loss: 0.746119, acc.: 60.16%] [G loss: 1.184753]\n",
      "epoch:11 step:10877 [D loss: 0.655145, acc.: 64.06%] [G loss: 0.949937]\n",
      "epoch:11 step:10878 [D loss: 0.636296, acc.: 63.28%] [G loss: 0.905598]\n",
      "epoch:11 step:10879 [D loss: 0.720953, acc.: 47.66%] [G loss: 0.927556]\n",
      "epoch:11 step:10880 [D loss: 0.681267, acc.: 59.38%] [G loss: 1.086823]\n",
      "epoch:11 step:10881 [D loss: 0.644247, acc.: 62.50%] [G loss: 1.077681]\n",
      "epoch:11 step:10882 [D loss: 0.553983, acc.: 73.44%] [G loss: 1.067402]\n",
      "epoch:11 step:10883 [D loss: 0.666687, acc.: 57.03%] [G loss: 0.594712]\n",
      "epoch:11 step:10884 [D loss: 0.470048, acc.: 78.12%] [G loss: 0.832252]\n",
      "epoch:11 step:10885 [D loss: 0.437240, acc.: 77.34%] [G loss: 0.438864]\n",
      "epoch:11 step:10886 [D loss: 0.734222, acc.: 58.59%] [G loss: 0.828327]\n",
      "epoch:11 step:10887 [D loss: 1.458135, acc.: 16.41%] [G loss: 1.319673]\n",
      "epoch:11 step:10888 [D loss: 0.740925, acc.: 54.69%] [G loss: 1.323844]\n",
      "epoch:11 step:10889 [D loss: 0.661011, acc.: 61.72%] [G loss: 0.977995]\n",
      "epoch:11 step:10890 [D loss: 0.697516, acc.: 53.12%] [G loss: 1.104179]\n",
      "epoch:11 step:10891 [D loss: 0.745789, acc.: 50.00%] [G loss: 1.019568]\n",
      "epoch:11 step:10892 [D loss: 0.645961, acc.: 59.38%] [G loss: 1.180028]\n",
      "epoch:11 step:10893 [D loss: 0.630649, acc.: 55.47%] [G loss: 1.066698]\n",
      "epoch:11 step:10894 [D loss: 0.461416, acc.: 79.69%] [G loss: 1.290735]\n",
      "epoch:11 step:10895 [D loss: 0.618500, acc.: 61.72%] [G loss: 0.946505]\n",
      "epoch:11 step:10896 [D loss: 0.417618, acc.: 81.25%] [G loss: 1.127776]\n",
      "epoch:11 step:10897 [D loss: 0.753407, acc.: 52.34%] [G loss: 1.059318]\n",
      "epoch:11 step:10898 [D loss: 0.598205, acc.: 75.00%] [G loss: 0.965046]\n",
      "epoch:11 step:10899 [D loss: 0.575361, acc.: 72.66%] [G loss: 0.916739]\n",
      "epoch:11 step:10900 [D loss: 0.600262, acc.: 67.97%] [G loss: 1.017814]\n",
      "epoch:11 step:10901 [D loss: 0.740241, acc.: 51.56%] [G loss: 0.728076]\n",
      "epoch:11 step:10902 [D loss: 0.607665, acc.: 67.97%] [G loss: 1.047662]\n",
      "epoch:11 step:10903 [D loss: 1.270136, acc.: 40.62%] [G loss: 1.009155]\n",
      "epoch:11 step:10904 [D loss: 0.675958, acc.: 62.50%] [G loss: 1.305717]\n",
      "epoch:11 step:10905 [D loss: 0.612940, acc.: 67.19%] [G loss: 1.341658]\n",
      "epoch:11 step:10906 [D loss: 0.606853, acc.: 64.84%] [G loss: 1.172555]\n",
      "epoch:11 step:10907 [D loss: 0.601140, acc.: 82.81%] [G loss: 1.086292]\n",
      "epoch:11 step:10908 [D loss: 0.682743, acc.: 63.28%] [G loss: 1.046065]\n",
      "epoch:11 step:10909 [D loss: 0.643717, acc.: 67.19%] [G loss: 0.959245]\n",
      "epoch:11 step:10910 [D loss: 0.628518, acc.: 67.19%] [G loss: 0.982240]\n",
      "epoch:11 step:10911 [D loss: 0.635336, acc.: 60.16%] [G loss: 0.851786]\n",
      "epoch:11 step:10912 [D loss: 0.605121, acc.: 68.75%] [G loss: 0.977960]\n",
      "epoch:11 step:10913 [D loss: 0.668165, acc.: 64.84%] [G loss: 0.965754]\n",
      "epoch:11 step:10914 [D loss: 0.684793, acc.: 54.69%] [G loss: 0.813793]\n",
      "epoch:11 step:10915 [D loss: 0.660132, acc.: 62.50%] [G loss: 0.911916]\n",
      "epoch:11 step:10916 [D loss: 0.668545, acc.: 58.59%] [G loss: 0.811245]\n",
      "epoch:11 step:10917 [D loss: 0.703984, acc.: 54.69%] [G loss: 0.878989]\n",
      "epoch:11 step:10918 [D loss: 0.709363, acc.: 50.78%] [G loss: 0.770741]\n",
      "epoch:11 step:10919 [D loss: 0.722321, acc.: 50.78%] [G loss: 0.766286]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:11 step:10920 [D loss: 0.592232, acc.: 66.41%] [G loss: 0.825141]\n",
      "epoch:11 step:10921 [D loss: 0.671575, acc.: 61.72%] [G loss: 0.798851]\n",
      "epoch:11 step:10922 [D loss: 0.674536, acc.: 60.94%] [G loss: 0.944825]\n",
      "epoch:11 step:10923 [D loss: 0.556521, acc.: 72.66%] [G loss: 0.743661]\n",
      "epoch:11 step:10924 [D loss: 0.628582, acc.: 61.72%] [G loss: 0.823643]\n",
      "epoch:11 step:10925 [D loss: 0.682131, acc.: 57.03%] [G loss: 0.852881]\n",
      "epoch:11 step:10926 [D loss: 0.650472, acc.: 57.81%] [G loss: 0.753900]\n",
      "epoch:11 step:10927 [D loss: 0.699162, acc.: 51.56%] [G loss: 0.955330]\n",
      "epoch:11 step:10928 [D loss: 0.669069, acc.: 57.03%] [G loss: 0.817625]\n",
      "epoch:11 step:10929 [D loss: 0.666770, acc.: 60.16%] [G loss: 0.684587]\n",
      "epoch:11 step:10930 [D loss: 0.665338, acc.: 61.72%] [G loss: 0.865168]\n",
      "epoch:11 step:10931 [D loss: 0.616760, acc.: 67.19%] [G loss: 0.843042]\n",
      "epoch:11 step:10932 [D loss: 0.661673, acc.: 64.06%] [G loss: 0.828252]\n",
      "epoch:11 step:10933 [D loss: 0.624318, acc.: 64.84%] [G loss: 0.877866]\n",
      "epoch:11 step:10934 [D loss: 0.724704, acc.: 49.22%] [G loss: 0.695913]\n",
      "epoch:11 step:10935 [D loss: 0.637429, acc.: 67.97%] [G loss: 0.743986]\n",
      "epoch:11 step:10936 [D loss: 0.676592, acc.: 57.81%] [G loss: 0.884588]\n",
      "epoch:11 step:10937 [D loss: 0.619158, acc.: 67.97%] [G loss: 0.726546]\n",
      "epoch:11 step:10938 [D loss: 0.650595, acc.: 61.72%] [G loss: 0.905073]\n",
      "epoch:11 step:10939 [D loss: 0.612882, acc.: 67.97%] [G loss: 0.856947]\n",
      "epoch:11 step:10940 [D loss: 0.621721, acc.: 61.72%] [G loss: 0.863189]\n",
      "epoch:11 step:10941 [D loss: 0.699437, acc.: 56.25%] [G loss: 0.876302]\n",
      "epoch:11 step:10942 [D loss: 0.614864, acc.: 66.41%] [G loss: 0.802882]\n",
      "epoch:11 step:10943 [D loss: 0.700817, acc.: 53.12%] [G loss: 0.864864]\n",
      "epoch:11 step:10944 [D loss: 0.651985, acc.: 63.28%] [G loss: 0.763519]\n",
      "epoch:11 step:10945 [D loss: 0.692417, acc.: 53.91%] [G loss: 0.744968]\n",
      "epoch:11 step:10946 [D loss: 0.648557, acc.: 60.16%] [G loss: 0.695528]\n",
      "epoch:11 step:10947 [D loss: 0.747003, acc.: 48.44%] [G loss: 0.874423]\n",
      "epoch:11 step:10948 [D loss: 0.500610, acc.: 81.25%] [G loss: 0.948019]\n",
      "epoch:11 step:10949 [D loss: 0.650801, acc.: 63.28%] [G loss: 0.909716]\n",
      "epoch:11 step:10950 [D loss: 0.698970, acc.: 55.47%] [G loss: 1.030007]\n",
      "epoch:11 step:10951 [D loss: 0.685333, acc.: 57.03%] [G loss: 0.872738]\n",
      "epoch:11 step:10952 [D loss: 0.609639, acc.: 70.31%] [G loss: 0.947008]\n",
      "epoch:11 step:10953 [D loss: 0.666244, acc.: 59.38%] [G loss: 0.960176]\n",
      "epoch:11 step:10954 [D loss: 0.651934, acc.: 59.38%] [G loss: 0.956982]\n",
      "epoch:11 step:10955 [D loss: 0.654173, acc.: 62.50%] [G loss: 0.848357]\n",
      "epoch:11 step:10956 [D loss: 0.720332, acc.: 44.53%] [G loss: 0.958350]\n",
      "epoch:11 step:10957 [D loss: 0.572096, acc.: 74.22%] [G loss: 0.983804]\n",
      "epoch:11 step:10958 [D loss: 0.622796, acc.: 65.62%] [G loss: 0.921982]\n",
      "epoch:11 step:10959 [D loss: 0.717094, acc.: 53.91%] [G loss: 0.881023]\n",
      "epoch:11 step:10960 [D loss: 0.764196, acc.: 53.91%] [G loss: 1.050660]\n",
      "epoch:11 step:10961 [D loss: 0.745644, acc.: 55.47%] [G loss: 0.925395]\n",
      "epoch:11 step:10962 [D loss: 0.692753, acc.: 54.69%] [G loss: 0.943070]\n",
      "epoch:11 step:10963 [D loss: 0.676124, acc.: 59.38%] [G loss: 0.873186]\n",
      "epoch:11 step:10964 [D loss: 0.703195, acc.: 53.12%] [G loss: 0.817717]\n",
      "epoch:11 step:10965 [D loss: 0.743427, acc.: 48.44%] [G loss: 0.757743]\n",
      "epoch:11 step:10966 [D loss: 0.677093, acc.: 57.03%] [G loss: 0.814299]\n",
      "epoch:11 step:10967 [D loss: 0.629256, acc.: 67.19%] [G loss: 0.820848]\n",
      "epoch:11 step:10968 [D loss: 0.659720, acc.: 62.50%] [G loss: 0.816465]\n",
      "epoch:11 step:10969 [D loss: 0.720385, acc.: 49.22%] [G loss: 0.907355]\n",
      "epoch:11 step:10970 [D loss: 0.377822, acc.: 84.38%] [G loss: 0.965961]\n",
      "epoch:11 step:10971 [D loss: 0.361585, acc.: 89.06%] [G loss: 0.999031]\n",
      "epoch:11 step:10972 [D loss: 0.343416, acc.: 90.62%] [G loss: 1.020728]\n",
      "epoch:11 step:10973 [D loss: 0.652820, acc.: 71.88%] [G loss: 1.047167]\n",
      "epoch:11 step:10974 [D loss: 0.642355, acc.: 67.97%] [G loss: 1.008792]\n",
      "epoch:11 step:10975 [D loss: 0.694834, acc.: 57.81%] [G loss: 0.934388]\n",
      "epoch:11 step:10976 [D loss: 0.645355, acc.: 64.84%] [G loss: 0.968075]\n",
      "epoch:11 step:10977 [D loss: 0.668225, acc.: 60.94%] [G loss: 0.932690]\n",
      "epoch:11 step:10978 [D loss: 0.649234, acc.: 62.50%] [G loss: 0.999984]\n",
      "epoch:11 step:10979 [D loss: 0.746114, acc.: 47.66%] [G loss: 0.835903]\n",
      "epoch:11 step:10980 [D loss: 0.754483, acc.: 43.75%] [G loss: 0.800152]\n",
      "epoch:11 step:10981 [D loss: 0.618241, acc.: 67.19%] [G loss: 0.832460]\n",
      "epoch:11 step:10982 [D loss: 0.748934, acc.: 45.31%] [G loss: 0.906870]\n",
      "epoch:11 step:10983 [D loss: 0.673137, acc.: 56.25%] [G loss: 0.844047]\n",
      "epoch:11 step:10984 [D loss: 0.720810, acc.: 47.66%] [G loss: 0.821997]\n",
      "epoch:11 step:10985 [D loss: 0.694569, acc.: 49.22%] [G loss: 0.810312]\n",
      "epoch:11 step:10986 [D loss: 0.697878, acc.: 53.12%] [G loss: 0.789865]\n",
      "epoch:11 step:10987 [D loss: 0.632058, acc.: 61.72%] [G loss: 0.826136]\n",
      "epoch:11 step:10988 [D loss: 0.664103, acc.: 60.94%] [G loss: 0.844734]\n",
      "epoch:11 step:10989 [D loss: 0.650159, acc.: 69.53%] [G loss: 0.794249]\n",
      "epoch:11 step:10990 [D loss: 0.634572, acc.: 67.19%] [G loss: 0.839422]\n",
      "epoch:11 step:10991 [D loss: 0.568094, acc.: 70.31%] [G loss: 0.865623]\n",
      "epoch:11 step:10992 [D loss: 0.654124, acc.: 60.16%] [G loss: 0.875889]\n",
      "epoch:11 step:10993 [D loss: 0.588092, acc.: 71.09%] [G loss: 0.863368]\n",
      "epoch:11 step:10994 [D loss: 0.563685, acc.: 74.22%] [G loss: 0.907521]\n",
      "epoch:11 step:10995 [D loss: 0.659866, acc.: 60.16%] [G loss: 0.840137]\n",
      "epoch:11 step:10996 [D loss: 0.794274, acc.: 43.75%] [G loss: 0.918401]\n",
      "epoch:11 step:10997 [D loss: 0.725191, acc.: 46.09%] [G loss: 0.774202]\n",
      "epoch:11 step:10998 [D loss: 0.737866, acc.: 50.78%] [G loss: 0.857940]\n",
      "epoch:11 step:10999 [D loss: 0.793032, acc.: 39.84%] [G loss: 0.693707]\n",
      "epoch:11 step:11000 [D loss: 0.702866, acc.: 56.25%] [G loss: 0.819096]\n",
      "##############\n",
      "[4.02732224 2.55887473 6.41027122 5.37682106 4.09209722 6.14241092\n",
      " 5.40868169 5.82466354 5.53608829 5.15138833]\n",
      "##########\n",
      "epoch:11 step:11001 [D loss: 0.687503, acc.: 54.69%] [G loss: 0.882609]\n",
      "epoch:11 step:11002 [D loss: 0.665583, acc.: 57.03%] [G loss: 0.810028]\n",
      "epoch:11 step:11003 [D loss: 0.377818, acc.: 85.94%] [G loss: 0.844919]\n",
      "epoch:11 step:11004 [D loss: 0.357575, acc.: 85.94%] [G loss: 1.033073]\n",
      "epoch:11 step:11005 [D loss: 0.429571, acc.: 89.06%] [G loss: 1.064494]\n",
      "epoch:11 step:11006 [D loss: 0.616948, acc.: 71.09%] [G loss: 1.036210]\n",
      "epoch:11 step:11007 [D loss: 0.357695, acc.: 91.41%] [G loss: 1.125803]\n",
      "epoch:11 step:11008 [D loss: 0.286490, acc.: 97.66%] [G loss: 1.188425]\n",
      "epoch:11 step:11009 [D loss: 0.355019, acc.: 90.62%] [G loss: 1.148986]\n",
      "epoch:11 step:11010 [D loss: 0.690444, acc.: 61.72%] [G loss: 1.156720]\n",
      "epoch:11 step:11011 [D loss: 0.607047, acc.: 65.62%] [G loss: 1.089238]\n",
      "epoch:11 step:11012 [D loss: 1.186227, acc.: 14.84%] [G loss: 1.268523]\n",
      "epoch:11 step:11013 [D loss: 0.320464, acc.: 88.28%] [G loss: 1.312697]\n",
      "epoch:11 step:11014 [D loss: 0.214210, acc.: 95.31%] [G loss: 1.446893]\n",
      "epoch:11 step:11015 [D loss: 0.412718, acc.: 87.50%] [G loss: 1.411769]\n",
      "epoch:11 step:11016 [D loss: 0.703384, acc.: 53.12%] [G loss: 1.244191]\n",
      "epoch:11 step:11017 [D loss: 0.943023, acc.: 50.00%] [G loss: 1.186607]\n",
      "epoch:11 step:11018 [D loss: 0.851972, acc.: 42.97%] [G loss: 1.159249]\n",
      "epoch:11 step:11019 [D loss: 0.649937, acc.: 63.28%] [G loss: 0.943341]\n",
      "epoch:11 step:11020 [D loss: 0.259818, acc.: 95.31%] [G loss: 1.008645]\n",
      "epoch:11 step:11021 [D loss: 0.326595, acc.: 89.84%] [G loss: 0.974254]\n",
      "epoch:11 step:11022 [D loss: 0.785782, acc.: 43.75%] [G loss: 0.372474]\n",
      "epoch:11 step:11023 [D loss: 0.814527, acc.: 40.62%] [G loss: 1.091810]\n",
      "epoch:11 step:11024 [D loss: 0.753029, acc.: 48.44%] [G loss: 0.928371]\n",
      "epoch:11 step:11025 [D loss: 0.710469, acc.: 53.12%] [G loss: 0.762148]\n",
      "epoch:11 step:11026 [D loss: 0.733249, acc.: 50.00%] [G loss: 0.924358]\n",
      "epoch:11 step:11027 [D loss: 0.650585, acc.: 63.28%] [G loss: 0.697009]\n",
      "epoch:11 step:11028 [D loss: 0.736419, acc.: 42.97%] [G loss: 0.386759]\n",
      "epoch:11 step:11029 [D loss: 0.776362, acc.: 44.53%] [G loss: 0.918341]\n",
      "epoch:11 step:11030 [D loss: 0.765717, acc.: 48.44%] [G loss: 0.527581]\n",
      "epoch:11 step:11031 [D loss: 0.909357, acc.: 49.22%] [G loss: 1.682902]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:11 step:11032 [D loss: 0.521703, acc.: 64.06%] [G loss: 2.884903]\n",
      "epoch:11 step:11033 [D loss: 0.414188, acc.: 79.69%] [G loss: 2.832104]\n",
      "epoch:11 step:11034 [D loss: 0.788592, acc.: 51.56%] [G loss: 1.984238]\n",
      "epoch:11 step:11035 [D loss: 1.301539, acc.: 42.19%] [G loss: 0.905622]\n",
      "epoch:11 step:11036 [D loss: 0.720689, acc.: 57.81%] [G loss: 0.917192]\n",
      "epoch:11 step:11037 [D loss: 0.628275, acc.: 63.28%] [G loss: 0.863309]\n",
      "epoch:11 step:11038 [D loss: 0.592435, acc.: 73.44%] [G loss: 0.905069]\n",
      "epoch:11 step:11039 [D loss: 0.557038, acc.: 73.44%] [G loss: 0.867817]\n",
      "epoch:11 step:11040 [D loss: 0.589380, acc.: 73.44%] [G loss: 0.921722]\n",
      "epoch:11 step:11041 [D loss: 0.628106, acc.: 64.06%] [G loss: 0.841063]\n",
      "epoch:11 step:11042 [D loss: 0.634403, acc.: 63.28%] [G loss: 0.877913]\n",
      "epoch:11 step:11043 [D loss: 0.582267, acc.: 78.91%] [G loss: 0.986228]\n",
      "epoch:11 step:11044 [D loss: 0.608314, acc.: 62.50%] [G loss: 1.018579]\n",
      "epoch:11 step:11045 [D loss: 0.626933, acc.: 68.75%] [G loss: 0.920865]\n",
      "epoch:11 step:11046 [D loss: 0.555262, acc.: 75.00%] [G loss: 0.955963]\n",
      "epoch:11 step:11047 [D loss: 0.585619, acc.: 68.75%] [G loss: 0.986301]\n",
      "epoch:11 step:11048 [D loss: 0.656462, acc.: 64.06%] [G loss: 0.903057]\n",
      "epoch:11 step:11049 [D loss: 0.612390, acc.: 64.06%] [G loss: 1.005440]\n",
      "epoch:11 step:11050 [D loss: 0.551520, acc.: 78.12%] [G loss: 0.880657]\n",
      "epoch:11 step:11051 [D loss: 0.712034, acc.: 47.66%] [G loss: 0.954124]\n",
      "epoch:11 step:11052 [D loss: 0.809876, acc.: 38.28%] [G loss: 0.600596]\n",
      "epoch:11 step:11053 [D loss: 0.437153, acc.: 83.59%] [G loss: 1.037144]\n",
      "epoch:11 step:11054 [D loss: 0.669951, acc.: 57.81%] [G loss: 0.981779]\n",
      "epoch:11 step:11055 [D loss: 0.634715, acc.: 64.06%] [G loss: 1.039465]\n",
      "epoch:11 step:11056 [D loss: 0.571175, acc.: 71.88%] [G loss: 0.991998]\n",
      "epoch:11 step:11057 [D loss: 0.521357, acc.: 80.47%] [G loss: 1.044137]\n",
      "epoch:11 step:11058 [D loss: 0.629566, acc.: 57.03%] [G loss: 0.981527]\n",
      "epoch:11 step:11059 [D loss: 0.632118, acc.: 70.31%] [G loss: 0.934468]\n",
      "epoch:11 step:11060 [D loss: 0.649919, acc.: 57.81%] [G loss: 1.043380]\n",
      "epoch:11 step:11061 [D loss: 0.682054, acc.: 56.25%] [G loss: 0.868887]\n",
      "epoch:11 step:11062 [D loss: 0.599507, acc.: 67.97%] [G loss: 0.956891]\n",
      "epoch:11 step:11063 [D loss: 0.524698, acc.: 75.00%] [G loss: 1.054192]\n",
      "epoch:11 step:11064 [D loss: 0.653866, acc.: 61.72%] [G loss: 0.948082]\n",
      "epoch:11 step:11065 [D loss: 0.667980, acc.: 57.03%] [G loss: 0.990700]\n",
      "epoch:11 step:11066 [D loss: 0.703406, acc.: 57.81%] [G loss: 0.881783]\n",
      "epoch:11 step:11067 [D loss: 0.637901, acc.: 67.97%] [G loss: 0.859403]\n",
      "epoch:11 step:11068 [D loss: 0.710535, acc.: 58.59%] [G loss: 0.958116]\n",
      "epoch:11 step:11069 [D loss: 0.675626, acc.: 60.16%] [G loss: 0.971331]\n",
      "epoch:11 step:11070 [D loss: 0.687446, acc.: 50.78%] [G loss: 0.972527]\n",
      "epoch:11 step:11071 [D loss: 0.379701, acc.: 87.50%] [G loss: 0.726656]\n",
      "epoch:11 step:11072 [D loss: 0.686338, acc.: 53.91%] [G loss: 1.026901]\n",
      "epoch:11 step:11073 [D loss: 0.588642, acc.: 68.75%] [G loss: 0.937653]\n",
      "epoch:11 step:11074 [D loss: 0.613045, acc.: 66.41%] [G loss: 0.896860]\n",
      "epoch:11 step:11075 [D loss: 0.548644, acc.: 78.12%] [G loss: 0.664931]\n",
      "epoch:11 step:11076 [D loss: 0.586080, acc.: 69.53%] [G loss: 0.985343]\n",
      "epoch:11 step:11077 [D loss: 0.511301, acc.: 78.91%] [G loss: 1.012025]\n",
      "epoch:11 step:11078 [D loss: 0.718772, acc.: 52.34%] [G loss: 0.364798]\n",
      "epoch:11 step:11079 [D loss: 0.854505, acc.: 35.16%] [G loss: 0.993609]\n",
      "epoch:11 step:11080 [D loss: 0.689369, acc.: 61.72%] [G loss: 0.877129]\n",
      "epoch:11 step:11081 [D loss: 0.503529, acc.: 79.69%] [G loss: 1.008427]\n",
      "epoch:11 step:11082 [D loss: 0.496188, acc.: 76.56%] [G loss: 1.058721]\n",
      "epoch:11 step:11083 [D loss: 0.718798, acc.: 54.69%] [G loss: 0.957321]\n",
      "epoch:11 step:11084 [D loss: 0.638305, acc.: 60.94%] [G loss: 0.913344]\n",
      "epoch:11 step:11085 [D loss: 0.707349, acc.: 57.81%] [G loss: 1.001818]\n",
      "epoch:11 step:11086 [D loss: 0.706089, acc.: 53.12%] [G loss: 0.915387]\n",
      "epoch:11 step:11087 [D loss: 0.736080, acc.: 50.78%] [G loss: 0.906941]\n",
      "epoch:11 step:11088 [D loss: 0.645352, acc.: 63.28%] [G loss: 0.988115]\n",
      "epoch:11 step:11089 [D loss: 0.536256, acc.: 71.88%] [G loss: 0.926103]\n",
      "epoch:11 step:11090 [D loss: 0.673378, acc.: 60.94%] [G loss: 0.958860]\n",
      "epoch:11 step:11091 [D loss: 0.943536, acc.: 33.59%] [G loss: 0.952268]\n",
      "epoch:11 step:11092 [D loss: 0.700161, acc.: 56.25%] [G loss: 0.930756]\n",
      "epoch:11 step:11093 [D loss: 0.590371, acc.: 67.97%] [G loss: 1.089491]\n",
      "epoch:11 step:11094 [D loss: 0.769271, acc.: 42.19%] [G loss: 1.003944]\n",
      "epoch:11 step:11095 [D loss: 0.679225, acc.: 57.03%] [G loss: 0.897389]\n",
      "epoch:11 step:11096 [D loss: 0.710683, acc.: 51.56%] [G loss: 0.882058]\n",
      "epoch:11 step:11097 [D loss: 0.712034, acc.: 49.22%] [G loss: 0.835522]\n",
      "epoch:11 step:11098 [D loss: 0.399112, acc.: 88.28%] [G loss: 0.754228]\n",
      "epoch:11 step:11099 [D loss: 0.567381, acc.: 72.66%] [G loss: 0.829353]\n",
      "epoch:11 step:11100 [D loss: 0.524146, acc.: 75.00%] [G loss: 0.940848]\n",
      "epoch:11 step:11101 [D loss: 0.549731, acc.: 80.47%] [G loss: 0.862679]\n",
      "epoch:11 step:11102 [D loss: 0.620160, acc.: 64.84%] [G loss: 0.836211]\n",
      "epoch:11 step:11103 [D loss: 0.436160, acc.: 85.94%] [G loss: 0.478717]\n",
      "epoch:11 step:11104 [D loss: 0.652061, acc.: 58.59%] [G loss: 0.527930]\n",
      "epoch:11 step:11105 [D loss: 0.672407, acc.: 64.84%] [G loss: 0.899415]\n",
      "epoch:11 step:11106 [D loss: 0.760133, acc.: 48.44%] [G loss: 1.006286]\n",
      "epoch:11 step:11107 [D loss: 0.595067, acc.: 66.41%] [G loss: 0.941087]\n",
      "epoch:11 step:11108 [D loss: 0.578314, acc.: 66.41%] [G loss: 0.929363]\n",
      "epoch:11 step:11109 [D loss: 0.636138, acc.: 58.59%] [G loss: 0.983464]\n",
      "epoch:11 step:11110 [D loss: 0.640889, acc.: 65.62%] [G loss: 1.100927]\n",
      "epoch:11 step:11111 [D loss: 0.336731, acc.: 95.31%] [G loss: 0.964236]\n",
      "epoch:11 step:11112 [D loss: 0.509856, acc.: 75.78%] [G loss: 1.033064]\n",
      "epoch:11 step:11113 [D loss: 0.279027, acc.: 95.31%] [G loss: 1.111783]\n",
      "epoch:11 step:11114 [D loss: 0.709542, acc.: 54.69%] [G loss: 1.142504]\n",
      "epoch:11 step:11115 [D loss: 0.601397, acc.: 64.84%] [G loss: 1.020554]\n",
      "epoch:11 step:11116 [D loss: 0.522190, acc.: 74.22%] [G loss: 0.927944]\n",
      "epoch:11 step:11117 [D loss: 0.572884, acc.: 71.09%] [G loss: 1.085591]\n",
      "epoch:11 step:11118 [D loss: 0.709828, acc.: 57.03%] [G loss: 1.071932]\n",
      "epoch:11 step:11119 [D loss: 0.738121, acc.: 50.78%] [G loss: 0.804013]\n",
      "epoch:11 step:11120 [D loss: 0.671679, acc.: 59.38%] [G loss: 0.736697]\n",
      "epoch:11 step:11121 [D loss: 0.695579, acc.: 53.12%] [G loss: 0.943839]\n",
      "epoch:11 step:11122 [D loss: 0.501214, acc.: 79.69%] [G loss: 0.931379]\n",
      "epoch:11 step:11123 [D loss: 0.500862, acc.: 83.59%] [G loss: 0.901880]\n",
      "epoch:11 step:11124 [D loss: 0.644439, acc.: 60.94%] [G loss: 0.973409]\n",
      "epoch:11 step:11125 [D loss: 0.602062, acc.: 66.41%] [G loss: 0.762977]\n",
      "epoch:11 step:11126 [D loss: 0.687195, acc.: 61.72%] [G loss: 1.053772]\n",
      "epoch:11 step:11127 [D loss: 0.802577, acc.: 42.97%] [G loss: 1.003530]\n",
      "epoch:11 step:11128 [D loss: 0.718886, acc.: 50.78%] [G loss: 1.074603]\n",
      "epoch:11 step:11129 [D loss: 0.716624, acc.: 46.09%] [G loss: 0.812657]\n",
      "epoch:11 step:11130 [D loss: 0.729788, acc.: 46.88%] [G loss: 0.873369]\n",
      "epoch:11 step:11131 [D loss: 0.591775, acc.: 68.75%] [G loss: 0.875077]\n",
      "epoch:11 step:11132 [D loss: 0.574748, acc.: 75.78%] [G loss: 0.902223]\n",
      "epoch:11 step:11133 [D loss: 0.697560, acc.: 55.47%] [G loss: 0.936078]\n",
      "epoch:11 step:11134 [D loss: 0.696536, acc.: 54.69%] [G loss: 1.129183]\n",
      "epoch:11 step:11135 [D loss: 0.643330, acc.: 61.72%] [G loss: 0.902882]\n",
      "epoch:11 step:11136 [D loss: 0.724367, acc.: 50.00%] [G loss: 1.123558]\n",
      "epoch:11 step:11137 [D loss: 0.538567, acc.: 81.25%] [G loss: 1.066583]\n",
      "epoch:11 step:11138 [D loss: 0.697441, acc.: 57.81%] [G loss: 0.898341]\n",
      "epoch:11 step:11139 [D loss: 0.481912, acc.: 82.03%] [G loss: 0.849407]\n",
      "epoch:11 step:11140 [D loss: 0.797649, acc.: 41.41%] [G loss: 0.969250]\n",
      "epoch:11 step:11141 [D loss: 0.838660, acc.: 32.81%] [G loss: 0.826411]\n",
      "epoch:11 step:11142 [D loss: 0.706287, acc.: 56.25%] [G loss: 0.934103]\n",
      "epoch:11 step:11143 [D loss: 0.700126, acc.: 52.34%] [G loss: 0.922921]\n",
      "epoch:11 step:11144 [D loss: 0.598529, acc.: 70.31%] [G loss: 0.910574]\n",
      "epoch:11 step:11145 [D loss: 0.675054, acc.: 56.25%] [G loss: 1.131298]\n",
      "epoch:11 step:11146 [D loss: 0.685054, acc.: 58.59%] [G loss: 0.745991]\n",
      "epoch:11 step:11147 [D loss: 0.680754, acc.: 59.38%] [G loss: 0.838874]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:11 step:11148 [D loss: 0.655879, acc.: 55.47%] [G loss: 0.898361]\n",
      "epoch:11 step:11149 [D loss: 0.586550, acc.: 71.09%] [G loss: 0.863273]\n",
      "epoch:11 step:11150 [D loss: 0.674805, acc.: 64.06%] [G loss: 0.804175]\n",
      "epoch:11 step:11151 [D loss: 0.624616, acc.: 66.41%] [G loss: 0.856177]\n",
      "epoch:11 step:11152 [D loss: 0.510321, acc.: 80.47%] [G loss: 1.078032]\n",
      "epoch:11 step:11153 [D loss: 0.704477, acc.: 53.12%] [G loss: 0.945510]\n",
      "epoch:11 step:11154 [D loss: 0.577056, acc.: 73.44%] [G loss: 1.010562]\n",
      "epoch:11 step:11155 [D loss: 0.565007, acc.: 70.31%] [G loss: 0.877802]\n",
      "epoch:11 step:11156 [D loss: 0.613132, acc.: 65.62%] [G loss: 0.869027]\n",
      "epoch:11 step:11157 [D loss: 0.306219, acc.: 89.84%] [G loss: 1.030539]\n",
      "epoch:11 step:11158 [D loss: 0.390602, acc.: 87.50%] [G loss: 1.141273]\n",
      "epoch:11 step:11159 [D loss: 0.411665, acc.: 91.41%] [G loss: 1.333913]\n",
      "epoch:11 step:11160 [D loss: 0.475906, acc.: 86.72%] [G loss: 1.287946]\n",
      "epoch:11 step:11161 [D loss: 0.240094, acc.: 92.19%] [G loss: 1.228376]\n",
      "epoch:11 step:11162 [D loss: 0.527611, acc.: 82.03%] [G loss: 0.889432]\n",
      "epoch:11 step:11163 [D loss: 1.119511, acc.: 35.16%] [G loss: 1.292356]\n",
      "epoch:11 step:11164 [D loss: 0.393876, acc.: 86.72%] [G loss: 1.448722]\n",
      "epoch:11 step:11165 [D loss: 0.950283, acc.: 48.44%] [G loss: 1.368357]\n",
      "epoch:11 step:11166 [D loss: 0.820830, acc.: 41.41%] [G loss: 1.178909]\n",
      "epoch:11 step:11167 [D loss: 0.763420, acc.: 52.34%] [G loss: 0.888072]\n",
      "epoch:11 step:11168 [D loss: 0.652073, acc.: 64.06%] [G loss: 0.996583]\n",
      "epoch:11 step:11169 [D loss: 0.769994, acc.: 44.53%] [G loss: 0.986387]\n",
      "epoch:11 step:11170 [D loss: 0.726438, acc.: 50.00%] [G loss: 0.981030]\n",
      "epoch:11 step:11171 [D loss: 0.633422, acc.: 60.16%] [G loss: 0.940315]\n",
      "epoch:11 step:11172 [D loss: 0.699622, acc.: 56.25%] [G loss: 0.846901]\n",
      "epoch:11 step:11173 [D loss: 0.644778, acc.: 62.50%] [G loss: 0.870890]\n",
      "epoch:11 step:11174 [D loss: 0.679827, acc.: 57.81%] [G loss: 1.017937]\n",
      "epoch:11 step:11175 [D loss: 0.620794, acc.: 65.62%] [G loss: 0.951183]\n",
      "epoch:11 step:11176 [D loss: 0.707370, acc.: 50.00%] [G loss: 0.950542]\n",
      "epoch:11 step:11177 [D loss: 0.639598, acc.: 63.28%] [G loss: 0.929757]\n",
      "epoch:11 step:11178 [D loss: 0.618735, acc.: 67.19%] [G loss: 0.899651]\n",
      "epoch:11 step:11179 [D loss: 0.680240, acc.: 56.25%] [G loss: 0.985439]\n",
      "epoch:11 step:11180 [D loss: 0.648982, acc.: 67.19%] [G loss: 0.953670]\n",
      "epoch:11 step:11181 [D loss: 0.672617, acc.: 56.25%] [G loss: 0.839221]\n",
      "epoch:11 step:11182 [D loss: 0.659015, acc.: 64.06%] [G loss: 0.862255]\n",
      "epoch:11 step:11183 [D loss: 0.669826, acc.: 59.38%] [G loss: 0.781153]\n",
      "epoch:11 step:11184 [D loss: 0.631468, acc.: 62.50%] [G loss: 0.847124]\n",
      "epoch:11 step:11185 [D loss: 0.540556, acc.: 73.44%] [G loss: 0.900054]\n",
      "epoch:11 step:11186 [D loss: 0.668653, acc.: 52.34%] [G loss: 0.652778]\n",
      "epoch:11 step:11187 [D loss: 0.786562, acc.: 43.75%] [G loss: 0.816154]\n",
      "epoch:11 step:11188 [D loss: 0.755060, acc.: 46.88%] [G loss: 0.869436]\n",
      "epoch:11 step:11189 [D loss: 0.540202, acc.: 68.75%] [G loss: 0.948688]\n",
      "epoch:11 step:11190 [D loss: 0.516573, acc.: 74.22%] [G loss: 0.878366]\n",
      "epoch:11 step:11191 [D loss: 0.448230, acc.: 75.00%] [G loss: 0.889773]\n",
      "epoch:11 step:11192 [D loss: 0.291456, acc.: 86.72%] [G loss: 0.992743]\n",
      "epoch:11 step:11193 [D loss: 0.326988, acc.: 85.94%] [G loss: 1.114377]\n",
      "epoch:11 step:11194 [D loss: 0.307902, acc.: 90.62%] [G loss: 1.185457]\n",
      "epoch:11 step:11195 [D loss: 0.750353, acc.: 50.00%] [G loss: 1.146971]\n",
      "epoch:11 step:11196 [D loss: 0.351550, acc.: 93.75%] [G loss: 1.208276]\n",
      "epoch:11 step:11197 [D loss: 0.247244, acc.: 97.66%] [G loss: 1.077737]\n",
      "epoch:11 step:11198 [D loss: 0.819872, acc.: 50.78%] [G loss: 1.018101]\n",
      "epoch:11 step:11199 [D loss: 1.351782, acc.: 10.94%] [G loss: 1.025578]\n",
      "epoch:11 step:11200 [D loss: 0.731444, acc.: 50.78%] [G loss: 1.022181]\n",
      "##############\n",
      "[4.50489237 2.12618493 7.00443035 6.05009809 4.63617144 6.22809703\n",
      " 5.50316648 6.15877363 5.99702905 5.13343861]\n",
      "##########\n",
      "epoch:11 step:11201 [D loss: 0.715780, acc.: 50.78%] [G loss: 0.902077]\n",
      "epoch:11 step:11202 [D loss: 0.742926, acc.: 50.00%] [G loss: 0.955668]\n",
      "epoch:11 step:11203 [D loss: 0.700120, acc.: 57.03%] [G loss: 0.876354]\n",
      "epoch:11 step:11204 [D loss: 0.723421, acc.: 51.56%] [G loss: 0.898413]\n",
      "epoch:11 step:11205 [D loss: 0.645562, acc.: 65.62%] [G loss: 0.959601]\n",
      "epoch:11 step:11206 [D loss: 0.563686, acc.: 72.66%] [G loss: 0.963686]\n",
      "epoch:11 step:11207 [D loss: 0.666909, acc.: 59.38%] [G loss: 1.015474]\n",
      "epoch:11 step:11208 [D loss: 0.610859, acc.: 64.84%] [G loss: 0.913422]\n",
      "epoch:11 step:11209 [D loss: 0.813988, acc.: 39.84%] [G loss: 0.834860]\n",
      "epoch:11 step:11210 [D loss: 0.688500, acc.: 52.34%] [G loss: 0.737759]\n",
      "epoch:11 step:11211 [D loss: 0.362507, acc.: 89.84%] [G loss: 0.902365]\n",
      "epoch:11 step:11212 [D loss: 0.377063, acc.: 85.16%] [G loss: 1.025189]\n",
      "epoch:11 step:11213 [D loss: 0.310146, acc.: 92.97%] [G loss: 1.036131]\n",
      "epoch:11 step:11214 [D loss: 0.698102, acc.: 52.34%] [G loss: 0.981715]\n",
      "epoch:11 step:11215 [D loss: 0.769751, acc.: 47.66%] [G loss: 0.929672]\n",
      "epoch:11 step:11216 [D loss: 0.764194, acc.: 39.06%] [G loss: 0.767270]\n",
      "epoch:11 step:11217 [D loss: 0.468876, acc.: 89.06%] [G loss: 0.995002]\n",
      "epoch:11 step:11218 [D loss: 0.702536, acc.: 49.22%] [G loss: 0.971652]\n",
      "epoch:11 step:11219 [D loss: 0.445754, acc.: 87.50%] [G loss: 0.891272]\n",
      "epoch:11 step:11220 [D loss: 0.700987, acc.: 57.81%] [G loss: 0.920208]\n",
      "epoch:11 step:11221 [D loss: 0.648077, acc.: 64.84%] [G loss: 0.839272]\n",
      "epoch:11 step:11222 [D loss: 0.849570, acc.: 35.16%] [G loss: 0.899736]\n",
      "epoch:11 step:11223 [D loss: 0.609722, acc.: 67.19%] [G loss: 0.974455]\n",
      "epoch:11 step:11224 [D loss: 0.551634, acc.: 72.66%] [G loss: 0.869725]\n",
      "epoch:11 step:11225 [D loss: 0.549506, acc.: 80.47%] [G loss: 0.943692]\n",
      "epoch:11 step:11226 [D loss: 0.600607, acc.: 69.53%] [G loss: 0.863677]\n",
      "epoch:11 step:11227 [D loss: 0.421962, acc.: 83.59%] [G loss: 1.027543]\n",
      "epoch:11 step:11228 [D loss: 0.590479, acc.: 72.66%] [G loss: 0.322734]\n",
      "epoch:11 step:11229 [D loss: 0.568221, acc.: 81.25%] [G loss: 0.958847]\n",
      "epoch:11 step:11230 [D loss: 0.576208, acc.: 67.97%] [G loss: 0.934545]\n",
      "epoch:11 step:11231 [D loss: 0.511452, acc.: 74.22%] [G loss: 0.909158]\n",
      "epoch:11 step:11232 [D loss: 0.487711, acc.: 77.34%] [G loss: 0.958504]\n",
      "epoch:11 step:11233 [D loss: 0.470480, acc.: 79.69%] [G loss: 0.856624]\n",
      "epoch:11 step:11234 [D loss: 0.590602, acc.: 71.09%] [G loss: 1.014727]\n",
      "epoch:11 step:11235 [D loss: 0.754736, acc.: 50.00%] [G loss: 1.085030]\n",
      "epoch:11 step:11236 [D loss: 0.257866, acc.: 92.19%] [G loss: 1.072455]\n",
      "epoch:11 step:11237 [D loss: 0.659956, acc.: 57.03%] [G loss: 1.123189]\n",
      "epoch:11 step:11238 [D loss: 0.529255, acc.: 79.69%] [G loss: 1.158095]\n",
      "epoch:11 step:11239 [D loss: 0.618295, acc.: 66.41%] [G loss: 1.007132]\n",
      "epoch:11 step:11240 [D loss: 0.459860, acc.: 81.25%] [G loss: 1.195403]\n",
      "epoch:11 step:11241 [D loss: 0.452369, acc.: 86.72%] [G loss: 1.207720]\n",
      "epoch:11 step:11242 [D loss: 0.403857, acc.: 89.84%] [G loss: 1.112545]\n",
      "epoch:11 step:11243 [D loss: 0.497987, acc.: 69.53%] [G loss: 0.982939]\n",
      "epoch:11 step:11244 [D loss: 0.261221, acc.: 94.53%] [G loss: 1.412450]\n",
      "epoch:12 step:11245 [D loss: 0.664146, acc.: 66.41%] [G loss: 0.562650]\n",
      "epoch:12 step:11246 [D loss: 0.971714, acc.: 28.12%] [G loss: 0.824441]\n",
      "epoch:12 step:11247 [D loss: 0.822838, acc.: 35.16%] [G loss: 0.679157]\n",
      "epoch:12 step:11248 [D loss: 0.773348, acc.: 43.75%] [G loss: 0.709301]\n",
      "epoch:12 step:11249 [D loss: 0.701923, acc.: 54.69%] [G loss: 0.929831]\n",
      "epoch:12 step:11250 [D loss: 0.713569, acc.: 54.69%] [G loss: 1.112215]\n",
      "epoch:12 step:11251 [D loss: 0.713553, acc.: 52.34%] [G loss: 0.804608]\n",
      "epoch:12 step:11252 [D loss: 0.826232, acc.: 41.41%] [G loss: 0.430889]\n",
      "epoch:12 step:11253 [D loss: 0.771184, acc.: 46.88%] [G loss: 0.760637]\n",
      "epoch:12 step:11254 [D loss: 0.679597, acc.: 56.25%] [G loss: 0.861812]\n",
      "epoch:12 step:11255 [D loss: 0.700335, acc.: 58.59%] [G loss: 0.995489]\n",
      "epoch:12 step:11256 [D loss: 0.752240, acc.: 44.53%] [G loss: 0.925084]\n",
      "epoch:12 step:11257 [D loss: 0.677588, acc.: 56.25%] [G loss: 0.731463]\n",
      "epoch:12 step:11258 [D loss: 0.734951, acc.: 49.22%] [G loss: 0.919471]\n",
      "epoch:12 step:11259 [D loss: 0.687950, acc.: 58.59%] [G loss: 0.757527]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:12 step:11260 [D loss: 0.715127, acc.: 54.69%] [G loss: 1.010924]\n",
      "epoch:12 step:11261 [D loss: 0.859025, acc.: 32.81%] [G loss: 1.079832]\n",
      "epoch:12 step:11262 [D loss: 0.696176, acc.: 51.56%] [G loss: 1.099136]\n",
      "epoch:12 step:11263 [D loss: 0.801607, acc.: 42.97%] [G loss: 1.039485]\n",
      "epoch:12 step:11264 [D loss: 0.751978, acc.: 50.00%] [G loss: 1.006476]\n",
      "epoch:12 step:11265 [D loss: 0.675856, acc.: 61.72%] [G loss: 1.207551]\n",
      "epoch:12 step:11266 [D loss: 0.620761, acc.: 67.19%] [G loss: 1.197483]\n",
      "epoch:12 step:11267 [D loss: 0.694723, acc.: 56.25%] [G loss: 1.136335]\n",
      "epoch:12 step:11268 [D loss: 0.743345, acc.: 47.66%] [G loss: 1.071803]\n",
      "epoch:12 step:11269 [D loss: 0.660888, acc.: 57.03%] [G loss: 1.087828]\n",
      "epoch:12 step:11270 [D loss: 0.642351, acc.: 64.84%] [G loss: 1.141217]\n",
      "epoch:12 step:11271 [D loss: 0.474944, acc.: 81.25%] [G loss: 1.247054]\n",
      "epoch:12 step:11272 [D loss: 0.567719, acc.: 67.97%] [G loss: 1.392817]\n",
      "epoch:12 step:11273 [D loss: 0.582872, acc.: 64.06%] [G loss: 1.067838]\n",
      "epoch:12 step:11274 [D loss: 0.522990, acc.: 74.22%] [G loss: 1.550499]\n",
      "epoch:12 step:11275 [D loss: 0.461524, acc.: 82.03%] [G loss: 1.279211]\n",
      "epoch:12 step:11276 [D loss: 0.552382, acc.: 75.00%] [G loss: 1.121381]\n",
      "epoch:12 step:11277 [D loss: 0.365351, acc.: 88.28%] [G loss: 1.373852]\n",
      "epoch:12 step:11278 [D loss: 0.421816, acc.: 83.59%] [G loss: 1.039991]\n",
      "epoch:12 step:11279 [D loss: 0.235278, acc.: 94.53%] [G loss: 1.434565]\n",
      "epoch:12 step:11280 [D loss: 0.362453, acc.: 79.69%] [G loss: 1.439336]\n",
      "epoch:12 step:11281 [D loss: 0.939998, acc.: 38.28%] [G loss: 1.183142]\n",
      "epoch:12 step:11282 [D loss: 1.268814, acc.: 28.91%] [G loss: 0.832151]\n",
      "epoch:12 step:11283 [D loss: 0.900075, acc.: 35.16%] [G loss: 0.980397]\n",
      "epoch:12 step:11284 [D loss: 0.758226, acc.: 46.09%] [G loss: 1.006226]\n",
      "epoch:12 step:11285 [D loss: 0.782155, acc.: 47.66%] [G loss: 0.998534]\n",
      "epoch:12 step:11286 [D loss: 0.699469, acc.: 56.25%] [G loss: 0.916423]\n",
      "epoch:12 step:11287 [D loss: 0.577979, acc.: 75.00%] [G loss: 0.938332]\n",
      "epoch:12 step:11288 [D loss: 0.644130, acc.: 60.16%] [G loss: 0.846306]\n",
      "epoch:12 step:11289 [D loss: 0.799160, acc.: 37.50%] [G loss: 0.856848]\n",
      "epoch:12 step:11290 [D loss: 0.626285, acc.: 61.72%] [G loss: 0.909787]\n",
      "epoch:12 step:11291 [D loss: 1.435178, acc.: 28.12%] [G loss: 1.081912]\n",
      "epoch:12 step:11292 [D loss: 0.662123, acc.: 59.38%] [G loss: 1.281850]\n",
      "epoch:12 step:11293 [D loss: 0.573940, acc.: 71.09%] [G loss: 1.562219]\n",
      "epoch:12 step:11294 [D loss: 0.636271, acc.: 65.62%] [G loss: 1.042467]\n",
      "epoch:12 step:11295 [D loss: 0.668891, acc.: 62.50%] [G loss: 1.074479]\n",
      "epoch:12 step:11296 [D loss: 0.679682, acc.: 60.16%] [G loss: 0.928494]\n",
      "epoch:12 step:11297 [D loss: 0.618847, acc.: 69.53%] [G loss: 1.050865]\n",
      "epoch:12 step:11298 [D loss: 0.639655, acc.: 61.72%] [G loss: 0.953525]\n",
      "epoch:12 step:11299 [D loss: 0.615526, acc.: 68.75%] [G loss: 0.913373]\n",
      "epoch:12 step:11300 [D loss: 0.648133, acc.: 68.75%] [G loss: 0.956451]\n",
      "epoch:12 step:11301 [D loss: 0.672954, acc.: 64.84%] [G loss: 0.873102]\n",
      "epoch:12 step:11302 [D loss: 0.714268, acc.: 49.22%] [G loss: 0.971868]\n",
      "epoch:12 step:11303 [D loss: 0.692493, acc.: 53.91%] [G loss: 0.903578]\n",
      "epoch:12 step:11304 [D loss: 0.680070, acc.: 55.47%] [G loss: 0.832613]\n",
      "epoch:12 step:11305 [D loss: 0.632318, acc.: 65.62%] [G loss: 0.877887]\n",
      "epoch:12 step:11306 [D loss: 0.597231, acc.: 72.66%] [G loss: 0.934825]\n",
      "epoch:12 step:11307 [D loss: 0.631136, acc.: 66.41%] [G loss: 0.905811]\n",
      "epoch:12 step:11308 [D loss: 0.573301, acc.: 76.56%] [G loss: 0.812518]\n",
      "epoch:12 step:11309 [D loss: 0.535019, acc.: 78.91%] [G loss: 1.053885]\n",
      "epoch:12 step:11310 [D loss: 0.611221, acc.: 68.75%] [G loss: 1.180887]\n",
      "epoch:12 step:11311 [D loss: 0.597908, acc.: 64.06%] [G loss: 0.896948]\n",
      "epoch:12 step:11312 [D loss: 0.544924, acc.: 77.34%] [G loss: 0.943694]\n",
      "epoch:12 step:11313 [D loss: 0.570790, acc.: 67.97%] [G loss: 0.741624]\n",
      "epoch:12 step:11314 [D loss: 0.668018, acc.: 55.47%] [G loss: 0.846008]\n",
      "epoch:12 step:11315 [D loss: 0.758066, acc.: 54.69%] [G loss: 0.697930]\n",
      "epoch:12 step:11316 [D loss: 0.667274, acc.: 60.16%] [G loss: 0.641849]\n",
      "epoch:12 step:11317 [D loss: 0.675354, acc.: 61.72%] [G loss: 0.809562]\n",
      "epoch:12 step:11318 [D loss: 0.746047, acc.: 50.78%] [G loss: 0.832404]\n",
      "epoch:12 step:11319 [D loss: 0.776092, acc.: 44.53%] [G loss: 0.782726]\n",
      "epoch:12 step:11320 [D loss: 0.607643, acc.: 58.59%] [G loss: 0.879423]\n",
      "epoch:12 step:11321 [D loss: 0.584042, acc.: 67.97%] [G loss: 0.899884]\n",
      "epoch:12 step:11322 [D loss: 0.755470, acc.: 49.22%] [G loss: 0.965835]\n",
      "epoch:12 step:11323 [D loss: 0.735733, acc.: 48.44%] [G loss: 0.833706]\n",
      "epoch:12 step:11324 [D loss: 0.698158, acc.: 57.03%] [G loss: 0.833275]\n",
      "epoch:12 step:11325 [D loss: 0.679524, acc.: 54.69%] [G loss: 0.781679]\n",
      "epoch:12 step:11326 [D loss: 0.649184, acc.: 60.16%] [G loss: 0.766481]\n",
      "epoch:12 step:11327 [D loss: 0.652718, acc.: 64.06%] [G loss: 0.855635]\n",
      "epoch:12 step:11328 [D loss: 0.691853, acc.: 51.56%] [G loss: 0.919795]\n",
      "epoch:12 step:11329 [D loss: 0.636305, acc.: 62.50%] [G loss: 0.795154]\n",
      "epoch:12 step:11330 [D loss: 0.636566, acc.: 64.84%] [G loss: 0.835352]\n",
      "epoch:12 step:11331 [D loss: 0.653330, acc.: 63.28%] [G loss: 0.832020]\n",
      "epoch:12 step:11332 [D loss: 0.643416, acc.: 67.19%] [G loss: 0.788603]\n",
      "epoch:12 step:11333 [D loss: 0.660038, acc.: 59.38%] [G loss: 0.829427]\n",
      "epoch:12 step:11334 [D loss: 0.730257, acc.: 46.09%] [G loss: 0.830530]\n",
      "epoch:12 step:11335 [D loss: 0.673419, acc.: 59.38%] [G loss: 0.748183]\n",
      "epoch:12 step:11336 [D loss: 0.624841, acc.: 69.53%] [G loss: 0.883799]\n",
      "epoch:12 step:11337 [D loss: 0.683348, acc.: 57.81%] [G loss: 0.879056]\n",
      "epoch:12 step:11338 [D loss: 0.694519, acc.: 57.03%] [G loss: 0.843660]\n",
      "epoch:12 step:11339 [D loss: 0.665956, acc.: 58.59%] [G loss: 0.875651]\n",
      "epoch:12 step:11340 [D loss: 0.669945, acc.: 52.34%] [G loss: 0.851760]\n",
      "epoch:12 step:11341 [D loss: 0.615220, acc.: 64.84%] [G loss: 0.877293]\n",
      "epoch:12 step:11342 [D loss: 0.684164, acc.: 54.69%] [G loss: 0.885661]\n",
      "epoch:12 step:11343 [D loss: 0.723267, acc.: 47.66%] [G loss: 0.795924]\n",
      "epoch:12 step:11344 [D loss: 0.626186, acc.: 65.62%] [G loss: 0.793689]\n",
      "epoch:12 step:11345 [D loss: 0.678837, acc.: 54.69%] [G loss: 0.855818]\n",
      "epoch:12 step:11346 [D loss: 0.754668, acc.: 46.09%] [G loss: 0.837151]\n",
      "epoch:12 step:11347 [D loss: 0.688026, acc.: 57.81%] [G loss: 0.840405]\n",
      "epoch:12 step:11348 [D loss: 0.599043, acc.: 67.19%] [G loss: 0.844424]\n",
      "epoch:12 step:11349 [D loss: 0.558240, acc.: 74.22%] [G loss: 0.920104]\n",
      "epoch:12 step:11350 [D loss: 0.625257, acc.: 67.97%] [G loss: 0.934086]\n",
      "epoch:12 step:11351 [D loss: 0.521709, acc.: 80.47%] [G loss: 0.973748]\n",
      "epoch:12 step:11352 [D loss: 0.609291, acc.: 69.53%] [G loss: 0.926149]\n",
      "epoch:12 step:11353 [D loss: 0.626377, acc.: 67.97%] [G loss: 0.881487]\n",
      "epoch:12 step:11354 [D loss: 0.669408, acc.: 60.16%] [G loss: 0.925197]\n",
      "epoch:12 step:11355 [D loss: 0.687182, acc.: 58.59%] [G loss: 0.885011]\n",
      "epoch:12 step:11356 [D loss: 0.624575, acc.: 64.84%] [G loss: 0.889137]\n",
      "epoch:12 step:11357 [D loss: 0.646574, acc.: 62.50%] [G loss: 0.920082]\n",
      "epoch:12 step:11358 [D loss: 0.651456, acc.: 61.72%] [G loss: 0.941606]\n",
      "epoch:12 step:11359 [D loss: 0.714587, acc.: 51.56%] [G loss: 0.919472]\n",
      "epoch:12 step:11360 [D loss: 0.735265, acc.: 55.47%] [G loss: 0.712427]\n",
      "epoch:12 step:11361 [D loss: 0.713732, acc.: 56.25%] [G loss: 0.749478]\n",
      "epoch:12 step:11362 [D loss: 0.566632, acc.: 70.31%] [G loss: 0.851468]\n",
      "epoch:12 step:11363 [D loss: 0.432999, acc.: 80.47%] [G loss: 0.933230]\n",
      "epoch:12 step:11364 [D loss: 0.843233, acc.: 37.50%] [G loss: 0.898884]\n",
      "epoch:12 step:11365 [D loss: 0.800062, acc.: 45.31%] [G loss: 0.914623]\n",
      "epoch:12 step:11366 [D loss: 0.754788, acc.: 47.66%] [G loss: 1.044914]\n",
      "epoch:12 step:11367 [D loss: 0.699228, acc.: 51.56%] [G loss: 0.996371]\n",
      "epoch:12 step:11368 [D loss: 0.585092, acc.: 67.97%] [G loss: 1.011003]\n",
      "epoch:12 step:11369 [D loss: 0.650174, acc.: 57.03%] [G loss: 1.053491]\n",
      "epoch:12 step:11370 [D loss: 0.658137, acc.: 57.03%] [G loss: 1.138659]\n",
      "epoch:12 step:11371 [D loss: 0.656085, acc.: 57.03%] [G loss: 1.125831]\n",
      "epoch:12 step:11372 [D loss: 0.683561, acc.: 55.47%] [G loss: 0.898869]\n",
      "epoch:12 step:11373 [D loss: 0.662717, acc.: 54.69%] [G loss: 1.043225]\n",
      "epoch:12 step:11374 [D loss: 0.579213, acc.: 71.09%] [G loss: 0.975919]\n",
      "epoch:12 step:11375 [D loss: 0.605341, acc.: 71.88%] [G loss: 1.026098]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:12 step:11376 [D loss: 0.614240, acc.: 67.19%] [G loss: 0.954413]\n",
      "epoch:12 step:11377 [D loss: 0.617324, acc.: 64.84%] [G loss: 1.090010]\n",
      "epoch:12 step:11378 [D loss: 0.569894, acc.: 70.31%] [G loss: 0.944149]\n",
      "epoch:12 step:11379 [D loss: 0.651667, acc.: 64.84%] [G loss: 0.798209]\n",
      "epoch:12 step:11380 [D loss: 0.637666, acc.: 61.72%] [G loss: 0.885263]\n",
      "epoch:12 step:11381 [D loss: 0.742626, acc.: 53.12%] [G loss: 0.761592]\n",
      "epoch:12 step:11382 [D loss: 0.680047, acc.: 53.12%] [G loss: 0.833832]\n",
      "epoch:12 step:11383 [D loss: 0.643243, acc.: 63.28%] [G loss: 0.712327]\n",
      "epoch:12 step:11384 [D loss: 0.583735, acc.: 71.09%] [G loss: 0.799885]\n",
      "epoch:12 step:11385 [D loss: 0.682266, acc.: 58.59%] [G loss: 0.809140]\n",
      "epoch:12 step:11386 [D loss: 0.705820, acc.: 58.59%] [G loss: 0.850391]\n",
      "epoch:12 step:11387 [D loss: 0.435113, acc.: 84.38%] [G loss: 0.987059]\n",
      "epoch:12 step:11388 [D loss: 0.584184, acc.: 78.91%] [G loss: 1.039674]\n",
      "epoch:12 step:11389 [D loss: 0.448250, acc.: 82.81%] [G loss: 1.062214]\n",
      "epoch:12 step:11390 [D loss: 0.566523, acc.: 76.56%] [G loss: 1.104702]\n",
      "epoch:12 step:11391 [D loss: 0.677285, acc.: 61.72%] [G loss: 1.048997]\n",
      "epoch:12 step:11392 [D loss: 0.711933, acc.: 53.12%] [G loss: 0.986182]\n",
      "epoch:12 step:11393 [D loss: 0.394567, acc.: 75.78%] [G loss: 1.057855]\n",
      "epoch:12 step:11394 [D loss: 0.274634, acc.: 89.84%] [G loss: 0.997921]\n",
      "epoch:12 step:11395 [D loss: 0.434284, acc.: 86.72%] [G loss: 1.195855]\n",
      "epoch:12 step:11396 [D loss: 0.568827, acc.: 71.88%] [G loss: 1.021491]\n",
      "epoch:12 step:11397 [D loss: 0.795322, acc.: 39.06%] [G loss: 0.959178]\n",
      "epoch:12 step:11398 [D loss: 0.701136, acc.: 50.78%] [G loss: 0.857908]\n",
      "epoch:12 step:11399 [D loss: 0.626979, acc.: 65.62%] [G loss: 0.984643]\n",
      "epoch:12 step:11400 [D loss: 0.748526, acc.: 48.44%] [G loss: 0.872674]\n",
      "##############\n",
      "[4.30447513 2.59602    6.31968869 5.32859521 4.1856644  6.30745851\n",
      " 5.11993756 5.01779709 5.37437492 4.7545914 ]\n",
      "##########\n",
      "epoch:12 step:11401 [D loss: 0.693911, acc.: 57.81%] [G loss: 0.805353]\n",
      "epoch:12 step:11402 [D loss: 0.752905, acc.: 53.91%] [G loss: 0.787845]\n",
      "epoch:12 step:11403 [D loss: 0.828290, acc.: 36.72%] [G loss: 0.354268]\n",
      "epoch:12 step:11404 [D loss: 0.555999, acc.: 72.66%] [G loss: 0.874971]\n",
      "epoch:12 step:11405 [D loss: 0.696460, acc.: 58.59%] [G loss: 0.921692]\n",
      "epoch:12 step:11406 [D loss: 0.659937, acc.: 58.59%] [G loss: 1.035209]\n",
      "epoch:12 step:11407 [D loss: 0.622524, acc.: 66.41%] [G loss: 0.522484]\n",
      "epoch:12 step:11408 [D loss: 0.552126, acc.: 75.00%] [G loss: 1.063172]\n",
      "epoch:12 step:11409 [D loss: 0.731838, acc.: 54.69%] [G loss: 1.058723]\n",
      "epoch:12 step:11410 [D loss: 1.214293, acc.: 28.12%] [G loss: 0.902618]\n",
      "epoch:12 step:11411 [D loss: 0.696966, acc.: 58.59%] [G loss: 1.080636]\n",
      "epoch:12 step:11412 [D loss: 0.742810, acc.: 55.47%] [G loss: 1.102112]\n",
      "epoch:12 step:11413 [D loss: 0.801843, acc.: 51.56%] [G loss: 1.214876]\n",
      "epoch:12 step:11414 [D loss: 0.669754, acc.: 59.38%] [G loss: 0.968196]\n",
      "epoch:12 step:11415 [D loss: 0.630485, acc.: 62.50%] [G loss: 1.008326]\n",
      "epoch:12 step:11416 [D loss: 0.683534, acc.: 60.94%] [G loss: 0.986402]\n",
      "epoch:12 step:11417 [D loss: 0.631477, acc.: 65.62%] [G loss: 0.970479]\n",
      "epoch:12 step:11418 [D loss: 0.717550, acc.: 50.78%] [G loss: 0.999674]\n",
      "epoch:12 step:11419 [D loss: 0.714110, acc.: 56.25%] [G loss: 0.955341]\n",
      "epoch:12 step:11420 [D loss: 0.552302, acc.: 77.34%] [G loss: 0.914045]\n",
      "epoch:12 step:11421 [D loss: 0.659340, acc.: 57.03%] [G loss: 1.007483]\n",
      "epoch:12 step:11422 [D loss: 0.723262, acc.: 46.88%] [G loss: 0.862739]\n",
      "epoch:12 step:11423 [D loss: 0.708382, acc.: 55.47%] [G loss: 0.759688]\n",
      "epoch:12 step:11424 [D loss: 0.690464, acc.: 51.56%] [G loss: 0.801962]\n",
      "epoch:12 step:11425 [D loss: 0.614402, acc.: 68.75%] [G loss: 0.878265]\n",
      "epoch:12 step:11426 [D loss: 0.594702, acc.: 71.88%] [G loss: 0.804562]\n",
      "epoch:12 step:11427 [D loss: 0.652383, acc.: 57.81%] [G loss: 0.833731]\n",
      "epoch:12 step:11428 [D loss: 0.594125, acc.: 73.44%] [G loss: 0.816182]\n",
      "epoch:12 step:11429 [D loss: 0.652126, acc.: 59.38%] [G loss: 0.857841]\n",
      "epoch:12 step:11430 [D loss: 0.753641, acc.: 46.09%] [G loss: 0.776846]\n",
      "epoch:12 step:11431 [D loss: 0.606410, acc.: 69.53%] [G loss: 0.820666]\n",
      "epoch:12 step:11432 [D loss: 0.641404, acc.: 57.81%] [G loss: 0.816722]\n",
      "epoch:12 step:11433 [D loss: 0.695125, acc.: 53.12%] [G loss: 0.676114]\n",
      "epoch:12 step:11434 [D loss: 0.627024, acc.: 68.75%] [G loss: 0.872930]\n",
      "epoch:12 step:11435 [D loss: 0.648656, acc.: 61.72%] [G loss: 0.831593]\n",
      "epoch:12 step:11436 [D loss: 0.555088, acc.: 76.56%] [G loss: 0.711866]\n",
      "epoch:12 step:11437 [D loss: 0.720418, acc.: 56.25%] [G loss: 0.875664]\n",
      "epoch:12 step:11438 [D loss: 0.559085, acc.: 75.00%] [G loss: 0.724445]\n",
      "epoch:12 step:11439 [D loss: 0.666832, acc.: 54.69%] [G loss: 0.769405]\n",
      "epoch:12 step:11440 [D loss: 0.746961, acc.: 46.09%] [G loss: 0.813584]\n",
      "epoch:12 step:11441 [D loss: 0.639082, acc.: 62.50%] [G loss: 0.843645]\n",
      "epoch:12 step:11442 [D loss: 0.608550, acc.: 67.97%] [G loss: 0.920079]\n",
      "epoch:12 step:11443 [D loss: 0.702287, acc.: 50.00%] [G loss: 0.789348]\n",
      "epoch:12 step:11444 [D loss: 0.732113, acc.: 54.69%] [G loss: 0.873653]\n",
      "epoch:12 step:11445 [D loss: 0.663260, acc.: 60.16%] [G loss: 1.015171]\n",
      "epoch:12 step:11446 [D loss: 0.698697, acc.: 50.78%] [G loss: 1.011928]\n",
      "epoch:12 step:11447 [D loss: 0.632269, acc.: 67.97%] [G loss: 0.902852]\n",
      "epoch:12 step:11448 [D loss: 0.592950, acc.: 70.31%] [G loss: 0.811042]\n",
      "epoch:12 step:11449 [D loss: 0.612824, acc.: 70.31%] [G loss: 0.873324]\n",
      "epoch:12 step:11450 [D loss: 0.584614, acc.: 71.88%] [G loss: 0.843031]\n",
      "epoch:12 step:11451 [D loss: 0.651695, acc.: 67.97%] [G loss: 0.899854]\n",
      "epoch:12 step:11452 [D loss: 0.585956, acc.: 71.88%] [G loss: 0.891472]\n",
      "epoch:12 step:11453 [D loss: 0.600652, acc.: 69.53%] [G loss: 0.831151]\n",
      "epoch:12 step:11454 [D loss: 0.723284, acc.: 55.47%] [G loss: 0.960642]\n",
      "epoch:12 step:11455 [D loss: 0.766274, acc.: 50.00%] [G loss: 0.934297]\n",
      "epoch:12 step:11456 [D loss: 0.674831, acc.: 62.50%] [G loss: 0.868167]\n",
      "epoch:12 step:11457 [D loss: 0.712939, acc.: 48.44%] [G loss: 0.837913]\n",
      "epoch:12 step:11458 [D loss: 0.807361, acc.: 42.97%] [G loss: 0.963812]\n",
      "epoch:12 step:11459 [D loss: 0.691317, acc.: 59.38%] [G loss: 0.863643]\n",
      "epoch:12 step:11460 [D loss: 0.744746, acc.: 46.09%] [G loss: 0.836286]\n",
      "epoch:12 step:11461 [D loss: 0.722867, acc.: 46.09%] [G loss: 0.773262]\n",
      "epoch:12 step:11462 [D loss: 0.649742, acc.: 62.50%] [G loss: 0.791718]\n",
      "epoch:12 step:11463 [D loss: 0.601753, acc.: 67.97%] [G loss: 0.807106]\n",
      "epoch:12 step:11464 [D loss: 0.419486, acc.: 71.09%] [G loss: 0.861567]\n",
      "epoch:12 step:11465 [D loss: 0.357041, acc.: 82.03%] [G loss: 0.991439]\n",
      "epoch:12 step:11466 [D loss: 0.601824, acc.: 64.84%] [G loss: 1.033357]\n",
      "epoch:12 step:11467 [D loss: 0.619775, acc.: 68.75%] [G loss: 1.007179]\n",
      "epoch:12 step:11468 [D loss: 0.685110, acc.: 59.38%] [G loss: 0.940802]\n",
      "epoch:12 step:11469 [D loss: 0.658516, acc.: 63.28%] [G loss: 0.869645]\n",
      "epoch:12 step:11470 [D loss: 0.638773, acc.: 64.84%] [G loss: 0.894839]\n",
      "epoch:12 step:11471 [D loss: 0.608310, acc.: 71.09%] [G loss: 0.865183]\n",
      "epoch:12 step:11472 [D loss: 0.651464, acc.: 65.62%] [G loss: 0.958538]\n",
      "epoch:12 step:11473 [D loss: 0.672786, acc.: 57.03%] [G loss: 0.913602]\n",
      "epoch:12 step:11474 [D loss: 0.288116, acc.: 90.62%] [G loss: 0.989090]\n",
      "epoch:12 step:11475 [D loss: 0.390899, acc.: 83.59%] [G loss: 1.149045]\n",
      "epoch:12 step:11476 [D loss: 0.274883, acc.: 89.84%] [G loss: 1.078272]\n",
      "epoch:12 step:11477 [D loss: 0.670849, acc.: 66.41%] [G loss: 1.148788]\n",
      "epoch:12 step:11478 [D loss: 0.485901, acc.: 85.94%] [G loss: 1.050309]\n",
      "epoch:12 step:11479 [D loss: 0.442597, acc.: 90.62%] [G loss: 1.071476]\n",
      "epoch:12 step:11480 [D loss: 0.632569, acc.: 65.62%] [G loss: 0.996913]\n",
      "epoch:12 step:11481 [D loss: 0.352150, acc.: 93.75%] [G loss: 0.763788]\n",
      "epoch:12 step:11482 [D loss: 0.352884, acc.: 90.62%] [G loss: 0.955969]\n",
      "epoch:12 step:11483 [D loss: 0.686818, acc.: 58.59%] [G loss: 1.142529]\n",
      "epoch:12 step:11484 [D loss: 0.693680, acc.: 55.47%] [G loss: 0.638247]\n",
      "epoch:12 step:11485 [D loss: 0.877085, acc.: 37.50%] [G loss: 0.279504]\n",
      "epoch:12 step:11486 [D loss: 0.653604, acc.: 58.59%] [G loss: 0.966175]\n",
      "epoch:12 step:11487 [D loss: 0.623073, acc.: 66.41%] [G loss: 0.837418]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:12 step:11488 [D loss: 0.723199, acc.: 44.53%] [G loss: 0.643625]\n",
      "epoch:12 step:11489 [D loss: 0.974123, acc.: 22.66%] [G loss: 0.697900]\n",
      "epoch:12 step:11490 [D loss: 0.739886, acc.: 48.44%] [G loss: 0.870786]\n",
      "epoch:12 step:11491 [D loss: 0.826618, acc.: 35.16%] [G loss: 1.024503]\n",
      "epoch:12 step:11492 [D loss: 0.987800, acc.: 25.00%] [G loss: 0.767246]\n",
      "epoch:12 step:11493 [D loss: 0.633078, acc.: 65.62%] [G loss: 1.042742]\n",
      "epoch:12 step:11494 [D loss: 0.733794, acc.: 54.69%] [G loss: 0.985071]\n",
      "epoch:12 step:11495 [D loss: 0.586082, acc.: 73.44%] [G loss: 0.900247]\n",
      "epoch:12 step:11496 [D loss: 0.689904, acc.: 54.69%] [G loss: 0.920148]\n",
      "epoch:12 step:11497 [D loss: 0.667217, acc.: 56.25%] [G loss: 0.989798]\n",
      "epoch:12 step:11498 [D loss: 0.609992, acc.: 67.97%] [G loss: 0.910916]\n",
      "epoch:12 step:11499 [D loss: 0.571159, acc.: 67.97%] [G loss: 0.555804]\n",
      "epoch:12 step:11500 [D loss: 0.306791, acc.: 87.50%] [G loss: 0.575150]\n",
      "epoch:12 step:11501 [D loss: 0.643273, acc.: 60.94%] [G loss: 0.761270]\n",
      "epoch:12 step:11502 [D loss: 0.852469, acc.: 35.16%] [G loss: 1.014277]\n",
      "epoch:12 step:11503 [D loss: 0.415055, acc.: 73.44%] [G loss: 1.047837]\n",
      "epoch:12 step:11504 [D loss: 0.514474, acc.: 69.53%] [G loss: 0.848392]\n",
      "epoch:12 step:11505 [D loss: 0.419727, acc.: 91.41%] [G loss: 1.224295]\n",
      "epoch:12 step:11506 [D loss: 0.669609, acc.: 62.50%] [G loss: 1.069763]\n",
      "epoch:12 step:11507 [D loss: 0.745885, acc.: 50.00%] [G loss: 1.150787]\n",
      "epoch:12 step:11508 [D loss: 0.732014, acc.: 47.66%] [G loss: 1.022428]\n",
      "epoch:12 step:11509 [D loss: 0.365670, acc.: 89.84%] [G loss: 0.888300]\n",
      "epoch:12 step:11510 [D loss: 0.693067, acc.: 50.00%] [G loss: 0.223435]\n",
      "epoch:12 step:11511 [D loss: 1.073267, acc.: 11.72%] [G loss: 0.878050]\n",
      "epoch:12 step:11512 [D loss: 0.693677, acc.: 54.69%] [G loss: 1.071491]\n",
      "epoch:12 step:11513 [D loss: 0.619990, acc.: 62.50%] [G loss: 1.110781]\n",
      "epoch:12 step:11514 [D loss: 0.619470, acc.: 61.72%] [G loss: 0.504221]\n",
      "epoch:12 step:11515 [D loss: 0.584559, acc.: 71.09%] [G loss: 0.764429]\n",
      "epoch:12 step:11516 [D loss: 0.839233, acc.: 44.53%] [G loss: 1.219280]\n",
      "epoch:12 step:11517 [D loss: 0.732971, acc.: 51.56%] [G loss: 1.266156]\n",
      "epoch:12 step:11518 [D loss: 0.480835, acc.: 74.22%] [G loss: 1.971835]\n",
      "epoch:12 step:11519 [D loss: 0.522081, acc.: 72.66%] [G loss: 1.896471]\n",
      "epoch:12 step:11520 [D loss: 0.506299, acc.: 78.91%] [G loss: 0.936315]\n",
      "epoch:12 step:11521 [D loss: 0.623086, acc.: 62.50%] [G loss: 0.902439]\n",
      "epoch:12 step:11522 [D loss: 1.105551, acc.: 23.44%] [G loss: 1.099479]\n",
      "epoch:12 step:11523 [D loss: 0.879987, acc.: 36.72%] [G loss: 0.872724]\n",
      "epoch:12 step:11524 [D loss: 0.667579, acc.: 60.94%] [G loss: 0.856602]\n",
      "epoch:12 step:11525 [D loss: 0.678262, acc.: 57.03%] [G loss: 0.812189]\n",
      "epoch:12 step:11526 [D loss: 0.657564, acc.: 61.72%] [G loss: 0.724243]\n",
      "epoch:12 step:11527 [D loss: 0.670210, acc.: 56.25%] [G loss: 0.764434]\n",
      "epoch:12 step:11528 [D loss: 0.713969, acc.: 58.59%] [G loss: 0.871440]\n",
      "epoch:12 step:11529 [D loss: 0.727765, acc.: 46.88%] [G loss: 0.824970]\n",
      "epoch:12 step:11530 [D loss: 0.753898, acc.: 41.41%] [G loss: 0.861920]\n",
      "epoch:12 step:11531 [D loss: 0.728283, acc.: 50.00%] [G loss: 0.886324]\n",
      "epoch:12 step:11532 [D loss: 0.644464, acc.: 60.94%] [G loss: 0.862679]\n",
      "epoch:12 step:11533 [D loss: 0.636302, acc.: 64.84%] [G loss: 0.867866]\n",
      "epoch:12 step:11534 [D loss: 0.572763, acc.: 74.22%] [G loss: 0.909514]\n",
      "epoch:12 step:11535 [D loss: 0.671056, acc.: 60.16%] [G loss: 0.898191]\n",
      "epoch:12 step:11536 [D loss: 0.539382, acc.: 71.09%] [G loss: 0.880669]\n",
      "epoch:12 step:11537 [D loss: 0.593946, acc.: 67.97%] [G loss: 0.840455]\n",
      "epoch:12 step:11538 [D loss: 0.711403, acc.: 50.00%] [G loss: 0.658427]\n",
      "epoch:12 step:11539 [D loss: 0.984496, acc.: 28.91%] [G loss: 0.869413]\n",
      "epoch:12 step:11540 [D loss: 0.700158, acc.: 57.03%] [G loss: 0.846541]\n",
      "epoch:12 step:11541 [D loss: 0.680825, acc.: 57.81%] [G loss: 0.875386]\n",
      "epoch:12 step:11542 [D loss: 0.678985, acc.: 59.38%] [G loss: 0.798556]\n",
      "epoch:12 step:11543 [D loss: 0.665563, acc.: 56.25%] [G loss: 0.846948]\n",
      "epoch:12 step:11544 [D loss: 0.649177, acc.: 62.50%] [G loss: 0.805074]\n",
      "epoch:12 step:11545 [D loss: 0.677908, acc.: 57.03%] [G loss: 0.811889]\n",
      "epoch:12 step:11546 [D loss: 0.691057, acc.: 57.03%] [G loss: 0.808264]\n",
      "epoch:12 step:11547 [D loss: 0.680002, acc.: 53.91%] [G loss: 0.769793]\n",
      "epoch:12 step:11548 [D loss: 0.742240, acc.: 42.97%] [G loss: 0.833051]\n",
      "epoch:12 step:11549 [D loss: 0.719622, acc.: 46.09%] [G loss: 0.783275]\n",
      "epoch:12 step:11550 [D loss: 0.649498, acc.: 61.72%] [G loss: 0.772864]\n",
      "epoch:12 step:11551 [D loss: 0.622847, acc.: 71.09%] [G loss: 0.747014]\n",
      "epoch:12 step:11552 [D loss: 0.711285, acc.: 48.44%] [G loss: 0.852670]\n",
      "epoch:12 step:11553 [D loss: 0.649199, acc.: 67.19%] [G loss: 0.816213]\n",
      "epoch:12 step:11554 [D loss: 0.641440, acc.: 69.53%] [G loss: 0.798308]\n",
      "epoch:12 step:11555 [D loss: 0.663846, acc.: 53.91%] [G loss: 0.781460]\n",
      "epoch:12 step:11556 [D loss: 0.528024, acc.: 77.34%] [G loss: 0.758901]\n",
      "epoch:12 step:11557 [D loss: 0.444645, acc.: 83.59%] [G loss: 0.955822]\n",
      "epoch:12 step:11558 [D loss: 0.394726, acc.: 82.03%] [G loss: 0.750539]\n",
      "epoch:12 step:11559 [D loss: 0.765109, acc.: 56.25%] [G loss: 0.975878]\n",
      "epoch:12 step:11560 [D loss: 0.704384, acc.: 53.12%] [G loss: 0.924437]\n",
      "epoch:12 step:11561 [D loss: 0.675604, acc.: 59.38%] [G loss: 0.923998]\n",
      "epoch:12 step:11562 [D loss: 0.658234, acc.: 62.50%] [G loss: 0.818034]\n",
      "epoch:12 step:11563 [D loss: 0.676412, acc.: 53.91%] [G loss: 0.845575]\n",
      "epoch:12 step:11564 [D loss: 0.692527, acc.: 55.47%] [G loss: 0.890433]\n",
      "epoch:12 step:11565 [D loss: 0.691325, acc.: 56.25%] [G loss: 0.746196]\n",
      "epoch:12 step:11566 [D loss: 0.721109, acc.: 44.53%] [G loss: 0.933514]\n",
      "epoch:12 step:11567 [D loss: 0.709801, acc.: 53.91%] [G loss: 0.874141]\n",
      "epoch:12 step:11568 [D loss: 0.709658, acc.: 48.44%] [G loss: 0.820179]\n",
      "epoch:12 step:11569 [D loss: 0.705007, acc.: 50.00%] [G loss: 0.830272]\n",
      "epoch:12 step:11570 [D loss: 0.672628, acc.: 54.69%] [G loss: 0.835268]\n",
      "epoch:12 step:11571 [D loss: 0.570916, acc.: 82.03%] [G loss: 0.784120]\n",
      "epoch:12 step:11572 [D loss: 0.589952, acc.: 73.44%] [G loss: 0.879756]\n",
      "epoch:12 step:11573 [D loss: 0.708023, acc.: 56.25%] [G loss: 0.868724]\n",
      "epoch:12 step:11574 [D loss: 0.698968, acc.: 56.25%] [G loss: 0.875292]\n",
      "epoch:12 step:11575 [D loss: 0.698031, acc.: 52.34%] [G loss: 0.831305]\n",
      "epoch:12 step:11576 [D loss: 0.655582, acc.: 60.94%] [G loss: 0.787898]\n",
      "epoch:12 step:11577 [D loss: 0.600757, acc.: 68.75%] [G loss: 0.914061]\n",
      "epoch:12 step:11578 [D loss: 0.436492, acc.: 87.50%] [G loss: 0.901418]\n",
      "epoch:12 step:11579 [D loss: 0.719813, acc.: 49.22%] [G loss: 0.879421]\n",
      "epoch:12 step:11580 [D loss: 0.430711, acc.: 80.47%] [G loss: 0.971556]\n",
      "epoch:12 step:11581 [D loss: 0.579845, acc.: 72.66%] [G loss: 0.924743]\n",
      "epoch:12 step:11582 [D loss: 0.614824, acc.: 74.22%] [G loss: 0.580408]\n",
      "epoch:12 step:11583 [D loss: 0.625791, acc.: 68.75%] [G loss: 0.851549]\n",
      "epoch:12 step:11584 [D loss: 0.706784, acc.: 42.97%] [G loss: 0.771494]\n",
      "epoch:12 step:11585 [D loss: 0.772191, acc.: 38.28%] [G loss: 0.900946]\n",
      "epoch:12 step:11586 [D loss: 0.541966, acc.: 75.00%] [G loss: 0.810250]\n",
      "epoch:12 step:11587 [D loss: 0.362576, acc.: 86.72%] [G loss: 0.634248]\n",
      "epoch:12 step:11588 [D loss: 0.476284, acc.: 84.38%] [G loss: 0.810437]\n",
      "epoch:12 step:11589 [D loss: 0.572297, acc.: 64.06%] [G loss: 1.020267]\n",
      "epoch:12 step:11590 [D loss: 0.307957, acc.: 89.84%] [G loss: 1.183241]\n",
      "epoch:12 step:11591 [D loss: 0.330770, acc.: 91.41%] [G loss: 0.418341]\n",
      "epoch:12 step:11592 [D loss: 0.753100, acc.: 46.09%] [G loss: 1.211205]\n",
      "epoch:12 step:11593 [D loss: 0.732697, acc.: 50.78%] [G loss: 1.065147]\n",
      "epoch:12 step:11594 [D loss: 0.587805, acc.: 71.09%] [G loss: 0.623284]\n",
      "epoch:12 step:11595 [D loss: 0.712571, acc.: 56.25%] [G loss: 0.815612]\n",
      "epoch:12 step:11596 [D loss: 0.682254, acc.: 52.34%] [G loss: 0.796138]\n",
      "epoch:12 step:11597 [D loss: 0.607978, acc.: 65.62%] [G loss: 1.029003]\n",
      "epoch:12 step:11598 [D loss: 0.583506, acc.: 69.53%] [G loss: 0.471009]\n",
      "epoch:12 step:11599 [D loss: 0.593258, acc.: 68.75%] [G loss: 1.139951]\n",
      "epoch:12 step:11600 [D loss: 0.737279, acc.: 46.88%] [G loss: 0.609150]\n",
      "##############\n",
      "[4.17220682 2.32620955 6.30243828 5.78546372 4.23788979 5.99959953\n",
      " 5.24241649 5.2165103  5.43652932 4.91198979]\n",
      "##########\n",
      "epoch:12 step:11601 [D loss: 0.525512, acc.: 75.78%] [G loss: 0.781114]\n",
      "epoch:12 step:11602 [D loss: 0.506195, acc.: 78.12%] [G loss: 1.209698]\n",
      "epoch:12 step:11603 [D loss: 0.542615, acc.: 75.00%] [G loss: 1.251780]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:12 step:11604 [D loss: 0.608180, acc.: 58.59%] [G loss: 1.260240]\n",
      "epoch:12 step:11605 [D loss: 0.967082, acc.: 44.53%] [G loss: 1.113809]\n",
      "epoch:12 step:11606 [D loss: 0.733377, acc.: 53.12%] [G loss: 1.218563]\n",
      "epoch:12 step:11607 [D loss: 0.743125, acc.: 43.75%] [G loss: 1.137932]\n",
      "epoch:12 step:11608 [D loss: 0.642968, acc.: 60.16%] [G loss: 1.164427]\n",
      "epoch:12 step:11609 [D loss: 0.986936, acc.: 39.84%] [G loss: 0.904501]\n",
      "epoch:12 step:11610 [D loss: 0.840505, acc.: 53.12%] [G loss: 0.875935]\n",
      "epoch:12 step:11611 [D loss: 0.827716, acc.: 37.50%] [G loss: 0.858202]\n",
      "epoch:12 step:11612 [D loss: 0.724918, acc.: 42.97%] [G loss: 0.766720]\n",
      "epoch:12 step:11613 [D loss: 0.668541, acc.: 57.03%] [G loss: 0.832581]\n",
      "epoch:12 step:11614 [D loss: 0.539100, acc.: 82.81%] [G loss: 0.983687]\n",
      "epoch:12 step:11615 [D loss: 0.550452, acc.: 73.44%] [G loss: 0.990539]\n",
      "epoch:12 step:11616 [D loss: 0.587225, acc.: 66.41%] [G loss: 0.973191]\n",
      "epoch:12 step:11617 [D loss: 0.711352, acc.: 48.44%] [G loss: 1.045638]\n",
      "epoch:12 step:11618 [D loss: 0.560174, acc.: 76.56%] [G loss: 0.961697]\n",
      "epoch:12 step:11619 [D loss: 0.648961, acc.: 64.84%] [G loss: 0.982977]\n",
      "epoch:12 step:11620 [D loss: 0.639903, acc.: 58.59%] [G loss: 0.875083]\n",
      "epoch:12 step:11621 [D loss: 0.605390, acc.: 68.75%] [G loss: 0.934743]\n",
      "epoch:12 step:11622 [D loss: 0.620146, acc.: 69.53%] [G loss: 0.871367]\n",
      "epoch:12 step:11623 [D loss: 0.603503, acc.: 65.62%] [G loss: 0.816316]\n",
      "epoch:12 step:11624 [D loss: 0.578383, acc.: 68.75%] [G loss: 0.920233]\n",
      "epoch:12 step:11625 [D loss: 0.596084, acc.: 64.84%] [G loss: 0.972060]\n",
      "epoch:12 step:11626 [D loss: 0.662413, acc.: 57.81%] [G loss: 1.053628]\n",
      "epoch:12 step:11627 [D loss: 0.690122, acc.: 60.94%] [G loss: 0.909005]\n",
      "epoch:12 step:11628 [D loss: 0.699040, acc.: 60.94%] [G loss: 0.916063]\n",
      "epoch:12 step:11629 [D loss: 0.699550, acc.: 54.69%] [G loss: 0.805486]\n",
      "epoch:12 step:11630 [D loss: 0.664777, acc.: 59.38%] [G loss: 0.917260]\n",
      "epoch:12 step:11631 [D loss: 0.637037, acc.: 64.06%] [G loss: 0.935072]\n",
      "epoch:12 step:11632 [D loss: 0.618116, acc.: 71.88%] [G loss: 0.878304]\n",
      "epoch:12 step:11633 [D loss: 0.684880, acc.: 56.25%] [G loss: 0.855172]\n",
      "epoch:12 step:11634 [D loss: 0.696580, acc.: 54.69%] [G loss: 0.889266]\n",
      "epoch:12 step:11635 [D loss: 0.677333, acc.: 57.81%] [G loss: 0.952647]\n",
      "epoch:12 step:11636 [D loss: 0.646779, acc.: 60.16%] [G loss: 0.967622]\n",
      "epoch:12 step:11637 [D loss: 0.756034, acc.: 49.22%] [G loss: 0.903681]\n",
      "epoch:12 step:11638 [D loss: 0.695802, acc.: 53.91%] [G loss: 0.966841]\n",
      "epoch:12 step:11639 [D loss: 0.687156, acc.: 53.12%] [G loss: 0.857785]\n",
      "epoch:12 step:11640 [D loss: 0.767396, acc.: 51.56%] [G loss: 0.944609]\n",
      "epoch:12 step:11641 [D loss: 0.466777, acc.: 82.03%] [G loss: 0.930976]\n",
      "epoch:12 step:11642 [D loss: 0.497826, acc.: 82.03%] [G loss: 1.088175]\n",
      "epoch:12 step:11643 [D loss: 0.417304, acc.: 75.00%] [G loss: 1.011327]\n",
      "epoch:12 step:11644 [D loss: 0.697256, acc.: 56.25%] [G loss: 0.946402]\n",
      "epoch:12 step:11645 [D loss: 0.644746, acc.: 61.72%] [G loss: 0.991674]\n",
      "epoch:12 step:11646 [D loss: 0.462312, acc.: 80.47%] [G loss: 0.854857]\n",
      "epoch:12 step:11647 [D loss: 0.673474, acc.: 57.81%] [G loss: 0.895059]\n",
      "epoch:12 step:11648 [D loss: 0.485168, acc.: 82.03%] [G loss: 0.942741]\n",
      "epoch:12 step:11649 [D loss: 0.369371, acc.: 88.28%] [G loss: 1.004940]\n",
      "epoch:12 step:11650 [D loss: 0.349893, acc.: 92.19%] [G loss: 1.035870]\n",
      "epoch:12 step:11651 [D loss: 0.536879, acc.: 62.50%] [G loss: 1.166734]\n",
      "epoch:12 step:11652 [D loss: 0.463926, acc.: 87.50%] [G loss: 1.307172]\n",
      "epoch:12 step:11653 [D loss: 0.383499, acc.: 93.75%] [G loss: 1.214350]\n",
      "epoch:12 step:11654 [D loss: 0.597801, acc.: 74.22%] [G loss: 0.936342]\n",
      "epoch:12 step:11655 [D loss: 1.298080, acc.: 15.62%] [G loss: 1.052661]\n",
      "epoch:12 step:11656 [D loss: 0.684479, acc.: 60.16%] [G loss: 1.384061]\n",
      "epoch:12 step:11657 [D loss: 0.835882, acc.: 41.41%] [G loss: 1.148978]\n",
      "epoch:12 step:11658 [D loss: 0.605063, acc.: 71.09%] [G loss: 0.924578]\n",
      "epoch:12 step:11659 [D loss: 0.651420, acc.: 60.94%] [G loss: 1.023745]\n",
      "epoch:12 step:11660 [D loss: 0.985993, acc.: 44.53%] [G loss: 1.289179]\n",
      "epoch:12 step:11661 [D loss: 0.722282, acc.: 56.25%] [G loss: 1.164238]\n",
      "epoch:12 step:11662 [D loss: 0.645647, acc.: 60.16%] [G loss: 1.107517]\n",
      "epoch:12 step:11663 [D loss: 0.465387, acc.: 79.69%] [G loss: 1.040908]\n",
      "epoch:12 step:11664 [D loss: 0.791507, acc.: 45.31%] [G loss: 0.922515]\n",
      "epoch:12 step:11665 [D loss: 0.957143, acc.: 30.47%] [G loss: 0.976552]\n",
      "epoch:12 step:11666 [D loss: 0.799560, acc.: 45.31%] [G loss: 0.976498]\n",
      "epoch:12 step:11667 [D loss: 0.734442, acc.: 49.22%] [G loss: 1.036400]\n",
      "epoch:12 step:11668 [D loss: 0.539645, acc.: 79.69%] [G loss: 1.078343]\n",
      "epoch:12 step:11669 [D loss: 0.508962, acc.: 76.56%] [G loss: 0.810069]\n",
      "epoch:12 step:11670 [D loss: 0.755023, acc.: 42.97%] [G loss: 0.864954]\n",
      "epoch:12 step:11671 [D loss: 0.656727, acc.: 57.81%] [G loss: 0.836094]\n",
      "epoch:12 step:11672 [D loss: 0.356680, acc.: 92.97%] [G loss: 1.119326]\n",
      "epoch:12 step:11673 [D loss: 0.542653, acc.: 75.00%] [G loss: 1.074713]\n",
      "epoch:12 step:11674 [D loss: 0.355448, acc.: 90.62%] [G loss: 0.862884]\n",
      "epoch:12 step:11675 [D loss: 0.642568, acc.: 67.97%] [G loss: 1.202462]\n",
      "epoch:12 step:11676 [D loss: 0.892980, acc.: 30.47%] [G loss: 0.981780]\n",
      "epoch:12 step:11677 [D loss: 0.844278, acc.: 34.38%] [G loss: 1.198783]\n",
      "epoch:12 step:11678 [D loss: 0.684254, acc.: 57.03%] [G loss: 1.109155]\n",
      "epoch:12 step:11679 [D loss: 0.656306, acc.: 55.47%] [G loss: 1.018812]\n",
      "epoch:12 step:11680 [D loss: 0.606625, acc.: 69.53%] [G loss: 1.128680]\n",
      "epoch:12 step:11681 [D loss: 0.792269, acc.: 48.44%] [G loss: 0.826808]\n",
      "epoch:12 step:11682 [D loss: 0.881804, acc.: 43.75%] [G loss: 0.981899]\n",
      "epoch:12 step:11683 [D loss: 0.764103, acc.: 45.31%] [G loss: 0.987405]\n",
      "epoch:12 step:11684 [D loss: 0.661140, acc.: 59.38%] [G loss: 1.200966]\n",
      "epoch:12 step:11685 [D loss: 0.668510, acc.: 55.47%] [G loss: 1.141288]\n",
      "epoch:12 step:11686 [D loss: 0.633974, acc.: 64.84%] [G loss: 1.225535]\n",
      "epoch:12 step:11687 [D loss: 0.564258, acc.: 69.53%] [G loss: 1.063931]\n",
      "epoch:12 step:11688 [D loss: 0.673858, acc.: 57.03%] [G loss: 1.219168]\n",
      "epoch:12 step:11689 [D loss: 0.690151, acc.: 57.81%] [G loss: 1.020184]\n",
      "epoch:12 step:11690 [D loss: 0.652620, acc.: 58.59%] [G loss: 1.130490]\n",
      "epoch:12 step:11691 [D loss: 0.610324, acc.: 63.28%] [G loss: 0.992069]\n",
      "epoch:12 step:11692 [D loss: 0.557621, acc.: 75.78%] [G loss: 0.816614]\n",
      "epoch:12 step:11693 [D loss: 0.520804, acc.: 82.81%] [G loss: 0.943847]\n",
      "epoch:12 step:11694 [D loss: 0.472299, acc.: 84.38%] [G loss: 0.969096]\n",
      "epoch:12 step:11695 [D loss: 0.433434, acc.: 86.72%] [G loss: 1.511011]\n",
      "epoch:12 step:11696 [D loss: 0.435261, acc.: 89.84%] [G loss: 1.133227]\n",
      "epoch:12 step:11697 [D loss: 0.436852, acc.: 86.72%] [G loss: 1.270361]\n",
      "epoch:12 step:11698 [D loss: 0.505818, acc.: 80.47%] [G loss: 1.136708]\n",
      "epoch:12 step:11699 [D loss: 0.356791, acc.: 90.62%] [G loss: 0.850613]\n",
      "epoch:12 step:11700 [D loss: 0.396360, acc.: 89.84%] [G loss: 1.408581]\n",
      "epoch:12 step:11701 [D loss: 0.323629, acc.: 96.09%] [G loss: 1.191259]\n",
      "epoch:12 step:11702 [D loss: 0.883194, acc.: 37.50%] [G loss: 1.108420]\n",
      "epoch:12 step:11703 [D loss: 0.563402, acc.: 76.56%] [G loss: 0.960331]\n",
      "epoch:12 step:11704 [D loss: 0.938666, acc.: 30.47%] [G loss: 0.961564]\n",
      "epoch:12 step:11705 [D loss: 1.023803, acc.: 30.47%] [G loss: 1.202565]\n",
      "epoch:12 step:11706 [D loss: 0.888231, acc.: 44.53%] [G loss: 0.888551]\n",
      "epoch:12 step:11707 [D loss: 0.749741, acc.: 53.91%] [G loss: 0.908398]\n",
      "epoch:12 step:11708 [D loss: 0.682129, acc.: 60.16%] [G loss: 0.980764]\n",
      "epoch:12 step:11709 [D loss: 0.636099, acc.: 59.38%] [G loss: 1.000944]\n",
      "epoch:12 step:11710 [D loss: 0.575177, acc.: 75.00%] [G loss: 1.123166]\n",
      "epoch:12 step:11711 [D loss: 0.511406, acc.: 78.12%] [G loss: 0.891653]\n",
      "epoch:12 step:11712 [D loss: 0.580884, acc.: 69.53%] [G loss: 0.929393]\n",
      "epoch:12 step:11713 [D loss: 0.527910, acc.: 77.34%] [G loss: 1.079672]\n",
      "epoch:12 step:11714 [D loss: 0.501868, acc.: 75.78%] [G loss: 1.135507]\n",
      "epoch:12 step:11715 [D loss: 0.683764, acc.: 56.25%] [G loss: 0.870612]\n",
      "epoch:12 step:11716 [D loss: 0.633714, acc.: 63.28%] [G loss: 0.943480]\n",
      "epoch:12 step:11717 [D loss: 0.606568, acc.: 68.75%] [G loss: 1.126485]\n",
      "epoch:12 step:11718 [D loss: 0.527884, acc.: 75.00%] [G loss: 1.641104]\n",
      "epoch:12 step:11719 [D loss: 0.452481, acc.: 82.81%] [G loss: 1.552881]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:12 step:11720 [D loss: 0.688220, acc.: 59.38%] [G loss: 1.271803]\n",
      "epoch:12 step:11721 [D loss: 0.714310, acc.: 56.25%] [G loss: 1.420705]\n",
      "epoch:12 step:11722 [D loss: 0.581631, acc.: 67.19%] [G loss: 1.265818]\n",
      "epoch:12 step:11723 [D loss: 0.879854, acc.: 46.88%] [G loss: 0.956607]\n",
      "epoch:12 step:11724 [D loss: 0.738029, acc.: 51.56%] [G loss: 0.759322]\n",
      "epoch:12 step:11725 [D loss: 0.702570, acc.: 54.69%] [G loss: 0.792280]\n",
      "epoch:12 step:11726 [D loss: 0.646093, acc.: 57.03%] [G loss: 0.715435]\n",
      "epoch:12 step:11727 [D loss: 0.605413, acc.: 70.31%] [G loss: 0.987289]\n",
      "epoch:12 step:11728 [D loss: 0.603362, acc.: 64.84%] [G loss: 0.897743]\n",
      "epoch:12 step:11729 [D loss: 0.656224, acc.: 63.28%] [G loss: 0.918839]\n",
      "epoch:12 step:11730 [D loss: 0.644740, acc.: 60.16%] [G loss: 0.782559]\n",
      "epoch:12 step:11731 [D loss: 0.704205, acc.: 55.47%] [G loss: 0.607008]\n",
      "epoch:12 step:11732 [D loss: 0.607510, acc.: 69.53%] [G loss: 0.783960]\n",
      "epoch:12 step:11733 [D loss: 0.764971, acc.: 45.31%] [G loss: 0.759903]\n",
      "epoch:12 step:11734 [D loss: 0.845942, acc.: 36.72%] [G loss: 0.789741]\n",
      "epoch:12 step:11735 [D loss: 0.645568, acc.: 55.47%] [G loss: 0.910985]\n",
      "epoch:12 step:11736 [D loss: 0.697198, acc.: 62.50%] [G loss: 0.944766]\n",
      "epoch:12 step:11737 [D loss: 0.729691, acc.: 53.12%] [G loss: 0.960587]\n",
      "epoch:12 step:11738 [D loss: 0.645357, acc.: 61.72%] [G loss: 0.997910]\n",
      "epoch:12 step:11739 [D loss: 0.643032, acc.: 61.72%] [G loss: 0.818890]\n",
      "epoch:12 step:11740 [D loss: 0.686228, acc.: 57.03%] [G loss: 0.788772]\n",
      "epoch:12 step:11741 [D loss: 0.582160, acc.: 69.53%] [G loss: 1.064358]\n",
      "epoch:12 step:11742 [D loss: 0.432707, acc.: 82.03%] [G loss: 1.015297]\n",
      "epoch:12 step:11743 [D loss: 0.411054, acc.: 81.25%] [G loss: 1.036870]\n",
      "epoch:12 step:11744 [D loss: 0.699902, acc.: 60.16%] [G loss: 1.042871]\n",
      "epoch:12 step:11745 [D loss: 0.707763, acc.: 58.59%] [G loss: 0.897888]\n",
      "epoch:12 step:11746 [D loss: 0.661500, acc.: 57.03%] [G loss: 1.078787]\n",
      "epoch:12 step:11747 [D loss: 0.571398, acc.: 68.75%] [G loss: 1.179480]\n",
      "epoch:12 step:11748 [D loss: 0.522899, acc.: 76.56%] [G loss: 1.129702]\n",
      "epoch:12 step:11749 [D loss: 0.533542, acc.: 69.53%] [G loss: 1.427383]\n",
      "epoch:12 step:11750 [D loss: 0.532777, acc.: 72.66%] [G loss: 1.218633]\n",
      "epoch:12 step:11751 [D loss: 0.550629, acc.: 68.75%] [G loss: 1.148634]\n",
      "epoch:12 step:11752 [D loss: 0.494537, acc.: 79.69%] [G loss: 1.414026]\n",
      "epoch:12 step:11753 [D loss: 0.678809, acc.: 61.72%] [G loss: 0.920649]\n",
      "epoch:12 step:11754 [D loss: 0.798349, acc.: 53.12%] [G loss: 0.999957]\n",
      "epoch:12 step:11755 [D loss: 0.616684, acc.: 65.62%] [G loss: 1.027225]\n",
      "epoch:12 step:11756 [D loss: 0.494944, acc.: 77.34%] [G loss: 0.973562]\n",
      "epoch:12 step:11757 [D loss: 0.425777, acc.: 72.66%] [G loss: 1.132001]\n",
      "epoch:12 step:11758 [D loss: 0.616197, acc.: 68.75%] [G loss: 0.993535]\n",
      "epoch:12 step:11759 [D loss: 0.580017, acc.: 67.19%] [G loss: 0.985663]\n",
      "epoch:12 step:11760 [D loss: 0.637281, acc.: 64.84%] [G loss: 0.976642]\n",
      "epoch:12 step:11761 [D loss: 0.601670, acc.: 67.97%] [G loss: 0.993655]\n",
      "epoch:12 step:11762 [D loss: 0.635685, acc.: 61.72%] [G loss: 0.983928]\n",
      "epoch:12 step:11763 [D loss: 0.660620, acc.: 58.59%] [G loss: 0.883696]\n",
      "epoch:12 step:11764 [D loss: 0.642381, acc.: 60.16%] [G loss: 0.851260]\n",
      "epoch:12 step:11765 [D loss: 0.611118, acc.: 68.75%] [G loss: 1.097275]\n",
      "epoch:12 step:11766 [D loss: 0.546133, acc.: 75.00%] [G loss: 0.960701]\n",
      "epoch:12 step:11767 [D loss: 0.540938, acc.: 78.12%] [G loss: 1.058090]\n",
      "epoch:12 step:11768 [D loss: 0.573817, acc.: 71.88%] [G loss: 1.000916]\n",
      "epoch:12 step:11769 [D loss: 0.649709, acc.: 60.16%] [G loss: 0.864482]\n",
      "epoch:12 step:11770 [D loss: 0.692222, acc.: 57.81%] [G loss: 0.942682]\n",
      "epoch:12 step:11771 [D loss: 0.543283, acc.: 67.19%] [G loss: 0.941029]\n",
      "epoch:12 step:11772 [D loss: 0.758295, acc.: 49.22%] [G loss: 0.942489]\n",
      "epoch:12 step:11773 [D loss: 0.660591, acc.: 57.03%] [G loss: 0.783559]\n",
      "epoch:12 step:11774 [D loss: 0.617571, acc.: 65.62%] [G loss: 0.896406]\n",
      "epoch:12 step:11775 [D loss: 0.790279, acc.: 42.19%] [G loss: 0.730335]\n",
      "epoch:12 step:11776 [D loss: 0.664812, acc.: 57.03%] [G loss: 0.751233]\n",
      "epoch:12 step:11777 [D loss: 0.583813, acc.: 71.88%] [G loss: 0.957236]\n",
      "epoch:12 step:11778 [D loss: 0.552837, acc.: 79.69%] [G loss: 0.902424]\n",
      "epoch:12 step:11779 [D loss: 0.453473, acc.: 85.94%] [G loss: 0.977936]\n",
      "epoch:12 step:11780 [D loss: 0.347820, acc.: 82.03%] [G loss: 0.813908]\n",
      "epoch:12 step:11781 [D loss: 0.361744, acc.: 87.50%] [G loss: 1.060583]\n",
      "epoch:12 step:11782 [D loss: 0.497981, acc.: 85.16%] [G loss: 1.118243]\n",
      "epoch:12 step:11783 [D loss: 0.686263, acc.: 59.38%] [G loss: 1.079466]\n",
      "epoch:12 step:11784 [D loss: 0.788260, acc.: 50.00%] [G loss: 1.102226]\n",
      "epoch:12 step:11785 [D loss: 0.585359, acc.: 71.09%] [G loss: 0.891725]\n",
      "epoch:12 step:11786 [D loss: 0.688555, acc.: 52.34%] [G loss: 1.000020]\n",
      "epoch:12 step:11787 [D loss: 0.725865, acc.: 50.00%] [G loss: 0.805997]\n",
      "epoch:12 step:11788 [D loss: 0.658123, acc.: 60.94%] [G loss: 1.208112]\n",
      "epoch:12 step:11789 [D loss: 0.903115, acc.: 39.84%] [G loss: 1.114384]\n",
      "epoch:12 step:11790 [D loss: 0.521933, acc.: 78.91%] [G loss: 1.373632]\n",
      "epoch:12 step:11791 [D loss: 0.538272, acc.: 69.53%] [G loss: 1.109875]\n",
      "epoch:12 step:11792 [D loss: 0.523125, acc.: 78.12%] [G loss: 1.176073]\n",
      "epoch:12 step:11793 [D loss: 0.462041, acc.: 82.81%] [G loss: 1.415977]\n",
      "epoch:12 step:11794 [D loss: 0.416608, acc.: 87.50%] [G loss: 1.404992]\n",
      "epoch:12 step:11795 [D loss: 0.513699, acc.: 68.75%] [G loss: 1.403980]\n",
      "epoch:12 step:11796 [D loss: 0.483128, acc.: 80.47%] [G loss: 1.240769]\n",
      "epoch:12 step:11797 [D loss: 0.569179, acc.: 69.53%] [G loss: 1.574837]\n",
      "epoch:12 step:11798 [D loss: 0.336508, acc.: 95.31%] [G loss: 0.986170]\n",
      "epoch:12 step:11799 [D loss: 0.482346, acc.: 79.69%] [G loss: 1.182820]\n",
      "epoch:12 step:11800 [D loss: 0.511596, acc.: 76.56%] [G loss: 1.275086]\n",
      "##############\n",
      "[3.92137231 2.41318903 6.31251324 5.73507649 4.75546939 6.14543691\n",
      " 5.20180013 5.86695819 5.68087303 5.21420593]\n",
      "##########\n",
      "epoch:12 step:11801 [D loss: 0.538219, acc.: 71.88%] [G loss: 1.162060]\n",
      "epoch:12 step:11802 [D loss: 0.491703, acc.: 79.69%] [G loss: 1.087672]\n",
      "epoch:12 step:11803 [D loss: 0.583603, acc.: 72.66%] [G loss: 0.976533]\n",
      "epoch:12 step:11804 [D loss: 0.936351, acc.: 50.00%] [G loss: 0.870818]\n",
      "epoch:12 step:11805 [D loss: 0.600126, acc.: 63.28%] [G loss: 0.990342]\n",
      "epoch:12 step:11806 [D loss: 0.749516, acc.: 54.69%] [G loss: 0.987008]\n",
      "epoch:12 step:11807 [D loss: 0.746874, acc.: 49.22%] [G loss: 0.958181]\n",
      "epoch:12 step:11808 [D loss: 0.618518, acc.: 68.75%] [G loss: 0.894531]\n",
      "epoch:12 step:11809 [D loss: 0.685774, acc.: 57.81%] [G loss: 1.196514]\n",
      "epoch:12 step:11810 [D loss: 0.277850, acc.: 89.84%] [G loss: 1.176381]\n",
      "epoch:12 step:11811 [D loss: 0.230559, acc.: 95.31%] [G loss: 1.315704]\n",
      "epoch:12 step:11812 [D loss: 0.354283, acc.: 89.06%] [G loss: 1.635825]\n",
      "epoch:12 step:11813 [D loss: 0.649784, acc.: 64.06%] [G loss: 1.516698]\n",
      "epoch:12 step:11814 [D loss: 0.553890, acc.: 75.00%] [G loss: 1.364620]\n",
      "epoch:12 step:11815 [D loss: 0.638121, acc.: 64.84%] [G loss: 1.103677]\n",
      "epoch:12 step:11816 [D loss: 0.630990, acc.: 66.41%] [G loss: 0.928239]\n",
      "epoch:12 step:11817 [D loss: 0.652369, acc.: 64.84%] [G loss: 1.176829]\n",
      "epoch:12 step:11818 [D loss: 0.707970, acc.: 57.81%] [G loss: 1.083525]\n",
      "epoch:12 step:11819 [D loss: 0.629034, acc.: 61.72%] [G loss: 1.494814]\n",
      "epoch:12 step:11820 [D loss: 0.582050, acc.: 70.31%] [G loss: 1.309647]\n",
      "epoch:12 step:11821 [D loss: 0.444476, acc.: 81.25%] [G loss: 1.179717]\n",
      "epoch:12 step:11822 [D loss: 0.785425, acc.: 57.03%] [G loss: 1.227872]\n",
      "epoch:12 step:11823 [D loss: 0.526941, acc.: 76.56%] [G loss: 1.216204]\n",
      "epoch:12 step:11824 [D loss: 0.839801, acc.: 48.44%] [G loss: 1.133884]\n",
      "epoch:12 step:11825 [D loss: 0.731012, acc.: 52.34%] [G loss: 0.986898]\n",
      "epoch:12 step:11826 [D loss: 0.678239, acc.: 58.59%] [G loss: 0.789239]\n",
      "epoch:12 step:11827 [D loss: 0.722616, acc.: 57.03%] [G loss: 0.964121]\n",
      "epoch:12 step:11828 [D loss: 0.750024, acc.: 45.31%] [G loss: 0.884758]\n",
      "epoch:12 step:11829 [D loss: 0.637947, acc.: 61.72%] [G loss: 0.888695]\n",
      "epoch:12 step:11830 [D loss: 0.691735, acc.: 53.91%] [G loss: 0.840026]\n",
      "epoch:12 step:11831 [D loss: 0.273442, acc.: 89.84%] [G loss: 0.918950]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:12 step:11832 [D loss: 0.455492, acc.: 85.94%] [G loss: 1.204971]\n",
      "epoch:12 step:11833 [D loss: 0.235331, acc.: 93.75%] [G loss: 1.167815]\n",
      "epoch:12 step:11834 [D loss: 0.660337, acc.: 65.62%] [G loss: 1.161371]\n",
      "epoch:12 step:11835 [D loss: 0.642324, acc.: 63.28%] [G loss: 1.094887]\n",
      "epoch:12 step:11836 [D loss: 0.593652, acc.: 68.75%] [G loss: 1.066981]\n",
      "epoch:12 step:11837 [D loss: 0.631846, acc.: 64.06%] [G loss: 0.925508]\n",
      "epoch:12 step:11838 [D loss: 0.711111, acc.: 47.66%] [G loss: 0.862193]\n",
      "epoch:12 step:11839 [D loss: 0.440478, acc.: 84.38%] [G loss: 0.677907]\n",
      "epoch:12 step:11840 [D loss: 0.659393, acc.: 61.72%] [G loss: 1.033383]\n",
      "epoch:12 step:11841 [D loss: 0.706840, acc.: 56.25%] [G loss: 0.827162]\n",
      "epoch:12 step:11842 [D loss: 0.675398, acc.: 62.50%] [G loss: 0.908878]\n",
      "epoch:12 step:11843 [D loss: 0.730706, acc.: 53.91%] [G loss: 0.993097]\n",
      "epoch:12 step:11844 [D loss: 0.302530, acc.: 88.28%] [G loss: 0.994019]\n",
      "epoch:12 step:11845 [D loss: 0.465258, acc.: 76.56%] [G loss: 1.092327]\n",
      "epoch:12 step:11846 [D loss: 0.306232, acc.: 92.19%] [G loss: 0.987633]\n",
      "epoch:12 step:11847 [D loss: 0.755914, acc.: 53.91%] [G loss: 1.046530]\n",
      "epoch:12 step:11848 [D loss: 0.780231, acc.: 42.19%] [G loss: 1.026808]\n",
      "epoch:12 step:11849 [D loss: 0.667090, acc.: 56.25%] [G loss: 1.067159]\n",
      "epoch:12 step:11850 [D loss: 0.663044, acc.: 60.94%] [G loss: 0.805498]\n",
      "epoch:12 step:11851 [D loss: 0.679484, acc.: 60.16%] [G loss: 0.983552]\n",
      "epoch:12 step:11852 [D loss: 0.518652, acc.: 82.03%] [G loss: 0.893146]\n",
      "epoch:12 step:11853 [D loss: 0.336694, acc.: 87.50%] [G loss: 0.951065]\n",
      "epoch:12 step:11854 [D loss: 0.718222, acc.: 53.12%] [G loss: 1.005500]\n",
      "epoch:12 step:11855 [D loss: 0.442278, acc.: 86.72%] [G loss: 1.088253]\n",
      "epoch:12 step:11856 [D loss: 0.534373, acc.: 72.66%] [G loss: 1.112520]\n",
      "epoch:12 step:11857 [D loss: 0.615843, acc.: 60.16%] [G loss: 1.054085]\n",
      "epoch:12 step:11858 [D loss: 0.726733, acc.: 49.22%] [G loss: 0.514011]\n",
      "epoch:12 step:11859 [D loss: 0.677952, acc.: 56.25%] [G loss: 0.918746]\n",
      "epoch:12 step:11860 [D loss: 0.716620, acc.: 53.12%] [G loss: 0.930725]\n",
      "epoch:12 step:11861 [D loss: 0.758325, acc.: 45.31%] [G loss: 0.663496]\n",
      "epoch:12 step:11862 [D loss: 1.066872, acc.: 42.19%] [G loss: 1.117197]\n",
      "epoch:12 step:11863 [D loss: 0.736249, acc.: 55.47%] [G loss: 1.096822]\n",
      "epoch:12 step:11864 [D loss: 0.634544, acc.: 60.94%] [G loss: 0.769861]\n",
      "epoch:12 step:11865 [D loss: 0.673176, acc.: 60.16%] [G loss: 0.993876]\n",
      "epoch:12 step:11866 [D loss: 0.695861, acc.: 53.91%] [G loss: 0.923254]\n",
      "epoch:12 step:11867 [D loss: 0.626474, acc.: 57.03%] [G loss: 1.273497]\n",
      "epoch:12 step:11868 [D loss: 0.765916, acc.: 51.56%] [G loss: 0.892044]\n",
      "epoch:12 step:11869 [D loss: 0.653227, acc.: 62.50%] [G loss: 0.999517]\n",
      "epoch:12 step:11870 [D loss: 0.621647, acc.: 61.72%] [G loss: 1.059583]\n",
      "epoch:12 step:11871 [D loss: 0.647643, acc.: 57.03%] [G loss: 0.977050]\n",
      "epoch:12 step:11872 [D loss: 0.682800, acc.: 57.81%] [G loss: 0.803936]\n",
      "epoch:12 step:11873 [D loss: 0.601643, acc.: 66.41%] [G loss: 0.911243]\n",
      "epoch:12 step:11874 [D loss: 0.685346, acc.: 56.25%] [G loss: 0.977193]\n",
      "epoch:12 step:11875 [D loss: 0.602758, acc.: 67.19%] [G loss: 0.993582]\n",
      "epoch:12 step:11876 [D loss: 0.673169, acc.: 57.03%] [G loss: 0.870968]\n",
      "epoch:12 step:11877 [D loss: 0.597573, acc.: 65.62%] [G loss: 0.986922]\n",
      "epoch:12 step:11878 [D loss: 0.508162, acc.: 83.59%] [G loss: 0.891801]\n",
      "epoch:12 step:11879 [D loss: 0.618278, acc.: 65.62%] [G loss: 0.757442]\n",
      "epoch:12 step:11880 [D loss: 0.655239, acc.: 60.94%] [G loss: 0.764829]\n",
      "epoch:12 step:11881 [D loss: 0.605966, acc.: 70.31%] [G loss: 0.893537]\n",
      "epoch:12 step:11882 [D loss: 0.614083, acc.: 64.84%] [G loss: 0.868822]\n",
      "epoch:12 step:11883 [D loss: 0.576430, acc.: 71.88%] [G loss: 0.802358]\n",
      "epoch:12 step:11884 [D loss: 0.794160, acc.: 38.28%] [G loss: 1.015534]\n",
      "epoch:12 step:11885 [D loss: 0.472362, acc.: 78.91%] [G loss: 0.939495]\n",
      "epoch:12 step:11886 [D loss: 0.767792, acc.: 42.19%] [G loss: 0.875744]\n",
      "epoch:12 step:11887 [D loss: 0.734461, acc.: 53.12%] [G loss: 0.906329]\n",
      "epoch:12 step:11888 [D loss: 0.563245, acc.: 71.09%] [G loss: 0.764161]\n",
      "epoch:12 step:11889 [D loss: 0.563897, acc.: 75.78%] [G loss: 0.956130]\n",
      "epoch:12 step:11890 [D loss: 0.570919, acc.: 67.97%] [G loss: 0.909160]\n",
      "epoch:12 step:11891 [D loss: 0.676567, acc.: 60.94%] [G loss: 0.838615]\n",
      "epoch:12 step:11892 [D loss: 0.514412, acc.: 76.56%] [G loss: 1.142992]\n",
      "epoch:12 step:11893 [D loss: 0.718049, acc.: 52.34%] [G loss: 1.226300]\n",
      "epoch:12 step:11894 [D loss: 0.465442, acc.: 82.81%] [G loss: 0.939633]\n",
      "epoch:12 step:11895 [D loss: 0.499103, acc.: 78.91%] [G loss: 1.041016]\n",
      "epoch:12 step:11896 [D loss: 0.743900, acc.: 52.34%] [G loss: 0.891577]\n",
      "epoch:12 step:11897 [D loss: 0.842770, acc.: 38.28%] [G loss: 0.755935]\n",
      "epoch:12 step:11898 [D loss: 0.934201, acc.: 27.34%] [G loss: 1.187335]\n",
      "epoch:12 step:11899 [D loss: 0.803830, acc.: 39.84%] [G loss: 0.900176]\n",
      "epoch:12 step:11900 [D loss: 0.819370, acc.: 40.62%] [G loss: 1.011995]\n",
      "epoch:12 step:11901 [D loss: 0.769927, acc.: 48.44%] [G loss: 0.956260]\n",
      "epoch:12 step:11902 [D loss: 0.728971, acc.: 54.69%] [G loss: 0.942213]\n",
      "epoch:12 step:11903 [D loss: 0.655443, acc.: 61.72%] [G loss: 0.993896]\n",
      "epoch:12 step:11904 [D loss: 0.611637, acc.: 67.19%] [G loss: 0.866169]\n",
      "epoch:12 step:11905 [D loss: 0.681286, acc.: 57.03%] [G loss: 0.856241]\n",
      "epoch:12 step:11906 [D loss: 0.721397, acc.: 47.66%] [G loss: 0.823246]\n",
      "epoch:12 step:11907 [D loss: 0.310819, acc.: 87.50%] [G loss: 1.015760]\n",
      "epoch:12 step:11908 [D loss: 0.290404, acc.: 89.06%] [G loss: 1.093828]\n",
      "epoch:12 step:11909 [D loss: 0.273693, acc.: 92.19%] [G loss: 1.198897]\n",
      "epoch:12 step:11910 [D loss: 0.664512, acc.: 63.28%] [G loss: 1.057266]\n",
      "epoch:12 step:11911 [D loss: 0.636442, acc.: 62.50%] [G loss: 1.106002]\n",
      "epoch:12 step:11912 [D loss: 0.766095, acc.: 53.12%] [G loss: 1.085734]\n",
      "epoch:12 step:11913 [D loss: 0.672371, acc.: 54.69%] [G loss: 0.970237]\n",
      "epoch:12 step:11914 [D loss: 0.704798, acc.: 52.34%] [G loss: 0.924595]\n",
      "epoch:12 step:11915 [D loss: 0.662251, acc.: 57.03%] [G loss: 0.896724]\n",
      "epoch:12 step:11916 [D loss: 0.734281, acc.: 46.88%] [G loss: 0.823653]\n",
      "epoch:12 step:11917 [D loss: 0.713710, acc.: 57.03%] [G loss: 0.892565]\n",
      "epoch:12 step:11918 [D loss: 0.578161, acc.: 75.78%] [G loss: 0.986408]\n",
      "epoch:12 step:11919 [D loss: 0.787071, acc.: 45.31%] [G loss: 0.905691]\n",
      "epoch:12 step:11920 [D loss: 0.716617, acc.: 50.00%] [G loss: 0.859912]\n",
      "epoch:12 step:11921 [D loss: 0.664269, acc.: 57.81%] [G loss: 0.903977]\n",
      "epoch:12 step:11922 [D loss: 0.692375, acc.: 52.34%] [G loss: 0.812556]\n",
      "epoch:12 step:11923 [D loss: 0.668684, acc.: 59.38%] [G loss: 0.896345]\n",
      "epoch:12 step:11924 [D loss: 0.661115, acc.: 58.59%] [G loss: 0.860380]\n",
      "epoch:12 step:11925 [D loss: 0.601925, acc.: 73.44%] [G loss: 0.746172]\n",
      "epoch:12 step:11926 [D loss: 0.594391, acc.: 70.31%] [G loss: 0.858741]\n",
      "epoch:12 step:11927 [D loss: 0.648680, acc.: 60.16%] [G loss: 0.869982]\n",
      "epoch:12 step:11928 [D loss: 0.472148, acc.: 82.81%] [G loss: 0.927267]\n",
      "epoch:12 step:11929 [D loss: 0.636204, acc.: 64.06%] [G loss: 0.852894]\n",
      "epoch:12 step:11930 [D loss: 0.550296, acc.: 77.34%] [G loss: 0.929711]\n",
      "epoch:12 step:11931 [D loss: 0.645444, acc.: 57.03%] [G loss: 0.833330]\n",
      "epoch:12 step:11932 [D loss: 0.706847, acc.: 49.22%] [G loss: 0.794512]\n",
      "epoch:12 step:11933 [D loss: 0.698672, acc.: 55.47%] [G loss: 0.880892]\n",
      "epoch:12 step:11934 [D loss: 0.730787, acc.: 50.78%] [G loss: 0.895190]\n",
      "epoch:12 step:11935 [D loss: 0.715759, acc.: 54.69%] [G loss: 0.765928]\n",
      "epoch:12 step:11936 [D loss: 0.678374, acc.: 55.47%] [G loss: 0.908320]\n",
      "epoch:12 step:11937 [D loss: 0.684087, acc.: 56.25%] [G loss: 0.751506]\n",
      "epoch:12 step:11938 [D loss: 0.624340, acc.: 71.88%] [G loss: 0.942067]\n",
      "epoch:12 step:11939 [D loss: 0.721671, acc.: 52.34%] [G loss: 0.864352]\n",
      "epoch:12 step:11940 [D loss: 0.474554, acc.: 66.41%] [G loss: 1.033532]\n",
      "epoch:12 step:11941 [D loss: 0.246761, acc.: 92.97%] [G loss: 1.243713]\n",
      "epoch:12 step:11942 [D loss: 0.381335, acc.: 96.09%] [G loss: 1.278327]\n",
      "epoch:12 step:11943 [D loss: 0.737317, acc.: 52.34%] [G loss: 1.224118]\n",
      "epoch:12 step:11944 [D loss: 0.291708, acc.: 94.53%] [G loss: 1.160177]\n",
      "epoch:12 step:11945 [D loss: 0.312819, acc.: 86.72%] [G loss: 1.068577]\n",
      "epoch:12 step:11946 [D loss: 0.269789, acc.: 99.22%] [G loss: 1.351610]\n",
      "epoch:12 step:11947 [D loss: 0.738336, acc.: 53.12%] [G loss: 1.097059]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:12 step:11948 [D loss: 0.528933, acc.: 81.25%] [G loss: 1.205926]\n",
      "epoch:12 step:11949 [D loss: 1.284193, acc.: 17.19%] [G loss: 1.069224]\n",
      "epoch:12 step:11950 [D loss: 0.252434, acc.: 94.53%] [G loss: 1.390637]\n",
      "epoch:12 step:11951 [D loss: 0.188689, acc.: 97.66%] [G loss: 1.493963]\n",
      "epoch:12 step:11952 [D loss: 0.293675, acc.: 95.31%] [G loss: 1.689684]\n",
      "epoch:12 step:11953 [D loss: 0.409231, acc.: 91.41%] [G loss: 1.353349]\n",
      "epoch:12 step:11954 [D loss: 0.945549, acc.: 50.00%] [G loss: 0.984441]\n",
      "epoch:12 step:11955 [D loss: 0.839255, acc.: 45.31%] [G loss: 1.033913]\n",
      "epoch:12 step:11956 [D loss: 0.615761, acc.: 63.28%] [G loss: 1.083913]\n",
      "epoch:12 step:11957 [D loss: 0.220421, acc.: 98.44%] [G loss: 1.224161]\n",
      "epoch:12 step:11958 [D loss: 0.226799, acc.: 97.66%] [G loss: 0.874001]\n",
      "epoch:12 step:11959 [D loss: 0.771195, acc.: 47.66%] [G loss: 1.248609]\n",
      "epoch:12 step:11960 [D loss: 0.756021, acc.: 53.12%] [G loss: 1.178476]\n",
      "epoch:12 step:11961 [D loss: 0.717859, acc.: 54.69%] [G loss: 0.949678]\n",
      "epoch:12 step:11962 [D loss: 0.715048, acc.: 51.56%] [G loss: 0.610296]\n",
      "epoch:12 step:11963 [D loss: 0.874328, acc.: 35.94%] [G loss: 1.039172]\n",
      "epoch:12 step:11964 [D loss: 0.643685, acc.: 63.28%] [G loss: 1.081958]\n",
      "epoch:12 step:11965 [D loss: 0.633484, acc.: 65.62%] [G loss: 0.957197]\n",
      "epoch:12 step:11966 [D loss: 0.692754, acc.: 60.16%] [G loss: 0.689943]\n",
      "epoch:12 step:11967 [D loss: 0.619832, acc.: 66.41%] [G loss: 0.901286]\n",
      "epoch:12 step:11968 [D loss: 0.644730, acc.: 62.50%] [G loss: 0.979466]\n",
      "epoch:12 step:11969 [D loss: 1.540993, acc.: 23.44%] [G loss: 1.169016]\n",
      "epoch:12 step:11970 [D loss: 0.643810, acc.: 59.38%] [G loss: 1.574950]\n",
      "epoch:12 step:11971 [D loss: 0.720056, acc.: 51.56%] [G loss: 1.141175]\n",
      "epoch:12 step:11972 [D loss: 0.363104, acc.: 92.19%] [G loss: 1.248857]\n",
      "epoch:12 step:11973 [D loss: 0.521010, acc.: 75.00%] [G loss: 1.131735]\n",
      "epoch:12 step:11974 [D loss: 0.342944, acc.: 92.19%] [G loss: 1.266081]\n",
      "epoch:12 step:11975 [D loss: 0.349421, acc.: 94.53%] [G loss: 1.294710]\n",
      "epoch:12 step:11976 [D loss: 0.310769, acc.: 94.53%] [G loss: 1.106314]\n",
      "epoch:12 step:11977 [D loss: 0.319994, acc.: 93.75%] [G loss: 1.363529]\n",
      "epoch:12 step:11978 [D loss: 0.787564, acc.: 45.31%] [G loss: 0.748963]\n",
      "epoch:12 step:11979 [D loss: 0.800365, acc.: 46.88%] [G loss: 1.143975]\n",
      "epoch:12 step:11980 [D loss: 0.676738, acc.: 60.94%] [G loss: 0.926660]\n",
      "epoch:12 step:11981 [D loss: 0.705338, acc.: 55.47%] [G loss: 0.918353]\n",
      "epoch:12 step:11982 [D loss: 0.756425, acc.: 46.88%] [G loss: 0.667477]\n",
      "epoch:12 step:11983 [D loss: 0.470329, acc.: 81.25%] [G loss: 0.594966]\n",
      "epoch:12 step:11984 [D loss: 0.545326, acc.: 68.75%] [G loss: 1.171484]\n",
      "epoch:12 step:11985 [D loss: 0.634035, acc.: 60.94%] [G loss: 0.684801]\n",
      "epoch:12 step:11986 [D loss: 0.901605, acc.: 34.38%] [G loss: 1.280785]\n",
      "epoch:12 step:11987 [D loss: 0.463814, acc.: 83.59%] [G loss: 1.127543]\n",
      "epoch:12 step:11988 [D loss: 0.680815, acc.: 60.16%] [G loss: 1.054015]\n",
      "epoch:12 step:11989 [D loss: 0.951631, acc.: 32.03%] [G loss: 1.432797]\n",
      "epoch:12 step:11990 [D loss: 0.473100, acc.: 77.34%] [G loss: 1.644241]\n",
      "epoch:12 step:11991 [D loss: 0.801018, acc.: 40.62%] [G loss: 1.870894]\n",
      "epoch:12 step:11992 [D loss: 0.593097, acc.: 62.50%] [G loss: 2.092297]\n",
      "epoch:12 step:11993 [D loss: 0.364646, acc.: 84.38%] [G loss: 2.184958]\n",
      "epoch:12 step:11994 [D loss: 0.344143, acc.: 92.19%] [G loss: 1.478131]\n",
      "epoch:12 step:11995 [D loss: 0.624114, acc.: 62.50%] [G loss: 1.456398]\n",
      "epoch:12 step:11996 [D loss: 0.903894, acc.: 43.75%] [G loss: 1.140023]\n",
      "epoch:12 step:11997 [D loss: 0.673440, acc.: 60.94%] [G loss: 1.285665]\n",
      "epoch:12 step:11998 [D loss: 0.783708, acc.: 50.00%] [G loss: 1.019734]\n",
      "epoch:12 step:11999 [D loss: 0.856820, acc.: 35.94%] [G loss: 1.041560]\n",
      "epoch:12 step:12000 [D loss: 0.617255, acc.: 60.94%] [G loss: 0.969993]\n",
      "##############\n",
      "[3.69585484 2.24804364 6.09188356 6.16962528 3.86089804 6.23599562\n",
      " 5.05026438 5.05641016 5.37340922 4.69404974]\n",
      "##########\n",
      "epoch:12 step:12001 [D loss: 0.572381, acc.: 67.19%] [G loss: 1.092797]\n",
      "epoch:12 step:12002 [D loss: 0.661355, acc.: 61.72%] [G loss: 0.999147]\n",
      "epoch:12 step:12003 [D loss: 0.569389, acc.: 78.12%] [G loss: 1.104639]\n",
      "epoch:12 step:12004 [D loss: 0.552922, acc.: 71.88%] [G loss: 1.003516]\n",
      "epoch:12 step:12005 [D loss: 0.630248, acc.: 64.06%] [G loss: 0.975129]\n",
      "epoch:12 step:12006 [D loss: 0.693294, acc.: 57.03%] [G loss: 1.033018]\n",
      "epoch:12 step:12007 [D loss: 0.711210, acc.: 52.34%] [G loss: 0.914521]\n",
      "epoch:12 step:12008 [D loss: 0.500729, acc.: 79.69%] [G loss: 0.988224]\n",
      "epoch:12 step:12009 [D loss: 0.604985, acc.: 70.31%] [G loss: 0.993403]\n",
      "epoch:12 step:12010 [D loss: 0.580555, acc.: 71.88%] [G loss: 0.982760]\n",
      "epoch:12 step:12011 [D loss: 0.546211, acc.: 76.56%] [G loss: 1.030303]\n",
      "epoch:12 step:12012 [D loss: 0.512521, acc.: 74.22%] [G loss: 1.052756]\n",
      "epoch:12 step:12013 [D loss: 0.548248, acc.: 71.88%] [G loss: 0.980937]\n",
      "epoch:12 step:12014 [D loss: 0.545567, acc.: 73.44%] [G loss: 1.102654]\n",
      "epoch:12 step:12015 [D loss: 0.741786, acc.: 52.34%] [G loss: 1.055878]\n",
      "epoch:12 step:12016 [D loss: 0.616281, acc.: 67.19%] [G loss: 1.034941]\n",
      "epoch:12 step:12017 [D loss: 0.635499, acc.: 63.28%] [G loss: 0.936029]\n",
      "epoch:12 step:12018 [D loss: 0.572207, acc.: 68.75%] [G loss: 0.975618]\n",
      "epoch:12 step:12019 [D loss: 0.538238, acc.: 73.44%] [G loss: 1.114467]\n",
      "epoch:12 step:12020 [D loss: 0.695298, acc.: 60.16%] [G loss: 1.187656]\n",
      "epoch:12 step:12021 [D loss: 0.598153, acc.: 71.09%] [G loss: 0.945978]\n",
      "epoch:12 step:12022 [D loss: 0.644776, acc.: 62.50%] [G loss: 1.027433]\n",
      "epoch:12 step:12023 [D loss: 0.766282, acc.: 47.66%] [G loss: 1.061330]\n",
      "epoch:12 step:12024 [D loss: 0.754099, acc.: 48.44%] [G loss: 0.933306]\n",
      "epoch:12 step:12025 [D loss: 0.594330, acc.: 66.41%] [G loss: 0.684311]\n",
      "epoch:12 step:12026 [D loss: 0.551979, acc.: 71.09%] [G loss: 1.024570]\n",
      "epoch:12 step:12027 [D loss: 0.738769, acc.: 52.34%] [G loss: 0.916962]\n",
      "epoch:12 step:12028 [D loss: 0.695600, acc.: 51.56%] [G loss: 0.573289]\n",
      "epoch:12 step:12029 [D loss: 0.708499, acc.: 53.91%] [G loss: 0.909785]\n",
      "epoch:12 step:12030 [D loss: 0.544559, acc.: 75.00%] [G loss: 0.675003]\n",
      "epoch:12 step:12031 [D loss: 0.708684, acc.: 50.00%] [G loss: 0.565102]\n",
      "epoch:12 step:12032 [D loss: 1.214797, acc.: 28.12%] [G loss: 1.008390]\n",
      "epoch:12 step:12033 [D loss: 0.773052, acc.: 44.53%] [G loss: 0.857476]\n",
      "epoch:12 step:12034 [D loss: 0.656891, acc.: 56.25%] [G loss: 1.106260]\n",
      "epoch:12 step:12035 [D loss: 0.482409, acc.: 78.91%] [G loss: 0.882562]\n",
      "epoch:12 step:12036 [D loss: 0.477518, acc.: 78.91%] [G loss: 0.899179]\n",
      "epoch:12 step:12037 [D loss: 0.517308, acc.: 71.88%] [G loss: 1.063181]\n",
      "epoch:12 step:12038 [D loss: 0.562855, acc.: 76.56%] [G loss: 0.906904]\n",
      "epoch:12 step:12039 [D loss: 0.819546, acc.: 41.41%] [G loss: 1.042289]\n",
      "epoch:12 step:12040 [D loss: 0.644272, acc.: 64.06%] [G loss: 1.017495]\n",
      "epoch:12 step:12041 [D loss: 0.685183, acc.: 57.03%] [G loss: 1.030503]\n",
      "epoch:12 step:12042 [D loss: 0.686351, acc.: 60.16%] [G loss: 0.974006]\n",
      "epoch:12 step:12043 [D loss: 0.688167, acc.: 60.94%] [G loss: 1.008013]\n",
      "epoch:12 step:12044 [D loss: 0.505075, acc.: 81.25%] [G loss: 1.193108]\n",
      "epoch:12 step:12045 [D loss: 0.520540, acc.: 81.25%] [G loss: 0.985213]\n",
      "epoch:12 step:12046 [D loss: 0.500980, acc.: 82.03%] [G loss: 0.934375]\n",
      "epoch:12 step:12047 [D loss: 0.566390, acc.: 69.53%] [G loss: 1.172780]\n",
      "epoch:12 step:12048 [D loss: 0.477235, acc.: 82.81%] [G loss: 1.042777]\n",
      "epoch:12 step:12049 [D loss: 0.559426, acc.: 72.66%] [G loss: 0.924986]\n",
      "epoch:12 step:12050 [D loss: 0.294035, acc.: 91.41%] [G loss: 1.007065]\n",
      "epoch:12 step:12051 [D loss: 0.642090, acc.: 61.72%] [G loss: 1.097794]\n",
      "epoch:12 step:12052 [D loss: 0.521900, acc.: 73.44%] [G loss: 1.031880]\n",
      "epoch:12 step:12053 [D loss: 0.495006, acc.: 85.16%] [G loss: 1.103979]\n",
      "epoch:12 step:12054 [D loss: 0.472473, acc.: 82.81%] [G loss: 1.240072]\n",
      "epoch:12 step:12055 [D loss: 0.756643, acc.: 53.12%] [G loss: 1.107559]\n",
      "epoch:12 step:12056 [D loss: 0.706932, acc.: 56.25%] [G loss: 1.097968]\n",
      "epoch:12 step:12057 [D loss: 0.896971, acc.: 34.38%] [G loss: 0.920361]\n",
      "epoch:12 step:12058 [D loss: 0.594317, acc.: 67.19%] [G loss: 0.932418]\n",
      "epoch:12 step:12059 [D loss: 0.452031, acc.: 85.94%] [G loss: 1.075045]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:12 step:12060 [D loss: 0.506149, acc.: 77.34%] [G loss: 1.273480]\n",
      "epoch:12 step:12061 [D loss: 0.571453, acc.: 72.66%] [G loss: 1.045524]\n",
      "epoch:12 step:12062 [D loss: 0.597637, acc.: 63.28%] [G loss: 0.957893]\n",
      "epoch:12 step:12063 [D loss: 0.560395, acc.: 72.66%] [G loss: 1.400808]\n",
      "epoch:12 step:12064 [D loss: 0.728765, acc.: 50.78%] [G loss: 0.791429]\n",
      "epoch:12 step:12065 [D loss: 0.706290, acc.: 60.16%] [G loss: 0.713422]\n",
      "epoch:12 step:12066 [D loss: 0.767020, acc.: 41.41%] [G loss: 1.351074]\n",
      "epoch:12 step:12067 [D loss: 0.603040, acc.: 68.75%] [G loss: 0.731391]\n",
      "epoch:12 step:12068 [D loss: 0.535371, acc.: 75.78%] [G loss: 0.698687]\n",
      "epoch:12 step:12069 [D loss: 0.633808, acc.: 59.38%] [G loss: 1.230889]\n",
      "epoch:12 step:12070 [D loss: 0.537359, acc.: 77.34%] [G loss: 1.060811]\n",
      "epoch:12 step:12071 [D loss: 0.752716, acc.: 46.09%] [G loss: 0.770552]\n",
      "epoch:12 step:12072 [D loss: 0.887019, acc.: 32.03%] [G loss: 0.802423]\n",
      "epoch:12 step:12073 [D loss: 0.623379, acc.: 64.84%] [G loss: 0.889777]\n",
      "epoch:12 step:12074 [D loss: 0.591019, acc.: 68.75%] [G loss: 0.876702]\n",
      "epoch:12 step:12075 [D loss: 0.507925, acc.: 75.78%] [G loss: 0.790490]\n",
      "epoch:12 step:12076 [D loss: 0.442693, acc.: 86.72%] [G loss: 0.804169]\n",
      "epoch:12 step:12077 [D loss: 0.631502, acc.: 61.72%] [G loss: 1.065021]\n",
      "epoch:12 step:12078 [D loss: 0.851440, acc.: 33.59%] [G loss: 1.091942]\n",
      "epoch:12 step:12079 [D loss: 0.956062, acc.: 25.00%] [G loss: 0.903958]\n",
      "epoch:12 step:12080 [D loss: 0.687415, acc.: 57.03%] [G loss: 0.819347]\n",
      "epoch:12 step:12081 [D loss: 0.694300, acc.: 52.34%] [G loss: 0.860688]\n",
      "epoch:12 step:12082 [D loss: 0.731997, acc.: 50.78%] [G loss: 0.870645]\n",
      "epoch:12 step:12083 [D loss: 0.758516, acc.: 41.41%] [G loss: 0.953190]\n",
      "epoch:12 step:12084 [D loss: 0.805530, acc.: 42.19%] [G loss: 1.026817]\n",
      "epoch:12 step:12085 [D loss: 0.706691, acc.: 53.91%] [G loss: 1.159332]\n",
      "epoch:12 step:12086 [D loss: 0.618674, acc.: 56.25%] [G loss: 0.892174]\n",
      "epoch:12 step:12087 [D loss: 0.818597, acc.: 36.72%] [G loss: 0.964023]\n",
      "epoch:12 step:12088 [D loss: 0.616428, acc.: 63.28%] [G loss: 1.059609]\n",
      "epoch:12 step:12089 [D loss: 0.599885, acc.: 68.75%] [G loss: 0.964360]\n",
      "epoch:12 step:12090 [D loss: 0.788473, acc.: 40.62%] [G loss: 0.943983]\n",
      "epoch:12 step:12091 [D loss: 0.688114, acc.: 53.91%] [G loss: 0.994248]\n",
      "epoch:12 step:12092 [D loss: 0.586099, acc.: 69.53%] [G loss: 1.000900]\n",
      "epoch:12 step:12093 [D loss: 0.571038, acc.: 67.19%] [G loss: 1.009509]\n",
      "epoch:12 step:12094 [D loss: 0.395765, acc.: 81.25%] [G loss: 1.015760]\n",
      "epoch:12 step:12095 [D loss: 0.352939, acc.: 92.19%] [G loss: 1.423162]\n",
      "epoch:12 step:12096 [D loss: 0.397674, acc.: 85.16%] [G loss: 1.087317]\n",
      "epoch:12 step:12097 [D loss: 0.496681, acc.: 81.25%] [G loss: 1.202118]\n",
      "epoch:12 step:12098 [D loss: 0.281347, acc.: 89.84%] [G loss: 1.250802]\n",
      "epoch:12 step:12099 [D loss: 0.557934, acc.: 71.09%] [G loss: 1.242342]\n",
      "epoch:12 step:12100 [D loss: 0.709712, acc.: 58.59%] [G loss: 1.298047]\n",
      "epoch:12 step:12101 [D loss: 0.464483, acc.: 85.94%] [G loss: 0.963967]\n",
      "epoch:12 step:12102 [D loss: 0.983767, acc.: 46.09%] [G loss: 0.968220]\n",
      "epoch:12 step:12103 [D loss: 0.865093, acc.: 39.84%] [G loss: 0.942593]\n",
      "epoch:12 step:12104 [D loss: 0.742678, acc.: 50.00%] [G loss: 0.884993]\n",
      "epoch:12 step:12105 [D loss: 0.684889, acc.: 60.16%] [G loss: 0.745072]\n",
      "epoch:12 step:12106 [D loss: 0.832027, acc.: 42.19%] [G loss: 0.881942]\n",
      "epoch:12 step:12107 [D loss: 0.664984, acc.: 57.81%] [G loss: 0.725073]\n",
      "epoch:12 step:12108 [D loss: 0.742572, acc.: 46.88%] [G loss: 0.851793]\n",
      "epoch:12 step:12109 [D loss: 0.655661, acc.: 57.81%] [G loss: 0.957284]\n",
      "epoch:12 step:12110 [D loss: 0.671590, acc.: 60.94%] [G loss: 0.892847]\n",
      "epoch:12 step:12111 [D loss: 0.578874, acc.: 66.41%] [G loss: 0.872844]\n",
      "epoch:12 step:12112 [D loss: 0.681831, acc.: 57.03%] [G loss: 0.851960]\n",
      "epoch:12 step:12113 [D loss: 0.637387, acc.: 71.09%] [G loss: 0.774110]\n",
      "epoch:12 step:12114 [D loss: 0.632492, acc.: 60.94%] [G loss: 0.924551]\n",
      "epoch:12 step:12115 [D loss: 0.679402, acc.: 54.69%] [G loss: 0.968578]\n",
      "epoch:12 step:12116 [D loss: 0.613757, acc.: 66.41%] [G loss: 0.807588]\n",
      "epoch:12 step:12117 [D loss: 0.628530, acc.: 71.09%] [G loss: 0.964596]\n",
      "epoch:12 step:12118 [D loss: 0.651965, acc.: 64.06%] [G loss: 0.883679]\n",
      "epoch:12 step:12119 [D loss: 0.617691, acc.: 68.75%] [G loss: 0.925610]\n",
      "epoch:12 step:12120 [D loss: 0.731445, acc.: 53.12%] [G loss: 0.923179]\n",
      "epoch:12 step:12121 [D loss: 0.643174, acc.: 63.28%] [G loss: 0.774630]\n",
      "epoch:12 step:12122 [D loss: 0.632100, acc.: 63.28%] [G loss: 0.940680]\n",
      "epoch:12 step:12123 [D loss: 0.680447, acc.: 60.16%] [G loss: 0.924206]\n",
      "epoch:12 step:12124 [D loss: 0.724675, acc.: 53.91%] [G loss: 0.881027]\n",
      "epoch:12 step:12125 [D loss: 0.689571, acc.: 51.56%] [G loss: 0.944230]\n",
      "epoch:12 step:12126 [D loss: 0.430418, acc.: 82.81%] [G loss: 0.956045]\n",
      "epoch:12 step:12127 [D loss: 0.419109, acc.: 84.38%] [G loss: 0.916656]\n",
      "epoch:12 step:12128 [D loss: 0.351424, acc.: 90.62%] [G loss: 1.040004]\n",
      "epoch:12 step:12129 [D loss: 0.228363, acc.: 95.31%] [G loss: 1.194401]\n",
      "epoch:12 step:12130 [D loss: 0.331075, acc.: 88.28%] [G loss: 1.159707]\n",
      "epoch:12 step:12131 [D loss: 0.371755, acc.: 89.06%] [G loss: 1.016731]\n",
      "epoch:12 step:12132 [D loss: 0.843928, acc.: 37.50%] [G loss: 1.280676]\n",
      "epoch:12 step:12133 [D loss: 0.507139, acc.: 75.78%] [G loss: 1.361425]\n",
      "epoch:12 step:12134 [D loss: 0.245679, acc.: 96.88%] [G loss: 1.019462]\n",
      "epoch:12 step:12135 [D loss: 0.864339, acc.: 43.75%] [G loss: 1.231057]\n",
      "epoch:12 step:12136 [D loss: 0.905877, acc.: 42.97%] [G loss: 0.984937]\n",
      "epoch:12 step:12137 [D loss: 0.814547, acc.: 48.44%] [G loss: 1.102690]\n",
      "epoch:12 step:12138 [D loss: 0.776463, acc.: 40.62%] [G loss: 0.983843]\n",
      "epoch:12 step:12139 [D loss: 0.703589, acc.: 58.59%] [G loss: 1.015352]\n",
      "epoch:12 step:12140 [D loss: 0.664179, acc.: 57.81%] [G loss: 0.975505]\n",
      "epoch:12 step:12141 [D loss: 0.645348, acc.: 60.94%] [G loss: 0.993114]\n",
      "epoch:12 step:12142 [D loss: 0.609370, acc.: 71.88%] [G loss: 1.017403]\n",
      "epoch:12 step:12143 [D loss: 0.528734, acc.: 78.12%] [G loss: 1.015182]\n",
      "epoch:12 step:12144 [D loss: 0.588178, acc.: 73.44%] [G loss: 1.033741]\n",
      "epoch:12 step:12145 [D loss: 0.604567, acc.: 71.09%] [G loss: 1.042425]\n",
      "epoch:12 step:12146 [D loss: 0.656899, acc.: 55.47%] [G loss: 0.983131]\n",
      "epoch:12 step:12147 [D loss: 0.623467, acc.: 70.31%] [G loss: 0.988932]\n",
      "epoch:12 step:12148 [D loss: 0.420925, acc.: 86.72%] [G loss: 0.955531]\n",
      "epoch:12 step:12149 [D loss: 0.595071, acc.: 74.22%] [G loss: 0.918289]\n",
      "epoch:12 step:12150 [D loss: 0.500269, acc.: 86.72%] [G loss: 0.938551]\n",
      "epoch:12 step:12151 [D loss: 0.690282, acc.: 55.47%] [G loss: 0.966118]\n",
      "epoch:12 step:12152 [D loss: 0.710424, acc.: 55.47%] [G loss: 0.950153]\n",
      "epoch:12 step:12153 [D loss: 0.596625, acc.: 67.97%] [G loss: 1.007135]\n",
      "epoch:12 step:12154 [D loss: 0.603082, acc.: 72.66%] [G loss: 0.581264]\n",
      "epoch:12 step:12155 [D loss: 0.583069, acc.: 64.84%] [G loss: 0.920379]\n",
      "epoch:12 step:12156 [D loss: 0.329704, acc.: 95.31%] [G loss: 1.012027]\n",
      "epoch:12 step:12157 [D loss: 0.718654, acc.: 50.78%] [G loss: 1.102025]\n",
      "epoch:12 step:12158 [D loss: 0.847860, acc.: 37.50%] [G loss: 1.109180]\n",
      "epoch:12 step:12159 [D loss: 0.718856, acc.: 55.47%] [G loss: 1.060047]\n",
      "epoch:12 step:12160 [D loss: 0.694728, acc.: 61.72%] [G loss: 0.975528]\n",
      "epoch:12 step:12161 [D loss: 0.666546, acc.: 63.28%] [G loss: 0.822986]\n",
      "epoch:12 step:12162 [D loss: 0.655766, acc.: 60.16%] [G loss: 0.855618]\n",
      "epoch:12 step:12163 [D loss: 0.551546, acc.: 72.66%] [G loss: 0.699045]\n",
      "epoch:12 step:12164 [D loss: 0.590909, acc.: 70.31%] [G loss: 1.012959]\n",
      "epoch:12 step:12165 [D loss: 0.579921, acc.: 68.75%] [G loss: 0.943857]\n",
      "epoch:12 step:12166 [D loss: 0.604474, acc.: 67.19%] [G loss: 0.978519]\n",
      "epoch:12 step:12167 [D loss: 0.520520, acc.: 79.69%] [G loss: 0.997738]\n",
      "epoch:12 step:12168 [D loss: 0.493932, acc.: 75.00%] [G loss: 0.955252]\n",
      "epoch:12 step:12169 [D loss: 0.477535, acc.: 82.81%] [G loss: 1.027208]\n",
      "epoch:12 step:12170 [D loss: 0.402105, acc.: 92.19%] [G loss: 1.012003]\n",
      "epoch:12 step:12171 [D loss: 0.489008, acc.: 84.38%] [G loss: 0.882597]\n",
      "epoch:12 step:12172 [D loss: 0.814830, acc.: 36.72%] [G loss: 1.124192]\n",
      "epoch:12 step:12173 [D loss: 0.257736, acc.: 94.53%] [G loss: 1.158537]\n",
      "epoch:12 step:12174 [D loss: 0.705112, acc.: 60.94%] [G loss: 0.943556]\n",
      "epoch:12 step:12175 [D loss: 0.594623, acc.: 68.75%] [G loss: 0.985024]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:12 step:12176 [D loss: 0.457430, acc.: 86.72%] [G loss: 0.990411]\n",
      "epoch:12 step:12177 [D loss: 0.524353, acc.: 79.69%] [G loss: 1.156208]\n",
      "epoch:12 step:12178 [D loss: 0.388579, acc.: 90.62%] [G loss: 1.108672]\n",
      "epoch:12 step:12179 [D loss: 0.405224, acc.: 89.06%] [G loss: 1.134106]\n",
      "epoch:12 step:12180 [D loss: 0.604332, acc.: 64.84%] [G loss: 1.086848]\n",
      "epoch:12 step:12181 [D loss: 0.247200, acc.: 96.88%] [G loss: 1.431769]\n",
      "epoch:13 step:12182 [D loss: 0.847887, acc.: 47.66%] [G loss: 0.734098]\n",
      "epoch:13 step:12183 [D loss: 0.723451, acc.: 54.69%] [G loss: 0.889219]\n",
      "epoch:13 step:12184 [D loss: 0.915051, acc.: 32.03%] [G loss: 0.953616]\n",
      "epoch:13 step:12185 [D loss: 0.745025, acc.: 42.19%] [G loss: 0.765779]\n",
      "epoch:13 step:12186 [D loss: 0.848548, acc.: 31.25%] [G loss: 1.077467]\n",
      "epoch:13 step:12187 [D loss: 0.769295, acc.: 46.88%] [G loss: 0.925891]\n",
      "epoch:13 step:12188 [D loss: 0.623442, acc.: 67.19%] [G loss: 0.884832]\n",
      "epoch:13 step:12189 [D loss: 0.768769, acc.: 42.19%] [G loss: 0.843533]\n",
      "epoch:13 step:12190 [D loss: 0.681603, acc.: 57.81%] [G loss: 0.904090]\n",
      "epoch:13 step:12191 [D loss: 0.890122, acc.: 32.81%] [G loss: 0.896560]\n",
      "epoch:13 step:12192 [D loss: 0.628685, acc.: 65.62%] [G loss: 0.887475]\n",
      "epoch:13 step:12193 [D loss: 0.680956, acc.: 58.59%] [G loss: 1.095213]\n",
      "epoch:13 step:12194 [D loss: 0.733981, acc.: 47.66%] [G loss: 1.067365]\n",
      "epoch:13 step:12195 [D loss: 0.695414, acc.: 51.56%] [G loss: 0.990045]\n",
      "epoch:13 step:12196 [D loss: 0.694220, acc.: 51.56%] [G loss: 1.004660]\n",
      "epoch:13 step:12197 [D loss: 0.583164, acc.: 72.66%] [G loss: 1.052956]\n",
      "epoch:13 step:12198 [D loss: 0.837181, acc.: 35.16%] [G loss: 1.068776]\n",
      "epoch:13 step:12199 [D loss: 0.627027, acc.: 67.19%] [G loss: 0.840359]\n",
      "epoch:13 step:12200 [D loss: 0.771919, acc.: 45.31%] [G loss: 0.706039]\n",
      "##############\n",
      "[4.1093619  2.29471996 6.69895029 6.10532217 4.55554638 6.51118124\n",
      " 5.52309804 5.8482723  5.86774467 5.26042576]\n",
      "##########\n",
      "epoch:13 step:12201 [D loss: 0.786347, acc.: 46.09%] [G loss: 1.132315]\n",
      "epoch:13 step:12202 [D loss: 0.650269, acc.: 62.50%] [G loss: 1.196725]\n",
      "epoch:13 step:12203 [D loss: 0.660208, acc.: 59.38%] [G loss: 1.071328]\n",
      "epoch:13 step:12204 [D loss: 0.698281, acc.: 55.47%] [G loss: 1.106842]\n",
      "epoch:13 step:12205 [D loss: 0.693032, acc.: 54.69%] [G loss: 0.955454]\n",
      "epoch:13 step:12206 [D loss: 0.644549, acc.: 60.94%] [G loss: 0.982960]\n",
      "epoch:13 step:12207 [D loss: 0.672713, acc.: 57.03%] [G loss: 1.099325]\n",
      "epoch:13 step:12208 [D loss: 0.485033, acc.: 82.03%] [G loss: 0.987212]\n",
      "epoch:13 step:12209 [D loss: 0.568713, acc.: 73.44%] [G loss: 1.269923]\n",
      "epoch:13 step:12210 [D loss: 0.594944, acc.: 69.53%] [G loss: 1.287914]\n",
      "epoch:13 step:12211 [D loss: 0.535533, acc.: 74.22%] [G loss: 1.097904]\n",
      "epoch:13 step:12212 [D loss: 0.472765, acc.: 78.91%] [G loss: 0.870677]\n",
      "epoch:13 step:12213 [D loss: 0.453323, acc.: 87.50%] [G loss: 1.109249]\n",
      "epoch:13 step:12214 [D loss: 0.345664, acc.: 88.28%] [G loss: 1.420938]\n",
      "epoch:13 step:12215 [D loss: 0.378745, acc.: 88.28%] [G loss: 1.531612]\n",
      "epoch:13 step:12216 [D loss: 0.174253, acc.: 94.53%] [G loss: 1.712261]\n",
      "epoch:13 step:12217 [D loss: 0.565621, acc.: 66.41%] [G loss: 1.491569]\n",
      "epoch:13 step:12218 [D loss: 0.703324, acc.: 59.38%] [G loss: 1.635936]\n",
      "epoch:13 step:12219 [D loss: 1.055866, acc.: 44.53%] [G loss: 1.179456]\n",
      "epoch:13 step:12220 [D loss: 0.850826, acc.: 47.66%] [G loss: 0.910240]\n",
      "epoch:13 step:12221 [D loss: 0.934286, acc.: 31.25%] [G loss: 1.068536]\n",
      "epoch:13 step:12222 [D loss: 0.685976, acc.: 56.25%] [G loss: 0.921396]\n",
      "epoch:13 step:12223 [D loss: 0.660395, acc.: 66.41%] [G loss: 0.958243]\n",
      "epoch:13 step:12224 [D loss: 0.615096, acc.: 62.50%] [G loss: 0.999133]\n",
      "epoch:13 step:12225 [D loss: 0.661358, acc.: 60.94%] [G loss: 0.872600]\n",
      "epoch:13 step:12226 [D loss: 0.729783, acc.: 49.22%] [G loss: 1.021953]\n",
      "epoch:13 step:12227 [D loss: 0.789069, acc.: 41.41%] [G loss: 0.868790]\n",
      "epoch:13 step:12228 [D loss: 0.698172, acc.: 51.56%] [G loss: 0.995058]\n",
      "epoch:13 step:12229 [D loss: 0.667836, acc.: 54.69%] [G loss: 0.963056]\n",
      "epoch:13 step:12230 [D loss: 0.807830, acc.: 49.22%] [G loss: 0.907407]\n",
      "epoch:13 step:12231 [D loss: 0.652705, acc.: 61.72%] [G loss: 0.964631]\n",
      "epoch:13 step:12232 [D loss: 0.664050, acc.: 59.38%] [G loss: 0.909746]\n",
      "epoch:13 step:12233 [D loss: 0.637315, acc.: 60.94%] [G loss: 0.996719]\n",
      "epoch:13 step:12234 [D loss: 0.689538, acc.: 58.59%] [G loss: 0.853984]\n",
      "epoch:13 step:12235 [D loss: 0.668867, acc.: 60.16%] [G loss: 0.913907]\n",
      "epoch:13 step:12236 [D loss: 0.647182, acc.: 65.62%] [G loss: 0.978597]\n",
      "epoch:13 step:12237 [D loss: 0.655049, acc.: 57.81%] [G loss: 0.906726]\n",
      "epoch:13 step:12238 [D loss: 0.653239, acc.: 60.94%] [G loss: 0.858978]\n",
      "epoch:13 step:12239 [D loss: 0.613181, acc.: 67.19%] [G loss: 0.903737]\n",
      "epoch:13 step:12240 [D loss: 0.670010, acc.: 57.03%] [G loss: 0.884361]\n",
      "epoch:13 step:12241 [D loss: 0.664784, acc.: 56.25%] [G loss: 1.086294]\n",
      "epoch:13 step:12242 [D loss: 0.681865, acc.: 57.03%] [G loss: 1.003648]\n",
      "epoch:13 step:12243 [D loss: 0.712965, acc.: 53.91%] [G loss: 0.963905]\n",
      "epoch:13 step:12244 [D loss: 0.641763, acc.: 64.84%] [G loss: 1.005808]\n",
      "epoch:13 step:12245 [D loss: 0.594757, acc.: 71.88%] [G loss: 0.949418]\n",
      "epoch:13 step:12246 [D loss: 0.663055, acc.: 55.47%] [G loss: 0.883474]\n",
      "epoch:13 step:12247 [D loss: 0.622721, acc.: 62.50%] [G loss: 0.905161]\n",
      "epoch:13 step:12248 [D loss: 0.640284, acc.: 59.38%] [G loss: 0.888946]\n",
      "epoch:13 step:12249 [D loss: 0.591262, acc.: 70.31%] [G loss: 1.001318]\n",
      "epoch:13 step:12250 [D loss: 0.624340, acc.: 67.97%] [G loss: 0.934345]\n",
      "epoch:13 step:12251 [D loss: 0.633404, acc.: 60.94%] [G loss: 0.891852]\n",
      "epoch:13 step:12252 [D loss: 0.602485, acc.: 68.75%] [G loss: 0.802191]\n",
      "epoch:13 step:12253 [D loss: 0.755880, acc.: 50.00%] [G loss: 0.926524]\n",
      "epoch:13 step:12254 [D loss: 0.657862, acc.: 59.38%] [G loss: 0.752541]\n",
      "epoch:13 step:12255 [D loss: 0.667878, acc.: 57.81%] [G loss: 0.855728]\n",
      "epoch:13 step:12256 [D loss: 0.605056, acc.: 69.53%] [G loss: 0.761458]\n",
      "epoch:13 step:12257 [D loss: 0.365076, acc.: 83.59%] [G loss: 0.895948]\n",
      "epoch:13 step:12258 [D loss: 0.391873, acc.: 85.94%] [G loss: 1.003854]\n",
      "epoch:13 step:12259 [D loss: 0.717575, acc.: 50.78%] [G loss: 0.947626]\n",
      "epoch:13 step:12260 [D loss: 0.708930, acc.: 54.69%] [G loss: 0.988002]\n",
      "epoch:13 step:12261 [D loss: 0.674983, acc.: 54.69%] [G loss: 0.928426]\n",
      "epoch:13 step:12262 [D loss: 0.687405, acc.: 59.38%] [G loss: 0.874326]\n",
      "epoch:13 step:12263 [D loss: 0.641827, acc.: 60.94%] [G loss: 0.852424]\n",
      "epoch:13 step:12264 [D loss: 0.655165, acc.: 62.50%] [G loss: 0.893818]\n",
      "epoch:13 step:12265 [D loss: 0.681565, acc.: 53.91%] [G loss: 0.851822]\n",
      "epoch:13 step:12266 [D loss: 0.645809, acc.: 60.94%] [G loss: 0.929601]\n",
      "epoch:13 step:12267 [D loss: 0.645673, acc.: 64.06%] [G loss: 0.847489]\n",
      "epoch:13 step:12268 [D loss: 0.659990, acc.: 64.84%] [G loss: 0.852034]\n",
      "epoch:13 step:12269 [D loss: 0.621489, acc.: 71.09%] [G loss: 0.910499]\n",
      "epoch:13 step:12270 [D loss: 0.609015, acc.: 71.09%] [G loss: 0.751688]\n",
      "epoch:13 step:12271 [D loss: 0.712542, acc.: 52.34%] [G loss: 0.884858]\n",
      "epoch:13 step:12272 [D loss: 0.665044, acc.: 56.25%] [G loss: 0.819167]\n",
      "epoch:13 step:12273 [D loss: 0.622009, acc.: 64.84%] [G loss: 0.762028]\n",
      "epoch:13 step:12274 [D loss: 0.576733, acc.: 71.88%] [G loss: 0.827971]\n",
      "epoch:13 step:12275 [D loss: 0.681607, acc.: 54.69%] [G loss: 0.791078]\n",
      "epoch:13 step:12276 [D loss: 0.656273, acc.: 60.16%] [G loss: 0.880480]\n",
      "epoch:13 step:12277 [D loss: 0.598457, acc.: 72.66%] [G loss: 0.912263]\n",
      "epoch:13 step:12278 [D loss: 0.563509, acc.: 71.88%] [G loss: 0.926668]\n",
      "epoch:13 step:12279 [D loss: 0.710261, acc.: 51.56%] [G loss: 0.797932]\n",
      "epoch:13 step:12280 [D loss: 0.693204, acc.: 60.16%] [G loss: 0.845674]\n",
      "epoch:13 step:12281 [D loss: 0.559051, acc.: 71.88%] [G loss: 0.786387]\n",
      "epoch:13 step:12282 [D loss: 0.707180, acc.: 54.69%] [G loss: 0.734513]\n",
      "epoch:13 step:12283 [D loss: 0.721051, acc.: 53.91%] [G loss: 0.825821]\n",
      "epoch:13 step:12284 [D loss: 0.658074, acc.: 61.72%] [G loss: 0.860340]\n",
      "epoch:13 step:12285 [D loss: 0.704818, acc.: 57.03%] [G loss: 0.858137]\n",
      "epoch:13 step:12286 [D loss: 0.541564, acc.: 75.78%] [G loss: 0.879179]\n",
      "epoch:13 step:12287 [D loss: 0.743159, acc.: 46.09%] [G loss: 0.868527]\n",
      "epoch:13 step:12288 [D loss: 0.594998, acc.: 67.19%] [G loss: 0.707728]\n",
      "epoch:13 step:12289 [D loss: 0.613584, acc.: 64.06%] [G loss: 0.929677]\n",
      "epoch:13 step:12290 [D loss: 0.652481, acc.: 60.16%] [G loss: 0.907691]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:13 step:12291 [D loss: 0.667911, acc.: 56.25%] [G loss: 0.927125]\n",
      "epoch:13 step:12292 [D loss: 0.655023, acc.: 60.16%] [G loss: 0.946515]\n",
      "epoch:13 step:12293 [D loss: 0.619640, acc.: 66.41%] [G loss: 0.879571]\n",
      "epoch:13 step:12294 [D loss: 0.608095, acc.: 68.75%] [G loss: 0.765444]\n",
      "epoch:13 step:12295 [D loss: 1.482126, acc.: 38.28%] [G loss: 0.945702]\n",
      "epoch:13 step:12296 [D loss: 0.650407, acc.: 64.06%] [G loss: 0.999736]\n",
      "epoch:13 step:12297 [D loss: 0.759673, acc.: 51.56%] [G loss: 0.825360]\n",
      "epoch:13 step:12298 [D loss: 0.673275, acc.: 58.59%] [G loss: 1.073870]\n",
      "epoch:13 step:12299 [D loss: 0.567401, acc.: 69.53%] [G loss: 1.100736]\n",
      "epoch:13 step:12300 [D loss: 0.432325, acc.: 77.34%] [G loss: 0.981623]\n",
      "epoch:13 step:12301 [D loss: 0.738929, acc.: 50.78%] [G loss: 1.040487]\n",
      "epoch:13 step:12302 [D loss: 0.676658, acc.: 58.59%] [G loss: 1.005221]\n",
      "epoch:13 step:12303 [D loss: 0.725135, acc.: 50.78%] [G loss: 0.882225]\n",
      "epoch:13 step:12304 [D loss: 0.751095, acc.: 46.88%] [G loss: 0.822445]\n",
      "epoch:13 step:12305 [D loss: 0.659680, acc.: 61.72%] [G loss: 1.099528]\n",
      "epoch:13 step:12306 [D loss: 0.718714, acc.: 50.78%] [G loss: 0.771799]\n",
      "epoch:13 step:12307 [D loss: 0.643883, acc.: 64.06%] [G loss: 0.952251]\n",
      "epoch:13 step:12308 [D loss: 0.675771, acc.: 61.72%] [G loss: 0.953922]\n",
      "epoch:13 step:12309 [D loss: 0.711301, acc.: 50.78%] [G loss: 0.928531]\n",
      "epoch:13 step:12310 [D loss: 0.689149, acc.: 55.47%] [G loss: 0.902172]\n",
      "epoch:13 step:12311 [D loss: 0.628997, acc.: 62.50%] [G loss: 0.926514]\n",
      "epoch:13 step:12312 [D loss: 0.650841, acc.: 61.72%] [G loss: 0.907480]\n",
      "epoch:13 step:12313 [D loss: 0.639800, acc.: 59.38%] [G loss: 0.989576]\n",
      "epoch:13 step:12314 [D loss: 0.578273, acc.: 68.75%] [G loss: 0.757500]\n",
      "epoch:13 step:12315 [D loss: 0.404854, acc.: 85.94%] [G loss: 1.022706]\n",
      "epoch:13 step:12316 [D loss: 0.539989, acc.: 77.34%] [G loss: 0.981071]\n",
      "epoch:13 step:12317 [D loss: 0.663276, acc.: 57.81%] [G loss: 0.999918]\n",
      "epoch:13 step:12318 [D loss: 0.670371, acc.: 60.94%] [G loss: 0.920187]\n",
      "epoch:13 step:12319 [D loss: 0.692374, acc.: 58.59%] [G loss: 0.864673]\n",
      "epoch:13 step:12320 [D loss: 0.663939, acc.: 64.06%] [G loss: 0.866736]\n",
      "epoch:13 step:12321 [D loss: 0.502962, acc.: 76.56%] [G loss: 0.884575]\n",
      "epoch:13 step:12322 [D loss: 0.587419, acc.: 72.66%] [G loss: 0.916494]\n",
      "epoch:13 step:12323 [D loss: 0.671336, acc.: 63.28%] [G loss: 0.890648]\n",
      "epoch:13 step:12324 [D loss: 0.508544, acc.: 62.50%] [G loss: 0.999167]\n",
      "epoch:13 step:12325 [D loss: 0.574723, acc.: 75.78%] [G loss: 1.050178]\n",
      "epoch:13 step:12326 [D loss: 0.414846, acc.: 83.59%] [G loss: 1.096703]\n",
      "epoch:13 step:12327 [D loss: 0.600833, acc.: 70.31%] [G loss: 0.472739]\n",
      "epoch:13 step:12328 [D loss: 0.820745, acc.: 39.84%] [G loss: 0.717600]\n",
      "epoch:13 step:12329 [D loss: 0.736489, acc.: 46.88%] [G loss: 1.048984]\n",
      "epoch:13 step:12330 [D loss: 0.286036, acc.: 94.53%] [G loss: 1.139729]\n",
      "epoch:13 step:12331 [D loss: 0.240641, acc.: 96.09%] [G loss: 1.079440]\n",
      "epoch:13 step:12332 [D loss: 0.765596, acc.: 56.25%] [G loss: 0.865491]\n",
      "epoch:13 step:12333 [D loss: 0.625330, acc.: 62.50%] [G loss: 0.967614]\n",
      "epoch:13 step:12334 [D loss: 0.797755, acc.: 43.75%] [G loss: 0.920681]\n",
      "epoch:13 step:12335 [D loss: 0.993144, acc.: 32.03%] [G loss: 1.349654]\n",
      "epoch:13 step:12336 [D loss: 0.703034, acc.: 59.38%] [G loss: 1.119717]\n",
      "epoch:13 step:12337 [D loss: 0.788100, acc.: 46.88%] [G loss: 1.679541]\n",
      "epoch:13 step:12338 [D loss: 0.639911, acc.: 54.69%] [G loss: 1.681017]\n",
      "epoch:13 step:12339 [D loss: 0.670070, acc.: 54.69%] [G loss: 2.320836]\n",
      "epoch:13 step:12340 [D loss: 0.617942, acc.: 67.19%] [G loss: 1.848041]\n",
      "epoch:13 step:12341 [D loss: 1.351252, acc.: 44.53%] [G loss: 1.120670]\n",
      "epoch:13 step:12342 [D loss: 0.657200, acc.: 60.16%] [G loss: 1.215641]\n",
      "epoch:13 step:12343 [D loss: 0.619224, acc.: 68.75%] [G loss: 1.157675]\n",
      "epoch:13 step:12344 [D loss: 0.668589, acc.: 59.38%] [G loss: 0.980135]\n",
      "epoch:13 step:12345 [D loss: 0.619052, acc.: 69.53%] [G loss: 1.076337]\n",
      "epoch:13 step:12346 [D loss: 0.677859, acc.: 59.38%] [G loss: 0.933850]\n",
      "epoch:13 step:12347 [D loss: 0.547172, acc.: 78.12%] [G loss: 0.985720]\n",
      "epoch:13 step:12348 [D loss: 0.580031, acc.: 72.66%] [G loss: 0.976835]\n",
      "epoch:13 step:12349 [D loss: 0.591100, acc.: 69.53%] [G loss: 0.959884]\n",
      "epoch:13 step:12350 [D loss: 0.614336, acc.: 71.88%] [G loss: 1.006358]\n",
      "epoch:13 step:12351 [D loss: 0.587522, acc.: 67.97%] [G loss: 0.983695]\n",
      "epoch:13 step:12352 [D loss: 0.595325, acc.: 71.88%] [G loss: 0.788946]\n",
      "epoch:13 step:12353 [D loss: 0.618152, acc.: 64.06%] [G loss: 0.889118]\n",
      "epoch:13 step:12354 [D loss: 0.569813, acc.: 71.88%] [G loss: 0.954785]\n",
      "epoch:13 step:12355 [D loss: 0.682060, acc.: 52.34%] [G loss: 0.818024]\n",
      "epoch:13 step:12356 [D loss: 0.638784, acc.: 64.84%] [G loss: 0.759722]\n",
      "epoch:13 step:12357 [D loss: 0.604372, acc.: 69.53%] [G loss: 0.831820]\n",
      "epoch:13 step:12358 [D loss: 0.742286, acc.: 46.88%] [G loss: 0.849537]\n",
      "epoch:13 step:12359 [D loss: 0.712204, acc.: 53.91%] [G loss: 0.951459]\n",
      "epoch:13 step:12360 [D loss: 0.685874, acc.: 60.16%] [G loss: 0.830764]\n",
      "epoch:13 step:12361 [D loss: 0.667890, acc.: 60.16%] [G loss: 0.831349]\n",
      "epoch:13 step:12362 [D loss: 0.677553, acc.: 57.81%] [G loss: 0.825761]\n",
      "epoch:13 step:12363 [D loss: 0.701494, acc.: 49.22%] [G loss: 0.831829]\n",
      "epoch:13 step:12364 [D loss: 0.641986, acc.: 66.41%] [G loss: 0.806170]\n",
      "epoch:13 step:12365 [D loss: 0.693680, acc.: 53.91%] [G loss: 0.869831]\n",
      "epoch:13 step:12366 [D loss: 0.723522, acc.: 50.78%] [G loss: 0.928815]\n",
      "epoch:13 step:12367 [D loss: 0.715506, acc.: 46.09%] [G loss: 0.800555]\n",
      "epoch:13 step:12368 [D loss: 0.660090, acc.: 60.16%] [G loss: 0.887113]\n",
      "epoch:13 step:12369 [D loss: 0.687084, acc.: 56.25%] [G loss: 0.805296]\n",
      "epoch:13 step:12370 [D loss: 0.680840, acc.: 59.38%] [G loss: 0.798914]\n",
      "epoch:13 step:12371 [D loss: 0.613996, acc.: 71.09%] [G loss: 0.891162]\n",
      "epoch:13 step:12372 [D loss: 0.667899, acc.: 59.38%] [G loss: 0.678482]\n",
      "epoch:13 step:12373 [D loss: 0.572454, acc.: 71.88%] [G loss: 0.915134]\n",
      "epoch:13 step:12374 [D loss: 0.688091, acc.: 54.69%] [G loss: 0.630675]\n",
      "epoch:13 step:12375 [D loss: 0.575315, acc.: 75.78%] [G loss: 0.913865]\n",
      "epoch:13 step:12376 [D loss: 0.643322, acc.: 59.38%] [G loss: 0.949996]\n",
      "epoch:13 step:12377 [D loss: 0.680447, acc.: 56.25%] [G loss: 0.875215]\n",
      "epoch:13 step:12378 [D loss: 0.687119, acc.: 60.94%] [G loss: 0.880991]\n",
      "epoch:13 step:12379 [D loss: 0.647737, acc.: 62.50%] [G loss: 0.926190]\n",
      "epoch:13 step:12380 [D loss: 0.761513, acc.: 46.09%] [G loss: 0.759483]\n",
      "epoch:13 step:12381 [D loss: 0.680152, acc.: 60.94%] [G loss: 0.928799]\n",
      "epoch:13 step:12382 [D loss: 0.569259, acc.: 70.31%] [G loss: 0.944219]\n",
      "epoch:13 step:12383 [D loss: 0.760770, acc.: 48.44%] [G loss: 0.833227]\n",
      "epoch:13 step:12384 [D loss: 0.638289, acc.: 62.50%] [G loss: 0.873983]\n",
      "epoch:13 step:12385 [D loss: 0.529348, acc.: 84.38%] [G loss: 0.806811]\n",
      "epoch:13 step:12386 [D loss: 0.629689, acc.: 64.06%] [G loss: 0.884582]\n",
      "epoch:13 step:12387 [D loss: 0.595342, acc.: 72.66%] [G loss: 0.766450]\n",
      "epoch:13 step:12388 [D loss: 0.579468, acc.: 71.88%] [G loss: 0.785547]\n",
      "epoch:13 step:12389 [D loss: 0.569197, acc.: 71.88%] [G loss: 0.976123]\n",
      "epoch:13 step:12390 [D loss: 0.579911, acc.: 69.53%] [G loss: 0.954166]\n",
      "epoch:13 step:12391 [D loss: 0.655218, acc.: 65.62%] [G loss: 0.771342]\n",
      "epoch:13 step:12392 [D loss: 0.801602, acc.: 42.97%] [G loss: 0.783219]\n",
      "epoch:13 step:12393 [D loss: 0.742578, acc.: 53.12%] [G loss: 0.860400]\n",
      "epoch:13 step:12394 [D loss: 0.738502, acc.: 49.22%] [G loss: 0.934370]\n",
      "epoch:13 step:12395 [D loss: 0.744001, acc.: 49.22%] [G loss: 0.926377]\n",
      "epoch:13 step:12396 [D loss: 0.726183, acc.: 46.88%] [G loss: 0.821484]\n",
      "epoch:13 step:12397 [D loss: 0.694878, acc.: 60.94%] [G loss: 0.940894]\n",
      "epoch:13 step:12398 [D loss: 0.700745, acc.: 57.03%] [G loss: 0.769333]\n",
      "epoch:13 step:12399 [D loss: 0.660870, acc.: 61.72%] [G loss: 0.907914]\n",
      "epoch:13 step:12400 [D loss: 0.614914, acc.: 72.66%] [G loss: 0.745083]\n",
      "##############\n",
      "[3.96302988 2.20489361 6.76341839 5.34012592 4.41381356 6.31859944\n",
      " 5.55421822 5.35949272 5.54292554 5.3776571 ]\n",
      "##########\n",
      "epoch:13 step:12401 [D loss: 0.378214, acc.: 85.94%] [G loss: 0.788267]\n",
      "epoch:13 step:12402 [D loss: 0.364907, acc.: 90.62%] [G loss: 0.914326]\n",
      "epoch:13 step:12403 [D loss: 0.544339, acc.: 78.91%] [G loss: 1.215395]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:13 step:12404 [D loss: 0.609543, acc.: 73.44%] [G loss: 1.120550]\n",
      "epoch:13 step:12405 [D loss: 0.737105, acc.: 53.91%] [G loss: 1.146007]\n",
      "epoch:13 step:12406 [D loss: 0.646016, acc.: 57.03%] [G loss: 1.068950]\n",
      "epoch:13 step:12407 [D loss: 0.633197, acc.: 64.84%] [G loss: 0.971008]\n",
      "epoch:13 step:12408 [D loss: 0.640820, acc.: 64.06%] [G loss: 0.945621]\n",
      "epoch:13 step:12409 [D loss: 0.618714, acc.: 65.62%] [G loss: 1.066052]\n",
      "epoch:13 step:12410 [D loss: 0.587837, acc.: 67.97%] [G loss: 1.051693]\n",
      "epoch:13 step:12411 [D loss: 0.252546, acc.: 87.50%] [G loss: 1.203101]\n",
      "epoch:13 step:12412 [D loss: 0.302211, acc.: 91.41%] [G loss: 1.115784]\n",
      "epoch:13 step:12413 [D loss: 0.273869, acc.: 89.84%] [G loss: 1.433305]\n",
      "epoch:13 step:12414 [D loss: 0.598504, acc.: 74.22%] [G loss: 1.040833]\n",
      "epoch:13 step:12415 [D loss: 0.407240, acc.: 86.72%] [G loss: 1.304520]\n",
      "epoch:13 step:12416 [D loss: 0.415412, acc.: 89.06%] [G loss: 1.221546]\n",
      "epoch:13 step:12417 [D loss: 0.583016, acc.: 69.53%] [G loss: 0.760035]\n",
      "epoch:13 step:12418 [D loss: 0.336788, acc.: 90.62%] [G loss: 1.025224]\n",
      "epoch:13 step:12419 [D loss: 0.409647, acc.: 84.38%] [G loss: 0.923270]\n",
      "epoch:13 step:12420 [D loss: 0.622572, acc.: 66.41%] [G loss: 0.831568]\n",
      "epoch:13 step:12421 [D loss: 0.615343, acc.: 66.41%] [G loss: 0.844076]\n",
      "epoch:13 step:12422 [D loss: 0.874110, acc.: 32.81%] [G loss: 0.812568]\n",
      "epoch:13 step:12423 [D loss: 0.556502, acc.: 70.31%] [G loss: 0.848407]\n",
      "epoch:13 step:12424 [D loss: 0.615269, acc.: 67.19%] [G loss: 0.665580]\n",
      "epoch:13 step:12425 [D loss: 0.857098, acc.: 37.50%] [G loss: 0.661412]\n",
      "epoch:13 step:12426 [D loss: 0.855496, acc.: 38.28%] [G loss: 0.794104]\n",
      "epoch:13 step:12427 [D loss: 0.926295, acc.: 35.16%] [G loss: 0.878419]\n",
      "epoch:13 step:12428 [D loss: 0.768616, acc.: 46.88%] [G loss: 0.617073]\n",
      "epoch:13 step:12429 [D loss: 0.996777, acc.: 30.47%] [G loss: 0.858090]\n",
      "epoch:13 step:12430 [D loss: 0.702520, acc.: 56.25%] [G loss: 1.225482]\n",
      "epoch:13 step:12431 [D loss: 0.730762, acc.: 51.56%] [G loss: 1.320554]\n",
      "epoch:13 step:12432 [D loss: 0.708293, acc.: 54.69%] [G loss: 1.191209]\n",
      "epoch:13 step:12433 [D loss: 0.733653, acc.: 50.00%] [G loss: 1.173091]\n",
      "epoch:13 step:12434 [D loss: 0.646522, acc.: 60.94%] [G loss: 1.348811]\n",
      "epoch:13 step:12435 [D loss: 0.670520, acc.: 57.03%] [G loss: 0.870505]\n",
      "epoch:13 step:12436 [D loss: 0.547898, acc.: 75.00%] [G loss: 0.974476]\n",
      "epoch:13 step:12437 [D loss: 0.396215, acc.: 82.81%] [G loss: 0.766490]\n",
      "epoch:13 step:12438 [D loss: 0.782051, acc.: 42.97%] [G loss: 0.965891]\n",
      "epoch:13 step:12439 [D loss: 0.694300, acc.: 53.12%] [G loss: 0.972474]\n",
      "epoch:13 step:12440 [D loss: 0.494492, acc.: 72.66%] [G loss: 1.112281]\n",
      "epoch:13 step:12441 [D loss: 0.778831, acc.: 53.91%] [G loss: 1.147637]\n",
      "epoch:13 step:12442 [D loss: 0.537079, acc.: 75.78%] [G loss: 0.967497]\n",
      "epoch:13 step:12443 [D loss: 0.627432, acc.: 64.84%] [G loss: 1.287543]\n",
      "epoch:13 step:12444 [D loss: 0.657513, acc.: 55.47%] [G loss: 1.134849]\n",
      "epoch:13 step:12445 [D loss: 0.586184, acc.: 68.75%] [G loss: 1.144604]\n",
      "epoch:13 step:12446 [D loss: 0.681793, acc.: 62.50%] [G loss: 1.205195]\n",
      "epoch:13 step:12447 [D loss: 0.623583, acc.: 64.84%] [G loss: 1.108546]\n",
      "epoch:13 step:12448 [D loss: 0.636073, acc.: 60.94%] [G loss: 0.869005]\n",
      "epoch:13 step:12449 [D loss: 0.632708, acc.: 64.06%] [G loss: 0.747078]\n",
      "epoch:13 step:12450 [D loss: 0.562411, acc.: 71.09%] [G loss: 1.132418]\n",
      "epoch:13 step:12451 [D loss: 0.590990, acc.: 68.75%] [G loss: 1.025671]\n",
      "epoch:13 step:12452 [D loss: 0.594888, acc.: 66.41%] [G loss: 1.338223]\n",
      "epoch:13 step:12453 [D loss: 0.479814, acc.: 85.16%] [G loss: 1.170115]\n",
      "epoch:13 step:12454 [D loss: 0.428814, acc.: 88.28%] [G loss: 1.429929]\n",
      "epoch:13 step:12455 [D loss: 0.470869, acc.: 76.56%] [G loss: 1.540922]\n",
      "epoch:13 step:12456 [D loss: 0.518676, acc.: 82.81%] [G loss: 1.129208]\n",
      "epoch:13 step:12457 [D loss: 0.527636, acc.: 78.91%] [G loss: 1.136181]\n",
      "epoch:13 step:12458 [D loss: 0.725369, acc.: 49.22%] [G loss: 1.309782]\n",
      "epoch:13 step:12459 [D loss: 1.019880, acc.: 39.06%] [G loss: 0.832135]\n",
      "epoch:13 step:12460 [D loss: 0.608805, acc.: 64.84%] [G loss: 0.857712]\n",
      "epoch:13 step:12461 [D loss: 0.675503, acc.: 53.12%] [G loss: 0.891520]\n",
      "epoch:13 step:12462 [D loss: 0.597415, acc.: 68.75%] [G loss: 0.936322]\n",
      "epoch:13 step:12463 [D loss: 0.542775, acc.: 82.81%] [G loss: 0.840162]\n",
      "epoch:13 step:12464 [D loss: 0.646138, acc.: 59.38%] [G loss: 0.912536]\n",
      "epoch:13 step:12465 [D loss: 0.737401, acc.: 48.44%] [G loss: 0.986925]\n",
      "epoch:13 step:12466 [D loss: 0.627578, acc.: 62.50%] [G loss: 0.801175]\n",
      "epoch:13 step:12467 [D loss: 0.724969, acc.: 58.59%] [G loss: 0.902134]\n",
      "epoch:13 step:12468 [D loss: 0.613226, acc.: 67.97%] [G loss: 1.069195]\n",
      "epoch:13 step:12469 [D loss: 0.691725, acc.: 53.12%] [G loss: 0.855098]\n",
      "epoch:13 step:12470 [D loss: 0.506561, acc.: 81.25%] [G loss: 0.910616]\n",
      "epoch:13 step:12471 [D loss: 0.450000, acc.: 82.81%] [G loss: 1.012657]\n",
      "epoch:13 step:12472 [D loss: 0.697696, acc.: 59.38%] [G loss: 0.779144]\n",
      "epoch:13 step:12473 [D loss: 0.513301, acc.: 77.34%] [G loss: 0.869898]\n",
      "epoch:13 step:12474 [D loss: 0.446944, acc.: 78.12%] [G loss: 0.901324]\n",
      "epoch:13 step:12475 [D loss: 0.775536, acc.: 49.22%] [G loss: 0.968070]\n",
      "epoch:13 step:12476 [D loss: 0.704881, acc.: 58.59%] [G loss: 0.873274]\n",
      "epoch:13 step:12477 [D loss: 0.661650, acc.: 58.59%] [G loss: 0.930381]\n",
      "epoch:13 step:12478 [D loss: 0.686557, acc.: 50.78%] [G loss: 0.839317]\n",
      "epoch:13 step:12479 [D loss: 0.652775, acc.: 57.81%] [G loss: 0.870382]\n",
      "epoch:13 step:12480 [D loss: 0.655913, acc.: 60.16%] [G loss: 0.797693]\n",
      "epoch:13 step:12481 [D loss: 0.684386, acc.: 53.91%] [G loss: 0.838934]\n",
      "epoch:13 step:12482 [D loss: 0.938083, acc.: 39.06%] [G loss: 0.922303]\n",
      "epoch:13 step:12483 [D loss: 0.677707, acc.: 61.72%] [G loss: 0.884302]\n",
      "epoch:13 step:12484 [D loss: 0.666117, acc.: 54.69%] [G loss: 0.969580]\n",
      "epoch:13 step:12485 [D loss: 0.766834, acc.: 42.19%] [G loss: 0.897159]\n",
      "epoch:13 step:12486 [D loss: 0.671384, acc.: 62.50%] [G loss: 0.894173]\n",
      "epoch:13 step:12487 [D loss: 0.756221, acc.: 49.22%] [G loss: 0.922760]\n",
      "epoch:13 step:12488 [D loss: 0.664561, acc.: 56.25%] [G loss: 0.804561]\n",
      "epoch:13 step:12489 [D loss: 0.780615, acc.: 39.06%] [G loss: 0.764006]\n",
      "epoch:13 step:12490 [D loss: 0.521883, acc.: 75.78%] [G loss: 0.857102]\n",
      "epoch:13 step:12491 [D loss: 0.681669, acc.: 50.78%] [G loss: 0.949996]\n",
      "epoch:13 step:12492 [D loss: 0.649703, acc.: 67.19%] [G loss: 0.894843]\n",
      "epoch:13 step:12493 [D loss: 0.486884, acc.: 71.09%] [G loss: 0.858821]\n",
      "epoch:13 step:12494 [D loss: 0.375237, acc.: 85.16%] [G loss: 1.041737]\n",
      "epoch:13 step:12495 [D loss: 0.283656, acc.: 92.19%] [G loss: 1.098757]\n",
      "epoch:13 step:12496 [D loss: 0.535034, acc.: 81.25%] [G loss: 1.028059]\n",
      "epoch:13 step:12497 [D loss: 0.719078, acc.: 54.69%] [G loss: 0.816410]\n",
      "epoch:13 step:12498 [D loss: 0.726199, acc.: 54.69%] [G loss: 1.045020]\n",
      "epoch:13 step:12499 [D loss: 0.865660, acc.: 31.25%] [G loss: 1.035703]\n",
      "epoch:13 step:12500 [D loss: 0.660237, acc.: 55.47%] [G loss: 1.031919]\n",
      "epoch:13 step:12501 [D loss: 0.643404, acc.: 61.72%] [G loss: 1.017185]\n",
      "epoch:13 step:12502 [D loss: 0.655609, acc.: 57.81%] [G loss: 0.980281]\n",
      "epoch:13 step:12503 [D loss: 0.642817, acc.: 64.06%] [G loss: 1.013245]\n",
      "epoch:13 step:12504 [D loss: 0.753523, acc.: 50.78%] [G loss: 0.817252]\n",
      "epoch:13 step:12505 [D loss: 0.743322, acc.: 50.78%] [G loss: 0.806572]\n",
      "epoch:13 step:12506 [D loss: 0.667892, acc.: 60.94%] [G loss: 0.796093]\n",
      "epoch:13 step:12507 [D loss: 0.656335, acc.: 65.62%] [G loss: 0.831521]\n",
      "epoch:13 step:12508 [D loss: 0.526144, acc.: 85.16%] [G loss: 0.725224]\n",
      "epoch:13 step:12509 [D loss: 0.566459, acc.: 75.00%] [G loss: 0.876136]\n",
      "epoch:13 step:12510 [D loss: 0.665319, acc.: 50.00%] [G loss: 1.054141]\n",
      "epoch:13 step:12511 [D loss: 0.651243, acc.: 64.84%] [G loss: 0.863197]\n",
      "epoch:13 step:12512 [D loss: 0.746568, acc.: 42.19%] [G loss: 0.823432]\n",
      "epoch:13 step:12513 [D loss: 0.689430, acc.: 53.12%] [G loss: 0.743384]\n",
      "epoch:13 step:12514 [D loss: 0.624488, acc.: 65.62%] [G loss: 0.853471]\n",
      "epoch:13 step:12515 [D loss: 0.481384, acc.: 74.22%] [G loss: 0.976229]\n",
      "epoch:13 step:12516 [D loss: 0.713543, acc.: 57.81%] [G loss: 0.944988]\n",
      "epoch:13 step:12517 [D loss: 0.421123, acc.: 80.47%] [G loss: 0.918616]\n",
      "epoch:13 step:12518 [D loss: 0.597059, acc.: 72.66%] [G loss: 0.843704]\n",
      "epoch:13 step:12519 [D loss: 0.616033, acc.: 67.97%] [G loss: 0.818682]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:13 step:12520 [D loss: 0.613110, acc.: 67.19%] [G loss: 0.865515]\n",
      "epoch:13 step:12521 [D loss: 0.729893, acc.: 48.44%] [G loss: 0.852854]\n",
      "epoch:13 step:12522 [D loss: 0.754835, acc.: 39.84%] [G loss: 0.899070]\n",
      "epoch:13 step:12523 [D loss: 0.550317, acc.: 69.53%] [G loss: 0.936145]\n",
      "epoch:13 step:12524 [D loss: 0.353349, acc.: 85.16%] [G loss: 1.032555]\n",
      "epoch:13 step:12525 [D loss: 0.447931, acc.: 89.06%] [G loss: 1.025087]\n",
      "epoch:13 step:12526 [D loss: 0.507022, acc.: 75.78%] [G loss: 1.055641]\n",
      "epoch:13 step:12527 [D loss: 0.259170, acc.: 92.97%] [G loss: 0.766745]\n",
      "epoch:13 step:12528 [D loss: 0.242726, acc.: 96.88%] [G loss: 1.120803]\n",
      "epoch:13 step:12529 [D loss: 0.731680, acc.: 54.69%] [G loss: 1.097839]\n",
      "epoch:13 step:12530 [D loss: 0.725373, acc.: 53.91%] [G loss: 1.016011]\n",
      "epoch:13 step:12531 [D loss: 0.569044, acc.: 73.44%] [G loss: 0.983221]\n",
      "epoch:13 step:12532 [D loss: 0.812352, acc.: 35.94%] [G loss: 1.038433]\n",
      "epoch:13 step:12533 [D loss: 0.700052, acc.: 53.91%] [G loss: 0.985311]\n",
      "epoch:13 step:12534 [D loss: 0.669179, acc.: 54.69%] [G loss: 0.997366]\n",
      "epoch:13 step:12535 [D loss: 0.660274, acc.: 62.50%] [G loss: 0.971354]\n",
      "epoch:13 step:12536 [D loss: 0.752108, acc.: 53.12%] [G loss: 1.024796]\n",
      "epoch:13 step:12537 [D loss: 0.649556, acc.: 67.97%] [G loss: 0.933832]\n",
      "epoch:13 step:12538 [D loss: 0.622878, acc.: 71.09%] [G loss: 1.008307]\n",
      "epoch:13 step:12539 [D loss: 0.634260, acc.: 64.06%] [G loss: 0.481409]\n",
      "epoch:13 step:12540 [D loss: 0.640789, acc.: 60.94%] [G loss: 1.011844]\n",
      "epoch:13 step:12541 [D loss: 0.633346, acc.: 64.06%] [G loss: 0.966744]\n",
      "epoch:13 step:12542 [D loss: 0.581167, acc.: 71.88%] [G loss: 1.143832]\n",
      "epoch:13 step:12543 [D loss: 0.613023, acc.: 68.75%] [G loss: 0.977312]\n",
      "epoch:13 step:12544 [D loss: 0.589452, acc.: 75.00%] [G loss: 0.870293]\n",
      "epoch:13 step:12545 [D loss: 0.639168, acc.: 62.50%] [G loss: 0.735357]\n",
      "epoch:13 step:12546 [D loss: 0.469688, acc.: 81.25%] [G loss: 0.833809]\n",
      "epoch:13 step:12547 [D loss: 0.292879, acc.: 90.62%] [G loss: 0.936451]\n",
      "epoch:13 step:12548 [D loss: 0.671133, acc.: 57.81%] [G loss: 0.825819]\n",
      "epoch:13 step:12549 [D loss: 0.761028, acc.: 39.84%] [G loss: 0.998103]\n",
      "epoch:13 step:12550 [D loss: 0.957486, acc.: 21.88%] [G loss: 1.035556]\n",
      "epoch:13 step:12551 [D loss: 0.598493, acc.: 67.97%] [G loss: 0.942012]\n",
      "epoch:13 step:12552 [D loss: 0.564884, acc.: 69.53%] [G loss: 1.070718]\n",
      "epoch:13 step:12553 [D loss: 0.657307, acc.: 65.62%] [G loss: 0.970366]\n",
      "epoch:13 step:12554 [D loss: 0.746724, acc.: 51.56%] [G loss: 1.085834]\n",
      "epoch:13 step:12555 [D loss: 0.646370, acc.: 57.81%] [G loss: 1.052043]\n",
      "epoch:13 step:12556 [D loss: 0.656694, acc.: 60.94%] [G loss: 0.745944]\n",
      "epoch:13 step:12557 [D loss: 1.005068, acc.: 33.59%] [G loss: 0.985269]\n",
      "epoch:13 step:12558 [D loss: 0.584772, acc.: 74.22%] [G loss: 0.787126]\n",
      "epoch:13 step:12559 [D loss: 0.534575, acc.: 78.91%] [G loss: 1.014750]\n",
      "epoch:13 step:12560 [D loss: 0.606544, acc.: 68.75%] [G loss: 0.906007]\n",
      "epoch:13 step:12561 [D loss: 0.592767, acc.: 67.97%] [G loss: 1.075055]\n",
      "epoch:13 step:12562 [D loss: 0.528058, acc.: 78.91%] [G loss: 1.103845]\n",
      "epoch:13 step:12563 [D loss: 0.656625, acc.: 56.25%] [G loss: 1.005198]\n",
      "epoch:13 step:12564 [D loss: 0.747666, acc.: 48.44%] [G loss: 1.032481]\n",
      "epoch:13 step:12565 [D loss: 0.908795, acc.: 31.25%] [G loss: 1.042326]\n",
      "epoch:13 step:12566 [D loss: 0.615233, acc.: 67.19%] [G loss: 0.864332]\n",
      "epoch:13 step:12567 [D loss: 0.607119, acc.: 67.19%] [G loss: 0.842731]\n",
      "epoch:13 step:12568 [D loss: 0.545569, acc.: 78.91%] [G loss: 1.034022]\n",
      "epoch:13 step:12569 [D loss: 0.639815, acc.: 67.19%] [G loss: 0.756521]\n",
      "epoch:13 step:12570 [D loss: 0.640151, acc.: 58.59%] [G loss: 1.262239]\n",
      "epoch:13 step:12571 [D loss: 0.824668, acc.: 39.06%] [G loss: 0.889435]\n",
      "epoch:13 step:12572 [D loss: 0.771205, acc.: 42.97%] [G loss: 0.908025]\n",
      "epoch:13 step:12573 [D loss: 0.727213, acc.: 45.31%] [G loss: 0.846658]\n",
      "epoch:13 step:12574 [D loss: 0.749439, acc.: 47.66%] [G loss: 0.899544]\n",
      "epoch:13 step:12575 [D loss: 0.771907, acc.: 39.84%] [G loss: 0.923854]\n",
      "epoch:13 step:12576 [D loss: 0.758418, acc.: 49.22%] [G loss: 0.793642]\n",
      "epoch:13 step:12577 [D loss: 0.590705, acc.: 66.41%] [G loss: 0.897761]\n",
      "epoch:13 step:12578 [D loss: 0.411803, acc.: 80.47%] [G loss: 0.899002]\n",
      "epoch:13 step:12579 [D loss: 0.439417, acc.: 81.25%] [G loss: 1.116589]\n",
      "epoch:13 step:12580 [D loss: 0.331969, acc.: 78.91%] [G loss: 1.077055]\n",
      "epoch:13 step:12581 [D loss: 0.593562, acc.: 73.44%] [G loss: 1.053464]\n",
      "epoch:13 step:12582 [D loss: 0.566233, acc.: 71.88%] [G loss: 1.068713]\n",
      "epoch:13 step:12583 [D loss: 0.382636, acc.: 81.25%] [G loss: 1.002679]\n",
      "epoch:13 step:12584 [D loss: 0.598121, acc.: 70.31%] [G loss: 1.071695]\n",
      "epoch:13 step:12585 [D loss: 0.409298, acc.: 90.62%] [G loss: 0.948143]\n",
      "epoch:13 step:12586 [D loss: 0.301706, acc.: 90.62%] [G loss: 1.069991]\n",
      "epoch:13 step:12587 [D loss: 0.321845, acc.: 92.19%] [G loss: 1.094129]\n",
      "epoch:13 step:12588 [D loss: 0.262055, acc.: 93.75%] [G loss: 0.888581]\n",
      "epoch:13 step:12589 [D loss: 0.403450, acc.: 90.62%] [G loss: 1.238970]\n",
      "epoch:13 step:12590 [D loss: 0.292195, acc.: 92.19%] [G loss: 0.634073]\n",
      "epoch:13 step:12591 [D loss: 0.991412, acc.: 42.19%] [G loss: 1.369720]\n",
      "epoch:13 step:12592 [D loss: 0.971841, acc.: 32.03%] [G loss: 0.737109]\n",
      "epoch:13 step:12593 [D loss: 0.722581, acc.: 66.41%] [G loss: 1.277136]\n",
      "epoch:13 step:12594 [D loss: 0.650543, acc.: 62.50%] [G loss: 1.227153]\n",
      "epoch:13 step:12595 [D loss: 0.585805, acc.: 73.44%] [G loss: 1.118893]\n",
      "epoch:13 step:12596 [D loss: 0.613876, acc.: 67.19%] [G loss: 1.148708]\n",
      "epoch:13 step:12597 [D loss: 0.563261, acc.: 73.44%] [G loss: 0.675115]\n",
      "epoch:13 step:12598 [D loss: 0.710184, acc.: 53.91%] [G loss: 0.366526]\n",
      "epoch:13 step:12599 [D loss: 0.470874, acc.: 72.66%] [G loss: 1.221704]\n",
      "epoch:13 step:12600 [D loss: 0.212765, acc.: 99.22%] [G loss: 1.530280]\n",
      "##############\n",
      "[4.28852622 2.07321662 6.40337047 5.43689925 4.75513263 6.13396245\n",
      " 5.46931854 5.34422192 5.64994503 4.9323027 ]\n",
      "##########\n",
      "epoch:13 step:12601 [D loss: 0.727830, acc.: 54.69%] [G loss: 1.079107]\n",
      "epoch:13 step:12602 [D loss: 0.848571, acc.: 50.00%] [G loss: 0.716695]\n",
      "epoch:13 step:12603 [D loss: 0.797724, acc.: 50.78%] [G loss: 1.145505]\n",
      "epoch:13 step:12604 [D loss: 0.569249, acc.: 68.75%] [G loss: 0.824292]\n",
      "epoch:13 step:12605 [D loss: 1.103079, acc.: 55.47%] [G loss: 1.292043]\n",
      "epoch:13 step:12606 [D loss: 0.434384, acc.: 85.94%] [G loss: 1.462973]\n",
      "epoch:13 step:12607 [D loss: 0.744737, acc.: 53.12%] [G loss: 1.381478]\n",
      "epoch:13 step:12608 [D loss: 0.371736, acc.: 91.41%] [G loss: 1.289941]\n",
      "epoch:13 step:12609 [D loss: 0.273857, acc.: 94.53%] [G loss: 0.817836]\n",
      "epoch:13 step:12610 [D loss: 1.030284, acc.: 48.44%] [G loss: 1.496707]\n",
      "epoch:13 step:12611 [D loss: 0.344908, acc.: 92.97%] [G loss: 1.228480]\n",
      "epoch:13 step:12612 [D loss: 0.582283, acc.: 71.88%] [G loss: 0.960352]\n",
      "epoch:13 step:12613 [D loss: 0.741370, acc.: 50.00%] [G loss: 1.142014]\n",
      "epoch:13 step:12614 [D loss: 0.620063, acc.: 64.84%] [G loss: 1.334131]\n",
      "epoch:13 step:12615 [D loss: 0.927058, acc.: 32.03%] [G loss: 0.794400]\n",
      "epoch:13 step:12616 [D loss: 0.841352, acc.: 43.75%] [G loss: 0.870157]\n",
      "epoch:13 step:12617 [D loss: 0.794006, acc.: 50.00%] [G loss: 1.212118]\n",
      "epoch:13 step:12618 [D loss: 0.711842, acc.: 53.91%] [G loss: 1.378822]\n",
      "epoch:13 step:12619 [D loss: 0.649675, acc.: 63.28%] [G loss: 1.061404]\n",
      "epoch:13 step:12620 [D loss: 0.803388, acc.: 41.41%] [G loss: 1.089037]\n",
      "epoch:13 step:12621 [D loss: 0.825136, acc.: 41.41%] [G loss: 1.296681]\n",
      "epoch:13 step:12622 [D loss: 0.701366, acc.: 59.38%] [G loss: 1.129984]\n",
      "epoch:13 step:12623 [D loss: 0.651082, acc.: 67.19%] [G loss: 1.008606]\n",
      "epoch:13 step:12624 [D loss: 0.690906, acc.: 52.34%] [G loss: 1.037629]\n",
      "epoch:13 step:12625 [D loss: 0.651408, acc.: 64.06%] [G loss: 1.182405]\n",
      "epoch:13 step:12626 [D loss: 0.697004, acc.: 58.59%] [G loss: 1.020749]\n",
      "epoch:13 step:12627 [D loss: 0.732750, acc.: 46.09%] [G loss: 0.936998]\n",
      "epoch:13 step:12628 [D loss: 0.690317, acc.: 51.56%] [G loss: 0.838270]\n",
      "epoch:13 step:12629 [D loss: 0.525465, acc.: 77.34%] [G loss: 1.064416]\n",
      "epoch:13 step:12630 [D loss: 0.547255, acc.: 75.00%] [G loss: 1.252130]\n",
      "epoch:13 step:12631 [D loss: 0.468004, acc.: 83.59%] [G loss: 1.212877]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:13 step:12632 [D loss: 0.425516, acc.: 84.38%] [G loss: 1.409188]\n",
      "epoch:13 step:12633 [D loss: 0.380514, acc.: 89.84%] [G loss: 1.456507]\n",
      "epoch:13 step:12634 [D loss: 0.418462, acc.: 85.16%] [G loss: 1.229405]\n",
      "epoch:13 step:12635 [D loss: 0.491222, acc.: 78.12%] [G loss: 0.996902]\n",
      "epoch:13 step:12636 [D loss: 0.417934, acc.: 88.28%] [G loss: 1.383857]\n",
      "epoch:13 step:12637 [D loss: 0.397151, acc.: 89.06%] [G loss: 1.019673]\n",
      "epoch:13 step:12638 [D loss: 0.396580, acc.: 89.06%] [G loss: 1.381432]\n",
      "epoch:13 step:12639 [D loss: 0.737697, acc.: 52.34%] [G loss: 1.010201]\n",
      "epoch:13 step:12640 [D loss: 0.735059, acc.: 54.69%] [G loss: 0.979609]\n",
      "epoch:13 step:12641 [D loss: 0.748534, acc.: 49.22%] [G loss: 1.240127]\n",
      "epoch:13 step:12642 [D loss: 0.974407, acc.: 27.34%] [G loss: 0.784307]\n",
      "epoch:13 step:12643 [D loss: 0.986673, acc.: 24.22%] [G loss: 0.923891]\n",
      "epoch:13 step:12644 [D loss: 0.744061, acc.: 53.91%] [G loss: 0.755180]\n",
      "epoch:13 step:12645 [D loss: 0.711032, acc.: 57.81%] [G loss: 0.909397]\n",
      "epoch:13 step:12646 [D loss: 0.540477, acc.: 76.56%] [G loss: 0.926412]\n",
      "epoch:13 step:12647 [D loss: 0.535640, acc.: 76.56%] [G loss: 1.116673]\n",
      "epoch:13 step:12648 [D loss: 0.596967, acc.: 71.09%] [G loss: 0.936937]\n",
      "epoch:13 step:12649 [D loss: 0.519428, acc.: 74.22%] [G loss: 1.240186]\n",
      "epoch:13 step:12650 [D loss: 0.532632, acc.: 78.12%] [G loss: 1.055535]\n",
      "epoch:13 step:12651 [D loss: 0.514379, acc.: 78.12%] [G loss: 1.157113]\n",
      "epoch:13 step:12652 [D loss: 0.529291, acc.: 76.56%] [G loss: 0.987148]\n",
      "epoch:13 step:12653 [D loss: 0.749004, acc.: 43.75%] [G loss: 1.299485]\n",
      "epoch:13 step:12654 [D loss: 0.816763, acc.: 49.22%] [G loss: 1.175385]\n",
      "epoch:13 step:12655 [D loss: 0.651188, acc.: 64.84%] [G loss: 1.608891]\n",
      "epoch:13 step:12656 [D loss: 0.632722, acc.: 66.41%] [G loss: 1.137398]\n",
      "epoch:13 step:12657 [D loss: 0.611943, acc.: 64.84%] [G loss: 1.144653]\n",
      "epoch:13 step:12658 [D loss: 0.770471, acc.: 54.69%] [G loss: 1.139430]\n",
      "epoch:13 step:12659 [D loss: 0.670649, acc.: 64.06%] [G loss: 1.287984]\n",
      "epoch:13 step:12660 [D loss: 0.626242, acc.: 69.53%] [G loss: 1.262912]\n",
      "epoch:13 step:12661 [D loss: 0.610264, acc.: 62.50%] [G loss: 1.029044]\n",
      "epoch:13 step:12662 [D loss: 0.614449, acc.: 63.28%] [G loss: 0.989910]\n",
      "epoch:13 step:12663 [D loss: 0.602251, acc.: 62.50%] [G loss: 0.970758]\n",
      "epoch:13 step:12664 [D loss: 0.617093, acc.: 67.19%] [G loss: 0.998903]\n",
      "epoch:13 step:12665 [D loss: 0.403973, acc.: 85.94%] [G loss: 1.188540]\n",
      "epoch:13 step:12666 [D loss: 0.589942, acc.: 70.31%] [G loss: 1.119715]\n",
      "epoch:13 step:12667 [D loss: 0.611926, acc.: 71.09%] [G loss: 0.961207]\n",
      "epoch:13 step:12668 [D loss: 0.584180, acc.: 67.19%] [G loss: 1.281460]\n",
      "epoch:13 step:12669 [D loss: 0.615548, acc.: 70.31%] [G loss: 1.185786]\n",
      "epoch:13 step:12670 [D loss: 0.888298, acc.: 40.62%] [G loss: 0.923182]\n",
      "epoch:13 step:12671 [D loss: 0.771730, acc.: 42.97%] [G loss: 0.759845]\n",
      "epoch:13 step:12672 [D loss: 0.697176, acc.: 53.12%] [G loss: 0.910553]\n",
      "epoch:13 step:12673 [D loss: 0.594407, acc.: 71.88%] [G loss: 0.797439]\n",
      "epoch:13 step:12674 [D loss: 0.710980, acc.: 50.00%] [G loss: 0.850998]\n",
      "epoch:13 step:12675 [D loss: 0.704272, acc.: 52.34%] [G loss: 0.928823]\n",
      "epoch:13 step:12676 [D loss: 0.687439, acc.: 52.34%] [G loss: 1.030039]\n",
      "epoch:13 step:12677 [D loss: 0.596913, acc.: 71.09%] [G loss: 0.944452]\n",
      "epoch:13 step:12678 [D loss: 0.541568, acc.: 80.47%] [G loss: 0.895296]\n",
      "epoch:13 step:12679 [D loss: 0.443081, acc.: 77.34%] [G loss: 0.948297]\n",
      "epoch:13 step:12680 [D loss: 0.353720, acc.: 87.50%] [G loss: 1.093893]\n",
      "epoch:13 step:12681 [D loss: 0.767465, acc.: 50.78%] [G loss: 1.054284]\n",
      "epoch:13 step:12682 [D loss: 0.726688, acc.: 56.25%] [G loss: 0.987593]\n",
      "epoch:13 step:12683 [D loss: 0.728528, acc.: 45.31%] [G loss: 1.035374]\n",
      "epoch:13 step:12684 [D loss: 0.670777, acc.: 60.16%] [G loss: 0.985368]\n",
      "epoch:13 step:12685 [D loss: 0.614722, acc.: 65.62%] [G loss: 1.060112]\n",
      "epoch:13 step:12686 [D loss: 0.582321, acc.: 69.53%] [G loss: 1.120975]\n",
      "epoch:13 step:12687 [D loss: 0.600937, acc.: 73.44%] [G loss: 1.097379]\n",
      "epoch:13 step:12688 [D loss: 0.527479, acc.: 77.34%] [G loss: 1.111007]\n",
      "epoch:13 step:12689 [D loss: 0.624485, acc.: 60.94%] [G loss: 1.086886]\n",
      "epoch:13 step:12690 [D loss: 0.670255, acc.: 57.03%] [G loss: 1.169324]\n",
      "epoch:13 step:12691 [D loss: 0.476583, acc.: 78.91%] [G loss: 1.024511]\n",
      "epoch:13 step:12692 [D loss: 0.472230, acc.: 80.47%] [G loss: 1.118820]\n",
      "epoch:13 step:12693 [D loss: 0.410672, acc.: 81.25%] [G loss: 1.101800]\n",
      "epoch:13 step:12694 [D loss: 0.356478, acc.: 83.59%] [G loss: 1.138315]\n",
      "epoch:13 step:12695 [D loss: 0.587147, acc.: 74.22%] [G loss: 0.996159]\n",
      "epoch:13 step:12696 [D loss: 0.444806, acc.: 85.16%] [G loss: 1.226852]\n",
      "epoch:13 step:12697 [D loss: 0.630257, acc.: 64.06%] [G loss: 1.099332]\n",
      "epoch:13 step:12698 [D loss: 0.636318, acc.: 65.62%] [G loss: 1.029553]\n",
      "epoch:13 step:12699 [D loss: 0.607802, acc.: 68.75%] [G loss: 1.140528]\n",
      "epoch:13 step:12700 [D loss: 0.659176, acc.: 54.69%] [G loss: 1.037387]\n",
      "epoch:13 step:12701 [D loss: 0.630056, acc.: 64.06%] [G loss: 0.956054]\n",
      "epoch:13 step:12702 [D loss: 0.656338, acc.: 57.81%] [G loss: 0.879725]\n",
      "epoch:13 step:12703 [D loss: 0.628701, acc.: 64.06%] [G loss: 1.004422]\n",
      "epoch:13 step:12704 [D loss: 0.569371, acc.: 70.31%] [G loss: 1.238096]\n",
      "epoch:13 step:12705 [D loss: 0.660059, acc.: 63.28%] [G loss: 1.122923]\n",
      "epoch:13 step:12706 [D loss: 0.730773, acc.: 52.34%] [G loss: 1.193624]\n",
      "epoch:13 step:12707 [D loss: 0.724857, acc.: 56.25%] [G loss: 1.095077]\n",
      "epoch:13 step:12708 [D loss: 0.485669, acc.: 78.91%] [G loss: 1.114228]\n",
      "epoch:13 step:12709 [D loss: 0.748090, acc.: 57.03%] [G loss: 0.907761]\n",
      "epoch:13 step:12710 [D loss: 0.788667, acc.: 41.41%] [G loss: 0.877375]\n",
      "epoch:13 step:12711 [D loss: 0.604490, acc.: 64.84%] [G loss: 0.878947]\n",
      "epoch:13 step:12712 [D loss: 0.708712, acc.: 52.34%] [G loss: 0.920932]\n",
      "epoch:13 step:12713 [D loss: 0.699107, acc.: 57.03%] [G loss: 0.906029]\n",
      "epoch:13 step:12714 [D loss: 0.638165, acc.: 69.53%] [G loss: 0.964395]\n",
      "epoch:13 step:12715 [D loss: 0.563447, acc.: 71.88%] [G loss: 1.041595]\n",
      "epoch:13 step:12716 [D loss: 0.473203, acc.: 80.47%] [G loss: 1.026136]\n",
      "epoch:13 step:12717 [D loss: 0.357842, acc.: 85.16%] [G loss: 1.095896]\n",
      "epoch:13 step:12718 [D loss: 0.359633, acc.: 89.84%] [G loss: 1.151484]\n",
      "epoch:13 step:12719 [D loss: 0.561672, acc.: 78.12%] [G loss: 0.384935]\n",
      "epoch:13 step:12720 [D loss: 0.550087, acc.: 76.56%] [G loss: 1.105410]\n",
      "epoch:13 step:12721 [D loss: 0.716145, acc.: 54.69%] [G loss: 1.128644]\n",
      "epoch:13 step:12722 [D loss: 0.533703, acc.: 78.12%] [G loss: 1.200347]\n",
      "epoch:13 step:12723 [D loss: 0.607663, acc.: 67.97%] [G loss: 1.107177]\n",
      "epoch:13 step:12724 [D loss: 0.864409, acc.: 37.50%] [G loss: 1.239402]\n",
      "epoch:13 step:12725 [D loss: 0.626563, acc.: 63.28%] [G loss: 1.101047]\n",
      "epoch:13 step:12726 [D loss: 0.830971, acc.: 42.97%] [G loss: 1.133209]\n",
      "epoch:13 step:12727 [D loss: 0.536527, acc.: 75.78%] [G loss: 1.455594]\n",
      "epoch:13 step:12728 [D loss: 0.514050, acc.: 76.56%] [G loss: 1.401018]\n",
      "epoch:13 step:12729 [D loss: 0.461410, acc.: 81.25%] [G loss: 1.363719]\n",
      "epoch:13 step:12730 [D loss: 0.469988, acc.: 82.81%] [G loss: 1.447667]\n",
      "epoch:13 step:12731 [D loss: 0.434993, acc.: 83.59%] [G loss: 1.290603]\n",
      "epoch:13 step:12732 [D loss: 0.534275, acc.: 75.78%] [G loss: 1.221614]\n",
      "epoch:13 step:12733 [D loss: 0.515217, acc.: 76.56%] [G loss: 1.266927]\n",
      "epoch:13 step:12734 [D loss: 0.615111, acc.: 66.41%] [G loss: 0.722990]\n",
      "epoch:13 step:12735 [D loss: 0.490740, acc.: 75.78%] [G loss: 1.124150]\n",
      "epoch:13 step:12736 [D loss: 0.464712, acc.: 81.25%] [G loss: 1.261997]\n",
      "epoch:13 step:12737 [D loss: 0.370838, acc.: 94.53%] [G loss: 1.637556]\n",
      "epoch:13 step:12738 [D loss: 0.372793, acc.: 89.84%] [G loss: 1.192717]\n",
      "epoch:13 step:12739 [D loss: 0.477297, acc.: 80.47%] [G loss: 0.749649]\n",
      "epoch:13 step:12740 [D loss: 0.581704, acc.: 75.78%] [G loss: 1.284140]\n",
      "epoch:13 step:12741 [D loss: 0.777970, acc.: 58.59%] [G loss: 1.012100]\n",
      "epoch:13 step:12742 [D loss: 0.429320, acc.: 76.56%] [G loss: 1.068038]\n",
      "epoch:13 step:12743 [D loss: 0.664205, acc.: 59.38%] [G loss: 0.867325]\n",
      "epoch:13 step:12744 [D loss: 0.697877, acc.: 57.03%] [G loss: 0.626134]\n",
      "epoch:13 step:12745 [D loss: 0.682022, acc.: 57.81%] [G loss: 1.117083]\n",
      "epoch:13 step:12746 [D loss: 0.714297, acc.: 58.59%] [G loss: 1.132719]\n",
      "epoch:13 step:12747 [D loss: 0.302196, acc.: 84.38%] [G loss: 1.296297]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:13 step:12748 [D loss: 0.251307, acc.: 91.41%] [G loss: 1.239936]\n",
      "epoch:13 step:12749 [D loss: 0.435655, acc.: 77.34%] [G loss: 1.523215]\n",
      "epoch:13 step:12750 [D loss: 0.738802, acc.: 57.81%] [G loss: 1.320059]\n",
      "epoch:13 step:12751 [D loss: 0.545516, acc.: 73.44%] [G loss: 1.054563]\n",
      "epoch:13 step:12752 [D loss: 0.662890, acc.: 60.94%] [G loss: 1.106179]\n",
      "epoch:13 step:12753 [D loss: 0.670235, acc.: 60.16%] [G loss: 1.236822]\n",
      "epoch:13 step:12754 [D loss: 0.677865, acc.: 60.16%] [G loss: 1.095933]\n",
      "epoch:13 step:12755 [D loss: 0.602997, acc.: 66.41%] [G loss: 1.171145]\n",
      "epoch:13 step:12756 [D loss: 0.493283, acc.: 80.47%] [G loss: 1.294130]\n",
      "epoch:13 step:12757 [D loss: 0.527622, acc.: 77.34%] [G loss: 1.357337]\n",
      "epoch:13 step:12758 [D loss: 0.309175, acc.: 86.72%] [G loss: 1.257423]\n",
      "epoch:13 step:12759 [D loss: 0.230151, acc.: 91.41%] [G loss: 1.751355]\n",
      "epoch:13 step:12760 [D loss: 0.396881, acc.: 82.03%] [G loss: 1.976480]\n",
      "epoch:13 step:12761 [D loss: 1.282844, acc.: 27.34%] [G loss: 1.467515]\n",
      "epoch:13 step:12762 [D loss: 0.673029, acc.: 58.59%] [G loss: 1.111915]\n",
      "epoch:13 step:12763 [D loss: 0.738309, acc.: 57.03%] [G loss: 1.218850]\n",
      "epoch:13 step:12764 [D loss: 0.685275, acc.: 62.50%] [G loss: 1.124204]\n",
      "epoch:13 step:12765 [D loss: 0.746777, acc.: 53.91%] [G loss: 0.991352]\n",
      "epoch:13 step:12766 [D loss: 0.734488, acc.: 49.22%] [G loss: 1.006603]\n",
      "epoch:13 step:12767 [D loss: 0.714651, acc.: 55.47%] [G loss: 1.125462]\n",
      "epoch:13 step:12768 [D loss: 0.339288, acc.: 83.59%] [G loss: 1.107771]\n",
      "epoch:13 step:12769 [D loss: 0.432809, acc.: 83.59%] [G loss: 1.135403]\n",
      "epoch:13 step:12770 [D loss: 0.256217, acc.: 91.41%] [G loss: 1.358297]\n",
      "epoch:13 step:12771 [D loss: 0.732480, acc.: 59.38%] [G loss: 1.311384]\n",
      "epoch:13 step:12772 [D loss: 0.672871, acc.: 60.16%] [G loss: 1.273686]\n",
      "epoch:13 step:12773 [D loss: 0.578950, acc.: 71.09%] [G loss: 1.343929]\n",
      "epoch:13 step:12774 [D loss: 0.631881, acc.: 66.41%] [G loss: 1.145150]\n",
      "epoch:13 step:12775 [D loss: 0.696830, acc.: 56.25%] [G loss: 1.061932]\n",
      "epoch:13 step:12776 [D loss: 0.459728, acc.: 81.25%] [G loss: 1.147092]\n",
      "epoch:13 step:12777 [D loss: 0.650234, acc.: 62.50%] [G loss: 1.167804]\n",
      "epoch:13 step:12778 [D loss: 0.688477, acc.: 56.25%] [G loss: 1.119486]\n",
      "epoch:13 step:12779 [D loss: 0.586515, acc.: 72.66%] [G loss: 1.159795]\n",
      "epoch:13 step:12780 [D loss: 0.533980, acc.: 68.75%] [G loss: 1.226045]\n",
      "epoch:13 step:12781 [D loss: 0.470433, acc.: 76.56%] [G loss: 1.174818]\n",
      "epoch:13 step:12782 [D loss: 0.598124, acc.: 64.84%] [G loss: 0.981375]\n",
      "epoch:13 step:12783 [D loss: 0.502112, acc.: 69.53%] [G loss: 1.146893]\n",
      "epoch:13 step:12784 [D loss: 0.742223, acc.: 51.56%] [G loss: 1.019238]\n",
      "epoch:13 step:12785 [D loss: 0.688763, acc.: 57.03%] [G loss: 1.087477]\n",
      "epoch:13 step:12786 [D loss: 0.589915, acc.: 67.97%] [G loss: 0.958031]\n",
      "epoch:13 step:12787 [D loss: 0.720028, acc.: 58.59%] [G loss: 0.873145]\n",
      "epoch:13 step:12788 [D loss: 0.734390, acc.: 46.88%] [G loss: 0.966346]\n",
      "epoch:13 step:12789 [D loss: 0.641567, acc.: 62.50%] [G loss: 0.971507]\n",
      "epoch:13 step:12790 [D loss: 0.343144, acc.: 90.62%] [G loss: 1.002035]\n",
      "epoch:13 step:12791 [D loss: 0.701164, acc.: 56.25%] [G loss: 1.067837]\n",
      "epoch:13 step:12792 [D loss: 0.580418, acc.: 73.44%] [G loss: 0.905254]\n",
      "epoch:13 step:12793 [D loss: 0.511910, acc.: 80.47%] [G loss: 0.987179]\n",
      "epoch:13 step:12794 [D loss: 0.642269, acc.: 60.16%] [G loss: 0.931593]\n",
      "epoch:13 step:12795 [D loss: 0.734353, acc.: 53.91%] [G loss: 0.950153]\n",
      "epoch:13 step:12796 [D loss: 0.704172, acc.: 57.03%] [G loss: 0.815671]\n",
      "epoch:13 step:12797 [D loss: 0.602904, acc.: 67.19%] [G loss: 0.782987]\n",
      "epoch:13 step:12798 [D loss: 0.634203, acc.: 64.06%] [G loss: 0.435745]\n",
      "epoch:13 step:12799 [D loss: 0.501340, acc.: 80.47%] [G loss: 0.719070]\n",
      "epoch:13 step:12800 [D loss: 1.013010, acc.: 49.22%] [G loss: 1.006543]\n",
      "##############\n",
      "[4.35976517 2.42466753 6.35659999 6.08020188 4.24214582 6.16588398\n",
      " 5.05810668 5.18847445 5.72508242 5.17062832]\n",
      "##########\n",
      "epoch:13 step:12801 [D loss: 0.506010, acc.: 76.56%] [G loss: 1.211373]\n",
      "epoch:13 step:12802 [D loss: 0.709338, acc.: 57.03%] [G loss: 1.133780]\n",
      "epoch:13 step:12803 [D loss: 0.717159, acc.: 53.12%] [G loss: 1.096904]\n",
      "epoch:13 step:12804 [D loss: 0.659875, acc.: 60.94%] [G loss: 0.691722]\n",
      "epoch:13 step:12805 [D loss: 0.639115, acc.: 65.62%] [G loss: 0.946236]\n",
      "epoch:13 step:12806 [D loss: 0.647147, acc.: 61.72%] [G loss: 0.855006]\n",
      "epoch:13 step:12807 [D loss: 0.641539, acc.: 64.84%] [G loss: 0.906657]\n",
      "epoch:13 step:12808 [D loss: 1.028931, acc.: 41.41%] [G loss: 0.940195]\n",
      "epoch:13 step:12809 [D loss: 0.643663, acc.: 61.72%] [G loss: 0.948855]\n",
      "epoch:13 step:12810 [D loss: 0.663878, acc.: 64.06%] [G loss: 0.940049]\n",
      "epoch:13 step:12811 [D loss: 0.563951, acc.: 74.22%] [G loss: 1.008228]\n",
      "epoch:13 step:12812 [D loss: 0.692131, acc.: 59.38%] [G loss: 0.915663]\n",
      "epoch:13 step:12813 [D loss: 0.603251, acc.: 67.97%] [G loss: 0.945676]\n",
      "epoch:13 step:12814 [D loss: 0.441286, acc.: 84.38%] [G loss: 0.959691]\n",
      "epoch:13 step:12815 [D loss: 0.491852, acc.: 82.81%] [G loss: 1.035564]\n",
      "epoch:13 step:12816 [D loss: 0.508846, acc.: 81.25%] [G loss: 0.859061]\n",
      "epoch:13 step:12817 [D loss: 0.616835, acc.: 71.88%] [G loss: 1.013597]\n",
      "epoch:13 step:12818 [D loss: 0.586694, acc.: 71.09%] [G loss: 0.769850]\n",
      "epoch:13 step:12819 [D loss: 0.656390, acc.: 59.38%] [G loss: 0.872145]\n",
      "epoch:13 step:12820 [D loss: 0.671800, acc.: 61.72%] [G loss: 0.837395]\n",
      "epoch:13 step:12821 [D loss: 0.866134, acc.: 36.72%] [G loss: 0.924979]\n",
      "epoch:13 step:12822 [D loss: 0.436015, acc.: 77.34%] [G loss: 0.862718]\n",
      "epoch:13 step:12823 [D loss: 0.779306, acc.: 43.75%] [G loss: 0.884970]\n",
      "epoch:13 step:12824 [D loss: 0.765668, acc.: 50.78%] [G loss: 0.680817]\n",
      "epoch:13 step:12825 [D loss: 0.552126, acc.: 74.22%] [G loss: 0.962320]\n",
      "epoch:13 step:12826 [D loss: 0.431318, acc.: 94.53%] [G loss: 1.114325]\n",
      "epoch:13 step:12827 [D loss: 0.644788, acc.: 69.53%] [G loss: 1.071454]\n",
      "epoch:13 step:12828 [D loss: 0.649844, acc.: 60.94%] [G loss: 0.886840]\n",
      "epoch:13 step:12829 [D loss: 0.394295, acc.: 87.50%] [G loss: 0.731504]\n",
      "epoch:13 step:12830 [D loss: 0.529340, acc.: 76.56%] [G loss: 1.010525]\n",
      "epoch:13 step:12831 [D loss: 0.524748, acc.: 69.53%] [G loss: 1.994995]\n",
      "epoch:13 step:12832 [D loss: 0.600568, acc.: 66.41%] [G loss: 1.238365]\n",
      "epoch:13 step:12833 [D loss: 0.574294, acc.: 68.75%] [G loss: 1.748692]\n",
      "epoch:13 step:12834 [D loss: 0.727915, acc.: 53.91%] [G loss: 0.870550]\n",
      "epoch:13 step:12835 [D loss: 1.006547, acc.: 25.00%] [G loss: 1.592920]\n",
      "epoch:13 step:12836 [D loss: 0.682794, acc.: 57.03%] [G loss: 1.132584]\n",
      "epoch:13 step:12837 [D loss: 0.765126, acc.: 48.44%] [G loss: 0.683269]\n",
      "epoch:13 step:12838 [D loss: 0.760399, acc.: 49.22%] [G loss: 0.632324]\n",
      "epoch:13 step:12839 [D loss: 0.835026, acc.: 34.38%] [G loss: 0.956906]\n",
      "epoch:13 step:12840 [D loss: 0.562463, acc.: 71.09%] [G loss: 1.068664]\n",
      "epoch:13 step:12841 [D loss: 0.755786, acc.: 47.66%] [G loss: 0.972388]\n",
      "epoch:13 step:12842 [D loss: 0.577252, acc.: 73.44%] [G loss: 1.232863]\n",
      "epoch:13 step:12843 [D loss: 0.746562, acc.: 54.69%] [G loss: 0.974687]\n",
      "epoch:13 step:12844 [D loss: 0.364270, acc.: 89.06%] [G loss: 1.069962]\n",
      "epoch:13 step:12845 [D loss: 0.315325, acc.: 90.62%] [G loss: 1.203999]\n",
      "epoch:13 step:12846 [D loss: 0.336928, acc.: 81.25%] [G loss: 1.469385]\n",
      "epoch:13 step:12847 [D loss: 0.721891, acc.: 57.03%] [G loss: 1.077049]\n",
      "epoch:13 step:12848 [D loss: 0.658202, acc.: 64.06%] [G loss: 1.150453]\n",
      "epoch:13 step:12849 [D loss: 0.678286, acc.: 63.28%] [G loss: 1.187910]\n",
      "epoch:13 step:12850 [D loss: 0.602847, acc.: 65.62%] [G loss: 1.215776]\n",
      "epoch:13 step:12851 [D loss: 0.710017, acc.: 49.22%] [G loss: 1.283087]\n",
      "epoch:13 step:12852 [D loss: 0.557393, acc.: 75.00%] [G loss: 1.044318]\n",
      "epoch:13 step:12853 [D loss: 0.664282, acc.: 58.59%] [G loss: 1.122178]\n",
      "epoch:13 step:12854 [D loss: 0.626406, acc.: 68.75%] [G loss: 1.004026]\n",
      "epoch:13 step:12855 [D loss: 0.502951, acc.: 81.25%] [G loss: 1.016645]\n",
      "epoch:13 step:12856 [D loss: 0.712176, acc.: 59.38%] [G loss: 1.056771]\n",
      "epoch:13 step:12857 [D loss: 0.674893, acc.: 65.62%] [G loss: 0.964128]\n",
      "epoch:13 step:12858 [D loss: 0.708193, acc.: 55.47%] [G loss: 0.923039]\n",
      "epoch:13 step:12859 [D loss: 0.744073, acc.: 42.97%] [G loss: 0.990359]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:13 step:12860 [D loss: 0.620886, acc.: 65.62%] [G loss: 1.009836]\n",
      "epoch:13 step:12861 [D loss: 0.638545, acc.: 66.41%] [G loss: 0.838406]\n",
      "epoch:13 step:12862 [D loss: 0.739210, acc.: 51.56%] [G loss: 0.841441]\n",
      "epoch:13 step:12863 [D loss: 0.588776, acc.: 70.31%] [G loss: 0.859360]\n",
      "epoch:13 step:12864 [D loss: 0.614345, acc.: 68.75%] [G loss: 1.018229]\n",
      "epoch:13 step:12865 [D loss: 0.433982, acc.: 85.94%] [G loss: 1.021648]\n",
      "epoch:13 step:12866 [D loss: 0.532506, acc.: 78.91%] [G loss: 0.736014]\n",
      "epoch:13 step:12867 [D loss: 0.843999, acc.: 49.22%] [G loss: 0.853779]\n",
      "epoch:13 step:12868 [D loss: 0.586542, acc.: 68.75%] [G loss: 1.166544]\n",
      "epoch:13 step:12869 [D loss: 0.680837, acc.: 57.81%] [G loss: 1.084632]\n",
      "epoch:13 step:12870 [D loss: 0.765342, acc.: 42.19%] [G loss: 0.921093]\n",
      "epoch:13 step:12871 [D loss: 0.750768, acc.: 52.34%] [G loss: 0.867469]\n",
      "epoch:13 step:12872 [D loss: 0.680362, acc.: 57.03%] [G loss: 0.958338]\n",
      "epoch:13 step:12873 [D loss: 0.764949, acc.: 43.75%] [G loss: 0.766637]\n",
      "epoch:13 step:12874 [D loss: 0.668569, acc.: 60.16%] [G loss: 0.559990]\n",
      "epoch:13 step:12875 [D loss: 0.651273, acc.: 60.16%] [G loss: 0.777740]\n",
      "epoch:13 step:12876 [D loss: 0.658420, acc.: 60.94%] [G loss: 0.886368]\n",
      "epoch:13 step:12877 [D loss: 0.366008, acc.: 78.91%] [G loss: 0.999303]\n",
      "epoch:13 step:12878 [D loss: 0.287685, acc.: 90.62%] [G loss: 1.176639]\n",
      "epoch:13 step:12879 [D loss: 0.346375, acc.: 92.19%] [G loss: 1.271285]\n",
      "epoch:13 step:12880 [D loss: 0.694933, acc.: 55.47%] [G loss: 1.171530]\n",
      "epoch:13 step:12881 [D loss: 0.238735, acc.: 98.44%] [G loss: 0.895122]\n",
      "epoch:13 step:12882 [D loss: 0.276129, acc.: 89.84%] [G loss: 1.342028]\n",
      "epoch:13 step:12883 [D loss: 0.369769, acc.: 89.06%] [G loss: 1.218465]\n",
      "epoch:13 step:12884 [D loss: 0.752058, acc.: 53.12%] [G loss: 1.362818]\n",
      "epoch:13 step:12885 [D loss: 0.525804, acc.: 79.69%] [G loss: 1.269479]\n",
      "epoch:13 step:12886 [D loss: 0.767357, acc.: 50.78%] [G loss: 0.997373]\n",
      "epoch:13 step:12887 [D loss: 0.209042, acc.: 98.44%] [G loss: 1.220029]\n",
      "epoch:13 step:12888 [D loss: 0.219548, acc.: 95.31%] [G loss: 1.243803]\n",
      "epoch:13 step:12889 [D loss: 0.344036, acc.: 82.81%] [G loss: 1.542044]\n",
      "epoch:13 step:12890 [D loss: 0.358191, acc.: 91.41%] [G loss: 1.660488]\n",
      "epoch:13 step:12891 [D loss: 0.931228, acc.: 46.88%] [G loss: 1.389570]\n",
      "epoch:13 step:12892 [D loss: 1.203935, acc.: 16.41%] [G loss: 1.350297]\n",
      "epoch:13 step:12893 [D loss: 0.834987, acc.: 42.97%] [G loss: 1.420509]\n",
      "epoch:13 step:12894 [D loss: 0.245582, acc.: 96.88%] [G loss: 1.052429]\n",
      "epoch:13 step:12895 [D loss: 0.217576, acc.: 100.00%] [G loss: 1.602675]\n",
      "epoch:13 step:12896 [D loss: 1.060005, acc.: 21.88%] [G loss: 1.284780]\n",
      "epoch:13 step:12897 [D loss: 0.749979, acc.: 55.47%] [G loss: 1.272558]\n",
      "epoch:13 step:12898 [D loss: 0.803051, acc.: 48.44%] [G loss: 1.185049]\n",
      "epoch:13 step:12899 [D loss: 0.571215, acc.: 67.19%] [G loss: 1.133082]\n",
      "epoch:13 step:12900 [D loss: 0.567074, acc.: 71.88%] [G loss: 1.208431]\n",
      "epoch:13 step:12901 [D loss: 0.594452, acc.: 67.97%] [G loss: 1.184314]\n",
      "epoch:13 step:12902 [D loss: 0.550870, acc.: 76.56%] [G loss: 1.240458]\n",
      "epoch:13 step:12903 [D loss: 0.783144, acc.: 53.91%] [G loss: 1.240486]\n",
      "epoch:13 step:12904 [D loss: 0.676626, acc.: 62.50%] [G loss: 1.040577]\n",
      "epoch:13 step:12905 [D loss: 0.589378, acc.: 75.00%] [G loss: 0.888331]\n",
      "epoch:13 step:12906 [D loss: 0.587952, acc.: 69.53%] [G loss: 0.984254]\n",
      "epoch:13 step:12907 [D loss: 0.546696, acc.: 72.66%] [G loss: 1.311447]\n",
      "epoch:13 step:12908 [D loss: 0.705429, acc.: 59.38%] [G loss: 0.976287]\n",
      "epoch:13 step:12909 [D loss: 0.404590, acc.: 78.91%] [G loss: 1.052419]\n",
      "epoch:13 step:12910 [D loss: 0.659815, acc.: 64.06%] [G loss: 1.039379]\n",
      "epoch:13 step:12911 [D loss: 0.345455, acc.: 91.41%] [G loss: 1.006242]\n",
      "epoch:13 step:12912 [D loss: 0.443450, acc.: 84.38%] [G loss: 1.214730]\n",
      "epoch:13 step:12913 [D loss: 0.307531, acc.: 90.62%] [G loss: 1.068987]\n",
      "epoch:13 step:12914 [D loss: 0.472402, acc.: 85.94%] [G loss: 1.072159]\n",
      "epoch:13 step:12915 [D loss: 0.735535, acc.: 53.91%] [G loss: 1.139341]\n",
      "epoch:13 step:12916 [D loss: 0.662300, acc.: 60.16%] [G loss: 1.010501]\n",
      "epoch:13 step:12917 [D loss: 0.625021, acc.: 69.53%] [G loss: 1.054310]\n",
      "epoch:13 step:12918 [D loss: 0.684665, acc.: 57.81%] [G loss: 0.998347]\n",
      "epoch:13 step:12919 [D loss: 1.406303, acc.: 24.22%] [G loss: 1.081521]\n",
      "epoch:13 step:12920 [D loss: 0.520471, acc.: 78.91%] [G loss: 1.067908]\n",
      "epoch:13 step:12921 [D loss: 0.532816, acc.: 79.69%] [G loss: 1.084541]\n",
      "epoch:13 step:12922 [D loss: 0.608832, acc.: 69.53%] [G loss: 1.004859]\n",
      "epoch:13 step:12923 [D loss: 0.579013, acc.: 71.88%] [G loss: 1.079417]\n",
      "epoch:13 step:12924 [D loss: 0.494770, acc.: 82.03%] [G loss: 0.973550]\n",
      "epoch:13 step:12925 [D loss: 0.609591, acc.: 67.19%] [G loss: 0.976904]\n",
      "epoch:13 step:12926 [D loss: 0.502102, acc.: 79.69%] [G loss: 0.835124]\n",
      "epoch:13 step:12927 [D loss: 0.244780, acc.: 92.97%] [G loss: 0.865153]\n",
      "epoch:13 step:12928 [D loss: 0.735614, acc.: 53.12%] [G loss: 0.528815]\n",
      "epoch:13 step:12929 [D loss: 0.676167, acc.: 57.81%] [G loss: 1.098461]\n",
      "epoch:13 step:12930 [D loss: 0.594536, acc.: 67.19%] [G loss: 1.171132]\n",
      "epoch:13 step:12931 [D loss: 0.489073, acc.: 80.47%] [G loss: 0.357968]\n",
      "epoch:13 step:12932 [D loss: 0.683987, acc.: 60.16%] [G loss: 1.180105]\n",
      "epoch:13 step:12933 [D loss: 0.552439, acc.: 75.78%] [G loss: 0.937611]\n",
      "epoch:13 step:12934 [D loss: 0.639543, acc.: 64.84%] [G loss: 1.134708]\n",
      "epoch:13 step:12935 [D loss: 0.470135, acc.: 84.38%] [G loss: 0.243106]\n",
      "epoch:13 step:12936 [D loss: 0.383043, acc.: 94.53%] [G loss: 0.313162]\n",
      "epoch:13 step:12937 [D loss: 0.237329, acc.: 93.75%] [G loss: 1.110802]\n",
      "epoch:13 step:12938 [D loss: 0.475887, acc.: 83.59%] [G loss: 1.299630]\n",
      "epoch:13 step:12939 [D loss: 0.463059, acc.: 86.72%] [G loss: 0.072027]\n",
      "epoch:13 step:12940 [D loss: 0.614644, acc.: 69.53%] [G loss: 1.236760]\n",
      "epoch:13 step:12941 [D loss: 0.951387, acc.: 30.47%] [G loss: 1.378791]\n",
      "epoch:13 step:12942 [D loss: 0.722833, acc.: 56.25%] [G loss: 1.250125]\n",
      "epoch:13 step:12943 [D loss: 0.556032, acc.: 75.00%] [G loss: 0.145842]\n",
      "epoch:13 step:12944 [D loss: 0.737249, acc.: 55.47%] [G loss: 0.749499]\n",
      "epoch:13 step:12945 [D loss: 0.230214, acc.: 94.53%] [G loss: 0.292651]\n",
      "epoch:13 step:12946 [D loss: 0.592100, acc.: 64.84%] [G loss: 1.370348]\n",
      "epoch:13 step:12947 [D loss: 1.489633, acc.: 33.59%] [G loss: 1.529698]\n",
      "epoch:13 step:12948 [D loss: 0.562466, acc.: 70.31%] [G loss: 1.455006]\n",
      "epoch:13 step:12949 [D loss: 0.385800, acc.: 88.28%] [G loss: 1.244656]\n",
      "epoch:13 step:12950 [D loss: 0.385387, acc.: 85.94%] [G loss: 1.056965]\n",
      "epoch:13 step:12951 [D loss: 0.597850, acc.: 71.88%] [G loss: 1.184802]\n",
      "epoch:13 step:12952 [D loss: 0.700629, acc.: 59.38%] [G loss: 1.279031]\n",
      "epoch:13 step:12953 [D loss: 0.684068, acc.: 56.25%] [G loss: 0.955406]\n",
      "epoch:13 step:12954 [D loss: 0.652814, acc.: 63.28%] [G loss: 0.979828]\n",
      "epoch:13 step:12955 [D loss: 0.504416, acc.: 75.78%] [G loss: 1.274181]\n",
      "epoch:13 step:12956 [D loss: 0.545043, acc.: 73.44%] [G loss: 1.195647]\n",
      "epoch:13 step:12957 [D loss: 0.706822, acc.: 55.47%] [G loss: 1.087898]\n",
      "epoch:13 step:12958 [D loss: 0.509176, acc.: 85.16%] [G loss: 1.080262]\n",
      "epoch:13 step:12959 [D loss: 0.759969, acc.: 55.47%] [G loss: 1.133716]\n",
      "epoch:13 step:12960 [D loss: 0.832498, acc.: 46.09%] [G loss: 1.113421]\n",
      "epoch:13 step:12961 [D loss: 0.740950, acc.: 50.00%] [G loss: 1.027963]\n",
      "epoch:13 step:12962 [D loss: 0.519929, acc.: 75.00%] [G loss: 0.953167]\n",
      "epoch:13 step:12963 [D loss: 0.401830, acc.: 82.03%] [G loss: 1.235025]\n",
      "epoch:13 step:12964 [D loss: 0.739399, acc.: 53.12%] [G loss: 1.176320]\n",
      "epoch:13 step:12965 [D loss: 0.684575, acc.: 64.06%] [G loss: 1.238795]\n",
      "epoch:13 step:12966 [D loss: 0.785034, acc.: 45.31%] [G loss: 1.015665]\n",
      "epoch:13 step:12967 [D loss: 0.443329, acc.: 80.47%] [G loss: 1.249999]\n",
      "epoch:13 step:12968 [D loss: 0.810097, acc.: 40.62%] [G loss: 1.154299]\n",
      "epoch:13 step:12969 [D loss: 0.738645, acc.: 50.00%] [G loss: 1.124221]\n",
      "epoch:13 step:12970 [D loss: 0.935616, acc.: 38.28%] [G loss: 1.102958]\n",
      "epoch:13 step:12971 [D loss: 0.665631, acc.: 59.38%] [G loss: 1.142117]\n",
      "epoch:13 step:12972 [D loss: 0.275055, acc.: 95.31%] [G loss: 1.291720]\n",
      "epoch:13 step:12973 [D loss: 0.376842, acc.: 80.47%] [G loss: 1.228435]\n",
      "epoch:13 step:12974 [D loss: 0.300221, acc.: 94.53%] [G loss: 1.552286]\n",
      "epoch:13 step:12975 [D loss: 0.323214, acc.: 96.88%] [G loss: 0.959712]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:13 step:12976 [D loss: 0.615760, acc.: 68.75%] [G loss: 1.231624]\n",
      "epoch:13 step:12977 [D loss: 0.298259, acc.: 93.75%] [G loss: 1.214577]\n",
      "epoch:13 step:12978 [D loss: 0.768684, acc.: 49.22%] [G loss: 1.144681]\n",
      "epoch:13 step:12979 [D loss: 0.772129, acc.: 50.78%] [G loss: 0.924575]\n",
      "epoch:13 step:12980 [D loss: 0.633965, acc.: 60.16%] [G loss: 0.994004]\n",
      "epoch:13 step:12981 [D loss: 0.650137, acc.: 63.28%] [G loss: 0.957627]\n",
      "epoch:13 step:12982 [D loss: 0.634300, acc.: 62.50%] [G loss: 1.062427]\n",
      "epoch:13 step:12983 [D loss: 0.658927, acc.: 60.16%] [G loss: 0.928182]\n",
      "epoch:13 step:12984 [D loss: 0.749224, acc.: 53.12%] [G loss: 1.096650]\n",
      "epoch:13 step:12985 [D loss: 0.242190, acc.: 94.53%] [G loss: 0.755905]\n",
      "epoch:13 step:12986 [D loss: 0.269767, acc.: 92.97%] [G loss: 1.052245]\n",
      "epoch:13 step:12987 [D loss: 0.254617, acc.: 92.19%] [G loss: 1.148601]\n",
      "epoch:13 step:12988 [D loss: 0.777389, acc.: 49.22%] [G loss: 1.038187]\n",
      "epoch:13 step:12989 [D loss: 1.341341, acc.: 23.44%] [G loss: 1.300980]\n",
      "epoch:13 step:12990 [D loss: 0.620968, acc.: 66.41%] [G loss: 1.486624]\n",
      "epoch:13 step:12991 [D loss: 0.497011, acc.: 71.09%] [G loss: 1.376863]\n",
      "epoch:13 step:12992 [D loss: 0.769179, acc.: 60.16%] [G loss: 1.147897]\n",
      "epoch:13 step:12993 [D loss: 0.721249, acc.: 52.34%] [G loss: 1.022039]\n",
      "epoch:13 step:12994 [D loss: 0.678776, acc.: 55.47%] [G loss: 1.162262]\n",
      "epoch:13 step:12995 [D loss: 0.737996, acc.: 49.22%] [G loss: 0.965681]\n",
      "epoch:13 step:12996 [D loss: 0.529488, acc.: 78.12%] [G loss: 0.943713]\n",
      "epoch:13 step:12997 [D loss: 0.507078, acc.: 83.59%] [G loss: 0.953573]\n",
      "epoch:13 step:12998 [D loss: 0.685654, acc.: 58.59%] [G loss: 1.050983]\n",
      "epoch:13 step:12999 [D loss: 0.670667, acc.: 61.72%] [G loss: 0.783484]\n",
      "epoch:13 step:13000 [D loss: 0.595173, acc.: 67.97%] [G loss: 0.831527]\n",
      "##############\n",
      "[4.27665729 2.63412169 6.40269025 5.26632874 4.17839602 6.18842366\n",
      " 5.12431763 5.44999152 5.96897493 4.82068379]\n",
      "##########\n",
      "epoch:13 step:13001 [D loss: 0.823376, acc.: 38.28%] [G loss: 1.036902]\n",
      "epoch:13 step:13002 [D loss: 0.601073, acc.: 68.75%] [G loss: 0.754252]\n",
      "epoch:13 step:13003 [D loss: 0.659400, acc.: 59.38%] [G loss: 0.976812]\n",
      "epoch:13 step:13004 [D loss: 0.650598, acc.: 64.06%] [G loss: 0.933044]\n",
      "epoch:13 step:13005 [D loss: 0.634081, acc.: 66.41%] [G loss: 0.882093]\n",
      "epoch:13 step:13006 [D loss: 0.593436, acc.: 66.41%] [G loss: 0.804618]\n",
      "epoch:13 step:13007 [D loss: 0.622211, acc.: 65.62%] [G loss: 0.925890]\n",
      "epoch:13 step:13008 [D loss: 0.666131, acc.: 58.59%] [G loss: 0.727422]\n",
      "epoch:13 step:13009 [D loss: 0.674544, acc.: 58.59%] [G loss: 0.850725]\n",
      "epoch:13 step:13010 [D loss: 0.652121, acc.: 64.06%] [G loss: 0.650937]\n",
      "epoch:13 step:13011 [D loss: 0.634441, acc.: 66.41%] [G loss: 0.869142]\n",
      "epoch:13 step:13012 [D loss: 0.534179, acc.: 76.56%] [G loss: 1.072677]\n",
      "epoch:13 step:13013 [D loss: 0.480672, acc.: 79.69%] [G loss: 0.933413]\n",
      "epoch:13 step:13014 [D loss: 0.594358, acc.: 69.53%] [G loss: 0.982614]\n",
      "epoch:13 step:13015 [D loss: 0.763578, acc.: 45.31%] [G loss: 0.633441]\n",
      "epoch:13 step:13016 [D loss: 0.762040, acc.: 46.09%] [G loss: 0.998015]\n",
      "epoch:13 step:13017 [D loss: 0.739677, acc.: 42.97%] [G loss: 0.826152]\n",
      "epoch:13 step:13018 [D loss: 0.761013, acc.: 36.72%] [G loss: 0.955019]\n",
      "epoch:13 step:13019 [D loss: 0.685996, acc.: 53.91%] [G loss: 0.789125]\n",
      "epoch:13 step:13020 [D loss: 0.629981, acc.: 62.50%] [G loss: 0.973939]\n",
      "epoch:13 step:13021 [D loss: 0.638544, acc.: 67.97%] [G loss: 0.829639]\n",
      "epoch:13 step:13022 [D loss: 0.534958, acc.: 73.44%] [G loss: 0.883914]\n",
      "epoch:13 step:13023 [D loss: 0.639557, acc.: 62.50%] [G loss: 1.046799]\n",
      "epoch:13 step:13024 [D loss: 0.758331, acc.: 53.12%] [G loss: 1.211566]\n",
      "epoch:13 step:13025 [D loss: 0.697173, acc.: 57.81%] [G loss: 0.909940]\n",
      "epoch:13 step:13026 [D loss: 0.513897, acc.: 83.59%] [G loss: 0.900191]\n",
      "epoch:13 step:13027 [D loss: 0.736237, acc.: 54.69%] [G loss: 0.922042]\n",
      "epoch:13 step:13028 [D loss: 0.547239, acc.: 71.88%] [G loss: 1.079042]\n",
      "epoch:13 step:13029 [D loss: 0.577534, acc.: 71.09%] [G loss: 0.799677]\n",
      "epoch:13 step:13030 [D loss: 0.606371, acc.: 60.16%] [G loss: 0.934409]\n",
      "epoch:13 step:13031 [D loss: 0.354905, acc.: 82.81%] [G loss: 1.036049]\n",
      "epoch:13 step:13032 [D loss: 0.294795, acc.: 92.19%] [G loss: 1.053489]\n",
      "epoch:13 step:13033 [D loss: 0.366589, acc.: 88.28%] [G loss: 1.179312]\n",
      "epoch:13 step:13034 [D loss: 0.396735, acc.: 87.50%] [G loss: 1.035939]\n",
      "epoch:13 step:13035 [D loss: 0.250502, acc.: 95.31%] [G loss: 0.435565]\n",
      "epoch:13 step:13036 [D loss: 0.591683, acc.: 72.66%] [G loss: 1.197298]\n",
      "epoch:13 step:13037 [D loss: 0.624687, acc.: 67.19%] [G loss: 1.214280]\n",
      "epoch:13 step:13038 [D loss: 0.297564, acc.: 92.97%] [G loss: 0.793870]\n",
      "epoch:13 step:13039 [D loss: 0.894303, acc.: 39.84%] [G loss: 1.183746]\n",
      "epoch:13 step:13040 [D loss: 0.718069, acc.: 51.56%] [G loss: 1.120843]\n",
      "epoch:13 step:13041 [D loss: 0.672763, acc.: 64.06%] [G loss: 1.138988]\n",
      "epoch:13 step:13042 [D loss: 0.552822, acc.: 74.22%] [G loss: 0.411117]\n",
      "epoch:13 step:13043 [D loss: 0.730945, acc.: 50.78%] [G loss: 0.821970]\n",
      "epoch:13 step:13044 [D loss: 1.703469, acc.: 28.91%] [G loss: 1.029683]\n",
      "epoch:13 step:13045 [D loss: 0.653803, acc.: 61.72%] [G loss: 1.111097]\n",
      "epoch:13 step:13046 [D loss: 0.546497, acc.: 69.53%] [G loss: 0.976664]\n",
      "epoch:13 step:13047 [D loss: 0.629335, acc.: 61.72%] [G loss: 1.107496]\n",
      "epoch:13 step:13048 [D loss: 0.553325, acc.: 72.66%] [G loss: 1.140061]\n",
      "epoch:13 step:13049 [D loss: 0.855418, acc.: 35.94%] [G loss: 1.050730]\n",
      "epoch:13 step:13050 [D loss: 0.651021, acc.: 63.28%] [G loss: 1.019296]\n",
      "epoch:13 step:13051 [D loss: 0.730123, acc.: 57.03%] [G loss: 0.689269]\n",
      "epoch:13 step:13052 [D loss: 0.610161, acc.: 67.19%] [G loss: 0.847299]\n",
      "epoch:13 step:13053 [D loss: 0.600817, acc.: 66.41%] [G loss: 0.962129]\n",
      "epoch:13 step:13054 [D loss: 0.687958, acc.: 54.69%] [G loss: 0.863099]\n",
      "epoch:13 step:13055 [D loss: 0.858215, acc.: 42.19%] [G loss: 1.139683]\n",
      "epoch:13 step:13056 [D loss: 0.623859, acc.: 62.50%] [G loss: 1.146415]\n",
      "epoch:13 step:13057 [D loss: 0.678484, acc.: 60.94%] [G loss: 1.016839]\n",
      "epoch:13 step:13058 [D loss: 0.537744, acc.: 77.34%] [G loss: 0.937437]\n",
      "epoch:13 step:13059 [D loss: 0.530274, acc.: 76.56%] [G loss: 0.982896]\n",
      "epoch:13 step:13060 [D loss: 0.770370, acc.: 50.00%] [G loss: 1.187051]\n",
      "epoch:13 step:13061 [D loss: 0.753847, acc.: 48.44%] [G loss: 0.977228]\n",
      "epoch:13 step:13062 [D loss: 0.737227, acc.: 46.88%] [G loss: 0.932187]\n",
      "epoch:13 step:13063 [D loss: 0.628616, acc.: 64.06%] [G loss: 0.865582]\n",
      "epoch:13 step:13064 [D loss: 0.577395, acc.: 67.19%] [G loss: 0.894043]\n",
      "epoch:13 step:13065 [D loss: 0.549174, acc.: 67.19%] [G loss: 0.888395]\n",
      "epoch:13 step:13066 [D loss: 0.356072, acc.: 86.72%] [G loss: 0.894801]\n",
      "epoch:13 step:13067 [D loss: 0.392346, acc.: 89.84%] [G loss: 1.022302]\n",
      "epoch:13 step:13068 [D loss: 0.362124, acc.: 90.62%] [G loss: 0.981317]\n",
      "epoch:13 step:13069 [D loss: 0.939670, acc.: 28.12%] [G loss: 1.065820]\n",
      "epoch:13 step:13070 [D loss: 0.437857, acc.: 87.50%] [G loss: 1.146082]\n",
      "epoch:13 step:13071 [D loss: 0.437138, acc.: 85.94%] [G loss: 0.761846]\n",
      "epoch:13 step:13072 [D loss: 0.733082, acc.: 50.00%] [G loss: 1.028318]\n",
      "epoch:13 step:13073 [D loss: 0.850958, acc.: 35.94%] [G loss: 0.950167]\n",
      "epoch:13 step:13074 [D loss: 0.759777, acc.: 42.97%] [G loss: 1.001025]\n",
      "epoch:13 step:13075 [D loss: 0.598039, acc.: 69.53%] [G loss: 0.882011]\n",
      "epoch:13 step:13076 [D loss: 0.829285, acc.: 39.84%] [G loss: 1.318229]\n",
      "epoch:13 step:13077 [D loss: 0.478753, acc.: 79.69%] [G loss: 1.195127]\n",
      "epoch:13 step:13078 [D loss: 0.536449, acc.: 71.88%] [G loss: 1.352483]\n",
      "epoch:13 step:13079 [D loss: 0.493401, acc.: 81.25%] [G loss: 1.439561]\n",
      "epoch:13 step:13080 [D loss: 0.450039, acc.: 81.25%] [G loss: 1.218174]\n",
      "epoch:13 step:13081 [D loss: 0.371760, acc.: 88.28%] [G loss: 1.350573]\n",
      "epoch:13 step:13082 [D loss: 0.454360, acc.: 84.38%] [G loss: 1.239763]\n",
      "epoch:13 step:13083 [D loss: 0.669095, acc.: 57.81%] [G loss: 1.384389]\n",
      "epoch:13 step:13084 [D loss: 0.513979, acc.: 82.03%] [G loss: 0.849502]\n",
      "epoch:13 step:13085 [D loss: 0.675365, acc.: 65.62%] [G loss: 1.006167]\n",
      "epoch:13 step:13086 [D loss: 0.741683, acc.: 52.34%] [G loss: 1.077510]\n",
      "epoch:13 step:13087 [D loss: 0.496720, acc.: 82.81%] [G loss: 1.080543]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:13 step:13088 [D loss: 0.671338, acc.: 60.16%] [G loss: 0.905242]\n",
      "epoch:13 step:13089 [D loss: 0.702097, acc.: 53.12%] [G loss: 0.809296]\n",
      "epoch:13 step:13090 [D loss: 0.518901, acc.: 82.03%] [G loss: 0.362751]\n",
      "epoch:13 step:13091 [D loss: 0.682897, acc.: 57.81%] [G loss: 0.865465]\n",
      "epoch:13 step:13092 [D loss: 0.447900, acc.: 89.84%] [G loss: 1.070906]\n",
      "epoch:13 step:13093 [D loss: 0.241378, acc.: 96.09%] [G loss: 1.023474]\n",
      "epoch:13 step:13094 [D loss: 0.643553, acc.: 62.50%] [G loss: 0.937037]\n",
      "epoch:13 step:13095 [D loss: 0.672807, acc.: 55.47%] [G loss: 1.179816]\n",
      "epoch:13 step:13096 [D loss: 0.693269, acc.: 53.91%] [G loss: 0.926307]\n",
      "epoch:13 step:13097 [D loss: 0.740500, acc.: 47.66%] [G loss: 1.049990]\n",
      "epoch:13 step:13098 [D loss: 0.662498, acc.: 62.50%] [G loss: 0.935343]\n",
      "epoch:13 step:13099 [D loss: 0.603579, acc.: 68.75%] [G loss: 1.020652]\n",
      "epoch:13 step:13100 [D loss: 0.501074, acc.: 74.22%] [G loss: 0.897184]\n",
      "epoch:13 step:13101 [D loss: 0.487479, acc.: 81.25%] [G loss: 1.019593]\n",
      "epoch:13 step:13102 [D loss: 0.651519, acc.: 61.72%] [G loss: 1.015815]\n",
      "epoch:13 step:13103 [D loss: 0.567662, acc.: 77.34%] [G loss: 1.083981]\n",
      "epoch:13 step:13104 [D loss: 0.513972, acc.: 77.34%] [G loss: 1.117376]\n",
      "epoch:13 step:13105 [D loss: 0.566750, acc.: 71.88%] [G loss: 1.137268]\n",
      "epoch:13 step:13106 [D loss: 0.415575, acc.: 84.38%] [G loss: 1.076955]\n",
      "epoch:13 step:13107 [D loss: 0.407617, acc.: 83.59%] [G loss: 1.050064]\n",
      "epoch:13 step:13108 [D loss: 0.383714, acc.: 92.19%] [G loss: 0.944276]\n",
      "epoch:13 step:13109 [D loss: 0.734233, acc.: 56.25%] [G loss: 0.972949]\n",
      "epoch:13 step:13110 [D loss: 0.248322, acc.: 92.97%] [G loss: 1.007763]\n",
      "epoch:13 step:13111 [D loss: 0.636571, acc.: 64.06%] [G loss: 0.893971]\n",
      "epoch:13 step:13112 [D loss: 0.454076, acc.: 89.06%] [G loss: 0.846925]\n",
      "epoch:13 step:13113 [D loss: 0.583840, acc.: 67.97%] [G loss: 1.077622]\n",
      "epoch:13 step:13114 [D loss: 0.370512, acc.: 89.84%] [G loss: 1.384953]\n",
      "epoch:13 step:13115 [D loss: 0.346078, acc.: 91.41%] [G loss: 0.928959]\n",
      "epoch:13 step:13116 [D loss: 0.459950, acc.: 77.34%] [G loss: 1.301053]\n",
      "epoch:13 step:13117 [D loss: 0.283837, acc.: 93.75%] [G loss: 1.332709]\n",
      "epoch:13 step:13118 [D loss: 0.285706, acc.: 89.06%] [G loss: 1.179023]\n",
      "epoch:14 step:13119 [D loss: 0.706295, acc.: 63.28%] [G loss: 1.231289]\n",
      "epoch:14 step:13120 [D loss: 1.137067, acc.: 15.62%] [G loss: 1.032421]\n",
      "epoch:14 step:13121 [D loss: 0.871422, acc.: 42.19%] [G loss: 0.892233]\n",
      "epoch:14 step:13122 [D loss: 0.674606, acc.: 57.03%] [G loss: 0.989234]\n",
      "epoch:14 step:13123 [D loss: 0.915630, acc.: 39.06%] [G loss: 0.886674]\n",
      "epoch:14 step:13124 [D loss: 0.876776, acc.: 34.38%] [G loss: 0.866352]\n",
      "epoch:14 step:13125 [D loss: 0.855220, acc.: 42.19%] [G loss: 0.891579]\n",
      "epoch:14 step:13126 [D loss: 0.833505, acc.: 33.59%] [G loss: 0.978261]\n",
      "epoch:14 step:13127 [D loss: 0.637014, acc.: 63.28%] [G loss: 0.984473]\n",
      "epoch:14 step:13128 [D loss: 0.696703, acc.: 59.38%] [G loss: 0.847628]\n",
      "epoch:14 step:13129 [D loss: 0.743869, acc.: 46.09%] [G loss: 1.060306]\n",
      "epoch:14 step:13130 [D loss: 0.716924, acc.: 57.03%] [G loss: 0.543023]\n",
      "epoch:14 step:13131 [D loss: 0.731873, acc.: 46.09%] [G loss: 1.110279]\n",
      "epoch:14 step:13132 [D loss: 0.588873, acc.: 71.09%] [G loss: 1.015455]\n",
      "epoch:14 step:13133 [D loss: 0.726418, acc.: 50.78%] [G loss: 0.846611]\n",
      "epoch:14 step:13134 [D loss: 0.726674, acc.: 51.56%] [G loss: 0.985096]\n",
      "epoch:14 step:13135 [D loss: 0.760977, acc.: 46.88%] [G loss: 1.109562]\n",
      "epoch:14 step:13136 [D loss: 0.759153, acc.: 50.78%] [G loss: 1.077243]\n",
      "epoch:14 step:13137 [D loss: 0.882812, acc.: 30.47%] [G loss: 1.048634]\n",
      "epoch:14 step:13138 [D loss: 0.735514, acc.: 49.22%] [G loss: 0.927965]\n",
      "epoch:14 step:13139 [D loss: 0.686159, acc.: 59.38%] [G loss: 1.169997]\n",
      "epoch:14 step:13140 [D loss: 0.657281, acc.: 61.72%] [G loss: 1.113638]\n",
      "epoch:14 step:13141 [D loss: 0.702251, acc.: 57.03%] [G loss: 1.117239]\n",
      "epoch:14 step:13142 [D loss: 0.671065, acc.: 64.84%] [G loss: 1.037663]\n",
      "epoch:14 step:13143 [D loss: 0.664837, acc.: 60.16%] [G loss: 0.840158]\n",
      "epoch:14 step:13144 [D loss: 0.751247, acc.: 46.09%] [G loss: 0.951496]\n",
      "epoch:14 step:13145 [D loss: 0.495128, acc.: 75.78%] [G loss: 1.132716]\n",
      "epoch:14 step:13146 [D loss: 0.575742, acc.: 68.75%] [G loss: 1.274467]\n",
      "epoch:14 step:13147 [D loss: 0.628748, acc.: 67.19%] [G loss: 1.302771]\n",
      "epoch:14 step:13148 [D loss: 0.568357, acc.: 71.09%] [G loss: 1.377151]\n",
      "epoch:14 step:13149 [D loss: 0.401912, acc.: 88.28%] [G loss: 1.478736]\n",
      "epoch:14 step:13150 [D loss: 0.491197, acc.: 82.03%] [G loss: 1.448359]\n",
      "epoch:14 step:13151 [D loss: 0.351011, acc.: 91.41%] [G loss: 1.365097]\n",
      "epoch:14 step:13152 [D loss: 0.388488, acc.: 89.84%] [G loss: 1.204463]\n",
      "epoch:14 step:13153 [D loss: 0.384227, acc.: 79.69%] [G loss: 1.623341]\n",
      "epoch:14 step:13154 [D loss: 0.194296, acc.: 94.53%] [G loss: 1.730986]\n",
      "epoch:14 step:13155 [D loss: 0.806569, acc.: 53.91%] [G loss: 1.396846]\n",
      "epoch:14 step:13156 [D loss: 1.074948, acc.: 36.72%] [G loss: 0.858503]\n",
      "epoch:14 step:13157 [D loss: 0.877449, acc.: 36.72%] [G loss: 0.964690]\n",
      "epoch:14 step:13158 [D loss: 0.788623, acc.: 42.19%] [G loss: 0.895174]\n",
      "epoch:14 step:13159 [D loss: 0.757509, acc.: 42.97%] [G loss: 0.907229]\n",
      "epoch:14 step:13160 [D loss: 0.695629, acc.: 53.91%] [G loss: 0.988260]\n",
      "epoch:14 step:13161 [D loss: 0.589935, acc.: 69.53%] [G loss: 0.969455]\n",
      "epoch:14 step:13162 [D loss: 0.654617, acc.: 64.84%] [G loss: 0.952434]\n",
      "epoch:14 step:13163 [D loss: 0.698419, acc.: 57.03%] [G loss: 0.909021]\n",
      "epoch:14 step:13164 [D loss: 0.617259, acc.: 64.84%] [G loss: 0.741540]\n",
      "epoch:14 step:13165 [D loss: 0.636453, acc.: 60.94%] [G loss: 1.003723]\n",
      "epoch:14 step:13166 [D loss: 0.854484, acc.: 42.19%] [G loss: 0.805131]\n",
      "epoch:14 step:13167 [D loss: 0.766134, acc.: 46.09%] [G loss: 1.116790]\n",
      "epoch:14 step:13168 [D loss: 0.620239, acc.: 70.31%] [G loss: 1.059103]\n",
      "epoch:14 step:13169 [D loss: 0.892430, acc.: 39.06%] [G loss: 1.155590]\n",
      "epoch:14 step:13170 [D loss: 0.640688, acc.: 60.94%] [G loss: 1.163604]\n",
      "epoch:14 step:13171 [D loss: 0.644070, acc.: 61.72%] [G loss: 1.268604]\n",
      "epoch:14 step:13172 [D loss: 0.597141, acc.: 66.41%] [G loss: 1.250977]\n",
      "epoch:14 step:13173 [D loss: 0.598301, acc.: 71.88%] [G loss: 1.147246]\n",
      "epoch:14 step:13174 [D loss: 0.651376, acc.: 60.94%] [G loss: 1.132329]\n",
      "epoch:14 step:13175 [D loss: 0.597581, acc.: 71.88%] [G loss: 1.119336]\n",
      "epoch:14 step:13176 [D loss: 0.618441, acc.: 66.41%] [G loss: 0.995708]\n",
      "epoch:14 step:13177 [D loss: 0.673152, acc.: 60.94%] [G loss: 0.871738]\n",
      "epoch:14 step:13178 [D loss: 0.622042, acc.: 64.84%] [G loss: 0.935284]\n",
      "epoch:14 step:13179 [D loss: 0.671942, acc.: 54.69%] [G loss: 1.021335]\n",
      "epoch:14 step:13180 [D loss: 0.642120, acc.: 63.28%] [G loss: 0.847864]\n",
      "epoch:14 step:13181 [D loss: 0.663439, acc.: 59.38%] [G loss: 0.896556]\n",
      "epoch:14 step:13182 [D loss: 0.650691, acc.: 57.03%] [G loss: 0.978934]\n",
      "epoch:14 step:13183 [D loss: 0.666332, acc.: 61.72%] [G loss: 0.905295]\n",
      "epoch:14 step:13184 [D loss: 0.617444, acc.: 65.62%] [G loss: 0.926773]\n",
      "epoch:14 step:13185 [D loss: 0.637932, acc.: 60.94%] [G loss: 0.939110]\n",
      "epoch:14 step:13186 [D loss: 0.568109, acc.: 75.78%] [G loss: 0.743367]\n",
      "epoch:14 step:13187 [D loss: 0.544551, acc.: 78.12%] [G loss: 1.022455]\n",
      "epoch:14 step:13188 [D loss: 0.678544, acc.: 57.81%] [G loss: 0.857671]\n",
      "epoch:14 step:13189 [D loss: 0.423093, acc.: 80.47%] [G loss: 0.981761]\n",
      "epoch:14 step:13190 [D loss: 0.760142, acc.: 46.09%] [G loss: 0.927156]\n",
      "epoch:14 step:13191 [D loss: 0.680924, acc.: 58.59%] [G loss: 0.829137]\n",
      "epoch:14 step:13192 [D loss: 0.647462, acc.: 60.94%] [G loss: 0.963158]\n",
      "epoch:14 step:13193 [D loss: 0.550857, acc.: 76.56%] [G loss: 0.988487]\n",
      "epoch:14 step:13194 [D loss: 0.355451, acc.: 83.59%] [G loss: 1.143827]\n",
      "epoch:14 step:13195 [D loss: 0.364324, acc.: 86.72%] [G loss: 1.216235]\n",
      "epoch:14 step:13196 [D loss: 0.700154, acc.: 55.47%] [G loss: 1.170179]\n",
      "epoch:14 step:13197 [D loss: 0.640574, acc.: 66.41%] [G loss: 0.921576]\n",
      "epoch:14 step:13198 [D loss: 0.676632, acc.: 57.03%] [G loss: 0.928802]\n",
      "epoch:14 step:13199 [D loss: 0.705021, acc.: 53.91%] [G loss: 0.983600]\n",
      "epoch:14 step:13200 [D loss: 0.625864, acc.: 62.50%] [G loss: 0.832197]\n",
      "##############\n",
      "[3.97031435 2.36900519 6.77811588 5.39531008 4.15930973 6.27882345\n",
      " 5.16520292 5.73703622 5.68329631 5.11822133]\n",
      "##########\n",
      "epoch:14 step:13201 [D loss: 0.735084, acc.: 52.34%] [G loss: 1.020184]\n",
      "epoch:14 step:13202 [D loss: 0.691329, acc.: 53.91%] [G loss: 0.884570]\n",
      "epoch:14 step:13203 [D loss: 0.741077, acc.: 54.69%] [G loss: 0.932845]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:14 step:13204 [D loss: 0.606211, acc.: 69.53%] [G loss: 0.880387]\n",
      "epoch:14 step:13205 [D loss: 0.695517, acc.: 53.91%] [G loss: 0.869539]\n",
      "epoch:14 step:13206 [D loss: 0.606257, acc.: 68.75%] [G loss: 0.816244]\n",
      "epoch:14 step:13207 [D loss: 0.598956, acc.: 68.75%] [G loss: 0.978632]\n",
      "epoch:14 step:13208 [D loss: 0.683990, acc.: 61.72%] [G loss: 0.942879]\n",
      "epoch:14 step:13209 [D loss: 0.643570, acc.: 60.94%] [G loss: 0.880175]\n",
      "epoch:14 step:13210 [D loss: 0.613517, acc.: 67.19%] [G loss: 0.971874]\n",
      "epoch:14 step:13211 [D loss: 0.638561, acc.: 59.38%] [G loss: 0.832067]\n",
      "epoch:14 step:13212 [D loss: 0.695694, acc.: 55.47%] [G loss: 0.913571]\n",
      "epoch:14 step:13213 [D loss: 0.667512, acc.: 61.72%] [G loss: 0.894391]\n",
      "epoch:14 step:13214 [D loss: 0.653358, acc.: 60.94%] [G loss: 0.774962]\n",
      "epoch:14 step:13215 [D loss: 0.568932, acc.: 77.34%] [G loss: 0.846227]\n",
      "epoch:14 step:13216 [D loss: 0.721733, acc.: 50.78%] [G loss: 0.779405]\n",
      "epoch:14 step:13217 [D loss: 0.653149, acc.: 57.81%] [G loss: 0.954926]\n",
      "epoch:14 step:13218 [D loss: 0.559667, acc.: 78.12%] [G loss: 0.881939]\n",
      "epoch:14 step:13219 [D loss: 0.724379, acc.: 55.47%] [G loss: 0.906032]\n",
      "epoch:14 step:13220 [D loss: 0.645925, acc.: 62.50%] [G loss: 0.835027]\n",
      "epoch:14 step:13221 [D loss: 0.612813, acc.: 66.41%] [G loss: 0.914217]\n",
      "epoch:14 step:13222 [D loss: 0.563057, acc.: 71.88%] [G loss: 0.928587]\n",
      "epoch:14 step:13223 [D loss: 0.383096, acc.: 85.16%] [G loss: 0.890196]\n",
      "epoch:14 step:13224 [D loss: 0.704350, acc.: 53.91%] [G loss: 0.861174]\n",
      "epoch:14 step:13225 [D loss: 0.536348, acc.: 68.75%] [G loss: 0.987184]\n",
      "epoch:14 step:13226 [D loss: 0.581258, acc.: 70.31%] [G loss: 0.836388]\n",
      "epoch:14 step:13227 [D loss: 0.649168, acc.: 60.16%] [G loss: 0.770097]\n",
      "epoch:14 step:13228 [D loss: 0.729902, acc.: 48.44%] [G loss: 1.041209]\n",
      "epoch:14 step:13229 [D loss: 0.682897, acc.: 58.59%] [G loss: 0.896552]\n",
      "epoch:14 step:13230 [D loss: 0.626886, acc.: 63.28%] [G loss: 1.069022]\n",
      "epoch:14 step:13231 [D loss: 0.710956, acc.: 57.03%] [G loss: 0.907428]\n",
      "epoch:14 step:13232 [D loss: 0.642359, acc.: 59.38%] [G loss: 0.979302]\n",
      "epoch:14 step:13233 [D loss: 0.660474, acc.: 57.81%] [G loss: 0.680092]\n",
      "epoch:14 step:13234 [D loss: 0.627134, acc.: 66.41%] [G loss: 1.115384]\n",
      "epoch:14 step:13235 [D loss: 0.651717, acc.: 62.50%] [G loss: 0.453542]\n",
      "epoch:14 step:13236 [D loss: 0.479647, acc.: 74.22%] [G loss: 0.852485]\n",
      "epoch:14 step:13237 [D loss: 0.311127, acc.: 82.81%] [G loss: 0.845920]\n",
      "epoch:14 step:13238 [D loss: 0.718584, acc.: 56.25%] [G loss: 1.109272]\n",
      "epoch:14 step:13239 [D loss: 0.646491, acc.: 59.38%] [G loss: 0.805623]\n",
      "epoch:14 step:13240 [D loss: 0.857779, acc.: 51.56%] [G loss: 1.193680]\n",
      "epoch:14 step:13241 [D loss: 0.767059, acc.: 46.09%] [G loss: 1.292398]\n",
      "epoch:14 step:13242 [D loss: 0.812850, acc.: 49.22%] [G loss: 1.488551]\n",
      "epoch:14 step:13243 [D loss: 0.687885, acc.: 56.25%] [G loss: 1.429893]\n",
      "epoch:14 step:13244 [D loss: 0.613908, acc.: 67.19%] [G loss: 1.254693]\n",
      "epoch:14 step:13245 [D loss: 0.627210, acc.: 62.50%] [G loss: 1.155303]\n",
      "epoch:14 step:13246 [D loss: 0.618689, acc.: 63.28%] [G loss: 1.088318]\n",
      "epoch:14 step:13247 [D loss: 0.522980, acc.: 78.12%] [G loss: 1.156610]\n",
      "epoch:14 step:13248 [D loss: 0.498664, acc.: 82.03%] [G loss: 1.027869]\n",
      "epoch:14 step:13249 [D loss: 0.430707, acc.: 86.72%] [G loss: 1.410676]\n",
      "epoch:14 step:13250 [D loss: 0.471471, acc.: 85.16%] [G loss: 1.167854]\n",
      "epoch:14 step:13251 [D loss: 0.668718, acc.: 58.59%] [G loss: 1.173337]\n",
      "epoch:14 step:13252 [D loss: 0.789517, acc.: 49.22%] [G loss: 1.147749]\n",
      "epoch:14 step:13253 [D loss: 0.728330, acc.: 57.81%] [G loss: 0.966776]\n",
      "epoch:14 step:13254 [D loss: 0.678274, acc.: 55.47%] [G loss: 1.090047]\n",
      "epoch:14 step:13255 [D loss: 0.664745, acc.: 60.94%] [G loss: 0.821586]\n",
      "epoch:14 step:13256 [D loss: 0.592974, acc.: 70.31%] [G loss: 0.895692]\n",
      "epoch:14 step:13257 [D loss: 0.489300, acc.: 83.59%] [G loss: 1.138564]\n",
      "epoch:14 step:13258 [D loss: 0.736337, acc.: 53.12%] [G loss: 0.916900]\n",
      "epoch:14 step:13259 [D loss: 0.743967, acc.: 50.00%] [G loss: 0.986676]\n",
      "epoch:14 step:13260 [D loss: 0.804985, acc.: 33.59%] [G loss: 0.851875]\n",
      "epoch:14 step:13261 [D loss: 0.469620, acc.: 78.12%] [G loss: 1.005373]\n",
      "epoch:14 step:13262 [D loss: 0.617658, acc.: 70.31%] [G loss: 0.922130]\n",
      "epoch:14 step:13263 [D loss: 0.437621, acc.: 83.59%] [G loss: 1.011019]\n",
      "epoch:14 step:13264 [D loss: 0.631754, acc.: 66.41%] [G loss: 0.620109]\n",
      "epoch:14 step:13265 [D loss: 0.647057, acc.: 64.84%] [G loss: 1.023534]\n",
      "epoch:14 step:13266 [D loss: 0.698561, acc.: 60.16%] [G loss: 0.921207]\n",
      "epoch:14 step:13267 [D loss: 0.363942, acc.: 86.72%] [G loss: 0.846748]\n",
      "epoch:14 step:13268 [D loss: 0.280581, acc.: 94.53%] [G loss: 1.018076]\n",
      "epoch:14 step:13269 [D loss: 0.645898, acc.: 61.72%] [G loss: 1.117267]\n",
      "epoch:14 step:13270 [D loss: 0.619040, acc.: 65.62%] [G loss: 1.157942]\n",
      "epoch:14 step:13271 [D loss: 0.670340, acc.: 55.47%] [G loss: 1.066433]\n",
      "epoch:14 step:13272 [D loss: 0.622612, acc.: 64.06%] [G loss: 1.063991]\n",
      "epoch:14 step:13273 [D loss: 0.578909, acc.: 71.88%] [G loss: 0.752268]\n",
      "epoch:14 step:13274 [D loss: 0.637397, acc.: 60.16%] [G loss: 1.002601]\n",
      "epoch:14 step:13275 [D loss: 0.694038, acc.: 55.47%] [G loss: 0.730009]\n",
      "epoch:14 step:13276 [D loss: 0.665020, acc.: 63.28%] [G loss: 1.025938]\n",
      "epoch:14 step:13277 [D loss: 0.663845, acc.: 63.28%] [G loss: 0.659818]\n",
      "epoch:14 step:13278 [D loss: 0.633488, acc.: 60.94%] [G loss: 0.947841]\n",
      "epoch:14 step:13279 [D loss: 0.714064, acc.: 52.34%] [G loss: 0.924938]\n",
      "epoch:14 step:13280 [D loss: 0.641400, acc.: 59.38%] [G loss: 0.875486]\n",
      "epoch:14 step:13281 [D loss: 0.578678, acc.: 69.53%] [G loss: 0.929554]\n",
      "epoch:14 step:13282 [D loss: 0.481586, acc.: 83.59%] [G loss: 0.864764]\n",
      "epoch:14 step:13283 [D loss: 0.907751, acc.: 41.41%] [G loss: 1.016346]\n",
      "epoch:14 step:13284 [D loss: 0.668628, acc.: 57.81%] [G loss: 0.995610]\n",
      "epoch:14 step:13285 [D loss: 0.725014, acc.: 46.88%] [G loss: 0.747800]\n",
      "epoch:14 step:13286 [D loss: 0.607439, acc.: 67.97%] [G loss: 1.004989]\n",
      "epoch:14 step:13287 [D loss: 0.793201, acc.: 47.66%] [G loss: 1.125853]\n",
      "epoch:14 step:13288 [D loss: 0.616774, acc.: 67.97%] [G loss: 1.042069]\n",
      "epoch:14 step:13289 [D loss: 0.608425, acc.: 64.84%] [G loss: 1.010611]\n",
      "epoch:14 step:13290 [D loss: 0.721753, acc.: 50.00%] [G loss: 0.871669]\n",
      "epoch:14 step:13291 [D loss: 0.550153, acc.: 74.22%] [G loss: 1.085091]\n",
      "epoch:14 step:13292 [D loss: 0.629920, acc.: 64.06%] [G loss: 0.998069]\n",
      "epoch:14 step:13293 [D loss: 0.739244, acc.: 51.56%] [G loss: 0.964465]\n",
      "epoch:14 step:13294 [D loss: 0.496659, acc.: 78.91%] [G loss: 1.026694]\n",
      "epoch:14 step:13295 [D loss: 0.665461, acc.: 57.81%] [G loss: 0.872811]\n",
      "epoch:14 step:13296 [D loss: 0.657846, acc.: 60.16%] [G loss: 0.896615]\n",
      "epoch:14 step:13297 [D loss: 0.779677, acc.: 42.97%] [G loss: 0.909682]\n",
      "epoch:14 step:13298 [D loss: 0.592962, acc.: 69.53%] [G loss: 0.946342]\n",
      "epoch:14 step:13299 [D loss: 0.521007, acc.: 75.00%] [G loss: 0.918787]\n",
      "epoch:14 step:13300 [D loss: 0.604275, acc.: 65.62%] [G loss: 1.032918]\n",
      "epoch:14 step:13301 [D loss: 0.587873, acc.: 70.31%] [G loss: 1.027647]\n",
      "epoch:14 step:13302 [D loss: 0.479750, acc.: 77.34%] [G loss: 0.865840]\n",
      "epoch:14 step:13303 [D loss: 0.698853, acc.: 58.59%] [G loss: 0.846605]\n",
      "epoch:14 step:13304 [D loss: 0.719472, acc.: 47.66%] [G loss: 0.902767]\n",
      "epoch:14 step:13305 [D loss: 0.686955, acc.: 58.59%] [G loss: 0.628256]\n",
      "epoch:14 step:13306 [D loss: 0.515833, acc.: 80.47%] [G loss: 0.900990]\n",
      "epoch:14 step:13307 [D loss: 0.636764, acc.: 64.84%] [G loss: 0.920999]\n",
      "epoch:14 step:13308 [D loss: 0.545420, acc.: 72.66%] [G loss: 1.075064]\n",
      "epoch:14 step:13309 [D loss: 0.543928, acc.: 74.22%] [G loss: 0.933011]\n",
      "epoch:14 step:13310 [D loss: 0.443216, acc.: 81.25%] [G loss: 1.051561]\n",
      "epoch:14 step:13311 [D loss: 0.779890, acc.: 42.97%] [G loss: 0.961904]\n",
      "epoch:14 step:13312 [D loss: 0.479989, acc.: 77.34%] [G loss: 1.317420]\n",
      "epoch:14 step:13313 [D loss: 0.613521, acc.: 65.62%] [G loss: 1.222086]\n",
      "epoch:14 step:13314 [D loss: 0.645079, acc.: 60.94%] [G loss: 0.882124]\n",
      "epoch:14 step:13315 [D loss: 0.771417, acc.: 53.12%] [G loss: 0.862183]\n",
      "epoch:14 step:13316 [D loss: 0.523544, acc.: 78.91%] [G loss: 1.253372]\n",
      "epoch:14 step:13317 [D loss: 0.859137, acc.: 35.94%] [G loss: 1.430897]\n",
      "epoch:14 step:13318 [D loss: 0.493037, acc.: 76.56%] [G loss: 1.085412]\n",
      "epoch:14 step:13319 [D loss: 0.458520, acc.: 79.69%] [G loss: 1.453344]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:14 step:13320 [D loss: 0.876140, acc.: 39.06%] [G loss: 1.027722]\n",
      "epoch:14 step:13321 [D loss: 0.752261, acc.: 56.25%] [G loss: 0.968897]\n",
      "epoch:14 step:13322 [D loss: 0.666536, acc.: 60.16%] [G loss: 0.992081]\n",
      "epoch:14 step:13323 [D loss: 0.689608, acc.: 51.56%] [G loss: 0.915554]\n",
      "epoch:14 step:13324 [D loss: 0.635537, acc.: 67.97%] [G loss: 1.091932]\n",
      "epoch:14 step:13325 [D loss: 0.496660, acc.: 79.69%] [G loss: 1.108865]\n",
      "epoch:14 step:13326 [D loss: 0.616729, acc.: 69.53%] [G loss: 1.356752]\n",
      "epoch:14 step:13327 [D loss: 0.540191, acc.: 75.78%] [G loss: 1.008837]\n",
      "epoch:14 step:13328 [D loss: 0.731345, acc.: 56.25%] [G loss: 0.868038]\n",
      "epoch:14 step:13329 [D loss: 0.829583, acc.: 36.72%] [G loss: 1.049564]\n",
      "epoch:14 step:13330 [D loss: 0.759735, acc.: 50.78%] [G loss: 1.065982]\n",
      "epoch:14 step:13331 [D loss: 0.716099, acc.: 51.56%] [G loss: 1.100018]\n",
      "epoch:14 step:13332 [D loss: 0.734048, acc.: 50.00%] [G loss: 0.945129]\n",
      "epoch:14 step:13333 [D loss: 0.753845, acc.: 51.56%] [G loss: 0.957730]\n",
      "epoch:14 step:13334 [D loss: 0.735137, acc.: 52.34%] [G loss: 0.867802]\n",
      "epoch:14 step:13335 [D loss: 0.679552, acc.: 63.28%] [G loss: 0.867774]\n",
      "epoch:14 step:13336 [D loss: 0.617373, acc.: 67.19%] [G loss: 0.857505]\n",
      "epoch:14 step:13337 [D loss: 0.648891, acc.: 57.03%] [G loss: 0.831088]\n",
      "epoch:14 step:13338 [D loss: 0.291665, acc.: 89.84%] [G loss: 1.076344]\n",
      "epoch:14 step:13339 [D loss: 0.306912, acc.: 85.94%] [G loss: 1.128730]\n",
      "epoch:14 step:13340 [D loss: 0.483977, acc.: 82.03%] [G loss: 1.162580]\n",
      "epoch:14 step:13341 [D loss: 0.502982, acc.: 79.69%] [G loss: 1.235319]\n",
      "epoch:14 step:13342 [D loss: 0.736335, acc.: 57.81%] [G loss: 1.095189]\n",
      "epoch:14 step:13343 [D loss: 0.655517, acc.: 59.38%] [G loss: 1.046746]\n",
      "epoch:14 step:13344 [D loss: 0.620087, acc.: 69.53%] [G loss: 0.939959]\n",
      "epoch:14 step:13345 [D loss: 0.590400, acc.: 66.41%] [G loss: 0.984218]\n",
      "epoch:14 step:13346 [D loss: 0.717023, acc.: 57.03%] [G loss: 1.059468]\n",
      "epoch:14 step:13347 [D loss: 0.616248, acc.: 60.94%] [G loss: 1.025396]\n",
      "epoch:14 step:13348 [D loss: 0.227953, acc.: 94.53%] [G loss: 0.968753]\n",
      "epoch:14 step:13349 [D loss: 0.283983, acc.: 92.19%] [G loss: 1.365661]\n",
      "epoch:14 step:13350 [D loss: 0.253935, acc.: 89.84%] [G loss: 1.230479]\n",
      "epoch:14 step:13351 [D loss: 0.670650, acc.: 66.41%] [G loss: 1.252070]\n",
      "epoch:14 step:13352 [D loss: 0.431189, acc.: 84.38%] [G loss: 1.247557]\n",
      "epoch:14 step:13353 [D loss: 0.312629, acc.: 92.19%] [G loss: 1.350158]\n",
      "epoch:14 step:13354 [D loss: 0.615254, acc.: 66.41%] [G loss: 0.993377]\n",
      "epoch:14 step:13355 [D loss: 0.404101, acc.: 84.38%] [G loss: 0.867471]\n",
      "epoch:14 step:13356 [D loss: 0.727526, acc.: 58.59%] [G loss: 0.980556]\n",
      "epoch:14 step:13357 [D loss: 0.767945, acc.: 52.34%] [G loss: 1.509709]\n",
      "epoch:14 step:13358 [D loss: 0.815054, acc.: 42.19%] [G loss: 0.320976]\n",
      "epoch:14 step:13359 [D loss: 0.914604, acc.: 41.41%] [G loss: 0.931479]\n",
      "epoch:14 step:13360 [D loss: 0.953122, acc.: 35.16%] [G loss: 1.056165]\n",
      "epoch:14 step:13361 [D loss: 0.723174, acc.: 48.44%] [G loss: 0.979186]\n",
      "epoch:14 step:13362 [D loss: 0.715623, acc.: 48.44%] [G loss: 1.105888]\n",
      "epoch:14 step:13363 [D loss: 0.807672, acc.: 36.72%] [G loss: 0.933790]\n",
      "epoch:14 step:13364 [D loss: 0.774388, acc.: 41.41%] [G loss: 0.909662]\n",
      "epoch:14 step:13365 [D loss: 0.717119, acc.: 50.00%] [G loss: 0.656775]\n",
      "epoch:14 step:13366 [D loss: 0.654425, acc.: 59.38%] [G loss: 0.934016]\n",
      "epoch:14 step:13367 [D loss: 0.664268, acc.: 57.03%] [G loss: 0.518018]\n",
      "epoch:14 step:13368 [D loss: 0.687960, acc.: 57.03%] [G loss: 1.011042]\n",
      "epoch:14 step:13369 [D loss: 0.654635, acc.: 62.50%] [G loss: 0.956308]\n",
      "epoch:14 step:13370 [D loss: 0.676314, acc.: 56.25%] [G loss: 0.883498]\n",
      "epoch:14 step:13371 [D loss: 0.668078, acc.: 62.50%] [G loss: 0.933038]\n",
      "epoch:14 step:13372 [D loss: 0.666950, acc.: 60.16%] [G loss: 0.768463]\n",
      "epoch:14 step:13373 [D loss: 0.511606, acc.: 88.28%] [G loss: 0.968402]\n",
      "epoch:14 step:13374 [D loss: 0.500163, acc.: 64.84%] [G loss: 0.672676]\n",
      "epoch:14 step:13375 [D loss: 0.596733, acc.: 73.44%] [G loss: 1.106922]\n",
      "epoch:14 step:13376 [D loss: 0.669807, acc.: 64.06%] [G loss: 1.123442]\n",
      "epoch:14 step:13377 [D loss: 0.287378, acc.: 94.53%] [G loss: 0.475301]\n",
      "epoch:14 step:13378 [D loss: 0.520786, acc.: 67.19%] [G loss: 1.158453]\n",
      "epoch:14 step:13379 [D loss: 0.374649, acc.: 95.31%] [G loss: 1.257275]\n",
      "epoch:14 step:13380 [D loss: 0.700027, acc.: 58.59%] [G loss: 1.261882]\n",
      "epoch:14 step:13381 [D loss: 0.608608, acc.: 64.06%] [G loss: 0.685119]\n",
      "epoch:14 step:13382 [D loss: 0.503051, acc.: 78.91%] [G loss: 1.181972]\n",
      "epoch:14 step:13383 [D loss: 0.422428, acc.: 90.62%] [G loss: 1.134002]\n",
      "epoch:14 step:13384 [D loss: 0.636724, acc.: 60.94%] [G loss: 0.534502]\n",
      "epoch:14 step:13385 [D loss: 0.633531, acc.: 61.72%] [G loss: 0.606342]\n",
      "epoch:14 step:13386 [D loss: 0.629610, acc.: 60.16%] [G loss: 1.155121]\n",
      "epoch:14 step:13387 [D loss: 0.469668, acc.: 82.81%] [G loss: 1.101076]\n",
      "epoch:14 step:13388 [D loss: 1.011497, acc.: 35.16%] [G loss: 1.374931]\n",
      "epoch:14 step:13389 [D loss: 0.537591, acc.: 71.88%] [G loss: 1.311809]\n",
      "epoch:14 step:13390 [D loss: 0.632184, acc.: 60.16%] [G loss: 1.120391]\n",
      "epoch:14 step:13391 [D loss: 0.438643, acc.: 85.94%] [G loss: 1.683962]\n",
      "epoch:14 step:13392 [D loss: 0.454637, acc.: 78.91%] [G loss: 1.225461]\n",
      "epoch:14 step:13393 [D loss: 0.618985, acc.: 64.06%] [G loss: 1.312993]\n",
      "epoch:14 step:13394 [D loss: 0.394615, acc.: 85.94%] [G loss: 1.927419]\n",
      "epoch:14 step:13395 [D loss: 0.600144, acc.: 61.72%] [G loss: 1.308411]\n",
      "epoch:14 step:13396 [D loss: 0.698311, acc.: 60.94%] [G loss: 1.338057]\n",
      "epoch:14 step:13397 [D loss: 0.434393, acc.: 82.03%] [G loss: 0.911409]\n",
      "epoch:14 step:13398 [D loss: 0.716341, acc.: 60.16%] [G loss: 1.064224]\n",
      "epoch:14 step:13399 [D loss: 0.859656, acc.: 55.47%] [G loss: 1.591174]\n",
      "epoch:14 step:13400 [D loss: 0.557368, acc.: 72.66%] [G loss: 1.399260]\n",
      "##############\n",
      "[3.96820433 2.64006065 6.2526222  5.66976045 4.11057413 5.72978855\n",
      " 5.40495996 5.42854084 5.53088143 4.45585441]\n",
      "##########\n",
      "epoch:14 step:13401 [D loss: 0.552121, acc.: 71.88%] [G loss: 0.859117]\n",
      "epoch:14 step:13402 [D loss: 0.779920, acc.: 52.34%] [G loss: 0.946908]\n",
      "epoch:14 step:13403 [D loss: 0.865706, acc.: 35.94%] [G loss: 0.982600]\n",
      "epoch:14 step:13404 [D loss: 0.900338, acc.: 36.72%] [G loss: 1.166645]\n",
      "epoch:14 step:13405 [D loss: 0.770332, acc.: 54.69%] [G loss: 0.816205]\n",
      "epoch:14 step:13406 [D loss: 0.673681, acc.: 53.91%] [G loss: 0.821593]\n",
      "epoch:14 step:13407 [D loss: 0.648949, acc.: 60.94%] [G loss: 0.910327]\n",
      "epoch:14 step:13408 [D loss: 0.641879, acc.: 63.28%] [G loss: 0.835318]\n",
      "epoch:14 step:13409 [D loss: 0.742816, acc.: 51.56%] [G loss: 0.917974]\n",
      "epoch:14 step:13410 [D loss: 0.639058, acc.: 60.94%] [G loss: 0.879312]\n",
      "epoch:14 step:13411 [D loss: 0.568256, acc.: 70.31%] [G loss: 0.954479]\n",
      "epoch:14 step:13412 [D loss: 0.653055, acc.: 58.59%] [G loss: 0.877753]\n",
      "epoch:14 step:13413 [D loss: 0.661489, acc.: 59.38%] [G loss: 0.796683]\n",
      "epoch:14 step:13414 [D loss: 0.662042, acc.: 61.72%] [G loss: 0.840587]\n",
      "epoch:14 step:13415 [D loss: 0.587765, acc.: 67.19%] [G loss: 0.995411]\n",
      "epoch:14 step:13416 [D loss: 0.507897, acc.: 82.03%] [G loss: 0.919413]\n",
      "epoch:14 step:13417 [D loss: 0.488710, acc.: 85.16%] [G loss: 0.918266]\n",
      "epoch:14 step:13418 [D loss: 0.542908, acc.: 77.34%] [G loss: 0.993925]\n",
      "epoch:14 step:13419 [D loss: 0.623755, acc.: 67.97%] [G loss: 0.875906]\n",
      "epoch:14 step:13420 [D loss: 0.634197, acc.: 64.06%] [G loss: 0.799757]\n",
      "epoch:14 step:13421 [D loss: 0.611228, acc.: 68.75%] [G loss: 0.742356]\n",
      "epoch:14 step:13422 [D loss: 0.760228, acc.: 48.44%] [G loss: 0.829721]\n",
      "epoch:14 step:13423 [D loss: 0.695816, acc.: 56.25%] [G loss: 0.884739]\n",
      "epoch:14 step:13424 [D loss: 0.707905, acc.: 50.78%] [G loss: 0.869750]\n",
      "epoch:14 step:13425 [D loss: 0.587647, acc.: 66.41%] [G loss: 0.935867]\n",
      "epoch:14 step:13426 [D loss: 0.716982, acc.: 50.00%] [G loss: 0.665905]\n",
      "epoch:14 step:13427 [D loss: 0.525095, acc.: 65.62%] [G loss: 0.869027]\n",
      "epoch:14 step:13428 [D loss: 0.646312, acc.: 58.59%] [G loss: 0.969574]\n",
      "epoch:14 step:13429 [D loss: 0.657098, acc.: 57.03%] [G loss: 0.905979]\n",
      "epoch:14 step:13430 [D loss: 0.434888, acc.: 71.09%] [G loss: 0.928132]\n",
      "epoch:14 step:13431 [D loss: 0.351710, acc.: 80.47%] [G loss: 1.092594]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:14 step:13432 [D loss: 0.263448, acc.: 91.41%] [G loss: 1.310592]\n",
      "epoch:14 step:13433 [D loss: 0.435588, acc.: 84.38%] [G loss: 1.228405]\n",
      "epoch:14 step:13434 [D loss: 0.776409, acc.: 47.66%] [G loss: 1.160756]\n",
      "epoch:14 step:13435 [D loss: 0.706719, acc.: 50.78%] [G loss: 0.932327]\n",
      "epoch:14 step:13436 [D loss: 0.727897, acc.: 46.88%] [G loss: 1.050907]\n",
      "epoch:14 step:13437 [D loss: 0.650930, acc.: 59.38%] [G loss: 0.753004]\n",
      "epoch:14 step:13438 [D loss: 0.714964, acc.: 52.34%] [G loss: 1.025510]\n",
      "epoch:14 step:13439 [D loss: 0.732731, acc.: 54.69%] [G loss: 0.967056]\n",
      "epoch:14 step:13440 [D loss: 0.724545, acc.: 53.91%] [G loss: 0.865605]\n",
      "epoch:14 step:13441 [D loss: 0.677703, acc.: 57.03%] [G loss: 1.035737]\n",
      "epoch:14 step:13442 [D loss: 0.663599, acc.: 59.38%] [G loss: 0.867066]\n",
      "epoch:14 step:13443 [D loss: 0.666589, acc.: 54.69%] [G loss: 1.006343]\n",
      "epoch:14 step:13444 [D loss: 0.725618, acc.: 57.03%] [G loss: 0.891435]\n",
      "epoch:14 step:13445 [D loss: 0.539150, acc.: 77.34%] [G loss: 0.916340]\n",
      "epoch:14 step:13446 [D loss: 0.591972, acc.: 67.97%] [G loss: 0.865932]\n",
      "epoch:14 step:13447 [D loss: 0.686375, acc.: 55.47%] [G loss: 1.101260]\n",
      "epoch:14 step:13448 [D loss: 0.729103, acc.: 51.56%] [G loss: 0.823967]\n",
      "epoch:14 step:13449 [D loss: 0.635872, acc.: 60.16%] [G loss: 0.983240]\n",
      "epoch:14 step:13450 [D loss: 0.637878, acc.: 61.72%] [G loss: 0.828713]\n",
      "epoch:14 step:13451 [D loss: 0.442459, acc.: 81.25%] [G loss: 0.881734]\n",
      "epoch:14 step:13452 [D loss: 0.306470, acc.: 88.28%] [G loss: 1.123954]\n",
      "epoch:14 step:13453 [D loss: 0.642276, acc.: 64.06%] [G loss: 1.046126]\n",
      "epoch:14 step:13454 [D loss: 0.306972, acc.: 94.53%] [G loss: 0.910291]\n",
      "epoch:14 step:13455 [D loss: 0.695116, acc.: 57.81%] [G loss: 1.136807]\n",
      "epoch:14 step:13456 [D loss: 0.595962, acc.: 70.31%] [G loss: 1.055445]\n",
      "epoch:14 step:13457 [D loss: 0.687256, acc.: 57.81%] [G loss: 1.067277]\n",
      "epoch:14 step:13458 [D loss: 0.736522, acc.: 51.56%] [G loss: 1.040604]\n",
      "epoch:14 step:13459 [D loss: 0.742593, acc.: 47.66%] [G loss: 0.955495]\n",
      "epoch:14 step:13460 [D loss: 0.448824, acc.: 84.38%] [G loss: 1.040274]\n",
      "epoch:14 step:13461 [D loss: 0.320444, acc.: 86.72%] [G loss: 0.912180]\n",
      "epoch:14 step:13462 [D loss: 0.359174, acc.: 92.19%] [G loss: 1.156631]\n",
      "epoch:14 step:13463 [D loss: 0.535582, acc.: 73.44%] [G loss: 1.254330]\n",
      "epoch:14 step:13464 [D loss: 0.202368, acc.: 96.09%] [G loss: 1.397148]\n",
      "epoch:14 step:13465 [D loss: 0.205569, acc.: 98.44%] [G loss: 1.365002]\n",
      "epoch:14 step:13466 [D loss: 0.740198, acc.: 55.47%] [G loss: 0.998455]\n",
      "epoch:14 step:13467 [D loss: 0.795833, acc.: 49.22%] [G loss: 1.127620]\n",
      "epoch:14 step:13468 [D loss: 0.584545, acc.: 71.88%] [G loss: 1.086349]\n",
      "epoch:14 step:13469 [D loss: 0.691454, acc.: 53.91%] [G loss: 1.034912]\n",
      "epoch:14 step:13470 [D loss: 0.692418, acc.: 54.69%] [G loss: 0.472105]\n",
      "epoch:14 step:13471 [D loss: 0.644656, acc.: 64.06%] [G loss: 1.081355]\n",
      "epoch:14 step:13472 [D loss: 0.643954, acc.: 61.72%] [G loss: 1.134051]\n",
      "epoch:14 step:13473 [D loss: 0.628237, acc.: 66.41%] [G loss: 0.602951]\n",
      "epoch:14 step:13474 [D loss: 0.733469, acc.: 49.22%] [G loss: 1.057512]\n",
      "epoch:14 step:13475 [D loss: 0.544604, acc.: 75.00%] [G loss: 0.584663]\n",
      "epoch:14 step:13476 [D loss: 0.665178, acc.: 58.59%] [G loss: 1.135043]\n",
      "epoch:14 step:13477 [D loss: 0.483305, acc.: 78.91%] [G loss: 1.010880]\n",
      "epoch:14 step:13478 [D loss: 0.969877, acc.: 44.53%] [G loss: 1.490079]\n",
      "epoch:14 step:13479 [D loss: 0.435946, acc.: 77.34%] [G loss: 1.330085]\n",
      "epoch:14 step:13480 [D loss: 0.711670, acc.: 58.59%] [G loss: 1.400454]\n",
      "epoch:14 step:13481 [D loss: 0.653033, acc.: 59.38%] [G loss: 1.241677]\n",
      "epoch:14 step:13482 [D loss: 0.455134, acc.: 85.94%] [G loss: 1.314204]\n",
      "epoch:14 step:13483 [D loss: 0.783182, acc.: 50.78%] [G loss: 1.047462]\n",
      "epoch:14 step:13484 [D loss: 0.560619, acc.: 74.22%] [G loss: 1.162495]\n",
      "epoch:14 step:13485 [D loss: 1.082695, acc.: 27.34%] [G loss: 0.946591]\n",
      "epoch:14 step:13486 [D loss: 0.660814, acc.: 56.25%] [G loss: 1.005058]\n",
      "epoch:14 step:13487 [D loss: 0.585528, acc.: 67.19%] [G loss: 1.042128]\n",
      "epoch:14 step:13488 [D loss: 0.382557, acc.: 90.62%] [G loss: 1.071002]\n",
      "epoch:14 step:13489 [D loss: 0.407464, acc.: 89.06%] [G loss: 1.256773]\n",
      "epoch:14 step:13490 [D loss: 0.475730, acc.: 80.47%] [G loss: 1.446489]\n",
      "epoch:14 step:13491 [D loss: 0.693218, acc.: 52.34%] [G loss: 1.324214]\n",
      "epoch:14 step:13492 [D loss: 0.563499, acc.: 68.75%] [G loss: 1.241930]\n",
      "epoch:14 step:13493 [D loss: 0.534713, acc.: 75.78%] [G loss: 1.107069]\n",
      "epoch:14 step:13494 [D loss: 0.690226, acc.: 54.69%] [G loss: 1.131594]\n",
      "epoch:14 step:13495 [D loss: 0.713540, acc.: 54.69%] [G loss: 0.748428]\n",
      "epoch:14 step:13496 [D loss: 0.648015, acc.: 58.59%] [G loss: 0.965092]\n",
      "epoch:14 step:13497 [D loss: 0.628238, acc.: 67.19%] [G loss: 0.912627]\n",
      "epoch:14 step:13498 [D loss: 0.397081, acc.: 85.94%] [G loss: 1.023188]\n",
      "epoch:14 step:13499 [D loss: 0.452831, acc.: 74.22%] [G loss: 1.267396]\n",
      "epoch:14 step:13500 [D loss: 0.671720, acc.: 59.38%] [G loss: 1.231446]\n",
      "epoch:14 step:13501 [D loss: 0.774762, acc.: 53.91%] [G loss: 1.013541]\n",
      "epoch:14 step:13502 [D loss: 0.716034, acc.: 51.56%] [G loss: 1.001190]\n",
      "epoch:14 step:13503 [D loss: 0.584543, acc.: 68.75%] [G loss: 1.017633]\n",
      "epoch:14 step:13504 [D loss: 0.545891, acc.: 71.88%] [G loss: 1.142529]\n",
      "epoch:14 step:13505 [D loss: 0.503356, acc.: 78.91%] [G loss: 1.172077]\n",
      "epoch:14 step:13506 [D loss: 0.620354, acc.: 67.19%] [G loss: 1.296131]\n",
      "epoch:14 step:13507 [D loss: 0.581818, acc.: 74.22%] [G loss: 1.058681]\n",
      "epoch:14 step:13508 [D loss: 0.823077, acc.: 39.84%] [G loss: 1.019397]\n",
      "epoch:14 step:13509 [D loss: 0.745672, acc.: 51.56%] [G loss: 1.042806]\n",
      "epoch:14 step:13510 [D loss: 0.772442, acc.: 48.44%] [G loss: 0.934462]\n",
      "epoch:14 step:13511 [D loss: 0.610130, acc.: 67.19%] [G loss: 0.850600]\n",
      "epoch:14 step:13512 [D loss: 0.740304, acc.: 45.31%] [G loss: 0.976873]\n",
      "epoch:14 step:13513 [D loss: 0.644276, acc.: 59.38%] [G loss: 1.039704]\n",
      "epoch:14 step:13514 [D loss: 0.526959, acc.: 75.78%] [G loss: 0.912934]\n",
      "epoch:14 step:13515 [D loss: 0.448302, acc.: 76.56%] [G loss: 1.044994]\n",
      "epoch:14 step:13516 [D loss: 0.486826, acc.: 75.00%] [G loss: 1.259474]\n",
      "epoch:14 step:13517 [D loss: 0.268856, acc.: 91.41%] [G loss: 1.288568]\n",
      "epoch:14 step:13518 [D loss: 0.721469, acc.: 60.94%] [G loss: 1.159286]\n",
      "epoch:14 step:13519 [D loss: 0.648037, acc.: 60.16%] [G loss: 1.085803]\n",
      "epoch:14 step:13520 [D loss: 0.316434, acc.: 93.75%] [G loss: 1.101054]\n",
      "epoch:14 step:13521 [D loss: 0.593904, acc.: 70.31%] [G loss: 1.123197]\n",
      "epoch:14 step:13522 [D loss: 0.383492, acc.: 91.41%] [G loss: 1.331069]\n",
      "epoch:14 step:13523 [D loss: 0.249059, acc.: 93.75%] [G loss: 1.158901]\n",
      "epoch:14 step:13524 [D loss: 0.262885, acc.: 96.88%] [G loss: 1.374098]\n",
      "epoch:14 step:13525 [D loss: 0.258752, acc.: 89.84%] [G loss: 1.520510]\n",
      "epoch:14 step:13526 [D loss: 0.365439, acc.: 93.75%] [G loss: 1.330874]\n",
      "epoch:14 step:13527 [D loss: 0.189329, acc.: 100.00%] [G loss: 1.084892]\n",
      "epoch:14 step:13528 [D loss: 0.374950, acc.: 91.41%] [G loss: 1.776620]\n",
      "epoch:14 step:13529 [D loss: 1.512942, acc.: 6.25%] [G loss: 1.353222]\n",
      "epoch:14 step:13530 [D loss: 0.255865, acc.: 95.31%] [G loss: 1.295115]\n",
      "epoch:14 step:13531 [D loss: 0.510644, acc.: 79.69%] [G loss: 0.518814]\n",
      "epoch:14 step:13532 [D loss: 0.373563, acc.: 92.19%] [G loss: 0.979583]\n",
      "epoch:14 step:13533 [D loss: 0.892660, acc.: 44.53%] [G loss: 1.172200]\n",
      "epoch:14 step:13534 [D loss: 0.337483, acc.: 92.97%] [G loss: 1.037668]\n",
      "epoch:14 step:13535 [D loss: 0.305664, acc.: 90.62%] [G loss: 1.152035]\n",
      "epoch:14 step:13536 [D loss: 0.351614, acc.: 84.38%] [G loss: 0.798812]\n",
      "epoch:14 step:13537 [D loss: 0.909352, acc.: 55.47%] [G loss: 1.290634]\n",
      "epoch:14 step:13538 [D loss: 0.883559, acc.: 50.00%] [G loss: 1.542290]\n",
      "epoch:14 step:13539 [D loss: 1.070548, acc.: 50.00%] [G loss: 1.713603]\n",
      "epoch:14 step:13540 [D loss: 1.042168, acc.: 48.44%] [G loss: 0.941668]\n",
      "epoch:14 step:13541 [D loss: 0.752362, acc.: 53.91%] [G loss: 1.177298]\n",
      "epoch:14 step:13542 [D loss: 0.406796, acc.: 84.38%] [G loss: 1.200199]\n",
      "epoch:14 step:13543 [D loss: 0.570851, acc.: 69.53%] [G loss: 0.912550]\n",
      "epoch:14 step:13544 [D loss: 0.902321, acc.: 39.06%] [G loss: 1.036090]\n",
      "epoch:14 step:13545 [D loss: 0.277305, acc.: 96.88%] [G loss: 0.587034]\n",
      "epoch:14 step:13546 [D loss: 0.606277, acc.: 64.06%] [G loss: 1.242242]\n",
      "epoch:14 step:13547 [D loss: 0.910321, acc.: 41.41%] [G loss: 0.930889]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:14 step:13548 [D loss: 0.634413, acc.: 62.50%] [G loss: 1.309850]\n",
      "epoch:14 step:13549 [D loss: 0.760635, acc.: 55.47%] [G loss: 1.540207]\n",
      "epoch:14 step:13550 [D loss: 0.736111, acc.: 52.34%] [G loss: 1.377661]\n",
      "epoch:14 step:13551 [D loss: 0.837522, acc.: 41.41%] [G loss: 1.148530]\n",
      "epoch:14 step:13552 [D loss: 0.789083, acc.: 43.75%] [G loss: 1.245160]\n",
      "epoch:14 step:13553 [D loss: 0.706913, acc.: 55.47%] [G loss: 1.503337]\n",
      "epoch:14 step:13554 [D loss: 0.530853, acc.: 71.88%] [G loss: 1.751165]\n",
      "epoch:14 step:13555 [D loss: 0.725396, acc.: 50.78%] [G loss: 1.876314]\n",
      "epoch:14 step:13556 [D loss: 0.788211, acc.: 58.59%] [G loss: 1.044405]\n",
      "epoch:14 step:13557 [D loss: 0.710686, acc.: 49.22%] [G loss: 1.189027]\n",
      "epoch:14 step:13558 [D loss: 0.552634, acc.: 70.31%] [G loss: 1.286668]\n",
      "epoch:14 step:13559 [D loss: 0.548513, acc.: 72.66%] [G loss: 1.591811]\n",
      "epoch:14 step:13560 [D loss: 0.602186, acc.: 71.88%] [G loss: 1.312316]\n",
      "epoch:14 step:13561 [D loss: 0.526950, acc.: 82.03%] [G loss: 0.884237]\n",
      "epoch:14 step:13562 [D loss: 0.766644, acc.: 49.22%] [G loss: 1.198189]\n",
      "epoch:14 step:13563 [D loss: 0.599712, acc.: 69.53%] [G loss: 1.002113]\n",
      "epoch:14 step:13564 [D loss: 0.603865, acc.: 67.19%] [G loss: 0.960670]\n",
      "epoch:14 step:13565 [D loss: 0.643948, acc.: 59.38%] [G loss: 0.936244]\n",
      "epoch:14 step:13566 [D loss: 0.492514, acc.: 80.47%] [G loss: 1.107931]\n",
      "epoch:14 step:13567 [D loss: 0.366744, acc.: 90.62%] [G loss: 1.123351]\n",
      "epoch:14 step:13568 [D loss: 0.527264, acc.: 78.12%] [G loss: 1.354971]\n",
      "epoch:14 step:13569 [D loss: 0.375103, acc.: 85.94%] [G loss: 1.371226]\n",
      "epoch:14 step:13570 [D loss: 0.253278, acc.: 99.22%] [G loss: 1.452128]\n",
      "epoch:14 step:13571 [D loss: 0.345599, acc.: 93.75%] [G loss: 1.050313]\n",
      "epoch:14 step:13572 [D loss: 0.461604, acc.: 83.59%] [G loss: 0.979628]\n",
      "epoch:14 step:13573 [D loss: 0.435942, acc.: 90.62%] [G loss: 1.384079]\n",
      "epoch:14 step:13574 [D loss: 0.353362, acc.: 92.97%] [G loss: 1.395902]\n",
      "epoch:14 step:13575 [D loss: 0.386257, acc.: 92.97%] [G loss: 1.018268]\n",
      "epoch:14 step:13576 [D loss: 0.911519, acc.: 39.06%] [G loss: 1.070051]\n",
      "epoch:14 step:13577 [D loss: 0.837267, acc.: 44.53%] [G loss: 1.644221]\n",
      "epoch:14 step:13578 [D loss: 0.655162, acc.: 59.38%] [G loss: 1.362361]\n",
      "epoch:14 step:13579 [D loss: 1.056108, acc.: 25.00%] [G loss: 1.120052]\n",
      "epoch:14 step:13580 [D loss: 0.945049, acc.: 42.97%] [G loss: 0.864121]\n",
      "epoch:14 step:13581 [D loss: 0.745037, acc.: 55.47%] [G loss: 0.874554]\n",
      "epoch:14 step:13582 [D loss: 0.628439, acc.: 67.97%] [G loss: 0.941658]\n",
      "epoch:14 step:13583 [D loss: 0.562223, acc.: 66.41%] [G loss: 0.891079]\n",
      "epoch:14 step:13584 [D loss: 0.604308, acc.: 64.06%] [G loss: 0.929450]\n",
      "epoch:14 step:13585 [D loss: 0.551192, acc.: 75.00%] [G loss: 1.001064]\n",
      "epoch:14 step:13586 [D loss: 0.445967, acc.: 84.38%] [G loss: 1.011743]\n",
      "epoch:14 step:13587 [D loss: 0.395941, acc.: 88.28%] [G loss: 1.282507]\n",
      "epoch:14 step:13588 [D loss: 0.447734, acc.: 80.47%] [G loss: 1.055929]\n",
      "epoch:14 step:13589 [D loss: 0.538016, acc.: 73.44%] [G loss: 1.021519]\n",
      "epoch:14 step:13590 [D loss: 0.738620, acc.: 52.34%] [G loss: 1.033411]\n",
      "epoch:14 step:13591 [D loss: 0.862927, acc.: 50.78%] [G loss: 1.248647]\n",
      "epoch:14 step:13592 [D loss: 0.723990, acc.: 60.94%] [G loss: 1.339238]\n",
      "epoch:14 step:13593 [D loss: 0.533711, acc.: 75.78%] [G loss: 1.429234]\n",
      "epoch:14 step:13594 [D loss: 0.667749, acc.: 64.84%] [G loss: 1.082021]\n",
      "epoch:14 step:13595 [D loss: 0.579808, acc.: 67.97%] [G loss: 1.310375]\n",
      "epoch:14 step:13596 [D loss: 0.645610, acc.: 64.84%] [G loss: 1.235401]\n",
      "epoch:14 step:13597 [D loss: 0.588823, acc.: 67.97%] [G loss: 1.035172]\n",
      "epoch:14 step:13598 [D loss: 0.573714, acc.: 71.88%] [G loss: 1.135428]\n",
      "epoch:14 step:13599 [D loss: 0.587441, acc.: 67.97%] [G loss: 1.139091]\n",
      "epoch:14 step:13600 [D loss: 0.564812, acc.: 69.53%] [G loss: 1.051433]\n",
      "##############\n",
      "[3.72254278 2.04708651 6.20930433 5.52464685 4.34805468 6.1903213\n",
      " 4.9056013  5.49592152 5.18330673 4.52914461]\n",
      "##########\n",
      "epoch:14 step:13601 [D loss: 0.537791, acc.: 74.22%] [G loss: 1.151600]\n",
      "epoch:14 step:13602 [D loss: 0.376780, acc.: 84.38%] [G loss: 1.390446]\n",
      "epoch:14 step:13603 [D loss: 0.568605, acc.: 71.88%] [G loss: 1.089376]\n",
      "epoch:14 step:13604 [D loss: 0.595178, acc.: 66.41%] [G loss: 1.202334]\n",
      "epoch:14 step:13605 [D loss: 0.441390, acc.: 84.38%] [G loss: 1.254516]\n",
      "epoch:14 step:13606 [D loss: 0.593264, acc.: 63.28%] [G loss: 1.198065]\n",
      "epoch:14 step:13607 [D loss: 0.823793, acc.: 49.22%] [G loss: 0.995503]\n",
      "epoch:14 step:13608 [D loss: 0.826041, acc.: 41.41%] [G loss: 0.869411]\n",
      "epoch:14 step:13609 [D loss: 0.624370, acc.: 63.28%] [G loss: 0.966552]\n",
      "epoch:14 step:13610 [D loss: 0.644175, acc.: 62.50%] [G loss: 0.892194]\n",
      "epoch:14 step:13611 [D loss: 0.650373, acc.: 66.41%] [G loss: 0.954789]\n",
      "epoch:14 step:13612 [D loss: 0.603649, acc.: 68.75%] [G loss: 0.918279]\n",
      "epoch:14 step:13613 [D loss: 0.582486, acc.: 71.09%] [G loss: 1.032425]\n",
      "epoch:14 step:13614 [D loss: 0.627840, acc.: 63.28%] [G loss: 0.997850]\n",
      "epoch:14 step:13615 [D loss: 0.479815, acc.: 82.03%] [G loss: 0.893291]\n",
      "epoch:14 step:13616 [D loss: 0.299196, acc.: 89.84%] [G loss: 1.145247]\n",
      "epoch:14 step:13617 [D loss: 0.306075, acc.: 87.50%] [G loss: 1.172160]\n",
      "epoch:14 step:13618 [D loss: 0.831450, acc.: 46.09%] [G loss: 1.120902]\n",
      "epoch:14 step:13619 [D loss: 0.714318, acc.: 57.03%] [G loss: 1.098535]\n",
      "epoch:14 step:13620 [D loss: 0.631393, acc.: 60.94%] [G loss: 1.129238]\n",
      "epoch:14 step:13621 [D loss: 0.672841, acc.: 57.81%] [G loss: 1.042005]\n",
      "epoch:14 step:13622 [D loss: 0.619714, acc.: 67.97%] [G loss: 0.998293]\n",
      "epoch:14 step:13623 [D loss: 0.554679, acc.: 71.09%] [G loss: 1.139295]\n",
      "epoch:14 step:13624 [D loss: 0.603570, acc.: 67.19%] [G loss: 1.214266]\n",
      "epoch:14 step:13625 [D loss: 0.528976, acc.: 73.44%] [G loss: 1.006326]\n",
      "epoch:14 step:13626 [D loss: 0.546043, acc.: 67.97%] [G loss: 1.037734]\n",
      "epoch:14 step:13627 [D loss: 0.658791, acc.: 56.25%] [G loss: 1.142700]\n",
      "epoch:14 step:13628 [D loss: 0.515970, acc.: 74.22%] [G loss: 1.146805]\n",
      "epoch:14 step:13629 [D loss: 0.393253, acc.: 83.59%] [G loss: 1.065569]\n",
      "epoch:14 step:13630 [D loss: 0.263699, acc.: 94.53%] [G loss: 1.418072]\n",
      "epoch:14 step:13631 [D loss: 0.310051, acc.: 87.50%] [G loss: 1.282124]\n",
      "epoch:14 step:13632 [D loss: 0.510436, acc.: 77.34%] [G loss: 1.282788]\n",
      "epoch:14 step:13633 [D loss: 0.549341, acc.: 72.66%] [G loss: 1.072234]\n",
      "epoch:14 step:13634 [D loss: 0.621241, acc.: 64.84%] [G loss: 1.331883]\n",
      "epoch:14 step:13635 [D loss: 0.596131, acc.: 67.97%] [G loss: 1.176441]\n",
      "epoch:14 step:13636 [D loss: 0.555387, acc.: 72.66%] [G loss: 1.187965]\n",
      "epoch:14 step:13637 [D loss: 0.563880, acc.: 70.31%] [G loss: 0.970228]\n",
      "epoch:14 step:13638 [D loss: 0.558853, acc.: 70.31%] [G loss: 0.838156]\n",
      "epoch:14 step:13639 [D loss: 0.693670, acc.: 57.81%] [G loss: 1.272534]\n",
      "epoch:14 step:13640 [D loss: 0.542524, acc.: 78.12%] [G loss: 1.185761]\n",
      "epoch:14 step:13641 [D loss: 0.515225, acc.: 78.91%] [G loss: 1.250233]\n",
      "epoch:14 step:13642 [D loss: 0.455164, acc.: 77.34%] [G loss: 1.002039]\n",
      "epoch:14 step:13643 [D loss: 0.646622, acc.: 64.84%] [G loss: 1.030069]\n",
      "epoch:14 step:13644 [D loss: 1.296551, acc.: 27.34%] [G loss: 1.287744]\n",
      "epoch:14 step:13645 [D loss: 0.506036, acc.: 73.44%] [G loss: 1.142204]\n",
      "epoch:14 step:13646 [D loss: 0.884587, acc.: 33.59%] [G loss: 1.189399]\n",
      "epoch:14 step:13647 [D loss: 0.787219, acc.: 46.88%] [G loss: 0.893587]\n",
      "epoch:14 step:13648 [D loss: 0.655305, acc.: 63.28%] [G loss: 1.214355]\n",
      "epoch:14 step:13649 [D loss: 0.586562, acc.: 70.31%] [G loss: 1.025421]\n",
      "epoch:14 step:13650 [D loss: 0.540055, acc.: 76.56%] [G loss: 1.090759]\n",
      "epoch:14 step:13651 [D loss: 0.503344, acc.: 76.56%] [G loss: 1.195745]\n",
      "epoch:14 step:13652 [D loss: 0.455983, acc.: 83.59%] [G loss: 1.372568]\n",
      "epoch:14 step:13653 [D loss: 0.705685, acc.: 53.12%] [G loss: 1.157423]\n",
      "epoch:14 step:13654 [D loss: 0.420086, acc.: 82.81%] [G loss: 1.233036]\n",
      "epoch:14 step:13655 [D loss: 0.477254, acc.: 77.34%] [G loss: 1.112396]\n",
      "epoch:14 step:13656 [D loss: 0.608795, acc.: 69.53%] [G loss: 1.023706]\n",
      "epoch:14 step:13657 [D loss: 1.026938, acc.: 37.50%] [G loss: 1.091046]\n",
      "epoch:14 step:13658 [D loss: 0.674807, acc.: 63.28%] [G loss: 1.247680]\n",
      "epoch:14 step:13659 [D loss: 0.761906, acc.: 51.56%] [G loss: 1.154174]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:14 step:13660 [D loss: 0.436249, acc.: 89.06%] [G loss: 1.366847]\n",
      "epoch:14 step:13661 [D loss: 0.448371, acc.: 86.72%] [G loss: 1.199356]\n",
      "epoch:14 step:13662 [D loss: 0.527889, acc.: 73.44%] [G loss: 1.102510]\n",
      "epoch:14 step:13663 [D loss: 0.453428, acc.: 87.50%] [G loss: 1.300691]\n",
      "epoch:14 step:13664 [D loss: 0.565828, acc.: 73.44%] [G loss: 0.874852]\n",
      "epoch:14 step:13665 [D loss: 0.554310, acc.: 67.97%] [G loss: 0.912208]\n",
      "epoch:14 step:13666 [D loss: 0.507657, acc.: 81.25%] [G loss: 1.102291]\n",
      "epoch:14 step:13667 [D loss: 0.331503, acc.: 92.19%] [G loss: 1.166311]\n",
      "epoch:14 step:13668 [D loss: 0.299050, acc.: 92.97%] [G loss: 0.885455]\n",
      "epoch:14 step:13669 [D loss: 0.788665, acc.: 54.69%] [G loss: 1.139761]\n",
      "epoch:14 step:13670 [D loss: 0.383926, acc.: 88.28%] [G loss: 1.293368]\n",
      "epoch:14 step:13671 [D loss: 0.654185, acc.: 63.28%] [G loss: 1.330918]\n",
      "epoch:14 step:13672 [D loss: 0.271755, acc.: 96.09%] [G loss: 1.826382]\n",
      "epoch:14 step:13673 [D loss: 0.490838, acc.: 78.91%] [G loss: 0.784677]\n",
      "epoch:14 step:13674 [D loss: 0.616077, acc.: 64.06%] [G loss: 1.275368]\n",
      "epoch:14 step:13675 [D loss: 0.460807, acc.: 78.91%] [G loss: 1.757082]\n",
      "epoch:14 step:13676 [D loss: 0.454636, acc.: 80.47%] [G loss: 1.169344]\n",
      "epoch:14 step:13677 [D loss: 0.635254, acc.: 63.28%] [G loss: 1.109986]\n",
      "epoch:14 step:13678 [D loss: 0.820692, acc.: 53.12%] [G loss: 1.050330]\n",
      "epoch:14 step:13679 [D loss: 0.298594, acc.: 94.53%] [G loss: 1.452012]\n",
      "epoch:14 step:13680 [D loss: 0.671854, acc.: 62.50%] [G loss: 1.304153]\n",
      "epoch:14 step:13681 [D loss: 0.682490, acc.: 57.81%] [G loss: 0.820140]\n",
      "epoch:14 step:13682 [D loss: 0.496693, acc.: 75.78%] [G loss: 1.008762]\n",
      "epoch:14 step:13683 [D loss: 0.645739, acc.: 60.16%] [G loss: 0.969724]\n",
      "epoch:14 step:13684 [D loss: 0.452599, acc.: 70.31%] [G loss: 1.297745]\n",
      "epoch:14 step:13685 [D loss: 0.257968, acc.: 92.97%] [G loss: 1.540139]\n",
      "epoch:14 step:13686 [D loss: 0.372401, acc.: 90.62%] [G loss: 1.773746]\n",
      "epoch:14 step:13687 [D loss: 0.786320, acc.: 50.00%] [G loss: 1.362680]\n",
      "epoch:14 step:13688 [D loss: 0.612632, acc.: 69.53%] [G loss: 1.429406]\n",
      "epoch:14 step:13689 [D loss: 0.673689, acc.: 60.94%] [G loss: 1.479409]\n",
      "epoch:14 step:13690 [D loss: 0.558011, acc.: 68.75%] [G loss: 1.255857]\n",
      "epoch:14 step:13691 [D loss: 0.504007, acc.: 77.34%] [G loss: 1.586414]\n",
      "epoch:14 step:13692 [D loss: 0.450727, acc.: 81.25%] [G loss: 1.180560]\n",
      "epoch:14 step:13693 [D loss: 0.456209, acc.: 80.47%] [G loss: 1.488097]\n",
      "epoch:14 step:13694 [D loss: 0.515231, acc.: 74.22%] [G loss: 1.938588]\n",
      "epoch:14 step:13695 [D loss: 0.358668, acc.: 83.59%] [G loss: 1.785274]\n",
      "epoch:14 step:13696 [D loss: 0.309765, acc.: 86.72%] [G loss: 1.103310]\n",
      "epoch:14 step:13697 [D loss: 0.451367, acc.: 78.91%] [G loss: 1.184210]\n",
      "epoch:14 step:13698 [D loss: 0.948437, acc.: 43.75%] [G loss: 1.156278]\n",
      "epoch:14 step:13699 [D loss: 0.671280, acc.: 56.25%] [G loss: 0.468871]\n",
      "epoch:14 step:13700 [D loss: 0.723699, acc.: 46.88%] [G loss: 1.032181]\n",
      "epoch:14 step:13701 [D loss: 0.845177, acc.: 34.38%] [G loss: 0.909745]\n",
      "epoch:14 step:13702 [D loss: 0.704617, acc.: 57.81%] [G loss: 1.080863]\n",
      "epoch:14 step:13703 [D loss: 0.712509, acc.: 57.03%] [G loss: 0.860237]\n",
      "epoch:14 step:13704 [D loss: 0.606934, acc.: 65.62%] [G loss: 0.788813]\n",
      "epoch:14 step:13705 [D loss: 0.370913, acc.: 75.78%] [G loss: 1.077135]\n",
      "epoch:14 step:13706 [D loss: 0.210958, acc.: 96.09%] [G loss: 0.737766]\n",
      "epoch:14 step:13707 [D loss: 0.303736, acc.: 82.81%] [G loss: 1.618204]\n",
      "epoch:14 step:13708 [D loss: 0.711136, acc.: 57.81%] [G loss: 1.470415]\n",
      "epoch:14 step:13709 [D loss: 0.791309, acc.: 55.47%] [G loss: 1.430965]\n",
      "epoch:14 step:13710 [D loss: 0.692401, acc.: 59.38%] [G loss: 1.310756]\n",
      "epoch:14 step:13711 [D loss: 0.628097, acc.: 63.28%] [G loss: 1.325347]\n",
      "epoch:14 step:13712 [D loss: 0.681592, acc.: 58.59%] [G loss: 1.299262]\n",
      "epoch:14 step:13713 [D loss: 0.415353, acc.: 79.69%] [G loss: 0.562640]\n",
      "epoch:14 step:13714 [D loss: 0.643382, acc.: 64.06%] [G loss: 0.999113]\n",
      "epoch:14 step:13715 [D loss: 0.687883, acc.: 55.47%] [G loss: 0.980313]\n",
      "epoch:14 step:13716 [D loss: 0.567290, acc.: 71.88%] [G loss: 1.232757]\n",
      "epoch:14 step:13717 [D loss: 0.686975, acc.: 61.72%] [G loss: 0.887353]\n",
      "epoch:14 step:13718 [D loss: 0.389444, acc.: 75.00%] [G loss: 1.036596]\n",
      "epoch:14 step:13719 [D loss: 0.510198, acc.: 76.56%] [G loss: 0.416228]\n",
      "epoch:14 step:13720 [D loss: 0.348834, acc.: 90.62%] [G loss: 1.111897]\n",
      "epoch:14 step:13721 [D loss: 0.631290, acc.: 60.94%] [G loss: 1.355558]\n",
      "epoch:14 step:13722 [D loss: 1.262100, acc.: 32.81%] [G loss: 1.725606]\n",
      "epoch:14 step:13723 [D loss: 0.573000, acc.: 71.09%] [G loss: 1.492712]\n",
      "epoch:14 step:13724 [D loss: 0.791953, acc.: 57.81%] [G loss: 1.381652]\n",
      "epoch:14 step:13725 [D loss: 0.771991, acc.: 56.25%] [G loss: 1.140566]\n",
      "epoch:14 step:13726 [D loss: 0.605964, acc.: 65.62%] [G loss: 1.200723]\n",
      "epoch:14 step:13727 [D loss: 0.491082, acc.: 81.25%] [G loss: 1.127820]\n",
      "epoch:14 step:13728 [D loss: 0.679671, acc.: 60.16%] [G loss: 1.100883]\n",
      "epoch:14 step:13729 [D loss: 0.543346, acc.: 74.22%] [G loss: 1.008193]\n",
      "epoch:14 step:13730 [D loss: 1.216535, acc.: 47.66%] [G loss: 0.868261]\n",
      "epoch:14 step:13731 [D loss: 0.535719, acc.: 78.12%] [G loss: 1.258355]\n",
      "epoch:14 step:13732 [D loss: 0.623031, acc.: 62.50%] [G loss: 1.281051]\n",
      "epoch:14 step:13733 [D loss: 0.566529, acc.: 69.53%] [G loss: 1.350997]\n",
      "epoch:14 step:13734 [D loss: 0.450462, acc.: 83.59%] [G loss: 0.887282]\n",
      "epoch:14 step:13735 [D loss: 0.421646, acc.: 85.16%] [G loss: 1.311122]\n",
      "epoch:14 step:13736 [D loss: 0.719830, acc.: 51.56%] [G loss: 1.332801]\n",
      "epoch:14 step:13737 [D loss: 0.505242, acc.: 75.00%] [G loss: 0.958535]\n",
      "epoch:14 step:13738 [D loss: 0.840589, acc.: 46.09%] [G loss: 0.958170]\n",
      "epoch:14 step:13739 [D loss: 0.627765, acc.: 67.19%] [G loss: 1.095766]\n",
      "epoch:14 step:13740 [D loss: 0.461322, acc.: 84.38%] [G loss: 0.988426]\n",
      "epoch:14 step:13741 [D loss: 0.726005, acc.: 58.59%] [G loss: 0.895878]\n",
      "epoch:14 step:13742 [D loss: 0.384056, acc.: 91.41%] [G loss: 1.097576]\n",
      "epoch:14 step:13743 [D loss: 0.847755, acc.: 40.62%] [G loss: 1.033028]\n",
      "epoch:14 step:13744 [D loss: 0.544935, acc.: 72.66%] [G loss: 1.252605]\n",
      "epoch:14 step:13745 [D loss: 0.674222, acc.: 55.47%] [G loss: 1.131892]\n",
      "epoch:14 step:13746 [D loss: 0.634879, acc.: 65.62%] [G loss: 1.201186]\n",
      "epoch:14 step:13747 [D loss: 0.546775, acc.: 71.88%] [G loss: 0.895335]\n",
      "epoch:14 step:13748 [D loss: 0.605154, acc.: 66.41%] [G loss: 0.903125]\n",
      "epoch:14 step:13749 [D loss: 0.783911, acc.: 44.53%] [G loss: 1.119002]\n",
      "epoch:14 step:13750 [D loss: 0.593102, acc.: 64.06%] [G loss: 1.044041]\n",
      "epoch:14 step:13751 [D loss: 0.447207, acc.: 83.59%] [G loss: 0.787537]\n",
      "epoch:14 step:13752 [D loss: 0.508218, acc.: 78.91%] [G loss: 1.253004]\n",
      "epoch:14 step:13753 [D loss: 0.568631, acc.: 75.00%] [G loss: 0.833830]\n",
      "epoch:14 step:13754 [D loss: 0.797085, acc.: 36.72%] [G loss: 1.160554]\n",
      "epoch:14 step:13755 [D loss: 0.884067, acc.: 39.84%] [G loss: 0.946589]\n",
      "epoch:14 step:13756 [D loss: 0.731391, acc.: 51.56%] [G loss: 0.669348]\n",
      "epoch:14 step:13757 [D loss: 0.940076, acc.: 46.88%] [G loss: 1.095423]\n",
      "epoch:14 step:13758 [D loss: 0.813287, acc.: 46.88%] [G loss: 1.137484]\n",
      "epoch:14 step:13759 [D loss: 0.406196, acc.: 88.28%] [G loss: 1.202064]\n",
      "epoch:14 step:13760 [D loss: 0.692064, acc.: 60.16%] [G loss: 1.130447]\n",
      "epoch:14 step:13761 [D loss: 0.764824, acc.: 47.66%] [G loss: 1.330301]\n",
      "epoch:14 step:13762 [D loss: 0.624218, acc.: 65.62%] [G loss: 1.010768]\n",
      "epoch:14 step:13763 [D loss: 0.694211, acc.: 52.34%] [G loss: 1.003073]\n",
      "epoch:14 step:13764 [D loss: 0.650226, acc.: 58.59%] [G loss: 0.927512]\n",
      "epoch:14 step:13765 [D loss: 0.702349, acc.: 51.56%] [G loss: 0.740317]\n",
      "epoch:14 step:13766 [D loss: 0.571366, acc.: 71.88%] [G loss: 0.843892]\n",
      "epoch:14 step:13767 [D loss: 0.667274, acc.: 54.69%] [G loss: 1.010537]\n",
      "epoch:14 step:13768 [D loss: 0.501102, acc.: 79.69%] [G loss: 0.953681]\n",
      "epoch:14 step:13769 [D loss: 0.597732, acc.: 64.84%] [G loss: 0.917016]\n",
      "epoch:14 step:13770 [D loss: 0.769199, acc.: 46.88%] [G loss: 1.052795]\n",
      "epoch:14 step:13771 [D loss: 0.716825, acc.: 50.00%] [G loss: 1.147079]\n",
      "epoch:14 step:13772 [D loss: 0.751809, acc.: 51.56%] [G loss: 0.920356]\n",
      "epoch:14 step:13773 [D loss: 0.633357, acc.: 64.06%] [G loss: 0.772225]\n",
      "epoch:14 step:13774 [D loss: 0.699752, acc.: 53.12%] [G loss: 0.973020]\n",
      "epoch:14 step:13775 [D loss: 0.721493, acc.: 52.34%] [G loss: 1.033344]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:14 step:13776 [D loss: 0.672947, acc.: 53.91%] [G loss: 0.839424]\n",
      "epoch:14 step:13777 [D loss: 0.544142, acc.: 79.69%] [G loss: 1.074174]\n",
      "epoch:14 step:13778 [D loss: 0.570850, acc.: 68.75%] [G loss: 0.951567]\n",
      "epoch:14 step:13779 [D loss: 0.585203, acc.: 73.44%] [G loss: 0.958170]\n",
      "epoch:14 step:13780 [D loss: 0.709306, acc.: 57.81%] [G loss: 0.936932]\n",
      "epoch:14 step:13781 [D loss: 0.377191, acc.: 89.06%] [G loss: 0.798331]\n",
      "epoch:14 step:13782 [D loss: 0.454166, acc.: 78.12%] [G loss: 1.108772]\n",
      "epoch:14 step:13783 [D loss: 0.370707, acc.: 88.28%] [G loss: 1.197860]\n",
      "epoch:14 step:13784 [D loss: 0.744371, acc.: 58.59%] [G loss: 1.119557]\n",
      "epoch:14 step:13785 [D loss: 0.639157, acc.: 63.28%] [G loss: 1.167955]\n",
      "epoch:14 step:13786 [D loss: 0.797565, acc.: 49.22%] [G loss: 1.061957]\n",
      "epoch:14 step:13787 [D loss: 0.629602, acc.: 61.72%] [G loss: 1.006481]\n",
      "epoch:14 step:13788 [D loss: 0.687811, acc.: 56.25%] [G loss: 0.957020]\n",
      "epoch:14 step:13789 [D loss: 0.645764, acc.: 67.97%] [G loss: 0.959557]\n",
      "epoch:14 step:13790 [D loss: 0.668584, acc.: 57.81%] [G loss: 0.912526]\n",
      "epoch:14 step:13791 [D loss: 0.632274, acc.: 64.06%] [G loss: 0.976588]\n",
      "epoch:14 step:13792 [D loss: 0.618258, acc.: 65.62%] [G loss: 1.001681]\n",
      "epoch:14 step:13793 [D loss: 0.732054, acc.: 53.12%] [G loss: 1.095937]\n",
      "epoch:14 step:13794 [D loss: 0.619310, acc.: 68.75%] [G loss: 1.041363]\n",
      "epoch:14 step:13795 [D loss: 0.673049, acc.: 51.56%] [G loss: 0.973230]\n",
      "epoch:14 step:13796 [D loss: 0.728415, acc.: 53.12%] [G loss: 0.927617]\n",
      "epoch:14 step:13797 [D loss: 0.632443, acc.: 65.62%] [G loss: 0.930982]\n",
      "epoch:14 step:13798 [D loss: 0.617350, acc.: 64.84%] [G loss: 1.026737]\n",
      "epoch:14 step:13799 [D loss: 0.658838, acc.: 60.94%] [G loss: 0.831967]\n",
      "epoch:14 step:13800 [D loss: 0.562857, acc.: 71.09%] [G loss: 1.044854]\n",
      "##############\n",
      "[3.86972236 2.31439739 6.39330317 5.42025163 4.50459684 5.88222665\n",
      " 5.49335834 5.43203629 5.99874774 5.27714648]\n",
      "##########\n",
      "epoch:14 step:13801 [D loss: 0.634340, acc.: 60.94%] [G loss: 0.892937]\n",
      "epoch:14 step:13802 [D loss: 0.527997, acc.: 74.22%] [G loss: 0.915984]\n",
      "epoch:14 step:13803 [D loss: 0.570371, acc.: 73.44%] [G loss: 1.024262]\n",
      "epoch:14 step:13804 [D loss: 0.627281, acc.: 62.50%] [G loss: 0.986296]\n",
      "epoch:14 step:13805 [D loss: 0.632125, acc.: 63.28%] [G loss: 0.798525]\n",
      "epoch:14 step:13806 [D loss: 0.772108, acc.: 47.66%] [G loss: 0.926065]\n",
      "epoch:14 step:13807 [D loss: 0.701421, acc.: 54.69%] [G loss: 1.069914]\n",
      "epoch:14 step:13808 [D loss: 0.700693, acc.: 58.59%] [G loss: 1.037933]\n",
      "epoch:14 step:13809 [D loss: 0.672250, acc.: 60.94%] [G loss: 1.005900]\n",
      "epoch:14 step:13810 [D loss: 0.666694, acc.: 56.25%] [G loss: 0.809714]\n",
      "epoch:14 step:13811 [D loss: 0.624189, acc.: 64.06%] [G loss: 1.023973]\n",
      "epoch:14 step:13812 [D loss: 0.587010, acc.: 71.09%] [G loss: 0.938602]\n",
      "epoch:14 step:13813 [D loss: 0.620814, acc.: 64.84%] [G loss: 1.031686]\n",
      "epoch:14 step:13814 [D loss: 0.330116, acc.: 92.19%] [G loss: 1.119681]\n",
      "epoch:14 step:13815 [D loss: 0.307554, acc.: 89.84%] [G loss: 1.025576]\n",
      "epoch:14 step:13816 [D loss: 0.402654, acc.: 87.50%] [G loss: 1.408116]\n",
      "epoch:14 step:13817 [D loss: 0.693219, acc.: 60.16%] [G loss: 1.284807]\n",
      "epoch:14 step:13818 [D loss: 0.276697, acc.: 92.19%] [G loss: 1.273887]\n",
      "epoch:14 step:13819 [D loss: 0.264366, acc.: 92.97%] [G loss: 1.428931]\n",
      "epoch:14 step:13820 [D loss: 0.323948, acc.: 92.19%] [G loss: 1.220189]\n",
      "epoch:14 step:13821 [D loss: 0.686310, acc.: 53.91%] [G loss: 1.054996]\n",
      "epoch:14 step:13822 [D loss: 0.453363, acc.: 88.28%] [G loss: 1.073519]\n",
      "epoch:14 step:13823 [D loss: 0.767388, acc.: 51.56%] [G loss: 1.025861]\n",
      "epoch:14 step:13824 [D loss: 0.257072, acc.: 90.62%] [G loss: 1.231094]\n",
      "epoch:14 step:13825 [D loss: 0.398325, acc.: 76.56%] [G loss: 1.420545]\n",
      "epoch:14 step:13826 [D loss: 0.171028, acc.: 98.44%] [G loss: 1.529575]\n",
      "epoch:14 step:13827 [D loss: 0.375687, acc.: 92.19%] [G loss: 1.706266]\n",
      "epoch:14 step:13828 [D loss: 0.914530, acc.: 50.78%] [G loss: 1.430853]\n",
      "epoch:14 step:13829 [D loss: 0.793408, acc.: 53.91%] [G loss: 0.775438]\n",
      "epoch:14 step:13830 [D loss: 0.655076, acc.: 60.16%] [G loss: 1.206281]\n",
      "epoch:14 step:13831 [D loss: 0.253390, acc.: 93.75%] [G loss: 1.415025]\n",
      "epoch:14 step:13832 [D loss: 0.224410, acc.: 94.53%] [G loss: 1.421767]\n",
      "epoch:14 step:13833 [D loss: 0.741107, acc.: 54.69%] [G loss: 1.202049]\n",
      "epoch:14 step:13834 [D loss: 0.879251, acc.: 43.75%] [G loss: 1.025970]\n",
      "epoch:14 step:13835 [D loss: 0.810364, acc.: 46.09%] [G loss: 0.412736]\n",
      "epoch:14 step:13836 [D loss: 0.645636, acc.: 61.72%] [G loss: 1.048798]\n",
      "epoch:14 step:13837 [D loss: 0.674592, acc.: 57.81%] [G loss: 0.936858]\n",
      "epoch:14 step:13838 [D loss: 0.634515, acc.: 64.84%] [G loss: 0.422646]\n",
      "epoch:14 step:13839 [D loss: 0.723331, acc.: 46.88%] [G loss: 1.095082]\n",
      "epoch:14 step:13840 [D loss: 0.661214, acc.: 64.84%] [G loss: 1.008193]\n",
      "epoch:14 step:13841 [D loss: 0.570382, acc.: 70.31%] [G loss: 1.019431]\n",
      "epoch:14 step:13842 [D loss: 0.711292, acc.: 47.66%] [G loss: 1.008986]\n",
      "epoch:14 step:13843 [D loss: 0.638324, acc.: 62.50%] [G loss: 1.125381]\n",
      "epoch:14 step:13844 [D loss: 0.669297, acc.: 55.47%] [G loss: 1.252962]\n",
      "epoch:14 step:13845 [D loss: 0.613351, acc.: 67.97%] [G loss: 1.177767]\n",
      "epoch:14 step:13846 [D loss: 0.255803, acc.: 93.75%] [G loss: 1.132502]\n",
      "epoch:14 step:13847 [D loss: 0.369185, acc.: 89.06%] [G loss: 1.238116]\n",
      "epoch:14 step:13848 [D loss: 0.267934, acc.: 92.97%] [G loss: 1.356062]\n",
      "epoch:14 step:13849 [D loss: 0.223946, acc.: 98.44%] [G loss: 1.374020]\n",
      "epoch:14 step:13850 [D loss: 0.360882, acc.: 83.59%] [G loss: 1.504966]\n",
      "epoch:14 step:13851 [D loss: 0.236370, acc.: 99.22%] [G loss: 1.026529]\n",
      "epoch:14 step:13852 [D loss: 1.124343, acc.: 21.88%] [G loss: 1.476017]\n",
      "epoch:14 step:13853 [D loss: 0.716307, acc.: 53.91%] [G loss: 0.878829]\n",
      "epoch:14 step:13854 [D loss: 0.897578, acc.: 41.41%] [G loss: 1.333488]\n",
      "epoch:14 step:13855 [D loss: 0.702504, acc.: 58.59%] [G loss: 1.405364]\n",
      "epoch:14 step:13856 [D loss: 0.790349, acc.: 47.66%] [G loss: 1.045194]\n",
      "epoch:14 step:13857 [D loss: 0.643626, acc.: 62.50%] [G loss: 1.059163]\n",
      "epoch:14 step:13858 [D loss: 0.622554, acc.: 68.75%] [G loss: 1.021469]\n",
      "epoch:14 step:13859 [D loss: 0.545196, acc.: 72.66%] [G loss: 1.114569]\n",
      "epoch:14 step:13860 [D loss: 0.499367, acc.: 80.47%] [G loss: 1.184079]\n",
      "epoch:14 step:13861 [D loss: 0.384275, acc.: 93.75%] [G loss: 0.822422]\n",
      "epoch:14 step:13862 [D loss: 0.924490, acc.: 42.19%] [G loss: 1.274999]\n",
      "epoch:14 step:13863 [D loss: 0.635125, acc.: 67.97%] [G loss: 1.255453]\n",
      "epoch:14 step:13864 [D loss: 0.584038, acc.: 62.50%] [G loss: 1.274725]\n",
      "epoch:14 step:13865 [D loss: 0.635621, acc.: 63.28%] [G loss: 0.883163]\n",
      "epoch:14 step:13866 [D loss: 0.484004, acc.: 81.25%] [G loss: 1.165056]\n",
      "epoch:14 step:13867 [D loss: 0.499879, acc.: 76.56%] [G loss: 1.338306]\n",
      "epoch:14 step:13868 [D loss: 0.359295, acc.: 90.62%] [G loss: 1.559556]\n",
      "epoch:14 step:13869 [D loss: 0.621719, acc.: 59.38%] [G loss: 1.128687]\n",
      "epoch:14 step:13870 [D loss: 0.932531, acc.: 48.44%] [G loss: 1.161992]\n",
      "epoch:14 step:13871 [D loss: 0.753153, acc.: 46.09%] [G loss: 1.034958]\n",
      "epoch:14 step:13872 [D loss: 0.673921, acc.: 57.81%] [G loss: 0.934417]\n",
      "epoch:14 step:13873 [D loss: 0.638758, acc.: 61.72%] [G loss: 0.958561]\n",
      "epoch:14 step:13874 [D loss: 0.496135, acc.: 76.56%] [G loss: 0.992014]\n",
      "epoch:14 step:13875 [D loss: 0.599062, acc.: 67.97%] [G loss: 0.953013]\n",
      "epoch:14 step:13876 [D loss: 0.715075, acc.: 51.56%] [G loss: 0.940828]\n",
      "epoch:14 step:13877 [D loss: 0.600850, acc.: 67.97%] [G loss: 1.001687]\n",
      "epoch:14 step:13878 [D loss: 0.542449, acc.: 75.78%] [G loss: 0.973626]\n",
      "epoch:14 step:13879 [D loss: 0.714548, acc.: 52.34%] [G loss: 0.983396]\n",
      "epoch:14 step:13880 [D loss: 0.814448, acc.: 50.00%] [G loss: 0.995459]\n",
      "epoch:14 step:13881 [D loss: 0.722270, acc.: 55.47%] [G loss: 0.970007]\n",
      "epoch:14 step:13882 [D loss: 0.560578, acc.: 70.31%] [G loss: 0.988366]\n",
      "epoch:14 step:13883 [D loss: 0.574095, acc.: 70.31%] [G loss: 0.862480]\n",
      "epoch:14 step:13884 [D loss: 0.572142, acc.: 71.88%] [G loss: 1.064400]\n",
      "epoch:14 step:13885 [D loss: 0.547590, acc.: 74.22%] [G loss: 1.072421]\n",
      "epoch:14 step:13886 [D loss: 0.389652, acc.: 89.84%] [G loss: 1.065631]\n",
      "epoch:14 step:13887 [D loss: 0.431297, acc.: 86.72%] [G loss: 1.008085]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:14 step:13888 [D loss: 0.560919, acc.: 71.88%] [G loss: 1.130867]\n",
      "epoch:14 step:13889 [D loss: 0.686152, acc.: 59.38%] [G loss: 1.100557]\n",
      "epoch:14 step:13890 [D loss: 0.681006, acc.: 56.25%] [G loss: 0.985402]\n",
      "epoch:14 step:13891 [D loss: 0.747841, acc.: 50.00%] [G loss: 0.988836]\n",
      "epoch:14 step:13892 [D loss: 0.415365, acc.: 81.25%] [G loss: 1.291615]\n",
      "epoch:14 step:13893 [D loss: 0.374731, acc.: 90.62%] [G loss: 0.910815]\n",
      "epoch:14 step:13894 [D loss: 0.806720, acc.: 45.31%] [G loss: 1.378720]\n",
      "epoch:14 step:13895 [D loss: 0.557144, acc.: 76.56%] [G loss: 1.135153]\n",
      "epoch:14 step:13896 [D loss: 0.688837, acc.: 62.50%] [G loss: 0.862881]\n",
      "epoch:14 step:13897 [D loss: 0.718244, acc.: 57.03%] [G loss: 1.087937]\n",
      "epoch:14 step:13898 [D loss: 0.538009, acc.: 74.22%] [G loss: 1.041207]\n",
      "epoch:14 step:13899 [D loss: 0.513556, acc.: 80.47%] [G loss: 0.995455]\n",
      "epoch:14 step:13900 [D loss: 0.412354, acc.: 78.91%] [G loss: 0.845183]\n",
      "epoch:14 step:13901 [D loss: 0.716365, acc.: 59.38%] [G loss: 1.013713]\n",
      "epoch:14 step:13902 [D loss: 0.703949, acc.: 57.03%] [G loss: 0.815677]\n",
      "epoch:14 step:13903 [D loss: 0.770095, acc.: 52.34%] [G loss: 1.026541]\n",
      "epoch:14 step:13904 [D loss: 0.328589, acc.: 92.97%] [G loss: 1.160286]\n",
      "epoch:14 step:13905 [D loss: 0.690519, acc.: 52.34%] [G loss: 1.126936]\n",
      "epoch:14 step:13906 [D loss: 0.773036, acc.: 53.91%] [G loss: 1.245722]\n",
      "epoch:14 step:13907 [D loss: 0.685298, acc.: 60.16%] [G loss: 1.119804]\n",
      "epoch:14 step:13908 [D loss: 0.833270, acc.: 33.59%] [G loss: 1.174777]\n",
      "epoch:14 step:13909 [D loss: 0.312548, acc.: 85.16%] [G loss: 1.194526]\n",
      "epoch:14 step:13910 [D loss: 0.427142, acc.: 86.72%] [G loss: 1.417799]\n",
      "epoch:14 step:13911 [D loss: 0.396523, acc.: 87.50%] [G loss: 1.253465]\n",
      "epoch:14 step:13912 [D loss: 0.330895, acc.: 89.06%] [G loss: 1.294476]\n",
      "epoch:14 step:13913 [D loss: 0.586079, acc.: 78.91%] [G loss: 1.366805]\n",
      "epoch:14 step:13914 [D loss: 0.335234, acc.: 91.41%] [G loss: 1.128248]\n",
      "epoch:14 step:13915 [D loss: 0.695146, acc.: 57.03%] [G loss: 0.986432]\n",
      "epoch:14 step:13916 [D loss: 0.734318, acc.: 50.78%] [G loss: 0.978451]\n",
      "epoch:14 step:13917 [D loss: 0.664081, acc.: 60.94%] [G loss: 0.978169]\n",
      "epoch:14 step:13918 [D loss: 0.705609, acc.: 57.03%] [G loss: 0.919378]\n",
      "epoch:14 step:13919 [D loss: 0.538828, acc.: 77.34%] [G loss: 1.233294]\n",
      "epoch:14 step:13920 [D loss: 0.530186, acc.: 68.75%] [G loss: 1.127677]\n",
      "epoch:14 step:13921 [D loss: 0.602024, acc.: 64.06%] [G loss: 1.074854]\n",
      "epoch:14 step:13922 [D loss: 0.290555, acc.: 90.62%] [G loss: 1.130489]\n",
      "epoch:14 step:13923 [D loss: 0.285821, acc.: 88.28%] [G loss: 1.232014]\n",
      "epoch:14 step:13924 [D loss: 0.233507, acc.: 91.41%] [G loss: 1.364133]\n",
      "epoch:14 step:13925 [D loss: 0.796234, acc.: 51.56%] [G loss: 1.215403]\n",
      "epoch:14 step:13926 [D loss: 0.538492, acc.: 71.88%] [G loss: 1.060238]\n",
      "epoch:14 step:13927 [D loss: 0.459854, acc.: 86.72%] [G loss: 1.420147]\n",
      "epoch:14 step:13928 [D loss: 0.450976, acc.: 83.59%] [G loss: 1.340516]\n",
      "epoch:14 step:13929 [D loss: 0.847196, acc.: 50.78%] [G loss: 0.963915]\n",
      "epoch:14 step:13930 [D loss: 0.788531, acc.: 47.66%] [G loss: 1.182132]\n",
      "epoch:14 step:13931 [D loss: 0.687758, acc.: 57.81%] [G loss: 0.997335]\n",
      "epoch:14 step:13932 [D loss: 0.649346, acc.: 62.50%] [G loss: 0.953813]\n",
      "epoch:14 step:13933 [D loss: 0.389564, acc.: 85.94%] [G loss: 0.958975]\n",
      "epoch:14 step:13934 [D loss: 0.535895, acc.: 75.78%] [G loss: 1.217427]\n",
      "epoch:14 step:13935 [D loss: 0.847855, acc.: 35.16%] [G loss: 1.040347]\n",
      "epoch:14 step:13936 [D loss: 0.855251, acc.: 40.62%] [G loss: 0.668335]\n",
      "epoch:14 step:13937 [D loss: 0.637592, acc.: 60.16%] [G loss: 0.856407]\n",
      "epoch:14 step:13938 [D loss: 0.834981, acc.: 41.41%] [G loss: 1.065795]\n",
      "epoch:14 step:13939 [D loss: 0.545923, acc.: 64.84%] [G loss: 0.850552]\n",
      "epoch:14 step:13940 [D loss: 0.662718, acc.: 60.94%] [G loss: 1.073130]\n",
      "epoch:14 step:13941 [D loss: 0.647463, acc.: 64.84%] [G loss: 1.019220]\n",
      "epoch:14 step:13942 [D loss: 0.685007, acc.: 60.94%] [G loss: 0.886764]\n",
      "epoch:14 step:13943 [D loss: 0.675698, acc.: 59.38%] [G loss: 0.934068]\n",
      "epoch:14 step:13944 [D loss: 0.627335, acc.: 65.62%] [G loss: 0.862034]\n",
      "epoch:14 step:13945 [D loss: 0.740892, acc.: 50.78%] [G loss: 0.946486]\n",
      "epoch:14 step:13946 [D loss: 0.623382, acc.: 65.62%] [G loss: 1.027941]\n",
      "epoch:14 step:13947 [D loss: 0.677928, acc.: 58.59%] [G loss: 1.005815]\n",
      "epoch:14 step:13948 [D loss: 0.694869, acc.: 55.47%] [G loss: 0.971679]\n",
      "epoch:14 step:13949 [D loss: 0.663539, acc.: 62.50%] [G loss: 1.079360]\n",
      "epoch:14 step:13950 [D loss: 0.981997, acc.: 37.50%] [G loss: 1.125984]\n",
      "epoch:14 step:13951 [D loss: 0.706968, acc.: 53.12%] [G loss: 1.024017]\n",
      "epoch:14 step:13952 [D loss: 0.601102, acc.: 69.53%] [G loss: 1.019320]\n",
      "epoch:14 step:13953 [D loss: 0.670801, acc.: 57.03%] [G loss: 0.908343]\n",
      "epoch:14 step:13954 [D loss: 0.679986, acc.: 55.47%] [G loss: 0.904721]\n",
      "epoch:14 step:13955 [D loss: 0.653715, acc.: 59.38%] [G loss: 0.964379]\n",
      "epoch:14 step:13956 [D loss: 0.731096, acc.: 50.00%] [G loss: 0.853004]\n",
      "epoch:14 step:13957 [D loss: 0.630964, acc.: 60.94%] [G loss: 1.051761]\n",
      "epoch:14 step:13958 [D loss: 0.656592, acc.: 57.03%] [G loss: 0.962408]\n",
      "epoch:14 step:13959 [D loss: 0.479226, acc.: 79.69%] [G loss: 0.844145]\n",
      "epoch:14 step:13960 [D loss: 0.547690, acc.: 76.56%] [G loss: 0.829606]\n",
      "epoch:14 step:13961 [D loss: 0.845396, acc.: 37.50%] [G loss: 0.926903]\n",
      "epoch:14 step:13962 [D loss: 0.743500, acc.: 53.12%] [G loss: 0.908754]\n",
      "epoch:14 step:13963 [D loss: 0.584123, acc.: 67.19%] [G loss: 0.541750]\n",
      "epoch:14 step:13964 [D loss: 0.659636, acc.: 59.38%] [G loss: 0.940786]\n",
      "epoch:14 step:13965 [D loss: 0.456762, acc.: 79.69%] [G loss: 0.984143]\n",
      "epoch:14 step:13966 [D loss: 0.374944, acc.: 92.19%] [G loss: 1.029071]\n",
      "epoch:14 step:13967 [D loss: 0.514488, acc.: 82.81%] [G loss: 0.741917]\n",
      "epoch:14 step:13968 [D loss: 0.345720, acc.: 77.34%] [G loss: 0.876423]\n",
      "epoch:14 step:13969 [D loss: 0.222389, acc.: 96.88%] [G loss: 1.033041]\n",
      "epoch:14 step:13970 [D loss: 0.273645, acc.: 96.09%] [G loss: 1.375705]\n",
      "epoch:14 step:13971 [D loss: 0.287826, acc.: 97.66%] [G loss: 1.305099]\n",
      "epoch:14 step:13972 [D loss: 0.197603, acc.: 98.44%] [G loss: 1.703858]\n",
      "epoch:14 step:13973 [D loss: 0.466698, acc.: 82.03%] [G loss: 1.526530]\n",
      "epoch:14 step:13974 [D loss: 0.842484, acc.: 37.50%] [G loss: 1.292653]\n",
      "epoch:14 step:13975 [D loss: 0.326179, acc.: 87.50%] [G loss: 1.315932]\n",
      "epoch:14 step:13976 [D loss: 0.746510, acc.: 57.03%] [G loss: 0.819422]\n",
      "epoch:14 step:13977 [D loss: 0.890440, acc.: 41.41%] [G loss: 1.350291]\n",
      "epoch:14 step:13978 [D loss: 0.941933, acc.: 40.62%] [G loss: 1.463535]\n",
      "epoch:14 step:13979 [D loss: 0.646835, acc.: 60.16%] [G loss: 1.344965]\n",
      "epoch:14 step:13980 [D loss: 0.761340, acc.: 51.56%] [G loss: 1.256548]\n",
      "epoch:14 step:13981 [D loss: 0.745343, acc.: 48.44%] [G loss: 0.984557]\n",
      "epoch:14 step:13982 [D loss: 0.718644, acc.: 53.12%] [G loss: 0.856313]\n",
      "epoch:14 step:13983 [D loss: 0.620391, acc.: 62.50%] [G loss: 1.162473]\n",
      "epoch:14 step:13984 [D loss: 1.395670, acc.: 19.53%] [G loss: 1.030150]\n",
      "epoch:14 step:13985 [D loss: 0.641554, acc.: 65.62%] [G loss: 1.244019]\n",
      "epoch:14 step:13986 [D loss: 0.657594, acc.: 56.25%] [G loss: 1.030823]\n",
      "epoch:14 step:13987 [D loss: 0.701059, acc.: 50.78%] [G loss: 1.050396]\n",
      "epoch:14 step:13988 [D loss: 0.598296, acc.: 65.62%] [G loss: 1.046979]\n",
      "epoch:14 step:13989 [D loss: 0.690698, acc.: 53.91%] [G loss: 1.091798]\n",
      "epoch:14 step:13990 [D loss: 0.659019, acc.: 60.16%] [G loss: 1.036485]\n",
      "epoch:14 step:13991 [D loss: 0.601771, acc.: 65.62%] [G loss: 1.103725]\n",
      "epoch:14 step:13992 [D loss: 0.690463, acc.: 52.34%] [G loss: 0.989186]\n",
      "epoch:14 step:13993 [D loss: 0.658738, acc.: 59.38%] [G loss: 0.902083]\n",
      "epoch:14 step:13994 [D loss: 0.562467, acc.: 76.56%] [G loss: 0.879709]\n",
      "epoch:14 step:13995 [D loss: 0.445535, acc.: 89.06%] [G loss: 1.049796]\n",
      "epoch:14 step:13996 [D loss: 0.470589, acc.: 76.56%] [G loss: 1.235791]\n",
      "epoch:14 step:13997 [D loss: 0.621726, acc.: 63.28%] [G loss: 1.231831]\n",
      "epoch:14 step:13998 [D loss: 0.784899, acc.: 48.44%] [G loss: 0.976545]\n",
      "epoch:14 step:13999 [D loss: 0.601384, acc.: 67.19%] [G loss: 1.211808]\n",
      "epoch:14 step:14000 [D loss: 0.781075, acc.: 58.59%] [G loss: 0.919746]\n",
      "##############\n",
      "[4.17512872 2.74092662 6.59955229 6.03887114 5.0710832  6.49339011\n",
      " 5.23971287 5.23281771 5.79675378 5.08109239]\n",
      "##########\n",
      "epoch:14 step:14001 [D loss: 0.751197, acc.: 47.66%] [G loss: 0.909570]\n",
      "epoch:14 step:14002 [D loss: 0.603396, acc.: 64.06%] [G loss: 0.991046]\n",
      "epoch:14 step:14003 [D loss: 0.439926, acc.: 77.34%] [G loss: 0.995396]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:14 step:14004 [D loss: 0.449269, acc.: 82.81%] [G loss: 1.195987]\n",
      "epoch:14 step:14005 [D loss: 0.444580, acc.: 85.16%] [G loss: 1.171214]\n",
      "epoch:14 step:14006 [D loss: 0.796236, acc.: 42.97%] [G loss: 0.922371]\n",
      "epoch:14 step:14007 [D loss: 0.492750, acc.: 79.69%] [G loss: 0.986901]\n",
      "epoch:14 step:14008 [D loss: 0.417371, acc.: 79.69%] [G loss: 1.044317]\n",
      "epoch:14 step:14009 [D loss: 0.635722, acc.: 61.72%] [G loss: 0.947660]\n",
      "epoch:14 step:14010 [D loss: 0.582733, acc.: 65.62%] [G loss: 0.851497]\n",
      "epoch:14 step:14011 [D loss: 0.609706, acc.: 62.50%] [G loss: 0.670451]\n",
      "epoch:14 step:14012 [D loss: 0.480455, acc.: 82.03%] [G loss: 0.966318]\n",
      "epoch:14 step:14013 [D loss: 0.519882, acc.: 78.12%] [G loss: 0.979611]\n",
      "epoch:14 step:14014 [D loss: 0.475401, acc.: 80.47%] [G loss: 0.868105]\n",
      "epoch:14 step:14015 [D loss: 0.519757, acc.: 74.22%] [G loss: 1.053771]\n",
      "epoch:14 step:14016 [D loss: 0.407112, acc.: 82.81%] [G loss: 1.110037]\n",
      "epoch:14 step:14017 [D loss: 0.335667, acc.: 89.84%] [G loss: 0.984285]\n",
      "epoch:14 step:14018 [D loss: 0.316676, acc.: 96.09%] [G loss: 1.181855]\n",
      "epoch:14 step:14019 [D loss: 0.400996, acc.: 91.41%] [G loss: 1.277997]\n",
      "epoch:14 step:14020 [D loss: 0.627914, acc.: 67.19%] [G loss: 0.581212]\n",
      "epoch:14 step:14021 [D loss: 0.627408, acc.: 60.94%] [G loss: 0.808954]\n",
      "epoch:14 step:14022 [D loss: 0.476660, acc.: 77.34%] [G loss: 1.531372]\n",
      "epoch:14 step:14023 [D loss: 0.688763, acc.: 64.84%] [G loss: 1.023015]\n",
      "epoch:14 step:14024 [D loss: 0.413746, acc.: 89.06%] [G loss: 1.341014]\n",
      "epoch:14 step:14025 [D loss: 0.822957, acc.: 54.69%] [G loss: 1.042094]\n",
      "epoch:14 step:14026 [D loss: 0.853079, acc.: 36.72%] [G loss: 0.856210]\n",
      "epoch:14 step:14027 [D loss: 0.606429, acc.: 66.41%] [G loss: 1.049421]\n",
      "epoch:14 step:14028 [D loss: 0.663267, acc.: 57.03%] [G loss: 1.057333]\n",
      "epoch:14 step:14029 [D loss: 0.611107, acc.: 65.62%] [G loss: 0.673605]\n",
      "epoch:14 step:14030 [D loss: 0.403531, acc.: 72.66%] [G loss: 0.870775]\n",
      "epoch:14 step:14031 [D loss: 0.768223, acc.: 52.34%] [G loss: 1.572442]\n",
      "epoch:14 step:14032 [D loss: 0.739818, acc.: 54.69%] [G loss: 1.261594]\n",
      "epoch:14 step:14033 [D loss: 0.747358, acc.: 50.78%] [G loss: 1.031219]\n",
      "epoch:14 step:14034 [D loss: 0.607895, acc.: 63.28%] [G loss: 1.055725]\n",
      "epoch:14 step:14035 [D loss: 0.459094, acc.: 81.25%] [G loss: 1.052893]\n",
      "epoch:14 step:14036 [D loss: 0.710489, acc.: 57.81%] [G loss: 1.002735]\n",
      "epoch:14 step:14037 [D loss: 0.648301, acc.: 67.19%] [G loss: 0.934969]\n",
      "epoch:14 step:14038 [D loss: 0.407264, acc.: 82.03%] [G loss: 0.969190]\n",
      "epoch:14 step:14039 [D loss: 0.317222, acc.: 92.97%] [G loss: 0.954429]\n",
      "epoch:14 step:14040 [D loss: 0.602608, acc.: 67.19%] [G loss: 1.309236]\n",
      "epoch:14 step:14041 [D loss: 0.685828, acc.: 53.12%] [G loss: 0.948028]\n",
      "epoch:14 step:14042 [D loss: 0.498315, acc.: 82.03%] [G loss: 0.857728]\n",
      "epoch:14 step:14043 [D loss: 0.471846, acc.: 83.59%] [G loss: 0.939611]\n",
      "epoch:14 step:14044 [D loss: 0.576697, acc.: 70.31%] [G loss: 1.103336]\n",
      "epoch:14 step:14045 [D loss: 0.602025, acc.: 64.84%] [G loss: 0.881254]\n",
      "epoch:14 step:14046 [D loss: 0.613753, acc.: 64.06%] [G loss: 1.003097]\n",
      "epoch:14 step:14047 [D loss: 0.230418, acc.: 91.41%] [G loss: 1.318833]\n",
      "epoch:14 step:14048 [D loss: 0.549875, acc.: 73.44%] [G loss: 1.258844]\n",
      "epoch:14 step:14049 [D loss: 0.761584, acc.: 53.12%] [G loss: 1.286877]\n",
      "epoch:14 step:14050 [D loss: 0.642300, acc.: 64.06%] [G loss: 1.079307]\n",
      "epoch:14 step:14051 [D loss: 0.547037, acc.: 72.66%] [G loss: 1.169404]\n",
      "epoch:14 step:14052 [D loss: 0.421218, acc.: 84.38%] [G loss: 1.146191]\n",
      "epoch:14 step:14053 [D loss: 0.501619, acc.: 83.59%] [G loss: 1.079625]\n",
      "epoch:14 step:14054 [D loss: 0.377337, acc.: 86.72%] [G loss: 1.172402]\n",
      "epoch:14 step:14055 [D loss: 0.353397, acc.: 82.03%] [G loss: 1.471034]\n",
      "epoch:15 step:14056 [D loss: 0.817738, acc.: 50.78%] [G loss: 1.436288]\n",
      "epoch:15 step:14057 [D loss: 0.788545, acc.: 52.34%] [G loss: 1.048472]\n",
      "epoch:15 step:14058 [D loss: 0.740802, acc.: 52.34%] [G loss: 1.050085]\n",
      "epoch:15 step:14059 [D loss: 0.797857, acc.: 43.75%] [G loss: 1.007212]\n",
      "epoch:15 step:14060 [D loss: 0.748244, acc.: 53.91%] [G loss: 1.050928]\n",
      "epoch:15 step:14061 [D loss: 0.732084, acc.: 49.22%] [G loss: 0.805536]\n",
      "epoch:15 step:14062 [D loss: 0.554933, acc.: 71.88%] [G loss: 0.972905]\n",
      "epoch:15 step:14063 [D loss: 0.781290, acc.: 50.00%] [G loss: 0.857770]\n",
      "epoch:15 step:14064 [D loss: 0.608350, acc.: 67.97%] [G loss: 1.261216]\n",
      "epoch:15 step:14065 [D loss: 0.590884, acc.: 69.53%] [G loss: 1.030866]\n",
      "epoch:15 step:14066 [D loss: 0.614362, acc.: 65.62%] [G loss: 1.125650]\n",
      "epoch:15 step:14067 [D loss: 0.530743, acc.: 78.12%] [G loss: 1.161908]\n",
      "epoch:15 step:14068 [D loss: 0.503039, acc.: 79.69%] [G loss: 0.802348]\n",
      "epoch:15 step:14069 [D loss: 0.634634, acc.: 61.72%] [G loss: 1.099128]\n",
      "epoch:15 step:14070 [D loss: 0.644806, acc.: 61.72%] [G loss: 1.007554]\n",
      "epoch:15 step:14071 [D loss: 0.662269, acc.: 64.06%] [G loss: 1.270128]\n",
      "epoch:15 step:14072 [D loss: 0.747012, acc.: 52.34%] [G loss: 0.916594]\n",
      "epoch:15 step:14073 [D loss: 0.660679, acc.: 64.06%] [G loss: 0.873258]\n",
      "epoch:15 step:14074 [D loss: 0.935453, acc.: 30.47%] [G loss: 0.684300]\n",
      "epoch:15 step:14075 [D loss: 1.012089, acc.: 23.44%] [G loss: 0.857275]\n",
      "epoch:15 step:14076 [D loss: 0.736876, acc.: 55.47%] [G loss: 1.395315]\n",
      "epoch:15 step:14077 [D loss: 0.685901, acc.: 60.16%] [G loss: 1.134992]\n",
      "epoch:15 step:14078 [D loss: 0.785235, acc.: 50.78%] [G loss: 0.864780]\n",
      "epoch:15 step:14079 [D loss: 0.785627, acc.: 42.97%] [G loss: 0.853421]\n",
      "epoch:15 step:14080 [D loss: 0.587529, acc.: 69.53%] [G loss: 1.115289]\n",
      "epoch:15 step:14081 [D loss: 0.794598, acc.: 43.75%] [G loss: 1.072243]\n",
      "epoch:15 step:14082 [D loss: 0.471974, acc.: 82.81%] [G loss: 1.097777]\n",
      "epoch:15 step:14083 [D loss: 0.527314, acc.: 75.78%] [G loss: 1.357649]\n",
      "epoch:15 step:14084 [D loss: 0.593628, acc.: 72.66%] [G loss: 1.446720]\n",
      "epoch:15 step:14085 [D loss: 0.576593, acc.: 67.97%] [G loss: 1.213974]\n",
      "epoch:15 step:14086 [D loss: 0.330700, acc.: 90.62%] [G loss: 1.529463]\n",
      "epoch:15 step:14087 [D loss: 0.390442, acc.: 84.38%] [G loss: 1.425359]\n",
      "epoch:15 step:14088 [D loss: 0.331209, acc.: 88.28%] [G loss: 1.602278]\n",
      "epoch:15 step:14089 [D loss: 0.307262, acc.: 91.41%] [G loss: 1.740924]\n",
      "epoch:15 step:14090 [D loss: 0.187486, acc.: 92.97%] [G loss: 1.682694]\n",
      "epoch:15 step:14091 [D loss: 0.159710, acc.: 96.88%] [G loss: 1.631207]\n",
      "epoch:15 step:14092 [D loss: 0.797849, acc.: 48.44%] [G loss: 1.789614]\n",
      "epoch:15 step:14093 [D loss: 0.969060, acc.: 42.19%] [G loss: 0.963763]\n",
      "epoch:15 step:14094 [D loss: 0.878088, acc.: 48.44%] [G loss: 1.123901]\n",
      "epoch:15 step:14095 [D loss: 0.674945, acc.: 55.47%] [G loss: 0.850008]\n",
      "epoch:15 step:14096 [D loss: 0.678421, acc.: 57.81%] [G loss: 0.648775]\n",
      "epoch:15 step:14097 [D loss: 0.578067, acc.: 73.44%] [G loss: 1.055979]\n",
      "epoch:15 step:14098 [D loss: 0.444043, acc.: 84.38%] [G loss: 1.102107]\n",
      "epoch:15 step:14099 [D loss: 0.537279, acc.: 77.34%] [G loss: 1.131573]\n",
      "epoch:15 step:14100 [D loss: 0.596355, acc.: 68.75%] [G loss: 0.772772]\n",
      "epoch:15 step:14101 [D loss: 0.395852, acc.: 85.94%] [G loss: 0.703920]\n",
      "epoch:15 step:14102 [D loss: 0.568011, acc.: 71.09%] [G loss: 1.120272]\n",
      "epoch:15 step:14103 [D loss: 0.680206, acc.: 57.03%] [G loss: 0.945006]\n",
      "epoch:15 step:14104 [D loss: 0.615312, acc.: 66.41%] [G loss: 0.283446]\n",
      "epoch:15 step:14105 [D loss: 0.552837, acc.: 68.75%] [G loss: 0.806956]\n",
      "epoch:15 step:14106 [D loss: 0.573587, acc.: 64.06%] [G loss: 0.152173]\n",
      "epoch:15 step:14107 [D loss: 0.355165, acc.: 89.06%] [G loss: 0.601741]\n",
      "epoch:15 step:14108 [D loss: 0.714698, acc.: 58.59%] [G loss: 0.601833]\n",
      "epoch:15 step:14109 [D loss: 0.731016, acc.: 55.47%] [G loss: 1.488512]\n",
      "epoch:15 step:14110 [D loss: 1.016358, acc.: 27.34%] [G loss: 0.397994]\n",
      "epoch:15 step:14111 [D loss: 0.787175, acc.: 39.84%] [G loss: 1.038555]\n",
      "epoch:15 step:14112 [D loss: 0.406321, acc.: 85.94%] [G loss: 0.602268]\n",
      "epoch:15 step:14113 [D loss: 0.805329, acc.: 56.25%] [G loss: 1.683552]\n",
      "epoch:15 step:14114 [D loss: 0.875531, acc.: 34.38%] [G loss: 1.155583]\n",
      "epoch:15 step:14115 [D loss: 0.695079, acc.: 57.03%] [G loss: 1.742721]\n",
      "epoch:15 step:14116 [D loss: 0.888043, acc.: 46.88%] [G loss: 1.209136]\n",
      "epoch:15 step:14117 [D loss: 0.953598, acc.: 39.06%] [G loss: 0.912718]\n",
      "epoch:15 step:14118 [D loss: 0.909774, acc.: 39.84%] [G loss: 2.134091]\n",
      "epoch:15 step:14119 [D loss: 0.657042, acc.: 55.47%] [G loss: 2.242546]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:15 step:14120 [D loss: 0.636512, acc.: 61.72%] [G loss: 1.575639]\n",
      "epoch:15 step:14121 [D loss: 0.645312, acc.: 59.38%] [G loss: 1.341088]\n",
      "epoch:15 step:14122 [D loss: 0.609164, acc.: 64.84%] [G loss: 1.352701]\n",
      "epoch:15 step:14123 [D loss: 0.563575, acc.: 73.44%] [G loss: 1.387517]\n",
      "epoch:15 step:14124 [D loss: 0.463126, acc.: 82.81%] [G loss: 1.374168]\n",
      "epoch:15 step:14125 [D loss: 0.509991, acc.: 73.44%] [G loss: 1.442276]\n",
      "epoch:15 step:14126 [D loss: 1.162708, acc.: 56.25%] [G loss: 1.006537]\n",
      "epoch:15 step:14127 [D loss: 0.666997, acc.: 62.50%] [G loss: 0.991420]\n",
      "epoch:15 step:14128 [D loss: 0.668576, acc.: 57.03%] [G loss: 0.893226]\n",
      "epoch:15 step:14129 [D loss: 0.681165, acc.: 57.81%] [G loss: 0.927272]\n",
      "epoch:15 step:14130 [D loss: 0.668373, acc.: 57.03%] [G loss: 0.982147]\n",
      "epoch:15 step:14131 [D loss: 0.401188, acc.: 84.38%] [G loss: 1.038618]\n",
      "epoch:15 step:14132 [D loss: 0.358366, acc.: 89.84%] [G loss: 1.039987]\n",
      "epoch:15 step:14133 [D loss: 0.655782, acc.: 63.28%] [G loss: 1.160002]\n",
      "epoch:15 step:14134 [D loss: 0.621331, acc.: 67.19%] [G loss: 0.945719]\n",
      "epoch:15 step:14135 [D loss: 0.580132, acc.: 68.75%] [G loss: 1.076520]\n",
      "epoch:15 step:14136 [D loss: 0.640249, acc.: 60.94%] [G loss: 1.015489]\n",
      "epoch:15 step:14137 [D loss: 0.468207, acc.: 83.59%] [G loss: 1.182454]\n",
      "epoch:15 step:14138 [D loss: 0.452567, acc.: 85.16%] [G loss: 0.953712]\n",
      "epoch:15 step:14139 [D loss: 0.667093, acc.: 65.62%] [G loss: 0.943487]\n",
      "epoch:15 step:14140 [D loss: 0.552220, acc.: 75.00%] [G loss: 1.357915]\n",
      "epoch:15 step:14141 [D loss: 0.590344, acc.: 69.53%] [G loss: 1.142872]\n",
      "epoch:15 step:14142 [D loss: 0.558296, acc.: 75.78%] [G loss: 1.048004]\n",
      "epoch:15 step:14143 [D loss: 0.468845, acc.: 83.59%] [G loss: 1.076909]\n",
      "epoch:15 step:14144 [D loss: 0.512013, acc.: 73.44%] [G loss: 1.211073]\n",
      "epoch:15 step:14145 [D loss: 0.541992, acc.: 75.00%] [G loss: 1.120613]\n",
      "epoch:15 step:14146 [D loss: 0.561437, acc.: 75.78%] [G loss: 1.177591]\n",
      "epoch:15 step:14147 [D loss: 0.410025, acc.: 89.84%] [G loss: 1.348349]\n",
      "epoch:15 step:14148 [D loss: 0.429712, acc.: 83.59%] [G loss: 0.981736]\n",
      "epoch:15 step:14149 [D loss: 0.514620, acc.: 72.66%] [G loss: 0.614331]\n",
      "epoch:15 step:14150 [D loss: 0.789154, acc.: 52.34%] [G loss: 1.079145]\n",
      "epoch:15 step:14151 [D loss: 0.762618, acc.: 51.56%] [G loss: 0.956673]\n",
      "epoch:15 step:14152 [D loss: 0.594281, acc.: 69.53%] [G loss: 0.990319]\n",
      "epoch:15 step:14153 [D loss: 0.781385, acc.: 50.00%] [G loss: 1.067171]\n",
      "epoch:15 step:14154 [D loss: 0.658980, acc.: 58.59%] [G loss: 0.622602]\n",
      "epoch:15 step:14155 [D loss: 0.801697, acc.: 46.88%] [G loss: 0.623801]\n",
      "epoch:15 step:14156 [D loss: 0.627201, acc.: 67.19%] [G loss: 0.629933]\n",
      "epoch:15 step:14157 [D loss: 0.831384, acc.: 44.53%] [G loss: 0.982933]\n",
      "epoch:15 step:14158 [D loss: 0.651492, acc.: 60.16%] [G loss: 0.944738]\n",
      "epoch:15 step:14159 [D loss: 0.721320, acc.: 60.16%] [G loss: 0.950602]\n",
      "epoch:15 step:14160 [D loss: 0.702590, acc.: 56.25%] [G loss: 1.014791]\n",
      "epoch:15 step:14161 [D loss: 0.777448, acc.: 46.09%] [G loss: 0.942148]\n",
      "epoch:15 step:14162 [D loss: 0.678001, acc.: 61.72%] [G loss: 0.944719]\n",
      "epoch:15 step:14163 [D loss: 0.645041, acc.: 59.38%] [G loss: 0.881433]\n",
      "epoch:15 step:14164 [D loss: 0.688436, acc.: 59.38%] [G loss: 1.049794]\n",
      "epoch:15 step:14165 [D loss: 0.706528, acc.: 53.91%] [G loss: 0.938573]\n",
      "epoch:15 step:14166 [D loss: 0.580976, acc.: 71.88%] [G loss: 0.966137]\n",
      "epoch:15 step:14167 [D loss: 0.666477, acc.: 60.16%] [G loss: 0.891854]\n",
      "epoch:15 step:14168 [D loss: 0.531866, acc.: 79.69%] [G loss: 1.000148]\n",
      "epoch:15 step:14169 [D loss: 0.564481, acc.: 73.44%] [G loss: 0.713393]\n",
      "epoch:15 step:14170 [D loss: 0.605304, acc.: 67.97%] [G loss: 1.018601]\n",
      "epoch:15 step:14171 [D loss: 0.722911, acc.: 50.00%] [G loss: 0.874680]\n",
      "epoch:15 step:14172 [D loss: 0.686185, acc.: 58.59%] [G loss: 1.071939]\n",
      "epoch:15 step:14173 [D loss: 0.578102, acc.: 68.75%] [G loss: 1.104263]\n",
      "epoch:15 step:14174 [D loss: 0.383789, acc.: 78.91%] [G loss: 0.952934]\n",
      "epoch:15 step:14175 [D loss: 0.748064, acc.: 57.81%] [G loss: 1.048188]\n",
      "epoch:15 step:14176 [D loss: 0.677548, acc.: 63.28%] [G loss: 0.969070]\n",
      "epoch:15 step:14177 [D loss: 0.588184, acc.: 72.66%] [G loss: 0.982543]\n",
      "epoch:15 step:14178 [D loss: 0.733079, acc.: 48.44%] [G loss: 0.909240]\n",
      "epoch:15 step:14179 [D loss: 0.573140, acc.: 74.22%] [G loss: 0.943231]\n",
      "epoch:15 step:14180 [D loss: 0.641045, acc.: 61.72%] [G loss: 1.049999]\n",
      "epoch:15 step:14181 [D loss: 0.612036, acc.: 67.19%] [G loss: 1.028654]\n",
      "epoch:15 step:14182 [D loss: 0.716852, acc.: 53.91%] [G loss: 0.978507]\n",
      "epoch:15 step:14183 [D loss: 0.716876, acc.: 53.91%] [G loss: 1.158834]\n",
      "epoch:15 step:14184 [D loss: 0.617211, acc.: 64.84%] [G loss: 0.914410]\n",
      "epoch:15 step:14185 [D loss: 0.570014, acc.: 73.44%] [G loss: 0.980443]\n",
      "epoch:15 step:14186 [D loss: 0.624546, acc.: 65.62%] [G loss: 0.855861]\n",
      "epoch:15 step:14187 [D loss: 0.703164, acc.: 58.59%] [G loss: 0.972626]\n",
      "epoch:15 step:14188 [D loss: 0.493744, acc.: 80.47%] [G loss: 0.950549]\n",
      "epoch:15 step:14189 [D loss: 0.405838, acc.: 82.81%] [G loss: 1.091744]\n",
      "epoch:15 step:14190 [D loss: 0.512566, acc.: 78.91%] [G loss: 1.256136]\n",
      "epoch:15 step:14191 [D loss: 0.604310, acc.: 67.97%] [G loss: 1.203139]\n",
      "epoch:15 step:14192 [D loss: 0.706460, acc.: 53.91%] [G loss: 0.935424]\n",
      "epoch:15 step:14193 [D loss: 0.644756, acc.: 62.50%] [G loss: 0.943678]\n",
      "epoch:15 step:14194 [D loss: 0.746173, acc.: 52.34%] [G loss: 0.994545]\n",
      "epoch:15 step:14195 [D loss: 0.393558, acc.: 85.94%] [G loss: 1.017793]\n",
      "epoch:15 step:14196 [D loss: 0.406587, acc.: 88.28%] [G loss: 1.120979]\n",
      "epoch:15 step:14197 [D loss: 0.477136, acc.: 84.38%] [G loss: 1.127386]\n",
      "epoch:15 step:14198 [D loss: 0.480060, acc.: 69.53%] [G loss: 0.844758]\n",
      "epoch:15 step:14199 [D loss: 0.461966, acc.: 86.72%] [G loss: 1.126798]\n",
      "epoch:15 step:14200 [D loss: 0.236137, acc.: 95.31%] [G loss: 1.446130]\n",
      "##############\n",
      "[4.03871916 2.01375707 6.43151039 5.28801149 4.20461016 6.19503158\n",
      " 5.17048542 4.88660761 5.85799125 4.97946465]\n",
      "##########\n",
      "epoch:15 step:14201 [D loss: 0.478934, acc.: 80.47%] [G loss: 1.326057]\n",
      "epoch:15 step:14202 [D loss: 0.645812, acc.: 62.50%] [G loss: 1.151433]\n",
      "epoch:15 step:14203 [D loss: 0.775998, acc.: 46.88%] [G loss: 0.742526]\n",
      "epoch:15 step:14204 [D loss: 0.232673, acc.: 92.19%] [G loss: 1.243509]\n",
      "epoch:15 step:14205 [D loss: 0.246943, acc.: 90.62%] [G loss: 1.303264]\n",
      "epoch:15 step:14206 [D loss: 0.310975, acc.: 94.53%] [G loss: 1.495272]\n",
      "epoch:15 step:14207 [D loss: 0.503371, acc.: 80.47%] [G loss: 1.035460]\n",
      "epoch:15 step:14208 [D loss: 0.935940, acc.: 39.06%] [G loss: 1.196840]\n",
      "epoch:15 step:14209 [D loss: 0.768155, acc.: 50.78%] [G loss: 0.420489]\n",
      "epoch:15 step:14210 [D loss: 0.593508, acc.: 67.97%] [G loss: 1.243418]\n",
      "epoch:15 step:14211 [D loss: 0.853118, acc.: 39.06%] [G loss: 1.074439]\n",
      "epoch:15 step:14212 [D loss: 0.704605, acc.: 57.03%] [G loss: 1.241609]\n",
      "epoch:15 step:14213 [D loss: 0.865937, acc.: 42.19%] [G loss: 1.022889]\n",
      "epoch:15 step:14214 [D loss: 0.783180, acc.: 46.09%] [G loss: 1.239242]\n",
      "epoch:15 step:14215 [D loss: 1.581823, acc.: 30.47%] [G loss: 1.044495]\n",
      "epoch:15 step:14216 [D loss: 0.758872, acc.: 50.00%] [G loss: 1.097798]\n",
      "epoch:15 step:14217 [D loss: 0.640888, acc.: 64.06%] [G loss: 1.189102]\n",
      "epoch:15 step:14218 [D loss: 0.658925, acc.: 61.72%] [G loss: 1.049704]\n",
      "epoch:15 step:14219 [D loss: 0.660873, acc.: 66.41%] [G loss: 0.850553]\n",
      "epoch:15 step:14220 [D loss: 0.681960, acc.: 58.59%] [G loss: 1.065946]\n",
      "epoch:15 step:14221 [D loss: 0.684516, acc.: 61.72%] [G loss: 0.958792]\n",
      "epoch:15 step:14222 [D loss: 0.678908, acc.: 59.38%] [G loss: 0.886785]\n",
      "epoch:15 step:14223 [D loss: 0.704434, acc.: 55.47%] [G loss: 0.924747]\n",
      "epoch:15 step:14224 [D loss: 0.739517, acc.: 55.47%] [G loss: 0.947423]\n",
      "epoch:15 step:14225 [D loss: 0.674640, acc.: 57.03%] [G loss: 0.857579]\n",
      "epoch:15 step:14226 [D loss: 0.673101, acc.: 57.81%] [G loss: 1.113939]\n",
      "epoch:15 step:14227 [D loss: 0.692014, acc.: 55.47%] [G loss: 1.209400]\n",
      "epoch:15 step:14228 [D loss: 0.648476, acc.: 60.16%] [G loss: 1.183220]\n",
      "epoch:15 step:14229 [D loss: 0.651425, acc.: 64.84%] [G loss: 1.062493]\n",
      "epoch:15 step:14230 [D loss: 0.702598, acc.: 53.91%] [G loss: 0.974123]\n",
      "epoch:15 step:14231 [D loss: 0.597731, acc.: 72.66%] [G loss: 0.993119]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:15 step:14232 [D loss: 0.662126, acc.: 58.59%] [G loss: 1.046866]\n",
      "epoch:15 step:14233 [D loss: 0.707802, acc.: 53.91%] [G loss: 0.907194]\n",
      "epoch:15 step:14234 [D loss: 0.723995, acc.: 56.25%] [G loss: 0.771855]\n",
      "epoch:15 step:14235 [D loss: 0.706412, acc.: 54.69%] [G loss: 0.844315]\n",
      "epoch:15 step:14236 [D loss: 0.688140, acc.: 57.03%] [G loss: 0.800561]\n",
      "epoch:15 step:14237 [D loss: 0.609471, acc.: 69.53%] [G loss: 1.015344]\n",
      "epoch:15 step:14238 [D loss: 0.649523, acc.: 60.16%] [G loss: 0.926346]\n",
      "epoch:15 step:14239 [D loss: 0.557884, acc.: 75.78%] [G loss: 0.889365]\n",
      "epoch:15 step:14240 [D loss: 0.727302, acc.: 53.91%] [G loss: 0.936041]\n",
      "epoch:15 step:14241 [D loss: 0.670048, acc.: 53.91%] [G loss: 1.028302]\n",
      "epoch:15 step:14242 [D loss: 0.695285, acc.: 59.38%] [G loss: 0.925404]\n",
      "epoch:15 step:14243 [D loss: 0.675420, acc.: 57.81%] [G loss: 0.999267]\n",
      "epoch:15 step:14244 [D loss: 0.651503, acc.: 64.84%] [G loss: 0.992746]\n",
      "epoch:15 step:14245 [D loss: 0.634849, acc.: 65.62%] [G loss: 0.882382]\n",
      "epoch:15 step:14246 [D loss: 0.650242, acc.: 54.69%] [G loss: 0.928063]\n",
      "epoch:15 step:14247 [D loss: 0.510966, acc.: 76.56%] [G loss: 1.021352]\n",
      "epoch:15 step:14248 [D loss: 0.628457, acc.: 60.16%] [G loss: 0.801720]\n",
      "epoch:15 step:14249 [D loss: 0.466090, acc.: 87.50%] [G loss: 0.845100]\n",
      "epoch:15 step:14250 [D loss: 0.599327, acc.: 70.31%] [G loss: 0.816546]\n",
      "epoch:15 step:14251 [D loss: 0.550735, acc.: 75.78%] [G loss: 1.578098]\n",
      "epoch:15 step:14252 [D loss: 0.516862, acc.: 80.47%] [G loss: 1.013385]\n",
      "epoch:15 step:14253 [D loss: 0.514166, acc.: 82.81%] [G loss: 1.063907]\n",
      "epoch:15 step:14254 [D loss: 0.747066, acc.: 50.78%] [G loss: 0.944357]\n",
      "epoch:15 step:14255 [D loss: 0.749585, acc.: 51.56%] [G loss: 0.931429]\n",
      "epoch:15 step:14256 [D loss: 0.459353, acc.: 82.03%] [G loss: 0.934302]\n",
      "epoch:15 step:14257 [D loss: 0.719013, acc.: 51.56%] [G loss: 1.143672]\n",
      "epoch:15 step:14258 [D loss: 0.566654, acc.: 76.56%] [G loss: 0.626739]\n",
      "epoch:15 step:14259 [D loss: 0.548396, acc.: 74.22%] [G loss: 0.930274]\n",
      "epoch:15 step:14260 [D loss: 0.549555, acc.: 78.12%] [G loss: 0.812300]\n",
      "epoch:15 step:14261 [D loss: 0.522398, acc.: 77.34%] [G loss: 0.856244]\n",
      "epoch:15 step:14262 [D loss: 0.561698, acc.: 67.97%] [G loss: 0.797806]\n",
      "epoch:15 step:14263 [D loss: 0.567534, acc.: 73.44%] [G loss: 0.647164]\n",
      "epoch:15 step:14264 [D loss: 0.558679, acc.: 74.22%] [G loss: 1.176724]\n",
      "epoch:15 step:14265 [D loss: 0.819736, acc.: 47.66%] [G loss: 1.047538]\n",
      "epoch:15 step:14266 [D loss: 0.828465, acc.: 40.62%] [G loss: 0.791304]\n",
      "epoch:15 step:14267 [D loss: 0.691925, acc.: 61.72%] [G loss: 0.893163]\n",
      "epoch:15 step:14268 [D loss: 0.744152, acc.: 50.78%] [G loss: 1.008557]\n",
      "epoch:15 step:14269 [D loss: 0.752859, acc.: 50.00%] [G loss: 0.766437]\n",
      "epoch:15 step:14270 [D loss: 0.819448, acc.: 38.28%] [G loss: 0.803313]\n",
      "epoch:15 step:14271 [D loss: 0.721251, acc.: 54.69%] [G loss: 0.862353]\n",
      "epoch:15 step:14272 [D loss: 0.580445, acc.: 74.22%] [G loss: 0.924304]\n",
      "epoch:15 step:14273 [D loss: 0.616164, acc.: 66.41%] [G loss: 0.735356]\n",
      "epoch:15 step:14274 [D loss: 0.588933, acc.: 70.31%] [G loss: 1.077216]\n",
      "epoch:15 step:14275 [D loss: 0.395077, acc.: 74.22%] [G loss: 0.971946]\n",
      "epoch:15 step:14276 [D loss: 0.300682, acc.: 89.06%] [G loss: 1.064958]\n",
      "epoch:15 step:14277 [D loss: 0.484123, acc.: 82.03%] [G loss: 1.040018]\n",
      "epoch:15 step:14278 [D loss: 0.587930, acc.: 72.66%] [G loss: 1.251454]\n",
      "epoch:15 step:14279 [D loss: 0.747362, acc.: 50.78%] [G loss: 1.131996]\n",
      "epoch:15 step:14280 [D loss: 0.655039, acc.: 60.16%] [G loss: 1.162337]\n",
      "epoch:15 step:14281 [D loss: 0.609145, acc.: 64.84%] [G loss: 1.101330]\n",
      "epoch:15 step:14282 [D loss: 0.590837, acc.: 67.97%] [G loss: 1.089235]\n",
      "epoch:15 step:14283 [D loss: 0.696125, acc.: 52.34%] [G loss: 1.081707]\n",
      "epoch:15 step:14284 [D loss: 0.497928, acc.: 82.81%] [G loss: 1.205765]\n",
      "epoch:15 step:14285 [D loss: 0.257970, acc.: 89.84%] [G loss: 0.995481]\n",
      "epoch:15 step:14286 [D loss: 0.269179, acc.: 91.41%] [G loss: 1.074478]\n",
      "epoch:15 step:14287 [D loss: 0.199094, acc.: 98.44%] [G loss: 1.195001]\n",
      "epoch:15 step:14288 [D loss: 0.563691, acc.: 75.78%] [G loss: 1.281729]\n",
      "epoch:15 step:14289 [D loss: 0.305334, acc.: 94.53%] [G loss: 0.902782]\n",
      "epoch:15 step:14290 [D loss: 0.286612, acc.: 92.97%] [G loss: 1.157339]\n",
      "epoch:15 step:14291 [D loss: 0.612608, acc.: 67.19%] [G loss: 1.546701]\n",
      "epoch:15 step:14292 [D loss: 0.347378, acc.: 89.84%] [G loss: 1.455714]\n",
      "epoch:15 step:14293 [D loss: 0.330648, acc.: 93.75%] [G loss: 1.331177]\n",
      "epoch:15 step:14294 [D loss: 0.697588, acc.: 60.94%] [G loss: 1.129291]\n",
      "epoch:15 step:14295 [D loss: 0.615970, acc.: 68.75%] [G loss: 1.173815]\n",
      "epoch:15 step:14296 [D loss: 0.928333, acc.: 31.25%] [G loss: 0.877997]\n",
      "epoch:15 step:14297 [D loss: 0.753408, acc.: 51.56%] [G loss: 0.655612]\n",
      "epoch:15 step:14298 [D loss: 0.718558, acc.: 60.94%] [G loss: 0.584027]\n",
      "epoch:15 step:14299 [D loss: 1.028907, acc.: 25.78%] [G loss: 1.107162]\n",
      "epoch:15 step:14300 [D loss: 0.780481, acc.: 47.66%] [G loss: 1.490753]\n",
      "epoch:15 step:14301 [D loss: 0.824729, acc.: 40.62%] [G loss: 1.192351]\n",
      "epoch:15 step:14302 [D loss: 0.769864, acc.: 53.12%] [G loss: 0.565817]\n",
      "epoch:15 step:14303 [D loss: 0.644564, acc.: 63.28%] [G loss: 1.149469]\n",
      "epoch:15 step:14304 [D loss: 0.681222, acc.: 61.72%] [G loss: 1.061889]\n",
      "epoch:15 step:14305 [D loss: 0.755101, acc.: 47.66%] [G loss: 0.974473]\n",
      "epoch:15 step:14306 [D loss: 0.655998, acc.: 67.19%] [G loss: 0.859744]\n",
      "epoch:15 step:14307 [D loss: 0.703500, acc.: 51.56%] [G loss: 0.922689]\n",
      "epoch:15 step:14308 [D loss: 0.671136, acc.: 64.84%] [G loss: 0.892659]\n",
      "epoch:15 step:14309 [D loss: 0.657986, acc.: 60.94%] [G loss: 0.717185]\n",
      "epoch:15 step:14310 [D loss: 0.485089, acc.: 81.25%] [G loss: 0.947930]\n",
      "epoch:15 step:14311 [D loss: 0.295566, acc.: 86.72%] [G loss: 0.937957]\n",
      "epoch:15 step:14312 [D loss: 0.530828, acc.: 79.69%] [G loss: 0.347758]\n",
      "epoch:15 step:14313 [D loss: 0.713150, acc.: 57.03%] [G loss: 0.534208]\n",
      "epoch:15 step:14314 [D loss: 0.407291, acc.: 74.22%] [G loss: 0.555272]\n",
      "epoch:15 step:14315 [D loss: 0.273588, acc.: 95.31%] [G loss: 1.158956]\n",
      "epoch:15 step:14316 [D loss: 0.284654, acc.: 92.19%] [G loss: 1.306699]\n",
      "epoch:15 step:14317 [D loss: 0.671944, acc.: 61.72%] [G loss: 1.215321]\n",
      "epoch:15 step:14318 [D loss: 0.785430, acc.: 44.53%] [G loss: 1.054730]\n",
      "epoch:15 step:14319 [D loss: 1.061710, acc.: 32.81%] [G loss: 1.364941]\n",
      "epoch:15 step:14320 [D loss: 0.482560, acc.: 83.59%] [G loss: 1.083730]\n",
      "epoch:15 step:14321 [D loss: 0.850540, acc.: 42.97%] [G loss: 1.243699]\n",
      "epoch:15 step:14322 [D loss: 0.648773, acc.: 61.72%] [G loss: 1.178020]\n",
      "epoch:15 step:14323 [D loss: 0.828090, acc.: 35.94%] [G loss: 1.255319]\n",
      "epoch:15 step:14324 [D loss: 0.460845, acc.: 78.91%] [G loss: 1.083933]\n",
      "epoch:15 step:14325 [D loss: 0.598688, acc.: 67.19%] [G loss: 1.135839]\n",
      "epoch:15 step:14326 [D loss: 0.564217, acc.: 71.88%] [G loss: 1.148889]\n",
      "epoch:15 step:14327 [D loss: 0.474239, acc.: 78.12%] [G loss: 1.211067]\n",
      "epoch:15 step:14328 [D loss: 0.562900, acc.: 78.91%] [G loss: 1.098384]\n",
      "epoch:15 step:14329 [D loss: 0.591023, acc.: 71.88%] [G loss: 0.972495]\n",
      "epoch:15 step:14330 [D loss: 0.502067, acc.: 75.00%] [G loss: 1.070739]\n",
      "epoch:15 step:14331 [D loss: 0.711923, acc.: 51.56%] [G loss: 0.881446]\n",
      "epoch:15 step:14332 [D loss: 0.573807, acc.: 70.31%] [G loss: 0.782912]\n",
      "epoch:15 step:14333 [D loss: 0.821063, acc.: 50.78%] [G loss: 1.020199]\n",
      "epoch:15 step:14334 [D loss: 0.417517, acc.: 74.22%] [G loss: 1.001620]\n",
      "epoch:15 step:14335 [D loss: 0.604467, acc.: 62.50%] [G loss: 1.339679]\n",
      "epoch:15 step:14336 [D loss: 0.721115, acc.: 53.91%] [G loss: 1.134312]\n",
      "epoch:15 step:14337 [D loss: 0.636381, acc.: 64.06%] [G loss: 1.945017]\n",
      "epoch:15 step:14338 [D loss: 0.734674, acc.: 49.22%] [G loss: 0.905357]\n",
      "epoch:15 step:14339 [D loss: 0.667098, acc.: 64.84%] [G loss: 0.901486]\n",
      "epoch:15 step:14340 [D loss: 0.609551, acc.: 69.53%] [G loss: 1.051264]\n",
      "epoch:15 step:14341 [D loss: 0.677257, acc.: 59.38%] [G loss: 0.998227]\n",
      "epoch:15 step:14342 [D loss: 0.499855, acc.: 74.22%] [G loss: 0.993972]\n",
      "epoch:15 step:14343 [D loss: 0.514369, acc.: 76.56%] [G loss: 1.010185]\n",
      "epoch:15 step:14344 [D loss: 0.346284, acc.: 85.94%] [G loss: 1.084762]\n",
      "epoch:15 step:14345 [D loss: 0.402980, acc.: 84.38%] [G loss: 1.022197]\n",
      "epoch:15 step:14346 [D loss: 0.655254, acc.: 56.25%] [G loss: 1.045241]\n",
      "epoch:15 step:14347 [D loss: 0.327937, acc.: 92.19%] [G loss: 1.101636]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:15 step:14348 [D loss: 0.342921, acc.: 92.19%] [G loss: 1.153540]\n",
      "epoch:15 step:14349 [D loss: 0.567000, acc.: 75.78%] [G loss: 0.993624]\n",
      "epoch:15 step:14350 [D loss: 1.039867, acc.: 23.44%] [G loss: 0.751769]\n",
      "epoch:15 step:14351 [D loss: 0.717626, acc.: 54.69%] [G loss: 0.976005]\n",
      "epoch:15 step:14352 [D loss: 0.718715, acc.: 51.56%] [G loss: 0.874020]\n",
      "epoch:15 step:14353 [D loss: 0.664337, acc.: 63.28%] [G loss: 1.014495]\n",
      "epoch:15 step:14354 [D loss: 0.757351, acc.: 50.78%] [G loss: 0.911283]\n",
      "epoch:15 step:14355 [D loss: 0.734579, acc.: 45.31%] [G loss: 0.880673]\n",
      "epoch:15 step:14356 [D loss: 0.856320, acc.: 42.19%] [G loss: 0.612002]\n",
      "epoch:15 step:14357 [D loss: 0.649158, acc.: 61.72%] [G loss: 0.834741]\n",
      "epoch:15 step:14358 [D loss: 0.686751, acc.: 56.25%] [G loss: 0.920753]\n",
      "epoch:15 step:14359 [D loss: 0.677288, acc.: 60.94%] [G loss: 0.852650]\n",
      "epoch:15 step:14360 [D loss: 0.548292, acc.: 72.66%] [G loss: 0.925682]\n",
      "epoch:15 step:14361 [D loss: 0.597081, acc.: 66.41%] [G loss: 0.533293]\n",
      "epoch:15 step:14362 [D loss: 0.649848, acc.: 63.28%] [G loss: 0.899018]\n",
      "epoch:15 step:14363 [D loss: 0.474620, acc.: 88.28%] [G loss: 0.510684]\n",
      "epoch:15 step:14364 [D loss: 0.260736, acc.: 93.75%] [G loss: 0.999398]\n",
      "epoch:15 step:14365 [D loss: 0.620955, acc.: 67.19%] [G loss: 0.790761]\n",
      "epoch:15 step:14366 [D loss: 0.523131, acc.: 81.25%] [G loss: 0.520461]\n",
      "epoch:15 step:14367 [D loss: 0.342668, acc.: 80.47%] [G loss: 0.960018]\n",
      "epoch:15 step:14368 [D loss: 0.239289, acc.: 96.09%] [G loss: 1.038641]\n",
      "epoch:15 step:14369 [D loss: 0.204669, acc.: 98.44%] [G loss: 1.181038]\n",
      "epoch:15 step:14370 [D loss: 0.296660, acc.: 89.06%] [G loss: 1.204397]\n",
      "epoch:15 step:14371 [D loss: 1.044005, acc.: 21.88%] [G loss: 0.923211]\n",
      "epoch:15 step:14372 [D loss: 0.757623, acc.: 50.00%] [G loss: 1.154322]\n",
      "epoch:15 step:14373 [D loss: 0.707722, acc.: 57.03%] [G loss: 1.080707]\n",
      "epoch:15 step:14374 [D loss: 0.699185, acc.: 56.25%] [G loss: 0.926835]\n",
      "epoch:15 step:14375 [D loss: 0.741404, acc.: 46.88%] [G loss: 0.945976]\n",
      "epoch:15 step:14376 [D loss: 1.045776, acc.: 24.22%] [G loss: 1.002248]\n",
      "epoch:15 step:14377 [D loss: 0.652432, acc.: 64.06%] [G loss: 1.186599]\n",
      "epoch:15 step:14378 [D loss: 0.753059, acc.: 50.00%] [G loss: 0.890353]\n",
      "epoch:15 step:14379 [D loss: 0.703730, acc.: 54.69%] [G loss: 0.994795]\n",
      "epoch:15 step:14380 [D loss: 0.640136, acc.: 63.28%] [G loss: 1.040401]\n",
      "epoch:15 step:14381 [D loss: 0.616629, acc.: 65.62%] [G loss: 0.845177]\n",
      "epoch:15 step:14382 [D loss: 0.444149, acc.: 91.41%] [G loss: 1.013460]\n",
      "epoch:15 step:14383 [D loss: 0.559276, acc.: 72.66%] [G loss: 0.905765]\n",
      "epoch:15 step:14384 [D loss: 0.621163, acc.: 65.62%] [G loss: 1.147445]\n",
      "epoch:15 step:14385 [D loss: 0.775378, acc.: 47.66%] [G loss: 0.960392]\n",
      "epoch:15 step:14386 [D loss: 0.612211, acc.: 67.19%] [G loss: 0.889614]\n",
      "epoch:15 step:14387 [D loss: 0.662739, acc.: 56.25%] [G loss: 0.708892]\n",
      "epoch:15 step:14388 [D loss: 0.664036, acc.: 67.97%] [G loss: 0.936562]\n",
      "epoch:15 step:14389 [D loss: 0.573117, acc.: 72.66%] [G loss: 0.926133]\n",
      "epoch:15 step:14390 [D loss: 0.685114, acc.: 56.25%] [G loss: 0.944157]\n",
      "epoch:15 step:14391 [D loss: 0.396811, acc.: 84.38%] [G loss: 0.993808]\n",
      "epoch:15 step:14392 [D loss: 0.692976, acc.: 53.91%] [G loss: 0.897198]\n",
      "epoch:15 step:14393 [D loss: 0.636760, acc.: 63.28%] [G loss: 0.621234]\n",
      "epoch:15 step:14394 [D loss: 0.580853, acc.: 69.53%] [G loss: 0.841663]\n",
      "epoch:15 step:14395 [D loss: 0.683271, acc.: 57.03%] [G loss: 0.905454]\n",
      "epoch:15 step:14396 [D loss: 0.776486, acc.: 45.31%] [G loss: 0.694860]\n",
      "epoch:15 step:14397 [D loss: 0.622196, acc.: 65.62%] [G loss: 0.925592]\n",
      "epoch:15 step:14398 [D loss: 0.391878, acc.: 85.94%] [G loss: 0.990063]\n",
      "epoch:15 step:14399 [D loss: 0.426984, acc.: 86.72%] [G loss: 0.755911]\n",
      "epoch:15 step:14400 [D loss: 0.630388, acc.: 63.28%] [G loss: 0.958957]\n",
      "##############\n",
      "[3.64766741 2.861881   6.39809304 5.84843802 4.68236734 6.3881948\n",
      " 5.14037598 5.56145704 5.90355318 4.65221741]\n",
      "##########\n",
      "epoch:15 step:14401 [D loss: 0.362954, acc.: 84.38%] [G loss: 0.286171]\n",
      "epoch:15 step:14402 [D loss: 0.625129, acc.: 62.50%] [G loss: 0.534893]\n",
      "epoch:15 step:14403 [D loss: 0.800184, acc.: 51.56%] [G loss: 0.729822]\n",
      "epoch:15 step:14404 [D loss: 0.854175, acc.: 37.50%] [G loss: 0.864606]\n",
      "epoch:15 step:14405 [D loss: 0.847115, acc.: 38.28%] [G loss: 1.392206]\n",
      "epoch:15 step:14406 [D loss: 0.435582, acc.: 83.59%] [G loss: 1.436622]\n",
      "epoch:15 step:14407 [D loss: 0.449991, acc.: 83.59%] [G loss: 1.780997]\n",
      "epoch:15 step:14408 [D loss: 0.396216, acc.: 87.50%] [G loss: 1.482478]\n",
      "epoch:15 step:14409 [D loss: 0.393695, acc.: 88.28%] [G loss: 1.436725]\n",
      "epoch:15 step:14410 [D loss: 0.366386, acc.: 92.97%] [G loss: 1.577576]\n",
      "epoch:15 step:14411 [D loss: 0.516198, acc.: 71.88%] [G loss: 1.247601]\n",
      "epoch:15 step:14412 [D loss: 0.323452, acc.: 95.31%] [G loss: 1.321609]\n",
      "epoch:15 step:14413 [D loss: 0.351383, acc.: 94.53%] [G loss: 1.150698]\n",
      "epoch:15 step:14414 [D loss: 0.293633, acc.: 96.88%] [G loss: 1.761884]\n",
      "epoch:15 step:14415 [D loss: 0.397938, acc.: 88.28%] [G loss: 1.767823]\n",
      "epoch:15 step:14416 [D loss: 0.410841, acc.: 89.06%] [G loss: 1.071937]\n",
      "epoch:15 step:14417 [D loss: 0.908230, acc.: 39.84%] [G loss: 0.777231]\n",
      "epoch:15 step:14418 [D loss: 0.728254, acc.: 52.34%] [G loss: 0.998063]\n",
      "epoch:15 step:14419 [D loss: 0.501317, acc.: 76.56%] [G loss: 0.877615]\n",
      "epoch:15 step:14420 [D loss: 1.111075, acc.: 21.88%] [G loss: 0.889221]\n",
      "epoch:15 step:14421 [D loss: 0.884375, acc.: 48.44%] [G loss: 1.230956]\n",
      "epoch:15 step:14422 [D loss: 0.827880, acc.: 37.50%] [G loss: 0.898617]\n",
      "epoch:15 step:14423 [D loss: 0.868556, acc.: 42.97%] [G loss: 0.581833]\n",
      "epoch:15 step:14424 [D loss: 0.404579, acc.: 88.28%] [G loss: 0.853236]\n",
      "epoch:15 step:14425 [D loss: 0.438068, acc.: 78.91%] [G loss: 1.079367]\n",
      "epoch:15 step:14426 [D loss: 0.439977, acc.: 79.69%] [G loss: 1.321197]\n",
      "epoch:15 step:14427 [D loss: 0.399169, acc.: 91.41%] [G loss: 1.115132]\n",
      "epoch:15 step:14428 [D loss: 0.786330, acc.: 50.78%] [G loss: 0.743419]\n",
      "epoch:15 step:14429 [D loss: 0.456416, acc.: 82.81%] [G loss: 0.920178]\n",
      "epoch:15 step:14430 [D loss: 0.659757, acc.: 63.28%] [G loss: 0.783430]\n",
      "epoch:15 step:14431 [D loss: 0.923803, acc.: 35.16%] [G loss: 0.664946]\n",
      "epoch:15 step:14432 [D loss: 0.739503, acc.: 48.44%] [G loss: 0.684071]\n",
      "epoch:15 step:14433 [D loss: 0.697282, acc.: 57.81%] [G loss: 0.892679]\n",
      "epoch:15 step:14434 [D loss: 0.567617, acc.: 75.00%] [G loss: 0.866321]\n",
      "epoch:15 step:14435 [D loss: 0.424235, acc.: 86.72%] [G loss: 1.069015]\n",
      "epoch:15 step:14436 [D loss: 0.513258, acc.: 75.00%] [G loss: 1.094176]\n",
      "epoch:15 step:14437 [D loss: 0.592917, acc.: 66.41%] [G loss: 1.386856]\n",
      "epoch:15 step:14438 [D loss: 0.711070, acc.: 52.34%] [G loss: 1.208472]\n",
      "epoch:15 step:14439 [D loss: 0.705366, acc.: 53.12%] [G loss: 1.261539]\n",
      "epoch:15 step:14440 [D loss: 0.615634, acc.: 63.28%] [G loss: 0.661151]\n",
      "epoch:15 step:14441 [D loss: 0.692779, acc.: 56.25%] [G loss: 1.142399]\n",
      "epoch:15 step:14442 [D loss: 0.565378, acc.: 74.22%] [G loss: 1.296512]\n",
      "epoch:15 step:14443 [D loss: 0.532030, acc.: 78.12%] [G loss: 0.800714]\n",
      "epoch:15 step:14444 [D loss: 0.671640, acc.: 56.25%] [G loss: 1.064250]\n",
      "epoch:15 step:14445 [D loss: 0.699614, acc.: 55.47%] [G loss: 1.148573]\n",
      "epoch:15 step:14446 [D loss: 0.632970, acc.: 58.59%] [G loss: 0.933106]\n",
      "epoch:15 step:14447 [D loss: 0.786759, acc.: 45.31%] [G loss: 1.185406]\n",
      "epoch:15 step:14448 [D loss: 0.707035, acc.: 53.12%] [G loss: 1.104078]\n",
      "epoch:15 step:14449 [D loss: 0.644790, acc.: 62.50%] [G loss: 1.153741]\n",
      "epoch:15 step:14450 [D loss: 0.697040, acc.: 53.91%] [G loss: 0.834045]\n",
      "epoch:15 step:14451 [D loss: 0.479289, acc.: 77.34%] [G loss: 0.999153]\n",
      "epoch:15 step:14452 [D loss: 0.427430, acc.: 75.78%] [G loss: 1.161254]\n",
      "epoch:15 step:14453 [D loss: 0.347751, acc.: 92.19%] [G loss: 1.270341]\n",
      "epoch:15 step:14454 [D loss: 0.344058, acc.: 85.16%] [G loss: 1.365439]\n",
      "epoch:15 step:14455 [D loss: 0.664652, acc.: 61.72%] [G loss: 1.358225]\n",
      "epoch:15 step:14456 [D loss: 0.574553, acc.: 69.53%] [G loss: 0.880711]\n",
      "epoch:15 step:14457 [D loss: 0.436031, acc.: 77.34%] [G loss: 1.187212]\n",
      "epoch:15 step:14458 [D loss: 0.563392, acc.: 72.66%] [G loss: 0.986092]\n",
      "epoch:15 step:14459 [D loss: 0.385559, acc.: 92.97%] [G loss: 1.174805]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:15 step:14460 [D loss: 0.348537, acc.: 85.94%] [G loss: 1.261868]\n",
      "epoch:15 step:14461 [D loss: 0.496179, acc.: 71.88%] [G loss: 1.257238]\n",
      "epoch:15 step:14462 [D loss: 0.249284, acc.: 95.31%] [G loss: 0.831337]\n",
      "epoch:15 step:14463 [D loss: 0.385939, acc.: 91.41%] [G loss: 1.480146]\n",
      "epoch:15 step:14464 [D loss: 0.253910, acc.: 98.44%] [G loss: 1.500748]\n",
      "epoch:15 step:14465 [D loss: 0.486640, acc.: 80.47%] [G loss: 1.378994]\n",
      "epoch:15 step:14466 [D loss: 1.063413, acc.: 36.72%] [G loss: 1.118201]\n",
      "epoch:15 step:14467 [D loss: 0.374790, acc.: 87.50%] [G loss: 0.827521]\n",
      "epoch:15 step:14468 [D loss: 0.375609, acc.: 93.75%] [G loss: 0.989340]\n",
      "epoch:15 step:14469 [D loss: 0.287104, acc.: 96.88%] [G loss: 0.223234]\n",
      "epoch:15 step:14470 [D loss: 1.364625, acc.: 44.53%] [G loss: 1.193880]\n",
      "epoch:15 step:14471 [D loss: 0.374963, acc.: 95.31%] [G loss: 1.570039]\n",
      "epoch:15 step:14472 [D loss: 0.336329, acc.: 90.62%] [G loss: 1.161506]\n",
      "epoch:15 step:14473 [D loss: 0.191594, acc.: 100.00%] [G loss: 1.478492]\n",
      "epoch:15 step:14474 [D loss: 0.130003, acc.: 100.00%] [G loss: 1.214945]\n",
      "epoch:15 step:14475 [D loss: 0.330634, acc.: 92.97%] [G loss: 1.391414]\n",
      "epoch:15 step:14476 [D loss: 0.720292, acc.: 60.94%] [G loss: 1.201750]\n",
      "epoch:15 step:14477 [D loss: 0.815806, acc.: 51.56%] [G loss: 0.102586]\n",
      "epoch:15 step:14478 [D loss: 0.534304, acc.: 65.62%] [G loss: 0.479993]\n",
      "epoch:15 step:14479 [D loss: 0.393441, acc.: 71.88%] [G loss: 1.719993]\n",
      "epoch:15 step:14480 [D loss: 0.172822, acc.: 98.44%] [G loss: 0.933946]\n",
      "epoch:15 step:14481 [D loss: 1.439568, acc.: 6.25%] [G loss: 0.928701]\n",
      "epoch:15 step:14482 [D loss: 0.687884, acc.: 61.72%] [G loss: 2.449719]\n",
      "epoch:15 step:14483 [D loss: 0.373997, acc.: 84.38%] [G loss: 2.766021]\n",
      "epoch:15 step:14484 [D loss: 1.022207, acc.: 47.66%] [G loss: 1.820897]\n",
      "epoch:15 step:14485 [D loss: 0.294538, acc.: 91.41%] [G loss: 1.384039]\n",
      "epoch:15 step:14486 [D loss: 0.830284, acc.: 52.34%] [G loss: 1.247796]\n",
      "epoch:15 step:14487 [D loss: 1.209885, acc.: 22.66%] [G loss: 1.299356]\n",
      "epoch:15 step:14488 [D loss: 0.954627, acc.: 38.28%] [G loss: 1.261262]\n",
      "epoch:15 step:14489 [D loss: 0.770483, acc.: 51.56%] [G loss: 1.221814]\n",
      "epoch:15 step:14490 [D loss: 0.831767, acc.: 32.03%] [G loss: 0.745354]\n",
      "epoch:15 step:14491 [D loss: 0.755037, acc.: 46.88%] [G loss: 1.074469]\n",
      "epoch:15 step:14492 [D loss: 0.806784, acc.: 38.28%] [G loss: 0.989779]\n",
      "epoch:15 step:14493 [D loss: 0.471894, acc.: 81.25%] [G loss: 0.966335]\n",
      "epoch:15 step:14494 [D loss: 0.827483, acc.: 38.28%] [G loss: 0.922566]\n",
      "epoch:15 step:14495 [D loss: 0.681631, acc.: 60.16%] [G loss: 0.982056]\n",
      "epoch:15 step:14496 [D loss: 0.728518, acc.: 57.81%] [G loss: 0.996967]\n",
      "epoch:15 step:14497 [D loss: 0.776618, acc.: 46.09%] [G loss: 1.034397]\n",
      "epoch:15 step:14498 [D loss: 0.788524, acc.: 47.66%] [G loss: 1.262873]\n",
      "epoch:15 step:14499 [D loss: 0.668471, acc.: 53.91%] [G loss: 1.523541]\n",
      "epoch:15 step:14500 [D loss: 0.733842, acc.: 56.25%] [G loss: 1.783819]\n",
      "epoch:15 step:14501 [D loss: 0.605274, acc.: 61.72%] [G loss: 1.230876]\n",
      "epoch:15 step:14502 [D loss: 0.582634, acc.: 66.41%] [G loss: 1.277908]\n",
      "epoch:15 step:14503 [D loss: 0.543474, acc.: 75.00%] [G loss: 1.241802]\n",
      "epoch:15 step:14504 [D loss: 0.413625, acc.: 89.84%] [G loss: 1.114303]\n",
      "epoch:15 step:14505 [D loss: 0.353445, acc.: 90.62%] [G loss: 1.257055]\n",
      "epoch:15 step:14506 [D loss: 0.421409, acc.: 89.84%] [G loss: 1.337575]\n",
      "epoch:15 step:14507 [D loss: 0.389865, acc.: 93.75%] [G loss: 2.079341]\n",
      "epoch:15 step:14508 [D loss: 0.484450, acc.: 86.72%] [G loss: 1.438965]\n",
      "epoch:15 step:14509 [D loss: 0.524222, acc.: 73.44%] [G loss: 1.321518]\n",
      "epoch:15 step:14510 [D loss: 0.405384, acc.: 89.06%] [G loss: 1.163974]\n",
      "epoch:15 step:14511 [D loss: 0.359367, acc.: 93.75%] [G loss: 1.214439]\n",
      "epoch:15 step:14512 [D loss: 0.407478, acc.: 91.41%] [G loss: 1.262494]\n",
      "epoch:15 step:14513 [D loss: 1.011208, acc.: 26.56%] [G loss: 1.128984]\n",
      "epoch:15 step:14514 [D loss: 0.657916, acc.: 56.25%] [G loss: 1.226469]\n",
      "epoch:15 step:14515 [D loss: 0.663695, acc.: 58.59%] [G loss: 0.635342]\n",
      "epoch:15 step:14516 [D loss: 1.127017, acc.: 17.19%] [G loss: 1.147391]\n",
      "epoch:15 step:14517 [D loss: 0.974196, acc.: 24.22%] [G loss: 0.796961]\n",
      "epoch:15 step:14518 [D loss: 0.735943, acc.: 48.44%] [G loss: 0.831803]\n",
      "epoch:15 step:14519 [D loss: 0.571966, acc.: 65.62%] [G loss: 0.947511]\n",
      "epoch:15 step:14520 [D loss: 0.577385, acc.: 71.09%] [G loss: 0.850153]\n",
      "epoch:15 step:14521 [D loss: 0.532609, acc.: 78.91%] [G loss: 0.872466]\n",
      "epoch:15 step:14522 [D loss: 0.574242, acc.: 72.66%] [G loss: 0.917462]\n",
      "epoch:15 step:14523 [D loss: 0.455396, acc.: 83.59%] [G loss: 0.888574]\n",
      "epoch:15 step:14524 [D loss: 0.483278, acc.: 85.94%] [G loss: 1.118096]\n",
      "epoch:15 step:14525 [D loss: 0.498388, acc.: 78.91%] [G loss: 1.268919]\n",
      "epoch:15 step:14526 [D loss: 0.512945, acc.: 76.56%] [G loss: 1.316046]\n",
      "epoch:15 step:14527 [D loss: 0.593896, acc.: 70.31%] [G loss: 1.401520]\n",
      "epoch:15 step:14528 [D loss: 0.754380, acc.: 50.00%] [G loss: 1.322642]\n",
      "epoch:15 step:14529 [D loss: 0.765050, acc.: 58.59%] [G loss: 1.296376]\n",
      "epoch:15 step:14530 [D loss: 0.608169, acc.: 68.75%] [G loss: 1.213451]\n",
      "epoch:15 step:14531 [D loss: 0.702576, acc.: 59.38%] [G loss: 1.099992]\n",
      "epoch:15 step:14532 [D loss: 0.695850, acc.: 59.38%] [G loss: 1.102488]\n",
      "epoch:15 step:14533 [D loss: 0.605071, acc.: 67.97%] [G loss: 0.962900]\n",
      "epoch:15 step:14534 [D loss: 0.518421, acc.: 75.78%] [G loss: 0.966071]\n",
      "epoch:15 step:14535 [D loss: 0.606047, acc.: 64.84%] [G loss: 0.806598]\n",
      "epoch:15 step:14536 [D loss: 0.500232, acc.: 82.03%] [G loss: 1.062075]\n",
      "epoch:15 step:14537 [D loss: 0.588195, acc.: 70.31%] [G loss: 1.054204]\n",
      "epoch:15 step:14538 [D loss: 0.630391, acc.: 64.84%] [G loss: 0.976173]\n",
      "epoch:15 step:14539 [D loss: 0.527026, acc.: 78.12%] [G loss: 1.134257]\n",
      "epoch:15 step:14540 [D loss: 0.633217, acc.: 65.62%] [G loss: 1.029267]\n",
      "epoch:15 step:14541 [D loss: 0.548013, acc.: 76.56%] [G loss: 1.059063]\n",
      "epoch:15 step:14542 [D loss: 0.655065, acc.: 59.38%] [G loss: 0.974207]\n",
      "epoch:15 step:14543 [D loss: 0.595487, acc.: 74.22%] [G loss: 1.013177]\n",
      "epoch:15 step:14544 [D loss: 0.657892, acc.: 53.12%] [G loss: 1.129930]\n",
      "epoch:15 step:14545 [D loss: 0.662983, acc.: 57.03%] [G loss: 0.826779]\n",
      "epoch:15 step:14546 [D loss: 0.627378, acc.: 69.53%] [G loss: 0.845711]\n",
      "epoch:15 step:14547 [D loss: 0.651884, acc.: 63.28%] [G loss: 1.011341]\n",
      "epoch:15 step:14548 [D loss: 0.629381, acc.: 70.31%] [G loss: 0.870354]\n",
      "epoch:15 step:14549 [D loss: 0.602161, acc.: 65.62%] [G loss: 0.883314]\n",
      "epoch:15 step:14550 [D loss: 0.718537, acc.: 55.47%] [G loss: 0.988561]\n",
      "epoch:15 step:14551 [D loss: 0.692077, acc.: 56.25%] [G loss: 0.896046]\n",
      "epoch:15 step:14552 [D loss: 0.597763, acc.: 67.19%] [G loss: 0.989995]\n",
      "epoch:15 step:14553 [D loss: 0.432076, acc.: 82.03%] [G loss: 1.256629]\n",
      "epoch:15 step:14554 [D loss: 0.447440, acc.: 77.34%] [G loss: 0.977746]\n",
      "epoch:15 step:14555 [D loss: 0.702084, acc.: 63.28%] [G loss: 0.906247]\n",
      "epoch:15 step:14556 [D loss: 0.727147, acc.: 54.69%] [G loss: 0.926962]\n",
      "epoch:15 step:14557 [D loss: 1.077012, acc.: 35.94%] [G loss: 0.996032]\n",
      "epoch:15 step:14558 [D loss: 0.613736, acc.: 68.75%] [G loss: 0.967970]\n",
      "epoch:15 step:14559 [D loss: 0.521306, acc.: 71.88%] [G loss: 1.073839]\n",
      "epoch:15 step:14560 [D loss: 0.527065, acc.: 74.22%] [G loss: 1.085995]\n",
      "epoch:15 step:14561 [D loss: 0.637121, acc.: 61.72%] [G loss: 1.125762]\n",
      "epoch:15 step:14562 [D loss: 0.604526, acc.: 66.41%] [G loss: 1.165591]\n",
      "epoch:15 step:14563 [D loss: 0.565990, acc.: 72.66%] [G loss: 1.093602]\n",
      "epoch:15 step:14564 [D loss: 0.709756, acc.: 53.91%] [G loss: 0.968502]\n",
      "epoch:15 step:14565 [D loss: 0.763636, acc.: 50.78%] [G loss: 1.037366]\n",
      "epoch:15 step:14566 [D loss: 0.494091, acc.: 82.03%] [G loss: 0.957174]\n",
      "epoch:15 step:14567 [D loss: 0.497908, acc.: 82.03%] [G loss: 0.995422]\n",
      "epoch:15 step:14568 [D loss: 0.539626, acc.: 75.78%] [G loss: 1.003001]\n",
      "epoch:15 step:14569 [D loss: 0.556810, acc.: 68.75%] [G loss: 0.953152]\n",
      "epoch:15 step:14570 [D loss: 0.558716, acc.: 67.19%] [G loss: 0.881905]\n",
      "epoch:15 step:14571 [D loss: 0.618088, acc.: 64.84%] [G loss: 0.973855]\n",
      "epoch:15 step:14572 [D loss: 0.556698, acc.: 74.22%] [G loss: 1.006167]\n",
      "epoch:15 step:14573 [D loss: 0.579055, acc.: 72.66%] [G loss: 0.840757]\n",
      "epoch:15 step:14574 [D loss: 0.564545, acc.: 79.69%] [G loss: 1.081056]\n",
      "epoch:15 step:14575 [D loss: 0.542607, acc.: 75.78%] [G loss: 1.080601]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:15 step:14576 [D loss: 0.513753, acc.: 81.25%] [G loss: 1.034891]\n",
      "epoch:15 step:14577 [D loss: 0.659408, acc.: 59.38%] [G loss: 0.938763]\n",
      "epoch:15 step:14578 [D loss: 0.544811, acc.: 76.56%] [G loss: 0.947863]\n",
      "epoch:15 step:14579 [D loss: 0.555670, acc.: 69.53%] [G loss: 1.009861]\n",
      "epoch:15 step:14580 [D loss: 0.782500, acc.: 44.53%] [G loss: 1.210321]\n",
      "epoch:15 step:14581 [D loss: 0.755823, acc.: 46.88%] [G loss: 0.783623]\n",
      "epoch:15 step:14582 [D loss: 0.503693, acc.: 75.78%] [G loss: 1.023852]\n",
      "epoch:15 step:14583 [D loss: 0.877756, acc.: 38.28%] [G loss: 0.961559]\n",
      "epoch:15 step:14584 [D loss: 0.788533, acc.: 43.75%] [G loss: 0.976958]\n",
      "epoch:15 step:14585 [D loss: 0.588365, acc.: 69.53%] [G loss: 1.135299]\n",
      "epoch:15 step:14586 [D loss: 0.761273, acc.: 46.09%] [G loss: 0.932357]\n",
      "epoch:15 step:14587 [D loss: 0.678467, acc.: 55.47%] [G loss: 0.891345]\n",
      "epoch:15 step:14588 [D loss: 0.559563, acc.: 71.09%] [G loss: 1.008910]\n",
      "epoch:15 step:14589 [D loss: 0.559616, acc.: 71.88%] [G loss: 0.891247]\n",
      "epoch:15 step:14590 [D loss: 0.495913, acc.: 72.66%] [G loss: 1.022357]\n",
      "epoch:15 step:14591 [D loss: 0.303815, acc.: 91.41%] [G loss: 1.209889]\n",
      "epoch:15 step:14592 [D loss: 0.352677, acc.: 92.19%] [G loss: 1.154286]\n",
      "epoch:15 step:14593 [D loss: 0.573328, acc.: 75.00%] [G loss: 1.035014]\n",
      "epoch:15 step:14594 [D loss: 0.473840, acc.: 87.50%] [G loss: 1.155239]\n",
      "epoch:15 step:14595 [D loss: 0.595354, acc.: 67.97%] [G loss: 1.146012]\n",
      "epoch:15 step:14596 [D loss: 0.571643, acc.: 74.22%] [G loss: 1.141553]\n",
      "epoch:15 step:14597 [D loss: 0.834724, acc.: 44.53%] [G loss: 0.968233]\n",
      "epoch:15 step:14598 [D loss: 0.635529, acc.: 60.16%] [G loss: 1.070825]\n",
      "epoch:15 step:14599 [D loss: 0.688632, acc.: 61.72%] [G loss: 1.028467]\n",
      "epoch:15 step:14600 [D loss: 0.590431, acc.: 65.62%] [G loss: 0.955725]\n",
      "##############\n",
      "[4.30911726 2.10339945 6.3944613  5.82111962 4.73953167 6.25996819\n",
      " 5.34597754 5.34994009 5.53656716 4.98299777]\n",
      "##########\n",
      "epoch:15 step:14601 [D loss: 0.662511, acc.: 58.59%] [G loss: 0.869750]\n",
      "epoch:15 step:14602 [D loss: 0.589750, acc.: 68.75%] [G loss: 1.078314]\n",
      "epoch:15 step:14603 [D loss: 0.533503, acc.: 80.47%] [G loss: 0.929177]\n",
      "epoch:15 step:14604 [D loss: 0.558051, acc.: 70.31%] [G loss: 1.018062]\n",
      "epoch:15 step:14605 [D loss: 0.523036, acc.: 75.00%] [G loss: 0.961624]\n",
      "epoch:15 step:14606 [D loss: 0.562184, acc.: 71.88%] [G loss: 0.871524]\n",
      "epoch:15 step:14607 [D loss: 0.551134, acc.: 74.22%] [G loss: 1.002862]\n",
      "epoch:15 step:14608 [D loss: 0.704162, acc.: 53.91%] [G loss: 1.040973]\n",
      "epoch:15 step:14609 [D loss: 0.434707, acc.: 84.38%] [G loss: 0.971882]\n",
      "epoch:15 step:14610 [D loss: 0.629865, acc.: 66.41%] [G loss: 0.917869]\n",
      "epoch:15 step:14611 [D loss: 0.558002, acc.: 68.75%] [G loss: 0.937900]\n",
      "epoch:15 step:14612 [D loss: 0.522101, acc.: 75.00%] [G loss: 0.984349]\n",
      "epoch:15 step:14613 [D loss: 0.568436, acc.: 67.97%] [G loss: 1.188738]\n",
      "epoch:15 step:14614 [D loss: 0.233983, acc.: 96.09%] [G loss: 1.279144]\n",
      "epoch:15 step:14615 [D loss: 0.598657, acc.: 70.31%] [G loss: 1.104271]\n",
      "epoch:15 step:14616 [D loss: 0.394949, acc.: 88.28%] [G loss: 1.202546]\n",
      "epoch:15 step:14617 [D loss: 0.744779, acc.: 57.03%] [G loss: 1.114235]\n",
      "epoch:15 step:14618 [D loss: 0.782992, acc.: 49.22%] [G loss: 0.855565]\n",
      "epoch:15 step:14619 [D loss: 0.566572, acc.: 70.31%] [G loss: 0.933006]\n",
      "epoch:15 step:14620 [D loss: 0.678586, acc.: 57.03%] [G loss: 1.040872]\n",
      "epoch:15 step:14621 [D loss: 0.336098, acc.: 87.50%] [G loss: 1.015893]\n",
      "epoch:15 step:14622 [D loss: 0.315962, acc.: 91.41%] [G loss: 1.339582]\n",
      "epoch:15 step:14623 [D loss: 0.390093, acc.: 89.06%] [G loss: 1.119045]\n",
      "epoch:15 step:14624 [D loss: 0.761083, acc.: 51.56%] [G loss: 1.093436]\n",
      "epoch:15 step:14625 [D loss: 0.672575, acc.: 61.72%] [G loss: 0.968856]\n",
      "epoch:15 step:14626 [D loss: 0.876484, acc.: 35.16%] [G loss: 0.827285]\n",
      "epoch:15 step:14627 [D loss: 0.677836, acc.: 58.59%] [G loss: 0.899780]\n",
      "epoch:15 step:14628 [D loss: 0.677006, acc.: 60.16%] [G loss: 0.988045]\n",
      "epoch:15 step:14629 [D loss: 0.560264, acc.: 72.66%] [G loss: 1.081246]\n",
      "epoch:15 step:14630 [D loss: 0.607501, acc.: 67.97%] [G loss: 0.760955]\n",
      "epoch:15 step:14631 [D loss: 0.698500, acc.: 52.34%] [G loss: 1.131173]\n",
      "epoch:15 step:14632 [D loss: 0.430302, acc.: 82.81%] [G loss: 1.245703]\n",
      "epoch:15 step:14633 [D loss: 1.161108, acc.: 47.66%] [G loss: 1.140491]\n",
      "epoch:15 step:14634 [D loss: 0.609275, acc.: 67.19%] [G loss: 1.026061]\n",
      "epoch:15 step:14635 [D loss: 0.808473, acc.: 45.31%] [G loss: 1.122473]\n",
      "epoch:15 step:14636 [D loss: 0.647285, acc.: 67.97%] [G loss: 1.133409]\n",
      "epoch:15 step:14637 [D loss: 0.574810, acc.: 71.88%] [G loss: 1.171793]\n",
      "epoch:15 step:14638 [D loss: 0.598855, acc.: 62.50%] [G loss: 1.016265]\n",
      "epoch:15 step:14639 [D loss: 0.673572, acc.: 58.59%] [G loss: 1.164144]\n",
      "epoch:15 step:14640 [D loss: 0.597037, acc.: 67.97%] [G loss: 1.077307]\n",
      "epoch:15 step:14641 [D loss: 0.566236, acc.: 67.19%] [G loss: 1.028025]\n",
      "epoch:15 step:14642 [D loss: 0.435180, acc.: 85.94%] [G loss: 1.237146]\n",
      "epoch:15 step:14643 [D loss: 0.528188, acc.: 78.12%] [G loss: 1.133600]\n",
      "epoch:15 step:14644 [D loss: 0.392234, acc.: 83.59%] [G loss: 1.138670]\n",
      "epoch:15 step:14645 [D loss: 0.733555, acc.: 55.47%] [G loss: 1.147386]\n",
      "epoch:15 step:14646 [D loss: 0.514143, acc.: 76.56%] [G loss: 1.180262]\n",
      "epoch:15 step:14647 [D loss: 0.406134, acc.: 86.72%] [G loss: 1.333532]\n",
      "epoch:15 step:14648 [D loss: 0.613557, acc.: 64.06%] [G loss: 1.029612]\n",
      "epoch:15 step:14649 [D loss: 0.860235, acc.: 36.72%] [G loss: 1.207963]\n",
      "epoch:15 step:14650 [D loss: 0.439816, acc.: 81.25%] [G loss: 1.087298]\n",
      "epoch:15 step:14651 [D loss: 0.657685, acc.: 62.50%] [G loss: 1.208260]\n",
      "epoch:15 step:14652 [D loss: 0.678072, acc.: 58.59%] [G loss: 1.254493]\n",
      "epoch:15 step:14653 [D loss: 0.599332, acc.: 62.50%] [G loss: 1.117660]\n",
      "epoch:15 step:14654 [D loss: 0.719752, acc.: 53.12%] [G loss: 1.061752]\n",
      "epoch:15 step:14655 [D loss: 0.336747, acc.: 90.62%] [G loss: 1.183162]\n",
      "epoch:15 step:14656 [D loss: 0.712830, acc.: 60.16%] [G loss: 1.023550]\n",
      "epoch:15 step:14657 [D loss: 0.467568, acc.: 80.47%] [G loss: 1.112659]\n",
      "epoch:15 step:14658 [D loss: 0.663558, acc.: 60.94%] [G loss: 0.962368]\n",
      "epoch:15 step:14659 [D loss: 0.583698, acc.: 64.84%] [G loss: 0.921657]\n",
      "epoch:15 step:14660 [D loss: 0.641784, acc.: 59.38%] [G loss: 0.799371]\n",
      "epoch:15 step:14661 [D loss: 0.726672, acc.: 53.91%] [G loss: 1.031051]\n",
      "epoch:15 step:14662 [D loss: 0.776609, acc.: 41.41%] [G loss: 0.898904]\n",
      "epoch:15 step:14663 [D loss: 0.584538, acc.: 76.56%] [G loss: 1.099508]\n",
      "epoch:15 step:14664 [D loss: 0.351003, acc.: 87.50%] [G loss: 1.096714]\n",
      "epoch:15 step:14665 [D loss: 0.750109, acc.: 47.66%] [G loss: 1.180141]\n",
      "epoch:15 step:14666 [D loss: 0.590153, acc.: 75.00%] [G loss: 1.086293]\n",
      "epoch:15 step:14667 [D loss: 0.556884, acc.: 75.78%] [G loss: 1.183900]\n",
      "epoch:15 step:14668 [D loss: 0.628251, acc.: 65.62%] [G loss: 0.986125]\n",
      "epoch:15 step:14669 [D loss: 0.774167, acc.: 49.22%] [G loss: 0.932029]\n",
      "epoch:15 step:14670 [D loss: 0.827970, acc.: 40.62%] [G loss: 0.652018]\n",
      "epoch:15 step:14671 [D loss: 0.697831, acc.: 53.91%] [G loss: 0.940168]\n",
      "epoch:15 step:14672 [D loss: 0.606824, acc.: 66.41%] [G loss: 0.659214]\n",
      "epoch:15 step:14673 [D loss: 0.561712, acc.: 75.78%] [G loss: 0.794294]\n",
      "epoch:15 step:14674 [D loss: 0.606570, acc.: 64.06%] [G loss: 0.896973]\n",
      "epoch:15 step:14675 [D loss: 0.517871, acc.: 76.56%] [G loss: 0.936528]\n",
      "epoch:15 step:14676 [D loss: 0.946051, acc.: 28.12%] [G loss: 0.868593]\n",
      "epoch:15 step:14677 [D loss: 0.662548, acc.: 58.59%] [G loss: 0.926342]\n",
      "epoch:15 step:14678 [D loss: 0.913286, acc.: 41.41%] [G loss: 1.065311]\n",
      "epoch:15 step:14679 [D loss: 0.610181, acc.: 68.75%] [G loss: 1.230959]\n",
      "epoch:15 step:14680 [D loss: 0.717449, acc.: 54.69%] [G loss: 1.009577]\n",
      "epoch:15 step:14681 [D loss: 0.682366, acc.: 57.03%] [G loss: 0.874619]\n",
      "epoch:15 step:14682 [D loss: 0.574233, acc.: 70.31%] [G loss: 0.917681]\n",
      "epoch:15 step:14683 [D loss: 0.680348, acc.: 56.25%] [G loss: 0.866115]\n",
      "epoch:15 step:14684 [D loss: 0.681247, acc.: 59.38%] [G loss: 0.839692]\n",
      "epoch:15 step:14685 [D loss: 0.555067, acc.: 69.53%] [G loss: 1.055931]\n",
      "epoch:15 step:14686 [D loss: 0.651813, acc.: 61.72%] [G loss: 0.957358]\n",
      "epoch:15 step:14687 [D loss: 0.614985, acc.: 62.50%] [G loss: 0.836082]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:15 step:14688 [D loss: 0.521872, acc.: 80.47%] [G loss: 0.928658]\n",
      "epoch:15 step:14689 [D loss: 0.564475, acc.: 75.00%] [G loss: 0.759271]\n",
      "epoch:15 step:14690 [D loss: 0.566440, acc.: 76.56%] [G loss: 0.937322]\n",
      "epoch:15 step:14691 [D loss: 0.654927, acc.: 61.72%] [G loss: 0.670833]\n",
      "epoch:15 step:14692 [D loss: 0.766930, acc.: 53.12%] [G loss: 1.033213]\n",
      "epoch:15 step:14693 [D loss: 0.978721, acc.: 28.91%] [G loss: 1.003657]\n",
      "epoch:15 step:14694 [D loss: 0.401985, acc.: 81.25%] [G loss: 1.066317]\n",
      "epoch:15 step:14695 [D loss: 0.744195, acc.: 51.56%] [G loss: 1.158479]\n",
      "epoch:15 step:14696 [D loss: 0.342136, acc.: 84.38%] [G loss: 1.063325]\n",
      "epoch:15 step:14697 [D loss: 0.715165, acc.: 56.25%] [G loss: 1.115165]\n",
      "epoch:15 step:14698 [D loss: 0.716733, acc.: 52.34%] [G loss: 1.035438]\n",
      "epoch:15 step:14699 [D loss: 0.574451, acc.: 73.44%] [G loss: 1.143689]\n",
      "epoch:15 step:14700 [D loss: 0.533539, acc.: 79.69%] [G loss: 0.815284]\n",
      "epoch:15 step:14701 [D loss: 0.600293, acc.: 67.97%] [G loss: 1.068319]\n",
      "epoch:15 step:14702 [D loss: 0.685206, acc.: 59.38%] [G loss: 1.067570]\n",
      "epoch:15 step:14703 [D loss: 0.571859, acc.: 72.66%] [G loss: 0.998466]\n",
      "epoch:15 step:14704 [D loss: 0.700337, acc.: 58.59%] [G loss: 1.152710]\n",
      "epoch:15 step:14705 [D loss: 0.570231, acc.: 76.56%] [G loss: 1.003565]\n",
      "epoch:15 step:14706 [D loss: 0.612090, acc.: 68.75%] [G loss: 1.107983]\n",
      "epoch:15 step:14707 [D loss: 0.753872, acc.: 46.88%] [G loss: 1.157893]\n",
      "epoch:15 step:14708 [D loss: 0.815615, acc.: 39.06%] [G loss: 1.167451]\n",
      "epoch:15 step:14709 [D loss: 0.812189, acc.: 43.75%] [G loss: 1.044534]\n",
      "epoch:15 step:14710 [D loss: 0.680645, acc.: 57.03%] [G loss: 0.875048]\n",
      "epoch:15 step:14711 [D loss: 0.733119, acc.: 50.78%] [G loss: 1.043929]\n",
      "epoch:15 step:14712 [D loss: 0.761274, acc.: 49.22%] [G loss: 1.028557]\n",
      "epoch:15 step:14713 [D loss: 0.761412, acc.: 52.34%] [G loss: 0.873259]\n",
      "epoch:15 step:14714 [D loss: 0.643936, acc.: 60.16%] [G loss: 0.849995]\n",
      "epoch:15 step:14715 [D loss: 0.533947, acc.: 80.47%] [G loss: 0.882699]\n",
      "epoch:15 step:14716 [D loss: 0.623401, acc.: 65.62%] [G loss: 0.817938]\n",
      "epoch:15 step:14717 [D loss: 0.734202, acc.: 51.56%] [G loss: 0.806251]\n",
      "epoch:15 step:14718 [D loss: 0.302769, acc.: 85.94%] [G loss: 1.017897]\n",
      "epoch:15 step:14719 [D loss: 0.256399, acc.: 96.09%] [G loss: 1.273114]\n",
      "epoch:15 step:14720 [D loss: 0.272100, acc.: 92.19%] [G loss: 1.169561]\n",
      "epoch:15 step:14721 [D loss: 0.637820, acc.: 64.84%] [G loss: 1.307417]\n",
      "epoch:15 step:14722 [D loss: 0.606287, acc.: 68.75%] [G loss: 1.095831]\n",
      "epoch:15 step:14723 [D loss: 0.733934, acc.: 53.12%] [G loss: 1.143995]\n",
      "epoch:15 step:14724 [D loss: 0.631191, acc.: 64.06%] [G loss: 0.889929]\n",
      "epoch:15 step:14725 [D loss: 0.713878, acc.: 54.69%] [G loss: 1.007744]\n",
      "epoch:15 step:14726 [D loss: 0.566550, acc.: 73.44%] [G loss: 1.137552]\n",
      "epoch:15 step:14727 [D loss: 0.622508, acc.: 66.41%] [G loss: 1.071263]\n",
      "epoch:15 step:14728 [D loss: 0.655071, acc.: 58.59%] [G loss: 1.050732]\n",
      "epoch:15 step:14729 [D loss: 0.595915, acc.: 65.62%] [G loss: 1.017119]\n",
      "epoch:15 step:14730 [D loss: 0.747299, acc.: 55.47%] [G loss: 0.917777]\n",
      "epoch:15 step:14731 [D loss: 0.616302, acc.: 66.41%] [G loss: 0.975527]\n",
      "epoch:15 step:14732 [D loss: 0.654421, acc.: 56.25%] [G loss: 0.871893]\n",
      "epoch:15 step:14733 [D loss: 0.753499, acc.: 46.88%] [G loss: 0.859154]\n",
      "epoch:15 step:14734 [D loss: 0.574868, acc.: 75.78%] [G loss: 0.918292]\n",
      "epoch:15 step:14735 [D loss: 0.612191, acc.: 64.84%] [G loss: 0.793677]\n",
      "epoch:15 step:14736 [D loss: 0.645563, acc.: 67.19%] [G loss: 0.875129]\n",
      "epoch:15 step:14737 [D loss: 0.523157, acc.: 67.19%] [G loss: 1.066062]\n",
      "epoch:15 step:14738 [D loss: 0.558833, acc.: 69.53%] [G loss: 0.894502]\n",
      "epoch:15 step:14739 [D loss: 0.344834, acc.: 84.38%] [G loss: 1.014823]\n",
      "epoch:15 step:14740 [D loss: 0.521336, acc.: 80.47%] [G loss: 0.975397]\n",
      "epoch:15 step:14741 [D loss: 0.502528, acc.: 80.47%] [G loss: 1.035924]\n",
      "epoch:15 step:14742 [D loss: 0.507773, acc.: 79.69%] [G loss: 0.795224]\n",
      "epoch:15 step:14743 [D loss: 0.782768, acc.: 48.44%] [G loss: 0.981873]\n",
      "epoch:15 step:14744 [D loss: 0.843164, acc.: 41.41%] [G loss: 0.843976]\n",
      "epoch:15 step:14745 [D loss: 0.729804, acc.: 53.91%] [G loss: 0.891626]\n",
      "epoch:15 step:14746 [D loss: 0.805144, acc.: 39.06%] [G loss: 0.883250]\n",
      "epoch:15 step:14747 [D loss: 0.767100, acc.: 38.28%] [G loss: 0.711342]\n",
      "epoch:15 step:14748 [D loss: 0.692284, acc.: 57.81%] [G loss: 0.958179]\n",
      "epoch:15 step:14749 [D loss: 0.622232, acc.: 64.06%] [G loss: 0.924747]\n",
      "epoch:15 step:14750 [D loss: 0.565156, acc.: 75.00%] [G loss: 0.964765]\n",
      "epoch:15 step:14751 [D loss: 0.443779, acc.: 67.97%] [G loss: 1.070001]\n",
      "epoch:15 step:14752 [D loss: 0.237182, acc.: 93.75%] [G loss: 1.143955]\n",
      "epoch:15 step:14753 [D loss: 0.262677, acc.: 97.66%] [G loss: 1.171651]\n",
      "epoch:15 step:14754 [D loss: 0.601117, acc.: 66.41%] [G loss: 0.900486]\n",
      "epoch:15 step:14755 [D loss: 0.276523, acc.: 87.50%] [G loss: 0.663603]\n",
      "epoch:15 step:14756 [D loss: 0.184620, acc.: 96.88%] [G loss: 0.694136]\n",
      "epoch:15 step:14757 [D loss: 0.397008, acc.: 85.94%] [G loss: 1.244844]\n",
      "epoch:15 step:14758 [D loss: 0.776351, acc.: 53.12%] [G loss: 0.770163]\n",
      "epoch:15 step:14759 [D loss: 0.408840, acc.: 92.19%] [G loss: 0.363620]\n",
      "epoch:15 step:14760 [D loss: 0.721431, acc.: 54.69%] [G loss: 1.129732]\n",
      "epoch:15 step:14761 [D loss: 0.284975, acc.: 89.84%] [G loss: 0.854693]\n",
      "epoch:15 step:14762 [D loss: 0.325126, acc.: 80.47%] [G loss: 0.843714]\n",
      "epoch:15 step:14763 [D loss: 1.474680, acc.: 50.00%] [G loss: 1.778636]\n",
      "epoch:15 step:14764 [D loss: 0.586748, acc.: 65.62%] [G loss: 1.959696]\n",
      "epoch:15 step:14765 [D loss: 1.071328, acc.: 39.06%] [G loss: 2.365448]\n",
      "epoch:15 step:14766 [D loss: 0.791513, acc.: 50.78%] [G loss: 1.137373]\n",
      "epoch:15 step:14767 [D loss: 0.818570, acc.: 49.22%] [G loss: 1.603526]\n",
      "epoch:15 step:14768 [D loss: 0.592479, acc.: 69.53%] [G loss: 1.264941]\n",
      "epoch:15 step:14769 [D loss: 0.647077, acc.: 64.84%] [G loss: 1.100360]\n",
      "epoch:15 step:14770 [D loss: 1.027392, acc.: 23.44%] [G loss: 1.351380]\n",
      "epoch:15 step:14771 [D loss: 0.723156, acc.: 47.66%] [G loss: 1.215590]\n",
      "epoch:15 step:14772 [D loss: 0.728202, acc.: 54.69%] [G loss: 1.155102]\n",
      "epoch:15 step:14773 [D loss: 0.586221, acc.: 68.75%] [G loss: 1.254183]\n",
      "epoch:15 step:14774 [D loss: 0.531781, acc.: 72.66%] [G loss: 1.369360]\n",
      "epoch:15 step:14775 [D loss: 0.505955, acc.: 80.47%] [G loss: 1.968081]\n",
      "epoch:15 step:14776 [D loss: 0.446994, acc.: 79.69%] [G loss: 1.432872]\n",
      "epoch:15 step:14777 [D loss: 0.759991, acc.: 50.00%] [G loss: 1.243625]\n",
      "epoch:15 step:14778 [D loss: 0.632313, acc.: 63.28%] [G loss: 1.178056]\n",
      "epoch:15 step:14779 [D loss: 0.396069, acc.: 89.84%] [G loss: 1.463665]\n",
      "epoch:15 step:14780 [D loss: 0.450742, acc.: 89.06%] [G loss: 1.280839]\n",
      "epoch:15 step:14781 [D loss: 0.422677, acc.: 89.06%] [G loss: 1.319217]\n",
      "epoch:15 step:14782 [D loss: 0.800004, acc.: 50.78%] [G loss: 1.184589]\n",
      "epoch:15 step:14783 [D loss: 0.824583, acc.: 50.78%] [G loss: 0.934114]\n",
      "epoch:15 step:14784 [D loss: 0.695356, acc.: 61.72%] [G loss: 0.810941]\n",
      "epoch:15 step:14785 [D loss: 0.532847, acc.: 70.31%] [G loss: 0.970679]\n",
      "epoch:15 step:14786 [D loss: 0.573583, acc.: 72.66%] [G loss: 0.892614]\n",
      "epoch:15 step:14787 [D loss: 0.501255, acc.: 78.12%] [G loss: 1.054088]\n",
      "epoch:15 step:14788 [D loss: 0.572186, acc.: 70.31%] [G loss: 1.054321]\n",
      "epoch:15 step:14789 [D loss: 0.674723, acc.: 56.25%] [G loss: 0.988372]\n",
      "epoch:15 step:14790 [D loss: 0.546694, acc.: 70.31%] [G loss: 1.109808]\n",
      "epoch:15 step:14791 [D loss: 0.543911, acc.: 77.34%] [G loss: 0.754574]\n",
      "epoch:15 step:14792 [D loss: 0.642510, acc.: 66.41%] [G loss: 1.012687]\n",
      "epoch:15 step:14793 [D loss: 0.611346, acc.: 64.06%] [G loss: 1.182231]\n",
      "epoch:15 step:14794 [D loss: 0.620684, acc.: 60.94%] [G loss: 1.090880]\n",
      "epoch:15 step:14795 [D loss: 0.627991, acc.: 64.06%] [G loss: 0.972330]\n",
      "epoch:15 step:14796 [D loss: 0.440908, acc.: 83.59%] [G loss: 0.921659]\n",
      "epoch:15 step:14797 [D loss: 0.495696, acc.: 79.69%] [G loss: 1.026966]\n",
      "epoch:15 step:14798 [D loss: 0.381369, acc.: 91.41%] [G loss: 1.225675]\n",
      "epoch:15 step:14799 [D loss: 0.571443, acc.: 69.53%] [G loss: 1.217089]\n",
      "epoch:15 step:14800 [D loss: 0.562602, acc.: 71.09%] [G loss: 0.962456]\n",
      "##############\n",
      "[4.20305868 2.44934915 6.86612039 6.17280229 4.83208681 6.59124678\n",
      " 5.32956704 5.84507035 6.24159868 5.04337048]\n",
      "##########\n",
      "epoch:15 step:14801 [D loss: 0.450076, acc.: 75.78%] [G loss: 1.017615]\n",
      "epoch:15 step:14802 [D loss: 0.663112, acc.: 61.72%] [G loss: 1.118304]\n",
      "epoch:15 step:14803 [D loss: 0.560215, acc.: 73.44%] [G loss: 1.224437]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:15 step:14804 [D loss: 0.413812, acc.: 91.41%] [G loss: 0.977461]\n",
      "epoch:15 step:14805 [D loss: 0.415719, acc.: 89.84%] [G loss: 1.050911]\n",
      "epoch:15 step:14806 [D loss: 0.609179, acc.: 69.53%] [G loss: 1.061976]\n",
      "epoch:15 step:14807 [D loss: 0.497757, acc.: 80.47%] [G loss: 0.820270]\n",
      "epoch:15 step:14808 [D loss: 0.814675, acc.: 44.53%] [G loss: 0.980377]\n",
      "epoch:15 step:14809 [D loss: 0.464519, acc.: 80.47%] [G loss: 1.045996]\n",
      "epoch:15 step:14810 [D loss: 0.468927, acc.: 78.91%] [G loss: 0.965883]\n",
      "epoch:15 step:14811 [D loss: 0.288027, acc.: 92.97%] [G loss: 0.564270]\n",
      "epoch:15 step:14812 [D loss: 0.408749, acc.: 85.94%] [G loss: 1.317534]\n",
      "epoch:15 step:14813 [D loss: 0.523822, acc.: 76.56%] [G loss: 1.051757]\n",
      "epoch:15 step:14814 [D loss: 0.603613, acc.: 61.72%] [G loss: 1.165090]\n",
      "epoch:15 step:14815 [D loss: 0.608143, acc.: 62.50%] [G loss: 1.081380]\n",
      "epoch:15 step:14816 [D loss: 0.743766, acc.: 56.25%] [G loss: 1.023840]\n",
      "epoch:15 step:14817 [D loss: 0.558837, acc.: 77.34%] [G loss: 0.435155]\n",
      "epoch:15 step:14818 [D loss: 0.901163, acc.: 53.12%] [G loss: 0.957728]\n",
      "epoch:15 step:14819 [D loss: 0.223811, acc.: 96.88%] [G loss: 1.497545]\n",
      "epoch:15 step:14820 [D loss: 0.646542, acc.: 57.81%] [G loss: 1.459326]\n",
      "epoch:15 step:14821 [D loss: 0.643062, acc.: 58.59%] [G loss: 1.479270]\n",
      "epoch:15 step:14822 [D loss: 0.581412, acc.: 70.31%] [G loss: 1.334882]\n",
      "epoch:15 step:14823 [D loss: 0.345926, acc.: 95.31%] [G loss: 1.373882]\n",
      "epoch:15 step:14824 [D loss: 0.389827, acc.: 87.50%] [G loss: 1.360318]\n",
      "epoch:15 step:14825 [D loss: 0.722285, acc.: 57.03%] [G loss: 1.584811]\n",
      "epoch:15 step:14826 [D loss: 0.754780, acc.: 48.44%] [G loss: 1.294290]\n",
      "epoch:15 step:14827 [D loss: 0.710231, acc.: 60.94%] [G loss: 1.462282]\n",
      "epoch:15 step:14828 [D loss: 0.670705, acc.: 60.16%] [G loss: 1.097788]\n",
      "epoch:15 step:14829 [D loss: 0.467506, acc.: 71.88%] [G loss: 1.163920]\n",
      "epoch:15 step:14830 [D loss: 0.393694, acc.: 87.50%] [G loss: 1.467626]\n",
      "epoch:15 step:14831 [D loss: 0.646967, acc.: 67.19%] [G loss: 1.420572]\n",
      "epoch:15 step:14832 [D loss: 0.423598, acc.: 89.06%] [G loss: 1.364130]\n",
      "epoch:15 step:14833 [D loss: 0.742139, acc.: 54.69%] [G loss: 1.405075]\n",
      "epoch:15 step:14834 [D loss: 0.834075, acc.: 39.84%] [G loss: 0.644108]\n",
      "epoch:15 step:14835 [D loss: 0.440163, acc.: 82.81%] [G loss: 0.628973]\n",
      "epoch:15 step:14836 [D loss: 0.606622, acc.: 71.09%] [G loss: 1.133023]\n",
      "epoch:15 step:14837 [D loss: 0.437393, acc.: 80.47%] [G loss: 1.248415]\n",
      "epoch:15 step:14838 [D loss: 0.636853, acc.: 60.16%] [G loss: 1.223412]\n",
      "epoch:15 step:14839 [D loss: 1.246570, acc.: 25.00%] [G loss: 1.356178]\n",
      "epoch:15 step:14840 [D loss: 0.689222, acc.: 56.25%] [G loss: 1.036089]\n",
      "epoch:15 step:14841 [D loss: 0.486907, acc.: 80.47%] [G loss: 1.042018]\n",
      "epoch:15 step:14842 [D loss: 0.785276, acc.: 41.41%] [G loss: 0.974835]\n",
      "epoch:15 step:14843 [D loss: 0.741797, acc.: 50.78%] [G loss: 1.143865]\n",
      "epoch:15 step:14844 [D loss: 0.817935, acc.: 46.88%] [G loss: 0.995804]\n",
      "epoch:15 step:14845 [D loss: 0.814212, acc.: 47.66%] [G loss: 1.096230]\n",
      "epoch:15 step:14846 [D loss: 0.358698, acc.: 85.16%] [G loss: 1.333809]\n",
      "epoch:15 step:14847 [D loss: 0.337999, acc.: 94.53%] [G loss: 1.235217]\n",
      "epoch:15 step:14848 [D loss: 0.295473, acc.: 94.53%] [G loss: 1.683425]\n",
      "epoch:15 step:14849 [D loss: 0.302863, acc.: 89.84%] [G loss: 1.473210]\n",
      "epoch:15 step:14850 [D loss: 0.603830, acc.: 63.28%] [G loss: 1.292324]\n",
      "epoch:15 step:14851 [D loss: 0.363754, acc.: 90.62%] [G loss: 1.322246]\n",
      "epoch:15 step:14852 [D loss: 0.736433, acc.: 53.91%] [G loss: 0.999681]\n",
      "epoch:15 step:14853 [D loss: 0.702938, acc.: 56.25%] [G loss: 1.185473]\n",
      "epoch:15 step:14854 [D loss: 0.645484, acc.: 64.06%] [G loss: 1.084192]\n",
      "epoch:15 step:14855 [D loss: 0.530786, acc.: 78.91%] [G loss: 1.066256]\n",
      "epoch:15 step:14856 [D loss: 0.576311, acc.: 74.22%] [G loss: 1.073903]\n",
      "epoch:15 step:14857 [D loss: 0.560590, acc.: 75.00%] [G loss: 1.174118]\n",
      "epoch:15 step:14858 [D loss: 0.821187, acc.: 41.41%] [G loss: 1.017831]\n",
      "epoch:15 step:14859 [D loss: 0.272769, acc.: 87.50%] [G loss: 0.993406]\n",
      "epoch:15 step:14860 [D loss: 0.277503, acc.: 93.75%] [G loss: 1.081722]\n",
      "epoch:15 step:14861 [D loss: 0.196878, acc.: 96.88%] [G loss: 1.481063]\n",
      "epoch:15 step:14862 [D loss: 0.786772, acc.: 50.00%] [G loss: 1.068661]\n",
      "epoch:15 step:14863 [D loss: 0.571968, acc.: 73.44%] [G loss: 0.811724]\n",
      "epoch:15 step:14864 [D loss: 0.424517, acc.: 90.62%] [G loss: 1.150470]\n",
      "epoch:15 step:14865 [D loss: 0.534919, acc.: 78.12%] [G loss: 1.266776]\n",
      "epoch:15 step:14866 [D loss: 0.892815, acc.: 49.22%] [G loss: 0.936817]\n",
      "epoch:15 step:14867 [D loss: 0.655902, acc.: 59.38%] [G loss: 0.934282]\n",
      "epoch:15 step:14868 [D loss: 0.723560, acc.: 57.03%] [G loss: 1.013190]\n",
      "epoch:15 step:14869 [D loss: 0.795674, acc.: 39.84%] [G loss: 0.836692]\n",
      "epoch:15 step:14870 [D loss: 0.444678, acc.: 84.38%] [G loss: 1.007387]\n",
      "epoch:15 step:14871 [D loss: 0.558475, acc.: 74.22%] [G loss: 0.991680]\n",
      "epoch:15 step:14872 [D loss: 0.656448, acc.: 60.16%] [G loss: 0.412803]\n",
      "epoch:15 step:14873 [D loss: 0.603338, acc.: 75.00%] [G loss: 1.038861]\n",
      "epoch:15 step:14874 [D loss: 0.550404, acc.: 75.00%] [G loss: 0.893953]\n",
      "epoch:15 step:14875 [D loss: 1.167037, acc.: 13.28%] [G loss: 1.112785]\n",
      "epoch:15 step:14876 [D loss: 0.588291, acc.: 75.00%] [G loss: 0.819921]\n",
      "epoch:15 step:14877 [D loss: 0.734778, acc.: 58.59%] [G loss: 1.084157]\n",
      "epoch:15 step:14878 [D loss: 0.670202, acc.: 64.84%] [G loss: 1.024212]\n",
      "epoch:15 step:14879 [D loss: 0.588811, acc.: 71.09%] [G loss: 0.692007]\n",
      "epoch:15 step:14880 [D loss: 0.446816, acc.: 90.62%] [G loss: 1.101612]\n",
      "epoch:15 step:14881 [D loss: 0.614329, acc.: 66.41%] [G loss: 0.848958]\n",
      "epoch:15 step:14882 [D loss: 0.728138, acc.: 51.56%] [G loss: 0.900865]\n",
      "epoch:15 step:14883 [D loss: 0.975307, acc.: 33.59%] [G loss: 1.046608]\n",
      "epoch:15 step:14884 [D loss: 0.679512, acc.: 54.69%] [G loss: 1.000439]\n",
      "epoch:15 step:14885 [D loss: 0.649750, acc.: 64.84%] [G loss: 0.798346]\n",
      "epoch:15 step:14886 [D loss: 0.428120, acc.: 82.81%] [G loss: 1.218373]\n",
      "epoch:15 step:14887 [D loss: 0.440857, acc.: 89.06%] [G loss: 1.004555]\n",
      "epoch:15 step:14888 [D loss: 0.596862, acc.: 63.28%] [G loss: 1.127570]\n",
      "epoch:15 step:14889 [D loss: 0.745568, acc.: 49.22%] [G loss: 1.122775]\n",
      "epoch:15 step:14890 [D loss: 0.795446, acc.: 40.62%] [G loss: 0.912543]\n",
      "epoch:15 step:14891 [D loss: 0.700666, acc.: 54.69%] [G loss: 1.037376]\n",
      "epoch:15 step:14892 [D loss: 0.722934, acc.: 51.56%] [G loss: 1.011158]\n",
      "epoch:15 step:14893 [D loss: 0.550794, acc.: 75.00%] [G loss: 1.008990]\n",
      "epoch:15 step:14894 [D loss: 0.745191, acc.: 52.34%] [G loss: 0.867833]\n",
      "epoch:15 step:14895 [D loss: 0.841941, acc.: 38.28%] [G loss: 0.784212]\n",
      "epoch:15 step:14896 [D loss: 0.605692, acc.: 63.28%] [G loss: 0.727012]\n",
      "epoch:15 step:14897 [D loss: 0.564501, acc.: 79.69%] [G loss: 0.887192]\n",
      "epoch:15 step:14898 [D loss: 0.635799, acc.: 68.75%] [G loss: 0.826928]\n",
      "epoch:15 step:14899 [D loss: 0.611027, acc.: 68.75%] [G loss: 1.120748]\n",
      "epoch:15 step:14900 [D loss: 0.494892, acc.: 67.19%] [G loss: 0.763431]\n",
      "epoch:15 step:14901 [D loss: 0.751961, acc.: 53.12%] [G loss: 0.913449]\n",
      "epoch:15 step:14902 [D loss: 0.525240, acc.: 74.22%] [G loss: 1.097325]\n",
      "epoch:15 step:14903 [D loss: 0.447914, acc.: 85.94%] [G loss: 1.090120]\n",
      "epoch:15 step:14904 [D loss: 0.685286, acc.: 57.81%] [G loss: 0.921964]\n",
      "epoch:15 step:14905 [D loss: 0.309114, acc.: 89.84%] [G loss: 1.151320]\n",
      "epoch:15 step:14906 [D loss: 0.277039, acc.: 92.97%] [G loss: 0.904280]\n",
      "epoch:15 step:14907 [D loss: 0.313249, acc.: 94.53%] [G loss: 0.643732]\n",
      "epoch:15 step:14908 [D loss: 0.364574, acc.: 95.31%] [G loss: 1.185669]\n",
      "epoch:15 step:14909 [D loss: 0.240079, acc.: 94.53%] [G loss: 1.354733]\n",
      "epoch:15 step:14910 [D loss: 0.697256, acc.: 53.91%] [G loss: 1.308213]\n",
      "epoch:15 step:14911 [D loss: 0.651731, acc.: 59.38%] [G loss: 0.821977]\n",
      "epoch:15 step:14912 [D loss: 0.442750, acc.: 74.22%] [G loss: 0.953235]\n",
      "epoch:15 step:14913 [D loss: 0.532944, acc.: 74.22%] [G loss: 1.178581]\n",
      "epoch:15 step:14914 [D loss: 0.544480, acc.: 75.00%] [G loss: 0.792541]\n",
      "epoch:15 step:14915 [D loss: 1.736190, acc.: 22.66%] [G loss: 0.918792]\n",
      "epoch:15 step:14916 [D loss: 0.575949, acc.: 65.62%] [G loss: 1.115915]\n",
      "epoch:15 step:14917 [D loss: 1.070079, acc.: 30.47%] [G loss: 1.425018]\n",
      "epoch:15 step:14918 [D loss: 0.580613, acc.: 69.53%] [G loss: 1.304171]\n",
      "epoch:15 step:14919 [D loss: 0.618694, acc.: 59.38%] [G loss: 1.161400]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:15 step:14920 [D loss: 0.700618, acc.: 54.69%] [G loss: 1.239724]\n",
      "epoch:15 step:14921 [D loss: 0.550311, acc.: 77.34%] [G loss: 1.009086]\n",
      "epoch:15 step:14922 [D loss: 0.633126, acc.: 60.16%] [G loss: 1.451442]\n",
      "epoch:15 step:14923 [D loss: 0.598854, acc.: 66.41%] [G loss: 1.076110]\n",
      "epoch:15 step:14924 [D loss: 0.652901, acc.: 60.16%] [G loss: 1.264039]\n",
      "epoch:15 step:14925 [D loss: 0.532763, acc.: 78.91%] [G loss: 1.011395]\n",
      "epoch:15 step:14926 [D loss: 0.629261, acc.: 62.50%] [G loss: 1.025092]\n",
      "epoch:15 step:14927 [D loss: 0.645880, acc.: 61.72%] [G loss: 1.038160]\n",
      "epoch:15 step:14928 [D loss: 0.591561, acc.: 74.22%] [G loss: 1.123921]\n",
      "epoch:15 step:14929 [D loss: 0.635986, acc.: 64.84%] [G loss: 1.035882]\n",
      "epoch:15 step:14930 [D loss: 0.477984, acc.: 86.72%] [G loss: 1.330565]\n",
      "epoch:15 step:14931 [D loss: 0.534685, acc.: 74.22%] [G loss: 1.074003]\n",
      "epoch:15 step:14932 [D loss: 0.395556, acc.: 88.28%] [G loss: 1.157947]\n",
      "epoch:15 step:14933 [D loss: 0.315517, acc.: 92.19%] [G loss: 1.106045]\n",
      "epoch:15 step:14934 [D loss: 0.683671, acc.: 57.81%] [G loss: 1.241400]\n",
      "epoch:15 step:14935 [D loss: 0.815755, acc.: 50.00%] [G loss: 1.144642]\n",
      "epoch:15 step:14936 [D loss: 0.846215, acc.: 32.03%] [G loss: 0.701739]\n",
      "epoch:15 step:14937 [D loss: 0.687490, acc.: 57.03%] [G loss: 0.976490]\n",
      "epoch:15 step:14938 [D loss: 0.599590, acc.: 68.75%] [G loss: 0.919038]\n",
      "epoch:15 step:14939 [D loss: 0.568931, acc.: 65.62%] [G loss: 0.707831]\n",
      "epoch:15 step:14940 [D loss: 0.379706, acc.: 74.22%] [G loss: 1.259511]\n",
      "epoch:15 step:14941 [D loss: 0.404996, acc.: 83.59%] [G loss: 1.070364]\n",
      "epoch:15 step:14942 [D loss: 0.267144, acc.: 97.66%] [G loss: 1.394027]\n",
      "epoch:15 step:14943 [D loss: 0.839080, acc.: 46.09%] [G loss: 1.262904]\n",
      "epoch:15 step:14944 [D loss: 0.360223, acc.: 93.75%] [G loss: 1.160363]\n",
      "epoch:15 step:14945 [D loss: 0.264323, acc.: 96.88%] [G loss: 1.091856]\n",
      "epoch:15 step:14946 [D loss: 0.719658, acc.: 53.12%] [G loss: 1.214424]\n",
      "epoch:15 step:14947 [D loss: 0.636877, acc.: 65.62%] [G loss: 1.290148]\n",
      "epoch:15 step:14948 [D loss: 0.707088, acc.: 56.25%] [G loss: 1.103574]\n",
      "epoch:15 step:14949 [D loss: 0.589358, acc.: 67.97%] [G loss: 1.013895]\n",
      "epoch:15 step:14950 [D loss: 0.631052, acc.: 68.75%] [G loss: 1.008411]\n",
      "epoch:15 step:14951 [D loss: 0.612343, acc.: 66.41%] [G loss: 0.932152]\n",
      "epoch:15 step:14952 [D loss: 0.715117, acc.: 55.47%] [G loss: 1.057716]\n",
      "epoch:15 step:14953 [D loss: 0.490654, acc.: 81.25%] [G loss: 0.800778]\n",
      "epoch:15 step:14954 [D loss: 0.458952, acc.: 83.59%] [G loss: 1.120631]\n",
      "epoch:15 step:14955 [D loss: 0.523048, acc.: 75.78%] [G loss: 1.098377]\n",
      "epoch:15 step:14956 [D loss: 0.612306, acc.: 68.75%] [G loss: 1.130130]\n",
      "epoch:15 step:14957 [D loss: 0.707306, acc.: 57.03%] [G loss: 0.749336]\n",
      "epoch:15 step:14958 [D loss: 0.664591, acc.: 54.69%] [G loss: 0.751430]\n",
      "epoch:15 step:14959 [D loss: 0.271173, acc.: 94.53%] [G loss: 1.084713]\n",
      "epoch:15 step:14960 [D loss: 0.463563, acc.: 82.03%] [G loss: 1.030437]\n",
      "epoch:15 step:14961 [D loss: 0.314139, acc.: 90.62%] [G loss: 1.171141]\n",
      "epoch:15 step:14962 [D loss: 0.768033, acc.: 55.47%] [G loss: 1.141181]\n",
      "epoch:15 step:14963 [D loss: 0.841826, acc.: 46.88%] [G loss: 1.061577]\n",
      "epoch:15 step:14964 [D loss: 0.654279, acc.: 58.59%] [G loss: 1.134755]\n",
      "epoch:15 step:14965 [D loss: 0.583193, acc.: 78.12%] [G loss: 1.207397]\n",
      "epoch:15 step:14966 [D loss: 0.635377, acc.: 67.19%] [G loss: 1.192998]\n",
      "epoch:15 step:14967 [D loss: 0.291864, acc.: 89.84%] [G loss: 1.181592]\n",
      "epoch:15 step:14968 [D loss: 0.808044, acc.: 47.66%] [G loss: 0.984049]\n",
      "epoch:15 step:14969 [D loss: 0.502330, acc.: 81.25%] [G loss: 1.174317]\n",
      "epoch:15 step:14970 [D loss: 0.546217, acc.: 77.34%] [G loss: 1.069269]\n",
      "epoch:15 step:14971 [D loss: 0.345773, acc.: 89.84%] [G loss: 1.118989]\n",
      "epoch:15 step:14972 [D loss: 0.224262, acc.: 96.88%] [G loss: 1.391211]\n",
      "epoch:15 step:14973 [D loss: 0.676913, acc.: 55.47%] [G loss: 1.281783]\n",
      "epoch:15 step:14974 [D loss: 0.628319, acc.: 64.84%] [G loss: 1.060181]\n",
      "epoch:15 step:14975 [D loss: 0.258989, acc.: 89.84%] [G loss: 1.218243]\n",
      "epoch:15 step:14976 [D loss: 0.177265, acc.: 98.44%] [G loss: 1.367371]\n",
      "epoch:15 step:14977 [D loss: 0.485983, acc.: 87.50%] [G loss: 1.161187]\n",
      "epoch:15 step:14978 [D loss: 0.660558, acc.: 60.94%] [G loss: 1.158421]\n",
      "epoch:15 step:14979 [D loss: 0.682524, acc.: 59.38%] [G loss: 0.968722]\n",
      "epoch:15 step:14980 [D loss: 0.620129, acc.: 65.62%] [G loss: 0.864364]\n",
      "epoch:15 step:14981 [D loss: 0.498398, acc.: 79.69%] [G loss: 1.115967]\n",
      "epoch:15 step:14982 [D loss: 0.611456, acc.: 60.94%] [G loss: 0.984457]\n",
      "epoch:15 step:14983 [D loss: 0.396328, acc.: 89.06%] [G loss: 1.238117]\n",
      "epoch:15 step:14984 [D loss: 0.267478, acc.: 85.16%] [G loss: 0.993574]\n",
      "epoch:15 step:14985 [D loss: 0.541086, acc.: 69.53%] [G loss: 0.827937]\n",
      "epoch:15 step:14986 [D loss: 0.625401, acc.: 65.62%] [G loss: 1.349200]\n",
      "epoch:15 step:14987 [D loss: 0.657242, acc.: 59.38%] [G loss: 1.170628]\n",
      "epoch:15 step:14988 [D loss: 0.611825, acc.: 63.28%] [G loss: 1.092760]\n",
      "epoch:15 step:14989 [D loss: 0.489825, acc.: 78.12%] [G loss: 1.364595]\n",
      "epoch:15 step:14990 [D loss: 0.569258, acc.: 72.66%] [G loss: 1.035182]\n",
      "epoch:15 step:14991 [D loss: 0.390560, acc.: 86.72%] [G loss: 1.180118]\n",
      "epoch:15 step:14992 [D loss: 0.356975, acc.: 78.12%] [G loss: 1.134280]\n",
      "epoch:16 step:14993 [D loss: 0.655462, acc.: 70.31%] [G loss: 1.166032]\n",
      "epoch:16 step:14994 [D loss: 0.841945, acc.: 44.53%] [G loss: 1.263471]\n",
      "epoch:16 step:14995 [D loss: 0.767203, acc.: 50.78%] [G loss: 1.217383]\n",
      "epoch:16 step:14996 [D loss: 0.661510, acc.: 59.38%] [G loss: 0.927439]\n",
      "epoch:16 step:14997 [D loss: 0.721668, acc.: 50.78%] [G loss: 0.862979]\n",
      "epoch:16 step:14998 [D loss: 0.570931, acc.: 72.66%] [G loss: 0.947038]\n",
      "epoch:16 step:14999 [D loss: 0.587800, acc.: 66.41%] [G loss: 0.902890]\n",
      "epoch:16 step:15000 [D loss: 0.529085, acc.: 77.34%] [G loss: 1.161684]\n",
      "##############\n",
      "[4.17493178 3.00961656 6.69485382 5.5507899  4.50700137 6.38064302\n",
      " 5.39670445 5.8411845  5.85583057 4.95594262]\n",
      "##########\n",
      "epoch:16 step:15001 [D loss: 0.479834, acc.: 76.56%] [G loss: 1.105689]\n",
      "epoch:16 step:15002 [D loss: 0.359015, acc.: 92.19%] [G loss: 0.763448]\n",
      "epoch:16 step:15003 [D loss: 0.718428, acc.: 54.69%] [G loss: 0.902992]\n",
      "epoch:16 step:15004 [D loss: 0.409909, acc.: 87.50%] [G loss: 1.307136]\n",
      "epoch:16 step:15005 [D loss: 0.470063, acc.: 82.03%] [G loss: 0.867159]\n",
      "epoch:16 step:15006 [D loss: 0.774399, acc.: 54.69%] [G loss: 1.028321]\n",
      "epoch:16 step:15007 [D loss: 0.428338, acc.: 85.94%] [G loss: 1.025284]\n",
      "epoch:16 step:15008 [D loss: 0.703734, acc.: 57.03%] [G loss: 1.062446]\n",
      "epoch:16 step:15009 [D loss: 0.799915, acc.: 39.84%] [G loss: 1.022070]\n",
      "epoch:16 step:15010 [D loss: 0.546101, acc.: 71.88%] [G loss: 0.855235]\n",
      "epoch:16 step:15011 [D loss: 0.958018, acc.: 35.94%] [G loss: 1.097460]\n",
      "epoch:16 step:15012 [D loss: 1.184661, acc.: 19.53%] [G loss: 0.841985]\n",
      "epoch:16 step:15013 [D loss: 0.965903, acc.: 35.94%] [G loss: 1.252270]\n",
      "epoch:16 step:15014 [D loss: 0.671762, acc.: 60.16%] [G loss: 1.298854]\n",
      "epoch:16 step:15015 [D loss: 0.888607, acc.: 39.84%] [G loss: 0.939383]\n",
      "epoch:16 step:15016 [D loss: 0.793991, acc.: 44.53%] [G loss: 1.204491]\n",
      "epoch:16 step:15017 [D loss: 0.781922, acc.: 52.34%] [G loss: 1.372512]\n",
      "epoch:16 step:15018 [D loss: 0.787696, acc.: 46.88%] [G loss: 1.031594]\n",
      "epoch:16 step:15019 [D loss: 0.388048, acc.: 80.47%] [G loss: 1.684072]\n",
      "epoch:16 step:15020 [D loss: 0.544327, acc.: 73.44%] [G loss: 1.524098]\n",
      "epoch:16 step:15021 [D loss: 0.659175, acc.: 60.16%] [G loss: 1.363282]\n",
      "epoch:16 step:15022 [D loss: 0.634577, acc.: 61.72%] [G loss: 1.300739]\n",
      "epoch:16 step:15023 [D loss: 0.229355, acc.: 95.31%] [G loss: 1.410298]\n",
      "epoch:16 step:15024 [D loss: 0.292966, acc.: 94.53%] [G loss: 1.495917]\n",
      "epoch:16 step:15025 [D loss: 0.238138, acc.: 96.09%] [G loss: 1.305828]\n",
      "epoch:16 step:15026 [D loss: 0.237266, acc.: 96.09%] [G loss: 1.618175]\n",
      "epoch:16 step:15027 [D loss: 0.162801, acc.: 96.88%] [G loss: 1.768644]\n",
      "epoch:16 step:15028 [D loss: 0.141316, acc.: 98.44%] [G loss: 1.808666]\n",
      "epoch:16 step:15029 [D loss: 0.932831, acc.: 51.56%] [G loss: 1.185768]\n",
      "epoch:16 step:15030 [D loss: 0.906721, acc.: 49.22%] [G loss: 1.335117]\n",
      "epoch:16 step:15031 [D loss: 0.864720, acc.: 44.53%] [G loss: 1.264603]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:16 step:15032 [D loss: 0.922481, acc.: 32.03%] [G loss: 1.203473]\n",
      "epoch:16 step:15033 [D loss: 0.613513, acc.: 66.41%] [G loss: 0.999273]\n",
      "epoch:16 step:15034 [D loss: 0.463576, acc.: 81.25%] [G loss: 1.074361]\n",
      "epoch:16 step:15035 [D loss: 0.397721, acc.: 89.84%] [G loss: 1.138126]\n",
      "epoch:16 step:15036 [D loss: 0.481167, acc.: 82.03%] [G loss: 1.106853]\n",
      "epoch:16 step:15037 [D loss: 0.549051, acc.: 73.44%] [G loss: 0.904013]\n",
      "epoch:16 step:15038 [D loss: 0.392735, acc.: 78.91%] [G loss: 0.736416]\n",
      "epoch:16 step:15039 [D loss: 0.827910, acc.: 44.53%] [G loss: 1.352595]\n",
      "epoch:16 step:15040 [D loss: 0.591591, acc.: 67.97%] [G loss: 1.220329]\n",
      "epoch:16 step:15041 [D loss: 0.703954, acc.: 55.47%] [G loss: 1.181447]\n",
      "epoch:16 step:15042 [D loss: 0.583025, acc.: 65.62%] [G loss: 0.854290]\n",
      "epoch:16 step:15043 [D loss: 0.454494, acc.: 85.16%] [G loss: 1.077313]\n",
      "epoch:16 step:15044 [D loss: 0.331058, acc.: 91.41%] [G loss: 1.313091]\n",
      "epoch:16 step:15045 [D loss: 0.973442, acc.: 28.12%] [G loss: 1.215251]\n",
      "epoch:16 step:15046 [D loss: 0.742761, acc.: 50.78%] [G loss: 1.042006]\n",
      "epoch:16 step:15047 [D loss: 0.746984, acc.: 53.91%] [G loss: 1.351073]\n",
      "epoch:16 step:15048 [D loss: 1.261678, acc.: 13.28%] [G loss: 0.538933]\n",
      "epoch:16 step:15049 [D loss: 0.337955, acc.: 84.38%] [G loss: 1.001642]\n",
      "epoch:16 step:15050 [D loss: 0.438116, acc.: 82.03%] [G loss: 1.186745]\n",
      "epoch:16 step:15051 [D loss: 1.050183, acc.: 18.75%] [G loss: 0.589473]\n",
      "epoch:16 step:15052 [D loss: 1.202677, acc.: 43.75%] [G loss: 1.433225]\n",
      "epoch:16 step:15053 [D loss: 0.808537, acc.: 48.44%] [G loss: 2.473874]\n",
      "epoch:16 step:15054 [D loss: 0.844826, acc.: 38.28%] [G loss: 2.142193]\n",
      "epoch:16 step:15055 [D loss: 0.646730, acc.: 64.06%] [G loss: 1.707279]\n",
      "epoch:16 step:15056 [D loss: 0.586673, acc.: 67.19%] [G loss: 1.529077]\n",
      "epoch:16 step:15057 [D loss: 0.731558, acc.: 57.81%] [G loss: 1.279319]\n",
      "epoch:16 step:15058 [D loss: 0.704583, acc.: 53.91%] [G loss: 1.481069]\n",
      "epoch:16 step:15059 [D loss: 0.657897, acc.: 60.16%] [G loss: 1.280042]\n",
      "epoch:16 step:15060 [D loss: 0.470847, acc.: 82.03%] [G loss: 2.013360]\n",
      "epoch:16 step:15061 [D loss: 0.451421, acc.: 86.72%] [G loss: 1.479942]\n",
      "epoch:16 step:15062 [D loss: 0.451641, acc.: 79.69%] [G loss: 1.554574]\n",
      "epoch:16 step:15063 [D loss: 0.790953, acc.: 61.72%] [G loss: 0.898217]\n",
      "epoch:16 step:15064 [D loss: 0.626383, acc.: 64.84%] [G loss: 0.798273]\n",
      "epoch:16 step:15065 [D loss: 0.655375, acc.: 62.50%] [G loss: 1.081013]\n",
      "epoch:16 step:15066 [D loss: 0.606264, acc.: 69.53%] [G loss: 1.175419]\n",
      "epoch:16 step:15067 [D loss: 0.633081, acc.: 64.06%] [G loss: 1.186278]\n",
      "epoch:16 step:15068 [D loss: 0.750995, acc.: 57.81%] [G loss: 1.246702]\n",
      "epoch:16 step:15069 [D loss: 0.386630, acc.: 86.72%] [G loss: 1.311837]\n",
      "epoch:16 step:15070 [D loss: 0.767752, acc.: 49.22%] [G loss: 1.313270]\n",
      "epoch:16 step:15071 [D loss: 0.594048, acc.: 73.44%] [G loss: 1.149839]\n",
      "epoch:16 step:15072 [D loss: 0.534346, acc.: 70.31%] [G loss: 1.268459]\n",
      "epoch:16 step:15073 [D loss: 0.485660, acc.: 77.34%] [G loss: 1.318580]\n",
      "epoch:16 step:15074 [D loss: 0.484684, acc.: 75.00%] [G loss: 1.135874]\n",
      "epoch:16 step:15075 [D loss: 0.431201, acc.: 85.94%] [G loss: 1.501187]\n",
      "epoch:16 step:15076 [D loss: 0.715078, acc.: 59.38%] [G loss: 1.104698]\n",
      "epoch:16 step:15077 [D loss: 0.570405, acc.: 75.00%] [G loss: 1.158006]\n",
      "epoch:16 step:15078 [D loss: 0.743195, acc.: 47.66%] [G loss: 0.931944]\n",
      "epoch:16 step:15079 [D loss: 0.575681, acc.: 72.66%] [G loss: 1.139723]\n",
      "epoch:16 step:15080 [D loss: 0.388314, acc.: 92.97%] [G loss: 1.008269]\n",
      "epoch:16 step:15081 [D loss: 0.673394, acc.: 61.72%] [G loss: 0.684243]\n",
      "epoch:16 step:15082 [D loss: 0.658906, acc.: 64.06%] [G loss: 1.422973]\n",
      "epoch:16 step:15083 [D loss: 0.489157, acc.: 79.69%] [G loss: 1.521500]\n",
      "epoch:16 step:15084 [D loss: 0.557521, acc.: 71.09%] [G loss: 0.981309]\n",
      "epoch:16 step:15085 [D loss: 0.503696, acc.: 78.12%] [G loss: 1.524113]\n",
      "epoch:16 step:15086 [D loss: 0.618992, acc.: 70.31%] [G loss: 0.961620]\n",
      "epoch:16 step:15087 [D loss: 1.002063, acc.: 32.03%] [G loss: 0.785872]\n",
      "epoch:16 step:15088 [D loss: 0.732315, acc.: 52.34%] [G loss: 0.573551]\n",
      "epoch:16 step:15089 [D loss: 0.596177, acc.: 67.19%] [G loss: 0.769569]\n",
      "epoch:16 step:15090 [D loss: 0.747141, acc.: 50.00%] [G loss: 0.725316]\n",
      "epoch:16 step:15091 [D loss: 0.708937, acc.: 48.44%] [G loss: 0.753513]\n",
      "epoch:16 step:15092 [D loss: 0.708856, acc.: 57.03%] [G loss: 1.076080]\n",
      "epoch:16 step:15093 [D loss: 0.718793, acc.: 55.47%] [G loss: 0.886912]\n",
      "epoch:16 step:15094 [D loss: 0.825354, acc.: 42.19%] [G loss: 1.071104]\n",
      "epoch:16 step:15095 [D loss: 0.839593, acc.: 42.19%] [G loss: 0.910519]\n",
      "epoch:16 step:15096 [D loss: 0.884708, acc.: 35.16%] [G loss: 0.667265]\n",
      "epoch:16 step:15097 [D loss: 0.804090, acc.: 45.31%] [G loss: 1.094774]\n",
      "epoch:16 step:15098 [D loss: 0.724206, acc.: 58.59%] [G loss: 0.875708]\n",
      "epoch:16 step:15099 [D loss: 0.643236, acc.: 66.41%] [G loss: 0.885107]\n",
      "epoch:16 step:15100 [D loss: 0.600705, acc.: 68.75%] [G loss: 0.824843]\n",
      "epoch:16 step:15101 [D loss: 0.737078, acc.: 55.47%] [G loss: 0.801546]\n",
      "epoch:16 step:15102 [D loss: 0.640260, acc.: 64.84%] [G loss: 1.006323]\n",
      "epoch:16 step:15103 [D loss: 0.676395, acc.: 53.91%] [G loss: 0.919885]\n",
      "epoch:16 step:15104 [D loss: 0.680804, acc.: 57.81%] [G loss: 0.965374]\n",
      "epoch:16 step:15105 [D loss: 0.627509, acc.: 64.06%] [G loss: 0.823223]\n",
      "epoch:16 step:15106 [D loss: 0.584841, acc.: 75.00%] [G loss: 0.913155]\n",
      "epoch:16 step:15107 [D loss: 0.590667, acc.: 75.00%] [G loss: 0.877310]\n",
      "epoch:16 step:15108 [D loss: 0.580862, acc.: 70.31%] [G loss: 0.991285]\n",
      "epoch:16 step:15109 [D loss: 0.551547, acc.: 74.22%] [G loss: 1.025979]\n",
      "epoch:16 step:15110 [D loss: 0.340161, acc.: 88.28%] [G loss: 1.015612]\n",
      "epoch:16 step:15111 [D loss: 0.299757, acc.: 89.84%] [G loss: 1.029426]\n",
      "epoch:16 step:15112 [D loss: 0.684533, acc.: 63.28%] [G loss: 1.048598]\n",
      "epoch:16 step:15113 [D loss: 0.673072, acc.: 50.78%] [G loss: 0.927343]\n",
      "epoch:16 step:15114 [D loss: 0.651854, acc.: 61.72%] [G loss: 0.962877]\n",
      "epoch:16 step:15115 [D loss: 0.732431, acc.: 46.09%] [G loss: 0.793375]\n",
      "epoch:16 step:15116 [D loss: 0.523958, acc.: 77.34%] [G loss: 0.984040]\n",
      "epoch:16 step:15117 [D loss: 0.589316, acc.: 72.66%] [G loss: 1.030114]\n",
      "epoch:16 step:15118 [D loss: 0.547609, acc.: 75.78%] [G loss: 0.964857]\n",
      "epoch:16 step:15119 [D loss: 0.735709, acc.: 55.47%] [G loss: 1.030454]\n",
      "epoch:16 step:15120 [D loss: 0.679540, acc.: 58.59%] [G loss: 0.948120]\n",
      "epoch:16 step:15121 [D loss: 0.713906, acc.: 54.69%] [G loss: 0.847518]\n",
      "epoch:16 step:15122 [D loss: 0.706516, acc.: 56.25%] [G loss: 0.860697]\n",
      "epoch:16 step:15123 [D loss: 0.650309, acc.: 60.94%] [G loss: 0.871082]\n",
      "epoch:16 step:15124 [D loss: 0.639502, acc.: 63.28%] [G loss: 0.983922]\n",
      "epoch:16 step:15125 [D loss: 0.438753, acc.: 83.59%] [G loss: 1.073393]\n",
      "epoch:16 step:15126 [D loss: 0.349332, acc.: 89.06%] [G loss: 1.066708]\n",
      "epoch:16 step:15127 [D loss: 0.387679, acc.: 93.75%] [G loss: 1.234699]\n",
      "epoch:16 step:15128 [D loss: 0.557883, acc.: 76.56%] [G loss: 1.043559]\n",
      "epoch:16 step:15129 [D loss: 0.635641, acc.: 64.06%] [G loss: 0.917603]\n",
      "epoch:16 step:15130 [D loss: 0.581674, acc.: 68.75%] [G loss: 1.122092]\n",
      "epoch:16 step:15131 [D loss: 0.709709, acc.: 52.34%] [G loss: 0.904258]\n",
      "epoch:16 step:15132 [D loss: 0.434830, acc.: 78.91%] [G loss: 1.055237]\n",
      "epoch:16 step:15133 [D loss: 0.358527, acc.: 88.28%] [G loss: 1.026599]\n",
      "epoch:16 step:15134 [D loss: 0.509897, acc.: 82.81%] [G loss: 1.136115]\n",
      "epoch:16 step:15135 [D loss: 0.362825, acc.: 80.47%] [G loss: 1.021183]\n",
      "epoch:16 step:15136 [D loss: 0.447596, acc.: 84.38%] [G loss: 1.243890]\n",
      "epoch:16 step:15137 [D loss: 0.269238, acc.: 93.75%] [G loss: 1.365495]\n",
      "epoch:16 step:15138 [D loss: 0.396918, acc.: 88.28%] [G loss: 1.101805]\n",
      "epoch:16 step:15139 [D loss: 0.563730, acc.: 73.44%] [G loss: 1.212238]\n",
      "epoch:16 step:15140 [D loss: 0.804709, acc.: 46.09%] [G loss: 1.282731]\n",
      "epoch:16 step:15141 [D loss: 0.428522, acc.: 71.88%] [G loss: 1.239029]\n",
      "epoch:16 step:15142 [D loss: 0.179338, acc.: 96.88%] [G loss: 1.413649]\n",
      "epoch:16 step:15143 [D loss: 0.273200, acc.: 98.44%] [G loss: 1.383787]\n",
      "epoch:16 step:15144 [D loss: 0.440800, acc.: 83.59%] [G loss: 1.163069]\n",
      "epoch:16 step:15145 [D loss: 0.743555, acc.: 57.81%] [G loss: 1.177244]\n",
      "epoch:16 step:15146 [D loss: 0.733817, acc.: 46.09%] [G loss: 1.091337]\n",
      "epoch:16 step:15147 [D loss: 0.594632, acc.: 68.75%] [G loss: 1.250502]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:16 step:15148 [D loss: 0.848673, acc.: 40.62%] [G loss: 0.793629]\n",
      "epoch:16 step:15149 [D loss: 0.756131, acc.: 52.34%] [G loss: 0.767485]\n",
      "epoch:16 step:15150 [D loss: 0.673984, acc.: 60.16%] [G loss: 0.810387]\n",
      "epoch:16 step:15151 [D loss: 0.798540, acc.: 46.88%] [G loss: 0.755333]\n",
      "epoch:16 step:15152 [D loss: 1.156691, acc.: 45.31%] [G loss: 1.049949]\n",
      "epoch:16 step:15153 [D loss: 0.651198, acc.: 63.28%] [G loss: 0.994515]\n",
      "epoch:16 step:15154 [D loss: 0.562562, acc.: 73.44%] [G loss: 1.251822]\n",
      "epoch:16 step:15155 [D loss: 0.559466, acc.: 71.88%] [G loss: 0.952402]\n",
      "epoch:16 step:15156 [D loss: 0.513380, acc.: 75.00%] [G loss: 1.065722]\n",
      "epoch:16 step:15157 [D loss: 0.724491, acc.: 53.91%] [G loss: 0.793522]\n",
      "epoch:16 step:15158 [D loss: 0.889094, acc.: 35.94%] [G loss: 0.883929]\n",
      "epoch:16 step:15159 [D loss: 1.380439, acc.: 13.28%] [G loss: 1.032277]\n",
      "epoch:16 step:15160 [D loss: 0.793566, acc.: 47.66%] [G loss: 1.160296]\n",
      "epoch:16 step:15161 [D loss: 0.778762, acc.: 51.56%] [G loss: 1.131111]\n",
      "epoch:16 step:15162 [D loss: 0.719451, acc.: 54.69%] [G loss: 0.967963]\n",
      "epoch:16 step:15163 [D loss: 0.813132, acc.: 35.16%] [G loss: 1.044805]\n",
      "epoch:16 step:15164 [D loss: 0.727228, acc.: 53.12%] [G loss: 1.290663]\n",
      "epoch:16 step:15165 [D loss: 0.774453, acc.: 45.31%] [G loss: 0.969649]\n",
      "epoch:16 step:15166 [D loss: 0.656799, acc.: 63.28%] [G loss: 0.993006]\n",
      "epoch:16 step:15167 [D loss: 0.758015, acc.: 53.91%] [G loss: 0.931438]\n",
      "epoch:16 step:15168 [D loss: 0.621183, acc.: 64.84%] [G loss: 0.918422]\n",
      "epoch:16 step:15169 [D loss: 0.726142, acc.: 49.22%] [G loss: 1.012170]\n",
      "epoch:16 step:15170 [D loss: 0.655819, acc.: 58.59%] [G loss: 1.010493]\n",
      "epoch:16 step:15171 [D loss: 0.733370, acc.: 50.78%] [G loss: 1.155219]\n",
      "epoch:16 step:15172 [D loss: 0.675124, acc.: 58.59%] [G loss: 0.847926]\n",
      "epoch:16 step:15173 [D loss: 0.664748, acc.: 57.81%] [G loss: 1.100296]\n",
      "epoch:16 step:15174 [D loss: 0.569132, acc.: 75.00%] [G loss: 0.964019]\n",
      "epoch:16 step:15175 [D loss: 0.652866, acc.: 60.94%] [G loss: 1.061053]\n",
      "epoch:16 step:15176 [D loss: 0.503636, acc.: 77.34%] [G loss: 1.159434]\n",
      "epoch:16 step:15177 [D loss: 0.663967, acc.: 57.81%] [G loss: 0.985794]\n",
      "epoch:16 step:15178 [D loss: 0.596513, acc.: 60.16%] [G loss: 0.978712]\n",
      "epoch:16 step:15179 [D loss: 0.607920, acc.: 62.50%] [G loss: 0.986049]\n",
      "epoch:16 step:15180 [D loss: 0.589018, acc.: 71.88%] [G loss: 1.117402]\n",
      "epoch:16 step:15181 [D loss: 0.519252, acc.: 81.25%] [G loss: 0.856937]\n",
      "epoch:16 step:15182 [D loss: 0.555486, acc.: 77.34%] [G loss: 0.938717]\n",
      "epoch:16 step:15183 [D loss: 0.609883, acc.: 61.72%] [G loss: 1.412882]\n",
      "epoch:16 step:15184 [D loss: 0.447747, acc.: 85.16%] [G loss: 1.175478]\n",
      "epoch:16 step:15185 [D loss: 0.563492, acc.: 76.56%] [G loss: 1.042427]\n",
      "epoch:16 step:15186 [D loss: 0.518559, acc.: 70.31%] [G loss: 1.027220]\n",
      "epoch:16 step:15187 [D loss: 0.497755, acc.: 77.34%] [G loss: 1.380258]\n",
      "epoch:16 step:15188 [D loss: 0.569941, acc.: 75.00%] [G loss: 0.840000]\n",
      "epoch:16 step:15189 [D loss: 0.474757, acc.: 84.38%] [G loss: 0.903820]\n",
      "epoch:16 step:15190 [D loss: 0.522453, acc.: 79.69%] [G loss: 0.926462]\n",
      "epoch:16 step:15191 [D loss: 0.706987, acc.: 55.47%] [G loss: 0.998013]\n",
      "epoch:16 step:15192 [D loss: 1.057270, acc.: 39.84%] [G loss: 0.764090]\n",
      "epoch:16 step:15193 [D loss: 0.581334, acc.: 68.75%] [G loss: 0.681152]\n",
      "epoch:16 step:15194 [D loss: 0.650950, acc.: 60.94%] [G loss: 0.888042]\n",
      "epoch:16 step:15195 [D loss: 0.675375, acc.: 57.81%] [G loss: 0.939435]\n",
      "epoch:16 step:15196 [D loss: 0.476605, acc.: 82.03%] [G loss: 0.990944]\n",
      "epoch:16 step:15197 [D loss: 0.741584, acc.: 53.91%] [G loss: 1.069421]\n",
      "epoch:16 step:15198 [D loss: 0.430063, acc.: 87.50%] [G loss: 0.985612]\n",
      "epoch:16 step:15199 [D loss: 0.408144, acc.: 89.06%] [G loss: 1.122021]\n",
      "epoch:16 step:15200 [D loss: 0.499122, acc.: 78.12%] [G loss: 1.115764]\n",
      "##############\n",
      "[3.90703055 2.35570033 6.70326893 5.45373261 4.42931599 6.50319394\n",
      " 5.38126882 5.76694478 5.74771235 4.80890753]\n",
      "##########\n",
      "epoch:16 step:15201 [D loss: 0.443565, acc.: 87.50%] [G loss: 1.179444]\n",
      "epoch:16 step:15202 [D loss: 0.860546, acc.: 52.34%] [G loss: 0.947581]\n",
      "epoch:16 step:15203 [D loss: 0.895228, acc.: 28.91%] [G loss: 1.081400]\n",
      "epoch:16 step:15204 [D loss: 0.711647, acc.: 57.81%] [G loss: 0.936035]\n",
      "epoch:16 step:15205 [D loss: 0.647701, acc.: 61.72%] [G loss: 1.001213]\n",
      "epoch:16 step:15206 [D loss: 0.726199, acc.: 50.78%] [G loss: 1.126996]\n",
      "epoch:16 step:15207 [D loss: 0.778971, acc.: 47.66%] [G loss: 1.152555]\n",
      "epoch:16 step:15208 [D loss: 0.795570, acc.: 50.00%] [G loss: 0.679064]\n",
      "epoch:16 step:15209 [D loss: 0.618950, acc.: 68.75%] [G loss: 0.938856]\n",
      "epoch:16 step:15210 [D loss: 0.697901, acc.: 57.81%] [G loss: 0.794391]\n",
      "epoch:16 step:15211 [D loss: 0.548954, acc.: 74.22%] [G loss: 0.912815]\n",
      "epoch:16 step:15212 [D loss: 0.426538, acc.: 75.78%] [G loss: 1.074745]\n",
      "epoch:16 step:15213 [D loss: 0.344458, acc.: 87.50%] [G loss: 1.127353]\n",
      "epoch:16 step:15214 [D loss: 0.529746, acc.: 75.78%] [G loss: 1.217144]\n",
      "epoch:16 step:15215 [D loss: 0.500185, acc.: 82.81%] [G loss: 1.122859]\n",
      "epoch:16 step:15216 [D loss: 0.659837, acc.: 60.94%] [G loss: 1.149900]\n",
      "epoch:16 step:15217 [D loss: 0.590453, acc.: 71.09%] [G loss: 1.028027]\n",
      "epoch:16 step:15218 [D loss: 0.792922, acc.: 52.34%] [G loss: 1.181599]\n",
      "epoch:16 step:15219 [D loss: 0.583533, acc.: 71.09%] [G loss: 1.055092]\n",
      "epoch:16 step:15220 [D loss: 0.726036, acc.: 54.69%] [G loss: 1.038845]\n",
      "epoch:16 step:15221 [D loss: 0.603295, acc.: 70.31%] [G loss: 1.067690]\n",
      "epoch:16 step:15222 [D loss: 0.369713, acc.: 75.78%] [G loss: 1.168170]\n",
      "epoch:16 step:15223 [D loss: 0.325363, acc.: 91.41%] [G loss: 1.262902]\n",
      "epoch:16 step:15224 [D loss: 0.230025, acc.: 94.53%] [G loss: 1.288674]\n",
      "epoch:16 step:15225 [D loss: 0.622563, acc.: 66.41%] [G loss: 1.455546]\n",
      "epoch:16 step:15226 [D loss: 0.397869, acc.: 88.28%] [G loss: 1.079941]\n",
      "epoch:16 step:15227 [D loss: 0.400638, acc.: 89.84%] [G loss: 1.311218]\n",
      "epoch:16 step:15228 [D loss: 0.616113, acc.: 67.19%] [G loss: 1.021127]\n",
      "epoch:16 step:15229 [D loss: 0.415185, acc.: 87.50%] [G loss: 1.336027]\n",
      "epoch:16 step:15230 [D loss: 0.424578, acc.: 85.94%] [G loss: 1.317310]\n",
      "epoch:16 step:15231 [D loss: 0.652706, acc.: 61.72%] [G loss: 1.187691]\n",
      "epoch:16 step:15232 [D loss: 0.618109, acc.: 65.62%] [G loss: 1.054212]\n",
      "epoch:16 step:15233 [D loss: 0.745191, acc.: 56.25%] [G loss: 1.030218]\n",
      "epoch:16 step:15234 [D loss: 0.584172, acc.: 65.62%] [G loss: 0.781319]\n",
      "epoch:16 step:15235 [D loss: 0.715252, acc.: 54.69%] [G loss: 0.745291]\n",
      "epoch:16 step:15236 [D loss: 0.678418, acc.: 55.47%] [G loss: 0.805749]\n",
      "epoch:16 step:15237 [D loss: 0.854362, acc.: 39.84%] [G loss: 0.870996]\n",
      "epoch:16 step:15238 [D loss: 0.698168, acc.: 59.38%] [G loss: 0.742059]\n",
      "epoch:16 step:15239 [D loss: 0.808770, acc.: 45.31%] [G loss: 0.765198]\n",
      "epoch:16 step:15240 [D loss: 0.747449, acc.: 47.66%] [G loss: 0.513331]\n",
      "epoch:16 step:15241 [D loss: 0.564064, acc.: 76.56%] [G loss: 0.903682]\n",
      "epoch:16 step:15242 [D loss: 0.724703, acc.: 50.00%] [G loss: 0.808369]\n",
      "epoch:16 step:15243 [D loss: 0.528961, acc.: 73.44%] [G loss: 1.025732]\n",
      "epoch:16 step:15244 [D loss: 0.658842, acc.: 60.16%] [G loss: 1.008434]\n",
      "epoch:16 step:15245 [D loss: 1.191617, acc.: 25.78%] [G loss: 0.990146]\n",
      "epoch:16 step:15246 [D loss: 0.604952, acc.: 70.31%] [G loss: 0.988788]\n",
      "epoch:16 step:15247 [D loss: 0.485303, acc.: 82.03%] [G loss: 0.876550]\n",
      "epoch:16 step:15248 [D loss: 0.309004, acc.: 88.28%] [G loss: 0.955187]\n",
      "epoch:16 step:15249 [D loss: 0.499981, acc.: 82.81%] [G loss: 0.858645]\n",
      "epoch:16 step:15250 [D loss: 0.723188, acc.: 55.47%] [G loss: 0.951440]\n",
      "epoch:16 step:15251 [D loss: 0.342768, acc.: 83.59%] [G loss: 1.136275]\n",
      "epoch:16 step:15252 [D loss: 0.436413, acc.: 77.34%] [G loss: 0.734598]\n",
      "epoch:16 step:15253 [D loss: 0.289741, acc.: 96.88%] [G loss: 0.800952]\n",
      "epoch:16 step:15254 [D loss: 0.621607, acc.: 65.62%] [G loss: 0.398929]\n",
      "epoch:16 step:15255 [D loss: 1.216446, acc.: 14.84%] [G loss: 0.968315]\n",
      "epoch:16 step:15256 [D loss: 0.796324, acc.: 54.69%] [G loss: 0.940647]\n",
      "epoch:16 step:15257 [D loss: 0.616467, acc.: 67.97%] [G loss: 1.031698]\n",
      "epoch:16 step:15258 [D loss: 0.924954, acc.: 31.25%] [G loss: 1.293824]\n",
      "epoch:16 step:15259 [D loss: 0.639804, acc.: 55.47%] [G loss: 1.164469]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:16 step:15260 [D loss: 0.840183, acc.: 36.72%] [G loss: 1.725467]\n",
      "epoch:16 step:15261 [D loss: 0.569280, acc.: 67.97%] [G loss: 1.452355]\n",
      "epoch:16 step:15262 [D loss: 0.866440, acc.: 39.84%] [G loss: 1.272278]\n",
      "epoch:16 step:15263 [D loss: 0.566137, acc.: 66.41%] [G loss: 1.262604]\n",
      "epoch:16 step:15264 [D loss: 0.505474, acc.: 73.44%] [G loss: 1.489003]\n",
      "epoch:16 step:15265 [D loss: 0.539502, acc.: 74.22%] [G loss: 1.676726]\n",
      "epoch:16 step:15266 [D loss: 0.564464, acc.: 73.44%] [G loss: 1.376356]\n",
      "epoch:16 step:15267 [D loss: 0.542893, acc.: 75.78%] [G loss: 1.185199]\n",
      "epoch:16 step:15268 [D loss: 0.507577, acc.: 79.69%] [G loss: 1.127189]\n",
      "epoch:16 step:15269 [D loss: 0.571868, acc.: 69.53%] [G loss: 1.395555]\n",
      "epoch:16 step:15270 [D loss: 0.817935, acc.: 56.25%] [G loss: 1.186723]\n",
      "epoch:16 step:15271 [D loss: 0.409442, acc.: 89.06%] [G loss: 1.120664]\n",
      "epoch:16 step:15272 [D loss: 0.642056, acc.: 64.84%] [G loss: 1.301042]\n",
      "epoch:16 step:15273 [D loss: 0.719876, acc.: 57.81%] [G loss: 1.093734]\n",
      "epoch:16 step:15274 [D loss: 0.579369, acc.: 73.44%] [G loss: 0.990870]\n",
      "epoch:16 step:15275 [D loss: 0.627335, acc.: 61.72%] [G loss: 1.082029]\n",
      "epoch:16 step:15276 [D loss: 0.631332, acc.: 67.19%] [G loss: 0.912823]\n",
      "epoch:16 step:15277 [D loss: 0.628885, acc.: 65.62%] [G loss: 1.103719]\n",
      "epoch:16 step:15278 [D loss: 0.604823, acc.: 70.31%] [G loss: 0.968460]\n",
      "epoch:16 step:15279 [D loss: 0.626761, acc.: 65.62%] [G loss: 0.956728]\n",
      "epoch:16 step:15280 [D loss: 0.538292, acc.: 77.34%] [G loss: 1.093012]\n",
      "epoch:16 step:15281 [D loss: 0.470955, acc.: 75.00%] [G loss: 1.067621]\n",
      "epoch:16 step:15282 [D loss: 0.636482, acc.: 65.62%] [G loss: 0.778906]\n",
      "epoch:16 step:15283 [D loss: 0.631760, acc.: 64.84%] [G loss: 0.926362]\n",
      "epoch:16 step:15284 [D loss: 0.752813, acc.: 57.03%] [G loss: 0.938640]\n",
      "epoch:16 step:15285 [D loss: 0.537674, acc.: 73.44%] [G loss: 1.021170]\n",
      "epoch:16 step:15286 [D loss: 0.721034, acc.: 54.69%] [G loss: 0.907456]\n",
      "epoch:16 step:15287 [D loss: 0.696556, acc.: 56.25%] [G loss: 1.168078]\n",
      "epoch:16 step:15288 [D loss: 0.683273, acc.: 60.94%] [G loss: 1.030917]\n",
      "epoch:16 step:15289 [D loss: 0.541438, acc.: 72.66%] [G loss: 1.078961]\n",
      "epoch:16 step:15290 [D loss: 0.520352, acc.: 75.00%] [G loss: 1.019654]\n",
      "epoch:16 step:15291 [D loss: 0.697645, acc.: 58.59%] [G loss: 1.179350]\n",
      "epoch:16 step:15292 [D loss: 0.508844, acc.: 76.56%] [G loss: 1.416024]\n",
      "epoch:16 step:15293 [D loss: 0.700230, acc.: 61.72%] [G loss: 1.201419]\n",
      "epoch:16 step:15294 [D loss: 0.727000, acc.: 61.72%] [G loss: 1.171999]\n",
      "epoch:16 step:15295 [D loss: 0.576350, acc.: 70.31%] [G loss: 0.998500]\n",
      "epoch:16 step:15296 [D loss: 0.694159, acc.: 55.47%] [G loss: 1.088142]\n",
      "epoch:16 step:15297 [D loss: 0.715891, acc.: 48.44%] [G loss: 0.822740]\n",
      "epoch:16 step:15298 [D loss: 0.725529, acc.: 51.56%] [G loss: 0.875305]\n",
      "epoch:16 step:15299 [D loss: 0.625857, acc.: 60.94%] [G loss: 0.973841]\n",
      "epoch:16 step:15300 [D loss: 0.711929, acc.: 50.00%] [G loss: 0.967188]\n",
      "epoch:16 step:15301 [D loss: 0.590889, acc.: 67.97%] [G loss: 0.898858]\n",
      "epoch:16 step:15302 [D loss: 0.736996, acc.: 53.12%] [G loss: 0.917419]\n",
      "epoch:16 step:15303 [D loss: 0.725826, acc.: 46.88%] [G loss: 0.834854]\n",
      "epoch:16 step:15304 [D loss: 0.509215, acc.: 73.44%] [G loss: 0.890332]\n",
      "epoch:16 step:15305 [D loss: 0.582771, acc.: 68.75%] [G loss: 0.906296]\n",
      "epoch:16 step:15306 [D loss: 0.325876, acc.: 88.28%] [G loss: 1.128893]\n",
      "epoch:16 step:15307 [D loss: 0.541029, acc.: 75.00%] [G loss: 1.084648]\n",
      "epoch:16 step:15308 [D loss: 0.616309, acc.: 71.88%] [G loss: 0.993156]\n",
      "epoch:16 step:15309 [D loss: 0.719322, acc.: 57.81%] [G loss: 0.983456]\n",
      "epoch:16 step:15310 [D loss: 0.670790, acc.: 57.81%] [G loss: 0.945262]\n",
      "epoch:16 step:15311 [D loss: 0.676773, acc.: 62.50%] [G loss: 1.040594]\n",
      "epoch:16 step:15312 [D loss: 0.672206, acc.: 60.16%] [G loss: 0.990195]\n",
      "epoch:16 step:15313 [D loss: 0.710043, acc.: 58.59%] [G loss: 1.011489]\n",
      "epoch:16 step:15314 [D loss: 0.584339, acc.: 70.31%] [G loss: 0.957628]\n",
      "epoch:16 step:15315 [D loss: 0.677277, acc.: 60.94%] [G loss: 0.845930]\n",
      "epoch:16 step:15316 [D loss: 0.620063, acc.: 66.41%] [G loss: 0.896943]\n",
      "epoch:16 step:15317 [D loss: 0.685488, acc.: 57.03%] [G loss: 0.810448]\n",
      "epoch:16 step:15318 [D loss: 0.732636, acc.: 49.22%] [G loss: 0.876069]\n",
      "epoch:16 step:15319 [D loss: 0.486822, acc.: 77.34%] [G loss: 0.845422]\n",
      "epoch:16 step:15320 [D loss: 0.456626, acc.: 82.81%] [G loss: 1.049806]\n",
      "epoch:16 step:15321 [D loss: 0.721405, acc.: 52.34%] [G loss: 0.935497]\n",
      "epoch:16 step:15322 [D loss: 0.728814, acc.: 50.00%] [G loss: 1.002857]\n",
      "epoch:16 step:15323 [D loss: 0.633221, acc.: 67.97%] [G loss: 0.657972]\n",
      "epoch:16 step:15324 [D loss: 0.702914, acc.: 50.00%] [G loss: 0.652463]\n",
      "epoch:16 step:15325 [D loss: 0.469577, acc.: 76.56%] [G loss: 1.030305]\n",
      "epoch:16 step:15326 [D loss: 0.470667, acc.: 72.66%] [G loss: 1.019379]\n",
      "epoch:16 step:15327 [D loss: 0.674546, acc.: 54.69%] [G loss: 0.833900]\n",
      "epoch:16 step:15328 [D loss: 0.397171, acc.: 88.28%] [G loss: 1.011926]\n",
      "epoch:16 step:15329 [D loss: 0.539877, acc.: 75.78%] [G loss: 0.985581]\n",
      "epoch:16 step:15330 [D loss: 0.632866, acc.: 60.94%] [G loss: 1.120811]\n",
      "epoch:16 step:15331 [D loss: 0.607419, acc.: 66.41%] [G loss: 1.107124]\n",
      "epoch:16 step:15332 [D loss: 0.664041, acc.: 60.16%] [G loss: 1.001801]\n",
      "epoch:16 step:15333 [D loss: 0.877940, acc.: 26.56%] [G loss: 0.915873]\n",
      "epoch:16 step:15334 [D loss: 0.488832, acc.: 82.81%] [G loss: 1.118609]\n",
      "epoch:16 step:15335 [D loss: 0.594271, acc.: 62.50%] [G loss: 1.232800]\n",
      "epoch:16 step:15336 [D loss: 0.394184, acc.: 91.41%] [G loss: 1.125470]\n",
      "epoch:16 step:15337 [D loss: 0.422268, acc.: 86.72%] [G loss: 1.316762]\n",
      "epoch:16 step:15338 [D loss: 0.221164, acc.: 96.88%] [G loss: 1.330765]\n",
      "epoch:16 step:15339 [D loss: 0.208764, acc.: 97.66%] [G loss: 0.680945]\n",
      "epoch:16 step:15340 [D loss: 0.769735, acc.: 53.91%] [G loss: 0.486310]\n",
      "epoch:16 step:15341 [D loss: 0.728390, acc.: 57.81%] [G loss: 1.177819]\n",
      "epoch:16 step:15342 [D loss: 0.550099, acc.: 75.78%] [G loss: 1.100367]\n",
      "epoch:16 step:15343 [D loss: 0.662501, acc.: 57.81%] [G loss: 1.269773]\n",
      "epoch:16 step:15344 [D loss: 0.573798, acc.: 69.53%] [G loss: 0.553719]\n",
      "epoch:16 step:15345 [D loss: 0.567246, acc.: 75.78%] [G loss: 1.113556]\n",
      "epoch:16 step:15346 [D loss: 0.539753, acc.: 71.88%] [G loss: 1.178325]\n",
      "epoch:16 step:15347 [D loss: 0.644692, acc.: 63.28%] [G loss: 1.119606]\n",
      "epoch:16 step:15348 [D loss: 0.604866, acc.: 65.62%] [G loss: 1.097857]\n",
      "epoch:16 step:15349 [D loss: 0.603990, acc.: 74.22%] [G loss: 1.149206]\n",
      "epoch:16 step:15350 [D loss: 0.521269, acc.: 75.78%] [G loss: 1.090851]\n",
      "epoch:16 step:15351 [D loss: 0.500121, acc.: 79.69%] [G loss: 0.944539]\n",
      "epoch:16 step:15352 [D loss: 0.635887, acc.: 68.75%] [G loss: 0.723045]\n",
      "epoch:16 step:15353 [D loss: 0.535393, acc.: 77.34%] [G loss: 1.188249]\n",
      "epoch:16 step:15354 [D loss: 0.563532, acc.: 69.53%] [G loss: 0.719606]\n",
      "epoch:16 step:15355 [D loss: 0.580968, acc.: 72.66%] [G loss: 1.022366]\n",
      "epoch:16 step:15356 [D loss: 0.572892, acc.: 68.75%] [G loss: 0.966526]\n",
      "epoch:16 step:15357 [D loss: 0.429604, acc.: 89.06%] [G loss: 0.846978]\n",
      "epoch:16 step:15358 [D loss: 0.306193, acc.: 88.28%] [G loss: 0.929805]\n",
      "epoch:16 step:15359 [D loss: 1.209310, acc.: 26.56%] [G loss: 0.811619]\n",
      "epoch:16 step:15360 [D loss: 0.977882, acc.: 28.91%] [G loss: 0.972146]\n",
      "epoch:16 step:15361 [D loss: 0.739153, acc.: 50.78%] [G loss: 1.031255]\n",
      "epoch:16 step:15362 [D loss: 0.550573, acc.: 71.09%] [G loss: 0.798843]\n",
      "epoch:16 step:15363 [D loss: 0.498150, acc.: 80.47%] [G loss: 1.176650]\n",
      "epoch:16 step:15364 [D loss: 0.530482, acc.: 75.00%] [G loss: 1.267785]\n",
      "epoch:16 step:15365 [D loss: 0.755425, acc.: 49.22%] [G loss: 1.198490]\n",
      "epoch:16 step:15366 [D loss: 0.643696, acc.: 65.62%] [G loss: 0.915662]\n",
      "epoch:16 step:15367 [D loss: 0.701746, acc.: 53.12%] [G loss: 0.877392]\n",
      "epoch:16 step:15368 [D loss: 0.805322, acc.: 45.31%] [G loss: 0.860720]\n",
      "epoch:16 step:15369 [D loss: 0.524690, acc.: 75.00%] [G loss: 1.089851]\n",
      "epoch:16 step:15370 [D loss: 0.474598, acc.: 75.78%] [G loss: 1.086592]\n",
      "epoch:16 step:15371 [D loss: 0.701941, acc.: 56.25%] [G loss: 1.270473]\n",
      "epoch:16 step:15372 [D loss: 0.445118, acc.: 84.38%] [G loss: 1.092429]\n",
      "epoch:16 step:15373 [D loss: 0.437335, acc.: 91.41%] [G loss: 1.140767]\n",
      "epoch:16 step:15374 [D loss: 0.666908, acc.: 58.59%] [G loss: 0.876112]\n",
      "epoch:16 step:15375 [D loss: 0.839338, acc.: 32.03%] [G loss: 1.039016]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:16 step:15376 [D loss: 0.748512, acc.: 41.41%] [G loss: 1.147024]\n",
      "epoch:16 step:15377 [D loss: 0.665859, acc.: 62.50%] [G loss: 1.074498]\n",
      "epoch:16 step:15378 [D loss: 0.592357, acc.: 72.66%] [G loss: 1.062629]\n",
      "epoch:16 step:15379 [D loss: 0.612699, acc.: 72.66%] [G loss: 1.030482]\n",
      "epoch:16 step:15380 [D loss: 0.665807, acc.: 56.25%] [G loss: 1.039793]\n",
      "epoch:16 step:15381 [D loss: 0.687705, acc.: 56.25%] [G loss: 1.012248]\n",
      "epoch:16 step:15382 [D loss: 0.633210, acc.: 60.16%] [G loss: 0.845698]\n",
      "epoch:16 step:15383 [D loss: 0.694450, acc.: 55.47%] [G loss: 0.869050]\n",
      "epoch:16 step:15384 [D loss: 0.847443, acc.: 34.38%] [G loss: 0.893856]\n",
      "epoch:16 step:15385 [D loss: 0.695143, acc.: 52.34%] [G loss: 1.037042]\n",
      "epoch:16 step:15386 [D loss: 0.724345, acc.: 50.00%] [G loss: 0.814962]\n",
      "epoch:16 step:15387 [D loss: 0.816759, acc.: 44.53%] [G loss: 0.960325]\n",
      "epoch:16 step:15388 [D loss: 0.353690, acc.: 88.28%] [G loss: 0.903435]\n",
      "epoch:16 step:15389 [D loss: 0.316818, acc.: 83.59%] [G loss: 0.909390]\n",
      "epoch:16 step:15390 [D loss: 0.244293, acc.: 96.88%] [G loss: 1.282224]\n",
      "epoch:16 step:15391 [D loss: 0.240799, acc.: 93.75%] [G loss: 1.316810]\n",
      "epoch:16 step:15392 [D loss: 0.504183, acc.: 79.69%] [G loss: 1.302766]\n",
      "epoch:16 step:15393 [D loss: 0.509586, acc.: 76.56%] [G loss: 1.344303]\n",
      "epoch:16 step:15394 [D loss: 0.261528, acc.: 92.19%] [G loss: 0.827666]\n",
      "epoch:16 step:15395 [D loss: 0.348500, acc.: 92.97%] [G loss: 0.892361]\n",
      "epoch:16 step:15396 [D loss: 0.293144, acc.: 97.66%] [G loss: 0.798118]\n",
      "epoch:16 step:15397 [D loss: 0.457597, acc.: 69.53%] [G loss: 0.788475]\n",
      "epoch:16 step:15398 [D loss: 0.182206, acc.: 98.44%] [G loss: 1.682657]\n",
      "epoch:16 step:15399 [D loss: 0.429009, acc.: 72.66%] [G loss: 1.891817]\n",
      "epoch:16 step:15400 [D loss: 0.321978, acc.: 96.88%] [G loss: 1.950641]\n",
      "##############\n",
      "[3.646265   2.64585323 6.85774554 5.26441366 4.66266943 6.25203002\n",
      " 5.27692638 5.92944557 5.44427692 4.60037768]\n",
      "##########\n",
      "epoch:16 step:15401 [D loss: 0.177771, acc.: 99.22%] [G loss: 1.765170]\n",
      "epoch:16 step:15402 [D loss: 0.472220, acc.: 79.69%] [G loss: 1.919858]\n",
      "epoch:16 step:15403 [D loss: 0.990220, acc.: 50.00%] [G loss: 1.122932]\n",
      "epoch:16 step:15404 [D loss: 0.327288, acc.: 91.41%] [G loss: 1.278528]\n",
      "epoch:16 step:15405 [D loss: 0.491183, acc.: 78.12%] [G loss: 1.241548]\n",
      "epoch:16 step:15406 [D loss: 0.325253, acc.: 96.09%] [G loss: 1.516692]\n",
      "epoch:16 step:15407 [D loss: 0.520361, acc.: 75.00%] [G loss: 1.259101]\n",
      "epoch:16 step:15408 [D loss: 0.312144, acc.: 95.31%] [G loss: 1.215760]\n",
      "epoch:16 step:15409 [D loss: 0.601692, acc.: 57.03%] [G loss: 1.548064]\n",
      "epoch:16 step:15410 [D loss: 0.215315, acc.: 95.31%] [G loss: 1.782685]\n",
      "epoch:16 step:15411 [D loss: 0.730609, acc.: 61.72%] [G loss: 1.124642]\n",
      "epoch:16 step:15412 [D loss: 0.520293, acc.: 72.66%] [G loss: 2.504654]\n",
      "epoch:16 step:15413 [D loss: 1.087760, acc.: 39.84%] [G loss: 1.945330]\n",
      "epoch:16 step:15414 [D loss: 1.098886, acc.: 46.09%] [G loss: 1.497439]\n",
      "epoch:16 step:15415 [D loss: 0.887296, acc.: 42.97%] [G loss: 0.573366]\n",
      "epoch:16 step:15416 [D loss: 0.543027, acc.: 69.53%] [G loss: 0.989926]\n",
      "epoch:16 step:15417 [D loss: 0.547248, acc.: 75.00%] [G loss: 1.525124]\n",
      "epoch:16 step:15418 [D loss: 0.981851, acc.: 35.94%] [G loss: 1.026987]\n",
      "epoch:16 step:15419 [D loss: 0.579270, acc.: 73.44%] [G loss: 2.153431]\n",
      "epoch:16 step:15420 [D loss: 0.438082, acc.: 78.91%] [G loss: 1.140477]\n",
      "epoch:16 step:15421 [D loss: 0.654825, acc.: 64.84%] [G loss: 1.118566]\n",
      "epoch:16 step:15422 [D loss: 1.026317, acc.: 52.34%] [G loss: 1.337536]\n",
      "epoch:16 step:15423 [D loss: 0.935178, acc.: 42.97%] [G loss: 1.363729]\n",
      "epoch:16 step:15424 [D loss: 0.892192, acc.: 40.62%] [G loss: 1.622641]\n",
      "epoch:16 step:15425 [D loss: 0.808970, acc.: 42.97%] [G loss: 1.895299]\n",
      "epoch:16 step:15426 [D loss: 0.849864, acc.: 52.34%] [G loss: 1.980477]\n",
      "epoch:16 step:15427 [D loss: 0.673259, acc.: 56.25%] [G loss: 2.163988]\n",
      "epoch:16 step:15428 [D loss: 0.694390, acc.: 57.03%] [G loss: 1.641740]\n",
      "epoch:16 step:15429 [D loss: 0.703731, acc.: 52.34%] [G loss: 2.142364]\n",
      "epoch:16 step:15430 [D loss: 0.785465, acc.: 55.47%] [G loss: 1.723299]\n",
      "epoch:16 step:15431 [D loss: 0.519375, acc.: 72.66%] [G loss: 1.317210]\n",
      "epoch:16 step:15432 [D loss: 0.520047, acc.: 75.00%] [G loss: 1.630011]\n",
      "epoch:16 step:15433 [D loss: 0.444842, acc.: 83.59%] [G loss: 1.282694]\n",
      "epoch:16 step:15434 [D loss: 0.449292, acc.: 82.03%] [G loss: 1.520673]\n",
      "epoch:16 step:15435 [D loss: 0.541594, acc.: 80.47%] [G loss: 1.222803]\n",
      "epoch:16 step:15436 [D loss: 0.582325, acc.: 71.88%] [G loss: 1.256281]\n",
      "epoch:16 step:15437 [D loss: 0.492188, acc.: 75.78%] [G loss: 1.249369]\n",
      "epoch:16 step:15438 [D loss: 0.506472, acc.: 72.66%] [G loss: 1.170771]\n",
      "epoch:16 step:15439 [D loss: 0.491300, acc.: 75.78%] [G loss: 1.095628]\n",
      "epoch:16 step:15440 [D loss: 0.519051, acc.: 71.88%] [G loss: 1.025965]\n",
      "epoch:16 step:15441 [D loss: 0.545951, acc.: 73.44%] [G loss: 1.365992]\n",
      "epoch:16 step:15442 [D loss: 0.465388, acc.: 81.25%] [G loss: 1.269987]\n",
      "epoch:16 step:15443 [D loss: 0.355480, acc.: 87.50%] [G loss: 1.740860]\n",
      "epoch:16 step:15444 [D loss: 0.364628, acc.: 89.06%] [G loss: 1.578505]\n",
      "epoch:16 step:15445 [D loss: 0.381678, acc.: 89.84%] [G loss: 1.262791]\n",
      "epoch:16 step:15446 [D loss: 0.405849, acc.: 86.72%] [G loss: 1.748419]\n",
      "epoch:16 step:15447 [D loss: 0.382511, acc.: 89.84%] [G loss: 1.194179]\n",
      "epoch:16 step:15448 [D loss: 0.268617, acc.: 93.75%] [G loss: 1.731149]\n",
      "epoch:16 step:15449 [D loss: 0.421328, acc.: 83.59%] [G loss: 1.828087]\n",
      "epoch:16 step:15450 [D loss: 0.789718, acc.: 53.12%] [G loss: 1.131092]\n",
      "epoch:16 step:15451 [D loss: 0.638841, acc.: 61.72%] [G loss: 1.369713]\n",
      "epoch:16 step:15452 [D loss: 0.803451, acc.: 44.53%] [G loss: 1.212946]\n",
      "epoch:16 step:15453 [D loss: 0.816950, acc.: 46.88%] [G loss: 1.136623]\n",
      "epoch:16 step:15454 [D loss: 0.918810, acc.: 37.50%] [G loss: 0.959615]\n",
      "epoch:16 step:15455 [D loss: 0.728498, acc.: 54.69%] [G loss: 1.026825]\n",
      "epoch:16 step:15456 [D loss: 0.547526, acc.: 74.22%] [G loss: 1.124830]\n",
      "epoch:16 step:15457 [D loss: 0.503298, acc.: 75.78%] [G loss: 1.256629]\n",
      "epoch:16 step:15458 [D loss: 0.531738, acc.: 72.66%] [G loss: 1.270440]\n",
      "epoch:16 step:15459 [D loss: 0.591831, acc.: 71.88%] [G loss: 1.067519]\n",
      "epoch:16 step:15460 [D loss: 0.436926, acc.: 78.91%] [G loss: 1.058225]\n",
      "epoch:16 step:15461 [D loss: 0.349619, acc.: 89.06%] [G loss: 1.123784]\n",
      "epoch:16 step:15462 [D loss: 0.381430, acc.: 85.94%] [G loss: 1.103883]\n",
      "epoch:16 step:15463 [D loss: 0.309365, acc.: 92.19%] [G loss: 1.441116]\n",
      "epoch:16 step:15464 [D loss: 0.519850, acc.: 75.78%] [G loss: 1.045505]\n",
      "epoch:16 step:15465 [D loss: 0.961658, acc.: 41.41%] [G loss: 1.426953]\n",
      "epoch:16 step:15466 [D loss: 0.649388, acc.: 64.84%] [G loss: 1.106312]\n",
      "epoch:16 step:15467 [D loss: 0.638807, acc.: 69.53%] [G loss: 1.082515]\n",
      "epoch:16 step:15468 [D loss: 0.687130, acc.: 61.72%] [G loss: 1.237845]\n",
      "epoch:16 step:15469 [D loss: 0.598270, acc.: 69.53%] [G loss: 1.026862]\n",
      "epoch:16 step:15470 [D loss: 0.631232, acc.: 64.84%] [G loss: 0.979493]\n",
      "epoch:16 step:15471 [D loss: 0.625733, acc.: 66.41%] [G loss: 1.051857]\n",
      "epoch:16 step:15472 [D loss: 0.572445, acc.: 74.22%] [G loss: 1.115323]\n",
      "epoch:16 step:15473 [D loss: 0.552412, acc.: 68.75%] [G loss: 1.000829]\n",
      "epoch:16 step:15474 [D loss: 0.646906, acc.: 60.16%] [G loss: 1.130646]\n",
      "epoch:16 step:15475 [D loss: 0.556437, acc.: 75.78%] [G loss: 1.149205]\n",
      "epoch:16 step:15476 [D loss: 0.414153, acc.: 83.59%] [G loss: 1.292254]\n",
      "epoch:16 step:15477 [D loss: 0.578867, acc.: 65.62%] [G loss: 1.379603]\n",
      "epoch:16 step:15478 [D loss: 0.570290, acc.: 74.22%] [G loss: 1.396069]\n",
      "epoch:16 step:15479 [D loss: 0.526752, acc.: 78.12%] [G loss: 1.276282]\n",
      "epoch:16 step:15480 [D loss: 0.558338, acc.: 71.09%] [G loss: 1.107997]\n",
      "epoch:16 step:15481 [D loss: 0.627478, acc.: 60.16%] [G loss: 0.988145]\n",
      "epoch:16 step:15482 [D loss: 0.627619, acc.: 65.62%] [G loss: 0.974137]\n",
      "epoch:16 step:15483 [D loss: 0.577562, acc.: 72.66%] [G loss: 1.044429]\n",
      "epoch:16 step:15484 [D loss: 0.659917, acc.: 57.81%] [G loss: 0.956342]\n",
      "epoch:16 step:15485 [D loss: 0.741168, acc.: 51.56%] [G loss: 0.992702]\n",
      "epoch:16 step:15486 [D loss: 0.607972, acc.: 67.97%] [G loss: 1.044359]\n",
      "epoch:16 step:15487 [D loss: 0.652078, acc.: 59.38%] [G loss: 1.166762]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:16 step:15488 [D loss: 0.644869, acc.: 63.28%] [G loss: 1.112426]\n",
      "epoch:16 step:15489 [D loss: 0.476202, acc.: 82.03%] [G loss: 1.290424]\n",
      "epoch:16 step:15490 [D loss: 0.308174, acc.: 89.06%] [G loss: 1.230593]\n",
      "epoch:16 step:15491 [D loss: 0.278396, acc.: 95.31%] [G loss: 1.359775]\n",
      "epoch:16 step:15492 [D loss: 0.769128, acc.: 58.59%] [G loss: 1.335169]\n",
      "epoch:16 step:15493 [D loss: 0.701551, acc.: 62.50%] [G loss: 1.163781]\n",
      "epoch:16 step:15494 [D loss: 0.635384, acc.: 58.59%] [G loss: 0.746624]\n",
      "epoch:16 step:15495 [D loss: 0.504345, acc.: 80.47%] [G loss: 1.087005]\n",
      "epoch:16 step:15496 [D loss: 0.400945, acc.: 91.41%] [G loss: 1.131676]\n",
      "epoch:16 step:15497 [D loss: 0.557757, acc.: 75.00%] [G loss: 1.023842]\n",
      "epoch:16 step:15498 [D loss: 0.621940, acc.: 64.06%] [G loss: 1.047801]\n",
      "epoch:16 step:15499 [D loss: 0.553257, acc.: 72.66%] [G loss: 1.063508]\n",
      "epoch:16 step:15500 [D loss: 0.561973, acc.: 71.09%] [G loss: 1.135855]\n",
      "epoch:16 step:15501 [D loss: 0.711957, acc.: 57.03%] [G loss: 0.993856]\n",
      "epoch:16 step:15502 [D loss: 0.365030, acc.: 88.28%] [G loss: 1.077174]\n",
      "epoch:16 step:15503 [D loss: 0.364691, acc.: 83.59%] [G loss: 1.182352]\n",
      "epoch:16 step:15504 [D loss: 0.351111, acc.: 85.94%] [G loss: 1.402514]\n",
      "epoch:16 step:15505 [D loss: 0.333880, acc.: 92.97%] [G loss: 1.454553]\n",
      "epoch:16 step:15506 [D loss: 0.427343, acc.: 84.38%] [G loss: 1.317730]\n",
      "epoch:16 step:15507 [D loss: 0.462041, acc.: 78.91%] [G loss: 1.952145]\n",
      "epoch:16 step:15508 [D loss: 0.746171, acc.: 55.47%] [G loss: 1.312886]\n",
      "epoch:16 step:15509 [D loss: 0.414182, acc.: 83.59%] [G loss: 1.358972]\n",
      "epoch:16 step:15510 [D loss: 0.606391, acc.: 62.50%] [G loss: 1.085195]\n",
      "epoch:16 step:15511 [D loss: 0.704583, acc.: 57.81%] [G loss: 1.035359]\n",
      "epoch:16 step:15512 [D loss: 0.491984, acc.: 78.12%] [G loss: 1.073228]\n",
      "epoch:16 step:15513 [D loss: 0.485392, acc.: 79.69%] [G loss: 1.073217]\n",
      "epoch:16 step:15514 [D loss: 0.524659, acc.: 76.56%] [G loss: 1.267749]\n",
      "epoch:16 step:15515 [D loss: 0.585041, acc.: 69.53%] [G loss: 1.419344]\n",
      "epoch:16 step:15516 [D loss: 0.334202, acc.: 92.19%] [G loss: 1.152056]\n",
      "epoch:16 step:15517 [D loss: 0.773736, acc.: 54.69%] [G loss: 1.171164]\n",
      "epoch:16 step:15518 [D loss: 0.710452, acc.: 58.59%] [G loss: 1.140740]\n",
      "epoch:16 step:15519 [D loss: 0.439589, acc.: 78.91%] [G loss: 0.840962]\n",
      "epoch:16 step:15520 [D loss: 0.805578, acc.: 53.91%] [G loss: 1.119124]\n",
      "epoch:16 step:15521 [D loss: 0.775090, acc.: 47.66%] [G loss: 0.957964]\n",
      "epoch:16 step:15522 [D loss: 0.477852, acc.: 83.59%] [G loss: 1.074616]\n",
      "epoch:16 step:15523 [D loss: 0.690782, acc.: 57.81%] [G loss: 1.138938]\n",
      "epoch:16 step:15524 [D loss: 0.719039, acc.: 52.34%] [G loss: 0.881198]\n",
      "epoch:16 step:15525 [D loss: 0.431381, acc.: 82.81%] [G loss: 1.046710]\n",
      "epoch:16 step:15526 [D loss: 0.512224, acc.: 78.12%] [G loss: 1.369292]\n",
      "epoch:16 step:15527 [D loss: 0.363139, acc.: 86.72%] [G loss: 1.332446]\n",
      "epoch:16 step:15528 [D loss: 0.203295, acc.: 96.88%] [G loss: 1.505781]\n",
      "epoch:16 step:15529 [D loss: 0.267926, acc.: 96.88%] [G loss: 0.869744]\n",
      "epoch:16 step:15530 [D loss: 0.440690, acc.: 86.72%] [G loss: 1.562243]\n",
      "epoch:16 step:15531 [D loss: 0.514341, acc.: 79.69%] [G loss: 1.594574]\n",
      "epoch:16 step:15532 [D loss: 0.462826, acc.: 82.81%] [G loss: 1.676545]\n",
      "epoch:16 step:15533 [D loss: 0.379839, acc.: 88.28%] [G loss: 1.637990]\n",
      "epoch:16 step:15534 [D loss: 0.719746, acc.: 50.78%] [G loss: 1.346337]\n",
      "epoch:16 step:15535 [D loss: 0.748552, acc.: 46.88%] [G loss: 1.420531]\n",
      "epoch:16 step:15536 [D loss: 0.604873, acc.: 64.06%] [G loss: 1.241268]\n",
      "epoch:16 step:15537 [D loss: 0.472384, acc.: 81.25%] [G loss: 1.102645]\n",
      "epoch:16 step:15538 [D loss: 0.564036, acc.: 74.22%] [G loss: 1.039422]\n",
      "epoch:16 step:15539 [D loss: 0.536310, acc.: 71.88%] [G loss: 1.136283]\n",
      "epoch:16 step:15540 [D loss: 0.655659, acc.: 60.94%] [G loss: 1.442596]\n",
      "epoch:16 step:15541 [D loss: 0.405317, acc.: 86.72%] [G loss: 1.573171]\n",
      "epoch:16 step:15542 [D loss: 0.348732, acc.: 86.72%] [G loss: 1.097699]\n",
      "epoch:16 step:15543 [D loss: 0.481487, acc.: 78.12%] [G loss: 1.079315]\n",
      "epoch:16 step:15544 [D loss: 0.404618, acc.: 83.59%] [G loss: 1.241665]\n",
      "epoch:16 step:15545 [D loss: 0.862280, acc.: 45.31%] [G loss: 0.880843]\n",
      "epoch:16 step:15546 [D loss: 0.317832, acc.: 86.72%] [G loss: 1.202621]\n",
      "epoch:16 step:15547 [D loss: 0.594824, acc.: 67.19%] [G loss: 1.170648]\n",
      "epoch:16 step:15548 [D loss: 0.438206, acc.: 85.16%] [G loss: 1.362799]\n",
      "epoch:16 step:15549 [D loss: 0.439200, acc.: 88.28%] [G loss: 1.557134]\n",
      "epoch:16 step:15550 [D loss: 0.754868, acc.: 52.34%] [G loss: 1.661271]\n",
      "epoch:16 step:15551 [D loss: 0.408279, acc.: 75.00%] [G loss: 1.663782]\n",
      "epoch:16 step:15552 [D loss: 0.440046, acc.: 81.25%] [G loss: 1.724425]\n",
      "epoch:16 step:15553 [D loss: 0.186099, acc.: 96.09%] [G loss: 2.129123]\n",
      "epoch:16 step:15554 [D loss: 0.921054, acc.: 50.00%] [G loss: 1.815297]\n",
      "epoch:16 step:15555 [D loss: 0.804317, acc.: 53.12%] [G loss: 1.232059]\n",
      "epoch:16 step:15556 [D loss: 0.772121, acc.: 52.34%] [G loss: 1.318078]\n",
      "epoch:16 step:15557 [D loss: 0.517584, acc.: 75.78%] [G loss: 1.144580]\n",
      "epoch:16 step:15558 [D loss: 0.224149, acc.: 92.19%] [G loss: 1.533102]\n",
      "epoch:16 step:15559 [D loss: 0.203074, acc.: 95.31%] [G loss: 1.289737]\n",
      "epoch:16 step:15560 [D loss: 0.197779, acc.: 94.53%] [G loss: 0.724914]\n",
      "epoch:16 step:15561 [D loss: 0.558395, acc.: 66.41%] [G loss: 1.501328]\n",
      "epoch:16 step:15562 [D loss: 0.389797, acc.: 91.41%] [G loss: 1.470338]\n",
      "epoch:16 step:15563 [D loss: 0.610201, acc.: 64.06%] [G loss: 1.651671]\n",
      "epoch:16 step:15564 [D loss: 0.565176, acc.: 74.22%] [G loss: 1.719401]\n",
      "epoch:16 step:15565 [D loss: 0.471925, acc.: 83.59%] [G loss: 1.722679]\n",
      "epoch:16 step:15566 [D loss: 0.648897, acc.: 64.06%] [G loss: 0.868208]\n",
      "epoch:16 step:15567 [D loss: 0.665149, acc.: 62.50%] [G loss: 1.373776]\n",
      "epoch:16 step:15568 [D loss: 0.347020, acc.: 86.72%] [G loss: 1.306996]\n",
      "epoch:16 step:15569 [D loss: 0.564702, acc.: 64.06%] [G loss: 1.476421]\n",
      "epoch:16 step:15570 [D loss: 0.294303, acc.: 88.28%] [G loss: 3.629029]\n",
      "epoch:16 step:15571 [D loss: 1.109321, acc.: 42.97%] [G loss: 3.126098]\n",
      "epoch:16 step:15572 [D loss: 1.322495, acc.: 43.75%] [G loss: 2.613548]\n",
      "epoch:16 step:15573 [D loss: 0.897745, acc.: 54.69%] [G loss: 1.872409]\n",
      "epoch:16 step:15574 [D loss: 0.875573, acc.: 53.12%] [G loss: 1.629783]\n",
      "epoch:16 step:15575 [D loss: 1.037012, acc.: 30.47%] [G loss: 1.171387]\n",
      "epoch:16 step:15576 [D loss: 0.840006, acc.: 47.66%] [G loss: 1.405705]\n",
      "epoch:16 step:15577 [D loss: 0.565237, acc.: 69.53%] [G loss: 1.774539]\n",
      "epoch:16 step:15578 [D loss: 0.615126, acc.: 63.28%] [G loss: 1.487464]\n",
      "epoch:16 step:15579 [D loss: 0.653042, acc.: 69.53%] [G loss: 1.788921]\n",
      "epoch:16 step:15580 [D loss: 0.513684, acc.: 78.91%] [G loss: 1.472278]\n",
      "epoch:16 step:15581 [D loss: 0.302535, acc.: 89.06%] [G loss: 1.409361]\n",
      "epoch:16 step:15582 [D loss: 0.709803, acc.: 58.59%] [G loss: 1.412353]\n",
      "epoch:16 step:15583 [D loss: 0.441871, acc.: 78.91%] [G loss: 1.857443]\n",
      "epoch:16 step:15584 [D loss: 0.285326, acc.: 96.88%] [G loss: 1.414801]\n",
      "epoch:16 step:15585 [D loss: 0.554233, acc.: 75.00%] [G loss: 1.261601]\n",
      "epoch:16 step:15586 [D loss: 0.701415, acc.: 59.38%] [G loss: 1.794703]\n",
      "epoch:16 step:15587 [D loss: 0.595253, acc.: 69.53%] [G loss: 1.104725]\n",
      "epoch:16 step:15588 [D loss: 0.489473, acc.: 81.25%] [G loss: 1.357787]\n",
      "epoch:16 step:15589 [D loss: 0.678584, acc.: 60.94%] [G loss: 0.938630]\n",
      "epoch:16 step:15590 [D loss: 0.499650, acc.: 80.47%] [G loss: 0.676178]\n",
      "epoch:16 step:15591 [D loss: 0.724838, acc.: 53.12%] [G loss: 0.664180]\n",
      "epoch:16 step:15592 [D loss: 0.409535, acc.: 86.72%] [G loss: 1.358078]\n",
      "epoch:16 step:15593 [D loss: 0.469926, acc.: 75.78%] [G loss: 1.268475]\n",
      "epoch:16 step:15594 [D loss: 0.375606, acc.: 85.94%] [G loss: 1.203738]\n",
      "epoch:16 step:15595 [D loss: 0.583937, acc.: 72.66%] [G loss: 1.164469]\n",
      "epoch:16 step:15596 [D loss: 0.589355, acc.: 66.41%] [G loss: 1.176543]\n",
      "epoch:16 step:15597 [D loss: 0.897283, acc.: 49.22%] [G loss: 1.422267]\n",
      "epoch:16 step:15598 [D loss: 0.656040, acc.: 64.84%] [G loss: 1.223928]\n",
      "epoch:16 step:15599 [D loss: 0.802002, acc.: 54.69%] [G loss: 1.082203]\n",
      "epoch:16 step:15600 [D loss: 0.583963, acc.: 69.53%] [G loss: 1.111235]\n",
      "##############\n",
      "[4.4424223  2.74862441 6.635038   5.57094742 4.34100096 6.0662908\n",
      " 5.17590995 5.65622473 5.62145552 5.10475366]\n",
      "##########\n",
      "epoch:16 step:15601 [D loss: 0.272500, acc.: 98.44%] [G loss: 1.149033]\n",
      "epoch:16 step:15602 [D loss: 0.711391, acc.: 64.84%] [G loss: 1.121414]\n",
      "epoch:16 step:15603 [D loss: 0.444713, acc.: 85.16%] [G loss: 0.990541]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:16 step:15604 [D loss: 0.767108, acc.: 56.25%] [G loss: 1.231561]\n",
      "epoch:16 step:15605 [D loss: 0.629231, acc.: 65.62%] [G loss: 1.064546]\n",
      "epoch:16 step:15606 [D loss: 0.713694, acc.: 59.38%] [G loss: 1.141137]\n",
      "epoch:16 step:15607 [D loss: 0.652771, acc.: 60.94%] [G loss: 1.091107]\n",
      "epoch:16 step:15608 [D loss: 0.570643, acc.: 71.88%] [G loss: 0.817573]\n",
      "epoch:16 step:15609 [D loss: 0.594408, acc.: 69.53%] [G loss: 1.005137]\n",
      "epoch:16 step:15610 [D loss: 0.448999, acc.: 85.16%] [G loss: 1.056716]\n",
      "epoch:16 step:15611 [D loss: 0.486655, acc.: 80.47%] [G loss: 0.985278]\n",
      "epoch:16 step:15612 [D loss: 0.563842, acc.: 68.75%] [G loss: 1.154704]\n",
      "epoch:16 step:15613 [D loss: 0.745462, acc.: 50.00%] [G loss: 1.142798]\n",
      "epoch:16 step:15614 [D loss: 0.600595, acc.: 61.72%] [G loss: 0.966613]\n",
      "epoch:16 step:15615 [D loss: 0.662246, acc.: 58.59%] [G loss: 0.969879]\n",
      "epoch:16 step:15616 [D loss: 0.592659, acc.: 64.84%] [G loss: 0.890414]\n",
      "epoch:16 step:15617 [D loss: 0.645112, acc.: 59.38%] [G loss: 1.184860]\n",
      "epoch:16 step:15618 [D loss: 0.720746, acc.: 49.22%] [G loss: 0.957240]\n",
      "epoch:16 step:15619 [D loss: 0.671817, acc.: 63.28%] [G loss: 1.386709]\n",
      "epoch:16 step:15620 [D loss: 0.599521, acc.: 65.62%] [G loss: 1.051023]\n",
      "epoch:16 step:15621 [D loss: 0.623517, acc.: 64.84%] [G loss: 0.922094]\n",
      "epoch:16 step:15622 [D loss: 0.539931, acc.: 75.78%] [G loss: 0.738588]\n",
      "epoch:16 step:15623 [D loss: 0.596472, acc.: 70.31%] [G loss: 1.006198]\n",
      "epoch:16 step:15624 [D loss: 0.500000, acc.: 82.03%] [G loss: 1.047448]\n",
      "epoch:16 step:15625 [D loss: 0.427355, acc.: 80.47%] [G loss: 1.003381]\n",
      "epoch:16 step:15626 [D loss: 0.492806, acc.: 75.00%] [G loss: 1.074233]\n",
      "epoch:16 step:15627 [D loss: 0.603851, acc.: 71.09%] [G loss: 1.172708]\n",
      "epoch:16 step:15628 [D loss: 0.616788, acc.: 64.84%] [G loss: 1.193297]\n",
      "epoch:16 step:15629 [D loss: 0.752643, acc.: 46.88%] [G loss: 0.818016]\n",
      "epoch:16 step:15630 [D loss: 0.976963, acc.: 22.66%] [G loss: 0.868858]\n",
      "epoch:16 step:15631 [D loss: 0.462906, acc.: 82.81%] [G loss: 1.251740]\n",
      "epoch:16 step:15632 [D loss: 0.939876, acc.: 30.47%] [G loss: 0.863493]\n",
      "epoch:16 step:15633 [D loss: 0.213138, acc.: 93.75%] [G loss: 1.370680]\n",
      "epoch:16 step:15634 [D loss: 0.756124, acc.: 53.91%] [G loss: 1.328834]\n",
      "epoch:16 step:15635 [D loss: 0.782187, acc.: 49.22%] [G loss: 1.041964]\n",
      "epoch:16 step:15636 [D loss: 0.728429, acc.: 50.78%] [G loss: 1.229845]\n",
      "epoch:16 step:15637 [D loss: 0.594974, acc.: 67.97%] [G loss: 0.999414]\n",
      "epoch:16 step:15638 [D loss: 0.512391, acc.: 76.56%] [G loss: 1.009795]\n",
      "epoch:16 step:15639 [D loss: 0.760055, acc.: 45.31%] [G loss: 1.181651]\n",
      "epoch:16 step:15640 [D loss: 0.516692, acc.: 78.91%] [G loss: 0.793313]\n",
      "epoch:16 step:15641 [D loss: 0.542104, acc.: 75.00%] [G loss: 0.943178]\n",
      "epoch:16 step:15642 [D loss: 0.403436, acc.: 81.25%] [G loss: 0.966496]\n",
      "epoch:16 step:15643 [D loss: 0.546347, acc.: 71.09%] [G loss: 1.192144]\n",
      "epoch:16 step:15644 [D loss: 0.788225, acc.: 43.75%] [G loss: 1.085231]\n",
      "epoch:16 step:15645 [D loss: 0.588526, acc.: 65.62%] [G loss: 0.950731]\n",
      "epoch:16 step:15646 [D loss: 0.769587, acc.: 52.34%] [G loss: 1.233700]\n",
      "epoch:16 step:15647 [D loss: 0.758134, acc.: 49.22%] [G loss: 0.924470]\n",
      "epoch:16 step:15648 [D loss: 0.751191, acc.: 53.91%] [G loss: 0.940527]\n",
      "epoch:16 step:15649 [D loss: 0.757686, acc.: 49.22%] [G loss: 0.964761]\n",
      "epoch:16 step:15650 [D loss: 0.707431, acc.: 57.03%] [G loss: 1.138708]\n",
      "epoch:16 step:15651 [D loss: 0.561185, acc.: 71.88%] [G loss: 1.121324]\n",
      "epoch:16 step:15652 [D loss: 0.539692, acc.: 75.78%] [G loss: 0.940715]\n",
      "epoch:16 step:15653 [D loss: 0.653570, acc.: 62.50%] [G loss: 0.640181]\n",
      "epoch:16 step:15654 [D loss: 0.688585, acc.: 60.16%] [G loss: 1.151524]\n",
      "epoch:16 step:15655 [D loss: 0.286754, acc.: 89.84%] [G loss: 1.275894]\n",
      "epoch:16 step:15656 [D loss: 0.233754, acc.: 92.19%] [G loss: 1.645463]\n",
      "epoch:16 step:15657 [D loss: 0.310346, acc.: 80.47%] [G loss: 1.531335]\n",
      "epoch:16 step:15658 [D loss: 0.568147, acc.: 69.53%] [G loss: 1.322249]\n",
      "epoch:16 step:15659 [D loss: 0.407205, acc.: 88.28%] [G loss: 1.487832]\n",
      "epoch:16 step:15660 [D loss: 0.651012, acc.: 61.72%] [G loss: 1.406327]\n",
      "epoch:16 step:15661 [D loss: 0.528324, acc.: 73.44%] [G loss: 1.377063]\n",
      "epoch:16 step:15662 [D loss: 0.564933, acc.: 72.66%] [G loss: 1.280213]\n",
      "epoch:16 step:15663 [D loss: 0.407583, acc.: 89.84%] [G loss: 1.411229]\n",
      "epoch:16 step:15664 [D loss: 0.589944, acc.: 67.97%] [G loss: 1.126212]\n",
      "epoch:16 step:15665 [D loss: 0.599732, acc.: 73.44%] [G loss: 1.170118]\n",
      "epoch:16 step:15666 [D loss: 0.423433, acc.: 80.47%] [G loss: 1.229011]\n",
      "epoch:16 step:15667 [D loss: 0.574656, acc.: 71.09%] [G loss: 1.087631]\n",
      "epoch:16 step:15668 [D loss: 0.641409, acc.: 67.19%] [G loss: 0.824485]\n",
      "epoch:16 step:15669 [D loss: 0.803788, acc.: 38.28%] [G loss: 0.872969]\n",
      "epoch:16 step:15670 [D loss: 0.764291, acc.: 40.62%] [G loss: 0.872341]\n",
      "epoch:16 step:15671 [D loss: 0.667804, acc.: 63.28%] [G loss: 0.749850]\n",
      "epoch:16 step:15672 [D loss: 0.507705, acc.: 76.56%] [G loss: 0.890148]\n",
      "epoch:16 step:15673 [D loss: 0.770434, acc.: 46.88%] [G loss: 0.686581]\n",
      "epoch:16 step:15674 [D loss: 0.387588, acc.: 79.69%] [G loss: 0.976269]\n",
      "epoch:16 step:15675 [D loss: 0.696801, acc.: 56.25%] [G loss: 0.508177]\n",
      "epoch:16 step:15676 [D loss: 0.252928, acc.: 92.97%] [G loss: 1.115951]\n",
      "epoch:16 step:15677 [D loss: 0.677458, acc.: 58.59%] [G loss: 1.188155]\n",
      "epoch:16 step:15678 [D loss: 0.818171, acc.: 43.75%] [G loss: 0.598900]\n",
      "epoch:16 step:15679 [D loss: 0.699174, acc.: 59.38%] [G loss: 1.514454]\n",
      "epoch:16 step:15680 [D loss: 0.987713, acc.: 32.03%] [G loss: 0.861019]\n",
      "epoch:16 step:15681 [D loss: 0.790731, acc.: 47.66%] [G loss: 1.413374]\n",
      "epoch:16 step:15682 [D loss: 0.692837, acc.: 57.03%] [G loss: 1.131203]\n",
      "epoch:16 step:15683 [D loss: 0.673198, acc.: 53.91%] [G loss: 0.803480]\n",
      "epoch:16 step:15684 [D loss: 0.794801, acc.: 46.09%] [G loss: 1.264503]\n",
      "epoch:16 step:15685 [D loss: 0.606684, acc.: 63.28%] [G loss: 1.568433]\n",
      "epoch:16 step:15686 [D loss: 0.423818, acc.: 78.91%] [G loss: 1.371879]\n",
      "epoch:16 step:15687 [D loss: 0.910915, acc.: 42.97%] [G loss: 1.228360]\n",
      "epoch:16 step:15688 [D loss: 0.529016, acc.: 71.88%] [G loss: 0.911572]\n",
      "epoch:16 step:15689 [D loss: 0.450973, acc.: 73.44%] [G loss: 1.387324]\n",
      "epoch:16 step:15690 [D loss: 0.873889, acc.: 49.22%] [G loss: 1.600820]\n",
      "epoch:16 step:15691 [D loss: 0.758696, acc.: 50.78%] [G loss: 2.153711]\n",
      "epoch:16 step:15692 [D loss: 0.699296, acc.: 63.28%] [G loss: 1.453310]\n",
      "epoch:16 step:15693 [D loss: 0.861345, acc.: 48.44%] [G loss: 1.153963]\n",
      "epoch:16 step:15694 [D loss: 0.824167, acc.: 50.00%] [G loss: 0.806111]\n",
      "epoch:16 step:15695 [D loss: 0.831961, acc.: 44.53%] [G loss: 0.991619]\n",
      "epoch:16 step:15696 [D loss: 0.841596, acc.: 46.09%] [G loss: 1.078513]\n",
      "epoch:16 step:15697 [D loss: 0.636570, acc.: 63.28%] [G loss: 1.388922]\n",
      "epoch:16 step:15698 [D loss: 0.946497, acc.: 42.19%] [G loss: 1.144144]\n",
      "epoch:16 step:15699 [D loss: 0.700645, acc.: 61.72%] [G loss: 1.137605]\n",
      "epoch:16 step:15700 [D loss: 0.709389, acc.: 63.28%] [G loss: 1.320651]\n",
      "epoch:16 step:15701 [D loss: 0.676732, acc.: 61.72%] [G loss: 1.047848]\n",
      "epoch:16 step:15702 [D loss: 0.359935, acc.: 89.06%] [G loss: 1.682142]\n",
      "epoch:16 step:15703 [D loss: 0.291761, acc.: 96.88%] [G loss: 1.950360]\n",
      "epoch:16 step:15704 [D loss: 0.700101, acc.: 57.81%] [G loss: 1.788308]\n",
      "epoch:16 step:15705 [D loss: 0.864616, acc.: 54.69%] [G loss: 1.077799]\n",
      "epoch:16 step:15706 [D loss: 0.653736, acc.: 60.16%] [G loss: 0.742960]\n",
      "epoch:16 step:15707 [D loss: 0.654271, acc.: 61.72%] [G loss: 0.841111]\n",
      "epoch:16 step:15708 [D loss: 0.528075, acc.: 78.91%] [G loss: 1.205003]\n",
      "epoch:16 step:15709 [D loss: 0.463135, acc.: 78.91%] [G loss: 1.099300]\n",
      "epoch:16 step:15710 [D loss: 0.318140, acc.: 96.88%] [G loss: 1.377553]\n",
      "epoch:16 step:15711 [D loss: 0.347867, acc.: 93.75%] [G loss: 1.368186]\n",
      "epoch:16 step:15712 [D loss: 0.297454, acc.: 95.31%] [G loss: 1.504564]\n",
      "epoch:16 step:15713 [D loss: 0.285298, acc.: 95.31%] [G loss: 1.595913]\n",
      "epoch:16 step:15714 [D loss: 0.661144, acc.: 59.38%] [G loss: 1.007355]\n",
      "epoch:16 step:15715 [D loss: 0.552998, acc.: 71.09%] [G loss: 1.181480]\n",
      "epoch:16 step:15716 [D loss: 0.345621, acc.: 86.72%] [G loss: 1.243033]\n",
      "epoch:16 step:15717 [D loss: 0.318814, acc.: 92.19%] [G loss: 1.193672]\n",
      "epoch:16 step:15718 [D loss: 0.333695, acc.: 92.19%] [G loss: 1.447791]\n",
      "epoch:16 step:15719 [D loss: 0.972747, acc.: 36.72%] [G loss: 1.187489]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:16 step:15720 [D loss: 0.840911, acc.: 46.09%] [G loss: 1.121394]\n",
      "epoch:16 step:15721 [D loss: 0.823397, acc.: 48.44%] [G loss: 0.735899]\n",
      "epoch:16 step:15722 [D loss: 0.629441, acc.: 62.50%] [G loss: 1.020275]\n",
      "epoch:16 step:15723 [D loss: 0.584822, acc.: 68.75%] [G loss: 1.023247]\n",
      "epoch:16 step:15724 [D loss: 0.613858, acc.: 61.72%] [G loss: 0.987293]\n",
      "epoch:16 step:15725 [D loss: 0.617326, acc.: 61.72%] [G loss: 1.129908]\n",
      "epoch:16 step:15726 [D loss: 0.592201, acc.: 67.19%] [G loss: 1.167621]\n",
      "epoch:16 step:15727 [D loss: 0.517519, acc.: 77.34%] [G loss: 1.077618]\n",
      "epoch:16 step:15728 [D loss: 0.534844, acc.: 77.34%] [G loss: 1.125967]\n",
      "epoch:16 step:15729 [D loss: 0.636799, acc.: 67.19%] [G loss: 1.119451]\n",
      "epoch:16 step:15730 [D loss: 0.754310, acc.: 44.53%] [G loss: 1.079469]\n",
      "epoch:16 step:15731 [D loss: 0.511671, acc.: 77.34%] [G loss: 0.992090]\n",
      "epoch:16 step:15732 [D loss: 0.405227, acc.: 86.72%] [G loss: 0.652904]\n",
      "epoch:16 step:15733 [D loss: 0.561699, acc.: 76.56%] [G loss: 0.774518]\n",
      "epoch:16 step:15734 [D loss: 0.582547, acc.: 70.31%] [G loss: 0.989254]\n",
      "epoch:16 step:15735 [D loss: 0.412545, acc.: 88.28%] [G loss: 1.159949]\n",
      "epoch:16 step:15736 [D loss: 0.705483, acc.: 57.03%] [G loss: 0.823234]\n",
      "epoch:16 step:15737 [D loss: 0.555135, acc.: 72.66%] [G loss: 1.175381]\n",
      "epoch:16 step:15738 [D loss: 0.367664, acc.: 82.81%] [G loss: 1.214868]\n",
      "epoch:16 step:15739 [D loss: 0.547165, acc.: 73.44%] [G loss: 1.299907]\n",
      "epoch:16 step:15740 [D loss: 0.728754, acc.: 54.69%] [G loss: 1.209580]\n",
      "epoch:16 step:15741 [D loss: 0.475611, acc.: 80.47%] [G loss: 1.062766]\n",
      "epoch:16 step:15742 [D loss: 0.599612, acc.: 65.62%] [G loss: 1.180928]\n",
      "epoch:16 step:15743 [D loss: 0.527553, acc.: 78.91%] [G loss: 1.316773]\n",
      "epoch:16 step:15744 [D loss: 0.343948, acc.: 92.19%] [G loss: 0.980071]\n",
      "epoch:16 step:15745 [D loss: 0.500038, acc.: 79.69%] [G loss: 1.562276]\n",
      "epoch:16 step:15746 [D loss: 0.275128, acc.: 92.97%] [G loss: 1.333979]\n",
      "epoch:16 step:15747 [D loss: 0.334423, acc.: 86.72%] [G loss: 1.563810]\n",
      "epoch:16 step:15748 [D loss: 0.348811, acc.: 78.91%] [G loss: 0.979305]\n",
      "epoch:16 step:15749 [D loss: 0.293346, acc.: 92.19%] [G loss: 1.814065]\n",
      "epoch:16 step:15750 [D loss: 0.535955, acc.: 68.75%] [G loss: 1.912682]\n",
      "epoch:16 step:15751 [D loss: 1.249545, acc.: 21.09%] [G loss: 1.364411]\n",
      "epoch:16 step:15752 [D loss: 0.769444, acc.: 53.91%] [G loss: 1.289627]\n",
      "epoch:16 step:15753 [D loss: 0.657026, acc.: 64.06%] [G loss: 0.743895]\n",
      "epoch:16 step:15754 [D loss: 0.627966, acc.: 68.75%] [G loss: 1.109897]\n",
      "epoch:16 step:15755 [D loss: 0.329478, acc.: 90.62%] [G loss: 1.332670]\n",
      "epoch:16 step:15756 [D loss: 0.228948, acc.: 96.88%] [G loss: 1.223922]\n",
      "epoch:16 step:15757 [D loss: 0.941743, acc.: 30.47%] [G loss: 0.868305]\n",
      "epoch:16 step:15758 [D loss: 0.635224, acc.: 64.84%] [G loss: 1.040064]\n",
      "epoch:16 step:15759 [D loss: 0.677406, acc.: 61.72%] [G loss: 1.252923]\n",
      "epoch:16 step:15760 [D loss: 0.524320, acc.: 75.00%] [G loss: 0.821504]\n",
      "epoch:16 step:15761 [D loss: 0.641725, acc.: 61.72%] [G loss: 1.190581]\n",
      "epoch:16 step:15762 [D loss: 0.742676, acc.: 52.34%] [G loss: 1.004650]\n",
      "epoch:16 step:15763 [D loss: 0.516656, acc.: 77.34%] [G loss: 1.118216]\n",
      "epoch:16 step:15764 [D loss: 0.788607, acc.: 42.97%] [G loss: 1.243192]\n",
      "epoch:16 step:15765 [D loss: 0.610069, acc.: 67.19%] [G loss: 1.115956]\n",
      "epoch:16 step:15766 [D loss: 0.470645, acc.: 78.12%] [G loss: 1.099301]\n",
      "epoch:16 step:15767 [D loss: 0.543873, acc.: 65.62%] [G loss: 1.209546]\n",
      "epoch:16 step:15768 [D loss: 0.662180, acc.: 60.16%] [G loss: 1.280746]\n",
      "epoch:16 step:15769 [D loss: 0.540295, acc.: 78.12%] [G loss: 1.367849]\n",
      "epoch:16 step:15770 [D loss: 0.770061, acc.: 47.66%] [G loss: 1.290155]\n",
      "epoch:16 step:15771 [D loss: 0.758517, acc.: 53.91%] [G loss: 1.023039]\n",
      "epoch:16 step:15772 [D loss: 0.394155, acc.: 84.38%] [G loss: 1.279258]\n",
      "epoch:16 step:15773 [D loss: 0.314208, acc.: 92.97%] [G loss: 1.219175]\n",
      "epoch:16 step:15774 [D loss: 0.399600, acc.: 81.25%] [G loss: 1.649260]\n",
      "epoch:16 step:15775 [D loss: 0.702060, acc.: 52.34%] [G loss: 1.323265]\n",
      "epoch:16 step:15776 [D loss: 0.864825, acc.: 46.88%] [G loss: 1.300120]\n",
      "epoch:16 step:15777 [D loss: 0.751528, acc.: 46.09%] [G loss: 1.206366]\n",
      "epoch:16 step:15778 [D loss: 0.409872, acc.: 84.38%] [G loss: 1.328960]\n",
      "epoch:16 step:15779 [D loss: 0.756612, acc.: 49.22%] [G loss: 1.099026]\n",
      "epoch:16 step:15780 [D loss: 0.750253, acc.: 54.69%] [G loss: 1.098075]\n",
      "epoch:16 step:15781 [D loss: 0.785174, acc.: 42.19%] [G loss: 0.988398]\n",
      "epoch:16 step:15782 [D loss: 0.704915, acc.: 50.78%] [G loss: 0.809827]\n",
      "epoch:16 step:15783 [D loss: 0.325005, acc.: 92.19%] [G loss: 1.324688]\n",
      "epoch:16 step:15784 [D loss: 0.315745, acc.: 88.28%] [G loss: 0.988372]\n",
      "epoch:16 step:15785 [D loss: 0.363746, acc.: 89.84%] [G loss: 1.075243]\n",
      "epoch:16 step:15786 [D loss: 0.263398, acc.: 96.88%] [G loss: 1.311936]\n",
      "epoch:16 step:15787 [D loss: 0.444440, acc.: 88.28%] [G loss: 1.267957]\n",
      "epoch:16 step:15788 [D loss: 0.274159, acc.: 96.09%] [G loss: 1.210775]\n",
      "epoch:16 step:15789 [D loss: 0.747204, acc.: 56.25%] [G loss: 1.120688]\n",
      "epoch:16 step:15790 [D loss: 0.718019, acc.: 50.00%] [G loss: 1.186501]\n",
      "epoch:16 step:15791 [D loss: 0.639456, acc.: 60.94%] [G loss: 1.282361]\n",
      "epoch:16 step:15792 [D loss: 0.511481, acc.: 76.56%] [G loss: 0.705935]\n",
      "epoch:16 step:15793 [D loss: 0.514773, acc.: 81.25%] [G loss: 1.062011]\n",
      "epoch:16 step:15794 [D loss: 0.923289, acc.: 49.22%] [G loss: 1.468792]\n",
      "epoch:16 step:15795 [D loss: 0.626206, acc.: 64.06%] [G loss: 1.332975]\n",
      "epoch:16 step:15796 [D loss: 0.298846, acc.: 95.31%] [G loss: 1.188980]\n",
      "epoch:16 step:15797 [D loss: 0.301805, acc.: 91.41%] [G loss: 1.330383]\n",
      "epoch:16 step:15798 [D loss: 0.193971, acc.: 98.44%] [G loss: 1.646444]\n",
      "epoch:16 step:15799 [D loss: 0.778729, acc.: 50.00%] [G loss: 1.491780]\n",
      "epoch:16 step:15800 [D loss: 0.426942, acc.: 82.81%] [G loss: 1.021905]\n",
      "##############\n",
      "[3.92225654 2.75772134 6.56273484 5.51151811 4.49540899 6.18808346\n",
      " 5.41091799 5.26370131 5.95173911 4.98624343]\n",
      "##########\n",
      "epoch:16 step:15801 [D loss: 0.372035, acc.: 89.84%] [G loss: 1.280199]\n",
      "epoch:16 step:15802 [D loss: 0.503916, acc.: 82.03%] [G loss: 1.140660]\n",
      "epoch:16 step:15803 [D loss: 1.068756, acc.: 32.81%] [G loss: 1.174311]\n",
      "epoch:16 step:15804 [D loss: 0.759326, acc.: 43.75%] [G loss: 0.823963]\n",
      "epoch:16 step:15805 [D loss: 0.669930, acc.: 63.28%] [G loss: 1.089349]\n",
      "epoch:16 step:15806 [D loss: 0.726011, acc.: 50.00%] [G loss: 1.055094]\n",
      "epoch:16 step:15807 [D loss: 0.448812, acc.: 85.16%] [G loss: 1.137794]\n",
      "epoch:16 step:15808 [D loss: 0.623729, acc.: 68.75%] [G loss: 0.922857]\n",
      "epoch:16 step:15809 [D loss: 0.643481, acc.: 64.06%] [G loss: 0.929221]\n",
      "epoch:16 step:15810 [D loss: 0.695893, acc.: 60.94%] [G loss: 1.023737]\n",
      "epoch:16 step:15811 [D loss: 0.608668, acc.: 71.88%] [G loss: 0.837071]\n",
      "epoch:16 step:15812 [D loss: 0.794724, acc.: 38.28%] [G loss: 0.825837]\n",
      "epoch:16 step:15813 [D loss: 0.421997, acc.: 83.59%] [G loss: 0.941406]\n",
      "epoch:16 step:15814 [D loss: 0.679844, acc.: 60.16%] [G loss: 1.059715]\n",
      "epoch:16 step:15815 [D loss: 0.640411, acc.: 62.50%] [G loss: 0.915525]\n",
      "epoch:16 step:15816 [D loss: 0.664352, acc.: 61.72%] [G loss: 0.901119]\n",
      "epoch:16 step:15817 [D loss: 0.502430, acc.: 84.38%] [G loss: 0.629246]\n",
      "epoch:16 step:15818 [D loss: 0.598933, acc.: 64.06%] [G loss: 1.028459]\n",
      "epoch:16 step:15819 [D loss: 0.612298, acc.: 63.28%] [G loss: 0.895199]\n",
      "epoch:16 step:15820 [D loss: 1.036288, acc.: 36.72%] [G loss: 1.125636]\n",
      "epoch:16 step:15821 [D loss: 0.595128, acc.: 72.66%] [G loss: 1.132030]\n",
      "epoch:16 step:15822 [D loss: 0.500652, acc.: 79.69%] [G loss: 1.148110]\n",
      "epoch:16 step:15823 [D loss: 0.376567, acc.: 91.41%] [G loss: 1.059996]\n",
      "epoch:16 step:15824 [D loss: 0.409003, acc.: 85.94%] [G loss: 1.137605]\n",
      "epoch:16 step:15825 [D loss: 0.615128, acc.: 63.28%] [G loss: 1.166887]\n",
      "epoch:16 step:15826 [D loss: 0.522188, acc.: 77.34%] [G loss: 1.129304]\n",
      "epoch:16 step:15827 [D loss: 0.701249, acc.: 57.81%] [G loss: 1.106809]\n",
      "epoch:16 step:15828 [D loss: 0.732705, acc.: 50.78%] [G loss: 1.045866]\n",
      "epoch:16 step:15829 [D loss: 0.750664, acc.: 47.66%] [G loss: 0.897392]\n",
      "epoch:16 step:15830 [D loss: 0.631577, acc.: 64.06%] [G loss: 1.027238]\n",
      "epoch:16 step:15831 [D loss: 0.710828, acc.: 52.34%] [G loss: 0.944471]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:16 step:15832 [D loss: 0.648324, acc.: 64.84%] [G loss: 0.915868]\n",
      "epoch:16 step:15833 [D loss: 0.646694, acc.: 62.50%] [G loss: 0.988785]\n",
      "epoch:16 step:15834 [D loss: 0.573765, acc.: 67.97%] [G loss: 1.025116]\n",
      "epoch:16 step:15835 [D loss: 0.663804, acc.: 67.19%] [G loss: 0.792252]\n",
      "epoch:16 step:15836 [D loss: 0.641394, acc.: 70.31%] [G loss: 0.655498]\n",
      "epoch:16 step:15837 [D loss: 0.431885, acc.: 80.47%] [G loss: 0.973370]\n",
      "epoch:16 step:15838 [D loss: 0.772328, acc.: 48.44%] [G loss: 0.735672]\n",
      "epoch:16 step:15839 [D loss: 0.383137, acc.: 92.19%] [G loss: 0.765686]\n",
      "epoch:16 step:15840 [D loss: 0.370432, acc.: 85.16%] [G loss: 1.141201]\n",
      "epoch:16 step:15841 [D loss: 0.596543, acc.: 69.53%] [G loss: 0.815472]\n",
      "epoch:16 step:15842 [D loss: 0.345744, acc.: 82.81%] [G loss: 0.886981]\n",
      "epoch:16 step:15843 [D loss: 0.338600, acc.: 84.38%] [G loss: 1.286969]\n",
      "epoch:16 step:15844 [D loss: 0.370168, acc.: 88.28%] [G loss: 1.383844]\n",
      "epoch:16 step:15845 [D loss: 0.344907, acc.: 97.66%] [G loss: 1.617753]\n",
      "epoch:16 step:15846 [D loss: 0.194219, acc.: 97.66%] [G loss: 1.606391]\n",
      "epoch:16 step:15847 [D loss: 0.655944, acc.: 60.94%] [G loss: 0.837296]\n",
      "epoch:16 step:15848 [D loss: 0.581536, acc.: 66.41%] [G loss: 1.115576]\n",
      "epoch:16 step:15849 [D loss: 0.191590, acc.: 99.22%] [G loss: 0.892448]\n",
      "epoch:16 step:15850 [D loss: 0.511609, acc.: 78.12%] [G loss: 1.398398]\n",
      "epoch:16 step:15851 [D loss: 0.535598, acc.: 73.44%] [G loss: 1.320845]\n",
      "epoch:16 step:15852 [D loss: 0.823597, acc.: 43.75%] [G loss: 0.906948]\n",
      "epoch:16 step:15853 [D loss: 0.593636, acc.: 65.62%] [G loss: 1.007666]\n",
      "epoch:16 step:15854 [D loss: 1.200376, acc.: 12.50%] [G loss: 1.122890]\n",
      "epoch:16 step:15855 [D loss: 0.703949, acc.: 57.03%] [G loss: 1.110980]\n",
      "epoch:16 step:15856 [D loss: 0.655313, acc.: 61.72%] [G loss: 1.216122]\n",
      "epoch:16 step:15857 [D loss: 0.860847, acc.: 39.06%] [G loss: 1.282219]\n",
      "epoch:16 step:15858 [D loss: 0.625658, acc.: 67.19%] [G loss: 1.189150]\n",
      "epoch:16 step:15859 [D loss: 0.711730, acc.: 54.69%] [G loss: 1.168334]\n",
      "epoch:16 step:15860 [D loss: 0.626215, acc.: 65.62%] [G loss: 1.237797]\n",
      "epoch:16 step:15861 [D loss: 0.696865, acc.: 59.38%] [G loss: 0.859800]\n",
      "epoch:16 step:15862 [D loss: 0.476846, acc.: 84.38%] [G loss: 1.033250]\n",
      "epoch:16 step:15863 [D loss: 0.531938, acc.: 68.75%] [G loss: 1.055928]\n",
      "epoch:16 step:15864 [D loss: 0.696198, acc.: 57.03%] [G loss: 0.881242]\n",
      "epoch:16 step:15865 [D loss: 0.577651, acc.: 71.09%] [G loss: 1.355578]\n",
      "epoch:16 step:15866 [D loss: 0.602137, acc.: 70.31%] [G loss: 0.881475]\n",
      "epoch:16 step:15867 [D loss: 0.550024, acc.: 71.88%] [G loss: 1.069826]\n",
      "epoch:16 step:15868 [D loss: 0.581877, acc.: 67.19%] [G loss: 1.147227]\n",
      "epoch:16 step:15869 [D loss: 0.381313, acc.: 87.50%] [G loss: 1.281351]\n",
      "epoch:16 step:15870 [D loss: 0.263532, acc.: 89.84%] [G loss: 1.398392]\n",
      "epoch:16 step:15871 [D loss: 0.791582, acc.: 44.53%] [G loss: 1.216830]\n",
      "epoch:16 step:15872 [D loss: 0.892479, acc.: 42.97%] [G loss: 1.203806]\n",
      "epoch:16 step:15873 [D loss: 0.850255, acc.: 44.53%] [G loss: 1.144071]\n",
      "epoch:16 step:15874 [D loss: 0.505136, acc.: 75.78%] [G loss: 0.977121]\n",
      "epoch:16 step:15875 [D loss: 0.500118, acc.: 79.69%] [G loss: 1.001055]\n",
      "epoch:16 step:15876 [D loss: 0.367728, acc.: 81.25%] [G loss: 1.325977]\n",
      "epoch:16 step:15877 [D loss: 0.334527, acc.: 82.81%] [G loss: 1.331465]\n",
      "epoch:16 step:15878 [D loss: 0.341808, acc.: 85.16%] [G loss: 1.400723]\n",
      "epoch:16 step:15879 [D loss: 0.335857, acc.: 88.28%] [G loss: 1.286624]\n",
      "epoch:16 step:15880 [D loss: 1.032291, acc.: 29.69%] [G loss: 1.334471]\n",
      "epoch:16 step:15881 [D loss: 0.337581, acc.: 94.53%] [G loss: 1.395043]\n",
      "epoch:16 step:15882 [D loss: 0.298015, acc.: 94.53%] [G loss: 1.153151]\n",
      "epoch:16 step:15883 [D loss: 0.762092, acc.: 51.56%] [G loss: 0.891278]\n",
      "epoch:16 step:15884 [D loss: 0.660015, acc.: 60.94%] [G loss: 1.298596]\n",
      "epoch:16 step:15885 [D loss: 0.658452, acc.: 60.16%] [G loss: 0.961684]\n",
      "epoch:16 step:15886 [D loss: 0.521744, acc.: 73.44%] [G loss: 1.193410]\n",
      "epoch:16 step:15887 [D loss: 0.592677, acc.: 71.88%] [G loss: 0.932470]\n",
      "epoch:16 step:15888 [D loss: 0.451249, acc.: 88.28%] [G loss: 1.132436]\n",
      "epoch:16 step:15889 [D loss: 0.649023, acc.: 63.28%] [G loss: 1.088623]\n",
      "epoch:16 step:15890 [D loss: 0.411216, acc.: 86.72%] [G loss: 0.522391]\n",
      "epoch:16 step:15891 [D loss: 0.355701, acc.: 85.16%] [G loss: 0.980842]\n",
      "epoch:16 step:15892 [D loss: 0.474098, acc.: 84.38%] [G loss: 1.213712]\n",
      "epoch:16 step:15893 [D loss: 0.557117, acc.: 74.22%] [G loss: 1.451343]\n",
      "epoch:16 step:15894 [D loss: 0.735688, acc.: 58.59%] [G loss: 1.398179]\n",
      "epoch:16 step:15895 [D loss: 0.733647, acc.: 53.12%] [G loss: 0.720512]\n",
      "epoch:16 step:15896 [D loss: 0.618960, acc.: 57.03%] [G loss: 1.452245]\n",
      "epoch:16 step:15897 [D loss: 0.335865, acc.: 90.62%] [G loss: 1.429785]\n",
      "epoch:16 step:15898 [D loss: 0.212970, acc.: 96.09%] [G loss: 1.422942]\n",
      "epoch:16 step:15899 [D loss: 0.891958, acc.: 50.78%] [G loss: 1.527801]\n",
      "epoch:16 step:15900 [D loss: 1.004917, acc.: 28.12%] [G loss: 1.394693]\n",
      "epoch:16 step:15901 [D loss: 0.774792, acc.: 50.00%] [G loss: 1.307318]\n",
      "epoch:16 step:15902 [D loss: 0.412345, acc.: 90.62%] [G loss: 1.018072]\n",
      "epoch:16 step:15903 [D loss: 0.758730, acc.: 47.66%] [G loss: 1.154216]\n",
      "epoch:16 step:15904 [D loss: 0.242641, acc.: 92.97%] [G loss: 1.310427]\n",
      "epoch:16 step:15905 [D loss: 0.780653, acc.: 42.97%] [G loss: 1.414804]\n",
      "epoch:16 step:15906 [D loss: 0.497636, acc.: 77.34%] [G loss: 1.227819]\n",
      "epoch:16 step:15907 [D loss: 0.556008, acc.: 71.88%] [G loss: 1.377310]\n",
      "epoch:16 step:15908 [D loss: 0.283660, acc.: 94.53%] [G loss: 1.229864]\n",
      "epoch:16 step:15909 [D loss: 0.234046, acc.: 94.53%] [G loss: 1.553066]\n",
      "epoch:16 step:15910 [D loss: 0.470073, acc.: 83.59%] [G loss: 1.298919]\n",
      "epoch:16 step:15911 [D loss: 0.707940, acc.: 60.16%] [G loss: 1.158477]\n",
      "epoch:16 step:15912 [D loss: 0.242509, acc.: 90.62%] [G loss: 0.737776]\n",
      "epoch:16 step:15913 [D loss: 0.375141, acc.: 77.34%] [G loss: 1.422273]\n",
      "epoch:16 step:15914 [D loss: 0.482462, acc.: 75.78%] [G loss: 1.302421]\n",
      "epoch:16 step:15915 [D loss: 0.598450, acc.: 64.84%] [G loss: 1.289173]\n",
      "epoch:16 step:15916 [D loss: 0.575684, acc.: 68.75%] [G loss: 1.037215]\n",
      "epoch:16 step:15917 [D loss: 0.682750, acc.: 64.84%] [G loss: 1.250475]\n",
      "epoch:16 step:15918 [D loss: 1.180919, acc.: 43.75%] [G loss: 1.393462]\n",
      "epoch:16 step:15919 [D loss: 0.592899, acc.: 65.62%] [G loss: 1.179502]\n",
      "epoch:16 step:15920 [D loss: 0.644350, acc.: 66.41%] [G loss: 1.370180]\n",
      "epoch:16 step:15921 [D loss: 0.231860, acc.: 91.41%] [G loss: 1.129807]\n",
      "epoch:16 step:15922 [D loss: 0.511451, acc.: 76.56%] [G loss: 1.521293]\n",
      "epoch:16 step:15923 [D loss: 0.546932, acc.: 73.44%] [G loss: 1.290142]\n",
      "epoch:16 step:15924 [D loss: 0.618919, acc.: 65.62%] [G loss: 1.054342]\n",
      "epoch:16 step:15925 [D loss: 0.551412, acc.: 77.34%] [G loss: 1.411289]\n",
      "epoch:16 step:15926 [D loss: 0.343385, acc.: 89.84%] [G loss: 1.290312]\n",
      "epoch:16 step:15927 [D loss: 0.432330, acc.: 84.38%] [G loss: 1.602411]\n",
      "epoch:16 step:15928 [D loss: 0.296692, acc.: 90.62%] [G loss: 1.361855]\n",
      "epoch:16 step:15929 [D loss: 0.221378, acc.: 93.75%] [G loss: 1.300177]\n",
      "epoch:17 step:15930 [D loss: 0.650115, acc.: 71.88%] [G loss: 1.195503]\n",
      "epoch:17 step:15931 [D loss: 0.799628, acc.: 51.56%] [G loss: 1.211894]\n",
      "epoch:17 step:15932 [D loss: 0.583904, acc.: 71.09%] [G loss: 0.944029]\n",
      "epoch:17 step:15933 [D loss: 0.697240, acc.: 58.59%] [G loss: 1.015170]\n",
      "epoch:17 step:15934 [D loss: 0.683152, acc.: 56.25%] [G loss: 1.143980]\n",
      "epoch:17 step:15935 [D loss: 0.522759, acc.: 75.00%] [G loss: 0.998529]\n",
      "epoch:17 step:15936 [D loss: 0.510096, acc.: 75.00%] [G loss: 1.030473]\n",
      "epoch:17 step:15937 [D loss: 0.450236, acc.: 87.50%] [G loss: 0.834790]\n",
      "epoch:17 step:15938 [D loss: 0.376184, acc.: 90.62%] [G loss: 1.192936]\n",
      "epoch:17 step:15939 [D loss: 0.297336, acc.: 89.06%] [G loss: 1.242125]\n",
      "epoch:17 step:15940 [D loss: 0.575142, acc.: 66.41%] [G loss: 1.061944]\n",
      "epoch:17 step:15941 [D loss: 0.530536, acc.: 76.56%] [G loss: 0.678582]\n",
      "epoch:17 step:15942 [D loss: 0.444101, acc.: 85.16%] [G loss: 0.432209]\n",
      "epoch:17 step:15943 [D loss: 0.936768, acc.: 50.78%] [G loss: 0.838156]\n",
      "epoch:17 step:15944 [D loss: 0.466039, acc.: 82.03%] [G loss: 1.658816]\n",
      "epoch:17 step:15945 [D loss: 0.566666, acc.: 69.53%] [G loss: 1.627701]\n",
      "epoch:17 step:15946 [D loss: 0.879831, acc.: 32.81%] [G loss: 0.685364]\n",
      "epoch:17 step:15947 [D loss: 0.643076, acc.: 64.84%] [G loss: 1.641140]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:17 step:15948 [D loss: 0.797890, acc.: 49.22%] [G loss: 0.520483]\n",
      "epoch:17 step:15949 [D loss: 1.043803, acc.: 33.59%] [G loss: 1.082574]\n",
      "epoch:17 step:15950 [D loss: 0.853819, acc.: 39.06%] [G loss: 1.139674]\n",
      "epoch:17 step:15951 [D loss: 0.670680, acc.: 61.72%] [G loss: 0.659652]\n",
      "epoch:17 step:15952 [D loss: 0.822081, acc.: 46.09%] [G loss: 1.172279]\n",
      "epoch:17 step:15953 [D loss: 0.825844, acc.: 46.88%] [G loss: 1.143492]\n",
      "epoch:17 step:15954 [D loss: 0.562452, acc.: 65.62%] [G loss: 0.830743]\n",
      "epoch:17 step:15955 [D loss: 1.296660, acc.: 11.72%] [G loss: 1.541459]\n",
      "epoch:17 step:15956 [D loss: 0.401419, acc.: 85.94%] [G loss: 1.383782]\n",
      "epoch:17 step:15957 [D loss: 0.747009, acc.: 46.88%] [G loss: 1.742074]\n",
      "epoch:17 step:15958 [D loss: 0.639071, acc.: 65.62%] [G loss: 1.559574]\n",
      "epoch:17 step:15959 [D loss: 0.638383, acc.: 61.72%] [G loss: 1.300660]\n",
      "epoch:17 step:15960 [D loss: 0.355843, acc.: 90.62%] [G loss: 1.413619]\n",
      "epoch:17 step:15961 [D loss: 0.307674, acc.: 94.53%] [G loss: 1.336525]\n",
      "epoch:17 step:15962 [D loss: 0.264085, acc.: 94.53%] [G loss: 1.668291]\n",
      "epoch:17 step:15963 [D loss: 0.286858, acc.: 93.75%] [G loss: 1.601340]\n",
      "epoch:17 step:15964 [D loss: 0.117751, acc.: 97.66%] [G loss: 1.819366]\n",
      "epoch:17 step:15965 [D loss: 0.132004, acc.: 97.66%] [G loss: 1.776094]\n",
      "epoch:17 step:15966 [D loss: 0.903839, acc.: 51.56%] [G loss: 1.268254]\n",
      "epoch:17 step:15967 [D loss: 0.843805, acc.: 49.22%] [G loss: 1.053020]\n",
      "epoch:17 step:15968 [D loss: 0.863714, acc.: 47.66%] [G loss: 0.950437]\n",
      "epoch:17 step:15969 [D loss: 0.685272, acc.: 58.59%] [G loss: 1.000497]\n",
      "epoch:17 step:15970 [D loss: 0.568998, acc.: 77.34%] [G loss: 1.002648]\n",
      "epoch:17 step:15971 [D loss: 0.539625, acc.: 71.88%] [G loss: 0.806667]\n",
      "epoch:17 step:15972 [D loss: 0.424970, acc.: 81.25%] [G loss: 1.297097]\n",
      "epoch:17 step:15973 [D loss: 0.533242, acc.: 74.22%] [G loss: 1.181114]\n",
      "epoch:17 step:15974 [D loss: 0.607609, acc.: 71.09%] [G loss: 1.075771]\n",
      "epoch:17 step:15975 [D loss: 0.477558, acc.: 78.12%] [G loss: 0.987141]\n",
      "epoch:17 step:15976 [D loss: 0.720847, acc.: 51.56%] [G loss: 1.076496]\n",
      "epoch:17 step:15977 [D loss: 0.809628, acc.: 38.28%] [G loss: 0.945157]\n",
      "epoch:17 step:15978 [D loss: 0.717585, acc.: 53.91%] [G loss: 1.195328]\n",
      "epoch:17 step:15979 [D loss: 0.514875, acc.: 75.00%] [G loss: 1.035376]\n",
      "epoch:17 step:15980 [D loss: 0.525024, acc.: 78.91%] [G loss: 1.165955]\n",
      "epoch:17 step:15981 [D loss: 0.426542, acc.: 83.59%] [G loss: 1.286798]\n",
      "epoch:17 step:15982 [D loss: 0.587848, acc.: 75.00%] [G loss: 1.022020]\n",
      "epoch:17 step:15983 [D loss: 0.657217, acc.: 60.94%] [G loss: 0.470572]\n",
      "epoch:17 step:15984 [D loss: 0.605341, acc.: 67.97%] [G loss: 0.686198]\n",
      "epoch:17 step:15985 [D loss: 0.670235, acc.: 55.47%] [G loss: 0.626725]\n",
      "epoch:17 step:15986 [D loss: 0.306307, acc.: 85.16%] [G loss: 0.255934]\n",
      "epoch:17 step:15987 [D loss: 0.426188, acc.: 67.97%] [G loss: 0.907064]\n",
      "epoch:17 step:15988 [D loss: 0.774725, acc.: 45.31%] [G loss: 1.260141]\n",
      "epoch:17 step:15989 [D loss: 0.437745, acc.: 74.22%] [G loss: 1.491030]\n",
      "epoch:17 step:15990 [D loss: 0.870489, acc.: 53.91%] [G loss: 1.159631]\n",
      "epoch:17 step:15991 [D loss: 0.697684, acc.: 57.03%] [G loss: 0.389704]\n",
      "epoch:17 step:15992 [D loss: 0.778573, acc.: 44.53%] [G loss: 1.222395]\n",
      "epoch:17 step:15993 [D loss: 0.915752, acc.: 32.81%] [G loss: 1.151213]\n",
      "epoch:17 step:15994 [D loss: 0.768683, acc.: 52.34%] [G loss: 0.593586]\n",
      "epoch:17 step:15995 [D loss: 0.994661, acc.: 28.12%] [G loss: 1.195385]\n",
      "epoch:17 step:15996 [D loss: 0.697817, acc.: 53.91%] [G loss: 1.051335]\n",
      "epoch:17 step:15997 [D loss: 0.823598, acc.: 49.22%] [G loss: 1.381207]\n",
      "epoch:17 step:15998 [D loss: 0.753917, acc.: 49.22%] [G loss: 1.574422]\n",
      "epoch:17 step:15999 [D loss: 0.618656, acc.: 63.28%] [G loss: 2.107383]\n",
      "epoch:17 step:16000 [D loss: 0.504481, acc.: 76.56%] [G loss: 1.371153]\n",
      "##############\n",
      "[4.1450651  2.86918651 6.69410866 6.57928778 4.88725379 6.26486253\n",
      " 5.50908833 5.8545704  6.09622402 5.21084856]\n",
      "##########\n",
      "epoch:17 step:16001 [D loss: 0.757935, acc.: 52.34%] [G loss: 1.374762]\n",
      "epoch:17 step:16002 [D loss: 0.689796, acc.: 59.38%] [G loss: 1.177085]\n",
      "epoch:17 step:16003 [D loss: 0.668103, acc.: 58.59%] [G loss: 1.415920]\n",
      "epoch:17 step:16004 [D loss: 0.714987, acc.: 59.38%] [G loss: 1.071616]\n",
      "epoch:17 step:16005 [D loss: 0.379022, acc.: 89.06%] [G loss: 1.469676]\n",
      "epoch:17 step:16006 [D loss: 0.535757, acc.: 67.97%] [G loss: 1.460363]\n",
      "epoch:17 step:16007 [D loss: 0.937365, acc.: 46.88%] [G loss: 1.224313]\n",
      "epoch:17 step:16008 [D loss: 0.815766, acc.: 45.31%] [G loss: 1.436978]\n",
      "epoch:17 step:16009 [D loss: 0.417249, acc.: 83.59%] [G loss: 1.554274]\n",
      "epoch:17 step:16010 [D loss: 0.479244, acc.: 85.16%] [G loss: 1.383068]\n",
      "epoch:17 step:16011 [D loss: 0.410546, acc.: 91.41%] [G loss: 1.494264]\n",
      "epoch:17 step:16012 [D loss: 0.380789, acc.: 92.19%] [G loss: 2.030216]\n",
      "epoch:17 step:16013 [D loss: 0.567376, acc.: 68.75%] [G loss: 1.392621]\n",
      "epoch:17 step:16014 [D loss: 0.450964, acc.: 85.94%] [G loss: 1.351678]\n",
      "epoch:17 step:16015 [D loss: 0.476308, acc.: 82.03%] [G loss: 1.476946]\n",
      "epoch:17 step:16016 [D loss: 0.461817, acc.: 82.81%] [G loss: 1.551659]\n",
      "epoch:17 step:16017 [D loss: 0.394216, acc.: 87.50%] [G loss: 1.066943]\n",
      "epoch:17 step:16018 [D loss: 0.375519, acc.: 88.28%] [G loss: 1.556023]\n",
      "epoch:17 step:16019 [D loss: 0.438743, acc.: 88.28%] [G loss: 1.172083]\n",
      "epoch:17 step:16020 [D loss: 0.416635, acc.: 88.28%] [G loss: 1.287891]\n",
      "epoch:17 step:16021 [D loss: 0.396013, acc.: 81.25%] [G loss: 2.442870]\n",
      "epoch:17 step:16022 [D loss: 0.258586, acc.: 100.00%] [G loss: 1.194473]\n",
      "epoch:17 step:16023 [D loss: 0.782829, acc.: 50.00%] [G loss: 1.444885]\n",
      "epoch:17 step:16024 [D loss: 0.849219, acc.: 55.47%] [G loss: 1.270898]\n",
      "epoch:17 step:16025 [D loss: 0.536110, acc.: 73.44%] [G loss: 1.114381]\n",
      "epoch:17 step:16026 [D loss: 0.541044, acc.: 75.00%] [G loss: 0.669150]\n",
      "epoch:17 step:16027 [D loss: 0.820873, acc.: 42.19%] [G loss: 0.779206]\n",
      "epoch:17 step:16028 [D loss: 0.738507, acc.: 58.59%] [G loss: 0.572132]\n",
      "epoch:17 step:16029 [D loss: 0.850720, acc.: 42.19%] [G loss: 0.670352]\n",
      "epoch:17 step:16030 [D loss: 0.582830, acc.: 67.19%] [G loss: 0.854951]\n",
      "epoch:17 step:16031 [D loss: 0.687124, acc.: 60.94%] [G loss: 0.656229]\n",
      "epoch:17 step:16032 [D loss: 0.811877, acc.: 47.66%] [G loss: 0.801467]\n",
      "epoch:17 step:16033 [D loss: 0.732814, acc.: 57.81%] [G loss: 1.289867]\n",
      "epoch:17 step:16034 [D loss: 0.781700, acc.: 42.19%] [G loss: 0.866027]\n",
      "epoch:17 step:16035 [D loss: 0.739977, acc.: 52.34%] [G loss: 0.817327]\n",
      "epoch:17 step:16036 [D loss: 0.526004, acc.: 70.31%] [G loss: 0.817503]\n",
      "epoch:17 step:16037 [D loss: 0.652362, acc.: 60.16%] [G loss: 1.121503]\n",
      "epoch:17 step:16038 [D loss: 0.670500, acc.: 59.38%] [G loss: 1.187728]\n",
      "epoch:17 step:16039 [D loss: 0.755315, acc.: 48.44%] [G loss: 1.111780]\n",
      "epoch:17 step:16040 [D loss: 0.583798, acc.: 68.75%] [G loss: 0.880657]\n",
      "epoch:17 step:16041 [D loss: 0.552226, acc.: 71.88%] [G loss: 1.091386]\n",
      "epoch:17 step:16042 [D loss: 0.582471, acc.: 69.53%] [G loss: 1.114775]\n",
      "epoch:17 step:16043 [D loss: 0.754505, acc.: 61.72%] [G loss: 1.120304]\n",
      "epoch:17 step:16044 [D loss: 0.468841, acc.: 82.03%] [G loss: 1.221524]\n",
      "epoch:17 step:16045 [D loss: 0.740252, acc.: 54.69%] [G loss: 0.971635]\n",
      "epoch:17 step:16046 [D loss: 0.643840, acc.: 63.28%] [G loss: 1.183823]\n",
      "epoch:17 step:16047 [D loss: 0.490484, acc.: 80.47%] [G loss: 1.135042]\n",
      "epoch:17 step:16048 [D loss: 0.273405, acc.: 92.19%] [G loss: 1.480471]\n",
      "epoch:17 step:16049 [D loss: 0.910330, acc.: 53.12%] [G loss: 1.066891]\n",
      "epoch:17 step:16050 [D loss: 0.608393, acc.: 69.53%] [G loss: 0.967497]\n",
      "epoch:17 step:16051 [D loss: 0.703161, acc.: 57.81%] [G loss: 0.640324]\n",
      "epoch:17 step:16052 [D loss: 0.821094, acc.: 37.50%] [G loss: 1.043343]\n",
      "epoch:17 step:16053 [D loss: 0.649042, acc.: 58.59%] [G loss: 1.060649]\n",
      "epoch:17 step:16054 [D loss: 0.751006, acc.: 50.00%] [G loss: 0.974830]\n",
      "epoch:17 step:16055 [D loss: 0.688449, acc.: 57.81%] [G loss: 1.120702]\n",
      "epoch:17 step:16056 [D loss: 0.766552, acc.: 51.56%] [G loss: 1.085190]\n",
      "epoch:17 step:16057 [D loss: 0.754847, acc.: 52.34%] [G loss: 0.980021]\n",
      "epoch:17 step:16058 [D loss: 0.696472, acc.: 53.12%] [G loss: 1.041162]\n",
      "epoch:17 step:16059 [D loss: 0.619051, acc.: 69.53%] [G loss: 0.998960]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:17 step:16060 [D loss: 0.635274, acc.: 62.50%] [G loss: 0.965508]\n",
      "epoch:17 step:16061 [D loss: 0.602941, acc.: 66.41%] [G loss: 0.942093]\n",
      "epoch:17 step:16062 [D loss: 0.579995, acc.: 67.97%] [G loss: 1.037355]\n",
      "epoch:17 step:16063 [D loss: 0.383424, acc.: 86.72%] [G loss: 1.258300]\n",
      "epoch:17 step:16064 [D loss: 0.516674, acc.: 78.12%] [G loss: 1.134911]\n",
      "epoch:17 step:16065 [D loss: 0.652108, acc.: 62.50%] [G loss: 1.120066]\n",
      "epoch:17 step:16066 [D loss: 0.694028, acc.: 60.16%] [G loss: 1.014571]\n",
      "epoch:17 step:16067 [D loss: 0.648544, acc.: 60.94%] [G loss: 0.852504]\n",
      "epoch:17 step:16068 [D loss: 0.662102, acc.: 57.81%] [G loss: 0.904231]\n",
      "epoch:17 step:16069 [D loss: 0.418418, acc.: 85.16%] [G loss: 1.049919]\n",
      "epoch:17 step:16070 [D loss: 0.461296, acc.: 80.47%] [G loss: 1.139650]\n",
      "epoch:17 step:16071 [D loss: 0.574948, acc.: 72.66%] [G loss: 1.110112]\n",
      "epoch:17 step:16072 [D loss: 0.291985, acc.: 90.62%] [G loss: 1.281453]\n",
      "epoch:17 step:16073 [D loss: 0.422054, acc.: 86.72%] [G loss: 1.336157]\n",
      "epoch:17 step:16074 [D loss: 0.246579, acc.: 96.09%] [G loss: 1.164586]\n",
      "epoch:17 step:16075 [D loss: 0.415841, acc.: 88.28%] [G loss: 1.351078]\n",
      "epoch:17 step:16076 [D loss: 0.619948, acc.: 67.97%] [G loss: 1.010215]\n",
      "epoch:17 step:16077 [D loss: 0.642438, acc.: 61.72%] [G loss: 0.688706]\n",
      "epoch:17 step:16078 [D loss: 0.246577, acc.: 89.84%] [G loss: 1.293162]\n",
      "epoch:17 step:16079 [D loss: 0.190258, acc.: 97.66%] [G loss: 1.341526]\n",
      "epoch:17 step:16080 [D loss: 0.265437, acc.: 94.53%] [G loss: 0.864707]\n",
      "epoch:17 step:16081 [D loss: 0.381891, acc.: 92.97%] [G loss: 1.308753]\n",
      "epoch:17 step:16082 [D loss: 0.819067, acc.: 44.53%] [G loss: 1.090932]\n",
      "epoch:17 step:16083 [D loss: 0.770137, acc.: 50.00%] [G loss: 1.272407]\n",
      "epoch:17 step:16084 [D loss: 0.545609, acc.: 71.09%] [G loss: 1.041856]\n",
      "epoch:17 step:16085 [D loss: 0.970195, acc.: 34.38%] [G loss: 0.833790]\n",
      "epoch:17 step:16086 [D loss: 0.677698, acc.: 61.72%] [G loss: 1.173914]\n",
      "epoch:17 step:16087 [D loss: 0.703091, acc.: 54.69%] [G loss: 0.817357]\n",
      "epoch:17 step:16088 [D loss: 0.831914, acc.: 42.97%] [G loss: 0.972488]\n",
      "epoch:17 step:16089 [D loss: 0.538855, acc.: 77.34%] [G loss: 0.928151]\n",
      "epoch:17 step:16090 [D loss: 0.763524, acc.: 51.56%] [G loss: 1.141891]\n",
      "epoch:17 step:16091 [D loss: 0.442416, acc.: 90.62%] [G loss: 1.130876]\n",
      "epoch:17 step:16092 [D loss: 0.469295, acc.: 74.22%] [G loss: 1.039132]\n",
      "epoch:17 step:16093 [D loss: 1.358991, acc.: 50.78%] [G loss: 1.033799]\n",
      "epoch:17 step:16094 [D loss: 0.602113, acc.: 67.97%] [G loss: 1.132563]\n",
      "epoch:17 step:16095 [D loss: 0.742761, acc.: 53.12%] [G loss: 1.308209]\n",
      "epoch:17 step:16096 [D loss: 0.721262, acc.: 50.78%] [G loss: 1.149835]\n",
      "epoch:17 step:16097 [D loss: 0.759158, acc.: 49.22%] [G loss: 1.091092]\n",
      "epoch:17 step:16098 [D loss: 0.641195, acc.: 65.62%] [G loss: 0.909078]\n",
      "epoch:17 step:16099 [D loss: 0.553712, acc.: 71.09%] [G loss: 0.685004]\n",
      "epoch:17 step:16100 [D loss: 0.691538, acc.: 58.59%] [G loss: 0.875114]\n",
      "epoch:17 step:16101 [D loss: 0.518659, acc.: 78.91%] [G loss: 0.953654]\n",
      "epoch:17 step:16102 [D loss: 0.653768, acc.: 60.16%] [G loss: 0.844489]\n",
      "epoch:17 step:16103 [D loss: 0.698889, acc.: 56.25%] [G loss: 0.958964]\n",
      "epoch:17 step:16104 [D loss: 0.627698, acc.: 67.97%] [G loss: 0.812514]\n",
      "epoch:17 step:16105 [D loss: 0.904552, acc.: 39.06%] [G loss: 0.780471]\n",
      "epoch:17 step:16106 [D loss: 0.694625, acc.: 50.78%] [G loss: 0.918093]\n",
      "epoch:17 step:16107 [D loss: 0.534788, acc.: 77.34%] [G loss: 1.081986]\n",
      "epoch:17 step:16108 [D loss: 0.669127, acc.: 57.81%] [G loss: 0.930247]\n",
      "epoch:17 step:16109 [D loss: 0.798688, acc.: 42.97%] [G loss: 0.842789]\n",
      "epoch:17 step:16110 [D loss: 0.672905, acc.: 64.06%] [G loss: 0.814078]\n",
      "epoch:17 step:16111 [D loss: 0.642098, acc.: 58.59%] [G loss: 1.091991]\n",
      "epoch:17 step:16112 [D loss: 0.717908, acc.: 53.12%] [G loss: 0.752844]\n",
      "epoch:17 step:16113 [D loss: 0.698943, acc.: 50.00%] [G loss: 1.005744]\n",
      "epoch:17 step:16114 [D loss: 0.681276, acc.: 55.47%] [G loss: 1.031752]\n",
      "epoch:17 step:16115 [D loss: 0.721808, acc.: 50.78%] [G loss: 1.106177]\n",
      "epoch:17 step:16116 [D loss: 0.650942, acc.: 54.69%] [G loss: 1.062903]\n",
      "epoch:17 step:16117 [D loss: 0.582945, acc.: 64.06%] [G loss: 1.088518]\n",
      "epoch:17 step:16118 [D loss: 0.607595, acc.: 64.84%] [G loss: 1.218031]\n",
      "epoch:17 step:16119 [D loss: 0.577493, acc.: 70.31%] [G loss: 1.154781]\n",
      "epoch:17 step:16120 [D loss: 0.654986, acc.: 58.59%] [G loss: 1.123103]\n",
      "epoch:17 step:16121 [D loss: 0.497247, acc.: 84.38%] [G loss: 1.437625]\n",
      "epoch:17 step:16122 [D loss: 0.540831, acc.: 70.31%] [G loss: 0.908507]\n",
      "epoch:17 step:16123 [D loss: 0.379184, acc.: 90.62%] [G loss: 1.123419]\n",
      "epoch:17 step:16124 [D loss: 0.553194, acc.: 74.22%] [G loss: 1.204163]\n",
      "epoch:17 step:16125 [D loss: 0.526568, acc.: 72.66%] [G loss: 1.176517]\n",
      "epoch:17 step:16126 [D loss: 0.517748, acc.: 76.56%] [G loss: 1.070042]\n",
      "epoch:17 step:16127 [D loss: 0.443831, acc.: 85.16%] [G loss: 1.373572]\n",
      "epoch:17 step:16128 [D loss: 0.654146, acc.: 57.81%] [G loss: 1.228685]\n",
      "epoch:17 step:16129 [D loss: 0.457558, acc.: 85.94%] [G loss: 1.302144]\n",
      "epoch:17 step:16130 [D loss: 0.355437, acc.: 90.62%] [G loss: 1.084212]\n",
      "epoch:17 step:16131 [D loss: 0.634299, acc.: 60.94%] [G loss: 1.246020]\n",
      "epoch:17 step:16132 [D loss: 0.481490, acc.: 85.94%] [G loss: 0.790851]\n",
      "epoch:17 step:16133 [D loss: 0.410798, acc.: 89.06%] [G loss: 1.452103]\n",
      "epoch:17 step:16134 [D loss: 0.465983, acc.: 86.72%] [G loss: 1.017394]\n",
      "epoch:17 step:16135 [D loss: 0.407287, acc.: 85.94%] [G loss: 0.924836]\n",
      "epoch:17 step:16136 [D loss: 0.327357, acc.: 92.97%] [G loss: 1.542176]\n",
      "epoch:17 step:16137 [D loss: 0.328854, acc.: 95.31%] [G loss: 1.371231]\n",
      "epoch:17 step:16138 [D loss: 0.442086, acc.: 83.59%] [G loss: 1.515166]\n",
      "epoch:17 step:16139 [D loss: 1.178971, acc.: 37.50%] [G loss: 0.724027]\n",
      "epoch:17 step:16140 [D loss: 1.109069, acc.: 14.84%] [G loss: 1.256962]\n",
      "epoch:17 step:16141 [D loss: 0.791974, acc.: 50.78%] [G loss: 0.836987]\n",
      "epoch:17 step:16142 [D loss: 0.680201, acc.: 57.81%] [G loss: 0.851599]\n",
      "epoch:17 step:16143 [D loss: 0.772764, acc.: 45.31%] [G loss: 0.850748]\n",
      "epoch:17 step:16144 [D loss: 0.740727, acc.: 50.78%] [G loss: 0.780186]\n",
      "epoch:17 step:16145 [D loss: 0.871019, acc.: 42.19%] [G loss: 1.012826]\n",
      "epoch:17 step:16146 [D loss: 0.560963, acc.: 71.09%] [G loss: 1.025297]\n",
      "epoch:17 step:16147 [D loss: 0.500455, acc.: 75.00%] [G loss: 0.975326]\n",
      "epoch:17 step:16148 [D loss: 0.417580, acc.: 90.62%] [G loss: 1.249188]\n",
      "epoch:17 step:16149 [D loss: 0.434040, acc.: 75.00%] [G loss: 1.013686]\n",
      "epoch:17 step:16150 [D loss: 0.361900, acc.: 82.81%] [G loss: 1.328470]\n",
      "epoch:17 step:16151 [D loss: 0.527767, acc.: 75.00%] [G loss: 1.444558]\n",
      "epoch:17 step:16152 [D loss: 0.551070, acc.: 74.22%] [G loss: 1.443035]\n",
      "epoch:17 step:16153 [D loss: 0.716968, acc.: 57.81%] [G loss: 1.188275]\n",
      "epoch:17 step:16154 [D loss: 0.553779, acc.: 71.09%] [G loss: 0.925328]\n",
      "epoch:17 step:16155 [D loss: 0.797694, acc.: 51.56%] [G loss: 1.265839]\n",
      "epoch:17 step:16156 [D loss: 0.548531, acc.: 72.66%] [G loss: 1.403261]\n",
      "epoch:17 step:16157 [D loss: 0.634220, acc.: 57.81%] [G loss: 1.465176]\n",
      "epoch:17 step:16158 [D loss: 0.594408, acc.: 73.44%] [G loss: 1.212838]\n",
      "epoch:17 step:16159 [D loss: 0.248452, acc.: 89.06%] [G loss: 1.256177]\n",
      "epoch:17 step:16160 [D loss: 0.326157, acc.: 88.28%] [G loss: 1.606438]\n",
      "epoch:17 step:16161 [D loss: 0.220439, acc.: 95.31%] [G loss: 1.600004]\n",
      "epoch:17 step:16162 [D loss: 0.634909, acc.: 64.84%] [G loss: 1.348302]\n",
      "epoch:17 step:16163 [D loss: 0.374155, acc.: 88.28%] [G loss: 1.084560]\n",
      "epoch:17 step:16164 [D loss: 0.321317, acc.: 93.75%] [G loss: 1.460680]\n",
      "epoch:17 step:16165 [D loss: 0.629333, acc.: 71.09%] [G loss: 1.056988]\n",
      "epoch:17 step:16166 [D loss: 0.439203, acc.: 82.81%] [G loss: 1.051185]\n",
      "epoch:17 step:16167 [D loss: 0.431613, acc.: 78.12%] [G loss: 1.282637]\n",
      "epoch:17 step:16168 [D loss: 0.675960, acc.: 61.72%] [G loss: 1.064596]\n",
      "epoch:17 step:16169 [D loss: 0.685263, acc.: 60.94%] [G loss: 0.758507]\n",
      "epoch:17 step:16170 [D loss: 0.961175, acc.: 35.94%] [G loss: 0.854603]\n",
      "epoch:17 step:16171 [D loss: 0.643698, acc.: 66.41%] [G loss: 0.782294]\n",
      "epoch:17 step:16172 [D loss: 0.640938, acc.: 63.28%] [G loss: 1.133924]\n",
      "epoch:17 step:16173 [D loss: 0.660933, acc.: 61.72%] [G loss: 1.208068]\n",
      "epoch:17 step:16174 [D loss: 0.739919, acc.: 53.12%] [G loss: 0.905773]\n",
      "epoch:17 step:16175 [D loss: 0.857111, acc.: 38.28%] [G loss: 1.018232]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:17 step:16176 [D loss: 0.623607, acc.: 62.50%] [G loss: 1.092264]\n",
      "epoch:17 step:16177 [D loss: 0.575889, acc.: 71.88%] [G loss: 0.971006]\n",
      "epoch:17 step:16178 [D loss: 0.596746, acc.: 69.53%] [G loss: 0.923928]\n",
      "epoch:17 step:16179 [D loss: 0.711585, acc.: 46.88%] [G loss: 0.806645]\n",
      "epoch:17 step:16180 [D loss: 0.559969, acc.: 70.31%] [G loss: 1.080652]\n",
      "epoch:17 step:16181 [D loss: 0.637487, acc.: 60.94%] [G loss: 1.042192]\n",
      "epoch:17 step:16182 [D loss: 0.641063, acc.: 64.06%] [G loss: 0.620089]\n",
      "epoch:17 step:16183 [D loss: 0.910389, acc.: 46.09%] [G loss: 1.041526]\n",
      "epoch:17 step:16184 [D loss: 0.396928, acc.: 90.62%] [G loss: 1.135398]\n",
      "epoch:17 step:16185 [D loss: 0.277664, acc.: 90.62%] [G loss: 1.135974]\n",
      "epoch:17 step:16186 [D loss: 0.566689, acc.: 71.09%] [G loss: 1.144677]\n",
      "epoch:17 step:16187 [D loss: 1.066633, acc.: 32.03%] [G loss: 1.046798]\n",
      "epoch:17 step:16188 [D loss: 0.345286, acc.: 80.47%] [G loss: 1.263983]\n",
      "epoch:17 step:16189 [D loss: 0.344937, acc.: 90.62%] [G loss: 1.304782]\n",
      "epoch:17 step:16190 [D loss: 0.297227, acc.: 95.31%] [G loss: 1.417555]\n",
      "epoch:17 step:16191 [D loss: 0.630450, acc.: 60.16%] [G loss: 1.238255]\n",
      "epoch:17 step:16192 [D loss: 0.757618, acc.: 50.00%] [G loss: 0.933141]\n",
      "epoch:17 step:16193 [D loss: 0.682297, acc.: 62.50%] [G loss: 1.052850]\n",
      "epoch:17 step:16194 [D loss: 0.476859, acc.: 83.59%] [G loss: 0.489016]\n",
      "epoch:17 step:16195 [D loss: 0.656350, acc.: 57.03%] [G loss: 1.121330]\n",
      "epoch:17 step:16196 [D loss: 0.573087, acc.: 69.53%] [G loss: 1.054988]\n",
      "epoch:17 step:16197 [D loss: 0.681657, acc.: 53.12%] [G loss: 1.037679]\n",
      "epoch:17 step:16198 [D loss: 0.670739, acc.: 64.06%] [G loss: 1.088234]\n",
      "epoch:17 step:16199 [D loss: 0.615453, acc.: 64.06%] [G loss: 1.110726]\n",
      "epoch:17 step:16200 [D loss: 0.536675, acc.: 71.88%] [G loss: 1.036988]\n",
      "##############\n",
      "[4.28634192 2.69481946 6.6738316  5.49359023 4.60184238 6.02191475\n",
      " 5.03599702 5.54396807 5.92198013 4.91288092]\n",
      "##########\n",
      "epoch:17 step:16201 [D loss: 0.555918, acc.: 75.78%] [G loss: 1.055361]\n",
      "epoch:17 step:16202 [D loss: 0.610820, acc.: 70.31%] [G loss: 0.815828]\n",
      "epoch:17 step:16203 [D loss: 0.604832, acc.: 68.75%] [G loss: 1.635342]\n",
      "epoch:17 step:16204 [D loss: 0.562623, acc.: 68.75%] [G loss: 0.942518]\n",
      "epoch:17 step:16205 [D loss: 0.524244, acc.: 75.00%] [G loss: 1.012519]\n",
      "epoch:17 step:16206 [D loss: 0.688148, acc.: 58.59%] [G loss: 0.863173]\n",
      "epoch:17 step:16207 [D loss: 0.442632, acc.: 78.91%] [G loss: 1.329577]\n",
      "epoch:17 step:16208 [D loss: 0.249517, acc.: 91.41%] [G loss: 1.272465]\n",
      "epoch:17 step:16209 [D loss: 0.556175, acc.: 71.88%] [G loss: 1.143730]\n",
      "epoch:17 step:16210 [D loss: 0.743830, acc.: 57.03%] [G loss: 1.233659]\n",
      "epoch:17 step:16211 [D loss: 0.606462, acc.: 67.19%] [G loss: 0.951177]\n",
      "epoch:17 step:16212 [D loss: 0.652021, acc.: 64.06%] [G loss: 0.834667]\n",
      "epoch:17 step:16213 [D loss: 0.659814, acc.: 64.84%] [G loss: 0.829699]\n",
      "epoch:17 step:16214 [D loss: 0.667797, acc.: 64.84%] [G loss: 1.038295]\n",
      "epoch:17 step:16215 [D loss: 0.562041, acc.: 74.22%] [G loss: 1.202403]\n",
      "epoch:17 step:16216 [D loss: 0.394063, acc.: 82.81%] [G loss: 0.802459]\n",
      "epoch:17 step:16217 [D loss: 0.388138, acc.: 89.84%] [G loss: 1.082773]\n",
      "epoch:17 step:16218 [D loss: 0.258399, acc.: 92.19%] [G loss: 1.409740]\n",
      "epoch:17 step:16219 [D loss: 0.511097, acc.: 69.53%] [G loss: 1.455141]\n",
      "epoch:17 step:16220 [D loss: 0.638018, acc.: 61.72%] [G loss: 0.912865]\n",
      "epoch:17 step:16221 [D loss: 0.365218, acc.: 85.94%] [G loss: 1.478604]\n",
      "epoch:17 step:16222 [D loss: 0.284232, acc.: 92.97%] [G loss: 1.486141]\n",
      "epoch:17 step:16223 [D loss: 0.627773, acc.: 69.53%] [G loss: 1.463215]\n",
      "epoch:17 step:16224 [D loss: 0.838977, acc.: 48.44%] [G loss: 1.169827]\n",
      "epoch:17 step:16225 [D loss: 0.671161, acc.: 58.59%] [G loss: 1.133792]\n",
      "epoch:17 step:16226 [D loss: 0.646682, acc.: 59.38%] [G loss: 1.099443]\n",
      "epoch:17 step:16227 [D loss: 0.599387, acc.: 69.53%] [G loss: 0.998894]\n",
      "epoch:17 step:16228 [D loss: 0.507266, acc.: 79.69%] [G loss: 0.314359]\n",
      "epoch:17 step:16229 [D loss: 0.624577, acc.: 64.06%] [G loss: 0.917847]\n",
      "epoch:17 step:16230 [D loss: 0.690633, acc.: 59.38%] [G loss: 1.079551]\n",
      "epoch:17 step:16231 [D loss: 0.674342, acc.: 58.59%] [G loss: 1.023977]\n",
      "epoch:17 step:16232 [D loss: 1.302483, acc.: 32.81%] [G loss: 1.147305]\n",
      "epoch:17 step:16233 [D loss: 1.215410, acc.: 25.78%] [G loss: 1.146985]\n",
      "epoch:17 step:16234 [D loss: 0.636978, acc.: 68.75%] [G loss: 1.569816]\n",
      "epoch:17 step:16235 [D loss: 0.719543, acc.: 53.91%] [G loss: 1.326279]\n",
      "epoch:17 step:16236 [D loss: 0.577043, acc.: 74.22%] [G loss: 1.150909]\n",
      "epoch:17 step:16237 [D loss: 0.681580, acc.: 58.59%] [G loss: 1.049700]\n",
      "epoch:17 step:16238 [D loss: 0.313338, acc.: 87.50%] [G loss: 1.088011]\n",
      "epoch:17 step:16239 [D loss: 0.678339, acc.: 57.03%] [G loss: 1.120430]\n",
      "epoch:17 step:16240 [D loss: 0.742913, acc.: 55.47%] [G loss: 0.864889]\n",
      "epoch:17 step:16241 [D loss: 0.364976, acc.: 85.94%] [G loss: 0.904291]\n",
      "epoch:17 step:16242 [D loss: 0.294569, acc.: 90.62%] [G loss: 1.071554]\n",
      "epoch:17 step:16243 [D loss: 0.222615, acc.: 95.31%] [G loss: 1.164564]\n",
      "epoch:17 step:16244 [D loss: 0.598764, acc.: 67.97%] [G loss: 1.449839]\n",
      "epoch:17 step:16245 [D loss: 0.652959, acc.: 68.75%] [G loss: 1.097340]\n",
      "epoch:17 step:16246 [D loss: 0.802066, acc.: 50.78%] [G loss: 1.131807]\n",
      "epoch:17 step:16247 [D loss: 0.674984, acc.: 58.59%] [G loss: 1.246670]\n",
      "epoch:17 step:16248 [D loss: 0.668313, acc.: 58.59%] [G loss: 1.029810]\n",
      "epoch:17 step:16249 [D loss: 0.666220, acc.: 57.03%] [G loss: 0.982107]\n",
      "epoch:17 step:16250 [D loss: 0.707940, acc.: 53.91%] [G loss: 1.129333]\n",
      "epoch:17 step:16251 [D loss: 0.627812, acc.: 59.38%] [G loss: 1.204002]\n",
      "epoch:17 step:16252 [D loss: 0.664318, acc.: 63.28%] [G loss: 0.897680]\n",
      "epoch:17 step:16253 [D loss: 0.726790, acc.: 53.12%] [G loss: 1.006051]\n",
      "epoch:17 step:16254 [D loss: 0.573193, acc.: 71.88%] [G loss: 0.928271]\n",
      "epoch:17 step:16255 [D loss: 0.683401, acc.: 57.81%] [G loss: 0.991129]\n",
      "epoch:17 step:16256 [D loss: 0.436718, acc.: 85.16%] [G loss: 1.102504]\n",
      "epoch:17 step:16257 [D loss: 0.392014, acc.: 92.97%] [G loss: 0.942844]\n",
      "epoch:17 step:16258 [D loss: 0.630934, acc.: 64.06%] [G loss: 1.036267]\n",
      "epoch:17 step:16259 [D loss: 0.697340, acc.: 55.47%] [G loss: 1.065996]\n",
      "epoch:17 step:16260 [D loss: 0.694111, acc.: 58.59%] [G loss: 0.879138]\n",
      "epoch:17 step:16261 [D loss: 0.691965, acc.: 60.16%] [G loss: 0.713712]\n",
      "epoch:17 step:16262 [D loss: 0.372228, acc.: 89.84%] [G loss: 0.999119]\n",
      "epoch:17 step:16263 [D loss: 0.287492, acc.: 94.53%] [G loss: 1.196256]\n",
      "epoch:17 step:16264 [D loss: 0.493295, acc.: 78.91%] [G loss: 0.931309]\n",
      "epoch:17 step:16265 [D loss: 0.297296, acc.: 91.41%] [G loss: 1.262372]\n",
      "epoch:17 step:16266 [D loss: 0.699264, acc.: 56.25%] [G loss: 1.158399]\n",
      "epoch:17 step:16267 [D loss: 0.490076, acc.: 82.81%] [G loss: 1.192525]\n",
      "epoch:17 step:16268 [D loss: 0.632895, acc.: 64.84%] [G loss: 0.607235]\n",
      "epoch:17 step:16269 [D loss: 0.769363, acc.: 49.22%] [G loss: 0.977594]\n",
      "epoch:17 step:16270 [D loss: 0.738598, acc.: 49.22%] [G loss: 0.992764]\n",
      "epoch:17 step:16271 [D loss: 0.423680, acc.: 78.12%] [G loss: 1.148742]\n",
      "epoch:17 step:16272 [D loss: 0.601271, acc.: 59.38%] [G loss: 1.150098]\n",
      "epoch:17 step:16273 [D loss: 0.536346, acc.: 70.31%] [G loss: 1.345269]\n",
      "epoch:17 step:16274 [D loss: 0.477707, acc.: 78.12%] [G loss: 1.084170]\n",
      "epoch:17 step:16275 [D loss: 0.284426, acc.: 93.75%] [G loss: 1.427626]\n",
      "epoch:17 step:16276 [D loss: 0.237891, acc.: 96.09%] [G loss: 1.667131]\n",
      "epoch:17 step:16277 [D loss: 0.740396, acc.: 53.12%] [G loss: 1.456746]\n",
      "epoch:17 step:16278 [D loss: 0.748182, acc.: 53.91%] [G loss: 1.048043]\n",
      "epoch:17 step:16279 [D loss: 0.447468, acc.: 88.28%] [G loss: 1.169930]\n",
      "epoch:17 step:16280 [D loss: 0.628715, acc.: 65.62%] [G loss: 1.205501]\n",
      "epoch:17 step:16281 [D loss: 0.571222, acc.: 70.31%] [G loss: 1.212272]\n",
      "epoch:17 step:16282 [D loss: 0.577984, acc.: 66.41%] [G loss: 1.209728]\n",
      "epoch:17 step:16283 [D loss: 0.535947, acc.: 77.34%] [G loss: 1.115510]\n",
      "epoch:17 step:16284 [D loss: 0.851060, acc.: 35.94%] [G loss: 1.276672]\n",
      "epoch:17 step:16285 [D loss: 0.591556, acc.: 71.09%] [G loss: 1.143296]\n",
      "epoch:17 step:16286 [D loss: 0.486917, acc.: 79.69%] [G loss: 1.245605]\n",
      "epoch:17 step:16287 [D loss: 0.365660, acc.: 92.19%] [G loss: 0.990203]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:17 step:16288 [D loss: 0.492761, acc.: 77.34%] [G loss: 1.251920]\n",
      "epoch:17 step:16289 [D loss: 0.630557, acc.: 64.06%] [G loss: 1.186984]\n",
      "epoch:17 step:16290 [D loss: 0.509789, acc.: 79.69%] [G loss: 1.398615]\n",
      "epoch:17 step:16291 [D loss: 0.771167, acc.: 52.34%] [G loss: 0.910758]\n",
      "epoch:17 step:16292 [D loss: 0.632805, acc.: 62.50%] [G loss: 1.024820]\n",
      "epoch:17 step:16293 [D loss: 0.569139, acc.: 71.09%] [G loss: 0.721208]\n",
      "epoch:17 step:16294 [D loss: 0.656084, acc.: 63.28%] [G loss: 0.865973]\n",
      "epoch:17 step:16295 [D loss: 0.510564, acc.: 73.44%] [G loss: 1.045692]\n",
      "epoch:17 step:16296 [D loss: 0.714737, acc.: 55.47%] [G loss: 0.977573]\n",
      "epoch:17 step:16297 [D loss: 0.831007, acc.: 47.66%] [G loss: 1.043422]\n",
      "epoch:17 step:16298 [D loss: 0.732245, acc.: 50.78%] [G loss: 0.990079]\n",
      "epoch:17 step:16299 [D loss: 0.500428, acc.: 78.91%] [G loss: 0.843936]\n",
      "epoch:17 step:16300 [D loss: 0.531038, acc.: 71.88%] [G loss: 1.097000]\n",
      "epoch:17 step:16301 [D loss: 0.615446, acc.: 62.50%] [G loss: 0.914474]\n",
      "epoch:17 step:16302 [D loss: 0.871078, acc.: 43.75%] [G loss: 0.645285]\n",
      "epoch:17 step:16303 [D loss: 0.681345, acc.: 56.25%] [G loss: 0.948866]\n",
      "epoch:17 step:16304 [D loss: 0.684607, acc.: 60.94%] [G loss: 1.247003]\n",
      "epoch:17 step:16305 [D loss: 0.703999, acc.: 52.34%] [G loss: 0.811883]\n",
      "epoch:17 step:16306 [D loss: 0.486540, acc.: 79.69%] [G loss: 1.254271]\n",
      "epoch:17 step:16307 [D loss: 0.348028, acc.: 89.84%] [G loss: 1.145899]\n",
      "epoch:17 step:16308 [D loss: 0.766637, acc.: 51.56%] [G loss: 1.124315]\n",
      "epoch:17 step:16309 [D loss: 0.510306, acc.: 84.38%] [G loss: 1.082308]\n",
      "epoch:17 step:16310 [D loss: 0.571709, acc.: 75.78%] [G loss: 0.889577]\n",
      "epoch:17 step:16311 [D loss: 0.642674, acc.: 62.50%] [G loss: 1.003784]\n",
      "epoch:17 step:16312 [D loss: 0.765161, acc.: 51.56%] [G loss: 0.958430]\n",
      "epoch:17 step:16313 [D loss: 0.553161, acc.: 72.66%] [G loss: 1.252589]\n",
      "epoch:17 step:16314 [D loss: 0.673390, acc.: 57.03%] [G loss: 1.025236]\n",
      "epoch:17 step:16315 [D loss: 0.686292, acc.: 60.94%] [G loss: 0.992455]\n",
      "epoch:17 step:16316 [D loss: 0.621384, acc.: 67.19%] [G loss: 0.974056]\n",
      "epoch:17 step:16317 [D loss: 0.584654, acc.: 68.75%] [G loss: 0.958417]\n",
      "epoch:17 step:16318 [D loss: 0.529334, acc.: 76.56%] [G loss: 0.877828]\n",
      "epoch:17 step:16319 [D loss: 0.571781, acc.: 71.88%] [G loss: 0.950978]\n",
      "epoch:17 step:16320 [D loss: 0.721650, acc.: 57.03%] [G loss: 0.988094]\n",
      "epoch:17 step:16321 [D loss: 0.961591, acc.: 31.25%] [G loss: 1.054933]\n",
      "epoch:17 step:16322 [D loss: 0.469396, acc.: 83.59%] [G loss: 1.108262]\n",
      "epoch:17 step:16323 [D loss: 0.649475, acc.: 60.16%] [G loss: 1.043800]\n",
      "epoch:17 step:16324 [D loss: 0.776108, acc.: 48.44%] [G loss: 1.017314]\n",
      "epoch:17 step:16325 [D loss: 0.275899, acc.: 88.28%] [G loss: 1.208892]\n",
      "epoch:17 step:16326 [D loss: 0.245455, acc.: 89.06%] [G loss: 1.389003]\n",
      "epoch:17 step:16327 [D loss: 0.233202, acc.: 96.88%] [G loss: 1.286842]\n",
      "epoch:17 step:16328 [D loss: 0.160470, acc.: 98.44%] [G loss: 1.341917]\n",
      "epoch:17 step:16329 [D loss: 0.418423, acc.: 87.50%] [G loss: 1.277524]\n",
      "epoch:17 step:16330 [D loss: 0.424526, acc.: 86.72%] [G loss: 1.414277]\n",
      "epoch:17 step:16331 [D loss: 0.191036, acc.: 98.44%] [G loss: 1.126335]\n",
      "epoch:17 step:16332 [D loss: 0.202915, acc.: 99.22%] [G loss: 1.517380]\n",
      "epoch:17 step:16333 [D loss: 0.240976, acc.: 97.66%] [G loss: 1.466533]\n",
      "epoch:17 step:16334 [D loss: 0.160855, acc.: 96.88%] [G loss: 1.096937]\n",
      "epoch:17 step:16335 [D loss: 0.245835, acc.: 96.09%] [G loss: 1.466690]\n",
      "epoch:17 step:16336 [D loss: 0.131983, acc.: 100.00%] [G loss: 1.830510]\n",
      "epoch:17 step:16337 [D loss: 0.690515, acc.: 62.50%] [G loss: 0.942149]\n",
      "epoch:17 step:16338 [D loss: 0.196077, acc.: 96.88%] [G loss: 1.962002]\n",
      "epoch:17 step:16339 [D loss: 0.320251, acc.: 91.41%] [G loss: 2.452824]\n",
      "epoch:17 step:16340 [D loss: 1.290477, acc.: 37.50%] [G loss: 1.563709]\n",
      "epoch:17 step:16341 [D loss: 0.485591, acc.: 75.78%] [G loss: 1.703828]\n",
      "epoch:17 step:16342 [D loss: 0.445323, acc.: 86.72%] [G loss: 1.666576]\n",
      "epoch:17 step:16343 [D loss: 0.354547, acc.: 84.38%] [G loss: 1.264946]\n",
      "epoch:17 step:16344 [D loss: 0.775095, acc.: 51.56%] [G loss: 0.928530]\n",
      "epoch:17 step:16345 [D loss: 0.474749, acc.: 78.91%] [G loss: 0.928319]\n",
      "epoch:17 step:16346 [D loss: 0.783757, acc.: 54.69%] [G loss: 0.219757]\n",
      "epoch:17 step:16347 [D loss: 0.620024, acc.: 66.41%] [G loss: 0.872201]\n",
      "epoch:17 step:16348 [D loss: 0.680811, acc.: 64.06%] [G loss: 2.206650]\n",
      "epoch:17 step:16349 [D loss: 1.433779, acc.: 34.38%] [G loss: 1.883636]\n",
      "epoch:17 step:16350 [D loss: 1.281034, acc.: 42.19%] [G loss: 1.827380]\n",
      "epoch:17 step:16351 [D loss: 1.444440, acc.: 21.09%] [G loss: 1.533290]\n",
      "epoch:17 step:16352 [D loss: 0.948017, acc.: 42.97%] [G loss: 1.549434]\n",
      "epoch:17 step:16353 [D loss: 0.676641, acc.: 60.94%] [G loss: 1.055012]\n",
      "epoch:17 step:16354 [D loss: 0.778199, acc.: 47.66%] [G loss: 1.072341]\n",
      "epoch:17 step:16355 [D loss: 0.988143, acc.: 30.47%] [G loss: 1.737929]\n",
      "epoch:17 step:16356 [D loss: 0.754279, acc.: 58.59%] [G loss: 1.461620]\n",
      "epoch:17 step:16357 [D loss: 0.507684, acc.: 71.09%] [G loss: 1.636226]\n",
      "epoch:17 step:16358 [D loss: 0.719146, acc.: 53.91%] [G loss: 1.174838]\n",
      "epoch:17 step:16359 [D loss: 0.481474, acc.: 75.00%] [G loss: 1.156478]\n",
      "epoch:17 step:16360 [D loss: 0.703604, acc.: 56.25%] [G loss: 1.091553]\n",
      "epoch:17 step:16361 [D loss: 0.758664, acc.: 52.34%] [G loss: 1.435673]\n",
      "epoch:17 step:16362 [D loss: 0.765204, acc.: 46.09%] [G loss: 1.277166]\n",
      "epoch:17 step:16363 [D loss: 0.655057, acc.: 57.03%] [G loss: 1.571546]\n",
      "epoch:17 step:16364 [D loss: 0.586772, acc.: 64.84%] [G loss: 1.639879]\n",
      "epoch:17 step:16365 [D loss: 0.626319, acc.: 67.19%] [G loss: 1.505995]\n",
      "epoch:17 step:16366 [D loss: 0.746531, acc.: 53.91%] [G loss: 1.884844]\n",
      "epoch:17 step:16367 [D loss: 0.779109, acc.: 59.38%] [G loss: 1.648880]\n",
      "epoch:17 step:16368 [D loss: 0.600611, acc.: 65.62%] [G loss: 1.817151]\n",
      "epoch:17 step:16369 [D loss: 0.574420, acc.: 63.28%] [G loss: 2.035427]\n",
      "epoch:17 step:16370 [D loss: 0.502295, acc.: 75.00%] [G loss: 1.855315]\n",
      "epoch:17 step:16371 [D loss: 0.494950, acc.: 74.22%] [G loss: 1.679255]\n",
      "epoch:17 step:16372 [D loss: 0.424919, acc.: 80.47%] [G loss: 1.537880]\n",
      "epoch:17 step:16373 [D loss: 0.580670, acc.: 70.31%] [G loss: 2.330838]\n",
      "epoch:17 step:16374 [D loss: 0.590779, acc.: 70.31%] [G loss: 1.157642]\n",
      "epoch:17 step:16375 [D loss: 0.550964, acc.: 67.97%] [G loss: 1.719677]\n",
      "epoch:17 step:16376 [D loss: 0.548361, acc.: 65.62%] [G loss: 1.181175]\n",
      "epoch:17 step:16377 [D loss: 0.386326, acc.: 85.16%] [G loss: 0.856568]\n",
      "epoch:17 step:16378 [D loss: 0.348793, acc.: 92.19%] [G loss: 1.332913]\n",
      "epoch:17 step:16379 [D loss: 0.370652, acc.: 89.84%] [G loss: 1.440798]\n",
      "epoch:17 step:16380 [D loss: 0.263046, acc.: 92.97%] [G loss: 1.386718]\n",
      "epoch:17 step:16381 [D loss: 0.285097, acc.: 92.19%] [G loss: 1.614072]\n",
      "epoch:17 step:16382 [D loss: 0.326971, acc.: 91.41%] [G loss: 2.187526]\n",
      "epoch:17 step:16383 [D loss: 0.530240, acc.: 78.12%] [G loss: 1.231065]\n",
      "epoch:17 step:16384 [D loss: 0.377055, acc.: 89.84%] [G loss: 1.298085]\n",
      "epoch:17 step:16385 [D loss: 0.350423, acc.: 89.84%] [G loss: 1.549902]\n",
      "epoch:17 step:16386 [D loss: 0.424829, acc.: 85.94%] [G loss: 1.295761]\n",
      "epoch:17 step:16387 [D loss: 0.939730, acc.: 39.84%] [G loss: 1.147159]\n",
      "epoch:17 step:16388 [D loss: 0.784605, acc.: 52.34%] [G loss: 1.387125]\n",
      "epoch:17 step:16389 [D loss: 0.768723, acc.: 52.34%] [G loss: 0.971206]\n",
      "epoch:17 step:16390 [D loss: 1.001628, acc.: 32.03%] [G loss: 1.196490]\n",
      "epoch:17 step:16391 [D loss: 1.231863, acc.: 15.62%] [G loss: 1.229331]\n",
      "epoch:17 step:16392 [D loss: 0.735875, acc.: 56.25%] [G loss: 1.083752]\n",
      "epoch:17 step:16393 [D loss: 0.692583, acc.: 62.50%] [G loss: 0.788447]\n",
      "epoch:17 step:16394 [D loss: 0.567060, acc.: 71.09%] [G loss: 0.995629]\n",
      "epoch:17 step:16395 [D loss: 0.545939, acc.: 73.44%] [G loss: 0.859695]\n",
      "epoch:17 step:16396 [D loss: 0.569014, acc.: 71.88%] [G loss: 0.921079]\n",
      "epoch:17 step:16397 [D loss: 0.340458, acc.: 91.41%] [G loss: 1.079048]\n",
      "epoch:17 step:16398 [D loss: 0.443218, acc.: 76.56%] [G loss: 1.136139]\n",
      "epoch:17 step:16399 [D loss: 0.405145, acc.: 89.06%] [G loss: 1.453522]\n",
      "epoch:17 step:16400 [D loss: 0.396496, acc.: 89.84%] [G loss: 1.056963]\n",
      "##############\n",
      "[3.79225578 2.31601379 6.13845793 5.64222202 4.32923935 6.04282241\n",
      " 5.26061261 5.39661675 5.44060238 4.14884996]\n",
      "##########\n",
      "epoch:17 step:16401 [D loss: 0.641092, acc.: 62.50%] [G loss: 1.234905]\n",
      "epoch:17 step:16402 [D loss: 0.888766, acc.: 50.00%] [G loss: 1.187241]\n",
      "epoch:17 step:16403 [D loss: 0.681367, acc.: 61.72%] [G loss: 1.128755]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:17 step:16404 [D loss: 0.575879, acc.: 73.44%] [G loss: 1.113260]\n",
      "epoch:17 step:16405 [D loss: 0.712080, acc.: 62.50%] [G loss: 1.050849]\n",
      "epoch:17 step:16406 [D loss: 0.654642, acc.: 64.06%] [G loss: 0.893279]\n",
      "epoch:17 step:16407 [D loss: 0.625875, acc.: 68.75%] [G loss: 0.927832]\n",
      "epoch:17 step:16408 [D loss: 0.644496, acc.: 60.94%] [G loss: 1.020515]\n",
      "epoch:17 step:16409 [D loss: 0.610989, acc.: 65.62%] [G loss: 1.215352]\n",
      "epoch:17 step:16410 [D loss: 0.499715, acc.: 72.66%] [G loss: 0.910560]\n",
      "epoch:17 step:16411 [D loss: 0.640391, acc.: 62.50%] [G loss: 1.116092]\n",
      "epoch:17 step:16412 [D loss: 0.551903, acc.: 73.44%] [G loss: 1.282457]\n",
      "epoch:17 step:16413 [D loss: 0.428367, acc.: 82.81%] [G loss: 1.399174]\n",
      "epoch:17 step:16414 [D loss: 0.681919, acc.: 60.16%] [G loss: 1.177391]\n",
      "epoch:17 step:16415 [D loss: 0.552315, acc.: 71.88%] [G loss: 1.450728]\n",
      "epoch:17 step:16416 [D loss: 0.573115, acc.: 69.53%] [G loss: 1.376327]\n",
      "epoch:17 step:16417 [D loss: 0.462391, acc.: 81.25%] [G loss: 1.312606]\n",
      "epoch:17 step:16418 [D loss: 0.717644, acc.: 56.25%] [G loss: 1.150226]\n",
      "epoch:17 step:16419 [D loss: 0.641802, acc.: 62.50%] [G loss: 0.958865]\n",
      "epoch:17 step:16420 [D loss: 0.677604, acc.: 57.81%] [G loss: 0.858725]\n",
      "epoch:17 step:16421 [D loss: 0.660812, acc.: 58.59%] [G loss: 0.943950]\n",
      "epoch:17 step:16422 [D loss: 0.699157, acc.: 57.81%] [G loss: 0.948362]\n",
      "epoch:17 step:16423 [D loss: 0.616375, acc.: 64.84%] [G loss: 1.043158]\n",
      "epoch:17 step:16424 [D loss: 0.573307, acc.: 71.88%] [G loss: 1.014445]\n",
      "epoch:17 step:16425 [D loss: 0.569755, acc.: 70.31%] [G loss: 1.075222]\n",
      "epoch:17 step:16426 [D loss: 0.425459, acc.: 89.84%] [G loss: 1.180434]\n",
      "epoch:17 step:16427 [D loss: 0.283972, acc.: 91.41%] [G loss: 1.319196]\n",
      "epoch:17 step:16428 [D loss: 0.260765, acc.: 92.19%] [G loss: 1.282274]\n",
      "epoch:17 step:16429 [D loss: 0.671059, acc.: 64.84%] [G loss: 1.225667]\n",
      "epoch:17 step:16430 [D loss: 0.746605, acc.: 53.91%] [G loss: 1.116855]\n",
      "epoch:17 step:16431 [D loss: 0.743467, acc.: 49.22%] [G loss: 0.628371]\n",
      "epoch:17 step:16432 [D loss: 0.622485, acc.: 60.16%] [G loss: 0.916268]\n",
      "epoch:17 step:16433 [D loss: 0.491791, acc.: 77.34%] [G loss: 1.005639]\n",
      "epoch:17 step:16434 [D loss: 0.584485, acc.: 67.19%] [G loss: 1.063275]\n",
      "epoch:17 step:16435 [D loss: 0.690721, acc.: 58.59%] [G loss: 1.007744]\n",
      "epoch:17 step:16436 [D loss: 0.595456, acc.: 67.97%] [G loss: 1.017916]\n",
      "epoch:17 step:16437 [D loss: 0.529720, acc.: 78.12%] [G loss: 1.014718]\n",
      "epoch:17 step:16438 [D loss: 0.740948, acc.: 46.88%] [G loss: 1.003735]\n",
      "epoch:17 step:16439 [D loss: 0.400846, acc.: 86.72%] [G loss: 1.035012]\n",
      "epoch:17 step:16440 [D loss: 0.385757, acc.: 82.81%] [G loss: 1.285382]\n",
      "epoch:17 step:16441 [D loss: 0.359651, acc.: 88.28%] [G loss: 1.021137]\n",
      "epoch:17 step:16442 [D loss: 0.359110, acc.: 83.59%] [G loss: 1.238522]\n",
      "epoch:17 step:16443 [D loss: 0.456028, acc.: 87.50%] [G loss: 1.339602]\n",
      "epoch:17 step:16444 [D loss: 0.416269, acc.: 86.72%] [G loss: 1.219996]\n",
      "epoch:17 step:16445 [D loss: 0.620339, acc.: 62.50%] [G loss: 1.208585]\n",
      "epoch:17 step:16446 [D loss: 0.489353, acc.: 76.56%] [G loss: 1.196493]\n",
      "epoch:17 step:16447 [D loss: 0.702771, acc.: 56.25%] [G loss: 1.124417]\n",
      "epoch:17 step:16448 [D loss: 0.648148, acc.: 67.97%] [G loss: 0.978073]\n",
      "epoch:17 step:16449 [D loss: 0.511297, acc.: 78.91%] [G loss: 1.115933]\n",
      "epoch:17 step:16450 [D loss: 0.560375, acc.: 71.09%] [G loss: 0.918509]\n",
      "epoch:17 step:16451 [D loss: 0.635201, acc.: 62.50%] [G loss: 1.311007]\n",
      "epoch:17 step:16452 [D loss: 0.617592, acc.: 70.31%] [G loss: 0.936130]\n",
      "epoch:17 step:16453 [D loss: 0.346561, acc.: 91.41%] [G loss: 1.199307]\n",
      "epoch:17 step:16454 [D loss: 0.754169, acc.: 54.69%] [G loss: 1.194256]\n",
      "epoch:17 step:16455 [D loss: 0.674993, acc.: 63.28%] [G loss: 0.909873]\n",
      "epoch:17 step:16456 [D loss: 0.351175, acc.: 85.16%] [G loss: 0.996989]\n",
      "epoch:17 step:16457 [D loss: 0.672794, acc.: 58.59%] [G loss: 1.008195]\n",
      "epoch:17 step:16458 [D loss: 0.703582, acc.: 60.94%] [G loss: 0.880793]\n",
      "epoch:17 step:16459 [D loss: 0.458173, acc.: 83.59%] [G loss: 1.147204]\n",
      "epoch:17 step:16460 [D loss: 0.683383, acc.: 57.03%] [G loss: 0.910059]\n",
      "epoch:17 step:16461 [D loss: 0.557287, acc.: 74.22%] [G loss: 0.984487]\n",
      "epoch:17 step:16462 [D loss: 0.516324, acc.: 71.88%] [G loss: 0.821299]\n",
      "epoch:17 step:16463 [D loss: 0.562538, acc.: 71.09%] [G loss: 1.168803]\n",
      "epoch:17 step:16464 [D loss: 0.383261, acc.: 84.38%] [G loss: 1.198525]\n",
      "epoch:17 step:16465 [D loss: 0.225540, acc.: 96.09%] [G loss: 1.350527]\n",
      "epoch:17 step:16466 [D loss: 0.289692, acc.: 93.75%] [G loss: 1.419325]\n",
      "epoch:17 step:16467 [D loss: 0.489368, acc.: 79.69%] [G loss: 1.518435]\n",
      "epoch:17 step:16468 [D loss: 0.421748, acc.: 85.94%] [G loss: 1.366455]\n",
      "epoch:17 step:16469 [D loss: 0.427031, acc.: 85.16%] [G loss: 1.605688]\n",
      "epoch:17 step:16470 [D loss: 0.391216, acc.: 91.41%] [G loss: 1.319493]\n",
      "epoch:17 step:16471 [D loss: 0.780555, acc.: 55.47%] [G loss: 1.169442]\n",
      "epoch:17 step:16472 [D loss: 0.619246, acc.: 67.97%] [G loss: 1.103872]\n",
      "epoch:17 step:16473 [D loss: 0.984611, acc.: 32.03%] [G loss: 1.110856]\n",
      "epoch:17 step:16474 [D loss: 0.677411, acc.: 57.81%] [G loss: 1.015964]\n",
      "epoch:17 step:16475 [D loss: 0.658296, acc.: 62.50%] [G loss: 1.170646]\n",
      "epoch:17 step:16476 [D loss: 0.672938, acc.: 58.59%] [G loss: 1.036890]\n",
      "epoch:17 step:16477 [D loss: 0.542621, acc.: 75.00%] [G loss: 0.915873]\n",
      "epoch:17 step:16478 [D loss: 0.512641, acc.: 72.66%] [G loss: 0.810260]\n",
      "epoch:17 step:16479 [D loss: 0.385427, acc.: 89.84%] [G loss: 0.792894]\n",
      "epoch:17 step:16480 [D loss: 0.534602, acc.: 72.66%] [G loss: 1.353038]\n",
      "epoch:17 step:16481 [D loss: 0.570197, acc.: 71.88%] [G loss: 0.562311]\n",
      "epoch:17 step:16482 [D loss: 1.243893, acc.: 26.56%] [G loss: 1.048813]\n",
      "epoch:17 step:16483 [D loss: 0.351019, acc.: 94.53%] [G loss: 0.865347]\n",
      "epoch:17 step:16484 [D loss: 0.649220, acc.: 61.72%] [G loss: 1.143472]\n",
      "epoch:17 step:16485 [D loss: 0.554747, acc.: 71.88%] [G loss: 0.989215]\n",
      "epoch:17 step:16486 [D loss: 0.624929, acc.: 60.94%] [G loss: 1.219913]\n",
      "epoch:17 step:16487 [D loss: 0.711189, acc.: 55.47%] [G loss: 1.298537]\n",
      "epoch:17 step:16488 [D loss: 0.235771, acc.: 93.75%] [G loss: 1.166330]\n",
      "epoch:17 step:16489 [D loss: 0.499699, acc.: 78.91%] [G loss: 1.633094]\n",
      "epoch:17 step:16490 [D loss: 0.257615, acc.: 89.06%] [G loss: 1.595717]\n",
      "epoch:17 step:16491 [D loss: 0.735470, acc.: 60.94%] [G loss: 1.481254]\n",
      "epoch:17 step:16492 [D loss: 0.723793, acc.: 56.25%] [G loss: 1.156360]\n",
      "epoch:17 step:16493 [D loss: 0.665611, acc.: 61.72%] [G loss: 0.999608]\n",
      "epoch:17 step:16494 [D loss: 0.411649, acc.: 90.62%] [G loss: 1.344433]\n",
      "epoch:17 step:16495 [D loss: 0.268179, acc.: 87.50%] [G loss: 1.079521]\n",
      "epoch:17 step:16496 [D loss: 0.190002, acc.: 96.09%] [G loss: 1.569537]\n",
      "epoch:17 step:16497 [D loss: 0.251628, acc.: 93.75%] [G loss: 1.367828]\n",
      "epoch:17 step:16498 [D loss: 0.532417, acc.: 76.56%] [G loss: 1.566090]\n",
      "epoch:17 step:16499 [D loss: 0.401386, acc.: 87.50%] [G loss: 0.600948]\n",
      "epoch:17 step:16500 [D loss: 0.438644, acc.: 82.03%] [G loss: 1.398599]\n",
      "epoch:17 step:16501 [D loss: 0.560728, acc.: 71.09%] [G loss: 1.176983]\n",
      "epoch:17 step:16502 [D loss: 0.554312, acc.: 74.22%] [G loss: 0.645521]\n",
      "epoch:17 step:16503 [D loss: 0.510813, acc.: 79.69%] [G loss: 1.277077]\n",
      "epoch:17 step:16504 [D loss: 0.927294, acc.: 49.22%] [G loss: 1.928778]\n",
      "epoch:17 step:16505 [D loss: 0.351302, acc.: 85.94%] [G loss: 1.366105]\n",
      "epoch:17 step:16506 [D loss: 0.201454, acc.: 95.31%] [G loss: 1.764807]\n",
      "epoch:17 step:16507 [D loss: 0.234765, acc.: 93.75%] [G loss: 1.057464]\n",
      "epoch:17 step:16508 [D loss: 0.301813, acc.: 92.97%] [G loss: 2.158114]\n",
      "epoch:17 step:16509 [D loss: 0.918964, acc.: 50.78%] [G loss: 1.466805]\n",
      "epoch:17 step:16510 [D loss: 1.045102, acc.: 26.56%] [G loss: 1.429269]\n",
      "epoch:17 step:16511 [D loss: 1.246472, acc.: 22.66%] [G loss: 1.299824]\n",
      "epoch:17 step:16512 [D loss: 0.979773, acc.: 40.62%] [G loss: 1.532067]\n",
      "epoch:17 step:16513 [D loss: 0.777667, acc.: 53.91%] [G loss: 1.313504]\n",
      "epoch:17 step:16514 [D loss: 0.659339, acc.: 64.84%] [G loss: 1.650433]\n",
      "epoch:17 step:16515 [D loss: 0.631954, acc.: 61.72%] [G loss: 1.271711]\n",
      "epoch:17 step:16516 [D loss: 0.297331, acc.: 88.28%] [G loss: 1.087578]\n",
      "epoch:17 step:16517 [D loss: 0.405502, acc.: 85.16%] [G loss: 1.275137]\n",
      "epoch:17 step:16518 [D loss: 0.388885, acc.: 77.34%] [G loss: 1.529971]\n",
      "epoch:17 step:16519 [D loss: 0.683898, acc.: 60.94%] [G loss: 1.326269]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:17 step:16520 [D loss: 0.540922, acc.: 78.12%] [G loss: 1.427398]\n",
      "epoch:17 step:16521 [D loss: 0.484247, acc.: 80.47%] [G loss: 1.267067]\n",
      "epoch:17 step:16522 [D loss: 0.652085, acc.: 56.25%] [G loss: 1.294277]\n",
      "epoch:17 step:16523 [D loss: 0.704620, acc.: 62.50%] [G loss: 1.084083]\n",
      "epoch:17 step:16524 [D loss: 0.596427, acc.: 69.53%] [G loss: 1.155342]\n",
      "epoch:17 step:16525 [D loss: 0.572041, acc.: 70.31%] [G loss: 1.283164]\n",
      "epoch:17 step:16526 [D loss: 0.666364, acc.: 57.81%] [G loss: 1.146326]\n",
      "epoch:17 step:16527 [D loss: 0.636201, acc.: 61.72%] [G loss: 1.137290]\n",
      "epoch:17 step:16528 [D loss: 0.620009, acc.: 67.19%] [G loss: 1.036093]\n",
      "epoch:17 step:16529 [D loss: 0.353540, acc.: 86.72%] [G loss: 1.135095]\n",
      "epoch:17 step:16530 [D loss: 0.414149, acc.: 93.75%] [G loss: 1.224266]\n",
      "epoch:17 step:16531 [D loss: 0.369727, acc.: 90.62%] [G loss: 1.308565]\n",
      "epoch:17 step:16532 [D loss: 0.569989, acc.: 69.53%] [G loss: 1.251054]\n",
      "epoch:17 step:16533 [D loss: 0.477449, acc.: 78.91%] [G loss: 0.914812]\n",
      "epoch:17 step:16534 [D loss: 0.486157, acc.: 78.91%] [G loss: 1.427654]\n",
      "epoch:17 step:16535 [D loss: 0.606261, acc.: 66.41%] [G loss: 1.161930]\n",
      "epoch:17 step:16536 [D loss: 0.683764, acc.: 57.03%] [G loss: 1.105999]\n",
      "epoch:17 step:16537 [D loss: 0.636265, acc.: 60.94%] [G loss: 1.056213]\n",
      "epoch:17 step:16538 [D loss: 0.492188, acc.: 72.66%] [G loss: 1.133306]\n",
      "epoch:17 step:16539 [D loss: 0.687302, acc.: 58.59%] [G loss: 1.004668]\n",
      "epoch:17 step:16540 [D loss: 0.483061, acc.: 83.59%] [G loss: 1.188256]\n",
      "epoch:17 step:16541 [D loss: 0.589626, acc.: 67.97%] [G loss: 1.165073]\n",
      "epoch:17 step:16542 [D loss: 0.570553, acc.: 75.78%] [G loss: 0.805389]\n",
      "epoch:17 step:16543 [D loss: 0.699637, acc.: 55.47%] [G loss: 0.825970]\n",
      "epoch:17 step:16544 [D loss: 0.678268, acc.: 60.16%] [G loss: 0.936394]\n",
      "epoch:17 step:16545 [D loss: 0.449422, acc.: 82.81%] [G loss: 1.212679]\n",
      "epoch:17 step:16546 [D loss: 0.501509, acc.: 78.12%] [G loss: 0.693442]\n",
      "epoch:17 step:16547 [D loss: 0.590833, acc.: 68.75%] [G loss: 1.249076]\n",
      "epoch:17 step:16548 [D loss: 0.549800, acc.: 75.78%] [G loss: 1.279322]\n",
      "epoch:17 step:16549 [D loss: 0.523442, acc.: 73.44%] [G loss: 1.165412]\n",
      "epoch:17 step:16550 [D loss: 0.809546, acc.: 42.19%] [G loss: 1.220465]\n",
      "epoch:17 step:16551 [D loss: 0.518894, acc.: 75.78%] [G loss: 1.133078]\n",
      "epoch:17 step:16552 [D loss: 0.619434, acc.: 61.72%] [G loss: 1.105543]\n",
      "epoch:17 step:16553 [D loss: 0.376707, acc.: 87.50%] [G loss: 1.227306]\n",
      "epoch:17 step:16554 [D loss: 0.645941, acc.: 62.50%] [G loss: 1.116457]\n",
      "epoch:17 step:16555 [D loss: 0.557377, acc.: 72.66%] [G loss: 1.176155]\n",
      "epoch:17 step:16556 [D loss: 0.674609, acc.: 56.25%] [G loss: 0.814784]\n",
      "epoch:17 step:16557 [D loss: 0.667786, acc.: 65.62%] [G loss: 1.233273]\n",
      "epoch:17 step:16558 [D loss: 0.481157, acc.: 76.56%] [G loss: 1.076612]\n",
      "epoch:17 step:16559 [D loss: 0.484592, acc.: 74.22%] [G loss: 1.115302]\n",
      "epoch:17 step:16560 [D loss: 0.815742, acc.: 53.91%] [G loss: 0.946865]\n",
      "epoch:17 step:16561 [D loss: 0.678789, acc.: 62.50%] [G loss: 0.980056]\n",
      "epoch:17 step:16562 [D loss: 0.391774, acc.: 81.25%] [G loss: 1.415679]\n",
      "epoch:17 step:16563 [D loss: 0.429527, acc.: 87.50%] [G loss: 1.088941]\n",
      "epoch:17 step:16564 [D loss: 0.442819, acc.: 87.50%] [G loss: 1.712355]\n",
      "epoch:17 step:16565 [D loss: 0.896922, acc.: 40.62%] [G loss: 1.146534]\n",
      "epoch:17 step:16566 [D loss: 0.537395, acc.: 69.53%] [G loss: 1.383271]\n",
      "epoch:17 step:16567 [D loss: 0.765095, acc.: 51.56%] [G loss: 1.317998]\n",
      "epoch:17 step:16568 [D loss: 0.510901, acc.: 75.00%] [G loss: 1.241101]\n",
      "epoch:17 step:16569 [D loss: 1.064028, acc.: 27.34%] [G loss: 1.436897]\n",
      "epoch:17 step:16570 [D loss: 0.289380, acc.: 92.97%] [G loss: 1.044530]\n",
      "epoch:17 step:16571 [D loss: 0.824487, acc.: 48.44%] [G loss: 0.966211]\n",
      "epoch:17 step:16572 [D loss: 0.689344, acc.: 57.03%] [G loss: 0.772306]\n",
      "epoch:17 step:16573 [D loss: 0.656524, acc.: 59.38%] [G loss: 1.098304]\n",
      "epoch:17 step:16574 [D loss: 0.378875, acc.: 90.62%] [G loss: 1.153728]\n",
      "epoch:17 step:16575 [D loss: 0.517040, acc.: 80.47%] [G loss: 0.839616]\n",
      "epoch:17 step:16576 [D loss: 0.645422, acc.: 57.03%] [G loss: 0.684098]\n",
      "epoch:17 step:16577 [D loss: 0.415390, acc.: 83.59%] [G loss: 0.925551]\n",
      "epoch:17 step:16578 [D loss: 0.419371, acc.: 86.72%] [G loss: 1.082627]\n",
      "epoch:17 step:16579 [D loss: 0.312038, acc.: 95.31%] [G loss: 1.063821]\n",
      "epoch:17 step:16580 [D loss: 0.695318, acc.: 58.59%] [G loss: 0.843982]\n",
      "epoch:17 step:16581 [D loss: 0.753093, acc.: 58.59%] [G loss: 1.339381]\n",
      "epoch:17 step:16582 [D loss: 0.733442, acc.: 51.56%] [G loss: 1.208215]\n",
      "epoch:17 step:16583 [D loss: 0.877328, acc.: 40.62%] [G loss: 1.627604]\n",
      "epoch:17 step:16584 [D loss: 1.000769, acc.: 32.81%] [G loss: 1.150171]\n",
      "epoch:17 step:16585 [D loss: 0.797465, acc.: 56.25%] [G loss: 1.271287]\n",
      "epoch:17 step:16586 [D loss: 0.853711, acc.: 45.31%] [G loss: 0.854602]\n",
      "epoch:17 step:16587 [D loss: 0.570980, acc.: 71.88%] [G loss: 1.564100]\n",
      "epoch:17 step:16588 [D loss: 0.545675, acc.: 78.91%] [G loss: 1.775137]\n",
      "epoch:17 step:16589 [D loss: 0.746947, acc.: 53.91%] [G loss: 1.360132]\n",
      "epoch:17 step:16590 [D loss: 0.544465, acc.: 68.75%] [G loss: 1.317034]\n",
      "epoch:17 step:16591 [D loss: 0.742591, acc.: 53.12%] [G loss: 1.337871]\n",
      "epoch:17 step:16592 [D loss: 0.317113, acc.: 82.03%] [G loss: 1.242303]\n",
      "epoch:17 step:16593 [D loss: 0.218789, acc.: 94.53%] [G loss: 1.496140]\n",
      "epoch:17 step:16594 [D loss: 0.146033, acc.: 98.44%] [G loss: 1.446446]\n",
      "epoch:17 step:16595 [D loss: 0.476773, acc.: 79.69%] [G loss: 1.337987]\n",
      "epoch:17 step:16596 [D loss: 0.479471, acc.: 75.78%] [G loss: 1.420924]\n",
      "epoch:17 step:16597 [D loss: 0.658656, acc.: 65.62%] [G loss: 1.336315]\n",
      "epoch:17 step:16598 [D loss: 0.571977, acc.: 69.53%] [G loss: 1.505650]\n",
      "epoch:17 step:16599 [D loss: 0.576903, acc.: 71.09%] [G loss: 1.244338]\n",
      "epoch:17 step:16600 [D loss: 0.440623, acc.: 84.38%] [G loss: 1.021308]\n",
      "##############\n",
      "[3.7315074  1.80970904 6.59477769 5.37264553 4.22624552 5.83574388\n",
      " 5.10714671 5.12656354 5.71937744 4.89913028]\n",
      "##########\n",
      "epoch:17 step:16601 [D loss: 0.704312, acc.: 58.59%] [G loss: 1.127817]\n",
      "epoch:17 step:16602 [D loss: 0.734680, acc.: 50.78%] [G loss: 1.043667]\n",
      "epoch:17 step:16603 [D loss: 0.477698, acc.: 75.78%] [G loss: 1.301887]\n",
      "epoch:17 step:16604 [D loss: 0.572905, acc.: 74.22%] [G loss: 1.091221]\n",
      "epoch:17 step:16605 [D loss: 0.734546, acc.: 56.25%] [G loss: 1.083642]\n",
      "epoch:17 step:16606 [D loss: 0.652043, acc.: 62.50%] [G loss: 0.995072]\n",
      "epoch:17 step:16607 [D loss: 0.707810, acc.: 52.34%] [G loss: 0.902860]\n",
      "epoch:17 step:16608 [D loss: 0.624670, acc.: 61.72%] [G loss: 1.043930]\n",
      "epoch:17 step:16609 [D loss: 0.586546, acc.: 67.19%] [G loss: 1.048310]\n",
      "epoch:17 step:16610 [D loss: 0.799131, acc.: 48.44%] [G loss: 1.082078]\n",
      "epoch:17 step:16611 [D loss: 0.468421, acc.: 76.56%] [G loss: 1.261184]\n",
      "epoch:17 step:16612 [D loss: 0.494033, acc.: 77.34%] [G loss: 1.063687]\n",
      "epoch:17 step:16613 [D loss: 0.374001, acc.: 85.94%] [G loss: 1.084956]\n",
      "epoch:17 step:16614 [D loss: 0.486339, acc.: 78.91%] [G loss: 0.732351]\n",
      "epoch:17 step:16615 [D loss: 0.478046, acc.: 78.12%] [G loss: 0.628783]\n",
      "epoch:17 step:16616 [D loss: 0.496215, acc.: 78.12%] [G loss: 0.750512]\n",
      "epoch:17 step:16617 [D loss: 1.115853, acc.: 28.12%] [G loss: 1.170654]\n",
      "epoch:17 step:16618 [D loss: 0.876573, acc.: 45.31%] [G loss: 1.156111]\n",
      "epoch:17 step:16619 [D loss: 0.767551, acc.: 55.47%] [G loss: 1.114183]\n",
      "epoch:17 step:16620 [D loss: 0.762585, acc.: 50.78%] [G loss: 0.911337]\n",
      "epoch:17 step:16621 [D loss: 0.752401, acc.: 58.59%] [G loss: 0.976929]\n",
      "epoch:17 step:16622 [D loss: 0.601574, acc.: 66.41%] [G loss: 1.076839]\n",
      "epoch:17 step:16623 [D loss: 0.949821, acc.: 46.09%] [G loss: 1.148965]\n",
      "epoch:17 step:16624 [D loss: 0.686294, acc.: 56.25%] [G loss: 1.170989]\n",
      "epoch:17 step:16625 [D loss: 0.279213, acc.: 94.53%] [G loss: 1.268381]\n",
      "epoch:17 step:16626 [D loss: 0.233244, acc.: 93.75%] [G loss: 1.378248]\n",
      "epoch:17 step:16627 [D loss: 0.303539, acc.: 94.53%] [G loss: 1.590135]\n",
      "epoch:17 step:16628 [D loss: 0.569868, acc.: 67.97%] [G loss: 1.335559]\n",
      "epoch:17 step:16629 [D loss: 0.216997, acc.: 94.53%] [G loss: 1.385729]\n",
      "epoch:17 step:16630 [D loss: 0.188640, acc.: 95.31%] [G loss: 1.713780]\n",
      "epoch:17 step:16631 [D loss: 0.293642, acc.: 92.97%] [G loss: 1.632906]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:17 step:16632 [D loss: 0.666456, acc.: 60.16%] [G loss: 1.288657]\n",
      "epoch:17 step:16633 [D loss: 0.435186, acc.: 86.72%] [G loss: 1.252333]\n",
      "epoch:17 step:16634 [D loss: 0.694038, acc.: 57.03%] [G loss: 1.392119]\n",
      "epoch:17 step:16635 [D loss: 0.209831, acc.: 97.66%] [G loss: 1.186751]\n",
      "epoch:17 step:16636 [D loss: 0.180881, acc.: 97.66%] [G loss: 1.304734]\n",
      "epoch:17 step:16637 [D loss: 0.146861, acc.: 99.22%] [G loss: 1.562449]\n",
      "epoch:17 step:16638 [D loss: 0.169272, acc.: 99.22%] [G loss: 1.691874]\n",
      "epoch:17 step:16639 [D loss: 0.843259, acc.: 53.91%] [G loss: 1.497154]\n",
      "epoch:17 step:16640 [D loss: 0.721271, acc.: 51.56%] [G loss: 1.136303]\n",
      "epoch:17 step:16641 [D loss: 0.859217, acc.: 45.31%] [G loss: 1.392930]\n",
      "epoch:17 step:16642 [D loss: 0.200569, acc.: 96.09%] [G loss: 1.486077]\n",
      "epoch:17 step:16643 [D loss: 0.265325, acc.: 92.19%] [G loss: 1.490173]\n",
      "epoch:17 step:16644 [D loss: 0.821383, acc.: 55.47%] [G loss: 1.076828]\n",
      "epoch:17 step:16645 [D loss: 0.789187, acc.: 54.69%] [G loss: 1.277157]\n",
      "epoch:17 step:16646 [D loss: 0.723102, acc.: 55.47%] [G loss: 1.153085]\n",
      "epoch:17 step:16647 [D loss: 0.640933, acc.: 59.38%] [G loss: 1.068674]\n",
      "epoch:17 step:16648 [D loss: 0.721340, acc.: 57.81%] [G loss: 0.917697]\n",
      "epoch:17 step:16649 [D loss: 0.627180, acc.: 64.06%] [G loss: 1.096838]\n",
      "epoch:17 step:16650 [D loss: 0.731213, acc.: 58.59%] [G loss: 0.998158]\n",
      "epoch:17 step:16651 [D loss: 0.529808, acc.: 76.56%] [G loss: 1.105170]\n",
      "epoch:17 step:16652 [D loss: 0.414484, acc.: 89.06%] [G loss: 1.122450]\n",
      "epoch:17 step:16653 [D loss: 0.616651, acc.: 62.50%] [G loss: 0.722347]\n",
      "epoch:17 step:16654 [D loss: 0.819617, acc.: 40.62%] [G loss: 1.252596]\n",
      "epoch:17 step:16655 [D loss: 0.540277, acc.: 71.88%] [G loss: 1.190190]\n",
      "epoch:17 step:16656 [D loss: 0.388953, acc.: 90.62%] [G loss: 1.174361]\n",
      "epoch:17 step:16657 [D loss: 0.281627, acc.: 87.50%] [G loss: 1.250157]\n",
      "epoch:17 step:16658 [D loss: 0.310570, acc.: 80.47%] [G loss: 0.975130]\n",
      "epoch:17 step:16659 [D loss: 0.188617, acc.: 98.44%] [G loss: 1.500487]\n",
      "epoch:17 step:16660 [D loss: 0.149740, acc.: 100.00%] [G loss: 1.718353]\n",
      "epoch:17 step:16661 [D loss: 0.167656, acc.: 99.22%] [G loss: 1.927307]\n",
      "epoch:17 step:16662 [D loss: 0.184339, acc.: 98.44%] [G loss: 1.877178]\n",
      "epoch:17 step:16663 [D loss: 0.758413, acc.: 56.25%] [G loss: 1.685201]\n",
      "epoch:17 step:16664 [D loss: 1.514340, acc.: 14.06%] [G loss: 1.738333]\n",
      "epoch:17 step:16665 [D loss: 0.867272, acc.: 53.12%] [G loss: 1.635432]\n",
      "epoch:17 step:16666 [D loss: 0.980708, acc.: 38.28%] [G loss: 1.168100]\n",
      "epoch:17 step:16667 [D loss: 0.916991, acc.: 36.72%] [G loss: 1.362500]\n",
      "epoch:17 step:16668 [D loss: 0.483448, acc.: 80.47%] [G loss: 1.218579]\n",
      "epoch:17 step:16669 [D loss: 0.460780, acc.: 81.25%] [G loss: 0.925218]\n",
      "epoch:17 step:16670 [D loss: 0.773467, acc.: 44.53%] [G loss: 0.917102]\n",
      "epoch:17 step:16671 [D loss: 0.556413, acc.: 67.97%] [G loss: 1.267861]\n",
      "epoch:17 step:16672 [D loss: 0.436436, acc.: 86.72%] [G loss: 1.137953]\n",
      "epoch:17 step:16673 [D loss: 0.633637, acc.: 64.84%] [G loss: 1.146789]\n",
      "epoch:17 step:16674 [D loss: 0.572525, acc.: 70.31%] [G loss: 0.914334]\n",
      "epoch:17 step:16675 [D loss: 0.326656, acc.: 89.84%] [G loss: 1.094360]\n",
      "epoch:17 step:16676 [D loss: 0.582923, acc.: 66.41%] [G loss: 1.175614]\n",
      "epoch:17 step:16677 [D loss: 0.628554, acc.: 60.94%] [G loss: 0.582447]\n",
      "epoch:17 step:16678 [D loss: 0.433469, acc.: 88.28%] [G loss: 0.922051]\n",
      "epoch:17 step:16679 [D loss: 0.396346, acc.: 88.28%] [G loss: 0.937089]\n",
      "epoch:17 step:16680 [D loss: 0.716771, acc.: 55.47%] [G loss: 0.796211]\n",
      "epoch:17 step:16681 [D loss: 1.173881, acc.: 41.41%] [G loss: 1.134422]\n",
      "epoch:17 step:16682 [D loss: 0.702734, acc.: 60.16%] [G loss: 1.208070]\n",
      "epoch:17 step:16683 [D loss: 0.940841, acc.: 48.44%] [G loss: 1.384419]\n",
      "epoch:17 step:16684 [D loss: 0.640542, acc.: 65.62%] [G loss: 1.535924]\n",
      "epoch:17 step:16685 [D loss: 0.526811, acc.: 72.66%] [G loss: 1.374849]\n",
      "epoch:17 step:16686 [D loss: 0.750828, acc.: 56.25%] [G loss: 0.806330]\n",
      "epoch:17 step:16687 [D loss: 0.697170, acc.: 52.34%] [G loss: 1.531525]\n",
      "epoch:17 step:16688 [D loss: 0.661569, acc.: 62.50%] [G loss: 1.438575]\n",
      "epoch:17 step:16689 [D loss: 0.488106, acc.: 75.00%] [G loss: 1.620585]\n",
      "epoch:17 step:16690 [D loss: 0.678496, acc.: 59.38%] [G loss: 1.915184]\n",
      "epoch:17 step:16691 [D loss: 0.706933, acc.: 62.50%] [G loss: 1.304636]\n",
      "epoch:17 step:16692 [D loss: 0.712250, acc.: 64.06%] [G loss: 1.121021]\n",
      "epoch:17 step:16693 [D loss: 0.592623, acc.: 69.53%] [G loss: 0.882511]\n",
      "epoch:17 step:16694 [D loss: 0.483110, acc.: 77.34%] [G loss: 0.963500]\n",
      "epoch:17 step:16695 [D loss: 0.441727, acc.: 82.81%] [G loss: 1.162927]\n",
      "epoch:17 step:16696 [D loss: 0.363408, acc.: 90.62%] [G loss: 1.254871]\n",
      "epoch:17 step:16697 [D loss: 0.324730, acc.: 85.16%] [G loss: 1.498777]\n",
      "epoch:17 step:16698 [D loss: 0.267398, acc.: 93.75%] [G loss: 1.307322]\n",
      "epoch:17 step:16699 [D loss: 0.565575, acc.: 71.88%] [G loss: 1.487506]\n",
      "epoch:17 step:16700 [D loss: 0.530013, acc.: 78.91%] [G loss: 1.327516]\n",
      "epoch:17 step:16701 [D loss: 0.468801, acc.: 76.56%] [G loss: 1.422662]\n",
      "epoch:17 step:16702 [D loss: 0.475438, acc.: 81.25%] [G loss: 0.921568]\n",
      "epoch:17 step:16703 [D loss: 0.364581, acc.: 82.03%] [G loss: 1.219190]\n",
      "epoch:17 step:16704 [D loss: 0.259363, acc.: 94.53%] [G loss: 1.450314]\n",
      "epoch:17 step:16705 [D loss: 0.455218, acc.: 81.25%] [G loss: 1.453214]\n",
      "epoch:17 step:16706 [D loss: 0.367821, acc.: 88.28%] [G loss: 1.460865]\n",
      "epoch:17 step:16707 [D loss: 0.692872, acc.: 56.25%] [G loss: 1.095141]\n",
      "epoch:17 step:16708 [D loss: 0.810247, acc.: 50.00%] [G loss: 1.408757]\n",
      "epoch:17 step:16709 [D loss: 0.833265, acc.: 52.34%] [G loss: 1.093541]\n",
      "epoch:17 step:16710 [D loss: 0.679833, acc.: 60.94%] [G loss: 1.026762]\n",
      "epoch:17 step:16711 [D loss: 0.620997, acc.: 65.62%] [G loss: 1.015972]\n",
      "epoch:17 step:16712 [D loss: 0.748762, acc.: 49.22%] [G loss: 0.653516]\n",
      "epoch:17 step:16713 [D loss: 0.754965, acc.: 54.69%] [G loss: 1.097975]\n",
      "epoch:17 step:16714 [D loss: 0.845339, acc.: 40.62%] [G loss: 0.805681]\n",
      "epoch:17 step:16715 [D loss: 0.495717, acc.: 77.34%] [G loss: 1.118007]\n",
      "epoch:17 step:16716 [D loss: 0.730191, acc.: 52.34%] [G loss: 1.129353]\n",
      "epoch:17 step:16717 [D loss: 0.709970, acc.: 56.25%] [G loss: 1.224392]\n",
      "epoch:17 step:16718 [D loss: 0.760773, acc.: 53.91%] [G loss: 1.523939]\n",
      "epoch:17 step:16719 [D loss: 0.687077, acc.: 55.47%] [G loss: 1.497585]\n",
      "epoch:17 step:16720 [D loss: 0.353751, acc.: 84.38%] [G loss: 1.669974]\n",
      "epoch:17 step:16721 [D loss: 0.261467, acc.: 95.31%] [G loss: 1.446826]\n",
      "epoch:17 step:16722 [D loss: 0.296035, acc.: 92.97%] [G loss: 1.399324]\n",
      "epoch:17 step:16723 [D loss: 0.341783, acc.: 93.75%] [G loss: 1.599789]\n",
      "epoch:17 step:16724 [D loss: 0.572773, acc.: 75.78%] [G loss: 1.652986]\n",
      "epoch:17 step:16725 [D loss: 0.389746, acc.: 87.50%] [G loss: 1.436725]\n",
      "epoch:17 step:16726 [D loss: 0.752363, acc.: 51.56%] [G loss: 1.089667]\n",
      "epoch:17 step:16727 [D loss: 0.677432, acc.: 57.03%] [G loss: 1.174465]\n",
      "epoch:17 step:16728 [D loss: 0.608024, acc.: 69.53%] [G loss: 1.096923]\n",
      "epoch:17 step:16729 [D loss: 0.500114, acc.: 75.00%] [G loss: 1.022106]\n",
      "epoch:17 step:16730 [D loss: 0.597484, acc.: 62.50%] [G loss: 1.273611]\n",
      "epoch:17 step:16731 [D loss: 0.507408, acc.: 71.88%] [G loss: 1.321375]\n",
      "epoch:17 step:16732 [D loss: 0.550358, acc.: 67.19%] [G loss: 0.903024]\n",
      "epoch:17 step:16733 [D loss: 0.292123, acc.: 92.19%] [G loss: 1.241396]\n",
      "epoch:17 step:16734 [D loss: 0.376659, acc.: 89.06%] [G loss: 1.202230]\n",
      "epoch:17 step:16735 [D loss: 0.201631, acc.: 97.66%] [G loss: 1.606137]\n",
      "epoch:17 step:16736 [D loss: 0.737590, acc.: 45.31%] [G loss: 1.586942]\n",
      "epoch:17 step:16737 [D loss: 0.416872, acc.: 83.59%] [G loss: 1.656934]\n",
      "epoch:17 step:16738 [D loss: 0.322762, acc.: 96.09%] [G loss: 1.648054]\n",
      "epoch:17 step:16739 [D loss: 0.385674, acc.: 85.16%] [G loss: 1.206223]\n",
      "epoch:17 step:16740 [D loss: 1.024360, acc.: 38.28%] [G loss: 1.010626]\n",
      "epoch:17 step:16741 [D loss: 0.708238, acc.: 61.72%] [G loss: 1.094707]\n",
      "epoch:17 step:16742 [D loss: 0.988465, acc.: 28.91%] [G loss: 0.991205]\n",
      "epoch:17 step:16743 [D loss: 0.616556, acc.: 70.31%] [G loss: 1.296840]\n",
      "epoch:17 step:16744 [D loss: 0.379134, acc.: 85.94%] [G loss: 0.841233]\n",
      "epoch:17 step:16745 [D loss: 0.651295, acc.: 63.28%] [G loss: 1.139914]\n",
      "epoch:17 step:16746 [D loss: 0.693506, acc.: 57.03%] [G loss: 1.240163]\n",
      "epoch:17 step:16747 [D loss: 0.693267, acc.: 59.38%] [G loss: 0.940912]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:17 step:16748 [D loss: 0.666133, acc.: 60.94%] [G loss: 1.080689]\n",
      "epoch:17 step:16749 [D loss: 0.761060, acc.: 42.19%] [G loss: 1.177835]\n",
      "epoch:17 step:16750 [D loss: 0.518278, acc.: 75.78%] [G loss: 0.982361]\n",
      "epoch:17 step:16751 [D loss: 0.621432, acc.: 68.75%] [G loss: 1.113536]\n",
      "epoch:17 step:16752 [D loss: 0.623909, acc.: 66.41%] [G loss: 1.087171]\n",
      "epoch:17 step:16753 [D loss: 0.658485, acc.: 60.94%] [G loss: 0.844128]\n",
      "epoch:17 step:16754 [D loss: 0.513606, acc.: 79.69%] [G loss: 1.041756]\n",
      "epoch:17 step:16755 [D loss: 0.662135, acc.: 60.94%] [G loss: 0.999334]\n",
      "epoch:17 step:16756 [D loss: 0.704314, acc.: 57.81%] [G loss: 0.928858]\n",
      "epoch:17 step:16757 [D loss: 0.649299, acc.: 56.25%] [G loss: 0.946299]\n",
      "epoch:17 step:16758 [D loss: 0.648966, acc.: 61.72%] [G loss: 1.050221]\n",
      "epoch:17 step:16759 [D loss: 0.648687, acc.: 65.62%] [G loss: 1.030792]\n",
      "epoch:17 step:16760 [D loss: 0.464594, acc.: 85.16%] [G loss: 0.923475]\n",
      "epoch:17 step:16761 [D loss: 0.497191, acc.: 78.12%] [G loss: 1.182437]\n",
      "epoch:17 step:16762 [D loss: 0.571234, acc.: 74.22%] [G loss: 1.020684]\n",
      "epoch:17 step:16763 [D loss: 0.422296, acc.: 84.38%] [G loss: 1.220473]\n",
      "epoch:17 step:16764 [D loss: 0.590835, acc.: 68.75%] [G loss: 1.197811]\n",
      "epoch:17 step:16765 [D loss: 0.741439, acc.: 52.34%] [G loss: 0.873416]\n",
      "epoch:17 step:16766 [D loss: 0.751833, acc.: 48.44%] [G loss: 1.095036]\n",
      "epoch:17 step:16767 [D loss: 0.708997, acc.: 54.69%] [G loss: 1.047846]\n",
      "epoch:17 step:16768 [D loss: 0.574039, acc.: 68.75%] [G loss: 1.025683]\n",
      "epoch:17 step:16769 [D loss: 0.570532, acc.: 73.44%] [G loss: 1.064813]\n",
      "epoch:17 step:16770 [D loss: 0.435210, acc.: 79.69%] [G loss: 0.854338]\n",
      "epoch:17 step:16771 [D loss: 0.466485, acc.: 78.12%] [G loss: 0.949077]\n",
      "epoch:17 step:16772 [D loss: 0.913511, acc.: 40.62%] [G loss: 1.108295]\n",
      "epoch:17 step:16773 [D loss: 0.707651, acc.: 53.91%] [G loss: 1.017605]\n",
      "epoch:17 step:16774 [D loss: 0.414469, acc.: 89.84%] [G loss: 1.155227]\n",
      "epoch:17 step:16775 [D loss: 0.787020, acc.: 48.44%] [G loss: 0.866325]\n",
      "epoch:17 step:16776 [D loss: 0.508186, acc.: 73.44%] [G loss: 1.012025]\n",
      "epoch:17 step:16777 [D loss: 0.441044, acc.: 83.59%] [G loss: 0.779743]\n",
      "epoch:17 step:16778 [D loss: 0.559354, acc.: 73.44%] [G loss: 1.129576]\n",
      "epoch:17 step:16779 [D loss: 0.245500, acc.: 96.88%] [G loss: 0.986471]\n",
      "epoch:17 step:16780 [D loss: 0.234548, acc.: 93.75%] [G loss: 1.323511]\n",
      "epoch:17 step:16781 [D loss: 0.379825, acc.: 83.59%] [G loss: 1.481649]\n",
      "epoch:17 step:16782 [D loss: 0.375924, acc.: 87.50%] [G loss: 1.384321]\n",
      "epoch:17 step:16783 [D loss: 0.280271, acc.: 88.28%] [G loss: 1.556259]\n",
      "epoch:17 step:16784 [D loss: 0.640061, acc.: 64.06%] [G loss: 1.414219]\n",
      "epoch:17 step:16785 [D loss: 0.678891, acc.: 60.16%] [G loss: 0.910196]\n",
      "epoch:17 step:16786 [D loss: 0.329771, acc.: 93.75%] [G loss: 1.369337]\n",
      "epoch:17 step:16787 [D loss: 0.537467, acc.: 75.00%] [G loss: 1.342279]\n",
      "epoch:17 step:16788 [D loss: 0.583396, acc.: 68.75%] [G loss: 1.341321]\n",
      "epoch:17 step:16789 [D loss: 0.579585, acc.: 69.53%] [G loss: 1.367598]\n",
      "epoch:17 step:16790 [D loss: 0.601939, acc.: 64.84%] [G loss: 1.309312]\n",
      "epoch:17 step:16791 [D loss: 0.699710, acc.: 59.38%] [G loss: 1.174828]\n",
      "epoch:17 step:16792 [D loss: 0.676483, acc.: 59.38%] [G loss: 1.183005]\n",
      "epoch:17 step:16793 [D loss: 0.724863, acc.: 56.25%] [G loss: 1.043182]\n",
      "epoch:17 step:16794 [D loss: 0.507423, acc.: 75.00%] [G loss: 0.764529]\n",
      "epoch:17 step:16795 [D loss: 0.613514, acc.: 67.97%] [G loss: 1.193257]\n",
      "epoch:17 step:16796 [D loss: 0.527988, acc.: 71.88%] [G loss: 1.181186]\n",
      "epoch:17 step:16797 [D loss: 0.844624, acc.: 33.59%] [G loss: 0.576940]\n",
      "epoch:17 step:16798 [D loss: 0.671007, acc.: 56.25%] [G loss: 1.232630]\n",
      "epoch:17 step:16799 [D loss: 1.324138, acc.: 34.38%] [G loss: 1.138396]\n",
      "epoch:17 step:16800 [D loss: 0.657487, acc.: 67.97%] [G loss: 1.464138]\n",
      "##############\n",
      "[3.98604423 2.76603841 6.50339674 5.55122084 4.9919615  6.26413157\n",
      " 5.11512918 5.77219162 6.17779516 5.22931744]\n",
      "##########\n",
      "epoch:17 step:16801 [D loss: 0.606637, acc.: 65.62%] [G loss: 1.253042]\n",
      "epoch:17 step:16802 [D loss: 0.706489, acc.: 56.25%] [G loss: 1.379998]\n",
      "epoch:17 step:16803 [D loss: 0.675556, acc.: 54.69%] [G loss: 1.182077]\n",
      "epoch:17 step:16804 [D loss: 0.710699, acc.: 60.94%] [G loss: 1.049775]\n",
      "epoch:17 step:16805 [D loss: 0.696928, acc.: 57.81%] [G loss: 1.282822]\n",
      "epoch:17 step:16806 [D loss: 0.538750, acc.: 75.78%] [G loss: 1.164556]\n",
      "epoch:17 step:16807 [D loss: 0.398340, acc.: 85.94%] [G loss: 1.019620]\n",
      "epoch:17 step:16808 [D loss: 0.704039, acc.: 62.50%] [G loss: 0.841362]\n",
      "epoch:17 step:16809 [D loss: 0.774548, acc.: 43.75%] [G loss: 1.008685]\n",
      "epoch:17 step:16810 [D loss: 0.715138, acc.: 50.00%] [G loss: 0.894734]\n",
      "epoch:17 step:16811 [D loss: 0.454187, acc.: 77.34%] [G loss: 0.893283]\n",
      "epoch:17 step:16812 [D loss: 0.443517, acc.: 81.25%] [G loss: 1.073127]\n",
      "epoch:17 step:16813 [D loss: 0.294039, acc.: 90.62%] [G loss: 1.025904]\n",
      "epoch:17 step:16814 [D loss: 0.421628, acc.: 74.22%] [G loss: 1.363836]\n",
      "epoch:17 step:16815 [D loss: 0.268162, acc.: 96.09%] [G loss: 1.434121]\n",
      "epoch:17 step:16816 [D loss: 0.309737, acc.: 92.97%] [G loss: 1.353511]\n",
      "epoch:17 step:16817 [D loss: 0.826743, acc.: 48.44%] [G loss: 1.504224]\n",
      "epoch:17 step:16818 [D loss: 0.424845, acc.: 87.50%] [G loss: 1.265509]\n",
      "epoch:17 step:16819 [D loss: 0.413693, acc.: 86.72%] [G loss: 1.227422]\n",
      "epoch:17 step:16820 [D loss: 0.734320, acc.: 52.34%] [G loss: 1.367305]\n",
      "epoch:17 step:16821 [D loss: 0.853650, acc.: 51.56%] [G loss: 1.041780]\n",
      "epoch:17 step:16822 [D loss: 0.676052, acc.: 58.59%] [G loss: 1.157253]\n",
      "epoch:17 step:16823 [D loss: 0.483207, acc.: 84.38%] [G loss: 1.035270]\n",
      "epoch:17 step:16824 [D loss: 0.670448, acc.: 56.25%] [G loss: 0.946784]\n",
      "epoch:17 step:16825 [D loss: 0.582356, acc.: 69.53%] [G loss: 1.117737]\n",
      "epoch:17 step:16826 [D loss: 0.504110, acc.: 82.81%] [G loss: 1.013271]\n",
      "epoch:17 step:16827 [D loss: 0.376894, acc.: 87.50%] [G loss: 1.213622]\n",
      "epoch:17 step:16828 [D loss: 0.282582, acc.: 93.75%] [G loss: 1.219377]\n",
      "epoch:17 step:16829 [D loss: 0.332830, acc.: 92.19%] [G loss: 1.345547]\n",
      "epoch:17 step:16830 [D loss: 0.561051, acc.: 67.97%] [G loss: 1.276041]\n",
      "epoch:17 step:16831 [D loss: 0.598157, acc.: 67.97%] [G loss: 1.280031]\n",
      "epoch:17 step:16832 [D loss: 0.507679, acc.: 76.56%] [G loss: 1.410125]\n",
      "epoch:17 step:16833 [D loss: 0.292213, acc.: 94.53%] [G loss: 0.933841]\n",
      "epoch:17 step:16834 [D loss: 0.573381, acc.: 67.19%] [G loss: 1.307131]\n",
      "epoch:17 step:16835 [D loss: 0.273586, acc.: 95.31%] [G loss: 1.234858]\n",
      "epoch:17 step:16836 [D loss: 0.799374, acc.: 53.91%] [G loss: 1.195698]\n",
      "epoch:17 step:16837 [D loss: 0.918097, acc.: 35.94%] [G loss: 0.951630]\n",
      "epoch:17 step:16838 [D loss: 0.525793, acc.: 80.47%] [G loss: 0.966822]\n",
      "epoch:17 step:16839 [D loss: 0.600323, acc.: 65.62%] [G loss: 1.010620]\n",
      "epoch:17 step:16840 [D loss: 0.510600, acc.: 77.34%] [G loss: 0.991313]\n",
      "epoch:17 step:16841 [D loss: 0.227412, acc.: 95.31%] [G loss: 1.190583]\n",
      "epoch:17 step:16842 [D loss: 0.868687, acc.: 38.28%] [G loss: 1.093754]\n",
      "epoch:17 step:16843 [D loss: 0.655132, acc.: 58.59%] [G loss: 1.286397]\n",
      "epoch:17 step:16844 [D loss: 0.660770, acc.: 57.03%] [G loss: 1.435286]\n",
      "epoch:17 step:16845 [D loss: 0.496075, acc.: 73.44%] [G loss: 0.953967]\n",
      "epoch:17 step:16846 [D loss: 0.385629, acc.: 86.72%] [G loss: 1.212406]\n",
      "epoch:17 step:16847 [D loss: 0.567403, acc.: 67.97%] [G loss: 1.265549]\n",
      "epoch:17 step:16848 [D loss: 0.454018, acc.: 81.25%] [G loss: 1.190306]\n",
      "epoch:17 step:16849 [D loss: 0.294120, acc.: 85.16%] [G loss: 1.248687]\n",
      "epoch:17 step:16850 [D loss: 0.257471, acc.: 95.31%] [G loss: 1.456052]\n",
      "epoch:17 step:16851 [D loss: 0.524506, acc.: 71.88%] [G loss: 1.183287]\n",
      "epoch:17 step:16852 [D loss: 0.706804, acc.: 57.81%] [G loss: 1.154022]\n",
      "epoch:17 step:16853 [D loss: 0.507913, acc.: 76.56%] [G loss: 1.146596]\n",
      "epoch:17 step:16854 [D loss: 0.661686, acc.: 64.06%] [G loss: 1.134436]\n",
      "epoch:17 step:16855 [D loss: 0.579906, acc.: 66.41%] [G loss: 1.033447]\n",
      "epoch:17 step:16856 [D loss: 0.618975, acc.: 69.53%] [G loss: 1.168870]\n",
      "epoch:17 step:16857 [D loss: 0.637379, acc.: 68.75%] [G loss: 1.153934]\n",
      "epoch:17 step:16858 [D loss: 0.234325, acc.: 89.84%] [G loss: 1.462578]\n",
      "epoch:17 step:16859 [D loss: 0.424140, acc.: 81.25%] [G loss: 1.222236]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:17 step:16860 [D loss: 0.437625, acc.: 86.72%] [G loss: 1.141848]\n",
      "epoch:17 step:16861 [D loss: 0.617325, acc.: 68.75%] [G loss: 1.050849]\n",
      "epoch:17 step:16862 [D loss: 0.625454, acc.: 68.75%] [G loss: 0.871333]\n",
      "epoch:17 step:16863 [D loss: 0.446853, acc.: 79.69%] [G loss: 0.878736]\n",
      "epoch:17 step:16864 [D loss: 0.797317, acc.: 55.47%] [G loss: 1.364348]\n",
      "epoch:17 step:16865 [D loss: 0.394361, acc.: 87.50%] [G loss: 1.366341]\n",
      "epoch:17 step:16866 [D loss: 0.206865, acc.: 92.97%] [G loss: 1.099219]\n",
      "epoch:18 step:16867 [D loss: 0.836243, acc.: 53.91%] [G loss: 1.099556]\n",
      "epoch:18 step:16868 [D loss: 0.811804, acc.: 53.91%] [G loss: 0.917183]\n",
      "epoch:18 step:16869 [D loss: 0.703908, acc.: 59.38%] [G loss: 1.076178]\n",
      "epoch:18 step:16870 [D loss: 0.754745, acc.: 53.91%] [G loss: 1.072060]\n",
      "epoch:18 step:16871 [D loss: 0.765412, acc.: 58.59%] [G loss: 1.169341]\n",
      "epoch:18 step:16872 [D loss: 0.653646, acc.: 62.50%] [G loss: 0.827531]\n",
      "epoch:18 step:16873 [D loss: 0.661280, acc.: 57.81%] [G loss: 0.758893]\n",
      "epoch:18 step:16874 [D loss: 0.651531, acc.: 57.03%] [G loss: 0.921362]\n",
      "epoch:18 step:16875 [D loss: 0.538195, acc.: 72.66%] [G loss: 1.175540]\n",
      "epoch:18 step:16876 [D loss: 0.554758, acc.: 74.22%] [G loss: 1.075107]\n",
      "epoch:18 step:16877 [D loss: 0.534554, acc.: 78.12%] [G loss: 0.949605]\n",
      "epoch:18 step:16878 [D loss: 0.489906, acc.: 78.91%] [G loss: 0.925952]\n",
      "epoch:18 step:16879 [D loss: 0.623284, acc.: 67.97%] [G loss: 0.617582]\n",
      "epoch:18 step:16880 [D loss: 0.763866, acc.: 58.59%] [G loss: 1.195657]\n",
      "epoch:18 step:16881 [D loss: 0.455215, acc.: 84.38%] [G loss: 1.302959]\n",
      "epoch:18 step:16882 [D loss: 0.550393, acc.: 72.66%] [G loss: 0.703147]\n",
      "epoch:18 step:16883 [D loss: 0.688168, acc.: 60.94%] [G loss: 0.674067]\n",
      "epoch:18 step:16884 [D loss: 0.838156, acc.: 46.09%] [G loss: 0.997384]\n",
      "epoch:18 step:16885 [D loss: 0.922841, acc.: 29.69%] [G loss: 0.630066]\n",
      "epoch:18 step:16886 [D loss: 0.851390, acc.: 32.81%] [G loss: 1.179101]\n",
      "epoch:18 step:16887 [D loss: 0.818086, acc.: 55.47%] [G loss: 0.936878]\n",
      "epoch:18 step:16888 [D loss: 0.665931, acc.: 58.59%] [G loss: 0.843278]\n",
      "epoch:18 step:16889 [D loss: 0.883006, acc.: 32.03%] [G loss: 1.035068]\n",
      "epoch:18 step:16890 [D loss: 0.725698, acc.: 55.47%] [G loss: 1.043526]\n",
      "epoch:18 step:16891 [D loss: 0.562665, acc.: 71.09%] [G loss: 1.050250]\n",
      "epoch:18 step:16892 [D loss: 0.716122, acc.: 50.78%] [G loss: 0.944765]\n",
      "epoch:18 step:16893 [D loss: 0.359018, acc.: 79.69%] [G loss: 1.213072]\n",
      "epoch:18 step:16894 [D loss: 0.416596, acc.: 85.16%] [G loss: 0.921590]\n",
      "epoch:18 step:16895 [D loss: 0.660971, acc.: 58.59%] [G loss: 1.331684]\n",
      "epoch:18 step:16896 [D loss: 0.613607, acc.: 60.94%] [G loss: 1.448699]\n",
      "epoch:18 step:16897 [D loss: 0.262749, acc.: 92.19%] [G loss: 1.279629]\n",
      "epoch:18 step:16898 [D loss: 0.242400, acc.: 96.88%] [G loss: 1.633550]\n",
      "epoch:18 step:16899 [D loss: 0.199172, acc.: 99.22%] [G loss: 1.680412]\n",
      "epoch:18 step:16900 [D loss: 0.234204, acc.: 96.88%] [G loss: 1.872473]\n",
      "epoch:18 step:16901 [D loss: 0.172353, acc.: 95.31%] [G loss: 1.470568]\n",
      "epoch:18 step:16902 [D loss: 0.174754, acc.: 92.97%] [G loss: 1.920420]\n",
      "epoch:18 step:16903 [D loss: 0.962547, acc.: 47.66%] [G loss: 1.322015]\n",
      "epoch:18 step:16904 [D loss: 0.925034, acc.: 44.53%] [G loss: 1.321543]\n",
      "epoch:18 step:16905 [D loss: 0.933921, acc.: 44.53%] [G loss: 0.801026]\n",
      "epoch:18 step:16906 [D loss: 0.697960, acc.: 52.34%] [G loss: 1.099843]\n",
      "epoch:18 step:16907 [D loss: 0.566717, acc.: 77.34%] [G loss: 0.636657]\n",
      "epoch:18 step:16908 [D loss: 0.459737, acc.: 85.16%] [G loss: 0.964367]\n",
      "epoch:18 step:16909 [D loss: 0.421038, acc.: 80.47%] [G loss: 1.190774]\n",
      "epoch:18 step:16910 [D loss: 0.565868, acc.: 71.09%] [G loss: 1.193845]\n",
      "epoch:18 step:16911 [D loss: 0.572750, acc.: 67.97%] [G loss: 0.731365]\n",
      "epoch:18 step:16912 [D loss: 0.461236, acc.: 79.69%] [G loss: 1.273455]\n",
      "epoch:18 step:16913 [D loss: 0.653428, acc.: 60.16%] [G loss: 0.428368]\n",
      "epoch:18 step:16914 [D loss: 0.835327, acc.: 42.97%] [G loss: 1.346618]\n",
      "epoch:18 step:16915 [D loss: 0.665153, acc.: 61.72%] [G loss: 1.247146]\n",
      "epoch:18 step:16916 [D loss: 0.462676, acc.: 85.94%] [G loss: 1.077628]\n",
      "epoch:18 step:16917 [D loss: 0.506354, acc.: 80.47%] [G loss: 1.055644]\n",
      "epoch:18 step:16918 [D loss: 0.673660, acc.: 59.38%] [G loss: 0.570816]\n",
      "epoch:18 step:16919 [D loss: 0.927259, acc.: 30.47%] [G loss: 1.493582]\n",
      "epoch:18 step:16920 [D loss: 0.929271, acc.: 28.91%] [G loss: 1.190122]\n",
      "epoch:18 step:16921 [D loss: 0.718556, acc.: 58.59%] [G loss: 1.212149]\n",
      "epoch:18 step:16922 [D loss: 0.691167, acc.: 53.91%] [G loss: 1.162802]\n",
      "epoch:18 step:16923 [D loss: 0.515780, acc.: 67.19%] [G loss: 0.734982]\n",
      "epoch:18 step:16924 [D loss: 0.463159, acc.: 82.03%] [G loss: 0.919281]\n",
      "epoch:18 step:16925 [D loss: 0.739975, acc.: 53.91%] [G loss: 0.894088]\n",
      "epoch:18 step:16926 [D loss: 0.496325, acc.: 79.69%] [G loss: 0.950831]\n",
      "epoch:18 step:16927 [D loss: 1.149852, acc.: 21.88%] [G loss: 0.608912]\n",
      "epoch:18 step:16928 [D loss: 0.831449, acc.: 45.31%] [G loss: 1.357505]\n",
      "epoch:18 step:16929 [D loss: 1.219169, acc.: 18.75%] [G loss: 1.242676]\n",
      "epoch:18 step:16930 [D loss: 0.639107, acc.: 56.25%] [G loss: 1.317182]\n",
      "epoch:18 step:16931 [D loss: 0.791606, acc.: 46.09%] [G loss: 1.428618]\n",
      "epoch:18 step:16932 [D loss: 0.690905, acc.: 54.69%] [G loss: 1.393860]\n",
      "epoch:18 step:16933 [D loss: 0.654955, acc.: 57.81%] [G loss: 1.647043]\n",
      "epoch:18 step:16934 [D loss: 0.511956, acc.: 78.91%] [G loss: 1.841181]\n",
      "epoch:18 step:16935 [D loss: 0.450561, acc.: 79.69%] [G loss: 2.790081]\n",
      "epoch:18 step:16936 [D loss: 0.364652, acc.: 82.81%] [G loss: 2.287227]\n",
      "epoch:18 step:16937 [D loss: 0.969621, acc.: 56.25%] [G loss: 1.240734]\n",
      "epoch:18 step:16938 [D loss: 0.706643, acc.: 60.16%] [G loss: 1.093771]\n",
      "epoch:18 step:16939 [D loss: 0.723890, acc.: 50.78%] [G loss: 1.217736]\n",
      "epoch:18 step:16940 [D loss: 0.593958, acc.: 67.97%] [G loss: 1.153847]\n",
      "epoch:18 step:16941 [D loss: 0.656685, acc.: 59.38%] [G loss: 1.006760]\n",
      "epoch:18 step:16942 [D loss: 0.444059, acc.: 78.91%] [G loss: 0.920148]\n",
      "epoch:18 step:16943 [D loss: 0.490886, acc.: 77.34%] [G loss: 1.172904]\n",
      "epoch:18 step:16944 [D loss: 0.736129, acc.: 55.47%] [G loss: 0.978112]\n",
      "epoch:18 step:16945 [D loss: 0.649958, acc.: 63.28%] [G loss: 0.987408]\n",
      "epoch:18 step:16946 [D loss: 0.403275, acc.: 90.62%] [G loss: 1.009978]\n",
      "epoch:18 step:16947 [D loss: 0.382270, acc.: 89.06%] [G loss: 1.116243]\n",
      "epoch:18 step:16948 [D loss: 0.317876, acc.: 90.62%] [G loss: 1.462808]\n",
      "epoch:18 step:16949 [D loss: 0.273007, acc.: 96.88%] [G loss: 1.500608]\n",
      "epoch:18 step:16950 [D loss: 0.530923, acc.: 71.88%] [G loss: 1.286576]\n",
      "epoch:18 step:16951 [D loss: 0.358070, acc.: 89.06%] [G loss: 1.969264]\n",
      "epoch:18 step:16952 [D loss: 0.433572, acc.: 88.28%] [G loss: 1.548181]\n",
      "epoch:18 step:16953 [D loss: 0.272339, acc.: 96.88%] [G loss: 1.644387]\n",
      "epoch:18 step:16954 [D loss: 0.250392, acc.: 98.44%] [G loss: 1.670880]\n",
      "epoch:18 step:16955 [D loss: 0.279228, acc.: 92.19%] [G loss: 1.716455]\n",
      "epoch:18 step:16956 [D loss: 0.347530, acc.: 91.41%] [G loss: 2.326240]\n",
      "epoch:18 step:16957 [D loss: 0.358811, acc.: 91.41%] [G loss: 1.936234]\n",
      "epoch:18 step:16958 [D loss: 0.242899, acc.: 95.31%] [G loss: 2.016409]\n",
      "epoch:18 step:16959 [D loss: 0.163591, acc.: 97.66%] [G loss: 2.568391]\n",
      "epoch:18 step:16960 [D loss: 0.344961, acc.: 88.28%] [G loss: 1.043119]\n",
      "epoch:18 step:16961 [D loss: 0.755353, acc.: 57.81%] [G loss: 1.364737]\n",
      "epoch:18 step:16962 [D loss: 0.631091, acc.: 60.94%] [G loss: 1.016286]\n",
      "epoch:18 step:16963 [D loss: 0.828278, acc.: 53.91%] [G loss: 1.231388]\n",
      "epoch:18 step:16964 [D loss: 0.799990, acc.: 53.12%] [G loss: 1.125116]\n",
      "epoch:18 step:16965 [D loss: 0.595107, acc.: 69.53%] [G loss: 1.276802]\n",
      "epoch:18 step:16966 [D loss: 0.594048, acc.: 66.41%] [G loss: 1.212145]\n",
      "epoch:18 step:16967 [D loss: 0.646221, acc.: 61.72%] [G loss: 1.267398]\n",
      "epoch:18 step:16968 [D loss: 0.770631, acc.: 50.00%] [G loss: 0.991921]\n",
      "epoch:18 step:16969 [D loss: 0.673373, acc.: 57.81%] [G loss: 1.305530]\n",
      "epoch:18 step:16970 [D loss: 1.098748, acc.: 27.34%] [G loss: 1.075524]\n",
      "epoch:18 step:16971 [D loss: 0.931471, acc.: 42.19%] [G loss: 1.110765]\n",
      "epoch:18 step:16972 [D loss: 0.779427, acc.: 52.34%] [G loss: 0.714692]\n",
      "epoch:18 step:16973 [D loss: 0.675149, acc.: 59.38%] [G loss: 1.241172]\n",
      "epoch:18 step:16974 [D loss: 0.648585, acc.: 61.72%] [G loss: 1.069411]\n",
      "epoch:18 step:16975 [D loss: 0.667073, acc.: 57.03%] [G loss: 1.061922]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:18 step:16976 [D loss: 0.706405, acc.: 51.56%] [G loss: 0.863493]\n",
      "epoch:18 step:16977 [D loss: 0.778761, acc.: 53.12%] [G loss: 1.091181]\n",
      "epoch:18 step:16978 [D loss: 0.582774, acc.: 69.53%] [G loss: 1.138692]\n",
      "epoch:18 step:16979 [D loss: 0.575659, acc.: 72.66%] [G loss: 1.098363]\n",
      "epoch:18 step:16980 [D loss: 0.461704, acc.: 85.16%] [G loss: 1.184140]\n",
      "epoch:18 step:16981 [D loss: 0.474088, acc.: 80.47%] [G loss: 1.044828]\n",
      "epoch:18 step:16982 [D loss: 0.629956, acc.: 63.28%] [G loss: 0.932751]\n",
      "epoch:18 step:16983 [D loss: 0.743737, acc.: 55.47%] [G loss: 0.912135]\n",
      "epoch:18 step:16984 [D loss: 0.549765, acc.: 72.66%] [G loss: 1.092124]\n",
      "epoch:18 step:16985 [D loss: 0.307142, acc.: 92.19%] [G loss: 1.068536]\n",
      "epoch:18 step:16986 [D loss: 0.707078, acc.: 64.06%] [G loss: 1.143780]\n",
      "epoch:18 step:16987 [D loss: 0.449323, acc.: 78.91%] [G loss: 0.982740]\n",
      "epoch:18 step:16988 [D loss: 0.567611, acc.: 66.41%] [G loss: 1.305316]\n",
      "epoch:18 step:16989 [D loss: 0.657017, acc.: 64.06%] [G loss: 1.202643]\n",
      "epoch:18 step:16990 [D loss: 0.593066, acc.: 72.66%] [G loss: 1.230017]\n",
      "epoch:18 step:16991 [D loss: 0.742489, acc.: 47.66%] [G loss: 1.130555]\n",
      "epoch:18 step:16992 [D loss: 0.656434, acc.: 67.19%] [G loss: 0.819586]\n",
      "epoch:18 step:16993 [D loss: 0.592035, acc.: 68.75%] [G loss: 1.188659]\n",
      "epoch:18 step:16994 [D loss: 0.661443, acc.: 57.81%] [G loss: 1.188916]\n",
      "epoch:18 step:16995 [D loss: 0.728350, acc.: 50.78%] [G loss: 1.009619]\n",
      "epoch:18 step:16996 [D loss: 0.471662, acc.: 78.91%] [G loss: 1.402466]\n",
      "epoch:18 step:16997 [D loss: 0.592160, acc.: 71.09%] [G loss: 1.069237]\n",
      "epoch:18 step:16998 [D loss: 0.621449, acc.: 65.62%] [G loss: 1.018075]\n",
      "epoch:18 step:16999 [D loss: 0.526976, acc.: 74.22%] [G loss: 1.184204]\n",
      "epoch:18 step:17000 [D loss: 0.390522, acc.: 85.16%] [G loss: 1.214515]\n",
      "##############\n",
      "[3.07130313 1.96082781 6.31314052 5.26182364 4.27371132 6.31774049\n",
      " 5.23504206 5.08505269 5.58153741 4.61391084]\n",
      "##########\n",
      "epoch:18 step:17001 [D loss: 0.595903, acc.: 67.97%] [G loss: 1.234728]\n",
      "epoch:18 step:17002 [D loss: 0.647872, acc.: 64.06%] [G loss: 1.248387]\n",
      "epoch:18 step:17003 [D loss: 0.656912, acc.: 63.28%] [G loss: 1.166152]\n",
      "epoch:18 step:17004 [D loss: 0.617289, acc.: 65.62%] [G loss: 1.226045]\n",
      "epoch:18 step:17005 [D loss: 0.695196, acc.: 55.47%] [G loss: 0.998923]\n",
      "epoch:18 step:17006 [D loss: 0.467159, acc.: 73.44%] [G loss: 1.219347]\n",
      "epoch:18 step:17007 [D loss: 0.439185, acc.: 83.59%] [G loss: 1.018786]\n",
      "epoch:18 step:17008 [D loss: 0.548312, acc.: 73.44%] [G loss: 1.522403]\n",
      "epoch:18 step:17009 [D loss: 0.265781, acc.: 93.75%] [G loss: 1.471105]\n",
      "epoch:18 step:17010 [D loss: 0.461909, acc.: 84.38%] [G loss: 1.435741]\n",
      "epoch:18 step:17011 [D loss: 0.224495, acc.: 95.31%] [G loss: 1.351719]\n",
      "epoch:18 step:17012 [D loss: 0.442406, acc.: 78.91%] [G loss: 1.437769]\n",
      "epoch:18 step:17013 [D loss: 0.622403, acc.: 64.84%] [G loss: 1.308920]\n",
      "epoch:18 step:17014 [D loss: 0.789670, acc.: 45.31%] [G loss: 1.193564]\n",
      "epoch:18 step:17015 [D loss: 0.259921, acc.: 91.41%] [G loss: 1.313470]\n",
      "epoch:18 step:17016 [D loss: 0.203859, acc.: 96.09%] [G loss: 1.442005]\n",
      "epoch:18 step:17017 [D loss: 0.233301, acc.: 95.31%] [G loss: 1.488272]\n",
      "epoch:18 step:17018 [D loss: 0.353507, acc.: 87.50%] [G loss: 1.729689]\n",
      "epoch:18 step:17019 [D loss: 0.781211, acc.: 51.56%] [G loss: 1.062762]\n",
      "epoch:18 step:17020 [D loss: 0.540052, acc.: 73.44%] [G loss: 1.160231]\n",
      "epoch:18 step:17021 [D loss: 0.540578, acc.: 74.22%] [G loss: 0.939238]\n",
      "epoch:18 step:17022 [D loss: 0.699367, acc.: 57.81%] [G loss: 0.847472]\n",
      "epoch:18 step:17023 [D loss: 0.611489, acc.: 64.06%] [G loss: 0.752658]\n",
      "epoch:18 step:17024 [D loss: 0.557361, acc.: 65.62%] [G loss: 0.991895]\n",
      "epoch:18 step:17025 [D loss: 0.841682, acc.: 47.66%] [G loss: 1.061374]\n",
      "epoch:18 step:17026 [D loss: 0.538251, acc.: 71.09%] [G loss: 1.204852]\n",
      "epoch:18 step:17027 [D loss: 0.742501, acc.: 57.81%] [G loss: 0.292634]\n",
      "epoch:18 step:17028 [D loss: 0.502029, acc.: 75.78%] [G loss: 1.341434]\n",
      "epoch:18 step:17029 [D loss: 0.458766, acc.: 78.91%] [G loss: 1.563158]\n",
      "epoch:18 step:17030 [D loss: 0.620816, acc.: 64.84%] [G loss: 1.414338]\n",
      "epoch:18 step:17031 [D loss: 0.570461, acc.: 67.97%] [G loss: 1.408510]\n",
      "epoch:18 step:17032 [D loss: 0.901664, acc.: 42.19%] [G loss: 1.201929]\n",
      "epoch:18 step:17033 [D loss: 0.722974, acc.: 55.47%] [G loss: 1.031484]\n",
      "epoch:18 step:17034 [D loss: 0.771282, acc.: 52.34%] [G loss: 0.895741]\n",
      "epoch:18 step:17035 [D loss: 0.567695, acc.: 71.09%] [G loss: 1.161316]\n",
      "epoch:18 step:17036 [D loss: 0.536410, acc.: 76.56%] [G loss: 0.874489]\n",
      "epoch:18 step:17037 [D loss: 0.664602, acc.: 58.59%] [G loss: 0.803367]\n",
      "epoch:18 step:17038 [D loss: 0.502277, acc.: 78.12%] [G loss: 1.010102]\n",
      "epoch:18 step:17039 [D loss: 0.823076, acc.: 40.62%] [G loss: 0.893949]\n",
      "epoch:18 step:17040 [D loss: 0.759137, acc.: 48.44%] [G loss: 1.112159]\n",
      "epoch:18 step:17041 [D loss: 0.751977, acc.: 54.69%] [G loss: 1.077163]\n",
      "epoch:18 step:17042 [D loss: 0.793185, acc.: 50.00%] [G loss: 1.281486]\n",
      "epoch:18 step:17043 [D loss: 0.718253, acc.: 52.34%] [G loss: 1.115079]\n",
      "epoch:18 step:17044 [D loss: 0.606107, acc.: 67.97%] [G loss: 1.032846]\n",
      "epoch:18 step:17045 [D loss: 0.690000, acc.: 57.03%] [G loss: 1.000093]\n",
      "epoch:18 step:17046 [D loss: 0.893907, acc.: 35.16%] [G loss: 1.266323]\n",
      "epoch:18 step:17047 [D loss: 0.785021, acc.: 48.44%] [G loss: 1.008264]\n",
      "epoch:18 step:17048 [D loss: 0.848789, acc.: 47.66%] [G loss: 1.345311]\n",
      "epoch:18 step:17049 [D loss: 0.669433, acc.: 56.25%] [G loss: 1.256893]\n",
      "epoch:18 step:17050 [D loss: 0.475053, acc.: 75.00%] [G loss: 1.320758]\n",
      "epoch:18 step:17051 [D loss: 0.582053, acc.: 68.75%] [G loss: 0.898954]\n",
      "epoch:18 step:17052 [D loss: 0.674507, acc.: 60.16%] [G loss: 1.064653]\n",
      "epoch:18 step:17053 [D loss: 0.689157, acc.: 58.59%] [G loss: 1.094995]\n",
      "epoch:18 step:17054 [D loss: 0.564093, acc.: 74.22%] [G loss: 0.758826]\n",
      "epoch:18 step:17055 [D loss: 0.658880, acc.: 58.59%] [G loss: 1.357506]\n",
      "epoch:18 step:17056 [D loss: 0.557546, acc.: 75.78%] [G loss: 1.261399]\n",
      "epoch:18 step:17057 [D loss: 0.584254, acc.: 67.19%] [G loss: 1.639125]\n",
      "epoch:18 step:17058 [D loss: 0.462740, acc.: 82.81%] [G loss: 0.799531]\n",
      "epoch:18 step:17059 [D loss: 0.657164, acc.: 68.75%] [G loss: 1.008925]\n",
      "epoch:18 step:17060 [D loss: 0.357534, acc.: 92.19%] [G loss: 1.148478]\n",
      "epoch:18 step:17061 [D loss: 0.577647, acc.: 69.53%] [G loss: 1.358190]\n",
      "epoch:18 step:17062 [D loss: 0.582118, acc.: 68.75%] [G loss: 1.011187]\n",
      "epoch:18 step:17063 [D loss: 0.486444, acc.: 79.69%] [G loss: 1.324651]\n",
      "epoch:18 step:17064 [D loss: 0.583805, acc.: 67.19%] [G loss: 1.247008]\n",
      "epoch:18 step:17065 [D loss: 0.734900, acc.: 49.22%] [G loss: 1.062892]\n",
      "epoch:18 step:17066 [D loss: 0.537364, acc.: 71.88%] [G loss: 1.261590]\n",
      "epoch:18 step:17067 [D loss: 0.294892, acc.: 90.62%] [G loss: 1.255242]\n",
      "epoch:18 step:17068 [D loss: 0.790367, acc.: 46.09%] [G loss: 1.306169]\n",
      "epoch:18 step:17069 [D loss: 0.554040, acc.: 73.44%] [G loss: 1.111974]\n",
      "epoch:18 step:17070 [D loss: 0.464728, acc.: 81.25%] [G loss: 1.376523]\n",
      "epoch:18 step:17071 [D loss: 0.548507, acc.: 74.22%] [G loss: 1.085031]\n",
      "epoch:18 step:17072 [D loss: 0.412474, acc.: 89.84%] [G loss: 1.357983]\n",
      "epoch:18 step:17073 [D loss: 0.338698, acc.: 90.62%] [G loss: 1.210829]\n",
      "epoch:18 step:17074 [D loss: 0.403707, acc.: 92.19%] [G loss: 1.463225]\n",
      "epoch:18 step:17075 [D loss: 0.437169, acc.: 85.94%] [G loss: 1.366066]\n",
      "epoch:18 step:17076 [D loss: 1.047289, acc.: 40.62%] [G loss: 1.138056]\n",
      "epoch:18 step:17077 [D loss: 0.950266, acc.: 36.72%] [G loss: 1.141276]\n",
      "epoch:18 step:17078 [D loss: 0.745045, acc.: 50.00%] [G loss: 0.807587]\n",
      "epoch:18 step:17079 [D loss: 0.744439, acc.: 45.31%] [G loss: 1.042707]\n",
      "epoch:18 step:17080 [D loss: 0.750507, acc.: 53.91%] [G loss: 0.777001]\n",
      "epoch:18 step:17081 [D loss: 0.812156, acc.: 42.19%] [G loss: 0.782975]\n",
      "epoch:18 step:17082 [D loss: 0.681859, acc.: 64.84%] [G loss: 1.058878]\n",
      "epoch:18 step:17083 [D loss: 0.594357, acc.: 68.75%] [G loss: 0.818733]\n",
      "epoch:18 step:17084 [D loss: 0.477028, acc.: 82.03%] [G loss: 0.883200]\n",
      "epoch:18 step:17085 [D loss: 0.588086, acc.: 66.41%] [G loss: 0.904117]\n",
      "epoch:18 step:17086 [D loss: 0.240666, acc.: 92.97%] [G loss: 1.207720]\n",
      "epoch:18 step:17087 [D loss: 0.248460, acc.: 88.28%] [G loss: 1.092535]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:18 step:17088 [D loss: 0.486654, acc.: 82.81%] [G loss: 1.212103]\n",
      "epoch:18 step:17089 [D loss: 0.613270, acc.: 65.62%] [G loss: 1.300458]\n",
      "epoch:18 step:17090 [D loss: 0.619883, acc.: 68.75%] [G loss: 1.497903]\n",
      "epoch:18 step:17091 [D loss: 0.553561, acc.: 71.88%] [G loss: 1.178607]\n",
      "epoch:18 step:17092 [D loss: 0.678299, acc.: 61.72%] [G loss: 1.242307]\n",
      "epoch:18 step:17093 [D loss: 0.601428, acc.: 75.78%] [G loss: 1.038490]\n",
      "epoch:18 step:17094 [D loss: 0.685962, acc.: 57.81%] [G loss: 1.313613]\n",
      "epoch:18 step:17095 [D loss: 0.674574, acc.: 56.25%] [G loss: 1.075932]\n",
      "epoch:18 step:17096 [D loss: 0.249902, acc.: 88.28%] [G loss: 1.397001]\n",
      "epoch:18 step:17097 [D loss: 0.202047, acc.: 97.66%] [G loss: 1.466558]\n",
      "epoch:18 step:17098 [D loss: 0.179646, acc.: 96.88%] [G loss: 1.446642]\n",
      "epoch:18 step:17099 [D loss: 0.587640, acc.: 71.09%] [G loss: 1.225266]\n",
      "epoch:18 step:17100 [D loss: 0.338144, acc.: 90.62%] [G loss: 1.234252]\n",
      "epoch:18 step:17101 [D loss: 0.254852, acc.: 96.09%] [G loss: 1.530518]\n",
      "epoch:18 step:17102 [D loss: 0.614222, acc.: 70.31%] [G loss: 0.871852]\n",
      "epoch:18 step:17103 [D loss: 0.276832, acc.: 96.09%] [G loss: 1.469330]\n",
      "epoch:18 step:17104 [D loss: 0.457316, acc.: 76.56%] [G loss: 1.845084]\n",
      "epoch:18 step:17105 [D loss: 0.732362, acc.: 56.25%] [G loss: 0.429466]\n",
      "epoch:18 step:17106 [D loss: 0.778032, acc.: 48.44%] [G loss: 0.915741]\n",
      "epoch:18 step:17107 [D loss: 0.974593, acc.: 46.09%] [G loss: 0.916125]\n",
      "epoch:18 step:17108 [D loss: 0.919896, acc.: 34.38%] [G loss: 0.861781]\n",
      "epoch:18 step:17109 [D loss: 0.459179, acc.: 88.28%] [G loss: 0.580301]\n",
      "epoch:18 step:17110 [D loss: 0.716043, acc.: 48.44%] [G loss: 1.244138]\n",
      "epoch:18 step:17111 [D loss: 0.940784, acc.: 38.28%] [G loss: 0.653322]\n",
      "epoch:18 step:17112 [D loss: 0.720718, acc.: 54.69%] [G loss: 0.998787]\n",
      "epoch:18 step:17113 [D loss: 0.689222, acc.: 61.72%] [G loss: 0.995058]\n",
      "epoch:18 step:17114 [D loss: 0.590733, acc.: 68.75%] [G loss: 1.061558]\n",
      "epoch:18 step:17115 [D loss: 0.687813, acc.: 59.38%] [G loss: 1.093128]\n",
      "epoch:18 step:17116 [D loss: 0.743818, acc.: 46.88%] [G loss: 0.945567]\n",
      "epoch:18 step:17117 [D loss: 0.661926, acc.: 64.84%] [G loss: 0.954827]\n",
      "epoch:18 step:17118 [D loss: 0.681973, acc.: 60.94%] [G loss: 0.835480]\n",
      "epoch:18 step:17119 [D loss: 0.671066, acc.: 63.28%] [G loss: 0.852514]\n",
      "epoch:18 step:17120 [D loss: 0.845552, acc.: 48.44%] [G loss: 0.989327]\n",
      "epoch:18 step:17121 [D loss: 0.454973, acc.: 82.81%] [G loss: 0.939539]\n",
      "epoch:18 step:17122 [D loss: 0.333547, acc.: 82.81%] [G loss: 1.123513]\n",
      "epoch:18 step:17123 [D loss: 0.521506, acc.: 82.03%] [G loss: 1.265788]\n",
      "epoch:18 step:17124 [D loss: 0.664115, acc.: 60.94%] [G loss: 1.105283]\n",
      "epoch:18 step:17125 [D loss: 0.293979, acc.: 88.28%] [G loss: 1.159741]\n",
      "epoch:18 step:17126 [D loss: 0.525080, acc.: 73.44%] [G loss: 1.505893]\n",
      "epoch:18 step:17127 [D loss: 0.308208, acc.: 94.53%] [G loss: 1.353176]\n",
      "epoch:18 step:17128 [D loss: 0.692699, acc.: 62.50%] [G loss: 1.259929]\n",
      "epoch:18 step:17129 [D loss: 0.590727, acc.: 65.62%] [G loss: 1.143986]\n",
      "epoch:18 step:17130 [D loss: 0.562406, acc.: 74.22%] [G loss: 1.131951]\n",
      "epoch:18 step:17131 [D loss: 0.500976, acc.: 78.91%] [G loss: 1.117092]\n",
      "epoch:18 step:17132 [D loss: 0.547348, acc.: 67.19%] [G loss: 1.086938]\n",
      "epoch:18 step:17133 [D loss: 0.594769, acc.: 67.19%] [G loss: 0.972557]\n",
      "epoch:18 step:17134 [D loss: 0.706843, acc.: 52.34%] [G loss: 0.972413]\n",
      "epoch:18 step:17135 [D loss: 0.505123, acc.: 78.91%] [G loss: 1.008223]\n",
      "epoch:18 step:17136 [D loss: 0.662245, acc.: 57.03%] [G loss: 1.202184]\n",
      "epoch:18 step:17137 [D loss: 0.658334, acc.: 57.03%] [G loss: 0.999516]\n",
      "epoch:18 step:17138 [D loss: 0.673045, acc.: 58.59%] [G loss: 1.175401]\n",
      "epoch:18 step:17139 [D loss: 0.613355, acc.: 64.84%] [G loss: 0.872203]\n",
      "epoch:18 step:17140 [D loss: 0.527019, acc.: 71.88%] [G loss: 1.000404]\n",
      "epoch:18 step:17141 [D loss: 0.651375, acc.: 63.28%] [G loss: 1.004918]\n",
      "epoch:18 step:17142 [D loss: 0.512934, acc.: 75.00%] [G loss: 1.022680]\n",
      "epoch:18 step:17143 [D loss: 0.650580, acc.: 62.50%] [G loss: 0.969301]\n",
      "epoch:18 step:17144 [D loss: 0.413175, acc.: 84.38%] [G loss: 1.534308]\n",
      "epoch:18 step:17145 [D loss: 0.279340, acc.: 86.72%] [G loss: 1.062059]\n",
      "epoch:18 step:17146 [D loss: 0.569486, acc.: 74.22%] [G loss: 1.249439]\n",
      "epoch:18 step:17147 [D loss: 0.796556, acc.: 50.78%] [G loss: 1.198089]\n",
      "epoch:18 step:17148 [D loss: 0.786944, acc.: 50.00%] [G loss: 0.890368]\n",
      "epoch:18 step:17149 [D loss: 0.646516, acc.: 64.06%] [G loss: 1.053298]\n",
      "epoch:18 step:17150 [D loss: 0.463391, acc.: 81.25%] [G loss: 1.052536]\n",
      "epoch:18 step:17151 [D loss: 0.512645, acc.: 75.78%] [G loss: 1.142180]\n",
      "epoch:18 step:17152 [D loss: 0.441126, acc.: 86.72%] [G loss: 1.030650]\n",
      "epoch:18 step:17153 [D loss: 0.306867, acc.: 89.84%] [G loss: 1.199813]\n",
      "epoch:18 step:17154 [D loss: 0.300952, acc.: 91.41%] [G loss: 1.174769]\n",
      "epoch:18 step:17155 [D loss: 0.341262, acc.: 78.91%] [G loss: 1.108404]\n",
      "epoch:18 step:17156 [D loss: 0.328387, acc.: 89.06%] [G loss: 1.336331]\n",
      "epoch:18 step:17157 [D loss: 0.552974, acc.: 75.00%] [G loss: 1.340424]\n",
      "epoch:18 step:17158 [D loss: 0.300982, acc.: 96.09%] [G loss: 1.453663]\n",
      "epoch:18 step:17159 [D loss: 0.208660, acc.: 97.66%] [G loss: 1.484873]\n",
      "epoch:18 step:17160 [D loss: 0.624873, acc.: 71.88%] [G loss: 0.993544]\n",
      "epoch:18 step:17161 [D loss: 0.889353, acc.: 53.91%] [G loss: 0.862717]\n",
      "epoch:18 step:17162 [D loss: 0.784045, acc.: 42.97%] [G loss: 1.030008]\n",
      "epoch:18 step:17163 [D loss: 0.890844, acc.: 34.38%] [G loss: 0.850154]\n",
      "epoch:18 step:17164 [D loss: 0.733664, acc.: 51.56%] [G loss: 0.963966]\n",
      "epoch:18 step:17165 [D loss: 0.585835, acc.: 72.66%] [G loss: 1.050748]\n",
      "epoch:18 step:17166 [D loss: 0.720015, acc.: 57.81%] [G loss: 0.970238]\n",
      "epoch:18 step:17167 [D loss: 0.677746, acc.: 60.94%] [G loss: 0.994244]\n",
      "epoch:18 step:17168 [D loss: 0.597629, acc.: 66.41%] [G loss: 0.767372]\n",
      "epoch:18 step:17169 [D loss: 0.798331, acc.: 39.06%] [G loss: 1.010153]\n",
      "epoch:18 step:17170 [D loss: 0.528216, acc.: 77.34%] [G loss: 1.135208]\n",
      "epoch:18 step:17171 [D loss: 0.466092, acc.: 75.00%] [G loss: 1.054203]\n",
      "epoch:18 step:17172 [D loss: 0.970545, acc.: 44.53%] [G loss: 1.286319]\n",
      "epoch:18 step:17173 [D loss: 0.688594, acc.: 57.03%] [G loss: 1.060537]\n",
      "epoch:18 step:17174 [D loss: 0.435802, acc.: 83.59%] [G loss: 1.189867]\n",
      "epoch:18 step:17175 [D loss: 0.265141, acc.: 90.62%] [G loss: 1.256642]\n",
      "epoch:18 step:17176 [D loss: 0.702720, acc.: 55.47%] [G loss: 1.315986]\n",
      "epoch:18 step:17177 [D loss: 0.576221, acc.: 71.88%] [G loss: 1.319079]\n",
      "epoch:18 step:17178 [D loss: 0.192818, acc.: 96.09%] [G loss: 1.236654]\n",
      "epoch:18 step:17179 [D loss: 0.192361, acc.: 97.66%] [G loss: 1.449178]\n",
      "epoch:18 step:17180 [D loss: 0.186833, acc.: 96.09%] [G loss: 1.485639]\n",
      "epoch:18 step:17181 [D loss: 0.207538, acc.: 97.66%] [G loss: 1.389395]\n",
      "epoch:18 step:17182 [D loss: 0.905761, acc.: 52.34%] [G loss: 1.314657]\n",
      "epoch:18 step:17183 [D loss: 0.877133, acc.: 48.44%] [G loss: 1.212505]\n",
      "epoch:18 step:17184 [D loss: 0.781600, acc.: 49.22%] [G loss: 1.153134]\n",
      "epoch:18 step:17185 [D loss: 0.827770, acc.: 45.31%] [G loss: 1.049305]\n",
      "epoch:18 step:17186 [D loss: 0.758272, acc.: 45.31%] [G loss: 0.962252]\n",
      "epoch:18 step:17187 [D loss: 0.824311, acc.: 46.09%] [G loss: 0.903355]\n",
      "epoch:18 step:17188 [D loss: 0.648833, acc.: 61.72%] [G loss: 0.956271]\n",
      "epoch:18 step:17189 [D loss: 0.566713, acc.: 71.09%] [G loss: 1.065042]\n",
      "epoch:18 step:17190 [D loss: 0.529341, acc.: 77.34%] [G loss: 0.924979]\n",
      "epoch:18 step:17191 [D loss: 0.590697, acc.: 64.84%] [G loss: 0.983307]\n",
      "epoch:18 step:17192 [D loss: 0.683991, acc.: 52.34%] [G loss: 0.970111]\n",
      "epoch:18 step:17193 [D loss: 0.538377, acc.: 80.47%] [G loss: 0.613845]\n",
      "epoch:18 step:17194 [D loss: 0.573317, acc.: 71.88%] [G loss: 0.966596]\n",
      "epoch:18 step:17195 [D loss: 0.610355, acc.: 66.41%] [G loss: 0.962131]\n",
      "epoch:18 step:17196 [D loss: 0.822637, acc.: 42.97%] [G loss: 0.757612]\n",
      "epoch:18 step:17197 [D loss: 0.588571, acc.: 64.84%] [G loss: 0.782957]\n",
      "epoch:18 step:17198 [D loss: 0.522059, acc.: 73.44%] [G loss: 0.969147]\n",
      "epoch:18 step:17199 [D loss: 0.235369, acc.: 94.53%] [G loss: 0.784155]\n",
      "epoch:18 step:17200 [D loss: 0.247860, acc.: 92.97%] [G loss: 1.282672]\n",
      "##############\n",
      "[4.04088847 2.41111182 6.53661685 5.96908566 4.8802439  6.43364543\n",
      " 5.61866195 5.86433357 6.07620043 5.36574481]\n",
      "##########\n",
      "epoch:18 step:17201 [D loss: 0.395506, acc.: 92.19%] [G loss: 0.609688]\n",
      "epoch:18 step:17202 [D loss: 0.205044, acc.: 97.66%] [G loss: 1.387005]\n",
      "epoch:18 step:17203 [D loss: 0.298834, acc.: 95.31%] [G loss: 1.529209]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:18 step:17204 [D loss: 0.471266, acc.: 84.38%] [G loss: 0.995380]\n",
      "epoch:18 step:17205 [D loss: 0.650972, acc.: 64.84%] [G loss: 1.112309]\n",
      "epoch:18 step:17206 [D loss: 0.874748, acc.: 30.47%] [G loss: 1.069370]\n",
      "epoch:18 step:17207 [D loss: 1.093012, acc.: 28.91%] [G loss: 0.496800]\n",
      "epoch:18 step:17208 [D loss: 0.181913, acc.: 99.22%] [G loss: 1.472391]\n",
      "epoch:18 step:17209 [D loss: 0.513744, acc.: 61.72%] [G loss: 0.941031]\n",
      "epoch:18 step:17210 [D loss: 0.301985, acc.: 86.72%] [G loss: 1.696031]\n",
      "epoch:18 step:17211 [D loss: 0.738459, acc.: 57.81%] [G loss: 1.962902]\n",
      "epoch:18 step:17212 [D loss: 0.101928, acc.: 99.22%] [G loss: 2.012465]\n",
      "epoch:18 step:17213 [D loss: 0.125553, acc.: 99.22%] [G loss: 2.287831]\n",
      "epoch:18 step:17214 [D loss: 0.998387, acc.: 48.44%] [G loss: 1.814769]\n",
      "epoch:18 step:17215 [D loss: 0.841869, acc.: 52.34%] [G loss: 1.114109]\n",
      "epoch:18 step:17216 [D loss: 0.701990, acc.: 67.19%] [G loss: 1.447970]\n",
      "epoch:18 step:17217 [D loss: 0.780039, acc.: 51.56%] [G loss: 0.635031]\n",
      "epoch:18 step:17218 [D loss: 0.619750, acc.: 65.62%] [G loss: 1.291997]\n",
      "epoch:18 step:17219 [D loss: 0.581940, acc.: 69.53%] [G loss: 1.274574]\n",
      "epoch:18 step:17220 [D loss: 0.510690, acc.: 77.34%] [G loss: 1.223827]\n",
      "epoch:18 step:17221 [D loss: 0.706527, acc.: 60.16%] [G loss: 1.130438]\n",
      "epoch:18 step:17222 [D loss: 0.622317, acc.: 65.62%] [G loss: 1.265853]\n",
      "epoch:18 step:17223 [D loss: 0.494798, acc.: 77.34%] [G loss: 0.838119]\n",
      "epoch:18 step:17224 [D loss: 0.558659, acc.: 72.66%] [G loss: 0.567380]\n",
      "epoch:18 step:17225 [D loss: 0.677866, acc.: 62.50%] [G loss: 1.376331]\n",
      "epoch:18 step:17226 [D loss: 0.481278, acc.: 76.56%] [G loss: 1.599336]\n",
      "epoch:18 step:17227 [D loss: 0.448889, acc.: 82.03%] [G loss: 1.660930]\n",
      "epoch:18 step:17228 [D loss: 0.757774, acc.: 58.59%] [G loss: 1.385478]\n",
      "epoch:18 step:17229 [D loss: 0.607611, acc.: 66.41%] [G loss: 1.262857]\n",
      "epoch:18 step:17230 [D loss: 0.448204, acc.: 82.03%] [G loss: 1.018915]\n",
      "epoch:18 step:17231 [D loss: 0.595717, acc.: 66.41%] [G loss: 1.149585]\n",
      "epoch:18 step:17232 [D loss: 0.595066, acc.: 72.66%] [G loss: 1.044702]\n",
      "epoch:18 step:17233 [D loss: 0.736093, acc.: 52.34%] [G loss: 1.136113]\n",
      "epoch:18 step:17234 [D loss: 0.599846, acc.: 70.31%] [G loss: 0.370086]\n",
      "epoch:18 step:17235 [D loss: 0.372385, acc.: 82.03%] [G loss: 0.994513]\n",
      "epoch:18 step:17236 [D loss: 0.253549, acc.: 92.97%] [G loss: 1.056490]\n",
      "epoch:18 step:17237 [D loss: 0.334040, acc.: 82.81%] [G loss: 1.323141]\n",
      "epoch:18 step:17238 [D loss: 0.354455, acc.: 90.62%] [G loss: 1.541363]\n",
      "epoch:18 step:17239 [D loss: 0.650180, acc.: 60.16%] [G loss: 1.257755]\n",
      "epoch:18 step:17240 [D loss: 0.424179, acc.: 84.38%] [G loss: 1.501103]\n",
      "epoch:18 step:17241 [D loss: 0.572212, acc.: 67.97%] [G loss: 1.265532]\n",
      "epoch:18 step:17242 [D loss: 0.632442, acc.: 60.94%] [G loss: 1.163082]\n",
      "epoch:18 step:17243 [D loss: 0.716652, acc.: 56.25%] [G loss: 1.054500]\n",
      "epoch:18 step:17244 [D loss: 0.830049, acc.: 47.66%] [G loss: 0.838932]\n",
      "epoch:18 step:17245 [D loss: 0.311952, acc.: 90.62%] [G loss: 1.043495]\n",
      "epoch:18 step:17246 [D loss: 0.233107, acc.: 93.75%] [G loss: 1.451479]\n",
      "epoch:18 step:17247 [D loss: 0.389376, acc.: 73.44%] [G loss: 0.966114]\n",
      "epoch:18 step:17248 [D loss: 0.451088, acc.: 80.47%] [G loss: 2.066406]\n",
      "epoch:18 step:17249 [D loss: 0.645328, acc.: 60.16%] [G loss: 1.080889]\n",
      "epoch:18 step:17250 [D loss: 0.779194, acc.: 44.53%] [G loss: 0.842985]\n",
      "epoch:18 step:17251 [D loss: 0.646218, acc.: 59.38%] [G loss: 0.513959]\n",
      "epoch:18 step:17252 [D loss: 0.813015, acc.: 56.25%] [G loss: 0.769742]\n",
      "epoch:18 step:17253 [D loss: 0.413642, acc.: 85.16%] [G loss: 0.917247]\n",
      "epoch:18 step:17254 [D loss: 0.619711, acc.: 64.06%] [G loss: 1.603054]\n",
      "epoch:18 step:17255 [D loss: 0.793597, acc.: 46.88%] [G loss: 0.896575]\n",
      "epoch:18 step:17256 [D loss: 0.883253, acc.: 36.72%] [G loss: 1.081393]\n",
      "epoch:18 step:17257 [D loss: 0.675505, acc.: 59.38%] [G loss: 0.452228]\n",
      "epoch:18 step:17258 [D loss: 0.715220, acc.: 53.12%] [G loss: 1.138083]\n",
      "epoch:18 step:17259 [D loss: 0.847637, acc.: 46.88%] [G loss: 0.685120]\n",
      "epoch:18 step:17260 [D loss: 0.843695, acc.: 33.59%] [G loss: 1.125471]\n",
      "epoch:18 step:17261 [D loss: 0.722377, acc.: 51.56%] [G loss: 1.120328]\n",
      "epoch:18 step:17262 [D loss: 0.839966, acc.: 47.66%] [G loss: 0.781580]\n",
      "epoch:18 step:17263 [D loss: 0.529156, acc.: 75.00%] [G loss: 1.042109]\n",
      "epoch:18 step:17264 [D loss: 0.545754, acc.: 73.44%] [G loss: 1.442305]\n",
      "epoch:18 step:17265 [D loss: 0.258480, acc.: 89.06%] [G loss: 1.194373]\n",
      "epoch:18 step:17266 [D loss: 0.618976, acc.: 57.03%] [G loss: 1.525370]\n",
      "epoch:18 step:17267 [D loss: 0.553731, acc.: 75.00%] [G loss: 1.359545]\n",
      "epoch:18 step:17268 [D loss: 0.295499, acc.: 91.41%] [G loss: 1.415151]\n",
      "epoch:18 step:17269 [D loss: 0.413633, acc.: 87.50%] [G loss: 1.408563]\n",
      "epoch:18 step:17270 [D loss: 0.411032, acc.: 89.84%] [G loss: 1.314656]\n",
      "epoch:18 step:17271 [D loss: 0.235511, acc.: 93.75%] [G loss: 1.456604]\n",
      "epoch:18 step:17272 [D loss: 0.228832, acc.: 96.09%] [G loss: 1.588978]\n",
      "epoch:18 step:17273 [D loss: 0.181353, acc.: 97.66%] [G loss: 1.229870]\n",
      "epoch:18 step:17274 [D loss: 0.417244, acc.: 85.94%] [G loss: 1.746801]\n",
      "epoch:18 step:17275 [D loss: 0.177393, acc.: 99.22%] [G loss: 1.825343]\n",
      "epoch:18 step:17276 [D loss: 0.276858, acc.: 94.53%] [G loss: 1.459338]\n",
      "epoch:18 step:17277 [D loss: 1.000294, acc.: 43.75%] [G loss: 1.557562]\n",
      "epoch:18 step:17278 [D loss: 0.235978, acc.: 96.88%] [G loss: 0.904050]\n",
      "epoch:18 step:17279 [D loss: 0.315753, acc.: 96.88%] [G loss: 1.395190]\n",
      "epoch:18 step:17280 [D loss: 0.394252, acc.: 82.03%] [G loss: 1.803864]\n",
      "epoch:18 step:17281 [D loss: 0.432203, acc.: 84.38%] [G loss: 1.620421]\n",
      "epoch:18 step:17282 [D loss: 0.289979, acc.: 97.66%] [G loss: 0.286226]\n",
      "epoch:18 step:17283 [D loss: 0.244987, acc.: 92.97%] [G loss: 1.670127]\n",
      "epoch:18 step:17284 [D loss: 0.148459, acc.: 99.22%] [G loss: 0.705476]\n",
      "epoch:18 step:17285 [D loss: 0.108012, acc.: 100.00%] [G loss: 1.524191]\n",
      "epoch:18 step:17286 [D loss: 0.708906, acc.: 60.16%] [G loss: 1.497969]\n",
      "epoch:18 step:17287 [D loss: 0.755684, acc.: 54.69%] [G loss: 0.412155]\n",
      "epoch:18 step:17288 [D loss: 1.026550, acc.: 50.00%] [G loss: 1.549671]\n",
      "epoch:18 step:17289 [D loss: 0.863996, acc.: 53.91%] [G loss: 0.653981]\n",
      "epoch:18 step:17290 [D loss: 0.558953, acc.: 67.19%] [G loss: 1.264710]\n",
      "epoch:18 step:17291 [D loss: 0.151609, acc.: 99.22%] [G loss: 2.010926]\n",
      "epoch:18 step:17292 [D loss: 0.894221, acc.: 51.56%] [G loss: 0.835214]\n",
      "epoch:18 step:17293 [D loss: 0.207268, acc.: 98.44%] [G loss: 1.678358]\n",
      "epoch:18 step:17294 [D loss: 0.268021, acc.: 89.06%] [G loss: 1.573785]\n",
      "epoch:18 step:17295 [D loss: 0.670194, acc.: 64.06%] [G loss: 2.494189]\n",
      "epoch:18 step:17296 [D loss: 0.304347, acc.: 90.62%] [G loss: 2.165056]\n",
      "epoch:18 step:17297 [D loss: 0.943672, acc.: 56.25%] [G loss: 1.378038]\n",
      "epoch:18 step:17298 [D loss: 1.201207, acc.: 34.38%] [G loss: 1.341018]\n",
      "epoch:18 step:17299 [D loss: 0.959500, acc.: 42.97%] [G loss: 0.190914]\n",
      "epoch:18 step:17300 [D loss: 0.906078, acc.: 39.84%] [G loss: 0.841295]\n",
      "epoch:18 step:17301 [D loss: 1.076071, acc.: 19.53%] [G loss: 1.182088]\n",
      "epoch:18 step:17302 [D loss: 0.684037, acc.: 64.06%] [G loss: 1.098671]\n",
      "epoch:18 step:17303 [D loss: 0.934897, acc.: 35.16%] [G loss: 0.715174]\n",
      "epoch:18 step:17304 [D loss: 0.287027, acc.: 95.31%] [G loss: 0.614139]\n",
      "epoch:18 step:17305 [D loss: 1.232410, acc.: 17.19%] [G loss: 1.020832]\n",
      "epoch:18 step:17306 [D loss: 0.809266, acc.: 44.53%] [G loss: 1.264245]\n",
      "epoch:18 step:17307 [D loss: 0.784922, acc.: 50.00%] [G loss: 0.937461]\n",
      "epoch:18 step:17308 [D loss: 0.661036, acc.: 60.94%] [G loss: 1.418242]\n",
      "epoch:18 step:17309 [D loss: 0.823189, acc.: 46.88%] [G loss: 1.290137]\n",
      "epoch:18 step:17310 [D loss: 0.800940, acc.: 42.97%] [G loss: 1.355124]\n",
      "epoch:18 step:17311 [D loss: 0.495600, acc.: 77.34%] [G loss: 1.460236]\n",
      "epoch:18 step:17312 [D loss: 0.666440, acc.: 60.94%] [G loss: 1.328626]\n",
      "epoch:18 step:17313 [D loss: 0.751225, acc.: 49.22%] [G loss: 1.097532]\n",
      "epoch:18 step:17314 [D loss: 0.456055, acc.: 85.16%] [G loss: 1.335943]\n",
      "epoch:18 step:17315 [D loss: 0.406150, acc.: 86.72%] [G loss: 1.613843]\n",
      "epoch:18 step:17316 [D loss: 0.353365, acc.: 90.62%] [G loss: 1.453307]\n",
      "epoch:18 step:17317 [D loss: 0.313695, acc.: 92.19%] [G loss: 1.478198]\n",
      "epoch:18 step:17318 [D loss: 0.315268, acc.: 92.19%] [G loss: 1.559231]\n",
      "epoch:18 step:17319 [D loss: 0.294495, acc.: 95.31%] [G loss: 1.760400]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:18 step:17320 [D loss: 0.351136, acc.: 91.41%] [G loss: 1.699121]\n",
      "epoch:18 step:17321 [D loss: 0.386307, acc.: 85.16%] [G loss: 1.446725]\n",
      "epoch:18 step:17322 [D loss: 0.297334, acc.: 93.75%] [G loss: 1.462739]\n",
      "epoch:18 step:17323 [D loss: 0.229007, acc.: 98.44%] [G loss: 2.155682]\n",
      "epoch:18 step:17324 [D loss: 0.724088, acc.: 57.81%] [G loss: 1.238214]\n",
      "epoch:18 step:17325 [D loss: 0.617066, acc.: 64.06%] [G loss: 1.262044]\n",
      "epoch:18 step:17326 [D loss: 0.755858, acc.: 47.66%] [G loss: 0.945812]\n",
      "epoch:18 step:17327 [D loss: 0.990955, acc.: 35.16%] [G loss: 1.258945]\n",
      "epoch:18 step:17328 [D loss: 1.034756, acc.: 31.25%] [G loss: 0.945189]\n",
      "epoch:18 step:17329 [D loss: 0.630935, acc.: 67.19%] [G loss: 0.666755]\n",
      "epoch:18 step:17330 [D loss: 0.672914, acc.: 61.72%] [G loss: 1.023795]\n",
      "epoch:18 step:17331 [D loss: 0.383596, acc.: 87.50%] [G loss: 0.914877]\n",
      "epoch:18 step:17332 [D loss: 0.354064, acc.: 93.75%] [G loss: 1.110392]\n",
      "epoch:18 step:17333 [D loss: 0.559943, acc.: 66.41%] [G loss: 0.904267]\n",
      "epoch:18 step:17334 [D loss: 0.306853, acc.: 90.62%] [G loss: 1.020414]\n",
      "epoch:18 step:17335 [D loss: 0.363269, acc.: 85.16%] [G loss: 1.408212]\n",
      "epoch:18 step:17336 [D loss: 0.343186, acc.: 88.28%] [G loss: 1.667970]\n",
      "epoch:18 step:17337 [D loss: 0.288340, acc.: 94.53%] [G loss: 1.672275]\n",
      "epoch:18 step:17338 [D loss: 0.506029, acc.: 71.88%] [G loss: 1.595992]\n",
      "epoch:18 step:17339 [D loss: 1.086066, acc.: 45.31%] [G loss: 1.803315]\n",
      "epoch:18 step:17340 [D loss: 0.692944, acc.: 61.72%] [G loss: 1.040232]\n",
      "epoch:18 step:17341 [D loss: 0.696631, acc.: 56.25%] [G loss: 1.336690]\n",
      "epoch:18 step:17342 [D loss: 0.719898, acc.: 53.91%] [G loss: 0.920661]\n",
      "epoch:18 step:17343 [D loss: 0.768424, acc.: 49.22%] [G loss: 0.879337]\n",
      "epoch:18 step:17344 [D loss: 0.755030, acc.: 50.00%] [G loss: 1.070162]\n",
      "epoch:18 step:17345 [D loss: 0.426741, acc.: 86.72%] [G loss: 1.251316]\n",
      "epoch:18 step:17346 [D loss: 0.568175, acc.: 69.53%] [G loss: 1.264781]\n",
      "epoch:18 step:17347 [D loss: 0.456813, acc.: 78.91%] [G loss: 1.426877]\n",
      "epoch:18 step:17348 [D loss: 0.687341, acc.: 64.06%] [G loss: 1.208269]\n",
      "epoch:18 step:17349 [D loss: 0.624974, acc.: 64.06%] [G loss: 1.459352]\n",
      "epoch:18 step:17350 [D loss: 0.259983, acc.: 92.97%] [G loss: 1.542028]\n",
      "epoch:18 step:17351 [D loss: 0.509639, acc.: 72.66%] [G loss: 1.703128]\n",
      "epoch:18 step:17352 [D loss: 0.473703, acc.: 80.47%] [G loss: 1.589837]\n",
      "epoch:18 step:17353 [D loss: 0.511212, acc.: 76.56%] [G loss: 1.621424]\n",
      "epoch:18 step:17354 [D loss: 0.460178, acc.: 78.91%] [G loss: 1.494017]\n",
      "epoch:18 step:17355 [D loss: 0.726269, acc.: 56.25%] [G loss: 1.370724]\n",
      "epoch:18 step:17356 [D loss: 0.637359, acc.: 66.41%] [G loss: 1.139645]\n",
      "epoch:18 step:17357 [D loss: 0.596952, acc.: 67.97%] [G loss: 1.103163]\n",
      "epoch:18 step:17358 [D loss: 0.635484, acc.: 66.41%] [G loss: 0.922336]\n",
      "epoch:18 step:17359 [D loss: 0.682395, acc.: 64.84%] [G loss: 1.145594]\n",
      "epoch:18 step:17360 [D loss: 0.529370, acc.: 78.12%] [G loss: 1.276719]\n",
      "epoch:18 step:17361 [D loss: 0.583576, acc.: 71.09%] [G loss: 1.062516]\n",
      "epoch:18 step:17362 [D loss: 0.592734, acc.: 68.75%] [G loss: 1.056705]\n",
      "epoch:18 step:17363 [D loss: 0.410354, acc.: 81.25%] [G loss: 0.882968]\n",
      "epoch:18 step:17364 [D loss: 0.280906, acc.: 87.50%] [G loss: 1.201837]\n",
      "epoch:18 step:17365 [D loss: 0.195248, acc.: 95.31%] [G loss: 1.715049]\n",
      "epoch:18 step:17366 [D loss: 0.715613, acc.: 58.59%] [G loss: 1.080721]\n",
      "epoch:18 step:17367 [D loss: 0.650816, acc.: 60.94%] [G loss: 1.182514]\n",
      "epoch:18 step:17368 [D loss: 0.722753, acc.: 55.47%] [G loss: 1.058230]\n",
      "epoch:18 step:17369 [D loss: 0.698887, acc.: 59.38%] [G loss: 1.054926]\n",
      "epoch:18 step:17370 [D loss: 0.503305, acc.: 77.34%] [G loss: 1.054634]\n",
      "epoch:18 step:17371 [D loss: 0.556720, acc.: 69.53%] [G loss: 0.906005]\n",
      "epoch:18 step:17372 [D loss: 0.757231, acc.: 46.09%] [G loss: 1.019503]\n",
      "epoch:18 step:17373 [D loss: 0.555913, acc.: 72.66%] [G loss: 0.898617]\n",
      "epoch:18 step:17374 [D loss: 0.518994, acc.: 72.66%] [G loss: 1.012623]\n",
      "epoch:18 step:17375 [D loss: 0.619364, acc.: 69.53%] [G loss: 1.010262]\n",
      "epoch:18 step:17376 [D loss: 0.472516, acc.: 77.34%] [G loss: 1.003996]\n",
      "epoch:18 step:17377 [D loss: 0.336641, acc.: 85.16%] [G loss: 1.193331]\n",
      "epoch:18 step:17378 [D loss: 0.320233, acc.: 92.19%] [G loss: 1.486459]\n",
      "epoch:18 step:17379 [D loss: 0.272401, acc.: 95.31%] [G loss: 1.409743]\n",
      "epoch:18 step:17380 [D loss: 0.398499, acc.: 88.28%] [G loss: 1.211498]\n",
      "epoch:18 step:17381 [D loss: 0.323455, acc.: 92.19%] [G loss: 1.175317]\n",
      "epoch:18 step:17382 [D loss: 0.625802, acc.: 63.28%] [G loss: 1.158426]\n",
      "epoch:18 step:17383 [D loss: 0.410013, acc.: 83.59%] [G loss: 1.242608]\n",
      "epoch:18 step:17384 [D loss: 0.593513, acc.: 67.19%] [G loss: 1.391479]\n",
      "epoch:18 step:17385 [D loss: 0.589618, acc.: 66.41%] [G loss: 1.148350]\n",
      "epoch:18 step:17386 [D loss: 0.471838, acc.: 78.91%] [G loss: 0.891911]\n",
      "epoch:18 step:17387 [D loss: 0.431676, acc.: 85.94%] [G loss: 1.266210]\n",
      "epoch:18 step:17388 [D loss: 0.512395, acc.: 78.12%] [G loss: 1.176018]\n",
      "epoch:18 step:17389 [D loss: 0.576649, acc.: 68.75%] [G loss: 0.824383]\n",
      "epoch:18 step:17390 [D loss: 0.320536, acc.: 86.72%] [G loss: 1.121840]\n",
      "epoch:18 step:17391 [D loss: 0.865849, acc.: 46.09%] [G loss: 1.348510]\n",
      "epoch:18 step:17392 [D loss: 0.678604, acc.: 58.59%] [G loss: 1.058123]\n",
      "epoch:18 step:17393 [D loss: 0.404091, acc.: 84.38%] [G loss: 1.076805]\n",
      "epoch:18 step:17394 [D loss: 0.865297, acc.: 44.53%] [G loss: 1.216663]\n",
      "epoch:18 step:17395 [D loss: 0.669469, acc.: 64.84%] [G loss: 1.103060]\n",
      "epoch:18 step:17396 [D loss: 0.473587, acc.: 81.25%] [G loss: 1.248916]\n",
      "epoch:18 step:17397 [D loss: 0.691651, acc.: 60.16%] [G loss: 1.177290]\n",
      "epoch:18 step:17398 [D loss: 0.582249, acc.: 71.09%] [G loss: 0.943779]\n",
      "epoch:18 step:17399 [D loss: 0.444045, acc.: 83.59%] [G loss: 0.976697]\n",
      "epoch:18 step:17400 [D loss: 0.476316, acc.: 82.03%] [G loss: 1.047601]\n",
      "##############\n",
      "[4.44263079 2.56718285 6.50571635 5.58364112 4.515413   6.42205256\n",
      " 5.25970781 5.50635953 5.97606671 4.92462335]\n",
      "##########\n",
      "epoch:18 step:17401 [D loss: 0.317975, acc.: 89.84%] [G loss: 0.916538]\n",
      "epoch:18 step:17402 [D loss: 0.211616, acc.: 97.66%] [G loss: 1.421092]\n",
      "epoch:18 step:17403 [D loss: 0.323334, acc.: 90.62%] [G loss: 1.281106]\n",
      "epoch:18 step:17404 [D loss: 0.405849, acc.: 92.19%] [G loss: 1.508639]\n",
      "epoch:18 step:17405 [D loss: 0.393146, acc.: 92.19%] [G loss: 1.200996]\n",
      "epoch:18 step:17406 [D loss: 0.544600, acc.: 68.75%] [G loss: 1.175647]\n",
      "epoch:18 step:17407 [D loss: 0.409418, acc.: 89.84%] [G loss: 1.548359]\n",
      "epoch:18 step:17408 [D loss: 0.593936, acc.: 67.19%] [G loss: 1.298468]\n",
      "epoch:18 step:17409 [D loss: 0.514370, acc.: 77.34%] [G loss: 0.870072]\n",
      "epoch:18 step:17410 [D loss: 0.595112, acc.: 70.31%] [G loss: 1.329622]\n",
      "epoch:18 step:17411 [D loss: 0.730540, acc.: 54.69%] [G loss: 1.258876]\n",
      "epoch:18 step:17412 [D loss: 0.559048, acc.: 76.56%] [G loss: 1.164990]\n",
      "epoch:18 step:17413 [D loss: 0.510536, acc.: 73.44%] [G loss: 1.287862]\n",
      "epoch:18 step:17414 [D loss: 0.337996, acc.: 92.19%] [G loss: 0.713302]\n",
      "epoch:18 step:17415 [D loss: 0.312422, acc.: 95.31%] [G loss: 1.194482]\n",
      "epoch:18 step:17416 [D loss: 0.318127, acc.: 94.53%] [G loss: 1.218300]\n",
      "epoch:18 step:17417 [D loss: 0.365116, acc.: 89.84%] [G loss: 0.896320]\n",
      "epoch:18 step:17418 [D loss: 0.348528, acc.: 89.06%] [G loss: 0.651170]\n",
      "epoch:18 step:17419 [D loss: 0.536143, acc.: 74.22%] [G loss: 1.042825]\n",
      "epoch:18 step:17420 [D loss: 0.395072, acc.: 74.22%] [G loss: 1.683225]\n",
      "epoch:18 step:17421 [D loss: 0.417400, acc.: 85.94%] [G loss: 1.497708]\n",
      "epoch:18 step:17422 [D loss: 0.291521, acc.: 92.97%] [G loss: 1.372703]\n",
      "epoch:18 step:17423 [D loss: 0.344871, acc.: 89.06%] [G loss: 1.727557]\n",
      "epoch:18 step:17424 [D loss: 0.399159, acc.: 87.50%] [G loss: 1.526556]\n",
      "epoch:18 step:17425 [D loss: 0.143077, acc.: 100.00%] [G loss: 1.724730]\n",
      "epoch:18 step:17426 [D loss: 0.606761, acc.: 67.97%] [G loss: 1.775459]\n",
      "epoch:18 step:17427 [D loss: 0.148761, acc.: 100.00%] [G loss: 1.736497]\n",
      "epoch:18 step:17428 [D loss: 0.946809, acc.: 36.72%] [G loss: 1.133932]\n",
      "epoch:18 step:17429 [D loss: 0.676203, acc.: 62.50%] [G loss: 1.515929]\n",
      "epoch:18 step:17430 [D loss: 0.660532, acc.: 61.72%] [G loss: 1.237073]\n",
      "epoch:18 step:17431 [D loss: 0.645950, acc.: 62.50%] [G loss: 0.935025]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:18 step:17432 [D loss: 0.560306, acc.: 69.53%] [G loss: 1.557620]\n",
      "epoch:18 step:17433 [D loss: 0.259464, acc.: 88.28%] [G loss: 1.663358]\n",
      "epoch:18 step:17434 [D loss: 0.397283, acc.: 83.59%] [G loss: 1.616103]\n",
      "epoch:18 step:17435 [D loss: 0.740887, acc.: 54.69%] [G loss: 1.320420]\n",
      "epoch:18 step:17436 [D loss: 0.643396, acc.: 63.28%] [G loss: 1.533541]\n",
      "epoch:18 step:17437 [D loss: 0.662839, acc.: 60.94%] [G loss: 1.096172]\n",
      "epoch:18 step:17438 [D loss: 0.673297, acc.: 57.81%] [G loss: 1.243826]\n",
      "epoch:18 step:17439 [D loss: 0.551870, acc.: 71.88%] [G loss: 1.066352]\n",
      "epoch:18 step:17440 [D loss: 0.439645, acc.: 81.25%] [G loss: 1.267534]\n",
      "epoch:18 step:17441 [D loss: 1.099339, acc.: 53.12%] [G loss: 1.128201]\n",
      "epoch:18 step:17442 [D loss: 0.563547, acc.: 72.66%] [G loss: 1.802367]\n",
      "epoch:18 step:17443 [D loss: 0.258018, acc.: 93.75%] [G loss: 1.518327]\n",
      "epoch:18 step:17444 [D loss: 0.423565, acc.: 80.47%] [G loss: 1.991900]\n",
      "epoch:18 step:17445 [D loss: 0.438366, acc.: 80.47%] [G loss: 2.003040]\n",
      "epoch:18 step:17446 [D loss: 0.795321, acc.: 55.47%] [G loss: 1.387200]\n",
      "epoch:18 step:17447 [D loss: 0.674950, acc.: 62.50%] [G loss: 1.167057]\n",
      "epoch:18 step:17448 [D loss: 0.648062, acc.: 67.97%] [G loss: 0.966509]\n",
      "epoch:18 step:17449 [D loss: 0.686583, acc.: 59.38%] [G loss: 1.227604]\n",
      "epoch:18 step:17450 [D loss: 0.723437, acc.: 56.25%] [G loss: 0.735207]\n",
      "epoch:18 step:17451 [D loss: 0.685595, acc.: 62.50%] [G loss: 1.073463]\n",
      "epoch:18 step:17452 [D loss: 0.618461, acc.: 66.41%] [G loss: 1.275771]\n",
      "epoch:18 step:17453 [D loss: 0.300630, acc.: 83.59%] [G loss: 1.243503]\n",
      "epoch:18 step:17454 [D loss: 0.215950, acc.: 93.75%] [G loss: 0.975217]\n",
      "epoch:18 step:17455 [D loss: 0.169377, acc.: 94.53%] [G loss: 0.874271]\n",
      "epoch:18 step:17456 [D loss: 0.684657, acc.: 62.50%] [G loss: 0.765896]\n",
      "epoch:18 step:17457 [D loss: 0.548529, acc.: 75.78%] [G loss: 0.977152]\n",
      "epoch:18 step:17458 [D loss: 0.431576, acc.: 83.59%] [G loss: 1.198832]\n",
      "epoch:18 step:17459 [D loss: 0.617181, acc.: 61.72%] [G loss: 1.509388]\n",
      "epoch:18 step:17460 [D loss: 0.674808, acc.: 58.59%] [G loss: 1.028219]\n",
      "epoch:18 step:17461 [D loss: 0.512427, acc.: 66.41%] [G loss: 1.118235]\n",
      "epoch:18 step:17462 [D loss: 0.562225, acc.: 72.66%] [G loss: 1.420473]\n",
      "epoch:18 step:17463 [D loss: 0.617863, acc.: 63.28%] [G loss: 1.307622]\n",
      "epoch:18 step:17464 [D loss: 0.579072, acc.: 71.09%] [G loss: 0.983010]\n",
      "epoch:18 step:17465 [D loss: 0.561262, acc.: 71.09%] [G loss: 0.951271]\n",
      "epoch:18 step:17466 [D loss: 0.405137, acc.: 79.69%] [G loss: 1.264304]\n",
      "epoch:18 step:17467 [D loss: 0.413284, acc.: 89.06%] [G loss: 1.283719]\n",
      "epoch:18 step:17468 [D loss: 0.376054, acc.: 88.28%] [G loss: 1.264074]\n",
      "epoch:18 step:17469 [D loss: 0.534343, acc.: 75.00%] [G loss: 1.044171]\n",
      "epoch:18 step:17470 [D loss: 0.488298, acc.: 78.91%] [G loss: 1.214825]\n",
      "epoch:18 step:17471 [D loss: 0.495407, acc.: 78.91%] [G loss: 1.268626]\n",
      "epoch:18 step:17472 [D loss: 0.784234, acc.: 51.56%] [G loss: 1.030991]\n",
      "epoch:18 step:17473 [D loss: 0.915703, acc.: 36.72%] [G loss: 1.131164]\n",
      "epoch:18 step:17474 [D loss: 0.608290, acc.: 70.31%] [G loss: 1.296319]\n",
      "epoch:18 step:17475 [D loss: 0.248754, acc.: 95.31%] [G loss: 1.042810]\n",
      "epoch:18 step:17476 [D loss: 0.742202, acc.: 51.56%] [G loss: 1.277965]\n",
      "epoch:18 step:17477 [D loss: 0.414479, acc.: 85.94%] [G loss: 1.231810]\n",
      "epoch:18 step:17478 [D loss: 0.527324, acc.: 70.31%] [G loss: 1.118137]\n",
      "epoch:18 step:17479 [D loss: 0.686272, acc.: 53.12%] [G loss: 0.956362]\n",
      "epoch:18 step:17480 [D loss: 0.917635, acc.: 32.81%] [G loss: 1.109813]\n",
      "epoch:18 step:17481 [D loss: 0.628121, acc.: 66.41%] [G loss: 1.085317]\n",
      "epoch:18 step:17482 [D loss: 0.495870, acc.: 79.69%] [G loss: 1.141315]\n",
      "epoch:18 step:17483 [D loss: 0.495521, acc.: 81.25%] [G loss: 1.218034]\n",
      "epoch:18 step:17484 [D loss: 0.526240, acc.: 80.47%] [G loss: 1.207422]\n",
      "epoch:18 step:17485 [D loss: 0.560431, acc.: 74.22%] [G loss: 1.019448]\n",
      "epoch:18 step:17486 [D loss: 0.388143, acc.: 82.81%] [G loss: 1.267271]\n",
      "epoch:18 step:17487 [D loss: 0.871445, acc.: 46.09%] [G loss: 0.915384]\n",
      "epoch:18 step:17488 [D loss: 0.576635, acc.: 68.75%] [G loss: 1.193765]\n",
      "epoch:18 step:17489 [D loss: 0.702075, acc.: 57.81%] [G loss: 1.224534]\n",
      "epoch:18 step:17490 [D loss: 0.526168, acc.: 69.53%] [G loss: 1.488519]\n",
      "epoch:18 step:17491 [D loss: 0.660063, acc.: 62.50%] [G loss: 1.004722]\n",
      "epoch:18 step:17492 [D loss: 0.609653, acc.: 70.31%] [G loss: 1.448969]\n",
      "epoch:18 step:17493 [D loss: 0.505212, acc.: 82.03%] [G loss: 1.042267]\n",
      "epoch:18 step:17494 [D loss: 0.690771, acc.: 59.38%] [G loss: 1.215435]\n",
      "epoch:18 step:17495 [D loss: 0.546913, acc.: 67.19%] [G loss: 1.106293]\n",
      "epoch:18 step:17496 [D loss: 0.442062, acc.: 77.34%] [G loss: 1.000065]\n",
      "epoch:18 step:17497 [D loss: 0.812122, acc.: 46.88%] [G loss: 0.461773]\n",
      "epoch:18 step:17498 [D loss: 0.585706, acc.: 68.75%] [G loss: 0.975461]\n",
      "epoch:18 step:17499 [D loss: 0.318668, acc.: 94.53%] [G loss: 0.816424]\n",
      "epoch:18 step:17500 [D loss: 0.737850, acc.: 59.38%] [G loss: 1.653374]\n",
      "epoch:18 step:17501 [D loss: 0.507463, acc.: 79.69%] [G loss: 1.424222]\n",
      "epoch:18 step:17502 [D loss: 0.898451, acc.: 35.16%] [G loss: 1.290153]\n",
      "epoch:18 step:17503 [D loss: 0.671226, acc.: 57.03%] [G loss: 1.435229]\n",
      "epoch:18 step:17504 [D loss: 0.697524, acc.: 60.94%] [G loss: 1.159603]\n",
      "epoch:18 step:17505 [D loss: 0.334075, acc.: 90.62%] [G loss: 1.420160]\n",
      "epoch:18 step:17506 [D loss: 0.631829, acc.: 57.81%] [G loss: 1.275163]\n",
      "epoch:18 step:17507 [D loss: 0.190346, acc.: 92.19%] [G loss: 1.510358]\n",
      "epoch:18 step:17508 [D loss: 0.756989, acc.: 47.66%] [G loss: 0.604704]\n",
      "epoch:18 step:17509 [D loss: 0.791957, acc.: 57.03%] [G loss: 1.696476]\n",
      "epoch:18 step:17510 [D loss: 0.700962, acc.: 58.59%] [G loss: 1.040672]\n",
      "epoch:18 step:17511 [D loss: 0.463483, acc.: 85.16%] [G loss: 1.686489]\n",
      "epoch:18 step:17512 [D loss: 0.515850, acc.: 75.78%] [G loss: 0.886063]\n",
      "epoch:18 step:17513 [D loss: 0.651866, acc.: 59.38%] [G loss: 1.019618]\n",
      "epoch:18 step:17514 [D loss: 0.573253, acc.: 67.19%] [G loss: 0.832667]\n",
      "epoch:18 step:17515 [D loss: 0.626713, acc.: 62.50%] [G loss: 0.965106]\n",
      "epoch:18 step:17516 [D loss: 0.364938, acc.: 89.06%] [G loss: 1.583764]\n",
      "epoch:18 step:17517 [D loss: 0.668965, acc.: 60.16%] [G loss: 1.157229]\n",
      "epoch:18 step:17518 [D loss: 0.684794, acc.: 52.34%] [G loss: 1.396269]\n",
      "epoch:18 step:17519 [D loss: 0.741063, acc.: 46.88%] [G loss: 1.174339]\n",
      "epoch:18 step:17520 [D loss: 0.724502, acc.: 50.00%] [G loss: 1.332541]\n",
      "epoch:18 step:17521 [D loss: 0.755839, acc.: 51.56%] [G loss: 1.492518]\n",
      "epoch:18 step:17522 [D loss: 0.681315, acc.: 58.59%] [G loss: 1.072627]\n",
      "epoch:18 step:17523 [D loss: 0.657305, acc.: 67.19%] [G loss: 1.076880]\n",
      "epoch:18 step:17524 [D loss: 0.539317, acc.: 70.31%] [G loss: 1.198504]\n",
      "epoch:18 step:17525 [D loss: 0.518702, acc.: 76.56%] [G loss: 1.697922]\n",
      "epoch:18 step:17526 [D loss: 0.746697, acc.: 54.69%] [G loss: 0.930829]\n",
      "epoch:18 step:17527 [D loss: 0.774591, acc.: 49.22%] [G loss: 1.248760]\n",
      "epoch:18 step:17528 [D loss: 0.680132, acc.: 54.69%] [G loss: 1.405640]\n",
      "epoch:18 step:17529 [D loss: 0.227694, acc.: 91.41%] [G loss: 1.461878]\n",
      "epoch:18 step:17530 [D loss: 0.227197, acc.: 89.06%] [G loss: 1.158035]\n",
      "epoch:18 step:17531 [D loss: 0.155374, acc.: 96.09%] [G loss: 1.651329]\n",
      "epoch:18 step:17532 [D loss: 0.414493, acc.: 88.28%] [G loss: 1.421234]\n",
      "epoch:18 step:17533 [D loss: 0.290961, acc.: 92.97%] [G loss: 1.683034]\n",
      "epoch:18 step:17534 [D loss: 0.665193, acc.: 63.28%] [G loss: 1.552878]\n",
      "epoch:18 step:17535 [D loss: 0.600653, acc.: 65.62%] [G loss: 1.093845]\n",
      "epoch:18 step:17536 [D loss: 0.651453, acc.: 60.94%] [G loss: 0.841622]\n",
      "epoch:18 step:17537 [D loss: 0.350593, acc.: 87.50%] [G loss: 0.827759]\n",
      "epoch:18 step:17538 [D loss: 0.606701, acc.: 68.75%] [G loss: 1.101025]\n",
      "epoch:18 step:17539 [D loss: 0.583362, acc.: 70.31%] [G loss: 0.933104]\n",
      "epoch:18 step:17540 [D loss: 0.332644, acc.: 90.62%] [G loss: 1.041017]\n",
      "epoch:18 step:17541 [D loss: 0.727876, acc.: 60.94%] [G loss: 1.160185]\n",
      "epoch:18 step:17542 [D loss: 0.786566, acc.: 48.44%] [G loss: 0.549634]\n",
      "epoch:18 step:17543 [D loss: 0.738409, acc.: 53.12%] [G loss: 1.085960]\n",
      "epoch:18 step:17544 [D loss: 1.652480, acc.: 18.75%] [G loss: 0.715518]\n",
      "epoch:18 step:17545 [D loss: 0.927866, acc.: 38.28%] [G loss: 1.299092]\n",
      "epoch:18 step:17546 [D loss: 0.724428, acc.: 55.47%] [G loss: 0.677605]\n",
      "epoch:18 step:17547 [D loss: 0.701111, acc.: 60.94%] [G loss: 1.132930]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:18 step:17548 [D loss: 0.427584, acc.: 85.16%] [G loss: 1.136979]\n",
      "epoch:18 step:17549 [D loss: 0.550148, acc.: 71.88%] [G loss: 1.169433]\n",
      "epoch:18 step:17550 [D loss: 0.544263, acc.: 64.06%] [G loss: 0.953576]\n",
      "epoch:18 step:17551 [D loss: 0.594523, acc.: 63.28%] [G loss: 0.603133]\n",
      "epoch:18 step:17552 [D loss: 0.690521, acc.: 54.69%] [G loss: 1.318221]\n",
      "epoch:18 step:17553 [D loss: 0.556972, acc.: 71.09%] [G loss: 0.376342]\n",
      "epoch:18 step:17554 [D loss: 1.127915, acc.: 26.56%] [G loss: 0.669442]\n",
      "epoch:18 step:17555 [D loss: 0.611240, acc.: 69.53%] [G loss: 1.204404]\n",
      "epoch:18 step:17556 [D loss: 0.587395, acc.: 65.62%] [G loss: 1.346330]\n",
      "epoch:18 step:17557 [D loss: 0.529130, acc.: 75.78%] [G loss: 1.281351]\n",
      "epoch:18 step:17558 [D loss: 0.530864, acc.: 75.00%] [G loss: 1.211858]\n",
      "epoch:18 step:17559 [D loss: 0.702208, acc.: 53.91%] [G loss: 1.387619]\n",
      "epoch:18 step:17560 [D loss: 0.379178, acc.: 90.62%] [G loss: 1.362062]\n",
      "epoch:18 step:17561 [D loss: 0.799642, acc.: 52.34%] [G loss: 1.232979]\n",
      "epoch:18 step:17562 [D loss: 0.285011, acc.: 95.31%] [G loss: 1.234142]\n",
      "epoch:18 step:17563 [D loss: 0.229506, acc.: 96.88%] [G loss: 1.397352]\n",
      "epoch:18 step:17564 [D loss: 0.408956, acc.: 88.28%] [G loss: 1.562228]\n",
      "epoch:18 step:17565 [D loss: 0.622234, acc.: 63.28%] [G loss: 1.371581]\n",
      "epoch:18 step:17566 [D loss: 0.214272, acc.: 96.88%] [G loss: 1.273814]\n",
      "epoch:18 step:17567 [D loss: 0.416669, acc.: 75.78%] [G loss: 1.289419]\n",
      "epoch:18 step:17568 [D loss: 0.436895, acc.: 85.94%] [G loss: 1.645157]\n",
      "epoch:18 step:17569 [D loss: 0.905532, acc.: 49.22%] [G loss: 1.455445]\n",
      "epoch:18 step:17570 [D loss: 0.529627, acc.: 76.56%] [G loss: 1.228611]\n",
      "epoch:18 step:17571 [D loss: 0.758359, acc.: 50.00%] [G loss: 1.363080]\n",
      "epoch:18 step:17572 [D loss: 0.244570, acc.: 93.75%] [G loss: 1.203245]\n",
      "epoch:18 step:17573 [D loss: 0.171058, acc.: 99.22%] [G loss: 1.487747]\n",
      "epoch:18 step:17574 [D loss: 0.170204, acc.: 97.66%] [G loss: 1.117082]\n",
      "epoch:18 step:17575 [D loss: 0.215983, acc.: 99.22%] [G loss: 1.108212]\n",
      "epoch:18 step:17576 [D loss: 0.760323, acc.: 53.12%] [G loss: 1.494608]\n",
      "epoch:18 step:17577 [D loss: 0.470762, acc.: 80.47%] [G loss: 1.712811]\n",
      "epoch:18 step:17578 [D loss: 0.775802, acc.: 50.78%] [G loss: 1.357072]\n",
      "epoch:18 step:17579 [D loss: 0.339544, acc.: 78.91%] [G loss: 0.723442]\n",
      "epoch:18 step:17580 [D loss: 0.176533, acc.: 96.09%] [G loss: 1.767310]\n",
      "epoch:18 step:17581 [D loss: 0.866032, acc.: 53.12%] [G loss: 1.608734]\n",
      "epoch:18 step:17582 [D loss: 0.830072, acc.: 50.00%] [G loss: 1.162354]\n",
      "epoch:18 step:17583 [D loss: 0.716690, acc.: 55.47%] [G loss: 0.657562]\n",
      "epoch:18 step:17584 [D loss: 0.417765, acc.: 92.19%] [G loss: 1.319399]\n",
      "epoch:18 step:17585 [D loss: 0.510528, acc.: 82.03%] [G loss: 1.201086]\n",
      "epoch:18 step:17586 [D loss: 0.505053, acc.: 76.56%] [G loss: 1.215779]\n",
      "epoch:18 step:17587 [D loss: 0.472369, acc.: 81.25%] [G loss: 0.896541]\n",
      "epoch:18 step:17588 [D loss: 1.084052, acc.: 20.31%] [G loss: 1.450753]\n",
      "epoch:18 step:17589 [D loss: 0.662970, acc.: 61.72%] [G loss: 1.230169]\n",
      "epoch:18 step:17590 [D loss: 0.318254, acc.: 91.41%] [G loss: 1.638035]\n",
      "epoch:18 step:17591 [D loss: 0.292875, acc.: 93.75%] [G loss: 1.456879]\n",
      "epoch:18 step:17592 [D loss: 0.204531, acc.: 100.00%] [G loss: 2.023182]\n",
      "epoch:18 step:17593 [D loss: 0.823568, acc.: 46.09%] [G loss: 1.626497]\n",
      "epoch:18 step:17594 [D loss: 0.338030, acc.: 93.75%] [G loss: 1.159989]\n",
      "epoch:18 step:17595 [D loss: 0.458656, acc.: 82.81%] [G loss: 1.277662]\n",
      "epoch:18 step:17596 [D loss: 0.293410, acc.: 94.53%] [G loss: 1.333972]\n",
      "epoch:18 step:17597 [D loss: 0.856449, acc.: 57.03%] [G loss: 1.827909]\n",
      "epoch:18 step:17598 [D loss: 1.252519, acc.: 41.41%] [G loss: 1.711789]\n",
      "epoch:18 step:17599 [D loss: 0.702205, acc.: 69.53%] [G loss: 1.022622]\n",
      "epoch:18 step:17600 [D loss: 0.797050, acc.: 50.78%] [G loss: 1.513075]\n",
      "##############\n",
      "[4.01848824 2.79688123 6.81086757 5.77684579 4.8297568  6.10933529\n",
      " 5.56657846 5.67001356 6.26575907 5.01778391]\n",
      "##########\n",
      "epoch:18 step:17601 [D loss: 0.567577, acc.: 73.44%] [G loss: 1.691642]\n",
      "epoch:18 step:17602 [D loss: 0.397802, acc.: 85.16%] [G loss: 1.480800]\n",
      "epoch:18 step:17603 [D loss: 0.521163, acc.: 76.56%] [G loss: 1.577690]\n",
      "epoch:18 step:17604 [D loss: 0.647243, acc.: 59.38%] [G loss: 1.331908]\n",
      "epoch:18 step:17605 [D loss: 0.742289, acc.: 56.25%] [G loss: 1.240843]\n",
      "epoch:18 step:17606 [D loss: 0.787558, acc.: 53.91%] [G loss: 1.026428]\n",
      "epoch:18 step:17607 [D loss: 0.327976, acc.: 82.03%] [G loss: 1.246461]\n",
      "epoch:18 step:17608 [D loss: 0.221203, acc.: 93.75%] [G loss: 1.155958]\n",
      "epoch:18 step:17609 [D loss: 0.226738, acc.: 92.19%] [G loss: 1.460818]\n",
      "epoch:18 step:17610 [D loss: 0.344524, acc.: 94.53%] [G loss: 1.632229]\n",
      "epoch:18 step:17611 [D loss: 1.090575, acc.: 40.62%] [G loss: 1.299722]\n",
      "epoch:18 step:17612 [D loss: 0.718396, acc.: 55.47%] [G loss: 1.002871]\n",
      "epoch:18 step:17613 [D loss: 0.579975, acc.: 73.44%] [G loss: 1.140465]\n",
      "epoch:18 step:17614 [D loss: 0.346294, acc.: 89.06%] [G loss: 1.185818]\n",
      "epoch:18 step:17615 [D loss: 0.221888, acc.: 95.31%] [G loss: 1.395519]\n",
      "epoch:18 step:17616 [D loss: 0.204977, acc.: 94.53%] [G loss: 1.734648]\n",
      "epoch:18 step:17617 [D loss: 0.544478, acc.: 71.09%] [G loss: 1.001140]\n",
      "epoch:18 step:17618 [D loss: 0.741576, acc.: 53.91%] [G loss: 1.344964]\n",
      "epoch:18 step:17619 [D loss: 0.742563, acc.: 49.22%] [G loss: 0.949364]\n",
      "epoch:18 step:17620 [D loss: 0.696973, acc.: 55.47%] [G loss: 1.400430]\n",
      "epoch:18 step:17621 [D loss: 0.685937, acc.: 58.59%] [G loss: 1.193449]\n",
      "epoch:18 step:17622 [D loss: 0.470157, acc.: 77.34%] [G loss: 1.200868]\n",
      "epoch:18 step:17623 [D loss: 0.636116, acc.: 64.84%] [G loss: 1.046339]\n",
      "epoch:18 step:17624 [D loss: 0.586934, acc.: 66.41%] [G loss: 1.142810]\n",
      "epoch:18 step:17625 [D loss: 0.351657, acc.: 93.75%] [G loss: 0.998085]\n",
      "epoch:18 step:17626 [D loss: 0.417746, acc.: 82.81%] [G loss: 1.093009]\n",
      "epoch:18 step:17627 [D loss: 0.551820, acc.: 71.88%] [G loss: 0.895444]\n",
      "epoch:18 step:17628 [D loss: 0.906861, acc.: 44.53%] [G loss: 0.854509]\n",
      "epoch:18 step:17629 [D loss: 0.666462, acc.: 63.28%] [G loss: 0.799380]\n",
      "epoch:18 step:17630 [D loss: 0.386777, acc.: 82.81%] [G loss: 1.402733]\n",
      "epoch:18 step:17631 [D loss: 0.695619, acc.: 60.16%] [G loss: 1.699058]\n",
      "epoch:18 step:17632 [D loss: 0.631149, acc.: 68.75%] [G loss: 1.226476]\n",
      "epoch:18 step:17633 [D loss: 0.412123, acc.: 88.28%] [G loss: 0.957855]\n",
      "epoch:18 step:17634 [D loss: 0.329744, acc.: 86.72%] [G loss: 1.294445]\n",
      "epoch:18 step:17635 [D loss: 0.288322, acc.: 93.75%] [G loss: 1.209374]\n",
      "epoch:18 step:17636 [D loss: 0.687989, acc.: 59.38%] [G loss: 1.075899]\n",
      "epoch:18 step:17637 [D loss: 0.747385, acc.: 53.91%] [G loss: 1.137337]\n",
      "epoch:18 step:17638 [D loss: 0.717338, acc.: 57.81%] [G loss: 1.290698]\n",
      "epoch:18 step:17639 [D loss: 0.590208, acc.: 64.84%] [G loss: 1.035180]\n",
      "epoch:18 step:17640 [D loss: 0.278834, acc.: 92.19%] [G loss: 1.009459]\n",
      "epoch:18 step:17641 [D loss: 0.414887, acc.: 78.12%] [G loss: 1.375775]\n",
      "epoch:18 step:17642 [D loss: 0.708130, acc.: 57.81%] [G loss: 1.170358]\n",
      "epoch:18 step:17643 [D loss: 0.416188, acc.: 88.28%] [G loss: 1.072789]\n",
      "epoch:18 step:17644 [D loss: 0.958241, acc.: 35.94%] [G loss: 0.627548]\n",
      "epoch:18 step:17645 [D loss: 1.390173, acc.: 13.28%] [G loss: 0.818209]\n",
      "epoch:18 step:17646 [D loss: 0.272703, acc.: 86.72%] [G loss: 1.214202]\n",
      "epoch:18 step:17647 [D loss: 0.236286, acc.: 96.88%] [G loss: 1.471834]\n",
      "epoch:18 step:17648 [D loss: 0.352414, acc.: 87.50%] [G loss: 1.444376]\n",
      "epoch:18 step:17649 [D loss: 0.657987, acc.: 56.25%] [G loss: 1.432786]\n",
      "epoch:18 step:17650 [D loss: 0.742397, acc.: 55.47%] [G loss: 1.750391]\n",
      "epoch:18 step:17651 [D loss: 0.637059, acc.: 56.25%] [G loss: 1.618976]\n",
      "epoch:18 step:17652 [D loss: 0.167165, acc.: 96.88%] [G loss: 1.538797]\n",
      "epoch:18 step:17653 [D loss: 0.703729, acc.: 54.69%] [G loss: 1.437032]\n",
      "epoch:18 step:17654 [D loss: 0.520847, acc.: 82.03%] [G loss: 1.425807]\n",
      "epoch:18 step:17655 [D loss: 0.776415, acc.: 57.03%] [G loss: 1.416965]\n",
      "epoch:18 step:17656 [D loss: 0.532414, acc.: 72.66%] [G loss: 1.446709]\n",
      "epoch:18 step:17657 [D loss: 0.248634, acc.: 87.50%] [G loss: 1.495783]\n",
      "epoch:18 step:17658 [D loss: 0.220310, acc.: 89.84%] [G loss: 1.890682]\n",
      "epoch:18 step:17659 [D loss: 0.187137, acc.: 96.09%] [G loss: 2.059934]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:18 step:17660 [D loss: 0.151038, acc.: 96.88%] [G loss: 1.837418]\n",
      "epoch:18 step:17661 [D loss: 0.241090, acc.: 96.09%] [G loss: 2.040437]\n",
      "epoch:18 step:17662 [D loss: 0.141298, acc.: 98.44%] [G loss: 2.007505]\n",
      "epoch:18 step:17663 [D loss: 0.647569, acc.: 64.84%] [G loss: 1.575331]\n",
      "epoch:18 step:17664 [D loss: 0.427187, acc.: 85.94%] [G loss: 1.505523]\n",
      "epoch:18 step:17665 [D loss: 0.471705, acc.: 79.69%] [G loss: 1.803688]\n",
      "epoch:18 step:17666 [D loss: 1.216876, acc.: 38.28%] [G loss: 1.071732]\n",
      "epoch:18 step:17667 [D loss: 0.832502, acc.: 47.66%] [G loss: 0.755870]\n",
      "epoch:18 step:17668 [D loss: 0.654399, acc.: 58.59%] [G loss: 0.959907]\n",
      "epoch:18 step:17669 [D loss: 0.626214, acc.: 65.62%] [G loss: 1.103078]\n",
      "epoch:18 step:17670 [D loss: 0.320363, acc.: 84.38%] [G loss: 1.155351]\n",
      "epoch:18 step:17671 [D loss: 1.161900, acc.: 54.69%] [G loss: 1.396747]\n",
      "epoch:18 step:17672 [D loss: 0.183006, acc.: 93.75%] [G loss: 1.680107]\n",
      "epoch:18 step:17673 [D loss: 0.724362, acc.: 49.22%] [G loss: 1.325943]\n",
      "epoch:18 step:17674 [D loss: 0.706928, acc.: 57.81%] [G loss: 1.051959]\n",
      "epoch:18 step:17675 [D loss: 0.587429, acc.: 65.62%] [G loss: 1.247403]\n",
      "epoch:18 step:17676 [D loss: 0.571277, acc.: 67.19%] [G loss: 1.068353]\n",
      "epoch:18 step:17677 [D loss: 0.984944, acc.: 34.38%] [G loss: 1.191083]\n",
      "epoch:18 step:17678 [D loss: 0.556790, acc.: 72.66%] [G loss: 1.254567]\n",
      "epoch:18 step:17679 [D loss: 0.696584, acc.: 53.91%] [G loss: 1.244003]\n",
      "epoch:18 step:17680 [D loss: 0.735270, acc.: 50.00%] [G loss: 0.831012]\n",
      "epoch:18 step:17681 [D loss: 0.440775, acc.: 84.38%] [G loss: 1.153786]\n",
      "epoch:18 step:17682 [D loss: 0.561742, acc.: 73.44%] [G loss: 1.072613]\n",
      "epoch:18 step:17683 [D loss: 0.771163, acc.: 48.44%] [G loss: 0.937184]\n",
      "epoch:18 step:17684 [D loss: 0.702199, acc.: 54.69%] [G loss: 1.042510]\n",
      "epoch:18 step:17685 [D loss: 0.734747, acc.: 46.09%] [G loss: 1.015581]\n",
      "epoch:18 step:17686 [D loss: 0.647641, acc.: 63.28%] [G loss: 0.891892]\n",
      "epoch:18 step:17687 [D loss: 0.379737, acc.: 83.59%] [G loss: 0.982679]\n",
      "epoch:18 step:17688 [D loss: 0.556097, acc.: 74.22%] [G loss: 0.961742]\n",
      "epoch:18 step:17689 [D loss: 0.576642, acc.: 71.09%] [G loss: 0.989767]\n",
      "epoch:18 step:17690 [D loss: 0.737270, acc.: 50.78%] [G loss: 0.980049]\n",
      "epoch:18 step:17691 [D loss: 0.681110, acc.: 53.91%] [G loss: 0.985607]\n",
      "epoch:18 step:17692 [D loss: 0.557216, acc.: 70.31%] [G loss: 1.004462]\n",
      "epoch:18 step:17693 [D loss: 0.522092, acc.: 79.69%] [G loss: 0.979072]\n",
      "epoch:18 step:17694 [D loss: 0.545671, acc.: 74.22%] [G loss: 1.017827]\n",
      "epoch:18 step:17695 [D loss: 0.554237, acc.: 74.22%] [G loss: 1.058033]\n",
      "epoch:18 step:17696 [D loss: 0.698911, acc.: 58.59%] [G loss: 0.421725]\n",
      "epoch:18 step:17697 [D loss: 0.704371, acc.: 54.69%] [G loss: 0.743774]\n",
      "epoch:18 step:17698 [D loss: 0.542955, acc.: 75.00%] [G loss: 0.948938]\n",
      "epoch:18 step:17699 [D loss: 0.909478, acc.: 38.28%] [G loss: 1.015968]\n",
      "epoch:18 step:17700 [D loss: 0.330434, acc.: 88.28%] [G loss: 0.909867]\n",
      "epoch:18 step:17701 [D loss: 0.464015, acc.: 86.72%] [G loss: 1.151849]\n",
      "epoch:18 step:17702 [D loss: 0.753524, acc.: 45.31%] [G loss: 0.906262]\n",
      "epoch:18 step:17703 [D loss: 0.709844, acc.: 52.34%] [G loss: 1.052007]\n",
      "epoch:18 step:17704 [D loss: 0.764770, acc.: 42.97%] [G loss: 0.892014]\n",
      "epoch:18 step:17705 [D loss: 0.460988, acc.: 82.03%] [G loss: 0.861495]\n",
      "epoch:18 step:17706 [D loss: 0.496779, acc.: 78.91%] [G loss: 0.965213]\n",
      "epoch:18 step:17707 [D loss: 0.278108, acc.: 92.97%] [G loss: 1.326611]\n",
      "epoch:18 step:17708 [D loss: 0.384084, acc.: 87.50%] [G loss: 1.190728]\n",
      "epoch:18 step:17709 [D loss: 0.812895, acc.: 43.75%] [G loss: 1.092386]\n",
      "epoch:18 step:17710 [D loss: 0.795574, acc.: 55.47%] [G loss: 1.142239]\n",
      "epoch:18 step:17711 [D loss: 0.484865, acc.: 78.91%] [G loss: 1.195818]\n",
      "epoch:18 step:17712 [D loss: 0.720593, acc.: 54.69%] [G loss: 1.080398]\n",
      "epoch:18 step:17713 [D loss: 0.829937, acc.: 56.25%] [G loss: 0.934419]\n",
      "epoch:18 step:17714 [D loss: 0.303829, acc.: 92.97%] [G loss: 1.250070]\n",
      "epoch:18 step:17715 [D loss: 0.575734, acc.: 69.53%] [G loss: 0.553381]\n",
      "epoch:18 step:17716 [D loss: 0.238036, acc.: 96.09%] [G loss: 1.469468]\n",
      "epoch:18 step:17717 [D loss: 0.158903, acc.: 99.22%] [G loss: 1.448652]\n",
      "epoch:18 step:17718 [D loss: 0.177877, acc.: 100.00%] [G loss: 1.582182]\n",
      "epoch:18 step:17719 [D loss: 0.218171, acc.: 99.22%] [G loss: 1.267832]\n",
      "epoch:18 step:17720 [D loss: 0.246529, acc.: 91.41%] [G loss: 1.907700]\n",
      "epoch:18 step:17721 [D loss: 0.421827, acc.: 83.59%] [G loss: 1.644376]\n",
      "epoch:18 step:17722 [D loss: 0.638654, acc.: 64.06%] [G loss: 1.629513]\n",
      "epoch:18 step:17723 [D loss: 0.356742, acc.: 85.16%] [G loss: 1.620996]\n",
      "epoch:18 step:17724 [D loss: 0.671237, acc.: 62.50%] [G loss: 1.345103]\n",
      "epoch:18 step:17725 [D loss: 0.467272, acc.: 78.12%] [G loss: 1.537970]\n",
      "epoch:18 step:17726 [D loss: 0.505201, acc.: 73.44%] [G loss: 1.437377]\n",
      "epoch:18 step:17727 [D loss: 0.623110, acc.: 64.84%] [G loss: 1.269650]\n",
      "epoch:18 step:17728 [D loss: 0.742346, acc.: 57.03%] [G loss: 0.429533]\n",
      "epoch:18 step:17729 [D loss: 0.688700, acc.: 57.03%] [G loss: 0.970496]\n",
      "epoch:18 step:17730 [D loss: 0.635934, acc.: 60.94%] [G loss: 1.070396]\n",
      "epoch:18 step:17731 [D loss: 0.587024, acc.: 69.53%] [G loss: 0.743033]\n",
      "epoch:18 step:17732 [D loss: 0.660419, acc.: 63.28%] [G loss: 1.171726]\n",
      "epoch:18 step:17733 [D loss: 0.629280, acc.: 60.16%] [G loss: 1.151958]\n",
      "epoch:18 step:17734 [D loss: 0.943681, acc.: 32.03%] [G loss: 0.746858]\n",
      "epoch:18 step:17735 [D loss: 0.671226, acc.: 61.72%] [G loss: 1.318272]\n",
      "epoch:18 step:17736 [D loss: 0.509194, acc.: 72.66%] [G loss: 1.187548]\n",
      "epoch:18 step:17737 [D loss: 0.637719, acc.: 64.06%] [G loss: 1.118791]\n",
      "epoch:18 step:17738 [D loss: 1.025451, acc.: 32.81%] [G loss: 1.350590]\n",
      "epoch:18 step:17739 [D loss: 0.600687, acc.: 61.72%] [G loss: 1.219322]\n",
      "epoch:18 step:17740 [D loss: 0.795406, acc.: 50.00%] [G loss: 1.178217]\n",
      "epoch:18 step:17741 [D loss: 0.608075, acc.: 64.84%] [G loss: 1.266096]\n",
      "epoch:18 step:17742 [D loss: 0.489624, acc.: 85.16%] [G loss: 1.415812]\n",
      "epoch:18 step:17743 [D loss: 0.205558, acc.: 99.22%] [G loss: 1.535587]\n",
      "epoch:18 step:17744 [D loss: 0.187213, acc.: 97.66%] [G loss: 1.598876]\n",
      "epoch:18 step:17745 [D loss: 0.567801, acc.: 64.84%] [G loss: 1.226481]\n",
      "epoch:18 step:17746 [D loss: 0.832633, acc.: 55.47%] [G loss: 1.431167]\n",
      "epoch:18 step:17747 [D loss: 0.641623, acc.: 59.38%] [G loss: 1.168709]\n",
      "epoch:18 step:17748 [D loss: 0.950313, acc.: 37.50%] [G loss: 1.066061]\n",
      "epoch:18 step:17749 [D loss: 0.623410, acc.: 67.97%] [G loss: 0.918413]\n",
      "epoch:18 step:17750 [D loss: 0.491192, acc.: 75.00%] [G loss: 1.084856]\n",
      "epoch:18 step:17751 [D loss: 0.452259, acc.: 73.44%] [G loss: 1.048181]\n",
      "epoch:18 step:17752 [D loss: 0.353869, acc.: 87.50%] [G loss: 0.857567]\n",
      "epoch:18 step:17753 [D loss: 0.484590, acc.: 75.00%] [G loss: 1.005863]\n",
      "epoch:18 step:17754 [D loss: 0.867609, acc.: 38.28%] [G loss: 1.223436]\n",
      "epoch:18 step:17755 [D loss: 0.397349, acc.: 87.50%] [G loss: 1.157147]\n",
      "epoch:18 step:17756 [D loss: 0.344012, acc.: 94.53%] [G loss: 1.289147]\n",
      "epoch:18 step:17757 [D loss: 0.674392, acc.: 61.72%] [G loss: 0.585119]\n",
      "epoch:18 step:17758 [D loss: 0.569114, acc.: 64.84%] [G loss: 1.602622]\n",
      "epoch:18 step:17759 [D loss: 0.305029, acc.: 93.75%] [G loss: 1.780669]\n",
      "epoch:18 step:17760 [D loss: 0.237287, acc.: 96.09%] [G loss: 1.620037]\n",
      "epoch:18 step:17761 [D loss: 0.322824, acc.: 94.53%] [G loss: 1.674652]\n",
      "epoch:18 step:17762 [D loss: 0.204616, acc.: 98.44%] [G loss: 1.572284]\n",
      "epoch:18 step:17763 [D loss: 0.215449, acc.: 99.22%] [G loss: 1.752485]\n",
      "epoch:18 step:17764 [D loss: 0.113297, acc.: 99.22%] [G loss: 1.672369]\n",
      "epoch:18 step:17765 [D loss: 0.239207, acc.: 91.41%] [G loss: 2.162099]\n",
      "epoch:18 step:17766 [D loss: 0.103421, acc.: 100.00%] [G loss: 1.761625]\n",
      "epoch:18 step:17767 [D loss: 0.198121, acc.: 99.22%] [G loss: 1.666556]\n",
      "epoch:18 step:17768 [D loss: 0.425343, acc.: 75.78%] [G loss: 0.874760]\n",
      "epoch:18 step:17769 [D loss: 0.444914, acc.: 77.34%] [G loss: 0.837278]\n",
      "epoch:18 step:17770 [D loss: 1.474119, acc.: 14.06%] [G loss: 1.155662]\n",
      "epoch:18 step:17771 [D loss: 0.866795, acc.: 46.09%] [G loss: 1.431180]\n",
      "epoch:18 step:17772 [D loss: 0.319843, acc.: 85.94%] [G loss: 1.617462]\n",
      "epoch:18 step:17773 [D loss: 0.966871, acc.: 42.97%] [G loss: 1.591189]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:18 step:17774 [D loss: 0.642743, acc.: 60.16%] [G loss: 1.365842]\n",
      "epoch:18 step:17775 [D loss: 0.529991, acc.: 76.56%] [G loss: 1.276428]\n",
      "epoch:18 step:17776 [D loss: 0.647920, acc.: 57.03%] [G loss: 1.173357]\n",
      "epoch:18 step:17777 [D loss: 0.463468, acc.: 78.91%] [G loss: 1.393493]\n",
      "epoch:18 step:17778 [D loss: 0.191540, acc.: 96.09%] [G loss: 1.686984]\n",
      "epoch:18 step:17779 [D loss: 0.691936, acc.: 55.47%] [G loss: 1.550210]\n",
      "epoch:18 step:17780 [D loss: 0.633952, acc.: 64.84%] [G loss: 1.382502]\n",
      "epoch:18 step:17781 [D loss: 0.775237, acc.: 50.78%] [G loss: 1.219002]\n",
      "epoch:18 step:17782 [D loss: 0.601935, acc.: 68.75%] [G loss: 1.546399]\n",
      "epoch:18 step:17783 [D loss: 0.482927, acc.: 75.78%] [G loss: 1.318391]\n",
      "epoch:18 step:17784 [D loss: 0.559267, acc.: 71.09%] [G loss: 1.229844]\n",
      "epoch:18 step:17785 [D loss: 0.467250, acc.: 77.34%] [G loss: 1.355000]\n",
      "epoch:18 step:17786 [D loss: 0.282184, acc.: 87.50%] [G loss: 1.499879]\n",
      "epoch:18 step:17787 [D loss: 0.265373, acc.: 94.53%] [G loss: 0.630733]\n",
      "epoch:18 step:17788 [D loss: 0.553872, acc.: 75.78%] [G loss: 1.584378]\n",
      "epoch:18 step:17789 [D loss: 0.616114, acc.: 67.97%] [G loss: 1.201775]\n",
      "epoch:18 step:17790 [D loss: 0.509349, acc.: 75.78%] [G loss: 1.135297]\n",
      "epoch:18 step:17791 [D loss: 0.455454, acc.: 77.34%] [G loss: 0.950009]\n",
      "epoch:18 step:17792 [D loss: 0.522889, acc.: 73.44%] [G loss: 1.251209]\n",
      "epoch:18 step:17793 [D loss: 0.461743, acc.: 81.25%] [G loss: 1.111381]\n",
      "epoch:18 step:17794 [D loss: 0.539343, acc.: 71.09%] [G loss: 0.792279]\n",
      "epoch:18 step:17795 [D loss: 0.159630, acc.: 96.09%] [G loss: 1.377874]\n",
      "epoch:18 step:17796 [D loss: 0.462390, acc.: 82.03%] [G loss: 1.489278]\n",
      "epoch:18 step:17797 [D loss: 0.437349, acc.: 82.03%] [G loss: 1.264460]\n",
      "epoch:18 step:17798 [D loss: 0.895810, acc.: 46.88%] [G loss: 1.068943]\n",
      "epoch:18 step:17799 [D loss: 0.500171, acc.: 73.44%] [G loss: 1.595746]\n",
      "epoch:18 step:17800 [D loss: 0.297904, acc.: 92.19%] [G loss: 1.254022]\n",
      "##############\n",
      "[3.88296017 2.28938339 6.53462173 5.6820733  4.32585265 6.08546674\n",
      " 5.43383603 5.50693566 5.92442349 4.92606756]\n",
      "##########\n",
      "epoch:18 step:17801 [D loss: 0.538106, acc.: 74.22%] [G loss: 1.179099]\n",
      "epoch:18 step:17802 [D loss: 0.335473, acc.: 89.06%] [G loss: 1.514798]\n",
      "epoch:18 step:17803 [D loss: 0.218235, acc.: 90.62%] [G loss: 1.399515]\n",
      "epoch:19 step:17804 [D loss: 0.849897, acc.: 51.56%] [G loss: 1.380224]\n",
      "epoch:19 step:17805 [D loss: 0.813028, acc.: 52.34%] [G loss: 1.216677]\n",
      "epoch:19 step:17806 [D loss: 0.704978, acc.: 55.47%] [G loss: 1.189886]\n",
      "epoch:19 step:17807 [D loss: 0.764034, acc.: 52.34%] [G loss: 1.285411]\n",
      "epoch:19 step:17808 [D loss: 0.779242, acc.: 50.78%] [G loss: 1.141742]\n",
      "epoch:19 step:17809 [D loss: 0.648620, acc.: 63.28%] [G loss: 1.005841]\n",
      "epoch:19 step:17810 [D loss: 0.630769, acc.: 61.72%] [G loss: 1.039975]\n",
      "epoch:19 step:17811 [D loss: 0.527216, acc.: 74.22%] [G loss: 1.062824]\n",
      "epoch:19 step:17812 [D loss: 0.494775, acc.: 77.34%] [G loss: 1.129356]\n",
      "epoch:19 step:17813 [D loss: 0.472871, acc.: 78.91%] [G loss: 0.450389]\n",
      "epoch:19 step:17814 [D loss: 0.660192, acc.: 60.94%] [G loss: 1.001638]\n",
      "epoch:19 step:17815 [D loss: 0.555051, acc.: 74.22%] [G loss: 1.364524]\n",
      "epoch:19 step:17816 [D loss: 0.496116, acc.: 81.25%] [G loss: 1.134945]\n",
      "epoch:19 step:17817 [D loss: 0.530148, acc.: 75.78%] [G loss: 0.406696]\n",
      "epoch:19 step:17818 [D loss: 0.560090, acc.: 69.53%] [G loss: 0.972616]\n",
      "epoch:19 step:17819 [D loss: 0.564836, acc.: 71.09%] [G loss: 0.971793]\n",
      "epoch:19 step:17820 [D loss: 0.736583, acc.: 53.91%] [G loss: 0.702184]\n",
      "epoch:19 step:17821 [D loss: 0.940625, acc.: 42.19%] [G loss: 0.905375]\n",
      "epoch:19 step:17822 [D loss: 0.802743, acc.: 53.12%] [G loss: 1.301027]\n",
      "epoch:19 step:17823 [D loss: 0.678426, acc.: 62.50%] [G loss: 1.281698]\n",
      "epoch:19 step:17824 [D loss: 0.877885, acc.: 44.53%] [G loss: 0.983115]\n",
      "epoch:19 step:17825 [D loss: 0.862523, acc.: 36.72%] [G loss: 1.429332]\n",
      "epoch:19 step:17826 [D loss: 0.736893, acc.: 58.59%] [G loss: 1.449135]\n",
      "epoch:19 step:17827 [D loss: 0.627125, acc.: 63.28%] [G loss: 1.292199]\n",
      "epoch:19 step:17828 [D loss: 0.688449, acc.: 57.81%] [G loss: 1.105591]\n",
      "epoch:19 step:17829 [D loss: 0.722849, acc.: 50.78%] [G loss: 1.071779]\n",
      "epoch:19 step:17830 [D loss: 0.185410, acc.: 98.44%] [G loss: 1.108463]\n",
      "epoch:19 step:17831 [D loss: 0.359092, acc.: 90.62%] [G loss: 1.541174]\n",
      "epoch:19 step:17832 [D loss: 0.532718, acc.: 70.31%] [G loss: 1.227886]\n",
      "epoch:19 step:17833 [D loss: 0.657121, acc.: 57.03%] [G loss: 1.274541]\n",
      "epoch:19 step:17834 [D loss: 0.243798, acc.: 93.75%] [G loss: 1.319772]\n",
      "epoch:19 step:17835 [D loss: 0.216463, acc.: 97.66%] [G loss: 1.606123]\n",
      "epoch:19 step:17836 [D loss: 0.147085, acc.: 100.00%] [G loss: 1.699461]\n",
      "epoch:19 step:17837 [D loss: 0.192197, acc.: 96.88%] [G loss: 1.824809]\n",
      "epoch:19 step:17838 [D loss: 0.163828, acc.: 95.31%] [G loss: 1.784418]\n",
      "epoch:19 step:17839 [D loss: 0.098696, acc.: 98.44%] [G loss: 1.839072]\n",
      "epoch:19 step:17840 [D loss: 0.978870, acc.: 51.56%] [G loss: 1.534703]\n",
      "epoch:19 step:17841 [D loss: 0.969815, acc.: 40.62%] [G loss: 0.914510]\n",
      "epoch:19 step:17842 [D loss: 1.009920, acc.: 39.84%] [G loss: 0.809311]\n",
      "epoch:19 step:17843 [D loss: 0.770744, acc.: 53.12%] [G loss: 0.994284]\n",
      "epoch:19 step:17844 [D loss: 0.559136, acc.: 68.75%] [G loss: 1.028356]\n",
      "epoch:19 step:17845 [D loss: 0.601948, acc.: 66.41%] [G loss: 0.940043]\n",
      "epoch:19 step:17846 [D loss: 0.334203, acc.: 92.19%] [G loss: 1.167792]\n",
      "epoch:19 step:17847 [D loss: 0.482470, acc.: 82.81%] [G loss: 1.326337]\n",
      "epoch:19 step:17848 [D loss: 0.579683, acc.: 73.44%] [G loss: 1.081418]\n",
      "epoch:19 step:17849 [D loss: 0.302185, acc.: 92.97%] [G loss: 1.295052]\n",
      "epoch:19 step:17850 [D loss: 0.686089, acc.: 58.59%] [G loss: 1.030427]\n",
      "epoch:19 step:17851 [D loss: 0.725286, acc.: 57.03%] [G loss: 0.733207]\n",
      "epoch:19 step:17852 [D loss: 0.656981, acc.: 64.84%] [G loss: 1.124086]\n",
      "epoch:19 step:17853 [D loss: 0.575953, acc.: 72.66%] [G loss: 0.854994]\n",
      "epoch:19 step:17854 [D loss: 0.675931, acc.: 62.50%] [G loss: 1.265079]\n",
      "epoch:19 step:17855 [D loss: 0.461474, acc.: 73.44%] [G loss: 1.274258]\n",
      "epoch:19 step:17856 [D loss: 0.519354, acc.: 73.44%] [G loss: 1.398734]\n",
      "epoch:19 step:17857 [D loss: 0.951837, acc.: 25.78%] [G loss: 1.179883]\n",
      "epoch:19 step:17858 [D loss: 0.855153, acc.: 44.53%] [G loss: 1.119107]\n",
      "epoch:19 step:17859 [D loss: 0.804509, acc.: 45.31%] [G loss: 1.097397]\n",
      "epoch:19 step:17860 [D loss: 0.225715, acc.: 95.31%] [G loss: 1.231271]\n",
      "epoch:19 step:17861 [D loss: 0.231581, acc.: 95.31%] [G loss: 1.108607]\n",
      "epoch:19 step:17862 [D loss: 0.644960, acc.: 64.06%] [G loss: 1.632817]\n",
      "epoch:19 step:17863 [D loss: 0.707049, acc.: 57.81%] [G loss: 0.447381]\n",
      "epoch:19 step:17864 [D loss: 0.822576, acc.: 50.00%] [G loss: 1.053262]\n",
      "epoch:19 step:17865 [D loss: 0.923092, acc.: 36.72%] [G loss: 0.405471]\n",
      "epoch:19 step:17866 [D loss: 0.575899, acc.: 65.62%] [G loss: 1.211847]\n",
      "epoch:19 step:17867 [D loss: 1.335750, acc.: 19.53%] [G loss: 1.086855]\n",
      "epoch:19 step:17868 [D loss: 0.707868, acc.: 55.47%] [G loss: 1.805511]\n",
      "epoch:19 step:17869 [D loss: 0.727836, acc.: 57.81%] [G loss: 1.574242]\n",
      "epoch:19 step:17870 [D loss: 0.638177, acc.: 64.06%] [G loss: 1.444795]\n",
      "epoch:19 step:17871 [D loss: 0.436947, acc.: 78.12%] [G loss: 1.917390]\n",
      "epoch:19 step:17872 [D loss: 0.489172, acc.: 78.91%] [G loss: 1.459709]\n",
      "epoch:19 step:17873 [D loss: 0.435063, acc.: 81.25%] [G loss: 1.611449]\n",
      "epoch:19 step:17874 [D loss: 0.464277, acc.: 80.47%] [G loss: 1.457448]\n",
      "epoch:19 step:17875 [D loss: 0.640009, acc.: 61.72%] [G loss: 1.122663]\n",
      "epoch:19 step:17876 [D loss: 0.752003, acc.: 49.22%] [G loss: 1.102538]\n",
      "epoch:19 step:17877 [D loss: 0.585024, acc.: 70.31%] [G loss: 1.452002]\n",
      "epoch:19 step:17878 [D loss: 0.423505, acc.: 88.28%] [G loss: 1.795067]\n",
      "epoch:19 step:17879 [D loss: 0.265565, acc.: 93.75%] [G loss: 1.188466]\n",
      "epoch:19 step:17880 [D loss: 0.448062, acc.: 86.72%] [G loss: 1.069759]\n",
      "epoch:19 step:17881 [D loss: 0.919996, acc.: 46.09%] [G loss: 1.115921]\n",
      "epoch:19 step:17882 [D loss: 0.682062, acc.: 62.50%] [G loss: 0.881718]\n",
      "epoch:19 step:17883 [D loss: 0.571448, acc.: 71.09%] [G loss: 1.207038]\n",
      "epoch:19 step:17884 [D loss: 0.428875, acc.: 90.62%] [G loss: 1.070159]\n",
      "epoch:19 step:17885 [D loss: 0.397649, acc.: 90.62%] [G loss: 1.058475]\n",
      "epoch:19 step:17886 [D loss: 0.400297, acc.: 86.72%] [G loss: 1.067472]\n",
      "epoch:19 step:17887 [D loss: 0.621691, acc.: 64.84%] [G loss: 1.329835]\n",
      "epoch:19 step:17888 [D loss: 0.448952, acc.: 87.50%] [G loss: 1.266067]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:19 step:17889 [D loss: 0.508820, acc.: 79.69%] [G loss: 1.027318]\n",
      "epoch:19 step:17890 [D loss: 0.420024, acc.: 89.84%] [G loss: 1.238051]\n",
      "epoch:19 step:17891 [D loss: 0.409292, acc.: 90.62%] [G loss: 1.575785]\n",
      "epoch:19 step:17892 [D loss: 0.337610, acc.: 92.97%] [G loss: 1.187510]\n",
      "epoch:19 step:17893 [D loss: 0.372957, acc.: 91.41%] [G loss: 1.304193]\n",
      "epoch:19 step:17894 [D loss: 0.387121, acc.: 90.62%] [G loss: 1.362587]\n",
      "epoch:19 step:17895 [D loss: 0.228770, acc.: 98.44%] [G loss: 1.524927]\n",
      "epoch:19 step:17896 [D loss: 0.315066, acc.: 88.28%] [G loss: 1.789613]\n",
      "epoch:19 step:17897 [D loss: 0.440268, acc.: 85.16%] [G loss: 1.538094]\n",
      "epoch:19 step:17898 [D loss: 0.761527, acc.: 58.59%] [G loss: 1.202722]\n",
      "epoch:19 step:17899 [D loss: 0.698929, acc.: 55.47%] [G loss: 1.424476]\n",
      "epoch:19 step:17900 [D loss: 0.740197, acc.: 53.12%] [G loss: 1.043661]\n",
      "epoch:19 step:17901 [D loss: 0.672408, acc.: 63.28%] [G loss: 1.439810]\n",
      "epoch:19 step:17902 [D loss: 0.680953, acc.: 58.59%] [G loss: 0.916552]\n",
      "epoch:19 step:17903 [D loss: 0.930688, acc.: 35.94%] [G loss: 0.593785]\n",
      "epoch:19 step:17904 [D loss: 0.469632, acc.: 79.69%] [G loss: 1.090392]\n",
      "epoch:19 step:17905 [D loss: 0.770594, acc.: 42.19%] [G loss: 1.114414]\n",
      "epoch:19 step:17906 [D loss: 0.853698, acc.: 42.19%] [G loss: 0.904593]\n",
      "epoch:19 step:17907 [D loss: 0.855577, acc.: 42.97%] [G loss: 1.175529]\n",
      "epoch:19 step:17908 [D loss: 0.739786, acc.: 50.78%] [G loss: 1.149404]\n",
      "epoch:19 step:17909 [D loss: 0.722722, acc.: 58.59%] [G loss: 1.001118]\n",
      "epoch:19 step:17910 [D loss: 0.531659, acc.: 68.75%] [G loss: 0.963851]\n",
      "epoch:19 step:17911 [D loss: 0.513289, acc.: 75.78%] [G loss: 0.924881]\n",
      "epoch:19 step:17912 [D loss: 0.739258, acc.: 50.78%] [G loss: 0.550076]\n",
      "epoch:19 step:17913 [D loss: 0.720863, acc.: 53.91%] [G loss: 0.691163]\n",
      "epoch:19 step:17914 [D loss: 0.658457, acc.: 64.06%] [G loss: 0.844235]\n",
      "epoch:19 step:17915 [D loss: 0.622327, acc.: 67.19%] [G loss: 0.949197]\n",
      "epoch:19 step:17916 [D loss: 0.504734, acc.: 78.91%] [G loss: 1.198816]\n",
      "epoch:19 step:17917 [D loss: 0.615370, acc.: 63.28%] [G loss: 0.931534]\n",
      "epoch:19 step:17918 [D loss: 0.507537, acc.: 78.91%] [G loss: 1.305735]\n",
      "epoch:19 step:17919 [D loss: 0.599407, acc.: 66.41%] [G loss: 1.022448]\n",
      "epoch:19 step:17920 [D loss: 0.656766, acc.: 64.84%] [G loss: 1.045540]\n",
      "epoch:19 step:17921 [D loss: 0.598405, acc.: 67.97%] [G loss: 1.321861]\n",
      "epoch:19 step:17922 [D loss: 0.317737, acc.: 82.03%] [G loss: 1.465386]\n",
      "epoch:19 step:17923 [D loss: 0.669611, acc.: 64.84%] [G loss: 1.301981]\n",
      "epoch:19 step:17924 [D loss: 0.417687, acc.: 86.72%] [G loss: 1.296562]\n",
      "epoch:19 step:17925 [D loss: 0.411442, acc.: 86.72%] [G loss: 1.479106]\n",
      "epoch:19 step:17926 [D loss: 0.775808, acc.: 50.00%] [G loss: 1.047251]\n",
      "epoch:19 step:17927 [D loss: 0.606810, acc.: 71.09%] [G loss: 1.121287]\n",
      "epoch:19 step:17928 [D loss: 0.714812, acc.: 53.91%] [G loss: 0.875041]\n",
      "epoch:19 step:17929 [D loss: 0.695601, acc.: 59.38%] [G loss: 1.295295]\n",
      "epoch:19 step:17930 [D loss: 0.771940, acc.: 52.34%] [G loss: 1.110597]\n",
      "epoch:19 step:17931 [D loss: 0.617539, acc.: 61.72%] [G loss: 1.121724]\n",
      "epoch:19 step:17932 [D loss: 0.680967, acc.: 57.81%] [G loss: 1.191694]\n",
      "epoch:19 step:17933 [D loss: 0.357997, acc.: 93.75%] [G loss: 1.113340]\n",
      "epoch:19 step:17934 [D loss: 0.562406, acc.: 69.53%] [G loss: 1.087996]\n",
      "epoch:19 step:17935 [D loss: 0.429801, acc.: 88.28%] [G loss: 1.191096]\n",
      "epoch:19 step:17936 [D loss: 0.588016, acc.: 65.62%] [G loss: 1.013965]\n",
      "epoch:19 step:17937 [D loss: 0.431925, acc.: 79.69%] [G loss: 1.180636]\n",
      "epoch:19 step:17938 [D loss: 0.499576, acc.: 82.03%] [G loss: 1.395264]\n",
      "epoch:19 step:17939 [D loss: 0.637181, acc.: 65.62%] [G loss: 1.340802]\n",
      "epoch:19 step:17940 [D loss: 0.843982, acc.: 36.72%] [G loss: 1.117095]\n",
      "epoch:19 step:17941 [D loss: 0.762075, acc.: 50.78%] [G loss: 1.093279]\n",
      "epoch:19 step:17942 [D loss: 0.537243, acc.: 75.00%] [G loss: 0.979811]\n",
      "epoch:19 step:17943 [D loss: 0.378250, acc.: 85.16%] [G loss: 1.175521]\n",
      "epoch:19 step:17944 [D loss: 0.349630, acc.: 93.75%] [G loss: 1.478933]\n",
      "epoch:19 step:17945 [D loss: 0.555117, acc.: 71.88%] [G loss: 1.125606]\n",
      "epoch:19 step:17946 [D loss: 0.269144, acc.: 92.19%] [G loss: 1.241196]\n",
      "epoch:19 step:17947 [D loss: 0.594926, acc.: 67.97%] [G loss: 1.285260]\n",
      "epoch:19 step:17948 [D loss: 0.171321, acc.: 99.22%] [G loss: 1.436459]\n",
      "epoch:19 step:17949 [D loss: 0.434324, acc.: 82.03%] [G loss: 1.535061]\n",
      "epoch:19 step:17950 [D loss: 0.536423, acc.: 69.53%] [G loss: 1.244298]\n",
      "epoch:19 step:17951 [D loss: 0.823868, acc.: 38.28%] [G loss: 1.182523]\n",
      "epoch:19 step:17952 [D loss: 0.220922, acc.: 96.09%] [G loss: 1.510368]\n",
      "epoch:19 step:17953 [D loss: 0.161658, acc.: 97.66%] [G loss: 1.634183]\n",
      "epoch:19 step:17954 [D loss: 0.224351, acc.: 96.09%] [G loss: 1.389317]\n",
      "epoch:19 step:17955 [D loss: 0.324363, acc.: 94.53%] [G loss: 1.768204]\n",
      "epoch:19 step:17956 [D loss: 0.755806, acc.: 57.03%] [G loss: 1.370269]\n",
      "epoch:19 step:17957 [D loss: 0.866567, acc.: 40.62%] [G loss: 1.438609]\n",
      "epoch:19 step:17958 [D loss: 0.714375, acc.: 53.91%] [G loss: 1.269840]\n",
      "epoch:19 step:17959 [D loss: 0.672940, acc.: 57.81%] [G loss: 1.444760]\n",
      "epoch:19 step:17960 [D loss: 0.589830, acc.: 63.28%] [G loss: 1.181778]\n",
      "epoch:19 step:17961 [D loss: 0.789209, acc.: 48.44%] [G loss: 1.329712]\n",
      "epoch:19 step:17962 [D loss: 0.696886, acc.: 58.59%] [G loss: 1.083129]\n",
      "epoch:19 step:17963 [D loss: 0.614073, acc.: 64.06%] [G loss: 0.792569]\n",
      "epoch:19 step:17964 [D loss: 0.596778, acc.: 70.31%] [G loss: 1.095062]\n",
      "epoch:19 step:17965 [D loss: 0.363773, acc.: 88.28%] [G loss: 1.000291]\n",
      "epoch:19 step:17966 [D loss: 0.461852, acc.: 81.25%] [G loss: 1.303427]\n",
      "epoch:19 step:17967 [D loss: 0.404218, acc.: 85.94%] [G loss: 1.328375]\n",
      "epoch:19 step:17968 [D loss: 0.586195, acc.: 70.31%] [G loss: 1.179674]\n",
      "epoch:19 step:17969 [D loss: 1.143888, acc.: 23.44%] [G loss: 1.454648]\n",
      "epoch:19 step:17970 [D loss: 0.725809, acc.: 50.00%] [G loss: 1.407335]\n",
      "epoch:19 step:17971 [D loss: 0.667307, acc.: 67.19%] [G loss: 0.864197]\n",
      "epoch:19 step:17972 [D loss: 0.640865, acc.: 64.84%] [G loss: 1.152435]\n",
      "epoch:19 step:17973 [D loss: 0.513560, acc.: 80.47%] [G loss: 0.803909]\n",
      "epoch:19 step:17974 [D loss: 0.778060, acc.: 42.97%] [G loss: 0.890646]\n",
      "epoch:19 step:17975 [D loss: 0.526811, acc.: 80.47%] [G loss: 1.026048]\n",
      "epoch:19 step:17976 [D loss: 0.751439, acc.: 55.47%] [G loss: 0.548974]\n",
      "epoch:19 step:17977 [D loss: 1.158766, acc.: 35.16%] [G loss: 0.918031]\n",
      "epoch:19 step:17978 [D loss: 0.517131, acc.: 78.12%] [G loss: 0.895515]\n",
      "epoch:19 step:17979 [D loss: 0.671806, acc.: 57.81%] [G loss: 1.014690]\n",
      "epoch:19 step:17980 [D loss: 0.715767, acc.: 51.56%] [G loss: 0.837910]\n",
      "epoch:19 step:17981 [D loss: 0.642376, acc.: 64.06%] [G loss: 0.816138]\n",
      "epoch:19 step:17982 [D loss: 0.476568, acc.: 81.25%] [G loss: 0.589193]\n",
      "epoch:19 step:17983 [D loss: 0.931697, acc.: 41.41%] [G loss: 0.806852]\n",
      "epoch:19 step:17984 [D loss: 0.867562, acc.: 39.06%] [G loss: 0.299586]\n",
      "epoch:19 step:17985 [D loss: 0.642791, acc.: 63.28%] [G loss: 1.017013]\n",
      "epoch:19 step:17986 [D loss: 0.714492, acc.: 50.78%] [G loss: 1.004277]\n",
      "epoch:19 step:17987 [D loss: 0.628374, acc.: 61.72%] [G loss: 0.885324]\n",
      "epoch:19 step:17988 [D loss: 0.872804, acc.: 47.66%] [G loss: 1.466731]\n",
      "epoch:19 step:17989 [D loss: 0.602073, acc.: 67.97%] [G loss: 1.371500]\n",
      "epoch:19 step:17990 [D loss: 0.674801, acc.: 57.81%] [G loss: 1.287675]\n",
      "epoch:19 step:17991 [D loss: 0.584564, acc.: 71.09%] [G loss: 1.268914]\n",
      "epoch:19 step:17992 [D loss: 0.631082, acc.: 64.06%] [G loss: 1.439700]\n",
      "epoch:19 step:17993 [D loss: 0.531532, acc.: 77.34%] [G loss: 1.129027]\n",
      "epoch:19 step:17994 [D loss: 0.541536, acc.: 71.88%] [G loss: 1.176542]\n",
      "epoch:19 step:17995 [D loss: 0.532898, acc.: 79.69%] [G loss: 1.161031]\n",
      "epoch:19 step:17996 [D loss: 0.491518, acc.: 76.56%] [G loss: 1.170079]\n",
      "epoch:19 step:17997 [D loss: 0.270830, acc.: 98.44%] [G loss: 1.169835]\n",
      "epoch:19 step:17998 [D loss: 0.382533, acc.: 87.50%] [G loss: 1.695220]\n",
      "epoch:19 step:17999 [D loss: 0.451565, acc.: 82.03%] [G loss: 1.186609]\n",
      "epoch:19 step:18000 [D loss: 0.498249, acc.: 78.91%] [G loss: 1.533044]\n",
      "##############\n",
      "[4.40924069 2.55528282 6.72236112 5.6260826  4.71921978 6.41728445\n",
      " 5.35224655 5.64025137 6.13293151 5.07184738]\n",
      "##########\n",
      "epoch:19 step:18001 [D loss: 0.383908, acc.: 89.06%] [G loss: 1.436508]\n",
      "epoch:19 step:18002 [D loss: 0.672891, acc.: 58.59%] [G loss: 0.784887]\n",
      "epoch:19 step:18003 [D loss: 0.388281, acc.: 88.28%] [G loss: 1.544480]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:19 step:18004 [D loss: 0.313746, acc.: 92.19%] [G loss: 1.371956]\n",
      "epoch:19 step:18005 [D loss: 0.658725, acc.: 60.94%] [G loss: 0.940246]\n",
      "epoch:19 step:18006 [D loss: 0.355914, acc.: 90.62%] [G loss: 1.039062]\n",
      "epoch:19 step:18007 [D loss: 0.383329, acc.: 78.12%] [G loss: 1.456614]\n",
      "epoch:19 step:18008 [D loss: 0.406220, acc.: 89.06%] [G loss: 1.301294]\n",
      "epoch:19 step:18009 [D loss: 0.257989, acc.: 95.31%] [G loss: 1.465144]\n",
      "epoch:19 step:18010 [D loss: 0.297055, acc.: 87.50%] [G loss: 1.367663]\n",
      "epoch:19 step:18011 [D loss: 0.291650, acc.: 92.97%] [G loss: 2.347427]\n",
      "epoch:19 step:18012 [D loss: 0.230421, acc.: 96.09%] [G loss: 1.640728]\n",
      "epoch:19 step:18013 [D loss: 1.362203, acc.: 43.75%] [G loss: 0.844527]\n",
      "epoch:19 step:18014 [D loss: 1.200918, acc.: 17.19%] [G loss: 0.566827]\n",
      "epoch:19 step:18015 [D loss: 0.847244, acc.: 39.84%] [G loss: 1.023968]\n",
      "epoch:19 step:18016 [D loss: 0.838279, acc.: 41.41%] [G loss: 1.201830]\n",
      "epoch:19 step:18017 [D loss: 0.671461, acc.: 60.16%] [G loss: 1.094591]\n",
      "epoch:19 step:18018 [D loss: 0.749750, acc.: 49.22%] [G loss: 0.832760]\n",
      "epoch:19 step:18019 [D loss: 0.702860, acc.: 57.81%] [G loss: 0.807113]\n",
      "epoch:19 step:18020 [D loss: 0.384762, acc.: 88.28%] [G loss: 0.987186]\n",
      "epoch:19 step:18021 [D loss: 0.388135, acc.: 83.59%] [G loss: 0.962123]\n",
      "epoch:19 step:18022 [D loss: 0.587280, acc.: 64.06%] [G loss: 1.091411]\n",
      "epoch:19 step:18023 [D loss: 0.194715, acc.: 99.22%] [G loss: 1.784001]\n",
      "epoch:19 step:18024 [D loss: 0.207868, acc.: 94.53%] [G loss: 1.267654]\n",
      "epoch:19 step:18025 [D loss: 0.858795, acc.: 46.09%] [G loss: 1.581008]\n",
      "epoch:19 step:18026 [D loss: 0.569078, acc.: 70.31%] [G loss: 2.104147]\n",
      "epoch:19 step:18027 [D loss: 0.721675, acc.: 62.50%] [G loss: 1.806906]\n",
      "epoch:19 step:18028 [D loss: 0.587943, acc.: 65.62%] [G loss: 1.245677]\n",
      "epoch:19 step:18029 [D loss: 0.642855, acc.: 59.38%] [G loss: 1.708430]\n",
      "epoch:19 step:18030 [D loss: 0.552760, acc.: 71.09%] [G loss: 1.317304]\n",
      "epoch:19 step:18031 [D loss: 0.633697, acc.: 62.50%] [G loss: 1.441302]\n",
      "epoch:19 step:18032 [D loss: 0.587239, acc.: 67.19%] [G loss: 1.457354]\n",
      "epoch:19 step:18033 [D loss: 0.170901, acc.: 94.53%] [G loss: 1.661317]\n",
      "epoch:19 step:18034 [D loss: 0.194611, acc.: 96.09%] [G loss: 1.892929]\n",
      "epoch:19 step:18035 [D loss: 0.194708, acc.: 95.31%] [G loss: 1.590468]\n",
      "epoch:19 step:18036 [D loss: 0.483467, acc.: 78.91%] [G loss: 1.715527]\n",
      "epoch:19 step:18037 [D loss: 0.379114, acc.: 86.72%] [G loss: 1.901967]\n",
      "epoch:19 step:18038 [D loss: 0.290924, acc.: 92.19%] [G loss: 1.811614]\n",
      "epoch:19 step:18039 [D loss: 0.603962, acc.: 65.62%] [G loss: 1.688934]\n",
      "epoch:19 step:18040 [D loss: 0.242916, acc.: 96.09%] [G loss: 1.856985]\n",
      "epoch:19 step:18041 [D loss: 0.229267, acc.: 94.53%] [G loss: 1.444877]\n",
      "epoch:19 step:18042 [D loss: 0.593060, acc.: 63.28%] [G loss: 1.360315]\n",
      "epoch:19 step:18043 [D loss: 0.644862, acc.: 67.19%] [G loss: 1.141110]\n",
      "epoch:19 step:18044 [D loss: 1.026754, acc.: 37.50%] [G loss: 1.210684]\n",
      "epoch:19 step:18045 [D loss: 0.583929, acc.: 67.97%] [G loss: 0.981252]\n",
      "epoch:19 step:18046 [D loss: 0.319228, acc.: 93.75%] [G loss: 1.100502]\n",
      "epoch:19 step:18047 [D loss: 0.602195, acc.: 67.97%] [G loss: 1.101270]\n",
      "epoch:19 step:18048 [D loss: 1.007671, acc.: 27.34%] [G loss: 0.993209]\n",
      "epoch:19 step:18049 [D loss: 0.771373, acc.: 52.34%] [G loss: 1.062475]\n",
      "epoch:19 step:18050 [D loss: 0.789645, acc.: 45.31%] [G loss: 0.681902]\n",
      "epoch:19 step:18051 [D loss: 0.871065, acc.: 42.97%] [G loss: 0.840924]\n",
      "epoch:19 step:18052 [D loss: 0.604856, acc.: 64.06%] [G loss: 1.114823]\n",
      "epoch:19 step:18053 [D loss: 0.721358, acc.: 53.91%] [G loss: 0.698961]\n",
      "epoch:19 step:18054 [D loss: 0.521778, acc.: 77.34%] [G loss: 0.981043]\n",
      "epoch:19 step:18055 [D loss: 0.561459, acc.: 78.91%] [G loss: 0.975491]\n",
      "epoch:19 step:18056 [D loss: 0.963091, acc.: 37.50%] [G loss: 1.065842]\n",
      "epoch:19 step:18057 [D loss: 0.469930, acc.: 86.72%] [G loss: 1.026430]\n",
      "epoch:19 step:18058 [D loss: 0.370317, acc.: 87.50%] [G loss: 1.188583]\n",
      "epoch:19 step:18059 [D loss: 0.214402, acc.: 92.97%] [G loss: 1.248248]\n",
      "epoch:19 step:18060 [D loss: 0.418453, acc.: 84.38%] [G loss: 1.246974]\n",
      "epoch:19 step:18061 [D loss: 0.677268, acc.: 58.59%] [G loss: 0.760973]\n",
      "epoch:19 step:18062 [D loss: 0.448003, acc.: 69.53%] [G loss: 1.223094]\n",
      "epoch:19 step:18063 [D loss: 0.193767, acc.: 96.09%] [G loss: 1.309511]\n",
      "epoch:19 step:18064 [D loss: 0.242689, acc.: 96.09%] [G loss: 1.525822]\n",
      "epoch:19 step:18065 [D loss: 0.594089, acc.: 64.06%] [G loss: 1.705573]\n",
      "epoch:19 step:18066 [D loss: 0.934660, acc.: 40.62%] [G loss: 0.667456]\n",
      "epoch:19 step:18067 [D loss: 0.725156, acc.: 60.16%] [G loss: 1.270236]\n",
      "epoch:19 step:18068 [D loss: 0.388920, acc.: 87.50%] [G loss: 1.175400]\n",
      "epoch:19 step:18069 [D loss: 0.642583, acc.: 62.50%] [G loss: 1.465678]\n",
      "epoch:19 step:18070 [D loss: 0.614523, acc.: 64.84%] [G loss: 0.985563]\n",
      "epoch:19 step:18071 [D loss: 0.711347, acc.: 57.81%] [G loss: 1.276064]\n",
      "epoch:19 step:18072 [D loss: 0.552637, acc.: 71.09%] [G loss: 0.744592]\n",
      "epoch:19 step:18073 [D loss: 0.754221, acc.: 46.88%] [G loss: 1.274228]\n",
      "epoch:19 step:18074 [D loss: 0.711001, acc.: 53.12%] [G loss: 1.275508]\n",
      "epoch:19 step:18075 [D loss: 0.759603, acc.: 50.78%] [G loss: 1.095032]\n",
      "epoch:19 step:18076 [D loss: 0.476368, acc.: 79.69%] [G loss: 1.130880]\n",
      "epoch:19 step:18077 [D loss: 0.498845, acc.: 75.00%] [G loss: 1.315062]\n",
      "epoch:19 step:18078 [D loss: 0.530370, acc.: 79.69%] [G loss: 1.267098]\n",
      "epoch:19 step:18079 [D loss: 0.513903, acc.: 71.09%] [G loss: 1.486456]\n",
      "epoch:19 step:18080 [D loss: 0.586537, acc.: 68.75%] [G loss: 1.599951]\n",
      "epoch:19 step:18081 [D loss: 0.410820, acc.: 85.16%] [G loss: 1.157279]\n",
      "epoch:19 step:18082 [D loss: 0.229991, acc.: 92.97%] [G loss: 1.368769]\n",
      "epoch:19 step:18083 [D loss: 0.813809, acc.: 48.44%] [G loss: 1.162477]\n",
      "epoch:19 step:18084 [D loss: 0.692845, acc.: 58.59%] [G loss: 1.140569]\n",
      "epoch:19 step:18085 [D loss: 0.483823, acc.: 77.34%] [G loss: 1.081174]\n",
      "epoch:19 step:18086 [D loss: 0.660288, acc.: 60.16%] [G loss: 1.059359]\n",
      "epoch:19 step:18087 [D loss: 0.749445, acc.: 49.22%] [G loss: 1.152584]\n",
      "epoch:19 step:18088 [D loss: 0.644073, acc.: 66.41%] [G loss: 0.960104]\n",
      "epoch:19 step:18089 [D loss: 0.541953, acc.: 77.34%] [G loss: 0.851515]\n",
      "epoch:19 step:18090 [D loss: 0.276723, acc.: 92.19%] [G loss: 0.858666]\n",
      "epoch:19 step:18091 [D loss: 0.338835, acc.: 94.53%] [G loss: 1.270687]\n",
      "epoch:19 step:18092 [D loss: 0.256843, acc.: 91.41%] [G loss: 0.887983]\n",
      "epoch:19 step:18093 [D loss: 0.238834, acc.: 92.19%] [G loss: 1.330097]\n",
      "epoch:19 step:18094 [D loss: 1.037693, acc.: 32.03%] [G loss: 1.158542]\n",
      "epoch:19 step:18095 [D loss: 0.737689, acc.: 59.38%] [G loss: 1.728378]\n",
      "epoch:19 step:18096 [D loss: 0.319335, acc.: 90.62%] [G loss: 2.046929]\n",
      "epoch:19 step:18097 [D loss: 0.827643, acc.: 58.59%] [G loss: 1.523646]\n",
      "epoch:19 step:18098 [D loss: 0.778538, acc.: 49.22%] [G loss: 0.597530]\n",
      "epoch:19 step:18099 [D loss: 0.640760, acc.: 61.72%] [G loss: 1.429216]\n",
      "epoch:19 step:18100 [D loss: 0.705372, acc.: 63.28%] [G loss: 1.515157]\n",
      "epoch:19 step:18101 [D loss: 0.355844, acc.: 92.97%] [G loss: 1.651089]\n",
      "epoch:19 step:18102 [D loss: 0.633136, acc.: 69.53%] [G loss: 1.853117]\n",
      "epoch:19 step:18103 [D loss: 0.402661, acc.: 82.81%] [G loss: 1.592098]\n",
      "epoch:19 step:18104 [D loss: 0.706491, acc.: 62.50%] [G loss: 1.681241]\n",
      "epoch:19 step:18105 [D loss: 0.632636, acc.: 66.41%] [G loss: 2.091474]\n",
      "epoch:19 step:18106 [D loss: 0.473731, acc.: 79.69%] [G loss: 1.471139]\n",
      "epoch:19 step:18107 [D loss: 0.671466, acc.: 60.94%] [G loss: 1.239922]\n",
      "epoch:19 step:18108 [D loss: 0.654438, acc.: 64.84%] [G loss: 1.111267]\n",
      "epoch:19 step:18109 [D loss: 0.629946, acc.: 66.41%] [G loss: 1.061628]\n",
      "epoch:19 step:18110 [D loss: 0.324750, acc.: 92.19%] [G loss: 1.278502]\n",
      "epoch:19 step:18111 [D loss: 0.953790, acc.: 34.38%] [G loss: 1.179378]\n",
      "epoch:19 step:18112 [D loss: 0.680778, acc.: 65.62%] [G loss: 0.668991]\n",
      "epoch:19 step:18113 [D loss: 0.832920, acc.: 43.75%] [G loss: 1.158234]\n",
      "epoch:19 step:18114 [D loss: 0.732829, acc.: 46.88%] [G loss: 1.008888]\n",
      "epoch:19 step:18115 [D loss: 0.539540, acc.: 78.12%] [G loss: 1.025071]\n",
      "epoch:19 step:18116 [D loss: 0.375398, acc.: 83.59%] [G loss: 1.148263]\n",
      "epoch:19 step:18117 [D loss: 0.333589, acc.: 86.72%] [G loss: 0.802544]\n",
      "epoch:19 step:18118 [D loss: 0.680752, acc.: 64.84%] [G loss: 1.265578]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:19 step:18119 [D loss: 0.447840, acc.: 79.69%] [G loss: 1.195986]\n",
      "epoch:19 step:18120 [D loss: 0.519317, acc.: 77.34%] [G loss: 1.328849]\n",
      "epoch:19 step:18121 [D loss: 0.382810, acc.: 91.41%] [G loss: 1.117376]\n",
      "epoch:19 step:18122 [D loss: 0.618800, acc.: 67.97%] [G loss: 0.941903]\n",
      "epoch:19 step:18123 [D loss: 0.519299, acc.: 67.97%] [G loss: 0.884872]\n",
      "epoch:19 step:18124 [D loss: 0.558348, acc.: 67.97%] [G loss: 1.453089]\n",
      "epoch:19 step:18125 [D loss: 0.509222, acc.: 75.00%] [G loss: 1.622488]\n",
      "epoch:19 step:18126 [D loss: 0.873746, acc.: 42.97%] [G loss: 1.106340]\n",
      "epoch:19 step:18127 [D loss: 0.777505, acc.: 47.66%] [G loss: 1.035954]\n",
      "epoch:19 step:18128 [D loss: 0.598825, acc.: 67.97%] [G loss: 1.163030]\n",
      "epoch:19 step:18129 [D loss: 0.659011, acc.: 60.16%] [G loss: 1.223780]\n",
      "epoch:19 step:18130 [D loss: 0.261981, acc.: 96.09%] [G loss: 1.190420]\n",
      "epoch:19 step:18131 [D loss: 0.271380, acc.: 93.75%] [G loss: 1.458589]\n",
      "epoch:19 step:18132 [D loss: 0.613144, acc.: 64.84%] [G loss: 1.292906]\n",
      "epoch:19 step:18133 [D loss: 0.845573, acc.: 47.66%] [G loss: 0.917478]\n",
      "epoch:19 step:18134 [D loss: 0.691905, acc.: 58.59%] [G loss: 0.995349]\n",
      "epoch:19 step:18135 [D loss: 0.884667, acc.: 37.50%] [G loss: 1.067103]\n",
      "epoch:19 step:18136 [D loss: 0.642763, acc.: 60.94%] [G loss: 1.245467]\n",
      "epoch:19 step:18137 [D loss: 0.452474, acc.: 81.25%] [G loss: 1.461714]\n",
      "epoch:19 step:18138 [D loss: 0.651605, acc.: 66.41%] [G loss: 1.163446]\n",
      "epoch:19 step:18139 [D loss: 0.349168, acc.: 86.72%] [G loss: 0.994859]\n",
      "epoch:19 step:18140 [D loss: 0.536456, acc.: 72.66%] [G loss: 1.104866]\n",
      "epoch:19 step:18141 [D loss: 0.605340, acc.: 67.19%] [G loss: 1.151803]\n",
      "epoch:19 step:18142 [D loss: 0.597477, acc.: 68.75%] [G loss: 1.376202]\n",
      "epoch:19 step:18143 [D loss: 0.752220, acc.: 53.91%] [G loss: 1.116440]\n",
      "epoch:19 step:18144 [D loss: 0.764644, acc.: 46.09%] [G loss: 0.846674]\n",
      "epoch:19 step:18145 [D loss: 0.530515, acc.: 70.31%] [G loss: 1.149355]\n",
      "epoch:19 step:18146 [D loss: 0.270426, acc.: 87.50%] [G loss: 1.157726]\n",
      "epoch:19 step:18147 [D loss: 0.247794, acc.: 95.31%] [G loss: 1.576417]\n",
      "epoch:19 step:18148 [D loss: 0.457885, acc.: 76.56%] [G loss: 1.508160]\n",
      "epoch:19 step:18149 [D loss: 0.165856, acc.: 98.44%] [G loss: 1.618997]\n",
      "epoch:19 step:18150 [D loss: 0.231487, acc.: 92.97%] [G loss: 1.793438]\n",
      "epoch:19 step:18151 [D loss: 0.729509, acc.: 57.03%] [G loss: 1.611828]\n",
      "epoch:19 step:18152 [D loss: 0.747050, acc.: 53.91%] [G loss: 1.364762]\n",
      "epoch:19 step:18153 [D loss: 0.528101, acc.: 75.00%] [G loss: 1.280241]\n",
      "epoch:19 step:18154 [D loss: 0.654021, acc.: 64.84%] [G loss: 1.116480]\n",
      "epoch:19 step:18155 [D loss: 0.669574, acc.: 62.50%] [G loss: 0.873783]\n",
      "epoch:19 step:18156 [D loss: 0.585354, acc.: 69.53%] [G loss: 1.039582]\n",
      "epoch:19 step:18157 [D loss: 0.636571, acc.: 59.38%] [G loss: 1.054146]\n",
      "epoch:19 step:18158 [D loss: 0.751268, acc.: 51.56%] [G loss: 0.840027]\n",
      "epoch:19 step:18159 [D loss: 0.671026, acc.: 59.38%] [G loss: 1.178054]\n",
      "epoch:19 step:18160 [D loss: 0.607821, acc.: 70.31%] [G loss: 1.119000]\n",
      "epoch:19 step:18161 [D loss: 0.526415, acc.: 72.66%] [G loss: 0.892969]\n",
      "epoch:19 step:18162 [D loss: 0.460994, acc.: 85.16%] [G loss: 1.138910]\n",
      "epoch:19 step:18163 [D loss: 0.588277, acc.: 64.84%] [G loss: 0.912500]\n",
      "epoch:19 step:18164 [D loss: 0.764445, acc.: 53.91%] [G loss: 1.158725]\n",
      "epoch:19 step:18165 [D loss: 0.554304, acc.: 71.88%] [G loss: 0.729355]\n",
      "epoch:19 step:18166 [D loss: 0.508831, acc.: 78.12%] [G loss: 1.194238]\n",
      "epoch:19 step:18167 [D loss: 0.598606, acc.: 70.31%] [G loss: 0.775683]\n",
      "epoch:19 step:18168 [D loss: 0.374769, acc.: 86.72%] [G loss: 0.998010]\n",
      "epoch:19 step:18169 [D loss: 0.265226, acc.: 91.41%] [G loss: 1.195640]\n",
      "epoch:19 step:18170 [D loss: 0.577051, acc.: 69.53%] [G loss: 1.326086]\n",
      "epoch:19 step:18171 [D loss: 0.735932, acc.: 53.12%] [G loss: 0.614599]\n",
      "epoch:19 step:18172 [D loss: 1.688138, acc.: 32.81%] [G loss: 1.397922]\n",
      "epoch:19 step:18173 [D loss: 0.426969, acc.: 88.28%] [G loss: 1.166338]\n",
      "epoch:19 step:18174 [D loss: 0.509841, acc.: 78.91%] [G loss: 1.429460]\n",
      "epoch:19 step:18175 [D loss: 0.685436, acc.: 59.38%] [G loss: 1.295393]\n",
      "epoch:19 step:18176 [D loss: 0.926905, acc.: 40.62%] [G loss: 1.317128]\n",
      "epoch:19 step:18177 [D loss: 0.790860, acc.: 45.31%] [G loss: 1.278395]\n",
      "epoch:19 step:18178 [D loss: 0.656209, acc.: 61.72%] [G loss: 1.133202]\n",
      "epoch:19 step:18179 [D loss: 0.707506, acc.: 53.91%] [G loss: 0.766376]\n",
      "epoch:19 step:18180 [D loss: 0.513089, acc.: 74.22%] [G loss: 1.186209]\n",
      "epoch:19 step:18181 [D loss: 0.544974, acc.: 67.97%] [G loss: 1.116683]\n",
      "epoch:19 step:18182 [D loss: 0.650392, acc.: 68.75%] [G loss: 1.090724]\n",
      "epoch:19 step:18183 [D loss: 0.526153, acc.: 72.66%] [G loss: 0.825000]\n",
      "epoch:19 step:18184 [D loss: 0.454166, acc.: 82.81%] [G loss: 0.898285]\n",
      "epoch:19 step:18185 [D loss: 0.651662, acc.: 61.72%] [G loss: 0.891116]\n",
      "epoch:19 step:18186 [D loss: 0.792299, acc.: 41.41%] [G loss: 1.213917]\n",
      "epoch:19 step:18187 [D loss: 0.633406, acc.: 62.50%] [G loss: 1.015565]\n",
      "epoch:19 step:18188 [D loss: 0.671821, acc.: 56.25%] [G loss: 1.135886]\n",
      "epoch:19 step:18189 [D loss: 0.672975, acc.: 59.38%] [G loss: 0.860153]\n",
      "epoch:19 step:18190 [D loss: 0.692889, acc.: 57.81%] [G loss: 0.986650]\n",
      "epoch:19 step:18191 [D loss: 0.518744, acc.: 77.34%] [G loss: 1.024236]\n",
      "epoch:19 step:18192 [D loss: 0.615203, acc.: 64.06%] [G loss: 0.800056]\n",
      "epoch:19 step:18193 [D loss: 0.582533, acc.: 73.44%] [G loss: 0.813324]\n",
      "epoch:19 step:18194 [D loss: 0.736307, acc.: 46.09%] [G loss: 1.083653]\n",
      "epoch:19 step:18195 [D loss: 0.813809, acc.: 42.19%] [G loss: 0.881297]\n",
      "epoch:19 step:18196 [D loss: 0.497357, acc.: 77.34%] [G loss: 1.018720]\n",
      "epoch:19 step:18197 [D loss: 0.751183, acc.: 42.19%] [G loss: 0.985448]\n",
      "epoch:19 step:18198 [D loss: 0.794237, acc.: 42.19%] [G loss: 1.004860]\n",
      "epoch:19 step:18199 [D loss: 0.290984, acc.: 89.84%] [G loss: 1.176832]\n",
      "epoch:19 step:18200 [D loss: 0.241772, acc.: 91.41%] [G loss: 1.248186]\n",
      "##############\n",
      "[4.11433264 2.49292859 6.419814   5.78810575 4.51910602 6.19546571\n",
      " 5.45120847 5.80015181 5.66188998 4.85219142]\n",
      "##########\n",
      "epoch:19 step:18201 [D loss: 0.217157, acc.: 96.09%] [G loss: 1.152839]\n",
      "epoch:19 step:18202 [D loss: 0.284225, acc.: 88.28%] [G loss: 1.584529]\n",
      "epoch:19 step:18203 [D loss: 0.324457, acc.: 96.09%] [G loss: 1.473730]\n",
      "epoch:19 step:18204 [D loss: 0.435137, acc.: 86.72%] [G loss: 1.566205]\n",
      "epoch:19 step:18205 [D loss: 0.195279, acc.: 99.22%] [G loss: 1.511693]\n",
      "epoch:19 step:18206 [D loss: 0.371866, acc.: 91.41%] [G loss: 1.551358]\n",
      "epoch:19 step:18207 [D loss: 0.172853, acc.: 99.22%] [G loss: 1.305566]\n",
      "epoch:19 step:18208 [D loss: 0.231347, acc.: 92.19%] [G loss: 1.296563]\n",
      "epoch:19 step:18209 [D loss: 0.164082, acc.: 99.22%] [G loss: 1.760989]\n",
      "epoch:19 step:18210 [D loss: 0.173300, acc.: 97.66%] [G loss: 1.027666]\n",
      "epoch:19 step:18211 [D loss: 0.175060, acc.: 100.00%] [G loss: 1.880278]\n",
      "epoch:19 step:18212 [D loss: 0.154371, acc.: 100.00%] [G loss: 1.204422]\n",
      "epoch:19 step:18213 [D loss: 0.207719, acc.: 98.44%] [G loss: 1.831619]\n",
      "epoch:19 step:18214 [D loss: 1.177668, acc.: 41.41%] [G loss: 0.831231]\n",
      "epoch:19 step:18215 [D loss: 0.256273, acc.: 98.44%] [G loss: 1.043136]\n",
      "epoch:19 step:18216 [D loss: 0.194805, acc.: 99.22%] [G loss: 1.678252]\n",
      "epoch:19 step:18217 [D loss: 0.473856, acc.: 69.53%] [G loss: 1.753437]\n",
      "epoch:19 step:18218 [D loss: 1.163505, acc.: 39.06%] [G loss: 0.623431]\n",
      "epoch:19 step:18219 [D loss: 0.502309, acc.: 76.56%] [G loss: 0.517014]\n",
      "epoch:19 step:18220 [D loss: 0.497805, acc.: 72.66%] [G loss: 1.744840]\n",
      "epoch:19 step:18221 [D loss: 0.371899, acc.: 80.47%] [G loss: 0.683277]\n",
      "epoch:19 step:18222 [D loss: 0.307318, acc.: 84.38%] [G loss: 1.165689]\n",
      "epoch:19 step:18223 [D loss: 1.098616, acc.: 37.50%] [G loss: 2.212276]\n",
      "epoch:19 step:18224 [D loss: 0.984862, acc.: 50.00%] [G loss: 0.631231]\n",
      "epoch:19 step:18225 [D loss: 1.741547, acc.: 6.25%] [G loss: 1.483531]\n",
      "epoch:19 step:18226 [D loss: 1.016751, acc.: 35.94%] [G loss: 1.838432]\n",
      "epoch:19 step:18227 [D loss: 0.809581, acc.: 45.31%] [G loss: 1.214039]\n",
      "epoch:19 step:18228 [D loss: 0.521511, acc.: 75.00%] [G loss: 1.232171]\n",
      "epoch:19 step:18229 [D loss: 1.033660, acc.: 29.69%] [G loss: 1.245984]\n",
      "epoch:19 step:18230 [D loss: 0.831369, acc.: 50.00%] [G loss: 1.427805]\n",
      "epoch:19 step:18231 [D loss: 0.476688, acc.: 78.12%] [G loss: 1.501115]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:19 step:18232 [D loss: 0.621758, acc.: 66.41%] [G loss: 1.271642]\n",
      "epoch:19 step:18233 [D loss: 0.537556, acc.: 69.53%] [G loss: 1.704960]\n",
      "epoch:19 step:18234 [D loss: 0.963329, acc.: 44.53%] [G loss: 1.767770]\n",
      "epoch:19 step:18235 [D loss: 0.914455, acc.: 38.28%] [G loss: 1.911279]\n",
      "epoch:19 step:18236 [D loss: 0.789894, acc.: 46.88%] [G loss: 2.222195]\n",
      "epoch:19 step:18237 [D loss: 0.754613, acc.: 56.25%] [G loss: 1.675255]\n",
      "epoch:19 step:18238 [D loss: 0.595234, acc.: 64.06%] [G loss: 1.842630]\n",
      "epoch:19 step:18239 [D loss: 0.633553, acc.: 66.41%] [G loss: 1.330750]\n",
      "epoch:19 step:18240 [D loss: 0.839205, acc.: 41.41%] [G loss: 1.465791]\n",
      "epoch:19 step:18241 [D loss: 0.692823, acc.: 60.94%] [G loss: 1.529901]\n",
      "epoch:19 step:18242 [D loss: 0.610516, acc.: 66.41%] [G loss: 1.486851]\n",
      "epoch:19 step:18243 [D loss: 0.608102, acc.: 68.75%] [G loss: 1.549780]\n",
      "epoch:19 step:18244 [D loss: 0.504036, acc.: 71.09%] [G loss: 1.525887]\n",
      "epoch:19 step:18245 [D loss: 0.605822, acc.: 70.31%] [G loss: 1.449759]\n",
      "epoch:19 step:18246 [D loss: 0.623833, acc.: 62.50%] [G loss: 1.453068]\n",
      "epoch:19 step:18247 [D loss: 0.497300, acc.: 75.78%] [G loss: 1.535243]\n",
      "epoch:19 step:18248 [D loss: 0.640506, acc.: 64.06%] [G loss: 1.100492]\n",
      "epoch:19 step:18249 [D loss: 0.565105, acc.: 71.09%] [G loss: 1.435215]\n",
      "epoch:19 step:18250 [D loss: 0.607616, acc.: 65.62%] [G loss: 1.772747]\n",
      "epoch:19 step:18251 [D loss: 0.557293, acc.: 67.19%] [G loss: 1.031593]\n",
      "epoch:19 step:18252 [D loss: 0.303300, acc.: 93.75%] [G loss: 1.398729]\n",
      "epoch:19 step:18253 [D loss: 0.372577, acc.: 87.50%] [G loss: 1.387401]\n",
      "epoch:19 step:18254 [D loss: 0.279561, acc.: 95.31%] [G loss: 1.653285]\n",
      "epoch:19 step:18255 [D loss: 0.355846, acc.: 90.62%] [G loss: 1.481370]\n",
      "epoch:19 step:18256 [D loss: 0.359929, acc.: 95.31%] [G loss: 2.550341]\n",
      "epoch:19 step:18257 [D loss: 0.344136, acc.: 91.41%] [G loss: 0.962230]\n",
      "epoch:19 step:18258 [D loss: 0.449789, acc.: 83.59%] [G loss: 1.689398]\n",
      "epoch:19 step:18259 [D loss: 0.334671, acc.: 89.84%] [G loss: 1.193848]\n",
      "epoch:19 step:18260 [D loss: 0.310625, acc.: 94.53%] [G loss: 1.279418]\n",
      "epoch:19 step:18261 [D loss: 0.693864, acc.: 59.38%] [G loss: 1.272429]\n",
      "epoch:19 step:18262 [D loss: 0.586923, acc.: 70.31%] [G loss: 1.248531]\n",
      "epoch:19 step:18263 [D loss: 0.772184, acc.: 50.00%] [G loss: 0.712358]\n",
      "epoch:19 step:18264 [D loss: 1.293342, acc.: 10.94%] [G loss: 0.776737]\n",
      "epoch:19 step:18265 [D loss: 1.033508, acc.: 35.16%] [G loss: 0.800899]\n",
      "epoch:19 step:18266 [D loss: 0.778411, acc.: 51.56%] [G loss: 0.763846]\n",
      "epoch:19 step:18267 [D loss: 0.699032, acc.: 56.25%] [G loss: 0.841697]\n",
      "epoch:19 step:18268 [D loss: 0.490720, acc.: 72.66%] [G loss: 0.855433]\n",
      "epoch:19 step:18269 [D loss: 0.554885, acc.: 66.41%] [G loss: 0.674169]\n",
      "epoch:19 step:18270 [D loss: 0.430689, acc.: 89.06%] [G loss: 0.992912]\n",
      "epoch:19 step:18271 [D loss: 0.327979, acc.: 91.41%] [G loss: 0.927957]\n",
      "epoch:19 step:18272 [D loss: 0.403837, acc.: 82.03%] [G loss: 1.031879]\n",
      "epoch:19 step:18273 [D loss: 0.420962, acc.: 79.69%] [G loss: 1.251873]\n",
      "epoch:19 step:18274 [D loss: 0.345299, acc.: 86.72%] [G loss: 1.145455]\n",
      "epoch:19 step:18275 [D loss: 0.611070, acc.: 66.41%] [G loss: 1.224689]\n",
      "epoch:19 step:18276 [D loss: 1.079006, acc.: 53.91%] [G loss: 1.103655]\n",
      "epoch:19 step:18277 [D loss: 0.524665, acc.: 74.22%] [G loss: 1.312970]\n",
      "epoch:19 step:18278 [D loss: 0.645660, acc.: 66.41%] [G loss: 1.271541]\n",
      "epoch:19 step:18279 [D loss: 0.766345, acc.: 52.34%] [G loss: 1.150676]\n",
      "epoch:19 step:18280 [D loss: 0.699675, acc.: 60.94%] [G loss: 0.711752]\n",
      "epoch:19 step:18281 [D loss: 0.660677, acc.: 61.72%] [G loss: 0.832175]\n",
      "epoch:19 step:18282 [D loss: 0.481937, acc.: 75.78%] [G loss: 0.892932]\n",
      "epoch:19 step:18283 [D loss: 0.508113, acc.: 72.66%] [G loss: 0.855576]\n",
      "epoch:19 step:18284 [D loss: 0.437626, acc.: 79.69%] [G loss: 1.274874]\n",
      "epoch:19 step:18285 [D loss: 0.801449, acc.: 51.56%] [G loss: 1.117524]\n",
      "epoch:19 step:18286 [D loss: 0.602443, acc.: 67.97%] [G loss: 1.117734]\n",
      "epoch:19 step:18287 [D loss: 0.322290, acc.: 92.19%] [G loss: 1.281242]\n",
      "epoch:19 step:18288 [D loss: 0.586494, acc.: 74.22%] [G loss: 1.208887]\n",
      "epoch:19 step:18289 [D loss: 0.738581, acc.: 51.56%] [G loss: 1.115317]\n",
      "epoch:19 step:18290 [D loss: 0.520498, acc.: 80.47%] [G loss: 1.281141]\n",
      "epoch:19 step:18291 [D loss: 0.539505, acc.: 71.09%] [G loss: 1.344390]\n",
      "epoch:19 step:18292 [D loss: 0.731426, acc.: 54.69%] [G loss: 1.225621]\n",
      "epoch:19 step:18293 [D loss: 0.621813, acc.: 67.19%] [G loss: 1.133830]\n",
      "epoch:19 step:18294 [D loss: 0.787198, acc.: 45.31%] [G loss: 1.023710]\n",
      "epoch:19 step:18295 [D loss: 0.664656, acc.: 59.38%] [G loss: 1.078790]\n",
      "epoch:19 step:18296 [D loss: 0.726798, acc.: 51.56%] [G loss: 1.038010]\n",
      "epoch:19 step:18297 [D loss: 0.706859, acc.: 61.72%] [G loss: 1.075665]\n",
      "epoch:19 step:18298 [D loss: 0.630050, acc.: 64.06%] [G loss: 1.091805]\n",
      "epoch:19 step:18299 [D loss: 0.602197, acc.: 68.75%] [G loss: 1.162637]\n",
      "epoch:19 step:18300 [D loss: 0.333313, acc.: 92.97%] [G loss: 1.100011]\n",
      "epoch:19 step:18301 [D loss: 0.243919, acc.: 92.97%] [G loss: 1.451086]\n",
      "epoch:19 step:18302 [D loss: 0.186687, acc.: 93.75%] [G loss: 1.662949]\n",
      "epoch:19 step:18303 [D loss: 0.602075, acc.: 64.06%] [G loss: 1.437067]\n",
      "epoch:19 step:18304 [D loss: 0.601595, acc.: 64.84%] [G loss: 1.386569]\n",
      "epoch:19 step:18305 [D loss: 0.648775, acc.: 61.72%] [G loss: 1.209882]\n",
      "epoch:19 step:18306 [D loss: 0.634836, acc.: 60.94%] [G loss: 1.335958]\n",
      "epoch:19 step:18307 [D loss: 0.443639, acc.: 84.38%] [G loss: 1.287952]\n",
      "epoch:19 step:18308 [D loss: 0.588718, acc.: 66.41%] [G loss: 0.820141]\n",
      "epoch:19 step:18309 [D loss: 0.713167, acc.: 51.56%] [G loss: 1.017552]\n",
      "epoch:19 step:18310 [D loss: 0.557326, acc.: 64.84%] [G loss: 0.687464]\n",
      "epoch:19 step:18311 [D loss: 0.557295, acc.: 70.31%] [G loss: 0.910608]\n",
      "epoch:19 step:18312 [D loss: 0.687750, acc.: 53.12%] [G loss: 1.147188]\n",
      "epoch:19 step:18313 [D loss: 0.435132, acc.: 76.56%] [G loss: 1.181788]\n",
      "epoch:19 step:18314 [D loss: 0.308102, acc.: 92.19%] [G loss: 1.408060]\n",
      "epoch:19 step:18315 [D loss: 0.281102, acc.: 96.09%] [G loss: 1.222302]\n",
      "epoch:19 step:18316 [D loss: 0.243482, acc.: 93.75%] [G loss: 1.394518]\n",
      "epoch:19 step:18317 [D loss: 0.426168, acc.: 79.69%] [G loss: 1.375942]\n",
      "epoch:19 step:18318 [D loss: 0.299935, acc.: 95.31%] [G loss: 1.469250]\n",
      "epoch:19 step:18319 [D loss: 0.520821, acc.: 76.56%] [G loss: 1.527630]\n",
      "epoch:19 step:18320 [D loss: 0.466265, acc.: 79.69%] [G loss: 1.442745]\n",
      "epoch:19 step:18321 [D loss: 0.756569, acc.: 49.22%] [G loss: 1.110478]\n",
      "epoch:19 step:18322 [D loss: 0.633974, acc.: 63.28%] [G loss: 1.225032]\n",
      "epoch:19 step:18323 [D loss: 0.604069, acc.: 68.75%] [G loss: 1.178359]\n",
      "epoch:19 step:18324 [D loss: 0.583733, acc.: 64.06%] [G loss: 1.015989]\n",
      "epoch:19 step:18325 [D loss: 0.668869, acc.: 60.16%] [G loss: 0.928894]\n",
      "epoch:19 step:18326 [D loss: 0.627606, acc.: 64.84%] [G loss: 1.155815]\n",
      "epoch:19 step:18327 [D loss: 0.347237, acc.: 85.94%] [G loss: 0.997019]\n",
      "epoch:19 step:18328 [D loss: 0.744939, acc.: 47.66%] [G loss: 1.262378]\n",
      "epoch:19 step:18329 [D loss: 0.524653, acc.: 75.78%] [G loss: 1.007077]\n",
      "epoch:19 step:18330 [D loss: 0.258679, acc.: 89.84%] [G loss: 1.381611]\n",
      "epoch:19 step:18331 [D loss: 0.497181, acc.: 78.91%] [G loss: 1.239648]\n",
      "epoch:19 step:18332 [D loss: 0.498380, acc.: 78.12%] [G loss: 1.149548]\n",
      "epoch:19 step:18333 [D loss: 0.350852, acc.: 89.06%] [G loss: 1.242620]\n",
      "epoch:19 step:18334 [D loss: 0.715408, acc.: 53.91%] [G loss: 1.133082]\n",
      "epoch:19 step:18335 [D loss: 0.673683, acc.: 57.03%] [G loss: 0.978474]\n",
      "epoch:19 step:18336 [D loss: 0.515261, acc.: 76.56%] [G loss: 0.957636]\n",
      "epoch:19 step:18337 [D loss: 0.596153, acc.: 66.41%] [G loss: 1.122772]\n",
      "epoch:19 step:18338 [D loss: 0.331141, acc.: 83.59%] [G loss: 1.386309]\n",
      "epoch:19 step:18339 [D loss: 0.185035, acc.: 96.88%] [G loss: 2.160093]\n",
      "epoch:19 step:18340 [D loss: 0.256893, acc.: 94.53%] [G loss: 1.396966]\n",
      "epoch:19 step:18341 [D loss: 0.324085, acc.: 92.97%] [G loss: 1.574371]\n",
      "epoch:19 step:18342 [D loss: 0.359929, acc.: 92.19%] [G loss: 1.418163]\n",
      "epoch:19 step:18343 [D loss: 0.450229, acc.: 82.81%] [G loss: 1.426558]\n",
      "epoch:19 step:18344 [D loss: 0.281799, acc.: 93.75%] [G loss: 1.463596]\n",
      "epoch:19 step:18345 [D loss: 0.744732, acc.: 52.34%] [G loss: 1.268453]\n",
      "epoch:19 step:18346 [D loss: 0.491681, acc.: 77.34%] [G loss: 0.930156]\n",
      "epoch:19 step:18347 [D loss: 0.651235, acc.: 64.06%] [G loss: 1.255478]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:19 step:18348 [D loss: 0.614287, acc.: 67.19%] [G loss: 1.218952]\n",
      "epoch:19 step:18349 [D loss: 0.718200, acc.: 56.25%] [G loss: 1.146553]\n",
      "epoch:19 step:18350 [D loss: 0.561857, acc.: 69.53%] [G loss: 0.955686]\n",
      "epoch:19 step:18351 [D loss: 0.486147, acc.: 78.91%] [G loss: 1.207416]\n",
      "epoch:19 step:18352 [D loss: 0.504122, acc.: 72.66%] [G loss: 1.226907]\n",
      "epoch:19 step:18353 [D loss: 0.366209, acc.: 88.28%] [G loss: 1.514271]\n",
      "epoch:19 step:18354 [D loss: 0.707048, acc.: 57.81%] [G loss: 1.488633]\n",
      "epoch:19 step:18355 [D loss: 0.497031, acc.: 76.56%] [G loss: 1.314662]\n",
      "epoch:19 step:18356 [D loss: 1.061821, acc.: 38.28%] [G loss: 0.781066]\n",
      "epoch:19 step:18357 [D loss: 0.329666, acc.: 92.19%] [G loss: 1.555277]\n",
      "epoch:19 step:18358 [D loss: 0.573784, acc.: 71.88%] [G loss: 1.233107]\n",
      "epoch:19 step:18359 [D loss: 0.363462, acc.: 89.06%] [G loss: 1.206667]\n",
      "epoch:19 step:18360 [D loss: 0.456065, acc.: 83.59%] [G loss: 1.333755]\n",
      "epoch:19 step:18361 [D loss: 0.512414, acc.: 76.56%] [G loss: 1.045875]\n",
      "epoch:19 step:18362 [D loss: 0.235930, acc.: 95.31%] [G loss: 1.525527]\n",
      "epoch:19 step:18363 [D loss: 0.514758, acc.: 71.09%] [G loss: 1.304355]\n",
      "epoch:19 step:18364 [D loss: 0.186403, acc.: 95.31%] [G loss: 1.918888]\n",
      "epoch:19 step:18365 [D loss: 0.654154, acc.: 64.06%] [G loss: 1.689878]\n",
      "epoch:19 step:18366 [D loss: 0.641992, acc.: 67.19%] [G loss: 1.003138]\n",
      "epoch:19 step:18367 [D loss: 0.631872, acc.: 63.28%] [G loss: 0.763099]\n",
      "epoch:19 step:18368 [D loss: 0.499160, acc.: 78.91%] [G loss: 1.122477]\n",
      "epoch:19 step:18369 [D loss: 0.459024, acc.: 71.09%] [G loss: 1.380616]\n",
      "epoch:19 step:18370 [D loss: 0.180599, acc.: 96.88%] [G loss: 1.299532]\n",
      "epoch:19 step:18371 [D loss: 0.169789, acc.: 98.44%] [G loss: 1.959090]\n",
      "epoch:19 step:18372 [D loss: 0.556554, acc.: 71.88%] [G loss: 1.698339]\n",
      "epoch:19 step:18373 [D loss: 0.342078, acc.: 89.06%] [G loss: 1.712964]\n",
      "epoch:19 step:18374 [D loss: 0.510390, acc.: 79.69%] [G loss: 1.539861]\n",
      "epoch:19 step:18375 [D loss: 0.470758, acc.: 82.03%] [G loss: 1.745052]\n",
      "epoch:19 step:18376 [D loss: 0.401514, acc.: 87.50%] [G loss: 1.760897]\n",
      "epoch:19 step:18377 [D loss: 0.495401, acc.: 75.78%] [G loss: 1.019232]\n",
      "epoch:19 step:18378 [D loss: 0.418373, acc.: 83.59%] [G loss: 1.722886]\n",
      "epoch:19 step:18379 [D loss: 0.278576, acc.: 97.66%] [G loss: 2.264163]\n",
      "epoch:19 step:18380 [D loss: 0.270890, acc.: 88.28%] [G loss: 2.138910]\n",
      "epoch:19 step:18381 [D loss: 0.270428, acc.: 87.50%] [G loss: 2.499008]\n",
      "epoch:19 step:18382 [D loss: 0.120383, acc.: 99.22%] [G loss: 2.439461]\n",
      "epoch:19 step:18383 [D loss: 1.498862, acc.: 18.75%] [G loss: 2.251708]\n",
      "epoch:19 step:18384 [D loss: 0.976200, acc.: 48.44%] [G loss: 2.111025]\n",
      "epoch:19 step:18385 [D loss: 0.822582, acc.: 57.81%] [G loss: 1.672624]\n",
      "epoch:19 step:18386 [D loss: 0.949119, acc.: 47.66%] [G loss: 1.172379]\n",
      "epoch:19 step:18387 [D loss: 0.815110, acc.: 45.31%] [G loss: 1.267402]\n",
      "epoch:19 step:18388 [D loss: 0.811280, acc.: 51.56%] [G loss: 1.062828]\n",
      "epoch:19 step:18389 [D loss: 0.743141, acc.: 50.00%] [G loss: 1.111979]\n",
      "epoch:19 step:18390 [D loss: 0.334601, acc.: 82.03%] [G loss: 0.864044]\n",
      "epoch:19 step:18391 [D loss: 0.234087, acc.: 91.41%] [G loss: 1.219187]\n",
      "epoch:19 step:18392 [D loss: 0.657584, acc.: 62.50%] [G loss: 1.218758]\n",
      "epoch:19 step:18393 [D loss: 0.665661, acc.: 54.69%] [G loss: 1.315472]\n",
      "epoch:19 step:18394 [D loss: 0.579415, acc.: 68.75%] [G loss: 1.026010]\n",
      "epoch:19 step:18395 [D loss: 0.655619, acc.: 63.28%] [G loss: 1.301445]\n",
      "epoch:19 step:18396 [D loss: 0.686399, acc.: 63.28%] [G loss: 1.224070]\n",
      "epoch:19 step:18397 [D loss: 0.680913, acc.: 54.69%] [G loss: 1.287915]\n",
      "epoch:19 step:18398 [D loss: 0.451407, acc.: 82.81%] [G loss: 1.071230]\n",
      "epoch:19 step:18399 [D loss: 0.628159, acc.: 61.72%] [G loss: 0.839438]\n",
      "epoch:19 step:18400 [D loss: 0.734832, acc.: 52.34%] [G loss: 1.401534]\n",
      "##############\n",
      "[4.00412716 2.5813604  7.00690145 5.77559887 4.9730192  6.06754554\n",
      " 5.07699683 5.9664524  5.77957684 5.10080506]\n",
      "##########\n",
      "epoch:19 step:18401 [D loss: 0.585040, acc.: 67.19%] [G loss: 1.244018]\n",
      "epoch:19 step:18402 [D loss: 0.900409, acc.: 44.53%] [G loss: 1.177676]\n",
      "epoch:19 step:18403 [D loss: 0.616645, acc.: 61.72%] [G loss: 1.231987]\n",
      "epoch:19 step:18404 [D loss: 0.559010, acc.: 67.97%] [G loss: 1.285352]\n",
      "epoch:19 step:18405 [D loss: 0.733315, acc.: 55.47%] [G loss: 0.875807]\n",
      "epoch:19 step:18406 [D loss: 0.644309, acc.: 66.41%] [G loss: 1.380607]\n",
      "epoch:19 step:18407 [D loss: 0.266334, acc.: 94.53%] [G loss: 2.012935]\n",
      "epoch:19 step:18408 [D loss: 0.355547, acc.: 89.06%] [G loss: 1.848163]\n",
      "epoch:19 step:18409 [D loss: 0.763543, acc.: 57.81%] [G loss: 1.720825]\n",
      "epoch:19 step:18410 [D loss: 0.791208, acc.: 53.12%] [G loss: 1.242666]\n",
      "epoch:19 step:18411 [D loss: 0.754836, acc.: 49.22%] [G loss: 1.382068]\n",
      "epoch:19 step:18412 [D loss: 0.785723, acc.: 47.66%] [G loss: 1.345002]\n",
      "epoch:19 step:18413 [D loss: 0.448748, acc.: 81.25%] [G loss: 1.256213]\n",
      "epoch:19 step:18414 [D loss: 0.747872, acc.: 55.47%] [G loss: 1.395134]\n",
      "epoch:19 step:18415 [D loss: 0.579061, acc.: 71.88%] [G loss: 1.166919]\n",
      "epoch:19 step:18416 [D loss: 0.327517, acc.: 92.19%] [G loss: 1.398423]\n",
      "epoch:19 step:18417 [D loss: 0.476680, acc.: 81.25%] [G loss: 1.068541]\n",
      "epoch:19 step:18418 [D loss: 0.448861, acc.: 78.91%] [G loss: 1.392915]\n",
      "epoch:19 step:18419 [D loss: 0.203648, acc.: 95.31%] [G loss: 1.266214]\n",
      "epoch:19 step:18420 [D loss: 0.237191, acc.: 96.88%] [G loss: 1.424139]\n",
      "epoch:19 step:18421 [D loss: 0.859605, acc.: 54.69%] [G loss: 2.590821]\n",
      "epoch:19 step:18422 [D loss: 0.812766, acc.: 47.66%] [G loss: 1.122710]\n",
      "epoch:19 step:18423 [D loss: 0.754828, acc.: 49.22%] [G loss: 0.957674]\n",
      "epoch:19 step:18424 [D loss: 0.592482, acc.: 68.75%] [G loss: 1.094101]\n",
      "epoch:19 step:18425 [D loss: 0.548284, acc.: 68.75%] [G loss: 1.137155]\n",
      "epoch:19 step:18426 [D loss: 0.618481, acc.: 64.84%] [G loss: 1.090485]\n",
      "epoch:19 step:18427 [D loss: 0.286265, acc.: 95.31%] [G loss: 1.128364]\n",
      "epoch:19 step:18428 [D loss: 0.926350, acc.: 35.16%] [G loss: 1.691749]\n",
      "epoch:19 step:18429 [D loss: 0.622927, acc.: 65.62%] [G loss: 0.858969]\n",
      "epoch:19 step:18430 [D loss: 0.669725, acc.: 56.25%] [G loss: 0.799286]\n",
      "epoch:19 step:18431 [D loss: 0.679776, acc.: 53.12%] [G loss: 0.810317]\n",
      "epoch:19 step:18432 [D loss: 0.457331, acc.: 83.59%] [G loss: 1.407226]\n",
      "epoch:19 step:18433 [D loss: 0.468964, acc.: 81.25%] [G loss: 1.034031]\n",
      "epoch:19 step:18434 [D loss: 0.736944, acc.: 56.25%] [G loss: 1.292382]\n",
      "epoch:19 step:18435 [D loss: 0.508277, acc.: 71.88%] [G loss: 1.236831]\n",
      "epoch:19 step:18436 [D loss: 0.269259, acc.: 93.75%] [G loss: 1.179467]\n",
      "epoch:19 step:18437 [D loss: 0.384704, acc.: 86.72%] [G loss: 1.506087]\n",
      "epoch:19 step:18438 [D loss: 0.458719, acc.: 87.50%] [G loss: 1.244329]\n",
      "epoch:19 step:18439 [D loss: 0.789521, acc.: 52.34%] [G loss: 0.932184]\n",
      "epoch:19 step:18440 [D loss: 0.578945, acc.: 71.09%] [G loss: 1.143931]\n",
      "epoch:19 step:18441 [D loss: 0.736877, acc.: 53.91%] [G loss: 0.768417]\n",
      "epoch:19 step:18442 [D loss: 0.960560, acc.: 41.41%] [G loss: 0.809875]\n",
      "epoch:19 step:18443 [D loss: 0.916367, acc.: 40.62%] [G loss: 1.224190]\n",
      "epoch:19 step:18444 [D loss: 0.587993, acc.: 70.31%] [G loss: 0.936733]\n",
      "epoch:19 step:18445 [D loss: 0.786361, acc.: 47.66%] [G loss: 0.989137]\n",
      "epoch:19 step:18446 [D loss: 0.822043, acc.: 47.66%] [G loss: 0.952726]\n",
      "epoch:19 step:18447 [D loss: 0.526645, acc.: 72.66%] [G loss: 1.317217]\n",
      "epoch:19 step:18448 [D loss: 0.374612, acc.: 89.06%] [G loss: 1.016690]\n",
      "epoch:19 step:18449 [D loss: 0.424657, acc.: 81.25%] [G loss: 0.963023]\n",
      "epoch:19 step:18450 [D loss: 0.487046, acc.: 78.91%] [G loss: 1.301693]\n",
      "epoch:19 step:18451 [D loss: 0.380824, acc.: 85.16%] [G loss: 1.061608]\n",
      "epoch:19 step:18452 [D loss: 0.630736, acc.: 65.62%] [G loss: 0.952513]\n",
      "epoch:19 step:18453 [D loss: 0.237832, acc.: 98.44%] [G loss: 1.157244]\n",
      "epoch:19 step:18454 [D loss: 0.693270, acc.: 56.25%] [G loss: 0.841774]\n",
      "epoch:19 step:18455 [D loss: 0.689991, acc.: 59.38%] [G loss: 1.048029]\n",
      "epoch:19 step:18456 [D loss: 0.763021, acc.: 49.22%] [G loss: 1.147211]\n",
      "epoch:19 step:18457 [D loss: 0.906080, acc.: 39.06%] [G loss: 1.287016]\n",
      "epoch:19 step:18458 [D loss: 0.773255, acc.: 46.88%] [G loss: 1.097368]\n",
      "epoch:19 step:18459 [D loss: 0.746838, acc.: 47.66%] [G loss: 1.227071]\n",
      "epoch:19 step:18460 [D loss: 0.657059, acc.: 61.72%] [G loss: 0.675690]\n",
      "epoch:19 step:18461 [D loss: 0.760076, acc.: 52.34%] [G loss: 0.995553]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:19 step:18462 [D loss: 0.455778, acc.: 83.59%] [G loss: 1.210250]\n",
      "epoch:19 step:18463 [D loss: 0.702703, acc.: 57.03%] [G loss: 0.923140]\n",
      "epoch:19 step:18464 [D loss: 0.711400, acc.: 52.34%] [G loss: 0.888930]\n",
      "epoch:19 step:18465 [D loss: 0.723495, acc.: 52.34%] [G loss: 1.347431]\n",
      "epoch:19 step:18466 [D loss: 0.313691, acc.: 90.62%] [G loss: 1.344005]\n",
      "epoch:19 step:18467 [D loss: 0.277859, acc.: 91.41%] [G loss: 1.369577]\n",
      "epoch:19 step:18468 [D loss: 0.280084, acc.: 90.62%] [G loss: 1.542583]\n",
      "epoch:19 step:18469 [D loss: 0.531432, acc.: 73.44%] [G loss: 1.522192]\n",
      "epoch:19 step:18470 [D loss: 0.517389, acc.: 73.44%] [G loss: 1.524053]\n",
      "epoch:19 step:18471 [D loss: 0.685414, acc.: 57.81%] [G loss: 1.390306]\n",
      "epoch:19 step:18472 [D loss: 0.566271, acc.: 73.44%] [G loss: 1.188089]\n",
      "epoch:19 step:18473 [D loss: 0.537691, acc.: 78.12%] [G loss: 1.260951]\n",
      "epoch:19 step:18474 [D loss: 0.403059, acc.: 87.50%] [G loss: 1.525980]\n",
      "epoch:19 step:18475 [D loss: 0.586038, acc.: 66.41%] [G loss: 1.164217]\n",
      "epoch:19 step:18476 [D loss: 0.674721, acc.: 56.25%] [G loss: 1.077573]\n",
      "epoch:19 step:18477 [D loss: 0.405856, acc.: 83.59%] [G loss: 1.199544]\n",
      "epoch:19 step:18478 [D loss: 0.539794, acc.: 74.22%] [G loss: 1.316029]\n",
      "epoch:19 step:18479 [D loss: 0.488749, acc.: 77.34%] [G loss: 0.982754]\n",
      "epoch:19 step:18480 [D loss: 0.784514, acc.: 51.56%] [G loss: 1.148922]\n",
      "epoch:19 step:18481 [D loss: 0.776928, acc.: 50.78%] [G loss: 0.810837]\n",
      "epoch:19 step:18482 [D loss: 0.546853, acc.: 77.34%] [G loss: 0.867448]\n",
      "epoch:19 step:18483 [D loss: 0.567341, acc.: 71.88%] [G loss: 1.205500]\n",
      "epoch:19 step:18484 [D loss: 0.876971, acc.: 39.06%] [G loss: 0.924300]\n",
      "epoch:19 step:18485 [D loss: 0.343425, acc.: 89.84%] [G loss: 1.099331]\n",
      "epoch:19 step:18486 [D loss: 0.391740, acc.: 88.28%] [G loss: 1.347004]\n",
      "epoch:19 step:18487 [D loss: 0.340961, acc.: 91.41%] [G loss: 0.687219]\n",
      "epoch:19 step:18488 [D loss: 0.386793, acc.: 85.94%] [G loss: 1.020548]\n",
      "epoch:19 step:18489 [D loss: 0.711652, acc.: 61.72%] [G loss: 1.355924]\n",
      "epoch:19 step:18490 [D loss: 0.624652, acc.: 64.06%] [G loss: 1.202746]\n",
      "epoch:19 step:18491 [D loss: 0.685878, acc.: 58.59%] [G loss: 0.652210]\n",
      "epoch:19 step:18492 [D loss: 0.795553, acc.: 51.56%] [G loss: 1.033122]\n",
      "epoch:19 step:18493 [D loss: 0.733317, acc.: 51.56%] [G loss: 0.948464]\n",
      "epoch:19 step:18494 [D loss: 0.738700, acc.: 58.59%] [G loss: 1.003606]\n",
      "epoch:19 step:18495 [D loss: 0.737690, acc.: 51.56%] [G loss: 1.101917]\n",
      "epoch:19 step:18496 [D loss: 0.571117, acc.: 71.88%] [G loss: 1.149357]\n",
      "epoch:19 step:18497 [D loss: 0.603366, acc.: 68.75%] [G loss: 0.968104]\n",
      "epoch:19 step:18498 [D loss: 0.651720, acc.: 67.97%] [G loss: 1.208752]\n",
      "epoch:19 step:18499 [D loss: 0.283950, acc.: 88.28%] [G loss: 1.243479]\n",
      "epoch:19 step:18500 [D loss: 0.240675, acc.: 90.62%] [G loss: 1.327519]\n",
      "epoch:19 step:18501 [D loss: 0.334305, acc.: 91.41%] [G loss: 1.456336]\n",
      "epoch:19 step:18502 [D loss: 0.450304, acc.: 83.59%] [G loss: 1.315549]\n",
      "epoch:19 step:18503 [D loss: 0.207993, acc.: 93.75%] [G loss: 0.474608]\n",
      "epoch:19 step:18504 [D loss: 0.189146, acc.: 95.31%] [G loss: 1.640004]\n",
      "epoch:19 step:18505 [D loss: 0.203939, acc.: 96.88%] [G loss: 1.207178]\n",
      "epoch:19 step:18506 [D loss: 0.916867, acc.: 34.38%] [G loss: 1.557820]\n",
      "epoch:19 step:18507 [D loss: 0.389744, acc.: 86.72%] [G loss: 1.362237]\n",
      "epoch:19 step:18508 [D loss: 0.728265, acc.: 57.03%] [G loss: 0.909754]\n",
      "epoch:19 step:18509 [D loss: 0.218800, acc.: 96.09%] [G loss: 1.500487]\n",
      "epoch:19 step:18510 [D loss: 0.166115, acc.: 99.22%] [G loss: 1.061705]\n",
      "epoch:19 step:18511 [D loss: 0.194634, acc.: 98.44%] [G loss: 1.754171]\n",
      "epoch:19 step:18512 [D loss: 0.321419, acc.: 85.16%] [G loss: 2.021095]\n",
      "epoch:19 step:18513 [D loss: 1.030762, acc.: 49.22%] [G loss: 0.982754]\n",
      "epoch:19 step:18514 [D loss: 0.768940, acc.: 57.81%] [G loss: 1.486537]\n",
      "epoch:19 step:18515 [D loss: 0.739192, acc.: 50.78%] [G loss: 0.919014]\n",
      "epoch:19 step:18516 [D loss: 0.212906, acc.: 96.09%] [G loss: 1.530197]\n",
      "epoch:19 step:18517 [D loss: 0.148968, acc.: 98.44%] [G loss: 1.740800]\n",
      "epoch:19 step:18518 [D loss: 0.762839, acc.: 57.81%] [G loss: 1.498164]\n",
      "epoch:19 step:18519 [D loss: 0.786357, acc.: 53.12%] [G loss: 1.062706]\n",
      "epoch:19 step:18520 [D loss: 0.796835, acc.: 48.44%] [G loss: 0.950766]\n",
      "epoch:19 step:18521 [D loss: 0.666935, acc.: 60.16%] [G loss: 1.053638]\n",
      "epoch:19 step:18522 [D loss: 0.657023, acc.: 61.72%] [G loss: 1.078852]\n",
      "epoch:19 step:18523 [D loss: 0.690621, acc.: 59.38%] [G loss: 1.084252]\n",
      "epoch:19 step:18524 [D loss: 0.691538, acc.: 62.50%] [G loss: 1.154700]\n",
      "epoch:19 step:18525 [D loss: 0.705206, acc.: 57.03%] [G loss: 1.250668]\n",
      "epoch:19 step:18526 [D loss: 0.480010, acc.: 79.69%] [G loss: 1.139302]\n",
      "epoch:19 step:18527 [D loss: 0.704466, acc.: 56.25%] [G loss: 1.231718]\n",
      "epoch:19 step:18528 [D loss: 0.671511, acc.: 57.03%] [G loss: 1.117418]\n",
      "epoch:19 step:18529 [D loss: 0.498010, acc.: 72.66%] [G loss: 1.446280]\n",
      "epoch:19 step:18530 [D loss: 0.585327, acc.: 67.97%] [G loss: 1.498939]\n",
      "epoch:19 step:18531 [D loss: 0.216782, acc.: 95.31%] [G loss: 1.543775]\n",
      "epoch:19 step:18532 [D loss: 0.278286, acc.: 92.97%] [G loss: 0.583966]\n",
      "epoch:19 step:18533 [D loss: 0.203778, acc.: 98.44%] [G loss: 1.502109]\n",
      "epoch:19 step:18534 [D loss: 0.314621, acc.: 90.62%] [G loss: 1.761568]\n",
      "epoch:19 step:18535 [D loss: 0.246579, acc.: 95.31%] [G loss: 1.586147]\n",
      "epoch:19 step:18536 [D loss: 0.238070, acc.: 96.88%] [G loss: 1.419327]\n",
      "epoch:19 step:18537 [D loss: 0.834138, acc.: 42.19%] [G loss: 1.566715]\n",
      "epoch:19 step:18538 [D loss: 0.675941, acc.: 62.50%] [G loss: 0.468819]\n",
      "epoch:19 step:18539 [D loss: 0.756309, acc.: 53.12%] [G loss: 1.233763]\n",
      "epoch:19 step:18540 [D loss: 0.679793, acc.: 56.25%] [G loss: 1.030558]\n",
      "epoch:19 step:18541 [D loss: 1.397417, acc.: 17.97%] [G loss: 1.513359]\n",
      "epoch:19 step:18542 [D loss: 0.476878, acc.: 83.59%] [G loss: 1.477294]\n",
      "epoch:19 step:18543 [D loss: 0.477989, acc.: 82.03%] [G loss: 1.386085]\n",
      "epoch:19 step:18544 [D loss: 0.606697, acc.: 69.53%] [G loss: 1.529741]\n",
      "epoch:19 step:18545 [D loss: 0.331078, acc.: 89.06%] [G loss: 1.723798]\n",
      "epoch:19 step:18546 [D loss: 0.278960, acc.: 92.97%] [G loss: 1.728680]\n",
      "epoch:19 step:18547 [D loss: 0.469664, acc.: 74.22%] [G loss: 1.521341]\n",
      "epoch:19 step:18548 [D loss: 0.754106, acc.: 59.38%] [G loss: 1.603319]\n",
      "epoch:19 step:18549 [D loss: 0.394924, acc.: 87.50%] [G loss: 1.590545]\n",
      "epoch:19 step:18550 [D loss: 0.642006, acc.: 62.50%] [G loss: 1.407581]\n",
      "epoch:19 step:18551 [D loss: 0.934058, acc.: 43.75%] [G loss: 1.058264]\n",
      "epoch:19 step:18552 [D loss: 0.291100, acc.: 92.19%] [G loss: 1.747946]\n",
      "epoch:19 step:18553 [D loss: 0.279812, acc.: 91.41%] [G loss: 1.363436]\n",
      "epoch:19 step:18554 [D loss: 0.717756, acc.: 57.81%] [G loss: 1.177643]\n",
      "epoch:19 step:18555 [D loss: 0.997156, acc.: 47.66%] [G loss: 1.634849]\n",
      "epoch:19 step:18556 [D loss: 0.731247, acc.: 51.56%] [G loss: 1.005543]\n",
      "epoch:19 step:18557 [D loss: 0.791573, acc.: 45.31%] [G loss: 1.078580]\n",
      "epoch:19 step:18558 [D loss: 0.595965, acc.: 67.97%] [G loss: 0.936674]\n",
      "epoch:19 step:18559 [D loss: 0.462363, acc.: 74.22%] [G loss: 0.724717]\n",
      "epoch:19 step:18560 [D loss: 0.641334, acc.: 64.84%] [G loss: 0.866874]\n",
      "epoch:19 step:18561 [D loss: 0.691331, acc.: 56.25%] [G loss: 0.962484]\n",
      "epoch:19 step:18562 [D loss: 0.511864, acc.: 78.91%] [G loss: 1.178141]\n",
      "epoch:19 step:18563 [D loss: 0.717376, acc.: 59.38%] [G loss: 1.125759]\n",
      "epoch:19 step:18564 [D loss: 0.664523, acc.: 57.03%] [G loss: 0.888076]\n",
      "epoch:19 step:18565 [D loss: 0.615661, acc.: 65.62%] [G loss: 0.670416]\n",
      "epoch:19 step:18566 [D loss: 0.654147, acc.: 58.59%] [G loss: 0.971217]\n",
      "epoch:19 step:18567 [D loss: 0.386427, acc.: 84.38%] [G loss: 0.897629]\n",
      "epoch:19 step:18568 [D loss: 0.509304, acc.: 78.91%] [G loss: 1.011526]\n",
      "epoch:19 step:18569 [D loss: 0.577757, acc.: 73.44%] [G loss: 1.095033]\n",
      "epoch:19 step:18570 [D loss: 0.418250, acc.: 85.16%] [G loss: 1.136402]\n",
      "epoch:19 step:18571 [D loss: 0.324248, acc.: 84.38%] [G loss: 1.164479]\n",
      "epoch:19 step:18572 [D loss: 0.319761, acc.: 90.62%] [G loss: 1.158407]\n",
      "epoch:19 step:18573 [D loss: 0.706275, acc.: 61.72%] [G loss: 1.213226]\n",
      "epoch:19 step:18574 [D loss: 0.924203, acc.: 38.28%] [G loss: 1.054809]\n",
      "epoch:19 step:18575 [D loss: 0.877955, acc.: 35.16%] [G loss: 1.076377]\n",
      "epoch:19 step:18576 [D loss: 0.780299, acc.: 53.12%] [G loss: 0.979860]\n",
      "epoch:19 step:18577 [D loss: 0.328456, acc.: 83.59%] [G loss: 0.715997]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:19 step:18578 [D loss: 0.327081, acc.: 94.53%] [G loss: 1.351309]\n",
      "epoch:19 step:18579 [D loss: 0.707490, acc.: 58.59%] [G loss: 1.033071]\n",
      "epoch:19 step:18580 [D loss: 0.519825, acc.: 76.56%] [G loss: 1.149827]\n",
      "epoch:19 step:18581 [D loss: 0.817652, acc.: 43.75%] [G loss: 1.021730]\n",
      "epoch:19 step:18582 [D loss: 0.711143, acc.: 55.47%] [G loss: 0.890650]\n",
      "epoch:19 step:18583 [D loss: 0.607897, acc.: 64.06%] [G loss: 1.022000]\n",
      "epoch:19 step:18584 [D loss: 0.355736, acc.: 88.28%] [G loss: 1.138362]\n",
      "epoch:19 step:18585 [D loss: 0.399477, acc.: 83.59%] [G loss: 1.182486]\n",
      "epoch:19 step:18586 [D loss: 0.593126, acc.: 68.75%] [G loss: 1.268712]\n",
      "epoch:19 step:18587 [D loss: 0.727351, acc.: 48.44%] [G loss: 1.268021]\n",
      "epoch:19 step:18588 [D loss: 0.651534, acc.: 64.06%] [G loss: 1.131250]\n",
      "epoch:19 step:18589 [D loss: 0.330960, acc.: 92.19%] [G loss: 1.354270]\n",
      "epoch:19 step:18590 [D loss: 0.755646, acc.: 49.22%] [G loss: 1.210043]\n",
      "epoch:19 step:18591 [D loss: 0.571221, acc.: 67.19%] [G loss: 1.060018]\n",
      "epoch:19 step:18592 [D loss: 0.761268, acc.: 52.34%] [G loss: 1.165348]\n",
      "epoch:19 step:18593 [D loss: 0.678015, acc.: 59.38%] [G loss: 1.096116]\n",
      "epoch:19 step:18594 [D loss: 0.552141, acc.: 64.06%] [G loss: 0.862670]\n",
      "epoch:19 step:18595 [D loss: 0.281592, acc.: 87.50%] [G loss: 1.310618]\n",
      "epoch:19 step:18596 [D loss: 0.380250, acc.: 89.84%] [G loss: 1.226211]\n",
      "epoch:19 step:18597 [D loss: 0.260135, acc.: 93.75%] [G loss: 1.519505]\n",
      "epoch:19 step:18598 [D loss: 0.497980, acc.: 78.12%] [G loss: 1.336935]\n",
      "epoch:19 step:18599 [D loss: 0.248860, acc.: 95.31%] [G loss: 1.326432]\n",
      "epoch:19 step:18600 [D loss: 0.668224, acc.: 59.38%] [G loss: 1.561333]\n",
      "##############\n",
      "[3.61974309 2.46970923 6.3813277  5.40146169 4.46845223 5.82819222\n",
      " 5.45633353 5.56460857 5.38432634 4.96053046]\n",
      "##########\n",
      "epoch:19 step:18601 [D loss: 0.803877, acc.: 42.19%] [G loss: 1.155172]\n",
      "epoch:19 step:18602 [D loss: 0.651980, acc.: 62.50%] [G loss: 1.224654]\n",
      "epoch:19 step:18603 [D loss: 0.568481, acc.: 71.88%] [G loss: 1.312318]\n",
      "epoch:19 step:18604 [D loss: 0.542815, acc.: 78.12%] [G loss: 1.338908]\n",
      "epoch:19 step:18605 [D loss: 0.561267, acc.: 71.09%] [G loss: 1.292359]\n",
      "epoch:19 step:18606 [D loss: 0.567176, acc.: 70.31%] [G loss: 1.149959]\n",
      "epoch:19 step:18607 [D loss: 0.216778, acc.: 97.66%] [G loss: 1.666128]\n",
      "epoch:19 step:18608 [D loss: 0.382267, acc.: 80.47%] [G loss: 1.327169]\n",
      "epoch:19 step:18609 [D loss: 0.301454, acc.: 93.75%] [G loss: 1.499053]\n",
      "epoch:19 step:18610 [D loss: 0.748843, acc.: 52.34%] [G loss: 1.401904]\n",
      "epoch:19 step:18611 [D loss: 0.348557, acc.: 83.59%] [G loss: 1.501563]\n",
      "epoch:19 step:18612 [D loss: 0.342546, acc.: 91.41%] [G loss: 1.654088]\n",
      "epoch:19 step:18613 [D loss: 0.440477, acc.: 84.38%] [G loss: 1.237865]\n",
      "epoch:19 step:18614 [D loss: 0.919563, acc.: 47.66%] [G loss: 0.721622]\n",
      "epoch:19 step:18615 [D loss: 0.759124, acc.: 44.53%] [G loss: 1.116135]\n",
      "epoch:19 step:18616 [D loss: 0.625764, acc.: 61.72%] [G loss: 1.176616]\n",
      "epoch:19 step:18617 [D loss: 0.679596, acc.: 60.16%] [G loss: 1.325858]\n",
      "epoch:19 step:18618 [D loss: 0.346334, acc.: 88.28%] [G loss: 1.055419]\n",
      "epoch:19 step:18619 [D loss: 0.462851, acc.: 86.72%] [G loss: 0.937430]\n",
      "epoch:19 step:18620 [D loss: 0.668973, acc.: 55.47%] [G loss: 1.082317]\n",
      "epoch:19 step:18621 [D loss: 0.672080, acc.: 56.25%] [G loss: 0.759162]\n",
      "epoch:19 step:18622 [D loss: 0.573937, acc.: 75.78%] [G loss: 1.190771]\n",
      "epoch:19 step:18623 [D loss: 0.801232, acc.: 44.53%] [G loss: 0.834066]\n",
      "epoch:19 step:18624 [D loss: 0.533014, acc.: 75.78%] [G loss: 1.092004]\n",
      "epoch:19 step:18625 [D loss: 0.597513, acc.: 63.28%] [G loss: 1.081891]\n",
      "epoch:19 step:18626 [D loss: 0.732919, acc.: 48.44%] [G loss: 0.892157]\n",
      "epoch:19 step:18627 [D loss: 0.662974, acc.: 69.53%] [G loss: 1.027817]\n",
      "epoch:19 step:18628 [D loss: 0.467260, acc.: 81.25%] [G loss: 1.134095]\n",
      "epoch:19 step:18629 [D loss: 0.621074, acc.: 66.41%] [G loss: 0.759216]\n",
      "epoch:19 step:18630 [D loss: 0.670469, acc.: 64.06%] [G loss: 0.948878]\n",
      "epoch:19 step:18631 [D loss: 0.765155, acc.: 46.09%] [G loss: 0.932084]\n",
      "epoch:19 step:18632 [D loss: 0.705385, acc.: 56.25%] [G loss: 0.855913]\n",
      "epoch:19 step:18633 [D loss: 0.543227, acc.: 71.88%] [G loss: 0.883179]\n",
      "epoch:19 step:18634 [D loss: 0.457216, acc.: 80.47%] [G loss: 1.187349]\n",
      "epoch:19 step:18635 [D loss: 0.377919, acc.: 89.06%] [G loss: 1.220603]\n",
      "epoch:19 step:18636 [D loss: 0.513109, acc.: 73.44%] [G loss: 1.233875]\n",
      "epoch:19 step:18637 [D loss: 0.422494, acc.: 89.06%] [G loss: 1.398568]\n",
      "epoch:19 step:18638 [D loss: 0.576090, acc.: 75.78%] [G loss: 1.248380]\n",
      "epoch:19 step:18639 [D loss: 0.776947, acc.: 48.44%] [G loss: 0.979168]\n",
      "epoch:19 step:18640 [D loss: 0.841395, acc.: 38.28%] [G loss: 0.960956]\n",
      "epoch:19 step:18641 [D loss: 0.763079, acc.: 46.09%] [G loss: 1.060226]\n",
      "epoch:19 step:18642 [D loss: 0.569964, acc.: 72.66%] [G loss: 1.099817]\n",
      "epoch:19 step:18643 [D loss: 0.615991, acc.: 65.62%] [G loss: 1.318258]\n",
      "epoch:19 step:18644 [D loss: 0.330476, acc.: 88.28%] [G loss: 1.296771]\n",
      "epoch:19 step:18645 [D loss: 0.562755, acc.: 66.41%] [G loss: 0.657247]\n",
      "epoch:19 step:18646 [D loss: 0.607349, acc.: 69.53%] [G loss: 1.347313]\n",
      "epoch:19 step:18647 [D loss: 0.607347, acc.: 69.53%] [G loss: 1.376858]\n",
      "epoch:19 step:18648 [D loss: 0.310819, acc.: 92.97%] [G loss: 1.171517]\n",
      "epoch:19 step:18649 [D loss: 0.669774, acc.: 61.72%] [G loss: 1.285417]\n",
      "epoch:19 step:18650 [D loss: 0.534905, acc.: 70.31%] [G loss: 1.219353]\n",
      "epoch:19 step:18651 [D loss: 0.410756, acc.: 85.16%] [G loss: 1.006841]\n",
      "epoch:19 step:18652 [D loss: 0.682080, acc.: 62.50%] [G loss: 1.258767]\n",
      "epoch:19 step:18653 [D loss: 0.311636, acc.: 93.75%] [G loss: 0.950496]\n",
      "epoch:19 step:18654 [D loss: 0.201330, acc.: 97.66%] [G loss: 1.600572]\n",
      "epoch:19 step:18655 [D loss: 0.244331, acc.: 93.75%] [G loss: 1.375319]\n",
      "epoch:19 step:18656 [D loss: 0.246354, acc.: 99.22%] [G loss: 1.382068]\n",
      "epoch:19 step:18657 [D loss: 0.172468, acc.: 98.44%] [G loss: 1.246802]\n",
      "epoch:19 step:18658 [D loss: 0.575385, acc.: 71.09%] [G loss: 1.333168]\n",
      "epoch:19 step:18659 [D loss: 0.578434, acc.: 68.75%] [G loss: 0.965033]\n",
      "epoch:19 step:18660 [D loss: 0.263652, acc.: 91.41%] [G loss: 1.586793]\n",
      "epoch:19 step:18661 [D loss: 0.312309, acc.: 91.41%] [G loss: 1.155566]\n",
      "epoch:19 step:18662 [D loss: 0.537373, acc.: 69.53%] [G loss: 0.464651]\n",
      "epoch:19 step:18663 [D loss: 0.704869, acc.: 57.03%] [G loss: 1.427211]\n",
      "epoch:19 step:18664 [D loss: 0.756818, acc.: 54.69%] [G loss: 1.726726]\n",
      "epoch:19 step:18665 [D loss: 0.768026, acc.: 54.69%] [G loss: 0.986783]\n",
      "epoch:19 step:18666 [D loss: 0.555740, acc.: 71.09%] [G loss: 0.817590]\n",
      "epoch:19 step:18667 [D loss: 0.635127, acc.: 62.50%] [G loss: 0.684350]\n",
      "epoch:19 step:18668 [D loss: 0.617302, acc.: 62.50%] [G loss: 0.567231]\n",
      "epoch:19 step:18669 [D loss: 1.183974, acc.: 42.97%] [G loss: 0.657704]\n",
      "epoch:19 step:18670 [D loss: 0.859999, acc.: 46.88%] [G loss: 1.267752]\n",
      "epoch:19 step:18671 [D loss: 0.455053, acc.: 78.12%] [G loss: 1.359619]\n",
      "epoch:19 step:18672 [D loss: 0.720112, acc.: 50.78%] [G loss: 1.517045]\n",
      "epoch:19 step:18673 [D loss: 0.326268, acc.: 93.75%] [G loss: 2.049937]\n",
      "epoch:19 step:18674 [D loss: 0.432609, acc.: 81.25%] [G loss: 1.724503]\n",
      "epoch:19 step:18675 [D loss: 0.662402, acc.: 64.06%] [G loss: 1.619987]\n",
      "epoch:19 step:18676 [D loss: 0.389166, acc.: 89.06%] [G loss: 1.535265]\n",
      "epoch:19 step:18677 [D loss: 0.437378, acc.: 82.81%] [G loss: 1.408320]\n",
      "epoch:19 step:18678 [D loss: 0.533512, acc.: 76.56%] [G loss: 1.446868]\n",
      "epoch:19 step:18679 [D loss: 0.315435, acc.: 89.84%] [G loss: 1.030918]\n",
      "epoch:19 step:18680 [D loss: 0.277820, acc.: 86.72%] [G loss: 1.499279]\n",
      "epoch:19 step:18681 [D loss: 0.282853, acc.: 87.50%] [G loss: 1.197458]\n",
      "epoch:19 step:18682 [D loss: 0.493535, acc.: 73.44%] [G loss: 1.862512]\n",
      "epoch:19 step:18683 [D loss: 0.926435, acc.: 50.00%] [G loss: 1.456236]\n",
      "epoch:19 step:18684 [D loss: 0.622484, acc.: 67.97%] [G loss: 0.613217]\n",
      "epoch:19 step:18685 [D loss: 1.249855, acc.: 30.47%] [G loss: 1.122877]\n",
      "epoch:19 step:18686 [D loss: 1.012493, acc.: 33.59%] [G loss: 0.838228]\n",
      "epoch:19 step:18687 [D loss: 0.718869, acc.: 56.25%] [G loss: 1.123610]\n",
      "epoch:19 step:18688 [D loss: 0.420727, acc.: 77.34%] [G loss: 1.118575]\n",
      "epoch:19 step:18689 [D loss: 0.324915, acc.: 93.75%] [G loss: 1.492075]\n",
      "epoch:19 step:18690 [D loss: 0.355959, acc.: 87.50%] [G loss: 1.188067]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:19 step:18691 [D loss: 0.816020, acc.: 46.09%] [G loss: 1.231229]\n",
      "epoch:19 step:18692 [D loss: 0.363450, acc.: 83.59%] [G loss: 1.304214]\n",
      "epoch:19 step:18693 [D loss: 0.491524, acc.: 70.31%] [G loss: 0.919737]\n",
      "epoch:19 step:18694 [D loss: 0.654930, acc.: 64.84%] [G loss: 0.951998]\n",
      "epoch:19 step:18695 [D loss: 0.491165, acc.: 78.91%] [G loss: 0.605983]\n",
      "epoch:19 step:18696 [D loss: 0.509671, acc.: 76.56%] [G loss: 1.179196]\n",
      "epoch:19 step:18697 [D loss: 0.442254, acc.: 80.47%] [G loss: 1.146636]\n",
      "epoch:19 step:18698 [D loss: 0.567074, acc.: 69.53%] [G loss: 1.075302]\n",
      "epoch:19 step:18699 [D loss: 0.621231, acc.: 69.53%] [G loss: 1.254703]\n",
      "epoch:19 step:18700 [D loss: 0.582513, acc.: 67.19%] [G loss: 0.855155]\n",
      "epoch:19 step:18701 [D loss: 0.347021, acc.: 87.50%] [G loss: 1.512221]\n",
      "epoch:19 step:18702 [D loss: 0.289764, acc.: 86.72%] [G loss: 1.940321]\n",
      "epoch:19 step:18703 [D loss: 0.182717, acc.: 100.00%] [G loss: 1.713289]\n",
      "epoch:19 step:18704 [D loss: 0.520556, acc.: 74.22%] [G loss: 1.792448]\n",
      "epoch:19 step:18705 [D loss: 1.277782, acc.: 19.53%] [G loss: 1.642096]\n",
      "epoch:19 step:18706 [D loss: 0.635414, acc.: 65.62%] [G loss: 1.764676]\n",
      "epoch:19 step:18707 [D loss: 0.423699, acc.: 80.47%] [G loss: 1.926366]\n",
      "epoch:19 step:18708 [D loss: 0.249533, acc.: 96.09%] [G loss: 1.271846]\n",
      "epoch:19 step:18709 [D loss: 0.161171, acc.: 100.00%] [G loss: 1.768785]\n",
      "epoch:19 step:18710 [D loss: 0.903801, acc.: 53.12%] [G loss: 1.356503]\n",
      "epoch:19 step:18711 [D loss: 0.777340, acc.: 53.91%] [G loss: 1.384677]\n",
      "epoch:19 step:18712 [D loss: 0.612565, acc.: 66.41%] [G loss: 1.144561]\n",
      "epoch:19 step:18713 [D loss: 0.425653, acc.: 91.41%] [G loss: 1.295095]\n",
      "epoch:19 step:18714 [D loss: 0.536061, acc.: 74.22%] [G loss: 0.997761]\n",
      "epoch:19 step:18715 [D loss: 0.316899, acc.: 79.69%] [G loss: 1.206780]\n",
      "epoch:19 step:18716 [D loss: 0.813441, acc.: 48.44%] [G loss: 1.189172]\n",
      "epoch:19 step:18717 [D loss: 0.632302, acc.: 61.72%] [G loss: 1.146195]\n",
      "epoch:19 step:18718 [D loss: 0.729553, acc.: 54.69%] [G loss: 1.375048]\n",
      "epoch:19 step:18719 [D loss: 0.393288, acc.: 82.81%] [G loss: 1.560323]\n",
      "epoch:19 step:18720 [D loss: 0.283059, acc.: 92.19%] [G loss: 1.286536]\n",
      "epoch:19 step:18721 [D loss: 0.568695, acc.: 73.44%] [G loss: 1.438674]\n",
      "epoch:19 step:18722 [D loss: 0.632238, acc.: 60.94%] [G loss: 1.058879]\n",
      "epoch:19 step:18723 [D loss: 0.248012, acc.: 89.84%] [G loss: 1.110906]\n",
      "epoch:19 step:18724 [D loss: 0.261452, acc.: 96.88%] [G loss: 1.582559]\n",
      "epoch:19 step:18725 [D loss: 0.620883, acc.: 66.41%] [G loss: 1.557215]\n",
      "epoch:19 step:18726 [D loss: 0.666839, acc.: 61.72%] [G loss: 0.966531]\n",
      "epoch:19 step:18727 [D loss: 0.566719, acc.: 75.78%] [G loss: 1.262649]\n",
      "epoch:19 step:18728 [D loss: 0.615244, acc.: 60.94%] [G loss: 1.328723]\n",
      "epoch:19 step:18729 [D loss: 0.593239, acc.: 67.97%] [G loss: 1.349489]\n",
      "epoch:19 step:18730 [D loss: 0.581804, acc.: 65.62%] [G loss: 1.352036]\n",
      "epoch:19 step:18731 [D loss: 0.507939, acc.: 75.00%] [G loss: 1.149608]\n",
      "epoch:19 step:18732 [D loss: 0.245081, acc.: 92.19%] [G loss: 1.413743]\n",
      "epoch:19 step:18733 [D loss: 0.354504, acc.: 91.41%] [G loss: 1.584647]\n",
      "epoch:19 step:18734 [D loss: 0.415988, acc.: 90.62%] [G loss: 1.370495]\n",
      "epoch:19 step:18735 [D loss: 0.724043, acc.: 58.59%] [G loss: 1.349653]\n",
      "epoch:19 step:18736 [D loss: 0.719009, acc.: 57.03%] [G loss: 1.136506]\n",
      "epoch:19 step:18737 [D loss: 0.592400, acc.: 68.75%] [G loss: 0.963923]\n",
      "epoch:19 step:18738 [D loss: 0.622506, acc.: 68.75%] [G loss: 1.269240]\n",
      "epoch:19 step:18739 [D loss: 0.432073, acc.: 85.16%] [G loss: 0.877997]\n",
      "epoch:19 step:18740 [D loss: 0.247849, acc.: 96.88%] [G loss: 1.329243]\n",
      "epoch:20 step:18741 [D loss: 0.683108, acc.: 65.62%] [G loss: 1.125383]\n",
      "epoch:20 step:18742 [D loss: 0.722672, acc.: 58.59%] [G loss: 1.131179]\n",
      "epoch:20 step:18743 [D loss: 0.792592, acc.: 47.66%] [G loss: 0.926916]\n",
      "epoch:20 step:18744 [D loss: 0.647398, acc.: 66.41%] [G loss: 0.918038]\n",
      "epoch:20 step:18745 [D loss: 0.642434, acc.: 58.59%] [G loss: 0.998321]\n",
      "epoch:20 step:18746 [D loss: 0.607519, acc.: 64.84%] [G loss: 1.093488]\n",
      "epoch:20 step:18747 [D loss: 0.545951, acc.: 67.97%] [G loss: 1.103833]\n",
      "epoch:20 step:18748 [D loss: 0.729779, acc.: 57.81%] [G loss: 1.213486]\n",
      "epoch:20 step:18749 [D loss: 0.521378, acc.: 77.34%] [G loss: 1.500363]\n",
      "epoch:20 step:18750 [D loss: 0.468951, acc.: 79.69%] [G loss: 1.138421]\n",
      "epoch:20 step:18751 [D loss: 0.637596, acc.: 60.16%] [G loss: 1.044259]\n",
      "epoch:20 step:18752 [D loss: 0.689125, acc.: 62.50%] [G loss: 1.311799]\n",
      "epoch:20 step:18753 [D loss: 0.440074, acc.: 79.69%] [G loss: 1.193303]\n",
      "epoch:20 step:18754 [D loss: 0.626272, acc.: 66.41%] [G loss: 1.007931]\n",
      "epoch:20 step:18755 [D loss: 0.497073, acc.: 82.03%] [G loss: 0.985333]\n",
      "epoch:20 step:18756 [D loss: 0.559009, acc.: 72.66%] [G loss: 1.097867]\n",
      "epoch:20 step:18757 [D loss: 0.655443, acc.: 61.72%] [G loss: 1.566278]\n",
      "epoch:20 step:18758 [D loss: 0.662023, acc.: 55.47%] [G loss: 1.158203]\n",
      "epoch:20 step:18759 [D loss: 0.792388, acc.: 50.00%] [G loss: 0.786400]\n",
      "epoch:20 step:18760 [D loss: 0.909496, acc.: 34.38%] [G loss: 1.113359]\n",
      "epoch:20 step:18761 [D loss: 0.808617, acc.: 50.00%] [G loss: 0.713095]\n",
      "epoch:20 step:18762 [D loss: 0.732306, acc.: 52.34%] [G loss: 0.884756]\n",
      "epoch:20 step:18763 [D loss: 0.783514, acc.: 45.31%] [G loss: 0.996625]\n",
      "epoch:20 step:18764 [D loss: 0.584699, acc.: 63.28%] [G loss: 1.103751]\n",
      "epoch:20 step:18765 [D loss: 0.559921, acc.: 72.66%] [G loss: 1.162513]\n",
      "epoch:20 step:18766 [D loss: 0.743407, acc.: 56.25%] [G loss: 1.329418]\n",
      "epoch:20 step:18767 [D loss: 0.395151, acc.: 82.03%] [G loss: 1.339681]\n",
      "epoch:20 step:18768 [D loss: 0.550623, acc.: 74.22%] [G loss: 1.386635]\n",
      "epoch:20 step:18769 [D loss: 0.491687, acc.: 75.00%] [G loss: 1.573243]\n",
      "epoch:20 step:18770 [D loss: 0.514235, acc.: 78.12%] [G loss: 1.303867]\n",
      "epoch:20 step:18771 [D loss: 0.252299, acc.: 92.97%] [G loss: 1.405417]\n",
      "epoch:20 step:18772 [D loss: 0.255271, acc.: 92.97%] [G loss: 1.513428]\n",
      "epoch:20 step:18773 [D loss: 0.169125, acc.: 97.66%] [G loss: 1.609322]\n",
      "epoch:20 step:18774 [D loss: 0.201944, acc.: 96.09%] [G loss: 1.901664]\n",
      "epoch:20 step:18775 [D loss: 0.110161, acc.: 99.22%] [G loss: 1.793107]\n",
      "epoch:20 step:18776 [D loss: 0.181986, acc.: 92.97%] [G loss: 2.143246]\n",
      "epoch:20 step:18777 [D loss: 0.909931, acc.: 47.66%] [G loss: 1.715164]\n",
      "epoch:20 step:18778 [D loss: 0.904930, acc.: 46.09%] [G loss: 1.720219]\n",
      "epoch:20 step:18779 [D loss: 1.019704, acc.: 43.75%] [G loss: 1.112859]\n",
      "epoch:20 step:18780 [D loss: 0.649825, acc.: 66.41%] [G loss: 1.005070]\n",
      "epoch:20 step:18781 [D loss: 0.626181, acc.: 65.62%] [G loss: 1.174576]\n",
      "epoch:20 step:18782 [D loss: 0.441759, acc.: 82.03%] [G loss: 0.865345]\n",
      "epoch:20 step:18783 [D loss: 0.320143, acc.: 89.06%] [G loss: 1.316717]\n",
      "epoch:20 step:18784 [D loss: 0.444226, acc.: 87.50%] [G loss: 0.937428]\n",
      "epoch:20 step:18785 [D loss: 0.572600, acc.: 71.88%] [G loss: 0.773602]\n",
      "epoch:20 step:18786 [D loss: 0.335197, acc.: 91.41%] [G loss: 1.142998]\n",
      "epoch:20 step:18787 [D loss: 0.651978, acc.: 61.72%] [G loss: 1.201953]\n",
      "epoch:20 step:18788 [D loss: 0.719909, acc.: 56.25%] [G loss: 0.679506]\n",
      "epoch:20 step:18789 [D loss: 0.628347, acc.: 64.06%] [G loss: 0.655192]\n",
      "epoch:20 step:18790 [D loss: 0.432530, acc.: 79.69%] [G loss: 0.741830]\n",
      "epoch:20 step:18791 [D loss: 0.596511, acc.: 62.50%] [G loss: 0.128231]\n",
      "epoch:20 step:18792 [D loss: 0.273650, acc.: 96.09%] [G loss: 1.247814]\n",
      "epoch:20 step:18793 [D loss: 0.486627, acc.: 76.56%] [G loss: 1.008427]\n",
      "epoch:20 step:18794 [D loss: 0.797746, acc.: 46.09%] [G loss: 0.751161]\n",
      "epoch:20 step:18795 [D loss: 0.754902, acc.: 49.22%] [G loss: 0.539544]\n",
      "epoch:20 step:18796 [D loss: 0.745554, acc.: 47.66%] [G loss: 0.586381]\n",
      "epoch:20 step:18797 [D loss: 1.426891, acc.: 50.78%] [G loss: 1.068160]\n",
      "epoch:20 step:18798 [D loss: 0.495745, acc.: 78.91%] [G loss: 2.136761]\n",
      "epoch:20 step:18799 [D loss: 0.657393, acc.: 56.25%] [G loss: 1.330289]\n",
      "epoch:20 step:18800 [D loss: 0.724880, acc.: 57.81%] [G loss: 1.562240]\n",
      "##############\n",
      "[4.21191448 2.89007534 6.5551794  6.34394127 4.77325807 6.18220253\n",
      " 5.74538351 5.88996979 6.15402289 5.1705963 ]\n",
      "##########\n",
      "epoch:20 step:18801 [D loss: 1.013757, acc.: 32.81%] [G loss: 1.851153]\n",
      "epoch:20 step:18802 [D loss: 0.777491, acc.: 52.34%] [G loss: 1.466871]\n",
      "epoch:20 step:18803 [D loss: 0.668238, acc.: 62.50%] [G loss: 1.186531]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:20 step:18804 [D loss: 0.770906, acc.: 50.00%] [G loss: 0.877336]\n",
      "epoch:20 step:18805 [D loss: 0.670842, acc.: 64.06%] [G loss: 1.384034]\n",
      "epoch:20 step:18806 [D loss: 0.782649, acc.: 52.34%] [G loss: 1.052077]\n",
      "epoch:20 step:18807 [D loss: 0.730181, acc.: 49.22%] [G loss: 1.030980]\n",
      "epoch:20 step:18808 [D loss: 0.709491, acc.: 53.91%] [G loss: 1.022506]\n",
      "epoch:20 step:18809 [D loss: 0.709831, acc.: 51.56%] [G loss: 1.608069]\n",
      "epoch:20 step:18810 [D loss: 0.633851, acc.: 64.06%] [G loss: 1.423320]\n",
      "epoch:20 step:18811 [D loss: 0.461249, acc.: 77.34%] [G loss: 1.318699]\n",
      "epoch:20 step:18812 [D loss: 0.607118, acc.: 70.31%] [G loss: 1.081008]\n",
      "epoch:20 step:18813 [D loss: 0.639420, acc.: 62.50%] [G loss: 1.003619]\n",
      "epoch:20 step:18814 [D loss: 0.627621, acc.: 63.28%] [G loss: 1.133698]\n",
      "epoch:20 step:18815 [D loss: 0.505169, acc.: 81.25%] [G loss: 0.987276]\n",
      "epoch:20 step:18816 [D loss: 0.303172, acc.: 89.84%] [G loss: 1.076744]\n",
      "epoch:20 step:18817 [D loss: 0.396218, acc.: 86.72%] [G loss: 1.790161]\n",
      "epoch:20 step:18818 [D loss: 0.877742, acc.: 48.44%] [G loss: 1.225172]\n",
      "epoch:20 step:18819 [D loss: 0.672778, acc.: 58.59%] [G loss: 1.114255]\n",
      "epoch:20 step:18820 [D loss: 0.715657, acc.: 56.25%] [G loss: 1.116057]\n",
      "epoch:20 step:18821 [D loss: 0.576590, acc.: 68.75%] [G loss: 1.198220]\n",
      "epoch:20 step:18822 [D loss: 0.613359, acc.: 67.19%] [G loss: 1.115666]\n",
      "epoch:20 step:18823 [D loss: 0.376726, acc.: 92.97%] [G loss: 1.765114]\n",
      "epoch:20 step:18824 [D loss: 0.646571, acc.: 58.59%] [G loss: 1.325989]\n",
      "epoch:20 step:18825 [D loss: 0.636192, acc.: 62.50%] [G loss: 1.171278]\n",
      "epoch:20 step:18826 [D loss: 0.677895, acc.: 63.28%] [G loss: 0.935440]\n",
      "epoch:20 step:18827 [D loss: 0.414653, acc.: 89.06%] [G loss: 1.037469]\n",
      "epoch:20 step:18828 [D loss: 0.464466, acc.: 79.69%] [G loss: 1.009313]\n",
      "epoch:20 step:18829 [D loss: 0.453315, acc.: 82.03%] [G loss: 1.373007]\n",
      "epoch:20 step:18830 [D loss: 0.524214, acc.: 77.34%] [G loss: 0.931275]\n",
      "epoch:20 step:18831 [D loss: 0.612574, acc.: 69.53%] [G loss: 2.315352]\n",
      "epoch:20 step:18832 [D loss: 0.508407, acc.: 75.78%] [G loss: 1.240124]\n",
      "epoch:20 step:18833 [D loss: 0.296436, acc.: 92.97%] [G loss: 1.069192]\n",
      "epoch:20 step:18834 [D loss: 0.573405, acc.: 72.66%] [G loss: 1.104637]\n",
      "epoch:20 step:18835 [D loss: 0.756431, acc.: 62.50%] [G loss: 1.451537]\n",
      "epoch:20 step:18836 [D loss: 0.644281, acc.: 59.38%] [G loss: 1.174133]\n",
      "epoch:20 step:18837 [D loss: 0.646314, acc.: 64.06%] [G loss: 1.086743]\n",
      "epoch:20 step:18838 [D loss: 0.666559, acc.: 59.38%] [G loss: 1.121384]\n",
      "epoch:20 step:18839 [D loss: 0.590214, acc.: 70.31%] [G loss: 0.840608]\n",
      "epoch:20 step:18840 [D loss: 0.743357, acc.: 48.44%] [G loss: 1.077220]\n",
      "epoch:20 step:18841 [D loss: 0.634666, acc.: 64.84%] [G loss: 1.009059]\n",
      "epoch:20 step:18842 [D loss: 0.797459, acc.: 50.00%] [G loss: 0.643425]\n",
      "epoch:20 step:18843 [D loss: 0.793494, acc.: 48.44%] [G loss: 0.787199]\n",
      "epoch:20 step:18844 [D loss: 0.793751, acc.: 54.69%] [G loss: 0.929352]\n",
      "epoch:20 step:18845 [D loss: 0.631471, acc.: 60.16%] [G loss: 1.187796]\n",
      "epoch:20 step:18846 [D loss: 0.717794, acc.: 56.25%] [G loss: 0.885092]\n",
      "epoch:20 step:18847 [D loss: 0.507141, acc.: 74.22%] [G loss: 1.038993]\n",
      "epoch:20 step:18848 [D loss: 0.624845, acc.: 68.75%] [G loss: 1.109812]\n",
      "epoch:20 step:18849 [D loss: 0.708316, acc.: 54.69%] [G loss: 0.770120]\n",
      "epoch:20 step:18850 [D loss: 0.757387, acc.: 44.53%] [G loss: 1.075719]\n",
      "epoch:20 step:18851 [D loss: 0.536628, acc.: 75.00%] [G loss: 0.848358]\n",
      "epoch:20 step:18852 [D loss: 0.598264, acc.: 65.62%] [G loss: 0.962276]\n",
      "epoch:20 step:18853 [D loss: 0.514024, acc.: 77.34%] [G loss: 1.133813]\n",
      "epoch:20 step:18854 [D loss: 0.495546, acc.: 77.34%] [G loss: 1.000585]\n",
      "epoch:20 step:18855 [D loss: 0.509104, acc.: 78.91%] [G loss: 1.317326]\n",
      "epoch:20 step:18856 [D loss: 0.864564, acc.: 44.53%] [G loss: 0.747858]\n",
      "epoch:20 step:18857 [D loss: 0.461870, acc.: 84.38%] [G loss: 1.155192]\n",
      "epoch:20 step:18858 [D loss: 0.384174, acc.: 80.47%] [G loss: 1.417654]\n",
      "epoch:20 step:18859 [D loss: 0.257562, acc.: 89.06%] [G loss: 1.570146]\n",
      "epoch:20 step:18860 [D loss: 0.702604, acc.: 71.09%] [G loss: 1.031379]\n",
      "epoch:20 step:18861 [D loss: 0.442901, acc.: 84.38%] [G loss: 0.962655]\n",
      "epoch:20 step:18862 [D loss: 0.582043, acc.: 69.53%] [G loss: 1.194986]\n",
      "epoch:20 step:18863 [D loss: 0.727649, acc.: 52.34%] [G loss: 1.129798]\n",
      "epoch:20 step:18864 [D loss: 0.578093, acc.: 67.19%] [G loss: 1.166623]\n",
      "epoch:20 step:18865 [D loss: 0.694855, acc.: 52.34%] [G loss: 1.205791]\n",
      "epoch:20 step:18866 [D loss: 0.598773, acc.: 73.44%] [G loss: 1.302865]\n",
      "epoch:20 step:18867 [D loss: 0.744401, acc.: 53.91%] [G loss: 1.049295]\n",
      "epoch:20 step:18868 [D loss: 0.734017, acc.: 49.22%] [G loss: 1.089453]\n",
      "epoch:20 step:18869 [D loss: 0.522652, acc.: 77.34%] [G loss: 1.114409]\n",
      "epoch:20 step:18870 [D loss: 0.396277, acc.: 87.50%] [G loss: 0.992512]\n",
      "epoch:20 step:18871 [D loss: 0.537978, acc.: 75.78%] [G loss: 1.037684]\n",
      "epoch:20 step:18872 [D loss: 0.554258, acc.: 70.31%] [G loss: 0.653650]\n",
      "epoch:20 step:18873 [D loss: 0.432811, acc.: 85.16%] [G loss: 1.132630]\n",
      "epoch:20 step:18874 [D loss: 0.341539, acc.: 89.06%] [G loss: 0.968144]\n",
      "epoch:20 step:18875 [D loss: 0.352542, acc.: 91.41%] [G loss: 1.131553]\n",
      "epoch:20 step:18876 [D loss: 0.645335, acc.: 61.72%] [G loss: 1.328563]\n",
      "epoch:20 step:18877 [D loss: 0.621249, acc.: 64.06%] [G loss: 1.136740]\n",
      "epoch:20 step:18878 [D loss: 0.619327, acc.: 60.94%] [G loss: 0.955572]\n",
      "epoch:20 step:18879 [D loss: 0.643146, acc.: 60.94%] [G loss: 1.025646]\n",
      "epoch:20 step:18880 [D loss: 0.381278, acc.: 83.59%] [G loss: 1.016230]\n",
      "epoch:20 step:18881 [D loss: 0.282786, acc.: 94.53%] [G loss: 0.975906]\n",
      "epoch:20 step:18882 [D loss: 0.665166, acc.: 64.84%] [G loss: 1.269970]\n",
      "epoch:20 step:18883 [D loss: 0.334087, acc.: 82.03%] [G loss: 1.488981]\n",
      "epoch:20 step:18884 [D loss: 0.626041, acc.: 67.19%] [G loss: 1.592261]\n",
      "epoch:20 step:18885 [D loss: 0.206326, acc.: 96.88%] [G loss: 1.505361]\n",
      "epoch:20 step:18886 [D loss: 0.452640, acc.: 83.59%] [G loss: 1.685462]\n",
      "epoch:20 step:18887 [D loss: 0.535222, acc.: 73.44%] [G loss: 1.325907]\n",
      "epoch:20 step:18888 [D loss: 0.652095, acc.: 60.94%] [G loss: 1.450908]\n",
      "epoch:20 step:18889 [D loss: 0.209945, acc.: 96.88%] [G loss: 0.950987]\n",
      "epoch:20 step:18890 [D loss: 0.161175, acc.: 98.44%] [G loss: 1.059575]\n",
      "epoch:20 step:18891 [D loss: 0.273511, acc.: 89.06%] [G loss: 1.168226]\n",
      "epoch:20 step:18892 [D loss: 0.351178, acc.: 93.75%] [G loss: 1.613002]\n",
      "epoch:20 step:18893 [D loss: 0.833435, acc.: 47.66%] [G loss: 1.417707]\n",
      "epoch:20 step:18894 [D loss: 0.692053, acc.: 55.47%] [G loss: 1.173764]\n",
      "epoch:20 step:18895 [D loss: 0.727171, acc.: 44.53%] [G loss: 1.154650]\n",
      "epoch:20 step:18896 [D loss: 0.933899, acc.: 40.62%] [G loss: 1.356483]\n",
      "epoch:20 step:18897 [D loss: 0.897322, acc.: 39.84%] [G loss: 1.086466]\n",
      "epoch:20 step:18898 [D loss: 0.756463, acc.: 49.22%] [G loss: 1.264868]\n",
      "epoch:20 step:18899 [D loss: 0.733052, acc.: 53.12%] [G loss: 1.167347]\n",
      "epoch:20 step:18900 [D loss: 0.596583, acc.: 66.41%] [G loss: 1.220220]\n",
      "epoch:20 step:18901 [D loss: 0.885803, acc.: 31.25%] [G loss: 1.118752]\n",
      "epoch:20 step:18902 [D loss: 0.444360, acc.: 81.25%] [G loss: 1.187397]\n",
      "epoch:20 step:18903 [D loss: 0.510683, acc.: 80.47%] [G loss: 1.033370]\n",
      "epoch:20 step:18904 [D loss: 0.648124, acc.: 64.06%] [G loss: 1.140859]\n",
      "epoch:20 step:18905 [D loss: 0.896408, acc.: 46.09%] [G loss: 1.355410]\n",
      "epoch:20 step:18906 [D loss: 0.786105, acc.: 53.12%] [G loss: 1.336850]\n",
      "epoch:20 step:18907 [D loss: 0.649963, acc.: 62.50%] [G loss: 1.234395]\n",
      "epoch:20 step:18908 [D loss: 0.590378, acc.: 63.28%] [G loss: 1.254509]\n",
      "epoch:20 step:18909 [D loss: 0.737380, acc.: 51.56%] [G loss: 1.031385]\n",
      "epoch:20 step:18910 [D loss: 0.607251, acc.: 64.06%] [G loss: 1.132563]\n",
      "epoch:20 step:18911 [D loss: 0.667985, acc.: 57.81%] [G loss: 1.072383]\n",
      "epoch:20 step:18912 [D loss: 0.732399, acc.: 52.34%] [G loss: 0.875186]\n",
      "epoch:20 step:18913 [D loss: 0.712333, acc.: 55.47%] [G loss: 0.930013]\n",
      "epoch:20 step:18914 [D loss: 0.715264, acc.: 58.59%] [G loss: 0.932089]\n",
      "epoch:20 step:18915 [D loss: 0.750735, acc.: 53.12%] [G loss: 1.053724]\n",
      "epoch:20 step:18916 [D loss: 0.615544, acc.: 60.16%] [G loss: 1.052371]\n",
      "epoch:20 step:18917 [D loss: 0.675202, acc.: 58.59%] [G loss: 1.132442]\n",
      "epoch:20 step:18918 [D loss: 0.733298, acc.: 46.88%] [G loss: 0.977770]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:20 step:18919 [D loss: 0.722591, acc.: 53.12%] [G loss: 1.002874]\n",
      "epoch:20 step:18920 [D loss: 0.780043, acc.: 46.09%] [G loss: 0.987749]\n",
      "epoch:20 step:18921 [D loss: 0.525692, acc.: 74.22%] [G loss: 1.116631]\n",
      "epoch:20 step:18922 [D loss: 0.554778, acc.: 71.88%] [G loss: 1.059192]\n",
      "epoch:20 step:18923 [D loss: 0.639213, acc.: 64.06%] [G loss: 1.178371]\n",
      "epoch:20 step:18924 [D loss: 0.382503, acc.: 89.06%] [G loss: 1.242450]\n",
      "epoch:20 step:18925 [D loss: 0.631122, acc.: 61.72%] [G loss: 1.179433]\n",
      "epoch:20 step:18926 [D loss: 0.730206, acc.: 46.09%] [G loss: 1.173632]\n",
      "epoch:20 step:18927 [D loss: 0.622209, acc.: 64.06%] [G loss: 1.109845]\n",
      "epoch:20 step:18928 [D loss: 0.400871, acc.: 85.94%] [G loss: 1.209971]\n",
      "epoch:20 step:18929 [D loss: 0.580237, acc.: 67.19%] [G loss: 1.277297]\n",
      "epoch:20 step:18930 [D loss: 0.603058, acc.: 67.97%] [G loss: 1.610094]\n",
      "epoch:20 step:18931 [D loss: 0.464088, acc.: 80.47%] [G loss: 1.022540]\n",
      "epoch:20 step:18932 [D loss: 0.264998, acc.: 96.09%] [G loss: 1.435494]\n",
      "epoch:20 step:18933 [D loss: 0.364585, acc.: 94.53%] [G loss: 0.998850]\n",
      "epoch:20 step:18934 [D loss: 0.248441, acc.: 94.53%] [G loss: 1.286054]\n",
      "epoch:20 step:18935 [D loss: 0.364172, acc.: 90.62%] [G loss: 0.745406]\n",
      "epoch:20 step:18936 [D loss: 0.440039, acc.: 82.81%] [G loss: 2.074677]\n",
      "epoch:20 step:18937 [D loss: 0.522100, acc.: 73.44%] [G loss: 0.934804]\n",
      "epoch:20 step:18938 [D loss: 0.356660, acc.: 90.62%] [G loss: 0.648076]\n",
      "epoch:20 step:18939 [D loss: 0.795069, acc.: 49.22%] [G loss: 0.427502]\n",
      "epoch:20 step:18940 [D loss: 0.564641, acc.: 77.34%] [G loss: 1.007076]\n",
      "epoch:20 step:18941 [D loss: 0.268517, acc.: 97.66%] [G loss: 0.895055]\n",
      "epoch:20 step:18942 [D loss: 0.938670, acc.: 29.69%] [G loss: 1.307167]\n",
      "epoch:20 step:18943 [D loss: 0.487441, acc.: 75.00%] [G loss: 0.722981]\n",
      "epoch:20 step:18944 [D loss: 0.503928, acc.: 75.78%] [G loss: 1.753054]\n",
      "epoch:20 step:18945 [D loss: 0.486714, acc.: 78.91%] [G loss: 1.347378]\n",
      "epoch:20 step:18946 [D loss: 0.389840, acc.: 88.28%] [G loss: 0.989034]\n",
      "epoch:20 step:18947 [D loss: 0.265943, acc.: 94.53%] [G loss: 1.772938]\n",
      "epoch:20 step:18948 [D loss: 0.296693, acc.: 92.97%] [G loss: 1.637785]\n",
      "epoch:20 step:18949 [D loss: 0.323969, acc.: 92.19%] [G loss: 1.111222]\n",
      "epoch:20 step:18950 [D loss: 1.316426, acc.: 37.50%] [G loss: 1.159201]\n",
      "epoch:20 step:18951 [D loss: 1.410659, acc.: 8.59%] [G loss: 1.241141]\n",
      "epoch:20 step:18952 [D loss: 0.776045, acc.: 50.78%] [G loss: 1.240669]\n",
      "epoch:20 step:18953 [D loss: 0.693011, acc.: 58.59%] [G loss: 1.378453]\n",
      "epoch:20 step:18954 [D loss: 1.103995, acc.: 23.44%] [G loss: 1.081204]\n",
      "epoch:20 step:18955 [D loss: 0.828021, acc.: 42.97%] [G loss: 1.254188]\n",
      "epoch:20 step:18956 [D loss: 0.657028, acc.: 64.06%] [G loss: 1.306552]\n",
      "epoch:20 step:18957 [D loss: 0.610471, acc.: 69.53%] [G loss: 0.805629]\n",
      "epoch:20 step:18958 [D loss: 0.359313, acc.: 94.53%] [G loss: 1.101648]\n",
      "epoch:20 step:18959 [D loss: 0.562417, acc.: 70.31%] [G loss: 1.167152]\n",
      "epoch:20 step:18960 [D loss: 0.334738, acc.: 80.47%] [G loss: 0.962642]\n",
      "epoch:20 step:18961 [D loss: 0.271045, acc.: 86.72%] [G loss: 1.215580]\n",
      "epoch:20 step:18962 [D loss: 0.373898, acc.: 92.19%] [G loss: 1.639608]\n",
      "epoch:20 step:18963 [D loss: 0.362312, acc.: 90.62%] [G loss: 1.376288]\n",
      "epoch:20 step:18964 [D loss: 0.743359, acc.: 54.69%] [G loss: 1.611252]\n",
      "epoch:20 step:18965 [D loss: 0.567432, acc.: 71.88%] [G loss: 1.122003]\n",
      "epoch:20 step:18966 [D loss: 0.640104, acc.: 68.75%] [G loss: 1.349116]\n",
      "epoch:20 step:18967 [D loss: 0.444981, acc.: 88.28%] [G loss: 1.215963]\n",
      "epoch:20 step:18968 [D loss: 0.580662, acc.: 70.31%] [G loss: 1.342260]\n",
      "epoch:20 step:18969 [D loss: 0.572794, acc.: 75.78%] [G loss: 1.181534]\n",
      "epoch:20 step:18970 [D loss: 0.173619, acc.: 92.97%] [G loss: 1.545052]\n",
      "epoch:20 step:18971 [D loss: 0.240851, acc.: 94.53%] [G loss: 1.347316]\n",
      "epoch:20 step:18972 [D loss: 0.147701, acc.: 99.22%] [G loss: 1.616011]\n",
      "epoch:20 step:18973 [D loss: 0.431126, acc.: 85.16%] [G loss: 1.655468]\n",
      "epoch:20 step:18974 [D loss: 0.249078, acc.: 96.88%] [G loss: 1.583189]\n",
      "epoch:20 step:18975 [D loss: 0.304835, acc.: 92.97%] [G loss: 1.324015]\n",
      "epoch:20 step:18976 [D loss: 0.593371, acc.: 68.75%] [G loss: 1.432152]\n",
      "epoch:20 step:18977 [D loss: 0.289844, acc.: 95.31%] [G loss: 1.143705]\n",
      "epoch:20 step:18978 [D loss: 0.254895, acc.: 93.75%] [G loss: 1.358000]\n",
      "epoch:20 step:18979 [D loss: 0.542506, acc.: 77.34%] [G loss: 1.082782]\n",
      "epoch:20 step:18980 [D loss: 0.876551, acc.: 36.72%] [G loss: 1.351499]\n",
      "epoch:20 step:18981 [D loss: 0.891444, acc.: 45.31%] [G loss: 1.098786]\n",
      "epoch:20 step:18982 [D loss: 0.575160, acc.: 71.09%] [G loss: 1.159691]\n",
      "epoch:20 step:18983 [D loss: 0.397619, acc.: 81.25%] [G loss: 0.873104]\n",
      "epoch:20 step:18984 [D loss: 0.675419, acc.: 64.84%] [G loss: 0.948044]\n",
      "epoch:20 step:18985 [D loss: 0.826117, acc.: 40.62%] [G loss: 0.864158]\n",
      "epoch:20 step:18986 [D loss: 0.782447, acc.: 49.22%] [G loss: 1.189784]\n",
      "epoch:20 step:18987 [D loss: 0.778352, acc.: 47.66%] [G loss: 0.968485]\n",
      "epoch:20 step:18988 [D loss: 1.032023, acc.: 35.94%] [G loss: 0.961649]\n",
      "epoch:20 step:18989 [D loss: 0.518917, acc.: 78.12%] [G loss: 0.974051]\n",
      "epoch:20 step:18990 [D loss: 0.751787, acc.: 47.66%] [G loss: 1.035663]\n",
      "epoch:20 step:18991 [D loss: 0.658749, acc.: 57.81%] [G loss: 1.222889]\n",
      "epoch:20 step:18992 [D loss: 0.725503, acc.: 54.69%] [G loss: 0.906036]\n",
      "epoch:20 step:18993 [D loss: 0.576357, acc.: 72.66%] [G loss: 1.093917]\n",
      "epoch:20 step:18994 [D loss: 0.473858, acc.: 81.25%] [G loss: 1.013402]\n",
      "epoch:20 step:18995 [D loss: 0.306911, acc.: 95.31%] [G loss: 1.284845]\n",
      "epoch:20 step:18996 [D loss: 0.368297, acc.: 76.56%] [G loss: 1.577715]\n",
      "epoch:20 step:18997 [D loss: 0.554979, acc.: 73.44%] [G loss: 1.414004]\n",
      "epoch:20 step:18998 [D loss: 0.990564, acc.: 28.91%] [G loss: 1.493181]\n",
      "epoch:20 step:18999 [D loss: 0.156984, acc.: 98.44%] [G loss: 1.647993]\n",
      "epoch:20 step:19000 [D loss: 0.211767, acc.: 97.66%] [G loss: 1.924305]\n",
      "##############\n",
      "[4.21272394 2.35057907 6.66192401 5.42618325 4.64047214 6.08614441\n",
      " 5.41908256 5.02271447 5.87794443 5.37740816]\n",
      "##########\n",
      "epoch:20 step:19001 [D loss: 0.187865, acc.: 100.00%] [G loss: 1.699901]\n",
      "epoch:20 step:19002 [D loss: 0.613989, acc.: 64.84%] [G loss: 1.527861]\n",
      "epoch:20 step:19003 [D loss: 0.767222, acc.: 50.78%] [G loss: 1.288951]\n",
      "epoch:20 step:19004 [D loss: 0.764902, acc.: 55.47%] [G loss: 1.608702]\n",
      "epoch:20 step:19005 [D loss: 0.438765, acc.: 85.16%] [G loss: 1.436046]\n",
      "epoch:20 step:19006 [D loss: 0.724714, acc.: 55.47%] [G loss: 1.102471]\n",
      "epoch:20 step:19007 [D loss: 0.538476, acc.: 74.22%] [G loss: 1.023877]\n",
      "epoch:20 step:19008 [D loss: 0.792259, acc.: 44.53%] [G loss: 1.050544]\n",
      "epoch:20 step:19009 [D loss: 0.699243, acc.: 57.81%] [G loss: 1.146897]\n",
      "epoch:20 step:19010 [D loss: 0.786487, acc.: 50.78%] [G loss: 1.010105]\n",
      "epoch:20 step:19011 [D loss: 0.586359, acc.: 68.75%] [G loss: 1.011591]\n",
      "epoch:20 step:19012 [D loss: 0.652679, acc.: 59.38%] [G loss: 0.940023]\n",
      "epoch:20 step:19013 [D loss: 0.728187, acc.: 58.59%] [G loss: 1.326749]\n",
      "epoch:20 step:19014 [D loss: 0.669432, acc.: 59.38%] [G loss: 1.115969]\n",
      "epoch:20 step:19015 [D loss: 0.526634, acc.: 73.44%] [G loss: 1.009815]\n",
      "epoch:20 step:19016 [D loss: 0.662132, acc.: 59.38%] [G loss: 1.172040]\n",
      "epoch:20 step:19017 [D loss: 0.740216, acc.: 51.56%] [G loss: 1.178816]\n",
      "epoch:20 step:19018 [D loss: 0.316062, acc.: 87.50%] [G loss: 1.610271]\n",
      "epoch:20 step:19019 [D loss: 0.241124, acc.: 90.62%] [G loss: 1.275405]\n",
      "epoch:20 step:19020 [D loss: 0.568123, acc.: 72.66%] [G loss: 1.069832]\n",
      "epoch:20 step:19021 [D loss: 0.787332, acc.: 46.88%] [G loss: 1.097125]\n",
      "epoch:20 step:19022 [D loss: 0.765282, acc.: 50.78%] [G loss: 0.761616]\n",
      "epoch:20 step:19023 [D loss: 0.606863, acc.: 64.84%] [G loss: 1.120328]\n",
      "epoch:20 step:19024 [D loss: 0.414551, acc.: 88.28%] [G loss: 1.141919]\n",
      "epoch:20 step:19025 [D loss: 0.447508, acc.: 87.50%] [G loss: 1.013153]\n",
      "epoch:20 step:19026 [D loss: 0.442779, acc.: 85.16%] [G loss: 1.093857]\n",
      "epoch:20 step:19027 [D loss: 0.308675, acc.: 91.41%] [G loss: 1.215930]\n",
      "epoch:20 step:19028 [D loss: 0.340314, acc.: 87.50%] [G loss: 1.823867]\n",
      "epoch:20 step:19029 [D loss: 0.225612, acc.: 96.09%] [G loss: 1.564154]\n",
      "epoch:20 step:19030 [D loss: 0.329213, acc.: 91.41%] [G loss: 1.618335]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:20 step:19031 [D loss: 1.481575, acc.: 40.62%] [G loss: 1.819444]\n",
      "epoch:20 step:19032 [D loss: 0.364372, acc.: 88.28%] [G loss: 1.537298]\n",
      "epoch:20 step:19033 [D loss: 0.351412, acc.: 89.06%] [G loss: 1.806908]\n",
      "epoch:20 step:19034 [D loss: 0.887810, acc.: 56.25%] [G loss: 1.096895]\n",
      "epoch:20 step:19035 [D loss: 0.755655, acc.: 56.25%] [G loss: 1.365717]\n",
      "epoch:20 step:19036 [D loss: 0.708460, acc.: 59.38%] [G loss: 0.828400]\n",
      "epoch:20 step:19037 [D loss: 0.584866, acc.: 66.41%] [G loss: 1.130995]\n",
      "epoch:20 step:19038 [D loss: 0.611699, acc.: 69.53%] [G loss: 1.145659]\n",
      "epoch:20 step:19039 [D loss: 0.576684, acc.: 71.09%] [G loss: 1.217092]\n",
      "epoch:20 step:19040 [D loss: 0.643231, acc.: 64.06%] [G loss: 1.076215]\n",
      "epoch:20 step:19041 [D loss: 0.649232, acc.: 66.41%] [G loss: 1.080309]\n",
      "epoch:20 step:19042 [D loss: 0.552691, acc.: 78.12%] [G loss: 0.776909]\n",
      "epoch:20 step:19043 [D loss: 0.611754, acc.: 68.75%] [G loss: 0.477790]\n",
      "epoch:20 step:19044 [D loss: 0.616545, acc.: 67.97%] [G loss: 0.801456]\n",
      "epoch:20 step:19045 [D loss: 0.678606, acc.: 58.59%] [G loss: 0.611551]\n",
      "epoch:20 step:19046 [D loss: 0.493212, acc.: 80.47%] [G loss: 1.161806]\n",
      "epoch:20 step:19047 [D loss: 0.605953, acc.: 65.62%] [G loss: 1.130464]\n",
      "epoch:20 step:19048 [D loss: 0.571460, acc.: 71.88%] [G loss: 0.835314]\n",
      "epoch:20 step:19049 [D loss: 0.250378, acc.: 94.53%] [G loss: 1.233168]\n",
      "epoch:20 step:19050 [D loss: 0.682269, acc.: 59.38%] [G loss: 1.150395]\n",
      "epoch:20 step:19051 [D loss: 0.555261, acc.: 72.66%] [G loss: 0.937872]\n",
      "epoch:20 step:19052 [D loss: 0.210586, acc.: 94.53%] [G loss: 1.314707]\n",
      "epoch:20 step:19053 [D loss: 0.559081, acc.: 62.50%] [G loss: 1.322318]\n",
      "epoch:20 step:19054 [D loss: 0.187931, acc.: 98.44%] [G loss: 1.363964]\n",
      "epoch:20 step:19055 [D loss: 0.289819, acc.: 95.31%] [G loss: 1.585844]\n",
      "epoch:20 step:19056 [D loss: 0.709205, acc.: 55.47%] [G loss: 1.534419]\n",
      "epoch:20 step:19057 [D loss: 0.790164, acc.: 50.78%] [G loss: 1.200402]\n",
      "epoch:20 step:19058 [D loss: 0.677175, acc.: 56.25%] [G loss: 1.032772]\n",
      "epoch:20 step:19059 [D loss: 0.738313, acc.: 53.12%] [G loss: 1.125280]\n",
      "epoch:20 step:19060 [D loss: 0.592459, acc.: 67.97%] [G loss: 1.090701]\n",
      "epoch:20 step:19061 [D loss: 0.781139, acc.: 46.09%] [G loss: 1.124979]\n",
      "epoch:20 step:19062 [D loss: 0.585776, acc.: 73.44%] [G loss: 0.836202]\n",
      "epoch:20 step:19063 [D loss: 0.711162, acc.: 56.25%] [G loss: 1.018530]\n",
      "epoch:20 step:19064 [D loss: 0.663847, acc.: 59.38%] [G loss: 1.068529]\n",
      "epoch:20 step:19065 [D loss: 0.704962, acc.: 54.69%] [G loss: 1.088154]\n",
      "epoch:20 step:19066 [D loss: 0.603513, acc.: 67.97%] [G loss: 1.090566]\n",
      "epoch:20 step:19067 [D loss: 0.355304, acc.: 85.94%] [G loss: 1.041060]\n",
      "epoch:20 step:19068 [D loss: 0.329485, acc.: 94.53%] [G loss: 1.350479]\n",
      "epoch:20 step:19069 [D loss: 0.561049, acc.: 74.22%] [G loss: 1.091283]\n",
      "epoch:20 step:19070 [D loss: 0.841704, acc.: 41.41%] [G loss: 1.280049]\n",
      "epoch:20 step:19071 [D loss: 0.675627, acc.: 62.50%] [G loss: 1.038129]\n",
      "epoch:20 step:19072 [D loss: 0.589820, acc.: 67.19%] [G loss: 1.006945]\n",
      "epoch:20 step:19073 [D loss: 0.572209, acc.: 70.31%] [G loss: 1.053300]\n",
      "epoch:20 step:19074 [D loss: 0.326617, acc.: 92.19%] [G loss: 1.239269]\n",
      "epoch:20 step:19075 [D loss: 0.736358, acc.: 48.44%] [G loss: 0.917089]\n",
      "epoch:20 step:19076 [D loss: 0.299271, acc.: 96.09%] [G loss: 1.030575]\n",
      "epoch:20 step:19077 [D loss: 0.713092, acc.: 51.56%] [G loss: 1.137999]\n",
      "epoch:20 step:19078 [D loss: 0.721453, acc.: 46.09%] [G loss: 0.984460]\n",
      "epoch:20 step:19079 [D loss: 0.510148, acc.: 75.00%] [G loss: 1.095234]\n",
      "epoch:20 step:19080 [D loss: 0.818177, acc.: 39.06%] [G loss: 1.220843]\n",
      "epoch:20 step:19081 [D loss: 0.789429, acc.: 51.56%] [G loss: 1.011074]\n",
      "epoch:20 step:19082 [D loss: 0.443146, acc.: 78.12%] [G loss: 1.091595]\n",
      "epoch:20 step:19083 [D loss: 0.246621, acc.: 96.88%] [G loss: 1.245674]\n",
      "epoch:20 step:19084 [D loss: 0.289540, acc.: 96.09%] [G loss: 1.206036]\n",
      "epoch:20 step:19085 [D loss: 0.398780, acc.: 85.94%] [G loss: 1.177260]\n",
      "epoch:20 step:19086 [D loss: 0.281098, acc.: 89.06%] [G loss: 1.425620]\n",
      "epoch:20 step:19087 [D loss: 0.163981, acc.: 100.00%] [G loss: 1.535548]\n",
      "epoch:20 step:19088 [D loss: 0.824220, acc.: 53.12%] [G loss: 1.466957]\n",
      "epoch:20 step:19089 [D loss: 0.654356, acc.: 61.72%] [G loss: 1.439559]\n",
      "epoch:20 step:19090 [D loss: 0.600703, acc.: 67.19%] [G loss: 1.225512]\n",
      "epoch:20 step:19091 [D loss: 0.470598, acc.: 85.16%] [G loss: 1.249051]\n",
      "epoch:20 step:19092 [D loss: 0.388947, acc.: 87.50%] [G loss: 1.292192]\n",
      "epoch:20 step:19093 [D loss: 0.421111, acc.: 89.06%] [G loss: 1.327358]\n",
      "epoch:20 step:19094 [D loss: 0.394847, acc.: 88.28%] [G loss: 1.138977]\n",
      "epoch:20 step:19095 [D loss: 0.593392, acc.: 66.41%] [G loss: 1.277052]\n",
      "epoch:20 step:19096 [D loss: 0.617061, acc.: 64.06%] [G loss: 1.478148]\n",
      "epoch:20 step:19097 [D loss: 0.334417, acc.: 96.09%] [G loss: 1.023647]\n",
      "epoch:20 step:19098 [D loss: 0.315788, acc.: 93.75%] [G loss: 0.754669]\n",
      "epoch:20 step:19099 [D loss: 0.481159, acc.: 76.56%] [G loss: 1.166677]\n",
      "epoch:20 step:19100 [D loss: 0.477034, acc.: 82.03%] [G loss: 1.534546]\n",
      "epoch:20 step:19101 [D loss: 0.483272, acc.: 82.03%] [G loss: 1.376649]\n",
      "epoch:20 step:19102 [D loss: 0.799561, acc.: 45.31%] [G loss: 1.279349]\n",
      "epoch:20 step:19103 [D loss: 0.846315, acc.: 43.75%] [G loss: 1.305979]\n",
      "epoch:20 step:19104 [D loss: 0.599960, acc.: 64.06%] [G loss: 1.179360]\n",
      "epoch:20 step:19105 [D loss: 0.368461, acc.: 87.50%] [G loss: 1.380601]\n",
      "epoch:20 step:19106 [D loss: 0.231286, acc.: 96.09%] [G loss: 1.274439]\n",
      "epoch:20 step:19107 [D loss: 0.593922, acc.: 70.31%] [G loss: 1.264934]\n",
      "epoch:20 step:19108 [D loss: 0.800581, acc.: 52.34%] [G loss: 1.139708]\n",
      "epoch:20 step:19109 [D loss: 0.432928, acc.: 88.28%] [G loss: 1.042261]\n",
      "epoch:20 step:19110 [D loss: 0.477221, acc.: 74.22%] [G loss: 1.355222]\n",
      "epoch:20 step:19111 [D loss: 0.279409, acc.: 99.22%] [G loss: 1.257134]\n",
      "epoch:20 step:19112 [D loss: 0.577665, acc.: 68.75%] [G loss: 1.552810]\n",
      "epoch:20 step:19113 [D loss: 0.843119, acc.: 50.00%] [G loss: 1.363666]\n",
      "epoch:20 step:19114 [D loss: 0.767044, acc.: 52.34%] [G loss: 1.547508]\n",
      "epoch:20 step:19115 [D loss: 0.706390, acc.: 57.81%] [G loss: 0.893344]\n",
      "epoch:20 step:19116 [D loss: 0.822177, acc.: 44.53%] [G loss: 0.780270]\n",
      "epoch:20 step:19117 [D loss: 0.430840, acc.: 80.47%] [G loss: 0.965147]\n",
      "epoch:20 step:19118 [D loss: 0.340338, acc.: 89.06%] [G loss: 1.164049]\n",
      "epoch:20 step:19119 [D loss: 0.746760, acc.: 50.00%] [G loss: 1.364724]\n",
      "epoch:20 step:19120 [D loss: 0.314704, acc.: 88.28%] [G loss: 1.353302]\n",
      "epoch:20 step:19121 [D loss: 0.280621, acc.: 93.75%] [G loss: 1.511202]\n",
      "epoch:20 step:19122 [D loss: 0.606934, acc.: 64.06%] [G loss: 1.301402]\n",
      "epoch:20 step:19123 [D loss: 0.770652, acc.: 53.12%] [G loss: 1.269521]\n",
      "epoch:20 step:19124 [D loss: 0.756478, acc.: 41.41%] [G loss: 0.961058]\n",
      "epoch:20 step:19125 [D loss: 0.576004, acc.: 71.09%] [G loss: 1.279378]\n",
      "epoch:20 step:19126 [D loss: 0.583362, acc.: 67.97%] [G loss: 1.162326]\n",
      "epoch:20 step:19127 [D loss: 0.463024, acc.: 86.72%] [G loss: 0.890797]\n",
      "epoch:20 step:19128 [D loss: 0.629383, acc.: 60.16%] [G loss: 0.729600]\n",
      "epoch:20 step:19129 [D loss: 0.706256, acc.: 62.50%] [G loss: 0.886045]\n",
      "epoch:20 step:19130 [D loss: 0.667313, acc.: 60.94%] [G loss: 1.006482]\n",
      "epoch:20 step:19131 [D loss: 0.829094, acc.: 41.41%] [G loss: 1.204125]\n",
      "epoch:20 step:19132 [D loss: 0.902023, acc.: 34.38%] [G loss: 1.138322]\n",
      "epoch:20 step:19133 [D loss: 0.537353, acc.: 74.22%] [G loss: 1.151191]\n",
      "epoch:20 step:19134 [D loss: 0.698149, acc.: 57.03%] [G loss: 1.003521]\n",
      "epoch:20 step:19135 [D loss: 0.789484, acc.: 46.09%] [G loss: 1.025802]\n",
      "epoch:20 step:19136 [D loss: 0.352956, acc.: 79.69%] [G loss: 1.088865]\n",
      "epoch:20 step:19137 [D loss: 0.327401, acc.: 78.12%] [G loss: 1.546218]\n",
      "epoch:20 step:19138 [D loss: 0.189234, acc.: 97.66%] [G loss: 1.377025]\n",
      "epoch:20 step:19139 [D loss: 0.203955, acc.: 92.19%] [G loss: 1.434127]\n",
      "epoch:20 step:19140 [D loss: 0.431873, acc.: 82.81%] [G loss: 1.522187]\n",
      "epoch:20 step:19141 [D loss: 0.429250, acc.: 82.03%] [G loss: 1.541510]\n",
      "epoch:20 step:19142 [D loss: 0.224086, acc.: 93.75%] [G loss: 1.770501]\n",
      "epoch:20 step:19143 [D loss: 0.381279, acc.: 91.41%] [G loss: 1.416610]\n",
      "epoch:20 step:19144 [D loss: 0.604655, acc.: 64.84%] [G loss: 0.965701]\n",
      "epoch:20 step:19145 [D loss: 0.201913, acc.: 92.19%] [G loss: 1.505394]\n",
      "epoch:20 step:19146 [D loss: 0.223007, acc.: 95.31%] [G loss: 1.991435]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:20 step:19147 [D loss: 0.130374, acc.: 100.00%] [G loss: 1.605044]\n",
      "epoch:20 step:19148 [D loss: 0.367780, acc.: 89.06%] [G loss: 2.325913]\n",
      "epoch:20 step:19149 [D loss: 0.182757, acc.: 99.22%] [G loss: 1.443049]\n",
      "epoch:20 step:19150 [D loss: 0.311824, acc.: 92.97%] [G loss: 1.870465]\n",
      "epoch:20 step:19151 [D loss: 1.226855, acc.: 30.47%] [G loss: 1.019242]\n",
      "epoch:20 step:19152 [D loss: 0.337966, acc.: 85.16%] [G loss: 1.268690]\n",
      "epoch:20 step:19153 [D loss: 0.581468, acc.: 67.97%] [G loss: 1.936650]\n",
      "epoch:20 step:19154 [D loss: 0.436879, acc.: 82.81%] [G loss: 1.879187]\n",
      "epoch:20 step:19155 [D loss: 0.606703, acc.: 60.16%] [G loss: 1.592297]\n",
      "epoch:20 step:19156 [D loss: 0.505597, acc.: 73.44%] [G loss: 1.211409]\n",
      "epoch:20 step:19157 [D loss: 0.904625, acc.: 54.69%] [G loss: 0.543000]\n",
      "epoch:20 step:19158 [D loss: 0.151504, acc.: 100.00%] [G loss: 1.456069]\n",
      "epoch:20 step:19159 [D loss: 0.507682, acc.: 70.31%] [G loss: 1.959091]\n",
      "epoch:20 step:19160 [D loss: 0.869416, acc.: 43.75%] [G loss: 1.066363]\n",
      "epoch:20 step:19161 [D loss: 1.424608, acc.: 17.19%] [G loss: 2.045279]\n",
      "epoch:20 step:19162 [D loss: 1.278422, acc.: 21.09%] [G loss: 1.991596]\n",
      "epoch:20 step:19163 [D loss: 1.043645, acc.: 39.84%] [G loss: 1.824271]\n",
      "epoch:20 step:19164 [D loss: 0.308893, acc.: 91.41%] [G loss: 1.287586]\n",
      "epoch:20 step:19165 [D loss: 0.594228, acc.: 69.53%] [G loss: 1.197806]\n",
      "epoch:20 step:19166 [D loss: 0.990650, acc.: 36.72%] [G loss: 1.094213]\n",
      "epoch:20 step:19167 [D loss: 0.416884, acc.: 85.16%] [G loss: 0.458192]\n",
      "epoch:20 step:19168 [D loss: 0.281811, acc.: 91.41%] [G loss: 1.150953]\n",
      "epoch:20 step:19169 [D loss: 0.898303, acc.: 46.88%] [G loss: 1.154229]\n",
      "epoch:20 step:19170 [D loss: 0.312114, acc.: 90.62%] [G loss: 0.763154]\n",
      "epoch:20 step:19171 [D loss: 0.836160, acc.: 52.34%] [G loss: 1.128546]\n",
      "epoch:20 step:19172 [D loss: 1.320817, acc.: 17.19%] [G loss: 1.379901]\n",
      "epoch:20 step:19173 [D loss: 0.986266, acc.: 32.81%] [G loss: 1.943559]\n",
      "epoch:20 step:19174 [D loss: 0.836022, acc.: 53.91%] [G loss: 2.668545]\n",
      "epoch:20 step:19175 [D loss: 0.570744, acc.: 59.38%] [G loss: 1.767367]\n",
      "epoch:20 step:19176 [D loss: 0.623707, acc.: 61.72%] [G loss: 2.189058]\n",
      "epoch:20 step:19177 [D loss: 0.736686, acc.: 48.44%] [G loss: 1.797577]\n",
      "epoch:20 step:19178 [D loss: 0.927944, acc.: 51.56%] [G loss: 1.378382]\n",
      "epoch:20 step:19179 [D loss: 0.626037, acc.: 58.59%] [G loss: 1.115161]\n",
      "epoch:20 step:19180 [D loss: 0.678322, acc.: 58.59%] [G loss: 1.012661]\n",
      "epoch:20 step:19181 [D loss: 0.703776, acc.: 57.81%] [G loss: 1.313718]\n",
      "epoch:20 step:19182 [D loss: 0.766314, acc.: 56.25%] [G loss: 1.191458]\n",
      "epoch:20 step:19183 [D loss: 0.573642, acc.: 77.34%] [G loss: 1.084494]\n",
      "epoch:20 step:19184 [D loss: 0.600109, acc.: 69.53%] [G loss: 1.062980]\n",
      "epoch:20 step:19185 [D loss: 0.683490, acc.: 64.84%] [G loss: 1.009303]\n",
      "epoch:20 step:19186 [D loss: 0.674689, acc.: 59.38%] [G loss: 1.041121]\n",
      "epoch:20 step:19187 [D loss: 0.544150, acc.: 76.56%] [G loss: 0.926326]\n",
      "epoch:20 step:19188 [D loss: 0.392324, acc.: 88.28%] [G loss: 1.028545]\n",
      "epoch:20 step:19189 [D loss: 0.341674, acc.: 88.28%] [G loss: 1.150821]\n",
      "epoch:20 step:19190 [D loss: 0.351668, acc.: 91.41%] [G loss: 1.178832]\n",
      "epoch:20 step:19191 [D loss: 0.290664, acc.: 92.19%] [G loss: 1.253293]\n",
      "epoch:20 step:19192 [D loss: 0.259632, acc.: 97.66%] [G loss: 1.450293]\n",
      "epoch:20 step:19193 [D loss: 0.300613, acc.: 96.09%] [G loss: 1.317388]\n",
      "epoch:20 step:19194 [D loss: 0.300087, acc.: 96.88%] [G loss: 1.565314]\n",
      "epoch:20 step:19195 [D loss: 0.342786, acc.: 92.97%] [G loss: 1.141589]\n",
      "epoch:20 step:19196 [D loss: 0.275690, acc.: 95.31%] [G loss: 1.423170]\n",
      "epoch:20 step:19197 [D loss: 0.271207, acc.: 97.66%] [G loss: 1.671844]\n",
      "epoch:20 step:19198 [D loss: 0.644738, acc.: 67.97%] [G loss: 1.027663]\n",
      "epoch:20 step:19199 [D loss: 0.538719, acc.: 73.44%] [G loss: 0.974598]\n",
      "epoch:20 step:19200 [D loss: 0.816450, acc.: 42.19%] [G loss: 0.924039]\n",
      "##############\n",
      "[4.30674321 2.34102456 6.66522896 6.15072687 4.9815526  6.51804299\n",
      " 5.05588573 5.31286058 5.7171712  5.20103138]\n",
      "##########\n",
      "epoch:20 step:19201 [D loss: 0.753664, acc.: 53.91%] [G loss: 1.300319]\n",
      "epoch:20 step:19202 [D loss: 1.017278, acc.: 25.00%] [G loss: 0.923519]\n",
      "epoch:20 step:19203 [D loss: 0.656127, acc.: 64.84%] [G loss: 0.922226]\n",
      "epoch:20 step:19204 [D loss: 0.466086, acc.: 75.00%] [G loss: 1.022051]\n",
      "epoch:20 step:19205 [D loss: 0.543557, acc.: 65.62%] [G loss: 0.853098]\n",
      "epoch:20 step:19206 [D loss: 0.561209, acc.: 64.06%] [G loss: 0.719404]\n",
      "epoch:20 step:19207 [D loss: 0.452843, acc.: 82.03%] [G loss: 1.343630]\n",
      "epoch:20 step:19208 [D loss: 0.216068, acc.: 96.88%] [G loss: 1.161419]\n",
      "epoch:20 step:19209 [D loss: 0.309505, acc.: 85.94%] [G loss: 1.236030]\n",
      "epoch:20 step:19210 [D loss: 0.204398, acc.: 99.22%] [G loss: 1.631219]\n",
      "epoch:20 step:19211 [D loss: 0.124614, acc.: 100.00%] [G loss: 1.312213]\n",
      "epoch:20 step:19212 [D loss: 0.342130, acc.: 94.53%] [G loss: 1.070324]\n",
      "epoch:20 step:19213 [D loss: 1.280738, acc.: 32.81%] [G loss: 0.662657]\n",
      "epoch:20 step:19214 [D loss: 0.785728, acc.: 57.03%] [G loss: 0.882159]\n",
      "epoch:20 step:19215 [D loss: 0.897881, acc.: 46.88%] [G loss: 0.801117]\n",
      "epoch:20 step:19216 [D loss: 0.590985, acc.: 71.09%] [G loss: 0.673847]\n",
      "epoch:20 step:19217 [D loss: 0.696165, acc.: 60.94%] [G loss: 0.749134]\n",
      "epoch:20 step:19218 [D loss: 0.666023, acc.: 60.94%] [G loss: 0.991840]\n",
      "epoch:20 step:19219 [D loss: 0.486464, acc.: 67.19%] [G loss: 0.819505]\n",
      "epoch:20 step:19220 [D loss: 0.817503, acc.: 52.34%] [G loss: 1.073323]\n",
      "epoch:20 step:19221 [D loss: 0.653694, acc.: 60.94%] [G loss: 1.048627]\n",
      "epoch:20 step:19222 [D loss: 0.890391, acc.: 37.50%] [G loss: 1.240484]\n",
      "epoch:20 step:19223 [D loss: 0.673775, acc.: 53.12%] [G loss: 1.298099]\n",
      "epoch:20 step:19224 [D loss: 0.461405, acc.: 74.22%] [G loss: 1.546774]\n",
      "epoch:20 step:19225 [D loss: 0.646307, acc.: 59.38%] [G loss: 1.527754]\n",
      "epoch:20 step:19226 [D loss: 0.562018, acc.: 69.53%] [G loss: 1.603577]\n",
      "epoch:20 step:19227 [D loss: 0.534447, acc.: 75.00%] [G loss: 1.291009]\n",
      "epoch:20 step:19228 [D loss: 0.493652, acc.: 78.91%] [G loss: 1.603107]\n",
      "epoch:20 step:19229 [D loss: 0.761225, acc.: 55.47%] [G loss: 1.293750]\n",
      "epoch:20 step:19230 [D loss: 0.616983, acc.: 65.62%] [G loss: 1.182288]\n",
      "epoch:20 step:19231 [D loss: 0.720840, acc.: 54.69%] [G loss: 1.291799]\n",
      "epoch:20 step:19232 [D loss: 0.635423, acc.: 67.97%] [G loss: 1.073394]\n",
      "epoch:20 step:19233 [D loss: 0.590239, acc.: 68.75%] [G loss: 1.364066]\n",
      "epoch:20 step:19234 [D loss: 0.547301, acc.: 73.44%] [G loss: 1.336987]\n",
      "epoch:20 step:19235 [D loss: 0.745839, acc.: 50.00%] [G loss: 1.248250]\n",
      "epoch:20 step:19236 [D loss: 0.463817, acc.: 82.03%] [G loss: 1.394384]\n",
      "epoch:20 step:19237 [D loss: 0.329592, acc.: 89.06%] [G loss: 1.374009]\n",
      "epoch:20 step:19238 [D loss: 0.182872, acc.: 96.88%] [G loss: 1.527799]\n",
      "epoch:20 step:19239 [D loss: 0.216620, acc.: 95.31%] [G loss: 1.763891]\n",
      "epoch:20 step:19240 [D loss: 0.563690, acc.: 70.31%] [G loss: 1.632629]\n",
      "epoch:20 step:19241 [D loss: 0.523694, acc.: 72.66%] [G loss: 1.347419]\n",
      "epoch:20 step:19242 [D loss: 0.573463, acc.: 71.88%] [G loss: 1.404776]\n",
      "epoch:20 step:19243 [D loss: 0.830416, acc.: 53.12%] [G loss: 0.993862]\n",
      "epoch:20 step:19244 [D loss: 0.634339, acc.: 60.94%] [G loss: 1.110008]\n",
      "epoch:20 step:19245 [D loss: 0.650717, acc.: 58.59%] [G loss: 1.178769]\n",
      "epoch:20 step:19246 [D loss: 0.613896, acc.: 63.28%] [G loss: 1.106327]\n",
      "epoch:20 step:19247 [D loss: 0.637976, acc.: 60.16%] [G loss: 1.116172]\n",
      "epoch:20 step:19248 [D loss: 0.660889, acc.: 59.38%] [G loss: 1.125876]\n",
      "epoch:20 step:19249 [D loss: 0.564594, acc.: 70.31%] [G loss: 1.248098]\n",
      "epoch:20 step:19250 [D loss: 0.250086, acc.: 92.19%] [G loss: 1.477965]\n",
      "epoch:20 step:19251 [D loss: 0.275392, acc.: 88.28%] [G loss: 1.262995]\n",
      "epoch:20 step:19252 [D loss: 0.299981, acc.: 89.06%] [G loss: 1.570771]\n",
      "epoch:20 step:19253 [D loss: 0.184509, acc.: 98.44%] [G loss: 1.513223]\n",
      "epoch:20 step:19254 [D loss: 0.268624, acc.: 97.66%] [G loss: 1.655455]\n",
      "epoch:20 step:19255 [D loss: 0.301850, acc.: 96.09%] [G loss: 1.678104]\n",
      "epoch:20 step:19256 [D loss: 0.718122, acc.: 58.59%] [G loss: 1.379097]\n",
      "epoch:20 step:19257 [D loss: 0.467874, acc.: 77.34%] [G loss: 1.188286]\n",
      "epoch:20 step:19258 [D loss: 0.646405, acc.: 63.28%] [G loss: 1.207267]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:20 step:19259 [D loss: 0.671447, acc.: 62.50%] [G loss: 1.009724]\n",
      "epoch:20 step:19260 [D loss: 0.527813, acc.: 78.91%] [G loss: 1.034098]\n",
      "epoch:20 step:19261 [D loss: 0.570704, acc.: 74.22%] [G loss: 0.884066]\n",
      "epoch:20 step:19262 [D loss: 0.621022, acc.: 67.19%] [G loss: 1.033790]\n",
      "epoch:20 step:19263 [D loss: 0.532436, acc.: 76.56%] [G loss: 0.979349]\n",
      "epoch:20 step:19264 [D loss: 0.361850, acc.: 82.81%] [G loss: 1.029781]\n",
      "epoch:20 step:19265 [D loss: 0.715554, acc.: 55.47%] [G loss: 1.388055]\n",
      "epoch:20 step:19266 [D loss: 0.554953, acc.: 75.00%] [G loss: 0.974506]\n",
      "epoch:20 step:19267 [D loss: 0.294859, acc.: 87.50%] [G loss: 1.388508]\n",
      "epoch:20 step:19268 [D loss: 0.753219, acc.: 53.91%] [G loss: 1.045887]\n",
      "epoch:20 step:19269 [D loss: 0.550480, acc.: 75.00%] [G loss: 1.302668]\n",
      "epoch:20 step:19270 [D loss: 0.324408, acc.: 94.53%] [G loss: 1.410746]\n",
      "epoch:20 step:19271 [D loss: 0.739735, acc.: 54.69%] [G loss: 1.127441]\n",
      "epoch:20 step:19272 [D loss: 0.591198, acc.: 67.97%] [G loss: 0.939377]\n",
      "epoch:20 step:19273 [D loss: 0.535981, acc.: 72.66%] [G loss: 1.340007]\n",
      "epoch:20 step:19274 [D loss: 0.632467, acc.: 61.72%] [G loss: 1.102587]\n",
      "epoch:20 step:19275 [D loss: 0.305223, acc.: 86.72%] [G loss: 1.203481]\n",
      "epoch:20 step:19276 [D loss: 0.207384, acc.: 95.31%] [G loss: 1.453165]\n",
      "epoch:20 step:19277 [D loss: 0.209941, acc.: 98.44%] [G loss: 1.446943]\n",
      "epoch:20 step:19278 [D loss: 0.449539, acc.: 82.03%] [G loss: 1.465791]\n",
      "epoch:20 step:19279 [D loss: 0.390487, acc.: 91.41%] [G loss: 0.755099]\n",
      "epoch:20 step:19280 [D loss: 0.443324, acc.: 83.59%] [G loss: 1.452576]\n",
      "epoch:20 step:19281 [D loss: 0.372426, acc.: 92.19%] [G loss: 0.725931]\n",
      "epoch:20 step:19282 [D loss: 0.766948, acc.: 49.22%] [G loss: 1.166102]\n",
      "epoch:20 step:19283 [D loss: 0.508763, acc.: 77.34%] [G loss: 0.958279]\n",
      "epoch:20 step:19284 [D loss: 0.726932, acc.: 56.25%] [G loss: 1.242545]\n",
      "epoch:20 step:19285 [D loss: 0.656308, acc.: 61.72%] [G loss: 1.226165]\n",
      "epoch:20 step:19286 [D loss: 0.595264, acc.: 64.84%] [G loss: 0.914084]\n",
      "epoch:20 step:19287 [D loss: 0.446439, acc.: 82.03%] [G loss: 0.961565]\n",
      "epoch:20 step:19288 [D loss: 0.506959, acc.: 75.78%] [G loss: 1.222659]\n",
      "epoch:20 step:19289 [D loss: 0.401825, acc.: 84.38%] [G loss: 1.405064]\n",
      "epoch:20 step:19290 [D loss: 0.282129, acc.: 97.66%] [G loss: 1.442745]\n",
      "epoch:20 step:19291 [D loss: 0.599987, acc.: 66.41%] [G loss: 1.587875]\n",
      "epoch:20 step:19292 [D loss: 0.340989, acc.: 93.75%] [G loss: 1.393048]\n",
      "epoch:20 step:19293 [D loss: 0.901356, acc.: 39.84%] [G loss: 1.365020]\n",
      "epoch:20 step:19294 [D loss: 0.265334, acc.: 92.19%] [G loss: 1.158754]\n",
      "epoch:20 step:19295 [D loss: 0.421110, acc.: 86.72%] [G loss: 1.522856]\n",
      "epoch:20 step:19296 [D loss: 0.344979, acc.: 87.50%] [G loss: 0.790158]\n",
      "epoch:20 step:19297 [D loss: 0.461454, acc.: 80.47%] [G loss: 1.723591]\n",
      "epoch:20 step:19298 [D loss: 0.371957, acc.: 91.41%] [G loss: 1.616936]\n",
      "epoch:20 step:19299 [D loss: 0.250275, acc.: 92.97%] [G loss: 0.897002]\n",
      "epoch:20 step:19300 [D loss: 1.023746, acc.: 32.81%] [G loss: 1.103315]\n",
      "epoch:20 step:19301 [D loss: 0.218756, acc.: 96.09%] [G loss: 1.566196]\n",
      "epoch:20 step:19302 [D loss: 0.936827, acc.: 54.69%] [G loss: 1.619444]\n",
      "epoch:20 step:19303 [D loss: 0.886211, acc.: 50.78%] [G loss: 1.107437]\n",
      "epoch:20 step:19304 [D loss: 0.808788, acc.: 44.53%] [G loss: 1.006987]\n",
      "epoch:20 step:19305 [D loss: 0.586104, acc.: 69.53%] [G loss: 1.266957]\n",
      "epoch:20 step:19306 [D loss: 0.264634, acc.: 89.06%] [G loss: 1.964828]\n",
      "epoch:20 step:19307 [D loss: 0.173196, acc.: 95.31%] [G loss: 1.637620]\n",
      "epoch:20 step:19308 [D loss: 0.227387, acc.: 98.44%] [G loss: 1.692826]\n",
      "epoch:20 step:19309 [D loss: 0.617172, acc.: 61.72%] [G loss: 1.640702]\n",
      "epoch:20 step:19310 [D loss: 0.422538, acc.: 82.03%] [G loss: 1.764233]\n",
      "epoch:20 step:19311 [D loss: 0.482170, acc.: 77.34%] [G loss: 1.491902]\n",
      "epoch:20 step:19312 [D loss: 0.510556, acc.: 75.00%] [G loss: 1.569672]\n",
      "epoch:20 step:19313 [D loss: 0.402264, acc.: 87.50%] [G loss: 1.572046]\n",
      "epoch:20 step:19314 [D loss: 0.384648, acc.: 85.94%] [G loss: 0.968382]\n",
      "epoch:20 step:19315 [D loss: 0.365982, acc.: 89.06%] [G loss: 1.340511]\n",
      "epoch:20 step:19316 [D loss: 0.279919, acc.: 94.53%] [G loss: 2.008702]\n",
      "epoch:20 step:19317 [D loss: 0.146920, acc.: 99.22%] [G loss: 2.075608]\n",
      "epoch:20 step:19318 [D loss: 0.097819, acc.: 100.00%] [G loss: 1.960688]\n",
      "epoch:20 step:19319 [D loss: 0.143011, acc.: 99.22%] [G loss: 2.433789]\n",
      "epoch:20 step:19320 [D loss: 0.781780, acc.: 50.78%] [G loss: 1.661326]\n",
      "epoch:20 step:19321 [D loss: 0.688791, acc.: 59.38%] [G loss: 1.294667]\n",
      "epoch:20 step:19322 [D loss: 0.638603, acc.: 57.03%] [G loss: 0.958788]\n",
      "epoch:20 step:19323 [D loss: 0.800743, acc.: 45.31%] [G loss: 1.524926]\n",
      "epoch:20 step:19324 [D loss: 0.835823, acc.: 48.44%] [G loss: 0.411670]\n",
      "epoch:20 step:19325 [D loss: 0.827731, acc.: 47.66%] [G loss: 1.030998]\n",
      "epoch:20 step:19326 [D loss: 0.574862, acc.: 72.66%] [G loss: 1.258716]\n",
      "epoch:20 step:19327 [D loss: 0.335293, acc.: 77.34%] [G loss: 1.004472]\n",
      "epoch:20 step:19328 [D loss: 0.231107, acc.: 92.19%] [G loss: 1.650699]\n",
      "epoch:20 step:19329 [D loss: 0.142077, acc.: 98.44%] [G loss: 2.420204]\n",
      "epoch:20 step:19330 [D loss: 0.254450, acc.: 95.31%] [G loss: 0.961829]\n",
      "epoch:20 step:19331 [D loss: 1.039351, acc.: 49.22%] [G loss: 1.359071]\n",
      "epoch:20 step:19332 [D loss: 0.912459, acc.: 48.44%] [G loss: 1.105661]\n",
      "epoch:20 step:19333 [D loss: 0.620020, acc.: 65.62%] [G loss: 0.729439]\n",
      "epoch:20 step:19334 [D loss: 0.559532, acc.: 67.97%] [G loss: 1.334814]\n",
      "epoch:20 step:19335 [D loss: 0.262931, acc.: 88.28%] [G loss: 1.585960]\n",
      "epoch:20 step:19336 [D loss: 0.890927, acc.: 46.88%] [G loss: 1.293140]\n",
      "epoch:20 step:19337 [D loss: 0.681911, acc.: 60.94%] [G loss: 1.154168]\n",
      "epoch:20 step:19338 [D loss: 0.854347, acc.: 42.19%] [G loss: 1.281573]\n",
      "epoch:20 step:19339 [D loss: 0.727672, acc.: 51.56%] [G loss: 0.590608]\n",
      "epoch:20 step:19340 [D loss: 0.384682, acc.: 72.66%] [G loss: 1.019207]\n",
      "epoch:20 step:19341 [D loss: 0.436012, acc.: 75.78%] [G loss: 0.772320]\n",
      "epoch:20 step:19342 [D loss: 0.292910, acc.: 88.28%] [G loss: 1.770567]\n",
      "epoch:20 step:19343 [D loss: 0.944590, acc.: 43.75%] [G loss: 1.643568]\n",
      "epoch:20 step:19344 [D loss: 0.874261, acc.: 52.34%] [G loss: 1.739839]\n",
      "epoch:20 step:19345 [D loss: 0.924467, acc.: 37.50%] [G loss: 1.691249]\n",
      "epoch:20 step:19346 [D loss: 0.556298, acc.: 73.44%] [G loss: 1.102996]\n",
      "epoch:20 step:19347 [D loss: 0.737500, acc.: 50.00%] [G loss: 1.062222]\n",
      "epoch:20 step:19348 [D loss: 0.522414, acc.: 75.00%] [G loss: 0.936826]\n",
      "epoch:20 step:19349 [D loss: 0.305075, acc.: 88.28%] [G loss: 0.832932]\n",
      "epoch:20 step:19350 [D loss: 1.031612, acc.: 26.56%] [G loss: 1.391696]\n",
      "epoch:20 step:19351 [D loss: 0.593019, acc.: 66.41%] [G loss: 0.975276]\n",
      "epoch:20 step:19352 [D loss: 0.604656, acc.: 65.62%] [G loss: 1.084211]\n",
      "epoch:20 step:19353 [D loss: 0.749088, acc.: 54.69%] [G loss: 1.082159]\n",
      "epoch:20 step:19354 [D loss: 0.862651, acc.: 41.41%] [G loss: 1.020489]\n",
      "epoch:20 step:19355 [D loss: 1.106146, acc.: 28.12%] [G loss: 1.362665]\n",
      "epoch:20 step:19356 [D loss: 0.531882, acc.: 65.62%] [G loss: 1.931679]\n",
      "epoch:20 step:19357 [D loss: 0.557684, acc.: 64.84%] [G loss: 1.776997]\n",
      "epoch:20 step:19358 [D loss: 0.696714, acc.: 59.38%] [G loss: 1.656415]\n",
      "epoch:20 step:19359 [D loss: 0.579387, acc.: 64.84%] [G loss: 1.263873]\n",
      "epoch:20 step:19360 [D loss: 0.666240, acc.: 57.81%] [G loss: 1.022395]\n",
      "epoch:20 step:19361 [D loss: 0.620697, acc.: 65.62%] [G loss: 1.319384]\n",
      "epoch:20 step:19362 [D loss: 0.540855, acc.: 80.47%] [G loss: 1.146472]\n",
      "epoch:20 step:19363 [D loss: 0.509761, acc.: 79.69%] [G loss: 1.233538]\n",
      "epoch:20 step:19364 [D loss: 0.471310, acc.: 82.03%] [G loss: 1.446724]\n",
      "epoch:20 step:19365 [D loss: 0.608195, acc.: 68.75%] [G loss: 1.205601]\n",
      "epoch:20 step:19366 [D loss: 0.528045, acc.: 78.91%] [G loss: 1.320306]\n",
      "epoch:20 step:19367 [D loss: 0.559245, acc.: 71.09%] [G loss: 1.317984]\n",
      "epoch:20 step:19368 [D loss: 0.588894, acc.: 69.53%] [G loss: 1.046762]\n",
      "epoch:20 step:19369 [D loss: 0.513210, acc.: 76.56%] [G loss: 1.258104]\n",
      "epoch:20 step:19370 [D loss: 0.308516, acc.: 96.88%] [G loss: 1.284505]\n",
      "epoch:20 step:19371 [D loss: 0.750708, acc.: 56.25%] [G loss: 1.115877]\n",
      "epoch:20 step:19372 [D loss: 0.426507, acc.: 84.38%] [G loss: 1.151015]\n",
      "epoch:20 step:19373 [D loss: 0.288395, acc.: 94.53%] [G loss: 1.276847]\n",
      "epoch:20 step:19374 [D loss: 0.396522, acc.: 86.72%] [G loss: 1.401721]\n",
      "epoch:20 step:19375 [D loss: 0.374336, acc.: 90.62%] [G loss: 1.283589]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:20 step:19376 [D loss: 0.509534, acc.: 75.78%] [G loss: 1.297002]\n",
      "epoch:20 step:19377 [D loss: 0.426272, acc.: 86.72%] [G loss: 1.339490]\n",
      "epoch:20 step:19378 [D loss: 0.557900, acc.: 75.00%] [G loss: 1.196947]\n",
      "epoch:20 step:19379 [D loss: 1.107999, acc.: 39.06%] [G loss: 1.250171]\n",
      "epoch:20 step:19380 [D loss: 0.969222, acc.: 35.94%] [G loss: 0.952314]\n",
      "epoch:20 step:19381 [D loss: 0.550811, acc.: 66.41%] [G loss: 0.858130]\n",
      "epoch:20 step:19382 [D loss: 0.826007, acc.: 46.88%] [G loss: 1.237246]\n",
      "epoch:20 step:19383 [D loss: 0.607032, acc.: 68.75%] [G loss: 0.908390]\n",
      "epoch:20 step:19384 [D loss: 0.412304, acc.: 83.59%] [G loss: 1.087033]\n",
      "epoch:20 step:19385 [D loss: 0.383417, acc.: 83.59%] [G loss: 1.110350]\n",
      "epoch:20 step:19386 [D loss: 0.306855, acc.: 85.16%] [G loss: 1.108781]\n",
      "epoch:20 step:19387 [D loss: 0.332482, acc.: 87.50%] [G loss: 1.052089]\n",
      "epoch:20 step:19388 [D loss: 0.375724, acc.: 83.59%] [G loss: 1.597272]\n",
      "epoch:20 step:19389 [D loss: 0.346230, acc.: 92.97%] [G loss: 1.620333]\n",
      "epoch:20 step:19390 [D loss: 0.294496, acc.: 89.84%] [G loss: 1.462760]\n",
      "epoch:20 step:19391 [D loss: 0.450886, acc.: 82.81%] [G loss: 1.662744]\n",
      "epoch:20 step:19392 [D loss: 0.599974, acc.: 70.31%] [G loss: 1.045915]\n",
      "epoch:20 step:19393 [D loss: 0.703630, acc.: 57.81%] [G loss: 0.838457]\n",
      "epoch:20 step:19394 [D loss: 0.862582, acc.: 46.09%] [G loss: 1.489048]\n",
      "epoch:20 step:19395 [D loss: 0.559175, acc.: 75.00%] [G loss: 1.066339]\n",
      "epoch:20 step:19396 [D loss: 0.600951, acc.: 66.41%] [G loss: 1.148560]\n",
      "epoch:20 step:19397 [D loss: 0.689626, acc.: 56.25%] [G loss: 0.809509]\n",
      "epoch:20 step:19398 [D loss: 0.670976, acc.: 64.06%] [G loss: 1.024378]\n",
      "epoch:20 step:19399 [D loss: 0.385705, acc.: 83.59%] [G loss: 0.935085]\n",
      "epoch:20 step:19400 [D loss: 0.577333, acc.: 63.28%] [G loss: 1.253950]\n",
      "##############\n",
      "[3.79142372 2.82978348 6.64955377 5.80094826 4.86158846 6.62815017\n",
      " 5.38927902 5.69580091 5.52869595 5.28137633]\n",
      "##########\n",
      "epoch:20 step:19401 [D loss: 0.458225, acc.: 78.12%] [G loss: 0.788254]\n",
      "epoch:20 step:19402 [D loss: 0.631198, acc.: 61.72%] [G loss: 0.831013]\n",
      "epoch:20 step:19403 [D loss: 0.660672, acc.: 58.59%] [G loss: 0.978192]\n",
      "epoch:20 step:19404 [D loss: 0.471453, acc.: 76.56%] [G loss: 1.444729]\n",
      "epoch:20 step:19405 [D loss: 0.237693, acc.: 92.97%] [G loss: 1.750635]\n",
      "epoch:20 step:19406 [D loss: 0.688668, acc.: 62.50%] [G loss: 1.492246]\n",
      "epoch:20 step:19407 [D loss: 0.686750, acc.: 59.38%] [G loss: 1.210892]\n",
      "epoch:20 step:19408 [D loss: 0.888083, acc.: 39.84%] [G loss: 1.248611]\n",
      "epoch:20 step:19409 [D loss: 0.554923, acc.: 68.75%] [G loss: 1.499121]\n",
      "epoch:20 step:19410 [D loss: 0.650614, acc.: 64.06%] [G loss: 1.316166]\n",
      "epoch:20 step:19411 [D loss: 0.611794, acc.: 66.41%] [G loss: 1.135299]\n",
      "epoch:20 step:19412 [D loss: 0.690326, acc.: 60.16%] [G loss: 1.069236]\n",
      "epoch:20 step:19413 [D loss: 0.752722, acc.: 48.44%] [G loss: 0.863473]\n",
      "epoch:20 step:19414 [D loss: 0.866617, acc.: 53.91%] [G loss: 1.052965]\n",
      "epoch:20 step:19415 [D loss: 0.732457, acc.: 50.00%] [G loss: 1.092467]\n",
      "epoch:20 step:19416 [D loss: 0.609977, acc.: 70.31%] [G loss: 1.070980]\n",
      "epoch:20 step:19417 [D loss: 0.625550, acc.: 62.50%] [G loss: 1.003826]\n",
      "epoch:20 step:19418 [D loss: 0.780999, acc.: 48.44%] [G loss: 0.986060]\n",
      "epoch:20 step:19419 [D loss: 0.576126, acc.: 75.00%] [G loss: 0.999762]\n",
      "epoch:20 step:19420 [D loss: 0.585421, acc.: 67.97%] [G loss: 1.031494]\n",
      "epoch:20 step:19421 [D loss: 0.560480, acc.: 70.31%] [G loss: 0.865797]\n",
      "epoch:20 step:19422 [D loss: 0.634941, acc.: 61.72%] [G loss: 1.139771]\n",
      "epoch:20 step:19423 [D loss: 0.625904, acc.: 60.94%] [G loss: 0.994417]\n",
      "epoch:20 step:19424 [D loss: 0.537403, acc.: 75.00%] [G loss: 1.052497]\n",
      "epoch:20 step:19425 [D loss: 0.600936, acc.: 63.28%] [G loss: 1.054935]\n",
      "epoch:20 step:19426 [D loss: 0.584317, acc.: 70.31%] [G loss: 1.160491]\n",
      "epoch:20 step:19427 [D loss: 0.584293, acc.: 68.75%] [G loss: 1.070230]\n",
      "epoch:20 step:19428 [D loss: 0.678086, acc.: 54.69%] [G loss: 0.922094]\n",
      "epoch:20 step:19429 [D loss: 0.781707, acc.: 46.09%] [G loss: 0.948936]\n",
      "epoch:20 step:19430 [D loss: 0.619939, acc.: 65.62%] [G loss: 0.968146]\n",
      "epoch:20 step:19431 [D loss: 0.683493, acc.: 54.69%] [G loss: 0.999195]\n",
      "epoch:20 step:19432 [D loss: 0.608876, acc.: 69.53%] [G loss: 0.878130]\n",
      "epoch:20 step:19433 [D loss: 0.520084, acc.: 77.34%] [G loss: 0.922101]\n",
      "epoch:20 step:19434 [D loss: 0.485221, acc.: 78.12%] [G loss: 1.131835]\n",
      "epoch:20 step:19435 [D loss: 0.662994, acc.: 63.28%] [G loss: 0.981414]\n",
      "epoch:20 step:19436 [D loss: 0.326701, acc.: 85.94%] [G loss: 0.983835]\n",
      "epoch:20 step:19437 [D loss: 0.350399, acc.: 86.72%] [G loss: 1.073699]\n",
      "epoch:20 step:19438 [D loss: 0.353374, acc.: 89.06%] [G loss: 1.254493]\n",
      "epoch:20 step:19439 [D loss: 0.613601, acc.: 67.19%] [G loss: 1.143210]\n",
      "epoch:20 step:19440 [D loss: 0.253210, acc.: 98.44%] [G loss: 1.296575]\n",
      "epoch:20 step:19441 [D loss: 0.262225, acc.: 89.84%] [G loss: 1.544893]\n",
      "epoch:20 step:19442 [D loss: 0.255301, acc.: 96.88%] [G loss: 1.516550]\n",
      "epoch:20 step:19443 [D loss: 0.760138, acc.: 50.78%] [G loss: 1.282060]\n",
      "epoch:20 step:19444 [D loss: 0.470602, acc.: 82.81%] [G loss: 1.342737]\n",
      "epoch:20 step:19445 [D loss: 0.742018, acc.: 56.25%] [G loss: 1.216989]\n",
      "epoch:20 step:19446 [D loss: 0.298226, acc.: 89.84%] [G loss: 1.320536]\n",
      "epoch:20 step:19447 [D loss: 0.238234, acc.: 92.19%] [G loss: 1.351959]\n",
      "epoch:20 step:19448 [D loss: 0.212559, acc.: 95.31%] [G loss: 1.528499]\n",
      "epoch:20 step:19449 [D loss: 0.168707, acc.: 99.22%] [G loss: 1.780904]\n",
      "epoch:20 step:19450 [D loss: 0.800963, acc.: 53.91%] [G loss: 1.317088]\n",
      "epoch:20 step:19451 [D loss: 0.647518, acc.: 62.50%] [G loss: 1.209609]\n",
      "epoch:20 step:19452 [D loss: 0.596745, acc.: 64.06%] [G loss: 1.300405]\n",
      "epoch:20 step:19453 [D loss: 0.218028, acc.: 93.75%] [G loss: 1.542547]\n",
      "epoch:20 step:19454 [D loss: 0.241201, acc.: 91.41%] [G loss: 2.165645]\n",
      "epoch:20 step:19455 [D loss: 0.775473, acc.: 55.47%] [G loss: 1.504133]\n",
      "epoch:20 step:19456 [D loss: 0.788779, acc.: 54.69%] [G loss: 1.354525]\n",
      "epoch:20 step:19457 [D loss: 0.663090, acc.: 60.16%] [G loss: 1.246592]\n",
      "epoch:20 step:19458 [D loss: 0.668811, acc.: 57.03%] [G loss: 1.260760]\n",
      "epoch:20 step:19459 [D loss: 0.644167, acc.: 64.84%] [G loss: 1.176460]\n",
      "epoch:20 step:19460 [D loss: 0.628496, acc.: 67.97%] [G loss: 1.046645]\n",
      "epoch:20 step:19461 [D loss: 0.708020, acc.: 58.59%] [G loss: 1.034812]\n",
      "epoch:20 step:19462 [D loss: 0.504193, acc.: 70.31%] [G loss: 1.144293]\n",
      "epoch:20 step:19463 [D loss: 0.312123, acc.: 91.41%] [G loss: 1.262877]\n",
      "epoch:20 step:19464 [D loss: 0.757405, acc.: 48.44%] [G loss: 1.256257]\n",
      "epoch:20 step:19465 [D loss: 0.766554, acc.: 52.34%] [G loss: 0.926000]\n",
      "epoch:20 step:19466 [D loss: 0.803128, acc.: 45.31%] [G loss: 1.122450]\n",
      "epoch:20 step:19467 [D loss: 0.271537, acc.: 92.97%] [G loss: 1.231605]\n",
      "epoch:20 step:19468 [D loss: 0.235823, acc.: 92.97%] [G loss: 1.226775]\n",
      "epoch:20 step:19469 [D loss: 0.154353, acc.: 98.44%] [G loss: 1.210636]\n",
      "epoch:20 step:19470 [D loss: 0.297523, acc.: 84.38%] [G loss: 1.455906]\n",
      "epoch:20 step:19471 [D loss: 0.157484, acc.: 98.44%] [G loss: 1.814693]\n",
      "epoch:20 step:19472 [D loss: 0.159518, acc.: 96.88%] [G loss: 1.812474]\n",
      "epoch:20 step:19473 [D loss: 0.100368, acc.: 100.00%] [G loss: 1.854118]\n",
      "epoch:20 step:19474 [D loss: 0.493005, acc.: 74.22%] [G loss: 1.956630]\n",
      "epoch:20 step:19475 [D loss: 0.857454, acc.: 48.44%] [G loss: 1.406233]\n",
      "epoch:20 step:19476 [D loss: 0.779504, acc.: 51.56%] [G loss: 1.381871]\n",
      "epoch:20 step:19477 [D loss: 0.440879, acc.: 85.94%] [G loss: 1.233427]\n",
      "epoch:20 step:19478 [D loss: 0.389606, acc.: 91.41%] [G loss: 1.286107]\n",
      "epoch:20 step:19479 [D loss: 0.261243, acc.: 87.50%] [G loss: 1.354479]\n",
      "epoch:20 step:19480 [D loss: 0.283793, acc.: 85.16%] [G loss: 1.457133]\n",
      "epoch:20 step:19481 [D loss: 0.966887, acc.: 39.06%] [G loss: 1.167664]\n",
      "epoch:20 step:19482 [D loss: 0.812676, acc.: 49.22%] [G loss: 1.331424]\n",
      "epoch:20 step:19483 [D loss: 0.891385, acc.: 41.41%] [G loss: 1.127570]\n",
      "epoch:20 step:19484 [D loss: 0.625840, acc.: 69.53%] [G loss: 0.441416]\n",
      "epoch:20 step:19485 [D loss: 0.214611, acc.: 97.66%] [G loss: 1.256778]\n",
      "epoch:20 step:19486 [D loss: 0.173326, acc.: 99.22%] [G loss: 1.238863]\n",
      "epoch:20 step:19487 [D loss: 0.398626, acc.: 92.19%] [G loss: 1.342424]\n",
      "epoch:20 step:19488 [D loss: 1.066080, acc.: 22.66%] [G loss: 1.214149]\n",
      "epoch:20 step:19489 [D loss: 0.711107, acc.: 57.81%] [G loss: 1.347292]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:20 step:19490 [D loss: 0.671062, acc.: 60.94%] [G loss: 1.319833]\n",
      "epoch:20 step:19491 [D loss: 0.490421, acc.: 80.47%] [G loss: 1.133762]\n",
      "epoch:20 step:19492 [D loss: 0.323239, acc.: 91.41%] [G loss: 1.248578]\n",
      "epoch:20 step:19493 [D loss: 0.401810, acc.: 88.28%] [G loss: 1.332194]\n",
      "epoch:20 step:19494 [D loss: 0.193855, acc.: 98.44%] [G loss: 1.263422]\n",
      "epoch:20 step:19495 [D loss: 0.364608, acc.: 77.34%] [G loss: 1.615298]\n",
      "epoch:20 step:19496 [D loss: 0.158180, acc.: 96.88%] [G loss: 1.752672]\n",
      "epoch:20 step:19497 [D loss: 0.231449, acc.: 96.88%] [G loss: 1.599544]\n",
      "epoch:20 step:19498 [D loss: 0.582852, acc.: 70.31%] [G loss: 1.645691]\n",
      "epoch:20 step:19499 [D loss: 0.875747, acc.: 52.34%] [G loss: 1.557769]\n",
      "epoch:20 step:19500 [D loss: 0.918945, acc.: 43.75%] [G loss: 1.091812]\n",
      "epoch:20 step:19501 [D loss: 0.631387, acc.: 63.28%] [G loss: 1.280030]\n",
      "epoch:20 step:19502 [D loss: 0.210497, acc.: 93.75%] [G loss: 1.510841]\n",
      "epoch:20 step:19503 [D loss: 0.209780, acc.: 100.00%] [G loss: 1.370067]\n",
      "epoch:20 step:19504 [D loss: 0.173141, acc.: 98.44%] [G loss: 1.463791]\n",
      "epoch:20 step:19505 [D loss: 0.828174, acc.: 51.56%] [G loss: 0.931173]\n",
      "epoch:20 step:19506 [D loss: 1.052554, acc.: 30.47%] [G loss: 1.057846]\n",
      "epoch:20 step:19507 [D loss: 0.721621, acc.: 58.59%] [G loss: 1.173052]\n",
      "epoch:20 step:19508 [D loss: 0.709338, acc.: 57.81%] [G loss: 1.127690]\n",
      "epoch:20 step:19509 [D loss: 0.760741, acc.: 51.56%] [G loss: 0.939007]\n",
      "epoch:20 step:19510 [D loss: 0.509579, acc.: 74.22%] [G loss: 1.028105]\n",
      "epoch:20 step:19511 [D loss: 0.495564, acc.: 82.81%] [G loss: 0.877868]\n",
      "epoch:20 step:19512 [D loss: 0.808689, acc.: 34.38%] [G loss: 0.974484]\n",
      "epoch:20 step:19513 [D loss: 0.558380, acc.: 73.44%] [G loss: 0.628156]\n",
      "epoch:20 step:19514 [D loss: 0.497801, acc.: 78.91%] [G loss: 0.824408]\n",
      "epoch:20 step:19515 [D loss: 0.613103, acc.: 65.62%] [G loss: 0.267785]\n",
      "epoch:20 step:19516 [D loss: 0.627792, acc.: 67.97%] [G loss: 0.370237]\n",
      "epoch:20 step:19517 [D loss: 0.890347, acc.: 37.50%] [G loss: 1.090284]\n",
      "epoch:20 step:19518 [D loss: 1.018450, acc.: 22.66%] [G loss: 1.125186]\n",
      "epoch:20 step:19519 [D loss: 0.403419, acc.: 89.84%] [G loss: 1.457152]\n",
      "epoch:20 step:19520 [D loss: 0.446174, acc.: 67.19%] [G loss: 0.938612]\n",
      "epoch:20 step:19521 [D loss: 0.247688, acc.: 89.84%] [G loss: 0.644387]\n",
      "epoch:20 step:19522 [D loss: 0.507261, acc.: 71.88%] [G loss: 1.607183]\n",
      "epoch:20 step:19523 [D loss: 0.651865, acc.: 61.72%] [G loss: 1.659312]\n",
      "epoch:20 step:19524 [D loss: 0.947120, acc.: 40.62%] [G loss: 1.525420]\n",
      "epoch:20 step:19525 [D loss: 0.699712, acc.: 60.94%] [G loss: 1.514570]\n",
      "epoch:20 step:19526 [D loss: 0.278659, acc.: 95.31%] [G loss: 1.268105]\n",
      "epoch:20 step:19527 [D loss: 0.850123, acc.: 44.53%] [G loss: 1.426402]\n",
      "epoch:20 step:19528 [D loss: 0.665804, acc.: 58.59%] [G loss: 1.189891]\n",
      "epoch:20 step:19529 [D loss: 1.070952, acc.: 25.00%] [G loss: 1.096636]\n",
      "epoch:20 step:19530 [D loss: 0.839645, acc.: 43.75%] [G loss: 1.043725]\n",
      "epoch:20 step:19531 [D loss: 0.314042, acc.: 89.06%] [G loss: 1.209986]\n",
      "epoch:20 step:19532 [D loss: 0.343318, acc.: 92.19%] [G loss: 1.270093]\n",
      "epoch:20 step:19533 [D loss: 0.429470, acc.: 85.16%] [G loss: 1.279141]\n",
      "epoch:20 step:19534 [D loss: 0.458165, acc.: 80.47%] [G loss: 1.288875]\n",
      "epoch:20 step:19535 [D loss: 0.550296, acc.: 70.31%] [G loss: 1.423541]\n",
      "epoch:20 step:19536 [D loss: 0.676298, acc.: 58.59%] [G loss: 1.367086]\n",
      "epoch:20 step:19537 [D loss: 0.806518, acc.: 46.88%] [G loss: 0.930712]\n",
      "epoch:20 step:19538 [D loss: 0.783441, acc.: 50.00%] [G loss: 1.180124]\n",
      "epoch:20 step:19539 [D loss: 1.124772, acc.: 26.56%] [G loss: 1.230075]\n",
      "epoch:20 step:19540 [D loss: 0.432429, acc.: 82.81%] [G loss: 1.653573]\n",
      "epoch:20 step:19541 [D loss: 0.387198, acc.: 85.16%] [G loss: 2.354139]\n",
      "epoch:20 step:19542 [D loss: 0.355277, acc.: 89.06%] [G loss: 1.996515]\n",
      "epoch:20 step:19543 [D loss: 0.462341, acc.: 75.00%] [G loss: 2.312195]\n",
      "epoch:20 step:19544 [D loss: 1.163948, acc.: 46.88%] [G loss: 1.263535]\n",
      "epoch:20 step:19545 [D loss: 0.600443, acc.: 75.78%] [G loss: 1.120101]\n",
      "epoch:20 step:19546 [D loss: 0.441436, acc.: 73.44%] [G loss: 0.993964]\n",
      "epoch:20 step:19547 [D loss: 0.731549, acc.: 46.88%] [G loss: 1.237527]\n",
      "epoch:20 step:19548 [D loss: 0.459124, acc.: 77.34%] [G loss: 1.632786]\n",
      "epoch:20 step:19549 [D loss: 0.200039, acc.: 96.88%] [G loss: 1.819609]\n",
      "epoch:20 step:19550 [D loss: 0.376660, acc.: 89.06%] [G loss: 1.915163]\n",
      "epoch:20 step:19551 [D loss: 0.686103, acc.: 60.16%] [G loss: 2.243155]\n",
      "epoch:20 step:19552 [D loss: 0.821957, acc.: 53.12%] [G loss: 1.793917]\n",
      "epoch:20 step:19553 [D loss: 0.435398, acc.: 81.25%] [G loss: 1.734928]\n",
      "epoch:20 step:19554 [D loss: 0.388551, acc.: 86.72%] [G loss: 1.466916]\n",
      "epoch:20 step:19555 [D loss: 0.162456, acc.: 98.44%] [G loss: 2.009232]\n",
      "epoch:20 step:19556 [D loss: 0.188373, acc.: 97.66%] [G loss: 2.865421]\n",
      "epoch:20 step:19557 [D loss: 0.481852, acc.: 82.81%] [G loss: 1.814250]\n",
      "epoch:20 step:19558 [D loss: 0.321975, acc.: 92.19%] [G loss: 1.298400]\n",
      "epoch:20 step:19559 [D loss: 0.302013, acc.: 93.75%] [G loss: 1.929606]\n",
      "epoch:20 step:19560 [D loss: 0.495857, acc.: 80.47%] [G loss: 1.624181]\n",
      "epoch:20 step:19561 [D loss: 0.885980, acc.: 50.00%] [G loss: 1.154914]\n",
      "epoch:20 step:19562 [D loss: 0.529250, acc.: 71.88%] [G loss: 1.263587]\n",
      "epoch:20 step:19563 [D loss: 0.376259, acc.: 91.41%] [G loss: 1.338937]\n",
      "epoch:20 step:19564 [D loss: 0.255056, acc.: 89.84%] [G loss: 1.616786]\n",
      "epoch:20 step:19565 [D loss: 0.311457, acc.: 88.28%] [G loss: 3.003561]\n",
      "epoch:20 step:19566 [D loss: 0.482915, acc.: 76.56%] [G loss: 2.064211]\n",
      "epoch:20 step:19567 [D loss: 0.504632, acc.: 85.16%] [G loss: 1.704063]\n",
      "epoch:20 step:19568 [D loss: 0.525137, acc.: 75.00%] [G loss: 1.412256]\n",
      "epoch:20 step:19569 [D loss: 0.435355, acc.: 84.38%] [G loss: 1.961102]\n",
      "epoch:20 step:19570 [D loss: 0.395442, acc.: 75.78%] [G loss: 1.336685]\n",
      "epoch:20 step:19571 [D loss: 0.319993, acc.: 86.72%] [G loss: 1.507458]\n",
      "epoch:20 step:19572 [D loss: 0.152678, acc.: 97.66%] [G loss: 1.722982]\n",
      "epoch:20 step:19573 [D loss: 0.392219, acc.: 82.81%] [G loss: 1.027647]\n",
      "epoch:20 step:19574 [D loss: 1.765405, acc.: 21.09%] [G loss: 1.344646]\n",
      "epoch:20 step:19575 [D loss: 0.888242, acc.: 39.06%] [G loss: 1.141540]\n",
      "epoch:20 step:19576 [D loss: 0.563634, acc.: 70.31%] [G loss: 1.382599]\n",
      "epoch:20 step:19577 [D loss: 0.505807, acc.: 71.88%] [G loss: 0.621226]\n",
      "epoch:20 step:19578 [D loss: 0.659786, acc.: 61.72%] [G loss: 1.079787]\n",
      "epoch:20 step:19579 [D loss: 0.916761, acc.: 35.94%] [G loss: 0.837331]\n",
      "epoch:20 step:19580 [D loss: 0.937011, acc.: 33.59%] [G loss: 1.054101]\n",
      "epoch:20 step:19581 [D loss: 0.771972, acc.: 50.78%] [G loss: 1.031084]\n",
      "epoch:20 step:19582 [D loss: 0.711383, acc.: 54.69%] [G loss: 1.204430]\n",
      "epoch:20 step:19583 [D loss: 0.524139, acc.: 72.66%] [G loss: 1.236315]\n",
      "epoch:20 step:19584 [D loss: 0.567777, acc.: 72.66%] [G loss: 1.129597]\n",
      "epoch:20 step:19585 [D loss: 0.388015, acc.: 83.59%] [G loss: 1.266105]\n",
      "epoch:20 step:19586 [D loss: 0.619564, acc.: 67.19%] [G loss: 1.485449]\n",
      "epoch:20 step:19587 [D loss: 0.578978, acc.: 67.19%] [G loss: 1.304914]\n",
      "epoch:20 step:19588 [D loss: 0.558975, acc.: 70.31%] [G loss: 1.465901]\n",
      "epoch:20 step:19589 [D loss: 0.396587, acc.: 84.38%] [G loss: 1.382885]\n",
      "epoch:20 step:19590 [D loss: 0.427171, acc.: 79.69%] [G loss: 1.728674]\n",
      "epoch:20 step:19591 [D loss: 0.398152, acc.: 86.72%] [G loss: 1.479918]\n",
      "epoch:20 step:19592 [D loss: 0.357033, acc.: 89.06%] [G loss: 1.658753]\n",
      "epoch:20 step:19593 [D loss: 0.366192, acc.: 89.84%] [G loss: 1.292421]\n",
      "epoch:20 step:19594 [D loss: 0.272884, acc.: 90.62%] [G loss: 1.956113]\n",
      "epoch:20 step:19595 [D loss: 0.349629, acc.: 92.19%] [G loss: 1.375760]\n",
      "epoch:20 step:19596 [D loss: 0.543143, acc.: 75.00%] [G loss: 1.389511]\n",
      "epoch:20 step:19597 [D loss: 0.359767, acc.: 82.81%] [G loss: 1.487133]\n",
      "epoch:20 step:19598 [D loss: 1.124456, acc.: 37.50%] [G loss: 1.201469]\n",
      "epoch:20 step:19599 [D loss: 0.599375, acc.: 68.75%] [G loss: 1.021161]\n",
      "epoch:20 step:19600 [D loss: 0.574541, acc.: 68.75%] [G loss: 0.732942]\n",
      "##############\n",
      "[4.10967559 2.15368198 6.99082244 5.49094803 4.45071983 6.29522778\n",
      " 5.07500173 5.43554583 5.79626891 5.14676275]\n",
      "##########\n",
      "epoch:20 step:19601 [D loss: 0.530590, acc.: 80.47%] [G loss: 0.907718]\n",
      "epoch:20 step:19602 [D loss: 0.619142, acc.: 65.62%] [G loss: 1.113863]\n",
      "epoch:20 step:19603 [D loss: 0.682159, acc.: 58.59%] [G loss: 1.196584]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:20 step:19604 [D loss: 0.625309, acc.: 64.06%] [G loss: 1.390821]\n",
      "epoch:20 step:19605 [D loss: 0.536807, acc.: 73.44%] [G loss: 1.139776]\n",
      "epoch:20 step:19606 [D loss: 0.698879, acc.: 56.25%] [G loss: 0.960804]\n",
      "epoch:20 step:19607 [D loss: 0.489947, acc.: 82.03%] [G loss: 1.340376]\n",
      "epoch:20 step:19608 [D loss: 0.683490, acc.: 59.38%] [G loss: 0.963975]\n",
      "epoch:20 step:19609 [D loss: 0.581237, acc.: 67.19%] [G loss: 1.194767]\n",
      "epoch:20 step:19610 [D loss: 0.740956, acc.: 57.03%] [G loss: 1.113788]\n",
      "epoch:20 step:19611 [D loss: 0.628099, acc.: 64.84%] [G loss: 1.120820]\n",
      "epoch:20 step:19612 [D loss: 0.582608, acc.: 69.53%] [G loss: 1.235878]\n",
      "epoch:20 step:19613 [D loss: 0.661265, acc.: 63.28%] [G loss: 1.228072]\n",
      "epoch:20 step:19614 [D loss: 0.676055, acc.: 60.16%] [G loss: 1.033613]\n",
      "epoch:20 step:19615 [D loss: 0.627434, acc.: 60.94%] [G loss: 0.989874]\n",
      "epoch:20 step:19616 [D loss: 0.621643, acc.: 65.62%] [G loss: 1.233644]\n",
      "epoch:20 step:19617 [D loss: 0.552306, acc.: 71.09%] [G loss: 1.001825]\n",
      "epoch:20 step:19618 [D loss: 0.503754, acc.: 75.00%] [G loss: 1.052878]\n",
      "epoch:20 step:19619 [D loss: 0.629201, acc.: 57.81%] [G loss: 1.066945]\n",
      "epoch:20 step:19620 [D loss: 0.654287, acc.: 60.94%] [G loss: 1.167925]\n",
      "epoch:20 step:19621 [D loss: 0.747772, acc.: 47.66%] [G loss: 1.191194]\n",
      "epoch:20 step:19622 [D loss: 0.659588, acc.: 55.47%] [G loss: 0.921060]\n",
      "epoch:20 step:19623 [D loss: 0.472775, acc.: 79.69%] [G loss: 1.299506]\n",
      "epoch:20 step:19624 [D loss: 0.365494, acc.: 88.28%] [G loss: 1.063452]\n",
      "epoch:20 step:19625 [D loss: 0.263307, acc.: 89.84%] [G loss: 1.391116]\n",
      "epoch:20 step:19626 [D loss: 0.372577, acc.: 82.81%] [G loss: 1.465492]\n",
      "epoch:20 step:19627 [D loss: 0.336320, acc.: 94.53%] [G loss: 1.124264]\n",
      "epoch:20 step:19628 [D loss: 0.710248, acc.: 57.81%] [G loss: 1.154055]\n",
      "epoch:20 step:19629 [D loss: 0.365855, acc.: 91.41%] [G loss: 1.247792]\n",
      "epoch:20 step:19630 [D loss: 0.354090, acc.: 86.72%] [G loss: 1.323554]\n",
      "epoch:20 step:19631 [D loss: 0.876692, acc.: 40.62%] [G loss: 1.325663]\n",
      "epoch:20 step:19632 [D loss: 0.819190, acc.: 46.09%] [G loss: 1.097412]\n",
      "epoch:20 step:19633 [D loss: 0.699883, acc.: 55.47%] [G loss: 1.053784]\n",
      "epoch:20 step:19634 [D loss: 0.625044, acc.: 64.84%] [G loss: 0.951132]\n",
      "epoch:20 step:19635 [D loss: 0.632520, acc.: 68.75%] [G loss: 0.943140]\n",
      "epoch:20 step:19636 [D loss: 0.614203, acc.: 64.84%] [G loss: 0.997904]\n",
      "epoch:20 step:19637 [D loss: 0.694139, acc.: 56.25%] [G loss: 1.024059]\n",
      "epoch:20 step:19638 [D loss: 0.603603, acc.: 67.19%] [G loss: 1.450191]\n",
      "epoch:20 step:19639 [D loss: 0.381998, acc.: 82.03%] [G loss: 1.340431]\n",
      "epoch:20 step:19640 [D loss: 0.309445, acc.: 96.09%] [G loss: 1.020321]\n",
      "epoch:20 step:19641 [D loss: 0.446533, acc.: 82.03%] [G loss: 1.458218]\n",
      "epoch:20 step:19642 [D loss: 0.572931, acc.: 64.84%] [G loss: 1.313162]\n",
      "epoch:20 step:19643 [D loss: 0.449498, acc.: 85.16%] [G loss: 0.927554]\n",
      "epoch:20 step:19644 [D loss: 0.292271, acc.: 95.31%] [G loss: 1.313686]\n",
      "epoch:20 step:19645 [D loss: 0.780226, acc.: 51.56%] [G loss: 1.340582]\n",
      "epoch:20 step:19646 [D loss: 0.548324, acc.: 75.78%] [G loss: 1.218956]\n",
      "epoch:20 step:19647 [D loss: 0.724006, acc.: 60.16%] [G loss: 1.054983]\n",
      "epoch:20 step:19648 [D loss: 0.780208, acc.: 47.66%] [G loss: 0.923543]\n",
      "epoch:20 step:19649 [D loss: 0.414279, acc.: 85.94%] [G loss: 1.135292]\n",
      "epoch:20 step:19650 [D loss: 0.561503, acc.: 74.22%] [G loss: 0.748340]\n",
      "epoch:20 step:19651 [D loss: 0.385278, acc.: 87.50%] [G loss: 0.971572]\n",
      "epoch:20 step:19652 [D loss: 0.257303, acc.: 92.97%] [G loss: 1.115435]\n",
      "epoch:20 step:19653 [D loss: 0.764232, acc.: 51.56%] [G loss: 0.742164]\n",
      "epoch:20 step:19654 [D loss: 0.751395, acc.: 55.47%] [G loss: 1.166687]\n",
      "epoch:20 step:19655 [D loss: 0.750962, acc.: 55.47%] [G loss: 1.232397]\n",
      "epoch:20 step:19656 [D loss: 0.553611, acc.: 71.09%] [G loss: 1.312274]\n",
      "epoch:20 step:19657 [D loss: 0.485189, acc.: 77.34%] [G loss: 1.247688]\n",
      "epoch:20 step:19658 [D loss: 0.585014, acc.: 67.19%] [G loss: 0.988032]\n",
      "epoch:20 step:19659 [D loss: 0.472661, acc.: 80.47%] [G loss: 1.265207]\n",
      "epoch:20 step:19660 [D loss: 0.293063, acc.: 91.41%] [G loss: 1.612388]\n",
      "epoch:20 step:19661 [D loss: 0.572212, acc.: 71.09%] [G loss: 1.467626]\n",
      "epoch:20 step:19662 [D loss: 0.556920, acc.: 79.69%] [G loss: 1.453391]\n",
      "epoch:20 step:19663 [D loss: 0.693827, acc.: 66.41%] [G loss: 1.390133]\n",
      "epoch:20 step:19664 [D loss: 0.568268, acc.: 74.22%] [G loss: 1.212546]\n",
      "epoch:20 step:19665 [D loss: 0.598063, acc.: 67.97%] [G loss: 1.255883]\n",
      "epoch:20 step:19666 [D loss: 0.519670, acc.: 76.56%] [G loss: 1.409960]\n",
      "epoch:20 step:19667 [D loss: 0.593057, acc.: 72.66%] [G loss: 1.187467]\n",
      "epoch:20 step:19668 [D loss: 0.586453, acc.: 70.31%] [G loss: 1.165826]\n",
      "epoch:20 step:19669 [D loss: 0.434867, acc.: 72.66%] [G loss: 1.547246]\n",
      "epoch:20 step:19670 [D loss: 0.507837, acc.: 81.25%] [G loss: 1.586855]\n",
      "epoch:20 step:19671 [D loss: 0.581369, acc.: 71.09%] [G loss: 1.282144]\n",
      "epoch:20 step:19672 [D loss: 0.562773, acc.: 69.53%] [G loss: 1.212700]\n",
      "epoch:20 step:19673 [D loss: 0.529096, acc.: 75.78%] [G loss: 1.029014]\n",
      "epoch:20 step:19674 [D loss: 0.420606, acc.: 84.38%] [G loss: 1.427274]\n",
      "epoch:20 step:19675 [D loss: 0.612640, acc.: 65.62%] [G loss: 1.253388]\n",
      "epoch:20 step:19676 [D loss: 0.207039, acc.: 100.00%] [G loss: 1.734964]\n",
      "epoch:20 step:19677 [D loss: 0.186809, acc.: 93.75%] [G loss: 1.295008]\n",
      "epoch:21 step:19678 [D loss: 0.630268, acc.: 71.09%] [G loss: 1.903897]\n",
      "epoch:21 step:19679 [D loss: 0.739644, acc.: 52.34%] [G loss: 1.213373]\n",
      "epoch:21 step:19680 [D loss: 0.612478, acc.: 65.62%] [G loss: 0.862255]\n",
      "epoch:21 step:19681 [D loss: 0.643887, acc.: 57.81%] [G loss: 1.019351]\n",
      "epoch:21 step:19682 [D loss: 0.572884, acc.: 71.88%] [G loss: 1.160589]\n",
      "epoch:21 step:19683 [D loss: 0.796745, acc.: 42.97%] [G loss: 0.986523]\n",
      "epoch:21 step:19684 [D loss: 0.420186, acc.: 86.72%] [G loss: 1.355384]\n",
      "epoch:21 step:19685 [D loss: 0.442925, acc.: 83.59%] [G loss: 1.186665]\n",
      "epoch:21 step:19686 [D loss: 0.419797, acc.: 82.03%] [G loss: 1.112276]\n",
      "epoch:21 step:19687 [D loss: 0.418020, acc.: 82.03%] [G loss: 1.051023]\n",
      "epoch:21 step:19688 [D loss: 0.406983, acc.: 85.94%] [G loss: 0.917217]\n",
      "epoch:21 step:19689 [D loss: 0.590021, acc.: 67.97%] [G loss: 0.995690]\n",
      "epoch:21 step:19690 [D loss: 0.682954, acc.: 59.38%] [G loss: 1.284828]\n",
      "epoch:21 step:19691 [D loss: 0.474932, acc.: 77.34%] [G loss: 1.133553]\n",
      "epoch:21 step:19692 [D loss: 0.367174, acc.: 89.84%] [G loss: 1.276955]\n",
      "epoch:21 step:19693 [D loss: 0.573302, acc.: 68.75%] [G loss: 0.705311]\n",
      "epoch:21 step:19694 [D loss: 0.712729, acc.: 57.81%] [G loss: 1.461026]\n",
      "epoch:21 step:19695 [D loss: 0.600954, acc.: 65.62%] [G loss: 1.021304]\n",
      "epoch:21 step:19696 [D loss: 0.844596, acc.: 47.66%] [G loss: 0.816056]\n",
      "epoch:21 step:19697 [D loss: 0.869261, acc.: 53.91%] [G loss: 0.927774]\n",
      "epoch:21 step:19698 [D loss: 0.760415, acc.: 48.44%] [G loss: 0.460375]\n",
      "epoch:21 step:19699 [D loss: 0.692158, acc.: 64.06%] [G loss: 0.960477]\n",
      "epoch:21 step:19700 [D loss: 0.619254, acc.: 66.41%] [G loss: 1.285244]\n",
      "epoch:21 step:19701 [D loss: 0.891532, acc.: 42.19%] [G loss: 0.999446]\n",
      "epoch:21 step:19702 [D loss: 0.638862, acc.: 64.06%] [G loss: 1.575880]\n",
      "epoch:21 step:19703 [D loss: 0.846927, acc.: 46.88%] [G loss: 1.379416]\n",
      "epoch:21 step:19704 [D loss: 0.363179, acc.: 89.06%] [G loss: 1.688177]\n",
      "epoch:21 step:19705 [D loss: 0.590068, acc.: 66.41%] [G loss: 1.202315]\n",
      "epoch:21 step:19706 [D loss: 0.617089, acc.: 61.72%] [G loss: 1.374923]\n",
      "epoch:21 step:19707 [D loss: 0.647611, acc.: 55.47%] [G loss: 1.791299]\n",
      "epoch:21 step:19708 [D loss: 0.411987, acc.: 82.81%] [G loss: 1.409591]\n",
      "epoch:21 step:19709 [D loss: 0.386597, acc.: 86.72%] [G loss: 1.507115]\n",
      "epoch:21 step:19710 [D loss: 0.222281, acc.: 96.88%] [G loss: 1.758624]\n",
      "epoch:21 step:19711 [D loss: 0.300408, acc.: 89.06%] [G loss: 1.978207]\n",
      "epoch:21 step:19712 [D loss: 0.153341, acc.: 98.44%] [G loss: 1.971641]\n",
      "epoch:21 step:19713 [D loss: 0.133889, acc.: 96.09%] [G loss: 2.242747]\n",
      "epoch:21 step:19714 [D loss: 1.091642, acc.: 49.22%] [G loss: 1.286176]\n",
      "epoch:21 step:19715 [D loss: 0.948971, acc.: 39.84%] [G loss: 1.149752]\n",
      "epoch:21 step:19716 [D loss: 0.942002, acc.: 41.41%] [G loss: 0.720961]\n",
      "epoch:21 step:19717 [D loss: 0.744212, acc.: 52.34%] [G loss: 1.242433]\n",
      "epoch:21 step:19718 [D loss: 0.578170, acc.: 69.53%] [G loss: 0.984932]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:21 step:19719 [D loss: 0.496330, acc.: 79.69%] [G loss: 0.914425]\n",
      "epoch:21 step:19720 [D loss: 0.402421, acc.: 85.94%] [G loss: 1.070728]\n",
      "epoch:21 step:19721 [D loss: 0.484526, acc.: 84.38%] [G loss: 1.250392]\n",
      "epoch:21 step:19722 [D loss: 0.596723, acc.: 71.88%] [G loss: 0.997023]\n",
      "epoch:21 step:19723 [D loss: 0.466133, acc.: 81.25%] [G loss: 0.975629]\n",
      "epoch:21 step:19724 [D loss: 0.545485, acc.: 80.47%] [G loss: 1.206542]\n",
      "epoch:21 step:19725 [D loss: 0.552940, acc.: 75.78%] [G loss: 1.064192]\n",
      "epoch:21 step:19726 [D loss: 0.781867, acc.: 51.56%] [G loss: 1.054525]\n",
      "epoch:21 step:19727 [D loss: 0.504242, acc.: 79.69%] [G loss: 0.645329]\n",
      "epoch:21 step:19728 [D loss: 0.519115, acc.: 75.00%] [G loss: 1.080037]\n",
      "epoch:21 step:19729 [D loss: 0.341032, acc.: 91.41%] [G loss: 1.338161]\n",
      "epoch:21 step:19730 [D loss: 0.690413, acc.: 55.47%] [G loss: 0.825212]\n",
      "epoch:21 step:19731 [D loss: 0.665558, acc.: 53.91%] [G loss: 1.048629]\n",
      "epoch:21 step:19732 [D loss: 0.598116, acc.: 68.75%] [G loss: 1.474612]\n",
      "epoch:21 step:19733 [D loss: 0.902635, acc.: 35.16%] [G loss: 1.196573]\n",
      "epoch:21 step:19734 [D loss: 0.307652, acc.: 91.41%] [G loss: 0.874671]\n",
      "epoch:21 step:19735 [D loss: 0.266289, acc.: 90.62%] [G loss: 1.771190]\n",
      "epoch:21 step:19736 [D loss: 0.911503, acc.: 42.97%] [G loss: 1.587925]\n",
      "epoch:21 step:19737 [D loss: 0.380199, acc.: 86.72%] [G loss: 1.544531]\n",
      "epoch:21 step:19738 [D loss: 0.742335, acc.: 53.12%] [G loss: 1.272225]\n",
      "epoch:21 step:19739 [D loss: 0.785836, acc.: 49.22%] [G loss: 1.233812]\n",
      "epoch:21 step:19740 [D loss: 0.529278, acc.: 77.34%] [G loss: 0.747980]\n",
      "epoch:21 step:19741 [D loss: 0.743547, acc.: 48.44%] [G loss: 1.086666]\n",
      "epoch:21 step:19742 [D loss: 0.673719, acc.: 59.38%] [G loss: 1.343913]\n",
      "epoch:21 step:19743 [D loss: 0.799258, acc.: 45.31%] [G loss: 1.460351]\n",
      "epoch:21 step:19744 [D loss: 0.704983, acc.: 57.81%] [G loss: 1.282790]\n",
      "epoch:21 step:19745 [D loss: 0.669562, acc.: 60.94%] [G loss: 1.256674]\n",
      "epoch:21 step:19746 [D loss: 0.660629, acc.: 60.94%] [G loss: 1.157218]\n",
      "epoch:21 step:19747 [D loss: 0.907369, acc.: 48.44%] [G loss: 1.871489]\n",
      "epoch:21 step:19748 [D loss: 0.250759, acc.: 93.75%] [G loss: 1.728426]\n",
      "epoch:21 step:19749 [D loss: 0.624226, acc.: 66.41%] [G loss: 1.464735]\n",
      "epoch:21 step:19750 [D loss: 0.543570, acc.: 75.78%] [G loss: 1.305245]\n",
      "epoch:21 step:19751 [D loss: 0.606993, acc.: 64.06%] [G loss: 0.951242]\n",
      "epoch:21 step:19752 [D loss: 0.447164, acc.: 78.12%] [G loss: 1.503606]\n",
      "epoch:21 step:19753 [D loss: 0.189015, acc.: 94.53%] [G loss: 1.437959]\n",
      "epoch:21 step:19754 [D loss: 0.346073, acc.: 82.81%] [G loss: 1.138407]\n",
      "epoch:21 step:19755 [D loss: 1.003794, acc.: 41.41%] [G loss: 1.280779]\n",
      "epoch:21 step:19756 [D loss: 0.746907, acc.: 54.69%] [G loss: 1.210441]\n",
      "epoch:21 step:19757 [D loss: 0.696074, acc.: 58.59%] [G loss: 0.637882]\n",
      "epoch:21 step:19758 [D loss: 0.710214, acc.: 57.03%] [G loss: 1.363537]\n",
      "epoch:21 step:19759 [D loss: 0.460043, acc.: 82.81%] [G loss: 1.382388]\n",
      "epoch:21 step:19760 [D loss: 0.465462, acc.: 78.91%] [G loss: 1.270600]\n",
      "epoch:21 step:19761 [D loss: 0.549379, acc.: 69.53%] [G loss: 1.362216]\n",
      "epoch:21 step:19762 [D loss: 0.557697, acc.: 72.66%] [G loss: 1.373236]\n",
      "epoch:21 step:19763 [D loss: 0.658031, acc.: 60.94%] [G loss: 0.872646]\n",
      "epoch:21 step:19764 [D loss: 0.491062, acc.: 83.59%] [G loss: 1.223910]\n",
      "epoch:21 step:19765 [D loss: 0.436141, acc.: 85.94%] [G loss: 1.387559]\n",
      "epoch:21 step:19766 [D loss: 0.454172, acc.: 86.72%] [G loss: 1.498438]\n",
      "epoch:21 step:19767 [D loss: 0.444231, acc.: 81.25%] [G loss: 1.323829]\n",
      "epoch:21 step:19768 [D loss: 0.436718, acc.: 80.47%] [G loss: 1.237847]\n",
      "epoch:21 step:19769 [D loss: 0.328837, acc.: 91.41%] [G loss: 1.863781]\n",
      "epoch:21 step:19770 [D loss: 0.293195, acc.: 94.53%] [G loss: 1.400586]\n",
      "epoch:21 step:19771 [D loss: 0.479278, acc.: 76.56%] [G loss: 1.428651]\n",
      "epoch:21 step:19772 [D loss: 0.755448, acc.: 53.91%] [G loss: 0.813420]\n",
      "epoch:21 step:19773 [D loss: 0.620487, acc.: 68.75%] [G loss: 1.419109]\n",
      "epoch:21 step:19774 [D loss: 0.511573, acc.: 80.47%] [G loss: 1.698200]\n",
      "epoch:21 step:19775 [D loss: 0.889893, acc.: 40.62%] [G loss: 1.073178]\n",
      "epoch:21 step:19776 [D loss: 0.680740, acc.: 56.25%] [G loss: 1.008398]\n",
      "epoch:21 step:19777 [D loss: 0.808101, acc.: 49.22%] [G loss: 0.987679]\n",
      "epoch:21 step:19778 [D loss: 0.553692, acc.: 71.88%] [G loss: 1.094380]\n",
      "epoch:21 step:19779 [D loss: 0.642352, acc.: 60.94%] [G loss: 0.953867]\n",
      "epoch:21 step:19780 [D loss: 0.683950, acc.: 60.94%] [G loss: 1.174235]\n",
      "epoch:21 step:19781 [D loss: 0.708360, acc.: 55.47%] [G loss: 1.004143]\n",
      "epoch:21 step:19782 [D loss: 0.745082, acc.: 54.69%] [G loss: 0.760752]\n",
      "epoch:21 step:19783 [D loss: 0.638305, acc.: 64.06%] [G loss: 0.906693]\n",
      "epoch:21 step:19784 [D loss: 0.584607, acc.: 68.75%] [G loss: 1.165555]\n",
      "epoch:21 step:19785 [D loss: 0.540383, acc.: 71.09%] [G loss: 1.153923]\n",
      "epoch:21 step:19786 [D loss: 0.816768, acc.: 46.88%] [G loss: 1.114672]\n",
      "epoch:21 step:19787 [D loss: 0.668054, acc.: 58.59%] [G loss: 0.951104]\n",
      "epoch:21 step:19788 [D loss: 0.628390, acc.: 61.72%] [G loss: 1.192519]\n",
      "epoch:21 step:19789 [D loss: 0.679893, acc.: 66.41%] [G loss: 1.360156]\n",
      "epoch:21 step:19790 [D loss: 0.421053, acc.: 85.94%] [G loss: 1.261168]\n",
      "epoch:21 step:19791 [D loss: 0.395449, acc.: 81.25%] [G loss: 1.211863]\n",
      "epoch:21 step:19792 [D loss: 0.399420, acc.: 86.72%] [G loss: 1.249582]\n",
      "epoch:21 step:19793 [D loss: 0.719989, acc.: 60.16%] [G loss: 1.120780]\n",
      "epoch:21 step:19794 [D loss: 0.891847, acc.: 37.50%] [G loss: 1.110689]\n",
      "epoch:21 step:19795 [D loss: 0.653551, acc.: 62.50%] [G loss: 1.166561]\n",
      "epoch:21 step:19796 [D loss: 0.340822, acc.: 92.19%] [G loss: 1.371173]\n",
      "epoch:21 step:19797 [D loss: 0.446426, acc.: 86.72%] [G loss: 1.352497]\n",
      "epoch:21 step:19798 [D loss: 0.425104, acc.: 83.59%] [G loss: 1.357473]\n",
      "epoch:21 step:19799 [D loss: 0.379463, acc.: 86.72%] [G loss: 1.250939]\n",
      "epoch:21 step:19800 [D loss: 0.664607, acc.: 62.50%] [G loss: 1.047763]\n",
      "##############\n",
      "[3.94816226 2.73265215 7.03110419 5.88699444 4.766911   6.32206956\n",
      " 5.64882673 5.72335417 6.07804357 4.87581963]\n",
      "##########\n",
      "epoch:21 step:19801 [D loss: 0.659502, acc.: 62.50%] [G loss: 0.948636]\n",
      "epoch:21 step:19802 [D loss: 0.733773, acc.: 53.91%] [G loss: 1.310091]\n",
      "epoch:21 step:19803 [D loss: 0.757141, acc.: 53.12%] [G loss: 1.177048]\n",
      "epoch:21 step:19804 [D loss: 0.665658, acc.: 62.50%] [G loss: 1.261344]\n",
      "epoch:21 step:19805 [D loss: 0.642248, acc.: 62.50%] [G loss: 1.053621]\n",
      "epoch:21 step:19806 [D loss: 0.561173, acc.: 72.66%] [G loss: 1.292150]\n",
      "epoch:21 step:19807 [D loss: 0.291538, acc.: 96.09%] [G loss: 1.256258]\n",
      "epoch:21 step:19808 [D loss: 0.420010, acc.: 84.38%] [G loss: 1.340279]\n",
      "epoch:21 step:19809 [D loss: 0.470216, acc.: 79.69%] [G loss: 1.164773]\n",
      "epoch:21 step:19810 [D loss: 0.577215, acc.: 74.22%] [G loss: 1.793186]\n",
      "epoch:21 step:19811 [D loss: 0.467942, acc.: 83.59%] [G loss: 1.173434]\n",
      "epoch:21 step:19812 [D loss: 0.623500, acc.: 60.16%] [G loss: 1.181323]\n",
      "epoch:21 step:19813 [D loss: 0.712405, acc.: 57.81%] [G loss: 1.100835]\n",
      "epoch:21 step:19814 [D loss: 0.612764, acc.: 65.62%] [G loss: 1.216128]\n",
      "epoch:21 step:19815 [D loss: 0.645377, acc.: 67.97%] [G loss: 1.228818]\n",
      "epoch:21 step:19816 [D loss: 0.516534, acc.: 78.12%] [G loss: 1.085637]\n",
      "epoch:21 step:19817 [D loss: 0.590343, acc.: 68.75%] [G loss: 1.453131]\n",
      "epoch:21 step:19818 [D loss: 0.598070, acc.: 65.62%] [G loss: 1.132775]\n",
      "epoch:21 step:19819 [D loss: 0.712654, acc.: 50.78%] [G loss: 0.994541]\n",
      "epoch:21 step:19820 [D loss: 0.332283, acc.: 86.72%] [G loss: 0.952657]\n",
      "epoch:21 step:19821 [D loss: 0.592918, acc.: 71.88%] [G loss: 1.281034]\n",
      "epoch:21 step:19822 [D loss: 0.244569, acc.: 93.75%] [G loss: 1.488482]\n",
      "epoch:21 step:19823 [D loss: 0.521916, acc.: 80.47%] [G loss: 1.260648]\n",
      "epoch:21 step:19824 [D loss: 0.696284, acc.: 59.38%] [G loss: 0.978116]\n",
      "epoch:21 step:19825 [D loss: 0.743437, acc.: 51.56%] [G loss: 1.081100]\n",
      "epoch:21 step:19826 [D loss: 0.289855, acc.: 85.94%] [G loss: 1.164277]\n",
      "epoch:21 step:19827 [D loss: 0.210398, acc.: 96.88%] [G loss: 0.783497]\n",
      "epoch:21 step:19828 [D loss: 0.265684, acc.: 96.09%] [G loss: 1.119005]\n",
      "epoch:21 step:19829 [D loss: 0.527735, acc.: 77.34%] [G loss: 1.181462]\n",
      "epoch:21 step:19830 [D loss: 0.833188, acc.: 46.88%] [G loss: 1.270813]\n",
      "epoch:21 step:19831 [D loss: 0.656354, acc.: 58.59%] [G loss: 1.179148]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:21 step:19832 [D loss: 0.667492, acc.: 59.38%] [G loss: 1.254346]\n",
      "epoch:21 step:19833 [D loss: 0.759531, acc.: 47.66%] [G loss: 1.282841]\n",
      "epoch:21 step:19834 [D loss: 1.458802, acc.: 28.91%] [G loss: 1.479403]\n",
      "epoch:21 step:19835 [D loss: 0.956142, acc.: 38.28%] [G loss: 1.398219]\n",
      "epoch:21 step:19836 [D loss: 0.535464, acc.: 73.44%] [G loss: 1.473558]\n",
      "epoch:21 step:19837 [D loss: 0.800310, acc.: 55.47%] [G loss: 1.140941]\n",
      "epoch:21 step:19838 [D loss: 0.709063, acc.: 60.16%] [G loss: 0.850344]\n",
      "epoch:21 step:19839 [D loss: 0.649849, acc.: 60.16%] [G loss: 1.056925]\n",
      "epoch:21 step:19840 [D loss: 0.597289, acc.: 71.09%] [G loss: 0.920708]\n",
      "epoch:21 step:19841 [D loss: 0.509226, acc.: 76.56%] [G loss: 1.066465]\n",
      "epoch:21 step:19842 [D loss: 0.756247, acc.: 57.03%] [G loss: 0.984786]\n",
      "epoch:21 step:19843 [D loss: 0.670194, acc.: 65.62%] [G loss: 1.151362]\n",
      "epoch:21 step:19844 [D loss: 0.683750, acc.: 59.38%] [G loss: 1.068988]\n",
      "epoch:21 step:19845 [D loss: 0.479254, acc.: 84.38%] [G loss: 0.997277]\n",
      "epoch:21 step:19846 [D loss: 0.792460, acc.: 49.22%] [G loss: 1.053720]\n",
      "epoch:21 step:19847 [D loss: 0.772496, acc.: 53.12%] [G loss: 1.093870]\n",
      "epoch:21 step:19848 [D loss: 0.653461, acc.: 59.38%] [G loss: 0.930970]\n",
      "epoch:21 step:19849 [D loss: 0.631215, acc.: 65.62%] [G loss: 0.964691]\n",
      "epoch:21 step:19850 [D loss: 0.641863, acc.: 65.62%] [G loss: 1.128816]\n",
      "epoch:21 step:19851 [D loss: 0.582122, acc.: 72.66%] [G loss: 0.910218]\n",
      "epoch:21 step:19852 [D loss: 0.668658, acc.: 61.72%] [G loss: 0.879908]\n",
      "epoch:21 step:19853 [D loss: 0.619499, acc.: 69.53%] [G loss: 0.938295]\n",
      "epoch:21 step:19854 [D loss: 0.746160, acc.: 49.22%] [G loss: 0.897048]\n",
      "epoch:21 step:19855 [D loss: 0.682624, acc.: 56.25%] [G loss: 0.852094]\n",
      "epoch:21 step:19856 [D loss: 0.726749, acc.: 53.12%] [G loss: 0.832838]\n",
      "epoch:21 step:19857 [D loss: 0.702963, acc.: 52.34%] [G loss: 0.889873]\n",
      "epoch:21 step:19858 [D loss: 0.605221, acc.: 64.06%] [G loss: 1.014925]\n",
      "epoch:21 step:19859 [D loss: 0.593152, acc.: 65.62%] [G loss: 0.941767]\n",
      "epoch:21 step:19860 [D loss: 0.737460, acc.: 48.44%] [G loss: 1.031766]\n",
      "epoch:21 step:19861 [D loss: 0.514316, acc.: 79.69%] [G loss: 1.079951]\n",
      "epoch:21 step:19862 [D loss: 0.616861, acc.: 62.50%] [G loss: 1.234059]\n",
      "epoch:21 step:19863 [D loss: 0.707736, acc.: 52.34%] [G loss: 1.035574]\n",
      "epoch:21 step:19864 [D loss: 0.724877, acc.: 50.00%] [G loss: 1.040353]\n",
      "epoch:21 step:19865 [D loss: 0.578172, acc.: 74.22%] [G loss: 0.950881]\n",
      "epoch:21 step:19866 [D loss: 0.635144, acc.: 64.84%] [G loss: 1.256754]\n",
      "epoch:21 step:19867 [D loss: 0.510694, acc.: 81.25%] [G loss: 0.905694]\n",
      "epoch:21 step:19868 [D loss: 0.541869, acc.: 71.88%] [G loss: 0.969782]\n",
      "epoch:21 step:19869 [D loss: 0.420146, acc.: 76.56%] [G loss: 1.165079]\n",
      "epoch:21 step:19870 [D loss: 0.518176, acc.: 81.25%] [G loss: 1.031357]\n",
      "epoch:21 step:19871 [D loss: 0.309254, acc.: 94.53%] [G loss: 0.957529]\n",
      "epoch:21 step:19872 [D loss: 0.457679, acc.: 85.94%] [G loss: 1.525587]\n",
      "epoch:21 step:19873 [D loss: 0.497973, acc.: 80.47%] [G loss: 1.048114]\n",
      "epoch:21 step:19874 [D loss: 0.529979, acc.: 79.69%] [G loss: 1.251137]\n",
      "epoch:21 step:19875 [D loss: 0.406780, acc.: 88.28%] [G loss: 1.362785]\n",
      "epoch:21 step:19876 [D loss: 0.758112, acc.: 48.44%] [G loss: 1.213373]\n",
      "epoch:21 step:19877 [D loss: 0.381318, acc.: 78.91%] [G loss: 1.539109]\n",
      "epoch:21 step:19878 [D loss: 0.212470, acc.: 97.66%] [G loss: 1.570120]\n",
      "epoch:21 step:19879 [D loss: 1.044634, acc.: 28.91%] [G loss: 1.318006]\n",
      "epoch:21 step:19880 [D loss: 0.422999, acc.: 85.94%] [G loss: 1.438337]\n",
      "epoch:21 step:19881 [D loss: 0.302335, acc.: 98.44%] [G loss: 0.729279]\n",
      "epoch:21 step:19882 [D loss: 0.533551, acc.: 76.56%] [G loss: 1.103723]\n",
      "epoch:21 step:19883 [D loss: 0.236519, acc.: 99.22%] [G loss: 1.167119]\n",
      "epoch:21 step:19884 [D loss: 0.597270, acc.: 70.31%] [G loss: 1.641840]\n",
      "epoch:21 step:19885 [D loss: 0.438058, acc.: 79.69%] [G loss: 1.233868]\n",
      "epoch:21 step:19886 [D loss: 0.639764, acc.: 68.75%] [G loss: 1.761614]\n",
      "epoch:21 step:19887 [D loss: 1.167005, acc.: 46.88%] [G loss: 1.328264]\n",
      "epoch:21 step:19888 [D loss: 0.921645, acc.: 40.62%] [G loss: 0.929882]\n",
      "epoch:21 step:19889 [D loss: 0.914023, acc.: 32.03%] [G loss: 1.090490]\n",
      "epoch:21 step:19890 [D loss: 0.898838, acc.: 38.28%] [G loss: 1.197777]\n",
      "epoch:21 step:19891 [D loss: 0.919077, acc.: 32.03%] [G loss: 1.257626]\n",
      "epoch:21 step:19892 [D loss: 0.752913, acc.: 49.22%] [G loss: 1.151101]\n",
      "epoch:21 step:19893 [D loss: 0.704490, acc.: 62.50%] [G loss: 1.054615]\n",
      "epoch:21 step:19894 [D loss: 0.671900, acc.: 58.59%] [G loss: 1.010683]\n",
      "epoch:21 step:19895 [D loss: 0.503407, acc.: 78.91%] [G loss: 1.046336]\n",
      "epoch:21 step:19896 [D loss: 0.493269, acc.: 75.78%] [G loss: 0.902522]\n",
      "epoch:21 step:19897 [D loss: 0.238649, acc.: 96.09%] [G loss: 0.991242]\n",
      "epoch:21 step:19898 [D loss: 0.213734, acc.: 99.22%] [G loss: 1.512612]\n",
      "epoch:21 step:19899 [D loss: 0.494318, acc.: 78.91%] [G loss: 1.374915]\n",
      "epoch:21 step:19900 [D loss: 0.376023, acc.: 89.84%] [G loss: 1.415552]\n",
      "epoch:21 step:19901 [D loss: 0.715377, acc.: 56.25%] [G loss: 1.260841]\n",
      "epoch:21 step:19902 [D loss: 0.601482, acc.: 70.31%] [G loss: 1.034702]\n",
      "epoch:21 step:19903 [D loss: 0.680811, acc.: 54.69%] [G loss: 1.159952]\n",
      "epoch:21 step:19904 [D loss: 0.529596, acc.: 77.34%] [G loss: 1.252495]\n",
      "epoch:21 step:19905 [D loss: 0.601300, acc.: 67.19%] [G loss: 1.224144]\n",
      "epoch:21 step:19906 [D loss: 0.538816, acc.: 75.00%] [G loss: 1.273619]\n",
      "epoch:21 step:19907 [D loss: 0.222280, acc.: 93.75%] [G loss: 1.550328]\n",
      "epoch:21 step:19908 [D loss: 0.223864, acc.: 95.31%] [G loss: 1.688116]\n",
      "epoch:21 step:19909 [D loss: 0.209330, acc.: 92.97%] [G loss: 1.609779]\n",
      "epoch:21 step:19910 [D loss: 0.613943, acc.: 65.62%] [G loss: 1.414445]\n",
      "epoch:21 step:19911 [D loss: 0.357199, acc.: 87.50%] [G loss: 1.508971]\n",
      "epoch:21 step:19912 [D loss: 0.265365, acc.: 98.44%] [G loss: 1.372851]\n",
      "epoch:21 step:19913 [D loss: 0.576321, acc.: 67.97%] [G loss: 1.378050]\n",
      "epoch:21 step:19914 [D loss: 0.379323, acc.: 82.81%] [G loss: 1.515876]\n",
      "epoch:21 step:19915 [D loss: 0.214880, acc.: 95.31%] [G loss: 1.550355]\n",
      "epoch:21 step:19916 [D loss: 0.506473, acc.: 75.00%] [G loss: 1.267160]\n",
      "epoch:21 step:19917 [D loss: 0.606606, acc.: 67.97%] [G loss: 1.370637]\n",
      "epoch:21 step:19918 [D loss: 0.783993, acc.: 48.44%] [G loss: 1.131072]\n",
      "epoch:21 step:19919 [D loss: 0.563737, acc.: 74.22%] [G loss: 1.010613]\n",
      "epoch:21 step:19920 [D loss: 0.338787, acc.: 88.28%] [G loss: 1.006506]\n",
      "epoch:21 step:19921 [D loss: 0.546392, acc.: 74.22%] [G loss: 1.106423]\n",
      "epoch:21 step:19922 [D loss: 0.691262, acc.: 53.91%] [G loss: 0.896439]\n",
      "epoch:21 step:19923 [D loss: 0.711702, acc.: 58.59%] [G loss: 1.109697]\n",
      "epoch:21 step:19924 [D loss: 0.864260, acc.: 42.97%] [G loss: 0.404398]\n",
      "epoch:21 step:19925 [D loss: 0.651241, acc.: 64.06%] [G loss: 0.982046]\n",
      "epoch:21 step:19926 [D loss: 0.475008, acc.: 78.12%] [G loss: 0.780167]\n",
      "epoch:21 step:19927 [D loss: 0.725363, acc.: 50.78%] [G loss: 0.598865]\n",
      "epoch:21 step:19928 [D loss: 0.339730, acc.: 91.41%] [G loss: 0.715790]\n",
      "epoch:21 step:19929 [D loss: 0.543800, acc.: 74.22%] [G loss: 0.913040]\n",
      "epoch:21 step:19930 [D loss: 1.139645, acc.: 41.41%] [G loss: 0.864071]\n",
      "epoch:21 step:19931 [D loss: 0.503803, acc.: 80.47%] [G loss: 1.114895]\n",
      "epoch:21 step:19932 [D loss: 0.249949, acc.: 97.66%] [G loss: 1.801970]\n",
      "epoch:21 step:19933 [D loss: 0.218401, acc.: 92.19%] [G loss: 1.727030]\n",
      "epoch:21 step:19934 [D loss: 0.220627, acc.: 98.44%] [G loss: 2.008641]\n",
      "epoch:21 step:19935 [D loss: 0.600306, acc.: 66.41%] [G loss: 0.338078]\n",
      "epoch:21 step:19936 [D loss: 0.612377, acc.: 66.41%] [G loss: 1.296949]\n",
      "epoch:21 step:19937 [D loss: 0.149867, acc.: 99.22%] [G loss: 1.891835]\n",
      "epoch:21 step:19938 [D loss: 1.130152, acc.: 53.12%] [G loss: 1.848438]\n",
      "epoch:21 step:19939 [D loss: 0.782058, acc.: 56.25%] [G loss: 1.951526]\n",
      "epoch:21 step:19940 [D loss: 0.991419, acc.: 51.56%] [G loss: 2.151120]\n",
      "epoch:21 step:19941 [D loss: 0.842019, acc.: 53.91%] [G loss: 1.760380]\n",
      "epoch:21 step:19942 [D loss: 0.608062, acc.: 70.31%] [G loss: 0.958718]\n",
      "epoch:21 step:19943 [D loss: 0.731877, acc.: 57.03%] [G loss: 1.166502]\n",
      "epoch:21 step:19944 [D loss: 0.632123, acc.: 62.50%] [G loss: 1.220516]\n",
      "epoch:21 step:19945 [D loss: 0.767701, acc.: 46.88%] [G loss: 1.161580]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:21 step:19946 [D loss: 0.562015, acc.: 74.22%] [G loss: 1.098857]\n",
      "epoch:21 step:19947 [D loss: 0.686572, acc.: 53.91%] [G loss: 1.221813]\n",
      "epoch:21 step:19948 [D loss: 0.647397, acc.: 58.59%] [G loss: 1.069900]\n",
      "epoch:21 step:19949 [D loss: 0.574036, acc.: 71.88%] [G loss: 1.077802]\n",
      "epoch:21 step:19950 [D loss: 0.607367, acc.: 64.84%] [G loss: 1.200918]\n",
      "epoch:21 step:19951 [D loss: 0.689276, acc.: 57.81%] [G loss: 1.008214]\n",
      "epoch:21 step:19952 [D loss: 0.553444, acc.: 71.09%] [G loss: 1.185714]\n",
      "epoch:21 step:19953 [D loss: 0.502116, acc.: 76.56%] [G loss: 1.139353]\n",
      "epoch:21 step:19954 [D loss: 0.551955, acc.: 73.44%] [G loss: 1.561374]\n",
      "epoch:21 step:19955 [D loss: 0.433265, acc.: 84.38%] [G loss: 1.127322]\n",
      "epoch:21 step:19956 [D loss: 0.264902, acc.: 92.19%] [G loss: 1.979517]\n",
      "epoch:21 step:19957 [D loss: 0.550449, acc.: 74.22%] [G loss: 1.239507]\n",
      "epoch:21 step:19958 [D loss: 0.691090, acc.: 53.12%] [G loss: 1.418060]\n",
      "epoch:21 step:19959 [D loss: 0.533934, acc.: 75.00%] [G loss: 1.221889]\n",
      "epoch:21 step:19960 [D loss: 0.720683, acc.: 52.34%] [G loss: 1.149157]\n",
      "epoch:21 step:19961 [D loss: 0.534805, acc.: 76.56%] [G loss: 1.099461]\n",
      "epoch:21 step:19962 [D loss: 0.545686, acc.: 75.00%] [G loss: 1.179966]\n",
      "epoch:21 step:19963 [D loss: 0.505945, acc.: 76.56%] [G loss: 1.179530]\n",
      "epoch:21 step:19964 [D loss: 0.424977, acc.: 82.81%] [G loss: 0.960653]\n",
      "epoch:21 step:19965 [D loss: 0.466723, acc.: 77.34%] [G loss: 1.281851]\n",
      "epoch:21 step:19966 [D loss: 0.301904, acc.: 93.75%] [G loss: 1.376590]\n",
      "epoch:21 step:19967 [D loss: 0.343892, acc.: 90.62%] [G loss: 1.126206]\n",
      "epoch:21 step:19968 [D loss: 0.661096, acc.: 57.81%] [G loss: 1.066747]\n",
      "epoch:21 step:19969 [D loss: 0.357567, acc.: 91.41%] [G loss: 1.387276]\n",
      "epoch:21 step:19970 [D loss: 0.354534, acc.: 85.16%] [G loss: 1.342357]\n",
      "epoch:21 step:19971 [D loss: 0.700506, acc.: 64.84%] [G loss: 0.845665]\n",
      "epoch:21 step:19972 [D loss: 0.882321, acc.: 41.41%] [G loss: 0.814264]\n",
      "epoch:21 step:19973 [D loss: 0.810790, acc.: 43.75%] [G loss: 1.456137]\n",
      "epoch:21 step:19974 [D loss: 0.569317, acc.: 71.09%] [G loss: 1.365794]\n",
      "epoch:21 step:19975 [D loss: 0.411643, acc.: 85.94%] [G loss: 1.344176]\n",
      "epoch:21 step:19976 [D loss: 0.364684, acc.: 91.41%] [G loss: 1.251526]\n",
      "epoch:21 step:19977 [D loss: 0.505060, acc.: 78.91%] [G loss: 1.268738]\n",
      "epoch:21 step:19978 [D loss: 0.720393, acc.: 51.56%] [G loss: 0.920293]\n",
      "epoch:21 step:19979 [D loss: 0.623206, acc.: 66.41%] [G loss: 1.249703]\n",
      "epoch:21 step:19980 [D loss: 0.536800, acc.: 75.78%] [G loss: 1.313653]\n",
      "epoch:21 step:19981 [D loss: 0.777617, acc.: 43.75%] [G loss: 0.982485]\n",
      "epoch:21 step:19982 [D loss: 0.614754, acc.: 64.84%] [G loss: 1.114635]\n",
      "epoch:21 step:19983 [D loss: 0.619987, acc.: 64.84%] [G loss: 1.187505]\n",
      "epoch:21 step:19984 [D loss: 0.629904, acc.: 64.06%] [G loss: 1.253504]\n",
      "epoch:21 step:19985 [D loss: 0.718522, acc.: 57.81%] [G loss: 1.159848]\n",
      "epoch:21 step:19986 [D loss: 0.353935, acc.: 87.50%] [G loss: 1.140098]\n",
      "epoch:21 step:19987 [D loss: 0.681014, acc.: 58.59%] [G loss: 0.662043]\n",
      "epoch:21 step:19988 [D loss: 0.666080, acc.: 57.03%] [G loss: 0.958930]\n",
      "epoch:21 step:19989 [D loss: 0.396504, acc.: 74.22%] [G loss: 0.978741]\n",
      "epoch:21 step:19990 [D loss: 0.284272, acc.: 89.06%] [G loss: 1.267999]\n",
      "epoch:21 step:19991 [D loss: 0.290142, acc.: 88.28%] [G loss: 1.312868]\n",
      "epoch:21 step:19992 [D loss: 0.366714, acc.: 89.84%] [G loss: 1.236775]\n",
      "epoch:21 step:19993 [D loss: 0.516929, acc.: 75.78%] [G loss: 1.307692]\n",
      "epoch:21 step:19994 [D loss: 0.652287, acc.: 64.84%] [G loss: 1.171864]\n",
      "epoch:21 step:19995 [D loss: 0.598895, acc.: 65.62%] [G loss: 1.072994]\n",
      "epoch:21 step:19996 [D loss: 0.630230, acc.: 65.62%] [G loss: 1.224219]\n",
      "epoch:21 step:19997 [D loss: 0.544050, acc.: 75.00%] [G loss: 1.011206]\n",
      "epoch:21 step:19998 [D loss: 0.625752, acc.: 61.72%] [G loss: 1.034572]\n",
      "epoch:21 step:19999 [D loss: 0.515760, acc.: 75.78%] [G loss: 1.248189]\n",
      "epoch:21 step:20000 [D loss: 0.671065, acc.: 59.38%] [G loss: 0.822076]\n",
      "##############\n",
      "[3.88481344 2.17575773 6.67947962 5.35607332 4.66806895 5.76865649\n",
      " 4.76500249 5.14881684 5.91982579 5.00348692]\n",
      "##########\n",
      "epoch:21 step:20001 [D loss: 0.823705, acc.: 41.41%] [G loss: 1.018015]\n",
      "epoch:21 step:20002 [D loss: 0.645919, acc.: 56.25%] [G loss: 1.047403]\n",
      "epoch:21 step:20003 [D loss: 0.506570, acc.: 79.69%] [G loss: 0.845957]\n",
      "epoch:21 step:20004 [D loss: 0.328331, acc.: 89.06%] [G loss: 1.054639]\n",
      "epoch:21 step:20005 [D loss: 0.417486, acc.: 75.78%] [G loss: 1.091822]\n",
      "epoch:21 step:20006 [D loss: 0.608742, acc.: 65.62%] [G loss: 0.810985]\n",
      "epoch:21 step:20007 [D loss: 0.809855, acc.: 53.12%] [G loss: 0.785227]\n",
      "epoch:21 step:20008 [D loss: 0.677823, acc.: 57.81%] [G loss: 1.043262]\n",
      "epoch:21 step:20009 [D loss: 0.601382, acc.: 64.84%] [G loss: 0.865632]\n",
      "epoch:21 step:20010 [D loss: 0.457915, acc.: 79.69%] [G loss: 1.030496]\n",
      "epoch:21 step:20011 [D loss: 0.285684, acc.: 86.72%] [G loss: 1.114240]\n",
      "epoch:21 step:20012 [D loss: 0.500513, acc.: 79.69%] [G loss: 0.876161]\n",
      "epoch:21 step:20013 [D loss: 0.276458, acc.: 89.06%] [G loss: 1.148597]\n",
      "epoch:21 step:20014 [D loss: 0.505222, acc.: 77.34%] [G loss: 1.293285]\n",
      "epoch:21 step:20015 [D loss: 0.513370, acc.: 75.78%] [G loss: 1.399636]\n",
      "epoch:21 step:20016 [D loss: 0.572178, acc.: 67.97%] [G loss: 1.248225]\n",
      "epoch:21 step:20017 [D loss: 0.749880, acc.: 49.22%] [G loss: 0.955116]\n",
      "epoch:21 step:20018 [D loss: 0.691670, acc.: 52.34%] [G loss: 0.592911]\n",
      "epoch:21 step:20019 [D loss: 0.230748, acc.: 94.53%] [G loss: 1.236957]\n",
      "epoch:21 step:20020 [D loss: 0.220016, acc.: 89.84%] [G loss: 1.427317]\n",
      "epoch:21 step:20021 [D loss: 0.204624, acc.: 96.09%] [G loss: 1.361628]\n",
      "epoch:21 step:20022 [D loss: 0.250353, acc.: 96.88%] [G loss: 0.641584]\n",
      "epoch:21 step:20023 [D loss: 0.174401, acc.: 94.53%] [G loss: 1.564732]\n",
      "epoch:21 step:20024 [D loss: 0.130696, acc.: 98.44%] [G loss: 0.870951]\n",
      "epoch:21 step:20025 [D loss: 0.689874, acc.: 59.38%] [G loss: 1.702492]\n",
      "epoch:21 step:20026 [D loss: 1.423362, acc.: 14.84%] [G loss: 1.599099]\n",
      "epoch:21 step:20027 [D loss: 0.309592, acc.: 94.53%] [G loss: 1.717470]\n",
      "epoch:21 step:20028 [D loss: 0.733685, acc.: 53.91%] [G loss: 1.675411]\n",
      "epoch:21 step:20029 [D loss: 0.622105, acc.: 65.62%] [G loss: 1.401476]\n",
      "epoch:21 step:20030 [D loss: 0.573484, acc.: 71.09%] [G loss: 1.448736]\n",
      "epoch:21 step:20031 [D loss: 0.530403, acc.: 74.22%] [G loss: 1.394272]\n",
      "epoch:21 step:20032 [D loss: 0.745098, acc.: 53.12%] [G loss: 1.447529]\n",
      "epoch:21 step:20033 [D loss: 0.613356, acc.: 70.31%] [G loss: 1.348075]\n",
      "epoch:21 step:20034 [D loss: 0.665758, acc.: 56.25%] [G loss: 1.120999]\n",
      "epoch:21 step:20035 [D loss: 0.417346, acc.: 83.59%] [G loss: 1.174804]\n",
      "epoch:21 step:20036 [D loss: 0.449090, acc.: 83.59%] [G loss: 1.055061]\n",
      "epoch:21 step:20037 [D loss: 0.433199, acc.: 83.59%] [G loss: 0.837933]\n",
      "epoch:21 step:20038 [D loss: 0.602229, acc.: 64.84%] [G loss: 1.141096]\n",
      "epoch:21 step:20039 [D loss: 0.425150, acc.: 85.16%] [G loss: 1.027293]\n",
      "epoch:21 step:20040 [D loss: 0.469720, acc.: 81.25%] [G loss: 0.967125]\n",
      "epoch:21 step:20041 [D loss: 0.507267, acc.: 75.78%] [G loss: 1.054178]\n",
      "epoch:21 step:20042 [D loss: 0.398758, acc.: 80.47%] [G loss: 0.969085]\n",
      "epoch:21 step:20043 [D loss: 0.309909, acc.: 81.25%] [G loss: 1.406361]\n",
      "epoch:21 step:20044 [D loss: 0.443333, acc.: 82.03%] [G loss: 1.211824]\n",
      "epoch:21 step:20045 [D loss: 0.716932, acc.: 58.59%] [G loss: 1.227200]\n",
      "epoch:21 step:20046 [D loss: 0.610679, acc.: 67.19%] [G loss: 0.909341]\n",
      "epoch:21 step:20047 [D loss: 0.767360, acc.: 57.03%] [G loss: 1.306061]\n",
      "epoch:21 step:20048 [D loss: 0.644527, acc.: 60.16%] [G loss: 1.080306]\n",
      "epoch:21 step:20049 [D loss: 0.589901, acc.: 67.97%] [G loss: 1.193162]\n",
      "epoch:21 step:20050 [D loss: 0.703086, acc.: 51.56%] [G loss: 1.231508]\n",
      "epoch:21 step:20051 [D loss: 0.810605, acc.: 43.75%] [G loss: 1.247582]\n",
      "epoch:21 step:20052 [D loss: 0.672860, acc.: 61.72%] [G loss: 1.146458]\n",
      "epoch:21 step:20053 [D loss: 0.623175, acc.: 68.75%] [G loss: 1.067966]\n",
      "epoch:21 step:20054 [D loss: 0.351017, acc.: 82.81%] [G loss: 1.219518]\n",
      "epoch:21 step:20055 [D loss: 0.193013, acc.: 96.88%] [G loss: 1.397932]\n",
      "epoch:21 step:20056 [D loss: 0.856809, acc.: 42.19%] [G loss: 1.151486]\n",
      "epoch:21 step:20057 [D loss: 0.543605, acc.: 77.34%] [G loss: 1.182554]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:21 step:20058 [D loss: 0.631803, acc.: 62.50%] [G loss: 0.859596]\n",
      "epoch:21 step:20059 [D loss: 0.717075, acc.: 55.47%] [G loss: 0.914403]\n",
      "epoch:21 step:20060 [D loss: 0.607041, acc.: 67.97%] [G loss: 1.130523]\n",
      "epoch:21 step:20061 [D loss: 0.450093, acc.: 79.69%] [G loss: 1.235956]\n",
      "epoch:21 step:20062 [D loss: 0.681703, acc.: 59.38%] [G loss: 1.072587]\n",
      "epoch:21 step:20063 [D loss: 0.659810, acc.: 59.38%] [G loss: 0.905967]\n",
      "epoch:21 step:20064 [D loss: 0.655316, acc.: 64.84%] [G loss: 1.112600]\n",
      "epoch:21 step:20065 [D loss: 0.494115, acc.: 73.44%] [G loss: 0.933118]\n",
      "epoch:21 step:20066 [D loss: 0.340646, acc.: 86.72%] [G loss: 0.855227]\n",
      "epoch:21 step:20067 [D loss: 0.294614, acc.: 92.19%] [G loss: 0.750811]\n",
      "epoch:21 step:20068 [D loss: 0.586540, acc.: 68.75%] [G loss: 1.116127]\n",
      "epoch:21 step:20069 [D loss: 0.598733, acc.: 61.72%] [G loss: 0.893711]\n",
      "epoch:21 step:20070 [D loss: 0.516532, acc.: 70.31%] [G loss: 1.235806]\n",
      "epoch:21 step:20071 [D loss: 0.596743, acc.: 66.41%] [G loss: 1.193748]\n",
      "epoch:21 step:20072 [D loss: 0.743116, acc.: 53.12%] [G loss: 1.066809]\n",
      "epoch:21 step:20073 [D loss: 0.526639, acc.: 64.84%] [G loss: 1.009323]\n",
      "epoch:21 step:20074 [D loss: 0.332276, acc.: 82.03%] [G loss: 1.813956]\n",
      "epoch:21 step:20075 [D loss: 0.154280, acc.: 97.66%] [G loss: 1.547243]\n",
      "epoch:21 step:20076 [D loss: 0.117297, acc.: 98.44%] [G loss: 1.922067]\n",
      "epoch:21 step:20077 [D loss: 0.265265, acc.: 97.66%] [G loss: 2.010794]\n",
      "epoch:21 step:20078 [D loss: 0.408089, acc.: 89.84%] [G loss: 1.977869]\n",
      "epoch:21 step:20079 [D loss: 0.106704, acc.: 99.22%] [G loss: 0.817324]\n",
      "epoch:21 step:20080 [D loss: 0.185762, acc.: 99.22%] [G loss: 2.012813]\n",
      "epoch:21 step:20081 [D loss: 0.176650, acc.: 98.44%] [G loss: 1.302362]\n",
      "epoch:21 step:20082 [D loss: 0.102455, acc.: 100.00%] [G loss: 1.456406]\n",
      "epoch:21 step:20083 [D loss: 0.115655, acc.: 100.00%] [G loss: 1.071682]\n",
      "epoch:21 step:20084 [D loss: 0.155658, acc.: 96.88%] [G loss: 1.908192]\n",
      "epoch:21 step:20085 [D loss: 0.095226, acc.: 100.00%] [G loss: 1.161521]\n",
      "epoch:21 step:20086 [D loss: 0.349528, acc.: 78.91%] [G loss: 2.358036]\n",
      "epoch:21 step:20087 [D loss: 0.740182, acc.: 57.81%] [G loss: 0.804345]\n",
      "epoch:21 step:20088 [D loss: 1.198115, acc.: 50.78%] [G loss: 0.908559]\n",
      "epoch:21 step:20089 [D loss: 2.024254, acc.: 26.56%] [G loss: 2.188210]\n",
      "epoch:21 step:20090 [D loss: 0.609598, acc.: 66.41%] [G loss: 1.290887]\n",
      "epoch:21 step:20091 [D loss: 0.483552, acc.: 76.56%] [G loss: 1.286403]\n",
      "epoch:21 step:20092 [D loss: 0.698470, acc.: 59.38%] [G loss: 0.654554]\n",
      "epoch:21 step:20093 [D loss: 0.480445, acc.: 79.69%] [G loss: 1.434101]\n",
      "epoch:21 step:20094 [D loss: 0.409725, acc.: 83.59%] [G loss: 0.514703]\n",
      "epoch:21 step:20095 [D loss: 1.284966, acc.: 50.78%] [G loss: 0.916405]\n",
      "epoch:21 step:20096 [D loss: 0.385185, acc.: 82.81%] [G loss: 2.686827]\n",
      "epoch:21 step:20097 [D loss: 0.894654, acc.: 53.91%] [G loss: 1.053183]\n",
      "epoch:21 step:20098 [D loss: 1.092810, acc.: 36.72%] [G loss: 1.176237]\n",
      "epoch:21 step:20099 [D loss: 1.308981, acc.: 17.97%] [G loss: 1.029853]\n",
      "epoch:21 step:20100 [D loss: 0.740894, acc.: 54.69%] [G loss: 1.588024]\n",
      "epoch:21 step:20101 [D loss: 0.657691, acc.: 63.28%] [G loss: 1.722896]\n",
      "epoch:21 step:20102 [D loss: 0.641674, acc.: 66.41%] [G loss: 1.484227]\n",
      "epoch:21 step:20103 [D loss: 1.006671, acc.: 36.72%] [G loss: 1.639645]\n",
      "epoch:21 step:20104 [D loss: 0.655675, acc.: 57.81%] [G loss: 1.380511]\n",
      "epoch:21 step:20105 [D loss: 0.551554, acc.: 73.44%] [G loss: 0.957405]\n",
      "epoch:21 step:20106 [D loss: 0.576133, acc.: 68.75%] [G loss: 0.929716]\n",
      "epoch:21 step:20107 [D loss: 0.594280, acc.: 69.53%] [G loss: 1.113477]\n",
      "epoch:21 step:20108 [D loss: 0.713262, acc.: 57.81%] [G loss: 1.209611]\n",
      "epoch:21 step:20109 [D loss: 0.919445, acc.: 34.38%] [G loss: 1.400008]\n",
      "epoch:21 step:20110 [D loss: 0.783492, acc.: 44.53%] [G loss: 2.263680]\n",
      "epoch:21 step:20111 [D loss: 0.718750, acc.: 50.78%] [G loss: 1.858949]\n",
      "epoch:21 step:20112 [D loss: 0.597656, acc.: 61.72%] [G loss: 1.812427]\n",
      "epoch:21 step:20113 [D loss: 0.638150, acc.: 59.38%] [G loss: 2.078299]\n",
      "epoch:21 step:20114 [D loss: 0.648335, acc.: 56.25%] [G loss: 2.052073]\n",
      "epoch:21 step:20115 [D loss: 0.907891, acc.: 44.53%] [G loss: 1.444430]\n",
      "epoch:21 step:20116 [D loss: 0.588814, acc.: 60.94%] [G loss: 1.453178]\n",
      "epoch:21 step:20117 [D loss: 0.507442, acc.: 76.56%] [G loss: 1.615339]\n",
      "epoch:21 step:20118 [D loss: 0.463495, acc.: 76.56%] [G loss: 1.671293]\n",
      "epoch:21 step:20119 [D loss: 0.518417, acc.: 74.22%] [G loss: 1.466167]\n",
      "epoch:21 step:20120 [D loss: 0.638091, acc.: 66.41%] [G loss: 1.725293]\n",
      "epoch:21 step:20121 [D loss: 0.513793, acc.: 76.56%] [G loss: 1.939388]\n",
      "epoch:21 step:20122 [D loss: 0.712966, acc.: 59.38%] [G loss: 1.519406]\n",
      "epoch:21 step:20123 [D loss: 0.622782, acc.: 65.62%] [G loss: 1.456122]\n",
      "epoch:21 step:20124 [D loss: 0.633027, acc.: 67.97%] [G loss: 1.354515]\n",
      "epoch:21 step:20125 [D loss: 0.531704, acc.: 77.34%] [G loss: 1.916177]\n",
      "epoch:21 step:20126 [D loss: 0.324049, acc.: 92.97%] [G loss: 2.522336]\n",
      "epoch:21 step:20127 [D loss: 0.405578, acc.: 92.19%] [G loss: 1.249975]\n",
      "epoch:21 step:20128 [D loss: 0.314317, acc.: 92.19%] [G loss: 1.630049]\n",
      "epoch:21 step:20129 [D loss: 0.349122, acc.: 92.97%] [G loss: 1.304753]\n",
      "epoch:21 step:20130 [D loss: 0.234372, acc.: 97.66%] [G loss: 2.325338]\n",
      "epoch:21 step:20131 [D loss: 0.437915, acc.: 84.38%] [G loss: 2.039697]\n",
      "epoch:21 step:20132 [D loss: 0.387938, acc.: 92.19%] [G loss: 1.187891]\n",
      "epoch:21 step:20133 [D loss: 0.271868, acc.: 94.53%] [G loss: 1.329033]\n",
      "epoch:21 step:20134 [D loss: 0.413700, acc.: 90.62%] [G loss: 1.755702]\n",
      "epoch:21 step:20135 [D loss: 0.782906, acc.: 54.69%] [G loss: 1.257831]\n",
      "epoch:21 step:20136 [D loss: 0.854697, acc.: 49.22%] [G loss: 1.523179]\n",
      "epoch:21 step:20137 [D loss: 0.704574, acc.: 60.16%] [G loss: 0.816906]\n",
      "epoch:21 step:20138 [D loss: 0.893383, acc.: 35.94%] [G loss: 0.980786]\n",
      "epoch:21 step:20139 [D loss: 1.063192, acc.: 28.12%] [G loss: 0.842004]\n",
      "epoch:21 step:20140 [D loss: 0.743272, acc.: 53.12%] [G loss: 0.749248]\n",
      "epoch:21 step:20141 [D loss: 0.630148, acc.: 67.19%] [G loss: 0.899935]\n",
      "epoch:21 step:20142 [D loss: 0.487953, acc.: 75.78%] [G loss: 0.920293]\n",
      "epoch:21 step:20143 [D loss: 0.573998, acc.: 73.44%] [G loss: 0.967338]\n",
      "epoch:21 step:20144 [D loss: 0.546093, acc.: 72.66%] [G loss: 1.142906]\n",
      "epoch:21 step:20145 [D loss: 0.318512, acc.: 89.84%] [G loss: 0.857695]\n",
      "epoch:21 step:20146 [D loss: 0.382038, acc.: 85.94%] [G loss: 1.235996]\n",
      "epoch:21 step:20147 [D loss: 0.267779, acc.: 94.53%] [G loss: 1.229877]\n",
      "epoch:21 step:20148 [D loss: 0.253978, acc.: 91.41%] [G loss: 1.326548]\n",
      "epoch:21 step:20149 [D loss: 0.457836, acc.: 85.16%] [G loss: 1.073581]\n",
      "epoch:21 step:20150 [D loss: 0.963489, acc.: 51.56%] [G loss: 0.952719]\n",
      "epoch:21 step:20151 [D loss: 0.902690, acc.: 39.84%] [G loss: 1.121527]\n",
      "epoch:21 step:20152 [D loss: 0.680678, acc.: 58.59%] [G loss: 1.119518]\n",
      "epoch:21 step:20153 [D loss: 0.735132, acc.: 57.81%] [G loss: 1.081918]\n",
      "epoch:21 step:20154 [D loss: 0.586960, acc.: 67.19%] [G loss: 0.888680]\n",
      "epoch:21 step:20155 [D loss: 0.559539, acc.: 80.47%] [G loss: 0.964185]\n",
      "epoch:21 step:20156 [D loss: 0.406125, acc.: 88.28%] [G loss: 1.077544]\n",
      "epoch:21 step:20157 [D loss: 0.517561, acc.: 78.91%] [G loss: 1.156949]\n",
      "epoch:21 step:20158 [D loss: 0.406594, acc.: 82.81%] [G loss: 1.164830]\n",
      "epoch:21 step:20159 [D loss: 0.724110, acc.: 57.81%] [G loss: 1.473957]\n",
      "epoch:21 step:20160 [D loss: 0.546265, acc.: 73.44%] [G loss: 1.225404]\n",
      "epoch:21 step:20161 [D loss: 0.461639, acc.: 78.91%] [G loss: 1.327182]\n",
      "epoch:21 step:20162 [D loss: 0.570186, acc.: 71.88%] [G loss: 1.356253]\n",
      "epoch:21 step:20163 [D loss: 0.619353, acc.: 70.31%] [G loss: 1.352308]\n",
      "epoch:21 step:20164 [D loss: 0.539397, acc.: 75.00%] [G loss: 1.357874]\n",
      "epoch:21 step:20165 [D loss: 0.542003, acc.: 68.75%] [G loss: 1.371577]\n",
      "epoch:21 step:20166 [D loss: 0.541637, acc.: 72.66%] [G loss: 1.251031]\n",
      "epoch:21 step:20167 [D loss: 0.482707, acc.: 82.03%] [G loss: 1.294459]\n",
      "epoch:21 step:20168 [D loss: 0.544681, acc.: 75.78%] [G loss: 1.172503]\n",
      "epoch:21 step:20169 [D loss: 0.733021, acc.: 54.69%] [G loss: 1.154753]\n",
      "epoch:21 step:20170 [D loss: 0.723589, acc.: 54.69%] [G loss: 1.194957]\n",
      "epoch:21 step:20171 [D loss: 0.586484, acc.: 74.22%] [G loss: 1.244283]\n",
      "epoch:21 step:20172 [D loss: 0.671693, acc.: 56.25%] [G loss: 1.093257]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:21 step:20173 [D loss: 0.647679, acc.: 64.06%] [G loss: 1.480192]\n",
      "epoch:21 step:20174 [D loss: 0.509410, acc.: 74.22%] [G loss: 1.226744]\n",
      "epoch:21 step:20175 [D loss: 0.314592, acc.: 87.50%] [G loss: 1.259540]\n",
      "epoch:21 step:20176 [D loss: 0.290276, acc.: 89.06%] [G loss: 1.274011]\n",
      "epoch:21 step:20177 [D loss: 0.689806, acc.: 60.94%] [G loss: 1.123890]\n",
      "epoch:21 step:20178 [D loss: 0.696824, acc.: 53.12%] [G loss: 1.323976]\n",
      "epoch:21 step:20179 [D loss: 0.828767, acc.: 47.66%] [G loss: 1.508658]\n",
      "epoch:21 step:20180 [D loss: 0.336215, acc.: 94.53%] [G loss: 1.241754]\n",
      "epoch:21 step:20181 [D loss: 0.294079, acc.: 92.97%] [G loss: 1.472625]\n",
      "epoch:21 step:20182 [D loss: 0.467366, acc.: 78.91%] [G loss: 1.396956]\n",
      "epoch:21 step:20183 [D loss: 0.640366, acc.: 60.16%] [G loss: 1.337587]\n",
      "epoch:21 step:20184 [D loss: 0.431118, acc.: 82.03%] [G loss: 1.327114]\n",
      "epoch:21 step:20185 [D loss: 0.424283, acc.: 85.16%] [G loss: 1.309610]\n",
      "epoch:21 step:20186 [D loss: 0.726508, acc.: 52.34%] [G loss: 1.173233]\n",
      "epoch:21 step:20187 [D loss: 0.505538, acc.: 83.59%] [G loss: 1.083594]\n",
      "epoch:21 step:20188 [D loss: 0.353200, acc.: 89.06%] [G loss: 1.263487]\n",
      "epoch:21 step:20189 [D loss: 0.421568, acc.: 86.72%] [G loss: 1.426250]\n",
      "epoch:21 step:20190 [D loss: 0.323542, acc.: 92.19%] [G loss: 1.336141]\n",
      "epoch:21 step:20191 [D loss: 0.424099, acc.: 87.50%] [G loss: 1.212829]\n",
      "epoch:21 step:20192 [D loss: 0.337695, acc.: 94.53%] [G loss: 1.258726]\n",
      "epoch:21 step:20193 [D loss: 0.676603, acc.: 62.50%] [G loss: 1.308101]\n",
      "epoch:21 step:20194 [D loss: 0.360340, acc.: 85.16%] [G loss: 1.312325]\n",
      "epoch:21 step:20195 [D loss: 0.586223, acc.: 69.53%] [G loss: 1.361791]\n",
      "epoch:21 step:20196 [D loss: 0.586728, acc.: 68.75%] [G loss: 1.372331]\n",
      "epoch:21 step:20197 [D loss: 0.467996, acc.: 75.78%] [G loss: 1.157483]\n",
      "epoch:21 step:20198 [D loss: 0.486843, acc.: 80.47%] [G loss: 1.202791]\n",
      "epoch:21 step:20199 [D loss: 0.425619, acc.: 85.94%] [G loss: 1.112438]\n",
      "epoch:21 step:20200 [D loss: 0.420006, acc.: 92.19%] [G loss: 0.903569]\n",
      "##############\n",
      "[4.01503663 2.73992859 6.66723624 5.10213204 4.80692926 5.84733622\n",
      " 5.08672891 5.78171468 6.02390082 5.27011077]\n",
      "##########\n",
      "epoch:21 step:20201 [D loss: 0.326123, acc.: 87.50%] [G loss: 1.184358]\n",
      "epoch:21 step:20202 [D loss: 0.805242, acc.: 46.09%] [G loss: 1.453549]\n",
      "epoch:21 step:20203 [D loss: 0.755245, acc.: 51.56%] [G loss: 1.334995]\n",
      "epoch:21 step:20204 [D loss: 0.427848, acc.: 78.91%] [G loss: 1.187631]\n",
      "epoch:21 step:20205 [D loss: 0.956557, acc.: 39.06%] [G loss: 1.273494]\n",
      "epoch:21 step:20206 [D loss: 0.729923, acc.: 53.91%] [G loss: 1.221057]\n",
      "epoch:21 step:20207 [D loss: 0.480198, acc.: 80.47%] [G loss: 0.871158]\n",
      "epoch:21 step:20208 [D loss: 0.721879, acc.: 54.69%] [G loss: 1.193424]\n",
      "epoch:21 step:20209 [D loss: 0.494730, acc.: 75.78%] [G loss: 1.089784]\n",
      "epoch:21 step:20210 [D loss: 0.431933, acc.: 84.38%] [G loss: 1.166982]\n",
      "epoch:21 step:20211 [D loss: 0.454959, acc.: 86.72%] [G loss: 1.187313]\n",
      "epoch:21 step:20212 [D loss: 0.255664, acc.: 92.97%] [G loss: 1.406985]\n",
      "epoch:21 step:20213 [D loss: 0.202486, acc.: 96.09%] [G loss: 1.482699]\n",
      "epoch:21 step:20214 [D loss: 0.308913, acc.: 89.06%] [G loss: 1.679967]\n",
      "epoch:21 step:20215 [D loss: 0.373333, acc.: 86.72%] [G loss: 1.619288]\n",
      "epoch:21 step:20216 [D loss: 0.625469, acc.: 67.19%] [G loss: 1.429501]\n",
      "epoch:21 step:20217 [D loss: 0.626752, acc.: 64.06%] [G loss: 1.640353]\n",
      "epoch:21 step:20218 [D loss: 0.605368, acc.: 68.75%] [G loss: 1.186320]\n",
      "epoch:21 step:20219 [D loss: 0.451789, acc.: 80.47%] [G loss: 1.456929]\n",
      "epoch:21 step:20220 [D loss: 0.331975, acc.: 92.19%] [G loss: 1.554515]\n",
      "epoch:21 step:20221 [D loss: 0.568651, acc.: 63.28%] [G loss: 1.594768]\n",
      "epoch:21 step:20222 [D loss: 0.442799, acc.: 82.81%] [G loss: 1.433625]\n",
      "epoch:21 step:20223 [D loss: 0.564119, acc.: 73.44%] [G loss: 1.574925]\n",
      "epoch:21 step:20224 [D loss: 0.380986, acc.: 84.38%] [G loss: 1.089790]\n",
      "epoch:21 step:20225 [D loss: 0.319892, acc.: 91.41%] [G loss: 1.567250]\n",
      "epoch:21 step:20226 [D loss: 0.202233, acc.: 97.66%] [G loss: 1.401645]\n",
      "epoch:21 step:20227 [D loss: 0.220638, acc.: 95.31%] [G loss: 1.739451]\n",
      "epoch:21 step:20228 [D loss: 0.317582, acc.: 92.97%] [G loss: 2.059092]\n",
      "epoch:21 step:20229 [D loss: 0.257564, acc.: 95.31%] [G loss: 1.461224]\n",
      "epoch:21 step:20230 [D loss: 0.496811, acc.: 78.91%] [G loss: 1.798657]\n",
      "epoch:21 step:20231 [D loss: 0.201792, acc.: 95.31%] [G loss: 1.780290]\n",
      "epoch:21 step:20232 [D loss: 0.310373, acc.: 94.53%] [G loss: 1.223371]\n",
      "epoch:21 step:20233 [D loss: 0.232447, acc.: 95.31%] [G loss: 0.873357]\n",
      "epoch:21 step:20234 [D loss: 0.163945, acc.: 100.00%] [G loss: 1.611722]\n",
      "epoch:21 step:20235 [D loss: 0.250823, acc.: 97.66%] [G loss: 1.514021]\n",
      "epoch:21 step:20236 [D loss: 0.243244, acc.: 96.88%] [G loss: 0.795713]\n",
      "epoch:21 step:20237 [D loss: 0.822833, acc.: 50.00%] [G loss: 1.913986]\n",
      "epoch:21 step:20238 [D loss: 0.400553, acc.: 77.34%] [G loss: 2.208179]\n",
      "epoch:21 step:20239 [D loss: 0.849138, acc.: 59.38%] [G loss: 1.373983]\n",
      "epoch:21 step:20240 [D loss: 0.723783, acc.: 56.25%] [G loss: 1.021351]\n",
      "epoch:21 step:20241 [D loss: 0.864745, acc.: 45.31%] [G loss: 1.304245]\n",
      "epoch:21 step:20242 [D loss: 0.611664, acc.: 64.06%] [G loss: 1.405315]\n",
      "epoch:21 step:20243 [D loss: 0.250728, acc.: 90.62%] [G loss: 1.468652]\n",
      "epoch:21 step:20244 [D loss: 0.143785, acc.: 100.00%] [G loss: 1.537356]\n",
      "epoch:21 step:20245 [D loss: 0.388347, acc.: 86.72%] [G loss: 1.534764]\n",
      "epoch:21 step:20246 [D loss: 0.711825, acc.: 60.16%] [G loss: 1.471932]\n",
      "epoch:21 step:20247 [D loss: 0.460535, acc.: 78.12%] [G loss: 1.106618]\n",
      "epoch:21 step:20248 [D loss: 0.681764, acc.: 61.72%] [G loss: 1.185321]\n",
      "epoch:21 step:20249 [D loss: 0.680285, acc.: 59.38%] [G loss: 0.726108]\n",
      "epoch:21 step:20250 [D loss: 0.598075, acc.: 68.75%] [G loss: 1.027495]\n",
      "epoch:21 step:20251 [D loss: 0.702814, acc.: 60.94%] [G loss: 1.449218]\n",
      "epoch:21 step:20252 [D loss: 0.474626, acc.: 79.69%] [G loss: 1.710281]\n",
      "epoch:21 step:20253 [D loss: 0.824964, acc.: 57.03%] [G loss: 1.700476]\n",
      "epoch:21 step:20254 [D loss: 0.162682, acc.: 96.88%] [G loss: 0.949281]\n",
      "epoch:21 step:20255 [D loss: 0.337970, acc.: 91.41%] [G loss: 2.156618]\n",
      "epoch:21 step:20256 [D loss: 0.247713, acc.: 93.75%] [G loss: 0.875517]\n",
      "epoch:21 step:20257 [D loss: 0.808145, acc.: 52.34%] [G loss: 1.446889]\n",
      "epoch:21 step:20258 [D loss: 0.788745, acc.: 50.78%] [G loss: 0.819265]\n",
      "epoch:21 step:20259 [D loss: 0.652406, acc.: 65.62%] [G loss: 1.564653]\n",
      "epoch:21 step:20260 [D loss: 0.712787, acc.: 60.16%] [G loss: 1.220299]\n",
      "epoch:21 step:20261 [D loss: 0.755842, acc.: 52.34%] [G loss: 1.477656]\n",
      "epoch:21 step:20262 [D loss: 0.580474, acc.: 71.09%] [G loss: 0.913898]\n",
      "epoch:21 step:20263 [D loss: 0.711989, acc.: 54.69%] [G loss: 0.759187]\n",
      "epoch:21 step:20264 [D loss: 0.260837, acc.: 92.97%] [G loss: 1.423679]\n",
      "epoch:21 step:20265 [D loss: 0.313626, acc.: 86.72%] [G loss: 1.245591]\n",
      "epoch:21 step:20266 [D loss: 0.271185, acc.: 92.19%] [G loss: 1.135848]\n",
      "epoch:21 step:20267 [D loss: 0.665709, acc.: 62.50%] [G loss: 1.322433]\n",
      "epoch:21 step:20268 [D loss: 0.409446, acc.: 82.03%] [G loss: 1.517069]\n",
      "epoch:21 step:20269 [D loss: 0.263269, acc.: 96.88%] [G loss: 1.072930]\n",
      "epoch:21 step:20270 [D loss: 0.630358, acc.: 66.41%] [G loss: 1.323845]\n",
      "epoch:21 step:20271 [D loss: 0.746576, acc.: 55.47%] [G loss: 1.218574]\n",
      "epoch:21 step:20272 [D loss: 0.357018, acc.: 92.19%] [G loss: 1.040130]\n",
      "epoch:21 step:20273 [D loss: 0.547860, acc.: 70.31%] [G loss: 1.394789]\n",
      "epoch:21 step:20274 [D loss: 0.631806, acc.: 61.72%] [G loss: 1.345276]\n",
      "epoch:21 step:20275 [D loss: 0.606620, acc.: 69.53%] [G loss: 1.348778]\n",
      "epoch:21 step:20276 [D loss: 0.598092, acc.: 67.97%] [G loss: 1.037949]\n",
      "epoch:21 step:20277 [D loss: 0.471088, acc.: 70.31%] [G loss: 1.116962]\n",
      "epoch:21 step:20278 [D loss: 0.327519, acc.: 90.62%] [G loss: 1.333240]\n",
      "epoch:21 step:20279 [D loss: 0.375416, acc.: 87.50%] [G loss: 1.574898]\n",
      "epoch:21 step:20280 [D loss: 0.424623, acc.: 84.38%] [G loss: 1.719649]\n",
      "epoch:21 step:20281 [D loss: 0.314327, acc.: 93.75%] [G loss: 1.289774]\n",
      "epoch:21 step:20282 [D loss: 0.899557, acc.: 52.34%] [G loss: 1.414176]\n",
      "epoch:21 step:20283 [D loss: 0.693283, acc.: 62.50%] [G loss: 1.667260]\n",
      "epoch:21 step:20284 [D loss: 0.753308, acc.: 53.12%] [G loss: 1.217747]\n",
      "epoch:21 step:20285 [D loss: 0.751172, acc.: 56.25%] [G loss: 1.239353]\n",
      "epoch:21 step:20286 [D loss: 0.495535, acc.: 74.22%] [G loss: 1.009636]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:21 step:20287 [D loss: 0.521567, acc.: 78.91%] [G loss: 1.418046]\n",
      "epoch:21 step:20288 [D loss: 0.620164, acc.: 61.72%] [G loss: 1.292328]\n",
      "epoch:21 step:20289 [D loss: 0.611762, acc.: 67.97%] [G loss: 1.205532]\n",
      "epoch:21 step:20290 [D loss: 0.490050, acc.: 78.12%] [G loss: 1.247805]\n",
      "epoch:21 step:20291 [D loss: 0.677034, acc.: 57.03%] [G loss: 1.335365]\n",
      "epoch:21 step:20292 [D loss: 0.461354, acc.: 82.03%] [G loss: 1.159326]\n",
      "epoch:21 step:20293 [D loss: 0.372639, acc.: 80.47%] [G loss: 1.285559]\n",
      "epoch:21 step:20294 [D loss: 0.356007, acc.: 91.41%] [G loss: 1.508257]\n",
      "epoch:21 step:20295 [D loss: 0.611151, acc.: 63.28%] [G loss: 1.319467]\n",
      "epoch:21 step:20296 [D loss: 0.510585, acc.: 77.34%] [G loss: 1.210528]\n",
      "epoch:21 step:20297 [D loss: 0.610913, acc.: 62.50%] [G loss: 1.234540]\n",
      "epoch:21 step:20298 [D loss: 0.615397, acc.: 67.19%] [G loss: 1.274699]\n",
      "epoch:21 step:20299 [D loss: 0.608407, acc.: 63.28%] [G loss: 1.319727]\n",
      "epoch:21 step:20300 [D loss: 0.503750, acc.: 82.81%] [G loss: 1.606973]\n",
      "epoch:21 step:20301 [D loss: 0.423788, acc.: 77.34%] [G loss: 1.250280]\n",
      "epoch:21 step:20302 [D loss: 0.564269, acc.: 71.88%] [G loss: 0.989570]\n",
      "epoch:21 step:20303 [D loss: 0.686550, acc.: 60.16%] [G loss: 1.145634]\n",
      "epoch:21 step:20304 [D loss: 0.648584, acc.: 66.41%] [G loss: 1.494667]\n",
      "epoch:21 step:20305 [D loss: 0.733243, acc.: 55.47%] [G loss: 1.299357]\n",
      "epoch:21 step:20306 [D loss: 0.432730, acc.: 89.06%] [G loss: 1.280869]\n",
      "epoch:21 step:20307 [D loss: 0.332470, acc.: 89.84%] [G loss: 1.224534]\n",
      "epoch:21 step:20308 [D loss: 0.722088, acc.: 58.59%] [G loss: 0.795497]\n",
      "epoch:21 step:20309 [D loss: 0.408811, acc.: 86.72%] [G loss: 0.739813]\n",
      "epoch:21 step:20310 [D loss: 0.382178, acc.: 76.56%] [G loss: 1.363037]\n",
      "epoch:21 step:20311 [D loss: 0.304536, acc.: 93.75%] [G loss: 0.654698]\n",
      "epoch:21 step:20312 [D loss: 0.562936, acc.: 70.31%] [G loss: 1.083175]\n",
      "epoch:21 step:20313 [D loss: 0.792531, acc.: 52.34%] [G loss: 1.300262]\n",
      "epoch:21 step:20314 [D loss: 0.982686, acc.: 42.19%] [G loss: 0.822220]\n",
      "epoch:21 step:20315 [D loss: 0.778878, acc.: 48.44%] [G loss: 1.296854]\n",
      "epoch:21 step:20316 [D loss: 0.702242, acc.: 58.59%] [G loss: 1.564984]\n",
      "epoch:21 step:20317 [D loss: 0.952495, acc.: 31.25%] [G loss: 1.325752]\n",
      "epoch:21 step:20318 [D loss: 0.178159, acc.: 94.53%] [G loss: 2.377284]\n",
      "epoch:21 step:20319 [D loss: 0.635462, acc.: 66.41%] [G loss: 1.931163]\n",
      "epoch:21 step:20320 [D loss: 0.969312, acc.: 48.44%] [G loss: 1.767810]\n",
      "epoch:21 step:20321 [D loss: 0.541989, acc.: 71.88%] [G loss: 1.246196]\n",
      "epoch:21 step:20322 [D loss: 0.580860, acc.: 67.19%] [G loss: 1.085526]\n",
      "epoch:21 step:20323 [D loss: 0.475159, acc.: 78.91%] [G loss: 1.231197]\n",
      "epoch:21 step:20324 [D loss: 0.596903, acc.: 67.19%] [G loss: 1.180021]\n",
      "epoch:21 step:20325 [D loss: 0.430737, acc.: 84.38%] [G loss: 1.347348]\n",
      "epoch:21 step:20326 [D loss: 0.517019, acc.: 78.91%] [G loss: 1.401767]\n",
      "epoch:21 step:20327 [D loss: 0.895012, acc.: 57.03%] [G loss: 1.351478]\n",
      "epoch:21 step:20328 [D loss: 0.606615, acc.: 64.84%] [G loss: 1.522527]\n",
      "epoch:21 step:20329 [D loss: 0.930194, acc.: 37.50%] [G loss: 1.590413]\n",
      "epoch:21 step:20330 [D loss: 0.767254, acc.: 47.66%] [G loss: 1.322566]\n",
      "epoch:21 step:20331 [D loss: 0.656602, acc.: 59.38%] [G loss: 1.478111]\n",
      "epoch:21 step:20332 [D loss: 0.771840, acc.: 55.47%] [G loss: 1.389391]\n",
      "epoch:21 step:20333 [D loss: 0.704302, acc.: 53.12%] [G loss: 0.759191]\n",
      "epoch:21 step:20334 [D loss: 0.675249, acc.: 63.28%] [G loss: 1.023261]\n",
      "epoch:21 step:20335 [D loss: 0.507054, acc.: 76.56%] [G loss: 0.996586]\n",
      "epoch:21 step:20336 [D loss: 0.703975, acc.: 56.25%] [G loss: 1.138470]\n",
      "epoch:21 step:20337 [D loss: 0.572571, acc.: 68.75%] [G loss: 1.231014]\n",
      "epoch:21 step:20338 [D loss: 0.700495, acc.: 57.81%] [G loss: 1.053761]\n",
      "epoch:21 step:20339 [D loss: 0.570052, acc.: 75.00%] [G loss: 0.751821]\n",
      "epoch:21 step:20340 [D loss: 0.195770, acc.: 97.66%] [G loss: 1.037148]\n",
      "epoch:21 step:20341 [D loss: 0.285660, acc.: 82.03%] [G loss: 1.266935]\n",
      "epoch:21 step:20342 [D loss: 0.155304, acc.: 98.44%] [G loss: 1.507857]\n",
      "epoch:21 step:20343 [D loss: 0.437885, acc.: 84.38%] [G loss: 1.630582]\n",
      "epoch:21 step:20344 [D loss: 0.383181, acc.: 85.94%] [G loss: 1.597832]\n",
      "epoch:21 step:20345 [D loss: 0.635350, acc.: 59.38%] [G loss: 1.493905]\n",
      "epoch:21 step:20346 [D loss: 0.466274, acc.: 83.59%] [G loss: 1.475737]\n",
      "epoch:21 step:20347 [D loss: 0.482111, acc.: 83.59%] [G loss: 1.423348]\n",
      "epoch:21 step:20348 [D loss: 0.257872, acc.: 98.44%] [G loss: 1.600672]\n",
      "epoch:21 step:20349 [D loss: 0.514340, acc.: 79.69%] [G loss: 1.442669]\n",
      "epoch:21 step:20350 [D loss: 0.471787, acc.: 84.38%] [G loss: 1.204607]\n",
      "epoch:21 step:20351 [D loss: 0.261777, acc.: 94.53%] [G loss: 1.488815]\n",
      "epoch:21 step:20352 [D loss: 0.538395, acc.: 71.09%] [G loss: 1.213096]\n",
      "epoch:21 step:20353 [D loss: 0.425066, acc.: 83.59%] [G loss: 1.224298]\n",
      "epoch:21 step:20354 [D loss: 0.583416, acc.: 67.19%] [G loss: 0.983188]\n",
      "epoch:21 step:20355 [D loss: 0.838926, acc.: 46.09%] [G loss: 0.608142]\n",
      "epoch:21 step:20356 [D loss: 0.547927, acc.: 71.88%] [G loss: 0.541342]\n",
      "epoch:21 step:20357 [D loss: 0.851021, acc.: 50.78%] [G loss: 1.188981]\n",
      "epoch:21 step:20358 [D loss: 1.151798, acc.: 25.78%] [G loss: 1.022846]\n",
      "epoch:21 step:20359 [D loss: 0.440270, acc.: 78.91%] [G loss: 1.240663]\n",
      "epoch:21 step:20360 [D loss: 0.630948, acc.: 65.62%] [G loss: 1.458638]\n",
      "epoch:21 step:20361 [D loss: 0.332693, acc.: 87.50%] [G loss: 1.161451]\n",
      "epoch:21 step:20362 [D loss: 0.485327, acc.: 75.78%] [G loss: 1.503209]\n",
      "epoch:21 step:20363 [D loss: 0.409571, acc.: 85.16%] [G loss: 1.314962]\n",
      "epoch:21 step:20364 [D loss: 0.868576, acc.: 54.69%] [G loss: 1.048160]\n",
      "epoch:21 step:20365 [D loss: 0.841457, acc.: 42.97%] [G loss: 1.290493]\n",
      "epoch:21 step:20366 [D loss: 0.808758, acc.: 54.69%] [G loss: 1.142037]\n",
      "epoch:21 step:20367 [D loss: 0.755518, acc.: 55.47%] [G loss: 1.175622]\n",
      "epoch:21 step:20368 [D loss: 0.715854, acc.: 54.69%] [G loss: 1.047167]\n",
      "epoch:21 step:20369 [D loss: 0.636955, acc.: 61.72%] [G loss: 1.125781]\n",
      "epoch:21 step:20370 [D loss: 0.733114, acc.: 51.56%] [G loss: 1.136621]\n",
      "epoch:21 step:20371 [D loss: 0.579976, acc.: 68.75%] [G loss: 1.315813]\n",
      "epoch:21 step:20372 [D loss: 0.765528, acc.: 54.69%] [G loss: 1.255488]\n",
      "epoch:21 step:20373 [D loss: 0.305407, acc.: 89.06%] [G loss: 1.371451]\n",
      "epoch:21 step:20374 [D loss: 0.223048, acc.: 92.97%] [G loss: 1.564363]\n",
      "epoch:21 step:20375 [D loss: 0.265077, acc.: 96.09%] [G loss: 1.553258]\n",
      "epoch:21 step:20376 [D loss: 0.563548, acc.: 74.22%] [G loss: 1.367438]\n",
      "epoch:21 step:20377 [D loss: 0.197776, acc.: 96.88%] [G loss: 1.644808]\n",
      "epoch:21 step:20378 [D loss: 0.157691, acc.: 97.66%] [G loss: 1.776609]\n",
      "epoch:21 step:20379 [D loss: 0.318540, acc.: 93.75%] [G loss: 0.796646]\n",
      "epoch:21 step:20380 [D loss: 0.880708, acc.: 48.44%] [G loss: 1.395754]\n",
      "epoch:21 step:20381 [D loss: 0.612134, acc.: 60.94%] [G loss: 1.172493]\n",
      "epoch:21 step:20382 [D loss: 0.911960, acc.: 38.28%] [G loss: 1.202407]\n",
      "epoch:21 step:20383 [D loss: 0.904754, acc.: 53.91%] [G loss: 1.836130]\n",
      "epoch:21 step:20384 [D loss: 0.128418, acc.: 100.00%] [G loss: 2.112570]\n",
      "epoch:21 step:20385 [D loss: 0.486030, acc.: 75.78%] [G loss: 1.724269]\n",
      "epoch:21 step:20386 [D loss: 0.248329, acc.: 93.75%] [G loss: 1.500522]\n",
      "epoch:21 step:20387 [D loss: 0.450814, acc.: 78.91%] [G loss: 1.866203]\n",
      "epoch:21 step:20388 [D loss: 0.372707, acc.: 87.50%] [G loss: 1.712464]\n",
      "epoch:21 step:20389 [D loss: 0.716069, acc.: 52.34%] [G loss: 1.544079]\n",
      "epoch:21 step:20390 [D loss: 0.216667, acc.: 95.31%] [G loss: 1.666592]\n",
      "epoch:21 step:20391 [D loss: 0.243458, acc.: 92.19%] [G loss: 1.301419]\n",
      "epoch:21 step:20392 [D loss: 0.842949, acc.: 49.22%] [G loss: 1.523182]\n",
      "epoch:21 step:20393 [D loss: 1.002398, acc.: 35.16%] [G loss: 1.230132]\n",
      "epoch:21 step:20394 [D loss: 0.747851, acc.: 56.25%] [G loss: 0.981593]\n",
      "epoch:21 step:20395 [D loss: 0.441713, acc.: 82.81%] [G loss: 1.671407]\n",
      "epoch:21 step:20396 [D loss: 0.427699, acc.: 80.47%] [G loss: 1.420617]\n",
      "epoch:21 step:20397 [D loss: 0.353651, acc.: 87.50%] [G loss: 1.706995]\n",
      "epoch:21 step:20398 [D loss: 0.432503, acc.: 78.91%] [G loss: 1.429764]\n",
      "epoch:21 step:20399 [D loss: 0.963984, acc.: 37.50%] [G loss: 1.415026]\n",
      "epoch:21 step:20400 [D loss: 0.698346, acc.: 57.03%] [G loss: 1.448698]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##############\n",
      "[4.06432191 2.80205176 6.66082748 5.80952436 4.97042544 6.08503879\n",
      " 5.33974101 5.69125781 6.16605967 5.20151654]\n",
      "##########\n",
      "epoch:21 step:20401 [D loss: 0.266025, acc.: 94.53%] [G loss: 2.230364]\n",
      "epoch:21 step:20402 [D loss: 0.564827, acc.: 73.44%] [G loss: 2.023154]\n",
      "epoch:21 step:20403 [D loss: 0.195912, acc.: 96.09%] [G loss: 2.641185]\n",
      "epoch:21 step:20404 [D loss: 0.898346, acc.: 50.78%] [G loss: 1.547907]\n",
      "epoch:21 step:20405 [D loss: 0.763678, acc.: 67.97%] [G loss: 1.182534]\n",
      "epoch:21 step:20406 [D loss: 0.529559, acc.: 71.88%] [G loss: 1.183892]\n",
      "epoch:21 step:20407 [D loss: 0.507586, acc.: 71.88%] [G loss: 0.702297]\n",
      "epoch:21 step:20408 [D loss: 0.780916, acc.: 62.50%] [G loss: 1.440967]\n",
      "epoch:21 step:20409 [D loss: 0.680910, acc.: 64.06%] [G loss: 1.530873]\n",
      "epoch:21 step:20410 [D loss: 0.376569, acc.: 87.50%] [G loss: 1.269993]\n",
      "epoch:21 step:20411 [D loss: 0.758584, acc.: 48.44%] [G loss: 1.398539]\n",
      "epoch:21 step:20412 [D loss: 0.406362, acc.: 88.28%] [G loss: 1.262063]\n",
      "epoch:21 step:20413 [D loss: 0.400322, acc.: 89.06%] [G loss: 1.236856]\n",
      "epoch:21 step:20414 [D loss: 0.660404, acc.: 60.94%] [G loss: 1.539227]\n",
      "epoch:21 step:20415 [D loss: 0.704458, acc.: 56.25%] [G loss: 1.438645]\n",
      "epoch:21 step:20416 [D loss: 0.496409, acc.: 76.56%] [G loss: 1.092865]\n",
      "epoch:21 step:20417 [D loss: 0.576224, acc.: 72.66%] [G loss: 1.339007]\n",
      "epoch:21 step:20418 [D loss: 0.245397, acc.: 93.75%] [G loss: 1.226192]\n",
      "epoch:21 step:20419 [D loss: 0.261127, acc.: 88.28%] [G loss: 1.132971]\n",
      "epoch:21 step:20420 [D loss: 0.157699, acc.: 100.00%] [G loss: 1.511050]\n",
      "epoch:21 step:20421 [D loss: 1.123858, acc.: 48.44%] [G loss: 1.835965]\n",
      "epoch:21 step:20422 [D loss: 0.682250, acc.: 55.47%] [G loss: 1.755194]\n",
      "epoch:21 step:20423 [D loss: 0.319369, acc.: 90.62%] [G loss: 1.862776]\n",
      "epoch:21 step:20424 [D loss: 0.703519, acc.: 57.81%] [G loss: 1.463344]\n",
      "epoch:21 step:20425 [D loss: 0.576197, acc.: 71.88%] [G loss: 1.596443]\n",
      "epoch:21 step:20426 [D loss: 0.218457, acc.: 96.88%] [G loss: 1.642759]\n",
      "epoch:21 step:20427 [D loss: 0.190604, acc.: 98.44%] [G loss: 1.824816]\n",
      "epoch:21 step:20428 [D loss: 0.781617, acc.: 51.56%] [G loss: 1.529548]\n",
      "epoch:21 step:20429 [D loss: 0.842000, acc.: 50.00%] [G loss: 1.611496]\n",
      "epoch:21 step:20430 [D loss: 0.814043, acc.: 48.44%] [G loss: 1.059613]\n",
      "epoch:21 step:20431 [D loss: 0.537588, acc.: 67.19%] [G loss: 1.034228]\n",
      "epoch:21 step:20432 [D loss: 0.563051, acc.: 68.75%] [G loss: 0.944712]\n",
      "epoch:21 step:20433 [D loss: 0.381581, acc.: 85.16%] [G loss: 1.135064]\n",
      "epoch:21 step:20434 [D loss: 0.737298, acc.: 54.69%] [G loss: 0.866942]\n",
      "epoch:21 step:20435 [D loss: 0.686418, acc.: 62.50%] [G loss: 1.344845]\n",
      "epoch:21 step:20436 [D loss: 0.448602, acc.: 85.94%] [G loss: 1.142846]\n",
      "epoch:21 step:20437 [D loss: 0.407831, acc.: 89.84%] [G loss: 1.027616]\n",
      "epoch:21 step:20438 [D loss: 0.707166, acc.: 57.81%] [G loss: 0.880243]\n",
      "epoch:21 step:20439 [D loss: 0.516989, acc.: 75.78%] [G loss: 1.125407]\n",
      "epoch:21 step:20440 [D loss: 0.642835, acc.: 63.28%] [G loss: 1.262729]\n",
      "epoch:21 step:20441 [D loss: 0.352758, acc.: 84.38%] [G loss: 1.184235]\n",
      "epoch:21 step:20442 [D loss: 0.463875, acc.: 82.81%] [G loss: 1.215596]\n",
      "epoch:21 step:20443 [D loss: 0.701613, acc.: 60.16%] [G loss: 1.588686]\n",
      "epoch:21 step:20444 [D loss: 0.401299, acc.: 82.81%] [G loss: 0.882482]\n",
      "epoch:21 step:20445 [D loss: 0.286558, acc.: 85.94%] [G loss: 1.527673]\n",
      "epoch:21 step:20446 [D loss: 0.167107, acc.: 99.22%] [G loss: 1.879708]\n",
      "epoch:21 step:20447 [D loss: 0.711818, acc.: 55.47%] [G loss: 1.679670]\n",
      "epoch:21 step:20448 [D loss: 0.955894, acc.: 41.41%] [G loss: 1.125045]\n",
      "epoch:21 step:20449 [D loss: 0.826804, acc.: 50.78%] [G loss: 1.141287]\n",
      "epoch:21 step:20450 [D loss: 0.665036, acc.: 59.38%] [G loss: 1.154682]\n",
      "epoch:21 step:20451 [D loss: 0.585670, acc.: 60.94%] [G loss: 0.363766]\n",
      "epoch:21 step:20452 [D loss: 0.304799, acc.: 88.28%] [G loss: 1.834003]\n",
      "epoch:21 step:20453 [D loss: 0.647438, acc.: 66.41%] [G loss: 1.648566]\n",
      "epoch:21 step:20454 [D loss: 0.638575, acc.: 70.31%] [G loss: 1.434296]\n",
      "epoch:21 step:20455 [D loss: 0.801561, acc.: 48.44%] [G loss: 0.434957]\n",
      "epoch:21 step:20456 [D loss: 0.774853, acc.: 53.91%] [G loss: 1.183762]\n",
      "epoch:21 step:20457 [D loss: 0.383993, acc.: 82.03%] [G loss: 1.626551]\n",
      "epoch:21 step:20458 [D loss: 0.229323, acc.: 96.88%] [G loss: 1.462920]\n",
      "epoch:21 step:20459 [D loss: 0.318756, acc.: 87.50%] [G loss: 1.496868]\n",
      "epoch:21 step:20460 [D loss: 0.583699, acc.: 65.62%] [G loss: 1.251862]\n",
      "epoch:21 step:20461 [D loss: 0.658803, acc.: 60.16%] [G loss: 1.485578]\n",
      "epoch:21 step:20462 [D loss: 0.697730, acc.: 57.03%] [G loss: 0.647095]\n",
      "epoch:21 step:20463 [D loss: 0.300065, acc.: 92.19%] [G loss: 1.171600]\n",
      "epoch:21 step:20464 [D loss: 0.775279, acc.: 53.12%] [G loss: 1.594236]\n",
      "epoch:21 step:20465 [D loss: 0.479802, acc.: 82.03%] [G loss: 0.936395]\n",
      "epoch:21 step:20466 [D loss: 0.777323, acc.: 50.78%] [G loss: 1.484467]\n",
      "epoch:21 step:20467 [D loss: 0.562045, acc.: 72.66%] [G loss: 1.301908]\n",
      "epoch:21 step:20468 [D loss: 0.219340, acc.: 89.84%] [G loss: 1.448566]\n",
      "epoch:21 step:20469 [D loss: 0.238127, acc.: 94.53%] [G loss: 1.585780]\n",
      "epoch:21 step:20470 [D loss: 0.193989, acc.: 97.66%] [G loss: 1.228753]\n",
      "epoch:21 step:20471 [D loss: 0.295205, acc.: 89.06%] [G loss: 1.704726]\n",
      "epoch:21 step:20472 [D loss: 0.229202, acc.: 96.88%] [G loss: 1.428808]\n",
      "epoch:21 step:20473 [D loss: 0.153964, acc.: 99.22%] [G loss: 1.986043]\n",
      "epoch:21 step:20474 [D loss: 0.675189, acc.: 58.59%] [G loss: 1.690600]\n",
      "epoch:21 step:20475 [D loss: 0.574070, acc.: 69.53%] [G loss: 0.729119]\n",
      "epoch:21 step:20476 [D loss: 0.759125, acc.: 52.34%] [G loss: 0.334255]\n",
      "epoch:21 step:20477 [D loss: 0.647224, acc.: 65.62%] [G loss: 1.389482]\n",
      "epoch:21 step:20478 [D loss: 0.398526, acc.: 87.50%] [G loss: 1.287622]\n",
      "epoch:21 step:20479 [D loss: 0.865221, acc.: 50.00%] [G loss: 1.213283]\n",
      "epoch:21 step:20480 [D loss: 0.836176, acc.: 52.34%] [G loss: 1.424823]\n",
      "epoch:21 step:20481 [D loss: 0.159735, acc.: 96.88%] [G loss: 1.590869]\n",
      "epoch:21 step:20482 [D loss: 0.195417, acc.: 94.53%] [G loss: 1.709515]\n",
      "epoch:21 step:20483 [D loss: 0.156694, acc.: 97.66%] [G loss: 1.676172]\n",
      "epoch:21 step:20484 [D loss: 0.862666, acc.: 51.56%] [G loss: 1.684351]\n",
      "epoch:21 step:20485 [D loss: 0.528610, acc.: 72.66%] [G loss: 0.876338]\n",
      "epoch:21 step:20486 [D loss: 0.536142, acc.: 71.09%] [G loss: 1.413273]\n",
      "epoch:21 step:20487 [D loss: 0.589236, acc.: 66.41%] [G loss: 0.652564]\n",
      "epoch:21 step:20488 [D loss: 0.613340, acc.: 68.75%] [G loss: 1.051535]\n",
      "epoch:21 step:20489 [D loss: 0.463645, acc.: 79.69%] [G loss: 0.775016]\n",
      "epoch:21 step:20490 [D loss: 0.573855, acc.: 74.22%] [G loss: 1.080067]\n",
      "epoch:21 step:20491 [D loss: 0.738667, acc.: 50.78%] [G loss: 1.093339]\n",
      "epoch:21 step:20492 [D loss: 0.404827, acc.: 83.59%] [G loss: 1.095170]\n",
      "epoch:21 step:20493 [D loss: 0.574496, acc.: 71.09%] [G loss: 1.042011]\n",
      "epoch:21 step:20494 [D loss: 0.568310, acc.: 75.78%] [G loss: 0.618524]\n",
      "epoch:21 step:20495 [D loss: 0.751831, acc.: 51.56%] [G loss: 0.796570]\n",
      "epoch:21 step:20496 [D loss: 0.452811, acc.: 89.06%] [G loss: 0.981073]\n",
      "epoch:21 step:20497 [D loss: 0.798110, acc.: 39.06%] [G loss: 0.825735]\n",
      "epoch:21 step:20498 [D loss: 0.992417, acc.: 55.47%] [G loss: 1.092154]\n",
      "epoch:21 step:20499 [D loss: 0.758021, acc.: 50.78%] [G loss: 1.274946]\n",
      "epoch:21 step:20500 [D loss: 0.652683, acc.: 58.59%] [G loss: 1.388989]\n",
      "epoch:21 step:20501 [D loss: 0.784829, acc.: 47.66%] [G loss: 1.318820]\n",
      "epoch:21 step:20502 [D loss: 0.557768, acc.: 73.44%] [G loss: 1.230638]\n",
      "epoch:21 step:20503 [D loss: 0.581202, acc.: 67.19%] [G loss: 1.290008]\n",
      "epoch:21 step:20504 [D loss: 0.569692, acc.: 72.66%] [G loss: 1.201348]\n",
      "epoch:21 step:20505 [D loss: 0.629970, acc.: 64.84%] [G loss: 1.111894]\n",
      "epoch:21 step:20506 [D loss: 0.671916, acc.: 56.25%] [G loss: 1.143172]\n",
      "epoch:21 step:20507 [D loss: 0.572214, acc.: 68.75%] [G loss: 1.010523]\n",
      "epoch:21 step:20508 [D loss: 0.532234, acc.: 78.12%] [G loss: 1.098112]\n",
      "epoch:21 step:20509 [D loss: 0.405755, acc.: 87.50%] [G loss: 1.073878]\n",
      "epoch:21 step:20510 [D loss: 0.625174, acc.: 64.06%] [G loss: 1.187040]\n",
      "epoch:21 step:20511 [D loss: 0.310226, acc.: 92.19%] [G loss: 1.202938]\n",
      "epoch:21 step:20512 [D loss: 0.465033, acc.: 79.69%] [G loss: 1.164638]\n",
      "epoch:21 step:20513 [D loss: 0.669483, acc.: 60.16%] [G loss: 0.943260]\n",
      "epoch:21 step:20514 [D loss: 0.727701, acc.: 49.22%] [G loss: 1.180262]\n",
      "epoch:21 step:20515 [D loss: 0.758831, acc.: 54.69%] [G loss: 1.079751]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:21 step:20516 [D loss: 0.477311, acc.: 75.00%] [G loss: 1.067631]\n",
      "epoch:21 step:20517 [D loss: 0.572936, acc.: 70.31%] [G loss: 1.275430]\n",
      "epoch:21 step:20518 [D loss: 0.258887, acc.: 93.75%] [G loss: 1.485776]\n",
      "epoch:21 step:20519 [D loss: 0.295543, acc.: 94.53%] [G loss: 1.470029]\n",
      "epoch:21 step:20520 [D loss: 0.866991, acc.: 52.34%] [G loss: 1.168734]\n",
      "epoch:21 step:20521 [D loss: 0.809481, acc.: 50.78%] [G loss: 1.307118]\n",
      "epoch:21 step:20522 [D loss: 0.492287, acc.: 80.47%] [G loss: 1.119073]\n",
      "epoch:21 step:20523 [D loss: 0.796077, acc.: 46.88%] [G loss: 1.098700]\n",
      "epoch:21 step:20524 [D loss: 0.370428, acc.: 82.03%] [G loss: 1.147301]\n",
      "epoch:21 step:20525 [D loss: 0.266752, acc.: 94.53%] [G loss: 1.357585]\n",
      "epoch:21 step:20526 [D loss: 0.396208, acc.: 85.94%] [G loss: 1.288155]\n",
      "epoch:21 step:20527 [D loss: 0.262998, acc.: 87.50%] [G loss: 1.535820]\n",
      "epoch:21 step:20528 [D loss: 0.170828, acc.: 99.22%] [G loss: 1.265610]\n",
      "epoch:21 step:20529 [D loss: 0.165629, acc.: 98.44%] [G loss: 1.628561]\n",
      "epoch:21 step:20530 [D loss: 0.220254, acc.: 98.44%] [G loss: 1.780355]\n",
      "epoch:21 step:20531 [D loss: 0.119492, acc.: 100.00%] [G loss: 1.615145]\n",
      "epoch:21 step:20532 [D loss: 0.331721, acc.: 91.41%] [G loss: 1.690160]\n",
      "epoch:21 step:20533 [D loss: 0.556325, acc.: 70.31%] [G loss: 1.741789]\n",
      "epoch:21 step:20534 [D loss: 0.228615, acc.: 95.31%] [G loss: 1.116346]\n",
      "epoch:21 step:20535 [D loss: 0.459984, acc.: 79.69%] [G loss: 1.524043]\n",
      "epoch:21 step:20536 [D loss: 1.462923, acc.: 21.09%] [G loss: 1.772820]\n",
      "epoch:21 step:20537 [D loss: 0.532472, acc.: 71.88%] [G loss: 1.821281]\n",
      "epoch:21 step:20538 [D loss: 0.595756, acc.: 67.19%] [G loss: 1.590061]\n",
      "epoch:21 step:20539 [D loss: 0.945586, acc.: 38.28%] [G loss: 1.098635]\n",
      "epoch:21 step:20540 [D loss: 0.770511, acc.: 60.16%] [G loss: 1.332704]\n",
      "epoch:21 step:20541 [D loss: 0.846582, acc.: 40.62%] [G loss: 0.945320]\n",
      "epoch:21 step:20542 [D loss: 0.582747, acc.: 64.84%] [G loss: 1.167620]\n",
      "epoch:21 step:20543 [D loss: 0.630309, acc.: 67.97%] [G loss: 0.986825]\n",
      "epoch:21 step:20544 [D loss: 0.599116, acc.: 66.41%] [G loss: 1.261015]\n",
      "epoch:21 step:20545 [D loss: 0.715014, acc.: 54.69%] [G loss: 1.239994]\n",
      "epoch:21 step:20546 [D loss: 0.557176, acc.: 71.09%] [G loss: 0.766106]\n",
      "epoch:21 step:20547 [D loss: 0.653820, acc.: 64.06%] [G loss: 1.228540]\n",
      "epoch:21 step:20548 [D loss: 0.696925, acc.: 57.03%] [G loss: 0.881221]\n",
      "epoch:21 step:20549 [D loss: 0.577110, acc.: 69.53%] [G loss: 1.107608]\n",
      "epoch:21 step:20550 [D loss: 0.570153, acc.: 69.53%] [G loss: 0.896862]\n",
      "epoch:21 step:20551 [D loss: 0.705472, acc.: 58.59%] [G loss: 1.347708]\n",
      "epoch:21 step:20552 [D loss: 0.498408, acc.: 81.25%] [G loss: 1.107920]\n",
      "epoch:21 step:20553 [D loss: 0.789412, acc.: 48.44%] [G loss: 1.259054]\n",
      "epoch:21 step:20554 [D loss: 0.579560, acc.: 72.66%] [G loss: 0.783487]\n",
      "epoch:21 step:20555 [D loss: 0.290165, acc.: 88.28%] [G loss: 0.961021]\n",
      "epoch:21 step:20556 [D loss: 0.751123, acc.: 52.34%] [G loss: 0.580098]\n",
      "epoch:21 step:20557 [D loss: 0.697334, acc.: 50.78%] [G loss: 1.074228]\n",
      "epoch:21 step:20558 [D loss: 0.864065, acc.: 37.50%] [G loss: 0.910903]\n",
      "epoch:21 step:20559 [D loss: 0.253409, acc.: 92.19%] [G loss: 1.127655]\n",
      "epoch:21 step:20560 [D loss: 0.361381, acc.: 77.34%] [G loss: 1.377303]\n",
      "epoch:21 step:20561 [D loss: 0.241855, acc.: 91.41%] [G loss: 1.466143]\n",
      "epoch:21 step:20562 [D loss: 0.154998, acc.: 99.22%] [G loss: 1.530531]\n",
      "epoch:21 step:20563 [D loss: 0.161891, acc.: 96.88%] [G loss: 1.667801]\n",
      "epoch:21 step:20564 [D loss: 0.145439, acc.: 98.44%] [G loss: 1.714287]\n",
      "epoch:21 step:20565 [D loss: 0.699622, acc.: 58.59%] [G loss: 1.687606]\n",
      "epoch:21 step:20566 [D loss: 0.193458, acc.: 97.66%] [G loss: 1.421419]\n",
      "epoch:21 step:20567 [D loss: 0.280259, acc.: 92.97%] [G loss: 1.900883]\n",
      "epoch:21 step:20568 [D loss: 0.888874, acc.: 50.00%] [G loss: 1.251714]\n",
      "epoch:21 step:20569 [D loss: 1.084249, acc.: 52.34%] [G loss: 1.208279]\n",
      "epoch:21 step:20570 [D loss: 0.793459, acc.: 50.00%] [G loss: 1.202760]\n",
      "epoch:21 step:20571 [D loss: 0.621464, acc.: 68.75%] [G loss: 0.784036]\n",
      "epoch:21 step:20572 [D loss: 0.851430, acc.: 35.16%] [G loss: 1.080043]\n",
      "epoch:21 step:20573 [D loss: 0.641677, acc.: 65.62%] [G loss: 0.881025]\n",
      "epoch:21 step:20574 [D loss: 0.592028, acc.: 64.06%] [G loss: 1.051587]\n",
      "epoch:21 step:20575 [D loss: 0.408119, acc.: 90.62%] [G loss: 0.965111]\n",
      "epoch:21 step:20576 [D loss: 0.317237, acc.: 86.72%] [G loss: 1.129262]\n",
      "epoch:21 step:20577 [D loss: 0.345224, acc.: 89.84%] [G loss: 1.026523]\n",
      "epoch:21 step:20578 [D loss: 0.500129, acc.: 83.59%] [G loss: 0.987273]\n",
      "epoch:21 step:20579 [D loss: 0.574544, acc.: 71.88%] [G loss: 1.115257]\n",
      "epoch:21 step:20580 [D loss: 0.514016, acc.: 79.69%] [G loss: 1.025960]\n",
      "epoch:21 step:20581 [D loss: 0.196615, acc.: 96.09%] [G loss: 1.138844]\n",
      "epoch:21 step:20582 [D loss: 0.312863, acc.: 85.94%] [G loss: 1.389144]\n",
      "epoch:21 step:20583 [D loss: 0.256871, acc.: 99.22%] [G loss: 1.511521]\n",
      "epoch:21 step:20584 [D loss: 0.688195, acc.: 57.03%] [G loss: 1.237302]\n",
      "epoch:21 step:20585 [D loss: 0.846110, acc.: 37.50%] [G loss: 1.145590]\n",
      "epoch:21 step:20586 [D loss: 0.546185, acc.: 69.53%] [G loss: 1.080755]\n",
      "epoch:21 step:20587 [D loss: 0.386144, acc.: 89.84%] [G loss: 1.275030]\n",
      "epoch:21 step:20588 [D loss: 0.379945, acc.: 86.72%] [G loss: 1.386757]\n",
      "epoch:21 step:20589 [D loss: 0.160714, acc.: 97.66%] [G loss: 1.692687]\n",
      "epoch:21 step:20590 [D loss: 0.766801, acc.: 50.00%] [G loss: 1.048359]\n",
      "epoch:21 step:20591 [D loss: 0.629050, acc.: 60.16%] [G loss: 1.057837]\n",
      "epoch:21 step:20592 [D loss: 0.696992, acc.: 57.81%] [G loss: 1.019062]\n",
      "epoch:21 step:20593 [D loss: 0.554258, acc.: 73.44%] [G loss: 1.158932]\n",
      "epoch:21 step:20594 [D loss: 0.423135, acc.: 87.50%] [G loss: 1.537913]\n",
      "epoch:21 step:20595 [D loss: 0.685818, acc.: 58.59%] [G loss: 1.145141]\n",
      "epoch:21 step:20596 [D loss: 0.326123, acc.: 88.28%] [G loss: 1.115180]\n",
      "epoch:21 step:20597 [D loss: 0.242964, acc.: 90.62%] [G loss: 2.044027]\n",
      "epoch:21 step:20598 [D loss: 0.235220, acc.: 97.66%] [G loss: 1.302212]\n",
      "epoch:21 step:20599 [D loss: 0.581376, acc.: 75.00%] [G loss: 1.734174]\n",
      "epoch:21 step:20600 [D loss: 0.621489, acc.: 64.06%] [G loss: 1.511320]\n",
      "##############\n",
      "[4.209635   2.68424002 6.68916508 6.00690645 4.87796492 6.32177302\n",
      " 5.6055273  5.68240694 6.09874606 5.16610541]\n",
      "##########\n",
      "epoch:21 step:20601 [D loss: 0.355603, acc.: 90.62%] [G loss: 1.669795]\n",
      "epoch:21 step:20602 [D loss: 0.403668, acc.: 86.72%] [G loss: 1.167962]\n",
      "epoch:21 step:20603 [D loss: 0.315048, acc.: 92.19%] [G loss: 1.476781]\n",
      "epoch:21 step:20604 [D loss: 0.337499, acc.: 84.38%] [G loss: 1.661823]\n",
      "epoch:21 step:20605 [D loss: 0.841069, acc.: 53.12%] [G loss: 1.300394]\n",
      "epoch:21 step:20606 [D loss: 0.241818, acc.: 89.84%] [G loss: 1.592840]\n",
      "epoch:21 step:20607 [D loss: 0.499080, acc.: 76.56%] [G loss: 1.497164]\n",
      "epoch:21 step:20608 [D loss: 0.562348, acc.: 67.19%] [G loss: 1.846941]\n",
      "epoch:21 step:20609 [D loss: 0.518237, acc.: 71.09%] [G loss: 1.069284]\n",
      "epoch:21 step:20610 [D loss: 0.397051, acc.: 85.16%] [G loss: 1.746294]\n",
      "epoch:21 step:20611 [D loss: 0.246476, acc.: 93.75%] [G loss: 1.449420]\n",
      "epoch:21 step:20612 [D loss: 0.373535, acc.: 87.50%] [G loss: 1.467314]\n",
      "epoch:21 step:20613 [D loss: 0.152136, acc.: 98.44%] [G loss: 1.497606]\n",
      "epoch:21 step:20614 [D loss: 0.187811, acc.: 93.75%] [G loss: 1.858459]\n",
      "epoch:22 step:20615 [D loss: 0.501644, acc.: 75.78%] [G loss: 1.721698]\n",
      "epoch:22 step:20616 [D loss: 0.727575, acc.: 57.81%] [G loss: 1.570346]\n",
      "epoch:22 step:20617 [D loss: 0.533093, acc.: 70.31%] [G loss: 1.108506]\n",
      "epoch:22 step:20618 [D loss: 0.840919, acc.: 37.50%] [G loss: 1.318207]\n",
      "epoch:22 step:20619 [D loss: 0.680045, acc.: 53.12%] [G loss: 0.988766]\n",
      "epoch:22 step:20620 [D loss: 0.391202, acc.: 86.72%] [G loss: 0.663215]\n",
      "epoch:22 step:20621 [D loss: 0.891591, acc.: 51.56%] [G loss: 1.288441]\n",
      "epoch:22 step:20622 [D loss: 0.523119, acc.: 67.97%] [G loss: 1.661795]\n",
      "epoch:22 step:20623 [D loss: 0.538450, acc.: 71.88%] [G loss: 1.417690]\n",
      "epoch:22 step:20624 [D loss: 0.174453, acc.: 97.66%] [G loss: 2.000445]\n",
      "epoch:22 step:20625 [D loss: 0.743564, acc.: 58.59%] [G loss: 1.777394]\n",
      "epoch:22 step:20626 [D loss: 0.333396, acc.: 92.19%] [G loss: 1.179939]\n",
      "epoch:22 step:20627 [D loss: 0.415086, acc.: 84.38%] [G loss: 1.253381]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:22 step:20628 [D loss: 0.730730, acc.: 55.47%] [G loss: 1.453170]\n",
      "epoch:22 step:20629 [D loss: 0.512015, acc.: 79.69%] [G loss: 2.173220]\n",
      "epoch:22 step:20630 [D loss: 0.955723, acc.: 47.66%] [G loss: 1.129198]\n",
      "epoch:22 step:20631 [D loss: 1.332367, acc.: 17.97%] [G loss: 2.165668]\n",
      "epoch:22 step:20632 [D loss: 1.179798, acc.: 26.56%] [G loss: 1.669745]\n",
      "epoch:22 step:20633 [D loss: 1.085052, acc.: 50.00%] [G loss: 1.359040]\n",
      "epoch:22 step:20634 [D loss: 0.843817, acc.: 52.34%] [G loss: 1.956789]\n",
      "epoch:22 step:20635 [D loss: 1.010092, acc.: 37.50%] [G loss: 1.525397]\n",
      "epoch:22 step:20636 [D loss: 0.759267, acc.: 51.56%] [G loss: 2.093078]\n",
      "epoch:22 step:20637 [D loss: 0.954433, acc.: 35.94%] [G loss: 1.159569]\n",
      "epoch:22 step:20638 [D loss: 0.779528, acc.: 49.22%] [G loss: 1.578283]\n",
      "epoch:22 step:20639 [D loss: 0.602068, acc.: 67.19%] [G loss: 1.355624]\n",
      "epoch:22 step:20640 [D loss: 0.841691, acc.: 36.72%] [G loss: 0.972617]\n",
      "epoch:22 step:20641 [D loss: 0.209898, acc.: 96.88%] [G loss: 1.767963]\n",
      "epoch:22 step:20642 [D loss: 0.483875, acc.: 78.12%] [G loss: 1.567318]\n",
      "epoch:22 step:20643 [D loss: 0.582366, acc.: 67.97%] [G loss: 1.826511]\n",
      "epoch:22 step:20644 [D loss: 0.439368, acc.: 78.91%] [G loss: 2.233802]\n",
      "epoch:22 step:20645 [D loss: 0.234470, acc.: 96.09%] [G loss: 1.744447]\n",
      "epoch:22 step:20646 [D loss: 0.175938, acc.: 98.44%] [G loss: 1.879890]\n",
      "epoch:22 step:20647 [D loss: 0.104975, acc.: 100.00%] [G loss: 2.260512]\n",
      "epoch:22 step:20648 [D loss: 0.140802, acc.: 98.44%] [G loss: 2.582141]\n",
      "epoch:22 step:20649 [D loss: 0.088231, acc.: 99.22%] [G loss: 2.193596]\n",
      "epoch:22 step:20650 [D loss: 0.063195, acc.: 99.22%] [G loss: 2.380192]\n",
      "epoch:22 step:20651 [D loss: 0.906693, acc.: 52.34%] [G loss: 1.595213]\n",
      "epoch:22 step:20652 [D loss: 0.898247, acc.: 46.09%] [G loss: 1.163417]\n",
      "epoch:22 step:20653 [D loss: 0.992662, acc.: 41.41%] [G loss: 1.222494]\n",
      "epoch:22 step:20654 [D loss: 0.770961, acc.: 48.44%] [G loss: 1.380581]\n",
      "epoch:22 step:20655 [D loss: 0.431246, acc.: 86.72%] [G loss: 1.307904]\n",
      "epoch:22 step:20656 [D loss: 0.365414, acc.: 88.28%] [G loss: 1.614448]\n",
      "epoch:22 step:20657 [D loss: 0.283575, acc.: 90.62%] [G loss: 1.532908]\n",
      "epoch:22 step:20658 [D loss: 0.300258, acc.: 92.19%] [G loss: 1.368751]\n",
      "epoch:22 step:20659 [D loss: 0.400387, acc.: 88.28%] [G loss: 1.760313]\n",
      "epoch:22 step:20660 [D loss: 0.258337, acc.: 96.88%] [G loss: 1.541102]\n",
      "epoch:22 step:20661 [D loss: 0.525403, acc.: 75.00%] [G loss: 1.455720]\n",
      "epoch:22 step:20662 [D loss: 0.535759, acc.: 74.22%] [G loss: 1.156839]\n",
      "epoch:22 step:20663 [D loss: 0.530087, acc.: 72.66%] [G loss: 0.949193]\n",
      "epoch:22 step:20664 [D loss: 0.485898, acc.: 75.78%] [G loss: 0.773594]\n",
      "epoch:22 step:20665 [D loss: 0.327149, acc.: 87.50%] [G loss: 1.059243]\n",
      "epoch:22 step:20666 [D loss: 0.274299, acc.: 92.19%] [G loss: 1.936623]\n",
      "epoch:22 step:20667 [D loss: 0.546346, acc.: 72.66%] [G loss: 0.928796]\n",
      "epoch:22 step:20668 [D loss: 0.660542, acc.: 54.69%] [G loss: 1.920752]\n",
      "epoch:22 step:20669 [D loss: 0.665658, acc.: 62.50%] [G loss: 1.427657]\n",
      "epoch:22 step:20670 [D loss: 0.742917, acc.: 55.47%] [G loss: 1.469468]\n",
      "epoch:22 step:20671 [D loss: 0.301413, acc.: 86.72%] [G loss: 1.672120]\n",
      "epoch:22 step:20672 [D loss: 0.157024, acc.: 98.44%] [G loss: 1.547035]\n",
      "epoch:22 step:20673 [D loss: 0.402416, acc.: 83.59%] [G loss: 1.186203]\n",
      "epoch:22 step:20674 [D loss: 0.538284, acc.: 71.09%] [G loss: 0.986930]\n",
      "epoch:22 step:20675 [D loss: 1.127760, acc.: 20.31%] [G loss: 1.683433]\n",
      "epoch:22 step:20676 [D loss: 0.867746, acc.: 48.44%] [G loss: 1.173593]\n",
      "epoch:22 step:20677 [D loss: 0.619018, acc.: 68.75%] [G loss: 0.347856]\n",
      "epoch:22 step:20678 [D loss: 0.901088, acc.: 43.75%] [G loss: 1.355973]\n",
      "epoch:22 step:20679 [D loss: 0.944026, acc.: 40.62%] [G loss: 1.120778]\n",
      "epoch:22 step:20680 [D loss: 0.900483, acc.: 46.09%] [G loss: 1.018962]\n",
      "epoch:22 step:20681 [D loss: 0.723962, acc.: 52.34%] [G loss: 1.482803]\n",
      "epoch:22 step:20682 [D loss: 1.135390, acc.: 28.91%] [G loss: 1.662389]\n",
      "epoch:22 step:20683 [D loss: 0.724863, acc.: 56.25%] [G loss: 2.100940]\n",
      "epoch:22 step:20684 [D loss: 0.611479, acc.: 67.97%] [G loss: 1.853275]\n",
      "epoch:22 step:20685 [D loss: 0.526512, acc.: 71.88%] [G loss: 1.612701]\n",
      "epoch:22 step:20686 [D loss: 0.845987, acc.: 43.75%] [G loss: 1.306343]\n",
      "epoch:22 step:20687 [D loss: 0.827159, acc.: 46.09%] [G loss: 1.175051]\n",
      "epoch:22 step:20688 [D loss: 0.608737, acc.: 67.97%] [G loss: 1.178765]\n",
      "epoch:22 step:20689 [D loss: 0.439665, acc.: 83.59%] [G loss: 1.671107]\n",
      "epoch:22 step:20690 [D loss: 0.252375, acc.: 90.62%] [G loss: 1.371012]\n",
      "epoch:22 step:20691 [D loss: 0.486285, acc.: 76.56%] [G loss: 1.747541]\n",
      "epoch:22 step:20692 [D loss: 0.907508, acc.: 51.56%] [G loss: 1.270236]\n",
      "epoch:22 step:20693 [D loss: 0.774022, acc.: 55.47%] [G loss: 1.210188]\n",
      "epoch:22 step:20694 [D loss: 0.623581, acc.: 67.19%] [G loss: 1.105799]\n",
      "epoch:22 step:20695 [D loss: 0.878316, acc.: 43.75%] [G loss: 1.386561]\n",
      "epoch:22 step:20696 [D loss: 0.476666, acc.: 78.12%] [G loss: 1.628717]\n",
      "epoch:22 step:20697 [D loss: 0.337277, acc.: 89.84%] [G loss: 1.759934]\n",
      "epoch:22 step:20698 [D loss: 0.519636, acc.: 67.19%] [G loss: 1.751083]\n",
      "epoch:22 step:20699 [D loss: 0.593099, acc.: 73.44%] [G loss: 1.652175]\n",
      "epoch:22 step:20700 [D loss: 0.616417, acc.: 65.62%] [G loss: 1.374100]\n",
      "epoch:22 step:20701 [D loss: 0.421194, acc.: 88.28%] [G loss: 1.292055]\n",
      "epoch:22 step:20702 [D loss: 0.404732, acc.: 85.94%] [G loss: 1.539383]\n",
      "epoch:22 step:20703 [D loss: 0.368641, acc.: 87.50%] [G loss: 1.159374]\n",
      "epoch:22 step:20704 [D loss: 0.465666, acc.: 84.38%] [G loss: 1.637860]\n",
      "epoch:22 step:20705 [D loss: 0.362799, acc.: 92.19%] [G loss: 1.622589]\n",
      "epoch:22 step:20706 [D loss: 0.371595, acc.: 91.41%] [G loss: 1.557367]\n",
      "epoch:22 step:20707 [D loss: 0.319567, acc.: 90.62%] [G loss: 1.758898]\n",
      "epoch:22 step:20708 [D loss: 0.585165, acc.: 67.19%] [G loss: 2.287557]\n",
      "epoch:22 step:20709 [D loss: 0.776256, acc.: 53.12%] [G loss: 1.212523]\n",
      "epoch:22 step:20710 [D loss: 0.647205, acc.: 63.28%] [G loss: 1.290912]\n",
      "epoch:22 step:20711 [D loss: 0.545042, acc.: 71.88%] [G loss: 0.958565]\n",
      "epoch:22 step:20712 [D loss: 0.871531, acc.: 42.19%] [G loss: 1.077521]\n",
      "epoch:22 step:20713 [D loss: 0.630573, acc.: 63.28%] [G loss: 0.819560]\n",
      "epoch:22 step:20714 [D loss: 0.552810, acc.: 67.19%] [G loss: 0.750546]\n",
      "epoch:22 step:20715 [D loss: 0.547623, acc.: 75.00%] [G loss: 0.684587]\n",
      "epoch:22 step:20716 [D loss: 0.856545, acc.: 42.97%] [G loss: 0.786076]\n",
      "epoch:22 step:20717 [D loss: 0.654843, acc.: 57.81%] [G loss: 1.137294]\n",
      "epoch:22 step:20718 [D loss: 0.599122, acc.: 65.62%] [G loss: 1.119883]\n",
      "epoch:22 step:20719 [D loss: 0.543099, acc.: 72.66%] [G loss: 1.036544]\n",
      "epoch:22 step:20720 [D loss: 0.724466, acc.: 60.16%] [G loss: 1.178173]\n",
      "epoch:22 step:20721 [D loss: 0.454932, acc.: 79.69%] [G loss: 1.060343]\n",
      "epoch:22 step:20722 [D loss: 0.512671, acc.: 78.91%] [G loss: 1.196405]\n",
      "epoch:22 step:20723 [D loss: 0.607888, acc.: 66.41%] [G loss: 0.920860]\n",
      "epoch:22 step:20724 [D loss: 0.581020, acc.: 67.19%] [G loss: 1.283928]\n",
      "epoch:22 step:20725 [D loss: 0.601780, acc.: 65.62%] [G loss: 0.766122]\n",
      "epoch:22 step:20726 [D loss: 0.613977, acc.: 65.62%] [G loss: 1.141029]\n",
      "epoch:22 step:20727 [D loss: 0.545307, acc.: 72.66%] [G loss: 0.681068]\n",
      "epoch:22 step:20728 [D loss: 0.682588, acc.: 56.25%] [G loss: 1.533758]\n",
      "epoch:22 step:20729 [D loss: 0.460417, acc.: 80.47%] [G loss: 1.292565]\n",
      "epoch:22 step:20730 [D loss: 0.629552, acc.: 68.75%] [G loss: 1.045543]\n",
      "epoch:22 step:20731 [D loss: 0.603364, acc.: 71.09%] [G loss: 1.002169]\n",
      "epoch:22 step:20732 [D loss: 0.500744, acc.: 75.78%] [G loss: 0.869374]\n",
      "epoch:22 step:20733 [D loss: 0.339644, acc.: 82.81%] [G loss: 1.550895]\n",
      "epoch:22 step:20734 [D loss: 0.655176, acc.: 64.84%] [G loss: 1.036816]\n",
      "epoch:22 step:20735 [D loss: 0.393531, acc.: 89.06%] [G loss: 0.800852]\n",
      "epoch:22 step:20736 [D loss: 0.475425, acc.: 77.34%] [G loss: 1.223079]\n",
      "epoch:22 step:20737 [D loss: 0.774212, acc.: 50.78%] [G loss: 0.801099]\n",
      "epoch:22 step:20738 [D loss: 0.659624, acc.: 61.72%] [G loss: 1.132286]\n",
      "epoch:22 step:20739 [D loss: 0.702806, acc.: 55.47%] [G loss: 1.142127]\n",
      "epoch:22 step:20740 [D loss: 0.550959, acc.: 73.44%] [G loss: 1.419616]\n",
      "epoch:22 step:20741 [D loss: 0.799413, acc.: 46.09%] [G loss: 1.116680]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:22 step:20742 [D loss: 0.682038, acc.: 58.59%] [G loss: 0.943494]\n",
      "epoch:22 step:20743 [D loss: 0.594196, acc.: 66.41%] [G loss: 1.259476]\n",
      "epoch:22 step:20744 [D loss: 0.397712, acc.: 82.81%] [G loss: 1.394328]\n",
      "epoch:22 step:20745 [D loss: 0.333255, acc.: 92.19%] [G loss: 0.975085]\n",
      "epoch:22 step:20746 [D loss: 0.446512, acc.: 82.81%] [G loss: 1.352010]\n",
      "epoch:22 step:20747 [D loss: 0.685559, acc.: 56.25%] [G loss: 0.881605]\n",
      "epoch:22 step:20748 [D loss: 0.381636, acc.: 86.72%] [G loss: 1.217201]\n",
      "epoch:22 step:20749 [D loss: 0.545751, acc.: 77.34%] [G loss: 1.419359]\n",
      "epoch:22 step:20750 [D loss: 0.669296, acc.: 56.25%] [G loss: 1.448366]\n",
      "epoch:22 step:20751 [D loss: 0.711495, acc.: 52.34%] [G loss: 0.904374]\n",
      "epoch:22 step:20752 [D loss: 0.788415, acc.: 47.66%] [G loss: 0.872499]\n",
      "epoch:22 step:20753 [D loss: 0.509706, acc.: 73.44%] [G loss: 1.068918]\n",
      "epoch:22 step:20754 [D loss: 0.555992, acc.: 69.53%] [G loss: 0.854107]\n",
      "epoch:22 step:20755 [D loss: 0.381902, acc.: 88.28%] [G loss: 1.363740]\n",
      "epoch:22 step:20756 [D loss: 0.737610, acc.: 56.25%] [G loss: 1.281110]\n",
      "epoch:22 step:20757 [D loss: 0.286424, acc.: 89.84%] [G loss: 1.488372]\n",
      "epoch:22 step:20758 [D loss: 0.469922, acc.: 82.03%] [G loss: 1.444688]\n",
      "epoch:22 step:20759 [D loss: 0.217458, acc.: 96.09%] [G loss: 1.370774]\n",
      "epoch:22 step:20760 [D loss: 0.477926, acc.: 81.25%] [G loss: 1.495069]\n",
      "epoch:22 step:20761 [D loss: 0.588651, acc.: 63.28%] [G loss: 1.320541]\n",
      "epoch:22 step:20762 [D loss: 0.796130, acc.: 43.75%] [G loss: 1.174164]\n",
      "epoch:22 step:20763 [D loss: 0.234471, acc.: 93.75%] [G loss: 1.360621]\n",
      "epoch:22 step:20764 [D loss: 0.188610, acc.: 96.09%] [G loss: 1.671555]\n",
      "epoch:22 step:20765 [D loss: 0.171333, acc.: 98.44%] [G loss: 1.852639]\n",
      "epoch:22 step:20766 [D loss: 0.312526, acc.: 95.31%] [G loss: 1.525733]\n",
      "epoch:22 step:20767 [D loss: 0.828868, acc.: 50.78%] [G loss: 1.500378]\n",
      "epoch:22 step:20768 [D loss: 0.604901, acc.: 65.62%] [G loss: 1.394949]\n",
      "epoch:22 step:20769 [D loss: 0.477253, acc.: 82.03%] [G loss: 1.184128]\n",
      "epoch:22 step:20770 [D loss: 0.766689, acc.: 52.34%] [G loss: 0.721435]\n",
      "epoch:22 step:20771 [D loss: 0.749997, acc.: 58.59%] [G loss: 1.056468]\n",
      "epoch:22 step:20772 [D loss: 0.728521, acc.: 52.34%] [G loss: 1.072620]\n",
      "epoch:22 step:20773 [D loss: 0.634724, acc.: 67.19%] [G loss: 1.005237]\n",
      "epoch:22 step:20774 [D loss: 0.408056, acc.: 79.69%] [G loss: 0.746344]\n",
      "epoch:22 step:20775 [D loss: 0.653110, acc.: 59.38%] [G loss: 1.031349]\n",
      "epoch:22 step:20776 [D loss: 0.363993, acc.: 88.28%] [G loss: 1.118391]\n",
      "epoch:22 step:20777 [D loss: 0.509436, acc.: 76.56%] [G loss: 1.314882]\n",
      "epoch:22 step:20778 [D loss: 0.375293, acc.: 89.06%] [G loss: 1.588520]\n",
      "epoch:22 step:20779 [D loss: 0.756802, acc.: 56.25%] [G loss: 1.584922]\n",
      "epoch:22 step:20780 [D loss: 0.903831, acc.: 49.22%] [G loss: 1.104398]\n",
      "epoch:22 step:20781 [D loss: 0.869591, acc.: 47.66%] [G loss: 0.887412]\n",
      "epoch:22 step:20782 [D loss: 0.803389, acc.: 50.00%] [G loss: 1.115114]\n",
      "epoch:22 step:20783 [D loss: 0.650851, acc.: 64.84%] [G loss: 1.145237]\n",
      "epoch:22 step:20784 [D loss: 0.548321, acc.: 77.34%] [G loss: 1.179488]\n",
      "epoch:22 step:20785 [D loss: 0.796803, acc.: 46.09%] [G loss: 0.992919]\n",
      "epoch:22 step:20786 [D loss: 0.658617, acc.: 59.38%] [G loss: 0.877109]\n",
      "epoch:22 step:20787 [D loss: 0.960402, acc.: 35.16%] [G loss: 1.046876]\n",
      "epoch:22 step:20788 [D loss: 0.865962, acc.: 42.97%] [G loss: 1.336682]\n",
      "epoch:22 step:20789 [D loss: 0.637250, acc.: 64.84%] [G loss: 1.351629]\n",
      "epoch:22 step:20790 [D loss: 0.599035, acc.: 69.53%] [G loss: 1.301877]\n",
      "epoch:22 step:20791 [D loss: 0.687522, acc.: 58.59%] [G loss: 0.904168]\n",
      "epoch:22 step:20792 [D loss: 0.988526, acc.: 42.97%] [G loss: 1.261589]\n",
      "epoch:22 step:20793 [D loss: 0.574652, acc.: 72.66%] [G loss: 1.272211]\n",
      "epoch:22 step:20794 [D loss: 0.783086, acc.: 53.91%] [G loss: 1.203247]\n",
      "epoch:22 step:20795 [D loss: 0.615434, acc.: 68.75%] [G loss: 1.029199]\n",
      "epoch:22 step:20796 [D loss: 0.647788, acc.: 62.50%] [G loss: 1.000407]\n",
      "epoch:22 step:20797 [D loss: 0.619785, acc.: 64.06%] [G loss: 0.986142]\n",
      "epoch:22 step:20798 [D loss: 0.674014, acc.: 60.94%] [G loss: 1.214162]\n",
      "epoch:22 step:20799 [D loss: 0.503311, acc.: 80.47%] [G loss: 1.191024]\n",
      "epoch:22 step:20800 [D loss: 0.663203, acc.: 60.16%] [G loss: 1.158259]\n",
      "##############\n",
      "[4.35880508 2.6961061  6.55520322 5.84598085 4.93499993 6.41146492\n",
      " 5.42214649 5.65330227 5.97428998 5.3034895 ]\n",
      "##########\n",
      "epoch:22 step:20801 [D loss: 0.600513, acc.: 64.84%] [G loss: 0.876284]\n",
      "epoch:22 step:20802 [D loss: 0.632082, acc.: 64.06%] [G loss: 1.113721]\n",
      "epoch:22 step:20803 [D loss: 0.630160, acc.: 62.50%] [G loss: 0.826895]\n",
      "epoch:22 step:20804 [D loss: 0.611370, acc.: 68.75%] [G loss: 1.047797]\n",
      "epoch:22 step:20805 [D loss: 0.716538, acc.: 52.34%] [G loss: 1.075611]\n",
      "epoch:22 step:20806 [D loss: 0.434189, acc.: 78.91%] [G loss: 0.892033]\n",
      "epoch:22 step:20807 [D loss: 0.479379, acc.: 78.12%] [G loss: 1.051614]\n",
      "epoch:22 step:20808 [D loss: 0.374768, acc.: 89.84%] [G loss: 1.291505]\n",
      "epoch:22 step:20809 [D loss: 0.474079, acc.: 81.25%] [G loss: 1.480585]\n",
      "epoch:22 step:20810 [D loss: 0.459342, acc.: 84.38%] [G loss: 1.208850]\n",
      "epoch:22 step:20811 [D loss: 0.464344, acc.: 80.47%] [G loss: 1.324696]\n",
      "epoch:22 step:20812 [D loss: 0.427605, acc.: 86.72%] [G loss: 1.740327]\n",
      "epoch:22 step:20813 [D loss: 0.669092, acc.: 53.91%] [G loss: 1.695239]\n",
      "epoch:22 step:20814 [D loss: 0.393719, acc.: 90.62%] [G loss: 1.289937]\n",
      "epoch:22 step:20815 [D loss: 0.267120, acc.: 98.44%] [G loss: 1.412947]\n",
      "epoch:22 step:20816 [D loss: 0.702060, acc.: 53.12%] [G loss: 1.310754]\n",
      "epoch:22 step:20817 [D loss: 0.275608, acc.: 99.22%] [G loss: 1.377338]\n",
      "epoch:22 step:20818 [D loss: 0.243714, acc.: 96.88%] [G loss: 1.404943]\n",
      "epoch:22 step:20819 [D loss: 0.338079, acc.: 96.09%] [G loss: 1.501423]\n",
      "epoch:22 step:20820 [D loss: 0.224714, acc.: 96.88%] [G loss: 1.418481]\n",
      "epoch:22 step:20821 [D loss: 0.205990, acc.: 95.31%] [G loss: 1.741497]\n",
      "epoch:22 step:20822 [D loss: 0.180921, acc.: 98.44%] [G loss: 1.848947]\n",
      "epoch:22 step:20823 [D loss: 0.256862, acc.: 93.75%] [G loss: 1.979438]\n",
      "epoch:22 step:20824 [D loss: 0.826140, acc.: 50.00%] [G loss: 1.473654]\n",
      "epoch:22 step:20825 [D loss: 0.896730, acc.: 46.88%] [G loss: 1.533394]\n",
      "epoch:22 step:20826 [D loss: 0.597950, acc.: 66.41%] [G loss: 1.202670]\n",
      "epoch:22 step:20827 [D loss: 0.652069, acc.: 57.03%] [G loss: 0.870595]\n",
      "epoch:22 step:20828 [D loss: 0.823133, acc.: 48.44%] [G loss: 1.018558]\n",
      "epoch:22 step:20829 [D loss: 0.729689, acc.: 60.94%] [G loss: 0.951083]\n",
      "epoch:22 step:20830 [D loss: 0.919508, acc.: 37.50%] [G loss: 0.945961]\n",
      "epoch:22 step:20831 [D loss: 0.402600, acc.: 82.81%] [G loss: 1.045674]\n",
      "epoch:22 step:20832 [D loss: 0.341912, acc.: 81.25%] [G loss: 1.166463]\n",
      "epoch:22 step:20833 [D loss: 0.274906, acc.: 89.06%] [G loss: 1.347988]\n",
      "epoch:22 step:20834 [D loss: 0.258031, acc.: 95.31%] [G loss: 1.307316]\n",
      "epoch:22 step:20835 [D loss: 0.324269, acc.: 92.19%] [G loss: 1.459565]\n",
      "epoch:22 step:20836 [D loss: 0.534968, acc.: 72.66%] [G loss: 1.486059]\n",
      "epoch:22 step:20837 [D loss: 0.546617, acc.: 76.56%] [G loss: 1.629245]\n",
      "epoch:22 step:20838 [D loss: 0.454450, acc.: 85.94%] [G loss: 1.365203]\n",
      "epoch:22 step:20839 [D loss: 0.311776, acc.: 96.09%] [G loss: 1.331946]\n",
      "epoch:22 step:20840 [D loss: 0.752222, acc.: 53.91%] [G loss: 1.201057]\n",
      "epoch:22 step:20841 [D loss: 0.621388, acc.: 63.28%] [G loss: 1.264766]\n",
      "epoch:22 step:20842 [D loss: 0.729213, acc.: 52.34%] [G loss: 0.898296]\n",
      "epoch:22 step:20843 [D loss: 0.663959, acc.: 58.59%] [G loss: 1.032329]\n",
      "epoch:22 step:20844 [D loss: 0.190305, acc.: 94.53%] [G loss: 1.219795]\n",
      "epoch:22 step:20845 [D loss: 0.243707, acc.: 96.09%] [G loss: 1.095748]\n",
      "epoch:22 step:20846 [D loss: 0.241194, acc.: 89.06%] [G loss: 1.189636]\n",
      "epoch:22 step:20847 [D loss: 0.617862, acc.: 67.97%] [G loss: 1.096507]\n",
      "epoch:22 step:20848 [D loss: 0.461478, acc.: 80.47%] [G loss: 1.462671]\n",
      "epoch:22 step:20849 [D loss: 0.354060, acc.: 90.62%] [G loss: 1.452275]\n",
      "epoch:22 step:20850 [D loss: 0.608526, acc.: 69.53%] [G loss: 1.151337]\n",
      "epoch:22 step:20851 [D loss: 0.311984, acc.: 91.41%] [G loss: 0.941389]\n",
      "epoch:22 step:20852 [D loss: 0.790767, acc.: 56.25%] [G loss: 1.387573]\n",
      "epoch:22 step:20853 [D loss: 0.820712, acc.: 46.09%] [G loss: 1.328920]\n",
      "epoch:22 step:20854 [D loss: 0.665949, acc.: 60.94%] [G loss: 1.074851]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:22 step:20855 [D loss: 0.541503, acc.: 71.88%] [G loss: 1.078663]\n",
      "epoch:22 step:20856 [D loss: 0.741932, acc.: 50.78%] [G loss: 1.078907]\n",
      "epoch:22 step:20857 [D loss: 0.471454, acc.: 84.38%] [G loss: 1.284640]\n",
      "epoch:22 step:20858 [D loss: 0.725933, acc.: 53.91%] [G loss: 1.052541]\n",
      "epoch:22 step:20859 [D loss: 0.632614, acc.: 62.50%] [G loss: 0.904947]\n",
      "epoch:22 step:20860 [D loss: 0.615095, acc.: 60.94%] [G loss: 1.255387]\n",
      "epoch:22 step:20861 [D loss: 0.622330, acc.: 67.19%] [G loss: 1.131869]\n",
      "epoch:22 step:20862 [D loss: 0.655711, acc.: 63.28%] [G loss: 1.066321]\n",
      "epoch:22 step:20863 [D loss: 0.618627, acc.: 65.62%] [G loss: 1.143902]\n",
      "epoch:22 step:20864 [D loss: 0.709123, acc.: 53.12%] [G loss: 1.018957]\n",
      "epoch:22 step:20865 [D loss: 0.680059, acc.: 56.25%] [G loss: 1.016073]\n",
      "epoch:22 step:20866 [D loss: 0.721646, acc.: 52.34%] [G loss: 1.082458]\n",
      "epoch:22 step:20867 [D loss: 0.727746, acc.: 55.47%] [G loss: 0.967822]\n",
      "epoch:22 step:20868 [D loss: 0.747897, acc.: 57.81%] [G loss: 1.190117]\n",
      "epoch:22 step:20869 [D loss: 0.381158, acc.: 92.19%] [G loss: 1.139879]\n",
      "epoch:22 step:20870 [D loss: 0.194898, acc.: 97.66%] [G loss: 1.276760]\n",
      "epoch:22 step:20871 [D loss: 0.378965, acc.: 89.06%] [G loss: 1.472896]\n",
      "epoch:22 step:20872 [D loss: 0.697468, acc.: 52.34%] [G loss: 1.199965]\n",
      "epoch:22 step:20873 [D loss: 0.242220, acc.: 88.28%] [G loss: 1.157158]\n",
      "epoch:22 step:20874 [D loss: 0.231455, acc.: 95.31%] [G loss: 1.718166]\n",
      "epoch:22 step:20875 [D loss: 0.153455, acc.: 99.22%] [G loss: 1.604154]\n",
      "epoch:22 step:20876 [D loss: 0.528234, acc.: 72.66%] [G loss: 1.346734]\n",
      "epoch:22 step:20877 [D loss: 0.628464, acc.: 62.50%] [G loss: 1.067160]\n",
      "epoch:22 step:20878 [D loss: 0.654141, acc.: 65.62%] [G loss: 1.219451]\n",
      "epoch:22 step:20879 [D loss: 0.423998, acc.: 83.59%] [G loss: 1.043545]\n",
      "epoch:22 step:20880 [D loss: 0.683448, acc.: 60.16%] [G loss: 0.936407]\n",
      "epoch:22 step:20881 [D loss: 0.640434, acc.: 59.38%] [G loss: 1.138654]\n",
      "epoch:22 step:20882 [D loss: 0.695662, acc.: 55.47%] [G loss: 1.180867]\n",
      "epoch:22 step:20883 [D loss: 0.391652, acc.: 84.38%] [G loss: 1.160975]\n",
      "epoch:22 step:20884 [D loss: 0.487934, acc.: 77.34%] [G loss: 0.977911]\n",
      "epoch:22 step:20885 [D loss: 0.437036, acc.: 89.06%] [G loss: 1.284155]\n",
      "epoch:22 step:20886 [D loss: 0.385195, acc.: 87.50%] [G loss: 1.466521]\n",
      "epoch:22 step:20887 [D loss: 0.477657, acc.: 81.25%] [G loss: 1.454729]\n",
      "epoch:22 step:20888 [D loss: 0.499055, acc.: 75.78%] [G loss: 1.199306]\n",
      "epoch:22 step:20889 [D loss: 0.630727, acc.: 66.41%] [G loss: 1.078939]\n",
      "epoch:22 step:20890 [D loss: 0.389445, acc.: 93.75%] [G loss: 1.002903]\n",
      "epoch:22 step:20891 [D loss: 0.663701, acc.: 64.84%] [G loss: 1.432795]\n",
      "epoch:22 step:20892 [D loss: 0.244413, acc.: 92.19%] [G loss: 1.262975]\n",
      "epoch:22 step:20893 [D loss: 0.228681, acc.: 92.19%] [G loss: 1.268344]\n",
      "epoch:22 step:20894 [D loss: 0.602880, acc.: 67.19%] [G loss: 1.243666]\n",
      "epoch:22 step:20895 [D loss: 0.802311, acc.: 54.69%] [G loss: 1.319667]\n",
      "epoch:22 step:20896 [D loss: 0.478520, acc.: 84.38%] [G loss: 1.365304]\n",
      "epoch:22 step:20897 [D loss: 0.561163, acc.: 67.19%] [G loss: 1.268319]\n",
      "epoch:22 step:20898 [D loss: 0.371342, acc.: 89.06%] [G loss: 1.251877]\n",
      "epoch:22 step:20899 [D loss: 0.667915, acc.: 63.28%] [G loss: 0.170999]\n",
      "epoch:22 step:20900 [D loss: 0.642364, acc.: 69.53%] [G loss: 1.006444]\n",
      "epoch:22 step:20901 [D loss: 0.322966, acc.: 93.75%] [G loss: 1.009409]\n",
      "epoch:22 step:20902 [D loss: 0.233368, acc.: 96.09%] [G loss: 1.613287]\n",
      "epoch:22 step:20903 [D loss: 0.225156, acc.: 95.31%] [G loss: 1.125999]\n",
      "epoch:22 step:20904 [D loss: 0.274932, acc.: 91.41%] [G loss: 1.743652]\n",
      "epoch:22 step:20905 [D loss: 0.565768, acc.: 66.41%] [G loss: 1.554106]\n",
      "epoch:22 step:20906 [D loss: 0.205261, acc.: 99.22%] [G loss: 1.687065]\n",
      "epoch:22 step:20907 [D loss: 0.157999, acc.: 99.22%] [G loss: 1.634487]\n",
      "epoch:22 step:20908 [D loss: 0.458426, acc.: 79.69%] [G loss: 1.254594]\n",
      "epoch:22 step:20909 [D loss: 0.921419, acc.: 40.62%] [G loss: 0.375690]\n",
      "epoch:22 step:20910 [D loss: 0.654108, acc.: 62.50%] [G loss: 0.628362]\n",
      "epoch:22 step:20911 [D loss: 0.989926, acc.: 42.19%] [G loss: 0.630237]\n",
      "epoch:22 step:20912 [D loss: 0.395129, acc.: 87.50%] [G loss: 0.793763]\n",
      "epoch:22 step:20913 [D loss: 0.294506, acc.: 96.09%] [G loss: 0.703500]\n",
      "epoch:22 step:20914 [D loss: 0.464707, acc.: 78.91%] [G loss: 1.128590]\n",
      "epoch:22 step:20915 [D loss: 1.032533, acc.: 31.25%] [G loss: 1.620157]\n",
      "epoch:22 step:20916 [D loss: 0.671051, acc.: 62.50%] [G loss: 1.449390]\n",
      "epoch:22 step:20917 [D loss: 0.599379, acc.: 68.75%] [G loss: 1.268314]\n",
      "epoch:22 step:20918 [D loss: 0.734420, acc.: 58.59%] [G loss: 1.342903]\n",
      "epoch:22 step:20919 [D loss: 0.553862, acc.: 67.97%] [G loss: 1.100984]\n",
      "epoch:22 step:20920 [D loss: 0.637280, acc.: 70.31%] [G loss: 0.794238]\n",
      "epoch:22 step:20921 [D loss: 0.463118, acc.: 80.47%] [G loss: 1.283668]\n",
      "epoch:22 step:20922 [D loss: 0.600077, acc.: 69.53%] [G loss: 0.530158]\n",
      "epoch:22 step:20923 [D loss: 0.253687, acc.: 89.84%] [G loss: 1.479705]\n",
      "epoch:22 step:20924 [D loss: 0.629389, acc.: 67.97%] [G loss: 0.726192]\n",
      "epoch:22 step:20925 [D loss: 0.689773, acc.: 57.81%] [G loss: 1.097131]\n",
      "epoch:22 step:20926 [D loss: 0.243001, acc.: 90.62%] [G loss: 0.542012]\n",
      "epoch:22 step:20927 [D loss: 0.254499, acc.: 90.62%] [G loss: 1.482835]\n",
      "epoch:22 step:20928 [D loss: 0.116989, acc.: 99.22%] [G loss: 0.856360]\n",
      "epoch:22 step:20929 [D loss: 0.218197, acc.: 96.88%] [G loss: 1.275034]\n",
      "epoch:22 step:20930 [D loss: 0.393986, acc.: 89.06%] [G loss: 1.210521]\n",
      "epoch:22 step:20931 [D loss: 0.859207, acc.: 39.84%] [G loss: 0.817224]\n",
      "epoch:22 step:20932 [D loss: 0.711710, acc.: 54.69%] [G loss: 1.502553]\n",
      "epoch:22 step:20933 [D loss: 0.505166, acc.: 73.44%] [G loss: 1.225420]\n",
      "epoch:22 step:20934 [D loss: 0.613351, acc.: 70.31%] [G loss: 2.295886]\n",
      "epoch:22 step:20935 [D loss: 0.348278, acc.: 86.72%] [G loss: 2.550716]\n",
      "epoch:22 step:20936 [D loss: 0.147246, acc.: 97.66%] [G loss: 2.809459]\n",
      "epoch:22 step:20937 [D loss: 0.749888, acc.: 57.03%] [G loss: 1.815783]\n",
      "epoch:22 step:20938 [D loss: 0.546158, acc.: 68.75%] [G loss: 2.042833]\n",
      "epoch:22 step:20939 [D loss: 0.251328, acc.: 94.53%] [G loss: 2.512220]\n",
      "epoch:22 step:20940 [D loss: 0.117379, acc.: 98.44%] [G loss: 2.645296]\n",
      "epoch:22 step:20941 [D loss: 0.089274, acc.: 97.66%] [G loss: 3.135590]\n",
      "epoch:22 step:20942 [D loss: 0.080570, acc.: 96.88%] [G loss: 3.776122]\n",
      "epoch:22 step:20943 [D loss: 0.104465, acc.: 98.44%] [G loss: 3.455929]\n",
      "epoch:22 step:20944 [D loss: 0.391546, acc.: 80.47%] [G loss: 2.816441]\n",
      "epoch:22 step:20945 [D loss: 0.203569, acc.: 95.31%] [G loss: 1.805791]\n",
      "epoch:22 step:20946 [D loss: 0.622659, acc.: 61.72%] [G loss: 2.058611]\n",
      "epoch:22 step:20947 [D loss: 1.610016, acc.: 11.72%] [G loss: 1.275651]\n",
      "epoch:22 step:20948 [D loss: 0.979134, acc.: 46.09%] [G loss: 1.106795]\n",
      "epoch:22 step:20949 [D loss: 0.554577, acc.: 70.31%] [G loss: 0.965504]\n",
      "epoch:22 step:20950 [D loss: 0.735512, acc.: 53.12%] [G loss: 0.746229]\n",
      "epoch:22 step:20951 [D loss: 0.581715, acc.: 67.97%] [G loss: 1.466672]\n",
      "epoch:22 step:20952 [D loss: 0.176984, acc.: 98.44%] [G loss: 1.515827]\n",
      "epoch:22 step:20953 [D loss: 0.415314, acc.: 78.91%] [G loss: 1.745380]\n",
      "epoch:22 step:20954 [D loss: 0.509526, acc.: 77.34%] [G loss: 1.232725]\n",
      "epoch:22 step:20955 [D loss: 0.937361, acc.: 43.75%] [G loss: 1.468747]\n",
      "epoch:22 step:20956 [D loss: 1.497809, acc.: 17.97%] [G loss: 1.455775]\n",
      "epoch:22 step:20957 [D loss: 0.819099, acc.: 50.00%] [G loss: 1.519561]\n",
      "epoch:22 step:20958 [D loss: 0.937239, acc.: 39.06%] [G loss: 0.917734]\n",
      "epoch:22 step:20959 [D loss: 0.778275, acc.: 56.25%] [G loss: 1.470148]\n",
      "epoch:22 step:20960 [D loss: 0.544122, acc.: 74.22%] [G loss: 1.409822]\n",
      "epoch:22 step:20961 [D loss: 0.407646, acc.: 85.16%] [G loss: 0.990308]\n",
      "epoch:22 step:20962 [D loss: 0.699546, acc.: 60.16%] [G loss: 1.300549]\n",
      "epoch:22 step:20963 [D loss: 0.487590, acc.: 78.12%] [G loss: 1.023035]\n",
      "epoch:22 step:20964 [D loss: 0.621298, acc.: 62.50%] [G loss: 1.310722]\n",
      "epoch:22 step:20965 [D loss: 0.299773, acc.: 91.41%] [G loss: 1.343432]\n",
      "epoch:22 step:20966 [D loss: 0.224963, acc.: 96.09%] [G loss: 1.672618]\n",
      "epoch:22 step:20967 [D loss: 0.272461, acc.: 95.31%] [G loss: 1.597608]\n",
      "epoch:22 step:20968 [D loss: 0.290867, acc.: 94.53%] [G loss: 0.921058]\n",
      "epoch:22 step:20969 [D loss: 0.415559, acc.: 82.81%] [G loss: 1.418027]\n",
      "epoch:22 step:20970 [D loss: 0.547466, acc.: 74.22%] [G loss: 1.435239]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:22 step:20971 [D loss: 0.265673, acc.: 91.41%] [G loss: 1.421513]\n",
      "epoch:22 step:20972 [D loss: 0.360481, acc.: 82.81%] [G loss: 0.988578]\n",
      "epoch:22 step:20973 [D loss: 0.261922, acc.: 93.75%] [G loss: 1.711391]\n",
      "epoch:22 step:20974 [D loss: 0.489497, acc.: 78.12%] [G loss: 1.702831]\n",
      "epoch:22 step:20975 [D loss: 0.726814, acc.: 64.06%] [G loss: 0.971522]\n",
      "epoch:22 step:20976 [D loss: 0.915731, acc.: 43.75%] [G loss: 1.319787]\n",
      "epoch:22 step:20977 [D loss: 0.744120, acc.: 60.94%] [G loss: 1.372582]\n",
      "epoch:22 step:20978 [D loss: 0.624245, acc.: 65.62%] [G loss: 1.328657]\n",
      "epoch:22 step:20979 [D loss: 0.602520, acc.: 69.53%] [G loss: 1.237112]\n",
      "epoch:22 step:20980 [D loss: 0.451137, acc.: 83.59%] [G loss: 0.997975]\n",
      "epoch:22 step:20981 [D loss: 0.670472, acc.: 54.69%] [G loss: 0.848943]\n",
      "epoch:22 step:20982 [D loss: 0.953289, acc.: 40.62%] [G loss: 1.116363]\n",
      "epoch:22 step:20983 [D loss: 0.363944, acc.: 86.72%] [G loss: 0.593813]\n",
      "epoch:22 step:20984 [D loss: 0.274747, acc.: 92.19%] [G loss: 1.043847]\n",
      "epoch:22 step:20985 [D loss: 0.345675, acc.: 87.50%] [G loss: 1.120469]\n",
      "epoch:22 step:20986 [D loss: 0.488509, acc.: 76.56%] [G loss: 1.039701]\n",
      "epoch:22 step:20987 [D loss: 1.348207, acc.: 15.62%] [G loss: 1.546225]\n",
      "epoch:22 step:20988 [D loss: 0.614511, acc.: 65.62%] [G loss: 1.299428]\n",
      "epoch:22 step:20989 [D loss: 0.817967, acc.: 49.22%] [G loss: 1.313164]\n",
      "epoch:22 step:20990 [D loss: 0.942327, acc.: 42.19%] [G loss: 1.050011]\n",
      "epoch:22 step:20991 [D loss: 0.525303, acc.: 72.66%] [G loss: 1.210606]\n",
      "epoch:22 step:20992 [D loss: 0.365538, acc.: 89.84%] [G loss: 1.442474]\n",
      "epoch:22 step:20993 [D loss: 0.797823, acc.: 53.12%] [G loss: 1.234798]\n",
      "epoch:22 step:20994 [D loss: 0.408598, acc.: 88.28%] [G loss: 0.989662]\n",
      "epoch:22 step:20995 [D loss: 0.374768, acc.: 88.28%] [G loss: 1.200522]\n",
      "epoch:22 step:20996 [D loss: 0.854754, acc.: 46.09%] [G loss: 1.465766]\n",
      "epoch:22 step:20997 [D loss: 0.778926, acc.: 42.19%] [G loss: 0.922069]\n",
      "epoch:22 step:20998 [D loss: 0.782349, acc.: 46.88%] [G loss: 1.044498]\n",
      "epoch:22 step:20999 [D loss: 0.727570, acc.: 51.56%] [G loss: 1.157663]\n",
      "epoch:22 step:21000 [D loss: 0.656587, acc.: 64.06%] [G loss: 1.209697]\n",
      "##############\n",
      "[4.17382369 2.44521509 6.2320169  5.94045634 4.25390259 6.31775913\n",
      " 4.95258476 5.36481869 6.04436548 5.04758534]\n",
      "##########\n",
      "epoch:22 step:21001 [D loss: 0.609236, acc.: 67.19%] [G loss: 0.863930]\n",
      "epoch:22 step:21002 [D loss: 0.609523, acc.: 64.06%] [G loss: 1.105947]\n",
      "epoch:22 step:21003 [D loss: 0.556637, acc.: 70.31%] [G loss: 1.095206]\n",
      "epoch:22 step:21004 [D loss: 0.530695, acc.: 73.44%] [G loss: 0.988674]\n",
      "epoch:22 step:21005 [D loss: 0.590115, acc.: 66.41%] [G loss: 1.159436]\n",
      "epoch:22 step:21006 [D loss: 0.730668, acc.: 53.91%] [G loss: 1.143892]\n",
      "epoch:22 step:21007 [D loss: 0.440730, acc.: 81.25%] [G loss: 1.229705]\n",
      "epoch:22 step:21008 [D loss: 0.524181, acc.: 76.56%] [G loss: 1.151810]\n",
      "epoch:22 step:21009 [D loss: 0.747829, acc.: 56.25%] [G loss: 0.993633]\n",
      "epoch:22 step:21010 [D loss: 0.296668, acc.: 85.16%] [G loss: 0.977957]\n",
      "epoch:22 step:21011 [D loss: 0.216601, acc.: 92.19%] [G loss: 1.322977]\n",
      "epoch:22 step:21012 [D loss: 0.241819, acc.: 92.19%] [G loss: 1.607149]\n",
      "epoch:22 step:21013 [D loss: 0.247495, acc.: 92.97%] [G loss: 1.787877]\n",
      "epoch:22 step:21014 [D loss: 0.250774, acc.: 96.88%] [G loss: 1.780788]\n",
      "epoch:22 step:21015 [D loss: 0.401391, acc.: 87.50%] [G loss: 1.586448]\n",
      "epoch:22 step:21016 [D loss: 0.211670, acc.: 95.31%] [G loss: 1.775504]\n",
      "epoch:22 step:21017 [D loss: 0.239167, acc.: 94.53%] [G loss: 1.755075]\n",
      "epoch:22 step:21018 [D loss: 0.272225, acc.: 96.88%] [G loss: 1.458240]\n",
      "epoch:22 step:21019 [D loss: 0.102910, acc.: 100.00%] [G loss: 1.464572]\n",
      "epoch:22 step:21020 [D loss: 0.335453, acc.: 80.47%] [G loss: 1.541900]\n",
      "epoch:22 step:21021 [D loss: 0.165555, acc.: 96.88%] [G loss: 0.668821]\n",
      "epoch:22 step:21022 [D loss: 0.138409, acc.: 99.22%] [G loss: 1.809273]\n",
      "epoch:22 step:21023 [D loss: 0.136432, acc.: 100.00%] [G loss: 1.264311]\n",
      "epoch:22 step:21024 [D loss: 0.202002, acc.: 98.44%] [G loss: 1.838217]\n",
      "epoch:22 step:21025 [D loss: 1.972377, acc.: 2.34%] [G loss: 1.804531]\n",
      "epoch:22 step:21026 [D loss: 0.485065, acc.: 77.34%] [G loss: 1.479568]\n",
      "epoch:22 step:21027 [D loss: 0.276312, acc.: 93.75%] [G loss: 2.024802]\n",
      "epoch:22 step:21028 [D loss: 0.278103, acc.: 92.19%] [G loss: 2.030836]\n",
      "epoch:22 step:21029 [D loss: 0.586565, acc.: 67.97%] [G loss: 1.428119]\n",
      "epoch:22 step:21030 [D loss: 0.674053, acc.: 57.81%] [G loss: 0.408582]\n",
      "epoch:22 step:21031 [D loss: 0.277560, acc.: 93.75%] [G loss: 1.518047]\n",
      "epoch:22 step:21032 [D loss: 0.310892, acc.: 87.50%] [G loss: 1.898903]\n",
      "epoch:22 step:21033 [D loss: 0.466496, acc.: 67.19%] [G loss: 0.804043]\n",
      "epoch:22 step:21034 [D loss: 0.349947, acc.: 87.50%] [G loss: 1.356775]\n",
      "epoch:22 step:21035 [D loss: 0.898790, acc.: 46.09%] [G loss: 1.506054]\n",
      "epoch:22 step:21036 [D loss: 2.164396, acc.: 3.12%] [G loss: 1.747378]\n",
      "epoch:22 step:21037 [D loss: 0.699424, acc.: 60.16%] [G loss: 1.367336]\n",
      "epoch:22 step:21038 [D loss: 0.366478, acc.: 85.94%] [G loss: 1.096590]\n",
      "epoch:22 step:21039 [D loss: 0.456219, acc.: 76.56%] [G loss: 1.128713]\n",
      "epoch:22 step:21040 [D loss: 1.125725, acc.: 18.75%] [G loss: 1.494155]\n",
      "epoch:22 step:21041 [D loss: 0.319680, acc.: 89.06%] [G loss: 1.491630]\n",
      "epoch:22 step:21042 [D loss: 0.334746, acc.: 85.94%] [G loss: 1.927513]\n",
      "epoch:22 step:21043 [D loss: 0.443600, acc.: 84.38%] [G loss: 1.603671]\n",
      "epoch:22 step:21044 [D loss: 0.294746, acc.: 89.06%] [G loss: 1.341412]\n",
      "epoch:22 step:21045 [D loss: 0.853811, acc.: 48.44%] [G loss: 1.457675]\n",
      "epoch:22 step:21046 [D loss: 1.042971, acc.: 49.22%] [G loss: 1.363052]\n",
      "epoch:22 step:21047 [D loss: 1.022874, acc.: 40.62%] [G loss: 1.519132]\n",
      "epoch:22 step:21048 [D loss: 0.927260, acc.: 48.44%] [G loss: 1.440024]\n",
      "epoch:22 step:21049 [D loss: 0.673531, acc.: 58.59%] [G loss: 1.779380]\n",
      "epoch:22 step:21050 [D loss: 0.645380, acc.: 67.97%] [G loss: 1.487242]\n",
      "epoch:22 step:21051 [D loss: 0.739738, acc.: 48.44%] [G loss: 1.939407]\n",
      "epoch:22 step:21052 [D loss: 0.728041, acc.: 63.28%] [G loss: 1.462383]\n",
      "epoch:22 step:21053 [D loss: 0.743807, acc.: 51.56%] [G loss: 1.213760]\n",
      "epoch:22 step:21054 [D loss: 0.696147, acc.: 53.91%] [G loss: 1.113568]\n",
      "epoch:22 step:21055 [D loss: 0.733290, acc.: 52.34%] [G loss: 1.228746]\n",
      "epoch:22 step:21056 [D loss: 0.771349, acc.: 53.91%] [G loss: 1.165122]\n",
      "epoch:22 step:21057 [D loss: 0.666704, acc.: 59.38%] [G loss: 1.246463]\n",
      "epoch:22 step:21058 [D loss: 0.658083, acc.: 60.16%] [G loss: 1.530178]\n",
      "epoch:22 step:21059 [D loss: 0.613643, acc.: 65.62%] [G loss: 1.169734]\n",
      "epoch:22 step:21060 [D loss: 0.712144, acc.: 54.69%] [G loss: 1.011160]\n",
      "epoch:22 step:21061 [D loss: 0.740395, acc.: 56.25%] [G loss: 1.090072]\n",
      "epoch:22 step:21062 [D loss: 0.502659, acc.: 80.47%] [G loss: 1.272529]\n",
      "epoch:22 step:21063 [D loss: 0.461503, acc.: 82.81%] [G loss: 1.476368]\n",
      "epoch:22 step:21064 [D loss: 0.428962, acc.: 84.38%] [G loss: 2.253662]\n",
      "epoch:22 step:21065 [D loss: 0.277247, acc.: 95.31%] [G loss: 1.683503]\n",
      "epoch:22 step:21066 [D loss: 0.264082, acc.: 97.66%] [G loss: 2.071072]\n",
      "epoch:22 step:21067 [D loss: 0.302746, acc.: 96.09%] [G loss: 1.602613]\n",
      "epoch:22 step:21068 [D loss: 0.421740, acc.: 86.72%] [G loss: 1.991211]\n",
      "epoch:22 step:21069 [D loss: 0.425134, acc.: 90.62%] [G loss: 1.270548]\n",
      "epoch:22 step:21070 [D loss: 0.305536, acc.: 95.31%] [G loss: 1.662748]\n",
      "epoch:22 step:21071 [D loss: 0.328098, acc.: 93.75%] [G loss: 2.300090]\n",
      "epoch:22 step:21072 [D loss: 0.591950, acc.: 64.84%] [G loss: 1.400241]\n",
      "epoch:22 step:21073 [D loss: 0.598735, acc.: 67.19%] [G loss: 1.759668]\n",
      "epoch:22 step:21074 [D loss: 0.734655, acc.: 53.12%] [G loss: 1.209653]\n",
      "epoch:22 step:21075 [D loss: 0.920490, acc.: 37.50%] [G loss: 1.089537]\n",
      "epoch:22 step:21076 [D loss: 0.841812, acc.: 45.31%] [G loss: 0.770311]\n",
      "epoch:22 step:21077 [D loss: 0.668596, acc.: 57.03%] [G loss: 0.941401]\n",
      "epoch:22 step:21078 [D loss: 0.524314, acc.: 75.00%] [G loss: 0.810799]\n",
      "epoch:22 step:21079 [D loss: 0.501144, acc.: 75.78%] [G loss: 1.284281]\n",
      "epoch:22 step:21080 [D loss: 0.500850, acc.: 81.25%] [G loss: 0.895857]\n",
      "epoch:22 step:21081 [D loss: 0.443801, acc.: 83.59%] [G loss: 1.150671]\n",
      "epoch:22 step:21082 [D loss: 0.297591, acc.: 89.84%] [G loss: 1.129578]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:22 step:21083 [D loss: 0.233837, acc.: 93.75%] [G loss: 1.394145]\n",
      "epoch:22 step:21084 [D loss: 0.184957, acc.: 96.88%] [G loss: 1.852923]\n",
      "epoch:22 step:21085 [D loss: 0.223748, acc.: 96.09%] [G loss: 1.170522]\n",
      "epoch:22 step:21086 [D loss: 0.321553, acc.: 96.09%] [G loss: 1.672917]\n",
      "epoch:22 step:21087 [D loss: 0.862083, acc.: 50.78%] [G loss: 1.231282]\n",
      "epoch:22 step:21088 [D loss: 0.451499, acc.: 79.69%] [G loss: 0.995497]\n",
      "epoch:22 step:21089 [D loss: 0.804992, acc.: 50.78%] [G loss: 1.423678]\n",
      "epoch:22 step:21090 [D loss: 0.645145, acc.: 64.06%] [G loss: 1.305147]\n",
      "epoch:22 step:21091 [D loss: 0.697106, acc.: 64.06%] [G loss: 0.973983]\n",
      "epoch:22 step:21092 [D loss: 0.730535, acc.: 54.69%] [G loss: 1.235352]\n",
      "epoch:22 step:21093 [D loss: 0.358966, acc.: 87.50%] [G loss: 1.188557]\n",
      "epoch:22 step:21094 [D loss: 0.518488, acc.: 73.44%] [G loss: 1.171411]\n",
      "epoch:22 step:21095 [D loss: 0.430259, acc.: 79.69%] [G loss: 1.371496]\n",
      "epoch:22 step:21096 [D loss: 0.853335, acc.: 51.56%] [G loss: 1.303036]\n",
      "epoch:22 step:21097 [D loss: 0.685791, acc.: 60.94%] [G loss: 1.093333]\n",
      "epoch:22 step:21098 [D loss: 0.431852, acc.: 82.03%] [G loss: 1.284674]\n",
      "epoch:22 step:21099 [D loss: 0.635931, acc.: 63.28%] [G loss: 1.171784]\n",
      "epoch:22 step:21100 [D loss: 0.668641, acc.: 57.81%] [G loss: 1.275088]\n",
      "epoch:22 step:21101 [D loss: 0.550579, acc.: 72.66%] [G loss: 1.441907]\n",
      "epoch:22 step:21102 [D loss: 0.478998, acc.: 81.25%] [G loss: 1.430164]\n",
      "epoch:22 step:21103 [D loss: 0.600261, acc.: 66.41%] [G loss: 1.092222]\n",
      "epoch:22 step:21104 [D loss: 0.715752, acc.: 57.81%] [G loss: 1.089847]\n",
      "epoch:22 step:21105 [D loss: 0.579548, acc.: 69.53%] [G loss: 1.287031]\n",
      "epoch:22 step:21106 [D loss: 0.702716, acc.: 54.69%] [G loss: 1.229272]\n",
      "epoch:22 step:21107 [D loss: 0.689270, acc.: 58.59%] [G loss: 1.163807]\n",
      "epoch:22 step:21108 [D loss: 0.499930, acc.: 81.25%] [G loss: 1.333253]\n",
      "epoch:22 step:21109 [D loss: 0.603236, acc.: 65.62%] [G loss: 1.148760]\n",
      "epoch:22 step:21110 [D loss: 0.586598, acc.: 69.53%] [G loss: 0.855510]\n",
      "epoch:22 step:21111 [D loss: 0.525827, acc.: 75.00%] [G loss: 1.219434]\n",
      "epoch:22 step:21112 [D loss: 0.283620, acc.: 87.50%] [G loss: 0.911167]\n",
      "epoch:22 step:21113 [D loss: 0.292654, acc.: 91.41%] [G loss: 1.610621]\n",
      "epoch:22 step:21114 [D loss: 0.704642, acc.: 61.72%] [G loss: 1.610378]\n",
      "epoch:22 step:21115 [D loss: 0.647754, acc.: 63.28%] [G loss: 1.112345]\n",
      "epoch:22 step:21116 [D loss: 0.604082, acc.: 64.84%] [G loss: 1.033034]\n",
      "epoch:22 step:21117 [D loss: 0.294020, acc.: 89.84%] [G loss: 1.549700]\n",
      "epoch:22 step:21118 [D loss: 0.257102, acc.: 92.19%] [G loss: 0.923813]\n",
      "epoch:22 step:21119 [D loss: 0.383015, acc.: 85.16%] [G loss: 1.120597]\n",
      "epoch:22 step:21120 [D loss: 0.761836, acc.: 50.78%] [G loss: 1.554218]\n",
      "epoch:22 step:21121 [D loss: 0.462454, acc.: 79.69%] [G loss: 0.928287]\n",
      "epoch:22 step:21122 [D loss: 0.398493, acc.: 85.16%] [G loss: 1.511473]\n",
      "epoch:22 step:21123 [D loss: 0.680010, acc.: 61.72%] [G loss: 0.957425]\n",
      "epoch:22 step:21124 [D loss: 0.390973, acc.: 83.59%] [G loss: 1.402444]\n",
      "epoch:22 step:21125 [D loss: 0.315697, acc.: 90.62%] [G loss: 1.171272]\n",
      "epoch:22 step:21126 [D loss: 0.311310, acc.: 92.97%] [G loss: 1.397966]\n",
      "epoch:22 step:21127 [D loss: 0.306806, acc.: 89.06%] [G loss: 1.473584]\n",
      "epoch:22 step:21128 [D loss: 0.478376, acc.: 81.25%] [G loss: 1.536815]\n",
      "epoch:22 step:21129 [D loss: 0.373699, acc.: 89.84%] [G loss: 1.423322]\n",
      "epoch:22 step:21130 [D loss: 0.605657, acc.: 62.50%] [G loss: 1.495242]\n",
      "epoch:22 step:21131 [D loss: 0.420321, acc.: 86.72%] [G loss: 1.364615]\n",
      "epoch:22 step:21132 [D loss: 0.614817, acc.: 70.31%] [G loss: 0.866055]\n",
      "epoch:22 step:21133 [D loss: 0.655163, acc.: 60.94%] [G loss: 1.112420]\n",
      "epoch:22 step:21134 [D loss: 0.509650, acc.: 75.78%] [G loss: 0.857073]\n",
      "epoch:22 step:21135 [D loss: 0.544991, acc.: 74.22%] [G loss: 0.845126]\n",
      "epoch:22 step:21136 [D loss: 0.608196, acc.: 64.84%] [G loss: 1.305059]\n",
      "epoch:22 step:21137 [D loss: 0.494014, acc.: 84.38%] [G loss: 1.377327]\n",
      "epoch:22 step:21138 [D loss: 0.314396, acc.: 86.72%] [G loss: 1.504422]\n",
      "epoch:22 step:21139 [D loss: 0.762955, acc.: 53.91%] [G loss: 1.235495]\n",
      "epoch:22 step:21140 [D loss: 0.750284, acc.: 50.78%] [G loss: 1.274579]\n",
      "epoch:22 step:21141 [D loss: 0.335136, acc.: 84.38%] [G loss: 1.419492]\n",
      "epoch:22 step:21142 [D loss: 0.590870, acc.: 67.97%] [G loss: 1.536699]\n",
      "epoch:22 step:21143 [D loss: 0.601998, acc.: 65.62%] [G loss: 1.141502]\n",
      "epoch:22 step:21144 [D loss: 0.351752, acc.: 92.97%] [G loss: 1.433291]\n",
      "epoch:22 step:21145 [D loss: 0.657475, acc.: 59.38%] [G loss: 1.119812]\n",
      "epoch:22 step:21146 [D loss: 0.575336, acc.: 71.88%] [G loss: 1.093262]\n",
      "epoch:22 step:21147 [D loss: 0.443218, acc.: 82.81%] [G loss: 1.094953]\n",
      "epoch:22 step:21148 [D loss: 0.735444, acc.: 58.59%] [G loss: 1.311388]\n",
      "epoch:22 step:21149 [D loss: 0.270774, acc.: 92.97%] [G loss: 1.198502]\n",
      "epoch:22 step:21150 [D loss: 0.160786, acc.: 96.09%] [G loss: 1.442013]\n",
      "epoch:22 step:21151 [D loss: 0.361920, acc.: 83.59%] [G loss: 1.457573]\n",
      "epoch:22 step:21152 [D loss: 0.366784, acc.: 92.19%] [G loss: 1.638964]\n",
      "epoch:22 step:21153 [D loss: 0.399826, acc.: 88.28%] [G loss: 1.271646]\n",
      "epoch:22 step:21154 [D loss: 0.472428, acc.: 78.12%] [G loss: 1.719642]\n",
      "epoch:22 step:21155 [D loss: 0.307265, acc.: 91.41%] [G loss: 1.786119]\n",
      "epoch:22 step:21156 [D loss: 0.577416, acc.: 67.97%] [G loss: 1.626525]\n",
      "epoch:22 step:21157 [D loss: 0.403334, acc.: 83.59%] [G loss: 1.389425]\n",
      "epoch:22 step:21158 [D loss: 0.715120, acc.: 57.03%] [G loss: 1.088721]\n",
      "epoch:22 step:21159 [D loss: 0.510822, acc.: 75.78%] [G loss: 1.323313]\n",
      "epoch:22 step:21160 [D loss: 0.551101, acc.: 67.19%] [G loss: 1.133041]\n",
      "epoch:22 step:21161 [D loss: 0.558659, acc.: 66.41%] [G loss: 1.008832]\n",
      "epoch:22 step:21162 [D loss: 0.387417, acc.: 84.38%] [G loss: 1.074388]\n",
      "epoch:22 step:21163 [D loss: 0.293993, acc.: 90.62%] [G loss: 1.314531]\n",
      "epoch:22 step:21164 [D loss: 0.497686, acc.: 68.75%] [G loss: 1.073792]\n",
      "epoch:22 step:21165 [D loss: 1.131230, acc.: 32.81%] [G loss: 1.563263]\n",
      "epoch:22 step:21166 [D loss: 0.671288, acc.: 60.94%] [G loss: 1.766339]\n",
      "epoch:22 step:21167 [D loss: 0.847101, acc.: 46.88%] [G loss: 1.010528]\n",
      "epoch:22 step:21168 [D loss: 0.314829, acc.: 92.19%] [G loss: 0.756093]\n",
      "epoch:22 step:21169 [D loss: 0.658872, acc.: 60.94%] [G loss: 1.286713]\n",
      "epoch:22 step:21170 [D loss: 0.385337, acc.: 83.59%] [G loss: 0.627404]\n",
      "epoch:22 step:21171 [D loss: 0.532338, acc.: 77.34%] [G loss: 1.681869]\n",
      "epoch:22 step:21172 [D loss: 0.617173, acc.: 69.53%] [G loss: 0.246947]\n",
      "epoch:22 step:21173 [D loss: 0.329858, acc.: 81.25%] [G loss: 1.521847]\n",
      "epoch:22 step:21174 [D loss: 0.268546, acc.: 96.09%] [G loss: 2.072832]\n",
      "epoch:22 step:21175 [D loss: 0.185806, acc.: 92.97%] [G loss: 0.965563]\n",
      "epoch:22 step:21176 [D loss: 0.583309, acc.: 69.53%] [G loss: 1.485718]\n",
      "epoch:22 step:21177 [D loss: 0.617156, acc.: 65.62%] [G loss: 1.806492]\n",
      "epoch:22 step:21178 [D loss: 0.572338, acc.: 72.66%] [G loss: 0.842295]\n",
      "epoch:22 step:21179 [D loss: 0.376961, acc.: 82.03%] [G loss: 1.128875]\n",
      "epoch:22 step:21180 [D loss: 0.193062, acc.: 93.75%] [G loss: 1.482932]\n",
      "epoch:22 step:21181 [D loss: 0.132625, acc.: 96.88%] [G loss: 1.672313]\n",
      "epoch:22 step:21182 [D loss: 0.262043, acc.: 89.06%] [G loss: 1.994529]\n",
      "epoch:22 step:21183 [D loss: 0.480111, acc.: 73.44%] [G loss: 2.132986]\n",
      "epoch:22 step:21184 [D loss: 0.235557, acc.: 98.44%] [G loss: 1.710097]\n",
      "epoch:22 step:21185 [D loss: 0.402752, acc.: 86.72%] [G loss: 1.668439]\n",
      "epoch:22 step:21186 [D loss: 0.452995, acc.: 81.25%] [G loss: 1.861088]\n",
      "epoch:22 step:21187 [D loss: 0.316409, acc.: 95.31%] [G loss: 1.409060]\n",
      "epoch:22 step:21188 [D loss: 0.290864, acc.: 92.97%] [G loss: 1.801211]\n",
      "epoch:22 step:21189 [D loss: 0.290781, acc.: 95.31%] [G loss: 1.502473]\n",
      "epoch:22 step:21190 [D loss: 0.279527, acc.: 90.62%] [G loss: 2.506615]\n",
      "epoch:22 step:21191 [D loss: 0.363381, acc.: 80.47%] [G loss: 2.050963]\n",
      "epoch:22 step:21192 [D loss: 0.051138, acc.: 100.00%] [G loss: 3.279073]\n",
      "epoch:22 step:21193 [D loss: 0.055612, acc.: 100.00%] [G loss: 3.082977]\n",
      "epoch:22 step:21194 [D loss: 0.991863, acc.: 53.91%] [G loss: 2.654986]\n",
      "epoch:22 step:21195 [D loss: 0.818182, acc.: 56.25%] [G loss: 2.072348]\n",
      "epoch:22 step:21196 [D loss: 0.643347, acc.: 63.28%] [G loss: 2.033365]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:22 step:21197 [D loss: 0.859461, acc.: 53.91%] [G loss: 1.319563]\n",
      "epoch:22 step:21198 [D loss: 0.641537, acc.: 63.28%] [G loss: 0.572035]\n",
      "epoch:22 step:21199 [D loss: 0.961627, acc.: 46.88%] [G loss: 0.721333]\n",
      "epoch:22 step:21200 [D loss: 0.726323, acc.: 57.81%] [G loss: 1.412096]\n",
      "##############\n",
      "[4.29815575 2.40582106 6.5446355  5.92040257 4.44367497 6.53249798\n",
      " 5.10658829 5.33706827 5.52735773 4.86752437]\n",
      "##########\n",
      "epoch:22 step:21201 [D loss: 0.191507, acc.: 92.97%] [G loss: 1.668508]\n",
      "epoch:22 step:21202 [D loss: 0.196133, acc.: 91.41%] [G loss: 1.693497]\n",
      "epoch:22 step:21203 [D loss: 0.190509, acc.: 93.75%] [G loss: 1.408277]\n",
      "epoch:22 step:21204 [D loss: 0.524202, acc.: 75.78%] [G loss: 1.790275]\n",
      "epoch:22 step:21205 [D loss: 0.757523, acc.: 59.38%] [G loss: 1.183668]\n",
      "epoch:22 step:21206 [D loss: 0.518456, acc.: 74.22%] [G loss: 1.558659]\n",
      "epoch:22 step:21207 [D loss: 0.728210, acc.: 60.16%] [G loss: 0.664995]\n",
      "epoch:22 step:21208 [D loss: 0.513215, acc.: 76.56%] [G loss: 1.153565]\n",
      "epoch:22 step:21209 [D loss: 0.411429, acc.: 76.56%] [G loss: 1.503144]\n",
      "epoch:22 step:21210 [D loss: 0.779006, acc.: 53.12%] [G loss: 1.370678]\n",
      "epoch:22 step:21211 [D loss: 0.690370, acc.: 59.38%] [G loss: 1.778219]\n",
      "epoch:22 step:21212 [D loss: 0.844133, acc.: 45.31%] [G loss: 1.913032]\n",
      "epoch:22 step:21213 [D loss: 0.619585, acc.: 65.62%] [G loss: 1.289124]\n",
      "epoch:22 step:21214 [D loss: 0.290154, acc.: 85.94%] [G loss: 1.356852]\n",
      "epoch:22 step:21215 [D loss: 0.289745, acc.: 90.62%] [G loss: 1.693844]\n",
      "epoch:22 step:21216 [D loss: 0.281338, acc.: 93.75%] [G loss: 1.689810]\n",
      "epoch:22 step:21217 [D loss: 0.616540, acc.: 66.41%] [G loss: 1.489141]\n",
      "epoch:22 step:21218 [D loss: 0.551111, acc.: 72.66%] [G loss: 1.244730]\n",
      "epoch:22 step:21219 [D loss: 0.585912, acc.: 71.09%] [G loss: 1.344018]\n",
      "epoch:22 step:21220 [D loss: 0.367852, acc.: 87.50%] [G loss: 1.659410]\n",
      "epoch:22 step:21221 [D loss: 0.424320, acc.: 85.16%] [G loss: 1.432022]\n",
      "epoch:22 step:21222 [D loss: 0.412252, acc.: 82.81%] [G loss: 1.167645]\n",
      "epoch:22 step:21223 [D loss: 0.343100, acc.: 82.81%] [G loss: 1.547979]\n",
      "epoch:22 step:21224 [D loss: 0.577015, acc.: 73.44%] [G loss: 1.764213]\n",
      "epoch:22 step:21225 [D loss: 0.295920, acc.: 88.28%] [G loss: 1.378635]\n",
      "epoch:22 step:21226 [D loss: 0.327044, acc.: 89.84%] [G loss: 1.413290]\n",
      "epoch:22 step:21227 [D loss: 0.703722, acc.: 55.47%] [G loss: 1.384005]\n",
      "epoch:22 step:21228 [D loss: 0.912533, acc.: 39.06%] [G loss: 1.108093]\n",
      "epoch:22 step:21229 [D loss: 0.778946, acc.: 53.12%] [G loss: 1.205590]\n",
      "epoch:22 step:21230 [D loss: 0.630589, acc.: 67.19%] [G loss: 0.822285]\n",
      "epoch:22 step:21231 [D loss: 0.764675, acc.: 53.12%] [G loss: 1.057521]\n",
      "epoch:22 step:21232 [D loss: 0.460356, acc.: 82.03%] [G loss: 1.350652]\n",
      "epoch:22 step:21233 [D loss: 0.533108, acc.: 70.31%] [G loss: 1.454823]\n",
      "epoch:22 step:21234 [D loss: 0.390056, acc.: 83.59%] [G loss: 1.303279]\n",
      "epoch:22 step:21235 [D loss: 0.664106, acc.: 54.69%] [G loss: 1.416791]\n",
      "epoch:22 step:21236 [D loss: 0.534326, acc.: 73.44%] [G loss: 1.242433]\n",
      "epoch:22 step:21237 [D loss: 0.650329, acc.: 66.41%] [G loss: 1.194485]\n",
      "epoch:22 step:21238 [D loss: 0.348408, acc.: 92.19%] [G loss: 1.193581]\n",
      "epoch:22 step:21239 [D loss: 0.585834, acc.: 67.97%] [G loss: 1.306053]\n",
      "epoch:22 step:21240 [D loss: 0.621906, acc.: 68.75%] [G loss: 1.280430]\n",
      "epoch:22 step:21241 [D loss: 0.609203, acc.: 62.50%] [G loss: 0.900731]\n",
      "epoch:22 step:21242 [D loss: 0.572189, acc.: 74.22%] [G loss: 1.138003]\n",
      "epoch:22 step:21243 [D loss: 0.667259, acc.: 65.62%] [G loss: 1.062584]\n",
      "epoch:22 step:21244 [D loss: 0.550522, acc.: 71.09%] [G loss: 1.338054]\n",
      "epoch:22 step:21245 [D loss: 0.626109, acc.: 66.41%] [G loss: 1.245383]\n",
      "epoch:22 step:21246 [D loss: 0.506457, acc.: 78.91%] [G loss: 1.232874]\n",
      "epoch:22 step:21247 [D loss: 0.329409, acc.: 86.72%] [G loss: 1.199661]\n",
      "epoch:22 step:21248 [D loss: 0.438079, acc.: 84.38%] [G loss: 1.240960]\n",
      "epoch:22 step:21249 [D loss: 0.489290, acc.: 80.47%] [G loss: 1.291168]\n",
      "epoch:22 step:21250 [D loss: 0.678915, acc.: 57.03%] [G loss: 1.578499]\n",
      "epoch:22 step:21251 [D loss: 0.562954, acc.: 71.09%] [G loss: 1.604535]\n",
      "epoch:22 step:21252 [D loss: 0.616058, acc.: 64.84%] [G loss: 1.501306]\n",
      "epoch:22 step:21253 [D loss: 0.344017, acc.: 91.41%] [G loss: 1.534932]\n",
      "epoch:22 step:21254 [D loss: 0.702928, acc.: 55.47%] [G loss: 1.313024]\n",
      "epoch:22 step:21255 [D loss: 0.271372, acc.: 85.16%] [G loss: 1.395875]\n",
      "epoch:22 step:21256 [D loss: 0.685303, acc.: 60.16%] [G loss: 1.639469]\n",
      "epoch:22 step:21257 [D loss: 0.635813, acc.: 58.59%] [G loss: 1.294788]\n",
      "epoch:22 step:21258 [D loss: 0.380078, acc.: 87.50%] [G loss: 1.325905]\n",
      "epoch:22 step:21259 [D loss: 0.209761, acc.: 99.22%] [G loss: 0.759945]\n",
      "epoch:22 step:21260 [D loss: 0.609506, acc.: 66.41%] [G loss: 1.466547]\n",
      "epoch:22 step:21261 [D loss: 0.336183, acc.: 88.28%] [G loss: 1.674383]\n",
      "epoch:22 step:21262 [D loss: 0.269582, acc.: 96.09%] [G loss: 1.561366]\n",
      "epoch:22 step:21263 [D loss: 0.260782, acc.: 95.31%] [G loss: 1.260391]\n",
      "epoch:22 step:21264 [D loss: 0.447980, acc.: 71.88%] [G loss: 1.797249]\n",
      "epoch:22 step:21265 [D loss: 0.445546, acc.: 80.47%] [G loss: 2.010739]\n",
      "epoch:22 step:21266 [D loss: 1.210730, acc.: 28.91%] [G loss: 0.773718]\n",
      "epoch:22 step:21267 [D loss: 1.186706, acc.: 21.09%] [G loss: 1.564731]\n",
      "epoch:22 step:21268 [D loss: 0.932911, acc.: 47.66%] [G loss: 1.647815]\n",
      "epoch:22 step:21269 [D loss: 0.826895, acc.: 53.12%] [G loss: 1.501588]\n",
      "epoch:22 step:21270 [D loss: 0.914927, acc.: 39.84%] [G loss: 1.498064]\n",
      "epoch:22 step:21271 [D loss: 0.700720, acc.: 60.94%] [G loss: 1.119019]\n",
      "epoch:22 step:21272 [D loss: 0.663211, acc.: 60.16%] [G loss: 1.249607]\n",
      "epoch:22 step:21273 [D loss: 0.434651, acc.: 84.38%] [G loss: 1.310706]\n",
      "epoch:22 step:21274 [D loss: 0.499645, acc.: 78.12%] [G loss: 1.357524]\n",
      "epoch:22 step:21275 [D loss: 0.581379, acc.: 72.66%] [G loss: 1.222832]\n",
      "epoch:22 step:21276 [D loss: 0.668142, acc.: 57.81%] [G loss: 0.963534]\n",
      "epoch:22 step:21277 [D loss: 0.318734, acc.: 82.03%] [G loss: 1.326175]\n",
      "epoch:22 step:21278 [D loss: 0.183368, acc.: 94.53%] [G loss: 1.687089]\n",
      "epoch:22 step:21279 [D loss: 0.143321, acc.: 98.44%] [G loss: 2.165354]\n",
      "epoch:22 step:21280 [D loss: 0.403006, acc.: 85.94%] [G loss: 1.804687]\n",
      "epoch:22 step:21281 [D loss: 0.264309, acc.: 94.53%] [G loss: 1.843918]\n",
      "epoch:22 step:21282 [D loss: 0.694120, acc.: 60.16%] [G loss: 1.664328]\n",
      "epoch:22 step:21283 [D loss: 0.525862, acc.: 74.22%] [G loss: 1.215519]\n",
      "epoch:22 step:21284 [D loss: 0.491748, acc.: 73.44%] [G loss: 1.008607]\n",
      "epoch:22 step:21285 [D loss: 0.280322, acc.: 91.41%] [G loss: 1.339422]\n",
      "epoch:22 step:21286 [D loss: 0.495894, acc.: 79.69%] [G loss: 1.571614]\n",
      "epoch:22 step:21287 [D loss: 0.456001, acc.: 81.25%] [G loss: 0.990149]\n",
      "epoch:22 step:21288 [D loss: 0.252230, acc.: 95.31%] [G loss: 1.524804]\n",
      "epoch:22 step:21289 [D loss: 0.546557, acc.: 75.78%] [G loss: 1.178568]\n",
      "epoch:22 step:21290 [D loss: 0.484698, acc.: 77.34%] [G loss: 1.102103]\n",
      "epoch:22 step:21291 [D loss: 1.062085, acc.: 34.38%] [G loss: 1.782401]\n",
      "epoch:22 step:21292 [D loss: 0.673854, acc.: 59.38%] [G loss: 0.874158]\n",
      "epoch:22 step:21293 [D loss: 0.597552, acc.: 71.09%] [G loss: 0.672268]\n",
      "epoch:22 step:21294 [D loss: 0.813180, acc.: 54.69%] [G loss: 1.002950]\n",
      "epoch:22 step:21295 [D loss: 0.919437, acc.: 39.06%] [G loss: 1.419038]\n",
      "epoch:22 step:21296 [D loss: 0.495517, acc.: 75.78%] [G loss: 1.114664]\n",
      "epoch:22 step:21297 [D loss: 0.379157, acc.: 85.16%] [G loss: 1.749380]\n",
      "epoch:22 step:21298 [D loss: 0.227180, acc.: 91.41%] [G loss: 1.486661]\n",
      "epoch:22 step:21299 [D loss: 0.457260, acc.: 79.69%] [G loss: 2.007562]\n",
      "epoch:22 step:21300 [D loss: 0.545846, acc.: 71.88%] [G loss: 0.748940]\n",
      "epoch:22 step:21301 [D loss: 0.328073, acc.: 88.28%] [G loss: 1.022973]\n",
      "epoch:22 step:21302 [D loss: 0.837811, acc.: 46.88%] [G loss: 1.083992]\n",
      "epoch:22 step:21303 [D loss: 0.931087, acc.: 40.62%] [G loss: 1.066102]\n",
      "epoch:22 step:21304 [D loss: 1.009187, acc.: 42.97%] [G loss: 1.409424]\n",
      "epoch:22 step:21305 [D loss: 1.707426, acc.: 24.22%] [G loss: 1.646894]\n",
      "epoch:22 step:21306 [D loss: 0.588192, acc.: 69.53%] [G loss: 1.423324]\n",
      "epoch:22 step:21307 [D loss: 0.564372, acc.: 68.75%] [G loss: 1.642308]\n",
      "epoch:22 step:21308 [D loss: 0.484171, acc.: 80.47%] [G loss: 1.633839]\n",
      "epoch:22 step:21309 [D loss: 0.875021, acc.: 46.09%] [G loss: 1.813774]\n",
      "epoch:22 step:21310 [D loss: 0.213844, acc.: 98.44%] [G loss: 1.517255]\n",
      "epoch:22 step:21311 [D loss: 0.161641, acc.: 94.53%] [G loss: 1.472245]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:22 step:21312 [D loss: 0.322529, acc.: 94.53%] [G loss: 1.619791]\n",
      "epoch:22 step:21313 [D loss: 0.423097, acc.: 85.16%] [G loss: 1.476520]\n",
      "epoch:22 step:21314 [D loss: 0.215370, acc.: 92.19%] [G loss: 1.512123]\n",
      "epoch:22 step:21315 [D loss: 0.137131, acc.: 98.44%] [G loss: 1.809241]\n",
      "epoch:22 step:21316 [D loss: 0.331427, acc.: 95.31%] [G loss: 1.846617]\n",
      "epoch:22 step:21317 [D loss: 0.789230, acc.: 55.47%] [G loss: 1.440491]\n",
      "epoch:22 step:21318 [D loss: 0.524146, acc.: 71.09%] [G loss: 1.449267]\n",
      "epoch:22 step:21319 [D loss: 0.759931, acc.: 48.44%] [G loss: 1.198412]\n",
      "epoch:22 step:21320 [D loss: 0.405188, acc.: 80.47%] [G loss: 1.285097]\n",
      "epoch:22 step:21321 [D loss: 0.212602, acc.: 93.75%] [G loss: 1.540234]\n",
      "epoch:22 step:21322 [D loss: 0.199347, acc.: 97.66%] [G loss: 1.988896]\n",
      "epoch:22 step:21323 [D loss: 0.157373, acc.: 97.66%] [G loss: 1.660208]\n",
      "epoch:22 step:21324 [D loss: 0.830514, acc.: 43.75%] [G loss: 2.121909]\n",
      "epoch:22 step:21325 [D loss: 0.463089, acc.: 78.91%] [G loss: 1.939725]\n",
      "epoch:22 step:21326 [D loss: 0.731239, acc.: 57.81%] [G loss: 1.701293]\n",
      "epoch:22 step:21327 [D loss: 0.118755, acc.: 99.22%] [G loss: 1.698684]\n",
      "epoch:22 step:21328 [D loss: 0.135930, acc.: 99.22%] [G loss: 1.793384]\n",
      "epoch:22 step:21329 [D loss: 0.932898, acc.: 46.88%] [G loss: 1.456224]\n",
      "epoch:22 step:21330 [D loss: 0.670605, acc.: 62.50%] [G loss: 1.517698]\n",
      "epoch:22 step:21331 [D loss: 0.696075, acc.: 63.28%] [G loss: 1.281611]\n",
      "epoch:22 step:21332 [D loss: 0.485974, acc.: 79.69%] [G loss: 1.470191]\n",
      "epoch:22 step:21333 [D loss: 0.386960, acc.: 89.06%] [G loss: 1.023545]\n",
      "epoch:22 step:21334 [D loss: 0.427289, acc.: 83.59%] [G loss: 1.452709]\n",
      "epoch:22 step:21335 [D loss: 0.556466, acc.: 72.66%] [G loss: 1.336805]\n",
      "epoch:22 step:21336 [D loss: 0.772025, acc.: 52.34%] [G loss: 1.274906]\n",
      "epoch:22 step:21337 [D loss: 0.619162, acc.: 61.72%] [G loss: 1.345713]\n",
      "epoch:22 step:21338 [D loss: 0.416063, acc.: 82.81%] [G loss: 0.948598]\n",
      "epoch:22 step:21339 [D loss: 0.622636, acc.: 67.19%] [G loss: 1.404476]\n",
      "epoch:22 step:21340 [D loss: 0.336408, acc.: 92.97%] [G loss: 1.480642]\n",
      "epoch:22 step:21341 [D loss: 0.455962, acc.: 81.25%] [G loss: 0.523371]\n",
      "epoch:22 step:21342 [D loss: 0.165721, acc.: 96.88%] [G loss: 1.549919]\n",
      "epoch:22 step:21343 [D loss: 0.648239, acc.: 64.06%] [G loss: 1.288853]\n",
      "epoch:22 step:21344 [D loss: 0.173982, acc.: 95.31%] [G loss: 1.127338]\n",
      "epoch:22 step:21345 [D loss: 0.227393, acc.: 94.53%] [G loss: 1.875543]\n",
      "epoch:22 step:21346 [D loss: 1.050266, acc.: 53.12%] [G loss: 2.287043]\n",
      "epoch:22 step:21347 [D loss: 0.226648, acc.: 92.19%] [G loss: 2.308513]\n",
      "epoch:22 step:21348 [D loss: 0.971424, acc.: 54.69%] [G loss: 2.149205]\n",
      "epoch:22 step:21349 [D loss: 0.768842, acc.: 57.03%] [G loss: 1.523903]\n",
      "epoch:22 step:21350 [D loss: 0.836917, acc.: 46.88%] [G loss: 1.628149]\n",
      "epoch:22 step:21351 [D loss: 0.713433, acc.: 61.72%] [G loss: 1.514860]\n",
      "epoch:22 step:21352 [D loss: 0.749446, acc.: 56.25%] [G loss: 1.269075]\n",
      "epoch:22 step:21353 [D loss: 0.385588, acc.: 79.69%] [G loss: 1.353229]\n",
      "epoch:22 step:21354 [D loss: 0.296762, acc.: 96.09%] [G loss: 1.290530]\n",
      "epoch:22 step:21355 [D loss: 0.517041, acc.: 76.56%] [G loss: 1.222058]\n",
      "epoch:22 step:21356 [D loss: 0.317542, acc.: 96.09%] [G loss: 1.132060]\n",
      "epoch:22 step:21357 [D loss: 0.211672, acc.: 98.44%] [G loss: 1.623436]\n",
      "epoch:22 step:21358 [D loss: 0.626752, acc.: 64.84%] [G loss: 1.313521]\n",
      "epoch:22 step:21359 [D loss: 0.551422, acc.: 71.09%] [G loss: 1.399490]\n",
      "epoch:22 step:21360 [D loss: 0.297711, acc.: 94.53%] [G loss: 1.434370]\n",
      "epoch:22 step:21361 [D loss: 0.518485, acc.: 75.78%] [G loss: 0.970838]\n",
      "epoch:22 step:21362 [D loss: 0.819687, acc.: 39.06%] [G loss: 1.081615]\n",
      "epoch:22 step:21363 [D loss: 0.325168, acc.: 93.75%] [G loss: 1.378577]\n",
      "epoch:22 step:21364 [D loss: 0.346743, acc.: 89.06%] [G loss: 1.319514]\n",
      "epoch:22 step:21365 [D loss: 0.665600, acc.: 59.38%] [G loss: 1.331500]\n",
      "epoch:22 step:21366 [D loss: 0.546537, acc.: 74.22%] [G loss: 1.164017]\n",
      "epoch:22 step:21367 [D loss: 0.641936, acc.: 64.06%] [G loss: 1.516150]\n",
      "epoch:22 step:21368 [D loss: 0.328025, acc.: 88.28%] [G loss: 1.399386]\n",
      "epoch:22 step:21369 [D loss: 0.245598, acc.: 91.41%] [G loss: 1.249408]\n",
      "epoch:22 step:21370 [D loss: 0.306226, acc.: 85.16%] [G loss: 1.208263]\n",
      "epoch:22 step:21371 [D loss: 0.323595, acc.: 92.19%] [G loss: 1.732720]\n",
      "epoch:22 step:21372 [D loss: 0.582478, acc.: 67.19%] [G loss: 1.632148]\n",
      "epoch:22 step:21373 [D loss: 0.579886, acc.: 67.19%] [G loss: 1.305184]\n",
      "epoch:22 step:21374 [D loss: 0.887108, acc.: 42.19%] [G loss: 1.515941]\n",
      "epoch:22 step:21375 [D loss: 0.751497, acc.: 55.47%] [G loss: 1.126405]\n",
      "epoch:22 step:21376 [D loss: 0.374025, acc.: 88.28%] [G loss: 1.508100]\n",
      "epoch:22 step:21377 [D loss: 0.454860, acc.: 81.25%] [G loss: 1.131012]\n",
      "epoch:22 step:21378 [D loss: 0.244201, acc.: 87.50%] [G loss: 1.215889]\n",
      "epoch:22 step:21379 [D loss: 0.503710, acc.: 75.00%] [G loss: 1.258567]\n",
      "epoch:22 step:21380 [D loss: 0.590432, acc.: 71.88%] [G loss: 0.541692]\n",
      "epoch:22 step:21381 [D loss: 0.397659, acc.: 86.72%] [G loss: 1.314036]\n",
      "epoch:22 step:21382 [D loss: 0.233922, acc.: 92.97%] [G loss: 1.414542]\n",
      "epoch:22 step:21383 [D loss: 0.386972, acc.: 75.78%] [G loss: 1.805409]\n",
      "epoch:22 step:21384 [D loss: 0.728132, acc.: 51.56%] [G loss: 1.504031]\n",
      "epoch:22 step:21385 [D loss: 0.824382, acc.: 46.09%] [G loss: 1.371396]\n",
      "epoch:22 step:21386 [D loss: 0.938406, acc.: 39.84%] [G loss: 1.469653]\n",
      "epoch:22 step:21387 [D loss: 0.684328, acc.: 57.81%] [G loss: 1.081270]\n",
      "epoch:22 step:21388 [D loss: 0.204219, acc.: 92.97%] [G loss: 1.444694]\n",
      "epoch:22 step:21389 [D loss: 0.232833, acc.: 94.53%] [G loss: 1.517845]\n",
      "epoch:22 step:21390 [D loss: 0.621940, acc.: 67.19%] [G loss: 1.164912]\n",
      "epoch:22 step:21391 [D loss: 0.473350, acc.: 78.91%] [G loss: 1.496612]\n",
      "epoch:22 step:21392 [D loss: 0.679781, acc.: 62.50%] [G loss: 1.411498]\n",
      "epoch:22 step:21393 [D loss: 0.674119, acc.: 62.50%] [G loss: 1.182572]\n",
      "epoch:22 step:21394 [D loss: 0.266009, acc.: 90.62%] [G loss: 1.178019]\n",
      "epoch:22 step:21395 [D loss: 0.183921, acc.: 94.53%] [G loss: 1.094092]\n",
      "epoch:22 step:21396 [D loss: 0.347353, acc.: 84.38%] [G loss: 1.145134]\n",
      "epoch:22 step:21397 [D loss: 0.621880, acc.: 65.62%] [G loss: 1.341707]\n",
      "epoch:22 step:21398 [D loss: 0.697278, acc.: 57.81%] [G loss: 1.580213]\n",
      "epoch:22 step:21399 [D loss: 0.881730, acc.: 41.41%] [G loss: 1.635649]\n",
      "epoch:22 step:21400 [D loss: 0.207014, acc.: 95.31%] [G loss: 1.579641]\n",
      "##############\n",
      "[3.62265765 2.83794313 6.83846368 5.67337006 4.42690215 5.97024244\n",
      " 5.51763466 5.65127464 6.20774681 4.97310408]\n",
      "##########\n",
      "epoch:22 step:21401 [D loss: 0.766560, acc.: 52.34%] [G loss: 1.521759]\n",
      "epoch:22 step:21402 [D loss: 0.588372, acc.: 67.19%] [G loss: 1.415257]\n",
      "epoch:22 step:21403 [D loss: 0.750563, acc.: 57.03%] [G loss: 0.998856]\n",
      "epoch:22 step:21404 [D loss: 0.652358, acc.: 67.19%] [G loss: 1.027995]\n",
      "epoch:22 step:21405 [D loss: 0.194553, acc.: 95.31%] [G loss: 1.273263]\n",
      "epoch:22 step:21406 [D loss: 0.211776, acc.: 92.97%] [G loss: 0.892517]\n",
      "epoch:22 step:21407 [D loss: 0.162293, acc.: 97.66%] [G loss: 1.688234]\n",
      "epoch:22 step:21408 [D loss: 0.172720, acc.: 97.66%] [G loss: 2.268229]\n",
      "epoch:22 step:21409 [D loss: 0.288275, acc.: 95.31%] [G loss: 1.621480]\n",
      "epoch:22 step:21410 [D loss: 0.127033, acc.: 100.00%] [G loss: 1.839452]\n",
      "epoch:22 step:21411 [D loss: 0.641070, acc.: 63.28%] [G loss: 1.352799]\n",
      "epoch:22 step:21412 [D loss: 0.494648, acc.: 77.34%] [G loss: 1.590129]\n",
      "epoch:22 step:21413 [D loss: 1.556636, acc.: 25.78%] [G loss: 1.494889]\n",
      "epoch:22 step:21414 [D loss: 0.400680, acc.: 85.94%] [G loss: 1.584615]\n",
      "epoch:22 step:21415 [D loss: 0.336408, acc.: 91.41%] [G loss: 1.774423]\n",
      "epoch:22 step:21416 [D loss: 0.611634, acc.: 59.38%] [G loss: 1.754809]\n",
      "epoch:22 step:21417 [D loss: 0.591538, acc.: 66.41%] [G loss: 1.645716]\n",
      "epoch:22 step:21418 [D loss: 0.176426, acc.: 96.09%] [G loss: 1.857725]\n",
      "epoch:22 step:21419 [D loss: 0.188723, acc.: 96.09%] [G loss: 1.741773]\n",
      "epoch:22 step:21420 [D loss: 0.159553, acc.: 100.00%] [G loss: 1.791434]\n",
      "epoch:22 step:21421 [D loss: 0.795324, acc.: 52.34%] [G loss: 1.558484]\n",
      "epoch:22 step:21422 [D loss: 0.345885, acc.: 91.41%] [G loss: 1.442299]\n",
      "epoch:22 step:21423 [D loss: 0.269689, acc.: 96.88%] [G loss: 1.701812]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:22 step:21424 [D loss: 0.375767, acc.: 89.84%] [G loss: 1.502665]\n",
      "epoch:22 step:21425 [D loss: 1.032938, acc.: 39.06%] [G loss: 1.231377]\n",
      "epoch:22 step:21426 [D loss: 0.583457, acc.: 68.75%] [G loss: 0.901062]\n",
      "epoch:22 step:21427 [D loss: 0.621423, acc.: 64.06%] [G loss: 1.283097]\n",
      "epoch:22 step:21428 [D loss: 1.049232, acc.: 21.88%] [G loss: 0.972878]\n",
      "epoch:22 step:21429 [D loss: 0.270482, acc.: 87.50%] [G loss: 1.309108]\n",
      "epoch:22 step:21430 [D loss: 0.380388, acc.: 89.06%] [G loss: 1.342757]\n",
      "epoch:22 step:21431 [D loss: 0.617265, acc.: 64.84%] [G loss: 1.308779]\n",
      "epoch:22 step:21432 [D loss: 0.666109, acc.: 58.59%] [G loss: 1.045207]\n",
      "epoch:22 step:21433 [D loss: 0.534551, acc.: 76.56%] [G loss: 1.116917]\n",
      "epoch:22 step:21434 [D loss: 0.994211, acc.: 25.00%] [G loss: 0.906432]\n",
      "epoch:22 step:21435 [D loss: 0.413576, acc.: 84.38%] [G loss: 1.272232]\n",
      "epoch:22 step:21436 [D loss: 0.647970, acc.: 63.28%] [G loss: 1.014787]\n",
      "epoch:22 step:21437 [D loss: 0.626188, acc.: 71.88%] [G loss: 1.063153]\n",
      "epoch:22 step:21438 [D loss: 0.685633, acc.: 57.81%] [G loss: 1.138847]\n",
      "epoch:22 step:21439 [D loss: 0.353089, acc.: 89.84%] [G loss: 0.886463]\n",
      "epoch:22 step:21440 [D loss: 0.683350, acc.: 65.62%] [G loss: 0.969665]\n",
      "epoch:22 step:21441 [D loss: 0.687404, acc.: 55.47%] [G loss: 0.823431]\n",
      "epoch:22 step:21442 [D loss: 0.770920, acc.: 52.34%] [G loss: 0.802723]\n",
      "epoch:22 step:21443 [D loss: 0.799568, acc.: 43.75%] [G loss: 0.843356]\n",
      "epoch:22 step:21444 [D loss: 0.409149, acc.: 87.50%] [G loss: 1.123103]\n",
      "epoch:22 step:21445 [D loss: 0.251943, acc.: 94.53%] [G loss: 1.781265]\n",
      "epoch:22 step:21446 [D loss: 0.289792, acc.: 90.62%] [G loss: 1.311485]\n",
      "epoch:22 step:21447 [D loss: 0.284351, acc.: 97.66%] [G loss: 1.810090]\n",
      "epoch:22 step:21448 [D loss: 0.420798, acc.: 85.94%] [G loss: 1.407884]\n",
      "epoch:22 step:21449 [D loss: 0.685808, acc.: 50.78%] [G loss: 1.641645]\n",
      "epoch:22 step:21450 [D loss: 0.715792, acc.: 53.91%] [G loss: 1.499556]\n",
      "epoch:22 step:21451 [D loss: 0.755322, acc.: 50.78%] [G loss: 0.692577]\n",
      "epoch:22 step:21452 [D loss: 0.669186, acc.: 62.50%] [G loss: 0.906123]\n",
      "epoch:22 step:21453 [D loss: 0.530675, acc.: 78.12%] [G loss: 1.355062]\n",
      "epoch:22 step:21454 [D loss: 0.704838, acc.: 56.25%] [G loss: 1.125168]\n",
      "epoch:22 step:21455 [D loss: 0.398243, acc.: 82.03%] [G loss: 1.316847]\n",
      "epoch:22 step:21456 [D loss: 0.363901, acc.: 85.94%] [G loss: 1.301971]\n",
      "epoch:22 step:21457 [D loss: 0.548297, acc.: 74.22%] [G loss: 1.313900]\n",
      "epoch:22 step:21458 [D loss: 0.691077, acc.: 60.16%] [G loss: 1.270432]\n",
      "epoch:22 step:21459 [D loss: 0.233430, acc.: 96.09%] [G loss: 1.297286]\n",
      "epoch:22 step:21460 [D loss: 0.831019, acc.: 40.62%] [G loss: 1.502358]\n",
      "epoch:22 step:21461 [D loss: 0.254347, acc.: 96.88%] [G loss: 1.585049]\n",
      "epoch:22 step:21462 [D loss: 0.225610, acc.: 98.44%] [G loss: 1.494748]\n",
      "epoch:22 step:21463 [D loss: 0.496887, acc.: 76.56%] [G loss: 1.421133]\n",
      "epoch:22 step:21464 [D loss: 0.140620, acc.: 98.44%] [G loss: 1.694429]\n",
      "epoch:22 step:21465 [D loss: 0.126373, acc.: 99.22%] [G loss: 1.767441]\n",
      "epoch:22 step:21466 [D loss: 0.113007, acc.: 99.22%] [G loss: 1.803981]\n",
      "epoch:22 step:21467 [D loss: 0.187731, acc.: 100.00%] [G loss: 1.417836]\n",
      "epoch:22 step:21468 [D loss: 0.102808, acc.: 100.00%] [G loss: 1.586957]\n",
      "epoch:22 step:21469 [D loss: 0.404923, acc.: 85.16%] [G loss: 1.275067]\n",
      "epoch:22 step:21470 [D loss: 0.683335, acc.: 59.38%] [G loss: 1.922597]\n",
      "epoch:22 step:21471 [D loss: 0.310331, acc.: 83.59%] [G loss: 1.816394]\n",
      "epoch:22 step:21472 [D loss: 0.202323, acc.: 98.44%] [G loss: 2.147816]\n",
      "epoch:22 step:21473 [D loss: 0.518798, acc.: 69.53%] [G loss: 1.421613]\n",
      "epoch:22 step:21474 [D loss: 0.466361, acc.: 78.91%] [G loss: 1.872478]\n",
      "epoch:22 step:21475 [D loss: 0.657431, acc.: 57.81%] [G loss: 1.905186]\n",
      "epoch:22 step:21476 [D loss: 0.845610, acc.: 53.12%] [G loss: 1.653257]\n",
      "epoch:22 step:21477 [D loss: 0.732872, acc.: 62.50%] [G loss: 1.564719]\n",
      "epoch:22 step:21478 [D loss: 0.860756, acc.: 42.19%] [G loss: 0.810417]\n",
      "epoch:22 step:21479 [D loss: 0.611466, acc.: 66.41%] [G loss: 1.177526]\n",
      "epoch:22 step:21480 [D loss: 0.799247, acc.: 46.88%] [G loss: 0.975990]\n",
      "epoch:22 step:21481 [D loss: 0.662454, acc.: 64.06%] [G loss: 1.252833]\n",
      "epoch:22 step:21482 [D loss: 0.915667, acc.: 41.41%] [G loss: 1.445621]\n",
      "epoch:22 step:21483 [D loss: 0.899339, acc.: 41.41%] [G loss: 1.702393]\n",
      "epoch:22 step:21484 [D loss: 0.464855, acc.: 75.00%] [G loss: 1.753240]\n",
      "epoch:22 step:21485 [D loss: 0.430650, acc.: 82.81%] [G loss: 1.596381]\n",
      "epoch:22 step:21486 [D loss: 0.706591, acc.: 55.47%] [G loss: 1.403352]\n",
      "epoch:22 step:21487 [D loss: 0.572840, acc.: 74.22%] [G loss: 1.440455]\n",
      "epoch:22 step:21488 [D loss: 0.393804, acc.: 85.94%] [G loss: 1.339638]\n",
      "epoch:22 step:21489 [D loss: 0.733359, acc.: 54.69%] [G loss: 1.176224]\n",
      "epoch:22 step:21490 [D loss: 0.491958, acc.: 73.44%] [G loss: 1.013158]\n",
      "epoch:22 step:21491 [D loss: 0.218058, acc.: 96.09%] [G loss: 1.150193]\n",
      "epoch:22 step:21492 [D loss: 0.230210, acc.: 89.84%] [G loss: 1.866540]\n",
      "epoch:22 step:21493 [D loss: 0.610922, acc.: 65.62%] [G loss: 2.054653]\n",
      "epoch:22 step:21494 [D loss: 0.949240, acc.: 39.84%] [G loss: 0.498946]\n",
      "epoch:22 step:21495 [D loss: 0.747393, acc.: 54.69%] [G loss: 0.910390]\n",
      "epoch:22 step:21496 [D loss: 0.916232, acc.: 44.53%] [G loss: 0.928579]\n",
      "epoch:22 step:21497 [D loss: 0.614494, acc.: 68.75%] [G loss: 0.954648]\n",
      "epoch:22 step:21498 [D loss: 0.444207, acc.: 72.66%] [G loss: 0.956094]\n",
      "epoch:22 step:21499 [D loss: 0.413607, acc.: 75.78%] [G loss: 1.230138]\n",
      "epoch:22 step:21500 [D loss: 0.229678, acc.: 94.53%] [G loss: 1.339428]\n",
      "epoch:22 step:21501 [D loss: 0.544916, acc.: 66.41%] [G loss: 0.840820]\n",
      "epoch:22 step:21502 [D loss: 0.845782, acc.: 51.56%] [G loss: 1.175596]\n",
      "epoch:22 step:21503 [D loss: 0.410104, acc.: 81.25%] [G loss: 1.391812]\n",
      "epoch:22 step:21504 [D loss: 0.317862, acc.: 91.41%] [G loss: 1.764470]\n",
      "epoch:22 step:21505 [D loss: 0.759385, acc.: 53.91%] [G loss: 1.460290]\n",
      "epoch:22 step:21506 [D loss: 0.960260, acc.: 49.22%] [G loss: 1.530107]\n",
      "epoch:22 step:21507 [D loss: 0.726588, acc.: 55.47%] [G loss: 1.262453]\n",
      "epoch:22 step:21508 [D loss: 0.587893, acc.: 65.62%] [G loss: 0.970071]\n",
      "epoch:22 step:21509 [D loss: 0.693492, acc.: 57.03%] [G loss: 1.109202]\n",
      "epoch:22 step:21510 [D loss: 0.721424, acc.: 53.12%] [G loss: 1.030786]\n",
      "epoch:22 step:21511 [D loss: 0.769798, acc.: 46.09%] [G loss: 0.947211]\n",
      "epoch:22 step:21512 [D loss: 0.390094, acc.: 89.84%] [G loss: 1.003577]\n",
      "epoch:22 step:21513 [D loss: 0.294158, acc.: 89.84%] [G loss: 1.218597]\n",
      "epoch:22 step:21514 [D loss: 0.411255, acc.: 86.72%] [G loss: 1.086552]\n",
      "epoch:22 step:21515 [D loss: 0.706210, acc.: 57.81%] [G loss: 1.475715]\n",
      "epoch:22 step:21516 [D loss: 0.634679, acc.: 65.62%] [G loss: 1.241236]\n",
      "epoch:22 step:21517 [D loss: 0.760548, acc.: 53.12%] [G loss: 1.296339]\n",
      "epoch:22 step:21518 [D loss: 0.344279, acc.: 76.56%] [G loss: 1.166430]\n",
      "epoch:22 step:21519 [D loss: 0.158974, acc.: 99.22%] [G loss: 1.472485]\n",
      "epoch:22 step:21520 [D loss: 0.171228, acc.: 97.66%] [G loss: 1.576059]\n",
      "epoch:22 step:21521 [D loss: 0.537507, acc.: 74.22%] [G loss: 1.480309]\n",
      "epoch:22 step:21522 [D loss: 0.640027, acc.: 61.72%] [G loss: 1.419327]\n",
      "epoch:22 step:21523 [D loss: 0.796103, acc.: 50.00%] [G loss: 1.396307]\n",
      "epoch:22 step:21524 [D loss: 0.308137, acc.: 85.16%] [G loss: 0.963587]\n",
      "epoch:22 step:21525 [D loss: 0.811406, acc.: 49.22%] [G loss: 1.228082]\n",
      "epoch:22 step:21526 [D loss: 0.215509, acc.: 94.53%] [G loss: 1.201909]\n",
      "epoch:22 step:21527 [D loss: 0.680672, acc.: 54.69%] [G loss: 1.290456]\n",
      "epoch:22 step:21528 [D loss: 0.500085, acc.: 80.47%] [G loss: 1.176104]\n",
      "epoch:22 step:21529 [D loss: 0.616855, acc.: 65.62%] [G loss: 1.305674]\n",
      "epoch:22 step:21530 [D loss: 0.203257, acc.: 95.31%] [G loss: 1.578274]\n",
      "epoch:22 step:21531 [D loss: 0.188842, acc.: 98.44%] [G loss: 1.594495]\n",
      "epoch:22 step:21532 [D loss: 0.537023, acc.: 71.88%] [G loss: 1.113929]\n",
      "epoch:22 step:21533 [D loss: 0.576645, acc.: 69.53%] [G loss: 1.148322]\n",
      "epoch:22 step:21534 [D loss: 0.220558, acc.: 96.09%] [G loss: 1.306768]\n",
      "epoch:22 step:21535 [D loss: 0.194434, acc.: 96.09%] [G loss: 1.888234]\n",
      "epoch:22 step:21536 [D loss: 0.807808, acc.: 46.09%] [G loss: 1.511877]\n",
      "epoch:22 step:21537 [D loss: 0.610667, acc.: 60.94%] [G loss: 1.419142]\n",
      "epoch:22 step:21538 [D loss: 0.464216, acc.: 79.69%] [G loss: 1.274543]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:22 step:21539 [D loss: 0.559572, acc.: 71.09%] [G loss: 1.554190]\n",
      "epoch:22 step:21540 [D loss: 0.556368, acc.: 76.56%] [G loss: 1.226759]\n",
      "epoch:22 step:21541 [D loss: 0.454567, acc.: 83.59%] [G loss: 1.649434]\n",
      "epoch:22 step:21542 [D loss: 0.498583, acc.: 73.44%] [G loss: 1.258209]\n",
      "epoch:22 step:21543 [D loss: 0.240590, acc.: 90.62%] [G loss: 1.547107]\n",
      "epoch:22 step:21544 [D loss: 0.404230, acc.: 86.72%] [G loss: 1.550751]\n",
      "epoch:22 step:21545 [D loss: 0.556995, acc.: 75.00%] [G loss: 1.416519]\n",
      "epoch:22 step:21546 [D loss: 0.564832, acc.: 68.75%] [G loss: 1.296184]\n",
      "epoch:22 step:21547 [D loss: 0.471821, acc.: 78.12%] [G loss: 1.264159]\n",
      "epoch:22 step:21548 [D loss: 0.440907, acc.: 80.47%] [G loss: 1.259580]\n",
      "epoch:22 step:21549 [D loss: 0.426633, acc.: 85.16%] [G loss: 1.343778]\n",
      "epoch:22 step:21550 [D loss: 0.210182, acc.: 93.75%] [G loss: 0.768909]\n",
      "epoch:22 step:21551 [D loss: 0.143435, acc.: 98.44%] [G loss: 1.803899]\n",
      "epoch:23 step:21552 [D loss: 0.720535, acc.: 53.91%] [G loss: 1.226227]\n",
      "epoch:23 step:21553 [D loss: 0.859654, acc.: 51.56%] [G loss: 1.494739]\n",
      "epoch:23 step:21554 [D loss: 0.584921, acc.: 64.06%] [G loss: 1.287072]\n",
      "epoch:23 step:21555 [D loss: 1.234371, acc.: 21.88%] [G loss: 1.502441]\n",
      "epoch:23 step:21556 [D loss: 0.628734, acc.: 64.06%] [G loss: 0.683560]\n",
      "epoch:23 step:21557 [D loss: 0.782447, acc.: 49.22%] [G loss: 0.728327]\n",
      "epoch:23 step:21558 [D loss: 0.367234, acc.: 91.41%] [G loss: 1.338946]\n",
      "epoch:23 step:21559 [D loss: 0.546599, acc.: 75.00%] [G loss: 1.193906]\n",
      "epoch:23 step:21560 [D loss: 0.371318, acc.: 89.84%] [G loss: 1.331558]\n",
      "epoch:23 step:21561 [D loss: 0.456892, acc.: 66.41%] [G loss: 0.385253]\n",
      "epoch:23 step:21562 [D loss: 0.780702, acc.: 57.03%] [G loss: 1.485616]\n",
      "epoch:23 step:21563 [D loss: 0.315796, acc.: 91.41%] [G loss: 1.623804]\n",
      "epoch:23 step:21564 [D loss: 0.495243, acc.: 80.47%] [G loss: 1.270823]\n",
      "epoch:23 step:21565 [D loss: 0.425518, acc.: 87.50%] [G loss: 1.170492]\n",
      "epoch:23 step:21566 [D loss: 0.604196, acc.: 61.72%] [G loss: 1.018113]\n",
      "epoch:23 step:21567 [D loss: 0.858340, acc.: 46.09%] [G loss: 0.581247]\n",
      "epoch:23 step:21568 [D loss: 1.132538, acc.: 17.19%] [G loss: 1.898208]\n",
      "epoch:23 step:21569 [D loss: 0.577812, acc.: 71.09%] [G loss: 0.575658]\n",
      "epoch:23 step:21570 [D loss: 1.298016, acc.: 21.09%] [G loss: 0.684860]\n",
      "epoch:23 step:21571 [D loss: 0.636362, acc.: 63.28%] [G loss: 1.730063]\n",
      "epoch:23 step:21572 [D loss: 0.902527, acc.: 45.31%] [G loss: 1.957512]\n",
      "epoch:23 step:21573 [D loss: 0.954072, acc.: 35.16%] [G loss: 1.163303]\n",
      "epoch:23 step:21574 [D loss: 0.778613, acc.: 52.34%] [G loss: 1.247778]\n",
      "epoch:23 step:21575 [D loss: 0.789888, acc.: 51.56%] [G loss: 1.049798]\n",
      "epoch:23 step:21576 [D loss: 0.587543, acc.: 69.53%] [G loss: 1.354528]\n",
      "epoch:23 step:21577 [D loss: 0.746419, acc.: 50.00%] [G loss: 1.210836]\n",
      "epoch:23 step:21578 [D loss: 0.269161, acc.: 89.84%] [G loss: 1.369496]\n",
      "epoch:23 step:21579 [D loss: 0.423826, acc.: 92.19%] [G loss: 1.330469]\n",
      "epoch:23 step:21580 [D loss: 0.396138, acc.: 85.94%] [G loss: 1.198616]\n",
      "epoch:23 step:21581 [D loss: 0.479449, acc.: 78.12%] [G loss: 1.494541]\n",
      "epoch:23 step:21582 [D loss: 0.344863, acc.: 85.16%] [G loss: 1.738205]\n",
      "epoch:23 step:21583 [D loss: 0.143121, acc.: 99.22%] [G loss: 1.857434]\n",
      "epoch:23 step:21584 [D loss: 0.132598, acc.: 100.00%] [G loss: 1.928779]\n",
      "epoch:23 step:21585 [D loss: 0.158392, acc.: 96.88%] [G loss: 2.429423]\n",
      "epoch:23 step:21586 [D loss: 0.083293, acc.: 99.22%] [G loss: 2.176494]\n",
      "epoch:23 step:21587 [D loss: 0.094478, acc.: 100.00%] [G loss: 2.654812]\n",
      "epoch:23 step:21588 [D loss: 1.009091, acc.: 50.00%] [G loss: 1.620449]\n",
      "epoch:23 step:21589 [D loss: 0.857510, acc.: 48.44%] [G loss: 1.511055]\n",
      "epoch:23 step:21590 [D loss: 0.953504, acc.: 39.84%] [G loss: 1.237384]\n",
      "epoch:23 step:21591 [D loss: 0.741581, acc.: 50.00%] [G loss: 0.999300]\n",
      "epoch:23 step:21592 [D loss: 0.471508, acc.: 80.47%] [G loss: 1.053614]\n",
      "epoch:23 step:21593 [D loss: 0.421064, acc.: 82.03%] [G loss: 1.136624]\n",
      "epoch:23 step:21594 [D loss: 0.285886, acc.: 92.97%] [G loss: 1.263556]\n",
      "epoch:23 step:21595 [D loss: 0.359968, acc.: 91.41%] [G loss: 1.247993]\n",
      "epoch:23 step:21596 [D loss: 0.415864, acc.: 88.28%] [G loss: 1.281587]\n",
      "epoch:23 step:21597 [D loss: 0.371287, acc.: 84.38%] [G loss: 1.074990]\n",
      "epoch:23 step:21598 [D loss: 0.515967, acc.: 81.25%] [G loss: 1.105014]\n",
      "epoch:23 step:21599 [D loss: 0.604784, acc.: 66.41%] [G loss: 1.310908]\n",
      "epoch:23 step:21600 [D loss: 0.602488, acc.: 67.97%] [G loss: 0.887323]\n",
      "##############\n",
      "[4.12802451 2.56594871 6.92486388 5.97058902 4.85127771 6.22562538\n",
      " 5.52939352 5.8145173  6.04662937 4.93523917]\n",
      "##########\n",
      "epoch:23 step:21601 [D loss: 0.381402, acc.: 89.84%] [G loss: 1.029937]\n",
      "epoch:23 step:21602 [D loss: 0.328614, acc.: 89.84%] [G loss: 1.329211]\n",
      "epoch:23 step:21603 [D loss: 0.559945, acc.: 64.06%] [G loss: 2.022389]\n",
      "epoch:23 step:21604 [D loss: 0.434405, acc.: 84.38%] [G loss: 1.507200]\n",
      "epoch:23 step:21605 [D loss: 0.690117, acc.: 55.47%] [G loss: 1.920236]\n",
      "epoch:23 step:21606 [D loss: 0.576664, acc.: 72.66%] [G loss: 1.072931]\n",
      "epoch:23 step:21607 [D loss: 0.604997, acc.: 64.06%] [G loss: 0.980972]\n",
      "epoch:23 step:21608 [D loss: 1.063527, acc.: 53.12%] [G loss: 1.530532]\n",
      "epoch:23 step:21609 [D loss: 0.185933, acc.: 97.66%] [G loss: 1.651274]\n",
      "epoch:23 step:21610 [D loss: 0.429057, acc.: 84.38%] [G loss: 0.505221]\n",
      "epoch:23 step:21611 [D loss: 0.184604, acc.: 97.66%] [G loss: 2.143941]\n",
      "epoch:23 step:21612 [D loss: 0.709345, acc.: 50.78%] [G loss: 1.785073]\n",
      "epoch:23 step:21613 [D loss: 0.880347, acc.: 41.41%] [G loss: 0.908326]\n",
      "epoch:23 step:21614 [D loss: 0.492278, acc.: 80.47%] [G loss: 1.640982]\n",
      "epoch:23 step:21615 [D loss: 0.756913, acc.: 50.78%] [G loss: 0.852233]\n",
      "epoch:23 step:21616 [D loss: 0.853858, acc.: 42.97%] [G loss: 1.145426]\n",
      "epoch:23 step:21617 [D loss: 0.680778, acc.: 65.62%] [G loss: 0.945290]\n",
      "epoch:23 step:21618 [D loss: 0.789424, acc.: 45.31%] [G loss: 0.819853]\n",
      "epoch:23 step:21619 [D loss: 0.940785, acc.: 32.81%] [G loss: 1.064233]\n",
      "epoch:23 step:21620 [D loss: 0.797513, acc.: 52.34%] [G loss: 0.993642]\n",
      "epoch:23 step:21621 [D loss: 0.640536, acc.: 63.28%] [G loss: 1.105938]\n",
      "epoch:23 step:21622 [D loss: 0.292123, acc.: 87.50%] [G loss: 1.375800]\n",
      "epoch:23 step:21623 [D loss: 0.384559, acc.: 86.72%] [G loss: 1.642663]\n",
      "epoch:23 step:21624 [D loss: 0.582578, acc.: 73.44%] [G loss: 1.351736]\n",
      "epoch:23 step:21625 [D loss: 0.464443, acc.: 81.25%] [G loss: 1.547766]\n",
      "epoch:23 step:21626 [D loss: 0.488451, acc.: 73.44%] [G loss: 1.818298]\n",
      "epoch:23 step:21627 [D loss: 0.170227, acc.: 98.44%] [G loss: 1.830154]\n",
      "epoch:23 step:21628 [D loss: 0.211822, acc.: 95.31%] [G loss: 1.938090]\n",
      "epoch:23 step:21629 [D loss: 1.193006, acc.: 47.66%] [G loss: 0.808385]\n",
      "epoch:23 step:21630 [D loss: 0.748523, acc.: 55.47%] [G loss: 0.364909]\n",
      "epoch:23 step:21631 [D loss: 0.987639, acc.: 34.38%] [G loss: 0.931580]\n",
      "epoch:23 step:21632 [D loss: 0.714275, acc.: 53.12%] [G loss: 1.421827]\n",
      "epoch:23 step:21633 [D loss: 0.731300, acc.: 51.56%] [G loss: 1.738005]\n",
      "epoch:23 step:21634 [D loss: 0.556894, acc.: 75.78%] [G loss: 1.517442]\n",
      "epoch:23 step:21635 [D loss: 0.557559, acc.: 72.66%] [G loss: 1.268547]\n",
      "epoch:23 step:21636 [D loss: 0.692301, acc.: 56.25%] [G loss: 1.250183]\n",
      "epoch:23 step:21637 [D loss: 0.722836, acc.: 61.72%] [G loss: 1.206751]\n",
      "epoch:23 step:21638 [D loss: 0.511609, acc.: 78.12%] [G loss: 1.215735]\n",
      "epoch:23 step:21639 [D loss: 0.495798, acc.: 79.69%] [G loss: 1.343916]\n",
      "epoch:23 step:21640 [D loss: 0.565209, acc.: 73.44%] [G loss: 1.028491]\n",
      "epoch:23 step:21641 [D loss: 0.684387, acc.: 64.84%] [G loss: 1.272653]\n",
      "epoch:23 step:21642 [D loss: 0.496641, acc.: 77.34%] [G loss: 1.453238]\n",
      "epoch:23 step:21643 [D loss: 0.325458, acc.: 92.19%] [G loss: 1.421377]\n",
      "epoch:23 step:21644 [D loss: 0.290238, acc.: 91.41%] [G loss: 1.588995]\n",
      "epoch:23 step:21645 [D loss: 0.484923, acc.: 77.34%] [G loss: 1.479846]\n",
      "epoch:23 step:21646 [D loss: 0.583991, acc.: 68.75%] [G loss: 1.260676]\n",
      "epoch:23 step:21647 [D loss: 0.564940, acc.: 67.97%] [G loss: 1.090030]\n",
      "epoch:23 step:21648 [D loss: 0.766408, acc.: 60.94%] [G loss: 1.196464]\n",
      "epoch:23 step:21649 [D loss: 0.635374, acc.: 64.84%] [G loss: 1.630018]\n",
      "epoch:23 step:21650 [D loss: 0.529009, acc.: 72.66%] [G loss: 1.417962]\n",
      "epoch:23 step:21651 [D loss: 0.596295, acc.: 67.97%] [G loss: 1.181117]\n",
      "epoch:23 step:21652 [D loss: 0.665341, acc.: 67.97%] [G loss: 1.268274]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:23 step:21653 [D loss: 0.673398, acc.: 61.72%] [G loss: 0.991349]\n",
      "epoch:23 step:21654 [D loss: 0.545548, acc.: 72.66%] [G loss: 1.177462]\n",
      "epoch:23 step:21655 [D loss: 0.638073, acc.: 62.50%] [G loss: 0.877429]\n",
      "epoch:23 step:21656 [D loss: 0.603923, acc.: 60.94%] [G loss: 0.865257]\n",
      "epoch:23 step:21657 [D loss: 0.680421, acc.: 67.19%] [G loss: 1.165188]\n",
      "epoch:23 step:21658 [D loss: 0.492197, acc.: 75.00%] [G loss: 1.342111]\n",
      "epoch:23 step:21659 [D loss: 0.541915, acc.: 71.88%] [G loss: 1.313901]\n",
      "epoch:23 step:21660 [D loss: 0.606649, acc.: 63.28%] [G loss: 0.804735]\n",
      "epoch:23 step:21661 [D loss: 0.581965, acc.: 70.31%] [G loss: 0.925825]\n",
      "epoch:23 step:21662 [D loss: 0.477130, acc.: 79.69%] [G loss: 0.983299]\n",
      "epoch:23 step:21663 [D loss: 0.538766, acc.: 71.09%] [G loss: 0.823316]\n",
      "epoch:23 step:21664 [D loss: 0.465316, acc.: 80.47%] [G loss: 0.782909]\n",
      "epoch:23 step:21665 [D loss: 0.492084, acc.: 71.88%] [G loss: 1.532147]\n",
      "epoch:23 step:21666 [D loss: 0.443802, acc.: 81.25%] [G loss: 0.968479]\n",
      "epoch:23 step:21667 [D loss: 0.620447, acc.: 64.84%] [G loss: 1.052288]\n",
      "epoch:23 step:21668 [D loss: 0.577497, acc.: 67.19%] [G loss: 1.202266]\n",
      "epoch:23 step:21669 [D loss: 0.478633, acc.: 72.66%] [G loss: 1.173125]\n",
      "epoch:23 step:21670 [D loss: 0.253014, acc.: 89.84%] [G loss: 1.670596]\n",
      "epoch:23 step:21671 [D loss: 0.583976, acc.: 78.12%] [G loss: 1.384229]\n",
      "epoch:23 step:21672 [D loss: 0.296740, acc.: 92.97%] [G loss: 1.410606]\n",
      "epoch:23 step:21673 [D loss: 0.332605, acc.: 87.50%] [G loss: 1.436147]\n",
      "epoch:23 step:21674 [D loss: 0.742603, acc.: 56.25%] [G loss: 1.199637]\n",
      "epoch:23 step:21675 [D loss: 0.724184, acc.: 55.47%] [G loss: 1.269990]\n",
      "epoch:23 step:21676 [D loss: 0.978775, acc.: 34.38%] [G loss: 1.094286]\n",
      "epoch:23 step:21677 [D loss: 0.553262, acc.: 73.44%] [G loss: 1.460114]\n",
      "epoch:23 step:21678 [D loss: 0.718431, acc.: 57.03%] [G loss: 1.320743]\n",
      "epoch:23 step:21679 [D loss: 0.779780, acc.: 51.56%] [G loss: 1.063267]\n",
      "epoch:23 step:21680 [D loss: 0.316359, acc.: 95.31%] [G loss: 1.181944]\n",
      "epoch:23 step:21681 [D loss: 0.265283, acc.: 92.97%] [G loss: 0.649306]\n",
      "epoch:23 step:21682 [D loss: 0.530669, acc.: 75.00%] [G loss: 1.578957]\n",
      "epoch:23 step:21683 [D loss: 0.416421, acc.: 83.59%] [G loss: 1.060432]\n",
      "epoch:23 step:21684 [D loss: 0.596880, acc.: 67.19%] [G loss: 1.690175]\n",
      "epoch:23 step:21685 [D loss: 0.765414, acc.: 45.31%] [G loss: 1.121808]\n",
      "epoch:23 step:21686 [D loss: 0.518757, acc.: 75.00%] [G loss: 1.282029]\n",
      "epoch:23 step:21687 [D loss: 0.773519, acc.: 50.00%] [G loss: 1.162142]\n",
      "epoch:23 step:21688 [D loss: 0.815477, acc.: 46.88%] [G loss: 0.932819]\n",
      "epoch:23 step:21689 [D loss: 0.538687, acc.: 74.22%] [G loss: 1.382625]\n",
      "epoch:23 step:21690 [D loss: 0.471979, acc.: 80.47%] [G loss: 1.087748]\n",
      "epoch:23 step:21691 [D loss: 0.577534, acc.: 67.97%] [G loss: 1.009100]\n",
      "epoch:23 step:21692 [D loss: 0.509557, acc.: 74.22%] [G loss: 1.041485]\n",
      "epoch:23 step:21693 [D loss: 0.784173, acc.: 43.75%] [G loss: 1.253975]\n",
      "epoch:23 step:21694 [D loss: 0.260040, acc.: 93.75%] [G loss: 1.574155]\n",
      "epoch:23 step:21695 [D loss: 0.672417, acc.: 70.31%] [G loss: 1.016101]\n",
      "epoch:23 step:21696 [D loss: 0.266679, acc.: 93.75%] [G loss: 1.489257]\n",
      "epoch:23 step:21697 [D loss: 0.626894, acc.: 66.41%] [G loss: 1.502911]\n",
      "epoch:23 step:21698 [D loss: 0.649717, acc.: 61.72%] [G loss: 1.304778]\n",
      "epoch:23 step:21699 [D loss: 0.751646, acc.: 49.22%] [G loss: 1.255836]\n",
      "epoch:23 step:21700 [D loss: 0.335140, acc.: 82.03%] [G loss: 1.118396]\n",
      "epoch:23 step:21701 [D loss: 0.209105, acc.: 99.22%] [G loss: 1.448948]\n",
      "epoch:23 step:21702 [D loss: 0.265631, acc.: 92.97%] [G loss: 1.454893]\n",
      "epoch:23 step:21703 [D loss: 0.388576, acc.: 92.19%] [G loss: 1.554975]\n",
      "epoch:23 step:21704 [D loss: 0.689718, acc.: 53.91%] [G loss: 1.112737]\n",
      "epoch:23 step:21705 [D loss: 0.635787, acc.: 60.16%] [G loss: 1.202438]\n",
      "epoch:23 step:21706 [D loss: 0.635358, acc.: 65.62%] [G loss: 1.130337]\n",
      "epoch:23 step:21707 [D loss: 0.642649, acc.: 65.62%] [G loss: 1.092776]\n",
      "epoch:23 step:21708 [D loss: 0.656441, acc.: 64.84%] [G loss: 0.579613]\n",
      "epoch:23 step:21709 [D loss: 0.932631, acc.: 35.16%] [G loss: 0.485276]\n",
      "epoch:23 step:21710 [D loss: 0.581546, acc.: 68.75%] [G loss: 0.996245]\n",
      "epoch:23 step:21711 [D loss: 0.543172, acc.: 71.88%] [G loss: 1.328203]\n",
      "epoch:23 step:21712 [D loss: 0.681367, acc.: 60.16%] [G loss: 1.189808]\n",
      "epoch:23 step:21713 [D loss: 0.439455, acc.: 83.59%] [G loss: 1.202801]\n",
      "epoch:23 step:21714 [D loss: 0.508676, acc.: 78.12%] [G loss: 1.076467]\n",
      "epoch:23 step:21715 [D loss: 0.600944, acc.: 64.84%] [G loss: 0.648207]\n",
      "epoch:23 step:21716 [D loss: 0.590674, acc.: 71.09%] [G loss: 0.928014]\n",
      "epoch:23 step:21717 [D loss: 0.856949, acc.: 44.53%] [G loss: 1.225099]\n",
      "epoch:23 step:21718 [D loss: 0.932957, acc.: 40.62%] [G loss: 1.087844]\n",
      "epoch:23 step:21719 [D loss: 0.656708, acc.: 62.50%] [G loss: 1.121927]\n",
      "epoch:23 step:21720 [D loss: 1.013247, acc.: 36.72%] [G loss: 1.321873]\n",
      "epoch:23 step:21721 [D loss: 0.639073, acc.: 64.06%] [G loss: 1.183122]\n",
      "epoch:23 step:21722 [D loss: 0.653506, acc.: 55.47%] [G loss: 1.045819]\n",
      "epoch:23 step:21723 [D loss: 0.724060, acc.: 53.12%] [G loss: 1.113742]\n",
      "epoch:23 step:21724 [D loss: 0.631456, acc.: 64.84%] [G loss: 1.222152]\n",
      "epoch:23 step:21725 [D loss: 0.808536, acc.: 47.66%] [G loss: 1.068994]\n",
      "epoch:23 step:21726 [D loss: 0.646911, acc.: 64.06%] [G loss: 1.194387]\n",
      "epoch:23 step:21727 [D loss: 0.563420, acc.: 71.09%] [G loss: 1.134171]\n",
      "epoch:23 step:21728 [D loss: 0.633379, acc.: 64.84%] [G loss: 1.168759]\n",
      "epoch:23 step:21729 [D loss: 0.719410, acc.: 48.44%] [G loss: 0.967216]\n",
      "epoch:23 step:21730 [D loss: 0.671428, acc.: 57.81%] [G loss: 0.910003]\n",
      "epoch:23 step:21731 [D loss: 0.669897, acc.: 55.47%] [G loss: 1.058923]\n",
      "epoch:23 step:21732 [D loss: 0.487030, acc.: 80.47%] [G loss: 1.116799]\n",
      "epoch:23 step:21733 [D loss: 0.463412, acc.: 82.81%] [G loss: 0.848276]\n",
      "epoch:23 step:21734 [D loss: 0.517185, acc.: 76.56%] [G loss: 1.076315]\n",
      "epoch:23 step:21735 [D loss: 0.335890, acc.: 90.62%] [G loss: 1.212155]\n",
      "epoch:23 step:21736 [D loss: 0.588133, acc.: 70.31%] [G loss: 1.115299]\n",
      "epoch:23 step:21737 [D loss: 0.660271, acc.: 60.94%] [G loss: 1.126810]\n",
      "epoch:23 step:21738 [D loss: 0.526590, acc.: 72.66%] [G loss: 1.142686]\n",
      "epoch:23 step:21739 [D loss: 0.567325, acc.: 64.84%] [G loss: 1.665560]\n",
      "epoch:23 step:21740 [D loss: 0.584835, acc.: 64.06%] [G loss: 1.034339]\n",
      "epoch:23 step:21741 [D loss: 0.549063, acc.: 71.88%] [G loss: 1.258111]\n",
      "epoch:23 step:21742 [D loss: 0.711340, acc.: 59.38%] [G loss: 1.315000]\n",
      "epoch:23 step:21743 [D loss: 0.366533, acc.: 79.69%] [G loss: 1.273473]\n",
      "epoch:23 step:21744 [D loss: 0.306801, acc.: 94.53%] [G loss: 1.620059]\n",
      "epoch:23 step:21745 [D loss: 0.189561, acc.: 99.22%] [G loss: 1.321012]\n",
      "epoch:23 step:21746 [D loss: 0.341413, acc.: 96.09%] [G loss: 1.210560]\n",
      "epoch:23 step:21747 [D loss: 0.455117, acc.: 82.03%] [G loss: 1.145113]\n",
      "epoch:23 step:21748 [D loss: 0.356458, acc.: 88.28%] [G loss: 1.499418]\n",
      "epoch:23 step:21749 [D loss: 0.349803, acc.: 91.41%] [G loss: 0.946398]\n",
      "epoch:23 step:21750 [D loss: 0.789155, acc.: 53.12%] [G loss: 0.816808]\n",
      "epoch:23 step:21751 [D loss: 0.605947, acc.: 65.62%] [G loss: 0.956313]\n",
      "epoch:23 step:21752 [D loss: 0.303793, acc.: 92.97%] [G loss: 1.727221]\n",
      "epoch:23 step:21753 [D loss: 0.866574, acc.: 40.62%] [G loss: 0.863550]\n",
      "epoch:23 step:21754 [D loss: 0.553291, acc.: 75.78%] [G loss: 0.716906]\n",
      "epoch:23 step:21755 [D loss: 0.290736, acc.: 94.53%] [G loss: 1.591709]\n",
      "epoch:23 step:21756 [D loss: 0.874085, acc.: 42.19%] [G loss: 1.894514]\n",
      "epoch:23 step:21757 [D loss: 0.232436, acc.: 97.66%] [G loss: 2.294102]\n",
      "epoch:23 step:21758 [D loss: 0.412255, acc.: 80.47%] [G loss: 1.896445]\n",
      "epoch:23 step:21759 [D loss: 0.459360, acc.: 75.78%] [G loss: 1.330700]\n",
      "epoch:23 step:21760 [D loss: 0.327978, acc.: 90.62%] [G loss: 1.589083]\n",
      "epoch:23 step:21761 [D loss: 1.317404, acc.: 46.09%] [G loss: 1.661610]\n",
      "epoch:23 step:21762 [D loss: 0.928479, acc.: 40.62%] [G loss: 0.976264]\n",
      "epoch:23 step:21763 [D loss: 0.938517, acc.: 35.16%] [G loss: 1.251860]\n",
      "epoch:23 step:21764 [D loss: 0.649119, acc.: 57.81%] [G loss: 1.330883]\n",
      "epoch:23 step:21765 [D loss: 0.848334, acc.: 52.34%] [G loss: 1.121856]\n",
      "epoch:23 step:21766 [D loss: 0.708975, acc.: 52.34%] [G loss: 0.984035]\n",
      "epoch:23 step:21767 [D loss: 0.808295, acc.: 49.22%] [G loss: 1.071109]\n",
      "epoch:23 step:21768 [D loss: 0.536519, acc.: 75.78%] [G loss: 1.193981]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:23 step:21769 [D loss: 0.690323, acc.: 57.03%] [G loss: 1.199094]\n",
      "epoch:23 step:21770 [D loss: 0.514003, acc.: 75.00%] [G loss: 0.799357]\n",
      "epoch:23 step:21771 [D loss: 0.275040, acc.: 87.50%] [G loss: 1.734757]\n",
      "epoch:23 step:21772 [D loss: 0.169269, acc.: 98.44%] [G loss: 1.574809]\n",
      "epoch:23 step:21773 [D loss: 0.209747, acc.: 97.66%] [G loss: 1.918501]\n",
      "epoch:23 step:21774 [D loss: 0.299175, acc.: 95.31%] [G loss: 1.548538]\n",
      "epoch:23 step:21775 [D loss: 0.679459, acc.: 62.50%] [G loss: 1.474710]\n",
      "epoch:23 step:21776 [D loss: 0.611303, acc.: 64.06%] [G loss: 1.039967]\n",
      "epoch:23 step:21777 [D loss: 0.680852, acc.: 62.50%] [G loss: 1.750329]\n",
      "epoch:23 step:21778 [D loss: 0.344707, acc.: 89.84%] [G loss: 2.067053]\n",
      "epoch:23 step:21779 [D loss: 0.410785, acc.: 80.47%] [G loss: 1.748570]\n",
      "epoch:23 step:21780 [D loss: 0.438373, acc.: 83.59%] [G loss: 1.692390]\n",
      "epoch:23 step:21781 [D loss: 0.125106, acc.: 99.22%] [G loss: 1.253204]\n",
      "epoch:23 step:21782 [D loss: 0.193941, acc.: 93.75%] [G loss: 1.626455]\n",
      "epoch:23 step:21783 [D loss: 0.132710, acc.: 99.22%] [G loss: 1.991232]\n",
      "epoch:23 step:21784 [D loss: 0.337164, acc.: 90.62%] [G loss: 1.537055]\n",
      "epoch:23 step:21785 [D loss: 0.183605, acc.: 99.22%] [G loss: 2.608622]\n",
      "epoch:23 step:21786 [D loss: 0.149956, acc.: 99.22%] [G loss: 1.798986]\n",
      "epoch:23 step:21787 [D loss: 0.474105, acc.: 74.22%] [G loss: 1.077445]\n",
      "epoch:23 step:21788 [D loss: 0.193324, acc.: 96.09%] [G loss: 1.824514]\n",
      "epoch:23 step:21789 [D loss: 0.232110, acc.: 98.44%] [G loss: 1.543193]\n",
      "epoch:23 step:21790 [D loss: 0.375034, acc.: 85.16%] [G loss: 1.791771]\n",
      "epoch:23 step:21791 [D loss: 0.484774, acc.: 78.91%] [G loss: 1.615125]\n",
      "epoch:23 step:21792 [D loss: 1.242887, acc.: 31.25%] [G loss: 0.805733]\n",
      "epoch:23 step:21793 [D loss: 0.416358, acc.: 85.94%] [G loss: 1.093684]\n",
      "epoch:23 step:21794 [D loss: 0.320847, acc.: 85.16%] [G loss: 1.020845]\n",
      "epoch:23 step:21795 [D loss: 0.453873, acc.: 82.81%] [G loss: 1.972379]\n",
      "epoch:23 step:21796 [D loss: 0.651471, acc.: 61.72%] [G loss: 0.807861]\n",
      "epoch:23 step:21797 [D loss: 0.583140, acc.: 61.72%] [G loss: 1.432145]\n",
      "epoch:23 step:21798 [D loss: 0.901079, acc.: 45.31%] [G loss: 0.692993]\n",
      "epoch:23 step:21799 [D loss: 0.761283, acc.: 49.22%] [G loss: 0.998139]\n",
      "epoch:23 step:21800 [D loss: 0.425619, acc.: 81.25%] [G loss: 1.204858]\n",
      "##############\n",
      "[4.35252107 2.73078328 6.68384143 5.60209959 4.6069243  6.23625086\n",
      " 5.61972113 5.35600057 6.10713921 4.98995008]\n",
      "##########\n",
      "epoch:23 step:21801 [D loss: 0.592076, acc.: 68.75%] [G loss: 0.698244]\n",
      "epoch:23 step:21802 [D loss: 0.477619, acc.: 76.56%] [G loss: 1.111174]\n",
      "epoch:23 step:21803 [D loss: 0.531752, acc.: 77.34%] [G loss: 1.150720]\n",
      "epoch:23 step:21804 [D loss: 0.420148, acc.: 85.16%] [G loss: 1.499039]\n",
      "epoch:23 step:21805 [D loss: 0.498091, acc.: 69.53%] [G loss: 1.307647]\n",
      "epoch:23 step:21806 [D loss: 0.203630, acc.: 97.66%] [G loss: 1.645621]\n",
      "epoch:23 step:21807 [D loss: 0.087979, acc.: 100.00%] [G loss: 1.454436]\n",
      "epoch:23 step:21808 [D loss: 0.152131, acc.: 97.66%] [G loss: 1.295765]\n",
      "epoch:23 step:21809 [D loss: 0.419057, acc.: 81.25%] [G loss: 1.924542]\n",
      "epoch:23 step:21810 [D loss: 0.156797, acc.: 96.88%] [G loss: 0.521583]\n",
      "epoch:23 step:21811 [D loss: 0.337795, acc.: 81.25%] [G loss: 1.354362]\n",
      "epoch:23 step:21812 [D loss: 0.156759, acc.: 97.66%] [G loss: 2.312878]\n",
      "epoch:23 step:21813 [D loss: 0.579296, acc.: 65.62%] [G loss: 1.767926]\n",
      "epoch:23 step:21814 [D loss: 1.146617, acc.: 48.44%] [G loss: 0.412550]\n",
      "epoch:23 step:21815 [D loss: 1.181067, acc.: 39.84%] [G loss: 1.443208]\n",
      "epoch:23 step:21816 [D loss: 0.381981, acc.: 80.47%] [G loss: 0.993355]\n",
      "epoch:23 step:21817 [D loss: 0.750536, acc.: 61.72%] [G loss: 0.713527]\n",
      "epoch:23 step:21818 [D loss: 0.645287, acc.: 67.19%] [G loss: 0.285396]\n",
      "epoch:23 step:21819 [D loss: 1.509006, acc.: 27.34%] [G loss: 1.520524]\n",
      "epoch:23 step:21820 [D loss: 1.006770, acc.: 42.97%] [G loss: 1.708819]\n",
      "epoch:23 step:21821 [D loss: 0.877512, acc.: 55.47%] [G loss: 1.783611]\n",
      "epoch:23 step:21822 [D loss: 0.574660, acc.: 69.53%] [G loss: 2.700013]\n",
      "epoch:23 step:21823 [D loss: 0.672083, acc.: 61.72%] [G loss: 1.588175]\n",
      "epoch:23 step:21824 [D loss: 0.855025, acc.: 46.09%] [G loss: 1.190784]\n",
      "epoch:23 step:21825 [D loss: 0.590172, acc.: 68.75%] [G loss: 1.992844]\n",
      "epoch:23 step:21826 [D loss: 0.489150, acc.: 75.00%] [G loss: 1.810563]\n",
      "epoch:23 step:21827 [D loss: 0.502829, acc.: 75.78%] [G loss: 1.520820]\n",
      "epoch:23 step:21828 [D loss: 0.563507, acc.: 69.53%] [G loss: 1.261406]\n",
      "epoch:23 step:21829 [D loss: 0.497070, acc.: 71.88%] [G loss: 1.358036]\n",
      "epoch:23 step:21830 [D loss: 0.286862, acc.: 86.72%] [G loss: 1.140798]\n",
      "epoch:23 step:21831 [D loss: 0.545478, acc.: 78.12%] [G loss: 1.665004]\n",
      "epoch:23 step:21832 [D loss: 0.761049, acc.: 53.91%] [G loss: 1.390717]\n",
      "epoch:23 step:21833 [D loss: 0.983775, acc.: 35.16%] [G loss: 1.263698]\n",
      "epoch:23 step:21834 [D loss: 0.646823, acc.: 60.94%] [G loss: 1.758946]\n",
      "epoch:23 step:21835 [D loss: 0.486645, acc.: 78.91%] [G loss: 1.532741]\n",
      "epoch:23 step:21836 [D loss: 0.464895, acc.: 84.38%] [G loss: 1.317060]\n",
      "epoch:23 step:21837 [D loss: 0.463534, acc.: 82.03%] [G loss: 1.350597]\n",
      "epoch:23 step:21838 [D loss: 0.352081, acc.: 90.62%] [G loss: 1.343535]\n",
      "epoch:23 step:21839 [D loss: 0.319531, acc.: 89.84%] [G loss: 1.334142]\n",
      "epoch:23 step:21840 [D loss: 0.213361, acc.: 96.09%] [G loss: 1.372101]\n",
      "epoch:23 step:21841 [D loss: 0.290678, acc.: 91.41%] [G loss: 1.605410]\n",
      "epoch:23 step:21842 [D loss: 0.438753, acc.: 84.38%] [G loss: 0.672045]\n",
      "epoch:23 step:21843 [D loss: 0.295846, acc.: 92.19%] [G loss: 0.438220]\n",
      "epoch:23 step:21844 [D loss: 0.346147, acc.: 80.47%] [G loss: 1.453776]\n",
      "epoch:23 step:21845 [D loss: 0.508879, acc.: 76.56%] [G loss: 0.925567]\n",
      "epoch:23 step:21846 [D loss: 0.691389, acc.: 58.59%] [G loss: 0.231891]\n",
      "epoch:23 step:21847 [D loss: 0.744398, acc.: 53.12%] [G loss: 1.204675]\n",
      "epoch:23 step:21848 [D loss: 0.931502, acc.: 44.53%] [G loss: 0.467454]\n",
      "epoch:23 step:21849 [D loss: 0.439580, acc.: 82.03%] [G loss: 1.462925]\n",
      "epoch:23 step:21850 [D loss: 0.535344, acc.: 73.44%] [G loss: 1.585226]\n",
      "epoch:23 step:21851 [D loss: 0.531500, acc.: 64.06%] [G loss: 1.767817]\n",
      "epoch:23 step:21852 [D loss: 0.624135, acc.: 64.84%] [G loss: 1.559485]\n",
      "epoch:23 step:21853 [D loss: 0.730051, acc.: 53.91%] [G loss: 1.237936]\n",
      "epoch:23 step:21854 [D loss: 0.498559, acc.: 78.12%] [G loss: 1.633990]\n",
      "epoch:23 step:21855 [D loss: 0.610528, acc.: 61.72%] [G loss: 1.096076]\n",
      "epoch:23 step:21856 [D loss: 0.598761, acc.: 71.88%] [G loss: 1.122416]\n",
      "epoch:23 step:21857 [D loss: 0.662183, acc.: 62.50%] [G loss: 1.137586]\n",
      "epoch:23 step:21858 [D loss: 0.522626, acc.: 72.66%] [G loss: 0.986482]\n",
      "epoch:23 step:21859 [D loss: 0.957068, acc.: 38.28%] [G loss: 1.228260]\n",
      "epoch:23 step:21860 [D loss: 0.290999, acc.: 89.06%] [G loss: 1.545208]\n",
      "epoch:23 step:21861 [D loss: 0.614178, acc.: 61.72%] [G loss: 1.169839]\n",
      "epoch:23 step:21862 [D loss: 0.712926, acc.: 56.25%] [G loss: 0.753197]\n",
      "epoch:23 step:21863 [D loss: 0.544989, acc.: 68.75%] [G loss: 1.169459]\n",
      "epoch:23 step:21864 [D loss: 0.785928, acc.: 54.69%] [G loss: 1.934146]\n",
      "epoch:23 step:21865 [D loss: 0.356306, acc.: 90.62%] [G loss: 1.797692]\n",
      "epoch:23 step:21866 [D loss: 0.625242, acc.: 69.53%] [G loss: 1.550638]\n",
      "epoch:23 step:21867 [D loss: 0.435464, acc.: 81.25%] [G loss: 1.834205]\n",
      "epoch:23 step:21868 [D loss: 0.557408, acc.: 69.53%] [G loss: 1.613072]\n",
      "epoch:23 step:21869 [D loss: 0.333588, acc.: 91.41%] [G loss: 1.461556]\n",
      "epoch:23 step:21870 [D loss: 0.460164, acc.: 83.59%] [G loss: 1.572812]\n",
      "epoch:23 step:21871 [D loss: 0.352061, acc.: 91.41%] [G loss: 1.617462]\n",
      "epoch:23 step:21872 [D loss: 0.328645, acc.: 90.62%] [G loss: 1.351377]\n",
      "epoch:23 step:21873 [D loss: 0.337154, acc.: 87.50%] [G loss: 1.437477]\n",
      "epoch:23 step:21874 [D loss: 0.774531, acc.: 57.81%] [G loss: 0.992449]\n",
      "epoch:23 step:21875 [D loss: 0.778702, acc.: 49.22%] [G loss: 1.078784]\n",
      "epoch:23 step:21876 [D loss: 0.410080, acc.: 86.72%] [G loss: 1.074306]\n",
      "epoch:23 step:21877 [D loss: 0.538219, acc.: 70.31%] [G loss: 1.122321]\n",
      "epoch:23 step:21878 [D loss: 0.284661, acc.: 86.72%] [G loss: 1.015402]\n",
      "epoch:23 step:21879 [D loss: 0.234492, acc.: 92.97%] [G loss: 1.125274]\n",
      "epoch:23 step:21880 [D loss: 0.759755, acc.: 58.59%] [G loss: 1.385442]\n",
      "epoch:23 step:21881 [D loss: 0.892022, acc.: 50.78%] [G loss: 1.704204]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:23 step:21882 [D loss: 0.927422, acc.: 39.06%] [G loss: 0.990100]\n",
      "epoch:23 step:21883 [D loss: 0.936095, acc.: 42.19%] [G loss: 1.214300]\n",
      "epoch:23 step:21884 [D loss: 0.804789, acc.: 49.22%] [G loss: 0.884274]\n",
      "epoch:23 step:21885 [D loss: 0.436505, acc.: 75.78%] [G loss: 0.984798]\n",
      "epoch:23 step:21886 [D loss: 0.695113, acc.: 56.25%] [G loss: 0.877010]\n",
      "epoch:23 step:21887 [D loss: 0.369221, acc.: 85.94%] [G loss: 1.002972]\n",
      "epoch:23 step:21888 [D loss: 0.742741, acc.: 57.03%] [G loss: 0.963646]\n",
      "epoch:23 step:21889 [D loss: 0.572674, acc.: 71.09%] [G loss: 0.828463]\n",
      "epoch:23 step:21890 [D loss: 0.463287, acc.: 78.91%] [G loss: 1.322894]\n",
      "epoch:23 step:21891 [D loss: 0.700813, acc.: 55.47%] [G loss: 1.125131]\n",
      "epoch:23 step:21892 [D loss: 0.851141, acc.: 40.62%] [G loss: 0.800716]\n",
      "epoch:23 step:21893 [D loss: 0.666749, acc.: 60.94%] [G loss: 1.073694]\n",
      "epoch:23 step:21894 [D loss: 0.282120, acc.: 92.19%] [G loss: 1.045638]\n",
      "epoch:23 step:21895 [D loss: 0.351547, acc.: 89.06%] [G loss: 1.257770]\n",
      "epoch:23 step:21896 [D loss: 0.311722, acc.: 96.09%] [G loss: 1.384169]\n",
      "epoch:23 step:21897 [D loss: 0.224263, acc.: 90.62%] [G loss: 1.083001]\n",
      "epoch:23 step:21898 [D loss: 0.228497, acc.: 94.53%] [G loss: 0.966039]\n",
      "epoch:23 step:21899 [D loss: 0.712104, acc.: 54.69%] [G loss: 1.373470]\n",
      "epoch:23 step:21900 [D loss: 0.676767, acc.: 61.72%] [G loss: 0.909829]\n",
      "epoch:23 step:21901 [D loss: 0.509202, acc.: 77.34%] [G loss: 1.261610]\n",
      "epoch:23 step:21902 [D loss: 0.549927, acc.: 75.00%] [G loss: 1.331936]\n",
      "epoch:23 step:21903 [D loss: 0.487970, acc.: 78.12%] [G loss: 1.128065]\n",
      "epoch:23 step:21904 [D loss: 0.470833, acc.: 84.38%] [G loss: 1.490756]\n",
      "epoch:23 step:21905 [D loss: 0.438397, acc.: 86.72%] [G loss: 1.227133]\n",
      "epoch:23 step:21906 [D loss: 0.834746, acc.: 46.88%] [G loss: 1.048825]\n",
      "epoch:23 step:21907 [D loss: 0.622170, acc.: 67.19%] [G loss: 1.274843]\n",
      "epoch:23 step:21908 [D loss: 0.529421, acc.: 77.34%] [G loss: 1.331521]\n",
      "epoch:23 step:21909 [D loss: 0.484301, acc.: 78.12%] [G loss: 1.022144]\n",
      "epoch:23 step:21910 [D loss: 0.345188, acc.: 91.41%] [G loss: 1.017226]\n",
      "epoch:23 step:21911 [D loss: 0.679036, acc.: 58.59%] [G loss: 1.018097]\n",
      "epoch:23 step:21912 [D loss: 0.548712, acc.: 71.88%] [G loss: 0.830424]\n",
      "epoch:23 step:21913 [D loss: 0.659724, acc.: 60.16%] [G loss: 0.926073]\n",
      "epoch:23 step:21914 [D loss: 0.599417, acc.: 71.09%] [G loss: 1.084309]\n",
      "epoch:23 step:21915 [D loss: 0.601495, acc.: 73.44%] [G loss: 0.768429]\n",
      "epoch:23 step:21916 [D loss: 0.323541, acc.: 86.72%] [G loss: 1.065062]\n",
      "epoch:23 step:21917 [D loss: 0.318699, acc.: 82.81%] [G loss: 0.914366]\n",
      "epoch:23 step:21918 [D loss: 0.469894, acc.: 83.59%] [G loss: 1.319175]\n",
      "epoch:23 step:21919 [D loss: 0.818979, acc.: 52.34%] [G loss: 1.348166]\n",
      "epoch:23 step:21920 [D loss: 0.550004, acc.: 72.66%] [G loss: 1.197346]\n",
      "epoch:23 step:21921 [D loss: 0.526009, acc.: 75.00%] [G loss: 1.464430]\n",
      "epoch:23 step:21922 [D loss: 0.453652, acc.: 85.16%] [G loss: 1.209979]\n",
      "epoch:23 step:21923 [D loss: 0.573127, acc.: 70.31%] [G loss: 1.198477]\n",
      "epoch:23 step:21924 [D loss: 0.750460, acc.: 53.91%] [G loss: 1.192260]\n",
      "epoch:23 step:21925 [D loss: 0.642438, acc.: 64.06%] [G loss: 1.049636]\n",
      "epoch:23 step:21926 [D loss: 0.514779, acc.: 78.12%] [G loss: 1.167463]\n",
      "epoch:23 step:21927 [D loss: 0.806829, acc.: 46.09%] [G loss: 1.103947]\n",
      "epoch:23 step:21928 [D loss: 0.420652, acc.: 75.00%] [G loss: 1.307864]\n",
      "epoch:23 step:21929 [D loss: 0.212162, acc.: 93.75%] [G loss: 1.737177]\n",
      "epoch:23 step:21930 [D loss: 0.825922, acc.: 55.47%] [G loss: 1.360285]\n",
      "epoch:23 step:21931 [D loss: 0.608608, acc.: 64.06%] [G loss: 1.459657]\n",
      "epoch:23 step:21932 [D loss: 0.549306, acc.: 68.75%] [G loss: 1.127075]\n",
      "epoch:23 step:21933 [D loss: 0.708224, acc.: 46.09%] [G loss: 1.047473]\n",
      "epoch:23 step:21934 [D loss: 0.565105, acc.: 69.53%] [G loss: 1.269299]\n",
      "epoch:23 step:21935 [D loss: 0.443342, acc.: 82.03%] [G loss: 1.245048]\n",
      "epoch:23 step:21936 [D loss: 0.613345, acc.: 64.06%] [G loss: 1.253912]\n",
      "epoch:23 step:21937 [D loss: 0.674356, acc.: 59.38%] [G loss: 1.048585]\n",
      "epoch:23 step:21938 [D loss: 0.595701, acc.: 67.97%] [G loss: 0.988318]\n",
      "epoch:23 step:21939 [D loss: 0.512235, acc.: 75.78%] [G loss: 1.460311]\n",
      "epoch:23 step:21940 [D loss: 0.420683, acc.: 82.03%] [G loss: 1.176594]\n",
      "epoch:23 step:21941 [D loss: 0.330206, acc.: 90.62%] [G loss: 1.272644]\n",
      "epoch:23 step:21942 [D loss: 0.610819, acc.: 64.84%] [G loss: 1.113013]\n",
      "epoch:23 step:21943 [D loss: 0.532842, acc.: 69.53%] [G loss: 1.208906]\n",
      "epoch:23 step:21944 [D loss: 0.309285, acc.: 87.50%] [G loss: 1.227271]\n",
      "epoch:23 step:21945 [D loss: 0.544819, acc.: 73.44%] [G loss: 1.265672]\n",
      "epoch:23 step:21946 [D loss: 0.791559, acc.: 47.66%] [G loss: 1.113989]\n",
      "epoch:23 step:21947 [D loss: 0.228422, acc.: 90.62%] [G loss: 1.389274]\n",
      "epoch:23 step:21948 [D loss: 0.201465, acc.: 92.97%] [G loss: 1.556466]\n",
      "epoch:23 step:21949 [D loss: 0.168236, acc.: 96.88%] [G loss: 1.770806]\n",
      "epoch:23 step:21950 [D loss: 0.137759, acc.: 98.44%] [G loss: 1.599982]\n",
      "epoch:23 step:21951 [D loss: 0.148919, acc.: 100.00%] [G loss: 2.263438]\n",
      "epoch:23 step:21952 [D loss: 0.186064, acc.: 99.22%] [G loss: 1.301070]\n",
      "epoch:23 step:21953 [D loss: 0.287082, acc.: 84.38%] [G loss: 1.279132]\n",
      "epoch:23 step:21954 [D loss: 0.112482, acc.: 100.00%] [G loss: 2.373173]\n",
      "epoch:23 step:21955 [D loss: 0.156387, acc.: 99.22%] [G loss: 2.087261]\n",
      "epoch:23 step:21956 [D loss: 0.140275, acc.: 96.88%] [G loss: 1.638194]\n",
      "epoch:23 step:21957 [D loss: 0.103081, acc.: 100.00%] [G loss: 2.364077]\n",
      "epoch:23 step:21958 [D loss: 0.075998, acc.: 100.00%] [G loss: 1.083902]\n",
      "epoch:23 step:21959 [D loss: 0.080045, acc.: 100.00%] [G loss: 2.173682]\n",
      "epoch:23 step:21960 [D loss: 0.089190, acc.: 100.00%] [G loss: 2.156227]\n",
      "epoch:23 step:21961 [D loss: 0.113888, acc.: 100.00%] [G loss: 0.260054]\n",
      "epoch:23 step:21962 [D loss: 1.055943, acc.: 46.09%] [G loss: 2.109845]\n",
      "epoch:23 step:21963 [D loss: 0.508742, acc.: 71.88%] [G loss: 1.280160]\n",
      "epoch:23 step:21964 [D loss: 0.361067, acc.: 78.91%] [G loss: 1.291414]\n",
      "epoch:23 step:21965 [D loss: 0.185873, acc.: 96.09%] [G loss: 2.924010]\n",
      "epoch:23 step:21966 [D loss: 0.427358, acc.: 79.69%] [G loss: 1.723820]\n",
      "epoch:23 step:21967 [D loss: 0.231887, acc.: 96.09%] [G loss: 1.500972]\n",
      "epoch:23 step:21968 [D loss: 0.190275, acc.: 96.88%] [G loss: 0.190754]\n",
      "epoch:23 step:21969 [D loss: 0.446084, acc.: 72.66%] [G loss: 0.160675]\n",
      "epoch:23 step:21970 [D loss: 0.079784, acc.: 100.00%] [G loss: 2.376374]\n",
      "epoch:23 step:21971 [D loss: 1.421340, acc.: 50.78%] [G loss: 2.432209]\n",
      "epoch:23 step:21972 [D loss: 1.042307, acc.: 50.78%] [G loss: 2.561560]\n",
      "epoch:23 step:21973 [D loss: 1.727761, acc.: 17.97%] [G loss: 1.827441]\n",
      "epoch:23 step:21974 [D loss: 0.838486, acc.: 51.56%] [G loss: 2.213130]\n",
      "epoch:23 step:21975 [D loss: 0.539236, acc.: 74.22%] [G loss: 1.296615]\n",
      "epoch:23 step:21976 [D loss: 0.632658, acc.: 66.41%] [G loss: 0.938099]\n",
      "epoch:23 step:21977 [D loss: 1.580271, acc.: 13.28%] [G loss: 1.281505]\n",
      "epoch:23 step:21978 [D loss: 0.332830, acc.: 87.50%] [G loss: 1.996639]\n",
      "epoch:23 step:21979 [D loss: 0.329983, acc.: 85.16%] [G loss: 2.064268]\n",
      "epoch:23 step:21980 [D loss: 0.501100, acc.: 73.44%] [G loss: 1.470756]\n",
      "epoch:23 step:21981 [D loss: 0.475989, acc.: 79.69%] [G loss: 1.935690]\n",
      "epoch:23 step:21982 [D loss: 0.901737, acc.: 47.66%] [G loss: 1.834589]\n",
      "epoch:23 step:21983 [D loss: 1.024378, acc.: 50.78%] [G loss: 1.753576]\n",
      "epoch:23 step:21984 [D loss: 0.904938, acc.: 45.31%] [G loss: 2.119340]\n",
      "epoch:23 step:21985 [D loss: 0.812638, acc.: 50.00%] [G loss: 1.887273]\n",
      "epoch:23 step:21986 [D loss: 0.624399, acc.: 57.81%] [G loss: 1.840297]\n",
      "epoch:23 step:21987 [D loss: 0.655927, acc.: 64.84%] [G loss: 1.609848]\n",
      "epoch:23 step:21988 [D loss: 0.815391, acc.: 47.66%] [G loss: 1.753463]\n",
      "epoch:23 step:21989 [D loss: 0.661933, acc.: 63.28%] [G loss: 1.267776]\n",
      "epoch:23 step:21990 [D loss: 0.672892, acc.: 61.72%] [G loss: 1.366454]\n",
      "epoch:23 step:21991 [D loss: 0.578390, acc.: 66.41%] [G loss: 1.198886]\n",
      "epoch:23 step:21992 [D loss: 0.593125, acc.: 64.06%] [G loss: 0.985542]\n",
      "epoch:23 step:21993 [D loss: 0.573791, acc.: 71.09%] [G loss: 1.224560]\n",
      "epoch:23 step:21994 [D loss: 0.644124, acc.: 57.81%] [G loss: 1.702409]\n",
      "epoch:23 step:21995 [D loss: 0.669240, acc.: 62.50%] [G loss: 1.445516]\n",
      "epoch:23 step:21996 [D loss: 0.581000, acc.: 67.19%] [G loss: 1.607960]\n",
      "epoch:23 step:21997 [D loss: 0.595568, acc.: 62.50%] [G loss: 1.249952]\n",
      "epoch:23 step:21998 [D loss: 0.711537, acc.: 58.59%] [G loss: 1.271439]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:23 step:21999 [D loss: 0.620559, acc.: 63.28%] [G loss: 1.218678]\n",
      "epoch:23 step:22000 [D loss: 0.551262, acc.: 73.44%] [G loss: 1.378388]\n",
      "##############\n",
      "[4.63105613 2.41245704 6.59948165 5.69720378 4.65630089 6.15735558\n",
      " 5.13660643 5.48838097 5.43366564 4.80504934]\n",
      "##########\n",
      "epoch:23 step:22001 [D loss: 0.463539, acc.: 81.25%] [G loss: 1.431925]\n",
      "epoch:23 step:22002 [D loss: 0.292398, acc.: 93.75%] [G loss: 1.600835]\n",
      "epoch:23 step:22003 [D loss: 0.381910, acc.: 89.84%] [G loss: 1.767707]\n",
      "epoch:23 step:22004 [D loss: 0.413013, acc.: 85.16%] [G loss: 2.186208]\n",
      "epoch:23 step:22005 [D loss: 0.347199, acc.: 90.62%] [G loss: 1.706309]\n",
      "epoch:23 step:22006 [D loss: 0.466310, acc.: 82.81%] [G loss: 1.243973]\n",
      "epoch:23 step:22007 [D loss: 0.350640, acc.: 90.62%] [G loss: 2.053018]\n",
      "epoch:23 step:22008 [D loss: 0.227302, acc.: 97.66%] [G loss: 1.428022]\n",
      "epoch:23 step:22009 [D loss: 0.694851, acc.: 57.81%] [G loss: 1.857652]\n",
      "epoch:23 step:22010 [D loss: 0.582698, acc.: 71.09%] [G loss: 0.896788]\n",
      "epoch:23 step:22011 [D loss: 0.638424, acc.: 65.62%] [G loss: 1.095769]\n",
      "epoch:23 step:22012 [D loss: 0.913304, acc.: 35.94%] [G loss: 0.898814]\n",
      "epoch:23 step:22013 [D loss: 1.107919, acc.: 23.44%] [G loss: 0.844458]\n",
      "epoch:23 step:22014 [D loss: 0.788517, acc.: 53.12%] [G loss: 0.809008]\n",
      "epoch:23 step:22015 [D loss: 0.617792, acc.: 67.97%] [G loss: 1.030055]\n",
      "epoch:23 step:22016 [D loss: 0.590814, acc.: 67.19%] [G loss: 0.941945]\n",
      "epoch:23 step:22017 [D loss: 0.511902, acc.: 76.56%] [G loss: 0.966743]\n",
      "epoch:23 step:22018 [D loss: 0.563458, acc.: 71.88%] [G loss: 0.960167]\n",
      "epoch:23 step:22019 [D loss: 0.378057, acc.: 84.38%] [G loss: 0.939287]\n",
      "epoch:23 step:22020 [D loss: 0.380781, acc.: 88.28%] [G loss: 1.451156]\n",
      "epoch:23 step:22021 [D loss: 0.272300, acc.: 92.97%] [G loss: 1.354461]\n",
      "epoch:23 step:22022 [D loss: 0.262257, acc.: 94.53%] [G loss: 1.380743]\n",
      "epoch:23 step:22023 [D loss: 0.404246, acc.: 85.94%] [G loss: 1.959106]\n",
      "epoch:23 step:22024 [D loss: 0.922608, acc.: 52.34%] [G loss: 0.899372]\n",
      "epoch:23 step:22025 [D loss: 0.419945, acc.: 83.59%] [G loss: 1.155983]\n",
      "epoch:23 step:22026 [D loss: 0.724717, acc.: 54.69%] [G loss: 1.201601]\n",
      "epoch:23 step:22027 [D loss: 0.675713, acc.: 61.72%] [G loss: 1.148221]\n",
      "epoch:23 step:22028 [D loss: 0.647554, acc.: 60.94%] [G loss: 1.105141]\n",
      "epoch:23 step:22029 [D loss: 0.504376, acc.: 79.69%] [G loss: 1.078743]\n",
      "epoch:23 step:22030 [D loss: 0.329192, acc.: 89.84%] [G loss: 1.147384]\n",
      "epoch:23 step:22031 [D loss: 0.369999, acc.: 90.62%] [G loss: 1.380128]\n",
      "epoch:23 step:22032 [D loss: 0.368895, acc.: 85.16%] [G loss: 1.142586]\n",
      "epoch:23 step:22033 [D loss: 0.892763, acc.: 43.75%] [G loss: 0.952698]\n",
      "epoch:23 step:22034 [D loss: 0.633079, acc.: 60.16%] [G loss: 1.092450]\n",
      "epoch:23 step:22035 [D loss: 0.425816, acc.: 73.44%] [G loss: 1.237344]\n",
      "epoch:23 step:22036 [D loss: 0.786246, acc.: 50.78%] [G loss: 1.230339]\n",
      "epoch:23 step:22037 [D loss: 0.659630, acc.: 60.16%] [G loss: 0.996058]\n",
      "epoch:23 step:22038 [D loss: 0.633415, acc.: 67.97%] [G loss: 1.288165]\n",
      "epoch:23 step:22039 [D loss: 0.689859, acc.: 53.91%] [G loss: 0.942207]\n",
      "epoch:23 step:22040 [D loss: 0.595387, acc.: 70.31%] [G loss: 1.167227]\n",
      "epoch:23 step:22041 [D loss: 0.722490, acc.: 62.50%] [G loss: 1.282354]\n",
      "epoch:23 step:22042 [D loss: 0.507761, acc.: 78.12%] [G loss: 1.280960]\n",
      "epoch:23 step:22043 [D loss: 0.705298, acc.: 54.69%] [G loss: 1.228181]\n",
      "epoch:23 step:22044 [D loss: 0.810351, acc.: 45.31%] [G loss: 1.256153]\n",
      "epoch:23 step:22045 [D loss: 0.597860, acc.: 69.53%] [G loss: 0.931415]\n",
      "epoch:23 step:22046 [D loss: 0.564766, acc.: 71.88%] [G loss: 1.306634]\n",
      "epoch:23 step:22047 [D loss: 0.735822, acc.: 50.00%] [G loss: 0.931329]\n",
      "epoch:23 step:22048 [D loss: 0.608267, acc.: 66.41%] [G loss: 1.250078]\n",
      "epoch:23 step:22049 [D loss: 0.293439, acc.: 86.72%] [G loss: 1.292637]\n",
      "epoch:23 step:22050 [D loss: 0.311637, acc.: 87.50%] [G loss: 1.437528]\n",
      "epoch:23 step:22051 [D loss: 0.571929, acc.: 71.09%] [G loss: 1.447853]\n",
      "epoch:23 step:22052 [D loss: 0.545720, acc.: 71.09%] [G loss: 1.333194]\n",
      "epoch:23 step:22053 [D loss: 0.474353, acc.: 78.91%] [G loss: 1.209974]\n",
      "epoch:23 step:22054 [D loss: 0.260030, acc.: 93.75%] [G loss: 1.281286]\n",
      "epoch:23 step:22055 [D loss: 0.221657, acc.: 95.31%] [G loss: 1.464328]\n",
      "epoch:23 step:22056 [D loss: 0.345562, acc.: 86.72%] [G loss: 1.522778]\n",
      "epoch:23 step:22057 [D loss: 0.741521, acc.: 56.25%] [G loss: 1.188548]\n",
      "epoch:23 step:22058 [D loss: 0.428402, acc.: 85.94%] [G loss: 1.217994]\n",
      "epoch:23 step:22059 [D loss: 0.443594, acc.: 82.03%] [G loss: 1.443067]\n",
      "epoch:23 step:22060 [D loss: 0.690369, acc.: 58.59%] [G loss: 1.290493]\n",
      "epoch:23 step:22061 [D loss: 0.383620, acc.: 83.59%] [G loss: 0.846894]\n",
      "epoch:23 step:22062 [D loss: 0.386227, acc.: 83.59%] [G loss: 1.154042]\n",
      "epoch:23 step:22063 [D loss: 0.524313, acc.: 74.22%] [G loss: 1.295166]\n",
      "epoch:23 step:22064 [D loss: 0.348206, acc.: 84.38%] [G loss: 1.581625]\n",
      "epoch:23 step:22065 [D loss: 0.450759, acc.: 85.94%] [G loss: 1.410872]\n",
      "epoch:23 step:22066 [D loss: 0.391908, acc.: 89.84%] [G loss: 1.639364]\n",
      "epoch:23 step:22067 [D loss: 0.712693, acc.: 57.81%] [G loss: 1.489048]\n",
      "epoch:23 step:22068 [D loss: 0.296967, acc.: 92.97%] [G loss: 1.505956]\n",
      "epoch:23 step:22069 [D loss: 0.519064, acc.: 74.22%] [G loss: 1.334584]\n",
      "epoch:23 step:22070 [D loss: 0.514034, acc.: 75.78%] [G loss: 1.121876]\n",
      "epoch:23 step:22071 [D loss: 0.451661, acc.: 85.16%] [G loss: 1.074930]\n",
      "epoch:23 step:22072 [D loss: 0.579419, acc.: 68.75%] [G loss: 0.973070]\n",
      "epoch:23 step:22073 [D loss: 0.478670, acc.: 80.47%] [G loss: 0.884470]\n",
      "epoch:23 step:22074 [D loss: 0.438374, acc.: 87.50%] [G loss: 0.954028]\n",
      "epoch:23 step:22075 [D loss: 0.428313, acc.: 76.56%] [G loss: 1.313292]\n",
      "epoch:23 step:22076 [D loss: 0.804105, acc.: 52.34%] [G loss: 1.198069]\n",
      "epoch:23 step:22077 [D loss: 0.745068, acc.: 56.25%] [G loss: 1.443668]\n",
      "epoch:23 step:22078 [D loss: 0.291138, acc.: 91.41%] [G loss: 1.412818]\n",
      "epoch:23 step:22079 [D loss: 0.864820, acc.: 45.31%] [G loss: 1.260657]\n",
      "epoch:23 step:22080 [D loss: 0.671942, acc.: 56.25%] [G loss: 1.375168]\n",
      "epoch:23 step:22081 [D loss: 0.509732, acc.: 78.12%] [G loss: 1.268105]\n",
      "epoch:23 step:22082 [D loss: 0.726694, acc.: 47.66%] [G loss: 1.306754]\n",
      "epoch:23 step:22083 [D loss: 0.495241, acc.: 76.56%] [G loss: 1.296274]\n",
      "epoch:23 step:22084 [D loss: 0.368607, acc.: 91.41%] [G loss: 0.820654]\n",
      "epoch:23 step:22085 [D loss: 0.415178, acc.: 86.72%] [G loss: 1.163712]\n",
      "epoch:23 step:22086 [D loss: 0.315598, acc.: 89.06%] [G loss: 1.152250]\n",
      "epoch:23 step:22087 [D loss: 0.182516, acc.: 96.88%] [G loss: 1.752918]\n",
      "epoch:23 step:22088 [D loss: 0.262600, acc.: 96.09%] [G loss: 1.771658]\n",
      "epoch:23 step:22089 [D loss: 0.419790, acc.: 85.94%] [G loss: 1.534413]\n",
      "epoch:23 step:22090 [D loss: 0.428805, acc.: 85.16%] [G loss: 1.292814]\n",
      "epoch:23 step:22091 [D loss: 0.435314, acc.: 88.28%] [G loss: 1.486517]\n",
      "epoch:23 step:22092 [D loss: 0.296352, acc.: 94.53%] [G loss: 1.429073]\n",
      "epoch:23 step:22093 [D loss: 0.562311, acc.: 70.31%] [G loss: 1.373757]\n",
      "epoch:23 step:22094 [D loss: 0.317375, acc.: 92.19%] [G loss: 1.189075]\n",
      "epoch:23 step:22095 [D loss: 0.757232, acc.: 53.12%] [G loss: 1.520169]\n",
      "epoch:23 step:22096 [D loss: 0.370396, acc.: 89.06%] [G loss: 1.300426]\n",
      "epoch:23 step:22097 [D loss: 0.707007, acc.: 55.47%] [G loss: 0.958998]\n",
      "epoch:23 step:22098 [D loss: 0.439226, acc.: 84.38%] [G loss: 1.013023]\n",
      "epoch:23 step:22099 [D loss: 0.433375, acc.: 81.25%] [G loss: 1.127744]\n",
      "epoch:23 step:22100 [D loss: 0.253730, acc.: 95.31%] [G loss: 1.112508]\n",
      "epoch:23 step:22101 [D loss: 0.501465, acc.: 73.44%] [G loss: 1.446002]\n",
      "epoch:23 step:22102 [D loss: 0.680751, acc.: 64.06%] [G loss: 1.280905]\n",
      "epoch:23 step:22103 [D loss: 0.346159, acc.: 89.84%] [G loss: 1.803129]\n",
      "epoch:23 step:22104 [D loss: 1.003592, acc.: 35.94%] [G loss: 0.939935]\n",
      "epoch:23 step:22105 [D loss: 0.214387, acc.: 93.75%] [G loss: 0.975051]\n",
      "epoch:23 step:22106 [D loss: 0.669124, acc.: 59.38%] [G loss: 1.093698]\n",
      "epoch:23 step:22107 [D loss: 0.621081, acc.: 66.41%] [G loss: 1.508913]\n",
      "epoch:23 step:22108 [D loss: 0.382675, acc.: 89.84%] [G loss: 1.086070]\n",
      "epoch:23 step:22109 [D loss: 0.684598, acc.: 61.72%] [G loss: 1.106858]\n",
      "epoch:23 step:22110 [D loss: 0.099068, acc.: 100.00%] [G loss: 1.700570]\n",
      "epoch:23 step:22111 [D loss: 0.311999, acc.: 92.19%] [G loss: 0.946282]\n",
      "epoch:23 step:22112 [D loss: 0.331703, acc.: 82.81%] [G loss: 1.754100]\n",
      "epoch:23 step:22113 [D loss: 0.677585, acc.: 64.06%] [G loss: 1.563210]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:23 step:22114 [D loss: 0.607492, acc.: 64.84%] [G loss: 1.632656]\n",
      "epoch:23 step:22115 [D loss: 0.547473, acc.: 70.31%] [G loss: 1.069895]\n",
      "epoch:23 step:22116 [D loss: 0.479798, acc.: 81.25%] [G loss: 1.701415]\n",
      "epoch:23 step:22117 [D loss: 0.171360, acc.: 97.66%] [G loss: 1.782576]\n",
      "epoch:23 step:22118 [D loss: 0.197572, acc.: 90.62%] [G loss: 1.526138]\n",
      "epoch:23 step:22119 [D loss: 0.145806, acc.: 99.22%] [G loss: 2.184143]\n",
      "epoch:23 step:22120 [D loss: 0.595330, acc.: 63.28%] [G loss: 1.377443]\n",
      "epoch:23 step:22121 [D loss: 0.403774, acc.: 83.59%] [G loss: 2.020868]\n",
      "epoch:23 step:22122 [D loss: 0.499800, acc.: 75.78%] [G loss: 1.773502]\n",
      "epoch:23 step:22123 [D loss: 0.506773, acc.: 71.88%] [G loss: 1.213299]\n",
      "epoch:23 step:22124 [D loss: 0.325942, acc.: 92.19%] [G loss: 1.387332]\n",
      "epoch:23 step:22125 [D loss: 0.339395, acc.: 91.41%] [G loss: 1.633511]\n",
      "epoch:23 step:22126 [D loss: 0.283364, acc.: 95.31%] [G loss: 1.132607]\n",
      "epoch:23 step:22127 [D loss: 0.251490, acc.: 92.97%] [G loss: 1.417793]\n",
      "epoch:23 step:22128 [D loss: 0.107883, acc.: 98.44%] [G loss: 1.007495]\n",
      "epoch:23 step:22129 [D loss: 0.172029, acc.: 96.09%] [G loss: 2.373089]\n",
      "epoch:23 step:22130 [D loss: 0.071038, acc.: 99.22%] [G loss: 2.198364]\n",
      "epoch:23 step:22131 [D loss: 0.748264, acc.: 60.94%] [G loss: 1.910267]\n",
      "epoch:23 step:22132 [D loss: 0.773064, acc.: 46.09%] [G loss: 1.150553]\n",
      "epoch:23 step:22133 [D loss: 0.636443, acc.: 66.41%] [G loss: 1.164458]\n",
      "epoch:23 step:22134 [D loss: 0.858681, acc.: 47.66%] [G loss: 1.088970]\n",
      "epoch:23 step:22135 [D loss: 1.143761, acc.: 32.03%] [G loss: 1.239245]\n",
      "epoch:23 step:22136 [D loss: 0.629376, acc.: 61.72%] [G loss: 1.446210]\n",
      "epoch:23 step:22137 [D loss: 0.661634, acc.: 57.81%] [G loss: 1.408778]\n",
      "epoch:23 step:22138 [D loss: 0.365809, acc.: 78.91%] [G loss: 1.548042]\n",
      "epoch:23 step:22139 [D loss: 0.147527, acc.: 96.88%] [G loss: 1.861190]\n",
      "epoch:23 step:22140 [D loss: 0.391567, acc.: 77.34%] [G loss: 1.976514]\n",
      "epoch:23 step:22141 [D loss: 0.394143, acc.: 82.03%] [G loss: 2.069294]\n",
      "epoch:23 step:22142 [D loss: 0.793171, acc.: 58.59%] [G loss: 1.531919]\n",
      "epoch:23 step:22143 [D loss: 0.650584, acc.: 60.16%] [G loss: 1.676884]\n",
      "epoch:23 step:22144 [D loss: 0.755297, acc.: 53.12%] [G loss: 1.512083]\n",
      "epoch:23 step:22145 [D loss: 0.400436, acc.: 87.50%] [G loss: 1.646208]\n",
      "epoch:23 step:22146 [D loss: 0.423050, acc.: 80.47%] [G loss: 1.969675]\n",
      "epoch:23 step:22147 [D loss: 0.760822, acc.: 59.38%] [G loss: 1.555105]\n",
      "epoch:23 step:22148 [D loss: 0.927773, acc.: 42.19%] [G loss: 1.429428]\n",
      "epoch:23 step:22149 [D loss: 0.955403, acc.: 35.94%] [G loss: 1.030199]\n",
      "epoch:23 step:22150 [D loss: 0.754955, acc.: 50.00%] [G loss: 1.186499]\n",
      "epoch:23 step:22151 [D loss: 0.246092, acc.: 92.97%] [G loss: 1.421893]\n",
      "epoch:23 step:22152 [D loss: 0.390815, acc.: 84.38%] [G loss: 1.386952]\n",
      "epoch:23 step:22153 [D loss: 0.469790, acc.: 73.44%] [G loss: 1.147667]\n",
      "epoch:23 step:22154 [D loss: 0.629541, acc.: 60.94%] [G loss: 1.374140]\n",
      "epoch:23 step:22155 [D loss: 0.642537, acc.: 64.06%] [G loss: 1.319750]\n",
      "epoch:23 step:22156 [D loss: 0.625497, acc.: 67.19%] [G loss: 1.315883]\n",
      "epoch:23 step:22157 [D loss: 0.599409, acc.: 71.09%] [G loss: 1.601550]\n",
      "epoch:23 step:22158 [D loss: 0.530555, acc.: 74.22%] [G loss: 1.094273]\n",
      "epoch:23 step:22159 [D loss: 0.390369, acc.: 90.62%] [G loss: 1.065616]\n",
      "epoch:23 step:22160 [D loss: 0.221113, acc.: 96.88%] [G loss: 1.133283]\n",
      "epoch:23 step:22161 [D loss: 0.772151, acc.: 53.12%] [G loss: 1.098162]\n",
      "epoch:23 step:22162 [D loss: 0.256906, acc.: 96.09%] [G loss: 1.465386]\n",
      "epoch:23 step:22163 [D loss: 0.410686, acc.: 86.72%] [G loss: 1.527088]\n",
      "epoch:23 step:22164 [D loss: 0.806466, acc.: 46.88%] [G loss: 1.006251]\n",
      "epoch:23 step:22165 [D loss: 0.814793, acc.: 47.66%] [G loss: 1.133381]\n",
      "epoch:23 step:22166 [D loss: 1.006867, acc.: 35.94%] [G loss: 1.115918]\n",
      "epoch:23 step:22167 [D loss: 0.502581, acc.: 79.69%] [G loss: 1.286675]\n",
      "epoch:23 step:22168 [D loss: 0.458408, acc.: 83.59%] [G loss: 1.431032]\n",
      "epoch:23 step:22169 [D loss: 0.453954, acc.: 81.25%] [G loss: 1.325678]\n",
      "epoch:23 step:22170 [D loss: 0.460669, acc.: 82.81%] [G loss: 1.121441]\n",
      "epoch:23 step:22171 [D loss: 0.619112, acc.: 61.72%] [G loss: 1.314672]\n",
      "epoch:23 step:22172 [D loss: 0.710461, acc.: 58.59%] [G loss: 1.221172]\n",
      "epoch:23 step:22173 [D loss: 0.456983, acc.: 82.81%] [G loss: 1.425368]\n",
      "epoch:23 step:22174 [D loss: 0.617998, acc.: 68.75%] [G loss: 1.340881]\n",
      "epoch:23 step:22175 [D loss: 0.330853, acc.: 89.06%] [G loss: 1.522477]\n",
      "epoch:23 step:22176 [D loss: 0.513255, acc.: 76.56%] [G loss: 1.395428]\n",
      "epoch:23 step:22177 [D loss: 0.606763, acc.: 68.75%] [G loss: 1.187292]\n",
      "epoch:23 step:22178 [D loss: 0.552151, acc.: 71.88%] [G loss: 1.880140]\n",
      "epoch:23 step:22179 [D loss: 0.617528, acc.: 64.06%] [G loss: 1.243700]\n",
      "epoch:23 step:22180 [D loss: 0.449856, acc.: 84.38%] [G loss: 1.224358]\n",
      "epoch:23 step:22181 [D loss: 0.388609, acc.: 83.59%] [G loss: 1.373530]\n",
      "epoch:23 step:22182 [D loss: 0.688962, acc.: 64.84%] [G loss: 1.233590]\n",
      "epoch:23 step:22183 [D loss: 0.358877, acc.: 87.50%] [G loss: 1.466422]\n",
      "epoch:23 step:22184 [D loss: 0.297634, acc.: 86.72%] [G loss: 1.715522]\n",
      "epoch:23 step:22185 [D loss: 0.247790, acc.: 95.31%] [G loss: 2.094768]\n",
      "epoch:23 step:22186 [D loss: 0.230427, acc.: 99.22%] [G loss: 1.703688]\n",
      "epoch:23 step:22187 [D loss: 0.534889, acc.: 75.00%] [G loss: 1.894373]\n",
      "epoch:23 step:22188 [D loss: 0.290254, acc.: 93.75%] [G loss: 1.633606]\n",
      "epoch:23 step:22189 [D loss: 0.644740, acc.: 57.81%] [G loss: 1.320344]\n",
      "epoch:23 step:22190 [D loss: 0.665372, acc.: 61.72%] [G loss: 0.954205]\n",
      "epoch:23 step:22191 [D loss: 0.860471, acc.: 46.09%] [G loss: 1.281254]\n",
      "epoch:23 step:22192 [D loss: 0.235353, acc.: 92.97%] [G loss: 1.230765]\n",
      "epoch:23 step:22193 [D loss: 0.803266, acc.: 46.88%] [G loss: 1.184167]\n",
      "epoch:23 step:22194 [D loss: 0.649417, acc.: 66.41%] [G loss: 0.820142]\n",
      "epoch:23 step:22195 [D loss: 0.229149, acc.: 95.31%] [G loss: 0.996020]\n",
      "epoch:23 step:22196 [D loss: 0.214116, acc.: 95.31%] [G loss: 0.881369]\n",
      "epoch:23 step:22197 [D loss: 0.208102, acc.: 96.09%] [G loss: 1.679730]\n",
      "epoch:23 step:22198 [D loss: 0.242768, acc.: 96.09%] [G loss: 2.066807]\n",
      "epoch:23 step:22199 [D loss: 0.321707, acc.: 85.16%] [G loss: 1.521546]\n",
      "epoch:23 step:22200 [D loss: 0.184617, acc.: 100.00%] [G loss: 2.397402]\n",
      "##############\n",
      "[4.20595697 2.57180705 6.67863591 5.86515306 4.52320234 6.39259081\n",
      " 5.20353623 5.8977747  5.9783796  5.24365949]\n",
      "##########\n",
      "epoch:23 step:22201 [D loss: 0.107578, acc.: 100.00%] [G loss: 1.881685]\n",
      "epoch:23 step:22202 [D loss: 0.304708, acc.: 90.62%] [G loss: 1.154981]\n",
      "epoch:23 step:22203 [D loss: 1.140454, acc.: 31.25%] [G loss: 1.565666]\n",
      "epoch:23 step:22204 [D loss: 0.753201, acc.: 57.81%] [G loss: 0.836416]\n",
      "epoch:23 step:22205 [D loss: 1.046910, acc.: 29.69%] [G loss: 0.975587]\n",
      "epoch:23 step:22206 [D loss: 0.637989, acc.: 67.19%] [G loss: 0.990285]\n",
      "epoch:23 step:22207 [D loss: 0.763462, acc.: 54.69%] [G loss: 1.451130]\n",
      "epoch:23 step:22208 [D loss: 0.854830, acc.: 45.31%] [G loss: 1.537667]\n",
      "epoch:23 step:22209 [D loss: 0.947315, acc.: 42.19%] [G loss: 0.869894]\n",
      "epoch:23 step:22210 [D loss: 0.541381, acc.: 69.53%] [G loss: 0.959664]\n",
      "epoch:23 step:22211 [D loss: 0.468708, acc.: 75.00%] [G loss: 1.604831]\n",
      "epoch:23 step:22212 [D loss: 0.462422, acc.: 79.69%] [G loss: 1.337824]\n",
      "epoch:23 step:22213 [D loss: 0.801031, acc.: 52.34%] [G loss: 0.824845]\n",
      "epoch:23 step:22214 [D loss: 0.407369, acc.: 75.78%] [G loss: 1.914347]\n",
      "epoch:23 step:22215 [D loss: 0.218524, acc.: 93.75%] [G loss: 1.479164]\n",
      "epoch:23 step:22216 [D loss: 0.184811, acc.: 95.31%] [G loss: 1.818240]\n",
      "epoch:23 step:22217 [D loss: 0.745168, acc.: 56.25%] [G loss: 1.615775]\n",
      "epoch:23 step:22218 [D loss: 0.588919, acc.: 66.41%] [G loss: 2.057869]\n",
      "epoch:23 step:22219 [D loss: 0.678984, acc.: 62.50%] [G loss: 1.337375]\n",
      "epoch:23 step:22220 [D loss: 0.623226, acc.: 60.94%] [G loss: 1.438660]\n",
      "epoch:23 step:22221 [D loss: 0.605076, acc.: 64.06%] [G loss: 1.251426]\n",
      "epoch:23 step:22222 [D loss: 0.423760, acc.: 82.81%] [G loss: 1.591824]\n",
      "epoch:23 step:22223 [D loss: 0.601991, acc.: 67.97%] [G loss: 1.706820]\n",
      "epoch:23 step:22224 [D loss: 0.706295, acc.: 54.69%] [G loss: 1.456184]\n",
      "epoch:23 step:22225 [D loss: 0.364757, acc.: 91.41%] [G loss: 1.377682]\n",
      "epoch:23 step:22226 [D loss: 0.659757, acc.: 62.50%] [G loss: 1.182587]\n",
      "epoch:23 step:22227 [D loss: 0.544166, acc.: 75.00%] [G loss: 1.472847]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:23 step:22228 [D loss: 0.748820, acc.: 51.56%] [G loss: 1.083432]\n",
      "epoch:23 step:22229 [D loss: 0.668763, acc.: 60.94%] [G loss: 0.961199]\n",
      "epoch:23 step:22230 [D loss: 0.512677, acc.: 78.12%] [G loss: 1.157957]\n",
      "epoch:23 step:22231 [D loss: 0.429018, acc.: 85.16%] [G loss: 0.907020]\n",
      "epoch:23 step:22232 [D loss: 0.765150, acc.: 49.22%] [G loss: 0.875351]\n",
      "epoch:23 step:22233 [D loss: 0.460814, acc.: 76.56%] [G loss: 1.108034]\n",
      "epoch:23 step:22234 [D loss: 0.338983, acc.: 90.62%] [G loss: 1.024475]\n",
      "epoch:23 step:22235 [D loss: 0.232715, acc.: 93.75%] [G loss: 1.257921]\n",
      "epoch:23 step:22236 [D loss: 0.459323, acc.: 80.47%] [G loss: 1.643710]\n",
      "epoch:23 step:22237 [D loss: 0.565316, acc.: 67.19%] [G loss: 1.537887]\n",
      "epoch:23 step:22238 [D loss: 0.346984, acc.: 90.62%] [G loss: 1.531252]\n",
      "epoch:23 step:22239 [D loss: 0.834995, acc.: 48.44%] [G loss: 1.377989]\n",
      "epoch:23 step:22240 [D loss: 0.969804, acc.: 39.84%] [G loss: 1.261342]\n",
      "epoch:23 step:22241 [D loss: 0.777463, acc.: 50.78%] [G loss: 1.130581]\n",
      "epoch:23 step:22242 [D loss: 0.825401, acc.: 46.88%] [G loss: 1.080551]\n",
      "epoch:23 step:22243 [D loss: 0.587490, acc.: 68.75%] [G loss: 1.040543]\n",
      "epoch:23 step:22244 [D loss: 0.645962, acc.: 64.06%] [G loss: 1.126317]\n",
      "epoch:23 step:22245 [D loss: 0.436284, acc.: 85.16%] [G loss: 1.119986]\n",
      "epoch:23 step:22246 [D loss: 0.738450, acc.: 56.25%] [G loss: 1.139899]\n",
      "epoch:23 step:22247 [D loss: 0.210746, acc.: 94.53%] [G loss: 1.337706]\n",
      "epoch:23 step:22248 [D loss: 0.251124, acc.: 90.62%] [G loss: 2.000802]\n",
      "epoch:23 step:22249 [D loss: 0.206618, acc.: 94.53%] [G loss: 1.374402]\n",
      "epoch:23 step:22250 [D loss: 0.283246, acc.: 96.09%] [G loss: 1.550280]\n",
      "epoch:23 step:22251 [D loss: 0.295246, acc.: 85.94%] [G loss: 1.846723]\n",
      "epoch:23 step:22252 [D loss: 0.143731, acc.: 99.22%] [G loss: 1.591983]\n",
      "epoch:23 step:22253 [D loss: 0.254057, acc.: 95.31%] [G loss: 2.079022]\n",
      "epoch:23 step:22254 [D loss: 0.773267, acc.: 52.34%] [G loss: 0.997289]\n",
      "epoch:23 step:22255 [D loss: 0.348356, acc.: 93.75%] [G loss: 1.193611]\n",
      "epoch:23 step:22256 [D loss: 0.756452, acc.: 53.12%] [G loss: 1.356966]\n",
      "epoch:23 step:22257 [D loss: 0.309185, acc.: 88.28%] [G loss: 1.041362]\n",
      "epoch:23 step:22258 [D loss: 0.948827, acc.: 54.69%] [G loss: 1.512287]\n",
      "epoch:23 step:22259 [D loss: 0.138173, acc.: 99.22%] [G loss: 2.268344]\n",
      "epoch:23 step:22260 [D loss: 0.137847, acc.: 97.66%] [G loss: 2.108097]\n",
      "epoch:23 step:22261 [D loss: 0.713534, acc.: 60.16%] [G loss: 2.429881]\n",
      "epoch:23 step:22262 [D loss: 0.516183, acc.: 75.78%] [G loss: 2.052603]\n",
      "epoch:23 step:22263 [D loss: 0.873850, acc.: 43.75%] [G loss: 1.662033]\n",
      "epoch:23 step:22264 [D loss: 0.155978, acc.: 100.00%] [G loss: 1.403724]\n",
      "epoch:23 step:22265 [D loss: 0.210266, acc.: 95.31%] [G loss: 1.880044]\n",
      "epoch:23 step:22266 [D loss: 1.000597, acc.: 48.44%] [G loss: 1.390743]\n",
      "epoch:23 step:22267 [D loss: 0.715156, acc.: 54.69%] [G loss: 1.341073]\n",
      "epoch:23 step:22268 [D loss: 0.801697, acc.: 55.47%] [G loss: 1.152421]\n",
      "epoch:23 step:22269 [D loss: 0.591198, acc.: 67.97%] [G loss: 1.070524]\n",
      "epoch:23 step:22270 [D loss: 0.491904, acc.: 76.56%] [G loss: 1.336918]\n",
      "epoch:23 step:22271 [D loss: 0.446069, acc.: 82.81%] [G loss: 1.509806]\n",
      "epoch:23 step:22272 [D loss: 0.474025, acc.: 79.69%] [G loss: 1.272210]\n",
      "epoch:23 step:22273 [D loss: 0.834200, acc.: 52.34%] [G loss: 1.101439]\n",
      "epoch:23 step:22274 [D loss: 0.525725, acc.: 72.66%] [G loss: 1.037528]\n",
      "epoch:23 step:22275 [D loss: 0.745202, acc.: 59.38%] [G loss: 1.540772]\n",
      "epoch:23 step:22276 [D loss: 0.468321, acc.: 81.25%] [G loss: 1.707770]\n",
      "epoch:23 step:22277 [D loss: 0.192129, acc.: 97.66%] [G loss: 2.076097]\n",
      "epoch:23 step:22278 [D loss: 0.662358, acc.: 61.72%] [G loss: 1.713469]\n",
      "epoch:23 step:22279 [D loss: 0.242009, acc.: 96.09%] [G loss: 1.776479]\n",
      "epoch:23 step:22280 [D loss: 0.419190, acc.: 76.56%] [G loss: 1.417689]\n",
      "epoch:23 step:22281 [D loss: 0.314367, acc.: 89.06%] [G loss: 1.860049]\n",
      "epoch:23 step:22282 [D loss: 0.446459, acc.: 82.03%] [G loss: 1.559682]\n",
      "epoch:23 step:22283 [D loss: 0.346421, acc.: 89.06%] [G loss: 1.440501]\n",
      "epoch:23 step:22284 [D loss: 0.225004, acc.: 94.53%] [G loss: 0.571081]\n",
      "epoch:23 step:22285 [D loss: 0.884480, acc.: 46.88%] [G loss: 1.668727]\n",
      "epoch:23 step:22286 [D loss: 0.532453, acc.: 74.22%] [G loss: 1.297261]\n",
      "epoch:23 step:22287 [D loss: 0.816188, acc.: 57.81%] [G loss: 1.698353]\n",
      "epoch:23 step:22288 [D loss: 0.761593, acc.: 55.47%] [G loss: 2.252488]\n",
      "epoch:23 step:22289 [D loss: 0.732945, acc.: 51.56%] [G loss: 1.786794]\n",
      "epoch:23 step:22290 [D loss: 0.708448, acc.: 64.06%] [G loss: 1.487369]\n",
      "epoch:23 step:22291 [D loss: 0.645414, acc.: 63.28%] [G loss: 0.812233]\n",
      "epoch:23 step:22292 [D loss: 0.276919, acc.: 88.28%] [G loss: 1.133046]\n",
      "epoch:23 step:22293 [D loss: 0.225144, acc.: 90.62%] [G loss: 0.894637]\n",
      "epoch:23 step:22294 [D loss: 0.182442, acc.: 92.97%] [G loss: 0.879181]\n",
      "epoch:23 step:22295 [D loss: 0.491556, acc.: 76.56%] [G loss: 2.190644]\n",
      "epoch:23 step:22296 [D loss: 0.892460, acc.: 56.25%] [G loss: 1.704332]\n",
      "epoch:23 step:22297 [D loss: 0.861711, acc.: 43.75%] [G loss: 1.680962]\n",
      "epoch:23 step:22298 [D loss: 0.430803, acc.: 78.91%] [G loss: 1.963162]\n",
      "epoch:23 step:22299 [D loss: 0.207573, acc.: 96.09%] [G loss: 1.943398]\n",
      "epoch:23 step:22300 [D loss: 0.123094, acc.: 98.44%] [G loss: 2.369409]\n",
      "epoch:23 step:22301 [D loss: 0.158066, acc.: 96.09%] [G loss: 3.060045]\n",
      "epoch:23 step:22302 [D loss: 0.499447, acc.: 65.62%] [G loss: 2.999517]\n",
      "epoch:23 step:22303 [D loss: 0.907368, acc.: 52.34%] [G loss: 2.236613]\n",
      "epoch:23 step:22304 [D loss: 0.651881, acc.: 61.72%] [G loss: 1.717141]\n",
      "epoch:23 step:22305 [D loss: 0.737481, acc.: 54.69%] [G loss: 1.675552]\n",
      "epoch:23 step:22306 [D loss: 0.998440, acc.: 40.62%] [G loss: 1.485969]\n",
      "epoch:23 step:22307 [D loss: 0.776141, acc.: 53.91%] [G loss: 1.053490]\n",
      "epoch:23 step:22308 [D loss: 0.640954, acc.: 68.75%] [G loss: 1.408822]\n",
      "epoch:23 step:22309 [D loss: 0.569392, acc.: 71.09%] [G loss: 1.445330]\n",
      "epoch:23 step:22310 [D loss: 0.247433, acc.: 92.19%] [G loss: 1.772578]\n",
      "epoch:23 step:22311 [D loss: 0.336422, acc.: 83.59%] [G loss: 1.275587]\n",
      "epoch:23 step:22312 [D loss: 0.438519, acc.: 86.72%] [G loss: 1.408911]\n",
      "epoch:23 step:22313 [D loss: 0.894740, acc.: 45.31%] [G loss: 1.518131]\n",
      "epoch:23 step:22314 [D loss: 0.727877, acc.: 56.25%] [G loss: 1.410452]\n",
      "epoch:23 step:22315 [D loss: 0.688715, acc.: 60.94%] [G loss: 1.136774]\n",
      "epoch:23 step:22316 [D loss: 0.336380, acc.: 83.59%] [G loss: 0.899485]\n",
      "epoch:23 step:22317 [D loss: 0.363905, acc.: 81.25%] [G loss: 1.140303]\n",
      "epoch:23 step:22318 [D loss: 0.274453, acc.: 90.62%] [G loss: 1.763589]\n",
      "epoch:23 step:22319 [D loss: 0.162793, acc.: 98.44%] [G loss: 1.144248]\n",
      "epoch:23 step:22320 [D loss: 0.148583, acc.: 97.66%] [G loss: 1.983933]\n",
      "epoch:23 step:22321 [D loss: 0.589934, acc.: 63.28%] [G loss: 1.756805]\n",
      "epoch:23 step:22322 [D loss: 1.004462, acc.: 35.94%] [G loss: 1.195589]\n",
      "epoch:23 step:22323 [D loss: 0.619027, acc.: 64.06%] [G loss: 1.593279]\n",
      "epoch:23 step:22324 [D loss: 1.047723, acc.: 32.81%] [G loss: 1.707955]\n",
      "epoch:23 step:22325 [D loss: 0.319631, acc.: 81.25%] [G loss: 1.451702]\n",
      "epoch:23 step:22326 [D loss: 0.167691, acc.: 98.44%] [G loss: 1.799762]\n",
      "epoch:23 step:22327 [D loss: 0.617972, acc.: 65.62%] [G loss: 1.795277]\n",
      "epoch:23 step:22328 [D loss: 0.261024, acc.: 96.09%] [G loss: 1.789245]\n",
      "epoch:23 step:22329 [D loss: 0.607321, acc.: 63.28%] [G loss: 0.551494]\n",
      "epoch:23 step:22330 [D loss: 0.804953, acc.: 51.56%] [G loss: 1.861059]\n",
      "epoch:23 step:22331 [D loss: 0.881881, acc.: 43.75%] [G loss: 1.380461]\n",
      "epoch:23 step:22332 [D loss: 0.815517, acc.: 51.56%] [G loss: 1.506082]\n",
      "epoch:23 step:22333 [D loss: 0.601659, acc.: 67.19%] [G loss: 1.240094]\n",
      "epoch:23 step:22334 [D loss: 0.528808, acc.: 73.44%] [G loss: 1.624355]\n",
      "epoch:23 step:22335 [D loss: 0.669269, acc.: 61.72%] [G loss: 1.280295]\n",
      "epoch:23 step:22336 [D loss: 0.554876, acc.: 73.44%] [G loss: 1.321033]\n",
      "epoch:23 step:22337 [D loss: 0.284943, acc.: 94.53%] [G loss: 1.386090]\n",
      "epoch:23 step:22338 [D loss: 0.705463, acc.: 53.12%] [G loss: 1.219521]\n",
      "epoch:23 step:22339 [D loss: 0.544010, acc.: 75.00%] [G loss: 1.327213]\n",
      "epoch:23 step:22340 [D loss: 0.823492, acc.: 51.56%] [G loss: 1.143527]\n",
      "epoch:23 step:22341 [D loss: 0.633566, acc.: 67.97%] [G loss: 0.977801]\n",
      "epoch:23 step:22342 [D loss: 0.230579, acc.: 94.53%] [G loss: 1.402206]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:23 step:22343 [D loss: 0.321594, acc.: 82.81%] [G loss: 1.213610]\n",
      "epoch:23 step:22344 [D loss: 0.280372, acc.: 92.97%] [G loss: 1.068631]\n",
      "epoch:23 step:22345 [D loss: 0.184945, acc.: 100.00%] [G loss: 1.424110]\n",
      "epoch:23 step:22346 [D loss: 0.282292, acc.: 94.53%] [G loss: 1.837788]\n",
      "epoch:23 step:22347 [D loss: 0.201448, acc.: 97.66%] [G loss: 1.477914]\n",
      "epoch:23 step:22348 [D loss: 0.616013, acc.: 67.19%] [G loss: 1.435688]\n",
      "epoch:23 step:22349 [D loss: 0.628821, acc.: 64.84%] [G loss: 1.434386]\n",
      "epoch:23 step:22350 [D loss: 0.648409, acc.: 64.84%] [G loss: 1.616090]\n",
      "epoch:23 step:22351 [D loss: 0.374161, acc.: 88.28%] [G loss: 1.441537]\n",
      "epoch:23 step:22352 [D loss: 0.472117, acc.: 77.34%] [G loss: 1.543776]\n",
      "epoch:23 step:22353 [D loss: 0.543569, acc.: 75.78%] [G loss: 1.261982]\n",
      "epoch:23 step:22354 [D loss: 0.552629, acc.: 69.53%] [G loss: 1.294200]\n",
      "epoch:23 step:22355 [D loss: 0.286034, acc.: 87.50%] [G loss: 1.547185]\n",
      "epoch:23 step:22356 [D loss: 0.193533, acc.: 96.88%] [G loss: 1.453626]\n",
      "epoch:23 step:22357 [D loss: 0.168788, acc.: 97.66%] [G loss: 1.433079]\n",
      "epoch:23 step:22358 [D loss: 0.770620, acc.: 52.34%] [G loss: 1.552415]\n",
      "epoch:23 step:22359 [D loss: 0.400144, acc.: 89.06%] [G loss: 1.321675]\n",
      "epoch:23 step:22360 [D loss: 0.320670, acc.: 94.53%] [G loss: 1.167414]\n",
      "epoch:23 step:22361 [D loss: 0.432310, acc.: 82.81%] [G loss: 0.965078]\n",
      "epoch:23 step:22362 [D loss: 0.794227, acc.: 50.00%] [G loss: 1.123210]\n",
      "epoch:23 step:22363 [D loss: 0.718747, acc.: 59.38%] [G loss: 1.136643]\n",
      "epoch:23 step:22364 [D loss: 0.778438, acc.: 50.78%] [G loss: 0.981478]\n",
      "epoch:23 step:22365 [D loss: 0.738353, acc.: 53.12%] [G loss: 1.009703]\n",
      "epoch:23 step:22366 [D loss: 0.270026, acc.: 92.97%] [G loss: 1.243035]\n",
      "epoch:23 step:22367 [D loss: 0.425734, acc.: 89.84%] [G loss: 1.385280]\n",
      "epoch:23 step:22368 [D loss: 0.744174, acc.: 54.69%] [G loss: 0.842045]\n",
      "epoch:23 step:22369 [D loss: 0.636039, acc.: 57.81%] [G loss: 1.082653]\n",
      "epoch:23 step:22370 [D loss: 0.653443, acc.: 58.59%] [G loss: 1.004114]\n",
      "epoch:23 step:22371 [D loss: 1.059123, acc.: 26.56%] [G loss: 1.021870]\n",
      "epoch:23 step:22372 [D loss: 0.284221, acc.: 92.19%] [G loss: 0.830912]\n",
      "epoch:23 step:22373 [D loss: 0.491937, acc.: 81.25%] [G loss: 1.357260]\n",
      "epoch:23 step:22374 [D loss: 0.594276, acc.: 70.31%] [G loss: 0.776703]\n",
      "epoch:23 step:22375 [D loss: 0.691656, acc.: 60.16%] [G loss: 1.155158]\n",
      "epoch:23 step:22376 [D loss: 0.603609, acc.: 64.06%] [G loss: 1.045418]\n",
      "epoch:23 step:22377 [D loss: 0.482217, acc.: 82.81%] [G loss: 1.158697]\n",
      "epoch:23 step:22378 [D loss: 0.533704, acc.: 75.00%] [G loss: 1.085838]\n",
      "epoch:23 step:22379 [D loss: 0.606489, acc.: 67.19%] [G loss: 1.136171]\n",
      "epoch:23 step:22380 [D loss: 0.469667, acc.: 80.47%] [G loss: 1.119671]\n",
      "epoch:23 step:22381 [D loss: 0.607293, acc.: 65.62%] [G loss: 1.092192]\n",
      "epoch:23 step:22382 [D loss: 0.481036, acc.: 83.59%] [G loss: 0.954739]\n",
      "epoch:23 step:22383 [D loss: 0.515047, acc.: 75.78%] [G loss: 1.104331]\n",
      "epoch:23 step:22384 [D loss: 0.648751, acc.: 62.50%] [G loss: 1.332526]\n",
      "epoch:23 step:22385 [D loss: 0.259417, acc.: 90.62%] [G loss: 1.356379]\n",
      "epoch:23 step:22386 [D loss: 0.479179, acc.: 81.25%] [G loss: 1.472571]\n",
      "epoch:23 step:22387 [D loss: 0.695601, acc.: 54.69%] [G loss: 1.365764]\n",
      "epoch:23 step:22388 [D loss: 0.717867, acc.: 58.59%] [G loss: 1.247008]\n",
      "epoch:23 step:22389 [D loss: 0.615899, acc.: 64.06%] [G loss: 1.003088]\n",
      "epoch:23 step:22390 [D loss: 0.585229, acc.: 66.41%] [G loss: 1.237638]\n",
      "epoch:23 step:22391 [D loss: 0.366767, acc.: 90.62%] [G loss: 1.255758]\n",
      "epoch:23 step:22392 [D loss: 0.191323, acc.: 97.66%] [G loss: 1.731384]\n",
      "epoch:23 step:22393 [D loss: 0.295812, acc.: 93.75%] [G loss: 1.618737]\n",
      "epoch:23 step:22394 [D loss: 0.881792, acc.: 44.53%] [G loss: 1.209144]\n",
      "epoch:23 step:22395 [D loss: 0.577295, acc.: 70.31%] [G loss: 1.267555]\n",
      "epoch:23 step:22396 [D loss: 0.345475, acc.: 92.19%] [G loss: 1.359619]\n",
      "epoch:23 step:22397 [D loss: 0.611509, acc.: 65.62%] [G loss: 1.029757]\n",
      "epoch:23 step:22398 [D loss: 0.371132, acc.: 80.47%] [G loss: 1.230503]\n",
      "epoch:23 step:22399 [D loss: 0.388090, acc.: 77.34%] [G loss: 1.434869]\n",
      "epoch:23 step:22400 [D loss: 0.353285, acc.: 86.72%] [G loss: 1.351433]\n",
      "##############\n",
      "[4.39739413 2.36086583 6.61496645 6.05819522 4.5818424  6.11806798\n",
      " 4.97733086 5.64368697 5.52074016 5.13569498]\n",
      "##########\n",
      "epoch:23 step:22401 [D loss: 0.183021, acc.: 98.44%] [G loss: 1.688560]\n",
      "epoch:23 step:22402 [D loss: 0.127761, acc.: 99.22%] [G loss: 1.318653]\n",
      "epoch:23 step:22403 [D loss: 0.162765, acc.: 98.44%] [G loss: 1.570421]\n",
      "epoch:23 step:22404 [D loss: 0.200794, acc.: 99.22%] [G loss: 1.980779]\n",
      "epoch:23 step:22405 [D loss: 0.115965, acc.: 100.00%] [G loss: 1.974951]\n",
      "epoch:23 step:22406 [D loss: 0.609359, acc.: 67.97%] [G loss: 1.968132]\n",
      "epoch:23 step:22407 [D loss: 0.571073, acc.: 68.75%] [G loss: 1.752037]\n",
      "epoch:23 step:22408 [D loss: 0.199744, acc.: 96.09%] [G loss: 1.455457]\n",
      "epoch:23 step:22409 [D loss: 0.380164, acc.: 85.94%] [G loss: 1.898989]\n",
      "epoch:23 step:22410 [D loss: 0.461029, acc.: 82.03%] [G loss: 1.778174]\n",
      "epoch:23 step:22411 [D loss: 0.570328, acc.: 71.09%] [G loss: 1.501879]\n",
      "epoch:23 step:22412 [D loss: 0.351798, acc.: 88.28%] [G loss: 1.243391]\n",
      "epoch:23 step:22413 [D loss: 0.693719, acc.: 57.03%] [G loss: 1.740896]\n",
      "epoch:23 step:22414 [D loss: 0.589989, acc.: 68.75%] [G loss: 1.011840]\n",
      "epoch:23 step:22415 [D loss: 0.844008, acc.: 45.31%] [G loss: 0.649540]\n",
      "epoch:23 step:22416 [D loss: 0.330770, acc.: 92.19%] [G loss: 1.378831]\n",
      "epoch:23 step:22417 [D loss: 0.563277, acc.: 71.09%] [G loss: 0.417946]\n",
      "epoch:23 step:22418 [D loss: 0.384654, acc.: 89.84%] [G loss: 0.806500]\n",
      "epoch:23 step:22419 [D loss: 0.715044, acc.: 53.91%] [G loss: 1.096988]\n",
      "epoch:23 step:22420 [D loss: 0.866029, acc.: 41.41%] [G loss: 1.496328]\n",
      "epoch:23 step:22421 [D loss: 0.898043, acc.: 43.75%] [G loss: 1.185407]\n",
      "epoch:23 step:22422 [D loss: 0.613684, acc.: 68.75%] [G loss: 1.335006]\n",
      "epoch:23 step:22423 [D loss: 0.520271, acc.: 78.12%] [G loss: 1.649836]\n",
      "epoch:23 step:22424 [D loss: 0.627413, acc.: 60.94%] [G loss: 1.120193]\n",
      "epoch:23 step:22425 [D loss: 0.784765, acc.: 51.56%] [G loss: 1.312645]\n",
      "epoch:23 step:22426 [D loss: 0.465394, acc.: 85.94%] [G loss: 1.243999]\n",
      "epoch:23 step:22427 [D loss: 0.570786, acc.: 67.97%] [G loss: 1.017150]\n",
      "epoch:23 step:22428 [D loss: 0.425411, acc.: 79.69%] [G loss: 1.250732]\n",
      "epoch:23 step:22429 [D loss: 0.222305, acc.: 94.53%] [G loss: 1.527440]\n",
      "epoch:23 step:22430 [D loss: 0.597016, acc.: 67.19%] [G loss: 1.638008]\n",
      "epoch:23 step:22431 [D loss: 0.850257, acc.: 47.66%] [G loss: 1.108074]\n",
      "epoch:23 step:22432 [D loss: 0.683631, acc.: 56.25%] [G loss: 1.314746]\n",
      "epoch:23 step:22433 [D loss: 0.294502, acc.: 89.84%] [G loss: 0.958072]\n",
      "epoch:23 step:22434 [D loss: 0.372229, acc.: 86.72%] [G loss: 0.943384]\n",
      "epoch:23 step:22435 [D loss: 0.269049, acc.: 92.97%] [G loss: 1.453441]\n",
      "epoch:23 step:22436 [D loss: 0.251331, acc.: 89.84%] [G loss: 1.722122]\n",
      "epoch:23 step:22437 [D loss: 0.167748, acc.: 98.44%] [G loss: 1.580070]\n",
      "epoch:23 step:22438 [D loss: 0.202580, acc.: 97.66%] [G loss: 1.473742]\n",
      "epoch:23 step:22439 [D loss: 0.934386, acc.: 52.34%] [G loss: 1.424073]\n",
      "epoch:23 step:22440 [D loss: 0.346802, acc.: 84.38%] [G loss: 1.524091]\n",
      "epoch:23 step:22441 [D loss: 0.223195, acc.: 97.66%] [G loss: 1.484816]\n",
      "epoch:23 step:22442 [D loss: 0.695579, acc.: 58.59%] [G loss: 1.505598]\n",
      "epoch:23 step:22443 [D loss: 0.636486, acc.: 61.72%] [G loss: 1.175757]\n",
      "epoch:23 step:22444 [D loss: 0.501934, acc.: 80.47%] [G loss: 1.035316]\n",
      "epoch:23 step:22445 [D loss: 0.345074, acc.: 88.28%] [G loss: 1.391072]\n",
      "epoch:23 step:22446 [D loss: 0.426344, acc.: 87.50%] [G loss: 1.129106]\n",
      "epoch:23 step:22447 [D loss: 0.268020, acc.: 94.53%] [G loss: 1.819882]\n",
      "epoch:23 step:22448 [D loss: 0.350039, acc.: 86.72%] [G loss: 1.714561]\n",
      "epoch:23 step:22449 [D loss: 0.170956, acc.: 96.88%] [G loss: 1.256570]\n",
      "epoch:23 step:22450 [D loss: 0.130437, acc.: 98.44%] [G loss: 2.045146]\n",
      "epoch:23 step:22451 [D loss: 0.099848, acc.: 99.22%] [G loss: 1.939417]\n",
      "epoch:23 step:22452 [D loss: 0.204377, acc.: 96.88%] [G loss: 2.180914]\n",
      "epoch:23 step:22453 [D loss: 0.781369, acc.: 53.12%] [G loss: 1.612320]\n",
      "epoch:23 step:22454 [D loss: 0.256280, acc.: 96.88%] [G loss: 2.278663]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:23 step:22455 [D loss: 0.448020, acc.: 75.00%] [G loss: 1.714639]\n",
      "epoch:23 step:22456 [D loss: 0.714912, acc.: 60.94%] [G loss: 1.874702]\n",
      "epoch:23 step:22457 [D loss: 0.275970, acc.: 94.53%] [G loss: 1.952940]\n",
      "epoch:23 step:22458 [D loss: 0.952095, acc.: 52.34%] [G loss: 1.598572]\n",
      "epoch:23 step:22459 [D loss: 0.703866, acc.: 55.47%] [G loss: 1.581129]\n",
      "epoch:23 step:22460 [D loss: 0.192019, acc.: 98.44%] [G loss: 1.649352]\n",
      "epoch:23 step:22461 [D loss: 0.527511, acc.: 71.88%] [G loss: 1.580123]\n",
      "epoch:23 step:22462 [D loss: 0.261481, acc.: 88.28%] [G loss: 1.906194]\n",
      "epoch:23 step:22463 [D loss: 0.249741, acc.: 89.84%] [G loss: 1.748877]\n",
      "epoch:23 step:22464 [D loss: 0.757981, acc.: 51.56%] [G loss: 1.647685]\n",
      "epoch:23 step:22465 [D loss: 0.844402, acc.: 42.97%] [G loss: 1.566390]\n",
      "epoch:23 step:22466 [D loss: 0.833336, acc.: 50.00%] [G loss: 1.304716]\n",
      "epoch:23 step:22467 [D loss: 0.419744, acc.: 81.25%] [G loss: 0.651388]\n",
      "epoch:23 step:22468 [D loss: 0.344983, acc.: 87.50%] [G loss: 1.240073]\n",
      "epoch:23 step:22469 [D loss: 0.873559, acc.: 41.41%] [G loss: 1.119231]\n",
      "epoch:23 step:22470 [D loss: 0.201856, acc.: 96.88%] [G loss: 0.197097]\n",
      "epoch:23 step:22471 [D loss: 0.556234, acc.: 72.66%] [G loss: 1.922111]\n",
      "epoch:23 step:22472 [D loss: 0.225319, acc.: 95.31%] [G loss: 1.957137]\n",
      "epoch:23 step:22473 [D loss: 0.598867, acc.: 65.62%] [G loss: 1.802989]\n",
      "epoch:23 step:22474 [D loss: 0.439111, acc.: 79.69%] [G loss: 1.667418]\n",
      "epoch:23 step:22475 [D loss: 0.274994, acc.: 89.06%] [G loss: 2.024547]\n",
      "epoch:23 step:22476 [D loss: 0.266545, acc.: 92.97%] [G loss: 1.564771]\n",
      "epoch:23 step:22477 [D loss: 0.144884, acc.: 100.00%] [G loss: 1.959045]\n",
      "epoch:23 step:22478 [D loss: 0.296912, acc.: 86.72%] [G loss: 1.272299]\n",
      "epoch:23 step:22479 [D loss: 0.903111, acc.: 53.12%] [G loss: 1.568524]\n",
      "epoch:23 step:22480 [D loss: 0.149316, acc.: 96.09%] [G loss: 1.509908]\n",
      "epoch:23 step:22481 [D loss: 0.632056, acc.: 62.50%] [G loss: 1.521183]\n",
      "epoch:23 step:22482 [D loss: 0.545107, acc.: 74.22%] [G loss: 1.508329]\n",
      "epoch:23 step:22483 [D loss: 0.384006, acc.: 84.38%] [G loss: 1.269938]\n",
      "epoch:23 step:22484 [D loss: 0.226900, acc.: 93.75%] [G loss: 1.099661]\n",
      "epoch:23 step:22485 [D loss: 0.116624, acc.: 99.22%] [G loss: 1.068826]\n",
      "epoch:23 step:22486 [D loss: 0.448275, acc.: 78.12%] [G loss: 1.433473]\n",
      "epoch:23 step:22487 [D loss: 0.121313, acc.: 100.00%] [G loss: 1.907601]\n",
      "epoch:23 step:22488 [D loss: 0.121275, acc.: 97.66%] [G loss: 1.914594]\n",
      "epoch:24 step:22489 [D loss: 0.691456, acc.: 54.69%] [G loss: 2.267432]\n",
      "epoch:24 step:22490 [D loss: 0.642602, acc.: 62.50%] [G loss: 1.477624]\n",
      "epoch:24 step:22491 [D loss: 0.876769, acc.: 39.06%] [G loss: 1.752067]\n",
      "epoch:24 step:22492 [D loss: 0.702614, acc.: 56.25%] [G loss: 1.249785]\n",
      "epoch:24 step:22493 [D loss: 0.840044, acc.: 36.72%] [G loss: 0.914697]\n",
      "epoch:24 step:22494 [D loss: 0.508658, acc.: 79.69%] [G loss: 1.115374]\n",
      "epoch:24 step:22495 [D loss: 0.901809, acc.: 53.91%] [G loss: 0.904263]\n",
      "epoch:24 step:22496 [D loss: 0.319507, acc.: 92.19%] [G loss: 1.340153]\n",
      "epoch:24 step:22497 [D loss: 0.428918, acc.: 82.81%] [G loss: 0.929535]\n",
      "epoch:24 step:22498 [D loss: 0.216868, acc.: 98.44%] [G loss: 1.205741]\n",
      "epoch:24 step:22499 [D loss: 0.285720, acc.: 90.62%] [G loss: 0.733668]\n",
      "epoch:24 step:22500 [D loss: 1.289089, acc.: 46.88%] [G loss: 1.647198]\n",
      "epoch:24 step:22501 [D loss: 0.394841, acc.: 85.94%] [G loss: 2.317867]\n",
      "epoch:24 step:22502 [D loss: 0.658998, acc.: 60.16%] [G loss: 2.349319]\n",
      "epoch:24 step:22503 [D loss: 0.536091, acc.: 72.66%] [G loss: 1.795910]\n",
      "epoch:24 step:22504 [D loss: 0.805870, acc.: 51.56%] [G loss: 0.427717]\n",
      "epoch:24 step:22505 [D loss: 0.743939, acc.: 57.03%] [G loss: 2.037752]\n",
      "epoch:24 step:22506 [D loss: 0.561445, acc.: 72.66%] [G loss: 1.681515]\n",
      "epoch:24 step:22507 [D loss: 0.949627, acc.: 46.09%] [G loss: 0.896420]\n",
      "epoch:24 step:22508 [D loss: 1.489638, acc.: 17.19%] [G loss: 0.625661]\n",
      "epoch:24 step:22509 [D loss: 0.954343, acc.: 35.94%] [G loss: 2.012702]\n",
      "epoch:24 step:22510 [D loss: 0.662766, acc.: 60.94%] [G loss: 1.565076]\n",
      "epoch:24 step:22511 [D loss: 1.111259, acc.: 22.66%] [G loss: 1.766883]\n",
      "epoch:24 step:22512 [D loss: 0.756794, acc.: 50.00%] [G loss: 1.456604]\n",
      "epoch:24 step:22513 [D loss: 0.424746, acc.: 85.16%] [G loss: 0.982736]\n",
      "epoch:24 step:22514 [D loss: 1.045939, acc.: 20.31%] [G loss: 0.942977]\n",
      "epoch:24 step:22515 [D loss: 0.249635, acc.: 90.62%] [G loss: 1.620929]\n",
      "epoch:24 step:22516 [D loss: 0.383924, acc.: 85.94%] [G loss: 1.732562]\n",
      "epoch:24 step:22517 [D loss: 0.466606, acc.: 78.12%] [G loss: 2.136568]\n",
      "epoch:24 step:22518 [D loss: 0.544555, acc.: 67.97%] [G loss: 1.612659]\n",
      "epoch:24 step:22519 [D loss: 0.229048, acc.: 92.19%] [G loss: 1.841562]\n",
      "epoch:24 step:22520 [D loss: 0.207119, acc.: 96.09%] [G loss: 2.100050]\n",
      "epoch:24 step:22521 [D loss: 0.120054, acc.: 98.44%] [G loss: 2.156946]\n",
      "epoch:24 step:22522 [D loss: 0.173255, acc.: 98.44%] [G loss: 1.671739]\n",
      "epoch:24 step:22523 [D loss: 0.070835, acc.: 100.00%] [G loss: 2.159554]\n",
      "epoch:24 step:22524 [D loss: 0.064270, acc.: 100.00%] [G loss: 2.220944]\n",
      "epoch:24 step:22525 [D loss: 1.070641, acc.: 50.00%] [G loss: 1.799583]\n",
      "epoch:24 step:22526 [D loss: 0.992299, acc.: 38.28%] [G loss: 1.373777]\n",
      "epoch:24 step:22527 [D loss: 0.945672, acc.: 38.28%] [G loss: 1.318243]\n",
      "epoch:24 step:22528 [D loss: 0.762223, acc.: 54.69%] [G loss: 0.892888]\n",
      "epoch:24 step:22529 [D loss: 0.553408, acc.: 74.22%] [G loss: 1.170337]\n",
      "epoch:24 step:22530 [D loss: 0.512266, acc.: 72.66%] [G loss: 1.352724]\n",
      "epoch:24 step:22531 [D loss: 0.269451, acc.: 91.41%] [G loss: 1.579438]\n",
      "epoch:24 step:22532 [D loss: 0.385951, acc.: 87.50%] [G loss: 1.612935]\n",
      "epoch:24 step:22533 [D loss: 0.430730, acc.: 85.94%] [G loss: 1.623533]\n",
      "epoch:24 step:22534 [D loss: 0.232323, acc.: 96.88%] [G loss: 1.436625]\n",
      "epoch:24 step:22535 [D loss: 0.640047, acc.: 60.94%] [G loss: 1.611285]\n",
      "epoch:24 step:22536 [D loss: 0.696984, acc.: 57.03%] [G loss: 1.247508]\n",
      "epoch:24 step:22537 [D loss: 0.552952, acc.: 75.00%] [G loss: 1.443327]\n",
      "epoch:24 step:22538 [D loss: 0.386192, acc.: 86.72%] [G loss: 1.211306]\n",
      "epoch:24 step:22539 [D loss: 0.296288, acc.: 92.97%] [G loss: 0.683816]\n",
      "epoch:24 step:22540 [D loss: 0.305584, acc.: 86.72%] [G loss: 0.906749]\n",
      "epoch:24 step:22541 [D loss: 0.538980, acc.: 72.66%] [G loss: 1.737699]\n",
      "epoch:24 step:22542 [D loss: 0.614292, acc.: 60.94%] [G loss: 1.421578]\n",
      "epoch:24 step:22543 [D loss: 0.593884, acc.: 66.41%] [G loss: 1.373214]\n",
      "epoch:24 step:22544 [D loss: 0.572192, acc.: 71.09%] [G loss: 0.818539]\n",
      "epoch:24 step:22545 [D loss: 0.346994, acc.: 80.47%] [G loss: 0.425326]\n",
      "epoch:24 step:22546 [D loss: 0.216782, acc.: 93.75%] [G loss: 1.156649]\n",
      "epoch:24 step:22547 [D loss: 0.272608, acc.: 93.75%] [G loss: 1.513506]\n",
      "epoch:24 step:22548 [D loss: 0.283646, acc.: 86.72%] [G loss: 1.997681]\n",
      "epoch:24 step:22549 [D loss: 0.612724, acc.: 66.41%] [G loss: 2.054212]\n",
      "epoch:24 step:22550 [D loss: 0.728356, acc.: 56.25%] [G loss: 1.476071]\n",
      "epoch:24 step:22551 [D loss: 0.593748, acc.: 68.75%] [G loss: 1.894488]\n",
      "epoch:24 step:22552 [D loss: 0.858874, acc.: 46.09%] [G loss: 1.350069]\n",
      "epoch:24 step:22553 [D loss: 0.992450, acc.: 35.94%] [G loss: 0.456177]\n",
      "epoch:24 step:22554 [D loss: 0.591346, acc.: 69.53%] [G loss: 1.693873]\n",
      "epoch:24 step:22555 [D loss: 0.832295, acc.: 47.66%] [G loss: 1.458387]\n",
      "epoch:24 step:22556 [D loss: 0.899574, acc.: 45.31%] [G loss: 1.828808]\n",
      "epoch:24 step:22557 [D loss: 1.280275, acc.: 22.66%] [G loss: 1.501915]\n",
      "epoch:24 step:22558 [D loss: 0.807877, acc.: 54.69%] [G loss: 1.517225]\n",
      "epoch:24 step:22559 [D loss: 0.290097, acc.: 89.06%] [G loss: 1.693746]\n",
      "epoch:24 step:22560 [D loss: 0.546797, acc.: 75.00%] [G loss: 1.159477]\n",
      "epoch:24 step:22561 [D loss: 0.431988, acc.: 80.47%] [G loss: 0.712613]\n",
      "epoch:24 step:22562 [D loss: 0.641070, acc.: 63.28%] [G loss: 1.142241]\n",
      "epoch:24 step:22563 [D loss: 0.392817, acc.: 77.34%] [G loss: 1.542962]\n",
      "epoch:24 step:22564 [D loss: 0.185200, acc.: 96.09%] [G loss: 0.550090]\n",
      "epoch:24 step:22565 [D loss: 0.257425, acc.: 89.84%] [G loss: 2.103389]\n",
      "epoch:24 step:22566 [D loss: 1.597184, acc.: 16.41%] [G loss: 1.139461]\n",
      "epoch:24 step:22567 [D loss: 0.837527, acc.: 53.91%] [G loss: 1.752241]\n",
      "epoch:24 step:22568 [D loss: 0.910968, acc.: 41.41%] [G loss: 1.707632]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:24 step:22569 [D loss: 1.300978, acc.: 20.31%] [G loss: 1.493217]\n",
      "epoch:24 step:22570 [D loss: 0.593958, acc.: 67.97%] [G loss: 1.852912]\n",
      "epoch:24 step:22571 [D loss: 0.530131, acc.: 67.97%] [G loss: 2.230128]\n",
      "epoch:24 step:22572 [D loss: 0.617699, acc.: 64.84%] [G loss: 2.020419]\n",
      "epoch:24 step:22573 [D loss: 0.491300, acc.: 73.44%] [G loss: 2.164858]\n",
      "epoch:24 step:22574 [D loss: 0.639929, acc.: 68.75%] [G loss: 2.276605]\n",
      "epoch:24 step:22575 [D loss: 0.347095, acc.: 84.38%] [G loss: 2.191464]\n",
      "epoch:24 step:22576 [D loss: 0.382353, acc.: 87.50%] [G loss: 1.409684]\n",
      "epoch:24 step:22577 [D loss: 0.383999, acc.: 90.62%] [G loss: 1.283289]\n",
      "epoch:24 step:22578 [D loss: 0.455812, acc.: 81.25%] [G loss: 2.353058]\n",
      "epoch:24 step:22579 [D loss: 0.496724, acc.: 77.34%] [G loss: 1.916472]\n",
      "epoch:24 step:22580 [D loss: 0.340921, acc.: 91.41%] [G loss: 1.985842]\n",
      "epoch:24 step:22581 [D loss: 0.323983, acc.: 89.84%] [G loss: 1.520879]\n",
      "epoch:24 step:22582 [D loss: 0.568861, acc.: 75.78%] [G loss: 1.067778]\n",
      "epoch:24 step:22583 [D loss: 0.855063, acc.: 50.00%] [G loss: 0.974515]\n",
      "epoch:24 step:22584 [D loss: 0.557152, acc.: 71.88%] [G loss: 1.418594]\n",
      "epoch:24 step:22585 [D loss: 0.530624, acc.: 73.44%] [G loss: 1.794075]\n",
      "epoch:24 step:22586 [D loss: 0.825013, acc.: 47.66%] [G loss: 0.777768]\n",
      "epoch:24 step:22587 [D loss: 0.533962, acc.: 73.44%] [G loss: 0.879069]\n",
      "epoch:24 step:22588 [D loss: 0.752627, acc.: 53.91%] [G loss: 1.089903]\n",
      "epoch:24 step:22589 [D loss: 0.542509, acc.: 67.97%] [G loss: 0.979414]\n",
      "epoch:24 step:22590 [D loss: 0.598564, acc.: 69.53%] [G loss: 1.275317]\n",
      "epoch:24 step:22591 [D loss: 0.457024, acc.: 79.69%] [G loss: 1.382472]\n",
      "epoch:24 step:22592 [D loss: 0.540734, acc.: 69.53%] [G loss: 1.385708]\n",
      "epoch:24 step:22593 [D loss: 0.542913, acc.: 73.44%] [G loss: 1.432864]\n",
      "epoch:24 step:22594 [D loss: 0.579096, acc.: 71.88%] [G loss: 1.441133]\n",
      "epoch:24 step:22595 [D loss: 0.564679, acc.: 70.31%] [G loss: 2.097200]\n",
      "epoch:24 step:22596 [D loss: 0.518794, acc.: 75.78%] [G loss: 1.540245]\n",
      "epoch:24 step:22597 [D loss: 0.557931, acc.: 66.41%] [G loss: 1.325475]\n",
      "epoch:24 step:22598 [D loss: 0.620013, acc.: 64.84%] [G loss: 1.010625]\n",
      "epoch:24 step:22599 [D loss: 0.498731, acc.: 78.12%] [G loss: 0.857018]\n",
      "epoch:24 step:22600 [D loss: 0.446935, acc.: 78.91%] [G loss: 1.305017]\n",
      "##############\n",
      "[4.7681874  2.64681092 6.8108412  5.70556627 4.4522518  6.0758645\n",
      " 5.40204082 5.74634192 5.88107972 5.15732003]\n",
      "##########\n",
      "epoch:24 step:22601 [D loss: 0.372911, acc.: 89.06%] [G loss: 1.247571]\n",
      "epoch:24 step:22602 [D loss: 0.448157, acc.: 75.00%] [G loss: 1.627956]\n",
      "epoch:24 step:22603 [D loss: 0.433140, acc.: 83.59%] [G loss: 1.748557]\n",
      "epoch:24 step:22604 [D loss: 0.614719, acc.: 64.06%] [G loss: 1.216272]\n",
      "epoch:24 step:22605 [D loss: 0.909410, acc.: 43.75%] [G loss: 1.304049]\n",
      "epoch:24 step:22606 [D loss: 0.842694, acc.: 56.25%] [G loss: 1.446018]\n",
      "epoch:24 step:22607 [D loss: 0.306470, acc.: 91.41%] [G loss: 1.579022]\n",
      "epoch:24 step:22608 [D loss: 0.643247, acc.: 73.44%] [G loss: 1.188695]\n",
      "epoch:24 step:22609 [D loss: 0.426488, acc.: 84.38%] [G loss: 1.520678]\n",
      "epoch:24 step:22610 [D loss: 0.420108, acc.: 80.47%] [G loss: 1.361715]\n",
      "epoch:24 step:22611 [D loss: 0.676099, acc.: 57.81%] [G loss: 1.041523]\n",
      "epoch:24 step:22612 [D loss: 0.632950, acc.: 64.84%] [G loss: 1.408102]\n",
      "epoch:24 step:22613 [D loss: 0.643652, acc.: 62.50%] [G loss: 1.450613]\n",
      "epoch:24 step:22614 [D loss: 0.559393, acc.: 69.53%] [G loss: 1.500922]\n",
      "epoch:24 step:22615 [D loss: 0.676292, acc.: 54.69%] [G loss: 0.939508]\n",
      "epoch:24 step:22616 [D loss: 0.486237, acc.: 79.69%] [G loss: 1.200870]\n",
      "epoch:24 step:22617 [D loss: 0.368320, acc.: 89.06%] [G loss: 1.270464]\n",
      "epoch:24 step:22618 [D loss: 0.284698, acc.: 89.84%] [G loss: 1.429699]\n",
      "epoch:24 step:22619 [D loss: 0.677424, acc.: 61.72%] [G loss: 1.225930]\n",
      "epoch:24 step:22620 [D loss: 0.372278, acc.: 88.28%] [G loss: 1.661048]\n",
      "epoch:24 step:22621 [D loss: 0.447379, acc.: 80.47%] [G loss: 1.490773]\n",
      "epoch:24 step:22622 [D loss: 0.270666, acc.: 92.97%] [G loss: 1.406943]\n",
      "epoch:24 step:22623 [D loss: 0.376327, acc.: 87.50%] [G loss: 1.363627]\n",
      "epoch:24 step:22624 [D loss: 0.618626, acc.: 66.41%] [G loss: 1.430653]\n",
      "epoch:24 step:22625 [D loss: 0.554559, acc.: 71.09%] [G loss: 1.357700]\n",
      "epoch:24 step:22626 [D loss: 0.502261, acc.: 75.00%] [G loss: 0.961705]\n",
      "epoch:24 step:22627 [D loss: 0.507622, acc.: 77.34%] [G loss: 1.159808]\n",
      "epoch:24 step:22628 [D loss: 0.361161, acc.: 84.38%] [G loss: 1.284204]\n",
      "epoch:24 step:22629 [D loss: 0.360683, acc.: 89.06%] [G loss: 1.500056]\n",
      "epoch:24 step:22630 [D loss: 0.648424, acc.: 64.84%] [G loss: 1.007337]\n",
      "epoch:24 step:22631 [D loss: 0.306938, acc.: 88.28%] [G loss: 1.431616]\n",
      "epoch:24 step:22632 [D loss: 0.788169, acc.: 53.91%] [G loss: 1.399076]\n",
      "epoch:24 step:22633 [D loss: 0.199588, acc.: 96.88%] [G loss: 1.416216]\n",
      "epoch:24 step:22634 [D loss: 0.435724, acc.: 85.16%] [G loss: 1.646732]\n",
      "epoch:24 step:22635 [D loss: 0.609057, acc.: 73.44%] [G loss: 1.449359]\n",
      "epoch:24 step:22636 [D loss: 0.701596, acc.: 59.38%] [G loss: 1.218868]\n",
      "epoch:24 step:22637 [D loss: 0.639321, acc.: 60.16%] [G loss: 1.629834]\n",
      "epoch:24 step:22638 [D loss: 0.138322, acc.: 98.44%] [G loss: 1.804903]\n",
      "epoch:24 step:22639 [D loss: 0.202728, acc.: 99.22%] [G loss: 1.923734]\n",
      "epoch:24 step:22640 [D loss: 0.398331, acc.: 84.38%] [G loss: 1.755776]\n",
      "epoch:24 step:22641 [D loss: 0.805138, acc.: 50.00%] [G loss: 1.579763]\n",
      "epoch:24 step:22642 [D loss: 0.672156, acc.: 55.47%] [G loss: 1.360995]\n",
      "epoch:24 step:22643 [D loss: 0.568626, acc.: 69.53%] [G loss: 1.365705]\n",
      "epoch:24 step:22644 [D loss: 0.888484, acc.: 39.84%] [G loss: 1.367679]\n",
      "epoch:24 step:22645 [D loss: 0.546396, acc.: 71.09%] [G loss: 0.899976]\n",
      "epoch:24 step:22646 [D loss: 0.699525, acc.: 60.16%] [G loss: 1.105805]\n",
      "epoch:24 step:22647 [D loss: 0.853324, acc.: 42.19%] [G loss: 0.953758]\n",
      "epoch:24 step:22648 [D loss: 0.484762, acc.: 71.88%] [G loss: 1.359159]\n",
      "epoch:24 step:22649 [D loss: 0.575279, acc.: 71.88%] [G loss: 0.281665]\n",
      "epoch:24 step:22650 [D loss: 0.412728, acc.: 85.94%] [G loss: 1.269600]\n",
      "epoch:24 step:22651 [D loss: 0.438243, acc.: 83.59%] [G loss: 1.144764]\n",
      "epoch:24 step:22652 [D loss: 0.445053, acc.: 78.91%] [G loss: 1.300185]\n",
      "epoch:24 step:22653 [D loss: 1.449136, acc.: 42.97%] [G loss: 1.479814]\n",
      "epoch:24 step:22654 [D loss: 0.704762, acc.: 60.16%] [G loss: 1.299239]\n",
      "epoch:24 step:22655 [D loss: 0.705067, acc.: 63.28%] [G loss: 1.334938]\n",
      "epoch:24 step:22656 [D loss: 0.651016, acc.: 64.84%] [G loss: 1.344669]\n",
      "epoch:24 step:22657 [D loss: 0.655109, acc.: 63.28%] [G loss: 1.200478]\n",
      "epoch:24 step:22658 [D loss: 0.726243, acc.: 53.91%] [G loss: 1.025882]\n",
      "epoch:24 step:22659 [D loss: 0.714596, acc.: 64.06%] [G loss: 1.193295]\n",
      "epoch:24 step:22660 [D loss: 0.580603, acc.: 71.09%] [G loss: 1.221665]\n",
      "epoch:24 step:22661 [D loss: 0.651345, acc.: 60.94%] [G loss: 1.226142]\n",
      "epoch:24 step:22662 [D loss: 0.603847, acc.: 68.75%] [G loss: 0.928645]\n",
      "epoch:24 step:22663 [D loss: 0.681690, acc.: 61.72%] [G loss: 1.022117]\n",
      "epoch:24 step:22664 [D loss: 0.487628, acc.: 80.47%] [G loss: 1.040961]\n",
      "epoch:24 step:22665 [D loss: 0.714248, acc.: 56.25%] [G loss: 0.947453]\n",
      "epoch:24 step:22666 [D loss: 0.629895, acc.: 64.84%] [G loss: 0.873429]\n",
      "epoch:24 step:22667 [D loss: 0.571940, acc.: 70.31%] [G loss: 1.070990]\n",
      "epoch:24 step:22668 [D loss: 0.714825, acc.: 54.69%] [G loss: 1.242223]\n",
      "epoch:24 step:22669 [D loss: 0.605916, acc.: 64.84%] [G loss: 1.222488]\n",
      "epoch:24 step:22670 [D loss: 0.722157, acc.: 52.34%] [G loss: 1.022260]\n",
      "epoch:24 step:22671 [D loss: 0.632290, acc.: 63.28%] [G loss: 1.134552]\n",
      "epoch:24 step:22672 [D loss: 0.583006, acc.: 69.53%] [G loss: 1.072709]\n",
      "epoch:24 step:22673 [D loss: 0.473148, acc.: 77.34%] [G loss: 1.097754]\n",
      "epoch:24 step:22674 [D loss: 0.583262, acc.: 69.53%] [G loss: 1.299463]\n",
      "epoch:24 step:22675 [D loss: 0.743542, acc.: 56.25%] [G loss: 1.007089]\n",
      "epoch:24 step:22676 [D loss: 0.665864, acc.: 55.47%] [G loss: 1.073196]\n",
      "epoch:24 step:22677 [D loss: 0.637925, acc.: 63.28%] [G loss: 1.276891]\n",
      "epoch:24 step:22678 [D loss: 0.527403, acc.: 76.56%] [G loss: 1.110528]\n",
      "epoch:24 step:22679 [D loss: 0.589477, acc.: 67.19%] [G loss: 1.045549]\n",
      "epoch:24 step:22680 [D loss: 0.432905, acc.: 78.91%] [G loss: 1.527887]\n",
      "epoch:24 step:22681 [D loss: 0.435769, acc.: 81.25%] [G loss: 1.525849]\n",
      "epoch:24 step:22682 [D loss: 0.454925, acc.: 78.12%] [G loss: 1.258507]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:24 step:22683 [D loss: 0.470083, acc.: 78.91%] [G loss: 1.174213]\n",
      "epoch:24 step:22684 [D loss: 0.546218, acc.: 72.66%] [G loss: 1.336773]\n",
      "epoch:24 step:22685 [D loss: 0.392154, acc.: 79.69%] [G loss: 1.603557]\n",
      "epoch:24 step:22686 [D loss: 0.379170, acc.: 87.50%] [G loss: 1.157049]\n",
      "epoch:24 step:22687 [D loss: 0.690331, acc.: 57.03%] [G loss: 1.220749]\n",
      "epoch:24 step:22688 [D loss: 0.238684, acc.: 95.31%] [G loss: 1.234798]\n",
      "epoch:24 step:22689 [D loss: 0.188723, acc.: 95.31%] [G loss: 2.009234]\n",
      "epoch:24 step:22690 [D loss: 0.921388, acc.: 40.62%] [G loss: 1.785266]\n",
      "epoch:24 step:22691 [D loss: 0.344985, acc.: 89.84%] [G loss: 1.897141]\n",
      "epoch:24 step:22692 [D loss: 0.221817, acc.: 97.66%] [G loss: 1.329846]\n",
      "epoch:24 step:22693 [D loss: 0.399796, acc.: 89.84%] [G loss: 1.796751]\n",
      "epoch:24 step:22694 [D loss: 0.217950, acc.: 97.66%] [G loss: 1.530885]\n",
      "epoch:24 step:22695 [D loss: 0.306903, acc.: 87.50%] [G loss: 1.501601]\n",
      "epoch:24 step:22696 [D loss: 0.273539, acc.: 94.53%] [G loss: 2.572292]\n",
      "epoch:24 step:22697 [D loss: 0.664101, acc.: 63.28%] [G loss: 1.384944]\n",
      "epoch:24 step:22698 [D loss: 1.329615, acc.: 43.75%] [G loss: 1.435594]\n",
      "epoch:24 step:22699 [D loss: 1.071193, acc.: 36.72%] [G loss: 0.974275]\n",
      "epoch:24 step:22700 [D loss: 0.641200, acc.: 64.06%] [G loss: 1.295840]\n",
      "epoch:24 step:22701 [D loss: 0.703868, acc.: 56.25%] [G loss: 1.426746]\n",
      "epoch:24 step:22702 [D loss: 0.791661, acc.: 60.16%] [G loss: 1.263030]\n",
      "epoch:24 step:22703 [D loss: 0.736636, acc.: 57.03%] [G loss: 1.193330]\n",
      "epoch:24 step:22704 [D loss: 0.829235, acc.: 42.19%] [G loss: 1.172868]\n",
      "epoch:24 step:22705 [D loss: 0.553755, acc.: 74.22%] [G loss: 0.882571]\n",
      "epoch:24 step:22706 [D loss: 0.397120, acc.: 87.50%] [G loss: 1.202708]\n",
      "epoch:24 step:22707 [D loss: 0.371976, acc.: 89.06%] [G loss: 1.228673]\n",
      "epoch:24 step:22708 [D loss: 0.202111, acc.: 96.88%] [G loss: 1.282179]\n",
      "epoch:24 step:22709 [D loss: 0.203577, acc.: 96.88%] [G loss: 1.758998]\n",
      "epoch:24 step:22710 [D loss: 0.363849, acc.: 89.84%] [G loss: 1.378494]\n",
      "epoch:24 step:22711 [D loss: 0.324170, acc.: 92.19%] [G loss: 1.414363]\n",
      "epoch:24 step:22712 [D loss: 0.577511, acc.: 67.19%] [G loss: 1.257195]\n",
      "epoch:24 step:22713 [D loss: 0.399593, acc.: 85.94%] [G loss: 1.129160]\n",
      "epoch:24 step:22714 [D loss: 0.700953, acc.: 52.34%] [G loss: 1.362427]\n",
      "epoch:24 step:22715 [D loss: 0.565123, acc.: 71.88%] [G loss: 1.149172]\n",
      "epoch:24 step:22716 [D loss: 0.621525, acc.: 65.62%] [G loss: 1.305846]\n",
      "epoch:24 step:22717 [D loss: 0.646204, acc.: 56.25%] [G loss: 1.109490]\n",
      "epoch:24 step:22718 [D loss: 0.210964, acc.: 92.19%] [G loss: 1.091617]\n",
      "epoch:24 step:22719 [D loss: 0.186834, acc.: 96.88%] [G loss: 1.456975]\n",
      "epoch:24 step:22720 [D loss: 0.140366, acc.: 97.66%] [G loss: 1.650205]\n",
      "epoch:24 step:22721 [D loss: 0.512457, acc.: 78.12%] [G loss: 1.784721]\n",
      "epoch:24 step:22722 [D loss: 0.337660, acc.: 92.97%] [G loss: 1.600373]\n",
      "epoch:24 step:22723 [D loss: 0.298219, acc.: 93.75%] [G loss: 1.731171]\n",
      "epoch:24 step:22724 [D loss: 0.654257, acc.: 62.50%] [G loss: 1.213004]\n",
      "epoch:24 step:22725 [D loss: 0.335483, acc.: 87.50%] [G loss: 1.484913]\n",
      "epoch:24 step:22726 [D loss: 0.404343, acc.: 86.72%] [G loss: 0.837004]\n",
      "epoch:24 step:22727 [D loss: 0.516121, acc.: 70.31%] [G loss: 0.707822]\n",
      "epoch:24 step:22728 [D loss: 0.700638, acc.: 60.16%] [G loss: 0.930898]\n",
      "epoch:24 step:22729 [D loss: 0.769265, acc.: 50.00%] [G loss: 1.131361]\n",
      "epoch:24 step:22730 [D loss: 0.786323, acc.: 48.44%] [G loss: 1.512673]\n",
      "epoch:24 step:22731 [D loss: 0.298930, acc.: 96.09%] [G loss: 1.310585]\n",
      "epoch:24 step:22732 [D loss: 0.631661, acc.: 60.94%] [G loss: 1.201191]\n",
      "epoch:24 step:22733 [D loss: 0.714235, acc.: 57.81%] [G loss: 1.302475]\n",
      "epoch:24 step:22734 [D loss: 0.890091, acc.: 34.38%] [G loss: 0.701013]\n",
      "epoch:24 step:22735 [D loss: 0.619327, acc.: 65.62%] [G loss: 1.204094]\n",
      "epoch:24 step:22736 [D loss: 0.631778, acc.: 66.41%] [G loss: 0.597593]\n",
      "epoch:24 step:22737 [D loss: 0.673934, acc.: 58.59%] [G loss: 0.854461]\n",
      "epoch:24 step:22738 [D loss: 0.665540, acc.: 58.59%] [G loss: 1.027603]\n",
      "epoch:24 step:22739 [D loss: 0.548742, acc.: 74.22%] [G loss: 1.448022]\n",
      "epoch:24 step:22740 [D loss: 0.739060, acc.: 52.34%] [G loss: 1.516910]\n",
      "epoch:24 step:22741 [D loss: 0.599398, acc.: 66.41%] [G loss: 0.935407]\n",
      "epoch:24 step:22742 [D loss: 0.602064, acc.: 67.19%] [G loss: 1.112428]\n",
      "epoch:24 step:22743 [D loss: 0.391698, acc.: 83.59%] [G loss: 1.095340]\n",
      "epoch:24 step:22744 [D loss: 0.232500, acc.: 92.97%] [G loss: 0.933110]\n",
      "epoch:24 step:22745 [D loss: 0.353674, acc.: 91.41%] [G loss: 1.629640]\n",
      "epoch:24 step:22746 [D loss: 0.763569, acc.: 48.44%] [G loss: 0.772770]\n",
      "epoch:24 step:22747 [D loss: 0.240346, acc.: 90.62%] [G loss: 1.238301]\n",
      "epoch:24 step:22748 [D loss: 0.389793, acc.: 79.69%] [G loss: 0.727279]\n",
      "epoch:24 step:22749 [D loss: 0.284642, acc.: 89.84%] [G loss: 1.625738]\n",
      "epoch:24 step:22750 [D loss: 0.908795, acc.: 34.38%] [G loss: 1.671979]\n",
      "epoch:24 step:22751 [D loss: 0.520400, acc.: 71.09%] [G loss: 1.873392]\n",
      "epoch:24 step:22752 [D loss: 0.425087, acc.: 80.47%] [G loss: 1.653534]\n",
      "epoch:24 step:22753 [D loss: 0.529932, acc.: 74.22%] [G loss: 1.232881]\n",
      "epoch:24 step:22754 [D loss: 0.785117, acc.: 47.66%] [G loss: 1.758751]\n",
      "epoch:24 step:22755 [D loss: 0.610486, acc.: 62.50%] [G loss: 1.666326]\n",
      "epoch:24 step:22756 [D loss: 0.706694, acc.: 62.50%] [G loss: 1.443148]\n",
      "epoch:24 step:22757 [D loss: 0.326490, acc.: 90.62%] [G loss: 1.620380]\n",
      "epoch:24 step:22758 [D loss: 0.506403, acc.: 75.78%] [G loss: 1.539319]\n",
      "epoch:24 step:22759 [D loss: 0.354989, acc.: 92.19%] [G loss: 1.034855]\n",
      "epoch:24 step:22760 [D loss: 0.316106, acc.: 92.19%] [G loss: 1.288546]\n",
      "epoch:24 step:22761 [D loss: 0.419925, acc.: 86.72%] [G loss: 1.454788]\n",
      "epoch:24 step:22762 [D loss: 0.432126, acc.: 81.25%] [G loss: 1.781340]\n",
      "epoch:24 step:22763 [D loss: 0.393783, acc.: 84.38%] [G loss: 1.448028]\n",
      "epoch:24 step:22764 [D loss: 0.246195, acc.: 92.19%] [G loss: 1.756875]\n",
      "epoch:24 step:22765 [D loss: 0.577628, acc.: 71.88%] [G loss: 1.268879]\n",
      "epoch:24 step:22766 [D loss: 0.542277, acc.: 73.44%] [G loss: 1.344778]\n",
      "epoch:24 step:22767 [D loss: 0.131171, acc.: 100.00%] [G loss: 1.585324]\n",
      "epoch:24 step:22768 [D loss: 0.662759, acc.: 66.41%] [G loss: 1.783754]\n",
      "epoch:24 step:22769 [D loss: 0.723331, acc.: 60.16%] [G loss: 1.542437]\n",
      "epoch:24 step:22770 [D loss: 0.482592, acc.: 72.66%] [G loss: 1.685399]\n",
      "epoch:24 step:22771 [D loss: 0.512192, acc.: 71.88%] [G loss: 0.947410]\n",
      "epoch:24 step:22772 [D loss: 0.688144, acc.: 60.16%] [G loss: 1.034632]\n",
      "epoch:24 step:22773 [D loss: 0.602300, acc.: 71.88%] [G loss: 1.262981]\n",
      "epoch:24 step:22774 [D loss: 1.191817, acc.: 47.66%] [G loss: 1.782691]\n",
      "epoch:24 step:22775 [D loss: 0.491470, acc.: 75.78%] [G loss: 1.843039]\n",
      "epoch:24 step:22776 [D loss: 0.545552, acc.: 73.44%] [G loss: 1.315669]\n",
      "epoch:24 step:22777 [D loss: 0.259504, acc.: 94.53%] [G loss: 1.710447]\n",
      "epoch:24 step:22778 [D loss: 0.617723, acc.: 65.62%] [G loss: 1.550733]\n",
      "epoch:24 step:22779 [D loss: 0.694762, acc.: 60.16%] [G loss: 1.259091]\n",
      "epoch:24 step:22780 [D loss: 0.379355, acc.: 88.28%] [G loss: 1.620825]\n",
      "epoch:24 step:22781 [D loss: 0.316851, acc.: 89.06%] [G loss: 0.916062]\n",
      "epoch:24 step:22782 [D loss: 0.782772, acc.: 55.47%] [G loss: 1.196460]\n",
      "epoch:24 step:22783 [D loss: 0.595759, acc.: 69.53%] [G loss: 1.177255]\n",
      "epoch:24 step:22784 [D loss: 0.578479, acc.: 70.31%] [G loss: 1.033342]\n",
      "epoch:24 step:22785 [D loss: 0.415369, acc.: 77.34%] [G loss: 1.559806]\n",
      "epoch:24 step:22786 [D loss: 0.201488, acc.: 98.44%] [G loss: 1.311034]\n",
      "epoch:24 step:22787 [D loss: 0.271565, acc.: 89.06%] [G loss: 1.337709]\n",
      "epoch:24 step:22788 [D loss: 0.272323, acc.: 94.53%] [G loss: 1.801412]\n",
      "epoch:24 step:22789 [D loss: 0.701920, acc.: 58.59%] [G loss: 0.999564]\n",
      "epoch:24 step:22790 [D loss: 0.680027, acc.: 60.94%] [G loss: 1.107845]\n",
      "epoch:24 step:22791 [D loss: 0.573597, acc.: 71.88%] [G loss: 1.285113]\n",
      "epoch:24 step:22792 [D loss: 0.588300, acc.: 67.19%] [G loss: 1.575655]\n",
      "epoch:24 step:22793 [D loss: 0.579993, acc.: 67.97%] [G loss: 1.199683]\n",
      "epoch:24 step:22794 [D loss: 0.548932, acc.: 73.44%] [G loss: 0.829195]\n",
      "epoch:24 step:22795 [D loss: 0.382891, acc.: 82.03%] [G loss: 1.228163]\n",
      "epoch:24 step:22796 [D loss: 0.733996, acc.: 57.81%] [G loss: 1.395473]\n",
      "epoch:24 step:22797 [D loss: 0.346822, acc.: 89.84%] [G loss: 0.369718]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:24 step:22798 [D loss: 0.568614, acc.: 70.31%] [G loss: 0.387127]\n",
      "epoch:24 step:22799 [D loss: 0.711740, acc.: 57.81%] [G loss: 1.122786]\n",
      "epoch:24 step:22800 [D loss: 0.290943, acc.: 91.41%] [G loss: 1.134395]\n",
      "##############\n",
      "[3.79566472 2.41945996 6.65063427 5.90049043 4.49472105 6.1212961\n",
      " 5.1517085  5.54806145 5.76915954 4.89032497]\n",
      "##########\n",
      "epoch:24 step:22801 [D loss: 0.237954, acc.: 95.31%] [G loss: 1.264577]\n",
      "epoch:24 step:22802 [D loss: 0.203288, acc.: 96.88%] [G loss: 1.425081]\n",
      "epoch:24 step:22803 [D loss: 0.378718, acc.: 88.28%] [G loss: 1.500091]\n",
      "epoch:24 step:22804 [D loss: 0.251250, acc.: 96.88%] [G loss: 1.642985]\n",
      "epoch:24 step:22805 [D loss: 0.392718, acc.: 89.06%] [G loss: 1.475212]\n",
      "epoch:24 step:22806 [D loss: 0.290435, acc.: 96.09%] [G loss: 1.538596]\n",
      "epoch:24 step:22807 [D loss: 0.330197, acc.: 92.19%] [G loss: 0.446929]\n",
      "epoch:24 step:22808 [D loss: 0.263554, acc.: 97.66%] [G loss: 1.173023]\n",
      "epoch:24 step:22809 [D loss: 0.260169, acc.: 94.53%] [G loss: 1.235617]\n",
      "epoch:24 step:22810 [D loss: 0.281246, acc.: 89.06%] [G loss: 1.865580]\n",
      "epoch:24 step:22811 [D loss: 0.776758, acc.: 58.59%] [G loss: 1.067512]\n",
      "epoch:24 step:22812 [D loss: 0.651335, acc.: 61.72%] [G loss: 1.131837]\n",
      "epoch:24 step:22813 [D loss: 0.476207, acc.: 75.78%] [G loss: 1.435444]\n",
      "epoch:24 step:22814 [D loss: 0.421039, acc.: 79.69%] [G loss: 1.758766]\n",
      "epoch:24 step:22815 [D loss: 0.253010, acc.: 90.62%] [G loss: 1.801292]\n",
      "epoch:24 step:22816 [D loss: 0.145291, acc.: 98.44%] [G loss: 2.371268]\n",
      "epoch:24 step:22817 [D loss: 0.242322, acc.: 94.53%] [G loss: 1.941174]\n",
      "epoch:24 step:22818 [D loss: 0.892723, acc.: 50.78%] [G loss: 1.528673]\n",
      "epoch:24 step:22819 [D loss: 0.536024, acc.: 76.56%] [G loss: 1.251156]\n",
      "epoch:24 step:22820 [D loss: 1.555665, acc.: 9.38%] [G loss: 0.935914]\n",
      "epoch:24 step:22821 [D loss: 0.694972, acc.: 64.84%] [G loss: 1.307406]\n",
      "epoch:24 step:22822 [D loss: 0.332579, acc.: 86.72%] [G loss: 1.208689]\n",
      "epoch:24 step:22823 [D loss: 0.952709, acc.: 35.94%] [G loss: 1.202460]\n",
      "epoch:24 step:22824 [D loss: 0.274546, acc.: 94.53%] [G loss: 1.306520]\n",
      "epoch:24 step:22825 [D loss: 0.565790, acc.: 71.09%] [G loss: 1.186213]\n",
      "epoch:24 step:22826 [D loss: 0.595979, acc.: 64.06%] [G loss: 0.739794]\n",
      "epoch:24 step:22827 [D loss: 0.469058, acc.: 79.69%] [G loss: 1.203808]\n",
      "epoch:24 step:22828 [D loss: 0.849717, acc.: 49.22%] [G loss: 1.060277]\n",
      "epoch:24 step:22829 [D loss: 0.948886, acc.: 39.84%] [G loss: 0.765005]\n",
      "epoch:24 step:22830 [D loss: 0.280309, acc.: 91.41%] [G loss: 0.816781]\n",
      "epoch:24 step:22831 [D loss: 0.317467, acc.: 79.69%] [G loss: 1.059283]\n",
      "epoch:24 step:22832 [D loss: 0.272114, acc.: 92.19%] [G loss: 1.063823]\n",
      "epoch:24 step:22833 [D loss: 0.326946, acc.: 85.94%] [G loss: 1.722525]\n",
      "epoch:24 step:22834 [D loss: 0.149836, acc.: 96.88%] [G loss: 1.316344]\n",
      "epoch:24 step:22835 [D loss: 0.113805, acc.: 99.22%] [G loss: 1.973149]\n",
      "epoch:24 step:22836 [D loss: 0.915196, acc.: 45.31%] [G loss: 1.625957]\n",
      "epoch:24 step:22837 [D loss: 0.704006, acc.: 62.50%] [G loss: 1.435017]\n",
      "epoch:24 step:22838 [D loss: 0.716386, acc.: 54.69%] [G loss: 1.226397]\n",
      "epoch:24 step:22839 [D loss: 0.451143, acc.: 80.47%] [G loss: 1.477930]\n",
      "epoch:24 step:22840 [D loss: 0.509425, acc.: 76.56%] [G loss: 1.539940]\n",
      "epoch:24 step:22841 [D loss: 0.475451, acc.: 84.38%] [G loss: 1.647963]\n",
      "epoch:24 step:22842 [D loss: 0.413266, acc.: 86.72%] [G loss: 1.312526]\n",
      "epoch:24 step:22843 [D loss: 0.656249, acc.: 64.84%] [G loss: 1.418047]\n",
      "epoch:24 step:22844 [D loss: 0.587044, acc.: 67.97%] [G loss: 0.494151]\n",
      "epoch:24 step:22845 [D loss: 0.543272, acc.: 75.00%] [G loss: 1.607508]\n",
      "epoch:24 step:22846 [D loss: 0.709646, acc.: 61.72%] [G loss: 1.663555]\n",
      "epoch:24 step:22847 [D loss: 0.404642, acc.: 91.41%] [G loss: 1.740831]\n",
      "epoch:24 step:22848 [D loss: 0.561088, acc.: 71.09%] [G loss: 1.269648]\n",
      "epoch:24 step:22849 [D loss: 0.648568, acc.: 60.16%] [G loss: 1.605732]\n",
      "epoch:24 step:22850 [D loss: 0.441147, acc.: 82.81%] [G loss: 1.738403]\n",
      "epoch:24 step:22851 [D loss: 0.492566, acc.: 77.34%] [G loss: 1.061969]\n",
      "epoch:24 step:22852 [D loss: 0.620373, acc.: 67.97%] [G loss: 1.362143]\n",
      "epoch:24 step:22853 [D loss: 0.264160, acc.: 87.50%] [G loss: 1.384437]\n",
      "epoch:24 step:22854 [D loss: 0.187090, acc.: 94.53%] [G loss: 1.798850]\n",
      "epoch:24 step:22855 [D loss: 0.347178, acc.: 87.50%] [G loss: 1.788139]\n",
      "epoch:24 step:22856 [D loss: 0.701190, acc.: 60.16%] [G loss: 1.510748]\n",
      "epoch:24 step:22857 [D loss: 0.663568, acc.: 62.50%] [G loss: 1.141882]\n",
      "epoch:24 step:22858 [D loss: 0.505829, acc.: 81.25%] [G loss: 1.058832]\n",
      "epoch:24 step:22859 [D loss: 0.495598, acc.: 79.69%] [G loss: 1.234650]\n",
      "epoch:24 step:22860 [D loss: 0.669660, acc.: 61.72%] [G loss: 1.276109]\n",
      "epoch:24 step:22861 [D loss: 0.686756, acc.: 55.47%] [G loss: 1.301790]\n",
      "epoch:24 step:22862 [D loss: 0.792686, acc.: 53.12%] [G loss: 0.976981]\n",
      "epoch:24 step:22863 [D loss: 0.629504, acc.: 65.62%] [G loss: 1.227149]\n",
      "epoch:24 step:22864 [D loss: 0.794022, acc.: 51.56%] [G loss: 1.371418]\n",
      "epoch:24 step:22865 [D loss: 0.238278, acc.: 89.06%] [G loss: 1.646832]\n",
      "epoch:24 step:22866 [D loss: 0.134798, acc.: 100.00%] [G loss: 1.615969]\n",
      "epoch:24 step:22867 [D loss: 0.841484, acc.: 52.34%] [G loss: 1.387954]\n",
      "epoch:24 step:22868 [D loss: 0.559251, acc.: 68.75%] [G loss: 1.052273]\n",
      "epoch:24 step:22869 [D loss: 0.513370, acc.: 72.66%] [G loss: 1.257554]\n",
      "epoch:24 step:22870 [D loss: 0.661612, acc.: 55.47%] [G loss: 1.135394]\n",
      "epoch:24 step:22871 [D loss: 0.740262, acc.: 52.34%] [G loss: 1.182748]\n",
      "epoch:24 step:22872 [D loss: 0.434523, acc.: 85.16%] [G loss: 1.353536]\n",
      "epoch:24 step:22873 [D loss: 0.682862, acc.: 53.91%] [G loss: 1.435545]\n",
      "epoch:24 step:22874 [D loss: 0.656972, acc.: 63.28%] [G loss: 1.179167]\n",
      "epoch:24 step:22875 [D loss: 0.594007, acc.: 67.97%] [G loss: 1.160104]\n",
      "epoch:24 step:22876 [D loss: 0.490771, acc.: 78.91%] [G loss: 1.308758]\n",
      "epoch:24 step:22877 [D loss: 0.270532, acc.: 91.41%] [G loss: 1.476085]\n",
      "epoch:24 step:22878 [D loss: 0.274804, acc.: 96.88%] [G loss: 1.057403]\n",
      "epoch:24 step:22879 [D loss: 0.548722, acc.: 73.44%] [G loss: 1.176355]\n",
      "epoch:24 step:22880 [D loss: 0.496967, acc.: 80.47%] [G loss: 1.616760]\n",
      "epoch:24 step:22881 [D loss: 0.293877, acc.: 90.62%] [G loss: 0.893946]\n",
      "epoch:24 step:22882 [D loss: 0.618948, acc.: 66.41%] [G loss: 1.156411]\n",
      "epoch:24 step:22883 [D loss: 0.701760, acc.: 56.25%] [G loss: 1.568248]\n",
      "epoch:24 step:22884 [D loss: 0.519941, acc.: 65.62%] [G loss: 1.639938]\n",
      "epoch:24 step:22885 [D loss: 0.109528, acc.: 100.00%] [G loss: 1.836061]\n",
      "epoch:24 step:22886 [D loss: 0.121191, acc.: 97.66%] [G loss: 2.143280]\n",
      "epoch:24 step:22887 [D loss: 0.122078, acc.: 97.66%] [G loss: 2.242450]\n",
      "epoch:24 step:22888 [D loss: 0.132669, acc.: 99.22%] [G loss: 1.411401]\n",
      "epoch:24 step:22889 [D loss: 0.140548, acc.: 98.44%] [G loss: 1.891332]\n",
      "epoch:24 step:22890 [D loss: 0.507206, acc.: 67.97%] [G loss: 2.619744]\n",
      "epoch:24 step:22891 [D loss: 0.173817, acc.: 100.00%] [G loss: 2.494821]\n",
      "epoch:24 step:22892 [D loss: 0.364073, acc.: 89.06%] [G loss: 1.875648]\n",
      "epoch:24 step:22893 [D loss: 0.227495, acc.: 89.84%] [G loss: 2.184080]\n",
      "epoch:24 step:22894 [D loss: 0.058978, acc.: 99.22%] [G loss: 2.818628]\n",
      "epoch:24 step:22895 [D loss: 0.051763, acc.: 100.00%] [G loss: 2.781998]\n",
      "epoch:24 step:22896 [D loss: 0.141521, acc.: 100.00%] [G loss: 2.222568]\n",
      "epoch:24 step:22897 [D loss: 0.064128, acc.: 100.00%] [G loss: 2.828883]\n",
      "epoch:24 step:22898 [D loss: 0.094466, acc.: 99.22%] [G loss: 1.376797]\n",
      "epoch:24 step:22899 [D loss: 1.119178, acc.: 50.00%] [G loss: 0.504126]\n",
      "epoch:24 step:22900 [D loss: 1.068468, acc.: 57.03%] [G loss: 1.286974]\n",
      "epoch:24 step:22901 [D loss: 0.177379, acc.: 98.44%] [G loss: 1.220010]\n",
      "epoch:24 step:22902 [D loss: 0.309350, acc.: 88.28%] [G loss: 1.736998]\n",
      "epoch:24 step:22903 [D loss: 0.725773, acc.: 60.94%] [G loss: 1.765849]\n",
      "epoch:24 step:22904 [D loss: 0.358083, acc.: 83.59%] [G loss: 0.830663]\n",
      "epoch:24 step:22905 [D loss: 0.835899, acc.: 55.47%] [G loss: 0.932734]\n",
      "epoch:24 step:22906 [D loss: 0.582371, acc.: 65.62%] [G loss: 1.588248]\n",
      "epoch:24 step:22907 [D loss: 0.658967, acc.: 63.28%] [G loss: 2.624149]\n",
      "epoch:24 step:22908 [D loss: 1.143141, acc.: 43.75%] [G loss: 1.578617]\n",
      "epoch:24 step:22909 [D loss: 1.371141, acc.: 30.47%] [G loss: 2.017740]\n",
      "epoch:24 step:22910 [D loss: 1.203290, acc.: 37.50%] [G loss: 0.975912]\n",
      "epoch:24 step:22911 [D loss: 1.176887, acc.: 32.81%] [G loss: 2.722808]\n",
      "epoch:24 step:22912 [D loss: 0.338108, acc.: 88.28%] [G loss: 2.019137]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:24 step:22913 [D loss: 0.597514, acc.: 67.97%] [G loss: 1.159283]\n",
      "epoch:24 step:22914 [D loss: 0.931810, acc.: 43.75%] [G loss: 1.486067]\n",
      "epoch:24 step:22915 [D loss: 0.372695, acc.: 88.28%] [G loss: 1.799844]\n",
      "epoch:24 step:22916 [D loss: 0.483340, acc.: 78.12%] [G loss: 2.497530]\n",
      "epoch:24 step:22917 [D loss: 0.520691, acc.: 71.88%] [G loss: 1.732180]\n",
      "epoch:24 step:22918 [D loss: 0.392371, acc.: 82.03%] [G loss: 1.994148]\n",
      "epoch:24 step:22919 [D loss: 0.782516, acc.: 53.91%] [G loss: 0.788049]\n",
      "epoch:24 step:22920 [D loss: 1.362043, acc.: 20.31%] [G loss: 1.726568]\n",
      "epoch:24 step:22921 [D loss: 0.871198, acc.: 49.22%] [G loss: 2.376519]\n",
      "epoch:24 step:22922 [D loss: 0.750910, acc.: 53.12%] [G loss: 2.293299]\n",
      "epoch:24 step:22923 [D loss: 0.641686, acc.: 60.16%] [G loss: 2.085155]\n",
      "epoch:24 step:22924 [D loss: 0.540885, acc.: 68.75%] [G loss: 2.276510]\n",
      "epoch:24 step:22925 [D loss: 0.629788, acc.: 60.94%] [G loss: 2.564524]\n",
      "epoch:24 step:22926 [D loss: 0.739650, acc.: 59.38%] [G loss: 1.772437]\n",
      "epoch:24 step:22927 [D loss: 0.723511, acc.: 53.12%] [G loss: 1.507039]\n",
      "epoch:24 step:22928 [D loss: 0.437963, acc.: 83.59%] [G loss: 1.965813]\n",
      "epoch:24 step:22929 [D loss: 0.604519, acc.: 64.06%] [G loss: 1.215147]\n",
      "epoch:24 step:22930 [D loss: 0.660253, acc.: 63.28%] [G loss: 1.217384]\n",
      "epoch:24 step:22931 [D loss: 0.593480, acc.: 63.28%] [G loss: 1.756127]\n",
      "epoch:24 step:22932 [D loss: 0.560720, acc.: 70.31%] [G loss: 1.600482]\n",
      "epoch:24 step:22933 [D loss: 0.694998, acc.: 52.34%] [G loss: 1.029581]\n",
      "epoch:24 step:22934 [D loss: 0.729153, acc.: 49.22%] [G loss: 1.040435]\n",
      "epoch:24 step:22935 [D loss: 0.724399, acc.: 51.56%] [G loss: 1.165453]\n",
      "epoch:24 step:22936 [D loss: 0.439656, acc.: 85.94%] [G loss: 1.128720]\n",
      "epoch:24 step:22937 [D loss: 0.446721, acc.: 84.38%] [G loss: 1.370626]\n",
      "epoch:24 step:22938 [D loss: 0.332434, acc.: 92.97%] [G loss: 1.355550]\n",
      "epoch:24 step:22939 [D loss: 0.354387, acc.: 89.84%] [G loss: 1.483420]\n",
      "epoch:24 step:22940 [D loss: 0.364968, acc.: 92.19%] [G loss: 1.581498]\n",
      "epoch:24 step:22941 [D loss: 0.413150, acc.: 85.16%] [G loss: 1.856845]\n",
      "epoch:24 step:22942 [D loss: 0.273512, acc.: 94.53%] [G loss: 1.615816]\n",
      "epoch:24 step:22943 [D loss: 0.419156, acc.: 89.06%] [G loss: 2.149576]\n",
      "epoch:24 step:22944 [D loss: 0.230882, acc.: 98.44%] [G loss: 1.990382]\n",
      "epoch:24 step:22945 [D loss: 0.365379, acc.: 89.06%] [G loss: 1.948701]\n",
      "epoch:24 step:22946 [D loss: 0.866296, acc.: 46.88%] [G loss: 1.019229]\n",
      "epoch:24 step:22947 [D loss: 0.616793, acc.: 65.62%] [G loss: 1.113522]\n",
      "epoch:24 step:22948 [D loss: 0.978098, acc.: 33.59%] [G loss: 0.827720]\n",
      "epoch:24 step:22949 [D loss: 0.927707, acc.: 35.94%] [G loss: 1.013132]\n",
      "epoch:24 step:22950 [D loss: 1.021888, acc.: 33.59%] [G loss: 0.767338]\n",
      "epoch:24 step:22951 [D loss: 0.588930, acc.: 68.75%] [G loss: 0.856008]\n",
      "epoch:24 step:22952 [D loss: 0.579316, acc.: 67.19%] [G loss: 0.907855]\n",
      "epoch:24 step:22953 [D loss: 0.498603, acc.: 78.12%] [G loss: 1.014498]\n",
      "epoch:24 step:22954 [D loss: 0.482592, acc.: 82.81%] [G loss: 1.164171]\n",
      "epoch:24 step:22955 [D loss: 0.474415, acc.: 82.03%] [G loss: 1.183526]\n",
      "epoch:24 step:22956 [D loss: 0.353161, acc.: 86.72%] [G loss: 1.355349]\n",
      "epoch:24 step:22957 [D loss: 0.328061, acc.: 90.62%] [G loss: 1.038112]\n",
      "epoch:24 step:22958 [D loss: 0.262824, acc.: 92.19%] [G loss: 1.629442]\n",
      "epoch:24 step:22959 [D loss: 0.211749, acc.: 96.88%] [G loss: 1.364909]\n",
      "epoch:24 step:22960 [D loss: 0.398429, acc.: 88.28%] [G loss: 1.613299]\n",
      "epoch:24 step:22961 [D loss: 1.026644, acc.: 39.84%] [G loss: 1.307342]\n",
      "epoch:24 step:22962 [D loss: 0.706441, acc.: 57.81%] [G loss: 1.214249]\n",
      "epoch:24 step:22963 [D loss: 0.603289, acc.: 65.62%] [G loss: 1.236463]\n",
      "epoch:24 step:22964 [D loss: 0.570364, acc.: 68.75%] [G loss: 1.252147]\n",
      "epoch:24 step:22965 [D loss: 0.572553, acc.: 76.56%] [G loss: 1.357440]\n",
      "epoch:24 step:22966 [D loss: 0.541791, acc.: 73.44%] [G loss: 1.044820]\n",
      "epoch:24 step:22967 [D loss: 0.380631, acc.: 84.38%] [G loss: 1.045735]\n",
      "epoch:24 step:22968 [D loss: 0.556923, acc.: 71.88%] [G loss: 1.126244]\n",
      "epoch:24 step:22969 [D loss: 0.317428, acc.: 87.50%] [G loss: 1.487994]\n",
      "epoch:24 step:22970 [D loss: 0.709024, acc.: 59.38%] [G loss: 1.195748]\n",
      "epoch:24 step:22971 [D loss: 0.627178, acc.: 65.62%] [G loss: 1.429855]\n",
      "epoch:24 step:22972 [D loss: 0.438793, acc.: 82.81%] [G loss: 1.362505]\n",
      "epoch:24 step:22973 [D loss: 0.547009, acc.: 76.56%] [G loss: 1.265170]\n",
      "epoch:24 step:22974 [D loss: 0.557442, acc.: 72.66%] [G loss: 1.371021]\n",
      "epoch:24 step:22975 [D loss: 0.474280, acc.: 82.03%] [G loss: 1.212240]\n",
      "epoch:24 step:22976 [D loss: 0.534169, acc.: 71.88%] [G loss: 1.480089]\n",
      "epoch:24 step:22977 [D loss: 0.535478, acc.: 72.66%] [G loss: 1.382383]\n",
      "epoch:24 step:22978 [D loss: 0.636076, acc.: 62.50%] [G loss: 1.210431]\n",
      "epoch:24 step:22979 [D loss: 0.578145, acc.: 69.53%] [G loss: 1.242144]\n",
      "epoch:24 step:22980 [D loss: 0.640522, acc.: 66.41%] [G loss: 1.325207]\n",
      "epoch:24 step:22981 [D loss: 0.745544, acc.: 53.91%] [G loss: 0.935132]\n",
      "epoch:24 step:22982 [D loss: 0.514303, acc.: 76.56%] [G loss: 1.358866]\n",
      "epoch:24 step:22983 [D loss: 0.728000, acc.: 56.25%] [G loss: 1.236477]\n",
      "epoch:24 step:22984 [D loss: 0.601046, acc.: 63.28%] [G loss: 1.032063]\n",
      "epoch:24 step:22985 [D loss: 0.413263, acc.: 85.16%] [G loss: 1.449114]\n",
      "epoch:24 step:22986 [D loss: 0.244442, acc.: 93.75%] [G loss: 1.204289]\n",
      "epoch:24 step:22987 [D loss: 0.221473, acc.: 95.31%] [G loss: 1.492222]\n",
      "epoch:24 step:22988 [D loss: 0.721162, acc.: 60.16%] [G loss: 1.341818]\n",
      "epoch:24 step:22989 [D loss: 0.651836, acc.: 64.06%] [G loss: 1.335375]\n",
      "epoch:24 step:22990 [D loss: 0.732036, acc.: 59.38%] [G loss: 1.153569]\n",
      "epoch:24 step:22991 [D loss: 0.283866, acc.: 90.62%] [G loss: 1.205221]\n",
      "epoch:24 step:22992 [D loss: 0.229944, acc.: 92.97%] [G loss: 1.723833]\n",
      "epoch:24 step:22993 [D loss: 0.389279, acc.: 86.72%] [G loss: 1.411388]\n",
      "epoch:24 step:22994 [D loss: 0.725478, acc.: 60.16%] [G loss: 1.108463]\n",
      "epoch:24 step:22995 [D loss: 0.428846, acc.: 82.03%] [G loss: 1.228802]\n",
      "epoch:24 step:22996 [D loss: 0.527099, acc.: 75.00%] [G loss: 1.069913]\n",
      "epoch:24 step:22997 [D loss: 0.714285, acc.: 58.59%] [G loss: 1.376772]\n",
      "epoch:24 step:22998 [D loss: 0.361400, acc.: 87.50%] [G loss: 1.489644]\n",
      "epoch:24 step:22999 [D loss: 0.386964, acc.: 82.81%] [G loss: 1.173764]\n",
      "epoch:24 step:23000 [D loss: 0.293027, acc.: 92.97%] [G loss: 1.517241]\n",
      "##############\n",
      "[4.47570272 2.68178069 6.63328889 5.6521045  4.36882816 5.93268858\n",
      " 5.13935958 5.52357986 5.9880395  4.90997328]\n",
      "##########\n",
      "epoch:24 step:23001 [D loss: 0.274926, acc.: 94.53%] [G loss: 1.440455]\n",
      "epoch:24 step:23002 [D loss: 0.339225, acc.: 92.19%] [G loss: 1.772494]\n",
      "epoch:24 step:23003 [D loss: 0.292988, acc.: 92.97%] [G loss: 1.536970]\n",
      "epoch:24 step:23004 [D loss: 0.641848, acc.: 63.28%] [G loss: 1.331255]\n",
      "epoch:24 step:23005 [D loss: 0.346748, acc.: 89.84%] [G loss: 1.548596]\n",
      "epoch:24 step:23006 [D loss: 0.718833, acc.: 54.69%] [G loss: 1.332194]\n",
      "epoch:24 step:23007 [D loss: 0.604003, acc.: 63.28%] [G loss: 0.997960]\n",
      "epoch:24 step:23008 [D loss: 0.582574, acc.: 65.62%] [G loss: 0.964208]\n",
      "epoch:24 step:23009 [D loss: 0.522970, acc.: 74.22%] [G loss: 1.140243]\n",
      "epoch:24 step:23010 [D loss: 0.583853, acc.: 65.62%] [G loss: 0.852121]\n",
      "epoch:24 step:23011 [D loss: 0.526274, acc.: 76.56%] [G loss: 1.390376]\n",
      "epoch:24 step:23012 [D loss: 0.292140, acc.: 94.53%] [G loss: 1.509944]\n",
      "epoch:24 step:23013 [D loss: 0.735090, acc.: 55.47%] [G loss: 1.395650]\n",
      "epoch:24 step:23014 [D loss: 0.575923, acc.: 72.66%] [G loss: 1.497543]\n",
      "epoch:24 step:23015 [D loss: 0.280825, acc.: 89.84%] [G loss: 0.424107]\n",
      "epoch:24 step:23016 [D loss: 0.633991, acc.: 62.50%] [G loss: 1.445366]\n",
      "epoch:24 step:23017 [D loss: 0.548474, acc.: 70.31%] [G loss: 1.442984]\n",
      "epoch:24 step:23018 [D loss: 0.310427, acc.: 89.06%] [G loss: 1.601960]\n",
      "epoch:24 step:23019 [D loss: 0.688299, acc.: 59.38%] [G loss: 1.156668]\n",
      "epoch:24 step:23020 [D loss: 0.573121, acc.: 72.66%] [G loss: 0.979574]\n",
      "epoch:24 step:23021 [D loss: 0.365508, acc.: 89.06%] [G loss: 1.483347]\n",
      "epoch:24 step:23022 [D loss: 0.493777, acc.: 82.81%] [G loss: 1.605137]\n",
      "epoch:24 step:23023 [D loss: 0.331738, acc.: 84.38%] [G loss: 1.520669]\n",
      "epoch:24 step:23024 [D loss: 0.161153, acc.: 97.66%] [G loss: 1.426880]\n",
      "epoch:24 step:23025 [D loss: 0.136362, acc.: 99.22%] [G loss: 2.027204]\n",
      "epoch:24 step:23026 [D loss: 0.284136, acc.: 95.31%] [G loss: 1.612257]\n",
      "epoch:24 step:23027 [D loss: 0.390193, acc.: 89.06%] [G loss: 1.362250]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:24 step:23028 [D loss: 0.367260, acc.: 90.62%] [G loss: 1.801868]\n",
      "epoch:24 step:23029 [D loss: 0.225342, acc.: 97.66%] [G loss: 1.395451]\n",
      "epoch:24 step:23030 [D loss: 0.726801, acc.: 64.84%] [G loss: 1.501628]\n",
      "epoch:24 step:23031 [D loss: 0.339064, acc.: 91.41%] [G loss: 1.596780]\n",
      "epoch:24 step:23032 [D loss: 0.786970, acc.: 51.56%] [G loss: 1.535441]\n",
      "epoch:24 step:23033 [D loss: 0.412603, acc.: 88.28%] [G loss: 1.309103]\n",
      "epoch:24 step:23034 [D loss: 0.687275, acc.: 59.38%] [G loss: 1.369660]\n",
      "epoch:24 step:23035 [D loss: 0.366569, acc.: 88.28%] [G loss: 1.193295]\n",
      "epoch:24 step:23036 [D loss: 0.703979, acc.: 60.16%] [G loss: 1.392986]\n",
      "epoch:24 step:23037 [D loss: 0.251890, acc.: 95.31%] [G loss: 1.660783]\n",
      "epoch:24 step:23038 [D loss: 0.282789, acc.: 92.19%] [G loss: 1.987781]\n",
      "epoch:24 step:23039 [D loss: 0.553946, acc.: 73.44%] [G loss: 1.026941]\n",
      "epoch:24 step:23040 [D loss: 0.295881, acc.: 96.88%] [G loss: 1.299153]\n",
      "epoch:24 step:23041 [D loss: 0.635581, acc.: 65.62%] [G loss: 1.579154]\n",
      "epoch:24 step:23042 [D loss: 0.196283, acc.: 93.75%] [G loss: 1.243758]\n",
      "epoch:24 step:23043 [D loss: 0.597844, acc.: 64.06%] [G loss: 1.125282]\n",
      "epoch:24 step:23044 [D loss: 0.180706, acc.: 96.88%] [G loss: 1.075179]\n",
      "epoch:24 step:23045 [D loss: 0.215502, acc.: 96.88%] [G loss: 1.554118]\n",
      "epoch:24 step:23046 [D loss: 0.455793, acc.: 76.56%] [G loss: 2.008220]\n",
      "epoch:24 step:23047 [D loss: 0.265745, acc.: 88.28%] [G loss: 1.843965]\n",
      "epoch:24 step:23048 [D loss: 0.259578, acc.: 92.19%] [G loss: 1.480359]\n",
      "epoch:24 step:23049 [D loss: 0.265771, acc.: 89.06%] [G loss: 1.236440]\n",
      "epoch:24 step:23050 [D loss: 0.724190, acc.: 64.06%] [G loss: 2.261657]\n",
      "epoch:24 step:23051 [D loss: 0.705856, acc.: 60.94%] [G loss: 1.347380]\n",
      "epoch:24 step:23052 [D loss: 0.749345, acc.: 53.12%] [G loss: 1.346633]\n",
      "epoch:24 step:23053 [D loss: 0.277637, acc.: 90.62%] [G loss: 1.068850]\n",
      "epoch:24 step:23054 [D loss: 0.168765, acc.: 93.75%] [G loss: 2.046058]\n",
      "epoch:24 step:23055 [D loss: 0.162793, acc.: 97.66%] [G loss: 1.821606]\n",
      "epoch:24 step:23056 [D loss: 0.198501, acc.: 95.31%] [G loss: 2.071556]\n",
      "epoch:24 step:23057 [D loss: 0.660553, acc.: 63.28%] [G loss: 1.799294]\n",
      "epoch:24 step:23058 [D loss: 0.283258, acc.: 90.62%] [G loss: 2.048260]\n",
      "epoch:24 step:23059 [D loss: 0.477126, acc.: 73.44%] [G loss: 1.983059]\n",
      "epoch:24 step:23060 [D loss: 0.362154, acc.: 85.94%] [G loss: 1.871971]\n",
      "epoch:24 step:23061 [D loss: 0.341644, acc.: 89.06%] [G loss: 1.575402]\n",
      "epoch:24 step:23062 [D loss: 0.257393, acc.: 91.41%] [G loss: 1.432109]\n",
      "epoch:24 step:23063 [D loss: 0.400755, acc.: 85.16%] [G loss: 2.007593]\n",
      "epoch:24 step:23064 [D loss: 0.278076, acc.: 92.19%] [G loss: 2.448284]\n",
      "epoch:24 step:23065 [D loss: 0.073558, acc.: 100.00%] [G loss: 2.808153]\n",
      "epoch:24 step:23066 [D loss: 0.077850, acc.: 99.22%] [G loss: 2.637246]\n",
      "epoch:24 step:23067 [D loss: 0.086885, acc.: 100.00%] [G loss: 3.153842]\n",
      "epoch:24 step:23068 [D loss: 0.900134, acc.: 53.12%] [G loss: 2.281658]\n",
      "epoch:24 step:23069 [D loss: 0.691200, acc.: 53.91%] [G loss: 1.128332]\n",
      "epoch:24 step:23070 [D loss: 0.998491, acc.: 33.59%] [G loss: 1.259077]\n",
      "epoch:24 step:23071 [D loss: 0.864198, acc.: 53.91%] [G loss: 0.862993]\n",
      "epoch:24 step:23072 [D loss: 0.732645, acc.: 56.25%] [G loss: 1.418922]\n",
      "epoch:24 step:23073 [D loss: 0.936328, acc.: 42.19%] [G loss: 0.968367]\n",
      "epoch:24 step:23074 [D loss: 0.621814, acc.: 67.97%] [G loss: 1.326237]\n",
      "epoch:24 step:23075 [D loss: 0.286266, acc.: 80.47%] [G loss: 1.465782]\n",
      "epoch:24 step:23076 [D loss: 0.223589, acc.: 91.41%] [G loss: 0.980978]\n",
      "epoch:24 step:23077 [D loss: 0.290067, acc.: 83.59%] [G loss: 1.898462]\n",
      "epoch:24 step:23078 [D loss: 0.344252, acc.: 85.94%] [G loss: 1.925991]\n",
      "epoch:24 step:23079 [D loss: 0.714496, acc.: 59.38%] [G loss: 1.427726]\n",
      "epoch:24 step:23080 [D loss: 0.624561, acc.: 68.75%] [G loss: 1.613145]\n",
      "epoch:24 step:23081 [D loss: 0.881123, acc.: 36.72%] [G loss: 1.205950]\n",
      "epoch:24 step:23082 [D loss: 0.382203, acc.: 86.72%] [G loss: 0.954444]\n",
      "epoch:24 step:23083 [D loss: 0.269614, acc.: 89.06%] [G loss: 1.172704]\n",
      "epoch:24 step:23084 [D loss: 0.707775, acc.: 60.16%] [G loss: 1.335805]\n",
      "epoch:24 step:23085 [D loss: 0.921141, acc.: 46.09%] [G loss: 1.030159]\n",
      "epoch:24 step:23086 [D loss: 1.256772, acc.: 21.88%] [G loss: 1.539487]\n",
      "epoch:24 step:23087 [D loss: 0.853760, acc.: 46.09%] [G loss: 1.679461]\n",
      "epoch:24 step:23088 [D loss: 0.323747, acc.: 86.72%] [G loss: 1.724420]\n",
      "epoch:24 step:23089 [D loss: 0.312141, acc.: 89.84%] [G loss: 1.542567]\n",
      "epoch:24 step:23090 [D loss: 0.553145, acc.: 71.09%] [G loss: 1.946485]\n",
      "epoch:24 step:23091 [D loss: 0.748457, acc.: 56.25%] [G loss: 1.245821]\n",
      "epoch:24 step:23092 [D loss: 0.430820, acc.: 80.47%] [G loss: 1.639910]\n",
      "epoch:24 step:23093 [D loss: 0.542925, acc.: 76.56%] [G loss: 1.717071]\n",
      "epoch:24 step:23094 [D loss: 0.522330, acc.: 75.78%] [G loss: 1.222705]\n",
      "epoch:24 step:23095 [D loss: 0.556007, acc.: 75.00%] [G loss: 1.330959]\n",
      "epoch:24 step:23096 [D loss: 0.567229, acc.: 72.66%] [G loss: 1.204428]\n",
      "epoch:24 step:23097 [D loss: 0.337306, acc.: 85.94%] [G loss: 0.856107]\n",
      "epoch:24 step:23098 [D loss: 0.841975, acc.: 44.53%] [G loss: 0.592317]\n",
      "epoch:24 step:23099 [D loss: 0.331228, acc.: 89.84%] [G loss: 1.314020]\n",
      "epoch:24 step:23100 [D loss: 0.447228, acc.: 81.25%] [G loss: 0.782593]\n",
      "epoch:24 step:23101 [D loss: 0.745654, acc.: 52.34%] [G loss: 0.922156]\n",
      "epoch:24 step:23102 [D loss: 0.687591, acc.: 55.47%] [G loss: 0.518996]\n",
      "epoch:24 step:23103 [D loss: 0.455863, acc.: 80.47%] [G loss: 1.249880]\n",
      "epoch:24 step:23104 [D loss: 0.517129, acc.: 70.31%] [G loss: 1.335635]\n",
      "epoch:24 step:23105 [D loss: 0.201953, acc.: 99.22%] [G loss: 1.368688]\n",
      "epoch:24 step:23106 [D loss: 0.998900, acc.: 34.38%] [G loss: 1.773539]\n",
      "epoch:24 step:23107 [D loss: 0.535375, acc.: 73.44%] [G loss: 1.623756]\n",
      "epoch:24 step:23108 [D loss: 0.488759, acc.: 73.44%] [G loss: 1.470578]\n",
      "epoch:24 step:23109 [D loss: 0.430209, acc.: 83.59%] [G loss: 1.483555]\n",
      "epoch:24 step:23110 [D loss: 0.225441, acc.: 92.19%] [G loss: 1.856045]\n",
      "epoch:24 step:23111 [D loss: 0.205688, acc.: 96.88%] [G loss: 2.051471]\n",
      "epoch:24 step:23112 [D loss: 0.178660, acc.: 92.97%] [G loss: 2.249470]\n",
      "epoch:24 step:23113 [D loss: 0.494289, acc.: 75.00%] [G loss: 2.484203]\n",
      "epoch:24 step:23114 [D loss: 0.278375, acc.: 94.53%] [G loss: 1.502356]\n",
      "epoch:24 step:23115 [D loss: 0.567687, acc.: 68.75%] [G loss: 1.210987]\n",
      "epoch:24 step:23116 [D loss: 0.599547, acc.: 68.75%] [G loss: 1.973872]\n",
      "epoch:24 step:23117 [D loss: 0.506766, acc.: 74.22%] [G loss: 1.892142]\n",
      "epoch:24 step:23118 [D loss: 0.126291, acc.: 96.88%] [G loss: 2.269198]\n",
      "epoch:24 step:23119 [D loss: 0.915491, acc.: 56.25%] [G loss: 1.613648]\n",
      "epoch:24 step:23120 [D loss: 0.271173, acc.: 88.28%] [G loss: 1.900208]\n",
      "epoch:24 step:23121 [D loss: 0.175849, acc.: 94.53%] [G loss: 2.337219]\n",
      "epoch:24 step:23122 [D loss: 0.178175, acc.: 96.88%] [G loss: 1.778583]\n",
      "epoch:24 step:23123 [D loss: 0.091096, acc.: 98.44%] [G loss: 2.750141]\n",
      "epoch:24 step:23124 [D loss: 0.309100, acc.: 87.50%] [G loss: 2.051235]\n",
      "epoch:24 step:23125 [D loss: 0.261913, acc.: 94.53%] [G loss: 1.534369]\n",
      "epoch:24 step:23126 [D loss: 0.797430, acc.: 47.66%] [G loss: 1.633986]\n",
      "epoch:24 step:23127 [D loss: 1.269623, acc.: 39.84%] [G loss: 1.031177]\n",
      "epoch:24 step:23128 [D loss: 1.053445, acc.: 42.19%] [G loss: 1.702022]\n",
      "epoch:24 step:23129 [D loss: 0.609664, acc.: 71.88%] [G loss: 1.522248]\n",
      "epoch:24 step:23130 [D loss: 0.637650, acc.: 57.81%] [G loss: 1.307778]\n",
      "epoch:24 step:23131 [D loss: 0.384112, acc.: 85.16%] [G loss: 0.770312]\n",
      "epoch:24 step:23132 [D loss: 0.223238, acc.: 93.75%] [G loss: 1.507335]\n",
      "epoch:24 step:23133 [D loss: 0.323855, acc.: 87.50%] [G loss: 1.859170]\n",
      "epoch:24 step:23134 [D loss: 0.165848, acc.: 95.31%] [G loss: 1.928662]\n",
      "epoch:24 step:23135 [D loss: 0.189899, acc.: 94.53%] [G loss: 1.848086]\n",
      "epoch:24 step:23136 [D loss: 0.173624, acc.: 97.66%] [G loss: 1.352734]\n",
      "epoch:24 step:23137 [D loss: 0.168679, acc.: 98.44%] [G loss: 1.985949]\n",
      "epoch:24 step:23138 [D loss: 0.234501, acc.: 89.06%] [G loss: 1.777164]\n",
      "epoch:24 step:23139 [D loss: 0.228881, acc.: 98.44%] [G loss: 0.858964]\n",
      "epoch:24 step:23140 [D loss: 0.684828, acc.: 62.50%] [G loss: 1.974094]\n",
      "epoch:24 step:23141 [D loss: 0.603231, acc.: 67.97%] [G loss: 0.980052]\n",
      "epoch:24 step:23142 [D loss: 0.905424, acc.: 39.06%] [G loss: 1.295884]\n",
      "epoch:24 step:23143 [D loss: 0.493359, acc.: 78.12%] [G loss: 0.488334]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:24 step:23144 [D loss: 0.434273, acc.: 78.91%] [G loss: 0.916846]\n",
      "epoch:24 step:23145 [D loss: 0.573114, acc.: 71.09%] [G loss: 1.274559]\n",
      "epoch:24 step:23146 [D loss: 1.183779, acc.: 34.38%] [G loss: 0.777980]\n",
      "epoch:24 step:23147 [D loss: 0.337758, acc.: 82.81%] [G loss: 1.465818]\n",
      "epoch:24 step:23148 [D loss: 0.406183, acc.: 77.34%] [G loss: 1.739761]\n",
      "epoch:24 step:23149 [D loss: 0.499525, acc.: 81.25%] [G loss: 0.572173]\n",
      "epoch:24 step:23150 [D loss: 1.332308, acc.: 21.88%] [G loss: 1.738809]\n",
      "epoch:24 step:23151 [D loss: 0.390290, acc.: 76.56%] [G loss: 1.265225]\n",
      "epoch:24 step:23152 [D loss: 0.230392, acc.: 93.75%] [G loss: 2.694433]\n",
      "epoch:24 step:23153 [D loss: 0.118773, acc.: 98.44%] [G loss: 2.144325]\n",
      "epoch:24 step:23154 [D loss: 0.748953, acc.: 57.81%] [G loss: 2.386532]\n",
      "epoch:24 step:23155 [D loss: 0.682403, acc.: 60.16%] [G loss: 2.413751]\n",
      "epoch:24 step:23156 [D loss: 0.754689, acc.: 53.91%] [G loss: 2.103307]\n",
      "epoch:24 step:23157 [D loss: 0.637362, acc.: 60.94%] [G loss: 1.591824]\n",
      "epoch:24 step:23158 [D loss: 0.619195, acc.: 64.06%] [G loss: 1.174673]\n",
      "epoch:24 step:23159 [D loss: 0.522460, acc.: 73.44%] [G loss: 1.682904]\n",
      "epoch:24 step:23160 [D loss: 0.617858, acc.: 66.41%] [G loss: 1.438149]\n",
      "epoch:24 step:23161 [D loss: 0.846145, acc.: 46.88%] [G loss: 1.488919]\n",
      "epoch:24 step:23162 [D loss: 0.585468, acc.: 67.19%] [G loss: 1.371525]\n",
      "epoch:24 step:23163 [D loss: 0.686275, acc.: 55.47%] [G loss: 1.163182]\n",
      "epoch:24 step:23164 [D loss: 0.651452, acc.: 59.38%] [G loss: 1.517768]\n",
      "epoch:24 step:23165 [D loss: 0.642910, acc.: 68.75%] [G loss: 1.087026]\n",
      "epoch:24 step:23166 [D loss: 0.678678, acc.: 57.81%] [G loss: 1.056698]\n",
      "epoch:24 step:23167 [D loss: 0.585635, acc.: 69.53%] [G loss: 0.904051]\n",
      "epoch:24 step:23168 [D loss: 0.489413, acc.: 78.12%] [G loss: 0.975989]\n",
      "epoch:24 step:23169 [D loss: 0.895618, acc.: 46.09%] [G loss: 1.487890]\n",
      "epoch:24 step:23170 [D loss: 0.428354, acc.: 85.16%] [G loss: 1.202931]\n",
      "epoch:24 step:23171 [D loss: 0.540483, acc.: 75.78%] [G loss: 0.887251]\n",
      "epoch:24 step:23172 [D loss: 0.346311, acc.: 88.28%] [G loss: 1.164001]\n",
      "epoch:24 step:23173 [D loss: 0.441428, acc.: 81.25%] [G loss: 1.204639]\n",
      "epoch:24 step:23174 [D loss: 0.470090, acc.: 75.78%] [G loss: 1.318922]\n",
      "epoch:24 step:23175 [D loss: 0.577269, acc.: 70.31%] [G loss: 1.191767]\n",
      "epoch:24 step:23176 [D loss: 0.830209, acc.: 49.22%] [G loss: 1.230950]\n",
      "epoch:24 step:23177 [D loss: 0.639927, acc.: 64.06%] [G loss: 1.317554]\n",
      "epoch:24 step:23178 [D loss: 0.606726, acc.: 63.28%] [G loss: 1.788904]\n",
      "epoch:24 step:23179 [D loss: 0.609121, acc.: 65.62%] [G loss: 1.286869]\n",
      "epoch:24 step:23180 [D loss: 0.568907, acc.: 67.97%] [G loss: 1.038552]\n",
      "epoch:24 step:23181 [D loss: 0.549051, acc.: 71.09%] [G loss: 1.172805]\n",
      "epoch:24 step:23182 [D loss: 0.438480, acc.: 83.59%] [G loss: 1.246886]\n",
      "epoch:24 step:23183 [D loss: 0.772147, acc.: 57.81%] [G loss: 1.342278]\n",
      "epoch:24 step:23184 [D loss: 0.309223, acc.: 88.28%] [G loss: 1.935594]\n",
      "epoch:24 step:23185 [D loss: 0.213448, acc.: 93.75%] [G loss: 1.667867]\n",
      "epoch:24 step:23186 [D loss: 0.299535, acc.: 95.31%] [G loss: 1.428100]\n",
      "epoch:24 step:23187 [D loss: 0.290827, acc.: 94.53%] [G loss: 1.603090]\n",
      "epoch:24 step:23188 [D loss: 0.250972, acc.: 92.97%] [G loss: 1.630808]\n",
      "epoch:24 step:23189 [D loss: 0.120844, acc.: 100.00%] [G loss: 1.988508]\n",
      "epoch:24 step:23190 [D loss: 0.271706, acc.: 94.53%] [G loss: 1.997891]\n",
      "epoch:24 step:23191 [D loss: 0.600578, acc.: 70.31%] [G loss: 1.393949]\n",
      "epoch:24 step:23192 [D loss: 0.377593, acc.: 89.06%] [G loss: 1.310767]\n",
      "epoch:24 step:23193 [D loss: 0.617126, acc.: 65.62%] [G loss: 1.733622]\n",
      "epoch:24 step:23194 [D loss: 0.252641, acc.: 90.62%] [G loss: 1.411523]\n",
      "epoch:24 step:23195 [D loss: 0.217813, acc.: 91.41%] [G loss: 0.908804]\n",
      "epoch:24 step:23196 [D loss: 0.151017, acc.: 98.44%] [G loss: 1.638858]\n",
      "epoch:24 step:23197 [D loss: 0.094454, acc.: 100.00%] [G loss: 2.176172]\n",
      "epoch:24 step:23198 [D loss: 0.950102, acc.: 53.91%] [G loss: 1.376060]\n",
      "epoch:24 step:23199 [D loss: 0.639368, acc.: 64.06%] [G loss: 1.463683]\n",
      "epoch:24 step:23200 [D loss: 0.572952, acc.: 72.66%] [G loss: 1.232802]\n",
      "##############\n",
      "[3.81167007 2.20474467 6.79656961 6.06877309 4.10844929 6.08687788\n",
      " 5.43580251 5.38291901 5.95166881 4.83881729]\n",
      "##########\n",
      "epoch:24 step:23201 [D loss: 0.207570, acc.: 91.41%] [G loss: 1.519016]\n",
      "epoch:24 step:23202 [D loss: 0.187606, acc.: 95.31%] [G loss: 1.621502]\n",
      "epoch:24 step:23203 [D loss: 0.803627, acc.: 52.34%] [G loss: 1.274270]\n",
      "epoch:24 step:23204 [D loss: 0.836302, acc.: 46.09%] [G loss: 1.234809]\n",
      "epoch:24 step:23205 [D loss: 0.668456, acc.: 65.62%] [G loss: 1.301011]\n",
      "epoch:24 step:23206 [D loss: 1.273558, acc.: 34.38%] [G loss: 1.312578]\n",
      "epoch:24 step:23207 [D loss: 0.685948, acc.: 60.94%] [G loss: 1.761774]\n",
      "epoch:24 step:23208 [D loss: 0.536761, acc.: 68.75%] [G loss: 2.006783]\n",
      "epoch:24 step:23209 [D loss: 0.595885, acc.: 67.19%] [G loss: 1.450608]\n",
      "epoch:24 step:23210 [D loss: 0.651705, acc.: 62.50%] [G loss: 1.083718]\n",
      "epoch:24 step:23211 [D loss: 0.526991, acc.: 71.88%] [G loss: 1.347712]\n",
      "epoch:24 step:23212 [D loss: 0.545087, acc.: 71.09%] [G loss: 1.225893]\n",
      "epoch:24 step:23213 [D loss: 0.692290, acc.: 54.69%] [G loss: 1.075734]\n",
      "epoch:24 step:23214 [D loss: 0.425707, acc.: 84.38%] [G loss: 1.401089]\n",
      "epoch:24 step:23215 [D loss: 0.359082, acc.: 91.41%] [G loss: 1.253835]\n",
      "epoch:24 step:23216 [D loss: 0.213426, acc.: 95.31%] [G loss: 1.085083]\n",
      "epoch:24 step:23217 [D loss: 0.180269, acc.: 96.09%] [G loss: 1.412938]\n",
      "epoch:24 step:23218 [D loss: 0.164712, acc.: 95.31%] [G loss: 1.561143]\n",
      "epoch:24 step:23219 [D loss: 0.126247, acc.: 99.22%] [G loss: 1.682955]\n",
      "epoch:24 step:23220 [D loss: 0.205432, acc.: 96.88%] [G loss: 1.705611]\n",
      "epoch:24 step:23221 [D loss: 0.110592, acc.: 100.00%] [G loss: 2.260724]\n",
      "epoch:24 step:23222 [D loss: 0.789074, acc.: 56.25%] [G loss: 1.908445]\n",
      "epoch:24 step:23223 [D loss: 0.783048, acc.: 50.00%] [G loss: 1.191045]\n",
      "epoch:24 step:23224 [D loss: 0.818840, acc.: 50.00%] [G loss: 0.960503]\n",
      "epoch:24 step:23225 [D loss: 0.651355, acc.: 67.19%] [G loss: 1.177230]\n",
      "epoch:24 step:23226 [D loss: 0.686573, acc.: 57.81%] [G loss: 1.195787]\n",
      "epoch:24 step:23227 [D loss: 0.366843, acc.: 81.25%] [G loss: 1.034516]\n",
      "epoch:24 step:23228 [D loss: 0.247279, acc.: 91.41%] [G loss: 1.087832]\n",
      "epoch:24 step:23229 [D loss: 0.519480, acc.: 75.78%] [G loss: 1.538654]\n",
      "epoch:24 step:23230 [D loss: 0.409123, acc.: 85.94%] [G loss: 1.566680]\n",
      "epoch:24 step:23231 [D loss: 0.312171, acc.: 92.97%] [G loss: 1.724108]\n",
      "epoch:24 step:23232 [D loss: 0.656317, acc.: 60.94%] [G loss: 1.300972]\n",
      "epoch:24 step:23233 [D loss: 0.229449, acc.: 96.88%] [G loss: 1.208694]\n",
      "epoch:24 step:23234 [D loss: 0.317627, acc.: 82.81%] [G loss: 1.516769]\n",
      "epoch:24 step:23235 [D loss: 0.513751, acc.: 74.22%] [G loss: 1.329394]\n",
      "epoch:24 step:23236 [D loss: 0.749471, acc.: 57.03%] [G loss: 1.490972]\n",
      "epoch:24 step:23237 [D loss: 0.444736, acc.: 79.69%] [G loss: 1.427255]\n",
      "epoch:24 step:23238 [D loss: 0.434621, acc.: 86.72%] [G loss: 0.849124]\n",
      "epoch:24 step:23239 [D loss: 0.607131, acc.: 66.41%] [G loss: 1.329076]\n",
      "epoch:24 step:23240 [D loss: 0.427364, acc.: 85.16%] [G loss: 1.531892]\n",
      "epoch:24 step:23241 [D loss: 0.345966, acc.: 91.41%] [G loss: 1.517256]\n",
      "epoch:24 step:23242 [D loss: 0.188007, acc.: 96.88%] [G loss: 1.369579]\n",
      "epoch:24 step:23243 [D loss: 0.169745, acc.: 98.44%] [G loss: 0.253690]\n",
      "epoch:24 step:23244 [D loss: 0.171242, acc.: 98.44%] [G loss: 1.404611]\n",
      "epoch:24 step:23245 [D loss: 0.266552, acc.: 89.84%] [G loss: 1.670123]\n",
      "epoch:24 step:23246 [D loss: 0.451913, acc.: 78.91%] [G loss: 1.956430]\n",
      "epoch:24 step:23247 [D loss: 0.819295, acc.: 52.34%] [G loss: 1.540804]\n",
      "epoch:24 step:23248 [D loss: 0.720522, acc.: 55.47%] [G loss: 1.207706]\n",
      "epoch:24 step:23249 [D loss: 0.823066, acc.: 47.66%] [G loss: 1.353442]\n",
      "epoch:24 step:23250 [D loss: 0.191550, acc.: 96.09%] [G loss: 1.633289]\n",
      "epoch:24 step:23251 [D loss: 0.241610, acc.: 94.53%] [G loss: 0.982334]\n",
      "epoch:24 step:23252 [D loss: 0.157089, acc.: 98.44%] [G loss: 1.078238]\n",
      "epoch:24 step:23253 [D loss: 0.692311, acc.: 58.59%] [G loss: 1.105314]\n",
      "epoch:24 step:23254 [D loss: 0.776634, acc.: 53.12%] [G loss: 1.044665]\n",
      "epoch:24 step:23255 [D loss: 0.702426, acc.: 55.47%] [G loss: 1.262913]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:24 step:23256 [D loss: 0.260699, acc.: 92.19%] [G loss: 1.623197]\n",
      "epoch:24 step:23257 [D loss: 0.365236, acc.: 85.94%] [G loss: 1.782287]\n",
      "epoch:24 step:23258 [D loss: 0.709867, acc.: 57.03%] [G loss: 0.939559]\n",
      "epoch:24 step:23259 [D loss: 0.579042, acc.: 71.88%] [G loss: 1.442054]\n",
      "epoch:24 step:23260 [D loss: 0.773987, acc.: 51.56%] [G loss: 0.337747]\n",
      "epoch:24 step:23261 [D loss: 0.627831, acc.: 57.03%] [G loss: 0.648600]\n",
      "epoch:24 step:23262 [D loss: 0.208185, acc.: 95.31%] [G loss: 0.902197]\n",
      "epoch:24 step:23263 [D loss: 0.434191, acc.: 79.69%] [G loss: 1.283056]\n",
      "epoch:24 step:23264 [D loss: 0.536310, acc.: 69.53%] [G loss: 1.725404]\n",
      "epoch:24 step:23265 [D loss: 0.493373, acc.: 79.69%] [G loss: 1.580531]\n",
      "epoch:24 step:23266 [D loss: 1.004953, acc.: 39.06%] [G loss: 1.297476]\n",
      "epoch:24 step:23267 [D loss: 0.710790, acc.: 53.91%] [G loss: 1.294076]\n",
      "epoch:24 step:23268 [D loss: 0.149673, acc.: 95.31%] [G loss: 1.488979]\n",
      "epoch:24 step:23269 [D loss: 0.197460, acc.: 92.97%] [G loss: 1.492101]\n",
      "epoch:24 step:23270 [D loss: 0.367056, acc.: 85.94%] [G loss: 1.970658]\n",
      "epoch:24 step:23271 [D loss: 0.714183, acc.: 59.38%] [G loss: 1.690985]\n",
      "epoch:24 step:23272 [D loss: 0.747537, acc.: 54.69%] [G loss: 1.404553]\n",
      "epoch:24 step:23273 [D loss: 0.635857, acc.: 59.38%] [G loss: 1.221286]\n",
      "epoch:24 step:23274 [D loss: 0.350455, acc.: 89.84%] [G loss: 1.343055]\n",
      "epoch:24 step:23275 [D loss: 0.951183, acc.: 37.50%] [G loss: 1.137270]\n",
      "epoch:24 step:23276 [D loss: 0.648423, acc.: 60.94%] [G loss: 0.852828]\n",
      "epoch:24 step:23277 [D loss: 1.137620, acc.: 22.66%] [G loss: 1.071080]\n",
      "epoch:24 step:23278 [D loss: 0.766515, acc.: 54.69%] [G loss: 0.551565]\n",
      "epoch:24 step:23279 [D loss: 0.235229, acc.: 92.19%] [G loss: 1.650612]\n",
      "epoch:24 step:23280 [D loss: 0.198652, acc.: 96.88%] [G loss: 1.816479]\n",
      "epoch:24 step:23281 [D loss: 0.407167, acc.: 81.25%] [G loss: 1.595874]\n",
      "epoch:24 step:23282 [D loss: 0.536212, acc.: 73.44%] [G loss: 1.587866]\n",
      "epoch:24 step:23283 [D loss: 0.564196, acc.: 72.66%] [G loss: 1.250040]\n",
      "epoch:24 step:23284 [D loss: 0.657841, acc.: 62.50%] [G loss: 1.635639]\n",
      "epoch:24 step:23285 [D loss: 0.766863, acc.: 48.44%] [G loss: 2.176559]\n",
      "epoch:24 step:23286 [D loss: 0.844415, acc.: 45.31%] [G loss: 1.833905]\n",
      "epoch:24 step:23287 [D loss: 0.748298, acc.: 57.03%] [G loss: 1.904503]\n",
      "epoch:24 step:23288 [D loss: 0.137296, acc.: 98.44%] [G loss: 2.330219]\n",
      "epoch:24 step:23289 [D loss: 0.298713, acc.: 85.94%] [G loss: 2.148665]\n",
      "epoch:24 step:23290 [D loss: 0.191033, acc.: 96.09%] [G loss: 2.219226]\n",
      "epoch:24 step:23291 [D loss: 0.252147, acc.: 94.53%] [G loss: 2.313527]\n",
      "epoch:24 step:23292 [D loss: 0.755698, acc.: 64.84%] [G loss: 1.415637]\n",
      "epoch:24 step:23293 [D loss: 0.723461, acc.: 59.38%] [G loss: 0.336204]\n",
      "epoch:24 step:23294 [D loss: 0.338532, acc.: 83.59%] [G loss: 1.091949]\n",
      "epoch:24 step:23295 [D loss: 0.796755, acc.: 51.56%] [G loss: 1.950563]\n",
      "epoch:24 step:23296 [D loss: 0.172260, acc.: 95.31%] [G loss: 2.958106]\n",
      "epoch:24 step:23297 [D loss: 0.133865, acc.: 97.66%] [G loss: 2.559031]\n",
      "epoch:24 step:23298 [D loss: 0.139271, acc.: 96.88%] [G loss: 2.096447]\n",
      "epoch:24 step:23299 [D loss: 1.024303, acc.: 53.12%] [G loss: 2.070848]\n",
      "epoch:24 step:23300 [D loss: 0.888057, acc.: 44.53%] [G loss: 2.448011]\n",
      "epoch:24 step:23301 [D loss: 0.439702, acc.: 82.81%] [G loss: 2.005060]\n",
      "epoch:24 step:23302 [D loss: 0.289216, acc.: 93.75%] [G loss: 2.796231]\n",
      "epoch:24 step:23303 [D loss: 0.109180, acc.: 96.88%] [G loss: 2.610268]\n",
      "epoch:24 step:23304 [D loss: 0.096994, acc.: 96.09%] [G loss: 2.962499]\n",
      "epoch:24 step:23305 [D loss: 0.287485, acc.: 89.06%] [G loss: 2.824746]\n",
      "epoch:24 step:23306 [D loss: 0.158441, acc.: 97.66%] [G loss: 2.919907]\n",
      "epoch:24 step:23307 [D loss: 0.115527, acc.: 99.22%] [G loss: 2.740228]\n",
      "epoch:24 step:23308 [D loss: 0.513477, acc.: 68.75%] [G loss: 2.117585]\n",
      "epoch:24 step:23309 [D loss: 1.153799, acc.: 40.62%] [G loss: 1.381617]\n",
      "epoch:24 step:23310 [D loss: 0.379100, acc.: 85.16%] [G loss: 2.007180]\n",
      "epoch:24 step:23311 [D loss: 0.229675, acc.: 94.53%] [G loss: 0.774389]\n",
      "epoch:24 step:23312 [D loss: 0.364095, acc.: 82.81%] [G loss: 4.041808]\n",
      "epoch:24 step:23313 [D loss: 0.058400, acc.: 100.00%] [G loss: 3.354226]\n",
      "epoch:24 step:23314 [D loss: 0.352099, acc.: 81.25%] [G loss: 2.465378]\n",
      "epoch:24 step:23315 [D loss: 0.379833, acc.: 83.59%] [G loss: 2.617650]\n",
      "epoch:24 step:23316 [D loss: 0.696874, acc.: 59.38%] [G loss: 2.499320]\n",
      "epoch:24 step:23317 [D loss: 0.393031, acc.: 82.03%] [G loss: 3.178077]\n",
      "epoch:24 step:23318 [D loss: 0.108678, acc.: 98.44%] [G loss: 2.646419]\n",
      "epoch:24 step:23319 [D loss: 0.089036, acc.: 97.66%] [G loss: 2.538908]\n",
      "epoch:24 step:23320 [D loss: 0.222948, acc.: 89.06%] [G loss: 2.560601]\n",
      "epoch:24 step:23321 [D loss: 0.975365, acc.: 57.81%] [G loss: 2.466238]\n",
      "epoch:24 step:23322 [D loss: 1.216062, acc.: 46.88%] [G loss: 2.649376]\n",
      "epoch:24 step:23323 [D loss: 0.692119, acc.: 60.16%] [G loss: 3.013832]\n",
      "epoch:24 step:23324 [D loss: 0.598920, acc.: 71.88%] [G loss: 2.887428]\n",
      "epoch:24 step:23325 [D loss: 0.390637, acc.: 77.34%] [G loss: 2.731152]\n",
      "epoch:24 step:23326 [D loss: 0.417378, acc.: 80.47%] [G loss: 3.957546]\n",
      "epoch:24 step:23327 [D loss: 0.516780, acc.: 70.31%] [G loss: 2.243153]\n",
      "epoch:24 step:23328 [D loss: 0.415220, acc.: 83.59%] [G loss: 2.486901]\n",
      "epoch:24 step:23329 [D loss: 0.429962, acc.: 79.69%] [G loss: 2.522462]\n",
      "epoch:24 step:23330 [D loss: 0.224867, acc.: 91.41%] [G loss: 2.562587]\n",
      "epoch:24 step:23331 [D loss: 0.740516, acc.: 63.28%] [G loss: 2.671432]\n",
      "epoch:24 step:23332 [D loss: 0.539941, acc.: 73.44%] [G loss: 2.233863]\n",
      "epoch:24 step:23333 [D loss: 0.608627, acc.: 69.53%] [G loss: 1.583974]\n",
      "epoch:24 step:23334 [D loss: 0.450539, acc.: 78.91%] [G loss: 2.216653]\n",
      "epoch:24 step:23335 [D loss: 0.284007, acc.: 88.28%] [G loss: 2.326069]\n",
      "epoch:24 step:23336 [D loss: 0.330069, acc.: 86.72%] [G loss: 2.594302]\n",
      "epoch:24 step:23337 [D loss: 0.381293, acc.: 86.72%] [G loss: 2.051114]\n",
      "epoch:24 step:23338 [D loss: 0.417691, acc.: 79.69%] [G loss: 1.651170]\n",
      "epoch:24 step:23339 [D loss: 0.298437, acc.: 85.16%] [G loss: 2.574890]\n",
      "epoch:24 step:23340 [D loss: 0.235918, acc.: 93.75%] [G loss: 2.313414]\n",
      "epoch:24 step:23341 [D loss: 0.373155, acc.: 83.59%] [G loss: 1.861850]\n",
      "epoch:24 step:23342 [D loss: 0.533720, acc.: 75.78%] [G loss: 2.548125]\n",
      "epoch:24 step:23343 [D loss: 0.441200, acc.: 82.81%] [G loss: 2.190846]\n",
      "epoch:24 step:23344 [D loss: 0.899209, acc.: 55.47%] [G loss: 1.238754]\n",
      "epoch:24 step:23345 [D loss: 0.405385, acc.: 82.03%] [G loss: 1.536462]\n",
      "epoch:24 step:23346 [D loss: 1.616396, acc.: 38.28%] [G loss: 1.786542]\n",
      "epoch:24 step:23347 [D loss: 0.774650, acc.: 54.69%] [G loss: 1.517253]\n",
      "epoch:24 step:23348 [D loss: 0.676020, acc.: 59.38%] [G loss: 2.015070]\n",
      "epoch:24 step:23349 [D loss: 0.565351, acc.: 69.53%] [G loss: 1.968218]\n",
      "epoch:24 step:23350 [D loss: 0.482589, acc.: 75.00%] [G loss: 1.353225]\n",
      "epoch:24 step:23351 [D loss: 0.448587, acc.: 82.81%] [G loss: 1.685066]\n",
      "epoch:24 step:23352 [D loss: 0.573371, acc.: 73.44%] [G loss: 1.748198]\n",
      "epoch:24 step:23353 [D loss: 0.512062, acc.: 74.22%] [G loss: 1.301598]\n",
      "epoch:24 step:23354 [D loss: 0.581623, acc.: 64.84%] [G loss: 1.289141]\n",
      "epoch:24 step:23355 [D loss: 0.702886, acc.: 60.16%] [G loss: 1.722502]\n",
      "epoch:24 step:23356 [D loss: 0.701266, acc.: 56.25%] [G loss: 1.578894]\n",
      "epoch:24 step:23357 [D loss: 0.628066, acc.: 69.53%] [G loss: 1.729504]\n",
      "epoch:24 step:23358 [D loss: 0.608673, acc.: 63.28%] [G loss: 1.459595]\n",
      "epoch:24 step:23359 [D loss: 0.567190, acc.: 68.75%] [G loss: 1.445019]\n",
      "epoch:24 step:23360 [D loss: 0.738625, acc.: 52.34%] [G loss: 1.486773]\n",
      "epoch:24 step:23361 [D loss: 0.615822, acc.: 68.75%] [G loss: 1.486693]\n",
      "epoch:24 step:23362 [D loss: 0.724253, acc.: 60.94%] [G loss: 1.296574]\n",
      "epoch:24 step:23363 [D loss: 0.643026, acc.: 64.84%] [G loss: 1.620999]\n",
      "epoch:24 step:23364 [D loss: 0.476542, acc.: 81.25%] [G loss: 1.334723]\n",
      "epoch:24 step:23365 [D loss: 0.450002, acc.: 79.69%] [G loss: 1.466970]\n",
      "epoch:24 step:23366 [D loss: 0.295459, acc.: 91.41%] [G loss: 1.688035]\n",
      "epoch:24 step:23367 [D loss: 0.565318, acc.: 75.00%] [G loss: 2.014400]\n",
      "epoch:24 step:23368 [D loss: 0.762229, acc.: 54.69%] [G loss: 1.467527]\n",
      "epoch:24 step:23369 [D loss: 0.596550, acc.: 67.19%] [G loss: 1.267624]\n",
      "epoch:24 step:23370 [D loss: 0.940253, acc.: 49.22%] [G loss: 1.281576]\n",
      "epoch:24 step:23371 [D loss: 0.802589, acc.: 49.22%] [G loss: 1.102468]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:24 step:23372 [D loss: 0.619333, acc.: 67.97%] [G loss: 1.109060]\n",
      "epoch:24 step:23373 [D loss: 0.372188, acc.: 78.91%] [G loss: 1.448463]\n",
      "epoch:24 step:23374 [D loss: 0.469207, acc.: 75.78%] [G loss: 1.208733]\n",
      "epoch:24 step:23375 [D loss: 0.633084, acc.: 64.06%] [G loss: 1.054396]\n",
      "epoch:24 step:23376 [D loss: 0.577157, acc.: 69.53%] [G loss: 1.169212]\n",
      "epoch:24 step:23377 [D loss: 0.534797, acc.: 75.00%] [G loss: 1.210923]\n",
      "epoch:24 step:23378 [D loss: 0.492992, acc.: 74.22%] [G loss: 1.116719]\n",
      "epoch:24 step:23379 [D loss: 0.448989, acc.: 81.25%] [G loss: 1.491819]\n",
      "epoch:24 step:23380 [D loss: 0.434139, acc.: 81.25%] [G loss: 1.527865]\n",
      "epoch:24 step:23381 [D loss: 0.544632, acc.: 71.88%] [G loss: 1.179347]\n",
      "epoch:24 step:23382 [D loss: 0.453807, acc.: 81.25%] [G loss: 1.243142]\n",
      "epoch:24 step:23383 [D loss: 0.401622, acc.: 89.06%] [G loss: 1.605921]\n",
      "epoch:24 step:23384 [D loss: 0.370420, acc.: 86.72%] [G loss: 1.489950]\n",
      "epoch:24 step:23385 [D loss: 0.504720, acc.: 79.69%] [G loss: 1.388313]\n",
      "epoch:24 step:23386 [D loss: 0.264859, acc.: 88.28%] [G loss: 1.879942]\n",
      "epoch:24 step:23387 [D loss: 0.172883, acc.: 96.88%] [G loss: 2.013563]\n",
      "epoch:24 step:23388 [D loss: 0.240461, acc.: 95.31%] [G loss: 2.486094]\n",
      "epoch:24 step:23389 [D loss: 0.291665, acc.: 92.97%] [G loss: 1.616778]\n",
      "epoch:24 step:23390 [D loss: 0.569126, acc.: 72.66%] [G loss: 1.379567]\n",
      "epoch:24 step:23391 [D loss: 0.387973, acc.: 88.28%] [G loss: 2.402190]\n",
      "epoch:24 step:23392 [D loss: 0.701634, acc.: 63.28%] [G loss: 1.537558]\n",
      "epoch:24 step:23393 [D loss: 0.627965, acc.: 67.97%] [G loss: 1.433774]\n",
      "epoch:24 step:23394 [D loss: 0.562391, acc.: 76.56%] [G loss: 0.934390]\n",
      "epoch:24 step:23395 [D loss: 0.646161, acc.: 59.38%] [G loss: 0.991680]\n",
      "epoch:24 step:23396 [D loss: 0.486863, acc.: 75.78%] [G loss: 1.210080]\n",
      "epoch:24 step:23397 [D loss: 0.333724, acc.: 86.72%] [G loss: 1.538785]\n",
      "epoch:24 step:23398 [D loss: 0.711855, acc.: 55.47%] [G loss: 1.481875]\n",
      "epoch:24 step:23399 [D loss: 0.296363, acc.: 87.50%] [G loss: 1.423456]\n",
      "epoch:24 step:23400 [D loss: 0.180825, acc.: 96.09%] [G loss: 1.135886]\n",
      "##############\n",
      "[3.96820233 2.70744436 6.50372055 5.90048655 4.05249727 5.91498481\n",
      " 5.06741196 5.17863705 5.76443111 4.67775741]\n",
      "##########\n",
      "epoch:24 step:23401 [D loss: 0.546716, acc.: 72.66%] [G loss: 1.574169]\n",
      "epoch:24 step:23402 [D loss: 0.635914, acc.: 61.72%] [G loss: 1.607499]\n",
      "epoch:24 step:23403 [D loss: 0.693758, acc.: 60.16%] [G loss: 1.242246]\n",
      "epoch:24 step:23404 [D loss: 0.644450, acc.: 63.28%] [G loss: 1.294392]\n",
      "epoch:24 step:23405 [D loss: 0.604897, acc.: 69.53%] [G loss: 1.087235]\n",
      "epoch:24 step:23406 [D loss: 0.526880, acc.: 73.44%] [G loss: 1.016048]\n",
      "epoch:24 step:23407 [D loss: 0.326427, acc.: 85.94%] [G loss: 1.152124]\n",
      "epoch:24 step:23408 [D loss: 0.432234, acc.: 80.47%] [G loss: 1.486703]\n",
      "epoch:24 step:23409 [D loss: 0.591847, acc.: 66.41%] [G loss: 1.263521]\n",
      "epoch:24 step:23410 [D loss: 0.514116, acc.: 78.91%] [G loss: 1.456535]\n",
      "epoch:24 step:23411 [D loss: 0.342201, acc.: 88.28%] [G loss: 1.262108]\n",
      "epoch:24 step:23412 [D loss: 0.252722, acc.: 96.09%] [G loss: 1.376683]\n",
      "epoch:24 step:23413 [D loss: 0.280430, acc.: 89.84%] [G loss: 1.353000]\n",
      "epoch:24 step:23414 [D loss: 0.191066, acc.: 95.31%] [G loss: 1.654207]\n",
      "epoch:24 step:23415 [D loss: 0.251012, acc.: 93.75%] [G loss: 1.926272]\n",
      "epoch:24 step:23416 [D loss: 0.743245, acc.: 59.38%] [G loss: 1.386555]\n",
      "epoch:24 step:23417 [D loss: 0.272245, acc.: 91.41%] [G loss: 1.621309]\n",
      "epoch:24 step:23418 [D loss: 0.493507, acc.: 78.91%] [G loss: 1.581719]\n",
      "epoch:24 step:23419 [D loss: 0.373112, acc.: 87.50%] [G loss: 1.539362]\n",
      "epoch:24 step:23420 [D loss: 0.253812, acc.: 93.75%] [G loss: 1.860838]\n",
      "epoch:24 step:23421 [D loss: 0.176980, acc.: 97.66%] [G loss: 1.574184]\n",
      "epoch:24 step:23422 [D loss: 0.179105, acc.: 95.31%] [G loss: 1.930500]\n",
      "epoch:24 step:23423 [D loss: 0.313559, acc.: 85.94%] [G loss: 1.345516]\n",
      "epoch:24 step:23424 [D loss: 0.134745, acc.: 100.00%] [G loss: 2.720395]\n",
      "epoch:24 step:23425 [D loss: 0.103451, acc.: 98.44%] [G loss: 1.968699]\n",
      "epoch:25 step:23426 [D loss: 0.447386, acc.: 79.69%] [G loss: 2.135897]\n",
      "epoch:25 step:23427 [D loss: 0.441948, acc.: 78.91%] [G loss: 1.660959]\n",
      "epoch:25 step:23428 [D loss: 0.464905, acc.: 78.91%] [G loss: 2.093682]\n",
      "epoch:25 step:23429 [D loss: 0.690417, acc.: 57.03%] [G loss: 1.811011]\n",
      "epoch:25 step:23430 [D loss: 0.427289, acc.: 82.81%] [G loss: 2.032897]\n",
      "epoch:25 step:23431 [D loss: 0.488728, acc.: 81.25%] [G loss: 0.761654]\n",
      "epoch:25 step:23432 [D loss: 0.331386, acc.: 87.50%] [G loss: 0.618301]\n",
      "epoch:25 step:23433 [D loss: 0.372686, acc.: 80.47%] [G loss: 1.176116]\n",
      "epoch:25 step:23434 [D loss: 0.173864, acc.: 97.66%] [G loss: 2.089958]\n",
      "epoch:25 step:23435 [D loss: 0.263040, acc.: 91.41%] [G loss: 2.848299]\n",
      "epoch:25 step:23436 [D loss: 0.264942, acc.: 93.75%] [G loss: 1.082536]\n",
      "epoch:25 step:23437 [D loss: 0.273339, acc.: 92.97%] [G loss: 0.679929]\n",
      "epoch:25 step:23438 [D loss: 0.216470, acc.: 97.66%] [G loss: 2.028037]\n",
      "epoch:25 step:23439 [D loss: 0.302225, acc.: 89.84%] [G loss: 0.921953]\n",
      "epoch:25 step:23440 [D loss: 0.743238, acc.: 54.69%] [G loss: 2.742489]\n",
      "epoch:25 step:23441 [D loss: 0.328568, acc.: 89.84%] [G loss: 1.628011]\n",
      "epoch:25 step:23442 [D loss: 0.451053, acc.: 73.44%] [G loss: 1.261485]\n",
      "epoch:25 step:23443 [D loss: 0.424033, acc.: 82.03%] [G loss: 1.878561]\n",
      "epoch:25 step:23444 [D loss: 1.340312, acc.: 23.44%] [G loss: 1.576462]\n",
      "epoch:25 step:23445 [D loss: 1.178493, acc.: 40.62%] [G loss: 1.262529]\n",
      "epoch:25 step:23446 [D loss: 0.873322, acc.: 49.22%] [G loss: 1.782949]\n",
      "epoch:25 step:23447 [D loss: 0.745423, acc.: 57.81%] [G loss: 1.280257]\n",
      "epoch:25 step:23448 [D loss: 0.773007, acc.: 56.25%] [G loss: 1.140433]\n",
      "epoch:25 step:23449 [D loss: 0.707134, acc.: 64.84%] [G loss: 0.799098]\n",
      "epoch:25 step:23450 [D loss: 0.465098, acc.: 77.34%] [G loss: 1.269417]\n",
      "epoch:25 step:23451 [D loss: 1.001083, acc.: 41.41%] [G loss: 1.523073]\n",
      "epoch:25 step:23452 [D loss: 0.717864, acc.: 58.59%] [G loss: 0.968828]\n",
      "epoch:25 step:23453 [D loss: 0.767282, acc.: 57.03%] [G loss: 1.802810]\n",
      "epoch:25 step:23454 [D loss: 0.654485, acc.: 65.62%] [G loss: 1.150140]\n",
      "epoch:25 step:23455 [D loss: 0.862804, acc.: 48.44%] [G loss: 1.736662]\n",
      "epoch:25 step:23456 [D loss: 0.412942, acc.: 82.03%] [G loss: 1.686200]\n",
      "epoch:25 step:23457 [D loss: 0.438017, acc.: 81.25%] [G loss: 1.609701]\n",
      "epoch:25 step:23458 [D loss: 0.375684, acc.: 87.50%] [G loss: 1.688818]\n",
      "epoch:25 step:23459 [D loss: 0.331587, acc.: 90.62%] [G loss: 1.742190]\n",
      "epoch:25 step:23460 [D loss: 0.284903, acc.: 91.41%] [G loss: 1.556758]\n",
      "epoch:25 step:23461 [D loss: 0.202434, acc.: 96.09%] [G loss: 2.167910]\n",
      "epoch:25 step:23462 [D loss: 0.909188, acc.: 51.56%] [G loss: 1.716038]\n",
      "epoch:25 step:23463 [D loss: 0.884764, acc.: 41.41%] [G loss: 1.210518]\n",
      "epoch:25 step:23464 [D loss: 0.792579, acc.: 53.91%] [G loss: 1.296264]\n",
      "epoch:25 step:23465 [D loss: 0.787833, acc.: 47.66%] [G loss: 1.017922]\n",
      "epoch:25 step:23466 [D loss: 0.575951, acc.: 67.19%] [G loss: 1.217902]\n",
      "epoch:25 step:23467 [D loss: 0.491104, acc.: 76.56%] [G loss: 1.235124]\n",
      "epoch:25 step:23468 [D loss: 0.404372, acc.: 89.06%] [G loss: 1.396555]\n",
      "epoch:25 step:23469 [D loss: 0.474643, acc.: 82.03%] [G loss: 1.428577]\n",
      "epoch:25 step:23470 [D loss: 0.483785, acc.: 76.56%] [G loss: 1.493129]\n",
      "epoch:25 step:23471 [D loss: 0.436769, acc.: 82.81%] [G loss: 1.249447]\n",
      "epoch:25 step:23472 [D loss: 0.688978, acc.: 57.03%] [G loss: 1.460647]\n",
      "epoch:25 step:23473 [D loss: 0.764619, acc.: 53.91%] [G loss: 1.122759]\n",
      "epoch:25 step:23474 [D loss: 0.687380, acc.: 59.38%] [G loss: 0.796225]\n",
      "epoch:25 step:23475 [D loss: 0.457869, acc.: 82.03%] [G loss: 1.211729]\n",
      "epoch:25 step:23476 [D loss: 0.567239, acc.: 74.22%] [G loss: 1.094961]\n",
      "epoch:25 step:23477 [D loss: 0.368780, acc.: 86.72%] [G loss: 1.248341]\n",
      "epoch:25 step:23478 [D loss: 0.589983, acc.: 70.31%] [G loss: 1.376512]\n",
      "epoch:25 step:23479 [D loss: 0.647306, acc.: 62.50%] [G loss: 1.305099]\n",
      "epoch:25 step:23480 [D loss: 0.798416, acc.: 57.81%] [G loss: 1.522154]\n",
      "epoch:25 step:23481 [D loss: 0.621018, acc.: 71.09%] [G loss: 1.229851]\n",
      "epoch:25 step:23482 [D loss: 0.349216, acc.: 85.16%] [G loss: 1.486504]\n",
      "epoch:25 step:23483 [D loss: 0.334777, acc.: 86.72%] [G loss: 1.308015]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:25 step:23484 [D loss: 0.513646, acc.: 74.22%] [G loss: 1.505305]\n",
      "epoch:25 step:23485 [D loss: 0.431188, acc.: 80.47%] [G loss: 1.263194]\n",
      "epoch:25 step:23486 [D loss: 0.703459, acc.: 54.69%] [G loss: 1.999086]\n",
      "epoch:25 step:23487 [D loss: 0.660951, acc.: 59.38%] [G loss: 1.507797]\n",
      "epoch:25 step:23488 [D loss: 0.505214, acc.: 74.22%] [G loss: 1.237918]\n",
      "epoch:25 step:23489 [D loss: 0.759003, acc.: 50.78%] [G loss: 1.222288]\n",
      "epoch:25 step:23490 [D loss: 0.626334, acc.: 63.28%] [G loss: 1.328767]\n",
      "epoch:25 step:23491 [D loss: 0.664073, acc.: 57.81%] [G loss: 0.910883]\n",
      "epoch:25 step:23492 [D loss: 0.575364, acc.: 69.53%] [G loss: 1.457974]\n",
      "epoch:25 step:23493 [D loss: 0.849644, acc.: 44.53%] [G loss: 1.043553]\n",
      "epoch:25 step:23494 [D loss: 0.544218, acc.: 72.66%] [G loss: 1.152213]\n",
      "epoch:25 step:23495 [D loss: 0.627532, acc.: 68.75%] [G loss: 1.155448]\n",
      "epoch:25 step:23496 [D loss: 0.228699, acc.: 89.84%] [G loss: 1.805113]\n",
      "epoch:25 step:23497 [D loss: 0.593520, acc.: 66.41%] [G loss: 1.376450]\n",
      "epoch:25 step:23498 [D loss: 0.391412, acc.: 84.38%] [G loss: 1.552603]\n",
      "epoch:25 step:23499 [D loss: 0.472141, acc.: 79.69%] [G loss: 1.488787]\n",
      "epoch:25 step:23500 [D loss: 0.226322, acc.: 92.19%] [G loss: 1.551099]\n",
      "epoch:25 step:23501 [D loss: 0.173642, acc.: 92.19%] [G loss: 2.359443]\n",
      "epoch:25 step:23502 [D loss: 0.222819, acc.: 93.75%] [G loss: 1.954355]\n",
      "epoch:25 step:23503 [D loss: 0.957504, acc.: 50.00%] [G loss: 1.782118]\n",
      "epoch:25 step:23504 [D loss: 0.692344, acc.: 63.28%] [G loss: 1.746007]\n",
      "epoch:25 step:23505 [D loss: 0.901698, acc.: 41.41%] [G loss: 1.070751]\n",
      "epoch:25 step:23506 [D loss: 0.731505, acc.: 56.25%] [G loss: 1.477008]\n",
      "epoch:25 step:23507 [D loss: 0.696429, acc.: 60.94%] [G loss: 2.047660]\n",
      "epoch:25 step:23508 [D loss: 0.705833, acc.: 57.81%] [G loss: 1.168832]\n",
      "epoch:25 step:23509 [D loss: 0.637677, acc.: 59.38%] [G loss: 1.318922]\n",
      "epoch:25 step:23510 [D loss: 0.654640, acc.: 60.94%] [G loss: 1.085065]\n",
      "epoch:25 step:23511 [D loss: 0.617529, acc.: 67.97%] [G loss: 1.259314]\n",
      "epoch:25 step:23512 [D loss: 0.549484, acc.: 74.22%] [G loss: 1.364342]\n",
      "epoch:25 step:23513 [D loss: 0.486995, acc.: 76.56%] [G loss: 1.369535]\n",
      "epoch:25 step:23514 [D loss: 0.447365, acc.: 82.81%] [G loss: 1.352177]\n",
      "epoch:25 step:23515 [D loss: 0.461526, acc.: 81.25%] [G loss: 1.577305]\n",
      "epoch:25 step:23516 [D loss: 0.630981, acc.: 65.62%] [G loss: 0.997888]\n",
      "epoch:25 step:23517 [D loss: 0.582414, acc.: 68.75%] [G loss: 1.375897]\n",
      "epoch:25 step:23518 [D loss: 0.353273, acc.: 89.06%] [G loss: 0.958492]\n",
      "epoch:25 step:23519 [D loss: 0.589196, acc.: 67.19%] [G loss: 1.067777]\n",
      "epoch:25 step:23520 [D loss: 0.570190, acc.: 71.09%] [G loss: 1.639313]\n",
      "epoch:25 step:23521 [D loss: 0.610302, acc.: 62.50%] [G loss: 1.243229]\n",
      "epoch:25 step:23522 [D loss: 0.522439, acc.: 75.78%] [G loss: 1.090724]\n",
      "epoch:25 step:23523 [D loss: 0.681069, acc.: 61.72%] [G loss: 1.085728]\n",
      "epoch:25 step:23524 [D loss: 0.680084, acc.: 64.06%] [G loss: 0.922801]\n",
      "epoch:25 step:23525 [D loss: 0.586102, acc.: 68.75%] [G loss: 0.948189]\n",
      "epoch:25 step:23526 [D loss: 0.526136, acc.: 75.00%] [G loss: 1.015827]\n",
      "epoch:25 step:23527 [D loss: 0.772319, acc.: 58.59%] [G loss: 0.937260]\n",
      "epoch:25 step:23528 [D loss: 0.690206, acc.: 55.47%] [G loss: 1.100226]\n",
      "epoch:25 step:23529 [D loss: 0.699319, acc.: 57.03%] [G loss: 1.020561]\n",
      "epoch:25 step:23530 [D loss: 0.593380, acc.: 65.62%] [G loss: 0.888062]\n",
      "epoch:25 step:23531 [D loss: 0.652159, acc.: 60.94%] [G loss: 0.974940]\n",
      "epoch:25 step:23532 [D loss: 0.547154, acc.: 69.53%] [G loss: 1.099834]\n",
      "epoch:25 step:23533 [D loss: 0.628801, acc.: 65.62%] [G loss: 1.364602]\n",
      "epoch:25 step:23534 [D loss: 0.594944, acc.: 68.75%] [G loss: 1.104742]\n",
      "epoch:25 step:23535 [D loss: 0.541087, acc.: 71.88%] [G loss: 1.145693]\n",
      "epoch:25 step:23536 [D loss: 0.614882, acc.: 66.41%] [G loss: 1.095224]\n",
      "epoch:25 step:23537 [D loss: 0.496515, acc.: 76.56%] [G loss: 1.556295]\n",
      "epoch:25 step:23538 [D loss: 0.487571, acc.: 78.12%] [G loss: 1.192633]\n",
      "epoch:25 step:23539 [D loss: 0.443777, acc.: 83.59%] [G loss: 1.513501]\n",
      "epoch:25 step:23540 [D loss: 0.421632, acc.: 82.81%] [G loss: 1.425532]\n",
      "epoch:25 step:23541 [D loss: 0.585908, acc.: 71.88%] [G loss: 1.337702]\n",
      "epoch:25 step:23542 [D loss: 0.458027, acc.: 76.56%] [G loss: 1.383288]\n",
      "epoch:25 step:23543 [D loss: 0.526323, acc.: 71.88%] [G loss: 1.167059]\n",
      "epoch:25 step:23544 [D loss: 0.273024, acc.: 86.72%] [G loss: 1.381561]\n",
      "epoch:25 step:23545 [D loss: 0.440295, acc.: 85.94%] [G loss: 1.346804]\n",
      "epoch:25 step:23546 [D loss: 0.557268, acc.: 69.53%] [G loss: 1.507656]\n",
      "epoch:25 step:23547 [D loss: 0.331972, acc.: 90.62%] [G loss: 1.617273]\n",
      "epoch:25 step:23548 [D loss: 0.727756, acc.: 60.94%] [G loss: 1.426996]\n",
      "epoch:25 step:23549 [D loss: 0.663539, acc.: 60.94%] [G loss: 1.133793]\n",
      "epoch:25 step:23550 [D loss: 0.776695, acc.: 51.56%] [G loss: 1.179515]\n",
      "epoch:25 step:23551 [D loss: 0.658392, acc.: 60.94%] [G loss: 1.082846]\n",
      "epoch:25 step:23552 [D loss: 0.659522, acc.: 64.06%] [G loss: 1.235768]\n",
      "epoch:25 step:23553 [D loss: 0.581453, acc.: 68.75%] [G loss: 1.238743]\n",
      "epoch:25 step:23554 [D loss: 0.430319, acc.: 81.25%] [G loss: 1.029518]\n",
      "epoch:25 step:23555 [D loss: 0.333260, acc.: 89.06%] [G loss: 1.278237]\n",
      "epoch:25 step:23556 [D loss: 0.353481, acc.: 89.06%] [G loss: 1.454770]\n",
      "epoch:25 step:23557 [D loss: 0.322327, acc.: 92.97%] [G loss: 1.645142]\n",
      "epoch:25 step:23558 [D loss: 0.449522, acc.: 78.12%] [G loss: 1.204609]\n",
      "epoch:25 step:23559 [D loss: 0.359278, acc.: 88.28%] [G loss: 1.402783]\n",
      "epoch:25 step:23560 [D loss: 0.476065, acc.: 80.47%] [G loss: 1.655738]\n",
      "epoch:25 step:23561 [D loss: 0.672321, acc.: 66.41%] [G loss: 1.536765]\n",
      "epoch:25 step:23562 [D loss: 0.541651, acc.: 73.44%] [G loss: 1.469662]\n",
      "epoch:25 step:23563 [D loss: 0.460201, acc.: 82.03%] [G loss: 1.296458]\n",
      "epoch:25 step:23564 [D loss: 0.335495, acc.: 89.84%] [G loss: 1.620042]\n",
      "epoch:25 step:23565 [D loss: 0.537117, acc.: 72.66%] [G loss: 1.487551]\n",
      "epoch:25 step:23566 [D loss: 0.659430, acc.: 64.84%] [G loss: 1.487997]\n",
      "epoch:25 step:23567 [D loss: 0.584459, acc.: 64.84%] [G loss: 1.514490]\n",
      "epoch:25 step:23568 [D loss: 0.310839, acc.: 86.72%] [G loss: 1.493128]\n",
      "epoch:25 step:23569 [D loss: 0.513018, acc.: 75.78%] [G loss: 1.541256]\n",
      "epoch:25 step:23570 [D loss: 0.229979, acc.: 95.31%] [G loss: 1.309655]\n",
      "epoch:25 step:23571 [D loss: 0.497063, acc.: 79.69%] [G loss: 1.534124]\n",
      "epoch:25 step:23572 [D loss: 0.616506, acc.: 64.06%] [G loss: 1.280401]\n",
      "epoch:25 step:23573 [D loss: 0.837823, acc.: 51.56%] [G loss: 1.084955]\n",
      "epoch:25 step:23574 [D loss: 0.363032, acc.: 80.47%] [G loss: 1.582057]\n",
      "epoch:25 step:23575 [D loss: 0.186115, acc.: 96.09%] [G loss: 1.455219]\n",
      "epoch:25 step:23576 [D loss: 0.350802, acc.: 85.94%] [G loss: 1.772741]\n",
      "epoch:25 step:23577 [D loss: 0.523810, acc.: 75.00%] [G loss: 1.673214]\n",
      "epoch:25 step:23578 [D loss: 0.874874, acc.: 51.56%] [G loss: 1.782613]\n",
      "epoch:25 step:23579 [D loss: 0.837156, acc.: 54.69%] [G loss: 1.512455]\n",
      "epoch:25 step:23580 [D loss: 0.657762, acc.: 67.97%] [G loss: 1.235245]\n",
      "epoch:25 step:23581 [D loss: 0.547653, acc.: 74.22%] [G loss: 0.392868]\n",
      "epoch:25 step:23582 [D loss: 0.544407, acc.: 71.88%] [G loss: 0.410467]\n",
      "epoch:25 step:23583 [D loss: 0.805391, acc.: 43.75%] [G loss: 1.297391]\n",
      "epoch:25 step:23584 [D loss: 0.542134, acc.: 74.22%] [G loss: 1.104901]\n",
      "epoch:25 step:23585 [D loss: 0.423025, acc.: 85.16%] [G loss: 1.025375]\n",
      "epoch:25 step:23586 [D loss: 0.672785, acc.: 59.38%] [G loss: 0.846563]\n",
      "epoch:25 step:23587 [D loss: 0.433426, acc.: 81.25%] [G loss: 1.169498]\n",
      "epoch:25 step:23588 [D loss: 0.396031, acc.: 88.28%] [G loss: 0.567010]\n",
      "epoch:25 step:23589 [D loss: 0.832016, acc.: 48.44%] [G loss: 1.626062]\n",
      "epoch:25 step:23590 [D loss: 0.409887, acc.: 88.28%] [G loss: 0.757619]\n",
      "epoch:25 step:23591 [D loss: 0.815651, acc.: 46.88%] [G loss: 0.695807]\n",
      "epoch:25 step:23592 [D loss: 0.583701, acc.: 71.88%] [G loss: 1.460227]\n",
      "epoch:25 step:23593 [D loss: 0.470905, acc.: 78.12%] [G loss: 1.116704]\n",
      "epoch:25 step:23594 [D loss: 0.825631, acc.: 42.97%] [G loss: 0.509279]\n",
      "epoch:25 step:23595 [D loss: 0.773412, acc.: 53.12%] [G loss: 1.492799]\n",
      "epoch:25 step:23596 [D loss: 0.677844, acc.: 64.84%] [G loss: 1.151755]\n",
      "epoch:25 step:23597 [D loss: 0.752772, acc.: 56.25%] [G loss: 1.104297]\n",
      "epoch:25 step:23598 [D loss: 0.658363, acc.: 66.41%] [G loss: 1.385452]\n",
      "epoch:25 step:23599 [D loss: 0.581472, acc.: 67.19%] [G loss: 1.246012]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:25 step:23600 [D loss: 0.724614, acc.: 56.25%] [G loss: 0.886253]\n",
      "##############\n",
      "[4.45007985 2.82351038 6.7702067  5.87934363 4.28825015 6.31450368\n",
      " 5.21705311 5.77064451 5.89766124 5.15981294]\n",
      "##########\n",
      "epoch:25 step:23601 [D loss: 0.591597, acc.: 70.31%] [G loss: 1.218486]\n",
      "epoch:25 step:23602 [D loss: 0.753229, acc.: 43.75%] [G loss: 1.253856]\n",
      "epoch:25 step:23603 [D loss: 0.655446, acc.: 64.06%] [G loss: 1.231899]\n",
      "epoch:25 step:23604 [D loss: 0.472872, acc.: 75.78%] [G loss: 1.117367]\n",
      "epoch:25 step:23605 [D loss: 0.548786, acc.: 69.53%] [G loss: 1.202001]\n",
      "epoch:25 step:23606 [D loss: 0.665708, acc.: 63.28%] [G loss: 1.145968]\n",
      "epoch:25 step:23607 [D loss: 0.704358, acc.: 59.38%] [G loss: 0.988350]\n",
      "epoch:25 step:23608 [D loss: 0.622595, acc.: 64.06%] [G loss: 1.239876]\n",
      "epoch:25 step:23609 [D loss: 0.502563, acc.: 74.22%] [G loss: 1.409430]\n",
      "epoch:25 step:23610 [D loss: 0.504556, acc.: 78.91%] [G loss: 1.170742]\n",
      "epoch:25 step:23611 [D loss: 0.673031, acc.: 58.59%] [G loss: 1.107019]\n",
      "epoch:25 step:23612 [D loss: 0.736456, acc.: 51.56%] [G loss: 0.916483]\n",
      "epoch:25 step:23613 [D loss: 0.472289, acc.: 79.69%] [G loss: 1.116240]\n",
      "epoch:25 step:23614 [D loss: 0.636236, acc.: 60.94%] [G loss: 1.090665]\n",
      "epoch:25 step:23615 [D loss: 0.473985, acc.: 77.34%] [G loss: 1.220957]\n",
      "epoch:25 step:23616 [D loss: 0.493666, acc.: 82.81%] [G loss: 1.261279]\n",
      "epoch:25 step:23617 [D loss: 0.234826, acc.: 96.09%] [G loss: 1.499303]\n",
      "epoch:25 step:23618 [D loss: 0.343084, acc.: 92.97%] [G loss: 1.505057]\n",
      "epoch:25 step:23619 [D loss: 0.350590, acc.: 84.38%] [G loss: 1.522859]\n",
      "epoch:25 step:23620 [D loss: 0.266565, acc.: 95.31%] [G loss: 1.801868]\n",
      "epoch:25 step:23621 [D loss: 0.347969, acc.: 92.19%] [G loss: 0.590845]\n",
      "epoch:25 step:23622 [D loss: 0.321145, acc.: 92.97%] [G loss: 1.252606]\n",
      "epoch:25 step:23623 [D loss: 0.337274, acc.: 91.41%] [G loss: 0.978277]\n",
      "epoch:25 step:23624 [D loss: 1.012677, acc.: 30.47%] [G loss: 1.649919]\n",
      "epoch:25 step:23625 [D loss: 0.255149, acc.: 96.09%] [G loss: 1.557390]\n",
      "epoch:25 step:23626 [D loss: 0.241167, acc.: 94.53%] [G loss: 2.400740]\n",
      "epoch:25 step:23627 [D loss: 0.776105, acc.: 57.03%] [G loss: 2.008883]\n",
      "epoch:25 step:23628 [D loss: 0.532295, acc.: 71.88%] [G loss: 1.636195]\n",
      "epoch:25 step:23629 [D loss: 0.185861, acc.: 97.66%] [G loss: 0.962687]\n",
      "epoch:25 step:23630 [D loss: 0.404066, acc.: 86.72%] [G loss: 1.113267]\n",
      "epoch:25 step:23631 [D loss: 0.348769, acc.: 85.16%] [G loss: 1.573817]\n",
      "epoch:25 step:23632 [D loss: 0.121823, acc.: 99.22%] [G loss: 2.449525]\n",
      "epoch:25 step:23633 [D loss: 0.284585, acc.: 92.97%] [G loss: 1.543493]\n",
      "epoch:25 step:23634 [D loss: 0.216397, acc.: 99.22%] [G loss: 1.999292]\n",
      "epoch:25 step:23635 [D loss: 1.173195, acc.: 51.56%] [G loss: 0.952615]\n",
      "epoch:25 step:23636 [D loss: 1.317282, acc.: 17.97%] [G loss: 0.814279]\n",
      "epoch:25 step:23637 [D loss: 0.711829, acc.: 57.81%] [G loss: 1.189956]\n",
      "epoch:25 step:23638 [D loss: 0.809942, acc.: 46.88%] [G loss: 0.795691]\n",
      "epoch:25 step:23639 [D loss: 0.899712, acc.: 41.41%] [G loss: 1.003056]\n",
      "epoch:25 step:23640 [D loss: 0.879825, acc.: 44.53%] [G loss: 1.205742]\n",
      "epoch:25 step:23641 [D loss: 0.809504, acc.: 50.00%] [G loss: 0.853879]\n",
      "epoch:25 step:23642 [D loss: 0.408686, acc.: 82.81%] [G loss: 1.535641]\n",
      "epoch:25 step:23643 [D loss: 0.543527, acc.: 71.09%] [G loss: 1.380954]\n",
      "epoch:25 step:23644 [D loss: 0.307047, acc.: 94.53%] [G loss: 1.256410]\n",
      "epoch:25 step:23645 [D loss: 0.224264, acc.: 90.62%] [G loss: 1.478036]\n",
      "epoch:25 step:23646 [D loss: 0.160663, acc.: 99.22%] [G loss: 1.291791]\n",
      "epoch:25 step:23647 [D loss: 0.391021, acc.: 87.50%] [G loss: 1.913692]\n",
      "epoch:25 step:23648 [D loss: 0.369932, acc.: 89.84%] [G loss: 1.881979]\n",
      "epoch:25 step:23649 [D loss: 0.659435, acc.: 64.06%] [G loss: 1.519225]\n",
      "epoch:25 step:23650 [D loss: 0.486040, acc.: 75.78%] [G loss: 1.650902]\n",
      "epoch:25 step:23651 [D loss: 0.738511, acc.: 55.47%] [G loss: 1.230171]\n",
      "epoch:25 step:23652 [D loss: 0.564510, acc.: 67.97%] [G loss: 1.904495]\n",
      "epoch:25 step:23653 [D loss: 0.660676, acc.: 58.59%] [G loss: 1.378534]\n",
      "epoch:25 step:23654 [D loss: 0.548085, acc.: 71.09%] [G loss: 1.543582]\n",
      "epoch:25 step:23655 [D loss: 0.252398, acc.: 91.41%] [G loss: 1.557300]\n",
      "epoch:25 step:23656 [D loss: 0.200324, acc.: 92.97%] [G loss: 1.509318]\n",
      "epoch:25 step:23657 [D loss: 0.126645, acc.: 99.22%] [G loss: 2.179083]\n",
      "epoch:25 step:23658 [D loss: 0.559500, acc.: 67.97%] [G loss: 1.946479]\n",
      "epoch:25 step:23659 [D loss: 0.352811, acc.: 85.94%] [G loss: 2.027194]\n",
      "epoch:25 step:23660 [D loss: 0.195616, acc.: 98.44%] [G loss: 1.907472]\n",
      "epoch:25 step:23661 [D loss: 0.572259, acc.: 67.19%] [G loss: 1.704150]\n",
      "epoch:25 step:23662 [D loss: 0.246563, acc.: 96.09%] [G loss: 1.747581]\n",
      "epoch:25 step:23663 [D loss: 0.199227, acc.: 98.44%] [G loss: 1.558668]\n",
      "epoch:25 step:23664 [D loss: 0.590545, acc.: 67.97%] [G loss: 1.116007]\n",
      "epoch:25 step:23665 [D loss: 0.560075, acc.: 71.88%] [G loss: 0.823109]\n",
      "epoch:25 step:23666 [D loss: 0.896826, acc.: 44.53%] [G loss: 1.299352]\n",
      "epoch:25 step:23667 [D loss: 0.593775, acc.: 63.28%] [G loss: 0.918672]\n",
      "epoch:25 step:23668 [D loss: 0.257462, acc.: 95.31%] [G loss: 1.408983]\n",
      "epoch:25 step:23669 [D loss: 0.565978, acc.: 71.88%] [G loss: 1.325822]\n",
      "epoch:25 step:23670 [D loss: 0.668101, acc.: 59.38%] [G loss: 1.193423]\n",
      "epoch:25 step:23671 [D loss: 0.728774, acc.: 55.47%] [G loss: 0.774781]\n",
      "epoch:25 step:23672 [D loss: 0.572378, acc.: 69.53%] [G loss: 1.067743]\n",
      "epoch:25 step:23673 [D loss: 0.529437, acc.: 77.34%] [G loss: 0.650491]\n",
      "epoch:25 step:23674 [D loss: 0.507756, acc.: 73.44%] [G loss: 1.118510]\n",
      "epoch:25 step:23675 [D loss: 0.666322, acc.: 65.62%] [G loss: 1.082445]\n",
      "epoch:25 step:23676 [D loss: 0.448319, acc.: 77.34%] [G loss: 1.525738]\n",
      "epoch:25 step:23677 [D loss: 0.380082, acc.: 89.06%] [G loss: 1.300475]\n",
      "epoch:25 step:23678 [D loss: 0.551453, acc.: 75.00%] [G loss: 1.323140]\n",
      "epoch:25 step:23679 [D loss: 0.271994, acc.: 95.31%] [G loss: 1.503819]\n",
      "epoch:25 step:23680 [D loss: 1.208320, acc.: 53.12%] [G loss: 1.108075]\n",
      "epoch:25 step:23681 [D loss: 0.146139, acc.: 98.44%] [G loss: 1.567812]\n",
      "epoch:25 step:23682 [D loss: 0.198490, acc.: 96.88%] [G loss: 1.771934]\n",
      "epoch:25 step:23683 [D loss: 0.782114, acc.: 53.12%] [G loss: 1.362803]\n",
      "epoch:25 step:23684 [D loss: 0.159413, acc.: 96.88%] [G loss: 1.588687]\n",
      "epoch:25 step:23685 [D loss: 0.139007, acc.: 99.22%] [G loss: 1.969581]\n",
      "epoch:25 step:23686 [D loss: 0.154535, acc.: 99.22%] [G loss: 2.434000]\n",
      "epoch:25 step:23687 [D loss: 1.004632, acc.: 31.25%] [G loss: 1.552469]\n",
      "epoch:25 step:23688 [D loss: 0.987210, acc.: 42.97%] [G loss: 1.882380]\n",
      "epoch:25 step:23689 [D loss: 0.917453, acc.: 46.09%] [G loss: 1.502204]\n",
      "epoch:25 step:23690 [D loss: 0.438137, acc.: 83.59%] [G loss: 1.092103]\n",
      "epoch:25 step:23691 [D loss: 0.648286, acc.: 62.50%] [G loss: 1.374204]\n",
      "epoch:25 step:23692 [D loss: 0.659436, acc.: 61.72%] [G loss: 0.902002]\n",
      "epoch:25 step:23693 [D loss: 0.794934, acc.: 49.22%] [G loss: 1.328232]\n",
      "epoch:25 step:23694 [D loss: 0.483286, acc.: 78.91%] [G loss: 1.011001]\n",
      "epoch:25 step:23695 [D loss: 0.731404, acc.: 61.72%] [G loss: 1.423225]\n",
      "epoch:25 step:23696 [D loss: 0.526074, acc.: 74.22%] [G loss: 1.019031]\n",
      "epoch:25 step:23697 [D loss: 0.530835, acc.: 78.12%] [G loss: 1.269816]\n",
      "epoch:25 step:23698 [D loss: 0.556657, acc.: 71.88%] [G loss: 1.299936]\n",
      "epoch:25 step:23699 [D loss: 0.507851, acc.: 71.88%] [G loss: 1.347211]\n",
      "epoch:25 step:23700 [D loss: 0.402372, acc.: 83.59%] [G loss: 2.094292]\n",
      "epoch:25 step:23701 [D loss: 0.403614, acc.: 87.50%] [G loss: 1.419931]\n",
      "epoch:25 step:23702 [D loss: 0.506925, acc.: 78.91%] [G loss: 1.082715]\n",
      "epoch:25 step:23703 [D loss: 0.322969, acc.: 85.16%] [G loss: 1.257164]\n",
      "epoch:25 step:23704 [D loss: 0.172979, acc.: 97.66%] [G loss: 1.795938]\n",
      "epoch:25 step:23705 [D loss: 0.548694, acc.: 76.56%] [G loss: 0.728218]\n",
      "epoch:25 step:23706 [D loss: 0.686027, acc.: 59.38%] [G loss: 1.512001]\n",
      "epoch:25 step:23707 [D loss: 0.422774, acc.: 82.03%] [G loss: 1.362958]\n",
      "epoch:25 step:23708 [D loss: 0.522748, acc.: 75.00%] [G loss: 0.942545]\n",
      "epoch:25 step:23709 [D loss: 0.334935, acc.: 89.84%] [G loss: 1.174711]\n",
      "epoch:25 step:23710 [D loss: 0.498155, acc.: 78.12%] [G loss: 1.175567]\n",
      "epoch:25 step:23711 [D loss: 0.404729, acc.: 86.72%] [G loss: 1.212257]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:25 step:23712 [D loss: 0.259259, acc.: 92.19%] [G loss: 1.134306]\n",
      "epoch:25 step:23713 [D loss: 0.342841, acc.: 85.94%] [G loss: 1.339519]\n",
      "epoch:25 step:23714 [D loss: 0.222815, acc.: 96.09%] [G loss: 2.052925]\n",
      "epoch:25 step:23715 [D loss: 0.190390, acc.: 98.44%] [G loss: 1.165628]\n",
      "epoch:25 step:23716 [D loss: 0.426548, acc.: 79.69%] [G loss: 1.680528]\n",
      "epoch:25 step:23717 [D loss: 0.372399, acc.: 87.50%] [G loss: 1.570723]\n",
      "epoch:25 step:23718 [D loss: 0.182553, acc.: 96.09%] [G loss: 1.731547]\n",
      "epoch:25 step:23719 [D loss: 0.854978, acc.: 49.22%] [G loss: 1.663257]\n",
      "epoch:25 step:23720 [D loss: 0.866660, acc.: 47.66%] [G loss: 1.721998]\n",
      "epoch:25 step:23721 [D loss: 0.683668, acc.: 60.94%] [G loss: 1.095677]\n",
      "epoch:25 step:23722 [D loss: 0.333189, acc.: 92.97%] [G loss: 1.402921]\n",
      "epoch:25 step:23723 [D loss: 0.341881, acc.: 90.62%] [G loss: 1.332962]\n",
      "epoch:25 step:23724 [D loss: 0.210601, acc.: 99.22%] [G loss: 1.764979]\n",
      "epoch:25 step:23725 [D loss: 0.445214, acc.: 85.16%] [G loss: 1.643985]\n",
      "epoch:25 step:23726 [D loss: 0.614727, acc.: 67.97%] [G loss: 1.428900]\n",
      "epoch:25 step:23727 [D loss: 0.632056, acc.: 64.06%] [G loss: 1.012314]\n",
      "epoch:25 step:23728 [D loss: 0.533308, acc.: 75.78%] [G loss: 1.154477]\n",
      "epoch:25 step:23729 [D loss: 0.637825, acc.: 64.84%] [G loss: 1.451741]\n",
      "epoch:25 step:23730 [D loss: 0.410186, acc.: 83.59%] [G loss: 1.573887]\n",
      "epoch:25 step:23731 [D loss: 0.563234, acc.: 72.66%] [G loss: 1.429059]\n",
      "epoch:25 step:23732 [D loss: 0.684199, acc.: 62.50%] [G loss: 1.503924]\n",
      "epoch:25 step:23733 [D loss: 0.424098, acc.: 84.38%] [G loss: 1.625376]\n",
      "epoch:25 step:23734 [D loss: 0.210901, acc.: 92.97%] [G loss: 1.253826]\n",
      "epoch:25 step:23735 [D loss: 0.635570, acc.: 65.62%] [G loss: 0.904174]\n",
      "epoch:25 step:23736 [D loss: 0.781502, acc.: 53.12%] [G loss: 1.302175]\n",
      "epoch:25 step:23737 [D loss: 0.157522, acc.: 92.97%] [G loss: 1.704026]\n",
      "epoch:25 step:23738 [D loss: 0.189649, acc.: 93.75%] [G loss: 1.513497]\n",
      "epoch:25 step:23739 [D loss: 0.128627, acc.: 97.66%] [G loss: 1.695495]\n",
      "epoch:25 step:23740 [D loss: 0.178763, acc.: 97.66%] [G loss: 2.078952]\n",
      "epoch:25 step:23741 [D loss: 0.578198, acc.: 69.53%] [G loss: 1.397326]\n",
      "epoch:25 step:23742 [D loss: 0.704514, acc.: 60.94%] [G loss: 1.577176]\n",
      "epoch:25 step:23743 [D loss: 0.685577, acc.: 56.25%] [G loss: 1.492189]\n",
      "epoch:25 step:23744 [D loss: 0.501944, acc.: 79.69%] [G loss: 1.271722]\n",
      "epoch:25 step:23745 [D loss: 0.441331, acc.: 81.25%] [G loss: 1.327618]\n",
      "epoch:25 step:23746 [D loss: 0.501364, acc.: 77.34%] [G loss: 0.870291]\n",
      "epoch:25 step:23747 [D loss: 0.385117, acc.: 86.72%] [G loss: 0.597822]\n",
      "epoch:25 step:23748 [D loss: 1.382701, acc.: 25.78%] [G loss: 1.219706]\n",
      "epoch:25 step:23749 [D loss: 0.814415, acc.: 43.75%] [G loss: 1.097200]\n",
      "epoch:25 step:23750 [D loss: 0.580536, acc.: 68.75%] [G loss: 1.626856]\n",
      "epoch:25 step:23751 [D loss: 0.602733, acc.: 71.09%] [G loss: 1.278826]\n",
      "epoch:25 step:23752 [D loss: 0.243153, acc.: 93.75%] [G loss: 1.351663]\n",
      "epoch:25 step:23753 [D loss: 0.238549, acc.: 96.09%] [G loss: 1.287242]\n",
      "epoch:25 step:23754 [D loss: 0.632743, acc.: 64.06%] [G loss: 1.064429]\n",
      "epoch:25 step:23755 [D loss: 0.894811, acc.: 41.41%] [G loss: 1.198453]\n",
      "epoch:25 step:23756 [D loss: 0.573830, acc.: 66.41%] [G loss: 1.155819]\n",
      "epoch:25 step:23757 [D loss: 0.531999, acc.: 73.44%] [G loss: 1.439426]\n",
      "epoch:25 step:23758 [D loss: 0.461786, acc.: 76.56%] [G loss: 1.654728]\n",
      "epoch:25 step:23759 [D loss: 0.212683, acc.: 91.41%] [G loss: 1.113795]\n",
      "epoch:25 step:23760 [D loss: 0.373060, acc.: 91.41%] [G loss: 1.832463]\n",
      "epoch:25 step:23761 [D loss: 0.201122, acc.: 96.09%] [G loss: 2.030957]\n",
      "epoch:25 step:23762 [D loss: 0.499835, acc.: 78.12%] [G loss: 1.588906]\n",
      "epoch:25 step:23763 [D loss: 0.541104, acc.: 73.44%] [G loss: 0.597613]\n",
      "epoch:25 step:23764 [D loss: 0.408062, acc.: 82.03%] [G loss: 2.119757]\n",
      "epoch:25 step:23765 [D loss: 0.744109, acc.: 56.25%] [G loss: 1.392922]\n",
      "epoch:25 step:23766 [D loss: 0.597414, acc.: 66.41%] [G loss: 1.127683]\n",
      "epoch:25 step:23767 [D loss: 0.280685, acc.: 85.94%] [G loss: 1.412628]\n",
      "epoch:25 step:23768 [D loss: 0.257953, acc.: 85.94%] [G loss: 1.714091]\n",
      "epoch:25 step:23769 [D loss: 0.131476, acc.: 99.22%] [G loss: 1.091393]\n",
      "epoch:25 step:23770 [D loss: 0.384136, acc.: 78.12%] [G loss: 0.401252]\n",
      "epoch:25 step:23771 [D loss: 0.306920, acc.: 89.06%] [G loss: 1.240999]\n",
      "epoch:25 step:23772 [D loss: 0.078993, acc.: 100.00%] [G loss: 1.073799]\n",
      "epoch:25 step:23773 [D loss: 0.833415, acc.: 53.91%] [G loss: 2.005713]\n",
      "epoch:25 step:23774 [D loss: 0.706236, acc.: 63.28%] [G loss: 1.091677]\n",
      "epoch:25 step:23775 [D loss: 0.335657, acc.: 89.84%] [G loss: 0.573086]\n",
      "epoch:25 step:23776 [D loss: 0.590946, acc.: 67.19%] [G loss: 0.844692]\n",
      "epoch:25 step:23777 [D loss: 0.705019, acc.: 57.03%] [G loss: 1.414506]\n",
      "epoch:25 step:23778 [D loss: 0.372009, acc.: 89.84%] [G loss: 0.347508]\n",
      "epoch:25 step:23779 [D loss: 0.749589, acc.: 57.81%] [G loss: 1.354838]\n",
      "epoch:25 step:23780 [D loss: 0.703174, acc.: 53.12%] [G loss: 1.342110]\n",
      "epoch:25 step:23781 [D loss: 0.590593, acc.: 66.41%] [G loss: 1.464467]\n",
      "epoch:25 step:23782 [D loss: 0.372719, acc.: 85.16%] [G loss: 1.205692]\n",
      "epoch:25 step:23783 [D loss: 0.220901, acc.: 96.88%] [G loss: 1.738573]\n",
      "epoch:25 step:23784 [D loss: 0.185750, acc.: 98.44%] [G loss: 1.373808]\n",
      "epoch:25 step:23785 [D loss: 0.264832, acc.: 92.19%] [G loss: 0.830638]\n",
      "epoch:25 step:23786 [D loss: 0.314636, acc.: 87.50%] [G loss: 1.232354]\n",
      "epoch:25 step:23787 [D loss: 0.552428, acc.: 69.53%] [G loss: 1.573742]\n",
      "epoch:25 step:23788 [D loss: 0.533864, acc.: 78.12%] [G loss: 0.833670]\n",
      "epoch:25 step:23789 [D loss: 0.497233, acc.: 75.00%] [G loss: 1.013950]\n",
      "epoch:25 step:23790 [D loss: 1.222194, acc.: 48.44%] [G loss: 1.997178]\n",
      "epoch:25 step:23791 [D loss: 0.687813, acc.: 64.84%] [G loss: 2.205660]\n",
      "epoch:25 step:23792 [D loss: 0.937905, acc.: 45.31%] [G loss: 1.470870]\n",
      "epoch:25 step:23793 [D loss: 0.594128, acc.: 68.75%] [G loss: 2.056551]\n",
      "epoch:25 step:23794 [D loss: 0.149577, acc.: 94.53%] [G loss: 2.131447]\n",
      "epoch:25 step:23795 [D loss: 0.167591, acc.: 95.31%] [G loss: 2.357648]\n",
      "epoch:25 step:23796 [D loss: 0.319233, acc.: 86.72%] [G loss: 2.164705]\n",
      "epoch:25 step:23797 [D loss: 0.123615, acc.: 99.22%] [G loss: 3.127369]\n",
      "epoch:25 step:23798 [D loss: 0.893570, acc.: 50.78%] [G loss: 2.364328]\n",
      "epoch:25 step:23799 [D loss: 0.285518, acc.: 93.75%] [G loss: 1.444369]\n",
      "epoch:25 step:23800 [D loss: 0.452399, acc.: 79.69%] [G loss: 1.791668]\n",
      "##############\n",
      "[3.99888172 2.70474734 6.50677648 5.94786109 4.77442996 6.09737179\n",
      " 5.14911782 5.4578765  6.0896875  4.99945873]\n",
      "##########\n",
      "epoch:25 step:23801 [D loss: 0.720932, acc.: 57.81%] [G loss: 1.112676]\n",
      "epoch:25 step:23802 [D loss: 1.088296, acc.: 44.53%] [G loss: 0.924150]\n",
      "epoch:25 step:23803 [D loss: 0.986626, acc.: 32.81%] [G loss: 1.003685]\n",
      "epoch:25 step:23804 [D loss: 0.414101, acc.: 76.56%] [G loss: 0.933046]\n",
      "epoch:25 step:23805 [D loss: 0.265143, acc.: 85.16%] [G loss: 1.431262]\n",
      "epoch:25 step:23806 [D loss: 0.251202, acc.: 90.62%] [G loss: 1.435409]\n",
      "epoch:25 step:23807 [D loss: 0.470020, acc.: 78.12%] [G loss: 1.564697]\n",
      "epoch:25 step:23808 [D loss: 0.673994, acc.: 54.69%] [G loss: 1.158059]\n",
      "epoch:25 step:23809 [D loss: 0.708723, acc.: 59.38%] [G loss: 1.821740]\n",
      "epoch:25 step:23810 [D loss: 0.429834, acc.: 81.25%] [G loss: 1.499917]\n",
      "epoch:25 step:23811 [D loss: 0.461186, acc.: 75.00%] [G loss: 1.256447]\n",
      "epoch:25 step:23812 [D loss: 0.259849, acc.: 91.41%] [G loss: 2.007003]\n",
      "epoch:25 step:23813 [D loss: 0.348527, acc.: 90.62%] [G loss: 1.873664]\n",
      "epoch:25 step:23814 [D loss: 0.767509, acc.: 52.34%] [G loss: 1.850325]\n",
      "epoch:25 step:23815 [D loss: 0.983705, acc.: 35.16%] [G loss: 0.840531]\n",
      "epoch:25 step:23816 [D loss: 0.627448, acc.: 60.94%] [G loss: 0.883910]\n",
      "epoch:25 step:23817 [D loss: 0.620429, acc.: 68.75%] [G loss: 1.079582]\n",
      "epoch:25 step:23818 [D loss: 1.033775, acc.: 34.38%] [G loss: 0.989530]\n",
      "epoch:25 step:23819 [D loss: 1.059896, acc.: 28.91%] [G loss: 1.247053]\n",
      "epoch:25 step:23820 [D loss: 0.720343, acc.: 59.38%] [G loss: 1.249424]\n",
      "epoch:25 step:23821 [D loss: 0.809586, acc.: 58.59%] [G loss: 1.596783]\n",
      "epoch:25 step:23822 [D loss: 0.449772, acc.: 81.25%] [G loss: 1.710521]\n",
      "epoch:25 step:23823 [D loss: 0.344180, acc.: 92.19%] [G loss: 1.581139]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:25 step:23824 [D loss: 0.353949, acc.: 89.84%] [G loss: 1.773992]\n",
      "epoch:25 step:23825 [D loss: 0.623099, acc.: 65.62%] [G loss: 1.675188]\n",
      "epoch:25 step:23826 [D loss: 0.492680, acc.: 78.91%] [G loss: 1.675403]\n",
      "epoch:25 step:23827 [D loss: 0.312129, acc.: 93.75%] [G loss: 1.496910]\n",
      "epoch:25 step:23828 [D loss: 0.456126, acc.: 82.03%] [G loss: 1.091875]\n",
      "epoch:25 step:23829 [D loss: 0.350783, acc.: 90.62%] [G loss: 1.424224]\n",
      "epoch:25 step:23830 [D loss: 0.184098, acc.: 97.66%] [G loss: 1.739275]\n",
      "epoch:25 step:23831 [D loss: 0.256075, acc.: 89.84%] [G loss: 1.662445]\n",
      "epoch:25 step:23832 [D loss: 0.257584, acc.: 91.41%] [G loss: 1.382346]\n",
      "epoch:25 step:23833 [D loss: 0.224626, acc.: 95.31%] [G loss: 2.206707]\n",
      "epoch:25 step:23834 [D loss: 0.263543, acc.: 97.66%] [G loss: 2.198863]\n",
      "epoch:25 step:23835 [D loss: 0.362978, acc.: 89.06%] [G loss: 0.871382]\n",
      "epoch:25 step:23836 [D loss: 0.852360, acc.: 53.12%] [G loss: 1.582189]\n",
      "epoch:25 step:23837 [D loss: 0.449382, acc.: 79.69%] [G loss: 1.623410]\n",
      "epoch:25 step:23838 [D loss: 0.257866, acc.: 93.75%] [G loss: 1.720025]\n",
      "epoch:25 step:23839 [D loss: 0.277993, acc.: 92.19%] [G loss: 1.276822]\n",
      "epoch:25 step:23840 [D loss: 0.282494, acc.: 92.97%] [G loss: 1.090547]\n",
      "epoch:25 step:23841 [D loss: 0.216081, acc.: 96.09%] [G loss: 1.679747]\n",
      "epoch:25 step:23842 [D loss: 0.337206, acc.: 82.81%] [G loss: 1.257170]\n",
      "epoch:25 step:23843 [D loss: 0.421164, acc.: 73.44%] [G loss: 1.586591]\n",
      "epoch:25 step:23844 [D loss: 0.230675, acc.: 92.97%] [G loss: 2.129102]\n",
      "epoch:25 step:23845 [D loss: 0.325488, acc.: 89.06%] [G loss: 1.653713]\n",
      "epoch:25 step:23846 [D loss: 1.041857, acc.: 45.31%] [G loss: 1.423643]\n",
      "epoch:25 step:23847 [D loss: 1.345003, acc.: 38.28%] [G loss: 1.168416]\n",
      "epoch:25 step:23848 [D loss: 0.403825, acc.: 85.94%] [G loss: 1.349085]\n",
      "epoch:25 step:23849 [D loss: 0.593134, acc.: 64.06%] [G loss: 1.027823]\n",
      "epoch:25 step:23850 [D loss: 0.394939, acc.: 78.12%] [G loss: 1.105452]\n",
      "epoch:25 step:23851 [D loss: 1.003319, acc.: 32.81%] [G loss: 0.882888]\n",
      "epoch:25 step:23852 [D loss: 0.129934, acc.: 98.44%] [G loss: 1.882419]\n",
      "epoch:25 step:23853 [D loss: 0.114125, acc.: 99.22%] [G loss: 1.488965]\n",
      "epoch:25 step:23854 [D loss: 0.551572, acc.: 75.00%] [G loss: 1.589462]\n",
      "epoch:25 step:23855 [D loss: 0.276341, acc.: 87.50%] [G loss: 0.865018]\n",
      "epoch:25 step:23856 [D loss: 1.226914, acc.: 37.50%] [G loss: 1.412434]\n",
      "epoch:25 step:23857 [D loss: 1.164142, acc.: 37.50%] [G loss: 0.651704]\n",
      "epoch:25 step:23858 [D loss: 1.011647, acc.: 46.88%] [G loss: 1.466077]\n",
      "epoch:25 step:23859 [D loss: 0.956689, acc.: 35.16%] [G loss: 0.866027]\n",
      "epoch:25 step:23860 [D loss: 0.982178, acc.: 35.16%] [G loss: 2.068469]\n",
      "epoch:25 step:23861 [D loss: 0.745550, acc.: 54.69%] [G loss: 1.948950]\n",
      "epoch:25 step:23862 [D loss: 0.988625, acc.: 39.06%] [G loss: 1.607503]\n",
      "epoch:25 step:23863 [D loss: 0.765361, acc.: 54.69%] [G loss: 1.678487]\n",
      "epoch:25 step:23864 [D loss: 0.831089, acc.: 47.66%] [G loss: 1.158816]\n",
      "epoch:25 step:23865 [D loss: 0.699351, acc.: 53.12%] [G loss: 1.465374]\n",
      "epoch:25 step:23866 [D loss: 0.767187, acc.: 53.12%] [G loss: 1.375410]\n",
      "epoch:25 step:23867 [D loss: 0.814279, acc.: 49.22%] [G loss: 1.133345]\n",
      "epoch:25 step:23868 [D loss: 0.586236, acc.: 72.66%] [G loss: 1.624395]\n",
      "epoch:25 step:23869 [D loss: 0.584819, acc.: 65.62%] [G loss: 2.120391]\n",
      "epoch:25 step:23870 [D loss: 0.675694, acc.: 62.50%] [G loss: 1.338739]\n",
      "epoch:25 step:23871 [D loss: 0.629692, acc.: 54.69%] [G loss: 1.984217]\n",
      "epoch:25 step:23872 [D loss: 0.707127, acc.: 55.47%] [G loss: 1.164362]\n",
      "epoch:25 step:23873 [D loss: 0.282059, acc.: 92.19%] [G loss: 1.445267]\n",
      "epoch:25 step:23874 [D loss: 0.261901, acc.: 93.75%] [G loss: 1.868105]\n",
      "epoch:25 step:23875 [D loss: 0.245308, acc.: 96.88%] [G loss: 1.738446]\n",
      "epoch:25 step:23876 [D loss: 0.172691, acc.: 97.66%] [G loss: 1.984956]\n",
      "epoch:25 step:23877 [D loss: 0.156123, acc.: 99.22%] [G loss: 1.889178]\n",
      "epoch:25 step:23878 [D loss: 0.164356, acc.: 99.22%] [G loss: 1.936771]\n",
      "epoch:25 step:23879 [D loss: 0.224301, acc.: 96.88%] [G loss: 2.188123]\n",
      "epoch:25 step:23880 [D loss: 0.182310, acc.: 98.44%] [G loss: 1.937365]\n",
      "epoch:25 step:23881 [D loss: 0.152441, acc.: 96.09%] [G loss: 1.906144]\n",
      "epoch:25 step:23882 [D loss: 0.203504, acc.: 96.88%] [G loss: 2.041689]\n",
      "epoch:25 step:23883 [D loss: 0.606000, acc.: 65.62%] [G loss: 2.022703]\n",
      "epoch:25 step:23884 [D loss: 0.443465, acc.: 75.78%] [G loss: 1.632275]\n",
      "epoch:25 step:23885 [D loss: 0.545826, acc.: 73.44%] [G loss: 2.121907]\n",
      "epoch:25 step:23886 [D loss: 0.793571, acc.: 46.09%] [G loss: 1.369116]\n",
      "epoch:25 step:23887 [D loss: 0.969464, acc.: 46.09%] [G loss: 1.095810]\n",
      "epoch:25 step:23888 [D loss: 0.639030, acc.: 60.94%] [G loss: 1.077713]\n",
      "epoch:25 step:23889 [D loss: 0.346382, acc.: 88.28%] [G loss: 1.372699]\n",
      "epoch:25 step:23890 [D loss: 0.287094, acc.: 89.06%] [G loss: 1.401031]\n",
      "epoch:25 step:23891 [D loss: 0.195907, acc.: 96.09%] [G loss: 1.327135]\n",
      "epoch:25 step:23892 [D loss: 0.255105, acc.: 92.97%] [G loss: 1.855468]\n",
      "epoch:25 step:23893 [D loss: 0.190813, acc.: 95.31%] [G loss: 1.524928]\n",
      "epoch:25 step:23894 [D loss: 0.214486, acc.: 92.97%] [G loss: 1.789990]\n",
      "epoch:25 step:23895 [D loss: 0.127244, acc.: 96.88%] [G loss: 2.129861]\n",
      "epoch:25 step:23896 [D loss: 0.193374, acc.: 96.88%] [G loss: 1.971096]\n",
      "epoch:25 step:23897 [D loss: 0.150427, acc.: 100.00%] [G loss: 2.117931]\n",
      "epoch:25 step:23898 [D loss: 1.166494, acc.: 44.53%] [G loss: 1.632328]\n",
      "epoch:25 step:23899 [D loss: 0.817269, acc.: 60.16%] [G loss: 1.373099]\n",
      "epoch:25 step:23900 [D loss: 0.700316, acc.: 60.16%] [G loss: 0.968557]\n",
      "epoch:25 step:23901 [D loss: 0.496526, acc.: 79.69%] [G loss: 1.018765]\n",
      "epoch:25 step:23902 [D loss: 0.552334, acc.: 68.75%] [G loss: 1.205419]\n",
      "epoch:25 step:23903 [D loss: 0.629776, acc.: 64.06%] [G loss: 0.745448]\n",
      "epoch:25 step:23904 [D loss: 0.212857, acc.: 95.31%] [G loss: 2.003253]\n",
      "epoch:25 step:23905 [D loss: 0.318963, acc.: 89.84%] [G loss: 1.807048]\n",
      "epoch:25 step:23906 [D loss: 0.255819, acc.: 89.06%] [G loss: 1.674387]\n",
      "epoch:25 step:23907 [D loss: 0.991114, acc.: 50.00%] [G loss: 1.707212]\n",
      "epoch:25 step:23908 [D loss: 0.712352, acc.: 60.16%] [G loss: 1.255447]\n",
      "epoch:25 step:23909 [D loss: 0.452868, acc.: 84.38%] [G loss: 1.538257]\n",
      "epoch:25 step:23910 [D loss: 0.924535, acc.: 35.16%] [G loss: 0.998418]\n",
      "epoch:25 step:23911 [D loss: 0.636097, acc.: 64.84%] [G loss: 1.238040]\n",
      "epoch:25 step:23912 [D loss: 0.613510, acc.: 64.06%] [G loss: 1.258578]\n",
      "epoch:25 step:23913 [D loss: 0.579103, acc.: 67.19%] [G loss: 1.450634]\n",
      "epoch:25 step:23914 [D loss: 0.314618, acc.: 92.97%] [G loss: 1.416294]\n",
      "epoch:25 step:23915 [D loss: 0.314028, acc.: 87.50%] [G loss: 1.169411]\n",
      "epoch:25 step:23916 [D loss: 0.402418, acc.: 85.16%] [G loss: 1.894380]\n",
      "epoch:25 step:23917 [D loss: 0.587362, acc.: 68.75%] [G loss: 1.010184]\n",
      "epoch:25 step:23918 [D loss: 0.777815, acc.: 53.91%] [G loss: 1.171832]\n",
      "epoch:25 step:23919 [D loss: 0.504174, acc.: 76.56%] [G loss: 0.872701]\n",
      "epoch:25 step:23920 [D loss: 0.493314, acc.: 75.78%] [G loss: 1.619498]\n",
      "epoch:25 step:23921 [D loss: 0.650469, acc.: 60.16%] [G loss: 0.545859]\n",
      "epoch:25 step:23922 [D loss: 0.490010, acc.: 82.81%] [G loss: 1.160672]\n",
      "epoch:25 step:23923 [D loss: 0.361795, acc.: 82.03%] [G loss: 1.433189]\n",
      "epoch:25 step:23924 [D loss: 0.313721, acc.: 85.94%] [G loss: 1.817229]\n",
      "epoch:25 step:23925 [D loss: 0.647328, acc.: 64.06%] [G loss: 1.777861]\n",
      "epoch:25 step:23926 [D loss: 0.733711, acc.: 57.03%] [G loss: 1.266198]\n",
      "epoch:25 step:23927 [D loss: 0.565037, acc.: 73.44%] [G loss: 1.190632]\n",
      "epoch:25 step:23928 [D loss: 0.291256, acc.: 85.94%] [G loss: 1.306952]\n",
      "epoch:25 step:23929 [D loss: 0.236282, acc.: 89.06%] [G loss: 1.490726]\n",
      "epoch:25 step:23930 [D loss: 0.308073, acc.: 89.84%] [G loss: 2.093825]\n",
      "epoch:25 step:23931 [D loss: 0.621336, acc.: 63.28%] [G loss: 1.403165]\n",
      "epoch:25 step:23932 [D loss: 0.246138, acc.: 98.44%] [G loss: 1.841933]\n",
      "epoch:25 step:23933 [D loss: 0.267596, acc.: 94.53%] [G loss: 1.625591]\n",
      "epoch:25 step:23934 [D loss: 0.754609, acc.: 56.25%] [G loss: 1.337387]\n",
      "epoch:25 step:23935 [D loss: 0.420618, acc.: 89.06%] [G loss: 0.983220]\n",
      "epoch:25 step:23936 [D loss: 0.209694, acc.: 96.88%] [G loss: 1.368932]\n",
      "epoch:25 step:23937 [D loss: 0.301163, acc.: 90.62%] [G loss: 1.079970]\n",
      "epoch:25 step:23938 [D loss: 0.429067, acc.: 80.47%] [G loss: 1.609418]\n",
      "epoch:25 step:23939 [D loss: 0.486218, acc.: 79.69%] [G loss: 1.555395]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:25 step:23940 [D loss: 0.333325, acc.: 88.28%] [G loss: 1.420037]\n",
      "epoch:25 step:23941 [D loss: 0.749557, acc.: 57.81%] [G loss: 1.321446]\n",
      "epoch:25 step:23942 [D loss: 0.262053, acc.: 96.09%] [G loss: 1.136438]\n",
      "epoch:25 step:23943 [D loss: 0.430502, acc.: 79.69%] [G loss: 1.093312]\n",
      "epoch:25 step:23944 [D loss: 0.470598, acc.: 75.00%] [G loss: 1.349473]\n",
      "epoch:25 step:23945 [D loss: 0.477793, acc.: 76.56%] [G loss: 1.043447]\n",
      "epoch:25 step:23946 [D loss: 0.426322, acc.: 86.72%] [G loss: 1.486697]\n",
      "epoch:25 step:23947 [D loss: 0.463406, acc.: 77.34%] [G loss: 1.719558]\n",
      "epoch:25 step:23948 [D loss: 0.437375, acc.: 81.25%] [G loss: 1.363196]\n",
      "epoch:25 step:23949 [D loss: 0.186905, acc.: 99.22%] [G loss: 1.074115]\n",
      "epoch:25 step:23950 [D loss: 0.835631, acc.: 53.12%] [G loss: 1.094522]\n",
      "epoch:25 step:23951 [D loss: 0.622919, acc.: 63.28%] [G loss: 1.389226]\n",
      "epoch:25 step:23952 [D loss: 0.378845, acc.: 79.69%] [G loss: 1.562445]\n",
      "epoch:25 step:23953 [D loss: 0.666795, acc.: 63.28%] [G loss: 1.134113]\n",
      "epoch:25 step:23954 [D loss: 0.579618, acc.: 64.06%] [G loss: 1.391716]\n",
      "epoch:25 step:23955 [D loss: 0.376632, acc.: 89.06%] [G loss: 1.153120]\n",
      "epoch:25 step:23956 [D loss: 0.722335, acc.: 48.44%] [G loss: 1.066421]\n",
      "epoch:25 step:23957 [D loss: 0.739539, acc.: 59.38%] [G loss: 0.813990]\n",
      "epoch:25 step:23958 [D loss: 0.389011, acc.: 86.72%] [G loss: 1.398393]\n",
      "epoch:25 step:23959 [D loss: 0.354930, acc.: 89.84%] [G loss: 1.345861]\n",
      "epoch:25 step:23960 [D loss: 0.306385, acc.: 89.84%] [G loss: 1.459051]\n",
      "epoch:25 step:23961 [D loss: 0.194011, acc.: 94.53%] [G loss: 1.713074]\n",
      "epoch:25 step:23962 [D loss: 0.483426, acc.: 71.88%] [G loss: 1.864819]\n",
      "epoch:25 step:23963 [D loss: 0.410783, acc.: 85.16%] [G loss: 2.032598]\n",
      "epoch:25 step:23964 [D loss: 0.405185, acc.: 84.38%] [G loss: 1.866113]\n",
      "epoch:25 step:23965 [D loss: 0.359582, acc.: 87.50%] [G loss: 1.858184]\n",
      "epoch:25 step:23966 [D loss: 0.275983, acc.: 92.97%] [G loss: 1.781668]\n",
      "epoch:25 step:23967 [D loss: 0.702838, acc.: 61.72%] [G loss: 0.652224]\n",
      "epoch:25 step:23968 [D loss: 0.485506, acc.: 73.44%] [G loss: 1.276766]\n",
      "epoch:25 step:23969 [D loss: 0.541203, acc.: 75.78%] [G loss: 1.282480]\n",
      "epoch:25 step:23970 [D loss: 0.395578, acc.: 82.81%] [G loss: 1.380022]\n",
      "epoch:25 step:23971 [D loss: 0.576835, acc.: 69.53%] [G loss: 1.212317]\n",
      "epoch:25 step:23972 [D loss: 0.396477, acc.: 84.38%] [G loss: 1.376486]\n",
      "epoch:25 step:23973 [D loss: 0.420806, acc.: 78.12%] [G loss: 1.521773]\n",
      "epoch:25 step:23974 [D loss: 0.457574, acc.: 78.91%] [G loss: 1.933830]\n",
      "epoch:25 step:23975 [D loss: 0.320039, acc.: 92.19%] [G loss: 1.611828]\n",
      "epoch:25 step:23976 [D loss: 0.484314, acc.: 79.69%] [G loss: 1.406953]\n",
      "epoch:25 step:23977 [D loss: 0.467447, acc.: 75.00%] [G loss: 2.004865]\n",
      "epoch:25 step:23978 [D loss: 1.006685, acc.: 35.16%] [G loss: 1.651508]\n",
      "epoch:25 step:23979 [D loss: 0.369226, acc.: 77.34%] [G loss: 1.717577]\n",
      "epoch:25 step:23980 [D loss: 0.593601, acc.: 68.75%] [G loss: 0.948565]\n",
      "epoch:25 step:23981 [D loss: 0.496390, acc.: 78.12%] [G loss: 1.701942]\n",
      "epoch:25 step:23982 [D loss: 0.465035, acc.: 78.91%] [G loss: 1.662160]\n",
      "epoch:25 step:23983 [D loss: 0.641769, acc.: 65.62%] [G loss: 1.864767]\n",
      "epoch:25 step:23984 [D loss: 0.376564, acc.: 75.78%] [G loss: 1.777299]\n",
      "epoch:25 step:23985 [D loss: 0.489941, acc.: 75.78%] [G loss: 2.168420]\n",
      "epoch:25 step:23986 [D loss: 0.100355, acc.: 100.00%] [G loss: 2.590332]\n",
      "epoch:25 step:23987 [D loss: 0.574181, acc.: 67.97%] [G loss: 2.031284]\n",
      "epoch:25 step:23988 [D loss: 0.731440, acc.: 60.16%] [G loss: 1.807029]\n",
      "epoch:25 step:23989 [D loss: 0.602119, acc.: 63.28%] [G loss: 1.755893]\n",
      "epoch:25 step:23990 [D loss: 0.219153, acc.: 96.88%] [G loss: 1.770444]\n",
      "epoch:25 step:23991 [D loss: 0.189616, acc.: 92.97%] [G loss: 1.891228]\n",
      "epoch:25 step:23992 [D loss: 0.134268, acc.: 95.31%] [G loss: 1.883363]\n",
      "epoch:25 step:23993 [D loss: 0.180722, acc.: 96.88%] [G loss: 1.471858]\n",
      "epoch:25 step:23994 [D loss: 0.605464, acc.: 66.41%] [G loss: 2.154236]\n",
      "epoch:25 step:23995 [D loss: 0.435096, acc.: 86.72%] [G loss: 1.746370]\n",
      "epoch:25 step:23996 [D loss: 0.450903, acc.: 79.69%] [G loss: 1.931814]\n",
      "epoch:25 step:23997 [D loss: 0.440460, acc.: 79.69%] [G loss: 1.365963]\n",
      "epoch:25 step:23998 [D loss: 0.277706, acc.: 92.97%] [G loss: 1.926735]\n",
      "epoch:25 step:23999 [D loss: 0.400115, acc.: 88.28%] [G loss: 2.036546]\n",
      "epoch:25 step:24000 [D loss: 0.212301, acc.: 96.88%] [G loss: 1.518137]\n",
      "##############\n",
      "[3.89000492 2.64199459 6.78925975 5.72060263 4.77412709 6.45065922\n",
      " 5.55935543 5.87552254 5.86666123 5.06529617]\n",
      "##########\n",
      "epoch:25 step:24001 [D loss: 0.368146, acc.: 83.59%] [G loss: 0.864310]\n",
      "epoch:25 step:24002 [D loss: 0.117648, acc.: 96.88%] [G loss: 3.236095]\n",
      "epoch:25 step:24003 [D loss: 0.142915, acc.: 96.09%] [G loss: 1.669330]\n",
      "epoch:25 step:24004 [D loss: 0.072678, acc.: 100.00%] [G loss: 3.108315]\n",
      "epoch:25 step:24005 [D loss: 1.011762, acc.: 54.69%] [G loss: 2.098036]\n",
      "epoch:25 step:24006 [D loss: 0.639091, acc.: 63.28%] [G loss: 1.805505]\n",
      "epoch:25 step:24007 [D loss: 0.958892, acc.: 38.28%] [G loss: 0.772403]\n",
      "epoch:25 step:24008 [D loss: 0.849256, acc.: 53.12%] [G loss: 1.170359]\n",
      "epoch:25 step:24009 [D loss: 0.868783, acc.: 37.50%] [G loss: 1.265410]\n",
      "epoch:25 step:24010 [D loss: 0.742298, acc.: 53.91%] [G loss: 0.727953]\n",
      "epoch:25 step:24011 [D loss: 0.870119, acc.: 47.66%] [G loss: 0.898180]\n",
      "epoch:25 step:24012 [D loss: 0.256489, acc.: 89.06%] [G loss: 0.761044]\n",
      "epoch:25 step:24013 [D loss: 0.209185, acc.: 93.75%] [G loss: 1.004125]\n",
      "epoch:25 step:24014 [D loss: 0.190716, acc.: 93.75%] [G loss: 2.267329]\n",
      "epoch:25 step:24015 [D loss: 0.443772, acc.: 77.34%] [G loss: 2.078075]\n",
      "epoch:25 step:24016 [D loss: 0.814822, acc.: 56.25%] [G loss: 1.377605]\n",
      "epoch:25 step:24017 [D loss: 0.717761, acc.: 64.84%] [G loss: 1.459504]\n",
      "epoch:25 step:24018 [D loss: 0.732607, acc.: 53.12%] [G loss: 0.864750]\n",
      "epoch:25 step:24019 [D loss: 0.391243, acc.: 86.72%] [G loss: 0.312898]\n",
      "epoch:25 step:24020 [D loss: 0.239468, acc.: 90.62%] [G loss: 1.201638]\n",
      "epoch:25 step:24021 [D loss: 0.936507, acc.: 42.19%] [G loss: 1.192452]\n",
      "epoch:25 step:24022 [D loss: 0.697641, acc.: 56.25%] [G loss: 1.140653]\n",
      "epoch:25 step:24023 [D loss: 0.807354, acc.: 48.44%] [G loss: 1.281880]\n",
      "epoch:25 step:24024 [D loss: 0.823935, acc.: 46.88%] [G loss: 1.430229]\n",
      "epoch:25 step:24025 [D loss: 0.359512, acc.: 78.91%] [G loss: 1.364711]\n",
      "epoch:25 step:24026 [D loss: 0.299443, acc.: 89.84%] [G loss: 1.663413]\n",
      "epoch:25 step:24027 [D loss: 0.174431, acc.: 96.09%] [G loss: 1.653542]\n",
      "epoch:25 step:24028 [D loss: 0.799733, acc.: 57.03%] [G loss: 1.486280]\n",
      "epoch:25 step:24029 [D loss: 0.506572, acc.: 72.66%] [G loss: 1.308059]\n",
      "epoch:25 step:24030 [D loss: 0.506270, acc.: 75.78%] [G loss: 1.869375]\n",
      "epoch:25 step:24031 [D loss: 0.593842, acc.: 65.62%] [G loss: 0.852277]\n",
      "epoch:25 step:24032 [D loss: 0.708026, acc.: 60.16%] [G loss: 1.306700]\n",
      "epoch:25 step:24033 [D loss: 0.904478, acc.: 53.12%] [G loss: 1.987370]\n",
      "epoch:25 step:24034 [D loss: 0.499458, acc.: 71.88%] [G loss: 2.087713]\n",
      "epoch:25 step:24035 [D loss: 0.741339, acc.: 55.47%] [G loss: 1.809345]\n",
      "epoch:25 step:24036 [D loss: 0.522495, acc.: 75.00%] [G loss: 1.598453]\n",
      "epoch:25 step:24037 [D loss: 0.687605, acc.: 60.94%] [G loss: 1.397427]\n",
      "epoch:25 step:24038 [D loss: 0.473502, acc.: 79.69%] [G loss: 1.240505]\n",
      "epoch:25 step:24039 [D loss: 0.732277, acc.: 52.34%] [G loss: 1.045686]\n",
      "epoch:25 step:24040 [D loss: 0.672390, acc.: 60.16%] [G loss: 1.214499]\n",
      "epoch:25 step:24041 [D loss: 0.310860, acc.: 89.06%] [G loss: 1.796098]\n",
      "epoch:25 step:24042 [D loss: 0.256146, acc.: 94.53%] [G loss: 1.642731]\n",
      "epoch:25 step:24043 [D loss: 0.938091, acc.: 38.28%] [G loss: 1.380303]\n",
      "epoch:25 step:24044 [D loss: 0.531706, acc.: 72.66%] [G loss: 1.406893]\n",
      "epoch:25 step:24045 [D loss: 0.574629, acc.: 69.53%] [G loss: 1.520822]\n",
      "epoch:25 step:24046 [D loss: 0.523781, acc.: 73.44%] [G loss: 1.169919]\n",
      "epoch:25 step:24047 [D loss: 0.219693, acc.: 94.53%] [G loss: 1.520489]\n",
      "epoch:25 step:24048 [D loss: 0.374199, acc.: 85.16%] [G loss: 1.684913]\n",
      "epoch:25 step:24049 [D loss: 0.201737, acc.: 95.31%] [G loss: 1.950257]\n",
      "epoch:25 step:24050 [D loss: 0.653594, acc.: 61.72%] [G loss: 1.709194]\n",
      "epoch:25 step:24051 [D loss: 0.313449, acc.: 89.84%] [G loss: 1.728262]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:25 step:24052 [D loss: 0.562757, acc.: 70.31%] [G loss: 1.547522]\n",
      "epoch:25 step:24053 [D loss: 0.732812, acc.: 51.56%] [G loss: 1.266711]\n",
      "epoch:25 step:24054 [D loss: 0.250084, acc.: 91.41%] [G loss: 1.190907]\n",
      "epoch:25 step:24055 [D loss: 0.324964, acc.: 84.38%] [G loss: 1.860207]\n",
      "epoch:25 step:24056 [D loss: 0.653952, acc.: 63.28%] [G loss: 1.614119]\n",
      "epoch:25 step:24057 [D loss: 0.265452, acc.: 88.28%] [G loss: 1.116081]\n",
      "epoch:25 step:24058 [D loss: 0.222543, acc.: 89.84%] [G loss: 1.819092]\n",
      "epoch:25 step:24059 [D loss: 0.152209, acc.: 97.66%] [G loss: 2.682714]\n",
      "epoch:25 step:24060 [D loss: 0.163141, acc.: 99.22%] [G loss: 2.483283]\n",
      "epoch:25 step:24061 [D loss: 0.454177, acc.: 76.56%] [G loss: 1.319907]\n",
      "epoch:25 step:24062 [D loss: 0.230246, acc.: 96.09%] [G loss: 1.652981]\n",
      "epoch:25 step:24063 [D loss: 1.104702, acc.: 39.84%] [G loss: 0.962309]\n",
      "epoch:25 step:24064 [D loss: 0.813739, acc.: 64.06%] [G loss: 1.471135]\n",
      "epoch:25 step:24065 [D loss: 1.024873, acc.: 44.53%] [G loss: 1.179468]\n",
      "epoch:25 step:24066 [D loss: 0.663916, acc.: 63.28%] [G loss: 1.462069]\n",
      "epoch:25 step:24067 [D loss: 0.674563, acc.: 58.59%] [G loss: 1.817455]\n",
      "epoch:25 step:24068 [D loss: 0.685006, acc.: 56.25%] [G loss: 1.272445]\n",
      "epoch:25 step:24069 [D loss: 0.239487, acc.: 94.53%] [G loss: 1.495337]\n",
      "epoch:25 step:24070 [D loss: 0.245077, acc.: 91.41%] [G loss: 1.684283]\n",
      "epoch:25 step:24071 [D loss: 0.186395, acc.: 96.09%] [G loss: 1.744198]\n",
      "epoch:25 step:24072 [D loss: 0.335251, acc.: 82.81%] [G loss: 1.915419]\n",
      "epoch:25 step:24073 [D loss: 0.235345, acc.: 96.09%] [G loss: 1.902619]\n",
      "epoch:25 step:24074 [D loss: 0.294489, acc.: 91.41%] [G loss: 1.479309]\n",
      "epoch:25 step:24075 [D loss: 0.167813, acc.: 97.66%] [G loss: 1.543556]\n",
      "epoch:25 step:24076 [D loss: 0.363323, acc.: 90.62%] [G loss: 2.219307]\n",
      "epoch:25 step:24077 [D loss: 0.885664, acc.: 54.69%] [G loss: 1.051713]\n",
      "epoch:25 step:24078 [D loss: 0.883126, acc.: 43.75%] [G loss: 1.732119]\n",
      "epoch:25 step:24079 [D loss: 0.802288, acc.: 55.47%] [G loss: 1.533419]\n",
      "epoch:25 step:24080 [D loss: 0.601446, acc.: 66.41%] [G loss: 1.467858]\n",
      "epoch:25 step:24081 [D loss: 0.509825, acc.: 77.34%] [G loss: 0.644254]\n",
      "epoch:25 step:24082 [D loss: 0.926875, acc.: 41.41%] [G loss: 0.800339]\n",
      "epoch:25 step:24083 [D loss: 0.769272, acc.: 50.78%] [G loss: 1.396967]\n",
      "epoch:25 step:24084 [D loss: 0.245743, acc.: 91.41%] [G loss: 1.231571]\n",
      "epoch:25 step:24085 [D loss: 0.361354, acc.: 84.38%] [G loss: 0.884244]\n",
      "epoch:25 step:24086 [D loss: 0.503897, acc.: 77.34%] [G loss: 1.328212]\n",
      "epoch:25 step:24087 [D loss: 0.577264, acc.: 66.41%] [G loss: 1.387786]\n",
      "epoch:25 step:24088 [D loss: 0.469842, acc.: 69.53%] [G loss: 1.676017]\n",
      "epoch:25 step:24089 [D loss: 0.261077, acc.: 89.06%] [G loss: 2.456945]\n",
      "epoch:25 step:24090 [D loss: 0.120603, acc.: 97.66%] [G loss: 2.556162]\n",
      "epoch:25 step:24091 [D loss: 0.820614, acc.: 52.34%] [G loss: 1.839418]\n",
      "epoch:25 step:24092 [D loss: 0.724823, acc.: 58.59%] [G loss: 1.980692]\n",
      "epoch:25 step:24093 [D loss: 0.684403, acc.: 64.06%] [G loss: 1.515554]\n",
      "epoch:25 step:24094 [D loss: 0.573689, acc.: 66.41%] [G loss: 1.854194]\n",
      "epoch:25 step:24095 [D loss: 0.948740, acc.: 38.28%] [G loss: 1.649495]\n",
      "epoch:25 step:24096 [D loss: 0.513296, acc.: 75.78%] [G loss: 1.801783]\n",
      "epoch:25 step:24097 [D loss: 0.769454, acc.: 53.12%] [G loss: 1.601861]\n",
      "epoch:25 step:24098 [D loss: 0.720144, acc.: 53.91%] [G loss: 1.236830]\n",
      "epoch:25 step:24099 [D loss: 0.433762, acc.: 81.25%] [G loss: 1.256315]\n",
      "epoch:25 step:24100 [D loss: 0.640509, acc.: 58.59%] [G loss: 0.939098]\n",
      "epoch:25 step:24101 [D loss: 0.772391, acc.: 51.56%] [G loss: 1.198512]\n",
      "epoch:25 step:24102 [D loss: 0.862657, acc.: 42.19%] [G loss: 1.229268]\n",
      "epoch:25 step:24103 [D loss: 0.818350, acc.: 44.53%] [G loss: 1.111892]\n",
      "epoch:25 step:24104 [D loss: 0.647691, acc.: 65.62%] [G loss: 0.924124]\n",
      "epoch:25 step:24105 [D loss: 0.570565, acc.: 71.88%] [G loss: 0.830974]\n",
      "epoch:25 step:24106 [D loss: 0.747524, acc.: 49.22%] [G loss: 1.001426]\n",
      "epoch:25 step:24107 [D loss: 0.388364, acc.: 88.28%] [G loss: 0.980338]\n",
      "epoch:25 step:24108 [D loss: 0.481125, acc.: 82.03%] [G loss: 1.126778]\n",
      "epoch:25 step:24109 [D loss: 0.290940, acc.: 89.06%] [G loss: 1.029563]\n",
      "epoch:25 step:24110 [D loss: 0.376825, acc.: 87.50%] [G loss: 1.333933]\n",
      "epoch:25 step:24111 [D loss: 0.448167, acc.: 81.25%] [G loss: 1.284349]\n",
      "epoch:25 step:24112 [D loss: 0.373768, acc.: 86.72%] [G loss: 1.108514]\n",
      "epoch:25 step:24113 [D loss: 0.585775, acc.: 68.75%] [G loss: 1.332305]\n",
      "epoch:25 step:24114 [D loss: 0.856913, acc.: 42.97%] [G loss: 1.066551]\n",
      "epoch:25 step:24115 [D loss: 0.751716, acc.: 56.25%] [G loss: 1.134092]\n",
      "epoch:25 step:24116 [D loss: 0.794023, acc.: 46.88%] [G loss: 0.920976]\n",
      "epoch:25 step:24117 [D loss: 0.659321, acc.: 60.16%] [G loss: 0.901035]\n",
      "epoch:25 step:24118 [D loss: 0.630288, acc.: 57.81%] [G loss: 1.210648]\n",
      "epoch:25 step:24119 [D loss: 0.619676, acc.: 64.84%] [G loss: 1.089272]\n",
      "epoch:25 step:24120 [D loss: 0.650301, acc.: 58.59%] [G loss: 1.037157]\n",
      "epoch:25 step:24121 [D loss: 0.234006, acc.: 93.75%] [G loss: 1.027879]\n",
      "epoch:25 step:24122 [D loss: 0.288372, acc.: 89.06%] [G loss: 1.563460]\n",
      "epoch:25 step:24123 [D loss: 0.199704, acc.: 98.44%] [G loss: 1.431915]\n",
      "epoch:25 step:24124 [D loss: 0.306544, acc.: 98.44%] [G loss: 1.341840]\n",
      "epoch:25 step:24125 [D loss: 0.157801, acc.: 97.66%] [G loss: 1.662764]\n",
      "epoch:25 step:24126 [D loss: 0.291004, acc.: 85.16%] [G loss: 1.564354]\n",
      "epoch:25 step:24127 [D loss: 0.278183, acc.: 91.41%] [G loss: 2.031700]\n",
      "epoch:25 step:24128 [D loss: 0.644486, acc.: 60.16%] [G loss: 1.789899]\n",
      "epoch:25 step:24129 [D loss: 0.354045, acc.: 87.50%] [G loss: 1.148536]\n",
      "epoch:25 step:24130 [D loss: 0.688996, acc.: 57.03%] [G loss: 0.994775]\n",
      "epoch:25 step:24131 [D loss: 0.265855, acc.: 88.28%] [G loss: 0.966237]\n",
      "epoch:25 step:24132 [D loss: 0.140983, acc.: 98.44%] [G loss: 1.340223]\n",
      "epoch:25 step:24133 [D loss: 0.140279, acc.: 98.44%] [G loss: 2.101874]\n",
      "epoch:25 step:24134 [D loss: 0.144865, acc.: 97.66%] [G loss: 1.649485]\n",
      "epoch:25 step:24135 [D loss: 0.776999, acc.: 54.69%] [G loss: 2.371693]\n",
      "epoch:25 step:24136 [D loss: 0.702072, acc.: 59.38%] [G loss: 1.677975]\n",
      "epoch:25 step:24137 [D loss: 0.632792, acc.: 63.28%] [G loss: 1.645934]\n",
      "epoch:25 step:24138 [D loss: 0.171509, acc.: 96.09%] [G loss: 1.373845]\n",
      "epoch:25 step:24139 [D loss: 0.224598, acc.: 93.75%] [G loss: 1.352137]\n",
      "epoch:25 step:24140 [D loss: 0.946908, acc.: 45.31%] [G loss: 1.795951]\n",
      "epoch:25 step:24141 [D loss: 0.650347, acc.: 61.72%] [G loss: 1.470315]\n",
      "epoch:25 step:24142 [D loss: 0.857040, acc.: 45.31%] [G loss: 1.034516]\n",
      "epoch:25 step:24143 [D loss: 0.587376, acc.: 65.62%] [G loss: 1.310480]\n",
      "epoch:25 step:24144 [D loss: 0.538533, acc.: 74.22%] [G loss: 0.682812]\n",
      "epoch:25 step:24145 [D loss: 0.556716, acc.: 65.62%] [G loss: 1.611650]\n",
      "epoch:25 step:24146 [D loss: 0.584355, acc.: 68.75%] [G loss: 1.113953]\n",
      "epoch:25 step:24147 [D loss: 0.582162, acc.: 64.84%] [G loss: 1.097759]\n",
      "epoch:25 step:24148 [D loss: 0.685173, acc.: 58.59%] [G loss: 1.213769]\n",
      "epoch:25 step:24149 [D loss: 0.369063, acc.: 87.50%] [G loss: 1.213676]\n",
      "epoch:25 step:24150 [D loss: 0.506151, acc.: 78.12%] [G loss: 1.270877]\n",
      "epoch:25 step:24151 [D loss: 0.309076, acc.: 92.97%] [G loss: 1.596690]\n",
      "epoch:25 step:24152 [D loss: 0.471532, acc.: 81.25%] [G loss: 1.362822]\n",
      "epoch:25 step:24153 [D loss: 0.163109, acc.: 99.22%] [G loss: 1.546318]\n",
      "epoch:25 step:24154 [D loss: 0.211350, acc.: 95.31%] [G loss: 1.763025]\n",
      "epoch:25 step:24155 [D loss: 0.180669, acc.: 97.66%] [G loss: 1.704793]\n",
      "epoch:25 step:24156 [D loss: 0.214142, acc.: 96.88%] [G loss: 2.053403]\n",
      "epoch:25 step:24157 [D loss: 1.366395, acc.: 53.91%] [G loss: 2.112264]\n",
      "epoch:25 step:24158 [D loss: 0.228238, acc.: 93.75%] [G loss: 2.982671]\n",
      "epoch:25 step:24159 [D loss: 1.009859, acc.: 50.78%] [G loss: 2.091199]\n",
      "epoch:25 step:24160 [D loss: 0.725791, acc.: 59.38%] [G loss: 1.626920]\n",
      "epoch:25 step:24161 [D loss: 0.577984, acc.: 63.28%] [G loss: 1.908122]\n",
      "epoch:25 step:24162 [D loss: 0.797445, acc.: 52.34%] [G loss: 1.496093]\n",
      "epoch:25 step:24163 [D loss: 0.997494, acc.: 28.91%] [G loss: 1.195808]\n",
      "epoch:25 step:24164 [D loss: 0.428489, acc.: 79.69%] [G loss: 1.470611]\n",
      "epoch:25 step:24165 [D loss: 0.608026, acc.: 60.16%] [G loss: 1.229313]\n",
      "epoch:25 step:24166 [D loss: 0.247446, acc.: 96.09%] [G loss: 1.607726]\n",
      "epoch:25 step:24167 [D loss: 0.264920, acc.: 94.53%] [G loss: 1.218278]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:25 step:24168 [D loss: 0.193911, acc.: 98.44%] [G loss: 1.446181]\n",
      "epoch:25 step:24169 [D loss: 0.506698, acc.: 75.00%] [G loss: 1.602388]\n",
      "epoch:25 step:24170 [D loss: 0.473461, acc.: 82.03%] [G loss: 1.425790]\n",
      "epoch:25 step:24171 [D loss: 0.616603, acc.: 61.72%] [G loss: 1.187471]\n",
      "epoch:25 step:24172 [D loss: 0.587489, acc.: 64.06%] [G loss: 1.514205]\n",
      "epoch:25 step:24173 [D loss: 0.463357, acc.: 81.25%] [G loss: 1.397104]\n",
      "epoch:25 step:24174 [D loss: 0.241415, acc.: 95.31%] [G loss: 1.423827]\n",
      "epoch:25 step:24175 [D loss: 0.315415, acc.: 85.94%] [G loss: 1.568525]\n",
      "epoch:25 step:24176 [D loss: 0.640520, acc.: 62.50%] [G loss: 1.473853]\n",
      "epoch:25 step:24177 [D loss: 0.745142, acc.: 57.03%] [G loss: 1.229029]\n",
      "epoch:25 step:24178 [D loss: 0.753607, acc.: 52.34%] [G loss: 1.132818]\n",
      "epoch:25 step:24179 [D loss: 0.328219, acc.: 92.19%] [G loss: 0.674674]\n",
      "epoch:25 step:24180 [D loss: 0.562018, acc.: 68.75%] [G loss: 1.335101]\n",
      "epoch:25 step:24181 [D loss: 0.201065, acc.: 99.22%] [G loss: 0.938874]\n",
      "epoch:25 step:24182 [D loss: 0.594648, acc.: 68.75%] [G loss: 1.464635]\n",
      "epoch:25 step:24183 [D loss: 0.673545, acc.: 60.16%] [G loss: 1.309683]\n",
      "epoch:25 step:24184 [D loss: 0.431495, acc.: 81.25%] [G loss: 0.816038]\n",
      "epoch:25 step:24185 [D loss: 0.582282, acc.: 71.09%] [G loss: 1.506084]\n",
      "epoch:25 step:24186 [D loss: 0.691943, acc.: 58.59%] [G loss: 1.223163]\n",
      "epoch:25 step:24187 [D loss: 0.917543, acc.: 42.97%] [G loss: 1.431416]\n",
      "epoch:25 step:24188 [D loss: 0.568138, acc.: 66.41%] [G loss: 1.788795]\n",
      "epoch:25 step:24189 [D loss: 0.297087, acc.: 89.06%] [G loss: 1.264668]\n",
      "epoch:25 step:24190 [D loss: 0.392122, acc.: 83.59%] [G loss: 1.222471]\n",
      "epoch:25 step:24191 [D loss: 0.468530, acc.: 81.25%] [G loss: 1.321776]\n",
      "epoch:25 step:24192 [D loss: 0.284757, acc.: 95.31%] [G loss: 1.890804]\n",
      "epoch:25 step:24193 [D loss: 0.262742, acc.: 91.41%] [G loss: 1.554962]\n",
      "epoch:25 step:24194 [D loss: 0.137029, acc.: 98.44%] [G loss: 1.589040]\n",
      "epoch:25 step:24195 [D loss: 0.494807, acc.: 75.78%] [G loss: 1.635672]\n",
      "epoch:25 step:24196 [D loss: 0.655778, acc.: 61.72%] [G loss: 1.657194]\n",
      "epoch:25 step:24197 [D loss: 0.699244, acc.: 58.59%] [G loss: 1.219145]\n",
      "epoch:25 step:24198 [D loss: 0.501214, acc.: 74.22%] [G loss: 1.287865]\n",
      "epoch:25 step:24199 [D loss: 0.196540, acc.: 93.75%] [G loss: 1.438973]\n",
      "epoch:25 step:24200 [D loss: 0.226381, acc.: 92.97%] [G loss: 1.613741]\n",
      "##############\n",
      "[3.81066424 2.78309879 6.48901726 5.42686063 4.63357567 6.24514989\n",
      " 5.20324561 5.43558106 5.49145055 5.04679226]\n",
      "##########\n",
      "epoch:25 step:24201 [D loss: 0.592250, acc.: 64.06%] [G loss: 1.779215]\n",
      "epoch:25 step:24202 [D loss: 0.233785, acc.: 93.75%] [G loss: 2.324295]\n",
      "epoch:25 step:24203 [D loss: 0.430712, acc.: 81.25%] [G loss: 1.488720]\n",
      "epoch:25 step:24204 [D loss: 0.865870, acc.: 53.91%] [G loss: 1.823132]\n",
      "epoch:25 step:24205 [D loss: 0.451066, acc.: 76.56%] [G loss: 1.545558]\n",
      "epoch:25 step:24206 [D loss: 0.374147, acc.: 85.16%] [G loss: 1.643314]\n",
      "epoch:25 step:24207 [D loss: 0.264135, acc.: 94.53%] [G loss: 1.175653]\n",
      "epoch:25 step:24208 [D loss: 0.617075, acc.: 63.28%] [G loss: 1.457562]\n",
      "epoch:25 step:24209 [D loss: 0.635020, acc.: 67.19%] [G loss: 1.285336]\n",
      "epoch:25 step:24210 [D loss: 0.612246, acc.: 62.50%] [G loss: 1.127563]\n",
      "epoch:25 step:24211 [D loss: 0.422929, acc.: 80.47%] [G loss: 1.300354]\n",
      "epoch:25 step:24212 [D loss: 0.681417, acc.: 57.81%] [G loss: 1.157326]\n",
      "epoch:25 step:24213 [D loss: 0.563966, acc.: 71.88%] [G loss: 1.272227]\n",
      "epoch:25 step:24214 [D loss: 1.006115, acc.: 32.03%] [G loss: 1.447003]\n",
      "epoch:25 step:24215 [D loss: 0.875405, acc.: 44.53%] [G loss: 0.942286]\n",
      "epoch:25 step:24216 [D loss: 0.247713, acc.: 89.06%] [G loss: 1.109843]\n",
      "epoch:25 step:24217 [D loss: 0.432010, acc.: 75.00%] [G loss: 1.579944]\n",
      "epoch:25 step:24218 [D loss: 0.292446, acc.: 90.62%] [G loss: 1.885914]\n",
      "epoch:25 step:24219 [D loss: 0.365410, acc.: 87.50%] [G loss: 1.972159]\n",
      "epoch:25 step:24220 [D loss: 0.597870, acc.: 66.41%] [G loss: 1.762075]\n",
      "epoch:25 step:24221 [D loss: 0.398043, acc.: 84.38%] [G loss: 1.651400]\n",
      "epoch:25 step:24222 [D loss: 0.746368, acc.: 53.12%] [G loss: 1.201840]\n",
      "epoch:25 step:24223 [D loss: 0.918071, acc.: 41.41%] [G loss: 1.570322]\n",
      "epoch:25 step:24224 [D loss: 0.741272, acc.: 52.34%] [G loss: 1.328200]\n",
      "epoch:25 step:24225 [D loss: 0.232872, acc.: 92.19%] [G loss: 1.271902]\n",
      "epoch:25 step:24226 [D loss: 0.327064, acc.: 85.94%] [G loss: 1.329628]\n",
      "epoch:25 step:24227 [D loss: 0.196794, acc.: 98.44%] [G loss: 1.933449]\n",
      "epoch:25 step:24228 [D loss: 0.292188, acc.: 91.41%] [G loss: 1.569631]\n",
      "epoch:25 step:24229 [D loss: 0.139219, acc.: 99.22%] [G loss: 1.604184]\n",
      "epoch:25 step:24230 [D loss: 0.178587, acc.: 99.22%] [G loss: 2.102496]\n",
      "epoch:25 step:24231 [D loss: 0.154772, acc.: 98.44%] [G loss: 2.291974]\n",
      "epoch:25 step:24232 [D loss: 0.650664, acc.: 62.50%] [G loss: 2.018135]\n",
      "epoch:25 step:24233 [D loss: 0.108740, acc.: 100.00%] [G loss: 2.194010]\n",
      "epoch:25 step:24234 [D loss: 0.131955, acc.: 97.66%] [G loss: 1.796556]\n",
      "epoch:25 step:24235 [D loss: 0.169945, acc.: 100.00%] [G loss: 1.723386]\n",
      "epoch:25 step:24236 [D loss: 0.999340, acc.: 46.88%] [G loss: 1.952145]\n",
      "epoch:25 step:24237 [D loss: 0.886203, acc.: 42.19%] [G loss: 1.675164]\n",
      "epoch:25 step:24238 [D loss: 0.608040, acc.: 61.72%] [G loss: 1.323864]\n",
      "epoch:25 step:24239 [D loss: 0.494151, acc.: 79.69%] [G loss: 1.333965]\n",
      "epoch:25 step:24240 [D loss: 0.473746, acc.: 64.06%] [G loss: 1.289689]\n",
      "epoch:25 step:24241 [D loss: 0.199323, acc.: 99.22%] [G loss: 1.463281]\n",
      "epoch:25 step:24242 [D loss: 0.635681, acc.: 60.94%] [G loss: 1.308132]\n",
      "epoch:25 step:24243 [D loss: 0.549965, acc.: 75.78%] [G loss: 1.013792]\n",
      "epoch:25 step:24244 [D loss: 0.452942, acc.: 85.16%] [G loss: 1.629207]\n",
      "epoch:25 step:24245 [D loss: 0.743577, acc.: 50.78%] [G loss: 1.425833]\n",
      "epoch:25 step:24246 [D loss: 0.767028, acc.: 60.94%] [G loss: 0.968441]\n",
      "epoch:25 step:24247 [D loss: 0.637261, acc.: 59.38%] [G loss: 1.083864]\n",
      "epoch:25 step:24248 [D loss: 0.672929, acc.: 60.16%] [G loss: 1.203436]\n",
      "epoch:25 step:24249 [D loss: 0.422553, acc.: 78.91%] [G loss: 1.136997]\n",
      "epoch:25 step:24250 [D loss: 0.417413, acc.: 74.22%] [G loss: 1.369783]\n",
      "epoch:25 step:24251 [D loss: 0.721749, acc.: 60.94%] [G loss: 0.977821]\n",
      "epoch:25 step:24252 [D loss: 0.518750, acc.: 75.00%] [G loss: 0.881935]\n",
      "epoch:25 step:24253 [D loss: 0.967951, acc.: 34.38%] [G loss: 0.424594]\n",
      "epoch:25 step:24254 [D loss: 0.684369, acc.: 58.59%] [G loss: 1.171701]\n",
      "epoch:25 step:24255 [D loss: 0.376513, acc.: 82.81%] [G loss: 0.660959]\n",
      "epoch:25 step:24256 [D loss: 0.553562, acc.: 66.41%] [G loss: 1.388295]\n",
      "epoch:25 step:24257 [D loss: 0.182720, acc.: 99.22%] [G loss: 1.391972]\n",
      "epoch:25 step:24258 [D loss: 0.274549, acc.: 96.09%] [G loss: 1.837035]\n",
      "epoch:25 step:24259 [D loss: 0.952690, acc.: 41.41%] [G loss: 1.284485]\n",
      "epoch:25 step:24260 [D loss: 0.824552, acc.: 46.88%] [G loss: 1.549252]\n",
      "epoch:25 step:24261 [D loss: 0.841293, acc.: 48.44%] [G loss: 1.715082]\n",
      "epoch:25 step:24262 [D loss: 0.775442, acc.: 44.53%] [G loss: 1.277040]\n",
      "epoch:25 step:24263 [D loss: 0.672264, acc.: 62.50%] [G loss: 1.165715]\n",
      "epoch:25 step:24264 [D loss: 0.539017, acc.: 74.22%] [G loss: 1.668391]\n",
      "epoch:25 step:24265 [D loss: 0.844195, acc.: 40.62%] [G loss: 1.403869]\n",
      "epoch:25 step:24266 [D loss: 0.300354, acc.: 89.84%] [G loss: 1.518977]\n",
      "epoch:25 step:24267 [D loss: 0.309153, acc.: 91.41%] [G loss: 1.638141]\n",
      "epoch:25 step:24268 [D loss: 0.661067, acc.: 67.19%] [G loss: 1.220041]\n",
      "epoch:25 step:24269 [D loss: 0.559731, acc.: 71.09%] [G loss: 1.060367]\n",
      "epoch:25 step:24270 [D loss: 0.327220, acc.: 92.19%] [G loss: 1.232014]\n",
      "epoch:25 step:24271 [D loss: 0.695126, acc.: 55.47%] [G loss: 1.431117]\n",
      "epoch:25 step:24272 [D loss: 0.210764, acc.: 93.75%] [G loss: 1.478846]\n",
      "epoch:25 step:24273 [D loss: 0.248769, acc.: 96.09%] [G loss: 1.694471]\n",
      "epoch:25 step:24274 [D loss: 0.562056, acc.: 70.31%] [G loss: 1.712741]\n",
      "epoch:25 step:24275 [D loss: 0.203306, acc.: 92.97%] [G loss: 2.034044]\n",
      "epoch:25 step:24276 [D loss: 0.134035, acc.: 97.66%] [G loss: 2.081456]\n",
      "epoch:25 step:24277 [D loss: 0.161931, acc.: 97.66%] [G loss: 2.143267]\n",
      "epoch:25 step:24278 [D loss: 0.117574, acc.: 100.00%] [G loss: 1.175832]\n",
      "epoch:25 step:24279 [D loss: 0.123272, acc.: 99.22%] [G loss: 1.883278]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:25 step:24280 [D loss: 0.230904, acc.: 93.75%] [G loss: 2.161227]\n",
      "epoch:25 step:24281 [D loss: 0.734543, acc.: 59.38%] [G loss: 1.356897]\n",
      "epoch:25 step:24282 [D loss: 0.196050, acc.: 95.31%] [G loss: 1.526351]\n",
      "epoch:25 step:24283 [D loss: 0.553811, acc.: 75.78%] [G loss: 1.670698]\n",
      "epoch:25 step:24284 [D loss: 0.518416, acc.: 76.56%] [G loss: 1.359924]\n",
      "epoch:25 step:24285 [D loss: 0.564236, acc.: 69.53%] [G loss: 1.497945]\n",
      "epoch:25 step:24286 [D loss: 0.396363, acc.: 85.16%] [G loss: 1.124668]\n",
      "epoch:25 step:24287 [D loss: 0.743647, acc.: 52.34%] [G loss: 1.300563]\n",
      "epoch:25 step:24288 [D loss: 0.636085, acc.: 67.97%] [G loss: 0.945257]\n",
      "epoch:25 step:24289 [D loss: 0.572949, acc.: 69.53%] [G loss: 1.094504]\n",
      "epoch:25 step:24290 [D loss: 0.453368, acc.: 79.69%] [G loss: 0.936230]\n",
      "epoch:25 step:24291 [D loss: 0.529113, acc.: 75.78%] [G loss: 1.091307]\n",
      "epoch:25 step:24292 [D loss: 0.573201, acc.: 71.88%] [G loss: 1.113231]\n",
      "epoch:25 step:24293 [D loss: 0.738499, acc.: 53.12%] [G loss: 1.080183]\n",
      "epoch:25 step:24294 [D loss: 0.608999, acc.: 64.84%] [G loss: 1.337274]\n",
      "epoch:25 step:24295 [D loss: 0.634905, acc.: 69.53%] [G loss: 1.179294]\n",
      "epoch:25 step:24296 [D loss: 0.771780, acc.: 53.12%] [G loss: 1.274232]\n",
      "epoch:25 step:24297 [D loss: 0.372652, acc.: 89.84%] [G loss: 1.106605]\n",
      "epoch:25 step:24298 [D loss: 0.488048, acc.: 82.03%] [G loss: 1.030243]\n",
      "epoch:25 step:24299 [D loss: 0.568677, acc.: 71.88%] [G loss: 1.306692]\n",
      "epoch:25 step:24300 [D loss: 0.359326, acc.: 86.72%] [G loss: 1.295027]\n",
      "epoch:25 step:24301 [D loss: 0.672278, acc.: 62.50%] [G loss: 0.954486]\n",
      "epoch:25 step:24302 [D loss: 0.673779, acc.: 58.59%] [G loss: 0.941828]\n",
      "epoch:25 step:24303 [D loss: 0.353850, acc.: 86.72%] [G loss: 1.023831]\n",
      "epoch:25 step:24304 [D loss: 0.806250, acc.: 48.44%] [G loss: 1.028631]\n",
      "epoch:25 step:24305 [D loss: 0.536259, acc.: 69.53%] [G loss: 1.062792]\n",
      "epoch:25 step:24306 [D loss: 0.628579, acc.: 64.84%] [G loss: 1.119017]\n",
      "epoch:25 step:24307 [D loss: 0.228161, acc.: 89.84%] [G loss: 1.309686]\n",
      "epoch:25 step:24308 [D loss: 0.303428, acc.: 87.50%] [G loss: 1.515625]\n",
      "epoch:25 step:24309 [D loss: 0.203251, acc.: 95.31%] [G loss: 1.748220]\n",
      "epoch:25 step:24310 [D loss: 0.098603, acc.: 100.00%] [G loss: 2.475899]\n",
      "epoch:25 step:24311 [D loss: 0.128611, acc.: 99.22%] [G loss: 1.814278]\n",
      "epoch:25 step:24312 [D loss: 0.183250, acc.: 97.66%] [G loss: 1.835483]\n",
      "epoch:25 step:24313 [D loss: 0.753611, acc.: 56.25%] [G loss: 1.756525]\n",
      "epoch:25 step:24314 [D loss: 0.123449, acc.: 100.00%] [G loss: 1.511801]\n",
      "epoch:25 step:24315 [D loss: 0.265891, acc.: 92.97%] [G loss: 1.640257]\n",
      "epoch:25 step:24316 [D loss: 1.038828, acc.: 39.84%] [G loss: 1.704859]\n",
      "epoch:25 step:24317 [D loss: 0.940379, acc.: 50.78%] [G loss: 1.439715]\n",
      "epoch:25 step:24318 [D loss: 0.650623, acc.: 59.38%] [G loss: 1.323292]\n",
      "epoch:25 step:24319 [D loss: 0.459091, acc.: 84.38%] [G loss: 0.975089]\n",
      "epoch:25 step:24320 [D loss: 0.565569, acc.: 72.66%] [G loss: 1.174327]\n",
      "epoch:25 step:24321 [D loss: 0.432113, acc.: 85.94%] [G loss: 1.059396]\n",
      "epoch:25 step:24322 [D loss: 0.626356, acc.: 67.97%] [G loss: 0.935842]\n",
      "epoch:25 step:24323 [D loss: 0.327245, acc.: 86.72%] [G loss: 1.263201]\n",
      "epoch:25 step:24324 [D loss: 0.194142, acc.: 95.31%] [G loss: 1.239464]\n",
      "epoch:25 step:24325 [D loss: 0.396914, acc.: 85.16%] [G loss: 1.682976]\n",
      "epoch:25 step:24326 [D loss: 0.585327, acc.: 64.84%] [G loss: 1.435936]\n",
      "epoch:25 step:24327 [D loss: 0.597046, acc.: 67.19%] [G loss: 1.032675]\n",
      "epoch:25 step:24328 [D loss: 0.548151, acc.: 74.22%] [G loss: 1.092634]\n",
      "epoch:25 step:24329 [D loss: 0.263201, acc.: 89.06%] [G loss: 1.541375]\n",
      "epoch:25 step:24330 [D loss: 0.450640, acc.: 73.44%] [G loss: 1.709842]\n",
      "epoch:25 step:24331 [D loss: 0.270383, acc.: 93.75%] [G loss: 1.208781]\n",
      "epoch:25 step:24332 [D loss: 0.755065, acc.: 57.03%] [G loss: 1.729007]\n",
      "epoch:25 step:24333 [D loss: 0.954059, acc.: 46.09%] [G loss: 1.674987]\n",
      "epoch:25 step:24334 [D loss: 0.479007, acc.: 82.81%] [G loss: 1.419505]\n",
      "epoch:25 step:24335 [D loss: 0.321201, acc.: 93.75%] [G loss: 1.497459]\n",
      "epoch:25 step:24336 [D loss: 0.334873, acc.: 89.84%] [G loss: 1.039897]\n",
      "epoch:25 step:24337 [D loss: 0.173111, acc.: 94.53%] [G loss: 1.787458]\n",
      "epoch:25 step:24338 [D loss: 0.894346, acc.: 43.75%] [G loss: 1.193271]\n",
      "epoch:25 step:24339 [D loss: 0.891248, acc.: 39.84%] [G loss: 1.387277]\n",
      "epoch:25 step:24340 [D loss: 0.661380, acc.: 62.50%] [G loss: 1.488318]\n",
      "epoch:25 step:24341 [D loss: 0.361420, acc.: 85.94%] [G loss: 1.287491]\n",
      "epoch:25 step:24342 [D loss: 0.258283, acc.: 91.41%] [G loss: 1.755151]\n",
      "epoch:25 step:24343 [D loss: 0.448088, acc.: 85.94%] [G loss: 1.733337]\n",
      "epoch:25 step:24344 [D loss: 0.397738, acc.: 87.50%] [G loss: 1.321346]\n",
      "epoch:25 step:24345 [D loss: 0.202595, acc.: 93.75%] [G loss: 1.871834]\n",
      "epoch:25 step:24346 [D loss: 0.153424, acc.: 99.22%] [G loss: 1.708777]\n",
      "epoch:25 step:24347 [D loss: 0.473528, acc.: 75.78%] [G loss: 1.713255]\n",
      "epoch:25 step:24348 [D loss: 0.667790, acc.: 62.50%] [G loss: 1.586271]\n",
      "epoch:25 step:24349 [D loss: 0.437165, acc.: 80.47%] [G loss: 1.566660]\n",
      "epoch:25 step:24350 [D loss: 0.613793, acc.: 68.75%] [G loss: 1.491278]\n",
      "epoch:25 step:24351 [D loss: 0.453576, acc.: 83.59%] [G loss: 1.734992]\n",
      "epoch:25 step:24352 [D loss: 0.377130, acc.: 86.72%] [G loss: 1.307492]\n",
      "epoch:25 step:24353 [D loss: 0.693735, acc.: 58.59%] [G loss: 1.451529]\n",
      "epoch:25 step:24354 [D loss: 0.186372, acc.: 96.09%] [G loss: 1.018407]\n",
      "epoch:25 step:24355 [D loss: 0.268801, acc.: 93.75%] [G loss: 1.483554]\n",
      "epoch:25 step:24356 [D loss: 0.419192, acc.: 82.03%] [G loss: 1.285979]\n",
      "epoch:25 step:24357 [D loss: 0.457357, acc.: 82.81%] [G loss: 1.472166]\n",
      "epoch:25 step:24358 [D loss: 0.672629, acc.: 60.16%] [G loss: 1.364361]\n",
      "epoch:25 step:24359 [D loss: 0.297509, acc.: 85.16%] [G loss: 1.935915]\n",
      "epoch:25 step:24360 [D loss: 0.261260, acc.: 97.66%] [G loss: 1.808856]\n",
      "epoch:25 step:24361 [D loss: 0.132828, acc.: 99.22%] [G loss: 1.687286]\n",
      "epoch:25 step:24362 [D loss: 0.198558, acc.: 93.75%] [G loss: 1.491201]\n",
      "epoch:26 step:24363 [D loss: 0.543692, acc.: 69.53%] [G loss: 1.408579]\n",
      "epoch:26 step:24364 [D loss: 0.653480, acc.: 63.28%] [G loss: 1.502108]\n",
      "epoch:26 step:24365 [D loss: 0.432176, acc.: 79.69%] [G loss: 1.051736]\n",
      "epoch:26 step:24366 [D loss: 0.823076, acc.: 45.31%] [G loss: 1.007602]\n",
      "epoch:26 step:24367 [D loss: 0.894103, acc.: 38.28%] [G loss: 1.112544]\n",
      "epoch:26 step:24368 [D loss: 0.709368, acc.: 56.25%] [G loss: 1.524993]\n",
      "epoch:26 step:24369 [D loss: 0.601562, acc.: 66.41%] [G loss: 2.147605]\n",
      "epoch:26 step:24370 [D loss: 0.447467, acc.: 79.69%] [G loss: 1.479026]\n",
      "epoch:26 step:24371 [D loss: 0.325006, acc.: 89.84%] [G loss: 1.799473]\n",
      "epoch:26 step:24372 [D loss: 0.164280, acc.: 96.88%] [G loss: 1.749556]\n",
      "epoch:26 step:24373 [D loss: 0.339553, acc.: 88.28%] [G loss: 1.803486]\n",
      "epoch:26 step:24374 [D loss: 0.555176, acc.: 68.75%] [G loss: 1.550315]\n",
      "epoch:26 step:24375 [D loss: 0.299249, acc.: 92.19%] [G loss: 2.274514]\n",
      "epoch:26 step:24376 [D loss: 0.844310, acc.: 45.31%] [G loss: 1.548277]\n",
      "epoch:26 step:24377 [D loss: 0.171918, acc.: 98.44%] [G loss: 1.663510]\n",
      "epoch:26 step:24378 [D loss: 0.417496, acc.: 85.16%] [G loss: 1.454173]\n",
      "epoch:26 step:24379 [D loss: 1.057967, acc.: 41.41%] [G loss: 0.879434]\n",
      "epoch:26 step:24380 [D loss: 0.633891, acc.: 63.28%] [G loss: 1.822985]\n",
      "epoch:26 step:24381 [D loss: 1.168415, acc.: 37.50%] [G loss: 1.276219]\n",
      "epoch:26 step:24382 [D loss: 0.788678, acc.: 54.69%] [G loss: 1.708964]\n",
      "epoch:26 step:24383 [D loss: 1.255501, acc.: 28.12%] [G loss: 1.275138]\n",
      "epoch:26 step:24384 [D loss: 0.755838, acc.: 57.81%] [G loss: 2.013182]\n",
      "epoch:26 step:24385 [D loss: 0.916373, acc.: 52.34%] [G loss: 1.322912]\n",
      "epoch:26 step:24386 [D loss: 0.552335, acc.: 69.53%] [G loss: 1.420612]\n",
      "epoch:26 step:24387 [D loss: 0.586308, acc.: 69.53%] [G loss: 1.684777]\n",
      "epoch:26 step:24388 [D loss: 1.365994, acc.: 13.28%] [G loss: 1.816725]\n",
      "epoch:26 step:24389 [D loss: 0.237143, acc.: 91.41%] [G loss: 1.728838]\n",
      "epoch:26 step:24390 [D loss: 0.272853, acc.: 92.97%] [G loss: 2.853850]\n",
      "epoch:26 step:24391 [D loss: 0.469189, acc.: 79.69%] [G loss: 2.651906]\n",
      "epoch:26 step:24392 [D loss: 0.471327, acc.: 76.56%] [G loss: 1.632971]\n",
      "epoch:26 step:24393 [D loss: 0.097185, acc.: 99.22%] [G loss: 2.951197]\n",
      "epoch:26 step:24394 [D loss: 0.127878, acc.: 100.00%] [G loss: 2.594629]\n",
      "epoch:26 step:24395 [D loss: 0.075808, acc.: 98.44%] [G loss: 2.410236]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:26 step:24396 [D loss: 0.178015, acc.: 96.88%] [G loss: 2.654270]\n",
      "epoch:26 step:24397 [D loss: 0.055570, acc.: 100.00%] [G loss: 2.405837]\n",
      "epoch:26 step:24398 [D loss: 0.045312, acc.: 100.00%] [G loss: 2.067453]\n",
      "epoch:26 step:24399 [D loss: 0.949748, acc.: 53.91%] [G loss: 2.609194]\n",
      "epoch:26 step:24400 [D loss: 0.920735, acc.: 46.88%] [G loss: 1.541612]\n",
      "##############\n",
      "[4.08980216 2.6392582  6.72425316 5.99532169 4.67806855 6.54156722\n",
      " 5.86851066 5.93464113 5.82412214 5.1197361 ]\n",
      "##########\n",
      "epoch:26 step:24401 [D loss: 0.960495, acc.: 50.00%] [G loss: 1.303523]\n",
      "epoch:26 step:24402 [D loss: 0.687736, acc.: 57.03%] [G loss: 1.375494]\n",
      "epoch:26 step:24403 [D loss: 0.343224, acc.: 89.84%] [G loss: 1.452586]\n",
      "epoch:26 step:24404 [D loss: 0.239974, acc.: 95.31%] [G loss: 1.462034]\n",
      "epoch:26 step:24405 [D loss: 0.187725, acc.: 95.31%] [G loss: 1.177296]\n",
      "epoch:26 step:24406 [D loss: 0.196363, acc.: 94.53%] [G loss: 1.688239]\n",
      "epoch:26 step:24407 [D loss: 0.315403, acc.: 90.62%] [G loss: 1.135258]\n",
      "epoch:26 step:24408 [D loss: 0.218200, acc.: 94.53%] [G loss: 1.779541]\n",
      "epoch:26 step:24409 [D loss: 0.344613, acc.: 90.62%] [G loss: 1.577454]\n",
      "epoch:26 step:24410 [D loss: 0.721214, acc.: 59.38%] [G loss: 1.475135]\n",
      "epoch:26 step:24411 [D loss: 0.558495, acc.: 72.66%] [G loss: 1.653138]\n",
      "epoch:26 step:24412 [D loss: 0.434357, acc.: 81.25%] [G loss: 1.805263]\n",
      "epoch:26 step:24413 [D loss: 0.156880, acc.: 96.88%] [G loss: 2.313908]\n",
      "epoch:26 step:24414 [D loss: 0.147329, acc.: 99.22%] [G loss: 1.880274]\n",
      "epoch:26 step:24415 [D loss: 0.302674, acc.: 92.97%] [G loss: 1.659494]\n",
      "epoch:26 step:24416 [D loss: 0.559886, acc.: 67.19%] [G loss: 1.587989]\n",
      "epoch:26 step:24417 [D loss: 0.686816, acc.: 55.47%] [G loss: 1.665241]\n",
      "epoch:26 step:24418 [D loss: 0.370392, acc.: 87.50%] [G loss: 1.493496]\n",
      "epoch:26 step:24419 [D loss: 0.126057, acc.: 97.66%] [G loss: 1.728918]\n",
      "epoch:26 step:24420 [D loss: 0.361571, acc.: 77.34%] [G loss: 1.328799]\n",
      "epoch:26 step:24421 [D loss: 0.201005, acc.: 96.88%] [G loss: 1.931122]\n",
      "epoch:26 step:24422 [D loss: 0.456110, acc.: 71.88%] [G loss: 1.796609]\n",
      "epoch:26 step:24423 [D loss: 0.742683, acc.: 56.25%] [G loss: 2.340898]\n",
      "epoch:26 step:24424 [D loss: 0.670176, acc.: 61.72%] [G loss: 1.565341]\n",
      "epoch:26 step:24425 [D loss: 0.243655, acc.: 96.88%] [G loss: 1.634822]\n",
      "epoch:26 step:24426 [D loss: 1.029761, acc.: 39.84%] [G loss: 0.993596]\n",
      "epoch:26 step:24427 [D loss: 1.006933, acc.: 32.03%] [G loss: 0.776714]\n",
      "epoch:26 step:24428 [D loss: 0.647703, acc.: 65.62%] [G loss: 1.825897]\n",
      "epoch:26 step:24429 [D loss: 0.613114, acc.: 68.75%] [G loss: 2.007041]\n",
      "epoch:26 step:24430 [D loss: 1.148891, acc.: 34.38%] [G loss: 1.434886]\n",
      "epoch:26 step:24431 [D loss: 0.973478, acc.: 45.31%] [G loss: 0.902547]\n",
      "epoch:26 step:24432 [D loss: 0.694928, acc.: 57.81%] [G loss: 1.832527]\n",
      "epoch:26 step:24433 [D loss: 0.194353, acc.: 93.75%] [G loss: 1.037133]\n",
      "epoch:26 step:24434 [D loss: 0.359987, acc.: 82.81%] [G loss: 1.604138]\n",
      "epoch:26 step:24435 [D loss: 0.308323, acc.: 87.50%] [G loss: 2.319277]\n",
      "epoch:26 step:24436 [D loss: 0.469107, acc.: 76.56%] [G loss: 1.016431]\n",
      "epoch:26 step:24437 [D loss: 0.373499, acc.: 80.47%] [G loss: 0.642486]\n",
      "epoch:26 step:24438 [D loss: 0.161270, acc.: 93.75%] [G loss: 2.217098]\n",
      "epoch:26 step:24439 [D loss: 0.219048, acc.: 96.88%] [G loss: 2.180972]\n",
      "epoch:26 step:24440 [D loss: 1.297747, acc.: 32.81%] [G loss: 1.497226]\n",
      "epoch:26 step:24441 [D loss: 0.864203, acc.: 54.69%] [G loss: 1.308963]\n",
      "epoch:26 step:24442 [D loss: 1.051302, acc.: 49.22%] [G loss: 1.562023]\n",
      "epoch:26 step:24443 [D loss: 0.999048, acc.: 39.84%] [G loss: 0.796745]\n",
      "epoch:26 step:24444 [D loss: 0.740217, acc.: 58.59%] [G loss: 1.840652]\n",
      "epoch:26 step:24445 [D loss: 0.582538, acc.: 67.97%] [G loss: 1.400784]\n",
      "epoch:26 step:24446 [D loss: 0.739866, acc.: 57.03%] [G loss: 1.296522]\n",
      "epoch:26 step:24447 [D loss: 0.723455, acc.: 56.25%] [G loss: 1.272289]\n",
      "epoch:26 step:24448 [D loss: 0.782977, acc.: 50.78%] [G loss: 0.863263]\n",
      "epoch:26 step:24449 [D loss: 0.509854, acc.: 75.00%] [G loss: 1.314798]\n",
      "epoch:26 step:24450 [D loss: 0.467917, acc.: 78.91%] [G loss: 1.455849]\n",
      "epoch:26 step:24451 [D loss: 0.550399, acc.: 72.66%] [G loss: 1.456104]\n",
      "epoch:26 step:24452 [D loss: 0.464679, acc.: 78.91%] [G loss: 1.532483]\n",
      "epoch:26 step:24453 [D loss: 0.559350, acc.: 67.97%] [G loss: 1.753089]\n",
      "epoch:26 step:24454 [D loss: 0.301121, acc.: 89.84%] [G loss: 1.685729]\n",
      "epoch:26 step:24455 [D loss: 0.256399, acc.: 94.53%] [G loss: 2.223233]\n",
      "epoch:26 step:24456 [D loss: 0.495250, acc.: 79.69%] [G loss: 1.299402]\n",
      "epoch:26 step:24457 [D loss: 0.594316, acc.: 67.19%] [G loss: 1.750145]\n",
      "epoch:26 step:24458 [D loss: 0.518279, acc.: 71.88%] [G loss: 2.010919]\n",
      "epoch:26 step:24459 [D loss: 0.427405, acc.: 82.81%] [G loss: 1.590965]\n",
      "epoch:26 step:24460 [D loss: 0.516089, acc.: 74.22%] [G loss: 1.467655]\n",
      "epoch:26 step:24461 [D loss: 0.584301, acc.: 70.31%] [G loss: 1.598954]\n",
      "epoch:26 step:24462 [D loss: 0.624993, acc.: 67.19%] [G loss: 1.531891]\n",
      "epoch:26 step:24463 [D loss: 0.379151, acc.: 86.72%] [G loss: 1.437590]\n",
      "epoch:26 step:24464 [D loss: 0.558672, acc.: 74.22%] [G loss: 1.468289]\n",
      "epoch:26 step:24465 [D loss: 0.535235, acc.: 69.53%] [G loss: 1.208145]\n",
      "epoch:26 step:24466 [D loss: 0.678552, acc.: 65.62%] [G loss: 1.022699]\n",
      "epoch:26 step:24467 [D loss: 0.705259, acc.: 55.47%] [G loss: 1.349448]\n",
      "epoch:26 step:24468 [D loss: 0.649676, acc.: 67.97%] [G loss: 1.717487]\n",
      "epoch:26 step:24469 [D loss: 0.403589, acc.: 79.69%] [G loss: 1.346477]\n",
      "epoch:26 step:24470 [D loss: 0.465240, acc.: 76.56%] [G loss: 1.408675]\n",
      "epoch:26 step:24471 [D loss: 0.658473, acc.: 60.94%] [G loss: 1.130040]\n",
      "epoch:26 step:24472 [D loss: 0.554244, acc.: 68.75%] [G loss: 1.082134]\n",
      "epoch:26 step:24473 [D loss: 0.566320, acc.: 71.09%] [G loss: 1.287049]\n",
      "epoch:26 step:24474 [D loss: 0.323968, acc.: 90.62%] [G loss: 1.389442]\n",
      "epoch:26 step:24475 [D loss: 0.302039, acc.: 89.06%] [G loss: 1.421150]\n",
      "epoch:26 step:24476 [D loss: 0.237575, acc.: 92.19%] [G loss: 2.213786]\n",
      "epoch:26 step:24477 [D loss: 0.190417, acc.: 96.88%] [G loss: 1.131692]\n",
      "epoch:26 step:24478 [D loss: 0.588142, acc.: 67.97%] [G loss: 1.541979]\n",
      "epoch:26 step:24479 [D loss: 0.923115, acc.: 46.88%] [G loss: 0.933281]\n",
      "epoch:26 step:24480 [D loss: 0.956590, acc.: 50.00%] [G loss: 1.261149]\n",
      "epoch:26 step:24481 [D loss: 0.551170, acc.: 71.88%] [G loss: 1.131258]\n",
      "epoch:26 step:24482 [D loss: 0.252999, acc.: 89.84%] [G loss: 1.207626]\n",
      "epoch:26 step:24483 [D loss: 0.212767, acc.: 93.75%] [G loss: 1.582752]\n",
      "epoch:26 step:24484 [D loss: 0.180297, acc.: 96.88%] [G loss: 1.035765]\n",
      "epoch:26 step:24485 [D loss: 0.540734, acc.: 71.88%] [G loss: 1.903457]\n",
      "epoch:26 step:24486 [D loss: 0.724974, acc.: 56.25%] [G loss: 1.809418]\n",
      "epoch:26 step:24487 [D loss: 0.720807, acc.: 57.03%] [G loss: 1.489470]\n",
      "epoch:26 step:24488 [D loss: 0.670780, acc.: 63.28%] [G loss: 1.302198]\n",
      "epoch:26 step:24489 [D loss: 0.630425, acc.: 60.94%] [G loss: 1.722967]\n",
      "epoch:26 step:24490 [D loss: 0.392126, acc.: 82.81%] [G loss: 1.240008]\n",
      "epoch:26 step:24491 [D loss: 0.284215, acc.: 92.19%] [G loss: 1.116009]\n",
      "epoch:26 step:24492 [D loss: 0.152743, acc.: 99.22%] [G loss: 2.340794]\n",
      "epoch:26 step:24493 [D loss: 0.281412, acc.: 89.06%] [G loss: 2.104566]\n",
      "epoch:26 step:24494 [D loss: 0.175489, acc.: 96.88%] [G loss: 2.173421]\n",
      "epoch:26 step:24495 [D loss: 0.805401, acc.: 61.72%] [G loss: 2.098060]\n",
      "epoch:26 step:24496 [D loss: 0.743282, acc.: 60.16%] [G loss: 1.505824]\n",
      "epoch:26 step:24497 [D loss: 0.653521, acc.: 64.06%] [G loss: 1.025798]\n",
      "epoch:26 step:24498 [D loss: 0.857775, acc.: 50.00%] [G loss: 1.680586]\n",
      "epoch:26 step:24499 [D loss: 0.517753, acc.: 74.22%] [G loss: 1.188794]\n",
      "epoch:26 step:24500 [D loss: 0.462537, acc.: 80.47%] [G loss: 1.163163]\n",
      "epoch:26 step:24501 [D loss: 0.370571, acc.: 82.81%] [G loss: 0.872446]\n",
      "epoch:26 step:24502 [D loss: 0.743444, acc.: 59.38%] [G loss: 1.518224]\n",
      "epoch:26 step:24503 [D loss: 0.547435, acc.: 74.22%] [G loss: 1.563685]\n",
      "epoch:26 step:24504 [D loss: 0.602908, acc.: 64.84%] [G loss: 1.484344]\n",
      "epoch:26 step:24505 [D loss: 0.283133, acc.: 90.62%] [G loss: 1.610395]\n",
      "epoch:26 step:24506 [D loss: 0.521007, acc.: 73.44%] [G loss: 1.472133]\n",
      "epoch:26 step:24507 [D loss: 0.238937, acc.: 93.75%] [G loss: 1.604150]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:26 step:24508 [D loss: 0.630318, acc.: 64.84%] [G loss: 1.673129]\n",
      "epoch:26 step:24509 [D loss: 0.592577, acc.: 71.09%] [G loss: 1.102013]\n",
      "epoch:26 step:24510 [D loss: 0.663515, acc.: 59.38%] [G loss: 1.237935]\n",
      "epoch:26 step:24511 [D loss: 0.314936, acc.: 85.16%] [G loss: 0.955359]\n",
      "epoch:26 step:24512 [D loss: 0.176764, acc.: 95.31%] [G loss: 1.591552]\n",
      "epoch:26 step:24513 [D loss: 0.265227, acc.: 94.53%] [G loss: 1.496885]\n",
      "epoch:26 step:24514 [D loss: 0.312497, acc.: 94.53%] [G loss: 1.468225]\n",
      "epoch:26 step:24515 [D loss: 0.784254, acc.: 57.81%] [G loss: 1.306862]\n",
      "epoch:26 step:24516 [D loss: 0.599635, acc.: 66.41%] [G loss: 1.115043]\n",
      "epoch:26 step:24517 [D loss: 0.718637, acc.: 56.25%] [G loss: 1.387922]\n",
      "epoch:26 step:24518 [D loss: 0.675500, acc.: 61.72%] [G loss: 0.562741]\n",
      "epoch:26 step:24519 [D loss: 0.675235, acc.: 57.81%] [G loss: 1.013839]\n",
      "epoch:26 step:24520 [D loss: 0.788221, acc.: 50.00%] [G loss: 0.961114]\n",
      "epoch:26 step:24521 [D loss: 0.973100, acc.: 48.44%] [G loss: 1.076169]\n",
      "epoch:26 step:24522 [D loss: 0.755043, acc.: 49.22%] [G loss: 1.299373]\n",
      "epoch:26 step:24523 [D loss: 0.656959, acc.: 60.16%] [G loss: 1.204640]\n",
      "epoch:26 step:24524 [D loss: 0.612649, acc.: 64.06%] [G loss: 1.186723]\n",
      "epoch:26 step:24525 [D loss: 0.459214, acc.: 84.38%] [G loss: 1.007204]\n",
      "epoch:26 step:24526 [D loss: 0.600615, acc.: 71.09%] [G loss: 1.349658]\n",
      "epoch:26 step:24527 [D loss: 0.483697, acc.: 79.69%] [G loss: 1.174616]\n",
      "epoch:26 step:24528 [D loss: 0.672289, acc.: 60.94%] [G loss: 0.935162]\n",
      "epoch:26 step:24529 [D loss: 0.620106, acc.: 67.97%] [G loss: 1.113952]\n",
      "epoch:26 step:24530 [D loss: 0.774551, acc.: 54.69%] [G loss: 0.903988]\n",
      "epoch:26 step:24531 [D loss: 0.712011, acc.: 59.38%] [G loss: 1.113416]\n",
      "epoch:26 step:24532 [D loss: 0.614371, acc.: 64.06%] [G loss: 0.913502]\n",
      "epoch:26 step:24533 [D loss: 0.529880, acc.: 76.56%] [G loss: 1.393053]\n",
      "epoch:26 step:24534 [D loss: 0.643303, acc.: 65.62%] [G loss: 0.885447]\n",
      "epoch:26 step:24535 [D loss: 0.590893, acc.: 72.66%] [G loss: 0.911255]\n",
      "epoch:26 step:24536 [D loss: 0.712151, acc.: 61.72%] [G loss: 0.847169]\n",
      "epoch:26 step:24537 [D loss: 0.824308, acc.: 46.88%] [G loss: 1.244134]\n",
      "epoch:26 step:24538 [D loss: 0.536210, acc.: 76.56%] [G loss: 1.158704]\n",
      "epoch:26 step:24539 [D loss: 0.731652, acc.: 51.56%] [G loss: 1.400387]\n",
      "epoch:26 step:24540 [D loss: 0.598867, acc.: 62.50%] [G loss: 1.327446]\n",
      "epoch:26 step:24541 [D loss: 0.481421, acc.: 81.25%] [G loss: 1.249285]\n",
      "epoch:26 step:24542 [D loss: 0.623255, acc.: 60.16%] [G loss: 1.186333]\n",
      "epoch:26 step:24543 [D loss: 0.531202, acc.: 75.00%] [G loss: 1.017068]\n",
      "epoch:26 step:24544 [D loss: 0.640715, acc.: 67.97%] [G loss: 1.165633]\n",
      "epoch:26 step:24545 [D loss: 0.576010, acc.: 67.97%] [G loss: 1.217483]\n",
      "epoch:26 step:24546 [D loss: 0.487860, acc.: 78.91%] [G loss: 1.175353]\n",
      "epoch:26 step:24547 [D loss: 0.551206, acc.: 67.19%] [G loss: 1.329614]\n",
      "epoch:26 step:24548 [D loss: 0.580764, acc.: 72.66%] [G loss: 1.102122]\n",
      "epoch:26 step:24549 [D loss: 0.682178, acc.: 57.81%] [G loss: 1.302947]\n",
      "epoch:26 step:24550 [D loss: 0.586882, acc.: 65.62%] [G loss: 1.294736]\n",
      "epoch:26 step:24551 [D loss: 0.650384, acc.: 64.06%] [G loss: 1.312113]\n",
      "epoch:26 step:24552 [D loss: 0.593763, acc.: 67.97%] [G loss: 1.398626]\n",
      "epoch:26 step:24553 [D loss: 0.620881, acc.: 66.41%] [G loss: 1.094853]\n",
      "epoch:26 step:24554 [D loss: 0.400144, acc.: 80.47%] [G loss: 1.253924]\n",
      "epoch:26 step:24555 [D loss: 0.408938, acc.: 84.38%] [G loss: 1.753960]\n",
      "epoch:26 step:24556 [D loss: 0.282859, acc.: 90.62%] [G loss: 1.420403]\n",
      "epoch:26 step:24557 [D loss: 0.413659, acc.: 85.16%] [G loss: 1.341985]\n",
      "epoch:26 step:24558 [D loss: 0.501455, acc.: 77.34%] [G loss: 1.229916]\n",
      "epoch:26 step:24559 [D loss: 0.367145, acc.: 92.19%] [G loss: 1.565020]\n",
      "epoch:26 step:24560 [D loss: 0.367449, acc.: 89.84%] [G loss: 1.284498]\n",
      "epoch:26 step:24561 [D loss: 0.624269, acc.: 63.28%] [G loss: 1.496496]\n",
      "epoch:26 step:24562 [D loss: 0.195281, acc.: 99.22%] [G loss: 0.867542]\n",
      "epoch:26 step:24563 [D loss: 0.216015, acc.: 94.53%] [G loss: 1.111016]\n",
      "epoch:26 step:24564 [D loss: 0.773688, acc.: 46.09%] [G loss: 1.451494]\n",
      "epoch:26 step:24565 [D loss: 0.216157, acc.: 96.88%] [G loss: 1.438113]\n",
      "epoch:26 step:24566 [D loss: 0.184548, acc.: 96.09%] [G loss: 2.616693]\n",
      "epoch:26 step:24567 [D loss: 0.434353, acc.: 85.16%] [G loss: 1.635036]\n",
      "epoch:26 step:24568 [D loss: 0.224194, acc.: 93.75%] [G loss: 1.639123]\n",
      "epoch:26 step:24569 [D loss: 0.194030, acc.: 94.53%] [G loss: 1.916665]\n",
      "epoch:26 step:24570 [D loss: 0.224177, acc.: 95.31%] [G loss: 1.716997]\n",
      "epoch:26 step:24571 [D loss: 0.219610, acc.: 95.31%] [G loss: 1.663920]\n",
      "epoch:26 step:24572 [D loss: 1.325246, acc.: 48.44%] [G loss: 1.556634]\n",
      "epoch:26 step:24573 [D loss: 1.005010, acc.: 46.88%] [G loss: 1.937148]\n",
      "epoch:26 step:24574 [D loss: 1.052961, acc.: 28.12%] [G loss: 0.930254]\n",
      "epoch:26 step:24575 [D loss: 0.853155, acc.: 42.19%] [G loss: 1.257309]\n",
      "epoch:26 step:24576 [D loss: 0.980258, acc.: 34.38%] [G loss: 1.422527]\n",
      "epoch:26 step:24577 [D loss: 0.798347, acc.: 54.69%] [G loss: 1.405292]\n",
      "epoch:26 step:24578 [D loss: 0.650600, acc.: 66.41%] [G loss: 1.037857]\n",
      "epoch:26 step:24579 [D loss: 0.499321, acc.: 78.91%] [G loss: 1.081348]\n",
      "epoch:26 step:24580 [D loss: 0.343485, acc.: 86.72%] [G loss: 1.266950]\n",
      "epoch:26 step:24581 [D loss: 0.335620, acc.: 83.59%] [G loss: 1.258439]\n",
      "epoch:26 step:24582 [D loss: 0.299493, acc.: 82.03%] [G loss: 1.523949]\n",
      "epoch:26 step:24583 [D loss: 0.172802, acc.: 97.66%] [G loss: 1.510788]\n",
      "epoch:26 step:24584 [D loss: 0.304109, acc.: 95.31%] [G loss: 1.961500]\n",
      "epoch:26 step:24585 [D loss: 0.272017, acc.: 100.00%] [G loss: 1.682094]\n",
      "epoch:26 step:24586 [D loss: 0.642289, acc.: 64.84%] [G loss: 1.305142]\n",
      "epoch:26 step:24587 [D loss: 0.431333, acc.: 82.81%] [G loss: 1.419359]\n",
      "epoch:26 step:24588 [D loss: 0.693919, acc.: 53.91%] [G loss: 1.110669]\n",
      "epoch:26 step:24589 [D loss: 0.510332, acc.: 74.22%] [G loss: 1.348073]\n",
      "epoch:26 step:24590 [D loss: 0.613839, acc.: 64.84%] [G loss: 1.103150]\n",
      "epoch:26 step:24591 [D loss: 0.654387, acc.: 59.38%] [G loss: 1.159387]\n",
      "epoch:26 step:24592 [D loss: 0.177153, acc.: 95.31%] [G loss: 1.339430]\n",
      "epoch:26 step:24593 [D loss: 0.194152, acc.: 95.31%] [G loss: 1.557872]\n",
      "epoch:26 step:24594 [D loss: 0.228239, acc.: 93.75%] [G loss: 1.739212]\n",
      "epoch:26 step:24595 [D loss: 0.530177, acc.: 69.53%] [G loss: 1.618849]\n",
      "epoch:26 step:24596 [D loss: 0.619012, acc.: 66.41%] [G loss: 1.414725]\n",
      "epoch:26 step:24597 [D loss: 0.246912, acc.: 98.44%] [G loss: 1.260507]\n",
      "epoch:26 step:24598 [D loss: 0.593465, acc.: 63.28%] [G loss: 1.480962]\n",
      "epoch:26 step:24599 [D loss: 0.444978, acc.: 79.69%] [G loss: 1.386276]\n",
      "epoch:26 step:24600 [D loss: 0.383082, acc.: 89.06%] [G loss: 0.922308]\n",
      "##############\n",
      "[3.94064518 2.61484343 6.73605423 5.5389684  4.5082787  6.47957897\n",
      " 5.4449529  5.49684292 5.65380367 5.17508671]\n",
      "##########\n",
      "epoch:26 step:24601 [D loss: 0.624130, acc.: 63.28%] [G loss: 1.167877]\n",
      "epoch:26 step:24602 [D loss: 0.511049, acc.: 72.66%] [G loss: 1.245841]\n",
      "epoch:26 step:24603 [D loss: 0.849057, acc.: 47.66%] [G loss: 1.056190]\n",
      "epoch:26 step:24604 [D loss: 0.571826, acc.: 75.78%] [G loss: 0.834991]\n",
      "epoch:26 step:24605 [D loss: 0.417841, acc.: 85.16%] [G loss: 1.126553]\n",
      "epoch:26 step:24606 [D loss: 0.708707, acc.: 53.12%] [G loss: 0.968959]\n",
      "epoch:26 step:24607 [D loss: 0.634600, acc.: 64.84%] [G loss: 0.961552]\n",
      "epoch:26 step:24608 [D loss: 0.652418, acc.: 59.38%] [G loss: 1.354919]\n",
      "epoch:26 step:24609 [D loss: 0.506508, acc.: 76.56%] [G loss: 1.194512]\n",
      "epoch:26 step:24610 [D loss: 0.461639, acc.: 82.03%] [G loss: 1.043528]\n",
      "epoch:26 step:24611 [D loss: 0.613012, acc.: 66.41%] [G loss: 1.201251]\n",
      "epoch:26 step:24612 [D loss: 0.866891, acc.: 40.62%] [G loss: 0.801731]\n",
      "epoch:26 step:24613 [D loss: 0.521735, acc.: 74.22%] [G loss: 1.165978]\n",
      "epoch:26 step:24614 [D loss: 0.662958, acc.: 61.72%] [G loss: 1.238574]\n",
      "epoch:26 step:24615 [D loss: 0.629431, acc.: 67.97%] [G loss: 0.705689]\n",
      "epoch:26 step:24616 [D loss: 0.609979, acc.: 63.28%] [G loss: 1.403771]\n",
      "epoch:26 step:24617 [D loss: 0.479602, acc.: 75.78%] [G loss: 1.622465]\n",
      "epoch:26 step:24618 [D loss: 0.341170, acc.: 81.25%] [G loss: 1.563025]\n",
      "epoch:26 step:24619 [D loss: 0.509896, acc.: 74.22%] [G loss: 1.246809]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:26 step:24620 [D loss: 0.612529, acc.: 67.19%] [G loss: 1.672061]\n",
      "epoch:26 step:24621 [D loss: 0.204232, acc.: 92.97%] [G loss: 1.280826]\n",
      "epoch:26 step:24622 [D loss: 0.248781, acc.: 93.75%] [G loss: 1.706150]\n",
      "epoch:26 step:24623 [D loss: 0.151305, acc.: 99.22%] [G loss: 2.004498]\n",
      "epoch:26 step:24624 [D loss: 0.668665, acc.: 64.06%] [G loss: 1.225823]\n",
      "epoch:26 step:24625 [D loss: 0.562007, acc.: 70.31%] [G loss: 1.931984]\n",
      "epoch:26 step:24626 [D loss: 0.430698, acc.: 85.16%] [G loss: 1.361058]\n",
      "epoch:26 step:24627 [D loss: 0.490466, acc.: 78.12%] [G loss: 1.100150]\n",
      "epoch:26 step:24628 [D loss: 0.704082, acc.: 56.25%] [G loss: 1.187220]\n",
      "epoch:26 step:24629 [D loss: 0.544367, acc.: 69.53%] [G loss: 1.031539]\n",
      "epoch:26 step:24630 [D loss: 0.747167, acc.: 54.69%] [G loss: 1.120337]\n",
      "epoch:26 step:24631 [D loss: 0.299169, acc.: 92.19%] [G loss: 1.057237]\n",
      "epoch:26 step:24632 [D loss: 0.463990, acc.: 85.16%] [G loss: 1.519439]\n",
      "epoch:26 step:24633 [D loss: 0.432230, acc.: 83.59%] [G loss: 1.235717]\n",
      "epoch:26 step:24634 [D loss: 0.477043, acc.: 79.69%] [G loss: 1.629305]\n",
      "epoch:26 step:24635 [D loss: 0.545868, acc.: 76.56%] [G loss: 1.404026]\n",
      "epoch:26 step:24636 [D loss: 0.393999, acc.: 86.72%] [G loss: 1.071195]\n",
      "epoch:26 step:24637 [D loss: 0.425526, acc.: 86.72%] [G loss: 1.555415]\n",
      "epoch:26 step:24638 [D loss: 0.340911, acc.: 92.19%] [G loss: 1.304418]\n",
      "epoch:26 step:24639 [D loss: 0.431627, acc.: 82.03%] [G loss: 1.659920]\n",
      "epoch:26 step:24640 [D loss: 0.319616, acc.: 89.84%] [G loss: 2.175768]\n",
      "epoch:26 step:24641 [D loss: 0.195146, acc.: 95.31%] [G loss: 1.510233]\n",
      "epoch:26 step:24642 [D loss: 0.661796, acc.: 60.94%] [G loss: 1.586575]\n",
      "epoch:26 step:24643 [D loss: 0.674058, acc.: 57.81%] [G loss: 1.265190]\n",
      "epoch:26 step:24644 [D loss: 0.479464, acc.: 78.12%] [G loss: 1.282538]\n",
      "epoch:26 step:24645 [D loss: 0.608908, acc.: 61.72%] [G loss: 1.113903]\n",
      "epoch:26 step:24646 [D loss: 0.425254, acc.: 82.03%] [G loss: 1.537176]\n",
      "epoch:26 step:24647 [D loss: 0.422694, acc.: 83.59%] [G loss: 1.637042]\n",
      "epoch:26 step:24648 [D loss: 0.473561, acc.: 79.69%] [G loss: 1.215438]\n",
      "epoch:26 step:24649 [D loss: 0.305060, acc.: 82.81%] [G loss: 1.781980]\n",
      "epoch:26 step:24650 [D loss: 0.249154, acc.: 96.09%] [G loss: 1.773104]\n",
      "epoch:26 step:24651 [D loss: 0.138132, acc.: 98.44%] [G loss: 1.525530]\n",
      "epoch:26 step:24652 [D loss: 0.231688, acc.: 89.84%] [G loss: 1.501456]\n",
      "epoch:26 step:24653 [D loss: 0.568028, acc.: 70.31%] [G loss: 0.989219]\n",
      "epoch:26 step:24654 [D loss: 0.266434, acc.: 95.31%] [G loss: 1.534836]\n",
      "epoch:26 step:24655 [D loss: 0.278124, acc.: 85.94%] [G loss: 1.687348]\n",
      "epoch:26 step:24656 [D loss: 1.083436, acc.: 38.28%] [G loss: 1.352159]\n",
      "epoch:26 step:24657 [D loss: 0.672285, acc.: 62.50%] [G loss: 1.181643]\n",
      "epoch:26 step:24658 [D loss: 0.563479, acc.: 69.53%] [G loss: 1.262700]\n",
      "epoch:26 step:24659 [D loss: 0.285197, acc.: 94.53%] [G loss: 1.356597]\n",
      "epoch:26 step:24660 [D loss: 0.281587, acc.: 89.84%] [G loss: 1.326005]\n",
      "epoch:26 step:24661 [D loss: 0.288031, acc.: 86.72%] [G loss: 2.129517]\n",
      "epoch:26 step:24662 [D loss: 0.347066, acc.: 87.50%] [G loss: 2.106646]\n",
      "epoch:26 step:24663 [D loss: 0.724116, acc.: 54.69%] [G loss: 1.235908]\n",
      "epoch:26 step:24664 [D loss: 0.827774, acc.: 52.34%] [G loss: 1.332635]\n",
      "epoch:26 step:24665 [D loss: 0.684774, acc.: 63.28%] [G loss: 1.178919]\n",
      "epoch:26 step:24666 [D loss: 0.854984, acc.: 49.22%] [G loss: 1.666390]\n",
      "epoch:26 step:24667 [D loss: 0.833899, acc.: 50.78%] [G loss: 1.173434]\n",
      "epoch:26 step:24668 [D loss: 0.585933, acc.: 69.53%] [G loss: 1.754757]\n",
      "epoch:26 step:24669 [D loss: 0.428156, acc.: 77.34%] [G loss: 1.050539]\n",
      "epoch:26 step:24670 [D loss: 0.657872, acc.: 64.84%] [G loss: 1.364176]\n",
      "epoch:26 step:24671 [D loss: 0.211324, acc.: 94.53%] [G loss: 1.134824]\n",
      "epoch:26 step:24672 [D loss: 0.910541, acc.: 42.19%] [G loss: 0.962718]\n",
      "epoch:26 step:24673 [D loss: 0.756524, acc.: 60.16%] [G loss: 1.003742]\n",
      "epoch:26 step:24674 [D loss: 0.376848, acc.: 75.78%] [G loss: 1.592144]\n",
      "epoch:26 step:24675 [D loss: 0.202074, acc.: 91.41%] [G loss: 1.891076]\n",
      "epoch:26 step:24676 [D loss: 0.257802, acc.: 85.94%] [G loss: 2.223120]\n",
      "epoch:26 step:24677 [D loss: 0.180802, acc.: 97.66%] [G loss: 2.206015]\n",
      "epoch:26 step:24678 [D loss: 0.658203, acc.: 63.28%] [G loss: 1.632053]\n",
      "epoch:26 step:24679 [D loss: 0.961706, acc.: 48.44%] [G loss: 1.623785]\n",
      "epoch:26 step:24680 [D loss: 0.542844, acc.: 72.66%] [G loss: 1.578416]\n",
      "epoch:26 step:24681 [D loss: 0.680246, acc.: 63.28%] [G loss: 0.655764]\n",
      "epoch:26 step:24682 [D loss: 0.571959, acc.: 70.31%] [G loss: 1.206149]\n",
      "epoch:26 step:24683 [D loss: 0.522287, acc.: 77.34%] [G loss: 1.839716]\n",
      "epoch:26 step:24684 [D loss: 0.592280, acc.: 62.50%] [G loss: 1.562569]\n",
      "epoch:26 step:24685 [D loss: 0.852422, acc.: 46.88%] [G loss: 1.183458]\n",
      "epoch:26 step:24686 [D loss: 0.999853, acc.: 38.28%] [G loss: 1.338039]\n",
      "epoch:26 step:24687 [D loss: 0.658386, acc.: 61.72%] [G loss: 1.158985]\n",
      "epoch:26 step:24688 [D loss: 0.566159, acc.: 74.22%] [G loss: 0.720685]\n",
      "epoch:26 step:24689 [D loss: 0.323702, acc.: 89.84%] [G loss: 0.739040]\n",
      "epoch:26 step:24690 [D loss: 0.574938, acc.: 64.06%] [G loss: 1.599565]\n",
      "epoch:26 step:24691 [D loss: 0.699170, acc.: 53.12%] [G loss: 1.278016]\n",
      "epoch:26 step:24692 [D loss: 0.694601, acc.: 57.81%] [G loss: 1.194148]\n",
      "epoch:26 step:24693 [D loss: 0.463485, acc.: 80.47%] [G loss: 1.203066]\n",
      "epoch:26 step:24694 [D loss: 0.381070, acc.: 88.28%] [G loss: 1.241497]\n",
      "epoch:26 step:24695 [D loss: 0.345692, acc.: 82.81%] [G loss: 1.485625]\n",
      "epoch:26 step:24696 [D loss: 0.154015, acc.: 99.22%] [G loss: 1.763478]\n",
      "epoch:26 step:24697 [D loss: 0.325617, acc.: 92.97%] [G loss: 1.625651]\n",
      "epoch:26 step:24698 [D loss: 0.242080, acc.: 89.84%] [G loss: 1.675637]\n",
      "epoch:26 step:24699 [D loss: 0.357741, acc.: 89.84%] [G loss: 1.777366]\n",
      "epoch:26 step:24700 [D loss: 0.396100, acc.: 84.38%] [G loss: 1.901892]\n",
      "epoch:26 step:24701 [D loss: 0.505547, acc.: 78.12%] [G loss: 1.356615]\n",
      "epoch:26 step:24702 [D loss: 0.656738, acc.: 57.81%] [G loss: 1.478833]\n",
      "epoch:26 step:24703 [D loss: 0.551161, acc.: 71.09%] [G loss: 1.075401]\n",
      "epoch:26 step:24704 [D loss: 0.217954, acc.: 92.19%] [G loss: 1.670622]\n",
      "epoch:26 step:24705 [D loss: 0.251017, acc.: 87.50%] [G loss: 2.094468]\n",
      "epoch:26 step:24706 [D loss: 0.124442, acc.: 98.44%] [G loss: 1.802221]\n",
      "epoch:26 step:24707 [D loss: 0.138858, acc.: 98.44%] [G loss: 1.861472]\n",
      "epoch:26 step:24708 [D loss: 0.116736, acc.: 99.22%] [G loss: 2.262036]\n",
      "epoch:26 step:24709 [D loss: 0.088298, acc.: 100.00%] [G loss: 2.587895]\n",
      "epoch:26 step:24710 [D loss: 0.649109, acc.: 64.06%] [G loss: 2.118824]\n",
      "epoch:26 step:24711 [D loss: 0.971278, acc.: 51.56%] [G loss: 1.719824]\n",
      "epoch:26 step:24712 [D loss: 0.226857, acc.: 97.66%] [G loss: 1.407525]\n",
      "epoch:26 step:24713 [D loss: 0.896419, acc.: 44.53%] [G loss: 1.030250]\n",
      "epoch:26 step:24714 [D loss: 0.727644, acc.: 57.03%] [G loss: 1.292351]\n",
      "epoch:26 step:24715 [D loss: 0.742723, acc.: 60.16%] [G loss: 0.996818]\n",
      "epoch:26 step:24716 [D loss: 0.517568, acc.: 72.66%] [G loss: 0.891483]\n",
      "epoch:26 step:24717 [D loss: 0.770515, acc.: 51.56%] [G loss: 1.289163]\n",
      "epoch:26 step:24718 [D loss: 0.518449, acc.: 78.12%] [G loss: 1.254361]\n",
      "epoch:26 step:24719 [D loss: 0.666672, acc.: 62.50%] [G loss: 0.664415]\n",
      "epoch:26 step:24720 [D loss: 0.369333, acc.: 87.50%] [G loss: 0.695853]\n",
      "epoch:26 step:24721 [D loss: 0.459580, acc.: 82.81%] [G loss: 1.332150]\n",
      "epoch:26 step:24722 [D loss: 0.480754, acc.: 75.78%] [G loss: 1.063768]\n",
      "epoch:26 step:24723 [D loss: 0.703326, acc.: 61.72%] [G loss: 0.933029]\n",
      "epoch:26 step:24724 [D loss: 0.319837, acc.: 89.06%] [G loss: 1.264624]\n",
      "epoch:26 step:24725 [D loss: 0.673648, acc.: 60.16%] [G loss: 1.548403]\n",
      "epoch:26 step:24726 [D loss: 0.373953, acc.: 89.06%] [G loss: 1.583323]\n",
      "epoch:26 step:24727 [D loss: 0.193515, acc.: 93.75%] [G loss: 1.550532]\n",
      "epoch:26 step:24728 [D loss: 0.213067, acc.: 92.97%] [G loss: 1.821737]\n",
      "epoch:26 step:24729 [D loss: 0.123890, acc.: 100.00%] [G loss: 1.518835]\n",
      "epoch:26 step:24730 [D loss: 0.691750, acc.: 60.16%] [G loss: 1.112320]\n",
      "epoch:26 step:24731 [D loss: 0.797161, acc.: 53.12%] [G loss: 1.707590]\n",
      "epoch:26 step:24732 [D loss: 0.674033, acc.: 68.75%] [G loss: 1.632005]\n",
      "epoch:26 step:24733 [D loss: 0.517025, acc.: 77.34%] [G loss: 1.811789]\n",
      "epoch:26 step:24734 [D loss: 0.664618, acc.: 60.16%] [G loss: 1.901354]\n",
      "epoch:26 step:24735 [D loss: 0.511654, acc.: 75.00%] [G loss: 1.612529]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:26 step:24736 [D loss: 0.807561, acc.: 50.78%] [G loss: 1.191996]\n",
      "epoch:26 step:24737 [D loss: 0.760230, acc.: 53.91%] [G loss: 1.200298]\n",
      "epoch:26 step:24738 [D loss: 0.617770, acc.: 63.28%] [G loss: 0.521334]\n",
      "epoch:26 step:24739 [D loss: 0.225878, acc.: 92.19%] [G loss: 1.353113]\n",
      "epoch:26 step:24740 [D loss: 0.164769, acc.: 98.44%] [G loss: 1.257852]\n",
      "epoch:26 step:24741 [D loss: 0.729979, acc.: 56.25%] [G loss: 1.504589]\n",
      "epoch:26 step:24742 [D loss: 0.377804, acc.: 91.41%] [G loss: 1.432058]\n",
      "epoch:26 step:24743 [D loss: 0.289783, acc.: 96.09%] [G loss: 1.557778]\n",
      "epoch:26 step:24744 [D loss: 0.679348, acc.: 57.03%] [G loss: 1.216137]\n",
      "epoch:26 step:24745 [D loss: 0.682058, acc.: 60.94%] [G loss: 1.412994]\n",
      "epoch:26 step:24746 [D loss: 0.517867, acc.: 74.22%] [G loss: 1.153645]\n",
      "epoch:26 step:24747 [D loss: 0.578725, acc.: 67.19%] [G loss: 1.172254]\n",
      "epoch:26 step:24748 [D loss: 0.621074, acc.: 65.62%] [G loss: 1.405167]\n",
      "epoch:26 step:24749 [D loss: 0.979778, acc.: 39.84%] [G loss: 1.166904]\n",
      "epoch:26 step:24750 [D loss: 0.431248, acc.: 85.16%] [G loss: 1.207104]\n",
      "epoch:26 step:24751 [D loss: 0.390731, acc.: 85.16%] [G loss: 1.025204]\n",
      "epoch:26 step:24752 [D loss: 0.391994, acc.: 83.59%] [G loss: 1.397723]\n",
      "epoch:26 step:24753 [D loss: 0.687704, acc.: 57.81%] [G loss: 1.289302]\n",
      "epoch:26 step:24754 [D loss: 0.690009, acc.: 61.72%] [G loss: 1.292280]\n",
      "epoch:26 step:24755 [D loss: 0.319870, acc.: 90.62%] [G loss: 1.193458]\n",
      "epoch:26 step:24756 [D loss: 0.491829, acc.: 78.12%] [G loss: 1.286746]\n",
      "epoch:26 step:24757 [D loss: 0.825862, acc.: 44.53%] [G loss: 1.389367]\n",
      "epoch:26 step:24758 [D loss: 0.170446, acc.: 96.09%] [G loss: 1.366938]\n",
      "epoch:26 step:24759 [D loss: 0.446344, acc.: 75.00%] [G loss: 1.542373]\n",
      "epoch:26 step:24760 [D loss: 0.096460, acc.: 100.00%] [G loss: 1.886493]\n",
      "epoch:26 step:24761 [D loss: 0.139432, acc.: 99.22%] [G loss: 1.691298]\n",
      "epoch:26 step:24762 [D loss: 0.203993, acc.: 96.09%] [G loss: 2.270178]\n",
      "epoch:26 step:24763 [D loss: 0.165222, acc.: 100.00%] [G loss: 2.031997]\n",
      "epoch:26 step:24764 [D loss: 0.085704, acc.: 100.00%] [G loss: 2.348288]\n",
      "epoch:26 step:24765 [D loss: 0.121982, acc.: 99.22%] [G loss: 2.288150]\n",
      "epoch:26 step:24766 [D loss: 0.451334, acc.: 77.34%] [G loss: 2.114446]\n",
      "epoch:26 step:24767 [D loss: 0.102759, acc.: 100.00%] [G loss: 2.615616]\n",
      "epoch:26 step:24768 [D loss: 0.060693, acc.: 100.00%] [G loss: 2.255037]\n",
      "epoch:26 step:24769 [D loss: 0.048409, acc.: 100.00%] [G loss: 2.828361]\n",
      "epoch:26 step:24770 [D loss: 0.091673, acc.: 100.00%] [G loss: 2.845750]\n",
      "epoch:26 step:24771 [D loss: 0.060574, acc.: 100.00%] [G loss: 2.633847]\n",
      "epoch:26 step:24772 [D loss: 0.161127, acc.: 97.66%] [G loss: 2.536184]\n",
      "epoch:26 step:24773 [D loss: 0.847573, acc.: 53.91%] [G loss: 2.039470]\n",
      "epoch:26 step:24774 [D loss: 0.085177, acc.: 100.00%] [G loss: 2.056586]\n",
      "epoch:26 step:24775 [D loss: 0.092849, acc.: 99.22%] [G loss: 2.524166]\n",
      "epoch:26 step:24776 [D loss: 0.114833, acc.: 98.44%] [G loss: 1.738649]\n",
      "epoch:26 step:24777 [D loss: 0.077823, acc.: 99.22%] [G loss: 2.424045]\n",
      "epoch:26 step:24778 [D loss: 0.340351, acc.: 80.47%] [G loss: 1.920708]\n",
      "epoch:26 step:24779 [D loss: 0.056105, acc.: 100.00%] [G loss: 2.069552]\n",
      "epoch:26 step:24780 [D loss: 0.066904, acc.: 100.00%] [G loss: 2.661847]\n",
      "epoch:26 step:24781 [D loss: 0.054247, acc.: 100.00%] [G loss: 2.978373]\n",
      "epoch:26 step:24782 [D loss: 0.066751, acc.: 100.00%] [G loss: 2.694702]\n",
      "epoch:26 step:24783 [D loss: 0.569487, acc.: 67.19%] [G loss: 1.758379]\n",
      "epoch:26 step:24784 [D loss: 0.663097, acc.: 62.50%] [G loss: 0.350754]\n",
      "epoch:26 step:24785 [D loss: 0.112893, acc.: 98.44%] [G loss: 0.628063]\n",
      "epoch:26 step:24786 [D loss: 0.337200, acc.: 82.03%] [G loss: 2.087200]\n",
      "epoch:26 step:24787 [D loss: 0.152817, acc.: 98.44%] [G loss: 1.441664]\n",
      "epoch:26 step:24788 [D loss: 1.146490, acc.: 20.31%] [G loss: 0.675488]\n",
      "epoch:26 step:24789 [D loss: 0.050341, acc.: 100.00%] [G loss: 2.909372]\n",
      "epoch:26 step:24790 [D loss: 1.617190, acc.: 50.78%] [G loss: 1.626083]\n",
      "epoch:26 step:24791 [D loss: 0.123741, acc.: 96.88%] [G loss: 3.385037]\n",
      "epoch:26 step:24792 [D loss: 0.244230, acc.: 90.62%] [G loss: 0.654676]\n",
      "epoch:26 step:24793 [D loss: 1.064357, acc.: 46.88%] [G loss: 0.934505]\n",
      "epoch:26 step:24794 [D loss: 1.821712, acc.: 35.16%] [G loss: 1.116204]\n",
      "epoch:26 step:24795 [D loss: 1.237712, acc.: 48.44%] [G loss: 0.782648]\n",
      "epoch:26 step:24796 [D loss: 1.415689, acc.: 17.97%] [G loss: 1.362254]\n",
      "epoch:26 step:24797 [D loss: 1.493380, acc.: 14.84%] [G loss: 1.793609]\n",
      "epoch:26 step:24798 [D loss: 0.592070, acc.: 67.19%] [G loss: 1.466618]\n",
      "epoch:26 step:24799 [D loss: 1.173883, acc.: 24.22%] [G loss: 1.616507]\n",
      "epoch:26 step:24800 [D loss: 0.342209, acc.: 88.28%] [G loss: 1.928992]\n",
      "##############\n",
      "[4.45223782 2.918872   6.69523278 6.05402177 4.85998467 6.29970136\n",
      " 5.22267684 5.63363754 5.92202028 5.05772316]\n",
      "##########\n",
      "epoch:26 step:24801 [D loss: 0.837512, acc.: 53.12%] [G loss: 1.361815]\n",
      "epoch:26 step:24802 [D loss: 0.987639, acc.: 29.69%] [G loss: 1.437698]\n",
      "epoch:26 step:24803 [D loss: 0.846354, acc.: 44.53%] [G loss: 0.730477]\n",
      "epoch:26 step:24804 [D loss: 0.792937, acc.: 46.88%] [G loss: 0.993568]\n",
      "epoch:26 step:24805 [D loss: 0.864014, acc.: 43.75%] [G loss: 1.007789]\n",
      "epoch:26 step:24806 [D loss: 0.706398, acc.: 61.72%] [G loss: 1.292142]\n",
      "epoch:26 step:24807 [D loss: 0.732759, acc.: 56.25%] [G loss: 1.431995]\n",
      "epoch:26 step:24808 [D loss: 0.732439, acc.: 50.00%] [G loss: 1.086219]\n",
      "epoch:26 step:24809 [D loss: 0.588947, acc.: 68.75%] [G loss: 1.335184]\n",
      "epoch:26 step:24810 [D loss: 0.568629, acc.: 75.00%] [G loss: 1.459841]\n",
      "epoch:26 step:24811 [D loss: 0.533265, acc.: 75.00%] [G loss: 1.715019]\n",
      "epoch:26 step:24812 [D loss: 0.474616, acc.: 78.91%] [G loss: 1.911264]\n",
      "epoch:26 step:24813 [D loss: 0.226612, acc.: 95.31%] [G loss: 2.262698]\n",
      "epoch:26 step:24814 [D loss: 0.196646, acc.: 97.66%] [G loss: 2.410035]\n",
      "epoch:26 step:24815 [D loss: 0.318247, acc.: 91.41%] [G loss: 1.924799]\n",
      "epoch:26 step:24816 [D loss: 0.260672, acc.: 93.75%] [G loss: 1.926490]\n",
      "epoch:26 step:24817 [D loss: 0.403297, acc.: 85.16%] [G loss: 2.049806]\n",
      "epoch:26 step:24818 [D loss: 0.231233, acc.: 95.31%] [G loss: 2.083688]\n",
      "epoch:26 step:24819 [D loss: 0.199273, acc.: 97.66%] [G loss: 2.838216]\n",
      "epoch:26 step:24820 [D loss: 0.619961, acc.: 59.38%] [G loss: 1.901507]\n",
      "epoch:26 step:24821 [D loss: 0.472275, acc.: 78.12%] [G loss: 1.695249]\n",
      "epoch:26 step:24822 [D loss: 0.678426, acc.: 60.16%] [G loss: 1.736310]\n",
      "epoch:26 step:24823 [D loss: 0.699893, acc.: 57.03%] [G loss: 1.268222]\n",
      "epoch:26 step:24824 [D loss: 0.663668, acc.: 58.59%] [G loss: 1.088129]\n",
      "epoch:26 step:24825 [D loss: 0.700999, acc.: 56.25%] [G loss: 1.417336]\n",
      "epoch:26 step:24826 [D loss: 0.514059, acc.: 72.66%] [G loss: 1.187656]\n",
      "epoch:26 step:24827 [D loss: 0.358376, acc.: 81.25%] [G loss: 1.610687]\n",
      "epoch:26 step:24828 [D loss: 0.214556, acc.: 98.44%] [G loss: 1.388540]\n",
      "epoch:26 step:24829 [D loss: 0.303566, acc.: 93.75%] [G loss: 1.684685]\n",
      "epoch:26 step:24830 [D loss: 0.091226, acc.: 99.22%] [G loss: 1.041628]\n",
      "epoch:26 step:24831 [D loss: 0.273216, acc.: 84.38%] [G loss: 1.360250]\n",
      "epoch:26 step:24832 [D loss: 0.144656, acc.: 98.44%] [G loss: 2.171638]\n",
      "epoch:26 step:24833 [D loss: 0.117921, acc.: 99.22%] [G loss: 1.954541]\n",
      "epoch:26 step:24834 [D loss: 0.117728, acc.: 99.22%] [G loss: 1.519900]\n",
      "epoch:26 step:24835 [D loss: 1.231417, acc.: 43.75%] [G loss: 1.469371]\n",
      "epoch:26 step:24836 [D loss: 0.501431, acc.: 81.25%] [G loss: 1.267803]\n",
      "epoch:26 step:24837 [D loss: 0.964484, acc.: 37.50%] [G loss: 1.087515]\n",
      "epoch:26 step:24838 [D loss: 0.488471, acc.: 78.12%] [G loss: 1.188036]\n",
      "epoch:26 step:24839 [D loss: 0.428847, acc.: 87.50%] [G loss: 1.389712]\n",
      "epoch:26 step:24840 [D loss: 0.519065, acc.: 79.69%] [G loss: 1.255929]\n",
      "epoch:26 step:24841 [D loss: 0.202139, acc.: 96.09%] [G loss: 1.002889]\n",
      "epoch:26 step:24842 [D loss: 0.374494, acc.: 82.81%] [G loss: 1.087092]\n",
      "epoch:26 step:24843 [D loss: 0.196937, acc.: 94.53%] [G loss: 1.540402]\n",
      "epoch:26 step:24844 [D loss: 0.963645, acc.: 53.12%] [G loss: 1.033123]\n",
      "epoch:26 step:24845 [D loss: 0.632156, acc.: 60.94%] [G loss: 1.144460]\n",
      "epoch:26 step:24846 [D loss: 0.522886, acc.: 68.75%] [G loss: 1.299227]\n",
      "epoch:26 step:24847 [D loss: 0.753262, acc.: 53.91%] [G loss: 1.016508]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:26 step:24848 [D loss: 0.665462, acc.: 62.50%] [G loss: 1.080712]\n",
      "epoch:26 step:24849 [D loss: 0.617489, acc.: 67.97%] [G loss: 1.241219]\n",
      "epoch:26 step:24850 [D loss: 0.643915, acc.: 60.16%] [G loss: 0.858446]\n",
      "epoch:26 step:24851 [D loss: 0.267887, acc.: 90.62%] [G loss: 1.543865]\n",
      "epoch:26 step:24852 [D loss: 0.166635, acc.: 99.22%] [G loss: 1.322180]\n",
      "epoch:26 step:24853 [D loss: 0.264785, acc.: 96.88%] [G loss: 1.209456]\n",
      "epoch:26 step:24854 [D loss: 0.700351, acc.: 55.47%] [G loss: 1.324222]\n",
      "epoch:26 step:24855 [D loss: 0.717336, acc.: 51.56%] [G loss: 1.072173]\n",
      "epoch:26 step:24856 [D loss: 0.444361, acc.: 82.03%] [G loss: 1.455727]\n",
      "epoch:26 step:24857 [D loss: 0.447108, acc.: 83.59%] [G loss: 1.241711]\n",
      "epoch:26 step:24858 [D loss: 0.605999, acc.: 69.53%] [G loss: 1.085994]\n",
      "epoch:26 step:24859 [D loss: 0.414543, acc.: 88.28%] [G loss: 1.072391]\n",
      "epoch:26 step:24860 [D loss: 0.257174, acc.: 87.50%] [G loss: 1.514938]\n",
      "epoch:26 step:24861 [D loss: 0.192853, acc.: 95.31%] [G loss: 1.520859]\n",
      "epoch:26 step:24862 [D loss: 0.707501, acc.: 58.59%] [G loss: 1.368992]\n",
      "epoch:26 step:24863 [D loss: 0.906879, acc.: 42.97%] [G loss: 1.227947]\n",
      "epoch:26 step:24864 [D loss: 0.503106, acc.: 74.22%] [G loss: 1.284622]\n",
      "epoch:26 step:24865 [D loss: 0.168613, acc.: 97.66%] [G loss: 1.440262]\n",
      "epoch:26 step:24866 [D loss: 0.130170, acc.: 97.66%] [G loss: 1.480592]\n",
      "epoch:26 step:24867 [D loss: 0.263265, acc.: 91.41%] [G loss: 1.840909]\n",
      "epoch:26 step:24868 [D loss: 0.576300, acc.: 74.22%] [G loss: 1.507195]\n",
      "epoch:26 step:24869 [D loss: 0.385160, acc.: 88.28%] [G loss: 1.961244]\n",
      "epoch:26 step:24870 [D loss: 0.358085, acc.: 88.28%] [G loss: 1.524963]\n",
      "epoch:26 step:24871 [D loss: 0.644842, acc.: 64.06%] [G loss: 1.244120]\n",
      "epoch:26 step:24872 [D loss: 0.289431, acc.: 87.50%] [G loss: 1.475110]\n",
      "epoch:26 step:24873 [D loss: 0.165221, acc.: 96.88%] [G loss: 1.558738]\n",
      "epoch:26 step:24874 [D loss: 0.474362, acc.: 79.69%] [G loss: 1.688553]\n",
      "epoch:26 step:24875 [D loss: 0.161727, acc.: 99.22%] [G loss: 1.800403]\n",
      "epoch:26 step:24876 [D loss: 0.327910, acc.: 93.75%] [G loss: 2.007890]\n",
      "epoch:26 step:24877 [D loss: 0.302563, acc.: 89.84%] [G loss: 2.014143]\n",
      "epoch:26 step:24878 [D loss: 0.812326, acc.: 46.88%] [G loss: 1.705392]\n",
      "epoch:26 step:24879 [D loss: 0.358975, acc.: 86.72%] [G loss: 1.960933]\n",
      "epoch:26 step:24880 [D loss: 0.683607, acc.: 60.94%] [G loss: 1.318842]\n",
      "epoch:26 step:24881 [D loss: 0.539698, acc.: 70.31%] [G loss: 0.927237]\n",
      "epoch:26 step:24882 [D loss: 0.641353, acc.: 63.28%] [G loss: 1.412437]\n",
      "epoch:26 step:24883 [D loss: 0.536548, acc.: 71.88%] [G loss: 1.492098]\n",
      "epoch:26 step:24884 [D loss: 0.542575, acc.: 73.44%] [G loss: 1.145768]\n",
      "epoch:26 step:24885 [D loss: 0.733472, acc.: 53.91%] [G loss: 1.215378]\n",
      "epoch:26 step:24886 [D loss: 0.329108, acc.: 82.81%] [G loss: 1.559969]\n",
      "epoch:26 step:24887 [D loss: 0.641451, acc.: 65.62%] [G loss: 1.424944]\n",
      "epoch:26 step:24888 [D loss: 0.462984, acc.: 77.34%] [G loss: 1.841604]\n",
      "epoch:26 step:24889 [D loss: 0.161763, acc.: 98.44%] [G loss: 1.409880]\n",
      "epoch:26 step:24890 [D loss: 0.618037, acc.: 66.41%] [G loss: 1.641969]\n",
      "epoch:26 step:24891 [D loss: 0.454196, acc.: 81.25%] [G loss: 1.234080]\n",
      "epoch:26 step:24892 [D loss: 0.405180, acc.: 82.81%] [G loss: 1.713062]\n",
      "epoch:26 step:24893 [D loss: 0.851886, acc.: 48.44%] [G loss: 1.513774]\n",
      "epoch:26 step:24894 [D loss: 0.601254, acc.: 68.75%] [G loss: 1.576006]\n",
      "epoch:26 step:24895 [D loss: 0.504149, acc.: 71.09%] [G loss: 1.094991]\n",
      "epoch:26 step:24896 [D loss: 0.545766, acc.: 74.22%] [G loss: 1.146750]\n",
      "epoch:26 step:24897 [D loss: 0.244623, acc.: 90.62%] [G loss: 1.398808]\n",
      "epoch:26 step:24898 [D loss: 0.149576, acc.: 96.88%] [G loss: 1.882658]\n",
      "epoch:26 step:24899 [D loss: 0.221351, acc.: 97.66%] [G loss: 1.740665]\n",
      "epoch:26 step:24900 [D loss: 0.362804, acc.: 89.84%] [G loss: 1.761337]\n",
      "epoch:26 step:24901 [D loss: 0.284696, acc.: 92.19%] [G loss: 1.865418]\n",
      "epoch:26 step:24902 [D loss: 0.333176, acc.: 94.53%] [G loss: 1.424073]\n",
      "epoch:26 step:24903 [D loss: 0.258844, acc.: 96.09%] [G loss: 1.847284]\n",
      "epoch:26 step:24904 [D loss: 0.515695, acc.: 75.78%] [G loss: 1.714804]\n",
      "epoch:26 step:24905 [D loss: 0.271141, acc.: 95.31%] [G loss: 1.731319]\n",
      "epoch:26 step:24906 [D loss: 0.739702, acc.: 50.00%] [G loss: 1.568735]\n",
      "epoch:26 step:24907 [D loss: 0.281218, acc.: 92.97%] [G loss: 0.927130]\n",
      "epoch:26 step:24908 [D loss: 0.630562, acc.: 62.50%] [G loss: 1.661111]\n",
      "epoch:26 step:24909 [D loss: 0.424873, acc.: 80.47%] [G loss: 1.522068]\n",
      "epoch:26 step:24910 [D loss: 0.347579, acc.: 94.53%] [G loss: 1.848165]\n",
      "epoch:26 step:24911 [D loss: 0.291681, acc.: 91.41%] [G loss: 1.176193]\n",
      "epoch:26 step:24912 [D loss: 0.322814, acc.: 89.84%] [G loss: 1.201625]\n",
      "epoch:26 step:24913 [D loss: 0.510443, acc.: 76.56%] [G loss: 1.837452]\n",
      "epoch:26 step:24914 [D loss: 0.440518, acc.: 82.81%] [G loss: 1.639610]\n",
      "epoch:26 step:24915 [D loss: 1.146860, acc.: 28.12%] [G loss: 1.623101]\n",
      "epoch:26 step:24916 [D loss: 0.323970, acc.: 85.94%] [G loss: 1.903018]\n",
      "epoch:26 step:24917 [D loss: 0.540367, acc.: 71.09%] [G loss: 1.650232]\n",
      "epoch:26 step:24918 [D loss: 0.168778, acc.: 97.66%] [G loss: 2.319448]\n",
      "epoch:26 step:24919 [D loss: 0.285148, acc.: 96.09%] [G loss: 0.935741]\n",
      "epoch:26 step:24920 [D loss: 0.347798, acc.: 86.72%] [G loss: 2.017686]\n",
      "epoch:26 step:24921 [D loss: 0.197614, acc.: 93.75%] [G loss: 1.502805]\n",
      "epoch:26 step:24922 [D loss: 0.412616, acc.: 82.03%] [G loss: 1.748096]\n",
      "epoch:26 step:24923 [D loss: 0.097330, acc.: 98.44%] [G loss: 2.206285]\n",
      "epoch:26 step:24924 [D loss: 0.662464, acc.: 62.50%] [G loss: 2.288676]\n",
      "epoch:26 step:24925 [D loss: 0.607814, acc.: 65.62%] [G loss: 2.118564]\n",
      "epoch:26 step:24926 [D loss: 0.836678, acc.: 53.12%] [G loss: 1.485429]\n",
      "epoch:26 step:24927 [D loss: 0.262441, acc.: 92.97%] [G loss: 1.506581]\n",
      "epoch:26 step:24928 [D loss: 0.205611, acc.: 94.53%] [G loss: 1.238992]\n",
      "epoch:26 step:24929 [D loss: 0.119847, acc.: 100.00%] [G loss: 1.939299]\n",
      "epoch:26 step:24930 [D loss: 0.146616, acc.: 100.00%] [G loss: 1.466408]\n",
      "epoch:26 step:24931 [D loss: 0.826568, acc.: 54.69%] [G loss: 1.514972]\n",
      "epoch:26 step:24932 [D loss: 0.556087, acc.: 71.88%] [G loss: 1.506310]\n",
      "epoch:26 step:24933 [D loss: 0.609091, acc.: 63.28%] [G loss: 1.673069]\n",
      "epoch:26 step:24934 [D loss: 0.546850, acc.: 72.66%] [G loss: 1.259450]\n",
      "epoch:26 step:24935 [D loss: 0.444964, acc.: 82.81%] [G loss: 1.646903]\n",
      "epoch:26 step:24936 [D loss: 0.424809, acc.: 83.59%] [G loss: 1.903968]\n",
      "epoch:26 step:24937 [D loss: 0.398616, acc.: 85.16%] [G loss: 2.196433]\n",
      "epoch:26 step:24938 [D loss: 0.210772, acc.: 96.09%] [G loss: 2.419717]\n",
      "epoch:26 step:24939 [D loss: 0.193571, acc.: 95.31%] [G loss: 2.587581]\n",
      "epoch:26 step:24940 [D loss: 0.092321, acc.: 99.22%] [G loss: 2.797484]\n",
      "epoch:26 step:24941 [D loss: 0.086618, acc.: 100.00%] [G loss: 2.775850]\n",
      "epoch:26 step:24942 [D loss: 0.776076, acc.: 58.59%] [G loss: 2.450285]\n",
      "epoch:26 step:24943 [D loss: 0.692251, acc.: 65.62%] [G loss: 0.817599]\n",
      "epoch:26 step:24944 [D loss: 0.647899, acc.: 66.41%] [G loss: 0.866839]\n",
      "epoch:26 step:24945 [D loss: 0.828480, acc.: 50.00%] [G loss: 1.234403]\n",
      "epoch:26 step:24946 [D loss: 0.672809, acc.: 61.72%] [G loss: 1.080137]\n",
      "epoch:26 step:24947 [D loss: 0.833345, acc.: 48.44%] [G loss: 0.502015]\n",
      "epoch:26 step:24948 [D loss: 0.695474, acc.: 57.03%] [G loss: 1.098890]\n",
      "epoch:26 step:24949 [D loss: 0.239769, acc.: 92.19%] [G loss: 0.891231]\n",
      "epoch:26 step:24950 [D loss: 0.251470, acc.: 88.28%] [G loss: 1.895638]\n",
      "epoch:26 step:24951 [D loss: 0.358569, acc.: 80.47%] [G loss: 1.716728]\n",
      "epoch:26 step:24952 [D loss: 0.259306, acc.: 96.09%] [G loss: 2.342309]\n",
      "epoch:26 step:24953 [D loss: 1.146803, acc.: 26.56%] [G loss: 1.472128]\n",
      "epoch:26 step:24954 [D loss: 0.623931, acc.: 66.41%] [G loss: 1.984291]\n",
      "epoch:26 step:24955 [D loss: 0.804510, acc.: 52.34%] [G loss: 2.046242]\n",
      "epoch:26 step:24956 [D loss: 0.313683, acc.: 93.75%] [G loss: 1.718154]\n",
      "epoch:26 step:24957 [D loss: 0.204204, acc.: 96.09%] [G loss: 1.540890]\n",
      "epoch:26 step:24958 [D loss: 0.721151, acc.: 60.16%] [G loss: 1.653351]\n",
      "epoch:26 step:24959 [D loss: 0.687884, acc.: 57.03%] [G loss: 0.996085]\n",
      "epoch:26 step:24960 [D loss: 0.615204, acc.: 66.41%] [G loss: 1.029966]\n",
      "epoch:26 step:24961 [D loss: 1.038154, acc.: 31.25%] [G loss: 1.003150]\n",
      "epoch:26 step:24962 [D loss: 0.201201, acc.: 93.75%] [G loss: 1.766048]\n",
      "epoch:26 step:24963 [D loss: 0.170926, acc.: 95.31%] [G loss: 1.466976]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:26 step:24964 [D loss: 0.159983, acc.: 99.22%] [G loss: 1.795538]\n",
      "epoch:26 step:24965 [D loss: 0.883920, acc.: 47.66%] [G loss: 1.528406]\n",
      "epoch:26 step:24966 [D loss: 0.517189, acc.: 72.66%] [G loss: 1.556692]\n",
      "epoch:26 step:24967 [D loss: 0.801743, acc.: 44.53%] [G loss: 1.448192]\n",
      "epoch:26 step:24968 [D loss: 0.354479, acc.: 85.94%] [G loss: 1.423237]\n",
      "epoch:26 step:24969 [D loss: 0.392101, acc.: 85.16%] [G loss: 1.057096]\n",
      "epoch:26 step:24970 [D loss: 0.280007, acc.: 95.31%] [G loss: 1.407181]\n",
      "epoch:26 step:24971 [D loss: 0.264368, acc.: 87.50%] [G loss: 1.876881]\n",
      "epoch:26 step:24972 [D loss: 0.732088, acc.: 58.59%] [G loss: 1.722499]\n",
      "epoch:26 step:24973 [D loss: 0.267931, acc.: 90.62%] [G loss: 1.671112]\n",
      "epoch:26 step:24974 [D loss: 0.278036, acc.: 93.75%] [G loss: 1.450051]\n",
      "epoch:26 step:24975 [D loss: 0.659817, acc.: 53.91%] [G loss: 1.495010]\n",
      "epoch:26 step:24976 [D loss: 0.792404, acc.: 43.75%] [G loss: 1.493289]\n",
      "epoch:26 step:24977 [D loss: 0.735785, acc.: 53.12%] [G loss: 1.106539]\n",
      "epoch:26 step:24978 [D loss: 0.547300, acc.: 74.22%] [G loss: 1.407679]\n",
      "epoch:26 step:24979 [D loss: 0.452875, acc.: 82.03%] [G loss: 1.200135]\n",
      "epoch:26 step:24980 [D loss: 0.523041, acc.: 69.53%] [G loss: 1.040534]\n",
      "epoch:26 step:24981 [D loss: 0.325333, acc.: 94.53%] [G loss: 0.790498]\n",
      "epoch:26 step:24982 [D loss: 0.283246, acc.: 93.75%] [G loss: 1.556963]\n",
      "epoch:26 step:24983 [D loss: 0.757293, acc.: 52.34%] [G loss: 1.268139]\n",
      "epoch:26 step:24984 [D loss: 0.559681, acc.: 72.66%] [G loss: 1.353731]\n",
      "epoch:26 step:24985 [D loss: 0.565945, acc.: 69.53%] [G loss: 1.457486]\n",
      "epoch:26 step:24986 [D loss: 0.330194, acc.: 95.31%] [G loss: 1.295045]\n",
      "epoch:26 step:24987 [D loss: 0.419508, acc.: 81.25%] [G loss: 1.084229]\n",
      "epoch:26 step:24988 [D loss: 0.548835, acc.: 71.88%] [G loss: 1.674516]\n",
      "epoch:26 step:24989 [D loss: 0.420382, acc.: 82.81%] [G loss: 1.354987]\n",
      "epoch:26 step:24990 [D loss: 0.662175, acc.: 60.16%] [G loss: 1.466806]\n",
      "epoch:26 step:24991 [D loss: 0.626330, acc.: 64.84%] [G loss: 1.292109]\n",
      "epoch:26 step:24992 [D loss: 0.535345, acc.: 74.22%] [G loss: 1.349789]\n",
      "epoch:26 step:24993 [D loss: 0.318352, acc.: 91.41%] [G loss: 1.429681]\n",
      "epoch:26 step:24994 [D loss: 0.526924, acc.: 74.22%] [G loss: 1.396020]\n",
      "epoch:26 step:24995 [D loss: 0.303812, acc.: 91.41%] [G loss: 1.410848]\n",
      "epoch:26 step:24996 [D loss: 0.440559, acc.: 84.38%] [G loss: 1.702381]\n",
      "epoch:26 step:24997 [D loss: 0.383779, acc.: 89.84%] [G loss: 1.557566]\n",
      "epoch:26 step:24998 [D loss: 0.755506, acc.: 54.69%] [G loss: 0.828700]\n",
      "epoch:26 step:24999 [D loss: 0.533418, acc.: 75.78%] [G loss: 0.759628]\n",
      "epoch:26 step:25000 [D loss: 0.746915, acc.: 54.69%] [G loss: 0.867531]\n",
      "##############\n",
      "[3.87377655 2.53783715 6.82253676 5.92497622 4.27935027 6.07190773\n",
      " 5.30793722 5.77853255 5.46761646 4.83270645]\n",
      "##########\n",
      "epoch:26 step:25001 [D loss: 0.345460, acc.: 80.47%] [G loss: 1.465371]\n",
      "epoch:26 step:25002 [D loss: 0.414513, acc.: 83.59%] [G loss: 1.000118]\n",
      "epoch:26 step:25003 [D loss: 0.390624, acc.: 74.22%] [G loss: 1.515810]\n",
      "epoch:26 step:25004 [D loss: 0.630100, acc.: 64.84%] [G loss: 1.519313]\n",
      "epoch:26 step:25005 [D loss: 0.905339, acc.: 47.66%] [G loss: 1.416765]\n",
      "epoch:26 step:25006 [D loss: 0.324320, acc.: 88.28%] [G loss: 1.478123]\n",
      "epoch:26 step:25007 [D loss: 0.331479, acc.: 89.84%] [G loss: 1.142804]\n",
      "epoch:26 step:25008 [D loss: 0.436808, acc.: 76.56%] [G loss: 1.546337]\n",
      "epoch:26 step:25009 [D loss: 0.311426, acc.: 91.41%] [G loss: 1.889282]\n",
      "epoch:26 step:25010 [D loss: 0.280831, acc.: 97.66%] [G loss: 0.690391]\n",
      "epoch:26 step:25011 [D loss: 0.294870, acc.: 92.97%] [G loss: 1.361088]\n",
      "epoch:26 step:25012 [D loss: 0.213452, acc.: 95.31%] [G loss: 0.995647]\n",
      "epoch:26 step:25013 [D loss: 0.519771, acc.: 76.56%] [G loss: 1.784281]\n",
      "epoch:26 step:25014 [D loss: 1.124142, acc.: 27.34%] [G loss: 0.877706]\n",
      "epoch:26 step:25015 [D loss: 0.731168, acc.: 53.12%] [G loss: 1.238084]\n",
      "epoch:26 step:25016 [D loss: 0.623722, acc.: 64.84%] [G loss: 1.116549]\n",
      "epoch:26 step:25017 [D loss: 0.621545, acc.: 69.53%] [G loss: 1.487406]\n",
      "epoch:26 step:25018 [D loss: 0.756110, acc.: 53.91%] [G loss: 0.844722]\n",
      "epoch:26 step:25019 [D loss: 0.764521, acc.: 47.66%] [G loss: 0.610337]\n",
      "epoch:26 step:25020 [D loss: 0.487466, acc.: 80.47%] [G loss: 0.967659]\n",
      "epoch:26 step:25021 [D loss: 0.438790, acc.: 76.56%] [G loss: 1.555761]\n",
      "epoch:26 step:25022 [D loss: 0.680658, acc.: 61.72%] [G loss: 1.329507]\n",
      "epoch:26 step:25023 [D loss: 0.529365, acc.: 73.44%] [G loss: 1.691007]\n",
      "epoch:26 step:25024 [D loss: 0.684097, acc.: 55.47%] [G loss: 1.120901]\n",
      "epoch:26 step:25025 [D loss: 0.275462, acc.: 87.50%] [G loss: 1.195674]\n",
      "epoch:26 step:25026 [D loss: 0.111289, acc.: 100.00%] [G loss: 1.661523]\n",
      "epoch:26 step:25027 [D loss: 0.135137, acc.: 97.66%] [G loss: 2.046938]\n",
      "epoch:26 step:25028 [D loss: 0.449349, acc.: 78.91%] [G loss: 1.950659]\n",
      "epoch:26 step:25029 [D loss: 0.250435, acc.: 92.97%] [G loss: 2.199047]\n",
      "epoch:26 step:25030 [D loss: 0.689384, acc.: 60.94%] [G loss: 1.859370]\n",
      "epoch:26 step:25031 [D loss: 0.444733, acc.: 75.00%] [G loss: 1.606465]\n",
      "epoch:26 step:25032 [D loss: 0.350904, acc.: 92.19%] [G loss: 1.573712]\n",
      "epoch:26 step:25033 [D loss: 0.200753, acc.: 92.97%] [G loss: 1.245763]\n",
      "epoch:26 step:25034 [D loss: 0.328925, acc.: 92.19%] [G loss: 1.708873]\n",
      "epoch:26 step:25035 [D loss: 0.420164, acc.: 85.94%] [G loss: 1.532359]\n",
      "epoch:26 step:25036 [D loss: 0.180178, acc.: 96.88%] [G loss: 1.491431]\n",
      "epoch:26 step:25037 [D loss: 0.530721, acc.: 71.88%] [G loss: 2.141720]\n",
      "epoch:26 step:25038 [D loss: 0.255003, acc.: 96.09%] [G loss: 1.578494]\n",
      "epoch:26 step:25039 [D loss: 0.537463, acc.: 76.56%] [G loss: 1.412526]\n",
      "epoch:26 step:25040 [D loss: 0.562114, acc.: 73.44%] [G loss: 1.582861]\n",
      "epoch:26 step:25041 [D loss: 0.518913, acc.: 76.56%] [G loss: 1.590381]\n",
      "epoch:26 step:25042 [D loss: 0.303952, acc.: 92.97%] [G loss: 1.768181]\n",
      "epoch:26 step:25043 [D loss: 0.819070, acc.: 48.44%] [G loss: 1.206577]\n",
      "epoch:26 step:25044 [D loss: 0.226557, acc.: 89.06%] [G loss: 0.936864]\n",
      "epoch:26 step:25045 [D loss: 0.210447, acc.: 96.88%] [G loss: 2.343809]\n",
      "epoch:26 step:25046 [D loss: 0.138757, acc.: 97.66%] [G loss: 2.568782]\n",
      "epoch:26 step:25047 [D loss: 0.128900, acc.: 99.22%] [G loss: 0.717458]\n",
      "epoch:26 step:25048 [D loss: 0.240390, acc.: 92.97%] [G loss: 1.843726]\n",
      "epoch:26 step:25049 [D loss: 0.189507, acc.: 96.88%] [G loss: 2.595973]\n",
      "epoch:26 step:25050 [D loss: 1.159868, acc.: 29.69%] [G loss: 1.285533]\n",
      "epoch:26 step:25051 [D loss: 1.274290, acc.: 40.62%] [G loss: 1.963065]\n",
      "epoch:26 step:25052 [D loss: 1.190203, acc.: 48.44%] [G loss: 1.110168]\n",
      "epoch:26 step:25053 [D loss: 0.809847, acc.: 51.56%] [G loss: 1.332058]\n",
      "epoch:26 step:25054 [D loss: 0.651676, acc.: 64.06%] [G loss: 0.865965]\n",
      "epoch:26 step:25055 [D loss: 1.166158, acc.: 38.28%] [G loss: 1.307729]\n",
      "epoch:26 step:25056 [D loss: 0.427911, acc.: 79.69%] [G loss: 1.331826]\n",
      "epoch:26 step:25057 [D loss: 0.929510, acc.: 42.97%] [G loss: 1.546023]\n",
      "epoch:26 step:25058 [D loss: 0.138164, acc.: 98.44%] [G loss: 1.569460]\n",
      "epoch:26 step:25059 [D loss: 0.182219, acc.: 94.53%] [G loss: 1.777726]\n",
      "epoch:26 step:25060 [D loss: 0.134166, acc.: 98.44%] [G loss: 1.842121]\n",
      "epoch:26 step:25061 [D loss: 0.436208, acc.: 82.03%] [G loss: 2.068194]\n",
      "epoch:26 step:25062 [D loss: 0.068921, acc.: 99.22%] [G loss: 2.756587]\n",
      "epoch:26 step:25063 [D loss: 0.071622, acc.: 100.00%] [G loss: 2.465785]\n",
      "epoch:26 step:25064 [D loss: 0.181486, acc.: 97.66%] [G loss: 1.748839]\n",
      "epoch:26 step:25065 [D loss: 1.409055, acc.: 21.88%] [G loss: 2.533041]\n",
      "epoch:26 step:25066 [D loss: 0.490967, acc.: 75.00%] [G loss: 2.070255]\n",
      "epoch:26 step:25067 [D loss: 0.819065, acc.: 48.44%] [G loss: 1.407230]\n",
      "epoch:26 step:25068 [D loss: 0.546310, acc.: 69.53%] [G loss: 1.890329]\n",
      "epoch:26 step:25069 [D loss: 0.135341, acc.: 98.44%] [G loss: 2.523752]\n",
      "epoch:26 step:25070 [D loss: 0.419712, acc.: 78.91%] [G loss: 2.455821]\n",
      "epoch:26 step:25071 [D loss: 0.299458, acc.: 90.62%] [G loss: 2.686149]\n",
      "epoch:26 step:25072 [D loss: 0.338596, acc.: 82.03%] [G loss: 2.952038]\n",
      "epoch:26 step:25073 [D loss: 0.367205, acc.: 87.50%] [G loss: 2.564244]\n",
      "epoch:26 step:25074 [D loss: 0.875587, acc.: 52.34%] [G loss: 2.252980]\n",
      "epoch:26 step:25075 [D loss: 0.092178, acc.: 100.00%] [G loss: 2.154568]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:26 step:25076 [D loss: 0.089790, acc.: 100.00%] [G loss: 1.456766]\n",
      "epoch:26 step:25077 [D loss: 1.098880, acc.: 47.66%] [G loss: 1.329685]\n",
      "epoch:26 step:25078 [D loss: 0.727793, acc.: 57.81%] [G loss: 1.844063]\n",
      "epoch:26 step:25079 [D loss: 0.623826, acc.: 67.19%] [G loss: 0.946213]\n",
      "epoch:26 step:25080 [D loss: 0.533463, acc.: 71.09%] [G loss: 1.589433]\n",
      "epoch:26 step:25081 [D loss: 0.192563, acc.: 98.44%] [G loss: 1.739039]\n",
      "epoch:26 step:25082 [D loss: 0.205732, acc.: 96.88%] [G loss: 1.610711]\n",
      "epoch:26 step:25083 [D loss: 0.588827, acc.: 67.19%] [G loss: 1.697978]\n",
      "epoch:26 step:25084 [D loss: 0.953786, acc.: 53.12%] [G loss: 1.899180]\n",
      "epoch:26 step:25085 [D loss: 0.778674, acc.: 58.59%] [G loss: 1.883882]\n",
      "epoch:26 step:25086 [D loss: 0.183944, acc.: 93.75%] [G loss: 1.236446]\n",
      "epoch:26 step:25087 [D loss: 0.259656, acc.: 90.62%] [G loss: 1.775913]\n",
      "epoch:26 step:25088 [D loss: 0.147266, acc.: 98.44%] [G loss: 1.134697]\n",
      "epoch:26 step:25089 [D loss: 1.165712, acc.: 35.16%] [G loss: 0.737216]\n",
      "epoch:26 step:25090 [D loss: 0.540666, acc.: 75.00%] [G loss: 0.744130]\n",
      "epoch:26 step:25091 [D loss: 0.635611, acc.: 67.19%] [G loss: 0.895269]\n",
      "epoch:26 step:25092 [D loss: 0.663618, acc.: 60.94%] [G loss: 1.422912]\n",
      "epoch:26 step:25093 [D loss: 1.464193, acc.: 41.41%] [G loss: 2.403399]\n",
      "epoch:26 step:25094 [D loss: 0.889311, acc.: 50.78%] [G loss: 1.975697]\n",
      "epoch:26 step:25095 [D loss: 0.943092, acc.: 43.75%] [G loss: 2.118198]\n",
      "epoch:26 step:25096 [D loss: 0.744718, acc.: 56.25%] [G loss: 2.002554]\n",
      "epoch:26 step:25097 [D loss: 0.227561, acc.: 91.41%] [G loss: 2.387295]\n",
      "epoch:26 step:25098 [D loss: 0.204308, acc.: 97.66%] [G loss: 3.077442]\n",
      "epoch:26 step:25099 [D loss: 0.343572, acc.: 80.47%] [G loss: 2.661536]\n",
      "epoch:26 step:25100 [D loss: 0.511842, acc.: 64.84%] [G loss: 2.774067]\n",
      "epoch:26 step:25101 [D loss: 0.853934, acc.: 59.38%] [G loss: 1.530952]\n",
      "epoch:26 step:25102 [D loss: 0.509622, acc.: 71.09%] [G loss: 1.132885]\n",
      "epoch:26 step:25103 [D loss: 0.170788, acc.: 94.53%] [G loss: 1.431311]\n",
      "epoch:26 step:25104 [D loss: 0.136406, acc.: 98.44%] [G loss: 1.966866]\n",
      "epoch:26 step:25105 [D loss: 0.103362, acc.: 98.44%] [G loss: 2.769407]\n",
      "epoch:26 step:25106 [D loss: 0.151000, acc.: 99.22%] [G loss: 1.763263]\n",
      "epoch:26 step:25107 [D loss: 1.137883, acc.: 35.94%] [G loss: 1.614605]\n",
      "epoch:26 step:25108 [D loss: 0.712557, acc.: 59.38%] [G loss: 1.785039]\n",
      "epoch:26 step:25109 [D loss: 0.480564, acc.: 79.69%] [G loss: 1.210988]\n",
      "epoch:26 step:25110 [D loss: 0.227297, acc.: 93.75%] [G loss: 1.568161]\n",
      "epoch:26 step:25111 [D loss: 0.216407, acc.: 90.62%] [G loss: 1.970085]\n",
      "epoch:26 step:25112 [D loss: 0.070601, acc.: 100.00%] [G loss: 2.067512]\n",
      "epoch:26 step:25113 [D loss: 0.584964, acc.: 66.41%] [G loss: 2.101618]\n",
      "epoch:26 step:25114 [D loss: 0.778730, acc.: 56.25%] [G loss: 1.686339]\n",
      "epoch:26 step:25115 [D loss: 0.771603, acc.: 53.12%] [G loss: 0.908372]\n",
      "epoch:26 step:25116 [D loss: 0.958837, acc.: 39.84%] [G loss: 1.235696]\n",
      "epoch:26 step:25117 [D loss: 0.685561, acc.: 61.72%] [G loss: 0.826210]\n",
      "epoch:26 step:25118 [D loss: 0.685731, acc.: 64.06%] [G loss: 1.101493]\n",
      "epoch:26 step:25119 [D loss: 0.679801, acc.: 55.47%] [G loss: 1.434476]\n",
      "epoch:26 step:25120 [D loss: 0.493347, acc.: 74.22%] [G loss: 1.369923]\n",
      "epoch:26 step:25121 [D loss: 0.320447, acc.: 89.84%] [G loss: 1.850811]\n",
      "epoch:26 step:25122 [D loss: 0.293546, acc.: 87.50%] [G loss: 1.480606]\n",
      "epoch:26 step:25123 [D loss: 0.493257, acc.: 74.22%] [G loss: 1.440686]\n",
      "epoch:26 step:25124 [D loss: 0.550741, acc.: 75.78%] [G loss: 1.352496]\n",
      "epoch:26 step:25125 [D loss: 0.721530, acc.: 62.50%] [G loss: 1.155826]\n",
      "epoch:26 step:25126 [D loss: 0.477199, acc.: 79.69%] [G loss: 0.964436]\n",
      "epoch:26 step:25127 [D loss: 0.553765, acc.: 69.53%] [G loss: 0.971361]\n",
      "epoch:26 step:25128 [D loss: 0.358705, acc.: 86.72%] [G loss: 1.504976]\n",
      "epoch:26 step:25129 [D loss: 0.300702, acc.: 94.53%] [G loss: 1.083322]\n",
      "epoch:26 step:25130 [D loss: 0.405253, acc.: 75.78%] [G loss: 1.591991]\n",
      "epoch:26 step:25131 [D loss: 0.122949, acc.: 100.00%] [G loss: 1.761546]\n",
      "epoch:26 step:25132 [D loss: 0.590886, acc.: 64.84%] [G loss: 2.063710]\n",
      "epoch:26 step:25133 [D loss: 0.733212, acc.: 59.38%] [G loss: 0.845974]\n",
      "epoch:26 step:25134 [D loss: 0.666560, acc.: 59.38%] [G loss: 0.541070]\n",
      "epoch:26 step:25135 [D loss: 0.555524, acc.: 71.09%] [G loss: 1.150568]\n",
      "epoch:26 step:25136 [D loss: 0.252781, acc.: 89.06%] [G loss: 1.282213]\n",
      "epoch:26 step:25137 [D loss: 0.492547, acc.: 68.75%] [G loss: 1.303563]\n",
      "epoch:26 step:25138 [D loss: 0.588557, acc.: 68.75%] [G loss: 1.483913]\n",
      "epoch:26 step:25139 [D loss: 0.342169, acc.: 92.97%] [G loss: 1.295959]\n",
      "epoch:26 step:25140 [D loss: 0.975827, acc.: 39.84%] [G loss: 1.745048]\n",
      "epoch:26 step:25141 [D loss: 0.617398, acc.: 65.62%] [G loss: 1.293441]\n",
      "epoch:26 step:25142 [D loss: 0.361256, acc.: 88.28%] [G loss: 1.548904]\n",
      "epoch:26 step:25143 [D loss: 0.373165, acc.: 85.16%] [G loss: 0.982239]\n",
      "epoch:26 step:25144 [D loss: 0.326307, acc.: 89.06%] [G loss: 1.457099]\n",
      "epoch:26 step:25145 [D loss: 0.505229, acc.: 75.78%] [G loss: 1.349741]\n",
      "epoch:26 step:25146 [D loss: 0.677088, acc.: 63.28%] [G loss: 1.219216]\n",
      "epoch:26 step:25147 [D loss: 0.525915, acc.: 73.44%] [G loss: 1.462051]\n",
      "epoch:26 step:25148 [D loss: 0.288237, acc.: 91.41%] [G loss: 1.164935]\n",
      "epoch:26 step:25149 [D loss: 0.575110, acc.: 71.88%] [G loss: 1.715671]\n",
      "epoch:26 step:25150 [D loss: 0.598558, acc.: 71.09%] [G loss: 1.116780]\n",
      "epoch:26 step:25151 [D loss: 0.801664, acc.: 48.44%] [G loss: 0.743106]\n",
      "epoch:26 step:25152 [D loss: 0.701260, acc.: 61.72%] [G loss: 1.472117]\n",
      "epoch:26 step:25153 [D loss: 0.204190, acc.: 93.75%] [G loss: 1.351315]\n",
      "epoch:26 step:25154 [D loss: 0.168224, acc.: 99.22%] [G loss: 1.608796]\n",
      "epoch:26 step:25155 [D loss: 0.233176, acc.: 94.53%] [G loss: 1.776992]\n",
      "epoch:26 step:25156 [D loss: 0.164576, acc.: 99.22%] [G loss: 1.956074]\n",
      "epoch:26 step:25157 [D loss: 0.266888, acc.: 93.75%] [G loss: 1.997463]\n",
      "epoch:26 step:25158 [D loss: 0.365837, acc.: 85.94%] [G loss: 2.008444]\n",
      "epoch:26 step:25159 [D loss: 0.562693, acc.: 71.88%] [G loss: 1.512455]\n",
      "epoch:26 step:25160 [D loss: 0.529702, acc.: 75.00%] [G loss: 1.602018]\n",
      "epoch:26 step:25161 [D loss: 0.587076, acc.: 66.41%] [G loss: 1.321179]\n",
      "epoch:26 step:25162 [D loss: 0.508703, acc.: 75.00%] [G loss: 0.730335]\n",
      "epoch:26 step:25163 [D loss: 0.514064, acc.: 72.66%] [G loss: 1.404636]\n",
      "epoch:26 step:25164 [D loss: 0.512036, acc.: 78.91%] [G loss: 1.449349]\n",
      "epoch:26 step:25165 [D loss: 0.586810, acc.: 68.75%] [G loss: 1.167855]\n",
      "epoch:26 step:25166 [D loss: 0.218839, acc.: 89.84%] [G loss: 1.485143]\n",
      "epoch:26 step:25167 [D loss: 0.194288, acc.: 94.53%] [G loss: 1.333995]\n",
      "epoch:26 step:25168 [D loss: 0.160749, acc.: 97.66%] [G loss: 1.544562]\n",
      "epoch:26 step:25169 [D loss: 0.843076, acc.: 50.00%] [G loss: 1.315015]\n",
      "epoch:26 step:25170 [D loss: 0.577333, acc.: 67.19%] [G loss: 1.456746]\n",
      "epoch:26 step:25171 [D loss: 0.375839, acc.: 85.94%] [G loss: 1.316710]\n",
      "epoch:26 step:25172 [D loss: 0.547920, acc.: 69.53%] [G loss: 1.147907]\n",
      "epoch:26 step:25173 [D loss: 0.771458, acc.: 52.34%] [G loss: 0.807619]\n",
      "epoch:26 step:25174 [D loss: 0.392654, acc.: 86.72%] [G loss: 1.155742]\n",
      "epoch:26 step:25175 [D loss: 0.916620, acc.: 35.16%] [G loss: 1.376675]\n",
      "epoch:26 step:25176 [D loss: 0.712715, acc.: 58.59%] [G loss: 1.565269]\n",
      "epoch:26 step:25177 [D loss: 0.192716, acc.: 97.66%] [G loss: 1.411349]\n",
      "epoch:26 step:25178 [D loss: 0.432078, acc.: 83.59%] [G loss: 1.527246]\n",
      "epoch:26 step:25179 [D loss: 0.607677, acc.: 70.31%] [G loss: 0.962222]\n",
      "epoch:26 step:25180 [D loss: 0.772789, acc.: 49.22%] [G loss: 1.428601]\n",
      "epoch:26 step:25181 [D loss: 0.585799, acc.: 70.31%] [G loss: 1.244417]\n",
      "epoch:26 step:25182 [D loss: 0.685043, acc.: 59.38%] [G loss: 1.117147]\n",
      "epoch:26 step:25183 [D loss: 0.252768, acc.: 92.19%] [G loss: 1.325249]\n",
      "epoch:26 step:25184 [D loss: 0.500147, acc.: 78.12%] [G loss: 1.467248]\n",
      "epoch:26 step:25185 [D loss: 0.564815, acc.: 78.12%] [G loss: 1.419529]\n",
      "epoch:26 step:25186 [D loss: 0.732935, acc.: 53.12%] [G loss: 0.978223]\n",
      "epoch:26 step:25187 [D loss: 0.536072, acc.: 76.56%] [G loss: 1.053181]\n",
      "epoch:26 step:25188 [D loss: 0.458622, acc.: 83.59%] [G loss: 1.081098]\n",
      "epoch:26 step:25189 [D loss: 0.571438, acc.: 71.88%] [G loss: 1.466361]\n",
      "epoch:26 step:25190 [D loss: 0.630922, acc.: 66.41%] [G loss: 1.143440]\n",
      "epoch:26 step:25191 [D loss: 0.571097, acc.: 71.88%] [G loss: 1.213309]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:26 step:25192 [D loss: 0.622947, acc.: 67.97%] [G loss: 1.376305]\n",
      "epoch:26 step:25193 [D loss: 0.264118, acc.: 94.53%] [G loss: 1.009259]\n",
      "epoch:26 step:25194 [D loss: 0.372026, acc.: 84.38%] [G loss: 1.473813]\n",
      "epoch:26 step:25195 [D loss: 0.375514, acc.: 89.06%] [G loss: 1.428760]\n",
      "epoch:26 step:25196 [D loss: 0.215389, acc.: 98.44%] [G loss: 1.790172]\n",
      "epoch:26 step:25197 [D loss: 0.643872, acc.: 66.41%] [G loss: 1.527365]\n",
      "epoch:26 step:25198 [D loss: 0.838208, acc.: 46.88%] [G loss: 1.621894]\n",
      "epoch:26 step:25199 [D loss: 0.704460, acc.: 61.72%] [G loss: 1.594744]\n",
      "epoch:26 step:25200 [D loss: 0.680379, acc.: 60.94%] [G loss: 1.058898]\n",
      "##############\n",
      "[3.88993095 2.63424596 6.51665281 5.64402326 4.29927951 6.15211773\n",
      " 5.11800164 5.5193038  5.84566507 4.79104483]\n",
      "##########\n",
      "epoch:26 step:25201 [D loss: 0.593814, acc.: 71.88%] [G loss: 1.706144]\n",
      "epoch:26 step:25202 [D loss: 0.627867, acc.: 62.50%] [G loss: 1.130983]\n",
      "epoch:26 step:25203 [D loss: 0.286292, acc.: 89.84%] [G loss: 1.414675]\n",
      "epoch:26 step:25204 [D loss: 0.233313, acc.: 95.31%] [G loss: 1.331157]\n",
      "epoch:26 step:25205 [D loss: 0.533774, acc.: 75.78%] [G loss: 1.634330]\n",
      "epoch:26 step:25206 [D loss: 0.521841, acc.: 73.44%] [G loss: 1.426219]\n",
      "epoch:26 step:25207 [D loss: 0.216696, acc.: 94.53%] [G loss: 1.268553]\n",
      "epoch:26 step:25208 [D loss: 0.751212, acc.: 50.00%] [G loss: 1.527320]\n",
      "epoch:26 step:25209 [D loss: 0.305393, acc.: 90.62%] [G loss: 1.734273]\n",
      "epoch:26 step:25210 [D loss: 0.438163, acc.: 81.25%] [G loss: 1.523269]\n",
      "epoch:26 step:25211 [D loss: 0.328755, acc.: 91.41%] [G loss: 0.921049]\n",
      "epoch:26 step:25212 [D loss: 0.317588, acc.: 84.38%] [G loss: 1.457935]\n",
      "epoch:26 step:25213 [D loss: 0.219106, acc.: 93.75%] [G loss: 1.071310]\n",
      "epoch:26 step:25214 [D loss: 0.457191, acc.: 76.56%] [G loss: 1.758890]\n",
      "epoch:26 step:25215 [D loss: 0.248318, acc.: 96.88%] [G loss: 1.736494]\n",
      "epoch:26 step:25216 [D loss: 0.272071, acc.: 95.31%] [G loss: 1.618766]\n",
      "epoch:26 step:25217 [D loss: 0.328190, acc.: 88.28%] [G loss: 1.358801]\n",
      "epoch:26 step:25218 [D loss: 0.791954, acc.: 46.88%] [G loss: 1.316466]\n",
      "epoch:26 step:25219 [D loss: 0.222888, acc.: 94.53%] [G loss: 1.602597]\n",
      "epoch:26 step:25220 [D loss: 0.449487, acc.: 71.09%] [G loss: 1.840526]\n",
      "epoch:26 step:25221 [D loss: 0.396908, acc.: 76.56%] [G loss: 1.449753]\n",
      "epoch:26 step:25222 [D loss: 0.554169, acc.: 70.31%] [G loss: 1.376828]\n",
      "epoch:26 step:25223 [D loss: 1.033035, acc.: 41.41%] [G loss: 1.713828]\n",
      "epoch:26 step:25224 [D loss: 0.986851, acc.: 44.53%] [G loss: 1.876149]\n",
      "epoch:26 step:25225 [D loss: 0.785358, acc.: 56.25%] [G loss: 1.624964]\n",
      "epoch:26 step:25226 [D loss: 0.539078, acc.: 71.09%] [G loss: 1.640495]\n",
      "epoch:26 step:25227 [D loss: 0.836933, acc.: 47.66%] [G loss: 1.907280]\n",
      "epoch:26 step:25228 [D loss: 0.536871, acc.: 78.91%] [G loss: 1.456048]\n",
      "epoch:26 step:25229 [D loss: 0.674033, acc.: 62.50%] [G loss: 1.470807]\n",
      "epoch:26 step:25230 [D loss: 0.328225, acc.: 87.50%] [G loss: 1.625042]\n",
      "epoch:26 step:25231 [D loss: 0.626216, acc.: 64.84%] [G loss: 1.548974]\n",
      "epoch:26 step:25232 [D loss: 0.177135, acc.: 96.88%] [G loss: 1.642329]\n",
      "epoch:26 step:25233 [D loss: 0.219759, acc.: 94.53%] [G loss: 3.045698]\n",
      "epoch:26 step:25234 [D loss: 0.550187, acc.: 71.09%] [G loss: 1.818907]\n",
      "epoch:26 step:25235 [D loss: 0.555304, acc.: 71.88%] [G loss: 1.477438]\n",
      "epoch:26 step:25236 [D loss: 0.243258, acc.: 94.53%] [G loss: 1.949885]\n",
      "epoch:26 step:25237 [D loss: 0.499524, acc.: 78.12%] [G loss: 1.532747]\n",
      "epoch:26 step:25238 [D loss: 0.219761, acc.: 91.41%] [G loss: 1.296461]\n",
      "epoch:26 step:25239 [D loss: 0.060221, acc.: 100.00%] [G loss: 1.898675]\n",
      "epoch:26 step:25240 [D loss: 0.126841, acc.: 98.44%] [G loss: 2.239417]\n",
      "epoch:26 step:25241 [D loss: 0.458860, acc.: 82.03%] [G loss: 3.434970]\n",
      "epoch:26 step:25242 [D loss: 0.977034, acc.: 32.81%] [G loss: 2.255531]\n",
      "epoch:26 step:25243 [D loss: 0.407667, acc.: 82.03%] [G loss: 0.938387]\n",
      "epoch:26 step:25244 [D loss: 1.597674, acc.: 24.22%] [G loss: 1.113404]\n",
      "epoch:26 step:25245 [D loss: 1.198970, acc.: 27.34%] [G loss: 1.490699]\n",
      "epoch:26 step:25246 [D loss: 0.651881, acc.: 64.06%] [G loss: 1.439510]\n",
      "epoch:26 step:25247 [D loss: 0.254969, acc.: 92.97%] [G loss: 1.568698]\n",
      "epoch:26 step:25248 [D loss: 0.303564, acc.: 87.50%] [G loss: 2.027120]\n",
      "epoch:26 step:25249 [D loss: 0.346045, acc.: 89.06%] [G loss: 1.659070]\n",
      "epoch:26 step:25250 [D loss: 0.760369, acc.: 51.56%] [G loss: 1.459250]\n",
      "epoch:26 step:25251 [D loss: 0.534564, acc.: 71.88%] [G loss: 1.931828]\n",
      "epoch:26 step:25252 [D loss: 0.367039, acc.: 88.28%] [G loss: 2.185782]\n",
      "epoch:26 step:25253 [D loss: 0.565401, acc.: 71.88%] [G loss: 1.914666]\n",
      "epoch:26 step:25254 [D loss: 0.344795, acc.: 87.50%] [G loss: 1.937250]\n",
      "epoch:26 step:25255 [D loss: 0.337685, acc.: 95.31%] [G loss: 1.206064]\n",
      "epoch:26 step:25256 [D loss: 0.372824, acc.: 84.38%] [G loss: 1.315795]\n",
      "epoch:26 step:25257 [D loss: 0.283507, acc.: 94.53%] [G loss: 1.889794]\n",
      "epoch:26 step:25258 [D loss: 0.195185, acc.: 97.66%] [G loss: 1.790934]\n",
      "epoch:26 step:25259 [D loss: 0.504090, acc.: 75.00%] [G loss: 1.353941]\n",
      "epoch:26 step:25260 [D loss: 0.110896, acc.: 100.00%] [G loss: 1.431673]\n",
      "epoch:26 step:25261 [D loss: 0.176052, acc.: 96.09%] [G loss: 1.829091]\n",
      "epoch:26 step:25262 [D loss: 0.085781, acc.: 100.00%] [G loss: 2.096158]\n",
      "epoch:26 step:25263 [D loss: 0.335365, acc.: 86.72%] [G loss: 1.488165]\n",
      "epoch:26 step:25264 [D loss: 0.696573, acc.: 58.59%] [G loss: 1.421955]\n",
      "epoch:26 step:25265 [D loss: 0.463644, acc.: 82.03%] [G loss: 1.355064]\n",
      "epoch:26 step:25266 [D loss: 0.270301, acc.: 92.97%] [G loss: 1.457442]\n",
      "epoch:26 step:25267 [D loss: 0.379688, acc.: 86.72%] [G loss: 0.400573]\n",
      "epoch:26 step:25268 [D loss: 0.418122, acc.: 78.12%] [G loss: 1.327275]\n",
      "epoch:26 step:25269 [D loss: 1.160790, acc.: 37.50%] [G loss: 2.352678]\n",
      "epoch:26 step:25270 [D loss: 0.757524, acc.: 54.69%] [G loss: 1.822510]\n",
      "epoch:26 step:25271 [D loss: 0.333972, acc.: 87.50%] [G loss: 1.944242]\n",
      "epoch:26 step:25272 [D loss: 0.343824, acc.: 90.62%] [G loss: 1.497651]\n",
      "epoch:26 step:25273 [D loss: 0.261678, acc.: 95.31%] [G loss: 1.948059]\n",
      "epoch:26 step:25274 [D loss: 0.107310, acc.: 98.44%] [G loss: 2.239679]\n",
      "epoch:26 step:25275 [D loss: 0.747220, acc.: 54.69%] [G loss: 1.951125]\n",
      "epoch:26 step:25276 [D loss: 0.577108, acc.: 73.44%] [G loss: 1.343707]\n",
      "epoch:26 step:25277 [D loss: 0.815594, acc.: 53.12%] [G loss: 1.150984]\n",
      "epoch:26 step:25278 [D loss: 0.417773, acc.: 84.38%] [G loss: 1.092907]\n",
      "epoch:26 step:25279 [D loss: 0.219059, acc.: 96.09%] [G loss: 1.360904]\n",
      "epoch:26 step:25280 [D loss: 0.417715, acc.: 84.38%] [G loss: 1.227456]\n",
      "epoch:26 step:25281 [D loss: 0.763329, acc.: 56.25%] [G loss: 1.747643]\n",
      "epoch:26 step:25282 [D loss: 0.238619, acc.: 90.62%] [G loss: 1.487850]\n",
      "epoch:26 step:25283 [D loss: 0.248136, acc.: 91.41%] [G loss: 1.470995]\n",
      "epoch:26 step:25284 [D loss: 0.690723, acc.: 60.94%] [G loss: 1.779511]\n",
      "epoch:26 step:25285 [D loss: 0.690710, acc.: 57.03%] [G loss: 1.623260]\n",
      "epoch:26 step:25286 [D loss: 0.548804, acc.: 72.66%] [G loss: 1.275176]\n",
      "epoch:26 step:25287 [D loss: 0.649747, acc.: 63.28%] [G loss: 1.614233]\n",
      "epoch:26 step:25288 [D loss: 0.630583, acc.: 67.97%] [G loss: 1.661888]\n",
      "epoch:26 step:25289 [D loss: 0.564238, acc.: 71.88%] [G loss: 0.875463]\n",
      "epoch:26 step:25290 [D loss: 0.428889, acc.: 82.81%] [G loss: 1.457614]\n",
      "epoch:26 step:25291 [D loss: 0.314395, acc.: 80.47%] [G loss: 1.101323]\n",
      "epoch:26 step:25292 [D loss: 0.329409, acc.: 88.28%] [G loss: 1.497820]\n",
      "epoch:26 step:25293 [D loss: 0.299766, acc.: 90.62%] [G loss: 1.731434]\n",
      "epoch:26 step:25294 [D loss: 0.685401, acc.: 58.59%] [G loss: 2.053123]\n",
      "epoch:26 step:25295 [D loss: 0.566281, acc.: 64.84%] [G loss: 1.875765]\n",
      "epoch:26 step:25296 [D loss: 0.693543, acc.: 60.94%] [G loss: 1.514499]\n",
      "epoch:26 step:25297 [D loss: 0.551247, acc.: 69.53%] [G loss: 1.397061]\n",
      "epoch:26 step:25298 [D loss: 0.484116, acc.: 78.12%] [G loss: 1.348958]\n",
      "epoch:26 step:25299 [D loss: 0.397138, acc.: 77.34%] [G loss: 1.534444]\n",
      "epoch:27 step:25300 [D loss: 0.901770, acc.: 55.47%] [G loss: 1.141152]\n",
      "epoch:27 step:25301 [D loss: 0.928918, acc.: 37.50%] [G loss: 1.044919]\n",
      "epoch:27 step:25302 [D loss: 0.936286, acc.: 42.97%] [G loss: 1.234758]\n",
      "epoch:27 step:25303 [D loss: 0.514207, acc.: 79.69%] [G loss: 0.992461]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:27 step:25304 [D loss: 0.468840, acc.: 82.81%] [G loss: 1.179753]\n",
      "epoch:27 step:25305 [D loss: 0.688569, acc.: 55.47%] [G loss: 1.499148]\n",
      "epoch:27 step:25306 [D loss: 0.559607, acc.: 70.31%] [G loss: 0.769658]\n",
      "epoch:27 step:25307 [D loss: 0.697044, acc.: 54.69%] [G loss: 1.146122]\n",
      "epoch:27 step:25308 [D loss: 0.594154, acc.: 70.31%] [G loss: 1.296866]\n",
      "epoch:27 step:25309 [D loss: 0.460699, acc.: 82.03%] [G loss: 1.286963]\n",
      "epoch:27 step:25310 [D loss: 0.454504, acc.: 82.03%] [G loss: 1.105354]\n",
      "epoch:27 step:25311 [D loss: 0.449247, acc.: 80.47%] [G loss: 1.133320]\n",
      "epoch:27 step:25312 [D loss: 0.514786, acc.: 73.44%] [G loss: 1.357785]\n",
      "epoch:27 step:25313 [D loss: 0.466631, acc.: 83.59%] [G loss: 1.692642]\n",
      "epoch:27 step:25314 [D loss: 0.350218, acc.: 88.28%] [G loss: 0.690008]\n",
      "epoch:27 step:25315 [D loss: 0.320817, acc.: 91.41%] [G loss: 1.110025]\n",
      "epoch:27 step:25316 [D loss: 0.635265, acc.: 59.38%] [G loss: 0.998899]\n",
      "epoch:27 step:25317 [D loss: 0.432879, acc.: 82.81%] [G loss: 1.391715]\n",
      "epoch:27 step:25318 [D loss: 0.658385, acc.: 67.97%] [G loss: 1.474390]\n",
      "epoch:27 step:25319 [D loss: 0.709902, acc.: 56.25%] [G loss: 1.058301]\n",
      "epoch:27 step:25320 [D loss: 0.652426, acc.: 63.28%] [G loss: 1.279750]\n",
      "epoch:27 step:25321 [D loss: 0.620955, acc.: 64.84%] [G loss: 0.648421]\n",
      "epoch:27 step:25322 [D loss: 0.617272, acc.: 64.06%] [G loss: 0.896167]\n",
      "epoch:27 step:25323 [D loss: 0.472805, acc.: 77.34%] [G loss: 1.539611]\n",
      "epoch:27 step:25324 [D loss: 0.454097, acc.: 81.25%] [G loss: 1.128906]\n",
      "epoch:27 step:25325 [D loss: 1.035571, acc.: 28.12%] [G loss: 1.241814]\n",
      "epoch:27 step:25326 [D loss: 0.513483, acc.: 68.75%] [G loss: 1.383210]\n",
      "epoch:27 step:25327 [D loss: 0.351207, acc.: 88.28%] [G loss: 1.579776]\n",
      "epoch:27 step:25328 [D loss: 0.286250, acc.: 92.19%] [G loss: 2.105537]\n",
      "epoch:27 step:25329 [D loss: 0.466296, acc.: 75.78%] [G loss: 1.640826]\n",
      "epoch:27 step:25330 [D loss: 0.185175, acc.: 95.31%] [G loss: 1.619722]\n",
      "epoch:27 step:25331 [D loss: 0.194186, acc.: 98.44%] [G loss: 1.657876]\n",
      "epoch:27 step:25332 [D loss: 0.122157, acc.: 98.44%] [G loss: 2.026360]\n",
      "epoch:27 step:25333 [D loss: 0.143568, acc.: 100.00%] [G loss: 2.095254]\n",
      "epoch:27 step:25334 [D loss: 0.107882, acc.: 99.22%] [G loss: 1.831796]\n",
      "epoch:27 step:25335 [D loss: 0.073980, acc.: 99.22%] [G loss: 1.798158]\n",
      "epoch:27 step:25336 [D loss: 0.907057, acc.: 55.47%] [G loss: 1.636594]\n",
      "epoch:27 step:25337 [D loss: 0.758324, acc.: 51.56%] [G loss: 1.487060]\n",
      "epoch:27 step:25338 [D loss: 0.754512, acc.: 53.91%] [G loss: 1.278205]\n",
      "epoch:27 step:25339 [D loss: 0.653092, acc.: 64.84%] [G loss: 1.187621]\n",
      "epoch:27 step:25340 [D loss: 0.560882, acc.: 71.09%] [G loss: 1.520105]\n",
      "epoch:27 step:25341 [D loss: 0.356651, acc.: 92.19%] [G loss: 1.256526]\n",
      "epoch:27 step:25342 [D loss: 0.285434, acc.: 90.62%] [G loss: 1.318501]\n",
      "epoch:27 step:25343 [D loss: 0.752694, acc.: 55.47%] [G loss: 1.269485]\n",
      "epoch:27 step:25344 [D loss: 0.631920, acc.: 64.06%] [G loss: 1.859761]\n",
      "epoch:27 step:25345 [D loss: 0.458183, acc.: 81.25%] [G loss: 1.329924]\n",
      "epoch:27 step:25346 [D loss: 0.739067, acc.: 54.69%] [G loss: 1.393660]\n",
      "epoch:27 step:25347 [D loss: 0.672040, acc.: 54.69%] [G loss: 1.270117]\n",
      "epoch:27 step:25348 [D loss: 0.662079, acc.: 57.03%] [G loss: 0.933247]\n",
      "epoch:27 step:25349 [D loss: 0.511044, acc.: 75.78%] [G loss: 0.451550]\n",
      "epoch:27 step:25350 [D loss: 0.397965, acc.: 80.47%] [G loss: 1.108066]\n",
      "epoch:27 step:25351 [D loss: 0.308403, acc.: 86.72%] [G loss: 1.458310]\n",
      "epoch:27 step:25352 [D loss: 0.351757, acc.: 92.19%] [G loss: 1.304803]\n",
      "epoch:27 step:25353 [D loss: 0.770316, acc.: 45.31%] [G loss: 1.188006]\n",
      "epoch:27 step:25354 [D loss: 0.628341, acc.: 65.62%] [G loss: 0.878330]\n",
      "epoch:27 step:25355 [D loss: 0.571798, acc.: 68.75%] [G loss: 1.076657]\n",
      "epoch:27 step:25356 [D loss: 0.298314, acc.: 82.03%] [G loss: 1.425303]\n",
      "epoch:27 step:25357 [D loss: 0.305079, acc.: 89.06%] [G loss: 1.849166]\n",
      "epoch:27 step:25358 [D loss: 0.257811, acc.: 92.97%] [G loss: 1.310024]\n",
      "epoch:27 step:25359 [D loss: 0.274095, acc.: 88.28%] [G loss: 0.732474]\n",
      "epoch:27 step:25360 [D loss: 0.686351, acc.: 57.81%] [G loss: 1.722541]\n",
      "epoch:27 step:25361 [D loss: 0.582344, acc.: 69.53%] [G loss: 1.779673]\n",
      "epoch:27 step:25362 [D loss: 0.338424, acc.: 87.50%] [G loss: 0.905661]\n",
      "epoch:27 step:25363 [D loss: 1.108990, acc.: 27.34%] [G loss: 0.587449]\n",
      "epoch:27 step:25364 [D loss: 0.799112, acc.: 51.56%] [G loss: 0.525364]\n",
      "epoch:27 step:25365 [D loss: 0.792791, acc.: 50.78%] [G loss: 1.643293]\n",
      "epoch:27 step:25366 [D loss: 0.714018, acc.: 54.69%] [G loss: 1.151395]\n",
      "epoch:27 step:25367 [D loss: 0.694255, acc.: 62.50%] [G loss: 1.037997]\n",
      "epoch:27 step:25368 [D loss: 0.568884, acc.: 69.53%] [G loss: 1.082147]\n",
      "epoch:27 step:25369 [D loss: 0.581329, acc.: 70.31%] [G loss: 1.027179]\n",
      "epoch:27 step:25370 [D loss: 0.368216, acc.: 80.47%] [G loss: 1.719199]\n",
      "epoch:27 step:25371 [D loss: 0.312990, acc.: 92.19%] [G loss: 1.495800]\n",
      "epoch:27 step:25372 [D loss: 0.391432, acc.: 85.16%] [G loss: 1.194617]\n",
      "epoch:27 step:25373 [D loss: 0.458211, acc.: 74.22%] [G loss: 2.023192]\n",
      "epoch:27 step:25374 [D loss: 0.293161, acc.: 89.06%] [G loss: 2.297641]\n",
      "epoch:27 step:25375 [D loss: 0.173360, acc.: 94.53%] [G loss: 2.055538]\n",
      "epoch:27 step:25376 [D loss: 0.382980, acc.: 87.50%] [G loss: 2.128906]\n",
      "epoch:27 step:25377 [D loss: 1.069548, acc.: 37.50%] [G loss: 1.249195]\n",
      "epoch:27 step:25378 [D loss: 1.023012, acc.: 36.72%] [G loss: 1.304390]\n",
      "epoch:27 step:25379 [D loss: 0.753047, acc.: 50.78%] [G loss: 1.575285]\n",
      "epoch:27 step:25380 [D loss: 0.789109, acc.: 54.69%] [G loss: 1.625083]\n",
      "epoch:27 step:25381 [D loss: 0.411526, acc.: 82.81%] [G loss: 1.076668]\n",
      "epoch:27 step:25382 [D loss: 0.327246, acc.: 92.19%] [G loss: 1.658853]\n",
      "epoch:27 step:25383 [D loss: 0.679779, acc.: 60.94%] [G loss: 1.993083]\n",
      "epoch:27 step:25384 [D loss: 0.629228, acc.: 65.62%] [G loss: 1.670447]\n",
      "epoch:27 step:25385 [D loss: 0.640555, acc.: 66.41%] [G loss: 1.244874]\n",
      "epoch:27 step:25386 [D loss: 0.408941, acc.: 84.38%] [G loss: 0.994483]\n",
      "epoch:27 step:25387 [D loss: 0.413341, acc.: 83.59%] [G loss: 1.270456]\n",
      "epoch:27 step:25388 [D loss: 0.382449, acc.: 88.28%] [G loss: 1.365575]\n",
      "epoch:27 step:25389 [D loss: 0.410776, acc.: 87.50%] [G loss: 1.211982]\n",
      "epoch:27 step:25390 [D loss: 0.432272, acc.: 78.91%] [G loss: 1.698578]\n",
      "epoch:27 step:25391 [D loss: 0.444687, acc.: 71.09%] [G loss: 1.325375]\n",
      "epoch:27 step:25392 [D loss: 0.201003, acc.: 97.66%] [G loss: 2.101577]\n",
      "epoch:27 step:25393 [D loss: 0.509817, acc.: 78.12%] [G loss: 2.068373]\n",
      "epoch:27 step:25394 [D loss: 0.691386, acc.: 64.84%] [G loss: 1.209468]\n",
      "epoch:27 step:25395 [D loss: 0.512802, acc.: 77.34%] [G loss: 1.461881]\n",
      "epoch:27 step:25396 [D loss: 0.464260, acc.: 82.03%] [G loss: 0.789695]\n",
      "epoch:27 step:25397 [D loss: 0.671214, acc.: 60.94%] [G loss: 1.821316]\n",
      "epoch:27 step:25398 [D loss: 0.586330, acc.: 69.53%] [G loss: 0.923584]\n",
      "epoch:27 step:25399 [D loss: 0.707141, acc.: 61.72%] [G loss: 1.139460]\n",
      "epoch:27 step:25400 [D loss: 0.626533, acc.: 65.62%] [G loss: 1.424066]\n",
      "##############\n",
      "[4.4406638  2.53338234 7.15260499 5.53839836 4.37127154 6.13450735\n",
      " 5.25222331 5.45415316 6.07522071 4.92351434]\n",
      "##########\n",
      "epoch:27 step:25401 [D loss: 0.764309, acc.: 54.69%] [G loss: 1.441427]\n",
      "epoch:27 step:25402 [D loss: 0.625581, acc.: 67.97%] [G loss: 1.537772]\n",
      "epoch:27 step:25403 [D loss: 0.673466, acc.: 63.28%] [G loss: 1.050306]\n",
      "epoch:27 step:25404 [D loss: 0.673811, acc.: 64.06%] [G loss: 1.155817]\n",
      "epoch:27 step:25405 [D loss: 0.589369, acc.: 69.53%] [G loss: 1.097431]\n",
      "epoch:27 step:25406 [D loss: 0.372993, acc.: 86.72%] [G loss: 0.949354]\n",
      "epoch:27 step:25407 [D loss: 0.527949, acc.: 75.00%] [G loss: 1.143084]\n",
      "epoch:27 step:25408 [D loss: 0.727258, acc.: 54.69%] [G loss: 0.791981]\n",
      "epoch:27 step:25409 [D loss: 0.632958, acc.: 66.41%] [G loss: 1.101760]\n",
      "epoch:27 step:25410 [D loss: 0.314460, acc.: 89.06%] [G loss: 1.509923]\n",
      "epoch:27 step:25411 [D loss: 0.571263, acc.: 68.75%] [G loss: 1.454313]\n",
      "epoch:27 step:25412 [D loss: 0.340250, acc.: 89.84%] [G loss: 1.103242]\n",
      "epoch:27 step:25413 [D loss: 0.321114, acc.: 87.50%] [G loss: 1.217672]\n",
      "epoch:27 step:25414 [D loss: 0.315024, acc.: 89.06%] [G loss: 1.281226]\n",
      "epoch:27 step:25415 [D loss: 0.806535, acc.: 51.56%] [G loss: 1.205444]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:27 step:25416 [D loss: 0.454523, acc.: 82.81%] [G loss: 1.676761]\n",
      "epoch:27 step:25417 [D loss: 0.352073, acc.: 88.28%] [G loss: 1.580229]\n",
      "epoch:27 step:25418 [D loss: 0.236861, acc.: 91.41%] [G loss: 1.824484]\n",
      "epoch:27 step:25419 [D loss: 0.328380, acc.: 82.03%] [G loss: 1.383640]\n",
      "epoch:27 step:25420 [D loss: 0.203058, acc.: 93.75%] [G loss: 1.910527]\n",
      "epoch:27 step:25421 [D loss: 0.219697, acc.: 93.75%] [G loss: 2.149003]\n",
      "epoch:27 step:25422 [D loss: 0.803614, acc.: 53.12%] [G loss: 1.624881]\n",
      "epoch:27 step:25423 [D loss: 0.891990, acc.: 51.56%] [G loss: 1.753766]\n",
      "epoch:27 step:25424 [D loss: 0.900055, acc.: 42.97%] [G loss: 1.547178]\n",
      "epoch:27 step:25425 [D loss: 0.814215, acc.: 55.47%] [G loss: 1.301436]\n",
      "epoch:27 step:25426 [D loss: 0.867449, acc.: 49.22%] [G loss: 1.354961]\n",
      "epoch:27 step:25427 [D loss: 0.582305, acc.: 72.66%] [G loss: 1.298144]\n",
      "epoch:27 step:25428 [D loss: 0.315172, acc.: 88.28%] [G loss: 1.365381]\n",
      "epoch:27 step:25429 [D loss: 0.284219, acc.: 92.97%] [G loss: 1.597837]\n",
      "epoch:27 step:25430 [D loss: 0.235291, acc.: 98.44%] [G loss: 0.974011]\n",
      "epoch:27 step:25431 [D loss: 0.582455, acc.: 68.75%] [G loss: 1.487042]\n",
      "epoch:27 step:25432 [D loss: 0.361965, acc.: 82.81%] [G loss: 1.873311]\n",
      "epoch:27 step:25433 [D loss: 0.232852, acc.: 94.53%] [G loss: 1.672162]\n",
      "epoch:27 step:25434 [D loss: 0.246291, acc.: 95.31%] [G loss: 1.409850]\n",
      "epoch:27 step:25435 [D loss: 0.691298, acc.: 62.50%] [G loss: 1.471827]\n",
      "epoch:27 step:25436 [D loss: 0.717454, acc.: 60.94%] [G loss: 1.888133]\n",
      "epoch:27 step:25437 [D loss: 0.571755, acc.: 69.53%] [G loss: 1.558654]\n",
      "epoch:27 step:25438 [D loss: 0.431596, acc.: 79.69%] [G loss: 1.781315]\n",
      "epoch:27 step:25439 [D loss: 0.225969, acc.: 92.19%] [G loss: 1.579262]\n",
      "epoch:27 step:25440 [D loss: 0.156314, acc.: 97.66%] [G loss: 1.905291]\n",
      "epoch:27 step:25441 [D loss: 0.348779, acc.: 89.06%] [G loss: 1.496415]\n",
      "epoch:27 step:25442 [D loss: 0.200769, acc.: 95.31%] [G loss: 1.528644]\n",
      "epoch:27 step:25443 [D loss: 0.656933, acc.: 67.97%] [G loss: 2.029092]\n",
      "epoch:27 step:25444 [D loss: 0.227128, acc.: 93.75%] [G loss: 1.931780]\n",
      "epoch:27 step:25445 [D loss: 0.473077, acc.: 76.56%] [G loss: 1.786585]\n",
      "epoch:27 step:25446 [D loss: 0.539789, acc.: 71.88%] [G loss: 1.832185]\n",
      "epoch:27 step:25447 [D loss: 0.823492, acc.: 48.44%] [G loss: 1.489403]\n",
      "epoch:27 step:25448 [D loss: 0.186375, acc.: 96.09%] [G loss: 1.869325]\n",
      "epoch:27 step:25449 [D loss: 0.201967, acc.: 93.75%] [G loss: 1.735205]\n",
      "epoch:27 step:25450 [D loss: 0.188495, acc.: 98.44%] [G loss: 2.098142]\n",
      "epoch:27 step:25451 [D loss: 0.184385, acc.: 96.88%] [G loss: 1.917932]\n",
      "epoch:27 step:25452 [D loss: 0.811948, acc.: 55.47%] [G loss: 1.421818]\n",
      "epoch:27 step:25453 [D loss: 0.686391, acc.: 59.38%] [G loss: 0.590507]\n",
      "epoch:27 step:25454 [D loss: 0.693564, acc.: 59.38%] [G loss: 1.152348]\n",
      "epoch:27 step:25455 [D loss: 0.720494, acc.: 57.03%] [G loss: 1.106386]\n",
      "epoch:27 step:25456 [D loss: 0.983708, acc.: 39.06%] [G loss: 1.228681]\n",
      "epoch:27 step:25457 [D loss: 0.713629, acc.: 57.03%] [G loss: 1.014736]\n",
      "epoch:27 step:25458 [D loss: 0.851227, acc.: 40.62%] [G loss: 1.063186]\n",
      "epoch:27 step:25459 [D loss: 0.543612, acc.: 73.44%] [G loss: 1.292037]\n",
      "epoch:27 step:25460 [D loss: 0.474935, acc.: 82.81%] [G loss: 0.979184]\n",
      "epoch:27 step:25461 [D loss: 0.433075, acc.: 80.47%] [G loss: 1.368005]\n",
      "epoch:27 step:25462 [D loss: 0.424460, acc.: 85.94%] [G loss: 1.486537]\n",
      "epoch:27 step:25463 [D loss: 0.365707, acc.: 92.19%] [G loss: 0.985388]\n",
      "epoch:27 step:25464 [D loss: 0.361861, acc.: 88.28%] [G loss: 1.374735]\n",
      "epoch:27 step:25465 [D loss: 0.623392, acc.: 67.19%] [G loss: 0.923279]\n",
      "epoch:27 step:25466 [D loss: 0.637136, acc.: 63.28%] [G loss: 0.890069]\n",
      "epoch:27 step:25467 [D loss: 1.156881, acc.: 36.72%] [G loss: 1.176050]\n",
      "epoch:27 step:25468 [D loss: 0.568171, acc.: 73.44%] [G loss: 1.526652]\n",
      "epoch:27 step:25469 [D loss: 0.472453, acc.: 80.47%] [G loss: 1.235609]\n",
      "epoch:27 step:25470 [D loss: 0.701208, acc.: 55.47%] [G loss: 1.400672]\n",
      "epoch:27 step:25471 [D loss: 0.594835, acc.: 66.41%] [G loss: 1.444237]\n",
      "epoch:27 step:25472 [D loss: 0.803121, acc.: 44.53%] [G loss: 1.479190]\n",
      "epoch:27 step:25473 [D loss: 0.471909, acc.: 79.69%] [G loss: 0.957638]\n",
      "epoch:27 step:25474 [D loss: 0.661105, acc.: 60.16%] [G loss: 0.851627]\n",
      "epoch:27 step:25475 [D loss: 0.672056, acc.: 56.25%] [G loss: 0.884328]\n",
      "epoch:27 step:25476 [D loss: 0.768235, acc.: 48.44%] [G loss: 1.087193]\n",
      "epoch:27 step:25477 [D loss: 0.553227, acc.: 70.31%] [G loss: 1.065624]\n",
      "epoch:27 step:25478 [D loss: 0.380883, acc.: 87.50%] [G loss: 1.353890]\n",
      "epoch:27 step:25479 [D loss: 0.561155, acc.: 70.31%] [G loss: 0.880406]\n",
      "epoch:27 step:25480 [D loss: 0.661542, acc.: 66.41%] [G loss: 1.220639]\n",
      "epoch:27 step:25481 [D loss: 0.683653, acc.: 62.50%] [G loss: 0.507273]\n",
      "epoch:27 step:25482 [D loss: 0.647830, acc.: 62.50%] [G loss: 1.124765]\n",
      "epoch:27 step:25483 [D loss: 0.687113, acc.: 63.28%] [G loss: 1.355016]\n",
      "epoch:27 step:25484 [D loss: 0.612907, acc.: 65.62%] [G loss: 1.383553]\n",
      "epoch:27 step:25485 [D loss: 0.572861, acc.: 72.66%] [G loss: 1.497149]\n",
      "epoch:27 step:25486 [D loss: 0.647944, acc.: 57.81%] [G loss: 1.414096]\n",
      "epoch:27 step:25487 [D loss: 0.650776, acc.: 64.84%] [G loss: 1.411129]\n",
      "epoch:27 step:25488 [D loss: 0.615566, acc.: 61.72%] [G loss: 1.278324]\n",
      "epoch:27 step:25489 [D loss: 0.485231, acc.: 82.03%] [G loss: 1.223358]\n",
      "epoch:27 step:25490 [D loss: 0.517189, acc.: 72.66%] [G loss: 1.077069]\n",
      "epoch:27 step:25491 [D loss: 0.313896, acc.: 86.72%] [G loss: 1.662252]\n",
      "epoch:27 step:25492 [D loss: 0.339883, acc.: 88.28%] [G loss: 1.637506]\n",
      "epoch:27 step:25493 [D loss: 0.143080, acc.: 100.00%] [G loss: 1.512983]\n",
      "epoch:27 step:25494 [D loss: 0.385765, acc.: 92.97%] [G loss: 1.750115]\n",
      "epoch:27 step:25495 [D loss: 0.386949, acc.: 86.72%] [G loss: 1.365125]\n",
      "epoch:27 step:25496 [D loss: 0.447028, acc.: 82.03%] [G loss: 1.541939]\n",
      "epoch:27 step:25497 [D loss: 0.316246, acc.: 90.62%] [G loss: 1.734220]\n",
      "epoch:27 step:25498 [D loss: 0.924146, acc.: 37.50%] [G loss: 1.495468]\n",
      "epoch:27 step:25499 [D loss: 0.164253, acc.: 96.09%] [G loss: 1.953383]\n",
      "epoch:27 step:25500 [D loss: 0.321104, acc.: 81.25%] [G loss: 2.019665]\n",
      "epoch:27 step:25501 [D loss: 0.672987, acc.: 61.72%] [G loss: 2.121243]\n",
      "epoch:27 step:25502 [D loss: 0.266834, acc.: 92.19%] [G loss: 1.834915]\n",
      "epoch:27 step:25503 [D loss: 0.115911, acc.: 97.66%] [G loss: 1.626172]\n",
      "epoch:27 step:25504 [D loss: 0.241916, acc.: 97.66%] [G loss: 2.497086]\n",
      "epoch:27 step:25505 [D loss: 0.122910, acc.: 97.66%] [G loss: 1.869070]\n",
      "epoch:27 step:25506 [D loss: 0.114800, acc.: 98.44%] [G loss: 2.064610]\n",
      "epoch:27 step:25507 [D loss: 0.099990, acc.: 99.22%] [G loss: 2.063300]\n",
      "epoch:27 step:25508 [D loss: 0.108992, acc.: 98.44%] [G loss: 2.714338]\n",
      "epoch:27 step:25509 [D loss: 1.391457, acc.: 35.94%] [G loss: 1.757709]\n",
      "epoch:27 step:25510 [D loss: 0.972854, acc.: 49.22%] [G loss: 1.380023]\n",
      "epoch:27 step:25511 [D loss: 0.728983, acc.: 57.81%] [G loss: 1.322502]\n",
      "epoch:27 step:25512 [D loss: 0.753452, acc.: 50.00%] [G loss: 1.170690]\n",
      "epoch:27 step:25513 [D loss: 0.890101, acc.: 46.09%] [G loss: 0.966259]\n",
      "epoch:27 step:25514 [D loss: 0.972202, acc.: 28.12%] [G loss: 0.541957]\n",
      "epoch:27 step:25515 [D loss: 0.841585, acc.: 42.19%] [G loss: 1.097130]\n",
      "epoch:27 step:25516 [D loss: 0.445120, acc.: 80.47%] [G loss: 1.341987]\n",
      "epoch:27 step:25517 [D loss: 0.208433, acc.: 94.53%] [G loss: 1.203762]\n",
      "epoch:27 step:25518 [D loss: 0.214982, acc.: 97.66%] [G loss: 1.523541]\n",
      "epoch:27 step:25519 [D loss: 0.367769, acc.: 78.91%] [G loss: 0.828220]\n",
      "epoch:27 step:25520 [D loss: 0.214378, acc.: 90.62%] [G loss: 1.414947]\n",
      "epoch:27 step:25521 [D loss: 0.246057, acc.: 94.53%] [G loss: 1.025003]\n",
      "epoch:27 step:25522 [D loss: 0.240979, acc.: 96.09%] [G loss: 2.034313]\n",
      "epoch:27 step:25523 [D loss: 0.609683, acc.: 66.41%] [G loss: 1.620279]\n",
      "epoch:27 step:25524 [D loss: 0.471798, acc.: 78.12%] [G loss: 1.795021]\n",
      "epoch:27 step:25525 [D loss: 0.858014, acc.: 42.97%] [G loss: 1.223003]\n",
      "epoch:27 step:25526 [D loss: 0.536679, acc.: 74.22%] [G loss: 1.507287]\n",
      "epoch:27 step:25527 [D loss: 0.733999, acc.: 56.25%] [G loss: 1.823348]\n",
      "epoch:27 step:25528 [D loss: 0.631055, acc.: 61.72%] [G loss: 1.240103]\n",
      "epoch:27 step:25529 [D loss: 0.170038, acc.: 96.09%] [G loss: 1.578014]\n",
      "epoch:27 step:25530 [D loss: 0.180800, acc.: 96.88%] [G loss: 1.952695]\n",
      "epoch:27 step:25531 [D loss: 0.104280, acc.: 99.22%] [G loss: 1.620204]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:27 step:25532 [D loss: 0.404844, acc.: 82.03%] [G loss: 1.929137]\n",
      "epoch:27 step:25533 [D loss: 0.175438, acc.: 96.88%] [G loss: 1.649797]\n",
      "epoch:27 step:25534 [D loss: 0.275876, acc.: 90.62%] [G loss: 1.894342]\n",
      "epoch:27 step:25535 [D loss: 0.512585, acc.: 68.75%] [G loss: 1.801124]\n",
      "epoch:27 step:25536 [D loss: 0.257817, acc.: 93.75%] [G loss: 1.092155]\n",
      "epoch:27 step:25537 [D loss: 0.260417, acc.: 94.53%] [G loss: 2.013217]\n",
      "epoch:27 step:25538 [D loss: 0.518624, acc.: 73.44%] [G loss: 1.944880]\n",
      "epoch:27 step:25539 [D loss: 0.557676, acc.: 70.31%] [G loss: 1.603703]\n",
      "epoch:27 step:25540 [D loss: 0.794152, acc.: 52.34%] [G loss: 0.636064]\n",
      "epoch:27 step:25541 [D loss: 0.605227, acc.: 68.75%] [G loss: 1.352705]\n",
      "epoch:27 step:25542 [D loss: 0.401569, acc.: 78.91%] [G loss: 1.599032]\n",
      "epoch:27 step:25543 [D loss: 0.478172, acc.: 79.69%] [G loss: 1.528074]\n",
      "epoch:27 step:25544 [D loss: 0.614589, acc.: 65.62%] [G loss: 1.367111]\n",
      "epoch:27 step:25545 [D loss: 0.659505, acc.: 60.94%] [G loss: 0.660320]\n",
      "epoch:27 step:25546 [D loss: 0.613914, acc.: 63.28%] [G loss: 1.094535]\n",
      "epoch:27 step:25547 [D loss: 0.555158, acc.: 75.78%] [G loss: 1.212251]\n",
      "epoch:27 step:25548 [D loss: 0.421898, acc.: 85.94%] [G loss: 0.971697]\n",
      "epoch:27 step:25549 [D loss: 0.837190, acc.: 35.94%] [G loss: 0.816769]\n",
      "epoch:27 step:25550 [D loss: 0.441763, acc.: 77.34%] [G loss: 1.246636]\n",
      "epoch:27 step:25551 [D loss: 0.550799, acc.: 74.22%] [G loss: 1.337227]\n",
      "epoch:27 step:25552 [D loss: 0.466165, acc.: 80.47%] [G loss: 1.511117]\n",
      "epoch:27 step:25553 [D loss: 0.265046, acc.: 96.88%] [G loss: 1.377603]\n",
      "epoch:27 step:25554 [D loss: 0.190072, acc.: 98.44%] [G loss: 1.542954]\n",
      "epoch:27 step:25555 [D loss: 0.120826, acc.: 100.00%] [G loss: 1.208438]\n",
      "epoch:27 step:25556 [D loss: 0.541541, acc.: 66.41%] [G loss: 1.352230]\n",
      "epoch:27 step:25557 [D loss: 0.420008, acc.: 81.25%] [G loss: 1.951261]\n",
      "epoch:27 step:25558 [D loss: 0.155325, acc.: 96.09%] [G loss: 2.128580]\n",
      "epoch:27 step:25559 [D loss: 0.085036, acc.: 100.00%] [G loss: 2.195275]\n",
      "epoch:27 step:25560 [D loss: 0.204514, acc.: 95.31%] [G loss: 2.706816]\n",
      "epoch:27 step:25561 [D loss: 0.663879, acc.: 59.38%] [G loss: 2.387685]\n",
      "epoch:27 step:25562 [D loss: 0.687608, acc.: 61.72%] [G loss: 0.835652]\n",
      "epoch:27 step:25563 [D loss: 0.699401, acc.: 60.94%] [G loss: 1.502918]\n",
      "epoch:27 step:25564 [D loss: 0.540739, acc.: 67.97%] [G loss: 1.077492]\n",
      "epoch:27 step:25565 [D loss: 0.841038, acc.: 41.41%] [G loss: 1.542970]\n",
      "epoch:27 step:25566 [D loss: 0.521419, acc.: 73.44%] [G loss: 1.269363]\n",
      "epoch:27 step:25567 [D loss: 0.798023, acc.: 46.88%] [G loss: 0.891834]\n",
      "epoch:27 step:25568 [D loss: 0.304298, acc.: 96.09%] [G loss: 0.657517]\n",
      "epoch:27 step:25569 [D loss: 0.764598, acc.: 57.81%] [G loss: 0.585256]\n",
      "epoch:27 step:25570 [D loss: 0.441847, acc.: 85.16%] [G loss: 1.106752]\n",
      "epoch:27 step:25571 [D loss: 0.372460, acc.: 89.84%] [G loss: 1.317477]\n",
      "epoch:27 step:25572 [D loss: 0.557530, acc.: 69.53%] [G loss: 1.311860]\n",
      "epoch:27 step:25573 [D loss: 0.470694, acc.: 79.69%] [G loss: 1.274241]\n",
      "epoch:27 step:25574 [D loss: 0.412758, acc.: 86.72%] [G loss: 1.245577]\n",
      "epoch:27 step:25575 [D loss: 0.286045, acc.: 94.53%] [G loss: 1.400680]\n",
      "epoch:27 step:25576 [D loss: 0.383375, acc.: 88.28%] [G loss: 1.476108]\n",
      "epoch:27 step:25577 [D loss: 0.259679, acc.: 93.75%] [G loss: 1.752883]\n",
      "epoch:27 step:25578 [D loss: 0.134682, acc.: 99.22%] [G loss: 1.909507]\n",
      "epoch:27 step:25579 [D loss: 0.585931, acc.: 72.66%] [G loss: 1.790065]\n",
      "epoch:27 step:25580 [D loss: 0.848737, acc.: 48.44%] [G loss: 1.302764]\n",
      "epoch:27 step:25581 [D loss: 0.637610, acc.: 64.84%] [G loss: 1.378338]\n",
      "epoch:27 step:25582 [D loss: 0.634677, acc.: 67.19%] [G loss: 0.750653]\n",
      "epoch:27 step:25583 [D loss: 0.229773, acc.: 96.09%] [G loss: 1.524956]\n",
      "epoch:27 step:25584 [D loss: 0.313045, acc.: 93.75%] [G loss: 1.022810]\n",
      "epoch:27 step:25585 [D loss: 0.366802, acc.: 85.94%] [G loss: 2.054684]\n",
      "epoch:27 step:25586 [D loss: 0.140581, acc.: 97.66%] [G loss: 1.588201]\n",
      "epoch:27 step:25587 [D loss: 0.195491, acc.: 98.44%] [G loss: 1.858949]\n",
      "epoch:27 step:25588 [D loss: 0.154947, acc.: 97.66%] [G loss: 2.036522]\n",
      "epoch:27 step:25589 [D loss: 0.196888, acc.: 95.31%] [G loss: 1.436795]\n",
      "epoch:27 step:25590 [D loss: 0.315145, acc.: 87.50%] [G loss: 2.234325]\n",
      "epoch:27 step:25591 [D loss: 0.601701, acc.: 70.31%] [G loss: 2.280446]\n",
      "epoch:27 step:25592 [D loss: 0.090365, acc.: 100.00%] [G loss: 2.773269]\n",
      "epoch:27 step:25593 [D loss: 0.944741, acc.: 58.59%] [G loss: 2.103999]\n",
      "epoch:27 step:25594 [D loss: 0.720819, acc.: 56.25%] [G loss: 2.001090]\n",
      "epoch:27 step:25595 [D loss: 0.653026, acc.: 57.81%] [G loss: 1.461299]\n",
      "epoch:27 step:25596 [D loss: 0.213143, acc.: 95.31%] [G loss: 1.325039]\n",
      "epoch:27 step:25597 [D loss: 0.147546, acc.: 99.22%] [G loss: 1.327986]\n",
      "epoch:27 step:25598 [D loss: 0.202167, acc.: 95.31%] [G loss: 1.949633]\n",
      "epoch:27 step:25599 [D loss: 0.374260, acc.: 83.59%] [G loss: 2.397369]\n",
      "epoch:27 step:25600 [D loss: 0.534083, acc.: 71.09%] [G loss: 1.395951]\n",
      "##############\n",
      "[3.87969275 2.48229853 6.58717706 5.6925614  4.44432482 6.27275415\n",
      " 5.11719698 5.41858584 5.68032183 4.85867389]\n",
      "##########\n",
      "epoch:27 step:25601 [D loss: 0.584398, acc.: 69.53%] [G loss: 0.412804]\n",
      "epoch:27 step:25602 [D loss: 1.232892, acc.: 44.53%] [G loss: 1.744308]\n",
      "epoch:27 step:25603 [D loss: 0.706072, acc.: 60.16%] [G loss: 2.090729]\n",
      "epoch:27 step:25604 [D loss: 0.533254, acc.: 75.00%] [G loss: 1.650789]\n",
      "epoch:27 step:25605 [D loss: 0.515978, acc.: 68.75%] [G loss: 0.944872]\n",
      "epoch:27 step:25606 [D loss: 0.225096, acc.: 95.31%] [G loss: 0.756814]\n",
      "epoch:27 step:25607 [D loss: 0.762986, acc.: 57.81%] [G loss: 1.157205]\n",
      "epoch:27 step:25608 [D loss: 0.395272, acc.: 82.03%] [G loss: 1.435737]\n",
      "epoch:27 step:25609 [D loss: 0.596883, acc.: 71.88%] [G loss: 1.008608]\n",
      "epoch:27 step:25610 [D loss: 0.878273, acc.: 52.34%] [G loss: 0.851454]\n",
      "epoch:27 step:25611 [D loss: 0.579484, acc.: 71.09%] [G loss: 1.425539]\n",
      "epoch:27 step:25612 [D loss: 0.231392, acc.: 94.53%] [G loss: 1.596603]\n",
      "epoch:27 step:25613 [D loss: 0.234869, acc.: 93.75%] [G loss: 2.179241]\n",
      "epoch:27 step:25614 [D loss: 0.606008, acc.: 73.44%] [G loss: 1.780299]\n",
      "epoch:27 step:25615 [D loss: 0.201511, acc.: 96.09%] [G loss: 2.061743]\n",
      "epoch:27 step:25616 [D loss: 0.484258, acc.: 81.25%] [G loss: 1.402225]\n",
      "epoch:27 step:25617 [D loss: 0.284661, acc.: 96.09%] [G loss: 1.240134]\n",
      "epoch:27 step:25618 [D loss: 0.356081, acc.: 90.62%] [G loss: 1.527335]\n",
      "epoch:27 step:25619 [D loss: 0.388268, acc.: 81.25%] [G loss: 1.724865]\n",
      "epoch:27 step:25620 [D loss: 0.240725, acc.: 96.88%] [G loss: 2.062979]\n",
      "epoch:27 step:25621 [D loss: 0.418460, acc.: 78.91%] [G loss: 2.258479]\n",
      "epoch:27 step:25622 [D loss: 0.774156, acc.: 51.56%] [G loss: 1.614171]\n",
      "epoch:27 step:25623 [D loss: 0.761089, acc.: 58.59%] [G loss: 1.463288]\n",
      "epoch:27 step:25624 [D loss: 0.636123, acc.: 62.50%] [G loss: 1.730104]\n",
      "epoch:27 step:25625 [D loss: 0.294242, acc.: 93.75%] [G loss: 1.871362]\n",
      "epoch:27 step:25626 [D loss: 0.339740, acc.: 80.47%] [G loss: 1.911389]\n",
      "epoch:27 step:25627 [D loss: 0.168539, acc.: 95.31%] [G loss: 2.028589]\n",
      "epoch:27 step:25628 [D loss: 0.368239, acc.: 86.72%] [G loss: 2.038832]\n",
      "epoch:27 step:25629 [D loss: 1.221335, acc.: 48.44%] [G loss: 1.178997]\n",
      "epoch:27 step:25630 [D loss: 0.547780, acc.: 75.00%] [G loss: 1.212354]\n",
      "epoch:27 step:25631 [D loss: 0.577224, acc.: 65.62%] [G loss: 0.999168]\n",
      "epoch:27 step:25632 [D loss: 0.535414, acc.: 71.09%] [G loss: 1.555513]\n",
      "epoch:27 step:25633 [D loss: 0.523244, acc.: 70.31%] [G loss: 0.849760]\n",
      "epoch:27 step:25634 [D loss: 0.514614, acc.: 75.00%] [G loss: 0.437209]\n",
      "epoch:27 step:25635 [D loss: 0.325043, acc.: 88.28%] [G loss: 1.473098]\n",
      "epoch:27 step:25636 [D loss: 0.516365, acc.: 74.22%] [G loss: 1.111742]\n",
      "epoch:27 step:25637 [D loss: 0.454471, acc.: 83.59%] [G loss: 1.730574]\n",
      "epoch:27 step:25638 [D loss: 0.435330, acc.: 80.47%] [G loss: 1.389347]\n",
      "epoch:27 step:25639 [D loss: 0.892676, acc.: 48.44%] [G loss: 1.685439]\n",
      "epoch:27 step:25640 [D loss: 1.106778, acc.: 26.56%] [G loss: 1.145971]\n",
      "epoch:27 step:25641 [D loss: 0.164463, acc.: 96.88%] [G loss: 1.712389]\n",
      "epoch:27 step:25642 [D loss: 0.320154, acc.: 78.91%] [G loss: 1.797148]\n",
      "epoch:27 step:25643 [D loss: 0.209708, acc.: 94.53%] [G loss: 1.665427]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:27 step:25644 [D loss: 0.192544, acc.: 94.53%] [G loss: 1.868590]\n",
      "epoch:27 step:25645 [D loss: 0.132941, acc.: 96.88%] [G loss: 2.464586]\n",
      "epoch:27 step:25646 [D loss: 0.102943, acc.: 99.22%] [G loss: 1.935450]\n",
      "epoch:27 step:25647 [D loss: 0.567043, acc.: 71.88%] [G loss: 1.952767]\n",
      "epoch:27 step:25648 [D loss: 0.723321, acc.: 61.72%] [G loss: 1.957214]\n",
      "epoch:27 step:25649 [D loss: 0.293392, acc.: 93.75%] [G loss: 1.506958]\n",
      "epoch:27 step:25650 [D loss: 0.749134, acc.: 55.47%] [G loss: 1.258765]\n",
      "epoch:27 step:25651 [D loss: 0.209280, acc.: 96.88%] [G loss: 1.544608]\n",
      "epoch:27 step:25652 [D loss: 0.377963, acc.: 88.28%] [G loss: 2.112792]\n",
      "epoch:27 step:25653 [D loss: 0.417385, acc.: 82.81%] [G loss: 1.728628]\n",
      "epoch:27 step:25654 [D loss: 0.892618, acc.: 40.62%] [G loss: 1.076173]\n",
      "epoch:27 step:25655 [D loss: 0.782624, acc.: 53.91%] [G loss: 1.454076]\n",
      "epoch:27 step:25656 [D loss: 0.447219, acc.: 79.69%] [G loss: 0.513311]\n",
      "epoch:27 step:25657 [D loss: 0.186378, acc.: 99.22%] [G loss: 1.297027]\n",
      "epoch:27 step:25658 [D loss: 0.370739, acc.: 85.16%] [G loss: 1.488167]\n",
      "epoch:27 step:25659 [D loss: 0.404329, acc.: 83.59%] [G loss: 1.474796]\n",
      "epoch:27 step:25660 [D loss: 0.972192, acc.: 39.84%] [G loss: 1.507233]\n",
      "epoch:27 step:25661 [D loss: 0.424433, acc.: 81.25%] [G loss: 1.711720]\n",
      "epoch:27 step:25662 [D loss: 0.353347, acc.: 84.38%] [G loss: 1.788848]\n",
      "epoch:27 step:25663 [D loss: 0.526148, acc.: 75.78%] [G loss: 1.834062]\n",
      "epoch:27 step:25664 [D loss: 0.111047, acc.: 100.00%] [G loss: 2.313209]\n",
      "epoch:27 step:25665 [D loss: 0.215595, acc.: 94.53%] [G loss: 2.379403]\n",
      "epoch:27 step:25666 [D loss: 0.149941, acc.: 97.66%] [G loss: 2.500414]\n",
      "epoch:27 step:25667 [D loss: 0.704581, acc.: 60.16%] [G loss: 1.438629]\n",
      "epoch:27 step:25668 [D loss: 0.491189, acc.: 74.22%] [G loss: 1.679752]\n",
      "epoch:27 step:25669 [D loss: 0.380569, acc.: 88.28%] [G loss: 1.212293]\n",
      "epoch:27 step:25670 [D loss: 0.377153, acc.: 86.72%] [G loss: 1.549417]\n",
      "epoch:27 step:25671 [D loss: 0.997235, acc.: 34.38%] [G loss: 1.230006]\n",
      "epoch:27 step:25672 [D loss: 0.548667, acc.: 76.56%] [G loss: 1.084398]\n",
      "epoch:27 step:25673 [D loss: 0.763322, acc.: 51.56%] [G loss: 1.187420]\n",
      "epoch:27 step:25674 [D loss: 0.342176, acc.: 86.72%] [G loss: 1.297096]\n",
      "epoch:27 step:25675 [D loss: 0.704821, acc.: 57.81%] [G loss: 1.376578]\n",
      "epoch:27 step:25676 [D loss: 0.196095, acc.: 92.19%] [G loss: 1.784284]\n",
      "epoch:27 step:25677 [D loss: 0.117195, acc.: 99.22%] [G loss: 1.622146]\n",
      "epoch:27 step:25678 [D loss: 0.945670, acc.: 45.31%] [G loss: 1.621189]\n",
      "epoch:27 step:25679 [D loss: 0.558207, acc.: 73.44%] [G loss: 1.544540]\n",
      "epoch:27 step:25680 [D loss: 0.428513, acc.: 87.50%] [G loss: 1.098419]\n",
      "epoch:27 step:25681 [D loss: 0.756397, acc.: 50.78%] [G loss: 1.452982]\n",
      "epoch:27 step:25682 [D loss: 0.537681, acc.: 75.00%] [G loss: 1.581842]\n",
      "epoch:27 step:25683 [D loss: 0.291289, acc.: 89.84%] [G loss: 1.389591]\n",
      "epoch:27 step:25684 [D loss: 0.512539, acc.: 75.00%] [G loss: 1.563199]\n",
      "epoch:27 step:25685 [D loss: 0.581965, acc.: 71.88%] [G loss: 0.879478]\n",
      "epoch:27 step:25686 [D loss: 0.466888, acc.: 82.03%] [G loss: 1.260206]\n",
      "epoch:27 step:25687 [D loss: 0.271733, acc.: 93.75%] [G loss: 1.674107]\n",
      "epoch:27 step:25688 [D loss: 0.180689, acc.: 98.44%] [G loss: 1.603124]\n",
      "epoch:27 step:25689 [D loss: 0.373084, acc.: 80.47%] [G loss: 1.572015]\n",
      "epoch:27 step:25690 [D loss: 0.813778, acc.: 47.66%] [G loss: 1.373634]\n",
      "epoch:27 step:25691 [D loss: 0.376199, acc.: 89.84%] [G loss: 1.627499]\n",
      "epoch:27 step:25692 [D loss: 0.326664, acc.: 83.59%] [G loss: 1.575318]\n",
      "epoch:27 step:25693 [D loss: 0.462827, acc.: 78.12%] [G loss: 0.795401]\n",
      "epoch:27 step:25694 [D loss: 0.912763, acc.: 42.19%] [G loss: 2.046596]\n",
      "epoch:27 step:25695 [D loss: 0.382062, acc.: 75.00%] [G loss: 1.181524]\n",
      "epoch:27 step:25696 [D loss: 0.212297, acc.: 92.19%] [G loss: 1.862823]\n",
      "epoch:27 step:25697 [D loss: 0.104816, acc.: 99.22%] [G loss: 1.494246]\n",
      "epoch:27 step:25698 [D loss: 0.095728, acc.: 99.22%] [G loss: 1.331453]\n",
      "epoch:27 step:25699 [D loss: 0.430152, acc.: 71.88%] [G loss: 2.741547]\n",
      "epoch:27 step:25700 [D loss: 0.162787, acc.: 98.44%] [G loss: 2.303909]\n",
      "epoch:27 step:25701 [D loss: 0.075638, acc.: 100.00%] [G loss: 1.555256]\n",
      "epoch:27 step:25702 [D loss: 0.310259, acc.: 95.31%] [G loss: 2.757813]\n",
      "epoch:27 step:25703 [D loss: 0.134196, acc.: 98.44%] [G loss: 1.878027]\n",
      "epoch:27 step:25704 [D loss: 0.160804, acc.: 97.66%] [G loss: 3.010536]\n",
      "epoch:27 step:25705 [D loss: 0.060651, acc.: 100.00%] [G loss: 2.206194]\n",
      "epoch:27 step:25706 [D loss: 0.165967, acc.: 93.75%] [G loss: 1.422779]\n",
      "epoch:27 step:25707 [D loss: 0.513475, acc.: 72.66%] [G loss: 3.084981]\n",
      "epoch:27 step:25708 [D loss: 0.135202, acc.: 97.66%] [G loss: 2.225831]\n",
      "epoch:27 step:25709 [D loss: 0.488367, acc.: 76.56%] [G loss: 2.000098]\n",
      "epoch:27 step:25710 [D loss: 1.650012, acc.: 25.78%] [G loss: 2.557268]\n",
      "epoch:27 step:25711 [D loss: 0.699421, acc.: 63.28%] [G loss: 1.912817]\n",
      "epoch:27 step:25712 [D loss: 0.351435, acc.: 85.16%] [G loss: 0.987707]\n",
      "epoch:27 step:25713 [D loss: 0.517542, acc.: 74.22%] [G loss: 0.400633]\n",
      "epoch:27 step:25714 [D loss: 0.515840, acc.: 75.00%] [G loss: 1.104891]\n",
      "epoch:27 step:25715 [D loss: 0.814540, acc.: 52.34%] [G loss: 1.442096]\n",
      "epoch:27 step:25716 [D loss: 0.532111, acc.: 75.00%] [G loss: 1.480376]\n",
      "epoch:27 step:25717 [D loss: 0.364198, acc.: 84.38%] [G loss: 0.842707]\n",
      "epoch:27 step:25718 [D loss: 0.873495, acc.: 60.94%] [G loss: 3.090594]\n",
      "epoch:27 step:25719 [D loss: 0.820431, acc.: 57.81%] [G loss: 2.841558]\n",
      "epoch:27 step:25720 [D loss: 1.231440, acc.: 43.75%] [G loss: 1.426461]\n",
      "epoch:27 step:25721 [D loss: 1.215270, acc.: 31.25%] [G loss: 0.451880]\n",
      "epoch:27 step:25722 [D loss: 0.899406, acc.: 46.09%] [G loss: 1.006670]\n",
      "epoch:27 step:25723 [D loss: 0.327884, acc.: 87.50%] [G loss: 1.760532]\n",
      "epoch:27 step:25724 [D loss: 0.390597, acc.: 78.91%] [G loss: 0.990750]\n",
      "epoch:27 step:25725 [D loss: 1.125706, acc.: 29.69%] [G loss: 1.676607]\n",
      "epoch:27 step:25726 [D loss: 0.239503, acc.: 93.75%] [G loss: 1.896256]\n",
      "epoch:27 step:25727 [D loss: 0.749769, acc.: 60.16%] [G loss: 2.475152]\n",
      "epoch:27 step:25728 [D loss: 0.765191, acc.: 56.25%] [G loss: 1.927425]\n",
      "epoch:27 step:25729 [D loss: 0.258484, acc.: 91.41%] [G loss: 2.241992]\n",
      "epoch:27 step:25730 [D loss: 0.798476, acc.: 54.69%] [G loss: 1.550781]\n",
      "epoch:27 step:25731 [D loss: 1.269251, acc.: 44.53%] [G loss: 1.415339]\n",
      "epoch:27 step:25732 [D loss: 0.995320, acc.: 36.72%] [G loss: 1.513433]\n",
      "epoch:27 step:25733 [D loss: 0.652137, acc.: 65.62%] [G loss: 1.641307]\n",
      "epoch:27 step:25734 [D loss: 0.686252, acc.: 61.72%] [G loss: 1.675417]\n",
      "epoch:27 step:25735 [D loss: 0.558873, acc.: 70.31%] [G loss: 1.538392]\n",
      "epoch:27 step:25736 [D loss: 0.838269, acc.: 45.31%] [G loss: 1.684172]\n",
      "epoch:27 step:25737 [D loss: 0.679405, acc.: 61.72%] [G loss: 1.376044]\n",
      "epoch:27 step:25738 [D loss: 0.719668, acc.: 64.06%] [G loss: 1.456245]\n",
      "epoch:27 step:25739 [D loss: 0.659331, acc.: 64.06%] [G loss: 1.352172]\n",
      "epoch:27 step:25740 [D loss: 0.823279, acc.: 48.44%] [G loss: 1.527095]\n",
      "epoch:27 step:25741 [D loss: 0.629049, acc.: 64.06%] [G loss: 1.812247]\n",
      "epoch:27 step:25742 [D loss: 0.707529, acc.: 53.91%] [G loss: 1.307087]\n",
      "epoch:27 step:25743 [D loss: 0.611520, acc.: 63.28%] [G loss: 1.573658]\n",
      "epoch:27 step:25744 [D loss: 0.648388, acc.: 62.50%] [G loss: 1.614484]\n",
      "epoch:27 step:25745 [D loss: 0.630920, acc.: 62.50%] [G loss: 1.176879]\n",
      "epoch:27 step:25746 [D loss: 0.533763, acc.: 74.22%] [G loss: 1.387875]\n",
      "epoch:27 step:25747 [D loss: 0.602332, acc.: 71.09%] [G loss: 1.600385]\n",
      "epoch:27 step:25748 [D loss: 0.438345, acc.: 82.03%] [G loss: 1.734754]\n",
      "epoch:27 step:25749 [D loss: 0.432861, acc.: 82.03%] [G loss: 1.581115]\n",
      "epoch:27 step:25750 [D loss: 0.295080, acc.: 92.19%] [G loss: 1.632208]\n",
      "epoch:27 step:25751 [D loss: 0.253347, acc.: 95.31%] [G loss: 2.274063]\n",
      "epoch:27 step:25752 [D loss: 0.350659, acc.: 88.28%] [G loss: 2.234315]\n",
      "epoch:27 step:25753 [D loss: 0.369523, acc.: 85.94%] [G loss: 1.929525]\n",
      "epoch:27 step:25754 [D loss: 0.487911, acc.: 82.03%] [G loss: 1.914709]\n",
      "epoch:27 step:25755 [D loss: 0.264602, acc.: 93.75%] [G loss: 2.337387]\n",
      "epoch:27 step:25756 [D loss: 0.245362, acc.: 96.88%] [G loss: 2.265146]\n",
      "epoch:27 step:25757 [D loss: 0.600071, acc.: 64.84%] [G loss: 2.183101]\n",
      "epoch:27 step:25758 [D loss: 0.488593, acc.: 80.47%] [G loss: 1.951713]\n",
      "epoch:27 step:25759 [D loss: 0.696806, acc.: 60.94%] [G loss: 1.094606]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:27 step:25760 [D loss: 0.741966, acc.: 48.44%] [G loss: 1.110889]\n",
      "epoch:27 step:25761 [D loss: 1.101492, acc.: 27.34%] [G loss: 1.684709]\n",
      "epoch:27 step:25762 [D loss: 0.773054, acc.: 42.97%] [G loss: 1.034148]\n",
      "epoch:27 step:25763 [D loss: 0.470836, acc.: 77.34%] [G loss: 1.345569]\n",
      "epoch:27 step:25764 [D loss: 0.376895, acc.: 85.16%] [G loss: 1.349118]\n",
      "epoch:27 step:25765 [D loss: 0.419192, acc.: 84.38%] [G loss: 1.654753]\n",
      "epoch:27 step:25766 [D loss: 0.432060, acc.: 85.94%] [G loss: 1.385477]\n",
      "epoch:27 step:25767 [D loss: 0.174161, acc.: 96.09%] [G loss: 1.649006]\n",
      "epoch:27 step:25768 [D loss: 0.246172, acc.: 91.41%] [G loss: 1.827882]\n",
      "epoch:27 step:25769 [D loss: 0.123871, acc.: 99.22%] [G loss: 2.051838]\n",
      "epoch:27 step:25770 [D loss: 0.080300, acc.: 100.00%] [G loss: 1.971657]\n",
      "epoch:27 step:25771 [D loss: 0.284508, acc.: 96.88%] [G loss: 2.248331]\n",
      "epoch:27 step:25772 [D loss: 0.769410, acc.: 56.25%] [G loss: 1.266988]\n",
      "epoch:27 step:25773 [D loss: 0.460613, acc.: 78.91%] [G loss: 1.245533]\n",
      "epoch:27 step:25774 [D loss: 0.648130, acc.: 60.94%] [G loss: 1.125782]\n",
      "epoch:27 step:25775 [D loss: 0.686808, acc.: 63.28%] [G loss: 1.610488]\n",
      "epoch:27 step:25776 [D loss: 0.567829, acc.: 71.09%] [G loss: 1.032644]\n",
      "epoch:27 step:25777 [D loss: 0.635197, acc.: 71.09%] [G loss: 1.274221]\n",
      "epoch:27 step:25778 [D loss: 0.260221, acc.: 89.06%] [G loss: 1.784944]\n",
      "epoch:27 step:25779 [D loss: 0.337773, acc.: 90.62%] [G loss: 1.694319]\n",
      "epoch:27 step:25780 [D loss: 0.164304, acc.: 99.22%] [G loss: 1.642682]\n",
      "epoch:27 step:25781 [D loss: 0.913099, acc.: 50.00%] [G loss: 1.462376]\n",
      "epoch:27 step:25782 [D loss: 0.836073, acc.: 46.88%] [G loss: 1.124169]\n",
      "epoch:27 step:25783 [D loss: 0.387960, acc.: 82.03%] [G loss: 1.162994]\n",
      "epoch:27 step:25784 [D loss: 0.551403, acc.: 72.66%] [G loss: 1.502109]\n",
      "epoch:27 step:25785 [D loss: 0.658059, acc.: 65.62%] [G loss: 1.107207]\n",
      "epoch:27 step:25786 [D loss: 0.609137, acc.: 61.72%] [G loss: 1.456814]\n",
      "epoch:27 step:25787 [D loss: 0.490585, acc.: 80.47%] [G loss: 1.566940]\n",
      "epoch:27 step:25788 [D loss: 0.340940, acc.: 89.06%] [G loss: 1.373460]\n",
      "epoch:27 step:25789 [D loss: 0.232327, acc.: 95.31%] [G loss: 1.754045]\n",
      "epoch:27 step:25790 [D loss: 0.407552, acc.: 84.38%] [G loss: 1.919630]\n",
      "epoch:27 step:25791 [D loss: 0.672318, acc.: 63.28%] [G loss: 1.269474]\n",
      "epoch:27 step:25792 [D loss: 0.673608, acc.: 61.72%] [G loss: 0.963407]\n",
      "epoch:27 step:25793 [D loss: 0.467117, acc.: 82.03%] [G loss: 1.003357]\n",
      "epoch:27 step:25794 [D loss: 0.388553, acc.: 88.28%] [G loss: 0.800107]\n",
      "epoch:27 step:25795 [D loss: 0.572090, acc.: 71.88%] [G loss: 1.238960]\n",
      "epoch:27 step:25796 [D loss: 0.419608, acc.: 88.28%] [G loss: 1.135304]\n",
      "epoch:27 step:25797 [D loss: 0.198875, acc.: 93.75%] [G loss: 1.828891]\n",
      "epoch:27 step:25798 [D loss: 0.170306, acc.: 98.44%] [G loss: 1.966419]\n",
      "epoch:27 step:25799 [D loss: 0.703822, acc.: 59.38%] [G loss: 1.473864]\n",
      "epoch:27 step:25800 [D loss: 0.909261, acc.: 39.84%] [G loss: 1.251074]\n",
      "##############\n",
      "[3.91519947 2.35966509 6.4631569  5.33250933 4.33134393 6.21078941\n",
      " 5.35991714 5.81506599 6.14543498 5.20720975]\n",
      "##########\n",
      "epoch:27 step:25801 [D loss: 0.509623, acc.: 74.22%] [G loss: 1.404554]\n",
      "epoch:27 step:25802 [D loss: 0.242116, acc.: 88.28%] [G loss: 1.573255]\n",
      "epoch:27 step:25803 [D loss: 0.147713, acc.: 98.44%] [G loss: 2.170150]\n",
      "epoch:27 step:25804 [D loss: 0.214365, acc.: 93.75%] [G loss: 1.837582]\n",
      "epoch:27 step:25805 [D loss: 0.638426, acc.: 67.19%] [G loss: 1.873398]\n",
      "epoch:27 step:25806 [D loss: 0.242043, acc.: 93.75%] [G loss: 1.530867]\n",
      "epoch:27 step:25807 [D loss: 0.300243, acc.: 89.06%] [G loss: 1.626766]\n",
      "epoch:27 step:25808 [D loss: 0.513832, acc.: 79.69%] [G loss: 1.930138]\n",
      "epoch:27 step:25809 [D loss: 0.377500, acc.: 83.59%] [G loss: 1.276163]\n",
      "epoch:27 step:25810 [D loss: 0.202861, acc.: 95.31%] [G loss: 1.637043]\n",
      "epoch:27 step:25811 [D loss: 0.265118, acc.: 92.19%] [G loss: 1.438874]\n",
      "epoch:27 step:25812 [D loss: 0.258685, acc.: 89.06%] [G loss: 1.984512]\n",
      "epoch:27 step:25813 [D loss: 0.346427, acc.: 92.19%] [G loss: 2.045643]\n",
      "epoch:27 step:25814 [D loss: 0.303660, acc.: 89.06%] [G loss: 1.935652]\n",
      "epoch:27 step:25815 [D loss: 0.601318, acc.: 60.94%] [G loss: 1.464546]\n",
      "epoch:27 step:25816 [D loss: 0.231739, acc.: 93.75%] [G loss: 1.398643]\n",
      "epoch:27 step:25817 [D loss: 0.460344, acc.: 78.91%] [G loss: 1.574893]\n",
      "epoch:27 step:25818 [D loss: 0.437327, acc.: 84.38%] [G loss: 1.334469]\n",
      "epoch:27 step:25819 [D loss: 0.406154, acc.: 84.38%] [G loss: 1.661802]\n",
      "epoch:27 step:25820 [D loss: 0.513079, acc.: 75.78%] [G loss: 1.035102]\n",
      "epoch:27 step:25821 [D loss: 0.536082, acc.: 73.44%] [G loss: 1.260033]\n",
      "epoch:27 step:25822 [D loss: 0.390003, acc.: 87.50%] [G loss: 1.206920]\n",
      "epoch:27 step:25823 [D loss: 0.176606, acc.: 95.31%] [G loss: 1.757967]\n",
      "epoch:27 step:25824 [D loss: 0.799010, acc.: 53.91%] [G loss: 1.752197]\n",
      "epoch:27 step:25825 [D loss: 0.457843, acc.: 82.81%] [G loss: 1.279830]\n",
      "epoch:27 step:25826 [D loss: 0.314371, acc.: 85.16%] [G loss: 1.860084]\n",
      "epoch:27 step:25827 [D loss: 0.565991, acc.: 68.75%] [G loss: 0.999295]\n",
      "epoch:27 step:25828 [D loss: 0.733930, acc.: 57.81%] [G loss: 1.436371]\n",
      "epoch:27 step:25829 [D loss: 0.337439, acc.: 87.50%] [G loss: 2.188824]\n",
      "epoch:27 step:25830 [D loss: 0.964207, acc.: 42.97%] [G loss: 1.066415]\n",
      "epoch:27 step:25831 [D loss: 0.588606, acc.: 66.41%] [G loss: 1.273676]\n",
      "epoch:27 step:25832 [D loss: 0.360468, acc.: 82.81%] [G loss: 1.747846]\n",
      "epoch:27 step:25833 [D loss: 0.175079, acc.: 99.22%] [G loss: 1.811780]\n",
      "epoch:27 step:25834 [D loss: 0.192084, acc.: 96.09%] [G loss: 1.702142]\n",
      "epoch:27 step:25835 [D loss: 0.129196, acc.: 97.66%] [G loss: 2.117939]\n",
      "epoch:27 step:25836 [D loss: 0.174265, acc.: 97.66%] [G loss: 2.212908]\n",
      "epoch:27 step:25837 [D loss: 0.487265, acc.: 75.78%] [G loss: 1.689667]\n",
      "epoch:27 step:25838 [D loss: 0.378379, acc.: 89.84%] [G loss: 1.784138]\n",
      "epoch:27 step:25839 [D loss: 0.478758, acc.: 81.25%] [G loss: 2.075985]\n",
      "epoch:27 step:25840 [D loss: 0.299830, acc.: 93.75%] [G loss: 1.991143]\n",
      "epoch:27 step:25841 [D loss: 0.362209, acc.: 88.28%] [G loss: 1.746125]\n",
      "epoch:27 step:25842 [D loss: 0.203081, acc.: 96.09%] [G loss: 1.731999]\n",
      "epoch:27 step:25843 [D loss: 0.669350, acc.: 64.06%] [G loss: 1.767408]\n",
      "epoch:27 step:25844 [D loss: 0.231391, acc.: 94.53%] [G loss: 2.178720]\n",
      "epoch:27 step:25845 [D loss: 0.369649, acc.: 82.81%] [G loss: 1.400753]\n",
      "epoch:27 step:25846 [D loss: 0.159852, acc.: 96.88%] [G loss: 2.503711]\n",
      "epoch:27 step:25847 [D loss: 0.156360, acc.: 99.22%] [G loss: 2.127393]\n",
      "epoch:27 step:25848 [D loss: 0.130223, acc.: 97.66%] [G loss: 1.639518]\n",
      "epoch:27 step:25849 [D loss: 0.116692, acc.: 100.00%] [G loss: 1.919806]\n",
      "epoch:27 step:25850 [D loss: 0.248699, acc.: 96.09%] [G loss: 0.992721]\n",
      "epoch:27 step:25851 [D loss: 0.325083, acc.: 85.94%] [G loss: 1.972200]\n",
      "epoch:27 step:25852 [D loss: 0.496978, acc.: 73.44%] [G loss: 1.741457]\n",
      "epoch:27 step:25853 [D loss: 0.085940, acc.: 99.22%] [G loss: 1.570110]\n",
      "epoch:27 step:25854 [D loss: 0.384755, acc.: 85.94%] [G loss: 2.523775]\n",
      "epoch:27 step:25855 [D loss: 0.073125, acc.: 98.44%] [G loss: 3.055849]\n",
      "epoch:27 step:25856 [D loss: 0.400036, acc.: 78.12%] [G loss: 3.329524]\n",
      "epoch:27 step:25857 [D loss: 0.354872, acc.: 82.03%] [G loss: 2.956998]\n",
      "epoch:27 step:25858 [D loss: 0.053659, acc.: 100.00%] [G loss: 2.811830]\n",
      "epoch:27 step:25859 [D loss: 0.615750, acc.: 65.62%] [G loss: 1.602068]\n",
      "epoch:27 step:25860 [D loss: 0.057810, acc.: 100.00%] [G loss: 1.660134]\n",
      "epoch:27 step:25861 [D loss: 0.998852, acc.: 52.34%] [G loss: 1.703081]\n",
      "epoch:27 step:25862 [D loss: 0.858069, acc.: 58.59%] [G loss: 1.265245]\n",
      "epoch:27 step:25863 [D loss: 0.614388, acc.: 64.06%] [G loss: 1.277667]\n",
      "epoch:27 step:25864 [D loss: 0.533989, acc.: 71.88%] [G loss: 1.616028]\n",
      "epoch:27 step:25865 [D loss: 0.150510, acc.: 97.66%] [G loss: 1.802224]\n",
      "epoch:27 step:25866 [D loss: 0.214052, acc.: 91.41%] [G loss: 2.180143]\n",
      "epoch:27 step:25867 [D loss: 0.192926, acc.: 93.75%] [G loss: 2.346801]\n",
      "epoch:27 step:25868 [D loss: 0.703790, acc.: 57.81%] [G loss: 2.190292]\n",
      "epoch:27 step:25869 [D loss: 0.541073, acc.: 72.66%] [G loss: 1.292446]\n",
      "epoch:27 step:25870 [D loss: 0.481041, acc.: 76.56%] [G loss: 1.996104]\n",
      "epoch:27 step:25871 [D loss: 0.308503, acc.: 90.62%] [G loss: 1.640478]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:27 step:25872 [D loss: 0.395318, acc.: 85.94%] [G loss: 1.957236]\n",
      "epoch:27 step:25873 [D loss: 0.389035, acc.: 82.03%] [G loss: 2.002169]\n",
      "epoch:27 step:25874 [D loss: 0.269729, acc.: 92.97%] [G loss: 1.990801]\n",
      "epoch:27 step:25875 [D loss: 0.265366, acc.: 89.84%] [G loss: 1.921111]\n",
      "epoch:27 step:25876 [D loss: 0.076827, acc.: 100.00%] [G loss: 2.436997]\n",
      "epoch:27 step:25877 [D loss: 0.079635, acc.: 99.22%] [G loss: 2.501000]\n",
      "epoch:27 step:25878 [D loss: 0.083961, acc.: 98.44%] [G loss: 2.455941]\n",
      "epoch:27 step:25879 [D loss: 0.705994, acc.: 63.28%] [G loss: 2.199775]\n",
      "epoch:27 step:25880 [D loss: 0.686648, acc.: 64.06%] [G loss: 1.808072]\n",
      "epoch:27 step:25881 [D loss: 0.531740, acc.: 75.00%] [G loss: 1.703024]\n",
      "epoch:27 step:25882 [D loss: 0.776316, acc.: 56.25%] [G loss: 1.445066]\n",
      "epoch:27 step:25883 [D loss: 0.451039, acc.: 78.91%] [G loss: 1.325630]\n",
      "epoch:27 step:25884 [D loss: 0.496682, acc.: 73.44%] [G loss: 1.335500]\n",
      "epoch:27 step:25885 [D loss: 0.861022, acc.: 57.81%] [G loss: 1.543036]\n",
      "epoch:27 step:25886 [D loss: 0.187933, acc.: 92.97%] [G loss: 1.750713]\n",
      "epoch:27 step:25887 [D loss: 0.079860, acc.: 99.22%] [G loss: 2.239684]\n",
      "epoch:27 step:25888 [D loss: 0.082073, acc.: 98.44%] [G loss: 3.139064]\n",
      "epoch:27 step:25889 [D loss: 0.182416, acc.: 97.66%] [G loss: 2.354234]\n",
      "epoch:27 step:25890 [D loss: 1.122773, acc.: 52.34%] [G loss: 1.435373]\n",
      "epoch:27 step:25891 [D loss: 0.771378, acc.: 53.91%] [G loss: 1.306858]\n",
      "epoch:27 step:25892 [D loss: 0.793594, acc.: 46.88%] [G loss: 1.138524]\n",
      "epoch:27 step:25893 [D loss: 0.502386, acc.: 72.66%] [G loss: 1.506570]\n",
      "epoch:27 step:25894 [D loss: 0.146571, acc.: 95.31%] [G loss: 1.728640]\n",
      "epoch:27 step:25895 [D loss: 0.819382, acc.: 53.12%] [G loss: 1.419569]\n",
      "epoch:27 step:25896 [D loss: 0.781043, acc.: 50.00%] [G loss: 1.832553]\n",
      "epoch:27 step:25897 [D loss: 0.857438, acc.: 47.66%] [G loss: 1.257037]\n",
      "epoch:27 step:25898 [D loss: 0.772641, acc.: 53.12%] [G loss: 1.015989]\n",
      "epoch:27 step:25899 [D loss: 0.240560, acc.: 88.28%] [G loss: 1.541314]\n",
      "epoch:27 step:25900 [D loss: 0.192474, acc.: 95.31%] [G loss: 1.535601]\n",
      "epoch:27 step:25901 [D loss: 0.220064, acc.: 92.97%] [G loss: 1.565953]\n",
      "epoch:27 step:25902 [D loss: 0.779942, acc.: 59.38%] [G loss: 1.450860]\n",
      "epoch:27 step:25903 [D loss: 0.767438, acc.: 50.78%] [G loss: 1.317796]\n",
      "epoch:27 step:25904 [D loss: 0.751104, acc.: 59.38%] [G loss: 0.989804]\n",
      "epoch:27 step:25905 [D loss: 0.379277, acc.: 82.03%] [G loss: 1.195200]\n",
      "epoch:27 step:25906 [D loss: 0.366558, acc.: 88.28%] [G loss: 1.531875]\n",
      "epoch:27 step:25907 [D loss: 0.227281, acc.: 95.31%] [G loss: 1.994229]\n",
      "epoch:27 step:25908 [D loss: 0.215253, acc.: 92.97%] [G loss: 1.950121]\n",
      "epoch:27 step:25909 [D loss: 0.879561, acc.: 48.44%] [G loss: 1.190679]\n",
      "epoch:27 step:25910 [D loss: 0.131298, acc.: 96.88%] [G loss: 1.246663]\n",
      "epoch:27 step:25911 [D loss: 0.281343, acc.: 89.84%] [G loss: 1.452986]\n",
      "epoch:27 step:25912 [D loss: 0.565914, acc.: 70.31%] [G loss: 1.624376]\n",
      "epoch:27 step:25913 [D loss: 0.791640, acc.: 45.31%] [G loss: 1.349221]\n",
      "epoch:27 step:25914 [D loss: 0.740154, acc.: 60.94%] [G loss: 1.249780]\n",
      "epoch:27 step:25915 [D loss: 0.785615, acc.: 53.12%] [G loss: 1.448471]\n",
      "epoch:27 step:25916 [D loss: 0.451287, acc.: 81.25%] [G loss: 1.823278]\n",
      "epoch:27 step:25917 [D loss: 0.451422, acc.: 78.91%] [G loss: 1.147550]\n",
      "epoch:27 step:25918 [D loss: 0.387670, acc.: 85.16%] [G loss: 1.325151]\n",
      "epoch:27 step:25919 [D loss: 0.314233, acc.: 89.84%] [G loss: 1.807800]\n",
      "epoch:27 step:25920 [D loss: 0.614178, acc.: 61.72%] [G loss: 1.761461]\n",
      "epoch:27 step:25921 [D loss: 0.465207, acc.: 84.38%] [G loss: 1.320794]\n",
      "epoch:27 step:25922 [D loss: 0.646933, acc.: 58.59%] [G loss: 1.568460]\n",
      "epoch:27 step:25923 [D loss: 0.258846, acc.: 95.31%] [G loss: 1.557552]\n",
      "epoch:27 step:25924 [D loss: 0.527145, acc.: 75.00%] [G loss: 0.943054]\n",
      "epoch:27 step:25925 [D loss: 0.513959, acc.: 76.56%] [G loss: 1.135010]\n",
      "epoch:27 step:25926 [D loss: 0.470815, acc.: 77.34%] [G loss: 1.472536]\n",
      "epoch:27 step:25927 [D loss: 0.674653, acc.: 63.28%] [G loss: 1.552356]\n",
      "epoch:27 step:25928 [D loss: 0.269586, acc.: 95.31%] [G loss: 1.394171]\n",
      "epoch:27 step:25929 [D loss: 0.381407, acc.: 85.16%] [G loss: 1.369568]\n",
      "epoch:27 step:25930 [D loss: 0.726097, acc.: 56.25%] [G loss: 1.070735]\n",
      "epoch:27 step:25931 [D loss: 0.241578, acc.: 93.75%] [G loss: 1.531085]\n",
      "epoch:27 step:25932 [D loss: 0.296896, acc.: 84.38%] [G loss: 1.616349]\n",
      "epoch:27 step:25933 [D loss: 0.249305, acc.: 95.31%] [G loss: 1.999426]\n",
      "epoch:27 step:25934 [D loss: 0.213625, acc.: 97.66%] [G loss: 2.055943]\n",
      "epoch:27 step:25935 [D loss: 0.791329, acc.: 50.78%] [G loss: 1.620037]\n",
      "epoch:27 step:25936 [D loss: 0.405369, acc.: 85.94%] [G loss: 1.606256]\n",
      "epoch:27 step:25937 [D loss: 0.635335, acc.: 69.53%] [G loss: 1.333934]\n",
      "epoch:27 step:25938 [D loss: 0.549687, acc.: 69.53%] [G loss: 1.087346]\n",
      "epoch:27 step:25939 [D loss: 0.540211, acc.: 71.88%] [G loss: 0.964467]\n",
      "epoch:27 step:25940 [D loss: 0.174491, acc.: 95.31%] [G loss: 1.678156]\n",
      "epoch:27 step:25941 [D loss: 0.671571, acc.: 60.94%] [G loss: 1.785375]\n",
      "epoch:27 step:25942 [D loss: 0.470009, acc.: 80.47%] [G loss: 1.291393]\n",
      "epoch:27 step:25943 [D loss: 0.557267, acc.: 70.31%] [G loss: 1.838972]\n",
      "epoch:27 step:25944 [D loss: 0.115456, acc.: 98.44%] [G loss: 2.194712]\n",
      "epoch:27 step:25945 [D loss: 0.145334, acc.: 99.22%] [G loss: 1.563213]\n",
      "epoch:27 step:25946 [D loss: 0.133772, acc.: 96.88%] [G loss: 2.129560]\n",
      "epoch:27 step:25947 [D loss: 0.168357, acc.: 96.88%] [G loss: 2.574840]\n",
      "epoch:27 step:25948 [D loss: 0.089644, acc.: 100.00%] [G loss: 2.733795]\n",
      "epoch:27 step:25949 [D loss: 0.073369, acc.: 100.00%] [G loss: 2.312070]\n",
      "epoch:27 step:25950 [D loss: 0.411959, acc.: 84.38%] [G loss: 1.134071]\n",
      "epoch:27 step:25951 [D loss: 0.998092, acc.: 49.22%] [G loss: 2.285515]\n",
      "epoch:27 step:25952 [D loss: 1.109303, acc.: 31.25%] [G loss: 1.838734]\n",
      "epoch:27 step:25953 [D loss: 0.742401, acc.: 59.38%] [G loss: 1.779391]\n",
      "epoch:27 step:25954 [D loss: 0.668555, acc.: 64.84%] [G loss: 0.575743]\n",
      "epoch:27 step:25955 [D loss: 1.067292, acc.: 35.16%] [G loss: 1.492181]\n",
      "epoch:27 step:25956 [D loss: 0.655510, acc.: 62.50%] [G loss: 1.063765]\n",
      "epoch:27 step:25957 [D loss: 1.081506, acc.: 35.94%] [G loss: 1.977021]\n",
      "epoch:27 step:25958 [D loss: 0.294334, acc.: 89.84%] [G loss: 1.823964]\n",
      "epoch:27 step:25959 [D loss: 0.319980, acc.: 89.06%] [G loss: 1.315168]\n",
      "epoch:27 step:25960 [D loss: 0.457994, acc.: 81.25%] [G loss: 1.189462]\n",
      "epoch:27 step:25961 [D loss: 0.576028, acc.: 67.19%] [G loss: 1.822393]\n",
      "epoch:27 step:25962 [D loss: 0.314334, acc.: 85.16%] [G loss: 1.690261]\n",
      "epoch:27 step:25963 [D loss: 0.056537, acc.: 99.22%] [G loss: 1.618392]\n",
      "epoch:27 step:25964 [D loss: 0.139050, acc.: 96.88%] [G loss: 2.126211]\n",
      "epoch:27 step:25965 [D loss: 0.749482, acc.: 51.56%] [G loss: 2.606613]\n",
      "epoch:27 step:25966 [D loss: 0.531048, acc.: 71.88%] [G loss: 1.932503]\n",
      "epoch:27 step:25967 [D loss: 0.722427, acc.: 58.59%] [G loss: 2.382218]\n",
      "epoch:27 step:25968 [D loss: 0.463021, acc.: 77.34%] [G loss: 1.880853]\n",
      "epoch:27 step:25969 [D loss: 0.596168, acc.: 69.53%] [G loss: 1.667744]\n",
      "epoch:27 step:25970 [D loss: 0.346837, acc.: 83.59%] [G loss: 2.367485]\n",
      "epoch:27 step:25971 [D loss: 0.469480, acc.: 78.91%] [G loss: 1.308342]\n",
      "epoch:27 step:25972 [D loss: 0.617750, acc.: 68.75%] [G loss: 1.411842]\n",
      "epoch:27 step:25973 [D loss: 0.250025, acc.: 91.41%] [G loss: 1.625431]\n",
      "epoch:27 step:25974 [D loss: 0.740307, acc.: 53.12%] [G loss: 1.537720]\n",
      "epoch:27 step:25975 [D loss: 0.726416, acc.: 55.47%] [G loss: 1.258839]\n",
      "epoch:27 step:25976 [D loss: 0.796307, acc.: 54.69%] [G loss: 0.759472]\n",
      "epoch:27 step:25977 [D loss: 0.791237, acc.: 41.41%] [G loss: 0.566123]\n",
      "epoch:27 step:25978 [D loss: 0.546949, acc.: 70.31%] [G loss: 1.276591]\n",
      "epoch:27 step:25979 [D loss: 0.592759, acc.: 71.88%] [G loss: 1.222978]\n",
      "epoch:27 step:25980 [D loss: 0.771206, acc.: 54.69%] [G loss: 0.789016]\n",
      "epoch:27 step:25981 [D loss: 0.294914, acc.: 93.75%] [G loss: 1.181148]\n",
      "epoch:27 step:25982 [D loss: 0.488303, acc.: 75.00%] [G loss: 1.204935]\n",
      "epoch:27 step:25983 [D loss: 0.290112, acc.: 87.50%] [G loss: 1.337490]\n",
      "epoch:27 step:25984 [D loss: 0.335958, acc.: 91.41%] [G loss: 0.874216]\n",
      "epoch:27 step:25985 [D loss: 0.464882, acc.: 79.69%] [G loss: 1.038515]\n",
      "epoch:27 step:25986 [D loss: 0.458741, acc.: 78.12%] [G loss: 1.241795]\n",
      "epoch:27 step:25987 [D loss: 0.576596, acc.: 64.84%] [G loss: 1.273617]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:27 step:25988 [D loss: 0.884028, acc.: 38.28%] [G loss: 0.634816]\n",
      "epoch:27 step:25989 [D loss: 0.692031, acc.: 60.94%] [G loss: 0.689910]\n",
      "epoch:27 step:25990 [D loss: 0.786970, acc.: 52.34%] [G loss: 0.784091]\n",
      "epoch:27 step:25991 [D loss: 0.385964, acc.: 89.06%] [G loss: 1.404618]\n",
      "epoch:27 step:25992 [D loss: 0.354792, acc.: 87.50%] [G loss: 1.679868]\n",
      "epoch:27 step:25993 [D loss: 0.304011, acc.: 89.84%] [G loss: 0.604246]\n",
      "epoch:27 step:25994 [D loss: 0.757913, acc.: 53.91%] [G loss: 1.220986]\n",
      "epoch:27 step:25995 [D loss: 0.709905, acc.: 60.94%] [G loss: 1.975836]\n",
      "epoch:27 step:25996 [D loss: 0.176638, acc.: 95.31%] [G loss: 2.065989]\n",
      "epoch:27 step:25997 [D loss: 0.299013, acc.: 90.62%] [G loss: 2.203376]\n",
      "epoch:27 step:25998 [D loss: 0.378387, acc.: 84.38%] [G loss: 1.567186]\n",
      "epoch:27 step:25999 [D loss: 0.149475, acc.: 96.09%] [G loss: 2.080703]\n",
      "epoch:27 step:26000 [D loss: 0.121841, acc.: 96.09%] [G loss: 2.057827]\n",
      "##############\n",
      "[4.03017509 2.3721678  6.79089802 5.93756352 4.47427271 6.47162543\n",
      " 5.36367499 6.01038005 5.71392004 5.08951159]\n",
      "##########\n",
      "epoch:27 step:26001 [D loss: 0.190069, acc.: 96.88%] [G loss: 1.992923]\n",
      "epoch:27 step:26002 [D loss: 0.679054, acc.: 59.38%] [G loss: 1.677033]\n",
      "epoch:27 step:26003 [D loss: 0.303923, acc.: 96.88%] [G loss: 1.579153]\n",
      "epoch:27 step:26004 [D loss: 0.756274, acc.: 56.25%] [G loss: 1.555874]\n",
      "epoch:27 step:26005 [D loss: 0.175304, acc.: 96.09%] [G loss: 1.727882]\n",
      "epoch:27 step:26006 [D loss: 0.149465, acc.: 97.66%] [G loss: 0.493808]\n",
      "epoch:27 step:26007 [D loss: 0.122900, acc.: 99.22%] [G loss: 0.993937]\n",
      "epoch:27 step:26008 [D loss: 0.191001, acc.: 95.31%] [G loss: 2.011489]\n",
      "epoch:27 step:26009 [D loss: 0.349026, acc.: 82.03%] [G loss: 2.278026]\n",
      "epoch:27 step:26010 [D loss: 0.373323, acc.: 85.94%] [G loss: 2.022555]\n",
      "epoch:27 step:26011 [D loss: 1.227797, acc.: 15.62%] [G loss: 2.344603]\n",
      "epoch:27 step:26012 [D loss: 0.037265, acc.: 99.22%] [G loss: 2.413192]\n",
      "epoch:27 step:26013 [D loss: 0.114870, acc.: 97.66%] [G loss: 2.539723]\n",
      "epoch:27 step:26014 [D loss: 1.110483, acc.: 50.78%] [G loss: 2.931050]\n",
      "epoch:27 step:26015 [D loss: 0.808983, acc.: 48.44%] [G loss: 2.030403]\n",
      "epoch:27 step:26016 [D loss: 1.387527, acc.: 23.44%] [G loss: 1.534766]\n",
      "epoch:27 step:26017 [D loss: 0.472316, acc.: 80.47%] [G loss: 2.497499]\n",
      "epoch:27 step:26018 [D loss: 0.832475, acc.: 50.00%] [G loss: 0.975960]\n",
      "epoch:27 step:26019 [D loss: 0.307018, acc.: 92.97%] [G loss: 2.094359]\n",
      "epoch:27 step:26020 [D loss: 0.700169, acc.: 63.28%] [G loss: 1.694179]\n",
      "epoch:27 step:26021 [D loss: 0.717413, acc.: 59.38%] [G loss: 1.113460]\n",
      "epoch:27 step:26022 [D loss: 0.502763, acc.: 78.91%] [G loss: 1.450199]\n",
      "epoch:27 step:26023 [D loss: 0.257128, acc.: 96.09%] [G loss: 1.666887]\n",
      "epoch:27 step:26024 [D loss: 0.354391, acc.: 88.28%] [G loss: 0.801133]\n",
      "epoch:27 step:26025 [D loss: 0.224167, acc.: 94.53%] [G loss: 1.439944]\n",
      "epoch:27 step:26026 [D loss: 0.545474, acc.: 71.88%] [G loss: 0.803581]\n",
      "epoch:27 step:26027 [D loss: 0.164725, acc.: 96.09%] [G loss: 1.498907]\n",
      "epoch:27 step:26028 [D loss: 0.169839, acc.: 97.66%] [G loss: 1.636227]\n",
      "epoch:27 step:26029 [D loss: 0.229521, acc.: 92.97%] [G loss: 1.680734]\n",
      "epoch:27 step:26030 [D loss: 0.192845, acc.: 96.09%] [G loss: 1.959362]\n",
      "epoch:27 step:26031 [D loss: 0.157483, acc.: 100.00%] [G loss: 2.495962]\n",
      "epoch:27 step:26032 [D loss: 0.127178, acc.: 99.22%] [G loss: 2.305707]\n",
      "epoch:27 step:26033 [D loss: 0.650231, acc.: 58.59%] [G loss: 1.476297]\n",
      "epoch:27 step:26034 [D loss: 1.032446, acc.: 47.66%] [G loss: 1.236168]\n",
      "epoch:27 step:26035 [D loss: 0.830430, acc.: 53.12%] [G loss: 1.590344]\n",
      "epoch:27 step:26036 [D loss: 0.711852, acc.: 54.69%] [G loss: 1.022452]\n",
      "epoch:27 step:26037 [D loss: 0.758773, acc.: 57.03%] [G loss: 1.537830]\n",
      "epoch:27 step:26038 [D loss: 0.227687, acc.: 92.97%] [G loss: 1.677246]\n",
      "epoch:27 step:26039 [D loss: 0.348070, acc.: 89.84%] [G loss: 1.735460]\n",
      "epoch:27 step:26040 [D loss: 0.472649, acc.: 79.69%] [G loss: 1.349375]\n",
      "epoch:27 step:26041 [D loss: 0.337725, acc.: 91.41%] [G loss: 1.413352]\n",
      "epoch:27 step:26042 [D loss: 0.371069, acc.: 84.38%] [G loss: 1.442785]\n",
      "epoch:27 step:26043 [D loss: 0.723134, acc.: 59.38%] [G loss: 1.430416]\n",
      "epoch:27 step:26044 [D loss: 0.187185, acc.: 99.22%] [G loss: 1.250656]\n",
      "epoch:27 step:26045 [D loss: 0.140743, acc.: 99.22%] [G loss: 1.405936]\n",
      "epoch:27 step:26046 [D loss: 0.381580, acc.: 86.72%] [G loss: 1.674749]\n",
      "epoch:27 step:26047 [D loss: 0.832008, acc.: 50.78%] [G loss: 1.517405]\n",
      "epoch:27 step:26048 [D loss: 0.808346, acc.: 46.09%] [G loss: 0.976027]\n",
      "epoch:27 step:26049 [D loss: 0.580650, acc.: 67.19%] [G loss: 1.145018]\n",
      "epoch:27 step:26050 [D loss: 0.523641, acc.: 74.22%] [G loss: 0.757008]\n",
      "epoch:27 step:26051 [D loss: 0.411064, acc.: 79.69%] [G loss: 0.698067]\n",
      "epoch:27 step:26052 [D loss: 0.294927, acc.: 93.75%] [G loss: 1.565409]\n",
      "epoch:27 step:26053 [D loss: 0.217645, acc.: 94.53%] [G loss: 1.183685]\n",
      "epoch:27 step:26054 [D loss: 0.145817, acc.: 99.22%] [G loss: 1.342692]\n",
      "epoch:27 step:26055 [D loss: 0.149815, acc.: 97.66%] [G loss: 2.010937]\n",
      "epoch:27 step:26056 [D loss: 0.140292, acc.: 98.44%] [G loss: 1.985785]\n",
      "epoch:27 step:26057 [D loss: 0.404012, acc.: 83.59%] [G loss: 1.870562]\n",
      "epoch:27 step:26058 [D loss: 0.864535, acc.: 52.34%] [G loss: 1.483165]\n",
      "epoch:27 step:26059 [D loss: 1.055905, acc.: 26.56%] [G loss: 0.997740]\n",
      "epoch:27 step:26060 [D loss: 0.418155, acc.: 82.81%] [G loss: 1.328725]\n",
      "epoch:27 step:26061 [D loss: 0.256043, acc.: 89.06%] [G loss: 0.692882]\n",
      "epoch:27 step:26062 [D loss: 0.347129, acc.: 78.12%] [G loss: 1.671031]\n",
      "epoch:27 step:26063 [D loss: 0.301323, acc.: 85.94%] [G loss: 1.664417]\n",
      "epoch:27 step:26064 [D loss: 1.014995, acc.: 48.44%] [G loss: 1.272128]\n",
      "epoch:27 step:26065 [D loss: 0.739686, acc.: 58.59%] [G loss: 1.891502]\n",
      "epoch:27 step:26066 [D loss: 0.744061, acc.: 58.59%] [G loss: 1.649907]\n",
      "epoch:27 step:26067 [D loss: 0.588009, acc.: 68.75%] [G loss: 1.362170]\n",
      "epoch:27 step:26068 [D loss: 0.644795, acc.: 63.28%] [G loss: 1.592596]\n",
      "epoch:27 step:26069 [D loss: 0.690656, acc.: 59.38%] [G loss: 1.348370]\n",
      "epoch:27 step:26070 [D loss: 0.467538, acc.: 78.12%] [G loss: 1.025160]\n",
      "epoch:27 step:26071 [D loss: 0.621406, acc.: 61.72%] [G loss: 1.409816]\n",
      "epoch:27 step:26072 [D loss: 0.636506, acc.: 59.38%] [G loss: 1.495313]\n",
      "epoch:27 step:26073 [D loss: 0.365070, acc.: 78.12%] [G loss: 1.415953]\n",
      "epoch:27 step:26074 [D loss: 0.306923, acc.: 90.62%] [G loss: 1.539156]\n",
      "epoch:27 step:26075 [D loss: 0.568039, acc.: 67.19%] [G loss: 1.407866]\n",
      "epoch:27 step:26076 [D loss: 0.647329, acc.: 66.41%] [G loss: 0.231657]\n",
      "epoch:27 step:26077 [D loss: 0.798959, acc.: 53.12%] [G loss: 1.277315]\n",
      "epoch:27 step:26078 [D loss: 0.346810, acc.: 87.50%] [G loss: 1.331387]\n",
      "epoch:27 step:26079 [D loss: 0.226532, acc.: 89.06%] [G loss: 1.413109]\n",
      "epoch:27 step:26080 [D loss: 0.156962, acc.: 97.66%] [G loss: 1.572079]\n",
      "epoch:27 step:26081 [D loss: 0.156420, acc.: 99.22%] [G loss: 1.757635]\n",
      "epoch:27 step:26082 [D loss: 0.331322, acc.: 90.62%] [G loss: 1.606953]\n",
      "epoch:27 step:26083 [D loss: 0.613515, acc.: 63.28%] [G loss: 1.516924]\n",
      "epoch:27 step:26084 [D loss: 0.552237, acc.: 71.88%] [G loss: 1.346612]\n",
      "epoch:27 step:26085 [D loss: 0.266013, acc.: 89.84%] [G loss: 1.296055]\n",
      "epoch:27 step:26086 [D loss: 0.714099, acc.: 57.03%] [G loss: 1.067874]\n",
      "epoch:27 step:26087 [D loss: 0.638697, acc.: 69.53%] [G loss: 1.538915]\n",
      "epoch:27 step:26088 [D loss: 1.348657, acc.: 24.22%] [G loss: 1.169707]\n",
      "epoch:27 step:26089 [D loss: 0.624339, acc.: 66.41%] [G loss: 0.749434]\n",
      "epoch:27 step:26090 [D loss: 0.271898, acc.: 88.28%] [G loss: 1.957177]\n",
      "epoch:27 step:26091 [D loss: 0.151610, acc.: 98.44%] [G loss: 2.003579]\n",
      "epoch:27 step:26092 [D loss: 0.175528, acc.: 96.09%] [G loss: 1.710024]\n",
      "epoch:27 step:26093 [D loss: 0.215203, acc.: 93.75%] [G loss: 2.031748]\n",
      "epoch:27 step:26094 [D loss: 0.282230, acc.: 94.53%] [G loss: 1.997216]\n",
      "epoch:27 step:26095 [D loss: 0.215138, acc.: 94.53%] [G loss: 0.949988]\n",
      "epoch:27 step:26096 [D loss: 0.714927, acc.: 60.16%] [G loss: 1.098848]\n",
      "epoch:27 step:26097 [D loss: 0.684445, acc.: 57.03%] [G loss: 2.116677]\n",
      "epoch:27 step:26098 [D loss: 0.790949, acc.: 55.47%] [G loss: 1.511858]\n",
      "epoch:27 step:26099 [D loss: 0.160378, acc.: 98.44%] [G loss: 1.961328]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:27 step:26100 [D loss: 0.166233, acc.: 96.88%] [G loss: 1.582894]\n",
      "epoch:27 step:26101 [D loss: 0.323194, acc.: 90.62%] [G loss: 1.926856]\n",
      "epoch:27 step:26102 [D loss: 0.261716, acc.: 96.09%] [G loss: 2.037718]\n",
      "epoch:27 step:26103 [D loss: 0.112450, acc.: 100.00%] [G loss: 0.960189]\n",
      "epoch:27 step:26104 [D loss: 0.183236, acc.: 95.31%] [G loss: 2.111692]\n",
      "epoch:27 step:26105 [D loss: 0.112890, acc.: 98.44%] [G loss: 1.981188]\n",
      "epoch:27 step:26106 [D loss: 1.080118, acc.: 44.53%] [G loss: 2.342980]\n",
      "epoch:27 step:26107 [D loss: 0.222453, acc.: 92.97%] [G loss: 2.528561]\n",
      "epoch:27 step:26108 [D loss: 0.073454, acc.: 99.22%] [G loss: 2.994945]\n",
      "epoch:27 step:26109 [D loss: 0.158159, acc.: 96.09%] [G loss: 2.693679]\n",
      "epoch:27 step:26110 [D loss: 1.088644, acc.: 50.78%] [G loss: 1.599548]\n",
      "epoch:27 step:26111 [D loss: 0.859387, acc.: 54.69%] [G loss: 1.471813]\n",
      "epoch:27 step:26112 [D loss: 0.486765, acc.: 80.47%] [G loss: 1.434725]\n",
      "epoch:27 step:26113 [D loss: 0.353715, acc.: 87.50%] [G loss: 1.215269]\n",
      "epoch:27 step:26114 [D loss: 0.145399, acc.: 96.09%] [G loss: 1.243767]\n",
      "epoch:27 step:26115 [D loss: 0.144978, acc.: 96.88%] [G loss: 1.616666]\n",
      "epoch:27 step:26116 [D loss: 0.385064, acc.: 85.94%] [G loss: 1.623096]\n",
      "epoch:27 step:26117 [D loss: 0.438996, acc.: 82.03%] [G loss: 2.287815]\n",
      "epoch:27 step:26118 [D loss: 0.210228, acc.: 97.66%] [G loss: 1.075703]\n",
      "epoch:27 step:26119 [D loss: 0.644929, acc.: 57.81%] [G loss: 1.519944]\n",
      "epoch:27 step:26120 [D loss: 0.866324, acc.: 52.34%] [G loss: 1.365614]\n",
      "epoch:27 step:26121 [D loss: 0.770033, acc.: 52.34%] [G loss: 0.838792]\n",
      "epoch:27 step:26122 [D loss: 0.395913, acc.: 85.94%] [G loss: 1.118274]\n",
      "epoch:27 step:26123 [D loss: 0.525467, acc.: 64.84%] [G loss: 1.066656]\n",
      "epoch:27 step:26124 [D loss: 0.234494, acc.: 90.62%] [G loss: 2.155452]\n",
      "epoch:27 step:26125 [D loss: 0.935632, acc.: 46.88%] [G loss: 1.895456]\n",
      "epoch:27 step:26126 [D loss: 0.903682, acc.: 45.31%] [G loss: 1.938713]\n",
      "epoch:27 step:26127 [D loss: 0.613229, acc.: 60.94%] [G loss: 1.704988]\n",
      "epoch:27 step:26128 [D loss: 0.342135, acc.: 90.62%] [G loss: 1.398555]\n",
      "epoch:27 step:26129 [D loss: 0.279550, acc.: 91.41%] [G loss: 1.967336]\n",
      "epoch:27 step:26130 [D loss: 0.103047, acc.: 99.22%] [G loss: 1.892504]\n",
      "epoch:27 step:26131 [D loss: 0.103298, acc.: 98.44%] [G loss: 2.158197]\n",
      "epoch:27 step:26132 [D loss: 0.148222, acc.: 96.88%] [G loss: 1.679136]\n",
      "epoch:27 step:26133 [D loss: 1.111516, acc.: 53.12%] [G loss: 2.035166]\n",
      "epoch:27 step:26134 [D loss: 1.123173, acc.: 35.16%] [G loss: 1.668925]\n",
      "epoch:27 step:26135 [D loss: 0.804681, acc.: 49.22%] [G loss: 1.770609]\n",
      "epoch:27 step:26136 [D loss: 0.802600, acc.: 46.09%] [G loss: 1.922010]\n",
      "epoch:27 step:26137 [D loss: 0.435781, acc.: 80.47%] [G loss: 1.808169]\n",
      "epoch:27 step:26138 [D loss: 0.821907, acc.: 52.34%] [G loss: 1.027770]\n",
      "epoch:27 step:26139 [D loss: 0.714858, acc.: 53.91%] [G loss: 1.818528]\n",
      "epoch:27 step:26140 [D loss: 0.496272, acc.: 76.56%] [G loss: 1.761739]\n",
      "epoch:27 step:26141 [D loss: 0.360900, acc.: 87.50%] [G loss: 1.223506]\n",
      "epoch:27 step:26142 [D loss: 0.259432, acc.: 89.06%] [G loss: 1.382358]\n",
      "epoch:27 step:26143 [D loss: 0.184850, acc.: 97.66%] [G loss: 1.487495]\n",
      "epoch:27 step:26144 [D loss: 0.234038, acc.: 89.06%] [G loss: 1.812351]\n",
      "epoch:27 step:26145 [D loss: 0.751370, acc.: 51.56%] [G loss: 1.524760]\n",
      "epoch:27 step:26146 [D loss: 0.283286, acc.: 95.31%] [G loss: 1.758449]\n",
      "epoch:27 step:26147 [D loss: 0.458191, acc.: 81.25%] [G loss: 1.652478]\n",
      "epoch:27 step:26148 [D loss: 0.391462, acc.: 84.38%] [G loss: 1.786222]\n",
      "epoch:27 step:26149 [D loss: 0.275932, acc.: 92.97%] [G loss: 1.666726]\n",
      "epoch:27 step:26150 [D loss: 0.136584, acc.: 100.00%] [G loss: 1.667821]\n",
      "epoch:27 step:26151 [D loss: 0.154387, acc.: 97.66%] [G loss: 1.750494]\n",
      "epoch:27 step:26152 [D loss: 0.196788, acc.: 99.22%] [G loss: 2.406146]\n",
      "epoch:27 step:26153 [D loss: 0.192442, acc.: 95.31%] [G loss: 1.980897]\n",
      "epoch:27 step:26154 [D loss: 0.226959, acc.: 96.09%] [G loss: 2.090896]\n",
      "epoch:27 step:26155 [D loss: 0.670532, acc.: 64.06%] [G loss: 1.649057]\n",
      "epoch:27 step:26156 [D loss: 0.283067, acc.: 88.28%] [G loss: 1.832537]\n",
      "epoch:27 step:26157 [D loss: 0.207050, acc.: 95.31%] [G loss: 1.788045]\n",
      "epoch:27 step:26158 [D loss: 0.207568, acc.: 96.88%] [G loss: 1.965953]\n",
      "epoch:27 step:26159 [D loss: 0.482211, acc.: 75.00%] [G loss: 1.960795]\n",
      "epoch:27 step:26160 [D loss: 0.342623, acc.: 91.41%] [G loss: 0.609152]\n",
      "epoch:27 step:26161 [D loss: 0.893788, acc.: 38.28%] [G loss: 1.520378]\n",
      "epoch:27 step:26162 [D loss: 0.733096, acc.: 59.38%] [G loss: 1.640422]\n",
      "epoch:27 step:26163 [D loss: 0.843626, acc.: 43.75%] [G loss: 1.465795]\n",
      "epoch:27 step:26164 [D loss: 0.473985, acc.: 79.69%] [G loss: 1.311945]\n",
      "epoch:27 step:26165 [D loss: 0.840621, acc.: 47.66%] [G loss: 1.124397]\n",
      "epoch:27 step:26166 [D loss: 0.798085, acc.: 57.03%] [G loss: 1.708551]\n",
      "epoch:27 step:26167 [D loss: 0.685282, acc.: 57.81%] [G loss: 0.775446]\n",
      "epoch:27 step:26168 [D loss: 0.661573, acc.: 60.16%] [G loss: 1.614264]\n",
      "epoch:27 step:26169 [D loss: 0.671934, acc.: 61.72%] [G loss: 1.077973]\n",
      "epoch:27 step:26170 [D loss: 0.582876, acc.: 69.53%] [G loss: 1.186571]\n",
      "epoch:27 step:26171 [D loss: 0.802404, acc.: 51.56%] [G loss: 0.793562]\n",
      "epoch:27 step:26172 [D loss: 0.685975, acc.: 59.38%] [G loss: 1.363519]\n",
      "epoch:27 step:26173 [D loss: 0.782568, acc.: 50.78%] [G loss: 1.358138]\n",
      "epoch:27 step:26174 [D loss: 0.500651, acc.: 75.78%] [G loss: 1.546643]\n",
      "epoch:27 step:26175 [D loss: 0.414459, acc.: 78.91%] [G loss: 1.623310]\n",
      "epoch:27 step:26176 [D loss: 0.235735, acc.: 93.75%] [G loss: 1.741260]\n",
      "epoch:27 step:26177 [D loss: 0.173488, acc.: 95.31%] [G loss: 1.653649]\n",
      "epoch:27 step:26178 [D loss: 0.688735, acc.: 53.91%] [G loss: 1.790501]\n",
      "epoch:27 step:26179 [D loss: 0.726577, acc.: 54.69%] [G loss: 1.508014]\n",
      "epoch:27 step:26180 [D loss: 0.874373, acc.: 34.38%] [G loss: 1.887163]\n",
      "epoch:27 step:26181 [D loss: 0.453074, acc.: 78.12%] [G loss: 1.363456]\n",
      "epoch:27 step:26182 [D loss: 0.335929, acc.: 88.28%] [G loss: 1.654672]\n",
      "epoch:27 step:26183 [D loss: 0.222276, acc.: 93.75%] [G loss: 2.150294]\n",
      "epoch:27 step:26184 [D loss: 0.183616, acc.: 96.09%] [G loss: 1.820587]\n",
      "epoch:27 step:26185 [D loss: 0.153386, acc.: 99.22%] [G loss: 2.067259]\n",
      "epoch:27 step:26186 [D loss: 0.194478, acc.: 96.88%] [G loss: 2.054314]\n",
      "epoch:27 step:26187 [D loss: 0.787662, acc.: 57.03%] [G loss: 1.763282]\n",
      "epoch:27 step:26188 [D loss: 0.312568, acc.: 86.72%] [G loss: 1.861608]\n",
      "epoch:27 step:26189 [D loss: 0.301842, acc.: 92.97%] [G loss: 1.607713]\n",
      "epoch:27 step:26190 [D loss: 0.748394, acc.: 57.03%] [G loss: 1.550165]\n",
      "epoch:27 step:26191 [D loss: 0.636459, acc.: 64.84%] [G loss: 1.214202]\n",
      "epoch:27 step:26192 [D loss: 0.646544, acc.: 60.94%] [G loss: 1.175249]\n",
      "epoch:27 step:26193 [D loss: 0.240364, acc.: 92.97%] [G loss: 1.475185]\n",
      "epoch:27 step:26194 [D loss: 0.276621, acc.: 92.19%] [G loss: 1.079443]\n",
      "epoch:27 step:26195 [D loss: 0.222433, acc.: 95.31%] [G loss: 1.688096]\n",
      "epoch:27 step:26196 [D loss: 0.251506, acc.: 97.66%] [G loss: 1.653236]\n",
      "epoch:27 step:26197 [D loss: 0.175547, acc.: 96.09%] [G loss: 1.581374]\n",
      "epoch:27 step:26198 [D loss: 0.102803, acc.: 99.22%] [G loss: 1.471879]\n",
      "epoch:27 step:26199 [D loss: 0.248010, acc.: 89.06%] [G loss: 1.904427]\n",
      "epoch:27 step:26200 [D loss: 0.254444, acc.: 96.09%] [G loss: 2.288377]\n",
      "##############\n",
      "[4.1519309  2.80750159 7.0637557  6.05997407 4.56658883 6.16867657\n",
      " 5.19473387 5.80580403 6.23402306 5.19964653]\n",
      "##########\n",
      "epoch:27 step:26201 [D loss: 0.541229, acc.: 71.88%] [G loss: 2.134719]\n",
      "epoch:27 step:26202 [D loss: 0.253800, acc.: 96.88%] [G loss: 1.739112]\n",
      "epoch:27 step:26203 [D loss: 0.491599, acc.: 75.78%] [G loss: 1.383183]\n",
      "epoch:27 step:26204 [D loss: 0.244067, acc.: 92.97%] [G loss: 1.495829]\n",
      "epoch:27 step:26205 [D loss: 0.272775, acc.: 91.41%] [G loss: 1.393206]\n",
      "epoch:27 step:26206 [D loss: 0.656293, acc.: 60.16%] [G loss: 1.525268]\n",
      "epoch:27 step:26207 [D loss: 0.444441, acc.: 79.69%] [G loss: 1.538098]\n",
      "epoch:27 step:26208 [D loss: 0.205426, acc.: 92.97%] [G loss: 1.845894]\n",
      "epoch:27 step:26209 [D loss: 0.590532, acc.: 69.53%] [G loss: 1.145957]\n",
      "epoch:27 step:26210 [D loss: 0.142922, acc.: 99.22%] [G loss: 0.919525]\n",
      "epoch:27 step:26211 [D loss: 0.145325, acc.: 97.66%] [G loss: 1.370543]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:27 step:26212 [D loss: 0.491064, acc.: 79.69%] [G loss: 1.074901]\n",
      "epoch:27 step:26213 [D loss: 0.860215, acc.: 46.09%] [G loss: 1.848302]\n",
      "epoch:27 step:26214 [D loss: 0.438212, acc.: 82.03%] [G loss: 1.642456]\n",
      "epoch:27 step:26215 [D loss: 1.498788, acc.: 21.09%] [G loss: 2.067627]\n",
      "epoch:27 step:26216 [D loss: 0.616721, acc.: 64.84%] [G loss: 1.526020]\n",
      "epoch:27 step:26217 [D loss: 0.262828, acc.: 94.53%] [G loss: 1.970716]\n",
      "epoch:27 step:26218 [D loss: 0.124805, acc.: 96.09%] [G loss: 2.371335]\n",
      "epoch:27 step:26219 [D loss: 1.193161, acc.: 48.44%] [G loss: 1.799145]\n",
      "epoch:27 step:26220 [D loss: 0.833556, acc.: 50.78%] [G loss: 1.850220]\n",
      "epoch:27 step:26221 [D loss: 0.242579, acc.: 92.97%] [G loss: 0.930584]\n",
      "epoch:27 step:26222 [D loss: 0.248090, acc.: 89.84%] [G loss: 1.875398]\n",
      "epoch:27 step:26223 [D loss: 0.138983, acc.: 94.53%] [G loss: 2.216482]\n",
      "epoch:27 step:26224 [D loss: 0.109665, acc.: 98.44%] [G loss: 2.354055]\n",
      "epoch:27 step:26225 [D loss: 0.085224, acc.: 99.22%] [G loss: 2.614054]\n",
      "epoch:27 step:26226 [D loss: 0.073771, acc.: 99.22%] [G loss: 2.868510]\n",
      "epoch:27 step:26227 [D loss: 0.832099, acc.: 54.69%] [G loss: 1.627253]\n",
      "epoch:27 step:26228 [D loss: 0.175975, acc.: 96.09%] [G loss: 1.945006]\n",
      "epoch:27 step:26229 [D loss: 0.525240, acc.: 71.88%] [G loss: 2.225214]\n",
      "epoch:27 step:26230 [D loss: 0.202724, acc.: 97.66%] [G loss: 1.854101]\n",
      "epoch:27 step:26231 [D loss: 0.321144, acc.: 85.94%] [G loss: 2.333780]\n",
      "epoch:27 step:26232 [D loss: 0.255138, acc.: 87.50%] [G loss: 2.214132]\n",
      "epoch:27 step:26233 [D loss: 0.043853, acc.: 100.00%] [G loss: 2.771055]\n",
      "epoch:27 step:26234 [D loss: 0.045231, acc.: 100.00%] [G loss: 3.051532]\n",
      "epoch:27 step:26235 [D loss: 0.106775, acc.: 97.66%] [G loss: 2.725791]\n",
      "epoch:27 step:26236 [D loss: 0.073054, acc.: 98.44%] [G loss: 2.790355]\n",
      "epoch:28 step:26237 [D loss: 0.041990, acc.: 100.00%] [G loss: 2.456450]\n",
      "epoch:28 step:26238 [D loss: 0.123992, acc.: 99.22%] [G loss: 2.936704]\n",
      "epoch:28 step:26239 [D loss: 0.106945, acc.: 99.22%] [G loss: 1.516913]\n",
      "epoch:28 step:26240 [D loss: 0.361488, acc.: 84.38%] [G loss: 1.922502]\n",
      "epoch:28 step:26241 [D loss: 0.343451, acc.: 89.06%] [G loss: 0.941744]\n",
      "epoch:28 step:26242 [D loss: 0.220833, acc.: 90.62%] [G loss: 3.068387]\n",
      "epoch:28 step:26243 [D loss: 0.102092, acc.: 100.00%] [G loss: 1.596980]\n",
      "epoch:28 step:26244 [D loss: 0.068718, acc.: 99.22%] [G loss: 2.708547]\n",
      "epoch:28 step:26245 [D loss: 0.098245, acc.: 99.22%] [G loss: 1.194560]\n",
      "epoch:28 step:26246 [D loss: 0.276945, acc.: 86.72%] [G loss: 1.712322]\n",
      "epoch:28 step:26247 [D loss: 0.167923, acc.: 94.53%] [G loss: 2.376220]\n",
      "epoch:28 step:26248 [D loss: 0.052281, acc.: 100.00%] [G loss: 3.350685]\n",
      "epoch:28 step:26249 [D loss: 0.157235, acc.: 96.88%] [G loss: 0.824104]\n",
      "epoch:28 step:26250 [D loss: 0.379224, acc.: 79.69%] [G loss: 1.188981]\n",
      "epoch:28 step:26251 [D loss: 0.682922, acc.: 59.38%] [G loss: 3.300839]\n",
      "epoch:28 step:26252 [D loss: 0.129928, acc.: 96.88%] [G loss: 3.657077]\n",
      "epoch:28 step:26253 [D loss: 0.497710, acc.: 76.56%] [G loss: 1.713370]\n",
      "epoch:28 step:26254 [D loss: 0.267277, acc.: 92.97%] [G loss: 3.043932]\n",
      "epoch:28 step:26255 [D loss: 0.984701, acc.: 44.53%] [G loss: 0.549452]\n",
      "epoch:28 step:26256 [D loss: 1.642035, acc.: 48.44%] [G loss: 1.945130]\n",
      "epoch:28 step:26257 [D loss: 2.025093, acc.: 14.06%] [G loss: 1.563984]\n",
      "epoch:28 step:26258 [D loss: 0.928623, acc.: 55.47%] [G loss: 2.859112]\n",
      "epoch:28 step:26259 [D loss: 0.987560, acc.: 43.75%] [G loss: 2.972403]\n",
      "epoch:28 step:26260 [D loss: 0.247632, acc.: 92.19%] [G loss: 1.271516]\n",
      "epoch:28 step:26261 [D loss: 0.133824, acc.: 99.22%] [G loss: 2.156842]\n",
      "epoch:28 step:26262 [D loss: 1.037176, acc.: 49.22%] [G loss: 1.132190]\n",
      "epoch:28 step:26263 [D loss: 0.974272, acc.: 53.12%] [G loss: 1.656062]\n",
      "epoch:28 step:26264 [D loss: 1.011869, acc.: 39.06%] [G loss: 1.043397]\n",
      "epoch:28 step:26265 [D loss: 0.803820, acc.: 44.53%] [G loss: 1.774313]\n",
      "epoch:28 step:26266 [D loss: 1.025877, acc.: 36.72%] [G loss: 2.705780]\n",
      "epoch:28 step:26267 [D loss: 0.288011, acc.: 89.06%] [G loss: 3.727619]\n",
      "epoch:28 step:26268 [D loss: 0.258518, acc.: 96.09%] [G loss: 3.413310]\n",
      "epoch:28 step:26269 [D loss: 0.172439, acc.: 96.09%] [G loss: 2.371715]\n",
      "epoch:28 step:26270 [D loss: 0.270196, acc.: 92.19%] [G loss: 2.876357]\n",
      "epoch:28 step:26271 [D loss: 0.134947, acc.: 98.44%] [G loss: 3.931273]\n",
      "epoch:28 step:26272 [D loss: 0.069508, acc.: 98.44%] [G loss: 3.382175]\n",
      "epoch:28 step:26273 [D loss: 0.981106, acc.: 51.56%] [G loss: 2.032997]\n",
      "epoch:28 step:26274 [D loss: 0.665205, acc.: 59.38%] [G loss: 1.369226]\n",
      "epoch:28 step:26275 [D loss: 0.943841, acc.: 43.75%] [G loss: 1.274572]\n",
      "epoch:28 step:26276 [D loss: 0.641587, acc.: 69.53%] [G loss: 0.945923]\n",
      "epoch:28 step:26277 [D loss: 0.669028, acc.: 56.25%] [G loss: 1.219315]\n",
      "epoch:28 step:26278 [D loss: 0.384369, acc.: 84.38%] [G loss: 1.814061]\n",
      "epoch:28 step:26279 [D loss: 0.315061, acc.: 90.62%] [G loss: 1.754753]\n",
      "epoch:28 step:26280 [D loss: 0.276568, acc.: 97.66%] [G loss: 1.594563]\n",
      "epoch:28 step:26281 [D loss: 0.409566, acc.: 85.16%] [G loss: 1.883129]\n",
      "epoch:28 step:26282 [D loss: 0.260225, acc.: 93.75%] [G loss: 1.402157]\n",
      "epoch:28 step:26283 [D loss: 0.526495, acc.: 75.00%] [G loss: 1.144962]\n",
      "epoch:28 step:26284 [D loss: 0.592873, acc.: 65.62%] [G loss: 1.323701]\n",
      "epoch:28 step:26285 [D loss: 0.544550, acc.: 75.00%] [G loss: 1.640186]\n",
      "epoch:28 step:26286 [D loss: 0.328971, acc.: 90.62%] [G loss: 2.253303]\n",
      "epoch:28 step:26287 [D loss: 0.253221, acc.: 91.41%] [G loss: 2.141272]\n",
      "epoch:28 step:26288 [D loss: 0.266743, acc.: 91.41%] [G loss: 1.816604]\n",
      "epoch:28 step:26289 [D loss: 0.363922, acc.: 89.06%] [G loss: 1.273831]\n",
      "epoch:28 step:26290 [D loss: 0.523111, acc.: 75.78%] [G loss: 1.275268]\n",
      "epoch:28 step:26291 [D loss: 0.593908, acc.: 71.09%] [G loss: 1.805487]\n",
      "epoch:28 step:26292 [D loss: 0.445917, acc.: 81.25%] [G loss: 1.452649]\n",
      "epoch:28 step:26293 [D loss: 0.184671, acc.: 96.88%] [G loss: 1.341336]\n",
      "epoch:28 step:26294 [D loss: 0.239845, acc.: 92.19%] [G loss: 0.810250]\n",
      "epoch:28 step:26295 [D loss: 0.434325, acc.: 79.69%] [G loss: 1.338634]\n",
      "epoch:28 step:26296 [D loss: 0.389790, acc.: 79.69%] [G loss: 1.884655]\n",
      "epoch:28 step:26297 [D loss: 0.787382, acc.: 54.69%] [G loss: 2.421140]\n",
      "epoch:28 step:26298 [D loss: 0.596466, acc.: 69.53%] [G loss: 1.936067]\n",
      "epoch:28 step:26299 [D loss: 0.349807, acc.: 92.19%] [G loss: 1.706335]\n",
      "epoch:28 step:26300 [D loss: 1.050337, acc.: 34.38%] [G loss: 1.252815]\n",
      "epoch:28 step:26301 [D loss: 0.712519, acc.: 60.94%] [G loss: 1.294234]\n",
      "epoch:28 step:26302 [D loss: 0.514291, acc.: 70.31%] [G loss: 1.915970]\n",
      "epoch:28 step:26303 [D loss: 0.560329, acc.: 73.44%] [G loss: 1.025015]\n",
      "epoch:28 step:26304 [D loss: 0.849525, acc.: 52.34%] [G loss: 1.686038]\n",
      "epoch:28 step:26305 [D loss: 0.881777, acc.: 45.31%] [G loss: 0.522928]\n",
      "epoch:28 step:26306 [D loss: 0.717895, acc.: 60.94%] [G loss: 0.947101]\n",
      "epoch:28 step:26307 [D loss: 0.156326, acc.: 96.09%] [G loss: 1.591903]\n",
      "epoch:28 step:26308 [D loss: 0.278644, acc.: 92.97%] [G loss: 1.936380]\n",
      "epoch:28 step:26309 [D loss: 0.192490, acc.: 97.66%] [G loss: 2.105427]\n",
      "epoch:28 step:26310 [D loss: 0.431886, acc.: 82.03%] [G loss: 1.738062]\n",
      "epoch:28 step:26311 [D loss: 0.321183, acc.: 85.16%] [G loss: 1.435164]\n",
      "epoch:28 step:26312 [D loss: 0.179542, acc.: 92.19%] [G loss: 1.940799]\n",
      "epoch:28 step:26313 [D loss: 0.203495, acc.: 92.97%] [G loss: 2.696655]\n",
      "epoch:28 step:26314 [D loss: 1.139586, acc.: 39.84%] [G loss: 1.683949]\n",
      "epoch:28 step:26315 [D loss: 0.538427, acc.: 72.66%] [G loss: 0.639432]\n",
      "epoch:28 step:26316 [D loss: 1.052817, acc.: 34.38%] [G loss: 1.193503]\n",
      "epoch:28 step:26317 [D loss: 0.829980, acc.: 49.22%] [G loss: 1.380818]\n",
      "epoch:28 step:26318 [D loss: 0.719819, acc.: 60.16%] [G loss: 1.131830]\n",
      "epoch:28 step:26319 [D loss: 0.852019, acc.: 45.31%] [G loss: 1.696380]\n",
      "epoch:28 step:26320 [D loss: 0.547233, acc.: 71.09%] [G loss: 2.372529]\n",
      "epoch:28 step:26321 [D loss: 0.592168, acc.: 64.84%] [G loss: 1.242093]\n",
      "epoch:28 step:26322 [D loss: 0.778130, acc.: 50.78%] [G loss: 1.161622]\n",
      "epoch:28 step:26323 [D loss: 0.652211, acc.: 63.28%] [G loss: 1.191094]\n",
      "epoch:28 step:26324 [D loss: 0.693377, acc.: 57.03%] [G loss: 1.321166]\n",
      "epoch:28 step:26325 [D loss: 0.583450, acc.: 68.75%] [G loss: 1.402174]\n",
      "epoch:28 step:26326 [D loss: 0.711926, acc.: 60.94%] [G loss: 1.841052]\n",
      "epoch:28 step:26327 [D loss: 0.512737, acc.: 74.22%] [G loss: 1.120881]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:28 step:26328 [D loss: 0.541459, acc.: 72.66%] [G loss: 1.325871]\n",
      "epoch:28 step:26329 [D loss: 0.553325, acc.: 67.97%] [G loss: 1.497577]\n",
      "epoch:28 step:26330 [D loss: 0.567524, acc.: 71.88%] [G loss: 1.295933]\n",
      "epoch:28 step:26331 [D loss: 0.471136, acc.: 78.91%] [G loss: 1.101309]\n",
      "epoch:28 step:26332 [D loss: 0.609844, acc.: 67.19%] [G loss: 1.533179]\n",
      "epoch:28 step:26333 [D loss: 0.432914, acc.: 82.03%] [G loss: 1.379939]\n",
      "epoch:28 step:26334 [D loss: 0.397236, acc.: 82.81%] [G loss: 1.753200]\n",
      "epoch:28 step:26335 [D loss: 0.447092, acc.: 81.25%] [G loss: 1.203295]\n",
      "epoch:28 step:26336 [D loss: 0.338672, acc.: 91.41%] [G loss: 1.460643]\n",
      "epoch:28 step:26337 [D loss: 0.585878, acc.: 67.97%] [G loss: 1.177899]\n",
      "epoch:28 step:26338 [D loss: 0.634586, acc.: 66.41%] [G loss: 1.614104]\n",
      "epoch:28 step:26339 [D loss: 0.590617, acc.: 71.88%] [G loss: 1.284981]\n",
      "epoch:28 step:26340 [D loss: 0.512128, acc.: 82.81%] [G loss: 1.344269]\n",
      "epoch:28 step:26341 [D loss: 0.353235, acc.: 89.06%] [G loss: 1.481025]\n",
      "epoch:28 step:26342 [D loss: 0.900248, acc.: 52.34%] [G loss: 1.310372]\n",
      "epoch:28 step:26343 [D loss: 0.464655, acc.: 82.81%] [G loss: 1.136550]\n",
      "epoch:28 step:26344 [D loss: 0.495412, acc.: 77.34%] [G loss: 0.888299]\n",
      "epoch:28 step:26345 [D loss: 0.433654, acc.: 82.81%] [G loss: 1.667790]\n",
      "epoch:28 step:26346 [D loss: 0.609725, acc.: 71.09%] [G loss: 1.507404]\n",
      "epoch:28 step:26347 [D loss: 0.609438, acc.: 62.50%] [G loss: 2.144805]\n",
      "epoch:28 step:26348 [D loss: 0.570423, acc.: 67.19%] [G loss: 1.238742]\n",
      "epoch:28 step:26349 [D loss: 0.673155, acc.: 64.06%] [G loss: 1.273876]\n",
      "epoch:28 step:26350 [D loss: 0.371368, acc.: 85.94%] [G loss: 1.214353]\n",
      "epoch:28 step:26351 [D loss: 0.387708, acc.: 86.72%] [G loss: 1.572621]\n",
      "epoch:28 step:26352 [D loss: 0.597123, acc.: 68.75%] [G loss: 1.237537]\n",
      "epoch:28 step:26353 [D loss: 0.386210, acc.: 80.47%] [G loss: 1.380731]\n",
      "epoch:28 step:26354 [D loss: 0.294321, acc.: 92.19%] [G loss: 1.340924]\n",
      "epoch:28 step:26355 [D loss: 0.166458, acc.: 95.31%] [G loss: 1.760698]\n",
      "epoch:28 step:26356 [D loss: 0.425508, acc.: 85.16%] [G loss: 1.581798]\n",
      "epoch:28 step:26357 [D loss: 0.240879, acc.: 94.53%] [G loss: 1.756656]\n",
      "epoch:28 step:26358 [D loss: 0.159842, acc.: 99.22%] [G loss: 1.765242]\n",
      "epoch:28 step:26359 [D loss: 0.595411, acc.: 64.84%] [G loss: 1.674475]\n",
      "epoch:28 step:26360 [D loss: 0.393513, acc.: 85.16%] [G loss: 1.549112]\n",
      "epoch:28 step:26361 [D loss: 0.606747, acc.: 64.84%] [G loss: 1.601777]\n",
      "epoch:28 step:26362 [D loss: 0.626679, acc.: 70.31%] [G loss: 1.551520]\n",
      "epoch:28 step:26363 [D loss: 0.636833, acc.: 64.84%] [G loss: 1.558498]\n",
      "epoch:28 step:26364 [D loss: 0.493032, acc.: 71.88%] [G loss: 1.758162]\n",
      "epoch:28 step:26365 [D loss: 0.465132, acc.: 76.56%] [G loss: 1.396198]\n",
      "epoch:28 step:26366 [D loss: 0.199382, acc.: 95.31%] [G loss: 1.869210]\n",
      "epoch:28 step:26367 [D loss: 0.265314, acc.: 92.97%] [G loss: 1.818103]\n",
      "epoch:28 step:26368 [D loss: 0.238852, acc.: 96.09%] [G loss: 2.144355]\n",
      "epoch:28 step:26369 [D loss: 0.455265, acc.: 82.03%] [G loss: 1.793900]\n",
      "epoch:28 step:26370 [D loss: 0.389632, acc.: 83.59%] [G loss: 1.667255]\n",
      "epoch:28 step:26371 [D loss: 0.428628, acc.: 83.59%] [G loss: 1.375249]\n",
      "epoch:28 step:26372 [D loss: 0.676968, acc.: 65.62%] [G loss: 1.428929]\n",
      "epoch:28 step:26373 [D loss: 0.524717, acc.: 74.22%] [G loss: 1.798363]\n",
      "epoch:28 step:26374 [D loss: 0.371939, acc.: 86.72%] [G loss: 1.128789]\n",
      "epoch:28 step:26375 [D loss: 0.327784, acc.: 83.59%] [G loss: 1.745805]\n",
      "epoch:28 step:26376 [D loss: 0.551312, acc.: 74.22%] [G loss: 1.528842]\n",
      "epoch:28 step:26377 [D loss: 0.319276, acc.: 90.62%] [G loss: 1.319241]\n",
      "epoch:28 step:26378 [D loss: 0.617256, acc.: 67.19%] [G loss: 0.988614]\n",
      "epoch:28 step:26379 [D loss: 0.365978, acc.: 81.25%] [G loss: 1.238147]\n",
      "epoch:28 step:26380 [D loss: 0.813553, acc.: 52.34%] [G loss: 1.384792]\n",
      "epoch:28 step:26381 [D loss: 0.234640, acc.: 95.31%] [G loss: 1.366960]\n",
      "epoch:28 step:26382 [D loss: 0.586987, acc.: 70.31%] [G loss: 1.017089]\n",
      "epoch:28 step:26383 [D loss: 0.654198, acc.: 58.59%] [G loss: 1.446750]\n",
      "epoch:28 step:26384 [D loss: 1.123272, acc.: 26.56%] [G loss: 1.536379]\n",
      "epoch:28 step:26385 [D loss: 0.233202, acc.: 95.31%] [G loss: 1.976339]\n",
      "epoch:28 step:26386 [D loss: 0.172519, acc.: 94.53%] [G loss: 1.873491]\n",
      "epoch:28 step:26387 [D loss: 0.368110, acc.: 90.62%] [G loss: 1.643499]\n",
      "epoch:28 step:26388 [D loss: 0.266708, acc.: 95.31%] [G loss: 1.813048]\n",
      "epoch:28 step:26389 [D loss: 0.913572, acc.: 48.44%] [G loss: 1.595678]\n",
      "epoch:28 step:26390 [D loss: 0.687453, acc.: 60.16%] [G loss: 1.395584]\n",
      "epoch:28 step:26391 [D loss: 0.631960, acc.: 64.06%] [G loss: 1.052295]\n",
      "epoch:28 step:26392 [D loss: 0.353845, acc.: 83.59%] [G loss: 1.478231]\n",
      "epoch:28 step:26393 [D loss: 1.257088, acc.: 28.12%] [G loss: 1.754314]\n",
      "epoch:28 step:26394 [D loss: 0.715988, acc.: 57.81%] [G loss: 1.522145]\n",
      "epoch:28 step:26395 [D loss: 0.200035, acc.: 95.31%] [G loss: 1.624761]\n",
      "epoch:28 step:26396 [D loss: 0.952695, acc.: 44.53%] [G loss: 1.790721]\n",
      "epoch:28 step:26397 [D loss: 0.766038, acc.: 58.59%] [G loss: 1.244932]\n",
      "epoch:28 step:26398 [D loss: 0.559804, acc.: 68.75%] [G loss: 1.307443]\n",
      "epoch:28 step:26399 [D loss: 0.685205, acc.: 57.81%] [G loss: 1.113781]\n",
      "epoch:28 step:26400 [D loss: 0.706344, acc.: 57.81%] [G loss: 1.272409]\n",
      "##############\n",
      "[3.86969294 2.68043055 6.79805351 5.81611172 4.22450156 6.1178208\n",
      " 5.51584466 5.47910668 5.67220969 5.21840016]\n",
      "##########\n",
      "epoch:28 step:26401 [D loss: 0.607777, acc.: 68.75%] [G loss: 1.198466]\n",
      "epoch:28 step:26402 [D loss: 0.422672, acc.: 81.25%] [G loss: 1.407390]\n",
      "epoch:28 step:26403 [D loss: 0.269355, acc.: 92.97%] [G loss: 1.705734]\n",
      "epoch:28 step:26404 [D loss: 0.391151, acc.: 84.38%] [G loss: 1.449390]\n",
      "epoch:28 step:26405 [D loss: 0.560069, acc.: 71.88%] [G loss: 1.442443]\n",
      "epoch:28 step:26406 [D loss: 0.605507, acc.: 66.41%] [G loss: 1.676734]\n",
      "epoch:28 step:26407 [D loss: 0.401861, acc.: 83.59%] [G loss: 1.459554]\n",
      "epoch:28 step:26408 [D loss: 0.545401, acc.: 69.53%] [G loss: 1.125889]\n",
      "epoch:28 step:26409 [D loss: 0.501947, acc.: 78.12%] [G loss: 1.544929]\n",
      "epoch:28 step:26410 [D loss: 0.465638, acc.: 81.25%] [G loss: 1.531961]\n",
      "epoch:28 step:26411 [D loss: 0.635625, acc.: 68.75%] [G loss: 1.502017]\n",
      "epoch:28 step:26412 [D loss: 0.355427, acc.: 82.81%] [G loss: 1.488250]\n",
      "epoch:28 step:26413 [D loss: 0.694676, acc.: 59.38%] [G loss: 1.471939]\n",
      "epoch:28 step:26414 [D loss: 0.813326, acc.: 50.78%] [G loss: 1.324858]\n",
      "epoch:28 step:26415 [D loss: 0.914838, acc.: 41.41%] [G loss: 1.117790]\n",
      "epoch:28 step:26416 [D loss: 0.483865, acc.: 77.34%] [G loss: 1.154325]\n",
      "epoch:28 step:26417 [D loss: 0.353312, acc.: 82.81%] [G loss: 0.843074]\n",
      "epoch:28 step:26418 [D loss: 0.329072, acc.: 85.16%] [G loss: 1.766000]\n",
      "epoch:28 step:26419 [D loss: 0.385056, acc.: 85.16%] [G loss: 1.794599]\n",
      "epoch:28 step:26420 [D loss: 0.176154, acc.: 97.66%] [G loss: 1.016092]\n",
      "epoch:28 step:26421 [D loss: 0.984676, acc.: 39.06%] [G loss: 1.850298]\n",
      "epoch:28 step:26422 [D loss: 0.963789, acc.: 39.06%] [G loss: 1.468951]\n",
      "epoch:28 step:26423 [D loss: 0.549945, acc.: 75.00%] [G loss: 2.027838]\n",
      "epoch:28 step:26424 [D loss: 0.252672, acc.: 94.53%] [G loss: 1.063433]\n",
      "epoch:28 step:26425 [D loss: 0.710721, acc.: 60.16%] [G loss: 1.889881]\n",
      "epoch:28 step:26426 [D loss: 0.347924, acc.: 87.50%] [G loss: 1.338551]\n",
      "epoch:28 step:26427 [D loss: 0.364706, acc.: 92.19%] [G loss: 1.385483]\n",
      "epoch:28 step:26428 [D loss: 0.309905, acc.: 83.59%] [G loss: 0.708019]\n",
      "epoch:28 step:26429 [D loss: 0.304689, acc.: 87.50%] [G loss: 1.006224]\n",
      "epoch:28 step:26430 [D loss: 0.132282, acc.: 97.66%] [G loss: 2.126513]\n",
      "epoch:28 step:26431 [D loss: 0.225213, acc.: 94.53%] [G loss: 1.374190]\n",
      "epoch:28 step:26432 [D loss: 0.273233, acc.: 94.53%] [G loss: 1.488488]\n",
      "epoch:28 step:26433 [D loss: 0.489064, acc.: 75.00%] [G loss: 1.837276]\n",
      "epoch:28 step:26434 [D loss: 0.327801, acc.: 90.62%] [G loss: 2.406635]\n",
      "epoch:28 step:26435 [D loss: 1.134212, acc.: 32.81%] [G loss: 1.593723]\n",
      "epoch:28 step:26436 [D loss: 0.681891, acc.: 60.16%] [G loss: 2.237903]\n",
      "epoch:28 step:26437 [D loss: 0.160952, acc.: 97.66%] [G loss: 1.950146]\n",
      "epoch:28 step:26438 [D loss: 0.870033, acc.: 53.12%] [G loss: 2.372491]\n",
      "epoch:28 step:26439 [D loss: 0.448812, acc.: 78.12%] [G loss: 1.478324]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:28 step:26440 [D loss: 0.236127, acc.: 91.41%] [G loss: 0.826660]\n",
      "epoch:28 step:26441 [D loss: 0.338425, acc.: 90.62%] [G loss: 0.556611]\n",
      "epoch:28 step:26442 [D loss: 0.146816, acc.: 98.44%] [G loss: 0.686621]\n",
      "epoch:28 step:26443 [D loss: 0.494014, acc.: 72.66%] [G loss: 2.266508]\n",
      "epoch:28 step:26444 [D loss: 0.157628, acc.: 98.44%] [G loss: 2.539329]\n",
      "epoch:28 step:26445 [D loss: 0.233457, acc.: 93.75%] [G loss: 1.966164]\n",
      "epoch:28 step:26446 [D loss: 1.483471, acc.: 35.16%] [G loss: 2.413353]\n",
      "epoch:28 step:26447 [D loss: 0.982624, acc.: 49.22%] [G loss: 1.562761]\n",
      "epoch:28 step:26448 [D loss: 1.223235, acc.: 21.88%] [G loss: 1.180704]\n",
      "epoch:28 step:26449 [D loss: 0.995171, acc.: 42.19%] [G loss: 2.019931]\n",
      "epoch:28 step:26450 [D loss: 0.760057, acc.: 55.47%] [G loss: 1.594498]\n",
      "epoch:28 step:26451 [D loss: 0.706520, acc.: 61.72%] [G loss: 1.858719]\n",
      "epoch:28 step:26452 [D loss: 0.849084, acc.: 53.91%] [G loss: 1.432095]\n",
      "epoch:28 step:26453 [D loss: 0.664697, acc.: 59.38%] [G loss: 1.289408]\n",
      "epoch:28 step:26454 [D loss: 0.405777, acc.: 85.16%] [G loss: 1.539965]\n",
      "epoch:28 step:26455 [D loss: 0.396529, acc.: 87.50%] [G loss: 1.418396]\n",
      "epoch:28 step:26456 [D loss: 0.158196, acc.: 96.88%] [G loss: 1.523564]\n",
      "epoch:28 step:26457 [D loss: 0.218513, acc.: 91.41%] [G loss: 1.812737]\n",
      "epoch:28 step:26458 [D loss: 0.218929, acc.: 96.88%] [G loss: 1.665325]\n",
      "epoch:28 step:26459 [D loss: 0.141657, acc.: 99.22%] [G loss: 1.894957]\n",
      "epoch:28 step:26460 [D loss: 0.638803, acc.: 64.06%] [G loss: 1.353944]\n",
      "epoch:28 step:26461 [D loss: 0.565140, acc.: 69.53%] [G loss: 1.801704]\n",
      "epoch:28 step:26462 [D loss: 0.568285, acc.: 71.88%] [G loss: 1.093668]\n",
      "epoch:28 step:26463 [D loss: 0.472719, acc.: 78.91%] [G loss: 1.145421]\n",
      "epoch:28 step:26464 [D loss: 0.450452, acc.: 83.59%] [G loss: 1.470470]\n",
      "epoch:28 step:26465 [D loss: 0.546582, acc.: 68.75%] [G loss: 1.529321]\n",
      "epoch:28 step:26466 [D loss: 0.212641, acc.: 92.97%] [G loss: 1.201779]\n",
      "epoch:28 step:26467 [D loss: 0.236870, acc.: 92.19%] [G loss: 1.924344]\n",
      "epoch:28 step:26468 [D loss: 0.160712, acc.: 96.09%] [G loss: 2.007519]\n",
      "epoch:28 step:26469 [D loss: 0.483105, acc.: 78.12%] [G loss: 1.866044]\n",
      "epoch:28 step:26470 [D loss: 0.283263, acc.: 94.53%] [G loss: 2.038260]\n",
      "epoch:28 step:26471 [D loss: 0.181121, acc.: 99.22%] [G loss: 1.920671]\n",
      "epoch:28 step:26472 [D loss: 0.636032, acc.: 64.84%] [G loss: 1.395352]\n",
      "epoch:28 step:26473 [D loss: 0.219524, acc.: 97.66%] [G loss: 1.623181]\n",
      "epoch:28 step:26474 [D loss: 0.274304, acc.: 94.53%] [G loss: 1.608878]\n",
      "epoch:28 step:26475 [D loss: 0.436699, acc.: 81.25%] [G loss: 1.052809]\n",
      "epoch:28 step:26476 [D loss: 0.411529, acc.: 86.72%] [G loss: 1.774167]\n",
      "epoch:28 step:26477 [D loss: 1.078518, acc.: 37.50%] [G loss: 1.033302]\n",
      "epoch:28 step:26478 [D loss: 0.513658, acc.: 80.47%] [G loss: 1.005417]\n",
      "epoch:28 step:26479 [D loss: 1.134465, acc.: 51.56%] [G loss: 1.354860]\n",
      "epoch:28 step:26480 [D loss: 0.550951, acc.: 77.34%] [G loss: 1.590245]\n",
      "epoch:28 step:26481 [D loss: 0.683799, acc.: 62.50%] [G loss: 1.587492]\n",
      "epoch:28 step:26482 [D loss: 0.713024, acc.: 60.16%] [G loss: 1.229669]\n",
      "epoch:28 step:26483 [D loss: 0.620431, acc.: 67.97%] [G loss: 0.853389]\n",
      "epoch:28 step:26484 [D loss: 0.511570, acc.: 78.12%] [G loss: 0.968186]\n",
      "epoch:28 step:26485 [D loss: 0.631307, acc.: 59.38%] [G loss: 1.307587]\n",
      "epoch:28 step:26486 [D loss: 0.688716, acc.: 56.25%] [G loss: 1.243536]\n",
      "epoch:28 step:26487 [D loss: 0.628148, acc.: 68.75%] [G loss: 1.072886]\n",
      "epoch:28 step:26488 [D loss: 0.597498, acc.: 67.97%] [G loss: 1.288609]\n",
      "epoch:28 step:26489 [D loss: 0.474551, acc.: 78.12%] [G loss: 1.579263]\n",
      "epoch:28 step:26490 [D loss: 0.405025, acc.: 88.28%] [G loss: 1.714115]\n",
      "epoch:28 step:26491 [D loss: 0.290649, acc.: 94.53%] [G loss: 1.712479]\n",
      "epoch:28 step:26492 [D loss: 0.129674, acc.: 99.22%] [G loss: 1.063083]\n",
      "epoch:28 step:26493 [D loss: 0.249485, acc.: 97.66%] [G loss: 1.877004]\n",
      "epoch:28 step:26494 [D loss: 0.409485, acc.: 84.38%] [G loss: 1.575749]\n",
      "epoch:28 step:26495 [D loss: 0.136895, acc.: 99.22%] [G loss: 1.311815]\n",
      "epoch:28 step:26496 [D loss: 0.258851, acc.: 88.28%] [G loss: 1.850525]\n",
      "epoch:28 step:26497 [D loss: 0.188732, acc.: 98.44%] [G loss: 1.453347]\n",
      "epoch:28 step:26498 [D loss: 0.479392, acc.: 75.00%] [G loss: 1.999099]\n",
      "epoch:28 step:26499 [D loss: 0.554989, acc.: 69.53%] [G loss: 1.683141]\n",
      "epoch:28 step:26500 [D loss: 0.477171, acc.: 79.69%] [G loss: 1.665872]\n",
      "epoch:28 step:26501 [D loss: 0.423574, acc.: 82.03%] [G loss: 2.317003]\n",
      "epoch:28 step:26502 [D loss: 0.687645, acc.: 64.84%] [G loss: 1.538394]\n",
      "epoch:28 step:26503 [D loss: 0.492398, acc.: 73.44%] [G loss: 1.921938]\n",
      "epoch:28 step:26504 [D loss: 0.794423, acc.: 50.78%] [G loss: 0.648833]\n",
      "epoch:28 step:26505 [D loss: 0.314583, acc.: 89.06%] [G loss: 1.332468]\n",
      "epoch:28 step:26506 [D loss: 0.598769, acc.: 66.41%] [G loss: 1.477104]\n",
      "epoch:28 step:26507 [D loss: 0.331076, acc.: 91.41%] [G loss: 1.527845]\n",
      "epoch:28 step:26508 [D loss: 0.469678, acc.: 82.81%] [G loss: 1.467480]\n",
      "epoch:28 step:26509 [D loss: 0.521541, acc.: 72.66%] [G loss: 1.360753]\n",
      "epoch:28 step:26510 [D loss: 0.417399, acc.: 85.94%] [G loss: 1.509381]\n",
      "epoch:28 step:26511 [D loss: 0.553275, acc.: 74.22%] [G loss: 1.422113]\n",
      "epoch:28 step:26512 [D loss: 0.276790, acc.: 96.09%] [G loss: 1.539647]\n",
      "epoch:28 step:26513 [D loss: 0.466165, acc.: 83.59%] [G loss: 1.494247]\n",
      "epoch:28 step:26514 [D loss: 0.235754, acc.: 94.53%] [G loss: 1.605685]\n",
      "epoch:28 step:26515 [D loss: 0.143903, acc.: 96.88%] [G loss: 2.100303]\n",
      "epoch:28 step:26516 [D loss: 0.324561, acc.: 89.84%] [G loss: 1.491335]\n",
      "epoch:28 step:26517 [D loss: 0.867841, acc.: 50.00%] [G loss: 1.693462]\n",
      "epoch:28 step:26518 [D loss: 0.752869, acc.: 51.56%] [G loss: 1.336917]\n",
      "epoch:28 step:26519 [D loss: 0.625419, acc.: 67.19%] [G loss: 1.433743]\n",
      "epoch:28 step:26520 [D loss: 0.345698, acc.: 82.81%] [G loss: 1.592284]\n",
      "epoch:28 step:26521 [D loss: 0.401349, acc.: 84.38%] [G loss: 1.893172]\n",
      "epoch:28 step:26522 [D loss: 0.277340, acc.: 94.53%] [G loss: 0.898323]\n",
      "epoch:28 step:26523 [D loss: 0.227056, acc.: 91.41%] [G loss: 1.729916]\n",
      "epoch:28 step:26524 [D loss: 0.219771, acc.: 97.66%] [G loss: 1.704276]\n",
      "epoch:28 step:26525 [D loss: 0.108145, acc.: 100.00%] [G loss: 2.349157]\n",
      "epoch:28 step:26526 [D loss: 0.255009, acc.: 93.75%] [G loss: 1.715912]\n",
      "epoch:28 step:26527 [D loss: 0.427176, acc.: 83.59%] [G loss: 1.627962]\n",
      "epoch:28 step:26528 [D loss: 0.124238, acc.: 99.22%] [G loss: 2.574769]\n",
      "epoch:28 step:26529 [D loss: 0.134623, acc.: 96.88%] [G loss: 2.101454]\n",
      "epoch:28 step:26530 [D loss: 0.497136, acc.: 77.34%] [G loss: 1.734880]\n",
      "epoch:28 step:26531 [D loss: 0.777110, acc.: 58.59%] [G loss: 1.458668]\n",
      "epoch:28 step:26532 [D loss: 0.802623, acc.: 52.34%] [G loss: 1.253333]\n",
      "epoch:28 step:26533 [D loss: 0.552187, acc.: 71.88%] [G loss: 1.100859]\n",
      "epoch:28 step:26534 [D loss: 0.312472, acc.: 91.41%] [G loss: 1.388710]\n",
      "epoch:28 step:26535 [D loss: 0.231048, acc.: 96.88%] [G loss: 0.852178]\n",
      "epoch:28 step:26536 [D loss: 0.566464, acc.: 64.06%] [G loss: 1.136412]\n",
      "epoch:28 step:26537 [D loss: 0.527631, acc.: 75.00%] [G loss: 1.270908]\n",
      "epoch:28 step:26538 [D loss: 0.536199, acc.: 71.09%] [G loss: 1.338086]\n",
      "epoch:28 step:26539 [D loss: 0.728770, acc.: 60.94%] [G loss: 1.547232]\n",
      "epoch:28 step:26540 [D loss: 0.528681, acc.: 76.56%] [G loss: 1.411694]\n",
      "epoch:28 step:26541 [D loss: 0.285624, acc.: 86.72%] [G loss: 0.853400]\n",
      "epoch:28 step:26542 [D loss: 0.320524, acc.: 89.84%] [G loss: 1.607568]\n",
      "epoch:28 step:26543 [D loss: 0.551196, acc.: 70.31%] [G loss: 1.792209]\n",
      "epoch:28 step:26544 [D loss: 0.181563, acc.: 96.09%] [G loss: 1.618572]\n",
      "epoch:28 step:26545 [D loss: 0.137691, acc.: 97.66%] [G loss: 2.071979]\n",
      "epoch:28 step:26546 [D loss: 0.364842, acc.: 87.50%] [G loss: 1.662441]\n",
      "epoch:28 step:26547 [D loss: 0.182604, acc.: 99.22%] [G loss: 1.788801]\n",
      "epoch:28 step:26548 [D loss: 0.109987, acc.: 98.44%] [G loss: 1.873459]\n",
      "epoch:28 step:26549 [D loss: 0.253614, acc.: 88.28%] [G loss: 2.612335]\n",
      "epoch:28 step:26550 [D loss: 0.103459, acc.: 98.44%] [G loss: 2.209130]\n",
      "epoch:28 step:26551 [D loss: 0.074508, acc.: 99.22%] [G loss: 2.484108]\n",
      "epoch:28 step:26552 [D loss: 1.034341, acc.: 53.91%] [G loss: 2.180815]\n",
      "epoch:28 step:26553 [D loss: 1.033095, acc.: 50.00%] [G loss: 1.263868]\n",
      "epoch:28 step:26554 [D loss: 0.659633, acc.: 63.28%] [G loss: 1.230721]\n",
      "epoch:28 step:26555 [D loss: 1.685726, acc.: 9.38%] [G loss: 1.135374]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:28 step:26556 [D loss: 0.848841, acc.: 45.31%] [G loss: 1.334249]\n",
      "epoch:28 step:26557 [D loss: 0.686119, acc.: 60.16%] [G loss: 1.593383]\n",
      "epoch:28 step:26558 [D loss: 0.665577, acc.: 65.62%] [G loss: 1.162960]\n",
      "epoch:28 step:26559 [D loss: 0.435501, acc.: 77.34%] [G loss: 1.580827]\n",
      "epoch:28 step:26560 [D loss: 0.358148, acc.: 89.06%] [G loss: 1.721054]\n",
      "epoch:28 step:26561 [D loss: 0.351368, acc.: 88.28%] [G loss: 1.465731]\n",
      "epoch:28 step:26562 [D loss: 0.658276, acc.: 55.47%] [G loss: 0.865847]\n",
      "epoch:28 step:26563 [D loss: 0.500596, acc.: 74.22%] [G loss: 0.601622]\n",
      "epoch:28 step:26564 [D loss: 0.900318, acc.: 50.78%] [G loss: 1.167832]\n",
      "epoch:28 step:26565 [D loss: 0.646031, acc.: 59.38%] [G loss: 1.016937]\n",
      "epoch:28 step:26566 [D loss: 0.335001, acc.: 92.19%] [G loss: 1.372031]\n",
      "epoch:28 step:26567 [D loss: 0.327761, acc.: 90.62%] [G loss: 0.926056]\n",
      "epoch:28 step:26568 [D loss: 0.224871, acc.: 90.62%] [G loss: 1.436995]\n",
      "epoch:28 step:26569 [D loss: 0.205905, acc.: 95.31%] [G loss: 1.666465]\n",
      "epoch:28 step:26570 [D loss: 0.244761, acc.: 88.28%] [G loss: 2.039735]\n",
      "epoch:28 step:26571 [D loss: 0.139676, acc.: 98.44%] [G loss: 1.582769]\n",
      "epoch:28 step:26572 [D loss: 0.067950, acc.: 100.00%] [G loss: 2.504453]\n",
      "epoch:28 step:26573 [D loss: 0.354304, acc.: 90.62%] [G loss: 1.995341]\n",
      "epoch:28 step:26574 [D loss: 0.465239, acc.: 82.03%] [G loss: 0.766933]\n",
      "epoch:28 step:26575 [D loss: 0.526115, acc.: 76.56%] [G loss: 1.973493]\n",
      "epoch:28 step:26576 [D loss: 0.621886, acc.: 57.81%] [G loss: 1.805220]\n",
      "epoch:28 step:26577 [D loss: 0.269964, acc.: 93.75%] [G loss: 1.597246]\n",
      "epoch:28 step:26578 [D loss: 0.199691, acc.: 94.53%] [G loss: 0.967099]\n",
      "epoch:28 step:26579 [D loss: 0.085120, acc.: 100.00%] [G loss: 1.876900]\n",
      "epoch:28 step:26580 [D loss: 0.082271, acc.: 100.00%] [G loss: 2.015627]\n",
      "epoch:28 step:26581 [D loss: 0.087488, acc.: 100.00%] [G loss: 2.043573]\n",
      "epoch:28 step:26582 [D loss: 0.090719, acc.: 99.22%] [G loss: 1.438656]\n",
      "epoch:28 step:26583 [D loss: 0.118953, acc.: 97.66%] [G loss: 2.152891]\n",
      "epoch:28 step:26584 [D loss: 0.482892, acc.: 78.91%] [G loss: 2.798524]\n",
      "epoch:28 step:26585 [D loss: 1.065072, acc.: 44.53%] [G loss: 2.359077]\n",
      "epoch:28 step:26586 [D loss: 0.224930, acc.: 96.09%] [G loss: 2.454252]\n",
      "epoch:28 step:26587 [D loss: 0.762364, acc.: 59.38%] [G loss: 2.086444]\n",
      "epoch:28 step:26588 [D loss: 0.516450, acc.: 74.22%] [G loss: 0.358799]\n",
      "epoch:28 step:26589 [D loss: 0.499274, acc.: 73.44%] [G loss: 1.639693]\n",
      "epoch:28 step:26590 [D loss: 0.463689, acc.: 78.91%] [G loss: 0.934322]\n",
      "epoch:28 step:26591 [D loss: 0.822792, acc.: 50.00%] [G loss: 1.639769]\n",
      "epoch:28 step:26592 [D loss: 0.652432, acc.: 59.38%] [G loss: 1.320959]\n",
      "epoch:28 step:26593 [D loss: 0.867355, acc.: 42.19%] [G loss: 0.956818]\n",
      "epoch:28 step:26594 [D loss: 0.464753, acc.: 75.78%] [G loss: 1.396332]\n",
      "epoch:28 step:26595 [D loss: 0.206466, acc.: 94.53%] [G loss: 1.987299]\n",
      "epoch:28 step:26596 [D loss: 0.438148, acc.: 82.81%] [G loss: 1.739072]\n",
      "epoch:28 step:26597 [D loss: 0.428204, acc.: 84.38%] [G loss: 1.633597]\n",
      "epoch:28 step:26598 [D loss: 0.392041, acc.: 82.03%] [G loss: 1.397396]\n",
      "epoch:28 step:26599 [D loss: 0.487207, acc.: 75.78%] [G loss: 1.415090]\n",
      "epoch:28 step:26600 [D loss: 0.413041, acc.: 85.94%] [G loss: 1.246407]\n",
      "##############\n",
      "[3.89055622 2.74924894 6.53532535 6.08716157 4.45247605 6.51548162\n",
      " 5.45403233 6.14131122 5.98653675 4.98157003]\n",
      "##########\n",
      "epoch:28 step:26601 [D loss: 0.134222, acc.: 97.66%] [G loss: 1.564251]\n",
      "epoch:28 step:26602 [D loss: 0.120615, acc.: 97.66%] [G loss: 2.193806]\n",
      "epoch:28 step:26603 [D loss: 0.212791, acc.: 93.75%] [G loss: 2.421916]\n",
      "epoch:28 step:26604 [D loss: 0.772981, acc.: 56.25%] [G loss: 1.322035]\n",
      "epoch:28 step:26605 [D loss: 0.240107, acc.: 87.50%] [G loss: 1.619425]\n",
      "epoch:28 step:26606 [D loss: 0.095721, acc.: 99.22%] [G loss: 1.417651]\n",
      "epoch:28 step:26607 [D loss: 0.197300, acc.: 98.44%] [G loss: 1.011868]\n",
      "epoch:28 step:26608 [D loss: 0.498435, acc.: 74.22%] [G loss: 1.637332]\n",
      "epoch:28 step:26609 [D loss: 0.691711, acc.: 54.69%] [G loss: 1.648701]\n",
      "epoch:28 step:26610 [D loss: 0.760246, acc.: 56.25%] [G loss: 1.272354]\n",
      "epoch:28 step:26611 [D loss: 0.608657, acc.: 66.41%] [G loss: 1.243432]\n",
      "epoch:28 step:26612 [D loss: 0.819098, acc.: 57.03%] [G loss: 1.178469]\n",
      "epoch:28 step:26613 [D loss: 0.183052, acc.: 93.75%] [G loss: 1.524981]\n",
      "epoch:28 step:26614 [D loss: 0.156839, acc.: 96.88%] [G loss: 1.780383]\n",
      "epoch:28 step:26615 [D loss: 0.873191, acc.: 50.00%] [G loss: 1.173680]\n",
      "epoch:28 step:26616 [D loss: 0.237351, acc.: 94.53%] [G loss: 1.505185]\n",
      "epoch:28 step:26617 [D loss: 0.261775, acc.: 96.09%] [G loss: 1.409051]\n",
      "epoch:28 step:26618 [D loss: 0.843411, acc.: 46.88%] [G loss: 1.379210]\n",
      "epoch:28 step:26619 [D loss: 0.594072, acc.: 72.66%] [G loss: 1.293267]\n",
      "epoch:28 step:26620 [D loss: 0.468797, acc.: 79.69%] [G loss: 1.426067]\n",
      "epoch:28 step:26621 [D loss: 0.648233, acc.: 62.50%] [G loss: 1.745638]\n",
      "epoch:28 step:26622 [D loss: 0.482285, acc.: 76.56%] [G loss: 1.198114]\n",
      "epoch:28 step:26623 [D loss: 0.553140, acc.: 73.44%] [G loss: 0.875112]\n",
      "epoch:28 step:26624 [D loss: 0.746302, acc.: 57.03%] [G loss: 1.082716]\n",
      "epoch:28 step:26625 [D loss: 0.333017, acc.: 88.28%] [G loss: 1.496065]\n",
      "epoch:28 step:26626 [D loss: 0.302313, acc.: 93.75%] [G loss: 1.575502]\n",
      "epoch:28 step:26627 [D loss: 0.989990, acc.: 38.28%] [G loss: 1.399045]\n",
      "epoch:28 step:26628 [D loss: 0.576131, acc.: 67.97%] [G loss: 1.383995]\n",
      "epoch:28 step:26629 [D loss: 0.382051, acc.: 80.47%] [G loss: 1.428776]\n",
      "epoch:28 step:26630 [D loss: 0.433778, acc.: 82.03%] [G loss: 0.979526]\n",
      "epoch:28 step:26631 [D loss: 0.852175, acc.: 45.31%] [G loss: 1.232508]\n",
      "epoch:28 step:26632 [D loss: 0.212536, acc.: 92.97%] [G loss: 0.779948]\n",
      "epoch:28 step:26633 [D loss: 0.148168, acc.: 97.66%] [G loss: 1.688701]\n",
      "epoch:28 step:26634 [D loss: 0.116215, acc.: 98.44%] [G loss: 2.428725]\n",
      "epoch:28 step:26635 [D loss: 0.130095, acc.: 97.66%] [G loss: 1.377162]\n",
      "epoch:28 step:26636 [D loss: 0.131285, acc.: 98.44%] [G loss: 2.290480]\n",
      "epoch:28 step:26637 [D loss: 0.171201, acc.: 98.44%] [G loss: 1.791723]\n",
      "epoch:28 step:26638 [D loss: 0.202662, acc.: 92.97%] [G loss: 2.134249]\n",
      "epoch:28 step:26639 [D loss: 0.201091, acc.: 96.88%] [G loss: 2.077504]\n",
      "epoch:28 step:26640 [D loss: 0.172570, acc.: 98.44%] [G loss: 1.715622]\n",
      "epoch:28 step:26641 [D loss: 0.244596, acc.: 89.84%] [G loss: 2.734231]\n",
      "epoch:28 step:26642 [D loss: 0.093243, acc.: 100.00%] [G loss: 2.245009]\n",
      "epoch:28 step:26643 [D loss: 0.142287, acc.: 98.44%] [G loss: 2.096975]\n",
      "epoch:28 step:26644 [D loss: 0.210166, acc.: 93.75%] [G loss: 2.405265]\n",
      "epoch:28 step:26645 [D loss: 0.121323, acc.: 98.44%] [G loss: 2.112581]\n",
      "epoch:28 step:26646 [D loss: 0.250034, acc.: 89.84%] [G loss: 0.993325]\n",
      "epoch:28 step:26647 [D loss: 2.953591, acc.: 1.56%] [G loss: 2.135710]\n",
      "epoch:28 step:26648 [D loss: 0.333401, acc.: 89.84%] [G loss: 2.946906]\n",
      "epoch:28 step:26649 [D loss: 0.615022, acc.: 65.62%] [G loss: 1.372058]\n",
      "epoch:28 step:26650 [D loss: 0.452878, acc.: 82.03%] [G loss: 1.503377]\n",
      "epoch:28 step:26651 [D loss: 0.771577, acc.: 60.94%] [G loss: 1.777078]\n",
      "epoch:28 step:26652 [D loss: 0.563338, acc.: 75.00%] [G loss: 1.811201]\n",
      "epoch:28 step:26653 [D loss: 0.882911, acc.: 50.00%] [G loss: 1.364104]\n",
      "epoch:28 step:26654 [D loss: 0.625619, acc.: 67.19%] [G loss: 1.426472]\n",
      "epoch:28 step:26655 [D loss: 0.521540, acc.: 75.00%] [G loss: 2.111232]\n",
      "epoch:28 step:26656 [D loss: 0.928951, acc.: 46.09%] [G loss: 2.151320]\n",
      "epoch:28 step:26657 [D loss: 1.290513, acc.: 42.97%] [G loss: 1.964071]\n",
      "epoch:28 step:26658 [D loss: 1.261169, acc.: 38.28%] [G loss: 2.165679]\n",
      "epoch:28 step:26659 [D loss: 0.989142, acc.: 50.00%] [G loss: 2.251501]\n",
      "epoch:28 step:26660 [D loss: 0.299511, acc.: 86.72%] [G loss: 2.073908]\n",
      "epoch:28 step:26661 [D loss: 0.547037, acc.: 72.66%] [G loss: 1.368048]\n",
      "epoch:28 step:26662 [D loss: 0.957602, acc.: 44.53%] [G loss: 1.743368]\n",
      "epoch:28 step:26663 [D loss: 0.349510, acc.: 83.59%] [G loss: 3.138290]\n",
      "epoch:28 step:26664 [D loss: 0.199067, acc.: 95.31%] [G loss: 2.351393]\n",
      "epoch:28 step:26665 [D loss: 0.732192, acc.: 60.16%] [G loss: 1.743569]\n",
      "epoch:28 step:26666 [D loss: 0.416897, acc.: 80.47%] [G loss: 2.160732]\n",
      "epoch:28 step:26667 [D loss: 0.838079, acc.: 52.34%] [G loss: 2.546686]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:28 step:26668 [D loss: 0.998705, acc.: 47.66%] [G loss: 1.909044]\n",
      "epoch:28 step:26669 [D loss: 0.827259, acc.: 50.00%] [G loss: 1.688349]\n",
      "epoch:28 step:26670 [D loss: 0.605904, acc.: 67.19%] [G loss: 1.167916]\n",
      "epoch:28 step:26671 [D loss: 0.763157, acc.: 52.34%] [G loss: 1.276387]\n",
      "epoch:28 step:26672 [D loss: 0.580244, acc.: 66.41%] [G loss: 1.469541]\n",
      "epoch:28 step:26673 [D loss: 0.846876, acc.: 39.84%] [G loss: 1.658894]\n",
      "epoch:28 step:26674 [D loss: 0.754138, acc.: 54.69%] [G loss: 1.925502]\n",
      "epoch:28 step:26675 [D loss: 0.674908, acc.: 66.41%] [G loss: 1.124711]\n",
      "epoch:28 step:26676 [D loss: 0.671068, acc.: 65.62%] [G loss: 1.593401]\n",
      "epoch:28 step:26677 [D loss: 0.808656, acc.: 50.78%] [G loss: 0.910155]\n",
      "epoch:28 step:26678 [D loss: 0.670127, acc.: 57.81%] [G loss: 1.448787]\n",
      "epoch:28 step:26679 [D loss: 0.714485, acc.: 52.34%] [G loss: 1.313002]\n",
      "epoch:28 step:26680 [D loss: 0.549829, acc.: 71.88%] [G loss: 1.162410]\n",
      "epoch:28 step:26681 [D loss: 0.529321, acc.: 71.88%] [G loss: 1.416557]\n",
      "epoch:28 step:26682 [D loss: 0.705670, acc.: 53.91%] [G loss: 1.384612]\n",
      "epoch:28 step:26683 [D loss: 0.707935, acc.: 56.25%] [G loss: 1.341363]\n",
      "epoch:28 step:26684 [D loss: 0.447825, acc.: 82.81%] [G loss: 2.156295]\n",
      "epoch:28 step:26685 [D loss: 0.358928, acc.: 86.72%] [G loss: 1.814885]\n",
      "epoch:28 step:26686 [D loss: 0.297309, acc.: 94.53%] [G loss: 1.944516]\n",
      "epoch:28 step:26687 [D loss: 0.185605, acc.: 92.19%] [G loss: 2.250410]\n",
      "epoch:28 step:26688 [D loss: 0.135338, acc.: 96.09%] [G loss: 2.206343]\n",
      "epoch:28 step:26689 [D loss: 0.204255, acc.: 96.88%] [G loss: 2.157512]\n",
      "epoch:28 step:26690 [D loss: 0.239568, acc.: 94.53%] [G loss: 2.115453]\n",
      "epoch:28 step:26691 [D loss: 0.279324, acc.: 93.75%] [G loss: 2.750152]\n",
      "epoch:28 step:26692 [D loss: 0.159198, acc.: 96.88%] [G loss: 2.226658]\n",
      "epoch:28 step:26693 [D loss: 0.114862, acc.: 98.44%] [G loss: 2.209590]\n",
      "epoch:28 step:26694 [D loss: 0.755645, acc.: 57.81%] [G loss: 1.861653]\n",
      "epoch:28 step:26695 [D loss: 0.521485, acc.: 77.34%] [G loss: 1.899827]\n",
      "epoch:28 step:26696 [D loss: 0.718752, acc.: 57.81%] [G loss: 1.419662]\n",
      "epoch:28 step:26697 [D loss: 0.752006, acc.: 50.78%] [G loss: 1.520791]\n",
      "epoch:28 step:26698 [D loss: 0.794229, acc.: 53.12%] [G loss: 0.837347]\n",
      "epoch:28 step:26699 [D loss: 0.800218, acc.: 53.12%] [G loss: 1.055879]\n",
      "epoch:28 step:26700 [D loss: 0.460190, acc.: 81.25%] [G loss: 1.289176]\n",
      "epoch:28 step:26701 [D loss: 0.326471, acc.: 85.94%] [G loss: 1.250169]\n",
      "epoch:28 step:26702 [D loss: 0.368856, acc.: 86.72%] [G loss: 1.362520]\n",
      "epoch:28 step:26703 [D loss: 0.329703, acc.: 88.28%] [G loss: 1.563207]\n",
      "epoch:28 step:26704 [D loss: 0.172938, acc.: 97.66%] [G loss: 1.784448]\n",
      "epoch:28 step:26705 [D loss: 0.123664, acc.: 97.66%] [G loss: 2.362730]\n",
      "epoch:28 step:26706 [D loss: 0.123898, acc.: 98.44%] [G loss: 1.700519]\n",
      "epoch:28 step:26707 [D loss: 0.075211, acc.: 100.00%] [G loss: 2.527686]\n",
      "epoch:28 step:26708 [D loss: 0.188569, acc.: 96.88%] [G loss: 2.403405]\n",
      "epoch:28 step:26709 [D loss: 0.913638, acc.: 55.47%] [G loss: 1.603469]\n",
      "epoch:28 step:26710 [D loss: 0.339518, acc.: 89.06%] [G loss: 1.554875]\n",
      "epoch:28 step:26711 [D loss: 0.777467, acc.: 56.25%] [G loss: 1.592889]\n",
      "epoch:28 step:26712 [D loss: 0.463402, acc.: 75.00%] [G loss: 1.188782]\n",
      "epoch:28 step:26713 [D loss: 0.423681, acc.: 83.59%] [G loss: 1.427807]\n",
      "epoch:28 step:26714 [D loss: 0.461788, acc.: 81.25%] [G loss: 1.402286]\n",
      "epoch:28 step:26715 [D loss: 0.231931, acc.: 92.97%] [G loss: 1.696250]\n",
      "epoch:28 step:26716 [D loss: 0.481323, acc.: 70.31%] [G loss: 1.857293]\n",
      "epoch:28 step:26717 [D loss: 0.291807, acc.: 83.59%] [G loss: 1.302762]\n",
      "epoch:28 step:26718 [D loss: 1.082451, acc.: 42.19%] [G loss: 1.932571]\n",
      "epoch:28 step:26719 [D loss: 0.741694, acc.: 56.25%] [G loss: 1.556124]\n",
      "epoch:28 step:26720 [D loss: 0.470153, acc.: 78.12%] [G loss: 1.394610]\n",
      "epoch:28 step:26721 [D loss: 0.661970, acc.: 61.72%] [G loss: 1.146229]\n",
      "epoch:28 step:26722 [D loss: 0.692929, acc.: 60.16%] [G loss: 1.068055]\n",
      "epoch:28 step:26723 [D loss: 0.537273, acc.: 73.44%] [G loss: 1.060072]\n",
      "epoch:28 step:26724 [D loss: 0.561098, acc.: 65.62%] [G loss: 1.186371]\n",
      "epoch:28 step:26725 [D loss: 0.221579, acc.: 97.66%] [G loss: 1.126752]\n",
      "epoch:28 step:26726 [D loss: 0.176635, acc.: 99.22%] [G loss: 1.429576]\n",
      "epoch:28 step:26727 [D loss: 0.239225, acc.: 93.75%] [G loss: 1.277279]\n",
      "epoch:28 step:26728 [D loss: 0.577378, acc.: 69.53%] [G loss: 1.816121]\n",
      "epoch:28 step:26729 [D loss: 0.643408, acc.: 64.06%] [G loss: 1.365784]\n",
      "epoch:28 step:26730 [D loss: 0.392621, acc.: 88.28%] [G loss: 1.599932]\n",
      "epoch:28 step:26731 [D loss: 0.369526, acc.: 85.94%] [G loss: 1.256977]\n",
      "epoch:28 step:26732 [D loss: 0.595150, acc.: 67.19%] [G loss: 1.371136]\n",
      "epoch:28 step:26733 [D loss: 0.462756, acc.: 77.34%] [G loss: 1.528131]\n",
      "epoch:28 step:26734 [D loss: 0.272647, acc.: 89.06%] [G loss: 1.291198]\n",
      "epoch:28 step:26735 [D loss: 0.148455, acc.: 100.00%] [G loss: 1.570906]\n",
      "epoch:28 step:26736 [D loss: 0.422348, acc.: 78.12%] [G loss: 1.658725]\n",
      "epoch:28 step:26737 [D loss: 0.565962, acc.: 69.53%] [G loss: 1.269428]\n",
      "epoch:28 step:26738 [D loss: 0.415384, acc.: 85.16%] [G loss: 1.381446]\n",
      "epoch:28 step:26739 [D loss: 0.202530, acc.: 92.97%] [G loss: 1.527829]\n",
      "epoch:28 step:26740 [D loss: 0.094553, acc.: 98.44%] [G loss: 1.985341]\n",
      "epoch:28 step:26741 [D loss: 0.159535, acc.: 95.31%] [G loss: 1.915958]\n",
      "epoch:28 step:26742 [D loss: 0.280524, acc.: 92.19%] [G loss: 1.638371]\n",
      "epoch:28 step:26743 [D loss: 0.114037, acc.: 96.88%] [G loss: 2.071444]\n",
      "epoch:28 step:26744 [D loss: 0.106396, acc.: 99.22%] [G loss: 1.952564]\n",
      "epoch:28 step:26745 [D loss: 0.612167, acc.: 64.84%] [G loss: 1.595324]\n",
      "epoch:28 step:26746 [D loss: 0.379892, acc.: 85.16%] [G loss: 1.490949]\n",
      "epoch:28 step:26747 [D loss: 0.210912, acc.: 94.53%] [G loss: 1.385418]\n",
      "epoch:28 step:26748 [D loss: 0.361081, acc.: 87.50%] [G loss: 1.987538]\n",
      "epoch:28 step:26749 [D loss: 0.363771, acc.: 86.72%] [G loss: 1.521026]\n",
      "epoch:28 step:26750 [D loss: 0.376732, acc.: 89.84%] [G loss: 1.823321]\n",
      "epoch:28 step:26751 [D loss: 0.298684, acc.: 89.06%] [G loss: 1.993426]\n",
      "epoch:28 step:26752 [D loss: 0.718712, acc.: 57.03%] [G loss: 1.612356]\n",
      "epoch:28 step:26753 [D loss: 0.136009, acc.: 97.66%] [G loss: 0.883281]\n",
      "epoch:28 step:26754 [D loss: 0.222495, acc.: 94.53%] [G loss: 1.968060]\n",
      "epoch:28 step:26755 [D loss: 0.258969, acc.: 91.41%] [G loss: 2.221001]\n",
      "epoch:28 step:26756 [D loss: 0.272976, acc.: 92.19%] [G loss: 2.008453]\n",
      "epoch:28 step:26757 [D loss: 0.272628, acc.: 93.75%] [G loss: 1.561737]\n",
      "epoch:28 step:26758 [D loss: 0.228504, acc.: 96.09%] [G loss: 1.448188]\n",
      "epoch:28 step:26759 [D loss: 0.319050, acc.: 91.41%] [G loss: 1.929849]\n",
      "epoch:28 step:26760 [D loss: 0.170911, acc.: 96.09%] [G loss: 2.351151]\n",
      "epoch:28 step:26761 [D loss: 0.752176, acc.: 59.38%] [G loss: 1.485771]\n",
      "epoch:28 step:26762 [D loss: 0.613589, acc.: 63.28%] [G loss: 1.360725]\n",
      "epoch:28 step:26763 [D loss: 0.313466, acc.: 89.84%] [G loss: 1.640913]\n",
      "epoch:28 step:26764 [D loss: 0.793345, acc.: 51.56%] [G loss: 1.330752]\n",
      "epoch:28 step:26765 [D loss: 0.709635, acc.: 55.47%] [G loss: 1.199360]\n",
      "epoch:28 step:26766 [D loss: 0.296942, acc.: 89.06%] [G loss: 1.478680]\n",
      "epoch:28 step:26767 [D loss: 0.781627, acc.: 50.00%] [G loss: 0.983629]\n",
      "epoch:28 step:26768 [D loss: 0.371240, acc.: 89.06%] [G loss: 0.496517]\n",
      "epoch:28 step:26769 [D loss: 0.225350, acc.: 92.19%] [G loss: 1.643896]\n",
      "epoch:28 step:26770 [D loss: 0.172574, acc.: 97.66%] [G loss: 1.802133]\n",
      "epoch:28 step:26771 [D loss: 0.218358, acc.: 96.09%] [G loss: 1.789235]\n",
      "epoch:28 step:26772 [D loss: 0.111937, acc.: 99.22%] [G loss: 2.036299]\n",
      "epoch:28 step:26773 [D loss: 0.131409, acc.: 96.88%] [G loss: 1.601388]\n",
      "epoch:28 step:26774 [D loss: 0.562151, acc.: 71.09%] [G loss: 2.406314]\n",
      "epoch:28 step:26775 [D loss: 0.361925, acc.: 84.38%] [G loss: 1.377139]\n",
      "epoch:28 step:26776 [D loss: 0.525406, acc.: 75.78%] [G loss: 1.903031]\n",
      "epoch:28 step:26777 [D loss: 0.897430, acc.: 44.53%] [G loss: 1.390152]\n",
      "epoch:28 step:26778 [D loss: 0.237935, acc.: 92.97%] [G loss: 2.283178]\n",
      "epoch:28 step:26779 [D loss: 0.098926, acc.: 100.00%] [G loss: 2.659738]\n",
      "epoch:28 step:26780 [D loss: 0.238832, acc.: 92.97%] [G loss: 1.797985]\n",
      "epoch:28 step:26781 [D loss: 0.116250, acc.: 99.22%] [G loss: 2.266646]\n",
      "epoch:28 step:26782 [D loss: 0.170855, acc.: 96.88%] [G loss: 1.221890]\n",
      "epoch:28 step:26783 [D loss: 0.088523, acc.: 100.00%] [G loss: 0.473745]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:28 step:26784 [D loss: 0.142324, acc.: 97.66%] [G loss: 2.723834]\n",
      "epoch:28 step:26785 [D loss: 0.383757, acc.: 77.34%] [G loss: 2.357748]\n",
      "epoch:28 step:26786 [D loss: 0.070649, acc.: 100.00%] [G loss: 2.290269]\n",
      "epoch:28 step:26787 [D loss: 0.156634, acc.: 94.53%] [G loss: 3.100943]\n",
      "epoch:28 step:26788 [D loss: 0.064145, acc.: 100.00%] [G loss: 2.951105]\n",
      "epoch:28 step:26789 [D loss: 0.165344, acc.: 96.88%] [G loss: 2.351271]\n",
      "epoch:28 step:26790 [D loss: 0.041996, acc.: 100.00%] [G loss: 2.119603]\n",
      "epoch:28 step:26791 [D loss: 0.132850, acc.: 96.09%] [G loss: 3.024960]\n",
      "epoch:28 step:26792 [D loss: 0.262631, acc.: 84.38%] [G loss: 3.480578]\n",
      "epoch:28 step:26793 [D loss: 0.016284, acc.: 100.00%] [G loss: 4.562970]\n",
      "epoch:28 step:26794 [D loss: 0.026598, acc.: 100.00%] [G loss: 4.442389]\n",
      "epoch:28 step:26795 [D loss: 1.492780, acc.: 51.56%] [G loss: 2.367645]\n",
      "epoch:28 step:26796 [D loss: 1.650517, acc.: 15.62%] [G loss: 1.824248]\n",
      "epoch:28 step:26797 [D loss: 0.815777, acc.: 54.69%] [G loss: 1.245621]\n",
      "epoch:28 step:26798 [D loss: 1.585442, acc.: 21.88%] [G loss: 2.768928]\n",
      "epoch:28 step:26799 [D loss: 0.256072, acc.: 91.41%] [G loss: 3.581303]\n",
      "epoch:28 step:26800 [D loss: 0.094086, acc.: 98.44%] [G loss: 2.991001]\n",
      "##############\n",
      "[4.63850225 3.11570673 6.44152652 6.49385303 4.68016304 6.51926766\n",
      " 5.21305415 5.44266801 5.95380112 5.1443796 ]\n",
      "##########\n",
      "epoch:28 step:26801 [D loss: 1.126516, acc.: 48.44%] [G loss: 2.790831]\n",
      "epoch:28 step:26802 [D loss: 1.265893, acc.: 49.22%] [G loss: 1.905984]\n",
      "epoch:28 step:26803 [D loss: 0.882828, acc.: 46.88%] [G loss: 1.394722]\n",
      "epoch:28 step:26804 [D loss: 0.476794, acc.: 78.12%] [G loss: 1.767742]\n",
      "epoch:28 step:26805 [D loss: 0.247873, acc.: 93.75%] [G loss: 1.677437]\n",
      "epoch:28 step:26806 [D loss: 0.159198, acc.: 96.09%] [G loss: 2.052655]\n",
      "epoch:28 step:26807 [D loss: 0.224345, acc.: 92.19%] [G loss: 2.662231]\n",
      "epoch:28 step:26808 [D loss: 0.116519, acc.: 98.44%] [G loss: 2.746034]\n",
      "epoch:28 step:26809 [D loss: 0.188596, acc.: 96.88%] [G loss: 2.661878]\n",
      "epoch:28 step:26810 [D loss: 0.079394, acc.: 96.09%] [G loss: 3.349131]\n",
      "epoch:28 step:26811 [D loss: 0.100144, acc.: 99.22%] [G loss: 3.415414]\n",
      "epoch:28 step:26812 [D loss: 0.137578, acc.: 97.66%] [G loss: 3.041557]\n",
      "epoch:28 step:26813 [D loss: 0.599678, acc.: 70.31%] [G loss: 2.534857]\n",
      "epoch:28 step:26814 [D loss: 0.372137, acc.: 84.38%] [G loss: 1.664670]\n",
      "epoch:28 step:26815 [D loss: 0.115774, acc.: 96.88%] [G loss: 2.309171]\n",
      "epoch:28 step:26816 [D loss: 0.133089, acc.: 96.88%] [G loss: 1.954694]\n",
      "epoch:28 step:26817 [D loss: 0.119820, acc.: 96.88%] [G loss: 1.837500]\n",
      "epoch:28 step:26818 [D loss: 0.036463, acc.: 100.00%] [G loss: 2.834692]\n",
      "epoch:28 step:26819 [D loss: 0.047278, acc.: 99.22%] [G loss: 2.629896]\n",
      "epoch:28 step:26820 [D loss: 0.127050, acc.: 97.66%] [G loss: 1.172974]\n",
      "epoch:28 step:26821 [D loss: 0.322788, acc.: 83.59%] [G loss: 2.613084]\n",
      "epoch:28 step:26822 [D loss: 0.038115, acc.: 99.22%] [G loss: 3.593732]\n",
      "epoch:28 step:26823 [D loss: 3.155525, acc.: 38.28%] [G loss: 2.667537]\n",
      "epoch:28 step:26824 [D loss: 1.582393, acc.: 43.75%] [G loss: 1.535493]\n",
      "epoch:28 step:26825 [D loss: 0.917369, acc.: 53.12%] [G loss: 1.794515]\n",
      "epoch:28 step:26826 [D loss: 0.552095, acc.: 73.44%] [G loss: 2.051217]\n",
      "epoch:28 step:26827 [D loss: 0.290621, acc.: 84.38%] [G loss: 2.387536]\n",
      "epoch:28 step:26828 [D loss: 0.071492, acc.: 99.22%] [G loss: 3.230727]\n",
      "epoch:28 step:26829 [D loss: 0.078517, acc.: 99.22%] [G loss: 3.319167]\n",
      "epoch:28 step:26830 [D loss: 0.772820, acc.: 57.81%] [G loss: 2.369397]\n",
      "epoch:28 step:26831 [D loss: 0.796654, acc.: 53.12%] [G loss: 2.185585]\n",
      "epoch:28 step:26832 [D loss: 0.212840, acc.: 89.84%] [G loss: 2.307972]\n",
      "epoch:28 step:26833 [D loss: 0.274812, acc.: 92.19%] [G loss: 1.764855]\n",
      "epoch:28 step:26834 [D loss: 0.349974, acc.: 84.38%] [G loss: 1.995377]\n",
      "epoch:28 step:26835 [D loss: 0.316214, acc.: 86.72%] [G loss: 1.271769]\n",
      "epoch:28 step:26836 [D loss: 0.660967, acc.: 65.62%] [G loss: 1.759459]\n",
      "epoch:28 step:26837 [D loss: 0.566688, acc.: 69.53%] [G loss: 1.697213]\n",
      "epoch:28 step:26838 [D loss: 0.908468, acc.: 52.34%] [G loss: 2.148902]\n",
      "epoch:28 step:26839 [D loss: 0.185699, acc.: 96.09%] [G loss: 2.819032]\n",
      "epoch:28 step:26840 [D loss: 0.289452, acc.: 88.28%] [G loss: 2.340266]\n",
      "epoch:28 step:26841 [D loss: 0.234391, acc.: 97.66%] [G loss: 2.462604]\n",
      "epoch:28 step:26842 [D loss: 0.422184, acc.: 85.16%] [G loss: 2.510181]\n",
      "epoch:28 step:26843 [D loss: 0.388053, acc.: 81.25%] [G loss: 2.617975]\n",
      "epoch:28 step:26844 [D loss: 0.337119, acc.: 90.62%] [G loss: 2.754457]\n",
      "epoch:28 step:26845 [D loss: 0.228090, acc.: 93.75%] [G loss: 2.189680]\n",
      "epoch:28 step:26846 [D loss: 0.505069, acc.: 76.56%] [G loss: 2.713045]\n",
      "epoch:28 step:26847 [D loss: 0.176964, acc.: 99.22%] [G loss: 2.280108]\n",
      "epoch:28 step:26848 [D loss: 0.358697, acc.: 88.28%] [G loss: 2.256498]\n",
      "epoch:28 step:26849 [D loss: 0.557335, acc.: 71.09%] [G loss: 1.833084]\n",
      "epoch:28 step:26850 [D loss: 0.311062, acc.: 93.75%] [G loss: 2.048828]\n",
      "epoch:28 step:26851 [D loss: 0.528845, acc.: 71.09%] [G loss: 1.296036]\n",
      "epoch:28 step:26852 [D loss: 0.452240, acc.: 85.16%] [G loss: 1.786231]\n",
      "epoch:28 step:26853 [D loss: 0.553452, acc.: 75.78%] [G loss: 0.993734]\n",
      "epoch:28 step:26854 [D loss: 0.248790, acc.: 92.97%] [G loss: 2.180396]\n",
      "epoch:28 step:26855 [D loss: 0.658704, acc.: 61.72%] [G loss: 2.048379]\n",
      "epoch:28 step:26856 [D loss: 0.356222, acc.: 87.50%] [G loss: 1.379538]\n",
      "epoch:28 step:26857 [D loss: 0.516342, acc.: 78.91%] [G loss: 1.156747]\n",
      "epoch:28 step:26858 [D loss: 0.528687, acc.: 72.66%] [G loss: 1.498573]\n",
      "epoch:28 step:26859 [D loss: 0.712904, acc.: 60.16%] [G loss: 1.396534]\n",
      "epoch:28 step:26860 [D loss: 0.344244, acc.: 86.72%] [G loss: 1.720095]\n",
      "epoch:28 step:26861 [D loss: 0.489946, acc.: 77.34%] [G loss: 1.286379]\n",
      "epoch:28 step:26862 [D loss: 0.657919, acc.: 65.62%] [G loss: 1.283538]\n",
      "epoch:28 step:26863 [D loss: 0.640180, acc.: 64.84%] [G loss: 1.629969]\n",
      "epoch:28 step:26864 [D loss: 0.485793, acc.: 81.25%] [G loss: 0.989740]\n",
      "epoch:28 step:26865 [D loss: 0.458682, acc.: 75.78%] [G loss: 1.470022]\n",
      "epoch:28 step:26866 [D loss: 0.240028, acc.: 96.09%] [G loss: 1.370375]\n",
      "epoch:28 step:26867 [D loss: 0.685107, acc.: 60.94%] [G loss: 1.330510]\n",
      "epoch:28 step:26868 [D loss: 0.249235, acc.: 91.41%] [G loss: 1.304636]\n",
      "epoch:28 step:26869 [D loss: 0.125119, acc.: 96.88%] [G loss: 1.334458]\n",
      "epoch:28 step:26870 [D loss: 0.190671, acc.: 94.53%] [G loss: 1.697572]\n",
      "epoch:28 step:26871 [D loss: 0.145436, acc.: 96.88%] [G loss: 1.990565]\n",
      "epoch:28 step:26872 [D loss: 0.390493, acc.: 86.72%] [G loss: 2.006851]\n",
      "epoch:28 step:26873 [D loss: 0.317837, acc.: 89.06%] [G loss: 2.351160]\n",
      "epoch:28 step:26874 [D loss: 0.406324, acc.: 82.81%] [G loss: 1.281576]\n",
      "epoch:28 step:26875 [D loss: 0.995367, acc.: 50.00%] [G loss: 1.822891]\n",
      "epoch:28 step:26876 [D loss: 0.861462, acc.: 46.09%] [G loss: 1.618732]\n",
      "epoch:28 step:26877 [D loss: 0.498249, acc.: 78.91%] [G loss: 1.411458]\n",
      "epoch:28 step:26878 [D loss: 0.590059, acc.: 72.66%] [G loss: 1.328063]\n",
      "epoch:28 step:26879 [D loss: 0.317236, acc.: 87.50%] [G loss: 1.485170]\n",
      "epoch:28 step:26880 [D loss: 0.195997, acc.: 93.75%] [G loss: 1.663145]\n",
      "epoch:28 step:26881 [D loss: 0.094191, acc.: 99.22%] [G loss: 2.586363]\n",
      "epoch:28 step:26882 [D loss: 0.061427, acc.: 100.00%] [G loss: 1.895429]\n",
      "epoch:28 step:26883 [D loss: 0.157066, acc.: 98.44%] [G loss: 2.162306]\n",
      "epoch:28 step:26884 [D loss: 0.140403, acc.: 98.44%] [G loss: 2.640197]\n",
      "epoch:28 step:26885 [D loss: 0.082387, acc.: 100.00%] [G loss: 2.176347]\n",
      "epoch:28 step:26886 [D loss: 0.162501, acc.: 95.31%] [G loss: 2.599544]\n",
      "epoch:28 step:26887 [D loss: 0.056633, acc.: 100.00%] [G loss: 2.316189]\n",
      "epoch:28 step:26888 [D loss: 0.548740, acc.: 74.22%] [G loss: 1.435133]\n",
      "epoch:28 step:26889 [D loss: 0.630718, acc.: 63.28%] [G loss: 1.920954]\n",
      "epoch:28 step:26890 [D loss: 0.559603, acc.: 68.75%] [G loss: 1.927769]\n",
      "epoch:28 step:26891 [D loss: 0.259487, acc.: 92.97%] [G loss: 1.945742]\n",
      "epoch:28 step:26892 [D loss: 0.511102, acc.: 73.44%] [G loss: 2.315091]\n",
      "epoch:28 step:26893 [D loss: 0.540315, acc.: 73.44%] [G loss: 1.884451]\n",
      "epoch:28 step:26894 [D loss: 0.799657, acc.: 56.25%] [G loss: 0.957066]\n",
      "epoch:28 step:26895 [D loss: 0.267302, acc.: 84.38%] [G loss: 2.247900]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:28 step:26896 [D loss: 0.217401, acc.: 92.97%] [G loss: 1.358040]\n",
      "epoch:28 step:26897 [D loss: 0.110605, acc.: 98.44%] [G loss: 2.553507]\n",
      "epoch:28 step:26898 [D loss: 0.700070, acc.: 57.03%] [G loss: 1.491048]\n",
      "epoch:28 step:26899 [D loss: 0.390909, acc.: 83.59%] [G loss: 1.723514]\n",
      "epoch:28 step:26900 [D loss: 0.386409, acc.: 86.72%] [G loss: 0.870288]\n",
      "epoch:28 step:26901 [D loss: 0.408371, acc.: 84.38%] [G loss: 1.346832]\n",
      "epoch:28 step:26902 [D loss: 0.788378, acc.: 53.12%] [G loss: 1.254691]\n",
      "epoch:28 step:26903 [D loss: 1.032589, acc.: 37.50%] [G loss: 0.394028]\n",
      "epoch:28 step:26904 [D loss: 0.835989, acc.: 54.69%] [G loss: 2.020895]\n",
      "epoch:28 step:26905 [D loss: 0.709998, acc.: 56.25%] [G loss: 1.066946]\n",
      "epoch:28 step:26906 [D loss: 0.639158, acc.: 67.19%] [G loss: 1.478168]\n",
      "epoch:28 step:26907 [D loss: 0.588220, acc.: 71.88%] [G loss: 1.608243]\n",
      "epoch:28 step:26908 [D loss: 0.598947, acc.: 67.19%] [G loss: 1.754244]\n",
      "epoch:28 step:26909 [D loss: 0.674413, acc.: 64.06%] [G loss: 1.406621]\n",
      "epoch:28 step:26910 [D loss: 0.451626, acc.: 81.25%] [G loss: 1.326958]\n",
      "epoch:28 step:26911 [D loss: 0.701961, acc.: 58.59%] [G loss: 1.518545]\n",
      "epoch:28 step:26912 [D loss: 0.551308, acc.: 74.22%] [G loss: 1.533147]\n",
      "epoch:28 step:26913 [D loss: 0.507322, acc.: 73.44%] [G loss: 1.339857]\n",
      "epoch:28 step:26914 [D loss: 0.475851, acc.: 80.47%] [G loss: 1.013818]\n",
      "epoch:28 step:26915 [D loss: 0.498448, acc.: 79.69%] [G loss: 1.014138]\n",
      "epoch:28 step:26916 [D loss: 0.467157, acc.: 82.81%] [G loss: 1.011416]\n",
      "epoch:28 step:26917 [D loss: 0.399905, acc.: 85.16%] [G loss: 1.157591]\n",
      "epoch:28 step:26918 [D loss: 0.530597, acc.: 74.22%] [G loss: 1.327089]\n",
      "epoch:28 step:26919 [D loss: 0.562588, acc.: 71.88%] [G loss: 0.975013]\n",
      "epoch:28 step:26920 [D loss: 0.444942, acc.: 80.47%] [G loss: 1.004715]\n",
      "epoch:28 step:26921 [D loss: 0.499593, acc.: 77.34%] [G loss: 1.141193]\n",
      "epoch:28 step:26922 [D loss: 0.605722, acc.: 68.75%] [G loss: 1.323065]\n",
      "epoch:28 step:26923 [D loss: 0.554540, acc.: 73.44%] [G loss: 1.695487]\n",
      "epoch:28 step:26924 [D loss: 0.584090, acc.: 67.97%] [G loss: 1.249158]\n",
      "epoch:28 step:26925 [D loss: 0.498565, acc.: 78.91%] [G loss: 1.264445]\n",
      "epoch:28 step:26926 [D loss: 0.471223, acc.: 75.00%] [G loss: 1.117923]\n",
      "epoch:28 step:26927 [D loss: 0.548449, acc.: 71.88%] [G loss: 1.392694]\n",
      "epoch:28 step:26928 [D loss: 0.582262, acc.: 71.09%] [G loss: 1.635101]\n",
      "epoch:28 step:26929 [D loss: 0.413257, acc.: 85.94%] [G loss: 1.574297]\n",
      "epoch:28 step:26930 [D loss: 0.318177, acc.: 89.84%] [G loss: 1.670601]\n",
      "epoch:28 step:26931 [D loss: 0.774819, acc.: 56.25%] [G loss: 1.387342]\n",
      "epoch:28 step:26932 [D loss: 0.227079, acc.: 93.75%] [G loss: 1.667172]\n",
      "epoch:28 step:26933 [D loss: 0.199431, acc.: 92.97%] [G loss: 2.152332]\n",
      "epoch:28 step:26934 [D loss: 0.246059, acc.: 97.66%] [G loss: 1.924815]\n",
      "epoch:28 step:26935 [D loss: 0.350622, acc.: 92.97%] [G loss: 1.850814]\n",
      "epoch:28 step:26936 [D loss: 0.135404, acc.: 100.00%] [G loss: 1.899611]\n",
      "epoch:28 step:26937 [D loss: 0.185666, acc.: 93.75%] [G loss: 2.038202]\n",
      "epoch:28 step:26938 [D loss: 0.224118, acc.: 96.09%] [G loss: 2.382832]\n",
      "epoch:28 step:26939 [D loss: 0.565420, acc.: 71.09%] [G loss: 1.964716]\n",
      "epoch:28 step:26940 [D loss: 0.330437, acc.: 90.62%] [G loss: 1.776895]\n",
      "epoch:28 step:26941 [D loss: 0.703893, acc.: 56.25%] [G loss: 1.819334]\n",
      "epoch:28 step:26942 [D loss: 0.187337, acc.: 93.75%] [G loss: 1.628419]\n",
      "epoch:28 step:26943 [D loss: 0.180839, acc.: 94.53%] [G loss: 1.971022]\n",
      "epoch:28 step:26944 [D loss: 0.083477, acc.: 99.22%] [G loss: 2.102723]\n",
      "epoch:28 step:26945 [D loss: 0.126304, acc.: 98.44%] [G loss: 2.173455]\n",
      "epoch:28 step:26946 [D loss: 0.642944, acc.: 67.97%] [G loss: 1.519470]\n",
      "epoch:28 step:26947 [D loss: 0.513352, acc.: 76.56%] [G loss: 1.750802]\n",
      "epoch:28 step:26948 [D loss: 0.520657, acc.: 72.66%] [G loss: 1.536321]\n",
      "epoch:28 step:26949 [D loss: 0.189002, acc.: 92.97%] [G loss: 0.877779]\n",
      "epoch:28 step:26950 [D loss: 0.157982, acc.: 96.88%] [G loss: 1.992844]\n",
      "epoch:28 step:26951 [D loss: 0.709321, acc.: 56.25%] [G loss: 1.614596]\n",
      "epoch:28 step:26952 [D loss: 0.776014, acc.: 56.25%] [G loss: 1.192416]\n",
      "epoch:28 step:26953 [D loss: 0.483787, acc.: 79.69%] [G loss: 1.086969]\n",
      "epoch:28 step:26954 [D loss: 1.216627, acc.: 23.44%] [G loss: 1.101181]\n",
      "epoch:28 step:26955 [D loss: 0.930888, acc.: 43.75%] [G loss: 1.754266]\n",
      "epoch:28 step:26956 [D loss: 0.553374, acc.: 73.44%] [G loss: 1.240825]\n",
      "epoch:28 step:26957 [D loss: 0.636181, acc.: 65.62%] [G loss: 1.342975]\n",
      "epoch:28 step:26958 [D loss: 0.351023, acc.: 86.72%] [G loss: 1.466569]\n",
      "epoch:28 step:26959 [D loss: 0.353881, acc.: 88.28%] [G loss: 1.319589]\n",
      "epoch:28 step:26960 [D loss: 0.513356, acc.: 77.34%] [G loss: 1.539313]\n",
      "epoch:28 step:26961 [D loss: 0.743945, acc.: 57.81%] [G loss: 1.360862]\n",
      "epoch:28 step:26962 [D loss: 0.681089, acc.: 60.94%] [G loss: 1.367104]\n",
      "epoch:28 step:26963 [D loss: 0.259655, acc.: 92.19%] [G loss: 1.277960]\n",
      "epoch:28 step:26964 [D loss: 0.185701, acc.: 93.75%] [G loss: 1.620876]\n",
      "epoch:28 step:26965 [D loss: 0.154698, acc.: 97.66%] [G loss: 2.047171]\n",
      "epoch:28 step:26966 [D loss: 0.100434, acc.: 100.00%] [G loss: 1.388721]\n",
      "epoch:28 step:26967 [D loss: 0.121799, acc.: 100.00%] [G loss: 1.754282]\n",
      "epoch:28 step:26968 [D loss: 0.114426, acc.: 98.44%] [G loss: 2.106960]\n",
      "epoch:28 step:26969 [D loss: 0.078999, acc.: 99.22%] [G loss: 2.194329]\n",
      "epoch:28 step:26970 [D loss: 0.444314, acc.: 78.12%] [G loss: 2.327913]\n",
      "epoch:28 step:26971 [D loss: 0.661590, acc.: 62.50%] [G loss: 1.990372]\n",
      "epoch:28 step:26972 [D loss: 0.579247, acc.: 71.88%] [G loss: 1.612051]\n",
      "epoch:28 step:26973 [D loss: 0.503520, acc.: 78.12%] [G loss: 1.269723]\n",
      "epoch:28 step:26974 [D loss: 0.379492, acc.: 89.84%] [G loss: 1.028427]\n",
      "epoch:28 step:26975 [D loss: 0.191013, acc.: 95.31%] [G loss: 1.909339]\n",
      "epoch:28 step:26976 [D loss: 0.104501, acc.: 99.22%] [G loss: 1.675520]\n",
      "epoch:28 step:26977 [D loss: 0.775452, acc.: 62.50%] [G loss: 1.618138]\n",
      "epoch:28 step:26978 [D loss: 0.503423, acc.: 74.22%] [G loss: 1.351053]\n",
      "epoch:28 step:26979 [D loss: 0.356521, acc.: 83.59%] [G loss: 1.450560]\n",
      "epoch:28 step:26980 [D loss: 0.567482, acc.: 69.53%] [G loss: 1.443837]\n",
      "epoch:28 step:26981 [D loss: 0.182842, acc.: 97.66%] [G loss: 1.127871]\n",
      "epoch:28 step:26982 [D loss: 0.126795, acc.: 96.88%] [G loss: 0.312707]\n",
      "epoch:28 step:26983 [D loss: 0.412270, acc.: 84.38%] [G loss: 2.092902]\n",
      "epoch:28 step:26984 [D loss: 1.176331, acc.: 30.47%] [G loss: 1.711663]\n",
      "epoch:28 step:26985 [D loss: 0.361016, acc.: 85.94%] [G loss: 1.487385]\n",
      "epoch:28 step:26986 [D loss: 0.346397, acc.: 87.50%] [G loss: 1.996709]\n",
      "epoch:28 step:26987 [D loss: 0.493418, acc.: 77.34%] [G loss: 1.184942]\n",
      "epoch:28 step:26988 [D loss: 0.594423, acc.: 67.97%] [G loss: 1.467144]\n",
      "epoch:28 step:26989 [D loss: 0.240239, acc.: 93.75%] [G loss: 1.159875]\n",
      "epoch:28 step:26990 [D loss: 0.223043, acc.: 89.06%] [G loss: 1.042145]\n",
      "epoch:28 step:26991 [D loss: 0.141957, acc.: 96.09%] [G loss: 1.963181]\n",
      "epoch:28 step:26992 [D loss: 0.144275, acc.: 96.88%] [G loss: 2.133902]\n",
      "epoch:28 step:26993 [D loss: 0.207859, acc.: 94.53%] [G loss: 2.315356]\n",
      "epoch:28 step:26994 [D loss: 0.560199, acc.: 67.97%] [G loss: 1.568035]\n",
      "epoch:28 step:26995 [D loss: 1.073799, acc.: 33.59%] [G loss: 1.622876]\n",
      "epoch:28 step:26996 [D loss: 0.768103, acc.: 57.81%] [G loss: 1.529507]\n",
      "epoch:28 step:26997 [D loss: 0.657293, acc.: 61.72%] [G loss: 1.265294]\n",
      "epoch:28 step:26998 [D loss: 0.397684, acc.: 75.00%] [G loss: 1.692976]\n",
      "epoch:28 step:26999 [D loss: 0.532304, acc.: 70.31%] [G loss: 1.813313]\n",
      "epoch:28 step:27000 [D loss: 0.151729, acc.: 95.31%] [G loss: 2.027945]\n",
      "##############\n",
      "[4.0128987  2.33528569 6.53168045 5.85358705 4.63046197 6.01401209\n",
      " 5.57566646 5.27117649 6.12002692 4.9935449 ]\n",
      "##########\n",
      "epoch:28 step:27001 [D loss: 1.026701, acc.: 46.09%] [G loss: 2.234095]\n",
      "epoch:28 step:27002 [D loss: 0.833162, acc.: 56.25%] [G loss: 1.507674]\n",
      "epoch:28 step:27003 [D loss: 0.719447, acc.: 62.50%] [G loss: 1.619126]\n",
      "epoch:28 step:27004 [D loss: 0.242879, acc.: 92.97%] [G loss: 0.864738]\n",
      "epoch:28 step:27005 [D loss: 0.654913, acc.: 64.84%] [G loss: 1.901985]\n",
      "epoch:28 step:27006 [D loss: 0.777489, acc.: 60.94%] [G loss: 1.526988]\n",
      "epoch:28 step:27007 [D loss: 0.612195, acc.: 68.75%] [G loss: 1.696422]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:28 step:27008 [D loss: 0.825212, acc.: 52.34%] [G loss: 1.322381]\n",
      "epoch:28 step:27009 [D loss: 0.667110, acc.: 62.50%] [G loss: 1.232312]\n",
      "epoch:28 step:27010 [D loss: 0.192821, acc.: 94.53%] [G loss: 1.241741]\n",
      "epoch:28 step:27011 [D loss: 0.394646, acc.: 82.03%] [G loss: 1.426417]\n",
      "epoch:28 step:27012 [D loss: 0.599470, acc.: 67.97%] [G loss: 1.072062]\n",
      "epoch:28 step:27013 [D loss: 0.615414, acc.: 68.75%] [G loss: 1.438826]\n",
      "epoch:28 step:27014 [D loss: 0.689565, acc.: 60.94%] [G loss: 0.968614]\n",
      "epoch:28 step:27015 [D loss: 0.454106, acc.: 78.12%] [G loss: 0.852058]\n",
      "epoch:28 step:27016 [D loss: 0.261134, acc.: 87.50%] [G loss: 1.389633]\n",
      "epoch:28 step:27017 [D loss: 0.184157, acc.: 93.75%] [G loss: 1.653260]\n",
      "epoch:28 step:27018 [D loss: 0.121776, acc.: 100.00%] [G loss: 1.835607]\n",
      "epoch:28 step:27019 [D loss: 0.257532, acc.: 96.88%] [G loss: 2.262781]\n",
      "epoch:28 step:27020 [D loss: 0.459614, acc.: 78.12%] [G loss: 1.457209]\n",
      "epoch:28 step:27021 [D loss: 0.363240, acc.: 87.50%] [G loss: 1.680171]\n",
      "epoch:28 step:27022 [D loss: 0.185282, acc.: 94.53%] [G loss: 1.829365]\n",
      "epoch:28 step:27023 [D loss: 0.776456, acc.: 54.69%] [G loss: 1.756883]\n",
      "epoch:28 step:27024 [D loss: 0.347247, acc.: 92.19%] [G loss: 1.757964]\n",
      "epoch:28 step:27025 [D loss: 0.638740, acc.: 65.62%] [G loss: 1.492249]\n",
      "epoch:28 step:27026 [D loss: 0.323162, acc.: 91.41%] [G loss: 1.213786]\n",
      "epoch:28 step:27027 [D loss: 0.132911, acc.: 97.66%] [G loss: 1.824945]\n",
      "epoch:28 step:27028 [D loss: 0.140514, acc.: 98.44%] [G loss: 1.222187]\n",
      "epoch:28 step:27029 [D loss: 0.144788, acc.: 99.22%] [G loss: 1.527302]\n",
      "epoch:28 step:27030 [D loss: 0.330850, acc.: 82.81%] [G loss: 0.763390]\n",
      "epoch:28 step:27031 [D loss: 0.141663, acc.: 98.44%] [G loss: 2.262048]\n",
      "epoch:28 step:27032 [D loss: 0.135420, acc.: 98.44%] [G loss: 2.035705]\n",
      "epoch:28 step:27033 [D loss: 0.486905, acc.: 69.53%] [G loss: 2.196203]\n",
      "epoch:28 step:27034 [D loss: 0.429449, acc.: 77.34%] [G loss: 1.776111]\n",
      "epoch:28 step:27035 [D loss: 0.402257, acc.: 86.72%] [G loss: 1.362594]\n",
      "epoch:28 step:27036 [D loss: 0.282273, acc.: 93.75%] [G loss: 0.978842]\n",
      "epoch:28 step:27037 [D loss: 0.936768, acc.: 52.34%] [G loss: 1.827032]\n",
      "epoch:28 step:27038 [D loss: 0.519170, acc.: 76.56%] [G loss: 2.296754]\n",
      "epoch:28 step:27039 [D loss: 0.397210, acc.: 81.25%] [G loss: 1.457527]\n",
      "epoch:28 step:27040 [D loss: 0.154026, acc.: 95.31%] [G loss: 2.094545]\n",
      "epoch:28 step:27041 [D loss: 0.119791, acc.: 99.22%] [G loss: 2.018261]\n",
      "epoch:28 step:27042 [D loss: 0.073384, acc.: 100.00%] [G loss: 2.397563]\n",
      "epoch:28 step:27043 [D loss: 1.328701, acc.: 40.62%] [G loss: 1.776643]\n",
      "epoch:28 step:27044 [D loss: 0.295673, acc.: 91.41%] [G loss: 1.966485]\n",
      "epoch:28 step:27045 [D loss: 0.237060, acc.: 93.75%] [G loss: 1.827769]\n",
      "epoch:28 step:27046 [D loss: 0.348359, acc.: 88.28%] [G loss: 2.239178]\n",
      "epoch:28 step:27047 [D loss: 0.832152, acc.: 55.47%] [G loss: 1.554572]\n",
      "epoch:28 step:27048 [D loss: 0.830608, acc.: 43.75%] [G loss: 1.746561]\n",
      "epoch:28 step:27049 [D loss: 0.589853, acc.: 69.53%] [G loss: 1.394830]\n",
      "epoch:28 step:27050 [D loss: 0.654511, acc.: 65.62%] [G loss: 1.261992]\n",
      "epoch:28 step:27051 [D loss: 0.180333, acc.: 95.31%] [G loss: 1.200468]\n",
      "epoch:28 step:27052 [D loss: 0.177978, acc.: 94.53%] [G loss: 1.657676]\n",
      "epoch:28 step:27053 [D loss: 0.570830, acc.: 72.66%] [G loss: 1.864625]\n",
      "epoch:28 step:27054 [D loss: 0.381674, acc.: 86.72%] [G loss: 1.213083]\n",
      "epoch:28 step:27055 [D loss: 0.525214, acc.: 69.53%] [G loss: 1.442547]\n",
      "epoch:28 step:27056 [D loss: 0.712030, acc.: 60.16%] [G loss: 1.915389]\n",
      "epoch:28 step:27057 [D loss: 0.487811, acc.: 79.69%] [G loss: 1.041804]\n",
      "epoch:28 step:27058 [D loss: 0.552553, acc.: 69.53%] [G loss: 0.911577]\n",
      "epoch:28 step:27059 [D loss: 0.387018, acc.: 87.50%] [G loss: 1.067173]\n",
      "epoch:28 step:27060 [D loss: 0.653838, acc.: 58.59%] [G loss: 0.663994]\n",
      "epoch:28 step:27061 [D loss: 0.161514, acc.: 96.88%] [G loss: 1.693991]\n",
      "epoch:28 step:27062 [D loss: 0.558444, acc.: 67.97%] [G loss: 1.692475]\n",
      "epoch:28 step:27063 [D loss: 0.526454, acc.: 73.44%] [G loss: 0.792367]\n",
      "epoch:28 step:27064 [D loss: 0.571331, acc.: 65.62%] [G loss: 1.707656]\n",
      "epoch:28 step:27065 [D loss: 0.341688, acc.: 89.06%] [G loss: 0.811007]\n",
      "epoch:28 step:27066 [D loss: 0.466171, acc.: 75.78%] [G loss: 1.568568]\n",
      "epoch:28 step:27067 [D loss: 0.095299, acc.: 99.22%] [G loss: 1.731051]\n",
      "epoch:28 step:27068 [D loss: 0.111232, acc.: 98.44%] [G loss: 1.692761]\n",
      "epoch:28 step:27069 [D loss: 0.158400, acc.: 97.66%] [G loss: 2.493900]\n",
      "epoch:28 step:27070 [D loss: 1.411890, acc.: 24.22%] [G loss: 2.559329]\n",
      "epoch:28 step:27071 [D loss: 0.896014, acc.: 51.56%] [G loss: 1.751083]\n",
      "epoch:28 step:27072 [D loss: 0.760701, acc.: 56.25%] [G loss: 1.773350]\n",
      "epoch:28 step:27073 [D loss: 0.750292, acc.: 58.59%] [G loss: 1.826329]\n",
      "epoch:28 step:27074 [D loss: 0.361574, acc.: 89.06%] [G loss: 1.484016]\n",
      "epoch:28 step:27075 [D loss: 0.642387, acc.: 62.50%] [G loss: 1.867352]\n",
      "epoch:28 step:27076 [D loss: 0.712159, acc.: 57.81%] [G loss: 1.607002]\n",
      "epoch:28 step:27077 [D loss: 0.345996, acc.: 91.41%] [G loss: 1.521849]\n",
      "epoch:28 step:27078 [D loss: 0.281051, acc.: 91.41%] [G loss: 1.395650]\n",
      "epoch:28 step:27079 [D loss: 0.208029, acc.: 94.53%] [G loss: 1.735546]\n",
      "epoch:28 step:27080 [D loss: 0.219034, acc.: 96.88%] [G loss: 1.367092]\n",
      "epoch:28 step:27081 [D loss: 0.167491, acc.: 95.31%] [G loss: 1.671679]\n",
      "epoch:28 step:27082 [D loss: 0.827239, acc.: 52.34%] [G loss: 1.893319]\n",
      "epoch:28 step:27083 [D loss: 0.327779, acc.: 91.41%] [G loss: 1.539549]\n",
      "epoch:28 step:27084 [D loss: 0.533894, acc.: 73.44%] [G loss: 1.527233]\n",
      "epoch:28 step:27085 [D loss: 0.387655, acc.: 87.50%] [G loss: 1.610993]\n",
      "epoch:28 step:27086 [D loss: 0.243847, acc.: 89.84%] [G loss: 1.658206]\n",
      "epoch:28 step:27087 [D loss: 0.186250, acc.: 96.09%] [G loss: 1.798575]\n",
      "epoch:28 step:27088 [D loss: 0.383979, acc.: 77.34%] [G loss: 1.802336]\n",
      "epoch:28 step:27089 [D loss: 0.324203, acc.: 91.41%] [G loss: 2.281659]\n",
      "epoch:28 step:27090 [D loss: 0.164773, acc.: 96.88%] [G loss: 1.959343]\n",
      "epoch:28 step:27091 [D loss: 0.357359, acc.: 83.59%] [G loss: 2.548665]\n",
      "epoch:28 step:27092 [D loss: 0.573827, acc.: 71.09%] [G loss: 1.504939]\n",
      "epoch:28 step:27093 [D loss: 0.269357, acc.: 90.62%] [G loss: 2.143398]\n",
      "epoch:28 step:27094 [D loss: 0.116151, acc.: 98.44%] [G loss: 1.656489]\n",
      "epoch:28 step:27095 [D loss: 0.273460, acc.: 86.72%] [G loss: 1.229411]\n",
      "epoch:28 step:27096 [D loss: 0.257684, acc.: 92.97%] [G loss: 1.710017]\n",
      "epoch:28 step:27097 [D loss: 0.677823, acc.: 65.62%] [G loss: 2.092425]\n",
      "epoch:28 step:27098 [D loss: 1.051971, acc.: 43.75%] [G loss: 2.420165]\n",
      "epoch:28 step:27099 [D loss: 0.794557, acc.: 49.22%] [G loss: 1.977218]\n",
      "epoch:28 step:27100 [D loss: 0.515831, acc.: 72.66%] [G loss: 1.633285]\n",
      "epoch:28 step:27101 [D loss: 0.540214, acc.: 75.00%] [G loss: 1.780608]\n",
      "epoch:28 step:27102 [D loss: 0.705716, acc.: 57.03%] [G loss: 1.306791]\n",
      "epoch:28 step:27103 [D loss: 0.794737, acc.: 51.56%] [G loss: 1.640773]\n",
      "epoch:28 step:27104 [D loss: 0.388863, acc.: 85.16%] [G loss: 1.527469]\n",
      "epoch:28 step:27105 [D loss: 0.626143, acc.: 67.19%] [G loss: 1.418571]\n",
      "epoch:28 step:27106 [D loss: 0.427649, acc.: 85.16%] [G loss: 1.621997]\n",
      "epoch:28 step:27107 [D loss: 0.466244, acc.: 78.91%] [G loss: 1.332974]\n",
      "epoch:28 step:27108 [D loss: 0.711492, acc.: 56.25%] [G loss: 1.266738]\n",
      "epoch:28 step:27109 [D loss: 0.598140, acc.: 69.53%] [G loss: 1.085702]\n",
      "epoch:28 step:27110 [D loss: 0.490326, acc.: 81.25%] [G loss: 1.367713]\n",
      "epoch:28 step:27111 [D loss: 0.555871, acc.: 68.75%] [G loss: 1.431762]\n",
      "epoch:28 step:27112 [D loss: 0.194855, acc.: 96.09%] [G loss: 1.035466]\n",
      "epoch:28 step:27113 [D loss: 0.166740, acc.: 92.97%] [G loss: 1.639463]\n",
      "epoch:28 step:27114 [D loss: 0.095317, acc.: 98.44%] [G loss: 2.256755]\n",
      "epoch:28 step:27115 [D loss: 0.622633, acc.: 67.19%] [G loss: 1.915141]\n",
      "epoch:28 step:27116 [D loss: 0.777128, acc.: 56.25%] [G loss: 1.961936]\n",
      "epoch:28 step:27117 [D loss: 0.673582, acc.: 59.38%] [G loss: 0.981424]\n",
      "epoch:28 step:27118 [D loss: 0.536101, acc.: 71.09%] [G loss: 1.022620]\n",
      "epoch:28 step:27119 [D loss: 0.442597, acc.: 78.91%] [G loss: 1.791000]\n",
      "epoch:28 step:27120 [D loss: 0.284178, acc.: 91.41%] [G loss: 0.791794]\n",
      "epoch:28 step:27121 [D loss: 0.165719, acc.: 96.09%] [G loss: 1.749902]\n",
      "epoch:28 step:27122 [D loss: 0.245375, acc.: 89.84%] [G loss: 2.197212]\n",
      "epoch:28 step:27123 [D loss: 0.140740, acc.: 99.22%] [G loss: 1.710912]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:28 step:27124 [D loss: 0.714656, acc.: 58.59%] [G loss: 2.081442]\n",
      "epoch:28 step:27125 [D loss: 0.219261, acc.: 97.66%] [G loss: 1.406895]\n",
      "epoch:28 step:27126 [D loss: 0.198790, acc.: 96.09%] [G loss: 1.422048]\n",
      "epoch:28 step:27127 [D loss: 0.388202, acc.: 85.16%] [G loss: 1.710048]\n",
      "epoch:28 step:27128 [D loss: 0.328974, acc.: 88.28%] [G loss: 1.119425]\n",
      "epoch:28 step:27129 [D loss: 0.302532, acc.: 89.84%] [G loss: 0.911858]\n",
      "epoch:28 step:27130 [D loss: 0.175238, acc.: 95.31%] [G loss: 1.975828]\n",
      "epoch:28 step:27131 [D loss: 0.187611, acc.: 96.09%] [G loss: 2.088429]\n",
      "epoch:28 step:27132 [D loss: 0.103858, acc.: 99.22%] [G loss: 1.635121]\n",
      "epoch:28 step:27133 [D loss: 0.153301, acc.: 97.66%] [G loss: 2.457825]\n",
      "epoch:28 step:27134 [D loss: 0.081530, acc.: 99.22%] [G loss: 1.533910]\n",
      "epoch:28 step:27135 [D loss: 0.073700, acc.: 100.00%] [G loss: 2.212818]\n",
      "epoch:28 step:27136 [D loss: 0.116102, acc.: 99.22%] [G loss: 2.052192]\n",
      "epoch:28 step:27137 [D loss: 0.114153, acc.: 99.22%] [G loss: 2.691355]\n",
      "epoch:28 step:27138 [D loss: 0.285763, acc.: 85.16%] [G loss: 0.808596]\n",
      "epoch:28 step:27139 [D loss: 0.125061, acc.: 100.00%] [G loss: 2.360713]\n",
      "epoch:28 step:27140 [D loss: 0.168390, acc.: 98.44%] [G loss: 2.163410]\n",
      "epoch:28 step:27141 [D loss: 0.253691, acc.: 92.97%] [G loss: 2.015064]\n",
      "epoch:28 step:27142 [D loss: 0.182227, acc.: 98.44%] [G loss: 2.025385]\n",
      "epoch:28 step:27143 [D loss: 1.078025, acc.: 45.31%] [G loss: 1.942070]\n",
      "epoch:28 step:27144 [D loss: 0.266968, acc.: 95.31%] [G loss: 1.562247]\n",
      "epoch:28 step:27145 [D loss: 0.121763, acc.: 97.66%] [G loss: 2.252181]\n",
      "epoch:28 step:27146 [D loss: 0.867478, acc.: 46.88%] [G loss: 1.834293]\n",
      "epoch:28 step:27147 [D loss: 0.542805, acc.: 67.97%] [G loss: 2.603239]\n",
      "epoch:28 step:27148 [D loss: 0.079875, acc.: 99.22%] [G loss: 1.652644]\n",
      "epoch:28 step:27149 [D loss: 0.204687, acc.: 98.44%] [G loss: 1.180927]\n",
      "epoch:28 step:27150 [D loss: 1.336184, acc.: 28.12%] [G loss: 1.846041]\n",
      "epoch:28 step:27151 [D loss: 1.421116, acc.: 29.69%] [G loss: 2.339093]\n",
      "epoch:28 step:27152 [D loss: 1.353101, acc.: 33.59%] [G loss: 2.296653]\n",
      "epoch:28 step:27153 [D loss: 0.588340, acc.: 71.09%] [G loss: 1.895060]\n",
      "epoch:28 step:27154 [D loss: 0.764368, acc.: 57.81%] [G loss: 1.758141]\n",
      "epoch:28 step:27155 [D loss: 0.204895, acc.: 89.84%] [G loss: 2.332425]\n",
      "epoch:28 step:27156 [D loss: 0.104089, acc.: 98.44%] [G loss: 2.376448]\n",
      "epoch:28 step:27157 [D loss: 0.458143, acc.: 78.12%] [G loss: 1.151703]\n",
      "epoch:28 step:27158 [D loss: 0.420596, acc.: 80.47%] [G loss: 1.780168]\n",
      "epoch:28 step:27159 [D loss: 0.326278, acc.: 89.84%] [G loss: 1.840925]\n",
      "epoch:28 step:27160 [D loss: 0.216428, acc.: 90.62%] [G loss: 1.595278]\n",
      "epoch:28 step:27161 [D loss: 0.132514, acc.: 96.88%] [G loss: 1.546720]\n",
      "epoch:28 step:27162 [D loss: 0.112503, acc.: 98.44%] [G loss: 2.031846]\n",
      "epoch:28 step:27163 [D loss: 0.102978, acc.: 98.44%] [G loss: 2.361518]\n",
      "epoch:28 step:27164 [D loss: 0.912915, acc.: 54.69%] [G loss: 1.592685]\n",
      "epoch:28 step:27165 [D loss: 0.231857, acc.: 90.62%] [G loss: 2.176780]\n",
      "epoch:28 step:27166 [D loss: 0.636995, acc.: 67.97%] [G loss: 1.846843]\n",
      "epoch:28 step:27167 [D loss: 0.392917, acc.: 82.03%] [G loss: 2.662558]\n",
      "epoch:28 step:27168 [D loss: 0.197571, acc.: 94.53%] [G loss: 2.193362]\n",
      "epoch:28 step:27169 [D loss: 0.112208, acc.: 99.22%] [G loss: 2.748903]\n",
      "epoch:28 step:27170 [D loss: 0.126893, acc.: 98.44%] [G loss: 2.055677]\n",
      "epoch:28 step:27171 [D loss: 0.059331, acc.: 100.00%] [G loss: 2.569009]\n",
      "epoch:28 step:27172 [D loss: 0.100363, acc.: 96.88%] [G loss: 2.504938]\n",
      "epoch:28 step:27173 [D loss: 0.067331, acc.: 100.00%] [G loss: 2.624187]\n",
      "epoch:29 step:27174 [D loss: 0.353474, acc.: 82.03%] [G loss: 1.376111]\n",
      "epoch:29 step:27175 [D loss: 0.285957, acc.: 90.62%] [G loss: 1.390280]\n",
      "epoch:29 step:27176 [D loss: 0.639664, acc.: 62.50%] [G loss: 2.274461]\n",
      "epoch:29 step:27177 [D loss: 0.741960, acc.: 63.28%] [G loss: 2.272067]\n",
      "epoch:29 step:27178 [D loss: 1.012798, acc.: 36.72%] [G loss: 2.015667]\n",
      "epoch:29 step:27179 [D loss: 0.576396, acc.: 69.53%] [G loss: 2.017208]\n",
      "epoch:29 step:27180 [D loss: 0.225576, acc.: 96.09%] [G loss: 1.206172]\n",
      "epoch:29 step:27181 [D loss: 0.229174, acc.: 93.75%] [G loss: 1.816775]\n",
      "epoch:29 step:27182 [D loss: 0.491550, acc.: 73.44%] [G loss: 0.423533]\n",
      "epoch:29 step:27183 [D loss: 0.096813, acc.: 99.22%] [G loss: 0.512894]\n",
      "epoch:29 step:27184 [D loss: 0.084224, acc.: 99.22%] [G loss: 1.182451]\n",
      "epoch:29 step:27185 [D loss: 0.170619, acc.: 99.22%] [G loss: 1.855139]\n",
      "epoch:29 step:27186 [D loss: 2.046894, acc.: 44.53%] [G loss: 1.717069]\n",
      "epoch:29 step:27187 [D loss: 0.583393, acc.: 67.97%] [G loss: 2.815274]\n",
      "epoch:29 step:27188 [D loss: 0.231479, acc.: 93.75%] [G loss: 1.875869]\n",
      "epoch:29 step:27189 [D loss: 0.556598, acc.: 74.22%] [G loss: 2.029166]\n",
      "epoch:29 step:27190 [D loss: 0.406177, acc.: 82.81%] [G loss: 1.249068]\n",
      "epoch:29 step:27191 [D loss: 0.397325, acc.: 81.25%] [G loss: 2.402278]\n",
      "epoch:29 step:27192 [D loss: 1.442353, acc.: 11.72%] [G loss: 1.438741]\n",
      "epoch:29 step:27193 [D loss: 0.791134, acc.: 51.56%] [G loss: 1.487263]\n",
      "epoch:29 step:27194 [D loss: 1.777131, acc.: 9.38%] [G loss: 1.636285]\n",
      "epoch:29 step:27195 [D loss: 0.814742, acc.: 57.03%] [G loss: 2.176108]\n",
      "epoch:29 step:27196 [D loss: 0.711437, acc.: 59.38%] [G loss: 1.057687]\n",
      "epoch:29 step:27197 [D loss: 0.765267, acc.: 53.12%] [G loss: 1.270000]\n",
      "epoch:29 step:27198 [D loss: 0.241657, acc.: 94.53%] [G loss: 1.584240]\n",
      "epoch:29 step:27199 [D loss: 1.340302, acc.: 16.41%] [G loss: 1.660869]\n",
      "epoch:29 step:27200 [D loss: 0.184733, acc.: 96.88%] [G loss: 2.120404]\n",
      "##############\n",
      "[4.14998807 2.65668424 6.71682388 5.69733559 4.98523388 6.37495557\n",
      " 5.86430937 6.14700055 5.86573783 5.04587776]\n",
      "##########\n",
      "epoch:29 step:27201 [D loss: 0.370611, acc.: 84.38%] [G loss: 2.101892]\n",
      "epoch:29 step:27202 [D loss: 0.342828, acc.: 86.72%] [G loss: 1.910955]\n",
      "epoch:29 step:27203 [D loss: 0.628316, acc.: 64.84%] [G loss: 1.892506]\n",
      "epoch:29 step:27204 [D loss: 0.123195, acc.: 97.66%] [G loss: 2.535358]\n",
      "epoch:29 step:27205 [D loss: 0.128559, acc.: 98.44%] [G loss: 2.629320]\n",
      "epoch:29 step:27206 [D loss: 0.059507, acc.: 100.00%] [G loss: 2.924054]\n",
      "epoch:29 step:27207 [D loss: 0.125026, acc.: 99.22%] [G loss: 2.830590]\n",
      "epoch:29 step:27208 [D loss: 0.086731, acc.: 99.22%] [G loss: 2.510104]\n",
      "epoch:29 step:27209 [D loss: 0.065193, acc.: 100.00%] [G loss: 2.911247]\n",
      "epoch:29 step:27210 [D loss: 1.188390, acc.: 50.78%] [G loss: 1.698378]\n",
      "epoch:29 step:27211 [D loss: 0.913140, acc.: 46.09%] [G loss: 1.474573]\n",
      "epoch:29 step:27212 [D loss: 0.994310, acc.: 41.41%] [G loss: 0.870470]\n",
      "epoch:29 step:27213 [D loss: 0.674493, acc.: 54.69%] [G loss: 0.580383]\n",
      "epoch:29 step:27214 [D loss: 0.403504, acc.: 87.50%] [G loss: 1.271353]\n",
      "epoch:29 step:27215 [D loss: 0.362194, acc.: 85.94%] [G loss: 1.468137]\n",
      "epoch:29 step:27216 [D loss: 0.236927, acc.: 90.62%] [G loss: 2.636299]\n",
      "epoch:29 step:27217 [D loss: 0.240107, acc.: 93.75%] [G loss: 1.784338]\n",
      "epoch:29 step:27218 [D loss: 0.294177, acc.: 91.41%] [G loss: 2.003469]\n",
      "epoch:29 step:27219 [D loss: 0.195367, acc.: 98.44%] [G loss: 1.876953]\n",
      "epoch:29 step:27220 [D loss: 0.424388, acc.: 81.25%] [G loss: 1.778220]\n",
      "epoch:29 step:27221 [D loss: 0.521555, acc.: 77.34%] [G loss: 1.516322]\n",
      "epoch:29 step:27222 [D loss: 0.557389, acc.: 71.88%] [G loss: 1.695816]\n",
      "epoch:29 step:27223 [D loss: 0.434693, acc.: 79.69%] [G loss: 1.617555]\n",
      "epoch:29 step:27224 [D loss: 0.184654, acc.: 96.88%] [G loss: 1.363690]\n",
      "epoch:29 step:27225 [D loss: 0.134263, acc.: 98.44%] [G loss: 2.029249]\n",
      "epoch:29 step:27226 [D loss: 0.252357, acc.: 94.53%] [G loss: 1.883339]\n",
      "epoch:29 step:27227 [D loss: 0.474149, acc.: 78.12%] [G loss: 1.976800]\n",
      "epoch:29 step:27228 [D loss: 0.487655, acc.: 78.12%] [G loss: 1.658643]\n",
      "epoch:29 step:27229 [D loss: 0.341553, acc.: 91.41%] [G loss: 1.732457]\n",
      "epoch:29 step:27230 [D loss: 0.243453, acc.: 89.06%] [G loss: 1.722932]\n",
      "epoch:29 step:27231 [D loss: 0.125376, acc.: 99.22%] [G loss: 1.820686]\n",
      "epoch:29 step:27232 [D loss: 0.089578, acc.: 100.00%] [G loss: 1.863997]\n",
      "epoch:29 step:27233 [D loss: 0.476177, acc.: 74.22%] [G loss: 1.373790]\n",
      "epoch:29 step:27234 [D loss: 0.514019, acc.: 78.12%] [G loss: 2.043119]\n",
      "epoch:29 step:27235 [D loss: 0.404438, acc.: 80.47%] [G loss: 2.799461]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:29 step:27236 [D loss: 0.319786, acc.: 85.94%] [G loss: 2.285093]\n",
      "epoch:29 step:27237 [D loss: 0.943344, acc.: 43.75%] [G loss: 1.847107]\n",
      "epoch:29 step:27238 [D loss: 2.737858, acc.: 22.66%] [G loss: 1.279808]\n",
      "epoch:29 step:27239 [D loss: 0.497592, acc.: 75.78%] [G loss: 2.056837]\n",
      "epoch:29 step:27240 [D loss: 0.470591, acc.: 78.12%] [G loss: 1.346105]\n",
      "epoch:29 step:27241 [D loss: 0.963777, acc.: 46.09%] [G loss: 1.369207]\n",
      "epoch:29 step:27242 [D loss: 0.903230, acc.: 41.41%] [G loss: 1.577865]\n",
      "epoch:29 step:27243 [D loss: 0.611144, acc.: 61.72%] [G loss: 1.292035]\n",
      "epoch:29 step:27244 [D loss: 0.275736, acc.: 89.06%] [G loss: 1.356359]\n",
      "epoch:29 step:27245 [D loss: 0.228511, acc.: 95.31%] [G loss: 2.218365]\n",
      "epoch:29 step:27246 [D loss: 0.284341, acc.: 89.84%] [G loss: 1.328086]\n",
      "epoch:29 step:27247 [D loss: 0.528525, acc.: 77.34%] [G loss: 1.845755]\n",
      "epoch:29 step:27248 [D loss: 0.201598, acc.: 93.75%] [G loss: 1.676175]\n",
      "epoch:29 step:27249 [D loss: 0.117089, acc.: 96.88%] [G loss: 1.808187]\n",
      "epoch:29 step:27250 [D loss: 0.109745, acc.: 99.22%] [G loss: 2.193121]\n",
      "epoch:29 step:27251 [D loss: 0.700535, acc.: 60.16%] [G loss: 1.809198]\n",
      "epoch:29 step:27252 [D loss: 0.430216, acc.: 82.81%] [G loss: 1.071686]\n",
      "epoch:29 step:27253 [D loss: 0.863618, acc.: 45.31%] [G loss: 1.767839]\n",
      "epoch:29 step:27254 [D loss: 0.826921, acc.: 54.69%] [G loss: 1.742917]\n",
      "epoch:29 step:27255 [D loss: 0.929811, acc.: 45.31%] [G loss: 0.733886]\n",
      "epoch:29 step:27256 [D loss: 0.606371, acc.: 70.31%] [G loss: 1.442155]\n",
      "epoch:29 step:27257 [D loss: 0.562537, acc.: 67.97%] [G loss: 1.589204]\n",
      "epoch:29 step:27258 [D loss: 0.638640, acc.: 67.19%] [G loss: 1.935396]\n",
      "epoch:29 step:27259 [D loss: 0.616695, acc.: 64.84%] [G loss: 1.117950]\n",
      "epoch:29 step:27260 [D loss: 0.714527, acc.: 57.03%] [G loss: 1.255782]\n",
      "epoch:29 step:27261 [D loss: 0.447608, acc.: 82.81%] [G loss: 1.109914]\n",
      "epoch:29 step:27262 [D loss: 0.589673, acc.: 67.97%] [G loss: 1.391805]\n",
      "epoch:29 step:27263 [D loss: 0.539812, acc.: 71.88%] [G loss: 2.189374]\n",
      "epoch:29 step:27264 [D loss: 0.602351, acc.: 67.97%] [G loss: 1.349527]\n",
      "epoch:29 step:27265 [D loss: 0.420308, acc.: 82.03%] [G loss: 1.497655]\n",
      "epoch:29 step:27266 [D loss: 0.265279, acc.: 94.53%] [G loss: 1.664613]\n",
      "epoch:29 step:27267 [D loss: 0.463802, acc.: 75.78%] [G loss: 1.240798]\n",
      "epoch:29 step:27268 [D loss: 0.345919, acc.: 87.50%] [G loss: 1.622802]\n",
      "epoch:29 step:27269 [D loss: 0.509516, acc.: 76.56%] [G loss: 1.774479]\n",
      "epoch:29 step:27270 [D loss: 0.398525, acc.: 85.16%] [G loss: 1.906716]\n",
      "epoch:29 step:27271 [D loss: 0.518361, acc.: 74.22%] [G loss: 1.852767]\n",
      "epoch:29 step:27272 [D loss: 0.637046, acc.: 62.50%] [G loss: 1.365535]\n",
      "epoch:29 step:27273 [D loss: 0.580008, acc.: 67.97%] [G loss: 1.433295]\n",
      "epoch:29 step:27274 [D loss: 0.609713, acc.: 66.41%] [G loss: 1.307629]\n",
      "epoch:29 step:27275 [D loss: 0.796261, acc.: 53.91%] [G loss: 1.066033]\n",
      "epoch:29 step:27276 [D loss: 0.585258, acc.: 68.75%] [G loss: 1.195511]\n",
      "epoch:29 step:27277 [D loss: 0.827730, acc.: 50.00%] [G loss: 1.402470]\n",
      "epoch:29 step:27278 [D loss: 0.606465, acc.: 64.84%] [G loss: 0.948810]\n",
      "epoch:29 step:27279 [D loss: 0.821688, acc.: 57.03%] [G loss: 1.403541]\n",
      "epoch:29 step:27280 [D loss: 0.538349, acc.: 74.22%] [G loss: 0.794138]\n",
      "epoch:29 step:27281 [D loss: 0.642129, acc.: 64.84%] [G loss: 1.266840]\n",
      "epoch:29 step:27282 [D loss: 0.629028, acc.: 60.16%] [G loss: 1.043357]\n",
      "epoch:29 step:27283 [D loss: 0.617175, acc.: 68.75%] [G loss: 1.731321]\n",
      "epoch:29 step:27284 [D loss: 0.391538, acc.: 84.38%] [G loss: 1.675564]\n",
      "epoch:29 step:27285 [D loss: 0.458181, acc.: 80.47%] [G loss: 1.142082]\n",
      "epoch:29 step:27286 [D loss: 0.435244, acc.: 82.03%] [G loss: 1.245032]\n",
      "epoch:29 step:27287 [D loss: 0.238980, acc.: 95.31%] [G loss: 1.049334]\n",
      "epoch:29 step:27288 [D loss: 0.374721, acc.: 82.03%] [G loss: 1.238406]\n",
      "epoch:29 step:27289 [D loss: 0.616757, acc.: 64.84%] [G loss: 1.999541]\n",
      "epoch:29 step:27290 [D loss: 0.467615, acc.: 80.47%] [G loss: 1.070228]\n",
      "epoch:29 step:27291 [D loss: 0.495074, acc.: 76.56%] [G loss: 1.270246]\n",
      "epoch:29 step:27292 [D loss: 0.288811, acc.: 87.50%] [G loss: 1.492607]\n",
      "epoch:29 step:27293 [D loss: 0.247179, acc.: 89.84%] [G loss: 1.705992]\n",
      "epoch:29 step:27294 [D loss: 0.202026, acc.: 92.97%] [G loss: 1.889282]\n",
      "epoch:29 step:27295 [D loss: 0.170680, acc.: 97.66%] [G loss: 1.715652]\n",
      "epoch:29 step:27296 [D loss: 0.651943, acc.: 63.28%] [G loss: 1.400055]\n",
      "epoch:29 step:27297 [D loss: 0.825265, acc.: 48.44%] [G loss: 1.342635]\n",
      "epoch:29 step:27298 [D loss: 0.782321, acc.: 48.44%] [G loss: 1.373052]\n",
      "epoch:29 step:27299 [D loss: 0.630355, acc.: 63.28%] [G loss: 1.141182]\n",
      "epoch:29 step:27300 [D loss: 0.587885, acc.: 64.84%] [G loss: 1.317528]\n",
      "epoch:29 step:27301 [D loss: 0.431278, acc.: 85.16%] [G loss: 1.132594]\n",
      "epoch:29 step:27302 [D loss: 0.368112, acc.: 81.25%] [G loss: 1.099189]\n",
      "epoch:29 step:27303 [D loss: 0.188105, acc.: 96.09%] [G loss: 1.585364]\n",
      "epoch:29 step:27304 [D loss: 0.294284, acc.: 92.97%] [G loss: 0.808475]\n",
      "epoch:29 step:27305 [D loss: 0.241520, acc.: 96.88%] [G loss: 1.605191]\n",
      "epoch:29 step:27306 [D loss: 0.663077, acc.: 65.62%] [G loss: 1.543778]\n",
      "epoch:29 step:27307 [D loss: 0.433922, acc.: 82.81%] [G loss: 1.342025]\n",
      "epoch:29 step:27308 [D loss: 0.415659, acc.: 85.16%] [G loss: 1.242721]\n",
      "epoch:29 step:27309 [D loss: 0.630626, acc.: 63.28%] [G loss: 1.956369]\n",
      "epoch:29 step:27310 [D loss: 0.558999, acc.: 71.09%] [G loss: 0.494086]\n",
      "epoch:29 step:27311 [D loss: 0.349318, acc.: 93.75%] [G loss: 1.572687]\n",
      "epoch:29 step:27312 [D loss: 0.229804, acc.: 95.31%] [G loss: 1.336202]\n",
      "epoch:29 step:27313 [D loss: 0.289673, acc.: 92.19%] [G loss: 0.997522]\n",
      "epoch:29 step:27314 [D loss: 0.311365, acc.: 92.97%] [G loss: 1.897744]\n",
      "epoch:29 step:27315 [D loss: 0.763867, acc.: 51.56%] [G loss: 1.318053]\n",
      "epoch:29 step:27316 [D loss: 0.213959, acc.: 97.66%] [G loss: 1.357887]\n",
      "epoch:29 step:27317 [D loss: 0.473940, acc.: 75.78%] [G loss: 1.757440]\n",
      "epoch:29 step:27318 [D loss: 0.123083, acc.: 99.22%] [G loss: 1.803381]\n",
      "epoch:29 step:27319 [D loss: 0.462967, acc.: 81.25%] [G loss: 1.625747]\n",
      "epoch:29 step:27320 [D loss: 0.501408, acc.: 78.12%] [G loss: 1.702296]\n",
      "epoch:29 step:27321 [D loss: 0.731422, acc.: 53.91%] [G loss: 1.401184]\n",
      "epoch:29 step:27322 [D loss: 0.238343, acc.: 93.75%] [G loss: 1.090530]\n",
      "epoch:29 step:27323 [D loss: 0.261077, acc.: 88.28%] [G loss: 1.710467]\n",
      "epoch:29 step:27324 [D loss: 0.189910, acc.: 96.09%] [G loss: 1.514053]\n",
      "epoch:29 step:27325 [D loss: 0.229295, acc.: 97.66%] [G loss: 1.988262]\n",
      "epoch:29 step:27326 [D loss: 0.773454, acc.: 53.91%] [G loss: 1.590102]\n",
      "epoch:29 step:27327 [D loss: 0.584711, acc.: 67.19%] [G loss: 1.335560]\n",
      "epoch:29 step:27328 [D loss: 0.761613, acc.: 53.12%] [G loss: 1.156229]\n",
      "epoch:29 step:27329 [D loss: 0.400373, acc.: 86.72%] [G loss: 1.029588]\n",
      "epoch:29 step:27330 [D loss: 0.764627, acc.: 53.12%] [G loss: 0.791062]\n",
      "epoch:29 step:27331 [D loss: 0.979893, acc.: 35.16%] [G loss: 1.297911]\n",
      "epoch:29 step:27332 [D loss: 0.556536, acc.: 66.41%] [G loss: 1.207488]\n",
      "epoch:29 step:27333 [D loss: 0.463053, acc.: 77.34%] [G loss: 1.370577]\n",
      "epoch:29 step:27334 [D loss: 0.577886, acc.: 71.88%] [G loss: 0.808986]\n",
      "epoch:29 step:27335 [D loss: 0.332881, acc.: 89.84%] [G loss: 1.449780]\n",
      "epoch:29 step:27336 [D loss: 0.625077, acc.: 64.84%] [G loss: 1.410252]\n",
      "epoch:29 step:27337 [D loss: 0.418304, acc.: 85.16%] [G loss: 1.535941]\n",
      "epoch:29 step:27338 [D loss: 0.486202, acc.: 81.25%] [G loss: 1.239640]\n",
      "epoch:29 step:27339 [D loss: 0.637426, acc.: 66.41%] [G loss: 1.165145]\n",
      "epoch:29 step:27340 [D loss: 0.451293, acc.: 82.03%] [G loss: 1.256794]\n",
      "epoch:29 step:27341 [D loss: 0.486199, acc.: 78.12%] [G loss: 1.399300]\n",
      "epoch:29 step:27342 [D loss: 0.643706, acc.: 64.06%] [G loss: 1.450916]\n",
      "epoch:29 step:27343 [D loss: 0.746965, acc.: 52.34%] [G loss: 1.281559]\n",
      "epoch:29 step:27344 [D loss: 0.699269, acc.: 60.16%] [G loss: 1.271568]\n",
      "epoch:29 step:27345 [D loss: 0.658437, acc.: 65.62%] [G loss: 1.053396]\n",
      "epoch:29 step:27346 [D loss: 0.584521, acc.: 66.41%] [G loss: 0.366753]\n",
      "epoch:29 step:27347 [D loss: 0.695120, acc.: 57.03%] [G loss: 1.155307]\n",
      "epoch:29 step:27348 [D loss: 0.537451, acc.: 78.12%] [G loss: 1.196276]\n",
      "epoch:29 step:27349 [D loss: 0.521537, acc.: 75.00%] [G loss: 1.404070]\n",
      "epoch:29 step:27350 [D loss: 0.746561, acc.: 57.03%] [G loss: 1.298363]\n",
      "epoch:29 step:27351 [D loss: 0.652585, acc.: 63.28%] [G loss: 1.061921]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:29 step:27352 [D loss: 0.511275, acc.: 75.00%] [G loss: 1.310274]\n",
      "epoch:29 step:27353 [D loss: 0.658793, acc.: 64.84%] [G loss: 1.074790]\n",
      "epoch:29 step:27354 [D loss: 0.337711, acc.: 87.50%] [G loss: 1.278211]\n",
      "epoch:29 step:27355 [D loss: 0.356920, acc.: 88.28%] [G loss: 1.409116]\n",
      "epoch:29 step:27356 [D loss: 0.552444, acc.: 71.09%] [G loss: 1.513287]\n",
      "epoch:29 step:27357 [D loss: 0.356696, acc.: 79.69%] [G loss: 1.582907]\n",
      "epoch:29 step:27358 [D loss: 0.581153, acc.: 66.41%] [G loss: 1.234084]\n",
      "epoch:29 step:27359 [D loss: 0.633349, acc.: 67.97%] [G loss: 1.356468]\n",
      "epoch:29 step:27360 [D loss: 0.617676, acc.: 63.28%] [G loss: 0.977823]\n",
      "epoch:29 step:27361 [D loss: 0.396349, acc.: 83.59%] [G loss: 1.444188]\n",
      "epoch:29 step:27362 [D loss: 0.760317, acc.: 47.66%] [G loss: 1.455133]\n",
      "epoch:29 step:27363 [D loss: 0.415956, acc.: 84.38%] [G loss: 1.252856]\n",
      "epoch:29 step:27364 [D loss: 0.431859, acc.: 83.59%] [G loss: 1.492025]\n",
      "epoch:29 step:27365 [D loss: 0.264085, acc.: 89.06%] [G loss: 1.498330]\n",
      "epoch:29 step:27366 [D loss: 0.206338, acc.: 92.97%] [G loss: 2.017886]\n",
      "epoch:29 step:27367 [D loss: 0.196935, acc.: 92.97%] [G loss: 1.935143]\n",
      "epoch:29 step:27368 [D loss: 0.197387, acc.: 98.44%] [G loss: 1.917269]\n",
      "epoch:29 step:27369 [D loss: 0.265993, acc.: 96.09%] [G loss: 1.667787]\n",
      "epoch:29 step:27370 [D loss: 0.234499, acc.: 97.66%] [G loss: 2.003537]\n",
      "epoch:29 step:27371 [D loss: 0.201060, acc.: 97.66%] [G loss: 1.612615]\n",
      "epoch:29 step:27372 [D loss: 1.071064, acc.: 31.25%] [G loss: 1.687951]\n",
      "epoch:29 step:27373 [D loss: 0.139860, acc.: 97.66%] [G loss: 1.266406]\n",
      "epoch:29 step:27374 [D loss: 0.109448, acc.: 99.22%] [G loss: 1.919316]\n",
      "epoch:29 step:27375 [D loss: 0.751476, acc.: 53.91%] [G loss: 1.215437]\n",
      "epoch:29 step:27376 [D loss: 0.371619, acc.: 83.59%] [G loss: 1.123652]\n",
      "epoch:29 step:27377 [D loss: 0.108531, acc.: 99.22%] [G loss: 0.983942]\n",
      "epoch:29 step:27378 [D loss: 0.179633, acc.: 98.44%] [G loss: 1.805099]\n",
      "epoch:29 step:27379 [D loss: 0.127154, acc.: 97.66%] [G loss: 1.649754]\n",
      "epoch:29 step:27380 [D loss: 0.386479, acc.: 78.12%] [G loss: 3.023836]\n",
      "epoch:29 step:27381 [D loss: 0.155450, acc.: 97.66%] [G loss: 2.724964]\n",
      "epoch:29 step:27382 [D loss: 0.116833, acc.: 99.22%] [G loss: 2.837787]\n",
      "epoch:29 step:27383 [D loss: 1.296765, acc.: 49.22%] [G loss: 1.989490]\n",
      "epoch:29 step:27384 [D loss: 1.171222, acc.: 42.97%] [G loss: 1.798234]\n",
      "epoch:29 step:27385 [D loss: 0.830583, acc.: 57.03%] [G loss: 1.655116]\n",
      "epoch:29 step:27386 [D loss: 0.744324, acc.: 53.91%] [G loss: 1.435989]\n",
      "epoch:29 step:27387 [D loss: 1.354759, acc.: 14.84%] [G loss: 1.341706]\n",
      "epoch:29 step:27388 [D loss: 0.914702, acc.: 44.53%] [G loss: 1.334231]\n",
      "epoch:29 step:27389 [D loss: 0.663981, acc.: 64.84%] [G loss: 1.511817]\n",
      "epoch:29 step:27390 [D loss: 0.459860, acc.: 77.34%] [G loss: 1.521083]\n",
      "epoch:29 step:27391 [D loss: 0.224253, acc.: 93.75%] [G loss: 1.442197]\n",
      "epoch:29 step:27392 [D loss: 0.192049, acc.: 97.66%] [G loss: 1.759095]\n",
      "epoch:29 step:27393 [D loss: 0.178198, acc.: 94.53%] [G loss: 1.833490]\n",
      "epoch:29 step:27394 [D loss: 0.109086, acc.: 98.44%] [G loss: 2.241627]\n",
      "epoch:29 step:27395 [D loss: 0.161639, acc.: 98.44%] [G loss: 2.133207]\n",
      "epoch:29 step:27396 [D loss: 0.163576, acc.: 97.66%] [G loss: 2.515409]\n",
      "epoch:29 step:27397 [D loss: 0.697588, acc.: 56.25%] [G loss: 1.519553]\n",
      "epoch:29 step:27398 [D loss: 0.352987, acc.: 85.94%] [G loss: 1.412004]\n",
      "epoch:29 step:27399 [D loss: 0.615750, acc.: 61.72%] [G loss: 1.452013]\n",
      "epoch:29 step:27400 [D loss: 0.466047, acc.: 76.56%] [G loss: 1.076652]\n",
      "##############\n",
      "[4.22821234 2.30647419 6.58526431 5.56433293 4.87952862 6.35833253\n",
      " 5.47397306 5.82499787 5.83830048 5.14448399]\n",
      "##########\n",
      "epoch:29 step:27401 [D loss: 0.721360, acc.: 57.03%] [G loss: 1.370109]\n",
      "epoch:29 step:27402 [D loss: 0.461855, acc.: 79.69%] [G loss: 1.613823]\n",
      "epoch:29 step:27403 [D loss: 0.138839, acc.: 94.53%] [G loss: 1.739671]\n",
      "epoch:29 step:27404 [D loss: 0.158871, acc.: 96.09%] [G loss: 2.166405]\n",
      "epoch:29 step:27405 [D loss: 0.076790, acc.: 100.00%] [G loss: 2.416688]\n",
      "epoch:29 step:27406 [D loss: 0.439105, acc.: 81.25%] [G loss: 2.055945]\n",
      "epoch:29 step:27407 [D loss: 0.220524, acc.: 97.66%] [G loss: 2.286375]\n",
      "epoch:29 step:27408 [D loss: 0.145427, acc.: 100.00%] [G loss: 2.910464]\n",
      "epoch:29 step:27409 [D loss: 0.564197, acc.: 69.53%] [G loss: 1.962687]\n",
      "epoch:29 step:27410 [D loss: 0.139823, acc.: 97.66%] [G loss: 2.013219]\n",
      "epoch:29 step:27411 [D loss: 0.249510, acc.: 92.19%] [G loss: 1.764219]\n",
      "epoch:29 step:27412 [D loss: 0.349927, acc.: 86.72%] [G loss: 2.144562]\n",
      "epoch:29 step:27413 [D loss: 0.414902, acc.: 85.16%] [G loss: 1.287433]\n",
      "epoch:29 step:27414 [D loss: 0.826730, acc.: 54.69%] [G loss: 1.880851]\n",
      "epoch:29 step:27415 [D loss: 0.506417, acc.: 78.12%] [G loss: 0.895132]\n",
      "epoch:29 step:27416 [D loss: 0.328403, acc.: 85.16%] [G loss: 1.081375]\n",
      "epoch:29 step:27417 [D loss: 0.388049, acc.: 92.97%] [G loss: 1.668791]\n",
      "epoch:29 step:27418 [D loss: 0.655950, acc.: 65.62%] [G loss: 1.471655]\n",
      "epoch:29 step:27419 [D loss: 0.723812, acc.: 57.81%] [G loss: 0.885354]\n",
      "epoch:29 step:27420 [D loss: 0.825071, acc.: 46.88%] [G loss: 1.350881]\n",
      "epoch:29 step:27421 [D loss: 0.468267, acc.: 82.03%] [G loss: 1.410243]\n",
      "epoch:29 step:27422 [D loss: 0.839544, acc.: 54.69%] [G loss: 1.342632]\n",
      "epoch:29 step:27423 [D loss: 0.739112, acc.: 54.69%] [G loss: 0.886089]\n",
      "epoch:29 step:27424 [D loss: 0.445897, acc.: 80.47%] [G loss: 1.818683]\n",
      "epoch:29 step:27425 [D loss: 0.372350, acc.: 90.62%] [G loss: 1.081306]\n",
      "epoch:29 step:27426 [D loss: 0.461022, acc.: 80.47%] [G loss: 1.085481]\n",
      "epoch:29 step:27427 [D loss: 0.361595, acc.: 82.81%] [G loss: 1.533555]\n",
      "epoch:29 step:27428 [D loss: 0.236707, acc.: 92.19%] [G loss: 2.278775]\n",
      "epoch:29 step:27429 [D loss: 0.112688, acc.: 98.44%] [G loss: 2.107949]\n",
      "epoch:29 step:27430 [D loss: 0.357194, acc.: 82.03%] [G loss: 2.465250]\n",
      "epoch:29 step:27431 [D loss: 0.381944, acc.: 81.25%] [G loss: 1.711659]\n",
      "epoch:29 step:27432 [D loss: 0.112298, acc.: 97.66%] [G loss: 2.856199]\n",
      "epoch:29 step:27433 [D loss: 0.091690, acc.: 100.00%] [G loss: 1.895553]\n",
      "epoch:29 step:27434 [D loss: 0.077805, acc.: 100.00%] [G loss: 2.475969]\n",
      "epoch:29 step:27435 [D loss: 0.402058, acc.: 80.47%] [G loss: 1.255671]\n",
      "epoch:29 step:27436 [D loss: 0.721103, acc.: 60.94%] [G loss: 1.698816]\n",
      "epoch:29 step:27437 [D loss: 0.760586, acc.: 55.47%] [G loss: 1.305858]\n",
      "epoch:29 step:27438 [D loss: 0.269201, acc.: 96.88%] [G loss: 1.366971]\n",
      "epoch:29 step:27439 [D loss: 1.009604, acc.: 37.50%] [G loss: 1.667417]\n",
      "epoch:29 step:27440 [D loss: 0.362096, acc.: 88.28%] [G loss: 1.687443]\n",
      "epoch:29 step:27441 [D loss: 0.782152, acc.: 53.12%] [G loss: 0.353038]\n",
      "epoch:29 step:27442 [D loss: 0.658773, acc.: 65.62%] [G loss: 1.322169]\n",
      "epoch:29 step:27443 [D loss: 0.732439, acc.: 56.25%] [G loss: 1.121414]\n",
      "epoch:29 step:27444 [D loss: 0.446277, acc.: 79.69%] [G loss: 1.104885]\n",
      "epoch:29 step:27445 [D loss: 0.661291, acc.: 61.72%] [G loss: 1.499442]\n",
      "epoch:29 step:27446 [D loss: 0.544555, acc.: 72.66%] [G loss: 1.578135]\n",
      "epoch:29 step:27447 [D loss: 0.283063, acc.: 89.84%] [G loss: 1.908315]\n",
      "epoch:29 step:27448 [D loss: 0.432440, acc.: 85.94%] [G loss: 1.958674]\n",
      "epoch:29 step:27449 [D loss: 0.509625, acc.: 76.56%] [G loss: 2.471492]\n",
      "epoch:29 step:27450 [D loss: 0.501503, acc.: 78.91%] [G loss: 2.357512]\n",
      "epoch:29 step:27451 [D loss: 0.378282, acc.: 85.16%] [G loss: 1.563892]\n",
      "epoch:29 step:27452 [D loss: 0.267712, acc.: 85.16%] [G loss: 1.975471]\n",
      "epoch:29 step:27453 [D loss: 0.409383, acc.: 82.03%] [G loss: 0.963230]\n",
      "epoch:29 step:27454 [D loss: 0.794967, acc.: 54.69%] [G loss: 1.927028]\n",
      "epoch:29 step:27455 [D loss: 0.477338, acc.: 74.22%] [G loss: 1.289539]\n",
      "epoch:29 step:27456 [D loss: 1.401929, acc.: 22.66%] [G loss: 2.564990]\n",
      "epoch:29 step:27457 [D loss: 0.280413, acc.: 85.16%] [G loss: 1.781073]\n",
      "epoch:29 step:27458 [D loss: 0.294429, acc.: 89.06%] [G loss: 1.970366]\n",
      "epoch:29 step:27459 [D loss: 0.224853, acc.: 97.66%] [G loss: 1.553068]\n",
      "epoch:29 step:27460 [D loss: 0.192392, acc.: 96.88%] [G loss: 2.268770]\n",
      "epoch:29 step:27461 [D loss: 0.192554, acc.: 100.00%] [G loss: 1.784184]\n",
      "epoch:29 step:27462 [D loss: 0.155977, acc.: 98.44%] [G loss: 2.140087]\n",
      "epoch:29 step:27463 [D loss: 0.197147, acc.: 96.88%] [G loss: 2.113273]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:29 step:27464 [D loss: 0.436954, acc.: 85.16%] [G loss: 1.891778]\n",
      "epoch:29 step:27465 [D loss: 0.144222, acc.: 99.22%] [G loss: 2.130114]\n",
      "epoch:29 step:27466 [D loss: 0.132106, acc.: 96.88%] [G loss: 2.494457]\n",
      "epoch:29 step:27467 [D loss: 0.425340, acc.: 76.56%] [G loss: 2.567493]\n",
      "epoch:29 step:27468 [D loss: 0.962749, acc.: 50.00%] [G loss: 2.167578]\n",
      "epoch:29 step:27469 [D loss: 0.707424, acc.: 55.47%] [G loss: 1.259108]\n",
      "epoch:29 step:27470 [D loss: 0.520350, acc.: 79.69%] [G loss: 1.488325]\n",
      "epoch:29 step:27471 [D loss: 0.314071, acc.: 90.62%] [G loss: 1.300725]\n",
      "epoch:29 step:27472 [D loss: 0.423016, acc.: 78.12%] [G loss: 1.433253]\n",
      "epoch:29 step:27473 [D loss: 0.816984, acc.: 48.44%] [G loss: 1.703272]\n",
      "epoch:29 step:27474 [D loss: 0.460548, acc.: 78.12%] [G loss: 1.962645]\n",
      "epoch:29 step:27475 [D loss: 0.415115, acc.: 83.59%] [G loss: 1.016889]\n",
      "epoch:29 step:27476 [D loss: 0.686394, acc.: 60.16%] [G loss: 1.116196]\n",
      "epoch:29 step:27477 [D loss: 0.343483, acc.: 92.19%] [G loss: 0.616315]\n",
      "epoch:29 step:27478 [D loss: 0.174798, acc.: 96.88%] [G loss: 1.273178]\n",
      "epoch:29 step:27479 [D loss: 0.274581, acc.: 94.53%] [G loss: 0.747077]\n",
      "epoch:29 step:27480 [D loss: 0.500387, acc.: 79.69%] [G loss: 1.512108]\n",
      "epoch:29 step:27481 [D loss: 0.158510, acc.: 96.88%] [G loss: 0.493639]\n",
      "epoch:29 step:27482 [D loss: 0.090471, acc.: 98.44%] [G loss: 2.386828]\n",
      "epoch:29 step:27483 [D loss: 0.360363, acc.: 85.16%] [G loss: 2.077260]\n",
      "epoch:29 step:27484 [D loss: 0.087764, acc.: 100.00%] [G loss: 2.265107]\n",
      "epoch:29 step:27485 [D loss: 0.586057, acc.: 63.28%] [G loss: 2.247867]\n",
      "epoch:29 step:27486 [D loss: 0.082584, acc.: 98.44%] [G loss: 2.854996]\n",
      "epoch:29 step:27487 [D loss: 0.054584, acc.: 99.22%] [G loss: 2.585252]\n",
      "epoch:29 step:27488 [D loss: 0.063638, acc.: 100.00%] [G loss: 3.151492]\n",
      "epoch:29 step:27489 [D loss: 0.767295, acc.: 57.81%] [G loss: 2.526238]\n",
      "epoch:29 step:27490 [D loss: 0.980246, acc.: 50.78%] [G loss: 2.100364]\n",
      "epoch:29 step:27491 [D loss: 0.486850, acc.: 74.22%] [G loss: 1.556656]\n",
      "epoch:29 step:27492 [D loss: 1.053719, acc.: 35.16%] [G loss: 1.362687]\n",
      "epoch:29 step:27493 [D loss: 0.458827, acc.: 80.47%] [G loss: 0.906554]\n",
      "epoch:29 step:27494 [D loss: 0.466697, acc.: 77.34%] [G loss: 1.734968]\n",
      "epoch:29 step:27495 [D loss: 0.443281, acc.: 80.47%] [G loss: 1.599054]\n",
      "epoch:29 step:27496 [D loss: 0.289424, acc.: 92.97%] [G loss: 1.437271]\n",
      "epoch:29 step:27497 [D loss: 0.414444, acc.: 86.72%] [G loss: 2.042604]\n",
      "epoch:29 step:27498 [D loss: 0.522160, acc.: 74.22%] [G loss: 1.683196]\n",
      "epoch:29 step:27499 [D loss: 0.382452, acc.: 88.28%] [G loss: 1.731007]\n",
      "epoch:29 step:27500 [D loss: 0.199049, acc.: 96.88%] [G loss: 1.571771]\n",
      "epoch:29 step:27501 [D loss: 0.214817, acc.: 97.66%] [G loss: 1.625533]\n",
      "epoch:29 step:27502 [D loss: 0.628416, acc.: 64.84%] [G loss: 1.828490]\n",
      "epoch:29 step:27503 [D loss: 0.435190, acc.: 85.16%] [G loss: 1.436394]\n",
      "epoch:29 step:27504 [D loss: 0.255791, acc.: 93.75%] [G loss: 1.529501]\n",
      "epoch:29 step:27505 [D loss: 0.321330, acc.: 81.25%] [G loss: 2.283571]\n",
      "epoch:29 step:27506 [D loss: 0.524542, acc.: 75.00%] [G loss: 1.834281]\n",
      "epoch:29 step:27507 [D loss: 0.105012, acc.: 99.22%] [G loss: 2.336071]\n",
      "epoch:29 step:27508 [D loss: 0.082812, acc.: 100.00%] [G loss: 1.582284]\n",
      "epoch:29 step:27509 [D loss: 0.111225, acc.: 99.22%] [G loss: 2.288593]\n",
      "epoch:29 step:27510 [D loss: 0.366774, acc.: 88.28%] [G loss: 2.002218]\n",
      "epoch:29 step:27511 [D loss: 0.296155, acc.: 90.62%] [G loss: 2.296026]\n",
      "epoch:29 step:27512 [D loss: 0.407205, acc.: 85.16%] [G loss: 2.403019]\n",
      "epoch:29 step:27513 [D loss: 0.576689, acc.: 63.28%] [G loss: 2.007888]\n",
      "epoch:29 step:27514 [D loss: 0.243737, acc.: 96.88%] [G loss: 1.348004]\n",
      "epoch:29 step:27515 [D loss: 0.150440, acc.: 96.88%] [G loss: 1.360911]\n",
      "epoch:29 step:27516 [D loss: 0.140476, acc.: 97.66%] [G loss: 0.525902]\n",
      "epoch:29 step:27517 [D loss: 0.334796, acc.: 80.47%] [G loss: 2.121777]\n",
      "epoch:29 step:27518 [D loss: 0.120525, acc.: 96.09%] [G loss: 2.289391]\n",
      "epoch:29 step:27519 [D loss: 0.093821, acc.: 99.22%] [G loss: 2.126331]\n",
      "epoch:29 step:27520 [D loss: 0.056356, acc.: 100.00%] [G loss: 2.884647]\n",
      "epoch:29 step:27521 [D loss: 0.485179, acc.: 69.53%] [G loss: 2.967456]\n",
      "epoch:29 step:27522 [D loss: 1.139804, acc.: 43.75%] [G loss: 0.436815]\n",
      "epoch:29 step:27523 [D loss: 0.204839, acc.: 97.66%] [G loss: 1.782047]\n",
      "epoch:29 step:27524 [D loss: 0.614954, acc.: 67.97%] [G loss: 0.872890]\n",
      "epoch:29 step:27525 [D loss: 0.522605, acc.: 73.44%] [G loss: 1.358232]\n",
      "epoch:29 step:27526 [D loss: 0.468543, acc.: 78.91%] [G loss: 2.077353]\n",
      "epoch:29 step:27527 [D loss: 0.429779, acc.: 78.91%] [G loss: 2.111118]\n",
      "epoch:29 step:27528 [D loss: 1.008014, acc.: 46.88%] [G loss: 1.138838]\n",
      "epoch:29 step:27529 [D loss: 0.735401, acc.: 57.03%] [G loss: 1.409342]\n",
      "epoch:29 step:27530 [D loss: 0.693869, acc.: 64.84%] [G loss: 0.984779]\n",
      "epoch:29 step:27531 [D loss: 0.393226, acc.: 89.06%] [G loss: 1.271096]\n",
      "epoch:29 step:27532 [D loss: 0.439743, acc.: 82.03%] [G loss: 1.604370]\n",
      "epoch:29 step:27533 [D loss: 0.336640, acc.: 89.06%] [G loss: 1.593466]\n",
      "epoch:29 step:27534 [D loss: 0.566934, acc.: 75.00%] [G loss: 0.942125]\n",
      "epoch:29 step:27535 [D loss: 0.291916, acc.: 89.06%] [G loss: 1.727103]\n",
      "epoch:29 step:27536 [D loss: 0.171063, acc.: 96.88%] [G loss: 1.928959]\n",
      "epoch:29 step:27537 [D loss: 0.347155, acc.: 89.84%] [G loss: 1.759699]\n",
      "epoch:29 step:27538 [D loss: 0.159157, acc.: 96.88%] [G loss: 1.981693]\n",
      "epoch:29 step:27539 [D loss: 0.079434, acc.: 99.22%] [G loss: 2.256735]\n",
      "epoch:29 step:27540 [D loss: 0.112816, acc.: 96.88%] [G loss: 2.019166]\n",
      "epoch:29 step:27541 [D loss: 0.748145, acc.: 57.03%] [G loss: 1.451964]\n",
      "epoch:29 step:27542 [D loss: 0.195264, acc.: 95.31%] [G loss: 2.116152]\n",
      "epoch:29 step:27543 [D loss: 0.422614, acc.: 79.69%] [G loss: 1.946781]\n",
      "epoch:29 step:27544 [D loss: 0.208686, acc.: 92.97%] [G loss: 1.840924]\n",
      "epoch:29 step:27545 [D loss: 0.483452, acc.: 75.00%] [G loss: 2.141107]\n",
      "epoch:29 step:27546 [D loss: 0.530299, acc.: 76.56%] [G loss: 1.785225]\n",
      "epoch:29 step:27547 [D loss: 0.839290, acc.: 56.25%] [G loss: 1.677177]\n",
      "epoch:29 step:27548 [D loss: 0.528161, acc.: 73.44%] [G loss: 1.089670]\n",
      "epoch:29 step:27549 [D loss: 0.880684, acc.: 39.84%] [G loss: 1.240436]\n",
      "epoch:29 step:27550 [D loss: 0.244529, acc.: 90.62%] [G loss: 1.367657]\n",
      "epoch:29 step:27551 [D loss: 0.163752, acc.: 98.44%] [G loss: 1.690362]\n",
      "epoch:29 step:27552 [D loss: 0.470863, acc.: 81.25%] [G loss: 1.688108]\n",
      "epoch:29 step:27553 [D loss: 0.198748, acc.: 93.75%] [G loss: 1.452112]\n",
      "epoch:29 step:27554 [D loss: 0.177578, acc.: 95.31%] [G loss: 1.812812]\n",
      "epoch:29 step:27555 [D loss: 0.691217, acc.: 61.72%] [G loss: 1.926104]\n",
      "epoch:29 step:27556 [D loss: 0.831172, acc.: 48.44%] [G loss: 1.505908]\n",
      "epoch:29 step:27557 [D loss: 0.468785, acc.: 76.56%] [G loss: 1.590965]\n",
      "epoch:29 step:27558 [D loss: 0.564222, acc.: 70.31%] [G loss: 1.363276]\n",
      "epoch:29 step:27559 [D loss: 0.562196, acc.: 67.19%] [G loss: 1.152488]\n",
      "epoch:29 step:27560 [D loss: 0.514441, acc.: 75.00%] [G loss: 1.317009]\n",
      "epoch:29 step:27561 [D loss: 0.433695, acc.: 79.69%] [G loss: 1.339908]\n",
      "epoch:29 step:27562 [D loss: 0.432468, acc.: 78.91%] [G loss: 1.369356]\n",
      "epoch:29 step:27563 [D loss: 0.544073, acc.: 72.66%] [G loss: 1.419288]\n",
      "epoch:29 step:27564 [D loss: 0.905514, acc.: 42.19%] [G loss: 1.719591]\n",
      "epoch:29 step:27565 [D loss: 0.538490, acc.: 69.53%] [G loss: 1.632810]\n",
      "epoch:29 step:27566 [D loss: 0.454038, acc.: 70.31%] [G loss: 1.395805]\n",
      "epoch:29 step:27567 [D loss: 0.542792, acc.: 71.09%] [G loss: 1.485316]\n",
      "epoch:29 step:27568 [D loss: 0.880128, acc.: 45.31%] [G loss: 1.148789]\n",
      "epoch:29 step:27569 [D loss: 0.160567, acc.: 93.75%] [G loss: 1.509066]\n",
      "epoch:29 step:27570 [D loss: 0.149583, acc.: 96.88%] [G loss: 1.743321]\n",
      "epoch:29 step:27571 [D loss: 0.179509, acc.: 95.31%] [G loss: 2.351573]\n",
      "epoch:29 step:27572 [D loss: 0.145782, acc.: 97.66%] [G loss: 1.674847]\n",
      "epoch:29 step:27573 [D loss: 0.181645, acc.: 96.09%] [G loss: 2.284294]\n",
      "epoch:29 step:27574 [D loss: 0.315766, acc.: 89.06%] [G loss: 1.714904]\n",
      "epoch:29 step:27575 [D loss: 0.101649, acc.: 98.44%] [G loss: 2.725206]\n",
      "epoch:29 step:27576 [D loss: 0.186523, acc.: 97.66%] [G loss: 2.531350]\n",
      "epoch:29 step:27577 [D loss: 0.258105, acc.: 91.41%] [G loss: 0.586571]\n",
      "epoch:29 step:27578 [D loss: 0.182297, acc.: 95.31%] [G loss: 2.685028]\n",
      "epoch:29 step:27579 [D loss: 0.125705, acc.: 99.22%] [G loss: 1.871933]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:29 step:27580 [D loss: 0.096667, acc.: 97.66%] [G loss: 3.110282]\n",
      "epoch:29 step:27581 [D loss: 0.247199, acc.: 95.31%] [G loss: 2.130744]\n",
      "epoch:29 step:27582 [D loss: 0.756249, acc.: 58.59%] [G loss: 2.674366]\n",
      "epoch:29 step:27583 [D loss: 0.421535, acc.: 83.59%] [G loss: 2.951553]\n",
      "epoch:29 step:27584 [D loss: 1.315048, acc.: 49.22%] [G loss: 1.992198]\n",
      "epoch:29 step:27585 [D loss: 0.497852, acc.: 75.00%] [G loss: 1.517661]\n",
      "epoch:29 step:27586 [D loss: 0.615973, acc.: 62.50%] [G loss: 2.808438]\n",
      "epoch:29 step:27587 [D loss: 0.346050, acc.: 86.72%] [G loss: 1.776934]\n",
      "epoch:29 step:27588 [D loss: 0.530757, acc.: 71.88%] [G loss: 0.807665]\n",
      "epoch:29 step:27589 [D loss: 0.546445, acc.: 73.44%] [G loss: 1.758227]\n",
      "epoch:29 step:27590 [D loss: 0.306990, acc.: 89.06%] [G loss: 0.569852]\n",
      "epoch:29 step:27591 [D loss: 0.263502, acc.: 95.31%] [G loss: 1.427411]\n",
      "epoch:29 step:27592 [D loss: 0.905262, acc.: 58.59%] [G loss: 2.068725]\n",
      "epoch:29 step:27593 [D loss: 0.608834, acc.: 63.28%] [G loss: 2.693519]\n",
      "epoch:29 step:27594 [D loss: 1.556479, acc.: 45.31%] [G loss: 1.008847]\n",
      "epoch:29 step:27595 [D loss: 1.843937, acc.: 11.72%] [G loss: 1.933814]\n",
      "epoch:29 step:27596 [D loss: 0.802181, acc.: 57.81%] [G loss: 1.735990]\n",
      "epoch:29 step:27597 [D loss: 0.261975, acc.: 89.06%] [G loss: 2.339487]\n",
      "epoch:29 step:27598 [D loss: 1.263144, acc.: 44.53%] [G loss: 2.257530]\n",
      "epoch:29 step:27599 [D loss: 0.831995, acc.: 50.00%] [G loss: 3.108963]\n",
      "epoch:29 step:27600 [D loss: 0.767780, acc.: 65.62%] [G loss: 2.225809]\n",
      "##############\n",
      "[3.94091789 2.91562334 6.56337627 5.80082061 4.39810873 5.96513153\n",
      " 4.61350807 5.57215141 5.61539972 4.84113606]\n",
      "##########\n",
      "epoch:29 step:27601 [D loss: 0.258361, acc.: 89.84%] [G loss: 1.743030]\n",
      "epoch:29 step:27602 [D loss: 0.993056, acc.: 48.44%] [G loss: 1.427767]\n",
      "epoch:29 step:27603 [D loss: 0.365316, acc.: 83.59%] [G loss: 2.466199]\n",
      "epoch:29 step:27604 [D loss: 0.886237, acc.: 51.56%] [G loss: 2.153758]\n",
      "epoch:29 step:27605 [D loss: 0.967207, acc.: 45.31%] [G loss: 1.567221]\n",
      "epoch:29 step:27606 [D loss: 0.813300, acc.: 55.47%] [G loss: 1.756037]\n",
      "epoch:29 step:27607 [D loss: 0.772374, acc.: 51.56%] [G loss: 2.145258]\n",
      "epoch:29 step:27608 [D loss: 0.580596, acc.: 65.62%] [G loss: 2.721520]\n",
      "epoch:29 step:27609 [D loss: 0.494285, acc.: 76.56%] [G loss: 1.822752]\n",
      "epoch:29 step:27610 [D loss: 0.778130, acc.: 53.91%] [G loss: 2.043518]\n",
      "epoch:29 step:27611 [D loss: 0.752425, acc.: 57.81%] [G loss: 1.354932]\n",
      "epoch:29 step:27612 [D loss: 0.649806, acc.: 62.50%] [G loss: 1.466935]\n",
      "epoch:29 step:27613 [D loss: 0.611737, acc.: 71.88%] [G loss: 2.219207]\n",
      "epoch:29 step:27614 [D loss: 0.594245, acc.: 68.75%] [G loss: 2.329930]\n",
      "epoch:29 step:27615 [D loss: 0.615563, acc.: 66.41%] [G loss: 1.668467]\n",
      "epoch:29 step:27616 [D loss: 0.368277, acc.: 86.72%] [G loss: 1.641074]\n",
      "epoch:29 step:27617 [D loss: 0.460235, acc.: 80.47%] [G loss: 1.815711]\n",
      "epoch:29 step:27618 [D loss: 0.725115, acc.: 56.25%] [G loss: 1.444129]\n",
      "epoch:29 step:27619 [D loss: 0.582310, acc.: 66.41%] [G loss: 2.224984]\n",
      "epoch:29 step:27620 [D loss: 0.612186, acc.: 66.41%] [G loss: 1.598090]\n",
      "epoch:29 step:27621 [D loss: 0.237952, acc.: 92.19%] [G loss: 1.959286]\n",
      "epoch:29 step:27622 [D loss: 0.130277, acc.: 96.09%] [G loss: 1.940622]\n",
      "epoch:29 step:27623 [D loss: 0.177940, acc.: 95.31%] [G loss: 2.414038]\n",
      "epoch:29 step:27624 [D loss: 0.062801, acc.: 99.22%] [G loss: 2.205107]\n",
      "epoch:29 step:27625 [D loss: 0.045515, acc.: 100.00%] [G loss: 2.883267]\n",
      "epoch:29 step:27626 [D loss: 0.095865, acc.: 99.22%] [G loss: 2.592205]\n",
      "epoch:29 step:27627 [D loss: 0.129707, acc.: 97.66%] [G loss: 1.884563]\n",
      "epoch:29 step:27628 [D loss: 0.280211, acc.: 94.53%] [G loss: 2.601383]\n",
      "epoch:29 step:27629 [D loss: 0.096445, acc.: 98.44%] [G loss: 3.458159]\n",
      "epoch:29 step:27630 [D loss: 0.130711, acc.: 97.66%] [G loss: 2.830219]\n",
      "epoch:29 step:27631 [D loss: 0.763998, acc.: 59.38%] [G loss: 2.382316]\n",
      "epoch:29 step:27632 [D loss: 0.469589, acc.: 79.69%] [G loss: 1.700079]\n",
      "epoch:29 step:27633 [D loss: 0.745525, acc.: 55.47%] [G loss: 1.254563]\n",
      "epoch:29 step:27634 [D loss: 0.741296, acc.: 49.22%] [G loss: 1.143061]\n",
      "epoch:29 step:27635 [D loss: 1.209790, acc.: 31.25%] [G loss: 1.372915]\n",
      "epoch:29 step:27636 [D loss: 0.687174, acc.: 60.94%] [G loss: 1.084100]\n",
      "epoch:29 step:27637 [D loss: 0.467443, acc.: 75.00%] [G loss: 1.150088]\n",
      "epoch:29 step:27638 [D loss: 0.333306, acc.: 83.59%] [G loss: 1.706053]\n",
      "epoch:29 step:27639 [D loss: 0.244456, acc.: 95.31%] [G loss: 1.660603]\n",
      "epoch:29 step:27640 [D loss: 0.275481, acc.: 95.31%] [G loss: 1.508230]\n",
      "epoch:29 step:27641 [D loss: 0.116496, acc.: 96.88%] [G loss: 1.075581]\n",
      "epoch:29 step:27642 [D loss: 0.232038, acc.: 90.62%] [G loss: 2.164725]\n",
      "epoch:29 step:27643 [D loss: 0.107293, acc.: 99.22%] [G loss: 1.636429]\n",
      "epoch:29 step:27644 [D loss: 0.160872, acc.: 96.09%] [G loss: 2.462524]\n",
      "epoch:29 step:27645 [D loss: 0.126281, acc.: 100.00%] [G loss: 2.777579]\n",
      "epoch:29 step:27646 [D loss: 1.482304, acc.: 47.66%] [G loss: 2.091483]\n",
      "epoch:29 step:27647 [D loss: 0.895980, acc.: 53.12%] [G loss: 1.460441]\n",
      "epoch:29 step:27648 [D loss: 0.685273, acc.: 61.72%] [G loss: 1.191735]\n",
      "epoch:29 step:27649 [D loss: 0.495179, acc.: 75.00%] [G loss: 1.253017]\n",
      "epoch:29 step:27650 [D loss: 0.656652, acc.: 64.06%] [G loss: 1.256294]\n",
      "epoch:29 step:27651 [D loss: 0.520117, acc.: 76.56%] [G loss: 1.204594]\n",
      "epoch:29 step:27652 [D loss: 0.273314, acc.: 88.28%] [G loss: 1.280617]\n",
      "epoch:29 step:27653 [D loss: 0.630778, acc.: 67.19%] [G loss: 1.525107]\n",
      "epoch:29 step:27654 [D loss: 0.131292, acc.: 99.22%] [G loss: 1.496282]\n",
      "epoch:29 step:27655 [D loss: 0.813197, acc.: 53.12%] [G loss: 2.096247]\n",
      "epoch:29 step:27656 [D loss: 0.603042, acc.: 70.31%] [G loss: 0.825947]\n",
      "epoch:29 step:27657 [D loss: 0.638127, acc.: 65.62%] [G loss: 1.001060]\n",
      "epoch:29 step:27658 [D loss: 0.551559, acc.: 74.22%] [G loss: 1.095508]\n",
      "epoch:29 step:27659 [D loss: 0.802039, acc.: 46.09%] [G loss: 1.209928]\n",
      "epoch:29 step:27660 [D loss: 0.440881, acc.: 81.25%] [G loss: 1.180903]\n",
      "epoch:29 step:27661 [D loss: 0.488420, acc.: 75.78%] [G loss: 1.742426]\n",
      "epoch:29 step:27662 [D loss: 0.314604, acc.: 90.62%] [G loss: 1.363590]\n",
      "epoch:29 step:27663 [D loss: 0.256410, acc.: 96.09%] [G loss: 1.295106]\n",
      "epoch:29 step:27664 [D loss: 0.263650, acc.: 95.31%] [G loss: 1.752117]\n",
      "epoch:29 step:27665 [D loss: 0.763396, acc.: 54.69%] [G loss: 1.625532]\n",
      "epoch:29 step:27666 [D loss: 0.733968, acc.: 60.16%] [G loss: 1.499720]\n",
      "epoch:29 step:27667 [D loss: 0.458745, acc.: 83.59%] [G loss: 1.684979]\n",
      "epoch:29 step:27668 [D loss: 0.564805, acc.: 68.75%] [G loss: 1.185132]\n",
      "epoch:29 step:27669 [D loss: 0.539745, acc.: 71.88%] [G loss: 1.523032]\n",
      "epoch:29 step:27670 [D loss: 0.437227, acc.: 82.81%] [G loss: 1.847908]\n",
      "epoch:29 step:27671 [D loss: 0.204873, acc.: 96.09%] [G loss: 1.772660]\n",
      "epoch:29 step:27672 [D loss: 0.220019, acc.: 95.31%] [G loss: 1.850276]\n",
      "epoch:29 step:27673 [D loss: 0.611949, acc.: 65.62%] [G loss: 1.141929]\n",
      "epoch:29 step:27674 [D loss: 0.666479, acc.: 58.59%] [G loss: 1.542362]\n",
      "epoch:29 step:27675 [D loss: 0.663398, acc.: 59.38%] [G loss: 1.168530]\n",
      "epoch:29 step:27676 [D loss: 0.242054, acc.: 90.62%] [G loss: 1.192073]\n",
      "epoch:29 step:27677 [D loss: 0.157307, acc.: 96.88%] [G loss: 1.880764]\n",
      "epoch:29 step:27678 [D loss: 0.219636, acc.: 96.09%] [G loss: 1.886949]\n",
      "epoch:29 step:27679 [D loss: 0.602252, acc.: 66.41%] [G loss: 1.967076]\n",
      "epoch:29 step:27680 [D loss: 0.175622, acc.: 96.09%] [G loss: 2.105496]\n",
      "epoch:29 step:27681 [D loss: 0.161569, acc.: 99.22%] [G loss: 1.360433]\n",
      "epoch:29 step:27682 [D loss: 0.561293, acc.: 69.53%] [G loss: 1.656901]\n",
      "epoch:29 step:27683 [D loss: 0.257241, acc.: 94.53%] [G loss: 1.742403]\n",
      "epoch:29 step:27684 [D loss: 0.467930, acc.: 75.00%] [G loss: 1.844563]\n",
      "epoch:29 step:27685 [D loss: 0.265576, acc.: 92.97%] [G loss: 1.929127]\n",
      "epoch:29 step:27686 [D loss: 0.211355, acc.: 96.88%] [G loss: 1.985972]\n",
      "epoch:29 step:27687 [D loss: 0.289071, acc.: 96.88%] [G loss: 2.209457]\n",
      "epoch:29 step:27688 [D loss: 0.250833, acc.: 94.53%] [G loss: 2.442367]\n",
      "epoch:29 step:27689 [D loss: 0.692155, acc.: 58.59%] [G loss: 1.616911]\n",
      "epoch:29 step:27690 [D loss: 0.126360, acc.: 98.44%] [G loss: 1.859874]\n",
      "epoch:29 step:27691 [D loss: 0.391370, acc.: 85.16%] [G loss: 1.496628]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:29 step:27692 [D loss: 0.446195, acc.: 81.25%] [G loss: 1.925547]\n",
      "epoch:29 step:27693 [D loss: 0.335381, acc.: 90.62%] [G loss: 1.875092]\n",
      "epoch:29 step:27694 [D loss: 0.364879, acc.: 85.94%] [G loss: 1.697008]\n",
      "epoch:29 step:27695 [D loss: 0.222337, acc.: 98.44%] [G loss: 1.674763]\n",
      "epoch:29 step:27696 [D loss: 0.300022, acc.: 94.53%] [G loss: 2.023256]\n",
      "epoch:29 step:27697 [D loss: 0.366325, acc.: 82.81%] [G loss: 1.240672]\n",
      "epoch:29 step:27698 [D loss: 0.626909, acc.: 60.16%] [G loss: 1.523674]\n",
      "epoch:29 step:27699 [D loss: 0.494133, acc.: 75.00%] [G loss: 1.988567]\n",
      "epoch:29 step:27700 [D loss: 0.210198, acc.: 92.19%] [G loss: 1.684340]\n",
      "epoch:29 step:27701 [D loss: 0.433819, acc.: 83.59%] [G loss: 1.558133]\n",
      "epoch:29 step:27702 [D loss: 0.394934, acc.: 86.72%] [G loss: 1.991256]\n",
      "epoch:29 step:27703 [D loss: 0.282301, acc.: 93.75%] [G loss: 2.004594]\n",
      "epoch:29 step:27704 [D loss: 0.651855, acc.: 65.62%] [G loss: 1.466260]\n",
      "epoch:29 step:27705 [D loss: 0.456866, acc.: 79.69%] [G loss: 1.731837]\n",
      "epoch:29 step:27706 [D loss: 0.225276, acc.: 95.31%] [G loss: 1.986125]\n",
      "epoch:29 step:27707 [D loss: 0.249994, acc.: 92.19%] [G loss: 1.921756]\n",
      "epoch:29 step:27708 [D loss: 0.322520, acc.: 88.28%] [G loss: 1.981887]\n",
      "epoch:29 step:27709 [D loss: 0.095813, acc.: 100.00%] [G loss: 2.396809]\n",
      "epoch:29 step:27710 [D loss: 0.155382, acc.: 96.88%] [G loss: 2.555829]\n",
      "epoch:29 step:27711 [D loss: 0.353019, acc.: 88.28%] [G loss: 2.172288]\n",
      "epoch:29 step:27712 [D loss: 0.174615, acc.: 98.44%] [G loss: 1.580140]\n",
      "epoch:29 step:27713 [D loss: 0.296096, acc.: 92.97%] [G loss: 2.184381]\n",
      "epoch:29 step:27714 [D loss: 0.224177, acc.: 92.97%] [G loss: 1.939187]\n",
      "epoch:29 step:27715 [D loss: 0.391399, acc.: 82.03%] [G loss: 1.559174]\n",
      "epoch:29 step:27716 [D loss: 0.398805, acc.: 82.81%] [G loss: 1.971210]\n",
      "epoch:29 step:27717 [D loss: 0.261801, acc.: 96.09%] [G loss: 1.931354]\n",
      "epoch:29 step:27718 [D loss: 0.142473, acc.: 97.66%] [G loss: 2.089982]\n",
      "epoch:29 step:27719 [D loss: 0.255451, acc.: 95.31%] [G loss: 1.471933]\n",
      "epoch:29 step:27720 [D loss: 0.239047, acc.: 94.53%] [G loss: 1.539968]\n",
      "epoch:29 step:27721 [D loss: 0.157592, acc.: 98.44%] [G loss: 2.041528]\n",
      "epoch:29 step:27722 [D loss: 0.138220, acc.: 99.22%] [G loss: 2.000147]\n",
      "epoch:29 step:27723 [D loss: 0.235435, acc.: 93.75%] [G loss: 2.491220]\n",
      "epoch:29 step:27724 [D loss: 0.219709, acc.: 94.53%] [G loss: 1.968644]\n",
      "epoch:29 step:27725 [D loss: 0.187813, acc.: 97.66%] [G loss: 2.020338]\n",
      "epoch:29 step:27726 [D loss: 0.288283, acc.: 91.41%] [G loss: 1.832217]\n",
      "epoch:29 step:27727 [D loss: 0.101069, acc.: 99.22%] [G loss: 1.217558]\n",
      "epoch:29 step:27728 [D loss: 0.176657, acc.: 96.09%] [G loss: 2.057837]\n",
      "epoch:29 step:27729 [D loss: 0.274192, acc.: 88.28%] [G loss: 2.112648]\n",
      "epoch:29 step:27730 [D loss: 0.082454, acc.: 99.22%] [G loss: 2.004042]\n",
      "epoch:29 step:27731 [D loss: 0.128297, acc.: 99.22%] [G loss: 2.952766]\n",
      "epoch:29 step:27732 [D loss: 0.228008, acc.: 90.62%] [G loss: 1.747509]\n",
      "epoch:29 step:27733 [D loss: 0.283381, acc.: 89.06%] [G loss: 3.029695]\n",
      "epoch:29 step:27734 [D loss: 0.052263, acc.: 100.00%] [G loss: 2.192545]\n",
      "epoch:29 step:27735 [D loss: 0.896796, acc.: 56.25%] [G loss: 2.023694]\n",
      "epoch:29 step:27736 [D loss: 0.643778, acc.: 65.62%] [G loss: 1.703815]\n",
      "epoch:29 step:27737 [D loss: 0.546956, acc.: 71.09%] [G loss: 1.407534]\n",
      "epoch:29 step:27738 [D loss: 0.309702, acc.: 89.84%] [G loss: 1.245138]\n",
      "epoch:29 step:27739 [D loss: 0.287927, acc.: 82.81%] [G loss: 1.545424]\n",
      "epoch:29 step:27740 [D loss: 0.153662, acc.: 97.66%] [G loss: 2.206360]\n",
      "epoch:29 step:27741 [D loss: 0.292219, acc.: 89.84%] [G loss: 1.951437]\n",
      "epoch:29 step:27742 [D loss: 0.725010, acc.: 58.59%] [G loss: 1.983985]\n",
      "epoch:29 step:27743 [D loss: 0.606242, acc.: 64.84%] [G loss: 1.582924]\n",
      "epoch:29 step:27744 [D loss: 0.515489, acc.: 75.78%] [G loss: 1.333069]\n",
      "epoch:29 step:27745 [D loss: 0.643445, acc.: 63.28%] [G loss: 1.126319]\n",
      "epoch:29 step:27746 [D loss: 0.371360, acc.: 88.28%] [G loss: 0.520419]\n",
      "epoch:29 step:27747 [D loss: 0.957070, acc.: 57.03%] [G loss: 2.088402]\n",
      "epoch:29 step:27748 [D loss: 0.374654, acc.: 89.06%] [G loss: 1.239276]\n",
      "epoch:29 step:27749 [D loss: 0.328632, acc.: 89.06%] [G loss: 2.268779]\n",
      "epoch:29 step:27750 [D loss: 0.352907, acc.: 81.25%] [G loss: 2.252952]\n",
      "epoch:29 step:27751 [D loss: 0.411126, acc.: 85.16%] [G loss: 2.337041]\n",
      "epoch:29 step:27752 [D loss: 0.558206, acc.: 68.75%] [G loss: 2.629331]\n",
      "epoch:29 step:27753 [D loss: 0.727414, acc.: 63.28%] [G loss: 1.801187]\n",
      "epoch:29 step:27754 [D loss: 0.523812, acc.: 76.56%] [G loss: 1.595121]\n",
      "epoch:29 step:27755 [D loss: 0.281150, acc.: 92.97%] [G loss: 1.774340]\n",
      "epoch:29 step:27756 [D loss: 0.197808, acc.: 93.75%] [G loss: 1.244198]\n",
      "epoch:29 step:27757 [D loss: 0.558146, acc.: 74.22%] [G loss: 1.503535]\n",
      "epoch:29 step:27758 [D loss: 0.403323, acc.: 79.69%] [G loss: 1.612860]\n",
      "epoch:29 step:27759 [D loss: 0.545819, acc.: 70.31%] [G loss: 1.358349]\n",
      "epoch:29 step:27760 [D loss: 0.289567, acc.: 90.62%] [G loss: 1.367330]\n",
      "epoch:29 step:27761 [D loss: 0.379827, acc.: 86.72%] [G loss: 1.839465]\n",
      "epoch:29 step:27762 [D loss: 0.165968, acc.: 93.75%] [G loss: 1.926203]\n",
      "epoch:29 step:27763 [D loss: 0.881894, acc.: 46.88%] [G loss: 1.917413]\n",
      "epoch:29 step:27764 [D loss: 0.175570, acc.: 92.97%] [G loss: 2.273450]\n",
      "epoch:29 step:27765 [D loss: 0.176923, acc.: 92.19%] [G loss: 1.596418]\n",
      "epoch:29 step:27766 [D loss: 0.356943, acc.: 85.16%] [G loss: 1.996803]\n",
      "epoch:29 step:27767 [D loss: 0.898481, acc.: 53.12%] [G loss: 2.329699]\n",
      "epoch:29 step:27768 [D loss: 0.339027, acc.: 90.62%] [G loss: 1.596321]\n",
      "epoch:29 step:27769 [D loss: 0.250404, acc.: 89.84%] [G loss: 1.740339]\n",
      "epoch:29 step:27770 [D loss: 0.546785, acc.: 67.19%] [G loss: 1.286271]\n",
      "epoch:29 step:27771 [D loss: 0.287920, acc.: 92.97%] [G loss: 1.385278]\n",
      "epoch:29 step:27772 [D loss: 0.312314, acc.: 85.94%] [G loss: 1.412892]\n",
      "epoch:29 step:27773 [D loss: 0.217138, acc.: 92.97%] [G loss: 1.788078]\n",
      "epoch:29 step:27774 [D loss: 0.407103, acc.: 85.16%] [G loss: 1.175724]\n",
      "epoch:29 step:27775 [D loss: 0.317372, acc.: 87.50%] [G loss: 2.101561]\n",
      "epoch:29 step:27776 [D loss: 0.201190, acc.: 97.66%] [G loss: 1.955367]\n",
      "epoch:29 step:27777 [D loss: 0.209714, acc.: 91.41%] [G loss: 2.120476]\n",
      "epoch:29 step:27778 [D loss: 0.409361, acc.: 76.56%] [G loss: 2.156890]\n",
      "epoch:29 step:27779 [D loss: 0.606787, acc.: 64.84%] [G loss: 1.973204]\n",
      "epoch:29 step:27780 [D loss: 0.699665, acc.: 55.47%] [G loss: 1.107712]\n",
      "epoch:29 step:27781 [D loss: 0.453053, acc.: 78.91%] [G loss: 0.980653]\n",
      "epoch:29 step:27782 [D loss: 0.202571, acc.: 94.53%] [G loss: 1.587706]\n",
      "epoch:29 step:27783 [D loss: 0.668902, acc.: 59.38%] [G loss: 1.720749]\n",
      "epoch:29 step:27784 [D loss: 0.324710, acc.: 89.06%] [G loss: 1.951468]\n",
      "epoch:29 step:27785 [D loss: 0.442346, acc.: 79.69%] [G loss: 1.441644]\n",
      "epoch:29 step:27786 [D loss: 0.795732, acc.: 50.00%] [G loss: 1.463141]\n",
      "epoch:29 step:27787 [D loss: 1.308718, acc.: 20.31%] [G loss: 1.035784]\n",
      "epoch:29 step:27788 [D loss: 0.246919, acc.: 92.19%] [G loss: 1.966363]\n",
      "epoch:29 step:27789 [D loss: 0.209260, acc.: 92.97%] [G loss: 1.353255]\n",
      "epoch:29 step:27790 [D loss: 0.127029, acc.: 97.66%] [G loss: 1.302989]\n",
      "epoch:29 step:27791 [D loss: 0.826158, acc.: 55.47%] [G loss: 1.447871]\n",
      "epoch:29 step:27792 [D loss: 0.445214, acc.: 80.47%] [G loss: 1.834830]\n",
      "epoch:29 step:27793 [D loss: 0.573828, acc.: 71.09%] [G loss: 1.570401]\n",
      "epoch:29 step:27794 [D loss: 0.405683, acc.: 82.03%] [G loss: 1.711248]\n",
      "epoch:29 step:27795 [D loss: 0.187235, acc.: 93.75%] [G loss: 1.612517]\n",
      "epoch:29 step:27796 [D loss: 0.173960, acc.: 93.75%] [G loss: 1.729160]\n",
      "epoch:29 step:27797 [D loss: 0.246523, acc.: 89.06%] [G loss: 1.850671]\n",
      "epoch:29 step:27798 [D loss: 0.486077, acc.: 70.31%] [G loss: 2.434953]\n",
      "epoch:29 step:27799 [D loss: 0.080192, acc.: 100.00%] [G loss: 2.080357]\n",
      "epoch:29 step:27800 [D loss: 0.330082, acc.: 86.72%] [G loss: 2.287408]\n",
      "##############\n",
      "[3.9734944  3.08511624 6.65066124 6.07482835 4.54863592 6.13808168\n",
      " 5.09243137 5.89743609 6.17882088 5.12188304]\n",
      "##########\n",
      "epoch:29 step:27801 [D loss: 0.401094, acc.: 85.16%] [G loss: 2.311625]\n",
      "epoch:29 step:27802 [D loss: 0.204244, acc.: 91.41%] [G loss: 2.322401]\n",
      "epoch:29 step:27803 [D loss: 0.170078, acc.: 94.53%] [G loss: 2.938615]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:29 step:27804 [D loss: 0.603285, acc.: 67.19%] [G loss: 3.228807]\n",
      "epoch:29 step:27805 [D loss: 0.078595, acc.: 99.22%] [G loss: 2.286410]\n",
      "epoch:29 step:27806 [D loss: 0.055490, acc.: 100.00%] [G loss: 2.064325]\n",
      "epoch:29 step:27807 [D loss: 0.201496, acc.: 91.41%] [G loss: 2.698651]\n",
      "epoch:29 step:27808 [D loss: 0.074551, acc.: 98.44%] [G loss: 1.918831]\n",
      "epoch:29 step:27809 [D loss: 0.302560, acc.: 85.94%] [G loss: 2.547446]\n",
      "epoch:29 step:27810 [D loss: 0.049349, acc.: 99.22%] [G loss: 3.609567]\n",
      "epoch:29 step:27811 [D loss: 0.716894, acc.: 64.06%] [G loss: 3.012720]\n",
      "epoch:29 step:27812 [D loss: 1.477018, acc.: 49.22%] [G loss: 3.032691]\n",
      "epoch:29 step:27813 [D loss: 1.425384, acc.: 50.78%] [G loss: 2.078026]\n",
      "epoch:29 step:27814 [D loss: 0.688756, acc.: 61.72%] [G loss: 1.821605]\n",
      "epoch:29 step:27815 [D loss: 0.785217, acc.: 53.12%] [G loss: 1.415463]\n",
      "epoch:29 step:27816 [D loss: 0.205820, acc.: 96.09%] [G loss: 1.714926]\n",
      "epoch:29 step:27817 [D loss: 0.127205, acc.: 97.66%] [G loss: 2.087882]\n",
      "epoch:29 step:27818 [D loss: 0.128893, acc.: 96.88%] [G loss: 1.795497]\n",
      "epoch:29 step:27819 [D loss: 0.065980, acc.: 100.00%] [G loss: 2.162480]\n",
      "epoch:29 step:27820 [D loss: 0.117418, acc.: 96.88%] [G loss: 2.049546]\n",
      "epoch:29 step:27821 [D loss: 0.049356, acc.: 100.00%] [G loss: 2.840013]\n",
      "epoch:29 step:27822 [D loss: 0.041669, acc.: 100.00%] [G loss: 3.048795]\n",
      "epoch:29 step:27823 [D loss: 0.064246, acc.: 99.22%] [G loss: 2.465090]\n",
      "epoch:29 step:27824 [D loss: 0.086998, acc.: 99.22%] [G loss: 2.447997]\n",
      "epoch:29 step:27825 [D loss: 0.641162, acc.: 67.97%] [G loss: 1.941226]\n",
      "epoch:29 step:27826 [D loss: 0.713206, acc.: 64.06%] [G loss: 0.922778]\n",
      "epoch:29 step:27827 [D loss: 0.465382, acc.: 75.78%] [G loss: 0.724117]\n",
      "epoch:29 step:27828 [D loss: 0.357620, acc.: 77.34%] [G loss: 2.078222]\n",
      "epoch:29 step:27829 [D loss: 0.819261, acc.: 58.59%] [G loss: 3.158972]\n",
      "epoch:29 step:27830 [D loss: 0.542882, acc.: 71.09%] [G loss: 2.277466]\n",
      "epoch:29 step:27831 [D loss: 1.172384, acc.: 39.06%] [G loss: 0.602008]\n",
      "epoch:29 step:27832 [D loss: 0.271559, acc.: 87.50%] [G loss: 2.285873]\n",
      "epoch:29 step:27833 [D loss: 0.065198, acc.: 100.00%] [G loss: 2.628757]\n",
      "epoch:29 step:27834 [D loss: 0.325790, acc.: 83.59%] [G loss: 2.985440]\n",
      "epoch:29 step:27835 [D loss: 0.650327, acc.: 65.62%] [G loss: 2.555331]\n",
      "epoch:29 step:27836 [D loss: 0.057463, acc.: 99.22%] [G loss: 2.963436]\n",
      "epoch:29 step:27837 [D loss: 0.236331, acc.: 92.97%] [G loss: 3.113680]\n",
      "epoch:29 step:27838 [D loss: 0.160971, acc.: 96.09%] [G loss: 3.433148]\n",
      "epoch:29 step:27839 [D loss: 1.025123, acc.: 52.34%] [G loss: 2.015817]\n",
      "epoch:29 step:27840 [D loss: 1.028738, acc.: 46.88%] [G loss: 2.557230]\n",
      "epoch:29 step:27841 [D loss: 0.564760, acc.: 70.31%] [G loss: 2.039618]\n",
      "epoch:29 step:27842 [D loss: 0.638389, acc.: 58.59%] [G loss: 1.105967]\n",
      "epoch:29 step:27843 [D loss: 0.813995, acc.: 50.78%] [G loss: 1.257859]\n",
      "epoch:29 step:27844 [D loss: 0.878664, acc.: 48.44%] [G loss: 1.623728]\n",
      "epoch:29 step:27845 [D loss: 0.590879, acc.: 67.97%] [G loss: 1.181658]\n",
      "epoch:29 step:27846 [D loss: 0.665745, acc.: 63.28%] [G loss: 1.422668]\n",
      "epoch:29 step:27847 [D loss: 0.453042, acc.: 79.69%] [G loss: 1.331205]\n",
      "epoch:29 step:27848 [D loss: 0.850591, acc.: 48.44%] [G loss: 1.062937]\n",
      "epoch:29 step:27849 [D loss: 0.617679, acc.: 64.06%] [G loss: 1.872056]\n",
      "epoch:29 step:27850 [D loss: 0.622401, acc.: 67.19%] [G loss: 2.070949]\n",
      "epoch:29 step:27851 [D loss: 0.697487, acc.: 60.16%] [G loss: 1.422900]\n",
      "epoch:29 step:27852 [D loss: 0.674247, acc.: 65.62%] [G loss: 1.393222]\n",
      "epoch:29 step:27853 [D loss: 0.482707, acc.: 76.56%] [G loss: 1.461886]\n",
      "epoch:29 step:27854 [D loss: 0.717875, acc.: 56.25%] [G loss: 1.184771]\n",
      "epoch:29 step:27855 [D loss: 0.305824, acc.: 90.62%] [G loss: 0.985299]\n",
      "epoch:29 step:27856 [D loss: 0.395746, acc.: 83.59%] [G loss: 1.540495]\n",
      "epoch:29 step:27857 [D loss: 0.154051, acc.: 99.22%] [G loss: 1.927031]\n",
      "epoch:29 step:27858 [D loss: 0.273353, acc.: 96.88%] [G loss: 0.708951]\n",
      "epoch:29 step:27859 [D loss: 0.361993, acc.: 87.50%] [G loss: 1.034485]\n",
      "epoch:29 step:27860 [D loss: 0.603004, acc.: 70.31%] [G loss: 0.843126]\n",
      "epoch:29 step:27861 [D loss: 0.791839, acc.: 50.00%] [G loss: 1.620834]\n",
      "epoch:29 step:27862 [D loss: 0.810471, acc.: 50.00%] [G loss: 0.888466]\n",
      "epoch:29 step:27863 [D loss: 0.486240, acc.: 75.78%] [G loss: 1.334909]\n",
      "epoch:29 step:27864 [D loss: 0.539015, acc.: 73.44%] [G loss: 1.212750]\n",
      "epoch:29 step:27865 [D loss: 0.281700, acc.: 91.41%] [G loss: 1.563848]\n",
      "epoch:29 step:27866 [D loss: 0.356611, acc.: 85.16%] [G loss: 1.455479]\n",
      "epoch:29 step:27867 [D loss: 0.247479, acc.: 92.97%] [G loss: 1.545325]\n",
      "epoch:29 step:27868 [D loss: 0.867135, acc.: 46.09%] [G loss: 1.295119]\n",
      "epoch:29 step:27869 [D loss: 0.145544, acc.: 98.44%] [G loss: 1.553215]\n",
      "epoch:29 step:27870 [D loss: 0.227710, acc.: 89.84%] [G loss: 1.980359]\n",
      "epoch:29 step:27871 [D loss: 0.218043, acc.: 93.75%] [G loss: 2.068651]\n",
      "epoch:29 step:27872 [D loss: 0.325080, acc.: 92.19%] [G loss: 2.072501]\n",
      "epoch:29 step:27873 [D loss: 0.146778, acc.: 96.88%] [G loss: 1.853541]\n",
      "epoch:29 step:27874 [D loss: 0.163148, acc.: 96.09%] [G loss: 2.263454]\n",
      "epoch:29 step:27875 [D loss: 0.208099, acc.: 97.66%] [G loss: 1.853696]\n",
      "epoch:29 step:27876 [D loss: 0.546139, acc.: 73.44%] [G loss: 1.854724]\n",
      "epoch:29 step:27877 [D loss: 0.315252, acc.: 92.97%] [G loss: 0.399456]\n",
      "epoch:29 step:27878 [D loss: 0.660751, acc.: 57.03%] [G loss: 1.613107]\n",
      "epoch:29 step:27879 [D loss: 0.153697, acc.: 96.09%] [G loss: 1.870074]\n",
      "epoch:29 step:27880 [D loss: 0.157024, acc.: 97.66%] [G loss: 2.049309]\n",
      "epoch:29 step:27881 [D loss: 0.244696, acc.: 90.62%] [G loss: 1.967318]\n",
      "epoch:29 step:27882 [D loss: 0.107220, acc.: 97.66%] [G loss: 2.365270]\n",
      "epoch:29 step:27883 [D loss: 0.357043, acc.: 84.38%] [G loss: 2.097494]\n",
      "epoch:29 step:27884 [D loss: 0.534828, acc.: 72.66%] [G loss: 1.506021]\n",
      "epoch:29 step:27885 [D loss: 0.592849, acc.: 63.28%] [G loss: 2.150398]\n",
      "epoch:29 step:27886 [D loss: 0.153980, acc.: 96.88%] [G loss: 1.819645]\n",
      "epoch:29 step:27887 [D loss: 0.143821, acc.: 96.88%] [G loss: 2.081825]\n",
      "epoch:29 step:27888 [D loss: 0.831394, acc.: 53.91%] [G loss: 1.670643]\n",
      "epoch:29 step:27889 [D loss: 0.648442, acc.: 65.62%] [G loss: 1.475149]\n",
      "epoch:29 step:27890 [D loss: 0.583090, acc.: 71.88%] [G loss: 1.260048]\n",
      "epoch:29 step:27891 [D loss: 0.518250, acc.: 78.12%] [G loss: 1.390354]\n",
      "epoch:29 step:27892 [D loss: 0.376957, acc.: 87.50%] [G loss: 0.985052]\n",
      "epoch:29 step:27893 [D loss: 0.348434, acc.: 89.84%] [G loss: 1.393413]\n",
      "epoch:29 step:27894 [D loss: 0.602910, acc.: 69.53%] [G loss: 1.150425]\n",
      "epoch:29 step:27895 [D loss: 0.574916, acc.: 67.97%] [G loss: 1.482461]\n",
      "epoch:29 step:27896 [D loss: 0.489683, acc.: 75.78%] [G loss: 1.500467]\n",
      "epoch:29 step:27897 [D loss: 0.312129, acc.: 90.62%] [G loss: 1.780060]\n",
      "epoch:29 step:27898 [D loss: 0.682735, acc.: 60.16%] [G loss: 2.453979]\n",
      "epoch:29 step:27899 [D loss: 0.229808, acc.: 96.09%] [G loss: 1.876877]\n",
      "epoch:29 step:27900 [D loss: 0.262774, acc.: 89.84%] [G loss: 1.843791]\n",
      "epoch:29 step:27901 [D loss: 0.118653, acc.: 98.44%] [G loss: 0.824056]\n",
      "epoch:29 step:27902 [D loss: 0.079073, acc.: 100.00%] [G loss: 2.327712]\n",
      "epoch:29 step:27903 [D loss: 0.106934, acc.: 98.44%] [G loss: 2.267630]\n",
      "epoch:29 step:27904 [D loss: 0.086291, acc.: 100.00%] [G loss: 2.256593]\n",
      "epoch:29 step:27905 [D loss: 0.088217, acc.: 99.22%] [G loss: 2.514249]\n",
      "epoch:29 step:27906 [D loss: 0.069045, acc.: 98.44%] [G loss: 2.854632]\n",
      "epoch:29 step:27907 [D loss: 0.706286, acc.: 57.81%] [G loss: 1.992634]\n",
      "epoch:29 step:27908 [D loss: 0.983678, acc.: 53.12%] [G loss: 2.025189]\n",
      "epoch:29 step:27909 [D loss: 0.810307, acc.: 56.25%] [G loss: 1.029020]\n",
      "epoch:29 step:27910 [D loss: 0.574807, acc.: 70.31%] [G loss: 1.446108]\n",
      "epoch:29 step:27911 [D loss: 0.533478, acc.: 75.78%] [G loss: 1.516000]\n",
      "epoch:29 step:27912 [D loss: 0.202367, acc.: 94.53%] [G loss: 1.438089]\n",
      "epoch:29 step:27913 [D loss: 0.255637, acc.: 92.97%] [G loss: 1.690410]\n",
      "epoch:29 step:27914 [D loss: 0.367724, acc.: 89.06%] [G loss: 1.774645]\n",
      "epoch:29 step:27915 [D loss: 0.230077, acc.: 96.88%] [G loss: 2.199622]\n",
      "epoch:29 step:27916 [D loss: 0.190167, acc.: 97.66%] [G loss: 2.114482]\n",
      "epoch:29 step:27917 [D loss: 0.677207, acc.: 64.84%] [G loss: 1.880647]\n",
      "epoch:29 step:27918 [D loss: 0.657193, acc.: 60.94%] [G loss: 2.164754]\n",
      "epoch:29 step:27919 [D loss: 0.077987, acc.: 100.00%] [G loss: 2.699396]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:29 step:27920 [D loss: 0.404474, acc.: 80.47%] [G loss: 2.340559]\n",
      "epoch:29 step:27921 [D loss: 0.835162, acc.: 51.56%] [G loss: 1.197231]\n",
      "epoch:29 step:27922 [D loss: 0.335184, acc.: 85.16%] [G loss: 1.705412]\n",
      "epoch:29 step:27923 [D loss: 0.499912, acc.: 74.22%] [G loss: 1.447661]\n",
      "epoch:29 step:27924 [D loss: 0.601454, acc.: 63.28%] [G loss: 1.093785]\n",
      "epoch:29 step:27925 [D loss: 0.394317, acc.: 88.28%] [G loss: 1.507193]\n",
      "epoch:29 step:27926 [D loss: 0.426115, acc.: 86.72%] [G loss: 1.648206]\n",
      "epoch:29 step:27927 [D loss: 0.178200, acc.: 95.31%] [G loss: 2.119148]\n",
      "epoch:29 step:27928 [D loss: 0.104229, acc.: 99.22%] [G loss: 1.506753]\n",
      "epoch:29 step:27929 [D loss: 0.200884, acc.: 94.53%] [G loss: 1.946559]\n",
      "epoch:29 step:27930 [D loss: 0.226833, acc.: 96.88%] [G loss: 2.230098]\n",
      "epoch:29 step:27931 [D loss: 0.363251, acc.: 90.62%] [G loss: 0.540097]\n",
      "epoch:29 step:27932 [D loss: 0.614105, acc.: 65.62%] [G loss: 1.850602]\n",
      "epoch:29 step:27933 [D loss: 0.635093, acc.: 61.72%] [G loss: 1.399422]\n",
      "epoch:29 step:27934 [D loss: 1.564885, acc.: 18.75%] [G loss: 0.826504]\n",
      "epoch:29 step:27935 [D loss: 0.398745, acc.: 85.94%] [G loss: 1.295618]\n",
      "epoch:29 step:27936 [D loss: 0.544889, acc.: 67.97%] [G loss: 2.001142]\n",
      "epoch:29 step:27937 [D loss: 0.225047, acc.: 91.41%] [G loss: 1.823176]\n",
      "epoch:29 step:27938 [D loss: 0.838729, acc.: 50.78%] [G loss: 1.911011]\n",
      "epoch:29 step:27939 [D loss: 0.596052, acc.: 67.19%] [G loss: 1.342526]\n",
      "epoch:29 step:27940 [D loss: 0.347438, acc.: 89.06%] [G loss: 1.934781]\n",
      "epoch:29 step:27941 [D loss: 0.348611, acc.: 76.56%] [G loss: 2.060654]\n",
      "epoch:29 step:27942 [D loss: 0.120866, acc.: 98.44%] [G loss: 1.515781]\n",
      "epoch:29 step:27943 [D loss: 1.053252, acc.: 29.69%] [G loss: 1.893605]\n",
      "epoch:29 step:27944 [D loss: 0.843903, acc.: 58.59%] [G loss: 1.946687]\n",
      "epoch:29 step:27945 [D loss: 0.813686, acc.: 49.22%] [G loss: 1.735040]\n",
      "epoch:29 step:27946 [D loss: 0.672862, acc.: 59.38%] [G loss: 1.495894]\n",
      "epoch:29 step:27947 [D loss: 0.168667, acc.: 93.75%] [G loss: 1.777313]\n",
      "epoch:29 step:27948 [D loss: 0.141028, acc.: 96.88%] [G loss: 1.717148]\n",
      "epoch:29 step:27949 [D loss: 0.579007, acc.: 66.41%] [G loss: 0.749413]\n",
      "epoch:29 step:27950 [D loss: 0.777382, acc.: 55.47%] [G loss: 0.967666]\n",
      "epoch:29 step:27951 [D loss: 0.879505, acc.: 46.09%] [G loss: 1.258363]\n",
      "epoch:29 step:27952 [D loss: 0.484448, acc.: 76.56%] [G loss: 1.514717]\n",
      "epoch:29 step:27953 [D loss: 0.153718, acc.: 97.66%] [G loss: 1.451577]\n",
      "epoch:29 step:27954 [D loss: 0.163101, acc.: 96.88%] [G loss: 1.984672]\n",
      "epoch:29 step:27955 [D loss: 0.112559, acc.: 98.44%] [G loss: 1.825316]\n",
      "epoch:29 step:27956 [D loss: 0.302303, acc.: 89.84%] [G loss: 1.778788]\n",
      "epoch:29 step:27957 [D loss: 0.385450, acc.: 80.47%] [G loss: 2.055407]\n",
      "epoch:29 step:27958 [D loss: 0.322396, acc.: 92.19%] [G loss: 1.793533]\n",
      "epoch:29 step:27959 [D loss: 0.154892, acc.: 96.09%] [G loss: 2.098706]\n",
      "epoch:29 step:27960 [D loss: 0.614783, acc.: 65.62%] [G loss: 1.703734]\n",
      "epoch:29 step:27961 [D loss: 0.363260, acc.: 86.72%] [G loss: 1.712158]\n",
      "epoch:29 step:27962 [D loss: 0.686978, acc.: 57.81%] [G loss: 0.414091]\n",
      "epoch:29 step:27963 [D loss: 0.319014, acc.: 89.84%] [G loss: 0.952281]\n",
      "epoch:29 step:27964 [D loss: 0.302868, acc.: 86.72%] [G loss: 1.764540]\n",
      "epoch:29 step:27965 [D loss: 0.112469, acc.: 98.44%] [G loss: 1.945080]\n",
      "epoch:29 step:27966 [D loss: 0.154710, acc.: 95.31%] [G loss: 1.997933]\n",
      "epoch:29 step:27967 [D loss: 0.121560, acc.: 99.22%] [G loss: 1.706253]\n",
      "epoch:29 step:27968 [D loss: 0.346827, acc.: 78.12%] [G loss: 2.740462]\n",
      "epoch:29 step:27969 [D loss: 0.065600, acc.: 100.00%] [G loss: 2.889456]\n",
      "epoch:29 step:27970 [D loss: 0.424702, acc.: 77.34%] [G loss: 2.192631]\n",
      "epoch:29 step:27971 [D loss: 0.265119, acc.: 95.31%] [G loss: 2.208805]\n",
      "epoch:29 step:27972 [D loss: 0.337225, acc.: 89.06%] [G loss: 1.825032]\n",
      "epoch:29 step:27973 [D loss: 1.063754, acc.: 37.50%] [G loss: 2.465572]\n",
      "epoch:29 step:27974 [D loss: 0.522913, acc.: 71.88%] [G loss: 1.775877]\n",
      "epoch:29 step:27975 [D loss: 0.377539, acc.: 85.94%] [G loss: 0.511948]\n",
      "epoch:29 step:27976 [D loss: 0.484521, acc.: 79.69%] [G loss: 2.169572]\n",
      "epoch:29 step:27977 [D loss: 0.168165, acc.: 96.09%] [G loss: 2.396785]\n",
      "epoch:29 step:27978 [D loss: 0.122686, acc.: 98.44%] [G loss: 2.073541]\n",
      "epoch:29 step:27979 [D loss: 0.080928, acc.: 100.00%] [G loss: 2.005289]\n",
      "epoch:29 step:27980 [D loss: 1.000505, acc.: 48.44%] [G loss: 1.761591]\n",
      "epoch:29 step:27981 [D loss: 0.156587, acc.: 98.44%] [G loss: 1.711963]\n",
      "epoch:29 step:27982 [D loss: 0.273542, acc.: 88.28%] [G loss: 1.827658]\n",
      "epoch:29 step:27983 [D loss: 0.324238, acc.: 91.41%] [G loss: 1.692496]\n",
      "epoch:29 step:27984 [D loss: 0.913716, acc.: 46.09%] [G loss: 1.606515]\n",
      "epoch:29 step:27985 [D loss: 0.556859, acc.: 69.53%] [G loss: 1.685508]\n",
      "epoch:29 step:27986 [D loss: 0.655477, acc.: 64.06%] [G loss: 1.654217]\n",
      "epoch:29 step:27987 [D loss: 0.750879, acc.: 53.12%] [G loss: 1.651267]\n",
      "epoch:29 step:27988 [D loss: 0.294779, acc.: 82.81%] [G loss: 1.253169]\n",
      "epoch:29 step:27989 [D loss: 0.162016, acc.: 100.00%] [G loss: 1.697524]\n",
      "epoch:29 step:27990 [D loss: 0.642736, acc.: 62.50%] [G loss: 1.449458]\n",
      "epoch:29 step:27991 [D loss: 0.710122, acc.: 55.47%] [G loss: 1.198845]\n",
      "epoch:29 step:27992 [D loss: 0.407530, acc.: 81.25%] [G loss: 1.462368]\n",
      "epoch:29 step:27993 [D loss: 0.881784, acc.: 39.84%] [G loss: 1.268554]\n",
      "epoch:29 step:27994 [D loss: 0.232276, acc.: 96.88%] [G loss: 1.253684]\n",
      "epoch:29 step:27995 [D loss: 0.631143, acc.: 64.84%] [G loss: 1.130512]\n",
      "epoch:29 step:27996 [D loss: 0.607531, acc.: 64.84%] [G loss: 1.184345]\n",
      "epoch:29 step:27997 [D loss: 0.378525, acc.: 80.47%] [G loss: 1.362944]\n",
      "epoch:29 step:27998 [D loss: 0.193882, acc.: 94.53%] [G loss: 2.013449]\n",
      "epoch:29 step:27999 [D loss: 0.708451, acc.: 57.03%] [G loss: 1.456794]\n",
      "epoch:29 step:28000 [D loss: 0.484070, acc.: 80.47%] [G loss: 1.305744]\n",
      "##############\n",
      "[3.81529906 2.65619633 6.7315331  5.78569348 4.39842131 6.4964311\n",
      " 5.51505121 5.45351602 6.07088279 5.28392807]\n",
      "##########\n",
      "epoch:29 step:28001 [D loss: 0.463884, acc.: 81.25%] [G loss: 1.119018]\n",
      "epoch:29 step:28002 [D loss: 0.752367, acc.: 55.47%] [G loss: 2.261064]\n",
      "epoch:29 step:28003 [D loss: 0.131374, acc.: 99.22%] [G loss: 1.283967]\n",
      "epoch:29 step:28004 [D loss: 0.182766, acc.: 94.53%] [G loss: 1.703512]\n",
      "epoch:29 step:28005 [D loss: 0.360168, acc.: 78.91%] [G loss: 2.538760]\n",
      "epoch:29 step:28006 [D loss: 0.132379, acc.: 96.88%] [G loss: 2.393838]\n",
      "epoch:29 step:28007 [D loss: 0.823530, acc.: 55.47%] [G loss: 2.036158]\n",
      "epoch:29 step:28008 [D loss: 0.687236, acc.: 62.50%] [G loss: 1.684191]\n",
      "epoch:29 step:28009 [D loss: 0.834037, acc.: 50.00%] [G loss: 1.282511]\n",
      "epoch:29 step:28010 [D loss: 0.687226, acc.: 60.16%] [G loss: 1.536397]\n",
      "epoch:29 step:28011 [D loss: 0.600796, acc.: 66.41%] [G loss: 1.235945]\n",
      "epoch:29 step:28012 [D loss: 0.637463, acc.: 65.62%] [G loss: 1.344182]\n",
      "epoch:29 step:28013 [D loss: 0.714949, acc.: 60.94%] [G loss: 1.083573]\n",
      "epoch:29 step:28014 [D loss: 0.398496, acc.: 85.16%] [G loss: 0.854453]\n",
      "epoch:29 step:28015 [D loss: 0.272470, acc.: 91.41%] [G loss: 1.728430]\n",
      "epoch:29 step:28016 [D loss: 0.344589, acc.: 78.91%] [G loss: 1.394893]\n",
      "epoch:29 step:28017 [D loss: 0.239147, acc.: 92.19%] [G loss: 1.965992]\n",
      "epoch:29 step:28018 [D loss: 0.144310, acc.: 99.22%] [G loss: 2.587168]\n",
      "epoch:29 step:28019 [D loss: 0.995868, acc.: 49.22%] [G loss: 1.957931]\n",
      "epoch:29 step:28020 [D loss: 0.177060, acc.: 99.22%] [G loss: 1.665359]\n",
      "epoch:29 step:28021 [D loss: 0.472690, acc.: 77.34%] [G loss: 1.807824]\n",
      "epoch:29 step:28022 [D loss: 0.350943, acc.: 87.50%] [G loss: 1.706275]\n",
      "epoch:29 step:28023 [D loss: 0.241171, acc.: 96.88%] [G loss: 1.835308]\n",
      "epoch:29 step:28024 [D loss: 0.121093, acc.: 98.44%] [G loss: 2.052385]\n",
      "epoch:29 step:28025 [D loss: 0.102745, acc.: 99.22%] [G loss: 1.990690]\n",
      "epoch:29 step:28026 [D loss: 0.153881, acc.: 100.00%] [G loss: 1.975786]\n",
      "epoch:29 step:28027 [D loss: 0.082869, acc.: 99.22%] [G loss: 1.935020]\n",
      "epoch:29 step:28028 [D loss: 0.216705, acc.: 96.09%] [G loss: 1.912620]\n",
      "epoch:29 step:28029 [D loss: 0.488975, acc.: 72.66%] [G loss: 2.083400]\n",
      "epoch:29 step:28030 [D loss: 0.118215, acc.: 100.00%] [G loss: 1.287452]\n",
      "epoch:29 step:28031 [D loss: 0.089555, acc.: 100.00%] [G loss: 2.331739]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:29 step:28032 [D loss: 0.170060, acc.: 95.31%] [G loss: 2.354536]\n",
      "epoch:29 step:28033 [D loss: 0.575203, acc.: 71.09%] [G loss: 2.856393]\n",
      "epoch:29 step:28034 [D loss: 0.432965, acc.: 79.69%] [G loss: 2.420849]\n",
      "epoch:29 step:28035 [D loss: 0.893093, acc.: 53.12%] [G loss: 1.784527]\n",
      "epoch:29 step:28036 [D loss: 0.774312, acc.: 60.16%] [G loss: 1.264139]\n",
      "epoch:29 step:28037 [D loss: 0.646690, acc.: 69.53%] [G loss: 1.506698]\n",
      "epoch:29 step:28038 [D loss: 0.675158, acc.: 62.50%] [G loss: 1.466416]\n",
      "epoch:29 step:28039 [D loss: 0.739588, acc.: 56.25%] [G loss: 1.589679]\n",
      "epoch:29 step:28040 [D loss: 0.837305, acc.: 50.78%] [G loss: 1.349720]\n",
      "epoch:29 step:28041 [D loss: 0.429481, acc.: 80.47%] [G loss: 1.384221]\n",
      "epoch:29 step:28042 [D loss: 0.862974, acc.: 46.09%] [G loss: 1.107692]\n",
      "epoch:29 step:28043 [D loss: 0.309740, acc.: 89.06%] [G loss: 1.197692]\n",
      "epoch:29 step:28044 [D loss: 0.438956, acc.: 81.25%] [G loss: 1.367101]\n",
      "epoch:29 step:28045 [D loss: 0.793973, acc.: 46.88%] [G loss: 1.536250]\n",
      "epoch:29 step:28046 [D loss: 0.570914, acc.: 74.22%] [G loss: 1.366617]\n",
      "epoch:29 step:28047 [D loss: 0.403074, acc.: 89.06%] [G loss: 1.331023]\n",
      "epoch:29 step:28048 [D loss: 0.635978, acc.: 60.94%] [G loss: 1.377006]\n",
      "epoch:29 step:28049 [D loss: 0.354628, acc.: 88.28%] [G loss: 1.455744]\n",
      "epoch:29 step:28050 [D loss: 0.163791, acc.: 98.44%] [G loss: 1.920923]\n",
      "epoch:29 step:28051 [D loss: 0.106261, acc.: 97.66%] [G loss: 1.698133]\n",
      "epoch:29 step:28052 [D loss: 0.492314, acc.: 74.22%] [G loss: 1.467568]\n",
      "epoch:29 step:28053 [D loss: 0.803000, acc.: 53.12%] [G loss: 1.579781]\n",
      "epoch:29 step:28054 [D loss: 0.554446, acc.: 71.09%] [G loss: 1.410047]\n",
      "epoch:29 step:28055 [D loss: 0.360571, acc.: 92.97%] [G loss: 1.290374]\n",
      "epoch:29 step:28056 [D loss: 0.533492, acc.: 72.66%] [G loss: 1.510938]\n",
      "epoch:29 step:28057 [D loss: 0.253595, acc.: 92.19%] [G loss: 1.353245]\n",
      "epoch:29 step:28058 [D loss: 0.354760, acc.: 76.56%] [G loss: 1.753057]\n",
      "epoch:29 step:28059 [D loss: 0.391067, acc.: 83.59%] [G loss: 2.082385]\n",
      "epoch:29 step:28060 [D loss: 0.260669, acc.: 96.09%] [G loss: 1.960098]\n",
      "epoch:29 step:28061 [D loss: 0.960973, acc.: 44.53%] [G loss: 1.095510]\n",
      "epoch:29 step:28062 [D loss: 0.281909, acc.: 92.97%] [G loss: 1.761380]\n",
      "epoch:29 step:28063 [D loss: 0.392607, acc.: 89.84%] [G loss: 0.217327]\n",
      "epoch:29 step:28064 [D loss: 0.229274, acc.: 97.66%] [G loss: 1.026726]\n",
      "epoch:29 step:28065 [D loss: 0.142015, acc.: 99.22%] [G loss: 1.860620]\n",
      "epoch:29 step:28066 [D loss: 0.191067, acc.: 98.44%] [G loss: 1.098905]\n",
      "epoch:29 step:28067 [D loss: 0.170039, acc.: 95.31%] [G loss: 1.977446]\n",
      "epoch:29 step:28068 [D loss: 0.159248, acc.: 95.31%] [G loss: 1.548190]\n",
      "epoch:29 step:28069 [D loss: 0.317453, acc.: 85.16%] [G loss: 2.701220]\n",
      "epoch:29 step:28070 [D loss: 0.078185, acc.: 99.22%] [G loss: 2.897772]\n",
      "epoch:29 step:28071 [D loss: 0.042388, acc.: 100.00%] [G loss: 2.649100]\n",
      "epoch:29 step:28072 [D loss: 0.233397, acc.: 91.41%] [G loss: 3.034608]\n",
      "epoch:29 step:28073 [D loss: 0.231549, acc.: 89.06%] [G loss: 3.293797]\n",
      "epoch:29 step:28074 [D loss: 0.041617, acc.: 100.00%] [G loss: 3.160485]\n",
      "epoch:29 step:28075 [D loss: 0.291168, acc.: 86.72%] [G loss: 3.391102]\n",
      "epoch:29 step:28076 [D loss: 0.049855, acc.: 100.00%] [G loss: 3.192249]\n",
      "epoch:29 step:28077 [D loss: 0.887167, acc.: 59.38%] [G loss: 2.344564]\n",
      "epoch:29 step:28078 [D loss: 0.342194, acc.: 89.06%] [G loss: 2.320458]\n",
      "epoch:29 step:28079 [D loss: 0.785821, acc.: 60.94%] [G loss: 1.511269]\n",
      "epoch:29 step:28080 [D loss: 0.800328, acc.: 54.69%] [G loss: 1.826242]\n",
      "epoch:29 step:28081 [D loss: 0.149194, acc.: 97.66%] [G loss: 1.528754]\n",
      "epoch:29 step:28082 [D loss: 0.176305, acc.: 90.62%] [G loss: 2.341075]\n",
      "epoch:29 step:28083 [D loss: 1.691239, acc.: 10.16%] [G loss: 1.768256]\n",
      "epoch:29 step:28084 [D loss: 0.072074, acc.: 99.22%] [G loss: 2.472712]\n",
      "epoch:29 step:28085 [D loss: 0.105436, acc.: 95.31%] [G loss: 2.072299]\n",
      "epoch:29 step:28086 [D loss: 0.074781, acc.: 100.00%] [G loss: 3.069862]\n",
      "epoch:29 step:28087 [D loss: 0.633947, acc.: 60.94%] [G loss: 2.422461]\n",
      "epoch:29 step:28088 [D loss: 0.158992, acc.: 92.97%] [G loss: 3.364427]\n",
      "epoch:29 step:28089 [D loss: 0.452434, acc.: 78.91%] [G loss: 3.382788]\n",
      "epoch:29 step:28090 [D loss: 0.471383, acc.: 78.12%] [G loss: 2.691301]\n",
      "epoch:29 step:28091 [D loss: 0.113956, acc.: 96.09%] [G loss: 2.750238]\n",
      "epoch:29 step:28092 [D loss: 0.172440, acc.: 93.75%] [G loss: 2.953223]\n",
      "epoch:29 step:28093 [D loss: 1.626498, acc.: 46.09%] [G loss: 1.582604]\n",
      "epoch:29 step:28094 [D loss: 1.100971, acc.: 39.84%] [G loss: 2.024189]\n",
      "epoch:29 step:28095 [D loss: 0.524355, acc.: 71.88%] [G loss: 2.456255]\n",
      "epoch:29 step:28096 [D loss: 0.032885, acc.: 100.00%] [G loss: 3.544913]\n",
      "epoch:29 step:28097 [D loss: 0.060299, acc.: 98.44%] [G loss: 3.101960]\n",
      "epoch:29 step:28098 [D loss: 0.061206, acc.: 98.44%] [G loss: 3.149523]\n",
      "epoch:29 step:28099 [D loss: 0.045184, acc.: 99.22%] [G loss: 2.655916]\n",
      "epoch:29 step:28100 [D loss: 0.209926, acc.: 89.84%] [G loss: 2.715913]\n",
      "epoch:29 step:28101 [D loss: 0.835017, acc.: 44.53%] [G loss: 4.360787]\n",
      "epoch:29 step:28102 [D loss: 0.873844, acc.: 64.06%] [G loss: 1.471889]\n",
      "epoch:29 step:28103 [D loss: 0.363650, acc.: 83.59%] [G loss: 2.355240]\n",
      "epoch:29 step:28104 [D loss: 0.116989, acc.: 97.66%] [G loss: 1.899271]\n",
      "epoch:29 step:28105 [D loss: 0.201503, acc.: 89.84%] [G loss: 2.004455]\n",
      "epoch:29 step:28106 [D loss: 0.220290, acc.: 88.28%] [G loss: 1.963222]\n",
      "epoch:29 step:28107 [D loss: 0.103426, acc.: 97.66%] [G loss: 4.087902]\n",
      "epoch:29 step:28108 [D loss: 0.035391, acc.: 100.00%] [G loss: 2.468027]\n",
      "epoch:29 step:28109 [D loss: 0.051373, acc.: 99.22%] [G loss: 2.120954]\n",
      "epoch:29 step:28110 [D loss: 0.059965, acc.: 98.44%] [G loss: 2.395143]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "if not os.path.isdir('saved_models_mnist_{}'.format('cgan')):\n",
    "    os.mkdir('saved_models_mnist_{}'.format('cgan'))\n",
    "f = open('saved_models_mnist_{}/log_collapse1.txt'.format('cgan'), mode='w')\n",
    "\n",
    "\n",
    "from keras.datasets import fashion_mnist,mnist\n",
    "from keras.layers import Input, Dense, Reshape, Flatten, Dropout, multiply\n",
    "from keras.layers import BatchNormalization, Activation, Embedding, ZeroPadding2D\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.layers.convolutional import UpSampling2D, Conv2D\n",
    "from keras.models import Sequential, Model\n",
    "from keras.optimizers import Adam\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "class CGAN():\n",
    "    def __init__(self):\n",
    "        # Input shape\n",
    "        self.img_rows = 28\n",
    "        self.img_cols = 28\n",
    "        self.channels = 1\n",
    "        self.img_shape = (self.img_rows, self.img_cols, self.channels)\n",
    "        self.num_classes = 10\n",
    "        self.latent_dim = 100\n",
    "        self.x = []\n",
    "        self.y = np.zeros((31, 1), dtype=np.int)\n",
    "        self.y = list(self.y)\n",
    "        for i in range(31):\n",
    "            self.y[i] = []\n",
    "\n",
    "        optimizer = Adam(0.0002, 0.5)\n",
    "\n",
    "        # Build and compile the discriminator\n",
    "        self.discriminator = self.build_discriminator()\n",
    "        self.discriminator.compile(loss=['binary_crossentropy'],\n",
    "            optimizer=optimizer,\n",
    "            metrics=['accuracy'])\n",
    "\n",
    "        # Build the generator\n",
    "        self.generator = self.build_generator()\n",
    "\n",
    "        # The generator takes noise and the target label as input\n",
    "        # and generates the corresponding digit of that label\n",
    "        noise = Input(shape=(self.latent_dim,))\n",
    "        label = Input(shape=(1,))\n",
    "        img = self.generator([noise, label])\n",
    "\n",
    "        # For the combined model we will only train the generator\n",
    "        self.discriminator.trainable = False\n",
    "\n",
    "        # The discriminator takes generated image as input and determines validity\n",
    "        # and the label of that image\n",
    "        valid = self.discriminator([img, label])\n",
    "\n",
    "        # The combined model  (stacked generator and discriminator)\n",
    "        # Trains generator to fool discriminator\n",
    "        self.combined = Model([noise, label], valid)\n",
    "        self.combined.compile(loss=['binary_crossentropy'],\n",
    "            optimizer=optimizer)\n",
    "\n",
    "    def build_generator(self):\n",
    "\n",
    "        model = Sequential()\n",
    "\n",
    "        model.add(Dense(512 * 7 * 7, input_dim=self.latent_dim))\n",
    "        model.add(Reshape((7,7, 512)))\n",
    "        model.add(Activation(\"relu\"))\n",
    "\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(UpSampling2D())\n",
    "        model.add(Conv2D(256, kernel_size=3, padding=\"same\"))\n",
    "        model.add(Activation(\"relu\"))\n",
    "\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(UpSampling2D())\n",
    "        model.add(Conv2D(128, kernel_size=3,strides=1,padding=\"same\"))\n",
    "        model.add(Activation(\"relu\"))\n",
    "\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(UpSampling2D())\n",
    "        model.add(Conv2D(64, kernel_size=3,strides=1, padding=\"same\"))\n",
    "        model.add(Activation(\"relu\"))\n",
    "\n",
    "        model.add(Conv2D(self.channels, strides=2,kernel_size=3, padding=\"same\"))\n",
    "        model.add(Activation(\"tanh\"))\n",
    "\n",
    "        model.summary()\n",
    "\n",
    "        noise = Input(shape=(self.latent_dim,))\n",
    "        label = Input(shape=(1,), dtype='int32')\n",
    "        label_embedding = Flatten()(Embedding(self.num_classes, self.latent_dim)(label))\n",
    "\n",
    "        model_input = multiply([noise, label_embedding])\n",
    "        img = model(model_input)\n",
    "\n",
    "        return Model([noise, label], img)\n",
    "    def build_discriminator(self):\n",
    "        model = Sequential()\n",
    "        model.add(Dense(self.img_rows*self.img_cols*self.channels, input_dim=np.prod(self.img_shape)))\n",
    "        model.add(Reshape((self.img_rows,self.img_cols,self.channels)))\n",
    "\n",
    "        model.add(Conv2D(64, kernel_size=3, strides=2,padding=\"same\"))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(Conv2D(128, kernel_size=3, strides=2, padding=\"same\"))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(Conv2D(256, kernel_size=3, strides=2, padding=\"same\"))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(Conv2D(512, kernel_size=3, strides=1, padding=\"same\"))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "        model.summary()\n",
    "        img = Input(shape=self.img_shape)\n",
    "        label = Input(shape=(1,), dtype='int32')\n",
    "\n",
    "        label_embedding = Flatten()(Embedding(self.num_classes, np.prod(self.img_shape))(label))\n",
    "        flat_img = Flatten()(img)\n",
    "\n",
    "        model_input = multiply([flat_img, label_embedding])\n",
    "\n",
    "        validity = model(model_input)\n",
    "\n",
    "        return Model([img, label], validity)\n",
    "\n",
    "    def train(self, epochs, batch_size=128, sample_interval=50):\n",
    "\n",
    "        # Load the dataset\n",
    "        (X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "        # Configure input\n",
    "        X_train = (X_train.astype(np.float32) - 127.5) / 127.5\n",
    "        X_train = np.expand_dims(X_train, axis=3)\n",
    "        X_test = (X_test.astype(np.float32) - 127.5) / 127.5\n",
    "        # X_test = X_test / 127.5 - 1.\n",
    "        X_test = np.expand_dims(X_test, axis=3)\n",
    "\n",
    "        y_train = y_train.reshape(-1, 1)\n",
    "\n",
    "        # Adversarial ground truths\n",
    "        valid = np.ones((batch_size, 1))\n",
    "        fake = np.zeros((batch_size, 1))\n",
    "\n",
    "        nb_batches = int(X_train.shape[0] / batch_size)\n",
    "        global_step = 0\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "\n",
    "            for index in range(nb_batches):\n",
    "                global_step += 1\n",
    "                imgs = X_train[index * batch_size:(index + 1) * batch_size]\n",
    "                labels = y_train[index * batch_size:(index + 1) * batch_size]\n",
    "\n",
    "                # Sample noise as generator input\n",
    "                noise = np.random.normal(0, 1, (batch_size, 100))\n",
    "\n",
    "                # Generate a half batch of new images\n",
    "                gen_imgs = self.generator.predict([noise, labels])\n",
    "\n",
    "                # Train the discriminator\n",
    "                d_loss_real = self.discriminator.train_on_batch([imgs, labels], valid)\n",
    "                d_loss_fake = self.discriminator.train_on_batch([gen_imgs, labels], fake)\n",
    "                d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
    "\n",
    "                # ---------------------\n",
    "                #  Train Generator\n",
    "                # ---------------------\n",
    "\n",
    "                # Condition on labels\n",
    "                sampled_labels = np.random.randint(0, 10, batch_size).reshape(-1, 1)\n",
    "\n",
    "                # Train the generator\n",
    "                g_loss = self.combined.train_on_batch([noise, sampled_labels], valid)\n",
    "\n",
    "                # Plot the progress\n",
    "                print(\"epoch:%d step:%d [D loss: %f, acc.: %.2f%%] [G loss: %f]\" % (epoch,global_step, d_loss[0], 100 * d_loss[1], g_loss))\n",
    "\n",
    "                sampleSize = 5000\n",
    "                # If at save interval => save generated image samples\n",
    "                if global_step % sample_interval == 0:\n",
    "                    s = self.sample_images(global_step, X_test,y_test, sampleSize)\n",
    "    def sample_images(self, epoch,x_test,y_test,sample_num):\n",
    "        r, c = sample_num//10, 10\n",
    "        noise = np.random.normal(0, 1, (r * c, 100))\n",
    "        sampled_labels = np.array([num for _ in range(r) for num in range(c)])\n",
    "        gen_imgs = self.generator.predict([noise,sampled_labels])\n",
    "        # Rescale images 0 - 1\n",
    "        gen_imgs = 0.5 * gen_imgs + 0.5\n",
    "        labels = np.squeeze(y_test[:sample_num])\n",
    "        labels = np.squeeze(labels)\n",
    "        dis_real = cal_distance_image_real(x_test[:sample_num], labels)\n",
    "        dis_fake = cal_distance_image_fake(gen_imgs)\n",
    "        dis_cha = dis_real - dis_fake\n",
    "        print('##############')\n",
    "        # print(dis_real)\n",
    "        # print(dis_fake)\n",
    "        print(dis_cha)\n",
    "        print('##########')\n",
    "        f.writelines('\\n')\n",
    "        f.writelines('epoch:' + str(epoch))\n",
    "        f.writelines('\\n')\n",
    "        f.writelines('紧度')\n",
    "        f.writelines('\\n')\n",
    "        f.writelines(' %.8f ' % (i) for i in dis_cha)\n",
    "        f.writelines('\\n')\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    cgan = CGAN()\n",
    "    cgan.train(epochs=30, batch_size=64, sample_interval=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pppppppp [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
